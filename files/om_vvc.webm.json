{"text": " So, we continue with our next talk, again, about Codex, next time about VBC, with two projects about encoding and decoding VBC, please welcome Adam. Hi, everyone, so today I want to introduce you to VBank and VBdeck, those are open source implementations for VBC. Now, to pick everyone up about VBC, so VBC is this new codec that was finalized just over two years ago, and if you want to know one thing about VBC, you basically, VBC allows you to have the same quality as HEBC at half the bitrate, and on top of that, it was developed by the Dravet, which is the joint video experts group, and it's called a versatile, because it's applicable in versatile scenarios, right? So we have support for screen content, HDR, as we heard in the previous talk, immersive 8K, and we can do some fancy stuff like doing adaptive streaming with OpenGob. All right, so now let me talk you through a little bit of the background of our projects, VBdeck and VBank. So of course, those are both, you know, those are team efforts, right? They're developed by a whole team of researchers at the front of our HHI, mostly in the video coding systems group. Now front of our HHI, if you don't know it, like modern video coding probably wouldn't be what it is if it wasn't for HHI, and HHI is part of a biggest European research organization, the Front of our Society, which is a big German non-profit. And then about me, so I'm Adam Iskovsky, I've been at HHI since 2016, I've been leading the project since 2019, and since about a year I'm also the co-head of the video coding systems group. So why did we even start the software project? So basically, you know, there was HVC for which the test model was HM, and HVC uses square blocks. So they had this method of indexing blocks within, like within the frames using this set index method, which is really amazing for square blocks. And then, you know, they were exploring VVC based on the exploration model, which was still based on HM, except VVC supports rectangular blocks, right? So it's more than only square blocks, and there were really a lot of code for working around this set index thing. And at HHI, we wanted to do even more than that. So we started work on our own partitioner, and we just decided that this is not going to work. And what we had to do, we basically had to write our own software to deal with it, which we very creatively named the next software, which later became the VTM 1.0. And basically, the biggest difference is we had one big map that was mapping the position within the frame to like an object that was describing the current coding block. So the next software, it became the VTM, which is the reference software for the VVC standard. And you can see there in the graph how the VTM was developing over time with regards to the gains over HM with the encoding time, decoding time. And here, you can also see how we started our implementation projects from VTM. So from the VTM 3.0, super early, we already started work on the VVDec. And then from VTM 6.0, we started the work on VVNG. Then in the early 2020, Benjamin Pross became my boss. We basically started the VCS group, and he brought up the idea maybe we can do the project's open source, which we did initially end of 2020 under a little bit shaky license. But with some back and forth with the headquarters, we were able to change it to like a modified BSD3 license. And after some more back and forth, we actually have an unmodified, like a standard open source license, the clear BSD3. All right, so let's talk some more about the projects, you know, some hard facts. So as I already mentioned, they are based off VTM, they are both written fully in C++, but we do have like a pure C interface. So you can integrate it into frameworks or, you know, just use it from a pure C code. Those are C++ projects, so they are object-based, but it's kept very simple. So we try to, you know, not hide anything, no getters, no setters, and like have all the control over what is happening in the memory. Contrary to some other, you know, some other projects, we do not do assembler at all. We do only vectorization using intrinsics, which of course has the advantage that we get stuff like ARM support for free through this amazing SIMD everywhere library. Also support for Vasem cross compilation, so WebAssembly, which we also did. And what we try to do, we try to make those projects as simple as possible. So basically, we only expose options that are use case relevant, but like the coding options, everything that's like connected to efficiency, we try to define it for the user to just have the simplest experience possible. Yeah, they're both available on GitHub under the PSD3 close clear license, as I already mentioned. All right, so how do we do the development? The development is done internally without HHIs. We have our own main Git repo that we basically, from which we push squashed updates to the GitHub repo. Why is it internal? I know many people find it a little bit, you know, there might be issues with that, but you know, here on the right, you can see, or maybe you cannot see, a typical magic quest that I would, you know, do on the internal stuff, on the internal repo, and I think this is just not something that is ready to be released to the public, you know. So I would rather, you know, hide those kind of hiccups, and yeah, it just takes too much time to make stuff nice for, you know, for being public. And I also think not everyone at HCI might be comfortable, you know, being like a public developer. But yeah, all of the stuff that we have internally, it eventually goes to the public repo, either for new releases, to fix bugs or issues, you know, we develop a big new feature, we would push it, and you know, if someone was to make a large contribution, of course, to rebase the code. All right, so VBDec, the decoder project. So the highlights, it's fully compliant with the main 10 profile of EBC, of course, give or take a few bugs, so actually it was supposed to be fully compliant since the version 1.0. But you know, stuff happens, we find bugs, we fix the bugs. But basically there is no feature that is really missing. It's multi-platform, so it works on all the major, all the major OSs, and it also works on different architectures, thanks to Zimdi everywhere, as mentioned. So we have, like, x86 support, ERM, I also saw people, you know, doing builds for RISC V. So this is very nice. Also one thing I'm kind of proud of also is that from the first version we have like a unified thread pool. So also something that was already talked about, basically everything is, like, all the tasks are collected within this one thread pool that just balances itself, right? There is, like, no frame threads, slice threads, which also means we are multi-threading is independent of bitstream features, right? We don't need tiles, slices to be able to parallelize, so I think this is a really nice feature. All right, let's look a little bit into the development history. So this on the left is, like, the performance graph for, you know, different resolutions, different coding conditions, so like random access or all intram, and, you know, major milestones mentioned 1.0, full compliance with the standard in the version 1.3. We did a three times memory reduction, and, you know, I was also asking myself, how could we ever release any other, how could we have ever released any other version? But yeah, at least we managed to get it better. 1.4 we got a major performance boost based of external contributions in GitHub, so this was really nice to see. And in between, we really had a lot of, you know, small improvements, and as you can see in the graphs, it does add up. All right, about the VVank, so VVank, you know, it's an encoder project. Of course, it's way more complex, way more interesting. It has way more degrees of freedom, right? Like the decoder just does this one thing and has zero degree of freedom, right? Basically the standard tells us exactly what to do, and the encoder has all of those choices that it has to do. Anyway, what I like to say is, you know, it's basically the best open source encoder out there. As you can see here on the right, it's runtime versus efficiency. So, you know, for a given runtime, we can have the best efficiency, and for any of our working points, we can get this efficiency the fastest. Of course, you know, it's not the best encoder if you want to encode UHD live. We're not quite there yet. But, you know, at those slower working points, it really doesn't get better than that, at least not that I am aware of. All right, so we have five presets on the encoder, from faster to slower. And you can see, this is a single-threaded graph, you can see more or less how those presets compare to XO65 in orange. With very efficient multi-treading, at least like between, you know, up to eight threads or with up to 16 threads with some additional options. I'm going to talk about this a little bit in two slides. And we have a very good optimization for human visual system based on the XPS and our metric, which I'm also going to mention a little bit later. We have really excellent rate control, so, you know, with bit rate deviations, rarely more than 2%, and like almost never more than 5%. As I mentioned, simple interface, and it's, you know, this thing can be used for academic, amateur, commercial uses, the license really allows it all. All right, so we have those five presets. How do we derive those presets? Like from an academic point of view, this is actually done in a very interesting way. So we take all not use case-related options of the encoder, and we do, like, large-scale optimization. So we start with a very simple, very fast working point, and then we try to derive which option should be changed as the next one. And this is always the option which basically gives incrementally the next best working point. Right? And this is a huge optimization. It takes really a lot of compute time, so we don't do this so often, like every two or three versions, or if we know one tool got implemented way better, we can, like, try to only optimize for this tool within the option space from the last optimization. We target HD and UHD, natural content, but we do sanity checks for resolution and, like, screen content or, you know, HDR. And the one issue that we still have is, you know, at the beginning here, you can see that our curve gets a little bit steeper, right? So we cannot go too fast, because at some point, for, like, every two times speed up, we're just losing too much efficiency, this is because, you know, we started from the reference software which was designed for the ability, and the efficiency is still work in progress. All right, about the multi-treading. So our multi-treading is also, I would say, done differently than in many other encoders, so we do the multi-treading over CTUs, so, like, the modern macro blocks and CTU lines, like we simulate a wavefront parallel processing without using the syntax, and we parallelize independent frames, right? Like two frames are independent of each other and the references are already done, we can do those in parallel, which, of course, means that, you know, how much we can parallelize depends on the number of CTUs that are available, which are always more in high resolution or with smaller CTU sizes. That's why the faster and fast presets, which have smaller CTUs, they parallelize a little bit better, which you can see on the top right there in the full HD parallelization efficiency plot, right? You can see, like, after eight, it kind of, well, it doesn't saturate, but, like, after eight threads, there might be better ways to utilize the resources than to just enable more threads. Exactly, and how can we improve the scaling? So we can improve the scaling by enabling normative features of EBC, so either doing tiles that is independent regions within the picture, or enabling the normative wavefront, which allows us to kill one dependency within the encoding, and this is on the bottom right, so you can see, you know, if we enable those additional features, the multi-treading scaling actually gets much better, but it costs between three to five percent of bitrate overhead. But still, even with those other features, the encoder is not ready yet for more than, let's say, 32 threads, so, like, you know, if you have a really, really big server, the encoder will not be able to utilize all the cores. Yeah, and about our optimization for the human visual system, it's based on the XPSNR, which is, you know, this new metric that a colleague at HHI developed. It has a really high correlation with most based on some public data sets. There are publications. You can look up. They're mentioned on the bottom left, and it has been contributed to FFMPEG as filter, and I think it is somewhere in the backlog of FFMPEG waiting to be looked at. You can see on the right here a lot of graphs, so basically, in the last JVET meeting, no, the JVET meeting one before last, there was a verification test with actual human subjects, where we, you know, where VTM was tested with, like, the new compression technology, and we submitted VVNG to be tested alongside of it in the slow preset, right? So the slower preset has around the efficiency of VTM. Slow preset is objectively five percent behind, and as you can see in the graphs, VVNG in orange matches or outperforms VTM, which means that our visual optimization is well able to at least close this five percent gap, if not even, you know, add more in terms of visual, like, subject to visual quality. So yeah, that's really nice. All right. VVNG in practice, you know, everyone asks in the end, so what kind of FPS can you achieve? So we did some encodes onto mobile workstation kind of computers, encodes using all defaults, which means eight threads, and, you know, for HD versus live, it's like, for faster, it's around times four, like, live times four, so around 15 FPS, medium around lifetime, times 30, right, so around two FPS, I'm talking about HD 60 FPS as live. For UHD, the faster can do, like, 15 times live, fast 30, and medium, well, let's just say medium would only be of interest for, like, large-scale VOD encodings, right? But you know, FPS also depends on many other factors, like bit rate, content, you know, your actual CPU and stuff like that, so this is more like ballpark numbers. Excuse me, is this HDR content? It is not HDR content, but it's 10-bit. So it should be roughly the same for HDR, like we only do, we only test with 10-bit usually. It works for 8-bit, but it's kind of 10-bit native. All right, also some version history for the VVNC thing, for the VVNC project. So our first major milestone was the 0.3, where we added frame threading, and you can see on this multi-threaded efficiency versus speed graph that it was, you know, a huge leap for us. In the 1.0, we added the pure C interface, allowing, you know, the integrations into pure C frameworks, 1.4, scene cut detection, 1.5, we added, like, arbitrary intra-period, so it doesn't have to be aligned to anything. We added a fast decode preset, and in the newest version, the thing that I really like about it is that we added the ARM support, and, you know, every version, we had improved ray control, things also to, you know, great community feedback, and, you know, from one version to another, your encode might be 10% faster, but if you had a ray control problem and it got fixed, it's going to be, you know, like, way, way better. So this is, like, this hard-to-quantify improvements are actually one of the most important ones. And you know, you can see how the curve behaves, extrapolating, I'm sure we're going to get even faster and better in the future. All right, about the ecosystem and the community, of course, you know, this is raw video encoding and decoding, this is really only of academic interest, right, like, it doesn't really bring you anything. That's why we have been looking into FFMPEG support for a long time. There was an open access paper over one and a half years ago that described how to do it for the decoder. There are some patches in the pipeline with FFMPEG. We also put in our wiki how to apply them manually, if you, you know, if you want to build it, you know, I've talked about this a lot, but the thing is, you know, if it's not in FFMPEG, it doesn't exist. That's why, you know, we put up a, like, how-to for you on how to do it. All right, about playback, once you get this FFMPEG with VBC included, you can just link whatever player uses FFMPEG as its back-end and it's going to work. As far as I know, for VLC, you might force it to use the FFMPEG as the demuxer. Not sure about it. I didn't test it myself. It comes, like, from community feedback. I know there are some exo-player integrations going around, which allow you to, you know, to use it in Android apps more easily. We have a toy web browser example, but it's nothing like the VLC.js. It's really a toy example. And for maxing and demaxing, you can just use GPEG, sorry, for maxing, dashing, you can just use GPEG since the version 2.0. And I think it also needs to be linked to an FFMPEG with VBC support. All right. For the community, we do our open to external contributions and we wish to get some. That's also why I'm talking to you, to get some interest. So we try to, you know, make this more easy by, you know, stating that the authors of VVNC are also retained at copyright. We don't have, like, a contributors agreement, so this is, like, the only way we can make it happen. We are interested in all kinds of contributions, you know, efficiency, speed-up, and, you know, we're going to, throughout the review this, test, generate, result, whatever is needed, give proper feedback, march, so, yeah. Please do if you're interested. To conclude, you know, if you just entered the room, I talked to you about our open source implementations of the VVC standard. And I'm looking forward to, you know, contributions, also results, tests, if you want to try it out, and general feedback. Thanks a lot. And a question in the room, yeah. What confused me, because I know a little bit about the backstory, so H265, right, was the super proprietary and the royalties, and the Alliance for Media Launch, the AV-1 company. Yes. And now your colleague is open source and free, right? So to recap. Why is it H266, is the free? To recap the question, the question was H265 was a proprietary codec with licensing, AV-1 is a non-properary codec, and then I'm talking about VVC, which is the successor of HEVC, so H265. And there is a small confusion, so I'm not talking about the codec as being open source, it's about the implementations of it, right, so you have to differentiate between implementations and the technology itself. There will be licensing for the technology itself, but, you know, there is still open source implementations also of HEVC, so that's kind of the way I would like to see it, you know. So it won't be like with MP3, but also developed, it will be completely free to use, forever? No, it won't. I mean, the software is free to use, but, you know, if you build your streaming service based on the technology, independent of which software you use, you have to pay royalties for the technology. Because you have patents, but patent issues? Yes, I mean, there is, you know, this technology cost stuff to develop, and people want to get their investment back, you know. Okay, disclaimer, I'm doing, yes, in the optimizations for video codec in general. My focus is on, and my comment to you is using a library like Cindy Everywhere, it works. It's going to give you the initial results that you want, but you will never get the optimal performance out of your hardware. We had some really, really good examples of code, particular algorithms like more instructions in forensics, a move mask type of in forensics, that are very common in popular in Intel. If you try to port them with Cindy Everywhere or some kind of abstraction layer to ARM, you're going to have to emulate this behavior, so ideally, you have to provide some way to provide optimized functions for ARM or any other future architecture. Otherwise, you're just going to have your Intel layer transferred, translated to ARM. It will work, but you will never optimize your software. So to recap, to recap the comment, there was a comment that Cindy Everywhere works, gives a nice initial, you know, initial deliverable, but will never match hand optimized assembler. We are... How do you know assembler? See, see the corresponding ARM intrinsics. I mean, when I say assembler, I mean, intrinsics, so, you know, we are aware of it, and we are looking a little bit of it, you know, there are different kinds of intrinsic kernels that are implemented there. You know, sometimes you have like two pieces of memory that needs to be added up and stored somewhere else. There, Cindy Everywhere works really nice, but when it's like lookup tables, shuffles, it works worse. We are aware. We are looking into, you know, identifying the kernels where there's the biggest potential for improvement and doing those manually. We are looking at HDR, implementation of a ARM of VBX, okay, so I'm doing the ARM and VMT optimizations for that, and the way to do the transpose, for example, and that is completely different to the way it is, especially with, because for AVX2, you have 256 bit-wide registers. You don't have that with VM, but you have other instructions to help you try to tackle the outcome. Yeah. So my point is that if you are open to contributions with specific optimizations that you might find people to help with that, but if you restrict yourself to only using the library and only use Intel intrinsics and then translate that one using the library, you might lose some performance. A lot. We are not restricting ourselves, you know, to only using this. It's just because, you know, we only have so many resources, this was the fastest way to do it. We can play it out on, you know, like actually this thing can play out VBC videos with our software, but yeah, totally. I think there is, there would need to be some changes to the build process, maybe to that like structure of the project to enable this, but yeah, this is something really very interesting and I think there will be a lot of research going on in that direction. Thanks. One last question, yeah? How does it compare, what are the advantages of AV1 in terms of compression or computation? Well, yeah, so the question is, what are the advantages of VBC or VVNG? VBC over AV1. All right. So what are the advantages of VBC over AV1? So VBC is a successor to HVBC, right? It was done by people who were really knowledgeable on how to make a standard work. So you know, it's the one thing, it just provides the additional bitrate savings, right? So here you still see like 20% additional bitrate savings over like the best case of AV1 and there isn't so many of these initial hiccups, right? So the HDR support just works, you know, immersive stuff just works a little, like a lot of those things, they just work. And then we can do stuff on top of that, like doing open-gop adaptive streaming, which allows you to reduce the bitrate by like another 10% on top of that, right? Like with all the other standards, I think the adaptive streaming can only be done with close-cops or with a prediction break. I would say more mature, but you know, I know there are different views of this, more compression efficiency and really versatile mature usability. Thank you, Adam. Thanks. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.200000000000001, "text": " So, we continue with our next talk, again, about Codex, next time about VBC, with two", "tokens": [407, 11, 321, 2354, 365, 527, 958, 751, 11, 797, 11, 466, 15549, 87, 11, 958, 565, 466, 691, 7869, 11, 365, 732], "temperature": 0.0, "avg_logprob": -0.44959501786665484, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.14039887487888336}, {"id": 1, "seek": 0, "start": 11.200000000000001, "end": 17.2, "text": " projects about encoding and decoding VBC, please welcome Adam.", "tokens": [4455, 466, 43430, 293, 979, 8616, 691, 7869, 11, 1767, 2928, 7938, 13], "temperature": 0.0, "avg_logprob": -0.44959501786665484, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.14039887487888336}, {"id": 2, "seek": 0, "start": 17.2, "end": 25.52, "text": " Hi, everyone, so today I want to introduce you to VBank and VBdeck, those are open source", "tokens": [2421, 11, 1518, 11, 370, 965, 286, 528, 281, 5366, 291, 281, 691, 33, 657, 293, 691, 33, 1479, 547, 11, 729, 366, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.44959501786665484, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.14039887487888336}, {"id": 3, "seek": 0, "start": 25.52, "end": 27.72, "text": " implementations for VBC.", "tokens": [4445, 763, 337, 691, 7869, 13], "temperature": 0.0, "avg_logprob": -0.44959501786665484, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.14039887487888336}, {"id": 4, "seek": 2772, "start": 27.72, "end": 34.519999999999996, "text": " Now, to pick everyone up about VBC, so VBC is this new codec that was finalized just", "tokens": [823, 11, 281, 1888, 1518, 493, 466, 691, 7869, 11, 370, 691, 7869, 307, 341, 777, 3089, 66, 300, 390, 2572, 1602, 445], "temperature": 0.0, "avg_logprob": -0.19443700994764054, "compression_ratio": 1.610236220472441, "no_speech_prob": 0.00022384626208804548}, {"id": 5, "seek": 2772, "start": 34.519999999999996, "end": 39.72, "text": " over two years ago, and if you want to know one thing about VBC, you basically, VBC allows", "tokens": [670, 732, 924, 2057, 11, 293, 498, 291, 528, 281, 458, 472, 551, 466, 691, 7869, 11, 291, 1936, 11, 691, 7869, 4045], "temperature": 0.0, "avg_logprob": -0.19443700994764054, "compression_ratio": 1.610236220472441, "no_speech_prob": 0.00022384626208804548}, {"id": 6, "seek": 2772, "start": 39.72, "end": 45.519999999999996, "text": " you to have the same quality as HEBC at half the bitrate, and on top of that, it was developed", "tokens": [291, 281, 362, 264, 912, 3125, 382, 11827, 7869, 412, 1922, 264, 857, 4404, 11, 293, 322, 1192, 295, 300, 11, 309, 390, 4743], "temperature": 0.0, "avg_logprob": -0.19443700994764054, "compression_ratio": 1.610236220472441, "no_speech_prob": 0.00022384626208804548}, {"id": 7, "seek": 2772, "start": 45.519999999999996, "end": 51.16, "text": " by the Dravet, which is the joint video experts group, and it's called a versatile, because", "tokens": [538, 264, 15971, 9771, 11, 597, 307, 264, 7225, 960, 8572, 1594, 11, 293, 309, 311, 1219, 257, 25057, 11, 570], "temperature": 0.0, "avg_logprob": -0.19443700994764054, "compression_ratio": 1.610236220472441, "no_speech_prob": 0.00022384626208804548}, {"id": 8, "seek": 2772, "start": 51.16, "end": 53.480000000000004, "text": " it's applicable in versatile scenarios, right?", "tokens": [309, 311, 21142, 294, 25057, 15077, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19443700994764054, "compression_ratio": 1.610236220472441, "no_speech_prob": 0.00022384626208804548}, {"id": 9, "seek": 5348, "start": 53.48, "end": 59.44, "text": " So we have support for screen content, HDR, as we heard in the previous talk, immersive", "tokens": [407, 321, 362, 1406, 337, 2568, 2701, 11, 29650, 11, 382, 321, 2198, 294, 264, 3894, 751, 11, 35409], "temperature": 0.0, "avg_logprob": -0.23747208192176425, "compression_ratio": 1.48068669527897, "no_speech_prob": 8.70689982548356e-05}, {"id": 10, "seek": 5348, "start": 59.44, "end": 65.6, "text": " 8K, and we can do some fancy stuff like doing adaptive streaming with OpenGob.", "tokens": [1649, 42, 11, 293, 321, 393, 360, 512, 10247, 1507, 411, 884, 27912, 11791, 365, 7238, 38, 996, 13], "temperature": 0.0, "avg_logprob": -0.23747208192176425, "compression_ratio": 1.48068669527897, "no_speech_prob": 8.70689982548356e-05}, {"id": 11, "seek": 5348, "start": 65.6, "end": 74.32, "text": " All right, so now let me talk you through a little bit of the background of our projects,", "tokens": [1057, 558, 11, 370, 586, 718, 385, 751, 291, 807, 257, 707, 857, 295, 264, 3678, 295, 527, 4455, 11], "temperature": 0.0, "avg_logprob": -0.23747208192176425, "compression_ratio": 1.48068669527897, "no_speech_prob": 8.70689982548356e-05}, {"id": 12, "seek": 5348, "start": 74.32, "end": 76.32, "text": " VBdeck and VBank.", "tokens": [691, 33, 1479, 547, 293, 691, 33, 657, 13], "temperature": 0.0, "avg_logprob": -0.23747208192176425, "compression_ratio": 1.48068669527897, "no_speech_prob": 8.70689982548356e-05}, {"id": 13, "seek": 5348, "start": 76.32, "end": 81.92, "text": " So of course, those are both, you know, those are team efforts, right?", "tokens": [407, 295, 1164, 11, 729, 366, 1293, 11, 291, 458, 11, 729, 366, 1469, 6484, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.23747208192176425, "compression_ratio": 1.48068669527897, "no_speech_prob": 8.70689982548356e-05}, {"id": 14, "seek": 8192, "start": 81.92, "end": 87.6, "text": " They're developed by a whole team of researchers at the front of our HHI, mostly in the video", "tokens": [814, 434, 4743, 538, 257, 1379, 1469, 295, 10309, 412, 264, 1868, 295, 527, 389, 49038, 11, 5240, 294, 264, 960], "temperature": 0.0, "avg_logprob": -0.1602244415283203, "compression_ratio": 1.6195652173913044, "no_speech_prob": 5.603840691037476e-05}, {"id": 15, "seek": 8192, "start": 87.6, "end": 89.04, "text": " coding systems group.", "tokens": [17720, 3652, 1594, 13], "temperature": 0.0, "avg_logprob": -0.1602244415283203, "compression_ratio": 1.6195652173913044, "no_speech_prob": 5.603840691037476e-05}, {"id": 16, "seek": 8192, "start": 89.04, "end": 94.0, "text": " Now front of our HHI, if you don't know it, like modern video coding probably wouldn't", "tokens": [823, 1868, 295, 527, 389, 49038, 11, 498, 291, 500, 380, 458, 309, 11, 411, 4363, 960, 17720, 1391, 2759, 380], "temperature": 0.0, "avg_logprob": -0.1602244415283203, "compression_ratio": 1.6195652173913044, "no_speech_prob": 5.603840691037476e-05}, {"id": 17, "seek": 8192, "start": 94.0, "end": 101.4, "text": " be what it is if it wasn't for HHI, and HHI is part of a biggest European research organization,", "tokens": [312, 437, 309, 307, 498, 309, 2067, 380, 337, 389, 49038, 11, 293, 389, 49038, 307, 644, 295, 257, 3880, 6473, 2132, 4475, 11], "temperature": 0.0, "avg_logprob": -0.1602244415283203, "compression_ratio": 1.6195652173913044, "no_speech_prob": 5.603840691037476e-05}, {"id": 18, "seek": 8192, "start": 101.4, "end": 105.4, "text": " the Front of our Society, which is a big German non-profit.", "tokens": [264, 17348, 295, 527, 13742, 11, 597, 307, 257, 955, 6521, 2107, 12, 14583, 13], "temperature": 0.0, "avg_logprob": -0.1602244415283203, "compression_ratio": 1.6195652173913044, "no_speech_prob": 5.603840691037476e-05}, {"id": 19, "seek": 8192, "start": 105.4, "end": 110.2, "text": " And then about me, so I'm Adam Iskovsky, I've been at HHI since 2016, I've been leading", "tokens": [400, 550, 466, 385, 11, 370, 286, 478, 7938, 1119, 33516, 25810, 11, 286, 600, 668, 412, 389, 49038, 1670, 6549, 11, 286, 600, 668, 5775], "temperature": 0.0, "avg_logprob": -0.1602244415283203, "compression_ratio": 1.6195652173913044, "no_speech_prob": 5.603840691037476e-05}, {"id": 20, "seek": 11020, "start": 110.2, "end": 115.64, "text": " the project since 2019, and since about a year I'm also the co-head of the video coding", "tokens": [264, 1716, 1670, 6071, 11, 293, 1670, 466, 257, 1064, 286, 478, 611, 264, 598, 12, 1934, 295, 264, 960, 17720], "temperature": 0.0, "avg_logprob": -0.13967628122490144, "compression_ratio": 1.628099173553719, "no_speech_prob": 1.2688677088590339e-05}, {"id": 21, "seek": 11020, "start": 115.64, "end": 118.72, "text": " systems group.", "tokens": [3652, 1594, 13], "temperature": 0.0, "avg_logprob": -0.13967628122490144, "compression_ratio": 1.628099173553719, "no_speech_prob": 1.2688677088590339e-05}, {"id": 22, "seek": 11020, "start": 118.72, "end": 120.76, "text": " So why did we even start the software project?", "tokens": [407, 983, 630, 321, 754, 722, 264, 4722, 1716, 30], "temperature": 0.0, "avg_logprob": -0.13967628122490144, "compression_ratio": 1.628099173553719, "no_speech_prob": 1.2688677088590339e-05}, {"id": 23, "seek": 11020, "start": 120.76, "end": 127.16, "text": " So basically, you know, there was HVC for which the test model was HM, and HVC uses", "tokens": [407, 1936, 11, 291, 458, 11, 456, 390, 389, 53, 34, 337, 597, 264, 1500, 2316, 390, 389, 44, 11, 293, 389, 53, 34, 4960], "temperature": 0.0, "avg_logprob": -0.13967628122490144, "compression_ratio": 1.628099173553719, "no_speech_prob": 1.2688677088590339e-05}, {"id": 24, "seek": 11020, "start": 127.16, "end": 128.16, "text": " square blocks.", "tokens": [3732, 8474, 13], "temperature": 0.0, "avg_logprob": -0.13967628122490144, "compression_ratio": 1.628099173553719, "no_speech_prob": 1.2688677088590339e-05}, {"id": 25, "seek": 11020, "start": 128.16, "end": 134.44, "text": " So they had this method of indexing blocks within, like within the frames using this", "tokens": [407, 436, 632, 341, 3170, 295, 8186, 278, 8474, 1951, 11, 411, 1951, 264, 12083, 1228, 341], "temperature": 0.0, "avg_logprob": -0.13967628122490144, "compression_ratio": 1.628099173553719, "no_speech_prob": 1.2688677088590339e-05}, {"id": 26, "seek": 11020, "start": 134.44, "end": 138.84, "text": " set index method, which is really amazing for square blocks.", "tokens": [992, 8186, 3170, 11, 597, 307, 534, 2243, 337, 3732, 8474, 13], "temperature": 0.0, "avg_logprob": -0.13967628122490144, "compression_ratio": 1.628099173553719, "no_speech_prob": 1.2688677088590339e-05}, {"id": 27, "seek": 13884, "start": 138.84, "end": 145.20000000000002, "text": " And then, you know, they were exploring VVC based on the exploration model, which was", "tokens": [400, 550, 11, 291, 458, 11, 436, 645, 12736, 691, 53, 34, 2361, 322, 264, 16197, 2316, 11, 597, 390], "temperature": 0.0, "avg_logprob": -0.13424808838788202, "compression_ratio": 1.6915254237288135, "no_speech_prob": 4.314061516197398e-05}, {"id": 28, "seek": 13884, "start": 145.20000000000002, "end": 149.28, "text": " still based on HM, except VVC supports rectangular blocks, right?", "tokens": [920, 2361, 322, 389, 44, 11, 3993, 691, 53, 34, 9346, 31167, 8474, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.13424808838788202, "compression_ratio": 1.6915254237288135, "no_speech_prob": 4.314061516197398e-05}, {"id": 29, "seek": 13884, "start": 149.28, "end": 152.52, "text": " So it's more than only square blocks, and there were really a lot of code for working", "tokens": [407, 309, 311, 544, 813, 787, 3732, 8474, 11, 293, 456, 645, 534, 257, 688, 295, 3089, 337, 1364], "temperature": 0.0, "avg_logprob": -0.13424808838788202, "compression_ratio": 1.6915254237288135, "no_speech_prob": 4.314061516197398e-05}, {"id": 30, "seek": 13884, "start": 152.52, "end": 155.32, "text": " around this set index thing.", "tokens": [926, 341, 992, 8186, 551, 13], "temperature": 0.0, "avg_logprob": -0.13424808838788202, "compression_ratio": 1.6915254237288135, "no_speech_prob": 4.314061516197398e-05}, {"id": 31, "seek": 13884, "start": 155.32, "end": 157.88, "text": " And at HHI, we wanted to do even more than that.", "tokens": [400, 412, 389, 49038, 11, 321, 1415, 281, 360, 754, 544, 813, 300, 13], "temperature": 0.0, "avg_logprob": -0.13424808838788202, "compression_ratio": 1.6915254237288135, "no_speech_prob": 4.314061516197398e-05}, {"id": 32, "seek": 13884, "start": 157.88, "end": 161.44, "text": " So we started work on our own partitioner, and we just decided that this is not going", "tokens": [407, 321, 1409, 589, 322, 527, 1065, 24808, 260, 11, 293, 321, 445, 3047, 300, 341, 307, 406, 516], "temperature": 0.0, "avg_logprob": -0.13424808838788202, "compression_ratio": 1.6915254237288135, "no_speech_prob": 4.314061516197398e-05}, {"id": 33, "seek": 13884, "start": 161.44, "end": 162.44, "text": " to work.", "tokens": [281, 589, 13], "temperature": 0.0, "avg_logprob": -0.13424808838788202, "compression_ratio": 1.6915254237288135, "no_speech_prob": 4.314061516197398e-05}, {"id": 34, "seek": 13884, "start": 162.44, "end": 166.8, "text": " And what we had to do, we basically had to write our own software to deal with it, which", "tokens": [400, 437, 321, 632, 281, 360, 11, 321, 1936, 632, 281, 2464, 527, 1065, 4722, 281, 2028, 365, 309, 11, 597], "temperature": 0.0, "avg_logprob": -0.13424808838788202, "compression_ratio": 1.6915254237288135, "no_speech_prob": 4.314061516197398e-05}, {"id": 35, "seek": 16680, "start": 166.8, "end": 174.16000000000003, "text": " we very creatively named the next software, which later became the VTM 1.0.", "tokens": [321, 588, 43750, 4926, 264, 958, 4722, 11, 597, 1780, 3062, 264, 691, 42023, 502, 13, 15, 13], "temperature": 0.0, "avg_logprob": -0.09990207894334516, "compression_ratio": 1.7387755102040816, "no_speech_prob": 3.258170181652531e-05}, {"id": 36, "seek": 16680, "start": 174.16000000000003, "end": 178.8, "text": " And basically, the biggest difference is we had one big map that was mapping the position", "tokens": [400, 1936, 11, 264, 3880, 2649, 307, 321, 632, 472, 955, 4471, 300, 390, 18350, 264, 2535], "temperature": 0.0, "avg_logprob": -0.09990207894334516, "compression_ratio": 1.7387755102040816, "no_speech_prob": 3.258170181652531e-05}, {"id": 37, "seek": 16680, "start": 178.8, "end": 184.28, "text": " within the frame to like an object that was describing the current coding block.", "tokens": [1951, 264, 3920, 281, 411, 364, 2657, 300, 390, 16141, 264, 2190, 17720, 3461, 13], "temperature": 0.0, "avg_logprob": -0.09990207894334516, "compression_ratio": 1.7387755102040816, "no_speech_prob": 3.258170181652531e-05}, {"id": 38, "seek": 16680, "start": 184.28, "end": 189.48000000000002, "text": " So the next software, it became the VTM, which is the reference software for the VVC standard.", "tokens": [407, 264, 958, 4722, 11, 309, 3062, 264, 691, 42023, 11, 597, 307, 264, 6408, 4722, 337, 264, 691, 53, 34, 3832, 13], "temperature": 0.0, "avg_logprob": -0.09990207894334516, "compression_ratio": 1.7387755102040816, "no_speech_prob": 3.258170181652531e-05}, {"id": 39, "seek": 16680, "start": 189.48000000000002, "end": 193.8, "text": " And you can see there in the graph how the VTM was developing over time with regards", "tokens": [400, 291, 393, 536, 456, 294, 264, 4295, 577, 264, 691, 42023, 390, 6416, 670, 565, 365, 14258], "temperature": 0.0, "avg_logprob": -0.09990207894334516, "compression_ratio": 1.7387755102040816, "no_speech_prob": 3.258170181652531e-05}, {"id": 40, "seek": 19380, "start": 193.8, "end": 199.32000000000002, "text": " to the gains over HM with the encoding time, decoding time.", "tokens": [281, 264, 16823, 670, 389, 44, 365, 264, 43430, 565, 11, 979, 8616, 565, 13], "temperature": 0.0, "avg_logprob": -0.16530006100433042, "compression_ratio": 1.536231884057971, "no_speech_prob": 4.153394547756761e-05}, {"id": 41, "seek": 19380, "start": 199.32000000000002, "end": 204.08, "text": " And here, you can also see how we started our implementation projects from VTM.", "tokens": [400, 510, 11, 291, 393, 611, 536, 577, 321, 1409, 527, 11420, 4455, 490, 691, 42023, 13], "temperature": 0.0, "avg_logprob": -0.16530006100433042, "compression_ratio": 1.536231884057971, "no_speech_prob": 4.153394547756761e-05}, {"id": 42, "seek": 19380, "start": 204.08, "end": 208.72, "text": " So from the VTM 3.0, super early, we already started work on the VVDec.", "tokens": [407, 490, 264, 691, 42023, 805, 13, 15, 11, 1687, 2440, 11, 321, 1217, 1409, 589, 322, 264, 691, 53, 35, 3045, 13], "temperature": 0.0, "avg_logprob": -0.16530006100433042, "compression_ratio": 1.536231884057971, "no_speech_prob": 4.153394547756761e-05}, {"id": 43, "seek": 19380, "start": 208.72, "end": 215.24, "text": " And then from VTM 6.0, we started the work on VVNG.", "tokens": [400, 550, 490, 691, 42023, 1386, 13, 15, 11, 321, 1409, 264, 589, 322, 691, 53, 45, 38, 13], "temperature": 0.0, "avg_logprob": -0.16530006100433042, "compression_ratio": 1.536231884057971, "no_speech_prob": 4.153394547756761e-05}, {"id": 44, "seek": 19380, "start": 215.24, "end": 219.96, "text": " Then in the early 2020, Benjamin Pross became my boss.", "tokens": [1396, 294, 264, 2440, 4808, 11, 22231, 430, 1887, 3062, 452, 5741, 13], "temperature": 0.0, "avg_logprob": -0.16530006100433042, "compression_ratio": 1.536231884057971, "no_speech_prob": 4.153394547756761e-05}, {"id": 45, "seek": 21996, "start": 219.96, "end": 225.24, "text": " We basically started the VCS group, and he brought up the idea maybe we can do the project's", "tokens": [492, 1936, 1409, 264, 691, 26283, 1594, 11, 293, 415, 3038, 493, 264, 1558, 1310, 321, 393, 360, 264, 1716, 311], "temperature": 0.0, "avg_logprob": -0.2007442870230045, "compression_ratio": 1.6437246963562753, "no_speech_prob": 2.7105648769065738e-05}, {"id": 46, "seek": 21996, "start": 225.24, "end": 231.52, "text": " open source, which we did initially end of 2020 under a little bit shaky license.", "tokens": [1269, 4009, 11, 597, 321, 630, 9105, 917, 295, 4808, 833, 257, 707, 857, 44785, 10476, 13], "temperature": 0.0, "avg_logprob": -0.2007442870230045, "compression_ratio": 1.6437246963562753, "no_speech_prob": 2.7105648769065738e-05}, {"id": 47, "seek": 21996, "start": 231.52, "end": 235.64000000000001, "text": " But with some back and forth with the headquarters, we were able to change it to like a modified", "tokens": [583, 365, 512, 646, 293, 5220, 365, 264, 21052, 11, 321, 645, 1075, 281, 1319, 309, 281, 411, 257, 15873], "temperature": 0.0, "avg_logprob": -0.2007442870230045, "compression_ratio": 1.6437246963562753, "no_speech_prob": 2.7105648769065738e-05}, {"id": 48, "seek": 21996, "start": 235.64000000000001, "end": 237.08, "text": " BSD3 license.", "tokens": [363, 23969, 18, 10476, 13], "temperature": 0.0, "avg_logprob": -0.2007442870230045, "compression_ratio": 1.6437246963562753, "no_speech_prob": 2.7105648769065738e-05}, {"id": 49, "seek": 21996, "start": 237.08, "end": 242.24, "text": " And after some more back and forth, we actually have an unmodified, like a standard open source", "tokens": [400, 934, 512, 544, 646, 293, 5220, 11, 321, 767, 362, 364, 517, 8014, 2587, 11, 411, 257, 3832, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.2007442870230045, "compression_ratio": 1.6437246963562753, "no_speech_prob": 2.7105648769065738e-05}, {"id": 50, "seek": 21996, "start": 242.24, "end": 244.24, "text": " license, the clear BSD3.", "tokens": [10476, 11, 264, 1850, 363, 23969, 18, 13], "temperature": 0.0, "avg_logprob": -0.2007442870230045, "compression_ratio": 1.6437246963562753, "no_speech_prob": 2.7105648769065738e-05}, {"id": 51, "seek": 24424, "start": 244.24, "end": 252.72, "text": " All right, so let's talk some more about the projects, you know, some hard facts.", "tokens": [1057, 558, 11, 370, 718, 311, 751, 512, 544, 466, 264, 4455, 11, 291, 458, 11, 512, 1152, 9130, 13], "temperature": 0.0, "avg_logprob": -0.17952473958333334, "compression_ratio": 1.606060606060606, "no_speech_prob": 2.494602267688606e-05}, {"id": 52, "seek": 24424, "start": 252.72, "end": 259.28000000000003, "text": " So as I already mentioned, they are based off VTM, they are both written fully in C++,", "tokens": [407, 382, 286, 1217, 2835, 11, 436, 366, 2361, 766, 691, 42023, 11, 436, 366, 1293, 3720, 4498, 294, 383, 25472, 11], "temperature": 0.0, "avg_logprob": -0.17952473958333334, "compression_ratio": 1.606060606060606, "no_speech_prob": 2.494602267688606e-05}, {"id": 53, "seek": 24424, "start": 259.28000000000003, "end": 261.72, "text": " but we do have like a pure C interface.", "tokens": [457, 321, 360, 362, 411, 257, 6075, 383, 9226, 13], "temperature": 0.0, "avg_logprob": -0.17952473958333334, "compression_ratio": 1.606060606060606, "no_speech_prob": 2.494602267688606e-05}, {"id": 54, "seek": 24424, "start": 261.72, "end": 269.16, "text": " So you can integrate it into frameworks or, you know, just use it from a pure C code.", "tokens": [407, 291, 393, 13365, 309, 666, 29834, 420, 11, 291, 458, 11, 445, 764, 309, 490, 257, 6075, 383, 3089, 13], "temperature": 0.0, "avg_logprob": -0.17952473958333334, "compression_ratio": 1.606060606060606, "no_speech_prob": 2.494602267688606e-05}, {"id": 55, "seek": 24424, "start": 269.16, "end": 273.72, "text": " Those are C++ projects, so they are object-based, but it's kept very simple.", "tokens": [3950, 366, 383, 25472, 4455, 11, 370, 436, 366, 2657, 12, 6032, 11, 457, 309, 311, 4305, 588, 2199, 13], "temperature": 0.0, "avg_logprob": -0.17952473958333334, "compression_ratio": 1.606060606060606, "no_speech_prob": 2.494602267688606e-05}, {"id": 56, "seek": 27372, "start": 273.72, "end": 278.48, "text": " So we try to, you know, not hide anything, no getters, no setters, and like have all", "tokens": [407, 321, 853, 281, 11, 291, 458, 11, 406, 6479, 1340, 11, 572, 483, 1559, 11, 572, 992, 1559, 11, 293, 411, 362, 439], "temperature": 0.0, "avg_logprob": -0.15027002768941444, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.00011756590538425371}, {"id": 57, "seek": 27372, "start": 278.48, "end": 282.16, "text": " the control over what is happening in the memory.", "tokens": [264, 1969, 670, 437, 307, 2737, 294, 264, 4675, 13], "temperature": 0.0, "avg_logprob": -0.15027002768941444, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.00011756590538425371}, {"id": 58, "seek": 27372, "start": 282.16, "end": 288.32000000000005, "text": " Contrary to some other, you know, some other projects, we do not do assembler at all.", "tokens": [4839, 81, 822, 281, 512, 661, 11, 291, 458, 11, 512, 661, 4455, 11, 321, 360, 406, 360, 8438, 1918, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.15027002768941444, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.00011756590538425371}, {"id": 59, "seek": 27372, "start": 288.32000000000005, "end": 293.44000000000005, "text": " We do only vectorization using intrinsics, which of course has the advantage that we", "tokens": [492, 360, 787, 8062, 2144, 1228, 28621, 1167, 11, 597, 295, 1164, 575, 264, 5002, 300, 321], "temperature": 0.0, "avg_logprob": -0.15027002768941444, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.00011756590538425371}, {"id": 60, "seek": 27372, "start": 293.44000000000005, "end": 300.64000000000004, "text": " get stuff like ARM support for free through this amazing SIMD everywhere library.", "tokens": [483, 1507, 411, 45209, 1406, 337, 1737, 807, 341, 2243, 24738, 35, 5315, 6405, 13], "temperature": 0.0, "avg_logprob": -0.15027002768941444, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.00011756590538425371}, {"id": 61, "seek": 30064, "start": 300.64, "end": 307.52, "text": " Also support for Vasem cross compilation, so WebAssembly, which we also did.", "tokens": [2743, 1406, 337, 23299, 443, 3278, 40261, 11, 370, 9573, 10884, 19160, 11, 597, 321, 611, 630, 13], "temperature": 0.0, "avg_logprob": -0.1852282010591947, "compression_ratio": 1.6475770925110131, "no_speech_prob": 4.523078678175807e-05}, {"id": 62, "seek": 30064, "start": 307.52, "end": 311.36, "text": " And what we try to do, we try to make those projects as simple as possible.", "tokens": [400, 437, 321, 853, 281, 360, 11, 321, 853, 281, 652, 729, 4455, 382, 2199, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.1852282010591947, "compression_ratio": 1.6475770925110131, "no_speech_prob": 4.523078678175807e-05}, {"id": 63, "seek": 30064, "start": 311.36, "end": 316.0, "text": " So basically, we only expose options that are use case relevant, but like the coding", "tokens": [407, 1936, 11, 321, 787, 19219, 3956, 300, 366, 764, 1389, 7340, 11, 457, 411, 264, 17720], "temperature": 0.0, "avg_logprob": -0.1852282010591947, "compression_ratio": 1.6475770925110131, "no_speech_prob": 4.523078678175807e-05}, {"id": 64, "seek": 30064, "start": 316.0, "end": 321.36, "text": " options, everything that's like connected to efficiency, we try to define it for the", "tokens": [3956, 11, 1203, 300, 311, 411, 4582, 281, 10493, 11, 321, 853, 281, 6964, 309, 337, 264], "temperature": 0.0, "avg_logprob": -0.1852282010591947, "compression_ratio": 1.6475770925110131, "no_speech_prob": 4.523078678175807e-05}, {"id": 65, "seek": 30064, "start": 321.36, "end": 324.76, "text": " user to just have the simplest experience possible.", "tokens": [4195, 281, 445, 362, 264, 22811, 1752, 1944, 13], "temperature": 0.0, "avg_logprob": -0.1852282010591947, "compression_ratio": 1.6475770925110131, "no_speech_prob": 4.523078678175807e-05}, {"id": 66, "seek": 32476, "start": 324.76, "end": 330.96, "text": " Yeah, they're both available on GitHub under the PSD3 close clear license, as I already", "tokens": [865, 11, 436, 434, 1293, 2435, 322, 23331, 833, 264, 8168, 35, 18, 1998, 1850, 10476, 11, 382, 286, 1217], "temperature": 0.0, "avg_logprob": -0.21620297865434127, "compression_ratio": 1.5419847328244274, "no_speech_prob": 3.011470107594505e-05}, {"id": 67, "seek": 32476, "start": 330.96, "end": 331.96, "text": " mentioned.", "tokens": [2835, 13], "temperature": 0.0, "avg_logprob": -0.21620297865434127, "compression_ratio": 1.5419847328244274, "no_speech_prob": 3.011470107594505e-05}, {"id": 68, "seek": 32476, "start": 331.96, "end": 334.15999999999997, "text": " All right, so how do we do the development?", "tokens": [1057, 558, 11, 370, 577, 360, 321, 360, 264, 3250, 30], "temperature": 0.0, "avg_logprob": -0.21620297865434127, "compression_ratio": 1.5419847328244274, "no_speech_prob": 3.011470107594505e-05}, {"id": 69, "seek": 32476, "start": 334.15999999999997, "end": 337.52, "text": " The development is done internally without HHIs.", "tokens": [440, 3250, 307, 1096, 19501, 1553, 389, 39, 6802, 13], "temperature": 0.0, "avg_logprob": -0.21620297865434127, "compression_ratio": 1.5419847328244274, "no_speech_prob": 3.011470107594505e-05}, {"id": 70, "seek": 32476, "start": 337.52, "end": 346.4, "text": " We have our own main Git repo that we basically, from which we push squashed updates to the", "tokens": [492, 362, 527, 1065, 2135, 16939, 49040, 300, 321, 1936, 11, 490, 597, 321, 2944, 2339, 12219, 9205, 281, 264], "temperature": 0.0, "avg_logprob": -0.21620297865434127, "compression_ratio": 1.5419847328244274, "no_speech_prob": 3.011470107594505e-05}, {"id": 71, "seek": 32476, "start": 346.4, "end": 347.4, "text": " GitHub repo.", "tokens": [23331, 49040, 13], "temperature": 0.0, "avg_logprob": -0.21620297865434127, "compression_ratio": 1.5419847328244274, "no_speech_prob": 3.011470107594505e-05}, {"id": 72, "seek": 32476, "start": 347.4, "end": 348.4, "text": " Why is it internal?", "tokens": [1545, 307, 309, 6920, 30], "temperature": 0.0, "avg_logprob": -0.21620297865434127, "compression_ratio": 1.5419847328244274, "no_speech_prob": 3.011470107594505e-05}, {"id": 73, "seek": 32476, "start": 348.4, "end": 353.36, "text": " I know many people find it a little bit, you know, there might be issues with that, but", "tokens": [286, 458, 867, 561, 915, 309, 257, 707, 857, 11, 291, 458, 11, 456, 1062, 312, 2663, 365, 300, 11, 457], "temperature": 0.0, "avg_logprob": -0.21620297865434127, "compression_ratio": 1.5419847328244274, "no_speech_prob": 3.011470107594505e-05}, {"id": 74, "seek": 35336, "start": 353.36, "end": 358.28000000000003, "text": " you know, here on the right, you can see, or maybe you cannot see, a typical magic", "tokens": [291, 458, 11, 510, 322, 264, 558, 11, 291, 393, 536, 11, 420, 1310, 291, 2644, 536, 11, 257, 7476, 5585], "temperature": 0.0, "avg_logprob": -0.17468369973672404, "compression_ratio": 1.8099547511312217, "no_speech_prob": 6.874431710457429e-05}, {"id": 75, "seek": 35336, "start": 358.28000000000003, "end": 363.44, "text": " quest that I would, you know, do on the internal stuff, on the internal repo, and I think this", "tokens": [866, 300, 286, 576, 11, 291, 458, 11, 360, 322, 264, 6920, 1507, 11, 322, 264, 6920, 49040, 11, 293, 286, 519, 341], "temperature": 0.0, "avg_logprob": -0.17468369973672404, "compression_ratio": 1.8099547511312217, "no_speech_prob": 6.874431710457429e-05}, {"id": 76, "seek": 35336, "start": 363.44, "end": 368.48, "text": " is just not something that is ready to be released to the public, you know.", "tokens": [307, 445, 406, 746, 300, 307, 1919, 281, 312, 4736, 281, 264, 1908, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.17468369973672404, "compression_ratio": 1.8099547511312217, "no_speech_prob": 6.874431710457429e-05}, {"id": 77, "seek": 35336, "start": 368.48, "end": 374.04, "text": " So I would rather, you know, hide those kind of hiccups, and yeah, it just takes too much", "tokens": [407, 286, 576, 2831, 11, 291, 458, 11, 6479, 729, 733, 295, 23697, 66, 7528, 11, 293, 1338, 11, 309, 445, 2516, 886, 709], "temperature": 0.0, "avg_logprob": -0.17468369973672404, "compression_ratio": 1.8099547511312217, "no_speech_prob": 6.874431710457429e-05}, {"id": 78, "seek": 35336, "start": 374.04, "end": 379.0, "text": " time to make stuff nice for, you know, for being public.", "tokens": [565, 281, 652, 1507, 1481, 337, 11, 291, 458, 11, 337, 885, 1908, 13], "temperature": 0.0, "avg_logprob": -0.17468369973672404, "compression_ratio": 1.8099547511312217, "no_speech_prob": 6.874431710457429e-05}, {"id": 79, "seek": 37900, "start": 379.0, "end": 383.68, "text": " And I also think not everyone at HCI might be comfortable, you know, being like a public", "tokens": [400, 286, 611, 519, 406, 1518, 412, 389, 25240, 1062, 312, 4619, 11, 291, 458, 11, 885, 411, 257, 1908], "temperature": 0.0, "avg_logprob": -0.20390820503234863, "compression_ratio": 1.6150943396226416, "no_speech_prob": 1.7980410120799206e-05}, {"id": 80, "seek": 37900, "start": 383.68, "end": 384.68, "text": " developer.", "tokens": [10754, 13], "temperature": 0.0, "avg_logprob": -0.20390820503234863, "compression_ratio": 1.6150943396226416, "no_speech_prob": 1.7980410120799206e-05}, {"id": 81, "seek": 37900, "start": 384.68, "end": 389.48, "text": " But yeah, all of the stuff that we have internally, it eventually goes to the public repo, either", "tokens": [583, 1338, 11, 439, 295, 264, 1507, 300, 321, 362, 19501, 11, 309, 4728, 1709, 281, 264, 1908, 49040, 11, 2139], "temperature": 0.0, "avg_logprob": -0.20390820503234863, "compression_ratio": 1.6150943396226416, "no_speech_prob": 1.7980410120799206e-05}, {"id": 82, "seek": 37900, "start": 389.48, "end": 395.08, "text": " for new releases, to fix bugs or issues, you know, we develop a big new feature, we would", "tokens": [337, 777, 16952, 11, 281, 3191, 15120, 420, 2663, 11, 291, 458, 11, 321, 1499, 257, 955, 777, 4111, 11, 321, 576], "temperature": 0.0, "avg_logprob": -0.20390820503234863, "compression_ratio": 1.6150943396226416, "no_speech_prob": 1.7980410120799206e-05}, {"id": 83, "seek": 37900, "start": 395.08, "end": 400.44, "text": " push it, and you know, if someone was to make a large contribution, of course, to rebase", "tokens": [2944, 309, 11, 293, 291, 458, 11, 498, 1580, 390, 281, 652, 257, 2416, 13150, 11, 295, 1164, 11, 281, 12970, 651], "temperature": 0.0, "avg_logprob": -0.20390820503234863, "compression_ratio": 1.6150943396226416, "no_speech_prob": 1.7980410120799206e-05}, {"id": 84, "seek": 37900, "start": 400.44, "end": 401.44, "text": " the code.", "tokens": [264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.20390820503234863, "compression_ratio": 1.6150943396226416, "no_speech_prob": 1.7980410120799206e-05}, {"id": 85, "seek": 37900, "start": 401.44, "end": 406.72, "text": " All right, so VBDec, the decoder project.", "tokens": [1057, 558, 11, 370, 691, 33, 35, 3045, 11, 264, 979, 19866, 1716, 13], "temperature": 0.0, "avg_logprob": -0.20390820503234863, "compression_ratio": 1.6150943396226416, "no_speech_prob": 1.7980410120799206e-05}, {"id": 86, "seek": 40672, "start": 406.72, "end": 411.84000000000003, "text": " So the highlights, it's fully compliant with the main 10 profile of EBC, of course, give", "tokens": [407, 264, 14254, 11, 309, 311, 4498, 36248, 365, 264, 2135, 1266, 7964, 295, 462, 7869, 11, 295, 1164, 11, 976], "temperature": 0.0, "avg_logprob": -0.18061751704062184, "compression_ratio": 1.6263345195729537, "no_speech_prob": 2.913169919338543e-05}, {"id": 87, "seek": 40672, "start": 411.84000000000003, "end": 416.72, "text": " or take a few bugs, so actually it was supposed to be fully compliant since the version 1.0.", "tokens": [420, 747, 257, 1326, 15120, 11, 370, 767, 309, 390, 3442, 281, 312, 4498, 36248, 1670, 264, 3037, 502, 13, 15, 13], "temperature": 0.0, "avg_logprob": -0.18061751704062184, "compression_ratio": 1.6263345195729537, "no_speech_prob": 2.913169919338543e-05}, {"id": 88, "seek": 40672, "start": 416.72, "end": 420.68, "text": " But you know, stuff happens, we find bugs, we fix the bugs.", "tokens": [583, 291, 458, 11, 1507, 2314, 11, 321, 915, 15120, 11, 321, 3191, 264, 15120, 13], "temperature": 0.0, "avg_logprob": -0.18061751704062184, "compression_ratio": 1.6263345195729537, "no_speech_prob": 2.913169919338543e-05}, {"id": 89, "seek": 40672, "start": 420.68, "end": 424.04, "text": " But basically there is no feature that is really missing.", "tokens": [583, 1936, 456, 307, 572, 4111, 300, 307, 534, 5361, 13], "temperature": 0.0, "avg_logprob": -0.18061751704062184, "compression_ratio": 1.6263345195729537, "no_speech_prob": 2.913169919338543e-05}, {"id": 90, "seek": 40672, "start": 424.04, "end": 430.28000000000003, "text": " It's multi-platform, so it works on all the major, all the major OSs, and it also works", "tokens": [467, 311, 4825, 12, 39975, 837, 11, 370, 309, 1985, 322, 439, 264, 2563, 11, 439, 264, 2563, 12731, 82, 11, 293, 309, 611, 1985], "temperature": 0.0, "avg_logprob": -0.18061751704062184, "compression_ratio": 1.6263345195729537, "no_speech_prob": 2.913169919338543e-05}, {"id": 91, "seek": 40672, "start": 430.28000000000003, "end": 433.88000000000005, "text": " on different architectures, thanks to Zimdi everywhere, as mentioned.", "tokens": [322, 819, 6331, 1303, 11, 3231, 281, 1176, 332, 4504, 5315, 11, 382, 2835, 13], "temperature": 0.0, "avg_logprob": -0.18061751704062184, "compression_ratio": 1.6263345195729537, "no_speech_prob": 2.913169919338543e-05}, {"id": 92, "seek": 43388, "start": 433.88, "end": 439.52, "text": " So we have, like, x86 support, ERM, I also saw people, you know, doing builds for RISC", "tokens": [407, 321, 362, 11, 411, 11, 2031, 22193, 1406, 11, 14929, 44, 11, 286, 611, 1866, 561, 11, 291, 458, 11, 884, 15182, 337, 497, 2343, 34], "temperature": 0.0, "avg_logprob": -0.20091128126483096, "compression_ratio": 1.549800796812749, "no_speech_prob": 2.871583819796797e-05}, {"id": 93, "seek": 43388, "start": 439.52, "end": 441.32, "text": " V.", "tokens": [691, 13], "temperature": 0.0, "avg_logprob": -0.20091128126483096, "compression_ratio": 1.549800796812749, "no_speech_prob": 2.871583819796797e-05}, {"id": 94, "seek": 43388, "start": 441.32, "end": 443.2, "text": " So this is very nice.", "tokens": [407, 341, 307, 588, 1481, 13], "temperature": 0.0, "avg_logprob": -0.20091128126483096, "compression_ratio": 1.549800796812749, "no_speech_prob": 2.871583819796797e-05}, {"id": 95, "seek": 43388, "start": 443.2, "end": 448.28, "text": " Also one thing I'm kind of proud of also is that from the first version we have like", "tokens": [2743, 472, 551, 286, 478, 733, 295, 4570, 295, 611, 307, 300, 490, 264, 700, 3037, 321, 362, 411], "temperature": 0.0, "avg_logprob": -0.20091128126483096, "compression_ratio": 1.549800796812749, "no_speech_prob": 2.871583819796797e-05}, {"id": 96, "seek": 43388, "start": 448.28, "end": 450.2, "text": " a unified thread pool.", "tokens": [257, 26787, 7207, 7005, 13], "temperature": 0.0, "avg_logprob": -0.20091128126483096, "compression_ratio": 1.549800796812749, "no_speech_prob": 2.871583819796797e-05}, {"id": 97, "seek": 43388, "start": 450.2, "end": 455.44, "text": " So also something that was already talked about, basically everything is, like, all the tasks", "tokens": [407, 611, 746, 300, 390, 1217, 2825, 466, 11, 1936, 1203, 307, 11, 411, 11, 439, 264, 9608], "temperature": 0.0, "avg_logprob": -0.20091128126483096, "compression_ratio": 1.549800796812749, "no_speech_prob": 2.871583819796797e-05}, {"id": 98, "seek": 43388, "start": 455.44, "end": 460.12, "text": " are collected within this one thread pool that just balances itself, right?", "tokens": [366, 11087, 1951, 341, 472, 7207, 7005, 300, 445, 33993, 2564, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.20091128126483096, "compression_ratio": 1.549800796812749, "no_speech_prob": 2.871583819796797e-05}, {"id": 99, "seek": 46012, "start": 460.12, "end": 464.88, "text": " There is, like, no frame threads, slice threads, which also means we are multi-threading is", "tokens": [821, 307, 11, 411, 11, 572, 3920, 19314, 11, 13153, 19314, 11, 597, 611, 1355, 321, 366, 4825, 12, 392, 35908, 307], "temperature": 0.0, "avg_logprob": -0.2091678526343369, "compression_ratio": 1.6857142857142857, "no_speech_prob": 2.5395816919626668e-05}, {"id": 100, "seek": 46012, "start": 464.88, "end": 466.92, "text": " independent of bitstream features, right?", "tokens": [6695, 295, 857, 9291, 4122, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2091678526343369, "compression_ratio": 1.6857142857142857, "no_speech_prob": 2.5395816919626668e-05}, {"id": 101, "seek": 46012, "start": 466.92, "end": 473.2, "text": " We don't need tiles, slices to be able to parallelize, so I think this is a really nice", "tokens": [492, 500, 380, 643, 21982, 11, 19793, 281, 312, 1075, 281, 8952, 1125, 11, 370, 286, 519, 341, 307, 257, 534, 1481], "temperature": 0.0, "avg_logprob": -0.2091678526343369, "compression_ratio": 1.6857142857142857, "no_speech_prob": 2.5395816919626668e-05}, {"id": 102, "seek": 46012, "start": 473.2, "end": 474.2, "text": " feature.", "tokens": [4111, 13], "temperature": 0.0, "avg_logprob": -0.2091678526343369, "compression_ratio": 1.6857142857142857, "no_speech_prob": 2.5395816919626668e-05}, {"id": 103, "seek": 46012, "start": 474.2, "end": 476.72, "text": " All right, let's look a little bit into the development history.", "tokens": [1057, 558, 11, 718, 311, 574, 257, 707, 857, 666, 264, 3250, 2503, 13], "temperature": 0.0, "avg_logprob": -0.2091678526343369, "compression_ratio": 1.6857142857142857, "no_speech_prob": 2.5395816919626668e-05}, {"id": 104, "seek": 46012, "start": 476.72, "end": 482.08, "text": " So this on the left is, like, the performance graph for, you know, different resolutions,", "tokens": [407, 341, 322, 264, 1411, 307, 11, 411, 11, 264, 3389, 4295, 337, 11, 291, 458, 11, 819, 32179, 11], "temperature": 0.0, "avg_logprob": -0.2091678526343369, "compression_ratio": 1.6857142857142857, "no_speech_prob": 2.5395816919626668e-05}, {"id": 105, "seek": 46012, "start": 482.08, "end": 488.28000000000003, "text": " different coding conditions, so like random access or all intram, and, you know, major", "tokens": [819, 17720, 4487, 11, 370, 411, 4974, 2105, 420, 439, 560, 2356, 11, 293, 11, 291, 458, 11, 2563], "temperature": 0.0, "avg_logprob": -0.2091678526343369, "compression_ratio": 1.6857142857142857, "no_speech_prob": 2.5395816919626668e-05}, {"id": 106, "seek": 48828, "start": 488.28, "end": 493.35999999999996, "text": " milestones mentioned 1.0, full compliance with the standard in the version 1.3.", "tokens": [42038, 2835, 502, 13, 15, 11, 1577, 15882, 365, 264, 3832, 294, 264, 3037, 502, 13, 18, 13], "temperature": 0.0, "avg_logprob": -0.2256253378731864, "compression_ratio": 1.6215139442231075, "no_speech_prob": 6.263356044655666e-05}, {"id": 107, "seek": 48828, "start": 493.35999999999996, "end": 498.03999999999996, "text": " We did a three times memory reduction, and, you know, I was also asking myself, how could", "tokens": [492, 630, 257, 1045, 1413, 4675, 11004, 11, 293, 11, 291, 458, 11, 286, 390, 611, 3365, 2059, 11, 577, 727], "temperature": 0.0, "avg_logprob": -0.2256253378731864, "compression_ratio": 1.6215139442231075, "no_speech_prob": 6.263356044655666e-05}, {"id": 108, "seek": 48828, "start": 498.03999999999996, "end": 503.47999999999996, "text": " we ever release any other, how could we have ever released any other version?", "tokens": [321, 1562, 4374, 604, 661, 11, 577, 727, 321, 362, 1562, 4736, 604, 661, 3037, 30], "temperature": 0.0, "avg_logprob": -0.2256253378731864, "compression_ratio": 1.6215139442231075, "no_speech_prob": 6.263356044655666e-05}, {"id": 109, "seek": 48828, "start": 503.47999999999996, "end": 507.55999999999995, "text": " But yeah, at least we managed to get it better.", "tokens": [583, 1338, 11, 412, 1935, 321, 6453, 281, 483, 309, 1101, 13], "temperature": 0.0, "avg_logprob": -0.2256253378731864, "compression_ratio": 1.6215139442231075, "no_speech_prob": 6.263356044655666e-05}, {"id": 110, "seek": 48828, "start": 507.55999999999995, "end": 514.0, "text": " 1.4 we got a major performance boost based of external contributions in GitHub, so this", "tokens": [502, 13, 19, 321, 658, 257, 2563, 3389, 9194, 2361, 295, 8320, 15725, 294, 23331, 11, 370, 341], "temperature": 0.0, "avg_logprob": -0.2256253378731864, "compression_ratio": 1.6215139442231075, "no_speech_prob": 6.263356044655666e-05}, {"id": 111, "seek": 48828, "start": 514.0, "end": 515.4399999999999, "text": " was really nice to see.", "tokens": [390, 534, 1481, 281, 536, 13], "temperature": 0.0, "avg_logprob": -0.2256253378731864, "compression_ratio": 1.6215139442231075, "no_speech_prob": 6.263356044655666e-05}, {"id": 112, "seek": 51544, "start": 515.44, "end": 520.0, "text": " And in between, we really had a lot of, you know, small improvements, and as you can see", "tokens": [400, 294, 1296, 11, 321, 534, 632, 257, 688, 295, 11, 291, 458, 11, 1359, 13797, 11, 293, 382, 291, 393, 536], "temperature": 0.0, "avg_logprob": -0.20816179814229485, "compression_ratio": 1.7095588235294117, "no_speech_prob": 1.3782558198727202e-05}, {"id": 113, "seek": 51544, "start": 520.0, "end": 522.32, "text": " in the graphs, it does add up.", "tokens": [294, 264, 24877, 11, 309, 775, 909, 493, 13], "temperature": 0.0, "avg_logprob": -0.20816179814229485, "compression_ratio": 1.7095588235294117, "no_speech_prob": 1.3782558198727202e-05}, {"id": 114, "seek": 51544, "start": 522.32, "end": 529.5200000000001, "text": " All right, about the VVank, so VVank, you know, it's an encoder project.", "tokens": [1057, 558, 11, 466, 264, 691, 53, 657, 11, 370, 691, 53, 657, 11, 291, 458, 11, 309, 311, 364, 2058, 19866, 1716, 13], "temperature": 0.0, "avg_logprob": -0.20816179814229485, "compression_ratio": 1.7095588235294117, "no_speech_prob": 1.3782558198727202e-05}, {"id": 115, "seek": 51544, "start": 529.5200000000001, "end": 532.72, "text": " Of course, it's way more complex, way more interesting.", "tokens": [2720, 1164, 11, 309, 311, 636, 544, 3997, 11, 636, 544, 1880, 13], "temperature": 0.0, "avg_logprob": -0.20816179814229485, "compression_ratio": 1.7095588235294117, "no_speech_prob": 1.3782558198727202e-05}, {"id": 116, "seek": 51544, "start": 532.72, "end": 534.24, "text": " It has way more degrees of freedom, right?", "tokens": [467, 575, 636, 544, 5310, 295, 5645, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.20816179814229485, "compression_ratio": 1.7095588235294117, "no_speech_prob": 1.3782558198727202e-05}, {"id": 117, "seek": 51544, "start": 534.24, "end": 539.6800000000001, "text": " Like the decoder just does this one thing and has zero degree of freedom, right?", "tokens": [1743, 264, 979, 19866, 445, 775, 341, 472, 551, 293, 575, 4018, 4314, 295, 5645, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.20816179814229485, "compression_ratio": 1.7095588235294117, "no_speech_prob": 1.3782558198727202e-05}, {"id": 118, "seek": 51544, "start": 539.6800000000001, "end": 545.0400000000001, "text": " Basically the standard tells us exactly what to do, and the encoder has all of those choices", "tokens": [8537, 264, 3832, 5112, 505, 2293, 437, 281, 360, 11, 293, 264, 2058, 19866, 575, 439, 295, 729, 7994], "temperature": 0.0, "avg_logprob": -0.20816179814229485, "compression_ratio": 1.7095588235294117, "no_speech_prob": 1.3782558198727202e-05}, {"id": 119, "seek": 54504, "start": 545.04, "end": 546.56, "text": " that it has to do.", "tokens": [300, 309, 575, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.15625379955957805, "compression_ratio": 1.7654320987654322, "no_speech_prob": 3.919135269825347e-05}, {"id": 120, "seek": 54504, "start": 546.56, "end": 552.04, "text": " Anyway, what I like to say is, you know, it's basically the best open source encoder out", "tokens": [5684, 11, 437, 286, 411, 281, 584, 307, 11, 291, 458, 11, 309, 311, 1936, 264, 1151, 1269, 4009, 2058, 19866, 484], "temperature": 0.0, "avg_logprob": -0.15625379955957805, "compression_ratio": 1.7654320987654322, "no_speech_prob": 3.919135269825347e-05}, {"id": 121, "seek": 54504, "start": 552.04, "end": 553.04, "text": " there.", "tokens": [456, 13], "temperature": 0.0, "avg_logprob": -0.15625379955957805, "compression_ratio": 1.7654320987654322, "no_speech_prob": 3.919135269825347e-05}, {"id": 122, "seek": 54504, "start": 553.04, "end": 556.1999999999999, "text": " As you can see here on the right, it's runtime versus efficiency.", "tokens": [1018, 291, 393, 536, 510, 322, 264, 558, 11, 309, 311, 34474, 5717, 10493, 13], "temperature": 0.0, "avg_logprob": -0.15625379955957805, "compression_ratio": 1.7654320987654322, "no_speech_prob": 3.919135269825347e-05}, {"id": 123, "seek": 54504, "start": 556.1999999999999, "end": 561.92, "text": " So, you know, for a given runtime, we can have the best efficiency, and for any of our", "tokens": [407, 11, 291, 458, 11, 337, 257, 2212, 34474, 11, 321, 393, 362, 264, 1151, 10493, 11, 293, 337, 604, 295, 527], "temperature": 0.0, "avg_logprob": -0.15625379955957805, "compression_ratio": 1.7654320987654322, "no_speech_prob": 3.919135269825347e-05}, {"id": 124, "seek": 54504, "start": 561.92, "end": 566.76, "text": " working points, we can get this efficiency the fastest.", "tokens": [1364, 2793, 11, 321, 393, 483, 341, 10493, 264, 14573, 13], "temperature": 0.0, "avg_logprob": -0.15625379955957805, "compression_ratio": 1.7654320987654322, "no_speech_prob": 3.919135269825347e-05}, {"id": 125, "seek": 54504, "start": 566.76, "end": 570.1999999999999, "text": " Of course, you know, it's not the best encoder if you want to encode UHD live.", "tokens": [2720, 1164, 11, 291, 458, 11, 309, 311, 406, 264, 1151, 2058, 19866, 498, 291, 528, 281, 2058, 1429, 624, 22859, 1621, 13], "temperature": 0.0, "avg_logprob": -0.15625379955957805, "compression_ratio": 1.7654320987654322, "no_speech_prob": 3.919135269825347e-05}, {"id": 126, "seek": 54504, "start": 570.1999999999999, "end": 571.7199999999999, "text": " We're not quite there yet.", "tokens": [492, 434, 406, 1596, 456, 1939, 13], "temperature": 0.0, "avg_logprob": -0.15625379955957805, "compression_ratio": 1.7654320987654322, "no_speech_prob": 3.919135269825347e-05}, {"id": 127, "seek": 57172, "start": 571.72, "end": 576.88, "text": " But, you know, at those slower working points, it really doesn't get better than that, at", "tokens": [583, 11, 291, 458, 11, 412, 729, 14009, 1364, 2793, 11, 309, 534, 1177, 380, 483, 1101, 813, 300, 11, 412], "temperature": 0.0, "avg_logprob": -0.20103604452950613, "compression_ratio": 1.667883211678832, "no_speech_prob": 4.531364538706839e-05}, {"id": 128, "seek": 57172, "start": 576.88, "end": 579.0, "text": " least not that I am aware of.", "tokens": [1935, 406, 300, 286, 669, 3650, 295, 13], "temperature": 0.0, "avg_logprob": -0.20103604452950613, "compression_ratio": 1.667883211678832, "no_speech_prob": 4.531364538706839e-05}, {"id": 129, "seek": 57172, "start": 579.0, "end": 584.48, "text": " All right, so we have five presets on the encoder, from faster to slower.", "tokens": [1057, 558, 11, 370, 321, 362, 1732, 41865, 322, 264, 2058, 19866, 11, 490, 4663, 281, 14009, 13], "temperature": 0.0, "avg_logprob": -0.20103604452950613, "compression_ratio": 1.667883211678832, "no_speech_prob": 4.531364538706839e-05}, {"id": 130, "seek": 57172, "start": 584.48, "end": 589.48, "text": " And you can see, this is a single-threaded graph, you can see more or less how those", "tokens": [400, 291, 393, 536, 11, 341, 307, 257, 2167, 12, 392, 2538, 292, 4295, 11, 291, 393, 536, 544, 420, 1570, 577, 729], "temperature": 0.0, "avg_logprob": -0.20103604452950613, "compression_ratio": 1.667883211678832, "no_speech_prob": 4.531364538706839e-05}, {"id": 131, "seek": 57172, "start": 589.48, "end": 593.12, "text": " presets compare to XO65 in orange.", "tokens": [41865, 6794, 281, 1783, 46, 16824, 294, 7671, 13], "temperature": 0.0, "avg_logprob": -0.20103604452950613, "compression_ratio": 1.667883211678832, "no_speech_prob": 4.531364538706839e-05}, {"id": 132, "seek": 57172, "start": 593.12, "end": 597.72, "text": " With very efficient multi-treading, at least like between, you know, up to eight threads", "tokens": [2022, 588, 7148, 4825, 12, 83, 35908, 11, 412, 1935, 411, 1296, 11, 291, 458, 11, 493, 281, 3180, 19314], "temperature": 0.0, "avg_logprob": -0.20103604452950613, "compression_ratio": 1.667883211678832, "no_speech_prob": 4.531364538706839e-05}, {"id": 133, "seek": 57172, "start": 597.72, "end": 600.28, "text": " or with up to 16 threads with some additional options.", "tokens": [420, 365, 493, 281, 3165, 19314, 365, 512, 4497, 3956, 13], "temperature": 0.0, "avg_logprob": -0.20103604452950613, "compression_ratio": 1.667883211678832, "no_speech_prob": 4.531364538706839e-05}, {"id": 134, "seek": 60028, "start": 600.28, "end": 604.9599999999999, "text": " I'm going to talk about this a little bit in two slides.", "tokens": [286, 478, 516, 281, 751, 466, 341, 257, 707, 857, 294, 732, 9788, 13], "temperature": 0.0, "avg_logprob": -0.1648287477746474, "compression_ratio": 1.612781954887218, "no_speech_prob": 6.739430682500824e-05}, {"id": 135, "seek": 60028, "start": 604.9599999999999, "end": 610.36, "text": " And we have a very good optimization for human visual system based on the XPS and our metric,", "tokens": [400, 321, 362, 257, 588, 665, 19618, 337, 1952, 5056, 1185, 2361, 322, 264, 1783, 6273, 293, 527, 20678, 11], "temperature": 0.0, "avg_logprob": -0.1648287477746474, "compression_ratio": 1.612781954887218, "no_speech_prob": 6.739430682500824e-05}, {"id": 136, "seek": 60028, "start": 610.36, "end": 612.28, "text": " which I'm also going to mention a little bit later.", "tokens": [597, 286, 478, 611, 516, 281, 2152, 257, 707, 857, 1780, 13], "temperature": 0.0, "avg_logprob": -0.1648287477746474, "compression_ratio": 1.612781954887218, "no_speech_prob": 6.739430682500824e-05}, {"id": 137, "seek": 60028, "start": 612.28, "end": 617.64, "text": " We have really excellent rate control, so, you know, with bit rate deviations, rarely", "tokens": [492, 362, 534, 7103, 3314, 1969, 11, 370, 11, 291, 458, 11, 365, 857, 3314, 31219, 763, 11, 13752], "temperature": 0.0, "avg_logprob": -0.1648287477746474, "compression_ratio": 1.612781954887218, "no_speech_prob": 6.739430682500824e-05}, {"id": 138, "seek": 60028, "start": 617.64, "end": 622.24, "text": " more than 2%, and like almost never more than 5%.", "tokens": [544, 813, 568, 8923, 293, 411, 1920, 1128, 544, 813, 1025, 6856], "temperature": 0.0, "avg_logprob": -0.1648287477746474, "compression_ratio": 1.612781954887218, "no_speech_prob": 6.739430682500824e-05}, {"id": 139, "seek": 60028, "start": 622.24, "end": 628.6, "text": " As I mentioned, simple interface, and it's, you know, this thing can be used for academic,", "tokens": [1018, 286, 2835, 11, 2199, 9226, 11, 293, 309, 311, 11, 291, 458, 11, 341, 551, 393, 312, 1143, 337, 7778, 11], "temperature": 0.0, "avg_logprob": -0.1648287477746474, "compression_ratio": 1.612781954887218, "no_speech_prob": 6.739430682500824e-05}, {"id": 140, "seek": 62860, "start": 628.6, "end": 632.88, "text": " amateur, commercial uses, the license really allows it all.", "tokens": [29339, 11, 6841, 4960, 11, 264, 10476, 534, 4045, 309, 439, 13], "temperature": 0.0, "avg_logprob": -0.20760502815246581, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.7197340639540926e-05}, {"id": 141, "seek": 62860, "start": 632.88, "end": 635.52, "text": " All right, so we have those five presets.", "tokens": [1057, 558, 11, 370, 321, 362, 729, 1732, 41865, 13], "temperature": 0.0, "avg_logprob": -0.20760502815246581, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.7197340639540926e-05}, {"id": 142, "seek": 62860, "start": 635.52, "end": 636.96, "text": " How do we derive those presets?", "tokens": [1012, 360, 321, 28446, 729, 41865, 30], "temperature": 0.0, "avg_logprob": -0.20760502815246581, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.7197340639540926e-05}, {"id": 143, "seek": 62860, "start": 636.96, "end": 641.5600000000001, "text": " Like from an academic point of view, this is actually done in a very interesting way.", "tokens": [1743, 490, 364, 7778, 935, 295, 1910, 11, 341, 307, 767, 1096, 294, 257, 588, 1880, 636, 13], "temperature": 0.0, "avg_logprob": -0.20760502815246581, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.7197340639540926e-05}, {"id": 144, "seek": 62860, "start": 641.5600000000001, "end": 646.8000000000001, "text": " So we take all not use case-related options of the encoder, and we do, like, large-scale", "tokens": [407, 321, 747, 439, 406, 764, 1389, 12, 12004, 3956, 295, 264, 2058, 19866, 11, 293, 321, 360, 11, 411, 11, 2416, 12, 20033], "temperature": 0.0, "avg_logprob": -0.20760502815246581, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.7197340639540926e-05}, {"id": 145, "seek": 62860, "start": 646.8000000000001, "end": 647.8000000000001, "text": " optimization.", "tokens": [19618, 13], "temperature": 0.0, "avg_logprob": -0.20760502815246581, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.7197340639540926e-05}, {"id": 146, "seek": 62860, "start": 647.8000000000001, "end": 653.2, "text": " So we start with a very simple, very fast working point, and then we try to derive which", "tokens": [407, 321, 722, 365, 257, 588, 2199, 11, 588, 2370, 1364, 935, 11, 293, 550, 321, 853, 281, 28446, 597], "temperature": 0.0, "avg_logprob": -0.20760502815246581, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.7197340639540926e-05}, {"id": 147, "seek": 62860, "start": 653.2, "end": 656.52, "text": " option should be changed as the next one.", "tokens": [3614, 820, 312, 3105, 382, 264, 958, 472, 13], "temperature": 0.0, "avg_logprob": -0.20760502815246581, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.7197340639540926e-05}, {"id": 148, "seek": 65652, "start": 656.52, "end": 660.76, "text": " And this is always the option which basically gives incrementally the next best working", "tokens": [400, 341, 307, 1009, 264, 3614, 597, 1936, 2709, 26200, 379, 264, 958, 1151, 1364], "temperature": 0.0, "avg_logprob": -0.13363528010821102, "compression_ratio": 1.6623931623931625, "no_speech_prob": 2.5396744604222476e-05}, {"id": 149, "seek": 65652, "start": 660.76, "end": 661.76, "text": " point.", "tokens": [935, 13], "temperature": 0.0, "avg_logprob": -0.13363528010821102, "compression_ratio": 1.6623931623931625, "no_speech_prob": 2.5396744604222476e-05}, {"id": 150, "seek": 65652, "start": 661.76, "end": 662.76, "text": " Right?", "tokens": [1779, 30], "temperature": 0.0, "avg_logprob": -0.13363528010821102, "compression_ratio": 1.6623931623931625, "no_speech_prob": 2.5396744604222476e-05}, {"id": 151, "seek": 65652, "start": 662.76, "end": 663.76, "text": " And this is a huge optimization.", "tokens": [400, 341, 307, 257, 2603, 19618, 13], "temperature": 0.0, "avg_logprob": -0.13363528010821102, "compression_ratio": 1.6623931623931625, "no_speech_prob": 2.5396744604222476e-05}, {"id": 152, "seek": 65652, "start": 663.76, "end": 668.72, "text": " It takes really a lot of compute time, so we don't do this so often, like every two", "tokens": [467, 2516, 534, 257, 688, 295, 14722, 565, 11, 370, 321, 500, 380, 360, 341, 370, 2049, 11, 411, 633, 732], "temperature": 0.0, "avg_logprob": -0.13363528010821102, "compression_ratio": 1.6623931623931625, "no_speech_prob": 2.5396744604222476e-05}, {"id": 153, "seek": 65652, "start": 668.72, "end": 673.84, "text": " or three versions, or if we know one tool got implemented way better, we can, like,", "tokens": [420, 1045, 9606, 11, 420, 498, 321, 458, 472, 2290, 658, 12270, 636, 1101, 11, 321, 393, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.13363528010821102, "compression_ratio": 1.6623931623931625, "no_speech_prob": 2.5396744604222476e-05}, {"id": 154, "seek": 65652, "start": 673.84, "end": 680.0, "text": " try to only optimize for this tool within the option space from the last optimization.", "tokens": [853, 281, 787, 19719, 337, 341, 2290, 1951, 264, 3614, 1901, 490, 264, 1036, 19618, 13], "temperature": 0.0, "avg_logprob": -0.13363528010821102, "compression_ratio": 1.6623931623931625, "no_speech_prob": 2.5396744604222476e-05}, {"id": 155, "seek": 68000, "start": 680.0, "end": 687.08, "text": " We target HD and UHD, natural content, but we do sanity checks for resolution and, like,", "tokens": [492, 3779, 12149, 293, 624, 22859, 11, 3303, 2701, 11, 457, 321, 360, 47892, 13834, 337, 8669, 293, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.15204164537332826, "compression_ratio": 1.6311787072243347, "no_speech_prob": 5.849111403222196e-06}, {"id": 156, "seek": 68000, "start": 687.08, "end": 690.64, "text": " screen content or, you know, HDR.", "tokens": [2568, 2701, 420, 11, 291, 458, 11, 29650, 13], "temperature": 0.0, "avg_logprob": -0.15204164537332826, "compression_ratio": 1.6311787072243347, "no_speech_prob": 5.849111403222196e-06}, {"id": 157, "seek": 68000, "start": 690.64, "end": 696.76, "text": " And the one issue that we still have is, you know, at the beginning here, you can see that", "tokens": [400, 264, 472, 2734, 300, 321, 920, 362, 307, 11, 291, 458, 11, 412, 264, 2863, 510, 11, 291, 393, 536, 300], "temperature": 0.0, "avg_logprob": -0.15204164537332826, "compression_ratio": 1.6311787072243347, "no_speech_prob": 5.849111403222196e-06}, {"id": 158, "seek": 68000, "start": 696.76, "end": 698.84, "text": " our curve gets a little bit steeper, right?", "tokens": [527, 7605, 2170, 257, 707, 857, 16841, 260, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.15204164537332826, "compression_ratio": 1.6311787072243347, "no_speech_prob": 5.849111403222196e-06}, {"id": 159, "seek": 68000, "start": 698.84, "end": 703.96, "text": " So we cannot go too fast, because at some point, for, like, every two times speed up,", "tokens": [407, 321, 2644, 352, 886, 2370, 11, 570, 412, 512, 935, 11, 337, 11, 411, 11, 633, 732, 1413, 3073, 493, 11], "temperature": 0.0, "avg_logprob": -0.15204164537332826, "compression_ratio": 1.6311787072243347, "no_speech_prob": 5.849111403222196e-06}, {"id": 160, "seek": 68000, "start": 703.96, "end": 707.24, "text": " we're just losing too much efficiency, this is because, you know, we started from the", "tokens": [321, 434, 445, 7027, 886, 709, 10493, 11, 341, 307, 570, 11, 291, 458, 11, 321, 1409, 490, 264], "temperature": 0.0, "avg_logprob": -0.15204164537332826, "compression_ratio": 1.6311787072243347, "no_speech_prob": 5.849111403222196e-06}, {"id": 161, "seek": 70724, "start": 707.24, "end": 713.2, "text": " reference software which was designed for the ability, and the efficiency is still work", "tokens": [6408, 4722, 597, 390, 4761, 337, 264, 3485, 11, 293, 264, 10493, 307, 920, 589], "temperature": 0.0, "avg_logprob": -0.2321442257274281, "compression_ratio": 1.5829145728643217, "no_speech_prob": 1.1600967809499707e-05}, {"id": 162, "seek": 70724, "start": 713.2, "end": 714.2, "text": " in progress.", "tokens": [294, 4205, 13], "temperature": 0.0, "avg_logprob": -0.2321442257274281, "compression_ratio": 1.5829145728643217, "no_speech_prob": 1.1600967809499707e-05}, {"id": 163, "seek": 70724, "start": 714.2, "end": 718.36, "text": " All right, about the multi-treading.", "tokens": [1057, 558, 11, 466, 264, 4825, 12, 83, 35908, 13], "temperature": 0.0, "avg_logprob": -0.2321442257274281, "compression_ratio": 1.5829145728643217, "no_speech_prob": 1.1600967809499707e-05}, {"id": 164, "seek": 70724, "start": 718.36, "end": 723.4, "text": " So our multi-treading is also, I would say, done differently than in many other encoders,", "tokens": [407, 527, 4825, 12, 83, 35908, 307, 611, 11, 286, 576, 584, 11, 1096, 7614, 813, 294, 867, 661, 2058, 378, 433, 11], "temperature": 0.0, "avg_logprob": -0.2321442257274281, "compression_ratio": 1.5829145728643217, "no_speech_prob": 1.1600967809499707e-05}, {"id": 165, "seek": 70724, "start": 723.4, "end": 732.48, "text": " so we do the multi-treading over CTUs, so, like, the modern macro blocks and CTU lines,", "tokens": [370, 321, 360, 264, 4825, 12, 83, 35908, 670, 19529, 29211, 11, 370, 11, 411, 11, 264, 4363, 18887, 8474, 293, 19529, 52, 3876, 11], "temperature": 0.0, "avg_logprob": -0.2321442257274281, "compression_ratio": 1.5829145728643217, "no_speech_prob": 1.1600967809499707e-05}, {"id": 166, "seek": 73248, "start": 732.48, "end": 738.64, "text": " like we simulate a wavefront parallel processing without using the syntax, and we parallelize", "tokens": [411, 321, 27817, 257, 5772, 11496, 8952, 9007, 1553, 1228, 264, 28431, 11, 293, 321, 8952, 1125], "temperature": 0.0, "avg_logprob": -0.16281915664672852, "compression_ratio": 1.7061224489795919, "no_speech_prob": 1.3381690223468468e-05}, {"id": 167, "seek": 73248, "start": 738.64, "end": 740.16, "text": " independent frames, right?", "tokens": [6695, 12083, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.16281915664672852, "compression_ratio": 1.7061224489795919, "no_speech_prob": 1.3381690223468468e-05}, {"id": 168, "seek": 73248, "start": 740.16, "end": 743.6800000000001, "text": " Like two frames are independent of each other and the references are already done, we can", "tokens": [1743, 732, 12083, 366, 6695, 295, 1184, 661, 293, 264, 15400, 366, 1217, 1096, 11, 321, 393], "temperature": 0.0, "avg_logprob": -0.16281915664672852, "compression_ratio": 1.7061224489795919, "no_speech_prob": 1.3381690223468468e-05}, {"id": 169, "seek": 73248, "start": 743.6800000000001, "end": 749.72, "text": " do those in parallel, which, of course, means that, you know, how much we can parallelize", "tokens": [360, 729, 294, 8952, 11, 597, 11, 295, 1164, 11, 1355, 300, 11, 291, 458, 11, 577, 709, 321, 393, 8952, 1125], "temperature": 0.0, "avg_logprob": -0.16281915664672852, "compression_ratio": 1.7061224489795919, "no_speech_prob": 1.3381690223468468e-05}, {"id": 170, "seek": 73248, "start": 749.72, "end": 755.32, "text": " depends on the number of CTUs that are available, which are always more in high resolution or", "tokens": [5946, 322, 264, 1230, 295, 19529, 29211, 300, 366, 2435, 11, 597, 366, 1009, 544, 294, 1090, 8669, 420], "temperature": 0.0, "avg_logprob": -0.16281915664672852, "compression_ratio": 1.7061224489795919, "no_speech_prob": 1.3381690223468468e-05}, {"id": 171, "seek": 73248, "start": 755.32, "end": 757.8000000000001, "text": " with smaller CTU sizes.", "tokens": [365, 4356, 19529, 52, 11602, 13], "temperature": 0.0, "avg_logprob": -0.16281915664672852, "compression_ratio": 1.7061224489795919, "no_speech_prob": 1.3381690223468468e-05}, {"id": 172, "seek": 75780, "start": 757.8, "end": 762.64, "text": " That's why the faster and fast presets, which have smaller CTUs, they parallelize a little", "tokens": [663, 311, 983, 264, 4663, 293, 2370, 41865, 11, 597, 362, 4356, 19529, 29211, 11, 436, 8952, 1125, 257, 707], "temperature": 0.0, "avg_logprob": -0.16301482331519032, "compression_ratio": 1.6609442060085837, "no_speech_prob": 2.1617710444843397e-05}, {"id": 173, "seek": 75780, "start": 762.64, "end": 769.3199999999999, "text": " bit better, which you can see on the top right there in the full HD parallelization efficiency", "tokens": [857, 1101, 11, 597, 291, 393, 536, 322, 264, 1192, 558, 456, 294, 264, 1577, 12149, 8952, 2144, 10493], "temperature": 0.0, "avg_logprob": -0.16301482331519032, "compression_ratio": 1.6609442060085837, "no_speech_prob": 2.1617710444843397e-05}, {"id": 174, "seek": 75780, "start": 769.3199999999999, "end": 770.3199999999999, "text": " plot, right?", "tokens": [7542, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.16301482331519032, "compression_ratio": 1.6609442060085837, "no_speech_prob": 2.1617710444843397e-05}, {"id": 175, "seek": 75780, "start": 770.3199999999999, "end": 775.9599999999999, "text": " You can see, like, after eight, it kind of, well, it doesn't saturate, but, like, after", "tokens": [509, 393, 536, 11, 411, 11, 934, 3180, 11, 309, 733, 295, 11, 731, 11, 309, 1177, 380, 21160, 473, 11, 457, 11, 411, 11, 934], "temperature": 0.0, "avg_logprob": -0.16301482331519032, "compression_ratio": 1.6609442060085837, "no_speech_prob": 2.1617710444843397e-05}, {"id": 176, "seek": 75780, "start": 775.9599999999999, "end": 784.24, "text": " eight threads, there might be better ways to utilize the resources than to just enable", "tokens": [3180, 19314, 11, 456, 1062, 312, 1101, 2098, 281, 16117, 264, 3593, 813, 281, 445, 9528], "temperature": 0.0, "avg_logprob": -0.16301482331519032, "compression_ratio": 1.6609442060085837, "no_speech_prob": 2.1617710444843397e-05}, {"id": 177, "seek": 75780, "start": 784.24, "end": 786.24, "text": " more threads.", "tokens": [544, 19314, 13], "temperature": 0.0, "avg_logprob": -0.16301482331519032, "compression_ratio": 1.6609442060085837, "no_speech_prob": 2.1617710444843397e-05}, {"id": 178, "seek": 78624, "start": 786.24, "end": 790.16, "text": " Exactly, and how can we improve the scaling?", "tokens": [7587, 11, 293, 577, 393, 321, 3470, 264, 21589, 30], "temperature": 0.0, "avg_logprob": -0.14297328044458762, "compression_ratio": 1.742489270386266, "no_speech_prob": 3.395572639419697e-05}, {"id": 179, "seek": 78624, "start": 790.16, "end": 795.36, "text": " So we can improve the scaling by enabling normative features of EBC, so either doing", "tokens": [407, 321, 393, 3470, 264, 21589, 538, 23148, 2026, 1166, 4122, 295, 462, 7869, 11, 370, 2139, 884], "temperature": 0.0, "avg_logprob": -0.14297328044458762, "compression_ratio": 1.742489270386266, "no_speech_prob": 3.395572639419697e-05}, {"id": 180, "seek": 78624, "start": 795.36, "end": 802.16, "text": " tiles that is independent regions within the picture, or enabling the normative wavefront,", "tokens": [21982, 300, 307, 6695, 10682, 1951, 264, 3036, 11, 420, 23148, 264, 2026, 1166, 5772, 11496, 11], "temperature": 0.0, "avg_logprob": -0.14297328044458762, "compression_ratio": 1.742489270386266, "no_speech_prob": 3.395572639419697e-05}, {"id": 181, "seek": 78624, "start": 802.16, "end": 810.12, "text": " which allows us to kill one dependency within the encoding, and this is on the bottom right,", "tokens": [597, 4045, 505, 281, 1961, 472, 33621, 1951, 264, 43430, 11, 293, 341, 307, 322, 264, 2767, 558, 11], "temperature": 0.0, "avg_logprob": -0.14297328044458762, "compression_ratio": 1.742489270386266, "no_speech_prob": 3.395572639419697e-05}, {"id": 182, "seek": 78624, "start": 810.12, "end": 814.92, "text": " so you can see, you know, if we enable those additional features, the multi-treading scaling", "tokens": [370, 291, 393, 536, 11, 291, 458, 11, 498, 321, 9528, 729, 4497, 4122, 11, 264, 4825, 12, 83, 35908, 21589], "temperature": 0.0, "avg_logprob": -0.14297328044458762, "compression_ratio": 1.742489270386266, "no_speech_prob": 3.395572639419697e-05}, {"id": 183, "seek": 81492, "start": 814.92, "end": 822.64, "text": " actually gets much better, but it costs between three to five percent of bitrate overhead.", "tokens": [767, 2170, 709, 1101, 11, 457, 309, 5497, 1296, 1045, 281, 1732, 3043, 295, 857, 4404, 19922, 13], "temperature": 0.0, "avg_logprob": -0.16265069788152522, "compression_ratio": 1.5433962264150944, "no_speech_prob": 3.9198261220008135e-05}, {"id": 184, "seek": 81492, "start": 822.64, "end": 827.52, "text": " But still, even with those other features, the encoder is not ready yet for more than,", "tokens": [583, 920, 11, 754, 365, 729, 661, 4122, 11, 264, 2058, 19866, 307, 406, 1919, 1939, 337, 544, 813, 11], "temperature": 0.0, "avg_logprob": -0.16265069788152522, "compression_ratio": 1.5433962264150944, "no_speech_prob": 3.9198261220008135e-05}, {"id": 185, "seek": 81492, "start": 827.52, "end": 834.4, "text": " let's say, 32 threads, so, like, you know, if you have a really, really big server, the", "tokens": [718, 311, 584, 11, 8858, 19314, 11, 370, 11, 411, 11, 291, 458, 11, 498, 291, 362, 257, 534, 11, 534, 955, 7154, 11, 264], "temperature": 0.0, "avg_logprob": -0.16265069788152522, "compression_ratio": 1.5433962264150944, "no_speech_prob": 3.9198261220008135e-05}, {"id": 186, "seek": 81492, "start": 834.4, "end": 837.76, "text": " encoder will not be able to utilize all the cores.", "tokens": [2058, 19866, 486, 406, 312, 1075, 281, 16117, 439, 264, 24826, 13], "temperature": 0.0, "avg_logprob": -0.16265069788152522, "compression_ratio": 1.5433962264150944, "no_speech_prob": 3.9198261220008135e-05}, {"id": 187, "seek": 81492, "start": 837.76, "end": 843.88, "text": " Yeah, and about our optimization for the human visual system, it's based on the XPSNR, which", "tokens": [865, 11, 293, 466, 527, 19618, 337, 264, 1952, 5056, 1185, 11, 309, 311, 2361, 322, 264, 1783, 6273, 45, 49, 11, 597], "temperature": 0.0, "avg_logprob": -0.16265069788152522, "compression_ratio": 1.5433962264150944, "no_speech_prob": 3.9198261220008135e-05}, {"id": 188, "seek": 84388, "start": 843.88, "end": 847.76, "text": " is, you know, this new metric that a colleague at HHI developed.", "tokens": [307, 11, 291, 458, 11, 341, 777, 20678, 300, 257, 13532, 412, 389, 49038, 4743, 13], "temperature": 0.0, "avg_logprob": -0.21325194451116747, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.492146748205414e-05}, {"id": 189, "seek": 84388, "start": 847.76, "end": 851.28, "text": " It has a really high correlation with most based on some public data sets.", "tokens": [467, 575, 257, 534, 1090, 20009, 365, 881, 2361, 322, 512, 1908, 1412, 6352, 13], "temperature": 0.0, "avg_logprob": -0.21325194451116747, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.492146748205414e-05}, {"id": 190, "seek": 84388, "start": 851.28, "end": 852.96, "text": " There are publications.", "tokens": [821, 366, 25618, 13], "temperature": 0.0, "avg_logprob": -0.21325194451116747, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.492146748205414e-05}, {"id": 191, "seek": 84388, "start": 852.96, "end": 853.96, "text": " You can look up.", "tokens": [509, 393, 574, 493, 13], "temperature": 0.0, "avg_logprob": -0.21325194451116747, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.492146748205414e-05}, {"id": 192, "seek": 84388, "start": 853.96, "end": 859.76, "text": " They're mentioned on the bottom left, and it has been contributed to FFMPEG as filter,", "tokens": [814, 434, 2835, 322, 264, 2767, 1411, 11, 293, 309, 575, 668, 18434, 281, 479, 37, 44, 5208, 38, 382, 6608, 11], "temperature": 0.0, "avg_logprob": -0.21325194451116747, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.492146748205414e-05}, {"id": 193, "seek": 84388, "start": 859.76, "end": 866.92, "text": " and I think it is somewhere in the backlog of FFMPEG waiting to be looked at.", "tokens": [293, 286, 519, 309, 307, 4079, 294, 264, 47364, 295, 479, 37, 44, 5208, 38, 3806, 281, 312, 2956, 412, 13], "temperature": 0.0, "avg_logprob": -0.21325194451116747, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.492146748205414e-05}, {"id": 194, "seek": 84388, "start": 866.92, "end": 871.32, "text": " You can see on the right here a lot of graphs, so basically, in the last JVET meeting, no,", "tokens": [509, 393, 536, 322, 264, 558, 510, 257, 688, 295, 24877, 11, 370, 1936, 11, 294, 264, 1036, 508, 53, 4850, 3440, 11, 572, 11], "temperature": 0.0, "avg_logprob": -0.21325194451116747, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.492146748205414e-05}, {"id": 195, "seek": 87132, "start": 871.32, "end": 878.32, "text": " the JVET meeting one before last, there was a verification test with actual human subjects,", "tokens": [264, 508, 53, 4850, 3440, 472, 949, 1036, 11, 456, 390, 257, 30206, 1500, 365, 3539, 1952, 13066, 11], "temperature": 0.0, "avg_logprob": -0.16941432044619606, "compression_ratio": 1.6285714285714286, "no_speech_prob": 2.4509028662578203e-05}, {"id": 196, "seek": 87132, "start": 878.32, "end": 882.44, "text": " where we, you know, where VTM was tested with, like, the new compression technology, and", "tokens": [689, 321, 11, 291, 458, 11, 689, 691, 42023, 390, 8246, 365, 11, 411, 11, 264, 777, 19355, 2899, 11, 293], "temperature": 0.0, "avg_logprob": -0.16941432044619606, "compression_ratio": 1.6285714285714286, "no_speech_prob": 2.4509028662578203e-05}, {"id": 197, "seek": 87132, "start": 882.44, "end": 886.5200000000001, "text": " we submitted VVNG to be tested alongside of it in the slow preset, right?", "tokens": [321, 14405, 691, 53, 45, 38, 281, 312, 8246, 12385, 295, 309, 294, 264, 2964, 32081, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.16941432044619606, "compression_ratio": 1.6285714285714286, "no_speech_prob": 2.4509028662578203e-05}, {"id": 198, "seek": 87132, "start": 886.5200000000001, "end": 889.6, "text": " So the slower preset has around the efficiency of VTM.", "tokens": [407, 264, 14009, 32081, 575, 926, 264, 10493, 295, 691, 42023, 13], "temperature": 0.0, "avg_logprob": -0.16941432044619606, "compression_ratio": 1.6285714285714286, "no_speech_prob": 2.4509028662578203e-05}, {"id": 199, "seek": 87132, "start": 889.6, "end": 896.6, "text": " Slow preset is objectively five percent behind, and as you can see in the graphs, VVNG in", "tokens": [17703, 32081, 307, 46067, 1732, 3043, 2261, 11, 293, 382, 291, 393, 536, 294, 264, 24877, 11, 691, 53, 45, 38, 294], "temperature": 0.0, "avg_logprob": -0.16941432044619606, "compression_ratio": 1.6285714285714286, "no_speech_prob": 2.4509028662578203e-05}, {"id": 200, "seek": 89660, "start": 896.6, "end": 903.84, "text": " orange matches or outperforms VTM, which means that our visual optimization is well able", "tokens": [7671, 10676, 420, 484, 26765, 82, 691, 42023, 11, 597, 1355, 300, 527, 5056, 19618, 307, 731, 1075], "temperature": 0.0, "avg_logprob": -0.16188205018335458, "compression_ratio": 1.4680851063829787, "no_speech_prob": 1.7071010006475262e-05}, {"id": 201, "seek": 89660, "start": 903.84, "end": 909.72, "text": " to at least close this five percent gap, if not even, you know, add more in terms of visual,", "tokens": [281, 412, 1935, 1998, 341, 1732, 3043, 7417, 11, 498, 406, 754, 11, 291, 458, 11, 909, 544, 294, 2115, 295, 5056, 11], "temperature": 0.0, "avg_logprob": -0.16188205018335458, "compression_ratio": 1.4680851063829787, "no_speech_prob": 1.7071010006475262e-05}, {"id": 202, "seek": 89660, "start": 909.72, "end": 913.72, "text": " like, subject to visual quality.", "tokens": [411, 11, 3983, 281, 5056, 3125, 13], "temperature": 0.0, "avg_logprob": -0.16188205018335458, "compression_ratio": 1.4680851063829787, "no_speech_prob": 1.7071010006475262e-05}, {"id": 203, "seek": 89660, "start": 913.72, "end": 915.72, "text": " So yeah, that's really nice.", "tokens": [407, 1338, 11, 300, 311, 534, 1481, 13], "temperature": 0.0, "avg_logprob": -0.16188205018335458, "compression_ratio": 1.4680851063829787, "no_speech_prob": 1.7071010006475262e-05}, {"id": 204, "seek": 89660, "start": 915.72, "end": 916.72, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.16188205018335458, "compression_ratio": 1.4680851063829787, "no_speech_prob": 1.7071010006475262e-05}, {"id": 205, "seek": 89660, "start": 916.72, "end": 923.72, "text": " VVNG in practice, you know, everyone asks in the end, so what kind of FPS can you achieve?", "tokens": [691, 53, 45, 38, 294, 3124, 11, 291, 458, 11, 1518, 8962, 294, 264, 917, 11, 370, 437, 733, 295, 26429, 393, 291, 4584, 30], "temperature": 0.0, "avg_logprob": -0.16188205018335458, "compression_ratio": 1.4680851063829787, "no_speech_prob": 1.7071010006475262e-05}, {"id": 206, "seek": 92372, "start": 923.72, "end": 930.44, "text": " So we did some encodes onto mobile workstation kind of computers, encodes using all defaults,", "tokens": [407, 321, 630, 512, 2058, 4789, 3911, 6013, 589, 19159, 733, 295, 10807, 11, 2058, 4789, 1228, 439, 7576, 82, 11], "temperature": 0.0, "avg_logprob": -0.1992923046680207, "compression_ratio": 1.6037735849056605, "no_speech_prob": 4.443060970515944e-05}, {"id": 207, "seek": 92372, "start": 930.44, "end": 936.76, "text": " which means eight threads, and, you know, for HD versus live, it's like, for faster,", "tokens": [597, 1355, 3180, 19314, 11, 293, 11, 291, 458, 11, 337, 12149, 5717, 1621, 11, 309, 311, 411, 11, 337, 4663, 11], "temperature": 0.0, "avg_logprob": -0.1992923046680207, "compression_ratio": 1.6037735849056605, "no_speech_prob": 4.443060970515944e-05}, {"id": 208, "seek": 92372, "start": 936.76, "end": 942.9200000000001, "text": " it's around times four, like, live times four, so around 15 FPS, medium around lifetime,", "tokens": [309, 311, 926, 1413, 1451, 11, 411, 11, 1621, 1413, 1451, 11, 370, 926, 2119, 26429, 11, 6399, 926, 11364, 11], "temperature": 0.0, "avg_logprob": -0.1992923046680207, "compression_ratio": 1.6037735849056605, "no_speech_prob": 4.443060970515944e-05}, {"id": 209, "seek": 92372, "start": 942.9200000000001, "end": 950.2, "text": " times 30, right, so around two FPS, I'm talking about HD 60 FPS as live.", "tokens": [1413, 2217, 11, 558, 11, 370, 926, 732, 26429, 11, 286, 478, 1417, 466, 12149, 4060, 26429, 382, 1621, 13], "temperature": 0.0, "avg_logprob": -0.1992923046680207, "compression_ratio": 1.6037735849056605, "no_speech_prob": 4.443060970515944e-05}, {"id": 210, "seek": 95020, "start": 950.2, "end": 955.6, "text": " For UHD, the faster can do, like, 15 times live, fast 30, and medium, well, let's just", "tokens": [1171, 624, 22859, 11, 264, 4663, 393, 360, 11, 411, 11, 2119, 1413, 1621, 11, 2370, 2217, 11, 293, 6399, 11, 731, 11, 718, 311, 445], "temperature": 0.0, "avg_logprob": -0.17384295818234277, "compression_ratio": 1.5131086142322097, "no_speech_prob": 4.147773506701924e-05}, {"id": 211, "seek": 95020, "start": 955.6, "end": 961.08, "text": " say medium would only be of interest for, like, large-scale VOD encodings, right?", "tokens": [584, 6399, 576, 787, 312, 295, 1179, 337, 11, 411, 11, 2416, 12, 20033, 691, 14632, 2058, 378, 1109, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17384295818234277, "compression_ratio": 1.5131086142322097, "no_speech_prob": 4.147773506701924e-05}, {"id": 212, "seek": 95020, "start": 961.08, "end": 966.0400000000001, "text": " But you know, FPS also depends on many other factors, like bit rate, content, you know,", "tokens": [583, 291, 458, 11, 26429, 611, 5946, 322, 867, 661, 6771, 11, 411, 857, 3314, 11, 2701, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.17384295818234277, "compression_ratio": 1.5131086142322097, "no_speech_prob": 4.147773506701924e-05}, {"id": 213, "seek": 95020, "start": 966.0400000000001, "end": 971.08, "text": " your actual CPU and stuff like that, so this is more like ballpark numbers.", "tokens": [428, 3539, 13199, 293, 1507, 411, 300, 11, 370, 341, 307, 544, 411, 2594, 31239, 3547, 13], "temperature": 0.0, "avg_logprob": -0.17384295818234277, "compression_ratio": 1.5131086142322097, "no_speech_prob": 4.147773506701924e-05}, {"id": 214, "seek": 95020, "start": 971.08, "end": 975.12, "text": " Excuse me, is this HDR content?", "tokens": [11359, 385, 11, 307, 341, 29650, 2701, 30], "temperature": 0.0, "avg_logprob": -0.17384295818234277, "compression_ratio": 1.5131086142322097, "no_speech_prob": 4.147773506701924e-05}, {"id": 215, "seek": 95020, "start": 975.12, "end": 977.84, "text": " It is not HDR content, but it's 10-bit.", "tokens": [467, 307, 406, 29650, 2701, 11, 457, 309, 311, 1266, 12, 5260, 13], "temperature": 0.0, "avg_logprob": -0.17384295818234277, "compression_ratio": 1.5131086142322097, "no_speech_prob": 4.147773506701924e-05}, {"id": 216, "seek": 97784, "start": 977.84, "end": 985.96, "text": " So it should be roughly the same for HDR, like we only do, we only test with 10-bit usually.", "tokens": [407, 309, 820, 312, 9810, 264, 912, 337, 29650, 11, 411, 321, 787, 360, 11, 321, 787, 1500, 365, 1266, 12, 5260, 2673, 13], "temperature": 0.0, "avg_logprob": -0.15883538030808972, "compression_ratio": 1.537593984962406, "no_speech_prob": 1.7118818504968658e-05}, {"id": 217, "seek": 97784, "start": 985.96, "end": 988.84, "text": " It works for 8-bit, but it's kind of 10-bit native.", "tokens": [467, 1985, 337, 1649, 12, 5260, 11, 457, 309, 311, 733, 295, 1266, 12, 5260, 8470, 13], "temperature": 0.0, "avg_logprob": -0.15883538030808972, "compression_ratio": 1.537593984962406, "no_speech_prob": 1.7118818504968658e-05}, {"id": 218, "seek": 97784, "start": 988.84, "end": 995.8000000000001, "text": " All right, also some version history for the VVNC thing, for the VVNC project.", "tokens": [1057, 558, 11, 611, 512, 3037, 2503, 337, 264, 691, 53, 45, 34, 551, 11, 337, 264, 691, 53, 45, 34, 1716, 13], "temperature": 0.0, "avg_logprob": -0.15883538030808972, "compression_ratio": 1.537593984962406, "no_speech_prob": 1.7118818504968658e-05}, {"id": 219, "seek": 97784, "start": 995.8000000000001, "end": 1000.5600000000001, "text": " So our first major milestone was the 0.3, where we added frame threading, and you can", "tokens": [407, 527, 700, 2563, 28048, 390, 264, 1958, 13, 18, 11, 689, 321, 3869, 3920, 7207, 278, 11, 293, 291, 393], "temperature": 0.0, "avg_logprob": -0.15883538030808972, "compression_ratio": 1.537593984962406, "no_speech_prob": 1.7118818504968658e-05}, {"id": 220, "seek": 97784, "start": 1000.5600000000001, "end": 1005.52, "text": " see on this multi-threaded efficiency versus speed graph that it was, you know, a huge", "tokens": [536, 322, 341, 4825, 12, 392, 2538, 292, 10493, 5717, 3073, 4295, 300, 309, 390, 11, 291, 458, 11, 257, 2603], "temperature": 0.0, "avg_logprob": -0.15883538030808972, "compression_ratio": 1.537593984962406, "no_speech_prob": 1.7118818504968658e-05}, {"id": 221, "seek": 97784, "start": 1005.52, "end": 1007.0400000000001, "text": " leap for us.", "tokens": [19438, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.15883538030808972, "compression_ratio": 1.537593984962406, "no_speech_prob": 1.7118818504968658e-05}, {"id": 222, "seek": 100704, "start": 1007.04, "end": 1012.3199999999999, "text": " In the 1.0, we added the pure C interface, allowing, you know, the integrations into", "tokens": [682, 264, 502, 13, 15, 11, 321, 3869, 264, 6075, 383, 9226, 11, 8293, 11, 291, 458, 11, 264, 3572, 763, 666], "temperature": 0.0, "avg_logprob": -0.20849514703681, "compression_ratio": 1.7259786476868328, "no_speech_prob": 1.8881302821682766e-05}, {"id": 223, "seek": 100704, "start": 1012.3199999999999, "end": 1018.9599999999999, "text": " pure C frameworks, 1.4, scene cut detection, 1.5, we added, like, arbitrary intra-period,", "tokens": [6075, 383, 29834, 11, 502, 13, 19, 11, 4145, 1723, 17784, 11, 502, 13, 20, 11, 321, 3869, 11, 411, 11, 23211, 43358, 12, 610, 2695, 11], "temperature": 0.0, "avg_logprob": -0.20849514703681, "compression_ratio": 1.7259786476868328, "no_speech_prob": 1.8881302821682766e-05}, {"id": 224, "seek": 100704, "start": 1018.9599999999999, "end": 1021.4, "text": " so it doesn't have to be aligned to anything.", "tokens": [370, 309, 1177, 380, 362, 281, 312, 17962, 281, 1340, 13], "temperature": 0.0, "avg_logprob": -0.20849514703681, "compression_ratio": 1.7259786476868328, "no_speech_prob": 1.8881302821682766e-05}, {"id": 225, "seek": 100704, "start": 1021.4, "end": 1025.72, "text": " We added a fast decode preset, and in the newest version, the thing that I really like", "tokens": [492, 3869, 257, 2370, 979, 1429, 32081, 11, 293, 294, 264, 17569, 3037, 11, 264, 551, 300, 286, 534, 411], "temperature": 0.0, "avg_logprob": -0.20849514703681, "compression_ratio": 1.7259786476868328, "no_speech_prob": 1.8881302821682766e-05}, {"id": 226, "seek": 100704, "start": 1025.72, "end": 1031.56, "text": " about it is that we added the ARM support, and, you know, every version, we had improved", "tokens": [466, 309, 307, 300, 321, 3869, 264, 8943, 44, 1406, 11, 293, 11, 291, 458, 11, 633, 3037, 11, 321, 632, 9689], "temperature": 0.0, "avg_logprob": -0.20849514703681, "compression_ratio": 1.7259786476868328, "no_speech_prob": 1.8881302821682766e-05}, {"id": 227, "seek": 100704, "start": 1031.56, "end": 1036.28, "text": " ray control, things also to, you know, great community feedback, and, you know, from one", "tokens": [18592, 1969, 11, 721, 611, 281, 11, 291, 458, 11, 869, 1768, 5824, 11, 293, 11, 291, 458, 11, 490, 472], "temperature": 0.0, "avg_logprob": -0.20849514703681, "compression_ratio": 1.7259786476868328, "no_speech_prob": 1.8881302821682766e-05}, {"id": 228, "seek": 103628, "start": 1036.28, "end": 1041.36, "text": " version to another, your encode might be 10% faster, but if you had a ray control problem", "tokens": [3037, 281, 1071, 11, 428, 2058, 1429, 1062, 312, 1266, 4, 4663, 11, 457, 498, 291, 632, 257, 18592, 1969, 1154], "temperature": 0.0, "avg_logprob": -0.1380844260707046, "compression_ratio": 1.6632302405498283, "no_speech_prob": 1.0402028237876948e-05}, {"id": 229, "seek": 103628, "start": 1041.36, "end": 1046.68, "text": " and it got fixed, it's going to be, you know, like, way, way better.", "tokens": [293, 309, 658, 6806, 11, 309, 311, 516, 281, 312, 11, 291, 458, 11, 411, 11, 636, 11, 636, 1101, 13], "temperature": 0.0, "avg_logprob": -0.1380844260707046, "compression_ratio": 1.6632302405498283, "no_speech_prob": 1.0402028237876948e-05}, {"id": 230, "seek": 103628, "start": 1046.68, "end": 1052.6, "text": " So this is, like, this hard-to-quantify improvements are actually one of the most important ones.", "tokens": [407, 341, 307, 11, 411, 11, 341, 1152, 12, 1353, 12, 358, 394, 2505, 13797, 366, 767, 472, 295, 264, 881, 1021, 2306, 13], "temperature": 0.0, "avg_logprob": -0.1380844260707046, "compression_ratio": 1.6632302405498283, "no_speech_prob": 1.0402028237876948e-05}, {"id": 231, "seek": 103628, "start": 1052.6, "end": 1057.12, "text": " And you know, you can see how the curve behaves, extrapolating, I'm sure we're going to get", "tokens": [400, 291, 458, 11, 291, 393, 536, 577, 264, 7605, 36896, 11, 48224, 990, 11, 286, 478, 988, 321, 434, 516, 281, 483], "temperature": 0.0, "avg_logprob": -0.1380844260707046, "compression_ratio": 1.6632302405498283, "no_speech_prob": 1.0402028237876948e-05}, {"id": 232, "seek": 103628, "start": 1057.12, "end": 1059.28, "text": " even faster and better in the future.", "tokens": [754, 4663, 293, 1101, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.1380844260707046, "compression_ratio": 1.6632302405498283, "no_speech_prob": 1.0402028237876948e-05}, {"id": 233, "seek": 103628, "start": 1059.28, "end": 1064.52, "text": " All right, about the ecosystem and the community, of course, you know, this is raw video encoding", "tokens": [1057, 558, 11, 466, 264, 11311, 293, 264, 1768, 11, 295, 1164, 11, 291, 458, 11, 341, 307, 8936, 960, 43430], "temperature": 0.0, "avg_logprob": -0.1380844260707046, "compression_ratio": 1.6632302405498283, "no_speech_prob": 1.0402028237876948e-05}, {"id": 234, "seek": 106452, "start": 1064.52, "end": 1070.48, "text": " and decoding, this is really only of academic interest, right, like, it doesn't really bring", "tokens": [293, 979, 8616, 11, 341, 307, 534, 787, 295, 7778, 1179, 11, 558, 11, 411, 11, 309, 1177, 380, 534, 1565], "temperature": 0.0, "avg_logprob": -0.15196691240583146, "compression_ratio": 1.6688741721854305, "no_speech_prob": 7.781279418850318e-05}, {"id": 235, "seek": 106452, "start": 1070.48, "end": 1071.48, "text": " you anything.", "tokens": [291, 1340, 13], "temperature": 0.0, "avg_logprob": -0.15196691240583146, "compression_ratio": 1.6688741721854305, "no_speech_prob": 7.781279418850318e-05}, {"id": 236, "seek": 106452, "start": 1071.48, "end": 1075.52, "text": " That's why we have been looking into FFMPEG support for a long time.", "tokens": [663, 311, 983, 321, 362, 668, 1237, 666, 479, 37, 44, 5208, 38, 1406, 337, 257, 938, 565, 13], "temperature": 0.0, "avg_logprob": -0.15196691240583146, "compression_ratio": 1.6688741721854305, "no_speech_prob": 7.781279418850318e-05}, {"id": 237, "seek": 106452, "start": 1075.52, "end": 1079.84, "text": " There was an open access paper over one and a half years ago that described how to do", "tokens": [821, 390, 364, 1269, 2105, 3035, 670, 472, 293, 257, 1922, 924, 2057, 300, 7619, 577, 281, 360], "temperature": 0.0, "avg_logprob": -0.15196691240583146, "compression_ratio": 1.6688741721854305, "no_speech_prob": 7.781279418850318e-05}, {"id": 238, "seek": 106452, "start": 1079.84, "end": 1081.6399999999999, "text": " it for the decoder.", "tokens": [309, 337, 264, 979, 19866, 13], "temperature": 0.0, "avg_logprob": -0.15196691240583146, "compression_ratio": 1.6688741721854305, "no_speech_prob": 7.781279418850318e-05}, {"id": 239, "seek": 106452, "start": 1081.6399999999999, "end": 1084.0, "text": " There are some patches in the pipeline with FFMPEG.", "tokens": [821, 366, 512, 26531, 294, 264, 15517, 365, 479, 37, 44, 5208, 38, 13], "temperature": 0.0, "avg_logprob": -0.15196691240583146, "compression_ratio": 1.6688741721854305, "no_speech_prob": 7.781279418850318e-05}, {"id": 240, "seek": 106452, "start": 1084.0, "end": 1088.76, "text": " We also put in our wiki how to apply them manually, if you, you know, if you want to", "tokens": [492, 611, 829, 294, 527, 261, 9850, 577, 281, 3079, 552, 16945, 11, 498, 291, 11, 291, 458, 11, 498, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.15196691240583146, "compression_ratio": 1.6688741721854305, "no_speech_prob": 7.781279418850318e-05}, {"id": 241, "seek": 106452, "start": 1088.76, "end": 1093.6, "text": " build it, you know, I've talked about this a lot, but the thing is, you know, if it's", "tokens": [1322, 309, 11, 291, 458, 11, 286, 600, 2825, 466, 341, 257, 688, 11, 457, 264, 551, 307, 11, 291, 458, 11, 498, 309, 311], "temperature": 0.0, "avg_logprob": -0.15196691240583146, "compression_ratio": 1.6688741721854305, "no_speech_prob": 7.781279418850318e-05}, {"id": 242, "seek": 109360, "start": 1093.6, "end": 1096.56, "text": " not in FFMPEG, it doesn't exist.", "tokens": [406, 294, 479, 37, 44, 5208, 38, 11, 309, 1177, 380, 2514, 13], "temperature": 0.0, "avg_logprob": -0.16643667541094273, "compression_ratio": 1.564102564102564, "no_speech_prob": 3.1166175176622346e-05}, {"id": 243, "seek": 109360, "start": 1096.56, "end": 1102.52, "text": " That's why, you know, we put up a, like, how-to for you on how to do it.", "tokens": [663, 311, 983, 11, 291, 458, 11, 321, 829, 493, 257, 11, 411, 11, 577, 12, 1353, 337, 291, 322, 577, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.16643667541094273, "compression_ratio": 1.564102564102564, "no_speech_prob": 3.1166175176622346e-05}, {"id": 244, "seek": 109360, "start": 1102.52, "end": 1107.8, "text": " All right, about playback, once you get this FFMPEG with VBC included, you can just link", "tokens": [1057, 558, 11, 466, 37223, 11, 1564, 291, 483, 341, 479, 37, 44, 5208, 38, 365, 691, 7869, 5556, 11, 291, 393, 445, 2113], "temperature": 0.0, "avg_logprob": -0.16643667541094273, "compression_ratio": 1.564102564102564, "no_speech_prob": 3.1166175176622346e-05}, {"id": 245, "seek": 109360, "start": 1107.8, "end": 1111.24, "text": " whatever player uses FFMPEG as its back-end and it's going to work.", "tokens": [2035, 4256, 4960, 479, 37, 44, 5208, 38, 382, 1080, 646, 12, 521, 293, 309, 311, 516, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.16643667541094273, "compression_ratio": 1.564102564102564, "no_speech_prob": 3.1166175176622346e-05}, {"id": 246, "seek": 109360, "start": 1111.24, "end": 1116.76, "text": " As far as I know, for VLC, you might force it to use the FFMPEG as the demuxer.", "tokens": [1018, 1400, 382, 286, 458, 11, 337, 691, 14766, 11, 291, 1062, 3464, 309, 281, 764, 264, 479, 37, 44, 5208, 38, 382, 264, 1371, 2449, 260, 13], "temperature": 0.0, "avg_logprob": -0.16643667541094273, "compression_ratio": 1.564102564102564, "no_speech_prob": 3.1166175176622346e-05}, {"id": 247, "seek": 109360, "start": 1116.76, "end": 1117.76, "text": " Not sure about it.", "tokens": [1726, 988, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.16643667541094273, "compression_ratio": 1.564102564102564, "no_speech_prob": 3.1166175176622346e-05}, {"id": 248, "seek": 109360, "start": 1117.76, "end": 1118.76, "text": " I didn't test it myself.", "tokens": [286, 994, 380, 1500, 309, 2059, 13], "temperature": 0.0, "avg_logprob": -0.16643667541094273, "compression_ratio": 1.564102564102564, "no_speech_prob": 3.1166175176622346e-05}, {"id": 249, "seek": 109360, "start": 1118.76, "end": 1120.9199999999998, "text": " It comes, like, from community feedback.", "tokens": [467, 1487, 11, 411, 11, 490, 1768, 5824, 13], "temperature": 0.0, "avg_logprob": -0.16643667541094273, "compression_ratio": 1.564102564102564, "no_speech_prob": 3.1166175176622346e-05}, {"id": 250, "seek": 112092, "start": 1120.92, "end": 1125.28, "text": " I know there are some exo-player integrations going around, which allow you to, you know,", "tokens": [286, 458, 456, 366, 512, 454, 78, 12, 19125, 3572, 763, 516, 926, 11, 597, 2089, 291, 281, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.16771588222585992, "compression_ratio": 1.5867158671586716, "no_speech_prob": 8.804436947684735e-05}, {"id": 251, "seek": 112092, "start": 1125.28, "end": 1128.3200000000002, "text": " to use it in Android apps more easily.", "tokens": [281, 764, 309, 294, 8853, 7733, 544, 3612, 13], "temperature": 0.0, "avg_logprob": -0.16771588222585992, "compression_ratio": 1.5867158671586716, "no_speech_prob": 8.804436947684735e-05}, {"id": 252, "seek": 112092, "start": 1128.3200000000002, "end": 1133.0800000000002, "text": " We have a toy web browser example, but it's nothing like the VLC.js.", "tokens": [492, 362, 257, 12058, 3670, 11185, 1365, 11, 457, 309, 311, 1825, 411, 264, 691, 14766, 13, 25530, 13], "temperature": 0.0, "avg_logprob": -0.16771588222585992, "compression_ratio": 1.5867158671586716, "no_speech_prob": 8.804436947684735e-05}, {"id": 253, "seek": 112092, "start": 1133.0800000000002, "end": 1134.88, "text": " It's really a toy example.", "tokens": [467, 311, 534, 257, 12058, 1365, 13], "temperature": 0.0, "avg_logprob": -0.16771588222585992, "compression_ratio": 1.5867158671586716, "no_speech_prob": 8.804436947684735e-05}, {"id": 254, "seek": 112092, "start": 1134.88, "end": 1140.04, "text": " And for maxing and demaxing, you can just use GPEG, sorry, for maxing, dashing, you", "tokens": [400, 337, 11469, 278, 293, 1371, 2797, 278, 11, 291, 393, 445, 764, 460, 5208, 38, 11, 2597, 11, 337, 11469, 278, 11, 1482, 571, 11, 291], "temperature": 0.0, "avg_logprob": -0.16771588222585992, "compression_ratio": 1.5867158671586716, "no_speech_prob": 8.804436947684735e-05}, {"id": 255, "seek": 112092, "start": 1140.04, "end": 1143.6000000000001, "text": " can just use GPEG since the version 2.0.", "tokens": [393, 445, 764, 460, 5208, 38, 1670, 264, 3037, 568, 13, 15, 13], "temperature": 0.0, "avg_logprob": -0.16771588222585992, "compression_ratio": 1.5867158671586716, "no_speech_prob": 8.804436947684735e-05}, {"id": 256, "seek": 112092, "start": 1143.6000000000001, "end": 1149.4, "text": " And I think it also needs to be linked to an FFMPEG with VBC support.", "tokens": [400, 286, 519, 309, 611, 2203, 281, 312, 9408, 281, 364, 479, 37, 44, 5208, 38, 365, 691, 7869, 1406, 13], "temperature": 0.0, "avg_logprob": -0.16771588222585992, "compression_ratio": 1.5867158671586716, "no_speech_prob": 8.804436947684735e-05}, {"id": 257, "seek": 112092, "start": 1149.4, "end": 1150.4, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.16771588222585992, "compression_ratio": 1.5867158671586716, "no_speech_prob": 8.804436947684735e-05}, {"id": 258, "seek": 115040, "start": 1150.4, "end": 1155.76, "text": " For the community, we do our open to external contributions and we wish to get some.", "tokens": [1171, 264, 1768, 11, 321, 360, 527, 1269, 281, 8320, 15725, 293, 321, 3172, 281, 483, 512, 13], "temperature": 0.0, "avg_logprob": -0.1966254160954402, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.000181606927071698}, {"id": 259, "seek": 115040, "start": 1155.76, "end": 1160.0, "text": " That's also why I'm talking to you, to get some interest.", "tokens": [663, 311, 611, 983, 286, 478, 1417, 281, 291, 11, 281, 483, 512, 1179, 13], "temperature": 0.0, "avg_logprob": -0.1966254160954402, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.000181606927071698}, {"id": 260, "seek": 115040, "start": 1160.0, "end": 1164.64, "text": " So we try to, you know, make this more easy by, you know, stating that the authors of", "tokens": [407, 321, 853, 281, 11, 291, 458, 11, 652, 341, 544, 1858, 538, 11, 291, 458, 11, 26688, 300, 264, 16552, 295], "temperature": 0.0, "avg_logprob": -0.1966254160954402, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.000181606927071698}, {"id": 261, "seek": 115040, "start": 1164.64, "end": 1167.2, "text": " VVNC are also retained at copyright.", "tokens": [691, 53, 45, 34, 366, 611, 33438, 412, 17996, 13], "temperature": 0.0, "avg_logprob": -0.1966254160954402, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.000181606927071698}, {"id": 262, "seek": 115040, "start": 1167.2, "end": 1171.4, "text": " We don't have, like, a contributors agreement, so this is, like, the only way we can make", "tokens": [492, 500, 380, 362, 11, 411, 11, 257, 45627, 8106, 11, 370, 341, 307, 11, 411, 11, 264, 787, 636, 321, 393, 652], "temperature": 0.0, "avg_logprob": -0.1966254160954402, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.000181606927071698}, {"id": 263, "seek": 115040, "start": 1171.4, "end": 1172.8400000000001, "text": " it happen.", "tokens": [309, 1051, 13], "temperature": 0.0, "avg_logprob": -0.1966254160954402, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.000181606927071698}, {"id": 264, "seek": 115040, "start": 1172.8400000000001, "end": 1178.3200000000002, "text": " We are interested in all kinds of contributions, you know, efficiency, speed-up, and, you know,", "tokens": [492, 366, 3102, 294, 439, 3685, 295, 15725, 11, 291, 458, 11, 10493, 11, 3073, 12, 1010, 11, 293, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1966254160954402, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.000181606927071698}, {"id": 265, "seek": 117832, "start": 1178.32, "end": 1183.24, "text": " we're going to, throughout the review this, test, generate, result, whatever is needed,", "tokens": [321, 434, 516, 281, 11, 3710, 264, 3131, 341, 11, 1500, 11, 8460, 11, 1874, 11, 2035, 307, 2978, 11], "temperature": 0.0, "avg_logprob": -0.222757371805482, "compression_ratio": 1.626923076923077, "no_speech_prob": 9.03356631170027e-05}, {"id": 266, "seek": 117832, "start": 1183.24, "end": 1186.76, "text": " give proper feedback, march, so, yeah.", "tokens": [976, 2296, 5824, 11, 8368, 11, 370, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.222757371805482, "compression_ratio": 1.626923076923077, "no_speech_prob": 9.03356631170027e-05}, {"id": 267, "seek": 117832, "start": 1186.76, "end": 1188.8799999999999, "text": " Please do if you're interested.", "tokens": [2555, 360, 498, 291, 434, 3102, 13], "temperature": 0.0, "avg_logprob": -0.222757371805482, "compression_ratio": 1.626923076923077, "no_speech_prob": 9.03356631170027e-05}, {"id": 268, "seek": 117832, "start": 1188.8799999999999, "end": 1193.76, "text": " To conclude, you know, if you just entered the room, I talked to you about our open source", "tokens": [1407, 16886, 11, 291, 458, 11, 498, 291, 445, 9065, 264, 1808, 11, 286, 2825, 281, 291, 466, 527, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.222757371805482, "compression_ratio": 1.626923076923077, "no_speech_prob": 9.03356631170027e-05}, {"id": 269, "seek": 117832, "start": 1193.76, "end": 1196.72, "text": " implementations of the VVC standard.", "tokens": [4445, 763, 295, 264, 691, 53, 34, 3832, 13], "temperature": 0.0, "avg_logprob": -0.222757371805482, "compression_ratio": 1.626923076923077, "no_speech_prob": 9.03356631170027e-05}, {"id": 270, "seek": 117832, "start": 1196.72, "end": 1202.2, "text": " And I'm looking forward to, you know, contributions, also results, tests, if you want to try it", "tokens": [400, 286, 478, 1237, 2128, 281, 11, 291, 458, 11, 15725, 11, 611, 3542, 11, 6921, 11, 498, 291, 528, 281, 853, 309], "temperature": 0.0, "avg_logprob": -0.222757371805482, "compression_ratio": 1.626923076923077, "no_speech_prob": 9.03356631170027e-05}, {"id": 271, "seek": 117832, "start": 1202.2, "end": 1204.2, "text": " out, and general feedback.", "tokens": [484, 11, 293, 2674, 5824, 13], "temperature": 0.0, "avg_logprob": -0.222757371805482, "compression_ratio": 1.626923076923077, "no_speech_prob": 9.03356631170027e-05}, {"id": 272, "seek": 117832, "start": 1204.2, "end": 1205.2, "text": " Thanks a lot.", "tokens": [2561, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.222757371805482, "compression_ratio": 1.626923076923077, "no_speech_prob": 9.03356631170027e-05}, {"id": 273, "seek": 120520, "start": 1205.2, "end": 1212.2, "text": " And a question in the room, yeah.", "tokens": [400, 257, 1168, 294, 264, 1808, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.5126006547794786, "compression_ratio": 1.3932038834951457, "no_speech_prob": 0.008220846764743328}, {"id": 274, "seek": 120520, "start": 1212.2, "end": 1220.2, "text": " What confused me, because I know a little bit about the backstory, so H265, right, was", "tokens": [708, 9019, 385, 11, 570, 286, 458, 257, 707, 857, 466, 264, 36899, 11, 370, 389, 10880, 20, 11, 558, 11, 390], "temperature": 0.0, "avg_logprob": -0.5126006547794786, "compression_ratio": 1.3932038834951457, "no_speech_prob": 0.008220846764743328}, {"id": 275, "seek": 120520, "start": 1220.2, "end": 1227.32, "text": " the super proprietary and the royalties, and the Alliance for Media Launch, the AV-1", "tokens": [264, 1687, 38992, 293, 264, 36364, 26471, 11, 293, 264, 21859, 337, 14741, 28119, 11, 264, 30198, 12, 16], "temperature": 0.0, "avg_logprob": -0.5126006547794786, "compression_ratio": 1.3932038834951457, "no_speech_prob": 0.008220846764743328}, {"id": 276, "seek": 120520, "start": 1227.32, "end": 1228.32, "text": " company.", "tokens": [2237, 13], "temperature": 0.0, "avg_logprob": -0.5126006547794786, "compression_ratio": 1.3932038834951457, "no_speech_prob": 0.008220846764743328}, {"id": 277, "seek": 120520, "start": 1228.32, "end": 1229.32, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.5126006547794786, "compression_ratio": 1.3932038834951457, "no_speech_prob": 0.008220846764743328}, {"id": 278, "seek": 120520, "start": 1229.32, "end": 1232.0, "text": " And now your colleague is open source and free, right?", "tokens": [400, 586, 428, 13532, 307, 1269, 4009, 293, 1737, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.5126006547794786, "compression_ratio": 1.3932038834951457, "no_speech_prob": 0.008220846764743328}, {"id": 279, "seek": 120520, "start": 1232.0, "end": 1233.0, "text": " So to recap.", "tokens": [407, 281, 20928, 13], "temperature": 0.0, "avg_logprob": -0.5126006547794786, "compression_ratio": 1.3932038834951457, "no_speech_prob": 0.008220846764743328}, {"id": 280, "seek": 123300, "start": 1233.0, "end": 1236.96, "text": " Why is it H266, is the free?", "tokens": [1545, 307, 309, 389, 10880, 21, 11, 307, 264, 1737, 30], "temperature": 0.0, "avg_logprob": -0.22291168212890625, "compression_ratio": 1.5454545454545454, "no_speech_prob": 6.479929288616404e-05}, {"id": 281, "seek": 123300, "start": 1236.96, "end": 1244.64, "text": " To recap the question, the question was H265 was a proprietary codec with licensing, AV-1", "tokens": [1407, 20928, 264, 1168, 11, 264, 1168, 390, 389, 10880, 20, 390, 257, 38992, 3089, 66, 365, 29759, 11, 30198, 12, 16], "temperature": 0.0, "avg_logprob": -0.22291168212890625, "compression_ratio": 1.5454545454545454, "no_speech_prob": 6.479929288616404e-05}, {"id": 282, "seek": 123300, "start": 1244.64, "end": 1253.12, "text": " is a non-properary codec, and then I'm talking about VVC, which is the successor of HEVC,", "tokens": [307, 257, 2107, 12, 4318, 610, 822, 3089, 66, 11, 293, 550, 286, 478, 1417, 466, 691, 53, 34, 11, 597, 307, 264, 31864, 295, 11827, 53, 34, 11], "temperature": 0.0, "avg_logprob": -0.22291168212890625, "compression_ratio": 1.5454545454545454, "no_speech_prob": 6.479929288616404e-05}, {"id": 283, "seek": 123300, "start": 1253.12, "end": 1254.92, "text": " so H265.", "tokens": [370, 389, 10880, 20, 13], "temperature": 0.0, "avg_logprob": -0.22291168212890625, "compression_ratio": 1.5454545454545454, "no_speech_prob": 6.479929288616404e-05}, {"id": 284, "seek": 123300, "start": 1254.92, "end": 1261.16, "text": " And there is a small confusion, so I'm not talking about the codec as being open source,", "tokens": [400, 456, 307, 257, 1359, 15075, 11, 370, 286, 478, 406, 1417, 466, 264, 3089, 66, 382, 885, 1269, 4009, 11], "temperature": 0.0, "avg_logprob": -0.22291168212890625, "compression_ratio": 1.5454545454545454, "no_speech_prob": 6.479929288616404e-05}, {"id": 285, "seek": 126116, "start": 1261.16, "end": 1265.48, "text": " it's about the implementations of it, right, so you have to differentiate between implementations", "tokens": [309, 311, 466, 264, 4445, 763, 295, 309, 11, 558, 11, 370, 291, 362, 281, 23203, 1296, 4445, 763], "temperature": 0.0, "avg_logprob": -0.2504027517218339, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.0002623559848871082}, {"id": 286, "seek": 126116, "start": 1265.48, "end": 1267.48, "text": " and the technology itself.", "tokens": [293, 264, 2899, 2564, 13], "temperature": 0.0, "avg_logprob": -0.2504027517218339, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.0002623559848871082}, {"id": 287, "seek": 126116, "start": 1267.48, "end": 1271.68, "text": " There will be licensing for the technology itself, but, you know, there is still open", "tokens": [821, 486, 312, 29759, 337, 264, 2899, 2564, 11, 457, 11, 291, 458, 11, 456, 307, 920, 1269], "temperature": 0.0, "avg_logprob": -0.2504027517218339, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.0002623559848871082}, {"id": 288, "seek": 126116, "start": 1271.68, "end": 1279.0400000000002, "text": " source implementations also of HEVC, so that's kind of the way I would like to see it, you", "tokens": [4009, 4445, 763, 611, 295, 11827, 53, 34, 11, 370, 300, 311, 733, 295, 264, 636, 286, 576, 411, 281, 536, 309, 11, 291], "temperature": 0.0, "avg_logprob": -0.2504027517218339, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.0002623559848871082}, {"id": 289, "seek": 126116, "start": 1279.0400000000002, "end": 1280.0400000000002, "text": " know.", "tokens": [458, 13], "temperature": 0.0, "avg_logprob": -0.2504027517218339, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.0002623559848871082}, {"id": 290, "seek": 126116, "start": 1280.0400000000002, "end": 1289.0400000000002, "text": " So it won't be like with MP3, but also developed, it will be completely free to use, forever?", "tokens": [407, 309, 1582, 380, 312, 411, 365, 14146, 18, 11, 457, 611, 4743, 11, 309, 486, 312, 2584, 1737, 281, 764, 11, 5680, 30], "temperature": 0.0, "avg_logprob": -0.2504027517218339, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.0002623559848871082}, {"id": 291, "seek": 126116, "start": 1289.0400000000002, "end": 1290.0400000000002, "text": " No, it won't.", "tokens": [883, 11, 309, 1582, 380, 13], "temperature": 0.0, "avg_logprob": -0.2504027517218339, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.0002623559848871082}, {"id": 292, "seek": 129004, "start": 1290.04, "end": 1296.76, "text": " I mean, the software is free to use, but, you know, if you build your streaming service", "tokens": [286, 914, 11, 264, 4722, 307, 1737, 281, 764, 11, 457, 11, 291, 458, 11, 498, 291, 1322, 428, 11791, 2643], "temperature": 0.0, "avg_logprob": -0.24536800384521484, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.0013358205324038863}, {"id": 293, "seek": 129004, "start": 1296.76, "end": 1301.6, "text": " based on the technology, independent of which software you use, you have to pay royalties", "tokens": [2361, 322, 264, 2899, 11, 6695, 295, 597, 4722, 291, 764, 11, 291, 362, 281, 1689, 36364, 26471], "temperature": 0.0, "avg_logprob": -0.24536800384521484, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.0013358205324038863}, {"id": 294, "seek": 129004, "start": 1301.6, "end": 1302.6, "text": " for the technology.", "tokens": [337, 264, 2899, 13], "temperature": 0.0, "avg_logprob": -0.24536800384521484, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.0013358205324038863}, {"id": 295, "seek": 129004, "start": 1302.6, "end": 1307.1599999999999, "text": " Because you have patents, but patent issues?", "tokens": [1436, 291, 362, 38142, 11, 457, 20495, 2663, 30], "temperature": 0.0, "avg_logprob": -0.24536800384521484, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.0013358205324038863}, {"id": 296, "seek": 129004, "start": 1307.1599999999999, "end": 1312.92, "text": " Yes, I mean, there is, you know, this technology cost stuff to develop, and people want to", "tokens": [1079, 11, 286, 914, 11, 456, 307, 11, 291, 458, 11, 341, 2899, 2063, 1507, 281, 1499, 11, 293, 561, 528, 281], "temperature": 0.0, "avg_logprob": -0.24536800384521484, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.0013358205324038863}, {"id": 297, "seek": 129004, "start": 1312.92, "end": 1315.32, "text": " get their investment back, you know.", "tokens": [483, 641, 6078, 646, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.24536800384521484, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.0013358205324038863}, {"id": 298, "seek": 131532, "start": 1315.32, "end": 1321.96, "text": " Okay, disclaimer, I'm doing, yes, in the optimizations for video codec in general.", "tokens": [1033, 11, 40896, 11, 286, 478, 884, 11, 2086, 11, 294, 264, 5028, 14455, 337, 960, 3089, 66, 294, 2674, 13], "temperature": 0.0, "avg_logprob": -0.27847689390182495, "compression_ratio": 1.5390625, "no_speech_prob": 0.009119036607444286}, {"id": 299, "seek": 131532, "start": 1321.96, "end": 1329.56, "text": " My focus is on, and my comment to you is using a library like Cindy Everywhere, it works.", "tokens": [1222, 1879, 307, 322, 11, 293, 452, 2871, 281, 291, 307, 1228, 257, 6405, 411, 32185, 37322, 11, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.27847689390182495, "compression_ratio": 1.5390625, "no_speech_prob": 0.009119036607444286}, {"id": 300, "seek": 131532, "start": 1329.56, "end": 1333.04, "text": " It's going to give you the initial results that you want, but you will never get the", "tokens": [467, 311, 516, 281, 976, 291, 264, 5883, 3542, 300, 291, 528, 11, 457, 291, 486, 1128, 483, 264], "temperature": 0.0, "avg_logprob": -0.27847689390182495, "compression_ratio": 1.5390625, "no_speech_prob": 0.009119036607444286}, {"id": 301, "seek": 131532, "start": 1333.04, "end": 1336.56, "text": " optimal performance out of your hardware.", "tokens": [16252, 3389, 484, 295, 428, 8837, 13], "temperature": 0.0, "avg_logprob": -0.27847689390182495, "compression_ratio": 1.5390625, "no_speech_prob": 0.009119036607444286}, {"id": 302, "seek": 131532, "start": 1336.56, "end": 1342.3999999999999, "text": " We had some really, really good examples of code, particular algorithms like more instructions", "tokens": [492, 632, 512, 534, 11, 534, 665, 5110, 295, 3089, 11, 1729, 14642, 411, 544, 9415], "temperature": 0.0, "avg_logprob": -0.27847689390182495, "compression_ratio": 1.5390625, "no_speech_prob": 0.009119036607444286}, {"id": 303, "seek": 134240, "start": 1342.4, "end": 1347.88, "text": " in forensics, a move mask type of in forensics, that are very common in popular in Intel.", "tokens": [294, 32034, 1167, 11, 257, 1286, 6094, 2010, 295, 294, 32034, 1167, 11, 300, 366, 588, 2689, 294, 3743, 294, 19762, 13], "temperature": 0.0, "avg_logprob": -0.41059680938720705, "compression_ratio": 1.696, "no_speech_prob": 0.0018987288931384683}, {"id": 304, "seek": 134240, "start": 1347.88, "end": 1353.8400000000001, "text": " If you try to port them with Cindy Everywhere or some kind of abstraction layer to ARM,", "tokens": [759, 291, 853, 281, 2436, 552, 365, 32185, 37322, 420, 512, 733, 295, 37765, 4583, 281, 45209, 11], "temperature": 0.0, "avg_logprob": -0.41059680938720705, "compression_ratio": 1.696, "no_speech_prob": 0.0018987288931384683}, {"id": 305, "seek": 134240, "start": 1353.8400000000001, "end": 1360.0, "text": " you're going to have to emulate this behavior, so ideally, you have to provide some way to", "tokens": [291, 434, 516, 281, 362, 281, 45497, 341, 5223, 11, 370, 22915, 11, 291, 362, 281, 2893, 512, 636, 281], "temperature": 0.0, "avg_logprob": -0.41059680938720705, "compression_ratio": 1.696, "no_speech_prob": 0.0018987288931384683}, {"id": 306, "seek": 134240, "start": 1360.0, "end": 1365.64, "text": " provide optimized functions for ARM or any other future architecture.", "tokens": [2893, 26941, 6828, 337, 45209, 420, 604, 661, 2027, 9482, 13], "temperature": 0.0, "avg_logprob": -0.41059680938720705, "compression_ratio": 1.696, "no_speech_prob": 0.0018987288931384683}, {"id": 307, "seek": 134240, "start": 1365.64, "end": 1371.92, "text": " Otherwise, you're just going to have your Intel layer transferred, translated to ARM.", "tokens": [10328, 11, 291, 434, 445, 516, 281, 362, 428, 19762, 4583, 15809, 11, 16805, 281, 45209, 13], "temperature": 0.0, "avg_logprob": -0.41059680938720705, "compression_ratio": 1.696, "no_speech_prob": 0.0018987288931384683}, {"id": 308, "seek": 137192, "start": 1371.92, "end": 1375.24, "text": " It will work, but you will never optimize your software.", "tokens": [467, 486, 589, 11, 457, 291, 486, 1128, 19719, 428, 4722, 13], "temperature": 0.0, "avg_logprob": -0.2606864561114395, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.00014176101831253618}, {"id": 309, "seek": 137192, "start": 1375.24, "end": 1382.52, "text": " So to recap, to recap the comment, there was a comment that Cindy Everywhere works, gives", "tokens": [407, 281, 20928, 11, 281, 20928, 264, 2871, 11, 456, 390, 257, 2871, 300, 32185, 37322, 1985, 11, 2709], "temperature": 0.0, "avg_logprob": -0.2606864561114395, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.00014176101831253618}, {"id": 310, "seek": 137192, "start": 1382.52, "end": 1388.68, "text": " a nice initial, you know, initial deliverable, but will never match hand optimized assembler.", "tokens": [257, 1481, 5883, 11, 291, 458, 11, 5883, 4239, 712, 11, 457, 486, 1128, 2995, 1011, 26941, 8438, 1918, 13], "temperature": 0.0, "avg_logprob": -0.2606864561114395, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.00014176101831253618}, {"id": 311, "seek": 137192, "start": 1388.68, "end": 1389.68, "text": " We are...", "tokens": [492, 366, 485], "temperature": 0.0, "avg_logprob": -0.2606864561114395, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.00014176101831253618}, {"id": 312, "seek": 137192, "start": 1389.68, "end": 1390.68, "text": " How do you know assembler?", "tokens": [1012, 360, 291, 458, 8438, 1918, 30], "temperature": 0.0, "avg_logprob": -0.2606864561114395, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.00014176101831253618}, {"id": 313, "seek": 137192, "start": 1390.68, "end": 1393.76, "text": " See, see the corresponding ARM intrinsics.", "tokens": [3008, 11, 536, 264, 11760, 45209, 28621, 1167, 13], "temperature": 0.0, "avg_logprob": -0.2606864561114395, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.00014176101831253618}, {"id": 314, "seek": 137192, "start": 1393.76, "end": 1401.1200000000001, "text": " I mean, when I say assembler, I mean, intrinsics, so, you know, we are aware of it, and we", "tokens": [286, 914, 11, 562, 286, 584, 8438, 1918, 11, 286, 914, 11, 28621, 1167, 11, 370, 11, 291, 458, 11, 321, 366, 3650, 295, 309, 11, 293, 321], "temperature": 0.0, "avg_logprob": -0.2606864561114395, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.00014176101831253618}, {"id": 315, "seek": 140112, "start": 1401.12, "end": 1406.4399999999998, "text": " are looking a little bit of it, you know, there are different kinds of intrinsic kernels", "tokens": [366, 1237, 257, 707, 857, 295, 309, 11, 291, 458, 11, 456, 366, 819, 3685, 295, 35698, 23434, 1625], "temperature": 0.0, "avg_logprob": -0.16870514551798502, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.0001430669508408755}, {"id": 316, "seek": 140112, "start": 1406.4399999999998, "end": 1407.4399999999998, "text": " that are implemented there.", "tokens": [300, 366, 12270, 456, 13], "temperature": 0.0, "avg_logprob": -0.16870514551798502, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.0001430669508408755}, {"id": 317, "seek": 140112, "start": 1407.4399999999998, "end": 1411.6399999999999, "text": " You know, sometimes you have like two pieces of memory that needs to be added up and stored", "tokens": [509, 458, 11, 2171, 291, 362, 411, 732, 3755, 295, 4675, 300, 2203, 281, 312, 3869, 493, 293, 12187], "temperature": 0.0, "avg_logprob": -0.16870514551798502, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.0001430669508408755}, {"id": 318, "seek": 140112, "start": 1411.6399999999999, "end": 1412.6399999999999, "text": " somewhere else.", "tokens": [4079, 1646, 13], "temperature": 0.0, "avg_logprob": -0.16870514551798502, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.0001430669508408755}, {"id": 319, "seek": 140112, "start": 1412.6399999999999, "end": 1418.84, "text": " There, Cindy Everywhere works really nice, but when it's like lookup tables, shuffles,", "tokens": [821, 11, 32185, 37322, 1985, 534, 1481, 11, 457, 562, 309, 311, 411, 574, 1010, 8020, 11, 402, 1245, 904, 11], "temperature": 0.0, "avg_logprob": -0.16870514551798502, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.0001430669508408755}, {"id": 320, "seek": 140112, "start": 1418.84, "end": 1419.84, "text": " it works worse.", "tokens": [309, 1985, 5324, 13], "temperature": 0.0, "avg_logprob": -0.16870514551798502, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.0001430669508408755}, {"id": 321, "seek": 140112, "start": 1419.84, "end": 1420.84, "text": " We are aware.", "tokens": [492, 366, 3650, 13], "temperature": 0.0, "avg_logprob": -0.16870514551798502, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.0001430669508408755}, {"id": 322, "seek": 140112, "start": 1420.84, "end": 1424.7199999999998, "text": " We are looking into, you know, identifying the kernels where there's the biggest potential", "tokens": [492, 366, 1237, 666, 11, 291, 458, 11, 16696, 264, 23434, 1625, 689, 456, 311, 264, 3880, 3995], "temperature": 0.0, "avg_logprob": -0.16870514551798502, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.0001430669508408755}, {"id": 323, "seek": 140112, "start": 1424.7199999999998, "end": 1427.36, "text": " for improvement and doing those manually.", "tokens": [337, 10444, 293, 884, 729, 16945, 13], "temperature": 0.0, "avg_logprob": -0.16870514551798502, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.0001430669508408755}, {"id": 324, "seek": 142736, "start": 1427.36, "end": 1434.36, "text": " We are looking at HDR, implementation of a ARM of VBX, okay, so I'm doing the ARM and", "tokens": [492, 366, 1237, 412, 29650, 11, 11420, 295, 257, 45209, 295, 691, 33, 55, 11, 1392, 11, 370, 286, 478, 884, 264, 45209, 293], "temperature": 0.0, "avg_logprob": -0.4404884338378906, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.008693956770002842}, {"id": 325, "seek": 142736, "start": 1434.36, "end": 1439.8, "text": " VMT optimizations for that, and the way to do the transpose, for example, and that is", "tokens": [18038, 51, 5028, 14455, 337, 300, 11, 293, 264, 636, 281, 360, 264, 25167, 11, 337, 1365, 11, 293, 300, 307], "temperature": 0.0, "avg_logprob": -0.4404884338378906, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.008693956770002842}, {"id": 326, "seek": 142736, "start": 1439.8, "end": 1446.84, "text": " completely different to the way it is, especially with, because for AVX2, you have 256 bit-wide", "tokens": [2584, 819, 281, 264, 636, 309, 307, 11, 2318, 365, 11, 570, 337, 30198, 55, 17, 11, 291, 362, 38882, 857, 12, 7990], "temperature": 0.0, "avg_logprob": -0.4404884338378906, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.008693956770002842}, {"id": 327, "seek": 142736, "start": 1446.84, "end": 1447.84, "text": " registers.", "tokens": [38351, 13], "temperature": 0.0, "avg_logprob": -0.4404884338378906, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.008693956770002842}, {"id": 328, "seek": 142736, "start": 1447.84, "end": 1451.8799999999999, "text": " You don't have that with VM, but you have other instructions to help you try to tackle", "tokens": [509, 500, 380, 362, 300, 365, 18038, 11, 457, 291, 362, 661, 9415, 281, 854, 291, 853, 281, 14896], "temperature": 0.0, "avg_logprob": -0.4404884338378906, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.008693956770002842}, {"id": 329, "seek": 142736, "start": 1451.8799999999999, "end": 1452.8799999999999, "text": " the outcome.", "tokens": [264, 9700, 13], "temperature": 0.0, "avg_logprob": -0.4404884338378906, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.008693956770002842}, {"id": 330, "seek": 142736, "start": 1452.8799999999999, "end": 1453.8799999999999, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.4404884338378906, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.008693956770002842}, {"id": 331, "seek": 145388, "start": 1453.88, "end": 1462.44, "text": " So my point is that if you are open to contributions with specific optimizations that you might", "tokens": [407, 452, 935, 307, 300, 498, 291, 366, 1269, 281, 15725, 365, 2685, 5028, 14455, 300, 291, 1062], "temperature": 0.0, "avg_logprob": -0.22413921356201172, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0004127031425014138}, {"id": 332, "seek": 145388, "start": 1462.44, "end": 1469.3600000000001, "text": " find people to help with that, but if you restrict yourself to only using the library", "tokens": [915, 561, 281, 854, 365, 300, 11, 457, 498, 291, 7694, 1803, 281, 787, 1228, 264, 6405], "temperature": 0.0, "avg_logprob": -0.22413921356201172, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0004127031425014138}, {"id": 333, "seek": 145388, "start": 1469.3600000000001, "end": 1475.96, "text": " and only use Intel intrinsics and then translate that one using the library, you might lose", "tokens": [293, 787, 764, 19762, 28621, 1167, 293, 550, 13799, 300, 472, 1228, 264, 6405, 11, 291, 1062, 3624], "temperature": 0.0, "avg_logprob": -0.22413921356201172, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0004127031425014138}, {"id": 334, "seek": 145388, "start": 1475.96, "end": 1476.96, "text": " some performance.", "tokens": [512, 3389, 13], "temperature": 0.0, "avg_logprob": -0.22413921356201172, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0004127031425014138}, {"id": 335, "seek": 145388, "start": 1476.96, "end": 1477.96, "text": " A lot.", "tokens": [316, 688, 13], "temperature": 0.0, "avg_logprob": -0.22413921356201172, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0004127031425014138}, {"id": 336, "seek": 145388, "start": 1477.96, "end": 1481.4, "text": " We are not restricting ourselves, you know, to only using this.", "tokens": [492, 366, 406, 1472, 37714, 4175, 11, 291, 458, 11, 281, 787, 1228, 341, 13], "temperature": 0.0, "avg_logprob": -0.22413921356201172, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0004127031425014138}, {"id": 337, "seek": 148140, "start": 1481.4, "end": 1484.68, "text": " It's just because, you know, we only have so many resources, this was the fastest way", "tokens": [467, 311, 445, 570, 11, 291, 458, 11, 321, 787, 362, 370, 867, 3593, 11, 341, 390, 264, 14573, 636], "temperature": 0.0, "avg_logprob": -0.16708404060423843, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.00017198619025293738}, {"id": 338, "seek": 148140, "start": 1484.68, "end": 1485.68, "text": " to do it.", "tokens": [281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.16708404060423843, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.00017198619025293738}, {"id": 339, "seek": 148140, "start": 1485.68, "end": 1491.2800000000002, "text": " We can play it out on, you know, like actually this thing can play out VBC videos with our", "tokens": [492, 393, 862, 309, 484, 322, 11, 291, 458, 11, 411, 767, 341, 551, 393, 862, 484, 691, 7869, 2145, 365, 527], "temperature": 0.0, "avg_logprob": -0.16708404060423843, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.00017198619025293738}, {"id": 340, "seek": 148140, "start": 1491.2800000000002, "end": 1493.68, "text": " software, but yeah, totally.", "tokens": [4722, 11, 457, 1338, 11, 3879, 13], "temperature": 0.0, "avg_logprob": -0.16708404060423843, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.00017198619025293738}, {"id": 341, "seek": 148140, "start": 1493.68, "end": 1497.8400000000001, "text": " I think there is, there would need to be some changes to the build process, maybe to that", "tokens": [286, 519, 456, 307, 11, 456, 576, 643, 281, 312, 512, 2962, 281, 264, 1322, 1399, 11, 1310, 281, 300], "temperature": 0.0, "avg_logprob": -0.16708404060423843, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.00017198619025293738}, {"id": 342, "seek": 148140, "start": 1497.8400000000001, "end": 1504.16, "text": " like structure of the project to enable this, but yeah, this is something really very interesting", "tokens": [411, 3877, 295, 264, 1716, 281, 9528, 341, 11, 457, 1338, 11, 341, 307, 746, 534, 588, 1880], "temperature": 0.0, "avg_logprob": -0.16708404060423843, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.00017198619025293738}, {"id": 343, "seek": 148140, "start": 1504.16, "end": 1507.6000000000001, "text": " and I think there will be a lot of research going on in that direction.", "tokens": [293, 286, 519, 456, 486, 312, 257, 688, 295, 2132, 516, 322, 294, 300, 3513, 13], "temperature": 0.0, "avg_logprob": -0.16708404060423843, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.00017198619025293738}, {"id": 344, "seek": 148140, "start": 1507.6000000000001, "end": 1508.6000000000001, "text": " Thanks.", "tokens": [2561, 13], "temperature": 0.0, "avg_logprob": -0.16708404060423843, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.00017198619025293738}, {"id": 345, "seek": 150860, "start": 1508.6, "end": 1511.6, "text": " One last question, yeah?", "tokens": [1485, 1036, 1168, 11, 1338, 30], "temperature": 0.0, "avg_logprob": -0.4289126512480945, "compression_ratio": 1.7248322147651007, "no_speech_prob": 0.0007580282399430871}, {"id": 346, "seek": 150860, "start": 1511.6, "end": 1518.3999999999999, "text": " How does it compare, what are the advantages of AV1 in terms of compression or computation?", "tokens": [1012, 775, 309, 6794, 11, 437, 366, 264, 14906, 295, 30198, 16, 294, 2115, 295, 19355, 420, 24903, 30], "temperature": 0.0, "avg_logprob": -0.4289126512480945, "compression_ratio": 1.7248322147651007, "no_speech_prob": 0.0007580282399430871}, {"id": 347, "seek": 150860, "start": 1518.3999999999999, "end": 1526.6, "text": " Well, yeah, so the question is, what are the advantages of VBC or VVNG?", "tokens": [1042, 11, 1338, 11, 370, 264, 1168, 307, 11, 437, 366, 264, 14906, 295, 691, 7869, 420, 691, 53, 45, 38, 30], "temperature": 0.0, "avg_logprob": -0.4289126512480945, "compression_ratio": 1.7248322147651007, "no_speech_prob": 0.0007580282399430871}, {"id": 348, "seek": 150860, "start": 1526.6, "end": 1531.6, "text": " VBC over AV1.", "tokens": [691, 7869, 670, 30198, 16, 13], "temperature": 0.0, "avg_logprob": -0.4289126512480945, "compression_ratio": 1.7248322147651007, "no_speech_prob": 0.0007580282399430871}, {"id": 349, "seek": 150860, "start": 1531.6, "end": 1532.6, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.4289126512480945, "compression_ratio": 1.7248322147651007, "no_speech_prob": 0.0007580282399430871}, {"id": 350, "seek": 150860, "start": 1532.6, "end": 1537.04, "text": " So what are the advantages of VBC over AV1?", "tokens": [407, 437, 366, 264, 14906, 295, 691, 7869, 670, 30198, 16, 30], "temperature": 0.0, "avg_logprob": -0.4289126512480945, "compression_ratio": 1.7248322147651007, "no_speech_prob": 0.0007580282399430871}, {"id": 351, "seek": 153704, "start": 1537.04, "end": 1539.3999999999999, "text": " So VBC is a successor to HVBC, right?", "tokens": [407, 691, 7869, 307, 257, 31864, 281, 389, 53, 7869, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18648887167171557, "compression_ratio": 1.5892857142857142, "no_speech_prob": 2.5287297830800526e-05}, {"id": 352, "seek": 153704, "start": 1539.3999999999999, "end": 1544.68, "text": " It was done by people who were really knowledgeable on how to make a standard work.", "tokens": [467, 390, 1096, 538, 561, 567, 645, 534, 33800, 322, 577, 281, 652, 257, 3832, 589, 13], "temperature": 0.0, "avg_logprob": -0.18648887167171557, "compression_ratio": 1.5892857142857142, "no_speech_prob": 2.5287297830800526e-05}, {"id": 353, "seek": 153704, "start": 1544.68, "end": 1552.24, "text": " So you know, it's the one thing, it just provides the additional bitrate savings, right?", "tokens": [407, 291, 458, 11, 309, 311, 264, 472, 551, 11, 309, 445, 6417, 264, 4497, 857, 4404, 13454, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18648887167171557, "compression_ratio": 1.5892857142857142, "no_speech_prob": 2.5287297830800526e-05}, {"id": 354, "seek": 153704, "start": 1552.24, "end": 1558.8799999999999, "text": " So here you still see like 20% additional bitrate savings over like the best case of", "tokens": [407, 510, 291, 920, 536, 411, 945, 4, 4497, 857, 4404, 13454, 670, 411, 264, 1151, 1389, 295], "temperature": 0.0, "avg_logprob": -0.18648887167171557, "compression_ratio": 1.5892857142857142, "no_speech_prob": 2.5287297830800526e-05}, {"id": 355, "seek": 153704, "start": 1558.8799999999999, "end": 1563.8, "text": " AV1 and there isn't so many of these initial hiccups, right?", "tokens": [30198, 16, 293, 456, 1943, 380, 370, 867, 295, 613, 5883, 23697, 66, 7528, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18648887167171557, "compression_ratio": 1.5892857142857142, "no_speech_prob": 2.5287297830800526e-05}, {"id": 356, "seek": 156380, "start": 1563.8, "end": 1568.9199999999998, "text": " So the HDR support just works, you know, immersive stuff just works a little, like a lot of", "tokens": [407, 264, 29650, 1406, 445, 1985, 11, 291, 458, 11, 35409, 1507, 445, 1985, 257, 707, 11, 411, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.19888106179893564, "compression_ratio": 1.7053941908713692, "no_speech_prob": 3.168562034261413e-05}, {"id": 357, "seek": 156380, "start": 1568.9199999999998, "end": 1571.6, "text": " those things, they just work.", "tokens": [729, 721, 11, 436, 445, 589, 13], "temperature": 0.0, "avg_logprob": -0.19888106179893564, "compression_ratio": 1.7053941908713692, "no_speech_prob": 3.168562034261413e-05}, {"id": 358, "seek": 156380, "start": 1571.6, "end": 1577.52, "text": " And then we can do stuff on top of that, like doing open-gop adaptive streaming, which allows", "tokens": [400, 550, 321, 393, 360, 1507, 322, 1192, 295, 300, 11, 411, 884, 1269, 12, 70, 404, 27912, 11791, 11, 597, 4045], "temperature": 0.0, "avg_logprob": -0.19888106179893564, "compression_ratio": 1.7053941908713692, "no_speech_prob": 3.168562034261413e-05}, {"id": 359, "seek": 156380, "start": 1577.52, "end": 1581.96, "text": " you to reduce the bitrate by like another 10% on top of that, right?", "tokens": [291, 281, 5407, 264, 857, 4404, 538, 411, 1071, 1266, 4, 322, 1192, 295, 300, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19888106179893564, "compression_ratio": 1.7053941908713692, "no_speech_prob": 3.168562034261413e-05}, {"id": 360, "seek": 156380, "start": 1581.96, "end": 1586.6399999999999, "text": " Like with all the other standards, I think the adaptive streaming can only be done with", "tokens": [1743, 365, 439, 264, 661, 7787, 11, 286, 519, 264, 27912, 11791, 393, 787, 312, 1096, 365], "temperature": 0.0, "avg_logprob": -0.19888106179893564, "compression_ratio": 1.7053941908713692, "no_speech_prob": 3.168562034261413e-05}, {"id": 361, "seek": 156380, "start": 1586.6399999999999, "end": 1592.56, "text": " close-cops or with a prediction break.", "tokens": [1998, 12, 66, 3370, 420, 365, 257, 17630, 1821, 13], "temperature": 0.0, "avg_logprob": -0.19888106179893564, "compression_ratio": 1.7053941908713692, "no_speech_prob": 3.168562034261413e-05}, {"id": 362, "seek": 159256, "start": 1592.56, "end": 1600.44, "text": " I would say more mature, but you know, I know there are different views of this, more compression", "tokens": [286, 576, 584, 544, 14442, 11, 457, 291, 458, 11, 286, 458, 456, 366, 819, 6809, 295, 341, 11, 544, 19355], "temperature": 0.0, "avg_logprob": -0.37697185940212674, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00023463893739972264}, {"id": 363, "seek": 159256, "start": 1600.44, "end": 1605.8799999999999, "text": " efficiency and really versatile mature usability.", "tokens": [10493, 293, 534, 25057, 14442, 46878, 13], "temperature": 0.0, "avg_logprob": -0.37697185940212674, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00023463893739972264}, {"id": 364, "seek": 159256, "start": 1605.8799999999999, "end": 1607.8799999999999, "text": " Thank you, Adam.", "tokens": [1044, 291, 11, 7938, 13], "temperature": 0.0, "avg_logprob": -0.37697185940212674, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00023463893739972264}, {"id": 365, "seek": 159256, "start": 1607.8799999999999, "end": 1608.8799999999999, "text": " Thanks.", "tokens": [2561, 13], "temperature": 0.0, "avg_logprob": -0.37697185940212674, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00023463893739972264}, {"id": 366, "seek": 160888, "start": 1608.88, "end": 1625.8400000000001, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 1.0, "avg_logprob": -1.094945294516427, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.00031882154871709645}], "language": "en"}