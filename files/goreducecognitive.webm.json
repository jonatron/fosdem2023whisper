{"text": " Okay, our first actual speaker today is Frederico, who is a maintainer of Metal LB, which I personally use, thank you, over at RedHeads and he'll be talking to us about cognitive loads. So a round of applause for Frederico. Yeah, it works. Yeah, so today I'm going to talk about cognitive load and how it affects our code base, why it matters and how we can reduce it. And the reason why I put together this talk is because over the past, I would say, two years, I started contributing first and then maintaining the Metal LB project. Is anyone using it? Okay, so if it's gotten less stable, that's because of me. But by doing that, I started reviewing a good amount of PRs and over this period, I kind of identified the recurring patterns that I was keeping asking and asking over. And those recurring patterns, those scattered suggestions that I try to give in code reviews are what this talk is about. In terms of code, Metal LB is a nicely sized project, not too big, not too small, and I think it's worth keeping alive. So some quick words about me, I'm Frederico, I work for RedHead, I'm part of a networking team in charge of making the OpenShift platform suitable for telco workloads. That means that I touch and contribute a lot of these different network-related projects, but that doesn't mean that I'm a network expert because I'm not. So don't come asking to fix your router, as my parents do because I won't. All of these are my handles. Probably the most annoying one needs to be adjusted, but you can find me there. If you have questions to ask, if you need to provide feedback, I'll try to reply. So let's start with cognitive load, and this is the Wikipedia definition. Cognitive load is meant to be the extra energy, the amount of effort that we need to put in place to understand something that applies perfectly to our codebase. It might be because we are reading something that we wrote years ago where we were less expert. It might be because we are trying to review some code that somebody else is trying to push to our project. It might be because we got a bug report and we need to correlate the behavior that we get from the reality and what we understand from our code. And the less energy we spend, we are able to spend the better because it might be evening and we might be tired and we might have some urgency about that. That's why it's so important. And sometimes, this complexity is proportional. This extra energy is proportional to the complexity of our code. Think about cryptography. Think about ultra-optimized code that runs in embedded systems. But some other times, it's not. Take this example and take the same run through another skater. This takes a lot more energy to understand that this function prints hello world. So this is to say that we need to put an effort because that effort gets our reward in terms of speed of development and speed of understanding. So say that a disclaimer, not everything is black and white. Of course, there might be exceptions to the suggestions that I'm going to say. And this talk is more or less a collection of scattered robots that I collected from sources that I trust. So in case you don't like them, blame the sources. In general, I think that the stuff that we write should take care of two sites. One is, of course, the implementation, and this implementation is pretty clear, I guess. This function is just doing the sum of two numbers. It's easy to understand. We can't argue with that. But what if we land on a code base that is doing something like this, and this takes more energy compared to a better version of it, where the function is named nicely. So we understand what it's doing. This is to say, and this is something that is going to be a requirement in this talk, that what matters is not only how we care about the implementation, but also how we care about the users of our packages, of our functions, of our objects. So let's start with the first item, which is the line of sight. And this is something that I believe every good and idiomatic code base should try to foster. Basically, we have this leftmost indented line where all the happy path leaves, and we have this indented one where we handle all the exceptions. And I expect every code base, which is well written where I land to, to respect this rule. And there are a few tips to do this. It wasn't me. So these are just tips to do that, to implement this. And let's see why it matters, how it will make our code base better. This was more or less a real example that I got from a real PR, and it was really hard to follow all the special cases. And so I tried to give feedback and try to hammer it with suggestions in order to leverage early returns and flipping errors, removing else, when a CNL is something that I try to get rid of. Like, it's a red flag, and I think three times before allowing it to go through. And then leverage more returns and then, yeah, leverage more returns and then, sorry, yeah, trapping into a function so we can leverage even more returns because now we have a smaller scope. So we got to something from something which looked like this to something that looked like this. And I dare you to say that this is easier to understand. And remember, like, this is understandable, but this requires a lot of energy. It's clear. It's better because of all the reasons that I already said before. There is this nice blog post from Matt Ryder about this very same topic. He more or less gives the same set of advices. Linocyte is not a nice exercise. It's a rule of thumb that allows us to untangle our code and to make it slicker and easier to understand. Next I'm going to talk about package names. This is another favorite of mine. We know that naming is hard, and that is particularly true in case of package names. We know that the name of a package should be small enough because that is consuming screen space, but should be also good enough to let us understand the purpose of the package. In Go there is even more because when we use an object, the name of the package is part of the name. So that is an opportunity for us to put some value in that part that the reader can consume. And again, I'm starting with a bad example. We have this utility package, and we have this copy node function that is totally fictional, but that utility part is a wasted opportunity. It's part of the name that doesn't add any value. So it's better to take and split our package, smaller scoped packages that do and explain what to do. And in this case, from the colon side, you have node.copy, which still explains the purpose of the function, and it's not wasting space. And this was taken from the official Go blog, and it says basically the same thing. There is no need to have these gigantic kitchen sink packages where we throw everything because in Go packages are free. So it's fine to split them in a better way. Next one is going to be about errors, and I see also this happening very frequently. In Go, errors are types, and let's say that the developer wants to handle a special error. And the problem with these approaches is that we are giving away the fact that errors are types, and we are converting them to a string, and we are treating them as a string. And since Go 1.13, we have, like, and there are, like, that's legacy. So there are no excuses not to use this. There are two ways, one is to assert that the error that we are checking is an instance of a given object that we have somewhere, and there is another, sorry, this is new because the other one wasn't working. And there is another one, which is about asserting that the error that we want to handle implements the error interface against a specific real type. But there is more. So in this way, you can have wraps of errors, and you can assert that the error that you are checking not only equals the one that you are handling, but also any error inside this wrap. And this is how you wrap them. You can either use errors.wrap, so the return error from this function will contain the value returned by this, but will also return true if we assert against the wrapped one. And also there is the way suggested by the standard library, which is using the %w formators. So both of them will return you a wrapped error. So now let's talk about pure functions and why they are important. So a pure function has two properties. One is the fact that no matter how time, when you call it, no matter how many times you call it, with a given set of input parameters, it will return always the same output. And the other property is the fact that it shouldn't rely on the state of your system. It shouldn't modify the state of the system. Should it be global variables or static variables or your input parameters or anything that is external to the function. And why it matters. This is an example where the behavior of this function depends on the state of an external system that is accessed through a client. And then you have the business logic after that. And why this is bad. I would say that mostly because this is hard to test or we can mock the external system, we can do tricks to replace the client, but moving away the statefulness part of the function away and having the business logic implemented as a pure function will allow us to be quicker in writing the implementation and to write our tests. And how about the second part. So we have a function that accepts a pointer and in some random cases it changes the object. And what's the problem with that? The problem with that is now on the reading side because you don't know that it's not clear enough that this function is changing the node. So you get your bug report and you look at the code and you know that somewhere the name of the node changed, but you don't know why. And that's because it's not clear from outside that is what this function is doing and it's harder to reason about it. So a better way is to change the name of the function so it's clear, but I think that and this comes quite often, a better way to do that is to delegate the responsibility of changing the object outside and changing the function to be a pure function. Again this version is easier to understand, it's easier to reason about, it's clear when you will have something to change. And this can also say about environment variables. In the world of pods and containers, adding a new knob as an environment variable is so convenient. Just add an environment variable, you consume it from the function where you need it and you are done. But the problem with that is that you then don't have control anymore on all the knobs on all the parameters that your program is consuming because they are all scattered across the code base and that is bad because you can't foresee what a given function is doing by reading its calling site. So again, this is something that should be avoided, environment variables should be read in your main functions and then be propagated through all the stacks. So another topic that I care about is function arguments. And the first one is Booleans. So you start with something like this where you have a simple setup function that is easy enough and then with all the good intentions of the world, thanks, with all the good intentions of the world, the developer starts adding a parameter but then we need another one and then we need another one. And how does it look on the calling site? Something like this and you think, true, false, true, true, false, what the hell? And then you need to stop, you need to enter into this function, you need to understand was it, where was the enable webbook parameter? It was the first one and then you get back here and this works but adds friction and getting a better version of it is so cheap that we should do that because we are doing a favor to our future selves, we are doing a favor to the maintainer and it's going to be easier to understand. Another option might be to pass a structure to the function that also works but not this. Now I want to talk about function overloading or the fact that God doesn't have, so it's more or less the same as the other one. God doesn't have function overloading so it's easy to have this full variety of the same function where we need to slightly change the behavior. So you start with creating a service, then you need one with a backend, then you need one with an IP and then you need one with a backend and with an IP and it's clear that can get easily out of hand. So an approach that I really like is using a variety of the argument with some modifiers that accept the parameter and do what they have to do and this is how it looks from the calling site, again, it's clear, it's easy to understand, your future self will thank you for this. And there is also another version where you can have these generator functions. I think it's on the borderline of being too magic for me but, again, this one is easy to read. So next one, I see this happening a lot in the world of controllers where you have one file that basically implements all the methods related to a controller. So you have this file and you need to add an utility function and then all the other functions are methods and what do you do? You add a new method, even if it doesn't have to be a method. So you look at something like this and you think, hmm, why is this a method? Is there something wrong with that? And this, again, is adding friction that could be avoided. So if a function is a function, just make it a function and not a method because also testing is easier. You don't have to have the instance that you are not using for anything just in order to test this function. And then a word about pointers. Go has pointers, like not all other languages, so people might find them hard to reason about. And when I see two functions like this, my first thing, thought is, like, this one is not changing the object and the second one is doing that. So this is the rule of thumb that I'm trying to apply. If a function is not changing the object, then pass the object with a value, otherwise pass the pointer. But there are also exceptions. There are some kind of objects that can be passed by value or they can, but they will give you a bad afternoon. But so mutex is file descriptors. We need to pass them by reference because that's the way it works. We have linters that help us in that and we have this rule of thumb that says if you look at the object, if all the methods associated with the pointer, then use a pointer. One might argue how about performances. We are passing the whole object instead of passing just the reference. Yeah, passing the reference is cheaper, but this is not see, this is go, and that's not always clear. So what we should care about is the readability. And we have a lot of toolery that will help us to understand if that can be optimized if it's in the hot path. And then we need to sacrifice a bit the reliability of our program in order to have better performances. So now I'm going to talk about something that was advocated in clean code where it says that our code base should read like a newspaper, which means that you open a file, you should have all the high level concepts on the top of the file, and then start to find all the nitty details of the implementation in the bottom of the file. And these applies pretty well to go. So what I expect from a well-written go file is to have all the public methods, all the public objects in the top of the file, because when I open the file, I see what this package has to offer to the external world. And so those are our high level concepts by definition. And another thing that I think is sometimes underestimated is the fact that we can have our packages split into files. So again, in order to have a better navigability of our code base, we can split it into files, have a main file related to the package that is named after the package, and then have these smaller entities where we put the different logics. And this is basically what I'm trying to say here. So try to have the public fields on the top, try to remove or to move the utility functions in the bottom, split the package into file, because again, it's free. It won't cost any energy to you or to the executable, and have a main package file that is named after the package. Next item is about asynchronous functions. And I saw this many times. It's one of the nice things about Go, right? It's so easy, so convenient to implement concurrent code. You can just implement Go routines, you can pass channels and have fan in, fan out. But the problem with that is that something like this has some flaws. And I think that is way better to, again, take the business logic, move it to a synchronous function that is easier to test without all the infrastructure that you need to put in place with channels, with weight groups in order to reverse the synchronousness of your function just in order to test it. So if you can, move the business logic into a synchronous function and let the calling site handle the life cycle of the Go routine. So again, that part has to be delegated on the client code, and that will make our function easier to test and our code base easier to reason about. And again, I didn't invent this as everything else. This is from the code review Go wiki, and it's basically saying the same thing, like try to use synchronous functions as much as you can. Next item is about functions that lie, and what I mean by that. You have something that is, what would you expect this function to do? Clear the node. Exactly. That's what I would expect. But the developer found a very edgy corner case where if the name of the node is do not clean, then do not clean. And he was doing that with the all good faith of the word. He's trying to solve a problem here. But the problem is that, again, this is going to give us a bad afternoon because we'll see that the node is not being cleared and we'll have to put a lot of printfs in our code or to do a lot of debugging in order to understand why is this happening. So again, this is done with good intentions, but the result is not so good. So again, as I said multiple times today, we should defer this responsibility to the calling site because that will result in a code base that requires less energy and less effort to understand. What if we have this function called 100 times in our code base, then I don't know. Just call it clear the node, but do not clean one or have one filter function, whatever, but not lie to the reader. So wrapping up, there is no much to wrap up. I mean, it was just a list of no related items. Maybe the only take away that is globally is to say that we should be smart and let our readers, the calling site over the code base do a bit more because that will give us a better day in the future. I'm a strong believer of the Pareto principle, most often when it's on the bad side of it, but in this case, I think that by applying these set of rules that will take very less to implement, those will improve the quality of the code base a lot. And then I want to finish with this quote from Rob Pike, simplicity is complicated, but the clarity is worth the fight. And with that, I'm finished. Sorry? Are there any questions, I'll try to come with a microphone, if it doesn't work, we'll have to repeat it. Hi, thanks for the talk. I was wondering, do you see any room for automating some of these rules and wisdom that you share today, maybe something else as well? I don't know, I should think about that. Probably some of them, yes, like avoiding having functions or raising a flag if a function is accepting a channel, for example, but there are exceptions to that, so that shouldn't be blocking. There are some others, like the function that is lying to the user is something that depends on the implementation, or for example, having a function that accepts five booleans should be flagged. So, I see that, I think that it depends on the case, but some of them might be automated. Any more questions? No? Thank you very much. How was it?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 21.400000000000002, "text": " Okay, our first actual speaker today is Frederico, who is a maintainer of Metal LB, which I personally", "tokens": [1033, 11, 527, 700, 3539, 8145, 965, 307, 27535, 2789, 11, 567, 307, 257, 6909, 260, 295, 23488, 441, 33, 11, 597, 286, 5665], "temperature": 0.0, "avg_logprob": -0.3326228948739859, "compression_ratio": 1.2671232876712328, "no_speech_prob": 0.37511202692985535}, {"id": 1, "seek": 0, "start": 21.400000000000002, "end": 26.6, "text": " use, thank you, over at RedHeads and he'll be talking to us about cognitive loads.", "tokens": [764, 11, 1309, 291, 11, 670, 412, 4477, 39, 2056, 82, 293, 415, 603, 312, 1417, 281, 505, 466, 15605, 12668, 13], "temperature": 0.0, "avg_logprob": -0.3326228948739859, "compression_ratio": 1.2671232876712328, "no_speech_prob": 0.37511202692985535}, {"id": 2, "seek": 2660, "start": 26.6, "end": 31.6, "text": " So a round of applause for Frederico.", "tokens": [407, 257, 3098, 295, 9969, 337, 27535, 2789, 13], "temperature": 0.0, "avg_logprob": -0.2371406304208856, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.0015659552300348878}, {"id": 3, "seek": 2660, "start": 31.6, "end": 36.6, "text": " Yeah, it works.", "tokens": [865, 11, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.2371406304208856, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.0015659552300348878}, {"id": 4, "seek": 2660, "start": 36.6, "end": 44.6, "text": " Yeah, so today I'm going to talk about cognitive load and how it affects our code base, why", "tokens": [865, 11, 370, 965, 286, 478, 516, 281, 751, 466, 15605, 3677, 293, 577, 309, 11807, 527, 3089, 3096, 11, 983], "temperature": 0.0, "avg_logprob": -0.2371406304208856, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.0015659552300348878}, {"id": 5, "seek": 2660, "start": 44.6, "end": 47.68000000000001, "text": " it matters and how we can reduce it.", "tokens": [309, 7001, 293, 577, 321, 393, 5407, 309, 13], "temperature": 0.0, "avg_logprob": -0.2371406304208856, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.0015659552300348878}, {"id": 6, "seek": 2660, "start": 47.68000000000001, "end": 52.56, "text": " And the reason why I put together this talk is because over the past, I would say, two", "tokens": [400, 264, 1778, 983, 286, 829, 1214, 341, 751, 307, 570, 670, 264, 1791, 11, 286, 576, 584, 11, 732], "temperature": 0.0, "avg_logprob": -0.2371406304208856, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.0015659552300348878}, {"id": 7, "seek": 5256, "start": 52.56, "end": 57.92, "text": " years, I started contributing first and then maintaining the Metal LB project.", "tokens": [924, 11, 286, 1409, 19270, 700, 293, 550, 14916, 264, 23488, 441, 33, 1716, 13], "temperature": 0.0, "avg_logprob": -0.17205471590340857, "compression_ratio": 1.5233644859813085, "no_speech_prob": 0.0003088477242272347}, {"id": 8, "seek": 5256, "start": 57.92, "end": 59.800000000000004, "text": " Is anyone using it?", "tokens": [1119, 2878, 1228, 309, 30], "temperature": 0.0, "avg_logprob": -0.17205471590340857, "compression_ratio": 1.5233644859813085, "no_speech_prob": 0.0003088477242272347}, {"id": 9, "seek": 5256, "start": 59.800000000000004, "end": 65.60000000000001, "text": " Okay, so if it's gotten less stable, that's because of me.", "tokens": [1033, 11, 370, 498, 309, 311, 5768, 1570, 8351, 11, 300, 311, 570, 295, 385, 13], "temperature": 0.0, "avg_logprob": -0.17205471590340857, "compression_ratio": 1.5233644859813085, "no_speech_prob": 0.0003088477242272347}, {"id": 10, "seek": 5256, "start": 65.60000000000001, "end": 74.64, "text": " But by doing that, I started reviewing a good amount of PRs and over this period, I kind", "tokens": [583, 538, 884, 300, 11, 286, 1409, 19576, 257, 665, 2372, 295, 11568, 82, 293, 670, 341, 2896, 11, 286, 733], "temperature": 0.0, "avg_logprob": -0.17205471590340857, "compression_ratio": 1.5233644859813085, "no_speech_prob": 0.0003088477242272347}, {"id": 11, "seek": 5256, "start": 74.64, "end": 80.76, "text": " of identified the recurring patterns that I was keeping asking and asking over.", "tokens": [295, 9234, 264, 32279, 8294, 300, 286, 390, 5145, 3365, 293, 3365, 670, 13], "temperature": 0.0, "avg_logprob": -0.17205471590340857, "compression_ratio": 1.5233644859813085, "no_speech_prob": 0.0003088477242272347}, {"id": 12, "seek": 8076, "start": 80.76, "end": 86.96000000000001, "text": " And those recurring patterns, those scattered suggestions that I try to give in code reviews", "tokens": [400, 729, 32279, 8294, 11, 729, 21986, 13396, 300, 286, 853, 281, 976, 294, 3089, 10229], "temperature": 0.0, "avg_logprob": -0.16576380258078102, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.00011920641554752365}, {"id": 13, "seek": 8076, "start": 86.96000000000001, "end": 89.96000000000001, "text": " are what this talk is about.", "tokens": [366, 437, 341, 751, 307, 466, 13], "temperature": 0.0, "avg_logprob": -0.16576380258078102, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.00011920641554752365}, {"id": 14, "seek": 8076, "start": 89.96000000000001, "end": 97.32000000000001, "text": " In terms of code, Metal LB is a nicely sized project, not too big, not too small, and I", "tokens": [682, 2115, 295, 3089, 11, 23488, 441, 33, 307, 257, 9594, 20004, 1716, 11, 406, 886, 955, 11, 406, 886, 1359, 11, 293, 286], "temperature": 0.0, "avg_logprob": -0.16576380258078102, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.00011920641554752365}, {"id": 15, "seek": 8076, "start": 97.32000000000001, "end": 102.2, "text": " think it's worth keeping alive.", "tokens": [519, 309, 311, 3163, 5145, 5465, 13], "temperature": 0.0, "avg_logprob": -0.16576380258078102, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.00011920641554752365}, {"id": 16, "seek": 8076, "start": 102.2, "end": 107.24000000000001, "text": " So some quick words about me, I'm Frederico, I work for RedHead, I'm part of a networking", "tokens": [407, 512, 1702, 2283, 466, 385, 11, 286, 478, 27535, 2789, 11, 286, 589, 337, 4477, 39, 2056, 11, 286, 478, 644, 295, 257, 17985], "temperature": 0.0, "avg_logprob": -0.16576380258078102, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.00011920641554752365}, {"id": 17, "seek": 10724, "start": 107.24, "end": 112.83999999999999, "text": " team in charge of making the OpenShift platform suitable for telco workloads.", "tokens": [1469, 294, 4602, 295, 1455, 264, 7238, 7774, 2008, 3663, 12873, 337, 15284, 1291, 32452, 13], "temperature": 0.0, "avg_logprob": -0.16586067991436654, "compression_ratio": 1.6124031007751938, "no_speech_prob": 0.00011881579121109098}, {"id": 18, "seek": 10724, "start": 112.83999999999999, "end": 119.96, "text": " That means that I touch and contribute a lot of these different network-related projects,", "tokens": [663, 1355, 300, 286, 2557, 293, 10586, 257, 688, 295, 613, 819, 3209, 12, 12004, 4455, 11], "temperature": 0.0, "avg_logprob": -0.16586067991436654, "compression_ratio": 1.6124031007751938, "no_speech_prob": 0.00011881579121109098}, {"id": 19, "seek": 10724, "start": 119.96, "end": 123.84, "text": " but that doesn't mean that I'm a network expert because I'm not.", "tokens": [457, 300, 1177, 380, 914, 300, 286, 478, 257, 3209, 5844, 570, 286, 478, 406, 13], "temperature": 0.0, "avg_logprob": -0.16586067991436654, "compression_ratio": 1.6124031007751938, "no_speech_prob": 0.00011881579121109098}, {"id": 20, "seek": 10724, "start": 123.84, "end": 129.64, "text": " So don't come asking to fix your router, as my parents do because I won't.", "tokens": [407, 500, 380, 808, 3365, 281, 3191, 428, 22492, 11, 382, 452, 3152, 360, 570, 286, 1582, 380, 13], "temperature": 0.0, "avg_logprob": -0.16586067991436654, "compression_ratio": 1.6124031007751938, "no_speech_prob": 0.00011881579121109098}, {"id": 21, "seek": 10724, "start": 129.64, "end": 131.84, "text": " All of these are my handles.", "tokens": [1057, 295, 613, 366, 452, 18722, 13], "temperature": 0.0, "avg_logprob": -0.16586067991436654, "compression_ratio": 1.6124031007751938, "no_speech_prob": 0.00011881579121109098}, {"id": 22, "seek": 10724, "start": 131.84, "end": 136.2, "text": " Probably the most annoying one needs to be adjusted, but you can find me there.", "tokens": [9210, 264, 881, 11304, 472, 2203, 281, 312, 19871, 11, 457, 291, 393, 915, 385, 456, 13], "temperature": 0.0, "avg_logprob": -0.16586067991436654, "compression_ratio": 1.6124031007751938, "no_speech_prob": 0.00011881579121109098}, {"id": 23, "seek": 13620, "start": 136.2, "end": 143.51999999999998, "text": " If you have questions to ask, if you need to provide feedback, I'll try to reply.", "tokens": [759, 291, 362, 1651, 281, 1029, 11, 498, 291, 643, 281, 2893, 5824, 11, 286, 603, 853, 281, 16972, 13], "temperature": 0.0, "avg_logprob": -0.14182257165714185, "compression_ratio": 1.6330645161290323, "no_speech_prob": 6.706600106554106e-05}, {"id": 24, "seek": 13620, "start": 143.51999999999998, "end": 149.76, "text": " So let's start with cognitive load, and this is the Wikipedia definition.", "tokens": [407, 718, 311, 722, 365, 15605, 3677, 11, 293, 341, 307, 264, 28999, 7123, 13], "temperature": 0.0, "avg_logprob": -0.14182257165714185, "compression_ratio": 1.6330645161290323, "no_speech_prob": 6.706600106554106e-05}, {"id": 25, "seek": 13620, "start": 149.76, "end": 154.64, "text": " Cognitive load is meant to be the extra energy, the amount of effort that we need to put in", "tokens": [383, 2912, 2187, 3677, 307, 4140, 281, 312, 264, 2857, 2281, 11, 264, 2372, 295, 4630, 300, 321, 643, 281, 829, 294], "temperature": 0.0, "avg_logprob": -0.14182257165714185, "compression_ratio": 1.6330645161290323, "no_speech_prob": 6.706600106554106e-05}, {"id": 26, "seek": 13620, "start": 154.64, "end": 161.51999999999998, "text": " place to understand something that applies perfectly to our codebase.", "tokens": [1081, 281, 1223, 746, 300, 13165, 6239, 281, 527, 3089, 17429, 13], "temperature": 0.0, "avg_logprob": -0.14182257165714185, "compression_ratio": 1.6330645161290323, "no_speech_prob": 6.706600106554106e-05}, {"id": 27, "seek": 13620, "start": 161.51999999999998, "end": 165.51999999999998, "text": " It might be because we are reading something that we wrote years ago where we were less", "tokens": [467, 1062, 312, 570, 321, 366, 3760, 746, 300, 321, 4114, 924, 2057, 689, 321, 645, 1570], "temperature": 0.0, "avg_logprob": -0.14182257165714185, "compression_ratio": 1.6330645161290323, "no_speech_prob": 6.706600106554106e-05}, {"id": 28, "seek": 16552, "start": 165.52, "end": 166.52, "text": " expert.", "tokens": [5844, 13], "temperature": 0.0, "avg_logprob": -0.14720516643304934, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.0002000643580686301}, {"id": 29, "seek": 16552, "start": 166.52, "end": 171.44, "text": " It might be because we are trying to review some code that somebody else is trying to", "tokens": [467, 1062, 312, 570, 321, 366, 1382, 281, 3131, 512, 3089, 300, 2618, 1646, 307, 1382, 281], "temperature": 0.0, "avg_logprob": -0.14720516643304934, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.0002000643580686301}, {"id": 30, "seek": 16552, "start": 171.44, "end": 172.88000000000002, "text": " push to our project.", "tokens": [2944, 281, 527, 1716, 13], "temperature": 0.0, "avg_logprob": -0.14720516643304934, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.0002000643580686301}, {"id": 31, "seek": 16552, "start": 172.88000000000002, "end": 177.88, "text": " It might be because we got a bug report and we need to correlate the behavior that we", "tokens": [467, 1062, 312, 570, 321, 658, 257, 7426, 2275, 293, 321, 643, 281, 48742, 264, 5223, 300, 321], "temperature": 0.0, "avg_logprob": -0.14720516643304934, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.0002000643580686301}, {"id": 32, "seek": 16552, "start": 177.88, "end": 186.08, "text": " get from the reality and what we understand from our code.", "tokens": [483, 490, 264, 4103, 293, 437, 321, 1223, 490, 527, 3089, 13], "temperature": 0.0, "avg_logprob": -0.14720516643304934, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.0002000643580686301}, {"id": 33, "seek": 16552, "start": 186.08, "end": 191.44, "text": " And the less energy we spend, we are able to spend the better because it might be evening", "tokens": [400, 264, 1570, 2281, 321, 3496, 11, 321, 366, 1075, 281, 3496, 264, 1101, 570, 309, 1062, 312, 5634], "temperature": 0.0, "avg_logprob": -0.14720516643304934, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.0002000643580686301}, {"id": 34, "seek": 19144, "start": 191.44, "end": 196.16, "text": " and we might be tired and we might have some urgency about that.", "tokens": [293, 321, 1062, 312, 5868, 293, 321, 1062, 362, 512, 29734, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.1832669513060315, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.00012451464135665447}, {"id": 35, "seek": 19144, "start": 196.16, "end": 198.4, "text": " That's why it's so important.", "tokens": [663, 311, 983, 309, 311, 370, 1021, 13], "temperature": 0.0, "avg_logprob": -0.1832669513060315, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.00012451464135665447}, {"id": 36, "seek": 19144, "start": 198.4, "end": 203.48, "text": " And sometimes, this complexity is proportional.", "tokens": [400, 2171, 11, 341, 14024, 307, 24969, 13], "temperature": 0.0, "avg_logprob": -0.1832669513060315, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.00012451464135665447}, {"id": 37, "seek": 19144, "start": 203.48, "end": 206.92, "text": " This extra energy is proportional to the complexity of our code.", "tokens": [639, 2857, 2281, 307, 24969, 281, 264, 14024, 295, 527, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1832669513060315, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.00012451464135665447}, {"id": 38, "seek": 19144, "start": 206.92, "end": 208.52, "text": " Think about cryptography.", "tokens": [6557, 466, 9844, 5820, 13], "temperature": 0.0, "avg_logprob": -0.1832669513060315, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.00012451464135665447}, {"id": 39, "seek": 19144, "start": 208.52, "end": 213.8, "text": " Think about ultra-optimized code that runs in embedded systems.", "tokens": [6557, 466, 14808, 12, 5747, 332, 1602, 3089, 300, 6676, 294, 16741, 3652, 13], "temperature": 0.0, "avg_logprob": -0.1832669513060315, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.00012451464135665447}, {"id": 40, "seek": 19144, "start": 213.8, "end": 215.84, "text": " But some other times, it's not.", "tokens": [583, 512, 661, 1413, 11, 309, 311, 406, 13], "temperature": 0.0, "avg_logprob": -0.1832669513060315, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.00012451464135665447}, {"id": 41, "seek": 19144, "start": 215.84, "end": 220.44, "text": " Take this example and take the same run through another skater.", "tokens": [3664, 341, 1365, 293, 747, 264, 912, 1190, 807, 1071, 1110, 771, 13], "temperature": 0.0, "avg_logprob": -0.1832669513060315, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.00012451464135665447}, {"id": 42, "seek": 22044, "start": 220.44, "end": 228.24, "text": " This takes a lot more energy to understand that this function prints hello world.", "tokens": [639, 2516, 257, 688, 544, 2281, 281, 1223, 300, 341, 2445, 22305, 7751, 1002, 13], "temperature": 0.0, "avg_logprob": -0.20525680371184848, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.00020504814165178686}, {"id": 43, "seek": 22044, "start": 228.24, "end": 236.24, "text": " So this is to say that we need to put an effort because that effort gets our reward in terms", "tokens": [407, 341, 307, 281, 584, 300, 321, 643, 281, 829, 364, 4630, 570, 300, 4630, 2170, 527, 7782, 294, 2115], "temperature": 0.0, "avg_logprob": -0.20525680371184848, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.00020504814165178686}, {"id": 44, "seek": 22044, "start": 236.24, "end": 241.16, "text": " of speed of development and speed of understanding.", "tokens": [295, 3073, 295, 3250, 293, 3073, 295, 3701, 13], "temperature": 0.0, "avg_logprob": -0.20525680371184848, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.00020504814165178686}, {"id": 45, "seek": 22044, "start": 241.16, "end": 249.12, "text": " So say that a disclaimer, not everything is black and white.", "tokens": [407, 584, 300, 257, 40896, 11, 406, 1203, 307, 2211, 293, 2418, 13], "temperature": 0.0, "avg_logprob": -0.20525680371184848, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.00020504814165178686}, {"id": 46, "seek": 24912, "start": 249.12, "end": 254.24, "text": " Of course, there might be exceptions to the suggestions that I'm going to say.", "tokens": [2720, 1164, 11, 456, 1062, 312, 22847, 281, 264, 13396, 300, 286, 478, 516, 281, 584, 13], "temperature": 0.0, "avg_logprob": -0.14150287486888743, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00021124309569131583}, {"id": 47, "seek": 24912, "start": 254.24, "end": 260.16, "text": " And this talk is more or less a collection of scattered robots that I collected from", "tokens": [400, 341, 751, 307, 544, 420, 1570, 257, 5765, 295, 21986, 14733, 300, 286, 11087, 490], "temperature": 0.0, "avg_logprob": -0.14150287486888743, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00021124309569131583}, {"id": 48, "seek": 24912, "start": 260.16, "end": 261.92, "text": " sources that I trust.", "tokens": [7139, 300, 286, 3361, 13], "temperature": 0.0, "avg_logprob": -0.14150287486888743, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00021124309569131583}, {"id": 49, "seek": 24912, "start": 261.92, "end": 268.92, "text": " So in case you don't like them, blame the sources.", "tokens": [407, 294, 1389, 291, 500, 380, 411, 552, 11, 10127, 264, 7139, 13], "temperature": 0.0, "avg_logprob": -0.14150287486888743, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00021124309569131583}, {"id": 50, "seek": 24912, "start": 268.92, "end": 276.12, "text": " In general, I think that the stuff that we write should take care of two sites.", "tokens": [682, 2674, 11, 286, 519, 300, 264, 1507, 300, 321, 2464, 820, 747, 1127, 295, 732, 7533, 13], "temperature": 0.0, "avg_logprob": -0.14150287486888743, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00021124309569131583}, {"id": 51, "seek": 27612, "start": 276.12, "end": 283.08, "text": " One is, of course, the implementation, and this implementation is pretty clear, I guess.", "tokens": [1485, 307, 11, 295, 1164, 11, 264, 11420, 11, 293, 341, 11420, 307, 1238, 1850, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.15497239122112977, "compression_ratio": 1.676595744680851, "no_speech_prob": 7.365208875853568e-05}, {"id": 52, "seek": 27612, "start": 283.08, "end": 285.44, "text": " This function is just doing the sum of two numbers.", "tokens": [639, 2445, 307, 445, 884, 264, 2408, 295, 732, 3547, 13], "temperature": 0.0, "avg_logprob": -0.15497239122112977, "compression_ratio": 1.676595744680851, "no_speech_prob": 7.365208875853568e-05}, {"id": 53, "seek": 27612, "start": 285.44, "end": 286.92, "text": " It's easy to understand.", "tokens": [467, 311, 1858, 281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.15497239122112977, "compression_ratio": 1.676595744680851, "no_speech_prob": 7.365208875853568e-05}, {"id": 54, "seek": 27612, "start": 286.92, "end": 288.68, "text": " We can't argue with that.", "tokens": [492, 393, 380, 9695, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.15497239122112977, "compression_ratio": 1.676595744680851, "no_speech_prob": 7.365208875853568e-05}, {"id": 55, "seek": 27612, "start": 288.68, "end": 294.48, "text": " But what if we land on a code base that is doing something like this, and this takes", "tokens": [583, 437, 498, 321, 2117, 322, 257, 3089, 3096, 300, 307, 884, 746, 411, 341, 11, 293, 341, 2516], "temperature": 0.0, "avg_logprob": -0.15497239122112977, "compression_ratio": 1.676595744680851, "no_speech_prob": 7.365208875853568e-05}, {"id": 56, "seek": 27612, "start": 294.48, "end": 303.6, "text": " more energy compared to a better version of it, where the function is named nicely.", "tokens": [544, 2281, 5347, 281, 257, 1101, 3037, 295, 309, 11, 689, 264, 2445, 307, 4926, 9594, 13], "temperature": 0.0, "avg_logprob": -0.15497239122112977, "compression_ratio": 1.676595744680851, "no_speech_prob": 7.365208875853568e-05}, {"id": 57, "seek": 27612, "start": 303.6, "end": 305.76, "text": " So we understand what it's doing.", "tokens": [407, 321, 1223, 437, 309, 311, 884, 13], "temperature": 0.0, "avg_logprob": -0.15497239122112977, "compression_ratio": 1.676595744680851, "no_speech_prob": 7.365208875853568e-05}, {"id": 58, "seek": 30576, "start": 305.76, "end": 310.08, "text": " This is to say, and this is something that is going to be a requirement in this talk,", "tokens": [639, 307, 281, 584, 11, 293, 341, 307, 746, 300, 307, 516, 281, 312, 257, 11695, 294, 341, 751, 11], "temperature": 0.0, "avg_logprob": -0.12667419396194757, "compression_ratio": 1.74235807860262, "no_speech_prob": 0.00010055131133412942}, {"id": 59, "seek": 30576, "start": 310.08, "end": 314.48, "text": " that what matters is not only how we care about the implementation, but also how we", "tokens": [300, 437, 7001, 307, 406, 787, 577, 321, 1127, 466, 264, 11420, 11, 457, 611, 577, 321], "temperature": 0.0, "avg_logprob": -0.12667419396194757, "compression_ratio": 1.74235807860262, "no_speech_prob": 0.00010055131133412942}, {"id": 60, "seek": 30576, "start": 314.48, "end": 321.28, "text": " care about the users of our packages, of our functions, of our objects.", "tokens": [1127, 466, 264, 5022, 295, 527, 17401, 11, 295, 527, 6828, 11, 295, 527, 6565, 13], "temperature": 0.0, "avg_logprob": -0.12667419396194757, "compression_ratio": 1.74235807860262, "no_speech_prob": 0.00010055131133412942}, {"id": 61, "seek": 30576, "start": 321.28, "end": 326.12, "text": " So let's start with the first item, which is the line of sight.", "tokens": [407, 718, 311, 722, 365, 264, 700, 3174, 11, 597, 307, 264, 1622, 295, 7860, 13], "temperature": 0.0, "avg_logprob": -0.12667419396194757, "compression_ratio": 1.74235807860262, "no_speech_prob": 0.00010055131133412942}, {"id": 62, "seek": 30576, "start": 326.12, "end": 330.59999999999997, "text": " And this is something that I believe every good and idiomatic code base should try to", "tokens": [400, 341, 307, 746, 300, 286, 1697, 633, 665, 293, 18014, 13143, 3089, 3096, 820, 853, 281], "temperature": 0.0, "avg_logprob": -0.12667419396194757, "compression_ratio": 1.74235807860262, "no_speech_prob": 0.00010055131133412942}, {"id": 63, "seek": 30576, "start": 330.59999999999997, "end": 331.59999999999997, "text": " foster.", "tokens": [17114, 13], "temperature": 0.0, "avg_logprob": -0.12667419396194757, "compression_ratio": 1.74235807860262, "no_speech_prob": 0.00010055131133412942}, {"id": 64, "seek": 33160, "start": 331.6, "end": 338.44, "text": " Basically, we have this leftmost indented line where all the happy path leaves, and we have", "tokens": [8537, 11, 321, 362, 341, 1411, 1761, 1016, 6003, 1622, 689, 439, 264, 2055, 3100, 5510, 11, 293, 321, 362], "temperature": 0.0, "avg_logprob": -0.2016382820998566, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.0003634634776972234}, {"id": 65, "seek": 33160, "start": 338.44, "end": 341.40000000000003, "text": " this indented one where we handle all the exceptions.", "tokens": [341, 1016, 6003, 472, 689, 321, 4813, 439, 264, 22847, 13], "temperature": 0.0, "avg_logprob": -0.2016382820998566, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.0003634634776972234}, {"id": 66, "seek": 33160, "start": 341.40000000000003, "end": 347.64000000000004, "text": " And I expect every code base, which is well written where I land to, to respect this rule.", "tokens": [400, 286, 2066, 633, 3089, 3096, 11, 597, 307, 731, 3720, 689, 286, 2117, 281, 11, 281, 3104, 341, 4978, 13], "temperature": 0.0, "avg_logprob": -0.2016382820998566, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.0003634634776972234}, {"id": 67, "seek": 33160, "start": 347.64000000000004, "end": 355.32000000000005, "text": " And there are a few tips to do this.", "tokens": [400, 456, 366, 257, 1326, 6082, 281, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.2016382820998566, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.0003634634776972234}, {"id": 68, "seek": 33160, "start": 355.32000000000005, "end": 359.84000000000003, "text": " It wasn't me.", "tokens": [467, 2067, 380, 385, 13], "temperature": 0.0, "avg_logprob": -0.2016382820998566, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.0003634634776972234}, {"id": 69, "seek": 35984, "start": 359.84, "end": 364.47999999999996, "text": " So these are just tips to do that, to implement this.", "tokens": [407, 613, 366, 445, 6082, 281, 360, 300, 11, 281, 4445, 341, 13], "temperature": 0.0, "avg_logprob": -0.13595244017514316, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.000616279081441462}, {"id": 70, "seek": 35984, "start": 364.47999999999996, "end": 368.44, "text": " And let's see why it matters, how it will make our code base better.", "tokens": [400, 718, 311, 536, 983, 309, 7001, 11, 577, 309, 486, 652, 527, 3089, 3096, 1101, 13], "temperature": 0.0, "avg_logprob": -0.13595244017514316, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.000616279081441462}, {"id": 71, "seek": 35984, "start": 368.44, "end": 374.4, "text": " This was more or less a real example that I got from a real PR, and it was really hard", "tokens": [639, 390, 544, 420, 1570, 257, 957, 1365, 300, 286, 658, 490, 257, 957, 11568, 11, 293, 309, 390, 534, 1152], "temperature": 0.0, "avg_logprob": -0.13595244017514316, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.000616279081441462}, {"id": 72, "seek": 35984, "start": 374.4, "end": 376.2, "text": " to follow all the special cases.", "tokens": [281, 1524, 439, 264, 2121, 3331, 13], "temperature": 0.0, "avg_logprob": -0.13595244017514316, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.000616279081441462}, {"id": 73, "seek": 35984, "start": 376.2, "end": 383.84, "text": " And so I tried to give feedback and try to hammer it with suggestions in order to leverage", "tokens": [400, 370, 286, 3031, 281, 976, 5824, 293, 853, 281, 13017, 309, 365, 13396, 294, 1668, 281, 13982], "temperature": 0.0, "avg_logprob": -0.13595244017514316, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.000616279081441462}, {"id": 74, "seek": 38384, "start": 383.84, "end": 392.88, "text": " early returns and flipping errors, removing else, when a CNL is something that I try to", "tokens": [2440, 11247, 293, 26886, 13603, 11, 12720, 1646, 11, 562, 257, 14589, 43, 307, 746, 300, 286, 853, 281], "temperature": 0.0, "avg_logprob": -0.2766583063831068, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0005813512834720314}, {"id": 75, "seek": 38384, "start": 392.88, "end": 393.88, "text": " get rid of.", "tokens": [483, 3973, 295, 13], "temperature": 0.0, "avg_logprob": -0.2766583063831068, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0005813512834720314}, {"id": 76, "seek": 38384, "start": 393.88, "end": 400.71999999999997, "text": " Like, it's a red flag, and I think three times before allowing it to go through.", "tokens": [1743, 11, 309, 311, 257, 2182, 7166, 11, 293, 286, 519, 1045, 1413, 949, 8293, 309, 281, 352, 807, 13], "temperature": 0.0, "avg_logprob": -0.2766583063831068, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0005813512834720314}, {"id": 77, "seek": 38384, "start": 400.71999999999997, "end": 410.0, "text": " And then leverage more returns and then, yeah, leverage more returns and then, sorry, yeah,", "tokens": [400, 550, 13982, 544, 11247, 293, 550, 11, 1338, 11, 13982, 544, 11247, 293, 550, 11, 2597, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.2766583063831068, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0005813512834720314}, {"id": 78, "seek": 41000, "start": 410.0, "end": 416.28, "text": " trapping into a function so we can leverage even more returns because now we have a smaller", "tokens": [944, 3759, 666, 257, 2445, 370, 321, 393, 13982, 754, 544, 11247, 570, 586, 321, 362, 257, 4356], "temperature": 0.0, "avg_logprob": -0.2086303017356179, "compression_ratio": 1.6650485436893203, "no_speech_prob": 5.639765004161745e-05}, {"id": 79, "seek": 41000, "start": 416.28, "end": 417.28, "text": " scope.", "tokens": [11923, 13], "temperature": 0.0, "avg_logprob": -0.2086303017356179, "compression_ratio": 1.6650485436893203, "no_speech_prob": 5.639765004161745e-05}, {"id": 80, "seek": 41000, "start": 417.28, "end": 423.56, "text": " So we got to something from something which looked like this to something that looked", "tokens": [407, 321, 658, 281, 746, 490, 746, 597, 2956, 411, 341, 281, 746, 300, 2956], "temperature": 0.0, "avg_logprob": -0.2086303017356179, "compression_ratio": 1.6650485436893203, "no_speech_prob": 5.639765004161745e-05}, {"id": 81, "seek": 41000, "start": 423.56, "end": 424.72, "text": " like this.", "tokens": [411, 341, 13], "temperature": 0.0, "avg_logprob": -0.2086303017356179, "compression_ratio": 1.6650485436893203, "no_speech_prob": 5.639765004161745e-05}, {"id": 82, "seek": 41000, "start": 424.72, "end": 428.44, "text": " And I dare you to say that this is easier to understand.", "tokens": [400, 286, 8955, 291, 281, 584, 300, 341, 307, 3571, 281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.2086303017356179, "compression_ratio": 1.6650485436893203, "no_speech_prob": 5.639765004161745e-05}, {"id": 83, "seek": 41000, "start": 428.44, "end": 433.72, "text": " And remember, like, this is understandable, but this requires a lot of energy.", "tokens": [400, 1604, 11, 411, 11, 341, 307, 25648, 11, 457, 341, 7029, 257, 688, 295, 2281, 13], "temperature": 0.0, "avg_logprob": -0.2086303017356179, "compression_ratio": 1.6650485436893203, "no_speech_prob": 5.639765004161745e-05}, {"id": 84, "seek": 41000, "start": 433.72, "end": 434.72, "text": " It's clear.", "tokens": [467, 311, 1850, 13], "temperature": 0.0, "avg_logprob": -0.2086303017356179, "compression_ratio": 1.6650485436893203, "no_speech_prob": 5.639765004161745e-05}, {"id": 85, "seek": 43472, "start": 434.72, "end": 440.08000000000004, "text": " It's better because of all the reasons that I already said before.", "tokens": [467, 311, 1101, 570, 295, 439, 264, 4112, 300, 286, 1217, 848, 949, 13], "temperature": 0.0, "avg_logprob": -0.2058148701985677, "compression_ratio": 1.5402843601895735, "no_speech_prob": 0.00018521994934417307}, {"id": 86, "seek": 43472, "start": 440.08000000000004, "end": 445.28000000000003, "text": " There is this nice blog post from Matt Ryder about this very same topic.", "tokens": [821, 307, 341, 1481, 6968, 2183, 490, 7397, 13654, 1068, 466, 341, 588, 912, 4829, 13], "temperature": 0.0, "avg_logprob": -0.2058148701985677, "compression_ratio": 1.5402843601895735, "no_speech_prob": 0.00018521994934417307}, {"id": 87, "seek": 43472, "start": 445.28000000000003, "end": 449.76000000000005, "text": " He more or less gives the same set of advices.", "tokens": [634, 544, 420, 1570, 2709, 264, 912, 992, 295, 1551, 1473, 13], "temperature": 0.0, "avg_logprob": -0.2058148701985677, "compression_ratio": 1.5402843601895735, "no_speech_prob": 0.00018521994934417307}, {"id": 88, "seek": 43472, "start": 449.76000000000005, "end": 452.16, "text": " Linocyte is not a nice exercise.", "tokens": [9355, 31078, 975, 307, 406, 257, 1481, 5380, 13], "temperature": 0.0, "avg_logprob": -0.2058148701985677, "compression_ratio": 1.5402843601895735, "no_speech_prob": 0.00018521994934417307}, {"id": 89, "seek": 43472, "start": 452.16, "end": 458.96000000000004, "text": " It's a rule of thumb that allows us to untangle our code and to make it slicker and easier", "tokens": [467, 311, 257, 4978, 295, 9298, 300, 4045, 505, 281, 1701, 7846, 527, 3089, 293, 281, 652, 309, 1061, 33804, 293, 3571], "temperature": 0.0, "avg_logprob": -0.2058148701985677, "compression_ratio": 1.5402843601895735, "no_speech_prob": 0.00018521994934417307}, {"id": 90, "seek": 43472, "start": 458.96000000000004, "end": 461.68, "text": " to understand.", "tokens": [281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.2058148701985677, "compression_ratio": 1.5402843601895735, "no_speech_prob": 0.00018521994934417307}, {"id": 91, "seek": 46168, "start": 461.68, "end": 464.96, "text": " Next I'm going to talk about package names.", "tokens": [3087, 286, 478, 516, 281, 751, 466, 7372, 5288, 13], "temperature": 0.0, "avg_logprob": -0.11380879471941692, "compression_ratio": 1.6748768472906403, "no_speech_prob": 8.03843722678721e-05}, {"id": 92, "seek": 46168, "start": 464.96, "end": 470.72, "text": " This is another favorite of mine.", "tokens": [639, 307, 1071, 2954, 295, 3892, 13], "temperature": 0.0, "avg_logprob": -0.11380879471941692, "compression_ratio": 1.6748768472906403, "no_speech_prob": 8.03843722678721e-05}, {"id": 93, "seek": 46168, "start": 470.72, "end": 478.08, "text": " We know that naming is hard, and that is particularly true in case of package names.", "tokens": [492, 458, 300, 25290, 307, 1152, 11, 293, 300, 307, 4098, 2074, 294, 1389, 295, 7372, 5288, 13], "temperature": 0.0, "avg_logprob": -0.11380879471941692, "compression_ratio": 1.6748768472906403, "no_speech_prob": 8.03843722678721e-05}, {"id": 94, "seek": 46168, "start": 478.08, "end": 484.44, "text": " We know that the name of a package should be small enough because that is consuming", "tokens": [492, 458, 300, 264, 1315, 295, 257, 7372, 820, 312, 1359, 1547, 570, 300, 307, 19867], "temperature": 0.0, "avg_logprob": -0.11380879471941692, "compression_ratio": 1.6748768472906403, "no_speech_prob": 8.03843722678721e-05}, {"id": 95, "seek": 46168, "start": 484.44, "end": 491.12, "text": " screen space, but should be also good enough to let us understand the purpose of the package.", "tokens": [2568, 1901, 11, 457, 820, 312, 611, 665, 1547, 281, 718, 505, 1223, 264, 4334, 295, 264, 7372, 13], "temperature": 0.0, "avg_logprob": -0.11380879471941692, "compression_ratio": 1.6748768472906403, "no_speech_prob": 8.03843722678721e-05}, {"id": 96, "seek": 49112, "start": 491.12, "end": 496.8, "text": " In Go there is even more because when we use an object, the name of the package is part", "tokens": [682, 1037, 456, 307, 754, 544, 570, 562, 321, 764, 364, 2657, 11, 264, 1315, 295, 264, 7372, 307, 644], "temperature": 0.0, "avg_logprob": -0.1765687863032023, "compression_ratio": 1.6905829596412556, "no_speech_prob": 5.7061537518166006e-05}, {"id": 97, "seek": 49112, "start": 496.8, "end": 497.8, "text": " of the name.", "tokens": [295, 264, 1315, 13], "temperature": 0.0, "avg_logprob": -0.1765687863032023, "compression_ratio": 1.6905829596412556, "no_speech_prob": 5.7061537518166006e-05}, {"id": 98, "seek": 49112, "start": 497.8, "end": 505.72, "text": " So that is an opportunity for us to put some value in that part that the reader can consume.", "tokens": [407, 300, 307, 364, 2650, 337, 505, 281, 829, 512, 2158, 294, 300, 644, 300, 264, 15149, 393, 14732, 13], "temperature": 0.0, "avg_logprob": -0.1765687863032023, "compression_ratio": 1.6905829596412556, "no_speech_prob": 5.7061537518166006e-05}, {"id": 99, "seek": 49112, "start": 505.72, "end": 508.52, "text": " And again, I'm starting with a bad example.", "tokens": [400, 797, 11, 286, 478, 2891, 365, 257, 1578, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1765687863032023, "compression_ratio": 1.6905829596412556, "no_speech_prob": 5.7061537518166006e-05}, {"id": 100, "seek": 49112, "start": 508.52, "end": 515.6, "text": " We have this utility package, and we have this copy node function that is totally fictional,", "tokens": [492, 362, 341, 14877, 7372, 11, 293, 321, 362, 341, 5055, 9984, 2445, 300, 307, 3879, 28911, 11], "temperature": 0.0, "avg_logprob": -0.1765687863032023, "compression_ratio": 1.6905829596412556, "no_speech_prob": 5.7061537518166006e-05}, {"id": 101, "seek": 49112, "start": 515.6, "end": 518.72, "text": " but that utility part is a wasted opportunity.", "tokens": [457, 300, 14877, 644, 307, 257, 19496, 2650, 13], "temperature": 0.0, "avg_logprob": -0.1765687863032023, "compression_ratio": 1.6905829596412556, "no_speech_prob": 5.7061537518166006e-05}, {"id": 102, "seek": 51872, "start": 518.72, "end": 521.6800000000001, "text": " It's part of the name that doesn't add any value.", "tokens": [467, 311, 644, 295, 264, 1315, 300, 1177, 380, 909, 604, 2158, 13], "temperature": 0.0, "avg_logprob": -0.1603699485854347, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.888973515131511e-05}, {"id": 103, "seek": 51872, "start": 521.6800000000001, "end": 529.72, "text": " So it's better to take and split our package, smaller scoped packages that do and explain", "tokens": [407, 309, 311, 1101, 281, 747, 293, 7472, 527, 7372, 11, 4356, 795, 27277, 17401, 300, 360, 293, 2903], "temperature": 0.0, "avg_logprob": -0.1603699485854347, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.888973515131511e-05}, {"id": 104, "seek": 51872, "start": 529.72, "end": 530.72, "text": " what to do.", "tokens": [437, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.1603699485854347, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.888973515131511e-05}, {"id": 105, "seek": 51872, "start": 530.72, "end": 536.88, "text": " And in this case, from the colon side, you have node.copy, which still explains the purpose", "tokens": [400, 294, 341, 1389, 11, 490, 264, 8255, 1252, 11, 291, 362, 9984, 13, 13084, 88, 11, 597, 920, 13948, 264, 4334], "temperature": 0.0, "avg_logprob": -0.1603699485854347, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.888973515131511e-05}, {"id": 106, "seek": 51872, "start": 536.88, "end": 540.48, "text": " of the function, and it's not wasting space.", "tokens": [295, 264, 2445, 11, 293, 309, 311, 406, 20457, 1901, 13], "temperature": 0.0, "avg_logprob": -0.1603699485854347, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.888973515131511e-05}, {"id": 107, "seek": 51872, "start": 540.48, "end": 547.0400000000001, "text": " And this was taken from the official Go blog, and it says basically the same thing.", "tokens": [400, 341, 390, 2726, 490, 264, 4783, 1037, 6968, 11, 293, 309, 1619, 1936, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.1603699485854347, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.888973515131511e-05}, {"id": 108, "seek": 54704, "start": 547.04, "end": 553.88, "text": " There is no need to have these gigantic kitchen sink packages where we throw everything because", "tokens": [821, 307, 572, 643, 281, 362, 613, 26800, 6525, 9500, 17401, 689, 321, 3507, 1203, 570], "temperature": 0.0, "avg_logprob": -0.15328474967710434, "compression_ratio": 1.447674418604651, "no_speech_prob": 8.765578968450427e-05}, {"id": 109, "seek": 54704, "start": 553.88, "end": 555.52, "text": " in Go packages are free.", "tokens": [294, 1037, 17401, 366, 1737, 13], "temperature": 0.0, "avg_logprob": -0.15328474967710434, "compression_ratio": 1.447674418604651, "no_speech_prob": 8.765578968450427e-05}, {"id": 110, "seek": 54704, "start": 555.52, "end": 562.64, "text": " So it's fine to split them in a better way.", "tokens": [407, 309, 311, 2489, 281, 7472, 552, 294, 257, 1101, 636, 13], "temperature": 0.0, "avg_logprob": -0.15328474967710434, "compression_ratio": 1.447674418604651, "no_speech_prob": 8.765578968450427e-05}, {"id": 111, "seek": 54704, "start": 562.64, "end": 571.24, "text": " Next one is going to be about errors, and I see also this happening very frequently.", "tokens": [3087, 472, 307, 516, 281, 312, 466, 13603, 11, 293, 286, 536, 611, 341, 2737, 588, 10374, 13], "temperature": 0.0, "avg_logprob": -0.15328474967710434, "compression_ratio": 1.447674418604651, "no_speech_prob": 8.765578968450427e-05}, {"id": 112, "seek": 57124, "start": 571.24, "end": 577.48, "text": " In Go, errors are types, and let's say that the developer wants to handle a special error.", "tokens": [682, 1037, 11, 13603, 366, 3467, 11, 293, 718, 311, 584, 300, 264, 10754, 2738, 281, 4813, 257, 2121, 6713, 13], "temperature": 0.0, "avg_logprob": -0.1605676202213063, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.0002569742500782013}, {"id": 113, "seek": 57124, "start": 577.48, "end": 581.24, "text": " And the problem with these approaches is that we are giving away the fact that errors are", "tokens": [400, 264, 1154, 365, 613, 11587, 307, 300, 321, 366, 2902, 1314, 264, 1186, 300, 13603, 366], "temperature": 0.0, "avg_logprob": -0.1605676202213063, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.0002569742500782013}, {"id": 114, "seek": 57124, "start": 581.24, "end": 586.72, "text": " types, and we are converting them to a string, and we are treating them as a string.", "tokens": [3467, 11, 293, 321, 366, 29942, 552, 281, 257, 6798, 11, 293, 321, 366, 15083, 552, 382, 257, 6798, 13], "temperature": 0.0, "avg_logprob": -0.1605676202213063, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.0002569742500782013}, {"id": 115, "seek": 57124, "start": 586.72, "end": 592.08, "text": " And since Go 1.13, we have, like, and there are, like, that's legacy.", "tokens": [400, 1670, 1037, 502, 13, 7668, 11, 321, 362, 11, 411, 11, 293, 456, 366, 11, 411, 11, 300, 311, 11711, 13], "temperature": 0.0, "avg_logprob": -0.1605676202213063, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.0002569742500782013}, {"id": 116, "seek": 57124, "start": 592.08, "end": 595.96, "text": " So there are no excuses not to use this.", "tokens": [407, 456, 366, 572, 24666, 406, 281, 764, 341, 13], "temperature": 0.0, "avg_logprob": -0.1605676202213063, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.0002569742500782013}, {"id": 117, "seek": 59596, "start": 595.96, "end": 601.36, "text": " There are two ways, one is to assert that the error that we are checking is an instance", "tokens": [821, 366, 732, 2098, 11, 472, 307, 281, 19810, 300, 264, 6713, 300, 321, 366, 8568, 307, 364, 5197], "temperature": 0.0, "avg_logprob": -0.13072121143341064, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.0002325015520909801}, {"id": 118, "seek": 59596, "start": 601.36, "end": 610.72, "text": " of a given object that we have somewhere, and there is another, sorry, this is new because", "tokens": [295, 257, 2212, 2657, 300, 321, 362, 4079, 11, 293, 456, 307, 1071, 11, 2597, 11, 341, 307, 777, 570], "temperature": 0.0, "avg_logprob": -0.13072121143341064, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.0002325015520909801}, {"id": 119, "seek": 59596, "start": 610.72, "end": 613.5600000000001, "text": " the other one wasn't working.", "tokens": [264, 661, 472, 2067, 380, 1364, 13], "temperature": 0.0, "avg_logprob": -0.13072121143341064, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.0002325015520909801}, {"id": 120, "seek": 59596, "start": 613.5600000000001, "end": 620.24, "text": " And there is another one, which is about asserting that the error that we want to handle implements", "tokens": [400, 456, 307, 1071, 472, 11, 597, 307, 466, 1256, 27187, 300, 264, 6713, 300, 321, 528, 281, 4813, 704, 17988], "temperature": 0.0, "avg_logprob": -0.13072121143341064, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.0002325015520909801}, {"id": 121, "seek": 59596, "start": 620.24, "end": 625.88, "text": " the error interface against a specific real type.", "tokens": [264, 6713, 9226, 1970, 257, 2685, 957, 2010, 13], "temperature": 0.0, "avg_logprob": -0.13072121143341064, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.0002325015520909801}, {"id": 122, "seek": 62588, "start": 625.88, "end": 627.0, "text": " But there is more.", "tokens": [583, 456, 307, 544, 13], "temperature": 0.0, "avg_logprob": -0.146102927196985, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.00011890775931533426}, {"id": 123, "seek": 62588, "start": 627.0, "end": 633.8, "text": " So in this way, you can have wraps of errors, and you can assert that the error that you", "tokens": [407, 294, 341, 636, 11, 291, 393, 362, 25831, 295, 13603, 11, 293, 291, 393, 19810, 300, 264, 6713, 300, 291], "temperature": 0.0, "avg_logprob": -0.146102927196985, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.00011890775931533426}, {"id": 124, "seek": 62588, "start": 633.8, "end": 641.24, "text": " are checking not only equals the one that you are handling, but also any error inside", "tokens": [366, 8568, 406, 787, 6915, 264, 472, 300, 291, 366, 13175, 11, 457, 611, 604, 6713, 1854], "temperature": 0.0, "avg_logprob": -0.146102927196985, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.00011890775931533426}, {"id": 125, "seek": 62588, "start": 641.24, "end": 642.24, "text": " this wrap.", "tokens": [341, 7019, 13], "temperature": 0.0, "avg_logprob": -0.146102927196985, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.00011890775931533426}, {"id": 126, "seek": 62588, "start": 642.24, "end": 643.76, "text": " And this is how you wrap them.", "tokens": [400, 341, 307, 577, 291, 7019, 552, 13], "temperature": 0.0, "avg_logprob": -0.146102927196985, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.00011890775931533426}, {"id": 127, "seek": 62588, "start": 643.76, "end": 652.32, "text": " You can either use errors.wrap, so the return error from this function will contain the", "tokens": [509, 393, 2139, 764, 13603, 13, 86, 4007, 11, 370, 264, 2736, 6713, 490, 341, 2445, 486, 5304, 264], "temperature": 0.0, "avg_logprob": -0.146102927196985, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.00011890775931533426}, {"id": 128, "seek": 65232, "start": 652.32, "end": 661.0, "text": " value returned by this, but will also return true if we assert against the wrapped one.", "tokens": [2158, 8752, 538, 341, 11, 457, 486, 611, 2736, 2074, 498, 321, 19810, 1970, 264, 14226, 472, 13], "temperature": 0.0, "avg_logprob": -0.22945201808008656, "compression_ratio": 1.5231788079470199, "no_speech_prob": 6.557390588568524e-05}, {"id": 129, "seek": 65232, "start": 661.0, "end": 668.72, "text": " And also there is the way suggested by the standard library, which is using the %w formators.", "tokens": [400, 611, 456, 307, 264, 636, 10945, 538, 264, 3832, 6405, 11, 597, 307, 1228, 264, 14189, 86, 7877, 830, 13], "temperature": 0.0, "avg_logprob": -0.22945201808008656, "compression_ratio": 1.5231788079470199, "no_speech_prob": 6.557390588568524e-05}, {"id": 130, "seek": 65232, "start": 668.72, "end": 674.0, "text": " So both of them will return you a wrapped error.", "tokens": [407, 1293, 295, 552, 486, 2736, 291, 257, 14226, 6713, 13], "temperature": 0.0, "avg_logprob": -0.22945201808008656, "compression_ratio": 1.5231788079470199, "no_speech_prob": 6.557390588568524e-05}, {"id": 131, "seek": 67400, "start": 674.0, "end": 682.64, "text": " So now let's talk about pure functions and why they are important.", "tokens": [407, 586, 718, 311, 751, 466, 6075, 6828, 293, 983, 436, 366, 1021, 13], "temperature": 0.0, "avg_logprob": -0.0970165293703797, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.034971294051502e-05}, {"id": 132, "seek": 67400, "start": 682.64, "end": 685.12, "text": " So a pure function has two properties.", "tokens": [407, 257, 6075, 2445, 575, 732, 7221, 13], "temperature": 0.0, "avg_logprob": -0.0970165293703797, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.034971294051502e-05}, {"id": 133, "seek": 67400, "start": 685.12, "end": 690.4, "text": " One is the fact that no matter how time, when you call it, no matter how many times you", "tokens": [1485, 307, 264, 1186, 300, 572, 1871, 577, 565, 11, 562, 291, 818, 309, 11, 572, 1871, 577, 867, 1413, 291], "temperature": 0.0, "avg_logprob": -0.0970165293703797, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.034971294051502e-05}, {"id": 134, "seek": 67400, "start": 690.4, "end": 698.0, "text": " call it, with a given set of input parameters, it will return always the same output.", "tokens": [818, 309, 11, 365, 257, 2212, 992, 295, 4846, 9834, 11, 309, 486, 2736, 1009, 264, 912, 5598, 13], "temperature": 0.0, "avg_logprob": -0.0970165293703797, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.034971294051502e-05}, {"id": 135, "seek": 67400, "start": 698.0, "end": 703.2, "text": " And the other property is the fact that it shouldn't rely on the state of your system.", "tokens": [400, 264, 661, 4707, 307, 264, 1186, 300, 309, 4659, 380, 10687, 322, 264, 1785, 295, 428, 1185, 13], "temperature": 0.0, "avg_logprob": -0.0970165293703797, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.034971294051502e-05}, {"id": 136, "seek": 70320, "start": 703.2, "end": 707.0400000000001, "text": " It shouldn't modify the state of the system.", "tokens": [467, 4659, 380, 16927, 264, 1785, 295, 264, 1185, 13], "temperature": 0.0, "avg_logprob": -0.1693071867290296, "compression_ratio": 1.7477477477477477, "no_speech_prob": 4.227922181598842e-05}, {"id": 137, "seek": 70320, "start": 707.0400000000001, "end": 713.12, "text": " Should it be global variables or static variables or your input parameters or anything that", "tokens": [6454, 309, 312, 4338, 9102, 420, 13437, 9102, 420, 428, 4846, 9834, 420, 1340, 300], "temperature": 0.0, "avg_logprob": -0.1693071867290296, "compression_ratio": 1.7477477477477477, "no_speech_prob": 4.227922181598842e-05}, {"id": 138, "seek": 70320, "start": 713.12, "end": 715.2, "text": " is external to the function.", "tokens": [307, 8320, 281, 264, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1693071867290296, "compression_ratio": 1.7477477477477477, "no_speech_prob": 4.227922181598842e-05}, {"id": 139, "seek": 70320, "start": 715.2, "end": 717.88, "text": " And why it matters.", "tokens": [400, 983, 309, 7001, 13], "temperature": 0.0, "avg_logprob": -0.1693071867290296, "compression_ratio": 1.7477477477477477, "no_speech_prob": 4.227922181598842e-05}, {"id": 140, "seek": 70320, "start": 717.88, "end": 724.0400000000001, "text": " This is an example where the behavior of this function depends on the state of an external", "tokens": [639, 307, 364, 1365, 689, 264, 5223, 295, 341, 2445, 5946, 322, 264, 1785, 295, 364, 8320], "temperature": 0.0, "avg_logprob": -0.1693071867290296, "compression_ratio": 1.7477477477477477, "no_speech_prob": 4.227922181598842e-05}, {"id": 141, "seek": 70320, "start": 724.0400000000001, "end": 727.6, "text": " system that is accessed through a client.", "tokens": [1185, 300, 307, 34211, 807, 257, 6423, 13], "temperature": 0.0, "avg_logprob": -0.1693071867290296, "compression_ratio": 1.7477477477477477, "no_speech_prob": 4.227922181598842e-05}, {"id": 142, "seek": 70320, "start": 727.6, "end": 730.6800000000001, "text": " And then you have the business logic after that.", "tokens": [400, 550, 291, 362, 264, 1606, 9952, 934, 300, 13], "temperature": 0.0, "avg_logprob": -0.1693071867290296, "compression_ratio": 1.7477477477477477, "no_speech_prob": 4.227922181598842e-05}, {"id": 143, "seek": 70320, "start": 730.6800000000001, "end": 732.0, "text": " And why this is bad.", "tokens": [400, 983, 341, 307, 1578, 13], "temperature": 0.0, "avg_logprob": -0.1693071867290296, "compression_ratio": 1.7477477477477477, "no_speech_prob": 4.227922181598842e-05}, {"id": 144, "seek": 73200, "start": 732.0, "end": 738.28, "text": " I would say that mostly because this is hard to test or we can mock the external system,", "tokens": [286, 576, 584, 300, 5240, 570, 341, 307, 1152, 281, 1500, 420, 321, 393, 17362, 264, 8320, 1185, 11], "temperature": 0.0, "avg_logprob": -0.15122851053873698, "compression_ratio": 1.6582914572864322, "no_speech_prob": 0.00013115412730257958}, {"id": 145, "seek": 73200, "start": 738.28, "end": 747.36, "text": " we can do tricks to replace the client, but moving away the statefulness part of the function", "tokens": [321, 393, 360, 11733, 281, 7406, 264, 6423, 11, 457, 2684, 1314, 264, 1785, 26872, 644, 295, 264, 2445], "temperature": 0.0, "avg_logprob": -0.15122851053873698, "compression_ratio": 1.6582914572864322, "no_speech_prob": 0.00013115412730257958}, {"id": 146, "seek": 73200, "start": 747.36, "end": 755.8, "text": " away and having the business logic implemented as a pure function will allow us to be quicker", "tokens": [1314, 293, 1419, 264, 1606, 9952, 12270, 382, 257, 6075, 2445, 486, 2089, 505, 281, 312, 16255], "temperature": 0.0, "avg_logprob": -0.15122851053873698, "compression_ratio": 1.6582914572864322, "no_speech_prob": 0.00013115412730257958}, {"id": 147, "seek": 73200, "start": 755.8, "end": 759.04, "text": " in writing the implementation and to write our tests.", "tokens": [294, 3579, 264, 11420, 293, 281, 2464, 527, 6921, 13], "temperature": 0.0, "avg_logprob": -0.15122851053873698, "compression_ratio": 1.6582914572864322, "no_speech_prob": 0.00013115412730257958}, {"id": 148, "seek": 75904, "start": 759.04, "end": 762.4, "text": " And how about the second part.", "tokens": [400, 577, 466, 264, 1150, 644, 13], "temperature": 0.0, "avg_logprob": -0.12960801521937051, "compression_ratio": 1.7387387387387387, "no_speech_prob": 7.703872688580304e-05}, {"id": 149, "seek": 75904, "start": 762.4, "end": 771.5999999999999, "text": " So we have a function that accepts a pointer and in some random cases it changes the object.", "tokens": [407, 321, 362, 257, 2445, 300, 33538, 257, 23918, 293, 294, 512, 4974, 3331, 309, 2962, 264, 2657, 13], "temperature": 0.0, "avg_logprob": -0.12960801521937051, "compression_ratio": 1.7387387387387387, "no_speech_prob": 7.703872688580304e-05}, {"id": 150, "seek": 75904, "start": 771.5999999999999, "end": 773.0799999999999, "text": " And what's the problem with that?", "tokens": [400, 437, 311, 264, 1154, 365, 300, 30], "temperature": 0.0, "avg_logprob": -0.12960801521937051, "compression_ratio": 1.7387387387387387, "no_speech_prob": 7.703872688580304e-05}, {"id": 151, "seek": 75904, "start": 773.0799999999999, "end": 777.1999999999999, "text": " The problem with that is now on the reading side because you don't know that it's not", "tokens": [440, 1154, 365, 300, 307, 586, 322, 264, 3760, 1252, 570, 291, 500, 380, 458, 300, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.12960801521937051, "compression_ratio": 1.7387387387387387, "no_speech_prob": 7.703872688580304e-05}, {"id": 152, "seek": 75904, "start": 777.1999999999999, "end": 779.76, "text": " clear enough that this function is changing the node.", "tokens": [1850, 1547, 300, 341, 2445, 307, 4473, 264, 9984, 13], "temperature": 0.0, "avg_logprob": -0.12960801521937051, "compression_ratio": 1.7387387387387387, "no_speech_prob": 7.703872688580304e-05}, {"id": 153, "seek": 75904, "start": 779.76, "end": 786.0799999999999, "text": " So you get your bug report and you look at the code and you know that somewhere the name", "tokens": [407, 291, 483, 428, 7426, 2275, 293, 291, 574, 412, 264, 3089, 293, 291, 458, 300, 4079, 264, 1315], "temperature": 0.0, "avg_logprob": -0.12960801521937051, "compression_ratio": 1.7387387387387387, "no_speech_prob": 7.703872688580304e-05}, {"id": 154, "seek": 78608, "start": 786.08, "end": 789.12, "text": " of the node changed, but you don't know why.", "tokens": [295, 264, 9984, 3105, 11, 457, 291, 500, 380, 458, 983, 13], "temperature": 0.0, "avg_logprob": -0.15117912942712958, "compression_ratio": 1.675, "no_speech_prob": 6.896603008499369e-05}, {"id": 155, "seek": 78608, "start": 789.12, "end": 797.24, "text": " And that's because it's not clear from outside that is what this function is doing and it's", "tokens": [400, 300, 311, 570, 309, 311, 406, 1850, 490, 2380, 300, 307, 437, 341, 2445, 307, 884, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.15117912942712958, "compression_ratio": 1.675, "no_speech_prob": 6.896603008499369e-05}, {"id": 156, "seek": 78608, "start": 797.24, "end": 799.5200000000001, "text": " harder to reason about it.", "tokens": [6081, 281, 1778, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.15117912942712958, "compression_ratio": 1.675, "no_speech_prob": 6.896603008499369e-05}, {"id": 157, "seek": 78608, "start": 799.5200000000001, "end": 807.5600000000001, "text": " So a better way is to change the name of the function so it's clear, but I think that", "tokens": [407, 257, 1101, 636, 307, 281, 1319, 264, 1315, 295, 264, 2445, 370, 309, 311, 1850, 11, 457, 286, 519, 300], "temperature": 0.0, "avg_logprob": -0.15117912942712958, "compression_ratio": 1.675, "no_speech_prob": 6.896603008499369e-05}, {"id": 158, "seek": 78608, "start": 807.5600000000001, "end": 815.32, "text": " and this comes quite often, a better way to do that is to delegate the responsibility", "tokens": [293, 341, 1487, 1596, 2049, 11, 257, 1101, 636, 281, 360, 300, 307, 281, 40999, 264, 6357], "temperature": 0.0, "avg_logprob": -0.15117912942712958, "compression_ratio": 1.675, "no_speech_prob": 6.896603008499369e-05}, {"id": 159, "seek": 81532, "start": 815.32, "end": 819.24, "text": " of changing the object outside and changing the function to be a pure function.", "tokens": [295, 4473, 264, 2657, 2380, 293, 4473, 264, 2445, 281, 312, 257, 6075, 2445, 13], "temperature": 0.0, "avg_logprob": -0.14839645794459752, "compression_ratio": 1.7184466019417475, "no_speech_prob": 6.664618558716029e-05}, {"id": 160, "seek": 81532, "start": 819.24, "end": 826.32, "text": " Again this version is easier to understand, it's easier to reason about, it's clear when", "tokens": [3764, 341, 3037, 307, 3571, 281, 1223, 11, 309, 311, 3571, 281, 1778, 466, 11, 309, 311, 1850, 562], "temperature": 0.0, "avg_logprob": -0.14839645794459752, "compression_ratio": 1.7184466019417475, "no_speech_prob": 6.664618558716029e-05}, {"id": 161, "seek": 81532, "start": 826.32, "end": 829.32, "text": " you will have something to change.", "tokens": [291, 486, 362, 746, 281, 1319, 13], "temperature": 0.0, "avg_logprob": -0.14839645794459752, "compression_ratio": 1.7184466019417475, "no_speech_prob": 6.664618558716029e-05}, {"id": 162, "seek": 81532, "start": 829.32, "end": 833.6800000000001, "text": " And this can also say about environment variables.", "tokens": [400, 341, 393, 611, 584, 466, 2823, 9102, 13], "temperature": 0.0, "avg_logprob": -0.14839645794459752, "compression_ratio": 1.7184466019417475, "no_speech_prob": 6.664618558716029e-05}, {"id": 163, "seek": 81532, "start": 833.6800000000001, "end": 840.84, "text": " In the world of pods and containers, adding a new knob as an environment variable is so", "tokens": [682, 264, 1002, 295, 31925, 293, 17089, 11, 5127, 257, 777, 26759, 382, 364, 2823, 7006, 307, 370], "temperature": 0.0, "avg_logprob": -0.14839645794459752, "compression_ratio": 1.7184466019417475, "no_speech_prob": 6.664618558716029e-05}, {"id": 164, "seek": 81532, "start": 840.84, "end": 841.84, "text": " convenient.", "tokens": [10851, 13], "temperature": 0.0, "avg_logprob": -0.14839645794459752, "compression_ratio": 1.7184466019417475, "no_speech_prob": 6.664618558716029e-05}, {"id": 165, "seek": 84184, "start": 841.84, "end": 846.24, "text": " Just add an environment variable, you consume it from the function where you need it and", "tokens": [1449, 909, 364, 2823, 7006, 11, 291, 14732, 309, 490, 264, 2445, 689, 291, 643, 309, 293], "temperature": 0.0, "avg_logprob": -0.19333274023873465, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.00010701730207074434}, {"id": 166, "seek": 84184, "start": 846.24, "end": 847.4, "text": " you are done.", "tokens": [291, 366, 1096, 13], "temperature": 0.0, "avg_logprob": -0.19333274023873465, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.00010701730207074434}, {"id": 167, "seek": 84184, "start": 847.4, "end": 852.5600000000001, "text": " But the problem with that is that you then don't have control anymore on all the knobs", "tokens": [583, 264, 1154, 365, 300, 307, 300, 291, 550, 500, 380, 362, 1969, 3602, 322, 439, 264, 46999], "temperature": 0.0, "avg_logprob": -0.19333274023873465, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.00010701730207074434}, {"id": 168, "seek": 84184, "start": 852.5600000000001, "end": 859.52, "text": " on all the parameters that your program is consuming because they are all scattered across", "tokens": [322, 439, 264, 9834, 300, 428, 1461, 307, 19867, 570, 436, 366, 439, 21986, 2108], "temperature": 0.0, "avg_logprob": -0.19333274023873465, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.00010701730207074434}, {"id": 169, "seek": 84184, "start": 859.52, "end": 868.52, "text": " the code base and that is bad because you can't foresee what a given function is doing", "tokens": [264, 3089, 3096, 293, 300, 307, 1578, 570, 291, 393, 380, 38736, 437, 257, 2212, 2445, 307, 884], "temperature": 0.0, "avg_logprob": -0.19333274023873465, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.00010701730207074434}, {"id": 170, "seek": 86852, "start": 868.52, "end": 873.0799999999999, "text": " by reading its calling site.", "tokens": [538, 3760, 1080, 5141, 3621, 13], "temperature": 0.0, "avg_logprob": -0.19896000309994347, "compression_ratio": 1.5123456790123457, "no_speech_prob": 0.00010145960550289601}, {"id": 171, "seek": 86852, "start": 873.0799999999999, "end": 878.52, "text": " So again, this is something that should be avoided, environment variables should be read", "tokens": [407, 797, 11, 341, 307, 746, 300, 820, 312, 24890, 11, 2823, 9102, 820, 312, 1401], "temperature": 0.0, "avg_logprob": -0.19896000309994347, "compression_ratio": 1.5123456790123457, "no_speech_prob": 0.00010145960550289601}, {"id": 172, "seek": 86852, "start": 878.52, "end": 889.52, "text": " in your main functions and then be propagated through all the stacks.", "tokens": [294, 428, 2135, 6828, 293, 550, 312, 12425, 770, 807, 439, 264, 30792, 13], "temperature": 0.0, "avg_logprob": -0.19896000309994347, "compression_ratio": 1.5123456790123457, "no_speech_prob": 0.00010145960550289601}, {"id": 173, "seek": 86852, "start": 889.52, "end": 896.56, "text": " So another topic that I care about is function arguments.", "tokens": [407, 1071, 4829, 300, 286, 1127, 466, 307, 2445, 12869, 13], "temperature": 0.0, "avg_logprob": -0.19896000309994347, "compression_ratio": 1.5123456790123457, "no_speech_prob": 0.00010145960550289601}, {"id": 174, "seek": 89656, "start": 896.56, "end": 903.1199999999999, "text": " And the first one is Booleans.", "tokens": [400, 264, 700, 472, 307, 23351, 24008, 13], "temperature": 0.0, "avg_logprob": -0.14519954735124616, "compression_ratio": 1.7413793103448276, "no_speech_prob": 6.264964758884162e-05}, {"id": 175, "seek": 89656, "start": 903.1199999999999, "end": 910.16, "text": " So you start with something like this where you have a simple setup function that is easy", "tokens": [407, 291, 722, 365, 746, 411, 341, 689, 291, 362, 257, 2199, 8657, 2445, 300, 307, 1858], "temperature": 0.0, "avg_logprob": -0.14519954735124616, "compression_ratio": 1.7413793103448276, "no_speech_prob": 6.264964758884162e-05}, {"id": 176, "seek": 89656, "start": 910.16, "end": 919.92, "text": " enough and then with all the good intentions of the world, thanks, with all the good intentions", "tokens": [1547, 293, 550, 365, 439, 264, 665, 19354, 295, 264, 1002, 11, 3231, 11, 365, 439, 264, 665, 19354], "temperature": 0.0, "avg_logprob": -0.14519954735124616, "compression_ratio": 1.7413793103448276, "no_speech_prob": 6.264964758884162e-05}, {"id": 177, "seek": 89656, "start": 919.92, "end": 925.9599999999999, "text": " of the world, the developer starts adding a parameter but then we need another one and", "tokens": [295, 264, 1002, 11, 264, 10754, 3719, 5127, 257, 13075, 457, 550, 321, 643, 1071, 472, 293], "temperature": 0.0, "avg_logprob": -0.14519954735124616, "compression_ratio": 1.7413793103448276, "no_speech_prob": 6.264964758884162e-05}, {"id": 178, "seek": 92596, "start": 925.96, "end": 929.36, "text": " then we need another one.", "tokens": [550, 321, 643, 1071, 472, 13], "temperature": 0.0, "avg_logprob": -0.19423416137695312, "compression_ratio": 1.7830188679245282, "no_speech_prob": 7.072114385664463e-05}, {"id": 179, "seek": 92596, "start": 929.36, "end": 932.2, "text": " And how does it look on the calling site?", "tokens": [400, 577, 775, 309, 574, 322, 264, 5141, 3621, 30], "temperature": 0.0, "avg_logprob": -0.19423416137695312, "compression_ratio": 1.7830188679245282, "no_speech_prob": 7.072114385664463e-05}, {"id": 180, "seek": 92596, "start": 932.2, "end": 938.88, "text": " Something like this and you think, true, false, true, true, false, what the hell?", "tokens": [6595, 411, 341, 293, 291, 519, 11, 2074, 11, 7908, 11, 2074, 11, 2074, 11, 7908, 11, 437, 264, 4921, 30], "temperature": 0.0, "avg_logprob": -0.19423416137695312, "compression_ratio": 1.7830188679245282, "no_speech_prob": 7.072114385664463e-05}, {"id": 181, "seek": 92596, "start": 938.88, "end": 943.44, "text": " And then you need to stop, you need to enter into this function, you need to understand", "tokens": [400, 550, 291, 643, 281, 1590, 11, 291, 643, 281, 3242, 666, 341, 2445, 11, 291, 643, 281, 1223], "temperature": 0.0, "avg_logprob": -0.19423416137695312, "compression_ratio": 1.7830188679245282, "no_speech_prob": 7.072114385664463e-05}, {"id": 182, "seek": 92596, "start": 943.44, "end": 948.12, "text": " was it, where was the enable webbook parameter?", "tokens": [390, 309, 11, 689, 390, 264, 9528, 3670, 2939, 13075, 30], "temperature": 0.0, "avg_logprob": -0.19423416137695312, "compression_ratio": 1.7830188679245282, "no_speech_prob": 7.072114385664463e-05}, {"id": 183, "seek": 92596, "start": 948.12, "end": 954.4000000000001, "text": " It was the first one and then you get back here and this works but adds friction and getting", "tokens": [467, 390, 264, 700, 472, 293, 550, 291, 483, 646, 510, 293, 341, 1985, 457, 10860, 17710, 293, 1242], "temperature": 0.0, "avg_logprob": -0.19423416137695312, "compression_ratio": 1.7830188679245282, "no_speech_prob": 7.072114385664463e-05}, {"id": 184, "seek": 95440, "start": 954.4, "end": 961.0, "text": " a better version of it is so cheap that we should do that because we are doing a favor", "tokens": [257, 1101, 3037, 295, 309, 307, 370, 7084, 300, 321, 820, 360, 300, 570, 321, 366, 884, 257, 2294], "temperature": 0.0, "avg_logprob": -0.1049846393961302, "compression_ratio": 1.6568047337278107, "no_speech_prob": 2.8892824047943577e-05}, {"id": 185, "seek": 95440, "start": 961.0, "end": 967.76, "text": " to our future selves, we are doing a favor to the maintainer and it's going to be easier", "tokens": [281, 527, 2027, 41900, 11, 321, 366, 884, 257, 2294, 281, 264, 6909, 260, 293, 309, 311, 516, 281, 312, 3571], "temperature": 0.0, "avg_logprob": -0.1049846393961302, "compression_ratio": 1.6568047337278107, "no_speech_prob": 2.8892824047943577e-05}, {"id": 186, "seek": 95440, "start": 967.76, "end": 968.76, "text": " to understand.", "tokens": [281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.1049846393961302, "compression_ratio": 1.6568047337278107, "no_speech_prob": 2.8892824047943577e-05}, {"id": 187, "seek": 95440, "start": 968.76, "end": 980.0, "text": " Another option might be to pass a structure to the function that also works but not this.", "tokens": [3996, 3614, 1062, 312, 281, 1320, 257, 3877, 281, 264, 2445, 300, 611, 1985, 457, 406, 341, 13], "temperature": 0.0, "avg_logprob": -0.1049846393961302, "compression_ratio": 1.6568047337278107, "no_speech_prob": 2.8892824047943577e-05}, {"id": 188, "seek": 98000, "start": 980.0, "end": 986.4, "text": " Now I want to talk about function overloading or the fact that God doesn't have, so it's", "tokens": [823, 286, 528, 281, 751, 466, 2445, 28777, 278, 420, 264, 1186, 300, 1265, 1177, 380, 362, 11, 370, 309, 311], "temperature": 0.0, "avg_logprob": -0.1482075492104331, "compression_ratio": 1.7684729064039408, "no_speech_prob": 8.870432793628424e-05}, {"id": 189, "seek": 98000, "start": 986.4, "end": 988.96, "text": " more or less the same as the other one.", "tokens": [544, 420, 1570, 264, 912, 382, 264, 661, 472, 13], "temperature": 0.0, "avg_logprob": -0.1482075492104331, "compression_ratio": 1.7684729064039408, "no_speech_prob": 8.870432793628424e-05}, {"id": 190, "seek": 98000, "start": 988.96, "end": 997.36, "text": " God doesn't have function overloading so it's easy to have this full variety of the same", "tokens": [1265, 1177, 380, 362, 2445, 28777, 278, 370, 309, 311, 1858, 281, 362, 341, 1577, 5673, 295, 264, 912], "temperature": 0.0, "avg_logprob": -0.1482075492104331, "compression_ratio": 1.7684729064039408, "no_speech_prob": 8.870432793628424e-05}, {"id": 191, "seek": 98000, "start": 997.36, "end": 1000.72, "text": " function where we need to slightly change the behavior.", "tokens": [2445, 689, 321, 643, 281, 4748, 1319, 264, 5223, 13], "temperature": 0.0, "avg_logprob": -0.1482075492104331, "compression_ratio": 1.7684729064039408, "no_speech_prob": 8.870432793628424e-05}, {"id": 192, "seek": 98000, "start": 1000.72, "end": 1005.0, "text": " So you start with creating a service, then you need one with a backend, then you need", "tokens": [407, 291, 722, 365, 4084, 257, 2643, 11, 550, 291, 643, 472, 365, 257, 38087, 11, 550, 291, 643], "temperature": 0.0, "avg_logprob": -0.1482075492104331, "compression_ratio": 1.7684729064039408, "no_speech_prob": 8.870432793628424e-05}, {"id": 193, "seek": 100500, "start": 1005.0, "end": 1012.88, "text": " one with an IP and then you need one with a backend and with an IP and it's clear that", "tokens": [472, 365, 364, 8671, 293, 550, 291, 643, 472, 365, 257, 38087, 293, 365, 364, 8671, 293, 309, 311, 1850, 300], "temperature": 0.0, "avg_logprob": -0.18394293467203776, "compression_ratio": 1.5901639344262295, "no_speech_prob": 7.263926090672612e-05}, {"id": 194, "seek": 100500, "start": 1012.88, "end": 1015.52, "text": " can get easily out of hand.", "tokens": [393, 483, 3612, 484, 295, 1011, 13], "temperature": 0.0, "avg_logprob": -0.18394293467203776, "compression_ratio": 1.5901639344262295, "no_speech_prob": 7.263926090672612e-05}, {"id": 195, "seek": 100500, "start": 1015.52, "end": 1022.8, "text": " So an approach that I really like is using a variety of the argument with some modifiers", "tokens": [407, 364, 3109, 300, 286, 534, 411, 307, 1228, 257, 5673, 295, 264, 6770, 365, 512, 1072, 23463], "temperature": 0.0, "avg_logprob": -0.18394293467203776, "compression_ratio": 1.5901639344262295, "no_speech_prob": 7.263926090672612e-05}, {"id": 196, "seek": 100500, "start": 1022.8, "end": 1031.96, "text": " that accept the parameter and do what they have to do and this is how it looks from the", "tokens": [300, 3241, 264, 13075, 293, 360, 437, 436, 362, 281, 360, 293, 341, 307, 577, 309, 1542, 490, 264], "temperature": 0.0, "avg_logprob": -0.18394293467203776, "compression_ratio": 1.5901639344262295, "no_speech_prob": 7.263926090672612e-05}, {"id": 197, "seek": 103196, "start": 1031.96, "end": 1040.3600000000001, "text": " calling site, again, it's clear, it's easy to understand, your future self will thank", "tokens": [5141, 3621, 11, 797, 11, 309, 311, 1850, 11, 309, 311, 1858, 281, 1223, 11, 428, 2027, 2698, 486, 1309], "temperature": 0.0, "avg_logprob": -0.1715774408976237, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.00016665973816998303}, {"id": 198, "seek": 103196, "start": 1040.3600000000001, "end": 1043.0, "text": " you for this.", "tokens": [291, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.1715774408976237, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.00016665973816998303}, {"id": 199, "seek": 103196, "start": 1043.0, "end": 1047.8, "text": " And there is also another version where you can have these generator functions.", "tokens": [400, 456, 307, 611, 1071, 3037, 689, 291, 393, 362, 613, 19265, 6828, 13], "temperature": 0.0, "avg_logprob": -0.1715774408976237, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.00016665973816998303}, {"id": 200, "seek": 103196, "start": 1047.8, "end": 1055.2, "text": " I think it's on the borderline of being too magic for me but, again, this one is easy", "tokens": [286, 519, 309, 311, 322, 264, 7838, 1889, 295, 885, 886, 5585, 337, 385, 457, 11, 797, 11, 341, 472, 307, 1858], "temperature": 0.0, "avg_logprob": -0.1715774408976237, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.00016665973816998303}, {"id": 201, "seek": 103196, "start": 1055.2, "end": 1059.3600000000001, "text": " to read.", "tokens": [281, 1401, 13], "temperature": 0.0, "avg_logprob": -0.1715774408976237, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.00016665973816998303}, {"id": 202, "seek": 105936, "start": 1059.36, "end": 1067.12, "text": " So next one, I see this happening a lot in the world of controllers where you have one", "tokens": [407, 958, 472, 11, 286, 536, 341, 2737, 257, 688, 294, 264, 1002, 295, 26903, 689, 291, 362, 472], "temperature": 0.0, "avg_logprob": -0.12724691087549383, "compression_ratio": 1.735, "no_speech_prob": 6.64158578729257e-05}, {"id": 203, "seek": 105936, "start": 1067.12, "end": 1072.6799999999998, "text": " file that basically implements all the methods related to a controller.", "tokens": [3991, 300, 1936, 704, 17988, 439, 264, 7150, 4077, 281, 257, 10561, 13], "temperature": 0.0, "avg_logprob": -0.12724691087549383, "compression_ratio": 1.735, "no_speech_prob": 6.64158578729257e-05}, {"id": 204, "seek": 105936, "start": 1072.6799999999998, "end": 1077.32, "text": " So you have this file and you need to add an utility function and then all the other", "tokens": [407, 291, 362, 341, 3991, 293, 291, 643, 281, 909, 364, 14877, 2445, 293, 550, 439, 264, 661], "temperature": 0.0, "avg_logprob": -0.12724691087549383, "compression_ratio": 1.735, "no_speech_prob": 6.64158578729257e-05}, {"id": 205, "seek": 105936, "start": 1077.32, "end": 1079.7199999999998, "text": " functions are methods and what do you do?", "tokens": [6828, 366, 7150, 293, 437, 360, 291, 360, 30], "temperature": 0.0, "avg_logprob": -0.12724691087549383, "compression_ratio": 1.735, "no_speech_prob": 6.64158578729257e-05}, {"id": 206, "seek": 105936, "start": 1079.7199999999998, "end": 1084.28, "text": " You add a new method, even if it doesn't have to be a method.", "tokens": [509, 909, 257, 777, 3170, 11, 754, 498, 309, 1177, 380, 362, 281, 312, 257, 3170, 13], "temperature": 0.0, "avg_logprob": -0.12724691087549383, "compression_ratio": 1.735, "no_speech_prob": 6.64158578729257e-05}, {"id": 207, "seek": 108428, "start": 1084.28, "end": 1089.6, "text": " So you look at something like this and you think, hmm, why is this a method?", "tokens": [407, 291, 574, 412, 746, 411, 341, 293, 291, 519, 11, 16478, 11, 983, 307, 341, 257, 3170, 30], "temperature": 0.0, "avg_logprob": -0.13052766629964999, "compression_ratio": 1.711111111111111, "no_speech_prob": 6.388869223883376e-05}, {"id": 208, "seek": 108428, "start": 1089.6, "end": 1092.04, "text": " Is there something wrong with that?", "tokens": [1119, 456, 746, 2085, 365, 300, 30], "temperature": 0.0, "avg_logprob": -0.13052766629964999, "compression_ratio": 1.711111111111111, "no_speech_prob": 6.388869223883376e-05}, {"id": 209, "seek": 108428, "start": 1092.04, "end": 1095.44, "text": " And this, again, is adding friction that could be avoided.", "tokens": [400, 341, 11, 797, 11, 307, 5127, 17710, 300, 727, 312, 24890, 13], "temperature": 0.0, "avg_logprob": -0.13052766629964999, "compression_ratio": 1.711111111111111, "no_speech_prob": 6.388869223883376e-05}, {"id": 210, "seek": 108428, "start": 1095.44, "end": 1101.28, "text": " So if a function is a function, just make it a function and not a method because also", "tokens": [407, 498, 257, 2445, 307, 257, 2445, 11, 445, 652, 309, 257, 2445, 293, 406, 257, 3170, 570, 611], "temperature": 0.0, "avg_logprob": -0.13052766629964999, "compression_ratio": 1.711111111111111, "no_speech_prob": 6.388869223883376e-05}, {"id": 211, "seek": 108428, "start": 1101.28, "end": 1102.28, "text": " testing is easier.", "tokens": [4997, 307, 3571, 13], "temperature": 0.0, "avg_logprob": -0.13052766629964999, "compression_ratio": 1.711111111111111, "no_speech_prob": 6.388869223883376e-05}, {"id": 212, "seek": 108428, "start": 1102.28, "end": 1107.84, "text": " You don't have to have the instance that you are not using for anything just in order to", "tokens": [509, 500, 380, 362, 281, 362, 264, 5197, 300, 291, 366, 406, 1228, 337, 1340, 445, 294, 1668, 281], "temperature": 0.0, "avg_logprob": -0.13052766629964999, "compression_ratio": 1.711111111111111, "no_speech_prob": 6.388869223883376e-05}, {"id": 213, "seek": 108428, "start": 1107.84, "end": 1110.44, "text": " test this function.", "tokens": [1500, 341, 2445, 13], "temperature": 0.0, "avg_logprob": -0.13052766629964999, "compression_ratio": 1.711111111111111, "no_speech_prob": 6.388869223883376e-05}, {"id": 214, "seek": 111044, "start": 1110.44, "end": 1116.8, "text": " And then a word about pointers.", "tokens": [400, 550, 257, 1349, 466, 44548, 13], "temperature": 0.0, "avg_logprob": -0.17134181843247526, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00012271502055227757}, {"id": 215, "seek": 111044, "start": 1116.8, "end": 1127.24, "text": " Go has pointers, like not all other languages, so people might find them hard to reason about.", "tokens": [1037, 575, 44548, 11, 411, 406, 439, 661, 8650, 11, 370, 561, 1062, 915, 552, 1152, 281, 1778, 466, 13], "temperature": 0.0, "avg_logprob": -0.17134181843247526, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00012271502055227757}, {"id": 216, "seek": 111044, "start": 1127.24, "end": 1132.8, "text": " And when I see two functions like this, my first thing, thought is, like, this one is", "tokens": [400, 562, 286, 536, 732, 6828, 411, 341, 11, 452, 700, 551, 11, 1194, 307, 11, 411, 11, 341, 472, 307], "temperature": 0.0, "avg_logprob": -0.17134181843247526, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00012271502055227757}, {"id": 217, "seek": 111044, "start": 1132.8, "end": 1135.64, "text": " not changing the object and the second one is doing that.", "tokens": [406, 4473, 264, 2657, 293, 264, 1150, 472, 307, 884, 300, 13], "temperature": 0.0, "avg_logprob": -0.17134181843247526, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00012271502055227757}, {"id": 218, "seek": 111044, "start": 1135.64, "end": 1138.8, "text": " So this is the rule of thumb that I'm trying to apply.", "tokens": [407, 341, 307, 264, 4978, 295, 9298, 300, 286, 478, 1382, 281, 3079, 13], "temperature": 0.0, "avg_logprob": -0.17134181843247526, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00012271502055227757}, {"id": 219, "seek": 113880, "start": 1138.8, "end": 1142.96, "text": " If a function is not changing the object, then pass the object with a value, otherwise", "tokens": [759, 257, 2445, 307, 406, 4473, 264, 2657, 11, 550, 1320, 264, 2657, 365, 257, 2158, 11, 5911], "temperature": 0.0, "avg_logprob": -0.1654638093093346, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.000181448514922522}, {"id": 220, "seek": 113880, "start": 1142.96, "end": 1146.12, "text": " pass the pointer.", "tokens": [1320, 264, 23918, 13], "temperature": 0.0, "avg_logprob": -0.1654638093093346, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.000181448514922522}, {"id": 221, "seek": 113880, "start": 1146.12, "end": 1147.84, "text": " But there are also exceptions.", "tokens": [583, 456, 366, 611, 22847, 13], "temperature": 0.0, "avg_logprob": -0.1654638093093346, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.000181448514922522}, {"id": 222, "seek": 113880, "start": 1147.84, "end": 1152.2, "text": " There are some kind of objects that can be passed by value or they can, but they will", "tokens": [821, 366, 512, 733, 295, 6565, 300, 393, 312, 4678, 538, 2158, 420, 436, 393, 11, 457, 436, 486], "temperature": 0.0, "avg_logprob": -0.1654638093093346, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.000181448514922522}, {"id": 223, "seek": 113880, "start": 1152.2, "end": 1155.2, "text": " give you a bad afternoon.", "tokens": [976, 291, 257, 1578, 6499, 13], "temperature": 0.0, "avg_logprob": -0.1654638093093346, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.000181448514922522}, {"id": 224, "seek": 113880, "start": 1155.2, "end": 1159.48, "text": " But so mutex is file descriptors.", "tokens": [583, 370, 24523, 87, 307, 3991, 31280, 830, 13], "temperature": 0.0, "avg_logprob": -0.1654638093093346, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.000181448514922522}, {"id": 225, "seek": 113880, "start": 1159.48, "end": 1162.76, "text": " We need to pass them by reference because that's the way it works.", "tokens": [492, 643, 281, 1320, 552, 538, 6408, 570, 300, 311, 264, 636, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.1654638093093346, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.000181448514922522}, {"id": 226, "seek": 113880, "start": 1162.76, "end": 1168.28, "text": " We have linters that help us in that and we have this rule of thumb that says if you look", "tokens": [492, 362, 22896, 1559, 300, 854, 505, 294, 300, 293, 321, 362, 341, 4978, 295, 9298, 300, 1619, 498, 291, 574], "temperature": 0.0, "avg_logprob": -0.1654638093093346, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.000181448514922522}, {"id": 227, "seek": 116828, "start": 1168.28, "end": 1177.8, "text": " at the object, if all the methods associated with the pointer, then use a pointer.", "tokens": [412, 264, 2657, 11, 498, 439, 264, 7150, 6615, 365, 264, 23918, 11, 550, 764, 257, 23918, 13], "temperature": 0.0, "avg_logprob": -0.18315033479170365, "compression_ratio": 1.6618357487922706, "no_speech_prob": 3.1596897315466776e-05}, {"id": 228, "seek": 116828, "start": 1177.8, "end": 1180.04, "text": " One might argue how about performances.", "tokens": [1485, 1062, 9695, 577, 466, 16087, 13], "temperature": 0.0, "avg_logprob": -0.18315033479170365, "compression_ratio": 1.6618357487922706, "no_speech_prob": 3.1596897315466776e-05}, {"id": 229, "seek": 116828, "start": 1180.04, "end": 1184.28, "text": " We are passing the whole object instead of passing just the reference.", "tokens": [492, 366, 8437, 264, 1379, 2657, 2602, 295, 8437, 445, 264, 6408, 13], "temperature": 0.0, "avg_logprob": -0.18315033479170365, "compression_ratio": 1.6618357487922706, "no_speech_prob": 3.1596897315466776e-05}, {"id": 230, "seek": 116828, "start": 1184.28, "end": 1190.3999999999999, "text": " Yeah, passing the reference is cheaper, but this is not see, this is go, and that's not", "tokens": [865, 11, 8437, 264, 6408, 307, 12284, 11, 457, 341, 307, 406, 536, 11, 341, 307, 352, 11, 293, 300, 311, 406], "temperature": 0.0, "avg_logprob": -0.18315033479170365, "compression_ratio": 1.6618357487922706, "no_speech_prob": 3.1596897315466776e-05}, {"id": 231, "seek": 116828, "start": 1190.3999999999999, "end": 1191.3999999999999, "text": " always clear.", "tokens": [1009, 1850, 13], "temperature": 0.0, "avg_logprob": -0.18315033479170365, "compression_ratio": 1.6618357487922706, "no_speech_prob": 3.1596897315466776e-05}, {"id": 232, "seek": 116828, "start": 1191.3999999999999, "end": 1194.48, "text": " So what we should care about is the readability.", "tokens": [407, 437, 321, 820, 1127, 466, 307, 264, 1401, 2310, 13], "temperature": 0.0, "avg_logprob": -0.18315033479170365, "compression_ratio": 1.6618357487922706, "no_speech_prob": 3.1596897315466776e-05}, {"id": 233, "seek": 119448, "start": 1194.48, "end": 1200.72, "text": " And we have a lot of toolery that will help us to understand if that can be optimized", "tokens": [400, 321, 362, 257, 688, 295, 2290, 2109, 300, 486, 854, 505, 281, 1223, 498, 300, 393, 312, 26941], "temperature": 0.0, "avg_logprob": -0.13852665298863462, "compression_ratio": 1.515, "no_speech_prob": 4.530910518951714e-05}, {"id": 234, "seek": 119448, "start": 1200.72, "end": 1204.76, "text": " if it's in the hot path.", "tokens": [498, 309, 311, 294, 264, 2368, 3100, 13], "temperature": 0.0, "avg_logprob": -0.13852665298863462, "compression_ratio": 1.515, "no_speech_prob": 4.530910518951714e-05}, {"id": 235, "seek": 119448, "start": 1204.76, "end": 1215.52, "text": " And then we need to sacrifice a bit the reliability of our program in order to have better performances.", "tokens": [400, 550, 321, 643, 281, 11521, 257, 857, 264, 24550, 295, 527, 1461, 294, 1668, 281, 362, 1101, 16087, 13], "temperature": 0.0, "avg_logprob": -0.13852665298863462, "compression_ratio": 1.515, "no_speech_prob": 4.530910518951714e-05}, {"id": 236, "seek": 119448, "start": 1215.52, "end": 1221.04, "text": " So now I'm going to talk about something that was advocated in clean code where it says", "tokens": [407, 586, 286, 478, 516, 281, 751, 466, 746, 300, 390, 7915, 770, 294, 2541, 3089, 689, 309, 1619], "temperature": 0.0, "avg_logprob": -0.13852665298863462, "compression_ratio": 1.515, "no_speech_prob": 4.530910518951714e-05}, {"id": 237, "seek": 122104, "start": 1221.04, "end": 1228.32, "text": " that our code base should read like a newspaper, which means that you open a file, you should", "tokens": [300, 527, 3089, 3096, 820, 1401, 411, 257, 13669, 11, 597, 1355, 300, 291, 1269, 257, 3991, 11, 291, 820], "temperature": 0.0, "avg_logprob": -0.13693716170939993, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0002414978516753763}, {"id": 238, "seek": 122104, "start": 1228.32, "end": 1233.8, "text": " have all the high level concepts on the top of the file, and then start to find all the", "tokens": [362, 439, 264, 1090, 1496, 10392, 322, 264, 1192, 295, 264, 3991, 11, 293, 550, 722, 281, 915, 439, 264], "temperature": 0.0, "avg_logprob": -0.13693716170939993, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0002414978516753763}, {"id": 239, "seek": 122104, "start": 1233.8, "end": 1237.76, "text": " nitty details of the implementation in the bottom of the file.", "tokens": [297, 10016, 4365, 295, 264, 11420, 294, 264, 2767, 295, 264, 3991, 13], "temperature": 0.0, "avg_logprob": -0.13693716170939993, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0002414978516753763}, {"id": 240, "seek": 122104, "start": 1237.76, "end": 1241.52, "text": " And these applies pretty well to go.", "tokens": [400, 613, 13165, 1238, 731, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.13693716170939993, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0002414978516753763}, {"id": 241, "seek": 122104, "start": 1241.52, "end": 1247.6399999999999, "text": " So what I expect from a well-written go file is to have all the public methods, all the", "tokens": [407, 437, 286, 2066, 490, 257, 731, 12, 26859, 352, 3991, 307, 281, 362, 439, 264, 1908, 7150, 11, 439, 264], "temperature": 0.0, "avg_logprob": -0.13693716170939993, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0002414978516753763}, {"id": 242, "seek": 124764, "start": 1247.64, "end": 1252.3600000000001, "text": " public objects in the top of the file, because when I open the file, I see what this package", "tokens": [1908, 6565, 294, 264, 1192, 295, 264, 3991, 11, 570, 562, 286, 1269, 264, 3991, 11, 286, 536, 437, 341, 7372], "temperature": 0.0, "avg_logprob": -0.12125536600748697, "compression_ratio": 1.5618556701030928, "no_speech_prob": 7.263456063810736e-05}, {"id": 243, "seek": 124764, "start": 1252.3600000000001, "end": 1255.6000000000001, "text": " has to offer to the external world.", "tokens": [575, 281, 2626, 281, 264, 8320, 1002, 13], "temperature": 0.0, "avg_logprob": -0.12125536600748697, "compression_ratio": 1.5618556701030928, "no_speech_prob": 7.263456063810736e-05}, {"id": 244, "seek": 124764, "start": 1255.6000000000001, "end": 1262.2800000000002, "text": " And so those are our high level concepts by definition.", "tokens": [400, 370, 729, 366, 527, 1090, 1496, 10392, 538, 7123, 13], "temperature": 0.0, "avg_logprob": -0.12125536600748697, "compression_ratio": 1.5618556701030928, "no_speech_prob": 7.263456063810736e-05}, {"id": 245, "seek": 124764, "start": 1262.2800000000002, "end": 1268.2800000000002, "text": " And another thing that I think is sometimes underestimated is the fact that we can have", "tokens": [400, 1071, 551, 300, 286, 519, 307, 2171, 24612, 33008, 307, 264, 1186, 300, 321, 393, 362], "temperature": 0.0, "avg_logprob": -0.12125536600748697, "compression_ratio": 1.5618556701030928, "no_speech_prob": 7.263456063810736e-05}, {"id": 246, "seek": 124764, "start": 1268.2800000000002, "end": 1270.5600000000002, "text": " our packages split into files.", "tokens": [527, 17401, 7472, 666, 7098, 13], "temperature": 0.0, "avg_logprob": -0.12125536600748697, "compression_ratio": 1.5618556701030928, "no_speech_prob": 7.263456063810736e-05}, {"id": 247, "seek": 127056, "start": 1270.56, "end": 1278.8799999999999, "text": " So again, in order to have a better navigability of our code base, we can split it into files,", "tokens": [407, 797, 11, 294, 1668, 281, 362, 257, 1101, 7407, 2310, 295, 527, 3089, 3096, 11, 321, 393, 7472, 309, 666, 7098, 11], "temperature": 0.0, "avg_logprob": -0.10593929806271114, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.00012830998457502574}, {"id": 248, "seek": 127056, "start": 1278.8799999999999, "end": 1288.04, "text": " have a main file related to the package that is named after the package, and then have", "tokens": [362, 257, 2135, 3991, 4077, 281, 264, 7372, 300, 307, 4926, 934, 264, 7372, 11, 293, 550, 362], "temperature": 0.0, "avg_logprob": -0.10593929806271114, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.00012830998457502574}, {"id": 249, "seek": 127056, "start": 1288.04, "end": 1294.9199999999998, "text": " these smaller entities where we put the different logics.", "tokens": [613, 4356, 16667, 689, 321, 829, 264, 819, 3565, 1167, 13], "temperature": 0.0, "avg_logprob": -0.10593929806271114, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.00012830998457502574}, {"id": 250, "seek": 127056, "start": 1294.9199999999998, "end": 1299.32, "text": " And this is basically what I'm trying to say here.", "tokens": [400, 341, 307, 1936, 437, 286, 478, 1382, 281, 584, 510, 13], "temperature": 0.0, "avg_logprob": -0.10593929806271114, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.00012830998457502574}, {"id": 251, "seek": 129932, "start": 1299.32, "end": 1306.96, "text": " So try to have the public fields on the top, try to remove or to move the utility functions", "tokens": [407, 853, 281, 362, 264, 1908, 7909, 322, 264, 1192, 11, 853, 281, 4159, 420, 281, 1286, 264, 14877, 6828], "temperature": 0.0, "avg_logprob": -0.1320147772093077, "compression_ratio": 1.5919540229885059, "no_speech_prob": 7.614937203470618e-05}, {"id": 252, "seek": 129932, "start": 1306.96, "end": 1311.08, "text": " in the bottom, split the package into file, because again, it's free.", "tokens": [294, 264, 2767, 11, 7472, 264, 7372, 666, 3991, 11, 570, 797, 11, 309, 311, 1737, 13], "temperature": 0.0, "avg_logprob": -0.1320147772093077, "compression_ratio": 1.5919540229885059, "no_speech_prob": 7.614937203470618e-05}, {"id": 253, "seek": 129932, "start": 1311.08, "end": 1320.8799999999999, "text": " It won't cost any energy to you or to the executable, and have a main package file that", "tokens": [467, 1582, 380, 2063, 604, 2281, 281, 291, 420, 281, 264, 7568, 712, 11, 293, 362, 257, 2135, 7372, 3991, 300], "temperature": 0.0, "avg_logprob": -0.1320147772093077, "compression_ratio": 1.5919540229885059, "no_speech_prob": 7.614937203470618e-05}, {"id": 254, "seek": 129932, "start": 1320.8799999999999, "end": 1323.9199999999998, "text": " is named after the package.", "tokens": [307, 4926, 934, 264, 7372, 13], "temperature": 0.0, "avg_logprob": -0.1320147772093077, "compression_ratio": 1.5919540229885059, "no_speech_prob": 7.614937203470618e-05}, {"id": 255, "seek": 132392, "start": 1323.92, "end": 1329.28, "text": " Next item is about asynchronous functions.", "tokens": [3087, 3174, 307, 466, 49174, 6828, 13], "temperature": 0.0, "avg_logprob": -0.21759327598240064, "compression_ratio": 1.4797687861271676, "no_speech_prob": 0.000241735004237853}, {"id": 256, "seek": 132392, "start": 1329.28, "end": 1334.28, "text": " And I saw this many times.", "tokens": [400, 286, 1866, 341, 867, 1413, 13], "temperature": 0.0, "avg_logprob": -0.21759327598240064, "compression_ratio": 1.4797687861271676, "no_speech_prob": 0.000241735004237853}, {"id": 257, "seek": 132392, "start": 1334.28, "end": 1337.44, "text": " It's one of the nice things about Go, right?", "tokens": [467, 311, 472, 295, 264, 1481, 721, 466, 1037, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21759327598240064, "compression_ratio": 1.4797687861271676, "no_speech_prob": 0.000241735004237853}, {"id": 258, "seek": 132392, "start": 1337.44, "end": 1341.88, "text": " It's so easy, so convenient to implement concurrent code.", "tokens": [467, 311, 370, 1858, 11, 370, 10851, 281, 4445, 37702, 3089, 13], "temperature": 0.0, "avg_logprob": -0.21759327598240064, "compression_ratio": 1.4797687861271676, "no_speech_prob": 0.000241735004237853}, {"id": 259, "seek": 132392, "start": 1341.88, "end": 1348.44, "text": " You can just implement Go routines, you can pass channels and have fan in, fan out.", "tokens": [509, 393, 445, 4445, 1037, 33827, 11, 291, 393, 1320, 9235, 293, 362, 3429, 294, 11, 3429, 484, 13], "temperature": 0.0, "avg_logprob": -0.21759327598240064, "compression_ratio": 1.4797687861271676, "no_speech_prob": 0.000241735004237853}, {"id": 260, "seek": 134844, "start": 1348.44, "end": 1355.0, "text": " But the problem with that is that something like this has some flaws.", "tokens": [583, 264, 1154, 365, 300, 307, 300, 746, 411, 341, 575, 512, 27108, 13], "temperature": 0.0, "avg_logprob": -0.128590342642247, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.000106908890302293}, {"id": 261, "seek": 134844, "start": 1355.0, "end": 1361.48, "text": " And I think that is way better to, again, take the business logic, move it to a synchronous", "tokens": [400, 286, 519, 300, 307, 636, 1101, 281, 11, 797, 11, 747, 264, 1606, 9952, 11, 1286, 309, 281, 257, 44743], "temperature": 0.0, "avg_logprob": -0.128590342642247, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.000106908890302293}, {"id": 262, "seek": 134844, "start": 1361.48, "end": 1366.6000000000001, "text": " function that is easier to test without all the infrastructure that you need to put in", "tokens": [2445, 300, 307, 3571, 281, 1500, 1553, 439, 264, 6896, 300, 291, 643, 281, 829, 294], "temperature": 0.0, "avg_logprob": -0.128590342642247, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.000106908890302293}, {"id": 263, "seek": 134844, "start": 1366.6000000000001, "end": 1375.0, "text": " place with channels, with weight groups in order to reverse the synchronousness of your", "tokens": [1081, 365, 9235, 11, 365, 3364, 3935, 294, 1668, 281, 9943, 264, 44743, 1287, 295, 428], "temperature": 0.0, "avg_logprob": -0.128590342642247, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.000106908890302293}, {"id": 264, "seek": 134844, "start": 1375.0, "end": 1377.16, "text": " function just in order to test it.", "tokens": [2445, 445, 294, 1668, 281, 1500, 309, 13], "temperature": 0.0, "avg_logprob": -0.128590342642247, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.000106908890302293}, {"id": 265, "seek": 137716, "start": 1377.16, "end": 1382.68, "text": " So if you can, move the business logic into a synchronous function and let the calling", "tokens": [407, 498, 291, 393, 11, 1286, 264, 1606, 9952, 666, 257, 44743, 2445, 293, 718, 264, 5141], "temperature": 0.0, "avg_logprob": -0.1428509439740862, "compression_ratio": 1.5781990521327014, "no_speech_prob": 3.897466740454547e-05}, {"id": 266, "seek": 137716, "start": 1382.68, "end": 1386.68, "text": " site handle the life cycle of the Go routine.", "tokens": [3621, 4813, 264, 993, 6586, 295, 264, 1037, 9927, 13], "temperature": 0.0, "avg_logprob": -0.1428509439740862, "compression_ratio": 1.5781990521327014, "no_speech_prob": 3.897466740454547e-05}, {"id": 267, "seek": 137716, "start": 1386.68, "end": 1394.24, "text": " So again, that part has to be delegated on the client code, and that will make our function", "tokens": [407, 797, 11, 300, 644, 575, 281, 312, 15824, 770, 322, 264, 6423, 3089, 11, 293, 300, 486, 652, 527, 2445], "temperature": 0.0, "avg_logprob": -0.1428509439740862, "compression_ratio": 1.5781990521327014, "no_speech_prob": 3.897466740454547e-05}, {"id": 268, "seek": 137716, "start": 1394.24, "end": 1399.44, "text": " easier to test and our code base easier to reason about.", "tokens": [3571, 281, 1500, 293, 527, 3089, 3096, 3571, 281, 1778, 466, 13], "temperature": 0.0, "avg_logprob": -0.1428509439740862, "compression_ratio": 1.5781990521327014, "no_speech_prob": 3.897466740454547e-05}, {"id": 269, "seek": 137716, "start": 1399.44, "end": 1404.16, "text": " And again, I didn't invent this as everything else.", "tokens": [400, 797, 11, 286, 994, 380, 7962, 341, 382, 1203, 1646, 13], "temperature": 0.0, "avg_logprob": -0.1428509439740862, "compression_ratio": 1.5781990521327014, "no_speech_prob": 3.897466740454547e-05}, {"id": 270, "seek": 140416, "start": 1404.16, "end": 1411.16, "text": " This is from the code review Go wiki, and it's basically saying the same thing, like", "tokens": [639, 307, 490, 264, 3089, 3131, 1037, 261, 9850, 11, 293, 309, 311, 1936, 1566, 264, 912, 551, 11, 411], "temperature": 0.0, "avg_logprob": -0.18388811747233072, "compression_ratio": 1.5330188679245282, "no_speech_prob": 9.272293391404673e-05}, {"id": 271, "seek": 140416, "start": 1411.16, "end": 1419.2, "text": " try to use synchronous functions as much as you can.", "tokens": [853, 281, 764, 44743, 6828, 382, 709, 382, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.18388811747233072, "compression_ratio": 1.5330188679245282, "no_speech_prob": 9.272293391404673e-05}, {"id": 272, "seek": 140416, "start": 1419.2, "end": 1424.1200000000001, "text": " Next item is about functions that lie, and what I mean by that.", "tokens": [3087, 3174, 307, 466, 6828, 300, 4544, 11, 293, 437, 286, 914, 538, 300, 13], "temperature": 0.0, "avg_logprob": -0.18388811747233072, "compression_ratio": 1.5330188679245282, "no_speech_prob": 9.272293391404673e-05}, {"id": 273, "seek": 140416, "start": 1424.1200000000001, "end": 1430.8000000000002, "text": " You have something that is, what would you expect this function to do?", "tokens": [509, 362, 746, 300, 307, 11, 437, 576, 291, 2066, 341, 2445, 281, 360, 30], "temperature": 0.0, "avg_logprob": -0.18388811747233072, "compression_ratio": 1.5330188679245282, "no_speech_prob": 9.272293391404673e-05}, {"id": 274, "seek": 140416, "start": 1430.8000000000002, "end": 1431.8000000000002, "text": " Clear the node.", "tokens": [14993, 264, 9984, 13], "temperature": 0.0, "avg_logprob": -0.18388811747233072, "compression_ratio": 1.5330188679245282, "no_speech_prob": 9.272293391404673e-05}, {"id": 275, "seek": 140416, "start": 1431.8000000000002, "end": 1432.8000000000002, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.18388811747233072, "compression_ratio": 1.5330188679245282, "no_speech_prob": 9.272293391404673e-05}, {"id": 276, "seek": 140416, "start": 1432.8000000000002, "end": 1433.8000000000002, "text": " That's what I would expect.", "tokens": [663, 311, 437, 286, 576, 2066, 13], "temperature": 0.0, "avg_logprob": -0.18388811747233072, "compression_ratio": 1.5330188679245282, "no_speech_prob": 9.272293391404673e-05}, {"id": 277, "seek": 143380, "start": 1433.8, "end": 1440.36, "text": " But the developer found a very edgy corner case where if the name of the node is do not", "tokens": [583, 264, 10754, 1352, 257, 588, 1257, 1480, 4538, 1389, 689, 498, 264, 1315, 295, 264, 9984, 307, 360, 406], "temperature": 0.0, "avg_logprob": -0.1661243438720703, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.00016777314885985106}, {"id": 278, "seek": 143380, "start": 1440.36, "end": 1442.96, "text": " clean, then do not clean.", "tokens": [2541, 11, 550, 360, 406, 2541, 13], "temperature": 0.0, "avg_logprob": -0.1661243438720703, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.00016777314885985106}, {"id": 279, "seek": 143380, "start": 1442.96, "end": 1448.08, "text": " And he was doing that with the all good faith of the word.", "tokens": [400, 415, 390, 884, 300, 365, 264, 439, 665, 4522, 295, 264, 1349, 13], "temperature": 0.0, "avg_logprob": -0.1661243438720703, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.00016777314885985106}, {"id": 280, "seek": 143380, "start": 1448.08, "end": 1450.6, "text": " He's trying to solve a problem here.", "tokens": [634, 311, 1382, 281, 5039, 257, 1154, 510, 13], "temperature": 0.0, "avg_logprob": -0.1661243438720703, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.00016777314885985106}, {"id": 281, "seek": 143380, "start": 1450.6, "end": 1455.32, "text": " But the problem is that, again, this is going to give us a bad afternoon because we'll see", "tokens": [583, 264, 1154, 307, 300, 11, 797, 11, 341, 307, 516, 281, 976, 505, 257, 1578, 6499, 570, 321, 603, 536], "temperature": 0.0, "avg_logprob": -0.1661243438720703, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.00016777314885985106}, {"id": 282, "seek": 143380, "start": 1455.32, "end": 1463.36, "text": " that the node is not being cleared and we'll have to put a lot of printfs in our code or", "tokens": [300, 264, 9984, 307, 406, 885, 19725, 293, 321, 603, 362, 281, 829, 257, 688, 295, 4482, 16883, 294, 527, 3089, 420], "temperature": 0.0, "avg_logprob": -0.1661243438720703, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.00016777314885985106}, {"id": 283, "seek": 146336, "start": 1463.36, "end": 1468.9199999999998, "text": " to do a lot of debugging in order to understand why is this happening.", "tokens": [281, 360, 257, 688, 295, 45592, 294, 1668, 281, 1223, 983, 307, 341, 2737, 13], "temperature": 0.0, "avg_logprob": -0.18970933453790073, "compression_ratio": 1.4903225806451612, "no_speech_prob": 7.121823000488803e-05}, {"id": 284, "seek": 146336, "start": 1468.9199999999998, "end": 1476.76, "text": " So again, this is done with good intentions, but the result is not so good.", "tokens": [407, 797, 11, 341, 307, 1096, 365, 665, 19354, 11, 457, 264, 1874, 307, 406, 370, 665, 13], "temperature": 0.0, "avg_logprob": -0.18970933453790073, "compression_ratio": 1.4903225806451612, "no_speech_prob": 7.121823000488803e-05}, {"id": 285, "seek": 146336, "start": 1476.76, "end": 1486.3999999999999, "text": " So again, as I said multiple times today, we should defer this responsibility to the", "tokens": [407, 797, 11, 382, 286, 848, 3866, 1413, 965, 11, 321, 820, 25704, 341, 6357, 281, 264], "temperature": 0.0, "avg_logprob": -0.18970933453790073, "compression_ratio": 1.4903225806451612, "no_speech_prob": 7.121823000488803e-05}, {"id": 286, "seek": 148640, "start": 1486.4, "end": 1494.3200000000002, "text": " calling site because that will result in a code base that requires less energy and less", "tokens": [5141, 3621, 570, 300, 486, 1874, 294, 257, 3089, 3096, 300, 7029, 1570, 2281, 293, 1570], "temperature": 0.0, "avg_logprob": -0.18193813517123839, "compression_ratio": 1.592783505154639, "no_speech_prob": 7.363293116213754e-05}, {"id": 287, "seek": 148640, "start": 1494.3200000000002, "end": 1496.2800000000002, "text": " effort to understand.", "tokens": [4630, 281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.18193813517123839, "compression_ratio": 1.592783505154639, "no_speech_prob": 7.363293116213754e-05}, {"id": 288, "seek": 148640, "start": 1496.2800000000002, "end": 1501.4, "text": " What if we have this function called 100 times in our code base, then I don't know.", "tokens": [708, 498, 321, 362, 341, 2445, 1219, 2319, 1413, 294, 527, 3089, 3096, 11, 550, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.18193813517123839, "compression_ratio": 1.592783505154639, "no_speech_prob": 7.363293116213754e-05}, {"id": 289, "seek": 148640, "start": 1501.4, "end": 1509.6000000000001, "text": " Just call it clear the node, but do not clean one or have one filter function, whatever,", "tokens": [1449, 818, 309, 1850, 264, 9984, 11, 457, 360, 406, 2541, 472, 420, 362, 472, 6608, 2445, 11, 2035, 11], "temperature": 0.0, "avg_logprob": -0.18193813517123839, "compression_ratio": 1.592783505154639, "no_speech_prob": 7.363293116213754e-05}, {"id": 290, "seek": 148640, "start": 1509.6000000000001, "end": 1514.0400000000002, "text": " but not lie to the reader.", "tokens": [457, 406, 4544, 281, 264, 15149, 13], "temperature": 0.0, "avg_logprob": -0.18193813517123839, "compression_ratio": 1.592783505154639, "no_speech_prob": 7.363293116213754e-05}, {"id": 291, "seek": 151404, "start": 1514.04, "end": 1522.56, "text": " So wrapping up, there is no much to wrap up.", "tokens": [407, 21993, 493, 11, 456, 307, 572, 709, 281, 7019, 493, 13], "temperature": 0.0, "avg_logprob": -0.19366057489959287, "compression_ratio": 1.4886363636363635, "no_speech_prob": 6.607926479773596e-05}, {"id": 292, "seek": 151404, "start": 1522.56, "end": 1526.92, "text": " I mean, it was just a list of no related items.", "tokens": [286, 914, 11, 309, 390, 445, 257, 1329, 295, 572, 4077, 4754, 13], "temperature": 0.0, "avg_logprob": -0.19366057489959287, "compression_ratio": 1.4886363636363635, "no_speech_prob": 6.607926479773596e-05}, {"id": 293, "seek": 151404, "start": 1526.92, "end": 1534.6399999999999, "text": " Maybe the only take away that is globally is to say that we should be smart and let", "tokens": [2704, 264, 787, 747, 1314, 300, 307, 18958, 307, 281, 584, 300, 321, 820, 312, 4069, 293, 718], "temperature": 0.0, "avg_logprob": -0.19366057489959287, "compression_ratio": 1.4886363636363635, "no_speech_prob": 6.607926479773596e-05}, {"id": 294, "seek": 151404, "start": 1534.6399999999999, "end": 1541.76, "text": " our readers, the calling site over the code base do a bit more because that will give", "tokens": [527, 17147, 11, 264, 5141, 3621, 670, 264, 3089, 3096, 360, 257, 857, 544, 570, 300, 486, 976], "temperature": 0.0, "avg_logprob": -0.19366057489959287, "compression_ratio": 1.4886363636363635, "no_speech_prob": 6.607926479773596e-05}, {"id": 295, "seek": 154176, "start": 1541.76, "end": 1546.36, "text": " us a better day in the future.", "tokens": [505, 257, 1101, 786, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.14813640594482422, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00010291798389516771}, {"id": 296, "seek": 154176, "start": 1546.36, "end": 1554.68, "text": " I'm a strong believer of the Pareto principle, most often when it's on the bad side of it,", "tokens": [286, 478, 257, 2068, 23892, 295, 264, 31189, 1353, 8665, 11, 881, 2049, 562, 309, 311, 322, 264, 1578, 1252, 295, 309, 11], "temperature": 0.0, "avg_logprob": -0.14813640594482422, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00010291798389516771}, {"id": 297, "seek": 154176, "start": 1554.68, "end": 1559.32, "text": " but in this case, I think that by applying these set of rules that will take very less", "tokens": [457, 294, 341, 1389, 11, 286, 519, 300, 538, 9275, 613, 992, 295, 4474, 300, 486, 747, 588, 1570], "temperature": 0.0, "avg_logprob": -0.14813640594482422, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00010291798389516771}, {"id": 298, "seek": 154176, "start": 1559.32, "end": 1568.28, "text": " to implement, those will improve the quality of the code base a lot.", "tokens": [281, 4445, 11, 729, 486, 3470, 264, 3125, 295, 264, 3089, 3096, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.14813640594482422, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00010291798389516771}, {"id": 299, "seek": 156828, "start": 1568.28, "end": 1576.16, "text": " And then I want to finish with this quote from Rob Pike, simplicity is complicated,", "tokens": [400, 550, 286, 528, 281, 2413, 365, 341, 6513, 490, 5424, 46791, 11, 25632, 307, 6179, 11], "temperature": 0.0, "avg_logprob": -0.35348902808295357, "compression_ratio": 1.28099173553719, "no_speech_prob": 0.00027182293706573546}, {"id": 300, "seek": 156828, "start": 1576.16, "end": 1579.76, "text": " but the clarity is worth the fight.", "tokens": [457, 264, 16992, 307, 3163, 264, 2092, 13], "temperature": 0.0, "avg_logprob": -0.35348902808295357, "compression_ratio": 1.28099173553719, "no_speech_prob": 0.00027182293706573546}, {"id": 301, "seek": 156828, "start": 1579.76, "end": 1584.76, "text": " And with that, I'm finished.", "tokens": [400, 365, 300, 11, 286, 478, 4335, 13], "temperature": 0.0, "avg_logprob": -0.35348902808295357, "compression_ratio": 1.28099173553719, "no_speech_prob": 0.00027182293706573546}, {"id": 302, "seek": 156828, "start": 1584.76, "end": 1585.76, "text": " Sorry?", "tokens": [4919, 30], "temperature": 0.0, "avg_logprob": -0.35348902808295357, "compression_ratio": 1.28099173553719, "no_speech_prob": 0.00027182293706573546}, {"id": 303, "seek": 158576, "start": 1585.76, "end": 1599.04, "text": " Are there any questions, I'll try to come with a microphone, if it doesn't work, we'll", "tokens": [2014, 456, 604, 1651, 11, 286, 603, 853, 281, 808, 365, 257, 10952, 11, 498, 309, 1177, 380, 589, 11, 321, 603], "temperature": 0.0, "avg_logprob": -0.3043873126690204, "compression_ratio": 1.4339622641509433, "no_speech_prob": 0.0016737114638090134}, {"id": 304, "seek": 158576, "start": 1599.04, "end": 1601.24, "text": " have to repeat it.", "tokens": [362, 281, 7149, 309, 13], "temperature": 0.0, "avg_logprob": -0.3043873126690204, "compression_ratio": 1.4339622641509433, "no_speech_prob": 0.0016737114638090134}, {"id": 305, "seek": 158576, "start": 1601.24, "end": 1606.68, "text": " Hi, thanks for the talk.", "tokens": [2421, 11, 3231, 337, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.3043873126690204, "compression_ratio": 1.4339622641509433, "no_speech_prob": 0.0016737114638090134}, {"id": 306, "seek": 158576, "start": 1606.68, "end": 1614.72, "text": " I was wondering, do you see any room for automating some of these rules and wisdom that you share", "tokens": [286, 390, 6359, 11, 360, 291, 536, 604, 1808, 337, 3553, 990, 512, 295, 613, 4474, 293, 10712, 300, 291, 2073], "temperature": 0.0, "avg_logprob": -0.3043873126690204, "compression_ratio": 1.4339622641509433, "no_speech_prob": 0.0016737114638090134}, {"id": 307, "seek": 161472, "start": 1614.72, "end": 1619.96, "text": " today, maybe something else as well?", "tokens": [965, 11, 1310, 746, 1646, 382, 731, 30], "temperature": 0.0, "avg_logprob": -0.1792710901616694, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0005056613008491695}, {"id": 308, "seek": 161472, "start": 1619.96, "end": 1622.48, "text": " I don't know, I should think about that.", "tokens": [286, 500, 380, 458, 11, 286, 820, 519, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.1792710901616694, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0005056613008491695}, {"id": 309, "seek": 161472, "start": 1622.48, "end": 1628.72, "text": " Probably some of them, yes, like avoiding having functions or raising a flag if a function", "tokens": [9210, 512, 295, 552, 11, 2086, 11, 411, 20220, 1419, 6828, 420, 11225, 257, 7166, 498, 257, 2445], "temperature": 0.0, "avg_logprob": -0.1792710901616694, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0005056613008491695}, {"id": 310, "seek": 161472, "start": 1628.72, "end": 1635.72, "text": " is accepting a channel, for example, but there are exceptions to that, so that shouldn't", "tokens": [307, 17391, 257, 2269, 11, 337, 1365, 11, 457, 456, 366, 22847, 281, 300, 11, 370, 300, 4659, 380], "temperature": 0.0, "avg_logprob": -0.1792710901616694, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0005056613008491695}, {"id": 311, "seek": 161472, "start": 1635.72, "end": 1636.72, "text": " be blocking.", "tokens": [312, 17776, 13], "temperature": 0.0, "avg_logprob": -0.1792710901616694, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0005056613008491695}, {"id": 312, "seek": 161472, "start": 1636.72, "end": 1642.6000000000001, "text": " There are some others, like the function that is lying to the user is something that depends", "tokens": [821, 366, 512, 2357, 11, 411, 264, 2445, 300, 307, 8493, 281, 264, 4195, 307, 746, 300, 5946], "temperature": 0.0, "avg_logprob": -0.1792710901616694, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0005056613008491695}, {"id": 313, "seek": 164260, "start": 1642.6, "end": 1650.56, "text": " on the implementation, or for example, having a function that accepts five booleans should", "tokens": [322, 264, 11420, 11, 420, 337, 1365, 11, 1419, 257, 2445, 300, 33538, 1732, 748, 4812, 599, 820], "temperature": 0.0, "avg_logprob": -0.2805751013377356, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.0008171220542863011}, {"id": 314, "seek": 164260, "start": 1650.56, "end": 1651.56, "text": " be flagged.", "tokens": [312, 7166, 3004, 13], "temperature": 0.0, "avg_logprob": -0.2805751013377356, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.0008171220542863011}, {"id": 315, "seek": 164260, "start": 1651.56, "end": 1662.36, "text": " So, I see that, I think that it depends on the case, but some of them might be automated.", "tokens": [407, 11, 286, 536, 300, 11, 286, 519, 300, 309, 5946, 322, 264, 1389, 11, 457, 512, 295, 552, 1062, 312, 18473, 13], "temperature": 0.0, "avg_logprob": -0.2805751013377356, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.0008171220542863011}, {"id": 316, "seek": 164260, "start": 1662.36, "end": 1664.56, "text": " Any more questions?", "tokens": [2639, 544, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2805751013377356, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.0008171220542863011}, {"id": 317, "seek": 164260, "start": 1664.56, "end": 1666.84, "text": " No?", "tokens": [883, 30], "temperature": 0.0, "avg_logprob": -0.2805751013377356, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.0008171220542863011}, {"id": 318, "seek": 166684, "start": 1666.84, "end": 1678.52, "text": " Thank you very much.", "tokens": [1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.40368849890572683, "compression_ratio": 0.8, "no_speech_prob": 0.0037398184649646282}, {"id": 319, "seek": 167852, "start": 1678.52, "end": 1698.08, "text": " How was it?", "tokens": [50364, 1012, 390, 309, 30, 51342], "temperature": 0.2, "avg_logprob": -0.8714945656912667, "compression_ratio": 0.5789473684210527, "no_speech_prob": 0.0006459502037614584}], "language": "en"}