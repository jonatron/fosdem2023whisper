{"text": " Hello, like I said, it will be digested because this topic is a little bit, let's say, complex at one side, but from the other side, it will help you to save a lot of time and, of course, money. My name is Alexander Dubrikov. I am CTO of QXAP Company with the Gas Resolverance Manganee, we build with QXAP BE. So I'm an open source enthusiast, I'm involved in many open source projects, Camelia, Frisvich, OpenZeef, Asterisk, and many, many, many else. So QXAP BE is a company based in Amsterdam, it's a company which is behind Homer and Hapk and a lot of other projects which helps you to monitor systems. Of course, we like to make open source projects and a lot of our projects are open sources with good license. So what's the problem we have? Yeah, somebody of you knows about Homer and Homer is a very good, great tool to make monitoring system to store all data, use e-messages, also some local information, but sometimes you also need to store some metrics, some statistics, and therefore you use Prometoids or you use InfluxDB for time series, you use Elasticsearch to store some logs information, some CDRs, and at the end it's mess, because it's so many staff which confuse you, you have to maintain, you have to spend all of time, and in our company we decide what we can do here, how we can help you guys to make your life easier. Then we step back, we view this problem on a different angle, and we decide to make a new application, it's called Quirin. What is about Quirin? Quirin is normally its collector, which you have already Grafana, you have already Prometos, you have already Telegraph, which will send the data in special formats, and we created this application which can read all these formats and store data for you. So of course you can ask what about Homoids, Homoids can also send some information, some SIP information to Quirin, and this can be always stored in the database. But it's not only about Homoids, it's also about these different statistics, what you can receive from your agents, from Prometos agents, from InflexDB, etc. Everything is stored to Quirin, and we created this engine and stored it in the database. So what we did better than in Homo, we wrote a great documentation. So if you go to this website, I trust you guys, this was the number one point, once we started the project, we wrote a great documentation, you can go to our website and you will see all steps, how you can install, how you configure without headaches. So at the end, you know what SIP is normally for us, it's just an event. But what about VEPRTC, it's also an event, because we have different platforms, it can be genres, it can be even free switch and so on, they generated own events in JSON format and how we can collect it. At the end, we decide, so we have only metrics, we have logs, and we have traces. At the end, it's all our information, what we generated in voice over IP stacks, it's related only to these three categories. And of course, it can be generated from different sites. So if we're talking about working Prometos, Elasticsearch, it's already existing with agents which you probably guys already use, and you can generate this data and send to querying. How you can read it, if you use Grafana, probably it's everybody, if you use Grafana, Grafana has already native plugins for local, from KL, temple, API, and we support it as well. So you should not install any additional plugins, it works from the box. We have very cool query stuff which you can extract any data from querying, we'll show them. And of course, you can use any agents what you already exist, this can be Grafana agents, this can be lockstash, vectors, telegraph, and so on, so on. Also, for you, make your life easy, we develop our data explorer, which is already integrated inside of querying, you can use similar to Grafana. And what is very important, we already have a lot of deployment, and it's some big gaming providers, enterprise solutions, and this query, you can use it also for EoT, it's scalable very, very, very well. Now working samples, like I said already, you have these agents, so I don't have too much time, it's an industry standard which you can use its Prometos API, it can be influx CDB insertions, Temporal API, etc. We insert this data to stacks which reads from API points, it can be on open telemetry, it can be local elastic search, etc. It goes to different basket and we insert to database. It's like back end, like database we use Klikals, Klikals is very, you probably heard about Klikals, Klikals is very, very, very performant database, it can be scalable very well linear and horizontal. You can use a lot of some features like UDF functions, etc. You can use also S3 storage if you would like to save your money and if you use AWS or two. And how you can read data? You can read data using this API, it's LOKL, do you know guys what your LOKL is Prometoiskl? No? Okay. LOKL, Prometoiskl is special languages which develop in this company is Prometoisk and it helps you to make some complex statistics, some complex search for logs and information. So it's not like before we use all select from blah, blah, blah, but it's very, very, very limited. So very for the guys from Influx, from Prometoiskl, they develop this promkl language which is very, very flexible and you don't have any limits to do any queries and how it works I will show you. For example, you store data in query and you set labels, how you insert data, you set labels, it's free switch, it's generated fingerprints and in that query you just say, ah, show me everything what is related to free switch and it's very, very fast, lightning fast, display your data here. Second one, what to do if you store Zip messages, you can also set, ah, pipe with results and extract any type of fields from Zip messages, it can be airport, it can be callity, whatever you want. And Janus, for example, Janus generated a lot of events which we can store almost in query and we can extract RTT in labels from this Janus event, but it's not the last. Now what we can do with RTT events, you can just make, unrape and put this information to basket for 10 seconds and immediately from this event information you generate charts, so it's converted automatically. Now you can also do exactly same for elastic storage input or RTT, roundtrip, so information what your switch is generated, you can convert any information what you already stored in database to charts. What about HEPLIFI, Homer, you can also set, ah, let me check all method invites and put to basket for one minute and display what's, how it looks in time series. What about RTTCP, you can also send RTTCP information, you can display most data packet to us and so on. You can send any HEP statistics and display it automatically in query. You can do same with Spromkl, HEPMAP, so about OpenTelemetry, OpenTelemetry it's de facto standard which guys from next room developed and it's already used in many applications. OpenTelemetry it's just internal tracing, you can use our special libraries, you connect it to your application and it will trace all your functions, execution time, these ideas and you will send this open traces to query and you can display how many seconds, microseconds your function execution was taken, what's plugin was, how much time it took, plugin usage, etc. And this is how you can handle and see in, for example in this Janus, it's offer, offer how many microseconds it takes, how many ises taken, etc. This is exact, it's not only about Janus but also you can make, you can also enable OpenTelemetry stuff and you will see how many microseconds, milliseconds takes your query. In service graph you can also make automatically display, it's generated automatically you can check rate and automatically it's generated query and display charts for each node. If you don't like OpenTelemetry and you don't know how to, let's say, connect it to external library we can use eBPF, eBPF is special functions in kernel, you can compile special model which will trace all your functions and generate all traces sent to our collector. Without eBPF we will display, we will present in Berlin for Camelio how you can use OpenTelemetry and make performance optimization. So Janus, we created for Janus, we created special application which is called JAWS. It's a web socket collector which collect all information from Janus and we converted all data to OpenTelemetry. And we can display this data like media, okay, okay, next, next, next. It's ice failure for Janus, the same information you can exactly display here. You can do aggregation type in Janus telemetry, see which nodes Janus proceed, etc. Also very important you can set any alert on any metrics what you send to query using alert manager, what is very important. You can even use fraud detection if you want. So last topic, Open 5G, probably guys you saw yesterday we did some hack. Open 5G stacks, it's stacks which does EMS and all this stuff, it includes Camelio, some TPA engines. In 5 minutes we installed HEPLIFI agents and we sent information to querying, exactly using same stuff. This is device how it looks like, so it's bad quality but at the end it's small mini-computer which has Docker which starts all EMS stacks and we, yeah, using querying, we trace everything. Giovanni sent in Facebook this post, we did it exactly yesterday and it works very, very well and when we did some test he connected to Vicentene, go to another room because Vicentene has only 0.2 watts here I think and goes in the next room and immediately it was displayed what packet was here because his signal is dropped. So if you support, if you like open source and if you like this project, star us, so it's cost nothing but the process like a cookie. So of course sponsor open source projects because without open source our life will be more difficult and we have this block querying there, we have a lot, our team wrote a lot of nice documentation how you use querying, how you can integrate your traces, everything. So it's all examples, all good stuff inside. Yeah, that's it. Like I said, sorry guys, this topic is very, very, very, very complex but it's, I have only 15 minutes. So, yeah, so if you have any questions, go ahead. Yeah. It's very something like Joss for Facebook. Yeah, Joss, it's. Okay, it's Joss for 3C, theoretically, it's because it's open source, you can adapt events but this is what I said, it's each application generated own format. At the end it's a JSON format, so it's JSON events. You can of course adapt and convert it and send to open telemetry. Yeah, you can. Okay, it's about here, you know, so just to repeat, so of course you can send all data to querying and you can create locks and zip information by using open telemetry stuff. What we work in this, Camelia for example, to send all this information in open telemetry you send out using HAP encapsulation and you can collect all locks and information with your dialogs ID with, for example, for zip, you know, and you can store it. So you can select, for example. Yeah, you can select it, exactly in querying, you can click and you will immediately jump to Homer website, you have HomerView where you can display this in chat, in view, zip code view or in table. And the other way around? Yeah, it's awesome, it works also as well, yeah, it's a round-trip integration. Okay, thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.120000000000001, "text": " Hello, like I said, it will be digested because this topic is a little bit, let's say, complex", "tokens": [50364, 2425, 11, 411, 286, 848, 11, 309, 486, 312, 13884, 292, 570, 341, 4829, 307, 257, 707, 857, 11, 718, 311, 584, 11, 3997, 50920], "temperature": 0.0, "avg_logprob": -0.41674099546490295, "compression_ratio": 1.423963133640553, "no_speech_prob": 0.5767538547515869}, {"id": 1, "seek": 0, "start": 11.120000000000001, "end": 17.88, "text": " at one side, but from the other side, it will help you to save a lot of time and, of course,", "tokens": [50920, 412, 472, 1252, 11, 457, 490, 264, 661, 1252, 11, 309, 486, 854, 291, 281, 3155, 257, 688, 295, 565, 293, 11, 295, 1164, 11, 51258], "temperature": 0.0, "avg_logprob": -0.41674099546490295, "compression_ratio": 1.423963133640553, "no_speech_prob": 0.5767538547515869}, {"id": 2, "seek": 0, "start": 17.88, "end": 18.88, "text": " money.", "tokens": [51258, 1460, 13, 51308], "temperature": 0.0, "avg_logprob": -0.41674099546490295, "compression_ratio": 1.423963133640553, "no_speech_prob": 0.5767538547515869}, {"id": 3, "seek": 0, "start": 18.88, "end": 19.88, "text": " My name is Alexander Dubrikov.", "tokens": [51308, 1222, 1315, 307, 14845, 16488, 470, 33516, 13, 51358], "temperature": 0.0, "avg_logprob": -0.41674099546490295, "compression_ratio": 1.423963133640553, "no_speech_prob": 0.5767538547515869}, {"id": 4, "seek": 0, "start": 19.88, "end": 26.72, "text": " I am CTO of QXAP Company with the Gas Resolverance Manganee, we build with QXAP BE.", "tokens": [51358, 286, 669, 383, 15427, 295, 1249, 55, 4715, 13918, 365, 264, 24025, 5015, 401, 331, 719, 376, 17017, 1653, 11, 321, 1322, 365, 1249, 55, 4715, 13513, 13, 51700], "temperature": 0.0, "avg_logprob": -0.41674099546490295, "compression_ratio": 1.423963133640553, "no_speech_prob": 0.5767538547515869}, {"id": 5, "seek": 2672, "start": 26.72, "end": 33.0, "text": " So I'm an open source enthusiast, I'm involved in many open source projects, Camelia, Frisvich,", "tokens": [50364, 407, 286, 478, 364, 1269, 4009, 18076, 525, 11, 286, 478, 3288, 294, 867, 1269, 4009, 4455, 11, 6886, 26091, 11, 1526, 271, 85, 480, 11, 50678], "temperature": 0.0, "avg_logprob": -0.45537507798936633, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.060380078852176666}, {"id": 6, "seek": 2672, "start": 33.0, "end": 38.12, "text": " OpenZeef, Asterisk, and many, many, many else.", "tokens": [50678, 7238, 57, 1653, 69, 11, 316, 3120, 7797, 11, 293, 867, 11, 867, 11, 867, 1646, 13, 50934], "temperature": 0.0, "avg_logprob": -0.45537507798936633, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.060380078852176666}, {"id": 7, "seek": 2672, "start": 38.12, "end": 45.28, "text": " So QXAP BE is a company based in Amsterdam, it's a company which is behind Homer and Hapk", "tokens": [50934, 407, 1249, 55, 4715, 13513, 307, 257, 2237, 2361, 294, 28291, 11, 309, 311, 257, 2237, 597, 307, 2261, 42273, 293, 389, 569, 74, 51292], "temperature": 0.0, "avg_logprob": -0.45537507798936633, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.060380078852176666}, {"id": 8, "seek": 2672, "start": 45.28, "end": 51.96, "text": " and a lot of other projects which helps you to monitor systems.", "tokens": [51292, 293, 257, 688, 295, 661, 4455, 597, 3665, 291, 281, 6002, 3652, 13, 51626], "temperature": 0.0, "avg_logprob": -0.45537507798936633, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.060380078852176666}, {"id": 9, "seek": 5196, "start": 51.96, "end": 58.36, "text": " Of course, we like to make open source projects and a lot of our projects are open sources", "tokens": [50364, 2720, 1164, 11, 321, 411, 281, 652, 1269, 4009, 4455, 293, 257, 688, 295, 527, 4455, 366, 1269, 7139, 50684], "temperature": 0.0, "avg_logprob": -0.29842015413137585, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.02502826601266861}, {"id": 10, "seek": 5196, "start": 58.36, "end": 60.84, "text": " with good license.", "tokens": [50684, 365, 665, 10476, 13, 50808], "temperature": 0.0, "avg_logprob": -0.29842015413137585, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.02502826601266861}, {"id": 11, "seek": 5196, "start": 60.84, "end": 62.760000000000005, "text": " So what's the problem we have?", "tokens": [50808, 407, 437, 311, 264, 1154, 321, 362, 30, 50904], "temperature": 0.0, "avg_logprob": -0.29842015413137585, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.02502826601266861}, {"id": 12, "seek": 5196, "start": 62.760000000000005, "end": 68.96000000000001, "text": " Yeah, somebody of you knows about Homer and Homer is a very good, great tool to make monitoring", "tokens": [50904, 865, 11, 2618, 295, 291, 3255, 466, 42273, 293, 42273, 307, 257, 588, 665, 11, 869, 2290, 281, 652, 11028, 51214], "temperature": 0.0, "avg_logprob": -0.29842015413137585, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.02502826601266861}, {"id": 13, "seek": 5196, "start": 68.96000000000001, "end": 75.56, "text": " system to store all data, use e-messages, also some local information, but sometimes", "tokens": [51214, 1185, 281, 3531, 439, 1412, 11, 764, 308, 12, 76, 442, 1660, 11, 611, 512, 2654, 1589, 11, 457, 2171, 51544], "temperature": 0.0, "avg_logprob": -0.29842015413137585, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.02502826601266861}, {"id": 14, "seek": 5196, "start": 75.56, "end": 80.28, "text": " you also need to store some metrics, some statistics, and therefore you use Prometoids", "tokens": [51544, 291, 611, 643, 281, 3531, 512, 16367, 11, 512, 12523, 11, 293, 4412, 291, 764, 2114, 649, 78, 3742, 51780], "temperature": 0.0, "avg_logprob": -0.29842015413137585, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.02502826601266861}, {"id": 15, "seek": 8028, "start": 80.28, "end": 85.64, "text": " or you use InfluxDB for time series, you use Elasticsearch to store some logs information,", "tokens": [50364, 420, 291, 764, 682, 3423, 2449, 27735, 337, 565, 2638, 11, 291, 764, 2699, 2750, 405, 1178, 281, 3531, 512, 20820, 1589, 11, 50632], "temperature": 0.0, "avg_logprob": -0.2474921646938529, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.03713458403944969}, {"id": 16, "seek": 8028, "start": 85.64, "end": 92.28, "text": " some CDRs, and at the end it's mess, because it's so many staff which confuse you, you", "tokens": [50632, 512, 6743, 49, 82, 11, 293, 412, 264, 917, 309, 311, 2082, 11, 570, 309, 311, 370, 867, 3525, 597, 28584, 291, 11, 291, 50964], "temperature": 0.0, "avg_logprob": -0.2474921646938529, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.03713458403944969}, {"id": 17, "seek": 8028, "start": 92.28, "end": 99.48, "text": " have to maintain, you have to spend all of time, and in our company we decide what we", "tokens": [50964, 362, 281, 6909, 11, 291, 362, 281, 3496, 439, 295, 565, 11, 293, 294, 527, 2237, 321, 4536, 437, 321, 51324], "temperature": 0.0, "avg_logprob": -0.2474921646938529, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.03713458403944969}, {"id": 18, "seek": 8028, "start": 99.48, "end": 104.64, "text": " can do here, how we can help you guys to make your life easier.", "tokens": [51324, 393, 360, 510, 11, 577, 321, 393, 854, 291, 1074, 281, 652, 428, 993, 3571, 13, 51582], "temperature": 0.0, "avg_logprob": -0.2474921646938529, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.03713458403944969}, {"id": 19, "seek": 10464, "start": 104.64, "end": 112.36, "text": " Then we step back, we view this problem on a different angle, and we decide to make a", "tokens": [50364, 1396, 321, 1823, 646, 11, 321, 1910, 341, 1154, 322, 257, 819, 5802, 11, 293, 321, 4536, 281, 652, 257, 50750], "temperature": 0.0, "avg_logprob": -0.2908196920876975, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.10066273808479309}, {"id": 20, "seek": 10464, "start": 112.36, "end": 115.0, "text": " new application, it's called Quirin.", "tokens": [50750, 777, 3861, 11, 309, 311, 1219, 2326, 347, 259, 13, 50882], "temperature": 0.0, "avg_logprob": -0.2908196920876975, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.10066273808479309}, {"id": 21, "seek": 10464, "start": 115.0, "end": 116.0, "text": " What is about Quirin?", "tokens": [50882, 708, 307, 466, 2326, 347, 259, 30, 50932], "temperature": 0.0, "avg_logprob": -0.2908196920876975, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.10066273808479309}, {"id": 22, "seek": 10464, "start": 116.0, "end": 122.44, "text": " Quirin is normally its collector, which you have already Grafana, you have already Prometos,", "tokens": [50932, 2326, 347, 259, 307, 5646, 1080, 23960, 11, 597, 291, 362, 1217, 8985, 69, 2095, 11, 291, 362, 1217, 2114, 649, 329, 11, 51254], "temperature": 0.0, "avg_logprob": -0.2908196920876975, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.10066273808479309}, {"id": 23, "seek": 10464, "start": 122.44, "end": 128.8, "text": " you have already Telegraph, which will send the data in special formats, and we created", "tokens": [51254, 291, 362, 1217, 1989, 6363, 2662, 11, 597, 486, 2845, 264, 1412, 294, 2121, 25879, 11, 293, 321, 2942, 51572], "temperature": 0.0, "avg_logprob": -0.2908196920876975, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.10066273808479309}, {"id": 24, "seek": 12880, "start": 128.8, "end": 135.36, "text": " this application which can read all these formats and store data for you.", "tokens": [50364, 341, 3861, 597, 393, 1401, 439, 613, 25879, 293, 3531, 1412, 337, 291, 13, 50692], "temperature": 0.0, "avg_logprob": -0.2718658674330938, "compression_ratio": 1.6564102564102565, "no_speech_prob": 0.0257840845733881}, {"id": 25, "seek": 12880, "start": 135.36, "end": 142.76000000000002, "text": " So of course you can ask what about Homoids, Homoids can also send some information, some", "tokens": [50692, 407, 295, 1164, 291, 393, 1029, 437, 466, 389, 13395, 3742, 11, 389, 13395, 3742, 393, 611, 2845, 512, 1589, 11, 512, 51062], "temperature": 0.0, "avg_logprob": -0.2718658674330938, "compression_ratio": 1.6564102564102565, "no_speech_prob": 0.0257840845733881}, {"id": 26, "seek": 12880, "start": 142.76000000000002, "end": 147.8, "text": " SIP information to Quirin, and this can be always stored in the database.", "tokens": [51062, 318, 9139, 1589, 281, 2326, 347, 259, 11, 293, 341, 393, 312, 1009, 12187, 294, 264, 8149, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2718658674330938, "compression_ratio": 1.6564102564102565, "no_speech_prob": 0.0257840845733881}, {"id": 27, "seek": 12880, "start": 147.8, "end": 152.48000000000002, "text": " But it's not only about Homoids, it's also about these different statistics, what you", "tokens": [51314, 583, 309, 311, 406, 787, 466, 389, 13395, 3742, 11, 309, 311, 611, 466, 613, 819, 12523, 11, 437, 291, 51548], "temperature": 0.0, "avg_logprob": -0.2718658674330938, "compression_ratio": 1.6564102564102565, "no_speech_prob": 0.0257840845733881}, {"id": 28, "seek": 15248, "start": 152.48, "end": 159.84, "text": " can receive from your agents, from Prometos agents, from InflexDB, etc.", "tokens": [50364, 393, 4774, 490, 428, 12554, 11, 490, 2114, 649, 329, 12554, 11, 490, 11537, 2021, 27735, 11, 5183, 13, 50732], "temperature": 0.0, "avg_logprob": -0.26611845520721084, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.01581091247498989}, {"id": 29, "seek": 15248, "start": 159.84, "end": 167.23999999999998, "text": " Everything is stored to Quirin, and we created this engine and stored it in the database.", "tokens": [50732, 5471, 307, 12187, 281, 2326, 347, 259, 11, 293, 321, 2942, 341, 2848, 293, 12187, 309, 294, 264, 8149, 13, 51102], "temperature": 0.0, "avg_logprob": -0.26611845520721084, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.01581091247498989}, {"id": 30, "seek": 15248, "start": 167.23999999999998, "end": 173.16, "text": " So what we did better than in Homo, we wrote a great documentation.", "tokens": [51102, 407, 437, 321, 630, 1101, 813, 294, 389, 13395, 11, 321, 4114, 257, 869, 14333, 13, 51398], "temperature": 0.0, "avg_logprob": -0.26611845520721084, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.01581091247498989}, {"id": 31, "seek": 15248, "start": 173.16, "end": 179.6, "text": " So if you go to this website, I trust you guys, this was the number one point, once we", "tokens": [51398, 407, 498, 291, 352, 281, 341, 3144, 11, 286, 3361, 291, 1074, 11, 341, 390, 264, 1230, 472, 935, 11, 1564, 321, 51720], "temperature": 0.0, "avg_logprob": -0.26611845520721084, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.01581091247498989}, {"id": 32, "seek": 17960, "start": 179.6, "end": 185.64, "text": " started the project, we wrote a great documentation, you can go to our website and you will see", "tokens": [50364, 1409, 264, 1716, 11, 321, 4114, 257, 869, 14333, 11, 291, 393, 352, 281, 527, 3144, 293, 291, 486, 536, 50666], "temperature": 0.0, "avg_logprob": -0.27322511935452803, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.01720544509589672}, {"id": 33, "seek": 17960, "start": 185.64, "end": 192.76, "text": " all steps, how you can install, how you configure without headaches.", "tokens": [50666, 439, 4439, 11, 577, 291, 393, 3625, 11, 577, 291, 22162, 1553, 35046, 13, 51022], "temperature": 0.0, "avg_logprob": -0.27322511935452803, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.01720544509589672}, {"id": 34, "seek": 17960, "start": 192.76, "end": 197.4, "text": " So at the end, you know what SIP is normally for us, it's just an event.", "tokens": [51022, 407, 412, 264, 917, 11, 291, 458, 437, 318, 9139, 307, 5646, 337, 505, 11, 309, 311, 445, 364, 2280, 13, 51254], "temperature": 0.0, "avg_logprob": -0.27322511935452803, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.01720544509589672}, {"id": 35, "seek": 17960, "start": 197.4, "end": 201.92, "text": " But what about VEPRTC, it's also an event, because we have different platforms, it can", "tokens": [51254, 583, 437, 466, 691, 8929, 49, 18238, 11, 309, 311, 611, 364, 2280, 11, 570, 321, 362, 819, 9473, 11, 309, 393, 51480], "temperature": 0.0, "avg_logprob": -0.27322511935452803, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.01720544509589672}, {"id": 36, "seek": 17960, "start": 201.92, "end": 207.32, "text": " be genres, it can be even free switch and so on, they generated own events in JSON format", "tokens": [51480, 312, 30057, 11, 309, 393, 312, 754, 1737, 3679, 293, 370, 322, 11, 436, 10833, 1065, 3931, 294, 31828, 7877, 51750], "temperature": 0.0, "avg_logprob": -0.27322511935452803, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.01720544509589672}, {"id": 37, "seek": 20732, "start": 207.32, "end": 209.48, "text": " and how we can collect it.", "tokens": [50364, 293, 577, 321, 393, 2500, 309, 13, 50472], "temperature": 0.0, "avg_logprob": -0.2851003192719959, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.006181005854159594}, {"id": 38, "seek": 20732, "start": 209.48, "end": 214.64, "text": " At the end, we decide, so we have only metrics, we have logs, and we have traces.", "tokens": [50472, 1711, 264, 917, 11, 321, 4536, 11, 370, 321, 362, 787, 16367, 11, 321, 362, 20820, 11, 293, 321, 362, 26076, 13, 50730], "temperature": 0.0, "avg_logprob": -0.2851003192719959, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.006181005854159594}, {"id": 39, "seek": 20732, "start": 214.64, "end": 220.12, "text": " At the end, it's all our information, what we generated in voice over IP stacks, it's", "tokens": [50730, 1711, 264, 917, 11, 309, 311, 439, 527, 1589, 11, 437, 321, 10833, 294, 3177, 670, 8671, 30792, 11, 309, 311, 51004], "temperature": 0.0, "avg_logprob": -0.2851003192719959, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.006181005854159594}, {"id": 40, "seek": 20732, "start": 220.12, "end": 222.56, "text": " related only to these three categories.", "tokens": [51004, 4077, 787, 281, 613, 1045, 10479, 13, 51126], "temperature": 0.0, "avg_logprob": -0.2851003192719959, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.006181005854159594}, {"id": 41, "seek": 20732, "start": 222.56, "end": 225.24, "text": " And of course, it can be generated from different sites.", "tokens": [51126, 400, 295, 1164, 11, 309, 393, 312, 10833, 490, 819, 7533, 13, 51260], "temperature": 0.0, "avg_logprob": -0.2851003192719959, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.006181005854159594}, {"id": 42, "seek": 20732, "start": 225.24, "end": 232.04, "text": " So if we're talking about working Prometos, Elasticsearch, it's already existing with agents", "tokens": [51260, 407, 498, 321, 434, 1417, 466, 1364, 2114, 649, 329, 11, 2699, 2750, 405, 1178, 11, 309, 311, 1217, 6741, 365, 12554, 51600], "temperature": 0.0, "avg_logprob": -0.2851003192719959, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.006181005854159594}, {"id": 43, "seek": 23204, "start": 232.04, "end": 238.68, "text": " which you probably guys already use, and you can generate this data and send to querying.", "tokens": [50364, 597, 291, 1391, 1074, 1217, 764, 11, 293, 291, 393, 8460, 341, 1412, 293, 2845, 281, 7083, 1840, 13, 50696], "temperature": 0.0, "avg_logprob": -0.23745518345986644, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.024805279448628426}, {"id": 44, "seek": 23204, "start": 238.68, "end": 244.12, "text": " How you can read it, if you use Grafana, probably it's everybody, if you use Grafana, Grafana", "tokens": [50696, 1012, 291, 393, 1401, 309, 11, 498, 291, 764, 8985, 69, 2095, 11, 1391, 309, 311, 2201, 11, 498, 291, 764, 8985, 69, 2095, 11, 8985, 69, 2095, 50968], "temperature": 0.0, "avg_logprob": -0.23745518345986644, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.024805279448628426}, {"id": 45, "seek": 23204, "start": 244.12, "end": 249.92, "text": " has already native plugins for local, from KL, temple, API, and we support it as well.", "tokens": [50968, 575, 1217, 8470, 33759, 337, 2654, 11, 490, 47991, 11, 10184, 11, 9362, 11, 293, 321, 1406, 309, 382, 731, 13, 51258], "temperature": 0.0, "avg_logprob": -0.23745518345986644, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.024805279448628426}, {"id": 46, "seek": 23204, "start": 249.92, "end": 256.8, "text": " So you should not install any additional plugins, it works from the box.", "tokens": [51258, 407, 291, 820, 406, 3625, 604, 4497, 33759, 11, 309, 1985, 490, 264, 2424, 13, 51602], "temperature": 0.0, "avg_logprob": -0.23745518345986644, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.024805279448628426}, {"id": 47, "seek": 25680, "start": 256.8, "end": 264.76, "text": " We have very cool query stuff which you can extract any data from querying, we'll show", "tokens": [50364, 492, 362, 588, 1627, 14581, 1507, 597, 291, 393, 8947, 604, 1412, 490, 7083, 1840, 11, 321, 603, 855, 50762], "temperature": 0.0, "avg_logprob": -0.3193346543745561, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.01685464382171631}, {"id": 48, "seek": 25680, "start": 264.76, "end": 265.76, "text": " them.", "tokens": [50762, 552, 13, 50812], "temperature": 0.0, "avg_logprob": -0.3193346543745561, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.01685464382171631}, {"id": 49, "seek": 25680, "start": 265.76, "end": 269.6, "text": " And of course, you can use any agents what you already exist, this can be Grafana agents,", "tokens": [50812, 400, 295, 1164, 11, 291, 393, 764, 604, 12554, 437, 291, 1217, 2514, 11, 341, 393, 312, 8985, 69, 2095, 12554, 11, 51004], "temperature": 0.0, "avg_logprob": -0.3193346543745561, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.01685464382171631}, {"id": 50, "seek": 25680, "start": 269.6, "end": 274.12, "text": " this can be lockstash, vectors, telegraph, and so on, so on.", "tokens": [51004, 341, 393, 312, 4017, 372, 1299, 11, 18875, 11, 4304, 34091, 11, 293, 370, 322, 11, 370, 322, 13, 51230], "temperature": 0.0, "avg_logprob": -0.3193346543745561, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.01685464382171631}, {"id": 51, "seek": 25680, "start": 274.12, "end": 280.48, "text": " Also, for you, make your life easy, we develop our data explorer, which is already integrated", "tokens": [51230, 2743, 11, 337, 291, 11, 652, 428, 993, 1858, 11, 321, 1499, 527, 1412, 39680, 11, 597, 307, 1217, 10919, 51548], "temperature": 0.0, "avg_logprob": -0.3193346543745561, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.01685464382171631}, {"id": 52, "seek": 25680, "start": 280.48, "end": 284.6, "text": " inside of querying, you can use similar to Grafana.", "tokens": [51548, 1854, 295, 7083, 1840, 11, 291, 393, 764, 2531, 281, 8985, 69, 2095, 13, 51754], "temperature": 0.0, "avg_logprob": -0.3193346543745561, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.01685464382171631}, {"id": 53, "seek": 28460, "start": 284.6, "end": 291.08000000000004, "text": " And what is very important, we already have a lot of deployment, and it's some big gaming", "tokens": [50364, 400, 437, 307, 588, 1021, 11, 321, 1217, 362, 257, 688, 295, 19317, 11, 293, 309, 311, 512, 955, 9703, 50688], "temperature": 0.0, "avg_logprob": -0.26568310077373797, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.03815886750817299}, {"id": 54, "seek": 28460, "start": 291.08000000000004, "end": 297.20000000000005, "text": " providers, enterprise solutions, and this query, you can use it also for EoT, it's scalable", "tokens": [50688, 11330, 11, 14132, 6547, 11, 293, 341, 14581, 11, 291, 393, 764, 309, 611, 337, 462, 78, 51, 11, 309, 311, 38481, 50994], "temperature": 0.0, "avg_logprob": -0.26568310077373797, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.03815886750817299}, {"id": 55, "seek": 28460, "start": 297.20000000000005, "end": 299.56, "text": " very, very, very well.", "tokens": [50994, 588, 11, 588, 11, 588, 731, 13, 51112], "temperature": 0.0, "avg_logprob": -0.26568310077373797, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.03815886750817299}, {"id": 56, "seek": 28460, "start": 299.56, "end": 304.20000000000005, "text": " Now working samples, like I said already, you have these agents, so I don't have too", "tokens": [51112, 823, 1364, 10938, 11, 411, 286, 848, 1217, 11, 291, 362, 613, 12554, 11, 370, 286, 500, 380, 362, 886, 51344], "temperature": 0.0, "avg_logprob": -0.26568310077373797, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.03815886750817299}, {"id": 57, "seek": 28460, "start": 304.20000000000005, "end": 312.12, "text": " much time, it's an industry standard which you can use its Prometos API, it can be influx", "tokens": [51344, 709, 565, 11, 309, 311, 364, 3518, 3832, 597, 291, 393, 764, 1080, 2114, 649, 329, 9362, 11, 309, 393, 312, 9922, 2449, 51740], "temperature": 0.0, "avg_logprob": -0.26568310077373797, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.03815886750817299}, {"id": 58, "seek": 31212, "start": 312.12, "end": 315.16, "text": " CDB insertions, Temporal API, etc.", "tokens": [50364, 6743, 33, 8969, 626, 11, 8095, 2816, 304, 9362, 11, 5183, 13, 50516], "temperature": 0.0, "avg_logprob": -0.3906073570251465, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.02506835013628006}, {"id": 59, "seek": 31212, "start": 315.16, "end": 325.52, "text": " We insert this data to stacks which reads from API points, it can be on open telemetry,", "tokens": [50516, 492, 8969, 341, 1412, 281, 30792, 597, 15700, 490, 9362, 2793, 11, 309, 393, 312, 322, 1269, 4304, 5537, 627, 11, 51034], "temperature": 0.0, "avg_logprob": -0.3906073570251465, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.02506835013628006}, {"id": 60, "seek": 31212, "start": 325.52, "end": 328.0, "text": " it can be local elastic search, etc.", "tokens": [51034, 309, 393, 312, 2654, 17115, 3164, 11, 5183, 13, 51158], "temperature": 0.0, "avg_logprob": -0.3906073570251465, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.02506835013628006}, {"id": 61, "seek": 31212, "start": 328.0, "end": 333.96, "text": " It goes to different basket and we insert to database.", "tokens": [51158, 467, 1709, 281, 819, 8390, 293, 321, 8969, 281, 8149, 13, 51456], "temperature": 0.0, "avg_logprob": -0.3906073570251465, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.02506835013628006}, {"id": 62, "seek": 31212, "start": 333.96, "end": 340.04, "text": " It's like back end, like database we use Klikals, Klikals is very, you probably heard", "tokens": [51456, 467, 311, 411, 646, 917, 11, 411, 8149, 321, 764, 591, 13462, 1124, 11, 591, 13462, 1124, 307, 588, 11, 291, 1391, 2198, 51760], "temperature": 0.0, "avg_logprob": -0.3906073570251465, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.02506835013628006}, {"id": 63, "seek": 34004, "start": 340.04, "end": 346.52000000000004, "text": " about Klikals, Klikals is very, very, very performant database, it can be scalable very", "tokens": [50364, 466, 591, 13462, 1124, 11, 591, 13462, 1124, 307, 588, 11, 588, 11, 588, 2042, 394, 8149, 11, 309, 393, 312, 38481, 588, 50688], "temperature": 0.0, "avg_logprob": -0.26509857177734375, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.01769634336233139}, {"id": 64, "seek": 34004, "start": 346.52000000000004, "end": 351.40000000000003, "text": " well linear and horizontal.", "tokens": [50688, 731, 8213, 293, 12750, 13, 50932], "temperature": 0.0, "avg_logprob": -0.26509857177734375, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.01769634336233139}, {"id": 65, "seek": 34004, "start": 351.40000000000003, "end": 355.6, "text": " You can use a lot of some features like UDF functions, etc.", "tokens": [50932, 509, 393, 764, 257, 688, 295, 512, 4122, 411, 624, 35, 37, 6828, 11, 5183, 13, 51142], "temperature": 0.0, "avg_logprob": -0.26509857177734375, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.01769634336233139}, {"id": 66, "seek": 34004, "start": 355.6, "end": 364.64000000000004, "text": " You can use also S3 storage if you would like to save your money and if you use AWS or two.", "tokens": [51142, 509, 393, 764, 611, 318, 18, 6725, 498, 291, 576, 411, 281, 3155, 428, 1460, 293, 498, 291, 764, 17650, 420, 732, 13, 51594], "temperature": 0.0, "avg_logprob": -0.26509857177734375, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.01769634336233139}, {"id": 67, "seek": 34004, "start": 364.64000000000004, "end": 366.24, "text": " And how you can read data?", "tokens": [51594, 400, 577, 291, 393, 1401, 1412, 30, 51674], "temperature": 0.0, "avg_logprob": -0.26509857177734375, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.01769634336233139}, {"id": 68, "seek": 36624, "start": 366.24, "end": 372.44, "text": " You can read data using this API, it's LOKL, do you know guys what your LOKL is Prometoiskl?", "tokens": [50364, 509, 393, 1401, 1412, 1228, 341, 9362, 11, 309, 311, 441, 9443, 43, 11, 360, 291, 458, 1074, 437, 428, 441, 9443, 43, 307, 2114, 649, 78, 7797, 75, 30, 50674], "temperature": 0.0, "avg_logprob": -0.31373319055280113, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.1294647455215454}, {"id": 69, "seek": 36624, "start": 372.44, "end": 373.44, "text": " No?", "tokens": [50674, 883, 30, 50724], "temperature": 0.0, "avg_logprob": -0.31373319055280113, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.1294647455215454}, {"id": 70, "seek": 36624, "start": 373.44, "end": 374.44, "text": " Okay.", "tokens": [50724, 1033, 13, 50774], "temperature": 0.0, "avg_logprob": -0.31373319055280113, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.1294647455215454}, {"id": 71, "seek": 36624, "start": 374.44, "end": 382.52, "text": " LOKL, Prometoiskl is special languages which develop in this company is Prometoisk and", "tokens": [50774, 441, 9443, 43, 11, 2114, 649, 78, 7797, 75, 307, 2121, 8650, 597, 1499, 294, 341, 2237, 307, 2114, 649, 78, 7797, 293, 51178], "temperature": 0.0, "avg_logprob": -0.31373319055280113, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.1294647455215454}, {"id": 72, "seek": 36624, "start": 382.52, "end": 389.12, "text": " it helps you to make some complex statistics, some complex search for logs and information.", "tokens": [51178, 309, 3665, 291, 281, 652, 512, 3997, 12523, 11, 512, 3997, 3164, 337, 20820, 293, 1589, 13, 51508], "temperature": 0.0, "avg_logprob": -0.31373319055280113, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.1294647455215454}, {"id": 73, "seek": 36624, "start": 389.12, "end": 393.40000000000003, "text": " So it's not like before we use all select from blah, blah, blah, but it's very, very,", "tokens": [51508, 407, 309, 311, 406, 411, 949, 321, 764, 439, 3048, 490, 12288, 11, 12288, 11, 12288, 11, 457, 309, 311, 588, 11, 588, 11, 51722], "temperature": 0.0, "avg_logprob": -0.31373319055280113, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.1294647455215454}, {"id": 74, "seek": 36624, "start": 393.40000000000003, "end": 394.40000000000003, "text": " very limited.", "tokens": [51722, 588, 5567, 13, 51772], "temperature": 0.0, "avg_logprob": -0.31373319055280113, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.1294647455215454}, {"id": 75, "seek": 39440, "start": 394.4, "end": 399.91999999999996, "text": " So very for the guys from Influx, from Prometoiskl, they develop this promkl language which is", "tokens": [50364, 407, 588, 337, 264, 1074, 490, 682, 3423, 2449, 11, 490, 2114, 649, 78, 7797, 75, 11, 436, 1499, 341, 2234, 7837, 2856, 597, 307, 50640], "temperature": 0.0, "avg_logprob": -0.3059207109304575, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.033914122730493546}, {"id": 76, "seek": 39440, "start": 399.91999999999996, "end": 405.76, "text": " very, very flexible and you don't have any limits to do any queries and how it works", "tokens": [50640, 588, 11, 588, 11358, 293, 291, 500, 380, 362, 604, 10406, 281, 360, 604, 24109, 293, 577, 309, 1985, 50932], "temperature": 0.0, "avg_logprob": -0.3059207109304575, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.033914122730493546}, {"id": 77, "seek": 39440, "start": 405.76, "end": 406.76, "text": " I will show you.", "tokens": [50932, 286, 486, 855, 291, 13, 50982], "temperature": 0.0, "avg_logprob": -0.3059207109304575, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.033914122730493546}, {"id": 78, "seek": 39440, "start": 406.76, "end": 416.56, "text": " For example, you store data in query and you set labels, how you insert data, you set labels,", "tokens": [50982, 1171, 1365, 11, 291, 3531, 1412, 294, 14581, 293, 291, 992, 16949, 11, 577, 291, 8969, 1412, 11, 291, 992, 16949, 11, 51472], "temperature": 0.0, "avg_logprob": -0.3059207109304575, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.033914122730493546}, {"id": 79, "seek": 39440, "start": 416.56, "end": 421.47999999999996, "text": " it's free switch, it's generated fingerprints and in that query you just say, ah, show me", "tokens": [51472, 309, 311, 1737, 3679, 11, 309, 311, 10833, 42170, 293, 294, 300, 14581, 291, 445, 584, 11, 3716, 11, 855, 385, 51718], "temperature": 0.0, "avg_logprob": -0.3059207109304575, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.033914122730493546}, {"id": 80, "seek": 42148, "start": 421.48, "end": 426.44, "text": " everything what is related to free switch and it's very, very fast, lightning fast,", "tokens": [50364, 1203, 437, 307, 4077, 281, 1737, 3679, 293, 309, 311, 588, 11, 588, 2370, 11, 16589, 2370, 11, 50612], "temperature": 0.0, "avg_logprob": -0.30901426639197005, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.011638063006103039}, {"id": 81, "seek": 42148, "start": 426.44, "end": 428.52000000000004, "text": " display your data here.", "tokens": [50612, 4674, 428, 1412, 510, 13, 50716], "temperature": 0.0, "avg_logprob": -0.30901426639197005, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.011638063006103039}, {"id": 82, "seek": 42148, "start": 428.52000000000004, "end": 436.36, "text": " Second one, what to do if you store Zip messages, you can also set, ah, pipe with results and", "tokens": [50716, 5736, 472, 11, 437, 281, 360, 498, 291, 3531, 1176, 647, 7897, 11, 291, 393, 611, 992, 11, 3716, 11, 11240, 365, 3542, 293, 51108], "temperature": 0.0, "avg_logprob": -0.30901426639197005, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.011638063006103039}, {"id": 83, "seek": 42148, "start": 436.36, "end": 441.32, "text": " extract any type of fields from Zip messages, it can be airport, it can be callity, whatever", "tokens": [51108, 8947, 604, 2010, 295, 7909, 490, 1176, 647, 7897, 11, 309, 393, 312, 10155, 11, 309, 393, 312, 818, 507, 11, 2035, 51356], "temperature": 0.0, "avg_logprob": -0.30901426639197005, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.011638063006103039}, {"id": 84, "seek": 42148, "start": 441.32, "end": 443.0, "text": " you want.", "tokens": [51356, 291, 528, 13, 51440], "temperature": 0.0, "avg_logprob": -0.30901426639197005, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.011638063006103039}, {"id": 85, "seek": 42148, "start": 443.0, "end": 447.96000000000004, "text": " And Janus, for example, Janus generated a lot of events which we can store almost in", "tokens": [51440, 400, 4956, 301, 11, 337, 1365, 11, 4956, 301, 10833, 257, 688, 295, 3931, 597, 321, 393, 3531, 1920, 294, 51688], "temperature": 0.0, "avg_logprob": -0.30901426639197005, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.011638063006103039}, {"id": 86, "seek": 44796, "start": 447.96, "end": 457.76, "text": " query and we can extract RTT in labels from this Janus event, but it's not the last.", "tokens": [50364, 14581, 293, 321, 393, 8947, 21797, 51, 294, 16949, 490, 341, 4956, 301, 2280, 11, 457, 309, 311, 406, 264, 1036, 13, 50854], "temperature": 0.0, "avg_logprob": -0.30763170670489876, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.020459236577153206}, {"id": 87, "seek": 44796, "start": 457.76, "end": 462.76, "text": " Now what we can do with RTT events, you can just make, unrape and put this information", "tokens": [50854, 823, 437, 321, 393, 360, 365, 21797, 51, 3931, 11, 291, 393, 445, 652, 11, 517, 424, 494, 293, 829, 341, 1589, 51104], "temperature": 0.0, "avg_logprob": -0.30763170670489876, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.020459236577153206}, {"id": 88, "seek": 44796, "start": 462.76, "end": 468.32, "text": " to basket for 10 seconds and immediately from this event information you generate charts,", "tokens": [51104, 281, 8390, 337, 1266, 3949, 293, 4258, 490, 341, 2280, 1589, 291, 8460, 17767, 11, 51382], "temperature": 0.0, "avg_logprob": -0.30763170670489876, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.020459236577153206}, {"id": 89, "seek": 44796, "start": 468.32, "end": 470.84, "text": " so it's converted automatically.", "tokens": [51382, 370, 309, 311, 16424, 6772, 13, 51508], "temperature": 0.0, "avg_logprob": -0.30763170670489876, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.020459236577153206}, {"id": 90, "seek": 44796, "start": 470.84, "end": 476.12, "text": " Now you can also do exactly same for elastic storage input or RTT, roundtrip, so information", "tokens": [51508, 823, 291, 393, 611, 360, 2293, 912, 337, 17115, 6725, 4846, 420, 21797, 51, 11, 3098, 83, 8400, 11, 370, 1589, 51772], "temperature": 0.0, "avg_logprob": -0.30763170670489876, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.020459236577153206}, {"id": 91, "seek": 47612, "start": 476.12, "end": 480.68, "text": " what your switch is generated, you can convert any information what you already stored in", "tokens": [50364, 437, 428, 3679, 307, 10833, 11, 291, 393, 7620, 604, 1589, 437, 291, 1217, 12187, 294, 50592], "temperature": 0.0, "avg_logprob": -0.33418454621967514, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0046129385009408}, {"id": 92, "seek": 47612, "start": 480.68, "end": 484.16, "text": " database to charts.", "tokens": [50592, 8149, 281, 17767, 13, 50766], "temperature": 0.0, "avg_logprob": -0.33418454621967514, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0046129385009408}, {"id": 93, "seek": 47612, "start": 484.16, "end": 491.16, "text": " What about HEPLIFI, Homer, you can also set, ah, let me check all method invites and put", "tokens": [50766, 708, 466, 389, 8929, 43, 12775, 40, 11, 42273, 11, 291, 393, 611, 992, 11, 3716, 11, 718, 385, 1520, 439, 3170, 35719, 293, 829, 51116], "temperature": 0.0, "avg_logprob": -0.33418454621967514, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0046129385009408}, {"id": 94, "seek": 47612, "start": 491.16, "end": 499.96, "text": " to basket for one minute and display what's, how it looks in time series.", "tokens": [51116, 281, 8390, 337, 472, 3456, 293, 4674, 437, 311, 11, 577, 309, 1542, 294, 565, 2638, 13, 51556], "temperature": 0.0, "avg_logprob": -0.33418454621967514, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0046129385009408}, {"id": 95, "seek": 47612, "start": 499.96, "end": 505.68, "text": " What about RTTCP, you can also send RTTCP information, you can display most data packet", "tokens": [51556, 708, 466, 21797, 51, 20049, 11, 291, 393, 611, 2845, 21797, 51, 20049, 1589, 11, 291, 393, 4674, 881, 1412, 20300, 51842], "temperature": 0.0, "avg_logprob": -0.33418454621967514, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0046129385009408}, {"id": 96, "seek": 50568, "start": 505.68, "end": 507.16, "text": " to us and so on.", "tokens": [50364, 281, 505, 293, 370, 322, 13, 50438], "temperature": 0.0, "avg_logprob": -0.3370016464079269, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.008005933836102486}, {"id": 97, "seek": 50568, "start": 507.16, "end": 514.08, "text": " You can send any HEP statistics and display it automatically in query.", "tokens": [50438, 509, 393, 2845, 604, 389, 8929, 12523, 293, 4674, 309, 6772, 294, 14581, 13, 50784], "temperature": 0.0, "avg_logprob": -0.3370016464079269, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.008005933836102486}, {"id": 98, "seek": 50568, "start": 514.08, "end": 521.44, "text": " You can do same with Spromkl, HEPMAP, so about OpenTelemetry, OpenTelemetry it's de facto", "tokens": [50784, 509, 393, 360, 912, 365, 7702, 298, 7837, 11, 389, 8929, 44, 4715, 11, 370, 466, 7238, 14233, 306, 5537, 627, 11, 7238, 14233, 306, 5537, 627, 309, 311, 368, 42225, 51152], "temperature": 0.0, "avg_logprob": -0.3370016464079269, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.008005933836102486}, {"id": 99, "seek": 50568, "start": 521.44, "end": 527.5600000000001, "text": " standard which guys from next room developed and it's already used in many applications.", "tokens": [51152, 3832, 597, 1074, 490, 958, 1808, 4743, 293, 309, 311, 1217, 1143, 294, 867, 5821, 13, 51458], "temperature": 0.0, "avg_logprob": -0.3370016464079269, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.008005933836102486}, {"id": 100, "seek": 50568, "start": 527.5600000000001, "end": 532.16, "text": " OpenTelemetry it's just internal tracing, you can use our special libraries, you connect", "tokens": [51458, 7238, 14233, 306, 5537, 627, 309, 311, 445, 6920, 25262, 11, 291, 393, 764, 527, 2121, 15148, 11, 291, 1745, 51688], "temperature": 0.0, "avg_logprob": -0.3370016464079269, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.008005933836102486}, {"id": 101, "seek": 53216, "start": 532.16, "end": 537.24, "text": " it to your application and it will trace all your functions, execution time, these ideas", "tokens": [50364, 309, 281, 428, 3861, 293, 309, 486, 13508, 439, 428, 6828, 11, 15058, 565, 11, 613, 3487, 50618], "temperature": 0.0, "avg_logprob": -0.36853802457768864, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.01955471746623516}, {"id": 102, "seek": 53216, "start": 537.24, "end": 544.3199999999999, "text": " and you will send this open traces to query and you can display how many seconds, microseconds", "tokens": [50618, 293, 291, 486, 2845, 341, 1269, 26076, 281, 14581, 293, 291, 393, 4674, 577, 867, 3949, 11, 3123, 37841, 28750, 50972], "temperature": 0.0, "avg_logprob": -0.36853802457768864, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.01955471746623516}, {"id": 103, "seek": 53216, "start": 544.3199999999999, "end": 550.24, "text": " your function execution was taken, what's plugin was, how much time it took, plugin", "tokens": [50972, 428, 2445, 15058, 390, 2726, 11, 437, 311, 23407, 390, 11, 577, 709, 565, 309, 1890, 11, 23407, 51268], "temperature": 0.0, "avg_logprob": -0.36853802457768864, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.01955471746623516}, {"id": 104, "seek": 53216, "start": 550.24, "end": 551.76, "text": " usage, etc.", "tokens": [51268, 14924, 11, 5183, 13, 51344], "temperature": 0.0, "avg_logprob": -0.36853802457768864, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.01955471746623516}, {"id": 105, "seek": 53216, "start": 551.76, "end": 561.3199999999999, "text": " And this is how you can handle and see in, for example in this Janus, it's offer, offer", "tokens": [51344, 400, 341, 307, 577, 291, 393, 4813, 293, 536, 294, 11, 337, 1365, 294, 341, 4956, 301, 11, 309, 311, 2626, 11, 2626, 51822], "temperature": 0.0, "avg_logprob": -0.36853802457768864, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.01955471746623516}, {"id": 106, "seek": 56132, "start": 561.44, "end": 565.6, "text": " how many microseconds it takes, how many ises taken, etc.", "tokens": [50370, 577, 867, 3123, 37841, 28750, 309, 2516, 11, 577, 867, 307, 279, 2726, 11, 5183, 13, 50578], "temperature": 0.0, "avg_logprob": -0.32406044006347656, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.010256171226501465}, {"id": 107, "seek": 56132, "start": 565.6, "end": 573.2, "text": " This is exact, it's not only about Janus but also you can make, you can also enable", "tokens": [50578, 639, 307, 1900, 11, 309, 311, 406, 787, 466, 4956, 301, 457, 611, 291, 393, 652, 11, 291, 393, 611, 9528, 50958], "temperature": 0.0, "avg_logprob": -0.32406044006347656, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.010256171226501465}, {"id": 108, "seek": 56132, "start": 573.2, "end": 582.0, "text": " OpenTelemetry stuff and you will see how many microseconds, milliseconds takes your query.", "tokens": [50958, 7238, 14233, 306, 5537, 627, 1507, 293, 291, 486, 536, 577, 867, 3123, 37841, 28750, 11, 34184, 2516, 428, 14581, 13, 51398], "temperature": 0.0, "avg_logprob": -0.32406044006347656, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.010256171226501465}, {"id": 109, "seek": 56132, "start": 582.0, "end": 585.96, "text": " In service graph you can also make automatically display, it's generated automatically you", "tokens": [51398, 682, 2643, 4295, 291, 393, 611, 652, 6772, 4674, 11, 309, 311, 10833, 6772, 291, 51596], "temperature": 0.0, "avg_logprob": -0.32406044006347656, "compression_ratio": 1.6822916666666667, "no_speech_prob": 0.010256171226501465}, {"id": 110, "seek": 58596, "start": 585.96, "end": 594.2, "text": " can check rate and automatically it's generated query and display charts for each node.", "tokens": [50364, 393, 1520, 3314, 293, 6772, 309, 311, 10833, 14581, 293, 4674, 17767, 337, 1184, 9984, 13, 50776], "temperature": 0.0, "avg_logprob": -0.20572941119854266, "compression_ratio": 1.5919282511210762, "no_speech_prob": 0.00709948455914855}, {"id": 111, "seek": 58596, "start": 594.2, "end": 598.88, "text": " If you don't like OpenTelemetry and you don't know how to, let's say, connect it to external", "tokens": [50776, 759, 291, 500, 380, 411, 7238, 14233, 306, 5537, 627, 293, 291, 500, 380, 458, 577, 281, 11, 718, 311, 584, 11, 1745, 309, 281, 8320, 51010], "temperature": 0.0, "avg_logprob": -0.20572941119854266, "compression_ratio": 1.5919282511210762, "no_speech_prob": 0.00709948455914855}, {"id": 112, "seek": 58596, "start": 598.88, "end": 605.52, "text": " library we can use eBPF, eBPF is special functions in kernel, you can compile special", "tokens": [51010, 6405, 321, 393, 764, 308, 33, 47, 37, 11, 308, 33, 47, 37, 307, 2121, 6828, 294, 28256, 11, 291, 393, 31413, 2121, 51342], "temperature": 0.0, "avg_logprob": -0.20572941119854266, "compression_ratio": 1.5919282511210762, "no_speech_prob": 0.00709948455914855}, {"id": 113, "seek": 58596, "start": 605.52, "end": 613.08, "text": " model which will trace all your functions and generate all traces sent to our collector.", "tokens": [51342, 2316, 597, 486, 13508, 439, 428, 6828, 293, 8460, 439, 26076, 2279, 281, 527, 23960, 13, 51720], "temperature": 0.0, "avg_logprob": -0.20572941119854266, "compression_ratio": 1.5919282511210762, "no_speech_prob": 0.00709948455914855}, {"id": 114, "seek": 61308, "start": 613.08, "end": 618.9200000000001, "text": " Without eBPF we will display, we will present in Berlin for Camelio how you can use OpenTelemetry", "tokens": [50364, 9129, 308, 33, 47, 37, 321, 486, 4674, 11, 321, 486, 1974, 294, 13848, 337, 6886, 338, 1004, 577, 291, 393, 764, 7238, 14233, 306, 5537, 627, 50656], "temperature": 0.0, "avg_logprob": -0.35623288958260185, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.02756829559803009}, {"id": 115, "seek": 61308, "start": 618.9200000000001, "end": 623.9200000000001, "text": " and make performance optimization.", "tokens": [50656, 293, 652, 3389, 19618, 13, 50906], "temperature": 0.0, "avg_logprob": -0.35623288958260185, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.02756829559803009}, {"id": 116, "seek": 61308, "start": 623.9200000000001, "end": 630.8000000000001, "text": " So Janus, we created for Janus, we created special application which is called JAWS.", "tokens": [50906, 407, 4956, 301, 11, 321, 2942, 337, 4956, 301, 11, 321, 2942, 2121, 3861, 597, 307, 1219, 26401, 12508, 13, 51250], "temperature": 0.0, "avg_logprob": -0.35623288958260185, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.02756829559803009}, {"id": 117, "seek": 61308, "start": 630.8000000000001, "end": 636.8000000000001, "text": " It's a web socket collector which collect all information from Janus and we converted", "tokens": [51250, 467, 311, 257, 3670, 19741, 23960, 597, 2500, 439, 1589, 490, 4956, 301, 293, 321, 16424, 51550], "temperature": 0.0, "avg_logprob": -0.35623288958260185, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.02756829559803009}, {"id": 118, "seek": 61308, "start": 636.8000000000001, "end": 639.4000000000001, "text": " all data to OpenTelemetry.", "tokens": [51550, 439, 1412, 281, 7238, 14233, 306, 5537, 627, 13, 51680], "temperature": 0.0, "avg_logprob": -0.35623288958260185, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.02756829559803009}, {"id": 119, "seek": 63940, "start": 639.4, "end": 644.8, "text": " And we can display this data like media, okay, okay, next, next, next.", "tokens": [50364, 400, 321, 393, 4674, 341, 1412, 411, 3021, 11, 1392, 11, 1392, 11, 958, 11, 958, 11, 958, 13, 50634], "temperature": 0.0, "avg_logprob": -0.32250307986610816, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.12124549597501755}, {"id": 120, "seek": 63940, "start": 644.8, "end": 650.4, "text": " It's ice failure for Janus, the same information you can exactly display here.", "tokens": [50634, 467, 311, 4435, 7763, 337, 4956, 301, 11, 264, 912, 1589, 291, 393, 2293, 4674, 510, 13, 50914], "temperature": 0.0, "avg_logprob": -0.32250307986610816, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.12124549597501755}, {"id": 121, "seek": 63940, "start": 650.4, "end": 657.3199999999999, "text": " You can do aggregation type in Janus telemetry, see which nodes Janus proceed, etc.", "tokens": [50914, 509, 393, 360, 16743, 399, 2010, 294, 4956, 301, 4304, 5537, 627, 11, 536, 597, 13891, 4956, 301, 8991, 11, 5183, 13, 51260], "temperature": 0.0, "avg_logprob": -0.32250307986610816, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.12124549597501755}, {"id": 122, "seek": 63940, "start": 657.3199999999999, "end": 662.8, "text": " Also very important you can set any alert on any metrics what you send to query using", "tokens": [51260, 2743, 588, 1021, 291, 393, 992, 604, 9615, 322, 604, 16367, 437, 291, 2845, 281, 14581, 1228, 51534], "temperature": 0.0, "avg_logprob": -0.32250307986610816, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.12124549597501755}, {"id": 123, "seek": 63940, "start": 662.8, "end": 666.3199999999999, "text": " alert manager, what is very important.", "tokens": [51534, 9615, 6598, 11, 437, 307, 588, 1021, 13, 51710], "temperature": 0.0, "avg_logprob": -0.32250307986610816, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.12124549597501755}, {"id": 124, "seek": 66632, "start": 666.32, "end": 670.5200000000001, "text": " You can even use fraud detection if you want.", "tokens": [50364, 509, 393, 754, 764, 14560, 17784, 498, 291, 528, 13, 50574], "temperature": 0.0, "avg_logprob": -0.35138238271077477, "compression_ratio": 1.3419354838709678, "no_speech_prob": 0.044318798929452896}, {"id": 125, "seek": 66632, "start": 670.5200000000001, "end": 680.8000000000001, "text": " So last topic, Open 5G, probably guys you saw yesterday we did some hack.", "tokens": [50574, 407, 1036, 4829, 11, 7238, 1025, 38, 11, 1391, 1074, 291, 1866, 5186, 321, 630, 512, 10339, 13, 51088], "temperature": 0.0, "avg_logprob": -0.35138238271077477, "compression_ratio": 1.3419354838709678, "no_speech_prob": 0.044318798929452896}, {"id": 126, "seek": 66632, "start": 680.8000000000001, "end": 688.48, "text": " Open 5G stacks, it's stacks which does EMS and all this stuff, it includes Camelio, some", "tokens": [51088, 7238, 1025, 38, 30792, 11, 309, 311, 30792, 597, 775, 462, 10288, 293, 439, 341, 1507, 11, 309, 5974, 6886, 338, 1004, 11, 512, 51472], "temperature": 0.0, "avg_logprob": -0.35138238271077477, "compression_ratio": 1.3419354838709678, "no_speech_prob": 0.044318798929452896}, {"id": 127, "seek": 68848, "start": 688.48, "end": 689.64, "text": " TPA engines.", "tokens": [50364, 314, 10297, 12982, 13, 50422], "temperature": 0.0, "avg_logprob": -0.4181542063868323, "compression_ratio": 1.4366197183098592, "no_speech_prob": 0.14887553453445435}, {"id": 128, "seek": 68848, "start": 689.64, "end": 698.72, "text": " In 5 minutes we installed HEPLIFI agents and we sent information to querying, exactly using", "tokens": [50422, 682, 1025, 2077, 321, 8899, 389, 8929, 43, 12775, 40, 12554, 293, 321, 2279, 1589, 281, 7083, 1840, 11, 2293, 1228, 50876], "temperature": 0.0, "avg_logprob": -0.4181542063868323, "compression_ratio": 1.4366197183098592, "no_speech_prob": 0.14887553453445435}, {"id": 129, "seek": 68848, "start": 698.72, "end": 699.72, "text": " same stuff.", "tokens": [50876, 912, 1507, 13, 50926], "temperature": 0.0, "avg_logprob": -0.4181542063868323, "compression_ratio": 1.4366197183098592, "no_speech_prob": 0.14887553453445435}, {"id": 130, "seek": 68848, "start": 699.72, "end": 706.24, "text": " This is device how it looks like, so it's bad quality but at the end it's small mini-computer", "tokens": [50926, 639, 307, 4302, 577, 309, 1542, 411, 11, 370, 309, 311, 1578, 3125, 457, 412, 264, 917, 309, 311, 1359, 8382, 12, 1112, 13849, 51252], "temperature": 0.0, "avg_logprob": -0.4181542063868323, "compression_ratio": 1.4366197183098592, "no_speech_prob": 0.14887553453445435}, {"id": 131, "seek": 68848, "start": 706.24, "end": 717.2, "text": " which has Docker which starts all EMS stacks and we, yeah, using querying, we trace everything.", "tokens": [51252, 597, 575, 33772, 597, 3719, 439, 462, 10288, 30792, 293, 321, 11, 1338, 11, 1228, 7083, 1840, 11, 321, 13508, 1203, 13, 51800], "temperature": 0.0, "avg_logprob": -0.4181542063868323, "compression_ratio": 1.4366197183098592, "no_speech_prob": 0.14887553453445435}, {"id": 132, "seek": 71720, "start": 718.2, "end": 727.1600000000001, "text": " Giovanni sent in Facebook this post, we did it exactly yesterday and it works very, very", "tokens": [50414, 47089, 35832, 2279, 294, 4384, 341, 2183, 11, 321, 630, 309, 2293, 5186, 293, 309, 1985, 588, 11, 588, 50862], "temperature": 0.0, "avg_logprob": -0.3855979118818118, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.14174242317676544}, {"id": 133, "seek": 71720, "start": 727.1600000000001, "end": 734.48, "text": " well and when we did some test he connected to Vicentene, go to another room because Vicentene", "tokens": [50862, 731, 293, 562, 321, 630, 512, 1500, 415, 4582, 281, 33316, 317, 1450, 11, 352, 281, 1071, 1808, 570, 33316, 317, 1450, 51228], "temperature": 0.0, "avg_logprob": -0.3855979118818118, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.14174242317676544}, {"id": 134, "seek": 71720, "start": 734.48, "end": 740.0400000000001, "text": " has only 0.2 watts here I think and goes in the next room and immediately it was displayed", "tokens": [51228, 575, 787, 1958, 13, 17, 31247, 510, 286, 519, 293, 1709, 294, 264, 958, 1808, 293, 4258, 309, 390, 16372, 51506], "temperature": 0.0, "avg_logprob": -0.3855979118818118, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.14174242317676544}, {"id": 135, "seek": 71720, "start": 740.0400000000001, "end": 743.1600000000001, "text": " what packet was here because his signal is dropped.", "tokens": [51506, 437, 20300, 390, 510, 570, 702, 6358, 307, 8119, 13, 51662], "temperature": 0.0, "avg_logprob": -0.3855979118818118, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.14174242317676544}, {"id": 136, "seek": 74316, "start": 743.16, "end": 748.92, "text": " So if you support, if you like open source and if you like this project, star us, so", "tokens": [50364, 407, 498, 291, 1406, 11, 498, 291, 411, 1269, 4009, 293, 498, 291, 411, 341, 1716, 11, 3543, 505, 11, 370, 50652], "temperature": 0.0, "avg_logprob": -0.2825081883644571, "compression_ratio": 1.7665198237885462, "no_speech_prob": 0.012228268198668957}, {"id": 137, "seek": 74316, "start": 748.92, "end": 753.64, "text": " it's cost nothing but the process like a cookie.", "tokens": [50652, 309, 311, 2063, 1825, 457, 264, 1399, 411, 257, 14417, 13, 50888], "temperature": 0.0, "avg_logprob": -0.2825081883644571, "compression_ratio": 1.7665198237885462, "no_speech_prob": 0.012228268198668957}, {"id": 138, "seek": 74316, "start": 753.64, "end": 759.92, "text": " So of course sponsor open source projects because without open source our life will be", "tokens": [50888, 407, 295, 1164, 16198, 1269, 4009, 4455, 570, 1553, 1269, 4009, 527, 993, 486, 312, 51202], "temperature": 0.0, "avg_logprob": -0.2825081883644571, "compression_ratio": 1.7665198237885462, "no_speech_prob": 0.012228268198668957}, {"id": 139, "seek": 74316, "start": 759.92, "end": 765.7199999999999, "text": " more difficult and we have this block querying there, we have a lot, our team wrote a lot", "tokens": [51202, 544, 2252, 293, 321, 362, 341, 3461, 7083, 1840, 456, 11, 321, 362, 257, 688, 11, 527, 1469, 4114, 257, 688, 51492], "temperature": 0.0, "avg_logprob": -0.2825081883644571, "compression_ratio": 1.7665198237885462, "no_speech_prob": 0.012228268198668957}, {"id": 140, "seek": 74316, "start": 765.7199999999999, "end": 772.12, "text": " of nice documentation how you use querying, how you can integrate your traces, everything.", "tokens": [51492, 295, 1481, 14333, 577, 291, 764, 7083, 1840, 11, 577, 291, 393, 13365, 428, 26076, 11, 1203, 13, 51812], "temperature": 0.0, "avg_logprob": -0.2825081883644571, "compression_ratio": 1.7665198237885462, "no_speech_prob": 0.012228268198668957}, {"id": 141, "seek": 77212, "start": 772.2, "end": 775.5600000000001, "text": " So it's all examples, all good stuff inside.", "tokens": [50368, 407, 309, 311, 439, 5110, 11, 439, 665, 1507, 1854, 13, 50536], "temperature": 0.0, "avg_logprob": -0.5101083517074585, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.07148163765668869}, {"id": 142, "seek": 77212, "start": 777.16, "end": 778.16, "text": " Yeah, that's it.", "tokens": [50616, 865, 11, 300, 311, 309, 13, 50666], "temperature": 0.0, "avg_logprob": -0.5101083517074585, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.07148163765668869}, {"id": 143, "seek": 77212, "start": 783.92, "end": 789.0, "text": " Like I said, sorry guys, this topic is very, very, very, very complex but it's, I have", "tokens": [50954, 1743, 286, 848, 11, 2597, 1074, 11, 341, 4829, 307, 588, 11, 588, 11, 588, 11, 588, 3997, 457, 309, 311, 11, 286, 362, 51208], "temperature": 0.0, "avg_logprob": -0.5101083517074585, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.07148163765668869}, {"id": 144, "seek": 77212, "start": 789.0, "end": 790.0, "text": " only 15 minutes.", "tokens": [51208, 787, 2119, 2077, 13, 51258], "temperature": 0.0, "avg_logprob": -0.5101083517074585, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.07148163765668869}, {"id": 145, "seek": 77212, "start": 790.8, "end": 793.88, "text": " So, yeah, so if you have any questions, go ahead.", "tokens": [51298, 407, 11, 1338, 11, 370, 498, 291, 362, 604, 1651, 11, 352, 2286, 13, 51452], "temperature": 0.0, "avg_logprob": -0.5101083517074585, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.07148163765668869}, {"id": 146, "seek": 77212, "start": 795.96, "end": 796.48, "text": " Yeah.", "tokens": [51556, 865, 13, 51582], "temperature": 0.0, "avg_logprob": -0.5101083517074585, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.07148163765668869}, {"id": 147, "seek": 77212, "start": 796.48, "end": 798.8, "text": " It's very something like Joss for Facebook.", "tokens": [51582, 467, 311, 588, 746, 411, 508, 772, 337, 4384, 13, 51698], "temperature": 0.0, "avg_logprob": -0.5101083517074585, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.07148163765668869}, {"id": 148, "seek": 77212, "start": 800.48, "end": 801.48, "text": " Yeah, Joss, it's.", "tokens": [51782, 865, 11, 508, 772, 11, 309, 311, 13, 51832], "temperature": 0.0, "avg_logprob": -0.5101083517074585, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.07148163765668869}, {"id": 149, "seek": 80212, "start": 803.12, "end": 807.84, "text": " Okay, it's Joss for 3C, theoretically, it's because it's open source, you can adapt events", "tokens": [50414, 1033, 11, 309, 311, 508, 772, 337, 805, 34, 11, 29400, 11, 309, 311, 570, 309, 311, 1269, 4009, 11, 291, 393, 6231, 3931, 50650], "temperature": 0.0, "avg_logprob": -0.37747845704528105, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.017134958878159523}, {"id": 150, "seek": 80212, "start": 807.84, "end": 814.28, "text": " but this is what I said, it's each application generated own format.", "tokens": [50650, 457, 341, 307, 437, 286, 848, 11, 309, 311, 1184, 3861, 10833, 1065, 7877, 13, 50972], "temperature": 0.0, "avg_logprob": -0.37747845704528105, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.017134958878159523}, {"id": 151, "seek": 80212, "start": 814.28, "end": 817.24, "text": " At the end it's a JSON format, so it's JSON events.", "tokens": [50972, 1711, 264, 917, 309, 311, 257, 31828, 7877, 11, 370, 309, 311, 31828, 3931, 13, 51120], "temperature": 0.0, "avg_logprob": -0.37747845704528105, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.017134958878159523}, {"id": 152, "seek": 80212, "start": 817.24, "end": 820.04, "text": " You can of course adapt and convert it and send to open telemetry.", "tokens": [51120, 509, 393, 295, 1164, 6231, 293, 7620, 309, 293, 2845, 281, 1269, 4304, 5537, 627, 13, 51260], "temperature": 0.0, "avg_logprob": -0.37747845704528105, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.017134958878159523}, {"id": 153, "seek": 80212, "start": 820.04, "end": 821.04, "text": " Yeah, you can.", "tokens": [51260, 865, 11, 291, 393, 13, 51310], "temperature": 0.0, "avg_logprob": -0.37747845704528105, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.017134958878159523}, {"id": 154, "seek": 82104, "start": 821.4399999999999, "end": 836.3199999999999, "text": " Okay, it's about here, you know, so just to repeat, so of course you can send all data", "tokens": [50384, 1033, 11, 309, 311, 466, 510, 11, 291, 458, 11, 370, 445, 281, 7149, 11, 370, 295, 1164, 291, 393, 2845, 439, 1412, 51128], "temperature": 0.0, "avg_logprob": -0.33764049368844906, "compression_ratio": 1.5529411764705883, "no_speech_prob": 0.012156752869486809}, {"id": 155, "seek": 82104, "start": 836.3199999999999, "end": 843.8, "text": " to querying and you can create locks and zip information by using open telemetry stuff.", "tokens": [51128, 281, 7083, 1840, 293, 291, 393, 1884, 20703, 293, 20730, 1589, 538, 1228, 1269, 4304, 5537, 627, 1507, 13, 51502], "temperature": 0.0, "avg_logprob": -0.33764049368844906, "compression_ratio": 1.5529411764705883, "no_speech_prob": 0.012156752869486809}, {"id": 156, "seek": 82104, "start": 843.8, "end": 849.04, "text": " What we work in this, Camelia for example, to send all this information in open telemetry", "tokens": [51502, 708, 321, 589, 294, 341, 11, 6886, 26091, 337, 1365, 11, 281, 2845, 439, 341, 1589, 294, 1269, 4304, 5537, 627, 51764], "temperature": 0.0, "avg_logprob": -0.33764049368844906, "compression_ratio": 1.5529411764705883, "no_speech_prob": 0.012156752869486809}, {"id": 157, "seek": 84904, "start": 849.04, "end": 855.1999999999999, "text": " you send out using HAP encapsulation and you can collect all locks and information with", "tokens": [50364, 291, 2845, 484, 1228, 389, 4715, 38745, 2776, 293, 291, 393, 2500, 439, 20703, 293, 1589, 365, 50672], "temperature": 0.0, "avg_logprob": -0.39173527767783717, "compression_ratio": 1.68, "no_speech_prob": 0.024426095187664032}, {"id": 158, "seek": 84904, "start": 855.1999999999999, "end": 859.04, "text": " your dialogs ID with, for example, for zip, you know, and you can store it.", "tokens": [50672, 428, 19308, 82, 7348, 365, 11, 337, 1365, 11, 337, 20730, 11, 291, 458, 11, 293, 291, 393, 3531, 309, 13, 50864], "temperature": 0.0, "avg_logprob": -0.39173527767783717, "compression_ratio": 1.68, "no_speech_prob": 0.024426095187664032}, {"id": 159, "seek": 84904, "start": 859.04, "end": 860.52, "text": " So you can select, for example.", "tokens": [50864, 407, 291, 393, 3048, 11, 337, 1365, 13, 50938], "temperature": 0.0, "avg_logprob": -0.39173527767783717, "compression_ratio": 1.68, "no_speech_prob": 0.024426095187664032}, {"id": 160, "seek": 84904, "start": 860.52, "end": 864.7199999999999, "text": " Yeah, you can select it, exactly in querying, you can click and you will immediately jump", "tokens": [50938, 865, 11, 291, 393, 3048, 309, 11, 2293, 294, 7083, 1840, 11, 291, 393, 2052, 293, 291, 486, 4258, 3012, 51148], "temperature": 0.0, "avg_logprob": -0.39173527767783717, "compression_ratio": 1.68, "no_speech_prob": 0.024426095187664032}, {"id": 161, "seek": 84904, "start": 864.7199999999999, "end": 873.0799999999999, "text": " to Homer website, you have HomerView where you can display this in chat, in view, zip", "tokens": [51148, 281, 42273, 3144, 11, 291, 362, 42273, 30203, 689, 291, 393, 4674, 341, 294, 5081, 11, 294, 1910, 11, 20730, 51566], "temperature": 0.0, "avg_logprob": -0.39173527767783717, "compression_ratio": 1.68, "no_speech_prob": 0.024426095187664032}, {"id": 162, "seek": 84904, "start": 873.0799999999999, "end": 874.76, "text": " code view or in table.", "tokens": [51566, 3089, 1910, 420, 294, 3199, 13, 51650], "temperature": 0.0, "avg_logprob": -0.39173527767783717, "compression_ratio": 1.68, "no_speech_prob": 0.024426095187664032}, {"id": 163, "seek": 84904, "start": 876.3199999999999, "end": 877.5999999999999, "text": " And the other way around?", "tokens": [51728, 400, 264, 661, 636, 926, 30, 51792], "temperature": 0.0, "avg_logprob": -0.39173527767783717, "compression_ratio": 1.68, "no_speech_prob": 0.024426095187664032}, {"id": 164, "seek": 87760, "start": 877.6, "end": 881.36, "text": " Yeah, it's awesome, it works also as well, yeah, it's a round-trip integration.", "tokens": [50364, 865, 11, 309, 311, 3476, 11, 309, 1985, 611, 382, 731, 11, 1338, 11, 309, 311, 257, 3098, 12, 83, 8400, 10980, 13, 50552], "temperature": 0.0, "avg_logprob": -0.5018513419411399, "compression_ratio": 1.1162790697674418, "no_speech_prob": 0.014124066568911076}, {"id": 165, "seek": 87760, "start": 883.9200000000001, "end": 885.24, "text": " Okay, thank you.", "tokens": [50680, 1033, 11, 1309, 291, 13, 50746], "temperature": 0.0, "avg_logprob": -0.5018513419411399, "compression_ratio": 1.1162790697674418, "no_speech_prob": 0.014124066568911076}], "language": "en"}