{"text": " Yes, Fernando is fine. Fernando, he's going to talk about using Rust for your network management tools. Take it away. All right. Thank you. All right. So, welcome everyone. My name is Fernando. I'm a senior software engineer at Drehat. I work for the Networking Services Team, mainly in focus on network management tools, and today we are going to talk what was our journey, building a Rust tool for network management. So, okay. We did not start with Rust. We have started with Python, but after some time we decide that we wanted to shift to Rust. So, this is two talks in one. One is how we did build the project in Rust, and what we learned when moving from Python to Rust. Okay. So, network management. What's network management? Basically, it's all the operations that you do to configure your networking. Roots, interfaces, DNS, firewalling, whatever you do, it's network management. So, it's a process that is quite complex because it requires a lot of coordination between user space and kernel space. We need to check when we get notification for kernel space because all the tools could modify the network status. We also need to communicate with kernel in order to configure stuff. So, it's a quite complex task. There is already a tool which is network manager. It's by default, the tool that is in almost all situations used for managing your Linux network configuration, and we were willing to use it and we were willing to build in top of a network manager because implementing everything was really, really complex. So, we created NMS state, and NMS state is a tool that communicates with network manager and it's a library with a command line tool, and allow us to configure the network with using declarative states. So, you can define what do you want, and you don't need to care about how is network manager or how is the kernel doing, and what's going to do or what are the dependencies. You don't need to care about any of that. NMS state is going to manage it, so it makes everything easier. So, as I say, we started to build NMS state in Python, and one day we noticed that a lot of our users were willing to chip a binary and not Python, don't use the Python environment, and well, there were also some performance issues because we need to do a lot of operations. So, we decided to give it a try to REST, and we have a problem is that we have a library and a binary, and we needed to move both of them to REST, and also we already have a big base of users. So, we could not break them, and we need to do it in a way that we are going to support, we need to support all the features that we already did in Python. So, well, we created our own NMS state library in REST, I will tell you how, and also the NMS state CTL tool, which is the command line tool. All right. So, the first thing is that we are using Jamel files and JSON files, and we are parsing them. So, in Python, this was quite trivial with an schema, and we needed to find a way to do it. In Python, we were using dictionary, so the user could create a dictionary, and it was using a Jamel library, it was quite trivial to convert that Jamel into a dictionary, and we needed something in REST to do this. So, we end up looking at CD. CD is a framework for serializing and deserializing REST data structures efficiently and generically we use it for Jamel and JSON, but it supports other formats. This allows us to keep our declarative state, keep our API, so that was pretty good, and we noticed that CD allow us to implement our own serializers and deserializers. So, that was also a big plus because we could do validation steps and simplify the validation work when getting the configuration file from the user, and then there were a lot of decorators on server, so it was quite good for creating aliases, for creating multiple helper functions, and also some conditional deserialization and serializations. So, here's an example. For example, this is a interface state for a general bond, and we basically define it is app, it is have an IPv4 address with this address, with this prefix length, and it is enabled, and then we define the link aggregation options. So, we have the mod options and the ports. One really good thing that we have is that we have a partial editing. So, you can define what you want to change, and we are going to merge it with what you already have on configure on the system. About the decorators, as you can see there, we were able to use the decorator for example, accepting numbers as a string, accepting strings, accepting only the number, custom strings, creating alias, renaming, yeah, all of that, and it was quite good. So, okay. We communicate with Neville Manager and we communicate with Neville Manager to configure the network state, and we have a problem is that before we were using the Lebanon bindings, Python bindings, and they were not available in trust, and we tried to create a trust bindings, but it was quite complex because they use gObject and we did not have gObject, and it was a big mess, but we noticed that Neville Manager is providing a Divas API. So, we say, okay, let's use Divas then, and we noticed that there is a create which is Zitabas, and with Zitabas, we were able to communicate with Neville Manager using the Divas API, and with Zitabas, and we were able to encode the data structures that we were using to communicate with Neville Manager and configure the settings that we wanted. So, using this, we solved one of the problems, which is telling Neville Manager what we want to do, and also fetching what already Neville Manager have, which is also important because, all right, there are some options that maybe we do not want to overwrite because the user configured it that way, and for patch editing, that is important. We need to know what the user configured and what the user was to modify. So, okay, one problem solved. Then, we have another problem. So, Neville Manager does not provide at all real-time information from kernel, and we needed that because we also do verification. So, when you configure something, NMS state do a verification step, which what it does is compare what the user defined, which what is configured on the system. We have a problem because Neville Manager was not providing real-time information, and sometimes it took quite sometimes to get the information that we wanted, and we were having some problems on the verification. So, we were looking for a library, and we did not find any library that certified our requirements, but we noticed that there is already a Rastnet link library, and that link is a kernel API for communication between user place and kernel, also, I think, between kernel components, and it was perfect. We could use Rastnet link, which is an existing library, to build another tool, which is NISPOR. So, NISPOR only queries information from kernel, and show you in a jammel file, or basically, proper data structures. Well, it was quite good because we started to contribute to Rastnet link, because Rastnet link was an independent project, and they didn't support everything. So, we were able to help there, and currently, a lot of people use Rastnet link, and it's a quite big project, and probably the one that most of the people use when need to work with NEL link and REST. So, we have one more problem. Okay. Now, we have network manager working, we have verification working, validation working, we can read the configuration, we can do a lot of stuff. But then, networking is complex, and there is one thing that is called OBS, OBSDB, and network manager configure OBS, right? But they do not configure global OBSDB settings. And that was a problem because we wanted to do that. So, how we did? We basically started to use sockets, and using the Rast SDD library for stream sockets, we were able to communicate with OBSDB send petitions, read what they already have stored on the OBSDB, and configure whatever OBSDB settings the user want to configure. So, we created our own set of JSON or using set of JSON libraries, we created our own JSON RPC to communicate with OBSDB. This is internal of NMS state. We have considered to put it on a separate crate, but we did not yet. Then, we had another problem. Okay. I promise this will end. We are going to have a solution. It will stop at some point. So, we had users, the users were using our Python library, and some of them were willing to move to Rast, some of them were willing to move to Goland, but we were already developing a Rast solution. And some of them didn't want to move from the Python code to Rast. So, what we did is create bindings, and we create plenty of them. First of all, we created C bindings. So, C users could use the Rast library. Then, from the C bindings, we created the Python and Goland bindings. And finally, one of the other problem that we had is that we got a huge integration test base, and we wanted to reuse them. So, with the Python bindings, we were able to integrate the Python integration test that we had into our Rast library. So, it was quite cool because we were able to start building the new Rast NMS date, but at the same time, using the Python integration test. And this way, we were sure that we were not breaking any existing use case that we already support. So, that's it. It was a success. And we are quite proud because most of the people that were using it liked the idea, and even the ones that did not care about if you use Python or Rast, we're happy because the change was completely transparent for the final user. If you were using Python, nothing will change for you. The code is the same. You didn't need to do anything different. So, it will be a transparent update. And if you are using Python and are willing to use Rast, okay, you need to change your code. But basically, the API is the same. So, well, you were able to use the same Jamel files, and the same JSON files, and everything will work. So, we got a lot of adoptions, and right now, the user base of NMS date is still growing, and we are quite happy. Also, it was recreated goal and bindings because OpenShift people and Kubernetes people were wiling to use it and it's written in goal and bindings. So, we provided them with goal and bindings, and they really liked it. So, yeah, it was a success story. Yeah. So, basically, that was our journey. I would like to hear, I think we have time for questions. So, please, as whatever you want, I promise you there are no dumb questions. So, thank you very much. All right, any question? Okay. I wondered what your experience was in terms of time to implement in Rust versus Python. All right. From a developer point of view. I think it took us around two years, two developers mainly working on it. It was full-time. It was a long journey, but it helped us a lot having the Python integration test working with the new library, because we were sure that we were not breaking the existing cases and speed up the things a little bit. Absolutely. Do you have a feeling for how long it would have taken you if you had re-implemented it in Python? I mean, I know that's not really a thing, but roughly how long if you had said right? Going back to Python. No, if you had said, right, we've got it in Python, but for no good reason, we're going to rewrite it from scratch in Python to make it cleaner, let's say. Just as like, how long does it take to write something in Python versus Rust or maybe it's not possible to guess? Well, I think it depends. In my opinion, this is a personal opinion, writing Python is much easier, but then you have more bugs. This was my experience. When I implement something in Python, I do it in 30 minutes, one hour, two hours, but then I got bugs. When I do it in Rust, it took me more longer, a lot of compiler errors, a lot of unsafe stuff everywhere, so we need to avoid that, but then it's quite stable. I can say that nowadays, the Rust version, it is younger that the Python one is more stable. We got less bug reports and we have more users. Thank you. Yeah, thank you. Did you run into any problems in terms of compatibility when you created C bindings from the Rust code? No, not at all. To be honest, we did not have any problem. It was quite straightforward. We did not have any problem. I must say that the NMS state library is, well, we spoke to the users, it's quite simple, so that makes it simple for us. We did not have any problem. That's it. Okay, thanks. Before. You mentioned that it was a long journey when you implemented this in Rust. Could you compare what you have expected in the beginning of this journey and with the reality? I must say that I'm not the only one person working on this. There is my teammate, Chris, and Chris was the lead here. I must say that I did not trust very much, that we were able to do it in two years. So we were like, yeah, in two years, we are going to have Rust and I was like, I don't think so. But he was right. So I think my expectation is that it will take much longer, but it was much simpler than what I thought. So also, I thought that we could have more problems with finding the libraries that we need to do all the positions that we needed. But I must say that Rust have a great ecosystem. So the libraries that we are using, they are really, really well maintained and that's great. Let's work for us. We have a question from the matrix. Sure. So that's a bit weird. Tanya is asking, how long did it take your team to learn Rust or did they know Rust already? No. We did not know Rust. I mean, we didn't know what Rust was and we did some work on Rust. But we did one thing here. We started with NISPOR instead with NMS state. So when we noticed what are the missing pieces, we first started with NISPOR, which is much simpler than NMS state, and we learned on the way. I must say that I am most surprised with all the Rust resources that it was quite easy to learn. But we learned on the way. When we needed something, we started learning it. And then we revisited the code and we changed things. For example, initially, we did not understood correctly how to use traits, so we did not use them. And then we noticed, right, traits are really useful. We are not using them. And then we started to implement traits everywhere and make it more flexible. Thank you. Great. There's no more questions. Thank you for your time. Thank you for listening. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.44, "text": " Yes, Fernando is fine.", "tokens": [1079, 11, 30190, 307, 2489, 13], "temperature": 0.0, "avg_logprob": -0.4004800584581163, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.022128742188215256}, {"id": 1, "seek": 0, "start": 9.44, "end": 13.92, "text": " Fernando, he's going to talk about using Rust for", "tokens": [30190, 11, 415, 311, 516, 281, 751, 466, 1228, 34952, 337], "temperature": 0.0, "avg_logprob": -0.4004800584581163, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.022128742188215256}, {"id": 2, "seek": 0, "start": 13.92, "end": 16.64, "text": " your network management tools. Take it away.", "tokens": [428, 3209, 4592, 3873, 13, 3664, 309, 1314, 13], "temperature": 0.0, "avg_logprob": -0.4004800584581163, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.022128742188215256}, {"id": 3, "seek": 0, "start": 16.64, "end": 18.76, "text": " All right. Thank you.", "tokens": [1057, 558, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.4004800584581163, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.022128742188215256}, {"id": 4, "seek": 0, "start": 18.76, "end": 25.2, "text": " All right. So, welcome everyone.", "tokens": [1057, 558, 13, 407, 11, 2928, 1518, 13], "temperature": 0.0, "avg_logprob": -0.4004800584581163, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.022128742188215256}, {"id": 5, "seek": 0, "start": 25.2, "end": 26.240000000000002, "text": " My name is Fernando.", "tokens": [1222, 1315, 307, 30190, 13], "temperature": 0.0, "avg_logprob": -0.4004800584581163, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.022128742188215256}, {"id": 6, "seek": 0, "start": 26.240000000000002, "end": 28.16, "text": " I'm a senior software engineer at Drehat.", "tokens": [286, 478, 257, 7965, 4722, 11403, 412, 413, 9017, 267, 13], "temperature": 0.0, "avg_logprob": -0.4004800584581163, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.022128742188215256}, {"id": 7, "seek": 2816, "start": 28.16, "end": 30.16, "text": " I work for the Networking Services Team,", "tokens": [286, 589, 337, 264, 12640, 278, 12124, 7606, 11], "temperature": 0.0, "avg_logprob": -0.225462242409035, "compression_ratio": 1.6581196581196582, "no_speech_prob": 9.60902325459756e-05}, {"id": 8, "seek": 2816, "start": 30.16, "end": 32.76, "text": " mainly in focus on network management tools,", "tokens": [8704, 294, 1879, 322, 3209, 4592, 3873, 11], "temperature": 0.0, "avg_logprob": -0.225462242409035, "compression_ratio": 1.6581196581196582, "no_speech_prob": 9.60902325459756e-05}, {"id": 9, "seek": 2816, "start": 32.76, "end": 36.24, "text": " and today we are going to talk what was our journey,", "tokens": [293, 965, 321, 366, 516, 281, 751, 437, 390, 527, 4671, 11], "temperature": 0.0, "avg_logprob": -0.225462242409035, "compression_ratio": 1.6581196581196582, "no_speech_prob": 9.60902325459756e-05}, {"id": 10, "seek": 2816, "start": 36.24, "end": 40.08, "text": " building a Rust tool for network management.", "tokens": [2390, 257, 34952, 2290, 337, 3209, 4592, 13], "temperature": 0.0, "avg_logprob": -0.225462242409035, "compression_ratio": 1.6581196581196582, "no_speech_prob": 9.60902325459756e-05}, {"id": 11, "seek": 2816, "start": 40.08, "end": 43.28, "text": " So, okay. We did not start with Rust.", "tokens": [407, 11, 1392, 13, 492, 630, 406, 722, 365, 34952, 13], "temperature": 0.0, "avg_logprob": -0.225462242409035, "compression_ratio": 1.6581196581196582, "no_speech_prob": 9.60902325459756e-05}, {"id": 12, "seek": 2816, "start": 43.28, "end": 44.519999999999996, "text": " We have started with Python,", "tokens": [492, 362, 1409, 365, 15329, 11], "temperature": 0.0, "avg_logprob": -0.225462242409035, "compression_ratio": 1.6581196581196582, "no_speech_prob": 9.60902325459756e-05}, {"id": 13, "seek": 2816, "start": 44.519999999999996, "end": 47.84, "text": " but after some time we decide that we wanted to shift to Rust.", "tokens": [457, 934, 512, 565, 321, 4536, 300, 321, 1415, 281, 5513, 281, 34952, 13], "temperature": 0.0, "avg_logprob": -0.225462242409035, "compression_ratio": 1.6581196581196582, "no_speech_prob": 9.60902325459756e-05}, {"id": 14, "seek": 2816, "start": 47.84, "end": 50.32, "text": " So, this is two talks in one.", "tokens": [407, 11, 341, 307, 732, 6686, 294, 472, 13], "temperature": 0.0, "avg_logprob": -0.225462242409035, "compression_ratio": 1.6581196581196582, "no_speech_prob": 9.60902325459756e-05}, {"id": 15, "seek": 2816, "start": 50.32, "end": 54.68, "text": " One is how we did build the project in Rust,", "tokens": [1485, 307, 577, 321, 630, 1322, 264, 1716, 294, 34952, 11], "temperature": 0.0, "avg_logprob": -0.225462242409035, "compression_ratio": 1.6581196581196582, "no_speech_prob": 9.60902325459756e-05}, {"id": 16, "seek": 5468, "start": 54.68, "end": 58.72, "text": " and what we learned when moving from Python to Rust.", "tokens": [293, 437, 321, 3264, 562, 2684, 490, 15329, 281, 34952, 13], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 17, "seek": 5468, "start": 58.72, "end": 60.68, "text": " Okay. So, network management.", "tokens": [1033, 13, 407, 11, 3209, 4592, 13], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 18, "seek": 5468, "start": 60.68, "end": 61.88, "text": " What's network management?", "tokens": [708, 311, 3209, 4592, 30], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 19, "seek": 5468, "start": 61.88, "end": 63.88, "text": " Basically, it's all the operations that you do", "tokens": [8537, 11, 309, 311, 439, 264, 7705, 300, 291, 360], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 20, "seek": 5468, "start": 63.88, "end": 65.44, "text": " to configure your networking.", "tokens": [281, 22162, 428, 17985, 13], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 21, "seek": 5468, "start": 65.44, "end": 67.76, "text": " Roots, interfaces, DNS,", "tokens": [3101, 1971, 11, 28416, 11, 35153, 11], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 22, "seek": 5468, "start": 67.76, "end": 69.52, "text": " firewalling, whatever you do,", "tokens": [36109, 278, 11, 2035, 291, 360, 11], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 23, "seek": 5468, "start": 69.52, "end": 71.03999999999999, "text": " it's network management.", "tokens": [309, 311, 3209, 4592, 13], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 24, "seek": 5468, "start": 71.03999999999999, "end": 75.12, "text": " So, it's a process that is quite complex because it requires", "tokens": [407, 11, 309, 311, 257, 1399, 300, 307, 1596, 3997, 570, 309, 7029], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 25, "seek": 5468, "start": 75.12, "end": 78.24, "text": " a lot of coordination between user space and kernel space.", "tokens": [257, 688, 295, 21252, 1296, 4195, 1901, 293, 28256, 1901, 13], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 26, "seek": 5468, "start": 78.24, "end": 80.88, "text": " We need to check when we get", "tokens": [492, 643, 281, 1520, 562, 321, 483], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 27, "seek": 5468, "start": 80.88, "end": 83.28, "text": " notification for kernel space because all the tools", "tokens": [11554, 337, 28256, 1901, 570, 439, 264, 3873], "temperature": 0.0, "avg_logprob": -0.18405303017037813, "compression_ratio": 1.7453183520599251, "no_speech_prob": 8.459370292257518e-05}, {"id": 28, "seek": 8328, "start": 83.28, "end": 86.2, "text": " could modify the network status.", "tokens": [727, 16927, 264, 3209, 6558, 13], "temperature": 0.0, "avg_logprob": -0.2453321698068202, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8288017599843442e-05}, {"id": 29, "seek": 8328, "start": 86.2, "end": 88.4, "text": " We also need to communicate with", "tokens": [492, 611, 643, 281, 7890, 365], "temperature": 0.0, "avg_logprob": -0.2453321698068202, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8288017599843442e-05}, {"id": 30, "seek": 8328, "start": 88.4, "end": 92.56, "text": " kernel in order to configure stuff.", "tokens": [28256, 294, 1668, 281, 22162, 1507, 13], "temperature": 0.0, "avg_logprob": -0.2453321698068202, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8288017599843442e-05}, {"id": 31, "seek": 8328, "start": 92.56, "end": 95.32000000000001, "text": " So, it's a quite complex task.", "tokens": [407, 11, 309, 311, 257, 1596, 3997, 5633, 13], "temperature": 0.0, "avg_logprob": -0.2453321698068202, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8288017599843442e-05}, {"id": 32, "seek": 8328, "start": 95.32000000000001, "end": 98.76, "text": " There is already a tool which is network manager.", "tokens": [821, 307, 1217, 257, 2290, 597, 307, 3209, 6598, 13], "temperature": 0.0, "avg_logprob": -0.2453321698068202, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8288017599843442e-05}, {"id": 33, "seek": 8328, "start": 98.76, "end": 103.72, "text": " It's by default, the tool that is in almost all situations used", "tokens": [467, 311, 538, 7576, 11, 264, 2290, 300, 307, 294, 1920, 439, 6851, 1143], "temperature": 0.0, "avg_logprob": -0.2453321698068202, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8288017599843442e-05}, {"id": 34, "seek": 8328, "start": 103.72, "end": 107.56, "text": " for managing your Linux network configuration,", "tokens": [337, 11642, 428, 18734, 3209, 11694, 11], "temperature": 0.0, "avg_logprob": -0.2453321698068202, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8288017599843442e-05}, {"id": 35, "seek": 8328, "start": 107.56, "end": 110.04, "text": " and we were willing to use it and we were", "tokens": [293, 321, 645, 4950, 281, 764, 309, 293, 321, 645], "temperature": 0.0, "avg_logprob": -0.2453321698068202, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8288017599843442e-05}, {"id": 36, "seek": 11004, "start": 110.04, "end": 113.56, "text": " willing to build in top of a network manager because", "tokens": [4950, 281, 1322, 294, 1192, 295, 257, 3209, 6598, 570], "temperature": 0.0, "avg_logprob": -0.23172985423694958, "compression_ratio": 1.7136363636363636, "no_speech_prob": 1.162348962679971e-05}, {"id": 37, "seek": 11004, "start": 113.56, "end": 116.68, "text": " implementing everything was really, really complex.", "tokens": [18114, 1203, 390, 534, 11, 534, 3997, 13], "temperature": 0.0, "avg_logprob": -0.23172985423694958, "compression_ratio": 1.7136363636363636, "no_speech_prob": 1.162348962679971e-05}, {"id": 38, "seek": 11004, "start": 116.68, "end": 118.4, "text": " So, we created NMS state,", "tokens": [407, 11, 321, 2942, 426, 10288, 1785, 11], "temperature": 0.0, "avg_logprob": -0.23172985423694958, "compression_ratio": 1.7136363636363636, "no_speech_prob": 1.162348962679971e-05}, {"id": 39, "seek": 11004, "start": 118.4, "end": 120.68, "text": " and NMS state is a tool that communicates with", "tokens": [293, 426, 10288, 1785, 307, 257, 2290, 300, 3363, 1024, 365], "temperature": 0.0, "avg_logprob": -0.23172985423694958, "compression_ratio": 1.7136363636363636, "no_speech_prob": 1.162348962679971e-05}, {"id": 40, "seek": 11004, "start": 120.68, "end": 126.4, "text": " network manager and it's a library with a command line tool,", "tokens": [3209, 6598, 293, 309, 311, 257, 6405, 365, 257, 5622, 1622, 2290, 11], "temperature": 0.0, "avg_logprob": -0.23172985423694958, "compression_ratio": 1.7136363636363636, "no_speech_prob": 1.162348962679971e-05}, {"id": 41, "seek": 11004, "start": 126.4, "end": 133.32, "text": " and allow us to configure the network with using declarative states.", "tokens": [293, 2089, 505, 281, 22162, 264, 3209, 365, 1228, 16694, 1166, 4368, 13], "temperature": 0.0, "avg_logprob": -0.23172985423694958, "compression_ratio": 1.7136363636363636, "no_speech_prob": 1.162348962679971e-05}, {"id": 42, "seek": 11004, "start": 133.32, "end": 135.64000000000001, "text": " So, you can define what do you want,", "tokens": [407, 11, 291, 393, 6964, 437, 360, 291, 528, 11], "temperature": 0.0, "avg_logprob": -0.23172985423694958, "compression_ratio": 1.7136363636363636, "no_speech_prob": 1.162348962679971e-05}, {"id": 43, "seek": 11004, "start": 135.64000000000001, "end": 137.08, "text": " and you don't need to care about", "tokens": [293, 291, 500, 380, 643, 281, 1127, 466], "temperature": 0.0, "avg_logprob": -0.23172985423694958, "compression_ratio": 1.7136363636363636, "no_speech_prob": 1.162348962679971e-05}, {"id": 44, "seek": 13708, "start": 137.08, "end": 140.12, "text": " how is network manager or how is the kernel doing,", "tokens": [577, 307, 3209, 6598, 420, 577, 307, 264, 28256, 884, 11], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 45, "seek": 13708, "start": 140.12, "end": 143.20000000000002, "text": " and what's going to do or what are the dependencies.", "tokens": [293, 437, 311, 516, 281, 360, 420, 437, 366, 264, 36606, 13], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 46, "seek": 13708, "start": 143.20000000000002, "end": 145.12, "text": " You don't need to care about any of that.", "tokens": [509, 500, 380, 643, 281, 1127, 466, 604, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 47, "seek": 13708, "start": 145.12, "end": 147.12, "text": " NMS state is going to manage it,", "tokens": [426, 10288, 1785, 307, 516, 281, 3067, 309, 11], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 48, "seek": 13708, "start": 147.12, "end": 150.28, "text": " so it makes everything easier.", "tokens": [370, 309, 1669, 1203, 3571, 13], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 49, "seek": 13708, "start": 150.28, "end": 153.8, "text": " So, as I say, we started to build NMS state in Python,", "tokens": [407, 11, 382, 286, 584, 11, 321, 1409, 281, 1322, 426, 10288, 1785, 294, 15329, 11], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 50, "seek": 13708, "start": 153.8, "end": 157.92000000000002, "text": " and one day we noticed that a lot of our users were", "tokens": [293, 472, 786, 321, 5694, 300, 257, 688, 295, 527, 5022, 645], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 51, "seek": 13708, "start": 157.92000000000002, "end": 161.12, "text": " willing to chip a binary and not Python,", "tokens": [4950, 281, 11409, 257, 17434, 293, 406, 15329, 11], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 52, "seek": 13708, "start": 161.12, "end": 163.04000000000002, "text": " don't use the Python environment,", "tokens": [500, 380, 764, 264, 15329, 2823, 11], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 53, "seek": 13708, "start": 163.04000000000002, "end": 165.84, "text": " and well, there were also some performance issues", "tokens": [293, 731, 11, 456, 645, 611, 512, 3389, 2663], "temperature": 0.0, "avg_logprob": -0.2076307265989242, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.3186258911446203e-05}, {"id": 54, "seek": 16584, "start": 165.84, "end": 167.72, "text": " because we need to do a lot of operations.", "tokens": [570, 321, 643, 281, 360, 257, 688, 295, 7705, 13], "temperature": 0.0, "avg_logprob": -0.17488859453771868, "compression_ratio": 1.8443396226415094, "no_speech_prob": 1.6650441466481425e-05}, {"id": 55, "seek": 16584, "start": 167.72, "end": 170.88, "text": " So, we decided to give it a try to REST,", "tokens": [407, 11, 321, 3047, 281, 976, 309, 257, 853, 281, 497, 14497, 11], "temperature": 0.0, "avg_logprob": -0.17488859453771868, "compression_ratio": 1.8443396226415094, "no_speech_prob": 1.6650441466481425e-05}, {"id": 56, "seek": 16584, "start": 170.88, "end": 175.76, "text": " and we have a problem is that we have a library and a binary,", "tokens": [293, 321, 362, 257, 1154, 307, 300, 321, 362, 257, 6405, 293, 257, 17434, 11], "temperature": 0.0, "avg_logprob": -0.17488859453771868, "compression_ratio": 1.8443396226415094, "no_speech_prob": 1.6650441466481425e-05}, {"id": 57, "seek": 16584, "start": 175.76, "end": 178.84, "text": " and we needed to move both of them to REST,", "tokens": [293, 321, 2978, 281, 1286, 1293, 295, 552, 281, 497, 14497, 11], "temperature": 0.0, "avg_logprob": -0.17488859453771868, "compression_ratio": 1.8443396226415094, "no_speech_prob": 1.6650441466481425e-05}, {"id": 58, "seek": 16584, "start": 178.84, "end": 184.12, "text": " and also we already have a big base of users.", "tokens": [293, 611, 321, 1217, 362, 257, 955, 3096, 295, 5022, 13], "temperature": 0.0, "avg_logprob": -0.17488859453771868, "compression_ratio": 1.8443396226415094, "no_speech_prob": 1.6650441466481425e-05}, {"id": 59, "seek": 16584, "start": 184.12, "end": 185.6, "text": " So, we could not break them,", "tokens": [407, 11, 321, 727, 406, 1821, 552, 11], "temperature": 0.0, "avg_logprob": -0.17488859453771868, "compression_ratio": 1.8443396226415094, "no_speech_prob": 1.6650441466481425e-05}, {"id": 60, "seek": 16584, "start": 185.6, "end": 188.4, "text": " and we need to do it in a way that we are going to support,", "tokens": [293, 321, 643, 281, 360, 309, 294, 257, 636, 300, 321, 366, 516, 281, 1406, 11], "temperature": 0.0, "avg_logprob": -0.17488859453771868, "compression_ratio": 1.8443396226415094, "no_speech_prob": 1.6650441466481425e-05}, {"id": 61, "seek": 16584, "start": 188.4, "end": 192.8, "text": " we need to support all the features that we already did in Python.", "tokens": [321, 643, 281, 1406, 439, 264, 4122, 300, 321, 1217, 630, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.17488859453771868, "compression_ratio": 1.8443396226415094, "no_speech_prob": 1.6650441466481425e-05}, {"id": 62, "seek": 19280, "start": 192.8, "end": 196.76000000000002, "text": " So, well, we created our own NMS state library in REST,", "tokens": [407, 11, 731, 11, 321, 2942, 527, 1065, 426, 10288, 1785, 6405, 294, 497, 14497, 11], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 63, "seek": 19280, "start": 196.76000000000002, "end": 198.88000000000002, "text": " I will tell you how,", "tokens": [286, 486, 980, 291, 577, 11], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 64, "seek": 19280, "start": 198.88000000000002, "end": 201.64000000000001, "text": " and also the NMS state CTL tool,", "tokens": [293, 611, 264, 426, 10288, 1785, 19529, 43, 2290, 11], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 65, "seek": 19280, "start": 201.64000000000001, "end": 204.68, "text": " which is the command line tool.", "tokens": [597, 307, 264, 5622, 1622, 2290, 13], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 66, "seek": 19280, "start": 205.12, "end": 208.56, "text": " All right. So, the first thing is that we are using", "tokens": [1057, 558, 13, 407, 11, 264, 700, 551, 307, 300, 321, 366, 1228], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 67, "seek": 19280, "start": 208.56, "end": 211.4, "text": " Jamel files and JSON files, and we are parsing them.", "tokens": [10372, 338, 7098, 293, 31828, 7098, 11, 293, 321, 366, 21156, 278, 552, 13], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 68, "seek": 19280, "start": 211.4, "end": 214.60000000000002, "text": " So, in Python, this was quite trivial with an schema,", "tokens": [407, 11, 294, 15329, 11, 341, 390, 1596, 26703, 365, 364, 34078, 11], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 69, "seek": 19280, "start": 214.60000000000002, "end": 216.72000000000003, "text": " and we needed to find a way to do it.", "tokens": [293, 321, 2978, 281, 915, 257, 636, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 70, "seek": 19280, "start": 216.72000000000003, "end": 218.52, "text": " In Python, we were using dictionary,", "tokens": [682, 15329, 11, 321, 645, 1228, 25890, 11], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 71, "seek": 19280, "start": 218.52, "end": 220.32000000000002, "text": " so the user could create a dictionary,", "tokens": [370, 264, 4195, 727, 1884, 257, 25890, 11], "temperature": 0.0, "avg_logprob": -0.17331278324127197, "compression_ratio": 1.6693548387096775, "no_speech_prob": 9.13541043701116e-06}, {"id": 72, "seek": 22032, "start": 220.32, "end": 223.35999999999999, "text": " and it was using a Jamel library,", "tokens": [293, 309, 390, 1228, 257, 10372, 338, 6405, 11], "temperature": 0.0, "avg_logprob": -0.2700776073420159, "compression_ratio": 1.5666666666666667, "no_speech_prob": 7.0903247433307115e-06}, {"id": 73, "seek": 22032, "start": 223.35999999999999, "end": 227.84, "text": " it was quite trivial to convert that Jamel into a dictionary,", "tokens": [309, 390, 1596, 26703, 281, 7620, 300, 10372, 338, 666, 257, 25890, 11], "temperature": 0.0, "avg_logprob": -0.2700776073420159, "compression_ratio": 1.5666666666666667, "no_speech_prob": 7.0903247433307115e-06}, {"id": 74, "seek": 22032, "start": 227.84, "end": 230.0, "text": " and we needed something in REST to do this.", "tokens": [293, 321, 2978, 746, 294, 497, 14497, 281, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.2700776073420159, "compression_ratio": 1.5666666666666667, "no_speech_prob": 7.0903247433307115e-06}, {"id": 75, "seek": 22032, "start": 230.0, "end": 232.95999999999998, "text": " So, we end up looking at CD.", "tokens": [407, 11, 321, 917, 493, 1237, 412, 6743, 13], "temperature": 0.0, "avg_logprob": -0.2700776073420159, "compression_ratio": 1.5666666666666667, "no_speech_prob": 7.0903247433307115e-06}, {"id": 76, "seek": 22032, "start": 232.95999999999998, "end": 234.92, "text": " CD is a framework for serializing and", "tokens": [6743, 307, 257, 8388, 337, 17436, 3319, 293], "temperature": 0.0, "avg_logprob": -0.2700776073420159, "compression_ratio": 1.5666666666666667, "no_speech_prob": 7.0903247433307115e-06}, {"id": 77, "seek": 22032, "start": 234.92, "end": 238.48, "text": " deserializing REST data structures efficiently and", "tokens": [730, 260, 831, 3319, 497, 14497, 1412, 9227, 19621, 293], "temperature": 0.0, "avg_logprob": -0.2700776073420159, "compression_ratio": 1.5666666666666667, "no_speech_prob": 7.0903247433307115e-06}, {"id": 78, "seek": 22032, "start": 238.48, "end": 242.51999999999998, "text": " generically we use it for Jamel and JSON,", "tokens": [1337, 984, 321, 764, 309, 337, 10372, 338, 293, 31828, 11], "temperature": 0.0, "avg_logprob": -0.2700776073420159, "compression_ratio": 1.5666666666666667, "no_speech_prob": 7.0903247433307115e-06}, {"id": 79, "seek": 22032, "start": 242.51999999999998, "end": 245.04, "text": " but it supports other formats.", "tokens": [457, 309, 9346, 661, 25879, 13], "temperature": 0.0, "avg_logprob": -0.2700776073420159, "compression_ratio": 1.5666666666666667, "no_speech_prob": 7.0903247433307115e-06}, {"id": 80, "seek": 22032, "start": 245.04, "end": 248.79999999999998, "text": " This allows us to keep our declarative state,", "tokens": [639, 4045, 505, 281, 1066, 527, 16694, 1166, 1785, 11], "temperature": 0.0, "avg_logprob": -0.2700776073420159, "compression_ratio": 1.5666666666666667, "no_speech_prob": 7.0903247433307115e-06}, {"id": 81, "seek": 24880, "start": 248.8, "end": 252.56, "text": " keep our API, so that was pretty good,", "tokens": [1066, 527, 9362, 11, 370, 300, 390, 1238, 665, 11], "temperature": 0.0, "avg_logprob": -0.20022791082208807, "compression_ratio": 1.6339285714285714, "no_speech_prob": 2.6535222787060775e-05}, {"id": 82, "seek": 24880, "start": 252.56, "end": 255.20000000000002, "text": " and we noticed that CD allow us to", "tokens": [293, 321, 5694, 300, 6743, 2089, 505, 281], "temperature": 0.0, "avg_logprob": -0.20022791082208807, "compression_ratio": 1.6339285714285714, "no_speech_prob": 2.6535222787060775e-05}, {"id": 83, "seek": 24880, "start": 255.20000000000002, "end": 258.56, "text": " implement our own serializers and deserializers.", "tokens": [4445, 527, 1065, 17436, 22525, 293, 730, 260, 831, 22525, 13], "temperature": 0.0, "avg_logprob": -0.20022791082208807, "compression_ratio": 1.6339285714285714, "no_speech_prob": 2.6535222787060775e-05}, {"id": 84, "seek": 24880, "start": 258.56, "end": 261.12, "text": " So, that was also a big plus because we", "tokens": [407, 11, 300, 390, 611, 257, 955, 1804, 570, 321], "temperature": 0.0, "avg_logprob": -0.20022791082208807, "compression_ratio": 1.6339285714285714, "no_speech_prob": 2.6535222787060775e-05}, {"id": 85, "seek": 24880, "start": 261.12, "end": 264.88, "text": " could do validation steps and simplify", "tokens": [727, 360, 24071, 4439, 293, 20460], "temperature": 0.0, "avg_logprob": -0.20022791082208807, "compression_ratio": 1.6339285714285714, "no_speech_prob": 2.6535222787060775e-05}, {"id": 86, "seek": 24880, "start": 264.88, "end": 267.64, "text": " the validation work when", "tokens": [264, 24071, 589, 562], "temperature": 0.0, "avg_logprob": -0.20022791082208807, "compression_ratio": 1.6339285714285714, "no_speech_prob": 2.6535222787060775e-05}, {"id": 87, "seek": 24880, "start": 267.64, "end": 270.48, "text": " getting the configuration file from the user,", "tokens": [1242, 264, 11694, 3991, 490, 264, 4195, 11], "temperature": 0.0, "avg_logprob": -0.20022791082208807, "compression_ratio": 1.6339285714285714, "no_speech_prob": 2.6535222787060775e-05}, {"id": 88, "seek": 24880, "start": 270.48, "end": 274.44, "text": " and then there were a lot of decorators on server,", "tokens": [293, 550, 456, 645, 257, 688, 295, 7919, 3391, 322, 7154, 11], "temperature": 0.0, "avg_logprob": -0.20022791082208807, "compression_ratio": 1.6339285714285714, "no_speech_prob": 2.6535222787060775e-05}, {"id": 89, "seek": 24880, "start": 274.44, "end": 277.92, "text": " so it was quite good for creating aliases,", "tokens": [370, 309, 390, 1596, 665, 337, 4084, 10198, 1957, 11], "temperature": 0.0, "avg_logprob": -0.20022791082208807, "compression_ratio": 1.6339285714285714, "no_speech_prob": 2.6535222787060775e-05}, {"id": 90, "seek": 27792, "start": 277.92, "end": 281.88, "text": " for creating multiple helper functions,", "tokens": [337, 4084, 3866, 36133, 6828, 11], "temperature": 0.0, "avg_logprob": -0.23666399352404535, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.7374568415107206e-05}, {"id": 91, "seek": 27792, "start": 281.88, "end": 287.04, "text": " and also some conditional deserialization and serializations.", "tokens": [293, 611, 512, 27708, 730, 260, 831, 2144, 293, 17436, 14455, 13], "temperature": 0.0, "avg_logprob": -0.23666399352404535, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.7374568415107206e-05}, {"id": 92, "seek": 27792, "start": 287.04, "end": 289.40000000000003, "text": " So, here's an example.", "tokens": [407, 11, 510, 311, 364, 1365, 13], "temperature": 0.0, "avg_logprob": -0.23666399352404535, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.7374568415107206e-05}, {"id": 93, "seek": 27792, "start": 289.40000000000003, "end": 295.68, "text": " For example, this is a interface state for a general bond,", "tokens": [1171, 1365, 11, 341, 307, 257, 9226, 1785, 337, 257, 2674, 6086, 11], "temperature": 0.0, "avg_logprob": -0.23666399352404535, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.7374568415107206e-05}, {"id": 94, "seek": 27792, "start": 295.68, "end": 298.6, "text": " and we basically define it is app,", "tokens": [293, 321, 1936, 6964, 309, 307, 724, 11], "temperature": 0.0, "avg_logprob": -0.23666399352404535, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.7374568415107206e-05}, {"id": 95, "seek": 27792, "start": 298.6, "end": 302.04, "text": " it is have an IPv4 address with this address,", "tokens": [309, 307, 362, 364, 8671, 85, 19, 2985, 365, 341, 2985, 11], "temperature": 0.0, "avg_logprob": -0.23666399352404535, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.7374568415107206e-05}, {"id": 96, "seek": 27792, "start": 302.04, "end": 303.64, "text": " with this prefix length,", "tokens": [365, 341, 46969, 4641, 11], "temperature": 0.0, "avg_logprob": -0.23666399352404535, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.7374568415107206e-05}, {"id": 97, "seek": 27792, "start": 303.64, "end": 304.96000000000004, "text": " and it is enabled,", "tokens": [293, 309, 307, 15172, 11], "temperature": 0.0, "avg_logprob": -0.23666399352404535, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.7374568415107206e-05}, {"id": 98, "seek": 27792, "start": 304.96000000000004, "end": 307.68, "text": " and then we define the link aggregation options.", "tokens": [293, 550, 321, 6964, 264, 2113, 16743, 399, 3956, 13], "temperature": 0.0, "avg_logprob": -0.23666399352404535, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.7374568415107206e-05}, {"id": 99, "seek": 30768, "start": 307.68, "end": 311.12, "text": " So, we have the mod options and the ports.", "tokens": [407, 11, 321, 362, 264, 1072, 3956, 293, 264, 18160, 13], "temperature": 0.0, "avg_logprob": -0.19446403915817673, "compression_ratio": 1.8133333333333332, "no_speech_prob": 7.521404313592939e-06}, {"id": 100, "seek": 30768, "start": 311.12, "end": 317.2, "text": " One really good thing that we have is that we have a partial editing.", "tokens": [1485, 534, 665, 551, 300, 321, 362, 307, 300, 321, 362, 257, 14641, 10000, 13], "temperature": 0.0, "avg_logprob": -0.19446403915817673, "compression_ratio": 1.8133333333333332, "no_speech_prob": 7.521404313592939e-06}, {"id": 101, "seek": 30768, "start": 317.2, "end": 319.36, "text": " So, you can define what you want to change,", "tokens": [407, 11, 291, 393, 6964, 437, 291, 528, 281, 1319, 11], "temperature": 0.0, "avg_logprob": -0.19446403915817673, "compression_ratio": 1.8133333333333332, "no_speech_prob": 7.521404313592939e-06}, {"id": 102, "seek": 30768, "start": 319.36, "end": 321.48, "text": " and we are going to merge it with", "tokens": [293, 321, 366, 516, 281, 22183, 309, 365], "temperature": 0.0, "avg_logprob": -0.19446403915817673, "compression_ratio": 1.8133333333333332, "no_speech_prob": 7.521404313592939e-06}, {"id": 103, "seek": 30768, "start": 321.48, "end": 325.52, "text": " what you already have on configure on the system.", "tokens": [437, 291, 1217, 362, 322, 22162, 322, 264, 1185, 13], "temperature": 0.0, "avg_logprob": -0.19446403915817673, "compression_ratio": 1.8133333333333332, "no_speech_prob": 7.521404313592939e-06}, {"id": 104, "seek": 30768, "start": 325.52, "end": 328.24, "text": " About the decorators, as you can see there,", "tokens": [7769, 264, 7919, 3391, 11, 382, 291, 393, 536, 456, 11], "temperature": 0.0, "avg_logprob": -0.19446403915817673, "compression_ratio": 1.8133333333333332, "no_speech_prob": 7.521404313592939e-06}, {"id": 105, "seek": 30768, "start": 328.24, "end": 331.24, "text": " we were able to use the decorator for example,", "tokens": [321, 645, 1075, 281, 764, 264, 7919, 1639, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.19446403915817673, "compression_ratio": 1.8133333333333332, "no_speech_prob": 7.521404313592939e-06}, {"id": 106, "seek": 30768, "start": 331.24, "end": 333.24, "text": " accepting numbers as a string,", "tokens": [17391, 3547, 382, 257, 6798, 11], "temperature": 0.0, "avg_logprob": -0.19446403915817673, "compression_ratio": 1.8133333333333332, "no_speech_prob": 7.521404313592939e-06}, {"id": 107, "seek": 30768, "start": 333.24, "end": 336.36, "text": " accepting strings, accepting only the number,", "tokens": [17391, 13985, 11, 17391, 787, 264, 1230, 11], "temperature": 0.0, "avg_logprob": -0.19446403915817673, "compression_ratio": 1.8133333333333332, "no_speech_prob": 7.521404313592939e-06}, {"id": 108, "seek": 33636, "start": 336.36, "end": 340.48, "text": " custom strings, creating alias, renaming,", "tokens": [2375, 13985, 11, 4084, 419, 4609, 11, 8124, 5184, 11], "temperature": 0.0, "avg_logprob": -0.23780820657918741, "compression_ratio": 1.6532663316582914, "no_speech_prob": 8.12377311376622e-06}, {"id": 109, "seek": 33636, "start": 340.48, "end": 345.92, "text": " yeah, all of that, and it was quite good.", "tokens": [1338, 11, 439, 295, 300, 11, 293, 309, 390, 1596, 665, 13], "temperature": 0.0, "avg_logprob": -0.23780820657918741, "compression_ratio": 1.6532663316582914, "no_speech_prob": 8.12377311376622e-06}, {"id": 110, "seek": 33636, "start": 345.92, "end": 348.6, "text": " So, okay. We communicate with", "tokens": [407, 11, 1392, 13, 492, 7890, 365], "temperature": 0.0, "avg_logprob": -0.23780820657918741, "compression_ratio": 1.6532663316582914, "no_speech_prob": 8.12377311376622e-06}, {"id": 111, "seek": 33636, "start": 348.6, "end": 350.72, "text": " Neville Manager and we communicate with", "tokens": [1734, 8386, 13821, 293, 321, 7890, 365], "temperature": 0.0, "avg_logprob": -0.23780820657918741, "compression_ratio": 1.6532663316582914, "no_speech_prob": 8.12377311376622e-06}, {"id": 112, "seek": 33636, "start": 350.72, "end": 356.32, "text": " Neville Manager to configure the network state,", "tokens": [1734, 8386, 13821, 281, 22162, 264, 3209, 1785, 11], "temperature": 0.0, "avg_logprob": -0.23780820657918741, "compression_ratio": 1.6532663316582914, "no_speech_prob": 8.12377311376622e-06}, {"id": 113, "seek": 33636, "start": 356.32, "end": 358.64, "text": " and we have a problem is that before we were using", "tokens": [293, 321, 362, 257, 1154, 307, 300, 949, 321, 645, 1228], "temperature": 0.0, "avg_logprob": -0.23780820657918741, "compression_ratio": 1.6532663316582914, "no_speech_prob": 8.12377311376622e-06}, {"id": 114, "seek": 33636, "start": 358.64, "end": 361.88, "text": " the Lebanon bindings, Python bindings,", "tokens": [264, 29532, 14786, 1109, 11, 15329, 14786, 1109, 11], "temperature": 0.0, "avg_logprob": -0.23780820657918741, "compression_ratio": 1.6532663316582914, "no_speech_prob": 8.12377311376622e-06}, {"id": 115, "seek": 33636, "start": 361.88, "end": 364.72, "text": " and they were not available in trust,", "tokens": [293, 436, 645, 406, 2435, 294, 3361, 11], "temperature": 0.0, "avg_logprob": -0.23780820657918741, "compression_ratio": 1.6532663316582914, "no_speech_prob": 8.12377311376622e-06}, {"id": 116, "seek": 36472, "start": 364.72, "end": 368.04, "text": " and we tried to create a trust bindings,", "tokens": [293, 321, 3031, 281, 1884, 257, 3361, 14786, 1109, 11], "temperature": 0.0, "avg_logprob": -0.25462266265368855, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.4231547286035493e-05}, {"id": 117, "seek": 36472, "start": 368.04, "end": 369.84000000000003, "text": " but it was quite complex because they use", "tokens": [457, 309, 390, 1596, 3997, 570, 436, 764], "temperature": 0.0, "avg_logprob": -0.25462266265368855, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.4231547286035493e-05}, {"id": 118, "seek": 36472, "start": 369.84000000000003, "end": 371.8, "text": " gObject and we did not have gObject,", "tokens": [290, 45483, 1020, 293, 321, 630, 406, 362, 290, 45483, 1020, 11], "temperature": 0.0, "avg_logprob": -0.25462266265368855, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.4231547286035493e-05}, {"id": 119, "seek": 36472, "start": 371.8, "end": 373.64000000000004, "text": " and it was a big mess,", "tokens": [293, 309, 390, 257, 955, 2082, 11], "temperature": 0.0, "avg_logprob": -0.25462266265368855, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.4231547286035493e-05}, {"id": 120, "seek": 36472, "start": 373.64000000000004, "end": 378.68, "text": " but we noticed that Neville Manager is providing a Divas API.", "tokens": [457, 321, 5694, 300, 1734, 8386, 13821, 307, 6530, 257, 9886, 296, 9362, 13], "temperature": 0.0, "avg_logprob": -0.25462266265368855, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.4231547286035493e-05}, {"id": 121, "seek": 36472, "start": 378.68, "end": 382.16, "text": " So, we say, okay, let's use Divas then,", "tokens": [407, 11, 321, 584, 11, 1392, 11, 718, 311, 764, 9886, 296, 550, 11], "temperature": 0.0, "avg_logprob": -0.25462266265368855, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.4231547286035493e-05}, {"id": 122, "seek": 36472, "start": 382.16, "end": 386.32000000000005, "text": " and we noticed that there is a create which is Zitabas,", "tokens": [293, 321, 5694, 300, 456, 307, 257, 1884, 597, 307, 1176, 270, 455, 296, 11], "temperature": 0.0, "avg_logprob": -0.25462266265368855, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.4231547286035493e-05}, {"id": 123, "seek": 36472, "start": 386.32000000000005, "end": 389.72, "text": " and with Zitabas, we were able to communicate with", "tokens": [293, 365, 1176, 270, 455, 296, 11, 321, 645, 1075, 281, 7890, 365], "temperature": 0.0, "avg_logprob": -0.25462266265368855, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.4231547286035493e-05}, {"id": 124, "seek": 36472, "start": 389.72, "end": 393.04, "text": " Neville Manager using the Divas API,", "tokens": [1734, 8386, 13821, 1228, 264, 9886, 296, 9362, 11], "temperature": 0.0, "avg_logprob": -0.25462266265368855, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.4231547286035493e-05}, {"id": 125, "seek": 39304, "start": 393.04, "end": 395.92, "text": " and with Zitabas, and we were able to", "tokens": [293, 365, 1176, 270, 455, 296, 11, 293, 321, 645, 1075, 281], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 126, "seek": 39304, "start": 395.92, "end": 398.88, "text": " encode the data structures that we were using", "tokens": [2058, 1429, 264, 1412, 9227, 300, 321, 645, 1228], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 127, "seek": 39304, "start": 398.88, "end": 401.96000000000004, "text": " to communicate with Neville Manager", "tokens": [281, 7890, 365, 1734, 8386, 13821], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 128, "seek": 39304, "start": 401.96000000000004, "end": 405.16, "text": " and configure the settings that we wanted.", "tokens": [293, 22162, 264, 6257, 300, 321, 1415, 13], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 129, "seek": 39304, "start": 405.16, "end": 408.76000000000005, "text": " So, using this, we solved one of the problems,", "tokens": [407, 11, 1228, 341, 11, 321, 13041, 472, 295, 264, 2740, 11], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 130, "seek": 39304, "start": 408.76000000000005, "end": 411.36, "text": " which is telling Neville Manager what we want to do,", "tokens": [597, 307, 3585, 1734, 8386, 13821, 437, 321, 528, 281, 360, 11], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 131, "seek": 39304, "start": 411.36, "end": 414.6, "text": " and also fetching what already Neville Manager have,", "tokens": [293, 611, 23673, 278, 437, 1217, 1734, 8386, 13821, 362, 11], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 132, "seek": 39304, "start": 414.6, "end": 416.6, "text": " which is also important because,", "tokens": [597, 307, 611, 1021, 570, 11], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 133, "seek": 39304, "start": 416.6, "end": 418.72, "text": " all right, there are some options", "tokens": [439, 558, 11, 456, 366, 512, 3956], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 134, "seek": 39304, "start": 418.72, "end": 421.04, "text": " that maybe we do not want to overwrite", "tokens": [300, 1310, 321, 360, 406, 528, 281, 670, 21561], "temperature": 0.0, "avg_logprob": -0.1931579824079547, "compression_ratio": 1.8304347826086957, "no_speech_prob": 1.3176293577998877e-05}, {"id": 135, "seek": 42104, "start": 421.04, "end": 423.64000000000004, "text": " because the user configured it that way,", "tokens": [570, 264, 4195, 30538, 309, 300, 636, 11], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 136, "seek": 42104, "start": 423.64000000000004, "end": 425.88, "text": " and for patch editing, that is important.", "tokens": [293, 337, 9972, 10000, 11, 300, 307, 1021, 13], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 137, "seek": 42104, "start": 425.88, "end": 427.32, "text": " We need to know what the user configured", "tokens": [492, 643, 281, 458, 437, 264, 4195, 30538], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 138, "seek": 42104, "start": 427.32, "end": 429.52000000000004, "text": " and what the user was to modify.", "tokens": [293, 437, 264, 4195, 390, 281, 16927, 13], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 139, "seek": 42104, "start": 429.52000000000004, "end": 432.40000000000003, "text": " So, okay, one problem solved.", "tokens": [407, 11, 1392, 11, 472, 1154, 13041, 13], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 140, "seek": 42104, "start": 432.40000000000003, "end": 434.32000000000005, "text": " Then, we have another problem.", "tokens": [1396, 11, 321, 362, 1071, 1154, 13], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 141, "seek": 42104, "start": 434.32000000000005, "end": 436.0, "text": " So, Neville Manager does not provide", "tokens": [407, 11, 1734, 8386, 13821, 775, 406, 2893], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 142, "seek": 42104, "start": 436.0, "end": 439.04, "text": " at all real-time information from kernel,", "tokens": [412, 439, 957, 12, 3766, 1589, 490, 28256, 11], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 143, "seek": 42104, "start": 439.04, "end": 442.24, "text": " and we needed that because we also do verification.", "tokens": [293, 321, 2978, 300, 570, 321, 611, 360, 30206, 13], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 144, "seek": 42104, "start": 442.24, "end": 444.64000000000004, "text": " So, when you configure something,", "tokens": [407, 11, 562, 291, 22162, 746, 11], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 145, "seek": 42104, "start": 444.64000000000004, "end": 449.28000000000003, "text": " NMS state do a verification step,", "tokens": [426, 10288, 1785, 360, 257, 30206, 1823, 11], "temperature": 0.0, "avg_logprob": -0.2387995636254026, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.257081839867169e-05}, {"id": 146, "seek": 44928, "start": 449.28, "end": 452.59999999999997, "text": " which what it does is compare what the user defined,", "tokens": [597, 437, 309, 775, 307, 6794, 437, 264, 4195, 7642, 11], "temperature": 0.0, "avg_logprob": -0.20119317372639975, "compression_ratio": 1.75, "no_speech_prob": 9.786678674572613e-06}, {"id": 147, "seek": 44928, "start": 452.59999999999997, "end": 455.64, "text": " which what is configured on the system.", "tokens": [597, 437, 307, 30538, 322, 264, 1185, 13], "temperature": 0.0, "avg_logprob": -0.20119317372639975, "compression_ratio": 1.75, "no_speech_prob": 9.786678674572613e-06}, {"id": 148, "seek": 44928, "start": 455.64, "end": 457.96, "text": " We have a problem because Neville Manager", "tokens": [492, 362, 257, 1154, 570, 1734, 8386, 13821], "temperature": 0.0, "avg_logprob": -0.20119317372639975, "compression_ratio": 1.75, "no_speech_prob": 9.786678674572613e-06}, {"id": 149, "seek": 44928, "start": 457.96, "end": 459.47999999999996, "text": " was not providing real-time information,", "tokens": [390, 406, 6530, 957, 12, 3766, 1589, 11], "temperature": 0.0, "avg_logprob": -0.20119317372639975, "compression_ratio": 1.75, "no_speech_prob": 9.786678674572613e-06}, {"id": 150, "seek": 44928, "start": 459.47999999999996, "end": 463.28, "text": " and sometimes it took quite", "tokens": [293, 2171, 309, 1890, 1596], "temperature": 0.0, "avg_logprob": -0.20119317372639975, "compression_ratio": 1.75, "no_speech_prob": 9.786678674572613e-06}, {"id": 151, "seek": 44928, "start": 463.28, "end": 467.23999999999995, "text": " sometimes to get the information that we wanted,", "tokens": [2171, 281, 483, 264, 1589, 300, 321, 1415, 11], "temperature": 0.0, "avg_logprob": -0.20119317372639975, "compression_ratio": 1.75, "no_speech_prob": 9.786678674572613e-06}, {"id": 152, "seek": 44928, "start": 467.23999999999995, "end": 471.64, "text": " and we were having some problems on the verification.", "tokens": [293, 321, 645, 1419, 512, 2740, 322, 264, 30206, 13], "temperature": 0.0, "avg_logprob": -0.20119317372639975, "compression_ratio": 1.75, "no_speech_prob": 9.786678674572613e-06}, {"id": 153, "seek": 44928, "start": 471.64, "end": 473.59999999999997, "text": " So, we were looking for a library,", "tokens": [407, 11, 321, 645, 1237, 337, 257, 6405, 11], "temperature": 0.0, "avg_logprob": -0.20119317372639975, "compression_ratio": 1.75, "no_speech_prob": 9.786678674572613e-06}, {"id": 154, "seek": 44928, "start": 473.59999999999997, "end": 475.35999999999996, "text": " and we did not find any library that", "tokens": [293, 321, 630, 406, 915, 604, 6405, 300], "temperature": 0.0, "avg_logprob": -0.20119317372639975, "compression_ratio": 1.75, "no_speech_prob": 9.786678674572613e-06}, {"id": 155, "seek": 47536, "start": 475.36, "end": 479.64, "text": " certified our requirements, but we noticed", "tokens": [18580, 527, 7728, 11, 457, 321, 5694], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 156, "seek": 47536, "start": 479.64, "end": 481.72, "text": " that there is already a Rastnet link library,", "tokens": [300, 456, 307, 1217, 257, 497, 525, 7129, 2113, 6405, 11], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 157, "seek": 47536, "start": 481.72, "end": 485.08000000000004, "text": " and that link is a kernel API for", "tokens": [293, 300, 2113, 307, 257, 28256, 9362, 337], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 158, "seek": 47536, "start": 485.08000000000004, "end": 487.48, "text": " communication between user place and kernel,", "tokens": [6101, 1296, 4195, 1081, 293, 28256, 11], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 159, "seek": 47536, "start": 487.48, "end": 489.6, "text": " also, I think, between kernel components,", "tokens": [611, 11, 286, 519, 11, 1296, 28256, 6677, 11], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 160, "seek": 47536, "start": 489.6, "end": 491.32, "text": " and it was perfect.", "tokens": [293, 309, 390, 2176, 13], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 161, "seek": 47536, "start": 491.32, "end": 492.76, "text": " We could use Rastnet link,", "tokens": [492, 727, 764, 497, 525, 7129, 2113, 11], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 162, "seek": 47536, "start": 492.76, "end": 494.2, "text": " which is an existing library,", "tokens": [597, 307, 364, 6741, 6405, 11], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 163, "seek": 47536, "start": 494.2, "end": 496.68, "text": " to build another tool, which is NISPOR.", "tokens": [281, 1322, 1071, 2290, 11, 597, 307, 426, 2343, 47, 2483, 13], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 164, "seek": 47536, "start": 496.68, "end": 500.36, "text": " So, NISPOR only queries information from kernel,", "tokens": [407, 11, 426, 2343, 47, 2483, 787, 24109, 1589, 490, 28256, 11], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 165, "seek": 47536, "start": 500.36, "end": 503.04, "text": " and show you in a jammel file,", "tokens": [293, 855, 291, 294, 257, 361, 5136, 338, 3991, 11], "temperature": 0.0, "avg_logprob": -0.2808899118118927, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.2043261196813546e-05}, {"id": 166, "seek": 50304, "start": 503.04, "end": 507.32, "text": " or basically, proper data structures.", "tokens": [420, 1936, 11, 2296, 1412, 9227, 13], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 167, "seek": 50304, "start": 507.8, "end": 510.48, "text": " Well, it was quite good because we", "tokens": [1042, 11, 309, 390, 1596, 665, 570, 321], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 168, "seek": 50304, "start": 510.48, "end": 511.92, "text": " started to contribute to Rastnet link,", "tokens": [1409, 281, 10586, 281, 497, 525, 7129, 2113, 11], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 169, "seek": 50304, "start": 511.92, "end": 516.5600000000001, "text": " because Rastnet link was an independent project,", "tokens": [570, 497, 525, 7129, 2113, 390, 364, 6695, 1716, 11], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 170, "seek": 50304, "start": 516.5600000000001, "end": 519.52, "text": " and they didn't support everything.", "tokens": [293, 436, 994, 380, 1406, 1203, 13], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 171, "seek": 50304, "start": 519.52, "end": 521.28, "text": " So, we were able to help there,", "tokens": [407, 11, 321, 645, 1075, 281, 854, 456, 11], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 172, "seek": 50304, "start": 521.28, "end": 524.12, "text": " and currently, a lot of people use Rastnet link,", "tokens": [293, 4362, 11, 257, 688, 295, 561, 764, 497, 525, 7129, 2113, 11], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 173, "seek": 50304, "start": 524.12, "end": 526.08, "text": " and it's a quite big project,", "tokens": [293, 309, 311, 257, 1596, 955, 1716, 11], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 174, "seek": 50304, "start": 526.08, "end": 528.24, "text": " and probably the one that most of", "tokens": [293, 1391, 264, 472, 300, 881, 295], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 175, "seek": 50304, "start": 528.24, "end": 532.32, "text": " the people use when need to work with NEL link and REST.", "tokens": [264, 561, 764, 562, 643, 281, 589, 365, 426, 3158, 2113, 293, 497, 14497, 13], "temperature": 0.0, "avg_logprob": -0.24298314633576767, "compression_ratio": 1.6722689075630253, "no_speech_prob": 3.559190736268647e-05}, {"id": 176, "seek": 53232, "start": 532.32, "end": 538.2800000000001, "text": " So, we have one more problem.", "tokens": [407, 11, 321, 362, 472, 544, 1154, 13], "temperature": 0.0, "avg_logprob": -0.2140050401874617, "compression_ratio": 1.7878787878787878, "no_speech_prob": 8.796083420747891e-06}, {"id": 177, "seek": 53232, "start": 538.2800000000001, "end": 541.4000000000001, "text": " Okay. Now, we have network manager working,", "tokens": [1033, 13, 823, 11, 321, 362, 3209, 6598, 1364, 11], "temperature": 0.0, "avg_logprob": -0.2140050401874617, "compression_ratio": 1.7878787878787878, "no_speech_prob": 8.796083420747891e-06}, {"id": 178, "seek": 53232, "start": 541.4000000000001, "end": 544.2, "text": " we have verification working, validation working,", "tokens": [321, 362, 30206, 1364, 11, 24071, 1364, 11], "temperature": 0.0, "avg_logprob": -0.2140050401874617, "compression_ratio": 1.7878787878787878, "no_speech_prob": 8.796083420747891e-06}, {"id": 179, "seek": 53232, "start": 544.2, "end": 545.84, "text": " we can read the configuration,", "tokens": [321, 393, 1401, 264, 11694, 11], "temperature": 0.0, "avg_logprob": -0.2140050401874617, "compression_ratio": 1.7878787878787878, "no_speech_prob": 8.796083420747891e-06}, {"id": 180, "seek": 53232, "start": 545.84, "end": 547.24, "text": " we can do a lot of stuff.", "tokens": [321, 393, 360, 257, 688, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.2140050401874617, "compression_ratio": 1.7878787878787878, "no_speech_prob": 8.796083420747891e-06}, {"id": 181, "seek": 53232, "start": 547.24, "end": 550.12, "text": " But then, networking is complex,", "tokens": [583, 550, 11, 17985, 307, 3997, 11], "temperature": 0.0, "avg_logprob": -0.2140050401874617, "compression_ratio": 1.7878787878787878, "no_speech_prob": 8.796083420747891e-06}, {"id": 182, "seek": 53232, "start": 550.12, "end": 552.5600000000001, "text": " and there is one thing that is called OBS,", "tokens": [293, 456, 307, 472, 551, 300, 307, 1219, 422, 8176, 11], "temperature": 0.0, "avg_logprob": -0.2140050401874617, "compression_ratio": 1.7878787878787878, "no_speech_prob": 8.796083420747891e-06}, {"id": 183, "seek": 53232, "start": 552.5600000000001, "end": 557.08, "text": " OBSDB, and network manager configure OBS, right?", "tokens": [422, 8176, 27735, 11, 293, 3209, 6598, 22162, 422, 8176, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2140050401874617, "compression_ratio": 1.7878787878787878, "no_speech_prob": 8.796083420747891e-06}, {"id": 184, "seek": 53232, "start": 557.08, "end": 561.4000000000001, "text": " But they do not configure global OBSDB settings.", "tokens": [583, 436, 360, 406, 22162, 4338, 422, 8176, 27735, 6257, 13], "temperature": 0.0, "avg_logprob": -0.2140050401874617, "compression_ratio": 1.7878787878787878, "no_speech_prob": 8.796083420747891e-06}, {"id": 185, "seek": 56140, "start": 561.4, "end": 565.0799999999999, "text": " And that was a problem because we wanted to do that.", "tokens": [400, 300, 390, 257, 1154, 570, 321, 1415, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2452111079775054, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.8244279999635182e-05}, {"id": 186, "seek": 56140, "start": 565.0799999999999, "end": 566.88, "text": " So, how we did?", "tokens": [407, 11, 577, 321, 630, 30], "temperature": 0.0, "avg_logprob": -0.2452111079775054, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.8244279999635182e-05}, {"id": 187, "seek": 56140, "start": 566.88, "end": 569.88, "text": " We basically started to use sockets,", "tokens": [492, 1936, 1409, 281, 764, 370, 11984, 11], "temperature": 0.0, "avg_logprob": -0.2452111079775054, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.8244279999635182e-05}, {"id": 188, "seek": 56140, "start": 569.88, "end": 574.9599999999999, "text": " and using the Rast SDD library for stream sockets,", "tokens": [293, 1228, 264, 497, 525, 14638, 35, 6405, 337, 4309, 370, 11984, 11], "temperature": 0.0, "avg_logprob": -0.2452111079775054, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.8244279999635182e-05}, {"id": 189, "seek": 56140, "start": 574.9599999999999, "end": 584.16, "text": " we were able to communicate with OBSDB send petitions,", "tokens": [321, 645, 1075, 281, 7890, 365, 422, 8176, 27735, 2845, 3817, 2451, 11], "temperature": 0.0, "avg_logprob": -0.2452111079775054, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.8244279999635182e-05}, {"id": 190, "seek": 56140, "start": 584.16, "end": 587.1999999999999, "text": " read what they already have stored on the OBSDB,", "tokens": [1401, 437, 436, 1217, 362, 12187, 322, 264, 422, 8176, 27735, 11], "temperature": 0.0, "avg_logprob": -0.2452111079775054, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.8244279999635182e-05}, {"id": 191, "seek": 56140, "start": 587.1999999999999, "end": 590.6, "text": " and configure whatever OBSDB settings", "tokens": [293, 22162, 2035, 422, 8176, 27735, 6257], "temperature": 0.0, "avg_logprob": -0.2452111079775054, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.8244279999635182e-05}, {"id": 192, "seek": 59060, "start": 590.6, "end": 591.96, "text": " the user want to configure.", "tokens": [264, 4195, 528, 281, 22162, 13], "temperature": 0.0, "avg_logprob": -0.30230919520060223, "compression_ratio": 1.502415458937198, "no_speech_prob": 1.5886522305663675e-05}, {"id": 193, "seek": 59060, "start": 591.96, "end": 594.9200000000001, "text": " So, we created our own set of", "tokens": [407, 11, 321, 2942, 527, 1065, 992, 295], "temperature": 0.0, "avg_logprob": -0.30230919520060223, "compression_ratio": 1.502415458937198, "no_speech_prob": 1.5886522305663675e-05}, {"id": 194, "seek": 59060, "start": 594.9200000000001, "end": 597.9200000000001, "text": " JSON or using set of JSON libraries,", "tokens": [31828, 420, 1228, 992, 295, 31828, 15148, 11], "temperature": 0.0, "avg_logprob": -0.30230919520060223, "compression_ratio": 1.502415458937198, "no_speech_prob": 1.5886522305663675e-05}, {"id": 195, "seek": 59060, "start": 597.9200000000001, "end": 602.0400000000001, "text": " we created our own JSON RPC to communicate with OBSDB.", "tokens": [321, 2942, 527, 1065, 31828, 497, 12986, 281, 7890, 365, 422, 8176, 27735, 13], "temperature": 0.0, "avg_logprob": -0.30230919520060223, "compression_ratio": 1.502415458937198, "no_speech_prob": 1.5886522305663675e-05}, {"id": 196, "seek": 59060, "start": 602.0400000000001, "end": 605.0, "text": " This is internal of NMS state.", "tokens": [639, 307, 6920, 295, 426, 10288, 1785, 13], "temperature": 0.0, "avg_logprob": -0.30230919520060223, "compression_ratio": 1.502415458937198, "no_speech_prob": 1.5886522305663675e-05}, {"id": 197, "seek": 59060, "start": 605.0, "end": 609.2, "text": " We have considered to put it on a separate crate,", "tokens": [492, 362, 4888, 281, 829, 309, 322, 257, 4994, 42426, 11], "temperature": 0.0, "avg_logprob": -0.30230919520060223, "compression_ratio": 1.502415458937198, "no_speech_prob": 1.5886522305663675e-05}, {"id": 198, "seek": 59060, "start": 609.2, "end": 611.6800000000001, "text": " but we did not yet.", "tokens": [457, 321, 630, 406, 1939, 13], "temperature": 0.0, "avg_logprob": -0.30230919520060223, "compression_ratio": 1.502415458937198, "no_speech_prob": 1.5886522305663675e-05}, {"id": 199, "seek": 59060, "start": 613.2, "end": 616.6, "text": " Then, we had another problem.", "tokens": [1396, 11, 321, 632, 1071, 1154, 13], "temperature": 0.0, "avg_logprob": -0.30230919520060223, "compression_ratio": 1.502415458937198, "no_speech_prob": 1.5886522305663675e-05}, {"id": 200, "seek": 59060, "start": 616.6, "end": 619.8000000000001, "text": " Okay. I promise this will end.", "tokens": [1033, 13, 286, 6228, 341, 486, 917, 13], "temperature": 0.0, "avg_logprob": -0.30230919520060223, "compression_ratio": 1.502415458937198, "no_speech_prob": 1.5886522305663675e-05}, {"id": 201, "seek": 61980, "start": 619.8, "end": 621.8, "text": " We are going to have a solution.", "tokens": [492, 366, 516, 281, 362, 257, 3827, 13], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 202, "seek": 61980, "start": 621.8, "end": 623.92, "text": " It will stop at some point.", "tokens": [467, 486, 1590, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 203, "seek": 61980, "start": 623.92, "end": 626.0799999999999, "text": " So, we had users,", "tokens": [407, 11, 321, 632, 5022, 11], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 204, "seek": 61980, "start": 626.0799999999999, "end": 628.4799999999999, "text": " the users were using our Python library,", "tokens": [264, 5022, 645, 1228, 527, 15329, 6405, 11], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 205, "seek": 61980, "start": 628.4799999999999, "end": 630.92, "text": " and some of them were willing to move to Rast,", "tokens": [293, 512, 295, 552, 645, 4950, 281, 1286, 281, 497, 525, 11], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 206, "seek": 61980, "start": 630.92, "end": 633.8, "text": " some of them were willing to move to Goland,", "tokens": [512, 295, 552, 645, 4950, 281, 1286, 281, 36319, 474, 11], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 207, "seek": 61980, "start": 633.8, "end": 637.5999999999999, "text": " but we were already developing a Rast solution.", "tokens": [457, 321, 645, 1217, 6416, 257, 497, 525, 3827, 13], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 208, "seek": 61980, "start": 637.5999999999999, "end": 639.88, "text": " And some of them didn't want to move", "tokens": [400, 512, 295, 552, 994, 380, 528, 281, 1286], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 209, "seek": 61980, "start": 639.88, "end": 642.24, "text": " from the Python code to Rast.", "tokens": [490, 264, 15329, 3089, 281, 497, 525, 13], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 210, "seek": 61980, "start": 642.24, "end": 645.5999999999999, "text": " So, what we did is create bindings,", "tokens": [407, 11, 437, 321, 630, 307, 1884, 14786, 1109, 11], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 211, "seek": 61980, "start": 645.5999999999999, "end": 647.4799999999999, "text": " and we create plenty of them.", "tokens": [293, 321, 1884, 7140, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.18782931963602703, "compression_ratio": 1.893719806763285, "no_speech_prob": 2.1734671463491395e-05}, {"id": 212, "seek": 64748, "start": 647.48, "end": 650.8000000000001, "text": " First of all, we created C bindings.", "tokens": [2386, 295, 439, 11, 321, 2942, 383, 14786, 1109, 13], "temperature": 0.0, "avg_logprob": -0.15636888114354944, "compression_ratio": 1.639344262295082, "no_speech_prob": 1.0111768460774329e-05}, {"id": 213, "seek": 64748, "start": 650.8000000000001, "end": 655.32, "text": " So, C users could use the Rast library.", "tokens": [407, 11, 383, 5022, 727, 764, 264, 497, 525, 6405, 13], "temperature": 0.0, "avg_logprob": -0.15636888114354944, "compression_ratio": 1.639344262295082, "no_speech_prob": 1.0111768460774329e-05}, {"id": 214, "seek": 64748, "start": 655.32, "end": 657.16, "text": " Then, from the C bindings,", "tokens": [1396, 11, 490, 264, 383, 14786, 1109, 11], "temperature": 0.0, "avg_logprob": -0.15636888114354944, "compression_ratio": 1.639344262295082, "no_speech_prob": 1.0111768460774329e-05}, {"id": 215, "seek": 64748, "start": 657.16, "end": 660.6800000000001, "text": " we created the Python and Goland bindings.", "tokens": [321, 2942, 264, 15329, 293, 36319, 474, 14786, 1109, 13], "temperature": 0.0, "avg_logprob": -0.15636888114354944, "compression_ratio": 1.639344262295082, "no_speech_prob": 1.0111768460774329e-05}, {"id": 216, "seek": 64748, "start": 660.6800000000001, "end": 665.44, "text": " And finally, one of the other problem that we had is that", "tokens": [400, 2721, 11, 472, 295, 264, 661, 1154, 300, 321, 632, 307, 300], "temperature": 0.0, "avg_logprob": -0.15636888114354944, "compression_ratio": 1.639344262295082, "no_speech_prob": 1.0111768460774329e-05}, {"id": 217, "seek": 64748, "start": 665.44, "end": 669.52, "text": " we got a huge integration test base,", "tokens": [321, 658, 257, 2603, 10980, 1500, 3096, 11], "temperature": 0.0, "avg_logprob": -0.15636888114354944, "compression_ratio": 1.639344262295082, "no_speech_prob": 1.0111768460774329e-05}, {"id": 218, "seek": 64748, "start": 669.52, "end": 672.04, "text": " and we wanted to reuse them.", "tokens": [293, 321, 1415, 281, 26225, 552, 13], "temperature": 0.0, "avg_logprob": -0.15636888114354944, "compression_ratio": 1.639344262295082, "no_speech_prob": 1.0111768460774329e-05}, {"id": 219, "seek": 64748, "start": 672.04, "end": 675.52, "text": " So, with the Python bindings,", "tokens": [407, 11, 365, 264, 15329, 14786, 1109, 11], "temperature": 0.0, "avg_logprob": -0.15636888114354944, "compression_ratio": 1.639344262295082, "no_speech_prob": 1.0111768460774329e-05}, {"id": 220, "seek": 67552, "start": 675.52, "end": 678.8, "text": " we were able to integrate the Python integration test", "tokens": [321, 645, 1075, 281, 13365, 264, 15329, 10980, 1500], "temperature": 0.0, "avg_logprob": -0.15816431138121967, "compression_ratio": 1.748792270531401, "no_speech_prob": 6.7421742642181925e-06}, {"id": 221, "seek": 67552, "start": 678.8, "end": 681.28, "text": " that we had into our Rast library.", "tokens": [300, 321, 632, 666, 527, 497, 525, 6405, 13], "temperature": 0.0, "avg_logprob": -0.15816431138121967, "compression_ratio": 1.748792270531401, "no_speech_prob": 6.7421742642181925e-06}, {"id": 222, "seek": 67552, "start": 681.28, "end": 684.28, "text": " So, it was quite cool because we were able to start", "tokens": [407, 11, 309, 390, 1596, 1627, 570, 321, 645, 1075, 281, 722], "temperature": 0.0, "avg_logprob": -0.15816431138121967, "compression_ratio": 1.748792270531401, "no_speech_prob": 6.7421742642181925e-06}, {"id": 223, "seek": 67552, "start": 684.28, "end": 687.52, "text": " building the new Rast NMS date,", "tokens": [2390, 264, 777, 497, 525, 426, 10288, 4002, 11], "temperature": 0.0, "avg_logprob": -0.15816431138121967, "compression_ratio": 1.748792270531401, "no_speech_prob": 6.7421742642181925e-06}, {"id": 224, "seek": 67552, "start": 687.52, "end": 688.64, "text": " but at the same time,", "tokens": [457, 412, 264, 912, 565, 11], "temperature": 0.0, "avg_logprob": -0.15816431138121967, "compression_ratio": 1.748792270531401, "no_speech_prob": 6.7421742642181925e-06}, {"id": 225, "seek": 67552, "start": 688.64, "end": 691.84, "text": " using the Python integration test.", "tokens": [1228, 264, 15329, 10980, 1500, 13], "temperature": 0.0, "avg_logprob": -0.15816431138121967, "compression_ratio": 1.748792270531401, "no_speech_prob": 6.7421742642181925e-06}, {"id": 226, "seek": 67552, "start": 691.84, "end": 695.16, "text": " And this way, we were sure that we were not", "tokens": [400, 341, 636, 11, 321, 645, 988, 300, 321, 645, 406], "temperature": 0.0, "avg_logprob": -0.15816431138121967, "compression_ratio": 1.748792270531401, "no_speech_prob": 6.7421742642181925e-06}, {"id": 227, "seek": 67552, "start": 695.16, "end": 700.52, "text": " breaking any existing use case that we already support.", "tokens": [7697, 604, 6741, 764, 1389, 300, 321, 1217, 1406, 13], "temperature": 0.0, "avg_logprob": -0.15816431138121967, "compression_ratio": 1.748792270531401, "no_speech_prob": 6.7421742642181925e-06}, {"id": 228, "seek": 67552, "start": 700.52, "end": 704.8, "text": " So, that's it. It was a success.", "tokens": [407, 11, 300, 311, 309, 13, 467, 390, 257, 2245, 13], "temperature": 0.0, "avg_logprob": -0.15816431138121967, "compression_ratio": 1.748792270531401, "no_speech_prob": 6.7421742642181925e-06}, {"id": 229, "seek": 70480, "start": 704.8, "end": 708.24, "text": " And we are quite proud because most of the people that were", "tokens": [400, 321, 366, 1596, 4570, 570, 881, 295, 264, 561, 300, 645], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 230, "seek": 70480, "start": 708.24, "end": 710.56, "text": " using it liked the idea,", "tokens": [1228, 309, 4501, 264, 1558, 11], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 231, "seek": 70480, "start": 710.56, "end": 715.88, "text": " and even the ones that did not care about if you use Python or Rast,", "tokens": [293, 754, 264, 2306, 300, 630, 406, 1127, 466, 498, 291, 764, 15329, 420, 497, 525, 11], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 232, "seek": 70480, "start": 715.88, "end": 717.88, "text": " we're happy because the change was", "tokens": [321, 434, 2055, 570, 264, 1319, 390], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 233, "seek": 70480, "start": 717.88, "end": 720.56, "text": " completely transparent for the final user.", "tokens": [2584, 12737, 337, 264, 2572, 4195, 13], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 234, "seek": 70480, "start": 720.56, "end": 723.4, "text": " If you were using Python,", "tokens": [759, 291, 645, 1228, 15329, 11], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 235, "seek": 70480, "start": 723.4, "end": 725.52, "text": " nothing will change for you.", "tokens": [1825, 486, 1319, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 236, "seek": 70480, "start": 725.52, "end": 726.9599999999999, "text": " The code is the same.", "tokens": [440, 3089, 307, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 237, "seek": 70480, "start": 726.9599999999999, "end": 729.52, "text": " You didn't need to do anything different.", "tokens": [509, 994, 380, 643, 281, 360, 1340, 819, 13], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 238, "seek": 70480, "start": 729.52, "end": 732.12, "text": " So, it will be a transparent update.", "tokens": [407, 11, 309, 486, 312, 257, 12737, 5623, 13], "temperature": 0.0, "avg_logprob": -0.16954004875967435, "compression_ratio": 1.646808510638298, "no_speech_prob": 4.8134646931430325e-05}, {"id": 239, "seek": 73212, "start": 732.12, "end": 736.04, "text": " And if you are using Python and are willing to use Rast,", "tokens": [400, 498, 291, 366, 1228, 15329, 293, 366, 4950, 281, 764, 497, 525, 11], "temperature": 0.0, "avg_logprob": -0.20179414311680224, "compression_ratio": 1.6320754716981132, "no_speech_prob": 1.1616578376560938e-05}, {"id": 240, "seek": 73212, "start": 736.04, "end": 738.24, "text": " okay, you need to change your code.", "tokens": [1392, 11, 291, 643, 281, 1319, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.20179414311680224, "compression_ratio": 1.6320754716981132, "no_speech_prob": 1.1616578376560938e-05}, {"id": 241, "seek": 73212, "start": 738.24, "end": 741.24, "text": " But basically, the API is the same.", "tokens": [583, 1936, 11, 264, 9362, 307, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.20179414311680224, "compression_ratio": 1.6320754716981132, "no_speech_prob": 1.1616578376560938e-05}, {"id": 242, "seek": 73212, "start": 741.24, "end": 747.52, "text": " So, well, you were able to use the same Jamel files,", "tokens": [407, 11, 731, 11, 291, 645, 1075, 281, 764, 264, 912, 10372, 338, 7098, 11], "temperature": 0.0, "avg_logprob": -0.20179414311680224, "compression_ratio": 1.6320754716981132, "no_speech_prob": 1.1616578376560938e-05}, {"id": 243, "seek": 73212, "start": 747.52, "end": 749.04, "text": " and the same JSON files,", "tokens": [293, 264, 912, 31828, 7098, 11], "temperature": 0.0, "avg_logprob": -0.20179414311680224, "compression_ratio": 1.6320754716981132, "no_speech_prob": 1.1616578376560938e-05}, {"id": 244, "seek": 73212, "start": 749.04, "end": 750.64, "text": " and everything will work.", "tokens": [293, 1203, 486, 589, 13], "temperature": 0.0, "avg_logprob": -0.20179414311680224, "compression_ratio": 1.6320754716981132, "no_speech_prob": 1.1616578376560938e-05}, {"id": 245, "seek": 73212, "start": 750.64, "end": 752.84, "text": " So, we got a lot of adoptions,", "tokens": [407, 11, 321, 658, 257, 688, 295, 6878, 626, 11], "temperature": 0.0, "avg_logprob": -0.20179414311680224, "compression_ratio": 1.6320754716981132, "no_speech_prob": 1.1616578376560938e-05}, {"id": 246, "seek": 73212, "start": 752.84, "end": 757.6800000000001, "text": " and right now, the user base of NMS date is still growing,", "tokens": [293, 558, 586, 11, 264, 4195, 3096, 295, 426, 10288, 4002, 307, 920, 4194, 11], "temperature": 0.0, "avg_logprob": -0.20179414311680224, "compression_ratio": 1.6320754716981132, "no_speech_prob": 1.1616578376560938e-05}, {"id": 247, "seek": 73212, "start": 757.6800000000001, "end": 759.64, "text": " and we are quite happy.", "tokens": [293, 321, 366, 1596, 2055, 13], "temperature": 0.0, "avg_logprob": -0.20179414311680224, "compression_ratio": 1.6320754716981132, "no_speech_prob": 1.1616578376560938e-05}, {"id": 248, "seek": 75964, "start": 759.64, "end": 763.16, "text": " Also, it was recreated goal and bindings because", "tokens": [2743, 11, 309, 390, 850, 26559, 3387, 293, 14786, 1109, 570], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 249, "seek": 75964, "start": 763.16, "end": 765.28, "text": " OpenShift people and Kubernetes people were", "tokens": [7238, 7774, 2008, 561, 293, 23145, 561, 645], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 250, "seek": 75964, "start": 765.28, "end": 767.96, "text": " wiling to use it and it's written in goal and bindings.", "tokens": [261, 4883, 281, 764, 309, 293, 309, 311, 3720, 294, 3387, 293, 14786, 1109, 13], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 251, "seek": 75964, "start": 767.96, "end": 771.64, "text": " So, we provided them with goal and bindings,", "tokens": [407, 11, 321, 5649, 552, 365, 3387, 293, 14786, 1109, 11], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 252, "seek": 75964, "start": 771.64, "end": 773.28, "text": " and they really liked it.", "tokens": [293, 436, 534, 4501, 309, 13], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 253, "seek": 75964, "start": 773.28, "end": 776.16, "text": " So, yeah, it was a success story.", "tokens": [407, 11, 1338, 11, 309, 390, 257, 2245, 1657, 13], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 254, "seek": 75964, "start": 776.16, "end": 781.76, "text": " Yeah. So, basically, that was our journey.", "tokens": [865, 13, 407, 11, 1936, 11, 300, 390, 527, 4671, 13], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 255, "seek": 75964, "start": 781.76, "end": 783.6, "text": " I would like to hear,", "tokens": [286, 576, 411, 281, 1568, 11], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 256, "seek": 75964, "start": 783.6, "end": 785.56, "text": " I think we have time for questions.", "tokens": [286, 519, 321, 362, 565, 337, 1651, 13], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 257, "seek": 75964, "start": 785.56, "end": 788.76, "text": " So, please, as whatever you want,", "tokens": [407, 11, 1767, 11, 382, 2035, 291, 528, 11], "temperature": 0.0, "avg_logprob": -0.27843263414171004, "compression_ratio": 1.6724137931034482, "no_speech_prob": 3.80293968191836e-05}, {"id": 258, "seek": 78876, "start": 788.76, "end": 791.52, "text": " I promise you there are no dumb questions.", "tokens": [286, 6228, 291, 456, 366, 572, 10316, 1651, 13], "temperature": 0.0, "avg_logprob": -0.4349983677719579, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005306102684698999}, {"id": 259, "seek": 78876, "start": 791.52, "end": 793.76, "text": " So, thank you very much.", "tokens": [407, 11, 1309, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.4349983677719579, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005306102684698999}, {"id": 260, "seek": 78876, "start": 793.76, "end": 805.28, "text": " All right, any question? Okay.", "tokens": [1057, 558, 11, 604, 1168, 30, 1033, 13], "temperature": 0.0, "avg_logprob": -0.4349983677719579, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005306102684698999}, {"id": 261, "seek": 78876, "start": 807.68, "end": 812.3199999999999, "text": " I wondered what your experience was in terms of time to", "tokens": [286, 17055, 437, 428, 1752, 390, 294, 2115, 295, 565, 281], "temperature": 0.0, "avg_logprob": -0.4349983677719579, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005306102684698999}, {"id": 262, "seek": 78876, "start": 812.3199999999999, "end": 814.52, "text": " implement in Rust versus Python.", "tokens": [4445, 294, 34952, 5717, 15329, 13], "temperature": 0.0, "avg_logprob": -0.4349983677719579, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005306102684698999}, {"id": 263, "seek": 78876, "start": 814.52, "end": 815.4399999999999, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.4349983677719579, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005306102684698999}, {"id": 264, "seek": 81544, "start": 815.44, "end": 818.8800000000001, "text": " From a developer point of view.", "tokens": [3358, 257, 10754, 935, 295, 1910, 13], "temperature": 0.0, "avg_logprob": -0.23044044740738406, "compression_ratio": 1.625, "no_speech_prob": 0.0002873143239412457}, {"id": 265, "seek": 81544, "start": 818.8800000000001, "end": 822.72, "text": " I think it took us around two years,", "tokens": [286, 519, 309, 1890, 505, 926, 732, 924, 11], "temperature": 0.0, "avg_logprob": -0.23044044740738406, "compression_ratio": 1.625, "no_speech_prob": 0.0002873143239412457}, {"id": 266, "seek": 81544, "start": 822.72, "end": 826.0400000000001, "text": " two developers mainly working on it.", "tokens": [732, 8849, 8704, 1364, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.23044044740738406, "compression_ratio": 1.625, "no_speech_prob": 0.0002873143239412457}, {"id": 267, "seek": 81544, "start": 826.0400000000001, "end": 828.2800000000001, "text": " It was full-time.", "tokens": [467, 390, 1577, 12, 3766, 13], "temperature": 0.0, "avg_logprob": -0.23044044740738406, "compression_ratio": 1.625, "no_speech_prob": 0.0002873143239412457}, {"id": 268, "seek": 81544, "start": 828.2800000000001, "end": 830.6, "text": " It was a long journey,", "tokens": [467, 390, 257, 938, 4671, 11], "temperature": 0.0, "avg_logprob": -0.23044044740738406, "compression_ratio": 1.625, "no_speech_prob": 0.0002873143239412457}, {"id": 269, "seek": 81544, "start": 830.6, "end": 833.84, "text": " but it helped us a lot having", "tokens": [457, 309, 4254, 505, 257, 688, 1419], "temperature": 0.0, "avg_logprob": -0.23044044740738406, "compression_ratio": 1.625, "no_speech_prob": 0.0002873143239412457}, {"id": 270, "seek": 81544, "start": 833.84, "end": 837.24, "text": " the Python integration test working with the new library,", "tokens": [264, 15329, 10980, 1500, 1364, 365, 264, 777, 6405, 11], "temperature": 0.0, "avg_logprob": -0.23044044740738406, "compression_ratio": 1.625, "no_speech_prob": 0.0002873143239412457}, {"id": 271, "seek": 81544, "start": 837.24, "end": 839.12, "text": " because we were sure that we were not", "tokens": [570, 321, 645, 988, 300, 321, 645, 406], "temperature": 0.0, "avg_logprob": -0.23044044740738406, "compression_ratio": 1.625, "no_speech_prob": 0.0002873143239412457}, {"id": 272, "seek": 81544, "start": 839.12, "end": 843.96, "text": " breaking the existing cases and speed up the things a little bit.", "tokens": [7697, 264, 6741, 3331, 293, 3073, 493, 264, 721, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.23044044740738406, "compression_ratio": 1.625, "no_speech_prob": 0.0002873143239412457}, {"id": 273, "seek": 84396, "start": 843.96, "end": 846.64, "text": " Absolutely. Do you have a feeling for how long it would have", "tokens": [7021, 13, 1144, 291, 362, 257, 2633, 337, 577, 938, 309, 576, 362], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 274, "seek": 84396, "start": 846.64, "end": 849.2, "text": " taken you if you had re-implemented it in Python?", "tokens": [2726, 291, 498, 291, 632, 319, 12, 332, 781, 14684, 309, 294, 15329, 30], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 275, "seek": 84396, "start": 849.2, "end": 850.8000000000001, "text": " I mean, I know that's not really a thing,", "tokens": [286, 914, 11, 286, 458, 300, 311, 406, 534, 257, 551, 11], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 276, "seek": 84396, "start": 850.8000000000001, "end": 853.2, "text": " but roughly how long if you had said right?", "tokens": [457, 9810, 577, 938, 498, 291, 632, 848, 558, 30], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 277, "seek": 84396, "start": 853.2, "end": 854.2800000000001, "text": " Going back to Python.", "tokens": [10963, 646, 281, 15329, 13], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 278, "seek": 84396, "start": 854.2800000000001, "end": 855.44, "text": " No, if you had said, right,", "tokens": [883, 11, 498, 291, 632, 848, 11, 558, 11], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 279, "seek": 84396, "start": 855.44, "end": 857.52, "text": " we've got it in Python, but for no good reason,", "tokens": [321, 600, 658, 309, 294, 15329, 11, 457, 337, 572, 665, 1778, 11], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 280, "seek": 84396, "start": 857.52, "end": 858.84, "text": " we're going to rewrite it from scratch in", "tokens": [321, 434, 516, 281, 28132, 309, 490, 8459, 294], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 281, "seek": 84396, "start": 858.84, "end": 861.2800000000001, "text": " Python to make it cleaner, let's say.", "tokens": [15329, 281, 652, 309, 16532, 11, 718, 311, 584, 13], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 282, "seek": 84396, "start": 861.2800000000001, "end": 863.72, "text": " Just as like, how long does it take to write something in", "tokens": [1449, 382, 411, 11, 577, 938, 775, 309, 747, 281, 2464, 746, 294], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 283, "seek": 84396, "start": 863.72, "end": 867.32, "text": " Python versus Rust or maybe it's not possible to guess?", "tokens": [15329, 5717, 34952, 420, 1310, 309, 311, 406, 1944, 281, 2041, 30], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 284, "seek": 84396, "start": 867.32, "end": 869.24, "text": " Well, I think it depends.", "tokens": [1042, 11, 286, 519, 309, 5946, 13], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 285, "seek": 84396, "start": 869.24, "end": 871.96, "text": " In my opinion, this is a personal opinion,", "tokens": [682, 452, 4800, 11, 341, 307, 257, 2973, 4800, 11], "temperature": 0.0, "avg_logprob": -0.18630809205951113, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0004244754964020103}, {"id": 286, "seek": 87196, "start": 871.96, "end": 875.64, "text": " writing Python is much easier,", "tokens": [3579, 15329, 307, 709, 3571, 11], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 287, "seek": 87196, "start": 875.64, "end": 877.84, "text": " but then you have more bugs.", "tokens": [457, 550, 291, 362, 544, 15120, 13], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 288, "seek": 87196, "start": 877.84, "end": 879.64, "text": " This was my experience.", "tokens": [639, 390, 452, 1752, 13], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 289, "seek": 87196, "start": 879.64, "end": 882.08, "text": " When I implement something in Python,", "tokens": [1133, 286, 4445, 746, 294, 15329, 11], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 290, "seek": 87196, "start": 882.08, "end": 885.32, "text": " I do it in 30 minutes,", "tokens": [286, 360, 309, 294, 2217, 2077, 11], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 291, "seek": 87196, "start": 885.32, "end": 888.8000000000001, "text": " one hour, two hours, but then I got bugs.", "tokens": [472, 1773, 11, 732, 2496, 11, 457, 550, 286, 658, 15120, 13], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 292, "seek": 87196, "start": 888.8000000000001, "end": 890.1600000000001, "text": " When I do it in Rust,", "tokens": [1133, 286, 360, 309, 294, 34952, 11], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 293, "seek": 87196, "start": 890.1600000000001, "end": 891.64, "text": " it took me more longer,", "tokens": [309, 1890, 385, 544, 2854, 11], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 294, "seek": 87196, "start": 891.64, "end": 893.72, "text": " a lot of compiler errors,", "tokens": [257, 688, 295, 31958, 13603, 11], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 295, "seek": 87196, "start": 893.72, "end": 897.12, "text": " a lot of unsafe stuff everywhere,", "tokens": [257, 688, 295, 35948, 1507, 5315, 11], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 296, "seek": 87196, "start": 897.12, "end": 899.0, "text": " so we need to avoid that,", "tokens": [370, 321, 643, 281, 5042, 300, 11], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 297, "seek": 87196, "start": 899.0, "end": 901.24, "text": " but then it's quite stable.", "tokens": [457, 550, 309, 311, 1596, 8351, 13], "temperature": 0.0, "avg_logprob": -0.2082252329046076, "compression_ratio": 1.6093023255813954, "no_speech_prob": 1.8011029169429094e-05}, {"id": 298, "seek": 90124, "start": 901.24, "end": 904.24, "text": " I can say that nowadays,", "tokens": [286, 393, 584, 300, 13434, 11], "temperature": 0.0, "avg_logprob": -0.510078854031033, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.00048076314851641655}, {"id": 299, "seek": 90124, "start": 904.24, "end": 905.84, "text": " the Rust version,", "tokens": [264, 34952, 3037, 11], "temperature": 0.0, "avg_logprob": -0.510078854031033, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.00048076314851641655}, {"id": 300, "seek": 90124, "start": 905.84, "end": 910.2, "text": " it is younger that the Python one is more stable.", "tokens": [309, 307, 7037, 300, 264, 15329, 472, 307, 544, 8351, 13], "temperature": 0.0, "avg_logprob": -0.510078854031033, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.00048076314851641655}, {"id": 301, "seek": 90124, "start": 910.2, "end": 914.44, "text": " We got less bug reports and we have more users.", "tokens": [492, 658, 1570, 7426, 7122, 293, 321, 362, 544, 5022, 13], "temperature": 0.0, "avg_logprob": -0.510078854031033, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.00048076314851641655}, {"id": 302, "seek": 90124, "start": 914.44, "end": 915.52, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.510078854031033, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.00048076314851641655}, {"id": 303, "seek": 90124, "start": 915.52, "end": 917.64, "text": " Yeah, thank you.", "tokens": [865, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.510078854031033, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.00048076314851641655}, {"id": 304, "seek": 91764, "start": 917.64, "end": 933.48, "text": " Did you run into any problems in terms of", "tokens": [2589, 291, 1190, 666, 604, 2740, 294, 2115, 295], "temperature": 0.0, "avg_logprob": -0.21856978445342093, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0009594522998668253}, {"id": 305, "seek": 91764, "start": 933.48, "end": 935.6, "text": " compatibility when you created", "tokens": [34237, 562, 291, 2942], "temperature": 0.0, "avg_logprob": -0.21856978445342093, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0009594522998668253}, {"id": 306, "seek": 91764, "start": 935.6, "end": 938.4399999999999, "text": " C bindings from the Rust code?", "tokens": [383, 14786, 1109, 490, 264, 34952, 3089, 30], "temperature": 0.0, "avg_logprob": -0.21856978445342093, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0009594522998668253}, {"id": 307, "seek": 91764, "start": 938.4399999999999, "end": 940.56, "text": " No, not at all. To be honest,", "tokens": [883, 11, 406, 412, 439, 13, 1407, 312, 3245, 11], "temperature": 0.0, "avg_logprob": -0.21856978445342093, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0009594522998668253}, {"id": 308, "seek": 91764, "start": 940.56, "end": 941.72, "text": " we did not have any problem.", "tokens": [321, 630, 406, 362, 604, 1154, 13], "temperature": 0.0, "avg_logprob": -0.21856978445342093, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0009594522998668253}, {"id": 309, "seek": 91764, "start": 941.72, "end": 943.8, "text": " It was quite straightforward.", "tokens": [467, 390, 1596, 15325, 13], "temperature": 0.0, "avg_logprob": -0.21856978445342093, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0009594522998668253}, {"id": 310, "seek": 91764, "start": 943.8, "end": 946.04, "text": " We did not have any problem.", "tokens": [492, 630, 406, 362, 604, 1154, 13], "temperature": 0.0, "avg_logprob": -0.21856978445342093, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0009594522998668253}, {"id": 311, "seek": 94604, "start": 946.04, "end": 948.4399999999999, "text": " I must say that the NMS state library is,", "tokens": [286, 1633, 584, 300, 264, 426, 10288, 1785, 6405, 307, 11], "temperature": 0.0, "avg_logprob": -0.40775956047905815, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.0002988937485497445}, {"id": 312, "seek": 94604, "start": 948.4399999999999, "end": 950.48, "text": " well, we spoke to the users,", "tokens": [731, 11, 321, 7179, 281, 264, 5022, 11], "temperature": 0.0, "avg_logprob": -0.40775956047905815, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.0002988937485497445}, {"id": 313, "seek": 94604, "start": 950.48, "end": 956.24, "text": " it's quite simple, so that makes it simple for us.", "tokens": [309, 311, 1596, 2199, 11, 370, 300, 1669, 309, 2199, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.40775956047905815, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.0002988937485497445}, {"id": 314, "seek": 94604, "start": 956.24, "end": 960.76, "text": " We did not have any problem. That's it.", "tokens": [492, 630, 406, 362, 604, 1154, 13, 663, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.40775956047905815, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.0002988937485497445}, {"id": 315, "seek": 94604, "start": 960.76, "end": 961.9599999999999, "text": " Okay, thanks.", "tokens": [1033, 11, 3231, 13], "temperature": 0.0, "avg_logprob": -0.40775956047905815, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.0002988937485497445}, {"id": 316, "seek": 96196, "start": 961.96, "end": 977.88, "text": " Before. You mentioned that it was", "tokens": [4546, 13, 509, 2835, 300, 309, 390], "temperature": 0.0, "avg_logprob": -0.29889681074354385, "compression_ratio": 1.366412213740458, "no_speech_prob": 0.0037656209897249937}, {"id": 317, "seek": 96196, "start": 977.88, "end": 982.4000000000001, "text": " a long journey when you implemented this in Rust.", "tokens": [257, 938, 4671, 562, 291, 12270, 341, 294, 34952, 13], "temperature": 0.0, "avg_logprob": -0.29889681074354385, "compression_ratio": 1.366412213740458, "no_speech_prob": 0.0037656209897249937}, {"id": 318, "seek": 96196, "start": 982.4000000000001, "end": 985.84, "text": " Could you compare what you have", "tokens": [7497, 291, 6794, 437, 291, 362], "temperature": 0.0, "avg_logprob": -0.29889681074354385, "compression_ratio": 1.366412213740458, "no_speech_prob": 0.0037656209897249937}, {"id": 319, "seek": 96196, "start": 985.84, "end": 990.72, "text": " expected in the beginning of this journey and with the reality?", "tokens": [5176, 294, 264, 2863, 295, 341, 4671, 293, 365, 264, 4103, 30], "temperature": 0.0, "avg_logprob": -0.29889681074354385, "compression_ratio": 1.366412213740458, "no_speech_prob": 0.0037656209897249937}, {"id": 320, "seek": 99072, "start": 990.72, "end": 994.48, "text": " I must say that I'm not the only one person working on this.", "tokens": [286, 1633, 584, 300, 286, 478, 406, 264, 787, 472, 954, 1364, 322, 341, 13], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 321, "seek": 99072, "start": 994.48, "end": 996.24, "text": " There is my teammate, Chris,", "tokens": [821, 307, 452, 25467, 11, 6688, 11], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 322, "seek": 99072, "start": 996.24, "end": 999.6, "text": " and Chris was the lead here.", "tokens": [293, 6688, 390, 264, 1477, 510, 13], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 323, "seek": 99072, "start": 999.6, "end": 1001.8000000000001, "text": " I must say that I did not trust very much,", "tokens": [286, 1633, 584, 300, 286, 630, 406, 3361, 588, 709, 11], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 324, "seek": 99072, "start": 1001.8000000000001, "end": 1003.84, "text": " that we were able to do it in two years.", "tokens": [300, 321, 645, 1075, 281, 360, 309, 294, 732, 924, 13], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 325, "seek": 99072, "start": 1003.84, "end": 1005.36, "text": " So we were like, yeah, in two years,", "tokens": [407, 321, 645, 411, 11, 1338, 11, 294, 732, 924, 11], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 326, "seek": 99072, "start": 1005.36, "end": 1009.24, "text": " we are going to have Rust and I was like, I don't think so.", "tokens": [321, 366, 516, 281, 362, 34952, 293, 286, 390, 411, 11, 286, 500, 380, 519, 370, 13], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 327, "seek": 99072, "start": 1009.24, "end": 1011.52, "text": " But he was right.", "tokens": [583, 415, 390, 558, 13], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 328, "seek": 99072, "start": 1011.52, "end": 1015.4, "text": " So I think my expectation is that it will take much longer,", "tokens": [407, 286, 519, 452, 14334, 307, 300, 309, 486, 747, 709, 2854, 11], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 329, "seek": 99072, "start": 1015.4, "end": 1018.2, "text": " but it was much simpler than what I thought.", "tokens": [457, 309, 390, 709, 18587, 813, 437, 286, 1194, 13], "temperature": 0.0, "avg_logprob": -0.21828262565671935, "compression_ratio": 1.708502024291498, "no_speech_prob": 0.00011687698133755475}, {"id": 330, "seek": 101820, "start": 1018.2, "end": 1023.44, "text": " So also, I thought that we could have more problems", "tokens": [407, 611, 11, 286, 1194, 300, 321, 727, 362, 544, 2740], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 331, "seek": 101820, "start": 1023.44, "end": 1025.44, "text": " with finding the libraries that we", "tokens": [365, 5006, 264, 15148, 300, 321], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 332, "seek": 101820, "start": 1025.44, "end": 1027.8, "text": " need to do all the positions that we needed.", "tokens": [643, 281, 360, 439, 264, 8432, 300, 321, 2978, 13], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 333, "seek": 101820, "start": 1027.8, "end": 1031.64, "text": " But I must say that Rust have a great ecosystem.", "tokens": [583, 286, 1633, 584, 300, 34952, 362, 257, 869, 11311, 13], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 334, "seek": 101820, "start": 1031.64, "end": 1034.28, "text": " So the libraries that we are using,", "tokens": [407, 264, 15148, 300, 321, 366, 1228, 11], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 335, "seek": 101820, "start": 1034.28, "end": 1038.0800000000002, "text": " they are really, really well maintained and that's great.", "tokens": [436, 366, 534, 11, 534, 731, 17578, 293, 300, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 336, "seek": 101820, "start": 1038.0800000000002, "end": 1039.52, "text": " Let's work for us.", "tokens": [961, 311, 589, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 337, "seek": 101820, "start": 1039.52, "end": 1041.44, "text": " We have a question from the matrix.", "tokens": [492, 362, 257, 1168, 490, 264, 8141, 13], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 338, "seek": 101820, "start": 1041.44, "end": 1042.32, "text": " Sure.", "tokens": [4894, 13], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 339, "seek": 101820, "start": 1042.32, "end": 1043.56, "text": " So that's a bit weird.", "tokens": [407, 300, 311, 257, 857, 3657, 13], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 340, "seek": 101820, "start": 1043.56, "end": 1045.96, "text": " Tanya is asking, how long did it take", "tokens": [314, 8791, 307, 3365, 11, 577, 938, 630, 309, 747], "temperature": 0.0, "avg_logprob": -0.2750985518745754, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.35143883805722e-05}, {"id": 341, "seek": 104596, "start": 1045.96, "end": 1049.04, "text": " your team to learn Rust or did they know Rust already?", "tokens": [428, 1469, 281, 1466, 34952, 420, 630, 436, 458, 34952, 1217, 30], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 342, "seek": 104596, "start": 1049.04, "end": 1050.0, "text": " No.", "tokens": [883, 13], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 343, "seek": 104596, "start": 1050.0, "end": 1051.56, "text": " We did not know Rust.", "tokens": [492, 630, 406, 458, 34952, 13], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 344, "seek": 104596, "start": 1051.56, "end": 1055.08, "text": " I mean, we didn't know what Rust was", "tokens": [286, 914, 11, 321, 994, 380, 458, 437, 34952, 390], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 345, "seek": 104596, "start": 1055.08, "end": 1057.52, "text": " and we did some work on Rust.", "tokens": [293, 321, 630, 512, 589, 322, 34952, 13], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 346, "seek": 104596, "start": 1057.52, "end": 1058.6000000000001, "text": " But we did one thing here.", "tokens": [583, 321, 630, 472, 551, 510, 13], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 347, "seek": 104596, "start": 1058.6000000000001, "end": 1061.72, "text": " We started with NISPOR instead with NMS state.", "tokens": [492, 1409, 365, 426, 2343, 47, 2483, 2602, 365, 426, 10288, 1785, 13], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 348, "seek": 104596, "start": 1061.72, "end": 1064.4, "text": " So when we noticed what are the missing pieces,", "tokens": [407, 562, 321, 5694, 437, 366, 264, 5361, 3755, 11], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 349, "seek": 104596, "start": 1064.4, "end": 1066.2, "text": " we first started with NISPOR, which", "tokens": [321, 700, 1409, 365, 426, 2343, 47, 2483, 11, 597], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 350, "seek": 104596, "start": 1066.2, "end": 1071.2, "text": " is much simpler than NMS state, and we learned on the way.", "tokens": [307, 709, 18587, 813, 426, 10288, 1785, 11, 293, 321, 3264, 322, 264, 636, 13], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 351, "seek": 104596, "start": 1071.2, "end": 1072.64, "text": " I must say that I am most surprised", "tokens": [286, 1633, 584, 300, 286, 669, 881, 6100], "temperature": 0.0, "avg_logprob": -0.18285858154296875, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00013484856754075736}, {"id": 352, "seek": 107264, "start": 1072.64, "end": 1077.64, "text": " with all the Rust resources that it was quite easy to learn.", "tokens": [365, 439, 264, 34952, 3593, 300, 309, 390, 1596, 1858, 281, 1466, 13], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 353, "seek": 107264, "start": 1077.64, "end": 1080.0800000000002, "text": " But we learned on the way.", "tokens": [583, 321, 3264, 322, 264, 636, 13], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 354, "seek": 107264, "start": 1080.0800000000002, "end": 1082.0, "text": " When we needed something, we started learning it.", "tokens": [1133, 321, 2978, 746, 11, 321, 1409, 2539, 309, 13], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 355, "seek": 107264, "start": 1082.0, "end": 1084.3600000000001, "text": " And then we revisited the code and we changed things.", "tokens": [400, 550, 321, 20767, 1226, 264, 3089, 293, 321, 3105, 721, 13], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 356, "seek": 107264, "start": 1084.3600000000001, "end": 1086.5600000000002, "text": " For example, initially, we did not", "tokens": [1171, 1365, 11, 9105, 11, 321, 630, 406], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 357, "seek": 107264, "start": 1086.5600000000002, "end": 1088.8000000000002, "text": " understood correctly how to use traits,", "tokens": [7320, 8944, 577, 281, 764, 19526, 11], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 358, "seek": 107264, "start": 1088.8000000000002, "end": 1090.24, "text": " so we did not use them.", "tokens": [370, 321, 630, 406, 764, 552, 13], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 359, "seek": 107264, "start": 1090.24, "end": 1093.3200000000002, "text": " And then we noticed, right, traits are really useful.", "tokens": [400, 550, 321, 5694, 11, 558, 11, 19526, 366, 534, 4420, 13], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 360, "seek": 107264, "start": 1093.3200000000002, "end": 1095.1200000000001, "text": " We are not using them.", "tokens": [492, 366, 406, 1228, 552, 13], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 361, "seek": 107264, "start": 1095.1200000000001, "end": 1097.3200000000002, "text": " And then we started to implement traits everywhere", "tokens": [400, 550, 321, 1409, 281, 4445, 19526, 5315], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 362, "seek": 107264, "start": 1097.3200000000002, "end": 1100.2800000000002, "text": " and make it more flexible.", "tokens": [293, 652, 309, 544, 11358, 13], "temperature": 0.0, "avg_logprob": -0.1806089185899304, "compression_ratio": 1.7606177606177607, "no_speech_prob": 3.936487701139413e-05}, {"id": 363, "seek": 110028, "start": 1100.28, "end": 1103.04, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.4238293030682732, "compression_ratio": 1.205128205128205, "no_speech_prob": 0.00018548245134297758}, {"id": 364, "seek": 110028, "start": 1103.04, "end": 1103.54, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.4238293030682732, "compression_ratio": 1.205128205128205, "no_speech_prob": 0.00018548245134297758}, {"id": 365, "seek": 110028, "start": 1103.54, "end": 1105.84, "text": " There's no more questions.", "tokens": [821, 311, 572, 544, 1651, 13], "temperature": 0.0, "avg_logprob": -0.4238293030682732, "compression_ratio": 1.205128205128205, "no_speech_prob": 0.00018548245134297758}, {"id": 366, "seek": 110028, "start": 1105.84, "end": 1106.84, "text": " Thank you for your time.", "tokens": [1044, 291, 337, 428, 565, 13], "temperature": 0.0, "avg_logprob": -0.4238293030682732, "compression_ratio": 1.205128205128205, "no_speech_prob": 0.00018548245134297758}, {"id": 367, "seek": 110028, "start": 1106.84, "end": 1107.84, "text": " Thank you for listening.", "tokens": [1044, 291, 337, 4764, 13], "temperature": 0.0, "avg_logprob": -0.4238293030682732, "compression_ratio": 1.205128205128205, "no_speech_prob": 0.00018548245134297758}, {"id": 368, "seek": 110784, "start": 1107.84, "end": 1131.84, "text": " Thank you very much.", "tokens": [1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.7975339359707303, "compression_ratio": 0.7142857142857143, "no_speech_prob": 0.000709892890881747}], "language": "en"}