{"text": " Okay, hello everybody. Can you hear me? Yes, I see thumbs up at the back. Please come in, come in, roll up, roll up for the Matrix show or introducing Matrix 2.0 or how we are going to make or how we have made Matrix go boom, very technical term. Please take your seats, ladies and gentlemen. Right, so hi everybody. I'm Matthew. I'm the project lead and co-founder of Matrix and I'm here to tell you all about the work we've been doing to fix Matrix's performance problems and a few other things as well. So I'm guessing that a bunch of people know what Matrix is, given that Vostem has been running on Matrix during the pandemic and we're doing four hard to lead doing a hybrid Matrix version of Vostem right now as we speak. So hello to everybody following along on the HLS stream by Matrix. You probably know that Matrix is an open network for secure decentralized real-time communication. We have to say this because people watching the video might not know later on. You can use it for interoperable chats, so following along on Vostem, bridge through to ILC or X and PP, etc. You can use it for interoperable VoIP, but Matrix at its core is a real-time communication fabric for any kind of real-time comms. So you could use it for communication within VR or AR. You could use it to synchronize world data within VR and AR. You could use it for IoT. It is basically meant to be the missing communication layer of the open web. So no single party in Matrix owns your conversations. The second you talk to somebody on a different server, your conversations get replicated equally between the different servers, so there cannot be a gatekeeper. There cannot be some big tech company going and holding your conversations hostage. Instead, the conversations are shared between all the participants. To apologize, the network is a mesh of servers like Vostem.org, say, on the right, which might be talking to Mozilla.org, which might be talking to Matrix.org, or Nome.org, KDE.org, or whatever it is, and you have native Matrix clients like Element, or Fluffy Chat, or Mecca, or Katernion, or hundreds of others these days, which connect through to the Matrix server. Then you have application services, which glue additional things onto the Matrix server, like bridges, or bots. You have identity servers, which we don't talk about because they're a mess, and we need to get rid of them. And then you've got application services that bridge through to things like Slack, or Teams, or Telegram, or ILC, or XMPP, et cetera. And that is a schematic view of the public Matrix network. Now, the Matrix ecosystem, as it sits today, looks something like this. You've got the Matrix spec still being the kind of one true commonality across the whole ecosystem, spec.matrix.org, a whole bunch of markdown, and swagger, or open API, I should say, that defines how the server's on the bottom, talk to the clients on the top. So you've got Synapse, as our first-gen Python server, which has been proving to be a bit more than first-generation, as we've invested a lot of time making it fast and generally performant. So Synapse is not going away anytime soon. If anything, it is corroding into Rust as the Python is augmented cybernetically with a bunch of Rust. Then we have Dendrite in Go, which is also doing very well and is ending up focusing more on embedded use cases. So you use Synapse for massive servers and use Dendrite for ones you embed into an app. Then we have application services and bridges for things like ILC bridging, et cetera. And then many other servers and bots and bridges from the wider community. The green stuff is stuff that we published as the matrix.org foundation, all Apache licensed for people to build on top of. We have, then, the clients. On the far left, we have our original SDKs of matrix JS SDK, React SDK on top of it, and then iOS SDK and Android SDK too. These are relatively venerable SDKs now. JS SDK is eight years old, which is, you know, enough to probably get a degree or something. iOS SDK is about the same age. Android SDK is a little bit younger, but this is what the current generations of element use today. Then we have Hydrogen, which is a relative newcomer. This is a progressive web app SDK, super small. It's about 70, 80 kilobytes in total for the whole thing, including all end-to-end encryption. And it's designed for embedded web matrix instances. So we have Hydrogen itself, hydrogen.element.io, as a very lightweight PWA for playing around with matrix. We have chatterbox as intercom style embeds a matrix chatbox into your website. We have Surderoom, which is our crazy science fiction spatial collaboration on top of matrix platform, where you want to have the matrix bit as lightweight as possible, which is why we use Hydrogen, the lightest element, to make it happen. And then the thing we'll be talking about a lot today is element X. So this is a total rewrite of element mobile on iOS and Android. And for maximum cliche, we have rewritten it in Rust using the matrix Rust SDK. I hear we have Rust fans in the audience. So we'll be talking a lot about that. Meanwhile, on the community side, there are just more and more clients all over the place, like Thunderbird released its native matrix implementation. We've got Watch the Matrix, which is an excellent Apple Watch matrix client, which doesn't tether to your phone. It's actually running on the watch itself. NeoChats, and KD, and QTE, and C++. I wish I could name them all. I can't. I don't have time. So help for the network. Here is the total number of users we've ever seen on matrix, which is, looked as if it was going to hit 90 million, and then somebody turned off the server. Kids, this is what happens if you turn off the server, because it means the graph goes down. So please never, ever turn off your matrix servers ever again. This is literally the phone home stats that Synapse reports. So it doesn't include Android. It doesn't include Conduit or other servers. It also doesn't include all of the paranoid people, which is quite a lot of people running matrix who obviously aren't going to phone home their usage stats to us. It does include guest users and bridge users. So it's a little bit of an overestimate. But the important thing is the shape of the graph, which, as you can see, is continuing to go well, apart from that guy who turned off his server. In terms of the spec, we have fallen into this cadence of quarterly releases of matrix since the big 1.0 back in 2020, and then particularly in 2022, we've managed to crank out a point release every quarter. Just in, I think, the day before Last Foster, we had spaces, restricted joins, and actually the matrix ERI scheme, which is now being implemented all over the place. Then a few months later, we added aggregations and restricted knocking. Now, these features have often been around for years, but this is actually formalizing them into the proper long-term supported spec. 1.4 added threads, massive feature that has been an epic to get done, but it landed. Edits, private read receipts, a very long time complained about matrix being that you couldn't turn off read receipts, turns out it's surprisingly hard to do, but we now have it specced and implemented. Then 1.5 in November, we added in formalized references, we fixed up some things in the ASAPI, and I think we have basically maintenance release on 1.6 any day now. So nothing too exciting in the next release, mainly because we're building up to the big 2.0. Nice stat is that there were 120 MSCs in 2022, of which 39 came from the community, 27 from new contributors, 30 from the gray beards of the spec core team, and then 51 from the folks who are paid to work on matrix.org, mainly by element. So it's a reasonable mix of community and core project work. In terms of uptake, other than that, we obviously help the world's best open source conference, dodge COVID. Hopefully, apologies if matrix was painful over the last couple of years, but it's probably better than no false to me at all. Lots of government uptake. New news is Germany, we have bundles messenger rolling out matrix across the whole German government in November, also good martyred, the German healthcare agency, proposing it as a neutral standard for secure messaging in healthcare. Lots and lots of associated deployments in healthcare, education, utilities, manufacturing. Basically, if you are an organization who cannot put their data unencrypted into some proprietary silo, like teams or Slack, I think matrix hopefully provides a good alternative. Moodle is busy integrating matrix into the learning management system. Automatic have got a project called chat tricks, which embeds matrix into WordPress, so you can literally dump your little chat console based on hydrogen into your WordPress blog. Reddit is rumored to be building chat capability powered by matrix, mainly because I think they had public who sign up enabled and somebody logged in and discovered a matrix over there, and there's a lot of interest over matrix being potentially the communication there for the digital market sites. So, last year, we put out this slide to basically say the plan for 2022. In the early days of matrix, we were just trying to make it work. Then we tried to make it work right and managed to exit beta and launched the 1.0. The last year particularly has been trying to make it work fast, and I hope we have now made it work fast. I will attempt to prove this to you with a demo. We haven't seen anything yet. So, there is one of my cats helping me here as a kid. Now, along the bottom here, you might see three, four icons in fact, element X, element R, element X itself, so that's element X nightly, and then element normal. We're going to talk about element X here. So, I've got the nightly here, and I'm going on the ship. This is what you see as a little splash screen. I'm going to hit continue on that, and hopefully I've got enough connectivity to connect to the server. That's a good start. If it takes that long to discover that there's a server out there, then this demo might not go so smoothly. I'm going to log in as my actual main real matrix account. I'm not going to type in my password in front of you, but I'm going to pull it out of my password manager. Hit continue. If the server is there, there's too many people in the room. It hasn't even started talking to the server yet, okay? And that's it. I'm in. So, my account... So, if I was going to try to log in on my normal element account, it would take 20 minutes, because I'm in 4,000 rooms that date back to literally day one, or actually day minus two weeks or something of matrix, and I can go and scrub through all of these gazillion rooms there, and they are all actually there. I can go and find somewhere, I know, try not to expose anything too sensitive, but you can see it's actually already pulled in room previews on all of these things. Going to, I know, this week in matrix, and there is the chat. There is just no spinner here other than the slow network at the beginning, which really was the slow network. And you can see we've got reactions in here. We've got some nice bubbles. We've got replies. We've got joins and parts and day markers, read markers. We've got map markdown. This is the SwiftUI incarnation of element X, but all of the heavy lifting here is done by Rust, and it is transformative. The whole point here is to be faster than Telegram, and I think that we might have got it, although if anybody's in a Telegram account with 4,000 rooms, please tell me how long it takes to log into it afresh and how long it takes to launch. So talking about how long it takes to launch, if I go and quit the app like that and relaunch it, we're in. That was it. And I'm going to risk doing one other thing, which is to launch my non-nightly, which I haven't actually used for a couple of hours. And again, it's synced almost instantly. And what I'm going to do is that this is on a custom build, which is hooked up to Yeager. And if I go over to Yeager, and if I have enough internet connection to even load the Yeager UI, this is going to be really fun for demoing later if this is how bad the connectivity is. And I search for the well-known element X Matthew app in the last, actually, let's do the last 15 minutes or five minutes even, then we've actually hooked up Rust SDK so that all of the logging is structured and all of the logging gets uploaded via LTP to Yeager. And if I had internet access, I should start tethering, I would be able to show you a blow-by-blow account of what happened when I launched the app then a minute ago. So what we're going to see when it finally loads, hopefully, is first of all, it has to pull up a local cache of my messages if you're already logged in from disk. For this, we currently use sled, which is a key value database native to Rust. It hasn't been going amazingly well for us, and let's hope that's the right one. And as you can see here, at the top, we've got the build operation. And the 410 milliseconds there, frankly, should be more like 40, because all it's doing is loading up 20 rooms also out of sled. We're going to move to SQLite because if nothing else, sled spends its entire life rebuilding itself and defragmenting itself when you launch it, which is a bit unfortunate when you're trying to launch an app quickly. Then it restores your session and gets a whole bunch of events out of it, which is the first couple of events on the page. And if you scroll past those, the really interesting one here is doing the sync. So this on the server is 90 milliseconds to calculate your sync response. It's ended up being 900 over the wire because of all you people with your electronic magnetic interference and your mobile phones. But still, you saw that it was very usable. It's like a second to get to the point that you're viewing stuff. And in fact, we already are interactive before the sync response returns thanks to the local store having been resumed. So we have gone deep down the rabbit hole, so the saying goes, to try to optimize the performance on element X. So it is as snappy as iMessage or WhatsApp or Telegram, rather than the slightly clunky beast that we've had historically. So before it looked like this, you got a synapse on the right. We've all sorts of fun workers to do the various bits and bobs. And then we had element iOS with iOS SDK, mainly written in Objective-C, matrix kit in the UI layer with more Swift in it. You had MXCrypto, again written, I think, in Objective-C, and LibOm as the encryption library in C++ and C sitting below it. And then the database layer was horrific with a mix of flat files, realm, core data, carrier pigeon, element iOS has some issues. In our brave new sliding sync world, everything has changed. On the left-hand side, we now have on iOS SwiftUI for the funky app I just showed you. On Android, we have Jetpack Compose. Then we have Unify bindings to the Rust SDK, which has been a lot of fun. Even on our Rust team, it's been hacking way, contributing async bindings through to Swift, to Unify, so that we could expose Rust SDK, complete with nice futures and async through to Swift and Kotlin. And then you've got Rust SDK itself, which is doing all the heavy lifting. It's got the crypto crate within it. And then within that is Vdozomats, which is our native Rust encryption implementation for matrix. Below that, you've got sled and in futures equalize. This then talks through to a sliding sync proxy. And this is written in Go, and it implements MSE 3575, which is sliding sync. And this is the magic for how this works so quickly. It's basically storing, well, it's going and talking normal sync to normal Synapse. So this could be Synapse or Dendrite or Conduit or anything on the right-hand side. The Golang thing is an intermediary that is going and sucking up the state of your account, storing it in a local Postgres and then talking the very, very responsive API in order to pull that data into Element X itself. It does it by looking like this. Sliding sync lets the clients request the bare minimum of data that they need to render the UI. So here's an almost real request where we say, I want to see the currently visible rooms. I want to see the first page to preload it. So I want 20 rooms, 0 to 20. I want it sorted by recency and then name. I only want the avatar and whether it's encrypted. I'm going to get the calculated name whatever. I don't want any messages because we've done a waste time actually downloading scroll back. And we're going to filter it to not have invites, not have old rooms, and not have those pesky space rooms. And whilst we're at it, we want to have end-to-end encryption. We want to have two device messages and we want account data. And the server or the sliding sync proxy will literally just return about 10k of data, which is those 20 rooms with the bare data, bare essentials that you requested. The key design criteria for sliding sync is the performance is constant with the number of rooms. And this was the horrible mistake with the old API and frankly the whole design of matrix historically that as you join more rooms, it gets linearly slower for basically everything. And that was fine for the first few years when people are in a couple of hundred rooms, but obviously we don't want to predicate the success of the protocol on, yeah, it's fine as long as you're not a power user or it's fine as long as you don't actually use it. And if you think of matrix being a bit like a file system, imagine how awful, and I'm looking at you, EXT2, a file system would be if it just slowed down linearly with the number of files that you put in a directory or some other characteristic. And as more and more rooms pop up in matrix, it's not just chat rooms, it could be spaces. Now imagine that you go and join the EU and the, you know, you're working in the EU government and the EU has got a massive space of hierarchy over all of the countries and all of their public sector bodies. Even before you've talked to somebody, you might need to have visibility over this big hierarchy of like a thousand rooms. You do not want your matrix client to take a thousand times longer to log in or sync. So that's basically the entire idea here that you can have an infinite number of rooms, bit like IMAP, where you can have massive mail folders and yet you're only going to care about the subset that your client wants to actually manipulate. Having requested this range of 20 rooms, you then get updates from the server, and this is why it's called sliding sync, that you basically have requested a window over these rooms, these 20 rooms or whatever it might be. And then as the state changes on the server, you get updates of inserts of room here, delete one here, invalidate it here. It doesn't have to be rooms, in future it could be members or other sort of characteristics. This has been shamelessly stolen from Discord, so apologies to Discord folks if you're listening, but thank you also for coming up with this nice approach for how to maintain performance and scrolling on apps. And the end result is just many more. It makes login instant, sync instant, and also time to view rooms instant. Element X is only going to talk sliding sync. There is no point in us wasting time implementing both approaches, but they're really quite different, and we want everybody using Element X for it to have a snappy snappy snappy experience. We've done a lot of iterations. I've been driving the poor Rust team and sliding sync team and Element X team mad by constantly demanding us to try to get the launch time down to 100 mils or something, and there's gone through probably 10 iterations to see how we actually drive the API. And it's been really interesting. The end conclusion is, first of all, when you launch the app, you sync that first screen's worth of rooms, but without any timeline. Literally the request I just showed you. Next, you immediately increase the timeline limit on that window to one. So you'll fill in the room previews, and it was happening so fast earlier that we didn't even have time to spot it happening. And then you pre-cache a page's worth of history of the visible rooms. So when I jumped into TWIM and the history was already all loaded there, it's because the background and pre-cache had already happened because I'd stopped scrolling the room list and immediately jumped in to pre-populate the history for those pages. Then you also incrementally build the big list of all your rooms in the background, which I guess technically is ON with a number of rooms, but because it's happening in the background, it's not on the critical path. It means you can do the scroll for all your rooms or search for a room by name instantly and be able to find them. And finally, you cache it in Sled or SQLite. Rust SDK is doing all the heavy lifting here. The code base is maturing really well. We got it audited at the Vdozomat Slayer last year, thanks to Least Authority, funded by Gamatik. And we have, I think, three other audits planned this year. They were meant to happen last year, but we had disruption along the way. Then, high-quality bindings are critical for this. I mentioned that we've added AsyncFuture to UniFFI. I think this stack could be the ultimate stack for building cross-platform mobile apps going forwards. I mean, you can use Rust for the heavy lifting, and then you hook up at the top a very thin but very native performance layer based on whatever the iOS gives you. And at the beginning, UniFFI was a little bit, it didn't have everything we needed, and so we invested to go and particularly hook up the future support. And the end result, I think, is quite transformational. So that's Rust SDK. Meanwhile, whilst Element X is maturing, we need to keep the existing clients secured too. But so it's going to take us a while to get to parity between Element and Element X. And the project for this for crypto is called Element R, confusingly. So this replaces the old cryptography implementations in JS, iOS, and Android SDK with the same Rust crate that powers Rust SDK. So it's just the crypto crate that is providing a consistent encryption implementation across all the platforms. So this means that if we have hypothetically horrible CVEs popping up, we only have to fix them in one place in the Rust SDK, rather than having to do it four times over between where by West Android and Rust. And you can use this today. It is still beta, so it may kill your cat and flood your house. I've been using it, it occasionally logs me out, which is a bit frustrating because initial sync on V2 takes 20 minutes. But I recommend having a play if you're interested, enable Rusty and Twen's encryption in labs on Element iOS. Androids will be coming fairly soon and Web started working on Friday. We sent the first and received the first encrypted messages by Rust crypto in a Wasm blob inside Element Web then. Rather than climatically, it looks and feels identical to the current crypto, except it's written in Rust. Then another big thing we've done to speed things up is faster remote room joins. So this is a huge internal change to Synapse. So again, you only receive the subset of state you need to participate in a room. Breaks all the assumptions that Synapse had. The rooms are typically atomic. Instead, you basically trickle in the membership of the room in the background after having got the minimum subset to join the room. So for instance, matrix HQ right now, there are 92,948 state events for every user who has ever joined or changed their name or left and a whole bunch of other things. If you actually look at the subset you need to participate in the room, it's 152. So this speeds up the room join time from 15 minutes to 14 seconds. So finally, we will hopefully have fixed the problem where somebody gets and stores matrix Synapse immediately tries to join matrix HQ, sits there for 15 minutes looking at errors as their computer explodes and wonders why everybody thinks matrix is as amazing as it is. So I mean, the computer will still explode because they're still having to talk to all of the servers in the room, but at least they will be responsive in 14 seconds. And we hope that the Synthelating conversation in matrix HQ will be such that it distracts them from the smoke coming out to their server. There's still a lot of room for improvement here. We shouldn't be hammering dead servers, which is where a lot of that time is going. And also, we should be caching the partial state. So, you know, if I want to join matrix HQ, the server can just go and hand me the events I need to do that. Another big thing is matrix RTC. So this is the name we're referring to MSE3401 and 3898 as many because those were awful names, whereas matrix RTC is a bit more snappy. And this is multi-party native VoIP. We've always had one-to-one VoIP. Here, we are standardizing the multi-party Zoom teams, Jetsy style experience, but in a heterogeneous way. So you can use different clients. This is in lamps and element web. Video rooms looks like this on the right hand side, powered by element call. And it works as what we call a matroshka widget, where you embed element call here as a widget. So this is an iframe on the left hand side. But even though element call itself is a matrix client, it is piggybacking on the host's matrix client. So it shares the encryption and the identity. You don't have two logs in sessions. And really excitingly, we have multiple independent implementations of this in element call, hydrogen, third room, and also, I believe, famously, it has an independent implementation in their healthcare product for Germany. And I'll very quickly try to show you a demo of this. And I'm going to show you, where am I going? Oh, cool. That's good. Fozdom 2023. If anybody wants to heckle along on this, then feel free. Oh, I don't have any internet access, do I? Video conferencing demo, so when you don't have any Wi-Fi, it's always a good idea, right? Let's see how it does. So I'm going to pop into that room there. And here is element call. And then I'm also going to spin up a local hydrogen. Here's what I made earlier. Oh, hello, Amundee. Found some meeting here. This is Amundee and everybody. She co-founded Matrix. And I'm going to wish that this thing was telling me that a video call was happening in the room. And still being one that's ended, but in practice, there's one happening right now. I wonder if this is... I wonder why? Okay. Perhaps we'll use a different room. Let's go to Fozdom 2024. Back to the future, everybody. And go over to hydrogen here. And I think I should be able to just be able to join Fozdom 2024 on call.ams.host. Yeah, okay, here I can actually join it. And hey, Presto, you've got me staring at myself like a muppet because nobody else is responding to my comedy joke of moving to 2024. So everybody, oh, hello. Perfect. Somebody at the back. Thank you. Oh, and there's Amundee. So this thing is really cool because it is completely standardized multi-party void signaling. We have two entirely different code bases. There is not a line of codes in common between hydrogen here on the left and element call here on the right. And just like back in the day on the phone network, we could call each other on different things or have different set clients or whatever it might happen to be. Oh, we've got somebody remote. That's awesome. Then here we actually have a proper heterogeneous thing. So unlike JETC or some other conferencing system where everybody has to end up using the same system to work, this is providing an interoperable thing. And crap out on this one because I've got something better. I've got something better. So one of the other projects we have worked at, which we're just releasing now is called Waterfall. Now what we just did then was full mesh. All the clients were talking to one another. I'm amazed that it worked as well as it did. What you want to do, though, is to have what's called an SFU. So these guys which go and mix together the local video calls. And Sean Dubois, who's the project leader at Pion, the Golang WebRTC, wrote one of these called SFU to SFU based on reading MSC3401. And we renamed it Waterfall. We've fleshed it out and we've hooked it up to element call. And I will endeavour to show you what that looks like. And it's going to be quite similar in some ways. Let me actually try a demo, demo room in here. Again, if someone is already in there, I'm going to try a fresh one. Let's call it fresh demo. Again, if anybody wants to try following along on this URL, if you can see it, please do so. Now this looks a little bit different because it's connecting to the SFU instead. Oh, hello and hello. And hopefully we will get some video off and on. So this has been bounced off the go SFU. But perhaps I'll distract everybody by zooming. So this has got a completely different layout on it. And it thinks it's connected. Oh, there's Simon. I'm glad that Simon of all people is able to connect because he has written the vast majority of Waterfall. So thanks for demoing Simon. And I suspect it is not like in the packet loss here on my side. People are trying to connect in there. But it's working for some folks. It's very, very new, very alpha, but it's exciting to actually see this thing working. And if I quickly turn on debug here in developer mode, you'll see that it actually supports simulcast. So here you can see that Simon is 640 by 360 pixels. Whereas this guy here in dandelion, hello dandelion, is 320 by 240. And if I go and zoom embarrassingly, then it should catch up. There we go. 640 by 480. And it's going to renegotiate the higher resolution stream through. And all the people are going and actually uploading multiple low resolution and high resolution ones. So this is very early, but it's the shape of the future for doing proper massive scalable SFU based conferences. And that's actually looking good. I'm going to take a quick selfie. There we go. Right. Next demo or next stuff. I'm running out of time. I've got a lot of demos. OpenID Connect. Matrix is subject to MSE approval. Moving over to OpenID Connect. It rocks and gives us 2FA, multifactorial, pass keys, QR code login. You don't have to implement the weird matrix off APIs on the server or the clients anymore. ElementX has native OIDC on iOS already and will be OIDC first. First room is the first OIDC only matrix client. Go to our OIDC yet.com for the gory details. So SigningSync faster joins native VoIP and OIDC is a big change. Like this is fundamentally changing how federation works, how VoIP works, and critically how servers sync data to clients, and how you log in. Couldn't be a bigger change. So we are taking the liberty of declaring it matrix 2.0 when we finally release it. So this is not a breaking change. This is pure enthusiasm basically on my behalf because I think it's worth saying, hey guys, come back to matrix, give it another go because we fixed all the crap stuff and we're calling it matrix 2.0. Okay, I'm not doing well on time. We're halfway through in theory. We're going to go now to the future. Flying cars and jet packs and all that good stuff. First of all, digital markets act. Where we're going, we do not need gatekeepers. If you haven't heard about the DMA, it is a fascinating piece of legislation that mandates the big tech companies must interoperate together, particularly for their communication services. The whole idea is that it empowers users to pick the services they want to use and trust without sacrificing the ability to talk to other people. Now frankly, forces the gatekeepers to differentiate based on quality and features, rather than relying on a monopolistic situation where all of their users happen to be trapped in the silo. This is happening right now. The rules came into force in November. The rules start to apply in May and then gatekeepers get designated and it will start getting enforced, which is chunky GDPR style finds in March 2024 if the gatekeepers have not gone and interoperated things together. Turns out the matrix already provides a secure interoperable communication protocol. Who knows? The DMA requires the gatekeepers to maintain end-to-end encryption, which is good news. There's been a lot of paranoia that DMA is a secret attack on end-to-end encryption. It really isn't. Having spoken to the folks responsible, they really want to make sure that if WhatsApp does E2E today, then an interoperable WhatsApp also needs to do E2E. They don't want to be responsible for destroying privacy. So to re-encrypt, you need to either do it on the client side, so you would install something like a WhatsApp to matrix app if you want to link your WhatsApp account into matrix, or you could do a multi-head approach effectively, open APIs and have your app talk to WhatsApp as well as matrix or whatever. Or everybody ends up talking the same protocol, which means on the server side, the gatekeepers would have to add support for matrix or XNPP or RCS or whatever it might be alongside their somewhat legacy proprietary protocol. ITF is established a working group called MIMI, more instant messaging interoperability targeting the everybody talks the same protocol approach. We've proposed matrix as an ITF draft for content and transport layers, and we're trying to work with them to make the most of the mix. Decentralized MLS, this is another big thing where we're going, we don't need salamanders, because if you haven't noticed, all of the encryption historically have been called axolotl or ohm or proteus, all of which are species of salamander. MLS is another ITF working group, in fact the one from which MIMI has emerged for next generation end-to-end encryption. We have figured out how to make MLS work in a decentralized model. We have implemented it in a toy type script stack called MLSTS. It is currently being re-implemented on top of open MLS and Rust. At which point, when it works, we will integrate it into Rust SDK and build it into real clients and write an MSE. Are we MLS yet dot com for all the gory details? Here are some early performance testing, which is pretty interesting. Let me get the key right for you here. If you look at MEGOM creating new sessions, this is obviously the log log scale for all of you mathematicians. You can see this red dashed line here, showing how MEGOM sessions scale with a number of users, and it's up at 100 seconds if you've got 100,000 users in the room, which is pretty slow. However, if you look at an MLS update or adding new members, then they're down at 1,000 milliseconds, so a couple of seconds. This is a major algorithmic improvement for certain operations over even VODOSMATS. Support of VODOSMATS, which feels relatively new, may get displaced by open MLS and DMLS when we get there, hopefully later this year. In peer-to-peer matrix, where we're going, we don't need servers. Matrix is way too dependent on servers, and the admins and the risks of internet shutdowns and censorship. This is because home servers have to store their users' chat history and metadata. Peer-to-peer matrix exists to fix this. This is a long-running blue sky project, so to speak, where we go and embed your home server inside the app in order to not have a server running in the cloud. Dendrite is the server we use. Big news on Dendrite is, as of a few weeks ago, it passes 100% server API compliance, so it has a parity of a good old Synapse, and 93% client server API, and the 7% is boring stuff we don't really care about for this. Pinecone, the peer-to-peer overlay network, is going really well as well. We just switched to soft state routing for reliability, and as of about 4 a.m. this morning, not me. Initial store and forward relaying is here. I will very rapidly try to demo that. That's still my phone there. If I go and launch Peer-to-peer matrix, Dendrite is not running. Now it is running. This has literally got a Dendrite running inside my phone here, and if I go over to Visor here, I should hopefully also be able to run it on my Android thing. Here it is, and did it already crash? So it is a bit crashy. It is still beta. I've got Fosdom demo here, Fosdom demo here, and slightly, okay, when I first say hello there, then you can see yay, messages flowing back and forth peer-to-peer. Now if I take my iPhone and put it on to airplane mode like so, and send some messages through from Android, they still go. So this is Peer-to-peer matrix running over Bluetooth flow energy. It silently fell over from running over IP into Bluetooth mode. Now the exciting thing is that if I also run... Well, this is going to be an interesting demo. So here is Element Peer-to-peer running in iOS or macOS, because you can do that on an M1 Mac, and apparently there are five connected peers, which is three more than I was expecting, so hello everybody out there who's about to screw up my demo, and you can see the same history coming on here, and I can send a message through, and you can see both on iOS it came through on Android too. Now the really interesting thing is if I go and... Now you are going to screw up my demo. If I go and kill the Peer-to-peer app on Android, and I send a message here saying hello relaying, and actually not in that room, I'm going to do it in my DM through to Android. I'm going to say testing relays, or very badly typed, and critically my... Where has it gone? Has it crashed? No, there is. So I'm not actually in that room. I'm only in one room on my Mac here. However, this hopefully has gone and peered, relayed through to my Android phone. So if I now go and kill the app here on iOS, and relaunch it here on Android, if I knew how to use Android, come on. This is going to work, or is it going to search Google? There it is. Perfect. Hopefully the first thing this thing will do is to... I'm in the wrong room. If Dendrite launches, the red bar is telling me that it can't tell and talk to its own Dendrite. You can do it. Yes! Testing relaying. This is huge because historically Peer-to-peer matrix has had a massive problem that the other guy has to be online running the app at the same time. And a long story, but I ended up on an aircraft carrier a couple of months ago going and trying to explain a bunch of people how they could use matrix in that environment. And there are a bunch of us on board this thing. And it turns out that an aircraft carrier is a massive floating Faraday cage. And we went and fired up Peer-to-peer matrix on it. And we're very smart that we can talk to one another, but you had to physically wave at the other guy to get them to launch the app so they could receive the message. Whereas with a relay, you can obviously talk to them even if the app isn't running. So that's big. Right. We're almost there. Matrix is not just for chat and VoIP. This is the final thing. Third Room is a decentralized consular for, well, matrix is a consular for any kind of real-time data. Third Room is this tiny project done by Robert May and AJ to provide an open decentralized platform for spatial collaboration of any kind built on matrix. It uses hydrogen, 3JS, bit ECS, and rapier for a new engine called manifold. And the idea is you take a matrix room. You upload some GLTF 3D assets to it. You upload some WASM or JavaScript scripts to it. They use matrix RTC to spell up spatial VoIP and physics synchronization over WebRTC. And you get WebFirst, open decentralized virtual worlds and spatial apps without any of the cryptocurrency or token or Facebook stuff, apart from possibly the hardware. And it looks like this. So you can literally go to it right now, thirdroom.io, and I'm going to go to a world called third room presentation here. And it's going to hopefully pull this up out of my index DB, because I don't want to wait to download 50 megabytes over the network. And if the demo gods are smiling, then you find yourself in this rather snazzy demo world. Now, this is running in Braille. So no plugins or anything. And it's going at 60 frames a second. It does this with proper multi-threading using shared array buffers and atomics to synchronize together the WebGL thread and also the game thread and the main thread in the UI. You can see I'm indeed wandering around there wearing a placeholder avatar. I can flip into third person view here. And you can see I'm also wearing the same beautiful thing. We haven't got customizable avatars yet. Some of the things I can show you here is that you can go and click on buttons. And this is actually a script showing the layout of the different threads. I don't have time to show you that right now, but the game thread has got like rapier physics and WebAssembly. But a really fun thing is that you can just do freeform scripting of any kind. So one example could be this silly, silly, silly demo, which hopefully will load up rapidly. Oh, that's what happens if you this is a bug where you have your worlds overlaying on one another. I'm going to keep it like this, but this is pretty cool. So we've got the construct room from the matrix, so I'll see for in place on top of Mars down here. And if I go over to the TV and I click on it, predictably enough, the entire world goes matrix. So the script for that is literally just sitting there as a bunch of JavaScript uploaded into the media repository. And it's compiled down to Wasm in real time by the engine by QuickJS, thanks to Fabrice Bellard. And it's like four lines of code. You use WebSG, which is our new API called WebSceneGraph that we're going to propose to W3C as a 3D API for manipulating JLTF scene graphs. Now you make it intractable and then every tick, every frame, you see if it's being pressed and then you toggle the state and you enable the matrix material on the room. It's slightly cheated by hard coding it on the in the engine for now like this. Something that we haven't hard goaded though is this guy, which is really exciting. I'm going to refresh his time. And here you can see a big scary black blob with Poland noise, which is pulsating according to my voice as I bellow at it. And this thing is actually a huge chunk of C, which is compiled down to Wasm and is going and programmatically changing in real time the JLTF scene. So this is like the first proper, more advanced capabilities on top of third room. The whole idea is you can build any old app on top of this. You could build Figma on this. You could do multiplayer blender. In fact, we have an in-world editor in here where I can go and select this guy at the bottom and they will have a big white bagel around it. And we don't yet have the property editor, but you should be able to go in and directly manipulate it, change the opacity, the transformations, et cetera, and all that sort of thing. And it really ends up feeling a lot like the web. Rather than a DOM, you've got JLTF, rather than the DOM API, you've got the WebSG API, rather than JavaScript, you've got Wasm, Sandblocks, Blobs, with Rust and Zig and C and JavaScript within it. And there is one final thing I'm going to try to show you, which is probably going to go horribly wrong, which is that we've just added WebXR into third room. So if I go and put on my Facebook device, and there we go. And I back away a bit. Probably unplug it. You'll see, hopefully, in fact, I need to go full screen on that. I guess I do. There we go. Is that coming through? You can see that here I am wondering around third room. Probably can get them full off the stage and break my neck. And I can go and, like, spawn object. So you can have big crate. I can throw the crate away. I can spawn some other big crate. Let's run away from that one. Go and pick this guy up and throw it away. Go and pick that one up. It's over here. And throw it away, et cetera. And I mean, this is running at 90 frames a second. 90 frames a second. So that's a bit weird. It is as least as good as the native MetaHorizon stuff, the Facebook of ships, except it's running within WebXR in a browser in a completely open environment. So we're kind of hoping this provides a really viable platform to build a genuine open spatial collaboration plane for the web. I've already spoken about that. Coming up next is persistence. So we don't yet persist the changes into the matrix room, but we will by uploading little bits of JLTF files so you can even have bots which go into that. Another thing I should have shown you, but forgot, was this guy somewhere. I've lost it already. Never mind. Well, I was going to show you it's an echo. This guy here. But if in this room I go in, and I think this is going to be a comedy, yeah, that's what happens if London and Mars get mixed together for everybody. If I go and say hi because, look, it's matrix room, then if I do slash echo something, I get an echo back. That echo has come from a widget in Wasm running inside the world. So you can program matrix now from within Wasm blobs sitting within the room. Nothing to do with third room. You could use this in clients, et cetera, to start doing client-side widgets. So what's next? Loads of stuff. One big PSA is that Gitter is going native matrix roughly next week. We basically can't afford to run both the Gitter infrastructure and a bunch of matrix infrastructure. So Gitter will become a branded element instance. The API will go away. Please use matrix instead. And finally, we need help. Friends, don't let friends use proprietary chat services. Please use matrix. And critically, and this is new and it's really important, if you're benefiting commercially from matrix, please financially support the foundation because it's stuck in this horrible feedback loop at the moment where the better we make matrix, the less inclined it seems that people want to pay for support or pay for things if they can just grab it on GitHub. This can end up being a disaster where we run out of cash. So please, please, please contribute back, particularly if you're a government. You've got loads of money. Also, run a server, run bridges bots, build on matrix, follow us on MasterDone, and thank you very much. Thanks for listening. Sorry for running on time, as always.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.16, "text": " Okay, hello everybody. Can you hear me? Yes, I see thumbs up at the back. Please come in,", "tokens": [1033, 11, 7751, 2201, 13, 1664, 291, 1568, 385, 30, 1079, 11, 286, 536, 8838, 493, 412, 264, 646, 13, 2555, 808, 294, 11], "temperature": 0.0, "avg_logprob": -0.2564129384358724, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.3748026192188263}, {"id": 1, "seek": 0, "start": 14.16, "end": 20.240000000000002, "text": " come in, roll up, roll up for the Matrix show or introducing Matrix 2.0 or how we are going", "tokens": [808, 294, 11, 3373, 493, 11, 3373, 493, 337, 264, 36274, 855, 420, 15424, 36274, 568, 13, 15, 420, 577, 321, 366, 516], "temperature": 0.0, "avg_logprob": -0.2564129384358724, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.3748026192188263}, {"id": 2, "seek": 0, "start": 20.240000000000002, "end": 26.32, "text": " to make or how we have made Matrix go boom, very technical term. Please take your seats,", "tokens": [281, 652, 420, 577, 321, 362, 1027, 36274, 352, 9351, 11, 588, 6191, 1433, 13, 2555, 747, 428, 11069, 11], "temperature": 0.0, "avg_logprob": -0.2564129384358724, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.3748026192188263}, {"id": 3, "seek": 2632, "start": 26.32, "end": 33.76, "text": " ladies and gentlemen. Right, so hi everybody. I'm Matthew. I'm the project lead and co-founder", "tokens": [9974, 293, 11669, 13, 1779, 11, 370, 4879, 2201, 13, 286, 478, 12434, 13, 286, 478, 264, 1716, 1477, 293, 598, 12, 33348], "temperature": 0.0, "avg_logprob": -0.16690901748272552, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000797112297732383}, {"id": 4, "seek": 2632, "start": 33.76, "end": 39.28, "text": " of Matrix and I'm here to tell you all about the work we've been doing to fix Matrix's performance", "tokens": [295, 36274, 293, 286, 478, 510, 281, 980, 291, 439, 466, 264, 589, 321, 600, 668, 884, 281, 3191, 36274, 311, 3389], "temperature": 0.0, "avg_logprob": -0.16690901748272552, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000797112297732383}, {"id": 5, "seek": 2632, "start": 39.28, "end": 45.519999999999996, "text": " problems and a few other things as well. So I'm guessing that a bunch of people know what Matrix", "tokens": [2740, 293, 257, 1326, 661, 721, 382, 731, 13, 407, 286, 478, 17939, 300, 257, 3840, 295, 561, 458, 437, 36274], "temperature": 0.0, "avg_logprob": -0.16690901748272552, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000797112297732383}, {"id": 6, "seek": 2632, "start": 45.519999999999996, "end": 50.0, "text": " is, given that Vostem has been running on Matrix during the pandemic and we're doing", "tokens": [307, 11, 2212, 300, 691, 555, 443, 575, 668, 2614, 322, 36274, 1830, 264, 5388, 293, 321, 434, 884], "temperature": 0.0, "avg_logprob": -0.16690901748272552, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000797112297732383}, {"id": 7, "seek": 2632, "start": 50.0, "end": 55.2, "text": " four hard to lead doing a hybrid Matrix version of Vostem right now as we speak. So hello to", "tokens": [1451, 1152, 281, 1477, 884, 257, 13051, 36274, 3037, 295, 691, 555, 443, 558, 586, 382, 321, 1710, 13, 407, 7751, 281], "temperature": 0.0, "avg_logprob": -0.16690901748272552, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000797112297732383}, {"id": 8, "seek": 5520, "start": 55.2, "end": 61.28, "text": " everybody following along on the HLS stream by Matrix. You probably know that Matrix is an open", "tokens": [2201, 3480, 2051, 322, 264, 389, 19198, 4309, 538, 36274, 13, 509, 1391, 458, 300, 36274, 307, 364, 1269], "temperature": 0.0, "avg_logprob": -0.14562245777675084, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.00026862314553000033}, {"id": 9, "seek": 5520, "start": 61.28, "end": 66.8, "text": " network for secure decentralized real-time communication. We have to say this because", "tokens": [3209, 337, 7144, 32870, 957, 12, 3766, 6101, 13, 492, 362, 281, 584, 341, 570], "temperature": 0.0, "avg_logprob": -0.14562245777675084, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.00026862314553000033}, {"id": 10, "seek": 5520, "start": 66.8, "end": 71.12, "text": " people watching the video might not know later on. You can use it for interoperable chats,", "tokens": [561, 1976, 264, 960, 1062, 406, 458, 1780, 322, 13, 509, 393, 764, 309, 337, 728, 7192, 712, 38057, 11], "temperature": 0.0, "avg_logprob": -0.14562245777675084, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.00026862314553000033}, {"id": 11, "seek": 5520, "start": 71.12, "end": 76.24000000000001, "text": " so following along on Vostem, bridge through to ILC or X and PP, etc. You can use it for", "tokens": [370, 3480, 2051, 322, 691, 555, 443, 11, 7283, 807, 281, 286, 14766, 420, 1783, 293, 37369, 11, 5183, 13, 509, 393, 764, 309, 337], "temperature": 0.0, "avg_logprob": -0.14562245777675084, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.00026862314553000033}, {"id": 12, "seek": 5520, "start": 76.24000000000001, "end": 82.24000000000001, "text": " interoperable VoIP, but Matrix at its core is a real-time communication fabric for any kind", "tokens": [728, 7192, 712, 7518, 9139, 11, 457, 36274, 412, 1080, 4965, 307, 257, 957, 12, 3766, 6101, 7253, 337, 604, 733], "temperature": 0.0, "avg_logprob": -0.14562245777675084, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.00026862314553000033}, {"id": 13, "seek": 8224, "start": 82.24, "end": 87.11999999999999, "text": " of real-time comms. So you could use it for communication within VR or AR. You could use it", "tokens": [295, 957, 12, 3766, 800, 82, 13, 407, 291, 727, 764, 309, 337, 6101, 1951, 13722, 420, 8943, 13, 509, 727, 764, 309], "temperature": 0.0, "avg_logprob": -0.08784895871592834, "compression_ratio": 1.8320895522388059, "no_speech_prob": 4.3653220927808434e-05}, {"id": 14, "seek": 8224, "start": 87.11999999999999, "end": 92.96, "text": " to synchronize world data within VR and AR. You could use it for IoT. It is basically meant to be", "tokens": [281, 19331, 1125, 1002, 1412, 1951, 13722, 293, 8943, 13, 509, 727, 764, 309, 337, 30112, 13, 467, 307, 1936, 4140, 281, 312], "temperature": 0.0, "avg_logprob": -0.08784895871592834, "compression_ratio": 1.8320895522388059, "no_speech_prob": 4.3653220927808434e-05}, {"id": 15, "seek": 8224, "start": 92.96, "end": 100.8, "text": " the missing communication layer of the open web. So no single party in Matrix owns your conversations.", "tokens": [264, 5361, 6101, 4583, 295, 264, 1269, 3670, 13, 407, 572, 2167, 3595, 294, 36274, 19143, 428, 7315, 13], "temperature": 0.0, "avg_logprob": -0.08784895871592834, "compression_ratio": 1.8320895522388059, "no_speech_prob": 4.3653220927808434e-05}, {"id": 16, "seek": 8224, "start": 100.8, "end": 105.03999999999999, "text": " The second you talk to somebody on a different server, your conversations get replicated equally", "tokens": [440, 1150, 291, 751, 281, 2618, 322, 257, 819, 7154, 11, 428, 7315, 483, 46365, 12309], "temperature": 0.0, "avg_logprob": -0.08784895871592834, "compression_ratio": 1.8320895522388059, "no_speech_prob": 4.3653220927808434e-05}, {"id": 17, "seek": 8224, "start": 105.03999999999999, "end": 110.72, "text": " between the different servers, so there cannot be a gatekeeper. There cannot be some big tech company", "tokens": [1296, 264, 819, 15909, 11, 370, 456, 2644, 312, 257, 8539, 23083, 13, 821, 2644, 312, 512, 955, 7553, 2237], "temperature": 0.0, "avg_logprob": -0.08784895871592834, "compression_ratio": 1.8320895522388059, "no_speech_prob": 4.3653220927808434e-05}, {"id": 18, "seek": 11072, "start": 110.72, "end": 115.6, "text": " going and holding your conversations hostage. Instead, the conversations are shared between", "tokens": [516, 293, 5061, 428, 7315, 38434, 13, 7156, 11, 264, 7315, 366, 5507, 1296], "temperature": 0.0, "avg_logprob": -0.20811062622070312, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.00037020473973825574}, {"id": 19, "seek": 11072, "start": 115.6, "end": 122.48, "text": " all the participants. To apologize, the network is a mesh of servers like Vostem.org, say,", "tokens": [439, 264, 10503, 13, 1407, 12328, 11, 264, 3209, 307, 257, 17407, 295, 15909, 411, 691, 555, 443, 13, 4646, 11, 584, 11], "temperature": 0.0, "avg_logprob": -0.20811062622070312, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.00037020473973825574}, {"id": 20, "seek": 11072, "start": 122.48, "end": 127.2, "text": " on the right, which might be talking to Mozilla.org, which might be talking to Matrix.org, or Nome.org,", "tokens": [322, 264, 558, 11, 597, 1062, 312, 1417, 281, 3335, 26403, 13, 4646, 11, 597, 1062, 312, 1417, 281, 36274, 13, 4646, 11, 420, 426, 423, 13, 4646, 11], "temperature": 0.0, "avg_logprob": -0.20811062622070312, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.00037020473973825574}, {"id": 21, "seek": 11072, "start": 127.2, "end": 132.64, "text": " KDE.org, or whatever it is, and you have native Matrix clients like Element, or Fluffy Chat,", "tokens": [591, 22296, 13, 4646, 11, 420, 2035, 309, 307, 11, 293, 291, 362, 8470, 36274, 6982, 411, 20900, 11, 420, 3235, 14297, 27503, 11], "temperature": 0.0, "avg_logprob": -0.20811062622070312, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.00037020473973825574}, {"id": 22, "seek": 11072, "start": 132.64, "end": 137.28, "text": " or Mecca, or Katernion, or hundreds of others these days, which connect through to the Matrix", "tokens": [420, 1923, 22394, 11, 420, 591, 771, 77, 313, 11, 420, 6779, 295, 2357, 613, 1708, 11, 597, 1745, 807, 281, 264, 36274], "temperature": 0.0, "avg_logprob": -0.20811062622070312, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.00037020473973825574}, {"id": 23, "seek": 13728, "start": 137.28, "end": 143.2, "text": " server. Then you have application services, which glue additional things onto the Matrix server,", "tokens": [7154, 13, 1396, 291, 362, 3861, 3328, 11, 597, 8998, 4497, 721, 3911, 264, 36274, 7154, 11], "temperature": 0.0, "avg_logprob": -0.11841972668965657, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0002633456024341285}, {"id": 24, "seek": 13728, "start": 143.2, "end": 147.92000000000002, "text": " like bridges, or bots. You have identity servers, which we don't talk about because they're a mess,", "tokens": [411, 21114, 11, 420, 35410, 13, 509, 362, 6575, 15909, 11, 597, 321, 500, 380, 751, 466, 570, 436, 434, 257, 2082, 11], "temperature": 0.0, "avg_logprob": -0.11841972668965657, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0002633456024341285}, {"id": 25, "seek": 13728, "start": 147.92000000000002, "end": 152.8, "text": " and we need to get rid of them. And then you've got application services that bridge through to", "tokens": [293, 321, 643, 281, 483, 3973, 295, 552, 13, 400, 550, 291, 600, 658, 3861, 3328, 300, 7283, 807, 281], "temperature": 0.0, "avg_logprob": -0.11841972668965657, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0002633456024341285}, {"id": 26, "seek": 13728, "start": 152.8, "end": 158.8, "text": " things like Slack, or Teams, or Telegram, or ILC, or XMPP, et cetera. And that is a schematic view", "tokens": [721, 411, 37211, 11, 420, 24702, 11, 420, 14889, 1342, 11, 420, 286, 14766, 11, 420, 1783, 12224, 47, 11, 1030, 11458, 13, 400, 300, 307, 257, 44739, 1910], "temperature": 0.0, "avg_logprob": -0.11841972668965657, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0002633456024341285}, {"id": 27, "seek": 13728, "start": 158.8, "end": 164.48, "text": " of the public Matrix network. Now, the Matrix ecosystem, as it sits today, looks something", "tokens": [295, 264, 1908, 36274, 3209, 13, 823, 11, 264, 36274, 11311, 11, 382, 309, 12696, 965, 11, 1542, 746], "temperature": 0.0, "avg_logprob": -0.11841972668965657, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0002633456024341285}, {"id": 28, "seek": 16448, "start": 164.48, "end": 170.64, "text": " like this. You've got the Matrix spec still being the kind of one true commonality across the whole", "tokens": [411, 341, 13, 509, 600, 658, 264, 36274, 1608, 920, 885, 264, 733, 295, 472, 2074, 2689, 1860, 2108, 264, 1379], "temperature": 0.0, "avg_logprob": -0.13226415193997898, "compression_ratio": 1.658703071672355, "no_speech_prob": 0.00020419647626113147}, {"id": 29, "seek": 16448, "start": 170.64, "end": 177.2, "text": " ecosystem, spec.matrix.org, a whole bunch of markdown, and swagger, or open API, I should say,", "tokens": [11311, 11, 1608, 13, 15677, 6579, 13, 4646, 11, 257, 1379, 3840, 295, 1491, 5093, 11, 293, 1693, 11062, 11, 420, 1269, 9362, 11, 286, 820, 584, 11], "temperature": 0.0, "avg_logprob": -0.13226415193997898, "compression_ratio": 1.658703071672355, "no_speech_prob": 0.00020419647626113147}, {"id": 30, "seek": 16448, "start": 177.2, "end": 181.83999999999997, "text": " that defines how the server's on the bottom, talk to the clients on the top. So you've got Synapse,", "tokens": [300, 23122, 577, 264, 7154, 311, 322, 264, 2767, 11, 751, 281, 264, 6982, 322, 264, 1192, 13, 407, 291, 600, 658, 26155, 11145, 11], "temperature": 0.0, "avg_logprob": -0.13226415193997898, "compression_ratio": 1.658703071672355, "no_speech_prob": 0.00020419647626113147}, {"id": 31, "seek": 16448, "start": 181.83999999999997, "end": 186.88, "text": " as our first-gen Python server, which has been proving to be a bit more than first-generation,", "tokens": [382, 527, 700, 12, 1766, 15329, 7154, 11, 597, 575, 668, 27221, 281, 312, 257, 857, 544, 813, 700, 12, 30372, 11], "temperature": 0.0, "avg_logprob": -0.13226415193997898, "compression_ratio": 1.658703071672355, "no_speech_prob": 0.00020419647626113147}, {"id": 32, "seek": 16448, "start": 186.88, "end": 192.48, "text": " as we've invested a lot of time making it fast and generally performant. So Synapse is not going", "tokens": [382, 321, 600, 13104, 257, 688, 295, 565, 1455, 309, 2370, 293, 5101, 2042, 394, 13, 407, 26155, 11145, 307, 406, 516], "temperature": 0.0, "avg_logprob": -0.13226415193997898, "compression_ratio": 1.658703071672355, "no_speech_prob": 0.00020419647626113147}, {"id": 33, "seek": 19248, "start": 192.48, "end": 199.51999999999998, "text": " away anytime soon. If anything, it is corroding into Rust as the Python is augmented cybernetically", "tokens": [1314, 13038, 2321, 13, 759, 1340, 11, 309, 307, 45125, 3584, 666, 34952, 382, 264, 15329, 307, 36155, 13411, 7129, 984], "temperature": 0.0, "avg_logprob": -0.0865580766097359, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0001651387574383989}, {"id": 34, "seek": 19248, "start": 199.51999999999998, "end": 205.6, "text": " with a bunch of Rust. Then we have Dendrite in Go, which is also doing very well and is", "tokens": [365, 257, 3840, 295, 34952, 13, 1396, 321, 362, 413, 521, 35002, 294, 1037, 11, 597, 307, 611, 884, 588, 731, 293, 307], "temperature": 0.0, "avg_logprob": -0.0865580766097359, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0001651387574383989}, {"id": 35, "seek": 19248, "start": 205.6, "end": 210.39999999999998, "text": " ending up focusing more on embedded use cases. So you use Synapse for massive servers and use", "tokens": [8121, 493, 8416, 544, 322, 16741, 764, 3331, 13, 407, 291, 764, 26155, 11145, 337, 5994, 15909, 293, 764], "temperature": 0.0, "avg_logprob": -0.0865580766097359, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0001651387574383989}, {"id": 36, "seek": 19248, "start": 210.39999999999998, "end": 216.07999999999998, "text": " Dendrite for ones you embed into an app. Then we have application services and bridges for", "tokens": [413, 521, 35002, 337, 2306, 291, 12240, 666, 364, 724, 13, 1396, 321, 362, 3861, 3328, 293, 21114, 337], "temperature": 0.0, "avg_logprob": -0.0865580766097359, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0001651387574383989}, {"id": 37, "seek": 19248, "start": 216.07999999999998, "end": 221.44, "text": " things like ILC bridging, et cetera. And then many other servers and bots and bridges from the", "tokens": [721, 411, 286, 14766, 16362, 3249, 11, 1030, 11458, 13, 400, 550, 867, 661, 15909, 293, 35410, 293, 21114, 490, 264], "temperature": 0.0, "avg_logprob": -0.0865580766097359, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0001651387574383989}, {"id": 38, "seek": 22144, "start": 221.44, "end": 226.96, "text": " wider community. The green stuff is stuff that we published as the matrix.org foundation,", "tokens": [11842, 1768, 13, 440, 3092, 1507, 307, 1507, 300, 321, 6572, 382, 264, 8141, 13, 4646, 7030, 11], "temperature": 0.0, "avg_logprob": -0.13518464444863676, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.0001765429915394634}, {"id": 39, "seek": 22144, "start": 226.96, "end": 232.88, "text": " all Apache licensed for people to build on top of. We have, then, the clients. On the far left,", "tokens": [439, 46597, 25225, 337, 561, 281, 1322, 322, 1192, 295, 13, 492, 362, 11, 550, 11, 264, 6982, 13, 1282, 264, 1400, 1411, 11], "temperature": 0.0, "avg_logprob": -0.13518464444863676, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.0001765429915394634}, {"id": 40, "seek": 22144, "start": 232.88, "end": 239.52, "text": " we have our original SDKs of matrix JS SDK, React SDK on top of it, and then iOS SDK and", "tokens": [321, 362, 527, 3380, 37135, 82, 295, 8141, 33063, 37135, 11, 30644, 37135, 322, 1192, 295, 309, 11, 293, 550, 17430, 37135, 293], "temperature": 0.0, "avg_logprob": -0.13518464444863676, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.0001765429915394634}, {"id": 41, "seek": 22144, "start": 239.52, "end": 246.48, "text": " Android SDK too. These are relatively venerable SDKs now. JS SDK is eight years old, which is,", "tokens": [8853, 37135, 886, 13, 1981, 366, 7226, 6138, 260, 712, 37135, 82, 586, 13, 33063, 37135, 307, 3180, 924, 1331, 11, 597, 307, 11], "temperature": 0.0, "avg_logprob": -0.13518464444863676, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.0001765429915394634}, {"id": 42, "seek": 24648, "start": 246.48, "end": 252.16, "text": " you know, enough to probably get a degree or something. iOS SDK is about the same age. Android", "tokens": [291, 458, 11, 1547, 281, 1391, 483, 257, 4314, 420, 746, 13, 17430, 37135, 307, 466, 264, 912, 3205, 13, 8853], "temperature": 0.0, "avg_logprob": -0.09754479133476646, "compression_ratio": 1.5802047781569966, "no_speech_prob": 2.4161812689271756e-05}, {"id": 43, "seek": 24648, "start": 252.16, "end": 257.2, "text": " SDK is a little bit younger, but this is what the current generations of element use today.", "tokens": [37135, 307, 257, 707, 857, 7037, 11, 457, 341, 307, 437, 264, 2190, 10593, 295, 4478, 764, 965, 13], "temperature": 0.0, "avg_logprob": -0.09754479133476646, "compression_ratio": 1.5802047781569966, "no_speech_prob": 2.4161812689271756e-05}, {"id": 44, "seek": 24648, "start": 258.0, "end": 264.0, "text": " Then we have Hydrogen, which is a relative newcomer. This is a progressive web app SDK,", "tokens": [1396, 321, 362, 24231, 7747, 11, 597, 307, 257, 4972, 40014, 260, 13, 639, 307, 257, 16131, 3670, 724, 37135, 11], "temperature": 0.0, "avg_logprob": -0.09754479133476646, "compression_ratio": 1.5802047781569966, "no_speech_prob": 2.4161812689271756e-05}, {"id": 45, "seek": 24648, "start": 264.0, "end": 269.36, "text": " super small. It's about 70, 80 kilobytes in total for the whole thing, including all end-to-end", "tokens": [1687, 1359, 13, 467, 311, 466, 5285, 11, 4688, 5128, 996, 43673, 294, 3217, 337, 264, 1379, 551, 11, 3009, 439, 917, 12, 1353, 12, 521], "temperature": 0.0, "avg_logprob": -0.09754479133476646, "compression_ratio": 1.5802047781569966, "no_speech_prob": 2.4161812689271756e-05}, {"id": 46, "seek": 24648, "start": 269.36, "end": 275.36, "text": " encryption. And it's designed for embedded web matrix instances. So we have Hydrogen itself,", "tokens": [29575, 13, 400, 309, 311, 4761, 337, 16741, 3670, 8141, 14519, 13, 407, 321, 362, 24231, 7747, 2564, 11], "temperature": 0.0, "avg_logprob": -0.09754479133476646, "compression_ratio": 1.5802047781569966, "no_speech_prob": 2.4161812689271756e-05}, {"id": 47, "seek": 27536, "start": 275.36, "end": 282.0, "text": " hydrogen.element.io, as a very lightweight PWA for playing around with matrix. We have chatterbox", "tokens": [12697, 13, 68, 3054, 13, 1004, 11, 382, 257, 588, 22052, 430, 21449, 337, 2433, 926, 365, 8141, 13, 492, 362, 26929, 4995], "temperature": 0.0, "avg_logprob": -0.15007070333016018, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.00015135448484215885}, {"id": 48, "seek": 27536, "start": 282.0, "end": 288.24, "text": " as intercom style embeds a matrix chatbox into your website. We have Surderoom, which is our", "tokens": [382, 728, 1112, 3758, 12240, 82, 257, 8141, 5081, 4995, 666, 428, 3144, 13, 492, 362, 6732, 1068, 78, 298, 11, 597, 307, 527], "temperature": 0.0, "avg_logprob": -0.15007070333016018, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.00015135448484215885}, {"id": 49, "seek": 27536, "start": 288.24, "end": 294.64, "text": " crazy science fiction spatial collaboration on top of matrix platform, where you want to have", "tokens": [3219, 3497, 13266, 23598, 9363, 322, 1192, 295, 8141, 3663, 11, 689, 291, 528, 281, 362], "temperature": 0.0, "avg_logprob": -0.15007070333016018, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.00015135448484215885}, {"id": 50, "seek": 27536, "start": 294.64, "end": 298.56, "text": " the matrix bit as lightweight as possible, which is why we use Hydrogen, the lightest element,", "tokens": [264, 8141, 857, 382, 22052, 382, 1944, 11, 597, 307, 983, 321, 764, 24231, 7747, 11, 264, 1442, 377, 4478, 11], "temperature": 0.0, "avg_logprob": -0.15007070333016018, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.00015135448484215885}, {"id": 51, "seek": 27536, "start": 298.56, "end": 304.16, "text": " to make it happen. And then the thing we'll be talking about a lot today is element X. So this", "tokens": [281, 652, 309, 1051, 13, 400, 550, 264, 551, 321, 603, 312, 1417, 466, 257, 688, 965, 307, 4478, 1783, 13, 407, 341], "temperature": 0.0, "avg_logprob": -0.15007070333016018, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.00015135448484215885}, {"id": 52, "seek": 30416, "start": 304.16, "end": 311.20000000000005, "text": " is a total rewrite of element mobile on iOS and Android. And for maximum cliche, we have rewritten", "tokens": [307, 257, 3217, 28132, 295, 4478, 6013, 322, 17430, 293, 8853, 13, 400, 337, 6674, 46705, 11, 321, 362, 319, 26859], "temperature": 0.0, "avg_logprob": -0.12721979241622122, "compression_ratio": 1.5551181102362204, "no_speech_prob": 0.00011170455400133505}, {"id": 53, "seek": 30416, "start": 311.20000000000005, "end": 320.64000000000004, "text": " it in Rust using the matrix Rust SDK. I hear we have Rust fans in the audience. So we'll be talking", "tokens": [309, 294, 34952, 1228, 264, 8141, 34952, 37135, 13, 286, 1568, 321, 362, 34952, 4499, 294, 264, 4034, 13, 407, 321, 603, 312, 1417], "temperature": 0.0, "avg_logprob": -0.12721979241622122, "compression_ratio": 1.5551181102362204, "no_speech_prob": 0.00011170455400133505}, {"id": 54, "seek": 30416, "start": 320.64000000000004, "end": 324.8, "text": " a lot about that. Meanwhile, on the community side, there are just more and more clients all over", "tokens": [257, 688, 466, 300, 13, 13879, 11, 322, 264, 1768, 1252, 11, 456, 366, 445, 544, 293, 544, 6982, 439, 670], "temperature": 0.0, "avg_logprob": -0.12721979241622122, "compression_ratio": 1.5551181102362204, "no_speech_prob": 0.00011170455400133505}, {"id": 55, "seek": 30416, "start": 324.8, "end": 330.8, "text": " the place, like Thunderbird released its native matrix implementation. We've got Watch the Matrix,", "tokens": [264, 1081, 11, 411, 21023, 18080, 4736, 1080, 8470, 8141, 11420, 13, 492, 600, 658, 7277, 264, 36274, 11], "temperature": 0.0, "avg_logprob": -0.12721979241622122, "compression_ratio": 1.5551181102362204, "no_speech_prob": 0.00011170455400133505}, {"id": 56, "seek": 33080, "start": 330.8, "end": 336.16, "text": " which is an excellent Apple Watch matrix client, which doesn't tether to your phone. It's actually", "tokens": [597, 307, 364, 7103, 6373, 7277, 8141, 6423, 11, 597, 1177, 380, 256, 1666, 281, 428, 2593, 13, 467, 311, 767], "temperature": 0.0, "avg_logprob": -0.18018038218257992, "compression_ratio": 1.5728476821192052, "no_speech_prob": 0.00016416300786659122}, {"id": 57, "seek": 33080, "start": 336.16, "end": 344.32, "text": " running on the watch itself. NeoChats, and KD, and QTE, and C++. I wish I could name them all.", "tokens": [2614, 322, 264, 1159, 2564, 13, 24458, 6546, 1720, 11, 293, 591, 35, 11, 293, 1249, 13639, 11, 293, 383, 25472, 13, 286, 3172, 286, 727, 1315, 552, 439, 13], "temperature": 0.0, "avg_logprob": -0.18018038218257992, "compression_ratio": 1.5728476821192052, "no_speech_prob": 0.00016416300786659122}, {"id": 58, "seek": 33080, "start": 344.32, "end": 350.48, "text": " I can't. I don't have time. So help for the network. Here is the total number of users we've", "tokens": [286, 393, 380, 13, 286, 500, 380, 362, 565, 13, 407, 854, 337, 264, 3209, 13, 1692, 307, 264, 3217, 1230, 295, 5022, 321, 600], "temperature": 0.0, "avg_logprob": -0.18018038218257992, "compression_ratio": 1.5728476821192052, "no_speech_prob": 0.00016416300786659122}, {"id": 59, "seek": 33080, "start": 350.48, "end": 354.8, "text": " ever seen on matrix, which is, looked as if it was going to hit 90 million, and then somebody", "tokens": [1562, 1612, 322, 8141, 11, 597, 307, 11, 2956, 382, 498, 309, 390, 516, 281, 2045, 4289, 2459, 11, 293, 550, 2618], "temperature": 0.0, "avg_logprob": -0.18018038218257992, "compression_ratio": 1.5728476821192052, "no_speech_prob": 0.00016416300786659122}, {"id": 60, "seek": 33080, "start": 354.8, "end": 359.44, "text": " turned off the server. Kids, this is what happens if you turn off the server, because it means", "tokens": [3574, 766, 264, 7154, 13, 15694, 11, 341, 307, 437, 2314, 498, 291, 1261, 766, 264, 7154, 11, 570, 309, 1355], "temperature": 0.0, "avg_logprob": -0.18018038218257992, "compression_ratio": 1.5728476821192052, "no_speech_prob": 0.00016416300786659122}, {"id": 61, "seek": 35944, "start": 359.44, "end": 365.28, "text": " the graph goes down. So please never, ever turn off your matrix servers ever again. This is", "tokens": [264, 4295, 1709, 760, 13, 407, 1767, 1128, 11, 1562, 1261, 766, 428, 8141, 15909, 1562, 797, 13, 639, 307], "temperature": 0.0, "avg_logprob": -0.1464240592822694, "compression_ratio": 1.7840909090909092, "no_speech_prob": 9.386660531163216e-05}, {"id": 62, "seek": 35944, "start": 365.28, "end": 369.76, "text": " literally the phone home stats that Synapse reports. So it doesn't include Android. It doesn't", "tokens": [3736, 264, 2593, 1280, 18152, 300, 26155, 11145, 7122, 13, 407, 309, 1177, 380, 4090, 8853, 13, 467, 1177, 380], "temperature": 0.0, "avg_logprob": -0.1464240592822694, "compression_ratio": 1.7840909090909092, "no_speech_prob": 9.386660531163216e-05}, {"id": 63, "seek": 35944, "start": 369.76, "end": 375.84, "text": " include Conduit or other servers. It also doesn't include all of the paranoid people,", "tokens": [4090, 21793, 1983, 420, 661, 15909, 13, 467, 611, 1177, 380, 4090, 439, 295, 264, 43948, 561, 11], "temperature": 0.0, "avg_logprob": -0.1464240592822694, "compression_ratio": 1.7840909090909092, "no_speech_prob": 9.386660531163216e-05}, {"id": 64, "seek": 35944, "start": 375.84, "end": 379.6, "text": " which is quite a lot of people running matrix who obviously aren't going to phone home their usage", "tokens": [597, 307, 1596, 257, 688, 295, 561, 2614, 8141, 567, 2745, 3212, 380, 516, 281, 2593, 1280, 641, 14924], "temperature": 0.0, "avg_logprob": -0.1464240592822694, "compression_ratio": 1.7840909090909092, "no_speech_prob": 9.386660531163216e-05}, {"id": 65, "seek": 35944, "start": 379.6, "end": 385.36, "text": " stats to us. It does include guest users and bridge users. So it's a little bit of an overestimate.", "tokens": [18152, 281, 505, 13, 467, 775, 4090, 8341, 5022, 293, 7283, 5022, 13, 407, 309, 311, 257, 707, 857, 295, 364, 670, 377, 2905, 13], "temperature": 0.0, "avg_logprob": -0.1464240592822694, "compression_ratio": 1.7840909090909092, "no_speech_prob": 9.386660531163216e-05}, {"id": 66, "seek": 38536, "start": 385.36, "end": 390.24, "text": " But the important thing is the shape of the graph, which, as you can see, is continuing to go well,", "tokens": [583, 264, 1021, 551, 307, 264, 3909, 295, 264, 4295, 11, 597, 11, 382, 291, 393, 536, 11, 307, 9289, 281, 352, 731, 11], "temperature": 0.0, "avg_logprob": -0.08078140142012616, "compression_ratio": 1.579591836734694, "no_speech_prob": 5.271769259707071e-05}, {"id": 67, "seek": 38536, "start": 390.24, "end": 396.08000000000004, "text": " apart from that guy who turned off his server. In terms of the spec, we have fallen into this", "tokens": [4936, 490, 300, 2146, 567, 3574, 766, 702, 7154, 13, 682, 2115, 295, 264, 1608, 11, 321, 362, 11547, 666, 341], "temperature": 0.0, "avg_logprob": -0.08078140142012616, "compression_ratio": 1.579591836734694, "no_speech_prob": 5.271769259707071e-05}, {"id": 68, "seek": 38536, "start": 396.08000000000004, "end": 405.28000000000003, "text": " cadence of quarterly releases of matrix since the big 1.0 back in 2020, and then particularly in", "tokens": [46109, 295, 38633, 16952, 295, 8141, 1670, 264, 955, 502, 13, 15, 646, 294, 4808, 11, 293, 550, 4098, 294], "temperature": 0.0, "avg_logprob": -0.08078140142012616, "compression_ratio": 1.579591836734694, "no_speech_prob": 5.271769259707071e-05}, {"id": 69, "seek": 38536, "start": 405.28000000000003, "end": 413.28000000000003, "text": " 2022, we've managed to crank out a point release every quarter. Just in, I think, the day before", "tokens": [20229, 11, 321, 600, 6453, 281, 21263, 484, 257, 935, 4374, 633, 6555, 13, 1449, 294, 11, 286, 519, 11, 264, 786, 949], "temperature": 0.0, "avg_logprob": -0.08078140142012616, "compression_ratio": 1.579591836734694, "no_speech_prob": 5.271769259707071e-05}, {"id": 70, "seek": 41328, "start": 413.28, "end": 418.0, "text": " Last Foster, we had spaces, restricted joins, and actually the matrix ERI scheme, which is now", "tokens": [5264, 38756, 11, 321, 632, 7673, 11, 20608, 24397, 11, 293, 767, 264, 8141, 462, 5577, 12232, 11, 597, 307, 586], "temperature": 0.0, "avg_logprob": -0.15810876143606087, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.00015615037409588695}, {"id": 71, "seek": 41328, "start": 418.0, "end": 423.67999999999995, "text": " being implemented all over the place. Then a few months later, we added aggregations and restricted", "tokens": [885, 12270, 439, 670, 264, 1081, 13, 1396, 257, 1326, 2493, 1780, 11, 321, 3869, 16743, 763, 293, 20608], "temperature": 0.0, "avg_logprob": -0.15810876143606087, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.00015615037409588695}, {"id": 72, "seek": 41328, "start": 423.67999999999995, "end": 428.08, "text": " knocking. Now, these features have often been around for years, but this is actually formalizing", "tokens": [24085, 13, 823, 11, 613, 4122, 362, 2049, 668, 926, 337, 924, 11, 457, 341, 307, 767, 9860, 3319], "temperature": 0.0, "avg_logprob": -0.15810876143606087, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.00015615037409588695}, {"id": 73, "seek": 41328, "start": 428.08, "end": 434.96, "text": " them into the proper long-term supported spec. 1.4 added threads, massive feature that has been", "tokens": [552, 666, 264, 2296, 938, 12, 7039, 8104, 1608, 13, 502, 13, 19, 3869, 19314, 11, 5994, 4111, 300, 575, 668], "temperature": 0.0, "avg_logprob": -0.15810876143606087, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.00015615037409588695}, {"id": 74, "seek": 41328, "start": 436.0, "end": 441.35999999999996, "text": " an epic to get done, but it landed. Edits, private read receipts, a very long time", "tokens": [364, 13581, 281, 483, 1096, 11, 457, 309, 15336, 13, 3977, 1208, 11, 4551, 1401, 2268, 48908, 11, 257, 588, 938, 565], "temperature": 0.0, "avg_logprob": -0.15810876143606087, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.00015615037409588695}, {"id": 75, "seek": 44136, "start": 441.36, "end": 446.08000000000004, "text": " complained about matrix being that you couldn't turn off read receipts, turns out it's surprisingly", "tokens": [33951, 466, 8141, 885, 300, 291, 2809, 380, 1261, 766, 1401, 2268, 48908, 11, 4523, 484, 309, 311, 17600], "temperature": 0.0, "avg_logprob": -0.14926475133651343, "compression_ratio": 1.537162162162162, "no_speech_prob": 0.00021094763360451907}, {"id": 76, "seek": 44136, "start": 446.08000000000004, "end": 451.76, "text": " hard to do, but we now have it specced and implemented. Then 1.5 in November, we added in", "tokens": [1152, 281, 360, 11, 457, 321, 586, 362, 309, 1608, 1232, 293, 12270, 13, 1396, 502, 13, 20, 294, 7674, 11, 321, 3869, 294], "temperature": 0.0, "avg_logprob": -0.14926475133651343, "compression_ratio": 1.537162162162162, "no_speech_prob": 0.00021094763360451907}, {"id": 77, "seek": 44136, "start": 452.48, "end": 457.76, "text": " formalized references, we fixed up some things in the ASAPI, and I think we have basically", "tokens": [9860, 1602, 15400, 11, 321, 6806, 493, 512, 721, 294, 264, 7469, 4715, 40, 11, 293, 286, 519, 321, 362, 1936], "temperature": 0.0, "avg_logprob": -0.14926475133651343, "compression_ratio": 1.537162162162162, "no_speech_prob": 0.00021094763360451907}, {"id": 78, "seek": 44136, "start": 457.76, "end": 463.68, "text": " maintenance release on 1.6 any day now. So nothing too exciting in the next release,", "tokens": [11258, 4374, 322, 502, 13, 21, 604, 786, 586, 13, 407, 1825, 886, 4670, 294, 264, 958, 4374, 11], "temperature": 0.0, "avg_logprob": -0.14926475133651343, "compression_ratio": 1.537162162162162, "no_speech_prob": 0.00021094763360451907}, {"id": 79, "seek": 46368, "start": 463.68, "end": 472.48, "text": " mainly because we're building up to the big 2.0. Nice stat is that there were 120 MSCs in 2022,", "tokens": [8704, 570, 321, 434, 2390, 493, 281, 264, 955, 568, 13, 15, 13, 5490, 2219, 307, 300, 456, 645, 10411, 7395, 33290, 294, 20229, 11], "temperature": 0.0, "avg_logprob": -0.09699466975048335, "compression_ratio": 1.5020408163265306, "no_speech_prob": 0.00012687259004451334}, {"id": 80, "seek": 46368, "start": 472.48, "end": 478.48, "text": " of which 39 came from the community, 27 from new contributors, 30 from the gray beards of the", "tokens": [295, 597, 15238, 1361, 490, 264, 1768, 11, 7634, 490, 777, 45627, 11, 2217, 490, 264, 10855, 312, 2287, 295, 264], "temperature": 0.0, "avg_logprob": -0.09699466975048335, "compression_ratio": 1.5020408163265306, "no_speech_prob": 0.00012687259004451334}, {"id": 81, "seek": 46368, "start": 478.48, "end": 485.44, "text": " spec core team, and then 51 from the folks who are paid to work on matrix.org, mainly by element.", "tokens": [1608, 4965, 1469, 11, 293, 550, 18485, 490, 264, 4024, 567, 366, 4835, 281, 589, 322, 8141, 13, 4646, 11, 8704, 538, 4478, 13], "temperature": 0.0, "avg_logprob": -0.09699466975048335, "compression_ratio": 1.5020408163265306, "no_speech_prob": 0.00012687259004451334}, {"id": 82, "seek": 46368, "start": 485.44, "end": 492.48, "text": " So it's a reasonable mix of community and core project work. In terms of uptake,", "tokens": [407, 309, 311, 257, 10585, 2890, 295, 1768, 293, 4965, 1716, 589, 13, 682, 2115, 295, 493, 27612, 11], "temperature": 0.0, "avg_logprob": -0.09699466975048335, "compression_ratio": 1.5020408163265306, "no_speech_prob": 0.00012687259004451334}, {"id": 83, "seek": 49248, "start": 492.48, "end": 496.16, "text": " other than that, we obviously help the world's best open source conference, dodge COVID.", "tokens": [661, 813, 300, 11, 321, 2745, 854, 264, 1002, 311, 1151, 1269, 4009, 7586, 11, 27238, 4566, 13], "temperature": 0.0, "avg_logprob": -0.23467703890209354, "compression_ratio": 1.6707692307692308, "no_speech_prob": 0.001246241619810462}, {"id": 84, "seek": 49248, "start": 496.16, "end": 500.72, "text": " Hopefully, apologies if matrix was painful over the last couple of years, but it's probably", "tokens": [10429, 11, 34929, 498, 8141, 390, 11697, 670, 264, 1036, 1916, 295, 924, 11, 457, 309, 311, 1391], "temperature": 0.0, "avg_logprob": -0.23467703890209354, "compression_ratio": 1.6707692307692308, "no_speech_prob": 0.001246241619810462}, {"id": 85, "seek": 49248, "start": 500.72, "end": 506.8, "text": " better than no false to me at all. Lots of government uptake. New news is Germany,", "tokens": [1101, 813, 572, 7908, 281, 385, 412, 439, 13, 15908, 295, 2463, 493, 27612, 13, 1873, 2583, 307, 7244, 11], "temperature": 0.0, "avg_logprob": -0.23467703890209354, "compression_ratio": 1.6707692307692308, "no_speech_prob": 0.001246241619810462}, {"id": 86, "seek": 49248, "start": 506.8, "end": 511.28000000000003, "text": " we have bundles messenger rolling out matrix across the whole German government in November,", "tokens": [321, 362, 13882, 904, 26599, 9439, 484, 8141, 2108, 264, 1379, 6521, 2463, 294, 7674, 11], "temperature": 0.0, "avg_logprob": -0.23467703890209354, "compression_ratio": 1.6707692307692308, "no_speech_prob": 0.001246241619810462}, {"id": 87, "seek": 49248, "start": 511.28000000000003, "end": 516.08, "text": " also good martyred, the German healthcare agency, proposing it as a neutral standard for", "tokens": [611, 665, 12396, 88, 986, 11, 264, 6521, 8884, 7934, 11, 29939, 309, 382, 257, 10598, 3832, 337], "temperature": 0.0, "avg_logprob": -0.23467703890209354, "compression_ratio": 1.6707692307692308, "no_speech_prob": 0.001246241619810462}, {"id": 88, "seek": 49248, "start": 516.08, "end": 521.52, "text": " secure messaging in healthcare. Lots and lots of associated deployments in healthcare, education,", "tokens": [7144, 21812, 294, 8884, 13, 15908, 293, 3195, 295, 6615, 7274, 1117, 294, 8884, 11, 3309, 11], "temperature": 0.0, "avg_logprob": -0.23467703890209354, "compression_ratio": 1.6707692307692308, "no_speech_prob": 0.001246241619810462}, {"id": 89, "seek": 52152, "start": 521.52, "end": 527.36, "text": " utilities, manufacturing. Basically, if you are an organization who cannot put their data", "tokens": [30482, 11, 11096, 13, 8537, 11, 498, 291, 366, 364, 4475, 567, 2644, 829, 641, 1412], "temperature": 0.0, "avg_logprob": -0.12688780312586312, "compression_ratio": 1.5798611111111112, "no_speech_prob": 8.941588021116331e-05}, {"id": 90, "seek": 52152, "start": 527.36, "end": 533.4399999999999, "text": " unencrypted into some proprietary silo, like teams or Slack, I think matrix hopefully provides", "tokens": [517, 22660, 627, 25383, 666, 512, 38992, 3425, 78, 11, 411, 5491, 420, 37211, 11, 286, 519, 8141, 4696, 6417], "temperature": 0.0, "avg_logprob": -0.12688780312586312, "compression_ratio": 1.5798611111111112, "no_speech_prob": 8.941588021116331e-05}, {"id": 91, "seek": 52152, "start": 533.4399999999999, "end": 540.0799999999999, "text": " a good alternative. Moodle is busy integrating matrix into the learning management system.", "tokens": [257, 665, 8535, 13, 376, 1816, 306, 307, 5856, 26889, 8141, 666, 264, 2539, 4592, 1185, 13], "temperature": 0.0, "avg_logprob": -0.12688780312586312, "compression_ratio": 1.5798611111111112, "no_speech_prob": 8.941588021116331e-05}, {"id": 92, "seek": 52152, "start": 540.0799999999999, "end": 544.48, "text": " Automatic have got a project called chat tricks, which embeds matrix into WordPress,", "tokens": [6049, 13143, 362, 658, 257, 1716, 1219, 5081, 11733, 11, 597, 12240, 82, 8141, 666, 23239, 11], "temperature": 0.0, "avg_logprob": -0.12688780312586312, "compression_ratio": 1.5798611111111112, "no_speech_prob": 8.941588021116331e-05}, {"id": 93, "seek": 52152, "start": 544.48, "end": 550.16, "text": " so you can literally dump your little chat console based on hydrogen into your WordPress blog.", "tokens": [370, 291, 393, 3736, 11430, 428, 707, 5081, 11076, 2361, 322, 12697, 666, 428, 23239, 6968, 13], "temperature": 0.0, "avg_logprob": -0.12688780312586312, "compression_ratio": 1.5798611111111112, "no_speech_prob": 8.941588021116331e-05}, {"id": 94, "seek": 55016, "start": 550.16, "end": 555.1999999999999, "text": " Reddit is rumored to be building chat capability powered by matrix, mainly because I think they", "tokens": [4477, 17975, 307, 8347, 2769, 281, 312, 2390, 5081, 13759, 17786, 538, 8141, 11, 8704, 570, 286, 519, 436], "temperature": 0.0, "avg_logprob": -0.15812914839414793, "compression_ratio": 1.6312056737588652, "no_speech_prob": 9.683873213361949e-05}, {"id": 95, "seek": 55016, "start": 555.1999999999999, "end": 559.52, "text": " had public who sign up enabled and somebody logged in and discovered a matrix over there,", "tokens": [632, 1908, 567, 1465, 493, 15172, 293, 2618, 27231, 294, 293, 6941, 257, 8141, 670, 456, 11], "temperature": 0.0, "avg_logprob": -0.15812914839414793, "compression_ratio": 1.6312056737588652, "no_speech_prob": 9.683873213361949e-05}, {"id": 96, "seek": 55016, "start": 559.52, "end": 564.0799999999999, "text": " and there's a lot of interest over matrix being potentially the communication there", "tokens": [293, 456, 311, 257, 688, 295, 1179, 670, 8141, 885, 7263, 264, 6101, 456], "temperature": 0.0, "avg_logprob": -0.15812914839414793, "compression_ratio": 1.6312056737588652, "no_speech_prob": 9.683873213361949e-05}, {"id": 97, "seek": 55016, "start": 564.0799999999999, "end": 570.8, "text": " for the digital market sites. So, last year, we put out this slide to basically say the plan", "tokens": [337, 264, 4562, 2142, 7533, 13, 407, 11, 1036, 1064, 11, 321, 829, 484, 341, 4137, 281, 1936, 584, 264, 1393], "temperature": 0.0, "avg_logprob": -0.15812914839414793, "compression_ratio": 1.6312056737588652, "no_speech_prob": 9.683873213361949e-05}, {"id": 98, "seek": 55016, "start": 570.8, "end": 576.24, "text": " for 2022. In the early days of matrix, we were just trying to make it work. Then we tried to make", "tokens": [337, 20229, 13, 682, 264, 2440, 1708, 295, 8141, 11, 321, 645, 445, 1382, 281, 652, 309, 589, 13, 1396, 321, 3031, 281, 652], "temperature": 0.0, "avg_logprob": -0.15812914839414793, "compression_ratio": 1.6312056737588652, "no_speech_prob": 9.683873213361949e-05}, {"id": 99, "seek": 57624, "start": 576.24, "end": 582.0, "text": " it work right and managed to exit beta and launched the 1.0. The last year particularly", "tokens": [309, 589, 558, 293, 6453, 281, 11043, 9861, 293, 8730, 264, 502, 13, 15, 13, 440, 1036, 1064, 4098], "temperature": 0.0, "avg_logprob": -0.13313851485381256, "compression_ratio": 1.5054945054945055, "no_speech_prob": 9.75574366748333e-05}, {"id": 100, "seek": 57624, "start": 582.0, "end": 588.24, "text": " has been trying to make it work fast, and I hope we have now made it work fast. I will attempt", "tokens": [575, 668, 1382, 281, 652, 309, 589, 2370, 11, 293, 286, 1454, 321, 362, 586, 1027, 309, 589, 2370, 13, 286, 486, 5217], "temperature": 0.0, "avg_logprob": -0.13313851485381256, "compression_ratio": 1.5054945054945055, "no_speech_prob": 9.75574366748333e-05}, {"id": 101, "seek": 57624, "start": 588.24, "end": 598.72, "text": " to prove this to you with a demo. We haven't seen anything yet. So, there is one of my cats", "tokens": [281, 7081, 341, 281, 291, 365, 257, 10723, 13, 492, 2378, 380, 1612, 1340, 1939, 13, 407, 11, 456, 307, 472, 295, 452, 11111], "temperature": 0.0, "avg_logprob": -0.13313851485381256, "compression_ratio": 1.5054945054945055, "no_speech_prob": 9.75574366748333e-05}, {"id": 102, "seek": 59872, "start": 598.72, "end": 606.72, "text": " helping me here as a kid. Now, along the bottom here, you might see three, four icons in fact,", "tokens": [4315, 385, 510, 382, 257, 1636, 13, 823, 11, 2051, 264, 2767, 510, 11, 291, 1062, 536, 1045, 11, 1451, 23308, 294, 1186, 11], "temperature": 0.0, "avg_logprob": -0.2055043736729053, "compression_ratio": 1.7180616740088106, "no_speech_prob": 8.994094241643324e-05}, {"id": 103, "seek": 59872, "start": 606.72, "end": 612.48, "text": " element X, element R, element X itself, so that's element X nightly, and then element normal.", "tokens": [4478, 1783, 11, 4478, 497, 11, 4478, 1783, 2564, 11, 370, 300, 311, 4478, 1783, 1818, 356, 11, 293, 550, 4478, 2710, 13], "temperature": 0.0, "avg_logprob": -0.2055043736729053, "compression_ratio": 1.7180616740088106, "no_speech_prob": 8.994094241643324e-05}, {"id": 104, "seek": 59872, "start": 613.28, "end": 617.84, "text": " We're going to talk about element X here. So, I've got the nightly here, and I'm going on the ship.", "tokens": [492, 434, 516, 281, 751, 466, 4478, 1783, 510, 13, 407, 11, 286, 600, 658, 264, 1818, 356, 510, 11, 293, 286, 478, 516, 322, 264, 5374, 13], "temperature": 0.0, "avg_logprob": -0.2055043736729053, "compression_ratio": 1.7180616740088106, "no_speech_prob": 8.994094241643324e-05}, {"id": 105, "seek": 59872, "start": 618.72, "end": 624.5600000000001, "text": " This is what you see as a little splash screen. I'm going to hit continue on that, and hopefully I've", "tokens": [639, 307, 437, 291, 536, 382, 257, 707, 25757, 2568, 13, 286, 478, 516, 281, 2045, 2354, 322, 300, 11, 293, 4696, 286, 600], "temperature": 0.0, "avg_logprob": -0.2055043736729053, "compression_ratio": 1.7180616740088106, "no_speech_prob": 8.994094241643324e-05}, {"id": 106, "seek": 62456, "start": 624.56, "end": 630.56, "text": " got enough connectivity to connect to the server. That's a good start. If it takes that long to", "tokens": [658, 1547, 21095, 281, 1745, 281, 264, 7154, 13, 663, 311, 257, 665, 722, 13, 759, 309, 2516, 300, 938, 281], "temperature": 0.0, "avg_logprob": -0.12037388965336963, "compression_ratio": 1.7363636363636363, "no_speech_prob": 8.118276309687644e-05}, {"id": 107, "seek": 62456, "start": 630.56, "end": 634.64, "text": " discover that there's a server out there, then this demo might not go so smoothly. I'm going to", "tokens": [4411, 300, 456, 311, 257, 7154, 484, 456, 11, 550, 341, 10723, 1062, 406, 352, 370, 19565, 13, 286, 478, 516, 281], "temperature": 0.0, "avg_logprob": -0.12037388965336963, "compression_ratio": 1.7363636363636363, "no_speech_prob": 8.118276309687644e-05}, {"id": 108, "seek": 62456, "start": 634.64, "end": 639.68, "text": " log in as my actual main real matrix account. I'm not going to type in my password in front of you,", "tokens": [3565, 294, 382, 452, 3539, 2135, 957, 8141, 2696, 13, 286, 478, 406, 516, 281, 2010, 294, 452, 11524, 294, 1868, 295, 291, 11], "temperature": 0.0, "avg_logprob": -0.12037388965336963, "compression_ratio": 1.7363636363636363, "no_speech_prob": 8.118276309687644e-05}, {"id": 109, "seek": 62456, "start": 639.68, "end": 648.88, "text": " but I'm going to pull it out of my password manager. Hit continue. If the server is there,", "tokens": [457, 286, 478, 516, 281, 2235, 309, 484, 295, 452, 11524, 6598, 13, 9217, 2354, 13, 759, 264, 7154, 307, 456, 11], "temperature": 0.0, "avg_logprob": -0.12037388965336963, "compression_ratio": 1.7363636363636363, "no_speech_prob": 8.118276309687644e-05}, {"id": 110, "seek": 64888, "start": 648.88, "end": 655.28, "text": " there's too many people in the room. It hasn't even started talking to the server yet, okay? And", "tokens": [456, 311, 886, 867, 561, 294, 264, 1808, 13, 467, 6132, 380, 754, 1409, 1417, 281, 264, 7154, 1939, 11, 1392, 30, 400], "temperature": 0.0, "avg_logprob": -0.12801523928372366, "compression_ratio": 1.5685483870967742, "no_speech_prob": 4.196866575512104e-05}, {"id": 111, "seek": 64888, "start": 655.28, "end": 666.16, "text": " that's it. I'm in. So, my account... So, if I was going to try to log in on my normal element", "tokens": [300, 311, 309, 13, 286, 478, 294, 13, 407, 11, 452, 2696, 485, 407, 11, 498, 286, 390, 516, 281, 853, 281, 3565, 294, 322, 452, 2710, 4478], "temperature": 0.0, "avg_logprob": -0.12801523928372366, "compression_ratio": 1.5685483870967742, "no_speech_prob": 4.196866575512104e-05}, {"id": 112, "seek": 64888, "start": 666.16, "end": 672.16, "text": " account, it would take 20 minutes, because I'm in 4,000 rooms that date back to literally day one,", "tokens": [2696, 11, 309, 576, 747, 945, 2077, 11, 570, 286, 478, 294, 1017, 11, 1360, 9396, 300, 4002, 646, 281, 3736, 786, 472, 11], "temperature": 0.0, "avg_logprob": -0.12801523928372366, "compression_ratio": 1.5685483870967742, "no_speech_prob": 4.196866575512104e-05}, {"id": 113, "seek": 64888, "start": 672.16, "end": 677.76, "text": " or actually day minus two weeks or something of matrix, and I can go and scrub through all of these", "tokens": [420, 767, 786, 3175, 732, 3259, 420, 746, 295, 8141, 11, 293, 286, 393, 352, 293, 24163, 807, 439, 295, 613], "temperature": 0.0, "avg_logprob": -0.12801523928372366, "compression_ratio": 1.5685483870967742, "no_speech_prob": 4.196866575512104e-05}, {"id": 114, "seek": 67776, "start": 677.76, "end": 682.8, "text": " gazillion rooms there, and they are all actually there. I can go and find somewhere, I know,", "tokens": [26232, 11836, 9396, 456, 11, 293, 436, 366, 439, 767, 456, 13, 286, 393, 352, 293, 915, 4079, 11, 286, 458, 11], "temperature": 0.0, "avg_logprob": -0.11471956426447089, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0003316561342217028}, {"id": 115, "seek": 67776, "start": 682.8, "end": 687.36, "text": " try not to expose anything too sensitive, but you can see it's actually already pulled in", "tokens": [853, 406, 281, 19219, 1340, 886, 9477, 11, 457, 291, 393, 536, 309, 311, 767, 1217, 7373, 294], "temperature": 0.0, "avg_logprob": -0.11471956426447089, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0003316561342217028}, {"id": 116, "seek": 67776, "start": 687.36, "end": 692.64, "text": " room previews on all of these things. Going to, I know, this week in matrix, and there is the chat.", "tokens": [1808, 14281, 82, 322, 439, 295, 613, 721, 13, 10963, 281, 11, 286, 458, 11, 341, 1243, 294, 8141, 11, 293, 456, 307, 264, 5081, 13], "temperature": 0.0, "avg_logprob": -0.11471956426447089, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0003316561342217028}, {"id": 117, "seek": 67776, "start": 692.64, "end": 696.88, "text": " There is just no spinner here other than the slow network at the beginning, which really was the", "tokens": [821, 307, 445, 572, 44849, 510, 661, 813, 264, 2964, 3209, 412, 264, 2863, 11, 597, 534, 390, 264], "temperature": 0.0, "avg_logprob": -0.11471956426447089, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0003316561342217028}, {"id": 118, "seek": 67776, "start": 696.88, "end": 703.92, "text": " slow network. And you can see we've got reactions in here. We've got some nice bubbles. We've got", "tokens": [2964, 3209, 13, 400, 291, 393, 536, 321, 600, 658, 12215, 294, 510, 13, 492, 600, 658, 512, 1481, 16295, 13, 492, 600, 658], "temperature": 0.0, "avg_logprob": -0.11471956426447089, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0003316561342217028}, {"id": 119, "seek": 70392, "start": 703.92, "end": 710.4, "text": " replies. We've got joins and parts and day markers, read markers. We've got map markdown.", "tokens": [42289, 13, 492, 600, 658, 24397, 293, 3166, 293, 786, 19175, 11, 1401, 19175, 13, 492, 600, 658, 4471, 1491, 5093, 13], "temperature": 0.0, "avg_logprob": -0.13207750609426788, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.00011931738845305517}, {"id": 120, "seek": 70392, "start": 711.12, "end": 718.0799999999999, "text": " This is the SwiftUI incarnation of element X, but all of the heavy lifting here is done by Rust,", "tokens": [639, 307, 264, 25539, 46324, 49988, 295, 4478, 1783, 11, 457, 439, 295, 264, 4676, 15798, 510, 307, 1096, 538, 34952, 11], "temperature": 0.0, "avg_logprob": -0.13207750609426788, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.00011931738845305517}, {"id": 121, "seek": 70392, "start": 718.0799999999999, "end": 723.36, "text": " and it is transformative. The whole point here is to be faster than Telegram, and I think that we", "tokens": [293, 309, 307, 36070, 13, 440, 1379, 935, 510, 307, 281, 312, 4663, 813, 14889, 1342, 11, 293, 286, 519, 300, 321], "temperature": 0.0, "avg_logprob": -0.13207750609426788, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.00011931738845305517}, {"id": 122, "seek": 70392, "start": 723.36, "end": 729.12, "text": " might have got it, although if anybody's in a Telegram account with 4,000 rooms, please tell me", "tokens": [1062, 362, 658, 309, 11, 4878, 498, 4472, 311, 294, 257, 14889, 1342, 2696, 365, 1017, 11, 1360, 9396, 11, 1767, 980, 385], "temperature": 0.0, "avg_logprob": -0.13207750609426788, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.00011931738845305517}, {"id": 123, "seek": 72912, "start": 729.12, "end": 733.92, "text": " how long it takes to log into it afresh and how long it takes to launch. So talking about how long", "tokens": [577, 938, 309, 2516, 281, 3565, 666, 309, 3238, 3644, 293, 577, 938, 309, 2516, 281, 4025, 13, 407, 1417, 466, 577, 938], "temperature": 0.0, "avg_logprob": -0.1285739863684418, "compression_ratio": 1.7762557077625571, "no_speech_prob": 5.7861590903485194e-05}, {"id": 124, "seek": 72912, "start": 733.92, "end": 741.04, "text": " it takes to launch, if I go and quit the app like that and relaunch it, we're in. That was it.", "tokens": [309, 2516, 281, 4025, 11, 498, 286, 352, 293, 10366, 264, 724, 411, 300, 293, 5195, 1680, 309, 11, 321, 434, 294, 13, 663, 390, 309, 13], "temperature": 0.0, "avg_logprob": -0.1285739863684418, "compression_ratio": 1.7762557077625571, "no_speech_prob": 5.7861590903485194e-05}, {"id": 125, "seek": 72912, "start": 746.64, "end": 752.72, "text": " And I'm going to risk doing one other thing, which is to launch my non-nightly, which I haven't", "tokens": [400, 286, 478, 516, 281, 3148, 884, 472, 661, 551, 11, 597, 307, 281, 4025, 452, 2107, 12, 6402, 356, 11, 597, 286, 2378, 380], "temperature": 0.0, "avg_logprob": -0.1285739863684418, "compression_ratio": 1.7762557077625571, "no_speech_prob": 5.7861590903485194e-05}, {"id": 126, "seek": 72912, "start": 752.72, "end": 757.92, "text": " actually used for a couple of hours. And again, it's synced almost instantly. And what I'm going to", "tokens": [767, 1143, 337, 257, 1916, 295, 2496, 13, 400, 797, 11, 309, 311, 5451, 1232, 1920, 13518, 13, 400, 437, 286, 478, 516, 281], "temperature": 0.0, "avg_logprob": -0.1285739863684418, "compression_ratio": 1.7762557077625571, "no_speech_prob": 5.7861590903485194e-05}, {"id": 127, "seek": 75792, "start": 757.92, "end": 766.0, "text": " do is that this is on a custom build, which is hooked up to Yeager. And if I go over to Yeager,", "tokens": [360, 307, 300, 341, 307, 322, 257, 2375, 1322, 11, 597, 307, 20410, 493, 281, 835, 3557, 13, 400, 498, 286, 352, 670, 281, 835, 3557, 11], "temperature": 0.0, "avg_logprob": -0.119079356100045, "compression_ratio": 1.6212765957446809, "no_speech_prob": 9.798854443943128e-05}, {"id": 128, "seek": 75792, "start": 766.0, "end": 770.88, "text": " and if I have enough internet connection to even load the Yeager UI, this is going to be really", "tokens": [293, 498, 286, 362, 1547, 4705, 4984, 281, 754, 3677, 264, 835, 3557, 15682, 11, 341, 307, 516, 281, 312, 534], "temperature": 0.0, "avg_logprob": -0.119079356100045, "compression_ratio": 1.6212765957446809, "no_speech_prob": 9.798854443943128e-05}, {"id": 129, "seek": 75792, "start": 770.88, "end": 775.5999999999999, "text": " fun for demoing later if this is how bad the connectivity is. And I search for the well-known", "tokens": [1019, 337, 10723, 278, 1780, 498, 341, 307, 577, 1578, 264, 21095, 307, 13, 400, 286, 3164, 337, 264, 731, 12, 6861], "temperature": 0.0, "avg_logprob": -0.119079356100045, "compression_ratio": 1.6212765957446809, "no_speech_prob": 9.798854443943128e-05}, {"id": 130, "seek": 75792, "start": 775.5999999999999, "end": 780.88, "text": " element X Matthew app in the last, actually, let's do the last 15 minutes or five minutes even,", "tokens": [4478, 1783, 12434, 724, 294, 264, 1036, 11, 767, 11, 718, 311, 360, 264, 1036, 2119, 2077, 420, 1732, 2077, 754, 11], "temperature": 0.0, "avg_logprob": -0.119079356100045, "compression_ratio": 1.6212765957446809, "no_speech_prob": 9.798854443943128e-05}, {"id": 131, "seek": 78088, "start": 780.88, "end": 788.64, "text": " then we've actually hooked up Rust SDK so that all of the logging is structured and all of the", "tokens": [550, 321, 600, 767, 20410, 493, 34952, 37135, 370, 300, 439, 295, 264, 27991, 307, 18519, 293, 439, 295, 264], "temperature": 0.0, "avg_logprob": -0.12985437115033469, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00012895096733700484}, {"id": 132, "seek": 78088, "start": 788.64, "end": 797.2, "text": " logging gets uploaded via LTP to Yeager. And if I had internet access, I should start tethering,", "tokens": [27991, 2170, 17135, 5766, 441, 16804, 281, 835, 3557, 13, 400, 498, 286, 632, 4705, 2105, 11, 286, 820, 722, 256, 1666, 278, 11], "temperature": 0.0, "avg_logprob": -0.12985437115033469, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00012895096733700484}, {"id": 133, "seek": 78088, "start": 797.2, "end": 803.28, "text": " I would be able to show you a blow-by-blow account of what happened when I launched the app", "tokens": [286, 576, 312, 1075, 281, 855, 291, 257, 6327, 12, 2322, 12, 5199, 305, 2696, 295, 437, 2011, 562, 286, 8730, 264, 724], "temperature": 0.0, "avg_logprob": -0.12985437115033469, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00012895096733700484}, {"id": 134, "seek": 78088, "start": 803.28, "end": 807.76, "text": " then a minute ago. So what we're going to see when it finally loads, hopefully,", "tokens": [550, 257, 3456, 2057, 13, 407, 437, 321, 434, 516, 281, 536, 562, 309, 2721, 12668, 11, 4696, 11], "temperature": 0.0, "avg_logprob": -0.12985437115033469, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00012895096733700484}, {"id": 135, "seek": 80776, "start": 807.76, "end": 813.12, "text": " is first of all, it has to pull up a local cache of my messages if you're already logged in from", "tokens": [307, 700, 295, 439, 11, 309, 575, 281, 2235, 493, 257, 2654, 19459, 295, 452, 7897, 498, 291, 434, 1217, 27231, 294, 490], "temperature": 0.0, "avg_logprob": -0.13365292358398437, "compression_ratio": 1.5397350993377483, "no_speech_prob": 0.00017798611952457577}, {"id": 136, "seek": 80776, "start": 813.12, "end": 820.0, "text": " disk. For this, we currently use sled, which is a key value database native to Rust. It hasn't", "tokens": [12355, 13, 1171, 341, 11, 321, 4362, 764, 46242, 11, 597, 307, 257, 2141, 2158, 8149, 8470, 281, 34952, 13, 467, 6132, 380], "temperature": 0.0, "avg_logprob": -0.13365292358398437, "compression_ratio": 1.5397350993377483, "no_speech_prob": 0.00017798611952457577}, {"id": 137, "seek": 80776, "start": 820.0, "end": 825.92, "text": " been going amazingly well for us, and let's hope that's the right one. And as you can see here,", "tokens": [668, 516, 31762, 731, 337, 505, 11, 293, 718, 311, 1454, 300, 311, 264, 558, 472, 13, 400, 382, 291, 393, 536, 510, 11], "temperature": 0.0, "avg_logprob": -0.13365292358398437, "compression_ratio": 1.5397350993377483, "no_speech_prob": 0.00017798611952457577}, {"id": 138, "seek": 80776, "start": 825.92, "end": 830.8, "text": " at the top, we've got the build operation. And the 410 milliseconds there, frankly,", "tokens": [412, 264, 1192, 11, 321, 600, 658, 264, 1322, 6916, 13, 400, 264, 1017, 3279, 34184, 456, 11, 11939, 11], "temperature": 0.0, "avg_logprob": -0.13365292358398437, "compression_ratio": 1.5397350993377483, "no_speech_prob": 0.00017798611952457577}, {"id": 139, "seek": 80776, "start": 830.8, "end": 836.96, "text": " should be more like 40, because all it's doing is loading up 20 rooms also out of sled. We're", "tokens": [820, 312, 544, 411, 3356, 11, 570, 439, 309, 311, 884, 307, 15114, 493, 945, 9396, 611, 484, 295, 46242, 13, 492, 434], "temperature": 0.0, "avg_logprob": -0.13365292358398437, "compression_ratio": 1.5397350993377483, "no_speech_prob": 0.00017798611952457577}, {"id": 140, "seek": 83696, "start": 836.96, "end": 842.4000000000001, "text": " going to move to SQLite because if nothing else, sled spends its entire life rebuilding itself", "tokens": [516, 281, 1286, 281, 19200, 642, 570, 498, 1825, 1646, 11, 46242, 25620, 1080, 2302, 993, 36717, 2564], "temperature": 0.0, "avg_logprob": -0.08375815762818314, "compression_ratio": 1.728125, "no_speech_prob": 0.00014344292867463082}, {"id": 141, "seek": 83696, "start": 842.4000000000001, "end": 846.0, "text": " and defragmenting itself when you launch it, which is a bit unfortunate when you're trying to launch", "tokens": [293, 1060, 3731, 518, 278, 2564, 562, 291, 4025, 309, 11, 597, 307, 257, 857, 17843, 562, 291, 434, 1382, 281, 4025], "temperature": 0.0, "avg_logprob": -0.08375815762818314, "compression_ratio": 1.728125, "no_speech_prob": 0.00014344292867463082}, {"id": 142, "seek": 83696, "start": 846.0, "end": 850.5600000000001, "text": " an app quickly. Then it restores your session and gets a whole bunch of events out of it,", "tokens": [364, 724, 2661, 13, 1396, 309, 1472, 2706, 428, 5481, 293, 2170, 257, 1379, 3840, 295, 3931, 484, 295, 309, 11], "temperature": 0.0, "avg_logprob": -0.08375815762818314, "compression_ratio": 1.728125, "no_speech_prob": 0.00014344292867463082}, {"id": 143, "seek": 83696, "start": 850.5600000000001, "end": 854.08, "text": " which is the first couple of events on the page. And if you scroll past those,", "tokens": [597, 307, 264, 700, 1916, 295, 3931, 322, 264, 3028, 13, 400, 498, 291, 11369, 1791, 729, 11], "temperature": 0.0, "avg_logprob": -0.08375815762818314, "compression_ratio": 1.728125, "no_speech_prob": 0.00014344292867463082}, {"id": 144, "seek": 83696, "start": 854.08, "end": 861.12, "text": " the really interesting one here is doing the sync. So this on the server is 90 milliseconds", "tokens": [264, 534, 1880, 472, 510, 307, 884, 264, 20271, 13, 407, 341, 322, 264, 7154, 307, 4289, 34184], "temperature": 0.0, "avg_logprob": -0.08375815762818314, "compression_ratio": 1.728125, "no_speech_prob": 0.00014344292867463082}, {"id": 145, "seek": 83696, "start": 861.12, "end": 865.84, "text": " to calculate your sync response. It's ended up being 900 over the wire because of all you people", "tokens": [281, 8873, 428, 20271, 4134, 13, 467, 311, 4590, 493, 885, 22016, 670, 264, 6234, 570, 295, 439, 291, 561], "temperature": 0.0, "avg_logprob": -0.08375815762818314, "compression_ratio": 1.728125, "no_speech_prob": 0.00014344292867463082}, {"id": 146, "seek": 86584, "start": 865.84, "end": 871.2800000000001, "text": " with your electronic magnetic interference and your mobile phones. But still, you saw that it was", "tokens": [365, 428, 10092, 12688, 24497, 293, 428, 6013, 10216, 13, 583, 920, 11, 291, 1866, 300, 309, 390], "temperature": 0.0, "avg_logprob": -0.11603324455127381, "compression_ratio": 1.583617747440273, "no_speech_prob": 0.00027721747756004333}, {"id": 147, "seek": 86584, "start": 871.2800000000001, "end": 876.4, "text": " very usable. It's like a second to get to the point that you're viewing stuff. And in fact,", "tokens": [588, 29975, 13, 467, 311, 411, 257, 1150, 281, 483, 281, 264, 935, 300, 291, 434, 17480, 1507, 13, 400, 294, 1186, 11], "temperature": 0.0, "avg_logprob": -0.11603324455127381, "compression_ratio": 1.583617747440273, "no_speech_prob": 0.00027721747756004333}, {"id": 148, "seek": 86584, "start": 876.4, "end": 882.0, "text": " we already are interactive before the sync response returns thanks to the local store having been", "tokens": [321, 1217, 366, 15141, 949, 264, 20271, 4134, 11247, 3231, 281, 264, 2654, 3531, 1419, 668], "temperature": 0.0, "avg_logprob": -0.11603324455127381, "compression_ratio": 1.583617747440273, "no_speech_prob": 0.00027721747756004333}, {"id": 149, "seek": 86584, "start": 882.88, "end": 888.48, "text": " resumed. So we have gone deep down the rabbit hole, so the saying goes, to try to optimize", "tokens": [725, 28189, 13, 407, 321, 362, 2780, 2452, 760, 264, 19509, 5458, 11, 370, 264, 1566, 1709, 11, 281, 853, 281, 19719], "temperature": 0.0, "avg_logprob": -0.11603324455127381, "compression_ratio": 1.583617747440273, "no_speech_prob": 0.00027721747756004333}, {"id": 150, "seek": 86584, "start": 888.48, "end": 893.76, "text": " the performance on element X. So it is as snappy as iMessage or WhatsApp or Telegram,", "tokens": [264, 3389, 322, 4478, 1783, 13, 407, 309, 307, 382, 14528, 7966, 382, 741, 44, 442, 609, 420, 30513, 420, 14889, 1342, 11], "temperature": 0.0, "avg_logprob": -0.11603324455127381, "compression_ratio": 1.583617747440273, "no_speech_prob": 0.00027721747756004333}, {"id": 151, "seek": 89376, "start": 893.76, "end": 897.04, "text": " rather than the slightly clunky beast that we've had historically.", "tokens": [2831, 813, 264, 4748, 596, 25837, 13464, 300, 321, 600, 632, 16180, 13], "temperature": 0.0, "avg_logprob": -0.18279480352634336, "compression_ratio": 1.5693950177935942, "no_speech_prob": 6.158446194604039e-05}, {"id": 152, "seek": 89376, "start": 898.96, "end": 904.3199999999999, "text": " So before it looked like this, you got a synapse on the right. We've all sorts of fun", "tokens": [407, 949, 309, 2956, 411, 341, 11, 291, 658, 257, 5451, 11145, 322, 264, 558, 13, 492, 600, 439, 7527, 295, 1019], "temperature": 0.0, "avg_logprob": -0.18279480352634336, "compression_ratio": 1.5693950177935942, "no_speech_prob": 6.158446194604039e-05}, {"id": 153, "seek": 89376, "start": 904.3199999999999, "end": 910.16, "text": " workers to do the various bits and bobs. And then we had element iOS with iOS SDK, mainly written", "tokens": [5600, 281, 360, 264, 3683, 9239, 293, 748, 929, 13, 400, 550, 321, 632, 4478, 17430, 365, 17430, 37135, 11, 8704, 3720], "temperature": 0.0, "avg_logprob": -0.18279480352634336, "compression_ratio": 1.5693950177935942, "no_speech_prob": 6.158446194604039e-05}, {"id": 154, "seek": 89376, "start": 910.16, "end": 916.72, "text": " in Objective-C, matrix kit in the UI layer with more Swift in it. You had MXCrypto, again written,", "tokens": [294, 24753, 488, 12, 34, 11, 8141, 8260, 294, 264, 15682, 4583, 365, 544, 25539, 294, 309, 13, 509, 632, 47509, 38477, 662, 78, 11, 797, 3720, 11], "temperature": 0.0, "avg_logprob": -0.18279480352634336, "compression_ratio": 1.5693950177935942, "no_speech_prob": 6.158446194604039e-05}, {"id": 155, "seek": 89376, "start": 916.72, "end": 922.4, "text": " I think, in Objective-C, and LibOm as the encryption library in C++ and C sitting below it.", "tokens": [286, 519, 11, 294, 24753, 488, 12, 34, 11, 293, 15834, 46, 76, 382, 264, 29575, 6405, 294, 383, 25472, 293, 383, 3798, 2507, 309, 13], "temperature": 0.0, "avg_logprob": -0.18279480352634336, "compression_ratio": 1.5693950177935942, "no_speech_prob": 6.158446194604039e-05}, {"id": 156, "seek": 92240, "start": 922.4, "end": 929.04, "text": " And then the database layer was horrific with a mix of flat files, realm, core data, carrier", "tokens": [400, 550, 264, 8149, 4583, 390, 29248, 365, 257, 2890, 295, 4962, 7098, 11, 15355, 11, 4965, 1412, 11, 17574], "temperature": 0.0, "avg_logprob": -0.13958517375745272, "compression_ratio": 1.477366255144033, "no_speech_prob": 0.00012261446681804955}, {"id": 157, "seek": 92240, "start": 929.04, "end": 937.04, "text": " pigeon, element iOS has some issues. In our brave new sliding sync world, everything has changed.", "tokens": [37886, 11, 4478, 17430, 575, 512, 2663, 13, 682, 527, 12653, 777, 21169, 20271, 1002, 11, 1203, 575, 3105, 13], "temperature": 0.0, "avg_logprob": -0.13958517375745272, "compression_ratio": 1.477366255144033, "no_speech_prob": 0.00012261446681804955}, {"id": 158, "seek": 92240, "start": 937.04, "end": 941.4399999999999, "text": " On the left-hand side, we now have on iOS SwiftUI for the funky app I just showed you.", "tokens": [1282, 264, 1411, 12, 5543, 1252, 11, 321, 586, 362, 322, 17430, 25539, 46324, 337, 264, 33499, 724, 286, 445, 4712, 291, 13], "temperature": 0.0, "avg_logprob": -0.13958517375745272, "compression_ratio": 1.477366255144033, "no_speech_prob": 0.00012261446681804955}, {"id": 159, "seek": 92240, "start": 942.0, "end": 947.76, "text": " On Android, we have Jetpack Compose. Then we have Unify bindings to the Rust SDK,", "tokens": [1282, 8853, 11, 321, 362, 28730, 9539, 6620, 541, 13, 1396, 321, 362, 1156, 2505, 14786, 1109, 281, 264, 34952, 37135, 11], "temperature": 0.0, "avg_logprob": -0.13958517375745272, "compression_ratio": 1.477366255144033, "no_speech_prob": 0.00012261446681804955}, {"id": 160, "seek": 94776, "start": 947.76, "end": 953.28, "text": " which has been a lot of fun. Even on our Rust team, it's been hacking way, contributing async", "tokens": [597, 575, 668, 257, 688, 295, 1019, 13, 2754, 322, 527, 34952, 1469, 11, 309, 311, 668, 31422, 636, 11, 19270, 382, 34015], "temperature": 0.0, "avg_logprob": -0.18262096479827283, "compression_ratio": 1.597457627118644, "no_speech_prob": 9.269230213249102e-05}, {"id": 161, "seek": 94776, "start": 954.24, "end": 962.08, "text": " bindings through to Swift, to Unify, so that we could expose Rust SDK, complete with nice futures", "tokens": [14786, 1109, 807, 281, 25539, 11, 281, 1156, 2505, 11, 370, 300, 321, 727, 19219, 34952, 37135, 11, 3566, 365, 1481, 26071], "temperature": 0.0, "avg_logprob": -0.18262096479827283, "compression_ratio": 1.597457627118644, "no_speech_prob": 9.269230213249102e-05}, {"id": 162, "seek": 94776, "start": 962.08, "end": 968.0, "text": " and async through to Swift and Kotlin. And then you've got Rust SDK itself, which is doing all", "tokens": [293, 382, 34015, 807, 281, 25539, 293, 30123, 5045, 13, 400, 550, 291, 600, 658, 34952, 37135, 2564, 11, 597, 307, 884, 439], "temperature": 0.0, "avg_logprob": -0.18262096479827283, "compression_ratio": 1.597457627118644, "no_speech_prob": 9.269230213249102e-05}, {"id": 163, "seek": 94776, "start": 968.0, "end": 972.64, "text": " the heavy lifting. It's got the crypto crate within it. And then within that is Vdozomats,", "tokens": [264, 4676, 15798, 13, 467, 311, 658, 264, 17240, 42426, 1951, 309, 13, 400, 550, 1951, 300, 307, 691, 2595, 89, 298, 1720, 11], "temperature": 0.0, "avg_logprob": -0.18262096479827283, "compression_ratio": 1.597457627118644, "no_speech_prob": 9.269230213249102e-05}, {"id": 164, "seek": 97264, "start": 972.64, "end": 978.0, "text": " which is our native Rust encryption implementation for matrix. Below that, you've got sled and in", "tokens": [597, 307, 527, 8470, 34952, 29575, 11420, 337, 8141, 13, 36261, 300, 11, 291, 600, 658, 46242, 293, 294], "temperature": 0.0, "avg_logprob": -0.18219110107421874, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.00010115205805050209}, {"id": 165, "seek": 97264, "start": 978.0, "end": 983.36, "text": " futures equalize. This then talks through to a sliding sync proxy. And this is written in Go,", "tokens": [26071, 2681, 1125, 13, 639, 550, 6686, 807, 281, 257, 21169, 20271, 29690, 13, 400, 341, 307, 3720, 294, 1037, 11], "temperature": 0.0, "avg_logprob": -0.18219110107421874, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.00010115205805050209}, {"id": 166, "seek": 97264, "start": 983.36, "end": 989.4399999999999, "text": " and it implements MSE 3575, which is sliding sync. And this is the magic for how this works so quickly.", "tokens": [293, 309, 704, 17988, 376, 5879, 6976, 11901, 11, 597, 307, 21169, 20271, 13, 400, 341, 307, 264, 5585, 337, 577, 341, 1985, 370, 2661, 13], "temperature": 0.0, "avg_logprob": -0.18219110107421874, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.00010115205805050209}, {"id": 167, "seek": 97264, "start": 989.4399999999999, "end": 994.72, "text": " It's basically storing, well, it's going and talking normal sync to normal Synapse. So this", "tokens": [467, 311, 1936, 26085, 11, 731, 11, 309, 311, 516, 293, 1417, 2710, 20271, 281, 2710, 26155, 11145, 13, 407, 341], "temperature": 0.0, "avg_logprob": -0.18219110107421874, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.00010115205805050209}, {"id": 168, "seek": 97264, "start": 994.72, "end": 999.92, "text": " could be Synapse or Dendrite or Conduit or anything on the right-hand side. The Golang thing is an", "tokens": [727, 312, 26155, 11145, 420, 413, 521, 35002, 420, 21793, 1983, 420, 1340, 322, 264, 558, 12, 5543, 1252, 13, 440, 36319, 656, 551, 307, 364], "temperature": 0.0, "avg_logprob": -0.18219110107421874, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.00010115205805050209}, {"id": 169, "seek": 99992, "start": 999.92, "end": 1004.4799999999999, "text": " intermediary that is going and sucking up the state of your account, storing it in a local", "tokens": [15184, 822, 300, 307, 516, 293, 38669, 493, 264, 1785, 295, 428, 2696, 11, 26085, 309, 294, 257, 2654], "temperature": 0.0, "avg_logprob": -0.09403352901853364, "compression_ratio": 1.6690391459074734, "no_speech_prob": 3.7249032175168395e-05}, {"id": 170, "seek": 99992, "start": 1004.4799999999999, "end": 1011.12, "text": " Postgres and then talking the very, very responsive API in order to pull that data into Element X", "tokens": [10223, 45189, 293, 550, 1417, 264, 588, 11, 588, 21826, 9362, 294, 1668, 281, 2235, 300, 1412, 666, 20900, 1783], "temperature": 0.0, "avg_logprob": -0.09403352901853364, "compression_ratio": 1.6690391459074734, "no_speech_prob": 3.7249032175168395e-05}, {"id": 171, "seek": 99992, "start": 1011.12, "end": 1016.8, "text": " itself. It does it by looking like this. Sliding sync lets the clients request the bare minimum", "tokens": [2564, 13, 467, 775, 309, 538, 1237, 411, 341, 13, 6187, 2819, 20271, 6653, 264, 6982, 5308, 264, 6949, 7285], "temperature": 0.0, "avg_logprob": -0.09403352901853364, "compression_ratio": 1.6690391459074734, "no_speech_prob": 3.7249032175168395e-05}, {"id": 172, "seek": 99992, "start": 1016.8, "end": 1021.4399999999999, "text": " of data that they need to render the UI. So here's an almost real request where we say,", "tokens": [295, 1412, 300, 436, 643, 281, 15529, 264, 15682, 13, 407, 510, 311, 364, 1920, 957, 5308, 689, 321, 584, 11], "temperature": 0.0, "avg_logprob": -0.09403352901853364, "compression_ratio": 1.6690391459074734, "no_speech_prob": 3.7249032175168395e-05}, {"id": 173, "seek": 99992, "start": 1021.4399999999999, "end": 1025.6, "text": " I want to see the currently visible rooms. I want to see the first page to preload it. So I want", "tokens": [286, 528, 281, 536, 264, 4362, 8974, 9396, 13, 286, 528, 281, 536, 264, 700, 3028, 281, 659, 2907, 309, 13, 407, 286, 528], "temperature": 0.0, "avg_logprob": -0.09403352901853364, "compression_ratio": 1.6690391459074734, "no_speech_prob": 3.7249032175168395e-05}, {"id": 174, "seek": 102560, "start": 1025.6, "end": 1031.12, "text": " 20 rooms, 0 to 20. I want it sorted by recency and then name. I only want the avatar and whether", "tokens": [945, 9396, 11, 1958, 281, 945, 13, 286, 528, 309, 25462, 538, 850, 3020, 293, 550, 1315, 13, 286, 787, 528, 264, 36205, 293, 1968], "temperature": 0.0, "avg_logprob": -0.13957513703240287, "compression_ratio": 1.8063492063492064, "no_speech_prob": 8.240752504207194e-05}, {"id": 175, "seek": 102560, "start": 1031.12, "end": 1035.36, "text": " it's encrypted. I'm going to get the calculated name whatever. I don't want any messages because", "tokens": [309, 311, 36663, 13, 286, 478, 516, 281, 483, 264, 15598, 1315, 2035, 13, 286, 500, 380, 528, 604, 7897, 570], "temperature": 0.0, "avg_logprob": -0.13957513703240287, "compression_ratio": 1.8063492063492064, "no_speech_prob": 8.240752504207194e-05}, {"id": 176, "seek": 102560, "start": 1035.36, "end": 1040.48, "text": " we've done a waste time actually downloading scroll back. And we're going to filter it to", "tokens": [321, 600, 1096, 257, 5964, 565, 767, 32529, 11369, 646, 13, 400, 321, 434, 516, 281, 6608, 309, 281], "temperature": 0.0, "avg_logprob": -0.13957513703240287, "compression_ratio": 1.8063492063492064, "no_speech_prob": 8.240752504207194e-05}, {"id": 177, "seek": 102560, "start": 1040.48, "end": 1045.52, "text": " not have invites, not have old rooms, and not have those pesky space rooms. And whilst we're at it,", "tokens": [406, 362, 35719, 11, 406, 362, 1331, 9396, 11, 293, 406, 362, 729, 9262, 4133, 1901, 9396, 13, 400, 18534, 321, 434, 412, 309, 11], "temperature": 0.0, "avg_logprob": -0.13957513703240287, "compression_ratio": 1.8063492063492064, "no_speech_prob": 8.240752504207194e-05}, {"id": 178, "seek": 102560, "start": 1045.52, "end": 1049.76, "text": " we want to have end-to-end encryption. We want to have two device messages and we want account", "tokens": [321, 528, 281, 362, 917, 12, 1353, 12, 521, 29575, 13, 492, 528, 281, 362, 732, 4302, 7897, 293, 321, 528, 2696], "temperature": 0.0, "avg_logprob": -0.13957513703240287, "compression_ratio": 1.8063492063492064, "no_speech_prob": 8.240752504207194e-05}, {"id": 179, "seek": 104976, "start": 1049.76, "end": 1055.44, "text": " data. And the server or the sliding sync proxy will literally just return about 10k of data,", "tokens": [1412, 13, 400, 264, 7154, 420, 264, 21169, 20271, 29690, 486, 3736, 445, 2736, 466, 1266, 74, 295, 1412, 11], "temperature": 0.0, "avg_logprob": -0.13397921937884708, "compression_ratio": 1.674074074074074, "no_speech_prob": 4.528033605311066e-05}, {"id": 180, "seek": 104976, "start": 1055.44, "end": 1060.0, "text": " which is those 20 rooms with the bare data, bare essentials that you requested.", "tokens": [597, 307, 729, 945, 9396, 365, 264, 6949, 1412, 11, 6949, 46884, 300, 291, 16436, 13], "temperature": 0.0, "avg_logprob": -0.13397921937884708, "compression_ratio": 1.674074074074074, "no_speech_prob": 4.528033605311066e-05}, {"id": 181, "seek": 104976, "start": 1060.8, "end": 1067.12, "text": " The key design criteria for sliding sync is the performance is constant with the number of rooms.", "tokens": [440, 2141, 1715, 11101, 337, 21169, 20271, 307, 264, 3389, 307, 5754, 365, 264, 1230, 295, 9396, 13], "temperature": 0.0, "avg_logprob": -0.13397921937884708, "compression_ratio": 1.674074074074074, "no_speech_prob": 4.528033605311066e-05}, {"id": 182, "seek": 104976, "start": 1067.68, "end": 1072.8799999999999, "text": " And this was the horrible mistake with the old API and frankly the whole design of matrix", "tokens": [400, 341, 390, 264, 9263, 6146, 365, 264, 1331, 9362, 293, 11939, 264, 1379, 1715, 295, 8141], "temperature": 0.0, "avg_logprob": -0.13397921937884708, "compression_ratio": 1.674074074074074, "no_speech_prob": 4.528033605311066e-05}, {"id": 183, "seek": 104976, "start": 1072.8799999999999, "end": 1078.24, "text": " historically that as you join more rooms, it gets linearly slower for basically everything.", "tokens": [16180, 300, 382, 291, 3917, 544, 9396, 11, 309, 2170, 43586, 14009, 337, 1936, 1203, 13], "temperature": 0.0, "avg_logprob": -0.13397921937884708, "compression_ratio": 1.674074074074074, "no_speech_prob": 4.528033605311066e-05}, {"id": 184, "seek": 107824, "start": 1078.24, "end": 1081.52, "text": " And that was fine for the first few years when people are in a couple of hundred rooms,", "tokens": [400, 300, 390, 2489, 337, 264, 700, 1326, 924, 562, 561, 366, 294, 257, 1916, 295, 3262, 9396, 11], "temperature": 0.0, "avg_logprob": -0.08809769153594971, "compression_ratio": 1.7120743034055728, "no_speech_prob": 0.00010729495261330158}, {"id": 185, "seek": 107824, "start": 1081.52, "end": 1085.68, "text": " but obviously we don't want to predicate the success of the protocol on, yeah, it's fine as", "tokens": [457, 2745, 321, 500, 380, 528, 281, 3852, 8700, 264, 2245, 295, 264, 10336, 322, 11, 1338, 11, 309, 311, 2489, 382], "temperature": 0.0, "avg_logprob": -0.08809769153594971, "compression_ratio": 1.7120743034055728, "no_speech_prob": 0.00010729495261330158}, {"id": 186, "seek": 107824, "start": 1085.68, "end": 1090.4, "text": " long as you're not a power user or it's fine as long as you don't actually use it. And if you", "tokens": [938, 382, 291, 434, 406, 257, 1347, 4195, 420, 309, 311, 2489, 382, 938, 382, 291, 500, 380, 767, 764, 309, 13, 400, 498, 291], "temperature": 0.0, "avg_logprob": -0.08809769153594971, "compression_ratio": 1.7120743034055728, "no_speech_prob": 0.00010729495261330158}, {"id": 187, "seek": 107824, "start": 1090.4, "end": 1095.68, "text": " think of matrix being a bit like a file system, imagine how awful, and I'm looking at you,", "tokens": [519, 295, 8141, 885, 257, 857, 411, 257, 3991, 1185, 11, 3811, 577, 11232, 11, 293, 286, 478, 1237, 412, 291, 11], "temperature": 0.0, "avg_logprob": -0.08809769153594971, "compression_ratio": 1.7120743034055728, "no_speech_prob": 0.00010729495261330158}, {"id": 188, "seek": 107824, "start": 1095.68, "end": 1100.32, "text": " EXT2, a file system would be if it just slowed down linearly with the number of files that you put", "tokens": [16385, 51, 17, 11, 257, 3991, 1185, 576, 312, 498, 309, 445, 32057, 760, 43586, 365, 264, 1230, 295, 7098, 300, 291, 829], "temperature": 0.0, "avg_logprob": -0.08809769153594971, "compression_ratio": 1.7120743034055728, "no_speech_prob": 0.00010729495261330158}, {"id": 189, "seek": 107824, "start": 1100.32, "end": 1107.36, "text": " in a directory or some other characteristic. And as more and more rooms pop up in matrix,", "tokens": [294, 257, 21120, 420, 512, 661, 16282, 13, 400, 382, 544, 293, 544, 9396, 1665, 493, 294, 8141, 11], "temperature": 0.0, "avg_logprob": -0.08809769153594971, "compression_ratio": 1.7120743034055728, "no_speech_prob": 0.00010729495261330158}, {"id": 190, "seek": 110736, "start": 1107.36, "end": 1112.7199999999998, "text": " it's not just chat rooms, it could be spaces. Now imagine that you go and join the EU and the,", "tokens": [309, 311, 406, 445, 5081, 9396, 11, 309, 727, 312, 7673, 13, 823, 3811, 300, 291, 352, 293, 3917, 264, 10887, 293, 264, 11], "temperature": 0.0, "avg_logprob": -0.12859716908685093, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.993172817397863e-05}, {"id": 191, "seek": 110736, "start": 1113.6, "end": 1118.24, "text": " you know, you're working in the EU government and the EU has got a massive space of hierarchy over", "tokens": [291, 458, 11, 291, 434, 1364, 294, 264, 10887, 2463, 293, 264, 10887, 575, 658, 257, 5994, 1901, 295, 22333, 670], "temperature": 0.0, "avg_logprob": -0.12859716908685093, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.993172817397863e-05}, {"id": 192, "seek": 110736, "start": 1118.24, "end": 1122.8, "text": " all of the countries and all of their public sector bodies. Even before you've talked to somebody,", "tokens": [439, 295, 264, 3517, 293, 439, 295, 641, 1908, 6977, 7510, 13, 2754, 949, 291, 600, 2825, 281, 2618, 11], "temperature": 0.0, "avg_logprob": -0.12859716908685093, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.993172817397863e-05}, {"id": 193, "seek": 110736, "start": 1122.8, "end": 1127.4399999999998, "text": " you might need to have visibility over this big hierarchy of like a thousand rooms. You do not", "tokens": [291, 1062, 643, 281, 362, 19883, 670, 341, 955, 22333, 295, 411, 257, 4714, 9396, 13, 509, 360, 406], "temperature": 0.0, "avg_logprob": -0.12859716908685093, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.993172817397863e-05}, {"id": 194, "seek": 110736, "start": 1127.4399999999998, "end": 1134.7199999999998, "text": " want your matrix client to take a thousand times longer to log in or sync. So that's basically", "tokens": [528, 428, 8141, 6423, 281, 747, 257, 4714, 1413, 2854, 281, 3565, 294, 420, 20271, 13, 407, 300, 311, 1936], "temperature": 0.0, "avg_logprob": -0.12859716908685093, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.993172817397863e-05}, {"id": 195, "seek": 113472, "start": 1134.72, "end": 1139.76, "text": " the entire idea here that you can have an infinite number of rooms, bit like IMAP, where you can", "tokens": [264, 2302, 1558, 510, 300, 291, 393, 362, 364, 13785, 1230, 295, 9396, 11, 857, 411, 21463, 4715, 11, 689, 291, 393], "temperature": 0.0, "avg_logprob": -0.09771446709160332, "compression_ratio": 1.7107142857142856, "no_speech_prob": 4.2635012505343184e-05}, {"id": 196, "seek": 113472, "start": 1139.76, "end": 1143.76, "text": " have massive mail folders and yet you're only going to care about the subset that your client", "tokens": [362, 5994, 10071, 31082, 293, 1939, 291, 434, 787, 516, 281, 1127, 466, 264, 25993, 300, 428, 6423], "temperature": 0.0, "avg_logprob": -0.09771446709160332, "compression_ratio": 1.7107142857142856, "no_speech_prob": 4.2635012505343184e-05}, {"id": 197, "seek": 113472, "start": 1143.76, "end": 1150.72, "text": " wants to actually manipulate. Having requested this range of 20 rooms, you then get updates from", "tokens": [2738, 281, 767, 20459, 13, 10222, 16436, 341, 3613, 295, 945, 9396, 11, 291, 550, 483, 9205, 490], "temperature": 0.0, "avg_logprob": -0.09771446709160332, "compression_ratio": 1.7107142857142856, "no_speech_prob": 4.2635012505343184e-05}, {"id": 198, "seek": 113472, "start": 1150.72, "end": 1154.56, "text": " the server, and this is why it's called sliding sync, that you basically have requested a window", "tokens": [264, 7154, 11, 293, 341, 307, 983, 309, 311, 1219, 21169, 20271, 11, 300, 291, 1936, 362, 16436, 257, 4910], "temperature": 0.0, "avg_logprob": -0.09771446709160332, "compression_ratio": 1.7107142857142856, "no_speech_prob": 4.2635012505343184e-05}, {"id": 199, "seek": 113472, "start": 1155.6000000000001, "end": 1161.28, "text": " over these rooms, these 20 rooms or whatever it might be. And then as the state changes on the", "tokens": [670, 613, 9396, 11, 613, 945, 9396, 420, 2035, 309, 1062, 312, 13, 400, 550, 382, 264, 1785, 2962, 322, 264], "temperature": 0.0, "avg_logprob": -0.09771446709160332, "compression_ratio": 1.7107142857142856, "no_speech_prob": 4.2635012505343184e-05}, {"id": 200, "seek": 116128, "start": 1161.28, "end": 1166.72, "text": " server, you get updates of inserts of room here, delete one here, invalidate it here. It doesn't", "tokens": [7154, 11, 291, 483, 9205, 295, 49163, 295, 1808, 510, 11, 12097, 472, 510, 11, 34702, 473, 309, 510, 13, 467, 1177, 380], "temperature": 0.0, "avg_logprob": -0.16472419806286298, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0001806157233659178}, {"id": 201, "seek": 116128, "start": 1166.72, "end": 1172.3999999999999, "text": " have to be rooms, in future it could be members or other sort of characteristics. This has been", "tokens": [362, 281, 312, 9396, 11, 294, 2027, 309, 727, 312, 2679, 420, 661, 1333, 295, 10891, 13, 639, 575, 668], "temperature": 0.0, "avg_logprob": -0.16472419806286298, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0001806157233659178}, {"id": 202, "seek": 116128, "start": 1172.3999999999999, "end": 1176.8799999999999, "text": " shamelessly stolen from Discord, so apologies to Discord folks if you're listening, but thank you", "tokens": [40164, 356, 15900, 490, 32623, 11, 370, 34929, 281, 32623, 4024, 498, 291, 434, 4764, 11, 457, 1309, 291], "temperature": 0.0, "avg_logprob": -0.16472419806286298, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0001806157233659178}, {"id": 203, "seek": 116128, "start": 1176.8799999999999, "end": 1182.3999999999999, "text": " also for coming up with this nice approach for how to maintain performance and scrolling on apps.", "tokens": [611, 337, 1348, 493, 365, 341, 1481, 3109, 337, 577, 281, 6909, 3389, 293, 29053, 322, 7733, 13], "temperature": 0.0, "avg_logprob": -0.16472419806286298, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0001806157233659178}, {"id": 204, "seek": 116128, "start": 1183.28, "end": 1188.6399999999999, "text": " And the end result is just many more. It makes login instant, sync instant, and also time to", "tokens": [400, 264, 917, 1874, 307, 445, 867, 544, 13, 467, 1669, 24276, 9836, 11, 20271, 9836, 11, 293, 611, 565, 281], "temperature": 0.0, "avg_logprob": -0.16472419806286298, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0001806157233659178}, {"id": 205, "seek": 118864, "start": 1188.64, "end": 1194.8000000000002, "text": " view rooms instant. Element X is only going to talk sliding sync. There is no point in us wasting", "tokens": [1910, 9396, 9836, 13, 20900, 1783, 307, 787, 516, 281, 751, 21169, 20271, 13, 821, 307, 572, 935, 294, 505, 20457], "temperature": 0.0, "avg_logprob": -0.10142013482880174, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.0002782003430183977}, {"id": 206, "seek": 118864, "start": 1194.8000000000002, "end": 1199.2, "text": " time implementing both approaches, but they're really quite different, and we want everybody", "tokens": [565, 18114, 1293, 11587, 11, 457, 436, 434, 534, 1596, 819, 11, 293, 321, 528, 2201], "temperature": 0.0, "avg_logprob": -0.10142013482880174, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.0002782003430183977}, {"id": 207, "seek": 118864, "start": 1199.2, "end": 1205.3600000000001, "text": " using Element X for it to have a snappy snappy snappy experience. We've done a lot of iterations.", "tokens": [1228, 20900, 1783, 337, 309, 281, 362, 257, 14528, 7966, 14528, 7966, 14528, 7966, 1752, 13, 492, 600, 1096, 257, 688, 295, 36540, 13], "temperature": 0.0, "avg_logprob": -0.10142013482880174, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.0002782003430183977}, {"id": 208, "seek": 118864, "start": 1205.3600000000001, "end": 1210.88, "text": " I've been driving the poor Rust team and sliding sync team and Element X team mad by constantly", "tokens": [286, 600, 668, 4840, 264, 4716, 34952, 1469, 293, 21169, 20271, 1469, 293, 20900, 1783, 1469, 5244, 538, 6460], "temperature": 0.0, "avg_logprob": -0.10142013482880174, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.0002782003430183977}, {"id": 209, "seek": 118864, "start": 1210.88, "end": 1216.3200000000002, "text": " demanding us to try to get the launch time down to 100 mils or something, and there's gone through", "tokens": [19960, 505, 281, 853, 281, 483, 264, 4025, 565, 760, 281, 2319, 1962, 82, 420, 746, 11, 293, 456, 311, 2780, 807], "temperature": 0.0, "avg_logprob": -0.10142013482880174, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.0002782003430183977}, {"id": 210, "seek": 121632, "start": 1216.32, "end": 1221.9199999999998, "text": " probably 10 iterations to see how we actually drive the API. And it's been really interesting.", "tokens": [1391, 1266, 36540, 281, 536, 577, 321, 767, 3332, 264, 9362, 13, 400, 309, 311, 668, 534, 1880, 13], "temperature": 0.0, "avg_logprob": -0.09611708777291435, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.00012310707825236022}, {"id": 211, "seek": 121632, "start": 1221.9199999999998, "end": 1226.6399999999999, "text": " The end conclusion is, first of all, when you launch the app, you sync that first", "tokens": [440, 917, 10063, 307, 11, 700, 295, 439, 11, 562, 291, 4025, 264, 724, 11, 291, 20271, 300, 700], "temperature": 0.0, "avg_logprob": -0.09611708777291435, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.00012310707825236022}, {"id": 212, "seek": 121632, "start": 1226.6399999999999, "end": 1230.56, "text": " screen's worth of rooms, but without any timeline. Literally the request I just showed you.", "tokens": [2568, 311, 3163, 295, 9396, 11, 457, 1553, 604, 12933, 13, 23768, 264, 5308, 286, 445, 4712, 291, 13], "temperature": 0.0, "avg_logprob": -0.09611708777291435, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.00012310707825236022}, {"id": 213, "seek": 121632, "start": 1231.28, "end": 1236.8799999999999, "text": " Next, you immediately increase the timeline limit on that window to one. So you'll fill in the", "tokens": [3087, 11, 291, 4258, 3488, 264, 12933, 4948, 322, 300, 4910, 281, 472, 13, 407, 291, 603, 2836, 294, 264], "temperature": 0.0, "avg_logprob": -0.09611708777291435, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.00012310707825236022}, {"id": 214, "seek": 121632, "start": 1236.8799999999999, "end": 1241.9199999999998, "text": " room previews, and it was happening so fast earlier that we didn't even have time to spot it happening.", "tokens": [1808, 14281, 82, 11, 293, 309, 390, 2737, 370, 2370, 3071, 300, 321, 994, 380, 754, 362, 565, 281, 4008, 309, 2737, 13], "temperature": 0.0, "avg_logprob": -0.09611708777291435, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.00012310707825236022}, {"id": 215, "seek": 124192, "start": 1241.92, "end": 1248.0800000000002, "text": " And then you pre-cache a page's worth of history of the visible rooms. So when I jumped into TWIM", "tokens": [400, 550, 291, 659, 12, 66, 6000, 257, 3028, 311, 3163, 295, 2503, 295, 264, 8974, 9396, 13, 407, 562, 286, 13864, 666, 23737, 6324], "temperature": 0.0, "avg_logprob": -0.09802326534105384, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0001250484201591462}, {"id": 216, "seek": 124192, "start": 1248.0800000000002, "end": 1254.24, "text": " and the history was already all loaded there, it's because the background and pre-cache had already", "tokens": [293, 264, 2503, 390, 1217, 439, 13210, 456, 11, 309, 311, 570, 264, 3678, 293, 659, 12, 66, 6000, 632, 1217], "temperature": 0.0, "avg_logprob": -0.09802326534105384, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0001250484201591462}, {"id": 217, "seek": 124192, "start": 1254.24, "end": 1259.2, "text": " happened because I'd stopped scrolling the room list and immediately jumped in to pre-populate", "tokens": [2011, 570, 286, 1116, 5936, 29053, 264, 1808, 1329, 293, 4258, 13864, 294, 281, 659, 12, 13872, 5256], "temperature": 0.0, "avg_logprob": -0.09802326534105384, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0001250484201591462}, {"id": 218, "seek": 124192, "start": 1259.2, "end": 1265.2, "text": " the history for those pages. Then you also incrementally build the big list of all your rooms", "tokens": [264, 2503, 337, 729, 7183, 13, 1396, 291, 611, 26200, 379, 1322, 264, 955, 1329, 295, 439, 428, 9396], "temperature": 0.0, "avg_logprob": -0.09802326534105384, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0001250484201591462}, {"id": 219, "seek": 124192, "start": 1265.2, "end": 1269.92, "text": " in the background, which I guess technically is ON with a number of rooms, but because it's", "tokens": [294, 264, 3678, 11, 597, 286, 2041, 12120, 307, 9299, 365, 257, 1230, 295, 9396, 11, 457, 570, 309, 311], "temperature": 0.0, "avg_logprob": -0.09802326534105384, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0001250484201591462}, {"id": 220, "seek": 126992, "start": 1269.92, "end": 1273.6000000000001, "text": " happening in the background, it's not on the critical path. It means you can do the scroll", "tokens": [2737, 294, 264, 3678, 11, 309, 311, 406, 322, 264, 4924, 3100, 13, 467, 1355, 291, 393, 360, 264, 11369], "temperature": 0.0, "avg_logprob": -0.1919199574378229, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020352269348222762}, {"id": 221, "seek": 126992, "start": 1273.6000000000001, "end": 1278.5600000000002, "text": " for all your rooms or search for a room by name instantly and be able to find them. And finally,", "tokens": [337, 439, 428, 9396, 420, 3164, 337, 257, 1808, 538, 1315, 13518, 293, 312, 1075, 281, 915, 552, 13, 400, 2721, 11], "temperature": 0.0, "avg_logprob": -0.1919199574378229, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020352269348222762}, {"id": 222, "seek": 126992, "start": 1278.5600000000002, "end": 1284.0, "text": " you cache it in Sled or SQLite. Rust SDK is doing all the heavy lifting here.", "tokens": [291, 19459, 309, 294, 318, 1493, 420, 19200, 642, 13, 34952, 37135, 307, 884, 439, 264, 4676, 15798, 510, 13], "temperature": 0.0, "avg_logprob": -0.1919199574378229, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020352269348222762}, {"id": 223, "seek": 126992, "start": 1284.64, "end": 1290.4, "text": " The code base is maturing really well. We got it audited at the Vdozomat Slayer last year,", "tokens": [440, 3089, 3096, 307, 3803, 1345, 534, 731, 13, 492, 658, 309, 2379, 1226, 412, 264, 691, 2595, 89, 298, 267, 6187, 11167, 1036, 1064, 11], "temperature": 0.0, "avg_logprob": -0.1919199574378229, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020352269348222762}, {"id": 224, "seek": 126992, "start": 1290.4, "end": 1296.88, "text": " thanks to Least Authority, funded by Gamatik. And we have, I think, three other audits planned", "tokens": [3231, 281, 1456, 525, 29824, 11, 14385, 538, 24723, 267, 1035, 13, 400, 321, 362, 11, 286, 519, 11, 1045, 661, 2379, 1208, 8589], "temperature": 0.0, "avg_logprob": -0.1919199574378229, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020352269348222762}, {"id": 225, "seek": 129688, "start": 1296.88, "end": 1302.16, "text": " this year. They were meant to happen last year, but we had disruption along the way.", "tokens": [341, 1064, 13, 814, 645, 4140, 281, 1051, 1036, 1064, 11, 457, 321, 632, 28751, 2051, 264, 636, 13], "temperature": 0.0, "avg_logprob": -0.11975893540815874, "compression_ratio": 1.5724637681159421, "no_speech_prob": 6.355395453283563e-05}, {"id": 226, "seek": 129688, "start": 1303.0400000000002, "end": 1308.4, "text": " Then, high-quality bindings are critical for this. I mentioned that we've added AsyncFuture", "tokens": [1396, 11, 1090, 12, 11286, 14786, 1109, 366, 4924, 337, 341, 13, 286, 2835, 300, 321, 600, 3869, 1018, 34015, 37, 325, 540], "temperature": 0.0, "avg_logprob": -0.11975893540815874, "compression_ratio": 1.5724637681159421, "no_speech_prob": 6.355395453283563e-05}, {"id": 227, "seek": 129688, "start": 1308.4, "end": 1313.7600000000002, "text": " to UniFFI. I think this stack could be the ultimate stack for building cross-platform", "tokens": [281, 35191, 6345, 40, 13, 286, 519, 341, 8630, 727, 312, 264, 9705, 8630, 337, 2390, 3278, 12, 39975, 837], "temperature": 0.0, "avg_logprob": -0.11975893540815874, "compression_ratio": 1.5724637681159421, "no_speech_prob": 6.355395453283563e-05}, {"id": 228, "seek": 129688, "start": 1313.7600000000002, "end": 1318.88, "text": " mobile apps going forwards. I mean, you can use Rust for the heavy lifting,", "tokens": [6013, 7733, 516, 30126, 13, 286, 914, 11, 291, 393, 764, 34952, 337, 264, 4676, 15798, 11], "temperature": 0.0, "avg_logprob": -0.11975893540815874, "compression_ratio": 1.5724637681159421, "no_speech_prob": 6.355395453283563e-05}, {"id": 229, "seek": 129688, "start": 1318.88, "end": 1324.0, "text": " and then you hook up at the top a very thin but very native performance layer based on whatever", "tokens": [293, 550, 291, 6328, 493, 412, 264, 1192, 257, 588, 5862, 457, 588, 8470, 3389, 4583, 2361, 322, 2035], "temperature": 0.0, "avg_logprob": -0.11975893540815874, "compression_ratio": 1.5724637681159421, "no_speech_prob": 6.355395453283563e-05}, {"id": 230, "seek": 132400, "start": 1324.0, "end": 1331.44, "text": " the iOS gives you. And at the beginning, UniFFI was a little bit, it didn't have everything we", "tokens": [264, 17430, 2709, 291, 13, 400, 412, 264, 2863, 11, 35191, 6345, 40, 390, 257, 707, 857, 11, 309, 994, 380, 362, 1203, 321], "temperature": 0.0, "avg_logprob": -0.13757204301286452, "compression_ratio": 1.5196850393700787, "no_speech_prob": 6.450150249293074e-05}, {"id": 231, "seek": 132400, "start": 1331.44, "end": 1336.88, "text": " needed, and so we invested to go and particularly hook up the future support. And the end result,", "tokens": [2978, 11, 293, 370, 321, 13104, 281, 352, 293, 4098, 6328, 493, 264, 2027, 1406, 13, 400, 264, 917, 1874, 11], "temperature": 0.0, "avg_logprob": -0.13757204301286452, "compression_ratio": 1.5196850393700787, "no_speech_prob": 6.450150249293074e-05}, {"id": 232, "seek": 132400, "start": 1336.88, "end": 1343.12, "text": " I think, is quite transformational. So that's Rust SDK. Meanwhile, whilst Element X is maturing,", "tokens": [286, 519, 11, 307, 1596, 4088, 1478, 13, 407, 300, 311, 34952, 37135, 13, 13879, 11, 18534, 20900, 1783, 307, 3803, 1345, 11], "temperature": 0.0, "avg_logprob": -0.13757204301286452, "compression_ratio": 1.5196850393700787, "no_speech_prob": 6.450150249293074e-05}, {"id": 233, "seek": 132400, "start": 1343.12, "end": 1347.84, "text": " we need to keep the existing clients secured too. But so it's going to take us a while to get to", "tokens": [321, 643, 281, 1066, 264, 6741, 6982, 22905, 886, 13, 583, 370, 309, 311, 516, 281, 747, 505, 257, 1339, 281, 483, 281], "temperature": 0.0, "avg_logprob": -0.13757204301286452, "compression_ratio": 1.5196850393700787, "no_speech_prob": 6.450150249293074e-05}, {"id": 234, "seek": 134784, "start": 1347.84, "end": 1354.24, "text": " parity between Element and Element X. And the project for this for crypto is called Element R,", "tokens": [44747, 1296, 20900, 293, 20900, 1783, 13, 400, 264, 1716, 337, 341, 337, 17240, 307, 1219, 20900, 497, 11], "temperature": 0.0, "avg_logprob": -0.09251696642707376, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.00023076341312844306}, {"id": 235, "seek": 134784, "start": 1354.24, "end": 1362.0, "text": " confusingly. So this replaces the old cryptography implementations in JS, iOS, and Android SDK", "tokens": [13181, 356, 13, 407, 341, 46734, 264, 1331, 9844, 5820, 4445, 763, 294, 33063, 11, 17430, 11, 293, 8853, 37135], "temperature": 0.0, "avg_logprob": -0.09251696642707376, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.00023076341312844306}, {"id": 236, "seek": 134784, "start": 1362.0, "end": 1369.1999999999998, "text": " with the same Rust crate that powers Rust SDK. So it's just the crypto crate that is providing", "tokens": [365, 264, 912, 34952, 42426, 300, 8674, 34952, 37135, 13, 407, 309, 311, 445, 264, 17240, 42426, 300, 307, 6530], "temperature": 0.0, "avg_logprob": -0.09251696642707376, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.00023076341312844306}, {"id": 237, "seek": 134784, "start": 1369.1999999999998, "end": 1375.1999999999998, "text": " a consistent encryption implementation across all the platforms. So this means that if we have", "tokens": [257, 8398, 29575, 11420, 2108, 439, 264, 9473, 13, 407, 341, 1355, 300, 498, 321, 362], "temperature": 0.0, "avg_logprob": -0.09251696642707376, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.00023076341312844306}, {"id": 238, "seek": 137520, "start": 1375.2, "end": 1380.96, "text": " hypothetically horrible CVEs popping up, we only have to fix them in one place in the Rust SDK,", "tokens": [24371, 22652, 9263, 383, 7540, 82, 18374, 493, 11, 321, 787, 362, 281, 3191, 552, 294, 472, 1081, 294, 264, 34952, 37135, 11], "temperature": 0.0, "avg_logprob": -0.1404891014099121, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.0002331454015802592}, {"id": 239, "seek": 137520, "start": 1380.96, "end": 1385.92, "text": " rather than having to do it four times over between where by West Android and Rust.", "tokens": [2831, 813, 1419, 281, 360, 309, 1451, 1413, 670, 1296, 689, 538, 4055, 8853, 293, 34952, 13], "temperature": 0.0, "avg_logprob": -0.1404891014099121, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.0002331454015802592}, {"id": 240, "seek": 137520, "start": 1386.88, "end": 1393.28, "text": " And you can use this today. It is still beta, so it may kill your cat and flood your house.", "tokens": [400, 291, 393, 764, 341, 965, 13, 467, 307, 920, 9861, 11, 370, 309, 815, 1961, 428, 3857, 293, 10481, 428, 1782, 13], "temperature": 0.0, "avg_logprob": -0.1404891014099121, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.0002331454015802592}, {"id": 241, "seek": 137520, "start": 1393.28, "end": 1397.68, "text": " I've been using it, it occasionally logs me out, which is a bit frustrating because initial sync", "tokens": [286, 600, 668, 1228, 309, 11, 309, 16895, 20820, 385, 484, 11, 597, 307, 257, 857, 16522, 570, 5883, 20271], "temperature": 0.0, "avg_logprob": -0.1404891014099121, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.0002331454015802592}, {"id": 242, "seek": 137520, "start": 1397.68, "end": 1403.3600000000001, "text": " on V2 takes 20 minutes. But I recommend having a play if you're interested, enable Rusty", "tokens": [322, 691, 17, 2516, 945, 2077, 13, 583, 286, 2748, 1419, 257, 862, 498, 291, 434, 3102, 11, 9528, 34952, 88], "temperature": 0.0, "avg_logprob": -0.1404891014099121, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.0002331454015802592}, {"id": 243, "seek": 140336, "start": 1403.36, "end": 1408.6399999999999, "text": " and Twen's encryption in labs on Element iOS. Androids will be coming fairly soon and Web", "tokens": [293, 2574, 268, 311, 29575, 294, 20339, 322, 20900, 17430, 13, 400, 340, 3742, 486, 312, 1348, 6457, 2321, 293, 9573], "temperature": 0.0, "avg_logprob": -0.15816563099354236, "compression_ratio": 1.6013745704467355, "no_speech_prob": 8.116971730487421e-05}, {"id": 244, "seek": 140336, "start": 1408.6399999999999, "end": 1414.4799999999998, "text": " started working on Friday. We sent the first and received the first encrypted messages by Rust", "tokens": [1409, 1364, 322, 6984, 13, 492, 2279, 264, 700, 293, 4613, 264, 700, 36663, 7897, 538, 34952], "temperature": 0.0, "avg_logprob": -0.15816563099354236, "compression_ratio": 1.6013745704467355, "no_speech_prob": 8.116971730487421e-05}, {"id": 245, "seek": 140336, "start": 1414.4799999999998, "end": 1420.9599999999998, "text": " crypto in a Wasm blob inside Element Web then. Rather than climatically, it looks and feels", "tokens": [17240, 294, 257, 3027, 76, 46115, 1854, 20900, 9573, 550, 13, 16571, 813, 5644, 5030, 11, 309, 1542, 293, 3417], "temperature": 0.0, "avg_logprob": -0.15816563099354236, "compression_ratio": 1.6013745704467355, "no_speech_prob": 8.116971730487421e-05}, {"id": 246, "seek": 140336, "start": 1420.9599999999998, "end": 1426.4799999999998, "text": " identical to the current crypto, except it's written in Rust. Then another big thing we've", "tokens": [14800, 281, 264, 2190, 17240, 11, 3993, 309, 311, 3720, 294, 34952, 13, 1396, 1071, 955, 551, 321, 600], "temperature": 0.0, "avg_logprob": -0.15816563099354236, "compression_ratio": 1.6013745704467355, "no_speech_prob": 8.116971730487421e-05}, {"id": 247, "seek": 140336, "start": 1426.4799999999998, "end": 1432.32, "text": " done to speed things up is faster remote room joins. So this is a huge internal change to Synapse.", "tokens": [1096, 281, 3073, 721, 493, 307, 4663, 8607, 1808, 24397, 13, 407, 341, 307, 257, 2603, 6920, 1319, 281, 26155, 11145, 13], "temperature": 0.0, "avg_logprob": -0.15816563099354236, "compression_ratio": 1.6013745704467355, "no_speech_prob": 8.116971730487421e-05}, {"id": 248, "seek": 143232, "start": 1432.32, "end": 1436.96, "text": " So again, you only receive the subset of state you need to participate in a room.", "tokens": [407, 797, 11, 291, 787, 4774, 264, 25993, 295, 1785, 291, 643, 281, 8197, 294, 257, 1808, 13], "temperature": 0.0, "avg_logprob": -0.09825338528850885, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00027549025253392756}, {"id": 249, "seek": 143232, "start": 1436.96, "end": 1440.96, "text": " Breaks all the assumptions that Synapse had. The rooms are typically atomic.", "tokens": [7090, 5461, 439, 264, 17695, 300, 26155, 11145, 632, 13, 440, 9396, 366, 5850, 22275, 13], "temperature": 0.0, "avg_logprob": -0.09825338528850885, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00027549025253392756}, {"id": 250, "seek": 143232, "start": 1440.96, "end": 1445.12, "text": " Instead, you basically trickle in the membership of the room in the background after having got", "tokens": [7156, 11, 291, 1936, 4282, 306, 294, 264, 16560, 295, 264, 1808, 294, 264, 3678, 934, 1419, 658], "temperature": 0.0, "avg_logprob": -0.09825338528850885, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00027549025253392756}, {"id": 251, "seek": 143232, "start": 1445.12, "end": 1452.1599999999999, "text": " the minimum subset to join the room. So for instance, matrix HQ right now, there are 92,948", "tokens": [264, 7285, 25993, 281, 3917, 264, 1808, 13, 407, 337, 5197, 11, 8141, 43209, 558, 586, 11, 456, 366, 28225, 11, 24, 13318], "temperature": 0.0, "avg_logprob": -0.09825338528850885, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00027549025253392756}, {"id": 252, "seek": 143232, "start": 1452.1599999999999, "end": 1457.28, "text": " state events for every user who has ever joined or changed their name or left and a whole bunch", "tokens": [1785, 3931, 337, 633, 4195, 567, 575, 1562, 6869, 420, 3105, 641, 1315, 420, 1411, 293, 257, 1379, 3840], "temperature": 0.0, "avg_logprob": -0.09825338528850885, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00027549025253392756}, {"id": 253, "seek": 143232, "start": 1457.28, "end": 1460.8799999999999, "text": " of other things. If you actually look at the subset you need to participate in the room,", "tokens": [295, 661, 721, 13, 759, 291, 767, 574, 412, 264, 25993, 291, 643, 281, 8197, 294, 264, 1808, 11], "temperature": 0.0, "avg_logprob": -0.09825338528850885, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00027549025253392756}, {"id": 254, "seek": 146088, "start": 1460.88, "end": 1468.24, "text": " it's 152. So this speeds up the room join time from 15 minutes to 14 seconds. So finally,", "tokens": [309, 311, 2119, 17, 13, 407, 341, 16411, 493, 264, 1808, 3917, 565, 490, 2119, 2077, 281, 3499, 3949, 13, 407, 2721, 11], "temperature": 0.0, "avg_logprob": -0.11322165452516995, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.000280984299024567}, {"id": 255, "seek": 146088, "start": 1468.24, "end": 1473.44, "text": " we will hopefully have fixed the problem where somebody gets and stores matrix Synapse immediately", "tokens": [321, 486, 4696, 362, 6806, 264, 1154, 689, 2618, 2170, 293, 9512, 8141, 26155, 11145, 4258], "temperature": 0.0, "avg_logprob": -0.11322165452516995, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.000280984299024567}, {"id": 256, "seek": 146088, "start": 1473.44, "end": 1478.16, "text": " tries to join matrix HQ, sits there for 15 minutes looking at errors as their computer", "tokens": [9898, 281, 3917, 8141, 43209, 11, 12696, 456, 337, 2119, 2077, 1237, 412, 13603, 382, 641, 3820], "temperature": 0.0, "avg_logprob": -0.11322165452516995, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.000280984299024567}, {"id": 257, "seek": 146088, "start": 1478.16, "end": 1484.16, "text": " explodes and wonders why everybody thinks matrix is as amazing as it is. So I mean,", "tokens": [42610, 293, 27348, 983, 2201, 7309, 8141, 307, 382, 2243, 382, 309, 307, 13, 407, 286, 914, 11], "temperature": 0.0, "avg_logprob": -0.11322165452516995, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.000280984299024567}, {"id": 258, "seek": 146088, "start": 1484.16, "end": 1487.6000000000001, "text": " the computer will still explode because they're still having to talk to all of the servers in", "tokens": [264, 3820, 486, 920, 21411, 570, 436, 434, 920, 1419, 281, 751, 281, 439, 295, 264, 15909, 294], "temperature": 0.0, "avg_logprob": -0.11322165452516995, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.000280984299024567}, {"id": 259, "seek": 148760, "start": 1487.6, "end": 1492.08, "text": " the room, but at least they will be responsive in 14 seconds. And we hope that the Synthelating", "tokens": [264, 1808, 11, 457, 412, 1935, 436, 486, 312, 21826, 294, 3499, 3949, 13, 400, 321, 1454, 300, 264, 318, 18656, 338, 990], "temperature": 0.0, "avg_logprob": -0.13282377489151492, "compression_ratio": 1.6494845360824741, "no_speech_prob": 7.871066918596625e-05}, {"id": 260, "seek": 148760, "start": 1492.08, "end": 1497.12, "text": " conversation in matrix HQ will be such that it distracts them from the smoke coming out to their", "tokens": [3761, 294, 8141, 43209, 486, 312, 1270, 300, 309, 9945, 82, 552, 490, 264, 8439, 1348, 484, 281, 641], "temperature": 0.0, "avg_logprob": -0.13282377489151492, "compression_ratio": 1.6494845360824741, "no_speech_prob": 7.871066918596625e-05}, {"id": 261, "seek": 148760, "start": 1497.12, "end": 1502.1599999999999, "text": " server. There's still a lot of room for improvement here. We shouldn't be hammering dead servers,", "tokens": [7154, 13, 821, 311, 920, 257, 688, 295, 1808, 337, 10444, 510, 13, 492, 4659, 380, 312, 13017, 278, 3116, 15909, 11], "temperature": 0.0, "avg_logprob": -0.13282377489151492, "compression_ratio": 1.6494845360824741, "no_speech_prob": 7.871066918596625e-05}, {"id": 262, "seek": 148760, "start": 1502.1599999999999, "end": 1506.56, "text": " which is where a lot of that time is going. And also, we should be caching the partial state.", "tokens": [597, 307, 689, 257, 688, 295, 300, 565, 307, 516, 13, 400, 611, 11, 321, 820, 312, 269, 2834, 264, 14641, 1785, 13], "temperature": 0.0, "avg_logprob": -0.13282377489151492, "compression_ratio": 1.6494845360824741, "no_speech_prob": 7.871066918596625e-05}, {"id": 263, "seek": 148760, "start": 1506.56, "end": 1511.28, "text": " So, you know, if I want to join matrix HQ, the server can just go and hand me the events I need", "tokens": [407, 11, 291, 458, 11, 498, 286, 528, 281, 3917, 8141, 43209, 11, 264, 7154, 393, 445, 352, 293, 1011, 385, 264, 3931, 286, 643], "temperature": 0.0, "avg_logprob": -0.13282377489151492, "compression_ratio": 1.6494845360824741, "no_speech_prob": 7.871066918596625e-05}, {"id": 264, "seek": 151128, "start": 1511.28, "end": 1519.76, "text": " to do that. Another big thing is matrix RTC. So this is the name we're referring to MSE3401", "tokens": [281, 360, 300, 13, 3996, 955, 551, 307, 8141, 497, 18238, 13, 407, 341, 307, 264, 1315, 321, 434, 13761, 281, 376, 5879, 18, 5254, 16], "temperature": 0.0, "avg_logprob": -0.16988147388805042, "compression_ratio": 1.4841269841269842, "no_speech_prob": 9.236123878508806e-05}, {"id": 265, "seek": 151128, "start": 1519.76, "end": 1527.28, "text": " and 3898 as many because those were awful names, whereas matrix RTC is a bit more snappy. And this", "tokens": [293, 12843, 22516, 382, 867, 570, 729, 645, 11232, 5288, 11, 9735, 8141, 497, 18238, 307, 257, 857, 544, 14528, 7966, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.16988147388805042, "compression_ratio": 1.4841269841269842, "no_speech_prob": 9.236123878508806e-05}, {"id": 266, "seek": 151128, "start": 1527.28, "end": 1533.84, "text": " is multi-party native VoIP. We've always had one-to-one VoIP. Here, we are standardizing the", "tokens": [307, 4825, 12, 23409, 8470, 7518, 9139, 13, 492, 600, 1009, 632, 472, 12, 1353, 12, 546, 7518, 9139, 13, 1692, 11, 321, 366, 3832, 3319, 264], "temperature": 0.0, "avg_logprob": -0.16988147388805042, "compression_ratio": 1.4841269841269842, "no_speech_prob": 9.236123878508806e-05}, {"id": 267, "seek": 151128, "start": 1533.84, "end": 1540.96, "text": " multi-party Zoom teams, Jetsy style experience, but in a heterogeneous way. So you can use", "tokens": [4825, 12, 23409, 13453, 5491, 11, 508, 1385, 88, 3758, 1752, 11, 457, 294, 257, 20789, 31112, 636, 13, 407, 291, 393, 764], "temperature": 0.0, "avg_logprob": -0.16988147388805042, "compression_ratio": 1.4841269841269842, "no_speech_prob": 9.236123878508806e-05}, {"id": 268, "seek": 154096, "start": 1540.96, "end": 1545.44, "text": " different clients. This is in lamps and element web. Video rooms looks like this on the right", "tokens": [819, 6982, 13, 639, 307, 294, 34887, 293, 4478, 3670, 13, 9777, 9396, 1542, 411, 341, 322, 264, 558], "temperature": 0.0, "avg_logprob": -0.1563093361734342, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.00021943196770735085}, {"id": 269, "seek": 154096, "start": 1545.44, "end": 1550.4, "text": " hand side, powered by element call. And it works as what we call a matroshka widget, where you", "tokens": [1011, 1252, 11, 17786, 538, 4478, 818, 13, 400, 309, 1985, 382, 437, 321, 818, 257, 3803, 2635, 71, 2330, 34047, 11, 689, 291], "temperature": 0.0, "avg_logprob": -0.1563093361734342, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.00021943196770735085}, {"id": 270, "seek": 154096, "start": 1550.4, "end": 1555.1200000000001, "text": " embed element call here as a widget. So this is an iframe on the left hand side. But even though", "tokens": [12240, 4478, 818, 510, 382, 257, 34047, 13, 407, 341, 307, 364, 498, 81, 529, 322, 264, 1411, 1011, 1252, 13, 583, 754, 1673], "temperature": 0.0, "avg_logprob": -0.1563093361734342, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.00021943196770735085}, {"id": 271, "seek": 154096, "start": 1555.1200000000001, "end": 1560.96, "text": " element call itself is a matrix client, it is piggybacking on the host's matrix client. So it", "tokens": [4478, 818, 2564, 307, 257, 8141, 6423, 11, 309, 307, 39349, 3207, 278, 322, 264, 3975, 311, 8141, 6423, 13, 407, 309], "temperature": 0.0, "avg_logprob": -0.1563093361734342, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.00021943196770735085}, {"id": 272, "seek": 154096, "start": 1560.96, "end": 1565.2, "text": " shares the encryption and the identity. You don't have two logs in sessions. And really", "tokens": [12182, 264, 29575, 293, 264, 6575, 13, 509, 500, 380, 362, 732, 20820, 294, 11081, 13, 400, 534], "temperature": 0.0, "avg_logprob": -0.1563093361734342, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.00021943196770735085}, {"id": 273, "seek": 156520, "start": 1565.2, "end": 1570.72, "text": " excitingly, we have multiple independent implementations of this in element call, hydrogen, third room,", "tokens": [4670, 356, 11, 321, 362, 3866, 6695, 4445, 763, 295, 341, 294, 4478, 818, 11, 12697, 11, 2636, 1808, 11], "temperature": 0.0, "avg_logprob": -0.19834563658409513, "compression_ratio": 1.5573770491803278, "no_speech_prob": 5.196746496949345e-05}, {"id": 274, "seek": 156520, "start": 1570.72, "end": 1574.48, "text": " and also, I believe, famously, it has an independent implementation in their healthcare", "tokens": [293, 611, 11, 286, 1697, 11, 34360, 11, 309, 575, 364, 6695, 11420, 294, 641, 8884], "temperature": 0.0, "avg_logprob": -0.19834563658409513, "compression_ratio": 1.5573770491803278, "no_speech_prob": 5.196746496949345e-05}, {"id": 275, "seek": 156520, "start": 1574.48, "end": 1581.68, "text": " product for Germany. And I'll very quickly try to show you a demo of this. And I'm going to show", "tokens": [1674, 337, 7244, 13, 400, 286, 603, 588, 2661, 853, 281, 855, 291, 257, 10723, 295, 341, 13, 400, 286, 478, 516, 281, 855], "temperature": 0.0, "avg_logprob": -0.19834563658409513, "compression_ratio": 1.5573770491803278, "no_speech_prob": 5.196746496949345e-05}, {"id": 276, "seek": 156520, "start": 1581.68, "end": 1588.48, "text": " you, where am I going? Oh, cool. That's good. Fozdom 2023. If anybody wants to heckle along", "tokens": [291, 11, 689, 669, 286, 516, 30, 876, 11, 1627, 13, 663, 311, 665, 13, 8564, 89, 4121, 44377, 13, 759, 4472, 2738, 281, 12872, 306, 2051], "temperature": 0.0, "avg_logprob": -0.19834563658409513, "compression_ratio": 1.5573770491803278, "no_speech_prob": 5.196746496949345e-05}, {"id": 277, "seek": 158848, "start": 1588.48, "end": 1595.2, "text": " on this, then feel free. Oh, I don't have any internet access, do I? Video conferencing demo, so", "tokens": [322, 341, 11, 550, 841, 1737, 13, 876, 11, 286, 500, 380, 362, 604, 4705, 2105, 11, 360, 286, 30, 9777, 13765, 13644, 10723, 11, 370], "temperature": 0.0, "avg_logprob": -0.17579678592518863, "compression_ratio": 1.568, "no_speech_prob": 8.780389907769859e-05}, {"id": 278, "seek": 158848, "start": 1595.2, "end": 1599.6, "text": " when you don't have any Wi-Fi, it's always a good idea, right? Let's see how it does. So I'm going", "tokens": [562, 291, 500, 380, 362, 604, 14035, 12, 13229, 11, 309, 311, 1009, 257, 665, 1558, 11, 558, 30, 961, 311, 536, 577, 309, 775, 13, 407, 286, 478, 516], "temperature": 0.0, "avg_logprob": -0.17579678592518863, "compression_ratio": 1.568, "no_speech_prob": 8.780389907769859e-05}, {"id": 279, "seek": 158848, "start": 1599.6, "end": 1607.2, "text": " to pop into that room there. And here is element call. And then I'm also going to spin up a local", "tokens": [281, 1665, 666, 300, 1808, 456, 13, 400, 510, 307, 4478, 818, 13, 400, 550, 286, 478, 611, 516, 281, 6060, 493, 257, 2654], "temperature": 0.0, "avg_logprob": -0.17579678592518863, "compression_ratio": 1.568, "no_speech_prob": 8.780389907769859e-05}, {"id": 280, "seek": 158848, "start": 1607.2, "end": 1613.68, "text": " hydrogen. Here's what I made earlier. Oh, hello, Amundee. Found some meeting here. This is Amundee", "tokens": [12697, 13, 1692, 311, 437, 286, 1027, 3071, 13, 876, 11, 7751, 11, 2012, 997, 1653, 13, 8207, 512, 3440, 510, 13, 639, 307, 2012, 997, 1653], "temperature": 0.0, "avg_logprob": -0.17579678592518863, "compression_ratio": 1.568, "no_speech_prob": 8.780389907769859e-05}, {"id": 281, "seek": 161368, "start": 1613.68, "end": 1621.52, "text": " and everybody. She co-founded Matrix. And I'm going to wish that this thing was telling me that a", "tokens": [293, 2201, 13, 1240, 598, 12, 49547, 36274, 13, 400, 286, 478, 516, 281, 3172, 300, 341, 551, 390, 3585, 385, 300, 257], "temperature": 0.0, "avg_logprob": -0.17286084493001302, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.00011679394083330408}, {"id": 282, "seek": 161368, "start": 1621.52, "end": 1626.0800000000002, "text": " video call was happening in the room. And still being one that's ended, but in practice, there's", "tokens": [960, 818, 390, 2737, 294, 264, 1808, 13, 400, 920, 885, 472, 300, 311, 4590, 11, 457, 294, 3124, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.17286084493001302, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.00011679394083330408}, {"id": 283, "seek": 161368, "start": 1626.0800000000002, "end": 1633.2, "text": " one happening right now. I wonder if this is... I wonder why? Okay. Perhaps we'll use a different", "tokens": [472, 2737, 558, 586, 13, 286, 2441, 498, 341, 307, 485, 286, 2441, 983, 30, 1033, 13, 10517, 321, 603, 764, 257, 819], "temperature": 0.0, "avg_logprob": -0.17286084493001302, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.00011679394083330408}, {"id": 284, "seek": 161368, "start": 1633.2, "end": 1642.48, "text": " room. Let's go to Fozdom 2024. Back to the future, everybody. And go over to hydrogen here. And I", "tokens": [1808, 13, 961, 311, 352, 281, 8564, 89, 4121, 45237, 13, 5833, 281, 264, 2027, 11, 2201, 13, 400, 352, 670, 281, 12697, 510, 13, 400, 286], "temperature": 0.0, "avg_logprob": -0.17286084493001302, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.00011679394083330408}, {"id": 285, "seek": 164248, "start": 1642.48, "end": 1649.28, "text": " think I should be able to just be able to join Fozdom 2024 on call.ams.host. Yeah, okay, here", "tokens": [519, 286, 820, 312, 1075, 281, 445, 312, 1075, 281, 3917, 8564, 89, 4121, 45237, 322, 818, 13, 4070, 13, 6037, 13, 865, 11, 1392, 11, 510], "temperature": 0.0, "avg_logprob": -0.1267935170067681, "compression_ratio": 1.5139442231075697, "no_speech_prob": 0.00013232907804194838}, {"id": 286, "seek": 164248, "start": 1650.0, "end": 1654.64, "text": " I can actually join it. And hey, Presto, you've got me staring at myself like a muppet because", "tokens": [286, 393, 767, 3917, 309, 13, 400, 4177, 11, 35272, 78, 11, 291, 600, 658, 385, 18043, 412, 2059, 411, 257, 2992, 427, 302, 570], "temperature": 0.0, "avg_logprob": -0.1267935170067681, "compression_ratio": 1.5139442231075697, "no_speech_prob": 0.00013232907804194838}, {"id": 287, "seek": 164248, "start": 1654.64, "end": 1660.8, "text": " nobody else is responding to my comedy joke of moving to 2024. So everybody, oh, hello. Perfect.", "tokens": [5079, 1646, 307, 16670, 281, 452, 13394, 7647, 295, 2684, 281, 45237, 13, 407, 2201, 11, 1954, 11, 7751, 13, 10246, 13], "temperature": 0.0, "avg_logprob": -0.1267935170067681, "compression_ratio": 1.5139442231075697, "no_speech_prob": 0.00013232907804194838}, {"id": 288, "seek": 164248, "start": 1660.8, "end": 1671.76, "text": " Somebody at the back. Thank you. Oh, and there's Amundee. So this thing is really cool because", "tokens": [13463, 412, 264, 646, 13, 1044, 291, 13, 876, 11, 293, 456, 311, 2012, 997, 1653, 13, 407, 341, 551, 307, 534, 1627, 570], "temperature": 0.0, "avg_logprob": -0.1267935170067681, "compression_ratio": 1.5139442231075697, "no_speech_prob": 0.00013232907804194838}, {"id": 289, "seek": 167176, "start": 1671.76, "end": 1677.36, "text": " it is completely standardized multi-party void signaling. We have two entirely different", "tokens": [309, 307, 2584, 31677, 4825, 12, 23409, 22009, 38639, 13, 492, 362, 732, 7696, 819], "temperature": 0.0, "avg_logprob": -0.12571477890014648, "compression_ratio": 1.7046153846153846, "no_speech_prob": 0.00014107709284871817}, {"id": 290, "seek": 167176, "start": 1677.36, "end": 1680.96, "text": " code bases. There is not a line of codes in common between hydrogen here on the left", "tokens": [3089, 17949, 13, 821, 307, 406, 257, 1622, 295, 14211, 294, 2689, 1296, 12697, 510, 322, 264, 1411], "temperature": 0.0, "avg_logprob": -0.12571477890014648, "compression_ratio": 1.7046153846153846, "no_speech_prob": 0.00014107709284871817}, {"id": 291, "seek": 167176, "start": 1680.96, "end": 1685.52, "text": " and element call here on the right. And just like back in the day on the phone network,", "tokens": [293, 4478, 818, 510, 322, 264, 558, 13, 400, 445, 411, 646, 294, 264, 786, 322, 264, 2593, 3209, 11], "temperature": 0.0, "avg_logprob": -0.12571477890014648, "compression_ratio": 1.7046153846153846, "no_speech_prob": 0.00014107709284871817}, {"id": 292, "seek": 167176, "start": 1685.52, "end": 1689.12, "text": " we could call each other on different things or have different set clients or whatever it might", "tokens": [321, 727, 818, 1184, 661, 322, 819, 721, 420, 362, 819, 992, 6982, 420, 2035, 309, 1062], "temperature": 0.0, "avg_logprob": -0.12571477890014648, "compression_ratio": 1.7046153846153846, "no_speech_prob": 0.00014107709284871817}, {"id": 293, "seek": 167176, "start": 1689.12, "end": 1695.68, "text": " happen to be. Oh, we've got somebody remote. That's awesome. Then here we actually have a proper", "tokens": [1051, 281, 312, 13, 876, 11, 321, 600, 658, 2618, 8607, 13, 663, 311, 3476, 13, 1396, 510, 321, 767, 362, 257, 2296], "temperature": 0.0, "avg_logprob": -0.12571477890014648, "compression_ratio": 1.7046153846153846, "no_speech_prob": 0.00014107709284871817}, {"id": 294, "seek": 167176, "start": 1695.68, "end": 1701.52, "text": " heterogeneous thing. So unlike JETC or some other conferencing system where everybody has to end up", "tokens": [20789, 31112, 551, 13, 407, 8343, 508, 4850, 34, 420, 512, 661, 13765, 13644, 1185, 689, 2201, 575, 281, 917, 493], "temperature": 0.0, "avg_logprob": -0.12571477890014648, "compression_ratio": 1.7046153846153846, "no_speech_prob": 0.00014107709284871817}, {"id": 295, "seek": 170152, "start": 1701.52, "end": 1711.2, "text": " using the same system to work, this is providing an interoperable thing. And crap out on this one", "tokens": [1228, 264, 912, 1185, 281, 589, 11, 341, 307, 6530, 364, 728, 7192, 712, 551, 13, 400, 12426, 484, 322, 341, 472], "temperature": 0.0, "avg_logprob": -0.14990399009303043, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.00014650645607616752}, {"id": 296, "seek": 170152, "start": 1711.2, "end": 1716.8, "text": " because I've got something better. I've got something better. So one of the other projects we", "tokens": [570, 286, 600, 658, 746, 1101, 13, 286, 600, 658, 746, 1101, 13, 407, 472, 295, 264, 661, 4455, 321], "temperature": 0.0, "avg_logprob": -0.14990399009303043, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.00014650645607616752}, {"id": 297, "seek": 170152, "start": 1716.8, "end": 1722.6399999999999, "text": " have worked at, which we're just releasing now is called Waterfall. Now what we just did then was", "tokens": [362, 2732, 412, 11, 597, 321, 434, 445, 16327, 586, 307, 1219, 8772, 6691, 13, 823, 437, 321, 445, 630, 550, 390], "temperature": 0.0, "avg_logprob": -0.14990399009303043, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.00014650645607616752}, {"id": 298, "seek": 170152, "start": 1722.6399999999999, "end": 1725.92, "text": " full mesh. All the clients were talking to one another. I'm amazed that it worked as well as", "tokens": [1577, 17407, 13, 1057, 264, 6982, 645, 1417, 281, 472, 1071, 13, 286, 478, 20507, 300, 309, 2732, 382, 731, 382], "temperature": 0.0, "avg_logprob": -0.14990399009303043, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.00014650645607616752}, {"id": 299, "seek": 172592, "start": 1725.92, "end": 1732.4, "text": " it did. What you want to do, though, is to have what's called an SFU. So these guys which go and", "tokens": [309, 630, 13, 708, 291, 528, 281, 360, 11, 1673, 11, 307, 281, 362, 437, 311, 1219, 364, 31095, 52, 13, 407, 613, 1074, 597, 352, 293], "temperature": 0.0, "avg_logprob": -0.19244102131236684, "compression_ratio": 1.5, "no_speech_prob": 9.886061889119446e-05}, {"id": 300, "seek": 172592, "start": 1732.4, "end": 1739.44, "text": " mix together the local video calls. And Sean Dubois, who's the project leader at Pion,", "tokens": [2890, 1214, 264, 2654, 960, 5498, 13, 400, 14839, 16488, 7376, 11, 567, 311, 264, 1716, 5263, 412, 430, 313, 11], "temperature": 0.0, "avg_logprob": -0.19244102131236684, "compression_ratio": 1.5, "no_speech_prob": 9.886061889119446e-05}, {"id": 301, "seek": 172592, "start": 1739.44, "end": 1746.4, "text": " the Golang WebRTC, wrote one of these called SFU to SFU based on reading MSC3401. And we", "tokens": [264, 36319, 656, 9573, 49, 18238, 11, 4114, 472, 295, 613, 1219, 31095, 52, 281, 31095, 52, 2361, 322, 3760, 7395, 34, 18, 5254, 16, 13, 400, 321], "temperature": 0.0, "avg_logprob": -0.19244102131236684, "compression_ratio": 1.5, "no_speech_prob": 9.886061889119446e-05}, {"id": 302, "seek": 172592, "start": 1746.4, "end": 1750.88, "text": " renamed it Waterfall. We've fleshed it out and we've hooked it up to element call. And I will", "tokens": [40949, 309, 8772, 6691, 13, 492, 600, 12497, 292, 309, 484, 293, 321, 600, 20410, 309, 493, 281, 4478, 818, 13, 400, 286, 486], "temperature": 0.0, "avg_logprob": -0.19244102131236684, "compression_ratio": 1.5, "no_speech_prob": 9.886061889119446e-05}, {"id": 303, "seek": 175088, "start": 1750.88, "end": 1757.0400000000002, "text": " endeavour to show you what that looks like. And it's going to be quite similar in some ways.", "tokens": [19099, 6817, 281, 855, 291, 437, 300, 1542, 411, 13, 400, 309, 311, 516, 281, 312, 1596, 2531, 294, 512, 2098, 13], "temperature": 0.0, "avg_logprob": -0.12638809204101562, "compression_ratio": 1.5940170940170941, "no_speech_prob": 6.0031226894352585e-05}, {"id": 304, "seek": 175088, "start": 1757.0400000000002, "end": 1764.4, "text": " Let me actually try a demo, demo room in here. Again, if someone is already in there, I'm going", "tokens": [961, 385, 767, 853, 257, 10723, 11, 10723, 1808, 294, 510, 13, 3764, 11, 498, 1580, 307, 1217, 294, 456, 11, 286, 478, 516], "temperature": 0.0, "avg_logprob": -0.12638809204101562, "compression_ratio": 1.5940170940170941, "no_speech_prob": 6.0031226894352585e-05}, {"id": 305, "seek": 175088, "start": 1764.4, "end": 1769.0400000000002, "text": " to try a fresh one. Let's call it fresh demo. Again, if anybody wants to try following along", "tokens": [281, 853, 257, 4451, 472, 13, 961, 311, 818, 309, 4451, 10723, 13, 3764, 11, 498, 4472, 2738, 281, 853, 3480, 2051], "temperature": 0.0, "avg_logprob": -0.12638809204101562, "compression_ratio": 1.5940170940170941, "no_speech_prob": 6.0031226894352585e-05}, {"id": 306, "seek": 175088, "start": 1769.0400000000002, "end": 1775.3600000000001, "text": " on this URL, if you can see it, please do so. Now this looks a little bit different because", "tokens": [322, 341, 12905, 11, 498, 291, 393, 536, 309, 11, 1767, 360, 370, 13, 823, 341, 1542, 257, 707, 857, 819, 570], "temperature": 0.0, "avg_logprob": -0.12638809204101562, "compression_ratio": 1.5940170940170941, "no_speech_prob": 6.0031226894352585e-05}, {"id": 307, "seek": 177536, "start": 1775.36, "end": 1781.36, "text": " it's connecting to the SFU instead. Oh, hello and hello. And hopefully we will get some video", "tokens": [309, 311, 11015, 281, 264, 31095, 52, 2602, 13, 876, 11, 7751, 293, 7751, 13, 400, 4696, 321, 486, 483, 512, 960], "temperature": 0.0, "avg_logprob": -0.20071729024251303, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.00020383049559313804}, {"id": 308, "seek": 177536, "start": 1781.36, "end": 1787.6, "text": " off and on. So this has been bounced off the go SFU. But perhaps I'll distract everybody by", "tokens": [766, 293, 322, 13, 407, 341, 575, 668, 46482, 766, 264, 352, 31095, 52, 13, 583, 4317, 286, 603, 9945, 2201, 538], "temperature": 0.0, "avg_logprob": -0.20071729024251303, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.00020383049559313804}, {"id": 309, "seek": 177536, "start": 1787.6, "end": 1792.8799999999999, "text": " zooming. So this has got a completely different layout on it. And it thinks it's connected.", "tokens": [48226, 13, 407, 341, 575, 658, 257, 2584, 819, 13333, 322, 309, 13, 400, 309, 7309, 309, 311, 4582, 13], "temperature": 0.0, "avg_logprob": -0.20071729024251303, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.00020383049559313804}, {"id": 310, "seek": 177536, "start": 1794.3999999999999, "end": 1799.4399999999998, "text": " Oh, there's Simon. I'm glad that Simon of all people is able to connect because he has written", "tokens": [876, 11, 456, 311, 13193, 13, 286, 478, 5404, 300, 13193, 295, 439, 561, 307, 1075, 281, 1745, 570, 415, 575, 3720], "temperature": 0.0, "avg_logprob": -0.20071729024251303, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.00020383049559313804}, {"id": 311, "seek": 179944, "start": 1799.44, "end": 1805.76, "text": " the vast majority of Waterfall. So thanks for demoing Simon. And I suspect it is not like in", "tokens": [264, 8369, 6286, 295, 8772, 6691, 13, 407, 3231, 337, 10723, 278, 13193, 13, 400, 286, 9091, 309, 307, 406, 411, 294], "temperature": 0.0, "avg_logprob": -0.10779126485188802, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.00015562934277113527}, {"id": 312, "seek": 179944, "start": 1805.76, "end": 1811.3600000000001, "text": " the packet loss here on my side. People are trying to connect in there. But it's working for some", "tokens": [264, 20300, 4470, 510, 322, 452, 1252, 13, 3432, 366, 1382, 281, 1745, 294, 456, 13, 583, 309, 311, 1364, 337, 512], "temperature": 0.0, "avg_logprob": -0.10779126485188802, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.00015562934277113527}, {"id": 313, "seek": 179944, "start": 1811.3600000000001, "end": 1817.68, "text": " folks. It's very, very new, very alpha, but it's exciting to actually see this thing working.", "tokens": [4024, 13, 467, 311, 588, 11, 588, 777, 11, 588, 8961, 11, 457, 309, 311, 4670, 281, 767, 536, 341, 551, 1364, 13], "temperature": 0.0, "avg_logprob": -0.10779126485188802, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.00015562934277113527}, {"id": 314, "seek": 179944, "start": 1817.68, "end": 1823.44, "text": " And if I quickly turn on debug here in developer mode, you'll see that it actually supports", "tokens": [400, 498, 286, 2661, 1261, 322, 24083, 510, 294, 10754, 4391, 11, 291, 603, 536, 300, 309, 767, 9346], "temperature": 0.0, "avg_logprob": -0.10779126485188802, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.00015562934277113527}, {"id": 315, "seek": 182344, "start": 1823.44, "end": 1831.8400000000001, "text": " simulcast. So here you can see that Simon is 640 by 360 pixels. Whereas this guy here in dandelion,", "tokens": [1034, 425, 3734, 13, 407, 510, 291, 393, 536, 300, 13193, 307, 1386, 5254, 538, 13898, 18668, 13, 13813, 341, 2146, 510, 294, 274, 26406, 313, 11], "temperature": 0.0, "avg_logprob": -0.14463086311633772, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.0003046084602829069}, {"id": 316, "seek": 182344, "start": 1831.8400000000001, "end": 1839.04, "text": " hello dandelion, is 320 by 240. And if I go and zoom embarrassingly, then it should catch up. There", "tokens": [7751, 274, 26406, 313, 11, 307, 42429, 538, 26837, 13, 400, 498, 286, 352, 293, 8863, 9187, 12163, 11, 550, 309, 820, 3745, 493, 13, 821], "temperature": 0.0, "avg_logprob": -0.14463086311633772, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.0003046084602829069}, {"id": 317, "seek": 182344, "start": 1839.04, "end": 1844.64, "text": " we go. 640 by 480. And it's going to renegotiate the higher resolution stream through. And all", "tokens": [321, 352, 13, 1386, 5254, 538, 1017, 4702, 13, 400, 309, 311, 516, 281, 319, 28561, 8206, 473, 264, 2946, 8669, 4309, 807, 13, 400, 439], "temperature": 0.0, "avg_logprob": -0.14463086311633772, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.0003046084602829069}, {"id": 318, "seek": 182344, "start": 1844.64, "end": 1849.76, "text": " the people are going and actually uploading multiple low resolution and high resolution ones.", "tokens": [264, 561, 366, 516, 293, 767, 27301, 3866, 2295, 8669, 293, 1090, 8669, 2306, 13], "temperature": 0.0, "avg_logprob": -0.14463086311633772, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.0003046084602829069}, {"id": 319, "seek": 184976, "start": 1849.76, "end": 1854.56, "text": " So this is very early, but it's the shape of the future for doing proper massive scalable", "tokens": [407, 341, 307, 588, 2440, 11, 457, 309, 311, 264, 3909, 295, 264, 2027, 337, 884, 2296, 5994, 38481], "temperature": 0.0, "avg_logprob": -0.17349483853294737, "compression_ratio": 1.5047923322683705, "no_speech_prob": 0.00011196330160601065}, {"id": 320, "seek": 184976, "start": 1855.6, "end": 1859.52, "text": " SFU based conferences. And that's actually looking good. I'm going to take a quick selfie.", "tokens": [31095, 52, 2361, 22032, 13, 400, 300, 311, 767, 1237, 665, 13, 286, 478, 516, 281, 747, 257, 1702, 22147, 13], "temperature": 0.0, "avg_logprob": -0.17349483853294737, "compression_ratio": 1.5047923322683705, "no_speech_prob": 0.00011196330160601065}, {"id": 321, "seek": 184976, "start": 1859.52, "end": 1864.8, "text": " There we go. Right. Next demo or next stuff. I'm running out of time. I've got a lot of demos.", "tokens": [821, 321, 352, 13, 1779, 13, 3087, 10723, 420, 958, 1507, 13, 286, 478, 2614, 484, 295, 565, 13, 286, 600, 658, 257, 688, 295, 33788, 13], "temperature": 0.0, "avg_logprob": -0.17349483853294737, "compression_ratio": 1.5047923322683705, "no_speech_prob": 0.00011196330160601065}, {"id": 322, "seek": 184976, "start": 1866.0, "end": 1872.32, "text": " OpenID Connect. Matrix is subject to MSE approval. Moving over to OpenID Connect. It rocks and gives", "tokens": [7238, 2777, 11653, 13, 36274, 307, 3983, 281, 376, 5879, 13317, 13, 14242, 670, 281, 7238, 2777, 11653, 13, 467, 10989, 293, 2709], "temperature": 0.0, "avg_logprob": -0.17349483853294737, "compression_ratio": 1.5047923322683705, "no_speech_prob": 0.00011196330160601065}, {"id": 323, "seek": 184976, "start": 1872.32, "end": 1878.08, "text": " us 2FA, multifactorial, pass keys, QR code login. You don't have to implement the weird matrix", "tokens": [505, 568, 19684, 11, 39824, 578, 5181, 11, 1320, 9317, 11, 32784, 3089, 24276, 13, 509, 500, 380, 362, 281, 4445, 264, 3657, 8141], "temperature": 0.0, "avg_logprob": -0.17349483853294737, "compression_ratio": 1.5047923322683705, "no_speech_prob": 0.00011196330160601065}, {"id": 324, "seek": 187808, "start": 1878.08, "end": 1883.1999999999998, "text": " off APIs on the server or the clients anymore. ElementX has native OIDC on iOS already and", "tokens": [766, 21445, 322, 264, 7154, 420, 264, 6982, 3602, 13, 20900, 55, 575, 8470, 422, 2777, 34, 322, 17430, 1217, 293], "temperature": 0.0, "avg_logprob": -0.22576898847307478, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.00023255994892679155}, {"id": 325, "seek": 187808, "start": 1883.1999999999998, "end": 1890.6399999999999, "text": " will be OIDC first. First room is the first OIDC only matrix client. Go to our OIDC yet.com for", "tokens": [486, 312, 422, 2777, 34, 700, 13, 2386, 1808, 307, 264, 700, 422, 2777, 34, 787, 8141, 6423, 13, 1037, 281, 527, 422, 2777, 34, 1939, 13, 1112, 337], "temperature": 0.0, "avg_logprob": -0.22576898847307478, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.00023255994892679155}, {"id": 326, "seek": 187808, "start": 1890.6399999999999, "end": 1898.48, "text": " the gory details. So SigningSync faster joins native VoIP and OIDC is a big change. Like this is", "tokens": [264, 290, 827, 4365, 13, 407, 318, 9676, 50, 34015, 4663, 24397, 8470, 7518, 9139, 293, 422, 2777, 34, 307, 257, 955, 1319, 13, 1743, 341, 307], "temperature": 0.0, "avg_logprob": -0.22576898847307478, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.00023255994892679155}, {"id": 327, "seek": 187808, "start": 1898.48, "end": 1903.36, "text": " fundamentally changing how federation works, how VoIP works, and critically how servers sync data", "tokens": [17879, 4473, 577, 4636, 5053, 1985, 11, 577, 7518, 9139, 1985, 11, 293, 22797, 577, 15909, 20271, 1412], "temperature": 0.0, "avg_logprob": -0.22576898847307478, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.00023255994892679155}, {"id": 328, "seek": 190336, "start": 1903.36, "end": 1908.8799999999999, "text": " to clients, and how you log in. Couldn't be a bigger change. So we are taking the liberty of", "tokens": [281, 6982, 11, 293, 577, 291, 3565, 294, 13, 35800, 380, 312, 257, 3801, 1319, 13, 407, 321, 366, 1940, 264, 22849, 295], "temperature": 0.0, "avg_logprob": -0.19035341321807547, "compression_ratio": 1.5857740585774058, "no_speech_prob": 4.7845700464677066e-05}, {"id": 329, "seek": 190336, "start": 1908.8799999999999, "end": 1914.8799999999999, "text": " declaring it matrix 2.0 when we finally release it. So this is not a breaking change. This is pure", "tokens": [40374, 309, 8141, 568, 13, 15, 562, 321, 2721, 4374, 309, 13, 407, 341, 307, 406, 257, 7697, 1319, 13, 639, 307, 6075], "temperature": 0.0, "avg_logprob": -0.19035341321807547, "compression_ratio": 1.5857740585774058, "no_speech_prob": 4.7845700464677066e-05}, {"id": 330, "seek": 190336, "start": 1914.8799999999999, "end": 1919.36, "text": " enthusiasm basically on my behalf because I think it's worth saying, hey guys, come back to matrix,", "tokens": [23417, 1936, 322, 452, 9490, 570, 286, 519, 309, 311, 3163, 1566, 11, 4177, 1074, 11, 808, 646, 281, 8141, 11], "temperature": 0.0, "avg_logprob": -0.19035341321807547, "compression_ratio": 1.5857740585774058, "no_speech_prob": 4.7845700464677066e-05}, {"id": 331, "seek": 191936, "start": 1919.36, "end": 1933.9199999999998, "text": " give it another go because we fixed all the crap stuff and we're calling it matrix 2.0. Okay,", "tokens": [976, 309, 1071, 352, 570, 321, 6806, 439, 264, 12426, 1507, 293, 321, 434, 5141, 309, 8141, 568, 13, 15, 13, 1033, 11], "temperature": 0.0, "avg_logprob": -0.14694019464346078, "compression_ratio": 1.5378486055776892, "no_speech_prob": 4.072900992468931e-05}, {"id": 332, "seek": 191936, "start": 1933.9199999999998, "end": 1938.6399999999999, "text": " I'm not doing well on time. We're halfway through in theory. We're going to go now to the future.", "tokens": [286, 478, 406, 884, 731, 322, 565, 13, 492, 434, 15461, 807, 294, 5261, 13, 492, 434, 516, 281, 352, 586, 281, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.14694019464346078, "compression_ratio": 1.5378486055776892, "no_speech_prob": 4.072900992468931e-05}, {"id": 333, "seek": 191936, "start": 1938.6399999999999, "end": 1943.28, "text": " Flying cars and jet packs and all that good stuff. First of all, digital markets act. Where we're", "tokens": [34287, 5163, 293, 14452, 19403, 293, 439, 300, 665, 1507, 13, 2386, 295, 439, 11, 4562, 8383, 605, 13, 2305, 321, 434], "temperature": 0.0, "avg_logprob": -0.14694019464346078, "compression_ratio": 1.5378486055776892, "no_speech_prob": 4.072900992468931e-05}, {"id": 334, "seek": 191936, "start": 1943.28, "end": 1948.24, "text": " going, we do not need gatekeepers. If you haven't heard about the DMA, it is a fascinating piece", "tokens": [516, 11, 321, 360, 406, 643, 8539, 43153, 13, 759, 291, 2378, 380, 2198, 466, 264, 413, 9998, 11, 309, 307, 257, 10343, 2522], "temperature": 0.0, "avg_logprob": -0.14694019464346078, "compression_ratio": 1.5378486055776892, "no_speech_prob": 4.072900992468931e-05}, {"id": 335, "seek": 194824, "start": 1948.24, "end": 1953.04, "text": " of legislation that mandates the big tech companies must interoperate together, particularly for", "tokens": [295, 11329, 300, 48662, 264, 955, 7553, 3431, 1633, 728, 7192, 473, 1214, 11, 4098, 337], "temperature": 0.0, "avg_logprob": -0.08639998483185721, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.000511390098836273}, {"id": 336, "seek": 194824, "start": 1953.04, "end": 1957.52, "text": " their communication services. The whole idea is that it empowers users to pick the services they", "tokens": [641, 6101, 3328, 13, 440, 1379, 1558, 307, 300, 309, 4012, 23054, 5022, 281, 1888, 264, 3328, 436], "temperature": 0.0, "avg_logprob": -0.08639998483185721, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.000511390098836273}, {"id": 337, "seek": 194824, "start": 1957.52, "end": 1962.56, "text": " want to use and trust without sacrificing the ability to talk to other people. Now frankly,", "tokens": [528, 281, 764, 293, 3361, 1553, 42294, 264, 3485, 281, 751, 281, 661, 561, 13, 823, 11939, 11], "temperature": 0.0, "avg_logprob": -0.08639998483185721, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.000511390098836273}, {"id": 338, "seek": 194824, "start": 1962.56, "end": 1967.36, "text": " forces the gatekeepers to differentiate based on quality and features, rather than relying on a", "tokens": [5874, 264, 8539, 43153, 281, 23203, 2361, 322, 3125, 293, 4122, 11, 2831, 813, 24140, 322, 257], "temperature": 0.0, "avg_logprob": -0.08639998483185721, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.000511390098836273}, {"id": 339, "seek": 194824, "start": 1967.36, "end": 1972.08, "text": " monopolistic situation where all of their users happen to be trapped in the silo. This is happening", "tokens": [47721, 3142, 2590, 689, 439, 295, 641, 5022, 1051, 281, 312, 14994, 294, 264, 3425, 78, 13, 639, 307, 2737], "temperature": 0.0, "avg_logprob": -0.08639998483185721, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.000511390098836273}, {"id": 340, "seek": 197208, "start": 1972.08, "end": 1980.24, "text": " right now. The rules came into force in November. The rules start to apply in May and then gatekeepers", "tokens": [558, 586, 13, 440, 4474, 1361, 666, 3464, 294, 7674, 13, 440, 4474, 722, 281, 3079, 294, 1891, 293, 550, 8539, 43153], "temperature": 0.0, "avg_logprob": -0.10449561894497025, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.00013947015395388007}, {"id": 341, "seek": 197208, "start": 1980.24, "end": 1987.12, "text": " get designated and it will start getting enforced, which is chunky GDPR style finds in March 2024", "tokens": [483, 21688, 293, 309, 486, 722, 1242, 40953, 11, 597, 307, 45392, 19599, 49, 3758, 10704, 294, 6129, 45237], "temperature": 0.0, "avg_logprob": -0.10449561894497025, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.00013947015395388007}, {"id": 342, "seek": 197208, "start": 1987.12, "end": 1990.32, "text": " if the gatekeepers have not gone and interoperated things together.", "tokens": [498, 264, 8539, 43153, 362, 406, 2780, 293, 728, 7192, 770, 721, 1214, 13], "temperature": 0.0, "avg_logprob": -0.10449561894497025, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.00013947015395388007}, {"id": 343, "seek": 197208, "start": 1991.36, "end": 1995.52, "text": " Turns out the matrix already provides a secure interoperable communication protocol. Who knows?", "tokens": [29524, 484, 264, 8141, 1217, 6417, 257, 7144, 728, 7192, 712, 6101, 10336, 13, 2102, 3255, 30], "temperature": 0.0, "avg_logprob": -0.10449561894497025, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.00013947015395388007}, {"id": 344, "seek": 197208, "start": 1996.56, "end": 2001.76, "text": " The DMA requires the gatekeepers to maintain end-to-end encryption, which is good news. There's", "tokens": [440, 413, 9998, 7029, 264, 8539, 43153, 281, 6909, 917, 12, 1353, 12, 521, 29575, 11, 597, 307, 665, 2583, 13, 821, 311], "temperature": 0.0, "avg_logprob": -0.10449561894497025, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.00013947015395388007}, {"id": 345, "seek": 200176, "start": 2001.76, "end": 2007.2, "text": " been a lot of paranoia that DMA is a secret attack on end-to-end encryption. It really isn't. Having", "tokens": [668, 257, 688, 295, 31416, 654, 300, 413, 9998, 307, 257, 4054, 2690, 322, 917, 12, 1353, 12, 521, 29575, 13, 467, 534, 1943, 380, 13, 10222], "temperature": 0.0, "avg_logprob": -0.09421145531439012, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0003680337395053357}, {"id": 346, "seek": 200176, "start": 2007.2, "end": 2012.96, "text": " spoken to the folks responsible, they really want to make sure that if WhatsApp does E2E today,", "tokens": [10759, 281, 264, 4024, 6250, 11, 436, 534, 528, 281, 652, 988, 300, 498, 30513, 775, 462, 17, 36, 965, 11], "temperature": 0.0, "avg_logprob": -0.09421145531439012, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0003680337395053357}, {"id": 347, "seek": 200176, "start": 2012.96, "end": 2017.52, "text": " then an interoperable WhatsApp also needs to do E2E. They don't want to be responsible for", "tokens": [550, 364, 728, 7192, 712, 30513, 611, 2203, 281, 360, 462, 17, 36, 13, 814, 500, 380, 528, 281, 312, 6250, 337], "temperature": 0.0, "avg_logprob": -0.09421145531439012, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0003680337395053357}, {"id": 348, "seek": 200176, "start": 2017.52, "end": 2022.96, "text": " destroying privacy. So to re-encrypt, you need to either do it on the client side, so you would", "tokens": [19926, 11427, 13, 407, 281, 319, 12, 22660, 627, 662, 11, 291, 643, 281, 2139, 360, 309, 322, 264, 6423, 1252, 11, 370, 291, 576], "temperature": 0.0, "avg_logprob": -0.09421145531439012, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0003680337395053357}, {"id": 349, "seek": 200176, "start": 2022.96, "end": 2026.8799999999999, "text": " install something like a WhatsApp to matrix app if you want to link your WhatsApp account into", "tokens": [3625, 746, 411, 257, 30513, 281, 8141, 724, 498, 291, 528, 281, 2113, 428, 30513, 2696, 666], "temperature": 0.0, "avg_logprob": -0.09421145531439012, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0003680337395053357}, {"id": 350, "seek": 202688, "start": 2026.88, "end": 2032.4, "text": " matrix, or you could do a multi-head approach effectively, open APIs and have your app talk", "tokens": [8141, 11, 420, 291, 727, 360, 257, 4825, 12, 1934, 3109, 8659, 11, 1269, 21445, 293, 362, 428, 724, 751], "temperature": 0.0, "avg_logprob": -0.14309470767066593, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.00012209810665808618}, {"id": 351, "seek": 202688, "start": 2032.4, "end": 2037.2800000000002, "text": " to WhatsApp as well as matrix or whatever. Or everybody ends up talking the same protocol,", "tokens": [281, 30513, 382, 731, 382, 8141, 420, 2035, 13, 1610, 2201, 5314, 493, 1417, 264, 912, 10336, 11], "temperature": 0.0, "avg_logprob": -0.14309470767066593, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.00012209810665808618}, {"id": 352, "seek": 202688, "start": 2037.2800000000002, "end": 2041.7600000000002, "text": " which means on the server side, the gatekeepers would have to add support for matrix or XNPP", "tokens": [597, 1355, 322, 264, 7154, 1252, 11, 264, 8539, 43153, 576, 362, 281, 909, 1406, 337, 8141, 420, 1783, 45, 17755], "temperature": 0.0, "avg_logprob": -0.14309470767066593, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.00012209810665808618}, {"id": 353, "seek": 202688, "start": 2041.7600000000002, "end": 2047.2, "text": " or RCS or whatever it might be alongside their somewhat legacy proprietary protocol.", "tokens": [420, 497, 26283, 420, 2035, 309, 1062, 312, 12385, 641, 8344, 11711, 38992, 10336, 13], "temperature": 0.0, "avg_logprob": -0.14309470767066593, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.00012209810665808618}, {"id": 354, "seek": 202688, "start": 2047.2, "end": 2052.08, "text": " ITF is established a working group called MIMI, more instant messaging interoperability targeting", "tokens": [6783, 37, 307, 7545, 257, 1364, 1594, 1219, 376, 6324, 40, 11, 544, 9836, 21812, 728, 7192, 2310, 17918], "temperature": 0.0, "avg_logprob": -0.14309470767066593, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.00012209810665808618}, {"id": 355, "seek": 205208, "start": 2052.08, "end": 2057.6, "text": " the everybody talks the same protocol approach. We've proposed matrix as an ITF draft for content", "tokens": [264, 2201, 6686, 264, 912, 10336, 3109, 13, 492, 600, 10348, 8141, 382, 364, 6783, 37, 11206, 337, 2701], "temperature": 0.0, "avg_logprob": -0.11375970288741687, "compression_ratio": 1.6334519572953736, "no_speech_prob": 6.658537313342094e-05}, {"id": 356, "seek": 205208, "start": 2057.6, "end": 2061.6, "text": " and transport layers, and we're trying to work with them to make the most of the mix.", "tokens": [293, 5495, 7914, 11, 293, 321, 434, 1382, 281, 589, 365, 552, 281, 652, 264, 881, 295, 264, 2890, 13], "temperature": 0.0, "avg_logprob": -0.11375970288741687, "compression_ratio": 1.6334519572953736, "no_speech_prob": 6.658537313342094e-05}, {"id": 357, "seek": 205208, "start": 2063.2799999999997, "end": 2067.52, "text": " Decentralized MLS, this is another big thing where we're going, we don't need salamanders,", "tokens": [1346, 2207, 2155, 1602, 376, 19198, 11, 341, 307, 1071, 955, 551, 689, 321, 434, 516, 11, 321, 500, 380, 643, 1845, 335, 41430, 11], "temperature": 0.0, "avg_logprob": -0.11375970288741687, "compression_ratio": 1.6334519572953736, "no_speech_prob": 6.658537313342094e-05}, {"id": 358, "seek": 205208, "start": 2067.52, "end": 2072.7999999999997, "text": " because if you haven't noticed, all of the encryption historically have been called axolotl", "tokens": [570, 498, 291, 2378, 380, 5694, 11, 439, 295, 264, 29575, 16180, 362, 668, 1219, 6360, 401, 310, 75], "temperature": 0.0, "avg_logprob": -0.11375970288741687, "compression_ratio": 1.6334519572953736, "no_speech_prob": 6.658537313342094e-05}, {"id": 359, "seek": 205208, "start": 2072.7999999999997, "end": 2079.84, "text": " or ohm or proteus, all of which are species of salamander. MLS is another ITF working group,", "tokens": [420, 1954, 76, 420, 5631, 301, 11, 439, 295, 597, 366, 6172, 295, 1845, 335, 4483, 13, 376, 19198, 307, 1071, 6783, 37, 1364, 1594, 11], "temperature": 0.0, "avg_logprob": -0.11375970288741687, "compression_ratio": 1.6334519572953736, "no_speech_prob": 6.658537313342094e-05}, {"id": 360, "seek": 207984, "start": 2079.84, "end": 2084.1600000000003, "text": " in fact the one from which MIMI has emerged for next generation end-to-end encryption.", "tokens": [294, 1186, 264, 472, 490, 597, 376, 6324, 40, 575, 20178, 337, 958, 5125, 917, 12, 1353, 12, 521, 29575, 13], "temperature": 0.0, "avg_logprob": -0.14328650177502242, "compression_ratio": 1.573943661971831, "no_speech_prob": 3.61769889423158e-05}, {"id": 361, "seek": 207984, "start": 2085.04, "end": 2089.92, "text": " We have figured out how to make MLS work in a decentralized model. We have implemented it", "tokens": [492, 362, 8932, 484, 577, 281, 652, 376, 19198, 589, 294, 257, 32870, 2316, 13, 492, 362, 12270, 309], "temperature": 0.0, "avg_logprob": -0.14328650177502242, "compression_ratio": 1.573943661971831, "no_speech_prob": 3.61769889423158e-05}, {"id": 362, "seek": 207984, "start": 2089.92, "end": 2094.6400000000003, "text": " in a toy type script stack called MLSTS. It is currently being re-implemented on top of", "tokens": [294, 257, 12058, 2010, 5755, 8630, 1219, 376, 19198, 7327, 13, 467, 307, 4362, 885, 319, 12, 332, 781, 14684, 322, 1192, 295], "temperature": 0.0, "avg_logprob": -0.14328650177502242, "compression_ratio": 1.573943661971831, "no_speech_prob": 3.61769889423158e-05}, {"id": 363, "seek": 207984, "start": 2094.6400000000003, "end": 2099.6000000000004, "text": " open MLS and Rust. At which point, when it works, we will integrate it into Rust SDK and build it", "tokens": [1269, 376, 19198, 293, 34952, 13, 1711, 597, 935, 11, 562, 309, 1985, 11, 321, 486, 13365, 309, 666, 34952, 37135, 293, 1322, 309], "temperature": 0.0, "avg_logprob": -0.14328650177502242, "compression_ratio": 1.573943661971831, "no_speech_prob": 3.61769889423158e-05}, {"id": 364, "seek": 207984, "start": 2099.6000000000004, "end": 2105.1200000000003, "text": " into real clients and write an MSE. Are we MLS yet dot com for all the gory details?", "tokens": [666, 957, 6982, 293, 2464, 364, 376, 5879, 13, 2014, 321, 376, 19198, 1939, 5893, 395, 337, 439, 264, 290, 827, 4365, 30], "temperature": 0.0, "avg_logprob": -0.14328650177502242, "compression_ratio": 1.573943661971831, "no_speech_prob": 3.61769889423158e-05}, {"id": 365, "seek": 210512, "start": 2105.12, "end": 2111.7599999999998, "text": " Here are some early performance testing, which is pretty interesting. Let me get the key right", "tokens": [1692, 366, 512, 2440, 3389, 4997, 11, 597, 307, 1238, 1880, 13, 961, 385, 483, 264, 2141, 558], "temperature": 0.0, "avg_logprob": -0.17293526498894943, "compression_ratio": 1.5611814345991561, "no_speech_prob": 8.005089330254123e-05}, {"id": 366, "seek": 210512, "start": 2111.7599999999998, "end": 2116.72, "text": " for you here. If you look at MEGOM creating new sessions, this is obviously the log log scale", "tokens": [337, 291, 510, 13, 759, 291, 574, 412, 12003, 38, 5251, 4084, 777, 11081, 11, 341, 307, 2745, 264, 3565, 3565, 4373], "temperature": 0.0, "avg_logprob": -0.17293526498894943, "compression_ratio": 1.5611814345991561, "no_speech_prob": 8.005089330254123e-05}, {"id": 367, "seek": 210512, "start": 2116.72, "end": 2122.24, "text": " for all of you mathematicians. You can see this red dashed line here, showing how MEGOM", "tokens": [337, 439, 295, 291, 32811, 2567, 13, 509, 393, 536, 341, 2182, 8240, 292, 1622, 510, 11, 4099, 577, 12003, 38, 5251], "temperature": 0.0, "avg_logprob": -0.17293526498894943, "compression_ratio": 1.5611814345991561, "no_speech_prob": 8.005089330254123e-05}, {"id": 368, "seek": 210512, "start": 2122.24, "end": 2128.72, "text": " sessions scale with a number of users, and it's up at 100 seconds if you've got 100,000 users", "tokens": [11081, 4373, 365, 257, 1230, 295, 5022, 11, 293, 309, 311, 493, 412, 2319, 3949, 498, 291, 600, 658, 2319, 11, 1360, 5022], "temperature": 0.0, "avg_logprob": -0.17293526498894943, "compression_ratio": 1.5611814345991561, "no_speech_prob": 8.005089330254123e-05}, {"id": 369, "seek": 212872, "start": 2128.72, "end": 2136.56, "text": " in the room, which is pretty slow. However, if you look at an MLS update or adding new members,", "tokens": [294, 264, 1808, 11, 597, 307, 1238, 2964, 13, 2908, 11, 498, 291, 574, 412, 364, 376, 19198, 5623, 420, 5127, 777, 2679, 11], "temperature": 0.0, "avg_logprob": -0.17513008117675782, "compression_ratio": 1.4596774193548387, "no_speech_prob": 0.00011708794045262039}, {"id": 370, "seek": 212872, "start": 2136.56, "end": 2141.2799999999997, "text": " then they're down at 1,000 milliseconds, so a couple of seconds. This is a major", "tokens": [550, 436, 434, 760, 412, 502, 11, 1360, 34184, 11, 370, 257, 1916, 295, 3949, 13, 639, 307, 257, 2563], "temperature": 0.0, "avg_logprob": -0.17513008117675782, "compression_ratio": 1.4596774193548387, "no_speech_prob": 0.00011708794045262039}, {"id": 371, "seek": 212872, "start": 2141.2799999999997, "end": 2146.8799999999997, "text": " algorithmic improvement for certain operations over even VODOSMATS. Support of VODOSMATS,", "tokens": [9284, 299, 10444, 337, 1629, 7705, 670, 754, 691, 14632, 4367, 44, 2218, 50, 13, 18073, 295, 691, 14632, 4367, 44, 2218, 50, 11], "temperature": 0.0, "avg_logprob": -0.17513008117675782, "compression_ratio": 1.4596774193548387, "no_speech_prob": 0.00011708794045262039}, {"id": 372, "seek": 212872, "start": 2146.8799999999997, "end": 2154.08, "text": " which feels relatively new, may get displaced by open MLS and DMLS when we get there, hopefully", "tokens": [597, 3417, 7226, 777, 11, 815, 483, 33692, 538, 1269, 376, 19198, 293, 413, 12683, 50, 562, 321, 483, 456, 11, 4696], "temperature": 0.0, "avg_logprob": -0.17513008117675782, "compression_ratio": 1.4596774193548387, "no_speech_prob": 0.00011708794045262039}, {"id": 373, "seek": 215408, "start": 2154.08, "end": 2160.0, "text": " later this year. In peer-to-peer matrix, where we're going, we don't need servers. Matrix is way", "tokens": [1780, 341, 1064, 13, 682, 15108, 12, 1353, 12, 494, 260, 8141, 11, 689, 321, 434, 516, 11, 321, 500, 380, 643, 15909, 13, 36274, 307, 636], "temperature": 0.0, "avg_logprob": -0.11892208745402674, "compression_ratio": 1.7416974169741697, "no_speech_prob": 5.5325275752693415e-05}, {"id": 374, "seek": 215408, "start": 2160.0, "end": 2165.12, "text": " too dependent on servers, and the admins and the risks of internet shutdowns and censorship.", "tokens": [886, 12334, 322, 15909, 11, 293, 264, 5910, 1292, 293, 264, 10888, 295, 4705, 34927, 82, 293, 40985, 13], "temperature": 0.0, "avg_logprob": -0.11892208745402674, "compression_ratio": 1.7416974169741697, "no_speech_prob": 5.5325275752693415e-05}, {"id": 375, "seek": 215408, "start": 2165.12, "end": 2169.36, "text": " This is because home servers have to store their users' chat history and metadata. Peer-to-peer", "tokens": [639, 307, 570, 1280, 15909, 362, 281, 3531, 641, 5022, 6, 5081, 2503, 293, 26603, 13, 2396, 260, 12, 1353, 12, 494, 260], "temperature": 0.0, "avg_logprob": -0.11892208745402674, "compression_ratio": 1.7416974169741697, "no_speech_prob": 5.5325275752693415e-05}, {"id": 376, "seek": 215408, "start": 2169.36, "end": 2177.04, "text": " matrix exists to fix this. This is a long-running blue sky project, so to speak, where we go and", "tokens": [8141, 8198, 281, 3191, 341, 13, 639, 307, 257, 938, 12, 45482, 3344, 5443, 1716, 11, 370, 281, 1710, 11, 689, 321, 352, 293], "temperature": 0.0, "avg_logprob": -0.11892208745402674, "compression_ratio": 1.7416974169741697, "no_speech_prob": 5.5325275752693415e-05}, {"id": 377, "seek": 215408, "start": 2177.04, "end": 2182.3199999999997, "text": " embed your home server inside the app in order to not have a server running in the cloud.", "tokens": [12240, 428, 1280, 7154, 1854, 264, 724, 294, 1668, 281, 406, 362, 257, 7154, 2614, 294, 264, 4588, 13], "temperature": 0.0, "avg_logprob": -0.11892208745402674, "compression_ratio": 1.7416974169741697, "no_speech_prob": 5.5325275752693415e-05}, {"id": 378, "seek": 218232, "start": 2182.32, "end": 2189.04, "text": " Dendrite is the server we use. Big news on Dendrite is, as of a few weeks ago, it passes 100%", "tokens": [413, 521, 35002, 307, 264, 7154, 321, 764, 13, 5429, 2583, 322, 413, 521, 35002, 307, 11, 382, 295, 257, 1326, 3259, 2057, 11, 309, 11335, 2319, 4], "temperature": 0.0, "avg_logprob": -0.15696993580570928, "compression_ratio": 1.516, "no_speech_prob": 0.0001534550974611193}, {"id": 379, "seek": 218232, "start": 2189.04, "end": 2195.1200000000003, "text": " server API compliance, so it has a parity of a good old Synapse, and 93% client server API,", "tokens": [7154, 9362, 15882, 11, 370, 309, 575, 257, 44747, 295, 257, 665, 1331, 26155, 11145, 11, 293, 28876, 4, 6423, 7154, 9362, 11], "temperature": 0.0, "avg_logprob": -0.15696993580570928, "compression_ratio": 1.516, "no_speech_prob": 0.0001534550974611193}, {"id": 380, "seek": 218232, "start": 2195.1200000000003, "end": 2199.92, "text": " and the 7% is boring stuff we don't really care about for this. Pinecone, the peer-to-peer overlay", "tokens": [293, 264, 1614, 4, 307, 9989, 1507, 321, 500, 380, 534, 1127, 466, 337, 341, 13, 33531, 66, 546, 11, 264, 15108, 12, 1353, 12, 494, 260, 31741], "temperature": 0.0, "avg_logprob": -0.15696993580570928, "compression_ratio": 1.516, "no_speech_prob": 0.0001534550974611193}, {"id": 381, "seek": 218232, "start": 2199.92, "end": 2206.0800000000004, "text": " network, is going really well as well. We just switched to soft state routing for reliability,", "tokens": [3209, 11, 307, 516, 534, 731, 382, 731, 13, 492, 445, 16858, 281, 2787, 1785, 32722, 337, 24550, 11], "temperature": 0.0, "avg_logprob": -0.15696993580570928, "compression_ratio": 1.516, "no_speech_prob": 0.0001534550974611193}, {"id": 382, "seek": 220608, "start": 2206.08, "end": 2212.72, "text": " and as of about 4 a.m. this morning, not me. Initial store and forward relaying is here.", "tokens": [293, 382, 295, 466, 1017, 257, 13, 76, 13, 341, 2446, 11, 406, 385, 13, 22937, 831, 3531, 293, 2128, 24214, 278, 307, 510, 13], "temperature": 0.0, "avg_logprob": -0.15464436026180492, "compression_ratio": 1.5, "no_speech_prob": 0.00014443490363191813}, {"id": 383, "seek": 220608, "start": 2212.72, "end": 2222.96, "text": " I will very rapidly try to demo that. That's still my phone there. If I go and launch Peer-to-peer", "tokens": [286, 486, 588, 12910, 853, 281, 10723, 300, 13, 663, 311, 920, 452, 2593, 456, 13, 759, 286, 352, 293, 4025, 2396, 260, 12, 1353, 12, 494, 260], "temperature": 0.0, "avg_logprob": -0.15464436026180492, "compression_ratio": 1.5, "no_speech_prob": 0.00014443490363191813}, {"id": 384, "seek": 220608, "start": 2222.96, "end": 2228.88, "text": " matrix, Dendrite is not running. Now it is running. This has literally got a Dendrite running inside", "tokens": [8141, 11, 413, 521, 35002, 307, 406, 2614, 13, 823, 309, 307, 2614, 13, 639, 575, 3736, 658, 257, 413, 521, 35002, 2614, 1854], "temperature": 0.0, "avg_logprob": -0.15464436026180492, "compression_ratio": 1.5, "no_speech_prob": 0.00014443490363191813}, {"id": 385, "seek": 222888, "start": 2228.88, "end": 2236.88, "text": " my phone here, and if I go over to Visor here, I should hopefully also be able to run it on", "tokens": [452, 2593, 510, 11, 293, 498, 286, 352, 670, 281, 10410, 284, 510, 11, 286, 820, 4696, 611, 312, 1075, 281, 1190, 309, 322], "temperature": 0.0, "avg_logprob": -0.21235860780228016, "compression_ratio": 1.521505376344086, "no_speech_prob": 5.705860530724749e-05}, {"id": 386, "seek": 222888, "start": 2239.2000000000003, "end": 2246.48, "text": " my Android thing. Here it is, and did it already crash? So it is a bit crashy. It is still beta.", "tokens": [452, 8853, 551, 13, 1692, 309, 307, 11, 293, 630, 309, 1217, 8252, 30, 407, 309, 307, 257, 857, 8252, 88, 13, 467, 307, 920, 9861, 13], "temperature": 0.0, "avg_logprob": -0.21235860780228016, "compression_ratio": 1.521505376344086, "no_speech_prob": 5.705860530724749e-05}, {"id": 387, "seek": 222888, "start": 2247.6800000000003, "end": 2253.6, "text": " I've got Fosdom demo here, Fosdom demo here, and slightly, okay, when I first say hello there,", "tokens": [286, 600, 658, 479, 329, 4121, 10723, 510, 11, 479, 329, 4121, 10723, 510, 11, 293, 4748, 11, 1392, 11, 562, 286, 700, 584, 7751, 456, 11], "temperature": 0.0, "avg_logprob": -0.21235860780228016, "compression_ratio": 1.521505376344086, "no_speech_prob": 5.705860530724749e-05}, {"id": 388, "seek": 225360, "start": 2253.6, "end": 2259.12, "text": " then you can see yay, messages flowing back and forth peer-to-peer. Now if I take my iPhone", "tokens": [550, 291, 393, 536, 23986, 11, 7897, 13974, 646, 293, 5220, 15108, 12, 1353, 12, 494, 260, 13, 823, 498, 286, 747, 452, 7252], "temperature": 0.0, "avg_logprob": -0.14152605455000322, "compression_ratio": 1.6045454545454545, "no_speech_prob": 5.887505176360719e-05}, {"id": 389, "seek": 225360, "start": 2259.12, "end": 2263.6, "text": " and put it on to airplane mode like so, and send some messages through from Android,", "tokens": [293, 829, 309, 322, 281, 17130, 4391, 411, 370, 11, 293, 2845, 512, 7897, 807, 490, 8853, 11], "temperature": 0.0, "avg_logprob": -0.14152605455000322, "compression_ratio": 1.6045454545454545, "no_speech_prob": 5.887505176360719e-05}, {"id": 390, "seek": 225360, "start": 2263.6, "end": 2269.04, "text": " they still go. So this is Peer-to-peer matrix running over Bluetooth flow energy.", "tokens": [436, 920, 352, 13, 407, 341, 307, 2396, 260, 12, 1353, 12, 494, 260, 8141, 2614, 670, 20286, 3095, 2281, 13], "temperature": 0.0, "avg_logprob": -0.14152605455000322, "compression_ratio": 1.6045454545454545, "no_speech_prob": 5.887505176360719e-05}, {"id": 391, "seek": 225360, "start": 2269.04, "end": 2275.12, "text": " It silently fell over from running over IP into Bluetooth mode. Now the exciting thing is that", "tokens": [467, 40087, 5696, 670, 490, 2614, 670, 8671, 666, 20286, 4391, 13, 823, 264, 4670, 551, 307, 300], "temperature": 0.0, "avg_logprob": -0.14152605455000322, "compression_ratio": 1.6045454545454545, "no_speech_prob": 5.887505176360719e-05}, {"id": 392, "seek": 227512, "start": 2275.12, "end": 2289.04, "text": " if I also run... Well, this is going to be an interesting demo. So here is Element Peer-to-peer", "tokens": [498, 286, 611, 1190, 485, 1042, 11, 341, 307, 516, 281, 312, 364, 1880, 10723, 13, 407, 510, 307, 20900, 2396, 260, 12, 1353, 12, 494, 260], "temperature": 0.0, "avg_logprob": -0.1406155300140381, "compression_ratio": 1.5269709543568464, "no_speech_prob": 3.504414053168148e-05}, {"id": 393, "seek": 227512, "start": 2289.04, "end": 2293.44, "text": " running in iOS or macOS, because you can do that on an M1 Mac, and apparently there are five", "tokens": [2614, 294, 17430, 420, 7912, 4367, 11, 570, 291, 393, 360, 300, 322, 364, 376, 16, 5707, 11, 293, 7970, 456, 366, 1732], "temperature": 0.0, "avg_logprob": -0.1406155300140381, "compression_ratio": 1.5269709543568464, "no_speech_prob": 3.504414053168148e-05}, {"id": 394, "seek": 227512, "start": 2293.44, "end": 2297.2, "text": " connected peers, which is three more than I was expecting, so hello everybody out there who's", "tokens": [4582, 16739, 11, 597, 307, 1045, 544, 813, 286, 390, 9650, 11, 370, 7751, 2201, 484, 456, 567, 311], "temperature": 0.0, "avg_logprob": -0.1406155300140381, "compression_ratio": 1.5269709543568464, "no_speech_prob": 3.504414053168148e-05}, {"id": 395, "seek": 227512, "start": 2297.2, "end": 2302.08, "text": " about to screw up my demo, and you can see the same history coming on here, and I can", "tokens": [466, 281, 5630, 493, 452, 10723, 11, 293, 291, 393, 536, 264, 912, 2503, 1348, 322, 510, 11, 293, 286, 393], "temperature": 0.0, "avg_logprob": -0.1406155300140381, "compression_ratio": 1.5269709543568464, "no_speech_prob": 3.504414053168148e-05}, {"id": 396, "seek": 230208, "start": 2302.08, "end": 2307.36, "text": " send a message through, and you can see both on iOS it came through on Android too. Now the really", "tokens": [2845, 257, 3636, 807, 11, 293, 291, 393, 536, 1293, 322, 17430, 309, 1361, 807, 322, 8853, 886, 13, 823, 264, 534], "temperature": 0.0, "avg_logprob": -0.1312780201992142, "compression_ratio": 1.737556561085973, "no_speech_prob": 6.766244769096375e-05}, {"id": 397, "seek": 230208, "start": 2307.36, "end": 2316.56, "text": " interesting thing is if I go and... Now you are going to screw up my demo. If I go and kill the", "tokens": [1880, 551, 307, 498, 286, 352, 293, 485, 823, 291, 366, 516, 281, 5630, 493, 452, 10723, 13, 759, 286, 352, 293, 1961, 264], "temperature": 0.0, "avg_logprob": -0.1312780201992142, "compression_ratio": 1.737556561085973, "no_speech_prob": 6.766244769096375e-05}, {"id": 398, "seek": 230208, "start": 2316.56, "end": 2325.2, "text": " Peer-to-peer app on Android, and I send a message here saying hello relaying, and actually not in", "tokens": [2396, 260, 12, 1353, 12, 494, 260, 724, 322, 8853, 11, 293, 286, 2845, 257, 3636, 510, 1566, 7751, 24214, 278, 11, 293, 767, 406, 294], "temperature": 0.0, "avg_logprob": -0.1312780201992142, "compression_ratio": 1.737556561085973, "no_speech_prob": 6.766244769096375e-05}, {"id": 399, "seek": 230208, "start": 2325.2, "end": 2329.7599999999998, "text": " that room, I'm going to do it in my DM through to Android. I'm going to say testing relays,", "tokens": [300, 1808, 11, 286, 478, 516, 281, 360, 309, 294, 452, 15322, 807, 281, 8853, 13, 286, 478, 516, 281, 584, 4997, 1039, 3772, 11], "temperature": 0.0, "avg_logprob": -0.1312780201992142, "compression_ratio": 1.737556561085973, "no_speech_prob": 6.766244769096375e-05}, {"id": 400, "seek": 232976, "start": 2329.76, "end": 2339.36, "text": " or very badly typed, and critically my... Where has it gone? Has it crashed? No, there is. So I'm", "tokens": [420, 588, 13425, 33941, 11, 293, 22797, 452, 485, 2305, 575, 309, 2780, 30, 8646, 309, 24190, 30, 883, 11, 456, 307, 13, 407, 286, 478], "temperature": 0.0, "avg_logprob": -0.14992531334481587, "compression_ratio": 1.5, "no_speech_prob": 5.5396139941876754e-05}, {"id": 401, "seek": 232976, "start": 2339.36, "end": 2344.96, "text": " not actually in that room. I'm only in one room on my Mac here. However, this hopefully has gone", "tokens": [406, 767, 294, 300, 1808, 13, 286, 478, 787, 294, 472, 1808, 322, 452, 5707, 510, 13, 2908, 11, 341, 4696, 575, 2780], "temperature": 0.0, "avg_logprob": -0.14992531334481587, "compression_ratio": 1.5, "no_speech_prob": 5.5396139941876754e-05}, {"id": 402, "seek": 232976, "start": 2344.96, "end": 2351.84, "text": " and peered, relayed through to my Android phone. So if I now go and kill the app here on iOS,", "tokens": [293, 520, 4073, 11, 24214, 292, 807, 281, 452, 8853, 2593, 13, 407, 498, 286, 586, 352, 293, 1961, 264, 724, 510, 322, 17430, 11], "temperature": 0.0, "avg_logprob": -0.14992531334481587, "compression_ratio": 1.5, "no_speech_prob": 5.5396139941876754e-05}, {"id": 403, "seek": 235184, "start": 2351.84, "end": 2363.44, "text": " and relaunch it here on Android, if I knew how to use Android, come on. This is going to work,", "tokens": [293, 5195, 1680, 309, 510, 322, 8853, 11, 498, 286, 2586, 577, 281, 764, 8853, 11, 808, 322, 13, 639, 307, 516, 281, 589, 11], "temperature": 0.0, "avg_logprob": -0.20732184987009308, "compression_ratio": 1.4922279792746114, "no_speech_prob": 3.386967728147283e-05}, {"id": 404, "seek": 235184, "start": 2363.44, "end": 2369.28, "text": " or is it going to search Google? There it is. Perfect. Hopefully the first thing this thing will do", "tokens": [420, 307, 309, 516, 281, 3164, 3329, 30, 821, 309, 307, 13, 10246, 13, 10429, 264, 700, 551, 341, 551, 486, 360], "temperature": 0.0, "avg_logprob": -0.20732184987009308, "compression_ratio": 1.4922279792746114, "no_speech_prob": 3.386967728147283e-05}, {"id": 405, "seek": 235184, "start": 2370.0, "end": 2375.52, "text": " is to... I'm in the wrong room. If Dendrite launches, the red bar is telling me that it can't", "tokens": [307, 281, 485, 286, 478, 294, 264, 2085, 1808, 13, 759, 413, 521, 35002, 31841, 11, 264, 2182, 2159, 307, 3585, 385, 300, 309, 393, 380], "temperature": 0.0, "avg_logprob": -0.20732184987009308, "compression_ratio": 1.4922279792746114, "no_speech_prob": 3.386967728147283e-05}, {"id": 406, "seek": 237552, "start": 2375.52, "end": 2388.88, "text": " tell and talk to its own Dendrite. You can do it. Yes! Testing relaying. This is huge because", "tokens": [980, 293, 751, 281, 1080, 1065, 413, 521, 35002, 13, 509, 393, 360, 309, 13, 1079, 0, 45517, 24214, 278, 13, 639, 307, 2603, 570], "temperature": 0.0, "avg_logprob": -0.1550198197364807, "compression_ratio": 1.5313807531380754, "no_speech_prob": 7.4941803177353e-05}, {"id": 407, "seek": 237552, "start": 2390.48, "end": 2394.24, "text": " historically Peer-to-peer matrix has had a massive problem that the other guy has to be online", "tokens": [16180, 2396, 260, 12, 1353, 12, 494, 260, 8141, 575, 632, 257, 5994, 1154, 300, 264, 661, 2146, 575, 281, 312, 2950], "temperature": 0.0, "avg_logprob": -0.1550198197364807, "compression_ratio": 1.5313807531380754, "no_speech_prob": 7.4941803177353e-05}, {"id": 408, "seek": 237552, "start": 2394.24, "end": 2401.52, "text": " running the app at the same time. And a long story, but I ended up on an aircraft carrier", "tokens": [2614, 264, 724, 412, 264, 912, 565, 13, 400, 257, 938, 1657, 11, 457, 286, 4590, 493, 322, 364, 9465, 17574], "temperature": 0.0, "avg_logprob": -0.1550198197364807, "compression_ratio": 1.5313807531380754, "no_speech_prob": 7.4941803177353e-05}, {"id": 409, "seek": 237552, "start": 2401.52, "end": 2404.88, "text": " a couple of months ago going and trying to explain a bunch of people how they could use", "tokens": [257, 1916, 295, 2493, 2057, 516, 293, 1382, 281, 2903, 257, 3840, 295, 561, 577, 436, 727, 764], "temperature": 0.0, "avg_logprob": -0.1550198197364807, "compression_ratio": 1.5313807531380754, "no_speech_prob": 7.4941803177353e-05}, {"id": 410, "seek": 240488, "start": 2404.88, "end": 2408.6400000000003, "text": " matrix in that environment. And there are a bunch of us on board this thing. And it turns out that", "tokens": [8141, 294, 300, 2823, 13, 400, 456, 366, 257, 3840, 295, 505, 322, 3150, 341, 551, 13, 400, 309, 4523, 484, 300], "temperature": 0.0, "avg_logprob": -0.11280328285794299, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.00032130040926858783}, {"id": 411, "seek": 240488, "start": 2408.6400000000003, "end": 2414.1600000000003, "text": " an aircraft carrier is a massive floating Faraday cage. And we went and fired up Peer-to-peer", "tokens": [364, 9465, 17574, 307, 257, 5994, 12607, 9067, 345, 320, 17302, 13, 400, 321, 1437, 293, 11777, 493, 2396, 260, 12, 1353, 12, 494, 260], "temperature": 0.0, "avg_logprob": -0.11280328285794299, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.00032130040926858783}, {"id": 412, "seek": 240488, "start": 2414.1600000000003, "end": 2419.76, "text": " matrix on it. And we're very smart that we can talk to one another, but you had to physically", "tokens": [8141, 322, 309, 13, 400, 321, 434, 588, 4069, 300, 321, 393, 751, 281, 472, 1071, 11, 457, 291, 632, 281, 9762], "temperature": 0.0, "avg_logprob": -0.11280328285794299, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.00032130040926858783}, {"id": 413, "seek": 240488, "start": 2419.76, "end": 2423.6800000000003, "text": " wave at the other guy to get them to launch the app so they could receive the message.", "tokens": [5772, 412, 264, 661, 2146, 281, 483, 552, 281, 4025, 264, 724, 370, 436, 727, 4774, 264, 3636, 13], "temperature": 0.0, "avg_logprob": -0.11280328285794299, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.00032130040926858783}, {"id": 414, "seek": 240488, "start": 2423.6800000000003, "end": 2427.6, "text": " Whereas with a relay, you can obviously talk to them even if the app isn't running.", "tokens": [13813, 365, 257, 24214, 11, 291, 393, 2745, 751, 281, 552, 754, 498, 264, 724, 1943, 380, 2614, 13], "temperature": 0.0, "avg_logprob": -0.11280328285794299, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.00032130040926858783}, {"id": 415, "seek": 242760, "start": 2427.6, "end": 2434.96, "text": " So that's big. Right. We're almost there. Matrix is not just for chat and VoIP. This is", "tokens": [407, 300, 311, 955, 13, 1779, 13, 492, 434, 1920, 456, 13, 36274, 307, 406, 445, 337, 5081, 293, 7518, 9139, 13, 639, 307], "temperature": 0.0, "avg_logprob": -0.19069890975952147, "compression_ratio": 1.6161971830985915, "no_speech_prob": 8.786052785580978e-05}, {"id": 416, "seek": 242760, "start": 2434.96, "end": 2440.72, "text": " the final thing. Third Room is a decentralized consular for, well, matrix is a consular for", "tokens": [264, 2572, 551, 13, 12548, 19190, 307, 257, 32870, 1014, 1040, 337, 11, 731, 11, 8141, 307, 257, 1014, 1040, 337], "temperature": 0.0, "avg_logprob": -0.19069890975952147, "compression_ratio": 1.6161971830985915, "no_speech_prob": 8.786052785580978e-05}, {"id": 417, "seek": 242760, "start": 2440.72, "end": 2445.8399999999997, "text": " any kind of real-time data. Third Room is this tiny project done by Robert May and AJ to provide", "tokens": [604, 733, 295, 957, 12, 3766, 1412, 13, 12548, 19190, 307, 341, 5870, 1716, 1096, 538, 7977, 1891, 293, 32759, 281, 2893], "temperature": 0.0, "avg_logprob": -0.19069890975952147, "compression_ratio": 1.6161971830985915, "no_speech_prob": 8.786052785580978e-05}, {"id": 418, "seek": 242760, "start": 2445.8399999999997, "end": 2450.16, "text": " an open decentralized platform for spatial collaboration of any kind built on matrix.", "tokens": [364, 1269, 32870, 3663, 337, 23598, 9363, 295, 604, 733, 3094, 322, 8141, 13], "temperature": 0.0, "avg_logprob": -0.19069890975952147, "compression_ratio": 1.6161971830985915, "no_speech_prob": 8.786052785580978e-05}, {"id": 419, "seek": 242760, "start": 2450.16, "end": 2455.2799999999997, "text": " It uses hydrogen, 3JS, bit ECS, and rapier for a new engine called manifold. And the idea is you", "tokens": [467, 4960, 12697, 11, 805, 41, 50, 11, 857, 19081, 50, 11, 293, 5099, 811, 337, 257, 777, 2848, 1219, 47138, 13, 400, 264, 1558, 307, 291], "temperature": 0.0, "avg_logprob": -0.19069890975952147, "compression_ratio": 1.6161971830985915, "no_speech_prob": 8.786052785580978e-05}, {"id": 420, "seek": 245528, "start": 2455.28, "end": 2461.2000000000003, "text": " take a matrix room. You upload some GLTF 3D assets to it. You upload some WASM or JavaScript scripts", "tokens": [747, 257, 8141, 1808, 13, 509, 6580, 512, 16225, 20527, 805, 35, 9769, 281, 309, 13, 509, 6580, 512, 28984, 44, 420, 15778, 23294], "temperature": 0.0, "avg_logprob": -0.1580169226533623, "compression_ratio": 1.5019455252918288, "no_speech_prob": 6.55072508379817e-05}, {"id": 421, "seek": 245528, "start": 2461.2000000000003, "end": 2467.1200000000003, "text": " to it. They use matrix RTC to spell up spatial VoIP and physics synchronization over WebRTC.", "tokens": [281, 309, 13, 814, 764, 8141, 497, 18238, 281, 9827, 493, 23598, 7518, 9139, 293, 10649, 19331, 2144, 670, 9573, 49, 18238, 13], "temperature": 0.0, "avg_logprob": -0.1580169226533623, "compression_ratio": 1.5019455252918288, "no_speech_prob": 6.55072508379817e-05}, {"id": 422, "seek": 245528, "start": 2467.1200000000003, "end": 2471.6000000000004, "text": " And you get WebFirst, open decentralized virtual worlds and spatial apps without any of the", "tokens": [400, 291, 483, 9573, 27454, 11, 1269, 32870, 6374, 13401, 293, 23598, 7733, 1553, 604, 295, 264], "temperature": 0.0, "avg_logprob": -0.1580169226533623, "compression_ratio": 1.5019455252918288, "no_speech_prob": 6.55072508379817e-05}, {"id": 423, "seek": 245528, "start": 2471.6000000000004, "end": 2477.84, "text": " cryptocurrency or token or Facebook stuff, apart from possibly the hardware. And it looks like this.", "tokens": [28809, 420, 14862, 420, 4384, 1507, 11, 4936, 490, 6264, 264, 8837, 13, 400, 309, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1580169226533623, "compression_ratio": 1.5019455252918288, "no_speech_prob": 6.55072508379817e-05}, {"id": 424, "seek": 247784, "start": 2477.84, "end": 2484.48, "text": " So you can literally go to it right now, thirdroom.io, and I'm going to go to a world called", "tokens": [407, 291, 393, 3736, 352, 281, 309, 558, 586, 11, 2636, 2861, 13, 1004, 11, 293, 286, 478, 516, 281, 352, 281, 257, 1002, 1219], "temperature": 0.0, "avg_logprob": -0.21674487216413513, "compression_ratio": 1.6085409252669038, "no_speech_prob": 1.911528488562908e-05}, {"id": 425, "seek": 247784, "start": 2484.48, "end": 2490.8, "text": " third room presentation here. And it's going to hopefully pull this up out of my index DB,", "tokens": [2636, 1808, 5860, 510, 13, 400, 309, 311, 516, 281, 4696, 2235, 341, 493, 484, 295, 452, 8186, 26754, 11], "temperature": 0.0, "avg_logprob": -0.21674487216413513, "compression_ratio": 1.6085409252669038, "no_speech_prob": 1.911528488562908e-05}, {"id": 426, "seek": 247784, "start": 2490.8, "end": 2495.6000000000004, "text": " because I don't want to wait to download 50 megabytes over the network. And if the demo", "tokens": [570, 286, 500, 380, 528, 281, 1699, 281, 5484, 2625, 10816, 24538, 670, 264, 3209, 13, 400, 498, 264, 10723], "temperature": 0.0, "avg_logprob": -0.21674487216413513, "compression_ratio": 1.6085409252669038, "no_speech_prob": 1.911528488562908e-05}, {"id": 427, "seek": 247784, "start": 2495.6000000000004, "end": 2502.6400000000003, "text": " gods are smiling, then you find yourself in this rather snazzy demo world. Now, this is running", "tokens": [14049, 366, 16005, 11, 550, 291, 915, 1803, 294, 341, 2831, 14528, 89, 1229, 10723, 1002, 13, 823, 11, 341, 307, 2614], "temperature": 0.0, "avg_logprob": -0.21674487216413513, "compression_ratio": 1.6085409252669038, "no_speech_prob": 1.911528488562908e-05}, {"id": 428, "seek": 247784, "start": 2502.6400000000003, "end": 2506.8, "text": " in Braille. So no plugins or anything. And it's going at 60 frames a second. It does", "tokens": [294, 4991, 3409, 13, 407, 572, 33759, 420, 1340, 13, 400, 309, 311, 516, 412, 4060, 12083, 257, 1150, 13, 467, 775], "temperature": 0.0, "avg_logprob": -0.21674487216413513, "compression_ratio": 1.6085409252669038, "no_speech_prob": 1.911528488562908e-05}, {"id": 429, "seek": 250680, "start": 2506.8, "end": 2513.36, "text": " this with proper multi-threading using shared array buffers and atomics to synchronize together", "tokens": [341, 365, 2296, 4825, 12, 392, 35908, 1228, 5507, 10225, 9204, 433, 293, 12018, 1167, 281, 19331, 1125, 1214], "temperature": 0.0, "avg_logprob": -0.13816169241200324, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.00034576249890960753}, {"id": 430, "seek": 250680, "start": 2514.1600000000003, "end": 2520.96, "text": " the WebGL thread and also the game thread and the main thread in the UI. You can see I'm indeed", "tokens": [264, 9573, 19440, 7207, 293, 611, 264, 1216, 7207, 293, 264, 2135, 7207, 294, 264, 15682, 13, 509, 393, 536, 286, 478, 6451], "temperature": 0.0, "avg_logprob": -0.13816169241200324, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.00034576249890960753}, {"id": 431, "seek": 250680, "start": 2520.96, "end": 2526.96, "text": " wandering around there wearing a placeholder avatar. I can flip into third person view here.", "tokens": [26396, 926, 456, 4769, 257, 1081, 20480, 36205, 13, 286, 393, 7929, 666, 2636, 954, 1910, 510, 13], "temperature": 0.0, "avg_logprob": -0.13816169241200324, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.00034576249890960753}, {"id": 432, "seek": 250680, "start": 2526.96, "end": 2531.44, "text": " And you can see I'm also wearing the same beautiful thing. We haven't got customizable avatars yet.", "tokens": [400, 291, 393, 536, 286, 478, 611, 4769, 264, 912, 2238, 551, 13, 492, 2378, 380, 658, 47922, 1305, 267, 685, 1939, 13], "temperature": 0.0, "avg_logprob": -0.13816169241200324, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.00034576249890960753}, {"id": 433, "seek": 250680, "start": 2531.44, "end": 2534.96, "text": " Some of the things I can show you here is that you can go and click on buttons. And", "tokens": [2188, 295, 264, 721, 286, 393, 855, 291, 510, 307, 300, 291, 393, 352, 293, 2052, 322, 9905, 13, 400], "temperature": 0.0, "avg_logprob": -0.13816169241200324, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.00034576249890960753}, {"id": 434, "seek": 253496, "start": 2534.96, "end": 2538.96, "text": " this is actually a script showing the layout of the different threads. I don't have time to show", "tokens": [341, 307, 767, 257, 5755, 4099, 264, 13333, 295, 264, 819, 19314, 13, 286, 500, 380, 362, 565, 281, 855], "temperature": 0.0, "avg_logprob": -0.19947249094645184, "compression_ratio": 1.6310344827586207, "no_speech_prob": 2.9307375370990485e-05}, {"id": 435, "seek": 253496, "start": 2538.96, "end": 2544.0, "text": " you that right now, but the game thread has got like rapier physics and WebAssembly. But a really", "tokens": [291, 300, 558, 586, 11, 457, 264, 1216, 7207, 575, 658, 411, 5099, 811, 10649, 293, 9573, 10884, 19160, 13, 583, 257, 534], "temperature": 0.0, "avg_logprob": -0.19947249094645184, "compression_ratio": 1.6310344827586207, "no_speech_prob": 2.9307375370990485e-05}, {"id": 436, "seek": 253496, "start": 2544.0, "end": 2550.56, "text": " fun thing is that you can just do freeform scripting of any kind. So one example could be", "tokens": [1019, 551, 307, 300, 291, 393, 445, 360, 1737, 837, 5755, 278, 295, 604, 733, 13, 407, 472, 1365, 727, 312], "temperature": 0.0, "avg_logprob": -0.19947249094645184, "compression_ratio": 1.6310344827586207, "no_speech_prob": 2.9307375370990485e-05}, {"id": 437, "seek": 253496, "start": 2550.56, "end": 2557.36, "text": " this silly, silly, silly demo, which hopefully will load up rapidly. Oh, that's what happens if", "tokens": [341, 11774, 11, 11774, 11, 11774, 10723, 11, 597, 4696, 486, 3677, 493, 12910, 13, 876, 11, 300, 311, 437, 2314, 498], "temperature": 0.0, "avg_logprob": -0.19947249094645184, "compression_ratio": 1.6310344827586207, "no_speech_prob": 2.9307375370990485e-05}, {"id": 438, "seek": 253496, "start": 2557.36, "end": 2560.96, "text": " you this is a bug where you have your worlds overlaying on one another. I'm going to keep it", "tokens": [291, 341, 307, 257, 7426, 689, 291, 362, 428, 13401, 31741, 278, 322, 472, 1071, 13, 286, 478, 516, 281, 1066, 309], "temperature": 0.0, "avg_logprob": -0.19947249094645184, "compression_ratio": 1.6310344827586207, "no_speech_prob": 2.9307375370990485e-05}, {"id": 439, "seek": 256096, "start": 2560.96, "end": 2566.88, "text": " like this, but this is pretty cool. So we've got the construct room from the matrix,", "tokens": [411, 341, 11, 457, 341, 307, 1238, 1627, 13, 407, 321, 600, 658, 264, 7690, 1808, 490, 264, 8141, 11], "temperature": 0.0, "avg_logprob": -0.2294293667407746, "compression_ratio": 1.5352697095435686, "no_speech_prob": 5.682390110450797e-05}, {"id": 440, "seek": 256096, "start": 2566.88, "end": 2573.2, "text": " so I'll see for in place on top of Mars down here. And if I go over to the TV and I click on it,", "tokens": [370, 286, 603, 536, 337, 294, 1081, 322, 1192, 295, 9692, 760, 510, 13, 400, 498, 286, 352, 670, 281, 264, 3558, 293, 286, 2052, 322, 309, 11], "temperature": 0.0, "avg_logprob": -0.2294293667407746, "compression_ratio": 1.5352697095435686, "no_speech_prob": 5.682390110450797e-05}, {"id": 441, "seek": 256096, "start": 2573.2, "end": 2584.56, "text": " predictably enough, the entire world goes matrix. So the script for that is literally just sitting", "tokens": [6069, 1188, 1547, 11, 264, 2302, 1002, 1709, 8141, 13, 407, 264, 5755, 337, 300, 307, 3736, 445, 3798], "temperature": 0.0, "avg_logprob": -0.2294293667407746, "compression_ratio": 1.5352697095435686, "no_speech_prob": 5.682390110450797e-05}, {"id": 442, "seek": 256096, "start": 2584.56, "end": 2590.88, "text": " there as a bunch of JavaScript uploaded into the media repository. And it's compiled down", "tokens": [456, 382, 257, 3840, 295, 15778, 17135, 666, 264, 3021, 25841, 13, 400, 309, 311, 36548, 760], "temperature": 0.0, "avg_logprob": -0.2294293667407746, "compression_ratio": 1.5352697095435686, "no_speech_prob": 5.682390110450797e-05}, {"id": 443, "seek": 259088, "start": 2590.88, "end": 2596.96, "text": " to Wasm in real time by the engine by QuickJS, thanks to Fabrice Bellard. And it's like four", "tokens": [281, 3027, 76, 294, 957, 565, 538, 264, 2848, 538, 12101, 41, 50, 11, 3231, 281, 17440, 21299, 11485, 515, 13, 400, 309, 311, 411, 1451], "temperature": 0.0, "avg_logprob": -0.16464005377059593, "compression_ratio": 1.5620915032679739, "no_speech_prob": 0.00010086042311741039}, {"id": 444, "seek": 259088, "start": 2596.96, "end": 2601.6800000000003, "text": " lines of code. You use WebSG, which is our new API called WebSceneGraph that we're going to propose", "tokens": [3876, 295, 3089, 13, 509, 764, 9573, 50, 38, 11, 597, 307, 527, 777, 9362, 1219, 9573, 16806, 1450, 38, 2662, 300, 321, 434, 516, 281, 17421], "temperature": 0.0, "avg_logprob": -0.16464005377059593, "compression_ratio": 1.5620915032679739, "no_speech_prob": 0.00010086042311741039}, {"id": 445, "seek": 259088, "start": 2601.6800000000003, "end": 2608.56, "text": " to W3C as a 3D API for manipulating JLTF scene graphs. Now you make it intractable and then every", "tokens": [281, 343, 18, 34, 382, 257, 805, 35, 9362, 337, 40805, 508, 43, 20527, 4145, 24877, 13, 823, 291, 652, 309, 560, 1897, 712, 293, 550, 633], "temperature": 0.0, "avg_logprob": -0.16464005377059593, "compression_ratio": 1.5620915032679739, "no_speech_prob": 0.00010086042311741039}, {"id": 446, "seek": 259088, "start": 2609.2000000000003, "end": 2612.88, "text": " tick, every frame, you see if it's being pressed and then you toggle the state and you enable", "tokens": [5204, 11, 633, 3920, 11, 291, 536, 498, 309, 311, 885, 17355, 293, 550, 291, 31225, 264, 1785, 293, 291, 9528], "temperature": 0.0, "avg_logprob": -0.16464005377059593, "compression_ratio": 1.5620915032679739, "no_speech_prob": 0.00010086042311741039}, {"id": 447, "seek": 259088, "start": 2612.88, "end": 2618.88, "text": " the matrix material on the room. It's slightly cheated by hard coding it on the in the engine", "tokens": [264, 8141, 2527, 322, 264, 1808, 13, 467, 311, 4748, 28079, 538, 1152, 17720, 309, 322, 264, 294, 264, 2848], "temperature": 0.0, "avg_logprob": -0.16464005377059593, "compression_ratio": 1.5620915032679739, "no_speech_prob": 0.00010086042311741039}, {"id": 448, "seek": 261888, "start": 2618.88, "end": 2625.12, "text": " for now like this. Something that we haven't hard goaded though is this guy, which is really", "tokens": [337, 586, 411, 341, 13, 6595, 300, 321, 2378, 380, 1152, 352, 12777, 1673, 307, 341, 2146, 11, 597, 307, 534], "temperature": 0.0, "avg_logprob": -0.12871857906909698, "compression_ratio": 1.581896551724138, "no_speech_prob": 4.347645153757185e-05}, {"id": 449, "seek": 261888, "start": 2625.12, "end": 2632.96, "text": " exciting. I'm going to refresh his time. And here you can see a big scary black blob with", "tokens": [4670, 13, 286, 478, 516, 281, 15134, 702, 565, 13, 400, 510, 291, 393, 536, 257, 955, 6958, 2211, 46115, 365], "temperature": 0.0, "avg_logprob": -0.12871857906909698, "compression_ratio": 1.581896551724138, "no_speech_prob": 4.347645153757185e-05}, {"id": 450, "seek": 261888, "start": 2632.96, "end": 2638.48, "text": " Poland noise, which is pulsating according to my voice as I bellow at it. And this thing is", "tokens": [15950, 5658, 11, 597, 307, 32295, 990, 4650, 281, 452, 3177, 382, 286, 312, 1202, 412, 309, 13, 400, 341, 551, 307], "temperature": 0.0, "avg_logprob": -0.12871857906909698, "compression_ratio": 1.581896551724138, "no_speech_prob": 4.347645153757185e-05}, {"id": 451, "seek": 261888, "start": 2638.48, "end": 2643.84, "text": " actually a huge chunk of C, which is compiled down to Wasm and is going and programmatically", "tokens": [767, 257, 2603, 16635, 295, 383, 11, 597, 307, 36548, 760, 281, 3027, 76, 293, 307, 516, 293, 37648, 5030], "temperature": 0.0, "avg_logprob": -0.12871857906909698, "compression_ratio": 1.581896551724138, "no_speech_prob": 4.347645153757185e-05}, {"id": 452, "seek": 264384, "start": 2643.84, "end": 2652.2400000000002, "text": " changing in real time the JLTF scene. So this is like the first proper, more advanced capabilities", "tokens": [4473, 294, 957, 565, 264, 508, 43, 20527, 4145, 13, 407, 341, 307, 411, 264, 700, 2296, 11, 544, 7339, 10862], "temperature": 0.0, "avg_logprob": -0.14744214542576525, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.00010602684051264077}, {"id": 453, "seek": 264384, "start": 2652.2400000000002, "end": 2656.32, "text": " on top of third room. The whole idea is you can build any old app on top of this. You could", "tokens": [322, 1192, 295, 2636, 1808, 13, 440, 1379, 1558, 307, 291, 393, 1322, 604, 1331, 724, 322, 1192, 295, 341, 13, 509, 727], "temperature": 0.0, "avg_logprob": -0.14744214542576525, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.00010602684051264077}, {"id": 454, "seek": 264384, "start": 2656.32, "end": 2661.1200000000003, "text": " build Figma on this. You could do multiplayer blender. In fact, we have an in-world editor in", "tokens": [1322, 479, 16150, 322, 341, 13, 509, 727, 360, 27325, 24564, 13, 682, 1186, 11, 321, 362, 364, 294, 12, 13217, 9839, 294], "temperature": 0.0, "avg_logprob": -0.14744214542576525, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.00010602684051264077}, {"id": 455, "seek": 264384, "start": 2661.1200000000003, "end": 2666.1600000000003, "text": " here where I can go and select this guy at the bottom and they will have a big white bagel", "tokens": [510, 689, 286, 393, 352, 293, 3048, 341, 2146, 412, 264, 2767, 293, 436, 486, 362, 257, 955, 2418, 3411, 338], "temperature": 0.0, "avg_logprob": -0.14744214542576525, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.00010602684051264077}, {"id": 456, "seek": 264384, "start": 2666.1600000000003, "end": 2669.84, "text": " around it. And we don't yet have the property editor, but you should be able to go in and", "tokens": [926, 309, 13, 400, 321, 500, 380, 1939, 362, 264, 4707, 9839, 11, 457, 291, 820, 312, 1075, 281, 352, 294, 293], "temperature": 0.0, "avg_logprob": -0.14744214542576525, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.00010602684051264077}, {"id": 457, "seek": 266984, "start": 2669.84, "end": 2674.32, "text": " directly manipulate it, change the opacity, the transformations, et cetera, and all that sort", "tokens": [3838, 20459, 309, 11, 1319, 264, 41693, 11, 264, 34852, 11, 1030, 11458, 11, 293, 439, 300, 1333], "temperature": 0.0, "avg_logprob": -0.15598606139190438, "compression_ratio": 1.6784452296819787, "no_speech_prob": 3.5209712223149836e-05}, {"id": 458, "seek": 266984, "start": 2674.32, "end": 2681.92, "text": " of thing. And it really ends up feeling a lot like the web. Rather than a DOM, you've got JLTF,", "tokens": [295, 551, 13, 400, 309, 534, 5314, 493, 2633, 257, 688, 411, 264, 3670, 13, 16571, 813, 257, 35727, 11, 291, 600, 658, 508, 43, 20527, 11], "temperature": 0.0, "avg_logprob": -0.15598606139190438, "compression_ratio": 1.6784452296819787, "no_speech_prob": 3.5209712223149836e-05}, {"id": 459, "seek": 266984, "start": 2681.92, "end": 2687.04, "text": " rather than the DOM API, you've got the WebSG API, rather than JavaScript, you've got Wasm,", "tokens": [2831, 813, 264, 35727, 9362, 11, 291, 600, 658, 264, 9573, 50, 38, 9362, 11, 2831, 813, 15778, 11, 291, 600, 658, 3027, 76, 11], "temperature": 0.0, "avg_logprob": -0.15598606139190438, "compression_ratio": 1.6784452296819787, "no_speech_prob": 3.5209712223149836e-05}, {"id": 460, "seek": 266984, "start": 2687.04, "end": 2692.6400000000003, "text": " Sandblocks, Blobs, with Rust and Zig and C and JavaScript within it. And there is one final thing", "tokens": [7985, 15962, 2761, 11, 9865, 929, 11, 365, 34952, 293, 50004, 293, 383, 293, 15778, 1951, 309, 13, 400, 456, 307, 472, 2572, 551], "temperature": 0.0, "avg_logprob": -0.15598606139190438, "compression_ratio": 1.6784452296819787, "no_speech_prob": 3.5209712223149836e-05}, {"id": 461, "seek": 266984, "start": 2692.6400000000003, "end": 2696.2400000000002, "text": " I'm going to try to show you, which is probably going to go horribly wrong, which is that we've", "tokens": [286, 478, 516, 281, 853, 281, 855, 291, 11, 597, 307, 1391, 516, 281, 352, 45028, 2085, 11, 597, 307, 300, 321, 600], "temperature": 0.0, "avg_logprob": -0.15598606139190438, "compression_ratio": 1.6784452296819787, "no_speech_prob": 3.5209712223149836e-05}, {"id": 462, "seek": 269624, "start": 2696.24, "end": 2705.52, "text": " just added WebXR into third room. So if I go and put on my Facebook device, and there we go.", "tokens": [445, 3869, 9573, 55, 49, 666, 2636, 1808, 13, 407, 498, 286, 352, 293, 829, 322, 452, 4384, 4302, 11, 293, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.16910362243652344, "compression_ratio": 1.4090909090909092, "no_speech_prob": 1.9477951354929246e-05}, {"id": 463, "seek": 269624, "start": 2707.4399999999996, "end": 2712.08, "text": " And I back away a bit. Probably unplug it. You'll see, hopefully, in fact, I need to go full", "tokens": [400, 286, 646, 1314, 257, 857, 13, 9210, 39456, 309, 13, 509, 603, 536, 11, 4696, 11, 294, 1186, 11, 286, 643, 281, 352, 1577], "temperature": 0.0, "avg_logprob": -0.16910362243652344, "compression_ratio": 1.4090909090909092, "no_speech_prob": 1.9477951354929246e-05}, {"id": 464, "seek": 269624, "start": 2712.08, "end": 2720.56, "text": " screen on that. I guess I do. There we go. Is that coming through? You can see that here I am", "tokens": [2568, 322, 300, 13, 286, 2041, 286, 360, 13, 821, 321, 352, 13, 1119, 300, 1348, 807, 30, 509, 393, 536, 300, 510, 286, 669], "temperature": 0.0, "avg_logprob": -0.16910362243652344, "compression_ratio": 1.4090909090909092, "no_speech_prob": 1.9477951354929246e-05}, {"id": 465, "seek": 272056, "start": 2720.56, "end": 2727.84, "text": " wondering around third room. Probably can get them full off the stage and break my neck. And I can", "tokens": [6359, 926, 2636, 1808, 13, 9210, 393, 483, 552, 1577, 766, 264, 3233, 293, 1821, 452, 6189, 13, 400, 286, 393], "temperature": 0.0, "avg_logprob": -0.2019016559307392, "compression_ratio": 1.7255813953488373, "no_speech_prob": 5.0949060096172616e-05}, {"id": 466, "seek": 272056, "start": 2727.84, "end": 2734.24, "text": " go and, like, spawn object. So you can have big crate. I can throw the crate away. I can spawn", "tokens": [352, 293, 11, 411, 11, 17088, 2657, 13, 407, 291, 393, 362, 955, 42426, 13, 286, 393, 3507, 264, 42426, 1314, 13, 286, 393, 17088], "temperature": 0.0, "avg_logprob": -0.2019016559307392, "compression_ratio": 1.7255813953488373, "no_speech_prob": 5.0949060096172616e-05}, {"id": 467, "seek": 272056, "start": 2734.24, "end": 2741.04, "text": " some other big crate. Let's run away from that one. Go and pick this guy up and throw it away.", "tokens": [512, 661, 955, 42426, 13, 961, 311, 1190, 1314, 490, 300, 472, 13, 1037, 293, 1888, 341, 2146, 493, 293, 3507, 309, 1314, 13], "temperature": 0.0, "avg_logprob": -0.2019016559307392, "compression_ratio": 1.7255813953488373, "no_speech_prob": 5.0949060096172616e-05}, {"id": 468, "seek": 272056, "start": 2741.04, "end": 2746.4, "text": " Go and pick that one up. It's over here. And throw it away, et cetera. And I mean,", "tokens": [1037, 293, 1888, 300, 472, 493, 13, 467, 311, 670, 510, 13, 400, 3507, 309, 1314, 11, 1030, 11458, 13, 400, 286, 914, 11], "temperature": 0.0, "avg_logprob": -0.2019016559307392, "compression_ratio": 1.7255813953488373, "no_speech_prob": 5.0949060096172616e-05}, {"id": 469, "seek": 274640, "start": 2746.4, "end": 2762.4, "text": " this is running at 90 frames a second. 90 frames a second. So that's a bit weird. It is", "tokens": [341, 307, 2614, 412, 4289, 12083, 257, 1150, 13, 4289, 12083, 257, 1150, 13, 407, 300, 311, 257, 857, 3657, 13, 467, 307], "temperature": 0.0, "avg_logprob": -0.263167327305056, "compression_ratio": 1.385185185185185, "no_speech_prob": 3.8966980355326086e-05}, {"id": 470, "seek": 274640, "start": 2763.6800000000003, "end": 2771.6, "text": " as least as good as the native MetaHorizon stuff, the Facebook of ships, except it's running within", "tokens": [382, 1935, 382, 665, 382, 264, 8470, 6377, 64, 39, 284, 24057, 1507, 11, 264, 4384, 295, 11434, 11, 3993, 309, 311, 2614, 1951], "temperature": 0.0, "avg_logprob": -0.263167327305056, "compression_ratio": 1.385185185185185, "no_speech_prob": 3.8966980355326086e-05}, {"id": 471, "seek": 277160, "start": 2771.6, "end": 2776.72, "text": " WebXR in a browser in a completely open environment. So we're kind of hoping this provides a really", "tokens": [9573, 55, 49, 294, 257, 11185, 294, 257, 2584, 1269, 2823, 13, 407, 321, 434, 733, 295, 7159, 341, 6417, 257, 534], "temperature": 0.0, "avg_logprob": -0.14299105549906635, "compression_ratio": 1.5118110236220472, "no_speech_prob": 0.00016458820027764887}, {"id": 472, "seek": 277160, "start": 2776.72, "end": 2783.52, "text": " viable platform to build a genuine open spatial collaboration plane for the web. I've already", "tokens": [22024, 3663, 281, 1322, 257, 16699, 1269, 23598, 9363, 5720, 337, 264, 3670, 13, 286, 600, 1217], "temperature": 0.0, "avg_logprob": -0.14299105549906635, "compression_ratio": 1.5118110236220472, "no_speech_prob": 0.00016458820027764887}, {"id": 473, "seek": 277160, "start": 2783.52, "end": 2787.44, "text": " spoken about that. Coming up next is persistence. So we don't yet persist the changes into the", "tokens": [10759, 466, 300, 13, 12473, 493, 958, 307, 37617, 13, 407, 321, 500, 380, 1939, 13233, 264, 2962, 666, 264], "temperature": 0.0, "avg_logprob": -0.14299105549906635, "compression_ratio": 1.5118110236220472, "no_speech_prob": 0.00016458820027764887}, {"id": 474, "seek": 277160, "start": 2787.44, "end": 2792.16, "text": " matrix room, but we will by uploading little bits of JLTF files so you can even have bots which", "tokens": [8141, 1808, 11, 457, 321, 486, 538, 27301, 707, 9239, 295, 508, 43, 20527, 7098, 370, 291, 393, 754, 362, 35410, 597], "temperature": 0.0, "avg_logprob": -0.14299105549906635, "compression_ratio": 1.5118110236220472, "no_speech_prob": 0.00016458820027764887}, {"id": 475, "seek": 279216, "start": 2792.16, "end": 2801.2799999999997, "text": " go into that. Another thing I should have shown you, but forgot, was this guy somewhere. I've", "tokens": [352, 666, 300, 13, 3996, 551, 286, 820, 362, 4898, 291, 11, 457, 5298, 11, 390, 341, 2146, 4079, 13, 286, 600], "temperature": 0.0, "avg_logprob": -0.19826053013311368, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0001231152273248881}, {"id": 476, "seek": 279216, "start": 2801.2799999999997, "end": 2806.56, "text": " lost it already. Never mind. Well, I was going to show you it's an echo. This guy here. But if in", "tokens": [2731, 309, 1217, 13, 7344, 1575, 13, 1042, 11, 286, 390, 516, 281, 855, 291, 309, 311, 364, 14300, 13, 639, 2146, 510, 13, 583, 498, 294], "temperature": 0.0, "avg_logprob": -0.19826053013311368, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0001231152273248881}, {"id": 477, "seek": 279216, "start": 2806.56, "end": 2811.12, "text": " this room I go in, and I think this is going to be a comedy, yeah, that's what happens if London", "tokens": [341, 1808, 286, 352, 294, 11, 293, 286, 519, 341, 307, 516, 281, 312, 257, 13394, 11, 1338, 11, 300, 311, 437, 2314, 498, 7042], "temperature": 0.0, "avg_logprob": -0.19826053013311368, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0001231152273248881}, {"id": 478, "seek": 279216, "start": 2811.12, "end": 2816.16, "text": " and Mars get mixed together for everybody. If I go and say hi because, look, it's matrix room,", "tokens": [293, 9692, 483, 7467, 1214, 337, 2201, 13, 759, 286, 352, 293, 584, 4879, 570, 11, 574, 11, 309, 311, 8141, 1808, 11], "temperature": 0.0, "avg_logprob": -0.19826053013311368, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0001231152273248881}, {"id": 479, "seek": 281616, "start": 2816.16, "end": 2822.64, "text": " then if I do slash echo something, I get an echo back. That echo has come from a", "tokens": [550, 498, 286, 360, 17330, 14300, 746, 11, 286, 483, 364, 14300, 646, 13, 663, 14300, 575, 808, 490, 257], "temperature": 0.0, "avg_logprob": -0.1508847269518622, "compression_ratio": 1.595667870036101, "no_speech_prob": 1.732277996779885e-05}, {"id": 480, "seek": 281616, "start": 2822.64, "end": 2828.72, "text": " widget in Wasm running inside the world. So you can program matrix now from within Wasm", "tokens": [34047, 294, 3027, 76, 2614, 1854, 264, 1002, 13, 407, 291, 393, 1461, 8141, 586, 490, 1951, 3027, 76], "temperature": 0.0, "avg_logprob": -0.1508847269518622, "compression_ratio": 1.595667870036101, "no_speech_prob": 1.732277996779885e-05}, {"id": 481, "seek": 281616, "start": 2828.72, "end": 2832.7999999999997, "text": " blobs sitting within the room. Nothing to do with third room. You could use this in clients,", "tokens": [1749, 929, 3798, 1951, 264, 1808, 13, 6693, 281, 360, 365, 2636, 1808, 13, 509, 727, 764, 341, 294, 6982, 11], "temperature": 0.0, "avg_logprob": -0.1508847269518622, "compression_ratio": 1.595667870036101, "no_speech_prob": 1.732277996779885e-05}, {"id": 482, "seek": 281616, "start": 2832.7999999999997, "end": 2840.24, "text": " et cetera, to start doing client-side widgets. So what's next? Loads of stuff. One big PSA", "tokens": [1030, 11458, 11, 281, 722, 884, 6423, 12, 1812, 43355, 13, 407, 437, 311, 958, 30, 6130, 5834, 295, 1507, 13, 1485, 955, 8168, 32], "temperature": 0.0, "avg_logprob": -0.1508847269518622, "compression_ratio": 1.595667870036101, "no_speech_prob": 1.732277996779885e-05}, {"id": 483, "seek": 281616, "start": 2840.24, "end": 2845.52, "text": " is that Gitter is going native matrix roughly next week. We basically can't afford to run", "tokens": [307, 300, 460, 3904, 307, 516, 8470, 8141, 9810, 958, 1243, 13, 492, 1936, 393, 380, 6157, 281, 1190], "temperature": 0.0, "avg_logprob": -0.1508847269518622, "compression_ratio": 1.595667870036101, "no_speech_prob": 1.732277996779885e-05}, {"id": 484, "seek": 284552, "start": 2845.52, "end": 2849.7599999999998, "text": " both the Gitter infrastructure and a bunch of matrix infrastructure. So Gitter will become", "tokens": [1293, 264, 460, 3904, 6896, 293, 257, 3840, 295, 8141, 6896, 13, 407, 460, 3904, 486, 1813], "temperature": 0.0, "avg_logprob": -0.10888847351074218, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00019599565712269396}, {"id": 485, "seek": 284552, "start": 2849.7599999999998, "end": 2854.8, "text": " a branded element instance. The API will go away. Please use matrix instead. And finally,", "tokens": [257, 38510, 4478, 5197, 13, 440, 9362, 486, 352, 1314, 13, 2555, 764, 8141, 2602, 13, 400, 2721, 11], "temperature": 0.0, "avg_logprob": -0.10888847351074218, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00019599565712269396}, {"id": 486, "seek": 284552, "start": 2854.8, "end": 2861.04, "text": " we need help. Friends, don't let friends use proprietary chat services. Please use matrix.", "tokens": [321, 643, 854, 13, 14042, 11, 500, 380, 718, 1855, 764, 38992, 5081, 3328, 13, 2555, 764, 8141, 13], "temperature": 0.0, "avg_logprob": -0.10888847351074218, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00019599565712269396}, {"id": 487, "seek": 284552, "start": 2861.04, "end": 2865.44, "text": " And critically, and this is new and it's really important, if you're benefiting commercially", "tokens": [400, 22797, 11, 293, 341, 307, 777, 293, 309, 311, 534, 1021, 11, 498, 291, 434, 47515, 41751], "temperature": 0.0, "avg_logprob": -0.10888847351074218, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00019599565712269396}, {"id": 488, "seek": 284552, "start": 2865.44, "end": 2871.84, "text": " from matrix, please financially support the foundation because it's stuck in this horrible", "tokens": [490, 8141, 11, 1767, 20469, 1406, 264, 7030, 570, 309, 311, 5541, 294, 341, 9263], "temperature": 0.0, "avg_logprob": -0.10888847351074218, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00019599565712269396}, {"id": 489, "seek": 287184, "start": 2871.84, "end": 2876.56, "text": " feedback loop at the moment where the better we make matrix, the less inclined it seems", "tokens": [5824, 6367, 412, 264, 1623, 689, 264, 1101, 321, 652, 8141, 11, 264, 1570, 28173, 309, 2544], "temperature": 0.0, "avg_logprob": -0.10252441830105252, "compression_ratio": 1.5512820512820513, "no_speech_prob": 7.267414912348613e-05}, {"id": 490, "seek": 287184, "start": 2876.56, "end": 2882.56, "text": " that people want to pay for support or pay for things if they can just grab it on GitHub.", "tokens": [300, 561, 528, 281, 1689, 337, 1406, 420, 1689, 337, 721, 498, 436, 393, 445, 4444, 309, 322, 23331, 13], "temperature": 0.0, "avg_logprob": -0.10252441830105252, "compression_ratio": 1.5512820512820513, "no_speech_prob": 7.267414912348613e-05}, {"id": 491, "seek": 287184, "start": 2882.56, "end": 2887.6800000000003, "text": " This can end up being a disaster where we run out of cash. So please, please, please contribute", "tokens": [639, 393, 917, 493, 885, 257, 11293, 689, 321, 1190, 484, 295, 6388, 13, 407, 1767, 11, 1767, 11, 1767, 10586], "temperature": 0.0, "avg_logprob": -0.10252441830105252, "compression_ratio": 1.5512820512820513, "no_speech_prob": 7.267414912348613e-05}, {"id": 492, "seek": 287184, "start": 2887.6800000000003, "end": 2891.92, "text": " back, particularly if you're a government. You've got loads of money. Also, run a server,", "tokens": [646, 11, 4098, 498, 291, 434, 257, 2463, 13, 509, 600, 658, 12668, 295, 1460, 13, 2743, 11, 1190, 257, 7154, 11], "temperature": 0.0, "avg_logprob": -0.10252441830105252, "compression_ratio": 1.5512820512820513, "no_speech_prob": 7.267414912348613e-05}, {"id": 493, "seek": 289192, "start": 2891.92, "end": 2913.6800000000003, "text": " run bridges bots, build on matrix, follow us on MasterDone, and thank you very much.", "tokens": [1190, 21114, 35410, 11, 1322, 322, 8141, 11, 1524, 505, 322, 6140, 35, 546, 11, 293, 1309, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.49304859454815203, "compression_ratio": 1.2521739130434784, "no_speech_prob": 5.07178483530879e-05}, {"id": 494, "seek": 291368, "start": 2913.68, "end": 2923.9199999999996, "text": " Thanks for listening. Sorry for running on time, as always.", "tokens": [50364, 2561, 337, 4764, 13, 4919, 337, 2614, 322, 565, 11, 382, 1009, 13, 50876], "temperature": 0.0, "avg_logprob": -0.3619272708892822, "compression_ratio": 0.9672131147540983, "no_speech_prob": 6.97458817739971e-05}], "language": "en"}