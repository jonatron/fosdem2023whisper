{"text": " Hello everyone, welcome to this session about Cilium Service Mesh. My name is Raymond De Jong, I'm Field CTO for ISOFALENT, the originators from Cilium. Today I'm going to talk a bit about EBPF and Cilium as an introduction, after which I'm going to talk about how the Service Mesh is evolving, after which we'll talk about the Cilium Service Mesh features, what we can do today, and what we're planning to support in the future. Quick highlight of some upcoming features and some current features, and if we have time I have a little demo to show how it works. Can I see some hands from you if you know EBPF? Quite a lot, good. How many of you know Cilium? Cool. OK, how many of you use Cilium, actually? Not as much. OK, cool. So, for the ones who don't know what EBPF is, I'm going to do an introduction here, is EBPF is standing for Extended Berkeley Packet Filter, by itself that doesn't mean a lot, but what we like to compare it with is what JavaScript is to the browser, EBPF is to the kernel. What that means is that using EBPF we can attach programs to kernel events, and for the purpose of this session is that we can attach EBPF programs to kernel events related to networking, so that's either a socket being opened, a network packet being sent on a network device, that means that's a kernel event, and that means that we can attach a program to it and we can get a metrics from that packet, for example, or we can do load balancing and such. So Cilium is built on EBPF, you don't need to be a network, or sorry, you don't need to be an EBPF developer to actually work with Cilium. Cilium abstracts this complexity on technology under the hood, so based on the configuration you set, Cilium will mount the required EBPF programs for you to run, and Cilium in short provides networking and load balancing capabilities, security capabilities, and also a lot of observability capabilities using EBPF. So this is the 30,000 feet view where we are today, we started with plain networking, IPv6, IPv4 years ago, and now we expand that all the networking capabilities with BGP implementations, Netfor6, 64, extended load balancing out of the box we're working on, having GOBGP control playing fully supported with Cilium. On top of that we have an observability layer with our Hubble technology, which is a observability tool which provides service-to-service communication for your namespaces, so you can see what components, what services are talking to which services, after which you can make informed decisions, for example what kind of network policies you want to apply, also exporting metrics to tools like Rafaana, and service mesh on top of that to provide authentication, layer 7 path-based routing and such. On the right hand side we also have Kettergon, that's not something we'll talk about today, but that's runtime security using EBPF, which is also very interesting, and rerun across clouds, doesn't matter if it's on-prem or hybrid or multi-cluster, so it's agnostic of the platform, and supported by multiple cloud vendors. So as you may know, Google and false data plane V2 under the hood is actually Cilium. Microsoft has recently adopted Cilium as the default CNI for AKS clusters, and all their clusters will be migrated to Cilium, and AWS, EKS, anywhere by default is Cilium, so we see huge adoption in the field of Cilium. So let's talk about service mesh, so obviously if we talk about service mesh we talk about observing traffic, being able to secure traffic from application to application across clusters, doing traffic management, building resilience across applications across clouds. Service mesh originally, if you needed that capabilities, originally you would program your application either in Python or Go to get that observability. That wasn't really useful because you have to maintain all those libraries to get the information you need. That's where the sidecars came in, right, so that they abstract that complexity from the application to have a standard sidecar implementation to monitor traffic, to be able to route traffic, and to be able to extract metrics from that traffic. However, now with Cilium our goal is to move as close to the kernel as we already run in kernel with EBPF, so we're moving from a sidecar model to the kernel, and where we can we will support it using EBPF. The only part which is not yet there is Layer 7, so all the low balancing capabilities, routing capabilities in terms of IP to IP metrics are already available with Cilium using EBPF. Layer 7 routing is not yet in EBPF for multiple reasons, of which one is that EBPF has constraints in terms of how big a program can be, obviously it runs in kernel space, so it has constraints for a good reason, but in the future maybe we can even transport complex Layer 7 routing in EBPF. However, we already provide Layer 7 visibility and observability in using Cilium and EBPF, we already have the capabilities to inspect traffic using EBPF. We can already do the low balancing with the creep process replacement. The only part is the Layer 7, but the visibility of traffic, so HTTP traffic and such is already there. So surface mesh capabilities are extending those capabilities moving forward. So how does it work? So some of you may know that Cilium runs as an agent, as a demon set on the nodes, it programs the nodes to be mounting the EBPF programs for the capabilities you need, and we have an embedded Envoy running inside the Cilium agent. This is a narrow down Envoy proxy in the agent for networking capabilities, and we leverage this Envoy proxy on the node level to do surface mesh capabilities, so all the things like the HTTP path routing and such. So for each namespace you would create, and where you create, for example, an ingress resource or a gateway resource, that means that a listener will be created through the Envoy for that specific namespace for that specific workload. And we leverage C groups and stuff to have separation as well for the security reasons to not be able to have traffic across namespaces as such. So what is different with Cilium's surface mesh compared to other surface mesh implementations? First of all, our goal is to reduce operational complexity by removing sidecars, resource usage, reduced, better performance, and avoid sidecar startup shutdown race conditions. So obviously if you're not running sidecars at scale, this makes a huge difference. You don't have all the sidecar pods running alongside your normal pods, that will save memory, that will save CPU, that will save connection tracking, et cetera, et cetera. So a lot more efficient. And also in terms of latency, running a sidecar has a cost. So in this diagram you see that an application wants to send traffic to another application. What that means technically is that it goes through the TCP IP stack three times with the sidecar. First from the app, then inbound in the sidecar where the sidecar does its processing, and then external from the sidecar to the physical network device to hit the network to reach another node. With EBPF we are able to shortcut that connection and improve the latency because we can detect that traffic and we can see if it's destined for the physical network or it should be routed to the proxy. So once this app opens the socket using EBPF we can shortcut that connection to the physical network device to be routed on the physical network. If we need layer seven processing, that means that using EBPF we can shortcut the connection on the socket layer directly to the envoy proxy where the envoy proxy on the node does his HTTP routing and then forwards the traffic again on the physical network. So a lot less hops there. And it means that latency is much, much improved because we're not going through this TCP IP stack multiple times. In terms of throughput there's also a small difference because we can push more packets and in terms of pod ready performance this is also a consideration at scale because when you're scaling out your applications you always, with traditional sidecars, you need to wait for the sidecar to be spun up as well and to be ready to serve connections for that application. So without the sidecars with Cilium service mess it's already there. It's running on the node, it's embedded in the proxy so once you scale out your application the proxy immediately on that node can serve connections. So in short Cilium service mess provides traffic management, observability, security and resilience. The goal is to bring your own control plane or we are not developing a control plane on our own. What it means is that you can already use Ingress resources with Cilium 1.13 will support Gateway API. We are working on Spiffy integration so with the 1.13 release actually the ground work for MTLS and Spiffy integration is already there. You are not really able to use it yet but the goal is to support both MTLS and Spiffy using Cilium network policies so you can reference for example a Spiffy ID as a source and destination using Cilium network policies and then under the hood the Cilium agent part will connect to spy reserver where that identity is tracked and confirm if that's allowed. In terms of observability you can leverage the already available observability with Grafana or Hubble if you need to export events you can use scene platforms such as Splunk and open telemetry is also supported. If you are new, if you are running new classes you have an option you can run Cilium and you can already use Cilium service mesh out of the box this is obviously the preferred method but if you are running already an Istio based implementation there is still a lot of benefit to run Cilium under the hood there as well because for example we already encrypt the connectivity between the sidecar from an Istio based implementation towards the destination pod. What I mean by that is that when you run sidecars, when you run MTLS between applications that connectivity may be secure but the connection between the sidecar and the actual destination is encrypted on the node so anyone with specific privileges on a node could potentially listen on that virtual interface and e-drop traffic and that's obviously not secure. The running Cilium under the hood already gives you the benefit because we can encrypt on layer 4 directly on the socket layer to the destination pod obviously. With 1.12 so currently we have 1.12 available since I think 7 months. We already have a production ready Cilium service mesh, a conformant ingress controller which you can use for HDD path routing, canary releases and such. You can use Kubernetes as your service mesh control plane, fromisius metrics, open telemetry is supported. For power users we have Cilium Envoy Convict and Cilium cluster wide Envoy Convict CRDs available. These are temporarily I would say because the goal is to replace all that capabilities with Gateway API. And we're releasing more and more extended Grafana dashboards for layer 7 visibility so you can actually see between service to service what kind of metrics there are and what the latencies are and what return codes are, so golden signals. So the roadmap for 1.13 and we're very close for releasing 1.13, expected somewhere this month hopefully. You can already try a release candidate for Cilium 1.13 which includes a Gateway API support for HTTP routing, TLS termination, HTTP traffic splitting and waiting. So this allows you to do percentage based routing or canary releases as such without configuring Cilium Envoy Convict resources. And also the capability to have multiple ingresses parallel balancer. What that means is that currently when you create a Cilium ingress we rely on the hood on a low balancer to attract traffic and forward that to the proxy. Obviously at scale having a low balancer for each ingress, especially in clouds is expensive. So this with an annotation we allow multiple ingresses per low balancer so you can save cost there. So how am I doing at the time? Good features. So today ingress 1.12, also with services we are having support for annotations. So imagine you have received traffic from your ingress, you forward it to a service. That means we support annotations on a simple cluster IP to forward traffic for example to a specific endpoint. If you know what Cilium cluster mesh is we can connect Cilium across clusters. With simple annotations you can have even higher availability of services across clusters. Gateway API which I will show a bit later and the Envoy Convict. So this is a simple example of ingress and this is also something I will show in a demo. You have an ingress and from a specific path you want to forward traffic to specific service. We also support GRPC so you can also have specific GRPC URLs to be forwarded to specific services. TLS termination to terminate TLS using secrets, using ingress. A question I get a lot is what about SSL pass-through, that's on roadmap so keep that in mind. And obviously new in 1.13 is Gateway API and how it looks like is you will configure a Gateway resource. You specify the Gateway class name for Cilium to make sure that the Gateway is created and maintained through Cilium and then create listeners. So in this case an HTTP listener on port 80. Then additionally you create multiple HTTP routes, one or more. And this specify for example a path prefix for values forward slash details to be forwarded to a backend reference service called details. In terms of TLS termination, same constructs. You can also have for example a host name in there to only accept traffic for this given host name and you reference a secret in the Gateway resource and then in the HTTP routes you will specify the host name, you will reference the Gateway you want to use and then again a path prefix for example to forward to specific service. And then traffic splitting, very simple, also using HTTP routes. Again referencing your Gateway, a path prefix and then you have in this case an Echo 1 and Echo 2 service where you want to introduce slowly Echo 2 and in this case 25% of that traffic will be forwarded to the Echo 2 service. And this is the example what I talked about earlier. Using simple annotations you can extend service miscapabilities by annotating services. So in this case this service will receive traffic for GRPC and we can attach low balancing modes for in this case weighted least requests to be forwarded to backend endpoints. And using multi cluster capabilities you can extend these capabilities across two or more clusters depending on your cluster mesh configuration. And canary roll out, so you can even introduce new clusters, have the new version of your application running on the new cluster, so you're absolutely sure that you have no resource contingent on your original cluster and then on the service annotate traffic to forward slowly to remote cluster before you do the flip over. So this concludes the presentation part, so for example when you want to know more about Cilium go to the Cilium community, I encourage you to join our Slack channel if you have any questions, our team is there as well to answer questions for in Slack, any issues you may have or any roadmap or feature request you may have, we're very interested to hear from you. You can also contribute, so obviously if you want to develop on Cilium, join the Cilium Github and contribute, if you want to know more about EBPF go to EBPF.io and if you want to know more about Isovalent, the company who originated Cilium and want to for example work there, have a look there, we are looking for engineers as well, so feel free to have a look and if you want to know more, ask me after the session as well. All right, let me do, see how I'm doing with time, so in order to run Ingress and Gateway API, you need to set a certain amount of flags on your for example your hand value style, so this is an example, I've run a small demo on GKE, so this is a GKE cluster with Cilium installed, what you need to do is you need to enable the Ingress controller and in this case I'm also enabling metrics just because it's interesting to see what's going on. For Gateway API there's also a value, so Gateway API enabled through, this will trigger Gateway API to be enabled, for service mesh it's important to configure the cube proxy replacement to strict or probe, strict is recommended because you have the full cube proxy replacement capabilities in your cluster, this is also required for service mesh and that's basically it to get started. So for this simple demo, I've created a simple gateway with the Gateway class named Cilium, so this is running Cilium 1.13 Release Candidate 5 which has the Gateway API support and then a simple HTTP route for the book info example application which has matches for the details and the default path prefixes, so when I go into my environment, I want to show quickly the following, so if I do a Qubectl getService, you can see I already for the sake of time created this gateways, what I wanted to show you is that obviously a low balance is required, so GKE provisions me a low balancer, low balancer IP I can use to attract traffic, in this case I'm demoing a default HTTP gateway and a default HTTPS gateway, so I have two low balancers with each an external IP address assigned, so this configuration is applied, so if I do a Qubectl get a gateway, good point, obviously in your cluster you also need to install the CRDs for Gateway API support, here you can see I have my Gateway and our TLS Gateway and if I do a Qubectl get HTTP routes, I can see I have my book info HTTP route installed and this relates to this part obviously, so with that I should be able to connect to the details, so this is running the bookstore example, so I'm using that public IP as you can see it works and if I go to details I should be forwarded using the Gateway API HTTP routes to that specific details service and that works as well, for HTTPS again a simple example I've created that gateway, TLS gateway, I've created two listeners, so a listener for bookinfo.cillium.rocks and a listener for hipster shop.cillium.rocks, I didn't have installed the hipster shop for demo purposes, I'm also referencing two secrets, so I've used makesert to create a simple self signed certificate installed in my certificate store and created a secret which I reference using this listener, then again HTTP routes for the TLS gateway for bookinfo.cillium.rocks matches to only the details path prefix on port 9080 and again apart for the hipster shop, so that's what I'm going to show here, so if I do the default URL that doesn't work there's no list, there's no HTTP route configured, but for details I can see I can connect it securely and this certificate is run from the gateway resource as well. Obviously this is a self signed certificate, but obviously you can create signed certificates as well. With that, that concludes my presentation and the demo, I'm open for questions. Any questions? Hi, thank you very much for your presentation. When you talk about no layer 7 support in going to come or not? I'm not sure about that. HTTP routing requires quite a lot of memory, so obviously memory is limited in eBPF programs for good reasons, so it will depend on the eBPF foundation and the roadmap there, what we can support. Technically there's no reason why we shouldn't be able to do that, but in terms of memory we have constraints, so if those are being raised we potentially can have parts of even all parts using eBPF. Any other questions? Hi, does it provide or can you provide end to end encryption, especially between the nodes automatically or not? Yes, so our vision there is that you should configure, for example, IP stack or wire guard for node to node encryption in transit, and if you want authentication and authorization on top of that to configure SPIFI or MTLS between your applications. It's a multi-layered approach, so we're not doing the encryption on the MTLS part, but on the node level, if that makes sense. So MTLS again, SPIFI is on roadmap, hopefully for 1.13. Any other? No, okay, thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.6, "text": " Hello everyone, welcome to this session about Cilium Service Mesh.", "tokens": [2425, 1518, 11, 2928, 281, 341, 5481, 466, 383, 388, 2197, 9561, 376, 14935, 13], "temperature": 0.0, "avg_logprob": -0.26519793848837575, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.10455445945262909}, {"id": 1, "seek": 0, "start": 10.6, "end": 18.2, "text": " My name is Raymond De Jong, I'm Field CTO for ISOFALENT, the originators from Cilium.", "tokens": [1222, 1315, 307, 42813, 1346, 19589, 11, 286, 478, 17952, 383, 15427, 337, 25042, 37, 3427, 9536, 11, 264, 4957, 3391, 490, 383, 388, 2197, 13], "temperature": 0.0, "avg_logprob": -0.26519793848837575, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.10455445945262909}, {"id": 2, "seek": 0, "start": 18.2, "end": 23.2, "text": " Today I'm going to talk a bit about EBPF and Cilium as an introduction, after which", "tokens": [2692, 286, 478, 516, 281, 751, 257, 857, 466, 50148, 47, 37, 293, 383, 388, 2197, 382, 364, 9339, 11, 934, 597], "temperature": 0.0, "avg_logprob": -0.26519793848837575, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.10455445945262909}, {"id": 3, "seek": 0, "start": 23.2, "end": 28.44, "text": " I'm going to talk about how the Service Mesh is evolving, after which we'll talk about", "tokens": [286, 478, 516, 281, 751, 466, 577, 264, 9561, 376, 14935, 307, 21085, 11, 934, 597, 321, 603, 751, 466], "temperature": 0.0, "avg_logprob": -0.26519793848837575, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.10455445945262909}, {"id": 4, "seek": 2844, "start": 28.44, "end": 32.92, "text": " the Cilium Service Mesh features, what we can do today, and what we're planning to", "tokens": [264, 383, 388, 2197, 9561, 376, 14935, 4122, 11, 437, 321, 393, 360, 965, 11, 293, 437, 321, 434, 5038, 281], "temperature": 0.0, "avg_logprob": -0.1759345671709846, "compression_ratio": 1.555045871559633, "no_speech_prob": 5.1511367928469554e-05}, {"id": 5, "seek": 2844, "start": 32.92, "end": 36.08, "text": " support in the future.", "tokens": [1406, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.1759345671709846, "compression_ratio": 1.555045871559633, "no_speech_prob": 5.1511367928469554e-05}, {"id": 6, "seek": 2844, "start": 36.08, "end": 40.480000000000004, "text": " Quick highlight of some upcoming features and some current features, and if we have time", "tokens": [12101, 5078, 295, 512, 11500, 4122, 293, 512, 2190, 4122, 11, 293, 498, 321, 362, 565], "temperature": 0.0, "avg_logprob": -0.1759345671709846, "compression_ratio": 1.555045871559633, "no_speech_prob": 5.1511367928469554e-05}, {"id": 7, "seek": 2844, "start": 40.480000000000004, "end": 44.760000000000005, "text": " I have a little demo to show how it works.", "tokens": [286, 362, 257, 707, 10723, 281, 855, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.1759345671709846, "compression_ratio": 1.555045871559633, "no_speech_prob": 5.1511367928469554e-05}, {"id": 8, "seek": 2844, "start": 44.760000000000005, "end": 50.16, "text": " Can I see some hands from you if you know EBPF?", "tokens": [1664, 286, 536, 512, 2377, 490, 291, 498, 291, 458, 50148, 47, 37, 30], "temperature": 0.0, "avg_logprob": -0.1759345671709846, "compression_ratio": 1.555045871559633, "no_speech_prob": 5.1511367928469554e-05}, {"id": 9, "seek": 2844, "start": 50.16, "end": 51.44, "text": " Quite a lot, good.", "tokens": [20464, 257, 688, 11, 665, 13], "temperature": 0.0, "avg_logprob": -0.1759345671709846, "compression_ratio": 1.555045871559633, "no_speech_prob": 5.1511367928469554e-05}, {"id": 10, "seek": 2844, "start": 51.44, "end": 53.72, "text": " How many of you know Cilium?", "tokens": [1012, 867, 295, 291, 458, 383, 388, 2197, 30], "temperature": 0.0, "avg_logprob": -0.1759345671709846, "compression_ratio": 1.555045871559633, "no_speech_prob": 5.1511367928469554e-05}, {"id": 11, "seek": 2844, "start": 53.72, "end": 54.72, "text": " Cool.", "tokens": [8561, 13], "temperature": 0.0, "avg_logprob": -0.1759345671709846, "compression_ratio": 1.555045871559633, "no_speech_prob": 5.1511367928469554e-05}, {"id": 12, "seek": 5472, "start": 54.72, "end": 58.519999999999996, "text": " OK, how many of you use Cilium, actually?", "tokens": [2264, 11, 577, 867, 295, 291, 764, 383, 388, 2197, 11, 767, 30], "temperature": 0.0, "avg_logprob": -0.18071038634688766, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.00015933244139887393}, {"id": 13, "seek": 5472, "start": 58.519999999999996, "end": 59.519999999999996, "text": " Not as much.", "tokens": [1726, 382, 709, 13], "temperature": 0.0, "avg_logprob": -0.18071038634688766, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.00015933244139887393}, {"id": 14, "seek": 5472, "start": 59.519999999999996, "end": 60.519999999999996, "text": " OK, cool.", "tokens": [2264, 11, 1627, 13], "temperature": 0.0, "avg_logprob": -0.18071038634688766, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.00015933244139887393}, {"id": 15, "seek": 5472, "start": 60.519999999999996, "end": 65.2, "text": " So, for the ones who don't know what EBPF is, I'm going to do an introduction here,", "tokens": [407, 11, 337, 264, 2306, 567, 500, 380, 458, 437, 50148, 47, 37, 307, 11, 286, 478, 516, 281, 360, 364, 9339, 510, 11], "temperature": 0.0, "avg_logprob": -0.18071038634688766, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.00015933244139887393}, {"id": 16, "seek": 5472, "start": 65.2, "end": 72.72, "text": " is EBPF is standing for Extended Berkeley Packet Filter, by itself that doesn't mean", "tokens": [307, 50148, 47, 37, 307, 4877, 337, 9881, 3502, 23684, 18466, 302, 39592, 11, 538, 2564, 300, 1177, 380, 914], "temperature": 0.0, "avg_logprob": -0.18071038634688766, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.00015933244139887393}, {"id": 17, "seek": 5472, "start": 72.72, "end": 78.92, "text": " a lot, but what we like to compare it with is what JavaScript is to the browser, EBPF", "tokens": [257, 688, 11, 457, 437, 321, 411, 281, 6794, 309, 365, 307, 437, 15778, 307, 281, 264, 11185, 11, 50148, 47, 37], "temperature": 0.0, "avg_logprob": -0.18071038634688766, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.00015933244139887393}, {"id": 18, "seek": 5472, "start": 78.92, "end": 80.72, "text": " is to the kernel.", "tokens": [307, 281, 264, 28256, 13], "temperature": 0.0, "avg_logprob": -0.18071038634688766, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.00015933244139887393}, {"id": 19, "seek": 8072, "start": 80.72, "end": 88.24, "text": " What that means is that using EBPF we can attach programs to kernel events, and for", "tokens": [708, 300, 1355, 307, 300, 1228, 50148, 47, 37, 321, 393, 5085, 4268, 281, 28256, 3931, 11, 293, 337], "temperature": 0.0, "avg_logprob": -0.12880936334299486, "compression_ratio": 2.0, "no_speech_prob": 0.00011488491873024032}, {"id": 20, "seek": 8072, "start": 88.24, "end": 93.72, "text": " the purpose of this session is that we can attach EBPF programs to kernel events related", "tokens": [264, 4334, 295, 341, 5481, 307, 300, 321, 393, 5085, 50148, 47, 37, 4268, 281, 28256, 3931, 4077], "temperature": 0.0, "avg_logprob": -0.12880936334299486, "compression_ratio": 2.0, "no_speech_prob": 0.00011488491873024032}, {"id": 21, "seek": 8072, "start": 93.72, "end": 100.36, "text": " to networking, so that's either a socket being opened, a network packet being sent on a network", "tokens": [281, 17985, 11, 370, 300, 311, 2139, 257, 19741, 885, 5625, 11, 257, 3209, 20300, 885, 2279, 322, 257, 3209], "temperature": 0.0, "avg_logprob": -0.12880936334299486, "compression_ratio": 2.0, "no_speech_prob": 0.00011488491873024032}, {"id": 22, "seek": 8072, "start": 100.36, "end": 105.2, "text": " device, that means that's a kernel event, and that means that we can attach a program", "tokens": [4302, 11, 300, 1355, 300, 311, 257, 28256, 2280, 11, 293, 300, 1355, 300, 321, 393, 5085, 257, 1461], "temperature": 0.0, "avg_logprob": -0.12880936334299486, "compression_ratio": 2.0, "no_speech_prob": 0.00011488491873024032}, {"id": 23, "seek": 10520, "start": 105.2, "end": 111.88, "text": " to it and we can get a metrics from that packet, for example, or we can do load balancing", "tokens": [281, 309, 293, 321, 393, 483, 257, 16367, 490, 300, 20300, 11, 337, 1365, 11, 420, 321, 393, 360, 3677, 22495], "temperature": 0.0, "avg_logprob": -0.15583627422650656, "compression_ratio": 1.5913461538461537, "no_speech_prob": 2.288989708176814e-05}, {"id": 24, "seek": 10520, "start": 111.88, "end": 114.48, "text": " and such.", "tokens": [293, 1270, 13], "temperature": 0.0, "avg_logprob": -0.15583627422650656, "compression_ratio": 1.5913461538461537, "no_speech_prob": 2.288989708176814e-05}, {"id": 25, "seek": 10520, "start": 114.48, "end": 120.76, "text": " So Cilium is built on EBPF, you don't need to be a network, or sorry, you don't need", "tokens": [407, 383, 388, 2197, 307, 3094, 322, 50148, 47, 37, 11, 291, 500, 380, 643, 281, 312, 257, 3209, 11, 420, 2597, 11, 291, 500, 380, 643], "temperature": 0.0, "avg_logprob": -0.15583627422650656, "compression_ratio": 1.5913461538461537, "no_speech_prob": 2.288989708176814e-05}, {"id": 26, "seek": 10520, "start": 120.76, "end": 125.44, "text": " to be an EBPF developer to actually work with Cilium.", "tokens": [281, 312, 364, 50148, 47, 37, 10754, 281, 767, 589, 365, 383, 388, 2197, 13], "temperature": 0.0, "avg_logprob": -0.15583627422650656, "compression_ratio": 1.5913461538461537, "no_speech_prob": 2.288989708176814e-05}, {"id": 27, "seek": 10520, "start": 125.44, "end": 130.96, "text": " Cilium abstracts this complexity on technology under the hood, so based on the configuration", "tokens": [383, 388, 2197, 12649, 82, 341, 14024, 322, 2899, 833, 264, 13376, 11, 370, 2361, 322, 264, 11694], "temperature": 0.0, "avg_logprob": -0.15583627422650656, "compression_ratio": 1.5913461538461537, "no_speech_prob": 2.288989708176814e-05}, {"id": 28, "seek": 13096, "start": 130.96, "end": 138.12, "text": " you set, Cilium will mount the required EBPF programs for you to run, and Cilium in short", "tokens": [291, 992, 11, 383, 388, 2197, 486, 3746, 264, 4739, 50148, 47, 37, 4268, 337, 291, 281, 1190, 11, 293, 383, 388, 2197, 294, 2099], "temperature": 0.0, "avg_logprob": -0.14829963387794864, "compression_ratio": 1.6485355648535565, "no_speech_prob": 5.8532434195512906e-05}, {"id": 29, "seek": 13096, "start": 138.12, "end": 144.4, "text": " provides networking and load balancing capabilities, security capabilities, and also a lot of observability", "tokens": [6417, 17985, 293, 3677, 22495, 10862, 11, 3825, 10862, 11, 293, 611, 257, 688, 295, 9951, 2310], "temperature": 0.0, "avg_logprob": -0.14829963387794864, "compression_ratio": 1.6485355648535565, "no_speech_prob": 5.8532434195512906e-05}, {"id": 30, "seek": 13096, "start": 144.4, "end": 148.08, "text": " capabilities using EBPF.", "tokens": [10862, 1228, 50148, 47, 37, 13], "temperature": 0.0, "avg_logprob": -0.14829963387794864, "compression_ratio": 1.6485355648535565, "no_speech_prob": 5.8532434195512906e-05}, {"id": 31, "seek": 13096, "start": 148.08, "end": 153.68, "text": " So this is the 30,000 feet view where we are today, we started with plain networking,", "tokens": [407, 341, 307, 264, 2217, 11, 1360, 3521, 1910, 689, 321, 366, 965, 11, 321, 1409, 365, 11121, 17985, 11], "temperature": 0.0, "avg_logprob": -0.14829963387794864, "compression_ratio": 1.6485355648535565, "no_speech_prob": 5.8532434195512906e-05}, {"id": 32, "seek": 13096, "start": 153.68, "end": 160.60000000000002, "text": " IPv6, IPv4 years ago, and now we expand that all the networking capabilities with BGP", "tokens": [8671, 85, 21, 11, 8671, 85, 19, 924, 2057, 11, 293, 586, 321, 5268, 300, 439, 264, 17985, 10862, 365, 363, 38, 47], "temperature": 0.0, "avg_logprob": -0.14829963387794864, "compression_ratio": 1.6485355648535565, "no_speech_prob": 5.8532434195512906e-05}, {"id": 33, "seek": 16060, "start": 160.6, "end": 167.96, "text": " implementations, Netfor6, 64, extended load balancing out of the box we're working on,", "tokens": [4445, 763, 11, 6188, 2994, 21, 11, 12145, 11, 10913, 3677, 22495, 484, 295, 264, 2424, 321, 434, 1364, 322, 11], "temperature": 0.0, "avg_logprob": -0.20540055774507068, "compression_ratio": 1.6199261992619927, "no_speech_prob": 7.009216642472893e-05}, {"id": 34, "seek": 16060, "start": 167.96, "end": 171.72, "text": " having GOBGP control playing fully supported with Cilium.", "tokens": [1419, 10365, 33, 38, 47, 1969, 2433, 4498, 8104, 365, 383, 388, 2197, 13], "temperature": 0.0, "avg_logprob": -0.20540055774507068, "compression_ratio": 1.6199261992619927, "no_speech_prob": 7.009216642472893e-05}, {"id": 35, "seek": 16060, "start": 171.72, "end": 177.68, "text": " On top of that we have an observability layer with our Hubble technology, which is a observability", "tokens": [1282, 1192, 295, 300, 321, 362, 364, 9951, 2310, 4583, 365, 527, 42317, 2899, 11, 597, 307, 257, 9951, 2310], "temperature": 0.0, "avg_logprob": -0.20540055774507068, "compression_ratio": 1.6199261992619927, "no_speech_prob": 7.009216642472893e-05}, {"id": 36, "seek": 16060, "start": 177.68, "end": 184.72, "text": " tool which provides service-to-service communication for your namespaces, so you can see what components,", "tokens": [2290, 597, 6417, 2643, 12, 1353, 12, 39279, 6101, 337, 428, 5288, 79, 2116, 11, 370, 291, 393, 536, 437, 6677, 11], "temperature": 0.0, "avg_logprob": -0.20540055774507068, "compression_ratio": 1.6199261992619927, "no_speech_prob": 7.009216642472893e-05}, {"id": 37, "seek": 16060, "start": 184.72, "end": 189.68, "text": " what services are talking to which services, after which you can make informed decisions,", "tokens": [437, 3328, 366, 1417, 281, 597, 3328, 11, 934, 597, 291, 393, 652, 11740, 5327, 11], "temperature": 0.0, "avg_logprob": -0.20540055774507068, "compression_ratio": 1.6199261992619927, "no_speech_prob": 7.009216642472893e-05}, {"id": 38, "seek": 18968, "start": 189.68, "end": 194.68, "text": " for example what kind of network policies you want to apply, also exporting metrics", "tokens": [337, 1365, 437, 733, 295, 3209, 7657, 291, 528, 281, 3079, 11, 611, 44686, 16367], "temperature": 0.0, "avg_logprob": -0.1968764018237106, "compression_ratio": 1.5671140939597314, "no_speech_prob": 5.8319870731793344e-05}, {"id": 39, "seek": 18968, "start": 194.68, "end": 200.32, "text": " to tools like Rafaana, and service mesh on top of that to provide authentication, layer", "tokens": [281, 3873, 411, 497, 19846, 2095, 11, 293, 2643, 17407, 322, 1192, 295, 300, 281, 2893, 26643, 11, 4583], "temperature": 0.0, "avg_logprob": -0.1968764018237106, "compression_ratio": 1.5671140939597314, "no_speech_prob": 5.8319870731793344e-05}, {"id": 40, "seek": 18968, "start": 200.32, "end": 203.84, "text": " 7 path-based routing and such.", "tokens": [1614, 3100, 12, 6032, 32722, 293, 1270, 13], "temperature": 0.0, "avg_logprob": -0.1968764018237106, "compression_ratio": 1.5671140939597314, "no_speech_prob": 5.8319870731793344e-05}, {"id": 41, "seek": 18968, "start": 203.84, "end": 207.08, "text": " On the right hand side we also have Kettergon, that's not something we'll talk about today,", "tokens": [1282, 264, 558, 1011, 1252, 321, 611, 362, 591, 27296, 10660, 11, 300, 311, 406, 746, 321, 603, 751, 466, 965, 11], "temperature": 0.0, "avg_logprob": -0.1968764018237106, "compression_ratio": 1.5671140939597314, "no_speech_prob": 5.8319870731793344e-05}, {"id": 42, "seek": 18968, "start": 207.08, "end": 212.04000000000002, "text": " but that's runtime security using EBPF, which is also very interesting, and rerun across", "tokens": [457, 300, 311, 34474, 3825, 1228, 50148, 47, 37, 11, 597, 307, 611, 588, 1880, 11, 293, 43819, 409, 2108], "temperature": 0.0, "avg_logprob": -0.1968764018237106, "compression_ratio": 1.5671140939597314, "no_speech_prob": 5.8319870731793344e-05}, {"id": 43, "seek": 18968, "start": 212.04000000000002, "end": 217.72, "text": " clouds, doesn't matter if it's on-prem or hybrid or multi-cluster, so it's agnostic", "tokens": [12193, 11, 1177, 380, 1871, 498, 309, 311, 322, 12, 29403, 420, 13051, 420, 4825, 12, 3474, 8393, 11, 370, 309, 311, 623, 77, 19634], "temperature": 0.0, "avg_logprob": -0.1968764018237106, "compression_ratio": 1.5671140939597314, "no_speech_prob": 5.8319870731793344e-05}, {"id": 44, "seek": 21772, "start": 217.72, "end": 222.08, "text": " of the platform, and supported by multiple cloud vendors.", "tokens": [295, 264, 3663, 11, 293, 8104, 538, 3866, 4588, 22056, 13], "temperature": 0.0, "avg_logprob": -0.21366536735308053, "compression_ratio": 1.553648068669528, "no_speech_prob": 3.702962203533389e-05}, {"id": 45, "seek": 21772, "start": 222.08, "end": 227.2, "text": " So as you may know, Google and false data plane V2 under the hood is actually Cilium.", "tokens": [407, 382, 291, 815, 458, 11, 3329, 293, 7908, 1412, 5720, 691, 17, 833, 264, 13376, 307, 767, 383, 388, 2197, 13], "temperature": 0.0, "avg_logprob": -0.21366536735308053, "compression_ratio": 1.553648068669528, "no_speech_prob": 3.702962203533389e-05}, {"id": 46, "seek": 21772, "start": 227.2, "end": 233.12, "text": " Microsoft has recently adopted Cilium as the default CNI for AKS clusters, and all their", "tokens": [8116, 575, 3938, 12175, 383, 388, 2197, 382, 264, 7576, 14589, 40, 337, 24789, 50, 23313, 11, 293, 439, 641], "temperature": 0.0, "avg_logprob": -0.21366536735308053, "compression_ratio": 1.553648068669528, "no_speech_prob": 3.702962203533389e-05}, {"id": 47, "seek": 21772, "start": 233.12, "end": 238.36, "text": " clusters will be migrated to Cilium, and AWS, EKS, anywhere by default is Cilium, so we", "tokens": [23313, 486, 312, 48329, 281, 383, 388, 2197, 11, 293, 17650, 11, 462, 31558, 11, 4992, 538, 7576, 307, 383, 388, 2197, 11, 370, 321], "temperature": 0.0, "avg_logprob": -0.21366536735308053, "compression_ratio": 1.553648068669528, "no_speech_prob": 3.702962203533389e-05}, {"id": 48, "seek": 21772, "start": 238.36, "end": 244.88, "text": " see huge adoption in the field of Cilium.", "tokens": [536, 2603, 19215, 294, 264, 2519, 295, 383, 388, 2197, 13], "temperature": 0.0, "avg_logprob": -0.21366536735308053, "compression_ratio": 1.553648068669528, "no_speech_prob": 3.702962203533389e-05}, {"id": 49, "seek": 24488, "start": 244.88, "end": 250.24, "text": " So let's talk about service mesh, so obviously if we talk about service mesh we talk about", "tokens": [407, 718, 311, 751, 466, 2643, 17407, 11, 370, 2745, 498, 321, 751, 466, 2643, 17407, 321, 751, 466], "temperature": 0.0, "avg_logprob": -0.15060012681143625, "compression_ratio": 1.8839285714285714, "no_speech_prob": 2.8896620278828777e-05}, {"id": 50, "seek": 24488, "start": 250.24, "end": 256.64, "text": " observing traffic, being able to secure traffic from application to application across clusters,", "tokens": [22107, 6419, 11, 885, 1075, 281, 7144, 6419, 490, 3861, 281, 3861, 2108, 23313, 11], "temperature": 0.0, "avg_logprob": -0.15060012681143625, "compression_ratio": 1.8839285714285714, "no_speech_prob": 2.8896620278828777e-05}, {"id": 51, "seek": 24488, "start": 256.64, "end": 264.12, "text": " doing traffic management, building resilience across applications across clouds.", "tokens": [884, 6419, 4592, 11, 2390, 19980, 2108, 5821, 2108, 12193, 13], "temperature": 0.0, "avg_logprob": -0.15060012681143625, "compression_ratio": 1.8839285714285714, "no_speech_prob": 2.8896620278828777e-05}, {"id": 52, "seek": 24488, "start": 264.12, "end": 269.52, "text": " Service mesh originally, if you needed that capabilities, originally you would program", "tokens": [9561, 17407, 7993, 11, 498, 291, 2978, 300, 10862, 11, 7993, 291, 576, 1461], "temperature": 0.0, "avg_logprob": -0.15060012681143625, "compression_ratio": 1.8839285714285714, "no_speech_prob": 2.8896620278828777e-05}, {"id": 53, "seek": 24488, "start": 269.52, "end": 274.32, "text": " your application either in Python or Go to get that observability.", "tokens": [428, 3861, 2139, 294, 15329, 420, 1037, 281, 483, 300, 9951, 2310, 13], "temperature": 0.0, "avg_logprob": -0.15060012681143625, "compression_ratio": 1.8839285714285714, "no_speech_prob": 2.8896620278828777e-05}, {"id": 54, "seek": 27432, "start": 274.32, "end": 278.8, "text": " That wasn't really useful because you have to maintain all those libraries to get the", "tokens": [663, 2067, 380, 534, 4420, 570, 291, 362, 281, 6909, 439, 729, 15148, 281, 483, 264], "temperature": 0.0, "avg_logprob": -0.1502890946730128, "compression_ratio": 1.7027027027027026, "no_speech_prob": 3.858670243062079e-05}, {"id": 55, "seek": 27432, "start": 278.8, "end": 280.64, "text": " information you need.", "tokens": [1589, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.1502890946730128, "compression_ratio": 1.7027027027027026, "no_speech_prob": 3.858670243062079e-05}, {"id": 56, "seek": 27432, "start": 280.64, "end": 285.2, "text": " That's where the sidecars came in, right, so that they abstract that complexity from", "tokens": [663, 311, 689, 264, 1252, 66, 685, 1361, 294, 11, 558, 11, 370, 300, 436, 12649, 300, 14024, 490], "temperature": 0.0, "avg_logprob": -0.1502890946730128, "compression_ratio": 1.7027027027027026, "no_speech_prob": 3.858670243062079e-05}, {"id": 57, "seek": 27432, "start": 285.2, "end": 291.52, "text": " the application to have a standard sidecar implementation to monitor traffic, to be able", "tokens": [264, 3861, 281, 362, 257, 3832, 1252, 6166, 11420, 281, 6002, 6419, 11, 281, 312, 1075], "temperature": 0.0, "avg_logprob": -0.1502890946730128, "compression_ratio": 1.7027027027027026, "no_speech_prob": 3.858670243062079e-05}, {"id": 58, "seek": 27432, "start": 291.52, "end": 296.03999999999996, "text": " to route traffic, and to be able to extract metrics from that traffic.", "tokens": [281, 7955, 6419, 11, 293, 281, 312, 1075, 281, 8947, 16367, 490, 300, 6419, 13], "temperature": 0.0, "avg_logprob": -0.1502890946730128, "compression_ratio": 1.7027027027027026, "no_speech_prob": 3.858670243062079e-05}, {"id": 59, "seek": 27432, "start": 296.03999999999996, "end": 302.48, "text": " However, now with Cilium our goal is to move as close to the kernel as we already run in", "tokens": [2908, 11, 586, 365, 383, 388, 2197, 527, 3387, 307, 281, 1286, 382, 1998, 281, 264, 28256, 382, 321, 1217, 1190, 294], "temperature": 0.0, "avg_logprob": -0.1502890946730128, "compression_ratio": 1.7027027027027026, "no_speech_prob": 3.858670243062079e-05}, {"id": 60, "seek": 30248, "start": 302.48, "end": 308.48, "text": " kernel with EBPF, so we're moving from a sidecar model to the kernel, and where we", "tokens": [28256, 365, 50148, 47, 37, 11, 370, 321, 434, 2684, 490, 257, 1252, 6166, 2316, 281, 264, 28256, 11, 293, 689, 321], "temperature": 0.0, "avg_logprob": -0.16899427553502525, "compression_ratio": 1.49009900990099, "no_speech_prob": 2.9593045837827958e-05}, {"id": 61, "seek": 30248, "start": 308.48, "end": 313.6, "text": " can we will support it using EBPF.", "tokens": [393, 321, 486, 1406, 309, 1228, 50148, 47, 37, 13], "temperature": 0.0, "avg_logprob": -0.16899427553502525, "compression_ratio": 1.49009900990099, "no_speech_prob": 2.9593045837827958e-05}, {"id": 62, "seek": 30248, "start": 313.6, "end": 320.08000000000004, "text": " The only part which is not yet there is Layer 7, so all the low balancing capabilities,", "tokens": [440, 787, 644, 597, 307, 406, 1939, 456, 307, 35166, 1614, 11, 370, 439, 264, 2295, 22495, 10862, 11], "temperature": 0.0, "avg_logprob": -0.16899427553502525, "compression_ratio": 1.49009900990099, "no_speech_prob": 2.9593045837827958e-05}, {"id": 63, "seek": 30248, "start": 320.08000000000004, "end": 328.44, "text": " routing capabilities in terms of IP to IP metrics are already available with Cilium using EBPF.", "tokens": [32722, 10862, 294, 2115, 295, 8671, 281, 8671, 16367, 366, 1217, 2435, 365, 383, 388, 2197, 1228, 50148, 47, 37, 13], "temperature": 0.0, "avg_logprob": -0.16899427553502525, "compression_ratio": 1.49009900990099, "no_speech_prob": 2.9593045837827958e-05}, {"id": 64, "seek": 32844, "start": 328.44, "end": 337.76, "text": " Layer 7 routing is not yet in EBPF for multiple reasons, of which one is that EBPF has constraints", "tokens": [35166, 1614, 32722, 307, 406, 1939, 294, 50148, 47, 37, 337, 3866, 4112, 11, 295, 597, 472, 307, 300, 50148, 47, 37, 575, 18491], "temperature": 0.0, "avg_logprob": -0.15810574018038237, "compression_ratio": 1.564516129032258, "no_speech_prob": 1.77954225364374e-05}, {"id": 65, "seek": 32844, "start": 337.76, "end": 343.2, "text": " in terms of how big a program can be, obviously it runs in kernel space, so it has constraints", "tokens": [294, 2115, 295, 577, 955, 257, 1461, 393, 312, 11, 2745, 309, 6676, 294, 28256, 1901, 11, 370, 309, 575, 18491], "temperature": 0.0, "avg_logprob": -0.15810574018038237, "compression_ratio": 1.564516129032258, "no_speech_prob": 1.77954225364374e-05}, {"id": 66, "seek": 32844, "start": 343.2, "end": 348.96, "text": " for a good reason, but in the future maybe we can even transport complex Layer 7 routing", "tokens": [337, 257, 665, 1778, 11, 457, 294, 264, 2027, 1310, 321, 393, 754, 5495, 3997, 35166, 1614, 32722], "temperature": 0.0, "avg_logprob": -0.15810574018038237, "compression_ratio": 1.564516129032258, "no_speech_prob": 1.77954225364374e-05}, {"id": 67, "seek": 32844, "start": 348.96, "end": 351.44, "text": " in EBPF.", "tokens": [294, 50148, 47, 37, 13], "temperature": 0.0, "avg_logprob": -0.15810574018038237, "compression_ratio": 1.564516129032258, "no_speech_prob": 1.77954225364374e-05}, {"id": 68, "seek": 35144, "start": 351.44, "end": 358.88, "text": " However, we already provide Layer 7 visibility and observability in using Cilium and EBPF,", "tokens": [2908, 11, 321, 1217, 2893, 35166, 1614, 19883, 293, 9951, 2310, 294, 1228, 383, 388, 2197, 293, 50148, 47, 37, 11], "temperature": 0.0, "avg_logprob": -0.2084517595244617, "compression_ratio": 1.6336633663366336, "no_speech_prob": 1.6392570614698343e-05}, {"id": 69, "seek": 35144, "start": 358.88, "end": 363.4, "text": " we already have the capabilities to inspect traffic using EBPF.", "tokens": [321, 1217, 362, 264, 10862, 281, 15018, 6419, 1228, 50148, 47, 37, 13], "temperature": 0.0, "avg_logprob": -0.2084517595244617, "compression_ratio": 1.6336633663366336, "no_speech_prob": 1.6392570614698343e-05}, {"id": 70, "seek": 35144, "start": 363.4, "end": 368.2, "text": " We can already do the low balancing with the creep process replacement.", "tokens": [492, 393, 1217, 360, 264, 2295, 22495, 365, 264, 9626, 1399, 14419, 13], "temperature": 0.0, "avg_logprob": -0.2084517595244617, "compression_ratio": 1.6336633663366336, "no_speech_prob": 1.6392570614698343e-05}, {"id": 71, "seek": 35144, "start": 368.2, "end": 374.32, "text": " The only part is the Layer 7, but the visibility of traffic, so HTTP traffic and such is", "tokens": [440, 787, 644, 307, 264, 35166, 1614, 11, 457, 264, 19883, 295, 6419, 11, 370, 33283, 6419, 293, 1270, 307], "temperature": 0.0, "avg_logprob": -0.2084517595244617, "compression_ratio": 1.6336633663366336, "no_speech_prob": 1.6392570614698343e-05}, {"id": 72, "seek": 35144, "start": 374.32, "end": 375.48, "text": " already there.", "tokens": [1217, 456, 13], "temperature": 0.0, "avg_logprob": -0.2084517595244617, "compression_ratio": 1.6336633663366336, "no_speech_prob": 1.6392570614698343e-05}, {"id": 73, "seek": 37548, "start": 375.48, "end": 382.16, "text": " So surface mesh capabilities are extending those capabilities moving forward.", "tokens": [407, 3753, 17407, 10862, 366, 24360, 729, 10862, 2684, 2128, 13], "temperature": 0.0, "avg_logprob": -0.17394339617560892, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.107485099462792e-05}, {"id": 74, "seek": 37548, "start": 382.16, "end": 383.32, "text": " So how does it work?", "tokens": [407, 577, 775, 309, 589, 30], "temperature": 0.0, "avg_logprob": -0.17394339617560892, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.107485099462792e-05}, {"id": 75, "seek": 37548, "start": 383.32, "end": 389.76, "text": " So some of you may know that Cilium runs as an agent, as a demon set on the nodes, it", "tokens": [407, 512, 295, 291, 815, 458, 300, 383, 388, 2197, 6676, 382, 364, 9461, 11, 382, 257, 14283, 992, 322, 264, 13891, 11, 309], "temperature": 0.0, "avg_logprob": -0.17394339617560892, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.107485099462792e-05}, {"id": 76, "seek": 37548, "start": 389.76, "end": 395.8, "text": " programs the nodes to be mounting the EBPF programs for the capabilities you need, and", "tokens": [4268, 264, 13891, 281, 312, 22986, 264, 50148, 47, 37, 4268, 337, 264, 10862, 291, 643, 11, 293], "temperature": 0.0, "avg_logprob": -0.17394339617560892, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.107485099462792e-05}, {"id": 77, "seek": 37548, "start": 395.8, "end": 400.48, "text": " we have an embedded Envoy running inside the Cilium agent.", "tokens": [321, 362, 364, 16741, 2193, 35176, 2614, 1854, 264, 383, 388, 2197, 9461, 13], "temperature": 0.0, "avg_logprob": -0.17394339617560892, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.107485099462792e-05}, {"id": 78, "seek": 40048, "start": 400.48, "end": 407.12, "text": " This is a narrow down Envoy proxy in the agent for networking capabilities, and we", "tokens": [639, 307, 257, 9432, 760, 2193, 35176, 29690, 294, 264, 9461, 337, 17985, 10862, 11, 293, 321], "temperature": 0.0, "avg_logprob": -0.1603552003701528, "compression_ratio": 1.7033898305084745, "no_speech_prob": 1.9779190552071668e-05}, {"id": 79, "seek": 40048, "start": 407.12, "end": 413.84000000000003, "text": " leverage this Envoy proxy on the node level to do surface mesh capabilities, so all the", "tokens": [13982, 341, 2193, 35176, 29690, 322, 264, 9984, 1496, 281, 360, 3753, 17407, 10862, 11, 370, 439, 264], "temperature": 0.0, "avg_logprob": -0.1603552003701528, "compression_ratio": 1.7033898305084745, "no_speech_prob": 1.9779190552071668e-05}, {"id": 80, "seek": 40048, "start": 413.84000000000003, "end": 417.88, "text": " things like the HTTP path routing and such.", "tokens": [721, 411, 264, 33283, 3100, 32722, 293, 1270, 13], "temperature": 0.0, "avg_logprob": -0.1603552003701528, "compression_ratio": 1.7033898305084745, "no_speech_prob": 1.9779190552071668e-05}, {"id": 81, "seek": 40048, "start": 417.88, "end": 422.16, "text": " So for each namespace you would create, and where you create, for example, an ingress resource", "tokens": [407, 337, 1184, 5288, 17940, 291, 576, 1884, 11, 293, 689, 291, 1884, 11, 337, 1365, 11, 364, 3957, 735, 7684], "temperature": 0.0, "avg_logprob": -0.1603552003701528, "compression_ratio": 1.7033898305084745, "no_speech_prob": 1.9779190552071668e-05}, {"id": 82, "seek": 40048, "start": 422.16, "end": 428.76, "text": " or a gateway resource, that means that a listener will be created through the Envoy for that", "tokens": [420, 257, 28532, 7684, 11, 300, 1355, 300, 257, 31569, 486, 312, 2942, 807, 264, 2193, 35176, 337, 300], "temperature": 0.0, "avg_logprob": -0.1603552003701528, "compression_ratio": 1.7033898305084745, "no_speech_prob": 1.9779190552071668e-05}, {"id": 83, "seek": 42876, "start": 428.76, "end": 432.52, "text": " specific namespace for that specific workload.", "tokens": [2685, 5288, 17940, 337, 300, 2685, 20139, 13], "temperature": 0.0, "avg_logprob": -0.12584914284190912, "compression_ratio": 1.632034632034632, "no_speech_prob": 2.8252663469174877e-05}, {"id": 84, "seek": 42876, "start": 432.52, "end": 437.68, "text": " And we leverage C groups and stuff to have separation as well for the security reasons", "tokens": [400, 321, 13982, 383, 3935, 293, 1507, 281, 362, 14634, 382, 731, 337, 264, 3825, 4112], "temperature": 0.0, "avg_logprob": -0.12584914284190912, "compression_ratio": 1.632034632034632, "no_speech_prob": 2.8252663469174877e-05}, {"id": 85, "seek": 42876, "start": 437.68, "end": 443.76, "text": " to not be able to have traffic across namespaces as such.", "tokens": [281, 406, 312, 1075, 281, 362, 6419, 2108, 5288, 79, 2116, 382, 1270, 13], "temperature": 0.0, "avg_logprob": -0.12584914284190912, "compression_ratio": 1.632034632034632, "no_speech_prob": 2.8252663469174877e-05}, {"id": 86, "seek": 42876, "start": 443.76, "end": 449.96, "text": " So what is different with Cilium's surface mesh compared to other surface mesh implementations?", "tokens": [407, 437, 307, 819, 365, 383, 388, 2197, 311, 3753, 17407, 5347, 281, 661, 3753, 17407, 4445, 763, 30], "temperature": 0.0, "avg_logprob": -0.12584914284190912, "compression_ratio": 1.632034632034632, "no_speech_prob": 2.8252663469174877e-05}, {"id": 87, "seek": 42876, "start": 449.96, "end": 454.84, "text": " First of all, our goal is to reduce operational complexity by removing sidecars, resource", "tokens": [2386, 295, 439, 11, 527, 3387, 307, 281, 5407, 16607, 14024, 538, 12720, 1252, 66, 685, 11, 7684], "temperature": 0.0, "avg_logprob": -0.12584914284190912, "compression_ratio": 1.632034632034632, "no_speech_prob": 2.8252663469174877e-05}, {"id": 88, "seek": 45484, "start": 454.84, "end": 462.52, "text": " usage, reduced, better performance, and avoid sidecar startup shutdown race conditions.", "tokens": [14924, 11, 9212, 11, 1101, 3389, 11, 293, 5042, 1252, 6166, 18578, 34927, 4569, 4487, 13], "temperature": 0.0, "avg_logprob": -0.19450639088948568, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.1758328987052664e-05}, {"id": 89, "seek": 45484, "start": 462.52, "end": 466.56, "text": " So obviously if you're not running sidecars at scale, this makes a huge difference.", "tokens": [407, 2745, 498, 291, 434, 406, 2614, 1252, 66, 685, 412, 4373, 11, 341, 1669, 257, 2603, 2649, 13], "temperature": 0.0, "avg_logprob": -0.19450639088948568, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.1758328987052664e-05}, {"id": 90, "seek": 45484, "start": 466.56, "end": 471.44, "text": " You don't have all the sidecar pods running alongside your normal pods, that will save", "tokens": [509, 500, 380, 362, 439, 264, 1252, 6166, 31925, 2614, 12385, 428, 2710, 31925, 11, 300, 486, 3155], "temperature": 0.0, "avg_logprob": -0.19450639088948568, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.1758328987052664e-05}, {"id": 91, "seek": 45484, "start": 471.44, "end": 477.91999999999996, "text": " memory, that will save CPU, that will save connection tracking, et cetera, et cetera.", "tokens": [4675, 11, 300, 486, 3155, 13199, 11, 300, 486, 3155, 4984, 11603, 11, 1030, 11458, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.19450639088948568, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.1758328987052664e-05}, {"id": 92, "seek": 45484, "start": 477.91999999999996, "end": 480.32, "text": " So a lot more efficient.", "tokens": [407, 257, 688, 544, 7148, 13], "temperature": 0.0, "avg_logprob": -0.19450639088948568, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.1758328987052664e-05}, {"id": 93, "seek": 48032, "start": 480.32, "end": 484.68, "text": " And also in terms of latency, running a sidecar has a cost.", "tokens": [400, 611, 294, 2115, 295, 27043, 11, 2614, 257, 1252, 6166, 575, 257, 2063, 13], "temperature": 0.0, "avg_logprob": -0.10823506171550226, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.3832234799338039e-05}, {"id": 94, "seek": 48032, "start": 484.68, "end": 489.96, "text": " So in this diagram you see that an application wants to send traffic to another application.", "tokens": [407, 294, 341, 10686, 291, 536, 300, 364, 3861, 2738, 281, 2845, 6419, 281, 1071, 3861, 13], "temperature": 0.0, "avg_logprob": -0.10823506171550226, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.3832234799338039e-05}, {"id": 95, "seek": 48032, "start": 489.96, "end": 494.68, "text": " What that means technically is that it goes through the TCP IP stack three times with", "tokens": [708, 300, 1355, 12120, 307, 300, 309, 1709, 807, 264, 48965, 8671, 8630, 1045, 1413, 365], "temperature": 0.0, "avg_logprob": -0.10823506171550226, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.3832234799338039e-05}, {"id": 96, "seek": 48032, "start": 494.68, "end": 495.68, "text": " the sidecar.", "tokens": [264, 1252, 6166, 13], "temperature": 0.0, "avg_logprob": -0.10823506171550226, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.3832234799338039e-05}, {"id": 97, "seek": 48032, "start": 495.68, "end": 500.56, "text": " First from the app, then inbound in the sidecar where the sidecar does its processing, and", "tokens": [2386, 490, 264, 724, 11, 550, 294, 18767, 294, 264, 1252, 6166, 689, 264, 1252, 6166, 775, 1080, 9007, 11, 293], "temperature": 0.0, "avg_logprob": -0.10823506171550226, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.3832234799338039e-05}, {"id": 98, "seek": 48032, "start": 500.56, "end": 505.6, "text": " then external from the sidecar to the physical network device to hit the network to reach", "tokens": [550, 8320, 490, 264, 1252, 6166, 281, 264, 4001, 3209, 4302, 281, 2045, 264, 3209, 281, 2524], "temperature": 0.0, "avg_logprob": -0.10823506171550226, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.3832234799338039e-05}, {"id": 99, "seek": 48032, "start": 505.6, "end": 508.96, "text": " another node.", "tokens": [1071, 9984, 13], "temperature": 0.0, "avg_logprob": -0.10823506171550226, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.3832234799338039e-05}, {"id": 100, "seek": 50896, "start": 508.96, "end": 517.92, "text": " With EBPF we are able to shortcut that connection and improve the latency because we can detect", "tokens": [2022, 50148, 47, 37, 321, 366, 1075, 281, 24822, 300, 4984, 293, 3470, 264, 27043, 570, 321, 393, 5531], "temperature": 0.0, "avg_logprob": -0.12470986983355353, "compression_ratio": 1.766497461928934, "no_speech_prob": 4.973727845936082e-05}, {"id": 101, "seek": 50896, "start": 517.92, "end": 523.04, "text": " that traffic and we can see if it's destined for the physical network or it should be routed", "tokens": [300, 6419, 293, 321, 393, 536, 498, 309, 311, 33169, 337, 264, 4001, 3209, 420, 309, 820, 312, 4020, 292], "temperature": 0.0, "avg_logprob": -0.12470986983355353, "compression_ratio": 1.766497461928934, "no_speech_prob": 4.973727845936082e-05}, {"id": 102, "seek": 50896, "start": 523.04, "end": 526.04, "text": " to the proxy.", "tokens": [281, 264, 29690, 13], "temperature": 0.0, "avg_logprob": -0.12470986983355353, "compression_ratio": 1.766497461928934, "no_speech_prob": 4.973727845936082e-05}, {"id": 103, "seek": 50896, "start": 526.04, "end": 532.1999999999999, "text": " So once this app opens the socket using EBPF we can shortcut that connection to the physical", "tokens": [407, 1564, 341, 724, 9870, 264, 19741, 1228, 50148, 47, 37, 321, 393, 24822, 300, 4984, 281, 264, 4001], "temperature": 0.0, "avg_logprob": -0.12470986983355353, "compression_ratio": 1.766497461928934, "no_speech_prob": 4.973727845936082e-05}, {"id": 104, "seek": 50896, "start": 532.1999999999999, "end": 536.52, "text": " network device to be routed on the physical network.", "tokens": [3209, 4302, 281, 312, 4020, 292, 322, 264, 4001, 3209, 13], "temperature": 0.0, "avg_logprob": -0.12470986983355353, "compression_ratio": 1.766497461928934, "no_speech_prob": 4.973727845936082e-05}, {"id": 105, "seek": 53652, "start": 536.52, "end": 542.52, "text": " If we need layer seven processing, that means that using EBPF we can shortcut the connection", "tokens": [759, 321, 643, 4583, 3407, 9007, 11, 300, 1355, 300, 1228, 50148, 47, 37, 321, 393, 24822, 264, 4984], "temperature": 0.0, "avg_logprob": -0.16152607126438873, "compression_ratio": 1.5856573705179282, "no_speech_prob": 1.1389479368517641e-05}, {"id": 106, "seek": 53652, "start": 542.52, "end": 546.56, "text": " on the socket layer directly to the envoy proxy where the envoy proxy on the node does", "tokens": [322, 264, 19741, 4583, 3838, 281, 264, 35351, 29690, 689, 264, 35351, 29690, 322, 264, 9984, 775], "temperature": 0.0, "avg_logprob": -0.16152607126438873, "compression_ratio": 1.5856573705179282, "no_speech_prob": 1.1389479368517641e-05}, {"id": 107, "seek": 53652, "start": 546.56, "end": 551.52, "text": " his HTTP routing and then forwards the traffic again on the physical network.", "tokens": [702, 33283, 32722, 293, 550, 30126, 264, 6419, 797, 322, 264, 4001, 3209, 13], "temperature": 0.0, "avg_logprob": -0.16152607126438873, "compression_ratio": 1.5856573705179282, "no_speech_prob": 1.1389479368517641e-05}, {"id": 108, "seek": 53652, "start": 551.52, "end": 555.04, "text": " So a lot less hops there.", "tokens": [407, 257, 688, 1570, 47579, 456, 13], "temperature": 0.0, "avg_logprob": -0.16152607126438873, "compression_ratio": 1.5856573705179282, "no_speech_prob": 1.1389479368517641e-05}, {"id": 109, "seek": 53652, "start": 555.04, "end": 559.96, "text": " And it means that latency is much, much improved because we're not going through this TCP IP", "tokens": [400, 309, 1355, 300, 27043, 307, 709, 11, 709, 9689, 570, 321, 434, 406, 516, 807, 341, 48965, 8671], "temperature": 0.0, "avg_logprob": -0.16152607126438873, "compression_ratio": 1.5856573705179282, "no_speech_prob": 1.1389479368517641e-05}, {"id": 110, "seek": 53652, "start": 559.96, "end": 562.8, "text": " stack multiple times.", "tokens": [8630, 3866, 1413, 13], "temperature": 0.0, "avg_logprob": -0.16152607126438873, "compression_ratio": 1.5856573705179282, "no_speech_prob": 1.1389479368517641e-05}, {"id": 111, "seek": 56280, "start": 562.8, "end": 568.28, "text": " In terms of throughput there's also a small difference because we can push more packets", "tokens": [682, 2115, 295, 44629, 456, 311, 611, 257, 1359, 2649, 570, 321, 393, 2944, 544, 30364], "temperature": 0.0, "avg_logprob": -0.16539486635078504, "compression_ratio": 1.7611336032388665, "no_speech_prob": 1.85114022315247e-05}, {"id": 112, "seek": 56280, "start": 568.28, "end": 573.8399999999999, "text": " and in terms of pod ready performance this is also a consideration at scale because when", "tokens": [293, 294, 2115, 295, 2497, 1919, 3389, 341, 307, 611, 257, 12381, 412, 4373, 570, 562], "temperature": 0.0, "avg_logprob": -0.16539486635078504, "compression_ratio": 1.7611336032388665, "no_speech_prob": 1.85114022315247e-05}, {"id": 113, "seek": 56280, "start": 573.8399999999999, "end": 577.8399999999999, "text": " you're scaling out your applications you always, with traditional sidecars, you need to wait", "tokens": [291, 434, 21589, 484, 428, 5821, 291, 1009, 11, 365, 5164, 1252, 66, 685, 11, 291, 643, 281, 1699], "temperature": 0.0, "avg_logprob": -0.16539486635078504, "compression_ratio": 1.7611336032388665, "no_speech_prob": 1.85114022315247e-05}, {"id": 114, "seek": 56280, "start": 577.8399999999999, "end": 583.4799999999999, "text": " for the sidecar to be spun up as well and to be ready to serve connections for that", "tokens": [337, 264, 1252, 6166, 281, 312, 37038, 493, 382, 731, 293, 281, 312, 1919, 281, 4596, 9271, 337, 300], "temperature": 0.0, "avg_logprob": -0.16539486635078504, "compression_ratio": 1.7611336032388665, "no_speech_prob": 1.85114022315247e-05}, {"id": 115, "seek": 56280, "start": 583.4799999999999, "end": 584.9599999999999, "text": " application.", "tokens": [3861, 13], "temperature": 0.0, "avg_logprob": -0.16539486635078504, "compression_ratio": 1.7611336032388665, "no_speech_prob": 1.85114022315247e-05}, {"id": 116, "seek": 56280, "start": 584.9599999999999, "end": 589.0799999999999, "text": " So without the sidecars with Cilium service mess it's already there.", "tokens": [407, 1553, 264, 1252, 66, 685, 365, 383, 388, 2197, 2643, 2082, 309, 311, 1217, 456, 13], "temperature": 0.0, "avg_logprob": -0.16539486635078504, "compression_ratio": 1.7611336032388665, "no_speech_prob": 1.85114022315247e-05}, {"id": 117, "seek": 58908, "start": 589.08, "end": 593.88, "text": " It's running on the node, it's embedded in the proxy so once you scale out your application", "tokens": [467, 311, 2614, 322, 264, 9984, 11, 309, 311, 16741, 294, 264, 29690, 370, 1564, 291, 4373, 484, 428, 3861], "temperature": 0.0, "avg_logprob": -0.1665299203660753, "compression_ratio": 1.6360294117647058, "no_speech_prob": 5.9612262703012675e-05}, {"id": 118, "seek": 58908, "start": 593.88, "end": 600.12, "text": " the proxy immediately on that node can serve connections.", "tokens": [264, 29690, 4258, 322, 300, 9984, 393, 4596, 9271, 13], "temperature": 0.0, "avg_logprob": -0.1665299203660753, "compression_ratio": 1.6360294117647058, "no_speech_prob": 5.9612262703012675e-05}, {"id": 119, "seek": 58908, "start": 600.12, "end": 604.1600000000001, "text": " So in short Cilium service mess provides traffic management, observability, security", "tokens": [407, 294, 2099, 383, 388, 2197, 2643, 2082, 6417, 6419, 4592, 11, 9951, 2310, 11, 3825], "temperature": 0.0, "avg_logprob": -0.1665299203660753, "compression_ratio": 1.6360294117647058, "no_speech_prob": 5.9612262703012675e-05}, {"id": 120, "seek": 58908, "start": 604.1600000000001, "end": 605.5400000000001, "text": " and resilience.", "tokens": [293, 19980, 13], "temperature": 0.0, "avg_logprob": -0.1665299203660753, "compression_ratio": 1.6360294117647058, "no_speech_prob": 5.9612262703012675e-05}, {"id": 121, "seek": 58908, "start": 605.5400000000001, "end": 610.5200000000001, "text": " The goal is to bring your own control plane or we are not developing a control plane on", "tokens": [440, 3387, 307, 281, 1565, 428, 1065, 1969, 5720, 420, 321, 366, 406, 6416, 257, 1969, 5720, 322], "temperature": 0.0, "avg_logprob": -0.1665299203660753, "compression_ratio": 1.6360294117647058, "no_speech_prob": 5.9612262703012675e-05}, {"id": 122, "seek": 58908, "start": 610.5200000000001, "end": 611.8000000000001, "text": " our own.", "tokens": [527, 1065, 13], "temperature": 0.0, "avg_logprob": -0.1665299203660753, "compression_ratio": 1.6360294117647058, "no_speech_prob": 5.9612262703012675e-05}, {"id": 123, "seek": 58908, "start": 611.8000000000001, "end": 618.0400000000001, "text": " What it means is that you can already use Ingress resources with Cilium 1.13 will support Gateway", "tokens": [708, 309, 1355, 307, 300, 291, 393, 1217, 764, 682, 3091, 3593, 365, 383, 388, 2197, 502, 13, 7668, 486, 1406, 48394], "temperature": 0.0, "avg_logprob": -0.1665299203660753, "compression_ratio": 1.6360294117647058, "no_speech_prob": 5.9612262703012675e-05}, {"id": 124, "seek": 61804, "start": 618.04, "end": 619.28, "text": " API.", "tokens": [9362, 13], "temperature": 0.0, "avg_logprob": -0.14792322229456017, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010420785838505253}, {"id": 125, "seek": 61804, "start": 619.28, "end": 625.3199999999999, "text": " We are working on Spiffy integration so with the 1.13 release actually the ground work", "tokens": [492, 366, 1364, 322, 1738, 3661, 88, 10980, 370, 365, 264, 502, 13, 7668, 4374, 767, 264, 2727, 589], "temperature": 0.0, "avg_logprob": -0.14792322229456017, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010420785838505253}, {"id": 126, "seek": 61804, "start": 625.3199999999999, "end": 630.36, "text": " for MTLS and Spiffy integration is already there.", "tokens": [337, 37333, 19198, 293, 1738, 3661, 88, 10980, 307, 1217, 456, 13], "temperature": 0.0, "avg_logprob": -0.14792322229456017, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010420785838505253}, {"id": 127, "seek": 61804, "start": 630.36, "end": 636.48, "text": " You are not really able to use it yet but the goal is to support both MTLS and Spiffy", "tokens": [509, 366, 406, 534, 1075, 281, 764, 309, 1939, 457, 264, 3387, 307, 281, 1406, 1293, 37333, 19198, 293, 1738, 3661, 88], "temperature": 0.0, "avg_logprob": -0.14792322229456017, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010420785838505253}, {"id": 128, "seek": 61804, "start": 636.48, "end": 641.7199999999999, "text": " using Cilium network policies so you can reference for example a Spiffy ID as a source", "tokens": [1228, 383, 388, 2197, 3209, 7657, 370, 291, 393, 6408, 337, 1365, 257, 1738, 3661, 88, 7348, 382, 257, 4009], "temperature": 0.0, "avg_logprob": -0.14792322229456017, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010420785838505253}, {"id": 129, "seek": 61804, "start": 641.7199999999999, "end": 647.48, "text": " and destination using Cilium network policies and then under the hood the Cilium agent part", "tokens": [293, 12236, 1228, 383, 388, 2197, 3209, 7657, 293, 550, 833, 264, 13376, 264, 383, 388, 2197, 9461, 644], "temperature": 0.0, "avg_logprob": -0.14792322229456017, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010420785838505253}, {"id": 130, "seek": 64748, "start": 647.48, "end": 655.08, "text": " will connect to spy reserver where that identity is tracked and confirm if that's allowed.", "tokens": [486, 1745, 281, 20752, 725, 38241, 689, 300, 6575, 307, 31703, 293, 9064, 498, 300, 311, 4350, 13], "temperature": 0.0, "avg_logprob": -0.18206813209935238, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.52242389251478e-05}, {"id": 131, "seek": 64748, "start": 655.08, "end": 660.48, "text": " In terms of observability you can leverage the already available observability with Grafana", "tokens": [682, 2115, 295, 9951, 2310, 291, 393, 13982, 264, 1217, 2435, 9951, 2310, 365, 8985, 69, 2095], "temperature": 0.0, "avg_logprob": -0.18206813209935238, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.52242389251478e-05}, {"id": 132, "seek": 64748, "start": 660.48, "end": 666.52, "text": " or Hubble if you need to export events you can use scene platforms such as Splunk and", "tokens": [420, 42317, 498, 291, 643, 281, 10725, 3931, 291, 393, 764, 4145, 9473, 1270, 382, 19788, 3197, 293], "temperature": 0.0, "avg_logprob": -0.18206813209935238, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.52242389251478e-05}, {"id": 133, "seek": 64748, "start": 666.52, "end": 671.44, "text": " open telemetry is also supported.", "tokens": [1269, 4304, 5537, 627, 307, 611, 8104, 13], "temperature": 0.0, "avg_logprob": -0.18206813209935238, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.52242389251478e-05}, {"id": 134, "seek": 64748, "start": 671.44, "end": 675.16, "text": " If you are new, if you are running new classes you have an option you can run Cilium and", "tokens": [759, 291, 366, 777, 11, 498, 291, 366, 2614, 777, 5359, 291, 362, 364, 3614, 291, 393, 1190, 383, 388, 2197, 293], "temperature": 0.0, "avg_logprob": -0.18206813209935238, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.52242389251478e-05}, {"id": 135, "seek": 67516, "start": 675.16, "end": 681.3199999999999, "text": " you can already use Cilium service mesh out of the box this is obviously the preferred", "tokens": [291, 393, 1217, 764, 383, 388, 2197, 2643, 17407, 484, 295, 264, 2424, 341, 307, 2745, 264, 16494], "temperature": 0.0, "avg_logprob": -0.14313494591485887, "compression_ratio": 1.7488151658767772, "no_speech_prob": 2.7889387638424523e-05}, {"id": 136, "seek": 67516, "start": 681.3199999999999, "end": 688.1999999999999, "text": " method but if you are running already an Istio based implementation there is still a lot", "tokens": [3170, 457, 498, 291, 366, 2614, 1217, 364, 12810, 1004, 2361, 11420, 456, 307, 920, 257, 688], "temperature": 0.0, "avg_logprob": -0.14313494591485887, "compression_ratio": 1.7488151658767772, "no_speech_prob": 2.7889387638424523e-05}, {"id": 137, "seek": 67516, "start": 688.1999999999999, "end": 696.0799999999999, "text": " of benefit to run Cilium under the hood there as well because for example we already encrypt", "tokens": [295, 5121, 281, 1190, 383, 388, 2197, 833, 264, 13376, 456, 382, 731, 570, 337, 1365, 321, 1217, 17972, 662], "temperature": 0.0, "avg_logprob": -0.14313494591485887, "compression_ratio": 1.7488151658767772, "no_speech_prob": 2.7889387638424523e-05}, {"id": 138, "seek": 67516, "start": 696.0799999999999, "end": 702.56, "text": " the connectivity between the sidecar from an Istio based implementation towards the destination", "tokens": [264, 21095, 1296, 264, 1252, 6166, 490, 364, 12810, 1004, 2361, 11420, 3030, 264, 12236], "temperature": 0.0, "avg_logprob": -0.14313494591485887, "compression_ratio": 1.7488151658767772, "no_speech_prob": 2.7889387638424523e-05}, {"id": 139, "seek": 67516, "start": 702.56, "end": 703.56, "text": " pod.", "tokens": [2497, 13], "temperature": 0.0, "avg_logprob": -0.14313494591485887, "compression_ratio": 1.7488151658767772, "no_speech_prob": 2.7889387638424523e-05}, {"id": 140, "seek": 70356, "start": 703.56, "end": 710.92, "text": " What I mean by that is that when you run sidecars, when you run MTLS between applications that", "tokens": [708, 286, 914, 538, 300, 307, 300, 562, 291, 1190, 1252, 66, 685, 11, 562, 291, 1190, 37333, 19198, 1296, 5821, 300], "temperature": 0.0, "avg_logprob": -0.15837332568591153, "compression_ratio": 1.6822429906542056, "no_speech_prob": 5.089267870062031e-05}, {"id": 141, "seek": 70356, "start": 710.92, "end": 716.76, "text": " connectivity may be secure but the connection between the sidecar and the actual destination", "tokens": [21095, 815, 312, 7144, 457, 264, 4984, 1296, 264, 1252, 6166, 293, 264, 3539, 12236], "temperature": 0.0, "avg_logprob": -0.15837332568591153, "compression_ratio": 1.6822429906542056, "no_speech_prob": 5.089267870062031e-05}, {"id": 142, "seek": 70356, "start": 716.76, "end": 722.7199999999999, "text": " is encrypted on the node so anyone with specific privileges on a node could potentially listen", "tokens": [307, 36663, 322, 264, 9984, 370, 2878, 365, 2685, 32588, 322, 257, 9984, 727, 7263, 2140], "temperature": 0.0, "avg_logprob": -0.15837332568591153, "compression_ratio": 1.6822429906542056, "no_speech_prob": 5.089267870062031e-05}, {"id": 143, "seek": 70356, "start": 722.7199999999999, "end": 728.3599999999999, "text": " on that virtual interface and e-drop traffic and that's obviously not secure.", "tokens": [322, 300, 6374, 9226, 293, 308, 12, 23332, 6419, 293, 300, 311, 2745, 406, 7144, 13], "temperature": 0.0, "avg_logprob": -0.15837332568591153, "compression_ratio": 1.6822429906542056, "no_speech_prob": 5.089267870062031e-05}, {"id": 144, "seek": 72836, "start": 728.36, "end": 733.28, "text": " The running Cilium under the hood already gives you the benefit because we can encrypt", "tokens": [440, 2614, 383, 388, 2197, 833, 264, 13376, 1217, 2709, 291, 264, 5121, 570, 321, 393, 17972, 662], "temperature": 0.0, "avg_logprob": -0.14637590065980569, "compression_ratio": 1.5071090047393365, "no_speech_prob": 5.3598068916471675e-05}, {"id": 145, "seek": 72836, "start": 733.28, "end": 741.5600000000001, "text": " on layer 4 directly on the socket layer to the destination pod obviously.", "tokens": [322, 4583, 1017, 3838, 322, 264, 19741, 4583, 281, 264, 12236, 2497, 2745, 13], "temperature": 0.0, "avg_logprob": -0.14637590065980569, "compression_ratio": 1.5071090047393365, "no_speech_prob": 5.3598068916471675e-05}, {"id": 146, "seek": 72836, "start": 741.5600000000001, "end": 747.88, "text": " With 1.12 so currently we have 1.12 available since I think 7 months.", "tokens": [2022, 502, 13, 4762, 370, 4362, 321, 362, 502, 13, 4762, 2435, 1670, 286, 519, 1614, 2493, 13], "temperature": 0.0, "avg_logprob": -0.14637590065980569, "compression_ratio": 1.5071090047393365, "no_speech_prob": 5.3598068916471675e-05}, {"id": 147, "seek": 72836, "start": 747.88, "end": 752.48, "text": " We already have a production ready Cilium service mesh, a conformant ingress controller", "tokens": [492, 1217, 362, 257, 4265, 1919, 383, 388, 2197, 2643, 17407, 11, 257, 18975, 394, 3957, 735, 10561], "temperature": 0.0, "avg_logprob": -0.14637590065980569, "compression_ratio": 1.5071090047393365, "no_speech_prob": 5.3598068916471675e-05}, {"id": 148, "seek": 75248, "start": 752.48, "end": 758.6800000000001, "text": " which you can use for HDD path routing, canary releases and such.", "tokens": [597, 291, 393, 764, 337, 12149, 35, 3100, 32722, 11, 393, 822, 16952, 293, 1270, 13], "temperature": 0.0, "avg_logprob": -0.2559135214796344, "compression_ratio": 1.504, "no_speech_prob": 3.377423854544759e-05}, {"id": 149, "seek": 75248, "start": 758.6800000000001, "end": 763.9200000000001, "text": " You can use Kubernetes as your service mesh control plane, fromisius metrics, open telemetry", "tokens": [509, 393, 764, 23145, 382, 428, 2643, 17407, 1969, 5720, 11, 490, 271, 4872, 16367, 11, 1269, 4304, 5537, 627], "temperature": 0.0, "avg_logprob": -0.2559135214796344, "compression_ratio": 1.504, "no_speech_prob": 3.377423854544759e-05}, {"id": 150, "seek": 75248, "start": 763.9200000000001, "end": 765.8000000000001, "text": " is supported.", "tokens": [307, 8104, 13], "temperature": 0.0, "avg_logprob": -0.2559135214796344, "compression_ratio": 1.504, "no_speech_prob": 3.377423854544759e-05}, {"id": 151, "seek": 75248, "start": 765.8000000000001, "end": 771.12, "text": " For power users we have Cilium Envoy Convict and Cilium cluster wide Envoy Convict CRDs", "tokens": [1171, 1347, 5022, 321, 362, 383, 388, 2197, 2193, 35176, 2656, 85, 985, 293, 383, 388, 2197, 13630, 4874, 2193, 35176, 2656, 85, 985, 14123, 35, 82], "temperature": 0.0, "avg_logprob": -0.2559135214796344, "compression_ratio": 1.504, "no_speech_prob": 3.377423854544759e-05}, {"id": 152, "seek": 75248, "start": 771.12, "end": 772.52, "text": " available.", "tokens": [2435, 13], "temperature": 0.0, "avg_logprob": -0.2559135214796344, "compression_ratio": 1.504, "no_speech_prob": 3.377423854544759e-05}, {"id": 153, "seek": 75248, "start": 772.52, "end": 777.36, "text": " These are temporarily I would say because the goal is to replace all that capabilities", "tokens": [1981, 366, 23750, 286, 576, 584, 570, 264, 3387, 307, 281, 7406, 439, 300, 10862], "temperature": 0.0, "avg_logprob": -0.2559135214796344, "compression_ratio": 1.504, "no_speech_prob": 3.377423854544759e-05}, {"id": 154, "seek": 75248, "start": 777.36, "end": 780.72, "text": " with Gateway API.", "tokens": [365, 48394, 9362, 13], "temperature": 0.0, "avg_logprob": -0.2559135214796344, "compression_ratio": 1.504, "no_speech_prob": 3.377423854544759e-05}, {"id": 155, "seek": 78072, "start": 780.72, "end": 784.6800000000001, "text": " And we're releasing more and more extended Grafana dashboards for layer 7 visibility", "tokens": [400, 321, 434, 16327, 544, 293, 544, 10913, 8985, 69, 2095, 8240, 17228, 337, 4583, 1614, 19883], "temperature": 0.0, "avg_logprob": -0.14993701662336076, "compression_ratio": 1.5825688073394495, "no_speech_prob": 3.007056875503622e-05}, {"id": 156, "seek": 78072, "start": 784.6800000000001, "end": 791.28, "text": " so you can actually see between service to service what kind of metrics there are and", "tokens": [370, 291, 393, 767, 536, 1296, 2643, 281, 2643, 437, 733, 295, 16367, 456, 366, 293], "temperature": 0.0, "avg_logprob": -0.14993701662336076, "compression_ratio": 1.5825688073394495, "no_speech_prob": 3.007056875503622e-05}, {"id": 157, "seek": 78072, "start": 791.28, "end": 797.6, "text": " what the latencies are and what return codes are, so golden signals.", "tokens": [437, 264, 4465, 6464, 366, 293, 437, 2736, 14211, 366, 11, 370, 9729, 12354, 13], "temperature": 0.0, "avg_logprob": -0.14993701662336076, "compression_ratio": 1.5825688073394495, "no_speech_prob": 3.007056875503622e-05}, {"id": 158, "seek": 78072, "start": 797.6, "end": 804.96, "text": " So the roadmap for 1.13 and we're very close for releasing 1.13, expected somewhere this", "tokens": [407, 264, 35738, 337, 502, 13, 7668, 293, 321, 434, 588, 1998, 337, 16327, 502, 13, 7668, 11, 5176, 4079, 341], "temperature": 0.0, "avg_logprob": -0.14993701662336076, "compression_ratio": 1.5825688073394495, "no_speech_prob": 3.007056875503622e-05}, {"id": 159, "seek": 78072, "start": 804.96, "end": 807.6, "text": " month hopefully.", "tokens": [1618, 4696, 13], "temperature": 0.0, "avg_logprob": -0.14993701662336076, "compression_ratio": 1.5825688073394495, "no_speech_prob": 3.007056875503622e-05}, {"id": 160, "seek": 80760, "start": 807.6, "end": 815.24, "text": " You can already try a release candidate for Cilium 1.13 which includes a Gateway API support", "tokens": [509, 393, 1217, 853, 257, 4374, 11532, 337, 383, 388, 2197, 502, 13, 7668, 597, 5974, 257, 48394, 9362, 1406], "temperature": 0.0, "avg_logprob": -0.14123828844590622, "compression_ratio": 1.4715447154471544, "no_speech_prob": 2.683672573766671e-05}, {"id": 161, "seek": 80760, "start": 815.24, "end": 821.88, "text": " for HTTP routing, TLS termination, HTTP traffic splitting and waiting.", "tokens": [337, 33283, 32722, 11, 314, 19198, 1433, 2486, 11, 33283, 6419, 30348, 293, 3806, 13], "temperature": 0.0, "avg_logprob": -0.14123828844590622, "compression_ratio": 1.4715447154471544, "no_speech_prob": 2.683672573766671e-05}, {"id": 162, "seek": 80760, "start": 821.88, "end": 828.16, "text": " So this allows you to do percentage based routing or canary releases as such without", "tokens": [407, 341, 4045, 291, 281, 360, 9668, 2361, 32722, 420, 393, 822, 16952, 382, 1270, 1553], "temperature": 0.0, "avg_logprob": -0.14123828844590622, "compression_ratio": 1.4715447154471544, "no_speech_prob": 2.683672573766671e-05}, {"id": 163, "seek": 80760, "start": 828.16, "end": 831.24, "text": " configuring Cilium Envoy Convict resources.", "tokens": [6662, 1345, 383, 388, 2197, 2193, 35176, 2656, 85, 985, 3593, 13], "temperature": 0.0, "avg_logprob": -0.14123828844590622, "compression_ratio": 1.4715447154471544, "no_speech_prob": 2.683672573766671e-05}, {"id": 164, "seek": 80760, "start": 831.24, "end": 835.28, "text": " And also the capability to have multiple ingresses parallel balancer.", "tokens": [400, 611, 264, 13759, 281, 362, 3866, 3957, 40352, 8952, 3119, 28347, 13], "temperature": 0.0, "avg_logprob": -0.14123828844590622, "compression_ratio": 1.4715447154471544, "no_speech_prob": 2.683672573766671e-05}, {"id": 165, "seek": 83528, "start": 835.28, "end": 840.36, "text": " What that means is that currently when you create a Cilium ingress we rely on the hood", "tokens": [708, 300, 1355, 307, 300, 4362, 562, 291, 1884, 257, 383, 388, 2197, 3957, 735, 321, 10687, 322, 264, 13376], "temperature": 0.0, "avg_logprob": -0.19495117421052893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 2.1478144844877534e-05}, {"id": 166, "seek": 83528, "start": 840.36, "end": 846.28, "text": " on a low balancer to attract traffic and forward that to the proxy.", "tokens": [322, 257, 2295, 3119, 28347, 281, 5049, 6419, 293, 2128, 300, 281, 264, 29690, 13], "temperature": 0.0, "avg_logprob": -0.19495117421052893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 2.1478144844877534e-05}, {"id": 167, "seek": 83528, "start": 846.28, "end": 851.9599999999999, "text": " Obviously at scale having a low balancer for each ingress, especially in clouds is expensive.", "tokens": [7580, 412, 4373, 1419, 257, 2295, 3119, 28347, 337, 1184, 3957, 735, 11, 2318, 294, 12193, 307, 5124, 13], "temperature": 0.0, "avg_logprob": -0.19495117421052893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 2.1478144844877534e-05}, {"id": 168, "seek": 83528, "start": 851.9599999999999, "end": 856.8, "text": " So this with an annotation we allow multiple ingresses per low balancer so you can save", "tokens": [407, 341, 365, 364, 48654, 321, 2089, 3866, 3957, 40352, 680, 2295, 3119, 28347, 370, 291, 393, 3155], "temperature": 0.0, "avg_logprob": -0.19495117421052893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 2.1478144844877534e-05}, {"id": 169, "seek": 83528, "start": 856.8, "end": 860.64, "text": " cost there.", "tokens": [2063, 456, 13], "temperature": 0.0, "avg_logprob": -0.19495117421052893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 2.1478144844877534e-05}, {"id": 170, "seek": 83528, "start": 860.64, "end": 863.36, "text": " So how am I doing at the time?", "tokens": [407, 577, 669, 286, 884, 412, 264, 565, 30], "temperature": 0.0, "avg_logprob": -0.19495117421052893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 2.1478144844877534e-05}, {"id": 171, "seek": 86336, "start": 863.36, "end": 865.8000000000001, "text": " Good features.", "tokens": [2205, 4122, 13], "temperature": 0.0, "avg_logprob": -0.14741253345570665, "compression_ratio": 1.6863636363636363, "no_speech_prob": 5.530759153771214e-05}, {"id": 172, "seek": 86336, "start": 865.8000000000001, "end": 872.8000000000001, "text": " So today ingress 1.12, also with services we are having support for annotations.", "tokens": [407, 965, 3957, 735, 502, 13, 4762, 11, 611, 365, 3328, 321, 366, 1419, 1406, 337, 25339, 763, 13], "temperature": 0.0, "avg_logprob": -0.14741253345570665, "compression_ratio": 1.6863636363636363, "no_speech_prob": 5.530759153771214e-05}, {"id": 173, "seek": 86336, "start": 872.8000000000001, "end": 880.36, "text": " So imagine you have received traffic from your ingress, you forward it to a service.", "tokens": [407, 3811, 291, 362, 4613, 6419, 490, 428, 3957, 735, 11, 291, 2128, 309, 281, 257, 2643, 13], "temperature": 0.0, "avg_logprob": -0.14741253345570665, "compression_ratio": 1.6863636363636363, "no_speech_prob": 5.530759153771214e-05}, {"id": 174, "seek": 86336, "start": 880.36, "end": 885.88, "text": " That means we support annotations on a simple cluster IP to forward traffic for example", "tokens": [663, 1355, 321, 1406, 25339, 763, 322, 257, 2199, 13630, 8671, 281, 2128, 6419, 337, 1365], "temperature": 0.0, "avg_logprob": -0.14741253345570665, "compression_ratio": 1.6863636363636363, "no_speech_prob": 5.530759153771214e-05}, {"id": 175, "seek": 86336, "start": 885.88, "end": 888.48, "text": " to a specific endpoint.", "tokens": [281, 257, 2685, 35795, 13], "temperature": 0.0, "avg_logprob": -0.14741253345570665, "compression_ratio": 1.6863636363636363, "no_speech_prob": 5.530759153771214e-05}, {"id": 176, "seek": 86336, "start": 888.48, "end": 892.64, "text": " If you know what Cilium cluster mesh is we can connect Cilium across clusters.", "tokens": [759, 291, 458, 437, 383, 388, 2197, 13630, 17407, 307, 321, 393, 1745, 383, 388, 2197, 2108, 23313, 13], "temperature": 0.0, "avg_logprob": -0.14741253345570665, "compression_ratio": 1.6863636363636363, "no_speech_prob": 5.530759153771214e-05}, {"id": 177, "seek": 89264, "start": 892.64, "end": 897.92, "text": " With simple annotations you can have even higher availability of services across clusters.", "tokens": [2022, 2199, 25339, 763, 291, 393, 362, 754, 2946, 17945, 295, 3328, 2108, 23313, 13], "temperature": 0.0, "avg_logprob": -0.13365388833559477, "compression_ratio": 1.701195219123506, "no_speech_prob": 2.38294178416254e-05}, {"id": 178, "seek": 89264, "start": 897.92, "end": 902.8, "text": " Gateway API which I will show a bit later and the Envoy Convict.", "tokens": [48394, 9362, 597, 286, 486, 855, 257, 857, 1780, 293, 264, 2193, 35176, 2656, 85, 985, 13], "temperature": 0.0, "avg_logprob": -0.13365388833559477, "compression_ratio": 1.701195219123506, "no_speech_prob": 2.38294178416254e-05}, {"id": 179, "seek": 89264, "start": 902.8, "end": 908.36, "text": " So this is a simple example of ingress and this is also something I will show in a demo.", "tokens": [407, 341, 307, 257, 2199, 1365, 295, 3957, 735, 293, 341, 307, 611, 746, 286, 486, 855, 294, 257, 10723, 13], "temperature": 0.0, "avg_logprob": -0.13365388833559477, "compression_ratio": 1.701195219123506, "no_speech_prob": 2.38294178416254e-05}, {"id": 180, "seek": 89264, "start": 908.36, "end": 914.84, "text": " You have an ingress and from a specific path you want to forward traffic to specific service.", "tokens": [509, 362, 364, 3957, 735, 293, 490, 257, 2685, 3100, 291, 528, 281, 2128, 6419, 281, 2685, 2643, 13], "temperature": 0.0, "avg_logprob": -0.13365388833559477, "compression_ratio": 1.701195219123506, "no_speech_prob": 2.38294178416254e-05}, {"id": 181, "seek": 89264, "start": 914.84, "end": 921.2, "text": " We also support GRPC so you can also have specific GRPC URLs to be forwarded to specific", "tokens": [492, 611, 1406, 10903, 12986, 370, 291, 393, 611, 362, 2685, 10903, 12986, 43267, 281, 312, 2128, 292, 281, 2685], "temperature": 0.0, "avg_logprob": -0.13365388833559477, "compression_ratio": 1.701195219123506, "no_speech_prob": 2.38294178416254e-05}, {"id": 182, "seek": 92120, "start": 921.2, "end": 922.76, "text": " services.", "tokens": [3328, 13], "temperature": 0.0, "avg_logprob": -0.2192354683924203, "compression_ratio": 1.5381355932203389, "no_speech_prob": 2.7309166398481466e-05}, {"id": 183, "seek": 92120, "start": 922.76, "end": 929.1600000000001, "text": " TLS termination to terminate TLS using secrets, using ingress.", "tokens": [314, 19198, 1433, 2486, 281, 10761, 473, 314, 19198, 1228, 14093, 11, 1228, 3957, 735, 13], "temperature": 0.0, "avg_logprob": -0.2192354683924203, "compression_ratio": 1.5381355932203389, "no_speech_prob": 2.7309166398481466e-05}, {"id": 184, "seek": 92120, "start": 929.1600000000001, "end": 937.24, "text": " A question I get a lot is what about SSL pass-through, that's on roadmap so keep that in mind.", "tokens": [316, 1168, 286, 483, 257, 688, 307, 437, 466, 12238, 43, 1320, 12, 11529, 11, 300, 311, 322, 35738, 370, 1066, 300, 294, 1575, 13], "temperature": 0.0, "avg_logprob": -0.2192354683924203, "compression_ratio": 1.5381355932203389, "no_speech_prob": 2.7309166398481466e-05}, {"id": 185, "seek": 92120, "start": 937.24, "end": 942.08, "text": " And obviously new in 1.13 is Gateway API and how it looks like is you will configure a", "tokens": [400, 2745, 777, 294, 502, 13, 7668, 307, 48394, 9362, 293, 577, 309, 1542, 411, 307, 291, 486, 22162, 257], "temperature": 0.0, "avg_logprob": -0.2192354683924203, "compression_ratio": 1.5381355932203389, "no_speech_prob": 2.7309166398481466e-05}, {"id": 186, "seek": 92120, "start": 942.08, "end": 943.96, "text": " Gateway resource.", "tokens": [48394, 7684, 13], "temperature": 0.0, "avg_logprob": -0.2192354683924203, "compression_ratio": 1.5381355932203389, "no_speech_prob": 2.7309166398481466e-05}, {"id": 187, "seek": 92120, "start": 943.96, "end": 949.8000000000001, "text": " You specify the Gateway class name for Cilium to make sure that the Gateway is created and", "tokens": [509, 16500, 264, 48394, 1508, 1315, 337, 383, 388, 2197, 281, 652, 988, 300, 264, 48394, 307, 2942, 293], "temperature": 0.0, "avg_logprob": -0.2192354683924203, "compression_ratio": 1.5381355932203389, "no_speech_prob": 2.7309166398481466e-05}, {"id": 188, "seek": 94980, "start": 949.8, "end": 952.52, "text": " maintained through Cilium and then create listeners.", "tokens": [17578, 807, 383, 388, 2197, 293, 550, 1884, 23274, 13], "temperature": 0.0, "avg_logprob": -0.19097718738374256, "compression_ratio": 1.5309734513274336, "no_speech_prob": 7.940085197333246e-05}, {"id": 189, "seek": 94980, "start": 952.52, "end": 955.9599999999999, "text": " So in this case an HTTP listener on port 80.", "tokens": [407, 294, 341, 1389, 364, 33283, 31569, 322, 2436, 4688, 13], "temperature": 0.0, "avg_logprob": -0.19097718738374256, "compression_ratio": 1.5309734513274336, "no_speech_prob": 7.940085197333246e-05}, {"id": 190, "seek": 94980, "start": 955.9599999999999, "end": 960.5999999999999, "text": " Then additionally you create multiple HTTP routes, one or more.", "tokens": [1396, 43181, 291, 1884, 3866, 33283, 18242, 11, 472, 420, 544, 13], "temperature": 0.0, "avg_logprob": -0.19097718738374256, "compression_ratio": 1.5309734513274336, "no_speech_prob": 7.940085197333246e-05}, {"id": 191, "seek": 94980, "start": 960.5999999999999, "end": 966.8399999999999, "text": " And this specify for example a path prefix for values forward slash details to be forwarded", "tokens": [400, 341, 16500, 337, 1365, 257, 3100, 46969, 337, 4190, 2128, 17330, 4365, 281, 312, 2128, 292], "temperature": 0.0, "avg_logprob": -0.19097718738374256, "compression_ratio": 1.5309734513274336, "no_speech_prob": 7.940085197333246e-05}, {"id": 192, "seek": 94980, "start": 966.8399999999999, "end": 972.64, "text": " to a backend reference service called details.", "tokens": [281, 257, 38087, 6408, 2643, 1219, 4365, 13], "temperature": 0.0, "avg_logprob": -0.19097718738374256, "compression_ratio": 1.5309734513274336, "no_speech_prob": 7.940085197333246e-05}, {"id": 193, "seek": 94980, "start": 972.64, "end": 975.4799999999999, "text": " In terms of TLS termination, same constructs.", "tokens": [682, 2115, 295, 314, 19198, 1433, 2486, 11, 912, 7690, 82, 13], "temperature": 0.0, "avg_logprob": -0.19097718738374256, "compression_ratio": 1.5309734513274336, "no_speech_prob": 7.940085197333246e-05}, {"id": 194, "seek": 97548, "start": 975.48, "end": 981.84, "text": " You can also have for example a host name in there to only accept traffic for this given", "tokens": [509, 393, 611, 362, 337, 1365, 257, 3975, 1315, 294, 456, 281, 787, 3241, 6419, 337, 341, 2212], "temperature": 0.0, "avg_logprob": -0.11994436899820964, "compression_ratio": 1.75, "no_speech_prob": 2.6235846235067584e-05}, {"id": 195, "seek": 97548, "start": 981.84, "end": 988.6, "text": " host name and you reference a secret in the Gateway resource and then in the HTTP routes", "tokens": [3975, 1315, 293, 291, 6408, 257, 4054, 294, 264, 48394, 7684, 293, 550, 294, 264, 33283, 18242], "temperature": 0.0, "avg_logprob": -0.11994436899820964, "compression_ratio": 1.75, "no_speech_prob": 2.6235846235067584e-05}, {"id": 196, "seek": 97548, "start": 988.6, "end": 995.6, "text": " you will specify the host name, you will reference the Gateway you want to use and then again", "tokens": [291, 486, 16500, 264, 3975, 1315, 11, 291, 486, 6408, 264, 48394, 291, 528, 281, 764, 293, 550, 797], "temperature": 0.0, "avg_logprob": -0.11994436899820964, "compression_ratio": 1.75, "no_speech_prob": 2.6235846235067584e-05}, {"id": 197, "seek": 97548, "start": 995.6, "end": 1001.24, "text": " a path prefix for example to forward to specific service.", "tokens": [257, 3100, 46969, 337, 1365, 281, 2128, 281, 2685, 2643, 13], "temperature": 0.0, "avg_logprob": -0.11994436899820964, "compression_ratio": 1.75, "no_speech_prob": 2.6235846235067584e-05}, {"id": 198, "seek": 100124, "start": 1001.24, "end": 1006.12, "text": " And then traffic splitting, very simple, also using HTTP routes.", "tokens": [400, 550, 6419, 30348, 11, 588, 2199, 11, 611, 1228, 33283, 18242, 13], "temperature": 0.0, "avg_logprob": -0.15789101544548484, "compression_ratio": 1.5520361990950227, "no_speech_prob": 1.4467117580352351e-05}, {"id": 199, "seek": 100124, "start": 1006.12, "end": 1013.12, "text": " Again referencing your Gateway, a path prefix and then you have in this case an Echo 1 and", "tokens": [3764, 40582, 428, 48394, 11, 257, 3100, 46969, 293, 550, 291, 362, 294, 341, 1389, 364, 31887, 502, 293], "temperature": 0.0, "avg_logprob": -0.15789101544548484, "compression_ratio": 1.5520361990950227, "no_speech_prob": 1.4467117580352351e-05}, {"id": 200, "seek": 100124, "start": 1013.12, "end": 1019.76, "text": " Echo 2 service where you want to introduce slowly Echo 2 and in this case 25% of that", "tokens": [31887, 568, 2643, 689, 291, 528, 281, 5366, 5692, 31887, 568, 293, 294, 341, 1389, 3552, 4, 295, 300], "temperature": 0.0, "avg_logprob": -0.15789101544548484, "compression_ratio": 1.5520361990950227, "no_speech_prob": 1.4467117580352351e-05}, {"id": 201, "seek": 100124, "start": 1019.76, "end": 1025.32, "text": " traffic will be forwarded to the Echo 2 service.", "tokens": [6419, 486, 312, 2128, 292, 281, 264, 31887, 568, 2643, 13], "temperature": 0.0, "avg_logprob": -0.15789101544548484, "compression_ratio": 1.5520361990950227, "no_speech_prob": 1.4467117580352351e-05}, {"id": 202, "seek": 100124, "start": 1025.32, "end": 1028.04, "text": " And this is the example what I talked about earlier.", "tokens": [400, 341, 307, 264, 1365, 437, 286, 2825, 466, 3071, 13], "temperature": 0.0, "avg_logprob": -0.15789101544548484, "compression_ratio": 1.5520361990950227, "no_speech_prob": 1.4467117580352351e-05}, {"id": 203, "seek": 102804, "start": 1028.04, "end": 1034.36, "text": " Using simple annotations you can extend service miscapabilities by annotating services.", "tokens": [11142, 2199, 25339, 763, 291, 393, 10101, 2643, 3346, 9485, 6167, 538, 25339, 990, 3328, 13], "temperature": 0.0, "avg_logprob": -0.1865717831779929, "compression_ratio": 1.7361702127659575, "no_speech_prob": 7.333813846344128e-05}, {"id": 204, "seek": 102804, "start": 1034.36, "end": 1040.76, "text": " So in this case this service will receive traffic for GRPC and we can attach low balancing", "tokens": [407, 294, 341, 1389, 341, 2643, 486, 4774, 6419, 337, 10903, 12986, 293, 321, 393, 5085, 2295, 22495], "temperature": 0.0, "avg_logprob": -0.1865717831779929, "compression_ratio": 1.7361702127659575, "no_speech_prob": 7.333813846344128e-05}, {"id": 205, "seek": 102804, "start": 1040.76, "end": 1047.44, "text": " modes for in this case weighted least requests to be forwarded to backend endpoints.", "tokens": [14068, 337, 294, 341, 1389, 32807, 1935, 12475, 281, 312, 2128, 292, 281, 38087, 917, 20552, 13], "temperature": 0.0, "avg_logprob": -0.1865717831779929, "compression_ratio": 1.7361702127659575, "no_speech_prob": 7.333813846344128e-05}, {"id": 206, "seek": 102804, "start": 1047.44, "end": 1052.6399999999999, "text": " And using multi cluster capabilities you can extend these capabilities across two or more", "tokens": [400, 1228, 4825, 13630, 10862, 291, 393, 10101, 613, 10862, 2108, 732, 420, 544], "temperature": 0.0, "avg_logprob": -0.1865717831779929, "compression_ratio": 1.7361702127659575, "no_speech_prob": 7.333813846344128e-05}, {"id": 207, "seek": 102804, "start": 1052.6399999999999, "end": 1056.32, "text": " clusters depending on your cluster mesh configuration.", "tokens": [23313, 5413, 322, 428, 13630, 17407, 11694, 13], "temperature": 0.0, "avg_logprob": -0.1865717831779929, "compression_ratio": 1.7361702127659575, "no_speech_prob": 7.333813846344128e-05}, {"id": 208, "seek": 105632, "start": 1056.32, "end": 1061.48, "text": " And canary roll out, so you can even introduce new clusters, have the new version of your", "tokens": [400, 393, 822, 3373, 484, 11, 370, 291, 393, 754, 5366, 777, 23313, 11, 362, 264, 777, 3037, 295, 428], "temperature": 0.0, "avg_logprob": -0.20955083703482022, "compression_ratio": 1.7166666666666666, "no_speech_prob": 4.1610521293478087e-05}, {"id": 209, "seek": 105632, "start": 1061.48, "end": 1065.52, "text": " application running on the new cluster, so you're absolutely sure that you have no resource", "tokens": [3861, 2614, 322, 264, 777, 13630, 11, 370, 291, 434, 3122, 988, 300, 291, 362, 572, 7684], "temperature": 0.0, "avg_logprob": -0.20955083703482022, "compression_ratio": 1.7166666666666666, "no_speech_prob": 4.1610521293478087e-05}, {"id": 210, "seek": 105632, "start": 1065.52, "end": 1070.36, "text": " contingent on your original cluster and then on the service annotate traffic to forward", "tokens": [27820, 317, 322, 428, 3380, 13630, 293, 550, 322, 264, 2643, 25339, 473, 6419, 281, 2128], "temperature": 0.0, "avg_logprob": -0.20955083703482022, "compression_ratio": 1.7166666666666666, "no_speech_prob": 4.1610521293478087e-05}, {"id": 211, "seek": 105632, "start": 1070.36, "end": 1077.28, "text": " slowly to remote cluster before you do the flip over.", "tokens": [5692, 281, 8607, 13630, 949, 291, 360, 264, 7929, 670, 13], "temperature": 0.0, "avg_logprob": -0.20955083703482022, "compression_ratio": 1.7166666666666666, "no_speech_prob": 4.1610521293478087e-05}, {"id": 212, "seek": 105632, "start": 1077.28, "end": 1083.2, "text": " So this concludes the presentation part, so for example when you want to know more about", "tokens": [407, 341, 24643, 264, 5860, 644, 11, 370, 337, 1365, 562, 291, 528, 281, 458, 544, 466], "temperature": 0.0, "avg_logprob": -0.20955083703482022, "compression_ratio": 1.7166666666666666, "no_speech_prob": 4.1610521293478087e-05}, {"id": 213, "seek": 108320, "start": 1083.2, "end": 1088.1200000000001, "text": " Cilium go to the Cilium community, I encourage you to join our Slack channel if you have", "tokens": [383, 388, 2197, 352, 281, 264, 383, 388, 2197, 1768, 11, 286, 5373, 291, 281, 3917, 527, 37211, 2269, 498, 291, 362], "temperature": 0.0, "avg_logprob": -0.18614935105846775, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.00019474298460409045}, {"id": 214, "seek": 108320, "start": 1088.1200000000001, "end": 1093.72, "text": " any questions, our team is there as well to answer questions for in Slack, any issues", "tokens": [604, 1651, 11, 527, 1469, 307, 456, 382, 731, 281, 1867, 1651, 337, 294, 37211, 11, 604, 2663], "temperature": 0.0, "avg_logprob": -0.18614935105846775, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.00019474298460409045}, {"id": 215, "seek": 108320, "start": 1093.72, "end": 1097.44, "text": " you may have or any roadmap or feature request you may have, we're very interested to hear", "tokens": [291, 815, 362, 420, 604, 35738, 420, 4111, 5308, 291, 815, 362, 11, 321, 434, 588, 3102, 281, 1568], "temperature": 0.0, "avg_logprob": -0.18614935105846775, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.00019474298460409045}, {"id": 216, "seek": 108320, "start": 1097.44, "end": 1099.1200000000001, "text": " from you.", "tokens": [490, 291, 13], "temperature": 0.0, "avg_logprob": -0.18614935105846775, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.00019474298460409045}, {"id": 217, "seek": 108320, "start": 1099.1200000000001, "end": 1104.24, "text": " You can also contribute, so obviously if you want to develop on Cilium, join the Cilium", "tokens": [509, 393, 611, 10586, 11, 370, 2745, 498, 291, 528, 281, 1499, 322, 383, 388, 2197, 11, 3917, 264, 383, 388, 2197], "temperature": 0.0, "avg_logprob": -0.18614935105846775, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.00019474298460409045}, {"id": 218, "seek": 108320, "start": 1104.24, "end": 1110.52, "text": " Github and contribute, if you want to know more about EBPF go to EBPF.io and if you", "tokens": [460, 355, 836, 293, 10586, 11, 498, 291, 528, 281, 458, 544, 466, 50148, 47, 37, 352, 281, 50148, 47, 37, 13, 1004, 293, 498, 291], "temperature": 0.0, "avg_logprob": -0.18614935105846775, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.00019474298460409045}, {"id": 219, "seek": 111052, "start": 1110.52, "end": 1115.52, "text": " want to know more about Isovalent, the company who originated Cilium and want to for example", "tokens": [528, 281, 458, 544, 466, 286, 539, 3337, 317, 11, 264, 2237, 567, 31129, 383, 388, 2197, 293, 528, 281, 337, 1365], "temperature": 0.0, "avg_logprob": -0.18521861026161596, "compression_ratio": 1.6255924170616114, "no_speech_prob": 4.2159892473137006e-05}, {"id": 220, "seek": 111052, "start": 1115.52, "end": 1120.84, "text": " work there, have a look there, we are looking for engineers as well, so feel free to have", "tokens": [589, 456, 11, 362, 257, 574, 456, 11, 321, 366, 1237, 337, 11955, 382, 731, 11, 370, 841, 1737, 281, 362], "temperature": 0.0, "avg_logprob": -0.18521861026161596, "compression_ratio": 1.6255924170616114, "no_speech_prob": 4.2159892473137006e-05}, {"id": 221, "seek": 111052, "start": 1120.84, "end": 1125.8799999999999, "text": " a look and if you want to know more, ask me after the session as well.", "tokens": [257, 574, 293, 498, 291, 528, 281, 458, 544, 11, 1029, 385, 934, 264, 5481, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.18521861026161596, "compression_ratio": 1.6255924170616114, "no_speech_prob": 4.2159892473137006e-05}, {"id": 222, "seek": 111052, "start": 1125.8799999999999, "end": 1135.32, "text": " All right, let me do, see how I'm doing with time, so in order to run Ingress and Gateway", "tokens": [1057, 558, 11, 718, 385, 360, 11, 536, 577, 286, 478, 884, 365, 565, 11, 370, 294, 1668, 281, 1190, 682, 3091, 293, 48394], "temperature": 0.0, "avg_logprob": -0.18521861026161596, "compression_ratio": 1.6255924170616114, "no_speech_prob": 4.2159892473137006e-05}, {"id": 223, "seek": 113532, "start": 1135.32, "end": 1141.56, "text": " API, you need to set a certain amount of flags on your for example your hand value style,", "tokens": [9362, 11, 291, 643, 281, 992, 257, 1629, 2372, 295, 23265, 322, 428, 337, 1365, 428, 1011, 2158, 3758, 11], "temperature": 0.0, "avg_logprob": -0.17817165540612262, "compression_ratio": 1.7164750957854407, "no_speech_prob": 8.258603338617831e-05}, {"id": 224, "seek": 113532, "start": 1141.56, "end": 1147.6, "text": " so this is an example, I've run a small demo on GKE, so this is a GKE cluster with Cilium", "tokens": [370, 341, 307, 364, 1365, 11, 286, 600, 1190, 257, 1359, 10723, 322, 460, 8522, 11, 370, 341, 307, 257, 460, 8522, 13630, 365, 383, 388, 2197], "temperature": 0.0, "avg_logprob": -0.17817165540612262, "compression_ratio": 1.7164750957854407, "no_speech_prob": 8.258603338617831e-05}, {"id": 225, "seek": 113532, "start": 1147.6, "end": 1155.04, "text": " installed, what you need to do is you need to enable the Ingress controller and in this", "tokens": [8899, 11, 437, 291, 643, 281, 360, 307, 291, 643, 281, 9528, 264, 682, 3091, 10561, 293, 294, 341], "temperature": 0.0, "avg_logprob": -0.17817165540612262, "compression_ratio": 1.7164750957854407, "no_speech_prob": 8.258603338617831e-05}, {"id": 226, "seek": 113532, "start": 1155.04, "end": 1160.2, "text": " case I'm also enabling metrics just because it's interesting to see what's going on.", "tokens": [1389, 286, 478, 611, 23148, 16367, 445, 570, 309, 311, 1880, 281, 536, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.17817165540612262, "compression_ratio": 1.7164750957854407, "no_speech_prob": 8.258603338617831e-05}, {"id": 227, "seek": 113532, "start": 1160.2, "end": 1164.8799999999999, "text": " For Gateway API there's also a value, so Gateway API enabled through, this will trigger Gateway", "tokens": [1171, 48394, 9362, 456, 311, 611, 257, 2158, 11, 370, 48394, 9362, 15172, 807, 11, 341, 486, 7875, 48394], "temperature": 0.0, "avg_logprob": -0.17817165540612262, "compression_ratio": 1.7164750957854407, "no_speech_prob": 8.258603338617831e-05}, {"id": 228, "seek": 116488, "start": 1164.88, "end": 1172.44, "text": " API to be enabled, for service mesh it's important to configure the cube proxy replacement", "tokens": [9362, 281, 312, 15172, 11, 337, 2643, 17407, 309, 311, 1021, 281, 22162, 264, 13728, 29690, 14419], "temperature": 0.0, "avg_logprob": -0.21034214414399247, "compression_ratio": 1.646551724137931, "no_speech_prob": 2.2940968847251497e-05}, {"id": 229, "seek": 116488, "start": 1172.44, "end": 1178.6000000000001, "text": " to strict or probe, strict is recommended because you have the full cube proxy replacement", "tokens": [281, 10910, 420, 22715, 11, 10910, 307, 9628, 570, 291, 362, 264, 1577, 13728, 29690, 14419], "temperature": 0.0, "avg_logprob": -0.21034214414399247, "compression_ratio": 1.646551724137931, "no_speech_prob": 2.2940968847251497e-05}, {"id": 230, "seek": 116488, "start": 1178.6000000000001, "end": 1184.8000000000002, "text": " capabilities in your cluster, this is also required for service mesh and that's basically", "tokens": [10862, 294, 428, 13630, 11, 341, 307, 611, 4739, 337, 2643, 17407, 293, 300, 311, 1936], "temperature": 0.0, "avg_logprob": -0.21034214414399247, "compression_ratio": 1.646551724137931, "no_speech_prob": 2.2940968847251497e-05}, {"id": 231, "seek": 116488, "start": 1184.8000000000002, "end": 1187.88, "text": " it to get started.", "tokens": [309, 281, 483, 1409, 13], "temperature": 0.0, "avg_logprob": -0.21034214414399247, "compression_ratio": 1.646551724137931, "no_speech_prob": 2.2940968847251497e-05}, {"id": 232, "seek": 116488, "start": 1187.88, "end": 1194.2600000000002, "text": " So for this simple demo, I've created a simple gateway with the Gateway class named Cilium,", "tokens": [407, 337, 341, 2199, 10723, 11, 286, 600, 2942, 257, 2199, 28532, 365, 264, 48394, 1508, 4926, 383, 388, 2197, 11], "temperature": 0.0, "avg_logprob": -0.21034214414399247, "compression_ratio": 1.646551724137931, "no_speech_prob": 2.2940968847251497e-05}, {"id": 233, "seek": 119426, "start": 1194.26, "end": 1200.8799999999999, "text": " so this is running Cilium 1.13 Release Candidate 5 which has the Gateway API support and then", "tokens": [370, 341, 307, 2614, 383, 388, 2197, 502, 13, 7668, 34278, 20466, 327, 473, 1025, 597, 575, 264, 48394, 9362, 1406, 293, 550], "temperature": 0.0, "avg_logprob": -0.1694970783434416, "compression_ratio": 1.5041322314049588, "no_speech_prob": 5.017779039917514e-05}, {"id": 234, "seek": 119426, "start": 1200.8799999999999, "end": 1208.56, "text": " a simple HTTP route for the book info example application which has matches for the details", "tokens": [257, 2199, 33283, 7955, 337, 264, 1446, 13614, 1365, 3861, 597, 575, 10676, 337, 264, 4365], "temperature": 0.0, "avg_logprob": -0.1694970783434416, "compression_ratio": 1.5041322314049588, "no_speech_prob": 5.017779039917514e-05}, {"id": 235, "seek": 119426, "start": 1208.56, "end": 1216.32, "text": " and the default path prefixes, so when I go into my environment, I want to show quickly", "tokens": [293, 264, 7576, 3100, 18417, 36005, 11, 370, 562, 286, 352, 666, 452, 2823, 11, 286, 528, 281, 855, 2661], "temperature": 0.0, "avg_logprob": -0.1694970783434416, "compression_ratio": 1.5041322314049588, "no_speech_prob": 5.017779039917514e-05}, {"id": 236, "seek": 119426, "start": 1216.32, "end": 1222.6, "text": " the following, so if I do a Qubectl getService, you can see I already for the sake of time", "tokens": [264, 3480, 11, 370, 498, 286, 360, 257, 1249, 836, 557, 75, 483, 50, 25006, 11, 291, 393, 536, 286, 1217, 337, 264, 9717, 295, 565], "temperature": 0.0, "avg_logprob": -0.1694970783434416, "compression_ratio": 1.5041322314049588, "no_speech_prob": 5.017779039917514e-05}, {"id": 237, "seek": 122260, "start": 1222.6, "end": 1229.08, "text": " created this gateways, what I wanted to show you is that obviously a low balance is required,", "tokens": [2942, 341, 8539, 942, 11, 437, 286, 1415, 281, 855, 291, 307, 300, 2745, 257, 2295, 4772, 307, 4739, 11], "temperature": 0.0, "avg_logprob": -0.21203231811523438, "compression_ratio": 1.6242774566473988, "no_speech_prob": 4.3999141780659556e-05}, {"id": 238, "seek": 122260, "start": 1229.08, "end": 1237.24, "text": " so GKE provisions me a low balancer, low balancer IP I can use to attract traffic, in this case", "tokens": [370, 460, 8522, 25034, 385, 257, 2295, 3119, 28347, 11, 2295, 3119, 28347, 8671, 286, 393, 764, 281, 5049, 6419, 11, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.21203231811523438, "compression_ratio": 1.6242774566473988, "no_speech_prob": 4.3999141780659556e-05}, {"id": 239, "seek": 122260, "start": 1237.24, "end": 1244.12, "text": " I'm demoing a default HTTP gateway and a default HTTPS gateway, so I have two low balancers", "tokens": [286, 478, 10723, 278, 257, 7576, 33283, 28532, 293, 257, 7576, 11751, 51, 6273, 28532, 11, 370, 286, 362, 732, 2295, 3119, 4463, 433], "temperature": 0.0, "avg_logprob": -0.21203231811523438, "compression_ratio": 1.6242774566473988, "no_speech_prob": 4.3999141780659556e-05}, {"id": 240, "seek": 124412, "start": 1244.12, "end": 1253.08, "text": " with each an external IP address assigned, so this configuration is applied, so if I", "tokens": [365, 1184, 364, 8320, 8671, 2985, 13279, 11, 370, 341, 11694, 307, 6456, 11, 370, 498, 286], "temperature": 0.0, "avg_logprob": -0.2527344294956752, "compression_ratio": 1.4331550802139037, "no_speech_prob": 3.149699477944523e-05}, {"id": 241, "seek": 124412, "start": 1253.08, "end": 1263.08, "text": " do a Qubectl get a gateway, good point, obviously in your cluster you also need to install the", "tokens": [360, 257, 1249, 836, 557, 75, 483, 257, 28532, 11, 665, 935, 11, 2745, 294, 428, 13630, 291, 611, 643, 281, 3625, 264], "temperature": 0.0, "avg_logprob": -0.2527344294956752, "compression_ratio": 1.4331550802139037, "no_speech_prob": 3.149699477944523e-05}, {"id": 242, "seek": 124412, "start": 1263.08, "end": 1271.2399999999998, "text": " CRDs for Gateway API support, here you can see I have my Gateway and our TLS Gateway and", "tokens": [14123, 35, 82, 337, 48394, 9362, 1406, 11, 510, 291, 393, 536, 286, 362, 452, 48394, 293, 527, 314, 19198, 48394, 293], "temperature": 0.0, "avg_logprob": -0.2527344294956752, "compression_ratio": 1.4331550802139037, "no_speech_prob": 3.149699477944523e-05}, {"id": 243, "seek": 127124, "start": 1271.24, "end": 1282.96, "text": " if I do a Qubectl get HTTP routes, I can see I have my book info HTTP route installed and", "tokens": [498, 286, 360, 257, 1249, 836, 557, 75, 483, 33283, 18242, 11, 286, 393, 536, 286, 362, 452, 1446, 13614, 33283, 7955, 8899, 293], "temperature": 0.0, "avg_logprob": -0.14333990929831922, "compression_ratio": 1.5402298850574712, "no_speech_prob": 2.199939262936823e-05}, {"id": 244, "seek": 127124, "start": 1282.96, "end": 1292.44, "text": " this relates to this part obviously, so with that I should be able to connect to the details,", "tokens": [341, 16155, 281, 341, 644, 2745, 11, 370, 365, 300, 286, 820, 312, 1075, 281, 1745, 281, 264, 4365, 11], "temperature": 0.0, "avg_logprob": -0.14333990929831922, "compression_ratio": 1.5402298850574712, "no_speech_prob": 2.199939262936823e-05}, {"id": 245, "seek": 127124, "start": 1292.44, "end": 1298.56, "text": " so this is running the bookstore example, so I'm using that public IP as you can see", "tokens": [370, 341, 307, 2614, 264, 43478, 1365, 11, 370, 286, 478, 1228, 300, 1908, 8671, 382, 291, 393, 536], "temperature": 0.0, "avg_logprob": -0.14333990929831922, "compression_ratio": 1.5402298850574712, "no_speech_prob": 2.199939262936823e-05}, {"id": 246, "seek": 129856, "start": 1298.56, "end": 1306.28, "text": " it works and if I go to details I should be forwarded using the Gateway API HTTP routes", "tokens": [309, 1985, 293, 498, 286, 352, 281, 4365, 286, 820, 312, 2128, 292, 1228, 264, 48394, 9362, 33283, 18242], "temperature": 0.0, "avg_logprob": -0.20338286851581774, "compression_ratio": 1.545945945945946, "no_speech_prob": 0.0001150540920207277}, {"id": 247, "seek": 129856, "start": 1306.28, "end": 1315.04, "text": " to that specific details service and that works as well, for HTTPS again a simple example", "tokens": [281, 300, 2685, 4365, 2643, 293, 300, 1985, 382, 731, 11, 337, 11751, 51, 6273, 797, 257, 2199, 1365], "temperature": 0.0, "avg_logprob": -0.20338286851581774, "compression_ratio": 1.545945945945946, "no_speech_prob": 0.0001150540920207277}, {"id": 248, "seek": 129856, "start": 1315.04, "end": 1323.8799999999999, "text": " I've created that gateway, TLS gateway, I've created two listeners, so a listener for bookinfo.cillium.rocks", "tokens": [286, 600, 2942, 300, 28532, 11, 314, 19198, 28532, 11, 286, 600, 2942, 732, 23274, 11, 370, 257, 31569, 337, 1446, 259, 16931, 13, 66, 373, 2197, 13, 340, 2761], "temperature": 0.0, "avg_logprob": -0.20338286851581774, "compression_ratio": 1.545945945945946, "no_speech_prob": 0.0001150540920207277}, {"id": 249, "seek": 132388, "start": 1323.88, "end": 1331.16, "text": " and a listener for hipster shop.cillium.rocks, I didn't have installed the hipster shop for", "tokens": [293, 257, 31569, 337, 8103, 3120, 3945, 13, 66, 373, 2197, 13, 340, 2761, 11, 286, 994, 380, 362, 8899, 264, 8103, 3120, 3945, 337], "temperature": 0.0, "avg_logprob": -0.17480622961166056, "compression_ratio": 1.654708520179372, "no_speech_prob": 8.999153214972466e-05}, {"id": 250, "seek": 132388, "start": 1331.16, "end": 1338.5200000000002, "text": " demo purposes, I'm also referencing two secrets, so I've used makesert to create a simple self", "tokens": [10723, 9932, 11, 286, 478, 611, 40582, 732, 14093, 11, 370, 286, 600, 1143, 1669, 911, 281, 1884, 257, 2199, 2698], "temperature": 0.0, "avg_logprob": -0.17480622961166056, "compression_ratio": 1.654708520179372, "no_speech_prob": 8.999153214972466e-05}, {"id": 251, "seek": 132388, "start": 1338.5200000000002, "end": 1344.0800000000002, "text": " signed certificate installed in my certificate store and created a secret which I reference", "tokens": [8175, 15953, 8899, 294, 452, 15953, 3531, 293, 2942, 257, 4054, 597, 286, 6408], "temperature": 0.0, "avg_logprob": -0.17480622961166056, "compression_ratio": 1.654708520179372, "no_speech_prob": 8.999153214972466e-05}, {"id": 252, "seek": 132388, "start": 1344.0800000000002, "end": 1352.6000000000001, "text": " using this listener, then again HTTP routes for the TLS gateway for bookinfo.cillium.rocks", "tokens": [1228, 341, 31569, 11, 550, 797, 33283, 18242, 337, 264, 314, 19198, 28532, 337, 1446, 259, 16931, 13, 66, 373, 2197, 13, 340, 2761], "temperature": 0.0, "avg_logprob": -0.17480622961166056, "compression_ratio": 1.654708520179372, "no_speech_prob": 8.999153214972466e-05}, {"id": 253, "seek": 135260, "start": 1352.6, "end": 1361.3999999999999, "text": " matches to only the details path prefix on port 9080 and again apart for the hipster", "tokens": [10676, 281, 787, 264, 4365, 3100, 46969, 322, 2436, 4289, 4702, 293, 797, 4936, 337, 264, 8103, 3120], "temperature": 0.0, "avg_logprob": -0.1391220490137736, "compression_ratio": 1.4486486486486487, "no_speech_prob": 0.00012152029376011342}, {"id": 254, "seek": 135260, "start": 1361.3999999999999, "end": 1369.8799999999999, "text": " shop, so that's what I'm going to show here, so if I do the default URL that doesn't work", "tokens": [3945, 11, 370, 300, 311, 437, 286, 478, 516, 281, 855, 510, 11, 370, 498, 286, 360, 264, 7576, 12905, 300, 1177, 380, 589], "temperature": 0.0, "avg_logprob": -0.1391220490137736, "compression_ratio": 1.4486486486486487, "no_speech_prob": 0.00012152029376011342}, {"id": 255, "seek": 135260, "start": 1369.8799999999999, "end": 1376.08, "text": " there's no list, there's no HTTP route configured, but for details I can see I can connect it", "tokens": [456, 311, 572, 1329, 11, 456, 311, 572, 33283, 7955, 30538, 11, 457, 337, 4365, 286, 393, 536, 286, 393, 1745, 309], "temperature": 0.0, "avg_logprob": -0.1391220490137736, "compression_ratio": 1.4486486486486487, "no_speech_prob": 0.00012152029376011342}, {"id": 256, "seek": 137608, "start": 1376.08, "end": 1387.32, "text": " securely and this certificate is run from the gateway resource as well. Obviously this", "tokens": [38348, 293, 341, 15953, 307, 1190, 490, 264, 28532, 7684, 382, 731, 13, 7580, 341], "temperature": 0.0, "avg_logprob": -0.21866543228561813, "compression_ratio": 1.5263157894736843, "no_speech_prob": 3.3403252018615603e-05}, {"id": 257, "seek": 137608, "start": 1387.32, "end": 1393.28, "text": " is a self signed certificate, but obviously you can create signed certificates as well.", "tokens": [307, 257, 2698, 8175, 15953, 11, 457, 2745, 291, 393, 1884, 8175, 32941, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.21866543228561813, "compression_ratio": 1.5263157894736843, "no_speech_prob": 3.3403252018615603e-05}, {"id": 258, "seek": 139328, "start": 1393.28, "end": 1406.6399999999999, "text": " With that, that concludes my presentation and the demo, I'm open for questions. Any", "tokens": [2022, 300, 11, 300, 24643, 452, 5860, 293, 264, 10723, 11, 286, 478, 1269, 337, 1651, 13, 2639], "temperature": 0.0, "avg_logprob": -0.3028049652393048, "compression_ratio": 1.0804597701149425, "no_speech_prob": 0.0005784199456684291}, {"id": 259, "seek": 139328, "start": 1406.6399999999999, "end": 1407.6399999999999, "text": " questions?", "tokens": [1651, 30], "temperature": 0.0, "avg_logprob": -0.3028049652393048, "compression_ratio": 1.0804597701149425, "no_speech_prob": 0.0005784199456684291}, {"id": 260, "seek": 140764, "start": 1407.64, "end": 1426.64, "text": " Hi, thank you very much for your presentation. When you talk about no layer 7 support in", "tokens": [2421, 11, 1309, 291, 588, 709, 337, 428, 5860, 13, 1133, 291, 751, 466, 572, 4583, 1614, 1406, 294], "temperature": 0.0, "avg_logprob": -0.40016489443571673, "compression_ratio": 1.0602409638554218, "no_speech_prob": 0.003925061784684658}, {"id": 261, "seek": 142664, "start": 1426.64, "end": 1438.24, "text": " going to come or not? I'm not sure about that. HTTP routing requires quite a lot of memory,", "tokens": [516, 281, 808, 420, 406, 30, 286, 478, 406, 988, 466, 300, 13, 33283, 32722, 7029, 1596, 257, 688, 295, 4675, 11], "temperature": 0.0, "avg_logprob": -0.21945851914426115, "compression_ratio": 1.5407725321888412, "no_speech_prob": 0.00040513661224395037}, {"id": 262, "seek": 142664, "start": 1438.24, "end": 1445.2, "text": " so obviously memory is limited in eBPF programs for good reasons, so it will depend on the", "tokens": [370, 2745, 4675, 307, 5567, 294, 308, 33, 47, 37, 4268, 337, 665, 4112, 11, 370, 309, 486, 5672, 322, 264], "temperature": 0.0, "avg_logprob": -0.21945851914426115, "compression_ratio": 1.5407725321888412, "no_speech_prob": 0.00040513661224395037}, {"id": 263, "seek": 142664, "start": 1445.2, "end": 1450.16, "text": " eBPF foundation and the roadmap there, what we can support. Technically there's no reason", "tokens": [308, 33, 47, 37, 7030, 293, 264, 35738, 456, 11, 437, 321, 393, 1406, 13, 42494, 456, 311, 572, 1778], "temperature": 0.0, "avg_logprob": -0.21945851914426115, "compression_ratio": 1.5407725321888412, "no_speech_prob": 0.00040513661224395037}, {"id": 264, "seek": 142664, "start": 1450.16, "end": 1455.2800000000002, "text": " why we shouldn't be able to do that, but in terms of memory we have constraints, so if", "tokens": [983, 321, 4659, 380, 312, 1075, 281, 360, 300, 11, 457, 294, 2115, 295, 4675, 321, 362, 18491, 11, 370, 498], "temperature": 0.0, "avg_logprob": -0.21945851914426115, "compression_ratio": 1.5407725321888412, "no_speech_prob": 0.00040513661224395037}, {"id": 265, "seek": 145528, "start": 1455.28, "end": 1464.44, "text": " those are being raised we potentially can have parts of even all parts using eBPF.", "tokens": [729, 366, 885, 6005, 321, 7263, 393, 362, 3166, 295, 754, 439, 3166, 1228, 308, 33, 47, 37, 13], "temperature": 0.0, "avg_logprob": -0.3335327842018821, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0005276939482428133}, {"id": 266, "seek": 145528, "start": 1464.44, "end": 1465.44, "text": " Any other questions?", "tokens": [2639, 661, 1651, 30], "temperature": 0.0, "avg_logprob": -0.3335327842018821, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0005276939482428133}, {"id": 267, "seek": 145528, "start": 1465.44, "end": 1477.56, "text": " Hi, does it provide or can you provide end to end encryption, especially between the", "tokens": [2421, 11, 775, 309, 2893, 420, 393, 291, 2893, 917, 281, 917, 29575, 11, 2318, 1296, 264], "temperature": 0.0, "avg_logprob": -0.3335327842018821, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0005276939482428133}, {"id": 268, "seek": 145528, "start": 1477.56, "end": 1479.3999999999999, "text": " nodes automatically or not?", "tokens": [13891, 6772, 420, 406, 30], "temperature": 0.0, "avg_logprob": -0.3335327842018821, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0005276939482428133}, {"id": 269, "seek": 147940, "start": 1479.4, "end": 1485.24, "text": " Yes, so our vision there is that you should configure, for example, IP stack or wire guard", "tokens": [1079, 11, 370, 527, 5201, 456, 307, 300, 291, 820, 22162, 11, 337, 1365, 11, 8671, 8630, 420, 6234, 6290], "temperature": 0.0, "avg_logprob": -0.2310989803738064, "compression_ratio": 1.5726872246696035, "no_speech_prob": 0.00012490393419284374}, {"id": 270, "seek": 147940, "start": 1485.24, "end": 1491.16, "text": " for node to node encryption in transit, and if you want authentication and authorization", "tokens": [337, 9984, 281, 9984, 29575, 294, 17976, 11, 293, 498, 291, 528, 26643, 293, 33697], "temperature": 0.0, "avg_logprob": -0.2310989803738064, "compression_ratio": 1.5726872246696035, "no_speech_prob": 0.00012490393419284374}, {"id": 271, "seek": 147940, "start": 1491.16, "end": 1497.4, "text": " on top of that to configure SPIFI or MTLS between your applications. It's a multi-layered", "tokens": [322, 1192, 295, 300, 281, 22162, 8420, 12775, 40, 420, 37333, 19198, 1296, 428, 5821, 13, 467, 311, 257, 4825, 12, 8376, 4073], "temperature": 0.0, "avg_logprob": -0.2310989803738064, "compression_ratio": 1.5726872246696035, "no_speech_prob": 0.00012490393419284374}, {"id": 272, "seek": 147940, "start": 1497.4, "end": 1503.0800000000002, "text": " approach, so we're not doing the encryption on the MTLS part, but on the node level, if", "tokens": [3109, 11, 370, 321, 434, 406, 884, 264, 29575, 322, 264, 37333, 19198, 644, 11, 457, 322, 264, 9984, 1496, 11, 498], "temperature": 0.0, "avg_logprob": -0.2310989803738064, "compression_ratio": 1.5726872246696035, "no_speech_prob": 0.00012490393419284374}, {"id": 273, "seek": 150308, "start": 1503.08, "end": 1510.08, "text": " that makes sense. So MTLS again, SPIFI is on roadmap, hopefully for 1.13.", "tokens": [300, 1669, 2020, 13, 407, 37333, 19198, 797, 11, 8420, 12775, 40, 307, 322, 35738, 11, 4696, 337, 502, 13, 7668, 13], "temperature": 0.0, "avg_logprob": -0.306054555452787, "compression_ratio": 0.9125, "no_speech_prob": 0.00011435664055170491}, {"id": 274, "seek": 151008, "start": 1510.08, "end": 1535.8, "text": " Any other? No, okay, thank you. Thank you.", "tokens": [50364, 2639, 661, 30, 883, 11, 1392, 11, 1309, 291, 13, 1044, 291, 13, 51650], "temperature": 0.0, "avg_logprob": -0.4661155939102173, "compression_ratio": 1.0, "no_speech_prob": 0.0037184790708124638}], "language": "en"}