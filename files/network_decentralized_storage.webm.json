{"text": " So, great to see you all. So many people here. That's awesome. Welcome to my talk. It's called Decentralized Search with IPFS. Maybe first of all, like a quick pause. How many of you have used IPFS? Please raise your hand. Okay. Okay, nice. And how many of you have heard about IPFS? Okay, all of you. Okay, cool. So, you know all about it already, no? Yeah, so the talk is called How Does It Work Under the Hood? So we will dive in, yeah, pretty deep at some points of the talk. But yeah, first things first. My name is Dennis. I'm a research engineer at Protocol Labs. I'm working in a team called PROBLAB and we're doing network measurements and protocol optimizations there. I'm also an industrial PhD candidate at the University of G\u00f6ttingen and you can reach me on all these handles on the internet. So, if you have any questions, you can reach out and let me know your questions or just hear the venue after the talk. So what's in for you today? First of all, just in words and numbers, what is the IPFS? Just general overview. And at that point, after we covered that, I would just assume we have installed a local IPFS node on your computer and I will walk you through the different commands from, yeah, we are initializing some of the repository, we are publishing content to the network and so on and we'll explain what happens in each of these steps so that all of you hopefully get a glimpse on what's going on under the hood. So we are importing content, we connect to the network, I explain content routing, this is the very technical part and at the end some call-alls basically. So what is IPFS? IPFS stands for the Interplanetary File System and generally it's a decentralized storage and delivery network which builds on peer-to-peer networking and content-based addressing. So peer-to-peer networking, if you have followed along or if you have been here earlier today, Max gave a great talk about IPTP, about connectivity in general in peer-to-peer networks and IPFS is one of the main users of the IPTP library and builds on top of that. And most importantly, it's very tiny at the bottom, IPFS is not a blockchain, so also a common misconception, I'd like to emphasize that. N numbers, given these numbers are from mid last year, so probably in need of an update but this operation is since 2015, that hasn't changed. Numbers of requests exceed a billion in a week and hundreds of terabytes of traffic that we see and tens of millions of active users also weekly but it is a disclaimer, this is just from our vantage point, in a decentralized network no one has a complete view of what's going on, so these numbers could be much higher or just different in general. On ecosystem.ipfs.tech you can find some companies that build on top of this tech and it's all in these different areas, social media and so on and so forth, so worth looking up. What's the value proposition of IPFS? The most important thing that it does, it decouples the content from its host and it does this through a concept that's called content addressing and content addresses are just our permanent verifiable links and this allows you to request content with this or request data with that content address and anyone can serve you the content and just from the address that you asked with you can identify and verify that the content you got served is actually the one that you requested and you are not dependent on the authenticity of the host as it's the case with HTTP. Because it's a decentralized network, it's also censorship resistant and I like to put here that it alleviates backbone addiction, so what do I mean with that? Let's imagine all of you or all of us wanted to download a 100 megabyte YouTube video here in this room, we would put pressure, so if we were 100 people we would put pressure off about 10 gigabytes onto the backbone to just download the video into this room, wouldn't it be better if we could just download it once and distribute it across each other or download different parts and be a little bit more clever about that. In the similar vein, if we were working on a Google doc here inside this room, why does it stop working if we don't have internet connection anymore? It actually should work, it's actually ridiculous. And also, for some to the same category, this partition tolerance for emerging networks could also become very important or if you're just in a patchy coffee shop Wi-Fi. Alright, so how can you install IPFS? So there, I put down three different ways here, so IPFS in general is not, you don't install IPFS, IPFS is more specification and there are different implementations of this specification and the most common one is Kubo, which was formerly known as Go IPFS, so it's a Go implementation, there's a new one called IRO, which is in Rust and I think the newest one is in JavaScript called Helia, yeah, I think that's also the newest kid on the block and so I will talk about Kubo here and the easiest thing to get started is just download IPFS desktop, which is an electron app that bundles an IPFS node, gives you a nice UI and you can already interact and request CIDs from the network and so on. Then there's the IPFS companion, which is a browser extension that you can install to Firefox or your browser of choice or you directly use Brave or Opera, which comes in with a bundled IPFS node already, so if you enter a IPFS colon slash slash and a CID, it will resolve the content through the IPFS network. But as I said in the beginning, in this talk, we will focus on the command line because we're in a developer conference and I will also assume that we run Kubo, which is the reference implementation basically. So now we have downloaded Kubo from github.com slash IPFS slash Kubo and we want to import some content, we just want to get started. So we downloaded it and now we have this IPFS command on our machine and the first thing that we do is run IPFS in it and what this does is it generates a public parried key pair per default in ED25519 and it spits out this random string of characters, which is basically your public key. So formally it was just the hash of your public key, but now it's just encoded your public key in here and this is your PR identity, which will become important later on. And it also initializes your IPFS repository per default in your home directory under.ipfs. This is the location where it stores all the files. So if you interact with the IPFS network and request files, it stores it in this directory in a specific format similar to Git, how Git does the Git object store basically. And importantly, I will point this out a couple of times, this is just a local operation. So we haven't interacted with the network at all yet. So now we are ready to go, I have a file I want to add. So what I do is I run IPFS add and then my file name and in this case IPFS gives you like a progress bar or a Kubo gives you a progress bar and spits out again a random string of characters, which is the content identifier, the CID, which is the most fundamental ingredient here. And this is the part where it decouples the host, sorry, the content from its host. And as a mental model, you can think about the CID as a hash with some metadata. It's self-describing. So the metadata is this description part. You can see the ingredients at the bottom. So it's just an encoded version of some information like a CID version. So we have version zero and one and some other information that I won't go into right now. Then it's self-certifying. This is the point where if you request some data from the network, you certify the data that you could serve with the CID itself and not with the host that served you the content and just reiterating this. And it's an immutable identifier. And all these structures like the CID structure at the bottom and so on is governed by a project that's called multi-formats and it's also one of Prolucolab's projects here. And so the talk is called what happens under the hood, so what actually happened here. IPFS saw the file, which is just this white box here, a stream of bytes, and IPFS chunked it up. It's in different pieces, which is a common technique in networking, actually. And this gives us some nice properties. It allows us to do piecewise transfers so we can request blocks from different hosts, actually. And it allows for deduplication. Also if we have two blocks that are basically the same bytes, we can deduplicate that and save some storage space underneath. And also if the file was a video file, we also allow for random access so we could start in the middle of a video and don't need to stream all the previous bytes at all. And after we have chunked that up, what we do now or what IPFS does now is we need to put them, we need to put it together again. And what we do here is we hash each individual chunk. Each chunk gets its own CID, its own content identifier. Then the combination of each CID again gets another CID and we do this for both pairs at the bottom. And then the resulting common CIDs again will be put together yet again to generate the root CID, that's how we call it. And this is actually the CID that you see in the command line up there. So we took the chunks, put them, put the identifiers together to arrive at the final CID at the top. And this data structure is actually called a Merkle tree, but in IPFS land it's actually a Merkle deck because in Merkle trees your nodes are not allowed to have common parents. And the deck means here a directed acyclic graph. And let's imagine you didn't add a file but a directory. How do you encode the directory structure and not only the bytes and so on? All these formatting and serialization, deserialization things are governed by yet another project. It's called IPLD, which stands for Interplanetary Link Data. And IPLD does also a lot of more things, but for now this is specified in the scope of this project. So now we have imported the content. We have chunked it up, we've got the CID. But again, we haven't interacted with the network yet. So people think if you add something to IPFS you upload it somewhere and someone else takes care of hosting it for you, for free, which is not the case. So we added it to our local node. So now it ended up in this IPFS repository somewhere on our local machine. But only now we connect to the network and interact with it. For that we run IPFS daemon, which is a long-running process that connects to nodes in the network. We see some versioning information with which Go version was compiled with Kubo version we actually use. We see the addresses that the Kubo node listens on and also which ones are announced to the network, under which network addresses we are reachable. And then tells us that it started an API server, a web UI in the gateway. The API server is just an RPC API that is used by the command line to control the IPFS node. The web UI is the thing that you saw previously when you saw the screenshot of the IPFS desktop. So your local Kubo node also serves this web UI. And then the gateway. And the gateway is quite interesting. So this bridges the HTTP world with the IPFS world. So you can ask under this endpoint that you can see down there. If you put IPFS slash your CID inside the browser or in your SUD URL, the Kubo node will go ahead and resolve the CID in the network and serve it to you over HTTP. So this is like a bridge between both worlds. And ProCollapse and Cloudflare and so on are actually running these gateways on the internet right now, which you can use just a low barrier entry to the whole thing. And then the daemon is ready. And in this process, it has also connected to bootstrap nodes, which are hard coded to actually get to know other peers in the network. But you can also override it with your own bootstrap nodes. So now we are connected to the network. We have added our file to our own machine. But now the interesting or the problem or like the challenge, how do we actually find content hosts for a given CID? So I give my friend a CID, how does the node know that it needs to connect to me to request the content, actually? And I put here the solution is simple. We keep a mapping table. So we just have the CID mapped to the actual peer and every node has this on their machine. So everyone knows everything, basically. But as I said, the mapping table gets humongous, especially if we've split up those files into different chunks, and I think the default chunking size is 256 kilobytes. So we have just a lot of entries in this table. So this doesn't scale. So the solution would be to split this table, and each participating peer in this decentralized network holds a separate part of the table. But then we are back to square one. How do we know which peer holds which piece of this distributed hash table data? And the solution here would be to use a just deterministic distribution based on the Cademia DHT. Cademia is like a, is a, is a implementate or like a specific protocol for a distributed hash table. And at this point, I thought, so at this point, many talks on the internet about IPFS gloss over the DHT and how it works. And so when I got into this whole thing, I was lacking something. And so my experiment would be to just dive even a little deeper into, into this. And I would cover a bit of Cademia here, but at the end, this is very technical. But at the end, I would try to summarize everything so that everyone of you gets a little bit out of this. This whole process is called content routing. So this resolution of a CID to the content host. And IPFS uses an adaptation of the Cademia DHT by using a 256 bit key space. So we are hashing the CID and the PRID yet again with the SHA-256 to arrive in a common, in a common key space. And the distributed hash table in IPFS is just a distributed system that maps these keys to values. And the most important records here are provider records, which map a CID to a PRID. Some of the PRID is that what was generated when we initialize our node. And PRID and PR records, which then map the PRID to actually network addresses, like IP addresses and ports. So looking up a CID to a host for a CID is actually a two-step process. First we need to resolve the CID to a PRID, and then the PRID to their network addresses. And then we can connect to each other. And the distributed hash table here has two key features, first an X or distance metric. So that means we have some notion of closeness. So what this XOR thing does, so if I XOR two numbers together, the resulting number or this operation satisfies the condition, the requirements for a metric. So this means I can say a certain PRID is closer to a CID than some other PRID. So in this case, PRIDX could be closer to CID1 than PRIDY. And this allows us to basically sort CIDs with PRIDs together. And then this tree-based routing mechanism here. So in this bottom right diagram, I got this from the original paper, we have the black node. And with this tree-based routing, this is super clever as in each bubble, so all the PRID peers in the network can actually be considered as in a big try, a prefix try. And if we know only one PRID in each of these bubbles, we can guarantee that we can reach any other PRID in the network with O log N lookups by asking for even closer PRIDs based on this XOR routing mechanism here. So this was just abstractly what the distributed hash table in IPFS does. So how does it work concretely for IPFS? So we started the daemon process. What happened under the hood was we calculated the SHA-256 of our PRID, which just gives us a long string of bits and bytes, or just bits basically in our case. And we initialized a routing table at the bottom. And this routing table consists of different buckets. And each bucket is filled with peers that have a common prefix to our PRID, the hash from our PRID at the top. And when our node started up, we asked the bootstrap peers, hey, do you know anyone whose SHA-256 from PRID starts with a 1? And this means we have no common prefix, and we put them, those peers in bucket 0. Then we do the same for a prefix of 0, 0 and 0, 1, 1. And so we go through all the list until 255, and we fill up these buckets. And these are basically these buckets, these little blobs, these little circuits that you saw in the previous slide. And why did we do that? Because when we now want to retrieve content, so as I said, I handed the CID to my friend, and my friend enters the CID in the command line with this IPFS get command. Their node also calculates the SHA-256 of the CID, and then looks in its own routing table, sees, OK, I have a prefix of 2. I take one peer out of this bucket 2 and ask, yeah, locate the appropriate bucket, get the list of all peers, and then I asked all of these peers in the bucket, hey, do you know anyone? So first of all, do you know the provider record already? Do you know the CID and the PRID to that CID? And if yes, we are done, but if not, we are asking, do you know anyone closer based on this XR metric? And then this peer yet again looks in its own routing table, and so we get closer and closer and closer with this log n property that I showed you previously. And for publishing content, it's basically the same. We calculate the SHA-256 of the CID, locate the appropriate bucket, get a list of all the peers from that, and then we start parallel queries, but instead of asking for the provider record, we ask for even closer peers. And we terminate when the closest known peers in the query actually haven't replied with any peer that's closer, hasn't replied with anyone closer to the CID than we already know. And then we start the provider record with the 20 closest peers to that CID, and we do it with 20 because there's peer churn, so this is a permissionless network, and this means peers can come and go as they wish, and if we only started with one peer, we would risk that the provider record is not reachable when the node comes down, and in turn all content is not reachable. So this is like the very technical part of that, but let me summarize this. This is probably the easier way to understand all of this. First of all, so we added the content to our node, and so this is the file, enters the provider, the provider looks in its routing table, gets redirected to peer that is closer to the CID, and gets redirected until it finds the closest peer in this XR key space metric to the CID, and then it stores the provider record with that. Then off-band, the CID gets handed to the requester to my friend, and what I didn't say or told you yet, it's also IPFS maintains a long list or like, I don't know how many it is right now, probably a hundred or so, constant connections to other peers, and opportunistically just ask them, hey, do you know the CID or the provider record to the CID? And if this resolves, all good, we are done, but it's very unlikely for people to actually know a random CID. So let's assume this didn't work. So this requester also looks in its own routing table, gets redirected, gets redirected even closer, even closer to the peer ID of that CID, and then finds the peer that stores the provider record, fetches the provider record, then does again the same hops to find out the mapping from the peer ID to the network addresses, and then we can actually connect with each other and transfer the content, and we're done. So this is the content lifecycle, and this is actually, this is already it, well, already it is quite a bit, quite involved actually, and yeah, with that, it's already time for some callouts, get involved, IPFS is an open source project, if you're into measurements and so on, we have some grants open at radius.space, if you want to get involved with some network measurements, get your applications in, all action is in public, you can follow along our work, especially my work of our team, at this GitHub repository, we have plenty of requests for measurements that you can dive into, and extra ideas are always welcome. In general, IPFS is, I think, a very welcoming community, at least for me, and yeah, just, that's it. So, any questions? So is the way you describe it, using the DHT, how all nodes in the network share files with each other? There's one content routing mechanism, so there are multiple ones, so this first thing that I said here, so this opportunistic request to your immediate nodes is also some kind of content routing, so you're resolving the location of content, then there are some new efforts for building network indexes, which are just huge nodes that store the mappings, centralized nodes, which, like, federated centralized nodes, so not as bad, and I think, yeah, I think these are the important ones, basically, yeah, so there are more ways to resolve them. Also MDNS could also be one part, so if you're on the same network, you're broadcasting, I know, that's just for, sorry, for the local, yeah, okay, true, yeah, luckily we have a core maintainer of IPFS here, yeah, it's actually not a joke, but yeah, sorry, yeah. So I see that the provider records get replicated, but does the content actually get replicated across the network too? Yeah, so only if someone else chooses to, so you're publishing the provider record, so it's public somewhere, and anyone could look that up and also store the record themselves, so this is the idea, if content is popular and you care about the content being, staying alive in the network, it's called PIN, the CID, and this means you're fetching the content from this other provider and store it yourself and become the provider yourself, and because of the CID mechanism, which is self-certifying and so on, other peers that request the content from you don't even need to trust you, because the CID already encodes the trust chain here, but there's nothing that happened, it's not happening automatically here, so. But you can have multiple providers for the same company? Definitely, yeah, that's also, yeah, definitely, that's part of it. Another question is how does the project fit in, the concept of identity and trust and personas into IPFS, I'm thinking metadata, ramifications about the content and stuff like that. What do you mean exactly? For instance, just a history of the content, and can you trust that this content is from a certain person or from a certain, you know, like. I would argue this would probably be some mechanism on top of these content identification. So this is more for IPLD then, or for, perhaps, I would say, so if you want to say some content is from some specific person to, then you would work with signatures, so signing the data and so on, which is something you would bolt on top of IPFS, but nothing I think IPLD has encoded there right now. It's partly the same question about how it is ensured that there are no collisions in the content ID. No collisions? Yes, because if you publish some other content with the same content ID, you said it's happening locally, the content ID generation. You could fake contents. Yes, but then all these cryptographic hash functions would be broken then, which would be very bad. And if you have a hash collision, then it actually means you have the same content. That's the assumption right now, or maybe, yes, Joe. We just use a shadow 56 by default, and you can use also one like black 3, black 2, but if you find a collision in shadow 56, you have bigger problems and IPFS is not working. Exactly this, yeah. Follow on on this, how resilient is this against malicious actors that want to prevent me from reaching the content? It's a big question, but maybe something. Yes, so on peer-to-peer networks, often these kind of civil attacks are in the tech vector that is considered, which means you generate a lot of identities to populate just some part of the key space to block some requests from reaching the final destination and so on. From my experience, this is quite hard, and I haven't seen this happening. I cannot say that it's impossible or probably hard to tell. Max, do you want? Also, yeah, Kadeimnia has this mechanism where only long-living peers stay in the driving table. True, yeah, only, yeah. So this civil thing is just one attack vector, but this is like the common one that is considered. So there are many points in the code base where you need to think about what happens if a civil attack is going on, and one thing that Kadeimnia does is to keep, like, prefer long-running nodes, stable nodes in the routing table. So if someone immediately generates a lot of identities that they don't end up in your routing table and pollutes your routing, your content routing here, or interferes with that. All right, go ahead. I'm not sure if I want to ask it, but removing content, you know, deleting, you know, we got the EPR, so is there any solution that can be done? So, yeah, it's hard. That's part of the thing, if you could, then it's not censorship resistant anymore. And so what is one solution, well, one alleviation, maybe, is to have a blacklist of CID that you may publish or may not to say, okay, don't replicate this CID and so on, but this also, if you have such a list, then it's very easy to just look it up and see what's inside. Yeah, so deleting content is very tricky, however, I said it's permanent links, yeah, the links are permanent, but actually content still turns in the IPFS network, and these provider records that you publish into the network expire after 24 hours, so if no one actually re-provides the content or keeps the content, the content is gone as well. But a delete operation doesn't exist, so we just need to hope that no one will be provided any more, which you could do with these denialists, for example, yeah, Daniel, okay. Who is able to write into that blacklist and is there any? Yeah, this is just one, I don't know, to be completely honest, but this is just one, maybe Jeroko knows. There is no blacklist in the network right now, it's a few people that want that, but we have, sorry, earlier you said that we have gateways, and gateways is just a node that publicly is reachable, and those gateways, because many people say that, okay, they find some content illegal on IPFS, and instead of reporting to the actual node, so it's a content on IPFS, they just report it on the gateway, because they know HTTP and they don't know IPFS, and so our gateway has some blacklist that is somewhere, but it's not shared by the complete network, it's just for our gateway IPFS.io. So cloudfair, for example, and I've already read these gateways, or more, anyone could operate the gateway, so you could file a request for this, don't replicate the CID, it's a phishing website, for example, and then these CIDs are not served through the gateways, which is a common way to interact with the network right now. Just the gateways that follow the list, it's not a domain. Okay, we're running out of time, unless there is one more. I have a question regarding searching through the stored content, is there any mechanism on how to go through or index the files that are there to have some sort of like a search engine for that? Right, so there's a project called IPFS search, and this makes use, like among other things, of this immediate request for CIDs, so it's just sitting there listening, connecting to a lot of nodes, and as I said, if someone requests content, you immediately ask your connected peers, and you're connected to a lot of peers, and these IPFS search nodes are sitting there listening to these requests, and they see, okay, someone wants the CID, so I go ahead and request that CID as well, and then index that content on myself, and so you can then search on this IPFS search website for something, just with Google, and then you see CIDs popping in, and then you can request those CIDs from the IPFS network. So this is one approach to do that, to index content, yeah. Okay, thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.48, "text": " So, great to see you all.", "tokens": [407, 11, 869, 281, 536, 291, 439, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 1, "seek": 0, "start": 7.48, "end": 8.48, "text": " So many people here.", "tokens": [407, 867, 561, 510, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 2, "seek": 0, "start": 8.48, "end": 9.48, "text": " That's awesome.", "tokens": [663, 311, 3476, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 3, "seek": 0, "start": 9.48, "end": 10.48, "text": " Welcome to my talk.", "tokens": [4027, 281, 452, 751, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 4, "seek": 0, "start": 10.48, "end": 12.52, "text": " It's called Decentralized Search with IPFS.", "tokens": [467, 311, 1219, 1346, 2207, 2155, 1602, 17180, 365, 8671, 29318, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 5, "seek": 0, "start": 12.52, "end": 16.080000000000002, "text": " Maybe first of all, like a quick pause.", "tokens": [2704, 700, 295, 439, 11, 411, 257, 1702, 10465, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 6, "seek": 0, "start": 16.080000000000002, "end": 18.400000000000002, "text": " How many of you have used IPFS?", "tokens": [1012, 867, 295, 291, 362, 1143, 8671, 29318, 30], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 7, "seek": 0, "start": 18.400000000000002, "end": 20.080000000000002, "text": " Please raise your hand.", "tokens": [2555, 5300, 428, 1011, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 8, "seek": 0, "start": 20.080000000000002, "end": 21.080000000000002, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 9, "seek": 0, "start": 21.080000000000002, "end": 22.080000000000002, "text": " Okay, nice.", "tokens": [1033, 11, 1481, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 10, "seek": 0, "start": 22.080000000000002, "end": 23.92, "text": " And how many of you have heard about IPFS?", "tokens": [400, 577, 867, 295, 291, 362, 2198, 466, 8671, 29318, 30], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 11, "seek": 0, "start": 23.92, "end": 25.16, "text": " Okay, all of you.", "tokens": [1033, 11, 439, 295, 291, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 12, "seek": 0, "start": 25.16, "end": 26.16, "text": " Okay, cool.", "tokens": [1033, 11, 1627, 13], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 13, "seek": 0, "start": 26.16, "end": 28.64, "text": " So, you know all about it already, no?", "tokens": [407, 11, 291, 458, 439, 466, 309, 1217, 11, 572, 30], "temperature": 0.0, "avg_logprob": -0.2660094972640749, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.13896825909614563}, {"id": 14, "seek": 2864, "start": 28.64, "end": 31.560000000000002, "text": " Yeah, so the talk is called How Does It Work Under the Hood?", "tokens": [865, 11, 370, 264, 751, 307, 1219, 1012, 4402, 467, 6603, 6974, 264, 33213, 30], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 15, "seek": 2864, "start": 31.560000000000002, "end": 35.480000000000004, "text": " So we will dive in, yeah, pretty deep at some points of the talk.", "tokens": [407, 321, 486, 9192, 294, 11, 1338, 11, 1238, 2452, 412, 512, 2793, 295, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 16, "seek": 2864, "start": 35.480000000000004, "end": 38.120000000000005, "text": " But yeah, first things first.", "tokens": [583, 1338, 11, 700, 721, 700, 13], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 17, "seek": 2864, "start": 38.120000000000005, "end": 39.120000000000005, "text": " My name is Dennis.", "tokens": [1222, 1315, 307, 23376, 13], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 18, "seek": 2864, "start": 39.120000000000005, "end": 41.480000000000004, "text": " I'm a research engineer at Protocol Labs.", "tokens": [286, 478, 257, 2132, 11403, 412, 48753, 40047, 13], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 19, "seek": 2864, "start": 41.480000000000004, "end": 46.0, "text": " I'm working in a team called PROBLAB and we're doing network measurements and protocol", "tokens": [286, 478, 1364, 294, 257, 1469, 1219, 15008, 17624, 13868, 293, 321, 434, 884, 3209, 15383, 293, 10336], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 20, "seek": 2864, "start": 46.0, "end": 47.400000000000006, "text": " optimizations there.", "tokens": [5028, 14455, 456, 13], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 21, "seek": 2864, "start": 47.400000000000006, "end": 51.96, "text": " I'm also an industrial PhD candidate at the University of G\u00f6ttingen and you can reach", "tokens": [286, 478, 611, 364, 9987, 14476, 11532, 412, 264, 3535, 295, 460, 12082, 783, 268, 293, 291, 393, 2524], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 22, "seek": 2864, "start": 51.96, "end": 53.760000000000005, "text": " me on all these handles on the internet.", "tokens": [385, 322, 439, 613, 18722, 322, 264, 4705, 13], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 23, "seek": 2864, "start": 53.760000000000005, "end": 58.0, "text": " So, if you have any questions, you can reach out and let me know your questions or just", "tokens": [407, 11, 498, 291, 362, 604, 1651, 11, 291, 393, 2524, 484, 293, 718, 385, 458, 428, 1651, 420, 445], "temperature": 0.0, "avg_logprob": -0.22916520217369343, "compression_ratio": 1.6149253731343283, "no_speech_prob": 8.45069662318565e-05}, {"id": 24, "seek": 5800, "start": 58.0, "end": 60.28, "text": " hear the venue after the talk.", "tokens": [1568, 264, 21645, 934, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.17794601560577633, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00010219340038020164}, {"id": 25, "seek": 5800, "start": 60.28, "end": 61.76, "text": " So what's in for you today?", "tokens": [407, 437, 311, 294, 337, 291, 965, 30], "temperature": 0.0, "avg_logprob": -0.17794601560577633, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00010219340038020164}, {"id": 26, "seek": 5800, "start": 61.76, "end": 66.28, "text": " First of all, just in words and numbers, what is the IPFS?", "tokens": [2386, 295, 439, 11, 445, 294, 2283, 293, 3547, 11, 437, 307, 264, 8671, 29318, 30], "temperature": 0.0, "avg_logprob": -0.17794601560577633, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00010219340038020164}, {"id": 27, "seek": 5800, "start": 66.28, "end": 68.52, "text": " Just general overview.", "tokens": [1449, 2674, 12492, 13], "temperature": 0.0, "avg_logprob": -0.17794601560577633, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00010219340038020164}, {"id": 28, "seek": 5800, "start": 68.52, "end": 72.96000000000001, "text": " And at that point, after we covered that, I would just assume we have installed a local", "tokens": [400, 412, 300, 935, 11, 934, 321, 5343, 300, 11, 286, 576, 445, 6552, 321, 362, 8899, 257, 2654], "temperature": 0.0, "avg_logprob": -0.17794601560577633, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00010219340038020164}, {"id": 29, "seek": 5800, "start": 72.96000000000001, "end": 78.84, "text": " IPFS node on your computer and I will walk you through the different commands from, yeah,", "tokens": [8671, 29318, 9984, 322, 428, 3820, 293, 286, 486, 1792, 291, 807, 264, 819, 16901, 490, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.17794601560577633, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00010219340038020164}, {"id": 30, "seek": 5800, "start": 78.84, "end": 82.8, "text": " we are initializing some of the repository, we are publishing content to the network and", "tokens": [321, 366, 5883, 3319, 512, 295, 264, 25841, 11, 321, 366, 17832, 2701, 281, 264, 3209, 293], "temperature": 0.0, "avg_logprob": -0.17794601560577633, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00010219340038020164}, {"id": 31, "seek": 5800, "start": 82.8, "end": 86.44, "text": " so on and we'll explain what happens in each of these steps so that all of you hopefully", "tokens": [370, 322, 293, 321, 603, 2903, 437, 2314, 294, 1184, 295, 613, 4439, 370, 300, 439, 295, 291, 4696], "temperature": 0.0, "avg_logprob": -0.17794601560577633, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00010219340038020164}, {"id": 32, "seek": 8644, "start": 86.44, "end": 90.28, "text": " get a glimpse on what's going on under the hood.", "tokens": [483, 257, 25838, 322, 437, 311, 516, 322, 833, 264, 13376, 13], "temperature": 0.0, "avg_logprob": -0.1674638448977003, "compression_ratio": 1.608, "no_speech_prob": 3.3187057852046564e-05}, {"id": 33, "seek": 8644, "start": 90.28, "end": 93.8, "text": " So we are importing content, we connect to the network, I explain content routing, this", "tokens": [407, 321, 366, 43866, 2701, 11, 321, 1745, 281, 264, 3209, 11, 286, 2903, 2701, 32722, 11, 341], "temperature": 0.0, "avg_logprob": -0.1674638448977003, "compression_ratio": 1.608, "no_speech_prob": 3.3187057852046564e-05}, {"id": 34, "seek": 8644, "start": 93.8, "end": 99.2, "text": " is the very technical part and at the end some call-alls basically.", "tokens": [307, 264, 588, 6191, 644, 293, 412, 264, 917, 512, 818, 12, 39655, 1936, 13], "temperature": 0.0, "avg_logprob": -0.1674638448977003, "compression_ratio": 1.608, "no_speech_prob": 3.3187057852046564e-05}, {"id": 35, "seek": 8644, "start": 99.2, "end": 100.52, "text": " So what is IPFS?", "tokens": [407, 437, 307, 8671, 29318, 30], "temperature": 0.0, "avg_logprob": -0.1674638448977003, "compression_ratio": 1.608, "no_speech_prob": 3.3187057852046564e-05}, {"id": 36, "seek": 8644, "start": 100.52, "end": 106.84, "text": " IPFS stands for the Interplanetary File System and generally it's a decentralized storage", "tokens": [8671, 29318, 7382, 337, 264, 5751, 16554, 302, 822, 26196, 8910, 293, 5101, 309, 311, 257, 32870, 6725], "temperature": 0.0, "avg_logprob": -0.1674638448977003, "compression_ratio": 1.608, "no_speech_prob": 3.3187057852046564e-05}, {"id": 37, "seek": 8644, "start": 106.84, "end": 111.75999999999999, "text": " and delivery network which builds on peer-to-peer networking and content-based addressing.", "tokens": [293, 8982, 3209, 597, 15182, 322, 15108, 12, 1353, 12, 494, 260, 17985, 293, 2701, 12, 6032, 14329, 13], "temperature": 0.0, "avg_logprob": -0.1674638448977003, "compression_ratio": 1.608, "no_speech_prob": 3.3187057852046564e-05}, {"id": 38, "seek": 11176, "start": 111.76, "end": 116.44, "text": " So peer-to-peer networking, if you have followed along or if you have been here earlier today,", "tokens": [407, 15108, 12, 1353, 12, 494, 260, 17985, 11, 498, 291, 362, 6263, 2051, 420, 498, 291, 362, 668, 510, 3071, 965, 11], "temperature": 0.0, "avg_logprob": -0.1846071995726419, "compression_ratio": 1.5952380952380953, "no_speech_prob": 2.0107307136640884e-05}, {"id": 39, "seek": 11176, "start": 116.44, "end": 123.4, "text": " Max gave a great talk about IPTP, about connectivity in general in peer-to-peer networks and IPFS", "tokens": [7402, 2729, 257, 869, 751, 466, 8671, 16804, 11, 466, 21095, 294, 2674, 294, 15108, 12, 1353, 12, 494, 260, 9590, 293, 8671, 29318], "temperature": 0.0, "avg_logprob": -0.1846071995726419, "compression_ratio": 1.5952380952380953, "no_speech_prob": 2.0107307136640884e-05}, {"id": 40, "seek": 11176, "start": 123.4, "end": 128.52, "text": " is one of the main users of the IPTP library and builds on top of that.", "tokens": [307, 472, 295, 264, 2135, 5022, 295, 264, 8671, 16804, 6405, 293, 15182, 322, 1192, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.1846071995726419, "compression_ratio": 1.5952380952380953, "no_speech_prob": 2.0107307136640884e-05}, {"id": 41, "seek": 11176, "start": 128.52, "end": 133.12, "text": " And most importantly, it's very tiny at the bottom, IPFS is not a blockchain, so also", "tokens": [400, 881, 8906, 11, 309, 311, 588, 5870, 412, 264, 2767, 11, 8671, 29318, 307, 406, 257, 17176, 11, 370, 611], "temperature": 0.0, "avg_logprob": -0.1846071995726419, "compression_ratio": 1.5952380952380953, "no_speech_prob": 2.0107307136640884e-05}, {"id": 42, "seek": 11176, "start": 133.12, "end": 137.76, "text": " a common misconception, I'd like to emphasize that.", "tokens": [257, 2689, 41350, 11, 286, 1116, 411, 281, 16078, 300, 13], "temperature": 0.0, "avg_logprob": -0.1846071995726419, "compression_ratio": 1.5952380952380953, "no_speech_prob": 2.0107307136640884e-05}, {"id": 43, "seek": 13776, "start": 137.76, "end": 143.48, "text": " N numbers, given these numbers are from mid last year, so probably in need of an update", "tokens": [426, 3547, 11, 2212, 613, 3547, 366, 490, 2062, 1036, 1064, 11, 370, 1391, 294, 643, 295, 364, 5623], "temperature": 0.0, "avg_logprob": -0.1929021700464114, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.1285526094725356e-05}, {"id": 44, "seek": 13776, "start": 143.48, "end": 146.79999999999998, "text": " but this operation is since 2015, that hasn't changed.", "tokens": [457, 341, 6916, 307, 1670, 7546, 11, 300, 6132, 380, 3105, 13], "temperature": 0.0, "avg_logprob": -0.1929021700464114, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.1285526094725356e-05}, {"id": 45, "seek": 13776, "start": 146.79999999999998, "end": 152.28, "text": " Numbers of requests exceed a billion in a week and hundreds of terabytes of traffic that", "tokens": [22592, 1616, 295, 12475, 14048, 257, 5218, 294, 257, 1243, 293, 6779, 295, 1796, 24538, 295, 6419, 300], "temperature": 0.0, "avg_logprob": -0.1929021700464114, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.1285526094725356e-05}, {"id": 46, "seek": 13776, "start": 152.28, "end": 158.0, "text": " we see and tens of millions of active users also weekly but it is a disclaimer, this is", "tokens": [321, 536, 293, 10688, 295, 6803, 295, 4967, 5022, 611, 12460, 457, 309, 307, 257, 40896, 11, 341, 307], "temperature": 0.0, "avg_logprob": -0.1929021700464114, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.1285526094725356e-05}, {"id": 47, "seek": 13776, "start": 158.0, "end": 162.0, "text": " just from our vantage point, in a decentralized network no one has a complete view of what's", "tokens": [445, 490, 527, 46206, 935, 11, 294, 257, 32870, 3209, 572, 472, 575, 257, 3566, 1910, 295, 437, 311], "temperature": 0.0, "avg_logprob": -0.1929021700464114, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.1285526094725356e-05}, {"id": 48, "seek": 16200, "start": 162.0, "end": 170.16, "text": " going on, so these numbers could be much higher or just different in general.", "tokens": [516, 322, 11, 370, 613, 3547, 727, 312, 709, 2946, 420, 445, 819, 294, 2674, 13], "temperature": 0.0, "avg_logprob": -0.1854080224966074, "compression_ratio": 1.462686567164179, "no_speech_prob": 3.4743694413919e-05}, {"id": 49, "seek": 16200, "start": 170.16, "end": 176.12, "text": " On ecosystem.ipfs.tech you can find some companies that build on top of this tech and it's all", "tokens": [1282, 11311, 13, 647, 16883, 13, 25970, 291, 393, 915, 512, 3431, 300, 1322, 322, 1192, 295, 341, 7553, 293, 309, 311, 439], "temperature": 0.0, "avg_logprob": -0.1854080224966074, "compression_ratio": 1.462686567164179, "no_speech_prob": 3.4743694413919e-05}, {"id": 50, "seek": 16200, "start": 176.12, "end": 184.56, "text": " in these different areas, social media and so on and so forth, so worth looking up.", "tokens": [294, 613, 819, 3179, 11, 2093, 3021, 293, 370, 322, 293, 370, 5220, 11, 370, 3163, 1237, 493, 13], "temperature": 0.0, "avg_logprob": -0.1854080224966074, "compression_ratio": 1.462686567164179, "no_speech_prob": 3.4743694413919e-05}, {"id": 51, "seek": 16200, "start": 184.56, "end": 186.96, "text": " What's the value proposition of IPFS?", "tokens": [708, 311, 264, 2158, 24830, 295, 8671, 29318, 30], "temperature": 0.0, "avg_logprob": -0.1854080224966074, "compression_ratio": 1.462686567164179, "no_speech_prob": 3.4743694413919e-05}, {"id": 52, "seek": 18696, "start": 186.96, "end": 192.28, "text": " The most important thing that it does, it decouples the content from its host and it does this through", "tokens": [440, 881, 1021, 551, 300, 309, 775, 11, 309, 979, 263, 2622, 264, 2701, 490, 1080, 3975, 293, 309, 775, 341, 807], "temperature": 0.0, "avg_logprob": -0.15554118402225456, "compression_ratio": 1.9783549783549783, "no_speech_prob": 5.731825149268843e-05}, {"id": 53, "seek": 18696, "start": 192.28, "end": 198.72, "text": " a concept that's called content addressing and content addresses are just our permanent", "tokens": [257, 3410, 300, 311, 1219, 2701, 14329, 293, 2701, 16862, 366, 445, 527, 10996], "temperature": 0.0, "avg_logprob": -0.15554118402225456, "compression_ratio": 1.9783549783549783, "no_speech_prob": 5.731825149268843e-05}, {"id": 54, "seek": 18696, "start": 198.72, "end": 204.88, "text": " verifiable links and this allows you to request content with this or request data with that", "tokens": [1306, 30876, 6123, 293, 341, 4045, 291, 281, 5308, 2701, 365, 341, 420, 5308, 1412, 365, 300], "temperature": 0.0, "avg_logprob": -0.15554118402225456, "compression_ratio": 1.9783549783549783, "no_speech_prob": 5.731825149268843e-05}, {"id": 55, "seek": 18696, "start": 204.88, "end": 208.68, "text": " content address and anyone can serve you the content and just from the address that you", "tokens": [2701, 2985, 293, 2878, 393, 4596, 291, 264, 2701, 293, 445, 490, 264, 2985, 300, 291], "temperature": 0.0, "avg_logprob": -0.15554118402225456, "compression_ratio": 1.9783549783549783, "no_speech_prob": 5.731825149268843e-05}, {"id": 56, "seek": 18696, "start": 208.68, "end": 214.24, "text": " asked with you can identify and verify that the content you got served is actually the", "tokens": [2351, 365, 291, 393, 5876, 293, 16888, 300, 264, 2701, 291, 658, 7584, 307, 767, 264], "temperature": 0.0, "avg_logprob": -0.15554118402225456, "compression_ratio": 1.9783549783549783, "no_speech_prob": 5.731825149268843e-05}, {"id": 57, "seek": 21424, "start": 214.24, "end": 220.56, "text": " one that you requested and you are not dependent on the authenticity of the host as it's the", "tokens": [472, 300, 291, 16436, 293, 291, 366, 406, 12334, 322, 264, 34215, 295, 264, 3975, 382, 309, 311, 264], "temperature": 0.0, "avg_logprob": -0.15602781122381038, "compression_ratio": 1.6254545454545455, "no_speech_prob": 3.938885492971167e-05}, {"id": 58, "seek": 21424, "start": 220.56, "end": 222.76000000000002, "text": " case with HTTP.", "tokens": [1389, 365, 33283, 13], "temperature": 0.0, "avg_logprob": -0.15602781122381038, "compression_ratio": 1.6254545454545455, "no_speech_prob": 3.938885492971167e-05}, {"id": 59, "seek": 21424, "start": 222.76000000000002, "end": 226.64000000000001, "text": " Because it's a decentralized network, it's also censorship resistant and I like to put", "tokens": [1436, 309, 311, 257, 32870, 3209, 11, 309, 311, 611, 40985, 20383, 293, 286, 411, 281, 829], "temperature": 0.0, "avg_logprob": -0.15602781122381038, "compression_ratio": 1.6254545454545455, "no_speech_prob": 3.938885492971167e-05}, {"id": 60, "seek": 21424, "start": 226.64000000000001, "end": 230.0, "text": " here that it alleviates backbone addiction, so what do I mean with that?", "tokens": [510, 300, 309, 33201, 1024, 34889, 16835, 11, 370, 437, 360, 286, 914, 365, 300, 30], "temperature": 0.0, "avg_logprob": -0.15602781122381038, "compression_ratio": 1.6254545454545455, "no_speech_prob": 3.938885492971167e-05}, {"id": 61, "seek": 21424, "start": 230.0, "end": 234.8, "text": " Let's imagine all of you or all of us wanted to download a 100 megabyte YouTube video here", "tokens": [961, 311, 3811, 439, 295, 291, 420, 439, 295, 505, 1415, 281, 5484, 257, 2319, 10816, 34529, 3088, 960, 510], "temperature": 0.0, "avg_logprob": -0.15602781122381038, "compression_ratio": 1.6254545454545455, "no_speech_prob": 3.938885492971167e-05}, {"id": 62, "seek": 21424, "start": 234.8, "end": 239.08, "text": " in this room, we would put pressure, so if we were 100 people we would put pressure off", "tokens": [294, 341, 1808, 11, 321, 576, 829, 3321, 11, 370, 498, 321, 645, 2319, 561, 321, 576, 829, 3321, 766], "temperature": 0.0, "avg_logprob": -0.15602781122381038, "compression_ratio": 1.6254545454545455, "no_speech_prob": 3.938885492971167e-05}, {"id": 63, "seek": 23908, "start": 239.08, "end": 244.84, "text": " about 10 gigabytes onto the backbone to just download the video into this room, wouldn't", "tokens": [466, 1266, 42741, 3911, 264, 34889, 281, 445, 5484, 264, 960, 666, 341, 1808, 11, 2759, 380], "temperature": 0.0, "avg_logprob": -0.13133240671991145, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7946782211074606e-05}, {"id": 64, "seek": 23908, "start": 244.84, "end": 248.56, "text": " it be better if we could just download it once and distribute it across each other or", "tokens": [309, 312, 1101, 498, 321, 727, 445, 5484, 309, 1564, 293, 20594, 309, 2108, 1184, 661, 420], "temperature": 0.0, "avg_logprob": -0.13133240671991145, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7946782211074606e-05}, {"id": 65, "seek": 23908, "start": 248.56, "end": 252.84, "text": " download different parts and be a little bit more clever about that.", "tokens": [5484, 819, 3166, 293, 312, 257, 707, 857, 544, 13494, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.13133240671991145, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7946782211074606e-05}, {"id": 66, "seek": 23908, "start": 252.84, "end": 258.52000000000004, "text": " In the similar vein, if we were working on a Google doc here inside this room, why does", "tokens": [682, 264, 2531, 30669, 11, 498, 321, 645, 1364, 322, 257, 3329, 3211, 510, 1854, 341, 1808, 11, 983, 775], "temperature": 0.0, "avg_logprob": -0.13133240671991145, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7946782211074606e-05}, {"id": 67, "seek": 23908, "start": 258.52000000000004, "end": 262.84000000000003, "text": " it stop working if we don't have internet connection anymore?", "tokens": [309, 1590, 1364, 498, 321, 500, 380, 362, 4705, 4984, 3602, 30], "temperature": 0.0, "avg_logprob": -0.13133240671991145, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7946782211074606e-05}, {"id": 68, "seek": 23908, "start": 262.84000000000003, "end": 265.96000000000004, "text": " It actually should work, it's actually ridiculous.", "tokens": [467, 767, 820, 589, 11, 309, 311, 767, 11083, 13], "temperature": 0.0, "avg_logprob": -0.13133240671991145, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7946782211074606e-05}, {"id": 69, "seek": 26596, "start": 265.96, "end": 271.71999999999997, "text": " And also, for some to the same category, this partition tolerance for emerging networks", "tokens": [400, 611, 11, 337, 512, 281, 264, 912, 7719, 11, 341, 24808, 23368, 337, 14989, 9590], "temperature": 0.0, "avg_logprob": -0.26725444597067294, "compression_ratio": 1.5679012345679013, "no_speech_prob": 1.982225694519002e-05}, {"id": 70, "seek": 26596, "start": 271.71999999999997, "end": 278.28, "text": " could also become very important or if you're just in a patchy coffee shop Wi-Fi.", "tokens": [727, 611, 1813, 588, 1021, 420, 498, 291, 434, 445, 294, 257, 9972, 88, 4982, 3945, 14035, 12, 13229, 13], "temperature": 0.0, "avg_logprob": -0.26725444597067294, "compression_ratio": 1.5679012345679013, "no_speech_prob": 1.982225694519002e-05}, {"id": 71, "seek": 26596, "start": 278.28, "end": 282.08, "text": " Alright, so how can you install IPFS?", "tokens": [2798, 11, 370, 577, 393, 291, 3625, 8671, 29318, 30], "temperature": 0.0, "avg_logprob": -0.26725444597067294, "compression_ratio": 1.5679012345679013, "no_speech_prob": 1.982225694519002e-05}, {"id": 72, "seek": 26596, "start": 282.08, "end": 286.96, "text": " So there, I put down three different ways here, so IPFS in general is not, you don't", "tokens": [407, 456, 11, 286, 829, 760, 1045, 819, 2098, 510, 11, 370, 8671, 29318, 294, 2674, 307, 406, 11, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.26725444597067294, "compression_ratio": 1.5679012345679013, "no_speech_prob": 1.982225694519002e-05}, {"id": 73, "seek": 26596, "start": 286.96, "end": 293.2, "text": " install IPFS, IPFS is more specification and there are different implementations of this", "tokens": [3625, 8671, 29318, 11, 8671, 29318, 307, 544, 31256, 293, 456, 366, 819, 4445, 763, 295, 341], "temperature": 0.0, "avg_logprob": -0.26725444597067294, "compression_ratio": 1.5679012345679013, "no_speech_prob": 1.982225694519002e-05}, {"id": 74, "seek": 29320, "start": 293.2, "end": 297.68, "text": " specification and the most common one is Kubo, which was formerly known as Go IPFS,", "tokens": [31256, 293, 264, 881, 2689, 472, 307, 35805, 78, 11, 597, 390, 34777, 2570, 382, 1037, 8671, 29318, 11], "temperature": 0.0, "avg_logprob": -0.22035840461994038, "compression_ratio": 1.697674418604651, "no_speech_prob": 2.428047991998028e-05}, {"id": 75, "seek": 29320, "start": 297.68, "end": 302.24, "text": " so it's a Go implementation, there's a new one called IRO, which is in Rust and I think", "tokens": [370, 309, 311, 257, 1037, 11420, 11, 456, 311, 257, 777, 472, 1219, 286, 7142, 11, 597, 307, 294, 34952, 293, 286, 519], "temperature": 0.0, "avg_logprob": -0.22035840461994038, "compression_ratio": 1.697674418604651, "no_speech_prob": 2.428047991998028e-05}, {"id": 76, "seek": 29320, "start": 302.24, "end": 307.84, "text": " the newest one is in JavaScript called Helia, yeah, I think that's also the newest kid on", "tokens": [264, 17569, 472, 307, 294, 15778, 1219, 6128, 654, 11, 1338, 11, 286, 519, 300, 311, 611, 264, 17569, 1636, 322], "temperature": 0.0, "avg_logprob": -0.22035840461994038, "compression_ratio": 1.697674418604651, "no_speech_prob": 2.428047991998028e-05}, {"id": 77, "seek": 29320, "start": 307.84, "end": 314.4, "text": " the block and so I will talk about Kubo here and the easiest thing to get started is just", "tokens": [264, 3461, 293, 370, 286, 486, 751, 466, 35805, 78, 510, 293, 264, 12889, 551, 281, 483, 1409, 307, 445], "temperature": 0.0, "avg_logprob": -0.22035840461994038, "compression_ratio": 1.697674418604651, "no_speech_prob": 2.428047991998028e-05}, {"id": 78, "seek": 29320, "start": 314.4, "end": 318.8, "text": " download IPFS desktop, which is an electron app that bundles an IPFS node, gives you a", "tokens": [5484, 8671, 29318, 14502, 11, 597, 307, 364, 6084, 724, 300, 13882, 904, 364, 8671, 29318, 9984, 11, 2709, 291, 257], "temperature": 0.0, "avg_logprob": -0.22035840461994038, "compression_ratio": 1.697674418604651, "no_speech_prob": 2.428047991998028e-05}, {"id": 79, "seek": 31880, "start": 318.8, "end": 324.6, "text": " nice UI and you can already interact and request CIDs from the network and so on.", "tokens": [1481, 15682, 293, 291, 393, 1217, 4648, 293, 5308, 383, 2777, 82, 490, 264, 3209, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.12895436015555528, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.8053331586997956e-05}, {"id": 80, "seek": 31880, "start": 324.6, "end": 328.32, "text": " Then there's the IPFS companion, which is a browser extension that you can install to", "tokens": [1396, 456, 311, 264, 8671, 29318, 22363, 11, 597, 307, 257, 11185, 10320, 300, 291, 393, 3625, 281], "temperature": 0.0, "avg_logprob": -0.12895436015555528, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.8053331586997956e-05}, {"id": 81, "seek": 31880, "start": 328.32, "end": 334.24, "text": " Firefox or your browser of choice or you directly use Brave or Opera, which comes in with a", "tokens": [46613, 420, 428, 11185, 295, 3922, 420, 291, 3838, 764, 38545, 420, 39089, 11, 597, 1487, 294, 365, 257], "temperature": 0.0, "avg_logprob": -0.12895436015555528, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.8053331586997956e-05}, {"id": 82, "seek": 31880, "start": 334.24, "end": 340.08000000000004, "text": " bundled IPFS node already, so if you enter a IPFS colon slash slash and a CID, it will", "tokens": [13882, 1493, 8671, 29318, 9984, 1217, 11, 370, 498, 291, 3242, 257, 8671, 29318, 8255, 17330, 17330, 293, 257, 383, 2777, 11, 309, 486], "temperature": 0.0, "avg_logprob": -0.12895436015555528, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.8053331586997956e-05}, {"id": 83, "seek": 31880, "start": 340.08000000000004, "end": 343.88, "text": " resolve the content through the IPFS network.", "tokens": [14151, 264, 2701, 807, 264, 8671, 29318, 3209, 13], "temperature": 0.0, "avg_logprob": -0.12895436015555528, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.8053331586997956e-05}, {"id": 84, "seek": 31880, "start": 343.88, "end": 346.44, "text": " But as I said in the beginning, in this talk, we will focus on the command line because", "tokens": [583, 382, 286, 848, 294, 264, 2863, 11, 294, 341, 751, 11, 321, 486, 1879, 322, 264, 5622, 1622, 570], "temperature": 0.0, "avg_logprob": -0.12895436015555528, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.8053331586997956e-05}, {"id": 85, "seek": 34644, "start": 346.44, "end": 351.48, "text": " we're in a developer conference and I will also assume that we run Kubo, which is the", "tokens": [321, 434, 294, 257, 10754, 7586, 293, 286, 486, 611, 6552, 300, 321, 1190, 35805, 78, 11, 597, 307, 264], "temperature": 0.0, "avg_logprob": -0.13546328598193907, "compression_ratio": 1.6150234741784038, "no_speech_prob": 1.4966331036703195e-05}, {"id": 86, "seek": 34644, "start": 351.48, "end": 353.88, "text": " reference implementation basically.", "tokens": [6408, 11420, 1936, 13], "temperature": 0.0, "avg_logprob": -0.13546328598193907, "compression_ratio": 1.6150234741784038, "no_speech_prob": 1.4966331036703195e-05}, {"id": 87, "seek": 34644, "start": 353.88, "end": 362.36, "text": " So now we have downloaded Kubo from github.com slash IPFS slash Kubo and we want to import", "tokens": [407, 586, 321, 362, 21748, 35805, 78, 490, 290, 355, 836, 13, 1112, 17330, 8671, 29318, 17330, 35805, 78, 293, 321, 528, 281, 974], "temperature": 0.0, "avg_logprob": -0.13546328598193907, "compression_ratio": 1.6150234741784038, "no_speech_prob": 1.4966331036703195e-05}, {"id": 88, "seek": 34644, "start": 362.36, "end": 364.15999999999997, "text": " some content, we just want to get started.", "tokens": [512, 2701, 11, 321, 445, 528, 281, 483, 1409, 13], "temperature": 0.0, "avg_logprob": -0.13546328598193907, "compression_ratio": 1.6150234741784038, "no_speech_prob": 1.4966331036703195e-05}, {"id": 89, "seek": 34644, "start": 364.15999999999997, "end": 369.08, "text": " So we downloaded it and now we have this IPFS command on our machine and the first thing", "tokens": [407, 321, 21748, 309, 293, 586, 321, 362, 341, 8671, 29318, 5622, 322, 527, 3479, 293, 264, 700, 551], "temperature": 0.0, "avg_logprob": -0.13546328598193907, "compression_ratio": 1.6150234741784038, "no_speech_prob": 1.4966331036703195e-05}, {"id": 90, "seek": 36908, "start": 369.08, "end": 376.59999999999997, "text": " that we do is run IPFS in it and what this does is it generates a public parried key pair", "tokens": [300, 321, 360, 307, 1190, 8671, 29318, 294, 309, 293, 437, 341, 775, 307, 309, 23815, 257, 1908, 971, 2428, 2141, 6119], "temperature": 0.0, "avg_logprob": -0.22563497798959004, "compression_ratio": 1.5879828326180256, "no_speech_prob": 1.5685804100940004e-05}, {"id": 91, "seek": 36908, "start": 376.59999999999997, "end": 383.4, "text": " per default in ED25519 and it spits out this random string of characters, which is basically", "tokens": [680, 7576, 294, 18050, 6074, 20, 3405, 293, 309, 637, 1208, 484, 341, 4974, 6798, 295, 4342, 11, 597, 307, 1936], "temperature": 0.0, "avg_logprob": -0.22563497798959004, "compression_ratio": 1.5879828326180256, "no_speech_prob": 1.5685804100940004e-05}, {"id": 92, "seek": 36908, "start": 383.4, "end": 384.56, "text": " your public key.", "tokens": [428, 1908, 2141, 13], "temperature": 0.0, "avg_logprob": -0.22563497798959004, "compression_ratio": 1.5879828326180256, "no_speech_prob": 1.5685804100940004e-05}, {"id": 93, "seek": 36908, "start": 384.56, "end": 392.12, "text": " So formally it was just the hash of your public key, but now it's just encoded your public", "tokens": [407, 25983, 309, 390, 445, 264, 22019, 295, 428, 1908, 2141, 11, 457, 586, 309, 311, 445, 2058, 12340, 428, 1908], "temperature": 0.0, "avg_logprob": -0.22563497798959004, "compression_ratio": 1.5879828326180256, "no_speech_prob": 1.5685804100940004e-05}, {"id": 94, "seek": 36908, "start": 392.12, "end": 398.03999999999996, "text": " key in here and this is your PR identity, which will become important later on.", "tokens": [2141, 294, 510, 293, 341, 307, 428, 11568, 6575, 11, 597, 486, 1813, 1021, 1780, 322, 13], "temperature": 0.0, "avg_logprob": -0.22563497798959004, "compression_ratio": 1.5879828326180256, "no_speech_prob": 1.5685804100940004e-05}, {"id": 95, "seek": 39804, "start": 398.04, "end": 403.72, "text": " And it also initializes your IPFS repository per default in your home directory under.ipfs.", "tokens": [400, 309, 611, 5883, 5660, 428, 8671, 29318, 25841, 680, 7576, 294, 428, 1280, 21120, 833, 2411, 647, 16883, 13], "temperature": 0.0, "avg_logprob": -0.15487606757510025, "compression_ratio": 1.684981684981685, "no_speech_prob": 1.3207792108005378e-05}, {"id": 96, "seek": 39804, "start": 403.72, "end": 405.88, "text": " This is the location where it stores all the files.", "tokens": [639, 307, 264, 4914, 689, 309, 9512, 439, 264, 7098, 13], "temperature": 0.0, "avg_logprob": -0.15487606757510025, "compression_ratio": 1.684981684981685, "no_speech_prob": 1.3207792108005378e-05}, {"id": 97, "seek": 39804, "start": 405.88, "end": 410.72, "text": " So if you interact with the IPFS network and request files, it stores it in this directory", "tokens": [407, 498, 291, 4648, 365, 264, 8671, 29318, 3209, 293, 5308, 7098, 11, 309, 9512, 309, 294, 341, 21120], "temperature": 0.0, "avg_logprob": -0.15487606757510025, "compression_ratio": 1.684981684981685, "no_speech_prob": 1.3207792108005378e-05}, {"id": 98, "seek": 39804, "start": 410.72, "end": 417.88, "text": " in a specific format similar to Git, how Git does the Git object store basically.", "tokens": [294, 257, 2685, 7877, 2531, 281, 16939, 11, 577, 16939, 775, 264, 16939, 2657, 3531, 1936, 13], "temperature": 0.0, "avg_logprob": -0.15487606757510025, "compression_ratio": 1.684981684981685, "no_speech_prob": 1.3207792108005378e-05}, {"id": 99, "seek": 39804, "start": 417.88, "end": 421.24, "text": " And importantly, I will point this out a couple of times, this is just a local operation.", "tokens": [400, 8906, 11, 286, 486, 935, 341, 484, 257, 1916, 295, 1413, 11, 341, 307, 445, 257, 2654, 6916, 13], "temperature": 0.0, "avg_logprob": -0.15487606757510025, "compression_ratio": 1.684981684981685, "no_speech_prob": 1.3207792108005378e-05}, {"id": 100, "seek": 39804, "start": 421.24, "end": 425.32000000000005, "text": " So we haven't interacted with the network at all yet.", "tokens": [407, 321, 2378, 380, 49621, 365, 264, 3209, 412, 439, 1939, 13], "temperature": 0.0, "avg_logprob": -0.15487606757510025, "compression_ratio": 1.684981684981685, "no_speech_prob": 1.3207792108005378e-05}, {"id": 101, "seek": 42532, "start": 425.32, "end": 429.56, "text": " So now we are ready to go, I have a file I want to add.", "tokens": [407, 586, 321, 366, 1919, 281, 352, 11, 286, 362, 257, 3991, 286, 528, 281, 909, 13], "temperature": 0.0, "avg_logprob": -0.13489001021425948, "compression_ratio": 1.6963562753036436, "no_speech_prob": 5.172865712665953e-06}, {"id": 102, "seek": 42532, "start": 429.56, "end": 436.44, "text": " So what I do is I run IPFS add and then my file name and in this case IPFS gives you", "tokens": [407, 437, 286, 360, 307, 286, 1190, 8671, 29318, 909, 293, 550, 452, 3991, 1315, 293, 294, 341, 1389, 8671, 29318, 2709, 291], "temperature": 0.0, "avg_logprob": -0.13489001021425948, "compression_ratio": 1.6963562753036436, "no_speech_prob": 5.172865712665953e-06}, {"id": 103, "seek": 42532, "start": 436.44, "end": 441.08, "text": " like a progress bar or a Kubo gives you a progress bar and spits out again a random", "tokens": [411, 257, 4205, 2159, 420, 257, 35805, 78, 2709, 291, 257, 4205, 2159, 293, 637, 1208, 484, 797, 257, 4974], "temperature": 0.0, "avg_logprob": -0.13489001021425948, "compression_ratio": 1.6963562753036436, "no_speech_prob": 5.172865712665953e-06}, {"id": 104, "seek": 42532, "start": 441.08, "end": 446.32, "text": " string of characters, which is the content identifier, the CID, which is the most fundamental", "tokens": [6798, 295, 4342, 11, 597, 307, 264, 2701, 45690, 11, 264, 383, 2777, 11, 597, 307, 264, 881, 8088], "temperature": 0.0, "avg_logprob": -0.13489001021425948, "compression_ratio": 1.6963562753036436, "no_speech_prob": 5.172865712665953e-06}, {"id": 105, "seek": 42532, "start": 446.32, "end": 447.32, "text": " ingredient here.", "tokens": [14751, 510, 13], "temperature": 0.0, "avg_logprob": -0.13489001021425948, "compression_ratio": 1.6963562753036436, "no_speech_prob": 5.172865712665953e-06}, {"id": 106, "seek": 42532, "start": 447.32, "end": 452.08, "text": " And this is the part where it decouples the host, sorry, the content from its host.", "tokens": [400, 341, 307, 264, 644, 689, 309, 979, 263, 2622, 264, 3975, 11, 2597, 11, 264, 2701, 490, 1080, 3975, 13], "temperature": 0.0, "avg_logprob": -0.13489001021425948, "compression_ratio": 1.6963562753036436, "no_speech_prob": 5.172865712665953e-06}, {"id": 107, "seek": 45208, "start": 452.08, "end": 456.84, "text": " And as a mental model, you can think about the CID as a hash with some metadata.", "tokens": [400, 382, 257, 4973, 2316, 11, 291, 393, 519, 466, 264, 383, 2777, 382, 257, 22019, 365, 512, 26603, 13], "temperature": 0.0, "avg_logprob": -0.12866388048444474, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.202441671921406e-05}, {"id": 108, "seek": 45208, "start": 456.84, "end": 458.0, "text": " It's self-describing.", "tokens": [467, 311, 2698, 12, 14792, 39541, 13], "temperature": 0.0, "avg_logprob": -0.12866388048444474, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.202441671921406e-05}, {"id": 109, "seek": 45208, "start": 458.0, "end": 461.12, "text": " So the metadata is this description part.", "tokens": [407, 264, 26603, 307, 341, 3855, 644, 13], "temperature": 0.0, "avg_logprob": -0.12866388048444474, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.202441671921406e-05}, {"id": 110, "seek": 45208, "start": 461.12, "end": 463.35999999999996, "text": " You can see the ingredients at the bottom.", "tokens": [509, 393, 536, 264, 6952, 412, 264, 2767, 13], "temperature": 0.0, "avg_logprob": -0.12866388048444474, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.202441671921406e-05}, {"id": 111, "seek": 45208, "start": 463.35999999999996, "end": 467.96, "text": " So it's just an encoded version of some information like a CID version.", "tokens": [407, 309, 311, 445, 364, 2058, 12340, 3037, 295, 512, 1589, 411, 257, 383, 2777, 3037, 13], "temperature": 0.0, "avg_logprob": -0.12866388048444474, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.202441671921406e-05}, {"id": 112, "seek": 45208, "start": 467.96, "end": 474.44, "text": " So we have version zero and one and some other information that I won't go into right now.", "tokens": [407, 321, 362, 3037, 4018, 293, 472, 293, 512, 661, 1589, 300, 286, 1582, 380, 352, 666, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.12866388048444474, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.202441671921406e-05}, {"id": 113, "seek": 45208, "start": 474.44, "end": 475.91999999999996, "text": " Then it's self-certifying.", "tokens": [1396, 309, 311, 2698, 12, 48999, 5489, 13], "temperature": 0.0, "avg_logprob": -0.12866388048444474, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.202441671921406e-05}, {"id": 114, "seek": 47592, "start": 475.92, "end": 483.6, "text": " This is the point where if you request some data from the network, you certify the data", "tokens": [639, 307, 264, 935, 689, 498, 291, 5308, 512, 1412, 490, 264, 3209, 11, 291, 5351, 2505, 264, 1412], "temperature": 0.0, "avg_logprob": -0.1942142027395743, "compression_ratio": 1.6653225806451613, "no_speech_prob": 7.404977623082232e-06}, {"id": 115, "seek": 47592, "start": 483.6, "end": 489.28000000000003, "text": " that you could serve with the CID itself and not with the host that served you the content", "tokens": [300, 291, 727, 4596, 365, 264, 383, 2777, 2564, 293, 406, 365, 264, 3975, 300, 7584, 291, 264, 2701], "temperature": 0.0, "avg_logprob": -0.1942142027395743, "compression_ratio": 1.6653225806451613, "no_speech_prob": 7.404977623082232e-06}, {"id": 116, "seek": 47592, "start": 489.28000000000003, "end": 491.8, "text": " and just reiterating this.", "tokens": [293, 445, 25211, 990, 341, 13], "temperature": 0.0, "avg_logprob": -0.1942142027395743, "compression_ratio": 1.6653225806451613, "no_speech_prob": 7.404977623082232e-06}, {"id": 117, "seek": 47592, "start": 491.8, "end": 494.6, "text": " And it's an immutable identifier.", "tokens": [400, 309, 311, 364, 3397, 32148, 45690, 13], "temperature": 0.0, "avg_logprob": -0.1942142027395743, "compression_ratio": 1.6653225806451613, "no_speech_prob": 7.404977623082232e-06}, {"id": 118, "seek": 47592, "start": 494.6, "end": 499.0, "text": " And all these structures like the CID structure at the bottom and so on is governed by a project", "tokens": [400, 439, 613, 9227, 411, 264, 383, 2777, 3877, 412, 264, 2767, 293, 370, 322, 307, 35529, 538, 257, 1716], "temperature": 0.0, "avg_logprob": -0.1942142027395743, "compression_ratio": 1.6653225806451613, "no_speech_prob": 7.404977623082232e-06}, {"id": 119, "seek": 47592, "start": 499.0, "end": 505.08000000000004, "text": " that's called multi-formats and it's also one of Prolucolab's projects here.", "tokens": [300, 311, 1219, 4825, 12, 837, 1720, 293, 309, 311, 611, 472, 295, 1705, 75, 1311, 401, 455, 311, 4455, 510, 13], "temperature": 0.0, "avg_logprob": -0.1942142027395743, "compression_ratio": 1.6653225806451613, "no_speech_prob": 7.404977623082232e-06}, {"id": 120, "seek": 50508, "start": 505.08, "end": 511.08, "text": " And so the talk is called what happens under the hood, so what actually happened here.", "tokens": [400, 370, 264, 751, 307, 1219, 437, 2314, 833, 264, 13376, 11, 370, 437, 767, 2011, 510, 13], "temperature": 0.0, "avg_logprob": -0.21897836768108866, "compression_ratio": 1.6705426356589148, "no_speech_prob": 8.797600457910448e-06}, {"id": 121, "seek": 50508, "start": 511.08, "end": 517.4, "text": " IPFS saw the file, which is just this white box here, a stream of bytes, and IPFS chunked", "tokens": [8671, 29318, 1866, 264, 3991, 11, 597, 307, 445, 341, 2418, 2424, 510, 11, 257, 4309, 295, 36088, 11, 293, 8671, 29318, 16635, 292], "temperature": 0.0, "avg_logprob": -0.21897836768108866, "compression_ratio": 1.6705426356589148, "no_speech_prob": 8.797600457910448e-06}, {"id": 122, "seek": 50508, "start": 517.4, "end": 518.4, "text": " it up.", "tokens": [309, 493, 13], "temperature": 0.0, "avg_logprob": -0.21897836768108866, "compression_ratio": 1.6705426356589148, "no_speech_prob": 8.797600457910448e-06}, {"id": 123, "seek": 50508, "start": 518.4, "end": 523.3199999999999, "text": " It's in different pieces, which is a common technique in networking, actually.", "tokens": [467, 311, 294, 819, 3755, 11, 597, 307, 257, 2689, 6532, 294, 17985, 11, 767, 13], "temperature": 0.0, "avg_logprob": -0.21897836768108866, "compression_ratio": 1.6705426356589148, "no_speech_prob": 8.797600457910448e-06}, {"id": 124, "seek": 50508, "start": 523.3199999999999, "end": 526.88, "text": " And this gives us some nice properties.", "tokens": [400, 341, 2709, 505, 512, 1481, 7221, 13], "temperature": 0.0, "avg_logprob": -0.21897836768108866, "compression_ratio": 1.6705426356589148, "no_speech_prob": 8.797600457910448e-06}, {"id": 125, "seek": 50508, "start": 526.88, "end": 531.4399999999999, "text": " It allows us to do piecewise transfers so we can request blocks from different hosts,", "tokens": [467, 4045, 505, 281, 360, 2522, 3711, 29137, 370, 321, 393, 5308, 8474, 490, 819, 21573, 11], "temperature": 0.0, "avg_logprob": -0.21897836768108866, "compression_ratio": 1.6705426356589148, "no_speech_prob": 8.797600457910448e-06}, {"id": 126, "seek": 50508, "start": 531.4399999999999, "end": 532.96, "text": " actually.", "tokens": [767, 13], "temperature": 0.0, "avg_logprob": -0.21897836768108866, "compression_ratio": 1.6705426356589148, "no_speech_prob": 8.797600457910448e-06}, {"id": 127, "seek": 50508, "start": 532.96, "end": 534.76, "text": " And it allows for deduplication.", "tokens": [400, 309, 4045, 337, 4172, 84, 4770, 399, 13], "temperature": 0.0, "avg_logprob": -0.21897836768108866, "compression_ratio": 1.6705426356589148, "no_speech_prob": 8.797600457910448e-06}, {"id": 128, "seek": 53476, "start": 534.76, "end": 541.2, "text": " Also if we have two blocks that are basically the same bytes, we can deduplicate that and", "tokens": [2743, 498, 321, 362, 732, 8474, 300, 366, 1936, 264, 912, 36088, 11, 321, 393, 4172, 84, 4770, 473, 300, 293], "temperature": 0.0, "avg_logprob": -0.0887938395585164, "compression_ratio": 1.6565217391304348, "no_speech_prob": 1.473722204536898e-05}, {"id": 129, "seek": 53476, "start": 541.2, "end": 544.08, "text": " save some storage space underneath.", "tokens": [3155, 512, 6725, 1901, 7223, 13], "temperature": 0.0, "avg_logprob": -0.0887938395585164, "compression_ratio": 1.6565217391304348, "no_speech_prob": 1.473722204536898e-05}, {"id": 130, "seek": 53476, "start": 544.08, "end": 549.72, "text": " And also if the file was a video file, we also allow for random access so we could start", "tokens": [400, 611, 498, 264, 3991, 390, 257, 960, 3991, 11, 321, 611, 2089, 337, 4974, 2105, 370, 321, 727, 722], "temperature": 0.0, "avg_logprob": -0.0887938395585164, "compression_ratio": 1.6565217391304348, "no_speech_prob": 1.473722204536898e-05}, {"id": 131, "seek": 53476, "start": 549.72, "end": 556.72, "text": " in the middle of a video and don't need to stream all the previous bytes at all.", "tokens": [294, 264, 2808, 295, 257, 960, 293, 500, 380, 643, 281, 4309, 439, 264, 3894, 36088, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.0887938395585164, "compression_ratio": 1.6565217391304348, "no_speech_prob": 1.473722204536898e-05}, {"id": 132, "seek": 53476, "start": 556.72, "end": 562.16, "text": " And after we have chunked that up, what we do now or what IPFS does now is we need to", "tokens": [400, 934, 321, 362, 16635, 292, 300, 493, 11, 437, 321, 360, 586, 420, 437, 8671, 29318, 775, 586, 307, 321, 643, 281], "temperature": 0.0, "avg_logprob": -0.0887938395585164, "compression_ratio": 1.6565217391304348, "no_speech_prob": 1.473722204536898e-05}, {"id": 133, "seek": 56216, "start": 562.16, "end": 565.4399999999999, "text": " put them, we need to put it together again.", "tokens": [829, 552, 11, 321, 643, 281, 829, 309, 1214, 797, 13], "temperature": 0.0, "avg_logprob": -0.11447392060206486, "compression_ratio": 1.6936936936936937, "no_speech_prob": 1.6437956219306216e-05}, {"id": 134, "seek": 56216, "start": 565.4399999999999, "end": 569.3199999999999, "text": " And what we do here is we hash each individual chunk.", "tokens": [400, 437, 321, 360, 510, 307, 321, 22019, 1184, 2609, 16635, 13], "temperature": 0.0, "avg_logprob": -0.11447392060206486, "compression_ratio": 1.6936936936936937, "no_speech_prob": 1.6437956219306216e-05}, {"id": 135, "seek": 56216, "start": 569.3199999999999, "end": 574.0, "text": " Each chunk gets its own CID, its own content identifier.", "tokens": [6947, 16635, 2170, 1080, 1065, 383, 2777, 11, 1080, 1065, 2701, 45690, 13], "temperature": 0.0, "avg_logprob": -0.11447392060206486, "compression_ratio": 1.6936936936936937, "no_speech_prob": 1.6437956219306216e-05}, {"id": 136, "seek": 56216, "start": 574.0, "end": 580.36, "text": " Then the combination of each CID again gets another CID and we do this for both pairs", "tokens": [1396, 264, 6562, 295, 1184, 383, 2777, 797, 2170, 1071, 383, 2777, 293, 321, 360, 341, 337, 1293, 15494], "temperature": 0.0, "avg_logprob": -0.11447392060206486, "compression_ratio": 1.6936936936936937, "no_speech_prob": 1.6437956219306216e-05}, {"id": 137, "seek": 56216, "start": 580.36, "end": 581.8399999999999, "text": " at the bottom.", "tokens": [412, 264, 2767, 13], "temperature": 0.0, "avg_logprob": -0.11447392060206486, "compression_ratio": 1.6936936936936937, "no_speech_prob": 1.6437956219306216e-05}, {"id": 138, "seek": 56216, "start": 581.8399999999999, "end": 588.64, "text": " And then the resulting common CIDs again will be put together yet again to generate the", "tokens": [400, 550, 264, 16505, 2689, 383, 2777, 82, 797, 486, 312, 829, 1214, 1939, 797, 281, 8460, 264], "temperature": 0.0, "avg_logprob": -0.11447392060206486, "compression_ratio": 1.6936936936936937, "no_speech_prob": 1.6437956219306216e-05}, {"id": 139, "seek": 56216, "start": 588.64, "end": 590.6, "text": " root CID, that's how we call it.", "tokens": [5593, 383, 2777, 11, 300, 311, 577, 321, 818, 309, 13], "temperature": 0.0, "avg_logprob": -0.11447392060206486, "compression_ratio": 1.6936936936936937, "no_speech_prob": 1.6437956219306216e-05}, {"id": 140, "seek": 59060, "start": 590.6, "end": 593.9200000000001, "text": " And this is actually the CID that you see in the command line up there.", "tokens": [400, 341, 307, 767, 264, 383, 2777, 300, 291, 536, 294, 264, 5622, 1622, 493, 456, 13], "temperature": 0.0, "avg_logprob": -0.15354227250622166, "compression_ratio": 1.7245283018867925, "no_speech_prob": 1.0128574103873689e-05}, {"id": 141, "seek": 59060, "start": 593.9200000000001, "end": 600.48, "text": " So we took the chunks, put them, put the identifiers together to arrive at the final CID at the", "tokens": [407, 321, 1890, 264, 24004, 11, 829, 552, 11, 829, 264, 2473, 23463, 1214, 281, 8881, 412, 264, 2572, 383, 2777, 412, 264], "temperature": 0.0, "avg_logprob": -0.15354227250622166, "compression_ratio": 1.7245283018867925, "no_speech_prob": 1.0128574103873689e-05}, {"id": 142, "seek": 59060, "start": 600.48, "end": 601.48, "text": " top.", "tokens": [1192, 13], "temperature": 0.0, "avg_logprob": -0.15354227250622166, "compression_ratio": 1.7245283018867925, "no_speech_prob": 1.0128574103873689e-05}, {"id": 143, "seek": 59060, "start": 601.48, "end": 605.9200000000001, "text": " And this data structure is actually called a Merkle tree, but in IPFS land it's actually", "tokens": [400, 341, 1412, 3877, 307, 767, 1219, 257, 6124, 14677, 4230, 11, 457, 294, 8671, 29318, 2117, 309, 311, 767], "temperature": 0.0, "avg_logprob": -0.15354227250622166, "compression_ratio": 1.7245283018867925, "no_speech_prob": 1.0128574103873689e-05}, {"id": 144, "seek": 59060, "start": 605.9200000000001, "end": 611.28, "text": " a Merkle deck because in Merkle trees your nodes are not allowed to have common parents.", "tokens": [257, 6124, 14677, 9341, 570, 294, 6124, 14677, 5852, 428, 13891, 366, 406, 4350, 281, 362, 2689, 3152, 13], "temperature": 0.0, "avg_logprob": -0.15354227250622166, "compression_ratio": 1.7245283018867925, "no_speech_prob": 1.0128574103873689e-05}, {"id": 145, "seek": 59060, "start": 611.28, "end": 614.32, "text": " And the deck means here a directed acyclic graph.", "tokens": [400, 264, 9341, 1355, 510, 257, 12898, 696, 88, 66, 1050, 4295, 13], "temperature": 0.0, "avg_logprob": -0.15354227250622166, "compression_ratio": 1.7245283018867925, "no_speech_prob": 1.0128574103873689e-05}, {"id": 146, "seek": 59060, "start": 614.32, "end": 618.6, "text": " And let's imagine you didn't add a file but a directory.", "tokens": [400, 718, 311, 3811, 291, 994, 380, 909, 257, 3991, 457, 257, 21120, 13], "temperature": 0.0, "avg_logprob": -0.15354227250622166, "compression_ratio": 1.7245283018867925, "no_speech_prob": 1.0128574103873689e-05}, {"id": 147, "seek": 61860, "start": 618.6, "end": 624.8000000000001, "text": " How do you encode the directory structure and not only the bytes and so on?", "tokens": [1012, 360, 291, 2058, 1429, 264, 21120, 3877, 293, 406, 787, 264, 36088, 293, 370, 322, 30], "temperature": 0.0, "avg_logprob": -0.1672717503138951, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.384287497785408e-05}, {"id": 148, "seek": 61860, "start": 624.8000000000001, "end": 630.28, "text": " All these formatting and serialization, deserialization things are governed by yet another project.", "tokens": [1057, 613, 39366, 293, 17436, 2144, 11, 730, 260, 831, 2144, 721, 366, 35529, 538, 1939, 1071, 1716, 13], "temperature": 0.0, "avg_logprob": -0.1672717503138951, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.384287497785408e-05}, {"id": 149, "seek": 61860, "start": 630.28, "end": 634.64, "text": " It's called IPLD, which stands for Interplanetary Link Data.", "tokens": [467, 311, 1219, 8671, 23704, 11, 597, 7382, 337, 5751, 16554, 302, 822, 8466, 11888, 13], "temperature": 0.0, "avg_logprob": -0.1672717503138951, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.384287497785408e-05}, {"id": 150, "seek": 61860, "start": 634.64, "end": 640.6800000000001, "text": " And IPLD does also a lot of more things, but for now this is specified in the scope of", "tokens": [400, 8671, 23704, 775, 611, 257, 688, 295, 544, 721, 11, 457, 337, 586, 341, 307, 22206, 294, 264, 11923, 295], "temperature": 0.0, "avg_logprob": -0.1672717503138951, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.384287497785408e-05}, {"id": 151, "seek": 61860, "start": 640.6800000000001, "end": 642.36, "text": " this project.", "tokens": [341, 1716, 13], "temperature": 0.0, "avg_logprob": -0.1672717503138951, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.384287497785408e-05}, {"id": 152, "seek": 61860, "start": 642.36, "end": 646.84, "text": " So now we have imported the content.", "tokens": [407, 586, 321, 362, 25524, 264, 2701, 13], "temperature": 0.0, "avg_logprob": -0.1672717503138951, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.384287497785408e-05}, {"id": 153, "seek": 64684, "start": 646.84, "end": 650.24, "text": " We have chunked it up, we've got the CID.", "tokens": [492, 362, 16635, 292, 309, 493, 11, 321, 600, 658, 264, 383, 2777, 13], "temperature": 0.0, "avg_logprob": -0.121080524043033, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.5439109120052308e-05}, {"id": 154, "seek": 64684, "start": 650.24, "end": 653.64, "text": " But again, we haven't interacted with the network yet.", "tokens": [583, 797, 11, 321, 2378, 380, 49621, 365, 264, 3209, 1939, 13], "temperature": 0.0, "avg_logprob": -0.121080524043033, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.5439109120052308e-05}, {"id": 155, "seek": 64684, "start": 653.64, "end": 658.0400000000001, "text": " So people think if you add something to IPFS you upload it somewhere and someone else takes", "tokens": [407, 561, 519, 498, 291, 909, 746, 281, 8671, 29318, 291, 6580, 309, 4079, 293, 1580, 1646, 2516], "temperature": 0.0, "avg_logprob": -0.121080524043033, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.5439109120052308e-05}, {"id": 156, "seek": 64684, "start": 658.0400000000001, "end": 661.32, "text": " care of hosting it for you, for free, which is not the case.", "tokens": [1127, 295, 16058, 309, 337, 291, 11, 337, 1737, 11, 597, 307, 406, 264, 1389, 13], "temperature": 0.0, "avg_logprob": -0.121080524043033, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.5439109120052308e-05}, {"id": 157, "seek": 64684, "start": 661.32, "end": 663.6, "text": " So we added it to our local node.", "tokens": [407, 321, 3869, 309, 281, 527, 2654, 9984, 13], "temperature": 0.0, "avg_logprob": -0.121080524043033, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.5439109120052308e-05}, {"id": 158, "seek": 64684, "start": 663.6, "end": 669.96, "text": " So now it ended up in this IPFS repository somewhere on our local machine.", "tokens": [407, 586, 309, 4590, 493, 294, 341, 8671, 29318, 25841, 4079, 322, 527, 2654, 3479, 13], "temperature": 0.0, "avg_logprob": -0.121080524043033, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.5439109120052308e-05}, {"id": 159, "seek": 64684, "start": 669.96, "end": 673.6800000000001, "text": " But only now we connect to the network and interact with it.", "tokens": [583, 787, 586, 321, 1745, 281, 264, 3209, 293, 4648, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.121080524043033, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.5439109120052308e-05}, {"id": 160, "seek": 67368, "start": 673.68, "end": 681.16, "text": " For that we run IPFS daemon, which is a long-running process that connects to nodes in the network.", "tokens": [1171, 300, 321, 1190, 8671, 29318, 1120, 36228, 11, 597, 307, 257, 938, 12, 45482, 1399, 300, 16967, 281, 13891, 294, 264, 3209, 13], "temperature": 0.0, "avg_logprob": -0.13747495075441757, "compression_ratio": 1.6944444444444444, "no_speech_prob": 7.64177821110934e-06}, {"id": 161, "seek": 67368, "start": 681.16, "end": 684.52, "text": " We see some versioning information with which Go version was compiled with Kubo version", "tokens": [492, 536, 512, 3037, 278, 1589, 365, 597, 1037, 3037, 390, 36548, 365, 35805, 78, 3037], "temperature": 0.0, "avg_logprob": -0.13747495075441757, "compression_ratio": 1.6944444444444444, "no_speech_prob": 7.64177821110934e-06}, {"id": 162, "seek": 67368, "start": 684.52, "end": 686.56, "text": " we actually use.", "tokens": [321, 767, 764, 13], "temperature": 0.0, "avg_logprob": -0.13747495075441757, "compression_ratio": 1.6944444444444444, "no_speech_prob": 7.64177821110934e-06}, {"id": 163, "seek": 67368, "start": 686.56, "end": 692.3199999999999, "text": " We see the addresses that the Kubo node listens on and also which ones are announced to the", "tokens": [492, 536, 264, 16862, 300, 264, 35805, 78, 9984, 35959, 322, 293, 611, 597, 2306, 366, 7548, 281, 264], "temperature": 0.0, "avg_logprob": -0.13747495075441757, "compression_ratio": 1.6944444444444444, "no_speech_prob": 7.64177821110934e-06}, {"id": 164, "seek": 67368, "start": 692.3199999999999, "end": 697.0799999999999, "text": " network, under which network addresses we are reachable.", "tokens": [3209, 11, 833, 597, 3209, 16862, 321, 366, 2524, 712, 13], "temperature": 0.0, "avg_logprob": -0.13747495075441757, "compression_ratio": 1.6944444444444444, "no_speech_prob": 7.64177821110934e-06}, {"id": 165, "seek": 67368, "start": 697.0799999999999, "end": 701.5999999999999, "text": " And then tells us that it started an API server, a web UI in the gateway.", "tokens": [400, 550, 5112, 505, 300, 309, 1409, 364, 9362, 7154, 11, 257, 3670, 15682, 294, 264, 28532, 13], "temperature": 0.0, "avg_logprob": -0.13747495075441757, "compression_ratio": 1.6944444444444444, "no_speech_prob": 7.64177821110934e-06}, {"id": 166, "seek": 70160, "start": 701.6, "end": 706.96, "text": " The API server is just an RPC API that is used by the command line to control the IPFS", "tokens": [440, 9362, 7154, 307, 445, 364, 497, 12986, 9362, 300, 307, 1143, 538, 264, 5622, 1622, 281, 1969, 264, 8671, 29318], "temperature": 0.0, "avg_logprob": -0.0924589889390128, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.1122322575829457e-05}, {"id": 167, "seek": 70160, "start": 706.96, "end": 707.96, "text": " node.", "tokens": [9984, 13], "temperature": 0.0, "avg_logprob": -0.0924589889390128, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.1122322575829457e-05}, {"id": 168, "seek": 70160, "start": 707.96, "end": 712.84, "text": " The web UI is the thing that you saw previously when you saw the screenshot of the IPFS desktop.", "tokens": [440, 3670, 15682, 307, 264, 551, 300, 291, 1866, 8046, 562, 291, 1866, 264, 27712, 295, 264, 8671, 29318, 14502, 13], "temperature": 0.0, "avg_logprob": -0.0924589889390128, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.1122322575829457e-05}, {"id": 169, "seek": 70160, "start": 712.84, "end": 718.24, "text": " So your local Kubo node also serves this web UI.", "tokens": [407, 428, 2654, 35805, 78, 9984, 611, 13451, 341, 3670, 15682, 13], "temperature": 0.0, "avg_logprob": -0.0924589889390128, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.1122322575829457e-05}, {"id": 170, "seek": 70160, "start": 718.24, "end": 719.24, "text": " And then the gateway.", "tokens": [400, 550, 264, 28532, 13], "temperature": 0.0, "avg_logprob": -0.0924589889390128, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.1122322575829457e-05}, {"id": 171, "seek": 70160, "start": 719.24, "end": 720.64, "text": " And the gateway is quite interesting.", "tokens": [400, 264, 28532, 307, 1596, 1880, 13], "temperature": 0.0, "avg_logprob": -0.0924589889390128, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.1122322575829457e-05}, {"id": 172, "seek": 70160, "start": 720.64, "end": 724.84, "text": " So this bridges the HTTP world with the IPFS world.", "tokens": [407, 341, 21114, 264, 33283, 1002, 365, 264, 8671, 29318, 1002, 13], "temperature": 0.0, "avg_logprob": -0.0924589889390128, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.1122322575829457e-05}, {"id": 173, "seek": 70160, "start": 724.84, "end": 729.28, "text": " So you can ask under this endpoint that you can see down there.", "tokens": [407, 291, 393, 1029, 833, 341, 35795, 300, 291, 393, 536, 760, 456, 13], "temperature": 0.0, "avg_logprob": -0.0924589889390128, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.1122322575829457e-05}, {"id": 174, "seek": 72928, "start": 729.28, "end": 737.04, "text": " If you put IPFS slash your CID inside the browser or in your SUD URL, the Kubo node", "tokens": [759, 291, 829, 8671, 29318, 17330, 428, 383, 2777, 1854, 264, 11185, 420, 294, 428, 318, 9438, 12905, 11, 264, 35805, 78, 9984], "temperature": 0.0, "avg_logprob": -0.16822548599930498, "compression_ratio": 1.543726235741445, "no_speech_prob": 8.938272003433667e-06}, {"id": 175, "seek": 72928, "start": 737.04, "end": 740.76, "text": " will go ahead and resolve the CID in the network and serve it to you over HTTP.", "tokens": [486, 352, 2286, 293, 14151, 264, 383, 2777, 294, 264, 3209, 293, 4596, 309, 281, 291, 670, 33283, 13], "temperature": 0.0, "avg_logprob": -0.16822548599930498, "compression_ratio": 1.543726235741445, "no_speech_prob": 8.938272003433667e-06}, {"id": 176, "seek": 72928, "start": 740.76, "end": 744.04, "text": " So this is like a bridge between both worlds.", "tokens": [407, 341, 307, 411, 257, 7283, 1296, 1293, 13401, 13], "temperature": 0.0, "avg_logprob": -0.16822548599930498, "compression_ratio": 1.543726235741445, "no_speech_prob": 8.938272003433667e-06}, {"id": 177, "seek": 72928, "start": 744.04, "end": 749.48, "text": " And ProCollapse and Cloudflare and so on are actually running these gateways on the internet", "tokens": [400, 1705, 35294, 11145, 293, 8061, 3423, 543, 293, 370, 322, 366, 767, 2614, 613, 8539, 942, 322, 264, 4705], "temperature": 0.0, "avg_logprob": -0.16822548599930498, "compression_ratio": 1.543726235741445, "no_speech_prob": 8.938272003433667e-06}, {"id": 178, "seek": 72928, "start": 749.48, "end": 755.24, "text": " right now, which you can use just a low barrier entry to the whole thing.", "tokens": [558, 586, 11, 597, 291, 393, 764, 445, 257, 2295, 13357, 8729, 281, 264, 1379, 551, 13], "temperature": 0.0, "avg_logprob": -0.16822548599930498, "compression_ratio": 1.543726235741445, "no_speech_prob": 8.938272003433667e-06}, {"id": 179, "seek": 72928, "start": 755.24, "end": 757.1999999999999, "text": " And then the daemon is ready.", "tokens": [400, 550, 264, 1120, 36228, 307, 1919, 13], "temperature": 0.0, "avg_logprob": -0.16822548599930498, "compression_ratio": 1.543726235741445, "no_speech_prob": 8.938272003433667e-06}, {"id": 180, "seek": 75720, "start": 757.2, "end": 761.2800000000001, "text": " And in this process, it has also connected to bootstrap nodes, which are hard coded to", "tokens": [400, 294, 341, 1399, 11, 309, 575, 611, 4582, 281, 11450, 372, 4007, 13891, 11, 597, 366, 1152, 34874, 281], "temperature": 0.0, "avg_logprob": -0.13403048882117638, "compression_ratio": 1.7025862068965518, "no_speech_prob": 7.887589163146913e-06}, {"id": 181, "seek": 75720, "start": 761.2800000000001, "end": 763.9200000000001, "text": " actually get to know other peers in the network.", "tokens": [767, 483, 281, 458, 661, 16739, 294, 264, 3209, 13], "temperature": 0.0, "avg_logprob": -0.13403048882117638, "compression_ratio": 1.7025862068965518, "no_speech_prob": 7.887589163146913e-06}, {"id": 182, "seek": 75720, "start": 763.9200000000001, "end": 768.96, "text": " But you can also override it with your own bootstrap nodes.", "tokens": [583, 291, 393, 611, 42321, 309, 365, 428, 1065, 11450, 372, 4007, 13891, 13], "temperature": 0.0, "avg_logprob": -0.13403048882117638, "compression_ratio": 1.7025862068965518, "no_speech_prob": 7.887589163146913e-06}, {"id": 183, "seek": 75720, "start": 768.96, "end": 769.96, "text": " So now we are connected to the network.", "tokens": [407, 586, 321, 366, 4582, 281, 264, 3209, 13], "temperature": 0.0, "avg_logprob": -0.13403048882117638, "compression_ratio": 1.7025862068965518, "no_speech_prob": 7.887589163146913e-06}, {"id": 184, "seek": 75720, "start": 769.96, "end": 773.5200000000001, "text": " We have added our file to our own machine.", "tokens": [492, 362, 3869, 527, 3991, 281, 527, 1065, 3479, 13], "temperature": 0.0, "avg_logprob": -0.13403048882117638, "compression_ratio": 1.7025862068965518, "no_speech_prob": 7.887589163146913e-06}, {"id": 185, "seek": 75720, "start": 773.5200000000001, "end": 779.1600000000001, "text": " But now the interesting or the problem or like the challenge, how do we actually find", "tokens": [583, 586, 264, 1880, 420, 264, 1154, 420, 411, 264, 3430, 11, 577, 360, 321, 767, 915], "temperature": 0.0, "avg_logprob": -0.13403048882117638, "compression_ratio": 1.7025862068965518, "no_speech_prob": 7.887589163146913e-06}, {"id": 186, "seek": 75720, "start": 779.1600000000001, "end": 782.0, "text": " content hosts for a given CID?", "tokens": [2701, 21573, 337, 257, 2212, 383, 2777, 30], "temperature": 0.0, "avg_logprob": -0.13403048882117638, "compression_ratio": 1.7025862068965518, "no_speech_prob": 7.887589163146913e-06}, {"id": 187, "seek": 78200, "start": 782.0, "end": 788.64, "text": " So I give my friend a CID, how does the node know that it needs to connect to me to request", "tokens": [407, 286, 976, 452, 1277, 257, 383, 2777, 11, 577, 775, 264, 9984, 458, 300, 309, 2203, 281, 1745, 281, 385, 281, 5308], "temperature": 0.0, "avg_logprob": -0.1250986659198726, "compression_ratio": 1.5984251968503937, "no_speech_prob": 4.565415110846516e-06}, {"id": 188, "seek": 78200, "start": 788.64, "end": 789.64, "text": " the content, actually?", "tokens": [264, 2701, 11, 767, 30], "temperature": 0.0, "avg_logprob": -0.1250986659198726, "compression_ratio": 1.5984251968503937, "no_speech_prob": 4.565415110846516e-06}, {"id": 189, "seek": 78200, "start": 789.64, "end": 791.76, "text": " And I put here the solution is simple.", "tokens": [400, 286, 829, 510, 264, 3827, 307, 2199, 13], "temperature": 0.0, "avg_logprob": -0.1250986659198726, "compression_ratio": 1.5984251968503937, "no_speech_prob": 4.565415110846516e-06}, {"id": 190, "seek": 78200, "start": 791.76, "end": 792.76, "text": " We keep a mapping table.", "tokens": [492, 1066, 257, 18350, 3199, 13], "temperature": 0.0, "avg_logprob": -0.1250986659198726, "compression_ratio": 1.5984251968503937, "no_speech_prob": 4.565415110846516e-06}, {"id": 191, "seek": 78200, "start": 792.76, "end": 797.52, "text": " So we just have the CID mapped to the actual peer and every node has this on their machine.", "tokens": [407, 321, 445, 362, 264, 383, 2777, 33318, 281, 264, 3539, 15108, 293, 633, 9984, 575, 341, 322, 641, 3479, 13], "temperature": 0.0, "avg_logprob": -0.1250986659198726, "compression_ratio": 1.5984251968503937, "no_speech_prob": 4.565415110846516e-06}, {"id": 192, "seek": 78200, "start": 797.52, "end": 801.12, "text": " So everyone knows everything, basically.", "tokens": [407, 1518, 3255, 1203, 11, 1936, 13], "temperature": 0.0, "avg_logprob": -0.1250986659198726, "compression_ratio": 1.5984251968503937, "no_speech_prob": 4.565415110846516e-06}, {"id": 193, "seek": 78200, "start": 801.12, "end": 807.48, "text": " But as I said, the mapping table gets humongous, especially if we've split up those files into", "tokens": [583, 382, 286, 848, 11, 264, 18350, 3199, 2170, 1484, 556, 563, 11, 2318, 498, 321, 600, 7472, 493, 729, 7098, 666], "temperature": 0.0, "avg_logprob": -0.1250986659198726, "compression_ratio": 1.5984251968503937, "no_speech_prob": 4.565415110846516e-06}, {"id": 194, "seek": 80748, "start": 807.48, "end": 812.96, "text": " different chunks, and I think the default chunking size is 256 kilobytes.", "tokens": [819, 24004, 11, 293, 286, 519, 264, 7576, 16635, 278, 2744, 307, 38882, 5128, 996, 43673, 13], "temperature": 0.0, "avg_logprob": -0.1536746586070341, "compression_ratio": 1.6570247933884297, "no_speech_prob": 1.5204016563075129e-05}, {"id": 195, "seek": 80748, "start": 812.96, "end": 814.6, "text": " So we have just a lot of entries in this table.", "tokens": [407, 321, 362, 445, 257, 688, 295, 23041, 294, 341, 3199, 13], "temperature": 0.0, "avg_logprob": -0.1536746586070341, "compression_ratio": 1.6570247933884297, "no_speech_prob": 1.5204016563075129e-05}, {"id": 196, "seek": 80748, "start": 814.6, "end": 816.32, "text": " So this doesn't scale.", "tokens": [407, 341, 1177, 380, 4373, 13], "temperature": 0.0, "avg_logprob": -0.1536746586070341, "compression_ratio": 1.6570247933884297, "no_speech_prob": 1.5204016563075129e-05}, {"id": 197, "seek": 80748, "start": 816.32, "end": 820.5600000000001, "text": " So the solution would be to split this table, and each participating peer in this decentralized", "tokens": [407, 264, 3827, 576, 312, 281, 7472, 341, 3199, 11, 293, 1184, 13950, 15108, 294, 341, 32870], "temperature": 0.0, "avg_logprob": -0.1536746586070341, "compression_ratio": 1.6570247933884297, "no_speech_prob": 1.5204016563075129e-05}, {"id": 198, "seek": 80748, "start": 820.5600000000001, "end": 825.0, "text": " network holds a separate part of the table.", "tokens": [3209, 9190, 257, 4994, 644, 295, 264, 3199, 13], "temperature": 0.0, "avg_logprob": -0.1536746586070341, "compression_ratio": 1.6570247933884297, "no_speech_prob": 1.5204016563075129e-05}, {"id": 199, "seek": 80748, "start": 825.0, "end": 826.96, "text": " But then we are back to square one.", "tokens": [583, 550, 321, 366, 646, 281, 3732, 472, 13], "temperature": 0.0, "avg_logprob": -0.1536746586070341, "compression_ratio": 1.6570247933884297, "no_speech_prob": 1.5204016563075129e-05}, {"id": 200, "seek": 80748, "start": 826.96, "end": 831.64, "text": " How do we know which peer holds which piece of this distributed hash table data?", "tokens": [1012, 360, 321, 458, 597, 15108, 9190, 597, 2522, 295, 341, 12631, 22019, 3199, 1412, 30], "temperature": 0.0, "avg_logprob": -0.1536746586070341, "compression_ratio": 1.6570247933884297, "no_speech_prob": 1.5204016563075129e-05}, {"id": 201, "seek": 83164, "start": 831.64, "end": 838.4, "text": " And the solution here would be to use a just deterministic distribution based on the Cademia", "tokens": [400, 264, 3827, 510, 576, 312, 281, 764, 257, 445, 15957, 3142, 7316, 2361, 322, 264, 22323, 14058], "temperature": 0.0, "avg_logprob": -0.20621511869341413, "compression_ratio": 1.6260504201680672, "no_speech_prob": 1.4278063645178918e-05}, {"id": 202, "seek": 83164, "start": 838.4, "end": 839.4, "text": " DHT.", "tokens": [28606, 51, 13], "temperature": 0.0, "avg_logprob": -0.20621511869341413, "compression_ratio": 1.6260504201680672, "no_speech_prob": 1.4278063645178918e-05}, {"id": 203, "seek": 83164, "start": 839.4, "end": 844.56, "text": " Cademia is like a, is a, is a implementate or like a specific protocol for a distributed", "tokens": [22323, 14058, 307, 411, 257, 11, 307, 257, 11, 307, 257, 4445, 473, 420, 411, 257, 2685, 10336, 337, 257, 12631], "temperature": 0.0, "avg_logprob": -0.20621511869341413, "compression_ratio": 1.6260504201680672, "no_speech_prob": 1.4278063645178918e-05}, {"id": 204, "seek": 83164, "start": 844.56, "end": 846.3199999999999, "text": " hash table.", "tokens": [22019, 3199, 13], "temperature": 0.0, "avg_logprob": -0.20621511869341413, "compression_ratio": 1.6260504201680672, "no_speech_prob": 1.4278063645178918e-05}, {"id": 205, "seek": 83164, "start": 846.3199999999999, "end": 852.24, "text": " And at this point, I thought, so at this point, many talks on the internet about IPFS gloss", "tokens": [400, 412, 341, 935, 11, 286, 1194, 11, 370, 412, 341, 935, 11, 867, 6686, 322, 264, 4705, 466, 8671, 29318, 19574], "temperature": 0.0, "avg_logprob": -0.20621511869341413, "compression_ratio": 1.6260504201680672, "no_speech_prob": 1.4278063645178918e-05}, {"id": 206, "seek": 83164, "start": 852.24, "end": 854.3199999999999, "text": " over the DHT and how it works.", "tokens": [670, 264, 28606, 51, 293, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.20621511869341413, "compression_ratio": 1.6260504201680672, "no_speech_prob": 1.4278063645178918e-05}, {"id": 207, "seek": 83164, "start": 854.3199999999999, "end": 859.16, "text": " And so when I got into this whole thing, I was lacking something.", "tokens": [400, 370, 562, 286, 658, 666, 341, 1379, 551, 11, 286, 390, 20889, 746, 13], "temperature": 0.0, "avg_logprob": -0.20621511869341413, "compression_ratio": 1.6260504201680672, "no_speech_prob": 1.4278063645178918e-05}, {"id": 208, "seek": 85916, "start": 859.16, "end": 864.88, "text": " And so my experiment would be to just dive even a little deeper into, into this.", "tokens": [400, 370, 452, 5120, 576, 312, 281, 445, 9192, 754, 257, 707, 7731, 666, 11, 666, 341, 13], "temperature": 0.0, "avg_logprob": -0.14889069193417265, "compression_ratio": 1.6425339366515836, "no_speech_prob": 7.526770332333399e-06}, {"id": 209, "seek": 85916, "start": 864.88, "end": 870.0, "text": " And I would cover a bit of Cademia here, but at the end, this is very technical.", "tokens": [400, 286, 576, 2060, 257, 857, 295, 22323, 14058, 510, 11, 457, 412, 264, 917, 11, 341, 307, 588, 6191, 13], "temperature": 0.0, "avg_logprob": -0.14889069193417265, "compression_ratio": 1.6425339366515836, "no_speech_prob": 7.526770332333399e-06}, {"id": 210, "seek": 85916, "start": 870.0, "end": 874.68, "text": " But at the end, I would try to summarize everything so that everyone of you gets a little bit", "tokens": [583, 412, 264, 917, 11, 286, 576, 853, 281, 20858, 1203, 370, 300, 1518, 295, 291, 2170, 257, 707, 857], "temperature": 0.0, "avg_logprob": -0.14889069193417265, "compression_ratio": 1.6425339366515836, "no_speech_prob": 7.526770332333399e-06}, {"id": 211, "seek": 85916, "start": 874.68, "end": 875.92, "text": " out of this.", "tokens": [484, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.14889069193417265, "compression_ratio": 1.6425339366515836, "no_speech_prob": 7.526770332333399e-06}, {"id": 212, "seek": 85916, "start": 875.92, "end": 877.8, "text": " This whole process is called content routing.", "tokens": [639, 1379, 1399, 307, 1219, 2701, 32722, 13], "temperature": 0.0, "avg_logprob": -0.14889069193417265, "compression_ratio": 1.6425339366515836, "no_speech_prob": 7.526770332333399e-06}, {"id": 213, "seek": 85916, "start": 877.8, "end": 883.0799999999999, "text": " So this resolution of a CID to the content host.", "tokens": [407, 341, 8669, 295, 257, 383, 2777, 281, 264, 2701, 3975, 13], "temperature": 0.0, "avg_logprob": -0.14889069193417265, "compression_ratio": 1.6425339366515836, "no_speech_prob": 7.526770332333399e-06}, {"id": 214, "seek": 88308, "start": 883.08, "end": 890.36, "text": " And IPFS uses an adaptation of the Cademia DHT by using a 256 bit key space.", "tokens": [400, 8671, 29318, 4960, 364, 21549, 295, 264, 22323, 14058, 28606, 51, 538, 1228, 257, 38882, 857, 2141, 1901, 13], "temperature": 0.0, "avg_logprob": -0.11334338278140661, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.0449221008457243e-05}, {"id": 215, "seek": 88308, "start": 890.36, "end": 896.84, "text": " So we are hashing the CID and the PRID yet again with the SHA-256 to arrive in a common,", "tokens": [407, 321, 366, 575, 571, 264, 383, 2777, 293, 264, 11568, 2777, 1939, 797, 365, 264, 38820, 12, 6074, 21, 281, 8881, 294, 257, 2689, 11], "temperature": 0.0, "avg_logprob": -0.11334338278140661, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.0449221008457243e-05}, {"id": 216, "seek": 88308, "start": 896.84, "end": 898.76, "text": " in a common key space.", "tokens": [294, 257, 2689, 2141, 1901, 13], "temperature": 0.0, "avg_logprob": -0.11334338278140661, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.0449221008457243e-05}, {"id": 217, "seek": 88308, "start": 898.76, "end": 903.12, "text": " And the distributed hash table in IPFS is just a distributed system that maps these keys", "tokens": [400, 264, 12631, 22019, 3199, 294, 8671, 29318, 307, 445, 257, 12631, 1185, 300, 11317, 613, 9317], "temperature": 0.0, "avg_logprob": -0.11334338278140661, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.0449221008457243e-05}, {"id": 218, "seek": 88308, "start": 903.12, "end": 904.12, "text": " to values.", "tokens": [281, 4190, 13], "temperature": 0.0, "avg_logprob": -0.11334338278140661, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.0449221008457243e-05}, {"id": 219, "seek": 88308, "start": 904.12, "end": 910.32, "text": " And the most important records here are provider records, which map a CID to a PRID.", "tokens": [400, 264, 881, 1021, 7724, 510, 366, 12398, 7724, 11, 597, 4471, 257, 383, 2777, 281, 257, 11568, 2777, 13], "temperature": 0.0, "avg_logprob": -0.11334338278140661, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.0449221008457243e-05}, {"id": 220, "seek": 91032, "start": 910.32, "end": 914.96, "text": " Some of the PRID is that what was generated when we initialize our node.", "tokens": [2188, 295, 264, 11568, 2777, 307, 300, 437, 390, 10833, 562, 321, 5883, 1125, 527, 9984, 13], "temperature": 0.0, "avg_logprob": -0.19650084884078414, "compression_ratio": 1.7285067873303168, "no_speech_prob": 1.8338529116590507e-05}, {"id": 221, "seek": 91032, "start": 914.96, "end": 921.7600000000001, "text": " And PRID and PR records, which then map the PRID to actually network addresses, like IP", "tokens": [400, 11568, 2777, 293, 11568, 7724, 11, 597, 550, 4471, 264, 11568, 2777, 281, 767, 3209, 16862, 11, 411, 8671], "temperature": 0.0, "avg_logprob": -0.19650084884078414, "compression_ratio": 1.7285067873303168, "no_speech_prob": 1.8338529116590507e-05}, {"id": 222, "seek": 91032, "start": 921.7600000000001, "end": 923.1600000000001, "text": " addresses and ports.", "tokens": [16862, 293, 18160, 13], "temperature": 0.0, "avg_logprob": -0.19650084884078414, "compression_ratio": 1.7285067873303168, "no_speech_prob": 1.8338529116590507e-05}, {"id": 223, "seek": 91032, "start": 923.1600000000001, "end": 927.84, "text": " So looking up a CID to a host for a CID is actually a two-step process.", "tokens": [407, 1237, 493, 257, 383, 2777, 281, 257, 3975, 337, 257, 383, 2777, 307, 767, 257, 732, 12, 16792, 1399, 13], "temperature": 0.0, "avg_logprob": -0.19650084884078414, "compression_ratio": 1.7285067873303168, "no_speech_prob": 1.8338529116590507e-05}, {"id": 224, "seek": 91032, "start": 927.84, "end": 932.6800000000001, "text": " First we need to resolve the CID to a PRID, and then the PRID to their network addresses.", "tokens": [2386, 321, 643, 281, 14151, 264, 383, 2777, 281, 257, 11568, 2777, 11, 293, 550, 264, 11568, 2777, 281, 641, 3209, 16862, 13], "temperature": 0.0, "avg_logprob": -0.19650084884078414, "compression_ratio": 1.7285067873303168, "no_speech_prob": 1.8338529116590507e-05}, {"id": 225, "seek": 91032, "start": 932.6800000000001, "end": 935.0400000000001, "text": " And then we can connect to each other.", "tokens": [400, 550, 321, 393, 1745, 281, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.19650084884078414, "compression_ratio": 1.7285067873303168, "no_speech_prob": 1.8338529116590507e-05}, {"id": 226, "seek": 93504, "start": 935.04, "end": 941.68, "text": " And the distributed hash table here has two key features, first an X or distance metric.", "tokens": [400, 264, 12631, 22019, 3199, 510, 575, 732, 2141, 4122, 11, 700, 364, 1783, 420, 4560, 20678, 13], "temperature": 0.0, "avg_logprob": -0.13126367330551147, "compression_ratio": 1.626086956521739, "no_speech_prob": 5.254676580079831e-06}, {"id": 227, "seek": 93504, "start": 941.68, "end": 945.16, "text": " So that means we have some notion of closeness.", "tokens": [407, 300, 1355, 321, 362, 512, 10710, 295, 2611, 15264, 13], "temperature": 0.0, "avg_logprob": -0.13126367330551147, "compression_ratio": 1.626086956521739, "no_speech_prob": 5.254676580079831e-06}, {"id": 228, "seek": 93504, "start": 945.16, "end": 949.9599999999999, "text": " So what this XOR thing does, so if I XOR two numbers together, the resulting number or", "tokens": [407, 437, 341, 1783, 2483, 551, 775, 11, 370, 498, 286, 1783, 2483, 732, 3547, 1214, 11, 264, 16505, 1230, 420], "temperature": 0.0, "avg_logprob": -0.13126367330551147, "compression_ratio": 1.626086956521739, "no_speech_prob": 5.254676580079831e-06}, {"id": 229, "seek": 93504, "start": 949.9599999999999, "end": 954.88, "text": " this operation satisfies the condition, the requirements for a metric.", "tokens": [341, 6916, 44271, 264, 4188, 11, 264, 7728, 337, 257, 20678, 13], "temperature": 0.0, "avg_logprob": -0.13126367330551147, "compression_ratio": 1.626086956521739, "no_speech_prob": 5.254676580079831e-06}, {"id": 230, "seek": 93504, "start": 954.88, "end": 962.36, "text": " So this means I can say a certain PRID is closer to a CID than some other PRID.", "tokens": [407, 341, 1355, 286, 393, 584, 257, 1629, 11568, 2777, 307, 4966, 281, 257, 383, 2777, 813, 512, 661, 11568, 2777, 13], "temperature": 0.0, "avg_logprob": -0.13126367330551147, "compression_ratio": 1.626086956521739, "no_speech_prob": 5.254676580079831e-06}, {"id": 231, "seek": 96236, "start": 962.36, "end": 967.6800000000001, "text": " So in this case, PRIDX could be closer to CID1 than PRIDY.", "tokens": [407, 294, 341, 1389, 11, 11568, 2777, 55, 727, 312, 4966, 281, 383, 2777, 16, 813, 11568, 2777, 56, 13], "temperature": 0.0, "avg_logprob": -0.15969329305214458, "compression_ratio": 1.6036866359447004, "no_speech_prob": 4.091912614967441e-06}, {"id": 232, "seek": 96236, "start": 967.6800000000001, "end": 977.04, "text": " And this allows us to basically sort CIDs with PRIDs together.", "tokens": [400, 341, 4045, 505, 281, 1936, 1333, 383, 2777, 82, 365, 11568, 2777, 82, 1214, 13], "temperature": 0.0, "avg_logprob": -0.15969329305214458, "compression_ratio": 1.6036866359447004, "no_speech_prob": 4.091912614967441e-06}, {"id": 233, "seek": 96236, "start": 977.04, "end": 978.8000000000001, "text": " And then this tree-based routing mechanism here.", "tokens": [400, 550, 341, 4230, 12, 6032, 32722, 7513, 510, 13], "temperature": 0.0, "avg_logprob": -0.15969329305214458, "compression_ratio": 1.6036866359447004, "no_speech_prob": 4.091912614967441e-06}, {"id": 234, "seek": 96236, "start": 978.8000000000001, "end": 983.2, "text": " So in this bottom right diagram, I got this from the original paper, we have the black", "tokens": [407, 294, 341, 2767, 558, 10686, 11, 286, 658, 341, 490, 264, 3380, 3035, 11, 321, 362, 264, 2211], "temperature": 0.0, "avg_logprob": -0.15969329305214458, "compression_ratio": 1.6036866359447004, "no_speech_prob": 4.091912614967441e-06}, {"id": 235, "seek": 96236, "start": 983.2, "end": 984.52, "text": " node.", "tokens": [9984, 13], "temperature": 0.0, "avg_logprob": -0.15969329305214458, "compression_ratio": 1.6036866359447004, "no_speech_prob": 4.091912614967441e-06}, {"id": 236, "seek": 96236, "start": 984.52, "end": 989.72, "text": " And with this tree-based routing, this is super clever as in each bubble, so all the", "tokens": [400, 365, 341, 4230, 12, 6032, 32722, 11, 341, 307, 1687, 13494, 382, 294, 1184, 12212, 11, 370, 439, 264], "temperature": 0.0, "avg_logprob": -0.15969329305214458, "compression_ratio": 1.6036866359447004, "no_speech_prob": 4.091912614967441e-06}, {"id": 237, "seek": 98972, "start": 989.72, "end": 995.0400000000001, "text": " PRID peers in the network can actually be considered as in a big try, a prefix try.", "tokens": [11568, 2777, 16739, 294, 264, 3209, 393, 767, 312, 4888, 382, 294, 257, 955, 853, 11, 257, 46969, 853, 13], "temperature": 0.0, "avg_logprob": -0.16417249611445836, "compression_ratio": 1.5763358778625953, "no_speech_prob": 2.014073652389925e-05}, {"id": 238, "seek": 98972, "start": 995.0400000000001, "end": 1001.0400000000001, "text": " And if we know only one PRID in each of these bubbles, we can guarantee that we can reach", "tokens": [400, 498, 321, 458, 787, 472, 11568, 2777, 294, 1184, 295, 613, 16295, 11, 321, 393, 10815, 300, 321, 393, 2524], "temperature": 0.0, "avg_logprob": -0.16417249611445836, "compression_ratio": 1.5763358778625953, "no_speech_prob": 2.014073652389925e-05}, {"id": 239, "seek": 98972, "start": 1001.0400000000001, "end": 1007.32, "text": " any other PRID in the network with O log N lookups by asking for even closer PRIDs based", "tokens": [604, 661, 11568, 2777, 294, 264, 3209, 365, 422, 3565, 426, 574, 7528, 538, 3365, 337, 754, 4966, 11568, 2777, 82, 2361], "temperature": 0.0, "avg_logprob": -0.16417249611445836, "compression_ratio": 1.5763358778625953, "no_speech_prob": 2.014073652389925e-05}, {"id": 240, "seek": 98972, "start": 1007.32, "end": 1012.76, "text": " on this XOR routing mechanism here.", "tokens": [322, 341, 1783, 2483, 32722, 7513, 510, 13], "temperature": 0.0, "avg_logprob": -0.16417249611445836, "compression_ratio": 1.5763358778625953, "no_speech_prob": 2.014073652389925e-05}, {"id": 241, "seek": 98972, "start": 1012.76, "end": 1016.1600000000001, "text": " So this was just abstractly what the distributed hash table in IPFS does.", "tokens": [407, 341, 390, 445, 12649, 356, 437, 264, 12631, 22019, 3199, 294, 8671, 29318, 775, 13], "temperature": 0.0, "avg_logprob": -0.16417249611445836, "compression_ratio": 1.5763358778625953, "no_speech_prob": 2.014073652389925e-05}, {"id": 242, "seek": 98972, "start": 1016.1600000000001, "end": 1018.36, "text": " So how does it work concretely for IPFS?", "tokens": [407, 577, 775, 309, 589, 39481, 736, 337, 8671, 29318, 30], "temperature": 0.0, "avg_logprob": -0.16417249611445836, "compression_ratio": 1.5763358778625953, "no_speech_prob": 2.014073652389925e-05}, {"id": 243, "seek": 101836, "start": 1018.36, "end": 1019.64, "text": " So we started the daemon process.", "tokens": [407, 321, 1409, 264, 1120, 36228, 1399, 13], "temperature": 0.0, "avg_logprob": -0.12686633188790136, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.260525004909141e-05}, {"id": 244, "seek": 101836, "start": 1019.64, "end": 1024.96, "text": " What happened under the hood was we calculated the SHA-256 of our PRID, which just gives", "tokens": [708, 2011, 833, 264, 13376, 390, 321, 15598, 264, 38820, 12, 6074, 21, 295, 527, 11568, 2777, 11, 597, 445, 2709], "temperature": 0.0, "avg_logprob": -0.12686633188790136, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.260525004909141e-05}, {"id": 245, "seek": 101836, "start": 1024.96, "end": 1029.4, "text": " us a long string of bits and bytes, or just bits basically in our case.", "tokens": [505, 257, 938, 6798, 295, 9239, 293, 36088, 11, 420, 445, 9239, 1936, 294, 527, 1389, 13], "temperature": 0.0, "avg_logprob": -0.12686633188790136, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.260525004909141e-05}, {"id": 246, "seek": 101836, "start": 1029.4, "end": 1032.1200000000001, "text": " And we initialized a routing table at the bottom.", "tokens": [400, 321, 5883, 1602, 257, 32722, 3199, 412, 264, 2767, 13], "temperature": 0.0, "avg_logprob": -0.12686633188790136, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.260525004909141e-05}, {"id": 247, "seek": 101836, "start": 1032.1200000000001, "end": 1034.88, "text": " And this routing table consists of different buckets.", "tokens": [400, 341, 32722, 3199, 14689, 295, 819, 32191, 13], "temperature": 0.0, "avg_logprob": -0.12686633188790136, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.260525004909141e-05}, {"id": 248, "seek": 101836, "start": 1034.88, "end": 1043.8, "text": " And each bucket is filled with peers that have a common prefix to our PRID, the hash", "tokens": [400, 1184, 13058, 307, 6412, 365, 16739, 300, 362, 257, 2689, 46969, 281, 527, 11568, 2777, 11, 264, 22019], "temperature": 0.0, "avg_logprob": -0.12686633188790136, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.260525004909141e-05}, {"id": 249, "seek": 101836, "start": 1043.8, "end": 1046.16, "text": " from our PRID at the top.", "tokens": [490, 527, 11568, 2777, 412, 264, 1192, 13], "temperature": 0.0, "avg_logprob": -0.12686633188790136, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.260525004909141e-05}, {"id": 250, "seek": 104616, "start": 1046.16, "end": 1053.28, "text": " And when our node started up, we asked the bootstrap peers, hey, do you know anyone whose", "tokens": [400, 562, 527, 9984, 1409, 493, 11, 321, 2351, 264, 11450, 372, 4007, 16739, 11, 4177, 11, 360, 291, 458, 2878, 6104], "temperature": 0.0, "avg_logprob": -0.152867656487685, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.1657463801384438e-05}, {"id": 251, "seek": 104616, "start": 1053.28, "end": 1056.52, "text": " SHA-256 from PRID starts with a 1?", "tokens": [38820, 12, 6074, 21, 490, 11568, 2777, 3719, 365, 257, 502, 30], "temperature": 0.0, "avg_logprob": -0.152867656487685, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.1657463801384438e-05}, {"id": 252, "seek": 104616, "start": 1056.52, "end": 1062.3200000000002, "text": " And this means we have no common prefix, and we put them, those peers in bucket 0.", "tokens": [400, 341, 1355, 321, 362, 572, 2689, 46969, 11, 293, 321, 829, 552, 11, 729, 16739, 294, 13058, 1958, 13], "temperature": 0.0, "avg_logprob": -0.152867656487685, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.1657463801384438e-05}, {"id": 253, "seek": 104616, "start": 1062.3200000000002, "end": 1067.44, "text": " Then we do the same for a prefix of 0, 0 and 0, 1, 1.", "tokens": [1396, 321, 360, 264, 912, 337, 257, 46969, 295, 1958, 11, 1958, 293, 1958, 11, 502, 11, 502, 13], "temperature": 0.0, "avg_logprob": -0.152867656487685, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.1657463801384438e-05}, {"id": 254, "seek": 104616, "start": 1067.44, "end": 1072.5600000000002, "text": " And so we go through all the list until 255, and we fill up these buckets.", "tokens": [400, 370, 321, 352, 807, 439, 264, 1329, 1826, 3552, 20, 11, 293, 321, 2836, 493, 613, 32191, 13], "temperature": 0.0, "avg_logprob": -0.152867656487685, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.1657463801384438e-05}, {"id": 255, "seek": 107256, "start": 1072.56, "end": 1076.24, "text": " And these are basically these buckets, these little blobs, these little circuits that you", "tokens": [400, 613, 366, 1936, 613, 32191, 11, 613, 707, 1749, 929, 11, 613, 707, 26354, 300, 291], "temperature": 0.0, "avg_logprob": -0.15881266359423027, "compression_ratio": 1.6240601503759398, "no_speech_prob": 7.766532689856831e-06}, {"id": 256, "seek": 107256, "start": 1076.24, "end": 1079.32, "text": " saw in the previous slide.", "tokens": [1866, 294, 264, 3894, 4137, 13], "temperature": 0.0, "avg_logprob": -0.15881266359423027, "compression_ratio": 1.6240601503759398, "no_speech_prob": 7.766532689856831e-06}, {"id": 257, "seek": 107256, "start": 1079.32, "end": 1080.8799999999999, "text": " And why did we do that?", "tokens": [400, 983, 630, 321, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.15881266359423027, "compression_ratio": 1.6240601503759398, "no_speech_prob": 7.766532689856831e-06}, {"id": 258, "seek": 107256, "start": 1080.8799999999999, "end": 1085.9199999999998, "text": " Because when we now want to retrieve content, so as I said, I handed the CID to my friend,", "tokens": [1436, 562, 321, 586, 528, 281, 30254, 2701, 11, 370, 382, 286, 848, 11, 286, 16013, 264, 383, 2777, 281, 452, 1277, 11], "temperature": 0.0, "avg_logprob": -0.15881266359423027, "compression_ratio": 1.6240601503759398, "no_speech_prob": 7.766532689856831e-06}, {"id": 259, "seek": 107256, "start": 1085.9199999999998, "end": 1092.0, "text": " and my friend enters the CID in the command line with this IPFS get command.", "tokens": [293, 452, 1277, 18780, 264, 383, 2777, 294, 264, 5622, 1622, 365, 341, 8671, 29318, 483, 5622, 13], "temperature": 0.0, "avg_logprob": -0.15881266359423027, "compression_ratio": 1.6240601503759398, "no_speech_prob": 7.766532689856831e-06}, {"id": 260, "seek": 107256, "start": 1092.0, "end": 1097.12, "text": " Their node also calculates the SHA-256 of the CID, and then looks in its own routing", "tokens": [6710, 9984, 611, 4322, 1024, 264, 38820, 12, 6074, 21, 295, 264, 383, 2777, 11, 293, 550, 1542, 294, 1080, 1065, 32722], "temperature": 0.0, "avg_logprob": -0.15881266359423027, "compression_ratio": 1.6240601503759398, "no_speech_prob": 7.766532689856831e-06}, {"id": 261, "seek": 107256, "start": 1097.12, "end": 1100.6799999999998, "text": " table, sees, OK, I have a prefix of 2.", "tokens": [3199, 11, 8194, 11, 2264, 11, 286, 362, 257, 46969, 295, 568, 13], "temperature": 0.0, "avg_logprob": -0.15881266359423027, "compression_ratio": 1.6240601503759398, "no_speech_prob": 7.766532689856831e-06}, {"id": 262, "seek": 110068, "start": 1100.68, "end": 1106.04, "text": " I take one peer out of this bucket 2 and ask, yeah, locate the appropriate bucket, get the", "tokens": [286, 747, 472, 15108, 484, 295, 341, 13058, 568, 293, 1029, 11, 1338, 11, 22370, 264, 6854, 13058, 11, 483, 264], "temperature": 0.0, "avg_logprob": -0.1574834602466528, "compression_ratio": 1.8106060606060606, "no_speech_prob": 1.2803970093955286e-05}, {"id": 263, "seek": 110068, "start": 1106.04, "end": 1110.92, "text": " list of all peers, and then I asked all of these peers in the bucket, hey, do you know", "tokens": [1329, 295, 439, 16739, 11, 293, 550, 286, 2351, 439, 295, 613, 16739, 294, 264, 13058, 11, 4177, 11, 360, 291, 458], "temperature": 0.0, "avg_logprob": -0.1574834602466528, "compression_ratio": 1.8106060606060606, "no_speech_prob": 1.2803970093955286e-05}, {"id": 264, "seek": 110068, "start": 1110.92, "end": 1111.92, "text": " anyone?", "tokens": [2878, 30], "temperature": 0.0, "avg_logprob": -0.1574834602466528, "compression_ratio": 1.8106060606060606, "no_speech_prob": 1.2803970093955286e-05}, {"id": 265, "seek": 110068, "start": 1111.92, "end": 1114.24, "text": " So first of all, do you know the provider record already?", "tokens": [407, 700, 295, 439, 11, 360, 291, 458, 264, 12398, 2136, 1217, 30], "temperature": 0.0, "avg_logprob": -0.1574834602466528, "compression_ratio": 1.8106060606060606, "no_speech_prob": 1.2803970093955286e-05}, {"id": 266, "seek": 110068, "start": 1114.24, "end": 1117.92, "text": " Do you know the CID and the PRID to that CID?", "tokens": [1144, 291, 458, 264, 383, 2777, 293, 264, 11568, 2777, 281, 300, 383, 2777, 30], "temperature": 0.0, "avg_logprob": -0.1574834602466528, "compression_ratio": 1.8106060606060606, "no_speech_prob": 1.2803970093955286e-05}, {"id": 267, "seek": 110068, "start": 1117.92, "end": 1122.64, "text": " And if yes, we are done, but if not, we are asking, do you know anyone closer based on", "tokens": [400, 498, 2086, 11, 321, 366, 1096, 11, 457, 498, 406, 11, 321, 366, 3365, 11, 360, 291, 458, 2878, 4966, 2361, 322], "temperature": 0.0, "avg_logprob": -0.1574834602466528, "compression_ratio": 1.8106060606060606, "no_speech_prob": 1.2803970093955286e-05}, {"id": 268, "seek": 110068, "start": 1122.64, "end": 1123.64, "text": " this XR metric?", "tokens": [341, 1783, 49, 20678, 30], "temperature": 0.0, "avg_logprob": -0.1574834602466528, "compression_ratio": 1.8106060606060606, "no_speech_prob": 1.2803970093955286e-05}, {"id": 269, "seek": 110068, "start": 1123.64, "end": 1127.24, "text": " And then this peer yet again looks in its own routing table, and so we get closer and", "tokens": [400, 550, 341, 15108, 1939, 797, 1542, 294, 1080, 1065, 32722, 3199, 11, 293, 370, 321, 483, 4966, 293], "temperature": 0.0, "avg_logprob": -0.1574834602466528, "compression_ratio": 1.8106060606060606, "no_speech_prob": 1.2803970093955286e-05}, {"id": 270, "seek": 112724, "start": 1127.24, "end": 1134.72, "text": " closer and closer with this log n property that I showed you previously.", "tokens": [4966, 293, 4966, 365, 341, 3565, 297, 4707, 300, 286, 4712, 291, 8046, 13], "temperature": 0.0, "avg_logprob": -0.15396455786694055, "compression_ratio": 1.513157894736842, "no_speech_prob": 6.539467904076446e-06}, {"id": 271, "seek": 112724, "start": 1134.72, "end": 1137.88, "text": " And for publishing content, it's basically the same.", "tokens": [400, 337, 17832, 2701, 11, 309, 311, 1936, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.15396455786694055, "compression_ratio": 1.513157894736842, "no_speech_prob": 6.539467904076446e-06}, {"id": 272, "seek": 112724, "start": 1137.88, "end": 1143.36, "text": " We calculate the SHA-256 of the CID, locate the appropriate bucket, get a list of all", "tokens": [492, 8873, 264, 38820, 12, 6074, 21, 295, 264, 383, 2777, 11, 22370, 264, 6854, 13058, 11, 483, 257, 1329, 295, 439], "temperature": 0.0, "avg_logprob": -0.15396455786694055, "compression_ratio": 1.513157894736842, "no_speech_prob": 6.539467904076446e-06}, {"id": 273, "seek": 112724, "start": 1143.36, "end": 1150.6, "text": " the peers from that, and then we start parallel queries, but instead of asking for the provider", "tokens": [264, 16739, 490, 300, 11, 293, 550, 321, 722, 8952, 24109, 11, 457, 2602, 295, 3365, 337, 264, 12398], "temperature": 0.0, "avg_logprob": -0.15396455786694055, "compression_ratio": 1.513157894736842, "no_speech_prob": 6.539467904076446e-06}, {"id": 274, "seek": 112724, "start": 1150.6, "end": 1153.04, "text": " record, we ask for even closer peers.", "tokens": [2136, 11, 321, 1029, 337, 754, 4966, 16739, 13], "temperature": 0.0, "avg_logprob": -0.15396455786694055, "compression_ratio": 1.513157894736842, "no_speech_prob": 6.539467904076446e-06}, {"id": 275, "seek": 115304, "start": 1153.04, "end": 1161.32, "text": " And we terminate when the closest known peers in the query actually haven't replied with", "tokens": [400, 321, 10761, 473, 562, 264, 13699, 2570, 16739, 294, 264, 14581, 767, 2378, 380, 20345, 365], "temperature": 0.0, "avg_logprob": -0.14598907123912463, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.25484028912615e-06}, {"id": 276, "seek": 115304, "start": 1161.32, "end": 1171.24, "text": " any peer that's closer, hasn't replied with anyone closer to the CID than we already know.", "tokens": [604, 15108, 300, 311, 4966, 11, 6132, 380, 20345, 365, 2878, 4966, 281, 264, 383, 2777, 813, 321, 1217, 458, 13], "temperature": 0.0, "avg_logprob": -0.14598907123912463, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.25484028912615e-06}, {"id": 277, "seek": 115304, "start": 1171.24, "end": 1176.48, "text": " And then we start the provider record with the 20 closest peers to that CID, and we do", "tokens": [400, 550, 321, 722, 264, 12398, 2136, 365, 264, 945, 13699, 16739, 281, 300, 383, 2777, 11, 293, 321, 360], "temperature": 0.0, "avg_logprob": -0.14598907123912463, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.25484028912615e-06}, {"id": 278, "seek": 115304, "start": 1176.48, "end": 1181.8, "text": " it with 20 because there's peer churn, so this is a permissionless network, and this", "tokens": [309, 365, 945, 570, 456, 311, 15108, 417, 925, 11, 370, 341, 307, 257, 11226, 1832, 3209, 11, 293, 341], "temperature": 0.0, "avg_logprob": -0.14598907123912463, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.25484028912615e-06}, {"id": 279, "seek": 118180, "start": 1181.8, "end": 1187.32, "text": " means peers can come and go as they wish, and if we only started with one peer, we would", "tokens": [1355, 16739, 393, 808, 293, 352, 382, 436, 3172, 11, 293, 498, 321, 787, 1409, 365, 472, 15108, 11, 321, 576], "temperature": 0.0, "avg_logprob": -0.1350356694814321, "compression_ratio": 1.7276422764227641, "no_speech_prob": 5.172735654923599e-06}, {"id": 280, "seek": 118180, "start": 1187.32, "end": 1193.6, "text": " risk that the provider record is not reachable when the node comes down, and in turn all", "tokens": [3148, 300, 264, 12398, 2136, 307, 406, 2524, 712, 562, 264, 9984, 1487, 760, 11, 293, 294, 1261, 439], "temperature": 0.0, "avg_logprob": -0.1350356694814321, "compression_ratio": 1.7276422764227641, "no_speech_prob": 5.172735654923599e-06}, {"id": 281, "seek": 118180, "start": 1193.6, "end": 1197.52, "text": " content is not reachable.", "tokens": [2701, 307, 406, 2524, 712, 13], "temperature": 0.0, "avg_logprob": -0.1350356694814321, "compression_ratio": 1.7276422764227641, "no_speech_prob": 5.172735654923599e-06}, {"id": 282, "seek": 118180, "start": 1197.52, "end": 1201.44, "text": " So this is like the very technical part of that, but let me summarize this.", "tokens": [407, 341, 307, 411, 264, 588, 6191, 644, 295, 300, 11, 457, 718, 385, 20858, 341, 13], "temperature": 0.0, "avg_logprob": -0.1350356694814321, "compression_ratio": 1.7276422764227641, "no_speech_prob": 5.172735654923599e-06}, {"id": 283, "seek": 118180, "start": 1201.44, "end": 1206.28, "text": " This is probably the easier way to understand all of this.", "tokens": [639, 307, 1391, 264, 3571, 636, 281, 1223, 439, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.1350356694814321, "compression_ratio": 1.7276422764227641, "no_speech_prob": 5.172735654923599e-06}, {"id": 284, "seek": 118180, "start": 1206.28, "end": 1211.08, "text": " First of all, so we added the content to our node, and so this is the file, enters the", "tokens": [2386, 295, 439, 11, 370, 321, 3869, 264, 2701, 281, 527, 9984, 11, 293, 370, 341, 307, 264, 3991, 11, 18780, 264], "temperature": 0.0, "avg_logprob": -0.1350356694814321, "compression_ratio": 1.7276422764227641, "no_speech_prob": 5.172735654923599e-06}, {"id": 285, "seek": 121108, "start": 1211.08, "end": 1216.6799999999998, "text": " provider, the provider looks in its routing table, gets redirected to peer that is closer", "tokens": [12398, 11, 264, 12398, 1542, 294, 1080, 32722, 3199, 11, 2170, 29066, 292, 281, 15108, 300, 307, 4966], "temperature": 0.0, "avg_logprob": -0.14841999923973753, "compression_ratio": 1.7119341563786008, "no_speech_prob": 3.535127325449139e-05}, {"id": 286, "seek": 121108, "start": 1216.6799999999998, "end": 1224.72, "text": " to the CID, and gets redirected until it finds the closest peer in this XR key space metric", "tokens": [281, 264, 383, 2777, 11, 293, 2170, 29066, 292, 1826, 309, 10704, 264, 13699, 15108, 294, 341, 1783, 49, 2141, 1901, 20678], "temperature": 0.0, "avg_logprob": -0.14841999923973753, "compression_ratio": 1.7119341563786008, "no_speech_prob": 3.535127325449139e-05}, {"id": 287, "seek": 121108, "start": 1224.72, "end": 1228.12, "text": " to the CID, and then it stores the provider record with that.", "tokens": [281, 264, 383, 2777, 11, 293, 550, 309, 9512, 264, 12398, 2136, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.14841999923973753, "compression_ratio": 1.7119341563786008, "no_speech_prob": 3.535127325449139e-05}, {"id": 288, "seek": 121108, "start": 1228.12, "end": 1233.6799999999998, "text": " Then off-band, the CID gets handed to the requester to my friend, and what I didn't say", "tokens": [1396, 766, 12, 4235, 11, 264, 383, 2777, 2170, 16013, 281, 264, 1724, 3011, 281, 452, 1277, 11, 293, 437, 286, 994, 380, 584], "temperature": 0.0, "avg_logprob": -0.14841999923973753, "compression_ratio": 1.7119341563786008, "no_speech_prob": 3.535127325449139e-05}, {"id": 289, "seek": 121108, "start": 1233.6799999999998, "end": 1240.32, "text": " or told you yet, it's also IPFS maintains a long list or like, I don't know how many", "tokens": [420, 1907, 291, 1939, 11, 309, 311, 611, 8671, 29318, 33385, 257, 938, 1329, 420, 411, 11, 286, 500, 380, 458, 577, 867], "temperature": 0.0, "avg_logprob": -0.14841999923973753, "compression_ratio": 1.7119341563786008, "no_speech_prob": 3.535127325449139e-05}, {"id": 290, "seek": 124032, "start": 1240.32, "end": 1247.08, "text": " it is right now, probably a hundred or so, constant connections to other peers, and opportunistically", "tokens": [309, 307, 558, 586, 11, 1391, 257, 3262, 420, 370, 11, 5754, 9271, 281, 661, 16739, 11, 293, 2070, 20458], "temperature": 0.0, "avg_logprob": -0.12203892639705113, "compression_ratio": 1.61328125, "no_speech_prob": 1.0612612641125452e-05}, {"id": 291, "seek": 124032, "start": 1247.08, "end": 1252.96, "text": " just ask them, hey, do you know the CID or the provider record to the CID?", "tokens": [445, 1029, 552, 11, 4177, 11, 360, 291, 458, 264, 383, 2777, 420, 264, 12398, 2136, 281, 264, 383, 2777, 30], "temperature": 0.0, "avg_logprob": -0.12203892639705113, "compression_ratio": 1.61328125, "no_speech_prob": 1.0612612641125452e-05}, {"id": 292, "seek": 124032, "start": 1252.96, "end": 1258.32, "text": " And if this resolves, all good, we are done, but it's very unlikely for people to actually", "tokens": [400, 498, 341, 7923, 977, 11, 439, 665, 11, 321, 366, 1096, 11, 457, 309, 311, 588, 17518, 337, 561, 281, 767], "temperature": 0.0, "avg_logprob": -0.12203892639705113, "compression_ratio": 1.61328125, "no_speech_prob": 1.0612612641125452e-05}, {"id": 293, "seek": 124032, "start": 1258.32, "end": 1261.0, "text": " know a random CID.", "tokens": [458, 257, 4974, 383, 2777, 13], "temperature": 0.0, "avg_logprob": -0.12203892639705113, "compression_ratio": 1.61328125, "no_speech_prob": 1.0612612641125452e-05}, {"id": 294, "seek": 124032, "start": 1261.0, "end": 1262.48, "text": " So let's assume this didn't work.", "tokens": [407, 718, 311, 6552, 341, 994, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.12203892639705113, "compression_ratio": 1.61328125, "no_speech_prob": 1.0612612641125452e-05}, {"id": 295, "seek": 124032, "start": 1262.48, "end": 1267.1599999999999, "text": " So this requester also looks in its own routing table, gets redirected, gets redirected even", "tokens": [407, 341, 1724, 3011, 611, 1542, 294, 1080, 1065, 32722, 3199, 11, 2170, 29066, 292, 11, 2170, 29066, 292, 754], "temperature": 0.0, "avg_logprob": -0.12203892639705113, "compression_ratio": 1.61328125, "no_speech_prob": 1.0612612641125452e-05}, {"id": 296, "seek": 126716, "start": 1267.16, "end": 1277.88, "text": " closer, even closer to the peer ID of that CID, and then finds the peer that stores the", "tokens": [4966, 11, 754, 4966, 281, 264, 15108, 7348, 295, 300, 383, 2777, 11, 293, 550, 10704, 264, 15108, 300, 9512, 264], "temperature": 0.0, "avg_logprob": -0.10955775538577309, "compression_ratio": 1.7445652173913044, "no_speech_prob": 1.5204003830149304e-05}, {"id": 297, "seek": 126716, "start": 1277.88, "end": 1284.44, "text": " provider record, fetches the provider record, then does again the same hops to find out", "tokens": [12398, 2136, 11, 15136, 3781, 264, 12398, 2136, 11, 550, 775, 797, 264, 912, 47579, 281, 915, 484], "temperature": 0.0, "avg_logprob": -0.10955775538577309, "compression_ratio": 1.7445652173913044, "no_speech_prob": 1.5204003830149304e-05}, {"id": 298, "seek": 126716, "start": 1284.44, "end": 1288.5600000000002, "text": " the mapping from the peer ID to the network addresses, and then we can actually connect", "tokens": [264, 18350, 490, 264, 15108, 7348, 281, 264, 3209, 16862, 11, 293, 550, 321, 393, 767, 1745], "temperature": 0.0, "avg_logprob": -0.10955775538577309, "compression_ratio": 1.7445652173913044, "no_speech_prob": 1.5204003830149304e-05}, {"id": 299, "seek": 126716, "start": 1288.5600000000002, "end": 1295.44, "text": " with each other and transfer the content, and we're done.", "tokens": [365, 1184, 661, 293, 5003, 264, 2701, 11, 293, 321, 434, 1096, 13], "temperature": 0.0, "avg_logprob": -0.10955775538577309, "compression_ratio": 1.7445652173913044, "no_speech_prob": 1.5204003830149304e-05}, {"id": 300, "seek": 129544, "start": 1295.44, "end": 1302.2, "text": " So this is the content lifecycle, and this is actually, this is already it, well, already", "tokens": [407, 341, 307, 264, 2701, 45722, 11, 293, 341, 307, 767, 11, 341, 307, 1217, 309, 11, 731, 11, 1217], "temperature": 0.0, "avg_logprob": -0.1817403955662504, "compression_ratio": 1.7251184834123223, "no_speech_prob": 1.6178571968339384e-05}, {"id": 301, "seek": 129544, "start": 1302.2, "end": 1309.64, "text": " it is quite a bit, quite involved actually, and yeah, with that, it's already time for", "tokens": [309, 307, 1596, 257, 857, 11, 1596, 3288, 767, 11, 293, 1338, 11, 365, 300, 11, 309, 311, 1217, 565, 337], "temperature": 0.0, "avg_logprob": -0.1817403955662504, "compression_ratio": 1.7251184834123223, "no_speech_prob": 1.6178571968339384e-05}, {"id": 302, "seek": 129544, "start": 1309.64, "end": 1317.3600000000001, "text": " some callouts, get involved, IPFS is an open source project, if you're into measurements", "tokens": [512, 818, 7711, 11, 483, 3288, 11, 8671, 29318, 307, 364, 1269, 4009, 1716, 11, 498, 291, 434, 666, 15383], "temperature": 0.0, "avg_logprob": -0.1817403955662504, "compression_ratio": 1.7251184834123223, "no_speech_prob": 1.6178571968339384e-05}, {"id": 303, "seek": 129544, "start": 1317.3600000000001, "end": 1324.6000000000001, "text": " and so on, we have some grants open at radius.space, if you want to get involved with some network", "tokens": [293, 370, 322, 11, 321, 362, 512, 16101, 1269, 412, 15845, 13, 24824, 11, 498, 291, 528, 281, 483, 3288, 365, 512, 3209], "temperature": 0.0, "avg_logprob": -0.1817403955662504, "compression_ratio": 1.7251184834123223, "no_speech_prob": 1.6178571968339384e-05}, {"id": 304, "seek": 132460, "start": 1324.6, "end": 1330.24, "text": " measurements, get your applications in, all action is in public, you can follow along", "tokens": [15383, 11, 483, 428, 5821, 294, 11, 439, 3069, 307, 294, 1908, 11, 291, 393, 1524, 2051], "temperature": 0.0, "avg_logprob": -0.2149069622309521, "compression_ratio": 1.5743801652892562, "no_speech_prob": 2.2440557586378418e-05}, {"id": 305, "seek": 132460, "start": 1330.24, "end": 1336.8, "text": " our work, especially my work of our team, at this GitHub repository, we have plenty", "tokens": [527, 589, 11, 2318, 452, 589, 295, 527, 1469, 11, 412, 341, 23331, 25841, 11, 321, 362, 7140], "temperature": 0.0, "avg_logprob": -0.2149069622309521, "compression_ratio": 1.5743801652892562, "no_speech_prob": 2.2440557586378418e-05}, {"id": 306, "seek": 132460, "start": 1336.8, "end": 1342.48, "text": " of requests for measurements that you can dive into, and extra ideas are always welcome.", "tokens": [295, 12475, 337, 15383, 300, 291, 393, 9192, 666, 11, 293, 2857, 3487, 366, 1009, 2928, 13], "temperature": 0.0, "avg_logprob": -0.2149069622309521, "compression_ratio": 1.5743801652892562, "no_speech_prob": 2.2440557586378418e-05}, {"id": 307, "seek": 132460, "start": 1342.48, "end": 1351.48, "text": " In general, IPFS is, I think, a very welcoming community, at least for me, and yeah, just,", "tokens": [682, 2674, 11, 8671, 29318, 307, 11, 286, 519, 11, 257, 588, 17378, 1768, 11, 412, 1935, 337, 385, 11, 293, 1338, 11, 445, 11], "temperature": 0.0, "avg_logprob": -0.2149069622309521, "compression_ratio": 1.5743801652892562, "no_speech_prob": 2.2440557586378418e-05}, {"id": 308, "seek": 132460, "start": 1351.48, "end": 1352.48, "text": " that's it.", "tokens": [300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.2149069622309521, "compression_ratio": 1.5743801652892562, "no_speech_prob": 2.2440557586378418e-05}, {"id": 309, "seek": 135248, "start": 1352.48, "end": 1370.32, "text": " So, any questions?", "tokens": [407, 11, 604, 1651, 30], "temperature": 0.0, "avg_logprob": -0.34511267511468185, "compression_ratio": 1.196078431372549, "no_speech_prob": 0.0004199934774078429}, {"id": 310, "seek": 135248, "start": 1370.32, "end": 1376.4, "text": " So is the way you describe it, using the DHT, how all nodes in the network share files with", "tokens": [407, 307, 264, 636, 291, 6786, 309, 11, 1228, 264, 28606, 51, 11, 577, 439, 13891, 294, 264, 3209, 2073, 7098, 365], "temperature": 0.0, "avg_logprob": -0.34511267511468185, "compression_ratio": 1.196078431372549, "no_speech_prob": 0.0004199934774078429}, {"id": 311, "seek": 135248, "start": 1376.4, "end": 1377.72, "text": " each other?", "tokens": [1184, 661, 30], "temperature": 0.0, "avg_logprob": -0.34511267511468185, "compression_ratio": 1.196078431372549, "no_speech_prob": 0.0004199934774078429}, {"id": 312, "seek": 137772, "start": 1377.72, "end": 1384.96, "text": " There's one content routing mechanism, so there are multiple ones, so this first thing", "tokens": [821, 311, 472, 2701, 32722, 7513, 11, 370, 456, 366, 3866, 2306, 11, 370, 341, 700, 551], "temperature": 0.0, "avg_logprob": -0.18131329373615543, "compression_ratio": 1.7102803738317758, "no_speech_prob": 5.823696483275853e-05}, {"id": 313, "seek": 137772, "start": 1384.96, "end": 1389.0, "text": " that I said here, so this opportunistic request to your immediate nodes is also some kind of", "tokens": [300, 286, 848, 510, 11, 370, 341, 2070, 3142, 5308, 281, 428, 11629, 13891, 307, 611, 512, 733, 295], "temperature": 0.0, "avg_logprob": -0.18131329373615543, "compression_ratio": 1.7102803738317758, "no_speech_prob": 5.823696483275853e-05}, {"id": 314, "seek": 137772, "start": 1389.0, "end": 1393.92, "text": " content routing, so you're resolving the location of content, then there are some new efforts", "tokens": [2701, 32722, 11, 370, 291, 434, 49940, 264, 4914, 295, 2701, 11, 550, 456, 366, 512, 777, 6484], "temperature": 0.0, "avg_logprob": -0.18131329373615543, "compression_ratio": 1.7102803738317758, "no_speech_prob": 5.823696483275853e-05}, {"id": 315, "seek": 137772, "start": 1393.92, "end": 1398.84, "text": " for building network indexes, which are just huge nodes that store the mappings, centralized", "tokens": [337, 2390, 3209, 8186, 279, 11, 597, 366, 445, 2603, 13891, 300, 3531, 264, 463, 28968, 11, 32395], "temperature": 0.0, "avg_logprob": -0.18131329373615543, "compression_ratio": 1.7102803738317758, "no_speech_prob": 5.823696483275853e-05}, {"id": 316, "seek": 139884, "start": 1398.84, "end": 1408.8799999999999, "text": " nodes, which, like, federated centralized nodes, so not as bad, and I think, yeah, I think", "tokens": [13891, 11, 597, 11, 411, 11, 38024, 770, 32395, 13891, 11, 370, 406, 382, 1578, 11, 293, 286, 519, 11, 1338, 11, 286, 519], "temperature": 0.0, "avg_logprob": -0.2881864521601429, "compression_ratio": 1.4696132596685083, "no_speech_prob": 1.7215044863405637e-05}, {"id": 317, "seek": 139884, "start": 1408.8799999999999, "end": 1414.84, "text": " these are the important ones, basically, yeah, so there are more ways to resolve them.", "tokens": [613, 366, 264, 1021, 2306, 11, 1936, 11, 1338, 11, 370, 456, 366, 544, 2098, 281, 14151, 552, 13], "temperature": 0.0, "avg_logprob": -0.2881864521601429, "compression_ratio": 1.4696132596685083, "no_speech_prob": 1.7215044863405637e-05}, {"id": 318, "seek": 139884, "start": 1414.84, "end": 1419.9199999999998, "text": " Also MDNS could also be one part, so if you're on the same network, you're broadcasting,", "tokens": [2743, 22521, 42003, 727, 611, 312, 472, 644, 11, 370, 498, 291, 434, 322, 264, 912, 3209, 11, 291, 434, 30024, 11], "temperature": 0.0, "avg_logprob": -0.2881864521601429, "compression_ratio": 1.4696132596685083, "no_speech_prob": 1.7215044863405637e-05}, {"id": 319, "seek": 141992, "start": 1419.92, "end": 1429.2, "text": " I know, that's just for, sorry, for the local, yeah, okay, true, yeah, luckily we have a", "tokens": [286, 458, 11, 300, 311, 445, 337, 11, 2597, 11, 337, 264, 2654, 11, 1338, 11, 1392, 11, 2074, 11, 1338, 11, 22880, 321, 362, 257], "temperature": 0.0, "avg_logprob": -0.2810070456528082, "compression_ratio": 1.6010928961748634, "no_speech_prob": 7.101809023879468e-05}, {"id": 320, "seek": 141992, "start": 1429.2, "end": 1437.96, "text": " core maintainer of IPFS here, yeah, it's actually not a joke, but yeah, sorry, yeah.", "tokens": [4965, 6909, 260, 295, 8671, 29318, 510, 11, 1338, 11, 309, 311, 767, 406, 257, 7647, 11, 457, 1338, 11, 2597, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.2810070456528082, "compression_ratio": 1.6010928961748634, "no_speech_prob": 7.101809023879468e-05}, {"id": 321, "seek": 141992, "start": 1437.96, "end": 1442.44, "text": " So I see that the provider records get replicated, but does the content actually get replicated", "tokens": [407, 286, 536, 300, 264, 12398, 7724, 483, 46365, 11, 457, 775, 264, 2701, 767, 483, 46365], "temperature": 0.0, "avg_logprob": -0.2810070456528082, "compression_ratio": 1.6010928961748634, "no_speech_prob": 7.101809023879468e-05}, {"id": 322, "seek": 141992, "start": 1442.44, "end": 1444.1200000000001, "text": " across the network too?", "tokens": [2108, 264, 3209, 886, 30], "temperature": 0.0, "avg_logprob": -0.2810070456528082, "compression_ratio": 1.6010928961748634, "no_speech_prob": 7.101809023879468e-05}, {"id": 323, "seek": 144412, "start": 1444.12, "end": 1451.36, "text": " Yeah, so only if someone else chooses to, so you're publishing the provider record,", "tokens": [865, 11, 370, 787, 498, 1580, 1646, 25963, 281, 11, 370, 291, 434, 17832, 264, 12398, 2136, 11], "temperature": 0.0, "avg_logprob": -0.15030577977498372, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.803600025596097e-05}, {"id": 324, "seek": 144412, "start": 1451.36, "end": 1458.52, "text": " so it's public somewhere, and anyone could look that up and also store the record themselves,", "tokens": [370, 309, 311, 1908, 4079, 11, 293, 2878, 727, 574, 300, 493, 293, 611, 3531, 264, 2136, 2969, 11], "temperature": 0.0, "avg_logprob": -0.15030577977498372, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.803600025596097e-05}, {"id": 325, "seek": 144412, "start": 1458.52, "end": 1465.28, "text": " so this is the idea, if content is popular and you care about the content being, staying", "tokens": [370, 341, 307, 264, 1558, 11, 498, 2701, 307, 3743, 293, 291, 1127, 466, 264, 2701, 885, 11, 7939], "temperature": 0.0, "avg_logprob": -0.15030577977498372, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.803600025596097e-05}, {"id": 326, "seek": 144412, "start": 1465.28, "end": 1472.3999999999999, "text": " alive in the network, it's called PIN, the CID, and this means you're fetching the content", "tokens": [5465, 294, 264, 3209, 11, 309, 311, 1219, 430, 1464, 11, 264, 383, 2777, 11, 293, 341, 1355, 291, 434, 23673, 278, 264, 2701], "temperature": 0.0, "avg_logprob": -0.15030577977498372, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.803600025596097e-05}, {"id": 327, "seek": 147240, "start": 1472.4, "end": 1477.52, "text": " from this other provider and store it yourself and become the provider yourself, and because", "tokens": [490, 341, 661, 12398, 293, 3531, 309, 1803, 293, 1813, 264, 12398, 1803, 11, 293, 570], "temperature": 0.0, "avg_logprob": -0.252393562252782, "compression_ratio": 1.7992565055762082, "no_speech_prob": 4.673589864978567e-05}, {"id": 328, "seek": 147240, "start": 1477.52, "end": 1483.2, "text": " of the CID mechanism, which is self-certifying and so on, other peers that request the content", "tokens": [295, 264, 383, 2777, 7513, 11, 597, 307, 2698, 12, 48999, 5489, 293, 370, 322, 11, 661, 16739, 300, 5308, 264, 2701], "temperature": 0.0, "avg_logprob": -0.252393562252782, "compression_ratio": 1.7992565055762082, "no_speech_prob": 4.673589864978567e-05}, {"id": 329, "seek": 147240, "start": 1483.2, "end": 1490.2800000000002, "text": " from you don't even need to trust you, because the CID already encodes the trust chain here,", "tokens": [490, 291, 500, 380, 754, 643, 281, 3361, 291, 11, 570, 264, 383, 2777, 1217, 2058, 4789, 264, 3361, 5021, 510, 11], "temperature": 0.0, "avg_logprob": -0.252393562252782, "compression_ratio": 1.7992565055762082, "no_speech_prob": 4.673589864978567e-05}, {"id": 330, "seek": 147240, "start": 1490.2800000000002, "end": 1494.1200000000001, "text": " but there's nothing that happened, it's not happening automatically here, so.", "tokens": [457, 456, 311, 1825, 300, 2011, 11, 309, 311, 406, 2737, 6772, 510, 11, 370, 13], "temperature": 0.0, "avg_logprob": -0.252393562252782, "compression_ratio": 1.7992565055762082, "no_speech_prob": 4.673589864978567e-05}, {"id": 331, "seek": 147240, "start": 1494.1200000000001, "end": 1496.88, "text": " But you can have multiple providers for the same company?", "tokens": [583, 291, 393, 362, 3866, 11330, 337, 264, 912, 2237, 30], "temperature": 0.0, "avg_logprob": -0.252393562252782, "compression_ratio": 1.7992565055762082, "no_speech_prob": 4.673589864978567e-05}, {"id": 332, "seek": 147240, "start": 1496.88, "end": 1499.4, "text": " Definitely, yeah, that's also, yeah, definitely, that's part of it.", "tokens": [12151, 11, 1338, 11, 300, 311, 611, 11, 1338, 11, 2138, 11, 300, 311, 644, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.252393562252782, "compression_ratio": 1.7992565055762082, "no_speech_prob": 4.673589864978567e-05}, {"id": 333, "seek": 149940, "start": 1499.4, "end": 1506.0400000000002, "text": " Another question is how does the project fit in, the concept of identity and trust and", "tokens": [3996, 1168, 307, 577, 775, 264, 1716, 3318, 294, 11, 264, 3410, 295, 6575, 293, 3361, 293], "temperature": 0.0, "avg_logprob": -0.22300409467032786, "compression_ratio": 1.6009174311926606, "no_speech_prob": 0.0007395494030788541}, {"id": 334, "seek": 149940, "start": 1506.0400000000002, "end": 1511.8000000000002, "text": " personas into IPFS, I'm thinking metadata, ramifications about the content and stuff", "tokens": [12019, 666, 8671, 29318, 11, 286, 478, 1953, 26603, 11, 10211, 7833, 466, 264, 2701, 293, 1507], "temperature": 0.0, "avg_logprob": -0.22300409467032786, "compression_ratio": 1.6009174311926606, "no_speech_prob": 0.0007395494030788541}, {"id": 335, "seek": 149940, "start": 1511.8000000000002, "end": 1513.8000000000002, "text": " like that.", "tokens": [411, 300, 13], "temperature": 0.0, "avg_logprob": -0.22300409467032786, "compression_ratio": 1.6009174311926606, "no_speech_prob": 0.0007395494030788541}, {"id": 336, "seek": 149940, "start": 1513.8000000000002, "end": 1514.8000000000002, "text": " What do you mean exactly?", "tokens": [708, 360, 291, 914, 2293, 30], "temperature": 0.0, "avg_logprob": -0.22300409467032786, "compression_ratio": 1.6009174311926606, "no_speech_prob": 0.0007395494030788541}, {"id": 337, "seek": 149940, "start": 1514.8000000000002, "end": 1522.8000000000002, "text": " For instance, just a history of the content, and can you trust that this content is from", "tokens": [1171, 5197, 11, 445, 257, 2503, 295, 264, 2701, 11, 293, 393, 291, 3361, 300, 341, 2701, 307, 490], "temperature": 0.0, "avg_logprob": -0.22300409467032786, "compression_ratio": 1.6009174311926606, "no_speech_prob": 0.0007395494030788541}, {"id": 338, "seek": 149940, "start": 1522.8000000000002, "end": 1526.2, "text": " a certain person or from a certain, you know, like.", "tokens": [257, 1629, 954, 420, 490, 257, 1629, 11, 291, 458, 11, 411, 13], "temperature": 0.0, "avg_logprob": -0.22300409467032786, "compression_ratio": 1.6009174311926606, "no_speech_prob": 0.0007395494030788541}, {"id": 339, "seek": 152620, "start": 1526.2, "end": 1532.24, "text": " I would argue this would probably be some mechanism on top of these content identification.", "tokens": [286, 576, 9695, 341, 576, 1391, 312, 512, 7513, 322, 1192, 295, 613, 2701, 22065, 13], "temperature": 0.0, "avg_logprob": -0.229086960896407, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.00012284191325306892}, {"id": 340, "seek": 152620, "start": 1532.24, "end": 1538.16, "text": " So this is more for IPLD then, or for, perhaps, I would say, so if you want to say some content", "tokens": [407, 341, 307, 544, 337, 8671, 23704, 550, 11, 420, 337, 11, 4317, 11, 286, 576, 584, 11, 370, 498, 291, 528, 281, 584, 512, 2701], "temperature": 0.0, "avg_logprob": -0.229086960896407, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.00012284191325306892}, {"id": 341, "seek": 152620, "start": 1538.16, "end": 1543.72, "text": " is from some specific person to, then you would work with signatures, so signing the", "tokens": [307, 490, 512, 2685, 954, 281, 11, 550, 291, 576, 589, 365, 32322, 11, 370, 13393, 264], "temperature": 0.0, "avg_logprob": -0.229086960896407, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.00012284191325306892}, {"id": 342, "seek": 152620, "start": 1543.72, "end": 1548.92, "text": " data and so on, which is something you would bolt on top of IPFS, but nothing I think IPLD", "tokens": [1412, 293, 370, 322, 11, 597, 307, 746, 291, 576, 13436, 322, 1192, 295, 8671, 29318, 11, 457, 1825, 286, 519, 8671, 23704], "temperature": 0.0, "avg_logprob": -0.229086960896407, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.00012284191325306892}, {"id": 343, "seek": 152620, "start": 1548.92, "end": 1551.72, "text": " has encoded there right now.", "tokens": [575, 2058, 12340, 456, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.229086960896407, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.00012284191325306892}, {"id": 344, "seek": 155172, "start": 1551.72, "end": 1565.16, "text": " It's partly the same question about how it is ensured that there are no collisions in", "tokens": [467, 311, 17031, 264, 912, 1168, 466, 577, 309, 307, 3489, 3831, 300, 456, 366, 572, 46537, 294], "temperature": 0.0, "avg_logprob": -0.20993082288285375, "compression_ratio": 1.6023391812865497, "no_speech_prob": 0.000729611492715776}, {"id": 345, "seek": 155172, "start": 1565.16, "end": 1566.72, "text": " the content ID.", "tokens": [264, 2701, 7348, 13], "temperature": 0.0, "avg_logprob": -0.20993082288285375, "compression_ratio": 1.6023391812865497, "no_speech_prob": 0.000729611492715776}, {"id": 346, "seek": 155172, "start": 1566.72, "end": 1567.72, "text": " No collisions?", "tokens": [883, 46537, 30], "temperature": 0.0, "avg_logprob": -0.20993082288285375, "compression_ratio": 1.6023391812865497, "no_speech_prob": 0.000729611492715776}, {"id": 347, "seek": 155172, "start": 1567.72, "end": 1574.44, "text": " Yes, because if you publish some other content with the same content ID, you said it's happening", "tokens": [1079, 11, 570, 498, 291, 11374, 512, 661, 2701, 365, 264, 912, 2701, 7348, 11, 291, 848, 309, 311, 2737], "temperature": 0.0, "avg_logprob": -0.20993082288285375, "compression_ratio": 1.6023391812865497, "no_speech_prob": 0.000729611492715776}, {"id": 348, "seek": 155172, "start": 1574.44, "end": 1578.4, "text": " locally, the content ID generation.", "tokens": [16143, 11, 264, 2701, 7348, 5125, 13], "temperature": 0.0, "avg_logprob": -0.20993082288285375, "compression_ratio": 1.6023391812865497, "no_speech_prob": 0.000729611492715776}, {"id": 349, "seek": 155172, "start": 1578.4, "end": 1580.04, "text": " You could fake contents.", "tokens": [509, 727, 7592, 15768, 13], "temperature": 0.0, "avg_logprob": -0.20993082288285375, "compression_ratio": 1.6023391812865497, "no_speech_prob": 0.000729611492715776}, {"id": 350, "seek": 158004, "start": 1580.04, "end": 1587.04, "text": " Yes, but then all these cryptographic hash functions would be broken then, which would", "tokens": [1079, 11, 457, 550, 439, 613, 9844, 12295, 22019, 6828, 576, 312, 5463, 550, 11, 597, 576], "temperature": 0.0, "avg_logprob": -0.34233998385342684, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.948760397383012e-05}, {"id": 351, "seek": 158004, "start": 1587.04, "end": 1588.92, "text": " be very bad.", "tokens": [312, 588, 1578, 13], "temperature": 0.0, "avg_logprob": -0.34233998385342684, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.948760397383012e-05}, {"id": 352, "seek": 158004, "start": 1588.92, "end": 1592.6, "text": " And if you have a hash collision, then it actually means you have the same content.", "tokens": [400, 498, 291, 362, 257, 22019, 24644, 11, 550, 309, 767, 1355, 291, 362, 264, 912, 2701, 13], "temperature": 0.0, "avg_logprob": -0.34233998385342684, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.948760397383012e-05}, {"id": 353, "seek": 158004, "start": 1592.6, "end": 1597.3999999999999, "text": " That's the assumption right now, or maybe, yes, Joe.", "tokens": [663, 311, 264, 15302, 558, 586, 11, 420, 1310, 11, 2086, 11, 6807, 13], "temperature": 0.0, "avg_logprob": -0.34233998385342684, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.948760397383012e-05}, {"id": 354, "seek": 158004, "start": 1597.3999999999999, "end": 1602.48, "text": " We just use a shadow 56 by default, and you can use also one like black 3, black 2, but", "tokens": [492, 445, 764, 257, 8576, 19687, 538, 7576, 11, 293, 291, 393, 764, 611, 472, 411, 2211, 805, 11, 2211, 568, 11, 457], "temperature": 0.0, "avg_logprob": -0.34233998385342684, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.948760397383012e-05}, {"id": 355, "seek": 158004, "start": 1602.48, "end": 1606.8799999999999, "text": " if you find a collision in shadow 56, you have bigger problems and IPFS is not working.", "tokens": [498, 291, 915, 257, 24644, 294, 8576, 19687, 11, 291, 362, 3801, 2740, 293, 8671, 29318, 307, 406, 1364, 13], "temperature": 0.0, "avg_logprob": -0.34233998385342684, "compression_ratio": 1.5968992248062015, "no_speech_prob": 4.948760397383012e-05}, {"id": 356, "seek": 160688, "start": 1606.88, "end": 1612.8000000000002, "text": " Exactly this, yeah.", "tokens": [7587, 341, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.33864275614420575, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.00041262825834564865}, {"id": 357, "seek": 160688, "start": 1612.8000000000002, "end": 1619.8000000000002, "text": " Follow on on this, how resilient is this against malicious actors that want to prevent me from", "tokens": [9876, 322, 322, 341, 11, 577, 23699, 307, 341, 1970, 33496, 10037, 300, 528, 281, 4871, 385, 490], "temperature": 0.0, "avg_logprob": -0.33864275614420575, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.00041262825834564865}, {"id": 358, "seek": 160688, "start": 1619.8000000000002, "end": 1622.8000000000002, "text": " reaching the content?", "tokens": [9906, 264, 2701, 30], "temperature": 0.0, "avg_logprob": -0.33864275614420575, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.00041262825834564865}, {"id": 359, "seek": 160688, "start": 1622.8000000000002, "end": 1624.88, "text": " It's a big question, but maybe something.", "tokens": [467, 311, 257, 955, 1168, 11, 457, 1310, 746, 13], "temperature": 0.0, "avg_logprob": -0.33864275614420575, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.00041262825834564865}, {"id": 360, "seek": 160688, "start": 1624.88, "end": 1632.8000000000002, "text": " Yes, so on peer-to-peer networks, often these kind of civil attacks are in the tech vector", "tokens": [1079, 11, 370, 322, 15108, 12, 1353, 12, 494, 260, 9590, 11, 2049, 613, 733, 295, 5605, 8122, 366, 294, 264, 7553, 8062], "temperature": 0.0, "avg_logprob": -0.33864275614420575, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.00041262825834564865}, {"id": 361, "seek": 163280, "start": 1632.8, "end": 1638.8799999999999, "text": " that is considered, which means you generate a lot of identities to populate just some", "tokens": [300, 307, 4888, 11, 597, 1355, 291, 8460, 257, 688, 295, 24239, 281, 1665, 5256, 445, 512], "temperature": 0.0, "avg_logprob": -0.2214366863300274, "compression_ratio": 1.5048076923076923, "no_speech_prob": 3.368296165717766e-05}, {"id": 362, "seek": 163280, "start": 1638.8799999999999, "end": 1643.56, "text": " part of the key space to block some requests from reaching the final destination and so", "tokens": [644, 295, 264, 2141, 1901, 281, 3461, 512, 12475, 490, 9906, 264, 2572, 12236, 293, 370], "temperature": 0.0, "avg_logprob": -0.2214366863300274, "compression_ratio": 1.5048076923076923, "no_speech_prob": 3.368296165717766e-05}, {"id": 363, "seek": 163280, "start": 1643.56, "end": 1649.56, "text": " on.", "tokens": [322, 13], "temperature": 0.0, "avg_logprob": -0.2214366863300274, "compression_ratio": 1.5048076923076923, "no_speech_prob": 3.368296165717766e-05}, {"id": 364, "seek": 163280, "start": 1649.56, "end": 1655.76, "text": " From my experience, this is quite hard, and I haven't seen this happening.", "tokens": [3358, 452, 1752, 11, 341, 307, 1596, 1152, 11, 293, 286, 2378, 380, 1612, 341, 2737, 13], "temperature": 0.0, "avg_logprob": -0.2214366863300274, "compression_ratio": 1.5048076923076923, "no_speech_prob": 3.368296165717766e-05}, {"id": 365, "seek": 163280, "start": 1655.76, "end": 1660.8799999999999, "text": " I cannot say that it's impossible or probably hard to tell.", "tokens": [286, 2644, 584, 300, 309, 311, 6243, 420, 1391, 1152, 281, 980, 13], "temperature": 0.0, "avg_logprob": -0.2214366863300274, "compression_ratio": 1.5048076923076923, "no_speech_prob": 3.368296165717766e-05}, {"id": 366, "seek": 166088, "start": 1660.88, "end": 1662.88, "text": " Max, do you want?", "tokens": [7402, 11, 360, 291, 528, 30], "temperature": 0.0, "avg_logprob": -0.29166685301682044, "compression_ratio": 1.6747967479674797, "no_speech_prob": 5.0617472879821435e-05}, {"id": 367, "seek": 166088, "start": 1662.88, "end": 1669.64, "text": " Also, yeah, Kadeimnia has this mechanism where only long-living peers stay in the driving", "tokens": [2743, 11, 1338, 11, 591, 762, 332, 12679, 575, 341, 7513, 689, 787, 938, 12, 75, 2123, 16739, 1754, 294, 264, 4840], "temperature": 0.0, "avg_logprob": -0.29166685301682044, "compression_ratio": 1.6747967479674797, "no_speech_prob": 5.0617472879821435e-05}, {"id": 368, "seek": 166088, "start": 1669.64, "end": 1670.64, "text": " table.", "tokens": [3199, 13], "temperature": 0.0, "avg_logprob": -0.29166685301682044, "compression_ratio": 1.6747967479674797, "no_speech_prob": 5.0617472879821435e-05}, {"id": 369, "seek": 166088, "start": 1670.64, "end": 1673.2, "text": " True, yeah, only, yeah.", "tokens": [13587, 11, 1338, 11, 787, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.29166685301682044, "compression_ratio": 1.6747967479674797, "no_speech_prob": 5.0617472879821435e-05}, {"id": 370, "seek": 166088, "start": 1673.2, "end": 1678.44, "text": " So this civil thing is just one attack vector, but this is like the common one that is considered.", "tokens": [407, 341, 5605, 551, 307, 445, 472, 2690, 8062, 11, 457, 341, 307, 411, 264, 2689, 472, 300, 307, 4888, 13], "temperature": 0.0, "avg_logprob": -0.29166685301682044, "compression_ratio": 1.6747967479674797, "no_speech_prob": 5.0617472879821435e-05}, {"id": 371, "seek": 166088, "start": 1678.44, "end": 1682.72, "text": " So there are many points in the code base where you need to think about what happens", "tokens": [407, 456, 366, 867, 2793, 294, 264, 3089, 3096, 689, 291, 643, 281, 519, 466, 437, 2314], "temperature": 0.0, "avg_logprob": -0.29166685301682044, "compression_ratio": 1.6747967479674797, "no_speech_prob": 5.0617472879821435e-05}, {"id": 372, "seek": 166088, "start": 1682.72, "end": 1689.2, "text": " if a civil attack is going on, and one thing that Kadeimnia does is to keep, like, prefer", "tokens": [498, 257, 5605, 2690, 307, 516, 322, 11, 293, 472, 551, 300, 591, 762, 332, 12679, 775, 307, 281, 1066, 11, 411, 11, 4382], "temperature": 0.0, "avg_logprob": -0.29166685301682044, "compression_ratio": 1.6747967479674797, "no_speech_prob": 5.0617472879821435e-05}, {"id": 373, "seek": 168920, "start": 1689.2, "end": 1692.1200000000001, "text": " long-running nodes, stable nodes in the routing table.", "tokens": [938, 12, 45482, 13891, 11, 8351, 13891, 294, 264, 32722, 3199, 13], "temperature": 0.0, "avg_logprob": -0.23148163505222485, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.00013578501238953322}, {"id": 374, "seek": 168920, "start": 1692.1200000000001, "end": 1696.76, "text": " So if someone immediately generates a lot of identities that they don't end up in your", "tokens": [407, 498, 1580, 4258, 23815, 257, 688, 295, 24239, 300, 436, 500, 380, 917, 493, 294, 428], "temperature": 0.0, "avg_logprob": -0.23148163505222485, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.00013578501238953322}, {"id": 375, "seek": 168920, "start": 1696.76, "end": 1704.2, "text": " routing table and pollutes your routing, your content routing here, or interferes with", "tokens": [32722, 3199, 293, 6418, 1819, 428, 32722, 11, 428, 2701, 32722, 510, 11, 420, 25799, 279, 365], "temperature": 0.0, "avg_logprob": -0.23148163505222485, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.00013578501238953322}, {"id": 376, "seek": 168920, "start": 1704.2, "end": 1705.2, "text": " that.", "tokens": [300, 13], "temperature": 0.0, "avg_logprob": -0.23148163505222485, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.00013578501238953322}, {"id": 377, "seek": 168920, "start": 1705.2, "end": 1707.2, "text": " All right, go ahead.", "tokens": [1057, 558, 11, 352, 2286, 13], "temperature": 0.0, "avg_logprob": -0.23148163505222485, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.00013578501238953322}, {"id": 378, "seek": 168920, "start": 1707.2, "end": 1715.44, "text": " I'm not sure if I want to ask it, but removing content, you know, deleting, you know, we", "tokens": [286, 478, 406, 988, 498, 286, 528, 281, 1029, 309, 11, 457, 12720, 2701, 11, 291, 458, 11, 48946, 11, 291, 458, 11, 321], "temperature": 0.0, "avg_logprob": -0.23148163505222485, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.00013578501238953322}, {"id": 379, "seek": 171544, "start": 1715.44, "end": 1722.28, "text": " got the EPR, so is there any solution that can be done?", "tokens": [658, 264, 462, 15958, 11, 370, 307, 456, 604, 3827, 300, 393, 312, 1096, 30], "temperature": 0.0, "avg_logprob": -0.30424640705059103, "compression_ratio": 1.4350282485875707, "no_speech_prob": 0.0002689688408281654}, {"id": 380, "seek": 171544, "start": 1722.28, "end": 1724.76, "text": " So, yeah, it's hard.", "tokens": [407, 11, 1338, 11, 309, 311, 1152, 13], "temperature": 0.0, "avg_logprob": -0.30424640705059103, "compression_ratio": 1.4350282485875707, "no_speech_prob": 0.0002689688408281654}, {"id": 381, "seek": 171544, "start": 1724.76, "end": 1728.96, "text": " That's part of the thing, if you could, then it's not censorship resistant anymore.", "tokens": [663, 311, 644, 295, 264, 551, 11, 498, 291, 727, 11, 550, 309, 311, 406, 40985, 20383, 3602, 13], "temperature": 0.0, "avg_logprob": -0.30424640705059103, "compression_ratio": 1.4350282485875707, "no_speech_prob": 0.0002689688408281654}, {"id": 382, "seek": 171544, "start": 1728.96, "end": 1737.92, "text": " And so what is one solution, well, one alleviation, maybe, is to have a blacklist of CID that", "tokens": [400, 370, 437, 307, 472, 3827, 11, 731, 11, 472, 33201, 399, 11, 1310, 11, 307, 281, 362, 257, 2211, 8264, 295, 383, 2777, 300], "temperature": 0.0, "avg_logprob": -0.30424640705059103, "compression_ratio": 1.4350282485875707, "no_speech_prob": 0.0002689688408281654}, {"id": 383, "seek": 173792, "start": 1737.92, "end": 1746.52, "text": " you may publish or may not to say, okay, don't replicate this CID and so on, but this also,", "tokens": [291, 815, 11374, 420, 815, 406, 281, 584, 11, 1392, 11, 500, 380, 25356, 341, 383, 2777, 293, 370, 322, 11, 457, 341, 611, 11], "temperature": 0.0, "avg_logprob": -0.19973514477411905, "compression_ratio": 1.5758928571428572, "no_speech_prob": 6.642344487772789e-06}, {"id": 384, "seek": 173792, "start": 1746.52, "end": 1752.04, "text": " if you have such a list, then it's very easy to just look it up and see what's inside.", "tokens": [498, 291, 362, 1270, 257, 1329, 11, 550, 309, 311, 588, 1858, 281, 445, 574, 309, 493, 293, 536, 437, 311, 1854, 13], "temperature": 0.0, "avg_logprob": -0.19973514477411905, "compression_ratio": 1.5758928571428572, "no_speech_prob": 6.642344487772789e-06}, {"id": 385, "seek": 173792, "start": 1752.04, "end": 1760.16, "text": " Yeah, so deleting content is very tricky, however, I said it's permanent links, yeah,", "tokens": [865, 11, 370, 48946, 2701, 307, 588, 12414, 11, 4461, 11, 286, 848, 309, 311, 10996, 6123, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.19973514477411905, "compression_ratio": 1.5758928571428572, "no_speech_prob": 6.642344487772789e-06}, {"id": 386, "seek": 173792, "start": 1760.16, "end": 1765.4, "text": " the links are permanent, but actually content still turns in the IPFS network, and these", "tokens": [264, 6123, 366, 10996, 11, 457, 767, 2701, 920, 4523, 294, 264, 8671, 29318, 3209, 11, 293, 613], "temperature": 0.0, "avg_logprob": -0.19973514477411905, "compression_ratio": 1.5758928571428572, "no_speech_prob": 6.642344487772789e-06}, {"id": 387, "seek": 176540, "start": 1765.4, "end": 1772.4, "text": " provider records that you publish into the network expire after 24 hours, so if no one", "tokens": [12398, 7724, 300, 291, 11374, 666, 264, 3209, 45447, 934, 4022, 2496, 11, 370, 498, 572, 472], "temperature": 0.0, "avg_logprob": -0.13310348987579346, "compression_ratio": 1.5818181818181818, "no_speech_prob": 7.5257703429088e-06}, {"id": 388, "seek": 176540, "start": 1772.4, "end": 1778.48, "text": " actually re-provides the content or keeps the content, the content is gone as well.", "tokens": [767, 319, 12, 49911, 1875, 264, 2701, 420, 5965, 264, 2701, 11, 264, 2701, 307, 2780, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.13310348987579346, "compression_ratio": 1.5818181818181818, "no_speech_prob": 7.5257703429088e-06}, {"id": 389, "seek": 176540, "start": 1778.48, "end": 1786.0, "text": " But a delete operation doesn't exist, so we just need to hope that no one will be provided", "tokens": [583, 257, 12097, 6916, 1177, 380, 2514, 11, 370, 321, 445, 643, 281, 1454, 300, 572, 472, 486, 312, 5649], "temperature": 0.0, "avg_logprob": -0.13310348987579346, "compression_ratio": 1.5818181818181818, "no_speech_prob": 7.5257703429088e-06}, {"id": 390, "seek": 178600, "start": 1786.0, "end": 1796.44, "text": " any more, which you could do with these denialists, for example, yeah, Daniel, okay.", "tokens": [604, 544, 11, 597, 291, 727, 360, 365, 613, 28754, 1751, 11, 337, 1365, 11, 1338, 11, 8033, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.29389848311742145, "compression_ratio": 1.560747663551402, "no_speech_prob": 0.00014356730389408767}, {"id": 391, "seek": 178600, "start": 1796.44, "end": 1800.56, "text": " Who is able to write into that blacklist and is there any?", "tokens": [2102, 307, 1075, 281, 2464, 666, 300, 2211, 8264, 293, 307, 456, 604, 30], "temperature": 0.0, "avg_logprob": -0.29389848311742145, "compression_ratio": 1.560747663551402, "no_speech_prob": 0.00014356730389408767}, {"id": 392, "seek": 178600, "start": 1800.56, "end": 1807.28, "text": " Yeah, this is just one, I don't know, to be completely honest, but this is just one, maybe", "tokens": [865, 11, 341, 307, 445, 472, 11, 286, 500, 380, 458, 11, 281, 312, 2584, 3245, 11, 457, 341, 307, 445, 472, 11, 1310], "temperature": 0.0, "avg_logprob": -0.29389848311742145, "compression_ratio": 1.560747663551402, "no_speech_prob": 0.00014356730389408767}, {"id": 393, "seek": 178600, "start": 1807.28, "end": 1808.28, "text": " Jeroko knows.", "tokens": [8139, 13704, 3255, 13], "temperature": 0.0, "avg_logprob": -0.29389848311742145, "compression_ratio": 1.560747663551402, "no_speech_prob": 0.00014356730389408767}, {"id": 394, "seek": 178600, "start": 1808.28, "end": 1815.36, "text": " There is no blacklist in the network right now, it's a few people that want that, but", "tokens": [821, 307, 572, 2211, 8264, 294, 264, 3209, 558, 586, 11, 309, 311, 257, 1326, 561, 300, 528, 300, 11, 457], "temperature": 0.0, "avg_logprob": -0.29389848311742145, "compression_ratio": 1.560747663551402, "no_speech_prob": 0.00014356730389408767}, {"id": 395, "seek": 181536, "start": 1815.36, "end": 1821.6, "text": " we have, sorry, earlier you said that we have gateways, and gateways is just a node that", "tokens": [321, 362, 11, 2597, 11, 3071, 291, 848, 300, 321, 362, 8539, 942, 11, 293, 8539, 942, 307, 445, 257, 9984, 300], "temperature": 0.0, "avg_logprob": -0.22334009154230103, "compression_ratio": 1.783132530120482, "no_speech_prob": 0.00011670024832710624}, {"id": 396, "seek": 181536, "start": 1821.6, "end": 1827.8, "text": " publicly is reachable, and those gateways, because many people say that, okay, they find", "tokens": [14843, 307, 2524, 712, 11, 293, 729, 8539, 942, 11, 570, 867, 561, 584, 300, 11, 1392, 11, 436, 915], "temperature": 0.0, "avg_logprob": -0.22334009154230103, "compression_ratio": 1.783132530120482, "no_speech_prob": 0.00011670024832710624}, {"id": 397, "seek": 181536, "start": 1827.8, "end": 1833.12, "text": " some content illegal on IPFS, and instead of reporting to the actual node, so it's a content", "tokens": [512, 2701, 11905, 322, 8671, 29318, 11, 293, 2602, 295, 10031, 281, 264, 3539, 9984, 11, 370, 309, 311, 257, 2701], "temperature": 0.0, "avg_logprob": -0.22334009154230103, "compression_ratio": 1.783132530120482, "no_speech_prob": 0.00011670024832710624}, {"id": 398, "seek": 181536, "start": 1833.12, "end": 1837.32, "text": " on IPFS, they just report it on the gateway, because they know HTTP and they don't know", "tokens": [322, 8671, 29318, 11, 436, 445, 2275, 309, 322, 264, 28532, 11, 570, 436, 458, 33283, 293, 436, 500, 380, 458], "temperature": 0.0, "avg_logprob": -0.22334009154230103, "compression_ratio": 1.783132530120482, "no_speech_prob": 0.00011670024832710624}, {"id": 399, "seek": 181536, "start": 1837.32, "end": 1842.4399999999998, "text": " IPFS, and so our gateway has some blacklist that is somewhere, but it's not shared by", "tokens": [8671, 29318, 11, 293, 370, 527, 28532, 575, 512, 2211, 8264, 300, 307, 4079, 11, 457, 309, 311, 406, 5507, 538], "temperature": 0.0, "avg_logprob": -0.22334009154230103, "compression_ratio": 1.783132530120482, "no_speech_prob": 0.00011670024832710624}, {"id": 400, "seek": 184244, "start": 1842.44, "end": 1846.04, "text": " the complete network, it's just for our gateway IPFS.io.", "tokens": [264, 3566, 3209, 11, 309, 311, 445, 337, 527, 28532, 8671, 29318, 13, 1004, 13], "temperature": 0.0, "avg_logprob": -0.24175174281282244, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00017210704390890896}, {"id": 401, "seek": 184244, "start": 1846.04, "end": 1852.96, "text": " So cloudfair, for example, and I've already read these gateways, or more, anyone could", "tokens": [407, 4588, 69, 1246, 11, 337, 1365, 11, 293, 286, 600, 1217, 1401, 613, 8539, 942, 11, 420, 544, 11, 2878, 727], "temperature": 0.0, "avg_logprob": -0.24175174281282244, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00017210704390890896}, {"id": 402, "seek": 184244, "start": 1852.96, "end": 1859.92, "text": " operate the gateway, so you could file a request for this, don't replicate the CID, it's a", "tokens": [9651, 264, 28532, 11, 370, 291, 727, 3991, 257, 5308, 337, 341, 11, 500, 380, 25356, 264, 383, 2777, 11, 309, 311, 257], "temperature": 0.0, "avg_logprob": -0.24175174281282244, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00017210704390890896}, {"id": 403, "seek": 184244, "start": 1859.92, "end": 1864.48, "text": " phishing website, for example, and then these CIDs are not served through the gateways,", "tokens": [903, 3807, 3144, 11, 337, 1365, 11, 293, 550, 613, 383, 2777, 82, 366, 406, 7584, 807, 264, 8539, 942, 11], "temperature": 0.0, "avg_logprob": -0.24175174281282244, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00017210704390890896}, {"id": 404, "seek": 184244, "start": 1864.48, "end": 1866.72, "text": " which is a common way to interact with the network right now.", "tokens": [597, 307, 257, 2689, 636, 281, 4648, 365, 264, 3209, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.24175174281282244, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00017210704390890896}, {"id": 405, "seek": 186672, "start": 1866.72, "end": 1873.72, "text": " Just the gateways that follow the list, it's not a domain.", "tokens": [1449, 264, 8539, 942, 300, 1524, 264, 1329, 11, 309, 311, 406, 257, 9274, 13], "temperature": 0.0, "avg_logprob": -0.26894014994303383, "compression_ratio": 1.566137566137566, "no_speech_prob": 0.0013005416840314865}, {"id": 406, "seek": 186672, "start": 1873.72, "end": 1880.32, "text": " Okay, we're running out of time, unless there is one more.", "tokens": [1033, 11, 321, 434, 2614, 484, 295, 565, 11, 5969, 456, 307, 472, 544, 13], "temperature": 0.0, "avg_logprob": -0.26894014994303383, "compression_ratio": 1.566137566137566, "no_speech_prob": 0.0013005416840314865}, {"id": 407, "seek": 186672, "start": 1880.32, "end": 1886.6000000000001, "text": " I have a question regarding searching through the stored content, is there any mechanism", "tokens": [286, 362, 257, 1168, 8595, 10808, 807, 264, 12187, 2701, 11, 307, 456, 604, 7513], "temperature": 0.0, "avg_logprob": -0.26894014994303383, "compression_ratio": 1.566137566137566, "no_speech_prob": 0.0013005416840314865}, {"id": 408, "seek": 186672, "start": 1886.6000000000001, "end": 1895.2, "text": " on how to go through or index the files that are there to have some sort of like a search", "tokens": [322, 577, 281, 352, 807, 420, 8186, 264, 7098, 300, 366, 456, 281, 362, 512, 1333, 295, 411, 257, 3164], "temperature": 0.0, "avg_logprob": -0.26894014994303383, "compression_ratio": 1.566137566137566, "no_speech_prob": 0.0013005416840314865}, {"id": 409, "seek": 189520, "start": 1895.2, "end": 1897.32, "text": " engine for that?", "tokens": [2848, 337, 300, 30], "temperature": 0.0, "avg_logprob": -0.19282338995682566, "compression_ratio": 1.7149532710280373, "no_speech_prob": 6.393538933480158e-05}, {"id": 410, "seek": 189520, "start": 1897.32, "end": 1905.4, "text": " Right, so there's a project called IPFS search, and this makes use, like among other things,", "tokens": [1779, 11, 370, 456, 311, 257, 1716, 1219, 8671, 29318, 3164, 11, 293, 341, 1669, 764, 11, 411, 3654, 661, 721, 11], "temperature": 0.0, "avg_logprob": -0.19282338995682566, "compression_ratio": 1.7149532710280373, "no_speech_prob": 6.393538933480158e-05}, {"id": 411, "seek": 189520, "start": 1905.4, "end": 1910.88, "text": " of this immediate request for CIDs, so it's just sitting there listening, connecting to", "tokens": [295, 341, 11629, 5308, 337, 383, 2777, 82, 11, 370, 309, 311, 445, 3798, 456, 4764, 11, 11015, 281], "temperature": 0.0, "avg_logprob": -0.19282338995682566, "compression_ratio": 1.7149532710280373, "no_speech_prob": 6.393538933480158e-05}, {"id": 412, "seek": 189520, "start": 1910.88, "end": 1913.92, "text": " a lot of nodes, and as I said, if someone requests content, you immediately ask your", "tokens": [257, 688, 295, 13891, 11, 293, 382, 286, 848, 11, 498, 1580, 12475, 2701, 11, 291, 4258, 1029, 428], "temperature": 0.0, "avg_logprob": -0.19282338995682566, "compression_ratio": 1.7149532710280373, "no_speech_prob": 6.393538933480158e-05}, {"id": 413, "seek": 189520, "start": 1913.92, "end": 1919.88, "text": " connected peers, and you're connected to a lot of peers, and these IPFS search nodes", "tokens": [4582, 16739, 11, 293, 291, 434, 4582, 281, 257, 688, 295, 16739, 11, 293, 613, 8671, 29318, 3164, 13891], "temperature": 0.0, "avg_logprob": -0.19282338995682566, "compression_ratio": 1.7149532710280373, "no_speech_prob": 6.393538933480158e-05}, {"id": 414, "seek": 191988, "start": 1919.88, "end": 1925.24, "text": " are sitting there listening to these requests, and they see, okay, someone wants the CID,", "tokens": [366, 3798, 456, 4764, 281, 613, 12475, 11, 293, 436, 536, 11, 1392, 11, 1580, 2738, 264, 383, 2777, 11], "temperature": 0.0, "avg_logprob": -0.18599783363988845, "compression_ratio": 1.7551020408163265, "no_speech_prob": 4.812136830878444e-05}, {"id": 415, "seek": 191988, "start": 1925.24, "end": 1929.96, "text": " so I go ahead and request that CID as well, and then index that content on myself, and", "tokens": [370, 286, 352, 2286, 293, 5308, 300, 383, 2777, 382, 731, 11, 293, 550, 8186, 300, 2701, 322, 2059, 11, 293], "temperature": 0.0, "avg_logprob": -0.18599783363988845, "compression_ratio": 1.7551020408163265, "no_speech_prob": 4.812136830878444e-05}, {"id": 416, "seek": 191988, "start": 1929.96, "end": 1936.7600000000002, "text": " so you can then search on this IPFS search website for something, just with Google, and", "tokens": [370, 291, 393, 550, 3164, 322, 341, 8671, 29318, 3164, 3144, 337, 746, 11, 445, 365, 3329, 11, 293], "temperature": 0.0, "avg_logprob": -0.18599783363988845, "compression_ratio": 1.7551020408163265, "no_speech_prob": 4.812136830878444e-05}, {"id": 417, "seek": 191988, "start": 1936.7600000000002, "end": 1941.5200000000002, "text": " then you see CIDs popping in, and then you can request those CIDs from the IPFS network.", "tokens": [550, 291, 536, 383, 2777, 82, 18374, 294, 11, 293, 550, 291, 393, 5308, 729, 383, 2777, 82, 490, 264, 8671, 29318, 3209, 13], "temperature": 0.0, "avg_logprob": -0.18599783363988845, "compression_ratio": 1.7551020408163265, "no_speech_prob": 4.812136830878444e-05}, {"id": 418, "seek": 191988, "start": 1941.5200000000002, "end": 1946.5600000000002, "text": " So this is one approach to do that, to index content, yeah.", "tokens": [407, 341, 307, 472, 3109, 281, 360, 300, 11, 281, 8186, 2701, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.18599783363988845, "compression_ratio": 1.7551020408163265, "no_speech_prob": 4.812136830878444e-05}, {"id": 419, "seek": 191988, "start": 1946.5600000000002, "end": 1948.5600000000002, "text": " Okay, thank you.", "tokens": [1033, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.18599783363988845, "compression_ratio": 1.7551020408163265, "no_speech_prob": 4.812136830878444e-05}, {"id": 420, "seek": 194856, "start": 1948.56, "end": 1950.56, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.544139583905538, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.000278583203908056}], "language": "en"}