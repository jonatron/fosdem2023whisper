{"text": " So, we start with the first presentation by Olivier Caix from the G-Streamer of the State of the Union for this year. So, hi everyone. I'm Olivier Caix. I've been a short developer now for 15 years. And I'm going to tell you a bit of what has happened in the G-Streamer community in the last two years that we last met. Here. So, we have two major releases, 1.20, 1.22. Quite a lot of merge requests as you can see. And an interesting fact, in 1.22, a third of the commits were in the Rust modules. So, we've been investing a lot in Rust in the community. There's a lot of excitement there. And that's been happening. One of the kind of big things for us as developers that we did was to merge all of the various git repositories into one big giant repository. So, now everything is together, except for Rust. Rust modules are all on the local corner because they're released with the GTK-RS infrastructure. So, the rest of these three ones. But that's kind of our big change for the developers, but it doesn't change much for the end-user because we still release all the packages in separate car balls, just like these. Another thing that we did that's between infrastructure is we've improved our build system, and now we can select the elements one by one. Not just the plug-ins, but you can select exactly which element you want in the plug-in. And then we can also link all the plug-ins, all the elements, all the dependencies into one giant library. This makes it actually easier to make a smaller build because we can build only exactly the functionality that you need for a specific application. Create a big library that only has the exact functions that are being used, right, and nothing else. So, we did that for embedded systems mostly so that you can have something a little smaller. Another area, and there has been quite a lot of excitement in this terminal the last couple of years, is WebRTC. So, as probably all of you are familiar with, WebRTC is a way to send video and load it in SQL from browsers, and Distributor has one of the most complete implementation outside of the Google implementation that's used by the browsers. We were missing one big bit, and that was the congestion control, and that's been added in the last releases. So, now we have a module that is compatible with what's called Google congestion control, which is what Chrome and Firefox and Safari use. And this is in Rust. And to make that work, so we have a WebRTC implementation, but that did not do any of the actual encoding that was left separate on purpose. Now we have a module in Rust plug-in that will plug the encoder and the WebRTC and do the congestion control so that you can adapt the bitrate of the encoder to the encoding, and this is all automatic if you use this plug-in. We also have Web and Web, so these are also within Rust there. Web and Web are a way to replace RTMP, but based on WebRTC, so it's a single request, a single HTTP request way to set up a WebRTC stream. It's mostly meant to stream to and from a server, so it's really a replacement for RTMP for a low latency video transmission. Speaking of WebRTC, so WebRTC is based on RTMP, and this is an area where there's also been quite a bit of development. So, starting with 222-1 order correction, that's a system used mostly for legacy broadcast transmission, and we have the 2D order correction. So what does it mean 2D? It means that we do 4D order correction, which is basically, you absorb multiple packets, then you generate a new one, and if you have any of these packets except one, then you can regenerate the missing one, right? That's what the parallel error correction is. Traditionally, you would do like packets one, two, and three, and four, and then you would generate a fifth packet. What losses tend to come in bursts in networks? So with 2D error correction, we have this kind of traditional version, and also a version where you do packet one, and five, and ten, right? So if you have a burst, you can recover more of the more packets. The other thing that we've added, so just remember for a long time, we've had the API to add RTP-Ether extensions. That's a way to each packet to add a little header with something else. So for a long time, we had libraries to actually write these, but we didn't have something in the system to easily plug in something to insert this header in every packet without having to write application code. So this is something that we've added, and we've added a bunch of different modules. The multiple is this client-to-mixer audio level. This makes it possible for a sender of audio to say the volume that I'm sending is this, so that a mixer or some kind of service can select the person who speaks loudest without having to decode all of the audio. So it can know from this level who's speaking louder and just forward that one. Then, color space. So this is for VP9. If you want to send HDR over VP9, we now have this RTP-Ether extension to make it work. It's compatible with Chrome again, so this is a phase-on-article experiment. And we have an AD1 builder and deep builder, so this is, I think, probably the first thing where we've decided that the official implementation of a major feature is only available in Rust. So this is something that we're pretty happy about. Another thing, so H264, H265, they have two kinds of timestamp. Presentation timestamp, decoding timestamp. When you send RTP, normally only send a presentation timestamp. You need to apply an algorithm to recover the decoding timestamp. We now have modules that generate that. We also support RxC6651, so that's a way to synchronize streams immediately. So traditionally with RTP, we send two streams, audio, video, separate timestamps, and then sometimes later you get a packet telling you what the correspondence is. With RxC6651, we add the RTP-Ether extension in every packet so that we can be synchronized from the first packet. And we also improve our base class for video decoders a bit. So now it can recognize that there's a corruption and use that to request a retransmission previously. We kind of applied the error, but we let the application do the decision. Now we've added something to the base class. Another big feature that was worked on is that we basically rewrote the HLS and dash base class. So the previous one was over 10 years old and had been written largely without the specs. And even when we had the specs, HLS has changed quite a lot over the last 10 years. So now we have almost a state-of-the-art implementation based on 10 years more knowledge. It's much more simple, has fewer trends, much better control on how we download things, on the buffering. We do a little bit of the parsing in there because sadly for many of these for us, you have to parse the base stream to handle it properly. So this is all implemented as one in this decade. We've put a few things around decoding, mostly video decoding. One thing I'm quite excited about is the subframe decoding that has been quite a few years coming. And this means that we now have infrastructure in our base classes to start decoding a frame before you receive the entire frame. Some format, issue 6.46.5, we can split the frame in slices. And from this first now, you can actually start doing the decoding. We have two implementations of this. One is based on HPEG, which can do this only for issue 6.46.4. And the other one is for the exiling hardware because they have the hardware features to do that. So they can do super low latency decoding. We have WebM Alpha. So the WebM format, so HPEG tonight don't have support for transparency built in. But there's a WebM extension where we basically store two separate video streams. One with the colors and one with the transparency. And now we have an element that will spin up two decoders and then recombine them into a A1B stream. We have a DirectX Elevent library. So make it easier to integrate Direct 3D Elevent applications in the streamer to do zero copy and coding. For example, from a Windows application. And also speaking of Windows, our Direct 3D Elevent decoders are now default. So they're becoming the choice that will get auto plugged if you have them. So you get hardware accelerator decoding on Windows. That works. What about MacBooks? Yes, there's also... We've got a question already. So we have a hardware decoder from Mac and IOS, which is the same idea. CUDA, so some people use proprietary software and proprietary drivers. So we have now also a CUDA library so that you can insert more easily CUDA data into the streamer for encoding, decoding all these things. We have some more CUDA native elements, one that is a converter and a scaler, so using CUDA itself. We have CUDA and Direct 3D integration for Windows again. And this whole thing basically gives you zero copy and coding on NVIDIA hardware, especially when you match with some other CUDA-based software. But some people prefer free software. So we also have BAPI, we have a new plugin for BAPI. So we've had G-SUMOR BAPI for a long, long time. It was getting quite freaky. It was not based on any of the base classes that we have improved since then. So it's been completely rewritten from scratch with a new plugin that we call VA. It supports all the major codecs now that we've implemented, all the ones with VA. It supports AVY, it supports just 5, VPA, between 9 and 8, MPEG-2. Encoding, we only have the issue 6, 4, 5 codecs for now, but the rest are being worked on, as we speak. And using live VA, we have a bit more than VA. We have a bit more features. We have a compositor. It's an element that will take two or more streams and composite them into the same video. We have a D-interlacer. And we have a post-processor element with scaling and color space conversion, using the video functionality instead of the GPU. And open work has happened around 8 to 1 or something in the last two years. So we have quite a lot now. We have support for AV1, both in the legacy VA plugin and in the new VA plugin. We have it for AMD, the coders. We have it for Direct3D on Windows, using the NVDI-PI's. For Intel, using their multiple libraries, either Quixin, QSV, or the new VSDK. So we have pretty comprehensive AV1 support, in addition to the RTB plugin that I mentioned earlier. Another new thing that we've done is, this is our first official machine learning integration that is in G-streamer itself. So it's the first step. And we've written a plugin to use the Onyx runtime from Microsoft to basically take some video frames, some model and recognize objects, put little boxes in the metadata, and then another element that can take these boxes and draw them on the image. So this is the first step. A lot of work is happening right now to have a better video on the fixed framework as part of G-streamer. All these things I like about sometimes you want to have a UI. And a few pictures were recently added there. We have a GTK4 paintable, so that's an object. I would say that you can use the GTK4 to actually draw something on the screen. So now you can easily integrate G-streamer with GTK4 to your old copy playback. This one is in Rust, which is kind of cool. Qt6 as well as that thing, so that we have something that is very similar to what we have for Qt5, which is a QML item, so that you can integrate a G-streamer sync with the output with Qt and draw in your Qt application. And the last one is a niche case. So we had a Wayland sync for a long time, and what this Wayland sync allows you to do is to basically take the video buffer and give it to the Wayland compositor directly without going through the toolkit. So you can use the 2D hardware planes of the platform. This is multi-use useful and embedded. It allows you to do things like greater performance, not use the GPU on embedded systems where the GPU might be too slow to jail. Up to now, this all works fine, but you have to write a low level Wayland code, and that's non-trivial. So we've written a GTK widget that wraps up. So now we can write your application GTK, just add the widget, and you get all of these performance benefits for free. Last but not least, in this category, we added touch event navigation. So previously we had navigation, we could send letters, we could send mouse clicks, but now we can also send touch events so that you can have elements in your pipeline that are controlled by the user, such as we have a Webbar app, a web view, a webkit-based source. And we have some new tracers, so these are tools for developers to know actually what's going on in a pipeline live. We have a bunch of tracers already, four more were added. Some of them are quite useful, like we have one to generate buffer, to read the buffer lateness and one to trace the queue level, and these will output the information in a CSV file that you can then load and make nice graphs and understand what's the live performance of your pipeline, what's going on. We have one to draw pretty pipeline snapshots, so for a long time we had a feature where we could draw a dot file to draw a picture of the pipeline, but this required it. I added some code to the application to actually trigger it. With this tracer, now you can just listen to a unique signal and trigger it on the spot. The last one is the factory tracer. This is the very first feature that I mentioned. So it's nice to say, oh, I'm going to build a G-streamer, build specific for my application with only the elements I use. But if you use PlayVin, there's a lot of automated things, and you might not know exactly which plugins you've been using. So with this tracer, we can actually trace all the plugins that get loaded, all the elements that are used, and print, when you exit your application, print the list of what was actually used. A question about that. PlayVin sometimes tries to use PlayVin, but this got it later because it just worked. It's going to be listed anyway. So yes, right. PlayVin sometimes tries to use something, but it doesn't work because the hardware is not there or something. So in this case, the tracer will still list it. It's everything that is loaded, right? When they're tried or loaded, you call a function in it and it says no. So this is really at the loading stage at this place. Thank you. Any questions? Yes. You mentioned V1 and the RTP support in there. So can you also add the SPC extensions? I have no idea. Anyone knows? No. So RTP, any one extension, SVC extension in, I don't know if it's there. So we do layer selection of the highest quality here, but it's not there. So there is an external, there is a dependency description of RTP extension where you can get information about the SVC layers in there, which is basically something like that. So you encode the SPC layers into one screen, then you use these external extensions to vary information about what's in there and what isn't, so that you can do the connection. So that's what I got to introduce from the other video. None of the RTP and SPC stuff, including the VT1, which is quickly required because there's no SVC inside the screen. Yes, so the question was RTP, AV1, SVC, there's an extension that can make it really useful. It's being standardized and it's not implemented yet, but it will be at some point. I forgot to mention we have an online question, online question at number 43401. So if people at home want to ask questions, it's possible, but since we don't have any questions, there are any more questions on the floor. Q6, does support different rendering backends, like DirectX on Windows and Vulkan on Pino or something, with a QML event? And then Q6 supports post-interference that you can directly pass the DirectX buffer to the QML event? So does Q6 support other backends than OpenGL? And I think the answer right now is, won't it support OpenGL? Any more questions? Yes. Can you do a statically linked binary? Can you do a statically linked binary? Yes, you can. That's kind of one of the use cases as we create this statically linked library and then your application can link to it and only link the required bits. That's kind of the part of the trick to make it a little smaller. Yeah, my question. So you said that there is congestion control in WebRTC now? Yes. Is it like the same feature set as in Google's implementation? So, yeah. The question is about congestion control in WebRTC. Is it the same feature set as the Google implementation? As far as I know, yes, because it's basically a copy of the implementation in Rust. So they basically re-implement the same algorithm. So that is compatible. But it's pluggable. So you could write your own. There's a plug-in mechanism and the core version is in C, but this one is in Rust with a separate plug-in. One could write a different implementation because there's a bunch of heuristics in there. There's no line. Perfect answer. Thank you so much. Do you have a question? Yes. If I have an application that does WebRTC signaling of a matrix, for example, would I benefit from switching to WebRTC sync or would I sit with WebRTC? So the question is, if you have an implementation of WebRTC that does signaling something custom, for example, other matrix, would you benefit from using WebRTC sync? And the answer to that is yes, because it will do all of the encoding and congestion control hooked up for you. And there's an interface that you can implement for your own signaling. So the signaling is separate from this WebRTC sync. There's still a module that we can implement. We have one implemented for like a custom signaling mechanism where there's a server that's implemented, but you could write your own. Can I ask the last question? No, just a comment from the question before. The QT6 direct 3D integration. There is a merge request for it. Okay. So Tim says that for the QT, there's a direct 3D merge request open to integrate that. It's not merged yet, but do test it at home and complain when it doesn't work. Last question. Okay, thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.0, "text": " So, we start with the first presentation by Olivier Caix from the G-Streamer of the State of the Union for this year.", "tokens": [407, 11, 321, 722, 365, 264, 700, 5860, 538, 48075, 7544, 970, 490, 264, 460, 12, 4520, 1572, 260, 295, 264, 4533, 295, 264, 8133, 337, 341, 1064, 13], "temperature": 0.0, "avg_logprob": -0.3702827877468533, "compression_ratio": 1.5560975609756098, "no_speech_prob": 0.5662297606468201}, {"id": 1, "seek": 0, "start": 11.0, "end": 20.0, "text": " So, hi everyone. I'm Olivier Caix. I've been a short developer now for 15 years.", "tokens": [407, 11, 4879, 1518, 13, 286, 478, 48075, 7544, 970, 13, 286, 600, 668, 257, 2099, 10754, 586, 337, 2119, 924, 13], "temperature": 0.0, "avg_logprob": -0.3702827877468533, "compression_ratio": 1.5560975609756098, "no_speech_prob": 0.5662297606468201}, {"id": 2, "seek": 0, "start": 20.0, "end": 27.0, "text": " And I'm going to tell you a bit of what has happened in the G-Streamer community in the last two years that we last met.", "tokens": [400, 286, 478, 516, 281, 980, 291, 257, 857, 295, 437, 575, 2011, 294, 264, 460, 12, 4520, 1572, 260, 1768, 294, 264, 1036, 732, 924, 300, 321, 1036, 1131, 13], "temperature": 0.0, "avg_logprob": -0.3702827877468533, "compression_ratio": 1.5560975609756098, "no_speech_prob": 0.5662297606468201}, {"id": 3, "seek": 2700, "start": 27.0, "end": 35.0, "text": " Here. So, we have two major releases, 1.20, 1.22.", "tokens": [1692, 13, 407, 11, 321, 362, 732, 2563, 16952, 11, 502, 13, 2009, 11, 502, 13, 7490, 13], "temperature": 0.0, "avg_logprob": -0.23336150006550113, "compression_ratio": 1.4835164835164836, "no_speech_prob": 0.0003799567639362067}, {"id": 4, "seek": 2700, "start": 35.0, "end": 39.0, "text": " Quite a lot of merge requests as you can see.", "tokens": [20464, 257, 688, 295, 22183, 12475, 382, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.23336150006550113, "compression_ratio": 1.4835164835164836, "no_speech_prob": 0.0003799567639362067}, {"id": 5, "seek": 2700, "start": 39.0, "end": 46.0, "text": " And an interesting fact, in 1.22, a third of the commits were in the Rust modules.", "tokens": [400, 364, 1880, 1186, 11, 294, 502, 13, 7490, 11, 257, 2636, 295, 264, 48311, 645, 294, 264, 34952, 16679, 13], "temperature": 0.0, "avg_logprob": -0.23336150006550113, "compression_ratio": 1.4835164835164836, "no_speech_prob": 0.0003799567639362067}, {"id": 6, "seek": 2700, "start": 46.0, "end": 52.0, "text": " So, we've been investing a lot in Rust in the community. There's a lot of excitement there.", "tokens": [407, 11, 321, 600, 668, 10978, 257, 688, 294, 34952, 294, 264, 1768, 13, 821, 311, 257, 688, 295, 14755, 456, 13], "temperature": 0.0, "avg_logprob": -0.23336150006550113, "compression_ratio": 1.4835164835164836, "no_speech_prob": 0.0003799567639362067}, {"id": 7, "seek": 5200, "start": 52.0, "end": 61.0, "text": " And that's been happening. One of the kind of big things for us as developers that we did was to merge all of the various", "tokens": [400, 300, 311, 668, 2737, 13, 1485, 295, 264, 733, 295, 955, 721, 337, 505, 382, 8849, 300, 321, 630, 390, 281, 22183, 439, 295, 264, 3683], "temperature": 0.0, "avg_logprob": -0.26232803344726563, "compression_ratio": 1.490566037735849, "no_speech_prob": 8.671433170093223e-05}, {"id": 8, "seek": 5200, "start": 61.0, "end": 69.0, "text": " git repositories into one big giant repository. So, now everything is together, except for Rust.", "tokens": [18331, 22283, 2083, 666, 472, 955, 7410, 25841, 13, 407, 11, 586, 1203, 307, 1214, 11, 3993, 337, 34952, 13], "temperature": 0.0, "avg_logprob": -0.26232803344726563, "compression_ratio": 1.490566037735849, "no_speech_prob": 8.671433170093223e-05}, {"id": 9, "seek": 5200, "start": 69.0, "end": 75.0, "text": " Rust modules are all on the local corner because they're released with the GTK-RS infrastructure.", "tokens": [34952, 16679, 366, 439, 322, 264, 2654, 4538, 570, 436, 434, 4736, 365, 264, 17530, 42, 12, 43580, 6896, 13], "temperature": 0.0, "avg_logprob": -0.26232803344726563, "compression_ratio": 1.490566037735849, "no_speech_prob": 8.671433170093223e-05}, {"id": 10, "seek": 7500, "start": 75.0, "end": 83.0, "text": " So, the rest of these three ones. But that's kind of our big change for the developers,", "tokens": [407, 11, 264, 1472, 295, 613, 1045, 2306, 13, 583, 300, 311, 733, 295, 527, 955, 1319, 337, 264, 8849, 11], "temperature": 0.0, "avg_logprob": -0.29011624479947024, "compression_ratio": 1.5404040404040404, "no_speech_prob": 0.00012307545694056898}, {"id": 11, "seek": 7500, "start": 83.0, "end": 93.0, "text": " but it doesn't change much for the end-user because we still release all the packages in separate car balls, just like these.", "tokens": [457, 309, 1177, 380, 1319, 709, 337, 264, 917, 12, 18088, 570, 321, 920, 4374, 439, 264, 17401, 294, 4994, 1032, 9803, 11, 445, 411, 613, 13], "temperature": 0.0, "avg_logprob": -0.29011624479947024, "compression_ratio": 1.5404040404040404, "no_speech_prob": 0.00012307545694056898}, {"id": 12, "seek": 7500, "start": 93.0, "end": 99.0, "text": " Another thing that we did that's between infrastructure is we've improved our build system,", "tokens": [3996, 551, 300, 321, 630, 300, 311, 1296, 6896, 307, 321, 600, 9689, 527, 1322, 1185, 11], "temperature": 0.0, "avg_logprob": -0.29011624479947024, "compression_ratio": 1.5404040404040404, "no_speech_prob": 0.00012307545694056898}, {"id": 13, "seek": 9900, "start": 99.0, "end": 107.0, "text": " and now we can select the elements one by one. Not just the plug-ins, but you can select exactly which element you want in the plug-in.", "tokens": [293, 586, 321, 393, 3048, 264, 4959, 472, 538, 472, 13, 1726, 445, 264, 5452, 12, 1292, 11, 457, 291, 393, 3048, 2293, 597, 4478, 291, 528, 294, 264, 5452, 12, 259, 13], "temperature": 0.0, "avg_logprob": -0.0935697765140743, "compression_ratio": 1.7972350230414746, "no_speech_prob": 6.595655577257276e-05}, {"id": 14, "seek": 9900, "start": 107.0, "end": 114.0, "text": " And then we can also link all the plug-ins, all the elements, all the dependencies into one giant library.", "tokens": [400, 550, 321, 393, 611, 2113, 439, 264, 5452, 12, 1292, 11, 439, 264, 4959, 11, 439, 264, 36606, 666, 472, 7410, 6405, 13], "temperature": 0.0, "avg_logprob": -0.0935697765140743, "compression_ratio": 1.7972350230414746, "no_speech_prob": 6.595655577257276e-05}, {"id": 15, "seek": 9900, "start": 114.0, "end": 121.0, "text": " This makes it actually easier to make a smaller build because we can build only exactly the functionality that you need for a specific application.", "tokens": [639, 1669, 309, 767, 3571, 281, 652, 257, 4356, 1322, 570, 321, 393, 1322, 787, 2293, 264, 14980, 300, 291, 643, 337, 257, 2685, 3861, 13], "temperature": 0.0, "avg_logprob": -0.0935697765140743, "compression_ratio": 1.7972350230414746, "no_speech_prob": 6.595655577257276e-05}, {"id": 16, "seek": 12100, "start": 121.0, "end": 130.0, "text": " Create a big library that only has the exact functions that are being used, right, and nothing else.", "tokens": [20248, 257, 955, 6405, 300, 787, 575, 264, 1900, 6828, 300, 366, 885, 1143, 11, 558, 11, 293, 1825, 1646, 13], "temperature": 0.0, "avg_logprob": -0.22759919553189664, "compression_ratio": 1.5223880597014925, "no_speech_prob": 3.533066046657041e-05}, {"id": 17, "seek": 12100, "start": 130.0, "end": 139.0, "text": " So, we did that for embedded systems mostly so that you can have something a little smaller.", "tokens": [407, 11, 321, 630, 300, 337, 16741, 3652, 5240, 370, 300, 291, 393, 362, 746, 257, 707, 4356, 13], "temperature": 0.0, "avg_logprob": -0.22759919553189664, "compression_ratio": 1.5223880597014925, "no_speech_prob": 3.533066046657041e-05}, {"id": 18, "seek": 12100, "start": 139.0, "end": 145.0, "text": " Another area, and there has been quite a lot of excitement in this terminal the last couple of years, is WebRTC.", "tokens": [3996, 1859, 11, 293, 456, 575, 668, 1596, 257, 688, 295, 14755, 294, 341, 14709, 264, 1036, 1916, 295, 924, 11, 307, 9573, 49, 18238, 13], "temperature": 0.0, "avg_logprob": -0.22759919553189664, "compression_ratio": 1.5223880597014925, "no_speech_prob": 3.533066046657041e-05}, {"id": 19, "seek": 14500, "start": 145.0, "end": 153.0, "text": " So, as probably all of you are familiar with, WebRTC is a way to send video and load it in SQL from browsers,", "tokens": [407, 11, 382, 1391, 439, 295, 291, 366, 4963, 365, 11, 9573, 49, 18238, 307, 257, 636, 281, 2845, 960, 293, 3677, 309, 294, 19200, 490, 36069, 11], "temperature": 0.0, "avg_logprob": -0.14539953024990587, "compression_ratio": 1.5898617511520738, "no_speech_prob": 7.831493712728843e-05}, {"id": 20, "seek": 14500, "start": 153.0, "end": 161.0, "text": " and Distributor has one of the most complete implementation outside of the Google implementation that's used by the browsers.", "tokens": [293, 9840, 2024, 22163, 575, 472, 295, 264, 881, 3566, 11420, 2380, 295, 264, 3329, 11420, 300, 311, 1143, 538, 264, 36069, 13], "temperature": 0.0, "avg_logprob": -0.14539953024990587, "compression_ratio": 1.5898617511520738, "no_speech_prob": 7.831493712728843e-05}, {"id": 21, "seek": 14500, "start": 161.0, "end": 170.0, "text": " We were missing one big bit, and that was the congestion control, and that's been added in the last releases.", "tokens": [492, 645, 5361, 472, 955, 857, 11, 293, 300, 390, 264, 40816, 1969, 11, 293, 300, 311, 668, 3869, 294, 264, 1036, 16952, 13], "temperature": 0.0, "avg_logprob": -0.14539953024990587, "compression_ratio": 1.5898617511520738, "no_speech_prob": 7.831493712728843e-05}, {"id": 22, "seek": 17000, "start": 170.0, "end": 178.0, "text": " So, now we have a module that is compatible with what's called Google congestion control, which is what Chrome and Firefox and Safari use.", "tokens": [407, 11, 586, 321, 362, 257, 10088, 300, 307, 18218, 365, 437, 311, 1219, 3329, 40816, 1969, 11, 597, 307, 437, 15327, 293, 46613, 293, 43820, 764, 13], "temperature": 0.0, "avg_logprob": -0.12290145255423882, "compression_ratio": 1.477832512315271, "no_speech_prob": 4.003419235232286e-05}, {"id": 23, "seek": 17000, "start": 178.0, "end": 180.0, "text": " And this is in Rust.", "tokens": [400, 341, 307, 294, 34952, 13], "temperature": 0.0, "avg_logprob": -0.12290145255423882, "compression_ratio": 1.477832512315271, "no_speech_prob": 4.003419235232286e-05}, {"id": 24, "seek": 17000, "start": 180.0, "end": 190.0, "text": " And to make that work, so we have a WebRTC implementation, but that did not do any of the actual encoding that was left separate on purpose.", "tokens": [400, 281, 652, 300, 589, 11, 370, 321, 362, 257, 9573, 49, 18238, 11420, 11, 457, 300, 630, 406, 360, 604, 295, 264, 3539, 43430, 300, 390, 1411, 4994, 322, 4334, 13], "temperature": 0.0, "avg_logprob": -0.12290145255423882, "compression_ratio": 1.477832512315271, "no_speech_prob": 4.003419235232286e-05}, {"id": 25, "seek": 19000, "start": 190.0, "end": 203.0, "text": " Now we have a module in Rust plug-in that will plug the encoder and the WebRTC and do the congestion control so that you can adapt the bitrate of the encoder to the encoding,", "tokens": [823, 321, 362, 257, 10088, 294, 34952, 5452, 12, 259, 300, 486, 5452, 264, 2058, 19866, 293, 264, 9573, 49, 18238, 293, 360, 264, 40816, 1969, 370, 300, 291, 393, 6231, 264, 857, 4404, 295, 264, 2058, 19866, 281, 264, 43430, 11], "temperature": 0.0, "avg_logprob": -0.1524640380359087, "compression_ratio": 1.5410958904109588, "no_speech_prob": 3.424468377488665e-05}, {"id": 26, "seek": 19000, "start": 203.0, "end": 208.0, "text": " and this is all automatic if you use this plug-in.", "tokens": [293, 341, 307, 439, 12509, 498, 291, 764, 341, 5452, 12, 259, 13], "temperature": 0.0, "avg_logprob": -0.1524640380359087, "compression_ratio": 1.5410958904109588, "no_speech_prob": 3.424468377488665e-05}, {"id": 27, "seek": 20800, "start": 208.0, "end": 220.0, "text": " We also have Web and Web, so these are also within Rust there. Web and Web are a way to replace RTMP, but based on WebRTC, so it's a single request,", "tokens": [492, 611, 362, 9573, 293, 9573, 11, 370, 613, 366, 611, 1951, 34952, 456, 13, 9573, 293, 9573, 366, 257, 636, 281, 7406, 21797, 12224, 11, 457, 2361, 322, 9573, 49, 18238, 11, 370, 309, 311, 257, 2167, 5308, 11], "temperature": 0.0, "avg_logprob": -0.1645944913228353, "compression_ratio": 1.626865671641791, "no_speech_prob": 7.13809349690564e-05}, {"id": 28, "seek": 20800, "start": 220.0, "end": 225.0, "text": " a single HTTP request way to set up a WebRTC stream.", "tokens": [257, 2167, 33283, 5308, 636, 281, 992, 493, 257, 9573, 49, 18238, 4309, 13], "temperature": 0.0, "avg_logprob": -0.1645944913228353, "compression_ratio": 1.626865671641791, "no_speech_prob": 7.13809349690564e-05}, {"id": 29, "seek": 20800, "start": 225.0, "end": 237.0, "text": " It's mostly meant to stream to and from a server, so it's really a replacement for RTMP for a low latency video transmission.", "tokens": [467, 311, 5240, 4140, 281, 4309, 281, 293, 490, 257, 7154, 11, 370, 309, 311, 534, 257, 14419, 337, 21797, 12224, 337, 257, 2295, 27043, 960, 11574, 13], "temperature": 0.0, "avg_logprob": -0.1645944913228353, "compression_ratio": 1.626865671641791, "no_speech_prob": 7.13809349690564e-05}, {"id": 30, "seek": 23700, "start": 237.0, "end": 245.0, "text": " Speaking of WebRTC, so WebRTC is based on RTMP, and this is an area where there's also been quite a bit of development.", "tokens": [13069, 295, 9573, 49, 18238, 11, 370, 9573, 49, 18238, 307, 2361, 322, 21797, 12224, 11, 293, 341, 307, 364, 1859, 689, 456, 311, 611, 668, 1596, 257, 857, 295, 3250, 13], "temperature": 0.0, "avg_logprob": -0.19993943753449814, "compression_ratio": 1.434065934065934, "no_speech_prob": 7.955891487654299e-05}, {"id": 31, "seek": 23700, "start": 245.0, "end": 261.0, "text": " So, starting with 222-1 order correction, that's a system used mostly for legacy broadcast transmission, and we have the 2D order correction.", "tokens": [407, 11, 2891, 365, 5853, 17, 12, 16, 1668, 19984, 11, 300, 311, 257, 1185, 1143, 5240, 337, 11711, 9975, 11574, 11, 293, 321, 362, 264, 568, 35, 1668, 19984, 13], "temperature": 0.0, "avg_logprob": -0.19993943753449814, "compression_ratio": 1.434065934065934, "no_speech_prob": 7.955891487654299e-05}, {"id": 32, "seek": 26100, "start": 261.0, "end": 269.0, "text": " So what does it mean 2D? It means that we do 4D order correction, which is basically, you absorb multiple packets, then you generate a new one,", "tokens": [407, 437, 775, 309, 914, 568, 35, 30, 467, 1355, 300, 321, 360, 1017, 35, 1668, 19984, 11, 597, 307, 1936, 11, 291, 15631, 3866, 30364, 11, 550, 291, 8460, 257, 777, 472, 11], "temperature": 0.0, "avg_logprob": -0.18118844985961913, "compression_ratio": 1.763157894736842, "no_speech_prob": 1.643875839363318e-05}, {"id": 33, "seek": 26100, "start": 269.0, "end": 276.0, "text": " and if you have any of these packets except one, then you can regenerate the missing one, right? That's what the parallel error correction is.", "tokens": [293, 498, 291, 362, 604, 295, 613, 30364, 3993, 472, 11, 550, 291, 393, 26358, 473, 264, 5361, 472, 11, 558, 30, 663, 311, 437, 264, 8952, 6713, 19984, 307, 13], "temperature": 0.0, "avg_logprob": -0.18118844985961913, "compression_ratio": 1.763157894736842, "no_speech_prob": 1.643875839363318e-05}, {"id": 34, "seek": 26100, "start": 276.0, "end": 281.0, "text": " Traditionally, you would do like packets one, two, and three, and four, and then you would generate a fifth packet.", "tokens": [22017, 15899, 11, 291, 576, 360, 411, 30364, 472, 11, 732, 11, 293, 1045, 11, 293, 1451, 11, 293, 550, 291, 576, 8460, 257, 9266, 20300, 13], "temperature": 0.0, "avg_logprob": -0.18118844985961913, "compression_ratio": 1.763157894736842, "no_speech_prob": 1.643875839363318e-05}, {"id": 35, "seek": 28100, "start": 281.0, "end": 292.0, "text": " What losses tend to come in bursts in networks? So with 2D error correction, we have this kind of traditional version, and also a version where you do packet one, and five, and ten, right?", "tokens": [708, 15352, 3928, 281, 808, 294, 41663, 294, 9590, 30, 407, 365, 568, 35, 6713, 19984, 11, 321, 362, 341, 733, 295, 5164, 3037, 11, 293, 611, 257, 3037, 689, 291, 360, 20300, 472, 11, 293, 1732, 11, 293, 2064, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.176319790869644, "compression_ratio": 1.5635593220338984, "no_speech_prob": 6.499722076114267e-05}, {"id": 36, "seek": 28100, "start": 292.0, "end": 299.0, "text": " So if you have a burst, you can recover more of the more packets.", "tokens": [407, 498, 291, 362, 257, 12712, 11, 291, 393, 8114, 544, 295, 264, 544, 30364, 13], "temperature": 0.0, "avg_logprob": -0.176319790869644, "compression_ratio": 1.5635593220338984, "no_speech_prob": 6.499722076114267e-05}, {"id": 37, "seek": 28100, "start": 299.0, "end": 305.0, "text": " The other thing that we've added, so just remember for a long time, we've had the API to add RTP-Ether extensions.", "tokens": [440, 661, 551, 300, 321, 600, 3869, 11, 370, 445, 1604, 337, 257, 938, 565, 11, 321, 600, 632, 264, 9362, 281, 909, 497, 16804, 12, 36, 616, 25129, 13], "temperature": 0.0, "avg_logprob": -0.176319790869644, "compression_ratio": 1.5635593220338984, "no_speech_prob": 6.499722076114267e-05}, {"id": 38, "seek": 30500, "start": 305.0, "end": 313.0, "text": " That's a way to each packet to add a little header with something else. So for a long time, we had libraries to actually write these,", "tokens": [663, 311, 257, 636, 281, 1184, 20300, 281, 909, 257, 707, 23117, 365, 746, 1646, 13, 407, 337, 257, 938, 565, 11, 321, 632, 15148, 281, 767, 2464, 613, 11], "temperature": 0.0, "avg_logprob": -0.13278286877800435, "compression_ratio": 1.7083333333333333, "no_speech_prob": 4.6787801693426445e-05}, {"id": 39, "seek": 30500, "start": 313.0, "end": 324.0, "text": " but we didn't have something in the system to easily plug in something to insert this header in every packet without having to write application code.", "tokens": [457, 321, 994, 380, 362, 746, 294, 264, 1185, 281, 3612, 5452, 294, 746, 281, 8969, 341, 23117, 294, 633, 20300, 1553, 1419, 281, 2464, 3861, 3089, 13], "temperature": 0.0, "avg_logprob": -0.13278286877800435, "compression_ratio": 1.7083333333333333, "no_speech_prob": 4.6787801693426445e-05}, {"id": 40, "seek": 30500, "start": 324.0, "end": 329.0, "text": " So this is something that we've added, and we've added a bunch of different modules.", "tokens": [407, 341, 307, 746, 300, 321, 600, 3869, 11, 293, 321, 600, 3869, 257, 3840, 295, 819, 16679, 13], "temperature": 0.0, "avg_logprob": -0.13278286877800435, "compression_ratio": 1.7083333333333333, "no_speech_prob": 4.6787801693426445e-05}, {"id": 41, "seek": 32900, "start": 329.0, "end": 339.0, "text": " The multiple is this client-to-mixer audio level. This makes it possible for a sender of audio to say the volume that I'm sending is this,", "tokens": [440, 3866, 307, 341, 6423, 12, 1353, 12, 76, 970, 260, 6278, 1496, 13, 639, 1669, 309, 1944, 337, 257, 2845, 260, 295, 6278, 281, 584, 264, 5523, 300, 286, 478, 7750, 307, 341, 11], "temperature": 0.0, "avg_logprob": -0.140130667850889, "compression_ratio": 1.5906976744186045, "no_speech_prob": 8.085834269877523e-05}, {"id": 42, "seek": 32900, "start": 339.0, "end": 347.0, "text": " so that a mixer or some kind of service can select the person who speaks loudest without having to decode all of the audio.", "tokens": [370, 300, 257, 24063, 420, 512, 733, 295, 2643, 393, 3048, 264, 954, 567, 10789, 6588, 377, 1553, 1419, 281, 979, 1429, 439, 295, 264, 6278, 13], "temperature": 0.0, "avg_logprob": -0.140130667850889, "compression_ratio": 1.5906976744186045, "no_speech_prob": 8.085834269877523e-05}, {"id": 43, "seek": 32900, "start": 347.0, "end": 354.0, "text": " So it can know from this level who's speaking louder and just forward that one.", "tokens": [407, 309, 393, 458, 490, 341, 1496, 567, 311, 4124, 22717, 293, 445, 2128, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.140130667850889, "compression_ratio": 1.5906976744186045, "no_speech_prob": 8.085834269877523e-05}, {"id": 44, "seek": 35400, "start": 354.0, "end": 368.0, "text": " Then, color space. So this is for VP9. If you want to send HDR over VP9, we now have this RTP-Ether extension to make it work.", "tokens": [1396, 11, 2017, 1901, 13, 407, 341, 307, 337, 35812, 24, 13, 759, 291, 528, 281, 2845, 29650, 670, 35812, 24, 11, 321, 586, 362, 341, 497, 16804, 12, 36, 616, 10320, 281, 652, 309, 589, 13], "temperature": 0.0, "avg_logprob": -0.23832332844636878, "compression_ratio": 1.4698795180722892, "no_speech_prob": 0.00014610089419875294}, {"id": 45, "seek": 35400, "start": 368.0, "end": 372.0, "text": " It's compatible with Chrome again, so this is a phase-on-article experiment.", "tokens": [467, 311, 18218, 365, 15327, 797, 11, 370, 341, 307, 257, 5574, 12, 266, 12, 446, 3520, 5120, 13], "temperature": 0.0, "avg_logprob": -0.23832332844636878, "compression_ratio": 1.4698795180722892, "no_speech_prob": 0.00014610089419875294}, {"id": 46, "seek": 35400, "start": 372.0, "end": 383.0, "text": " And we have an AD1 builder and deep builder, so this is, I think, probably the first thing where we've decided that the official implementation of a major feature", "tokens": [400, 321, 362, 364, 9135, 16, 27377, 293, 2452, 27377, 11, 370, 341, 307, 11, 286, 519, 11, 1391, 264, 700, 551, 689, 321, 600, 3047, 300, 264, 4783, 11420, 295, 257, 2563, 4111], "temperature": 0.0, "avg_logprob": -0.23832332844636878, "compression_ratio": 1.4698795180722892, "no_speech_prob": 0.00014610089419875294}, {"id": 47, "seek": 38300, "start": 383.0, "end": 389.0, "text": " is only available in Rust. So this is something that we're pretty happy about.", "tokens": [307, 787, 2435, 294, 34952, 13, 407, 341, 307, 746, 300, 321, 434, 1238, 2055, 466, 13], "temperature": 0.0, "avg_logprob": -0.13277521441059728, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.00010218118404736742}, {"id": 48, "seek": 38300, "start": 389.0, "end": 394.0, "text": " Another thing, so H264, H265, they have two kinds of timestamp.", "tokens": [3996, 551, 11, 370, 389, 10880, 19, 11, 389, 10880, 20, 11, 436, 362, 732, 3685, 295, 49108, 1215, 13], "temperature": 0.0, "avg_logprob": -0.13277521441059728, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.00010218118404736742}, {"id": 49, "seek": 38300, "start": 394.0, "end": 401.0, "text": " Presentation timestamp, decoding timestamp. When you send RTP, normally only send a presentation timestamp.", "tokens": [33253, 399, 49108, 1215, 11, 979, 8616, 49108, 1215, 13, 1133, 291, 2845, 497, 16804, 11, 5646, 787, 2845, 257, 5860, 49108, 1215, 13], "temperature": 0.0, "avg_logprob": -0.13277521441059728, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.00010218118404736742}, {"id": 50, "seek": 38300, "start": 401.0, "end": 409.0, "text": " You need to apply an algorithm to recover the decoding timestamp. We now have modules that generate that.", "tokens": [509, 643, 281, 3079, 364, 9284, 281, 8114, 264, 979, 8616, 49108, 1215, 13, 492, 586, 362, 16679, 300, 8460, 300, 13], "temperature": 0.0, "avg_logprob": -0.13277521441059728, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.00010218118404736742}, {"id": 51, "seek": 40900, "start": 409.0, "end": 419.0, "text": " We also support RxC6651, so that's a way to synchronize streams immediately.", "tokens": [492, 611, 1406, 497, 87, 34, 21, 16824, 16, 11, 370, 300, 311, 257, 636, 281, 19331, 1125, 15842, 4258, 13], "temperature": 0.0, "avg_logprob": -0.1445449455497191, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.00010122585808858275}, {"id": 52, "seek": 40900, "start": 419.0, "end": 424.0, "text": " So traditionally with RTP, we send two streams, audio, video, separate timestamps,", "tokens": [407, 19067, 365, 497, 16804, 11, 321, 2845, 732, 15842, 11, 6278, 11, 960, 11, 4994, 49108, 23150, 11], "temperature": 0.0, "avg_logprob": -0.1445449455497191, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.00010122585808858275}, {"id": 53, "seek": 40900, "start": 424.0, "end": 428.0, "text": " and then sometimes later you get a packet telling you what the correspondence is.", "tokens": [293, 550, 2171, 1780, 291, 483, 257, 20300, 3585, 291, 437, 264, 38135, 307, 13], "temperature": 0.0, "avg_logprob": -0.1445449455497191, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.00010122585808858275}, {"id": 54, "seek": 40900, "start": 428.0, "end": 436.0, "text": " With RxC6651, we add the RTP-Ether extension in every packet so that we can be synchronized from the first packet.", "tokens": [2022, 497, 87, 34, 21, 16824, 16, 11, 321, 909, 264, 497, 16804, 12, 36, 616, 10320, 294, 633, 20300, 370, 300, 321, 393, 312, 19331, 1602, 490, 264, 700, 20300, 13], "temperature": 0.0, "avg_logprob": -0.1445449455497191, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.00010122585808858275}, {"id": 55, "seek": 43600, "start": 436.0, "end": 441.0, "text": " And we also improve our base class for video decoders a bit.", "tokens": [400, 321, 611, 3470, 527, 3096, 1508, 337, 960, 979, 378, 433, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.13676318316392497, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.00012504885671660304}, {"id": 56, "seek": 43600, "start": 441.0, "end": 452.0, "text": " So now it can recognize that there's a corruption and use that to request a retransmission previously.", "tokens": [407, 586, 309, 393, 5521, 300, 456, 311, 257, 17959, 293, 764, 300, 281, 5308, 257, 23106, 599, 29797, 8046, 13], "temperature": 0.0, "avg_logprob": -0.13676318316392497, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.00012504885671660304}, {"id": 57, "seek": 43600, "start": 452.0, "end": 458.0, "text": " We kind of applied the error, but we let the application do the decision.", "tokens": [492, 733, 295, 6456, 264, 6713, 11, 457, 321, 718, 264, 3861, 360, 264, 3537, 13], "temperature": 0.0, "avg_logprob": -0.13676318316392497, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.00012504885671660304}, {"id": 58, "seek": 45800, "start": 458.0, "end": 466.0, "text": " Now we've added something to the base class.", "tokens": [823, 321, 600, 3869, 746, 281, 264, 3096, 1508, 13], "temperature": 0.0, "avg_logprob": -0.13367112751664786, "compression_ratio": 1.434782608695652, "no_speech_prob": 3.7568763218587264e-05}, {"id": 59, "seek": 45800, "start": 466.0, "end": 474.0, "text": " Another big feature that was worked on is that we basically rewrote the HLS and dash base class.", "tokens": [3996, 955, 4111, 300, 390, 2732, 322, 307, 300, 321, 1936, 319, 7449, 1370, 264, 389, 19198, 293, 8240, 3096, 1508, 13], "temperature": 0.0, "avg_logprob": -0.13367112751664786, "compression_ratio": 1.434782608695652, "no_speech_prob": 3.7568763218587264e-05}, {"id": 60, "seek": 45800, "start": 474.0, "end": 482.0, "text": " So the previous one was over 10 years old and had been written largely without the specs.", "tokens": [407, 264, 3894, 472, 390, 670, 1266, 924, 1331, 293, 632, 668, 3720, 11611, 1553, 264, 27911, 13], "temperature": 0.0, "avg_logprob": -0.13367112751664786, "compression_ratio": 1.434782608695652, "no_speech_prob": 3.7568763218587264e-05}, {"id": 61, "seek": 48200, "start": 482.0, "end": 488.0, "text": " And even when we had the specs, HLS has changed quite a lot over the last 10 years.", "tokens": [400, 754, 562, 321, 632, 264, 27911, 11, 389, 19198, 575, 3105, 1596, 257, 688, 670, 264, 1036, 1266, 924, 13], "temperature": 0.0, "avg_logprob": -0.14168070458077095, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.00011549118789844215}, {"id": 62, "seek": 48200, "start": 488.0, "end": 497.0, "text": " So now we have almost a state-of-the-art implementation based on 10 years more knowledge.", "tokens": [407, 586, 321, 362, 1920, 257, 1785, 12, 2670, 12, 3322, 12, 446, 11420, 2361, 322, 1266, 924, 544, 3601, 13], "temperature": 0.0, "avg_logprob": -0.14168070458077095, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.00011549118789844215}, {"id": 63, "seek": 48200, "start": 497.0, "end": 505.0, "text": " It's much more simple, has fewer trends, much better control on how we download things, on the buffering.", "tokens": [467, 311, 709, 544, 2199, 11, 575, 13366, 13892, 11, 709, 1101, 1969, 322, 577, 321, 5484, 721, 11, 322, 264, 9204, 1794, 13], "temperature": 0.0, "avg_logprob": -0.14168070458077095, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.00011549118789844215}, {"id": 64, "seek": 50500, "start": 505.0, "end": 513.0, "text": " We do a little bit of the parsing in there because sadly for many of these for us, you have to parse the base stream to handle it properly.", "tokens": [492, 360, 257, 707, 857, 295, 264, 21156, 278, 294, 456, 570, 22023, 337, 867, 295, 613, 337, 505, 11, 291, 362, 281, 48377, 264, 3096, 4309, 281, 4813, 309, 6108, 13], "temperature": 0.0, "avg_logprob": -0.15461264716254342, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.00011038663069484755}, {"id": 65, "seek": 50500, "start": 513.0, "end": 521.0, "text": " So this is all implemented as one in this decade.", "tokens": [407, 341, 307, 439, 12270, 382, 472, 294, 341, 10378, 13], "temperature": 0.0, "avg_logprob": -0.15461264716254342, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.00011038663069484755}, {"id": 66, "seek": 50500, "start": 521.0, "end": 525.0, "text": " We've put a few things around decoding, mostly video decoding.", "tokens": [492, 600, 829, 257, 1326, 721, 926, 979, 8616, 11, 5240, 960, 979, 8616, 13], "temperature": 0.0, "avg_logprob": -0.15461264716254342, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.00011038663069484755}, {"id": 67, "seek": 50500, "start": 525.0, "end": 530.0, "text": " One thing I'm quite excited about is the subframe decoding that has been quite a few years coming.", "tokens": [1485, 551, 286, 478, 1596, 2919, 466, 307, 264, 1422, 17265, 979, 8616, 300, 575, 668, 1596, 257, 1326, 924, 1348, 13], "temperature": 0.0, "avg_logprob": -0.15461264716254342, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.00011038663069484755}, {"id": 68, "seek": 53000, "start": 530.0, "end": 539.0, "text": " And this means that we now have infrastructure in our base classes to start decoding a frame before you receive the entire frame.", "tokens": [400, 341, 1355, 300, 321, 586, 362, 6896, 294, 527, 3096, 5359, 281, 722, 979, 8616, 257, 3920, 949, 291, 4774, 264, 2302, 3920, 13], "temperature": 0.0, "avg_logprob": -0.2101714201647826, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.00012328273442108184}, {"id": 69, "seek": 53000, "start": 539.0, "end": 545.0, "text": " Some format, issue 6.46.5, we can split the frame in slices.", "tokens": [2188, 7877, 11, 2734, 1386, 13, 16169, 13, 20, 11, 321, 393, 7472, 264, 3920, 294, 19793, 13], "temperature": 0.0, "avg_logprob": -0.2101714201647826, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.00012328273442108184}, {"id": 70, "seek": 53000, "start": 545.0, "end": 550.0, "text": " And from this first now, you can actually start doing the decoding.", "tokens": [400, 490, 341, 700, 586, 11, 291, 393, 767, 722, 884, 264, 979, 8616, 13], "temperature": 0.0, "avg_logprob": -0.2101714201647826, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.00012328273442108184}, {"id": 71, "seek": 53000, "start": 550.0, "end": 552.0, "text": " We have two implementations of this.", "tokens": [492, 362, 732, 4445, 763, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.2101714201647826, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.00012328273442108184}, {"id": 72, "seek": 53000, "start": 552.0, "end": 557.0, "text": " One is based on HPEG, which can do this only for issue 6.46.4.", "tokens": [1485, 307, 2361, 322, 389, 5208, 38, 11, 597, 393, 360, 341, 787, 337, 2734, 1386, 13, 16169, 13, 19, 13], "temperature": 0.0, "avg_logprob": -0.2101714201647826, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.00012328273442108184}, {"id": 73, "seek": 55700, "start": 557.0, "end": 562.0, "text": " And the other one is for the exiling hardware because they have the hardware features to do that.", "tokens": [400, 264, 661, 472, 307, 337, 264, 454, 4883, 8837, 570, 436, 362, 264, 8837, 4122, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.13721894224484762, "compression_ratio": 1.609442060085837, "no_speech_prob": 5.383748430176638e-05}, {"id": 74, "seek": 55700, "start": 562.0, "end": 567.0, "text": " So they can do super low latency decoding.", "tokens": [407, 436, 393, 360, 1687, 2295, 27043, 979, 8616, 13], "temperature": 0.0, "avg_logprob": -0.13721894224484762, "compression_ratio": 1.609442060085837, "no_speech_prob": 5.383748430176638e-05}, {"id": 75, "seek": 55700, "start": 567.0, "end": 570.0, "text": " We have WebM Alpha.", "tokens": [492, 362, 9573, 44, 20588, 13], "temperature": 0.0, "avg_logprob": -0.13721894224484762, "compression_ratio": 1.609442060085837, "no_speech_prob": 5.383748430176638e-05}, {"id": 76, "seek": 55700, "start": 570.0, "end": 576.0, "text": " So the WebM format, so HPEG tonight don't have support for transparency built in.", "tokens": [407, 264, 9573, 44, 7877, 11, 370, 389, 5208, 38, 4440, 500, 380, 362, 1406, 337, 17131, 3094, 294, 13], "temperature": 0.0, "avg_logprob": -0.13721894224484762, "compression_ratio": 1.609442060085837, "no_speech_prob": 5.383748430176638e-05}, {"id": 77, "seek": 55700, "start": 576.0, "end": 582.0, "text": " But there's a WebM extension where we basically store two separate video streams.", "tokens": [583, 456, 311, 257, 9573, 44, 10320, 689, 321, 1936, 3531, 732, 4994, 960, 15842, 13], "temperature": 0.0, "avg_logprob": -0.13721894224484762, "compression_ratio": 1.609442060085837, "no_speech_prob": 5.383748430176638e-05}, {"id": 78, "seek": 55700, "start": 582.0, "end": 585.0, "text": " One with the colors and one with the transparency.", "tokens": [1485, 365, 264, 4577, 293, 472, 365, 264, 17131, 13], "temperature": 0.0, "avg_logprob": -0.13721894224484762, "compression_ratio": 1.609442060085837, "no_speech_prob": 5.383748430176638e-05}, {"id": 79, "seek": 58500, "start": 585.0, "end": 594.0, "text": " And now we have an element that will spin up two decoders and then recombine them into a A1B stream.", "tokens": [400, 586, 321, 362, 364, 4478, 300, 486, 6060, 493, 732, 979, 378, 433, 293, 550, 850, 3548, 533, 552, 666, 257, 316, 16, 33, 4309, 13], "temperature": 0.0, "avg_logprob": -0.21635441965871044, "compression_ratio": 1.492063492063492, "no_speech_prob": 9.017411503009498e-05}, {"id": 80, "seek": 58500, "start": 594.0, "end": 597.0, "text": " We have a DirectX Elevent library.", "tokens": [492, 362, 257, 18308, 55, 8024, 2475, 6405, 13], "temperature": 0.0, "avg_logprob": -0.21635441965871044, "compression_ratio": 1.492063492063492, "no_speech_prob": 9.017411503009498e-05}, {"id": 81, "seek": 58500, "start": 597.0, "end": 605.0, "text": " So make it easier to integrate Direct 3D Elevent applications in the streamer to do zero copy and coding.", "tokens": [407, 652, 309, 3571, 281, 13365, 18308, 805, 35, 8024, 2475, 5821, 294, 264, 4309, 260, 281, 360, 4018, 5055, 293, 17720, 13], "temperature": 0.0, "avg_logprob": -0.21635441965871044, "compression_ratio": 1.492063492063492, "no_speech_prob": 9.017411503009498e-05}, {"id": 82, "seek": 58500, "start": 605.0, "end": 609.0, "text": " For example, from a Windows application.", "tokens": [1171, 1365, 11, 490, 257, 8591, 3861, 13], "temperature": 0.0, "avg_logprob": -0.21635441965871044, "compression_ratio": 1.492063492063492, "no_speech_prob": 9.017411503009498e-05}, {"id": 83, "seek": 60900, "start": 609.0, "end": 616.0, "text": " And also speaking of Windows, our Direct 3D Elevent decoders are now default.", "tokens": [400, 611, 4124, 295, 8591, 11, 527, 18308, 805, 35, 8024, 2475, 979, 378, 433, 366, 586, 7576, 13], "temperature": 0.0, "avg_logprob": -0.2560657262802124, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0020442011300474405}, {"id": 84, "seek": 60900, "start": 616.0, "end": 621.0, "text": " So they're becoming the choice that will get auto plugged if you have them.", "tokens": [407, 436, 434, 5617, 264, 3922, 300, 486, 483, 8399, 25679, 498, 291, 362, 552, 13], "temperature": 0.0, "avg_logprob": -0.2560657262802124, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0020442011300474405}, {"id": 85, "seek": 60900, "start": 621.0, "end": 627.0, "text": " So you get hardware accelerator decoding on Windows. That works.", "tokens": [407, 291, 483, 8837, 39889, 979, 8616, 322, 8591, 13, 663, 1985, 13], "temperature": 0.0, "avg_logprob": -0.2560657262802124, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0020442011300474405}, {"id": 86, "seek": 60900, "start": 627.0, "end": 630.0, "text": " What about MacBooks?", "tokens": [708, 466, 31737, 82, 30], "temperature": 0.0, "avg_logprob": -0.2560657262802124, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0020442011300474405}, {"id": 87, "seek": 60900, "start": 630.0, "end": 632.0, "text": " Yes, there's also...", "tokens": [1079, 11, 456, 311, 611, 485], "temperature": 0.0, "avg_logprob": -0.2560657262802124, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0020442011300474405}, {"id": 88, "seek": 60900, "start": 632.0, "end": 634.0, "text": " We've got a question already.", "tokens": [492, 600, 658, 257, 1168, 1217, 13], "temperature": 0.0, "avg_logprob": -0.2560657262802124, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0020442011300474405}, {"id": 89, "seek": 63400, "start": 634.0, "end": 642.0, "text": " So we have a hardware decoder from Mac and IOS, which is the same idea.", "tokens": [407, 321, 362, 257, 8837, 979, 19866, 490, 5707, 293, 286, 4367, 11, 597, 307, 264, 912, 1558, 13], "temperature": 0.0, "avg_logprob": -0.2507825799890467, "compression_ratio": 1.510752688172043, "no_speech_prob": 0.00031853289692662656}, {"id": 90, "seek": 63400, "start": 642.0, "end": 648.0, "text": " CUDA, so some people use proprietary software and proprietary drivers.", "tokens": [29777, 7509, 11, 370, 512, 561, 764, 38992, 4722, 293, 38992, 11590, 13], "temperature": 0.0, "avg_logprob": -0.2507825799890467, "compression_ratio": 1.510752688172043, "no_speech_prob": 0.00031853289692662656}, {"id": 91, "seek": 63400, "start": 648.0, "end": 657.0, "text": " So we have now also a CUDA library so that you can insert more easily CUDA data into the streamer for encoding,", "tokens": [407, 321, 362, 586, 611, 257, 29777, 7509, 6405, 370, 300, 291, 393, 8969, 544, 3612, 29777, 7509, 1412, 666, 264, 4309, 260, 337, 43430, 11], "temperature": 0.0, "avg_logprob": -0.2507825799890467, "compression_ratio": 1.510752688172043, "no_speech_prob": 0.00031853289692662656}, {"id": 92, "seek": 63400, "start": 657.0, "end": 660.0, "text": " decoding all these things.", "tokens": [979, 8616, 439, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.2507825799890467, "compression_ratio": 1.510752688172043, "no_speech_prob": 0.00031853289692662656}, {"id": 93, "seek": 66000, "start": 660.0, "end": 668.0, "text": " We have some more CUDA native elements, one that is a converter and a scaler, so using CUDA itself.", "tokens": [492, 362, 512, 544, 29777, 7509, 8470, 4959, 11, 472, 300, 307, 257, 33905, 293, 257, 15664, 260, 11, 370, 1228, 29777, 7509, 2564, 13], "temperature": 0.0, "avg_logprob": -0.11175181315495418, "compression_ratio": 1.4519230769230769, "no_speech_prob": 3.3178963349200785e-05}, {"id": 94, "seek": 66000, "start": 668.0, "end": 672.0, "text": " We have CUDA and Direct 3D integration for Windows again.", "tokens": [492, 362, 29777, 7509, 293, 18308, 805, 35, 10980, 337, 8591, 797, 13], "temperature": 0.0, "avg_logprob": -0.11175181315495418, "compression_ratio": 1.4519230769230769, "no_speech_prob": 3.3178963349200785e-05}, {"id": 95, "seek": 66000, "start": 672.0, "end": 679.0, "text": " And this whole thing basically gives you zero copy and coding on NVIDIA hardware,", "tokens": [400, 341, 1379, 551, 1936, 2709, 291, 4018, 5055, 293, 17720, 322, 426, 3958, 6914, 8837, 11], "temperature": 0.0, "avg_logprob": -0.11175181315495418, "compression_ratio": 1.4519230769230769, "no_speech_prob": 3.3178963349200785e-05}, {"id": 96, "seek": 66000, "start": 679.0, "end": 685.0, "text": " especially when you match with some other CUDA-based software.", "tokens": [2318, 562, 291, 2995, 365, 512, 661, 29777, 7509, 12, 6032, 4722, 13], "temperature": 0.0, "avg_logprob": -0.11175181315495418, "compression_ratio": 1.4519230769230769, "no_speech_prob": 3.3178963349200785e-05}, {"id": 97, "seek": 68500, "start": 685.0, "end": 692.0, "text": " But some people prefer free software. So we also have BAPI, we have a new plugin for BAPI.", "tokens": [583, 512, 561, 4382, 1737, 4722, 13, 407, 321, 611, 362, 363, 4715, 40, 11, 321, 362, 257, 777, 23407, 337, 363, 4715, 40, 13], "temperature": 0.0, "avg_logprob": -0.1932589610417684, "compression_ratio": 1.5471698113207548, "no_speech_prob": 5.555147799896076e-05}, {"id": 98, "seek": 68500, "start": 692.0, "end": 696.0, "text": " So we've had G-SUMOR BAPI for a long, long time.", "tokens": [407, 321, 600, 632, 460, 12, 50, 14340, 2483, 363, 4715, 40, 337, 257, 938, 11, 938, 565, 13], "temperature": 0.0, "avg_logprob": -0.1932589610417684, "compression_ratio": 1.5471698113207548, "no_speech_prob": 5.555147799896076e-05}, {"id": 99, "seek": 68500, "start": 696.0, "end": 704.0, "text": " It was getting quite freaky. It was not based on any of the base classes that we have improved since then.", "tokens": [467, 390, 1242, 1596, 2130, 15681, 13, 467, 390, 406, 2361, 322, 604, 295, 264, 3096, 5359, 300, 321, 362, 9689, 1670, 550, 13], "temperature": 0.0, "avg_logprob": -0.1932589610417684, "compression_ratio": 1.5471698113207548, "no_speech_prob": 5.555147799896076e-05}, {"id": 100, "seek": 68500, "start": 704.0, "end": 711.0, "text": " So it's been completely rewritten from scratch with a new plugin that we call VA.", "tokens": [407, 309, 311, 668, 2584, 319, 26859, 490, 8459, 365, 257, 777, 23407, 300, 321, 818, 18527, 13], "temperature": 0.0, "avg_logprob": -0.1932589610417684, "compression_ratio": 1.5471698113207548, "no_speech_prob": 5.555147799896076e-05}, {"id": 101, "seek": 71100, "start": 711.0, "end": 715.0, "text": " It supports all the major codecs now that we've implemented, all the ones with VA.", "tokens": [467, 9346, 439, 264, 2563, 3089, 14368, 586, 300, 321, 600, 12270, 11, 439, 264, 2306, 365, 18527, 13], "temperature": 0.0, "avg_logprob": -0.3174542263821439, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.0002596885315142572}, {"id": 102, "seek": 71100, "start": 715.0, "end": 720.0, "text": " It supports AVY, it supports just 5, VPA, between 9 and 8, MPEG-2.", "tokens": [467, 9346, 30198, 56, 11, 309, 9346, 445, 1025, 11, 691, 10297, 11, 1296, 1722, 293, 1649, 11, 376, 5208, 38, 12, 17, 13], "temperature": 0.0, "avg_logprob": -0.3174542263821439, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.0002596885315142572}, {"id": 103, "seek": 71100, "start": 720.0, "end": 729.0, "text": " Encoding, we only have the issue 6, 4, 5 codecs for now, but the rest are being worked on, as we speak.", "tokens": [29584, 8616, 11, 321, 787, 362, 264, 2734, 1386, 11, 1017, 11, 1025, 3089, 14368, 337, 586, 11, 457, 264, 1472, 366, 885, 2732, 322, 11, 382, 321, 1710, 13], "temperature": 0.0, "avg_logprob": -0.3174542263821439, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.0002596885315142572}, {"id": 104, "seek": 71100, "start": 729.0, "end": 734.0, "text": " And using live VA, we have a bit more than VA.", "tokens": [400, 1228, 1621, 18527, 11, 321, 362, 257, 857, 544, 813, 18527, 13], "temperature": 0.0, "avg_logprob": -0.3174542263821439, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.0002596885315142572}, {"id": 105, "seek": 71100, "start": 734.0, "end": 738.0, "text": " We have a bit more features. We have a compositor.", "tokens": [492, 362, 257, 857, 544, 4122, 13, 492, 362, 257, 10199, 3029, 13], "temperature": 0.0, "avg_logprob": -0.3174542263821439, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.0002596885315142572}, {"id": 106, "seek": 73800, "start": 738.0, "end": 744.0, "text": " It's an element that will take two or more streams and composite them into the same video.", "tokens": [467, 311, 364, 4478, 300, 486, 747, 732, 420, 544, 15842, 293, 25557, 552, 666, 264, 912, 960, 13], "temperature": 0.0, "avg_logprob": -0.29446357634009385, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.000435850175563246}, {"id": 107, "seek": 73800, "start": 744.0, "end": 747.0, "text": " We have a D-interlacer.", "tokens": [492, 362, 257, 413, 12, 5106, 75, 12858, 13], "temperature": 0.0, "avg_logprob": -0.29446357634009385, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.000435850175563246}, {"id": 108, "seek": 73800, "start": 747.0, "end": 753.0, "text": " And we have a post-processor element with scaling and color space conversion,", "tokens": [400, 321, 362, 257, 2183, 12, 4318, 25432, 4478, 365, 21589, 293, 2017, 1901, 14298, 11], "temperature": 0.0, "avg_logprob": -0.29446357634009385, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.000435850175563246}, {"id": 109, "seek": 73800, "start": 753.0, "end": 762.0, "text": " using the video functionality instead of the GPU.", "tokens": [1228, 264, 960, 14980, 2602, 295, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.29446357634009385, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.000435850175563246}, {"id": 110, "seek": 73800, "start": 762.0, "end": 767.0, "text": " And open work has happened around 8 to 1 or something in the last two years.", "tokens": [400, 1269, 589, 575, 2011, 926, 1649, 281, 502, 420, 746, 294, 264, 1036, 732, 924, 13], "temperature": 0.0, "avg_logprob": -0.29446357634009385, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.000435850175563246}, {"id": 111, "seek": 76700, "start": 767.0, "end": 769.0, "text": " So we have quite a lot now.", "tokens": [407, 321, 362, 1596, 257, 688, 586, 13], "temperature": 0.0, "avg_logprob": -0.2530338867850926, "compression_ratio": 1.541899441340782, "no_speech_prob": 9.579556353855878e-05}, {"id": 112, "seek": 76700, "start": 769.0, "end": 776.0, "text": " We have support for AV1, both in the legacy VA plugin and in the new VA plugin.", "tokens": [492, 362, 1406, 337, 30198, 16, 11, 1293, 294, 264, 11711, 18527, 23407, 293, 294, 264, 777, 18527, 23407, 13], "temperature": 0.0, "avg_logprob": -0.2530338867850926, "compression_ratio": 1.541899441340782, "no_speech_prob": 9.579556353855878e-05}, {"id": 113, "seek": 76700, "start": 776.0, "end": 779.0, "text": " We have it for AMD, the coders.", "tokens": [492, 362, 309, 337, 34808, 11, 264, 17656, 433, 13], "temperature": 0.0, "avg_logprob": -0.2530338867850926, "compression_ratio": 1.541899441340782, "no_speech_prob": 9.579556353855878e-05}, {"id": 114, "seek": 76700, "start": 779.0, "end": 786.0, "text": " We have it for Direct3D on Windows, using the NVDI-PI's.", "tokens": [492, 362, 309, 337, 18308, 18, 35, 322, 8591, 11, 1228, 264, 46512, 3085, 12, 31701, 311, 13], "temperature": 0.0, "avg_logprob": -0.2530338867850926, "compression_ratio": 1.541899441340782, "no_speech_prob": 9.579556353855878e-05}, {"id": 115, "seek": 76700, "start": 786.0, "end": 792.0, "text": " For Intel, using their multiple libraries, either Quixin, QSV, or the new VSDK.", "tokens": [1171, 19762, 11, 1228, 641, 3866, 15148, 11, 2139, 2326, 970, 259, 11, 1249, 50, 53, 11, 420, 264, 777, 25091, 35, 42, 13], "temperature": 0.0, "avg_logprob": -0.2530338867850926, "compression_ratio": 1.541899441340782, "no_speech_prob": 9.579556353855878e-05}, {"id": 116, "seek": 79200, "start": 792.0, "end": 800.0, "text": " So we have pretty comprehensive AV1 support, in addition to the RTB plugin that I mentioned earlier.", "tokens": [407, 321, 362, 1238, 13914, 30198, 16, 1406, 11, 294, 4500, 281, 264, 21797, 33, 23407, 300, 286, 2835, 3071, 13], "temperature": 0.0, "avg_logprob": -0.19599934547178208, "compression_ratio": 1.4090909090909092, "no_speech_prob": 6.694444891763851e-05}, {"id": 117, "seek": 79200, "start": 800.0, "end": 809.0, "text": " Another new thing that we've done is, this is our first official machine learning integration that is in G-streamer itself.", "tokens": [3996, 777, 551, 300, 321, 600, 1096, 307, 11, 341, 307, 527, 700, 4783, 3479, 2539, 10980, 300, 307, 294, 460, 12, 9291, 260, 2564, 13], "temperature": 0.0, "avg_logprob": -0.19599934547178208, "compression_ratio": 1.4090909090909092, "no_speech_prob": 6.694444891763851e-05}, {"id": 118, "seek": 79200, "start": 809.0, "end": 811.0, "text": " So it's the first step.", "tokens": [407, 309, 311, 264, 700, 1823, 13], "temperature": 0.0, "avg_logprob": -0.19599934547178208, "compression_ratio": 1.4090909090909092, "no_speech_prob": 6.694444891763851e-05}, {"id": 119, "seek": 81100, "start": 811.0, "end": 824.0, "text": " And we've written a plugin to use the Onyx runtime from Microsoft to basically take some video frames,", "tokens": [400, 321, 600, 3720, 257, 23407, 281, 764, 264, 1282, 88, 87, 34474, 490, 8116, 281, 1936, 747, 512, 960, 12083, 11], "temperature": 0.0, "avg_logprob": -0.10692413782669326, "compression_ratio": 1.447674418604651, "no_speech_prob": 3.9914852095535025e-05}, {"id": 120, "seek": 81100, "start": 824.0, "end": 833.0, "text": " some model and recognize objects, put little boxes in the metadata,", "tokens": [512, 2316, 293, 5521, 6565, 11, 829, 707, 9002, 294, 264, 26603, 11], "temperature": 0.0, "avg_logprob": -0.10692413782669326, "compression_ratio": 1.447674418604651, "no_speech_prob": 3.9914852095535025e-05}, {"id": 121, "seek": 81100, "start": 833.0, "end": 838.0, "text": " and then another element that can take these boxes and draw them on the image.", "tokens": [293, 550, 1071, 4478, 300, 393, 747, 613, 9002, 293, 2642, 552, 322, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.10692413782669326, "compression_ratio": 1.447674418604651, "no_speech_prob": 3.9914852095535025e-05}, {"id": 122, "seek": 83800, "start": 838.0, "end": 848.0, "text": " So this is the first step. A lot of work is happening right now to have a better video on the fixed framework as part of G-streamer.", "tokens": [407, 341, 307, 264, 700, 1823, 13, 316, 688, 295, 589, 307, 2737, 558, 586, 281, 362, 257, 1101, 960, 322, 264, 6806, 8388, 382, 644, 295, 460, 12, 9291, 260, 13], "temperature": 0.0, "avg_logprob": -0.22286062240600585, "compression_ratio": 1.4328358208955223, "no_speech_prob": 8.343264198629186e-05}, {"id": 123, "seek": 83800, "start": 848.0, "end": 854.0, "text": " All these things I like about sometimes you want to have a UI.", "tokens": [1057, 613, 721, 286, 411, 466, 2171, 291, 528, 281, 362, 257, 15682, 13], "temperature": 0.0, "avg_logprob": -0.22286062240600585, "compression_ratio": 1.4328358208955223, "no_speech_prob": 8.343264198629186e-05}, {"id": 124, "seek": 83800, "start": 854.0, "end": 858.0, "text": " And a few pictures were recently added there.", "tokens": [400, 257, 1326, 5242, 645, 3938, 3869, 456, 13], "temperature": 0.0, "avg_logprob": -0.22286062240600585, "compression_ratio": 1.4328358208955223, "no_speech_prob": 8.343264198629186e-05}, {"id": 125, "seek": 83800, "start": 858.0, "end": 863.0, "text": " We have a GTK4 paintable, so that's an object.", "tokens": [492, 362, 257, 17530, 42, 19, 4225, 712, 11, 370, 300, 311, 364, 2657, 13], "temperature": 0.0, "avg_logprob": -0.22286062240600585, "compression_ratio": 1.4328358208955223, "no_speech_prob": 8.343264198629186e-05}, {"id": 126, "seek": 86300, "start": 863.0, "end": 868.0, "text": " I would say that you can use the GTK4 to actually draw something on the screen.", "tokens": [286, 576, 584, 300, 291, 393, 764, 264, 17530, 42, 19, 281, 767, 2642, 746, 322, 264, 2568, 13], "temperature": 0.0, "avg_logprob": -0.16531506522757108, "compression_ratio": 1.7235772357723578, "no_speech_prob": 6.916972051840276e-05}, {"id": 127, "seek": 86300, "start": 868.0, "end": 875.0, "text": " So now you can easily integrate G-streamer with GTK4 to your old copy playback.", "tokens": [407, 586, 291, 393, 3612, 13365, 460, 12, 9291, 260, 365, 17530, 42, 19, 281, 428, 1331, 5055, 37223, 13], "temperature": 0.0, "avg_logprob": -0.16531506522757108, "compression_ratio": 1.7235772357723578, "no_speech_prob": 6.916972051840276e-05}, {"id": 128, "seek": 86300, "start": 875.0, "end": 878.0, "text": " This one is in Rust, which is kind of cool.", "tokens": [639, 472, 307, 294, 34952, 11, 597, 307, 733, 295, 1627, 13], "temperature": 0.0, "avg_logprob": -0.16531506522757108, "compression_ratio": 1.7235772357723578, "no_speech_prob": 6.916972051840276e-05}, {"id": 129, "seek": 86300, "start": 878.0, "end": 884.0, "text": " Qt6 as well as that thing, so that we have something that is very similar to what we have for Qt5, which is a QML item,", "tokens": [1249, 83, 21, 382, 731, 382, 300, 551, 11, 370, 300, 321, 362, 746, 300, 307, 588, 2531, 281, 437, 321, 362, 337, 1249, 83, 20, 11, 597, 307, 257, 1249, 12683, 3174, 11], "temperature": 0.0, "avg_logprob": -0.16531506522757108, "compression_ratio": 1.7235772357723578, "no_speech_prob": 6.916972051840276e-05}, {"id": 130, "seek": 86300, "start": 884.0, "end": 892.0, "text": " so that you can integrate a G-streamer sync with the output with Qt and draw in your Qt application.", "tokens": [370, 300, 291, 393, 13365, 257, 460, 12, 9291, 260, 20271, 365, 264, 5598, 365, 1249, 83, 293, 2642, 294, 428, 1249, 83, 3861, 13], "temperature": 0.0, "avg_logprob": -0.16531506522757108, "compression_ratio": 1.7235772357723578, "no_speech_prob": 6.916972051840276e-05}, {"id": 131, "seek": 89200, "start": 892.0, "end": 897.0, "text": " And the last one is a niche case.", "tokens": [400, 264, 1036, 472, 307, 257, 19956, 1389, 13], "temperature": 0.0, "avg_logprob": -0.14567484174455916, "compression_ratio": 1.5233160621761659, "no_speech_prob": 6.810040940763429e-05}, {"id": 132, "seek": 89200, "start": 897.0, "end": 904.0, "text": " So we had a Wayland sync for a long time, and what this Wayland sync allows you to do is to basically take the video buffer", "tokens": [407, 321, 632, 257, 9558, 1661, 20271, 337, 257, 938, 565, 11, 293, 437, 341, 9558, 1661, 20271, 4045, 291, 281, 360, 307, 281, 1936, 747, 264, 960, 21762], "temperature": 0.0, "avg_logprob": -0.14567484174455916, "compression_ratio": 1.5233160621761659, "no_speech_prob": 6.810040940763429e-05}, {"id": 133, "seek": 89200, "start": 904.0, "end": 909.0, "text": " and give it to the Wayland compositor directly without going through the toolkit.", "tokens": [293, 976, 309, 281, 264, 9558, 1661, 10199, 3029, 3838, 1553, 516, 807, 264, 40167, 13], "temperature": 0.0, "avg_logprob": -0.14567484174455916, "compression_ratio": 1.5233160621761659, "no_speech_prob": 6.810040940763429e-05}, {"id": 134, "seek": 89200, "start": 909.0, "end": 914.0, "text": " So you can use the 2D hardware planes of the platform.", "tokens": [407, 291, 393, 764, 264, 568, 35, 8837, 14952, 295, 264, 3663, 13], "temperature": 0.0, "avg_logprob": -0.14567484174455916, "compression_ratio": 1.5233160621761659, "no_speech_prob": 6.810040940763429e-05}, {"id": 135, "seek": 91400, "start": 914.0, "end": 922.0, "text": " This is multi-use useful and embedded. It allows you to do things like greater performance, not use the GPU on embedded systems", "tokens": [639, 307, 4825, 12, 438, 4420, 293, 16741, 13, 467, 4045, 291, 281, 360, 721, 411, 5044, 3389, 11, 406, 764, 264, 18407, 322, 16741, 3652], "temperature": 0.0, "avg_logprob": -0.1659649827263572, "compression_ratio": 1.4744186046511627, "no_speech_prob": 6.602089706575498e-05}, {"id": 136, "seek": 91400, "start": 922.0, "end": 925.0, "text": " where the GPU might be too slow to jail.", "tokens": [689, 264, 18407, 1062, 312, 886, 2964, 281, 10511, 13], "temperature": 0.0, "avg_logprob": -0.1659649827263572, "compression_ratio": 1.4744186046511627, "no_speech_prob": 6.602089706575498e-05}, {"id": 137, "seek": 91400, "start": 925.0, "end": 935.0, "text": " Up to now, this all works fine, but you have to write a low level Wayland code, and that's non-trivial.", "tokens": [5858, 281, 586, 11, 341, 439, 1985, 2489, 11, 457, 291, 362, 281, 2464, 257, 2295, 1496, 9558, 1661, 3089, 11, 293, 300, 311, 2107, 12, 83, 470, 22640, 13], "temperature": 0.0, "avg_logprob": -0.1659649827263572, "compression_ratio": 1.4744186046511627, "no_speech_prob": 6.602089706575498e-05}, {"id": 138, "seek": 91400, "start": 935.0, "end": 939.0, "text": " So we've written a GTK widget that wraps up.", "tokens": [407, 321, 600, 3720, 257, 17530, 42, 34047, 300, 25831, 493, 13], "temperature": 0.0, "avg_logprob": -0.1659649827263572, "compression_ratio": 1.4744186046511627, "no_speech_prob": 6.602089706575498e-05}, {"id": 139, "seek": 93900, "start": 939.0, "end": 947.0, "text": " So now we can write your application GTK, just add the widget, and you get all of these performance benefits for free.", "tokens": [407, 586, 321, 393, 2464, 428, 3861, 17530, 42, 11, 445, 909, 264, 34047, 11, 293, 291, 483, 439, 295, 613, 3389, 5311, 337, 1737, 13], "temperature": 0.0, "avg_logprob": -0.14285016059875488, "compression_ratio": 1.6853448275862069, "no_speech_prob": 6.196687172632664e-05}, {"id": 140, "seek": 93900, "start": 947.0, "end": 954.0, "text": " Last but not least, in this category, we added touch event navigation.", "tokens": [5264, 457, 406, 1935, 11, 294, 341, 7719, 11, 321, 3869, 2557, 2280, 17346, 13], "temperature": 0.0, "avg_logprob": -0.14285016059875488, "compression_ratio": 1.6853448275862069, "no_speech_prob": 6.196687172632664e-05}, {"id": 141, "seek": 93900, "start": 954.0, "end": 959.0, "text": " So previously we had navigation, we could send letters, we could send mouse clicks,", "tokens": [407, 8046, 321, 632, 17346, 11, 321, 727, 2845, 7825, 11, 321, 727, 2845, 9719, 18521, 11], "temperature": 0.0, "avg_logprob": -0.14285016059875488, "compression_ratio": 1.6853448275862069, "no_speech_prob": 6.196687172632664e-05}, {"id": 142, "seek": 93900, "start": 959.0, "end": 966.0, "text": " but now we can also send touch events so that you can have elements in your pipeline that are controlled by the user,", "tokens": [457, 586, 321, 393, 611, 2845, 2557, 3931, 370, 300, 291, 393, 362, 4959, 294, 428, 15517, 300, 366, 10164, 538, 264, 4195, 11], "temperature": 0.0, "avg_logprob": -0.14285016059875488, "compression_ratio": 1.6853448275862069, "no_speech_prob": 6.196687172632664e-05}, {"id": 143, "seek": 96600, "start": 966.0, "end": 975.0, "text": " such as we have a Webbar app, a web view, a webkit-based source.", "tokens": [1270, 382, 321, 362, 257, 9573, 5356, 724, 11, 257, 3670, 1910, 11, 257, 3670, 22681, 12, 6032, 4009, 13], "temperature": 0.0, "avg_logprob": -0.2362419654583109, "compression_ratio": 1.5198019801980198, "no_speech_prob": 0.00015337398508563638}, {"id": 144, "seek": 96600, "start": 975.0, "end": 982.0, "text": " And we have some new tracers, so these are tools for developers to know actually what's going on in a pipeline live.", "tokens": [400, 321, 362, 512, 777, 504, 326, 433, 11, 370, 613, 366, 3873, 337, 8849, 281, 458, 767, 437, 311, 516, 322, 294, 257, 15517, 1621, 13], "temperature": 0.0, "avg_logprob": -0.2362419654583109, "compression_ratio": 1.5198019801980198, "no_speech_prob": 0.00015337398508563638}, {"id": 145, "seek": 96600, "start": 982.0, "end": 987.0, "text": " We have a bunch of tracers already, four more were added.", "tokens": [492, 362, 257, 3840, 295, 504, 326, 433, 1217, 11, 1451, 544, 645, 3869, 13], "temperature": 0.0, "avg_logprob": -0.2362419654583109, "compression_ratio": 1.5198019801980198, "no_speech_prob": 0.00015337398508563638}, {"id": 146, "seek": 96600, "start": 987.0, "end": 991.0, "text": " Some of them are quite useful, like we have one to generate buffer,", "tokens": [2188, 295, 552, 366, 1596, 4420, 11, 411, 321, 362, 472, 281, 8460, 21762, 11], "temperature": 0.0, "avg_logprob": -0.2362419654583109, "compression_ratio": 1.5198019801980198, "no_speech_prob": 0.00015337398508563638}, {"id": 147, "seek": 99100, "start": 991.0, "end": 998.0, "text": " to read the buffer lateness and one to trace the queue level, and these will output the information in a CSV file", "tokens": [281, 1401, 264, 21762, 4465, 15264, 293, 472, 281, 13508, 264, 18639, 1496, 11, 293, 613, 486, 5598, 264, 1589, 294, 257, 48814, 3991], "temperature": 0.0, "avg_logprob": -0.1559359394774145, "compression_ratio": 1.677685950413223, "no_speech_prob": 6.596533057745546e-05}, {"id": 148, "seek": 99100, "start": 998.0, "end": 1005.0, "text": " that you can then load and make nice graphs and understand what's the live performance of your pipeline, what's going on.", "tokens": [300, 291, 393, 550, 3677, 293, 652, 1481, 24877, 293, 1223, 437, 311, 264, 1621, 3389, 295, 428, 15517, 11, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.1559359394774145, "compression_ratio": 1.677685950413223, "no_speech_prob": 6.596533057745546e-05}, {"id": 149, "seek": 99100, "start": 1005.0, "end": 1012.0, "text": " We have one to draw pretty pipeline snapshots, so for a long time we had a feature where we could draw a dot file", "tokens": [492, 362, 472, 281, 2642, 1238, 15517, 19206, 27495, 11, 370, 337, 257, 938, 565, 321, 632, 257, 4111, 689, 321, 727, 2642, 257, 5893, 3991], "temperature": 0.0, "avg_logprob": -0.1559359394774145, "compression_ratio": 1.677685950413223, "no_speech_prob": 6.596533057745546e-05}, {"id": 150, "seek": 99100, "start": 1012.0, "end": 1016.0, "text": " to draw a picture of the pipeline, but this required it.", "tokens": [281, 2642, 257, 3036, 295, 264, 15517, 11, 457, 341, 4739, 309, 13], "temperature": 0.0, "avg_logprob": -0.1559359394774145, "compression_ratio": 1.677685950413223, "no_speech_prob": 6.596533057745546e-05}, {"id": 151, "seek": 101600, "start": 1016.0, "end": 1023.0, "text": " I added some code to the application to actually trigger it. With this tracer, now you can just listen to a unique signal", "tokens": [286, 3869, 512, 3089, 281, 264, 3861, 281, 767, 7875, 309, 13, 2022, 341, 504, 12858, 11, 586, 291, 393, 445, 2140, 281, 257, 3845, 6358], "temperature": 0.0, "avg_logprob": -0.18380758666992186, "compression_ratio": 1.6073825503355705, "no_speech_prob": 9.158164175460115e-05}, {"id": 152, "seek": 101600, "start": 1023.0, "end": 1025.0, "text": " and trigger it on the spot.", "tokens": [293, 7875, 309, 322, 264, 4008, 13], "temperature": 0.0, "avg_logprob": -0.18380758666992186, "compression_ratio": 1.6073825503355705, "no_speech_prob": 9.158164175460115e-05}, {"id": 153, "seek": 101600, "start": 1025.0, "end": 1031.0, "text": " The last one is the factory tracer. This is the very first feature that I mentioned.", "tokens": [440, 1036, 472, 307, 264, 9265, 504, 12858, 13, 639, 307, 264, 588, 700, 4111, 300, 286, 2835, 13], "temperature": 0.0, "avg_logprob": -0.18380758666992186, "compression_ratio": 1.6073825503355705, "no_speech_prob": 9.158164175460115e-05}, {"id": 154, "seek": 101600, "start": 1031.0, "end": 1038.0, "text": " So it's nice to say, oh, I'm going to build a G-streamer, build specific for my application with only the elements I use.", "tokens": [407, 309, 311, 1481, 281, 584, 11, 1954, 11, 286, 478, 516, 281, 1322, 257, 460, 12, 9291, 260, 11, 1322, 2685, 337, 452, 3861, 365, 787, 264, 4959, 286, 764, 13], "temperature": 0.0, "avg_logprob": -0.18380758666992186, "compression_ratio": 1.6073825503355705, "no_speech_prob": 9.158164175460115e-05}, {"id": 155, "seek": 101600, "start": 1038.0, "end": 1045.0, "text": " But if you use PlayVin, there's a lot of automated things, and you might not know exactly which plugins you've been using.", "tokens": [583, 498, 291, 764, 5506, 53, 259, 11, 456, 311, 257, 688, 295, 18473, 721, 11, 293, 291, 1062, 406, 458, 2293, 597, 33759, 291, 600, 668, 1228, 13], "temperature": 0.0, "avg_logprob": -0.18380758666992186, "compression_ratio": 1.6073825503355705, "no_speech_prob": 9.158164175460115e-05}, {"id": 156, "seek": 104500, "start": 1045.0, "end": 1050.0, "text": " So with this tracer, we can actually trace all the plugins that get loaded, all the elements that are used,", "tokens": [407, 365, 341, 504, 12858, 11, 321, 393, 767, 13508, 439, 264, 33759, 300, 483, 13210, 11, 439, 264, 4959, 300, 366, 1143, 11], "temperature": 0.0, "avg_logprob": -0.1969879413473195, "compression_ratio": 1.8174603174603174, "no_speech_prob": 0.00012112419790355489}, {"id": 157, "seek": 104500, "start": 1050.0, "end": 1057.0, "text": " and print, when you exit your application, print the list of what was actually used.", "tokens": [293, 4482, 11, 562, 291, 11043, 428, 3861, 11, 4482, 264, 1329, 295, 437, 390, 767, 1143, 13], "temperature": 0.0, "avg_logprob": -0.1969879413473195, "compression_ratio": 1.8174603174603174, "no_speech_prob": 0.00012112419790355489}, {"id": 158, "seek": 104500, "start": 1057.0, "end": 1065.0, "text": " A question about that. PlayVin sometimes tries to use PlayVin, but this got it later because it just worked.", "tokens": [316, 1168, 466, 300, 13, 5506, 53, 259, 2171, 9898, 281, 764, 5506, 53, 259, 11, 457, 341, 658, 309, 1780, 570, 309, 445, 2732, 13], "temperature": 0.0, "avg_logprob": -0.1969879413473195, "compression_ratio": 1.8174603174603174, "no_speech_prob": 0.00012112419790355489}, {"id": 159, "seek": 104500, "start": 1065.0, "end": 1067.0, "text": " It's going to be listed anyway.", "tokens": [467, 311, 516, 281, 312, 10052, 4033, 13], "temperature": 0.0, "avg_logprob": -0.1969879413473195, "compression_ratio": 1.8174603174603174, "no_speech_prob": 0.00012112419790355489}, {"id": 160, "seek": 104500, "start": 1067.0, "end": 1074.0, "text": " So yes, right. PlayVin sometimes tries to use something, but it doesn't work because the hardware is not there or something.", "tokens": [407, 2086, 11, 558, 13, 5506, 53, 259, 2171, 9898, 281, 764, 746, 11, 457, 309, 1177, 380, 589, 570, 264, 8837, 307, 406, 456, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.1969879413473195, "compression_ratio": 1.8174603174603174, "no_speech_prob": 0.00012112419790355489}, {"id": 161, "seek": 107400, "start": 1074.0, "end": 1078.0, "text": " So in this case, the tracer will still list it.", "tokens": [407, 294, 341, 1389, 11, 264, 504, 12858, 486, 920, 1329, 309, 13], "temperature": 0.0, "avg_logprob": -0.2350472795202377, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.00025991155416704714}, {"id": 162, "seek": 107400, "start": 1078.0, "end": 1084.0, "text": " It's everything that is loaded, right? When they're tried or loaded, you call a function in it and it says no.", "tokens": [467, 311, 1203, 300, 307, 13210, 11, 558, 30, 1133, 436, 434, 3031, 420, 13210, 11, 291, 818, 257, 2445, 294, 309, 293, 309, 1619, 572, 13], "temperature": 0.0, "avg_logprob": -0.2350472795202377, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.00025991155416704714}, {"id": 163, "seek": 107400, "start": 1084.0, "end": 1090.0, "text": " So this is really at the loading stage at this place.", "tokens": [407, 341, 307, 534, 412, 264, 15114, 3233, 412, 341, 1081, 13], "temperature": 0.0, "avg_logprob": -0.2350472795202377, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.00025991155416704714}, {"id": 164, "seek": 107400, "start": 1090.0, "end": 1093.0, "text": " Thank you. Any questions? Yes.", "tokens": [1044, 291, 13, 2639, 1651, 30, 1079, 13], "temperature": 0.0, "avg_logprob": -0.2350472795202377, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.00025991155416704714}, {"id": 165, "seek": 107400, "start": 1093.0, "end": 1101.0, "text": " You mentioned V1 and the RTP support in there. So can you also add the SPC extensions?", "tokens": [509, 2835, 691, 16, 293, 264, 497, 16804, 1406, 294, 456, 13, 407, 393, 291, 611, 909, 264, 8420, 34, 25129, 30], "temperature": 0.0, "avg_logprob": -0.2350472795202377, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.00025991155416704714}, {"id": 166, "seek": 110100, "start": 1101.0, "end": 1108.0, "text": " I have no idea. Anyone knows? No.", "tokens": [286, 362, 572, 1558, 13, 14643, 3255, 30, 883, 13], "temperature": 0.0, "avg_logprob": -0.36991246541341144, "compression_ratio": 1.6256410256410256, "no_speech_prob": 0.000777220178861171}, {"id": 167, "seek": 110100, "start": 1108.0, "end": 1113.0, "text": " So RTP, any one extension, SVC extension in, I don't know if it's there.", "tokens": [407, 497, 16804, 11, 604, 472, 10320, 11, 31910, 34, 10320, 294, 11, 286, 500, 380, 458, 498, 309, 311, 456, 13], "temperature": 0.0, "avg_logprob": -0.36991246541341144, "compression_ratio": 1.6256410256410256, "no_speech_prob": 0.000777220178861171}, {"id": 168, "seek": 110100, "start": 1113.0, "end": 1121.0, "text": " So we do layer selection of the highest quality here, but it's not there.", "tokens": [407, 321, 360, 4583, 9450, 295, 264, 6343, 3125, 510, 11, 457, 309, 311, 406, 456, 13], "temperature": 0.0, "avg_logprob": -0.36991246541341144, "compression_ratio": 1.6256410256410256, "no_speech_prob": 0.000777220178861171}, {"id": 169, "seek": 110100, "start": 1121.0, "end": 1128.0, "text": " So there is an external, there is a dependency description of RTP extension where you can get information about the SVC layers in there,", "tokens": [407, 456, 307, 364, 8320, 11, 456, 307, 257, 33621, 3855, 295, 497, 16804, 10320, 689, 291, 393, 483, 1589, 466, 264, 31910, 34, 7914, 294, 456, 11], "temperature": 0.0, "avg_logprob": -0.36991246541341144, "compression_ratio": 1.6256410256410256, "no_speech_prob": 0.000777220178861171}, {"id": 170, "seek": 112800, "start": 1128.0, "end": 1133.0, "text": " which is basically something like that. So you encode the SPC layers into one screen,", "tokens": [597, 307, 1936, 746, 411, 300, 13, 407, 291, 2058, 1429, 264, 8420, 34, 7914, 666, 472, 2568, 11], "temperature": 0.0, "avg_logprob": -0.4090083729137074, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.001041226671077311}, {"id": 171, "seek": 112800, "start": 1133.0, "end": 1141.0, "text": " then you use these external extensions to vary information about what's in there and what isn't, so that you can do the connection.", "tokens": [550, 291, 764, 613, 8320, 25129, 281, 10559, 1589, 466, 437, 311, 294, 456, 293, 437, 1943, 380, 11, 370, 300, 291, 393, 360, 264, 4984, 13], "temperature": 0.0, "avg_logprob": -0.4090083729137074, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.001041226671077311}, {"id": 172, "seek": 112800, "start": 1141.0, "end": 1144.0, "text": " So that's what I got to introduce from the other video.", "tokens": [407, 300, 311, 437, 286, 658, 281, 5366, 490, 264, 661, 960, 13], "temperature": 0.0, "avg_logprob": -0.4090083729137074, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.001041226671077311}, {"id": 173, "seek": 112800, "start": 1144.0, "end": 1151.0, "text": " None of the RTP and SPC stuff, including the VT1, which is quickly required because there's no SVC inside the screen.", "tokens": [14492, 295, 264, 497, 16804, 293, 8420, 34, 1507, 11, 3009, 264, 691, 51, 16, 11, 597, 307, 2661, 4739, 570, 456, 311, 572, 31910, 34, 1854, 264, 2568, 13], "temperature": 0.0, "avg_logprob": -0.4090083729137074, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.001041226671077311}, {"id": 174, "seek": 115100, "start": 1151.0, "end": 1161.0, "text": " Yes, so the question was RTP, AV1, SVC, there's an extension that can make it really useful.", "tokens": [1079, 11, 370, 264, 1168, 390, 497, 16804, 11, 30198, 16, 11, 31910, 34, 11, 456, 311, 364, 10320, 300, 393, 652, 309, 534, 4420, 13], "temperature": 0.0, "avg_logprob": -0.23659942519496863, "compression_ratio": 1.3967391304347827, "no_speech_prob": 0.001474869786761701}, {"id": 175, "seek": 115100, "start": 1161.0, "end": 1167.0, "text": " It's being standardized and it's not implemented yet, but it will be at some point.", "tokens": [467, 311, 885, 31677, 293, 309, 311, 406, 12270, 1939, 11, 457, 309, 486, 312, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.23659942519496863, "compression_ratio": 1.3967391304347827, "no_speech_prob": 0.001474869786761701}, {"id": 176, "seek": 115100, "start": 1167.0, "end": 1175.0, "text": " I forgot to mention we have an online question, online question at number 43401.", "tokens": [286, 5298, 281, 2152, 321, 362, 364, 2950, 1168, 11, 2950, 1168, 412, 1230, 17914, 5254, 16, 13], "temperature": 0.0, "avg_logprob": -0.23659942519496863, "compression_ratio": 1.3967391304347827, "no_speech_prob": 0.001474869786761701}, {"id": 177, "seek": 117500, "start": 1175.0, "end": 1183.0, "text": " So if people at home want to ask questions, it's possible, but since we don't have any questions, there are any more questions on the floor.", "tokens": [407, 498, 561, 412, 1280, 528, 281, 1029, 1651, 11, 309, 311, 1944, 11, 457, 1670, 321, 500, 380, 362, 604, 1651, 11, 456, 366, 604, 544, 1651, 322, 264, 4123, 13], "temperature": 0.0, "avg_logprob": -0.3662784894307454, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.004644705913960934}, {"id": 178, "seek": 117500, "start": 1183.0, "end": 1191.0, "text": " Q6, does support different rendering backends, like DirectX on Windows and Vulkan on Pino or something,", "tokens": [1249, 21, 11, 775, 1406, 819, 22407, 646, 2581, 11, 411, 18308, 55, 322, 8591, 293, 41434, 5225, 322, 430, 2982, 420, 746, 11], "temperature": 0.0, "avg_logprob": -0.3662784894307454, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.004644705913960934}, {"id": 179, "seek": 117500, "start": 1191.0, "end": 1193.0, "text": " with a QML event?", "tokens": [365, 257, 1249, 12683, 2280, 30], "temperature": 0.0, "avg_logprob": -0.3662784894307454, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.004644705913960934}, {"id": 180, "seek": 117500, "start": 1193.0, "end": 1199.0, "text": " And then Q6 supports post-interference that you can directly pass the DirectX buffer to the QML event?", "tokens": [400, 550, 1249, 21, 9346, 2183, 12, 5106, 5158, 300, 291, 393, 3838, 1320, 264, 18308, 55, 21762, 281, 264, 1249, 12683, 2280, 30], "temperature": 0.0, "avg_logprob": -0.3662784894307454, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.004644705913960934}, {"id": 181, "seek": 119900, "start": 1199.0, "end": 1211.0, "text": " So does Q6 support other backends than OpenGL? And I think the answer right now is, won't it support OpenGL?", "tokens": [407, 775, 1249, 21, 1406, 661, 646, 2581, 813, 7238, 19440, 30, 400, 286, 519, 264, 1867, 558, 586, 307, 11, 1582, 380, 309, 1406, 7238, 19440, 30], "temperature": 0.0, "avg_logprob": -0.19853890296256188, "compression_ratio": 1.7149321266968325, "no_speech_prob": 0.00047795611317269504}, {"id": 182, "seek": 119900, "start": 1211.0, "end": 1213.0, "text": " Any more questions? Yes.", "tokens": [2639, 544, 1651, 30, 1079, 13], "temperature": 0.0, "avg_logprob": -0.19853890296256188, "compression_ratio": 1.7149321266968325, "no_speech_prob": 0.00047795611317269504}, {"id": 183, "seek": 119900, "start": 1213.0, "end": 1215.0, "text": " Can you do a statically linked binary?", "tokens": [1664, 291, 360, 257, 2219, 984, 9408, 17434, 30], "temperature": 0.0, "avg_logprob": -0.19853890296256188, "compression_ratio": 1.7149321266968325, "no_speech_prob": 0.00047795611317269504}, {"id": 184, "seek": 119900, "start": 1215.0, "end": 1217.0, "text": " Can you do a statically linked binary? Yes, you can.", "tokens": [1664, 291, 360, 257, 2219, 984, 9408, 17434, 30, 1079, 11, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.19853890296256188, "compression_ratio": 1.7149321266968325, "no_speech_prob": 0.00047795611317269504}, {"id": 185, "seek": 119900, "start": 1217.0, "end": 1225.0, "text": " That's kind of one of the use cases as we create this statically linked library and then your application can link to it and only link the required bits.", "tokens": [663, 311, 733, 295, 472, 295, 264, 764, 3331, 382, 321, 1884, 341, 2219, 984, 9408, 6405, 293, 550, 428, 3861, 393, 2113, 281, 309, 293, 787, 2113, 264, 4739, 9239, 13], "temperature": 0.0, "avg_logprob": -0.19853890296256188, "compression_ratio": 1.7149321266968325, "no_speech_prob": 0.00047795611317269504}, {"id": 186, "seek": 122500, "start": 1225.0, "end": 1229.0, "text": " That's kind of the part of the trick to make it a little smaller.", "tokens": [663, 311, 733, 295, 264, 644, 295, 264, 4282, 281, 652, 309, 257, 707, 4356, 13], "temperature": 0.0, "avg_logprob": -0.28176509632783775, "compression_ratio": 1.361963190184049, "no_speech_prob": 0.0012097539147362113}, {"id": 187, "seek": 122500, "start": 1233.0, "end": 1235.0, "text": " Yeah, my question.", "tokens": [865, 11, 452, 1168, 13], "temperature": 0.0, "avg_logprob": -0.28176509632783775, "compression_ratio": 1.361963190184049, "no_speech_prob": 0.0012097539147362113}, {"id": 188, "seek": 122500, "start": 1235.0, "end": 1239.0, "text": " So you said that there is congestion control in WebRTC now?", "tokens": [407, 291, 848, 300, 456, 307, 40816, 1969, 294, 9573, 49, 18238, 586, 30], "temperature": 0.0, "avg_logprob": -0.28176509632783775, "compression_ratio": 1.361963190184049, "no_speech_prob": 0.0012097539147362113}, {"id": 189, "seek": 122500, "start": 1239.0, "end": 1241.0, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.28176509632783775, "compression_ratio": 1.361963190184049, "no_speech_prob": 0.0012097539147362113}, {"id": 190, "seek": 122500, "start": 1241.0, "end": 1247.0, "text": " Is it like the same feature set as in Google's implementation?", "tokens": [1119, 309, 411, 264, 912, 4111, 992, 382, 294, 3329, 311, 11420, 30], "temperature": 0.0, "avg_logprob": -0.28176509632783775, "compression_ratio": 1.361963190184049, "no_speech_prob": 0.0012097539147362113}, {"id": 191, "seek": 122500, "start": 1247.0, "end": 1249.0, "text": " So, yeah.", "tokens": [407, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.28176509632783775, "compression_ratio": 1.361963190184049, "no_speech_prob": 0.0012097539147362113}, {"id": 192, "seek": 124900, "start": 1249.0, "end": 1255.0, "text": " The question is about congestion control in WebRTC. Is it the same feature set as the Google implementation?", "tokens": [440, 1168, 307, 466, 40816, 1969, 294, 9573, 49, 18238, 13, 1119, 309, 264, 912, 4111, 992, 382, 264, 3329, 11420, 30], "temperature": 0.0, "avg_logprob": -0.16444442385718935, "compression_ratio": 1.5594059405940595, "no_speech_prob": 6.103311534388922e-05}, {"id": 193, "seek": 124900, "start": 1255.0, "end": 1261.0, "text": " As far as I know, yes, because it's basically a copy of the implementation in Rust.", "tokens": [1018, 1400, 382, 286, 458, 11, 2086, 11, 570, 309, 311, 1936, 257, 5055, 295, 264, 11420, 294, 34952, 13], "temperature": 0.0, "avg_logprob": -0.16444442385718935, "compression_ratio": 1.5594059405940595, "no_speech_prob": 6.103311534388922e-05}, {"id": 194, "seek": 124900, "start": 1261.0, "end": 1265.0, "text": " So they basically re-implement the same algorithm.", "tokens": [407, 436, 1936, 319, 12, 332, 43704, 264, 912, 9284, 13], "temperature": 0.0, "avg_logprob": -0.16444442385718935, "compression_ratio": 1.5594059405940595, "no_speech_prob": 6.103311534388922e-05}, {"id": 195, "seek": 124900, "start": 1265.0, "end": 1269.0, "text": " So that is compatible.", "tokens": [407, 300, 307, 18218, 13], "temperature": 0.0, "avg_logprob": -0.16444442385718935, "compression_ratio": 1.5594059405940595, "no_speech_prob": 6.103311534388922e-05}, {"id": 196, "seek": 124900, "start": 1269.0, "end": 1271.0, "text": " But it's pluggable. So you could write your own.", "tokens": [583, 309, 311, 499, 3562, 712, 13, 407, 291, 727, 2464, 428, 1065, 13], "temperature": 0.0, "avg_logprob": -0.16444442385718935, "compression_ratio": 1.5594059405940595, "no_speech_prob": 6.103311534388922e-05}, {"id": 197, "seek": 127100, "start": 1271.0, "end": 1279.0, "text": " There's a plug-in mechanism and the core version is in C, but this one is in Rust with a separate plug-in.", "tokens": [821, 311, 257, 5452, 12, 259, 7513, 293, 264, 4965, 3037, 307, 294, 383, 11, 457, 341, 472, 307, 294, 34952, 365, 257, 4994, 5452, 12, 259, 13], "temperature": 0.0, "avg_logprob": -0.23125090082007718, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00039069453487172723}, {"id": 198, "seek": 127100, "start": 1279.0, "end": 1285.0, "text": " One could write a different implementation because there's a bunch of heuristics in there.", "tokens": [1485, 727, 2464, 257, 819, 11420, 570, 456, 311, 257, 3840, 295, 415, 374, 6006, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.23125090082007718, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00039069453487172723}, {"id": 199, "seek": 127100, "start": 1285.0, "end": 1287.0, "text": " There's no line.", "tokens": [821, 311, 572, 1622, 13], "temperature": 0.0, "avg_logprob": -0.23125090082007718, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00039069453487172723}, {"id": 200, "seek": 127100, "start": 1287.0, "end": 1289.0, "text": " Perfect answer.", "tokens": [10246, 1867, 13], "temperature": 0.0, "avg_logprob": -0.23125090082007718, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00039069453487172723}, {"id": 201, "seek": 127100, "start": 1289.0, "end": 1291.0, "text": " Thank you so much.", "tokens": [1044, 291, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.23125090082007718, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00039069453487172723}, {"id": 202, "seek": 127100, "start": 1291.0, "end": 1293.0, "text": " Do you have a question?", "tokens": [1144, 291, 362, 257, 1168, 30], "temperature": 0.0, "avg_logprob": -0.23125090082007718, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00039069453487172723}, {"id": 203, "seek": 127100, "start": 1293.0, "end": 1295.0, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.23125090082007718, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00039069453487172723}, {"id": 204, "seek": 129500, "start": 1295.0, "end": 1307.0, "text": " If I have an application that does WebRTC signaling of a matrix, for example, would I benefit from switching to WebRTC sync or would I sit with WebRTC?", "tokens": [759, 286, 362, 364, 3861, 300, 775, 9573, 49, 18238, 38639, 295, 257, 8141, 11, 337, 1365, 11, 576, 286, 5121, 490, 16493, 281, 9573, 49, 18238, 20271, 420, 576, 286, 1394, 365, 9573, 49, 18238, 30], "temperature": 0.0, "avg_logprob": -0.1631658288496959, "compression_ratio": 1.776536312849162, "no_speech_prob": 0.0003612868022173643}, {"id": 205, "seek": 129500, "start": 1307.0, "end": 1317.0, "text": " So the question is, if you have an implementation of WebRTC that does signaling something custom, for example, other matrix, would you benefit from using WebRTC sync?", "tokens": [407, 264, 1168, 307, 11, 498, 291, 362, 364, 11420, 295, 9573, 49, 18238, 300, 775, 38639, 746, 2375, 11, 337, 1365, 11, 661, 8141, 11, 576, 291, 5121, 490, 1228, 9573, 49, 18238, 20271, 30], "temperature": 0.0, "avg_logprob": -0.1631658288496959, "compression_ratio": 1.776536312849162, "no_speech_prob": 0.0003612868022173643}, {"id": 206, "seek": 131700, "start": 1317.0, "end": 1328.0, "text": " And the answer to that is yes, because it will do all of the encoding and congestion control hooked up for you.", "tokens": [400, 264, 1867, 281, 300, 307, 2086, 11, 570, 309, 486, 360, 439, 295, 264, 43430, 293, 40816, 1969, 20410, 493, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.2015941386320153, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.0001993507903534919}, {"id": 207, "seek": 131700, "start": 1328.0, "end": 1332.0, "text": " And there's an interface that you can implement for your own signaling.", "tokens": [400, 456, 311, 364, 9226, 300, 291, 393, 4445, 337, 428, 1065, 38639, 13], "temperature": 0.0, "avg_logprob": -0.2015941386320153, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.0001993507903534919}, {"id": 208, "seek": 131700, "start": 1332.0, "end": 1335.0, "text": " So the signaling is separate from this WebRTC sync.", "tokens": [407, 264, 38639, 307, 4994, 490, 341, 9573, 49, 18238, 20271, 13], "temperature": 0.0, "avg_logprob": -0.2015941386320153, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.0001993507903534919}, {"id": 209, "seek": 131700, "start": 1335.0, "end": 1338.0, "text": " There's still a module that we can implement.", "tokens": [821, 311, 920, 257, 10088, 300, 321, 393, 4445, 13], "temperature": 0.0, "avg_logprob": -0.2015941386320153, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.0001993507903534919}, {"id": 210, "seek": 131700, "start": 1338.0, "end": 1345.0, "text": " We have one implemented for like a custom signaling mechanism where there's a server that's implemented, but you could write your own.", "tokens": [492, 362, 472, 12270, 337, 411, 257, 2375, 38639, 7513, 689, 456, 311, 257, 7154, 300, 311, 12270, 11, 457, 291, 727, 2464, 428, 1065, 13], "temperature": 0.0, "avg_logprob": -0.2015941386320153, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.0001993507903534919}, {"id": 211, "seek": 134500, "start": 1345.0, "end": 1349.0, "text": " Can I ask the last question?", "tokens": [1664, 286, 1029, 264, 1036, 1168, 30], "temperature": 0.0, "avg_logprob": -0.3092058234744602, "compression_ratio": 1.5032679738562091, "no_speech_prob": 0.0017404014943167567}, {"id": 212, "seek": 134500, "start": 1349.0, "end": 1351.0, "text": " No, just a comment from the question before.", "tokens": [883, 11, 445, 257, 2871, 490, 264, 1168, 949, 13], "temperature": 0.0, "avg_logprob": -0.3092058234744602, "compression_ratio": 1.5032679738562091, "no_speech_prob": 0.0017404014943167567}, {"id": 213, "seek": 134500, "start": 1351.0, "end": 1355.0, "text": " The QT6 direct 3D integration.", "tokens": [440, 1249, 51, 21, 2047, 805, 35, 10980, 13], "temperature": 0.0, "avg_logprob": -0.3092058234744602, "compression_ratio": 1.5032679738562091, "no_speech_prob": 0.0017404014943167567}, {"id": 214, "seek": 134500, "start": 1355.0, "end": 1357.0, "text": " There is a merge request for it.", "tokens": [821, 307, 257, 22183, 5308, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.3092058234744602, "compression_ratio": 1.5032679738562091, "no_speech_prob": 0.0017404014943167567}, {"id": 215, "seek": 134500, "start": 1357.0, "end": 1359.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.3092058234744602, "compression_ratio": 1.5032679738562091, "no_speech_prob": 0.0017404014943167567}, {"id": 216, "seek": 134500, "start": 1359.0, "end": 1370.0, "text": " So Tim says that for the QT, there's a direct 3D merge request open to integrate that.", "tokens": [407, 7172, 1619, 300, 337, 264, 1249, 51, 11, 456, 311, 257, 2047, 805, 35, 22183, 5308, 1269, 281, 13365, 300, 13], "temperature": 0.0, "avg_logprob": -0.3092058234744602, "compression_ratio": 1.5032679738562091, "no_speech_prob": 0.0017404014943167567}, {"id": 217, "seek": 137000, "start": 1370.0, "end": 1375.0, "text": " It's not merged yet, but do test it at home and complain when it doesn't work.", "tokens": [467, 311, 406, 36427, 1939, 11, 457, 360, 1500, 309, 412, 1280, 293, 11024, 562, 309, 1177, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.2709751674107143, "compression_ratio": 1.1224489795918366, "no_speech_prob": 0.0007644557626917958}, {"id": 218, "seek": 137000, "start": 1375.0, "end": 1378.0, "text": " Last question.", "tokens": [5264, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2709751674107143, "compression_ratio": 1.1224489795918366, "no_speech_prob": 0.0007644557626917958}, {"id": 219, "seek": 137800, "start": 1378.0, "end": 1401.0, "text": " Okay, thank you.", "tokens": [50364, 1033, 11, 1309, 291, 13, 51514], "temperature": 0.0, "avg_logprob": -0.49795570969581604, "compression_ratio": 0.6666666666666666, "no_speech_prob": 0.0008788623963482678}], "language": "en"}