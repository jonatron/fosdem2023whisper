{"text": " Okay so we start again. Our next talk is about liquid soap. Please welcome Romain. Hello and good morning. I'm really happy to be here after not two but three actually. And we gave a talk here before the whole thing happened that I don't want to talk about. A lot of things happened and I want to go back to it and talk about what we did both in the code and with the community and the kind of things that happened. So yeah first of all for those who weren't there at the first talk, what is liquid soap? It's a programming language. Technically it's a scripting language, scripted language. It's statically typed with inferred type. So if you're familiar with type script, it's type script but you don't have to write the type so everything here is a string, an integer, something. What does the language do? It allows you to create online stream and it's not a low level tool. So we delegate that and I'll talk a lot about it. What we want is to empower the user to rezone about the tool. That's what the language really does well. Programming, logic, business logic. I want to play that song. I want to switch to a live source. So that's an example of a full code that we can use to run two outputs on IceCast based on playlists, a file, a list of requests, an input from HTTP, all sort of stuff. Yeah. So what has happened with liquid soap since first time 2020? We worked with Radio France. That's the reason we came in 2020 and it was that starting point of a lot of new work because it really created a new cycle of work interest. We had a lot of community growth that reflect back on it in the first part of this talk. Then we do a lot of new features because guess what? We also had a lot of time during that time and we worked a lot on it. And I want to finish the talk by talking about future development and challenges that we foresee for the future. So first of all, what happened with the community? So I started looking back at the stats over the past three years and I looked at the GitHub stars. It's nice, but it was growing pretty steadily except for that little bump here when we did the 2.0 release. And I looked at the Slack channel, which I want to move out of this platform. But anyway, it was also growing pretty linearly. I was like, doesn't seem really anything happened over the past three years. Then I looked at the issues. And that's where I was like, yeah, I remember that. So what happened is when the whole shutdown happened, because we are a project that enables people to communicate online, well, it was one of the places that people wanted to go to communicate with people and to try to reach out, create link, maintain link. So we had a lot of people suddenly who were like, I want to do an online stream. I want to put music for my friend to listen to. I want to do all these things. And the second effect, we had a lot of people with time. So we're kind of one of those projects where you're like, oh, we like it. I like it. I'd like to look at it at some point, but I'm too busy and suddenly I have time. So people starting using it, submitting a lot of issues and well, we got busy. One of the things that we deal with so is because we didn't have that kind of in-person meeting, someone who's the other code developer of the project decided that we should do an online workshop, which was the thing to do. And it was really good because what it really allowed us is to get to meet our community. And I think one of the things that's really nice with this project is that it's both a technical project, but a lot of our users are actually not technical people. They're like people who have Burning Man Radio at the Burning Man thing. Some of the cute project we had was like, the top one was a network of community radios in Barcelona where they literally have trucks that they bring to different neighborhoods to do online reporting of what happens in the city. And the lower one was another Hungarian community radio. So that was really good to get to meet that. And I think we valued that a lot. We have, of course, we have industrial users, but this is also one of the core motivations for the project for us. And then, eventually, another thing we did, again, by product of having a lot of time, which was mainly some working on it, was to write a programming book specialized in audio stream, media stream, and how to use liquid soap for it. And it was very useful on many levels. One of them is that it forced us to rethink our API and reorganize it. So you say, can we do that? What's a good example to do that? Well, actually, it's not clear. Let's make a nice module that can do that easily, document it. And also, it enabled the users a lot to be more confident because, as I said, most of our users are not programmers. And so they come to this, and they're like, whoa, never touch a line of code. How can I do? So that book was a really good starting point to get people interested and more confident with the project. So what did we do for the new features, though? That's the part that the gist of the work we did. So first of all, we did a lot of language changes because for a long time, our focus was more on features. We only did a lot of output, a lot of input, a lot of different interesting operators. But when you start to want to implement things that are more complex, you also need powerful language extension or toolbox. And also, we did a lot of FFMP integration. So those are the two things that I'm going to talk next. And first, the language change. So yeah, more expressivity. You want to enable your users to write code that is nice, readable, that they can understand, that is powerful, but it doesn't have to have a million lines to do a simple thing. So simple things like that. These are like spreads, you know, to split out a list. You have a list, you want to get the first element, last element, and whatever else is left as a remainder. We could do that before, but we had to use functions and it was complicated. This really helps users just visualize the code and be like, all right, understand what this is doing, and have much less lines to write it. We implemented a lot of types that were missing. So for instance, a null variable. A lot of that will remain a sense of, of course, dynamic scripting languages like JavaScript or others. So we didn't have a null value. We did a null value and we added a nice operator that says if you have a null on X, if X is not null, it's a string, then you get X. If it's null, you get the string full. Stuff like that. But when you start writing actual usable code, you need these things and they're very useful. Yeah, you can write function with optional argument and you can exactly say the user didn't pass an argument. That's just basic programming language features. The other thing we did that was very useful is a new module syntax. That basically means that any value in the language can be attached methods or attributes to it. So here you have a string and that string has two methods. Well, attributes here, duration, floating number, and BPM. It's basically an object oriented ID, but not really an object. More like JavaScript hash, I guess. And that means that you can query the song.duration and get the floating point duration or you can print the song title as a string using the underlying value. That was really useful because when you want to create something that's easy to use for user, you need to structure your language. You need to have modules and you need to have functions in those modules. Also, another typical case is that now you can specialize things. So you have sources that have different functions. So all sources have a skip function. It means that you can get to the next track in your stream, but you may have sources that have specific function. So for instance, you can have a source that can insert metadata that's created with this operator. It will be added a new function that's called insert metadata, and now you can use it. So instead of having a billion of general calls that are API based, you can start really attaching specific use to specific variables and it makes things more compact, more specialized, and very useful for cleaning up your API. Another thing we did after that with the module is that now we were able to describe high level things. So one of those things that's really painful in static ID type language is parsing JSON. Why? Because JSON can be anything, and we really want to know that name is a string. We really want to know that name is a version. So in language like OKMOR you have to parse an object, iterate through the keys, validate that is a string, and every branch of that you need to think of what you're doing. And our users, again, not programmers. So what do we do? We try to find a primitive that's readable and easy to use. So what are you reading here? You're reading a parsing statement that says I want to parse and I want to get a module that's going to have a name, a version, and another script attribute that is itself a module that has a test function. It's what you get in a package that JSON for node modules. And this is a type annotation that says I want the name to be a string, the version to be a string, and the script to be a module with a test that's a string. And at runtime we're going to take all this information, we're going to try to parse this, and we're going to do two things. If we have what we need in the JSON, you can go on with your script. If we don't, we raise an error, you can cache the error and reason with it. But that really makes parsing of JSON more easier on the user, which is important because, again, when you want to connect a lot of interconnected systems for streaming, you want to be able to talk to JSON API. So pretty useful. And we did the same for Yemo recently. So yeah, you can do settings now. Yeah, those are the new features. There's more, but I don't want to spend too much time on it because the other part that I want to talk about that's exciting is the FFMPG integration. And that really started after Radio France because they had a strong need for it, and we started looking at the API from FFMPG. And the thing with the API from FFMPG is that it's really good. It's amazingly good. It's all very low level in C. So for us, because I didn't mention, but LiquidSup is implemented in OCaml, so we need to speak to low level implementation to really be efficient. We can talk to Pearl or to whatever, Python. And this C, it's really simple for us. But it's also extremely abstract. And that really helps us because, again, we want to do what we do well, which is the programming language side, the logic, the typing, the functions. But we're not specialists in multimedia implementation. We don't want to do that. We want to find people who do it better than us and interface with it. So that's the API for a FFMPG packet, which is a little tiny bit of encoded data. It contains, I don't know, an MP3 frame, a video, A or B frame, all the abstract things I don't want to know about. But it's going to tell me two things. It's going to tell me this is your data. This is your pointer to a presentation timestamp. And that thing here tells me this is the time at which you want to insert this packet in your stream. This is the data. That's what I need to know. Because then we can build a stream with it. We can pass the packet around to our different operators, not even knowing what they contain. The other thing that FFMPG really, yeah, so that's why we started doing, we started implementing a new encoder that was basically reflecting everything that you see as a parameter in the FFMPG command line. We think that we support it as an option in those encoders. And why do we think that is because another thing that FFMPG really does really well is describing their API. So I'm sorry, that's not very readable. But that's a C structure that has all the parameters name here for H264 encoders, description, type, somewhere, and minimum, maximum value, everything we need to basically write an interface to it. It also does it for filters. Again, not very readable. Sorry about that. But it's basically a programmatic interface to everything you need to know about parameters for FFMPG. That's also not readable. Great. So then what we can do is this is an FFMPG filter implemented in liquid soap. And if you could read well, you would see that every parameter is in the filter, like speed, is a floating point, optional. It has no value default. They saw no value default. Sometimes they don't. We get this information from the FFMPG C API, and we can plug into it immediately and be very confident that we're using it well. And so one of the things it allows us to do is to actually have scripted manipulation of FFMPG primitive like filters. So we take a source and we want to define a filter that is a flanger followed by a high pass and then output it. So you need a graph. That's just part of the C API. You need a source. You create an audio input from it. That's the FFMPG side. That's what they call an audio input. You pass it to the filter with the parameters. Everything is typed here, so we can check. That's the right value. And then you create an output. Run that. You have a high level description of your filter. I don't know if you all have manipulated FFMPG filters, but when you want to do complex filters, they have a description graph that's pretty hard to read. I'm used to that, so I'm biased. I can read these things easier, but also it's kind of more descriptive. It's typed, too. So this is another filter. It takes an audio, splits it into two sources. One of them is going to go through a flanger. The other one is a high pass. This is some conversion that was required. I don't know why. And then you merge them back. So we're describing now a graph that branches out, do two filtering and comes back together. This is a simple one, but you could use that to do, I don't know, a multi-band compressor, for instance. You can do that in FFMPG. It's just a little bit more structured and readable and also type safe. So next, I want to talk about how we implemented that. Yeah, I still have some time. This is the timeline for us, infinite time. We started here, and we go all the way here. If you use your imagination, all these little horizontal dots are audio packets that came from FFMPG. Vertical ones are video frame. This is your stream of data that you're sending to an ice castle, anything. What we do is that we find the lowest common denominator between the video rate and the audio rate. We need to find a little chunk of time that will contain the same amount of audio and data. Most of the time, with the parameters we have internally, it would be 0.04 seconds. That's what we call our frame. And then, the idea of the streaming loop, once you've parsed and prepared all your outputs, is to just recreate that frame every 0.04 seconds, infinitely many times. That just creates your stream. And so, here's an example. We have a simple script. It has two outputs. You want to save to a file and send to an ice castle server. Fullback is an operator that will take the first source available. So, the first one is an input. It's a hardware. So, it's one of the operators we have that can receive ice cast clients. So, let's say you want a DJ to connect to your radio. You can direct them to this input, and it starts streaming. The fullback will stream that data immediately. If it's not available, we have a queue of requests that you can. So, let's say you want to send a track to be played immediately after the following one. Every now and then, you can send a request here. Otherwise, we have a playlist of just files in the directory. And if that is not available, we have some kind of fullback. Just in case everything fails, something is going to say, I don't know. We're having technical issues. Please come back. So, now we're going to run the streaming algorithm and see how we do that. So, output.file starts. It always goes back from the output down to the inputs. And the reason is because all of that is dynamic. So, there's no reason to start asking these people here to prepare data. They might not be used because, up in the graph, the fullback might choose to use just one of them. So, we have to start from the output. Bring it down. So, I have an empty frame, a cycle, 23 sudden streaming cycle. And I want to fill it up with 0.04 seconds of data. I go to the fullback and say, hey, can you fill up this frame? Fullback is like, sure, let me ask first, input a hardware? Not available. But request.q has something in the queue, actually. Let me pass it down, pass it down to this operator. Request.q partially fills the frame. It added a little bit of audio and one video frame. What you can think about it is that it was just finishing a track. Remember, request.q takes files when you want to play them. So, I don't know. It's just done playing the jingle or the commercial that you wanted to finish. That's it. I'm done. So, it's a partial fill of the frame, in which case it comes back to the fullback that says, I need more. Playlist is not available. For some reason, the directory is empty. So, we go back to the single and say, hey, single, can you fill this frame? One of the things we do when we start the script is that we actually double check that we have at least one operator here that's always going to be available. So, that's what happens here. The fullback is being used. And single is, sure, I got a file. I prepared it. I can decode it. Boom. Finish filling up the frame. And then it goes all the way up the tree. We're ready to encode that, save it in the file. Now comes the second one, which is the iSCAS output. Same thing. It's like, hey, I need to send data to my iSCAS server. It goes back to the fullback. But then what we do here, of course, we cache stuff. So, we know that fullback has already produced a whole frame. We have saved it. We can just fill it up here, send it back to iSCAS, again, encode it if needed, send it back. So, the thing that's really nice with this algorithm is that, again, we don't really care about what's in the frame. We just care that we know that we can fill it up and we know how much is filled. And then we can pass it down. So, these things can actually be FFMpeg encoded packet. No problem. They can be raw PCM. Then we have to encode them. So, it's really, again, we are just looking at things from a high-level perspective. So, if the time for that whole cycle was t, we have two possibilities. If we generated the 0.04 second in less than 0.04 second for the computer, it means that we run faster than the real-time. We can sleep a little bit because we're generating things in real-time. If not, we have a problem. We need to catch up. So, we need to run the loop again as fast as possible. Basically, if you're in the red, you have a problem. It means that, I don't know, encoding takes too long. Something happened in your script. You cannot produce in real-time. What we want is to be in the green all the time so that we know we can deliver the content at a real-time rate all the time. So, that's how it works. Now, because I told you all that we now can use encoded content, we're having a little bit of problems that I won't have time to describe here. But essentially, sometimes we have to do a lower-level understanding of what's happening in the bitstream. So, basically, in ffmpeg, you have things that's called extra data. So, if you take an mp4 media, everything that is needed to decode like fman-table is in the header, it's communicated first, and then all the packets, the frames after that, don't have it. But if you take mpeg-ts, because mpeg-ts doesn't have a global header, every frame is going to have that data. And that was a problem because now we do things that ffmpeg doesn't do, which is a live switch between two different bitstreams. This is a RTMP input, this is a file, mp4. And when we live switch, if we started with this one, for instance, the muxer from ffmpeg might say, oh, you know what, I already have the, no, if we started with this one, the muxer will say, I know that all the frames are going to have the private data that I need, I can go on with it. And then we live switch to that, and suddenly we start receiving frames that don't have it. And the muxer is like, whoops, I cannot do it. So we have to insert those filters here to make sure that they're always present. Which is a problem for us because it means that the user has to think about low-level stuff. And that's part of one of the questions that I was wondering if ffmpeg might find some of the beautiful abstraction they have to alleviate that kind of problem. All right, almost done. I'm going to finish real quick. We have a 2.x release with tracks so you can manipulate and remix different tracks. Let's say you do an MKV with French, English, and Italian soundtrack and encode it in different format. We want to rewrite the whole clocking system and streaming because Okamera 5.0 does concurrency. It's pretty exciting. We want to think about JavaScript and YSM because we can do it and why not. And I'm very interested to see what VLC does because that's the next part and why they do it. And long-term development though is what we are wondering about because we have grown a lot of community, but most of our users are not programmers and our programming language is OKMO, which is still a niche language. And we're two developers, someone and myself. So one of the questions, you know, the project is 20 years. We're 40-year-old. At some point, we need to think about moving on. So what we have done so far is do a lot of automation, which is very powerful. It allows us to focus on the code and have less to think to do. Like, we have automated release. We do CI to run all the tests every time. We have augmented the number of automated tests we have so that we catch everything very quickly instead of relying on a lot of manual testing. But it's far as a challenge to think about how we can bring in more developers that like OKMO, like radio, is a pretty intersection of two niche things. And that's it for me. And thank you very much for your time. And maybe there are questions. So we have time for a couple of questions, yes? Yeah, so once you go from the debumster to the coder, it's expected to format the entity. Then the same thing on the mob suicide. So if the expected output format is something else, so it will actually tell you that you're expected to insert a bit stream filter again to get it forward. Yeah, it was actually an answer. There are APIs in FFMPEG to inform the user of the C API whether or not they need to insert those filters. And I see that there is automatic insertion of those filters in the code. I guess I have to have another pass at making sure I understand when and how. And I regretfully for this presentation I didn't dive again and I remember that sometimes it becomes a little bit intricate. But thank you very much. I will definitely have a good look. Is it possible to control the running script using an external automation, especially like editing running playlists? Yeah, absolutely. So are there any tools to control a running script from the external user? So we have a lot of different options. The traditional one, the old one was a TerNet connection. But we have a fully featured HTTP server, so you can write your own API endpoints. And basically because every source has their own methods now that are attached to it, and you can run scripts, you can basically take a source and say, okay, there's a function that inserts metadata, plug that into running everything else. We're programming language. So yeah, we have a lot of different options for that for sure. Can you use LiquidSoup to do static operations, not to compare files, and not with the goal of doing streaming, just to apply operations on many... Yes. The answer is yes, because the clock doesn't have to be... Oh yeah. Can you use LiquidSoup to do offline processing faster than real-time and not just real-time? The answer is yes, because you can run a clock that says, I don't want you to be real-time, I want you to run as fast as possible. But the sub-answer is that it's not a common case, it's not commonly tested. And that's part of the thing that I want to bring on more when we write the streaming. Because for instance, a request needs to resolve a file which needs to make a network request, download the file test that you can decode that. Most of the time we expect that to take a while, but it's not been tested a lot when you want to run very, very fast. And you run into race conditions that are very different. Okay. Thank you very much. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 15.0, "text": " Okay so we start again. Our next talk is about liquid soap. Please welcome Romain.", "tokens": [1033, 370, 321, 722, 797, 13, 2621, 958, 751, 307, 466, 6553, 14587, 13, 2555, 2928, 10141, 491, 13], "temperature": 0.0, "avg_logprob": -0.31909038081313623, "compression_ratio": 1.4519774011299436, "no_speech_prob": 0.4502122104167938}, {"id": 1, "seek": 0, "start": 15.0, "end": 20.96, "text": " Hello and good morning. I'm really happy to be here after not two but three actually.", "tokens": [2425, 293, 665, 2446, 13, 286, 478, 534, 2055, 281, 312, 510, 934, 406, 732, 457, 1045, 767, 13], "temperature": 0.0, "avg_logprob": -0.31909038081313623, "compression_ratio": 1.4519774011299436, "no_speech_prob": 0.4502122104167938}, {"id": 2, "seek": 0, "start": 20.96, "end": 27.400000000000002, "text": " And we gave a talk here before the whole thing happened that I don't want to talk about.", "tokens": [400, 321, 2729, 257, 751, 510, 949, 264, 1379, 551, 2011, 300, 286, 500, 380, 528, 281, 751, 466, 13], "temperature": 0.0, "avg_logprob": -0.31909038081313623, "compression_ratio": 1.4519774011299436, "no_speech_prob": 0.4502122104167938}, {"id": 3, "seek": 2740, "start": 27.4, "end": 32.879999999999995, "text": " A lot of things happened and I want to go back to it and talk about what we did both in the code", "tokens": [316, 688, 295, 721, 2011, 293, 286, 528, 281, 352, 646, 281, 309, 293, 751, 466, 437, 321, 630, 1293, 294, 264, 3089], "temperature": 0.0, "avg_logprob": -0.18511887900849694, "compression_ratio": 1.7846153846153847, "no_speech_prob": 0.00023973836505319923}, {"id": 4, "seek": 2740, "start": 32.879999999999995, "end": 38.56, "text": " and with the community and the kind of things that happened. So yeah first of all for those", "tokens": [293, 365, 264, 1768, 293, 264, 733, 295, 721, 300, 2011, 13, 407, 1338, 700, 295, 439, 337, 729], "temperature": 0.0, "avg_logprob": -0.18511887900849694, "compression_ratio": 1.7846153846153847, "no_speech_prob": 0.00023973836505319923}, {"id": 5, "seek": 2740, "start": 38.56, "end": 43.04, "text": " who weren't there at the first talk, what is liquid soap? It's a programming language.", "tokens": [567, 4999, 380, 456, 412, 264, 700, 751, 11, 437, 307, 6553, 14587, 30, 467, 311, 257, 9410, 2856, 13], "temperature": 0.0, "avg_logprob": -0.18511887900849694, "compression_ratio": 1.7846153846153847, "no_speech_prob": 0.00023973836505319923}, {"id": 6, "seek": 2740, "start": 43.04, "end": 48.68, "text": " Technically it's a scripting language, scripted language. It's statically typed with inferred", "tokens": [42494, 309, 311, 257, 5755, 278, 2856, 11, 5755, 292, 2856, 13, 467, 311, 2219, 984, 33941, 365, 13596, 986], "temperature": 0.0, "avg_logprob": -0.18511887900849694, "compression_ratio": 1.7846153846153847, "no_speech_prob": 0.00023973836505319923}, {"id": 7, "seek": 2740, "start": 48.68, "end": 54.519999999999996, "text": " type. So if you're familiar with type script, it's type script but you don't have to write the", "tokens": [2010, 13, 407, 498, 291, 434, 4963, 365, 2010, 5755, 11, 309, 311, 2010, 5755, 457, 291, 500, 380, 362, 281, 2464, 264], "temperature": 0.0, "avg_logprob": -0.18511887900849694, "compression_ratio": 1.7846153846153847, "no_speech_prob": 0.00023973836505319923}, {"id": 8, "seek": 5452, "start": 54.52, "end": 61.080000000000005, "text": " type so everything here is a string, an integer, something. What does the language do? It allows", "tokens": [2010, 370, 1203, 510, 307, 257, 6798, 11, 364, 24922, 11, 746, 13, 708, 775, 264, 2856, 360, 30, 467, 4045], "temperature": 0.0, "avg_logprob": -0.13526990154001972, "compression_ratio": 1.6623931623931625, "no_speech_prob": 4.797863948624581e-05}, {"id": 9, "seek": 5452, "start": 61.080000000000005, "end": 70.24000000000001, "text": " you to create online stream and it's not a low level tool. So we delegate that and I'll talk a", "tokens": [291, 281, 1884, 2950, 4309, 293, 309, 311, 406, 257, 2295, 1496, 2290, 13, 407, 321, 40999, 300, 293, 286, 603, 751, 257], "temperature": 0.0, "avg_logprob": -0.13526990154001972, "compression_ratio": 1.6623931623931625, "no_speech_prob": 4.797863948624581e-05}, {"id": 10, "seek": 5452, "start": 70.24000000000001, "end": 76.04, "text": " lot about it. What we want is to empower the user to rezone about the tool. That's what the language", "tokens": [688, 466, 309, 13, 708, 321, 528, 307, 281, 11071, 264, 4195, 281, 319, 16896, 466, 264, 2290, 13, 663, 311, 437, 264, 2856], "temperature": 0.0, "avg_logprob": -0.13526990154001972, "compression_ratio": 1.6623931623931625, "no_speech_prob": 4.797863948624581e-05}, {"id": 11, "seek": 5452, "start": 76.04, "end": 81.52000000000001, "text": " really does well. Programming, logic, business logic. I want to play that song. I want to switch", "tokens": [534, 775, 731, 13, 8338, 2810, 11, 9952, 11, 1606, 9952, 13, 286, 528, 281, 862, 300, 2153, 13, 286, 528, 281, 3679], "temperature": 0.0, "avg_logprob": -0.13526990154001972, "compression_ratio": 1.6623931623931625, "no_speech_prob": 4.797863948624581e-05}, {"id": 12, "seek": 8152, "start": 81.52, "end": 88.47999999999999, "text": " to a live source. So that's an example of a full code that we can use to run two outputs on", "tokens": [281, 257, 1621, 4009, 13, 407, 300, 311, 364, 1365, 295, 257, 1577, 3089, 300, 321, 393, 764, 281, 1190, 732, 23930, 322], "temperature": 0.0, "avg_logprob": -0.22301705993048035, "compression_ratio": 1.528225806451613, "no_speech_prob": 8.457509829895571e-05}, {"id": 13, "seek": 8152, "start": 88.47999999999999, "end": 95.44, "text": " IceCast based on playlists, a file, a list of requests, an input from HTTP, all sort of stuff.", "tokens": [15332, 34, 525, 2361, 322, 862, 36693, 11, 257, 3991, 11, 257, 1329, 295, 12475, 11, 364, 4846, 490, 33283, 11, 439, 1333, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.22301705993048035, "compression_ratio": 1.528225806451613, "no_speech_prob": 8.457509829895571e-05}, {"id": 14, "seek": 8152, "start": 95.44, "end": 103.52, "text": " Yeah. So what has happened with liquid soap since first time 2020? We worked with Radio France.", "tokens": [865, 13, 407, 437, 575, 2011, 365, 6553, 14587, 1670, 700, 565, 4808, 30, 492, 2732, 365, 17296, 6190, 13], "temperature": 0.0, "avg_logprob": -0.22301705993048035, "compression_ratio": 1.528225806451613, "no_speech_prob": 8.457509829895571e-05}, {"id": 15, "seek": 8152, "start": 103.52, "end": 109.84, "text": " That's the reason we came in 2020 and it was that starting point of a lot of new work because it", "tokens": [663, 311, 264, 1778, 321, 1361, 294, 4808, 293, 309, 390, 300, 2891, 935, 295, 257, 688, 295, 777, 589, 570, 309], "temperature": 0.0, "avg_logprob": -0.22301705993048035, "compression_ratio": 1.528225806451613, "no_speech_prob": 8.457509829895571e-05}, {"id": 16, "seek": 10984, "start": 109.84, "end": 120.32000000000001, "text": " really created a new cycle of work interest. We had a lot of community growth that reflect back", "tokens": [534, 2942, 257, 777, 6586, 295, 589, 1179, 13, 492, 632, 257, 688, 295, 1768, 4599, 300, 5031, 646], "temperature": 0.0, "avg_logprob": -0.13180560061806126, "compression_ratio": 1.6566523605150214, "no_speech_prob": 5.4677620937582105e-05}, {"id": 17, "seek": 10984, "start": 120.32000000000001, "end": 124.88000000000001, "text": " on it in the first part of this talk. Then we do a lot of new features because guess what? We also", "tokens": [322, 309, 294, 264, 700, 644, 295, 341, 751, 13, 1396, 321, 360, 257, 688, 295, 777, 4122, 570, 2041, 437, 30, 492, 611], "temperature": 0.0, "avg_logprob": -0.13180560061806126, "compression_ratio": 1.6566523605150214, "no_speech_prob": 5.4677620937582105e-05}, {"id": 18, "seek": 10984, "start": 124.88000000000001, "end": 131.32, "text": " had a lot of time during that time and we worked a lot on it. And I want to finish the talk by", "tokens": [632, 257, 688, 295, 565, 1830, 300, 565, 293, 321, 2732, 257, 688, 322, 309, 13, 400, 286, 528, 281, 2413, 264, 751, 538], "temperature": 0.0, "avg_logprob": -0.13180560061806126, "compression_ratio": 1.6566523605150214, "no_speech_prob": 5.4677620937582105e-05}, {"id": 19, "seek": 10984, "start": 131.32, "end": 136.16, "text": " talking about future development and challenges that we foresee for the future. So first of all,", "tokens": [1417, 466, 2027, 3250, 293, 4759, 300, 321, 38736, 337, 264, 2027, 13, 407, 700, 295, 439, 11], "temperature": 0.0, "avg_logprob": -0.13180560061806126, "compression_ratio": 1.6566523605150214, "no_speech_prob": 5.4677620937582105e-05}, {"id": 20, "seek": 13616, "start": 136.16, "end": 141.52, "text": " what happened with the community? So I started looking back at the stats over the past three", "tokens": [437, 2011, 365, 264, 1768, 30, 407, 286, 1409, 1237, 646, 412, 264, 18152, 670, 264, 1791, 1045], "temperature": 0.0, "avg_logprob": -0.1376676475052285, "compression_ratio": 1.7547169811320755, "no_speech_prob": 7.961038500070572e-05}, {"id": 21, "seek": 13616, "start": 141.52, "end": 148.28, "text": " years and I looked at the GitHub stars. It's nice, but it was growing pretty steadily except for", "tokens": [924, 293, 286, 2956, 412, 264, 23331, 6105, 13, 467, 311, 1481, 11, 457, 309, 390, 4194, 1238, 36129, 3993, 337], "temperature": 0.0, "avg_logprob": -0.1376676475052285, "compression_ratio": 1.7547169811320755, "no_speech_prob": 7.961038500070572e-05}, {"id": 22, "seek": 13616, "start": 148.28, "end": 156.72, "text": " that little bump here when we did the 2.0 release. And I looked at the Slack channel,", "tokens": [300, 707, 9961, 510, 562, 321, 630, 264, 568, 13, 15, 4374, 13, 400, 286, 2956, 412, 264, 37211, 2269, 11], "temperature": 0.0, "avg_logprob": -0.1376676475052285, "compression_ratio": 1.7547169811320755, "no_speech_prob": 7.961038500070572e-05}, {"id": 23, "seek": 13616, "start": 156.72, "end": 160.28, "text": " which I want to move out of this platform. But anyway, it was also growing pretty linearly.", "tokens": [597, 286, 528, 281, 1286, 484, 295, 341, 3663, 13, 583, 4033, 11, 309, 390, 611, 4194, 1238, 43586, 13], "temperature": 0.0, "avg_logprob": -0.1376676475052285, "compression_ratio": 1.7547169811320755, "no_speech_prob": 7.961038500070572e-05}, {"id": 24, "seek": 13616, "start": 160.28, "end": 164.76, "text": " I was like, doesn't seem really anything happened over the past three years. Then I looked at the", "tokens": [286, 390, 411, 11, 1177, 380, 1643, 534, 1340, 2011, 670, 264, 1791, 1045, 924, 13, 1396, 286, 2956, 412, 264], "temperature": 0.0, "avg_logprob": -0.1376676475052285, "compression_ratio": 1.7547169811320755, "no_speech_prob": 7.961038500070572e-05}, {"id": 25, "seek": 16476, "start": 164.76, "end": 170.39999999999998, "text": " issues. And that's where I was like, yeah, I remember that. So what happened is when the whole", "tokens": [2663, 13, 400, 300, 311, 689, 286, 390, 411, 11, 1338, 11, 286, 1604, 300, 13, 407, 437, 2011, 307, 562, 264, 1379], "temperature": 0.0, "avg_logprob": -0.1613609607403095, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0008206979837268591}, {"id": 26, "seek": 16476, "start": 170.39999999999998, "end": 174.64, "text": " shutdown happened, because we are a project that enables people to communicate online,", "tokens": [34927, 2011, 11, 570, 321, 366, 257, 1716, 300, 17077, 561, 281, 7890, 2950, 11], "temperature": 0.0, "avg_logprob": -0.1613609607403095, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0008206979837268591}, {"id": 27, "seek": 16476, "start": 174.64, "end": 180.88, "text": " well, it was one of the places that people wanted to go to communicate with people and to try to", "tokens": [731, 11, 309, 390, 472, 295, 264, 3190, 300, 561, 1415, 281, 352, 281, 7890, 365, 561, 293, 281, 853, 281], "temperature": 0.0, "avg_logprob": -0.1613609607403095, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0008206979837268591}, {"id": 28, "seek": 16476, "start": 180.88, "end": 187.64, "text": " reach out, create link, maintain link. So we had a lot of people suddenly who were like,", "tokens": [2524, 484, 11, 1884, 2113, 11, 6909, 2113, 13, 407, 321, 632, 257, 688, 295, 561, 5800, 567, 645, 411, 11], "temperature": 0.0, "avg_logprob": -0.1613609607403095, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0008206979837268591}, {"id": 29, "seek": 16476, "start": 187.64, "end": 191.68, "text": " I want to do an online stream. I want to put music for my friend to listen to. I want to do all", "tokens": [286, 528, 281, 360, 364, 2950, 4309, 13, 286, 528, 281, 829, 1318, 337, 452, 1277, 281, 2140, 281, 13, 286, 528, 281, 360, 439], "temperature": 0.0, "avg_logprob": -0.1613609607403095, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0008206979837268591}, {"id": 30, "seek": 19168, "start": 191.68, "end": 196.20000000000002, "text": " these things. And the second effect, we had a lot of people with time. So we're kind of one of", "tokens": [613, 721, 13, 400, 264, 1150, 1802, 11, 321, 632, 257, 688, 295, 561, 365, 565, 13, 407, 321, 434, 733, 295, 472, 295], "temperature": 0.0, "avg_logprob": -0.1548281692144439, "compression_ratio": 1.762081784386617, "no_speech_prob": 9.902851888909936e-05}, {"id": 31, "seek": 19168, "start": 196.20000000000002, "end": 199.76000000000002, "text": " those projects where you're like, oh, we like it. I like it. I'd like to look at it at some point,", "tokens": [729, 4455, 689, 291, 434, 411, 11, 1954, 11, 321, 411, 309, 13, 286, 411, 309, 13, 286, 1116, 411, 281, 574, 412, 309, 412, 512, 935, 11], "temperature": 0.0, "avg_logprob": -0.1548281692144439, "compression_ratio": 1.762081784386617, "no_speech_prob": 9.902851888909936e-05}, {"id": 32, "seek": 19168, "start": 199.76000000000002, "end": 204.88, "text": " but I'm too busy and suddenly I have time. So people starting using it, submitting a lot of", "tokens": [457, 286, 478, 886, 5856, 293, 5800, 286, 362, 565, 13, 407, 561, 2891, 1228, 309, 11, 31836, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.1548281692144439, "compression_ratio": 1.762081784386617, "no_speech_prob": 9.902851888909936e-05}, {"id": 33, "seek": 19168, "start": 204.88, "end": 211.24, "text": " issues and well, we got busy. One of the things that we deal with so is because we didn't have", "tokens": [2663, 293, 731, 11, 321, 658, 5856, 13, 1485, 295, 264, 721, 300, 321, 2028, 365, 370, 307, 570, 321, 994, 380, 362], "temperature": 0.0, "avg_logprob": -0.1548281692144439, "compression_ratio": 1.762081784386617, "no_speech_prob": 9.902851888909936e-05}, {"id": 34, "seek": 19168, "start": 211.24, "end": 217.36, "text": " that kind of in-person meeting, someone who's the other code developer of the project decided", "tokens": [300, 733, 295, 294, 12, 10813, 3440, 11, 1580, 567, 311, 264, 661, 3089, 10754, 295, 264, 1716, 3047], "temperature": 0.0, "avg_logprob": -0.1548281692144439, "compression_ratio": 1.762081784386617, "no_speech_prob": 9.902851888909936e-05}, {"id": 35, "seek": 21736, "start": 217.36, "end": 221.88000000000002, "text": " that we should do an online workshop, which was the thing to do. And it was really good because", "tokens": [300, 321, 820, 360, 364, 2950, 13541, 11, 597, 390, 264, 551, 281, 360, 13, 400, 309, 390, 534, 665, 570], "temperature": 0.0, "avg_logprob": -0.13312721252441406, "compression_ratio": 1.794007490636704, "no_speech_prob": 9.452655649511144e-05}, {"id": 36, "seek": 21736, "start": 221.88000000000002, "end": 226.36, "text": " what it really allowed us is to get to meet our community. And I think one of the things that's", "tokens": [437, 309, 534, 4350, 505, 307, 281, 483, 281, 1677, 527, 1768, 13, 400, 286, 519, 472, 295, 264, 721, 300, 311], "temperature": 0.0, "avg_logprob": -0.13312721252441406, "compression_ratio": 1.794007490636704, "no_speech_prob": 9.452655649511144e-05}, {"id": 37, "seek": 21736, "start": 226.36, "end": 231.0, "text": " really nice with this project is that it's both a technical project, but a lot of our users are", "tokens": [534, 1481, 365, 341, 1716, 307, 300, 309, 311, 1293, 257, 6191, 1716, 11, 457, 257, 688, 295, 527, 5022, 366], "temperature": 0.0, "avg_logprob": -0.13312721252441406, "compression_ratio": 1.794007490636704, "no_speech_prob": 9.452655649511144e-05}, {"id": 38, "seek": 21736, "start": 231.0, "end": 236.96, "text": " actually not technical people. They're like people who have Burning Man Radio at the Burning Man", "tokens": [767, 406, 6191, 561, 13, 814, 434, 411, 561, 567, 362, 43905, 2458, 17296, 412, 264, 43905, 2458], "temperature": 0.0, "avg_logprob": -0.13312721252441406, "compression_ratio": 1.794007490636704, "no_speech_prob": 9.452655649511144e-05}, {"id": 39, "seek": 21736, "start": 236.96, "end": 243.8, "text": " thing. Some of the cute project we had was like, the top one was a network of community radios", "tokens": [551, 13, 2188, 295, 264, 4052, 1716, 321, 632, 390, 411, 11, 264, 1192, 472, 390, 257, 3209, 295, 1768, 2843, 2717], "temperature": 0.0, "avg_logprob": -0.13312721252441406, "compression_ratio": 1.794007490636704, "no_speech_prob": 9.452655649511144e-05}, {"id": 40, "seek": 24380, "start": 243.8, "end": 248.92000000000002, "text": " in Barcelona where they literally have trucks that they bring to different neighborhoods to", "tokens": [294, 21247, 689, 436, 3736, 362, 16156, 300, 436, 1565, 281, 819, 20052, 281], "temperature": 0.0, "avg_logprob": -0.13210973178639132, "compression_ratio": 1.592274678111588, "no_speech_prob": 2.665872307261452e-05}, {"id": 41, "seek": 24380, "start": 248.92000000000002, "end": 257.44, "text": " do online reporting of what happens in the city. And the lower one was another Hungarian", "tokens": [360, 2950, 10031, 295, 437, 2314, 294, 264, 2307, 13, 400, 264, 3126, 472, 390, 1071, 38034], "temperature": 0.0, "avg_logprob": -0.13210973178639132, "compression_ratio": 1.592274678111588, "no_speech_prob": 2.665872307261452e-05}, {"id": 42, "seek": 24380, "start": 257.44, "end": 261.56, "text": " community radio. So that was really good to get to meet that. And I think we valued that a lot.", "tokens": [1768, 6477, 13, 407, 300, 390, 534, 665, 281, 483, 281, 1677, 300, 13, 400, 286, 519, 321, 22608, 300, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.13210973178639132, "compression_ratio": 1.592274678111588, "no_speech_prob": 2.665872307261452e-05}, {"id": 43, "seek": 24380, "start": 261.56, "end": 267.92, "text": " We have, of course, we have industrial users, but this is also one of the core motivations for", "tokens": [492, 362, 11, 295, 1164, 11, 321, 362, 9987, 5022, 11, 457, 341, 307, 611, 472, 295, 264, 4965, 39034, 337], "temperature": 0.0, "avg_logprob": -0.13210973178639132, "compression_ratio": 1.592274678111588, "no_speech_prob": 2.665872307261452e-05}, {"id": 44, "seek": 26792, "start": 267.92, "end": 274.52000000000004, "text": " the project for us. And then, eventually, another thing we did, again, by product of having a lot", "tokens": [264, 1716, 337, 505, 13, 400, 550, 11, 4728, 11, 1071, 551, 321, 630, 11, 797, 11, 538, 1674, 295, 1419, 257, 688], "temperature": 0.0, "avg_logprob": -0.13849889199564777, "compression_ratio": 1.6156462585034013, "no_speech_prob": 0.00013310795475263149}, {"id": 45, "seek": 26792, "start": 274.52000000000004, "end": 279.84000000000003, "text": " of time, which was mainly some working on it, was to write a programming book specialized in", "tokens": [295, 565, 11, 597, 390, 8704, 512, 1364, 322, 309, 11, 390, 281, 2464, 257, 9410, 1446, 19813, 294], "temperature": 0.0, "avg_logprob": -0.13849889199564777, "compression_ratio": 1.6156462585034013, "no_speech_prob": 0.00013310795475263149}, {"id": 46, "seek": 26792, "start": 279.84000000000003, "end": 285.76, "text": " audio stream, media stream, and how to use liquid soap for it. And it was very useful on many", "tokens": [6278, 4309, 11, 3021, 4309, 11, 293, 577, 281, 764, 6553, 14587, 337, 309, 13, 400, 309, 390, 588, 4420, 322, 867], "temperature": 0.0, "avg_logprob": -0.13849889199564777, "compression_ratio": 1.6156462585034013, "no_speech_prob": 0.00013310795475263149}, {"id": 47, "seek": 26792, "start": 285.76, "end": 290.56, "text": " levels. One of them is that it forced us to rethink our API and reorganize it. So you say,", "tokens": [4358, 13, 1485, 295, 552, 307, 300, 309, 7579, 505, 281, 34595, 527, 9362, 293, 41203, 1125, 309, 13, 407, 291, 584, 11], "temperature": 0.0, "avg_logprob": -0.13849889199564777, "compression_ratio": 1.6156462585034013, "no_speech_prob": 0.00013310795475263149}, {"id": 48, "seek": 26792, "start": 290.56, "end": 295.08000000000004, "text": " can we do that? What's a good example to do that? Well, actually, it's not clear. Let's make a nice", "tokens": [393, 321, 360, 300, 30, 708, 311, 257, 665, 1365, 281, 360, 300, 30, 1042, 11, 767, 11, 309, 311, 406, 1850, 13, 961, 311, 652, 257, 1481], "temperature": 0.0, "avg_logprob": -0.13849889199564777, "compression_ratio": 1.6156462585034013, "no_speech_prob": 0.00013310795475263149}, {"id": 49, "seek": 29508, "start": 295.08, "end": 300.08, "text": " module that can do that easily, document it. And also, it enabled the users a lot to be more", "tokens": [10088, 300, 393, 360, 300, 3612, 11, 4166, 309, 13, 400, 611, 11, 309, 15172, 264, 5022, 257, 688, 281, 312, 544], "temperature": 0.0, "avg_logprob": -0.11177916429480728, "compression_ratio": 1.5857740585774058, "no_speech_prob": 7.473141886293888e-05}, {"id": 50, "seek": 29508, "start": 300.08, "end": 305.76, "text": " confident because, as I said, most of our users are not programmers. And so they come to this,", "tokens": [6679, 570, 11, 382, 286, 848, 11, 881, 295, 527, 5022, 366, 406, 41504, 13, 400, 370, 436, 808, 281, 341, 11], "temperature": 0.0, "avg_logprob": -0.11177916429480728, "compression_ratio": 1.5857740585774058, "no_speech_prob": 7.473141886293888e-05}, {"id": 51, "seek": 29508, "start": 305.76, "end": 311.44, "text": " and they're like, whoa, never touch a line of code. How can I do? So that book was a really good", "tokens": [293, 436, 434, 411, 11, 13310, 11, 1128, 2557, 257, 1622, 295, 3089, 13, 1012, 393, 286, 360, 30, 407, 300, 1446, 390, 257, 534, 665], "temperature": 0.0, "avg_logprob": -0.11177916429480728, "compression_ratio": 1.5857740585774058, "no_speech_prob": 7.473141886293888e-05}, {"id": 52, "seek": 29508, "start": 311.44, "end": 320.91999999999996, "text": " starting point to get people interested and more confident with the project. So what did we do", "tokens": [2891, 935, 281, 483, 561, 3102, 293, 544, 6679, 365, 264, 1716, 13, 407, 437, 630, 321, 360], "temperature": 0.0, "avg_logprob": -0.11177916429480728, "compression_ratio": 1.5857740585774058, "no_speech_prob": 7.473141886293888e-05}, {"id": 53, "seek": 32092, "start": 320.92, "end": 327.64000000000004, "text": " for the new features, though? That's the part that the gist of the work we did. So first of all,", "tokens": [337, 264, 777, 4122, 11, 1673, 30, 663, 311, 264, 644, 300, 264, 290, 468, 295, 264, 589, 321, 630, 13, 407, 700, 295, 439, 11], "temperature": 0.0, "avg_logprob": -0.1245874563852946, "compression_ratio": 1.71875, "no_speech_prob": 0.0001414789876434952}, {"id": 54, "seek": 32092, "start": 327.64000000000004, "end": 334.68, "text": " we did a lot of language changes because for a long time, our focus was more on features. We only", "tokens": [321, 630, 257, 688, 295, 2856, 2962, 570, 337, 257, 938, 565, 11, 527, 1879, 390, 544, 322, 4122, 13, 492, 787], "temperature": 0.0, "avg_logprob": -0.1245874563852946, "compression_ratio": 1.71875, "no_speech_prob": 0.0001414789876434952}, {"id": 55, "seek": 32092, "start": 334.68, "end": 339.04, "text": " did a lot of output, a lot of input, a lot of different interesting operators. But when you", "tokens": [630, 257, 688, 295, 5598, 11, 257, 688, 295, 4846, 11, 257, 688, 295, 819, 1880, 19077, 13, 583, 562, 291], "temperature": 0.0, "avg_logprob": -0.1245874563852946, "compression_ratio": 1.71875, "no_speech_prob": 0.0001414789876434952}, {"id": 56, "seek": 32092, "start": 339.04, "end": 347.6, "text": " start to want to implement things that are more complex, you also need powerful language extension", "tokens": [722, 281, 528, 281, 4445, 721, 300, 366, 544, 3997, 11, 291, 611, 643, 4005, 2856, 10320], "temperature": 0.0, "avg_logprob": -0.1245874563852946, "compression_ratio": 1.71875, "no_speech_prob": 0.0001414789876434952}, {"id": 57, "seek": 34760, "start": 347.6, "end": 352.92, "text": " or toolbox. And also, we did a lot of FFMP integration. So those are the two things that I'm", "tokens": [420, 44593, 13, 400, 611, 11, 321, 630, 257, 688, 295, 479, 37, 12224, 10980, 13, 407, 729, 366, 264, 732, 721, 300, 286, 478], "temperature": 0.0, "avg_logprob": -0.14769307393876333, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.799012771807611e-05}, {"id": 58, "seek": 34760, "start": 352.92, "end": 358.36, "text": " going to talk next. And first, the language change. So yeah, more expressivity. You want to enable", "tokens": [516, 281, 751, 958, 13, 400, 700, 11, 264, 2856, 1319, 13, 407, 1338, 11, 544, 5109, 4253, 13, 509, 528, 281, 9528], "temperature": 0.0, "avg_logprob": -0.14769307393876333, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.799012771807611e-05}, {"id": 59, "seek": 34760, "start": 358.36, "end": 363.76000000000005, "text": " your users to write code that is nice, readable, that they can understand, that is powerful,", "tokens": [428, 5022, 281, 2464, 3089, 300, 307, 1481, 11, 49857, 11, 300, 436, 393, 1223, 11, 300, 307, 4005, 11], "temperature": 0.0, "avg_logprob": -0.14769307393876333, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.799012771807611e-05}, {"id": 60, "seek": 34760, "start": 363.76000000000005, "end": 368.24, "text": " but it doesn't have to have a million lines to do a simple thing. So simple things like that.", "tokens": [457, 309, 1177, 380, 362, 281, 362, 257, 2459, 3876, 281, 360, 257, 2199, 551, 13, 407, 2199, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.14769307393876333, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.799012771807611e-05}, {"id": 61, "seek": 34760, "start": 368.24, "end": 375.44, "text": " These are like spreads, you know, to split out a list. You have a list, you want to get the", "tokens": [1981, 366, 411, 25728, 11, 291, 458, 11, 281, 7472, 484, 257, 1329, 13, 509, 362, 257, 1329, 11, 291, 528, 281, 483, 264], "temperature": 0.0, "avg_logprob": -0.14769307393876333, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.799012771807611e-05}, {"id": 62, "seek": 37544, "start": 375.44, "end": 380.96, "text": " first element, last element, and whatever else is left as a remainder. We could do that before,", "tokens": [700, 4478, 11, 1036, 4478, 11, 293, 2035, 1646, 307, 1411, 382, 257, 29837, 13, 492, 727, 360, 300, 949, 11], "temperature": 0.0, "avg_logprob": -0.14690139445852726, "compression_ratio": 1.6041666666666667, "no_speech_prob": 4.672072100220248e-05}, {"id": 63, "seek": 37544, "start": 380.96, "end": 387.76, "text": " but we had to use functions and it was complicated. This really helps users just visualize the code", "tokens": [457, 321, 632, 281, 764, 6828, 293, 309, 390, 6179, 13, 639, 534, 3665, 5022, 445, 23273, 264, 3089], "temperature": 0.0, "avg_logprob": -0.14690139445852726, "compression_ratio": 1.6041666666666667, "no_speech_prob": 4.672072100220248e-05}, {"id": 64, "seek": 37544, "start": 387.76, "end": 392.72, "text": " and be like, all right, understand what this is doing, and have much less lines to write it.", "tokens": [293, 312, 411, 11, 439, 558, 11, 1223, 437, 341, 307, 884, 11, 293, 362, 709, 1570, 3876, 281, 2464, 309, 13], "temperature": 0.0, "avg_logprob": -0.14690139445852726, "compression_ratio": 1.6041666666666667, "no_speech_prob": 4.672072100220248e-05}, {"id": 65, "seek": 37544, "start": 392.72, "end": 402.0, "text": " We implemented a lot of types that were missing. So for instance, a null variable. A lot of that", "tokens": [492, 12270, 257, 688, 295, 3467, 300, 645, 5361, 13, 407, 337, 5197, 11, 257, 18184, 7006, 13, 316, 688, 295, 300], "temperature": 0.0, "avg_logprob": -0.14690139445852726, "compression_ratio": 1.6041666666666667, "no_speech_prob": 4.672072100220248e-05}, {"id": 66, "seek": 40200, "start": 402.0, "end": 407.76, "text": " will remain a sense of, of course, dynamic scripting languages like JavaScript or others. So we", "tokens": [486, 6222, 257, 2020, 295, 11, 295, 1164, 11, 8546, 5755, 278, 8650, 411, 15778, 420, 2357, 13, 407, 321], "temperature": 0.0, "avg_logprob": -0.17707210722423736, "compression_ratio": 1.6781115879828326, "no_speech_prob": 4.328161958255805e-05}, {"id": 67, "seek": 40200, "start": 407.76, "end": 412.84, "text": " didn't have a null value. We did a null value and we added a nice operator that says if you have a", "tokens": [994, 380, 362, 257, 18184, 2158, 13, 492, 630, 257, 18184, 2158, 293, 321, 3869, 257, 1481, 12973, 300, 1619, 498, 291, 362, 257], "temperature": 0.0, "avg_logprob": -0.17707210722423736, "compression_ratio": 1.6781115879828326, "no_speech_prob": 4.328161958255805e-05}, {"id": 68, "seek": 40200, "start": 412.84, "end": 419.24, "text": " null on X, if X is not null, it's a string, then you get X. If it's null, you get the string full.", "tokens": [18184, 322, 1783, 11, 498, 1783, 307, 406, 18184, 11, 309, 311, 257, 6798, 11, 550, 291, 483, 1783, 13, 759, 309, 311, 18184, 11, 291, 483, 264, 6798, 1577, 13], "temperature": 0.0, "avg_logprob": -0.17707210722423736, "compression_ratio": 1.6781115879828326, "no_speech_prob": 4.328161958255805e-05}, {"id": 69, "seek": 40200, "start": 419.24, "end": 426.16, "text": " Stuff like that. But when you start writing actual usable code, you need these things and they're", "tokens": [31347, 411, 300, 13, 583, 562, 291, 722, 3579, 3539, 29975, 3089, 11, 291, 643, 613, 721, 293, 436, 434], "temperature": 0.0, "avg_logprob": -0.17707210722423736, "compression_ratio": 1.6781115879828326, "no_speech_prob": 4.328161958255805e-05}, {"id": 70, "seek": 42616, "start": 426.16, "end": 433.52000000000004, "text": " very useful. Yeah, you can write function with optional argument and you can exactly say the", "tokens": [588, 4420, 13, 865, 11, 291, 393, 2464, 2445, 365, 17312, 6770, 293, 291, 393, 2293, 584, 264], "temperature": 0.0, "avg_logprob": -0.09964044392108917, "compression_ratio": 1.558011049723757, "no_speech_prob": 2.5859018933260813e-05}, {"id": 71, "seek": 42616, "start": 433.52000000000004, "end": 443.04, "text": " user didn't pass an argument. That's just basic programming language features. The other thing", "tokens": [4195, 994, 380, 1320, 364, 6770, 13, 663, 311, 445, 3875, 9410, 2856, 4122, 13, 440, 661, 551], "temperature": 0.0, "avg_logprob": -0.09964044392108917, "compression_ratio": 1.558011049723757, "no_speech_prob": 2.5859018933260813e-05}, {"id": 72, "seek": 42616, "start": 443.04, "end": 450.8, "text": " we did that was very useful is a new module syntax. That basically means that any value in the", "tokens": [321, 630, 300, 390, 588, 4420, 307, 257, 777, 10088, 28431, 13, 663, 1936, 1355, 300, 604, 2158, 294, 264], "temperature": 0.0, "avg_logprob": -0.09964044392108917, "compression_ratio": 1.558011049723757, "no_speech_prob": 2.5859018933260813e-05}, {"id": 73, "seek": 45080, "start": 450.8, "end": 457.28000000000003, "text": " language can be attached methods or attributes to it. So here you have a string and that string", "tokens": [2856, 393, 312, 8570, 7150, 420, 17212, 281, 309, 13, 407, 510, 291, 362, 257, 6798, 293, 300, 6798], "temperature": 0.0, "avg_logprob": -0.1636105091013807, "compression_ratio": 1.6926406926406927, "no_speech_prob": 1.4966926755732857e-05}, {"id": 74, "seek": 45080, "start": 457.28000000000003, "end": 465.2, "text": " has two methods. Well, attributes here, duration, floating number, and BPM. It's basically an object", "tokens": [575, 732, 7150, 13, 1042, 11, 17212, 510, 11, 16365, 11, 12607, 1230, 11, 293, 363, 18819, 13, 467, 311, 1936, 364, 2657], "temperature": 0.0, "avg_logprob": -0.1636105091013807, "compression_ratio": 1.6926406926406927, "no_speech_prob": 1.4966926755732857e-05}, {"id": 75, "seek": 45080, "start": 465.2, "end": 472.0, "text": " oriented ID, but not really an object. More like JavaScript hash, I guess. And that means that you", "tokens": [21841, 7348, 11, 457, 406, 534, 364, 2657, 13, 5048, 411, 15778, 22019, 11, 286, 2041, 13, 400, 300, 1355, 300, 291], "temperature": 0.0, "avg_logprob": -0.1636105091013807, "compression_ratio": 1.6926406926406927, "no_speech_prob": 1.4966926755732857e-05}, {"id": 76, "seek": 45080, "start": 472.0, "end": 478.56, "text": " can query the song.duration and get the floating point duration or you can print the song title", "tokens": [393, 14581, 264, 2153, 13, 67, 8167, 293, 483, 264, 12607, 935, 16365, 420, 291, 393, 4482, 264, 2153, 4876], "temperature": 0.0, "avg_logprob": -0.1636105091013807, "compression_ratio": 1.6926406926406927, "no_speech_prob": 1.4966926755732857e-05}, {"id": 77, "seek": 47856, "start": 478.56, "end": 486.16, "text": " as a string using the underlying value. That was really useful because when you want to create", "tokens": [382, 257, 6798, 1228, 264, 14217, 2158, 13, 663, 390, 534, 4420, 570, 562, 291, 528, 281, 1884], "temperature": 0.0, "avg_logprob": -0.09972544922225776, "compression_ratio": 1.7092511013215859, "no_speech_prob": 3.218199344701134e-05}, {"id": 78, "seek": 47856, "start": 486.16, "end": 491.52, "text": " something that's easy to use for user, you need to structure your language. You need to have modules", "tokens": [746, 300, 311, 1858, 281, 764, 337, 4195, 11, 291, 643, 281, 3877, 428, 2856, 13, 509, 643, 281, 362, 16679], "temperature": 0.0, "avg_logprob": -0.09972544922225776, "compression_ratio": 1.7092511013215859, "no_speech_prob": 3.218199344701134e-05}, {"id": 79, "seek": 47856, "start": 491.52, "end": 496.16, "text": " and you need to have functions in those modules. Also, another typical case is that now you can", "tokens": [293, 291, 643, 281, 362, 6828, 294, 729, 16679, 13, 2743, 11, 1071, 7476, 1389, 307, 300, 586, 291, 393], "temperature": 0.0, "avg_logprob": -0.09972544922225776, "compression_ratio": 1.7092511013215859, "no_speech_prob": 3.218199344701134e-05}, {"id": 80, "seek": 47856, "start": 496.16, "end": 502.08, "text": " specialize things. So you have sources that have different functions. So all sources have a skip", "tokens": [37938, 721, 13, 407, 291, 362, 7139, 300, 362, 819, 6828, 13, 407, 439, 7139, 362, 257, 10023], "temperature": 0.0, "avg_logprob": -0.09972544922225776, "compression_ratio": 1.7092511013215859, "no_speech_prob": 3.218199344701134e-05}, {"id": 81, "seek": 50208, "start": 502.08, "end": 508.71999999999997, "text": " function. It means that you can get to the next track in your stream, but you may have sources", "tokens": [2445, 13, 467, 1355, 300, 291, 393, 483, 281, 264, 958, 2837, 294, 428, 4309, 11, 457, 291, 815, 362, 7139], "temperature": 0.0, "avg_logprob": -0.08855027092827691, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.3209752069087699e-05}, {"id": 82, "seek": 50208, "start": 508.71999999999997, "end": 515.68, "text": " that have specific function. So for instance, you can have a source that can insert metadata", "tokens": [300, 362, 2685, 2445, 13, 407, 337, 5197, 11, 291, 393, 362, 257, 4009, 300, 393, 8969, 26603], "temperature": 0.0, "avg_logprob": -0.08855027092827691, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.3209752069087699e-05}, {"id": 83, "seek": 50208, "start": 515.68, "end": 521.36, "text": " that's created with this operator. It will be added a new function that's called insert metadata,", "tokens": [300, 311, 2942, 365, 341, 12973, 13, 467, 486, 312, 3869, 257, 777, 2445, 300, 311, 1219, 8969, 26603, 11], "temperature": 0.0, "avg_logprob": -0.08855027092827691, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.3209752069087699e-05}, {"id": 84, "seek": 50208, "start": 521.92, "end": 529.28, "text": " and now you can use it. So instead of having a billion of general calls that are API based,", "tokens": [293, 586, 291, 393, 764, 309, 13, 407, 2602, 295, 1419, 257, 5218, 295, 2674, 5498, 300, 366, 9362, 2361, 11], "temperature": 0.0, "avg_logprob": -0.08855027092827691, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.3209752069087699e-05}, {"id": 85, "seek": 52928, "start": 529.28, "end": 536.9599999999999, "text": " you can start really attaching specific use to specific variables and it makes things more compact,", "tokens": [291, 393, 722, 534, 39074, 2685, 764, 281, 2685, 9102, 293, 309, 1669, 721, 544, 14679, 11], "temperature": 0.0, "avg_logprob": -0.11165002414158412, "compression_ratio": 1.5648535564853556, "no_speech_prob": 2.8390677471179515e-05}, {"id": 86, "seek": 52928, "start": 537.68, "end": 545.04, "text": " more specialized, and very useful for cleaning up your API. Another thing we did after that", "tokens": [544, 19813, 11, 293, 588, 4420, 337, 8924, 493, 428, 9362, 13, 3996, 551, 321, 630, 934, 300], "temperature": 0.0, "avg_logprob": -0.11165002414158412, "compression_ratio": 1.5648535564853556, "no_speech_prob": 2.8390677471179515e-05}, {"id": 87, "seek": 52928, "start": 545.04, "end": 549.68, "text": " with the module is that now we were able to describe high level things. So one of those", "tokens": [365, 264, 10088, 307, 300, 586, 321, 645, 1075, 281, 6786, 1090, 1496, 721, 13, 407, 472, 295, 729], "temperature": 0.0, "avg_logprob": -0.11165002414158412, "compression_ratio": 1.5648535564853556, "no_speech_prob": 2.8390677471179515e-05}, {"id": 88, "seek": 52928, "start": 549.68, "end": 555.68, "text": " things that's really painful in static ID type language is parsing JSON. Why? Because JSON can", "tokens": [721, 300, 311, 534, 11697, 294, 13437, 7348, 2010, 2856, 307, 21156, 278, 31828, 13, 1545, 30, 1436, 31828, 393], "temperature": 0.0, "avg_logprob": -0.11165002414158412, "compression_ratio": 1.5648535564853556, "no_speech_prob": 2.8390677471179515e-05}, {"id": 89, "seek": 55568, "start": 555.68, "end": 561.76, "text": " be anything, and we really want to know that name is a string. We really want to know that name is", "tokens": [312, 1340, 11, 293, 321, 534, 528, 281, 458, 300, 1315, 307, 257, 6798, 13, 492, 534, 528, 281, 458, 300, 1315, 307], "temperature": 0.0, "avg_logprob": -0.13977491660196273, "compression_ratio": 1.756554307116105, "no_speech_prob": 5.222986510489136e-05}, {"id": 90, "seek": 55568, "start": 561.76, "end": 566.4, "text": " a version. So in language like OKMOR you have to parse an object, iterate through the keys,", "tokens": [257, 3037, 13, 407, 294, 2856, 411, 2264, 44, 2483, 291, 362, 281, 48377, 364, 2657, 11, 44497, 807, 264, 9317, 11], "temperature": 0.0, "avg_logprob": -0.13977491660196273, "compression_ratio": 1.756554307116105, "no_speech_prob": 5.222986510489136e-05}, {"id": 91, "seek": 55568, "start": 566.4, "end": 570.16, "text": " validate that is a string, and every branch of that you need to think of what you're doing.", "tokens": [29562, 300, 307, 257, 6798, 11, 293, 633, 9819, 295, 300, 291, 643, 281, 519, 295, 437, 291, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.13977491660196273, "compression_ratio": 1.756554307116105, "no_speech_prob": 5.222986510489136e-05}, {"id": 92, "seek": 55568, "start": 571.28, "end": 576.16, "text": " And our users, again, not programmers. So what do we do? We try to find a primitive that's", "tokens": [400, 527, 5022, 11, 797, 11, 406, 41504, 13, 407, 437, 360, 321, 360, 30, 492, 853, 281, 915, 257, 28540, 300, 311], "temperature": 0.0, "avg_logprob": -0.13977491660196273, "compression_ratio": 1.756554307116105, "no_speech_prob": 5.222986510489136e-05}, {"id": 93, "seek": 55568, "start": 577.12, "end": 583.28, "text": " readable and easy to use. So what are you reading here? You're reading a parsing statement that", "tokens": [49857, 293, 1858, 281, 764, 13, 407, 437, 366, 291, 3760, 510, 30, 509, 434, 3760, 257, 21156, 278, 5629, 300], "temperature": 0.0, "avg_logprob": -0.13977491660196273, "compression_ratio": 1.756554307116105, "no_speech_prob": 5.222986510489136e-05}, {"id": 94, "seek": 58328, "start": 583.28, "end": 589.12, "text": " says I want to parse and I want to get a module that's going to have a name, a version, and another", "tokens": [1619, 286, 528, 281, 48377, 293, 286, 528, 281, 483, 257, 10088, 300, 311, 516, 281, 362, 257, 1315, 11, 257, 3037, 11, 293, 1071], "temperature": 0.0, "avg_logprob": -0.09168741779942666, "compression_ratio": 1.954732510288066, "no_speech_prob": 2.045894871116616e-05}, {"id": 95, "seek": 58328, "start": 589.12, "end": 594.56, "text": " script attribute that is itself a module that has a test function. It's what you get in a package", "tokens": [5755, 19667, 300, 307, 2564, 257, 10088, 300, 575, 257, 1500, 2445, 13, 467, 311, 437, 291, 483, 294, 257, 7372], "temperature": 0.0, "avg_logprob": -0.09168741779942666, "compression_ratio": 1.954732510288066, "no_speech_prob": 2.045894871116616e-05}, {"id": 96, "seek": 58328, "start": 594.56, "end": 601.6, "text": " that JSON for node modules. And this is a type annotation that says I want the name to be a", "tokens": [300, 31828, 337, 9984, 16679, 13, 400, 341, 307, 257, 2010, 48654, 300, 1619, 286, 528, 264, 1315, 281, 312, 257], "temperature": 0.0, "avg_logprob": -0.09168741779942666, "compression_ratio": 1.954732510288066, "no_speech_prob": 2.045894871116616e-05}, {"id": 97, "seek": 58328, "start": 601.6, "end": 606.64, "text": " string, the version to be a string, and the script to be a module with a test that's a string.", "tokens": [6798, 11, 264, 3037, 281, 312, 257, 6798, 11, 293, 264, 5755, 281, 312, 257, 10088, 365, 257, 1500, 300, 311, 257, 6798, 13], "temperature": 0.0, "avg_logprob": -0.09168741779942666, "compression_ratio": 1.954732510288066, "no_speech_prob": 2.045894871116616e-05}, {"id": 98, "seek": 58328, "start": 607.4399999999999, "end": 611.52, "text": " And at runtime we're going to take all this information, we're going to try to parse this,", "tokens": [400, 412, 34474, 321, 434, 516, 281, 747, 439, 341, 1589, 11, 321, 434, 516, 281, 853, 281, 48377, 341, 11], "temperature": 0.0, "avg_logprob": -0.09168741779942666, "compression_ratio": 1.954732510288066, "no_speech_prob": 2.045894871116616e-05}, {"id": 99, "seek": 61152, "start": 611.52, "end": 616.24, "text": " and we're going to do two things. If we have what we need in the JSON, you can go on with your", "tokens": [293, 321, 434, 516, 281, 360, 732, 721, 13, 759, 321, 362, 437, 321, 643, 294, 264, 31828, 11, 291, 393, 352, 322, 365, 428], "temperature": 0.0, "avg_logprob": -0.10532714118642256, "compression_ratio": 1.6366906474820144, "no_speech_prob": 1.0781023775052745e-05}, {"id": 100, "seek": 61152, "start": 616.24, "end": 621.6, "text": " script. If we don't, we raise an error, you can cache the error and reason with it. But that", "tokens": [5755, 13, 759, 321, 500, 380, 11, 321, 5300, 364, 6713, 11, 291, 393, 19459, 264, 6713, 293, 1778, 365, 309, 13, 583, 300], "temperature": 0.0, "avg_logprob": -0.10532714118642256, "compression_ratio": 1.6366906474820144, "no_speech_prob": 1.0781023775052745e-05}, {"id": 101, "seek": 61152, "start": 621.6, "end": 627.1999999999999, "text": " really makes parsing of JSON more easier on the user, which is important because, again,", "tokens": [534, 1669, 21156, 278, 295, 31828, 544, 3571, 322, 264, 4195, 11, 597, 307, 1021, 570, 11, 797, 11], "temperature": 0.0, "avg_logprob": -0.10532714118642256, "compression_ratio": 1.6366906474820144, "no_speech_prob": 1.0781023775052745e-05}, {"id": 102, "seek": 61152, "start": 627.1999999999999, "end": 632.64, "text": " when you want to connect a lot of interconnected systems for streaming, you want to be able to", "tokens": [562, 291, 528, 281, 1745, 257, 688, 295, 36611, 3652, 337, 11791, 11, 291, 528, 281, 312, 1075, 281], "temperature": 0.0, "avg_logprob": -0.10532714118642256, "compression_ratio": 1.6366906474820144, "no_speech_prob": 1.0781023775052745e-05}, {"id": 103, "seek": 61152, "start": 632.64, "end": 638.96, "text": " talk to JSON API. So pretty useful. And we did the same for Yemo recently. So yeah,", "tokens": [751, 281, 31828, 9362, 13, 407, 1238, 4420, 13, 400, 321, 630, 264, 912, 337, 398, 36221, 3938, 13, 407, 1338, 11], "temperature": 0.0, "avg_logprob": -0.10532714118642256, "compression_ratio": 1.6366906474820144, "no_speech_prob": 1.0781023775052745e-05}, {"id": 104, "seek": 63896, "start": 638.96, "end": 645.9200000000001, "text": " you can do settings now. Yeah, those are the new features. There's more, but I don't want to spend", "tokens": [291, 393, 360, 6257, 586, 13, 865, 11, 729, 366, 264, 777, 4122, 13, 821, 311, 544, 11, 457, 286, 500, 380, 528, 281, 3496], "temperature": 0.0, "avg_logprob": -0.11317437345331366, "compression_ratio": 1.702127659574468, "no_speech_prob": 6.591464625671506e-05}, {"id": 105, "seek": 63896, "start": 645.9200000000001, "end": 650.4000000000001, "text": " too much time on it because the other part that I want to talk about that's exciting is the FFMPG", "tokens": [886, 709, 565, 322, 309, 570, 264, 661, 644, 300, 286, 528, 281, 751, 466, 300, 311, 4670, 307, 264, 479, 37, 12224, 38], "temperature": 0.0, "avg_logprob": -0.11317437345331366, "compression_ratio": 1.702127659574468, "no_speech_prob": 6.591464625671506e-05}, {"id": 106, "seek": 63896, "start": 650.4000000000001, "end": 654.5600000000001, "text": " integration. And that really started after Radio France because they had a strong need for it,", "tokens": [10980, 13, 400, 300, 534, 1409, 934, 17296, 6190, 570, 436, 632, 257, 2068, 643, 337, 309, 11], "temperature": 0.0, "avg_logprob": -0.11317437345331366, "compression_ratio": 1.702127659574468, "no_speech_prob": 6.591464625671506e-05}, {"id": 107, "seek": 63896, "start": 654.5600000000001, "end": 660.1600000000001, "text": " and we started looking at the API from FFMPG. And the thing with the API from FFMPG is that", "tokens": [293, 321, 1409, 1237, 412, 264, 9362, 490, 479, 37, 12224, 38, 13, 400, 264, 551, 365, 264, 9362, 490, 479, 37, 12224, 38, 307, 300], "temperature": 0.0, "avg_logprob": -0.11317437345331366, "compression_ratio": 1.702127659574468, "no_speech_prob": 6.591464625671506e-05}, {"id": 108, "seek": 63896, "start": 660.96, "end": 668.5600000000001, "text": " it's really good. It's amazingly good. It's all very low level in C. So for us, because I didn't", "tokens": [309, 311, 534, 665, 13, 467, 311, 31762, 665, 13, 467, 311, 439, 588, 2295, 1496, 294, 383, 13, 407, 337, 505, 11, 570, 286, 994, 380], "temperature": 0.0, "avg_logprob": -0.11317437345331366, "compression_ratio": 1.702127659574468, "no_speech_prob": 6.591464625671506e-05}, {"id": 109, "seek": 66856, "start": 668.56, "end": 675.28, "text": " mention, but LiquidSup is implemented in OCaml, so we need to speak to low level implementation", "tokens": [2152, 11, 457, 38943, 50, 1010, 307, 12270, 294, 422, 31030, 75, 11, 370, 321, 643, 281, 1710, 281, 2295, 1496, 11420], "temperature": 0.0, "avg_logprob": -0.1708895492553711, "compression_ratio": 1.5925925925925926, "no_speech_prob": 7.002623897278681e-05}, {"id": 110, "seek": 66856, "start": 675.28, "end": 682.16, "text": " to really be efficient. We can talk to Pearl or to whatever, Python. And this C, it's really", "tokens": [281, 534, 312, 7148, 13, 492, 393, 751, 281, 24639, 420, 281, 2035, 11, 15329, 13, 400, 341, 383, 11, 309, 311, 534], "temperature": 0.0, "avg_logprob": -0.1708895492553711, "compression_ratio": 1.5925925925925926, "no_speech_prob": 7.002623897278681e-05}, {"id": 111, "seek": 66856, "start": 682.16, "end": 687.5999999999999, "text": " simple for us. But it's also extremely abstract. And that really helps us because, again, we want", "tokens": [2199, 337, 505, 13, 583, 309, 311, 611, 4664, 12649, 13, 400, 300, 534, 3665, 505, 570, 11, 797, 11, 321, 528], "temperature": 0.0, "avg_logprob": -0.1708895492553711, "compression_ratio": 1.5925925925925926, "no_speech_prob": 7.002623897278681e-05}, {"id": 112, "seek": 66856, "start": 687.5999999999999, "end": 693.4399999999999, "text": " to do what we do well, which is the programming language side, the logic, the typing, the functions.", "tokens": [281, 360, 437, 321, 360, 731, 11, 597, 307, 264, 9410, 2856, 1252, 11, 264, 9952, 11, 264, 18444, 11, 264, 6828, 13], "temperature": 0.0, "avg_logprob": -0.1708895492553711, "compression_ratio": 1.5925925925925926, "no_speech_prob": 7.002623897278681e-05}, {"id": 113, "seek": 69344, "start": 693.44, "end": 699.2800000000001, "text": " But we're not specialists in multimedia implementation. We don't want to do that. We want", "tokens": [583, 321, 434, 406, 25476, 294, 49202, 11420, 13, 492, 500, 380, 528, 281, 360, 300, 13, 492, 528], "temperature": 0.0, "avg_logprob": -0.07435562042962937, "compression_ratio": 1.5397489539748954, "no_speech_prob": 5.644658085657284e-05}, {"id": 114, "seek": 69344, "start": 699.2800000000001, "end": 705.44, "text": " to find people who do it better than us and interface with it. So that's the API for a FFMPG", "tokens": [281, 915, 561, 567, 360, 309, 1101, 813, 505, 293, 9226, 365, 309, 13, 407, 300, 311, 264, 9362, 337, 257, 479, 37, 12224, 38], "temperature": 0.0, "avg_logprob": -0.07435562042962937, "compression_ratio": 1.5397489539748954, "no_speech_prob": 5.644658085657284e-05}, {"id": 115, "seek": 69344, "start": 705.44, "end": 710.6400000000001, "text": " packet, which is a little tiny bit of encoded data. It contains, I don't know, an MP3 frame,", "tokens": [20300, 11, 597, 307, 257, 707, 5870, 857, 295, 2058, 12340, 1412, 13, 467, 8306, 11, 286, 500, 380, 458, 11, 364, 14146, 18, 3920, 11], "temperature": 0.0, "avg_logprob": -0.07435562042962937, "compression_ratio": 1.5397489539748954, "no_speech_prob": 5.644658085657284e-05}, {"id": 116, "seek": 69344, "start": 710.6400000000001, "end": 716.6400000000001, "text": " a video, A or B frame, all the abstract things I don't want to know about. But it's going to", "tokens": [257, 960, 11, 316, 420, 363, 3920, 11, 439, 264, 12649, 721, 286, 500, 380, 528, 281, 458, 466, 13, 583, 309, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.07435562042962937, "compression_ratio": 1.5397489539748954, "no_speech_prob": 5.644658085657284e-05}, {"id": 117, "seek": 71664, "start": 716.64, "end": 724.3199999999999, "text": " tell me two things. It's going to tell me this is your data. This is your pointer to a presentation", "tokens": [980, 385, 732, 721, 13, 467, 311, 516, 281, 980, 385, 341, 307, 428, 1412, 13, 639, 307, 428, 23918, 281, 257, 5860], "temperature": 0.0, "avg_logprob": -0.0916991195058435, "compression_ratio": 1.7712177121771218, "no_speech_prob": 1.2211245120852254e-05}, {"id": 118, "seek": 71664, "start": 724.3199999999999, "end": 730.16, "text": " timestamp. And that thing here tells me this is the time at which you want to insert this packet", "tokens": [49108, 1215, 13, 400, 300, 551, 510, 5112, 385, 341, 307, 264, 565, 412, 597, 291, 528, 281, 8969, 341, 20300], "temperature": 0.0, "avg_logprob": -0.0916991195058435, "compression_ratio": 1.7712177121771218, "no_speech_prob": 1.2211245120852254e-05}, {"id": 119, "seek": 71664, "start": 730.16, "end": 735.12, "text": " in your stream. This is the data. That's what I need to know. Because then we can build a stream", "tokens": [294, 428, 4309, 13, 639, 307, 264, 1412, 13, 663, 311, 437, 286, 643, 281, 458, 13, 1436, 550, 321, 393, 1322, 257, 4309], "temperature": 0.0, "avg_logprob": -0.0916991195058435, "compression_ratio": 1.7712177121771218, "no_speech_prob": 1.2211245120852254e-05}, {"id": 120, "seek": 71664, "start": 735.12, "end": 739.12, "text": " with it. We can pass the packet around to our different operators, not even knowing what they", "tokens": [365, 309, 13, 492, 393, 1320, 264, 20300, 926, 281, 527, 819, 19077, 11, 406, 754, 5276, 437, 436], "temperature": 0.0, "avg_logprob": -0.0916991195058435, "compression_ratio": 1.7712177121771218, "no_speech_prob": 1.2211245120852254e-05}, {"id": 121, "seek": 71664, "start": 739.12, "end": 745.36, "text": " contain. The other thing that FFMPG really, yeah, so that's why we started doing, we started", "tokens": [5304, 13, 440, 661, 551, 300, 479, 37, 12224, 38, 534, 11, 1338, 11, 370, 300, 311, 983, 321, 1409, 884, 11, 321, 1409], "temperature": 0.0, "avg_logprob": -0.0916991195058435, "compression_ratio": 1.7712177121771218, "no_speech_prob": 1.2211245120852254e-05}, {"id": 122, "seek": 74536, "start": 745.36, "end": 752.08, "text": " implementing a new encoder that was basically reflecting everything that you see as a parameter", "tokens": [18114, 257, 777, 2058, 19866, 300, 390, 1936, 23543, 1203, 300, 291, 536, 382, 257, 13075], "temperature": 0.0, "avg_logprob": -0.07420927478421119, "compression_ratio": 1.6194690265486726, "no_speech_prob": 1.54411063704174e-05}, {"id": 123, "seek": 74536, "start": 752.08, "end": 759.6, "text": " in the FFMPG command line. We think that we support it as an option in those encoders.", "tokens": [294, 264, 479, 37, 12224, 38, 5622, 1622, 13, 492, 519, 300, 321, 1406, 309, 382, 364, 3614, 294, 729, 2058, 378, 433, 13], "temperature": 0.0, "avg_logprob": -0.07420927478421119, "compression_ratio": 1.6194690265486726, "no_speech_prob": 1.54411063704174e-05}, {"id": 124, "seek": 74536, "start": 760.72, "end": 765.36, "text": " And why do we think that is because another thing that FFMPG really does really well", "tokens": [400, 983, 360, 321, 519, 300, 307, 570, 1071, 551, 300, 479, 37, 12224, 38, 534, 775, 534, 731], "temperature": 0.0, "avg_logprob": -0.07420927478421119, "compression_ratio": 1.6194690265486726, "no_speech_prob": 1.54411063704174e-05}, {"id": 125, "seek": 74536, "start": 765.36, "end": 773.36, "text": " is describing their API. So I'm sorry, that's not very readable. But that's a C structure that has", "tokens": [307, 16141, 641, 9362, 13, 407, 286, 478, 2597, 11, 300, 311, 406, 588, 49857, 13, 583, 300, 311, 257, 383, 3877, 300, 575], "temperature": 0.0, "avg_logprob": -0.07420927478421119, "compression_ratio": 1.6194690265486726, "no_speech_prob": 1.54411063704174e-05}, {"id": 126, "seek": 77336, "start": 773.36, "end": 783.52, "text": " all the parameters name here for H264 encoders, description, type, somewhere, and minimum,", "tokens": [439, 264, 9834, 1315, 510, 337, 389, 10880, 19, 2058, 378, 433, 11, 3855, 11, 2010, 11, 4079, 11, 293, 7285, 11], "temperature": 0.0, "avg_logprob": -0.11964595958750734, "compression_ratio": 1.5965665236051503, "no_speech_prob": 2.1097839635331184e-05}, {"id": 127, "seek": 77336, "start": 783.52, "end": 789.92, "text": " maximum value, everything we need to basically write an interface to it. It also does it for filters.", "tokens": [6674, 2158, 11, 1203, 321, 643, 281, 1936, 2464, 364, 9226, 281, 309, 13, 467, 611, 775, 309, 337, 15995, 13], "temperature": 0.0, "avg_logprob": -0.11964595958750734, "compression_ratio": 1.5965665236051503, "no_speech_prob": 2.1097839635331184e-05}, {"id": 128, "seek": 77336, "start": 790.88, "end": 796.16, "text": " Again, not very readable. Sorry about that. But it's basically a programmatic interface", "tokens": [3764, 11, 406, 588, 49857, 13, 4919, 466, 300, 13, 583, 309, 311, 1936, 257, 1461, 25915, 9226], "temperature": 0.0, "avg_logprob": -0.11964595958750734, "compression_ratio": 1.5965665236051503, "no_speech_prob": 2.1097839635331184e-05}, {"id": 129, "seek": 77336, "start": 796.16, "end": 802.64, "text": " to everything you need to know about parameters for FFMPG. That's also not readable. Great.", "tokens": [281, 1203, 291, 643, 281, 458, 466, 9834, 337, 479, 37, 12224, 38, 13, 663, 311, 611, 406, 49857, 13, 3769, 13], "temperature": 0.0, "avg_logprob": -0.11964595958750734, "compression_ratio": 1.5965665236051503, "no_speech_prob": 2.1097839635331184e-05}, {"id": 130, "seek": 80264, "start": 802.64, "end": 809.52, "text": " So then what we can do is this is an FFMPG filter implemented in liquid soap. And if you could", "tokens": [407, 550, 437, 321, 393, 360, 307, 341, 307, 364, 479, 37, 12224, 38, 6608, 12270, 294, 6553, 14587, 13, 400, 498, 291, 727], "temperature": 0.0, "avg_logprob": -0.14222616078902264, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.580774839268997e-05}, {"id": 131, "seek": 80264, "start": 809.52, "end": 814.96, "text": " read well, you would see that every parameter is in the filter, like speed, is a floating point,", "tokens": [1401, 731, 11, 291, 576, 536, 300, 633, 13075, 307, 294, 264, 6608, 11, 411, 3073, 11, 307, 257, 12607, 935, 11], "temperature": 0.0, "avg_logprob": -0.14222616078902264, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.580774839268997e-05}, {"id": 132, "seek": 80264, "start": 814.96, "end": 820.8, "text": " optional. It has no value default. They saw no value default. Sometimes they don't.", "tokens": [17312, 13, 467, 575, 572, 2158, 7576, 13, 814, 1866, 572, 2158, 7576, 13, 4803, 436, 500, 380, 13], "temperature": 0.0, "avg_logprob": -0.14222616078902264, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.580774839268997e-05}, {"id": 133, "seek": 80264, "start": 821.36, "end": 827.76, "text": " We get this information from the FFMPG C API, and we can plug into it immediately and be very", "tokens": [492, 483, 341, 1589, 490, 264, 479, 37, 12224, 38, 383, 9362, 11, 293, 321, 393, 5452, 666, 309, 4258, 293, 312, 588], "temperature": 0.0, "avg_logprob": -0.14222616078902264, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.580774839268997e-05}, {"id": 134, "seek": 82776, "start": 827.76, "end": 833.76, "text": " confident that we're using it well. And so one of the things it allows us to do is to actually", "tokens": [6679, 300, 321, 434, 1228, 309, 731, 13, 400, 370, 472, 295, 264, 721, 309, 4045, 505, 281, 360, 307, 281, 767], "temperature": 0.0, "avg_logprob": -0.08851534770085262, "compression_ratio": 1.7117437722419928, "no_speech_prob": 1.129560132540064e-05}, {"id": 135, "seek": 82776, "start": 833.76, "end": 840.24, "text": " have scripted manipulation of FFMPG primitive like filters. So we take a source and we want to", "tokens": [362, 5755, 292, 26475, 295, 479, 37, 12224, 38, 28540, 411, 15995, 13, 407, 321, 747, 257, 4009, 293, 321, 528, 281], "temperature": 0.0, "avg_logprob": -0.08851534770085262, "compression_ratio": 1.7117437722419928, "no_speech_prob": 1.129560132540064e-05}, {"id": 136, "seek": 82776, "start": 840.24, "end": 846.88, "text": " define a filter that is a flanger followed by a high pass and then output it. So you need a graph.", "tokens": [6964, 257, 6608, 300, 307, 257, 932, 3176, 6263, 538, 257, 1090, 1320, 293, 550, 5598, 309, 13, 407, 291, 643, 257, 4295, 13], "temperature": 0.0, "avg_logprob": -0.08851534770085262, "compression_ratio": 1.7117437722419928, "no_speech_prob": 1.129560132540064e-05}, {"id": 137, "seek": 82776, "start": 846.88, "end": 851.28, "text": " That's just part of the C API. You need a source. You create an audio input from it. That's the", "tokens": [663, 311, 445, 644, 295, 264, 383, 9362, 13, 509, 643, 257, 4009, 13, 509, 1884, 364, 6278, 4846, 490, 309, 13, 663, 311, 264], "temperature": 0.0, "avg_logprob": -0.08851534770085262, "compression_ratio": 1.7117437722419928, "no_speech_prob": 1.129560132540064e-05}, {"id": 138, "seek": 82776, "start": 851.28, "end": 855.92, "text": " FFMPG side. That's what they call an audio input. You pass it to the filter with the parameters.", "tokens": [479, 37, 12224, 38, 1252, 13, 663, 311, 437, 436, 818, 364, 6278, 4846, 13, 509, 1320, 309, 281, 264, 6608, 365, 264, 9834, 13], "temperature": 0.0, "avg_logprob": -0.08851534770085262, "compression_ratio": 1.7117437722419928, "no_speech_prob": 1.129560132540064e-05}, {"id": 139, "seek": 85592, "start": 855.92, "end": 860.88, "text": " Everything is typed here, so we can check. That's the right value. And then you create an output.", "tokens": [5471, 307, 33941, 510, 11, 370, 321, 393, 1520, 13, 663, 311, 264, 558, 2158, 13, 400, 550, 291, 1884, 364, 5598, 13], "temperature": 0.0, "avg_logprob": -0.10557940426994772, "compression_ratio": 1.5884773662551441, "no_speech_prob": 3.697859574458562e-05}, {"id": 140, "seek": 85592, "start": 861.76, "end": 868.56, "text": " Run that. You have a high level description of your filter. I don't know if you all have manipulated", "tokens": [8950, 300, 13, 509, 362, 257, 1090, 1496, 3855, 295, 428, 6608, 13, 286, 500, 380, 458, 498, 291, 439, 362, 37161], "temperature": 0.0, "avg_logprob": -0.10557940426994772, "compression_ratio": 1.5884773662551441, "no_speech_prob": 3.697859574458562e-05}, {"id": 141, "seek": 85592, "start": 868.56, "end": 875.12, "text": " FFMPG filters, but when you want to do complex filters, they have a description graph that's", "tokens": [479, 37, 12224, 38, 15995, 11, 457, 562, 291, 528, 281, 360, 3997, 15995, 11, 436, 362, 257, 3855, 4295, 300, 311], "temperature": 0.0, "avg_logprob": -0.10557940426994772, "compression_ratio": 1.5884773662551441, "no_speech_prob": 3.697859574458562e-05}, {"id": 142, "seek": 85592, "start": 875.12, "end": 879.92, "text": " pretty hard to read. I'm used to that, so I'm biased. I can read these things easier, but also", "tokens": [1238, 1152, 281, 1401, 13, 286, 478, 1143, 281, 300, 11, 370, 286, 478, 28035, 13, 286, 393, 1401, 613, 721, 3571, 11, 457, 611], "temperature": 0.0, "avg_logprob": -0.10557940426994772, "compression_ratio": 1.5884773662551441, "no_speech_prob": 3.697859574458562e-05}, {"id": 143, "seek": 87992, "start": 879.92, "end": 886.4799999999999, "text": " it's kind of more descriptive. It's typed, too. So this is another filter. It takes an audio, splits", "tokens": [309, 311, 733, 295, 544, 42585, 13, 467, 311, 33941, 11, 886, 13, 407, 341, 307, 1071, 6608, 13, 467, 2516, 364, 6278, 11, 37741], "temperature": 0.0, "avg_logprob": -0.09741403248684466, "compression_ratio": 1.6494464944649447, "no_speech_prob": 1.1297454875602853e-05}, {"id": 144, "seek": 87992, "start": 886.4799999999999, "end": 892.0, "text": " it into two sources. One of them is going to go through a flanger. The other one is a high pass.", "tokens": [309, 666, 732, 7139, 13, 1485, 295, 552, 307, 516, 281, 352, 807, 257, 932, 3176, 13, 440, 661, 472, 307, 257, 1090, 1320, 13], "temperature": 0.0, "avg_logprob": -0.09741403248684466, "compression_ratio": 1.6494464944649447, "no_speech_prob": 1.1297454875602853e-05}, {"id": 145, "seek": 87992, "start": 892.64, "end": 895.5999999999999, "text": " This is some conversion that was required. I don't know why. And then you merge them back.", "tokens": [639, 307, 512, 14298, 300, 390, 4739, 13, 286, 500, 380, 458, 983, 13, 400, 550, 291, 22183, 552, 646, 13], "temperature": 0.0, "avg_logprob": -0.09741403248684466, "compression_ratio": 1.6494464944649447, "no_speech_prob": 1.1297454875602853e-05}, {"id": 146, "seek": 87992, "start": 896.3199999999999, "end": 900.88, "text": " So we're describing now a graph that branches out, do two filtering and comes back together.", "tokens": [407, 321, 434, 16141, 586, 257, 4295, 300, 14770, 484, 11, 360, 732, 30822, 293, 1487, 646, 1214, 13], "temperature": 0.0, "avg_logprob": -0.09741403248684466, "compression_ratio": 1.6494464944649447, "no_speech_prob": 1.1297454875602853e-05}, {"id": 147, "seek": 87992, "start": 901.92, "end": 904.0, "text": " This is a simple one, but you could use that to do, I don't know,", "tokens": [639, 307, 257, 2199, 472, 11, 457, 291, 727, 764, 300, 281, 360, 11, 286, 500, 380, 458, 11], "temperature": 0.0, "avg_logprob": -0.09741403248684466, "compression_ratio": 1.6494464944649447, "no_speech_prob": 1.1297454875602853e-05}, {"id": 148, "seek": 90400, "start": 904.0, "end": 912.4, "text": " a multi-band compressor, for instance. You can do that in FFMPG. It's just a little bit more", "tokens": [257, 4825, 12, 4235, 28765, 11, 337, 5197, 13, 509, 393, 360, 300, 294, 479, 37, 12224, 38, 13, 467, 311, 445, 257, 707, 857, 544], "temperature": 0.0, "avg_logprob": -0.10415953032824458, "compression_ratio": 1.5183673469387755, "no_speech_prob": 2.706517443584744e-05}, {"id": 149, "seek": 90400, "start": 912.4, "end": 918.96, "text": " structured and readable and also type safe. So next, I want to talk about how we implemented that.", "tokens": [18519, 293, 49857, 293, 611, 2010, 3273, 13, 407, 958, 11, 286, 528, 281, 751, 466, 577, 321, 12270, 300, 13], "temperature": 0.0, "avg_logprob": -0.10415953032824458, "compression_ratio": 1.5183673469387755, "no_speech_prob": 2.706517443584744e-05}, {"id": 150, "seek": 90400, "start": 919.84, "end": 926.8, "text": " Yeah, I still have some time. This is the timeline for us, infinite time. We started here,", "tokens": [865, 11, 286, 920, 362, 512, 565, 13, 639, 307, 264, 12933, 337, 505, 11, 13785, 565, 13, 492, 1409, 510, 11], "temperature": 0.0, "avg_logprob": -0.10415953032824458, "compression_ratio": 1.5183673469387755, "no_speech_prob": 2.706517443584744e-05}, {"id": 151, "seek": 90400, "start": 926.8, "end": 932.32, "text": " and we go all the way here. If you use your imagination, all these little horizontal dots", "tokens": [293, 321, 352, 439, 264, 636, 510, 13, 759, 291, 764, 428, 12938, 11, 439, 613, 707, 12750, 15026], "temperature": 0.0, "avg_logprob": -0.10415953032824458, "compression_ratio": 1.5183673469387755, "no_speech_prob": 2.706517443584744e-05}, {"id": 152, "seek": 93232, "start": 932.32, "end": 939.2, "text": " are audio packets that came from FFMPG. Vertical ones are video frame. This is your stream of data", "tokens": [366, 6278, 30364, 300, 1361, 490, 479, 37, 12224, 38, 13, 21044, 804, 2306, 366, 960, 3920, 13, 639, 307, 428, 4309, 295, 1412], "temperature": 0.0, "avg_logprob": -0.10826528448807565, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.00012303833500482142}, {"id": 153, "seek": 93232, "start": 940.08, "end": 946.1600000000001, "text": " that you're sending to an ice castle, anything. What we do is that we find the lowest common", "tokens": [300, 291, 434, 7750, 281, 364, 4435, 14114, 11, 1340, 13, 708, 321, 360, 307, 300, 321, 915, 264, 12437, 2689], "temperature": 0.0, "avg_logprob": -0.10826528448807565, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.00012303833500482142}, {"id": 154, "seek": 93232, "start": 946.1600000000001, "end": 953.2800000000001, "text": " denominator between the video rate and the audio rate. We need to find a little chunk of time that", "tokens": [20687, 1296, 264, 960, 3314, 293, 264, 6278, 3314, 13, 492, 643, 281, 915, 257, 707, 16635, 295, 565, 300], "temperature": 0.0, "avg_logprob": -0.10826528448807565, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.00012303833500482142}, {"id": 155, "seek": 93232, "start": 953.2800000000001, "end": 958.4000000000001, "text": " will contain the same amount of audio and data. Most of the time, with the parameters we have", "tokens": [486, 5304, 264, 912, 2372, 295, 6278, 293, 1412, 13, 4534, 295, 264, 565, 11, 365, 264, 9834, 321, 362], "temperature": 0.0, "avg_logprob": -0.10826528448807565, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.00012303833500482142}, {"id": 156, "seek": 95840, "start": 958.4, "end": 965.1999999999999, "text": " internally, it would be 0.04 seconds. That's what we call our frame. And then, the idea of the", "tokens": [19501, 11, 309, 576, 312, 1958, 13, 14565, 3949, 13, 663, 311, 437, 321, 818, 527, 3920, 13, 400, 550, 11, 264, 1558, 295, 264], "temperature": 0.0, "avg_logprob": -0.13346704171628368, "compression_ratio": 1.5793991416309012, "no_speech_prob": 1.668551158218179e-05}, {"id": 157, "seek": 95840, "start": 965.1999999999999, "end": 971.92, "text": " streaming loop, once you've parsed and prepared all your outputs, is to just recreate that frame", "tokens": [11791, 6367, 11, 1564, 291, 600, 21156, 292, 293, 4927, 439, 428, 23930, 11, 307, 281, 445, 25833, 300, 3920], "temperature": 0.0, "avg_logprob": -0.13346704171628368, "compression_ratio": 1.5793991416309012, "no_speech_prob": 1.668551158218179e-05}, {"id": 158, "seek": 95840, "start": 971.92, "end": 977.04, "text": " every 0.04 seconds, infinitely many times. That just creates your stream. And so,", "tokens": [633, 1958, 13, 14565, 3949, 11, 36227, 867, 1413, 13, 663, 445, 7829, 428, 4309, 13, 400, 370, 11], "temperature": 0.0, "avg_logprob": -0.13346704171628368, "compression_ratio": 1.5793991416309012, "no_speech_prob": 1.668551158218179e-05}, {"id": 159, "seek": 95840, "start": 978.72, "end": 983.28, "text": " here's an example. We have a simple script. It has two outputs. You want to save to a file and", "tokens": [510, 311, 364, 1365, 13, 492, 362, 257, 2199, 5755, 13, 467, 575, 732, 23930, 13, 509, 528, 281, 3155, 281, 257, 3991, 293], "temperature": 0.0, "avg_logprob": -0.13346704171628368, "compression_ratio": 1.5793991416309012, "no_speech_prob": 1.668551158218179e-05}, {"id": 160, "seek": 98328, "start": 983.28, "end": 988.9599999999999, "text": " send to an ice castle server. Fullback is an operator that will take the first source available.", "tokens": [2845, 281, 364, 4435, 14114, 7154, 13, 13841, 3207, 307, 364, 12973, 300, 486, 747, 264, 700, 4009, 2435, 13], "temperature": 0.0, "avg_logprob": -0.1169002428650856, "compression_ratio": 1.8066914498141264, "no_speech_prob": 3.642216688604094e-05}, {"id": 161, "seek": 98328, "start": 988.9599999999999, "end": 994.48, "text": " So, the first one is an input. It's a hardware. So, it's one of the operators we have that can", "tokens": [407, 11, 264, 700, 472, 307, 364, 4846, 13, 467, 311, 257, 8837, 13, 407, 11, 309, 311, 472, 295, 264, 19077, 321, 362, 300, 393], "temperature": 0.0, "avg_logprob": -0.1169002428650856, "compression_ratio": 1.8066914498141264, "no_speech_prob": 3.642216688604094e-05}, {"id": 162, "seek": 98328, "start": 994.48, "end": 1000.9599999999999, "text": " receive ice cast clients. So, let's say you want a DJ to connect to your radio. You can direct them", "tokens": [4774, 4435, 4193, 6982, 13, 407, 11, 718, 311, 584, 291, 528, 257, 13078, 281, 1745, 281, 428, 6477, 13, 509, 393, 2047, 552], "temperature": 0.0, "avg_logprob": -0.1169002428650856, "compression_ratio": 1.8066914498141264, "no_speech_prob": 3.642216688604094e-05}, {"id": 163, "seek": 98328, "start": 1000.9599999999999, "end": 1006.88, "text": " to this input, and it starts streaming. The fullback will stream that data immediately. If it's not", "tokens": [281, 341, 4846, 11, 293, 309, 3719, 11791, 13, 440, 1577, 3207, 486, 4309, 300, 1412, 4258, 13, 759, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.1169002428650856, "compression_ratio": 1.8066914498141264, "no_speech_prob": 3.642216688604094e-05}, {"id": 164, "seek": 98328, "start": 1006.88, "end": 1011.68, "text": " available, we have a queue of requests that you can. So, let's say you want to send a track to", "tokens": [2435, 11, 321, 362, 257, 18639, 295, 12475, 300, 291, 393, 13, 407, 11, 718, 311, 584, 291, 528, 281, 2845, 257, 2837, 281], "temperature": 0.0, "avg_logprob": -0.1169002428650856, "compression_ratio": 1.8066914498141264, "no_speech_prob": 3.642216688604094e-05}, {"id": 165, "seek": 101168, "start": 1011.68, "end": 1016.0799999999999, "text": " be played immediately after the following one. Every now and then, you can send a request here.", "tokens": [312, 3737, 4258, 934, 264, 3480, 472, 13, 2048, 586, 293, 550, 11, 291, 393, 2845, 257, 5308, 510, 13], "temperature": 0.0, "avg_logprob": -0.0947522955425715, "compression_ratio": 1.6245614035087719, "no_speech_prob": 2.8383490644046105e-05}, {"id": 166, "seek": 101168, "start": 1016.0799999999999, "end": 1021.4399999999999, "text": " Otherwise, we have a playlist of just files in the directory. And if that is not available,", "tokens": [10328, 11, 321, 362, 257, 16788, 295, 445, 7098, 294, 264, 21120, 13, 400, 498, 300, 307, 406, 2435, 11], "temperature": 0.0, "avg_logprob": -0.0947522955425715, "compression_ratio": 1.6245614035087719, "no_speech_prob": 2.8383490644046105e-05}, {"id": 167, "seek": 101168, "start": 1021.4399999999999, "end": 1025.2, "text": " we have some kind of fullback. Just in case everything fails, something is going to say,", "tokens": [321, 362, 512, 733, 295, 1577, 3207, 13, 1449, 294, 1389, 1203, 18199, 11, 746, 307, 516, 281, 584, 11], "temperature": 0.0, "avg_logprob": -0.0947522955425715, "compression_ratio": 1.6245614035087719, "no_speech_prob": 2.8383490644046105e-05}, {"id": 168, "seek": 101168, "start": 1025.2, "end": 1030.3999999999999, "text": " I don't know. We're having technical issues. Please come back. So, now we're going to run the", "tokens": [286, 500, 380, 458, 13, 492, 434, 1419, 6191, 2663, 13, 2555, 808, 646, 13, 407, 11, 586, 321, 434, 516, 281, 1190, 264], "temperature": 0.0, "avg_logprob": -0.0947522955425715, "compression_ratio": 1.6245614035087719, "no_speech_prob": 2.8383490644046105e-05}, {"id": 169, "seek": 101168, "start": 1031.6, "end": 1038.1599999999999, "text": " streaming algorithm and see how we do that. So, output.file starts. It always goes back from", "tokens": [11791, 9284, 293, 536, 577, 321, 360, 300, 13, 407, 11, 5598, 13, 69, 794, 3719, 13, 467, 1009, 1709, 646, 490], "temperature": 0.0, "avg_logprob": -0.0947522955425715, "compression_ratio": 1.6245614035087719, "no_speech_prob": 2.8383490644046105e-05}, {"id": 170, "seek": 103816, "start": 1038.16, "end": 1043.8400000000001, "text": " the output down to the inputs. And the reason is because all of that is dynamic. So, there's no", "tokens": [264, 5598, 760, 281, 264, 15743, 13, 400, 264, 1778, 307, 570, 439, 295, 300, 307, 8546, 13, 407, 11, 456, 311, 572], "temperature": 0.0, "avg_logprob": -0.11156872475501334, "compression_ratio": 1.645021645021645, "no_speech_prob": 2.3542710550827906e-05}, {"id": 171, "seek": 103816, "start": 1043.8400000000001, "end": 1048.72, "text": " reason to start asking these people here to prepare data. They might not be used because,", "tokens": [1778, 281, 722, 3365, 613, 561, 510, 281, 5940, 1412, 13, 814, 1062, 406, 312, 1143, 570, 11], "temperature": 0.0, "avg_logprob": -0.11156872475501334, "compression_ratio": 1.645021645021645, "no_speech_prob": 2.3542710550827906e-05}, {"id": 172, "seek": 103816, "start": 1049.3600000000001, "end": 1054.48, "text": " up in the graph, the fullback might choose to use just one of them. So, we have to start from the", "tokens": [493, 294, 264, 4295, 11, 264, 1577, 3207, 1062, 2826, 281, 764, 445, 472, 295, 552, 13, 407, 11, 321, 362, 281, 722, 490, 264], "temperature": 0.0, "avg_logprob": -0.11156872475501334, "compression_ratio": 1.645021645021645, "no_speech_prob": 2.3542710550827906e-05}, {"id": 173, "seek": 103816, "start": 1054.48, "end": 1062.8000000000002, "text": " output. Bring it down. So, I have an empty frame, a cycle, 23 sudden streaming cycle. And I want", "tokens": [5598, 13, 12842, 309, 760, 13, 407, 11, 286, 362, 364, 6707, 3920, 11, 257, 6586, 11, 6673, 3990, 11791, 6586, 13, 400, 286, 528], "temperature": 0.0, "avg_logprob": -0.11156872475501334, "compression_ratio": 1.645021645021645, "no_speech_prob": 2.3542710550827906e-05}, {"id": 174, "seek": 106280, "start": 1062.8, "end": 1068.8, "text": " to fill it up with 0.04 seconds of data. I go to the fullback and say, hey, can you fill up this", "tokens": [281, 2836, 309, 493, 365, 1958, 13, 14565, 3949, 295, 1412, 13, 286, 352, 281, 264, 1577, 3207, 293, 584, 11, 4177, 11, 393, 291, 2836, 493, 341], "temperature": 0.0, "avg_logprob": -0.10258815437555313, "compression_ratio": 1.6223776223776223, "no_speech_prob": 1.9819326553260908e-05}, {"id": 175, "seek": 106280, "start": 1068.8, "end": 1075.68, "text": " frame? Fullback is like, sure, let me ask first, input a hardware? Not available. But request.q", "tokens": [3920, 30, 13841, 3207, 307, 411, 11, 988, 11, 718, 385, 1029, 700, 11, 4846, 257, 8837, 30, 1726, 2435, 13, 583, 5308, 13, 80], "temperature": 0.0, "avg_logprob": -0.10258815437555313, "compression_ratio": 1.6223776223776223, "no_speech_prob": 1.9819326553260908e-05}, {"id": 176, "seek": 106280, "start": 1075.68, "end": 1080.8, "text": " has something in the queue, actually. Let me pass it down, pass it down to this operator.", "tokens": [575, 746, 294, 264, 18639, 11, 767, 13, 961, 385, 1320, 309, 760, 11, 1320, 309, 760, 281, 341, 12973, 13], "temperature": 0.0, "avg_logprob": -0.10258815437555313, "compression_ratio": 1.6223776223776223, "no_speech_prob": 1.9819326553260908e-05}, {"id": 177, "seek": 106280, "start": 1080.8, "end": 1086.08, "text": " Request.q partially fills the frame. It added a little bit of audio and one video frame.", "tokens": [1300, 20343, 13, 80, 18886, 22498, 264, 3920, 13, 467, 3869, 257, 707, 857, 295, 6278, 293, 472, 960, 3920, 13], "temperature": 0.0, "avg_logprob": -0.10258815437555313, "compression_ratio": 1.6223776223776223, "no_speech_prob": 1.9819326553260908e-05}, {"id": 178, "seek": 106280, "start": 1086.96, "end": 1092.72, "text": " What you can think about it is that it was just finishing a track. Remember, request.q takes", "tokens": [708, 291, 393, 519, 466, 309, 307, 300, 309, 390, 445, 12693, 257, 2837, 13, 5459, 11, 5308, 13, 80, 2516], "temperature": 0.0, "avg_logprob": -0.10258815437555313, "compression_ratio": 1.6223776223776223, "no_speech_prob": 1.9819326553260908e-05}, {"id": 179, "seek": 109272, "start": 1092.72, "end": 1097.2, "text": " files when you want to play them. So, I don't know. It's just done playing the jingle or the", "tokens": [7098, 562, 291, 528, 281, 862, 552, 13, 407, 11, 286, 500, 380, 458, 13, 467, 311, 445, 1096, 2433, 264, 49495, 420, 264], "temperature": 0.0, "avg_logprob": -0.11519230329073392, "compression_ratio": 1.6967509025270757, "no_speech_prob": 5.642918767989613e-05}, {"id": 180, "seek": 109272, "start": 1097.2, "end": 1103.52, "text": " commercial that you wanted to finish. That's it. I'm done. So, it's a partial fill of the frame,", "tokens": [6841, 300, 291, 1415, 281, 2413, 13, 663, 311, 309, 13, 286, 478, 1096, 13, 407, 11, 309, 311, 257, 14641, 2836, 295, 264, 3920, 11], "temperature": 0.0, "avg_logprob": -0.11519230329073392, "compression_ratio": 1.6967509025270757, "no_speech_prob": 5.642918767989613e-05}, {"id": 181, "seek": 109272, "start": 1103.52, "end": 1111.6000000000001, "text": " in which case it comes back to the fullback that says, I need more. Playlist is not available.", "tokens": [294, 597, 1389, 309, 1487, 646, 281, 264, 1577, 3207, 300, 1619, 11, 286, 643, 544, 13, 5506, 8264, 307, 406, 2435, 13], "temperature": 0.0, "avg_logprob": -0.11519230329073392, "compression_ratio": 1.6967509025270757, "no_speech_prob": 5.642918767989613e-05}, {"id": 182, "seek": 109272, "start": 1111.6000000000001, "end": 1116.0, "text": " For some reason, the directory is empty. So, we go back to the single and say, hey, single,", "tokens": [1171, 512, 1778, 11, 264, 21120, 307, 6707, 13, 407, 11, 321, 352, 646, 281, 264, 2167, 293, 584, 11, 4177, 11, 2167, 11], "temperature": 0.0, "avg_logprob": -0.11519230329073392, "compression_ratio": 1.6967509025270757, "no_speech_prob": 5.642918767989613e-05}, {"id": 183, "seek": 109272, "start": 1116.0, "end": 1121.76, "text": " can you fill this frame? One of the things we do when we start the script is that we actually", "tokens": [393, 291, 2836, 341, 3920, 30, 1485, 295, 264, 721, 321, 360, 562, 321, 722, 264, 5755, 307, 300, 321, 767], "temperature": 0.0, "avg_logprob": -0.11519230329073392, "compression_ratio": 1.6967509025270757, "no_speech_prob": 5.642918767989613e-05}, {"id": 184, "seek": 112176, "start": 1121.76, "end": 1126.24, "text": " double check that we have at least one operator here that's always going to be available. So,", "tokens": [3834, 1520, 300, 321, 362, 412, 1935, 472, 12973, 510, 300, 311, 1009, 516, 281, 312, 2435, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.1266583257646703, "compression_ratio": 1.6232394366197183, "no_speech_prob": 1.749907823977992e-05}, {"id": 185, "seek": 112176, "start": 1126.24, "end": 1131.6, "text": " that's what happens here. The fullback is being used. And single is, sure, I got a file. I prepared", "tokens": [300, 311, 437, 2314, 510, 13, 440, 1577, 3207, 307, 885, 1143, 13, 400, 2167, 307, 11, 988, 11, 286, 658, 257, 3991, 13, 286, 4927], "temperature": 0.0, "avg_logprob": -0.1266583257646703, "compression_ratio": 1.6232394366197183, "no_speech_prob": 1.749907823977992e-05}, {"id": 186, "seek": 112176, "start": 1131.6, "end": 1137.12, "text": " it. I can decode it. Boom. Finish filling up the frame. And then it goes all the way up the tree.", "tokens": [309, 13, 286, 393, 979, 1429, 309, 13, 15523, 13, 31583, 10623, 493, 264, 3920, 13, 400, 550, 309, 1709, 439, 264, 636, 493, 264, 4230, 13], "temperature": 0.0, "avg_logprob": -0.1266583257646703, "compression_ratio": 1.6232394366197183, "no_speech_prob": 1.749907823977992e-05}, {"id": 187, "seek": 112176, "start": 1137.84, "end": 1143.12, "text": " We're ready to encode that, save it in the file. Now comes the second one,", "tokens": [492, 434, 1919, 281, 2058, 1429, 300, 11, 3155, 309, 294, 264, 3991, 13, 823, 1487, 264, 1150, 472, 11], "temperature": 0.0, "avg_logprob": -0.1266583257646703, "compression_ratio": 1.6232394366197183, "no_speech_prob": 1.749907823977992e-05}, {"id": 188, "seek": 112176, "start": 1143.92, "end": 1148.8799999999999, "text": " which is the iSCAS output. Same thing. It's like, hey, I need to send data to my iSCAS server.", "tokens": [597, 307, 264, 741, 20839, 3160, 5598, 13, 10635, 551, 13, 467, 311, 411, 11, 4177, 11, 286, 643, 281, 2845, 1412, 281, 452, 741, 20839, 3160, 7154, 13], "temperature": 0.0, "avg_logprob": -0.1266583257646703, "compression_ratio": 1.6232394366197183, "no_speech_prob": 1.749907823977992e-05}, {"id": 189, "seek": 114888, "start": 1148.88, "end": 1154.4, "text": " It goes back to the fullback. But then what we do here, of course, we cache stuff. So,", "tokens": [467, 1709, 646, 281, 264, 1577, 3207, 13, 583, 550, 437, 321, 360, 510, 11, 295, 1164, 11, 321, 19459, 1507, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.0803071030782997, "compression_ratio": 1.6784140969162995, "no_speech_prob": 1.078248351404909e-05}, {"id": 190, "seek": 114888, "start": 1154.4, "end": 1160.0, "text": " we know that fullback has already produced a whole frame. We have saved it. We can just fill it up", "tokens": [321, 458, 300, 1577, 3207, 575, 1217, 7126, 257, 1379, 3920, 13, 492, 362, 6624, 309, 13, 492, 393, 445, 2836, 309, 493], "temperature": 0.0, "avg_logprob": -0.0803071030782997, "compression_ratio": 1.6784140969162995, "no_speech_prob": 1.078248351404909e-05}, {"id": 191, "seek": 114888, "start": 1160.0, "end": 1168.4, "text": " here, send it back to iSCAS, again, encode it if needed, send it back. So, the thing that's really", "tokens": [510, 11, 2845, 309, 646, 281, 741, 20839, 3160, 11, 797, 11, 2058, 1429, 309, 498, 2978, 11, 2845, 309, 646, 13, 407, 11, 264, 551, 300, 311, 534], "temperature": 0.0, "avg_logprob": -0.0803071030782997, "compression_ratio": 1.6784140969162995, "no_speech_prob": 1.078248351404909e-05}, {"id": 192, "seek": 114888, "start": 1168.4, "end": 1174.0, "text": " nice with this algorithm is that, again, we don't really care about what's in the frame. We just", "tokens": [1481, 365, 341, 9284, 307, 300, 11, 797, 11, 321, 500, 380, 534, 1127, 466, 437, 311, 294, 264, 3920, 13, 492, 445], "temperature": 0.0, "avg_logprob": -0.0803071030782997, "compression_ratio": 1.6784140969162995, "no_speech_prob": 1.078248351404909e-05}, {"id": 193, "seek": 117400, "start": 1174.0, "end": 1178.72, "text": " care that we know that we can fill it up and we know how much is filled. And then we can pass it", "tokens": [1127, 300, 321, 458, 300, 321, 393, 2836, 309, 493, 293, 321, 458, 577, 709, 307, 6412, 13, 400, 550, 321, 393, 1320, 309], "temperature": 0.0, "avg_logprob": -0.13380073618005822, "compression_ratio": 1.613733905579399, "no_speech_prob": 3.76089483324904e-05}, {"id": 194, "seek": 117400, "start": 1178.72, "end": 1186.96, "text": " down. So, these things can actually be FFMpeg encoded packet. No problem. They can be raw PCM.", "tokens": [760, 13, 407, 11, 613, 721, 393, 767, 312, 479, 37, 44, 494, 70, 2058, 12340, 20300, 13, 883, 1154, 13, 814, 393, 312, 8936, 6465, 44, 13], "temperature": 0.0, "avg_logprob": -0.13380073618005822, "compression_ratio": 1.613733905579399, "no_speech_prob": 3.76089483324904e-05}, {"id": 195, "seek": 117400, "start": 1186.96, "end": 1191.2, "text": " Then we have to encode them. So, it's really, again, we are just looking at things from a", "tokens": [1396, 321, 362, 281, 2058, 1429, 552, 13, 407, 11, 309, 311, 534, 11, 797, 11, 321, 366, 445, 1237, 412, 721, 490, 257], "temperature": 0.0, "avg_logprob": -0.13380073618005822, "compression_ratio": 1.613733905579399, "no_speech_prob": 3.76089483324904e-05}, {"id": 196, "seek": 117400, "start": 1191.2, "end": 1198.56, "text": " high-level perspective. So, if the time for that whole cycle was t, we have two possibilities.", "tokens": [1090, 12, 12418, 4585, 13, 407, 11, 498, 264, 565, 337, 300, 1379, 6586, 390, 256, 11, 321, 362, 732, 12178, 13], "temperature": 0.0, "avg_logprob": -0.13380073618005822, "compression_ratio": 1.613733905579399, "no_speech_prob": 3.76089483324904e-05}, {"id": 197, "seek": 119856, "start": 1198.56, "end": 1206.0, "text": " If we generated the 0.04 second in less than 0.04 second for the computer, it means that we run", "tokens": [759, 321, 10833, 264, 1958, 13, 14565, 1150, 294, 1570, 813, 1958, 13, 14565, 1150, 337, 264, 3820, 11, 309, 1355, 300, 321, 1190], "temperature": 0.0, "avg_logprob": -0.15140169583834134, "compression_ratio": 1.7536764705882353, "no_speech_prob": 2.880613101297058e-05}, {"id": 198, "seek": 119856, "start": 1206.0, "end": 1210.96, "text": " faster than the real-time. We can sleep a little bit because we're generating things in real-time.", "tokens": [4663, 813, 264, 957, 12, 3766, 13, 492, 393, 2817, 257, 707, 857, 570, 321, 434, 17746, 721, 294, 957, 12, 3766, 13], "temperature": 0.0, "avg_logprob": -0.15140169583834134, "compression_ratio": 1.7536764705882353, "no_speech_prob": 2.880613101297058e-05}, {"id": 199, "seek": 119856, "start": 1211.9199999999998, "end": 1216.48, "text": " If not, we have a problem. We need to catch up. So, we need to run the loop again as fast as", "tokens": [759, 406, 11, 321, 362, 257, 1154, 13, 492, 643, 281, 3745, 493, 13, 407, 11, 321, 643, 281, 1190, 264, 6367, 797, 382, 2370, 382], "temperature": 0.0, "avg_logprob": -0.15140169583834134, "compression_ratio": 1.7536764705882353, "no_speech_prob": 2.880613101297058e-05}, {"id": 200, "seek": 119856, "start": 1216.48, "end": 1220.8, "text": " possible. Basically, if you're in the red, you have a problem. It means that, I don't know,", "tokens": [1944, 13, 8537, 11, 498, 291, 434, 294, 264, 2182, 11, 291, 362, 257, 1154, 13, 467, 1355, 300, 11, 286, 500, 380, 458, 11], "temperature": 0.0, "avg_logprob": -0.15140169583834134, "compression_ratio": 1.7536764705882353, "no_speech_prob": 2.880613101297058e-05}, {"id": 201, "seek": 119856, "start": 1220.8, "end": 1225.28, "text": " encoding takes too long. Something happened in your script. You cannot produce in real-time. What", "tokens": [43430, 2516, 886, 938, 13, 6595, 2011, 294, 428, 5755, 13, 509, 2644, 5258, 294, 957, 12, 3766, 13, 708], "temperature": 0.0, "avg_logprob": -0.15140169583834134, "compression_ratio": 1.7536764705882353, "no_speech_prob": 2.880613101297058e-05}, {"id": 202, "seek": 122528, "start": 1225.28, "end": 1231.44, "text": " we want is to be in the green all the time so that we know we can deliver the content at a", "tokens": [321, 528, 307, 281, 312, 294, 264, 3092, 439, 264, 565, 370, 300, 321, 458, 321, 393, 4239, 264, 2701, 412, 257], "temperature": 0.0, "avg_logprob": -0.12996286275435467, "compression_ratio": 1.6167400881057268, "no_speech_prob": 3.37000165018253e-05}, {"id": 203, "seek": 122528, "start": 1231.44, "end": 1240.6399999999999, "text": " real-time rate all the time. So, that's how it works. Now, because I told you all that we now", "tokens": [957, 12, 3766, 3314, 439, 264, 565, 13, 407, 11, 300, 311, 577, 309, 1985, 13, 823, 11, 570, 286, 1907, 291, 439, 300, 321, 586], "temperature": 0.0, "avg_logprob": -0.12996286275435467, "compression_ratio": 1.6167400881057268, "no_speech_prob": 3.37000165018253e-05}, {"id": 204, "seek": 122528, "start": 1240.6399999999999, "end": 1247.28, "text": " can use encoded content, we're having a little bit of problems that I won't have time to describe", "tokens": [393, 764, 2058, 12340, 2701, 11, 321, 434, 1419, 257, 707, 857, 295, 2740, 300, 286, 1582, 380, 362, 565, 281, 6786], "temperature": 0.0, "avg_logprob": -0.12996286275435467, "compression_ratio": 1.6167400881057268, "no_speech_prob": 3.37000165018253e-05}, {"id": 205, "seek": 122528, "start": 1247.28, "end": 1254.0, "text": " here. But essentially, sometimes we have to do a lower-level understanding of what's", "tokens": [510, 13, 583, 4476, 11, 2171, 321, 362, 281, 360, 257, 3126, 12, 12418, 3701, 295, 437, 311], "temperature": 0.0, "avg_logprob": -0.12996286275435467, "compression_ratio": 1.6167400881057268, "no_speech_prob": 3.37000165018253e-05}, {"id": 206, "seek": 125400, "start": 1254.0, "end": 1258.8, "text": " happening in the bitstream. So, basically, in ffmpeg, you have things that's called extra data.", "tokens": [2737, 294, 264, 857, 9291, 13, 407, 11, 1936, 11, 294, 283, 69, 76, 494, 70, 11, 291, 362, 721, 300, 311, 1219, 2857, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1682554086049398, "compression_ratio": 1.8081180811808117, "no_speech_prob": 4.5363500248640776e-05}, {"id": 207, "seek": 125400, "start": 1258.8, "end": 1266.48, "text": " So, if you take an mp4 media, everything that is needed to decode like fman-table is in the header,", "tokens": [407, 11, 498, 291, 747, 364, 275, 79, 19, 3021, 11, 1203, 300, 307, 2978, 281, 979, 1429, 411, 283, 1601, 12, 23811, 307, 294, 264, 23117, 11], "temperature": 0.0, "avg_logprob": -0.1682554086049398, "compression_ratio": 1.8081180811808117, "no_speech_prob": 4.5363500248640776e-05}, {"id": 208, "seek": 125400, "start": 1266.48, "end": 1270.64, "text": " it's communicated first, and then all the packets, the frames after that, don't have it. But if you", "tokens": [309, 311, 34989, 700, 11, 293, 550, 439, 264, 30364, 11, 264, 12083, 934, 300, 11, 500, 380, 362, 309, 13, 583, 498, 291], "temperature": 0.0, "avg_logprob": -0.1682554086049398, "compression_ratio": 1.8081180811808117, "no_speech_prob": 4.5363500248640776e-05}, {"id": 209, "seek": 125400, "start": 1270.64, "end": 1276.64, "text": " take mpeg-ts, because mpeg-ts doesn't have a global header, every frame is going to have that data.", "tokens": [747, 275, 494, 70, 12, 1373, 11, 570, 275, 494, 70, 12, 1373, 1177, 380, 362, 257, 4338, 23117, 11, 633, 3920, 307, 516, 281, 362, 300, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1682554086049398, "compression_ratio": 1.8081180811808117, "no_speech_prob": 4.5363500248640776e-05}, {"id": 210, "seek": 125400, "start": 1276.64, "end": 1282.0, "text": " And that was a problem because now we do things that ffmpeg doesn't do, which is a live switch", "tokens": [400, 300, 390, 257, 1154, 570, 586, 321, 360, 721, 300, 283, 69, 76, 494, 70, 1177, 380, 360, 11, 597, 307, 257, 1621, 3679], "temperature": 0.0, "avg_logprob": -0.1682554086049398, "compression_ratio": 1.8081180811808117, "no_speech_prob": 4.5363500248640776e-05}, {"id": 211, "seek": 128200, "start": 1282.0, "end": 1289.28, "text": " between two different bitstreams. This is a RTMP input, this is a file, mp4. And when we live", "tokens": [1296, 732, 819, 857, 9291, 82, 13, 639, 307, 257, 21797, 12224, 4846, 11, 341, 307, 257, 3991, 11, 275, 79, 19, 13, 400, 562, 321, 1621], "temperature": 0.0, "avg_logprob": -0.15006073207071383, "compression_ratio": 1.8141263940520447, "no_speech_prob": 9.150386904366314e-05}, {"id": 212, "seek": 128200, "start": 1289.28, "end": 1295.28, "text": " switch, if we started with this one, for instance, the muxer from ffmpeg might say, oh, you know what,", "tokens": [3679, 11, 498, 321, 1409, 365, 341, 472, 11, 337, 5197, 11, 264, 275, 2449, 260, 490, 283, 69, 76, 494, 70, 1062, 584, 11, 1954, 11, 291, 458, 437, 11], "temperature": 0.0, "avg_logprob": -0.15006073207071383, "compression_ratio": 1.8141263940520447, "no_speech_prob": 9.150386904366314e-05}, {"id": 213, "seek": 128200, "start": 1296.4, "end": 1301.84, "text": " I already have the, no, if we started with this one, the muxer will say, I know that all the frames", "tokens": [286, 1217, 362, 264, 11, 572, 11, 498, 321, 1409, 365, 341, 472, 11, 264, 275, 2449, 260, 486, 584, 11, 286, 458, 300, 439, 264, 12083], "temperature": 0.0, "avg_logprob": -0.15006073207071383, "compression_ratio": 1.8141263940520447, "no_speech_prob": 9.150386904366314e-05}, {"id": 214, "seek": 128200, "start": 1301.84, "end": 1306.48, "text": " are going to have the private data that I need, I can go on with it. And then we live switch to that,", "tokens": [366, 516, 281, 362, 264, 4551, 1412, 300, 286, 643, 11, 286, 393, 352, 322, 365, 309, 13, 400, 550, 321, 1621, 3679, 281, 300, 11], "temperature": 0.0, "avg_logprob": -0.15006073207071383, "compression_ratio": 1.8141263940520447, "no_speech_prob": 9.150386904366314e-05}, {"id": 215, "seek": 128200, "start": 1306.48, "end": 1310.48, "text": " and suddenly we start receiving frames that don't have it. And the muxer is like, whoops,", "tokens": [293, 5800, 321, 722, 10040, 12083, 300, 500, 380, 362, 309, 13, 400, 264, 275, 2449, 260, 307, 411, 11, 567, 3370, 11], "temperature": 0.0, "avg_logprob": -0.15006073207071383, "compression_ratio": 1.8141263940520447, "no_speech_prob": 9.150386904366314e-05}, {"id": 216, "seek": 131048, "start": 1310.48, "end": 1314.4, "text": " I cannot do it. So we have to insert those filters here to make sure that they're always present.", "tokens": [286, 2644, 360, 309, 13, 407, 321, 362, 281, 8969, 729, 15995, 510, 281, 652, 988, 300, 436, 434, 1009, 1974, 13], "temperature": 0.0, "avg_logprob": -0.10503249790357506, "compression_ratio": 1.635036496350365, "no_speech_prob": 2.9277713110786863e-05}, {"id": 217, "seek": 131048, "start": 1314.4, "end": 1319.6, "text": " Which is a problem for us because it means that the user has to think about low-level stuff.", "tokens": [3013, 307, 257, 1154, 337, 505, 570, 309, 1355, 300, 264, 4195, 575, 281, 519, 466, 2295, 12, 12418, 1507, 13], "temperature": 0.0, "avg_logprob": -0.10503249790357506, "compression_ratio": 1.635036496350365, "no_speech_prob": 2.9277713110786863e-05}, {"id": 218, "seek": 131048, "start": 1319.6, "end": 1324.0, "text": " And that's part of one of the questions that I was wondering if ffmpeg might find", "tokens": [400, 300, 311, 644, 295, 472, 295, 264, 1651, 300, 286, 390, 6359, 498, 283, 69, 76, 494, 70, 1062, 915], "temperature": 0.0, "avg_logprob": -0.10503249790357506, "compression_ratio": 1.635036496350365, "no_speech_prob": 2.9277713110786863e-05}, {"id": 219, "seek": 131048, "start": 1324.0, "end": 1327.76, "text": " some of the beautiful abstraction they have to alleviate that kind of problem.", "tokens": [512, 295, 264, 2238, 37765, 436, 362, 281, 42701, 300, 733, 295, 1154, 13], "temperature": 0.0, "avg_logprob": -0.10503249790357506, "compression_ratio": 1.635036496350365, "no_speech_prob": 2.9277713110786863e-05}, {"id": 220, "seek": 131048, "start": 1329.1200000000001, "end": 1335.04, "text": " All right, almost done. I'm going to finish real quick. We have a 2.x release with tracks so you", "tokens": [1057, 558, 11, 1920, 1096, 13, 286, 478, 516, 281, 2413, 957, 1702, 13, 492, 362, 257, 568, 13, 87, 4374, 365, 10218, 370, 291], "temperature": 0.0, "avg_logprob": -0.10503249790357506, "compression_ratio": 1.635036496350365, "no_speech_prob": 2.9277713110786863e-05}, {"id": 221, "seek": 133504, "start": 1335.04, "end": 1340.6399999999999, "text": " can manipulate and remix different tracks. Let's say you do an MKV with French, English, and Italian", "tokens": [393, 20459, 293, 47788, 819, 10218, 13, 961, 311, 584, 291, 360, 364, 30770, 53, 365, 5522, 11, 3669, 11, 293, 10003], "temperature": 0.0, "avg_logprob": -0.18452516515204248, "compression_ratio": 1.496031746031746, "no_speech_prob": 7.977601489983499e-05}, {"id": 222, "seek": 133504, "start": 1340.6399999999999, "end": 1346.72, "text": " soundtrack and encode it in different format. We want to rewrite the whole clocking system", "tokens": [27029, 293, 2058, 1429, 309, 294, 819, 7877, 13, 492, 528, 281, 28132, 264, 1379, 7830, 278, 1185], "temperature": 0.0, "avg_logprob": -0.18452516515204248, "compression_ratio": 1.496031746031746, "no_speech_prob": 7.977601489983499e-05}, {"id": 223, "seek": 133504, "start": 1346.72, "end": 1351.36, "text": " and streaming because Okamera 5.0 does concurrency. It's pretty exciting. We want to think about", "tokens": [293, 11791, 570, 3477, 335, 1663, 1025, 13, 15, 775, 23702, 10457, 13, 467, 311, 1238, 4670, 13, 492, 528, 281, 519, 466], "temperature": 0.0, "avg_logprob": -0.18452516515204248, "compression_ratio": 1.496031746031746, "no_speech_prob": 7.977601489983499e-05}, {"id": 224, "seek": 133504, "start": 1351.36, "end": 1358.08, "text": " JavaScript and YSM because we can do it and why not. And I'm very interested to see what", "tokens": [15778, 293, 398, 26693, 570, 321, 393, 360, 309, 293, 983, 406, 13, 400, 286, 478, 588, 3102, 281, 536, 437], "temperature": 0.0, "avg_logprob": -0.18452516515204248, "compression_ratio": 1.496031746031746, "no_speech_prob": 7.977601489983499e-05}, {"id": 225, "seek": 135808, "start": 1358.08, "end": 1365.36, "text": " VLC does because that's the next part and why they do it. And long-term development though", "tokens": [691, 14766, 775, 570, 300, 311, 264, 958, 644, 293, 983, 436, 360, 309, 13, 400, 938, 12, 7039, 3250, 1673], "temperature": 0.0, "avg_logprob": -0.11085246404012045, "compression_ratio": 1.6236933797909407, "no_speech_prob": 5.130745194037445e-05}, {"id": 226, "seek": 135808, "start": 1365.36, "end": 1371.4399999999998, "text": " is what we are wondering about because we have grown a lot of community, but most of our users", "tokens": [307, 437, 321, 366, 6359, 466, 570, 321, 362, 7709, 257, 688, 295, 1768, 11, 457, 881, 295, 527, 5022], "temperature": 0.0, "avg_logprob": -0.11085246404012045, "compression_ratio": 1.6236933797909407, "no_speech_prob": 5.130745194037445e-05}, {"id": 227, "seek": 135808, "start": 1371.4399999999998, "end": 1376.1599999999999, "text": " are not programmers and our programming language is OKMO, which is still a niche language.", "tokens": [366, 406, 41504, 293, 527, 9410, 2856, 307, 2264, 18976, 11, 597, 307, 920, 257, 19956, 2856, 13], "temperature": 0.0, "avg_logprob": -0.11085246404012045, "compression_ratio": 1.6236933797909407, "no_speech_prob": 5.130745194037445e-05}, {"id": 228, "seek": 135808, "start": 1376.1599999999999, "end": 1379.84, "text": " And we're two developers, someone and myself. So one of the questions, you know, the project is", "tokens": [400, 321, 434, 732, 8849, 11, 1580, 293, 2059, 13, 407, 472, 295, 264, 1651, 11, 291, 458, 11, 264, 1716, 307], "temperature": 0.0, "avg_logprob": -0.11085246404012045, "compression_ratio": 1.6236933797909407, "no_speech_prob": 5.130745194037445e-05}, {"id": 229, "seek": 135808, "start": 1379.84, "end": 1386.48, "text": " 20 years. We're 40-year-old. At some point, we need to think about moving on. So what we have", "tokens": [945, 924, 13, 492, 434, 3356, 12, 5294, 12, 2641, 13, 1711, 512, 935, 11, 321, 643, 281, 519, 466, 2684, 322, 13, 407, 437, 321, 362], "temperature": 0.0, "avg_logprob": -0.11085246404012045, "compression_ratio": 1.6236933797909407, "no_speech_prob": 5.130745194037445e-05}, {"id": 230, "seek": 138648, "start": 1386.48, "end": 1392.0, "text": " done so far is do a lot of automation, which is very powerful. It allows us to focus on the code", "tokens": [1096, 370, 1400, 307, 360, 257, 688, 295, 17769, 11, 597, 307, 588, 4005, 13, 467, 4045, 505, 281, 1879, 322, 264, 3089], "temperature": 0.0, "avg_logprob": -0.09054002191266443, "compression_ratio": 1.7158273381294964, "no_speech_prob": 6.668864079983905e-05}, {"id": 231, "seek": 138648, "start": 1392.0, "end": 1396.24, "text": " and have less to think to do. Like, we have automated release. We do CI to run all the tests", "tokens": [293, 362, 1570, 281, 519, 281, 360, 13, 1743, 11, 321, 362, 18473, 4374, 13, 492, 360, 37777, 281, 1190, 439, 264, 6921], "temperature": 0.0, "avg_logprob": -0.09054002191266443, "compression_ratio": 1.7158273381294964, "no_speech_prob": 6.668864079983905e-05}, {"id": 232, "seek": 138648, "start": 1396.24, "end": 1400.8, "text": " every time. We have augmented the number of automated tests we have so that we catch everything", "tokens": [633, 565, 13, 492, 362, 36155, 264, 1230, 295, 18473, 6921, 321, 362, 370, 300, 321, 3745, 1203], "temperature": 0.0, "avg_logprob": -0.09054002191266443, "compression_ratio": 1.7158273381294964, "no_speech_prob": 6.668864079983905e-05}, {"id": 233, "seek": 138648, "start": 1400.8, "end": 1406.16, "text": " very quickly instead of relying on a lot of manual testing. But it's far as a challenge to", "tokens": [588, 2661, 2602, 295, 24140, 322, 257, 688, 295, 9688, 4997, 13, 583, 309, 311, 1400, 382, 257, 3430, 281], "temperature": 0.0, "avg_logprob": -0.09054002191266443, "compression_ratio": 1.7158273381294964, "no_speech_prob": 6.668864079983905e-05}, {"id": 234, "seek": 138648, "start": 1406.16, "end": 1412.72, "text": " think about how we can bring in more developers that like OKMO, like radio, is a pretty intersection", "tokens": [519, 466, 577, 321, 393, 1565, 294, 544, 8849, 300, 411, 2264, 18976, 11, 411, 6477, 11, 307, 257, 1238, 15236], "temperature": 0.0, "avg_logprob": -0.09054002191266443, "compression_ratio": 1.7158273381294964, "no_speech_prob": 6.668864079983905e-05}, {"id": 235, "seek": 141272, "start": 1412.72, "end": 1418.72, "text": " of two niche things. And that's it for me. And thank you very much for your time. And maybe there are questions.", "tokens": [295, 732, 19956, 721, 13, 400, 300, 311, 309, 337, 385, 13, 400, 1309, 291, 588, 709, 337, 428, 565, 13, 400, 1310, 456, 366, 1651, 13], "temperature": 0.0, "avg_logprob": -0.2799024274272303, "compression_ratio": 1.2307692307692308, "no_speech_prob": 0.00040880704182200134}, {"id": 236, "seek": 141872, "start": 1418.72, "end": 1444.72, "text": " So we have time for a couple of questions, yes?", "tokens": [407, 321, 362, 565, 337, 257, 1916, 295, 1651, 11, 2086, 30], "temperature": 0.0, "avg_logprob": -0.3770363926887512, "compression_ratio": 0.8545454545454545, "no_speech_prob": 0.005751900840550661}, {"id": 237, "seek": 144472, "start": 1444.72, "end": 1452.72, "text": " Yeah, so once you go from the debumster to the coder, it's expected to format the entity.", "tokens": [865, 11, 370, 1564, 291, 352, 490, 264, 3001, 449, 3120, 281, 264, 17656, 260, 11, 309, 311, 5176, 281, 7877, 264, 13977, 13], "temperature": 0.0, "avg_logprob": -0.5362978115887709, "compression_ratio": 1.5738636363636365, "no_speech_prob": 0.018826646730303764}, {"id": 238, "seek": 144472, "start": 1452.72, "end": 1458.72, "text": " Then the same thing on the mob suicide. So if the expected output format is something else,", "tokens": [1396, 264, 912, 551, 322, 264, 4298, 12308, 13, 407, 498, 264, 5176, 5598, 7877, 307, 746, 1646, 11], "temperature": 0.0, "avg_logprob": -0.5362978115887709, "compression_ratio": 1.5738636363636365, "no_speech_prob": 0.018826646730303764}, {"id": 239, "seek": 144472, "start": 1458.72, "end": 1466.72, "text": " so it will actually tell you that you're expected to insert a bit stream filter again to get it", "tokens": [370, 309, 486, 767, 980, 291, 300, 291, 434, 5176, 281, 8969, 257, 857, 4309, 6608, 797, 281, 483, 309], "temperature": 0.0, "avg_logprob": -0.5362978115887709, "compression_ratio": 1.5738636363636365, "no_speech_prob": 0.018826646730303764}, {"id": 240, "seek": 146672, "start": 1466.72, "end": 1481.72, "text": " forward. Yeah, it was actually an answer. There are APIs in FFMPEG to inform the user of the", "tokens": [2128, 13, 865, 11, 309, 390, 767, 364, 1867, 13, 821, 366, 21445, 294, 479, 37, 44, 5208, 38, 281, 1356, 264, 4195, 295, 264], "temperature": 0.0, "avg_logprob": -0.17280385805212933, "compression_ratio": 1.5517241379310345, "no_speech_prob": 6.807060708524659e-05}, {"id": 241, "seek": 146672, "start": 1481.72, "end": 1485.72, "text": " C API whether or not they need to insert those filters. And I see that there is automatic", "tokens": [383, 9362, 1968, 420, 406, 436, 643, 281, 8969, 729, 15995, 13, 400, 286, 536, 300, 456, 307, 12509], "temperature": 0.0, "avg_logprob": -0.17280385805212933, "compression_ratio": 1.5517241379310345, "no_speech_prob": 6.807060708524659e-05}, {"id": 242, "seek": 146672, "start": 1485.72, "end": 1489.72, "text": " insertion of those filters in the code. I guess I have to have another pass at making", "tokens": [8969, 313, 295, 729, 15995, 294, 264, 3089, 13, 286, 2041, 286, 362, 281, 362, 1071, 1320, 412, 1455], "temperature": 0.0, "avg_logprob": -0.17280385805212933, "compression_ratio": 1.5517241379310345, "no_speech_prob": 6.807060708524659e-05}, {"id": 243, "seek": 146672, "start": 1489.72, "end": 1494.72, "text": " sure I understand when and how. And I regretfully for this presentation I didn't dive again", "tokens": [988, 286, 1223, 562, 293, 577, 13, 400, 286, 10879, 2277, 337, 341, 5860, 286, 994, 380, 9192, 797], "temperature": 0.0, "avg_logprob": -0.17280385805212933, "compression_ratio": 1.5517241379310345, "no_speech_prob": 6.807060708524659e-05}, {"id": 244, "seek": 149472, "start": 1494.72, "end": 1497.72, "text": " and I remember that sometimes it becomes a little bit intricate. But thank you very much.", "tokens": [293, 286, 1604, 300, 2171, 309, 3643, 257, 707, 857, 38015, 13, 583, 1309, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.1693492889404297, "compression_ratio": 1.5849056603773586, "no_speech_prob": 0.00021167364320717752}, {"id": 245, "seek": 149472, "start": 1497.72, "end": 1500.72, "text": " I will definitely have a good look.", "tokens": [286, 486, 2138, 362, 257, 665, 574, 13], "temperature": 0.0, "avg_logprob": -0.1693492889404297, "compression_ratio": 1.5849056603773586, "no_speech_prob": 0.00021167364320717752}, {"id": 246, "seek": 149472, "start": 1500.72, "end": 1510.72, "text": " Is it possible to control the running script using an external automation, especially like editing running playlists?", "tokens": [1119, 309, 1944, 281, 1969, 264, 2614, 5755, 1228, 364, 8320, 17769, 11, 2318, 411, 10000, 2614, 862, 36693, 30], "temperature": 0.0, "avg_logprob": -0.1693492889404297, "compression_ratio": 1.5849056603773586, "no_speech_prob": 0.00021167364320717752}, {"id": 247, "seek": 149472, "start": 1510.72, "end": 1518.72, "text": " Yeah, absolutely. So are there any tools to control a running script from the external user?", "tokens": [865, 11, 3122, 13, 407, 366, 456, 604, 3873, 281, 1969, 257, 2614, 5755, 490, 264, 8320, 4195, 30], "temperature": 0.0, "avg_logprob": -0.1693492889404297, "compression_ratio": 1.5849056603773586, "no_speech_prob": 0.00021167364320717752}, {"id": 248, "seek": 151872, "start": 1518.72, "end": 1524.72, "text": " So we have a lot of different options. The traditional one, the old one was a TerNet connection.", "tokens": [407, 321, 362, 257, 688, 295, 819, 3956, 13, 440, 5164, 472, 11, 264, 1331, 472, 390, 257, 6564, 31890, 4984, 13], "temperature": 0.0, "avg_logprob": -0.15702864794227167, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.00016745712491683662}, {"id": 249, "seek": 151872, "start": 1524.72, "end": 1529.72, "text": " But we have a fully featured HTTP server, so you can write your own API endpoints.", "tokens": [583, 321, 362, 257, 4498, 13822, 33283, 7154, 11, 370, 291, 393, 2464, 428, 1065, 9362, 917, 20552, 13], "temperature": 0.0, "avg_logprob": -0.15702864794227167, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.00016745712491683662}, {"id": 250, "seek": 151872, "start": 1529.72, "end": 1534.72, "text": " And basically because every source has their own methods now that are attached to it,", "tokens": [400, 1936, 570, 633, 4009, 575, 641, 1065, 7150, 586, 300, 366, 8570, 281, 309, 11], "temperature": 0.0, "avg_logprob": -0.15702864794227167, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.00016745712491683662}, {"id": 251, "seek": 151872, "start": 1534.72, "end": 1537.72, "text": " and you can run scripts, you can basically take a source and say,", "tokens": [293, 291, 393, 1190, 23294, 11, 291, 393, 1936, 747, 257, 4009, 293, 584, 11], "temperature": 0.0, "avg_logprob": -0.15702864794227167, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.00016745712491683662}, {"id": 252, "seek": 151872, "start": 1537.72, "end": 1542.72, "text": " okay, there's a function that inserts metadata, plug that into running everything else.", "tokens": [1392, 11, 456, 311, 257, 2445, 300, 49163, 26603, 11, 5452, 300, 666, 2614, 1203, 1646, 13], "temperature": 0.0, "avg_logprob": -0.15702864794227167, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.00016745712491683662}, {"id": 253, "seek": 151872, "start": 1542.72, "end": 1547.72, "text": " We're programming language. So yeah, we have a lot of different options for that for sure.", "tokens": [492, 434, 9410, 2856, 13, 407, 1338, 11, 321, 362, 257, 688, 295, 819, 3956, 337, 300, 337, 988, 13], "temperature": 0.0, "avg_logprob": -0.15702864794227167, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.00016745712491683662}, {"id": 254, "seek": 154772, "start": 1547.72, "end": 1555.72, "text": " Can you use LiquidSoup to do static operations, not to compare files,", "tokens": [1664, 291, 764, 38943, 50, 1250, 281, 360, 13437, 7705, 11, 406, 281, 6794, 7098, 11], "temperature": 0.0, "avg_logprob": -0.1921090790719697, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.000408085499657318}, {"id": 255, "seek": 154772, "start": 1555.72, "end": 1563.72, "text": " and not with the goal of doing streaming, just to apply operations on many...", "tokens": [293, 406, 365, 264, 3387, 295, 884, 11791, 11, 445, 281, 3079, 7705, 322, 867, 485], "temperature": 0.0, "avg_logprob": -0.1921090790719697, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.000408085499657318}, {"id": 256, "seek": 154772, "start": 1563.72, "end": 1566.72, "text": " Yes. The answer is yes, because the clock doesn't have to be...", "tokens": [1079, 13, 440, 1867, 307, 2086, 11, 570, 264, 7830, 1177, 380, 362, 281, 312, 485], "temperature": 0.0, "avg_logprob": -0.1921090790719697, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.000408085499657318}, {"id": 257, "seek": 154772, "start": 1566.72, "end": 1571.72, "text": " Oh yeah. Can you use LiquidSoup to do offline processing faster than real-time and not just real-time?", "tokens": [876, 1338, 13, 1664, 291, 764, 38943, 50, 1250, 281, 360, 21857, 9007, 4663, 813, 957, 12, 3766, 293, 406, 445, 957, 12, 3766, 30], "temperature": 0.0, "avg_logprob": -0.1921090790719697, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.000408085499657318}, {"id": 258, "seek": 154772, "start": 1571.72, "end": 1574.72, "text": " The answer is yes, because you can run a clock that says,", "tokens": [440, 1867, 307, 2086, 11, 570, 291, 393, 1190, 257, 7830, 300, 1619, 11], "temperature": 0.0, "avg_logprob": -0.1921090790719697, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.000408085499657318}, {"id": 259, "seek": 157472, "start": 1574.72, "end": 1577.72, "text": " I don't want you to be real-time, I want you to run as fast as possible.", "tokens": [286, 500, 380, 528, 291, 281, 312, 957, 12, 3766, 11, 286, 528, 291, 281, 1190, 382, 2370, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.08924328306186124, "compression_ratio": 1.8161993769470406, "no_speech_prob": 9.08462461666204e-05}, {"id": 260, "seek": 157472, "start": 1577.72, "end": 1581.72, "text": " But the sub-answer is that it's not a common case, it's not commonly tested.", "tokens": [583, 264, 1422, 12, 43904, 307, 300, 309, 311, 406, 257, 2689, 1389, 11, 309, 311, 406, 12719, 8246, 13], "temperature": 0.0, "avg_logprob": -0.08924328306186124, "compression_ratio": 1.8161993769470406, "no_speech_prob": 9.08462461666204e-05}, {"id": 261, "seek": 157472, "start": 1581.72, "end": 1585.72, "text": " And that's part of the thing that I want to bring on more when we write the streaming.", "tokens": [400, 300, 311, 644, 295, 264, 551, 300, 286, 528, 281, 1565, 322, 544, 562, 321, 2464, 264, 11791, 13], "temperature": 0.0, "avg_logprob": -0.08924328306186124, "compression_ratio": 1.8161993769470406, "no_speech_prob": 9.08462461666204e-05}, {"id": 262, "seek": 157472, "start": 1585.72, "end": 1590.72, "text": " Because for instance, a request needs to resolve a file which needs to make a network request,", "tokens": [1436, 337, 5197, 11, 257, 5308, 2203, 281, 14151, 257, 3991, 597, 2203, 281, 652, 257, 3209, 5308, 11], "temperature": 0.0, "avg_logprob": -0.08924328306186124, "compression_ratio": 1.8161993769470406, "no_speech_prob": 9.08462461666204e-05}, {"id": 263, "seek": 157472, "start": 1590.72, "end": 1592.72, "text": " download the file test that you can decode that.", "tokens": [5484, 264, 3991, 1500, 300, 291, 393, 979, 1429, 300, 13], "temperature": 0.0, "avg_logprob": -0.08924328306186124, "compression_ratio": 1.8161993769470406, "no_speech_prob": 9.08462461666204e-05}, {"id": 264, "seek": 157472, "start": 1592.72, "end": 1594.72, "text": " Most of the time we expect that to take a while,", "tokens": [4534, 295, 264, 565, 321, 2066, 300, 281, 747, 257, 1339, 11], "temperature": 0.0, "avg_logprob": -0.08924328306186124, "compression_ratio": 1.8161993769470406, "no_speech_prob": 9.08462461666204e-05}, {"id": 265, "seek": 157472, "start": 1594.72, "end": 1597.72, "text": " but it's not been tested a lot when you want to run very, very fast.", "tokens": [457, 309, 311, 406, 668, 8246, 257, 688, 562, 291, 528, 281, 1190, 588, 11, 588, 2370, 13], "temperature": 0.0, "avg_logprob": -0.08924328306186124, "compression_ratio": 1.8161993769470406, "no_speech_prob": 9.08462461666204e-05}, {"id": 266, "seek": 157472, "start": 1597.72, "end": 1600.72, "text": " And you run into race conditions that are very different.", "tokens": [400, 291, 1190, 666, 4569, 4487, 300, 366, 588, 819, 13], "temperature": 0.0, "avg_logprob": -0.08924328306186124, "compression_ratio": 1.8161993769470406, "no_speech_prob": 9.08462461666204e-05}, {"id": 267, "seek": 157472, "start": 1600.72, "end": 1602.72, "text": " Okay. Thank you very much.", "tokens": [1033, 13, 1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.08924328306186124, "compression_ratio": 1.8161993769470406, "no_speech_prob": 9.08462461666204e-05}, {"id": 268, "seek": 160272, "start": 1602.72, "end": 1604.72, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1831303834915161, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.0004642180574592203}], "language": "en"}