{"text": " Hi everyone, it's a big pleasure to be here. My name is Armin Purnaki and I'm a PhD candidate in Applied Mathematics and I work on building tools for discourse analysis and we build tools for discourse analysis based on methods from graph theory, network science and natural language processing and today I want to present a tool called the Twitter Explorer that is already a bit older but that was built in the Max Planck Institute for Mathematics and Sciences in my previous group and the idea was to build a tool that allows researchers who don't necessarily have programming skills to collect Twitter data, visualize them using graphs and explore the data and maybe generate hypotheses in their pipelines. So this kind of tool building and this research happens in the field called computational social science so when I was preparing my slides two days ago I thought it would be good to maybe give a little overview of computational social science then say why we built the Twitter Explorer and where we saw somehow the need for a new tool, of course introduce the features of the tool because it's kind of a talk on programming, the architecture and maybe give some insights on the usage but when I was sitting down to make the slides two days ago I was confronted with this and of course since the tool is essentially an entry point into the free API there is also a part of it that uses the research API which of course led us directly to this question, what happens to the research API? It's also not entirely clear, right? So I want to maybe instead of giving this the talk the way I was planning to do it, I will do it but maybe I wanted to ask a few questions first that we might then discuss maybe in the discussion also and I think there is even some kind of something planned later right so some kind of panel discussion so I'm just going to throw some questions out there that I think are really pressing now especially in the research field. How serious is this but this I don't mean the implications of it because I know a few people whose thesis is now in jeopardy because they can't collect data in a way but how serious is it in the sense, how serious is it in the sense, will it actually happen or is it some scare tactic so I think this is something that is hard to predict and then these are questions also I think that we can discuss here is how or is there a way for us as users and not necessarily only as researchers to claim our data or our digital traces that we use and that we leave on these platforms and how can things like the Digital Services Act play a role in this and the last question is very broad but how do we move on in the sense of how can we see this as some kind of wake up call maybe and how can we use this new development to maybe on one hand move to different platforms but on the other hand also to think about how we do computational social science in the future. So with these questions that we're going to discuss later I'm still going to give my original talk so in computational social science a typical pipeline for a project is you have a research question then you collect data related to it and in this case it may be data from online social platforms and then you analyze it and ideally you generated some more insights on the research question you had in the beginning and sometimes the exploration and the analysis of the data can help you maybe refine also the questions you had in the beginning so it's some kind of loop that you can see in this way and the tool that I'm going to present the Twitter Explorer is precisely made for this second part for both facilitating the collection and also the exploration of such data and this pipeline is that we start with text so in our case it's tweets that are annotated with some kind of metadata we have on Twitter different types of interactions so you can mention someone you can reply to someone or retweet and we choose one type of metadata and cast it into an interaction network and then we want to find the most significant for instance clusters or the significant correlations in this data by using 2D spatializations and typically these are done using force layouts but today for instance in the graph room there were also some talks about new methods of node embedding and so I think this is also something that we can discuss maybe in the question section but one reason why I think force layouts are good is that especially if you use them in a context where you work with social science researchers who don't necessarily have a lot of knowledge about the latest machine learning algorithms they are quite straightforward to explain in the sense that you have a spring system and nodes that are strongly connected tend to attract each other and especially if you look at interaction networks on Twitter since retweeting can be considered endorsement open clusters in such 2D spatializations can then correspond to something like opinion clusters and there's a lot of research being done in that way but one question that we always had when we look at these networks is how do we actually go back to the data that generated them and this is something that we try to tackle with building these tools so why we built it is firstly to provide an interface for researchers without programming skills also to collect and visualize the data because we were working a lot with social scientists that did not have these programming skills but had a lot of hypotheses about the data that they could not test then of course to facilitate the exploration of controversial issues on social media and this is the point that I was making before is add some layer of interpretability to these 2D spatializations by providing an access from within the interface to the actual data that created these node positions and finally we see it in the context of a larger scientific scope of using the network paradigm as something like a sampling mechanism for the data because if you're confronted with a large number of tweets for instance of course everyone knows that you can't read all of them manually so you need some kind of way to get to the tweets that are relevant for you to read and this is what we use the network for essentially so when we look at read-read networks immediately identify for instance the most influential actors in the debate and then read precisely those tweets that they made to maybe influence other actors and we call this guided close reading because if you do only close reading then you have to read all the text if you have distant reading you kind of look only at the network on a structure level and this is something in between so what can the tool do it collects tweets I mean I think we have like one week left for the v2 and the v1 so far the v2 academic is safe but we don't know that so you can search for it from the past seven days using the API and in the second part in the visualizer you can do display just a simple time series of the tweets to see maybe if there's some kind of special activity during one day you can build these interaction networks build co-hashtag networks so we divide it into some kind of two types of networks which we call semantic networks and interaction networks and then you can compute the typical measures people compute on networks and especially compute clusters like using modularity based algorithms and all this happens in some kind of interactive interface using JavaScript and D3JS and this is essentially the part where it gets interesting because so far all the other things you can do it with a lot of other tools especially like AFI or I think you can even collect tweets right with some plugins so I think all of this is not new and this is kind of where it gets interesting and I think this is time for a quick demo I don't know how much okay I have plenty of time I think I talk too fast okay so I have prepared some Python environments that already have the Twitter Explorer installed but usually you would do it like this and then all you need to do to fire up this interactive interface is type Twitter Explorer collector and this will open a browser window from which you can choose your API access choose the path to which the tweets will be downloaded and insert your search query maybe adding some advanced settings and saving options so I don't know this is a question to the audience now what we should search for this is easy and I already this is you're looking into the future I already have this network prepared for the last slide sorry we could but what would we look for then API is there maybe a hashtag like API shutdown maybe we need to go to Twitter itself API something like this we ideally would find some kind of hashtag know that okay let's just use maybe this as a search query no okay now it's collecting in the background then we can open another browser window here fire up the visualizer now we see that while this is still collecting we can already access oh there were only 400 tweets so there seems to be so we can look at a time series of tweets and then we can choose different types of networks to create we can filter them by language if we want and this is the language of the Twitter API returns so it's not there's no language detection going on here we can do some network reduction methods like taking only the largest connected component of the graph then we have this option here to remove the metadata of nodes that are not what we call public figures so if you want to publish some explorable networks it is advisable to do so there is not as far as I know not a very distinctive or clear rule after which point one is considered such a public figure but within our consortium we decided that it's 5000 followers this is also something we could discuss but since Twitter is public by default in a way anything you post is somehow post potentially to be used in displays somewhere then you can export the graph to all sorts of formats then you can aggregate nodes this means that for instance removing them based on how many retweets they have or how many retweets they did themselves and remove for instance nodes that only retweeted one person so is there a chalk maybe somewhere so if you have a graph and then there are some nodes that only retweet this person they I don't know if everyone can see that actually but they tend to clutter the force directed algorithm and structurally they do not necessarily add anything to the network so if you have very very large graphs it makes sense to remove these and somehow englobe them into this super node and then you can do traditional community detection and then it will be saved as a HTML but you can then open so we see here that this is again now in a retweet network every node is a user and the link is drawn from A to B if A retweets B and now we can look at this user t-chambers and look at the actual tweets that were made for them to end up at this part of the visualization okay so the data we collect this kind of sparse so this network doesn't look that interesting but I have prepared some fallback option so what we did in a case study a few months ago was to look at the repercussion of some discussions in the US about red flag laws and red flag laws are specific kinds of laws for gun control that allow state level judges to confiscate temporarily guns from people that are deemed to be a threat to themselves or to the public and these laws created very big repercussions especially on social media and especially in the conservative camps and this is one typical example where people then can analyze on Twitter if there is something like echo chambers or if people then maybe retweet each other only from the similar camps and then people draw very quick conclusions very fast and what we want to do with this tool is to show that maybe things are not that simple as they seem so I have prepared these networks but I think I will make it a bit smaller so this is now a bit bigger than what we had before we have roughly 25,000 nodes and 90,000 links and this is already one limitation of the tool that I think I would also like to discuss in the end is that you can't display mentally huge graphs so 100,000 links approximately is kind of the limit and I think this is also where integrating it with other tools such as Sigma or Gaffrey might actually make a lot of sense and so now I can call it a nodes by the Louvain community we can turn off the light also and now we can wonder what are these two communities and right now the node size is proportional to the in-degree meaning how often a given node was retweeted but if we want to so these may then be considered as something like the opinion leaders of the given camps and so if we go here we see for instance on this side Donald Trump Jr. and we can then look exactly at the tweets that led the visualization to put him where where he was so okay we don't need to go into the details of what he said but you see you see the point we can also change the node size to the number of followers and then we get an immediate view at who the who the main actors are that in general are also influential on Twitter so we have the New York Times here and Wall Street Journal so so we can see that we have something like of a more liberal versus a more conservative camp but if we look only at the retweet behavior we might think that okay these are separated echo chambers and people do not talk to each other but what is interesting is if we look at other types of networks in these example so we can look at the replies I think I will make it a bit smaller and all of the sudden we don't see this very strong segregated clustering anymore that we saw here maybe it's easier if I put it in but we see something more of a hairball layout and when we look at the nodes we see that indeed the path of going for instance from Donald Trump to Hillary Clinton or New York Times of those people that were very far apart in the retweet network is maybe not that not that long in the reply network meaning that these opposing camps actually maybe do talk to each other and it might be more interesting to see how they talk to each other and what they say and this is something that is that you can do when you when you use this interface and look at the tweets and that the actual replies so so it allows you to then actually go to the parts of the platform that that generate this data and that then generate these networks and finally as a small example of the semantic networks we can look at the hashtags that are used again and you see that for instance there is one kind of hateful conservative hashtag cluster which which and again okay maybe I should have said that in the hashtag networks every node is a hashtag and they are connected if they appear together in the same tweet so this is a very very low level way of seeing what is going on in the data in a way you don't need to do some kind of topic modeling and or complicated techniques you can literally just by looking at the hashtags already get a hint at how the different camps speak about the same topic so if you go here in this area this is about gun confiscation laws so Marxism in this case is also good good example right now we don't really know how it is used right and it can be used either by conservatives or by liberals and and and it's important to look at it in the context of of the data so then we would have to okay five minutes left good I will go back to the slides okay so under the hood this this whole backend of the collector individualizer is written in python and it's using the streamlit python library to serve it on a local front end so this is actually a very convenient library and I guess a lot of people also know it but you can write your code in python and then it essentially serves it in interfaces that look like this and the explorer is written in html and javascript and it uses d3 and prints the graph on canvas which is also why it's probably not as as fast as sigma is but it has some nice other features that are that are especially due to this force graph library so I think if anyone has questions I'm going to go into the details in the questions and so this is how we install it it's fairly simple if you have a running python bigger than 3.7 and there's also an API so of course especially here probably people will not be so interested in using the streamlit interface but you may want to include it into some kind of existing code pipeline that you have and this is essentially the API for semantic networks and interaction networks so I invite you to try it out yourself while you still can you have five days of course if you have the research API you might be able to use it for a bit longer but otherwise go on these websites fast and I will stop the talk with some questions actually I came here with more questions than answers and I'm really hoping for a lively discussion now because I'm not I'm not originally a developer so I kind of wrote this a bit on my own and I wonder if this interact integration of python and javascript is actually a good idea because in theory it would also be possible to probably do everything in javascript and maybe do it on the client side so you wouldn't have to install all these libraries then okay maybe one thing that I would like to show is that I experimented with temporal networks so of course doing temporal force layouts is kind of a non-trivial task but we can kind of look a little bit at the temporality of these networks by at least displaying only the links that that are active during a given day so this is also kind of nice I think but I would like to discuss maybe other visualization paradigms for this kind of network then one thing that would be really interesting I think is to dig deeper into a visualization paradigm for hierarchical structure of communities meaning that okay in theory I can either run stochastic block models or Luvain community detections and stop them at a certain level and then have some kind of hierarchical node structure but how to visualize that is another question but I think it would be very interesting especially for very large graphs and then another question is force layouts should we still use them now that everyone is doing node2vec and all these other things I think yes but maybe there's good arguments against it and on a more like deeper conceptual level is and this is a question the first one is a question for people who already have more much more experience in building tools for the social sciences is how do you kind of further integrate these kinds of methods into existing maybe also more qualitative social science pipelines so yes it's kind of an open question and how can we devise something like a research protocol for these kinds of interactive network visualizations because as you saw in my demo we kind of look at the big nodes we look at the tweets they made and it gives us some kind of intuition of what's going on in the debate but how can we formalize such kinds of visual network analysis and I think I mean there's people in the audience who actually work on this so I will be very interesting for me to talk about this and finally to end on actually maybe a bit nicer note is that there is the network of force them as we had already said in the beginning on this website so it is updated every 15 minutes thanks to a data collection done by my colleague Beatrice thank you very much and so if you go on this website you can see the retweet network of force them and if you tweet and you can find yourself in the network also so yeah what do we have here in the middle okay force them itself then there was Ubuntu they beyond somewhere okay time's up thank you yes so the question is I mentioned that you can only collect tweets from the last seven days with the free API this is a limitation but the tool itself just writes into existing CSV it depends basically so if you do the same keyword search multiple times and it will just depend to a CSV yes I mean this is the question right now it depends because the question is what happens on mastodon I don't know all these like if you want to look at political controversies and such discussions I don't know if mastodon is mature enough yet to or adopted enough yet I think if you want to look at the fostering community it's great so for this yes but yeah this kind of profit for the city and so well actually for me that's more aggressive to see the difference the stricter of this sort of this diagram that we are going to use about the social of what we are talking about let's see the conference of citizens with human people same in collection yeah I don't know what to think about that well I don't know which point exactly should I address because you raised a lot of so so are you okay if I can rephrase so you are concerned about these kinds of this kind of research also yes because because it can be used to track users across political camps right yes okay I see so I think it's more about the representativity of Twitter data for for the wide wider population which of course you're you're totally right it is kind of a subset of highly politicized maybe also a bit more educated than average people so you cannot but but this is not what we're trying to do also you're not trying to infer I don't know actually lecture results based on Twitter data so I yeah I don't know if I addressed the point now maybe we can take more about it right", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.64, "text": " Hi everyone, it's a big pleasure to be here.", "tokens": [2421, 1518, 11, 309, 311, 257, 955, 6834, 281, 312, 510, 13], "temperature": 0.0, "avg_logprob": -0.21518248525159112, "compression_ratio": 1.4836601307189543, "no_speech_prob": 0.16955500841140747}, {"id": 1, "seek": 0, "start": 12.64, "end": 20.240000000000002, "text": " My name is Armin Purnaki and I'm a PhD candidate in Applied Mathematics and I work on building", "tokens": [1222, 1315, 307, 1587, 2367, 430, 925, 7421, 293, 286, 478, 257, 14476, 11532, 294, 3132, 39459, 15776, 37541, 293, 286, 589, 322, 2390], "temperature": 0.0, "avg_logprob": -0.21518248525159112, "compression_ratio": 1.4836601307189543, "no_speech_prob": 0.16955500841140747}, {"id": 2, "seek": 0, "start": 20.240000000000002, "end": 27.36, "text": " tools for discourse analysis and we build tools for discourse analysis based on methods", "tokens": [3873, 337, 23938, 5215, 293, 321, 1322, 3873, 337, 23938, 5215, 2361, 322, 7150], "temperature": 0.0, "avg_logprob": -0.21518248525159112, "compression_ratio": 1.4836601307189543, "no_speech_prob": 0.16955500841140747}, {"id": 3, "seek": 2736, "start": 27.36, "end": 32.96, "text": " from graph theory, network science and natural language processing and today I want to present", "tokens": [490, 4295, 5261, 11, 3209, 3497, 293, 3303, 2856, 9007, 293, 965, 286, 528, 281, 1974], "temperature": 0.0, "avg_logprob": -0.15484227498372397, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00011601932055782527}, {"id": 4, "seek": 2736, "start": 32.96, "end": 39.879999999999995, "text": " a tool called the Twitter Explorer that is already a bit older but that was built in", "tokens": [257, 2290, 1219, 264, 5794, 31895, 300, 307, 1217, 257, 857, 4906, 457, 300, 390, 3094, 294], "temperature": 0.0, "avg_logprob": -0.15484227498372397, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00011601932055782527}, {"id": 5, "seek": 2736, "start": 39.879999999999995, "end": 45.56, "text": " the Max Planck Institute for Mathematics and Sciences in my previous group and the idea", "tokens": [264, 7402, 8112, 547, 9446, 337, 15776, 37541, 293, 21108, 294, 452, 3894, 1594, 293, 264, 1558], "temperature": 0.0, "avg_logprob": -0.15484227498372397, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00011601932055782527}, {"id": 6, "seek": 2736, "start": 45.56, "end": 51.08, "text": " was to build a tool that allows researchers who don't necessarily have programming skills", "tokens": [390, 281, 1322, 257, 2290, 300, 4045, 10309, 567, 500, 380, 4725, 362, 9410, 3942], "temperature": 0.0, "avg_logprob": -0.15484227498372397, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00011601932055782527}, {"id": 7, "seek": 5108, "start": 51.08, "end": 59.36, "text": " to collect Twitter data, visualize them using graphs and explore the data and maybe generate", "tokens": [281, 2500, 5794, 1412, 11, 23273, 552, 1228, 24877, 293, 6839, 264, 1412, 293, 1310, 8460], "temperature": 0.0, "avg_logprob": -0.12164642150143543, "compression_ratio": 1.694915254237288, "no_speech_prob": 5.245015199761838e-05}, {"id": 8, "seek": 5108, "start": 59.36, "end": 61.64, "text": " hypotheses in their pipelines.", "tokens": [49969, 294, 641, 40168, 13], "temperature": 0.0, "avg_logprob": -0.12164642150143543, "compression_ratio": 1.694915254237288, "no_speech_prob": 5.245015199761838e-05}, {"id": 9, "seek": 5108, "start": 61.64, "end": 67.64, "text": " So this kind of tool building and this research happens in the field called computational", "tokens": [407, 341, 733, 295, 2290, 2390, 293, 341, 2132, 2314, 294, 264, 2519, 1219, 28270], "temperature": 0.0, "avg_logprob": -0.12164642150143543, "compression_ratio": 1.694915254237288, "no_speech_prob": 5.245015199761838e-05}, {"id": 10, "seek": 5108, "start": 67.64, "end": 74.6, "text": " social science so when I was preparing my slides two days ago I thought it would be", "tokens": [2093, 3497, 370, 562, 286, 390, 10075, 452, 9788, 732, 1708, 2057, 286, 1194, 309, 576, 312], "temperature": 0.0, "avg_logprob": -0.12164642150143543, "compression_ratio": 1.694915254237288, "no_speech_prob": 5.245015199761838e-05}, {"id": 11, "seek": 5108, "start": 74.6, "end": 79.84, "text": " good to maybe give a little overview of computational social science then say why we built the Twitter", "tokens": [665, 281, 1310, 976, 257, 707, 12492, 295, 28270, 2093, 3497, 550, 584, 983, 321, 3094, 264, 5794], "temperature": 0.0, "avg_logprob": -0.12164642150143543, "compression_ratio": 1.694915254237288, "no_speech_prob": 5.245015199761838e-05}, {"id": 12, "seek": 7984, "start": 79.84, "end": 85.04, "text": " Explorer and where we saw somehow the need for a new tool, of course introduce the features", "tokens": [31895, 293, 689, 321, 1866, 6063, 264, 643, 337, 257, 777, 2290, 11, 295, 1164, 5366, 264, 4122], "temperature": 0.0, "avg_logprob": -0.10201105659390673, "compression_ratio": 1.6227272727272728, "no_speech_prob": 3.850263965432532e-05}, {"id": 13, "seek": 7984, "start": 85.04, "end": 90.36, "text": " of the tool because it's kind of a talk on programming, the architecture and maybe give", "tokens": [295, 264, 2290, 570, 309, 311, 733, 295, 257, 751, 322, 9410, 11, 264, 9482, 293, 1310, 976], "temperature": 0.0, "avg_logprob": -0.10201105659390673, "compression_ratio": 1.6227272727272728, "no_speech_prob": 3.850263965432532e-05}, {"id": 14, "seek": 7984, "start": 90.36, "end": 96.52000000000001, "text": " some insights on the usage but when I was sitting down to make the slides two days ago", "tokens": [512, 14310, 322, 264, 14924, 457, 562, 286, 390, 3798, 760, 281, 652, 264, 9788, 732, 1708, 2057], "temperature": 0.0, "avg_logprob": -0.10201105659390673, "compression_ratio": 1.6227272727272728, "no_speech_prob": 3.850263965432532e-05}, {"id": 15, "seek": 7984, "start": 96.52000000000001, "end": 107.92, "text": " I was confronted with this and of course since the tool is essentially an entry point into", "tokens": [286, 390, 31257, 365, 341, 293, 295, 1164, 1670, 264, 2290, 307, 4476, 364, 8729, 935, 666], "temperature": 0.0, "avg_logprob": -0.10201105659390673, "compression_ratio": 1.6227272727272728, "no_speech_prob": 3.850263965432532e-05}, {"id": 16, "seek": 10792, "start": 107.92, "end": 115.04, "text": " the free API there is also a part of it that uses the research API which of course led", "tokens": [264, 1737, 9362, 456, 307, 611, 257, 644, 295, 309, 300, 4960, 264, 2132, 9362, 597, 295, 1164, 4684], "temperature": 0.0, "avg_logprob": -0.16220480330446932, "compression_ratio": 1.665158371040724, "no_speech_prob": 2.8803158784285188e-05}, {"id": 17, "seek": 10792, "start": 115.04, "end": 119.64, "text": " us directly to this question, what happens to the research API?", "tokens": [505, 3838, 281, 341, 1168, 11, 437, 2314, 281, 264, 2132, 9362, 30], "temperature": 0.0, "avg_logprob": -0.16220480330446932, "compression_ratio": 1.665158371040724, "no_speech_prob": 2.8803158784285188e-05}, {"id": 18, "seek": 10792, "start": 119.64, "end": 123.6, "text": " It's also not entirely clear, right?", "tokens": [467, 311, 611, 406, 7696, 1850, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.16220480330446932, "compression_ratio": 1.665158371040724, "no_speech_prob": 2.8803158784285188e-05}, {"id": 19, "seek": 10792, "start": 123.6, "end": 131.28, "text": " So I want to maybe instead of giving this the talk the way I was planning to do it, I will", "tokens": [407, 286, 528, 281, 1310, 2602, 295, 2902, 341, 264, 751, 264, 636, 286, 390, 5038, 281, 360, 309, 11, 286, 486], "temperature": 0.0, "avg_logprob": -0.16220480330446932, "compression_ratio": 1.665158371040724, "no_speech_prob": 2.8803158784285188e-05}, {"id": 20, "seek": 10792, "start": 131.28, "end": 136.2, "text": " do it but maybe I wanted to ask a few questions first that we might then discuss maybe in", "tokens": [360, 309, 457, 1310, 286, 1415, 281, 1029, 257, 1326, 1651, 700, 300, 321, 1062, 550, 2248, 1310, 294], "temperature": 0.0, "avg_logprob": -0.16220480330446932, "compression_ratio": 1.665158371040724, "no_speech_prob": 2.8803158784285188e-05}, {"id": 21, "seek": 13620, "start": 136.2, "end": 140.07999999999998, "text": " the discussion also and I think there is even some kind of something planned later right", "tokens": [264, 5017, 611, 293, 286, 519, 456, 307, 754, 512, 733, 295, 746, 8589, 1780, 558], "temperature": 0.0, "avg_logprob": -0.14813057417722092, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00017297817976213992}, {"id": 22, "seek": 13620, "start": 140.07999999999998, "end": 144.67999999999998, "text": " so some kind of panel discussion so I'm just going to throw some questions out there that", "tokens": [370, 512, 733, 295, 4831, 5017, 370, 286, 478, 445, 516, 281, 3507, 512, 1651, 484, 456, 300], "temperature": 0.0, "avg_logprob": -0.14813057417722092, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00017297817976213992}, {"id": 23, "seek": 13620, "start": 144.67999999999998, "end": 149.79999999999998, "text": " I think are really pressing now especially in the research field.", "tokens": [286, 519, 366, 534, 12417, 586, 2318, 294, 264, 2132, 2519, 13], "temperature": 0.0, "avg_logprob": -0.14813057417722092, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00017297817976213992}, {"id": 24, "seek": 13620, "start": 149.79999999999998, "end": 154.39999999999998, "text": " How serious is this but this I don't mean the implications of it because I know a few", "tokens": [1012, 3156, 307, 341, 457, 341, 286, 500, 380, 914, 264, 16602, 295, 309, 570, 286, 458, 257, 1326], "temperature": 0.0, "avg_logprob": -0.14813057417722092, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00017297817976213992}, {"id": 25, "seek": 13620, "start": 154.39999999999998, "end": 159.23999999999998, "text": " people whose thesis is now in jeopardy because they can't collect data in a way but how serious", "tokens": [561, 6104, 22288, 307, 586, 294, 44295, 88, 570, 436, 393, 380, 2500, 1412, 294, 257, 636, 457, 577, 3156], "temperature": 0.0, "avg_logprob": -0.14813057417722092, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00017297817976213992}, {"id": 26, "seek": 15924, "start": 159.24, "end": 166.12, "text": " is it in the sense, how serious is it in the sense, will it actually happen or is it some", "tokens": [307, 309, 294, 264, 2020, 11, 577, 3156, 307, 309, 294, 264, 2020, 11, 486, 309, 767, 1051, 420, 307, 309, 512], "temperature": 0.0, "avg_logprob": -0.1550198509579613, "compression_ratio": 1.766497461928934, "no_speech_prob": 2.616982237668708e-05}, {"id": 27, "seek": 15924, "start": 166.12, "end": 173.32000000000002, "text": " scare tactic so I think this is something that is hard to predict and then these are", "tokens": [17185, 31012, 370, 286, 519, 341, 307, 746, 300, 307, 1152, 281, 6069, 293, 550, 613, 366], "temperature": 0.0, "avg_logprob": -0.1550198509579613, "compression_ratio": 1.766497461928934, "no_speech_prob": 2.616982237668708e-05}, {"id": 28, "seek": 15924, "start": 173.32000000000002, "end": 179.0, "text": " questions also I think that we can discuss here is how or is there a way for us as users", "tokens": [1651, 611, 286, 519, 300, 321, 393, 2248, 510, 307, 577, 420, 307, 456, 257, 636, 337, 505, 382, 5022], "temperature": 0.0, "avg_logprob": -0.1550198509579613, "compression_ratio": 1.766497461928934, "no_speech_prob": 2.616982237668708e-05}, {"id": 29, "seek": 15924, "start": 179.0, "end": 184.4, "text": " and not necessarily only as researchers to claim our data or our digital traces that", "tokens": [293, 406, 4725, 787, 382, 10309, 281, 3932, 527, 1412, 420, 527, 4562, 26076, 300], "temperature": 0.0, "avg_logprob": -0.1550198509579613, "compression_ratio": 1.766497461928934, "no_speech_prob": 2.616982237668708e-05}, {"id": 30, "seek": 18440, "start": 184.4, "end": 189.56, "text": " we use and that we leave on these platforms and how can things like the Digital Services", "tokens": [321, 764, 293, 300, 321, 1856, 322, 613, 9473, 293, 577, 393, 721, 411, 264, 15522, 12124], "temperature": 0.0, "avg_logprob": -0.10205922968247358, "compression_ratio": 1.7425742574257426, "no_speech_prob": 0.00011310918489471078}, {"id": 31, "seek": 18440, "start": 189.56, "end": 197.96, "text": " Act play a role in this and the last question is very broad but how do we move on in the", "tokens": [3251, 862, 257, 3090, 294, 341, 293, 264, 1036, 1168, 307, 588, 4152, 457, 577, 360, 321, 1286, 322, 294, 264], "temperature": 0.0, "avg_logprob": -0.10205922968247358, "compression_ratio": 1.7425742574257426, "no_speech_prob": 0.00011310918489471078}, {"id": 32, "seek": 18440, "start": 197.96, "end": 205.48000000000002, "text": " sense of how can we see this as some kind of wake up call maybe and how can we use this", "tokens": [2020, 295, 577, 393, 321, 536, 341, 382, 512, 733, 295, 6634, 493, 818, 1310, 293, 577, 393, 321, 764, 341], "temperature": 0.0, "avg_logprob": -0.10205922968247358, "compression_ratio": 1.7425742574257426, "no_speech_prob": 0.00011310918489471078}, {"id": 33, "seek": 18440, "start": 205.48000000000002, "end": 211.04000000000002, "text": " new development to maybe on one hand move to different platforms but on the other hand", "tokens": [777, 3250, 281, 1310, 322, 472, 1011, 1286, 281, 819, 9473, 457, 322, 264, 661, 1011], "temperature": 0.0, "avg_logprob": -0.10205922968247358, "compression_ratio": 1.7425742574257426, "no_speech_prob": 0.00011310918489471078}, {"id": 34, "seek": 21104, "start": 211.04, "end": 216.92, "text": " also to think about how we do computational social science in the future.", "tokens": [611, 281, 519, 466, 577, 321, 360, 28270, 2093, 3497, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.15483987958807693, "compression_ratio": 1.683168316831683, "no_speech_prob": 3.572460263967514e-05}, {"id": 35, "seek": 21104, "start": 216.92, "end": 220.6, "text": " So with these questions that we're going to discuss later I'm still going to give my", "tokens": [407, 365, 613, 1651, 300, 321, 434, 516, 281, 2248, 1780, 286, 478, 920, 516, 281, 976, 452], "temperature": 0.0, "avg_logprob": -0.15483987958807693, "compression_ratio": 1.683168316831683, "no_speech_prob": 3.572460263967514e-05}, {"id": 36, "seek": 21104, "start": 220.6, "end": 229.39999999999998, "text": " original talk so in computational social science a typical pipeline for a project is you have", "tokens": [3380, 751, 370, 294, 28270, 2093, 3497, 257, 7476, 15517, 337, 257, 1716, 307, 291, 362], "temperature": 0.0, "avg_logprob": -0.15483987958807693, "compression_ratio": 1.683168316831683, "no_speech_prob": 3.572460263967514e-05}, {"id": 37, "seek": 21104, "start": 229.39999999999998, "end": 235.88, "text": " a research question then you collect data related to it and in this case it may be data", "tokens": [257, 2132, 1168, 550, 291, 2500, 1412, 4077, 281, 309, 293, 294, 341, 1389, 309, 815, 312, 1412], "temperature": 0.0, "avg_logprob": -0.15483987958807693, "compression_ratio": 1.683168316831683, "no_speech_prob": 3.572460263967514e-05}, {"id": 38, "seek": 23588, "start": 235.88, "end": 241.96, "text": " from online social platforms and then you analyze it and ideally you generated some", "tokens": [490, 2950, 2093, 9473, 293, 550, 291, 12477, 309, 293, 22915, 291, 10833, 512], "temperature": 0.0, "avg_logprob": -0.13384562350334006, "compression_ratio": 1.8235294117647058, "no_speech_prob": 2.3478336515836418e-05}, {"id": 39, "seek": 23588, "start": 241.96, "end": 246.12, "text": " more insights on the research question you had in the beginning and sometimes the exploration", "tokens": [544, 14310, 322, 264, 2132, 1168, 291, 632, 294, 264, 2863, 293, 2171, 264, 16197], "temperature": 0.0, "avg_logprob": -0.13384562350334006, "compression_ratio": 1.8235294117647058, "no_speech_prob": 2.3478336515836418e-05}, {"id": 40, "seek": 23588, "start": 246.12, "end": 250.88, "text": " and the analysis of the data can help you maybe refine also the questions you had in", "tokens": [293, 264, 5215, 295, 264, 1412, 393, 854, 291, 1310, 33906, 611, 264, 1651, 291, 632, 294], "temperature": 0.0, "avg_logprob": -0.13384562350334006, "compression_ratio": 1.8235294117647058, "no_speech_prob": 2.3478336515836418e-05}, {"id": 41, "seek": 23588, "start": 250.88, "end": 256.44, "text": " the beginning so it's some kind of loop that you can see in this way and the tool that", "tokens": [264, 2863, 370, 309, 311, 512, 733, 295, 6367, 300, 291, 393, 536, 294, 341, 636, 293, 264, 2290, 300], "temperature": 0.0, "avg_logprob": -0.13384562350334006, "compression_ratio": 1.8235294117647058, "no_speech_prob": 2.3478336515836418e-05}, {"id": 42, "seek": 23588, "start": 256.44, "end": 261.96, "text": " I'm going to present the Twitter Explorer is precisely made for this second part for", "tokens": [286, 478, 516, 281, 1974, 264, 5794, 31895, 307, 13402, 1027, 337, 341, 1150, 644, 337], "temperature": 0.0, "avg_logprob": -0.13384562350334006, "compression_ratio": 1.8235294117647058, "no_speech_prob": 2.3478336515836418e-05}, {"id": 43, "seek": 26196, "start": 261.96, "end": 269.47999999999996, "text": " both facilitating the collection and also the exploration of such data and this pipeline", "tokens": [1293, 47558, 264, 5765, 293, 611, 264, 16197, 295, 1270, 1412, 293, 341, 15517], "temperature": 0.0, "avg_logprob": -0.09334759223155487, "compression_ratio": 1.7352941176470589, "no_speech_prob": 5.61892447876744e-05}, {"id": 44, "seek": 26196, "start": 269.47999999999996, "end": 275.96, "text": " is that we start with text so in our case it's tweets that are annotated with some kind", "tokens": [307, 300, 321, 722, 365, 2487, 370, 294, 527, 1389, 309, 311, 25671, 300, 366, 25339, 770, 365, 512, 733], "temperature": 0.0, "avg_logprob": -0.09334759223155487, "compression_ratio": 1.7352941176470589, "no_speech_prob": 5.61892447876744e-05}, {"id": 45, "seek": 26196, "start": 275.96, "end": 281.28, "text": " of metadata we have on Twitter different types of interactions so you can mention someone", "tokens": [295, 26603, 321, 362, 322, 5794, 819, 3467, 295, 13280, 370, 291, 393, 2152, 1580], "temperature": 0.0, "avg_logprob": -0.09334759223155487, "compression_ratio": 1.7352941176470589, "no_speech_prob": 5.61892447876744e-05}, {"id": 46, "seek": 26196, "start": 281.28, "end": 289.67999999999995, "text": " you can reply to someone or retweet and we choose one type of metadata and cast it into", "tokens": [291, 393, 16972, 281, 1580, 420, 1533, 10354, 293, 321, 2826, 472, 2010, 295, 26603, 293, 4193, 309, 666], "temperature": 0.0, "avg_logprob": -0.09334759223155487, "compression_ratio": 1.7352941176470589, "no_speech_prob": 5.61892447876744e-05}, {"id": 47, "seek": 28968, "start": 289.68, "end": 298.16, "text": " an interaction network and then we want to find the most significant for instance clusters", "tokens": [364, 9285, 3209, 293, 550, 321, 528, 281, 915, 264, 881, 4776, 337, 5197, 23313], "temperature": 0.0, "avg_logprob": -0.10759843190511068, "compression_ratio": 1.6777251184834123, "no_speech_prob": 8.699357567820698e-05}, {"id": 48, "seek": 28968, "start": 298.16, "end": 305.36, "text": " or the significant correlations in this data by using 2D spatializations and typically", "tokens": [420, 264, 4776, 13983, 763, 294, 341, 1412, 538, 1228, 568, 35, 23598, 14455, 293, 5850], "temperature": 0.0, "avg_logprob": -0.10759843190511068, "compression_ratio": 1.6777251184834123, "no_speech_prob": 8.699357567820698e-05}, {"id": 49, "seek": 28968, "start": 305.36, "end": 310.28000000000003, "text": " these are done using force layouts but today for instance in the graph room there were", "tokens": [613, 366, 1096, 1228, 3464, 46100, 457, 965, 337, 5197, 294, 264, 4295, 1808, 456, 645], "temperature": 0.0, "avg_logprob": -0.10759843190511068, "compression_ratio": 1.6777251184834123, "no_speech_prob": 8.699357567820698e-05}, {"id": 50, "seek": 28968, "start": 310.28000000000003, "end": 314.88, "text": " also some talks about new methods of node embedding and so I think this is also something", "tokens": [611, 512, 6686, 466, 777, 7150, 295, 9984, 12240, 3584, 293, 370, 286, 519, 341, 307, 611, 746], "temperature": 0.0, "avg_logprob": -0.10759843190511068, "compression_ratio": 1.6777251184834123, "no_speech_prob": 8.699357567820698e-05}, {"id": 51, "seek": 31488, "start": 314.88, "end": 321.84, "text": " that we can discuss maybe in the question section but one reason why I think force layouts", "tokens": [300, 321, 393, 2248, 1310, 294, 264, 1168, 3541, 457, 472, 1778, 983, 286, 519, 3464, 46100], "temperature": 0.0, "avg_logprob": -0.10304704030354818, "compression_ratio": 1.6061946902654867, "no_speech_prob": 3.5287783248350024e-05}, {"id": 52, "seek": 31488, "start": 321.84, "end": 327.24, "text": " are good is that especially if you use them in a context where you work with social science", "tokens": [366, 665, 307, 300, 2318, 498, 291, 764, 552, 294, 257, 4319, 689, 291, 589, 365, 2093, 3497], "temperature": 0.0, "avg_logprob": -0.10304704030354818, "compression_ratio": 1.6061946902654867, "no_speech_prob": 3.5287783248350024e-05}, {"id": 53, "seek": 31488, "start": 327.24, "end": 333.2, "text": " researchers who don't necessarily have a lot of knowledge about the latest machine learning", "tokens": [10309, 567, 500, 380, 4725, 362, 257, 688, 295, 3601, 466, 264, 6792, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.10304704030354818, "compression_ratio": 1.6061946902654867, "no_speech_prob": 3.5287783248350024e-05}, {"id": 54, "seek": 31488, "start": 333.2, "end": 338.64, "text": " algorithms they are quite straightforward to explain in the sense that you have a spring", "tokens": [14642, 436, 366, 1596, 15325, 281, 2903, 294, 264, 2020, 300, 291, 362, 257, 5587], "temperature": 0.0, "avg_logprob": -0.10304704030354818, "compression_ratio": 1.6061946902654867, "no_speech_prob": 3.5287783248350024e-05}, {"id": 55, "seek": 33864, "start": 338.64, "end": 345.64, "text": " system and nodes that are strongly connected tend to attract each other and especially if", "tokens": [1185, 293, 13891, 300, 366, 10613, 4582, 3928, 281, 5049, 1184, 661, 293, 2318, 498], "temperature": 0.0, "avg_logprob": -0.12833700953303157, "compression_ratio": 1.6090909090909091, "no_speech_prob": 4.1911865992005914e-05}, {"id": 56, "seek": 33864, "start": 345.64, "end": 352.36, "text": " you look at interaction networks on Twitter since retweeting can be considered endorsement", "tokens": [291, 574, 412, 9285, 9590, 322, 5794, 1670, 1533, 826, 9880, 393, 312, 4888, 29228, 518], "temperature": 0.0, "avg_logprob": -0.12833700953303157, "compression_ratio": 1.6090909090909091, "no_speech_prob": 4.1911865992005914e-05}, {"id": 57, "seek": 33864, "start": 352.36, "end": 357.84, "text": " open clusters in such 2D spatializations can then correspond to something like opinion", "tokens": [1269, 23313, 294, 1270, 568, 35, 23598, 14455, 393, 550, 6805, 281, 746, 411, 4800], "temperature": 0.0, "avg_logprob": -0.12833700953303157, "compression_ratio": 1.6090909090909091, "no_speech_prob": 4.1911865992005914e-05}, {"id": 58, "seek": 33864, "start": 357.84, "end": 364.08, "text": " clusters and there's a lot of research being done in that way but one question that we", "tokens": [23313, 293, 456, 311, 257, 688, 295, 2132, 885, 1096, 294, 300, 636, 457, 472, 1168, 300, 321], "temperature": 0.0, "avg_logprob": -0.12833700953303157, "compression_ratio": 1.6090909090909091, "no_speech_prob": 4.1911865992005914e-05}, {"id": 59, "seek": 36408, "start": 364.08, "end": 368.91999999999996, "text": " always had when we look at these networks is how do we actually go back to the data", "tokens": [1009, 632, 562, 321, 574, 412, 613, 9590, 307, 577, 360, 321, 767, 352, 646, 281, 264, 1412], "temperature": 0.0, "avg_logprob": -0.1288438920051821, "compression_ratio": 1.8008130081300813, "no_speech_prob": 3.365589145687409e-05}, {"id": 60, "seek": 36408, "start": 368.91999999999996, "end": 374.56, "text": " that generated them and this is something that we try to tackle with building these", "tokens": [300, 10833, 552, 293, 341, 307, 746, 300, 321, 853, 281, 14896, 365, 2390, 613], "temperature": 0.0, "avg_logprob": -0.1288438920051821, "compression_ratio": 1.8008130081300813, "no_speech_prob": 3.365589145687409e-05}, {"id": 61, "seek": 36408, "start": 374.56, "end": 381.2, "text": " tools so why we built it is firstly to provide an interface for researchers without programming", "tokens": [3873, 370, 983, 321, 3094, 309, 307, 27376, 281, 2893, 364, 9226, 337, 10309, 1553, 9410], "temperature": 0.0, "avg_logprob": -0.1288438920051821, "compression_ratio": 1.8008130081300813, "no_speech_prob": 3.365589145687409e-05}, {"id": 62, "seek": 36408, "start": 381.2, "end": 385.71999999999997, "text": " skills also to collect and visualize the data because we were working a lot with social", "tokens": [3942, 611, 281, 2500, 293, 23273, 264, 1412, 570, 321, 645, 1364, 257, 688, 365, 2093], "temperature": 0.0, "avg_logprob": -0.1288438920051821, "compression_ratio": 1.8008130081300813, "no_speech_prob": 3.365589145687409e-05}, {"id": 63, "seek": 36408, "start": 385.71999999999997, "end": 392.03999999999996, "text": " scientists that did not have these programming skills but had a lot of hypotheses about the", "tokens": [7708, 300, 630, 406, 362, 613, 9410, 3942, 457, 632, 257, 688, 295, 49969, 466, 264], "temperature": 0.0, "avg_logprob": -0.1288438920051821, "compression_ratio": 1.8008130081300813, "no_speech_prob": 3.365589145687409e-05}, {"id": 64, "seek": 39204, "start": 392.04, "end": 398.56, "text": " data that they could not test then of course to facilitate the exploration of controversial", "tokens": [1412, 300, 436, 727, 406, 1500, 550, 295, 1164, 281, 20207, 264, 16197, 295, 17323], "temperature": 0.0, "avg_logprob": -0.08311487792374252, "compression_ratio": 1.6788990825688073, "no_speech_prob": 4.458250623429194e-05}, {"id": 65, "seek": 39204, "start": 398.56, "end": 405.92, "text": " issues on social media and this is the point that I was making before is add some layer", "tokens": [2663, 322, 2093, 3021, 293, 341, 307, 264, 935, 300, 286, 390, 1455, 949, 307, 909, 512, 4583], "temperature": 0.0, "avg_logprob": -0.08311487792374252, "compression_ratio": 1.6788990825688073, "no_speech_prob": 4.458250623429194e-05}, {"id": 66, "seek": 39204, "start": 405.92, "end": 412.12, "text": " of interpretability to these 2D spatializations by providing an access from within the interface", "tokens": [295, 7302, 2310, 281, 613, 568, 35, 23598, 14455, 538, 6530, 364, 2105, 490, 1951, 264, 9226], "temperature": 0.0, "avg_logprob": -0.08311487792374252, "compression_ratio": 1.6788990825688073, "no_speech_prob": 4.458250623429194e-05}, {"id": 67, "seek": 39204, "start": 412.12, "end": 420.32000000000005, "text": " to the actual data that created these node positions and finally we see it in the context", "tokens": [281, 264, 3539, 1412, 300, 2942, 613, 9984, 8432, 293, 2721, 321, 536, 309, 294, 264, 4319], "temperature": 0.0, "avg_logprob": -0.08311487792374252, "compression_ratio": 1.6788990825688073, "no_speech_prob": 4.458250623429194e-05}, {"id": 68, "seek": 42032, "start": 420.32, "end": 427.56, "text": " of a larger scientific scope of using the network paradigm as something like a sampling", "tokens": [295, 257, 4833, 8134, 11923, 295, 1228, 264, 3209, 24709, 382, 746, 411, 257, 21179], "temperature": 0.0, "avg_logprob": -0.08174393500810788, "compression_ratio": 1.6589861751152073, "no_speech_prob": 3.4194021282019094e-05}, {"id": 69, "seek": 42032, "start": 427.56, "end": 433.6, "text": " mechanism for the data because if you're confronted with a large number of tweets for instance", "tokens": [7513, 337, 264, 1412, 570, 498, 291, 434, 31257, 365, 257, 2416, 1230, 295, 25671, 337, 5197], "temperature": 0.0, "avg_logprob": -0.08174393500810788, "compression_ratio": 1.6589861751152073, "no_speech_prob": 3.4194021282019094e-05}, {"id": 70, "seek": 42032, "start": 433.6, "end": 437.71999999999997, "text": " of course everyone knows that you can't read all of them manually so you need some kind", "tokens": [295, 1164, 1518, 3255, 300, 291, 393, 380, 1401, 439, 295, 552, 16945, 370, 291, 643, 512, 733], "temperature": 0.0, "avg_logprob": -0.08174393500810788, "compression_ratio": 1.6589861751152073, "no_speech_prob": 3.4194021282019094e-05}, {"id": 71, "seek": 42032, "start": 437.71999999999997, "end": 445.08, "text": " of way to get to the tweets that are relevant for you to read and this is what we use the", "tokens": [295, 636, 281, 483, 281, 264, 25671, 300, 366, 7340, 337, 291, 281, 1401, 293, 341, 307, 437, 321, 764, 264], "temperature": 0.0, "avg_logprob": -0.08174393500810788, "compression_ratio": 1.6589861751152073, "no_speech_prob": 3.4194021282019094e-05}, {"id": 72, "seek": 44508, "start": 445.08, "end": 450.71999999999997, "text": " network for essentially so when we look at read-read networks immediately identify for", "tokens": [3209, 337, 4476, 370, 562, 321, 574, 412, 1401, 12, 2538, 9590, 4258, 5876, 337], "temperature": 0.0, "avg_logprob": -0.15547253634478594, "compression_ratio": 1.7772277227722773, "no_speech_prob": 7.013625872787088e-05}, {"id": 73, "seek": 44508, "start": 450.71999999999997, "end": 455.96, "text": " instance the most influential actors in the debate and then read precisely those tweets", "tokens": [5197, 264, 881, 22215, 10037, 294, 264, 7958, 293, 550, 1401, 13402, 729, 25671], "temperature": 0.0, "avg_logprob": -0.15547253634478594, "compression_ratio": 1.7772277227722773, "no_speech_prob": 7.013625872787088e-05}, {"id": 74, "seek": 44508, "start": 455.96, "end": 462.84, "text": " that they made to maybe influence other actors and we call this guided close reading because", "tokens": [300, 436, 1027, 281, 1310, 6503, 661, 10037, 293, 321, 818, 341, 19663, 1998, 3760, 570], "temperature": 0.0, "avg_logprob": -0.15547253634478594, "compression_ratio": 1.7772277227722773, "no_speech_prob": 7.013625872787088e-05}, {"id": 75, "seek": 44508, "start": 462.84, "end": 468.52, "text": " if you do only close reading then you have to read all the text if you have distant reading", "tokens": [498, 291, 360, 787, 1998, 3760, 550, 291, 362, 281, 1401, 439, 264, 2487, 498, 291, 362, 17275, 3760], "temperature": 0.0, "avg_logprob": -0.15547253634478594, "compression_ratio": 1.7772277227722773, "no_speech_prob": 7.013625872787088e-05}, {"id": 76, "seek": 46852, "start": 468.52, "end": 478.03999999999996, "text": " you kind of look only at the network on a structure level and this is something in between", "tokens": [291, 733, 295, 574, 787, 412, 264, 3209, 322, 257, 3877, 1496, 293, 341, 307, 746, 294, 1296], "temperature": 0.0, "avg_logprob": -0.14031432015555245, "compression_ratio": 1.5502958579881656, "no_speech_prob": 5.628217331832275e-05}, {"id": 77, "seek": 46852, "start": 478.03999999999996, "end": 485.96, "text": " so what can the tool do it collects tweets I mean I think we have like one week left", "tokens": [370, 437, 393, 264, 2290, 360, 309, 39897, 25671, 286, 914, 286, 519, 321, 362, 411, 472, 1243, 1411], "temperature": 0.0, "avg_logprob": -0.14031432015555245, "compression_ratio": 1.5502958579881656, "no_speech_prob": 5.628217331832275e-05}, {"id": 78, "seek": 46852, "start": 485.96, "end": 495.08, "text": " for the v2 and the v1 so far the v2 academic is safe but we don't know that so you can", "tokens": [337, 264, 371, 17, 293, 264, 371, 16, 370, 1400, 264, 371, 17, 7778, 307, 3273, 457, 321, 500, 380, 458, 300, 370, 291, 393], "temperature": 0.0, "avg_logprob": -0.14031432015555245, "compression_ratio": 1.5502958579881656, "no_speech_prob": 5.628217331832275e-05}, {"id": 79, "seek": 49508, "start": 495.08, "end": 500.8, "text": " search for it from the past seven days using the API and in the second part in the visualizer", "tokens": [3164, 337, 309, 490, 264, 1791, 3407, 1708, 1228, 264, 9362, 293, 294, 264, 1150, 644, 294, 264, 5056, 6545], "temperature": 0.0, "avg_logprob": -0.14217132613772437, "compression_ratio": 1.6651162790697673, "no_speech_prob": 8.450236055068672e-05}, {"id": 80, "seek": 49508, "start": 500.8, "end": 505.24, "text": " you can do display just a simple time series of the tweets to see maybe if there's some", "tokens": [291, 393, 360, 4674, 445, 257, 2199, 565, 2638, 295, 264, 25671, 281, 536, 1310, 498, 456, 311, 512], "temperature": 0.0, "avg_logprob": -0.14217132613772437, "compression_ratio": 1.6651162790697673, "no_speech_prob": 8.450236055068672e-05}, {"id": 81, "seek": 49508, "start": 505.24, "end": 514.0, "text": " kind of special activity during one day you can build these interaction networks build", "tokens": [733, 295, 2121, 5191, 1830, 472, 786, 291, 393, 1322, 613, 9285, 9590, 1322], "temperature": 0.0, "avg_logprob": -0.14217132613772437, "compression_ratio": 1.6651162790697673, "no_speech_prob": 8.450236055068672e-05}, {"id": 82, "seek": 49508, "start": 514.0, "end": 518.84, "text": " co-hashtag networks so we divide it into some kind of two types of networks which we call", "tokens": [598, 12, 12438, 357, 559, 9590, 370, 321, 9845, 309, 666, 512, 733, 295, 732, 3467, 295, 9590, 597, 321, 818], "temperature": 0.0, "avg_logprob": -0.14217132613772437, "compression_ratio": 1.6651162790697673, "no_speech_prob": 8.450236055068672e-05}, {"id": 83, "seek": 51884, "start": 518.84, "end": 525.72, "text": " semantic networks and interaction networks and then you can compute the typical measures", "tokens": [47982, 9590, 293, 9285, 9590, 293, 550, 291, 393, 14722, 264, 7476, 8000], "temperature": 0.0, "avg_logprob": -0.14711511836332433, "compression_ratio": 1.7107843137254901, "no_speech_prob": 8.07293108664453e-05}, {"id": 84, "seek": 51884, "start": 525.72, "end": 532.88, "text": " people compute on networks and especially compute clusters like using modularity based", "tokens": [561, 14722, 322, 9590, 293, 2318, 14722, 23313, 411, 1228, 31111, 507, 2361], "temperature": 0.0, "avg_logprob": -0.14711511836332433, "compression_ratio": 1.7107843137254901, "no_speech_prob": 8.07293108664453e-05}, {"id": 85, "seek": 51884, "start": 532.88, "end": 540.6, "text": " algorithms and all this happens in some kind of interactive interface using JavaScript", "tokens": [14642, 293, 439, 341, 2314, 294, 512, 733, 295, 15141, 9226, 1228, 15778], "temperature": 0.0, "avg_logprob": -0.14711511836332433, "compression_ratio": 1.7107843137254901, "no_speech_prob": 8.07293108664453e-05}, {"id": 86, "seek": 51884, "start": 540.6, "end": 547.12, "text": " and D3JS and this is essentially the part where it gets interesting because so far all", "tokens": [293, 413, 18, 41, 50, 293, 341, 307, 4476, 264, 644, 689, 309, 2170, 1880, 570, 370, 1400, 439], "temperature": 0.0, "avg_logprob": -0.14711511836332433, "compression_ratio": 1.7107843137254901, "no_speech_prob": 8.07293108664453e-05}, {"id": 87, "seek": 54712, "start": 547.12, "end": 552.52, "text": " the other things you can do it with a lot of other tools especially like AFI or I think", "tokens": [264, 661, 721, 291, 393, 360, 309, 365, 257, 688, 295, 661, 3873, 2318, 411, 20389, 40, 420, 286, 519], "temperature": 0.0, "avg_logprob": -0.13228014432466947, "compression_ratio": 1.6518987341772151, "no_speech_prob": 9.745662828208879e-05}, {"id": 88, "seek": 54712, "start": 552.52, "end": 556.8, "text": " you can even collect tweets right with some plugins so I think all of this is not new", "tokens": [291, 393, 754, 2500, 25671, 558, 365, 512, 33759, 370, 286, 519, 439, 295, 341, 307, 406, 777], "temperature": 0.0, "avg_logprob": -0.13228014432466947, "compression_ratio": 1.6518987341772151, "no_speech_prob": 9.745662828208879e-05}, {"id": 89, "seek": 54712, "start": 556.8, "end": 563.44, "text": " and this is kind of where it gets interesting and I think this is time for a quick demo", "tokens": [293, 341, 307, 733, 295, 689, 309, 2170, 1880, 293, 286, 519, 341, 307, 565, 337, 257, 1702, 10723], "temperature": 0.0, "avg_logprob": -0.13228014432466947, "compression_ratio": 1.6518987341772151, "no_speech_prob": 9.745662828208879e-05}, {"id": 90, "seek": 56344, "start": 563.44, "end": 581.2, "text": " I don't know how much okay I have plenty of time I think I talk too fast okay so I have", "tokens": [286, 500, 380, 458, 577, 709, 1392, 286, 362, 7140, 295, 565, 286, 519, 286, 751, 886, 2370, 1392, 370, 286, 362], "temperature": 0.0, "avg_logprob": -0.22683013357767245, "compression_ratio": 1.348148148148148, "no_speech_prob": 0.00013751057849731296}, {"id": 91, "seek": 56344, "start": 581.2, "end": 586.8800000000001, "text": " prepared some Python environments that already have the Twitter Explorer installed but usually", "tokens": [4927, 512, 15329, 12388, 300, 1217, 362, 264, 5794, 31895, 8899, 457, 2673], "temperature": 0.0, "avg_logprob": -0.22683013357767245, "compression_ratio": 1.348148148148148, "no_speech_prob": 0.00013751057849731296}, {"id": 92, "seek": 58688, "start": 586.88, "end": 597.68, "text": " you would do it like this and then all you need to do to fire up this interactive interface", "tokens": [291, 576, 360, 309, 411, 341, 293, 550, 439, 291, 643, 281, 360, 281, 2610, 493, 341, 15141, 9226], "temperature": 0.0, "avg_logprob": -0.10262825571257493, "compression_ratio": 1.5290697674418605, "no_speech_prob": 4.1288592910859734e-05}, {"id": 93, "seek": 58688, "start": 597.68, "end": 605.48, "text": " is type Twitter Explorer collector and this will open a browser window from which you", "tokens": [307, 2010, 5794, 31895, 23960, 293, 341, 486, 1269, 257, 11185, 4910, 490, 597, 291], "temperature": 0.0, "avg_logprob": -0.10262825571257493, "compression_ratio": 1.5290697674418605, "no_speech_prob": 4.1288592910859734e-05}, {"id": 94, "seek": 58688, "start": 605.48, "end": 614.92, "text": " can choose your API access choose the path to which the tweets will be downloaded and", "tokens": [393, 2826, 428, 9362, 2105, 2826, 264, 3100, 281, 597, 264, 25671, 486, 312, 21748, 293], "temperature": 0.0, "avg_logprob": -0.10262825571257493, "compression_ratio": 1.5290697674418605, "no_speech_prob": 4.1288592910859734e-05}, {"id": 95, "seek": 61492, "start": 614.92, "end": 621.28, "text": " insert your search query maybe adding some advanced settings and saving options so I", "tokens": [8969, 428, 3164, 14581, 1310, 5127, 512, 7339, 6257, 293, 6816, 3956, 370, 286], "temperature": 0.0, "avg_logprob": -0.1354206158564641, "compression_ratio": 1.6893203883495145, "no_speech_prob": 0.0002112408692482859}, {"id": 96, "seek": 61492, "start": 621.28, "end": 629.7199999999999, "text": " don't know this is a question to the audience now what we should search for this is easy", "tokens": [500, 380, 458, 341, 307, 257, 1168, 281, 264, 4034, 586, 437, 321, 820, 3164, 337, 341, 307, 1858], "temperature": 0.0, "avg_logprob": -0.1354206158564641, "compression_ratio": 1.6893203883495145, "no_speech_prob": 0.0002112408692482859}, {"id": 97, "seek": 61492, "start": 629.7199999999999, "end": 633.92, "text": " and I already this is you're looking into the future I already have this network prepared", "tokens": [293, 286, 1217, 341, 307, 291, 434, 1237, 666, 264, 2027, 286, 1217, 362, 341, 3209, 4927], "temperature": 0.0, "avg_logprob": -0.1354206158564641, "compression_ratio": 1.6893203883495145, "no_speech_prob": 0.0002112408692482859}, {"id": 98, "seek": 61492, "start": 633.92, "end": 643.24, "text": " for the last slide sorry we could but what would we look for then API is there maybe", "tokens": [337, 264, 1036, 4137, 2597, 321, 727, 457, 437, 576, 321, 574, 337, 550, 9362, 307, 456, 1310], "temperature": 0.0, "avg_logprob": -0.1354206158564641, "compression_ratio": 1.6893203883495145, "no_speech_prob": 0.0002112408692482859}, {"id": 99, "seek": 64324, "start": 643.24, "end": 656.84, "text": " a hashtag like API shutdown maybe we need to go to Twitter itself API something like", "tokens": [257, 20379, 411, 9362, 34927, 1310, 321, 643, 281, 352, 281, 5794, 2564, 9362, 746, 411], "temperature": 0.0, "avg_logprob": -0.2100528391396127, "compression_ratio": 1.3968253968253967, "no_speech_prob": 4.981978781870566e-05}, {"id": 100, "seek": 64324, "start": 656.84, "end": 666.04, "text": " this we ideally would find some kind of hashtag know that okay let's just use maybe this as", "tokens": [341, 321, 22915, 576, 915, 512, 733, 295, 20379, 458, 300, 1392, 718, 311, 445, 764, 1310, 341, 382], "temperature": 0.0, "avg_logprob": -0.2100528391396127, "compression_ratio": 1.3968253968253967, "no_speech_prob": 4.981978781870566e-05}, {"id": 101, "seek": 66604, "start": 666.04, "end": 677.56, "text": " a search query no okay now it's collecting in the background", "tokens": [257, 3164, 14581, 572, 1392, 586, 309, 311, 12510, 294, 264, 3678], "temperature": 0.0, "avg_logprob": -0.16930484771728516, "compression_ratio": 1.3392857142857142, "no_speech_prob": 2.62624780589249e-05}, {"id": 102, "seek": 66604, "start": 677.56, "end": 691.3199999999999, "text": " then we can open another browser window here fire up the visualizer now we see that while", "tokens": [550, 321, 393, 1269, 1071, 11185, 4910, 510, 2610, 493, 264, 5056, 6545, 586, 321, 536, 300, 1339], "temperature": 0.0, "avg_logprob": -0.16930484771728516, "compression_ratio": 1.3392857142857142, "no_speech_prob": 2.62624780589249e-05}, {"id": 103, "seek": 69132, "start": 691.32, "end": 697.0, "text": " this is still collecting we can already access oh there were only 400 tweets so there seems", "tokens": [341, 307, 920, 12510, 321, 393, 1217, 2105, 1954, 456, 645, 787, 8423, 25671, 370, 456, 2544], "temperature": 0.0, "avg_logprob": -0.14317403955662505, "compression_ratio": 1.5078125, "no_speech_prob": 1.3416019100986887e-05}, {"id": 104, "seek": 69132, "start": 697.0, "end": 708.32, "text": " to be so we can", "tokens": [281, 312, 370, 321, 393], "temperature": 0.0, "avg_logprob": -0.14317403955662505, "compression_ratio": 1.5078125, "no_speech_prob": 1.3416019100986887e-05}, {"id": 105, "seek": 69132, "start": 708.32, "end": 715.32, "text": " look at a time series of tweets and then we can choose different types of networks to", "tokens": [574, 412, 257, 565, 2638, 295, 25671, 293, 550, 321, 393, 2826, 819, 3467, 295, 9590, 281], "temperature": 0.0, "avg_logprob": -0.14317403955662505, "compression_ratio": 1.5078125, "no_speech_prob": 1.3416019100986887e-05}, {"id": 106, "seek": 71532, "start": 715.32, "end": 721.6800000000001, "text": " create we can filter them by language if we want and this is the language of the Twitter", "tokens": [1884, 321, 393, 6608, 552, 538, 2856, 498, 321, 528, 293, 341, 307, 264, 2856, 295, 264, 5794], "temperature": 0.0, "avg_logprob": -0.12131111531317988, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.00012509830412454903}, {"id": 107, "seek": 71532, "start": 721.6800000000001, "end": 730.5600000000001, "text": " API returns so it's not there's no language detection going on here we can do some network", "tokens": [9362, 11247, 370, 309, 311, 406, 456, 311, 572, 2856, 17784, 516, 322, 510, 321, 393, 360, 512, 3209], "temperature": 0.0, "avg_logprob": -0.12131111531317988, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.00012509830412454903}, {"id": 108, "seek": 71532, "start": 730.5600000000001, "end": 737.12, "text": " reduction methods like taking only the largest connected component of the graph then we have", "tokens": [11004, 7150, 411, 1940, 787, 264, 6443, 4582, 6542, 295, 264, 4295, 550, 321, 362], "temperature": 0.0, "avg_logprob": -0.12131111531317988, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.00012509830412454903}, {"id": 109, "seek": 71532, "start": 737.12, "end": 743.48, "text": " this option here to remove the metadata of nodes that are not what we call public figures", "tokens": [341, 3614, 510, 281, 4159, 264, 26603, 295, 13891, 300, 366, 406, 437, 321, 818, 1908, 9624], "temperature": 0.0, "avg_logprob": -0.12131111531317988, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.00012509830412454903}, {"id": 110, "seek": 74348, "start": 743.48, "end": 751.0, "text": " so if you want to publish some explorable networks it is advisable to do so there is", "tokens": [370, 498, 291, 528, 281, 11374, 512, 1490, 15249, 9590, 309, 307, 10280, 712, 281, 360, 370, 456, 307], "temperature": 0.0, "avg_logprob": -0.1271416384999345, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.0004272846272215247}, {"id": 111, "seek": 74348, "start": 751.0, "end": 758.36, "text": " not as far as I know not a very distinctive or clear rule after which point one is considered", "tokens": [406, 382, 1400, 382, 286, 458, 406, 257, 588, 27766, 420, 1850, 4978, 934, 597, 935, 472, 307, 4888], "temperature": 0.0, "avg_logprob": -0.1271416384999345, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.0004272846272215247}, {"id": 112, "seek": 74348, "start": 758.36, "end": 764.08, "text": " such a public figure but within our consortium we decided that it's 5000 followers this is", "tokens": [1270, 257, 1908, 2573, 457, 1951, 527, 38343, 2197, 321, 3047, 300, 309, 311, 23777, 13071, 341, 307], "temperature": 0.0, "avg_logprob": -0.1271416384999345, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.0004272846272215247}, {"id": 113, "seek": 74348, "start": 764.08, "end": 771.12, "text": " also something we could discuss but since Twitter is public by default in a way anything", "tokens": [611, 746, 321, 727, 2248, 457, 1670, 5794, 307, 1908, 538, 7576, 294, 257, 636, 1340], "temperature": 0.0, "avg_logprob": -0.1271416384999345, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.0004272846272215247}, {"id": 114, "seek": 77112, "start": 771.12, "end": 778.48, "text": " you post is somehow post potentially to be used in displays somewhere then you can export", "tokens": [291, 2183, 307, 6063, 2183, 7263, 281, 312, 1143, 294, 20119, 4079, 550, 291, 393, 10725], "temperature": 0.0, "avg_logprob": -0.10790900715061875, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.0002635197597555816}, {"id": 115, "seek": 77112, "start": 778.48, "end": 786.92, "text": " the graph to all sorts of formats then you can aggregate nodes this means that for instance", "tokens": [264, 4295, 281, 439, 7527, 295, 25879, 550, 291, 393, 26118, 13891, 341, 1355, 300, 337, 5197], "temperature": 0.0, "avg_logprob": -0.10790900715061875, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.0002635197597555816}, {"id": 116, "seek": 77112, "start": 786.92, "end": 792.76, "text": " removing them based on how many retweets they have or how many retweets they did themselves", "tokens": [12720, 552, 2361, 322, 577, 867, 1533, 826, 1385, 436, 362, 420, 577, 867, 1533, 826, 1385, 436, 630, 2969], "temperature": 0.0, "avg_logprob": -0.10790900715061875, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.0002635197597555816}, {"id": 117, "seek": 79276, "start": 792.76, "end": 806.16, "text": " and remove for instance nodes that only retweeted one person so is there a chalk maybe somewhere", "tokens": [293, 4159, 337, 5197, 13891, 300, 787, 1533, 10354, 292, 472, 954, 370, 307, 456, 257, 28660, 1310, 4079], "temperature": 0.0, "avg_logprob": -0.1836168332533403, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.00010716027463786304}, {"id": 118, "seek": 79276, "start": 806.16, "end": 820.3199999999999, "text": " so if you have a graph and then there are some nodes that only retweet this person they", "tokens": [370, 498, 291, 362, 257, 4295, 293, 550, 456, 366, 512, 13891, 300, 787, 1533, 10354, 341, 954, 436], "temperature": 0.0, "avg_logprob": -0.1836168332533403, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.00010716027463786304}, {"id": 119, "seek": 82032, "start": 820.32, "end": 825.6, "text": " I don't know if everyone can see that actually but they tend to clutter the force directed", "tokens": [286, 500, 380, 458, 498, 1518, 393, 536, 300, 767, 457, 436, 3928, 281, 40614, 264, 3464, 12898], "temperature": 0.0, "avg_logprob": -0.15247749955686804, "compression_ratio": 1.6153846153846154, "no_speech_prob": 5.6428609241265804e-05}, {"id": 120, "seek": 82032, "start": 825.6, "end": 830.96, "text": " algorithm and structurally they do not necessarily add anything to the network so if you have", "tokens": [9284, 293, 6594, 6512, 436, 360, 406, 4725, 909, 1340, 281, 264, 3209, 370, 498, 291, 362], "temperature": 0.0, "avg_logprob": -0.15247749955686804, "compression_ratio": 1.6153846153846154, "no_speech_prob": 5.6428609241265804e-05}, {"id": 121, "seek": 82032, "start": 830.96, "end": 836.2800000000001, "text": " very very large graphs it makes sense to remove these and somehow englobe them into this super", "tokens": [588, 588, 2416, 24877, 309, 1669, 2020, 281, 4159, 613, 293, 6063, 1741, 752, 650, 552, 666, 341, 1687], "temperature": 0.0, "avg_logprob": -0.15247749955686804, "compression_ratio": 1.6153846153846154, "no_speech_prob": 5.6428609241265804e-05}, {"id": 122, "seek": 82032, "start": 836.2800000000001, "end": 847.7600000000001, "text": " node and then you can do traditional community detection", "tokens": [9984, 293, 550, 291, 393, 360, 5164, 1768, 17784], "temperature": 0.0, "avg_logprob": -0.15247749955686804, "compression_ratio": 1.6153846153846154, "no_speech_prob": 5.6428609241265804e-05}, {"id": 123, "seek": 84776, "start": 847.76, "end": 863.64, "text": " and then it will be saved as a HTML but you can then open so we see here that this is", "tokens": [293, 550, 309, 486, 312, 6624, 382, 257, 17995, 457, 291, 393, 550, 1269, 370, 321, 536, 510, 300, 341, 307], "temperature": 0.0, "avg_logprob": -0.1871047846476237, "compression_ratio": 1.5535714285714286, "no_speech_prob": 5.645049168379046e-05}, {"id": 124, "seek": 84776, "start": 863.64, "end": 868.6, "text": " again now in a retweet network every node is a user and the link is drawn from A to", "tokens": [797, 586, 294, 257, 1533, 10354, 3209, 633, 9984, 307, 257, 4195, 293, 264, 2113, 307, 10117, 490, 316, 281], "temperature": 0.0, "avg_logprob": -0.1871047846476237, "compression_ratio": 1.5535714285714286, "no_speech_prob": 5.645049168379046e-05}, {"id": 125, "seek": 84776, "start": 868.6, "end": 877.24, "text": " B if A retweets B and now we can look at this user t-chambers and look at the actual tweets", "tokens": [363, 498, 316, 1533, 826, 1385, 363, 293, 586, 321, 393, 574, 412, 341, 4195, 256, 12, 339, 335, 1616, 293, 574, 412, 264, 3539, 25671], "temperature": 0.0, "avg_logprob": -0.1871047846476237, "compression_ratio": 1.5535714285714286, "no_speech_prob": 5.645049168379046e-05}, {"id": 126, "seek": 87724, "start": 877.24, "end": 892.64, "text": " that were made for them to end up at this part of the visualization okay so the data", "tokens": [300, 645, 1027, 337, 552, 281, 917, 493, 412, 341, 644, 295, 264, 25801, 1392, 370, 264, 1412], "temperature": 0.0, "avg_logprob": -0.14720691636551259, "compression_ratio": 1.4031007751937985, "no_speech_prob": 5.196434722165577e-05}, {"id": 127, "seek": 87724, "start": 892.64, "end": 898.96, "text": " we collect this kind of sparse so this network doesn't look that interesting but I have prepared", "tokens": [321, 2500, 341, 733, 295, 637, 11668, 370, 341, 3209, 1177, 380, 574, 300, 1880, 457, 286, 362, 4927], "temperature": 0.0, "avg_logprob": -0.14720691636551259, "compression_ratio": 1.4031007751937985, "no_speech_prob": 5.196434722165577e-05}, {"id": 128, "seek": 89896, "start": 898.96, "end": 911.12, "text": " some fallback option so what we did in a case study a few months ago was to look at the", "tokens": [512, 2100, 3207, 3614, 370, 437, 321, 630, 294, 257, 1389, 2979, 257, 1326, 2493, 2057, 390, 281, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.10116153378640452, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.00010689397458918393}, {"id": 129, "seek": 89896, "start": 911.12, "end": 918.52, "text": " repercussion of some discussions in the US about red flag laws and red flag laws are", "tokens": [28946, 25049, 295, 512, 11088, 294, 264, 2546, 466, 2182, 7166, 6064, 293, 2182, 7166, 6064, 366], "temperature": 0.0, "avg_logprob": -0.10116153378640452, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.00010689397458918393}, {"id": 130, "seek": 89896, "start": 918.52, "end": 927.6, "text": " specific kinds of laws for gun control that allow state level judges to confiscate temporarily", "tokens": [2685, 3685, 295, 6064, 337, 3874, 1969, 300, 2089, 1785, 1496, 14449, 281, 49868, 473, 23750], "temperature": 0.0, "avg_logprob": -0.10116153378640452, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.00010689397458918393}, {"id": 131, "seek": 92760, "start": 927.6, "end": 935.2, "text": " guns from people that are deemed to be a threat to themselves or to the public and these laws", "tokens": [10153, 490, 561, 300, 366, 27637, 281, 312, 257, 4734, 281, 2969, 420, 281, 264, 1908, 293, 613, 6064], "temperature": 0.0, "avg_logprob": -0.11693332069798519, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.00020267057698220015}, {"id": 132, "seek": 92760, "start": 935.2, "end": 940.64, "text": " created very big repercussions especially on social media and especially in the conservative", "tokens": [2942, 588, 955, 28946, 38899, 2318, 322, 2093, 3021, 293, 2318, 294, 264, 13780], "temperature": 0.0, "avg_logprob": -0.11693332069798519, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.00020267057698220015}, {"id": 133, "seek": 92760, "start": 940.64, "end": 947.8000000000001, "text": " camps and this is one typical example where people then can analyze on Twitter if there", "tokens": [16573, 293, 341, 307, 472, 7476, 1365, 689, 561, 550, 393, 12477, 322, 5794, 498, 456], "temperature": 0.0, "avg_logprob": -0.11693332069798519, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.00020267057698220015}, {"id": 134, "seek": 92760, "start": 947.8000000000001, "end": 952.36, "text": " is something like echo chambers or if people then maybe retweet each other only from the", "tokens": [307, 746, 411, 14300, 34513, 420, 498, 561, 550, 1310, 1533, 10354, 1184, 661, 787, 490, 264], "temperature": 0.0, "avg_logprob": -0.11693332069798519, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.00020267057698220015}, {"id": 135, "seek": 95236, "start": 952.36, "end": 958.32, "text": " similar camps and then people draw very quick conclusions very fast and what we want to", "tokens": [2531, 16573, 293, 550, 561, 2642, 588, 1702, 22865, 588, 2370, 293, 437, 321, 528, 281], "temperature": 0.0, "avg_logprob": -0.11555660338628859, "compression_ratio": 1.416, "no_speech_prob": 0.00015571115363854915}, {"id": 136, "seek": 95236, "start": 958.32, "end": 965.12, "text": " do with this tool is to show that maybe things are not that simple as they seem so I have", "tokens": [360, 365, 341, 2290, 307, 281, 855, 300, 1310, 721, 366, 406, 300, 2199, 382, 436, 1643, 370, 286, 362], "temperature": 0.0, "avg_logprob": -0.11555660338628859, "compression_ratio": 1.416, "no_speech_prob": 0.00015571115363854915}, {"id": 137, "seek": 96512, "start": 965.12, "end": 983.04, "text": " prepared these networks but I think I will make it a bit smaller so this is now a bit", "tokens": [4927, 613, 9590, 457, 286, 519, 286, 486, 652, 309, 257, 857, 4356, 370, 341, 307, 586, 257, 857], "temperature": 0.0, "avg_logprob": -0.09843699828438136, "compression_ratio": 1.3488372093023255, "no_speech_prob": 9.592105925548822e-05}, {"id": 138, "seek": 96512, "start": 983.04, "end": 994.12, "text": " bigger than what we had before we have roughly 25,000 nodes and 90,000 links and this is", "tokens": [3801, 813, 437, 321, 632, 949, 321, 362, 9810, 3552, 11, 1360, 13891, 293, 4289, 11, 1360, 6123, 293, 341, 307], "temperature": 0.0, "avg_logprob": -0.09843699828438136, "compression_ratio": 1.3488372093023255, "no_speech_prob": 9.592105925548822e-05}, {"id": 139, "seek": 99412, "start": 994.12, "end": 997.64, "text": " already one limitation of the tool that I think I would also like to discuss in the", "tokens": [1217, 472, 27432, 295, 264, 2290, 300, 286, 519, 286, 576, 611, 411, 281, 2248, 294, 264], "temperature": 0.0, "avg_logprob": -0.15746575091258588, "compression_ratio": 1.5688073394495412, "no_speech_prob": 0.0002806192496791482}, {"id": 140, "seek": 99412, "start": 997.64, "end": 1003.32, "text": " end is that you can't display mentally huge graphs so 100,000 links approximately is", "tokens": [917, 307, 300, 291, 393, 380, 4674, 17072, 2603, 24877, 370, 2319, 11, 1360, 6123, 10447, 307], "temperature": 0.0, "avg_logprob": -0.15746575091258588, "compression_ratio": 1.5688073394495412, "no_speech_prob": 0.0002806192496791482}, {"id": 141, "seek": 99412, "start": 1003.32, "end": 1008.2, "text": " kind of the limit and I think this is also where integrating it with other tools such", "tokens": [733, 295, 264, 4948, 293, 286, 519, 341, 307, 611, 689, 26889, 309, 365, 661, 3873, 1270], "temperature": 0.0, "avg_logprob": -0.15746575091258588, "compression_ratio": 1.5688073394495412, "no_speech_prob": 0.0002806192496791482}, {"id": 142, "seek": 99412, "start": 1008.2, "end": 1016.72, "text": " as Sigma or Gaffrey might actually make a lot of sense and so now I can call it a nodes", "tokens": [382, 36595, 420, 460, 2518, 7950, 1062, 767, 652, 257, 688, 295, 2020, 293, 370, 586, 286, 393, 818, 309, 257, 13891], "temperature": 0.0, "avg_logprob": -0.15746575091258588, "compression_ratio": 1.5688073394495412, "no_speech_prob": 0.0002806192496791482}, {"id": 143, "seek": 101672, "start": 1016.72, "end": 1026.72, "text": " by the Louvain community we can turn off the light also and now we can wonder what are", "tokens": [538, 264, 7272, 85, 491, 1768, 321, 393, 1261, 766, 264, 1442, 611, 293, 586, 321, 393, 2441, 437, 366], "temperature": 0.0, "avg_logprob": -0.15952039865347056, "compression_ratio": 1.5903614457831325, "no_speech_prob": 7.576842472190037e-05}, {"id": 144, "seek": 101672, "start": 1026.72, "end": 1033.96, "text": " these two communities and right now the node size is proportional to the in-degree meaning", "tokens": [613, 732, 4456, 293, 558, 586, 264, 9984, 2744, 307, 24969, 281, 264, 294, 12, 34368, 3620], "temperature": 0.0, "avg_logprob": -0.15952039865347056, "compression_ratio": 1.5903614457831325, "no_speech_prob": 7.576842472190037e-05}, {"id": 145, "seek": 101672, "start": 1033.96, "end": 1040.92, "text": " how often a given node was retweeted but if we want to so these may then be considered", "tokens": [577, 2049, 257, 2212, 9984, 390, 1533, 10354, 292, 457, 498, 321, 528, 281, 370, 613, 815, 550, 312, 4888], "temperature": 0.0, "avg_logprob": -0.15952039865347056, "compression_ratio": 1.5903614457831325, "no_speech_prob": 7.576842472190037e-05}, {"id": 146, "seek": 104092, "start": 1040.92, "end": 1047.0, "text": " as something like the opinion leaders of the given camps and so if we go here we see for", "tokens": [382, 746, 411, 264, 4800, 3523, 295, 264, 2212, 16573, 293, 370, 498, 321, 352, 510, 321, 536, 337], "temperature": 0.0, "avg_logprob": -0.10565147843471794, "compression_ratio": 1.6325581395348838, "no_speech_prob": 6.291684985626489e-05}, {"id": 147, "seek": 104092, "start": 1047.0, "end": 1053.72, "text": " instance on this side Donald Trump Jr. and we can then look exactly at the tweets that", "tokens": [5197, 322, 341, 1252, 8632, 3899, 17261, 13, 293, 321, 393, 550, 574, 2293, 412, 264, 25671, 300], "temperature": 0.0, "avg_logprob": -0.10565147843471794, "compression_ratio": 1.6325581395348838, "no_speech_prob": 6.291684985626489e-05}, {"id": 148, "seek": 104092, "start": 1053.72, "end": 1061.76, "text": " led the visualization to put him where where he was so okay we don't need to go into the", "tokens": [4684, 264, 25801, 281, 829, 796, 689, 689, 415, 390, 370, 1392, 321, 500, 380, 643, 281, 352, 666, 264], "temperature": 0.0, "avg_logprob": -0.10565147843471794, "compression_ratio": 1.6325581395348838, "no_speech_prob": 6.291684985626489e-05}, {"id": 149, "seek": 104092, "start": 1061.76, "end": 1069.04, "text": " details of what he said but you see you see the point we can also change the node size", "tokens": [4365, 295, 437, 415, 848, 457, 291, 536, 291, 536, 264, 935, 321, 393, 611, 1319, 264, 9984, 2744], "temperature": 0.0, "avg_logprob": -0.10565147843471794, "compression_ratio": 1.6325581395348838, "no_speech_prob": 6.291684985626489e-05}, {"id": 150, "seek": 106904, "start": 1069.04, "end": 1074.32, "text": " to the number of followers and then we get an immediate view at who the who the main", "tokens": [281, 264, 1230, 295, 13071, 293, 550, 321, 483, 364, 11629, 1910, 412, 567, 264, 567, 264, 2135], "temperature": 0.0, "avg_logprob": -0.09896542179969049, "compression_ratio": 1.5497076023391814, "no_speech_prob": 7.345448830164969e-05}, {"id": 151, "seek": 106904, "start": 1074.32, "end": 1085.56, "text": " actors are that in general are also influential on Twitter so we have the New York Times here", "tokens": [10037, 366, 300, 294, 2674, 366, 611, 22215, 322, 5794, 370, 321, 362, 264, 1873, 3609, 11366, 510], "temperature": 0.0, "avg_logprob": -0.09896542179969049, "compression_ratio": 1.5497076023391814, "no_speech_prob": 7.345448830164969e-05}, {"id": 152, "seek": 106904, "start": 1085.56, "end": 1094.84, "text": " and Wall Street Journal so so we can see that we have something like of a more liberal", "tokens": [293, 9551, 7638, 16936, 370, 370, 321, 393, 536, 300, 321, 362, 746, 411, 295, 257, 544, 13767], "temperature": 0.0, "avg_logprob": -0.09896542179969049, "compression_ratio": 1.5497076023391814, "no_speech_prob": 7.345448830164969e-05}, {"id": 153, "seek": 109484, "start": 1094.84, "end": 1100.52, "text": " versus a more conservative camp but if we look only at the retweet behavior we might think", "tokens": [5717, 257, 544, 13780, 2255, 457, 498, 321, 574, 787, 412, 264, 1533, 10354, 5223, 321, 1062, 519], "temperature": 0.0, "avg_logprob": -0.08666546571822394, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.008508353261277e-05}, {"id": 154, "seek": 109484, "start": 1100.52, "end": 1106.32, "text": " that okay these are separated echo chambers and people do not talk to each other but what", "tokens": [300, 1392, 613, 366, 12005, 14300, 34513, 293, 561, 360, 406, 751, 281, 1184, 661, 457, 437], "temperature": 0.0, "avg_logprob": -0.08666546571822394, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.008508353261277e-05}, {"id": 155, "seek": 109484, "start": 1106.32, "end": 1111.48, "text": " is interesting is if we look at other types of networks in these example so we can look", "tokens": [307, 1880, 307, 498, 321, 574, 412, 661, 3467, 295, 9590, 294, 613, 1365, 370, 321, 393, 574], "temperature": 0.0, "avg_logprob": -0.08666546571822394, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.008508353261277e-05}, {"id": 156, "seek": 109484, "start": 1111.48, "end": 1119.3999999999999, "text": " at the replies I think I will make it a bit smaller and all of the sudden we don't see", "tokens": [412, 264, 42289, 286, 519, 286, 486, 652, 309, 257, 857, 4356, 293, 439, 295, 264, 3990, 321, 500, 380, 536], "temperature": 0.0, "avg_logprob": -0.08666546571822394, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.008508353261277e-05}, {"id": 157, "seek": 111940, "start": 1119.4, "end": 1126.48, "text": " this very strong segregated clustering anymore that we saw here maybe it's easier if I put", "tokens": [341, 588, 2068, 47370, 596, 48673, 3602, 300, 321, 1866, 510, 1310, 309, 311, 3571, 498, 286, 829], "temperature": 0.0, "avg_logprob": -0.13342716580345518, "compression_ratio": 1.467032967032967, "no_speech_prob": 6.005646719131619e-05}, {"id": 158, "seek": 111940, "start": 1126.48, "end": 1142.64, "text": " it in but we see something more of a hairball layout and when we look at the nodes we see", "tokens": [309, 294, 457, 321, 536, 746, 544, 295, 257, 2578, 3129, 13333, 293, 562, 321, 574, 412, 264, 13891, 321, 536], "temperature": 0.0, "avg_logprob": -0.13342716580345518, "compression_ratio": 1.467032967032967, "no_speech_prob": 6.005646719131619e-05}, {"id": 159, "seek": 111940, "start": 1142.64, "end": 1148.0800000000002, "text": " that indeed the path of going for instance from Donald Trump to Hillary Clinton or New", "tokens": [300, 6451, 264, 3100, 295, 516, 337, 5197, 490, 8632, 3899, 281, 23284, 15445, 420, 1873], "temperature": 0.0, "avg_logprob": -0.13342716580345518, "compression_ratio": 1.467032967032967, "no_speech_prob": 6.005646719131619e-05}, {"id": 160, "seek": 114808, "start": 1148.08, "end": 1151.76, "text": " York Times of those people that were very far apart in the retweet network is maybe", "tokens": [3609, 11366, 295, 729, 561, 300, 645, 588, 1400, 4936, 294, 264, 1533, 10354, 3209, 307, 1310], "temperature": 0.0, "avg_logprob": -0.1023478845153192, "compression_ratio": 1.946188340807175, "no_speech_prob": 0.00025668341550044715}, {"id": 161, "seek": 114808, "start": 1151.76, "end": 1156.1999999999998, "text": " not that not that long in the reply network meaning that these opposing camps actually", "tokens": [406, 300, 406, 300, 938, 294, 264, 16972, 3209, 3620, 300, 613, 27890, 16573, 767], "temperature": 0.0, "avg_logprob": -0.1023478845153192, "compression_ratio": 1.946188340807175, "no_speech_prob": 0.00025668341550044715}, {"id": 162, "seek": 114808, "start": 1156.1999999999998, "end": 1160.24, "text": " maybe do talk to each other and it might be more interesting to see how they talk to each", "tokens": [1310, 360, 751, 281, 1184, 661, 293, 309, 1062, 312, 544, 1880, 281, 536, 577, 436, 751, 281, 1184], "temperature": 0.0, "avg_logprob": -0.1023478845153192, "compression_ratio": 1.946188340807175, "no_speech_prob": 0.00025668341550044715}, {"id": 163, "seek": 114808, "start": 1160.24, "end": 1165.1999999999998, "text": " other and what they say and this is something that is that you can do when you when you", "tokens": [661, 293, 437, 436, 584, 293, 341, 307, 746, 300, 307, 300, 291, 393, 360, 562, 291, 562, 291], "temperature": 0.0, "avg_logprob": -0.1023478845153192, "compression_ratio": 1.946188340807175, "no_speech_prob": 0.00025668341550044715}, {"id": 164, "seek": 114808, "start": 1165.1999999999998, "end": 1172.72, "text": " use this interface and look at the tweets and that the actual replies so so it allows", "tokens": [764, 341, 9226, 293, 574, 412, 264, 25671, 293, 300, 264, 3539, 42289, 370, 370, 309, 4045], "temperature": 0.0, "avg_logprob": -0.1023478845153192, "compression_ratio": 1.946188340807175, "no_speech_prob": 0.00025668341550044715}, {"id": 165, "seek": 117272, "start": 1172.72, "end": 1179.6000000000001, "text": " you to then actually go to the parts of the platform that that generate this data and", "tokens": [291, 281, 550, 767, 352, 281, 264, 3166, 295, 264, 3663, 300, 300, 8460, 341, 1412, 293], "temperature": 0.0, "avg_logprob": -0.10222147013011731, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.00010209457104792818}, {"id": 166, "seek": 117272, "start": 1179.6000000000001, "end": 1190.08, "text": " that then generate these networks and finally as a small example of the semantic networks", "tokens": [300, 550, 8460, 613, 9590, 293, 2721, 382, 257, 1359, 1365, 295, 264, 47982, 9590], "temperature": 0.0, "avg_logprob": -0.10222147013011731, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.00010209457104792818}, {"id": 167, "seek": 119008, "start": 1190.08, "end": 1204.72, "text": " we can look at the hashtags that are used again and you see that for instance there", "tokens": [321, 393, 574, 412, 264, 50016, 300, 366, 1143, 797, 293, 291, 536, 300, 337, 5197, 456], "temperature": 0.0, "avg_logprob": -0.12310813213216848, "compression_ratio": 1.64375, "no_speech_prob": 2.6618656193022616e-05}, {"id": 168, "seek": 119008, "start": 1204.72, "end": 1211.0, "text": " is one kind of hateful conservative hashtag cluster which which and again okay maybe I", "tokens": [307, 472, 733, 295, 4700, 906, 13780, 20379, 13630, 597, 597, 293, 797, 1392, 1310, 286], "temperature": 0.0, "avg_logprob": -0.12310813213216848, "compression_ratio": 1.64375, "no_speech_prob": 2.6618656193022616e-05}, {"id": 169, "seek": 119008, "start": 1211.0, "end": 1216.12, "text": " should have said that in the hashtag networks every node is a hashtag and they are connected", "tokens": [820, 362, 848, 300, 294, 264, 20379, 9590, 633, 9984, 307, 257, 20379, 293, 436, 366, 4582], "temperature": 0.0, "avg_logprob": -0.12310813213216848, "compression_ratio": 1.64375, "no_speech_prob": 2.6618656193022616e-05}, {"id": 170, "seek": 121612, "start": 1216.12, "end": 1223.8, "text": " if they appear together in the same tweet so this is a very very low level way of seeing", "tokens": [498, 436, 4204, 1214, 294, 264, 912, 15258, 370, 341, 307, 257, 588, 588, 2295, 1496, 636, 295, 2577], "temperature": 0.0, "avg_logprob": -0.100764061422909, "compression_ratio": 1.6775700934579438, "no_speech_prob": 3.644344542408362e-05}, {"id": 171, "seek": 121612, "start": 1223.8, "end": 1227.1999999999998, "text": " what is going on in the data in a way you don't need to do some kind of topic modeling", "tokens": [437, 307, 516, 322, 294, 264, 1412, 294, 257, 636, 291, 500, 380, 643, 281, 360, 512, 733, 295, 4829, 15983], "temperature": 0.0, "avg_logprob": -0.100764061422909, "compression_ratio": 1.6775700934579438, "no_speech_prob": 3.644344542408362e-05}, {"id": 172, "seek": 121612, "start": 1227.1999999999998, "end": 1232.1999999999998, "text": " and or complicated techniques you can literally just by looking at the hashtags already get", "tokens": [293, 420, 6179, 7512, 291, 393, 3736, 445, 538, 1237, 412, 264, 50016, 1217, 483], "temperature": 0.0, "avg_logprob": -0.100764061422909, "compression_ratio": 1.6775700934579438, "no_speech_prob": 3.644344542408362e-05}, {"id": 173, "seek": 121612, "start": 1232.1999999999998, "end": 1239.8, "text": " a hint at how the different camps speak about the same topic so if you go here in this area", "tokens": [257, 12075, 412, 577, 264, 819, 16573, 1710, 466, 264, 912, 4829, 370, 498, 291, 352, 510, 294, 341, 1859], "temperature": 0.0, "avg_logprob": -0.100764061422909, "compression_ratio": 1.6775700934579438, "no_speech_prob": 3.644344542408362e-05}, {"id": 174, "seek": 123980, "start": 1239.8, "end": 1248.6, "text": " this is about gun confiscation laws so Marxism in this case is also good good example right", "tokens": [341, 307, 466, 3874, 49868, 399, 6064, 370, 21703, 1434, 294, 341, 1389, 307, 611, 665, 665, 1365, 558], "temperature": 0.0, "avg_logprob": -0.15030800212513318, "compression_ratio": 1.612121212121212, "no_speech_prob": 0.00010201380791841075}, {"id": 175, "seek": 123980, "start": 1248.6, "end": 1253.9199999999998, "text": " now we don't really know how it is used right and it can be used either by conservatives", "tokens": [586, 321, 500, 380, 534, 458, 577, 309, 307, 1143, 558, 293, 309, 393, 312, 1143, 2139, 538, 39607], "temperature": 0.0, "avg_logprob": -0.15030800212513318, "compression_ratio": 1.612121212121212, "no_speech_prob": 0.00010201380791841075}, {"id": 176, "seek": 123980, "start": 1253.9199999999998, "end": 1259.6399999999999, "text": " or by liberals and and and it's important to look at it in the context of of the data", "tokens": [420, 538, 48617, 293, 293, 293, 309, 311, 1021, 281, 574, 412, 309, 294, 264, 4319, 295, 295, 264, 1412], "temperature": 0.0, "avg_logprob": -0.15030800212513318, "compression_ratio": 1.612121212121212, "no_speech_prob": 0.00010201380791841075}, {"id": 177, "seek": 125964, "start": 1259.64, "end": 1274.5200000000002, "text": " so then we would have to okay five minutes left good I will go back to the slides okay", "tokens": [370, 550, 321, 576, 362, 281, 1392, 1732, 2077, 1411, 665, 286, 486, 352, 646, 281, 264, 9788, 1392], "temperature": 0.0, "avg_logprob": -0.13148311376571656, "compression_ratio": 1.4369747899159664, "no_speech_prob": 5.13679078721907e-05}, {"id": 178, "seek": 125964, "start": 1274.5200000000002, "end": 1281.68, "text": " so under the hood this this whole backend of the collector individualizer is written", "tokens": [370, 833, 264, 13376, 341, 341, 1379, 38087, 295, 264, 23960, 2609, 6545, 307, 3720], "temperature": 0.0, "avg_logprob": -0.13148311376571656, "compression_ratio": 1.4369747899159664, "no_speech_prob": 5.13679078721907e-05}, {"id": 179, "seek": 128168, "start": 1281.68, "end": 1292.04, "text": " in python and it's using the streamlit python library to serve it on a local front end so", "tokens": [294, 38797, 293, 309, 311, 1228, 264, 4309, 23062, 38797, 6405, 281, 4596, 309, 322, 257, 2654, 1868, 917, 370], "temperature": 0.0, "avg_logprob": -0.13117960960634292, "compression_ratio": 1.6, "no_speech_prob": 6.810429476900026e-05}, {"id": 180, "seek": 128168, "start": 1292.04, "end": 1297.1200000000001, "text": " this is actually a very convenient library and I guess a lot of people also know it but", "tokens": [341, 307, 767, 257, 588, 10851, 6405, 293, 286, 2041, 257, 688, 295, 561, 611, 458, 309, 457], "temperature": 0.0, "avg_logprob": -0.13117960960634292, "compression_ratio": 1.6, "no_speech_prob": 6.810429476900026e-05}, {"id": 181, "seek": 128168, "start": 1297.1200000000001, "end": 1301.88, "text": " you can write your code in python and then it essentially serves it in interfaces that", "tokens": [291, 393, 2464, 428, 3089, 294, 38797, 293, 550, 309, 4476, 13451, 309, 294, 28416, 300], "temperature": 0.0, "avg_logprob": -0.13117960960634292, "compression_ratio": 1.6, "no_speech_prob": 6.810429476900026e-05}, {"id": 182, "seek": 130188, "start": 1301.88, "end": 1314.5600000000002, "text": " look like this and the explorer is written in html and javascript and it uses d3 and", "tokens": [574, 411, 341, 293, 264, 39680, 307, 3720, 294, 276, 83, 15480, 293, 361, 37331, 5944, 293, 309, 4960, 274, 18, 293], "temperature": 0.0, "avg_logprob": -0.16662364219551656, "compression_ratio": 1.5798816568047338, "no_speech_prob": 7.951618317747489e-05}, {"id": 183, "seek": 130188, "start": 1314.5600000000002, "end": 1323.3200000000002, "text": " prints the graph on canvas which is also why it's probably not as as fast as sigma is but", "tokens": [22305, 264, 4295, 322, 16267, 597, 307, 611, 983, 309, 311, 1391, 406, 382, 382, 2370, 382, 12771, 307, 457], "temperature": 0.0, "avg_logprob": -0.16662364219551656, "compression_ratio": 1.5798816568047338, "no_speech_prob": 7.951618317747489e-05}, {"id": 184, "seek": 130188, "start": 1323.3200000000002, "end": 1328.92, "text": " it has some nice other features that are that are especially due to this force graph library", "tokens": [309, 575, 512, 1481, 661, 4122, 300, 366, 300, 366, 2318, 3462, 281, 341, 3464, 4295, 6405], "temperature": 0.0, "avg_logprob": -0.16662364219551656, "compression_ratio": 1.5798816568047338, "no_speech_prob": 7.951618317747489e-05}, {"id": 185, "seek": 132892, "start": 1328.92, "end": 1335.3600000000001, "text": " so I think if anyone has questions I'm going to go into the details in the questions and", "tokens": [370, 286, 519, 498, 2878, 575, 1651, 286, 478, 516, 281, 352, 666, 264, 4365, 294, 264, 1651, 293], "temperature": 0.0, "avg_logprob": -0.11821585688097723, "compression_ratio": 1.555084745762712, "no_speech_prob": 6.596583989448845e-05}, {"id": 186, "seek": 132892, "start": 1335.3600000000001, "end": 1342.64, "text": " so this is how we install it it's fairly simple if you have a running python bigger than 3.7", "tokens": [370, 341, 307, 577, 321, 3625, 309, 309, 311, 6457, 2199, 498, 291, 362, 257, 2614, 38797, 3801, 813, 805, 13, 22], "temperature": 0.0, "avg_logprob": -0.11821585688097723, "compression_ratio": 1.555084745762712, "no_speech_prob": 6.596583989448845e-05}, {"id": 187, "seek": 132892, "start": 1342.64, "end": 1347.28, "text": " and there's also an API so of course especially here probably people will not be so interested", "tokens": [293, 456, 311, 611, 364, 9362, 370, 295, 1164, 2318, 510, 1391, 561, 486, 406, 312, 370, 3102], "temperature": 0.0, "avg_logprob": -0.11821585688097723, "compression_ratio": 1.555084745762712, "no_speech_prob": 6.596583989448845e-05}, {"id": 188, "seek": 132892, "start": 1347.28, "end": 1352.6000000000001, "text": " in using the streamlit interface but you may want to include it into some kind of existing", "tokens": [294, 1228, 264, 4309, 23062, 9226, 457, 291, 815, 528, 281, 4090, 309, 666, 512, 733, 295, 6741], "temperature": 0.0, "avg_logprob": -0.11821585688097723, "compression_ratio": 1.555084745762712, "no_speech_prob": 6.596583989448845e-05}, {"id": 189, "seek": 135260, "start": 1352.6, "end": 1361.84, "text": " code pipeline that you have and this is essentially the API for semantic networks and interaction", "tokens": [3089, 15517, 300, 291, 362, 293, 341, 307, 4476, 264, 9362, 337, 47982, 9590, 293, 9285], "temperature": 0.0, "avg_logprob": -0.10552609517024114, "compression_ratio": 1.6179775280898876, "no_speech_prob": 1.8906273908214644e-05}, {"id": 190, "seek": 135260, "start": 1361.84, "end": 1373.6, "text": " networks so I invite you to try it out yourself while you still can you have five days of course", "tokens": [9590, 370, 286, 7980, 291, 281, 853, 309, 484, 1803, 1339, 291, 920, 393, 291, 362, 1732, 1708, 295, 1164], "temperature": 0.0, "avg_logprob": -0.10552609517024114, "compression_ratio": 1.6179775280898876, "no_speech_prob": 1.8906273908214644e-05}, {"id": 191, "seek": 135260, "start": 1373.6, "end": 1380.1999999999998, "text": " if you have the research API you might be able to use it for a bit longer but otherwise go on", "tokens": [498, 291, 362, 264, 2132, 9362, 291, 1062, 312, 1075, 281, 764, 309, 337, 257, 857, 2854, 457, 5911, 352, 322], "temperature": 0.0, "avg_logprob": -0.10552609517024114, "compression_ratio": 1.6179775280898876, "no_speech_prob": 1.8906273908214644e-05}, {"id": 192, "seek": 138020, "start": 1380.2, "end": 1387.72, "text": " these websites fast and I will stop the talk with some questions actually I came here with more", "tokens": [613, 12891, 2370, 293, 286, 486, 1590, 264, 751, 365, 512, 1651, 767, 286, 1361, 510, 365, 544], "temperature": 0.0, "avg_logprob": -0.11366709223333395, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.00012907423661090434}, {"id": 193, "seek": 138020, "start": 1387.72, "end": 1393.64, "text": " questions than answers and I'm really hoping for a lively discussion now because I'm not I'm not", "tokens": [1651, 813, 6338, 293, 286, 478, 534, 7159, 337, 257, 30866, 5017, 586, 570, 286, 478, 406, 286, 478, 406], "temperature": 0.0, "avg_logprob": -0.11366709223333395, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.00012907423661090434}, {"id": 194, "seek": 138020, "start": 1393.64, "end": 1398.96, "text": " originally a developer so I kind of wrote this a bit on my own and I wonder if this", "tokens": [7993, 257, 10754, 370, 286, 733, 295, 4114, 341, 257, 857, 322, 452, 1065, 293, 286, 2441, 498, 341], "temperature": 0.0, "avg_logprob": -0.11366709223333395, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.00012907423661090434}, {"id": 195, "seek": 138020, "start": 1398.96, "end": 1403.32, "text": " interact integration of python and javascript is actually a good idea because in theory it would", "tokens": [4648, 10980, 295, 38797, 293, 361, 37331, 5944, 307, 767, 257, 665, 1558, 570, 294, 5261, 309, 576], "temperature": 0.0, "avg_logprob": -0.11366709223333395, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.00012907423661090434}, {"id": 196, "seek": 138020, "start": 1403.32, "end": 1408.4, "text": " also be possible to probably do everything in javascript and maybe do it on the client side", "tokens": [611, 312, 1944, 281, 1391, 360, 1203, 294, 361, 37331, 5944, 293, 1310, 360, 309, 322, 264, 6423, 1252], "temperature": 0.0, "avg_logprob": -0.11366709223333395, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.00012907423661090434}, {"id": 197, "seek": 140840, "start": 1408.4, "end": 1413.64, "text": " so you wouldn't have to install all these libraries then okay maybe one thing that I would like to", "tokens": [370, 291, 2759, 380, 362, 281, 3625, 439, 613, 15148, 550, 1392, 1310, 472, 551, 300, 286, 576, 411, 281], "temperature": 0.0, "avg_logprob": -0.09477283214700633, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.00011206077033421025}, {"id": 198, "seek": 140840, "start": 1413.64, "end": 1420.0, "text": " show is that I experimented with temporal networks so of course doing temporal force", "tokens": [855, 307, 300, 286, 5120, 292, 365, 30881, 9590, 370, 295, 1164, 884, 30881, 3464], "temperature": 0.0, "avg_logprob": -0.09477283214700633, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.00011206077033421025}, {"id": 199, "seek": 140840, "start": 1420.0, "end": 1427.72, "text": " layouts is kind of a non-trivial task but we can kind of look a little bit at the temporality", "tokens": [46100, 307, 733, 295, 257, 2107, 12, 83, 470, 22640, 5633, 457, 321, 393, 733, 295, 574, 257, 707, 857, 412, 264, 8219, 1860], "temperature": 0.0, "avg_logprob": -0.09477283214700633, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.00011206077033421025}, {"id": 200, "seek": 140840, "start": 1427.72, "end": 1433.72, "text": " of these networks by at least displaying only the links that that are active during a given day", "tokens": [295, 613, 9590, 538, 412, 1935, 36834, 787, 264, 6123, 300, 300, 366, 4967, 1830, 257, 2212, 786], "temperature": 0.0, "avg_logprob": -0.09477283214700633, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.00011206077033421025}, {"id": 201, "seek": 143372, "start": 1433.72, "end": 1441.16, "text": " so this is also kind of nice I think but I would like to discuss maybe other visualization paradigms", "tokens": [370, 341, 307, 611, 733, 295, 1481, 286, 519, 457, 286, 576, 411, 281, 2248, 1310, 661, 25801, 13480, 328, 2592], "temperature": 0.0, "avg_logprob": -0.14549895220024642, "compression_ratio": 1.728888888888889, "no_speech_prob": 3.759789979085326e-05}, {"id": 202, "seek": 143372, "start": 1441.16, "end": 1447.16, "text": " for this kind of network then one thing that would be really interesting I think is to dig", "tokens": [337, 341, 733, 295, 3209, 550, 472, 551, 300, 576, 312, 534, 1880, 286, 519, 307, 281, 2528], "temperature": 0.0, "avg_logprob": -0.14549895220024642, "compression_ratio": 1.728888888888889, "no_speech_prob": 3.759789979085326e-05}, {"id": 203, "seek": 143372, "start": 1447.16, "end": 1453.28, "text": " deeper into a visualization paradigm for hierarchical structure of communities meaning that okay in", "tokens": [7731, 666, 257, 25801, 24709, 337, 35250, 804, 3877, 295, 4456, 3620, 300, 1392, 294], "temperature": 0.0, "avg_logprob": -0.14549895220024642, "compression_ratio": 1.728888888888889, "no_speech_prob": 3.759789979085326e-05}, {"id": 204, "seek": 143372, "start": 1453.28, "end": 1459.08, "text": " theory I can either run stochastic block models or Luvain community detections and stop them at a", "tokens": [5261, 286, 393, 2139, 1190, 342, 8997, 2750, 3461, 5245, 420, 5047, 85, 491, 1768, 5531, 626, 293, 1590, 552, 412, 257], "temperature": 0.0, "avg_logprob": -0.14549895220024642, "compression_ratio": 1.728888888888889, "no_speech_prob": 3.759789979085326e-05}, {"id": 205, "seek": 145908, "start": 1459.08, "end": 1463.8799999999999, "text": " certain level and then have some kind of hierarchical node structure but how to visualize that is", "tokens": [1629, 1496, 293, 550, 362, 512, 733, 295, 35250, 804, 9984, 3877, 457, 577, 281, 23273, 300, 307], "temperature": 0.0, "avg_logprob": -0.11562555911494236, "compression_ratio": 1.7878787878787878, "no_speech_prob": 3.117439700872637e-05}, {"id": 206, "seek": 145908, "start": 1463.8799999999999, "end": 1467.32, "text": " another question but I think it would be very interesting especially for very large graphs", "tokens": [1071, 1168, 457, 286, 519, 309, 576, 312, 588, 1880, 2318, 337, 588, 2416, 24877], "temperature": 0.0, "avg_logprob": -0.11562555911494236, "compression_ratio": 1.7878787878787878, "no_speech_prob": 3.117439700872637e-05}, {"id": 207, "seek": 145908, "start": 1467.32, "end": 1473.12, "text": " and then another question is force layouts should we still use them now that everyone is", "tokens": [293, 550, 1071, 1168, 307, 3464, 46100, 820, 321, 920, 764, 552, 586, 300, 1518, 307], "temperature": 0.0, "avg_logprob": -0.11562555911494236, "compression_ratio": 1.7878787878787878, "no_speech_prob": 3.117439700872637e-05}, {"id": 208, "seek": 145908, "start": 1473.12, "end": 1478.3999999999999, "text": " doing node2vec and all these other things I think yes but maybe there's good arguments against it", "tokens": [884, 9984, 17, 303, 66, 293, 439, 613, 661, 721, 286, 519, 2086, 457, 1310, 456, 311, 665, 12869, 1970, 309], "temperature": 0.0, "avg_logprob": -0.11562555911494236, "compression_ratio": 1.7878787878787878, "no_speech_prob": 3.117439700872637e-05}, {"id": 209, "seek": 145908, "start": 1478.3999999999999, "end": 1486.24, "text": " and on a more like deeper conceptual level is and this is a question the first one is a question", "tokens": [293, 322, 257, 544, 411, 7731, 24106, 1496, 307, 293, 341, 307, 257, 1168, 264, 700, 472, 307, 257, 1168], "temperature": 0.0, "avg_logprob": -0.11562555911494236, "compression_ratio": 1.7878787878787878, "no_speech_prob": 3.117439700872637e-05}, {"id": 210, "seek": 148624, "start": 1486.24, "end": 1490.04, "text": " for people who already have more much more experience in building tools for the social", "tokens": [337, 561, 567, 1217, 362, 544, 709, 544, 1752, 294, 2390, 3873, 337, 264, 2093], "temperature": 0.0, "avg_logprob": -0.09859554213706893, "compression_ratio": 1.793103448275862, "no_speech_prob": 4.9782895075622946e-05}, {"id": 211, "seek": 148624, "start": 1490.04, "end": 1496.8, "text": " sciences is how do you kind of further integrate these kinds of methods into existing maybe also", "tokens": [17677, 307, 577, 360, 291, 733, 295, 3052, 13365, 613, 3685, 295, 7150, 666, 6741, 1310, 611], "temperature": 0.0, "avg_logprob": -0.09859554213706893, "compression_ratio": 1.793103448275862, "no_speech_prob": 4.9782895075622946e-05}, {"id": 212, "seek": 148624, "start": 1496.8, "end": 1504.28, "text": " more qualitative social science pipelines so yes it's kind of an open question and how can we", "tokens": [544, 31312, 2093, 3497, 40168, 370, 2086, 309, 311, 733, 295, 364, 1269, 1168, 293, 577, 393, 321], "temperature": 0.0, "avg_logprob": -0.09859554213706893, "compression_ratio": 1.793103448275862, "no_speech_prob": 4.9782895075622946e-05}, {"id": 213, "seek": 148624, "start": 1504.28, "end": 1508.48, "text": " devise something like a research protocol for these kinds of interactive network visualizations", "tokens": [1905, 908, 746, 411, 257, 2132, 10336, 337, 613, 3685, 295, 15141, 3209, 5056, 14455], "temperature": 0.0, "avg_logprob": -0.09859554213706893, "compression_ratio": 1.793103448275862, "no_speech_prob": 4.9782895075622946e-05}, {"id": 214, "seek": 148624, "start": 1508.48, "end": 1514.92, "text": " because as you saw in my demo we kind of look at the big nodes we look at the tweets they made", "tokens": [570, 382, 291, 1866, 294, 452, 10723, 321, 733, 295, 574, 412, 264, 955, 13891, 321, 574, 412, 264, 25671, 436, 1027], "temperature": 0.0, "avg_logprob": -0.09859554213706893, "compression_ratio": 1.793103448275862, "no_speech_prob": 4.9782895075622946e-05}, {"id": 215, "seek": 151492, "start": 1514.92, "end": 1520.04, "text": " and it gives us some kind of intuition of what's going on in the debate but how can we formalize", "tokens": [293, 309, 2709, 505, 512, 733, 295, 24002, 295, 437, 311, 516, 322, 294, 264, 7958, 457, 577, 393, 321, 9860, 1125], "temperature": 0.0, "avg_logprob": -0.12499883672693274, "compression_ratio": 1.6782608695652175, "no_speech_prob": 5.130323916091584e-05}, {"id": 216, "seek": 151492, "start": 1520.04, "end": 1524.96, "text": " such kinds of visual network analysis and I think I mean there's people in the audience who", "tokens": [1270, 3685, 295, 5056, 3209, 5215, 293, 286, 519, 286, 914, 456, 311, 561, 294, 264, 4034, 567], "temperature": 0.0, "avg_logprob": -0.12499883672693274, "compression_ratio": 1.6782608695652175, "no_speech_prob": 5.130323916091584e-05}, {"id": 217, "seek": 151492, "start": 1524.96, "end": 1531.0, "text": " actually work on this so I will be very interesting for me to talk about this and finally to end on", "tokens": [767, 589, 322, 341, 370, 286, 486, 312, 588, 1880, 337, 385, 281, 751, 466, 341, 293, 2721, 281, 917, 322], "temperature": 0.0, "avg_logprob": -0.12499883672693274, "compression_ratio": 1.6782608695652175, "no_speech_prob": 5.130323916091584e-05}, {"id": 218, "seek": 151492, "start": 1531.0, "end": 1540.04, "text": " actually maybe a bit nicer note is that there is the network of force them as we had already said", "tokens": [767, 1310, 257, 857, 22842, 3637, 307, 300, 456, 307, 264, 3209, 295, 3464, 552, 382, 321, 632, 1217, 848], "temperature": 0.0, "avg_logprob": -0.12499883672693274, "compression_ratio": 1.6782608695652175, "no_speech_prob": 5.130323916091584e-05}, {"id": 219, "seek": 154004, "start": 1540.04, "end": 1545.44, "text": " in the beginning on this website so it is updated every 15 minutes thanks to a data", "tokens": [294, 264, 2863, 322, 341, 3144, 370, 309, 307, 10588, 633, 2119, 2077, 3231, 281, 257, 1412], "temperature": 0.0, "avg_logprob": -0.11998239904642105, "compression_ratio": 1.68125, "no_speech_prob": 0.0001680046261753887}, {"id": 220, "seek": 154004, "start": 1545.44, "end": 1551.56, "text": " collection done by my colleague Beatrice thank you very much and so if you go on this website", "tokens": [5765, 1096, 538, 452, 13532, 16031, 21299, 1309, 291, 588, 709, 293, 370, 498, 291, 352, 322, 341, 3144], "temperature": 0.0, "avg_logprob": -0.11998239904642105, "compression_ratio": 1.68125, "no_speech_prob": 0.0001680046261753887}, {"id": 221, "seek": 154004, "start": 1551.56, "end": 1559.96, "text": " you can see the retweet network of force them and if you tweet and you can find yourself in", "tokens": [291, 393, 536, 264, 1533, 10354, 3209, 295, 3464, 552, 293, 498, 291, 15258, 293, 291, 393, 915, 1803, 294], "temperature": 0.0, "avg_logprob": -0.11998239904642105, "compression_ratio": 1.68125, "no_speech_prob": 0.0001680046261753887}, {"id": 222, "seek": 155996, "start": 1559.96, "end": 1574.96, "text": " the network also so yeah what do we have here in the middle okay force them itself then there was", "tokens": [264, 3209, 611, 370, 1338, 437, 360, 321, 362, 510, 294, 264, 2808, 1392, 3464, 552, 2564, 550, 456, 390], "temperature": 0.0, "avg_logprob": -0.16134322683016458, "compression_ratio": 1.2278481012658229, "no_speech_prob": 0.0004308581992518157}, {"id": 223, "seek": 157496, "start": 1574.96, "end": 1591.72, "text": " Ubuntu they beyond somewhere okay time's up thank you", "tokens": [50364, 30230, 45605, 436, 4399, 4079, 1392, 565, 311, 493, 1309, 291, 51202], "temperature": 0.0, "avg_logprob": -0.5169013908931187, "compression_ratio": 0.8833333333333333, "no_speech_prob": 0.0017413969617336988}, {"id": 224, "seek": 160496, "start": 1604.96, "end": 1619.8400000000001, "text": " yes so the question is I mentioned that you can only collect tweets from the last seven days", "tokens": [2086, 370, 264, 1168, 307, 286, 2835, 300, 291, 393, 787, 2500, 25671, 490, 264, 1036, 3407, 1708], "temperature": 0.0, "avg_logprob": -0.15488985379536946, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.020196253433823586}, {"id": 225, "seek": 160496, "start": 1619.8400000000001, "end": 1626.68, "text": " with the free API this is a limitation but the tool itself just writes into existing", "tokens": [365, 264, 1737, 9362, 341, 307, 257, 27432, 457, 264, 2290, 2564, 445, 13657, 666, 6741], "temperature": 0.0, "avg_logprob": -0.15488985379536946, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.020196253433823586}, {"id": 226, "seek": 160496, "start": 1626.68, "end": 1631.76, "text": " CSV it depends basically so if you do the same keyword search multiple times and it will just", "tokens": [48814, 309, 5946, 1936, 370, 498, 291, 360, 264, 912, 20428, 3164, 3866, 1413, 293, 309, 486, 445], "temperature": 0.0, "avg_logprob": -0.15488985379536946, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.020196253433823586}, {"id": 227, "seek": 163176, "start": 1631.76, "end": 1644.76, "text": " depend to a CSV yes I mean this is the question right now it depends because the question is", "tokens": [5672, 281, 257, 48814, 2086, 286, 914, 341, 307, 264, 1168, 558, 586, 309, 5946, 570, 264, 1168, 307], "temperature": 0.0, "avg_logprob": -0.15180918196557272, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.0005821111262775958}, {"id": 228, "seek": 163176, "start": 1644.76, "end": 1652.76, "text": " what happens on mastodon I don't know all these like if you want to look at political controversies", "tokens": [437, 2314, 322, 27055, 378, 266, 286, 500, 380, 458, 439, 613, 411, 498, 291, 528, 281, 574, 412, 3905, 11542, 530], "temperature": 0.0, "avg_logprob": -0.15180918196557272, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.0005821111262775958}, {"id": 229, "seek": 163176, "start": 1652.76, "end": 1660.56, "text": " and such discussions I don't know if mastodon is mature enough yet to or adopted enough yet I think", "tokens": [293, 1270, 11088, 286, 500, 380, 458, 498, 27055, 378, 266, 307, 14442, 1547, 1939, 281, 420, 12175, 1547, 1939, 286, 519], "temperature": 0.0, "avg_logprob": -0.15180918196557272, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.0005821111262775958}, {"id": 230, "seek": 166056, "start": 1660.56, "end": 1665.52, "text": " if you want to look at the fostering community it's great so for this yes but yeah", "tokens": [50364, 498, 291, 528, 281, 574, 412, 264, 17114, 278, 1768, 309, 311, 869, 370, 337, 341, 2086, 457, 1338, 50612], "temperature": 0.0, "avg_logprob": -0.3120031140067361, "compression_ratio": 1.1081081081081081, "no_speech_prob": 0.003042526077479124}, {"id": 231, "seek": 169056, "start": 1690.56, "end": 1698.36, "text": " this kind of profit for the city and so well actually for me that's more aggressive to see the", "tokens": [341, 733, 295, 7475, 337, 264, 2307, 293, 370, 731, 767, 337, 385, 300, 311, 544, 10762, 281, 536, 264], "temperature": 0.0, "avg_logprob": -0.7907094088467684, "compression_ratio": 1.6627218934911243, "no_speech_prob": 0.5616018176078796}, {"id": 232, "seek": 169056, "start": 1698.36, "end": 1704.44, "text": " difference the stricter of this sort of this diagram that we are going to use about the social", "tokens": [2649, 264, 1056, 299, 391, 295, 341, 1333, 295, 341, 10686, 300, 321, 366, 516, 281, 764, 466, 264, 2093], "temperature": 0.0, "avg_logprob": -0.7907094088467684, "compression_ratio": 1.6627218934911243, "no_speech_prob": 0.5616018176078796}, {"id": 233, "seek": 169056, "start": 1704.44, "end": 1711.84, "text": " of what we are talking about let's see the conference of citizens with human people same in", "tokens": [295, 437, 321, 366, 1417, 466, 718, 311, 536, 264, 7586, 295, 7180, 365, 1952, 561, 912, 294], "temperature": 0.0, "avg_logprob": -0.7907094088467684, "compression_ratio": 1.6627218934911243, "no_speech_prob": 0.5616018176078796}, {"id": 234, "seek": 171184, "start": 1711.84, "end": 1728.56, "text": " collection yeah I don't know what to think about that well I don't know which point exactly should", "tokens": [5765, 1338, 286, 500, 380, 458, 437, 281, 519, 466, 300, 731, 286, 500, 380, 458, 597, 935, 2293, 820], "temperature": 0.0, "avg_logprob": -0.22437011952302893, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.0003289284068159759}, {"id": 235, "seek": 171184, "start": 1728.56, "end": 1736.28, "text": " I address because you raised a lot of so so are you okay if I can rephrase so you are concerned", "tokens": [286, 2985, 570, 291, 6005, 257, 688, 295, 370, 370, 366, 291, 1392, 498, 286, 393, 319, 44598, 651, 370, 291, 366, 5922], "temperature": 0.0, "avg_logprob": -0.22437011952302893, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.0003289284068159759}, {"id": 236, "seek": 173628, "start": 1736.28, "end": 1742.3999999999999, "text": " about these kinds of this kind of research also yes because because it can be used to track users", "tokens": [466, 613, 3685, 295, 341, 733, 295, 2132, 611, 2086, 570, 570, 309, 393, 312, 1143, 281, 2837, 5022], "temperature": 0.0, "avg_logprob": -0.13045166306576486, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.00021206347446423024}, {"id": 237, "seek": 173628, "start": 1742.3999999999999, "end": 1756.6, "text": " across political camps right yes okay I see so I think it's more about the", "tokens": [2108, 3905, 16573, 558, 2086, 1392, 286, 536, 370, 286, 519, 309, 311, 544, 466, 264], "temperature": 0.0, "avg_logprob": -0.13045166306576486, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.00021206347446423024}, {"id": 238, "seek": 173628, "start": 1756.6, "end": 1761.48, "text": " representativity of Twitter data for for the wide wider population which of course you're", "tokens": [2906, 30142, 295, 5794, 1412, 337, 337, 264, 4874, 11842, 4415, 597, 295, 1164, 291, 434], "temperature": 0.0, "avg_logprob": -0.13045166306576486, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.00021206347446423024}, {"id": 239, "seek": 176148, "start": 1761.48, "end": 1767.44, "text": " you're totally right it is kind of a subset of highly politicized maybe also a bit more", "tokens": [291, 434, 3879, 558, 309, 307, 733, 295, 257, 25993, 295, 5405, 48044, 1602, 1310, 611, 257, 857, 544], "temperature": 0.0, "avg_logprob": -0.10612873804001581, "compression_ratio": 1.6777251184834123, "no_speech_prob": 0.00010179029777646065}, {"id": 240, "seek": 176148, "start": 1767.44, "end": 1771.8, "text": " educated than average people so you cannot but but this is not what we're trying to do", "tokens": [15872, 813, 4274, 561, 370, 291, 2644, 457, 457, 341, 307, 406, 437, 321, 434, 1382, 281, 360], "temperature": 0.0, "avg_logprob": -0.10612873804001581, "compression_ratio": 1.6777251184834123, "no_speech_prob": 0.00010179029777646065}, {"id": 241, "seek": 176148, "start": 1771.8, "end": 1776.8, "text": " also you're not trying to infer I don't know actually lecture results based on Twitter data", "tokens": [611, 291, 434, 406, 1382, 281, 13596, 286, 500, 380, 458, 767, 7991, 3542, 2361, 322, 5794, 1412], "temperature": 0.0, "avg_logprob": -0.10612873804001581, "compression_ratio": 1.6777251184834123, "no_speech_prob": 0.00010179029777646065}, {"id": 242, "seek": 177680, "start": 1776.8, "end": 1792.28, "text": " so I yeah I don't know if I addressed the point now maybe we can take more about it right", "tokens": [50364, 370, 286, 1338, 286, 500, 380, 458, 498, 286, 13847, 264, 935, 586, 1310, 321, 393, 747, 544, 466, 309, 558, 51138], "temperature": 0.0, "avg_logprob": -0.24058047930399576, "compression_ratio": 1.1125, "no_speech_prob": 0.0003037298156414181}], "language": "en"}