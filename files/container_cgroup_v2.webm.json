{"text": " Okay. I think we're ready to start. Oh, excellent. This time it worked perfectly. Thank you so much. Yeah. Chris is going to talk about C Group V2, seven years of C Group V2 in the kernel, very exciting time, and the future of Linux resource control. Take it away. Hello, everybody. Oh, yes. Please go on. Thank you. That's it. I'm done. Goodbye. Hello. I'm Chris Down. I work as a kernel engineer at Metta. I work on the kernels memory management subsystem, especially I'm a contributor to C Groups, which are one of the things which underpins our model of containers. I'm also a maintainer of the system D project. So there's two things on this slide, which you can hate me for. Most of the time I'm thinking about, you know, how we can make Linux just a little bit more reliable, just a little bit more usable at scale. We have a million plus machines. We can't just buy more RAM. It's not really a thing we can do. So we need to extract the absolute maximum from every single machine. Otherwise, there's a huge loss of capacity that could result. So that's the kind of thing I want to talk to you about today. However, the last seven years we have done this at Metta, how we've improved the reliability and capacity and extracted more efficiency. At Metta and in industry, we are increasingly facing this kind of problem where we can't effectively solve scaling problems just by throwing hardware at the problem. We can't construct data centers fast enough. We can't source clean power fast enough. We have hundreds of thousands of machines and we just can't afford to waste capacity because any small loss in capacity on a single machine translates to a very large amount at scale. Ultimately, what we need to do is use resources more efficiently and we need to build the kernel infrastructure in order to do that. Another challenge that we have is that many huge site incidents for companies like us and companies of our size are caused by lacking resource control. Not being able to control things like CPU, IO, memory and the like is one of the most pervasive causes of incidents and outages across our industry and we need to sustain an initiative industry-wide in order to fix this. So how does all of this relate to this C-groups thing in the title? So C-groups are a kernel mechanism to balance and control and isolate things like memory, CPU, IO, things that you share across a machine, things that processes share and I'm sure if you've operated containers before, which I'm going to assume that you have, judging by the fact you're in this room otherwise you may be lost in looking for the AI room, you know every single modern container runtime uses this. Stalker uses it, Chorus uses it, Kubernetes uses it, SystemD uses it. The reason they use it is because it's the most mature platform to do this work and it solves a lot of the long-standing problems which we had with kind of classic resource control in the form of view limits and things like that. C-groups have existed for about 14 years now and they have changed a lot in that time. Most notably, seven years ago in kernel 4.5 we released C-group 2. I gave a whole talk around the time when that happened on why we were moving to a totally new interface, why we weren't just iterating on the old interface and if you're interested in a really in-depth look at that then here's a talk which you can go and take a look at. But the most fundamental change really is that in C-group 2 what happens is that you enable or disable resources in the context of a particular C-group. In C-group 1 what you have is a hierarchy for memory, a hierarchy for CPU and the two will never meet. Those two things are completely independent. SystemD when it creates things in C-group V1 it will name them the same they get called something.slice or something.service but they have no relation to each other across resources. But in C-group 2 you have just a single C-group and you enable or disable resources in the context of that particular C-group so you can enable say memory control and IO control together. That might seem like you know an aesthetic kind of concern but it's really not. Without this major API change we simply cannot use C-groups to do complex resource control. Take the following scenario. Memory starts to run out on your machine. So when we start to run out of memory on a pretty much any modern operating system what do you do? Well you try and go and free some up. So we start to reclaim some page caches. We start to reclaim maybe some anonymous pages if we have swap. And this results in disk IO. And if we're particularly memory bound and it's really hard to free pages and we're having to walk the pages over and over and over to try and find stuff to free then it's going to cost a non-trivial amount of CPU cycles to do so. Looking through available memory to find pages which can be free can be extremely expensive on memory bound workloads. On some highly loaded or memory bound systems it can take you know double digit amount of CPU from the machine just to do this walking. It's a highly expensive process. And without having the single resource hierarchy we cannot take into account these transfers between the different resources how one leads to another because they're all completely independent. If you've been in the containers different before you've probably thinking I've seen this guy before and I think he's given this exact talk about three years ago. I'm sure some of you think and that already. Well the company name isn't the only thing which has changed in 2020. Also some seagrups things have changed since 2020 and obviously I don't want to rehash the same things over and over. I don't want to bore you. So this talk will mostly be about the changes since the last time I was here in 2020 with just a little bit of context setting just a little bit. This talk is really about the process of getting resource isolation working at scale. It's what it needs to happen in production not just in a theoretical concern. The elephant in the room of course is COVID. The last three years have seen pretty significant changes in behavior due to COVID especially for a platform like Facebook which we own of course. This was by about 27% over what you would usually expect and this came at a time where not only you're seeing increased demand but you literally can't go out and buy memory. You can't go out and buy more CPUs. You can't go out and buy more disks because there's a shortage because there's COVID. So what we really needed was to make more efficient use of the existing resources on the machine right. We need to have an acceleration or existing efforts around resource control in order to do that to make things more efficient. Now almost every single time that I give this sounds like a personal point of concern. Every time I give this talk somebody on Hacker News comments why don't you just get some more memory? Now I don't know how trivial people in this room think that is when you've got several million servers but it is slightly difficult sometimes. For example there's a huge amount of cost involved there and not just the money which is indeed substantial and I'm very glad it's not coming out of my bank account but also in things like power draw, in things like thermals, in things like hardware design trade-offs. Not to mention during COVID you just couldn't get these kind of, you couldn't get a hard drive, you couldn't get some memory. You'd go down to your local Best Buy and do it but that's about it. So not really an option. So here's a simple little proposition for you, for anyone in the room who wants to be brave. How do you view memory usage for a process in Linux? Oh come on. Free! My man said free. Oh lord. This was a trap. So I appreciate it though, big up about that. So yeah, so free and the like really only measure like one type of memory. They do have caches and buffers in the side but the thing is okay so for free or for PS which were shut at the back you know you do see something like the resident set size and you see some other details and you might be thinking hey you know that's fine like I don't really care about some of the other things that's the bit which my application is really using. For example we don't necessarily think that our programs rely on caches and buffers to operate in any sustainable way but the problem is the answer for any sufficiently complex system is almost certainly that a lot of those caches and buffers are not optional. They are basically essential. Let's take Chrome just as a facile example. The Chrome Binary's code segment is over 130 megs. He's a chunky boy. He is. He's a big boy. We load this code into memory. We do it gradually. We're not we're not maniacs. We do it gradually but you know we do it as part of the page cache. A boy if you want to execute some particular part of Chrome you know this cache isn't just nice to have the cache that has the code in it that runs this particular part of Chrome. We literally cannot make any forward progress without that part of the cache and the same goes for caches for the files you're loading especially for something like Chrome you probably do have a lot of caches so eventually those pages are going to have to make their way into the working set. They're going to have to make their way into main memory. In another particularly egregious case we have a demon at Meta and this demon aggregates metrics across a machine. It sends them to centralized storage and as part of this what it does is it runs a whole bunch of janky scripts and these janky scripts go and collect things across the machine. I mean we've all got one. We've all got this kind of demon where you collect all kind of janky stuff and you don't really know what it does but it sends some nice metrics and it looks nice and one of the things we were able to demonstrate is while the team had this demon thought that it took about 100 to 150 megabytes to run using the things that we'll talk about in this talk it actually was more like two gigabytes. So the difference is quite substantial on some things like you could be quite misunderstanding like what is taking memory on your machine. So in C-group 2 we have this file called memory.current that measures the current memory usage for the C-group including everything like caches, buffers, kernel objects, so on. So job done right? Well no the problem is here that whenever somebody comes to these talks and I say something like don't use RSS to measure your application they go and see oh we've added a new thing called memory.current and it measures everything great. I'm just gonna put some metrics based on that but it's quite important to understand what that actually means to have everything here right. The very fact that we are not talking about just the resident set size anymore means the ramifications are fundamentally different. We have caches, buffers, socket memory, TCP memory, kernel objects, all kind of stuff in here and that's exactly how it should be because we need that to prevent abuse of these resources which are valid resources across the system. They are things we actually need to run. So understanding why reasoning about memory.current might be more complicated than it seems comes down to why as an industry we tended to gravitate towards measuring RSS in the first place. We don't measure RSS because it measures anything useful we measure it because it's really fucking easy to measure. That's the reason we measure RSS like there's no other reason like it doesn't measure anything very useful. It kind of tells you vaguely like maybe what your application might be doing kind of but it doesn't tell you anything of any of the actually like interesting parts of your application only the bits you pretty much already knew. So memory.current suffers from pretty much exactly the opposite problem which is it tells you the truth and don't really know how to deal with that. Don't really know how to deal with being told how much memory application is using. For example if you set an 8 gigabyte memory limit in C root v2 how big is memory.current going to be on a machine which has no other thing running on it. It's probably going to be 8 gigabytes because we've decided that we're going to fill it with all kind of nice stuff. There's no reason we should evict that. There's no reason we should take away these nice you know K mem caches. There's no reason we should take away these slots because we have free memory so why not. Why not keep them around. So if there was no pressure for this to shrink from any outside scope then the slack is just going to expand until it reaches your limit. So what should we do? How should we know what the real needed amount of memory is at a given time? So let's take an example Linux kernel build for example which with no limits has a peak memory.current of just over 800 megabytes. In C root v2 we have this tunable called memory.high. This tunable reclaims memory from the C group until it goes back under some threshold. It just keeps on reclaiming and reclaiming and reclaiming and throttling until you reach back under. So right now things take about four minutes with no limits. This is about how long it takes to build the kernel and when I apply you know a throttling like a like a reclaim threshold of 600 megabytes actually you know the job finishes roughly about the same amount of time maybe a second more with about 25 percent less available memory at peak and the same even happens when we go down to 400 megabytes. Now we're using half the memory that we originally used with only a few seconds more wall time. It's it's pretty good trade-off. However if we just go just a little bit further then things just never even complete. We have to we have to control see the build right and this is nine minutes in it's still ain't done. So we know that the process needs somewhere between 300 and 400 megabytes of memory but it's pretty error prone to try and work out what the exact value is. So to get an accurate number for services at scale which are even more difficult than this because they dynamically shrink and expand depending on load we need a better automated way to do that. So determining the exact amount of memory required by an application is a really really difficult and error prone task right. So SEMPAI is this kind of simple self-contained tool to continually poll what's called pressure stall information or PSI. Pressure stall information is essentially a new thing we've added in CIGRI2 to determine whether a particular resource is oversaturated and we've never really had a metric like this in in the Linux kernel before. We've had many related metrics for example for memory we have things like you know page caches and buffer usage and so on but we don't really know how to tell pressure or over subscription from an efficient use of the system those two are very difficult to tell apart even with using things like page scans or or so on it's pretty difficult. So in SEMPAI what we do is we use these PSI pressure stall metrics to measure the amount of time which threads in a particular C group were stuck doing in this case memory work. So this pressure equals 0.16 thing kind of halfway down the slide means that you know 0.16 percent of the time I could have been doing more productive work but I've been stuck doing memory work. This could be things like you know waiting for a kernel memory lock it could be things like being throttled could be waiting for reclaimed to finish even more than that it could be memory related IO which which can also dominate to be honest things like refolding file content into the page cache or swapping in and pressure is essentially saying you know if I had a bit more memory I would be able to run so much faster 0.16 percent faster. So using PSI and memory.high what SEMPAI does is adjust just enough memory pressure on a C group to evict cold memory pages that aren't essential for workload performance. It's an integral controller which dynamically adapts to these memory peaks and troughs an example case being something like a web server which is somewhere where we have used it when more requests come we see that the pressure is growing and we expand the memory.high limit when fewer requests are coming we we see that and we start to decrease the amount of working set which we give again so it can be used to answer the question you know how much memory does my application actually use over time and in this case we find for the compile job the answer is about like 340 megabytes or so and that's fine you might be asking yourself what's the what are the benefits of this shrinking like why why does this even matter to be honest surely like when you're starting to run out of memory Linux is going to do it anyway and you're not wrong like that's true but the thing is what we kind of need here is to get ahead of memory shortages which which could be bad and amortize the work ahead of time when your machine is already highly contended it's already being driven into the ground and going towards the umkiller it's pretty hard to say hey bro could you just like like give me some pages right now like it's it's not exactly like what what's on its mind it's probably desperately trying to keep the atomic pool going so there's there's another thing as well which is you know it's pretty good for determining regressions which is what a lot of people use for rss for right like we this is the way we found out that that demon was using two gigabytes of memory instead of 150 megabytes of memory so it's pretty good for finding out hey how much does my application actually need to run so the combination of these things means that senpai is an essential part of how we do workload stacking of matter and it not only gives us an accurate read on what the demand is right now but allows us to adjust stacking expectations depending on what the workload is doing this feeds into another one of our efforts around efficiency which is improving memory offloading so traditionally on most operating systems you have only one real memory offloading location which is your disk um even if you don't have swap that's true because you do things like demand paging right you page things in gradually and you also have to you know evict and get things in the file cache so we're talking also here about like a lot of granular intermediate areas that could be considered for some page offloading for infrequently access pages but they're not really so frequently used um getting this data come into main memory again though can be very different in terms of how difficult it is depending on how far up the the triangle you go right for example um it's much easier to do it on an ssd than a hard drive because hard drives don't well they're slow and they also don't tolerate random head like head seeking very well but there are more granular gradual things that we can do as well for example one thing we can do is to start look at exact strategies outside of hardware one of the problems with the duality of either being in ram or on the disk is that even your disk even if it's quite fast even if if it's flash it tends to be quite a few orders of magnitude slower than your main memory is uh so one area which we have have been heavily invested in is looking at what we might term warm pages uh in Linux we have talked a lot about hot pages and cold pages if you look in the memory management code but there is like this kind of part of the working set which yes i do need it relatively frequently but i don't need it to make forward progress all the time so zswap is one of these one of these things we can use for that it's it's uh essentially a feature of the Linux kernel which compresses pages which looks like they will compress well and are not too hot into a separate pool in main memory we do have to page fold them back in into main memory again if if we actually want to use them of course but it's several orders of magnitude faster than trying to get it off the disk we still do have this swap for infrequently access pages there tends to be quite a bit cold working set as well um but you know this is kind of like this tiered hierarchy where we want to have warm uh warm pages instead swap hot pages in in main memory and kind of cold pages and swap one problem we had here was that even when we configure the kernel to swap as aggressively as possible it still wouldn't do it um if you've actually looked at the swap code and i've had the unfortunate misery of working on it um this you'll learn that swap code was implemented a very long time ago by the people who knew what swap did and how things worked but none of them are around to tell us what the hell anything means anymore and it's very confusing so i can't even describe to you how the old algorithm works because it has about 500 heuristics and i don't know why any of them are there um so for this reason you know we try to think how can we make this a little bit more efficient we are using non-rotational disks now we have zswap we have flash disks we have ssds we want to make a an algorithm which can handle this better so from kernel 5.8 um we have been working on a new algorithm which has already landed um so first we have code to track all swap ins and cache misses across the system so for every cache page we're having to page fold and evict and page fold and evict and page fold and evict over and over again what we want to do is try and page out a heat page instead if we're unlucky and this heat page actually it turns out to be hot then you know no biggie like we we've made a mistake but we'll try a different one next time we do have some heuristics to try and work out which one is hot and which one is not but they are kind of expensive so we don't use a lot of them um however you know if if we are lucky and the heat page does stay swapped out then that's one more page which we can use for file caches and we can use it for other processes and this means that we can engage swap a lot more readily in most scenarios importantly though we are not adding ioload this doesn't increase ioload or decrease endurance of the disk um we are just more intentional about in choosing how to apply the i it doesn't double up um we only trade one type of paging for another and our goal here is to reach an optimal state where the optimal state is doing the minimum amount of i o in order to sustain workload performance um so ideally what we do is have this tiered model of you know like I said main memory z swap and swap on disk this is super simple idea compared to the old model although the old algorithm has a lot of kind of weird heuristics as I mentioned a lot of penalties a lot of kind of strange things um in general it was not really written for an era where SSDs exist or where z swap exists so it's understandable that it needed some some care and attention so what were the effects of this change in prod like what what actually happened so on web servers we not only noticed like an increase in performance but we also noticed a decrease in heat memory by about two gigabytes or so out of about 16 gigabytes total the cache grew to fill this newly freed space and it grew by about two gigabytes from about uh two gigabytes of cache to four gigabytes of cache we also observed a measurable increase in web server performance from this change which is deeply encouraging and these are all indications that you know we are now starting to reclaim the right things actually we are making better decisions because things are looking pretty positive here so not only that but you see a decrease in disk i o because we are actually doing things correctly we are making the correct decisions and it's not really that often that you get a benefit in performance disk i o memory usage instead of having to trade off between them right so it probably indicates that this is the better solution for this kind of era this also meant that on some workloads uh we now had opportunities to stack where we did not have opportunities to stack before like running say multiple kinds of ads jobs or multiple kinds of web servers on top of each other uh many machines don't use up all of their resources but they use up just enough that it's pretty hard to stack something else on top of it because you're using just enough that it's not actually enough to sustainably run to workload side by side so this is another thing where we've managed to kind of push the needle just a little bit so that you can make quite a bit more use uh an efficiency out of the servers that exist the combination of changes to the swap algorithm using z-swap and squeezing workloads using senpai was a huge part of our operation during covid all of these things acting together we termed tmo which stands for transparent memory offloading and you can see some of the results we've had in production here in some cases we were able to save up to 20 percent of critical fleet-wide workloads memory with either neutral or even in some cases positive effects on workload performance so this opens up a lot of opportunities obviously in terms of reliability stacking and future growth this whole topic has a huge amount of cover i really could just do an entire talk on this um if you want to learn more i do recommend the post which is linked at the bottom my colleagues johannes and dan wrote an article with a lot more depth on you know how we achieve what we achieved and on things like cxl memory as well so let's come back to this this slide from earlier um we briefly touched on the fact that if bounded one resource can just turn into another a particularly egregious case being memory turning into i o when it gets bounded for this reason it might seem counterintuitive but we always need controls on i o when we have controls on memory otherwise memory pressure will always just directly translate to disk i o probably the most attuned way to solve this is to try to limit disk bandwidth or disk i ops however this doesn't really manifest usually very well in reality if you think about any modern storage device they tend to be quite complex they they're q devices you can throw a lot of commands of them in parallel and when you do that you often find that hey you know magically it can do more things the same reason we have i o schedulers because we can optimize what we do inside the disk also the mixture of i o really matters like reads versus writes sequential versus random even on ssds these things tend to matter um and it's really hard to turn to determine a single metric for loadedness for a storage device because the cost of one i o operation or one block of data is extremely variable depending on the wider context um so it's it's also really punitive to just have a limit on you know how much can i write how many i ops can i do um because even if nobody else is using the disk you're still slowed down to this level there's no opportunity to make the most of the disk when nobody else is doing anything right so it's not really good for this kind of best effort bursty work on a machine which we would like to do so the first way that we try to avoid this problem is by using latency as a metric for workload health so what we might try and do is apply a maximal target latency for i o completions on the main workload and if we exceed that we start dialing back other c groups with lucid latency requirements back to their own configured thresholds what this does is this prevents an application from thrashing on memory so much that it just kills i o across the system this actually works really well for systems where there's only one workload but the problem comes when you have a multi workload stacked case like this here we have two high priority workloads which are stacked on a single machine one has an i o dot latency of 10 milliseconds the other has 30 milliseconds but the problem here is as soon as workload one gets into trouble everyone else is going to suffer and there's no way around that we're just going to penalize them and there's no way to say you know how bad is the situation really and is it really them causing the problem this is fine if you're you know the thing you're throttling is just best effort but it's we here we have two important workloads right so how can we solve this so our solution is this thing called i o dot cost which might look very similar at first but notice the omission of the units these are not units in milliseconds these are weights in a similar way to how we do cpu scheduling so how do we know what 40 60 or 100 mean in this context well they add up to 200 so the idea is if you are saturating your disk you know best effort outside will get 40 will get i guess 20 percent of of the work it'll workload one will get 50 and workload two will get 30 so it balances out based on this kind of shares or weights like model how do we know when we reach this 100 percent of saturation though so what i o dot cost does is build a linear model of your disk over time it sees how the disk responds these variable loads passively and it works based on things like you know read or write i o whether it's random or sequential the size of the i o so it boils down this quite complex operation of you know how much can my disk actually do into a linear model which it which it handles itself it has a kind of a q s model you can implement but there's also a basic on the fly model using q depth so you can read more about it in the links at the bottom i won't waffle on too much but it is something which you can use to do kind of effective i o control in the old days i came to this room and talked about secret b2 and the historical response was basically that's nice docker doesn't support it though so please leave um i've had a nice chat with some docker lutz uh no the docker people are very nice and so are all the other container people and what's happened is we have it almost everywhere almost everywhere secret b2 is a thing we have quite a diversity of container run time some police report is basically supported everywhere um so even if nothing changes from your side moving to secret b2 means that you know you get significantly more reliable accounting for free we spent quite a while working with docker and system defoaks and so on and so forth to get things working and we're also really thankful to fedora for making secret b2 the default since fedora 32 as well as making things more reliable behind the scenes for users this also you know got some people's ass into gear when they had an issue on their github on their github that says it doesn't work in fedora so cheers fedora people uh it was a kind of a good signal that you know this is what we are actually doing this is what we as an industry as a as a technology community are actually doing uh and that was quite helpful the kd and gnom folks have also been busy using cgroups to give uh a better management of that kind of desktop handling david edmundson and henry chain from kd in particular gave this talk at kd academy the title of talk was using cgroups to make everything amazing now i'm not brazen enough to title my talk that but i'll just let it speak for itself for their one um it basically goes over the use of cgroups and c v2 for resource control and for interactive responsiveness on the desktop um so this is definitely kind of a developing space obviously there's been a lot of work on the server side here um but if you're interested in that i definitely recommend you know giving the talk a watch it really goes into challenges they had and then unique features c v2 has to solve those finally android is also using the metrics exported by the psi project in order to detect and prevent memory pressure events which affect the user experience as you can imagine on android interactive latency is extremely important you don't it would really suck if you're about to click a button and then you click it and that requires allocating memory and the whole phone freezes i mean it does still happen sometimes but obviously this is something which which they're trying to work on and we've been working quite closely with them to integrate the psi uh project into the into android hopefully this talk gave you some ideas about things you'd like to try out for yourself um we're still very actively improving uh kernel resource control it might have been seven years since we started but you know we still have plenty of things we want to do and what we really need is your feedback what we really need is more examples of uh how the community is using c v2 and problems and issues you've encountered um obviously everyone's needs are quite different and i and others are quite eager to know what we could be doing to help you what we could be doing to make things better what we could be doing to make things more intuitive because there's definitely work to be done there and i'll be around after the talk if you want to chat but feel free to drop me an email message me on mastodon always happy to hear feedback or suggestions um i've been chris down and this has been seven years of c at c review to future of Linux resource control thank you very much", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.16, "text": " Okay. I think we're ready to start. Oh, excellent. This time it worked perfectly. Thank you", "tokens": [1033, 13, 286, 519, 321, 434, 1919, 281, 722, 13, 876, 11, 7103, 13, 639, 565, 309, 2732, 6239, 13, 1044, 291], "temperature": 0.0, "avg_logprob": -0.2855898190851081, "compression_ratio": 1.3608247422680413, "no_speech_prob": 0.5618115663528442}, {"id": 1, "seek": 0, "start": 14.16, "end": 20.8, "text": " so much. Yeah. Chris is going to talk about C Group V2, seven years of C Group V2 in the", "tokens": [370, 709, 13, 865, 13, 6688, 307, 516, 281, 751, 466, 383, 10500, 691, 17, 11, 3407, 924, 295, 383, 10500, 691, 17, 294, 264], "temperature": 0.0, "avg_logprob": -0.2855898190851081, "compression_ratio": 1.3608247422680413, "no_speech_prob": 0.5618115663528442}, {"id": 2, "seek": 0, "start": 20.8, "end": 26.48, "text": " kernel, very exciting time, and the future of Linux resource control. Take it away.", "tokens": [28256, 11, 588, 4670, 565, 11, 293, 264, 2027, 295, 18734, 7684, 1969, 13, 3664, 309, 1314, 13], "temperature": 0.0, "avg_logprob": -0.2855898190851081, "compression_ratio": 1.3608247422680413, "no_speech_prob": 0.5618115663528442}, {"id": 3, "seek": 2648, "start": 26.48, "end": 35.76, "text": " Hello, everybody. Oh, yes. Please go on. Thank you. That's it. I'm done. Goodbye. Hello. I'm", "tokens": [2425, 11, 2201, 13, 876, 11, 2086, 13, 2555, 352, 322, 13, 1044, 291, 13, 663, 311, 309, 13, 286, 478, 1096, 13, 15528, 13, 2425, 13, 286, 478], "temperature": 0.0, "avg_logprob": -0.20098821384700263, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.00017803434457164258}, {"id": 4, "seek": 2648, "start": 35.76, "end": 40.56, "text": " Chris Down. I work as a kernel engineer at Metta. I work on the kernels memory management", "tokens": [6688, 9506, 13, 286, 589, 382, 257, 28256, 11403, 412, 6377, 1328, 13, 286, 589, 322, 264, 23434, 1625, 4675, 4592], "temperature": 0.0, "avg_logprob": -0.20098821384700263, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.00017803434457164258}, {"id": 5, "seek": 2648, "start": 40.56, "end": 45.04, "text": " subsystem, especially I'm a contributor to C Groups, which are one of the things which", "tokens": [2090, 9321, 11, 2318, 286, 478, 257, 42859, 281, 383, 10500, 82, 11, 597, 366, 472, 295, 264, 721, 597], "temperature": 0.0, "avg_logprob": -0.20098821384700263, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.00017803434457164258}, {"id": 6, "seek": 2648, "start": 45.04, "end": 49.36, "text": " underpins our model of containers. I'm also a maintainer of the system D project. So there's", "tokens": [833, 79, 1292, 527, 2316, 295, 17089, 13, 286, 478, 611, 257, 6909, 260, 295, 264, 1185, 413, 1716, 13, 407, 456, 311], "temperature": 0.0, "avg_logprob": -0.20098821384700263, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.00017803434457164258}, {"id": 7, "seek": 2648, "start": 49.36, "end": 53.44, "text": " two things on this slide, which you can hate me for. Most of the time I'm thinking about,", "tokens": [732, 721, 322, 341, 4137, 11, 597, 291, 393, 4700, 385, 337, 13, 4534, 295, 264, 565, 286, 478, 1953, 466, 11], "temperature": 0.0, "avg_logprob": -0.20098821384700263, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.00017803434457164258}, {"id": 8, "seek": 5344, "start": 53.44, "end": 57.12, "text": " you know, how we can make Linux just a little bit more reliable, just a little bit more usable", "tokens": [291, 458, 11, 577, 321, 393, 652, 18734, 445, 257, 707, 857, 544, 12924, 11, 445, 257, 707, 857, 544, 29975], "temperature": 0.0, "avg_logprob": -0.06774076502373878, "compression_ratio": 1.7173252279635258, "no_speech_prob": 0.00018051601364277303}, {"id": 9, "seek": 5344, "start": 57.12, "end": 61.28, "text": " at scale. We have a million plus machines. We can't just buy more RAM. It's not really a thing", "tokens": [412, 4373, 13, 492, 362, 257, 2459, 1804, 8379, 13, 492, 393, 380, 445, 2256, 544, 14561, 13, 467, 311, 406, 534, 257, 551], "temperature": 0.0, "avg_logprob": -0.06774076502373878, "compression_ratio": 1.7173252279635258, "no_speech_prob": 0.00018051601364277303}, {"id": 10, "seek": 5344, "start": 61.28, "end": 65.6, "text": " we can do. So we need to extract the absolute maximum from every single machine. Otherwise,", "tokens": [321, 393, 360, 13, 407, 321, 643, 281, 8947, 264, 8236, 6674, 490, 633, 2167, 3479, 13, 10328, 11], "temperature": 0.0, "avg_logprob": -0.06774076502373878, "compression_ratio": 1.7173252279635258, "no_speech_prob": 0.00018051601364277303}, {"id": 11, "seek": 5344, "start": 65.6, "end": 69.28, "text": " there's a huge loss of capacity that could result. So that's the kind of thing I want to talk to you", "tokens": [456, 311, 257, 2603, 4470, 295, 6042, 300, 727, 1874, 13, 407, 300, 311, 264, 733, 295, 551, 286, 528, 281, 751, 281, 291], "temperature": 0.0, "avg_logprob": -0.06774076502373878, "compression_ratio": 1.7173252279635258, "no_speech_prob": 0.00018051601364277303}, {"id": 12, "seek": 5344, "start": 69.28, "end": 73.68, "text": " about today. However, the last seven years we have done this at Metta, how we've improved the", "tokens": [466, 965, 13, 2908, 11, 264, 1036, 3407, 924, 321, 362, 1096, 341, 412, 6377, 1328, 11, 577, 321, 600, 9689, 264], "temperature": 0.0, "avg_logprob": -0.06774076502373878, "compression_ratio": 1.7173252279635258, "no_speech_prob": 0.00018051601364277303}, {"id": 13, "seek": 5344, "start": 73.68, "end": 80.32, "text": " reliability and capacity and extracted more efficiency. At Metta and in industry, we are", "tokens": [24550, 293, 6042, 293, 34086, 544, 10493, 13, 1711, 6377, 1328, 293, 294, 3518, 11, 321, 366], "temperature": 0.0, "avg_logprob": -0.06774076502373878, "compression_ratio": 1.7173252279635258, "no_speech_prob": 0.00018051601364277303}, {"id": 14, "seek": 8032, "start": 80.32, "end": 85.27999999999999, "text": " increasingly facing this kind of problem where we can't effectively solve scaling problems just by", "tokens": [12980, 7170, 341, 733, 295, 1154, 689, 321, 393, 380, 8659, 5039, 21589, 2740, 445, 538], "temperature": 0.0, "avg_logprob": -0.06600472132364908, "compression_ratio": 1.779874213836478, "no_speech_prob": 5.125563984620385e-05}, {"id": 15, "seek": 8032, "start": 85.27999999999999, "end": 89.03999999999999, "text": " throwing hardware at the problem. We can't construct data centers fast enough. We can't", "tokens": [10238, 8837, 412, 264, 1154, 13, 492, 393, 380, 7690, 1412, 10898, 2370, 1547, 13, 492, 393, 380], "temperature": 0.0, "avg_logprob": -0.06600472132364908, "compression_ratio": 1.779874213836478, "no_speech_prob": 5.125563984620385e-05}, {"id": 16, "seek": 8032, "start": 89.03999999999999, "end": 93.52, "text": " source clean power fast enough. We have hundreds of thousands of machines and we just can't afford", "tokens": [4009, 2541, 1347, 2370, 1547, 13, 492, 362, 6779, 295, 5383, 295, 8379, 293, 321, 445, 393, 380, 6157], "temperature": 0.0, "avg_logprob": -0.06600472132364908, "compression_ratio": 1.779874213836478, "no_speech_prob": 5.125563984620385e-05}, {"id": 17, "seek": 8032, "start": 93.52, "end": 98.16, "text": " to waste capacity because any small loss in capacity on a single machine translates to a", "tokens": [281, 5964, 6042, 570, 604, 1359, 4470, 294, 6042, 322, 257, 2167, 3479, 28468, 281, 257], "temperature": 0.0, "avg_logprob": -0.06600472132364908, "compression_ratio": 1.779874213836478, "no_speech_prob": 5.125563984620385e-05}, {"id": 18, "seek": 8032, "start": 98.16, "end": 102.8, "text": " very large amount at scale. Ultimately, what we need to do is use resources more efficiently", "tokens": [588, 2416, 2372, 412, 4373, 13, 23921, 11, 437, 321, 643, 281, 360, 307, 764, 3593, 544, 19621], "temperature": 0.0, "avg_logprob": -0.06600472132364908, "compression_ratio": 1.779874213836478, "no_speech_prob": 5.125563984620385e-05}, {"id": 19, "seek": 8032, "start": 102.8, "end": 108.0, "text": " and we need to build the kernel infrastructure in order to do that. Another challenge that we have", "tokens": [293, 321, 643, 281, 1322, 264, 28256, 6896, 294, 1668, 281, 360, 300, 13, 3996, 3430, 300, 321, 362], "temperature": 0.0, "avg_logprob": -0.06600472132364908, "compression_ratio": 1.779874213836478, "no_speech_prob": 5.125563984620385e-05}, {"id": 20, "seek": 10800, "start": 108.0, "end": 113.52, "text": " is that many huge site incidents for companies like us and companies of our size are caused by", "tokens": [307, 300, 867, 2603, 3621, 21139, 337, 3431, 411, 505, 293, 3431, 295, 527, 2744, 366, 7008, 538], "temperature": 0.0, "avg_logprob": -0.12950726559287623, "compression_ratio": 1.723021582733813, "no_speech_prob": 8.231824904214591e-05}, {"id": 21, "seek": 10800, "start": 113.52, "end": 119.12, "text": " lacking resource control. Not being able to control things like CPU, IO, memory and the like is one", "tokens": [20889, 7684, 1969, 13, 1726, 885, 1075, 281, 1969, 721, 411, 13199, 11, 39839, 11, 4675, 293, 264, 411, 307, 472], "temperature": 0.0, "avg_logprob": -0.12950726559287623, "compression_ratio": 1.723021582733813, "no_speech_prob": 8.231824904214591e-05}, {"id": 22, "seek": 10800, "start": 119.12, "end": 123.84, "text": " of the most pervasive causes of incidents and outages across our industry and we need to sustain", "tokens": [295, 264, 881, 680, 39211, 7700, 295, 21139, 293, 484, 1660, 2108, 527, 3518, 293, 321, 643, 281, 6769], "temperature": 0.0, "avg_logprob": -0.12950726559287623, "compression_ratio": 1.723021582733813, "no_speech_prob": 8.231824904214591e-05}, {"id": 23, "seek": 10800, "start": 123.84, "end": 131.04, "text": " an initiative industry-wide in order to fix this. So how does all of this relate to this", "tokens": [364, 11552, 3518, 12, 7990, 294, 1668, 281, 3191, 341, 13, 407, 577, 775, 439, 295, 341, 10961, 281, 341], "temperature": 0.0, "avg_logprob": -0.12950726559287623, "compression_ratio": 1.723021582733813, "no_speech_prob": 8.231824904214591e-05}, {"id": 24, "seek": 10800, "start": 131.04, "end": 136.72, "text": " C-groups thing in the title? So C-groups are a kernel mechanism to balance and control and isolate", "tokens": [383, 12, 17377, 82, 551, 294, 264, 4876, 30, 407, 383, 12, 17377, 82, 366, 257, 28256, 7513, 281, 4772, 293, 1969, 293, 25660], "temperature": 0.0, "avg_logprob": -0.12950726559287623, "compression_ratio": 1.723021582733813, "no_speech_prob": 8.231824904214591e-05}, {"id": 25, "seek": 13672, "start": 136.72, "end": 141.2, "text": " things like memory, CPU, IO, things that you share across a machine, things that processes share", "tokens": [721, 411, 4675, 11, 13199, 11, 39839, 11, 721, 300, 291, 2073, 2108, 257, 3479, 11, 721, 300, 7555, 2073], "temperature": 0.0, "avg_logprob": -0.1046208313533238, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.00010578709770925343}, {"id": 26, "seek": 13672, "start": 141.2, "end": 146.56, "text": " and I'm sure if you've operated containers before, which I'm going to assume that you have, judging", "tokens": [293, 286, 478, 988, 498, 291, 600, 20826, 17089, 949, 11, 597, 286, 478, 516, 281, 6552, 300, 291, 362, 11, 23587], "temperature": 0.0, "avg_logprob": -0.1046208313533238, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.00010578709770925343}, {"id": 27, "seek": 13672, "start": 146.56, "end": 149.52, "text": " by the fact you're in this room otherwise you may be lost in looking for the AI room,", "tokens": [538, 264, 1186, 291, 434, 294, 341, 1808, 5911, 291, 815, 312, 2731, 294, 1237, 337, 264, 7318, 1808, 11], "temperature": 0.0, "avg_logprob": -0.1046208313533238, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.00010578709770925343}, {"id": 28, "seek": 13672, "start": 151.12, "end": 155.68, "text": " you know every single modern container runtime uses this. Stalker uses it, Chorus uses it,", "tokens": [291, 458, 633, 2167, 4363, 10129, 34474, 4960, 341, 13, 745, 667, 260, 4960, 309, 11, 761, 26867, 4960, 309, 11], "temperature": 0.0, "avg_logprob": -0.1046208313533238, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.00010578709770925343}, {"id": 29, "seek": 13672, "start": 155.68, "end": 161.12, "text": " Kubernetes uses it, SystemD uses it. The reason they use it is because it's the most mature platform", "tokens": [23145, 4960, 309, 11, 8910, 35, 4960, 309, 13, 440, 1778, 436, 764, 309, 307, 570, 309, 311, 264, 881, 14442, 3663], "temperature": 0.0, "avg_logprob": -0.1046208313533238, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.00010578709770925343}, {"id": 30, "seek": 13672, "start": 161.12, "end": 164.88, "text": " to do this work and it solves a lot of the long-standing problems which we had with kind of", "tokens": [281, 360, 341, 589, 293, 309, 39890, 257, 688, 295, 264, 938, 12, 8618, 2740, 597, 321, 632, 365, 733, 295], "temperature": 0.0, "avg_logprob": -0.1046208313533238, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.00010578709770925343}, {"id": 31, "seek": 16488, "start": 164.88, "end": 170.4, "text": " classic resource control in the form of view limits and things like that. C-groups have existed", "tokens": [7230, 7684, 1969, 294, 264, 1254, 295, 1910, 10406, 293, 721, 411, 300, 13, 383, 12, 17377, 82, 362, 13135], "temperature": 0.0, "avg_logprob": -0.09356563831197805, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.0001500468497397378}, {"id": 32, "seek": 16488, "start": 170.4, "end": 175.28, "text": " for about 14 years now and they have changed a lot in that time. Most notably, seven years ago", "tokens": [337, 466, 3499, 924, 586, 293, 436, 362, 3105, 257, 688, 294, 300, 565, 13, 4534, 31357, 11, 3407, 924, 2057], "temperature": 0.0, "avg_logprob": -0.09356563831197805, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.0001500468497397378}, {"id": 33, "seek": 16488, "start": 175.28, "end": 181.68, "text": " in kernel 4.5 we released C-group 2. I gave a whole talk around the time when that happened on", "tokens": [294, 28256, 1017, 13, 20, 321, 4736, 383, 12, 17377, 568, 13, 286, 2729, 257, 1379, 751, 926, 264, 565, 562, 300, 2011, 322], "temperature": 0.0, "avg_logprob": -0.09356563831197805, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.0001500468497397378}, {"id": 34, "seek": 16488, "start": 181.68, "end": 185.2, "text": " why we were moving to a totally new interface, why we weren't just iterating on the old interface", "tokens": [983, 321, 645, 2684, 281, 257, 3879, 777, 9226, 11, 983, 321, 4999, 380, 445, 17138, 990, 322, 264, 1331, 9226], "temperature": 0.0, "avg_logprob": -0.09356563831197805, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.0001500468497397378}, {"id": 35, "seek": 16488, "start": 185.2, "end": 189.35999999999999, "text": " and if you're interested in a really in-depth look at that then here's a talk which you can", "tokens": [293, 498, 291, 434, 3102, 294, 257, 534, 294, 12, 25478, 574, 412, 300, 550, 510, 311, 257, 751, 597, 291, 393], "temperature": 0.0, "avg_logprob": -0.09356563831197805, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.0001500468497397378}, {"id": 36, "seek": 16488, "start": 189.35999999999999, "end": 194.24, "text": " go and take a look at. But the most fundamental change really is that in C-group 2 what happens is", "tokens": [352, 293, 747, 257, 574, 412, 13, 583, 264, 881, 8088, 1319, 534, 307, 300, 294, 383, 12, 17377, 568, 437, 2314, 307], "temperature": 0.0, "avg_logprob": -0.09356563831197805, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.0001500468497397378}, {"id": 37, "seek": 19424, "start": 194.24, "end": 201.28, "text": " that you enable or disable resources in the context of a particular C-group. In C-group 1 what you", "tokens": [300, 291, 9528, 420, 28362, 3593, 294, 264, 4319, 295, 257, 1729, 383, 12, 17377, 13, 682, 383, 12, 17377, 502, 437, 291], "temperature": 0.0, "avg_logprob": -0.04850858893276246, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.00025653885677456856}, {"id": 38, "seek": 19424, "start": 201.28, "end": 206.96, "text": " have is a hierarchy for memory, a hierarchy for CPU and the two will never meet. Those two things", "tokens": [362, 307, 257, 22333, 337, 4675, 11, 257, 22333, 337, 13199, 293, 264, 732, 486, 1128, 1677, 13, 3950, 732, 721], "temperature": 0.0, "avg_logprob": -0.04850858893276246, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.00025653885677456856}, {"id": 39, "seek": 19424, "start": 206.96, "end": 212.72, "text": " are completely independent. SystemD when it creates things in C-group V1 it will name them the same", "tokens": [366, 2584, 6695, 13, 8910, 35, 562, 309, 7829, 721, 294, 383, 12, 17377, 691, 16, 309, 486, 1315, 552, 264, 912], "temperature": 0.0, "avg_logprob": -0.04850858893276246, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.00025653885677456856}, {"id": 40, "seek": 19424, "start": 212.72, "end": 217.36, "text": " they get called something.slice or something.service but they have no relation to each other across", "tokens": [436, 483, 1219, 746, 13, 10418, 573, 420, 746, 13, 39279, 457, 436, 362, 572, 9721, 281, 1184, 661, 2108], "temperature": 0.0, "avg_logprob": -0.04850858893276246, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.00025653885677456856}, {"id": 41, "seek": 19424, "start": 217.36, "end": 222.8, "text": " resources. But in C-group 2 you have just a single C-group and you enable or disable resources in", "tokens": [3593, 13, 583, 294, 383, 12, 17377, 568, 291, 362, 445, 257, 2167, 383, 12, 17377, 293, 291, 9528, 420, 28362, 3593, 294], "temperature": 0.0, "avg_logprob": -0.04850858893276246, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.00025653885677456856}, {"id": 42, "seek": 22280, "start": 222.8, "end": 227.12, "text": " the context of that particular C-group so you can enable say memory control and IO control together.", "tokens": [264, 4319, 295, 300, 1729, 383, 12, 17377, 370, 291, 393, 9528, 584, 4675, 1969, 293, 39839, 1969, 1214, 13], "temperature": 0.0, "avg_logprob": -0.10379963590387713, "compression_ratio": 1.6271186440677967, "no_speech_prob": 2.7151574613526464e-05}, {"id": 43, "seek": 22280, "start": 230.32000000000002, "end": 235.60000000000002, "text": " That might seem like you know an aesthetic kind of concern but it's really not. Without this major", "tokens": [663, 1062, 1643, 411, 291, 458, 364, 20092, 733, 295, 3136, 457, 309, 311, 534, 406, 13, 9129, 341, 2563], "temperature": 0.0, "avg_logprob": -0.10379963590387713, "compression_ratio": 1.6271186440677967, "no_speech_prob": 2.7151574613526464e-05}, {"id": 44, "seek": 22280, "start": 235.60000000000002, "end": 240.88000000000002, "text": " API change we simply cannot use C-groups to do complex resource control. Take the following", "tokens": [9362, 1319, 321, 2935, 2644, 764, 383, 12, 17377, 82, 281, 360, 3997, 7684, 1969, 13, 3664, 264, 3480], "temperature": 0.0, "avg_logprob": -0.10379963590387713, "compression_ratio": 1.6271186440677967, "no_speech_prob": 2.7151574613526464e-05}, {"id": 45, "seek": 22280, "start": 240.88000000000002, "end": 246.96, "text": " scenario. Memory starts to run out on your machine. So when we start to run out of memory on a", "tokens": [9005, 13, 38203, 3719, 281, 1190, 484, 322, 428, 3479, 13, 407, 562, 321, 722, 281, 1190, 484, 295, 4675, 322, 257], "temperature": 0.0, "avg_logprob": -0.10379963590387713, "compression_ratio": 1.6271186440677967, "no_speech_prob": 2.7151574613526464e-05}, {"id": 46, "seek": 22280, "start": 246.96, "end": 251.36, "text": " pretty much any modern operating system what do you do? Well you try and go and free some up.", "tokens": [1238, 709, 604, 4363, 7447, 1185, 437, 360, 291, 360, 30, 1042, 291, 853, 293, 352, 293, 1737, 512, 493, 13], "temperature": 0.0, "avg_logprob": -0.10379963590387713, "compression_ratio": 1.6271186440677967, "no_speech_prob": 2.7151574613526464e-05}, {"id": 47, "seek": 25136, "start": 251.36, "end": 256.08000000000004, "text": " So we start to reclaim some page caches. We start to reclaim maybe some anonymous pages if we have", "tokens": [407, 321, 722, 281, 40074, 512, 3028, 269, 13272, 13, 492, 722, 281, 40074, 1310, 512, 24932, 7183, 498, 321, 362], "temperature": 0.0, "avg_logprob": -0.08337665623069829, "compression_ratio": 1.743682310469314, "no_speech_prob": 8.699042518856004e-05}, {"id": 48, "seek": 25136, "start": 256.08000000000004, "end": 263.36, "text": " swap. And this results in disk IO. And if we're particularly memory bound and it's really hard", "tokens": [18135, 13, 400, 341, 3542, 294, 12355, 39839, 13, 400, 498, 321, 434, 4098, 4675, 5472, 293, 309, 311, 534, 1152], "temperature": 0.0, "avg_logprob": -0.08337665623069829, "compression_ratio": 1.743682310469314, "no_speech_prob": 8.699042518856004e-05}, {"id": 49, "seek": 25136, "start": 263.36, "end": 267.92, "text": " to free pages and we're having to walk the pages over and over and over to try and find stuff to", "tokens": [281, 1737, 7183, 293, 321, 434, 1419, 281, 1792, 264, 7183, 670, 293, 670, 293, 670, 281, 853, 293, 915, 1507, 281], "temperature": 0.0, "avg_logprob": -0.08337665623069829, "compression_ratio": 1.743682310469314, "no_speech_prob": 8.699042518856004e-05}, {"id": 50, "seek": 25136, "start": 267.92, "end": 272.56, "text": " free then it's going to cost a non-trivial amount of CPU cycles to do so. Looking through available", "tokens": [1737, 550, 309, 311, 516, 281, 2063, 257, 2107, 12, 83, 470, 22640, 2372, 295, 13199, 17796, 281, 360, 370, 13, 11053, 807, 2435], "temperature": 0.0, "avg_logprob": -0.08337665623069829, "compression_ratio": 1.743682310469314, "no_speech_prob": 8.699042518856004e-05}, {"id": 51, "seek": 25136, "start": 272.56, "end": 277.04, "text": " memory to find pages which can be free can be extremely expensive on memory bound workloads.", "tokens": [4675, 281, 915, 7183, 597, 393, 312, 1737, 393, 312, 4664, 5124, 322, 4675, 5472, 32452, 13], "temperature": 0.0, "avg_logprob": -0.08337665623069829, "compression_ratio": 1.743682310469314, "no_speech_prob": 8.699042518856004e-05}, {"id": 52, "seek": 27704, "start": 277.04, "end": 282.0, "text": " On some highly loaded or memory bound systems it can take you know double digit amount of CPU", "tokens": [1282, 512, 5405, 13210, 420, 4675, 5472, 3652, 309, 393, 747, 291, 458, 3834, 14293, 2372, 295, 13199], "temperature": 0.0, "avg_logprob": -0.18631100848438295, "compression_ratio": 1.6763848396501457, "no_speech_prob": 0.00012062679161317647}, {"id": 53, "seek": 27704, "start": 282.0, "end": 286.56, "text": " from the machine just to do this walking. It's a highly expensive process. And without having", "tokens": [490, 264, 3479, 445, 281, 360, 341, 4494, 13, 467, 311, 257, 5405, 5124, 1399, 13, 400, 1553, 1419], "temperature": 0.0, "avg_logprob": -0.18631100848438295, "compression_ratio": 1.6763848396501457, "no_speech_prob": 0.00012062679161317647}, {"id": 54, "seek": 27704, "start": 286.56, "end": 291.52000000000004, "text": " the single resource hierarchy we cannot take into account these transfers between the different", "tokens": [264, 2167, 7684, 22333, 321, 2644, 747, 666, 2696, 613, 29137, 1296, 264, 819], "temperature": 0.0, "avg_logprob": -0.18631100848438295, "compression_ratio": 1.6763848396501457, "no_speech_prob": 0.00012062679161317647}, {"id": 55, "seek": 27704, "start": 291.52000000000004, "end": 297.52000000000004, "text": " resources how one leads to another because they're all completely independent. If you've been in", "tokens": [3593, 577, 472, 6689, 281, 1071, 570, 436, 434, 439, 2584, 6695, 13, 759, 291, 600, 668, 294], "temperature": 0.0, "avg_logprob": -0.18631100848438295, "compression_ratio": 1.6763848396501457, "no_speech_prob": 0.00012062679161317647}, {"id": 56, "seek": 27704, "start": 297.52000000000004, "end": 300.8, "text": " the containers different before you've probably thinking I've seen this guy before and I think", "tokens": [264, 17089, 819, 949, 291, 600, 1391, 1953, 286, 600, 1612, 341, 2146, 949, 293, 286, 519], "temperature": 0.0, "avg_logprob": -0.18631100848438295, "compression_ratio": 1.6763848396501457, "no_speech_prob": 0.00012062679161317647}, {"id": 57, "seek": 27704, "start": 300.8, "end": 304.88, "text": " he's given this exact talk about three years ago. I'm sure some of you think and that already. Well", "tokens": [415, 311, 2212, 341, 1900, 751, 466, 1045, 924, 2057, 13, 286, 478, 988, 512, 295, 291, 519, 293, 300, 1217, 13, 1042], "temperature": 0.0, "avg_logprob": -0.18631100848438295, "compression_ratio": 1.6763848396501457, "no_speech_prob": 0.00012062679161317647}, {"id": 58, "seek": 30488, "start": 304.88, "end": 310.15999999999997, "text": " the company name isn't the only thing which has changed in 2020. Also some seagrups things have", "tokens": [264, 2237, 1315, 1943, 380, 264, 787, 551, 597, 575, 3105, 294, 4808, 13, 2743, 512, 369, 559, 894, 1878, 721, 362], "temperature": 0.0, "avg_logprob": -0.16223739755564723, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.00023123680148273706}, {"id": 59, "seek": 30488, "start": 310.15999999999997, "end": 313.52, "text": " changed since 2020 and obviously I don't want to rehash the same things over and over. I don't", "tokens": [3105, 1670, 4808, 293, 2745, 286, 500, 380, 528, 281, 22355, 1299, 264, 912, 721, 670, 293, 670, 13, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.16223739755564723, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.00023123680148273706}, {"id": 60, "seek": 30488, "start": 313.52, "end": 317.68, "text": " want to bore you. So this talk will mostly be about the changes since the last time I was here in", "tokens": [528, 281, 26002, 291, 13, 407, 341, 751, 486, 5240, 312, 466, 264, 2962, 1670, 264, 1036, 565, 286, 390, 510, 294], "temperature": 0.0, "avg_logprob": -0.16223739755564723, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.00023123680148273706}, {"id": 61, "seek": 30488, "start": 317.68, "end": 322.48, "text": " 2020 with just a little bit of context setting just a little bit. This talk is really about the", "tokens": [4808, 365, 445, 257, 707, 857, 295, 4319, 3287, 445, 257, 707, 857, 13, 639, 751, 307, 534, 466, 264], "temperature": 0.0, "avg_logprob": -0.16223739755564723, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.00023123680148273706}, {"id": 62, "seek": 30488, "start": 322.48, "end": 328.0, "text": " process of getting resource isolation working at scale. It's what it needs to happen in production", "tokens": [1399, 295, 1242, 7684, 16001, 1364, 412, 4373, 13, 467, 311, 437, 309, 2203, 281, 1051, 294, 4265], "temperature": 0.0, "avg_logprob": -0.16223739755564723, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.00023123680148273706}, {"id": 63, "seek": 32800, "start": 328.0, "end": 336.64, "text": " not just in a theoretical concern. The elephant in the room of course is COVID. The last three years", "tokens": [406, 445, 294, 257, 20864, 3136, 13, 440, 19791, 294, 264, 1808, 295, 1164, 307, 4566, 13, 440, 1036, 1045, 924], "temperature": 0.0, "avg_logprob": -0.10610452191583042, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.00035790569381788373}, {"id": 64, "seek": 32800, "start": 336.64, "end": 342.08, "text": " have seen pretty significant changes in behavior due to COVID especially for a platform like Facebook", "tokens": [362, 1612, 1238, 4776, 2962, 294, 5223, 3462, 281, 4566, 2318, 337, 257, 3663, 411, 4384], "temperature": 0.0, "avg_logprob": -0.10610452191583042, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.00035790569381788373}, {"id": 65, "seek": 32800, "start": 342.08, "end": 347.36, "text": " which we own of course. This was by about 27% over what you would usually expect and this came", "tokens": [597, 321, 1065, 295, 1164, 13, 639, 390, 538, 466, 7634, 4, 670, 437, 291, 576, 2673, 2066, 293, 341, 1361], "temperature": 0.0, "avg_logprob": -0.10610452191583042, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.00035790569381788373}, {"id": 66, "seek": 32800, "start": 347.36, "end": 352.96, "text": " at a time where not only you're seeing increased demand but you literally can't go out and buy", "tokens": [412, 257, 565, 689, 406, 787, 291, 434, 2577, 6505, 4733, 457, 291, 3736, 393, 380, 352, 484, 293, 2256], "temperature": 0.0, "avg_logprob": -0.10610452191583042, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.00035790569381788373}, {"id": 67, "seek": 32800, "start": 352.96, "end": 357.04, "text": " memory. You can't go out and buy more CPUs. You can't go out and buy more disks because there's a", "tokens": [4675, 13, 509, 393, 380, 352, 484, 293, 2256, 544, 13199, 82, 13, 509, 393, 380, 352, 484, 293, 2256, 544, 41617, 570, 456, 311, 257], "temperature": 0.0, "avg_logprob": -0.10610452191583042, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.00035790569381788373}, {"id": 68, "seek": 35704, "start": 357.04, "end": 361.76000000000005, "text": " shortage because there's COVID. So what we really needed was to make more efficient use of the", "tokens": [24708, 570, 456, 311, 4566, 13, 407, 437, 321, 534, 2978, 390, 281, 652, 544, 7148, 764, 295, 264], "temperature": 0.0, "avg_logprob": -0.08065292778916246, "compression_ratio": 1.7104477611940299, "no_speech_prob": 0.0003201185609214008}, {"id": 69, "seek": 35704, "start": 361.76000000000005, "end": 366.64000000000004, "text": " existing resources on the machine right. We need to have an acceleration or existing efforts around", "tokens": [6741, 3593, 322, 264, 3479, 558, 13, 492, 643, 281, 362, 364, 17162, 420, 6741, 6484, 926], "temperature": 0.0, "avg_logprob": -0.08065292778916246, "compression_ratio": 1.7104477611940299, "no_speech_prob": 0.0003201185609214008}, {"id": 70, "seek": 35704, "start": 366.64000000000004, "end": 372.96000000000004, "text": " resource control in order to do that to make things more efficient. Now almost every single time that", "tokens": [7684, 1969, 294, 1668, 281, 360, 300, 281, 652, 721, 544, 7148, 13, 823, 1920, 633, 2167, 565, 300], "temperature": 0.0, "avg_logprob": -0.08065292778916246, "compression_ratio": 1.7104477611940299, "no_speech_prob": 0.0003201185609214008}, {"id": 71, "seek": 35704, "start": 372.96000000000004, "end": 377.36, "text": " I give this sounds like a personal point of concern. Every time I give this talk somebody on", "tokens": [286, 976, 341, 3263, 411, 257, 2973, 935, 295, 3136, 13, 2048, 565, 286, 976, 341, 751, 2618, 322], "temperature": 0.0, "avg_logprob": -0.08065292778916246, "compression_ratio": 1.7104477611940299, "no_speech_prob": 0.0003201185609214008}, {"id": 72, "seek": 35704, "start": 377.36, "end": 382.56, "text": " Hacker News comments why don't you just get some more memory? Now I don't know how trivial people", "tokens": [389, 23599, 7987, 3053, 983, 500, 380, 291, 445, 483, 512, 544, 4675, 30, 823, 286, 500, 380, 458, 577, 26703, 561], "temperature": 0.0, "avg_logprob": -0.08065292778916246, "compression_ratio": 1.7104477611940299, "no_speech_prob": 0.0003201185609214008}, {"id": 73, "seek": 35704, "start": 382.56, "end": 385.84000000000003, "text": " in this room think that is when you've got several million servers but it is slightly", "tokens": [294, 341, 1808, 519, 300, 307, 562, 291, 600, 658, 2940, 2459, 15909, 457, 309, 307, 4748], "temperature": 0.0, "avg_logprob": -0.08065292778916246, "compression_ratio": 1.7104477611940299, "no_speech_prob": 0.0003201185609214008}, {"id": 74, "seek": 38584, "start": 385.84, "end": 390.71999999999997, "text": " difficult sometimes. For example there's a huge amount of cost involved there and not just the", "tokens": [2252, 2171, 13, 1171, 1365, 456, 311, 257, 2603, 2372, 295, 2063, 3288, 456, 293, 406, 445, 264], "temperature": 0.0, "avg_logprob": -0.10162353515625, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.00017349011613987386}, {"id": 75, "seek": 38584, "start": 390.71999999999997, "end": 395.11999999999995, "text": " money which is indeed substantial and I'm very glad it's not coming out of my bank account but", "tokens": [1460, 597, 307, 6451, 16726, 293, 286, 478, 588, 5404, 309, 311, 406, 1348, 484, 295, 452, 3765, 2696, 457], "temperature": 0.0, "avg_logprob": -0.10162353515625, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.00017349011613987386}, {"id": 76, "seek": 38584, "start": 395.11999999999995, "end": 399.76, "text": " also in things like power draw, in things like thermals, in things like hardware design trade-offs.", "tokens": [611, 294, 721, 411, 1347, 2642, 11, 294, 721, 411, 8810, 1124, 11, 294, 721, 411, 8837, 1715, 4923, 12, 19231, 13], "temperature": 0.0, "avg_logprob": -0.10162353515625, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.00017349011613987386}, {"id": 77, "seek": 38584, "start": 399.76, "end": 405.12, "text": " Not to mention during COVID you just couldn't get these kind of, you couldn't get a hard drive,", "tokens": [1726, 281, 2152, 1830, 4566, 291, 445, 2809, 380, 483, 613, 733, 295, 11, 291, 2809, 380, 483, 257, 1152, 3332, 11], "temperature": 0.0, "avg_logprob": -0.10162353515625, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.00017349011613987386}, {"id": 78, "seek": 38584, "start": 405.12, "end": 408.88, "text": " you couldn't get some memory. You'd go down to your local Best Buy and do it but that's about it.", "tokens": [291, 2809, 380, 483, 512, 4675, 13, 509, 1116, 352, 760, 281, 428, 2654, 9752, 19146, 293, 360, 309, 457, 300, 311, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.10162353515625, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.00017349011613987386}, {"id": 79, "seek": 40888, "start": 408.88, "end": 416.15999999999997, "text": " So not really an option. So here's a simple little proposition for you, for anyone in the", "tokens": [407, 406, 534, 364, 3614, 13, 407, 510, 311, 257, 2199, 707, 24830, 337, 291, 11, 337, 2878, 294, 264], "temperature": 0.0, "avg_logprob": -0.19850619633992514, "compression_ratio": 1.377659574468085, "no_speech_prob": 5.2211933507351205e-05}, {"id": 80, "seek": 40888, "start": 416.15999999999997, "end": 420.0, "text": " room who wants to be brave. How do you view memory usage for a process in Linux?", "tokens": [1808, 567, 2738, 281, 312, 12653, 13, 1012, 360, 291, 1910, 4675, 14924, 337, 257, 1399, 294, 18734, 30], "temperature": 0.0, "avg_logprob": -0.19850619633992514, "compression_ratio": 1.377659574468085, "no_speech_prob": 5.2211933507351205e-05}, {"id": 81, "seek": 40888, "start": 422.56, "end": 433.68, "text": " Oh come on. Free! My man said free. Oh lord. This was a trap. So I appreciate it though,", "tokens": [876, 808, 322, 13, 11551, 0, 1222, 587, 848, 1737, 13, 876, 15448, 13, 639, 390, 257, 11487, 13, 407, 286, 4449, 309, 1673, 11], "temperature": 0.0, "avg_logprob": -0.19850619633992514, "compression_ratio": 1.377659574468085, "no_speech_prob": 5.2211933507351205e-05}, {"id": 82, "seek": 43368, "start": 433.68, "end": 439.2, "text": " big up about that. So yeah, so free and the like really only measure like one type of memory.", "tokens": [955, 493, 466, 300, 13, 407, 1338, 11, 370, 1737, 293, 264, 411, 534, 787, 3481, 411, 472, 2010, 295, 4675, 13], "temperature": 0.0, "avg_logprob": -0.14448804381891345, "compression_ratio": 1.8584905660377358, "no_speech_prob": 6.760915130143985e-05}, {"id": 83, "seek": 43368, "start": 439.2, "end": 444.32, "text": " They do have caches and buffers in the side but the thing is okay so for free or for PS which", "tokens": [814, 360, 362, 269, 13272, 293, 9204, 433, 294, 264, 1252, 457, 264, 551, 307, 1392, 370, 337, 1737, 420, 337, 8168, 597], "temperature": 0.0, "avg_logprob": -0.14448804381891345, "compression_ratio": 1.8584905660377358, "no_speech_prob": 6.760915130143985e-05}, {"id": 84, "seek": 43368, "start": 444.32, "end": 449.04, "text": " were shut at the back you know you do see something like the resident set size and you see some other", "tokens": [645, 5309, 412, 264, 646, 291, 458, 291, 360, 536, 746, 411, 264, 10832, 992, 2744, 293, 291, 536, 512, 661], "temperature": 0.0, "avg_logprob": -0.14448804381891345, "compression_ratio": 1.8584905660377358, "no_speech_prob": 6.760915130143985e-05}, {"id": 85, "seek": 43368, "start": 449.04, "end": 453.52, "text": " details and you might be thinking hey you know that's fine like I don't really care about some of", "tokens": [4365, 293, 291, 1062, 312, 1953, 4177, 291, 458, 300, 311, 2489, 411, 286, 500, 380, 534, 1127, 466, 512, 295], "temperature": 0.0, "avg_logprob": -0.14448804381891345, "compression_ratio": 1.8584905660377358, "no_speech_prob": 6.760915130143985e-05}, {"id": 86, "seek": 43368, "start": 453.52, "end": 457.2, "text": " the other things that's the bit which my application is really using. For example we don't necessarily", "tokens": [264, 661, 721, 300, 311, 264, 857, 597, 452, 3861, 307, 534, 1228, 13, 1171, 1365, 321, 500, 380, 4725], "temperature": 0.0, "avg_logprob": -0.14448804381891345, "compression_ratio": 1.8584905660377358, "no_speech_prob": 6.760915130143985e-05}, {"id": 87, "seek": 43368, "start": 457.2, "end": 462.88, "text": " think that our programs rely on caches and buffers to operate in any sustainable way but the problem", "tokens": [519, 300, 527, 4268, 10687, 322, 269, 13272, 293, 9204, 433, 281, 9651, 294, 604, 11235, 636, 457, 264, 1154], "temperature": 0.0, "avg_logprob": -0.14448804381891345, "compression_ratio": 1.8584905660377358, "no_speech_prob": 6.760915130143985e-05}, {"id": 88, "seek": 46288, "start": 462.88, "end": 467.68, "text": " is the answer for any sufficiently complex system is almost certainly that a lot of those caches", "tokens": [307, 264, 1867, 337, 604, 31868, 3997, 1185, 307, 1920, 3297, 300, 257, 688, 295, 729, 269, 13272], "temperature": 0.0, "avg_logprob": -0.10268021369165228, "compression_ratio": 1.721254355400697, "no_speech_prob": 0.00015808692842256278}, {"id": 89, "seek": 46288, "start": 467.68, "end": 473.92, "text": " and buffers are not optional. They are basically essential. Let's take Chrome just as a facile", "tokens": [293, 9204, 433, 366, 406, 17312, 13, 814, 366, 1936, 7115, 13, 961, 311, 747, 15327, 445, 382, 257, 23670], "temperature": 0.0, "avg_logprob": -0.10268021369165228, "compression_ratio": 1.721254355400697, "no_speech_prob": 0.00015808692842256278}, {"id": 90, "seek": 46288, "start": 473.92, "end": 481.04, "text": " example. The Chrome Binary's code segment is over 130 megs. He's a chunky boy. He is. He's a big boy.", "tokens": [1365, 13, 440, 15327, 363, 4066, 311, 3089, 9469, 307, 670, 19966, 10816, 82, 13, 634, 311, 257, 45392, 3237, 13, 634, 307, 13, 634, 311, 257, 955, 3237, 13], "temperature": 0.0, "avg_logprob": -0.10268021369165228, "compression_ratio": 1.721254355400697, "no_speech_prob": 0.00015808692842256278}, {"id": 91, "seek": 46288, "start": 481.04, "end": 485.84, "text": " We load this code into memory. We do it gradually. We're not we're not maniacs. We do it gradually but", "tokens": [492, 3677, 341, 3089, 666, 4675, 13, 492, 360, 309, 13145, 13, 492, 434, 406, 321, 434, 406, 47193, 82, 13, 492, 360, 309, 13145, 457], "temperature": 0.0, "avg_logprob": -0.10268021369165228, "compression_ratio": 1.721254355400697, "no_speech_prob": 0.00015808692842256278}, {"id": 92, "seek": 46288, "start": 485.84, "end": 489.36, "text": " you know we do it as part of the page cache. A boy if you want to execute some particular part of", "tokens": [291, 458, 321, 360, 309, 382, 644, 295, 264, 3028, 19459, 13, 316, 3237, 498, 291, 528, 281, 14483, 512, 1729, 644, 295], "temperature": 0.0, "avg_logprob": -0.10268021369165228, "compression_ratio": 1.721254355400697, "no_speech_prob": 0.00015808692842256278}, {"id": 93, "seek": 48936, "start": 489.36, "end": 495.36, "text": " Chrome you know this cache isn't just nice to have the cache that has the code in it that runs this", "tokens": [15327, 291, 458, 341, 19459, 1943, 380, 445, 1481, 281, 362, 264, 19459, 300, 575, 264, 3089, 294, 309, 300, 6676, 341], "temperature": 0.0, "avg_logprob": -0.08832628924147527, "compression_ratio": 1.9052287581699345, "no_speech_prob": 0.00024614535504952073}, {"id": 94, "seek": 48936, "start": 495.36, "end": 499.12, "text": " particular part of Chrome. We literally cannot make any forward progress without that part of the", "tokens": [1729, 644, 295, 15327, 13, 492, 3736, 2644, 652, 604, 2128, 4205, 1553, 300, 644, 295, 264], "temperature": 0.0, "avg_logprob": -0.08832628924147527, "compression_ratio": 1.9052287581699345, "no_speech_prob": 0.00024614535504952073}, {"id": 95, "seek": 48936, "start": 499.12, "end": 504.0, "text": " cache and the same goes for caches for the files you're loading especially for something like Chrome", "tokens": [19459, 293, 264, 912, 1709, 337, 269, 13272, 337, 264, 7098, 291, 434, 15114, 2318, 337, 746, 411, 15327], "temperature": 0.0, "avg_logprob": -0.08832628924147527, "compression_ratio": 1.9052287581699345, "no_speech_prob": 0.00024614535504952073}, {"id": 96, "seek": 48936, "start": 504.0, "end": 508.0, "text": " you probably do have a lot of caches so eventually those pages are going to have to make their way", "tokens": [291, 1391, 360, 362, 257, 688, 295, 269, 13272, 370, 4728, 729, 7183, 366, 516, 281, 362, 281, 652, 641, 636], "temperature": 0.0, "avg_logprob": -0.08832628924147527, "compression_ratio": 1.9052287581699345, "no_speech_prob": 0.00024614535504952073}, {"id": 97, "seek": 48936, "start": 508.0, "end": 512.5600000000001, "text": " into the working set. They're going to have to make their way into main memory. In another", "tokens": [666, 264, 1364, 992, 13, 814, 434, 516, 281, 362, 281, 652, 641, 636, 666, 2135, 4675, 13, 682, 1071], "temperature": 0.0, "avg_logprob": -0.08832628924147527, "compression_ratio": 1.9052287581699345, "no_speech_prob": 0.00024614535504952073}, {"id": 98, "seek": 48936, "start": 512.5600000000001, "end": 518.32, "text": " particularly egregious case we have a demon at Meta and this demon aggregates metrics across a", "tokens": [4098, 308, 11027, 851, 1389, 321, 362, 257, 14283, 412, 6377, 64, 293, 341, 14283, 16743, 1024, 16367, 2108, 257], "temperature": 0.0, "avg_logprob": -0.08832628924147527, "compression_ratio": 1.9052287581699345, "no_speech_prob": 0.00024614535504952073}, {"id": 99, "seek": 51832, "start": 518.32, "end": 522.72, "text": " machine. It sends them to centralized storage and as part of this what it does is it runs a whole", "tokens": [3479, 13, 467, 14790, 552, 281, 32395, 6725, 293, 382, 644, 295, 341, 437, 309, 775, 307, 309, 6676, 257, 1379], "temperature": 0.0, "avg_logprob": -0.0960109097617013, "compression_ratio": 1.8770764119601329, "no_speech_prob": 0.0002064958680421114}, {"id": 100, "seek": 51832, "start": 522.72, "end": 527.12, "text": " bunch of janky scripts and these janky scripts go and collect things across the machine. I mean", "tokens": [3840, 295, 361, 657, 88, 23294, 293, 613, 361, 657, 88, 23294, 352, 293, 2500, 721, 2108, 264, 3479, 13, 286, 914], "temperature": 0.0, "avg_logprob": -0.0960109097617013, "compression_ratio": 1.8770764119601329, "no_speech_prob": 0.0002064958680421114}, {"id": 101, "seek": 51832, "start": 527.12, "end": 531.2, "text": " we've all got one. We've all got this kind of demon where you collect all kind of janky stuff", "tokens": [321, 600, 439, 658, 472, 13, 492, 600, 439, 658, 341, 733, 295, 14283, 689, 291, 2500, 439, 733, 295, 361, 657, 88, 1507], "temperature": 0.0, "avg_logprob": -0.0960109097617013, "compression_ratio": 1.8770764119601329, "no_speech_prob": 0.0002064958680421114}, {"id": 102, "seek": 51832, "start": 531.2, "end": 535.44, "text": " and you don't really know what it does but it sends some nice metrics and it looks nice and", "tokens": [293, 291, 500, 380, 534, 458, 437, 309, 775, 457, 309, 14790, 512, 1481, 16367, 293, 309, 1542, 1481, 293], "temperature": 0.0, "avg_logprob": -0.0960109097617013, "compression_ratio": 1.8770764119601329, "no_speech_prob": 0.0002064958680421114}, {"id": 103, "seek": 51832, "start": 535.44, "end": 540.48, "text": " one of the things we were able to demonstrate is while the team had this demon thought that it", "tokens": [472, 295, 264, 721, 321, 645, 1075, 281, 11698, 307, 1339, 264, 1469, 632, 341, 14283, 1194, 300, 309], "temperature": 0.0, "avg_logprob": -0.0960109097617013, "compression_ratio": 1.8770764119601329, "no_speech_prob": 0.0002064958680421114}, {"id": 104, "seek": 51832, "start": 540.48, "end": 546.08, "text": " took about 100 to 150 megabytes to run using the things that we'll talk about in this talk", "tokens": [1890, 466, 2319, 281, 8451, 10816, 24538, 281, 1190, 1228, 264, 721, 300, 321, 603, 751, 466, 294, 341, 751], "temperature": 0.0, "avg_logprob": -0.0960109097617013, "compression_ratio": 1.8770764119601329, "no_speech_prob": 0.0002064958680421114}, {"id": 105, "seek": 54608, "start": 546.08, "end": 552.4000000000001, "text": " it actually was more like two gigabytes. So the difference is quite substantial on some things", "tokens": [309, 767, 390, 544, 411, 732, 42741, 13, 407, 264, 2649, 307, 1596, 16726, 322, 512, 721], "temperature": 0.0, "avg_logprob": -0.15928002829863647, "compression_ratio": 1.6797153024911031, "no_speech_prob": 8.458113734377548e-05}, {"id": 106, "seek": 54608, "start": 552.4000000000001, "end": 556.48, "text": " like you could be quite misunderstanding like what is taking memory on your machine.", "tokens": [411, 291, 727, 312, 1596, 29227, 411, 437, 307, 1940, 4675, 322, 428, 3479, 13], "temperature": 0.0, "avg_logprob": -0.15928002829863647, "compression_ratio": 1.6797153024911031, "no_speech_prob": 8.458113734377548e-05}, {"id": 107, "seek": 54608, "start": 558.08, "end": 562.88, "text": " So in C-group 2 we have this file called memory.current that measures the current memory usage for", "tokens": [407, 294, 383, 12, 17377, 568, 321, 362, 341, 3991, 1219, 4675, 13, 49827, 300, 8000, 264, 2190, 4675, 14924, 337], "temperature": 0.0, "avg_logprob": -0.15928002829863647, "compression_ratio": 1.6797153024911031, "no_speech_prob": 8.458113734377548e-05}, {"id": 108, "seek": 54608, "start": 562.88, "end": 567.6800000000001, "text": " the C-group including everything like caches, buffers, kernel objects, so on. So job done right?", "tokens": [264, 383, 12, 17377, 3009, 1203, 411, 269, 13272, 11, 9204, 433, 11, 28256, 6565, 11, 370, 322, 13, 407, 1691, 1096, 558, 30], "temperature": 0.0, "avg_logprob": -0.15928002829863647, "compression_ratio": 1.6797153024911031, "no_speech_prob": 8.458113734377548e-05}, {"id": 109, "seek": 54608, "start": 568.96, "end": 575.84, "text": " Well no the problem is here that whenever somebody comes to these talks and I say something like", "tokens": [1042, 572, 264, 1154, 307, 510, 300, 5699, 2618, 1487, 281, 613, 6686, 293, 286, 584, 746, 411], "temperature": 0.0, "avg_logprob": -0.15928002829863647, "compression_ratio": 1.6797153024911031, "no_speech_prob": 8.458113734377548e-05}, {"id": 110, "seek": 57584, "start": 575.84, "end": 581.12, "text": " don't use RSS to measure your application they go and see oh we've added a new thing called", "tokens": [500, 380, 764, 497, 21929, 281, 3481, 428, 3861, 436, 352, 293, 536, 1954, 321, 600, 3869, 257, 777, 551, 1219], "temperature": 0.0, "avg_logprob": -0.09562811805206595, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.000253425125265494}, {"id": 111, "seek": 57584, "start": 581.12, "end": 586.96, "text": " memory.current and it measures everything great. I'm just gonna put some metrics based on that", "tokens": [4675, 13, 49827, 293, 309, 8000, 1203, 869, 13, 286, 478, 445, 799, 829, 512, 16367, 2361, 322, 300], "temperature": 0.0, "avg_logprob": -0.09562811805206595, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.000253425125265494}, {"id": 112, "seek": 57584, "start": 587.76, "end": 592.1600000000001, "text": " but it's quite important to understand what that actually means to have everything here right.", "tokens": [457, 309, 311, 1596, 1021, 281, 1223, 437, 300, 767, 1355, 281, 362, 1203, 510, 558, 13], "temperature": 0.0, "avg_logprob": -0.09562811805206595, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.000253425125265494}, {"id": 113, "seek": 57584, "start": 592.1600000000001, "end": 596.64, "text": " The very fact that we are not talking about just the resident set size anymore means the", "tokens": [440, 588, 1186, 300, 321, 366, 406, 1417, 466, 445, 264, 10832, 992, 2744, 3602, 1355, 264], "temperature": 0.0, "avg_logprob": -0.09562811805206595, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.000253425125265494}, {"id": 114, "seek": 57584, "start": 596.64, "end": 601.76, "text": " ramifications are fundamentally different. We have caches, buffers, socket memory,", "tokens": [10211, 7833, 366, 17879, 819, 13, 492, 362, 269, 13272, 11, 9204, 433, 11, 19741, 4675, 11], "temperature": 0.0, "avg_logprob": -0.09562811805206595, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.000253425125265494}, {"id": 115, "seek": 60176, "start": 601.76, "end": 606.3199999999999, "text": " TCP memory, kernel objects, all kind of stuff in here and that's exactly how it should be because", "tokens": [48965, 4675, 11, 28256, 6565, 11, 439, 733, 295, 1507, 294, 510, 293, 300, 311, 2293, 577, 309, 820, 312, 570], "temperature": 0.0, "avg_logprob": -0.07598773488458598, "compression_ratio": 1.6517241379310346, "no_speech_prob": 9.391774801770225e-05}, {"id": 116, "seek": 60176, "start": 606.3199999999999, "end": 610.88, "text": " we need that to prevent abuse of these resources which are valid resources across the system.", "tokens": [321, 643, 300, 281, 4871, 9852, 295, 613, 3593, 597, 366, 7363, 3593, 2108, 264, 1185, 13], "temperature": 0.0, "avg_logprob": -0.07598773488458598, "compression_ratio": 1.6517241379310346, "no_speech_prob": 9.391774801770225e-05}, {"id": 117, "seek": 60176, "start": 610.88, "end": 616.8, "text": " They are things we actually need to run. So understanding why reasoning about memory.current", "tokens": [814, 366, 721, 321, 767, 643, 281, 1190, 13, 407, 3701, 983, 21577, 466, 4675, 13, 49827], "temperature": 0.0, "avg_logprob": -0.07598773488458598, "compression_ratio": 1.6517241379310346, "no_speech_prob": 9.391774801770225e-05}, {"id": 118, "seek": 60176, "start": 617.36, "end": 621.76, "text": " might be more complicated than it seems comes down to why as an industry we tended to gravitate", "tokens": [1062, 312, 544, 6179, 813, 309, 2544, 1487, 760, 281, 983, 382, 364, 3518, 321, 34732, 281, 7427, 8086], "temperature": 0.0, "avg_logprob": -0.07598773488458598, "compression_ratio": 1.6517241379310346, "no_speech_prob": 9.391774801770225e-05}, {"id": 119, "seek": 60176, "start": 621.76, "end": 627.76, "text": " towards measuring RSS in the first place. We don't measure RSS because it measures anything useful", "tokens": [3030, 13389, 497, 21929, 294, 264, 700, 1081, 13, 492, 500, 380, 3481, 497, 21929, 570, 309, 8000, 1340, 4420], "temperature": 0.0, "avg_logprob": -0.07598773488458598, "compression_ratio": 1.6517241379310346, "no_speech_prob": 9.391774801770225e-05}, {"id": 120, "seek": 62776, "start": 627.76, "end": 631.92, "text": " we measure it because it's really fucking easy to measure. That's the reason we measure RSS like", "tokens": [321, 3481, 309, 570, 309, 311, 534, 5546, 1858, 281, 3481, 13, 663, 311, 264, 1778, 321, 3481, 497, 21929, 411], "temperature": 0.0, "avg_logprob": -0.07564103512363579, "compression_ratio": 1.920265780730897, "no_speech_prob": 0.0001558714866405353}, {"id": 121, "seek": 62776, "start": 631.92, "end": 636.4, "text": " there's no other reason like it doesn't measure anything very useful. It kind of tells you vaguely", "tokens": [456, 311, 572, 661, 1778, 411, 309, 1177, 380, 3481, 1340, 588, 4420, 13, 467, 733, 295, 5112, 291, 13501, 48863], "temperature": 0.0, "avg_logprob": -0.07564103512363579, "compression_ratio": 1.920265780730897, "no_speech_prob": 0.0001558714866405353}, {"id": 122, "seek": 62776, "start": 636.4, "end": 640.48, "text": " like maybe what your application might be doing kind of but it doesn't tell you anything of any of", "tokens": [411, 1310, 437, 428, 3861, 1062, 312, 884, 733, 295, 457, 309, 1177, 380, 980, 291, 1340, 295, 604, 295], "temperature": 0.0, "avg_logprob": -0.07564103512363579, "compression_ratio": 1.920265780730897, "no_speech_prob": 0.0001558714866405353}, {"id": 123, "seek": 62776, "start": 640.48, "end": 644.56, "text": " the actually like interesting parts of your application only the bits you pretty much already", "tokens": [264, 767, 411, 1880, 3166, 295, 428, 3861, 787, 264, 9239, 291, 1238, 709, 1217], "temperature": 0.0, "avg_logprob": -0.07564103512363579, "compression_ratio": 1.920265780730897, "no_speech_prob": 0.0001558714866405353}, {"id": 124, "seek": 62776, "start": 644.56, "end": 650.8, "text": " knew. So memory.current suffers from pretty much exactly the opposite problem which is it tells", "tokens": [2586, 13, 407, 4675, 13, 49827, 33776, 490, 1238, 709, 2293, 264, 6182, 1154, 597, 307, 309, 5112], "temperature": 0.0, "avg_logprob": -0.07564103512363579, "compression_ratio": 1.920265780730897, "no_speech_prob": 0.0001558714866405353}, {"id": 125, "seek": 62776, "start": 650.8, "end": 656.16, "text": " you the truth and don't really know how to deal with that. Don't really know how to deal with", "tokens": [291, 264, 3494, 293, 500, 380, 534, 458, 577, 281, 2028, 365, 300, 13, 1468, 380, 534, 458, 577, 281, 2028, 365], "temperature": 0.0, "avg_logprob": -0.07564103512363579, "compression_ratio": 1.920265780730897, "no_speech_prob": 0.0001558714866405353}, {"id": 126, "seek": 65616, "start": 656.16, "end": 661.1999999999999, "text": " being told how much memory application is using. For example if you set an 8 gigabyte memory limit", "tokens": [885, 1907, 577, 709, 4675, 3861, 307, 1228, 13, 1171, 1365, 498, 291, 992, 364, 1649, 8741, 34529, 4675, 4948], "temperature": 0.0, "avg_logprob": -0.14291243001717288, "compression_ratio": 1.887459807073955, "no_speech_prob": 0.00013230202603153884}, {"id": 127, "seek": 65616, "start": 661.1999999999999, "end": 666.9599999999999, "text": " in C root v2 how big is memory.current going to be on a machine which has no other thing running on", "tokens": [294, 383, 5593, 371, 17, 577, 955, 307, 4675, 13, 49827, 516, 281, 312, 322, 257, 3479, 597, 575, 572, 661, 551, 2614, 322], "temperature": 0.0, "avg_logprob": -0.14291243001717288, "compression_ratio": 1.887459807073955, "no_speech_prob": 0.00013230202603153884}, {"id": 128, "seek": 65616, "start": 666.9599999999999, "end": 671.4399999999999, "text": " it. It's probably going to be 8 gigabytes because we've decided that we're going to fill it with", "tokens": [309, 13, 467, 311, 1391, 516, 281, 312, 1649, 42741, 570, 321, 600, 3047, 300, 321, 434, 516, 281, 2836, 309, 365], "temperature": 0.0, "avg_logprob": -0.14291243001717288, "compression_ratio": 1.887459807073955, "no_speech_prob": 0.00013230202603153884}, {"id": 129, "seek": 65616, "start": 671.4399999999999, "end": 675.52, "text": " all kind of nice stuff. There's no reason we should evict that. There's no reason we should take away", "tokens": [439, 733, 295, 1481, 1507, 13, 821, 311, 572, 1778, 321, 820, 1073, 985, 300, 13, 821, 311, 572, 1778, 321, 820, 747, 1314], "temperature": 0.0, "avg_logprob": -0.14291243001717288, "compression_ratio": 1.887459807073955, "no_speech_prob": 0.00013230202603153884}, {"id": 130, "seek": 65616, "start": 675.52, "end": 679.04, "text": " these nice you know K mem caches. There's no reason we should take away these slots because", "tokens": [613, 1481, 291, 458, 591, 1334, 269, 13272, 13, 821, 311, 572, 1778, 321, 820, 747, 1314, 613, 24266, 570], "temperature": 0.0, "avg_logprob": -0.14291243001717288, "compression_ratio": 1.887459807073955, "no_speech_prob": 0.00013230202603153884}, {"id": 131, "seek": 65616, "start": 679.6, "end": 685.12, "text": " we have free memory so why not. Why not keep them around. So if there was no pressure for this to", "tokens": [321, 362, 1737, 4675, 370, 983, 406, 13, 1545, 406, 1066, 552, 926, 13, 407, 498, 456, 390, 572, 3321, 337, 341, 281], "temperature": 0.0, "avg_logprob": -0.14291243001717288, "compression_ratio": 1.887459807073955, "no_speech_prob": 0.00013230202603153884}, {"id": 132, "seek": 68512, "start": 685.12, "end": 690.0, "text": " shrink from any outside scope then the slack is just going to expand until it reaches your limit.", "tokens": [23060, 490, 604, 2380, 11923, 550, 264, 29767, 307, 445, 516, 281, 5268, 1826, 309, 14235, 428, 4948, 13], "temperature": 0.0, "avg_logprob": -0.07408340706312952, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00012308855366427451}, {"id": 133, "seek": 68512, "start": 690.0, "end": 694.72, "text": " So what should we do? How should we know what the real needed amount of memory is at a given time?", "tokens": [407, 437, 820, 321, 360, 30, 1012, 820, 321, 458, 437, 264, 957, 2978, 2372, 295, 4675, 307, 412, 257, 2212, 565, 30], "temperature": 0.0, "avg_logprob": -0.07408340706312952, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00012308855366427451}, {"id": 134, "seek": 68512, "start": 696.24, "end": 701.84, "text": " So let's take an example Linux kernel build for example which with no limits has a peak memory.current", "tokens": [407, 718, 311, 747, 364, 1365, 18734, 28256, 1322, 337, 1365, 597, 365, 572, 10406, 575, 257, 10651, 4675, 13, 49827], "temperature": 0.0, "avg_logprob": -0.07408340706312952, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00012308855366427451}, {"id": 135, "seek": 68512, "start": 701.84, "end": 707.52, "text": " of just over 800 megabytes. In C root v2 we have this tunable called memory.high. This tunable", "tokens": [295, 445, 670, 13083, 10816, 24538, 13, 682, 383, 5593, 371, 17, 321, 362, 341, 4267, 712, 1219, 4675, 13, 21454, 13, 639, 4267, 712], "temperature": 0.0, "avg_logprob": -0.07408340706312952, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00012308855366427451}, {"id": 136, "seek": 68512, "start": 707.52, "end": 712.64, "text": " reclaims memory from the C group until it goes back under some threshold. It just keeps on reclaiming", "tokens": [40074, 82, 4675, 490, 264, 383, 1594, 1826, 309, 1709, 646, 833, 512, 14678, 13, 467, 445, 5965, 322, 40074, 278], "temperature": 0.0, "avg_logprob": -0.07408340706312952, "compression_ratio": 1.636963696369637, "no_speech_prob": 0.00012308855366427451}, {"id": 137, "seek": 71264, "start": 712.64, "end": 717.68, "text": " and reclaiming and reclaiming and throttling until you reach back under. So right now things take", "tokens": [293, 40074, 278, 293, 40074, 278, 293, 739, 1521, 1688, 1826, 291, 2524, 646, 833, 13, 407, 558, 586, 721, 747], "temperature": 0.0, "avg_logprob": -0.07049585246353698, "compression_ratio": 1.8140243902439024, "no_speech_prob": 0.00024093917454592884}, {"id": 138, "seek": 71264, "start": 717.68, "end": 722.48, "text": " about four minutes with no limits. This is about how long it takes to build the kernel and when I", "tokens": [466, 1451, 2077, 365, 572, 10406, 13, 639, 307, 466, 577, 938, 309, 2516, 281, 1322, 264, 28256, 293, 562, 286], "temperature": 0.0, "avg_logprob": -0.07049585246353698, "compression_ratio": 1.8140243902439024, "no_speech_prob": 0.00024093917454592884}, {"id": 139, "seek": 71264, "start": 722.48, "end": 728.24, "text": " apply you know a throttling like a like a reclaim threshold of 600 megabytes actually you know the", "tokens": [3079, 291, 458, 257, 739, 1521, 1688, 411, 257, 411, 257, 40074, 14678, 295, 11849, 10816, 24538, 767, 291, 458, 264], "temperature": 0.0, "avg_logprob": -0.07049585246353698, "compression_ratio": 1.8140243902439024, "no_speech_prob": 0.00024093917454592884}, {"id": 140, "seek": 71264, "start": 728.24, "end": 732.72, "text": " job finishes roughly about the same amount of time maybe a second more with about 25 percent less", "tokens": [1691, 23615, 9810, 466, 264, 912, 2372, 295, 565, 1310, 257, 1150, 544, 365, 466, 3552, 3043, 1570], "temperature": 0.0, "avg_logprob": -0.07049585246353698, "compression_ratio": 1.8140243902439024, "no_speech_prob": 0.00024093917454592884}, {"id": 141, "seek": 71264, "start": 732.72, "end": 737.28, "text": " available memory at peak and the same even happens when we go down to 400 megabytes. Now we're using", "tokens": [2435, 4675, 412, 10651, 293, 264, 912, 754, 2314, 562, 321, 352, 760, 281, 8423, 10816, 24538, 13, 823, 321, 434, 1228], "temperature": 0.0, "avg_logprob": -0.07049585246353698, "compression_ratio": 1.8140243902439024, "no_speech_prob": 0.00024093917454592884}, {"id": 142, "seek": 71264, "start": 737.28, "end": 741.52, "text": " half the memory that we originally used with only a few seconds more wall time. It's it's pretty good", "tokens": [1922, 264, 4675, 300, 321, 7993, 1143, 365, 787, 257, 1326, 3949, 544, 2929, 565, 13, 467, 311, 309, 311, 1238, 665], "temperature": 0.0, "avg_logprob": -0.07049585246353698, "compression_ratio": 1.8140243902439024, "no_speech_prob": 0.00024093917454592884}, {"id": 143, "seek": 74152, "start": 741.52, "end": 746.72, "text": " trade-off. However if we just go just a little bit further then things just never even complete. We", "tokens": [4923, 12, 4506, 13, 2908, 498, 321, 445, 352, 445, 257, 707, 857, 3052, 550, 721, 445, 1128, 754, 3566, 13, 492], "temperature": 0.0, "avg_logprob": -0.07314270421078331, "compression_ratio": 1.6490066225165563, "no_speech_prob": 5.48349526070524e-05}, {"id": 144, "seek": 74152, "start": 746.72, "end": 751.4399999999999, "text": " have to we have to control see the build right and this is nine minutes in it's still ain't done. So", "tokens": [362, 281, 321, 362, 281, 1969, 536, 264, 1322, 558, 293, 341, 307, 4949, 2077, 294, 309, 311, 920, 7862, 380, 1096, 13, 407], "temperature": 0.0, "avg_logprob": -0.07314270421078331, "compression_ratio": 1.6490066225165563, "no_speech_prob": 5.48349526070524e-05}, {"id": 145, "seek": 74152, "start": 751.4399999999999, "end": 757.28, "text": " we know that the process needs somewhere between 300 and 400 megabytes of memory but it's pretty", "tokens": [321, 458, 300, 264, 1399, 2203, 4079, 1296, 6641, 293, 8423, 10816, 24538, 295, 4675, 457, 309, 311, 1238], "temperature": 0.0, "avg_logprob": -0.07314270421078331, "compression_ratio": 1.6490066225165563, "no_speech_prob": 5.48349526070524e-05}, {"id": 146, "seek": 74152, "start": 757.28, "end": 762.24, "text": " error prone to try and work out what the exact value is. So to get an accurate number for services", "tokens": [6713, 25806, 281, 853, 293, 589, 484, 437, 264, 1900, 2158, 307, 13, 407, 281, 483, 364, 8559, 1230, 337, 3328], "temperature": 0.0, "avg_logprob": -0.07314270421078331, "compression_ratio": 1.6490066225165563, "no_speech_prob": 5.48349526070524e-05}, {"id": 147, "seek": 74152, "start": 762.24, "end": 766.4, "text": " at scale which are even more difficult than this because they dynamically shrink and expand depending", "tokens": [412, 4373, 597, 366, 754, 544, 2252, 813, 341, 570, 436, 43492, 23060, 293, 5268, 5413], "temperature": 0.0, "avg_logprob": -0.07314270421078331, "compression_ratio": 1.6490066225165563, "no_speech_prob": 5.48349526070524e-05}, {"id": 148, "seek": 76640, "start": 766.4, "end": 773.52, "text": " on load we need a better automated way to do that. So determining the exact amount of memory", "tokens": [322, 3677, 321, 643, 257, 1101, 18473, 636, 281, 360, 300, 13, 407, 23751, 264, 1900, 2372, 295, 4675], "temperature": 0.0, "avg_logprob": -0.1416443378553478, "compression_ratio": 1.6206896551724137, "no_speech_prob": 3.69705849152524e-05}, {"id": 149, "seek": 76640, "start": 773.52, "end": 778.9599999999999, "text": " required by an application is a really really difficult and error prone task right. So SEMPAI is", "tokens": [4739, 538, 364, 3861, 307, 257, 534, 534, 2252, 293, 6713, 25806, 5633, 558, 13, 407, 318, 6683, 10297, 40, 307], "temperature": 0.0, "avg_logprob": -0.1416443378553478, "compression_ratio": 1.6206896551724137, "no_speech_prob": 3.69705849152524e-05}, {"id": 150, "seek": 76640, "start": 778.9599999999999, "end": 784.64, "text": " this kind of simple self-contained tool to continually poll what's called pressure stall", "tokens": [341, 733, 295, 2199, 2698, 12, 9000, 3563, 2290, 281, 22277, 6418, 437, 311, 1219, 3321, 19633], "temperature": 0.0, "avg_logprob": -0.1416443378553478, "compression_ratio": 1.6206896551724137, "no_speech_prob": 3.69705849152524e-05}, {"id": 151, "seek": 76640, "start": 784.64, "end": 790.16, "text": " information or PSI. Pressure stall information is essentially a new thing we've added in CIGRI2", "tokens": [1589, 420, 8168, 40, 13, 6776, 540, 19633, 1589, 307, 4476, 257, 777, 551, 321, 600, 3869, 294, 383, 10489, 5577, 17], "temperature": 0.0, "avg_logprob": -0.1416443378553478, "compression_ratio": 1.6206896551724137, "no_speech_prob": 3.69705849152524e-05}, {"id": 152, "seek": 76640, "start": 790.16, "end": 794.3199999999999, "text": " to determine whether a particular resource is oversaturated and we've never really had a metric", "tokens": [281, 6997, 1968, 257, 1729, 7684, 307, 15488, 19493, 770, 293, 321, 600, 1128, 534, 632, 257, 20678], "temperature": 0.0, "avg_logprob": -0.1416443378553478, "compression_ratio": 1.6206896551724137, "no_speech_prob": 3.69705849152524e-05}, {"id": 153, "seek": 79432, "start": 794.32, "end": 800.0, "text": " like this in in the Linux kernel before. We've had many related metrics for example for memory we", "tokens": [411, 341, 294, 294, 264, 18734, 28256, 949, 13, 492, 600, 632, 867, 4077, 16367, 337, 1365, 337, 4675, 321], "temperature": 0.0, "avg_logprob": -0.1094654735765959, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.00011100320989498869}, {"id": 154, "seek": 79432, "start": 800.0, "end": 805.6, "text": " have things like you know page caches and buffer usage and so on but we don't really know how to", "tokens": [362, 721, 411, 291, 458, 3028, 269, 13272, 293, 21762, 14924, 293, 370, 322, 457, 321, 500, 380, 534, 458, 577, 281], "temperature": 0.0, "avg_logprob": -0.1094654735765959, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.00011100320989498869}, {"id": 155, "seek": 79432, "start": 805.6, "end": 811.2, "text": " tell pressure or over subscription from an efficient use of the system those two are very", "tokens": [980, 3321, 420, 670, 17231, 490, 364, 7148, 764, 295, 264, 1185, 729, 732, 366, 588], "temperature": 0.0, "avg_logprob": -0.1094654735765959, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.00011100320989498869}, {"id": 156, "seek": 79432, "start": 811.2, "end": 816.32, "text": " difficult to tell apart even with using things like page scans or or so on it's pretty difficult.", "tokens": [2252, 281, 980, 4936, 754, 365, 1228, 721, 411, 3028, 35116, 420, 420, 370, 322, 309, 311, 1238, 2252, 13], "temperature": 0.0, "avg_logprob": -0.1094654735765959, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.00011100320989498869}, {"id": 157, "seek": 79432, "start": 817.36, "end": 823.2, "text": " So in SEMPAI what we do is we use these PSI pressure stall metrics to measure the amount of time", "tokens": [407, 294, 318, 6683, 10297, 40, 437, 321, 360, 307, 321, 764, 613, 8168, 40, 3321, 19633, 16367, 281, 3481, 264, 2372, 295, 565], "temperature": 0.0, "avg_logprob": -0.1094654735765959, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.00011100320989498869}, {"id": 158, "seek": 82320, "start": 823.2, "end": 828.1600000000001, "text": " which threads in a particular C group were stuck doing in this case memory work. So this pressure", "tokens": [597, 19314, 294, 257, 1729, 383, 1594, 645, 5541, 884, 294, 341, 1389, 4675, 589, 13, 407, 341, 3321], "temperature": 0.0, "avg_logprob": -0.11466243772795706, "compression_ratio": 1.86084142394822, "no_speech_prob": 9.09518712433055e-05}, {"id": 159, "seek": 82320, "start": 828.1600000000001, "end": 834.48, "text": " equals 0.16 thing kind of halfway down the slide means that you know 0.16 percent of the time I", "tokens": [6915, 1958, 13, 6866, 551, 733, 295, 15461, 760, 264, 4137, 1355, 300, 291, 458, 1958, 13, 6866, 3043, 295, 264, 565, 286], "temperature": 0.0, "avg_logprob": -0.11466243772795706, "compression_ratio": 1.86084142394822, "no_speech_prob": 9.09518712433055e-05}, {"id": 160, "seek": 82320, "start": 834.48, "end": 839.76, "text": " could have been doing more productive work but I've been stuck doing memory work. This could be", "tokens": [727, 362, 668, 884, 544, 13304, 589, 457, 286, 600, 668, 5541, 884, 4675, 589, 13, 639, 727, 312], "temperature": 0.0, "avg_logprob": -0.11466243772795706, "compression_ratio": 1.86084142394822, "no_speech_prob": 9.09518712433055e-05}, {"id": 161, "seek": 82320, "start": 839.76, "end": 843.2, "text": " things like you know waiting for a kernel memory lock it could be things like being throttled", "tokens": [721, 411, 291, 458, 3806, 337, 257, 28256, 4675, 4017, 309, 727, 312, 721, 411, 885, 739, 1521, 1493], "temperature": 0.0, "avg_logprob": -0.11466243772795706, "compression_ratio": 1.86084142394822, "no_speech_prob": 9.09518712433055e-05}, {"id": 162, "seek": 82320, "start": 843.2, "end": 847.84, "text": " could be waiting for reclaimed to finish even more than that it could be memory related IO which", "tokens": [727, 312, 3806, 337, 850, 22642, 281, 2413, 754, 544, 813, 300, 309, 727, 312, 4675, 4077, 39839, 597], "temperature": 0.0, "avg_logprob": -0.11466243772795706, "compression_ratio": 1.86084142394822, "no_speech_prob": 9.09518712433055e-05}, {"id": 163, "seek": 82320, "start": 847.84, "end": 852.4000000000001, "text": " which can also dominate to be honest things like refolding file content into the page cache or", "tokens": [597, 393, 611, 28246, 281, 312, 3245, 721, 411, 1895, 2641, 278, 3991, 2701, 666, 264, 3028, 19459, 420], "temperature": 0.0, "avg_logprob": -0.11466243772795706, "compression_ratio": 1.86084142394822, "no_speech_prob": 9.09518712433055e-05}, {"id": 164, "seek": 85240, "start": 852.4, "end": 858.48, "text": " swapping in and pressure is essentially saying you know if I had a bit more memory I would be able", "tokens": [1693, 10534, 294, 293, 3321, 307, 4476, 1566, 291, 458, 498, 286, 632, 257, 857, 544, 4675, 286, 576, 312, 1075], "temperature": 0.0, "avg_logprob": -0.08518057736483488, "compression_ratio": 1.6228373702422145, "no_speech_prob": 5.082783900434151e-05}, {"id": 165, "seek": 85240, "start": 858.48, "end": 866.48, "text": " to run so much faster 0.16 percent faster. So using PSI and memory.high what SEMPAI does is", "tokens": [281, 1190, 370, 709, 4663, 1958, 13, 6866, 3043, 4663, 13, 407, 1228, 8168, 40, 293, 4675, 13, 21454, 437, 318, 6683, 10297, 40, 775, 307], "temperature": 0.0, "avg_logprob": -0.08518057736483488, "compression_ratio": 1.6228373702422145, "no_speech_prob": 5.082783900434151e-05}, {"id": 166, "seek": 85240, "start": 866.48, "end": 871.6, "text": " adjust just enough memory pressure on a C group to evict cold memory pages that aren't essential", "tokens": [4369, 445, 1547, 4675, 3321, 322, 257, 383, 1594, 281, 1073, 985, 3554, 4675, 7183, 300, 3212, 380, 7115], "temperature": 0.0, "avg_logprob": -0.08518057736483488, "compression_ratio": 1.6228373702422145, "no_speech_prob": 5.082783900434151e-05}, {"id": 167, "seek": 85240, "start": 871.6, "end": 875.84, "text": " for workload performance. It's an integral controller which dynamically adapts to these", "tokens": [337, 20139, 3389, 13, 467, 311, 364, 11573, 10561, 597, 43492, 23169, 1373, 281, 613], "temperature": 0.0, "avg_logprob": -0.08518057736483488, "compression_ratio": 1.6228373702422145, "no_speech_prob": 5.082783900434151e-05}, {"id": 168, "seek": 85240, "start": 875.84, "end": 879.92, "text": " memory peaks and troughs an example case being something like a web server which is somewhere", "tokens": [4675, 26897, 293, 504, 34445, 364, 1365, 1389, 885, 746, 411, 257, 3670, 7154, 597, 307, 4079], "temperature": 0.0, "avg_logprob": -0.08518057736483488, "compression_ratio": 1.6228373702422145, "no_speech_prob": 5.082783900434151e-05}, {"id": 169, "seek": 87992, "start": 879.92, "end": 884.16, "text": " where we have used it when more requests come we see that the pressure is growing and we expand", "tokens": [689, 321, 362, 1143, 309, 562, 544, 12475, 808, 321, 536, 300, 264, 3321, 307, 4194, 293, 321, 5268], "temperature": 0.0, "avg_logprob": -0.06617238304831764, "compression_ratio": 1.8259493670886076, "no_speech_prob": 4.979080767952837e-05}, {"id": 170, "seek": 87992, "start": 884.16, "end": 889.52, "text": " the memory.high limit when fewer requests are coming we we see that and we start to decrease", "tokens": [264, 4675, 13, 21454, 4948, 562, 13366, 12475, 366, 1348, 321, 321, 536, 300, 293, 321, 722, 281, 11514], "temperature": 0.0, "avg_logprob": -0.06617238304831764, "compression_ratio": 1.8259493670886076, "no_speech_prob": 4.979080767952837e-05}, {"id": 171, "seek": 87992, "start": 889.52, "end": 893.52, "text": " the amount of working set which we give again so it can be used to answer the question you know", "tokens": [264, 2372, 295, 1364, 992, 597, 321, 976, 797, 370, 309, 393, 312, 1143, 281, 1867, 264, 1168, 291, 458], "temperature": 0.0, "avg_logprob": -0.06617238304831764, "compression_ratio": 1.8259493670886076, "no_speech_prob": 4.979080767952837e-05}, {"id": 172, "seek": 87992, "start": 893.52, "end": 897.8399999999999, "text": " how much memory does my application actually use over time and in this case we find for the", "tokens": [577, 709, 4675, 775, 452, 3861, 767, 764, 670, 565, 293, 294, 341, 1389, 321, 915, 337, 264], "temperature": 0.0, "avg_logprob": -0.06617238304831764, "compression_ratio": 1.8259493670886076, "no_speech_prob": 4.979080767952837e-05}, {"id": 173, "seek": 87992, "start": 897.8399999999999, "end": 903.76, "text": " compile job the answer is about like 340 megabytes or so and that's fine you might be asking yourself", "tokens": [31413, 1691, 264, 1867, 307, 466, 411, 805, 5254, 10816, 24538, 420, 370, 293, 300, 311, 2489, 291, 1062, 312, 3365, 1803], "temperature": 0.0, "avg_logprob": -0.06617238304831764, "compression_ratio": 1.8259493670886076, "no_speech_prob": 4.979080767952837e-05}, {"id": 174, "seek": 87992, "start": 903.76, "end": 907.28, "text": " what's the what are the benefits of this shrinking like why why does this even matter to be honest", "tokens": [437, 311, 264, 437, 366, 264, 5311, 295, 341, 41684, 411, 983, 983, 775, 341, 754, 1871, 281, 312, 3245], "temperature": 0.0, "avg_logprob": -0.06617238304831764, "compression_ratio": 1.8259493670886076, "no_speech_prob": 4.979080767952837e-05}, {"id": 175, "seek": 90728, "start": 907.28, "end": 911.12, "text": " surely like when you're starting to run out of memory Linux is going to do it anyway and you're", "tokens": [11468, 411, 562, 291, 434, 2891, 281, 1190, 484, 295, 4675, 18734, 307, 516, 281, 360, 309, 4033, 293, 291, 434], "temperature": 0.0, "avg_logprob": -0.06912491464207315, "compression_ratio": 1.8257575757575757, "no_speech_prob": 5.253598283161409e-05}, {"id": 176, "seek": 90728, "start": 911.12, "end": 918.0799999999999, "text": " not wrong like that's true but the thing is what we kind of need here is to get ahead of memory", "tokens": [406, 2085, 411, 300, 311, 2074, 457, 264, 551, 307, 437, 321, 733, 295, 643, 510, 307, 281, 483, 2286, 295, 4675], "temperature": 0.0, "avg_logprob": -0.06912491464207315, "compression_ratio": 1.8257575757575757, "no_speech_prob": 5.253598283161409e-05}, {"id": 177, "seek": 90728, "start": 918.0799999999999, "end": 923.76, "text": " shortages which which could be bad and amortize the work ahead of time when your machine is already", "tokens": [46765, 597, 597, 727, 312, 1578, 293, 669, 477, 1125, 264, 589, 2286, 295, 565, 562, 428, 3479, 307, 1217], "temperature": 0.0, "avg_logprob": -0.06912491464207315, "compression_ratio": 1.8257575757575757, "no_speech_prob": 5.253598283161409e-05}, {"id": 178, "seek": 90728, "start": 923.76, "end": 927.92, "text": " highly contended it's already being driven into the ground and going towards the umkiller it's", "tokens": [5405, 660, 3502, 309, 311, 1217, 885, 9555, 666, 264, 2727, 293, 516, 3030, 264, 1105, 74, 10497, 309, 311], "temperature": 0.0, "avg_logprob": -0.06912491464207315, "compression_ratio": 1.8257575757575757, "no_speech_prob": 5.253598283161409e-05}, {"id": 179, "seek": 90728, "start": 927.92, "end": 933.1999999999999, "text": " pretty hard to say hey bro could you just like like give me some pages right now like it's it's", "tokens": [1238, 1152, 281, 584, 4177, 2006, 727, 291, 445, 411, 411, 976, 385, 512, 7183, 558, 586, 411, 309, 311, 309, 311], "temperature": 0.0, "avg_logprob": -0.06912491464207315, "compression_ratio": 1.8257575757575757, "no_speech_prob": 5.253598283161409e-05}, {"id": 180, "seek": 93320, "start": 933.2, "end": 937.76, "text": " not exactly like what what's on its mind it's probably desperately trying to keep the atomic", "tokens": [406, 2293, 411, 437, 437, 311, 322, 1080, 1575, 309, 311, 1391, 23726, 1382, 281, 1066, 264, 22275], "temperature": 0.0, "avg_logprob": -0.05900281804208537, "compression_ratio": 1.8469055374592833, "no_speech_prob": 4.497161353356205e-05}, {"id": 181, "seek": 93320, "start": 937.76, "end": 941.6800000000001, "text": " pool going so there's there's another thing as well which is you know it's pretty good for", "tokens": [7005, 516, 370, 456, 311, 456, 311, 1071, 551, 382, 731, 597, 307, 291, 458, 309, 311, 1238, 665, 337], "temperature": 0.0, "avg_logprob": -0.05900281804208537, "compression_ratio": 1.8469055374592833, "no_speech_prob": 4.497161353356205e-05}, {"id": 182, "seek": 93320, "start": 941.6800000000001, "end": 948.24, "text": " determining regressions which is what a lot of people use for rss for right like we this is the", "tokens": [23751, 1121, 735, 626, 597, 307, 437, 257, 688, 295, 561, 764, 337, 367, 3810, 337, 558, 411, 321, 341, 307, 264], "temperature": 0.0, "avg_logprob": -0.05900281804208537, "compression_ratio": 1.8469055374592833, "no_speech_prob": 4.497161353356205e-05}, {"id": 183, "seek": 93320, "start": 948.24, "end": 954.08, "text": " way we found out that that demon was using two gigabytes of memory instead of 150 megabytes", "tokens": [636, 321, 1352, 484, 300, 300, 14283, 390, 1228, 732, 42741, 295, 4675, 2602, 295, 8451, 10816, 24538], "temperature": 0.0, "avg_logprob": -0.05900281804208537, "compression_ratio": 1.8469055374592833, "no_speech_prob": 4.497161353356205e-05}, {"id": 184, "seek": 93320, "start": 954.08, "end": 958.88, "text": " of memory so it's pretty good for finding out hey how much does my application actually need to run", "tokens": [295, 4675, 370, 309, 311, 1238, 665, 337, 5006, 484, 4177, 577, 709, 775, 452, 3861, 767, 643, 281, 1190], "temperature": 0.0, "avg_logprob": -0.05900281804208537, "compression_ratio": 1.8469055374592833, "no_speech_prob": 4.497161353356205e-05}, {"id": 185, "seek": 93320, "start": 958.88, "end": 962.4000000000001, "text": " so the combination of these things means that senpai is an essential part of how we do workload", "tokens": [370, 264, 6562, 295, 613, 721, 1355, 300, 3151, 43502, 307, 364, 7115, 644, 295, 577, 321, 360, 20139], "temperature": 0.0, "avg_logprob": -0.05900281804208537, "compression_ratio": 1.8469055374592833, "no_speech_prob": 4.497161353356205e-05}, {"id": 186, "seek": 96240, "start": 962.4, "end": 966.72, "text": " stacking of matter and it not only gives us an accurate read on what the demand is right now", "tokens": [41376, 295, 1871, 293, 309, 406, 787, 2709, 505, 364, 8559, 1401, 322, 437, 264, 4733, 307, 558, 586], "temperature": 0.0, "avg_logprob": -0.053521034146143384, "compression_ratio": 1.86, "no_speech_prob": 0.0001475895696785301}, {"id": 187, "seek": 96240, "start": 966.72, "end": 973.1999999999999, "text": " but allows us to adjust stacking expectations depending on what the workload is doing this", "tokens": [457, 4045, 505, 281, 4369, 41376, 9843, 5413, 322, 437, 264, 20139, 307, 884, 341], "temperature": 0.0, "avg_logprob": -0.053521034146143384, "compression_ratio": 1.86, "no_speech_prob": 0.0001475895696785301}, {"id": 188, "seek": 96240, "start": 973.1999999999999, "end": 976.4, "text": " feeds into another one of our efforts around efficiency which is improving memory offloading", "tokens": [23712, 666, 1071, 472, 295, 527, 6484, 926, 10493, 597, 307, 11470, 4675, 766, 2907, 278], "temperature": 0.0, "avg_logprob": -0.053521034146143384, "compression_ratio": 1.86, "no_speech_prob": 0.0001475895696785301}, {"id": 189, "seek": 96240, "start": 976.4, "end": 980.9599999999999, "text": " so traditionally on most operating systems you have only one real memory offloading location", "tokens": [370, 19067, 322, 881, 7447, 3652, 291, 362, 787, 472, 957, 4675, 766, 2907, 278, 4914], "temperature": 0.0, "avg_logprob": -0.053521034146143384, "compression_ratio": 1.86, "no_speech_prob": 0.0001475895696785301}, {"id": 190, "seek": 96240, "start": 980.9599999999999, "end": 986.64, "text": " which is your disk um even if you don't have swap that's true because you do things like", "tokens": [597, 307, 428, 12355, 1105, 754, 498, 291, 500, 380, 362, 18135, 300, 311, 2074, 570, 291, 360, 721, 411], "temperature": 0.0, "avg_logprob": -0.053521034146143384, "compression_ratio": 1.86, "no_speech_prob": 0.0001475895696785301}, {"id": 191, "seek": 96240, "start": 986.64, "end": 991.28, "text": " demand paging right you page things in gradually and you also have to you know evict and get things", "tokens": [4733, 280, 3568, 558, 291, 3028, 721, 294, 13145, 293, 291, 611, 362, 281, 291, 458, 1073, 985, 293, 483, 721], "temperature": 0.0, "avg_logprob": -0.053521034146143384, "compression_ratio": 1.86, "no_speech_prob": 0.0001475895696785301}, {"id": 192, "seek": 99128, "start": 991.28, "end": 996.72, "text": " in the file cache so we're talking also here about like a lot of granular intermediate areas", "tokens": [294, 264, 3991, 19459, 370, 321, 434, 1417, 611, 510, 466, 411, 257, 688, 295, 39962, 19376, 3179], "temperature": 0.0, "avg_logprob": -0.05408886746243314, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.0001580211683176458}, {"id": 193, "seek": 99128, "start": 996.72, "end": 1000.72, "text": " that could be considered for some page offloading for infrequently access pages but they're not", "tokens": [300, 727, 312, 4888, 337, 512, 3028, 766, 2907, 278, 337, 1536, 265, 47519, 2105, 7183, 457, 436, 434, 406], "temperature": 0.0, "avg_logprob": -0.05408886746243314, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.0001580211683176458}, {"id": 194, "seek": 99128, "start": 1000.72, "end": 1007.28, "text": " really so frequently used um getting this data come into main memory again though can be very", "tokens": [534, 370, 10374, 1143, 1105, 1242, 341, 1412, 808, 666, 2135, 4675, 797, 1673, 393, 312, 588], "temperature": 0.0, "avg_logprob": -0.05408886746243314, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.0001580211683176458}, {"id": 195, "seek": 99128, "start": 1007.28, "end": 1012.64, "text": " different in terms of how difficult it is depending on how far up the the triangle you go right for", "tokens": [819, 294, 2115, 295, 577, 2252, 309, 307, 5413, 322, 577, 1400, 493, 264, 264, 13369, 291, 352, 558, 337], "temperature": 0.0, "avg_logprob": -0.05408886746243314, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.0001580211683176458}, {"id": 196, "seek": 99128, "start": 1012.64, "end": 1017.8399999999999, "text": " example um it's much easier to do it on an ssd than a hard drive because hard drives don't well", "tokens": [1365, 1105, 309, 311, 709, 3571, 281, 360, 309, 322, 364, 262, 82, 67, 813, 257, 1152, 3332, 570, 1152, 11754, 500, 380, 731], "temperature": 0.0, "avg_logprob": -0.05408886746243314, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.0001580211683176458}, {"id": 197, "seek": 101784, "start": 1017.84, "end": 1022.4, "text": " they're slow and they also don't tolerate random head like head seeking very well but there are", "tokens": [436, 434, 2964, 293, 436, 611, 500, 380, 25773, 4974, 1378, 411, 1378, 11670, 588, 731, 457, 456, 366], "temperature": 0.0, "avg_logprob": -0.07104925072711447, "compression_ratio": 1.781021897810219, "no_speech_prob": 5.9467321989359334e-05}, {"id": 198, "seek": 101784, "start": 1022.4, "end": 1028.4, "text": " more granular gradual things that we can do as well for example one thing we can do is to start", "tokens": [544, 39962, 32890, 721, 300, 321, 393, 360, 382, 731, 337, 1365, 472, 551, 321, 393, 360, 307, 281, 722], "temperature": 0.0, "avg_logprob": -0.07104925072711447, "compression_ratio": 1.781021897810219, "no_speech_prob": 5.9467321989359334e-05}, {"id": 199, "seek": 101784, "start": 1028.4, "end": 1033.3600000000001, "text": " look at exact strategies outside of hardware one of the problems with the duality of either being", "tokens": [574, 412, 1900, 9029, 2380, 295, 8837, 472, 295, 264, 2740, 365, 264, 11848, 507, 295, 2139, 885], "temperature": 0.0, "avg_logprob": -0.07104925072711447, "compression_ratio": 1.781021897810219, "no_speech_prob": 5.9467321989359334e-05}, {"id": 200, "seek": 101784, "start": 1033.3600000000001, "end": 1039.52, "text": " in ram or on the disk is that even your disk even if it's quite fast even if if it's flash it tends", "tokens": [294, 10211, 420, 322, 264, 12355, 307, 300, 754, 428, 12355, 754, 498, 309, 311, 1596, 2370, 754, 498, 498, 309, 311, 7319, 309, 12258], "temperature": 0.0, "avg_logprob": -0.07104925072711447, "compression_ratio": 1.781021897810219, "no_speech_prob": 5.9467321989359334e-05}, {"id": 201, "seek": 101784, "start": 1039.52, "end": 1045.2, "text": " to be quite a few orders of magnitude slower than your main memory is uh so one area which we have", "tokens": [281, 312, 1596, 257, 1326, 9470, 295, 15668, 14009, 813, 428, 2135, 4675, 307, 2232, 370, 472, 1859, 597, 321, 362], "temperature": 0.0, "avg_logprob": -0.07104925072711447, "compression_ratio": 1.781021897810219, "no_speech_prob": 5.9467321989359334e-05}, {"id": 202, "seek": 104520, "start": 1045.2, "end": 1050.24, "text": " have been heavily invested in is looking at what we might term warm pages uh in Linux we have talked", "tokens": [362, 668, 10950, 13104, 294, 307, 1237, 412, 437, 321, 1062, 1433, 4561, 7183, 2232, 294, 18734, 321, 362, 2825], "temperature": 0.0, "avg_logprob": -0.0719985754593559, "compression_ratio": 1.860759493670886, "no_speech_prob": 0.00016859755851328373}, {"id": 203, "seek": 104520, "start": 1050.24, "end": 1053.6000000000001, "text": " a lot about hot pages and cold pages if you look in the memory management code but there is like", "tokens": [257, 688, 466, 2368, 7183, 293, 3554, 7183, 498, 291, 574, 294, 264, 4675, 4592, 3089, 457, 456, 307, 411], "temperature": 0.0, "avg_logprob": -0.0719985754593559, "compression_ratio": 1.860759493670886, "no_speech_prob": 0.00016859755851328373}, {"id": 204, "seek": 104520, "start": 1053.6000000000001, "end": 1058.64, "text": " this kind of part of the working set which yes i do need it relatively frequently but i don't need", "tokens": [341, 733, 295, 644, 295, 264, 1364, 992, 597, 2086, 741, 360, 643, 309, 7226, 10374, 457, 741, 500, 380, 643], "temperature": 0.0, "avg_logprob": -0.0719985754593559, "compression_ratio": 1.860759493670886, "no_speech_prob": 0.00016859755851328373}, {"id": 205, "seek": 104520, "start": 1058.64, "end": 1064.0800000000002, "text": " it to make forward progress all the time so zswap is one of these one of these things we can use", "tokens": [309, 281, 652, 2128, 4205, 439, 264, 565, 370, 710, 25884, 569, 307, 472, 295, 613, 472, 295, 613, 721, 321, 393, 764], "temperature": 0.0, "avg_logprob": -0.0719985754593559, "compression_ratio": 1.860759493670886, "no_speech_prob": 0.00016859755851328373}, {"id": 206, "seek": 104520, "start": 1064.0800000000002, "end": 1069.1200000000001, "text": " for that it's it's uh essentially a feature of the Linux kernel which compresses pages which looks", "tokens": [337, 300, 309, 311, 309, 311, 2232, 4476, 257, 4111, 295, 264, 18734, 28256, 597, 14778, 279, 7183, 597, 1542], "temperature": 0.0, "avg_logprob": -0.0719985754593559, "compression_ratio": 1.860759493670886, "no_speech_prob": 0.00016859755851328373}, {"id": 207, "seek": 104520, "start": 1069.1200000000001, "end": 1074.32, "text": " like they will compress well and are not too hot into a separate pool in main memory we do have", "tokens": [411, 436, 486, 14778, 731, 293, 366, 406, 886, 2368, 666, 257, 4994, 7005, 294, 2135, 4675, 321, 360, 362], "temperature": 0.0, "avg_logprob": -0.0719985754593559, "compression_ratio": 1.860759493670886, "no_speech_prob": 0.00016859755851328373}, {"id": 208, "seek": 107432, "start": 1074.32, "end": 1079.52, "text": " to page fold them back in into main memory again if if we actually want to use them of course", "tokens": [281, 3028, 4860, 552, 646, 294, 666, 2135, 4675, 797, 498, 498, 321, 767, 528, 281, 764, 552, 295, 1164], "temperature": 0.0, "avg_logprob": -0.09107824203071244, "compression_ratio": 1.7992125984251968, "no_speech_prob": 3.3186257496709004e-05}, {"id": 209, "seek": 107432, "start": 1079.52, "end": 1082.8, "text": " but it's several orders of magnitude faster than trying to get it off the disk", "tokens": [457, 309, 311, 2940, 9470, 295, 15668, 4663, 813, 1382, 281, 483, 309, 766, 264, 12355], "temperature": 0.0, "avg_logprob": -0.09107824203071244, "compression_ratio": 1.7992125984251968, "no_speech_prob": 3.3186257496709004e-05}, {"id": 210, "seek": 107432, "start": 1084.8, "end": 1088.56, "text": " we still do have this swap for infrequently access pages there tends to be quite a bit", "tokens": [321, 920, 360, 362, 341, 18135, 337, 1536, 265, 47519, 2105, 7183, 456, 12258, 281, 312, 1596, 257, 857], "temperature": 0.0, "avg_logprob": -0.09107824203071244, "compression_ratio": 1.7992125984251968, "no_speech_prob": 3.3186257496709004e-05}, {"id": 211, "seek": 107432, "start": 1088.56, "end": 1094.56, "text": " cold working set as well um but you know this is kind of like this tiered hierarchy where we want", "tokens": [3554, 1364, 992, 382, 731, 1105, 457, 291, 458, 341, 307, 733, 295, 411, 341, 12362, 292, 22333, 689, 321, 528], "temperature": 0.0, "avg_logprob": -0.09107824203071244, "compression_ratio": 1.7992125984251968, "no_speech_prob": 3.3186257496709004e-05}, {"id": 212, "seek": 107432, "start": 1094.56, "end": 1099.52, "text": " to have warm uh warm pages instead swap hot pages in in main memory and kind of cold pages and swap", "tokens": [281, 362, 4561, 2232, 4561, 7183, 2602, 18135, 2368, 7183, 294, 294, 2135, 4675, 293, 733, 295, 3554, 7183, 293, 18135], "temperature": 0.0, "avg_logprob": -0.09107824203071244, "compression_ratio": 1.7992125984251968, "no_speech_prob": 3.3186257496709004e-05}, {"id": 213, "seek": 109952, "start": 1099.52, "end": 1104.72, "text": " one problem we had here was that even when we configure the kernel to swap as aggressively as", "tokens": [472, 1154, 321, 632, 510, 390, 300, 754, 562, 321, 22162, 264, 28256, 281, 18135, 382, 32024, 382], "temperature": 0.0, "avg_logprob": -0.08082806174434833, "compression_ratio": 1.7607361963190185, "no_speech_prob": 0.00016661312838550657}, {"id": 214, "seek": 109952, "start": 1104.72, "end": 1109.28, "text": " possible it still wouldn't do it um if you've actually looked at the swap code and i've had", "tokens": [1944, 309, 920, 2759, 380, 360, 309, 1105, 498, 291, 600, 767, 2956, 412, 264, 18135, 3089, 293, 741, 600, 632], "temperature": 0.0, "avg_logprob": -0.08082806174434833, "compression_ratio": 1.7607361963190185, "no_speech_prob": 0.00016661312838550657}, {"id": 215, "seek": 109952, "start": 1109.28, "end": 1114.48, "text": " the unfortunate misery of working on it um this you'll learn that swap code was implemented a very", "tokens": [264, 17843, 32309, 295, 1364, 322, 309, 1105, 341, 291, 603, 1466, 300, 18135, 3089, 390, 12270, 257, 588], "temperature": 0.0, "avg_logprob": -0.08082806174434833, "compression_ratio": 1.7607361963190185, "no_speech_prob": 0.00016661312838550657}, {"id": 216, "seek": 109952, "start": 1114.48, "end": 1120.48, "text": " long time ago by the people who knew what swap did and how things worked but none of them are", "tokens": [938, 565, 2057, 538, 264, 561, 567, 2586, 437, 18135, 630, 293, 577, 721, 2732, 457, 6022, 295, 552, 366], "temperature": 0.0, "avg_logprob": -0.08082806174434833, "compression_ratio": 1.7607361963190185, "no_speech_prob": 0.00016661312838550657}, {"id": 217, "seek": 109952, "start": 1120.48, "end": 1124.56, "text": " around to tell us what the hell anything means anymore and it's very confusing so i can't even", "tokens": [926, 281, 980, 505, 437, 264, 4921, 1340, 1355, 3602, 293, 309, 311, 588, 13181, 370, 741, 393, 380, 754], "temperature": 0.0, "avg_logprob": -0.08082806174434833, "compression_ratio": 1.7607361963190185, "no_speech_prob": 0.00016661312838550657}, {"id": 218, "seek": 109952, "start": 1124.56, "end": 1129.04, "text": " describe to you how the old algorithm works because it has about 500 heuristics and i don't know why", "tokens": [6786, 281, 291, 577, 264, 1331, 9284, 1985, 570, 309, 575, 466, 5923, 415, 374, 6006, 293, 741, 500, 380, 458, 983], "temperature": 0.0, "avg_logprob": -0.08082806174434833, "compression_ratio": 1.7607361963190185, "no_speech_prob": 0.00016661312838550657}, {"id": 219, "seek": 112904, "start": 1129.04, "end": 1134.0, "text": " any of them are there um so for this reason you know we try to think how can we make this a little", "tokens": [604, 295, 552, 366, 456, 1105, 370, 337, 341, 1778, 291, 458, 321, 853, 281, 519, 577, 393, 321, 652, 341, 257, 707], "temperature": 0.0, "avg_logprob": -0.0992105628262047, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00011964738223468885}, {"id": 220, "seek": 112904, "start": 1134.0, "end": 1139.2, "text": " bit more efficient we are using non-rotational disks now we have zswap we have flash disks we", "tokens": [857, 544, 7148, 321, 366, 1228, 2107, 12, 10536, 1478, 41617, 586, 321, 362, 710, 25884, 569, 321, 362, 7319, 41617, 321], "temperature": 0.0, "avg_logprob": -0.0992105628262047, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00011964738223468885}, {"id": 221, "seek": 112904, "start": 1139.2, "end": 1145.6, "text": " have ssds we want to make a an algorithm which can handle this better so from kernel 5.8 um we", "tokens": [362, 262, 82, 16063, 321, 528, 281, 652, 257, 364, 9284, 597, 393, 4813, 341, 1101, 370, 490, 28256, 1025, 13, 23, 1105, 321], "temperature": 0.0, "avg_logprob": -0.0992105628262047, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00011964738223468885}, {"id": 222, "seek": 112904, "start": 1145.6, "end": 1150.48, "text": " have been working on a new algorithm which has already landed um so first we have code to track", "tokens": [362, 668, 1364, 322, 257, 777, 9284, 597, 575, 1217, 15336, 1105, 370, 700, 321, 362, 3089, 281, 2837], "temperature": 0.0, "avg_logprob": -0.0992105628262047, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00011964738223468885}, {"id": 223, "seek": 112904, "start": 1150.48, "end": 1154.3999999999999, "text": " all swap ins and cache misses across the system so for every cache page we're having to page", "tokens": [439, 18135, 1028, 293, 19459, 29394, 2108, 264, 1185, 370, 337, 633, 19459, 3028, 321, 434, 1419, 281, 3028], "temperature": 0.0, "avg_logprob": -0.0992105628262047, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00011964738223468885}, {"id": 224, "seek": 115440, "start": 1154.4, "end": 1158.96, "text": " fold and evict and page fold and evict and page fold and evict over and over again what we want to", "tokens": [4860, 293, 1073, 985, 293, 3028, 4860, 293, 1073, 985, 293, 3028, 4860, 293, 1073, 985, 670, 293, 670, 797, 437, 321, 528, 281], "temperature": 0.0, "avg_logprob": -0.062245154565618944, "compression_ratio": 1.9718875502008033, "no_speech_prob": 0.00017811909492593259}, {"id": 225, "seek": 115440, "start": 1158.96, "end": 1166.3200000000002, "text": " do is try and page out a heat page instead if we're unlucky and this heat page actually it turns", "tokens": [360, 307, 853, 293, 3028, 484, 257, 3738, 3028, 2602, 498, 321, 434, 38838, 293, 341, 3738, 3028, 767, 309, 4523], "temperature": 0.0, "avg_logprob": -0.062245154565618944, "compression_ratio": 1.9718875502008033, "no_speech_prob": 0.00017811909492593259}, {"id": 226, "seek": 115440, "start": 1166.3200000000002, "end": 1170.96, "text": " out to be hot then you know no biggie like we we've made a mistake but we'll try a different one", "tokens": [484, 281, 312, 2368, 550, 291, 458, 572, 955, 9997, 411, 321, 321, 600, 1027, 257, 6146, 457, 321, 603, 853, 257, 819, 472], "temperature": 0.0, "avg_logprob": -0.062245154565618944, "compression_ratio": 1.9718875502008033, "no_speech_prob": 0.00017811909492593259}, {"id": 227, "seek": 115440, "start": 1170.96, "end": 1174.8000000000002, "text": " next time we do have some heuristics to try and work out which one is hot and which one is not but", "tokens": [958, 565, 321, 360, 362, 512, 415, 374, 6006, 281, 853, 293, 589, 484, 597, 472, 307, 2368, 293, 597, 472, 307, 406, 457], "temperature": 0.0, "avg_logprob": -0.062245154565618944, "compression_ratio": 1.9718875502008033, "no_speech_prob": 0.00017811909492593259}, {"id": 228, "seek": 115440, "start": 1174.8000000000002, "end": 1181.44, "text": " they are kind of expensive so we don't use a lot of them um however you know if if we are lucky and", "tokens": [436, 366, 733, 295, 5124, 370, 321, 500, 380, 764, 257, 688, 295, 552, 1105, 4461, 291, 458, 498, 498, 321, 366, 6356, 293], "temperature": 0.0, "avg_logprob": -0.062245154565618944, "compression_ratio": 1.9718875502008033, "no_speech_prob": 0.00017811909492593259}, {"id": 229, "seek": 118144, "start": 1181.44, "end": 1186.48, "text": " the heat page does stay swapped out then that's one more page which we can use for file caches and", "tokens": [264, 3738, 3028, 775, 1754, 50011, 484, 550, 300, 311, 472, 544, 3028, 597, 321, 393, 764, 337, 3991, 269, 13272, 293], "temperature": 0.0, "avg_logprob": -0.06850729072303102, "compression_ratio": 1.8346153846153845, "no_speech_prob": 0.00012745831918437034}, {"id": 230, "seek": 118144, "start": 1186.48, "end": 1192.0, "text": " we can use it for other processes and this means that we can engage swap a lot more readily in", "tokens": [321, 393, 764, 309, 337, 661, 7555, 293, 341, 1355, 300, 321, 393, 4683, 18135, 257, 688, 544, 26336, 294], "temperature": 0.0, "avg_logprob": -0.06850729072303102, "compression_ratio": 1.8346153846153845, "no_speech_prob": 0.00012745831918437034}, {"id": 231, "seek": 118144, "start": 1192.0, "end": 1197.3600000000001, "text": " most scenarios importantly though we are not adding ioload this doesn't increase ioload or", "tokens": [881, 15077, 8906, 1673, 321, 366, 406, 5127, 741, 7902, 345, 341, 1177, 380, 3488, 741, 7902, 345, 420], "temperature": 0.0, "avg_logprob": -0.06850729072303102, "compression_ratio": 1.8346153846153845, "no_speech_prob": 0.00012745831918437034}, {"id": 232, "seek": 118144, "start": 1197.3600000000001, "end": 1201.92, "text": " decrease endurance of the disk um we are just more intentional about in choosing how to apply", "tokens": [11514, 30325, 295, 264, 12355, 1105, 321, 366, 445, 544, 21935, 466, 294, 10875, 577, 281, 3079], "temperature": 0.0, "avg_logprob": -0.06850729072303102, "compression_ratio": 1.8346153846153845, "no_speech_prob": 0.00012745831918437034}, {"id": 233, "seek": 118144, "start": 1201.92, "end": 1207.44, "text": " the i it doesn't double up um we only trade one type of paging for another and our goal here is to", "tokens": [264, 741, 309, 1177, 380, 3834, 493, 1105, 321, 787, 4923, 472, 2010, 295, 280, 3568, 337, 1071, 293, 527, 3387, 510, 307, 281], "temperature": 0.0, "avg_logprob": -0.06850729072303102, "compression_ratio": 1.8346153846153845, "no_speech_prob": 0.00012745831918437034}, {"id": 234, "seek": 120744, "start": 1207.44, "end": 1213.2, "text": " reach an optimal state where the optimal state is doing the minimum amount of i o in order to sustain", "tokens": [2524, 364, 16252, 1785, 689, 264, 16252, 1785, 307, 884, 264, 7285, 2372, 295, 741, 277, 294, 1668, 281, 6769], "temperature": 0.0, "avg_logprob": -0.08275852203369141, "compression_ratio": 1.7670250896057347, "no_speech_prob": 7.030260167084634e-05}, {"id": 235, "seek": 120744, "start": 1213.2, "end": 1217.76, "text": " workload performance um so ideally what we do is have this tiered model of you know like I said main", "tokens": [20139, 3389, 1105, 370, 22915, 437, 321, 360, 307, 362, 341, 12362, 292, 2316, 295, 291, 458, 411, 286, 848, 2135], "temperature": 0.0, "avg_logprob": -0.08275852203369141, "compression_ratio": 1.7670250896057347, "no_speech_prob": 7.030260167084634e-05}, {"id": 236, "seek": 120744, "start": 1217.76, "end": 1224.72, "text": " memory z swap and swap on disk this is super simple idea compared to the old model although the old", "tokens": [4675, 710, 18135, 293, 18135, 322, 12355, 341, 307, 1687, 2199, 1558, 5347, 281, 264, 1331, 2316, 4878, 264, 1331], "temperature": 0.0, "avg_logprob": -0.08275852203369141, "compression_ratio": 1.7670250896057347, "no_speech_prob": 7.030260167084634e-05}, {"id": 237, "seek": 120744, "start": 1224.72, "end": 1229.28, "text": " algorithm has a lot of kind of weird heuristics as I mentioned a lot of penalties a lot of kind of", "tokens": [9284, 575, 257, 688, 295, 733, 295, 3657, 415, 374, 6006, 382, 286, 2835, 257, 688, 295, 35389, 257, 688, 295, 733, 295], "temperature": 0.0, "avg_logprob": -0.08275852203369141, "compression_ratio": 1.7670250896057347, "no_speech_prob": 7.030260167084634e-05}, {"id": 238, "seek": 120744, "start": 1229.28, "end": 1234.88, "text": " strange things um in general it was not really written for an era where SSDs exist or where", "tokens": [5861, 721, 1105, 294, 2674, 309, 390, 406, 534, 3720, 337, 364, 4249, 689, 30262, 82, 2514, 420, 689], "temperature": 0.0, "avg_logprob": -0.08275852203369141, "compression_ratio": 1.7670250896057347, "no_speech_prob": 7.030260167084634e-05}, {"id": 239, "seek": 123488, "start": 1234.88, "end": 1238.64, "text": " z swap exists so it's understandable that it needed some some care and attention", "tokens": [710, 18135, 8198, 370, 309, 311, 25648, 300, 309, 2978, 512, 512, 1127, 293, 3202], "temperature": 0.0, "avg_logprob": -0.10526723769104597, "compression_ratio": 1.908, "no_speech_prob": 7.659497350687161e-05}, {"id": 240, "seek": 123488, "start": 1240.0, "end": 1245.1200000000001, "text": " so what were the effects of this change in prod like what what actually happened so on web servers", "tokens": [370, 437, 645, 264, 5065, 295, 341, 1319, 294, 15792, 411, 437, 437, 767, 2011, 370, 322, 3670, 15909], "temperature": 0.0, "avg_logprob": -0.10526723769104597, "compression_ratio": 1.908, "no_speech_prob": 7.659497350687161e-05}, {"id": 241, "seek": 123488, "start": 1245.1200000000001, "end": 1250.16, "text": " we not only noticed like an increase in performance but we also noticed a decrease in heat memory by", "tokens": [321, 406, 787, 5694, 411, 364, 3488, 294, 3389, 457, 321, 611, 5694, 257, 11514, 294, 3738, 4675, 538], "temperature": 0.0, "avg_logprob": -0.10526723769104597, "compression_ratio": 1.908, "no_speech_prob": 7.659497350687161e-05}, {"id": 242, "seek": 123488, "start": 1250.16, "end": 1256.72, "text": " about two gigabytes or so out of about 16 gigabytes total the cache grew to fill this newly freed", "tokens": [466, 732, 42741, 420, 370, 484, 295, 466, 3165, 42741, 3217, 264, 19459, 6109, 281, 2836, 341, 15109, 21796], "temperature": 0.0, "avg_logprob": -0.10526723769104597, "compression_ratio": 1.908, "no_speech_prob": 7.659497350687161e-05}, {"id": 243, "seek": 123488, "start": 1256.72, "end": 1261.6000000000001, "text": " space and it grew by about two gigabytes from about uh two gigabytes of cache to four gigabytes of", "tokens": [1901, 293, 309, 6109, 538, 466, 732, 42741, 490, 466, 2232, 732, 42741, 295, 19459, 281, 1451, 42741, 295], "temperature": 0.0, "avg_logprob": -0.10526723769104597, "compression_ratio": 1.908, "no_speech_prob": 7.659497350687161e-05}, {"id": 244, "seek": 126160, "start": 1261.6, "end": 1266.32, "text": " cache we also observed a measurable increase in web server performance from this change which is", "tokens": [19459, 321, 611, 13095, 257, 43615, 3488, 294, 3670, 7154, 3389, 490, 341, 1319, 597, 307], "temperature": 0.0, "avg_logprob": -0.04412741453751274, "compression_ratio": 1.9415807560137457, "no_speech_prob": 0.00010588064469629899}, {"id": 245, "seek": 126160, "start": 1266.32, "end": 1270.8799999999999, "text": " deeply encouraging and these are all indications that you know we are now starting to reclaim the", "tokens": [8760, 14580, 293, 613, 366, 439, 44450, 300, 291, 458, 321, 366, 586, 2891, 281, 40074, 264], "temperature": 0.0, "avg_logprob": -0.04412741453751274, "compression_ratio": 1.9415807560137457, "no_speech_prob": 0.00010588064469629899}, {"id": 246, "seek": 126160, "start": 1270.8799999999999, "end": 1273.84, "text": " right things actually we are making better decisions because things are looking pretty", "tokens": [558, 721, 767, 321, 366, 1455, 1101, 5327, 570, 721, 366, 1237, 1238], "temperature": 0.0, "avg_logprob": -0.04412741453751274, "compression_ratio": 1.9415807560137457, "no_speech_prob": 0.00010588064469629899}, {"id": 247, "seek": 126160, "start": 1273.84, "end": 1278.3999999999999, "text": " positive here so not only that but you see a decrease in disk i o because we are actually", "tokens": [3353, 510, 370, 406, 787, 300, 457, 291, 536, 257, 11514, 294, 12355, 741, 277, 570, 321, 366, 767], "temperature": 0.0, "avg_logprob": -0.04412741453751274, "compression_ratio": 1.9415807560137457, "no_speech_prob": 0.00010588064469629899}, {"id": 248, "seek": 126160, "start": 1278.3999999999999, "end": 1283.4399999999998, "text": " doing things correctly we are making the correct decisions and it's not really that often that", "tokens": [884, 721, 8944, 321, 366, 1455, 264, 3006, 5327, 293, 309, 311, 406, 534, 300, 2049, 300], "temperature": 0.0, "avg_logprob": -0.04412741453751274, "compression_ratio": 1.9415807560137457, "no_speech_prob": 0.00010588064469629899}, {"id": 249, "seek": 126160, "start": 1283.4399999999998, "end": 1289.12, "text": " you get a benefit in performance disk i o memory usage instead of having to trade off between them", "tokens": [291, 483, 257, 5121, 294, 3389, 12355, 741, 277, 4675, 14924, 2602, 295, 1419, 281, 4923, 766, 1296, 552], "temperature": 0.0, "avg_logprob": -0.04412741453751274, "compression_ratio": 1.9415807560137457, "no_speech_prob": 0.00010588064469629899}, {"id": 250, "seek": 128912, "start": 1289.12, "end": 1294.32, "text": " right so it probably indicates that this is the better solution for this kind of era this also", "tokens": [558, 370, 309, 1391, 16203, 300, 341, 307, 264, 1101, 3827, 337, 341, 733, 295, 4249, 341, 611], "temperature": 0.0, "avg_logprob": -0.05177547931671143, "compression_ratio": 1.929078014184397, "no_speech_prob": 0.000289283343590796}, {"id": 251, "seek": 128912, "start": 1294.32, "end": 1299.28, "text": " meant that on some workloads uh we now had opportunities to stack where we did not have", "tokens": [4140, 300, 322, 512, 32452, 2232, 321, 586, 632, 4786, 281, 8630, 689, 321, 630, 406, 362], "temperature": 0.0, "avg_logprob": -0.05177547931671143, "compression_ratio": 1.929078014184397, "no_speech_prob": 0.000289283343590796}, {"id": 252, "seek": 128912, "start": 1299.28, "end": 1303.36, "text": " opportunities to stack before like running say multiple kinds of ads jobs or multiple kinds", "tokens": [4786, 281, 8630, 949, 411, 2614, 584, 3866, 3685, 295, 10342, 4782, 420, 3866, 3685], "temperature": 0.0, "avg_logprob": -0.05177547931671143, "compression_ratio": 1.929078014184397, "no_speech_prob": 0.000289283343590796}, {"id": 253, "seek": 128912, "start": 1303.36, "end": 1307.76, "text": " of web servers on top of each other uh many machines don't use up all of their resources", "tokens": [295, 3670, 15909, 322, 1192, 295, 1184, 661, 2232, 867, 8379, 500, 380, 764, 493, 439, 295, 641, 3593], "temperature": 0.0, "avg_logprob": -0.05177547931671143, "compression_ratio": 1.929078014184397, "no_speech_prob": 0.000289283343590796}, {"id": 254, "seek": 128912, "start": 1307.76, "end": 1312.7199999999998, "text": " but they use up just enough that it's pretty hard to stack something else on top of it", "tokens": [457, 436, 764, 493, 445, 1547, 300, 309, 311, 1238, 1152, 281, 8630, 746, 1646, 322, 1192, 295, 309], "temperature": 0.0, "avg_logprob": -0.05177547931671143, "compression_ratio": 1.929078014184397, "no_speech_prob": 0.000289283343590796}, {"id": 255, "seek": 128912, "start": 1312.7199999999998, "end": 1316.9599999999998, "text": " because you're using just enough that it's not actually enough to sustainably run to workload", "tokens": [570, 291, 434, 1228, 445, 1547, 300, 309, 311, 406, 767, 1547, 281, 6769, 1188, 1190, 281, 20139], "temperature": 0.0, "avg_logprob": -0.05177547931671143, "compression_ratio": 1.929078014184397, "no_speech_prob": 0.000289283343590796}, {"id": 256, "seek": 131696, "start": 1316.96, "end": 1320.96, "text": " side by side so this is another thing where we've managed to kind of push the needle just a little", "tokens": [1252, 538, 1252, 370, 341, 307, 1071, 551, 689, 321, 600, 6453, 281, 733, 295, 2944, 264, 11037, 445, 257, 707], "temperature": 0.0, "avg_logprob": -0.09253825280899391, "compression_ratio": 1.7259036144578312, "no_speech_prob": 8.113484364002943e-05}, {"id": 257, "seek": 131696, "start": 1320.96, "end": 1325.04, "text": " bit so that you can make quite a bit more use uh an efficiency out of the servers that exist", "tokens": [857, 370, 300, 291, 393, 652, 1596, 257, 857, 544, 764, 2232, 364, 10493, 484, 295, 264, 15909, 300, 2514], "temperature": 0.0, "avg_logprob": -0.09253825280899391, "compression_ratio": 1.7259036144578312, "no_speech_prob": 8.113484364002943e-05}, {"id": 258, "seek": 131696, "start": 1326.72, "end": 1331.2, "text": " the combination of changes to the swap algorithm using z-swap and squeezing workloads using senpai", "tokens": [264, 6562, 295, 2962, 281, 264, 18135, 9284, 1228, 710, 12, 25884, 569, 293, 36645, 32452, 1228, 3151, 43502], "temperature": 0.0, "avg_logprob": -0.09253825280899391, "compression_ratio": 1.7259036144578312, "no_speech_prob": 8.113484364002943e-05}, {"id": 259, "seek": 131696, "start": 1331.2, "end": 1336.08, "text": " was a huge part of our operation during covid all of these things acting together we termed tmo", "tokens": [390, 257, 2603, 644, 295, 527, 6916, 1830, 25616, 439, 295, 613, 721, 6577, 1214, 321, 1433, 292, 256, 3280], "temperature": 0.0, "avg_logprob": -0.09253825280899391, "compression_ratio": 1.7259036144578312, "no_speech_prob": 8.113484364002943e-05}, {"id": 260, "seek": 131696, "start": 1336.08, "end": 1340.24, "text": " which stands for transparent memory offloading and you can see some of the results we've had in", "tokens": [597, 7382, 337, 12737, 4675, 766, 2907, 278, 293, 291, 393, 536, 512, 295, 264, 3542, 321, 600, 632, 294], "temperature": 0.0, "avg_logprob": -0.09253825280899391, "compression_ratio": 1.7259036144578312, "no_speech_prob": 8.113484364002943e-05}, {"id": 261, "seek": 131696, "start": 1340.24, "end": 1345.52, "text": " production here in some cases we were able to save up to 20 percent of critical fleet-wide", "tokens": [4265, 510, 294, 512, 3331, 321, 645, 1075, 281, 3155, 493, 281, 945, 3043, 295, 4924, 19396, 12, 7990], "temperature": 0.0, "avg_logprob": -0.09253825280899391, "compression_ratio": 1.7259036144578312, "no_speech_prob": 8.113484364002943e-05}, {"id": 262, "seek": 134552, "start": 1345.52, "end": 1350.6399999999999, "text": " workloads memory with either neutral or even in some cases positive effects on workload performance", "tokens": [32452, 4675, 365, 2139, 10598, 420, 754, 294, 512, 3331, 3353, 5065, 322, 20139, 3389], "temperature": 0.0, "avg_logprob": -0.06647359292338213, "compression_ratio": 1.7217125382262997, "no_speech_prob": 8.296016312669963e-05}, {"id": 263, "seek": 134552, "start": 1351.28, "end": 1355.04, "text": " so this opens up a lot of opportunities obviously in terms of reliability stacking", "tokens": [370, 341, 9870, 493, 257, 688, 295, 4786, 2745, 294, 2115, 295, 24550, 41376], "temperature": 0.0, "avg_logprob": -0.06647359292338213, "compression_ratio": 1.7217125382262997, "no_speech_prob": 8.296016312669963e-05}, {"id": 264, "seek": 134552, "start": 1355.04, "end": 1359.92, "text": " and future growth this whole topic has a huge amount of cover i really could just do an entire", "tokens": [293, 2027, 4599, 341, 1379, 4829, 575, 257, 2603, 2372, 295, 2060, 741, 534, 727, 445, 360, 364, 2302], "temperature": 0.0, "avg_logprob": -0.06647359292338213, "compression_ratio": 1.7217125382262997, "no_speech_prob": 8.296016312669963e-05}, {"id": 265, "seek": 134552, "start": 1359.92, "end": 1363.92, "text": " talk on this um if you want to learn more i do recommend the post which is linked at the bottom", "tokens": [751, 322, 341, 1105, 498, 291, 528, 281, 1466, 544, 741, 360, 2748, 264, 2183, 597, 307, 9408, 412, 264, 2767], "temperature": 0.0, "avg_logprob": -0.06647359292338213, "compression_ratio": 1.7217125382262997, "no_speech_prob": 8.296016312669963e-05}, {"id": 266, "seek": 134552, "start": 1363.92, "end": 1368.0, "text": " my colleagues johannes and dan wrote an article with a lot more depth on you know how we achieve", "tokens": [452, 7734, 361, 1445, 969, 279, 293, 3277, 4114, 364, 7222, 365, 257, 688, 544, 7161, 322, 291, 458, 577, 321, 4584], "temperature": 0.0, "avg_logprob": -0.06647359292338213, "compression_ratio": 1.7217125382262997, "no_speech_prob": 8.296016312669963e-05}, {"id": 267, "seek": 134552, "start": 1368.0, "end": 1374.48, "text": " what we achieved and on things like cxl memory as well so let's come back to this this slide", "tokens": [437, 321, 11042, 293, 322, 721, 411, 269, 87, 75, 4675, 382, 731, 370, 718, 311, 808, 646, 281, 341, 341, 4137], "temperature": 0.0, "avg_logprob": -0.06647359292338213, "compression_ratio": 1.7217125382262997, "no_speech_prob": 8.296016312669963e-05}, {"id": 268, "seek": 137448, "start": 1374.48, "end": 1379.6, "text": " from earlier um we briefly touched on the fact that if bounded one resource can just turn into", "tokens": [490, 3071, 1105, 321, 10515, 9828, 322, 264, 1186, 300, 498, 37498, 472, 7684, 393, 445, 1261, 666], "temperature": 0.0, "avg_logprob": -0.09405209971409217, "compression_ratio": 1.80859375, "no_speech_prob": 0.0004064174718223512}, {"id": 269, "seek": 137448, "start": 1379.6, "end": 1383.92, "text": " another a particularly egregious case being memory turning into i o when it gets bounded", "tokens": [1071, 257, 4098, 308, 11027, 851, 1389, 885, 4675, 6246, 666, 741, 277, 562, 309, 2170, 37498], "temperature": 0.0, "avg_logprob": -0.09405209971409217, "compression_ratio": 1.80859375, "no_speech_prob": 0.0004064174718223512}, {"id": 270, "seek": 137448, "start": 1384.72, "end": 1389.52, "text": " for this reason it might seem counterintuitive but we always need controls on i o when we have", "tokens": [337, 341, 1778, 309, 1062, 1643, 5682, 686, 48314, 457, 321, 1009, 643, 9003, 322, 741, 277, 562, 321, 362], "temperature": 0.0, "avg_logprob": -0.09405209971409217, "compression_ratio": 1.80859375, "no_speech_prob": 0.0004064174718223512}, {"id": 271, "seek": 137448, "start": 1389.52, "end": 1394.72, "text": " controls on memory otherwise memory pressure will always just directly translate to disk i o", "tokens": [9003, 322, 4675, 5911, 4675, 3321, 486, 1009, 445, 3838, 13799, 281, 12355, 741, 277], "temperature": 0.0, "avg_logprob": -0.09405209971409217, "compression_ratio": 1.80859375, "no_speech_prob": 0.0004064174718223512}, {"id": 272, "seek": 137448, "start": 1396.16, "end": 1402.48, "text": " probably the most attuned way to solve this is to try to limit disk bandwidth or disk i ops", "tokens": [1391, 264, 881, 951, 43703, 636, 281, 5039, 341, 307, 281, 853, 281, 4948, 12355, 23647, 420, 12355, 741, 44663], "temperature": 0.0, "avg_logprob": -0.09405209971409217, "compression_ratio": 1.80859375, "no_speech_prob": 0.0004064174718223512}, {"id": 273, "seek": 140248, "start": 1402.48, "end": 1406.16, "text": " however this doesn't really manifest usually very well in reality if you think about any modern", "tokens": [4461, 341, 1177, 380, 534, 10067, 2673, 588, 731, 294, 4103, 498, 291, 519, 466, 604, 4363], "temperature": 0.0, "avg_logprob": -0.08976854489544245, "compression_ratio": 1.819935691318328, "no_speech_prob": 0.00017251913959626108}, {"id": 274, "seek": 140248, "start": 1406.16, "end": 1410.72, "text": " storage device they tend to be quite complex they they're q devices you can throw a lot of commands", "tokens": [6725, 4302, 436, 3928, 281, 312, 1596, 3997, 436, 436, 434, 9505, 5759, 291, 393, 3507, 257, 688, 295, 16901], "temperature": 0.0, "avg_logprob": -0.08976854489544245, "compression_ratio": 1.819935691318328, "no_speech_prob": 0.00017251913959626108}, {"id": 275, "seek": 140248, "start": 1410.72, "end": 1415.2, "text": " of them in parallel and when you do that you often find that hey you know magically it can do more", "tokens": [295, 552, 294, 8952, 293, 562, 291, 360, 300, 291, 2049, 915, 300, 4177, 291, 458, 39763, 309, 393, 360, 544], "temperature": 0.0, "avg_logprob": -0.08976854489544245, "compression_ratio": 1.819935691318328, "no_speech_prob": 0.00017251913959626108}, {"id": 276, "seek": 140248, "start": 1415.2, "end": 1419.6, "text": " things the same reason we have i o schedulers because we can optimize what we do inside the disk", "tokens": [721, 264, 912, 1778, 321, 362, 741, 277, 12000, 433, 570, 321, 393, 19719, 437, 321, 360, 1854, 264, 12355], "temperature": 0.0, "avg_logprob": -0.08976854489544245, "compression_ratio": 1.819935691318328, "no_speech_prob": 0.00017251913959626108}, {"id": 277, "seek": 140248, "start": 1420.56, "end": 1424.8, "text": " also the mixture of i o really matters like reads versus writes sequential versus random", "tokens": [611, 264, 9925, 295, 741, 277, 534, 7001, 411, 15700, 5717, 13657, 42881, 5717, 4974], "temperature": 0.0, "avg_logprob": -0.08976854489544245, "compression_ratio": 1.819935691318328, "no_speech_prob": 0.00017251913959626108}, {"id": 278, "seek": 140248, "start": 1424.8, "end": 1430.16, "text": " even on ssds these things tend to matter um and it's really hard to turn to determine", "tokens": [754, 322, 262, 82, 16063, 613, 721, 3928, 281, 1871, 1105, 293, 309, 311, 534, 1152, 281, 1261, 281, 6997], "temperature": 0.0, "avg_logprob": -0.08976854489544245, "compression_ratio": 1.819935691318328, "no_speech_prob": 0.00017251913959626108}, {"id": 279, "seek": 143016, "start": 1430.16, "end": 1435.52, "text": " a single metric for loadedness for a storage device because the cost of one i o operation or", "tokens": [257, 2167, 20678, 337, 13210, 1287, 337, 257, 6725, 4302, 570, 264, 2063, 295, 472, 741, 277, 6916, 420], "temperature": 0.0, "avg_logprob": -0.04501762883416537, "compression_ratio": 1.7773722627737227, "no_speech_prob": 2.1276033294270746e-05}, {"id": 280, "seek": 143016, "start": 1435.52, "end": 1442.16, "text": " one block of data is extremely variable depending on the wider context um so it's it's also really", "tokens": [472, 3461, 295, 1412, 307, 4664, 7006, 5413, 322, 264, 11842, 4319, 1105, 370, 309, 311, 309, 311, 611, 534], "temperature": 0.0, "avg_logprob": -0.04501762883416537, "compression_ratio": 1.7773722627737227, "no_speech_prob": 2.1276033294270746e-05}, {"id": 281, "seek": 143016, "start": 1442.16, "end": 1447.52, "text": " punitive to just have a limit on you know how much can i write how many i ops can i do um because", "tokens": [4468, 2187, 281, 445, 362, 257, 4948, 322, 291, 458, 577, 709, 393, 741, 2464, 577, 867, 741, 44663, 393, 741, 360, 1105, 570], "temperature": 0.0, "avg_logprob": -0.04501762883416537, "compression_ratio": 1.7773722627737227, "no_speech_prob": 2.1276033294270746e-05}, {"id": 282, "seek": 143016, "start": 1447.52, "end": 1452.16, "text": " even if nobody else is using the disk you're still slowed down to this level there's no opportunity", "tokens": [754, 498, 5079, 1646, 307, 1228, 264, 12355, 291, 434, 920, 32057, 760, 281, 341, 1496, 456, 311, 572, 2650], "temperature": 0.0, "avg_logprob": -0.04501762883416537, "compression_ratio": 1.7773722627737227, "no_speech_prob": 2.1276033294270746e-05}, {"id": 283, "seek": 143016, "start": 1452.16, "end": 1455.92, "text": " to make the most of the disk when nobody else is doing anything right so it's not really good for", "tokens": [281, 652, 264, 881, 295, 264, 12355, 562, 5079, 1646, 307, 884, 1340, 558, 370, 309, 311, 406, 534, 665, 337], "temperature": 0.0, "avg_logprob": -0.04501762883416537, "compression_ratio": 1.7773722627737227, "no_speech_prob": 2.1276033294270746e-05}, {"id": 284, "seek": 145592, "start": 1455.92, "end": 1462.88, "text": " this kind of best effort bursty work on a machine which we would like to do so the first way that", "tokens": [341, 733, 295, 1151, 4630, 12712, 88, 589, 322, 257, 3479, 597, 321, 576, 411, 281, 360, 370, 264, 700, 636, 300], "temperature": 0.0, "avg_logprob": -0.05320754221507481, "compression_ratio": 1.7697841726618706, "no_speech_prob": 4.098959834664129e-05}, {"id": 285, "seek": 145592, "start": 1462.88, "end": 1467.52, "text": " we try to avoid this problem is by using latency as a metric for workload health so what we might", "tokens": [321, 853, 281, 5042, 341, 1154, 307, 538, 1228, 27043, 382, 257, 20678, 337, 20139, 1585, 370, 437, 321, 1062], "temperature": 0.0, "avg_logprob": -0.05320754221507481, "compression_ratio": 1.7697841726618706, "no_speech_prob": 4.098959834664129e-05}, {"id": 286, "seek": 145592, "start": 1467.52, "end": 1472.16, "text": " try and do is apply a maximal target latency for i o completions on the main workload and if we", "tokens": [853, 293, 360, 307, 3079, 257, 49336, 3779, 27043, 337, 741, 277, 1557, 626, 322, 264, 2135, 20139, 293, 498, 321], "temperature": 0.0, "avg_logprob": -0.05320754221507481, "compression_ratio": 1.7697841726618706, "no_speech_prob": 4.098959834664129e-05}, {"id": 287, "seek": 145592, "start": 1472.16, "end": 1476.88, "text": " exceed that we start dialing back other c groups with lucid latency requirements back to their own", "tokens": [14048, 300, 321, 722, 5502, 278, 646, 661, 269, 3935, 365, 21296, 327, 27043, 7728, 646, 281, 641, 1065], "temperature": 0.0, "avg_logprob": -0.05320754221507481, "compression_ratio": 1.7697841726618706, "no_speech_prob": 4.098959834664129e-05}, {"id": 288, "seek": 145592, "start": 1476.88, "end": 1481.28, "text": " configured thresholds what this does is this prevents an application from thrashing on memory so much", "tokens": [30538, 14678, 82, 437, 341, 775, 307, 341, 22367, 364, 3861, 490, 739, 11077, 322, 4675, 370, 709], "temperature": 0.0, "avg_logprob": -0.05320754221507481, "compression_ratio": 1.7697841726618706, "no_speech_prob": 4.098959834664129e-05}, {"id": 289, "seek": 148128, "start": 1481.28, "end": 1486.16, "text": " that it just kills i o across the system this actually works really well for systems where", "tokens": [300, 309, 445, 14563, 741, 277, 2108, 264, 1185, 341, 767, 1985, 534, 731, 337, 3652, 689], "temperature": 0.0, "avg_logprob": -0.04105221755861297, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0004142392717767507}, {"id": 290, "seek": 148128, "start": 1486.16, "end": 1491.2, "text": " there's only one workload but the problem comes when you have a multi workload stacked case like this", "tokens": [456, 311, 787, 472, 20139, 457, 264, 1154, 1487, 562, 291, 362, 257, 4825, 20139, 28867, 1389, 411, 341], "temperature": 0.0, "avg_logprob": -0.04105221755861297, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0004142392717767507}, {"id": 291, "seek": 148128, "start": 1491.2, "end": 1495.52, "text": " here we have two high priority workloads which are stacked on a single machine one has an i o", "tokens": [510, 321, 362, 732, 1090, 9365, 32452, 597, 366, 28867, 322, 257, 2167, 3479, 472, 575, 364, 741, 277], "temperature": 0.0, "avg_logprob": -0.04105221755861297, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0004142392717767507}, {"id": 292, "seek": 148128, "start": 1495.52, "end": 1500.32, "text": " dot latency of 10 milliseconds the other has 30 milliseconds but the problem here is as soon as", "tokens": [5893, 27043, 295, 1266, 34184, 264, 661, 575, 2217, 34184, 457, 264, 1154, 510, 307, 382, 2321, 382], "temperature": 0.0, "avg_logprob": -0.04105221755861297, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0004142392717767507}, {"id": 293, "seek": 148128, "start": 1500.32, "end": 1504.8, "text": " workload one gets into trouble everyone else is going to suffer and there's no way around that", "tokens": [20139, 472, 2170, 666, 5253, 1518, 1646, 307, 516, 281, 9753, 293, 456, 311, 572, 636, 926, 300], "temperature": 0.0, "avg_logprob": -0.04105221755861297, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0004142392717767507}, {"id": 294, "seek": 148128, "start": 1504.8, "end": 1509.36, "text": " we're just going to penalize them and there's no way to say you know how bad is the situation", "tokens": [321, 434, 445, 516, 281, 13661, 1125, 552, 293, 456, 311, 572, 636, 281, 584, 291, 458, 577, 1578, 307, 264, 2590], "temperature": 0.0, "avg_logprob": -0.04105221755861297, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0004142392717767507}, {"id": 295, "seek": 150936, "start": 1509.36, "end": 1513.76, "text": " really and is it really them causing the problem this is fine if you're you know the thing you're", "tokens": [534, 293, 307, 309, 534, 552, 9853, 264, 1154, 341, 307, 2489, 498, 291, 434, 291, 458, 264, 551, 291, 434], "temperature": 0.0, "avg_logprob": -0.06368688029101771, "compression_ratio": 1.7625899280575539, "no_speech_prob": 2.4391756596742198e-05}, {"id": 296, "seek": 150936, "start": 1513.76, "end": 1518.3999999999999, "text": " throttling is just best effort but it's we here we have two important workloads right so how can", "tokens": [739, 1521, 1688, 307, 445, 1151, 4630, 457, 309, 311, 321, 510, 321, 362, 732, 1021, 32452, 558, 370, 577, 393], "temperature": 0.0, "avg_logprob": -0.06368688029101771, "compression_ratio": 1.7625899280575539, "no_speech_prob": 2.4391756596742198e-05}, {"id": 297, "seek": 150936, "start": 1518.3999999999999, "end": 1525.04, "text": " we solve this so our solution is this thing called i o dot cost which might look very similar at first", "tokens": [321, 5039, 341, 370, 527, 3827, 307, 341, 551, 1219, 741, 277, 5893, 2063, 597, 1062, 574, 588, 2531, 412, 700], "temperature": 0.0, "avg_logprob": -0.06368688029101771, "compression_ratio": 1.7625899280575539, "no_speech_prob": 2.4391756596742198e-05}, {"id": 298, "seek": 150936, "start": 1525.04, "end": 1528.8, "text": " but notice the omission of the units these are not units in milliseconds these are weights in", "tokens": [457, 3449, 264, 3406, 3106, 295, 264, 6815, 613, 366, 406, 6815, 294, 34184, 613, 366, 17443, 294], "temperature": 0.0, "avg_logprob": -0.06368688029101771, "compression_ratio": 1.7625899280575539, "no_speech_prob": 2.4391756596742198e-05}, {"id": 299, "seek": 150936, "start": 1528.8, "end": 1534.6399999999999, "text": " a similar way to how we do cpu scheduling so how do we know what 40 60 or 100 mean in this context", "tokens": [257, 2531, 636, 281, 577, 321, 360, 269, 34859, 29055, 370, 577, 360, 321, 458, 437, 3356, 4060, 420, 2319, 914, 294, 341, 4319], "temperature": 0.0, "avg_logprob": -0.06368688029101771, "compression_ratio": 1.7625899280575539, "no_speech_prob": 2.4391756596742198e-05}, {"id": 300, "seek": 153464, "start": 1534.64, "end": 1539.44, "text": " well they add up to 200 so the idea is if you are saturating your disk you know best effort", "tokens": [731, 436, 909, 493, 281, 2331, 370, 264, 1558, 307, 498, 291, 366, 21160, 990, 428, 12355, 291, 458, 1151, 4630], "temperature": 0.0, "avg_logprob": -0.10174925981369694, "compression_ratio": 1.806083650190114, "no_speech_prob": 1.8828377505997196e-05}, {"id": 301, "seek": 153464, "start": 1539.44, "end": 1545.76, "text": " outside will get 40 will get i guess 20 percent of of the work it'll workload one will get 50", "tokens": [2380, 486, 483, 3356, 486, 483, 741, 2041, 945, 3043, 295, 295, 264, 589, 309, 603, 20139, 472, 486, 483, 2625], "temperature": 0.0, "avg_logprob": -0.10174925981369694, "compression_ratio": 1.806083650190114, "no_speech_prob": 1.8828377505997196e-05}, {"id": 302, "seek": 153464, "start": 1545.76, "end": 1551.2800000000002, "text": " and workload two will get 30 so it balances out based on this kind of shares or weights like model", "tokens": [293, 20139, 732, 486, 483, 2217, 370, 309, 33993, 484, 2361, 322, 341, 733, 295, 12182, 420, 17443, 411, 2316], "temperature": 0.0, "avg_logprob": -0.10174925981369694, "compression_ratio": 1.806083650190114, "no_speech_prob": 1.8828377505997196e-05}, {"id": 303, "seek": 153464, "start": 1552.88, "end": 1557.5200000000002, "text": " how do we know when we reach this 100 percent of saturation though so what i o dot cost does is", "tokens": [577, 360, 321, 458, 562, 321, 2524, 341, 2319, 3043, 295, 27090, 1673, 370, 437, 741, 277, 5893, 2063, 775, 307], "temperature": 0.0, "avg_logprob": -0.10174925981369694, "compression_ratio": 1.806083650190114, "no_speech_prob": 1.8828377505997196e-05}, {"id": 304, "seek": 153464, "start": 1557.5200000000002, "end": 1561.76, "text": " build a linear model of your disk over time it sees how the disk responds these variable loads", "tokens": [1322, 257, 8213, 2316, 295, 428, 12355, 670, 565, 309, 8194, 577, 264, 12355, 27331, 613, 7006, 12668], "temperature": 0.0, "avg_logprob": -0.10174925981369694, "compression_ratio": 1.806083650190114, "no_speech_prob": 1.8828377505997196e-05}, {"id": 305, "seek": 156176, "start": 1561.76, "end": 1566.4, "text": " passively and it works based on things like you know read or write i o whether it's random or", "tokens": [1320, 3413, 293, 309, 1985, 2361, 322, 721, 411, 291, 458, 1401, 420, 2464, 741, 277, 1968, 309, 311, 4974, 420], "temperature": 0.0, "avg_logprob": -0.08385662271195099, "compression_ratio": 1.7765567765567765, "no_speech_prob": 4.254901796230115e-05}, {"id": 306, "seek": 156176, "start": 1566.4, "end": 1571.04, "text": " sequential the size of the i o so it boils down this quite complex operation of you know how much", "tokens": [42881, 264, 2744, 295, 264, 741, 277, 370, 309, 35049, 760, 341, 1596, 3997, 6916, 295, 291, 458, 577, 709], "temperature": 0.0, "avg_logprob": -0.08385662271195099, "compression_ratio": 1.7765567765567765, "no_speech_prob": 4.254901796230115e-05}, {"id": 307, "seek": 156176, "start": 1571.04, "end": 1578.24, "text": " can my disk actually do into a linear model which it which it handles itself it has a kind of a q", "tokens": [393, 452, 12355, 767, 360, 666, 257, 8213, 2316, 597, 309, 597, 309, 18722, 2564, 309, 575, 257, 733, 295, 257, 9505], "temperature": 0.0, "avg_logprob": -0.08385662271195099, "compression_ratio": 1.7765567765567765, "no_speech_prob": 4.254901796230115e-05}, {"id": 308, "seek": 156176, "start": 1578.24, "end": 1582.72, "text": " s model you can implement but there's also a basic on the fly model using q depth so you can read", "tokens": [262, 2316, 291, 393, 4445, 457, 456, 311, 611, 257, 3875, 322, 264, 3603, 2316, 1228, 9505, 7161, 370, 291, 393, 1401], "temperature": 0.0, "avg_logprob": -0.08385662271195099, "compression_ratio": 1.7765567765567765, "no_speech_prob": 4.254901796230115e-05}, {"id": 309, "seek": 156176, "start": 1582.72, "end": 1586.16, "text": " more about it in the links at the bottom i won't waffle on too much but it is something which you", "tokens": [544, 466, 309, 294, 264, 6123, 412, 264, 2767, 741, 1582, 380, 44328, 322, 886, 709, 457, 309, 307, 746, 597, 291], "temperature": 0.0, "avg_logprob": -0.08385662271195099, "compression_ratio": 1.7765567765567765, "no_speech_prob": 4.254901796230115e-05}, {"id": 310, "seek": 158616, "start": 1586.16, "end": 1592.0, "text": " can use to do kind of effective i o control in the old days i came to this room and talked about", "tokens": [393, 764, 281, 360, 733, 295, 4942, 741, 277, 1969, 294, 264, 1331, 1708, 741, 1361, 281, 341, 1808, 293, 2825, 466], "temperature": 0.0, "avg_logprob": -0.10447389296902955, "compression_ratio": 1.8877887788778878, "no_speech_prob": 0.00036073412047699094}, {"id": 311, "seek": 158616, "start": 1592.0, "end": 1596.24, "text": " secret b2 and the historical response was basically that's nice docker doesn't support it though so", "tokens": [4054, 272, 17, 293, 264, 8584, 4134, 390, 1936, 300, 311, 1481, 360, 9178, 1177, 380, 1406, 309, 1673, 370], "temperature": 0.0, "avg_logprob": -0.10447389296902955, "compression_ratio": 1.8877887788778878, "no_speech_prob": 0.00036073412047699094}, {"id": 312, "seek": 158616, "start": 1596.24, "end": 1602.72, "text": " please leave um i've had a nice chat with some docker lutz uh no the docker people are very nice", "tokens": [1767, 1856, 1105, 741, 600, 632, 257, 1481, 5081, 365, 512, 360, 9178, 287, 12950, 2232, 572, 264, 360, 9178, 561, 366, 588, 1481], "temperature": 0.0, "avg_logprob": -0.10447389296902955, "compression_ratio": 1.8877887788778878, "no_speech_prob": 0.00036073412047699094}, {"id": 313, "seek": 158616, "start": 1602.72, "end": 1606.88, "text": " and so are all the other container people and what's happened is we have it almost everywhere", "tokens": [293, 370, 366, 439, 264, 661, 10129, 561, 293, 437, 311, 2011, 307, 321, 362, 309, 1920, 5315], "temperature": 0.0, "avg_logprob": -0.10447389296902955, "compression_ratio": 1.8877887788778878, "no_speech_prob": 0.00036073412047699094}, {"id": 314, "seek": 158616, "start": 1606.88, "end": 1610.72, "text": " almost everywhere secret b2 is a thing we have quite a diversity of container run time some", "tokens": [1920, 5315, 4054, 272, 17, 307, 257, 551, 321, 362, 1596, 257, 8811, 295, 10129, 1190, 565, 512], "temperature": 0.0, "avg_logprob": -0.10447389296902955, "compression_ratio": 1.8877887788778878, "no_speech_prob": 0.00036073412047699094}, {"id": 315, "seek": 158616, "start": 1610.72, "end": 1614.64, "text": " police report is basically supported everywhere um so even if nothing changes from your side", "tokens": [3804, 2275, 307, 1936, 8104, 5315, 1105, 370, 754, 498, 1825, 2962, 490, 428, 1252], "temperature": 0.0, "avg_logprob": -0.10447389296902955, "compression_ratio": 1.8877887788778878, "no_speech_prob": 0.00036073412047699094}, {"id": 316, "seek": 161464, "start": 1614.64, "end": 1618.48, "text": " moving to secret b2 means that you know you get significantly more reliable accounting for free", "tokens": [2684, 281, 4054, 272, 17, 1355, 300, 291, 458, 291, 483, 10591, 544, 12924, 19163, 337, 1737], "temperature": 0.0, "avg_logprob": -0.08679594993591308, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.00016202498227357864}, {"id": 317, "seek": 161464, "start": 1619.1200000000001, "end": 1623.8400000000001, "text": " we spent quite a while working with docker and system defoaks and so on and so forth to get", "tokens": [321, 4418, 1596, 257, 1339, 1364, 365, 360, 9178, 293, 1185, 1060, 78, 5461, 293, 370, 322, 293, 370, 5220, 281, 483], "temperature": 0.0, "avg_logprob": -0.08679594993591308, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.00016202498227357864}, {"id": 318, "seek": 161464, "start": 1623.8400000000001, "end": 1627.76, "text": " things working and we're also really thankful to fedora for making secret b2 the default since", "tokens": [721, 1364, 293, 321, 434, 611, 534, 13611, 281, 4636, 3252, 337, 1455, 4054, 272, 17, 264, 7576, 1670], "temperature": 0.0, "avg_logprob": -0.08679594993591308, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.00016202498227357864}, {"id": 319, "seek": 161464, "start": 1627.76, "end": 1633.3600000000001, "text": " fedora 32 as well as making things more reliable behind the scenes for users this also you know", "tokens": [4636, 3252, 8858, 382, 731, 382, 1455, 721, 544, 12924, 2261, 264, 8026, 337, 5022, 341, 611, 291, 458], "temperature": 0.0, "avg_logprob": -0.08679594993591308, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.00016202498227357864}, {"id": 320, "seek": 161464, "start": 1633.3600000000001, "end": 1637.8400000000001, "text": " got some people's ass into gear when they had an issue on their github on their github that says it", "tokens": [658, 512, 561, 311, 1256, 666, 7394, 562, 436, 632, 364, 2734, 322, 641, 290, 355, 836, 322, 641, 290, 355, 836, 300, 1619, 309], "temperature": 0.0, "avg_logprob": -0.08679594993591308, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.00016202498227357864}, {"id": 321, "seek": 161464, "start": 1637.8400000000001, "end": 1642.48, "text": " doesn't work in fedora so cheers fedora people uh it was a kind of a good signal that you know this", "tokens": [1177, 380, 589, 294, 4636, 3252, 370, 15301, 4636, 3252, 561, 2232, 309, 390, 257, 733, 295, 257, 665, 6358, 300, 291, 458, 341], "temperature": 0.0, "avg_logprob": -0.08679594993591308, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.00016202498227357864}, {"id": 322, "seek": 164248, "start": 1642.48, "end": 1646.96, "text": " is what we are actually doing this is what we as an industry as a as a technology community are", "tokens": [307, 437, 321, 366, 767, 884, 341, 307, 437, 321, 382, 364, 3518, 382, 257, 382, 257, 2899, 1768, 366], "temperature": 0.0, "avg_logprob": -0.1281845549906581, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.00028828802169300616}, {"id": 323, "seek": 164248, "start": 1646.96, "end": 1653.1200000000001, "text": " actually doing uh and that was quite helpful the kd and gnom folks have also been busy using cgroups", "tokens": [767, 884, 2232, 293, 300, 390, 1596, 4961, 264, 350, 67, 293, 290, 15819, 4024, 362, 611, 668, 5856, 1228, 269, 17377, 82], "temperature": 0.0, "avg_logprob": -0.1281845549906581, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.00028828802169300616}, {"id": 324, "seek": 164248, "start": 1653.1200000000001, "end": 1657.84, "text": " to give uh a better management of that kind of desktop handling david edmundson and henry chain", "tokens": [281, 976, 2232, 257, 1101, 4592, 295, 300, 733, 295, 14502, 13175, 11753, 327, 1257, 35578, 3015, 293, 22253, 627, 5021], "temperature": 0.0, "avg_logprob": -0.1281845549906581, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.00028828802169300616}, {"id": 325, "seek": 164248, "start": 1657.84, "end": 1663.3600000000001, "text": " from kd in particular gave this talk at kd academy the title of talk was using cgroups to make", "tokens": [490, 350, 67, 294, 1729, 2729, 341, 751, 412, 350, 67, 25525, 264, 4876, 295, 751, 390, 1228, 269, 17377, 82, 281, 652], "temperature": 0.0, "avg_logprob": -0.1281845549906581, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.00028828802169300616}, {"id": 326, "seek": 164248, "start": 1663.3600000000001, "end": 1668.8, "text": " everything amazing now i'm not brazen enough to title my talk that but i'll just let it speak for", "tokens": [1203, 2243, 586, 741, 478, 406, 1548, 2904, 1547, 281, 4876, 452, 751, 300, 457, 741, 603, 445, 718, 309, 1710, 337], "temperature": 0.0, "avg_logprob": -0.1281845549906581, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.00028828802169300616}, {"id": 327, "seek": 166880, "start": 1668.8, "end": 1674.24, "text": " itself for their one um it basically goes over the use of cgroups and c v2 for resource control", "tokens": [2564, 337, 641, 472, 1105, 309, 1936, 1709, 670, 264, 764, 295, 269, 17377, 82, 293, 269, 371, 17, 337, 7684, 1969], "temperature": 0.0, "avg_logprob": -0.09229187702569436, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010046324314316735}, {"id": 328, "seek": 166880, "start": 1674.24, "end": 1678.3999999999999, "text": " and for interactive responsiveness on the desktop um so this is definitely kind of a developing", "tokens": [293, 337, 15141, 2914, 8477, 322, 264, 14502, 1105, 370, 341, 307, 2138, 733, 295, 257, 6416], "temperature": 0.0, "avg_logprob": -0.09229187702569436, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010046324314316735}, {"id": 329, "seek": 166880, "start": 1678.3999999999999, "end": 1682.1599999999999, "text": " space obviously there's been a lot of work on the server side here um but if you're interested in", "tokens": [1901, 2745, 456, 311, 668, 257, 688, 295, 589, 322, 264, 7154, 1252, 510, 1105, 457, 498, 291, 434, 3102, 294], "temperature": 0.0, "avg_logprob": -0.09229187702569436, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010046324314316735}, {"id": 330, "seek": 166880, "start": 1682.1599999999999, "end": 1686.48, "text": " that i definitely recommend you know giving the talk a watch it really goes into challenges they", "tokens": [300, 741, 2138, 2748, 291, 458, 2902, 264, 751, 257, 1159, 309, 534, 1709, 666, 4759, 436], "temperature": 0.0, "avg_logprob": -0.09229187702569436, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010046324314316735}, {"id": 331, "seek": 166880, "start": 1686.48, "end": 1692.3999999999999, "text": " had and then unique features c v2 has to solve those finally android is also using the metrics", "tokens": [632, 293, 550, 3845, 4122, 269, 371, 17, 575, 281, 5039, 729, 2721, 36157, 307, 611, 1228, 264, 16367], "temperature": 0.0, "avg_logprob": -0.09229187702569436, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010046324314316735}, {"id": 332, "seek": 166880, "start": 1692.3999999999999, "end": 1697.2, "text": " exported by the psi project in order to detect and prevent memory pressure events which affect the", "tokens": [42055, 538, 264, 20304, 1716, 294, 1668, 281, 5531, 293, 4871, 4675, 3321, 3931, 597, 3345, 264], "temperature": 0.0, "avg_logprob": -0.09229187702569436, "compression_ratio": 1.7575757575757576, "no_speech_prob": 0.00010046324314316735}, {"id": 333, "seek": 169720, "start": 1697.2, "end": 1701.92, "text": " user experience as you can imagine on android interactive latency is extremely important", "tokens": [4195, 1752, 382, 291, 393, 3811, 322, 36157, 15141, 27043, 307, 4664, 1021], "temperature": 0.0, "avg_logprob": -0.06547774841536337, "compression_ratio": 1.8085714285714285, "no_speech_prob": 0.0001275512477150187}, {"id": 334, "seek": 169720, "start": 1701.92, "end": 1704.96, "text": " you don't it would really suck if you're about to click a button and then you click it and that", "tokens": [291, 500, 380, 309, 576, 534, 9967, 498, 291, 434, 466, 281, 2052, 257, 2960, 293, 550, 291, 2052, 309, 293, 300], "temperature": 0.0, "avg_logprob": -0.06547774841536337, "compression_ratio": 1.8085714285714285, "no_speech_prob": 0.0001275512477150187}, {"id": 335, "seek": 169720, "start": 1704.96, "end": 1708.88, "text": " requires allocating memory and the whole phone freezes i mean it does still happen sometimes", "tokens": [7029, 12660, 990, 4675, 293, 264, 1379, 2593, 1737, 12214, 741, 914, 309, 775, 920, 1051, 2171], "temperature": 0.0, "avg_logprob": -0.06547774841536337, "compression_ratio": 1.8085714285714285, "no_speech_prob": 0.0001275512477150187}, {"id": 336, "seek": 169720, "start": 1708.88, "end": 1712.32, "text": " but obviously this is something which which they're trying to work on and we've been working", "tokens": [457, 2745, 341, 307, 746, 597, 597, 436, 434, 1382, 281, 589, 322, 293, 321, 600, 668, 1364], "temperature": 0.0, "avg_logprob": -0.06547774841536337, "compression_ratio": 1.8085714285714285, "no_speech_prob": 0.0001275512477150187}, {"id": 337, "seek": 169720, "start": 1712.32, "end": 1716.56, "text": " quite closely with them to integrate the psi uh project into the into android", "tokens": [1596, 8185, 365, 552, 281, 13365, 264, 20304, 2232, 1716, 666, 264, 666, 36157], "temperature": 0.0, "avg_logprob": -0.06547774841536337, "compression_ratio": 1.8085714285714285, "no_speech_prob": 0.0001275512477150187}, {"id": 338, "seek": 169720, "start": 1718.4, "end": 1721.68, "text": " hopefully this talk gave you some ideas about things you'd like to try out for yourself um", "tokens": [4696, 341, 751, 2729, 291, 512, 3487, 466, 721, 291, 1116, 411, 281, 853, 484, 337, 1803, 1105], "temperature": 0.0, "avg_logprob": -0.06547774841536337, "compression_ratio": 1.8085714285714285, "no_speech_prob": 0.0001275512477150187}, {"id": 339, "seek": 169720, "start": 1721.68, "end": 1725.92, "text": " we're still very actively improving uh kernel resource control it might have been seven years", "tokens": [321, 434, 920, 588, 13022, 11470, 2232, 28256, 7684, 1969, 309, 1062, 362, 668, 3407, 924], "temperature": 0.0, "avg_logprob": -0.06547774841536337, "compression_ratio": 1.8085714285714285, "no_speech_prob": 0.0001275512477150187}, {"id": 340, "seek": 172592, "start": 1725.92, "end": 1730.0800000000002, "text": " since we started but you know we still have plenty of things we want to do and what we really need", "tokens": [1670, 321, 1409, 457, 291, 458, 321, 920, 362, 7140, 295, 721, 321, 528, 281, 360, 293, 437, 321, 534, 643], "temperature": 0.0, "avg_logprob": -0.061831910089151745, "compression_ratio": 1.9939759036144578, "no_speech_prob": 0.00042672568815760314}, {"id": 341, "seek": 172592, "start": 1730.0800000000002, "end": 1735.1200000000001, "text": " is your feedback what we really need is more examples of uh how the community is using c v2", "tokens": [307, 428, 5824, 437, 321, 534, 643, 307, 544, 5110, 295, 2232, 577, 264, 1768, 307, 1228, 269, 371, 17], "temperature": 0.0, "avg_logprob": -0.061831910089151745, "compression_ratio": 1.9939759036144578, "no_speech_prob": 0.00042672568815760314}, {"id": 342, "seek": 172592, "start": 1735.1200000000001, "end": 1738.88, "text": " and problems and issues you've encountered um obviously everyone's needs are quite different", "tokens": [293, 2740, 293, 2663, 291, 600, 20381, 1105, 2745, 1518, 311, 2203, 366, 1596, 819], "temperature": 0.0, "avg_logprob": -0.061831910089151745, "compression_ratio": 1.9939759036144578, "no_speech_prob": 0.00042672568815760314}, {"id": 343, "seek": 172592, "start": 1738.88, "end": 1743.04, "text": " and i and others are quite eager to know what we could be doing to help you what we could be doing", "tokens": [293, 741, 293, 2357, 366, 1596, 18259, 281, 458, 437, 321, 727, 312, 884, 281, 854, 291, 437, 321, 727, 312, 884], "temperature": 0.0, "avg_logprob": -0.061831910089151745, "compression_ratio": 1.9939759036144578, "no_speech_prob": 0.00042672568815760314}, {"id": 344, "seek": 172592, "start": 1743.04, "end": 1746.24, "text": " to make things better what we could be doing to make things more intuitive because there's", "tokens": [281, 652, 721, 1101, 437, 321, 727, 312, 884, 281, 652, 721, 544, 21769, 570, 456, 311], "temperature": 0.0, "avg_logprob": -0.061831910089151745, "compression_ratio": 1.9939759036144578, "no_speech_prob": 0.00042672568815760314}, {"id": 345, "seek": 172592, "start": 1746.24, "end": 1749.28, "text": " definitely work to be done there and i'll be around after the talk if you want to chat but", "tokens": [2138, 589, 281, 312, 1096, 456, 293, 741, 603, 312, 926, 934, 264, 751, 498, 291, 528, 281, 5081, 457], "temperature": 0.0, "avg_logprob": -0.061831910089151745, "compression_ratio": 1.9939759036144578, "no_speech_prob": 0.00042672568815760314}, {"id": 346, "seek": 172592, "start": 1749.28, "end": 1754.0, "text": " feel free to drop me an email message me on mastodon always happy to hear feedback or suggestions", "tokens": [841, 1737, 281, 3270, 385, 364, 3796, 3636, 385, 322, 27055, 378, 266, 1009, 2055, 281, 1568, 5824, 420, 13396], "temperature": 0.0, "avg_logprob": -0.061831910089151745, "compression_ratio": 1.9939759036144578, "no_speech_prob": 0.00042672568815760314}, {"id": 347, "seek": 175400, "start": 1754.0, "end": 1758.72, "text": " um i've been chris down and this has been seven years of c at c review to future of", "tokens": [1105, 741, 600, 668, 417, 5714, 760, 293, 341, 575, 668, 3407, 924, 295, 269, 412, 269, 3131, 281, 2027, 295], "temperature": 0.0, "avg_logprob": -0.3416748335867217, "compression_ratio": 1.2352941176470589, "no_speech_prob": 0.0002057146921288222}, {"id": 348, "seek": 175872, "start": 1758.72, "end": 1784.64, "text": " Linux resource control thank you very much", "tokens": [50364, 18734, 7684, 1969, 1309, 291, 588, 709, 51660], "temperature": 0.0, "avg_logprob": -0.4190023422241211, "compression_ratio": 0.84, "no_speech_prob": 4.246649405104108e-05}], "language": "en"}