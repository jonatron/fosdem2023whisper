{"text": " Hi, everybody. Yes. So, talk about debug packages and distributing debug packages today. So, my name is Morten Lindr\u00f6. I go by the nickname of Fox Brown on the Internet. I have been a contributor to the Arch Linux distribution since 2016. I'm doing sort of open source development since 2013. I do sort of security teamwork, re-use the builds. My care is sort of about usable security, supply chain security and all of that stuff and a lot of secure boots. But today I'm going to talk about what I've been spending sort of two years of my life working on, which is debug packages in Arch Linux. So, in the skills correctly. So, one of the sort of, normally when you sort of get some crashes at some point, you will see this fancy little stack trace. And if you use systemd, you will at some point have the crash handlers getting you the seg faults, which happens. And then you can sort of just debug this with GDB. And if you do look at the backtrace, you just see nonsense. There's nothing here that makes sense at all. You can't figure out what happened. You don't know what crashed. And you have no idea. So, if you actually do this on an Arch Linux system today, what you'll actually see is not that nonsense backtrace. You'll instead see, no, let's cross Y. And you'll instead get this, which has a lot more information. You'll see what happened, what crashed it. You'll get all the symbols. And you did nothing. You did not download any debug packages. You didn't think about it. You just happened behind the scenes. And if we ask what actually happened, you'll see that there's some internal syscall that crashed it. So, this is super nice. This is a lot better than sort of what the debugging experience has been on Arch Linux previously. And it took me, I don't know, three years, two and a half years implementing a little bit on and off. So, why do we care about debug packages? So, if we, for instance, have Pacman, which is a fairly sort of simple and small binary, it's like half a meg of size if you build it. But if you strip away all the debug information, you can almost half the size, which is nice. So, if you don't need all of that information on your disk, it's nice to sort of have some space savings. And in more like extreme cases, like in KeyCAD, had some sole name inside of Python, it's like half a gig. And if you strip away the debug information, it's 33 megabytes. It's sort of nice to sort of have the opportunities to sort of debug all of this. And this can all be sort of very large. So, what people do instead is that GDB implements what we call detached debug symbols. And that allows us to sort of separate out the debug symbols from the binaries and sort of re-link it together on the system. And one of the key elements for this is this fancy little build ID, which gets stamped into every binary on your system. And we use that to sort of link. We define the build ID. We can make some standard directory on your system. We can split out the debug symbols from the binary, move it to that directory, add some debug link to the binary, and everything just works. It will be as if the binary was, as the debug sections were still on the binaries. This is nice. And this is sort of what Debian, Ubuntu, Fedora, all of them do to make those debug packages. And that's nice. But one of the things that you saw in the demonstration is that we also have the source code of the binaries. And that's more of a hack which some distributions have support for and some distribution doesn't support. So Debian, Ubuntu does not have source listings, I believe, while Fedora, SUSE, and now Arch as well has source listings. And the way this sort of works is sort of you do a little bit of hacking. So if we build Pacman just normally and we run GDB on it and we ask what the sources were, you'll have your embedded project path in those binaries. So what you can do then instead is to use debug edit. Historically, this has been part of the RPM upstream. So Pacman didn't want to have a dependency on RPM to support debug packages, which is a bit weird. But this was split out now into a separate project in back in 2001, no, yeah, 2021, which is now a separate project, which is quite nice, and it makes more sort of accessible for other package managers. So instead of sort of using the current working directory to embed stuff, we can rewrite all of those paths inside the binary to some standard path on the file system. So in Arch, we use source debug and then we do name spacing so we can have sources from multiple versions of Pacman. And if you sort of do these DOMs, you'll have rewritten all of those source listings, which is part of the binary, which is super nice. And then you can sort of get all the source code associated with binary. So before debug edit was available as a sort of normal thing, Pacman also had support for source listings, but he didn't use debug edit. He decided to use awk instead. So he then tried to parse out all of the file paths, I don't know, from read-off, try to figure out whatever was there and sort of try to get it out. And this worked for, like, simple C programs, but if you threw like a rush to go at it, it had no clue what that was at all. So it was a hack. It worked. It was in the source code for, I don't know, six years maybe. So I ripped that out last year. So this, yes. So when these packages get built and you have the debug symbols and have all of the source listings, we can then sort of compile all of this to some package and then distribute it to our distributions. So all our packages in Arch Linux goes to this repo.archin.org, which is a tier zero mirror. That's where all the packages gets distributed from to all our mirrors. And on this, there's two package pools. There is from corn extra. There's a package. Just flash debug pool. And for community, there's, okay, there's a big community's dashboard debug, not packages. But these can be fetched and distributed to all mirrors, but it's a huge amount of packages. So what we do instead is that we are synced over this to something called a debug info instance we have, which allows us to do fetch everything over HTTP instead. So debug info is a very cool microservice which is capable of getting you the source code and the symbols from binaries over HTTP. So you don't have to think about which debug packages do you need, which one do you have to download to get full backtrace. We can just point GDB at this instance and it will just fetch everything for us, which is quite nice. So it's written, maintained by the ELF maintenance. It's a web server in C in the year 2020. So it's running on, like, I think a few distributions, like, I think Boyd Linux has one, Debian has one, Debian and Ubuntu got one past six months. And there's Fedora and SUSE also has several of these. So it's super simple. We can just use the debug info. We can give it that this is some tar archives that you want to parse and give it a package pool. And we just set the debug info URLs variable and then we can run GDB on the binaries and it works. That's all you have to do to sort of make GDB read those files instead of having to distribute them. So, yes. And then you can have this debug info find command line thing to fetch stuff for you or you can use it as a library instead. But yeah. So running a web server in C in 2020 is, you know, a little bit iffy. So we sort of wrote this, distributed this in sort of this hardware system file. So if something gets exploited or something happening in that C code, you never know. It's still sort of only really contained to some fairly restrictive set of policies. So you can't ask your privileges, you can't really write anything to the system. But you can sort of just read stuff, which is quite nice. So the only really two paths this has access to on our sort of in production system is just these two package pools and some cache directory and sort of that's everything it sees. So that's fairly quite nice. Been planning to upstream it. And I think you bumped into and Debian uses this as well, but it's an extremely properly yet sadly. So, you know, we have debug packages, we distribute it, people can use them, but we can also parse metrics from people accessing this server. So I spent a little bit of time. Look what you're how this vendors. Yeah. Okay. It does not like that. I don't know. I can't zoom out. I hate this. So, so what you sort of see here is just some basic statistics. So what people have been doing on it, we enabled debug packages for all our packages fairly recently this year. So that's why you see the biggest corpus spike going straight up because we have more symbols now. But you also see that we reached two terabytes of data being sent out to different users the past month. So that's the last 30 days with two terabytes out. And you can see some statistics on how much data people are fetching the errors from through but statistics is sort of quite nice. And you sort of get this from free from hosting it. Yes. So all of this infrastructure that's been put up in Arch, of course, is all open source. There's no proprietary infrastructure. There's no hidden files. So all the stuff we use to distribute debug info is all in our infrastructure repository under the roles of debug info. That's sort of how we fetch all of the packages, how we do the service management stuff, and all of those things. Yes. So I'll probably have more time. Yes. So one of the things I also did because, you know, debug packages is usually done on C applications and stuff, but I don't actually know C. I do Python and Go instead. So what I also spent a lot of time on doing is to sort of try to get better debug info support in Go because that's cool. So here, just to sort of give an example, here we're going to crash the tail scale SSH client because that's a nice example, I think. So this instructed the Go compiler to actually give us a core dump. And then we can use the delve debugger in Go. And it actually, with a few patches, is able to read out all the debug symbols, all of the source code, which is fetched from the debug info server as well, which is quite nice as it will give us the more opportunities to sort of debug Go applications. It also works on Rust. It also works on Julia and whatever sort of programming languages you want. Which is quite nice. So it's sort of an improvement for the entire ecosystem as well. Yes. That was it. I'll have a lot of time for questions if anybody has anything. So I'm wondering what you actually store for the source. Is it the build tree or are you trying to remove some things to save storage? Because, I mean, you have like a package, you have an upstream source, you have patches on top of the upstream source, and then maybe even the build process might generate sources itself. Yes. So I don't quite know how, but this is just a binary, which sort of dwarf generates the source listing as part of the dwarf metadata, I think. So this is all the, there's some generated optimized out sources, I think, and there's some sort of things that points around to different sources, but it will mostly just be sort of the patched up, generated, done sources, which gets embedded there. So it's, the source listing is a nice bonus, but it's not necessarily some would normally be distributing with the binary. That answers the question. Yes. Any more questions? Thanks for using it. Could you upstream the system deservers files? Yes, it's been a moment to do this for a long time. It's a little bit problematic though, because you don't need to figure out sort of how the paths and stuff needs to get into the service file with some configuration file, but it can probably be done. And I think that there will be people use it as well. Yes, it should be upstreamed. Yes. Yeah. So, and we normally hide the HB server behind the proxy. Yes. It's written in C++ if that helps. Yeah, no, yes. It's actually C++ is not C. It's all the elf stuff that's mostly written in C, I think. Yeah, so it's a C++ program that uses Lib, micro, HBD, and SQLite to store our other data. Yeah. So we have it behind the reverse proxy to sort of get the TLS configuration going and outside, but we also just warranted the hardening there because it's just, it's easy with system D to just get the hardening there. So it's no reason to sort of not do it. So it's quite nice, but I'll try to upstream it. Thanks. Yes. Are those statistics on your dashboard pulled from the HTTP server he was describing? Are those from like your Nginx or whatever proxy you're using? What? Sorry. Are the statistics you had on your dashboard earlier? Yes. Are those pulled from the back end? Or are they from like a proxy in front? So the debug info has a slash metrics, which is all Promtail. So it just exports a bunch of metrics and you just point Promtail from it and it will just parse it. So that dashboard is something we made internally, which I just spent two weeks making, and that's also open source. So you can just fetch the JSON file for the dashboard on the Grafana and everything there is all sort of open. So you can go look at it. But it's all, it's just this sort of slash metrics endpoint of debug info. So the Red Hat people actually watches this for all the debug info servers that has been employed and they can like look at the statistics and errors from all of different servers and see how the traffic between all of those are sort of how much is Fedora distributing compared to Arch and stuff, which is quite nice. That was not public, I think. But yeah, it's cool. Can you tell us a bit about the requirements in terms of storage? Because I recently looked at another distribution and they didn't build all the packages because of lack of storage. So that's what I'm trying to figure out now because we enabled debug symbols for all the packages, but they're not currently distributing it to our mirrors. So Arch, the total mirror size for Arch is like 60, 70, 80 gigabytes, I think, of data. But I assume like that would be several hundreds if we actually upload all the debug packages. But I think Fedora in total is like three, four terabytes or something. So I assume it will go inside three, four times and stuff. I know like the LLVMD stuff is like a two gigabyte package, I think, with symbols and people try to optimize it a little bit so you get a better, faster to upload. So it's, yeah, one sort of main issue with debug edit and sort of debug info and stuff is that you have, Dwarf 5 has support for compressed sections, but debug edit does not understand the compressed sections. So you have to decompress the sections before you leave out the paths and there's no good way to sort of recompress everything again. So getting better support for sort of compressed Dwarf info would sort of help fix a few of those sort of space requirements, I think, on the mirrors. Can I ask another question? Is there work on the duplication instead of compression? Because you have different version of packages as well. So it's not that relevant for ours because we don't keep those versions and we don't really do delta files on the packages. So on the arch side of things I don't think that's really relevant for us, but I don't know. It could probably be done at some level, at least for like Fedora or Debian that keeps multiple versions of the same package. A small question, for which architectors are you generating those debug info binaries? So arch only really supports x8664. We don't really have any other architectures. But because we have the 32-bit port and we have the ARM people and I think they're just pulling our packages and probably building debug in full for them, but arch itself is not really distributing anything else on x8664 currently. So you mentioned different architectures. Do you know if there's plan to upstream the booking for D and in general risk five because I know Felix Yan is working on this? Yes, I know Felix is working on it. We want to, this is more an arch thing, but we don't have traditional build farm server setup. So it's a bit hard for us to do multiple architectures because one package maintainer has to build that package for each architecture. So currently we want to have support for more architectures and better support like V2, V3, V4 versions of X that you see now supporting. But you currently haven't really solved that in a good way currently. Okay, thanks. Thanks. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.36, "text": " Hi, everybody. Yes. So, talk about debug packages and", "tokens": [2421, 11, 2201, 13, 1079, 13, 407, 11, 751, 466, 24083, 17401, 293], "temperature": 0.0, "avg_logprob": -0.35632107257843015, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.427001953125}, {"id": 1, "seek": 0, "start": 12.36, "end": 18.2, "text": " distributing debug packages today. So, my name is Morten Lindr\u00f6. I go by the nickname", "tokens": [41406, 24083, 17401, 965, 13, 407, 11, 452, 1315, 307, 24977, 268, 16828, 81, 973, 13, 286, 352, 538, 264, 21641], "temperature": 0.0, "avg_logprob": -0.35632107257843015, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.427001953125}, {"id": 2, "seek": 0, "start": 18.2, "end": 22.32, "text": " of Fox Brown on the Internet. I have been a contributor to the Arch Linux distribution", "tokens": [295, 11388, 8030, 322, 264, 7703, 13, 286, 362, 668, 257, 42859, 281, 264, 10984, 18734, 7316], "temperature": 0.0, "avg_logprob": -0.35632107257843015, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.427001953125}, {"id": 3, "seek": 0, "start": 22.32, "end": 29.72, "text": " since 2016. I'm doing sort of open source development since 2013. I do sort of security", "tokens": [1670, 6549, 13, 286, 478, 884, 1333, 295, 1269, 4009, 3250, 1670, 9012, 13, 286, 360, 1333, 295, 3825], "temperature": 0.0, "avg_logprob": -0.35632107257843015, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.427001953125}, {"id": 4, "seek": 2972, "start": 29.72, "end": 34.08, "text": " teamwork, re-use the builds. My care is sort of about usable security, supply chain security", "tokens": [30015, 11, 319, 12, 438, 264, 15182, 13, 1222, 1127, 307, 1333, 295, 466, 29975, 3825, 11, 5847, 5021, 3825], "temperature": 0.0, "avg_logprob": -0.27660323761321687, "compression_ratio": 1.5625, "no_speech_prob": 6.556117295986041e-05}, {"id": 5, "seek": 2972, "start": 34.08, "end": 40.76, "text": " and all of that stuff and a lot of secure boots. But today I'm going to talk about", "tokens": [293, 439, 295, 300, 1507, 293, 257, 688, 295, 7144, 15194, 13, 583, 965, 286, 478, 516, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.27660323761321687, "compression_ratio": 1.5625, "no_speech_prob": 6.556117295986041e-05}, {"id": 6, "seek": 2972, "start": 40.76, "end": 45.6, "text": " what I've been spending sort of two years of my life working on, which is debug packages", "tokens": [437, 286, 600, 668, 6434, 1333, 295, 732, 924, 295, 452, 993, 1364, 322, 11, 597, 307, 24083, 17401], "temperature": 0.0, "avg_logprob": -0.27660323761321687, "compression_ratio": 1.5625, "no_speech_prob": 6.556117295986041e-05}, {"id": 7, "seek": 2972, "start": 45.6, "end": 54.480000000000004, "text": " in Arch Linux. So, in the skills correctly. So, one of the sort of, normally when you", "tokens": [294, 10984, 18734, 13, 407, 11, 294, 264, 3942, 8944, 13, 407, 11, 472, 295, 264, 1333, 295, 11, 5646, 562, 291], "temperature": 0.0, "avg_logprob": -0.27660323761321687, "compression_ratio": 1.5625, "no_speech_prob": 6.556117295986041e-05}, {"id": 8, "seek": 5448, "start": 54.48, "end": 61.16, "text": " sort of get some crashes at some point, you will see this fancy little stack trace. And", "tokens": [1333, 295, 483, 512, 28642, 412, 512, 935, 11, 291, 486, 536, 341, 10247, 707, 8630, 13508, 13, 400], "temperature": 0.0, "avg_logprob": -0.24154238547048262, "compression_ratio": 1.69377990430622, "no_speech_prob": 0.00017089329776354134}, {"id": 9, "seek": 5448, "start": 61.16, "end": 70.03999999999999, "text": " if you use systemd, you will at some point have the crash handlers getting you the seg", "tokens": [498, 291, 764, 1185, 67, 11, 291, 486, 412, 512, 935, 362, 264, 8252, 1011, 11977, 1242, 291, 264, 3896], "temperature": 0.0, "avg_logprob": -0.24154238547048262, "compression_ratio": 1.69377990430622, "no_speech_prob": 0.00017089329776354134}, {"id": 10, "seek": 5448, "start": 70.03999999999999, "end": 78.64, "text": " faults, which happens. And then you can sort of just debug this with GDB. And if you do", "tokens": [36090, 11, 597, 2314, 13, 400, 550, 291, 393, 1333, 295, 445, 24083, 341, 365, 460, 27735, 13, 400, 498, 291, 360], "temperature": 0.0, "avg_logprob": -0.24154238547048262, "compression_ratio": 1.69377990430622, "no_speech_prob": 0.00017089329776354134}, {"id": 11, "seek": 5448, "start": 78.64, "end": 83.32, "text": " look at the backtrace, you just see nonsense. There's nothing here that makes sense at all.", "tokens": [574, 412, 264, 646, 6903, 617, 11, 291, 445, 536, 14925, 13, 821, 311, 1825, 510, 300, 1669, 2020, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.24154238547048262, "compression_ratio": 1.69377990430622, "no_speech_prob": 0.00017089329776354134}, {"id": 12, "seek": 8332, "start": 83.32, "end": 88.08, "text": " You can't figure out what happened. You don't know what crashed. And you have no idea. So,", "tokens": [509, 393, 380, 2573, 484, 437, 2011, 13, 509, 500, 380, 458, 437, 24190, 13, 400, 291, 362, 572, 1558, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.17987489208732685, "compression_ratio": 1.7129186602870814, "no_speech_prob": 5.8893481764243916e-05}, {"id": 13, "seek": 8332, "start": 88.08, "end": 94.0, "text": " if you actually do this on an Arch Linux system today, what you'll actually see is not that", "tokens": [498, 291, 767, 360, 341, 322, 364, 10984, 18734, 1185, 965, 11, 437, 291, 603, 767, 536, 307, 406, 300], "temperature": 0.0, "avg_logprob": -0.17987489208732685, "compression_ratio": 1.7129186602870814, "no_speech_prob": 5.8893481764243916e-05}, {"id": 14, "seek": 8332, "start": 94.0, "end": 106.39999999999999, "text": " nonsense backtrace. You'll instead see, no, let's cross Y. And you'll instead get this,", "tokens": [14925, 646, 6903, 617, 13, 509, 603, 2602, 536, 11, 572, 11, 718, 311, 3278, 398, 13, 400, 291, 603, 2602, 483, 341, 11], "temperature": 0.0, "avg_logprob": -0.17987489208732685, "compression_ratio": 1.7129186602870814, "no_speech_prob": 5.8893481764243916e-05}, {"id": 15, "seek": 8332, "start": 106.39999999999999, "end": 109.96, "text": " which has a lot more information. You'll see what happened, what crashed it. You'll get", "tokens": [597, 575, 257, 688, 544, 1589, 13, 509, 603, 536, 437, 2011, 11, 437, 24190, 309, 13, 509, 603, 483], "temperature": 0.0, "avg_logprob": -0.17987489208732685, "compression_ratio": 1.7129186602870814, "no_speech_prob": 5.8893481764243916e-05}, {"id": 16, "seek": 10996, "start": 109.96, "end": 114.11999999999999, "text": " all the symbols. And you did nothing. You did not download any debug packages. You didn't", "tokens": [439, 264, 16944, 13, 400, 291, 630, 1825, 13, 509, 630, 406, 5484, 604, 24083, 17401, 13, 509, 994, 380], "temperature": 0.0, "avg_logprob": -0.18548916504446383, "compression_ratio": 1.6436363636363636, "no_speech_prob": 6.210199353517964e-05}, {"id": 17, "seek": 10996, "start": 114.11999999999999, "end": 121.8, "text": " think about it. You just happened behind the scenes. And if we ask what actually happened,", "tokens": [519, 466, 309, 13, 509, 445, 2011, 2261, 264, 8026, 13, 400, 498, 321, 1029, 437, 767, 2011, 11], "temperature": 0.0, "avg_logprob": -0.18548916504446383, "compression_ratio": 1.6436363636363636, "no_speech_prob": 6.210199353517964e-05}, {"id": 18, "seek": 10996, "start": 121.8, "end": 126.47999999999999, "text": " you'll see that there's some internal syscall that crashed it. So, this is super nice. This", "tokens": [291, 603, 536, 300, 456, 311, 512, 6920, 262, 749, 45459, 300, 24190, 309, 13, 407, 11, 341, 307, 1687, 1481, 13, 639], "temperature": 0.0, "avg_logprob": -0.18548916504446383, "compression_ratio": 1.6436363636363636, "no_speech_prob": 6.210199353517964e-05}, {"id": 19, "seek": 10996, "start": 126.47999999999999, "end": 131.88, "text": " is a lot better than sort of what the debugging experience has been on Arch Linux previously.", "tokens": [307, 257, 688, 1101, 813, 1333, 295, 437, 264, 45592, 1752, 575, 668, 322, 10984, 18734, 8046, 13], "temperature": 0.0, "avg_logprob": -0.18548916504446383, "compression_ratio": 1.6436363636363636, "no_speech_prob": 6.210199353517964e-05}, {"id": 20, "seek": 10996, "start": 131.88, "end": 136.24, "text": " And it took me, I don't know, three years, two and a half years implementing a little", "tokens": [400, 309, 1890, 385, 11, 286, 500, 380, 458, 11, 1045, 924, 11, 732, 293, 257, 1922, 924, 18114, 257, 707], "temperature": 0.0, "avg_logprob": -0.18548916504446383, "compression_ratio": 1.6436363636363636, "no_speech_prob": 6.210199353517964e-05}, {"id": 21, "seek": 13624, "start": 136.24, "end": 142.96, "text": " bit on and off. So, why do we care about debug packages? So, if we, for instance, have Pacman,", "tokens": [857, 322, 293, 766, 13, 407, 11, 983, 360, 321, 1127, 466, 24083, 17401, 30, 407, 11, 498, 321, 11, 337, 5197, 11, 362, 10702, 1601, 11], "temperature": 0.0, "avg_logprob": -0.16178732299804688, "compression_ratio": 1.6531365313653137, "no_speech_prob": 4.179160896455869e-05}, {"id": 22, "seek": 13624, "start": 142.96, "end": 149.28, "text": " which is a fairly sort of simple and small binary, it's like half a meg of size if you", "tokens": [597, 307, 257, 6457, 1333, 295, 2199, 293, 1359, 17434, 11, 309, 311, 411, 1922, 257, 10816, 295, 2744, 498, 291], "temperature": 0.0, "avg_logprob": -0.16178732299804688, "compression_ratio": 1.6531365313653137, "no_speech_prob": 4.179160896455869e-05}, {"id": 23, "seek": 13624, "start": 149.28, "end": 155.36, "text": " build it. But if you strip away all the debug information, you can almost half the size,", "tokens": [1322, 309, 13, 583, 498, 291, 12828, 1314, 439, 264, 24083, 1589, 11, 291, 393, 1920, 1922, 264, 2744, 11], "temperature": 0.0, "avg_logprob": -0.16178732299804688, "compression_ratio": 1.6531365313653137, "no_speech_prob": 4.179160896455869e-05}, {"id": 24, "seek": 13624, "start": 155.36, "end": 159.48000000000002, "text": " which is nice. So, if you don't need all of that information on your disk, it's nice to", "tokens": [597, 307, 1481, 13, 407, 11, 498, 291, 500, 380, 643, 439, 295, 300, 1589, 322, 428, 12355, 11, 309, 311, 1481, 281], "temperature": 0.0, "avg_logprob": -0.16178732299804688, "compression_ratio": 1.6531365313653137, "no_speech_prob": 4.179160896455869e-05}, {"id": 25, "seek": 13624, "start": 159.48000000000002, "end": 164.88, "text": " sort of have some space savings. And in more like extreme cases, like in KeyCAD, had some", "tokens": [1333, 295, 362, 512, 1901, 13454, 13, 400, 294, 544, 411, 8084, 3331, 11, 411, 294, 12759, 34, 6112, 11, 632, 512], "temperature": 0.0, "avg_logprob": -0.16178732299804688, "compression_ratio": 1.6531365313653137, "no_speech_prob": 4.179160896455869e-05}, {"id": 26, "seek": 16488, "start": 164.88, "end": 171.64, "text": " sole name inside of Python, it's like half a gig. And if you strip away the debug information,", "tokens": [12321, 1315, 1854, 295, 15329, 11, 309, 311, 411, 1922, 257, 8741, 13, 400, 498, 291, 12828, 1314, 264, 24083, 1589, 11], "temperature": 0.0, "avg_logprob": -0.20630461104372713, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.944520621094853e-05}, {"id": 27, "seek": 16488, "start": 171.64, "end": 176.72, "text": " it's 33 megabytes. It's sort of nice to sort of have the opportunities to sort of debug", "tokens": [309, 311, 11816, 10816, 24538, 13, 467, 311, 1333, 295, 1481, 281, 1333, 295, 362, 264, 4786, 281, 1333, 295, 24083], "temperature": 0.0, "avg_logprob": -0.20630461104372713, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.944520621094853e-05}, {"id": 28, "seek": 16488, "start": 176.72, "end": 185.4, "text": " all of this. And this can all be sort of very large. So, what people do instead is that", "tokens": [439, 295, 341, 13, 400, 341, 393, 439, 312, 1333, 295, 588, 2416, 13, 407, 11, 437, 561, 360, 2602, 307, 300], "temperature": 0.0, "avg_logprob": -0.20630461104372713, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.944520621094853e-05}, {"id": 29, "seek": 16488, "start": 185.4, "end": 190.24, "text": " GDB implements what we call detached debug symbols. And that allows us to sort of separate", "tokens": [460, 27735, 704, 17988, 437, 321, 818, 42050, 24083, 16944, 13, 400, 300, 4045, 505, 281, 1333, 295, 4994], "temperature": 0.0, "avg_logprob": -0.20630461104372713, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.944520621094853e-05}, {"id": 30, "seek": 19024, "start": 190.24, "end": 196.16, "text": " out the debug symbols from the binaries and sort of re-link it together on the system.", "tokens": [484, 264, 24083, 16944, 490, 264, 5171, 4889, 293, 1333, 295, 319, 12, 22473, 309, 1214, 322, 264, 1185, 13], "temperature": 0.0, "avg_logprob": -0.1460641334796774, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.00018382752023171633}, {"id": 31, "seek": 19024, "start": 196.16, "end": 201.08, "text": " And one of the key elements for this is this fancy little build ID, which gets stamped", "tokens": [400, 472, 295, 264, 2141, 4959, 337, 341, 307, 341, 10247, 707, 1322, 7348, 11, 597, 2170, 39111], "temperature": 0.0, "avg_logprob": -0.1460641334796774, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.00018382752023171633}, {"id": 32, "seek": 19024, "start": 201.08, "end": 208.76000000000002, "text": " into every binary on your system. And we use that to sort of link. We define the build", "tokens": [666, 633, 17434, 322, 428, 1185, 13, 400, 321, 764, 300, 281, 1333, 295, 2113, 13, 492, 6964, 264, 1322], "temperature": 0.0, "avg_logprob": -0.1460641334796774, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.00018382752023171633}, {"id": 33, "seek": 19024, "start": 208.76000000000002, "end": 215.68, "text": " ID. We can make some standard directory on your system. We can split out the debug symbols", "tokens": [7348, 13, 492, 393, 652, 512, 3832, 21120, 322, 428, 1185, 13, 492, 393, 7472, 484, 264, 24083, 16944], "temperature": 0.0, "avg_logprob": -0.1460641334796774, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.00018382752023171633}, {"id": 34, "seek": 21568, "start": 215.68, "end": 222.24, "text": " from the binary, move it to that directory, add some debug link to the binary, and everything", "tokens": [490, 264, 17434, 11, 1286, 309, 281, 300, 21120, 11, 909, 512, 24083, 2113, 281, 264, 17434, 11, 293, 1203], "temperature": 0.0, "avg_logprob": -0.1604936142598302, "compression_ratio": 1.77734375, "no_speech_prob": 9.093705011764541e-05}, {"id": 35, "seek": 21568, "start": 222.24, "end": 228.20000000000002, "text": " just works. It will be as if the binary was, as the debug sections were still on the binaries.", "tokens": [445, 1985, 13, 467, 486, 312, 382, 498, 264, 17434, 390, 11, 382, 264, 24083, 10863, 645, 920, 322, 264, 5171, 4889, 13], "temperature": 0.0, "avg_logprob": -0.1604936142598302, "compression_ratio": 1.77734375, "no_speech_prob": 9.093705011764541e-05}, {"id": 36, "seek": 21568, "start": 228.20000000000002, "end": 233.16, "text": " This is nice. And this is sort of what Debian, Ubuntu, Fedora, all of them do to make those", "tokens": [639, 307, 1481, 13, 400, 341, 307, 1333, 295, 437, 1346, 20196, 11, 30230, 45605, 11, 7772, 3252, 11, 439, 295, 552, 360, 281, 652, 729], "temperature": 0.0, "avg_logprob": -0.1604936142598302, "compression_ratio": 1.77734375, "no_speech_prob": 9.093705011764541e-05}, {"id": 37, "seek": 21568, "start": 233.16, "end": 240.12, "text": " debug packages. And that's nice. But one of the things that you saw in the demonstration", "tokens": [24083, 17401, 13, 400, 300, 311, 1481, 13, 583, 472, 295, 264, 721, 300, 291, 1866, 294, 264, 16520], "temperature": 0.0, "avg_logprob": -0.1604936142598302, "compression_ratio": 1.77734375, "no_speech_prob": 9.093705011764541e-05}, {"id": 38, "seek": 21568, "start": 240.12, "end": 244.84, "text": " is that we also have the source code of the binaries. And that's more of a hack which", "tokens": [307, 300, 321, 611, 362, 264, 4009, 3089, 295, 264, 5171, 4889, 13, 400, 300, 311, 544, 295, 257, 10339, 597], "temperature": 0.0, "avg_logprob": -0.1604936142598302, "compression_ratio": 1.77734375, "no_speech_prob": 9.093705011764541e-05}, {"id": 39, "seek": 24484, "start": 244.84, "end": 249.68, "text": " some distributions have support for and some distribution doesn't support. So Debian, Ubuntu", "tokens": [512, 37870, 362, 1406, 337, 293, 512, 7316, 1177, 380, 1406, 13, 407, 1346, 20196, 11, 30230, 45605], "temperature": 0.0, "avg_logprob": -0.20810408341257194, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.00025454993010498583}, {"id": 40, "seek": 24484, "start": 249.68, "end": 254.6, "text": " does not have source listings, I believe, while Fedora, SUSE, and now Arch as well has", "tokens": [775, 406, 362, 4009, 45615, 11, 286, 1697, 11, 1339, 7772, 3252, 11, 40117, 36, 11, 293, 586, 10984, 382, 731, 575], "temperature": 0.0, "avg_logprob": -0.20810408341257194, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.00025454993010498583}, {"id": 41, "seek": 24484, "start": 254.6, "end": 261.24, "text": " source listings. And the way this sort of works is sort of you do a little bit of hacking.", "tokens": [4009, 45615, 13, 400, 264, 636, 341, 1333, 295, 1985, 307, 1333, 295, 291, 360, 257, 707, 857, 295, 31422, 13], "temperature": 0.0, "avg_logprob": -0.20810408341257194, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.00025454993010498583}, {"id": 42, "seek": 24484, "start": 261.24, "end": 266.92, "text": " So if we build Pacman just normally and we run GDB on it and we ask what the sources", "tokens": [407, 498, 321, 1322, 10702, 1601, 445, 5646, 293, 321, 1190, 460, 27735, 322, 309, 293, 321, 1029, 437, 264, 7139], "temperature": 0.0, "avg_logprob": -0.20810408341257194, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.00025454993010498583}, {"id": 43, "seek": 24484, "start": 266.92, "end": 273.48, "text": " were, you'll have your embedded project path in those binaries. So what you can do then", "tokens": [645, 11, 291, 603, 362, 428, 16741, 1716, 3100, 294, 729, 5171, 4889, 13, 407, 437, 291, 393, 360, 550], "temperature": 0.0, "avg_logprob": -0.20810408341257194, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.00025454993010498583}, {"id": 44, "seek": 27348, "start": 273.48, "end": 281.68, "text": " instead is to use debug edit. Historically, this has been part of the RPM upstream. So", "tokens": [2602, 307, 281, 764, 24083, 8129, 13, 25108, 984, 11, 341, 575, 668, 644, 295, 264, 37389, 33915, 13, 407], "temperature": 0.0, "avg_logprob": -0.2436830064524775, "compression_ratio": 1.5521739130434782, "no_speech_prob": 4.826077201869339e-05}, {"id": 45, "seek": 27348, "start": 281.68, "end": 287.20000000000005, "text": " Pacman didn't want to have a dependency on RPM to support debug packages, which is a", "tokens": [10702, 1601, 994, 380, 528, 281, 362, 257, 33621, 322, 37389, 281, 1406, 24083, 17401, 11, 597, 307, 257], "temperature": 0.0, "avg_logprob": -0.2436830064524775, "compression_ratio": 1.5521739130434782, "no_speech_prob": 4.826077201869339e-05}, {"id": 46, "seek": 27348, "start": 287.20000000000005, "end": 293.8, "text": " bit weird. But this was split out now into a separate project in back in 2001, no, yeah,", "tokens": [857, 3657, 13, 583, 341, 390, 7472, 484, 586, 666, 257, 4994, 1716, 294, 646, 294, 16382, 11, 572, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.2436830064524775, "compression_ratio": 1.5521739130434782, "no_speech_prob": 4.826077201869339e-05}, {"id": 47, "seek": 27348, "start": 293.8, "end": 299.20000000000005, "text": " 2021, which is now a separate project, which is quite nice, and it makes more sort of accessible", "tokens": [7201, 11, 597, 307, 586, 257, 4994, 1716, 11, 597, 307, 1596, 1481, 11, 293, 309, 1669, 544, 1333, 295, 9515], "temperature": 0.0, "avg_logprob": -0.2436830064524775, "compression_ratio": 1.5521739130434782, "no_speech_prob": 4.826077201869339e-05}, {"id": 48, "seek": 29920, "start": 299.2, "end": 305.32, "text": " for other package managers. So instead of sort of using the current working directory", "tokens": [337, 661, 7372, 14084, 13, 407, 2602, 295, 1333, 295, 1228, 264, 2190, 1364, 21120], "temperature": 0.0, "avg_logprob": -0.18253770367852573, "compression_ratio": 1.577092511013216, "no_speech_prob": 6.049541480024345e-05}, {"id": 49, "seek": 29920, "start": 305.32, "end": 310.52, "text": " to embed stuff, we can rewrite all of those paths inside the binary to some standard path", "tokens": [281, 12240, 1507, 11, 321, 393, 28132, 439, 295, 729, 14518, 1854, 264, 17434, 281, 512, 3832, 3100], "temperature": 0.0, "avg_logprob": -0.18253770367852573, "compression_ratio": 1.577092511013216, "no_speech_prob": 6.049541480024345e-05}, {"id": 50, "seek": 29920, "start": 310.52, "end": 316.59999999999997, "text": " on the file system. So in Arch, we use source debug and then we do name spacing so we can", "tokens": [322, 264, 3991, 1185, 13, 407, 294, 10984, 11, 321, 764, 4009, 24083, 293, 550, 321, 360, 1315, 27739, 370, 321, 393], "temperature": 0.0, "avg_logprob": -0.18253770367852573, "compression_ratio": 1.577092511013216, "no_speech_prob": 6.049541480024345e-05}, {"id": 51, "seek": 29920, "start": 316.59999999999997, "end": 325.0, "text": " have sources from multiple versions of Pacman. And if you sort of do these DOMs, you'll have", "tokens": [362, 7139, 490, 3866, 9606, 295, 10702, 1601, 13, 400, 498, 291, 1333, 295, 360, 613, 35727, 82, 11, 291, 603, 362], "temperature": 0.0, "avg_logprob": -0.18253770367852573, "compression_ratio": 1.577092511013216, "no_speech_prob": 6.049541480024345e-05}, {"id": 52, "seek": 32500, "start": 325.0, "end": 330.6, "text": " rewritten all of those source listings, which is part of the binary, which is super nice.", "tokens": [319, 26859, 439, 295, 729, 4009, 45615, 11, 597, 307, 644, 295, 264, 17434, 11, 597, 307, 1687, 1481, 13], "temperature": 0.0, "avg_logprob": -0.16837037547250813, "compression_ratio": 1.6952380952380952, "no_speech_prob": 4.197780435788445e-05}, {"id": 53, "seek": 32500, "start": 330.6, "end": 337.64, "text": " And then you can sort of get all the source code associated with binary. So before debug", "tokens": [400, 550, 291, 393, 1333, 295, 483, 439, 264, 4009, 3089, 6615, 365, 17434, 13, 407, 949, 24083], "temperature": 0.0, "avg_logprob": -0.16837037547250813, "compression_ratio": 1.6952380952380952, "no_speech_prob": 4.197780435788445e-05}, {"id": 54, "seek": 32500, "start": 337.64, "end": 344.68, "text": " edit was available as a sort of normal thing, Pacman also had support for source listings,", "tokens": [8129, 390, 2435, 382, 257, 1333, 295, 2710, 551, 11, 10702, 1601, 611, 632, 1406, 337, 4009, 45615, 11], "temperature": 0.0, "avg_logprob": -0.16837037547250813, "compression_ratio": 1.6952380952380952, "no_speech_prob": 4.197780435788445e-05}, {"id": 55, "seek": 32500, "start": 344.68, "end": 349.92, "text": " but he didn't use debug edit. He decided to use awk instead. So he then tried to parse", "tokens": [457, 415, 994, 380, 764, 24083, 8129, 13, 634, 3047, 281, 764, 1714, 74, 2602, 13, 407, 415, 550, 3031, 281, 48377], "temperature": 0.0, "avg_logprob": -0.16837037547250813, "compression_ratio": 1.6952380952380952, "no_speech_prob": 4.197780435788445e-05}, {"id": 56, "seek": 34992, "start": 349.92, "end": 355.64000000000004, "text": " out all of the file paths, I don't know, from read-off, try to figure out whatever was there", "tokens": [484, 439, 295, 264, 3991, 14518, 11, 286, 500, 380, 458, 11, 490, 1401, 12, 4506, 11, 853, 281, 2573, 484, 2035, 390, 456], "temperature": 0.0, "avg_logprob": -0.2357561676590531, "compression_ratio": 1.6150442477876106, "no_speech_prob": 7.846427615731955e-05}, {"id": 57, "seek": 34992, "start": 355.64000000000004, "end": 360.88, "text": " and sort of try to get it out. And this worked for, like, simple C programs, but if you threw", "tokens": [293, 1333, 295, 853, 281, 483, 309, 484, 13, 400, 341, 2732, 337, 11, 411, 11, 2199, 383, 4268, 11, 457, 498, 291, 11918], "temperature": 0.0, "avg_logprob": -0.2357561676590531, "compression_ratio": 1.6150442477876106, "no_speech_prob": 7.846427615731955e-05}, {"id": 58, "seek": 34992, "start": 360.88, "end": 368.48, "text": " like a rush to go at it, it had no clue what that was at all. So it was a hack. It worked.", "tokens": [411, 257, 9300, 281, 352, 412, 309, 11, 309, 632, 572, 13602, 437, 300, 390, 412, 439, 13, 407, 309, 390, 257, 10339, 13, 467, 2732, 13], "temperature": 0.0, "avg_logprob": -0.2357561676590531, "compression_ratio": 1.6150442477876106, "no_speech_prob": 7.846427615731955e-05}, {"id": 59, "seek": 34992, "start": 368.48, "end": 373.36, "text": " It was in the source code for, I don't know, six years maybe. So I ripped that out last", "tokens": [467, 390, 294, 264, 4009, 3089, 337, 11, 286, 500, 380, 458, 11, 2309, 924, 1310, 13, 407, 286, 22780, 300, 484, 1036], "temperature": 0.0, "avg_logprob": -0.2357561676590531, "compression_ratio": 1.6150442477876106, "no_speech_prob": 7.846427615731955e-05}, {"id": 60, "seek": 37336, "start": 373.36, "end": 383.24, "text": " year. So this, yes. So when these packages get built and you have the debug symbols and", "tokens": [1064, 13, 407, 341, 11, 2086, 13, 407, 562, 613, 17401, 483, 3094, 293, 291, 362, 264, 24083, 16944, 293], "temperature": 0.0, "avg_logprob": -0.25786172259937634, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.462716267677024e-05}, {"id": 61, "seek": 37336, "start": 383.24, "end": 388.32, "text": " have all of the source listings, we can then sort of compile all of this to some package", "tokens": [362, 439, 295, 264, 4009, 45615, 11, 321, 393, 550, 1333, 295, 31413, 439, 295, 341, 281, 512, 7372], "temperature": 0.0, "avg_logprob": -0.25786172259937634, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.462716267677024e-05}, {"id": 62, "seek": 37336, "start": 388.32, "end": 396.8, "text": " and then distribute it to our distributions. So all our packages in Arch Linux goes to", "tokens": [293, 550, 20594, 309, 281, 527, 37870, 13, 407, 439, 527, 17401, 294, 10984, 18734, 1709, 281], "temperature": 0.0, "avg_logprob": -0.25786172259937634, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.462716267677024e-05}, {"id": 63, "seek": 37336, "start": 396.8, "end": 401.72, "text": " this repo.archin.org, which is a tier zero mirror. That's where all the packages gets", "tokens": [341, 49040, 13, 1178, 259, 13, 4646, 11, 597, 307, 257, 12362, 4018, 8013, 13, 663, 311, 689, 439, 264, 17401, 2170], "temperature": 0.0, "avg_logprob": -0.25786172259937634, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.462716267677024e-05}, {"id": 64, "seek": 40172, "start": 401.72, "end": 406.8, "text": " distributed from to all our mirrors. And on this, there's two package pools. There is", "tokens": [12631, 490, 281, 439, 527, 24238, 13, 400, 322, 341, 11, 456, 311, 732, 7372, 28688, 13, 821, 307], "temperature": 0.0, "avg_logprob": -0.3031813727484809, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.00014097534585744143}, {"id": 65, "seek": 40172, "start": 406.8, "end": 414.96000000000004, "text": " from corn extra. There's a package. Just flash debug pool. And for community, there's, okay,", "tokens": [490, 9046, 2857, 13, 821, 311, 257, 7372, 13, 1449, 7319, 24083, 7005, 13, 400, 337, 1768, 11, 456, 311, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.3031813727484809, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.00014097534585744143}, {"id": 66, "seek": 40172, "start": 414.96000000000004, "end": 421.36, "text": " there's a big community's dashboard debug, not packages. But these can be fetched and", "tokens": [456, 311, 257, 955, 1768, 311, 18342, 24083, 11, 406, 17401, 13, 583, 613, 393, 312, 23673, 292, 293], "temperature": 0.0, "avg_logprob": -0.3031813727484809, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.00014097534585744143}, {"id": 67, "seek": 40172, "start": 421.36, "end": 427.88000000000005, "text": " distributed to all mirrors, but it's a huge amount of packages. So what we do instead", "tokens": [12631, 281, 439, 24238, 11, 457, 309, 311, 257, 2603, 2372, 295, 17401, 13, 407, 437, 321, 360, 2602], "temperature": 0.0, "avg_logprob": -0.3031813727484809, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.00014097534585744143}, {"id": 68, "seek": 42788, "start": 427.88, "end": 432.44, "text": " is that we are synced over this to something called a debug info instance we have, which", "tokens": [307, 300, 321, 366, 5451, 1232, 670, 341, 281, 746, 1219, 257, 24083, 13614, 5197, 321, 362, 11, 597], "temperature": 0.0, "avg_logprob": -0.20515978613565133, "compression_ratio": 1.6666666666666667, "no_speech_prob": 3.951258986489847e-05}, {"id": 69, "seek": 42788, "start": 432.44, "end": 443.2, "text": " allows us to do fetch everything over HTTP instead. So debug info is a very cool microservice", "tokens": [4045, 505, 281, 360, 23673, 1203, 670, 33283, 2602, 13, 407, 24083, 13614, 307, 257, 588, 1627, 15547, 25006], "temperature": 0.0, "avg_logprob": -0.20515978613565133, "compression_ratio": 1.6666666666666667, "no_speech_prob": 3.951258986489847e-05}, {"id": 70, "seek": 42788, "start": 443.2, "end": 448.2, "text": " which is capable of getting you the source code and the symbols from binaries over HTTP.", "tokens": [597, 307, 8189, 295, 1242, 291, 264, 4009, 3089, 293, 264, 16944, 490, 5171, 4889, 670, 33283, 13], "temperature": 0.0, "avg_logprob": -0.20515978613565133, "compression_ratio": 1.6666666666666667, "no_speech_prob": 3.951258986489847e-05}, {"id": 71, "seek": 42788, "start": 448.2, "end": 452.64, "text": " So you don't have to think about which debug packages do you need, which one do you have", "tokens": [407, 291, 500, 380, 362, 281, 519, 466, 597, 24083, 17401, 360, 291, 643, 11, 597, 472, 360, 291, 362], "temperature": 0.0, "avg_logprob": -0.20515978613565133, "compression_ratio": 1.6666666666666667, "no_speech_prob": 3.951258986489847e-05}, {"id": 72, "seek": 45264, "start": 452.64, "end": 457.88, "text": " to download to get full backtrace. We can just point GDB at this instance and it will", "tokens": [281, 5484, 281, 483, 1577, 646, 6903, 617, 13, 492, 393, 445, 935, 460, 27735, 412, 341, 5197, 293, 309, 486], "temperature": 0.0, "avg_logprob": -0.2657584938951718, "compression_ratio": 1.4753363228699552, "no_speech_prob": 0.00012593145947903395}, {"id": 73, "seek": 45264, "start": 457.88, "end": 462.91999999999996, "text": " just fetch everything for us, which is quite nice.", "tokens": [445, 23673, 1203, 337, 505, 11, 597, 307, 1596, 1481, 13], "temperature": 0.0, "avg_logprob": -0.2657584938951718, "compression_ratio": 1.4753363228699552, "no_speech_prob": 0.00012593145947903395}, {"id": 74, "seek": 45264, "start": 462.91999999999996, "end": 471.15999999999997, "text": " So it's written, maintained by the ELF maintenance. It's a web server in C in the year 2020.", "tokens": [407, 309, 311, 3720, 11, 17578, 538, 264, 14426, 37, 11258, 13, 467, 311, 257, 3670, 7154, 294, 383, 294, 264, 1064, 4808, 13], "temperature": 0.0, "avg_logprob": -0.2657584938951718, "compression_ratio": 1.4753363228699552, "no_speech_prob": 0.00012593145947903395}, {"id": 75, "seek": 45264, "start": 471.15999999999997, "end": 475.88, "text": " So it's running on, like, I think a few distributions, like, I think Boyd Linux has one, Debian has", "tokens": [407, 309, 311, 2614, 322, 11, 411, 11, 286, 519, 257, 1326, 37870, 11, 411, 11, 286, 519, 9486, 67, 18734, 575, 472, 11, 1346, 20196, 575], "temperature": 0.0, "avg_logprob": -0.2657584938951718, "compression_ratio": 1.4753363228699552, "no_speech_prob": 0.00012593145947903395}, {"id": 76, "seek": 47588, "start": 475.88, "end": 482.88, "text": " one, Debian and Ubuntu got one past six months. And there's Fedora and SUSE also has several", "tokens": [472, 11, 1346, 20196, 293, 30230, 45605, 658, 472, 1791, 2309, 2493, 13, 400, 456, 311, 7772, 3252, 293, 40117, 36, 611, 575, 2940], "temperature": 0.0, "avg_logprob": -0.2724695098534059, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.00016398592561017722}, {"id": 77, "seek": 47588, "start": 482.88, "end": 488.96, "text": " of these. So it's super simple. We can just use the", "tokens": [295, 613, 13, 407, 309, 311, 1687, 2199, 13, 492, 393, 445, 764, 264], "temperature": 0.0, "avg_logprob": -0.2724695098534059, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.00016398592561017722}, {"id": 78, "seek": 47588, "start": 488.96, "end": 495.48, "text": " debug info. We can give it that this is some tar archives that you want to parse and give", "tokens": [24083, 13614, 13, 492, 393, 976, 309, 300, 341, 307, 512, 3112, 25607, 300, 291, 528, 281, 48377, 293, 976], "temperature": 0.0, "avg_logprob": -0.2724695098534059, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.00016398592561017722}, {"id": 79, "seek": 47588, "start": 495.48, "end": 501.08, "text": " it a package pool. And we just set the debug info URLs variable and then we can run GDB", "tokens": [309, 257, 7372, 7005, 13, 400, 321, 445, 992, 264, 24083, 13614, 43267, 7006, 293, 550, 321, 393, 1190, 460, 27735], "temperature": 0.0, "avg_logprob": -0.2724695098534059, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.00016398592561017722}, {"id": 80, "seek": 50108, "start": 501.08, "end": 506.68, "text": " on the binaries and it works. That's all you have to do to sort of make GDB read those", "tokens": [322, 264, 5171, 4889, 293, 309, 1985, 13, 663, 311, 439, 291, 362, 281, 360, 281, 1333, 295, 652, 460, 27735, 1401, 729], "temperature": 0.0, "avg_logprob": -0.19740216391427176, "compression_ratio": 1.4915254237288136, "no_speech_prob": 7.82029892434366e-05}, {"id": 81, "seek": 50108, "start": 506.68, "end": 514.1999999999999, "text": " files instead of having to distribute them. So, yes. And then you can have this debug", "tokens": [7098, 2602, 295, 1419, 281, 20594, 552, 13, 407, 11, 2086, 13, 400, 550, 291, 393, 362, 341, 24083], "temperature": 0.0, "avg_logprob": -0.19740216391427176, "compression_ratio": 1.4915254237288136, "no_speech_prob": 7.82029892434366e-05}, {"id": 82, "seek": 50108, "start": 514.1999999999999, "end": 521.28, "text": " info find command line thing to fetch stuff for you or you can use it as a library instead.", "tokens": [13614, 915, 5622, 1622, 551, 281, 23673, 1507, 337, 291, 420, 291, 393, 764, 309, 382, 257, 6405, 2602, 13], "temperature": 0.0, "avg_logprob": -0.19740216391427176, "compression_ratio": 1.4915254237288136, "no_speech_prob": 7.82029892434366e-05}, {"id": 83, "seek": 52128, "start": 521.28, "end": 531.24, "text": " But yeah. So running a web server in C in 2020 is, you know, a little bit iffy. So we", "tokens": [583, 1338, 13, 407, 2614, 257, 3670, 7154, 294, 383, 294, 4808, 307, 11, 291, 458, 11, 257, 707, 857, 498, 22522, 13, 407, 321], "temperature": 0.0, "avg_logprob": -0.272430419921875, "compression_ratio": 1.5938864628820961, "no_speech_prob": 2.116053110512439e-05}, {"id": 84, "seek": 52128, "start": 531.24, "end": 538.1999999999999, "text": " sort of wrote this, distributed this in sort of this hardware system file. So if something", "tokens": [1333, 295, 4114, 341, 11, 12631, 341, 294, 1333, 295, 341, 8837, 1185, 3991, 13, 407, 498, 746], "temperature": 0.0, "avg_logprob": -0.272430419921875, "compression_ratio": 1.5938864628820961, "no_speech_prob": 2.116053110512439e-05}, {"id": 85, "seek": 52128, "start": 538.1999999999999, "end": 543.56, "text": " gets exploited or something happening in that C code, you never know. It's still sort of", "tokens": [2170, 40918, 420, 746, 2737, 294, 300, 383, 3089, 11, 291, 1128, 458, 13, 467, 311, 920, 1333, 295], "temperature": 0.0, "avg_logprob": -0.272430419921875, "compression_ratio": 1.5938864628820961, "no_speech_prob": 2.116053110512439e-05}, {"id": 86, "seek": 52128, "start": 543.56, "end": 548.88, "text": " only really contained to some fairly restrictive set of policies. So you can't ask your privileges,", "tokens": [787, 534, 16212, 281, 512, 6457, 43220, 992, 295, 7657, 13, 407, 291, 393, 380, 1029, 428, 32588, 11], "temperature": 0.0, "avg_logprob": -0.272430419921875, "compression_ratio": 1.5938864628820961, "no_speech_prob": 2.116053110512439e-05}, {"id": 87, "seek": 54888, "start": 548.88, "end": 554.88, "text": " you can't really write anything to the system. But you can sort of just read stuff, which", "tokens": [291, 393, 380, 534, 2464, 1340, 281, 264, 1185, 13, 583, 291, 393, 1333, 295, 445, 1401, 1507, 11, 597], "temperature": 0.0, "avg_logprob": -0.22391245581886984, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0001558027433929965}, {"id": 88, "seek": 54888, "start": 554.88, "end": 561.84, "text": " is quite nice. So the only really two paths this has access to on our sort of in production", "tokens": [307, 1596, 1481, 13, 407, 264, 787, 534, 732, 14518, 341, 575, 2105, 281, 322, 527, 1333, 295, 294, 4265], "temperature": 0.0, "avg_logprob": -0.22391245581886984, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0001558027433929965}, {"id": 89, "seek": 54888, "start": 561.84, "end": 566.92, "text": " system is just these two package pools and some cache directory and sort of that's everything", "tokens": [1185, 307, 445, 613, 732, 7372, 28688, 293, 512, 19459, 21120, 293, 1333, 295, 300, 311, 1203], "temperature": 0.0, "avg_logprob": -0.22391245581886984, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0001558027433929965}, {"id": 90, "seek": 54888, "start": 566.92, "end": 573.16, "text": " it sees. So that's fairly quite nice. Been planning to upstream it. And I think you bumped", "tokens": [309, 8194, 13, 407, 300, 311, 6457, 1596, 1481, 13, 32839, 5038, 281, 33915, 309, 13, 400, 286, 519, 291, 42696], "temperature": 0.0, "avg_logprob": -0.22391245581886984, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0001558027433929965}, {"id": 91, "seek": 57316, "start": 573.16, "end": 583.56, "text": " into and Debian uses this as well, but it's an extremely properly yet sadly. So, you know,", "tokens": [666, 293, 1346, 20196, 4960, 341, 382, 731, 11, 457, 309, 311, 364, 4664, 6108, 1939, 22023, 13, 407, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.311557320987477, "compression_ratio": 1.45, "no_speech_prob": 0.00023034424521028996}, {"id": 92, "seek": 57316, "start": 583.56, "end": 589.16, "text": " we have debug packages, we distribute it, people can use them, but we can also parse", "tokens": [321, 362, 24083, 17401, 11, 321, 20594, 309, 11, 561, 393, 764, 552, 11, 457, 321, 393, 611, 48377], "temperature": 0.0, "avg_logprob": -0.311557320987477, "compression_ratio": 1.45, "no_speech_prob": 0.00023034424521028996}, {"id": 93, "seek": 57316, "start": 589.16, "end": 596.8, "text": " metrics from people accessing this server. So I spent a little bit of time. Look what", "tokens": [16367, 490, 561, 26440, 341, 7154, 13, 407, 286, 4418, 257, 707, 857, 295, 565, 13, 2053, 437], "temperature": 0.0, "avg_logprob": -0.311557320987477, "compression_ratio": 1.45, "no_speech_prob": 0.00023034424521028996}, {"id": 94, "seek": 59680, "start": 596.8, "end": 621.0, "text": " you're how this vendors. Yeah. Okay. It does not like that. I don't know. I can't zoom", "tokens": [291, 434, 577, 341, 22056, 13, 865, 13, 1033, 13, 467, 775, 406, 411, 300, 13, 286, 500, 380, 458, 13, 286, 393, 380, 8863], "temperature": 0.0, "avg_logprob": -0.4651969054649616, "compression_ratio": 1.048780487804878, "no_speech_prob": 0.0008575016399845481}, {"id": 95, "seek": 62100, "start": 621.0, "end": 637.8, "text": " out. I hate this. So, so what you sort of see here is just some basic statistics. So", "tokens": [484, 13, 286, 4700, 341, 13, 407, 11, 370, 437, 291, 1333, 295, 536, 510, 307, 445, 512, 3875, 12523, 13, 407], "temperature": 0.0, "avg_logprob": -0.20761378361628605, "compression_ratio": 1.4913294797687862, "no_speech_prob": 3.4626707929419354e-05}, {"id": 96, "seek": 62100, "start": 637.8, "end": 643.64, "text": " what people have been doing on it, we enabled debug packages for all our packages fairly", "tokens": [437, 561, 362, 668, 884, 322, 309, 11, 321, 15172, 24083, 17401, 337, 439, 527, 17401, 6457], "temperature": 0.0, "avg_logprob": -0.20761378361628605, "compression_ratio": 1.4913294797687862, "no_speech_prob": 3.4626707929419354e-05}, {"id": 97, "seek": 62100, "start": 643.64, "end": 647.64, "text": " recently this year. So that's why you see the biggest corpus spike going straight up", "tokens": [3938, 341, 1064, 13, 407, 300, 311, 983, 291, 536, 264, 3880, 1181, 31624, 21053, 516, 2997, 493], "temperature": 0.0, "avg_logprob": -0.20761378361628605, "compression_ratio": 1.4913294797687862, "no_speech_prob": 3.4626707929419354e-05}, {"id": 98, "seek": 64764, "start": 647.64, "end": 653.1999999999999, "text": " because we have more symbols now. But you also see that we reached two terabytes of", "tokens": [570, 321, 362, 544, 16944, 586, 13, 583, 291, 611, 536, 300, 321, 6488, 732, 1796, 24538, 295], "temperature": 0.0, "avg_logprob": -0.22441931976669136, "compression_ratio": 1.651376146788991, "no_speech_prob": 7.757311686873436e-05}, {"id": 99, "seek": 64764, "start": 653.1999999999999, "end": 658.08, "text": " data being sent out to different users the past month. So that's the last 30 days with", "tokens": [1412, 885, 2279, 484, 281, 819, 5022, 264, 1791, 1618, 13, 407, 300, 311, 264, 1036, 2217, 1708, 365], "temperature": 0.0, "avg_logprob": -0.22441931976669136, "compression_ratio": 1.651376146788991, "no_speech_prob": 7.757311686873436e-05}, {"id": 100, "seek": 64764, "start": 658.08, "end": 664.28, "text": " two terabytes out. And you can see some statistics on how much data people are fetching the errors", "tokens": [732, 1796, 24538, 484, 13, 400, 291, 393, 536, 512, 12523, 322, 577, 709, 1412, 561, 366, 23673, 278, 264, 13603], "temperature": 0.0, "avg_logprob": -0.22441931976669136, "compression_ratio": 1.651376146788991, "no_speech_prob": 7.757311686873436e-05}, {"id": 101, "seek": 64764, "start": 664.28, "end": 669.0, "text": " from through but statistics is sort of quite nice. And you sort of get this from free from", "tokens": [490, 807, 457, 12523, 307, 1333, 295, 1596, 1481, 13, 400, 291, 1333, 295, 483, 341, 490, 1737, 490], "temperature": 0.0, "avg_logprob": -0.22441931976669136, "compression_ratio": 1.651376146788991, "no_speech_prob": 7.757311686873436e-05}, {"id": 102, "seek": 66900, "start": 669.0, "end": 681.8, "text": " hosting it. Yes. So all of this infrastructure that's been put up in Arch, of course, is", "tokens": [16058, 309, 13, 1079, 13, 407, 439, 295, 341, 6896, 300, 311, 668, 829, 493, 294, 10984, 11, 295, 1164, 11, 307], "temperature": 0.0, "avg_logprob": -0.23313307762145996, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0001247196487383917}, {"id": 103, "seek": 66900, "start": 681.8, "end": 688.08, "text": " all open source. There's no proprietary infrastructure. There's no hidden files. So all the stuff", "tokens": [439, 1269, 4009, 13, 821, 311, 572, 38992, 6896, 13, 821, 311, 572, 7633, 7098, 13, 407, 439, 264, 1507], "temperature": 0.0, "avg_logprob": -0.23313307762145996, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0001247196487383917}, {"id": 104, "seek": 66900, "start": 688.08, "end": 692.2, "text": " we use to distribute debug info is all in our infrastructure repository under the roles", "tokens": [321, 764, 281, 20594, 24083, 13614, 307, 439, 294, 527, 6896, 25841, 833, 264, 9604], "temperature": 0.0, "avg_logprob": -0.23313307762145996, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0001247196487383917}, {"id": 105, "seek": 66900, "start": 692.2, "end": 697.24, "text": " of debug info. That's sort of how we fetch all of the packages, how we do the service", "tokens": [295, 24083, 13614, 13, 663, 311, 1333, 295, 577, 321, 23673, 439, 295, 264, 17401, 11, 577, 321, 360, 264, 2643], "temperature": 0.0, "avg_logprob": -0.23313307762145996, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0001247196487383917}, {"id": 106, "seek": 69724, "start": 697.24, "end": 709.64, "text": " management stuff, and all of those things. Yes. So I'll probably have more time. Yes.", "tokens": [4592, 1507, 11, 293, 439, 295, 729, 721, 13, 1079, 13, 407, 286, 603, 1391, 362, 544, 565, 13, 1079, 13], "temperature": 0.0, "avg_logprob": -0.16353326258452042, "compression_ratio": 1.5890410958904109, "no_speech_prob": 7.581634417874739e-05}, {"id": 107, "seek": 69724, "start": 709.64, "end": 715.12, "text": " So one of the things I also did because, you know, debug packages is usually done on C", "tokens": [407, 472, 295, 264, 721, 286, 611, 630, 570, 11, 291, 458, 11, 24083, 17401, 307, 2673, 1096, 322, 383], "temperature": 0.0, "avg_logprob": -0.16353326258452042, "compression_ratio": 1.5890410958904109, "no_speech_prob": 7.581634417874739e-05}, {"id": 108, "seek": 69724, "start": 715.12, "end": 720.28, "text": " applications and stuff, but I don't actually know C. I do Python and Go instead. So what", "tokens": [5821, 293, 1507, 11, 457, 286, 500, 380, 767, 458, 383, 13, 286, 360, 15329, 293, 1037, 2602, 13, 407, 437], "temperature": 0.0, "avg_logprob": -0.16353326258452042, "compression_ratio": 1.5890410958904109, "no_speech_prob": 7.581634417874739e-05}, {"id": 109, "seek": 69724, "start": 720.28, "end": 725.2, "text": " I also spent a lot of time on doing is to sort of try to get better debug info support", "tokens": [286, 611, 4418, 257, 688, 295, 565, 322, 884, 307, 281, 1333, 295, 853, 281, 483, 1101, 24083, 13614, 1406], "temperature": 0.0, "avg_logprob": -0.16353326258452042, "compression_ratio": 1.5890410958904109, "no_speech_prob": 7.581634417874739e-05}, {"id": 110, "seek": 72520, "start": 725.2, "end": 732.84, "text": " in Go because that's cool. So here, just to sort of give an example, here we're going", "tokens": [294, 1037, 570, 300, 311, 1627, 13, 407, 510, 11, 445, 281, 1333, 295, 976, 364, 1365, 11, 510, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.1773390719765111, "compression_ratio": 1.5945945945945945, "no_speech_prob": 2.5613046091166325e-05}, {"id": 111, "seek": 72520, "start": 732.84, "end": 739.48, "text": " to crash the tail scale SSH client because that's a nice example, I think. So this instructed", "tokens": [281, 8252, 264, 6838, 4373, 12238, 39, 6423, 570, 300, 311, 257, 1481, 1365, 11, 286, 519, 13, 407, 341, 36384], "temperature": 0.0, "avg_logprob": -0.1773390719765111, "compression_ratio": 1.5945945945945945, "no_speech_prob": 2.5613046091166325e-05}, {"id": 112, "seek": 72520, "start": 739.48, "end": 746.44, "text": " the Go compiler to actually give us a core dump. And then we can use the delve debugger", "tokens": [264, 1037, 31958, 281, 767, 976, 505, 257, 4965, 11430, 13, 400, 550, 321, 393, 764, 264, 43098, 24083, 1321], "temperature": 0.0, "avg_logprob": -0.1773390719765111, "compression_ratio": 1.5945945945945945, "no_speech_prob": 2.5613046091166325e-05}, {"id": 113, "seek": 72520, "start": 746.44, "end": 753.9200000000001, "text": " in Go. And it actually, with a few patches, is able to read out all the debug symbols,", "tokens": [294, 1037, 13, 400, 309, 767, 11, 365, 257, 1326, 26531, 11, 307, 1075, 281, 1401, 484, 439, 264, 24083, 16944, 11], "temperature": 0.0, "avg_logprob": -0.1773390719765111, "compression_ratio": 1.5945945945945945, "no_speech_prob": 2.5613046091166325e-05}, {"id": 114, "seek": 75392, "start": 753.92, "end": 758.52, "text": " all of the source code, which is fetched from the debug info server as well, which is quite", "tokens": [439, 295, 264, 4009, 3089, 11, 597, 307, 23673, 292, 490, 264, 24083, 13614, 7154, 382, 731, 11, 597, 307, 1596], "temperature": 0.0, "avg_logprob": -0.19337263561430432, "compression_ratio": 1.647887323943662, "no_speech_prob": 3.0642924684798345e-05}, {"id": 115, "seek": 75392, "start": 758.52, "end": 765.68, "text": " nice as it will give us the more opportunities to sort of debug Go applications. It also", "tokens": [1481, 382, 309, 486, 976, 505, 264, 544, 4786, 281, 1333, 295, 24083, 1037, 5821, 13, 467, 611], "temperature": 0.0, "avg_logprob": -0.19337263561430432, "compression_ratio": 1.647887323943662, "no_speech_prob": 3.0642924684798345e-05}, {"id": 116, "seek": 75392, "start": 765.68, "end": 770.4399999999999, "text": " works on Rust. It also works on Julia and whatever sort of programming languages you", "tokens": [1985, 322, 34952, 13, 467, 611, 1985, 322, 18551, 293, 2035, 1333, 295, 9410, 8650, 291], "temperature": 0.0, "avg_logprob": -0.19337263561430432, "compression_ratio": 1.647887323943662, "no_speech_prob": 3.0642924684798345e-05}, {"id": 117, "seek": 75392, "start": 770.4399999999999, "end": 774.7199999999999, "text": " want. Which is quite nice. So it's sort of an improvement for the entire ecosystem as", "tokens": [528, 13, 3013, 307, 1596, 1481, 13, 407, 309, 311, 1333, 295, 364, 10444, 337, 264, 2302, 11311, 382], "temperature": 0.0, "avg_logprob": -0.19337263561430432, "compression_ratio": 1.647887323943662, "no_speech_prob": 3.0642924684798345e-05}, {"id": 118, "seek": 77472, "start": 774.72, "end": 792.1600000000001, "text": " well. Yes. That was it. I'll have a lot of time for questions if anybody has anything.", "tokens": [731, 13, 1079, 13, 663, 390, 309, 13, 286, 603, 362, 257, 688, 295, 565, 337, 1651, 498, 4472, 575, 1340, 13], "temperature": 0.0, "avg_logprob": -0.36865076651939976, "compression_ratio": 1.048780487804878, "no_speech_prob": 0.0003160552296321839}, {"id": 119, "seek": 79216, "start": 792.16, "end": 814.7199999999999, "text": " So I'm wondering what you actually store for the source. Is it the build tree or are you", "tokens": [407, 286, 478, 6359, 437, 291, 767, 3531, 337, 264, 4009, 13, 1119, 309, 264, 1322, 4230, 420, 366, 291], "temperature": 0.0, "avg_logprob": -0.22645672162373862, "compression_ratio": 1.0602409638554218, "no_speech_prob": 0.00040043488843366504}, {"id": 120, "seek": 81472, "start": 814.72, "end": 822.36, "text": " trying to remove some things to save storage? Because, I mean, you have like a package,", "tokens": [1382, 281, 4159, 512, 721, 281, 3155, 6725, 30, 1436, 11, 286, 914, 11, 291, 362, 411, 257, 7372, 11], "temperature": 0.0, "avg_logprob": -0.21839190077507634, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.0006448354688473046}, {"id": 121, "seek": 81472, "start": 822.36, "end": 825.96, "text": " you have an upstream source, you have patches on top of the upstream source, and then maybe", "tokens": [291, 362, 364, 33915, 4009, 11, 291, 362, 26531, 322, 1192, 295, 264, 33915, 4009, 11, 293, 550, 1310], "temperature": 0.0, "avg_logprob": -0.21839190077507634, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.0006448354688473046}, {"id": 122, "seek": 81472, "start": 825.96, "end": 833.84, "text": " even the build process might generate sources itself. Yes. So I don't quite know how, but", "tokens": [754, 264, 1322, 1399, 1062, 8460, 7139, 2564, 13, 1079, 13, 407, 286, 500, 380, 1596, 458, 577, 11, 457], "temperature": 0.0, "avg_logprob": -0.21839190077507634, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.0006448354688473046}, {"id": 123, "seek": 81472, "start": 833.84, "end": 839.52, "text": " this is just a binary, which sort of dwarf generates the source listing as part of the", "tokens": [341, 307, 445, 257, 17434, 11, 597, 1333, 295, 35527, 23815, 264, 4009, 22161, 382, 644, 295, 264], "temperature": 0.0, "avg_logprob": -0.21839190077507634, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.0006448354688473046}, {"id": 124, "seek": 83952, "start": 839.52, "end": 845.12, "text": " dwarf metadata, I think. So this is all the, there's some generated optimized out sources,", "tokens": [35527, 26603, 11, 286, 519, 13, 407, 341, 307, 439, 264, 11, 456, 311, 512, 10833, 26941, 484, 7139, 11], "temperature": 0.0, "avg_logprob": -0.22209332498271814, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0003435919061303139}, {"id": 125, "seek": 83952, "start": 845.12, "end": 850.0799999999999, "text": " I think, and there's some sort of things that points around to different sources, but it", "tokens": [286, 519, 11, 293, 456, 311, 512, 1333, 295, 721, 300, 2793, 926, 281, 819, 7139, 11, 457, 309], "temperature": 0.0, "avg_logprob": -0.22209332498271814, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0003435919061303139}, {"id": 126, "seek": 83952, "start": 850.0799999999999, "end": 856.04, "text": " will mostly just be sort of the patched up, generated, done sources, which gets embedded", "tokens": [486, 5240, 445, 312, 1333, 295, 264, 9972, 292, 493, 11, 10833, 11, 1096, 7139, 11, 597, 2170, 16741], "temperature": 0.0, "avg_logprob": -0.22209332498271814, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0003435919061303139}, {"id": 127, "seek": 83952, "start": 856.04, "end": 860.96, "text": " there. So it's, the source listing is a nice bonus, but it's not necessarily some would", "tokens": [456, 13, 407, 309, 311, 11, 264, 4009, 22161, 307, 257, 1481, 10882, 11, 457, 309, 311, 406, 4725, 512, 576], "temperature": 0.0, "avg_logprob": -0.22209332498271814, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0003435919061303139}, {"id": 128, "seek": 86096, "start": 860.96, "end": 880.6, "text": " normally be distributing with the binary. That answers the question. Yes. Any more questions?", "tokens": [5646, 312, 41406, 365, 264, 17434, 13, 663, 6338, 264, 1168, 13, 1079, 13, 2639, 544, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2978436730124734, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.0002804925024975091}, {"id": 129, "seek": 86096, "start": 880.6, "end": 885.9200000000001, "text": " Thanks for using it. Could you upstream the system deservers files? Yes, it's been a", "tokens": [2561, 337, 1228, 309, 13, 7497, 291, 33915, 264, 1185, 730, 260, 840, 7098, 30, 1079, 11, 309, 311, 668, 257], "temperature": 0.0, "avg_logprob": -0.2978436730124734, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.0002804925024975091}, {"id": 130, "seek": 86096, "start": 885.9200000000001, "end": 889.44, "text": " moment to do this for a long time. It's a little bit problematic though, because you", "tokens": [1623, 281, 360, 341, 337, 257, 938, 565, 13, 467, 311, 257, 707, 857, 19011, 1673, 11, 570, 291], "temperature": 0.0, "avg_logprob": -0.2978436730124734, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.0002804925024975091}, {"id": 131, "seek": 88944, "start": 889.44, "end": 893.1600000000001, "text": " don't need to figure out sort of how the paths and stuff needs to get into the service file", "tokens": [500, 380, 643, 281, 2573, 484, 1333, 295, 577, 264, 14518, 293, 1507, 2203, 281, 483, 666, 264, 2643, 3991], "temperature": 0.0, "avg_logprob": -0.315977589467938, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.0001840497279772535}, {"id": 132, "seek": 88944, "start": 893.1600000000001, "end": 897.0400000000001, "text": " with some configuration file, but it can probably be done. And I think that there will be people", "tokens": [365, 512, 11694, 3991, 11, 457, 309, 393, 1391, 312, 1096, 13, 400, 286, 519, 300, 456, 486, 312, 561], "temperature": 0.0, "avg_logprob": -0.315977589467938, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.0001840497279772535}, {"id": 133, "seek": 88944, "start": 897.0400000000001, "end": 903.7600000000001, "text": " use it as well. Yes, it should be upstreamed. Yes.", "tokens": [764, 309, 382, 731, 13, 1079, 11, 309, 820, 312, 33915, 292, 13, 1079, 13], "temperature": 0.0, "avg_logprob": -0.315977589467938, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.0001840497279772535}, {"id": 134, "seek": 88944, "start": 903.7600000000001, "end": 916.96, "text": " Yeah. So, and we normally hide the HB server behind the proxy. Yes. It's written in C++", "tokens": [865, 13, 407, 11, 293, 321, 5646, 6479, 264, 389, 33, 7154, 2261, 264, 29690, 13, 1079, 13, 467, 311, 3720, 294, 383, 25472], "temperature": 0.0, "avg_logprob": -0.315977589467938, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.0001840497279772535}, {"id": 135, "seek": 91696, "start": 916.96, "end": 922.8000000000001, "text": " if that helps. Yeah, no, yes. It's actually C++ is not C. It's all the elf stuff that's", "tokens": [498, 300, 3665, 13, 865, 11, 572, 11, 2086, 13, 467, 311, 767, 383, 25472, 307, 406, 383, 13, 467, 311, 439, 264, 35565, 1507, 300, 311], "temperature": 0.0, "avg_logprob": -0.33751825185922474, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.00048306668759323657}, {"id": 136, "seek": 91696, "start": 922.8000000000001, "end": 933.12, "text": " mostly written in C, I think. Yeah, so it's a C++ program that uses Lib, micro, HBD,", "tokens": [5240, 3720, 294, 383, 11, 286, 519, 13, 865, 11, 370, 309, 311, 257, 383, 25472, 1461, 300, 4960, 15834, 11, 4532, 11, 389, 33, 35, 11], "temperature": 0.0, "avg_logprob": -0.33751825185922474, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.00048306668759323657}, {"id": 137, "seek": 91696, "start": 933.12, "end": 941.96, "text": " and SQLite to store our other data. Yeah. So we have it behind the reverse proxy to", "tokens": [293, 19200, 642, 281, 3531, 527, 661, 1412, 13, 865, 13, 407, 321, 362, 309, 2261, 264, 9943, 29690, 281], "temperature": 0.0, "avg_logprob": -0.33751825185922474, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.00048306668759323657}, {"id": 138, "seek": 91696, "start": 941.96, "end": 946.4000000000001, "text": " sort of get the TLS configuration going and outside, but we also just warranted the hardening", "tokens": [1333, 295, 483, 264, 314, 19198, 11694, 516, 293, 2380, 11, 457, 321, 611, 445, 16354, 292, 264, 1152, 4559], "temperature": 0.0, "avg_logprob": -0.33751825185922474, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.00048306668759323657}, {"id": 139, "seek": 94640, "start": 946.4, "end": 950.48, "text": " there because it's just, it's easy with system D to just get the hardening there. So it's", "tokens": [456, 570, 309, 311, 445, 11, 309, 311, 1858, 365, 1185, 413, 281, 445, 483, 264, 1152, 4559, 456, 13, 407, 309, 311], "temperature": 0.0, "avg_logprob": -0.3176793723270811, "compression_ratio": 1.3759398496240602, "no_speech_prob": 0.0003006231563631445}, {"id": 140, "seek": 94640, "start": 950.48, "end": 955.4, "text": " no reason to sort of not do it. So it's quite nice, but I'll try to upstream it.", "tokens": [572, 1778, 281, 1333, 295, 406, 360, 309, 13, 407, 309, 311, 1596, 1481, 11, 457, 286, 603, 853, 281, 33915, 309, 13], "temperature": 0.0, "avg_logprob": -0.3176793723270811, "compression_ratio": 1.3759398496240602, "no_speech_prob": 0.0003006231563631445}, {"id": 141, "seek": 94640, "start": 955.4, "end": 971.88, "text": " Thanks. Yes.", "tokens": [2561, 13, 1079, 13], "temperature": 0.0, "avg_logprob": -0.3176793723270811, "compression_ratio": 1.3759398496240602, "no_speech_prob": 0.0003006231563631445}, {"id": 142, "seek": 97188, "start": 971.88, "end": 979.24, "text": " Are those statistics on your dashboard pulled from the HTTP server he was describing? Are", "tokens": [2014, 729, 12523, 322, 428, 18342, 7373, 490, 264, 33283, 7154, 415, 390, 16141, 30, 2014], "temperature": 0.0, "avg_logprob": -0.2410010408472132, "compression_ratio": 1.7654320987654322, "no_speech_prob": 0.00045501202112063766}, {"id": 143, "seek": 97188, "start": 979.24, "end": 986.72, "text": " those from like your Nginx or whatever proxy you're using? What? Sorry. Are the statistics", "tokens": [729, 490, 411, 428, 426, 1494, 87, 420, 2035, 29690, 291, 434, 1228, 30, 708, 30, 4919, 13, 2014, 264, 12523], "temperature": 0.0, "avg_logprob": -0.2410010408472132, "compression_ratio": 1.7654320987654322, "no_speech_prob": 0.00045501202112063766}, {"id": 144, "seek": 97188, "start": 986.72, "end": 991.8, "text": " you had on your dashboard earlier? Yes. Are those pulled from the back end? Or are they", "tokens": [291, 632, 322, 428, 18342, 3071, 30, 1079, 13, 2014, 729, 7373, 490, 264, 646, 917, 30, 1610, 366, 436], "temperature": 0.0, "avg_logprob": -0.2410010408472132, "compression_ratio": 1.7654320987654322, "no_speech_prob": 0.00045501202112063766}, {"id": 145, "seek": 97188, "start": 991.8, "end": 996.44, "text": " from like a proxy in front? So the debug info has a slash metrics, which", "tokens": [490, 411, 257, 29690, 294, 1868, 30, 407, 264, 24083, 13614, 575, 257, 17330, 16367, 11, 597], "temperature": 0.0, "avg_logprob": -0.2410010408472132, "compression_ratio": 1.7654320987654322, "no_speech_prob": 0.00045501202112063766}, {"id": 146, "seek": 97188, "start": 996.44, "end": 1001.44, "text": " is all Promtail. So it just exports a bunch of metrics and you just point Promtail from", "tokens": [307, 439, 15833, 83, 864, 13, 407, 309, 445, 31428, 257, 3840, 295, 16367, 293, 291, 445, 935, 15833, 83, 864, 490], "temperature": 0.0, "avg_logprob": -0.2410010408472132, "compression_ratio": 1.7654320987654322, "no_speech_prob": 0.00045501202112063766}, {"id": 147, "seek": 100144, "start": 1001.44, "end": 1006.2800000000001, "text": " it and it will just parse it. So that dashboard is something we made internally, which I just", "tokens": [309, 293, 309, 486, 445, 48377, 309, 13, 407, 300, 18342, 307, 746, 321, 1027, 19501, 11, 597, 286, 445], "temperature": 0.0, "avg_logprob": -0.24487151418413436, "compression_ratio": 1.6996197718631179, "no_speech_prob": 5.359766510082409e-05}, {"id": 148, "seek": 100144, "start": 1006.2800000000001, "end": 1010.96, "text": " spent two weeks making, and that's also open source. So you can just fetch the JSON file", "tokens": [4418, 732, 3259, 1455, 11, 293, 300, 311, 611, 1269, 4009, 13, 407, 291, 393, 445, 23673, 264, 31828, 3991], "temperature": 0.0, "avg_logprob": -0.24487151418413436, "compression_ratio": 1.6996197718631179, "no_speech_prob": 5.359766510082409e-05}, {"id": 149, "seek": 100144, "start": 1010.96, "end": 1015.5200000000001, "text": " for the dashboard on the Grafana and everything there is all sort of open. So you can go look", "tokens": [337, 264, 18342, 322, 264, 8985, 69, 2095, 293, 1203, 456, 307, 439, 1333, 295, 1269, 13, 407, 291, 393, 352, 574], "temperature": 0.0, "avg_logprob": -0.24487151418413436, "compression_ratio": 1.6996197718631179, "no_speech_prob": 5.359766510082409e-05}, {"id": 150, "seek": 100144, "start": 1015.5200000000001, "end": 1021.4000000000001, "text": " at it. But it's all, it's just this sort of slash metrics endpoint of debug info. So", "tokens": [412, 309, 13, 583, 309, 311, 439, 11, 309, 311, 445, 341, 1333, 295, 17330, 16367, 35795, 295, 24083, 13614, 13, 407], "temperature": 0.0, "avg_logprob": -0.24487151418413436, "compression_ratio": 1.6996197718631179, "no_speech_prob": 5.359766510082409e-05}, {"id": 151, "seek": 100144, "start": 1021.4000000000001, "end": 1026.8400000000001, "text": " the Red Hat people actually watches this for all the debug info servers that has been", "tokens": [264, 4477, 15867, 561, 767, 17062, 341, 337, 439, 264, 24083, 13614, 15909, 300, 575, 668], "temperature": 0.0, "avg_logprob": -0.24487151418413436, "compression_ratio": 1.6996197718631179, "no_speech_prob": 5.359766510082409e-05}, {"id": 152, "seek": 102684, "start": 1026.84, "end": 1031.6, "text": " employed and they can like look at the statistics and errors from all of different servers and", "tokens": [20115, 293, 436, 393, 411, 574, 412, 264, 12523, 293, 13603, 490, 439, 295, 819, 15909, 293], "temperature": 0.0, "avg_logprob": -0.2986661125631893, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.00029308683588169515}, {"id": 153, "seek": 102684, "start": 1031.6, "end": 1037.8, "text": " see how the traffic between all of those are sort of how much is Fedora distributing compared", "tokens": [536, 577, 264, 6419, 1296, 439, 295, 729, 366, 1333, 295, 577, 709, 307, 7772, 3252, 41406, 5347], "temperature": 0.0, "avg_logprob": -0.2986661125631893, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.00029308683588169515}, {"id": 154, "seek": 102684, "start": 1037.8, "end": 1043.8, "text": " to Arch and stuff, which is quite nice. That was not public, I think. But yeah, it's cool.", "tokens": [281, 10984, 293, 1507, 11, 597, 307, 1596, 1481, 13, 663, 390, 406, 1908, 11, 286, 519, 13, 583, 1338, 11, 309, 311, 1627, 13], "temperature": 0.0, "avg_logprob": -0.2986661125631893, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.00029308683588169515}, {"id": 155, "seek": 104380, "start": 1043.8, "end": 1063.48, "text": " Can you tell us a bit about the requirements in terms of storage? Because I recently looked", "tokens": [1664, 291, 980, 505, 257, 857, 466, 264, 7728, 294, 2115, 295, 6725, 30, 1436, 286, 3938, 2956], "temperature": 0.0, "avg_logprob": -0.14865285594288896, "compression_ratio": 1.3893129770992367, "no_speech_prob": 0.00040408861241303384}, {"id": 156, "seek": 104380, "start": 1063.48, "end": 1069.96, "text": " at another distribution and they didn't build all the packages because of lack of storage.", "tokens": [412, 1071, 7316, 293, 436, 994, 380, 1322, 439, 264, 17401, 570, 295, 5011, 295, 6725, 13], "temperature": 0.0, "avg_logprob": -0.14865285594288896, "compression_ratio": 1.3893129770992367, "no_speech_prob": 0.00040408861241303384}, {"id": 157, "seek": 106996, "start": 1069.96, "end": 1074.3600000000001, "text": " So that's what I'm trying to figure out now because we enabled debug symbols for all the", "tokens": [407, 300, 311, 437, 286, 478, 1382, 281, 2573, 484, 586, 570, 321, 15172, 24083, 16944, 337, 439, 264], "temperature": 0.0, "avg_logprob": -0.20007679971416345, "compression_ratio": 1.510548523206751, "no_speech_prob": 3.0538387363776565e-05}, {"id": 158, "seek": 106996, "start": 1074.3600000000001, "end": 1078.96, "text": " packages, but they're not currently distributing it to our mirrors. So Arch, the total mirror", "tokens": [17401, 11, 457, 436, 434, 406, 4362, 41406, 309, 281, 527, 24238, 13, 407, 10984, 11, 264, 3217, 8013], "temperature": 0.0, "avg_logprob": -0.20007679971416345, "compression_ratio": 1.510548523206751, "no_speech_prob": 3.0538387363776565e-05}, {"id": 159, "seek": 106996, "start": 1078.96, "end": 1085.08, "text": " size for Arch is like 60, 70, 80 gigabytes, I think, of data. But I assume like that would", "tokens": [2744, 337, 10984, 307, 411, 4060, 11, 5285, 11, 4688, 42741, 11, 286, 519, 11, 295, 1412, 13, 583, 286, 6552, 411, 300, 576], "temperature": 0.0, "avg_logprob": -0.20007679971416345, "compression_ratio": 1.510548523206751, "no_speech_prob": 3.0538387363776565e-05}, {"id": 160, "seek": 106996, "start": 1085.08, "end": 1090.64, "text": " be several hundreds if we actually upload all the debug packages. But I think Fedora", "tokens": [312, 2940, 6779, 498, 321, 767, 6580, 439, 264, 24083, 17401, 13, 583, 286, 519, 7772, 3252], "temperature": 0.0, "avg_logprob": -0.20007679971416345, "compression_ratio": 1.510548523206751, "no_speech_prob": 3.0538387363776565e-05}, {"id": 161, "seek": 109064, "start": 1090.64, "end": 1100.3600000000001, "text": " in total is like three, four terabytes or something. So I assume it will go inside three,", "tokens": [294, 3217, 307, 411, 1045, 11, 1451, 1796, 24538, 420, 746, 13, 407, 286, 6552, 309, 486, 352, 1854, 1045, 11], "temperature": 0.0, "avg_logprob": -0.3191187750432909, "compression_ratio": 1.592760180995475, "no_speech_prob": 9.076352580450475e-05}, {"id": 162, "seek": 109064, "start": 1100.3600000000001, "end": 1106.3600000000001, "text": " four times and stuff. I know like the LLVMD stuff is like a two gigabyte package, I think,", "tokens": [1451, 1413, 293, 1507, 13, 286, 458, 411, 264, 441, 43, 53, 44, 35, 1507, 307, 411, 257, 732, 8741, 34529, 7372, 11, 286, 519, 11], "temperature": 0.0, "avg_logprob": -0.3191187750432909, "compression_ratio": 1.592760180995475, "no_speech_prob": 9.076352580450475e-05}, {"id": 163, "seek": 109064, "start": 1106.3600000000001, "end": 1111.0800000000002, "text": " with symbols and people try to optimize it a little bit so you get a better, faster", "tokens": [365, 16944, 293, 561, 853, 281, 19719, 309, 257, 707, 857, 370, 291, 483, 257, 1101, 11, 4663], "temperature": 0.0, "avg_logprob": -0.3191187750432909, "compression_ratio": 1.592760180995475, "no_speech_prob": 9.076352580450475e-05}, {"id": 164, "seek": 109064, "start": 1111.0800000000002, "end": 1119.3600000000001, "text": " to upload. So it's, yeah, one sort of main issue with debug edit and sort of debug info", "tokens": [281, 6580, 13, 407, 309, 311, 11, 1338, 11, 472, 1333, 295, 2135, 2734, 365, 24083, 8129, 293, 1333, 295, 24083, 13614], "temperature": 0.0, "avg_logprob": -0.3191187750432909, "compression_ratio": 1.592760180995475, "no_speech_prob": 9.076352580450475e-05}, {"id": 165, "seek": 111936, "start": 1119.36, "end": 1124.7199999999998, "text": " and stuff is that you have, Dwarf 5 has support for compressed sections, but debug edit does", "tokens": [293, 1507, 307, 300, 291, 362, 11, 413, 6925, 69, 1025, 575, 1406, 337, 30353, 10863, 11, 457, 24083, 8129, 775], "temperature": 0.0, "avg_logprob": -0.16195211410522461, "compression_ratio": 1.8130434782608695, "no_speech_prob": 0.00017760730406735092}, {"id": 166, "seek": 111936, "start": 1124.7199999999998, "end": 1129.8799999999999, "text": " not understand the compressed sections. So you have to decompress the sections before", "tokens": [406, 1223, 264, 30353, 10863, 13, 407, 291, 362, 281, 22867, 735, 264, 10863, 949], "temperature": 0.0, "avg_logprob": -0.16195211410522461, "compression_ratio": 1.8130434782608695, "no_speech_prob": 0.00017760730406735092}, {"id": 167, "seek": 111936, "start": 1129.8799999999999, "end": 1134.28, "text": " you leave out the paths and there's no good way to sort of recompress everything again.", "tokens": [291, 1856, 484, 264, 14518, 293, 456, 311, 572, 665, 636, 281, 1333, 295, 48000, 735, 1203, 797, 13], "temperature": 0.0, "avg_logprob": -0.16195211410522461, "compression_ratio": 1.8130434782608695, "no_speech_prob": 0.00017760730406735092}, {"id": 168, "seek": 111936, "start": 1134.28, "end": 1140.56, "text": " So getting better support for sort of compressed Dwarf info would sort of help fix a few of", "tokens": [407, 1242, 1101, 1406, 337, 1333, 295, 30353, 413, 6925, 69, 13614, 576, 1333, 295, 854, 3191, 257, 1326, 295], "temperature": 0.0, "avg_logprob": -0.16195211410522461, "compression_ratio": 1.8130434782608695, "no_speech_prob": 0.00017760730406735092}, {"id": 169, "seek": 111936, "start": 1140.56, "end": 1144.4399999999998, "text": " those sort of space requirements, I think, on the mirrors.", "tokens": [729, 1333, 295, 1901, 7728, 11, 286, 519, 11, 322, 264, 24238, 13], "temperature": 0.0, "avg_logprob": -0.16195211410522461, "compression_ratio": 1.8130434782608695, "no_speech_prob": 0.00017760730406735092}, {"id": 170, "seek": 114444, "start": 1144.44, "end": 1151.72, "text": " Can I ask another question? Is there work on the duplication instead of compression?", "tokens": [1664, 286, 1029, 1071, 1168, 30, 1119, 456, 589, 322, 264, 17154, 399, 2602, 295, 19355, 30], "temperature": 0.0, "avg_logprob": -0.18787229215943968, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0007045259117148817}, {"id": 171, "seek": 114444, "start": 1151.72, "end": 1157.52, "text": " Because you have different version of packages as well.", "tokens": [1436, 291, 362, 819, 3037, 295, 17401, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.18787229215943968, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0007045259117148817}, {"id": 172, "seek": 114444, "start": 1157.52, "end": 1162.64, "text": " So it's not that relevant for ours because we don't keep those versions and we don't", "tokens": [407, 309, 311, 406, 300, 7340, 337, 11896, 570, 321, 500, 380, 1066, 729, 9606, 293, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.18787229215943968, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0007045259117148817}, {"id": 173, "seek": 114444, "start": 1162.64, "end": 1167.64, "text": " really do delta files on the packages. So on the arch side of things I don't think that's", "tokens": [534, 360, 8289, 7098, 322, 264, 17401, 13, 407, 322, 264, 3912, 1252, 295, 721, 286, 500, 380, 519, 300, 311], "temperature": 0.0, "avg_logprob": -0.18787229215943968, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0007045259117148817}, {"id": 174, "seek": 116764, "start": 1167.64, "end": 1175.24, "text": " really relevant for us, but I don't know. It could probably be done at some level, at", "tokens": [534, 7340, 337, 505, 11, 457, 286, 500, 380, 458, 13, 467, 727, 1391, 312, 1096, 412, 512, 1496, 11, 412], "temperature": 0.0, "avg_logprob": -0.28255776925520465, "compression_ratio": 1.3046875, "no_speech_prob": 0.00018526929488871247}, {"id": 175, "seek": 116764, "start": 1175.24, "end": 1184.24, "text": " least for like Fedora or Debian that keeps multiple versions of the same package.", "tokens": [1935, 337, 411, 7772, 3252, 420, 1346, 20196, 300, 5965, 3866, 9606, 295, 264, 912, 7372, 13], "temperature": 0.0, "avg_logprob": -0.28255776925520465, "compression_ratio": 1.3046875, "no_speech_prob": 0.00018526929488871247}, {"id": 176, "seek": 118424, "start": 1184.24, "end": 1212.52, "text": " A small question, for which architectors are you generating those debug info binaries?", "tokens": [316, 1359, 1168, 11, 337, 597, 3912, 270, 557, 830, 366, 291, 17746, 729, 24083, 13614, 5171, 4889, 30], "temperature": 0.0, "avg_logprob": -0.30136809141739557, "compression_ratio": 1.075, "no_speech_prob": 0.00689238915219903}, {"id": 177, "seek": 121252, "start": 1212.52, "end": 1219.92, "text": " So arch only really supports x8664. We don't really have any other architectures. But because", "tokens": [407, 3912, 787, 534, 9346, 2031, 22193, 19395, 13, 492, 500, 380, 534, 362, 604, 661, 6331, 1303, 13, 583, 570], "temperature": 0.0, "avg_logprob": -0.2281822176540599, "compression_ratio": 1.4455958549222798, "no_speech_prob": 0.0005029269959777594}, {"id": 178, "seek": 121252, "start": 1219.92, "end": 1226.16, "text": " we have the 32-bit port and we have the ARM people and I think they're just pulling our", "tokens": [321, 362, 264, 8858, 12, 5260, 2436, 293, 321, 362, 264, 8943, 44, 561, 293, 286, 519, 436, 434, 445, 8407, 527], "temperature": 0.0, "avg_logprob": -0.2281822176540599, "compression_ratio": 1.4455958549222798, "no_speech_prob": 0.0005029269959777594}, {"id": 179, "seek": 121252, "start": 1226.16, "end": 1231.24, "text": " packages and probably building debug in full for them, but arch itself is not really distributing", "tokens": [17401, 293, 1391, 2390, 24083, 294, 1577, 337, 552, 11, 457, 3912, 2564, 307, 406, 534, 41406], "temperature": 0.0, "avg_logprob": -0.2281822176540599, "compression_ratio": 1.4455958549222798, "no_speech_prob": 0.0005029269959777594}, {"id": 180, "seek": 123124, "start": 1231.24, "end": 1246.16, "text": " anything else on x8664 currently.", "tokens": [1340, 1646, 322, 2031, 22193, 19395, 4362, 13], "temperature": 0.0, "avg_logprob": -0.2957812103570676, "compression_ratio": 1.3096774193548386, "no_speech_prob": 0.0030059057753533125}, {"id": 181, "seek": 123124, "start": 1246.16, "end": 1251.92, "text": " So you mentioned different architectures. Do you know if there's plan to upstream the", "tokens": [407, 291, 2835, 819, 6331, 1303, 13, 1144, 291, 458, 498, 456, 311, 1393, 281, 33915, 264], "temperature": 0.0, "avg_logprob": -0.2957812103570676, "compression_ratio": 1.3096774193548386, "no_speech_prob": 0.0030059057753533125}, {"id": 182, "seek": 123124, "start": 1251.92, "end": 1258.08, "text": " booking for D and in general risk five because I know Felix Yan is working on this?", "tokens": [34424, 337, 413, 293, 294, 2674, 3148, 1732, 570, 286, 458, 30169, 13633, 307, 1364, 322, 341, 30], "temperature": 0.0, "avg_logprob": -0.2957812103570676, "compression_ratio": 1.3096774193548386, "no_speech_prob": 0.0030059057753533125}, {"id": 183, "seek": 125808, "start": 1258.08, "end": 1266.08, "text": " Yes, I know Felix is working on it. We want to, this is more an arch thing, but we don't", "tokens": [1079, 11, 286, 458, 30169, 307, 1364, 322, 309, 13, 492, 528, 281, 11, 341, 307, 544, 364, 3912, 551, 11, 457, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.2257076386482485, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.0005132156074978411}, {"id": 184, "seek": 125808, "start": 1266.08, "end": 1271.6799999999998, "text": " have traditional build farm server setup. So it's a bit hard for us to do multiple architectures", "tokens": [362, 5164, 1322, 5421, 7154, 8657, 13, 407, 309, 311, 257, 857, 1152, 337, 505, 281, 360, 3866, 6331, 1303], "temperature": 0.0, "avg_logprob": -0.2257076386482485, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.0005132156074978411}, {"id": 185, "seek": 125808, "start": 1271.6799999999998, "end": 1277.24, "text": " because one package maintainer has to build that package for each architecture. So currently", "tokens": [570, 472, 7372, 6909, 260, 575, 281, 1322, 300, 7372, 337, 1184, 9482, 13, 407, 4362], "temperature": 0.0, "avg_logprob": -0.2257076386482485, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.0005132156074978411}, {"id": 186, "seek": 125808, "start": 1277.24, "end": 1284.4399999999998, "text": " we want to have support for more architectures and better support like V2, V3, V4 versions", "tokens": [321, 528, 281, 362, 1406, 337, 544, 6331, 1303, 293, 1101, 1406, 411, 691, 17, 11, 691, 18, 11, 691, 19, 9606], "temperature": 0.0, "avg_logprob": -0.2257076386482485, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.0005132156074978411}, {"id": 187, "seek": 128444, "start": 1284.44, "end": 1291.44, "text": " of X that you see now supporting. But you currently haven't really solved that in a good way currently.", "tokens": [295, 1783, 300, 291, 536, 586, 7231, 13, 583, 291, 4362, 2378, 380, 534, 13041, 300, 294, 257, 665, 636, 4362, 13], "temperature": 0.0, "avg_logprob": -0.43587562561035154, "compression_ratio": 1.4766355140186915, "no_speech_prob": 0.0009265650296583772}, {"id": 188, "seek": 128444, "start": 1291.44, "end": 1292.44, "text": " Okay, thanks.", "tokens": [1033, 11, 3231, 13], "temperature": 0.0, "avg_logprob": -0.43587562561035154, "compression_ratio": 1.4766355140186915, "no_speech_prob": 0.0009265650296583772}, {"id": 189, "seek": 128444, "start": 1292.44, "end": 1293.44, "text": " Thanks.", "tokens": [2561, 13], "temperature": 0.0, "avg_logprob": -0.43587562561035154, "compression_ratio": 1.4766355140186915, "no_speech_prob": 0.0009265650296583772}, {"id": 190, "seek": 128444, "start": 1293.44, "end": 1294.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.43587562561035154, "compression_ratio": 1.4766355140186915, "no_speech_prob": 0.0009265650296583772}, {"id": 191, "seek": 128444, "start": 1294.44, "end": 1295.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.43587562561035154, "compression_ratio": 1.4766355140186915, "no_speech_prob": 0.0009265650296583772}, {"id": 192, "seek": 129544, "start": 1295.44, "end": 1318.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.6716625349862235, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.002371366834267974}], "language": "en"}