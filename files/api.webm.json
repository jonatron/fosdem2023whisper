{"text": " Welcome, Bobor. Hi, everyone. Thank you. Thank you. Hi, everyone. I am super excited to be here. Welcome to one of my sessions about observing your APIs with API gateway plugins. Let me introduce myself first. My name is Bobor. I am a developer advocate for Apache API 6. Sometimes it's so difficult to pronounce my name. People say it's from different countries. Is it like a Bebo or Bobor or like a Bebo? And then I say, okay, you can translate my first name as a tiger. It means tiger, Bobor. My last name, Murzokov, English version will be Livermore. In this case, Tiger Livermore. You can call me like Tiger Livermore. It's up to you. And you can also reach out to me on these social channels if you have any questions regarding sessions. So with that, we can get started. First thing first, what I want to do now is take a selfie because I have my TikTok account. I just start to run my blog recently. Just a moment. Maybe this is better. That was good. Thank you. I will just put some hashtags on that. So thank you Fabiano. Now I can leave. I did my job. I can go home. I did my Instagram picture, right? But I have today a very interesting agenda for you. We'll talk about what is APIs and API observability and how we can use API gateway for observing your APIs as a central point for observation. And then we will break down all API observability three pillars. We know that we have logging, tracing, and metrics, right? And we will learn how to enable these three pillars by using Apache API 6 plugins. And I have then a small demo for you. I hope you will like it. And that's good. APIs, right? API is just the three letters acronym for application program interface. By now, we are all familiar with this term, right? Because we are living in increasingly API-centric world. Even chat GPT uses API. Because under the hood, it calls some OpenAI API lists to collect some language models. Now my question to you. Who doesn't know what is API? Everybody knows. You don't know. You are lucky I have a brief for you. You will get this T-shirt because you don't know what's API 6. What is your size? I will handle it for you here. Actually, I have enough T-shirts. If you are first the three good, if I get the first three good answer, I will give it to you. And we have also some medals, stickers if you would like to get, please feel free. It's like free stuff from community, I would say. And we know that success of your services, right, depends on the performance, availability, and integrity of your APIs. Here, another question, Rice. How to achieve these three indicators of success? How to achieve these three indicators of success for your APIs? Let's say we have API should be all the time available, right? It should be integratable. It should be performance with a high performance. Do you have any idea? Yes, you got one T-shirt. Yes, monitoring, exactly. And what do you say, distributing? Yeah, distribute system, monitoring? Just placing it as a service in a distributed process. Yeah, this is also a rice solution. But you will get only the medal. Sorry. But one solution can be using by API gateways. Because API gateways, actually, nowadays, what we do, we build multiple microservices and maybe several less APIs or multiple REST APIs for our unique, maybe, the service, right? And in this flow, API gateways serves as a central point for routing all your incoming requests to the internet destinations. These destinations can be, as you can see, database, or maybe short-party API services. Or it can be also some serverless APIs like Azure Function or AWS Lambda, maybe any other open source functions, right? And it means it's accessed a single layer between your clients and the backend services, right? That can manage all the traffic coming to your backend services. It's a very straightforward term, right? API gateway term. And then it can also be a right point to learn for your API observabilities because it's uniquely identified to know all the traffic moving from client side to our backend service network. And instead of relying on, let's say, some other technologies, SDKs, APIs, and services to enable this observability and improve this observability, you can easily integrate this job with API gateway. We have a bunch of API gateways. I'm not selling anything, but we are talking about now API 6, what kind of plugins you can use today. And next, for example, you can ask, what is Apache API 6? Maybe you know the world's largest open source software software foundation, Apache software foundation. Maybe some of you are part of it, right? Who is a part of it, ASF? Who is contributing to open source projects of Apache software foundation? You, we have some people. And who knows Apache Kafka, Cassandra, Tomcat? Everybody knows. And Apache API 6 is also one of the top fastest growing project of ESF nowadays. You can, of course, you cannot compare it with Cassandra, Tomcat, but maybe in the future. It was initiated in 2019, but we are still, we have some open source community around the world. I am, for example, visiting Tallinn, Estonia. We have contributors from US, Canada. We have some with China, India, and so on. You can check it out. It's a very nice API gateway solution. And as you can see, API plugins, it's a very hard mechanism in API gateway that can be plugged into your API gateway solution. With that, you can extend further some functionalities. You can enable cross-captain constants like authorization, authentication, security, transformation, rate limiting, and so on. At the same time, you can enable some kind of observation, right? And when you're using API 6, for example, you should face with multiple types of plugins broken down into several categories, or sometimes you want something custom plugin, right? To fit your needs. And with API 6, similar API gateway nowadays, more than API gateway provides some language support. You can choose your favorite language, your familiar reach, and you can create some custom plugins. Maybe you are Java developer, or maybe you are Go developer or Python, you can choose your favorite language and write the plugins. Let me show you. Or you don't want to write a code. There is a dashboard where you can do user-friendly dashboard by using it. You can just drag and drop existing plugins together to build new plugins. You can orchestrate one or multiple plugins in this way. You can specify some conditions and also put some business flow on it and generate new plugins. It's a very useful feature that API 6 dashboard provides. For example, you can put together multiple observability plugins in one flow and then maybe enable full observability backend tools in this diagram. Let me, you can just maybe observe later. Now let's jump into the main topic. What's the API observability? Can anyone tell what's the API observability? In one word. No? No. The other problem, like relation and latency, or just great status codes. Traces, yes, right? And for, I think I gave to you this short, right? For your, yeah. The actual thing is doing is very important. Yes, it's also right, yeah. And it means API observability is all about how you absorb your APIs, right? Instead of relying on predetermined data like metrics, monitoring, and wait for the failure, you can use API observability to enable announce, announce, or announce, in this diagram as you can see. Because compared to traditional API monitoring, we have traditional API monitoring and observability, right? This is monitoring focused on analyzing now and announce, what does it mean? Now and announce means you know what the measure, you know the number of requests, you know number of errors, that you know what the measure, right? But on the other hand, API observability lets you analyze exactly what was the issue, and how this issue occurred by learning three metrics, right? You know, again, like logging and metrics and tracing. So because API observability nowadays is a part of every API development teams, let's say, for example, who can use API observability during the API development? Yes, you can see, for example, product managers, they can use to learn consumption and usage of your APIs. Or maybe security team, they can use to protect or maybe detect some possible API threats from outside, right? So as I said, let's have a look at these three pillars now and learn what API gateway can provide as a solution for these pillars, tracing, logging, and metrics. If I start with logging, it's a very tribal step, right? To start your observability because you can use logs to identify or debug what's happening. If you are a junior developer, you will first start digging into logs because in order to understand the project, because the project has zero documentation, you need to have a look at logs, you need to have a look at some API things. So here, in order to enable this logging, you can use some kind of plugins. For example, API 6 provides HTTP-logger plugin, Kafka-logger, or it depends on which kind of integration you have. For example, you can use Google Cloud Logger. Let's say HTTP-logger is a basic logger. Let's just enable to push all the log data from your API gateway to HTTP-S or HTTP servers. It means you can further drive some useful metrics from that logs. Or let's say, what about metrics? Metrics are actually just the data collected over the time, right? Times gas, but the metrics collected. But metrics you can use in the future in the distributed systems like Elasticsearch. You can acquire these metrics using Elasticsearch, or maybe you can show these metrics by using a dashboard, like a Prometheus, right? The Prometheus dashboard provides some metric analysis. And for these, all the external popular platforms, let's say, like Grafana or Prometheus, Apache PR6 has pre-built connectors, I would say. And for example, like Zipkin. For tracing, we have Zipping plugin. You can just enable it with just one click, and it starts to learn some metrics or traces and so on. So now, enough talking, right? I can show something in real. Because we have a bunch of plugins, as I said, for the API observability, this time I decided to choose, for my demo, Prometheus plugin. Because with respect to Fabian, and I really like Prometheus and Grafana integration, now I will show you how you can easily enable this observability very fast. For that, I mean, you can have a look. That is my report, api6.net docker. It shows all the use cases of API GitHub in one report. And it has a branch called the API observability. If you navigate this branch, you will see a real example of some plugins, how to enable it, and you can have a hands-on exercises. Now, let me switch to my VS code. I'm using the VS code today for the session. But I'm talking about this repository. It has a five branch. You can learn some of the branch, like how you can enable health check, start from health check, and API observability. This is the starting point for you. And then it's very fast to spin up this project, because it uses docker-compose. And we are using, for the backend, api6.net, you can use Java project. It doesn't matter. You can use Python. I'm actually a Java developer, but I like to encourage myself to learn new languages. I start to learn C-sharp, and this small project on .net. So if you do some docker-compose app, docker-api6, of course, it will bring some containers, right? All useful containers, as you can see, like Prometheus, Grafana. We have a product API that is with .net. I have a small endpoint that maybe returns some list of products when you call this endpoint. As you can see, it's very simple here. When I do this, it returns... Let me maybe make it bigger here. It returns a MacBook price and some other product price. Simple. And also, I'm using Windows on my machine, some of the necessary containers are up and running in one kind of docker-compose app. Then if you open the project code on your favorite IDEA or IDEA tool, right? In my case, let's say VS Code, and you can see on the Commons folder some common line examples that I'm going to show today. First thing, how you can enable this Grafana or Prometheus, Zipkin, and so on. With API Gateway, you need to create your first upstream. If you navigate this here, you can see some kind of command. Of course, you can use a dashboard to create this upstream. It's up to you. If you're like a hard worker developer like me, you can just use the kind of commands. What we are doing here, as you can see, I had a product API, right? And then I am creating upstream. And upstream means just a set of backend API endpoints. And I have one single node, one node. You can have multiple nodes. You can have multiple instance of the same product API. For the simple case, I'm just creating this one upstream and one node. Let's jump into maybe terminal. I can open some new terminal here to run this code. So I'm using VSL, because on Windows it's a little bit difficult to run a Linux code. So let me open maybe one more terminal on the Ubuntu. There we go. I hope it's visible. And if I just click and press Enter, now I set API 6. Please create the upstream service. Register my ESP.NET Web API as a backend service. And it should have this kind of configuration. Then next step, next easy step, what I do is I need to create, let's say for prometers, I need to create a row. Because API Gateway has three very basics, like you need to create the upstream, you need to create a row, and enable some plugins. In my case, prometers plugins, right? As you can see, I have some plugins configuration on the top. Only single prometers. And I'm giving reference to the upstream that in the previous step we created. And that's all. Like I'm saying also, URI, for the row to find out which URI this plugin should absorb. I'm saying fresh API slash products. Here we go. And then if I get this command and press and put it to terminal, now I will enable this plugin very fast. An API six admin is saying, okay, now you have a row, you have upstream, now it's time to test. Prometers plugin, I enabled like this couple of steps, right? You see the five seconds or six seconds, it's all. But compared to Java projects, how you enable prometers also, maybe a little bit compared to the same steps. But this API Gateway, you are just extracting a little bit of huge work to separate service. And it's highly scalable. That's one of the advantages of using API Gateway, right? For your observability. And next, for example, I can generate some metrics by calling my maybe API into point several times, maybe like this. As you can see, it's responding me with the product list in the response. Maybe I can do it one more time. So we have some data on it. And now, if I navigate to... Maybe if I can request all the prometers metrics to see some result, right, in this output, I can run another command, maybe like this. Here we go. As you can see, metrics are enabled. I can see some metrics, HTTP metrics, plus some API six metrics, as you can see. If you have API six HTTP status, it was 200 returned and was fine. And, of course, it looks like a little bit ugly, right? Now, you can see even maybe these metrics on the dashboard. Just navigate to localhosts-targets, because we are running on localhost. When you deploy maybe to the cloud, you will have a domain and so on. But as you can see on the prometers, if I refresh it, you will have soon now some metrics on it. Of course, you can specify some parameters for your metrics. And let me... We need to maybe a little bit wait to be enabled these metrics on the UI. Yeah. Let me check the targets. It's unhealthy. Maybe we need to do some local compost down and up. Every time when it comes to demo, something fails. It's unexpected, not expected. Docker compost down. Maybe I will do this trick. And maybe then an up in a moment. Yep. And here we go. If I do up, it will bring and refresh some Docker stuff. This Docker always is kind of a issue. Now, if I do this, targets should be... No, no. It's still yes. It's stopping. Yes. Now we are in an upstate. And then let me also generate some logs once again. Or even it should be visible now. Let me go. API 6. HTTP status, if I have any. Or even you can see any traces, any metrics here. As you can see, I can even see ETCD. ETCD has a storage for the API 6. What kind of data exchanging between API 6 and the storage? And so on. I mean, you can filter out all the metrics you want. And even you can see in the graph. If it's not enough on a promises dashboard, you can connect with Grafana, right? Very easy. We have an API 6 Grafana dashboard. You can easily integrate also these logs and metrics by visualizing them. So with it, that was a very easy demo. I think we can continue. If you're interested in that, you can play with other plugins straightforward. And now maybe we can switch to my presentation. And maybe if you have any questions, we can jump into question presentation because we are already running out of time. Here are some references I'm giving out to you. For you. Yep. Any questions? OK, thanks. Thanks a lot. So, I have one more t-shirt. Yeah, I have a question regarding the plugins. For instance, with traffic, you have to kind of connect it to pilot and download them as it starts. How do you develop custom plugins for API 6 and how do you package them with the API gateway? Sorry, once again, last few sentences. There was a door is open. Sure. I was just wondering about plugin development, like how rich is the ecosystem for API 6. And if I were to develop a plugin, is it easy to package with the binary or do I have to connect to some kind of pilot and it downloads it? Yeah, very nice question. I love it. Very nice question. Yeah, it's very straightforward because we have now support for five different languages. If you are using this support program in English, we have plugin runners. You don't have to build anything. You can just run. Of course, you need to create some binaries for Java, let's say, Java file. And this Java file has a connection by using Unix socket files. It can communicate with Unix socket files and you can exchange some log data. I mean, the request data. I had another presentation also. Maybe I can share with you after the session about how to write in Java plugin, how to create plugin maybe in Python and so on. This is a t-shirt for you. So I will keep it. More questions? But I don't have a t-shirt. Hello. How do you compare API 6 to other API gateways like Gravity, Kong, or... Which API gateways again? How do you compare API 6 to other API gateways on the market? How do I compare or... What's its main selling point? Sorry, once again. What's its main selling point? Why is it better than other API gateways? Code coverage, do you mean? Compared to the others, I think it's a little bit... I think it would be a little bit hard to listen from that. I will come to... There's a lot of API gateways on the market. Yes, yes. Why is API 6... Oh, do you mean benchmarking? Ah, okay, I got it. I'm not, of course, trying to sell API 6, right? Even if I have a t-shirt. I'm just giving out a t-shirt. I'm an open source contributor because one reason is it provides hot reloading of plugins. You don't have to stop your instance. You don't have to stop the instance. You can just run these plugins on the fly. You can switch off one plugin. You can write your custom plugin enable while this API 6 instance is running. This is one of the advantages that any other API gateways they don't provide. And the performance is on the top now compared to com API gateway. Our performance is high, twice faster. You can check it out. And we have... API 6 not only has API gateway, it has also English controller. You can use it for Kubernetes English controller or even you can extend it to a service mesh for your Kubernetes services. That's one of the advantages. But these advantages also exist, of course. It is open source, too. Yeah. I hope I could answer. Sorry, it was a little bit hard to listen to. Okay. Could you please elaborate a little bit on the scalability of those plugins? It would be nice. You're worrying about how it's scalable, right? How much it can carry? How much observations can be done? Good question. You can enable multiple plugins. It's this up to you how many plugins you would like to use. And there should be some problems when it comes to millions, maybe billions of API calls. That's why we have different deployment modes. For example, you can deploy API 6 as a standalone or maybe you can deploy with multiple API 6 instance one storage. Or one API 6, different types of storage. Because ITCD is compared to other relational database, non-relational database, super fast to first data. That's why it's also easy to deploy in many places. That's scalable without any issue. Yeah. Does it make sense? Yeah, just a quick question. I saw there you had API 6 EngineX. Is EngineX the underlying API gateway? And API 6 sits on top of it and expands the capabilities of it. Because EngineX is quite limited in that. Yeah, true. EngineX is the root of the API 6. It's built on the top of EngineX. But it provides additional features, right? Yeah. We have one more question. I'll try to make it short. Can API 6 work with GraphQL APIs? Yes. GraphQL, I think nowadays became very popular also. Sorry. I think Nikola also had the talk about tracing, right? He has some of the talks about this GraphQL. We are improving, we're contributing more now, massively on the GraphQL. My answer is it's possible, yes. You can try it out. Any other questions? OK. Thanks a lot, everyone. Thank you for coming. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.0, "text": " Welcome, Bobor.", "tokens": [50364, 4027, 11, 6085, 284, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2607147428724501, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.46686792373657227}, {"id": 1, "seek": 0, "start": 5.0, "end": 9.0, "text": " Hi, everyone. Thank you.", "tokens": [50614, 2421, 11, 1518, 13, 1044, 291, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2607147428724501, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.46686792373657227}, {"id": 2, "seek": 0, "start": 9.0, "end": 14.0, "text": " Thank you. Hi, everyone.", "tokens": [50814, 1044, 291, 13, 2421, 11, 1518, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2607147428724501, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.46686792373657227}, {"id": 3, "seek": 0, "start": 14.0, "end": 16.0, "text": " I am super excited to be here.", "tokens": [51064, 286, 669, 1687, 2919, 281, 312, 510, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2607147428724501, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.46686792373657227}, {"id": 4, "seek": 0, "start": 16.0, "end": 19.0, "text": " Welcome to one of my sessions about", "tokens": [51164, 4027, 281, 472, 295, 452, 11081, 466, 51314], "temperature": 0.0, "avg_logprob": -0.2607147428724501, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.46686792373657227}, {"id": 5, "seek": 0, "start": 19.0, "end": 23.0, "text": " observing your APIs with API gateway plugins.", "tokens": [51314, 22107, 428, 21445, 365, 9362, 28532, 33759, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2607147428724501, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.46686792373657227}, {"id": 6, "seek": 0, "start": 23.0, "end": 25.0, "text": " Let me introduce myself first.", "tokens": [51514, 961, 385, 5366, 2059, 700, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2607147428724501, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.46686792373657227}, {"id": 7, "seek": 0, "start": 25.0, "end": 27.0, "text": " My name is Bobor.", "tokens": [51614, 1222, 1315, 307, 6085, 284, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2607147428724501, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.46686792373657227}, {"id": 8, "seek": 2700, "start": 27.0, "end": 30.0, "text": " I am a developer advocate for Apache API 6.", "tokens": [50364, 286, 669, 257, 10754, 14608, 337, 46597, 9362, 1386, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 9, "seek": 2700, "start": 30.0, "end": 33.0, "text": " Sometimes it's so difficult to pronounce my name.", "tokens": [50514, 4803, 309, 311, 370, 2252, 281, 19567, 452, 1315, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 10, "seek": 2700, "start": 33.0, "end": 35.0, "text": " People say it's from different countries.", "tokens": [50664, 3432, 584, 309, 311, 490, 819, 3517, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 11, "seek": 2700, "start": 35.0, "end": 38.0, "text": " Is it like a Bebo or Bobor or like a Bebo?", "tokens": [50764, 1119, 309, 411, 257, 879, 1763, 420, 6085, 284, 420, 411, 257, 879, 1763, 30, 50914], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 12, "seek": 2700, "start": 38.0, "end": 43.0, "text": " And then I say, okay, you can translate my first name as a tiger.", "tokens": [50914, 400, 550, 286, 584, 11, 1392, 11, 291, 393, 13799, 452, 700, 1315, 382, 257, 21432, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 13, "seek": 2700, "start": 43.0, "end": 45.0, "text": " It means tiger, Bobor.", "tokens": [51164, 467, 1355, 21432, 11, 6085, 284, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 14, "seek": 2700, "start": 45.0, "end": 49.0, "text": " My last name, Murzokov, English version will be Livermore.", "tokens": [51264, 1222, 1036, 1315, 11, 9373, 89, 453, 5179, 11, 3669, 3037, 486, 312, 28010, 3138, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 15, "seek": 2700, "start": 49.0, "end": 51.0, "text": " In this case, Tiger Livermore.", "tokens": [51464, 682, 341, 1389, 11, 22025, 28010, 3138, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 16, "seek": 2700, "start": 51.0, "end": 53.0, "text": " You can call me like Tiger Livermore.", "tokens": [51564, 509, 393, 818, 385, 411, 22025, 28010, 3138, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 17, "seek": 2700, "start": 53.0, "end": 55.0, "text": " It's up to you.", "tokens": [51664, 467, 311, 493, 281, 291, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1834079474210739, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.2121628075838089}, {"id": 18, "seek": 5500, "start": 55.0, "end": 58.0, "text": " And you can also reach out to me on these social channels", "tokens": [50364, 400, 291, 393, 611, 2524, 484, 281, 385, 322, 613, 2093, 9235, 50514], "temperature": 0.0, "avg_logprob": -0.15477611172583797, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.07248683273792267}, {"id": 19, "seek": 5500, "start": 58.0, "end": 61.0, "text": " if you have any questions regarding sessions.", "tokens": [50514, 498, 291, 362, 604, 1651, 8595, 11081, 13, 50664], "temperature": 0.0, "avg_logprob": -0.15477611172583797, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.07248683273792267}, {"id": 20, "seek": 5500, "start": 61.0, "end": 64.0, "text": " So with that, we can get started.", "tokens": [50664, 407, 365, 300, 11, 321, 393, 483, 1409, 13, 50814], "temperature": 0.0, "avg_logprob": -0.15477611172583797, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.07248683273792267}, {"id": 21, "seek": 5500, "start": 64.0, "end": 67.0, "text": " First thing first, what I want to do now is take a selfie", "tokens": [50814, 2386, 551, 700, 11, 437, 286, 528, 281, 360, 586, 307, 747, 257, 22147, 50964], "temperature": 0.0, "avg_logprob": -0.15477611172583797, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.07248683273792267}, {"id": 22, "seek": 5500, "start": 67.0, "end": 70.0, "text": " because I have my TikTok account.", "tokens": [50964, 570, 286, 362, 452, 20211, 2696, 13, 51114], "temperature": 0.0, "avg_logprob": -0.15477611172583797, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.07248683273792267}, {"id": 23, "seek": 5500, "start": 70.0, "end": 73.0, "text": " I just start to run my blog recently.", "tokens": [51114, 286, 445, 722, 281, 1190, 452, 6968, 3938, 13, 51264], "temperature": 0.0, "avg_logprob": -0.15477611172583797, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.07248683273792267}, {"id": 24, "seek": 5500, "start": 73.0, "end": 78.0, "text": " Just a moment. Maybe this is better.", "tokens": [51264, 1449, 257, 1623, 13, 2704, 341, 307, 1101, 13, 51514], "temperature": 0.0, "avg_logprob": -0.15477611172583797, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.07248683273792267}, {"id": 25, "seek": 5500, "start": 78.0, "end": 81.0, "text": " That was good. Thank you.", "tokens": [51514, 663, 390, 665, 13, 1044, 291, 13, 51664], "temperature": 0.0, "avg_logprob": -0.15477611172583797, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.07248683273792267}, {"id": 26, "seek": 8100, "start": 81.0, "end": 85.0, "text": " I will just put some hashtags on that.", "tokens": [50364, 286, 486, 445, 829, 512, 50016, 322, 300, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13569000363349915, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.21343940496444702}, {"id": 27, "seek": 8100, "start": 85.0, "end": 87.0, "text": " So thank you Fabiano. Now I can leave.", "tokens": [50564, 407, 1309, 291, 17440, 6254, 13, 823, 286, 393, 1856, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13569000363349915, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.21343940496444702}, {"id": 28, "seek": 8100, "start": 87.0, "end": 90.0, "text": " I did my job. I can go home.", "tokens": [50664, 286, 630, 452, 1691, 13, 286, 393, 352, 1280, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13569000363349915, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.21343940496444702}, {"id": 29, "seek": 8100, "start": 90.0, "end": 93.0, "text": " I did my Instagram picture, right?", "tokens": [50814, 286, 630, 452, 5281, 3036, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.13569000363349915, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.21343940496444702}, {"id": 30, "seek": 8100, "start": 93.0, "end": 97.0, "text": " But I have today a very interesting agenda for you.", "tokens": [50964, 583, 286, 362, 965, 257, 588, 1880, 9829, 337, 291, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13569000363349915, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.21343940496444702}, {"id": 31, "seek": 8100, "start": 97.0, "end": 101.0, "text": " We'll talk about what is APIs and API observability", "tokens": [51164, 492, 603, 751, 466, 437, 307, 21445, 293, 9362, 9951, 2310, 51364], "temperature": 0.0, "avg_logprob": -0.13569000363349915, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.21343940496444702}, {"id": 32, "seek": 8100, "start": 101.0, "end": 107.0, "text": " and how we can use API gateway for observing your APIs", "tokens": [51364, 293, 577, 321, 393, 764, 9362, 28532, 337, 22107, 428, 21445, 51664], "temperature": 0.0, "avg_logprob": -0.13569000363349915, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.21343940496444702}, {"id": 33, "seek": 8100, "start": 107.0, "end": 109.0, "text": " as a central point for observation.", "tokens": [51664, 382, 257, 5777, 935, 337, 14816, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13569000363349915, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.21343940496444702}, {"id": 34, "seek": 10900, "start": 109.0, "end": 113.0, "text": " And then we will break down all API observability three pillars.", "tokens": [50364, 400, 550, 321, 486, 1821, 760, 439, 9362, 9951, 2310, 1045, 26729, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 35, "seek": 10900, "start": 113.0, "end": 118.0, "text": " We know that we have logging, tracing, and metrics, right?", "tokens": [50564, 492, 458, 300, 321, 362, 27991, 11, 25262, 11, 293, 16367, 11, 558, 30, 50814], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 36, "seek": 10900, "start": 118.0, "end": 121.0, "text": " And we will learn how to enable these three pillars", "tokens": [50814, 400, 321, 486, 1466, 577, 281, 9528, 613, 1045, 26729, 50964], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 37, "seek": 10900, "start": 121.0, "end": 124.0, "text": " by using Apache API 6 plugins.", "tokens": [50964, 538, 1228, 46597, 9362, 1386, 33759, 13, 51114], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 38, "seek": 10900, "start": 124.0, "end": 127.0, "text": " And I have then a small demo for you.", "tokens": [51114, 400, 286, 362, 550, 257, 1359, 10723, 337, 291, 13, 51264], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 39, "seek": 10900, "start": 127.0, "end": 129.0, "text": " I hope you will like it.", "tokens": [51264, 286, 1454, 291, 486, 411, 309, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 40, "seek": 10900, "start": 129.0, "end": 131.0, "text": " And that's good.", "tokens": [51364, 400, 300, 311, 665, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 41, "seek": 10900, "start": 131.0, "end": 132.0, "text": " APIs, right?", "tokens": [51464, 21445, 11, 558, 30, 51514], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 42, "seek": 10900, "start": 132.0, "end": 134.0, "text": " API is just the three letters", "tokens": [51514, 9362, 307, 445, 264, 1045, 7825, 51614], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 43, "seek": 10900, "start": 134.0, "end": 136.0, "text": " acronym for application program interface.", "tokens": [51614, 39195, 337, 3861, 1461, 9226, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14583503282987154, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.050893403589725494}, {"id": 44, "seek": 13600, "start": 136.0, "end": 139.0, "text": " By now, we are all familiar with this term, right?", "tokens": [50364, 3146, 586, 11, 321, 366, 439, 4963, 365, 341, 1433, 11, 558, 30, 50514], "temperature": 0.0, "avg_logprob": -0.18209921959603187, "compression_ratio": 1.4700854700854702, "no_speech_prob": 0.04617410525679588}, {"id": 45, "seek": 13600, "start": 139.0, "end": 144.0, "text": " Because we are living in increasingly API-centric world.", "tokens": [50514, 1436, 321, 366, 2647, 294, 12980, 9362, 12, 45300, 1002, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18209921959603187, "compression_ratio": 1.4700854700854702, "no_speech_prob": 0.04617410525679588}, {"id": 46, "seek": 13600, "start": 144.0, "end": 147.0, "text": " Even chat GPT uses API.", "tokens": [50764, 2754, 5081, 26039, 51, 4960, 9362, 13, 50914], "temperature": 0.0, "avg_logprob": -0.18209921959603187, "compression_ratio": 1.4700854700854702, "no_speech_prob": 0.04617410525679588}, {"id": 47, "seek": 13600, "start": 147.0, "end": 151.0, "text": " Because under the hood, it calls some OpenAI API lists", "tokens": [50914, 1436, 833, 264, 13376, 11, 309, 5498, 512, 7238, 48698, 9362, 14511, 51114], "temperature": 0.0, "avg_logprob": -0.18209921959603187, "compression_ratio": 1.4700854700854702, "no_speech_prob": 0.04617410525679588}, {"id": 48, "seek": 13600, "start": 151.0, "end": 154.0, "text": " to collect some language models.", "tokens": [51114, 281, 2500, 512, 2856, 5245, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18209921959603187, "compression_ratio": 1.4700854700854702, "no_speech_prob": 0.04617410525679588}, {"id": 49, "seek": 13600, "start": 154.0, "end": 156.0, "text": " Now my question to you.", "tokens": [51264, 823, 452, 1168, 281, 291, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18209921959603187, "compression_ratio": 1.4700854700854702, "no_speech_prob": 0.04617410525679588}, {"id": 50, "seek": 13600, "start": 156.0, "end": 160.0, "text": " Who doesn't know what is API?", "tokens": [51364, 2102, 1177, 380, 458, 437, 307, 9362, 30, 51564], "temperature": 0.0, "avg_logprob": -0.18209921959603187, "compression_ratio": 1.4700854700854702, "no_speech_prob": 0.04617410525679588}, {"id": 51, "seek": 13600, "start": 160.0, "end": 162.0, "text": " Everybody knows. You don't know.", "tokens": [51564, 7646, 3255, 13, 509, 500, 380, 458, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18209921959603187, "compression_ratio": 1.4700854700854702, "no_speech_prob": 0.04617410525679588}, {"id": 52, "seek": 13600, "start": 162.0, "end": 165.0, "text": " You are lucky I have a brief for you.", "tokens": [51664, 509, 366, 6356, 286, 362, 257, 5353, 337, 291, 13, 51814], "temperature": 0.0, "avg_logprob": -0.18209921959603187, "compression_ratio": 1.4700854700854702, "no_speech_prob": 0.04617410525679588}, {"id": 53, "seek": 16500, "start": 165.0, "end": 170.0, "text": " You will get this T-shirt because you don't know what's API 6.", "tokens": [50364, 509, 486, 483, 341, 314, 12, 15313, 570, 291, 500, 380, 458, 437, 311, 9362, 1386, 13, 50614], "temperature": 0.0, "avg_logprob": -0.17683045905933045, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.020485427230596542}, {"id": 54, "seek": 16500, "start": 170.0, "end": 173.0, "text": " What is your size?", "tokens": [50614, 708, 307, 428, 2744, 30, 50764], "temperature": 0.0, "avg_logprob": -0.17683045905933045, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.020485427230596542}, {"id": 55, "seek": 16500, "start": 173.0, "end": 176.0, "text": " I will handle it for you here.", "tokens": [50764, 286, 486, 4813, 309, 337, 291, 510, 13, 50914], "temperature": 0.0, "avg_logprob": -0.17683045905933045, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.020485427230596542}, {"id": 56, "seek": 16500, "start": 176.0, "end": 178.0, "text": " Actually, I have enough T-shirts.", "tokens": [50914, 5135, 11, 286, 362, 1547, 314, 12, 25892, 13, 51014], "temperature": 0.0, "avg_logprob": -0.17683045905933045, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.020485427230596542}, {"id": 57, "seek": 16500, "start": 178.0, "end": 181.0, "text": " If you are first the three good,", "tokens": [51014, 759, 291, 366, 700, 264, 1045, 665, 11, 51164], "temperature": 0.0, "avg_logprob": -0.17683045905933045, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.020485427230596542}, {"id": 58, "seek": 16500, "start": 181.0, "end": 184.0, "text": " if I get the first three good answer, I will give it to you.", "tokens": [51164, 498, 286, 483, 264, 700, 1045, 665, 1867, 11, 286, 486, 976, 309, 281, 291, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17683045905933045, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.020485427230596542}, {"id": 59, "seek": 16500, "start": 184.0, "end": 188.0, "text": " And we have also some medals, stickers if you would like to get,", "tokens": [51314, 400, 321, 362, 611, 512, 38647, 11, 21019, 498, 291, 576, 411, 281, 483, 11, 51514], "temperature": 0.0, "avg_logprob": -0.17683045905933045, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.020485427230596542}, {"id": 60, "seek": 16500, "start": 188.0, "end": 189.0, "text": " please feel free.", "tokens": [51514, 1767, 841, 1737, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17683045905933045, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.020485427230596542}, {"id": 61, "seek": 16500, "start": 189.0, "end": 193.0, "text": " It's like free stuff from community, I would say.", "tokens": [51564, 467, 311, 411, 1737, 1507, 490, 1768, 11, 286, 576, 584, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17683045905933045, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.020485427230596542}, {"id": 62, "seek": 19300, "start": 193.0, "end": 197.0, "text": " And we know that success of your services, right,", "tokens": [50364, 400, 321, 458, 300, 2245, 295, 428, 3328, 11, 558, 11, 50564], "temperature": 0.0, "avg_logprob": -0.17705551147460938, "compression_ratio": 1.8657407407407407, "no_speech_prob": 0.04887251555919647}, {"id": 63, "seek": 19300, "start": 197.0, "end": 202.0, "text": " depends on the performance, availability, and integrity of your APIs.", "tokens": [50564, 5946, 322, 264, 3389, 11, 17945, 11, 293, 16000, 295, 428, 21445, 13, 50814], "temperature": 0.0, "avg_logprob": -0.17705551147460938, "compression_ratio": 1.8657407407407407, "no_speech_prob": 0.04887251555919647}, {"id": 64, "seek": 19300, "start": 202.0, "end": 204.0, "text": " Here, another question, Rice.", "tokens": [50814, 1692, 11, 1071, 1168, 11, 19386, 13, 50914], "temperature": 0.0, "avg_logprob": -0.17705551147460938, "compression_ratio": 1.8657407407407407, "no_speech_prob": 0.04887251555919647}, {"id": 65, "seek": 19300, "start": 204.0, "end": 208.0, "text": " How to achieve these three indicators of success?", "tokens": [50914, 1012, 281, 4584, 613, 1045, 22176, 295, 2245, 30, 51114], "temperature": 0.0, "avg_logprob": -0.17705551147460938, "compression_ratio": 1.8657407407407407, "no_speech_prob": 0.04887251555919647}, {"id": 66, "seek": 19300, "start": 208.0, "end": 212.0, "text": " How to achieve these three indicators of success for your APIs?", "tokens": [51114, 1012, 281, 4584, 613, 1045, 22176, 295, 2245, 337, 428, 21445, 30, 51314], "temperature": 0.0, "avg_logprob": -0.17705551147460938, "compression_ratio": 1.8657407407407407, "no_speech_prob": 0.04887251555919647}, {"id": 67, "seek": 19300, "start": 212.0, "end": 215.0, "text": " Let's say we have API should be all the time available, right?", "tokens": [51314, 961, 311, 584, 321, 362, 9362, 820, 312, 439, 264, 565, 2435, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.17705551147460938, "compression_ratio": 1.8657407407407407, "no_speech_prob": 0.04887251555919647}, {"id": 68, "seek": 19300, "start": 215.0, "end": 217.0, "text": " It should be integratable.", "tokens": [51464, 467, 820, 312, 3572, 31415, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17705551147460938, "compression_ratio": 1.8657407407407407, "no_speech_prob": 0.04887251555919647}, {"id": 69, "seek": 19300, "start": 217.0, "end": 220.0, "text": " It should be performance with a high performance.", "tokens": [51564, 467, 820, 312, 3389, 365, 257, 1090, 3389, 13, 51714], "temperature": 0.0, "avg_logprob": -0.17705551147460938, "compression_ratio": 1.8657407407407407, "no_speech_prob": 0.04887251555919647}, {"id": 70, "seek": 22000, "start": 220.0, "end": 223.0, "text": " Do you have any idea?", "tokens": [50364, 1144, 291, 362, 604, 1558, 30, 50514], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 71, "seek": 22000, "start": 223.0, "end": 227.0, "text": " Yes, you got one T-shirt.", "tokens": [50514, 1079, 11, 291, 658, 472, 314, 12, 15313, 13, 50714], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 72, "seek": 22000, "start": 227.0, "end": 229.0, "text": " Yes, monitoring, exactly.", "tokens": [50714, 1079, 11, 11028, 11, 2293, 13, 50814], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 73, "seek": 22000, "start": 229.0, "end": 232.0, "text": " And what do you say, distributing?", "tokens": [50814, 400, 437, 360, 291, 584, 11, 41406, 30, 50964], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 74, "seek": 22000, "start": 232.0, "end": 235.0, "text": " Yeah, distribute system, monitoring?", "tokens": [50964, 865, 11, 20594, 1185, 11, 11028, 30, 51114], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 75, "seek": 22000, "start": 235.0, "end": 240.0, "text": " Just placing it as a service in a distributed process.", "tokens": [51114, 1449, 17221, 309, 382, 257, 2643, 294, 257, 12631, 1399, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 76, "seek": 22000, "start": 240.0, "end": 241.0, "text": " Yeah, this is also a rice solution.", "tokens": [51364, 865, 11, 341, 307, 611, 257, 5090, 3827, 13, 51414], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 77, "seek": 22000, "start": 241.0, "end": 244.0, "text": " But you will get only the medal.", "tokens": [51414, 583, 291, 486, 483, 787, 264, 21364, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 78, "seek": 22000, "start": 244.0, "end": 245.0, "text": " Sorry.", "tokens": [51564, 4919, 13, 51614], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 79, "seek": 22000, "start": 245.0, "end": 249.0, "text": " But one solution can be using by API gateways.", "tokens": [51614, 583, 472, 3827, 393, 312, 1228, 538, 9362, 8539, 942, 13, 51814], "temperature": 0.0, "avg_logprob": -0.24141194122006196, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.08517789095640182}, {"id": 80, "seek": 24900, "start": 249.0, "end": 253.0, "text": " Because API gateways, actually, nowadays, what we do,", "tokens": [50364, 1436, 9362, 8539, 942, 11, 767, 11, 13434, 11, 437, 321, 360, 11, 50564], "temperature": 0.0, "avg_logprob": -0.1480740000692646, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0458068810403347}, {"id": 81, "seek": 24900, "start": 253.0, "end": 257.0, "text": " we build multiple microservices and maybe several less APIs", "tokens": [50564, 321, 1322, 3866, 15547, 47480, 293, 1310, 2940, 1570, 21445, 50764], "temperature": 0.0, "avg_logprob": -0.1480740000692646, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0458068810403347}, {"id": 82, "seek": 24900, "start": 257.0, "end": 263.0, "text": " or multiple REST APIs for our unique, maybe, the service, right?", "tokens": [50764, 420, 3866, 497, 14497, 21445, 337, 527, 3845, 11, 1310, 11, 264, 2643, 11, 558, 30, 51064], "temperature": 0.0, "avg_logprob": -0.1480740000692646, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0458068810403347}, {"id": 83, "seek": 24900, "start": 263.0, "end": 267.0, "text": " And in this flow, API gateways serves as a central point", "tokens": [51064, 400, 294, 341, 3095, 11, 9362, 8539, 942, 13451, 382, 257, 5777, 935, 51264], "temperature": 0.0, "avg_logprob": -0.1480740000692646, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0458068810403347}, {"id": 84, "seek": 24900, "start": 267.0, "end": 272.0, "text": " for routing all your incoming requests to the internet destinations.", "tokens": [51264, 337, 32722, 439, 428, 22341, 12475, 281, 264, 4705, 37787, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1480740000692646, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0458068810403347}, {"id": 85, "seek": 24900, "start": 272.0, "end": 275.0, "text": " These destinations can be, as you can see, database,", "tokens": [51514, 1981, 37787, 393, 312, 11, 382, 291, 393, 536, 11, 8149, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1480740000692646, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0458068810403347}, {"id": 86, "seek": 27500, "start": 275.0, "end": 278.0, "text": " or maybe short-party API services.", "tokens": [50364, 420, 1310, 2099, 12, 23409, 9362, 3328, 13, 50514], "temperature": 0.0, "avg_logprob": -0.13541580239931741, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.06591580808162689}, {"id": 87, "seek": 27500, "start": 278.0, "end": 282.0, "text": " Or it can be also some serverless APIs like Azure Function", "tokens": [50514, 1610, 309, 393, 312, 611, 512, 7154, 1832, 21445, 411, 11969, 11166, 882, 50714], "temperature": 0.0, "avg_logprob": -0.13541580239931741, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.06591580808162689}, {"id": 88, "seek": 27500, "start": 282.0, "end": 287.0, "text": " or AWS Lambda, maybe any other open source functions, right?", "tokens": [50714, 420, 17650, 45691, 11, 1310, 604, 661, 1269, 4009, 6828, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.13541580239931741, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.06591580808162689}, {"id": 89, "seek": 27500, "start": 287.0, "end": 291.0, "text": " And it means it's accessed a single layer between your clients", "tokens": [50964, 400, 309, 1355, 309, 311, 34211, 257, 2167, 4583, 1296, 428, 6982, 51164], "temperature": 0.0, "avg_logprob": -0.13541580239931741, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.06591580808162689}, {"id": 90, "seek": 27500, "start": 291.0, "end": 294.0, "text": " and the backend services, right?", "tokens": [51164, 293, 264, 38087, 3328, 11, 558, 30, 51314], "temperature": 0.0, "avg_logprob": -0.13541580239931741, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.06591580808162689}, {"id": 91, "seek": 27500, "start": 294.0, "end": 298.0, "text": " That can manage all the traffic coming to your backend services.", "tokens": [51314, 663, 393, 3067, 439, 264, 6419, 1348, 281, 428, 38087, 3328, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13541580239931741, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.06591580808162689}, {"id": 92, "seek": 27500, "start": 298.0, "end": 300.0, "text": " It's a very straightforward term, right?", "tokens": [51514, 467, 311, 257, 588, 15325, 1433, 11, 558, 30, 51614], "temperature": 0.0, "avg_logprob": -0.13541580239931741, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.06591580808162689}, {"id": 93, "seek": 27500, "start": 300.0, "end": 301.0, "text": " API gateway term.", "tokens": [51614, 9362, 28532, 1433, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13541580239931741, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.06591580808162689}, {"id": 94, "seek": 30100, "start": 301.0, "end": 306.0, "text": " And then it can also be a right point to learn", "tokens": [50364, 400, 550, 309, 393, 611, 312, 257, 558, 935, 281, 1466, 50614], "temperature": 0.0, "avg_logprob": -0.07595509574526832, "compression_ratio": 1.5601851851851851, "no_speech_prob": 0.0441443994641304}, {"id": 95, "seek": 30100, "start": 306.0, "end": 311.0, "text": " for your API observabilities because it's uniquely identified", "tokens": [50614, 337, 428, 9362, 9951, 6167, 570, 309, 311, 31474, 9234, 50864], "temperature": 0.0, "avg_logprob": -0.07595509574526832, "compression_ratio": 1.5601851851851851, "no_speech_prob": 0.0441443994641304}, {"id": 96, "seek": 30100, "start": 311.0, "end": 314.0, "text": " to know all the traffic moving from client side", "tokens": [50864, 281, 458, 439, 264, 6419, 2684, 490, 6423, 1252, 51014], "temperature": 0.0, "avg_logprob": -0.07595509574526832, "compression_ratio": 1.5601851851851851, "no_speech_prob": 0.0441443994641304}, {"id": 97, "seek": 30100, "start": 314.0, "end": 316.0, "text": " to our backend service network.", "tokens": [51014, 281, 527, 38087, 2643, 3209, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07595509574526832, "compression_ratio": 1.5601851851851851, "no_speech_prob": 0.0441443994641304}, {"id": 98, "seek": 30100, "start": 316.0, "end": 321.0, "text": " And instead of relying on, let's say, some other technologies,", "tokens": [51114, 400, 2602, 295, 24140, 322, 11, 718, 311, 584, 11, 512, 661, 7943, 11, 51364], "temperature": 0.0, "avg_logprob": -0.07595509574526832, "compression_ratio": 1.5601851851851851, "no_speech_prob": 0.0441443994641304}, {"id": 99, "seek": 30100, "start": 321.0, "end": 326.0, "text": " SDKs, APIs, and services to enable this observability", "tokens": [51364, 37135, 82, 11, 21445, 11, 293, 3328, 281, 9528, 341, 9951, 2310, 51614], "temperature": 0.0, "avg_logprob": -0.07595509574526832, "compression_ratio": 1.5601851851851851, "no_speech_prob": 0.0441443994641304}, {"id": 100, "seek": 30100, "start": 326.0, "end": 328.0, "text": " and improve this observability,", "tokens": [51614, 293, 3470, 341, 9951, 2310, 11, 51714], "temperature": 0.0, "avg_logprob": -0.07595509574526832, "compression_ratio": 1.5601851851851851, "no_speech_prob": 0.0441443994641304}, {"id": 101, "seek": 32800, "start": 328.0, "end": 331.0, "text": " you can easily integrate this job with API gateway.", "tokens": [50364, 291, 393, 3612, 13365, 341, 1691, 365, 9362, 28532, 13, 50514], "temperature": 0.0, "avg_logprob": -0.12417237371461004, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.044905830174684525}, {"id": 102, "seek": 32800, "start": 331.0, "end": 333.0, "text": " We have a bunch of API gateways.", "tokens": [50514, 492, 362, 257, 3840, 295, 9362, 8539, 942, 13, 50614], "temperature": 0.0, "avg_logprob": -0.12417237371461004, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.044905830174684525}, {"id": 103, "seek": 32800, "start": 333.0, "end": 336.0, "text": " I'm not selling anything, but we are talking about now", "tokens": [50614, 286, 478, 406, 6511, 1340, 11, 457, 321, 366, 1417, 466, 586, 50764], "temperature": 0.0, "avg_logprob": -0.12417237371461004, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.044905830174684525}, {"id": 104, "seek": 32800, "start": 336.0, "end": 341.0, "text": " API 6, what kind of plugins you can use today.", "tokens": [50764, 9362, 1386, 11, 437, 733, 295, 33759, 291, 393, 764, 965, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12417237371461004, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.044905830174684525}, {"id": 105, "seek": 32800, "start": 341.0, "end": 346.0, "text": " And next, for example, you can ask, what is Apache API 6?", "tokens": [51014, 400, 958, 11, 337, 1365, 11, 291, 393, 1029, 11, 437, 307, 46597, 9362, 1386, 30, 51264], "temperature": 0.0, "avg_logprob": -0.12417237371461004, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.044905830174684525}, {"id": 106, "seek": 32800, "start": 346.0, "end": 350.0, "text": " Maybe you know the world's largest open source software", "tokens": [51264, 2704, 291, 458, 264, 1002, 311, 6443, 1269, 4009, 4722, 51464], "temperature": 0.0, "avg_logprob": -0.12417237371461004, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.044905830174684525}, {"id": 107, "seek": 32800, "start": 350.0, "end": 352.0, "text": " software foundation, Apache software foundation.", "tokens": [51464, 4722, 7030, 11, 46597, 4722, 7030, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12417237371461004, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.044905830174684525}, {"id": 108, "seek": 32800, "start": 352.0, "end": 355.0, "text": " Maybe some of you are part of it, right?", "tokens": [51564, 2704, 512, 295, 291, 366, 644, 295, 309, 11, 558, 30, 51714], "temperature": 0.0, "avg_logprob": -0.12417237371461004, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.044905830174684525}, {"id": 109, "seek": 32800, "start": 355.0, "end": 357.0, "text": " Who is a part of it, ASF?", "tokens": [51714, 2102, 307, 257, 644, 295, 309, 11, 7469, 37, 30, 51814], "temperature": 0.0, "avg_logprob": -0.12417237371461004, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.044905830174684525}, {"id": 110, "seek": 35700, "start": 357.0, "end": 360.0, "text": " Who is contributing to open source projects of Apache", "tokens": [50364, 2102, 307, 19270, 281, 1269, 4009, 4455, 295, 46597, 50514], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 111, "seek": 35700, "start": 360.0, "end": 362.0, "text": " software foundation?", "tokens": [50514, 4722, 7030, 30, 50614], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 112, "seek": 35700, "start": 362.0, "end": 365.0, "text": " You, we have some people.", "tokens": [50614, 509, 11, 321, 362, 512, 561, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 113, "seek": 35700, "start": 365.0, "end": 370.0, "text": " And who knows Apache Kafka, Cassandra, Tomcat?", "tokens": [50764, 400, 567, 3255, 46597, 47064, 11, 18208, 18401, 11, 5041, 18035, 30, 51014], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 114, "seek": 35700, "start": 370.0, "end": 371.0, "text": " Everybody knows.", "tokens": [51014, 7646, 3255, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 115, "seek": 35700, "start": 371.0, "end": 375.0, "text": " And Apache API 6 is also one of the top fastest growing", "tokens": [51064, 400, 46597, 9362, 1386, 307, 611, 472, 295, 264, 1192, 14573, 4194, 51264], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 116, "seek": 35700, "start": 375.0, "end": 377.0, "text": " project of ESF nowadays.", "tokens": [51264, 1716, 295, 12564, 37, 13434, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 117, "seek": 35700, "start": 377.0, "end": 380.0, "text": " You can, of course, you cannot compare it with Cassandra,", "tokens": [51364, 509, 393, 11, 295, 1164, 11, 291, 2644, 6794, 309, 365, 18208, 18401, 11, 51514], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 118, "seek": 35700, "start": 380.0, "end": 382.0, "text": " Tomcat, but maybe in the future.", "tokens": [51514, 5041, 18035, 11, 457, 1310, 294, 264, 2027, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 119, "seek": 35700, "start": 382.0, "end": 385.0, "text": " It was initiated in 2019, but we are still,", "tokens": [51614, 467, 390, 28578, 294, 6071, 11, 457, 321, 366, 920, 11, 51764], "temperature": 0.0, "avg_logprob": -0.1492492711102521, "compression_ratio": 1.5261044176706828, "no_speech_prob": 0.04006307199597359}, {"id": 120, "seek": 38500, "start": 385.0, "end": 387.0, "text": " we have some open source community around the world.", "tokens": [50364, 321, 362, 512, 1269, 4009, 1768, 926, 264, 1002, 13, 50464], "temperature": 0.0, "avg_logprob": -0.13944847178909014, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.05836743488907814}, {"id": 121, "seek": 38500, "start": 387.0, "end": 390.0, "text": " I am, for example, visiting Tallinn, Estonia.", "tokens": [50464, 286, 669, 11, 337, 1365, 11, 11700, 42633, 7729, 11, 4410, 16999, 13, 50614], "temperature": 0.0, "avg_logprob": -0.13944847178909014, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.05836743488907814}, {"id": 122, "seek": 38500, "start": 390.0, "end": 393.0, "text": " We have contributors from US, Canada.", "tokens": [50614, 492, 362, 45627, 490, 2546, 11, 6309, 13, 50764], "temperature": 0.0, "avg_logprob": -0.13944847178909014, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.05836743488907814}, {"id": 123, "seek": 38500, "start": 393.0, "end": 396.0, "text": " We have some with China, India, and so on.", "tokens": [50764, 492, 362, 512, 365, 3533, 11, 5282, 11, 293, 370, 322, 13, 50914], "temperature": 0.0, "avg_logprob": -0.13944847178909014, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.05836743488907814}, {"id": 124, "seek": 38500, "start": 396.0, "end": 397.0, "text": " You can check it out.", "tokens": [50914, 509, 393, 1520, 309, 484, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13944847178909014, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.05836743488907814}, {"id": 125, "seek": 38500, "start": 397.0, "end": 401.0, "text": " It's a very nice API gateway solution.", "tokens": [50964, 467, 311, 257, 588, 1481, 9362, 28532, 3827, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13944847178909014, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.05836743488907814}, {"id": 126, "seek": 38500, "start": 401.0, "end": 406.0, "text": " And as you can see, API plugins, it's a very hard mechanism", "tokens": [51164, 400, 382, 291, 393, 536, 11, 9362, 33759, 11, 309, 311, 257, 588, 1152, 7513, 51414], "temperature": 0.0, "avg_logprob": -0.13944847178909014, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.05836743488907814}, {"id": 127, "seek": 38500, "start": 406.0, "end": 410.0, "text": " in API gateway that can be plugged into your API gateway", "tokens": [51414, 294, 9362, 28532, 300, 393, 312, 25679, 666, 428, 9362, 28532, 51614], "temperature": 0.0, "avg_logprob": -0.13944847178909014, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.05836743488907814}, {"id": 128, "seek": 38500, "start": 410.0, "end": 411.0, "text": " solution.", "tokens": [51614, 3827, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13944847178909014, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.05836743488907814}, {"id": 129, "seek": 41100, "start": 411.0, "end": 414.0, "text": " With that, you can extend further some functionalities.", "tokens": [50364, 2022, 300, 11, 291, 393, 10101, 3052, 512, 11745, 1088, 13, 50514], "temperature": 0.0, "avg_logprob": -0.13042466780718634, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.029812807217240334}, {"id": 130, "seek": 41100, "start": 414.0, "end": 418.0, "text": " You can enable cross-captain constants like authorization,", "tokens": [50514, 509, 393, 9528, 3278, 12, 496, 662, 491, 35870, 411, 33697, 11, 50714], "temperature": 0.0, "avg_logprob": -0.13042466780718634, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.029812807217240334}, {"id": 131, "seek": 41100, "start": 418.0, "end": 422.0, "text": " authentication, security, transformation, rate limiting,", "tokens": [50714, 26643, 11, 3825, 11, 9887, 11, 3314, 22083, 11, 50914], "temperature": 0.0, "avg_logprob": -0.13042466780718634, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.029812807217240334}, {"id": 132, "seek": 41100, "start": 422.0, "end": 423.0, "text": " and so on.", "tokens": [50914, 293, 370, 322, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13042466780718634, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.029812807217240334}, {"id": 133, "seek": 41100, "start": 423.0, "end": 427.0, "text": " At the same time, you can enable some kind of observation,", "tokens": [50964, 1711, 264, 912, 565, 11, 291, 393, 9528, 512, 733, 295, 14816, 11, 51164], "temperature": 0.0, "avg_logprob": -0.13042466780718634, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.029812807217240334}, {"id": 134, "seek": 41100, "start": 427.0, "end": 428.0, "text": " right?", "tokens": [51164, 558, 30, 51214], "temperature": 0.0, "avg_logprob": -0.13042466780718634, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.029812807217240334}, {"id": 135, "seek": 41100, "start": 428.0, "end": 431.0, "text": " And when you're using API 6, for example, you should face", "tokens": [51214, 400, 562, 291, 434, 1228, 9362, 1386, 11, 337, 1365, 11, 291, 820, 1851, 51364], "temperature": 0.0, "avg_logprob": -0.13042466780718634, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.029812807217240334}, {"id": 136, "seek": 41100, "start": 431.0, "end": 435.0, "text": " with multiple types of plugins broken down into several", "tokens": [51364, 365, 3866, 3467, 295, 33759, 5463, 760, 666, 2940, 51564], "temperature": 0.0, "avg_logprob": -0.13042466780718634, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.029812807217240334}, {"id": 137, "seek": 41100, "start": 435.0, "end": 439.0, "text": " categories, or sometimes you want something custom", "tokens": [51564, 10479, 11, 420, 2171, 291, 528, 746, 2375, 51764], "temperature": 0.0, "avg_logprob": -0.13042466780718634, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.029812807217240334}, {"id": 138, "seek": 43900, "start": 439.0, "end": 440.0, "text": " plugin, right?", "tokens": [50364, 23407, 11, 558, 30, 50414], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 139, "seek": 43900, "start": 440.0, "end": 442.0, "text": " To fit your needs.", "tokens": [50414, 1407, 3318, 428, 2203, 13, 50514], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 140, "seek": 43900, "start": 442.0, "end": 446.0, "text": " And with API 6, similar API gateway nowadays, more than", "tokens": [50514, 400, 365, 9362, 1386, 11, 2531, 9362, 28532, 13434, 11, 544, 813, 50714], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 141, "seek": 43900, "start": 446.0, "end": 449.0, "text": " API gateway provides some language support.", "tokens": [50714, 9362, 28532, 6417, 512, 2856, 1406, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 142, "seek": 43900, "start": 449.0, "end": 451.0, "text": " You can choose your favorite language, your familiar", "tokens": [50864, 509, 393, 2826, 428, 2954, 2856, 11, 428, 4963, 50964], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 143, "seek": 43900, "start": 451.0, "end": 454.0, "text": " reach, and you can create some custom plugins.", "tokens": [50964, 2524, 11, 293, 291, 393, 1884, 512, 2375, 33759, 13, 51114], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 144, "seek": 43900, "start": 454.0, "end": 458.0, "text": " Maybe you are Java developer, or maybe you are Go developer", "tokens": [51114, 2704, 291, 366, 10745, 10754, 11, 420, 1310, 291, 366, 1037, 10754, 51314], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 145, "seek": 43900, "start": 458.0, "end": 461.0, "text": " or Python, you can choose your favorite language and write", "tokens": [51314, 420, 15329, 11, 291, 393, 2826, 428, 2954, 2856, 293, 2464, 51464], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 146, "seek": 43900, "start": 461.0, "end": 462.0, "text": " the plugins.", "tokens": [51464, 264, 33759, 13, 51514], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 147, "seek": 43900, "start": 462.0, "end": 463.0, "text": " Let me show you.", "tokens": [51514, 961, 385, 855, 291, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 148, "seek": 43900, "start": 463.0, "end": 466.0, "text": " Or you don't want to write a code.", "tokens": [51564, 1610, 291, 500, 380, 528, 281, 2464, 257, 3089, 13, 51714], "temperature": 0.0, "avg_logprob": -0.18031363827841623, "compression_ratio": 1.774468085106383, "no_speech_prob": 0.047266386449337006}, {"id": 149, "seek": 46600, "start": 466.0, "end": 471.0, "text": " There is a dashboard where you can do user-friendly", "tokens": [50364, 821, 307, 257, 18342, 689, 291, 393, 360, 4195, 12, 22864, 50614], "temperature": 0.0, "avg_logprob": -0.1355626424153646, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0650000348687172}, {"id": 150, "seek": 46600, "start": 471.0, "end": 472.0, "text": " dashboard by using it.", "tokens": [50614, 18342, 538, 1228, 309, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1355626424153646, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0650000348687172}, {"id": 151, "seek": 46600, "start": 472.0, "end": 476.0, "text": " You can just drag and drop existing plugins together to", "tokens": [50664, 509, 393, 445, 5286, 293, 3270, 6741, 33759, 1214, 281, 50864], "temperature": 0.0, "avg_logprob": -0.1355626424153646, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0650000348687172}, {"id": 152, "seek": 46600, "start": 476.0, "end": 478.0, "text": " build new plugins.", "tokens": [50864, 1322, 777, 33759, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1355626424153646, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0650000348687172}, {"id": 153, "seek": 46600, "start": 478.0, "end": 481.0, "text": " You can orchestrate one or multiple plugins in this way.", "tokens": [50964, 509, 393, 14161, 4404, 472, 420, 3866, 33759, 294, 341, 636, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1355626424153646, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0650000348687172}, {"id": 154, "seek": 46600, "start": 481.0, "end": 486.0, "text": " You can specify some conditions and also put some", "tokens": [51114, 509, 393, 16500, 512, 4487, 293, 611, 829, 512, 51364], "temperature": 0.0, "avg_logprob": -0.1355626424153646, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0650000348687172}, {"id": 155, "seek": 46600, "start": 486.0, "end": 489.0, "text": " business flow on it and generate new plugins.", "tokens": [51364, 1606, 3095, 322, 309, 293, 8460, 777, 33759, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1355626424153646, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0650000348687172}, {"id": 156, "seek": 46600, "start": 489.0, "end": 493.0, "text": " It's a very useful feature that API 6 dashboard provides.", "tokens": [51514, 467, 311, 257, 588, 4420, 4111, 300, 9362, 1386, 18342, 6417, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1355626424153646, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0650000348687172}, {"id": 157, "seek": 49300, "start": 493.0, "end": 497.0, "text": " For example, you can put together multiple observability", "tokens": [50364, 1171, 1365, 11, 291, 393, 829, 1214, 3866, 9951, 2310, 50564], "temperature": 0.0, "avg_logprob": -0.14622370044836838, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.08003930002450943}, {"id": 158, "seek": 49300, "start": 497.0, "end": 501.0, "text": " plugins in one flow and then maybe enable full", "tokens": [50564, 33759, 294, 472, 3095, 293, 550, 1310, 9528, 1577, 50764], "temperature": 0.0, "avg_logprob": -0.14622370044836838, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.08003930002450943}, {"id": 159, "seek": 49300, "start": 501.0, "end": 505.0, "text": " observability backend tools in this diagram.", "tokens": [50764, 9951, 2310, 38087, 3873, 294, 341, 10686, 13, 50964], "temperature": 0.0, "avg_logprob": -0.14622370044836838, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.08003930002450943}, {"id": 160, "seek": 49300, "start": 505.0, "end": 508.0, "text": " Let me, you can just maybe observe later.", "tokens": [50964, 961, 385, 11, 291, 393, 445, 1310, 11441, 1780, 13, 51114], "temperature": 0.0, "avg_logprob": -0.14622370044836838, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.08003930002450943}, {"id": 161, "seek": 49300, "start": 508.0, "end": 511.0, "text": " Now let's jump into the main topic.", "tokens": [51114, 823, 718, 311, 3012, 666, 264, 2135, 4829, 13, 51264], "temperature": 0.0, "avg_logprob": -0.14622370044836838, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.08003930002450943}, {"id": 162, "seek": 49300, "start": 511.0, "end": 513.0, "text": " What's the API observability?", "tokens": [51264, 708, 311, 264, 9362, 9951, 2310, 30, 51364], "temperature": 0.0, "avg_logprob": -0.14622370044836838, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.08003930002450943}, {"id": 163, "seek": 49300, "start": 513.0, "end": 518.0, "text": " Can anyone tell what's the API observability?", "tokens": [51364, 1664, 2878, 980, 437, 311, 264, 9362, 9951, 2310, 30, 51614], "temperature": 0.0, "avg_logprob": -0.14622370044836838, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.08003930002450943}, {"id": 164, "seek": 49300, "start": 518.0, "end": 520.0, "text": " In one word.", "tokens": [51614, 682, 472, 1349, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14622370044836838, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.08003930002450943}, {"id": 165, "seek": 49300, "start": 520.0, "end": 522.0, "text": " No?", "tokens": [51714, 883, 30, 51814], "temperature": 0.0, "avg_logprob": -0.14622370044836838, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.08003930002450943}, {"id": 166, "seek": 52200, "start": 522.0, "end": 524.0, "text": " No.", "tokens": [50364, 883, 13, 50464], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 167, "seek": 52200, "start": 524.0, "end": 528.0, "text": " The other problem, like relation and latency, or", "tokens": [50464, 440, 661, 1154, 11, 411, 9721, 293, 27043, 11, 420, 50664], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 168, "seek": 52200, "start": 528.0, "end": 531.0, "text": " just great status codes.", "tokens": [50664, 445, 869, 6558, 14211, 13, 50814], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 169, "seek": 52200, "start": 531.0, "end": 533.0, "text": " Traces, yes, right?", "tokens": [50814, 1765, 2116, 11, 2086, 11, 558, 30, 50914], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 170, "seek": 52200, "start": 533.0, "end": 538.0, "text": " And for, I think I gave to you this short, right?", "tokens": [50914, 400, 337, 11, 286, 519, 286, 2729, 281, 291, 341, 2099, 11, 558, 30, 51164], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 171, "seek": 52200, "start": 538.0, "end": 540.0, "text": " For your, yeah.", "tokens": [51164, 1171, 428, 11, 1338, 13, 51264], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 172, "seek": 52200, "start": 540.0, "end": 543.0, "text": " The actual thing is doing is very important.", "tokens": [51264, 440, 3539, 551, 307, 884, 307, 588, 1021, 13, 51414], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 173, "seek": 52200, "start": 543.0, "end": 545.0, "text": " Yes, it's also right, yeah.", "tokens": [51414, 1079, 11, 309, 311, 611, 558, 11, 1338, 13, 51514], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 174, "seek": 52200, "start": 545.0, "end": 549.0, "text": " And it means API observability is all about how you absorb", "tokens": [51514, 400, 309, 1355, 9362, 9951, 2310, 307, 439, 466, 577, 291, 15631, 51714], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 175, "seek": 52200, "start": 549.0, "end": 550.0, "text": " your APIs, right?", "tokens": [51714, 428, 21445, 11, 558, 30, 51764], "temperature": 0.0, "avg_logprob": -0.48410083770751955, "compression_ratio": 1.5194174757281553, "no_speech_prob": 0.045261796563863754}, {"id": 176, "seek": 55000, "start": 550.0, "end": 554.0, "text": " Instead of relying on predetermined data like metrics,", "tokens": [50364, 7156, 295, 24140, 322, 3852, 35344, 2001, 1412, 411, 16367, 11, 50564], "temperature": 0.0, "avg_logprob": -0.15772536905800424, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.07271481305360794}, {"id": 177, "seek": 55000, "start": 554.0, "end": 558.0, "text": " monitoring, and wait for the failure, you can use", "tokens": [50564, 11028, 11, 293, 1699, 337, 264, 7763, 11, 291, 393, 764, 50764], "temperature": 0.0, "avg_logprob": -0.15772536905800424, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.07271481305360794}, {"id": 178, "seek": 55000, "start": 558.0, "end": 562.0, "text": " API observability to enable announce,", "tokens": [50764, 9362, 9951, 2310, 281, 9528, 7478, 11, 50964], "temperature": 0.0, "avg_logprob": -0.15772536905800424, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.07271481305360794}, {"id": 179, "seek": 55000, "start": 562.0, "end": 566.0, "text": " announce, or announce, in this diagram as you can see.", "tokens": [50964, 7478, 11, 420, 7478, 11, 294, 341, 10686, 382, 291, 393, 536, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15772536905800424, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.07271481305360794}, {"id": 180, "seek": 55000, "start": 566.0, "end": 570.0, "text": " Because compared to traditional API monitoring,", "tokens": [51164, 1436, 5347, 281, 5164, 9362, 11028, 11, 51364], "temperature": 0.0, "avg_logprob": -0.15772536905800424, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.07271481305360794}, {"id": 181, "seek": 55000, "start": 570.0, "end": 573.0, "text": " we have traditional API monitoring and observability, right?", "tokens": [51364, 321, 362, 5164, 9362, 11028, 293, 9951, 2310, 11, 558, 30, 51514], "temperature": 0.0, "avg_logprob": -0.15772536905800424, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.07271481305360794}, {"id": 182, "seek": 55000, "start": 573.0, "end": 577.0, "text": " This is monitoring focused on analyzing", "tokens": [51514, 639, 307, 11028, 5178, 322, 23663, 51714], "temperature": 0.0, "avg_logprob": -0.15772536905800424, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.07271481305360794}, {"id": 183, "seek": 57700, "start": 577.0, "end": 579.0, "text": " now and announce, what does it mean?", "tokens": [50364, 586, 293, 7478, 11, 437, 775, 309, 914, 30, 50464], "temperature": 0.0, "avg_logprob": -0.15421685133830154, "compression_ratio": 1.8130841121495327, "no_speech_prob": 0.05577618256211281}, {"id": 184, "seek": 57700, "start": 579.0, "end": 582.0, "text": " Now and announce means you know what the measure,", "tokens": [50464, 823, 293, 7478, 1355, 291, 458, 437, 264, 3481, 11, 50614], "temperature": 0.0, "avg_logprob": -0.15421685133830154, "compression_ratio": 1.8130841121495327, "no_speech_prob": 0.05577618256211281}, {"id": 185, "seek": 57700, "start": 582.0, "end": 585.0, "text": " you know the number of requests, you know number of errors,", "tokens": [50614, 291, 458, 264, 1230, 295, 12475, 11, 291, 458, 1230, 295, 13603, 11, 50764], "temperature": 0.0, "avg_logprob": -0.15421685133830154, "compression_ratio": 1.8130841121495327, "no_speech_prob": 0.05577618256211281}, {"id": 186, "seek": 57700, "start": 585.0, "end": 587.0, "text": " that you know what the measure, right?", "tokens": [50764, 300, 291, 458, 437, 264, 3481, 11, 558, 30, 50864], "temperature": 0.0, "avg_logprob": -0.15421685133830154, "compression_ratio": 1.8130841121495327, "no_speech_prob": 0.05577618256211281}, {"id": 187, "seek": 57700, "start": 587.0, "end": 592.0, "text": " But on the other hand, API observability lets you", "tokens": [50864, 583, 322, 264, 661, 1011, 11, 9362, 9951, 2310, 6653, 291, 51114], "temperature": 0.0, "avg_logprob": -0.15421685133830154, "compression_ratio": 1.8130841121495327, "no_speech_prob": 0.05577618256211281}, {"id": 188, "seek": 57700, "start": 592.0, "end": 596.0, "text": " analyze exactly what was the issue,", "tokens": [51114, 12477, 2293, 437, 390, 264, 2734, 11, 51314], "temperature": 0.0, "avg_logprob": -0.15421685133830154, "compression_ratio": 1.8130841121495327, "no_speech_prob": 0.05577618256211281}, {"id": 189, "seek": 57700, "start": 596.0, "end": 601.0, "text": " and how this issue occurred by learning three metrics, right?", "tokens": [51314, 293, 577, 341, 2734, 11068, 538, 2539, 1045, 16367, 11, 558, 30, 51564], "temperature": 0.0, "avg_logprob": -0.15421685133830154, "compression_ratio": 1.8130841121495327, "no_speech_prob": 0.05577618256211281}, {"id": 190, "seek": 57700, "start": 601.0, "end": 605.0, "text": " You know, again, like logging and metrics and tracing.", "tokens": [51564, 509, 458, 11, 797, 11, 411, 27991, 293, 16367, 293, 25262, 13, 51764], "temperature": 0.0, "avg_logprob": -0.15421685133830154, "compression_ratio": 1.8130841121495327, "no_speech_prob": 0.05577618256211281}, {"id": 191, "seek": 60500, "start": 605.0, "end": 610.0, "text": " So because API observability nowadays is a part of", "tokens": [50364, 407, 570, 9362, 9951, 2310, 13434, 307, 257, 644, 295, 50614], "temperature": 0.0, "avg_logprob": -0.14854986291182667, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.030331293120980263}, {"id": 192, "seek": 60500, "start": 610.0, "end": 614.0, "text": " every API development teams, let's say, for example,", "tokens": [50614, 633, 9362, 3250, 5491, 11, 718, 311, 584, 11, 337, 1365, 11, 50814], "temperature": 0.0, "avg_logprob": -0.14854986291182667, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.030331293120980263}, {"id": 193, "seek": 60500, "start": 614.0, "end": 617.0, "text": " who can use API observability during the API development?", "tokens": [50814, 567, 393, 764, 9362, 9951, 2310, 1830, 264, 9362, 3250, 30, 50964], "temperature": 0.0, "avg_logprob": -0.14854986291182667, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.030331293120980263}, {"id": 194, "seek": 60500, "start": 617.0, "end": 620.0, "text": " Yes, you can see, for example, product managers,", "tokens": [50964, 1079, 11, 291, 393, 536, 11, 337, 1365, 11, 1674, 14084, 11, 51114], "temperature": 0.0, "avg_logprob": -0.14854986291182667, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.030331293120980263}, {"id": 195, "seek": 60500, "start": 620.0, "end": 625.0, "text": " they can use to learn consumption and usage of your APIs.", "tokens": [51114, 436, 393, 764, 281, 1466, 12126, 293, 14924, 295, 428, 21445, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14854986291182667, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.030331293120980263}, {"id": 196, "seek": 60500, "start": 625.0, "end": 628.0, "text": " Or maybe security team, they can use to protect", "tokens": [51364, 1610, 1310, 3825, 1469, 11, 436, 393, 764, 281, 2371, 51514], "temperature": 0.0, "avg_logprob": -0.14854986291182667, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.030331293120980263}, {"id": 197, "seek": 60500, "start": 628.0, "end": 634.0, "text": " or maybe detect some possible API threats from outside, right?", "tokens": [51514, 420, 1310, 5531, 512, 1944, 9362, 14909, 490, 2380, 11, 558, 30, 51814], "temperature": 0.0, "avg_logprob": -0.14854986291182667, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.030331293120980263}, {"id": 198, "seek": 63400, "start": 634.0, "end": 639.0, "text": " So as I said, let's have a look at these three pillars now", "tokens": [50364, 407, 382, 286, 848, 11, 718, 311, 362, 257, 574, 412, 613, 1045, 26729, 586, 50614], "temperature": 0.0, "avg_logprob": -0.13016092920877848, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.01287014875560999}, {"id": 199, "seek": 63400, "start": 639.0, "end": 644.0, "text": " and learn what API gateway can provide as a solution", "tokens": [50614, 293, 1466, 437, 9362, 28532, 393, 2893, 382, 257, 3827, 50864], "temperature": 0.0, "avg_logprob": -0.13016092920877848, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.01287014875560999}, {"id": 200, "seek": 63400, "start": 644.0, "end": 648.0, "text": " for these pillars, tracing, logging, and metrics.", "tokens": [50864, 337, 613, 26729, 11, 25262, 11, 27991, 11, 293, 16367, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13016092920877848, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.01287014875560999}, {"id": 201, "seek": 63400, "start": 648.0, "end": 652.0, "text": " If I start with logging, it's a very tribal step, right?", "tokens": [51064, 759, 286, 722, 365, 27991, 11, 309, 311, 257, 588, 20958, 1823, 11, 558, 30, 51264], "temperature": 0.0, "avg_logprob": -0.13016092920877848, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.01287014875560999}, {"id": 202, "seek": 63400, "start": 652.0, "end": 655.0, "text": " To start your observability because you can use logs", "tokens": [51264, 1407, 722, 428, 9951, 2310, 570, 291, 393, 764, 20820, 51414], "temperature": 0.0, "avg_logprob": -0.13016092920877848, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.01287014875560999}, {"id": 203, "seek": 63400, "start": 655.0, "end": 660.0, "text": " to identify or debug what's happening.", "tokens": [51414, 281, 5876, 420, 24083, 437, 311, 2737, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13016092920877848, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.01287014875560999}, {"id": 204, "seek": 66000, "start": 660.0, "end": 664.0, "text": " If you are a junior developer, you will first start digging into logs", "tokens": [50364, 759, 291, 366, 257, 16195, 10754, 11, 291, 486, 700, 722, 17343, 666, 20820, 50564], "temperature": 0.0, "avg_logprob": -0.1567094746757956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.03527561202645302}, {"id": 205, "seek": 66000, "start": 664.0, "end": 666.0, "text": " because in order to understand the project,", "tokens": [50564, 570, 294, 1668, 281, 1223, 264, 1716, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1567094746757956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.03527561202645302}, {"id": 206, "seek": 66000, "start": 666.0, "end": 668.0, "text": " because the project has zero documentation,", "tokens": [50664, 570, 264, 1716, 575, 4018, 14333, 11, 50764], "temperature": 0.0, "avg_logprob": -0.1567094746757956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.03527561202645302}, {"id": 207, "seek": 66000, "start": 668.0, "end": 670.0, "text": " you need to have a look at logs,", "tokens": [50764, 291, 643, 281, 362, 257, 574, 412, 20820, 11, 50864], "temperature": 0.0, "avg_logprob": -0.1567094746757956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.03527561202645302}, {"id": 208, "seek": 66000, "start": 670.0, "end": 673.0, "text": " you need to have a look at some API things.", "tokens": [50864, 291, 643, 281, 362, 257, 574, 412, 512, 9362, 721, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1567094746757956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.03527561202645302}, {"id": 209, "seek": 66000, "start": 673.0, "end": 679.0, "text": " So here, in order to enable this logging,", "tokens": [51014, 407, 510, 11, 294, 1668, 281, 9528, 341, 27991, 11, 51314], "temperature": 0.0, "avg_logprob": -0.1567094746757956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.03527561202645302}, {"id": 210, "seek": 66000, "start": 679.0, "end": 681.0, "text": " you can use some kind of plugins.", "tokens": [51314, 291, 393, 764, 512, 733, 295, 33759, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1567094746757956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.03527561202645302}, {"id": 211, "seek": 66000, "start": 681.0, "end": 685.0, "text": " For example, API 6 provides HTTP-logger plugin, Kafka-logger,", "tokens": [51414, 1171, 1365, 11, 9362, 1386, 6417, 33283, 12, 4987, 1321, 23407, 11, 47064, 12, 4987, 1321, 11, 51614], "temperature": 0.0, "avg_logprob": -0.1567094746757956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.03527561202645302}, {"id": 212, "seek": 68500, "start": 685.0, "end": 689.0, "text": " or it depends on which kind of integration you have.", "tokens": [50364, 420, 309, 5946, 322, 597, 733, 295, 10980, 291, 362, 13, 50564], "temperature": 0.0, "avg_logprob": -0.101295300533897, "compression_ratio": 1.4954954954954955, "no_speech_prob": 0.06670200824737549}, {"id": 213, "seek": 68500, "start": 689.0, "end": 692.0, "text": " For example, you can use Google Cloud Logger.", "tokens": [50564, 1171, 1365, 11, 291, 393, 764, 3329, 8061, 10824, 1321, 13, 50714], "temperature": 0.0, "avg_logprob": -0.101295300533897, "compression_ratio": 1.4954954954954955, "no_speech_prob": 0.06670200824737549}, {"id": 214, "seek": 68500, "start": 692.0, "end": 695.0, "text": " Let's say HTTP-logger is a basic logger.", "tokens": [50714, 961, 311, 584, 33283, 12, 4987, 1321, 307, 257, 3875, 3565, 1321, 13, 50864], "temperature": 0.0, "avg_logprob": -0.101295300533897, "compression_ratio": 1.4954954954954955, "no_speech_prob": 0.06670200824737549}, {"id": 215, "seek": 68500, "start": 695.0, "end": 700.0, "text": " Let's just enable to push all the log data from your API gateway", "tokens": [50864, 961, 311, 445, 9528, 281, 2944, 439, 264, 3565, 1412, 490, 428, 9362, 28532, 51114], "temperature": 0.0, "avg_logprob": -0.101295300533897, "compression_ratio": 1.4954954954954955, "no_speech_prob": 0.06670200824737549}, {"id": 216, "seek": 68500, "start": 700.0, "end": 704.0, "text": " to HTTP-S or HTTP servers.", "tokens": [51114, 281, 33283, 12, 50, 420, 33283, 15909, 13, 51314], "temperature": 0.0, "avg_logprob": -0.101295300533897, "compression_ratio": 1.4954954954954955, "no_speech_prob": 0.06670200824737549}, {"id": 217, "seek": 68500, "start": 704.0, "end": 709.0, "text": " It means you can further drive some useful metrics from that logs.", "tokens": [51314, 467, 1355, 291, 393, 3052, 3332, 512, 4420, 16367, 490, 300, 20820, 13, 51564], "temperature": 0.0, "avg_logprob": -0.101295300533897, "compression_ratio": 1.4954954954954955, "no_speech_prob": 0.06670200824737549}, {"id": 218, "seek": 68500, "start": 709.0, "end": 712.0, "text": " Or let's say, what about metrics?", "tokens": [51564, 1610, 718, 311, 584, 11, 437, 466, 16367, 30, 51714], "temperature": 0.0, "avg_logprob": -0.101295300533897, "compression_ratio": 1.4954954954954955, "no_speech_prob": 0.06670200824737549}, {"id": 219, "seek": 71200, "start": 712.0, "end": 717.0, "text": " Metrics are actually just the data collected", "tokens": [50364, 6377, 10716, 366, 767, 445, 264, 1412, 11087, 50614], "temperature": 0.0, "avg_logprob": -0.20018823076002668, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.02504967898130417}, {"id": 220, "seek": 71200, "start": 717.0, "end": 719.0, "text": " over the time, right?", "tokens": [50614, 670, 264, 565, 11, 558, 30, 50714], "temperature": 0.0, "avg_logprob": -0.20018823076002668, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.02504967898130417}, {"id": 221, "seek": 71200, "start": 719.0, "end": 721.0, "text": " Times gas, but the metrics collected.", "tokens": [50714, 11366, 4211, 11, 457, 264, 16367, 11087, 13, 50814], "temperature": 0.0, "avg_logprob": -0.20018823076002668, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.02504967898130417}, {"id": 222, "seek": 71200, "start": 721.0, "end": 724.0, "text": " But metrics you can use in the future", "tokens": [50814, 583, 16367, 291, 393, 764, 294, 264, 2027, 50964], "temperature": 0.0, "avg_logprob": -0.20018823076002668, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.02504967898130417}, {"id": 223, "seek": 71200, "start": 724.0, "end": 727.0, "text": " in the distributed systems like Elasticsearch.", "tokens": [50964, 294, 264, 12631, 3652, 411, 2699, 2750, 405, 1178, 13, 51114], "temperature": 0.0, "avg_logprob": -0.20018823076002668, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.02504967898130417}, {"id": 224, "seek": 71200, "start": 727.0, "end": 729.0, "text": " You can acquire these metrics using Elasticsearch,", "tokens": [51114, 509, 393, 20001, 613, 16367, 1228, 2699, 2750, 405, 1178, 11, 51214], "temperature": 0.0, "avg_logprob": -0.20018823076002668, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.02504967898130417}, {"id": 225, "seek": 71200, "start": 729.0, "end": 734.0, "text": " or maybe you can show these metrics by using a dashboard,", "tokens": [51214, 420, 1310, 291, 393, 855, 613, 16367, 538, 1228, 257, 18342, 11, 51464], "temperature": 0.0, "avg_logprob": -0.20018823076002668, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.02504967898130417}, {"id": 226, "seek": 71200, "start": 734.0, "end": 735.0, "text": " like a Prometheus, right?", "tokens": [51464, 411, 257, 2114, 649, 42209, 11, 558, 30, 51514], "temperature": 0.0, "avg_logprob": -0.20018823076002668, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.02504967898130417}, {"id": 227, "seek": 71200, "start": 735.0, "end": 738.0, "text": " The Prometheus dashboard provides some metric analysis.", "tokens": [51514, 440, 2114, 649, 42209, 18342, 6417, 512, 20678, 5215, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20018823076002668, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.02504967898130417}, {"id": 228, "seek": 73800, "start": 738.0, "end": 743.0, "text": " And for these, all the external popular platforms,", "tokens": [50364, 400, 337, 613, 11, 439, 264, 8320, 3743, 9473, 11, 50614], "temperature": 0.0, "avg_logprob": -0.17111268607519006, "compression_ratio": 1.4619047619047618, "no_speech_prob": 0.03694987669587135}, {"id": 229, "seek": 73800, "start": 743.0, "end": 746.0, "text": " let's say, like Grafana or Prometheus,", "tokens": [50614, 718, 311, 584, 11, 411, 8985, 69, 2095, 420, 2114, 649, 42209, 11, 50764], "temperature": 0.0, "avg_logprob": -0.17111268607519006, "compression_ratio": 1.4619047619047618, "no_speech_prob": 0.03694987669587135}, {"id": 230, "seek": 73800, "start": 746.0, "end": 751.0, "text": " Apache PR6 has pre-built connectors, I would say.", "tokens": [50764, 46597, 11568, 21, 575, 659, 12, 23018, 31865, 11, 286, 576, 584, 13, 51014], "temperature": 0.0, "avg_logprob": -0.17111268607519006, "compression_ratio": 1.4619047619047618, "no_speech_prob": 0.03694987669587135}, {"id": 231, "seek": 73800, "start": 751.0, "end": 753.0, "text": " And for example, like Zipkin.", "tokens": [51014, 400, 337, 1365, 11, 411, 1176, 647, 5843, 13, 51114], "temperature": 0.0, "avg_logprob": -0.17111268607519006, "compression_ratio": 1.4619047619047618, "no_speech_prob": 0.03694987669587135}, {"id": 232, "seek": 73800, "start": 753.0, "end": 755.0, "text": " For tracing, we have Zipping plugin.", "tokens": [51114, 1171, 25262, 11, 321, 362, 1176, 6297, 23407, 13, 51214], "temperature": 0.0, "avg_logprob": -0.17111268607519006, "compression_ratio": 1.4619047619047618, "no_speech_prob": 0.03694987669587135}, {"id": 233, "seek": 73800, "start": 755.0, "end": 759.0, "text": " You can just enable it with just one click,", "tokens": [51214, 509, 393, 445, 9528, 309, 365, 445, 472, 2052, 11, 51414], "temperature": 0.0, "avg_logprob": -0.17111268607519006, "compression_ratio": 1.4619047619047618, "no_speech_prob": 0.03694987669587135}, {"id": 234, "seek": 73800, "start": 759.0, "end": 767.0, "text": " and it starts to learn some metrics or traces and so on.", "tokens": [51414, 293, 309, 3719, 281, 1466, 512, 16367, 420, 26076, 293, 370, 322, 13, 51814], "temperature": 0.0, "avg_logprob": -0.17111268607519006, "compression_ratio": 1.4619047619047618, "no_speech_prob": 0.03694987669587135}, {"id": 235, "seek": 76700, "start": 767.0, "end": 770.0, "text": " So now, enough talking, right?", "tokens": [50364, 407, 586, 11, 1547, 1417, 11, 558, 30, 50514], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 236, "seek": 76700, "start": 770.0, "end": 773.0, "text": " I can show something in real.", "tokens": [50514, 286, 393, 855, 746, 294, 957, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 237, "seek": 76700, "start": 773.0, "end": 775.0, "text": " Because we have a bunch of plugins,", "tokens": [50664, 1436, 321, 362, 257, 3840, 295, 33759, 11, 50764], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 238, "seek": 76700, "start": 775.0, "end": 778.0, "text": " as I said, for the API observability,", "tokens": [50764, 382, 286, 848, 11, 337, 264, 9362, 9951, 2310, 11, 50914], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 239, "seek": 76700, "start": 778.0, "end": 781.0, "text": " this time I decided to choose, for my demo,", "tokens": [50914, 341, 565, 286, 3047, 281, 2826, 11, 337, 452, 10723, 11, 51064], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 240, "seek": 76700, "start": 781.0, "end": 783.0, "text": " Prometheus plugin.", "tokens": [51064, 2114, 649, 42209, 23407, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 241, "seek": 76700, "start": 783.0, "end": 785.0, "text": " Because with respect to Fabian,", "tokens": [51164, 1436, 365, 3104, 281, 17440, 952, 11, 51264], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 242, "seek": 76700, "start": 785.0, "end": 789.0, "text": " and I really like Prometheus and Grafana integration,", "tokens": [51264, 293, 286, 534, 411, 2114, 649, 42209, 293, 8985, 69, 2095, 10980, 11, 51464], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 243, "seek": 76700, "start": 789.0, "end": 791.0, "text": " now I will show you how you can easily enable", "tokens": [51464, 586, 286, 486, 855, 291, 577, 291, 393, 3612, 9528, 51564], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 244, "seek": 76700, "start": 791.0, "end": 794.0, "text": " this observability very fast.", "tokens": [51564, 341, 9951, 2310, 588, 2370, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1335092883243739, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.011248395778238773}, {"id": 245, "seek": 79400, "start": 794.0, "end": 796.0, "text": " For that, I mean, you can have a look.", "tokens": [50364, 1171, 300, 11, 286, 914, 11, 291, 393, 362, 257, 574, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17897747764902666, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.03262807056307793}, {"id": 246, "seek": 79400, "start": 796.0, "end": 799.0, "text": " That is my report, api6.net docker.", "tokens": [50464, 663, 307, 452, 2275, 11, 1882, 72, 21, 13, 7129, 360, 9178, 13, 50614], "temperature": 0.0, "avg_logprob": -0.17897747764902666, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.03262807056307793}, {"id": 247, "seek": 79400, "start": 799.0, "end": 803.0, "text": " It shows all the use cases of API GitHub in one report.", "tokens": [50614, 467, 3110, 439, 264, 764, 3331, 295, 9362, 23331, 294, 472, 2275, 13, 50814], "temperature": 0.0, "avg_logprob": -0.17897747764902666, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.03262807056307793}, {"id": 248, "seek": 79400, "start": 803.0, "end": 807.0, "text": " And it has a branch called the API observability.", "tokens": [50814, 400, 309, 575, 257, 9819, 1219, 264, 9362, 9951, 2310, 13, 51014], "temperature": 0.0, "avg_logprob": -0.17897747764902666, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.03262807056307793}, {"id": 249, "seek": 79400, "start": 807.0, "end": 809.0, "text": " If you navigate this branch,", "tokens": [51014, 759, 291, 12350, 341, 9819, 11, 51114], "temperature": 0.0, "avg_logprob": -0.17897747764902666, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.03262807056307793}, {"id": 250, "seek": 79400, "start": 809.0, "end": 813.0, "text": " you will see a real example of some plugins,", "tokens": [51114, 291, 486, 536, 257, 957, 1365, 295, 512, 33759, 11, 51314], "temperature": 0.0, "avg_logprob": -0.17897747764902666, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.03262807056307793}, {"id": 251, "seek": 79400, "start": 813.0, "end": 817.0, "text": " how to enable it, and you can have a hands-on exercises.", "tokens": [51314, 577, 281, 9528, 309, 11, 293, 291, 393, 362, 257, 2377, 12, 266, 11900, 13, 51514], "temperature": 0.0, "avg_logprob": -0.17897747764902666, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.03262807056307793}, {"id": 252, "seek": 79400, "start": 817.0, "end": 821.0, "text": " Now, let me switch to my VS code.", "tokens": [51514, 823, 11, 718, 385, 3679, 281, 452, 25091, 3089, 13, 51714], "temperature": 0.0, "avg_logprob": -0.17897747764902666, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.03262807056307793}, {"id": 253, "seek": 79400, "start": 821.0, "end": 823.0, "text": " I'm using the VS code today for the session.", "tokens": [51714, 286, 478, 1228, 264, 25091, 3089, 965, 337, 264, 5481, 13, 51814], "temperature": 0.0, "avg_logprob": -0.17897747764902666, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.03262807056307793}, {"id": 254, "seek": 82300, "start": 823.0, "end": 828.0, "text": " But I'm talking about this repository.", "tokens": [50364, 583, 286, 478, 1417, 466, 341, 25841, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14363220104804406, "compression_ratio": 1.52, "no_speech_prob": 0.03791828453540802}, {"id": 255, "seek": 82300, "start": 828.0, "end": 830.0, "text": " It has a five branch.", "tokens": [50614, 467, 575, 257, 1732, 9819, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14363220104804406, "compression_ratio": 1.52, "no_speech_prob": 0.03791828453540802}, {"id": 256, "seek": 82300, "start": 830.0, "end": 832.0, "text": " You can learn some of the branch,", "tokens": [50714, 509, 393, 1466, 512, 295, 264, 9819, 11, 50814], "temperature": 0.0, "avg_logprob": -0.14363220104804406, "compression_ratio": 1.52, "no_speech_prob": 0.03791828453540802}, {"id": 257, "seek": 82300, "start": 832.0, "end": 834.0, "text": " like how you can enable health check,", "tokens": [50814, 411, 577, 291, 393, 9528, 1585, 1520, 11, 50914], "temperature": 0.0, "avg_logprob": -0.14363220104804406, "compression_ratio": 1.52, "no_speech_prob": 0.03791828453540802}, {"id": 258, "seek": 82300, "start": 834.0, "end": 837.0, "text": " start from health check, and API observability.", "tokens": [50914, 722, 490, 1585, 1520, 11, 293, 9362, 9951, 2310, 13, 51064], "temperature": 0.0, "avg_logprob": -0.14363220104804406, "compression_ratio": 1.52, "no_speech_prob": 0.03791828453540802}, {"id": 259, "seek": 82300, "start": 837.0, "end": 839.0, "text": " This is the starting point for you.", "tokens": [51064, 639, 307, 264, 2891, 935, 337, 291, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14363220104804406, "compression_ratio": 1.52, "no_speech_prob": 0.03791828453540802}, {"id": 260, "seek": 82300, "start": 839.0, "end": 843.0, "text": " And then it's very fast to spin up this project,", "tokens": [51164, 400, 550, 309, 311, 588, 2370, 281, 6060, 493, 341, 1716, 11, 51364], "temperature": 0.0, "avg_logprob": -0.14363220104804406, "compression_ratio": 1.52, "no_speech_prob": 0.03791828453540802}, {"id": 261, "seek": 82300, "start": 843.0, "end": 846.0, "text": " because it uses docker-compose.", "tokens": [51364, 570, 309, 4960, 360, 9178, 12, 21541, 541, 13, 51514], "temperature": 0.0, "avg_logprob": -0.14363220104804406, "compression_ratio": 1.52, "no_speech_prob": 0.03791828453540802}, {"id": 262, "seek": 82300, "start": 846.0, "end": 851.0, "text": " And we are using, for the backend, api6.net,", "tokens": [51514, 400, 321, 366, 1228, 11, 337, 264, 38087, 11, 1882, 72, 21, 13, 7129, 11, 51764], "temperature": 0.0, "avg_logprob": -0.14363220104804406, "compression_ratio": 1.52, "no_speech_prob": 0.03791828453540802}, {"id": 263, "seek": 85100, "start": 852.0, "end": 854.0, "text": " you can use Java project.", "tokens": [50414, 291, 393, 764, 10745, 1716, 13, 50514], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 264, "seek": 85100, "start": 854.0, "end": 856.0, "text": " It doesn't matter. You can use Python.", "tokens": [50514, 467, 1177, 380, 1871, 13, 509, 393, 764, 15329, 13, 50614], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 265, "seek": 85100, "start": 856.0, "end": 858.0, "text": " I'm actually a Java developer,", "tokens": [50614, 286, 478, 767, 257, 10745, 10754, 11, 50714], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 266, "seek": 85100, "start": 858.0, "end": 863.0, "text": " but I like to encourage myself to learn new languages.", "tokens": [50714, 457, 286, 411, 281, 5373, 2059, 281, 1466, 777, 8650, 13, 50964], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 267, "seek": 85100, "start": 863.0, "end": 865.0, "text": " I start to learn C-sharp,", "tokens": [50964, 286, 722, 281, 1466, 383, 12, 2716, 6529, 11, 51064], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 268, "seek": 85100, "start": 865.0, "end": 868.0, "text": " and this small project on .net.", "tokens": [51064, 293, 341, 1359, 1716, 322, 2411, 7129, 13, 51214], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 269, "seek": 85100, "start": 868.0, "end": 872.0, "text": " So if you do some docker-compose app,", "tokens": [51214, 407, 498, 291, 360, 512, 360, 9178, 12, 21541, 541, 724, 11, 51414], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 270, "seek": 85100, "start": 872.0, "end": 874.0, "text": " docker-api6, of course,", "tokens": [51414, 360, 9178, 12, 35891, 21, 11, 295, 1164, 11, 51514], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 271, "seek": 85100, "start": 874.0, "end": 876.0, "text": " it will bring some containers, right?", "tokens": [51514, 309, 486, 1565, 512, 17089, 11, 558, 30, 51614], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 272, "seek": 85100, "start": 876.0, "end": 878.0, "text": " All useful containers, as you can see,", "tokens": [51614, 1057, 4420, 17089, 11, 382, 291, 393, 536, 11, 51714], "temperature": 0.0, "avg_logprob": -0.15456725455619194, "compression_ratio": 1.52863436123348, "no_speech_prob": 0.1010856106877327}, {"id": 273, "seek": 87800, "start": 878.0, "end": 880.0, "text": " like Prometheus, Grafana.", "tokens": [50364, 411, 2114, 649, 42209, 11, 8985, 69, 2095, 13, 50464], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 274, "seek": 87800, "start": 880.0, "end": 883.0, "text": " We have a product API that is with .net.", "tokens": [50464, 492, 362, 257, 1674, 9362, 300, 307, 365, 2411, 7129, 13, 50614], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 275, "seek": 87800, "start": 883.0, "end": 886.0, "text": " I have a small endpoint that maybe returns", "tokens": [50614, 286, 362, 257, 1359, 35795, 300, 1310, 11247, 50764], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 276, "seek": 87800, "start": 886.0, "end": 889.0, "text": " some list of products when you call this endpoint.", "tokens": [50764, 512, 1329, 295, 3383, 562, 291, 818, 341, 35795, 13, 50914], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 277, "seek": 87800, "start": 889.0, "end": 892.0, "text": " As you can see, it's very simple here.", "tokens": [50914, 1018, 291, 393, 536, 11, 309, 311, 588, 2199, 510, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 278, "seek": 87800, "start": 892.0, "end": 895.0, "text": " When I do this, it returns...", "tokens": [51064, 1133, 286, 360, 341, 11, 309, 11247, 485, 51214], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 279, "seek": 87800, "start": 895.0, "end": 898.0, "text": " Let me maybe make it bigger here.", "tokens": [51214, 961, 385, 1310, 652, 309, 3801, 510, 13, 51364], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 280, "seek": 87800, "start": 898.0, "end": 900.0, "text": " It returns a MacBook price", "tokens": [51364, 467, 11247, 257, 31737, 3218, 51464], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 281, "seek": 87800, "start": 900.0, "end": 902.0, "text": " and some other product price.", "tokens": [51464, 293, 512, 661, 1674, 3218, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 282, "seek": 87800, "start": 902.0, "end": 903.0, "text": " Simple.", "tokens": [51564, 21532, 13, 51614], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 283, "seek": 87800, "start": 903.0, "end": 906.0, "text": " And also, I'm using Windows on my machine,", "tokens": [51614, 400, 611, 11, 286, 478, 1228, 8591, 322, 452, 3479, 11, 51764], "temperature": 0.0, "avg_logprob": -0.16245647869278898, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.06863289326429367}, {"id": 284, "seek": 90600, "start": 906.0, "end": 911.0, "text": " some of the necessary containers are up and running", "tokens": [50364, 512, 295, 264, 4818, 17089, 366, 493, 293, 2614, 50614], "temperature": 0.0, "avg_logprob": -0.16561372756958007, "compression_ratio": 1.493273542600897, "no_speech_prob": 0.010760892182588577}, {"id": 285, "seek": 90600, "start": 911.0, "end": 913.0, "text": " in one kind of docker-compose app.", "tokens": [50614, 294, 472, 733, 295, 360, 9178, 12, 21541, 541, 724, 13, 50714], "temperature": 0.0, "avg_logprob": -0.16561372756958007, "compression_ratio": 1.493273542600897, "no_speech_prob": 0.010760892182588577}, {"id": 286, "seek": 90600, "start": 913.0, "end": 917.0, "text": " Then if you open the project code", "tokens": [50714, 1396, 498, 291, 1269, 264, 1716, 3089, 50914], "temperature": 0.0, "avg_logprob": -0.16561372756958007, "compression_ratio": 1.493273542600897, "no_speech_prob": 0.010760892182588577}, {"id": 287, "seek": 90600, "start": 917.0, "end": 921.0, "text": " on your favorite IDEA or IDEA tool, right?", "tokens": [50914, 322, 428, 2954, 40930, 32, 420, 40930, 32, 2290, 11, 558, 30, 51114], "temperature": 0.0, "avg_logprob": -0.16561372756958007, "compression_ratio": 1.493273542600897, "no_speech_prob": 0.010760892182588577}, {"id": 288, "seek": 90600, "start": 921.0, "end": 924.0, "text": " In my case, let's say VS Code,", "tokens": [51114, 682, 452, 1389, 11, 718, 311, 584, 25091, 15549, 11, 51264], "temperature": 0.0, "avg_logprob": -0.16561372756958007, "compression_ratio": 1.493273542600897, "no_speech_prob": 0.010760892182588577}, {"id": 289, "seek": 90600, "start": 924.0, "end": 927.0, "text": " and you can see on the Commons folder", "tokens": [51264, 293, 291, 393, 536, 322, 264, 34894, 10820, 51414], "temperature": 0.0, "avg_logprob": -0.16561372756958007, "compression_ratio": 1.493273542600897, "no_speech_prob": 0.010760892182588577}, {"id": 290, "seek": 90600, "start": 927.0, "end": 929.0, "text": " some common line examples", "tokens": [51414, 512, 2689, 1622, 5110, 51514], "temperature": 0.0, "avg_logprob": -0.16561372756958007, "compression_ratio": 1.493273542600897, "no_speech_prob": 0.010760892182588577}, {"id": 291, "seek": 90600, "start": 929.0, "end": 931.0, "text": " that I'm going to show today.", "tokens": [51514, 300, 286, 478, 516, 281, 855, 965, 13, 51614], "temperature": 0.0, "avg_logprob": -0.16561372756958007, "compression_ratio": 1.493273542600897, "no_speech_prob": 0.010760892182588577}, {"id": 292, "seek": 90600, "start": 931.0, "end": 935.0, "text": " First thing, how you can enable this Grafana", "tokens": [51614, 2386, 551, 11, 577, 291, 393, 9528, 341, 8985, 69, 2095, 51814], "temperature": 0.0, "avg_logprob": -0.16561372756958007, "compression_ratio": 1.493273542600897, "no_speech_prob": 0.010760892182588577}, {"id": 293, "seek": 93500, "start": 935.0, "end": 937.0, "text": " or Prometheus, Zipkin, and so on.", "tokens": [50364, 420, 2114, 649, 42209, 11, 1176, 647, 5843, 11, 293, 370, 322, 13, 50464], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 294, "seek": 93500, "start": 937.0, "end": 941.0, "text": " With API Gateway, you need to create your first upstream.", "tokens": [50464, 2022, 9362, 48394, 11, 291, 643, 281, 1884, 428, 700, 33915, 13, 50664], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 295, "seek": 93500, "start": 941.0, "end": 943.0, "text": " If you navigate this here,", "tokens": [50664, 759, 291, 12350, 341, 510, 11, 50764], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 296, "seek": 93500, "start": 943.0, "end": 945.0, "text": " you can see some kind of command.", "tokens": [50764, 291, 393, 536, 512, 733, 295, 5622, 13, 50864], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 297, "seek": 93500, "start": 945.0, "end": 948.0, "text": " Of course, you can use a dashboard to create this upstream.", "tokens": [50864, 2720, 1164, 11, 291, 393, 764, 257, 18342, 281, 1884, 341, 33915, 13, 51014], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 298, "seek": 93500, "start": 948.0, "end": 949.0, "text": " It's up to you.", "tokens": [51014, 467, 311, 493, 281, 291, 13, 51064], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 299, "seek": 93500, "start": 949.0, "end": 953.0, "text": " If you're like a hard worker developer like me,", "tokens": [51064, 759, 291, 434, 411, 257, 1152, 11346, 10754, 411, 385, 11, 51264], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 300, "seek": 93500, "start": 953.0, "end": 955.0, "text": " you can just use the kind of commands.", "tokens": [51264, 291, 393, 445, 764, 264, 733, 295, 16901, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 301, "seek": 93500, "start": 955.0, "end": 957.0, "text": " What we are doing here, as you can see,", "tokens": [51364, 708, 321, 366, 884, 510, 11, 382, 291, 393, 536, 11, 51464], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 302, "seek": 93500, "start": 957.0, "end": 959.0, "text": " I had a product API, right?", "tokens": [51464, 286, 632, 257, 1674, 9362, 11, 558, 30, 51564], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 303, "seek": 93500, "start": 959.0, "end": 962.0, "text": " And then I am creating upstream.", "tokens": [51564, 400, 550, 286, 669, 4084, 33915, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14054402709007263, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.03192345052957535}, {"id": 304, "seek": 96200, "start": 962.0, "end": 967.0, "text": " And upstream means just a set of backend API endpoints.", "tokens": [50364, 400, 33915, 1355, 445, 257, 992, 295, 38087, 9362, 917, 20552, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11851963789566704, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.012780943885445595}, {"id": 305, "seek": 96200, "start": 967.0, "end": 970.0, "text": " And I have one single node, one node.", "tokens": [50614, 400, 286, 362, 472, 2167, 9984, 11, 472, 9984, 13, 50764], "temperature": 0.0, "avg_logprob": -0.11851963789566704, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.012780943885445595}, {"id": 306, "seek": 96200, "start": 970.0, "end": 971.0, "text": " You can have multiple nodes.", "tokens": [50764, 509, 393, 362, 3866, 13891, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11851963789566704, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.012780943885445595}, {"id": 307, "seek": 96200, "start": 971.0, "end": 975.0, "text": " You can have multiple instance of the same product API.", "tokens": [50814, 509, 393, 362, 3866, 5197, 295, 264, 912, 1674, 9362, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11851963789566704, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.012780943885445595}, {"id": 308, "seek": 96200, "start": 975.0, "end": 981.0, "text": " For the simple case, I'm just creating this one upstream", "tokens": [51014, 1171, 264, 2199, 1389, 11, 286, 478, 445, 4084, 341, 472, 33915, 51314], "temperature": 0.0, "avg_logprob": -0.11851963789566704, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.012780943885445595}, {"id": 309, "seek": 96200, "start": 981.0, "end": 982.0, "text": " and one node.", "tokens": [51314, 293, 472, 9984, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11851963789566704, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.012780943885445595}, {"id": 310, "seek": 96200, "start": 982.0, "end": 984.0, "text": " Let's jump into maybe terminal.", "tokens": [51364, 961, 311, 3012, 666, 1310, 14709, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11851963789566704, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.012780943885445595}, {"id": 311, "seek": 96200, "start": 984.0, "end": 989.0, "text": " I can open some new terminal here to run this code.", "tokens": [51464, 286, 393, 1269, 512, 777, 14709, 510, 281, 1190, 341, 3089, 13, 51714], "temperature": 0.0, "avg_logprob": -0.11851963789566704, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.012780943885445595}, {"id": 312, "seek": 98900, "start": 989.0, "end": 993.0, "text": " So I'm using VSL,", "tokens": [50364, 407, 286, 478, 1228, 25091, 43, 11, 50564], "temperature": 0.0, "avg_logprob": -0.2554029406923236, "compression_ratio": 1.3973214285714286, "no_speech_prob": 0.042619042098522186}, {"id": 313, "seek": 98900, "start": 993.0, "end": 997.0, "text": " because on Windows it's a little bit difficult to run a Linux code.", "tokens": [50564, 570, 322, 8591, 309, 311, 257, 707, 857, 2252, 281, 1190, 257, 18734, 3089, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2554029406923236, "compression_ratio": 1.3973214285714286, "no_speech_prob": 0.042619042098522186}, {"id": 314, "seek": 98900, "start": 997.0, "end": 1001.0, "text": " So let me open maybe one more terminal on the Ubuntu.", "tokens": [50764, 407, 718, 385, 1269, 1310, 472, 544, 14709, 322, 264, 30230, 45605, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2554029406923236, "compression_ratio": 1.3973214285714286, "no_speech_prob": 0.042619042098522186}, {"id": 315, "seek": 98900, "start": 1001.0, "end": 1003.0, "text": " There we go.", "tokens": [50964, 821, 321, 352, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2554029406923236, "compression_ratio": 1.3973214285714286, "no_speech_prob": 0.042619042098522186}, {"id": 316, "seek": 98900, "start": 1003.0, "end": 1004.0, "text": " I hope it's visible.", "tokens": [51064, 286, 1454, 309, 311, 8974, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2554029406923236, "compression_ratio": 1.3973214285714286, "no_speech_prob": 0.042619042098522186}, {"id": 317, "seek": 98900, "start": 1004.0, "end": 1009.0, "text": " And if I just click and press Enter,", "tokens": [51114, 400, 498, 286, 445, 2052, 293, 1886, 10399, 11, 51364], "temperature": 0.0, "avg_logprob": -0.2554029406923236, "compression_ratio": 1.3973214285714286, "no_speech_prob": 0.042619042098522186}, {"id": 318, "seek": 98900, "start": 1009.0, "end": 1011.0, "text": " now I set API 6.", "tokens": [51364, 586, 286, 992, 9362, 1386, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2554029406923236, "compression_ratio": 1.3973214285714286, "no_speech_prob": 0.042619042098522186}, {"id": 319, "seek": 98900, "start": 1011.0, "end": 1013.0, "text": " Please create the upstream service.", "tokens": [51464, 2555, 1884, 264, 33915, 2643, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2554029406923236, "compression_ratio": 1.3973214285714286, "no_speech_prob": 0.042619042098522186}, {"id": 320, "seek": 98900, "start": 1013.0, "end": 1018.0, "text": " Register my ESP.NET Web API as a backend service.", "tokens": [51564, 43167, 452, 12564, 47, 13, 35554, 9573, 9362, 382, 257, 38087, 2643, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2554029406923236, "compression_ratio": 1.3973214285714286, "no_speech_prob": 0.042619042098522186}, {"id": 321, "seek": 101800, "start": 1018.0, "end": 1021.0, "text": " And it should have this kind of configuration.", "tokens": [50364, 400, 309, 820, 362, 341, 733, 295, 11694, 13, 50514], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 322, "seek": 101800, "start": 1021.0, "end": 1024.0, "text": " Then next step, next easy step,", "tokens": [50514, 1396, 958, 1823, 11, 958, 1858, 1823, 11, 50664], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 323, "seek": 101800, "start": 1024.0, "end": 1027.0, "text": " what I do is I need to create,", "tokens": [50664, 437, 286, 360, 307, 286, 643, 281, 1884, 11, 50814], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 324, "seek": 101800, "start": 1027.0, "end": 1030.0, "text": " let's say for prometers, I need to create a row.", "tokens": [50814, 718, 311, 584, 337, 37786, 433, 11, 286, 643, 281, 1884, 257, 5386, 13, 50964], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 325, "seek": 101800, "start": 1030.0, "end": 1034.0, "text": " Because API Gateway has three very basics,", "tokens": [50964, 1436, 9362, 48394, 575, 1045, 588, 14688, 11, 51164], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 326, "seek": 101800, "start": 1034.0, "end": 1036.0, "text": " like you need to create the upstream,", "tokens": [51164, 411, 291, 643, 281, 1884, 264, 33915, 11, 51264], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 327, "seek": 101800, "start": 1036.0, "end": 1037.0, "text": " you need to create a row,", "tokens": [51264, 291, 643, 281, 1884, 257, 5386, 11, 51314], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 328, "seek": 101800, "start": 1037.0, "end": 1038.0, "text": " and enable some plugins.", "tokens": [51314, 293, 9528, 512, 33759, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 329, "seek": 101800, "start": 1038.0, "end": 1040.0, "text": " In my case, prometers plugins, right?", "tokens": [51364, 682, 452, 1389, 11, 37786, 433, 33759, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 330, "seek": 101800, "start": 1040.0, "end": 1044.0, "text": " As you can see, I have some plugins configuration on the top.", "tokens": [51464, 1018, 291, 393, 536, 11, 286, 362, 512, 33759, 11694, 322, 264, 1192, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 331, "seek": 101800, "start": 1044.0, "end": 1045.0, "text": " Only single prometers.", "tokens": [51664, 5686, 2167, 37786, 433, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14133538490484568, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.0463249534368515}, {"id": 332, "seek": 104500, "start": 1045.0, "end": 1048.0, "text": " And I'm giving reference to the upstream", "tokens": [50364, 400, 286, 478, 2902, 6408, 281, 264, 33915, 50514], "temperature": 0.0, "avg_logprob": -0.1527366828918457, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07797123491764069}, {"id": 333, "seek": 104500, "start": 1048.0, "end": 1050.0, "text": " that in the previous step we created.", "tokens": [50514, 300, 294, 264, 3894, 1823, 321, 2942, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1527366828918457, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07797123491764069}, {"id": 334, "seek": 104500, "start": 1050.0, "end": 1051.0, "text": " And that's all.", "tokens": [50614, 400, 300, 311, 439, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1527366828918457, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07797123491764069}, {"id": 335, "seek": 104500, "start": 1051.0, "end": 1054.0, "text": " Like I'm saying also, URI,", "tokens": [50664, 1743, 286, 478, 1566, 611, 11, 624, 5577, 11, 50814], "temperature": 0.0, "avg_logprob": -0.1527366828918457, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07797123491764069}, {"id": 336, "seek": 104500, "start": 1054.0, "end": 1060.0, "text": " for the row to find out which URI this plugin should absorb.", "tokens": [50814, 337, 264, 5386, 281, 915, 484, 597, 624, 5577, 341, 23407, 820, 15631, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1527366828918457, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07797123491764069}, {"id": 337, "seek": 104500, "start": 1060.0, "end": 1063.0, "text": " I'm saying fresh API slash products.", "tokens": [51114, 286, 478, 1566, 4451, 9362, 17330, 3383, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1527366828918457, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07797123491764069}, {"id": 338, "seek": 104500, "start": 1063.0, "end": 1064.0, "text": " Here we go.", "tokens": [51264, 1692, 321, 352, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1527366828918457, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07797123491764069}, {"id": 339, "seek": 104500, "start": 1064.0, "end": 1069.0, "text": " And then if I get this command and press and put it to terminal,", "tokens": [51314, 400, 550, 498, 286, 483, 341, 5622, 293, 1886, 293, 829, 309, 281, 14709, 11, 51564], "temperature": 0.0, "avg_logprob": -0.1527366828918457, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07797123491764069}, {"id": 340, "seek": 104500, "start": 1069.0, "end": 1072.0, "text": " now I will enable this plugin very fast.", "tokens": [51564, 586, 286, 486, 9528, 341, 23407, 588, 2370, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1527366828918457, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07797123491764069}, {"id": 341, "seek": 107200, "start": 1072.0, "end": 1075.0, "text": " An API six admin is saying,", "tokens": [50364, 1107, 9362, 2309, 24236, 307, 1566, 11, 50514], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 342, "seek": 107200, "start": 1075.0, "end": 1078.0, "text": " okay, now you have a row, you have upstream,", "tokens": [50514, 1392, 11, 586, 291, 362, 257, 5386, 11, 291, 362, 33915, 11, 50664], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 343, "seek": 107200, "start": 1078.0, "end": 1079.0, "text": " now it's time to test.", "tokens": [50664, 586, 309, 311, 565, 281, 1500, 13, 50714], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 344, "seek": 107200, "start": 1079.0, "end": 1083.0, "text": " Prometers plugin, I enabled like this couple of steps, right?", "tokens": [50714, 2114, 649, 433, 23407, 11, 286, 15172, 411, 341, 1916, 295, 4439, 11, 558, 30, 50914], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 345, "seek": 107200, "start": 1083.0, "end": 1086.0, "text": " You see the five seconds or six seconds, it's all.", "tokens": [50914, 509, 536, 264, 1732, 3949, 420, 2309, 3949, 11, 309, 311, 439, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 346, "seek": 107200, "start": 1086.0, "end": 1088.0, "text": " But compared to Java projects,", "tokens": [51064, 583, 5347, 281, 10745, 4455, 11, 51164], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 347, "seek": 107200, "start": 1088.0, "end": 1090.0, "text": " how you enable prometers also,", "tokens": [51164, 577, 291, 9528, 37786, 433, 611, 11, 51264], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 348, "seek": 107200, "start": 1090.0, "end": 1092.0, "text": " maybe a little bit compared to the same steps.", "tokens": [51264, 1310, 257, 707, 857, 5347, 281, 264, 912, 4439, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 349, "seek": 107200, "start": 1092.0, "end": 1096.0, "text": " But this API Gateway, you are just extracting", "tokens": [51364, 583, 341, 9362, 48394, 11, 291, 366, 445, 49844, 51564], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 350, "seek": 107200, "start": 1096.0, "end": 1099.0, "text": " a little bit of huge work to separate service.", "tokens": [51564, 257, 707, 857, 295, 2603, 589, 281, 4994, 2643, 13, 51714], "temperature": 0.0, "avg_logprob": -0.21939243704585706, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.03716196492314339}, {"id": 351, "seek": 109900, "start": 1099.0, "end": 1101.0, "text": " And it's highly scalable.", "tokens": [50364, 400, 309, 311, 5405, 38481, 13, 50464], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 352, "seek": 109900, "start": 1101.0, "end": 1104.0, "text": " That's one of the advantages of using API Gateway, right?", "tokens": [50464, 663, 311, 472, 295, 264, 14906, 295, 1228, 9362, 48394, 11, 558, 30, 50614], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 353, "seek": 109900, "start": 1104.0, "end": 1106.0, "text": " For your observability.", "tokens": [50614, 1171, 428, 9951, 2310, 13, 50714], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 354, "seek": 109900, "start": 1106.0, "end": 1110.0, "text": " And next, for example, I can generate some metrics", "tokens": [50714, 400, 958, 11, 337, 1365, 11, 286, 393, 8460, 512, 16367, 50914], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 355, "seek": 109900, "start": 1110.0, "end": 1114.0, "text": " by calling my maybe API into point several times,", "tokens": [50914, 538, 5141, 452, 1310, 9362, 666, 935, 2940, 1413, 11, 51114], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 356, "seek": 109900, "start": 1114.0, "end": 1116.0, "text": " maybe like this.", "tokens": [51114, 1310, 411, 341, 13, 51214], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 357, "seek": 109900, "start": 1116.0, "end": 1120.0, "text": " As you can see, it's responding me with the product list", "tokens": [51214, 1018, 291, 393, 536, 11, 309, 311, 16670, 385, 365, 264, 1674, 1329, 51414], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 358, "seek": 109900, "start": 1120.0, "end": 1121.0, "text": " in the response.", "tokens": [51414, 294, 264, 4134, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 359, "seek": 109900, "start": 1121.0, "end": 1123.0, "text": " Maybe I can do it one more time.", "tokens": [51464, 2704, 286, 393, 360, 309, 472, 544, 565, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 360, "seek": 109900, "start": 1123.0, "end": 1126.0, "text": " So we have some data on it.", "tokens": [51564, 407, 321, 362, 512, 1412, 322, 309, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13637103126162575, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.04744578152894974}, {"id": 361, "seek": 112600, "start": 1126.0, "end": 1131.0, "text": " And now, if I navigate to...", "tokens": [50364, 400, 586, 11, 498, 286, 12350, 281, 485, 50614], "temperature": 0.0, "avg_logprob": -0.13249032974243163, "compression_ratio": 1.6855670103092784, "no_speech_prob": 0.013937626034021378}, {"id": 362, "seek": 112600, "start": 1131.0, "end": 1134.0, "text": " Maybe if I can request all the prometers metrics", "tokens": [50614, 2704, 498, 286, 393, 5308, 439, 264, 37786, 433, 16367, 50764], "temperature": 0.0, "avg_logprob": -0.13249032974243163, "compression_ratio": 1.6855670103092784, "no_speech_prob": 0.013937626034021378}, {"id": 363, "seek": 112600, "start": 1134.0, "end": 1137.0, "text": " to see some result, right, in this output,", "tokens": [50764, 281, 536, 512, 1874, 11, 558, 11, 294, 341, 5598, 11, 50914], "temperature": 0.0, "avg_logprob": -0.13249032974243163, "compression_ratio": 1.6855670103092784, "no_speech_prob": 0.013937626034021378}, {"id": 364, "seek": 112600, "start": 1137.0, "end": 1141.0, "text": " I can run another command, maybe like this.", "tokens": [50914, 286, 393, 1190, 1071, 5622, 11, 1310, 411, 341, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13249032974243163, "compression_ratio": 1.6855670103092784, "no_speech_prob": 0.013937626034021378}, {"id": 365, "seek": 112600, "start": 1141.0, "end": 1142.0, "text": " Here we go.", "tokens": [51114, 1692, 321, 352, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13249032974243163, "compression_ratio": 1.6855670103092784, "no_speech_prob": 0.013937626034021378}, {"id": 366, "seek": 112600, "start": 1142.0, "end": 1144.0, "text": " As you can see, metrics are enabled.", "tokens": [51164, 1018, 291, 393, 536, 11, 16367, 366, 15172, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13249032974243163, "compression_ratio": 1.6855670103092784, "no_speech_prob": 0.013937626034021378}, {"id": 367, "seek": 112600, "start": 1144.0, "end": 1146.0, "text": " I can see some metrics, HTTP metrics,", "tokens": [51264, 286, 393, 536, 512, 16367, 11, 33283, 16367, 11, 51364], "temperature": 0.0, "avg_logprob": -0.13249032974243163, "compression_ratio": 1.6855670103092784, "no_speech_prob": 0.013937626034021378}, {"id": 368, "seek": 112600, "start": 1146.0, "end": 1149.0, "text": " plus some API six metrics, as you can see.", "tokens": [51364, 1804, 512, 9362, 2309, 16367, 11, 382, 291, 393, 536, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13249032974243163, "compression_ratio": 1.6855670103092784, "no_speech_prob": 0.013937626034021378}, {"id": 369, "seek": 112600, "start": 1149.0, "end": 1152.0, "text": " If you have API six HTTP status,", "tokens": [51514, 759, 291, 362, 9362, 2309, 33283, 6558, 11, 51664], "temperature": 0.0, "avg_logprob": -0.13249032974243163, "compression_ratio": 1.6855670103092784, "no_speech_prob": 0.013937626034021378}, {"id": 370, "seek": 115200, "start": 1152.0, "end": 1156.0, "text": " it was 200 returned and was fine.", "tokens": [50364, 309, 390, 2331, 8752, 293, 390, 2489, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1797504975245549, "compression_ratio": 1.5021645021645023, "no_speech_prob": 0.020166167989373207}, {"id": 371, "seek": 115200, "start": 1156.0, "end": 1161.0, "text": " And, of course, it looks like a little bit ugly, right?", "tokens": [50564, 400, 11, 295, 1164, 11, 309, 1542, 411, 257, 707, 857, 12246, 11, 558, 30, 50814], "temperature": 0.0, "avg_logprob": -0.1797504975245549, "compression_ratio": 1.5021645021645023, "no_speech_prob": 0.020166167989373207}, {"id": 372, "seek": 115200, "start": 1161.0, "end": 1165.0, "text": " Now, you can see even maybe these metrics on the dashboard.", "tokens": [50814, 823, 11, 291, 393, 536, 754, 1310, 613, 16367, 322, 264, 18342, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1797504975245549, "compression_ratio": 1.5021645021645023, "no_speech_prob": 0.020166167989373207}, {"id": 373, "seek": 115200, "start": 1165.0, "end": 1169.0, "text": " Just navigate to localhosts-targets,", "tokens": [51014, 1449, 12350, 281, 2654, 6037, 82, 12, 23480, 16284, 11, 51214], "temperature": 0.0, "avg_logprob": -0.1797504975245549, "compression_ratio": 1.5021645021645023, "no_speech_prob": 0.020166167989373207}, {"id": 374, "seek": 115200, "start": 1169.0, "end": 1171.0, "text": " because we are running on localhost.", "tokens": [51214, 570, 321, 366, 2614, 322, 2654, 6037, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1797504975245549, "compression_ratio": 1.5021645021645023, "no_speech_prob": 0.020166167989373207}, {"id": 375, "seek": 115200, "start": 1171.0, "end": 1173.0, "text": " When you deploy maybe to the cloud,", "tokens": [51314, 1133, 291, 7274, 1310, 281, 264, 4588, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1797504975245549, "compression_ratio": 1.5021645021645023, "no_speech_prob": 0.020166167989373207}, {"id": 376, "seek": 115200, "start": 1173.0, "end": 1175.0, "text": " you will have a domain and so on.", "tokens": [51414, 291, 486, 362, 257, 9274, 293, 370, 322, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1797504975245549, "compression_ratio": 1.5021645021645023, "no_speech_prob": 0.020166167989373207}, {"id": 377, "seek": 115200, "start": 1175.0, "end": 1179.0, "text": " But as you can see on the prometers, if I refresh it,", "tokens": [51514, 583, 382, 291, 393, 536, 322, 264, 37786, 433, 11, 498, 286, 15134, 309, 11, 51714], "temperature": 0.0, "avg_logprob": -0.1797504975245549, "compression_ratio": 1.5021645021645023, "no_speech_prob": 0.020166167989373207}, {"id": 378, "seek": 117900, "start": 1179.0, "end": 1183.0, "text": " you will have soon now some metrics on it.", "tokens": [50364, 291, 486, 362, 2321, 586, 512, 16367, 322, 309, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 379, "seek": 117900, "start": 1183.0, "end": 1188.0, "text": " Of course, you can specify some parameters for your metrics.", "tokens": [50564, 2720, 1164, 11, 291, 393, 16500, 512, 9834, 337, 428, 16367, 13, 50814], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 380, "seek": 117900, "start": 1188.0, "end": 1189.0, "text": " And let me...", "tokens": [50814, 400, 718, 385, 485, 50864], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 381, "seek": 117900, "start": 1189.0, "end": 1191.0, "text": " We need to maybe a little bit wait", "tokens": [50864, 492, 643, 281, 1310, 257, 707, 857, 1699, 50964], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 382, "seek": 117900, "start": 1191.0, "end": 1196.0, "text": " to be enabled these metrics on the UI.", "tokens": [50964, 281, 312, 15172, 613, 16367, 322, 264, 15682, 13, 51214], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 383, "seek": 117900, "start": 1196.0, "end": 1197.0, "text": " Yeah.", "tokens": [51214, 865, 13, 51264], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 384, "seek": 117900, "start": 1197.0, "end": 1199.0, "text": " Let me check the targets.", "tokens": [51264, 961, 385, 1520, 264, 12911, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 385, "seek": 117900, "start": 1199.0, "end": 1201.0, "text": " It's unhealthy.", "tokens": [51364, 467, 311, 29147, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 386, "seek": 117900, "start": 1201.0, "end": 1206.0, "text": " Maybe we need to do some local compost down and up.", "tokens": [51464, 2704, 321, 643, 281, 360, 512, 2654, 20203, 760, 293, 493, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 387, "seek": 117900, "start": 1206.0, "end": 1208.0, "text": " Every time when it comes to demo, something fails.", "tokens": [51714, 2048, 565, 562, 309, 1487, 281, 10723, 11, 746, 18199, 13, 51814], "temperature": 0.0, "avg_logprob": -0.14592703819274902, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.007902886718511581}, {"id": 388, "seek": 120800, "start": 1208.0, "end": 1211.0, "text": " It's unexpected, not expected.", "tokens": [50364, 467, 311, 13106, 11, 406, 5176, 13, 50514], "temperature": 0.0, "avg_logprob": -0.22549104690551758, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.031656328588724136}, {"id": 389, "seek": 120800, "start": 1211.0, "end": 1213.0, "text": " Docker compost down.", "tokens": [50514, 33772, 20203, 760, 13, 50614], "temperature": 0.0, "avg_logprob": -0.22549104690551758, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.031656328588724136}, {"id": 390, "seek": 120800, "start": 1213.0, "end": 1216.0, "text": " Maybe I will do this trick.", "tokens": [50614, 2704, 286, 486, 360, 341, 4282, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22549104690551758, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.031656328588724136}, {"id": 391, "seek": 120800, "start": 1216.0, "end": 1222.0, "text": " And maybe then an up in a moment.", "tokens": [50764, 400, 1310, 550, 364, 493, 294, 257, 1623, 13, 51064], "temperature": 0.0, "avg_logprob": -0.22549104690551758, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.031656328588724136}, {"id": 392, "seek": 120800, "start": 1222.0, "end": 1223.0, "text": " Yep.", "tokens": [51064, 7010, 13, 51114], "temperature": 0.0, "avg_logprob": -0.22549104690551758, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.031656328588724136}, {"id": 393, "seek": 120800, "start": 1223.0, "end": 1224.0, "text": " And here we go.", "tokens": [51114, 400, 510, 321, 352, 13, 51164], "temperature": 0.0, "avg_logprob": -0.22549104690551758, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.031656328588724136}, {"id": 394, "seek": 120800, "start": 1224.0, "end": 1231.0, "text": " If I do up, it will bring and refresh some Docker stuff.", "tokens": [51164, 759, 286, 360, 493, 11, 309, 486, 1565, 293, 15134, 512, 33772, 1507, 13, 51514], "temperature": 0.0, "avg_logprob": -0.22549104690551758, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.031656328588724136}, {"id": 395, "seek": 120800, "start": 1231.0, "end": 1233.0, "text": " This Docker always is kind of a issue.", "tokens": [51514, 639, 33772, 1009, 307, 733, 295, 257, 2734, 13, 51614], "temperature": 0.0, "avg_logprob": -0.22549104690551758, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.031656328588724136}, {"id": 396, "seek": 120800, "start": 1233.0, "end": 1237.0, "text": " Now, if I do this, targets should be...", "tokens": [51614, 823, 11, 498, 286, 360, 341, 11, 12911, 820, 312, 485, 51814], "temperature": 0.0, "avg_logprob": -0.22549104690551758, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.031656328588724136}, {"id": 397, "seek": 123700, "start": 1237.0, "end": 1238.0, "text": " No, no.", "tokens": [50364, 883, 11, 572, 13, 50414], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 398, "seek": 123700, "start": 1238.0, "end": 1239.0, "text": " It's still yes.", "tokens": [50414, 467, 311, 920, 2086, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 399, "seek": 123700, "start": 1239.0, "end": 1240.0, "text": " It's stopping.", "tokens": [50464, 467, 311, 12767, 13, 50514], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 400, "seek": 123700, "start": 1240.0, "end": 1241.0, "text": " Yes.", "tokens": [50514, 1079, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 401, "seek": 123700, "start": 1241.0, "end": 1242.0, "text": " Now we are in an upstate.", "tokens": [50564, 823, 321, 366, 294, 364, 493, 15406, 13, 50614], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 402, "seek": 123700, "start": 1242.0, "end": 1245.0, "text": " And then let me also generate some logs once again.", "tokens": [50614, 400, 550, 718, 385, 611, 8460, 512, 20820, 1564, 797, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 403, "seek": 123700, "start": 1245.0, "end": 1248.0, "text": " Or even it should be visible now.", "tokens": [50764, 1610, 754, 309, 820, 312, 8974, 586, 13, 50914], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 404, "seek": 123700, "start": 1248.0, "end": 1250.0, "text": " Let me go.", "tokens": [50914, 961, 385, 352, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 405, "seek": 123700, "start": 1250.0, "end": 1253.0, "text": " API 6.", "tokens": [51014, 9362, 1386, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 406, "seek": 123700, "start": 1253.0, "end": 1257.0, "text": " HTTP status, if I have any.", "tokens": [51164, 33283, 6558, 11, 498, 286, 362, 604, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 407, "seek": 123700, "start": 1257.0, "end": 1262.0, "text": " Or even you can see any traces, any metrics here.", "tokens": [51364, 1610, 754, 291, 393, 536, 604, 26076, 11, 604, 16367, 510, 13, 51614], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 408, "seek": 123700, "start": 1262.0, "end": 1265.0, "text": " As you can see, I can even see ETCD.", "tokens": [51614, 1018, 291, 393, 536, 11, 286, 393, 754, 536, 462, 18238, 35, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19489180600201642, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.02501865103840828}, {"id": 409, "seek": 126500, "start": 1265.0, "end": 1268.0, "text": " ETCD has a storage for the API 6.", "tokens": [50364, 462, 18238, 35, 575, 257, 6725, 337, 264, 9362, 1386, 13, 50514], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 410, "seek": 126500, "start": 1268.0, "end": 1272.0, "text": " What kind of data exchanging between API 6 and the storage?", "tokens": [50514, 708, 733, 295, 1412, 6210, 9741, 1296, 9362, 1386, 293, 264, 6725, 30, 50714], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 411, "seek": 126500, "start": 1272.0, "end": 1273.0, "text": " And so on.", "tokens": [50714, 400, 370, 322, 13, 50764], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 412, "seek": 126500, "start": 1273.0, "end": 1276.0, "text": " I mean, you can filter out all the metrics you want.", "tokens": [50764, 286, 914, 11, 291, 393, 6608, 484, 439, 264, 16367, 291, 528, 13, 50914], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 413, "seek": 126500, "start": 1276.0, "end": 1278.0, "text": " And even you can see in the graph.", "tokens": [50914, 400, 754, 291, 393, 536, 294, 264, 4295, 13, 51014], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 414, "seek": 126500, "start": 1278.0, "end": 1280.0, "text": " If it's not enough on a promises dashboard,", "tokens": [51014, 759, 309, 311, 406, 1547, 322, 257, 16403, 18342, 11, 51114], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 415, "seek": 126500, "start": 1280.0, "end": 1282.0, "text": " you can connect with Grafana, right?", "tokens": [51114, 291, 393, 1745, 365, 8985, 69, 2095, 11, 558, 30, 51214], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 416, "seek": 126500, "start": 1282.0, "end": 1284.0, "text": " Very easy.", "tokens": [51214, 4372, 1858, 13, 51314], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 417, "seek": 126500, "start": 1284.0, "end": 1287.0, "text": " We have an API 6 Grafana dashboard.", "tokens": [51314, 492, 362, 364, 9362, 1386, 8985, 69, 2095, 18342, 13, 51464], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 418, "seek": 126500, "start": 1287.0, "end": 1292.0, "text": " You can easily integrate also these logs and metrics", "tokens": [51464, 509, 393, 3612, 13365, 611, 613, 20820, 293, 16367, 51714], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 419, "seek": 126500, "start": 1292.0, "end": 1294.0, "text": " by visualizing them.", "tokens": [51714, 538, 5056, 3319, 552, 13, 51814], "temperature": 0.0, "avg_logprob": -0.15932951682855276, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.12154871970415115}, {"id": 420, "seek": 129400, "start": 1294.0, "end": 1296.0, "text": " So with it, that was a very easy demo.", "tokens": [50364, 407, 365, 309, 11, 300, 390, 257, 588, 1858, 10723, 13, 50464], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 421, "seek": 129400, "start": 1296.0, "end": 1298.0, "text": " I think we can continue.", "tokens": [50464, 286, 519, 321, 393, 2354, 13, 50564], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 422, "seek": 129400, "start": 1298.0, "end": 1301.0, "text": " If you're interested in that, you can play with other plugins", "tokens": [50564, 759, 291, 434, 3102, 294, 300, 11, 291, 393, 862, 365, 661, 33759, 50714], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 423, "seek": 129400, "start": 1301.0, "end": 1303.0, "text": " straightforward.", "tokens": [50714, 15325, 13, 50814], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 424, "seek": 129400, "start": 1303.0, "end": 1308.0, "text": " And now maybe we can switch to my presentation.", "tokens": [50814, 400, 586, 1310, 321, 393, 3679, 281, 452, 5860, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 425, "seek": 129400, "start": 1308.0, "end": 1310.0, "text": " And maybe if you have any questions,", "tokens": [51064, 400, 1310, 498, 291, 362, 604, 1651, 11, 51164], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 426, "seek": 129400, "start": 1310.0, "end": 1313.0, "text": " we can jump into question presentation", "tokens": [51164, 321, 393, 3012, 666, 1168, 5860, 51314], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 427, "seek": 129400, "start": 1313.0, "end": 1315.0, "text": " because we are already running out of time.", "tokens": [51314, 570, 321, 366, 1217, 2614, 484, 295, 565, 13, 51414], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 428, "seek": 129400, "start": 1315.0, "end": 1318.0, "text": " Here are some references I'm giving out to you.", "tokens": [51414, 1692, 366, 512, 15400, 286, 478, 2902, 484, 281, 291, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 429, "seek": 129400, "start": 1318.0, "end": 1320.0, "text": " For you.", "tokens": [51564, 1171, 291, 13, 51664], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 430, "seek": 129400, "start": 1320.0, "end": 1323.0, "text": " Yep.", "tokens": [51664, 7010, 13, 51814], "temperature": 0.0, "avg_logprob": -0.16610027494884672, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.005666214041411877}, {"id": 431, "seek": 132300, "start": 1323.0, "end": 1325.0, "text": " Any questions?", "tokens": [50364, 2639, 1651, 30, 50464], "temperature": 0.0, "avg_logprob": -0.21185312599971376, "compression_ratio": 1.2962962962962963, "no_speech_prob": 0.02275969833135605}, {"id": 432, "seek": 132300, "start": 1325.0, "end": 1326.0, "text": " OK, thanks.", "tokens": [50464, 2264, 11, 3231, 13, 50514], "temperature": 0.0, "avg_logprob": -0.21185312599971376, "compression_ratio": 1.2962962962962963, "no_speech_prob": 0.02275969833135605}, {"id": 433, "seek": 132300, "start": 1326.0, "end": 1327.0, "text": " Thanks a lot.", "tokens": [50514, 2561, 257, 688, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21185312599971376, "compression_ratio": 1.2962962962962963, "no_speech_prob": 0.02275969833135605}, {"id": 434, "seek": 132300, "start": 1327.0, "end": 1341.0, "text": " So, I have one more t-shirt.", "tokens": [50564, 407, 11, 286, 362, 472, 544, 256, 12, 15313, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21185312599971376, "compression_ratio": 1.2962962962962963, "no_speech_prob": 0.02275969833135605}, {"id": 435, "seek": 132300, "start": 1341.0, "end": 1345.0, "text": " Yeah, I have a question regarding the plugins.", "tokens": [51264, 865, 11, 286, 362, 257, 1168, 8595, 264, 33759, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21185312599971376, "compression_ratio": 1.2962962962962963, "no_speech_prob": 0.02275969833135605}, {"id": 436, "seek": 132300, "start": 1345.0, "end": 1350.0, "text": " For instance, with traffic, you have to kind of connect it", "tokens": [51464, 1171, 5197, 11, 365, 6419, 11, 291, 362, 281, 733, 295, 1745, 309, 51714], "temperature": 0.0, "avg_logprob": -0.21185312599971376, "compression_ratio": 1.2962962962962963, "no_speech_prob": 0.02275969833135605}, {"id": 437, "seek": 135000, "start": 1350.0, "end": 1353.0, "text": " to pilot and download them as it starts.", "tokens": [50364, 281, 9691, 293, 5484, 552, 382, 309, 3719, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 438, "seek": 135000, "start": 1353.0, "end": 1356.0, "text": " How do you develop custom plugins for API 6", "tokens": [50514, 1012, 360, 291, 1499, 2375, 33759, 337, 9362, 1386, 50664], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 439, "seek": 135000, "start": 1356.0, "end": 1360.0, "text": " and how do you package them with the API gateway?", "tokens": [50664, 293, 577, 360, 291, 7372, 552, 365, 264, 9362, 28532, 30, 50864], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 440, "seek": 135000, "start": 1360.0, "end": 1362.0, "text": " Sorry, once again, last few sentences.", "tokens": [50864, 4919, 11, 1564, 797, 11, 1036, 1326, 16579, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 441, "seek": 135000, "start": 1362.0, "end": 1364.0, "text": " There was a door is open.", "tokens": [50964, 821, 390, 257, 2853, 307, 1269, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 442, "seek": 135000, "start": 1364.0, "end": 1365.0, "text": " Sure.", "tokens": [51064, 4894, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 443, "seek": 135000, "start": 1365.0, "end": 1367.0, "text": " I was just wondering about plugin development,", "tokens": [51114, 286, 390, 445, 6359, 466, 23407, 3250, 11, 51214], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 444, "seek": 135000, "start": 1367.0, "end": 1371.0, "text": " like how rich is the ecosystem for API 6.", "tokens": [51214, 411, 577, 4593, 307, 264, 11311, 337, 9362, 1386, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 445, "seek": 135000, "start": 1371.0, "end": 1374.0, "text": " And if I were to develop a plugin,", "tokens": [51414, 400, 498, 286, 645, 281, 1499, 257, 23407, 11, 51564], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 446, "seek": 135000, "start": 1374.0, "end": 1378.0, "text": " is it easy to package with the binary", "tokens": [51564, 307, 309, 1858, 281, 7372, 365, 264, 17434, 51764], "temperature": 0.0, "avg_logprob": -0.1315388954602755, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.08540864288806915}, {"id": 447, "seek": 137800, "start": 1378.0, "end": 1381.0, "text": " or do I have to connect to some kind of pilot", "tokens": [50364, 420, 360, 286, 362, 281, 1745, 281, 512, 733, 295, 9691, 50514], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 448, "seek": 137800, "start": 1381.0, "end": 1382.0, "text": " and it downloads it?", "tokens": [50514, 293, 309, 36553, 309, 30, 50564], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 449, "seek": 137800, "start": 1382.0, "end": 1383.0, "text": " Yeah, very nice question.", "tokens": [50564, 865, 11, 588, 1481, 1168, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 450, "seek": 137800, "start": 1383.0, "end": 1384.0, "text": " I love it.", "tokens": [50614, 286, 959, 309, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 451, "seek": 137800, "start": 1384.0, "end": 1385.0, "text": " Very nice question.", "tokens": [50664, 4372, 1481, 1168, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 452, "seek": 137800, "start": 1385.0, "end": 1387.0, "text": " Yeah, it's very straightforward", "tokens": [50714, 865, 11, 309, 311, 588, 15325, 50814], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 453, "seek": 137800, "start": 1387.0, "end": 1391.0, "text": " because we have now support for five different languages.", "tokens": [50814, 570, 321, 362, 586, 1406, 337, 1732, 819, 8650, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 454, "seek": 137800, "start": 1391.0, "end": 1395.0, "text": " If you are using this support program in English,", "tokens": [51014, 759, 291, 366, 1228, 341, 1406, 1461, 294, 3669, 11, 51214], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 455, "seek": 137800, "start": 1395.0, "end": 1396.0, "text": " we have plugin runners.", "tokens": [51214, 321, 362, 23407, 33892, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 456, "seek": 137800, "start": 1396.0, "end": 1398.0, "text": " You don't have to build anything.", "tokens": [51264, 509, 500, 380, 362, 281, 1322, 1340, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 457, "seek": 137800, "start": 1398.0, "end": 1400.0, "text": " You can just run.", "tokens": [51364, 509, 393, 445, 1190, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 458, "seek": 137800, "start": 1400.0, "end": 1403.0, "text": " Of course, you need to create some binaries for Java,", "tokens": [51464, 2720, 1164, 11, 291, 643, 281, 1884, 512, 5171, 4889, 337, 10745, 11, 51614], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 459, "seek": 137800, "start": 1403.0, "end": 1405.0, "text": " let's say, Java file.", "tokens": [51614, 718, 311, 584, 11, 10745, 3991, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1372362355716893, "compression_ratio": 1.62109375, "no_speech_prob": 0.07394945621490479}, {"id": 460, "seek": 140500, "start": 1405.0, "end": 1407.0, "text": " And this Java file has a connection", "tokens": [50364, 400, 341, 10745, 3991, 575, 257, 4984, 50464], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 461, "seek": 140500, "start": 1407.0, "end": 1409.0, "text": " by using Unix socket files.", "tokens": [50464, 538, 1228, 1156, 970, 19741, 7098, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 462, "seek": 140500, "start": 1409.0, "end": 1412.0, "text": " It can communicate with Unix socket files", "tokens": [50564, 467, 393, 7890, 365, 1156, 970, 19741, 7098, 50714], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 463, "seek": 140500, "start": 1412.0, "end": 1414.0, "text": " and you can exchange some log data.", "tokens": [50714, 293, 291, 393, 7742, 512, 3565, 1412, 13, 50814], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 464, "seek": 140500, "start": 1414.0, "end": 1416.0, "text": " I mean, the request data.", "tokens": [50814, 286, 914, 11, 264, 5308, 1412, 13, 50914], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 465, "seek": 140500, "start": 1416.0, "end": 1418.0, "text": " I had another presentation also.", "tokens": [50914, 286, 632, 1071, 5860, 611, 13, 51014], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 466, "seek": 140500, "start": 1418.0, "end": 1421.0, "text": " Maybe I can share with you after the session", "tokens": [51014, 2704, 286, 393, 2073, 365, 291, 934, 264, 5481, 51164], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 467, "seek": 140500, "start": 1421.0, "end": 1423.0, "text": " about how to write in Java plugin,", "tokens": [51164, 466, 577, 281, 2464, 294, 10745, 23407, 11, 51264], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 468, "seek": 140500, "start": 1423.0, "end": 1426.0, "text": " how to create plugin maybe in Python and so on.", "tokens": [51264, 577, 281, 1884, 23407, 1310, 294, 15329, 293, 370, 322, 13, 51414], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 469, "seek": 140500, "start": 1426.0, "end": 1428.0, "text": " This is a t-shirt for you.", "tokens": [51414, 639, 307, 257, 256, 12, 15313, 337, 291, 13, 51514], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 470, "seek": 140500, "start": 1428.0, "end": 1430.0, "text": " So I will keep it.", "tokens": [51514, 407, 286, 486, 1066, 309, 13, 51614], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 471, "seek": 140500, "start": 1430.0, "end": 1431.0, "text": " More questions?", "tokens": [51614, 5048, 1651, 30, 51664], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 472, "seek": 140500, "start": 1431.0, "end": 1433.0, "text": " But I don't have a t-shirt.", "tokens": [51664, 583, 286, 500, 380, 362, 257, 256, 12, 15313, 13, 51764], "temperature": 0.0, "avg_logprob": -0.14064671674112636, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.05027315393090248}, {"id": 473, "seek": 143300, "start": 1433.0, "end": 1434.0, "text": " Hello.", "tokens": [50364, 2425, 13, 50414], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 474, "seek": 143300, "start": 1434.0, "end": 1437.0, "text": " How do you compare API 6 to other API gateways", "tokens": [50414, 1012, 360, 291, 6794, 9362, 1386, 281, 661, 9362, 8539, 942, 50564], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 475, "seek": 143300, "start": 1437.0, "end": 1440.0, "text": " like Gravity, Kong, or...", "tokens": [50564, 411, 49478, 11, 9832, 11, 420, 485, 50714], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 476, "seek": 143300, "start": 1440.0, "end": 1442.0, "text": " Which API gateways again?", "tokens": [50714, 3013, 9362, 8539, 942, 797, 30, 50814], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 477, "seek": 143300, "start": 1442.0, "end": 1448.0, "text": " How do you compare API 6 to other API gateways on the market?", "tokens": [50814, 1012, 360, 291, 6794, 9362, 1386, 281, 661, 9362, 8539, 942, 322, 264, 2142, 30, 51114], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 478, "seek": 143300, "start": 1448.0, "end": 1451.0, "text": " How do I compare or...", "tokens": [51114, 1012, 360, 286, 6794, 420, 485, 51264], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 479, "seek": 143300, "start": 1451.0, "end": 1453.0, "text": " What's its main selling point?", "tokens": [51264, 708, 311, 1080, 2135, 6511, 935, 30, 51364], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 480, "seek": 143300, "start": 1453.0, "end": 1455.0, "text": " Sorry, once again.", "tokens": [51364, 4919, 11, 1564, 797, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 481, "seek": 143300, "start": 1455.0, "end": 1456.0, "text": " What's its main selling point?", "tokens": [51464, 708, 311, 1080, 2135, 6511, 935, 30, 51514], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 482, "seek": 143300, "start": 1456.0, "end": 1462.0, "text": " Why is it better than other API gateways?", "tokens": [51514, 1545, 307, 309, 1101, 813, 661, 9362, 8539, 942, 30, 51814], "temperature": 0.0, "avg_logprob": -0.1931177839940908, "compression_ratio": 1.9440993788819876, "no_speech_prob": 0.23569966852664948}, {"id": 483, "seek": 146200, "start": 1462.0, "end": 1465.0, "text": " Code coverage, do you mean?", "tokens": [50364, 15549, 9645, 11, 360, 291, 914, 30, 50514], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 484, "seek": 146200, "start": 1465.0, "end": 1469.0, "text": " Compared to the others, I think it's a little bit...", "tokens": [50514, 30539, 281, 264, 2357, 11, 286, 519, 309, 311, 257, 707, 857, 485, 50714], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 485, "seek": 146200, "start": 1469.0, "end": 1472.0, "text": " I think it would be a little bit hard to listen from that.", "tokens": [50714, 286, 519, 309, 576, 312, 257, 707, 857, 1152, 281, 2140, 490, 300, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 486, "seek": 146200, "start": 1472.0, "end": 1474.0, "text": " I will come to...", "tokens": [50864, 286, 486, 808, 281, 485, 50964], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 487, "seek": 146200, "start": 1474.0, "end": 1477.0, "text": " There's a lot of API gateways on the market.", "tokens": [50964, 821, 311, 257, 688, 295, 9362, 8539, 942, 322, 264, 2142, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 488, "seek": 146200, "start": 1477.0, "end": 1478.0, "text": " Yes, yes.", "tokens": [51114, 1079, 11, 2086, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 489, "seek": 146200, "start": 1478.0, "end": 1480.0, "text": " Why is API 6...", "tokens": [51164, 1545, 307, 9362, 1386, 485, 51264], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 490, "seek": 146200, "start": 1480.0, "end": 1481.0, "text": " Oh, do you mean benchmarking?", "tokens": [51264, 876, 11, 360, 291, 914, 18927, 278, 30, 51314], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 491, "seek": 146200, "start": 1481.0, "end": 1483.0, "text": " Ah, okay, I got it.", "tokens": [51314, 2438, 11, 1392, 11, 286, 658, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 492, "seek": 146200, "start": 1483.0, "end": 1486.0, "text": " I'm not, of course, trying to sell API 6, right?", "tokens": [51414, 286, 478, 406, 11, 295, 1164, 11, 1382, 281, 3607, 9362, 1386, 11, 558, 30, 51564], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 493, "seek": 146200, "start": 1486.0, "end": 1487.0, "text": " Even if I have a t-shirt.", "tokens": [51564, 2754, 498, 286, 362, 257, 256, 12, 15313, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 494, "seek": 146200, "start": 1487.0, "end": 1488.0, "text": " I'm just giving out a t-shirt.", "tokens": [51614, 286, 478, 445, 2902, 484, 257, 256, 12, 15313, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 495, "seek": 146200, "start": 1488.0, "end": 1490.0, "text": " I'm an open source contributor", "tokens": [51664, 286, 478, 364, 1269, 4009, 42859, 51764], "temperature": 0.0, "avg_logprob": -0.2513016329871284, "compression_ratio": 1.6085271317829457, "no_speech_prob": 0.10117849707603455}, {"id": 496, "seek": 149000, "start": 1490.0, "end": 1495.0, "text": " because one reason is it provides hot reloading of plugins.", "tokens": [50364, 570, 472, 1778, 307, 309, 6417, 2368, 25628, 278, 295, 33759, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09850799923851376, "compression_ratio": 1.8026905829596414, "no_speech_prob": 0.13139493763446808}, {"id": 497, "seek": 149000, "start": 1495.0, "end": 1497.0, "text": " You don't have to stop your instance.", "tokens": [50614, 509, 500, 380, 362, 281, 1590, 428, 5197, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09850799923851376, "compression_ratio": 1.8026905829596414, "no_speech_prob": 0.13139493763446808}, {"id": 498, "seek": 149000, "start": 1497.0, "end": 1499.0, "text": " You don't have to stop the instance.", "tokens": [50714, 509, 500, 380, 362, 281, 1590, 264, 5197, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09850799923851376, "compression_ratio": 1.8026905829596414, "no_speech_prob": 0.13139493763446808}, {"id": 499, "seek": 149000, "start": 1499.0, "end": 1503.0, "text": " You can just run these plugins on the fly.", "tokens": [50814, 509, 393, 445, 1190, 613, 33759, 322, 264, 3603, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09850799923851376, "compression_ratio": 1.8026905829596414, "no_speech_prob": 0.13139493763446808}, {"id": 500, "seek": 149000, "start": 1503.0, "end": 1505.0, "text": " You can switch off one plugin.", "tokens": [51014, 509, 393, 3679, 766, 472, 23407, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09850799923851376, "compression_ratio": 1.8026905829596414, "no_speech_prob": 0.13139493763446808}, {"id": 501, "seek": 149000, "start": 1505.0, "end": 1509.0, "text": " You can write your custom plugin enable while this API 6 instance is running.", "tokens": [51114, 509, 393, 2464, 428, 2375, 23407, 9528, 1339, 341, 9362, 1386, 5197, 307, 2614, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09850799923851376, "compression_ratio": 1.8026905829596414, "no_speech_prob": 0.13139493763446808}, {"id": 502, "seek": 149000, "start": 1509.0, "end": 1513.0, "text": " This is one of the advantages that any other API gateways they don't provide.", "tokens": [51314, 639, 307, 472, 295, 264, 14906, 300, 604, 661, 9362, 8539, 942, 436, 500, 380, 2893, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09850799923851376, "compression_ratio": 1.8026905829596414, "no_speech_prob": 0.13139493763446808}, {"id": 503, "seek": 149000, "start": 1513.0, "end": 1516.0, "text": " And the performance is on the top now", "tokens": [51514, 400, 264, 3389, 307, 322, 264, 1192, 586, 51664], "temperature": 0.0, "avg_logprob": -0.09850799923851376, "compression_ratio": 1.8026905829596414, "no_speech_prob": 0.13139493763446808}, {"id": 504, "seek": 151600, "start": 1516.0, "end": 1518.0, "text": " compared to com API gateway.", "tokens": [50364, 5347, 281, 395, 9362, 28532, 13, 50464], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 505, "seek": 151600, "start": 1518.0, "end": 1520.0, "text": " Our performance is high, twice faster.", "tokens": [50464, 2621, 3389, 307, 1090, 11, 6091, 4663, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 506, "seek": 151600, "start": 1520.0, "end": 1522.0, "text": " You can check it out.", "tokens": [50564, 509, 393, 1520, 309, 484, 13, 50664], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 507, "seek": 151600, "start": 1522.0, "end": 1524.0, "text": " And we have...", "tokens": [50664, 400, 321, 362, 485, 50764], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 508, "seek": 151600, "start": 1524.0, "end": 1528.0, "text": " API 6 not only has API gateway, it has also English controller.", "tokens": [50764, 9362, 1386, 406, 787, 575, 9362, 28532, 11, 309, 575, 611, 3669, 10561, 13, 50964], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 509, "seek": 151600, "start": 1528.0, "end": 1531.0, "text": " You can use it for Kubernetes English controller", "tokens": [50964, 509, 393, 764, 309, 337, 23145, 3669, 10561, 51114], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 510, "seek": 151600, "start": 1531.0, "end": 1534.0, "text": " or even you can extend it to a service mesh", "tokens": [51114, 420, 754, 291, 393, 10101, 309, 281, 257, 2643, 17407, 51264], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 511, "seek": 151600, "start": 1534.0, "end": 1536.0, "text": " for your Kubernetes services.", "tokens": [51264, 337, 428, 23145, 3328, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 512, "seek": 151600, "start": 1536.0, "end": 1538.0, "text": " That's one of the advantages.", "tokens": [51364, 663, 311, 472, 295, 264, 14906, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 513, "seek": 151600, "start": 1538.0, "end": 1541.0, "text": " But these advantages also exist, of course.", "tokens": [51464, 583, 613, 14906, 611, 2514, 11, 295, 1164, 13, 51614], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 514, "seek": 151600, "start": 1541.0, "end": 1543.0, "text": " It is open source, too.", "tokens": [51614, 467, 307, 1269, 4009, 11, 886, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 515, "seek": 151600, "start": 1543.0, "end": 1544.0, "text": " Yeah.", "tokens": [51714, 865, 13, 51764], "temperature": 0.0, "avg_logprob": -0.14409118039267405, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.11873152107000351}, {"id": 516, "seek": 154400, "start": 1544.0, "end": 1546.0, "text": " I hope I could answer.", "tokens": [50364, 286, 1454, 286, 727, 1867, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 517, "seek": 154400, "start": 1546.0, "end": 1548.0, "text": " Sorry, it was a little bit hard to listen to.", "tokens": [50464, 4919, 11, 309, 390, 257, 707, 857, 1152, 281, 2140, 281, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 518, "seek": 154400, "start": 1548.0, "end": 1550.0, "text": " Okay.", "tokens": [50564, 1033, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 519, "seek": 154400, "start": 1550.0, "end": 1556.0, "text": " Could you please elaborate a little bit on the scalability of those plugins?", "tokens": [50664, 7497, 291, 1767, 20945, 257, 707, 857, 322, 264, 15664, 2310, 295, 729, 33759, 30, 50964], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 520, "seek": 154400, "start": 1556.0, "end": 1558.0, "text": " It would be nice.", "tokens": [50964, 467, 576, 312, 1481, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 521, "seek": 154400, "start": 1558.0, "end": 1561.0, "text": " You're worrying about how it's scalable, right?", "tokens": [51064, 509, 434, 18788, 466, 577, 309, 311, 38481, 11, 558, 30, 51214], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 522, "seek": 154400, "start": 1561.0, "end": 1564.0, "text": " How much it can carry?", "tokens": [51214, 1012, 709, 309, 393, 3985, 30, 51364], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 523, "seek": 154400, "start": 1564.0, "end": 1566.0, "text": " How much observations can be done?", "tokens": [51364, 1012, 709, 18163, 393, 312, 1096, 30, 51464], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 524, "seek": 154400, "start": 1566.0, "end": 1568.0, "text": " Good question.", "tokens": [51464, 2205, 1168, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 525, "seek": 154400, "start": 1568.0, "end": 1570.0, "text": " You can enable multiple plugins.", "tokens": [51564, 509, 393, 9528, 3866, 33759, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1625228480288857, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.05697416514158249}, {"id": 526, "seek": 157000, "start": 1570.0, "end": 1574.0, "text": " It's this up to you how many plugins you would like to use.", "tokens": [50364, 467, 311, 341, 493, 281, 291, 577, 867, 33759, 291, 576, 411, 281, 764, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14331444450046704, "compression_ratio": 1.6164383561643836, "no_speech_prob": 0.1102694496512413}, {"id": 527, "seek": 157000, "start": 1574.0, "end": 1579.0, "text": " And there should be some problems when it comes to millions,", "tokens": [50564, 400, 456, 820, 312, 512, 2740, 562, 309, 1487, 281, 6803, 11, 50814], "temperature": 0.0, "avg_logprob": -0.14331444450046704, "compression_ratio": 1.6164383561643836, "no_speech_prob": 0.1102694496512413}, {"id": 528, "seek": 157000, "start": 1579.0, "end": 1581.0, "text": " maybe billions of API calls.", "tokens": [50814, 1310, 17375, 295, 9362, 5498, 13, 50914], "temperature": 0.0, "avg_logprob": -0.14331444450046704, "compression_ratio": 1.6164383561643836, "no_speech_prob": 0.1102694496512413}, {"id": 529, "seek": 157000, "start": 1581.0, "end": 1584.0, "text": " That's why we have different deployment modes.", "tokens": [50914, 663, 311, 983, 321, 362, 819, 19317, 14068, 13, 51064], "temperature": 0.0, "avg_logprob": -0.14331444450046704, "compression_ratio": 1.6164383561643836, "no_speech_prob": 0.1102694496512413}, {"id": 530, "seek": 157000, "start": 1584.0, "end": 1588.0, "text": " For example, you can deploy API 6 as a standalone", "tokens": [51064, 1171, 1365, 11, 291, 393, 7274, 9362, 1386, 382, 257, 37454, 51264], "temperature": 0.0, "avg_logprob": -0.14331444450046704, "compression_ratio": 1.6164383561643836, "no_speech_prob": 0.1102694496512413}, {"id": 531, "seek": 157000, "start": 1588.0, "end": 1593.0, "text": " or maybe you can deploy with multiple API 6 instance one storage.", "tokens": [51264, 420, 1310, 291, 393, 7274, 365, 3866, 9362, 1386, 5197, 472, 6725, 13, 51514], "temperature": 0.0, "avg_logprob": -0.14331444450046704, "compression_ratio": 1.6164383561643836, "no_speech_prob": 0.1102694496512413}, {"id": 532, "seek": 157000, "start": 1593.0, "end": 1597.0, "text": " Or one API 6, different types of storage.", "tokens": [51514, 1610, 472, 9362, 1386, 11, 819, 3467, 295, 6725, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14331444450046704, "compression_ratio": 1.6164383561643836, "no_speech_prob": 0.1102694496512413}, {"id": 533, "seek": 159700, "start": 1597.0, "end": 1602.0, "text": " Because ITCD is compared to other relational database,", "tokens": [50364, 1436, 6783, 16508, 307, 5347, 281, 661, 38444, 8149, 11, 50614], "temperature": 0.0, "avg_logprob": -0.2414536022004627, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.012528419494628906}, {"id": 534, "seek": 159700, "start": 1602.0, "end": 1605.0, "text": " non-relational database, super fast to first data.", "tokens": [50614, 2107, 12, 4419, 1478, 8149, 11, 1687, 2370, 281, 700, 1412, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2414536022004627, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.012528419494628906}, {"id": 535, "seek": 159700, "start": 1605.0, "end": 1609.0, "text": " That's why it's also easy to deploy in many places.", "tokens": [50764, 663, 311, 983, 309, 311, 611, 1858, 281, 7274, 294, 867, 3190, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2414536022004627, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.012528419494628906}, {"id": 536, "seek": 159700, "start": 1609.0, "end": 1612.0, "text": " That's scalable without any issue.", "tokens": [50964, 663, 311, 38481, 1553, 604, 2734, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2414536022004627, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.012528419494628906}, {"id": 537, "seek": 159700, "start": 1612.0, "end": 1615.0, "text": " Yeah.", "tokens": [51114, 865, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2414536022004627, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.012528419494628906}, {"id": 538, "seek": 159700, "start": 1615.0, "end": 1618.0, "text": " Does it make sense?", "tokens": [51264, 4402, 309, 652, 2020, 30, 51414], "temperature": 0.0, "avg_logprob": -0.2414536022004627, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.012528419494628906}, {"id": 539, "seek": 159700, "start": 1618.0, "end": 1620.0, "text": " Yeah, just a quick question.", "tokens": [51414, 865, 11, 445, 257, 1702, 1168, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2414536022004627, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.012528419494628906}, {"id": 540, "seek": 159700, "start": 1620.0, "end": 1624.0, "text": " I saw there you had API 6 EngineX.", "tokens": [51514, 286, 1866, 456, 291, 632, 9362, 1386, 7659, 55, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2414536022004627, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.012528419494628906}, {"id": 541, "seek": 162400, "start": 1624.0, "end": 1628.0, "text": " Is EngineX the underlying API gateway?", "tokens": [50364, 1119, 7659, 55, 264, 14217, 9362, 28532, 30, 50564], "temperature": 0.0, "avg_logprob": -0.17263475708339526, "compression_ratio": 1.5125628140703518, "no_speech_prob": 0.06672512739896774}, {"id": 542, "seek": 162400, "start": 1628.0, "end": 1632.0, "text": " And API 6 sits on top of it and expands the capabilities of it.", "tokens": [50564, 400, 9362, 1386, 12696, 322, 1192, 295, 309, 293, 33706, 264, 10862, 295, 309, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17263475708339526, "compression_ratio": 1.5125628140703518, "no_speech_prob": 0.06672512739896774}, {"id": 543, "seek": 162400, "start": 1632.0, "end": 1635.0, "text": " Because EngineX is quite limited in that.", "tokens": [50764, 1436, 7659, 55, 307, 1596, 5567, 294, 300, 13, 50914], "temperature": 0.0, "avg_logprob": -0.17263475708339526, "compression_ratio": 1.5125628140703518, "no_speech_prob": 0.06672512739896774}, {"id": 544, "seek": 162400, "start": 1635.0, "end": 1636.0, "text": " Yeah, true.", "tokens": [50914, 865, 11, 2074, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17263475708339526, "compression_ratio": 1.5125628140703518, "no_speech_prob": 0.06672512739896774}, {"id": 545, "seek": 162400, "start": 1636.0, "end": 1640.0, "text": " EngineX is the root of the API 6.", "tokens": [50964, 7659, 55, 307, 264, 5593, 295, 264, 9362, 1386, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17263475708339526, "compression_ratio": 1.5125628140703518, "no_speech_prob": 0.06672512739896774}, {"id": 546, "seek": 162400, "start": 1640.0, "end": 1643.0, "text": " It's built on the top of EngineX.", "tokens": [51164, 467, 311, 3094, 322, 264, 1192, 295, 7659, 55, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17263475708339526, "compression_ratio": 1.5125628140703518, "no_speech_prob": 0.06672512739896774}, {"id": 547, "seek": 162400, "start": 1643.0, "end": 1646.0, "text": " But it provides additional features, right?", "tokens": [51314, 583, 309, 6417, 4497, 4122, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.17263475708339526, "compression_ratio": 1.5125628140703518, "no_speech_prob": 0.06672512739896774}, {"id": 548, "seek": 162400, "start": 1646.0, "end": 1650.0, "text": " Yeah.", "tokens": [51464, 865, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17263475708339526, "compression_ratio": 1.5125628140703518, "no_speech_prob": 0.06672512739896774}, {"id": 549, "seek": 162400, "start": 1650.0, "end": 1652.0, "text": " We have one more question.", "tokens": [51664, 492, 362, 472, 544, 1168, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17263475708339526, "compression_ratio": 1.5125628140703518, "no_speech_prob": 0.06672512739896774}, {"id": 550, "seek": 165200, "start": 1652.0, "end": 1654.0, "text": " I'll try to make it short.", "tokens": [50364, 286, 603, 853, 281, 652, 309, 2099, 13, 50464], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 551, "seek": 165200, "start": 1654.0, "end": 1659.0, "text": " Can API 6 work with GraphQL APIs?", "tokens": [50464, 1664, 9362, 1386, 589, 365, 21884, 13695, 21445, 30, 50714], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 552, "seek": 165200, "start": 1659.0, "end": 1660.0, "text": " Yes.", "tokens": [50714, 1079, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 553, "seek": 165200, "start": 1660.0, "end": 1663.0, "text": " GraphQL, I think nowadays became very popular also.", "tokens": [50764, 21884, 13695, 11, 286, 519, 13434, 3062, 588, 3743, 611, 13, 50914], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 554, "seek": 165200, "start": 1663.0, "end": 1664.0, "text": " Sorry.", "tokens": [50914, 4919, 13, 50964], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 555, "seek": 165200, "start": 1664.0, "end": 1667.0, "text": " I think Nikola also had the talk about tracing, right?", "tokens": [50964, 286, 519, 13969, 4711, 611, 632, 264, 751, 466, 25262, 11, 558, 30, 51114], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 556, "seek": 165200, "start": 1667.0, "end": 1671.0, "text": " He has some of the talks about this GraphQL.", "tokens": [51114, 634, 575, 512, 295, 264, 6686, 466, 341, 21884, 13695, 13, 51314], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 557, "seek": 165200, "start": 1671.0, "end": 1675.0, "text": " We are improving, we're contributing more now,", "tokens": [51314, 492, 366, 11470, 11, 321, 434, 19270, 544, 586, 11, 51514], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 558, "seek": 165200, "start": 1675.0, "end": 1677.0, "text": " massively on the GraphQL.", "tokens": [51514, 29379, 322, 264, 21884, 13695, 13, 51614], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 559, "seek": 165200, "start": 1677.0, "end": 1680.0, "text": " My answer is it's possible, yes.", "tokens": [51614, 1222, 1867, 307, 309, 311, 1944, 11, 2086, 13, 51764], "temperature": 0.0, "avg_logprob": -0.22393252548662204, "compression_ratio": 1.5, "no_speech_prob": 0.1333218514919281}, {"id": 560, "seek": 168000, "start": 1680.0, "end": 1683.0, "text": " You can try it out.", "tokens": [50364, 509, 393, 853, 309, 484, 13, 50514], "temperature": 0.0, "avg_logprob": -0.15629809942000952, "compression_ratio": 1.1222222222222222, "no_speech_prob": 0.03982812538743019}, {"id": 561, "seek": 168000, "start": 1683.0, "end": 1686.0, "text": " Any other questions?", "tokens": [50514, 2639, 661, 1651, 30, 50664], "temperature": 0.0, "avg_logprob": -0.15629809942000952, "compression_ratio": 1.1222222222222222, "no_speech_prob": 0.03982812538743019}, {"id": 562, "seek": 168000, "start": 1686.0, "end": 1687.0, "text": " OK.", "tokens": [50664, 2264, 13, 50714], "temperature": 0.0, "avg_logprob": -0.15629809942000952, "compression_ratio": 1.1222222222222222, "no_speech_prob": 0.03982812538743019}, {"id": 563, "seek": 168000, "start": 1687.0, "end": 1689.0, "text": " Thanks a lot, everyone.", "tokens": [50714, 2561, 257, 688, 11, 1518, 13, 50814], "temperature": 0.0, "avg_logprob": -0.15629809942000952, "compression_ratio": 1.1222222222222222, "no_speech_prob": 0.03982812538743019}, {"id": 564, "seek": 168000, "start": 1689.0, "end": 1690.0, "text": " Thank you for coming.", "tokens": [50814, 1044, 291, 337, 1348, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15629809942000952, "compression_ratio": 1.1222222222222222, "no_speech_prob": 0.03982812538743019}, {"id": 565, "seek": 168000, "start": 1690.0, "end": 1691.0, "text": " Thank you.", "tokens": [50864, 1044, 291, 13, 50914], "temperature": 0.0, "avg_logprob": -0.15629809942000952, "compression_ratio": 1.1222222222222222, "no_speech_prob": 0.03982812538743019}], "language": "en"}