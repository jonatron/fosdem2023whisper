{"text": " All right. Good afternoon, everyone. Before I get started, how many of you attended the session about service mesh this afternoon? Sorry about that. If you're fed up with me, you have to stay with me for another session. I will repeat some parts of it to introduce the topic. But otherwise, I'm sorry about that. So welcome to the session, Golden Signals with Cillium and Grafana. My name is Raymond De Jong. I'm field CTO for EMEA at Isovalent. Isovalent is the company which originated Cillium. And today I'm going to talk about Grafana and how Cillium enables you to get golden signals out of the box. Introduction about technology, a little bit about EBPF and Cillium, then about observability challenges and how we can tackle those challenges using observability. A bit on monitoring data operations and the default dashboards we provide. And then hopefully the demo gods are with me for a small demo to actually see how we get layer seven metrics. And we can see return codes and monitor application, response times, et cetera. So to start this topic, I want to introduce Cillium and EBPF. How many of you know about EBPF? Quite a lot, awesome. How many of you know about Cillium and are using Cillium? Cool. Great. So Isovalent is the company behind each Cillium and EBPF. We maintain it with the community. And to start with, EBPF is explaining what EBPF is and how it works. So we like to say what JavaScript is to the browser, EBPF is to the kernel. What we mean by that is that we make it extensible in a dynamic way. So that means we're not changing the kernel, but at kernel speed we can run programs based on kernel events. And for the context of this session, what's important is that considering metrics, considering getting useful information from your applications, what we're doing here is whenever a process opens to Sokort or a packet gets sent on the network device, on the node, we can expose metrics or we can export those metrics using EBPF. And we can use tools like Rafaana to display it in a good way so you can make, you can do data operations or you can see how your application or cluster is performing. Cillium runs on EBPF. The good thing about Cillium is you don't need to be an EBPF engineer to run an operate Cillium. You just set certain configuration options and EBPF programs will be mounted on the nodes and will run when they need to run. And Cillium on the high level provides a number of capabilities, networking capabilities, observability capabilities, also service mesh, and using catricon solution we can also use runtime visibility and observability security based on processes such as opening files, process execution, et cetera, et cetera. Today we'll focus about the observability part. So besides networking we can get rich visibility of metrics on your cluster. As you may know Google uses on data plane V2 actually under the hood Cillium, Microsoft has moved Azure default AKS clusters to Cillium so all the cloud providers see that Cillium is a powerful technology to run clusters at scale and to get useful metrics running them. So let's start with common challenges we see. One of the main challenges if we talk about performance of your application or performance of your clusters at scale is that you run into this issue of the finger pointing problem. What I mean by that is that network connectivity is layered and when you run into issues you need to especially at scale you need to be easily aware where a possible problem could exist and it can be in multiple layers and if you look at the OZ layer obviously it can be at the data link layer, the network layer, the transport layer or in the application layer. So the goal of Cillium with Kavana is to give you the tools to quickly inspect what's going on and to be more efficient in troubleshooting your cluster and or applications. Another common issue especially at scale is obviously the signal to noise problem. You may run in the cloud you get data from your notes you see IP addresses communicating with each other but IP addresses by itself mean nothing in Kubernetes clusters. They come, they go and at scale it's impossible to track and trace what's going on with service to service communication in your applications. Also where our existing mechanisms falling short so first of all network devices think about centralized monitoring or firewall solutions, think about Splunk. They are great to get alerts, to get dashboards but again at scale they can be very costly or they can be a bottleneck. Also these devices don't have awareness of the identities of your applications running on your Kubernetes clusters. Cloud provider network logs are nice for note to note communication but don't provide identity as well. You can monitor the host, you can see Linux host statistics but that gives you only visibility on the note level and again a Linux note doesn't have any awareness of the identities of the services running in your Kubernetes cluster. You may want to try to modify application code and this applies a bit to the service mesh session. You may want to install libraries which gives you visibility of the application but then you don't have visibility on the networking layer. Service mesh, main goal of service mesh is obviously visibility of the network and trend communication to get metrics out of that but that with the sidecar based implementation comes with a footprint and with induced latency plus you have operational complexity maintaining your service mesh solution on top of your Kubernetes clusters. So this is where Cilium comes around the corner is that we provide identity aware based observability and security. What that means is based on the labels you set on your workloads, we create unique identities and we're able to attach that identity in the data plane using eBPF and using that identity we can do things with that so we can secure the connectivity in this example a front end to a back end is allowed to communicate based on the network policies we set and the identities we are aware of and these identities are cluster wide property but in terms of observability this also means that we can use this identity to get rich metrics and data for that identity and you can monitor it effectively. This means that you're not looking anymore at IP addresses, you're looking at identities so the whole set of workloads the service to service communication for a front end to a back end. Hubble is our observability solution built on top of Cilium, how it works is that Cilium runs as a demon set on your cluster nodes as an agent and Hubble can retrieve data from those agents through a CLI or UI and we can export metrics based on your workloads. So there are three parts, first of all the Hubble UI gives a service dependency map so on a namespace level you can see what's deployed, what is communicating with each other, what kind of protocols they're using, what's coming between namespaces so you would see for example if there's inter namespace communication you can identify the source namespace, if you use cluster mesh you can even identify the source cluster, you can also identify egress traffic and ingress traffic on a namespace level. The Hubble CLI is more a power user tool to give you detailed flow, you can export it to JSON, you can do a lot of filtering based on labels. Hubble metrics is the part where mostly the topic for today is where you export metrics and you use Grafana for example to observe the performance of your cluster application. This is all fueled through EBPF so again think about a network device sending a packet, that's a kernel event, EBPF program gets attached to it, gets the metrics and it's done. This is a small screenshot of the CLI so this gives you flow visibility using Hubble observe commands, you can follow for example based on the label in this case X-Wing so we're following all the workloads labeled with X-Wing so again no IP addresses just labels. In purple it's highlighted these IDs we use so again each unique set of labels gets a unique cluster wide ID and based on those IDs we can track based on labels what communication is going on and there's a lot of metadata you can filter on things like headers, things like ports, things like protocols, obviously labels in Q&A spot names, services, worker nodes, DNS, we also have Cilium network policies which allow you to filter and observe two FQDN rules meaning we can inspect queries to external domains and we can filter based on that and obviously Cilium related identity such as world, ingress, egress, host and that kind of stuff. Policy verdict matches, things like dropped, allowed and stuff. This is the Hubble UI surface map like I said before this gives you a namespace level view in this case we have a jobs app and I'm using this app as well in the demo I'm showing a bit later so here you're looking at a namespace level view where you can see all the surface to surface communication of your application running in that namespace. In this case it's only intra namespace communication and you can see for example that the recruiter is talking to core API, the core API is talking to Elasticsearch, we have a zookeeper component, we identify Kafka, also identifying Kafka protocols so there are a number of protocols we can inspect and see and we also see layer 7 information so in this case HTTP calls to a specific URI or URL with specific method and return calls and this is triggered through just simple construct as a Syllium Network Policy. If you just allow let's say internamespace traffic and you are accepting HTTP that already triggers this visibility for you to see. Now using this data we can also export metrics to Grafana so we are working with Grafana a lot more lately that means that we are building a lot of more useful dashboards and also integrating with things like Tempo for getting transparent tracing in Grafana, all powered through Syllium and EBPF. This allows us to not only see on the network level metrics on performance on the node but also for surface to surface communication to provide golden signals things like HTTP request rate, latency, response codes and error codes which would as an application engineer would allow you to quickly see which component of the application is not responding as it should. But also detecting transient network layers so this will be more network related we may see retransmissions, we can see bytes sent and received and we can indicate things like boundary time to indicate a network layer problem. So maybe in a data center you have a specific rack switch or top of rack switch not performing as it should so nodes connected to that switch will have improved or will have reduced performance and you would see latency increasing. Now with the latest dashboards we also able to see programmatic API request using transparent tracing. This goes to the integration with Grafana. So at the moment your application need to be able to support it so you need to be able to inject traces. But we are working out of the box getting also this support and be able to help by help support HTTP traces as such. And then you get this exemplar so I am pointing at a small exemplar here after which you can inspect this with Tempo and you can see a span of a specific request and see where the problem may reside. A bit more on monitoring so this is more day 2 ops. I want to highlight that if you run Cillian and you are also using Grafana make sure that you install the agent, Hubble and operator metrics plugins. These are out of the box plugins we provide through the Grafana marketplace you can download. This gives you visibility in the performance of your cluster. So first of all agent metrics everything on the node level how the node is performing, how many throughput they are processing, how many memory the BPF is using, all this related stuff. Hubble metrics gives you the visibility across your cluster in terms of application, layer 7 return calls, policy verdicts so allows versus drops so you can monitor on the cluster level the performance of your applications. And in some cases you run an operator so you may want to track the number of identities, how the cluster in general is behaving, API responses and such. And finally what we released just a few days ago thanks to Raphael who is also here is the Cillian policy verdict metrics dashboard which gives you the capability to get meaningful graphs if you have workloads actually hitting network policies you set. What I mean by that is that when we work with customers with Cillian is they want to go to this micro segmentation zero trust model and you can use obviously Hubble to monitor service-to-service communication and to see if traffic is allowed and denied. But this dashboard also is a very useful tool to confirm if you have either ingress or egress policies which are matching with your traffic. So in this case we see green graphs which means that on ingress and egress we have matching traffic. The purple represents DNS matching traffic but if there's some yellow traffic that's either allow all match traffic which is too broadly which should trigger you to get even better network policies to make sure that kind of flows are actually related to a network policy to ensure that both ingress and egress traffic is secured as such. If you do so all the graphs will turn green and you know and you can confirm for that given namespace that you have secured it. Alright I've prepared a little demo. This runs this tenant jobs application I mentioned before. I'm running this on Kynes so just a simple Kynes cluster on my laptop. I'm showing here the components of my application so it's you know a number of workloads I've shown before on the screen shot. To help me through this demo I've created a little script and what this does it only updates a helm chart for this application so it makes my workflow a lot easier. I don't have to enter commands but we should see some things changing in a Grafana dashboard. Before I start this let me highlight the metrics so I need to log in. So I've installed Grafana, I've installed Tempo, I've installed Prometheus and configured Silium to export those metrics. So this is currently the performance of my application running on my Kynes cluster on my laptop. So as you can see we have 100% success rate, we have incoming 100% and we also have good Grafana information for the performance of the application. Okay so let me start with starting the script. Yes so I mentioned before that the Hubble metrics are available as soon as you configure some kind of layer 7 Silium network policy because that triggers the collection of those metrics for layer 7 and I'm showing this but I will show this a bit better in a different window. So what I'm going to do now is I want to increase the request volume so I'm configuring the crawler component to get more requests in my application. As you can see it's redeploying the crawler component. So this is something we should see in the Grafana dashboard. While this is redeploying I can show the helm chart I'm using. You need to be a bit patient with me because it takes one minute before the graphics, the Grafana dashboards are updated and you can actually see the impact of this new version of the application. So typically you configure Silium through a helm values file so in this case on the operator component I've enabled metrics and Prometheus. On the Hubble side I've configured Hubble relay to gather the metrics and also Prometheus and metrics. So in this part it's very interesting because if you want to have layer 7 visibility you need to have specific metrics being enabled. This will be documented in the Silium IO website once we have the new release ready. So as you can see we are matching HTTP V2, we have enabled exemplars, we are looking for labels in terms of context, source IP, source namespace etc. So these are important sets of labels you need to set and on the Prometheus side we've enabled it to gather the graphs. The Silium network policy I mentioned before this is just a simple example. We allow everything within a namespace. We have enabled DNS visibility so we're inspecting all DNS traffic to cube DNS that allows us to get visibility of the DNS queries. We've enabled ingress and egress for the purpose of the demo so we can also see that traffic. And what's important is that we have an empty or open rule HTTP which allows us to see all traffic, it allows all traffic, but that triggers the collection of metrics. Alright so on the demo side so it has deployed a new version of my application looking at my metrics. I can see incoming request volume increasing so you see already an increase of volume. We also see requests by source and response codes increasing so still 200, always fine, always good, just an increase of request per seconds. And also on the incoming side. Okay all good. Okay let's now deploy a new configuration of our app and this app has an error. So let's see what we can see there. I can redeploying the core API components and now we should be able to see the error rate increase as a result of core API configuration changing. So this will take one minute. Here I can select the destination workload so I can switch between core API or the loader component to see how the traffic for that destination is matching and how it's performing. Let's give it a few seconds to actually show. What I'm looking for is the incoming request to access rate. Obviously this application version has an error so the success rate will be lower than before. It's running. It's always a bit, takes a bit longer than I wanted. There we have it. In the meantime I'll already start the next step so I don't have you waiting. So here you see that the success rate is decreasing because of this faulty version of my application so I can really see there's something wrong with my application and as application developer or owning this namespace I should now be able to investigate what's going on. This also means that here on the incoming request to source and response code I would see the resumes components showing 500 and 503 error return codes which triggers me to check that component and communication between those components. Also on the destination site. All right. So now I've introduced a new version and what this does is changing the request duration. So again a new version of the application and let's see how we can monitor this performance of the application in Grafana. So let's check the request duration increase as a result of core API configuration changing. Okay. So let's use here. So I'm monitoring HTTP request duration by source and destination. So if the demo works well we see an increase there. Okay. It takes a bit too long. I'm comfortable with but it should be there any minute. It should appear any moment. Let me just... In the meantime I will deploy a new version of the application which also introduces tracing. So again for tracing to be supported you at this moment your application needs to support that. So in this case I'll deploy a new version of this application to support tracing. And this is using open telemetry. So let's deploy that in the meantime. That's deploying. In the meantime I can check how the request duration is doing. Okay. This part is not working yet but we should see a request duration increase. Oh God yeah thanks. That doesn't help. I clicked on something. Ah yes thank you so much. Yeah here you can see the request duration increasing. And I just deployed a new version of my application which supports tracing using open telemetry. And then you already can see that I have these exemplars appearing. So I now can not only inspect HTTP request duration but I can also inspect specific traces and exemplars. So if you click on this little box you get this window. You can get valuable information about this trace point. And then you can query it with track tempo. Yep let's leave this side. So here you can see a specific trace ID and you can see a node graph. So this is also nice. You can see between nodes what's going on and you see highlighted in red here what has a high latency as such. And here we can see that in this specific API call there is an error. So a post call and it has some events exception, random error. So something is wrong with my application. So this enables me as an application owner to troubleshoot my application effectively. So this concludes the demo. Let me quickly move to here. All right, so if you want to know more how to configure Cilium to enable metrics, how to configure Cilium with the right values for layer 7 monitoring, I recommend to read the documentation on Cilium.io. If you're using Cilium or planning to use Cilium and you have questions go to our Slack channel. We're happy to help you there. The community is out there and very helpful answering questions. If you want to know more about eBPF go to eBPF.io. We also have released or close to release a lab with this kind of dashboards as well. So feel free to check them out at isovenom.com. And if you want to know more about isovenom.com or you may want to contribute, we also have open positions for engineering as such. So if you want to know more, please check us out. I'm happy to take questions. Any questions? Hello. Thank you for your talk. Is it possible in the service graph of the Hubbell UI to show transitive dependencies of services with the tracing enabled? So with Hubbell UI, the open source version, you will see the service connectivity only. So that related information is not integrated in Hubbell as such. So you would switch between Hubbell and Grafana to get that information. On the enterprise, we have built in dashboards for getting that specific areas of monitoring. So let's say application or node performance or cluster-wide performance. We have some dashboards which should quickly highlight performance issues there. Okay. Thank you. Any other questions? Hello. Did you measure the impact of metrics, recollect of metrics on network performance? Yeah. We do have some performance-related reports on sodium.io. So yes, it comes with a price. Using EBPF, we keep it as low as possible. It's a very hard question to answer because it will depend on which flags you configure. So if you have full layer 7 visibility across all workloads in your cluster, of course it will have some performance impact for sure. Yes. Using EBPF, we keep it as low as possible. But yeah, it's a multi-dimensional question. It depends on the amount of traffic, the amount of applications, how big your cluster is, et cetera. So we have some performance reports you can check. So that's 500 nodes, 1,000 network policies, helpful, enabled, and you get some feel of how memory consumption and processing is with Selium. So feel free to check them out on the selium.io website. But in practice, it's a multi-dimensional story. Welcome. Any other questions in the background? Hi. Thanks for the talk. A couple of questions about the integration of Selium on AQS and GKE. Is there anything specific regarding those implementations or are all the tools that work natively on these kind of clusters? And second questions regarding above UI, is it possible to see intern namespace traffic flows or is it limited to intranamespace? OK. Good question. So to answer the second question first, yes, you can see that. So if there is communication between, from a different namespace in regards to your namespace and monitoring, you will see that. You will see those labels, and you will see the workloads, even across clusters if you enable cluster mesh. So yes, that works out of the box. On the cloud provider side, so if you run AQS with Azure CNI Powered by Selium, you have a limited set of metrics which are enabled. And that's obviously from support reasons for Microsoft to support that solution out of the box. However, you can also choose to bring your own CNI with AQS, and that also applies to GKE and AQS, to manage Selium yourself. Right? So then you have the freedom to configure the flags I just shown and to configure Selium as such. Keep in mind that you're responsible obviously of monitoring, managing Selium, and the cloud provider will manage the cluster. Any other question? Cool. We have to cut it in. Oh, yes. Sorry. OK. Thank you very much. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.32, "text": " All right. Good afternoon, everyone. Before I get started, how many of you attended the", "tokens": [1057, 558, 13, 2205, 6499, 11, 1518, 13, 4546, 286, 483, 1409, 11, 577, 867, 295, 291, 15990, 264], "temperature": 0.0, "avg_logprob": -0.18499632315202194, "compression_ratio": 1.6238532110091743, "no_speech_prob": 0.1384126842021942}, {"id": 1, "seek": 0, "start": 10.32, "end": 15.68, "text": " session about service mesh this afternoon? Sorry about that. If you're fed up with me,", "tokens": [5481, 466, 2643, 17407, 341, 6499, 30, 4919, 466, 300, 13, 759, 291, 434, 4636, 493, 365, 385, 11], "temperature": 0.0, "avg_logprob": -0.18499632315202194, "compression_ratio": 1.6238532110091743, "no_speech_prob": 0.1384126842021942}, {"id": 2, "seek": 0, "start": 15.68, "end": 22.28, "text": " you have to stay with me for another session. I will repeat some parts of it to introduce", "tokens": [291, 362, 281, 1754, 365, 385, 337, 1071, 5481, 13, 286, 486, 7149, 512, 3166, 295, 309, 281, 5366], "temperature": 0.0, "avg_logprob": -0.18499632315202194, "compression_ratio": 1.6238532110091743, "no_speech_prob": 0.1384126842021942}, {"id": 3, "seek": 0, "start": 22.28, "end": 28.16, "text": " the topic. But otherwise, I'm sorry about that. So welcome to the session, Golden Signals", "tokens": [264, 4829, 13, 583, 5911, 11, 286, 478, 2597, 466, 300, 13, 407, 2928, 281, 264, 5481, 11, 13410, 13515, 1124], "temperature": 0.0, "avg_logprob": -0.18499632315202194, "compression_ratio": 1.6238532110091743, "no_speech_prob": 0.1384126842021942}, {"id": 4, "seek": 2816, "start": 28.16, "end": 34.56, "text": " with Cillium and Grafana. My name is Raymond De Jong. I'm field CTO for EMEA at Isovalent.", "tokens": [365, 383, 373, 2197, 293, 8985, 69, 2095, 13, 1222, 1315, 307, 42813, 1346, 19589, 13, 286, 478, 2519, 383, 15427, 337, 462, 15454, 32, 412, 286, 539, 3337, 317, 13], "temperature": 0.0, "avg_logprob": -0.19213770894170965, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00018186261877417564}, {"id": 5, "seek": 2816, "start": 34.56, "end": 39.28, "text": " Isovalent is the company which originated Cillium. And today I'm going to talk about", "tokens": [286, 539, 3337, 317, 307, 264, 2237, 597, 31129, 383, 373, 2197, 13, 400, 965, 286, 478, 516, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.19213770894170965, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00018186261877417564}, {"id": 6, "seek": 2816, "start": 39.28, "end": 45.519999999999996, "text": " Grafana and how Cillium enables you to get golden signals out of the box. Introduction", "tokens": [8985, 69, 2095, 293, 577, 383, 373, 2197, 17077, 291, 281, 483, 9729, 12354, 484, 295, 264, 2424, 13, 27193, 882], "temperature": 0.0, "avg_logprob": -0.19213770894170965, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00018186261877417564}, {"id": 7, "seek": 2816, "start": 45.519999999999996, "end": 51.92, "text": " about technology, a little bit about EBPF and Cillium, then about observability challenges", "tokens": [466, 2899, 11, 257, 707, 857, 466, 50148, 47, 37, 293, 383, 373, 2197, 11, 550, 466, 9951, 2310, 4759], "temperature": 0.0, "avg_logprob": -0.19213770894170965, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00018186261877417564}, {"id": 8, "seek": 5192, "start": 51.92, "end": 59.08, "text": " and how we can tackle those challenges using observability. A bit on monitoring data operations", "tokens": [293, 577, 321, 393, 14896, 729, 4759, 1228, 9951, 2310, 13, 316, 857, 322, 11028, 1412, 7705], "temperature": 0.0, "avg_logprob": -0.16190328942724022, "compression_ratio": 1.6053811659192825, "no_speech_prob": 6.225655670277774e-05}, {"id": 9, "seek": 5192, "start": 59.08, "end": 63.88, "text": " and the default dashboards we provide. And then hopefully the demo gods are with me for", "tokens": [293, 264, 7576, 8240, 17228, 321, 2893, 13, 400, 550, 4696, 264, 10723, 14049, 366, 365, 385, 337], "temperature": 0.0, "avg_logprob": -0.16190328942724022, "compression_ratio": 1.6053811659192825, "no_speech_prob": 6.225655670277774e-05}, {"id": 10, "seek": 5192, "start": 63.88, "end": 70.28, "text": " a small demo to actually see how we get layer seven metrics. And we can see return codes", "tokens": [257, 1359, 10723, 281, 767, 536, 577, 321, 483, 4583, 3407, 16367, 13, 400, 321, 393, 536, 2736, 14211], "temperature": 0.0, "avg_logprob": -0.16190328942724022, "compression_ratio": 1.6053811659192825, "no_speech_prob": 6.225655670277774e-05}, {"id": 11, "seek": 5192, "start": 70.28, "end": 79.44, "text": " and monitor application, response times, et cetera. So to start this topic, I want to", "tokens": [293, 6002, 3861, 11, 4134, 1413, 11, 1030, 11458, 13, 407, 281, 722, 341, 4829, 11, 286, 528, 281], "temperature": 0.0, "avg_logprob": -0.16190328942724022, "compression_ratio": 1.6053811659192825, "no_speech_prob": 6.225655670277774e-05}, {"id": 12, "seek": 7944, "start": 79.44, "end": 85.67999999999999, "text": " introduce Cillium and EBPF. How many of you know about EBPF? Quite a lot, awesome. How", "tokens": [5366, 383, 373, 2197, 293, 50148, 47, 37, 13, 1012, 867, 295, 291, 458, 466, 50148, 47, 37, 30, 20464, 257, 688, 11, 3476, 13, 1012], "temperature": 0.0, "avg_logprob": -0.10465893922028718, "compression_ratio": 1.5987654320987654, "no_speech_prob": 5.9689580666599795e-05}, {"id": 13, "seek": 7944, "start": 85.67999999999999, "end": 96.92, "text": " many of you know about Cillium and are using Cillium? Cool. Great. So Isovalent is the", "tokens": [867, 295, 291, 458, 466, 383, 373, 2197, 293, 366, 1228, 383, 373, 2197, 30, 8561, 13, 3769, 13, 407, 286, 539, 3337, 317, 307, 264], "temperature": 0.0, "avg_logprob": -0.10465893922028718, "compression_ratio": 1.5987654320987654, "no_speech_prob": 5.9689580666599795e-05}, {"id": 14, "seek": 7944, "start": 96.92, "end": 102.72, "text": " company behind each Cillium and EBPF. We maintain it with the community. And to start", "tokens": [2237, 2261, 1184, 383, 373, 2197, 293, 50148, 47, 37, 13, 492, 6909, 309, 365, 264, 1768, 13, 400, 281, 722], "temperature": 0.0, "avg_logprob": -0.10465893922028718, "compression_ratio": 1.5987654320987654, "no_speech_prob": 5.9689580666599795e-05}, {"id": 15, "seek": 10272, "start": 102.72, "end": 110.56, "text": " with, EBPF is explaining what EBPF is and how it works. So we like to say what JavaScript", "tokens": [365, 11, 50148, 47, 37, 307, 13468, 437, 50148, 47, 37, 307, 293, 577, 309, 1985, 13, 407, 321, 411, 281, 584, 437, 15778], "temperature": 0.0, "avg_logprob": -0.09848352354400013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 5.930243423790671e-05}, {"id": 16, "seek": 10272, "start": 110.56, "end": 115.03999999999999, "text": " is to the browser, EBPF is to the kernel. What we mean by that is that we make it extensible", "tokens": [307, 281, 264, 11185, 11, 50148, 47, 37, 307, 281, 264, 28256, 13, 708, 321, 914, 538, 300, 307, 300, 321, 652, 309, 1279, 30633], "temperature": 0.0, "avg_logprob": -0.09848352354400013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 5.930243423790671e-05}, {"id": 17, "seek": 10272, "start": 115.03999999999999, "end": 120.2, "text": " in a dynamic way. So that means we're not changing the kernel, but at kernel speed we", "tokens": [294, 257, 8546, 636, 13, 407, 300, 1355, 321, 434, 406, 4473, 264, 28256, 11, 457, 412, 28256, 3073, 321], "temperature": 0.0, "avg_logprob": -0.09848352354400013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 5.930243423790671e-05}, {"id": 18, "seek": 10272, "start": 120.2, "end": 127.4, "text": " can run programs based on kernel events. And for the context of this session, what's important", "tokens": [393, 1190, 4268, 2361, 322, 28256, 3931, 13, 400, 337, 264, 4319, 295, 341, 5481, 11, 437, 311, 1021], "temperature": 0.0, "avg_logprob": -0.09848352354400013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 5.930243423790671e-05}, {"id": 19, "seek": 12740, "start": 127.4, "end": 133.28, "text": " is that considering metrics, considering getting useful information from your applications,", "tokens": [307, 300, 8079, 16367, 11, 8079, 1242, 4420, 1589, 490, 428, 5821, 11], "temperature": 0.0, "avg_logprob": -0.21826145566742997, "compression_ratio": 1.6267281105990783, "no_speech_prob": 8.620308653917164e-05}, {"id": 20, "seek": 12740, "start": 133.28, "end": 139.08, "text": " what we're doing here is whenever a process opens to Sokort or a packet gets sent on the", "tokens": [437, 321, 434, 884, 510, 307, 5699, 257, 1399, 9870, 281, 407, 74, 477, 420, 257, 20300, 2170, 2279, 322, 264], "temperature": 0.0, "avg_logprob": -0.21826145566742997, "compression_ratio": 1.6267281105990783, "no_speech_prob": 8.620308653917164e-05}, {"id": 21, "seek": 12740, "start": 139.08, "end": 144.32, "text": " network device, on the node, we can expose metrics or we can export those metrics using", "tokens": [3209, 4302, 11, 322, 264, 9984, 11, 321, 393, 19219, 16367, 420, 321, 393, 10725, 729, 16367, 1228], "temperature": 0.0, "avg_logprob": -0.21826145566742997, "compression_ratio": 1.6267281105990783, "no_speech_prob": 8.620308653917164e-05}, {"id": 22, "seek": 12740, "start": 144.32, "end": 152.68, "text": " EBPF. And we can use tools like Rafaana to display it in a good way so you can make,", "tokens": [50148, 47, 37, 13, 400, 321, 393, 764, 3873, 411, 497, 19846, 2095, 281, 4674, 309, 294, 257, 665, 636, 370, 291, 393, 652, 11], "temperature": 0.0, "avg_logprob": -0.21826145566742997, "compression_ratio": 1.6267281105990783, "no_speech_prob": 8.620308653917164e-05}, {"id": 23, "seek": 15268, "start": 152.68, "end": 159.76000000000002, "text": " you can do data operations or you can see how your application or cluster is performing.", "tokens": [291, 393, 360, 1412, 7705, 420, 291, 393, 536, 577, 428, 3861, 420, 13630, 307, 10205, 13], "temperature": 0.0, "avg_logprob": -0.09166722496350606, "compression_ratio": 1.6839622641509433, "no_speech_prob": 3.2619936973787844e-05}, {"id": 24, "seek": 15268, "start": 159.76000000000002, "end": 164.52, "text": " Cillium runs on EBPF. The good thing about Cillium is you don't need to be an EBPF engineer", "tokens": [383, 373, 2197, 6676, 322, 50148, 47, 37, 13, 440, 665, 551, 466, 383, 373, 2197, 307, 291, 500, 380, 643, 281, 312, 364, 50148, 47, 37, 11403], "temperature": 0.0, "avg_logprob": -0.09166722496350606, "compression_ratio": 1.6839622641509433, "no_speech_prob": 3.2619936973787844e-05}, {"id": 25, "seek": 15268, "start": 164.52, "end": 171.88, "text": " to run an operate Cillium. You just set certain configuration options and EBPF programs will", "tokens": [281, 1190, 364, 9651, 383, 373, 2197, 13, 509, 445, 992, 1629, 11694, 3956, 293, 50148, 47, 37, 4268, 486], "temperature": 0.0, "avg_logprob": -0.09166722496350606, "compression_ratio": 1.6839622641509433, "no_speech_prob": 3.2619936973787844e-05}, {"id": 26, "seek": 15268, "start": 171.88, "end": 178.24, "text": " be mounted on the nodes and will run when they need to run. And Cillium on the high", "tokens": [312, 19138, 322, 264, 13891, 293, 486, 1190, 562, 436, 643, 281, 1190, 13, 400, 383, 373, 2197, 322, 264, 1090], "temperature": 0.0, "avg_logprob": -0.09166722496350606, "compression_ratio": 1.6839622641509433, "no_speech_prob": 3.2619936973787844e-05}, {"id": 27, "seek": 17824, "start": 178.24, "end": 184.60000000000002, "text": " level provides a number of capabilities, networking capabilities, observability capabilities,", "tokens": [1496, 6417, 257, 1230, 295, 10862, 11, 17985, 10862, 11, 9951, 2310, 10862, 11], "temperature": 0.0, "avg_logprob": -0.22274966179570066, "compression_ratio": 1.8725490196078431, "no_speech_prob": 4.1126037103822455e-05}, {"id": 28, "seek": 17824, "start": 184.60000000000002, "end": 191.36, "text": " also service mesh, and using catricon solution we can also use runtime visibility and observability", "tokens": [611, 2643, 17407, 11, 293, 1228, 3857, 1341, 266, 3827, 321, 393, 611, 764, 34474, 19883, 293, 9951, 2310], "temperature": 0.0, "avg_logprob": -0.22274966179570066, "compression_ratio": 1.8725490196078431, "no_speech_prob": 4.1126037103822455e-05}, {"id": 29, "seek": 17824, "start": 191.36, "end": 199.52, "text": " security based on processes such as opening files, process execution, et cetera, et cetera.", "tokens": [3825, 2361, 322, 7555, 1270, 382, 5193, 7098, 11, 1399, 15058, 11, 1030, 11458, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.22274966179570066, "compression_ratio": 1.8725490196078431, "no_speech_prob": 4.1126037103822455e-05}, {"id": 30, "seek": 17824, "start": 199.52, "end": 206.12, "text": " Today we'll focus about the observability part. So besides networking we can get rich visibility", "tokens": [2692, 321, 603, 1879, 466, 264, 9951, 2310, 644, 13, 407, 11868, 17985, 321, 393, 483, 4593, 19883], "temperature": 0.0, "avg_logprob": -0.22274966179570066, "compression_ratio": 1.8725490196078431, "no_speech_prob": 4.1126037103822455e-05}, {"id": 31, "seek": 20612, "start": 206.12, "end": 212.92000000000002, "text": " of metrics on your cluster. As you may know Google uses on data plane", "tokens": [295, 16367, 322, 428, 13630, 13, 1018, 291, 815, 458, 3329, 4960, 322, 1412, 5720], "temperature": 0.0, "avg_logprob": -0.16106937899447904, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.380857692216523e-05}, {"id": 32, "seek": 20612, "start": 212.92000000000002, "end": 220.04, "text": " V2 actually under the hood Cillium, Microsoft has moved Azure default AKS clusters to Cillium", "tokens": [691, 17, 767, 833, 264, 13376, 383, 373, 2197, 11, 8116, 575, 4259, 11969, 7576, 24789, 50, 23313, 281, 383, 373, 2197], "temperature": 0.0, "avg_logprob": -0.16106937899447904, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.380857692216523e-05}, {"id": 33, "seek": 20612, "start": 220.04, "end": 224.56, "text": " so all the cloud providers see that Cillium is a powerful technology to run clusters at", "tokens": [370, 439, 264, 4588, 11330, 536, 300, 383, 373, 2197, 307, 257, 4005, 2899, 281, 1190, 23313, 412], "temperature": 0.0, "avg_logprob": -0.16106937899447904, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.380857692216523e-05}, {"id": 34, "seek": 20612, "start": 224.56, "end": 231.56, "text": " scale and to get useful metrics running them. So let's start with common challenges we see.", "tokens": [4373, 293, 281, 483, 4420, 16367, 2614, 552, 13, 407, 718, 311, 722, 365, 2689, 4759, 321, 536, 13], "temperature": 0.0, "avg_logprob": -0.16106937899447904, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.380857692216523e-05}, {"id": 35, "seek": 20612, "start": 231.56, "end": 235.92000000000002, "text": " One of the main challenges if we talk about performance of your application or performance", "tokens": [1485, 295, 264, 2135, 4759, 498, 321, 751, 466, 3389, 295, 428, 3861, 420, 3389], "temperature": 0.0, "avg_logprob": -0.16106937899447904, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.380857692216523e-05}, {"id": 36, "seek": 23592, "start": 235.92, "end": 241.48, "text": " of your clusters at scale is that you run into this issue of the finger pointing problem.", "tokens": [295, 428, 23313, 412, 4373, 307, 300, 291, 1190, 666, 341, 2734, 295, 264, 5984, 12166, 1154, 13], "temperature": 0.0, "avg_logprob": -0.1399828966926126, "compression_ratio": 1.8541666666666667, "no_speech_prob": 4.514199463301338e-05}, {"id": 37, "seek": 23592, "start": 241.48, "end": 246.76, "text": " What I mean by that is that network connectivity is layered and when you run into issues you", "tokens": [708, 286, 914, 538, 300, 307, 300, 3209, 21095, 307, 34666, 293, 562, 291, 1190, 666, 2663, 291], "temperature": 0.0, "avg_logprob": -0.1399828966926126, "compression_ratio": 1.8541666666666667, "no_speech_prob": 4.514199463301338e-05}, {"id": 38, "seek": 23592, "start": 246.76, "end": 253.48, "text": " need to especially at scale you need to be easily aware where a possible problem could", "tokens": [643, 281, 2318, 412, 4373, 291, 643, 281, 312, 3612, 3650, 689, 257, 1944, 1154, 727], "temperature": 0.0, "avg_logprob": -0.1399828966926126, "compression_ratio": 1.8541666666666667, "no_speech_prob": 4.514199463301338e-05}, {"id": 39, "seek": 23592, "start": 253.48, "end": 257.47999999999996, "text": " exist and it can be in multiple layers and if you look at the OZ layer obviously it can", "tokens": [2514, 293, 309, 393, 312, 294, 3866, 7914, 293, 498, 291, 574, 412, 264, 422, 57, 4583, 2745, 309, 393], "temperature": 0.0, "avg_logprob": -0.1399828966926126, "compression_ratio": 1.8541666666666667, "no_speech_prob": 4.514199463301338e-05}, {"id": 40, "seek": 23592, "start": 257.47999999999996, "end": 261.48, "text": " be at the data link layer, the network layer, the transport layer or in the application", "tokens": [312, 412, 264, 1412, 2113, 4583, 11, 264, 3209, 4583, 11, 264, 5495, 4583, 420, 294, 264, 3861], "temperature": 0.0, "avg_logprob": -0.1399828966926126, "compression_ratio": 1.8541666666666667, "no_speech_prob": 4.514199463301338e-05}, {"id": 41, "seek": 26148, "start": 261.48, "end": 267.88, "text": " layer. So the goal of Cillium with Kavana is to give you the tools to quickly inspect", "tokens": [4583, 13, 407, 264, 3387, 295, 383, 373, 2197, 365, 591, 29867, 307, 281, 976, 291, 264, 3873, 281, 2661, 15018], "temperature": 0.0, "avg_logprob": -0.13663029376371408, "compression_ratio": 1.5278969957081545, "no_speech_prob": 3.098939487244934e-05}, {"id": 42, "seek": 26148, "start": 267.88, "end": 276.16, "text": " what's going on and to be more efficient in troubleshooting your cluster and or applications.", "tokens": [437, 311, 516, 322, 293, 281, 312, 544, 7148, 294, 15379, 47011, 428, 13630, 293, 420, 5821, 13], "temperature": 0.0, "avg_logprob": -0.13663029376371408, "compression_ratio": 1.5278969957081545, "no_speech_prob": 3.098939487244934e-05}, {"id": 43, "seek": 26148, "start": 276.16, "end": 280.84000000000003, "text": " Another common issue especially at scale is obviously the signal to noise problem. You", "tokens": [3996, 2689, 2734, 2318, 412, 4373, 307, 2745, 264, 6358, 281, 5658, 1154, 13, 509], "temperature": 0.0, "avg_logprob": -0.13663029376371408, "compression_ratio": 1.5278969957081545, "no_speech_prob": 3.098939487244934e-05}, {"id": 44, "seek": 26148, "start": 280.84000000000003, "end": 286.76, "text": " may run in the cloud you get data from your notes you see IP addresses communicating with", "tokens": [815, 1190, 294, 264, 4588, 291, 483, 1412, 490, 428, 5570, 291, 536, 8671, 16862, 17559, 365], "temperature": 0.0, "avg_logprob": -0.13663029376371408, "compression_ratio": 1.5278969957081545, "no_speech_prob": 3.098939487244934e-05}, {"id": 45, "seek": 28676, "start": 286.76, "end": 291.76, "text": " each other but IP addresses by itself mean nothing in Kubernetes clusters. They come,", "tokens": [1184, 661, 457, 8671, 16862, 538, 2564, 914, 1825, 294, 23145, 23313, 13, 814, 808, 11], "temperature": 0.0, "avg_logprob": -0.17632130781809488, "compression_ratio": 1.5411255411255411, "no_speech_prob": 4.375771095510572e-05}, {"id": 46, "seek": 28676, "start": 291.76, "end": 297.44, "text": " they go and at scale it's impossible to track and trace what's going on with service to", "tokens": [436, 352, 293, 412, 4373, 309, 311, 6243, 281, 2837, 293, 13508, 437, 311, 516, 322, 365, 2643, 281], "temperature": 0.0, "avg_logprob": -0.17632130781809488, "compression_ratio": 1.5411255411255411, "no_speech_prob": 4.375771095510572e-05}, {"id": 47, "seek": 28676, "start": 297.44, "end": 304.68, "text": " service communication in your applications. Also where our existing mechanisms falling", "tokens": [2643, 6101, 294, 428, 5821, 13, 2743, 689, 527, 6741, 15902, 7440], "temperature": 0.0, "avg_logprob": -0.17632130781809488, "compression_ratio": 1.5411255411255411, "no_speech_prob": 4.375771095510572e-05}, {"id": 48, "seek": 28676, "start": 304.68, "end": 311.2, "text": " short so first of all network devices think about centralized monitoring or firewall solutions,", "tokens": [2099, 370, 700, 295, 439, 3209, 5759, 519, 466, 32395, 11028, 420, 36109, 6547, 11], "temperature": 0.0, "avg_logprob": -0.17632130781809488, "compression_ratio": 1.5411255411255411, "no_speech_prob": 4.375771095510572e-05}, {"id": 49, "seek": 31120, "start": 311.2, "end": 317.84, "text": " think about Splunk. They are great to get alerts, to get dashboards but again at scale", "tokens": [519, 466, 19788, 3197, 13, 814, 366, 869, 281, 483, 28061, 11, 281, 483, 8240, 17228, 457, 797, 412, 4373], "temperature": 0.0, "avg_logprob": -0.11632797516972186, "compression_ratio": 1.6026200873362446, "no_speech_prob": 2.619159386085812e-05}, {"id": 50, "seek": 31120, "start": 317.84, "end": 325.64, "text": " they can be very costly or they can be a bottleneck. Also these devices don't have awareness of", "tokens": [436, 393, 312, 588, 28328, 420, 436, 393, 312, 257, 44641, 547, 13, 2743, 613, 5759, 500, 380, 362, 8888, 295], "temperature": 0.0, "avg_logprob": -0.11632797516972186, "compression_ratio": 1.6026200873362446, "no_speech_prob": 2.619159386085812e-05}, {"id": 51, "seek": 31120, "start": 325.64, "end": 330.64, "text": " the identities of your applications running on your Kubernetes clusters. Cloud provider", "tokens": [264, 24239, 295, 428, 5821, 2614, 322, 428, 23145, 23313, 13, 8061, 12398], "temperature": 0.0, "avg_logprob": -0.11632797516972186, "compression_ratio": 1.6026200873362446, "no_speech_prob": 2.619159386085812e-05}, {"id": 52, "seek": 31120, "start": 330.64, "end": 337.2, "text": " network logs are nice for note to note communication but don't provide identity as well. You can", "tokens": [3209, 20820, 366, 1481, 337, 3637, 281, 3637, 6101, 457, 500, 380, 2893, 6575, 382, 731, 13, 509, 393], "temperature": 0.0, "avg_logprob": -0.11632797516972186, "compression_ratio": 1.6026200873362446, "no_speech_prob": 2.619159386085812e-05}, {"id": 53, "seek": 33720, "start": 337.2, "end": 344.32, "text": " monitor the host, you can see Linux host statistics but that gives you only visibility on the", "tokens": [6002, 264, 3975, 11, 291, 393, 536, 18734, 3975, 12523, 457, 300, 2709, 291, 787, 19883, 322, 264], "temperature": 0.0, "avg_logprob": -0.1538007656733195, "compression_ratio": 1.8619246861924685, "no_speech_prob": 1.7019681763486005e-05}, {"id": 54, "seek": 33720, "start": 344.32, "end": 350.0, "text": " note level and again a Linux note doesn't have any awareness of the identities of the", "tokens": [3637, 1496, 293, 797, 257, 18734, 3637, 1177, 380, 362, 604, 8888, 295, 264, 24239, 295, 264], "temperature": 0.0, "avg_logprob": -0.1538007656733195, "compression_ratio": 1.8619246861924685, "no_speech_prob": 1.7019681763486005e-05}, {"id": 55, "seek": 33720, "start": 350.0, "end": 356.0, "text": " services running in your Kubernetes cluster. You may want to try to modify application", "tokens": [3328, 2614, 294, 428, 23145, 13630, 13, 509, 815, 528, 281, 853, 281, 16927, 3861], "temperature": 0.0, "avg_logprob": -0.1538007656733195, "compression_ratio": 1.8619246861924685, "no_speech_prob": 1.7019681763486005e-05}, {"id": 56, "seek": 33720, "start": 356.0, "end": 360.48, "text": " code and this applies a bit to the service mesh session. You may want to install libraries", "tokens": [3089, 293, 341, 13165, 257, 857, 281, 264, 2643, 17407, 5481, 13, 509, 815, 528, 281, 3625, 15148], "temperature": 0.0, "avg_logprob": -0.1538007656733195, "compression_ratio": 1.8619246861924685, "no_speech_prob": 1.7019681763486005e-05}, {"id": 57, "seek": 33720, "start": 360.48, "end": 365.2, "text": " which gives you visibility of the application but then you don't have visibility on the", "tokens": [597, 2709, 291, 19883, 295, 264, 3861, 457, 550, 291, 500, 380, 362, 19883, 322, 264], "temperature": 0.0, "avg_logprob": -0.1538007656733195, "compression_ratio": 1.8619246861924685, "no_speech_prob": 1.7019681763486005e-05}, {"id": 58, "seek": 36520, "start": 365.2, "end": 371.84, "text": " networking layer. Service mesh, main goal of service mesh is obviously visibility of", "tokens": [17985, 4583, 13, 9561, 17407, 11, 2135, 3387, 295, 2643, 17407, 307, 2745, 19883, 295], "temperature": 0.0, "avg_logprob": -0.1463516760563505, "compression_ratio": 1.6542056074766356, "no_speech_prob": 3.019748328370042e-05}, {"id": 59, "seek": 36520, "start": 371.84, "end": 377.03999999999996, "text": " the network and trend communication to get metrics out of that but that with the sidecar", "tokens": [264, 3209, 293, 6028, 6101, 281, 483, 16367, 484, 295, 300, 457, 300, 365, 264, 1252, 6166], "temperature": 0.0, "avg_logprob": -0.1463516760563505, "compression_ratio": 1.6542056074766356, "no_speech_prob": 3.019748328370042e-05}, {"id": 60, "seek": 36520, "start": 377.03999999999996, "end": 383.08, "text": " based implementation comes with a footprint and with induced latency plus you have operational", "tokens": [2361, 11420, 1487, 365, 257, 24222, 293, 365, 33991, 27043, 1804, 291, 362, 16607], "temperature": 0.0, "avg_logprob": -0.1463516760563505, "compression_ratio": 1.6542056074766356, "no_speech_prob": 3.019748328370042e-05}, {"id": 61, "seek": 36520, "start": 383.08, "end": 389.4, "text": " complexity maintaining your service mesh solution on top of your Kubernetes clusters.", "tokens": [14024, 14916, 428, 2643, 17407, 3827, 322, 1192, 295, 428, 23145, 23313, 13], "temperature": 0.0, "avg_logprob": -0.1463516760563505, "compression_ratio": 1.6542056074766356, "no_speech_prob": 3.019748328370042e-05}, {"id": 62, "seek": 38940, "start": 389.4, "end": 397.32, "text": " So this is where Cilium comes around the corner is that we provide identity aware based observability", "tokens": [407, 341, 307, 689, 383, 388, 2197, 1487, 926, 264, 4538, 307, 300, 321, 2893, 6575, 3650, 2361, 9951, 2310], "temperature": 0.0, "avg_logprob": -0.177335122052361, "compression_ratio": 1.6898148148148149, "no_speech_prob": 3.146452581859194e-05}, {"id": 63, "seek": 38940, "start": 397.32, "end": 404.28, "text": " and security. What that means is based on the labels you set on your workloads, we create", "tokens": [293, 3825, 13, 708, 300, 1355, 307, 2361, 322, 264, 16949, 291, 992, 322, 428, 32452, 11, 321, 1884], "temperature": 0.0, "avg_logprob": -0.177335122052361, "compression_ratio": 1.6898148148148149, "no_speech_prob": 3.146452581859194e-05}, {"id": 64, "seek": 38940, "start": 404.28, "end": 411.47999999999996, "text": " unique identities and we're able to attach that identity in the data plane using eBPF", "tokens": [3845, 24239, 293, 321, 434, 1075, 281, 5085, 300, 6575, 294, 264, 1412, 5720, 1228, 308, 33, 47, 37], "temperature": 0.0, "avg_logprob": -0.177335122052361, "compression_ratio": 1.6898148148148149, "no_speech_prob": 3.146452581859194e-05}, {"id": 65, "seek": 38940, "start": 411.47999999999996, "end": 416.59999999999997, "text": " and using that identity we can do things with that so we can secure the connectivity in", "tokens": [293, 1228, 300, 6575, 321, 393, 360, 721, 365, 300, 370, 321, 393, 7144, 264, 21095, 294], "temperature": 0.0, "avg_logprob": -0.177335122052361, "compression_ratio": 1.6898148148148149, "no_speech_prob": 3.146452581859194e-05}, {"id": 66, "seek": 41660, "start": 416.6, "end": 421.56, "text": " this example a front end to a back end is allowed to communicate based on the network", "tokens": [341, 1365, 257, 1868, 917, 281, 257, 646, 917, 307, 4350, 281, 7890, 2361, 322, 264, 3209], "temperature": 0.0, "avg_logprob": -0.13800201219381744, "compression_ratio": 1.7689243027888446, "no_speech_prob": 3.897869464708492e-05}, {"id": 67, "seek": 41660, "start": 421.56, "end": 426.40000000000003, "text": " policies we set and the identities we are aware of and these identities are cluster", "tokens": [7657, 321, 992, 293, 264, 24239, 321, 366, 3650, 295, 293, 613, 24239, 366, 13630], "temperature": 0.0, "avg_logprob": -0.13800201219381744, "compression_ratio": 1.7689243027888446, "no_speech_prob": 3.897869464708492e-05}, {"id": 68, "seek": 41660, "start": 426.40000000000003, "end": 432.64000000000004, "text": " wide property but in terms of observability this also means that we can use this identity", "tokens": [4874, 4707, 457, 294, 2115, 295, 9951, 2310, 341, 611, 1355, 300, 321, 393, 764, 341, 6575], "temperature": 0.0, "avg_logprob": -0.13800201219381744, "compression_ratio": 1.7689243027888446, "no_speech_prob": 3.897869464708492e-05}, {"id": 69, "seek": 41660, "start": 432.64000000000004, "end": 439.72, "text": " to get rich metrics and data for that identity and you can monitor it effectively. This means", "tokens": [281, 483, 4593, 16367, 293, 1412, 337, 300, 6575, 293, 291, 393, 6002, 309, 8659, 13, 639, 1355], "temperature": 0.0, "avg_logprob": -0.13800201219381744, "compression_ratio": 1.7689243027888446, "no_speech_prob": 3.897869464708492e-05}, {"id": 70, "seek": 41660, "start": 439.72, "end": 444.96000000000004, "text": " that you're not looking anymore at IP addresses, you're looking at identities so the whole", "tokens": [300, 291, 434, 406, 1237, 3602, 412, 8671, 16862, 11, 291, 434, 1237, 412, 24239, 370, 264, 1379], "temperature": 0.0, "avg_logprob": -0.13800201219381744, "compression_ratio": 1.7689243027888446, "no_speech_prob": 3.897869464708492e-05}, {"id": 71, "seek": 44496, "start": 444.96, "end": 453.84, "text": " set of workloads the service to service communication for a front end to a back end.", "tokens": [992, 295, 32452, 264, 2643, 281, 2643, 6101, 337, 257, 1868, 917, 281, 257, 646, 917, 13], "temperature": 0.0, "avg_logprob": -0.17716003018756246, "compression_ratio": 1.6261682242990654, "no_speech_prob": 2.8794827812816948e-05}, {"id": 72, "seek": 44496, "start": 453.84, "end": 459.32, "text": " Hubble is our observability solution built on top of Cilium, how it works is that Cilium", "tokens": [42317, 307, 527, 9951, 2310, 3827, 3094, 322, 1192, 295, 383, 388, 2197, 11, 577, 309, 1985, 307, 300, 383, 388, 2197], "temperature": 0.0, "avg_logprob": -0.17716003018756246, "compression_ratio": 1.6261682242990654, "no_speech_prob": 2.8794827812816948e-05}, {"id": 73, "seek": 44496, "start": 459.32, "end": 466.52, "text": " runs as a demon set on your cluster nodes as an agent and Hubble can retrieve data from", "tokens": [6676, 382, 257, 14283, 992, 322, 428, 13630, 13891, 382, 364, 9461, 293, 42317, 393, 30254, 1412, 490], "temperature": 0.0, "avg_logprob": -0.17716003018756246, "compression_ratio": 1.6261682242990654, "no_speech_prob": 2.8794827812816948e-05}, {"id": 74, "seek": 44496, "start": 466.52, "end": 473.84, "text": " those agents through a CLI or UI and we can export metrics based on your workloads. So", "tokens": [729, 12554, 807, 257, 12855, 40, 420, 15682, 293, 321, 393, 10725, 16367, 2361, 322, 428, 32452, 13, 407], "temperature": 0.0, "avg_logprob": -0.17716003018756246, "compression_ratio": 1.6261682242990654, "no_speech_prob": 2.8794827812816948e-05}, {"id": 75, "seek": 47384, "start": 473.84, "end": 479.08, "text": " there are three parts, first of all the Hubble UI gives a service dependency map so on a", "tokens": [456, 366, 1045, 3166, 11, 700, 295, 439, 264, 42317, 15682, 2709, 257, 2643, 33621, 4471, 370, 322, 257], "temperature": 0.0, "avg_logprob": -0.15931347967351525, "compression_ratio": 1.8319672131147542, "no_speech_prob": 8.572234946768731e-05}, {"id": 76, "seek": 47384, "start": 479.08, "end": 485.11999999999995, "text": " namespace level you can see what's deployed, what is communicating with each other, what", "tokens": [5288, 17940, 1496, 291, 393, 536, 437, 311, 17826, 11, 437, 307, 17559, 365, 1184, 661, 11, 437], "temperature": 0.0, "avg_logprob": -0.15931347967351525, "compression_ratio": 1.8319672131147542, "no_speech_prob": 8.572234946768731e-05}, {"id": 77, "seek": 47384, "start": 485.11999999999995, "end": 491.08, "text": " kind of protocols they're using, what's coming between namespaces so you would see for example", "tokens": [733, 295, 20618, 436, 434, 1228, 11, 437, 311, 1348, 1296, 5288, 79, 2116, 370, 291, 576, 536, 337, 1365], "temperature": 0.0, "avg_logprob": -0.15931347967351525, "compression_ratio": 1.8319672131147542, "no_speech_prob": 8.572234946768731e-05}, {"id": 78, "seek": 47384, "start": 491.08, "end": 496.71999999999997, "text": " if there's inter namespace communication you can identify the source namespace, if you", "tokens": [498, 456, 311, 728, 5288, 17940, 6101, 291, 393, 5876, 264, 4009, 5288, 17940, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.15931347967351525, "compression_ratio": 1.8319672131147542, "no_speech_prob": 8.572234946768731e-05}, {"id": 79, "seek": 47384, "start": 496.71999999999997, "end": 502.64, "text": " use cluster mesh you can even identify the source cluster, you can also identify egress", "tokens": [764, 13630, 17407, 291, 393, 754, 5876, 264, 4009, 13630, 11, 291, 393, 611, 5876, 308, 3091], "temperature": 0.0, "avg_logprob": -0.15931347967351525, "compression_ratio": 1.8319672131147542, "no_speech_prob": 8.572234946768731e-05}, {"id": 80, "seek": 50264, "start": 502.64, "end": 508.2, "text": " traffic and ingress traffic on a namespace level. The Hubble CLI is more a power user", "tokens": [6419, 293, 3957, 735, 6419, 322, 257, 5288, 17940, 1496, 13, 440, 42317, 12855, 40, 307, 544, 257, 1347, 4195], "temperature": 0.0, "avg_logprob": -0.14184840066092355, "compression_ratio": 1.5833333333333333, "no_speech_prob": 3.3041091228369623e-05}, {"id": 81, "seek": 50264, "start": 508.2, "end": 513.16, "text": " tool to give you detailed flow, you can export it to JSON, you can do a lot of filtering", "tokens": [2290, 281, 976, 291, 9942, 3095, 11, 291, 393, 10725, 309, 281, 31828, 11, 291, 393, 360, 257, 688, 295, 30822], "temperature": 0.0, "avg_logprob": -0.14184840066092355, "compression_ratio": 1.5833333333333333, "no_speech_prob": 3.3041091228369623e-05}, {"id": 82, "seek": 50264, "start": 513.16, "end": 518.92, "text": " based on labels. Hubble metrics is the part where mostly the topic for today is where", "tokens": [2361, 322, 16949, 13, 42317, 16367, 307, 264, 644, 689, 5240, 264, 4829, 337, 965, 307, 689], "temperature": 0.0, "avg_logprob": -0.14184840066092355, "compression_ratio": 1.5833333333333333, "no_speech_prob": 3.3041091228369623e-05}, {"id": 83, "seek": 50264, "start": 518.92, "end": 524.4399999999999, "text": " you export metrics and you use Grafana for example to observe the performance of your", "tokens": [291, 10725, 16367, 293, 291, 764, 8985, 69, 2095, 337, 1365, 281, 11441, 264, 3389, 295, 428], "temperature": 0.0, "avg_logprob": -0.14184840066092355, "compression_ratio": 1.5833333333333333, "no_speech_prob": 3.3041091228369623e-05}, {"id": 84, "seek": 50264, "start": 524.4399999999999, "end": 530.48, "text": " cluster application. This is all fueled through EBPF so again think about a network device", "tokens": [13630, 3861, 13, 639, 307, 439, 45446, 807, 50148, 47, 37, 370, 797, 519, 466, 257, 3209, 4302], "temperature": 0.0, "avg_logprob": -0.14184840066092355, "compression_ratio": 1.5833333333333333, "no_speech_prob": 3.3041091228369623e-05}, {"id": 85, "seek": 53048, "start": 530.48, "end": 536.9200000000001, "text": " sending a packet, that's a kernel event, EBPF program gets attached to it, gets the metrics", "tokens": [7750, 257, 20300, 11, 300, 311, 257, 28256, 2280, 11, 50148, 47, 37, 1461, 2170, 8570, 281, 309, 11, 2170, 264, 16367], "temperature": 0.0, "avg_logprob": -0.15834370288220082, "compression_ratio": 1.493723849372385, "no_speech_prob": 2.501237759133801e-05}, {"id": 86, "seek": 53048, "start": 536.9200000000001, "end": 545.48, "text": " and it's done. This is a small screenshot of the CLI so this gives you flow visibility", "tokens": [293, 309, 311, 1096, 13, 639, 307, 257, 1359, 27712, 295, 264, 12855, 40, 370, 341, 2709, 291, 3095, 19883], "temperature": 0.0, "avg_logprob": -0.15834370288220082, "compression_ratio": 1.493723849372385, "no_speech_prob": 2.501237759133801e-05}, {"id": 87, "seek": 53048, "start": 545.48, "end": 550.52, "text": " using Hubble observe commands, you can follow for example based on the label in this case", "tokens": [1228, 42317, 11441, 16901, 11, 291, 393, 1524, 337, 1365, 2361, 322, 264, 7645, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.15834370288220082, "compression_ratio": 1.493723849372385, "no_speech_prob": 2.501237759133801e-05}, {"id": 88, "seek": 53048, "start": 550.52, "end": 555.88, "text": " X-Wing so we're following all the workloads labeled with X-Wing so again no IP addresses", "tokens": [1783, 12, 54, 278, 370, 321, 434, 3480, 439, 264, 32452, 21335, 365, 1783, 12, 54, 278, 370, 797, 572, 8671, 16862], "temperature": 0.0, "avg_logprob": -0.15834370288220082, "compression_ratio": 1.493723849372385, "no_speech_prob": 2.501237759133801e-05}, {"id": 89, "seek": 55588, "start": 555.88, "end": 562.36, "text": " just labels. In purple it's highlighted these IDs we use so again each unique set of labels", "tokens": [445, 16949, 13, 682, 9656, 309, 311, 17173, 613, 48212, 321, 764, 370, 797, 1184, 3845, 992, 295, 16949], "temperature": 0.0, "avg_logprob": -0.18999728034524357, "compression_ratio": 1.663594470046083, "no_speech_prob": 6.151099660200998e-05}, {"id": 90, "seek": 55588, "start": 562.36, "end": 568.64, "text": " gets a unique cluster wide ID and based on those IDs we can track based on labels what", "tokens": [2170, 257, 3845, 13630, 4874, 7348, 293, 2361, 322, 729, 48212, 321, 393, 2837, 2361, 322, 16949, 437], "temperature": 0.0, "avg_logprob": -0.18999728034524357, "compression_ratio": 1.663594470046083, "no_speech_prob": 6.151099660200998e-05}, {"id": 91, "seek": 55588, "start": 568.64, "end": 574.08, "text": " communication is going on and there's a lot of metadata you can filter on things like", "tokens": [6101, 307, 516, 322, 293, 456, 311, 257, 688, 295, 26603, 291, 393, 6608, 322, 721, 411], "temperature": 0.0, "avg_logprob": -0.18999728034524357, "compression_ratio": 1.663594470046083, "no_speech_prob": 6.151099660200998e-05}, {"id": 92, "seek": 55588, "start": 574.08, "end": 581.4, "text": " headers, things like ports, things like protocols, obviously labels in Q&A spot names, services,", "tokens": [45101, 11, 721, 411, 18160, 11, 721, 411, 20618, 11, 2745, 16949, 294, 1249, 5, 32, 4008, 5288, 11, 3328, 11], "temperature": 0.0, "avg_logprob": -0.18999728034524357, "compression_ratio": 1.663594470046083, "no_speech_prob": 6.151099660200998e-05}, {"id": 93, "seek": 58140, "start": 581.4, "end": 588.72, "text": " worker nodes, DNS, we also have Cilium network policies which allow you to filter and observe", "tokens": [11346, 13891, 11, 35153, 11, 321, 611, 362, 383, 388, 2197, 3209, 7657, 597, 2089, 291, 281, 6608, 293, 11441], "temperature": 0.0, "avg_logprob": -0.17567721472846137, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.0001061013899743557}, {"id": 94, "seek": 58140, "start": 588.72, "end": 596.64, "text": " two FQDN rules meaning we can inspect queries to external domains and we can filter based", "tokens": [732, 479, 48, 35, 45, 4474, 3620, 321, 393, 15018, 24109, 281, 8320, 25514, 293, 321, 393, 6608, 2361], "temperature": 0.0, "avg_logprob": -0.17567721472846137, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.0001061013899743557}, {"id": 95, "seek": 58140, "start": 596.64, "end": 602.64, "text": " on that and obviously Cilium related identity such as world, ingress, egress, host and that", "tokens": [322, 300, 293, 2745, 383, 388, 2197, 4077, 6575, 1270, 382, 1002, 11, 3957, 735, 11, 308, 3091, 11, 3975, 293, 300], "temperature": 0.0, "avg_logprob": -0.17567721472846137, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.0001061013899743557}, {"id": 96, "seek": 58140, "start": 602.64, "end": 611.0, "text": " kind of stuff. Policy verdict matches, things like dropped, allowed and stuff. This is the", "tokens": [733, 295, 1507, 13, 21708, 33957, 10676, 11, 721, 411, 8119, 11, 4350, 293, 1507, 13, 639, 307, 264], "temperature": 0.0, "avg_logprob": -0.17567721472846137, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.0001061013899743557}, {"id": 97, "seek": 61100, "start": 611.0, "end": 617.16, "text": " Hubble UI surface map like I said before this gives you a namespace level view in this case", "tokens": [42317, 15682, 3753, 4471, 411, 286, 848, 949, 341, 2709, 291, 257, 5288, 17940, 1496, 1910, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.14730900067549485, "compression_ratio": 1.8995633187772927, "no_speech_prob": 3.304263009340502e-05}, {"id": 98, "seek": 61100, "start": 617.16, "end": 622.96, "text": " we have a jobs app and I'm using this app as well in the demo I'm showing a bit later", "tokens": [321, 362, 257, 4782, 724, 293, 286, 478, 1228, 341, 724, 382, 731, 294, 264, 10723, 286, 478, 4099, 257, 857, 1780], "temperature": 0.0, "avg_logprob": -0.14730900067549485, "compression_ratio": 1.8995633187772927, "no_speech_prob": 3.304263009340502e-05}, {"id": 99, "seek": 61100, "start": 622.96, "end": 626.56, "text": " so here you're looking at a namespace level view where you can see all the surface to", "tokens": [370, 510, 291, 434, 1237, 412, 257, 5288, 17940, 1496, 1910, 689, 291, 393, 536, 439, 264, 3753, 281], "temperature": 0.0, "avg_logprob": -0.14730900067549485, "compression_ratio": 1.8995633187772927, "no_speech_prob": 3.304263009340502e-05}, {"id": 100, "seek": 61100, "start": 626.56, "end": 632.0, "text": " surface communication of your application running in that namespace. In this case it's", "tokens": [3753, 6101, 295, 428, 3861, 2614, 294, 300, 5288, 17940, 13, 682, 341, 1389, 309, 311], "temperature": 0.0, "avg_logprob": -0.14730900067549485, "compression_ratio": 1.8995633187772927, "no_speech_prob": 3.304263009340502e-05}, {"id": 101, "seek": 61100, "start": 632.0, "end": 637.08, "text": " only intra namespace communication and you can see for example that the recruiter is", "tokens": [787, 43358, 5288, 17940, 6101, 293, 291, 393, 536, 337, 1365, 300, 264, 9372, 1681, 307], "temperature": 0.0, "avg_logprob": -0.14730900067549485, "compression_ratio": 1.8995633187772927, "no_speech_prob": 3.304263009340502e-05}, {"id": 102, "seek": 63708, "start": 637.08, "end": 642.8000000000001, "text": " talking to core API, the core API is talking to Elasticsearch, we have a zookeeper component,", "tokens": [1417, 281, 4965, 9362, 11, 264, 4965, 9362, 307, 1417, 281, 2699, 2750, 405, 1178, 11, 321, 362, 257, 25347, 23083, 6542, 11], "temperature": 0.0, "avg_logprob": -0.17860116277422225, "compression_ratio": 1.6244343891402715, "no_speech_prob": 4.345420893514529e-05}, {"id": 103, "seek": 63708, "start": 642.8000000000001, "end": 649.12, "text": " we identify Kafka, also identifying Kafka protocols so there are a number of protocols", "tokens": [321, 5876, 47064, 11, 611, 16696, 47064, 20618, 370, 456, 366, 257, 1230, 295, 20618], "temperature": 0.0, "avg_logprob": -0.17860116277422225, "compression_ratio": 1.6244343891402715, "no_speech_prob": 4.345420893514529e-05}, {"id": 104, "seek": 63708, "start": 649.12, "end": 656.72, "text": " we can inspect and see and we also see layer 7 information so in this case HTTP calls to", "tokens": [321, 393, 15018, 293, 536, 293, 321, 611, 536, 4583, 1614, 1589, 370, 294, 341, 1389, 33283, 5498, 281], "temperature": 0.0, "avg_logprob": -0.17860116277422225, "compression_ratio": 1.6244343891402715, "no_speech_prob": 4.345420893514529e-05}, {"id": 105, "seek": 63708, "start": 656.72, "end": 663.0400000000001, "text": " a specific URI or URL with specific method and return calls and this is triggered through", "tokens": [257, 2685, 624, 5577, 420, 12905, 365, 2685, 3170, 293, 2736, 5498, 293, 341, 307, 21710, 807], "temperature": 0.0, "avg_logprob": -0.17860116277422225, "compression_ratio": 1.6244343891402715, "no_speech_prob": 4.345420893514529e-05}, {"id": 106, "seek": 66304, "start": 663.04, "end": 669.8399999999999, "text": " just simple construct as a Syllium Network Policy. If you just allow let's say internamespace", "tokens": [445, 2199, 7690, 382, 257, 3902, 285, 2197, 12640, 21708, 13, 759, 291, 445, 2089, 718, 311, 584, 728, 77, 1632, 17940], "temperature": 0.0, "avg_logprob": -0.2099969493809031, "compression_ratio": 1.4414893617021276, "no_speech_prob": 4.2912161006825045e-05}, {"id": 107, "seek": 66304, "start": 669.8399999999999, "end": 679.64, "text": " traffic and you are accepting HTTP that already triggers this visibility for you to see. Now", "tokens": [6419, 293, 291, 366, 17391, 33283, 300, 1217, 22827, 341, 19883, 337, 291, 281, 536, 13, 823], "temperature": 0.0, "avg_logprob": -0.2099969493809031, "compression_ratio": 1.4414893617021276, "no_speech_prob": 4.2912161006825045e-05}, {"id": 108, "seek": 66304, "start": 679.64, "end": 688.0799999999999, "text": " using this data we can also export metrics to Grafana so we are working with Grafana", "tokens": [1228, 341, 1412, 321, 393, 611, 10725, 16367, 281, 8985, 69, 2095, 370, 321, 366, 1364, 365, 8985, 69, 2095], "temperature": 0.0, "avg_logprob": -0.2099969493809031, "compression_ratio": 1.4414893617021276, "no_speech_prob": 4.2912161006825045e-05}, {"id": 109, "seek": 68808, "start": 688.08, "end": 695.4000000000001, "text": " a lot more lately that means that we are building a lot of more useful dashboards and also integrating", "tokens": [257, 688, 544, 12881, 300, 1355, 300, 321, 366, 2390, 257, 688, 295, 544, 4420, 8240, 17228, 293, 611, 26889], "temperature": 0.0, "avg_logprob": -0.14465048199608213, "compression_ratio": 1.5940170940170941, "no_speech_prob": 3.852093868772499e-05}, {"id": 110, "seek": 68808, "start": 695.4000000000001, "end": 701.96, "text": " with things like Tempo for getting transparent tracing in Grafana, all powered through Syllium", "tokens": [365, 721, 411, 8095, 2259, 337, 1242, 12737, 25262, 294, 8985, 69, 2095, 11, 439, 17786, 807, 3902, 285, 2197], "temperature": 0.0, "avg_logprob": -0.14465048199608213, "compression_ratio": 1.5940170940170941, "no_speech_prob": 3.852093868772499e-05}, {"id": 111, "seek": 68808, "start": 701.96, "end": 708.6800000000001, "text": " and EBPF. This allows us to not only see on the network level metrics on performance", "tokens": [293, 50148, 47, 37, 13, 639, 4045, 505, 281, 406, 787, 536, 322, 264, 3209, 1496, 16367, 322, 3389], "temperature": 0.0, "avg_logprob": -0.14465048199608213, "compression_ratio": 1.5940170940170941, "no_speech_prob": 3.852093868772499e-05}, {"id": 112, "seek": 68808, "start": 708.6800000000001, "end": 714.1600000000001, "text": " on the node but also for surface to surface communication to provide golden signals things", "tokens": [322, 264, 9984, 457, 611, 337, 3753, 281, 3753, 6101, 281, 2893, 9729, 12354, 721], "temperature": 0.0, "avg_logprob": -0.14465048199608213, "compression_ratio": 1.5940170940170941, "no_speech_prob": 3.852093868772499e-05}, {"id": 113, "seek": 71416, "start": 714.16, "end": 721.4, "text": " like HTTP request rate, latency, response codes and error codes which would as an application", "tokens": [411, 33283, 5308, 3314, 11, 27043, 11, 4134, 14211, 293, 6713, 14211, 597, 576, 382, 364, 3861], "temperature": 0.0, "avg_logprob": -0.16759855319292116, "compression_ratio": 1.6322869955156951, "no_speech_prob": 1.441356562281726e-05}, {"id": 114, "seek": 71416, "start": 721.4, "end": 728.4399999999999, "text": " engineer would allow you to quickly see which component of the application is not responding", "tokens": [11403, 576, 2089, 291, 281, 2661, 536, 597, 6542, 295, 264, 3861, 307, 406, 16670], "temperature": 0.0, "avg_logprob": -0.16759855319292116, "compression_ratio": 1.6322869955156951, "no_speech_prob": 1.441356562281726e-05}, {"id": 115, "seek": 71416, "start": 728.4399999999999, "end": 735.24, "text": " as it should. But also detecting transient network layers so this will be more network", "tokens": [382, 309, 820, 13, 583, 611, 40237, 41998, 3209, 7914, 370, 341, 486, 312, 544, 3209], "temperature": 0.0, "avg_logprob": -0.16759855319292116, "compression_ratio": 1.6322869955156951, "no_speech_prob": 1.441356562281726e-05}, {"id": 116, "seek": 71416, "start": 735.24, "end": 742.0799999999999, "text": " related we may see retransmissions, we can see bytes sent and received and we can indicate", "tokens": [4077, 321, 815, 536, 23106, 599, 76, 7922, 11, 321, 393, 536, 36088, 2279, 293, 4613, 293, 321, 393, 13330], "temperature": 0.0, "avg_logprob": -0.16759855319292116, "compression_ratio": 1.6322869955156951, "no_speech_prob": 1.441356562281726e-05}, {"id": 117, "seek": 74208, "start": 742.08, "end": 747.6800000000001, "text": " things like boundary time to indicate a network layer problem. So maybe in a data center you", "tokens": [721, 411, 12866, 565, 281, 13330, 257, 3209, 4583, 1154, 13, 407, 1310, 294, 257, 1412, 3056, 291], "temperature": 0.0, "avg_logprob": -0.13286237592820999, "compression_ratio": 1.6272727272727272, "no_speech_prob": 6.993589977355441e-06}, {"id": 118, "seek": 74208, "start": 747.6800000000001, "end": 752.6, "text": " have a specific rack switch or top of rack switch not performing as it should so nodes", "tokens": [362, 257, 2685, 14788, 3679, 420, 1192, 295, 14788, 3679, 406, 10205, 382, 309, 820, 370, 13891], "temperature": 0.0, "avg_logprob": -0.13286237592820999, "compression_ratio": 1.6272727272727272, "no_speech_prob": 6.993589977355441e-06}, {"id": 119, "seek": 74208, "start": 752.6, "end": 758.1600000000001, "text": " connected to that switch will have improved or will have reduced performance and you would", "tokens": [4582, 281, 300, 3679, 486, 362, 9689, 420, 486, 362, 9212, 3389, 293, 291, 576], "temperature": 0.0, "avg_logprob": -0.13286237592820999, "compression_ratio": 1.6272727272727272, "no_speech_prob": 6.993589977355441e-06}, {"id": 120, "seek": 74208, "start": 758.1600000000001, "end": 768.2800000000001, "text": " see latency increasing. Now with the latest dashboards we also able to see programmatic", "tokens": [536, 27043, 5662, 13, 823, 365, 264, 6792, 8240, 17228, 321, 611, 1075, 281, 536, 1461, 25915], "temperature": 0.0, "avg_logprob": -0.13286237592820999, "compression_ratio": 1.6272727272727272, "no_speech_prob": 6.993589977355441e-06}, {"id": 121, "seek": 76828, "start": 768.28, "end": 776.36, "text": " API request using transparent tracing. This goes to the integration with Grafana. So at", "tokens": [9362, 5308, 1228, 12737, 25262, 13, 639, 1709, 281, 264, 10980, 365, 8985, 69, 2095, 13, 407, 412], "temperature": 0.0, "avg_logprob": -0.19767283271340763, "compression_ratio": 1.647887323943662, "no_speech_prob": 2.1999225282343104e-05}, {"id": 122, "seek": 76828, "start": 776.36, "end": 780.3199999999999, "text": " the moment your application need to be able to support it so you need to be able to inject", "tokens": [264, 1623, 428, 3861, 643, 281, 312, 1075, 281, 1406, 309, 370, 291, 643, 281, 312, 1075, 281, 10711], "temperature": 0.0, "avg_logprob": -0.19767283271340763, "compression_ratio": 1.647887323943662, "no_speech_prob": 2.1999225282343104e-05}, {"id": 123, "seek": 76828, "start": 780.3199999999999, "end": 787.56, "text": " traces. But we are working out of the box getting also this support and be able to help", "tokens": [26076, 13, 583, 321, 366, 1364, 484, 295, 264, 2424, 1242, 611, 341, 1406, 293, 312, 1075, 281, 854], "temperature": 0.0, "avg_logprob": -0.19767283271340763, "compression_ratio": 1.647887323943662, "no_speech_prob": 2.1999225282343104e-05}, {"id": 124, "seek": 76828, "start": 787.56, "end": 794.48, "text": " by help support HTTP traces as such. And then you get this exemplar so I am pointing", "tokens": [538, 854, 1406, 33283, 26076, 382, 1270, 13, 400, 550, 291, 483, 341, 24112, 289, 370, 286, 669, 12166], "temperature": 0.0, "avg_logprob": -0.19767283271340763, "compression_ratio": 1.647887323943662, "no_speech_prob": 2.1999225282343104e-05}, {"id": 125, "seek": 79448, "start": 794.48, "end": 800.6800000000001, "text": " at a small exemplar here after which you can inspect this with Tempo and you can see a", "tokens": [412, 257, 1359, 24112, 289, 510, 934, 597, 291, 393, 15018, 341, 365, 8095, 2259, 293, 291, 393, 536, 257], "temperature": 0.0, "avg_logprob": -0.1971013387044271, "compression_ratio": 1.5676855895196506, "no_speech_prob": 4.29663086833898e-05}, {"id": 126, "seek": 79448, "start": 800.6800000000001, "end": 809.24, "text": " span of a specific request and see where the problem may reside. A bit more on monitoring", "tokens": [16174, 295, 257, 2685, 5308, 293, 536, 689, 264, 1154, 815, 40134, 13, 316, 857, 544, 322, 11028], "temperature": 0.0, "avg_logprob": -0.1971013387044271, "compression_ratio": 1.5676855895196506, "no_speech_prob": 4.29663086833898e-05}, {"id": 127, "seek": 79448, "start": 809.24, "end": 814.64, "text": " so this is more day 2 ops. I want to highlight that if you run Cillian and you are also using", "tokens": [370, 341, 307, 544, 786, 568, 44663, 13, 286, 528, 281, 5078, 300, 498, 291, 1190, 383, 373, 952, 293, 291, 366, 611, 1228], "temperature": 0.0, "avg_logprob": -0.1971013387044271, "compression_ratio": 1.5676855895196506, "no_speech_prob": 4.29663086833898e-05}, {"id": 128, "seek": 79448, "start": 814.64, "end": 820.4, "text": " Grafana make sure that you install the agent, Hubble and operator metrics plugins. These", "tokens": [8985, 69, 2095, 652, 988, 300, 291, 3625, 264, 9461, 11, 42317, 293, 12973, 16367, 33759, 13, 1981], "temperature": 0.0, "avg_logprob": -0.1971013387044271, "compression_ratio": 1.5676855895196506, "no_speech_prob": 4.29663086833898e-05}, {"id": 129, "seek": 82040, "start": 820.4, "end": 826.4, "text": " are out of the box plugins we provide through the Grafana marketplace you can download.", "tokens": [366, 484, 295, 264, 2424, 33759, 321, 2893, 807, 264, 8985, 69, 2095, 19455, 291, 393, 5484, 13], "temperature": 0.0, "avg_logprob": -0.18610808849334717, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0001988069125218317}, {"id": 130, "seek": 82040, "start": 826.4, "end": 831.24, "text": " This gives you visibility in the performance of your cluster. So first of all agent metrics", "tokens": [639, 2709, 291, 19883, 294, 264, 3389, 295, 428, 13630, 13, 407, 700, 295, 439, 9461, 16367], "temperature": 0.0, "avg_logprob": -0.18610808849334717, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0001988069125218317}, {"id": 131, "seek": 82040, "start": 831.24, "end": 836.0, "text": " everything on the node level how the node is performing, how many throughput they are", "tokens": [1203, 322, 264, 9984, 1496, 577, 264, 9984, 307, 10205, 11, 577, 867, 44629, 436, 366], "temperature": 0.0, "avg_logprob": -0.18610808849334717, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0001988069125218317}, {"id": 132, "seek": 82040, "start": 836.0, "end": 843.0, "text": " processing, how many memory the BPF is using, all this related stuff. Hubble metrics gives", "tokens": [9007, 11, 577, 867, 4675, 264, 40533, 37, 307, 1228, 11, 439, 341, 4077, 1507, 13, 42317, 16367, 2709], "temperature": 0.0, "avg_logprob": -0.18610808849334717, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0001988069125218317}, {"id": 133, "seek": 84300, "start": 843.0, "end": 851.36, "text": " you the visibility across your cluster in terms of application, layer 7 return calls,", "tokens": [291, 264, 19883, 2108, 428, 13630, 294, 2115, 295, 3861, 11, 4583, 1614, 2736, 5498, 11], "temperature": 0.0, "avg_logprob": -0.16609299035719882, "compression_ratio": 1.6167400881057268, "no_speech_prob": 2.1840562112629414e-05}, {"id": 134, "seek": 84300, "start": 851.36, "end": 857.96, "text": " policy verdicts so allows versus drops so you can monitor on the cluster level the performance", "tokens": [3897, 33957, 82, 370, 4045, 5717, 11438, 370, 291, 393, 6002, 322, 264, 13630, 1496, 264, 3389], "temperature": 0.0, "avg_logprob": -0.16609299035719882, "compression_ratio": 1.6167400881057268, "no_speech_prob": 2.1840562112629414e-05}, {"id": 135, "seek": 84300, "start": 857.96, "end": 864.24, "text": " of your applications. And in some cases you run an operator so you may want to track the", "tokens": [295, 428, 5821, 13, 400, 294, 512, 3331, 291, 1190, 364, 12973, 370, 291, 815, 528, 281, 2837, 264], "temperature": 0.0, "avg_logprob": -0.16609299035719882, "compression_ratio": 1.6167400881057268, "no_speech_prob": 2.1840562112629414e-05}, {"id": 136, "seek": 84300, "start": 864.24, "end": 871.84, "text": " number of identities, how the cluster in general is behaving, API responses and such. And finally", "tokens": [1230, 295, 24239, 11, 577, 264, 13630, 294, 2674, 307, 35263, 11, 9362, 13019, 293, 1270, 13, 400, 2721], "temperature": 0.0, "avg_logprob": -0.16609299035719882, "compression_ratio": 1.6167400881057268, "no_speech_prob": 2.1840562112629414e-05}, {"id": 137, "seek": 87184, "start": 871.84, "end": 877.2800000000001, "text": " what we released just a few days ago thanks to Raphael who is also here is the Cillian", "tokens": [437, 321, 4736, 445, 257, 1326, 1708, 2057, 3231, 281, 49690, 338, 567, 307, 611, 510, 307, 264, 383, 373, 952], "temperature": 0.0, "avg_logprob": -0.10299051543812693, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.39540708612185e-05}, {"id": 138, "seek": 87184, "start": 877.2800000000001, "end": 885.8000000000001, "text": " policy verdict metrics dashboard which gives you the capability to get meaningful graphs", "tokens": [3897, 33957, 16367, 18342, 597, 2709, 291, 264, 13759, 281, 483, 10995, 24877], "temperature": 0.0, "avg_logprob": -0.10299051543812693, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.39540708612185e-05}, {"id": 139, "seek": 87184, "start": 885.8000000000001, "end": 892.9200000000001, "text": " if you have workloads actually hitting network policies you set. What I mean by that is that", "tokens": [498, 291, 362, 32452, 767, 8850, 3209, 7657, 291, 992, 13, 708, 286, 914, 538, 300, 307, 300], "temperature": 0.0, "avg_logprob": -0.10299051543812693, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.39540708612185e-05}, {"id": 140, "seek": 87184, "start": 892.9200000000001, "end": 897.6, "text": " when we work with customers with Cillian is they want to go to this micro segmentation", "tokens": [562, 321, 589, 365, 4581, 365, 383, 373, 952, 307, 436, 528, 281, 352, 281, 341, 4532, 9469, 399], "temperature": 0.0, "avg_logprob": -0.10299051543812693, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.39540708612185e-05}, {"id": 141, "seek": 89760, "start": 897.6, "end": 903.72, "text": " zero trust model and you can use obviously Hubble to monitor service-to-service communication", "tokens": [4018, 3361, 2316, 293, 291, 393, 764, 2745, 42317, 281, 6002, 2643, 12, 1353, 12, 39279, 6101], "temperature": 0.0, "avg_logprob": -0.14369577520033894, "compression_ratio": 1.65625, "no_speech_prob": 4.087257184437476e-05}, {"id": 142, "seek": 89760, "start": 903.72, "end": 910.84, "text": " and to see if traffic is allowed and denied. But this dashboard also is a very useful tool", "tokens": [293, 281, 536, 498, 6419, 307, 4350, 293, 17774, 13, 583, 341, 18342, 611, 307, 257, 588, 4420, 2290], "temperature": 0.0, "avg_logprob": -0.14369577520033894, "compression_ratio": 1.65625, "no_speech_prob": 4.087257184437476e-05}, {"id": 143, "seek": 89760, "start": 910.84, "end": 917.0, "text": " to confirm if you have either ingress or egress policies which are matching with your traffic.", "tokens": [281, 9064, 498, 291, 362, 2139, 3957, 735, 420, 308, 3091, 7657, 597, 366, 14324, 365, 428, 6419, 13], "temperature": 0.0, "avg_logprob": -0.14369577520033894, "compression_ratio": 1.65625, "no_speech_prob": 4.087257184437476e-05}, {"id": 144, "seek": 89760, "start": 917.0, "end": 923.24, "text": " So in this case we see green graphs which means that on ingress and egress we have matching", "tokens": [407, 294, 341, 1389, 321, 536, 3092, 24877, 597, 1355, 300, 322, 3957, 735, 293, 308, 3091, 321, 362, 14324], "temperature": 0.0, "avg_logprob": -0.14369577520033894, "compression_ratio": 1.65625, "no_speech_prob": 4.087257184437476e-05}, {"id": 145, "seek": 92324, "start": 923.24, "end": 929.96, "text": " traffic. The purple represents DNS matching traffic but if there's some yellow traffic", "tokens": [6419, 13, 440, 9656, 8855, 35153, 14324, 6419, 457, 498, 456, 311, 512, 5566, 6419], "temperature": 0.0, "avg_logprob": -0.12696530646884563, "compression_ratio": 1.7244094488188977, "no_speech_prob": 6.004428360029124e-05}, {"id": 146, "seek": 92324, "start": 929.96, "end": 935.48, "text": " that's either allow all match traffic which is too broadly which should trigger you to", "tokens": [300, 311, 2139, 2089, 439, 2995, 6419, 597, 307, 886, 19511, 597, 820, 7875, 291, 281], "temperature": 0.0, "avg_logprob": -0.12696530646884563, "compression_ratio": 1.7244094488188977, "no_speech_prob": 6.004428360029124e-05}, {"id": 147, "seek": 92324, "start": 935.48, "end": 941.0, "text": " get even better network policies to make sure that kind of flows are actually related to", "tokens": [483, 754, 1101, 3209, 7657, 281, 652, 988, 300, 733, 295, 12867, 366, 767, 4077, 281], "temperature": 0.0, "avg_logprob": -0.12696530646884563, "compression_ratio": 1.7244094488188977, "no_speech_prob": 6.004428360029124e-05}, {"id": 148, "seek": 92324, "start": 941.0, "end": 947.32, "text": " a network policy to ensure that both ingress and egress traffic is secured as such. If", "tokens": [257, 3209, 3897, 281, 5586, 300, 1293, 3957, 735, 293, 308, 3091, 6419, 307, 22905, 382, 1270, 13, 759], "temperature": 0.0, "avg_logprob": -0.12696530646884563, "compression_ratio": 1.7244094488188977, "no_speech_prob": 6.004428360029124e-05}, {"id": 149, "seek": 92324, "start": 947.32, "end": 951.6, "text": " you do so all the graphs will turn green and you know and you can confirm for that given", "tokens": [291, 360, 370, 439, 264, 24877, 486, 1261, 3092, 293, 291, 458, 293, 291, 393, 9064, 337, 300, 2212], "temperature": 0.0, "avg_logprob": -0.12696530646884563, "compression_ratio": 1.7244094488188977, "no_speech_prob": 6.004428360029124e-05}, {"id": 150, "seek": 95160, "start": 951.6, "end": 961.28, "text": " namespace that you have secured it. Alright I've prepared a little demo. This runs this", "tokens": [5288, 17940, 300, 291, 362, 22905, 309, 13, 2798, 286, 600, 4927, 257, 707, 10723, 13, 639, 6676, 341], "temperature": 0.0, "avg_logprob": -0.23402866450223056, "compression_ratio": 1.5972850678733033, "no_speech_prob": 2.143872006854508e-05}, {"id": 151, "seek": 95160, "start": 961.28, "end": 968.6, "text": " tenant jobs application I mentioned before. I'm running this on Kynes so just a simple", "tokens": [31000, 4782, 3861, 286, 2835, 949, 13, 286, 478, 2614, 341, 322, 591, 2534, 279, 370, 445, 257, 2199], "temperature": 0.0, "avg_logprob": -0.23402866450223056, "compression_ratio": 1.5972850678733033, "no_speech_prob": 2.143872006854508e-05}, {"id": 152, "seek": 95160, "start": 968.6, "end": 975.0400000000001, "text": " Kynes cluster on my laptop. I'm showing here the components of my application so it's you", "tokens": [591, 2534, 279, 13630, 322, 452, 10732, 13, 286, 478, 4099, 510, 264, 6677, 295, 452, 3861, 370, 309, 311, 291], "temperature": 0.0, "avg_logprob": -0.23402866450223056, "compression_ratio": 1.5972850678733033, "no_speech_prob": 2.143872006854508e-05}, {"id": 153, "seek": 95160, "start": 975.0400000000001, "end": 981.08, "text": " know a number of workloads I've shown before on the screen shot. To help me through this", "tokens": [458, 257, 1230, 295, 32452, 286, 600, 4898, 949, 322, 264, 2568, 3347, 13, 1407, 854, 385, 807, 341], "temperature": 0.0, "avg_logprob": -0.23402866450223056, "compression_ratio": 1.5972850678733033, "no_speech_prob": 2.143872006854508e-05}, {"id": 154, "seek": 98108, "start": 981.08, "end": 986.84, "text": " demo I've created a little script and what this does it only updates a helm chart for", "tokens": [10723, 286, 600, 2942, 257, 707, 5755, 293, 437, 341, 775, 309, 787, 9205, 257, 29554, 6927, 337], "temperature": 0.0, "avg_logprob": -0.17625095730736143, "compression_ratio": 1.449438202247191, "no_speech_prob": 3.820180063485168e-05}, {"id": 155, "seek": 98108, "start": 986.84, "end": 993.9200000000001, "text": " this application so it makes my workflow a lot easier. I don't have to enter commands", "tokens": [341, 3861, 370, 309, 1669, 452, 20993, 257, 688, 3571, 13, 286, 500, 380, 362, 281, 3242, 16901], "temperature": 0.0, "avg_logprob": -0.17625095730736143, "compression_ratio": 1.449438202247191, "no_speech_prob": 3.820180063485168e-05}, {"id": 156, "seek": 98108, "start": 993.9200000000001, "end": 1001.5200000000001, "text": " but we should see some things changing in a Grafana dashboard. Before I start this let", "tokens": [457, 321, 820, 536, 512, 721, 4473, 294, 257, 8985, 69, 2095, 18342, 13, 4546, 286, 722, 341, 718], "temperature": 0.0, "avg_logprob": -0.17625095730736143, "compression_ratio": 1.449438202247191, "no_speech_prob": 3.820180063485168e-05}, {"id": 157, "seek": 100152, "start": 1001.52, "end": 1011.0799999999999, "text": " me highlight the metrics so I need to log in. So I've installed Grafana, I've installed", "tokens": [385, 5078, 264, 16367, 370, 286, 643, 281, 3565, 294, 13, 407, 286, 600, 8899, 8985, 69, 2095, 11, 286, 600, 8899], "temperature": 0.0, "avg_logprob": -0.1524364948272705, "compression_ratio": 1.6118721461187215, "no_speech_prob": 5.192981916479766e-06}, {"id": 158, "seek": 100152, "start": 1011.0799999999999, "end": 1016.12, "text": " Tempo, I've installed Prometheus and configured Silium to export those metrics. So this is", "tokens": [8095, 2259, 11, 286, 600, 8899, 2114, 649, 42209, 293, 30538, 6943, 2197, 281, 10725, 729, 16367, 13, 407, 341, 307], "temperature": 0.0, "avg_logprob": -0.1524364948272705, "compression_ratio": 1.6118721461187215, "no_speech_prob": 5.192981916479766e-06}, {"id": 159, "seek": 100152, "start": 1016.12, "end": 1021.76, "text": " currently the performance of my application running on my Kynes cluster on my laptop.", "tokens": [4362, 264, 3389, 295, 452, 3861, 2614, 322, 452, 591, 2534, 279, 13630, 322, 452, 10732, 13], "temperature": 0.0, "avg_logprob": -0.1524364948272705, "compression_ratio": 1.6118721461187215, "no_speech_prob": 5.192981916479766e-06}, {"id": 160, "seek": 100152, "start": 1021.76, "end": 1029.0, "text": " So as you can see we have 100% success rate, we have incoming 100% and we also have good", "tokens": [407, 382, 291, 393, 536, 321, 362, 2319, 4, 2245, 3314, 11, 321, 362, 22341, 2319, 4, 293, 321, 611, 362, 665], "temperature": 0.0, "avg_logprob": -0.1524364948272705, "compression_ratio": 1.6118721461187215, "no_speech_prob": 5.192981916479766e-06}, {"id": 161, "seek": 102900, "start": 1029.0, "end": 1037.52, "text": " Grafana information for the performance of the application. Okay so let me start with", "tokens": [8985, 69, 2095, 1589, 337, 264, 3389, 295, 264, 3861, 13, 1033, 370, 718, 385, 722, 365], "temperature": 0.0, "avg_logprob": -0.22071694519560217, "compression_ratio": 1.4945652173913044, "no_speech_prob": 1.5393483408843167e-05}, {"id": 162, "seek": 102900, "start": 1037.52, "end": 1047.88, "text": " starting the script. Yes so I mentioned before that the Hubble metrics are available as soon", "tokens": [2891, 264, 5755, 13, 1079, 370, 286, 2835, 949, 300, 264, 42317, 16367, 366, 2435, 382, 2321], "temperature": 0.0, "avg_logprob": -0.22071694519560217, "compression_ratio": 1.4945652173913044, "no_speech_prob": 1.5393483408843167e-05}, {"id": 163, "seek": 102900, "start": 1047.88, "end": 1053.04, "text": " as you configure some kind of layer 7 Silium network policy because that triggers the collection", "tokens": [382, 291, 22162, 512, 733, 295, 4583, 1614, 6943, 2197, 3209, 3897, 570, 300, 22827, 264, 5765], "temperature": 0.0, "avg_logprob": -0.22071694519560217, "compression_ratio": 1.4945652173913044, "no_speech_prob": 1.5393483408843167e-05}, {"id": 164, "seek": 105304, "start": 1053.04, "end": 1061.84, "text": " of those metrics for layer 7 and I'm showing this but I will show this a bit better in", "tokens": [295, 729, 16367, 337, 4583, 1614, 293, 286, 478, 4099, 341, 457, 286, 486, 855, 341, 257, 857, 1101, 294], "temperature": 0.0, "avg_logprob": -0.12479485405815972, "compression_ratio": 1.6495327102803738, "no_speech_prob": 2.452021544741001e-05}, {"id": 165, "seek": 105304, "start": 1061.84, "end": 1068.36, "text": " a different window. So what I'm going to do now is I want to increase the request volume", "tokens": [257, 819, 4910, 13, 407, 437, 286, 478, 516, 281, 360, 586, 307, 286, 528, 281, 3488, 264, 5308, 5523], "temperature": 0.0, "avg_logprob": -0.12479485405815972, "compression_ratio": 1.6495327102803738, "no_speech_prob": 2.452021544741001e-05}, {"id": 166, "seek": 105304, "start": 1068.36, "end": 1072.76, "text": " so I'm configuring the crawler component to get more requests in my application. As you", "tokens": [370, 286, 478, 6662, 1345, 264, 13999, 1918, 6542, 281, 483, 544, 12475, 294, 452, 3861, 13, 1018, 291], "temperature": 0.0, "avg_logprob": -0.12479485405815972, "compression_ratio": 1.6495327102803738, "no_speech_prob": 2.452021544741001e-05}, {"id": 167, "seek": 105304, "start": 1072.76, "end": 1079.48, "text": " can see it's redeploying the crawler component. So this is something we should see in the", "tokens": [393, 536, 309, 311, 14328, 2384, 278, 264, 13999, 1918, 6542, 13, 407, 341, 307, 746, 321, 820, 536, 294, 264], "temperature": 0.0, "avg_logprob": -0.12479485405815972, "compression_ratio": 1.6495327102803738, "no_speech_prob": 2.452021544741001e-05}, {"id": 168, "seek": 107948, "start": 1079.48, "end": 1086.72, "text": " Grafana dashboard. While this is redeploying I can show the helm chart I'm using. You", "tokens": [8985, 69, 2095, 18342, 13, 3987, 341, 307, 14328, 2384, 278, 286, 393, 855, 264, 29554, 6927, 286, 478, 1228, 13, 509], "temperature": 0.0, "avg_logprob": -0.1363120528886903, "compression_ratio": 1.6125461254612545, "no_speech_prob": 3.439892680034973e-05}, {"id": 169, "seek": 107948, "start": 1086.72, "end": 1091.68, "text": " need to be a bit patient with me because it takes one minute before the graphics, the", "tokens": [643, 281, 312, 257, 857, 4537, 365, 385, 570, 309, 2516, 472, 3456, 949, 264, 11837, 11, 264], "temperature": 0.0, "avg_logprob": -0.1363120528886903, "compression_ratio": 1.6125461254612545, "no_speech_prob": 3.439892680034973e-05}, {"id": 170, "seek": 107948, "start": 1091.68, "end": 1096.56, "text": " Grafana dashboards are updated and you can actually see the impact of this new version", "tokens": [8985, 69, 2095, 8240, 17228, 366, 10588, 293, 291, 393, 767, 536, 264, 2712, 295, 341, 777, 3037], "temperature": 0.0, "avg_logprob": -0.1363120528886903, "compression_ratio": 1.6125461254612545, "no_speech_prob": 3.439892680034973e-05}, {"id": 171, "seek": 107948, "start": 1096.56, "end": 1102.24, "text": " of the application. So typically you configure Silium through a helm values file so in this", "tokens": [295, 264, 3861, 13, 407, 5850, 291, 22162, 6943, 2197, 807, 257, 29554, 4190, 3991, 370, 294, 341], "temperature": 0.0, "avg_logprob": -0.1363120528886903, "compression_ratio": 1.6125461254612545, "no_speech_prob": 3.439892680034973e-05}, {"id": 172, "seek": 107948, "start": 1102.24, "end": 1109.2, "text": " case on the operator component I've enabled metrics and Prometheus. On the Hubble side", "tokens": [1389, 322, 264, 12973, 6542, 286, 600, 15172, 16367, 293, 2114, 649, 42209, 13, 1282, 264, 42317, 1252], "temperature": 0.0, "avg_logprob": -0.1363120528886903, "compression_ratio": 1.6125461254612545, "no_speech_prob": 3.439892680034973e-05}, {"id": 173, "seek": 110920, "start": 1109.2, "end": 1115.2, "text": " I've configured Hubble relay to gather the metrics and also Prometheus and metrics. So", "tokens": [286, 600, 30538, 42317, 24214, 281, 5448, 264, 16367, 293, 611, 2114, 649, 42209, 293, 16367, 13, 407], "temperature": 0.0, "avg_logprob": -0.16782120677912346, "compression_ratio": 1.6195652173913044, "no_speech_prob": 4.156452268944122e-05}, {"id": 174, "seek": 110920, "start": 1115.2, "end": 1119.52, "text": " in this part it's very interesting because if you want to have layer 7 visibility you", "tokens": [294, 341, 644, 309, 311, 588, 1880, 570, 498, 291, 528, 281, 362, 4583, 1614, 19883, 291], "temperature": 0.0, "avg_logprob": -0.16782120677912346, "compression_ratio": 1.6195652173913044, "no_speech_prob": 4.156452268944122e-05}, {"id": 175, "seek": 110920, "start": 1119.52, "end": 1126.2, "text": " need to have specific metrics being enabled. This will be documented in the Silium IO website", "tokens": [643, 281, 362, 2685, 16367, 885, 15172, 13, 639, 486, 312, 23007, 294, 264, 6943, 2197, 39839, 3144], "temperature": 0.0, "avg_logprob": -0.16782120677912346, "compression_ratio": 1.6195652173913044, "no_speech_prob": 4.156452268944122e-05}, {"id": 176, "seek": 110920, "start": 1126.2, "end": 1131.48, "text": " once we have the new release ready. So as you can see we are matching HTTP V2, we have", "tokens": [1564, 321, 362, 264, 777, 4374, 1919, 13, 407, 382, 291, 393, 536, 321, 366, 14324, 33283, 691, 17, 11, 321, 362], "temperature": 0.0, "avg_logprob": -0.16782120677912346, "compression_ratio": 1.6195652173913044, "no_speech_prob": 4.156452268944122e-05}, {"id": 177, "seek": 110920, "start": 1131.48, "end": 1137.8, "text": " enabled exemplars, we are looking for labels in terms of context, source IP, source namespace", "tokens": [15172, 24112, 685, 11, 321, 366, 1237, 337, 16949, 294, 2115, 295, 4319, 11, 4009, 8671, 11, 4009, 5288, 17940], "temperature": 0.0, "avg_logprob": -0.16782120677912346, "compression_ratio": 1.6195652173913044, "no_speech_prob": 4.156452268944122e-05}, {"id": 178, "seek": 113780, "start": 1137.8, "end": 1144.3999999999999, "text": " etc. So these are important sets of labels you need to set and on the Prometheus side", "tokens": [5183, 13, 407, 613, 366, 1021, 6352, 295, 16949, 291, 643, 281, 992, 293, 322, 264, 2114, 649, 42209, 1252], "temperature": 0.0, "avg_logprob": -0.18275476056475973, "compression_ratio": 1.5608695652173914, "no_speech_prob": 2.4969864170998335e-05}, {"id": 179, "seek": 113780, "start": 1144.3999999999999, "end": 1150.9199999999998, "text": " we've enabled it to gather the graphs. The Silium network policy I mentioned before this", "tokens": [321, 600, 15172, 309, 281, 5448, 264, 24877, 13, 440, 6943, 2197, 3209, 3897, 286, 2835, 949, 341], "temperature": 0.0, "avg_logprob": -0.18275476056475973, "compression_ratio": 1.5608695652173914, "no_speech_prob": 2.4969864170998335e-05}, {"id": 180, "seek": 113780, "start": 1150.9199999999998, "end": 1159.8, "text": " is just a simple example. We allow everything within a namespace. We have enabled DNS visibility", "tokens": [307, 445, 257, 2199, 1365, 13, 492, 2089, 1203, 1951, 257, 5288, 17940, 13, 492, 362, 15172, 35153, 19883], "temperature": 0.0, "avg_logprob": -0.18275476056475973, "compression_ratio": 1.5608695652173914, "no_speech_prob": 2.4969864170998335e-05}, {"id": 181, "seek": 113780, "start": 1159.8, "end": 1167.76, "text": " so we're inspecting all DNS traffic to cube DNS that allows us to get visibility of the", "tokens": [370, 321, 434, 15018, 278, 439, 35153, 6419, 281, 13728, 35153, 300, 4045, 505, 281, 483, 19883, 295, 264], "temperature": 0.0, "avg_logprob": -0.18275476056475973, "compression_ratio": 1.5608695652173914, "no_speech_prob": 2.4969864170998335e-05}, {"id": 182, "seek": 116776, "start": 1167.76, "end": 1173.72, "text": " DNS queries. We've enabled ingress and egress for the purpose of the demo so we can also", "tokens": [35153, 24109, 13, 492, 600, 15172, 3957, 735, 293, 308, 3091, 337, 264, 4334, 295, 264, 10723, 370, 321, 393, 611], "temperature": 0.0, "avg_logprob": -0.137867949729742, "compression_ratio": 1.6045454545454545, "no_speech_prob": 3.591965651139617e-05}, {"id": 183, "seek": 116776, "start": 1173.72, "end": 1181.04, "text": " see that traffic. And what's important is that we have an empty or open rule HTTP which", "tokens": [536, 300, 6419, 13, 400, 437, 311, 1021, 307, 300, 321, 362, 364, 6707, 420, 1269, 4978, 33283, 597], "temperature": 0.0, "avg_logprob": -0.137867949729742, "compression_ratio": 1.6045454545454545, "no_speech_prob": 3.591965651139617e-05}, {"id": 184, "seek": 116776, "start": 1181.04, "end": 1187.12, "text": " allows us to see all traffic, it allows all traffic, but that triggers the collection", "tokens": [4045, 505, 281, 536, 439, 6419, 11, 309, 4045, 439, 6419, 11, 457, 300, 22827, 264, 5765], "temperature": 0.0, "avg_logprob": -0.137867949729742, "compression_ratio": 1.6045454545454545, "no_speech_prob": 3.591965651139617e-05}, {"id": 185, "seek": 116776, "start": 1187.12, "end": 1196.48, "text": " of metrics. Alright so on the demo side so it has deployed a new version of my application", "tokens": [295, 16367, 13, 2798, 370, 322, 264, 10723, 1252, 370, 309, 575, 17826, 257, 777, 3037, 295, 452, 3861], "temperature": 0.0, "avg_logprob": -0.137867949729742, "compression_ratio": 1.6045454545454545, "no_speech_prob": 3.591965651139617e-05}, {"id": 186, "seek": 119648, "start": 1196.48, "end": 1204.92, "text": " looking at my metrics. I can see incoming request volume increasing so you see already", "tokens": [1237, 412, 452, 16367, 13, 286, 393, 536, 22341, 5308, 5523, 5662, 370, 291, 536, 1217], "temperature": 0.0, "avg_logprob": -0.198510929689569, "compression_ratio": 1.6352201257861636, "no_speech_prob": 6.931429379619658e-05}, {"id": 187, "seek": 119648, "start": 1204.92, "end": 1211.88, "text": " an increase of volume. We also see requests by source and response codes increasing so", "tokens": [364, 3488, 295, 5523, 13, 492, 611, 536, 12475, 538, 4009, 293, 4134, 14211, 5662, 370], "temperature": 0.0, "avg_logprob": -0.198510929689569, "compression_ratio": 1.6352201257861636, "no_speech_prob": 6.931429379619658e-05}, {"id": 188, "seek": 119648, "start": 1211.88, "end": 1218.6, "text": " still 200, always fine, always good, just an increase of request per seconds. And also", "tokens": [920, 2331, 11, 1009, 2489, 11, 1009, 665, 11, 445, 364, 3488, 295, 5308, 680, 3949, 13, 400, 611], "temperature": 0.0, "avg_logprob": -0.198510929689569, "compression_ratio": 1.6352201257861636, "no_speech_prob": 6.931429379619658e-05}, {"id": 189, "seek": 121860, "start": 1218.6, "end": 1229.8799999999999, "text": " on the incoming side. Okay all good. Okay let's now deploy a new configuration of our", "tokens": [322, 264, 22341, 1252, 13, 1033, 439, 665, 13, 1033, 718, 311, 586, 7274, 257, 777, 11694, 295, 527], "temperature": 0.0, "avg_logprob": -0.14375312086464703, "compression_ratio": 1.5290697674418605, "no_speech_prob": 3.2160231057787314e-05}, {"id": 190, "seek": 121860, "start": 1229.8799999999999, "end": 1240.8, "text": " app and this app has an error. So let's see what we can see there. I can redeploying the", "tokens": [724, 293, 341, 724, 575, 364, 6713, 13, 407, 718, 311, 536, 437, 321, 393, 536, 456, 13, 286, 393, 14328, 2384, 278, 264], "temperature": 0.0, "avg_logprob": -0.14375312086464703, "compression_ratio": 1.5290697674418605, "no_speech_prob": 3.2160231057787314e-05}, {"id": 191, "seek": 121860, "start": 1240.8, "end": 1246.7199999999998, "text": " core API components and now we should be able to see the error rate increase as a result", "tokens": [4965, 9362, 6677, 293, 586, 321, 820, 312, 1075, 281, 536, 264, 6713, 3314, 3488, 382, 257, 1874], "temperature": 0.0, "avg_logprob": -0.14375312086464703, "compression_ratio": 1.5290697674418605, "no_speech_prob": 3.2160231057787314e-05}, {"id": 192, "seek": 124672, "start": 1246.72, "end": 1256.64, "text": " of core API configuration changing. So this will take one minute. Here I can select the", "tokens": [295, 4965, 9362, 11694, 4473, 13, 407, 341, 486, 747, 472, 3456, 13, 1692, 286, 393, 3048, 264], "temperature": 0.0, "avg_logprob": -0.13699312907893482, "compression_ratio": 1.59009009009009, "no_speech_prob": 2.1592531993519515e-05}, {"id": 193, "seek": 124672, "start": 1256.64, "end": 1262.4, "text": " destination workload so I can switch between core API or the loader component to see how", "tokens": [12236, 20139, 370, 286, 393, 3679, 1296, 4965, 9362, 420, 264, 3677, 260, 6542, 281, 536, 577], "temperature": 0.0, "avg_logprob": -0.13699312907893482, "compression_ratio": 1.59009009009009, "no_speech_prob": 2.1592531993519515e-05}, {"id": 194, "seek": 124672, "start": 1262.4, "end": 1267.28, "text": " the traffic for that destination is matching and how it's performing. Let's give it a few", "tokens": [264, 6419, 337, 300, 12236, 307, 14324, 293, 577, 309, 311, 10205, 13, 961, 311, 976, 309, 257, 1326], "temperature": 0.0, "avg_logprob": -0.13699312907893482, "compression_ratio": 1.59009009009009, "no_speech_prob": 2.1592531993519515e-05}, {"id": 195, "seek": 124672, "start": 1267.28, "end": 1274.4, "text": " seconds to actually show. What I'm looking for is the incoming request to access rate.", "tokens": [3949, 281, 767, 855, 13, 708, 286, 478, 1237, 337, 307, 264, 22341, 5308, 281, 2105, 3314, 13], "temperature": 0.0, "avg_logprob": -0.13699312907893482, "compression_ratio": 1.59009009009009, "no_speech_prob": 2.1592531993519515e-05}, {"id": 196, "seek": 127440, "start": 1274.4, "end": 1279.5600000000002, "text": " Obviously this application version has an error so the success rate will be lower than", "tokens": [7580, 341, 3861, 3037, 575, 364, 6713, 370, 264, 2245, 3314, 486, 312, 3126, 813], "temperature": 0.0, "avg_logprob": -0.372439233880294, "compression_ratio": 1.131578947368421, "no_speech_prob": 1.3100429896439891e-05}, {"id": 197, "seek": 127956, "start": 1279.56, "end": 1309.52, "text": " before. It's running. It's always a bit, takes a bit longer than I wanted. There we", "tokens": [949, 13, 467, 311, 2614, 13, 467, 311, 1009, 257, 857, 11, 2516, 257, 857, 2854, 813, 286, 1415, 13, 821, 321], "temperature": 0.0, "avg_logprob": -0.36503087557279146, "compression_ratio": 1.0921052631578947, "no_speech_prob": 0.0002615120611153543}, {"id": 198, "seek": 130952, "start": 1309.52, "end": 1325.96, "text": " have it. In the meantime I'll already start the next step so I don't have you waiting.", "tokens": [362, 309, 13, 682, 264, 14991, 286, 603, 1217, 722, 264, 958, 1823, 370, 286, 500, 380, 362, 291, 3806, 13], "temperature": 0.0, "avg_logprob": -0.15873253345489502, "compression_ratio": 1.6091954022988506, "no_speech_prob": 5.1436800276860595e-05}, {"id": 199, "seek": 130952, "start": 1325.96, "end": 1331.4, "text": " So here you see that the success rate is decreasing because of this faulty version of my application", "tokens": [407, 510, 291, 536, 300, 264, 2245, 3314, 307, 23223, 570, 295, 341, 2050, 5773, 3037, 295, 452, 3861], "temperature": 0.0, "avg_logprob": -0.15873253345489502, "compression_ratio": 1.6091954022988506, "no_speech_prob": 5.1436800276860595e-05}, {"id": 200, "seek": 130952, "start": 1331.4, "end": 1337.68, "text": " so I can really see there's something wrong with my application and as application developer", "tokens": [370, 286, 393, 534, 536, 456, 311, 746, 2085, 365, 452, 3861, 293, 382, 3861, 10754], "temperature": 0.0, "avg_logprob": -0.15873253345489502, "compression_ratio": 1.6091954022988506, "no_speech_prob": 5.1436800276860595e-05}, {"id": 201, "seek": 133768, "start": 1337.68, "end": 1343.72, "text": " or owning this namespace I should now be able to investigate what's going on. This also", "tokens": [420, 29820, 341, 5288, 17940, 286, 820, 586, 312, 1075, 281, 15013, 437, 311, 516, 322, 13, 639, 611], "temperature": 0.0, "avg_logprob": -0.21016244888305663, "compression_ratio": 1.5139664804469273, "no_speech_prob": 5.697409505955875e-05}, {"id": 202, "seek": 133768, "start": 1343.72, "end": 1349.88, "text": " means that here on the incoming request to source and response code I would see the resumes", "tokens": [1355, 300, 510, 322, 264, 22341, 5308, 281, 4009, 293, 4134, 3089, 286, 576, 536, 264, 48068], "temperature": 0.0, "avg_logprob": -0.21016244888305663, "compression_ratio": 1.5139664804469273, "no_speech_prob": 5.697409505955875e-05}, {"id": 203, "seek": 133768, "start": 1349.88, "end": 1357.44, "text": " components showing 500 and 503 error return codes which triggers me to check that component", "tokens": [6677, 4099, 5923, 293, 2625, 18, 6713, 2736, 14211, 597, 22827, 385, 281, 1520, 300, 6542], "temperature": 0.0, "avg_logprob": -0.21016244888305663, "compression_ratio": 1.5139664804469273, "no_speech_prob": 5.697409505955875e-05}, {"id": 204, "seek": 135744, "start": 1357.44, "end": 1368.56, "text": " and communication between those components. Also on the destination site. All right. So", "tokens": [293, 6101, 1296, 729, 6677, 13, 2743, 322, 264, 12236, 3621, 13, 1057, 558, 13, 407], "temperature": 0.0, "avg_logprob": -0.15214048805883376, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.1857400750159286e-05}, {"id": 205, "seek": 135744, "start": 1368.56, "end": 1378.64, "text": " now I've introduced a new version and what this does is changing the request duration.", "tokens": [586, 286, 600, 7268, 257, 777, 3037, 293, 437, 341, 775, 307, 4473, 264, 5308, 16365, 13], "temperature": 0.0, "avg_logprob": -0.15214048805883376, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.1857400750159286e-05}, {"id": 206, "seek": 135744, "start": 1378.64, "end": 1383.1200000000001, "text": " So again a new version of the application and let's see how we can monitor this performance", "tokens": [407, 797, 257, 777, 3037, 295, 264, 3861, 293, 718, 311, 536, 577, 321, 393, 6002, 341, 3389], "temperature": 0.0, "avg_logprob": -0.15214048805883376, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.1857400750159286e-05}, {"id": 207, "seek": 138312, "start": 1383.12, "end": 1388.1599999999999, "text": " of the application in Grafana. So let's check the request duration increase as a result", "tokens": [295, 264, 3861, 294, 8985, 69, 2095, 13, 407, 718, 311, 1520, 264, 5308, 16365, 3488, 382, 257, 1874], "temperature": 0.0, "avg_logprob": -0.14481722513834636, "compression_ratio": 1.356060606060606, "no_speech_prob": 7.079415809130296e-05}, {"id": 208, "seek": 138312, "start": 1388.1599999999999, "end": 1399.12, "text": " of core API configuration changing. Okay. So let's use here. So I'm monitoring HTTP request", "tokens": [295, 4965, 9362, 11694, 4473, 13, 1033, 13, 407, 718, 311, 764, 510, 13, 407, 286, 478, 11028, 33283, 5308], "temperature": 0.0, "avg_logprob": -0.14481722513834636, "compression_ratio": 1.356060606060606, "no_speech_prob": 7.079415809130296e-05}, {"id": 209, "seek": 139912, "start": 1399.12, "end": 1415.32, "text": " duration by source and destination. So if the demo works well we see an increase there.", "tokens": [16365, 538, 4009, 293, 12236, 13, 407, 498, 264, 10723, 1985, 731, 321, 536, 364, 3488, 456, 13], "temperature": 0.0, "avg_logprob": -0.22074222564697266, "compression_ratio": 1.1012658227848102, "no_speech_prob": 0.00012315125786699355}, {"id": 210, "seek": 141532, "start": 1415.32, "end": 1444.1599999999999, "text": " Okay. It takes a bit too long. I'm comfortable with but it should be there any minute. It", "tokens": [1033, 13, 467, 2516, 257, 857, 886, 938, 13, 286, 478, 4619, 365, 457, 309, 820, 312, 456, 604, 3456, 13, 467], "temperature": 0.0, "avg_logprob": -0.4237419275137094, "compression_ratio": 1.0595238095238095, "no_speech_prob": 0.0006206427933648229}, {"id": 211, "seek": 144416, "start": 1444.16, "end": 1456.44, "text": " should appear any moment. Let me just... In the meantime I will deploy a new version of", "tokens": [820, 4204, 604, 1623, 13, 961, 385, 445, 485, 682, 264, 14991, 286, 486, 7274, 257, 777, 3037, 295], "temperature": 0.0, "avg_logprob": -0.18084670651343562, "compression_ratio": 1.6287425149700598, "no_speech_prob": 2.326299909327645e-05}, {"id": 212, "seek": 144416, "start": 1456.44, "end": 1462.48, "text": " the application which also introduces tracing. So again for tracing to be supported you at", "tokens": [264, 3861, 597, 611, 31472, 25262, 13, 407, 797, 337, 25262, 281, 312, 8104, 291, 412], "temperature": 0.0, "avg_logprob": -0.18084670651343562, "compression_ratio": 1.6287425149700598, "no_speech_prob": 2.326299909327645e-05}, {"id": 213, "seek": 144416, "start": 1462.48, "end": 1468.3200000000002, "text": " this moment your application needs to support that. So in this case I'll deploy a new version", "tokens": [341, 1623, 428, 3861, 2203, 281, 1406, 300, 13, 407, 294, 341, 1389, 286, 603, 7274, 257, 777, 3037], "temperature": 0.0, "avg_logprob": -0.18084670651343562, "compression_ratio": 1.6287425149700598, "no_speech_prob": 2.326299909327645e-05}, {"id": 214, "seek": 146832, "start": 1468.32, "end": 1476.8799999999999, "text": " of this application to support tracing. And this is using open telemetry. So let's deploy", "tokens": [295, 341, 3861, 281, 1406, 25262, 13, 400, 341, 307, 1228, 1269, 4304, 5537, 627, 13, 407, 718, 311, 7274], "temperature": 0.0, "avg_logprob": -0.14843837949964736, "compression_ratio": 1.4108527131782946, "no_speech_prob": 6.514924461953342e-05}, {"id": 215, "seek": 146832, "start": 1476.8799999999999, "end": 1485.72, "text": " that in the meantime. That's deploying. In the meantime I can check how the request duration", "tokens": [300, 294, 264, 14991, 13, 663, 311, 34198, 13, 682, 264, 14991, 286, 393, 1520, 577, 264, 5308, 16365], "temperature": 0.0, "avg_logprob": -0.14843837949964736, "compression_ratio": 1.4108527131782946, "no_speech_prob": 6.514924461953342e-05}, {"id": 216, "seek": 148572, "start": 1485.72, "end": 1500.0, "text": " is doing. Okay. This part is not working yet but we should see a request duration increase.", "tokens": [307, 884, 13, 1033, 13, 639, 644, 307, 406, 1364, 1939, 457, 321, 820, 536, 257, 5308, 16365, 3488, 13], "temperature": 0.0, "avg_logprob": -0.22015120058643575, "compression_ratio": 1.3120567375886525, "no_speech_prob": 8.695320138940588e-05}, {"id": 217, "seek": 148572, "start": 1500.0, "end": 1508.3600000000001, "text": " Oh God yeah thanks. That doesn't help. I clicked on something. Ah yes thank you so much. Yeah", "tokens": [876, 1265, 1338, 3231, 13, 663, 1177, 380, 854, 13, 286, 23370, 322, 746, 13, 2438, 2086, 1309, 291, 370, 709, 13, 865], "temperature": 0.0, "avg_logprob": -0.22015120058643575, "compression_ratio": 1.3120567375886525, "no_speech_prob": 8.695320138940588e-05}, {"id": 218, "seek": 150836, "start": 1508.36, "end": 1516.6799999999998, "text": " here you can see the request duration increasing. And I just deployed a new version of my application", "tokens": [510, 291, 393, 536, 264, 5308, 16365, 5662, 13, 400, 286, 445, 17826, 257, 777, 3037, 295, 452, 3861], "temperature": 0.0, "avg_logprob": -0.16391718955267043, "compression_ratio": 1.665158371040724, "no_speech_prob": 3.731396282091737e-05}, {"id": 219, "seek": 150836, "start": 1516.6799999999998, "end": 1522.4399999999998, "text": " which supports tracing using open telemetry. And then you already can see that I have these", "tokens": [597, 9346, 25262, 1228, 1269, 4304, 5537, 627, 13, 400, 550, 291, 1217, 393, 536, 300, 286, 362, 613], "temperature": 0.0, "avg_logprob": -0.16391718955267043, "compression_ratio": 1.665158371040724, "no_speech_prob": 3.731396282091737e-05}, {"id": 220, "seek": 150836, "start": 1522.4399999999998, "end": 1529.8799999999999, "text": " exemplars appearing. So I now can not only inspect HTTP request duration but I can also", "tokens": [24112, 685, 19870, 13, 407, 286, 586, 393, 406, 787, 15018, 33283, 5308, 16365, 457, 286, 393, 611], "temperature": 0.0, "avg_logprob": -0.16391718955267043, "compression_ratio": 1.665158371040724, "no_speech_prob": 3.731396282091737e-05}, {"id": 221, "seek": 150836, "start": 1529.8799999999999, "end": 1535.76, "text": " inspect specific traces and exemplars. So if you click on this little box you get this", "tokens": [15018, 2685, 26076, 293, 24112, 685, 13, 407, 498, 291, 2052, 322, 341, 707, 2424, 291, 483, 341], "temperature": 0.0, "avg_logprob": -0.16391718955267043, "compression_ratio": 1.665158371040724, "no_speech_prob": 3.731396282091737e-05}, {"id": 222, "seek": 153576, "start": 1535.76, "end": 1542.12, "text": " window. You can get valuable information about this trace point. And then you can query it", "tokens": [4910, 13, 509, 393, 483, 8263, 1589, 466, 341, 13508, 935, 13, 400, 550, 291, 393, 14581, 309], "temperature": 0.0, "avg_logprob": -0.14350238376193578, "compression_ratio": 1.6542056074766356, "no_speech_prob": 4.6969584218459204e-05}, {"id": 223, "seek": 153576, "start": 1542.12, "end": 1551.16, "text": " with track tempo. Yep let's leave this side. So here you can see a specific trace ID and", "tokens": [365, 2837, 8972, 13, 7010, 718, 311, 1856, 341, 1252, 13, 407, 510, 291, 393, 536, 257, 2685, 13508, 7348, 293], "temperature": 0.0, "avg_logprob": -0.14350238376193578, "compression_ratio": 1.6542056074766356, "no_speech_prob": 4.6969584218459204e-05}, {"id": 224, "seek": 153576, "start": 1551.16, "end": 1557.0, "text": " you can see a node graph. So this is also nice. You can see between nodes what's going", "tokens": [291, 393, 536, 257, 9984, 4295, 13, 407, 341, 307, 611, 1481, 13, 509, 393, 536, 1296, 13891, 437, 311, 516], "temperature": 0.0, "avg_logprob": -0.14350238376193578, "compression_ratio": 1.6542056074766356, "no_speech_prob": 4.6969584218459204e-05}, {"id": 225, "seek": 153576, "start": 1557.0, "end": 1564.2, "text": " on and you see highlighted in red here what has a high latency as such. And here we can", "tokens": [322, 293, 291, 536, 17173, 294, 2182, 510, 437, 575, 257, 1090, 27043, 382, 1270, 13, 400, 510, 321, 393], "temperature": 0.0, "avg_logprob": -0.14350238376193578, "compression_ratio": 1.6542056074766356, "no_speech_prob": 4.6969584218459204e-05}, {"id": 226, "seek": 156420, "start": 1564.2, "end": 1577.2, "text": " see that in this specific API call there is an error. So a post call and it has some events", "tokens": [536, 300, 294, 341, 2685, 9362, 818, 456, 307, 364, 6713, 13, 407, 257, 2183, 818, 293, 309, 575, 512, 3931], "temperature": 0.0, "avg_logprob": -0.1512637436389923, "compression_ratio": 1.5885714285714285, "no_speech_prob": 2.5386971174157225e-05}, {"id": 227, "seek": 156420, "start": 1577.2, "end": 1582.4, "text": " exception, random error. So something is wrong with my application. So this enables me as", "tokens": [11183, 11, 4974, 6713, 13, 407, 746, 307, 2085, 365, 452, 3861, 13, 407, 341, 17077, 385, 382], "temperature": 0.0, "avg_logprob": -0.1512637436389923, "compression_ratio": 1.5885714285714285, "no_speech_prob": 2.5386971174157225e-05}, {"id": 228, "seek": 156420, "start": 1582.4, "end": 1590.48, "text": " an application owner to troubleshoot my application effectively. So this concludes the demo. Let", "tokens": [364, 3861, 7289, 281, 15379, 24467, 452, 3861, 8659, 13, 407, 341, 24643, 264, 10723, 13, 961], "temperature": 0.0, "avg_logprob": -0.1512637436389923, "compression_ratio": 1.5885714285714285, "no_speech_prob": 2.5386971174157225e-05}, {"id": 229, "seek": 159048, "start": 1590.48, "end": 1598.44, "text": " me quickly move to here. All right, so if you want to know more how to configure Cilium", "tokens": [385, 2661, 1286, 281, 510, 13, 1057, 558, 11, 370, 498, 291, 528, 281, 458, 544, 577, 281, 22162, 383, 388, 2197], "temperature": 0.0, "avg_logprob": -0.1780964917150037, "compression_ratio": 1.751937984496124, "no_speech_prob": 5.142149166204035e-05}, {"id": 230, "seek": 159048, "start": 1598.44, "end": 1605.56, "text": " to enable metrics, how to configure Cilium with the right values for layer 7 monitoring,", "tokens": [281, 9528, 16367, 11, 577, 281, 22162, 383, 388, 2197, 365, 264, 558, 4190, 337, 4583, 1614, 11028, 11], "temperature": 0.0, "avg_logprob": -0.1780964917150037, "compression_ratio": 1.751937984496124, "no_speech_prob": 5.142149166204035e-05}, {"id": 231, "seek": 159048, "start": 1605.56, "end": 1610.76, "text": " I recommend to read the documentation on Cilium.io. If you're using Cilium or planning to use", "tokens": [286, 2748, 281, 1401, 264, 14333, 322, 383, 388, 2197, 13, 1004, 13, 759, 291, 434, 1228, 383, 388, 2197, 420, 5038, 281, 764], "temperature": 0.0, "avg_logprob": -0.1780964917150037, "compression_ratio": 1.751937984496124, "no_speech_prob": 5.142149166204035e-05}, {"id": 232, "seek": 159048, "start": 1610.76, "end": 1614.64, "text": " Cilium and you have questions go to our Slack channel. We're happy to help you there. The", "tokens": [383, 388, 2197, 293, 291, 362, 1651, 352, 281, 527, 37211, 2269, 13, 492, 434, 2055, 281, 854, 291, 456, 13, 440], "temperature": 0.0, "avg_logprob": -0.1780964917150037, "compression_ratio": 1.751937984496124, "no_speech_prob": 5.142149166204035e-05}, {"id": 233, "seek": 159048, "start": 1614.64, "end": 1619.6, "text": " community is out there and very helpful answering questions. If you want to know more about", "tokens": [1768, 307, 484, 456, 293, 588, 4961, 13430, 1651, 13, 759, 291, 528, 281, 458, 544, 466], "temperature": 0.0, "avg_logprob": -0.1780964917150037, "compression_ratio": 1.751937984496124, "no_speech_prob": 5.142149166204035e-05}, {"id": 234, "seek": 161960, "start": 1619.6, "end": 1627.32, "text": " eBPF go to eBPF.io. We also have released or close to release a lab with this kind of dashboards", "tokens": [308, 33, 47, 37, 352, 281, 308, 33, 47, 37, 13, 1004, 13, 492, 611, 362, 4736, 420, 1998, 281, 4374, 257, 2715, 365, 341, 733, 295, 8240, 17228], "temperature": 0.0, "avg_logprob": -0.2301920006074101, "compression_ratio": 1.5081967213114753, "no_speech_prob": 8.966383757069707e-05}, {"id": 235, "seek": 161960, "start": 1627.32, "end": 1632.6799999999998, "text": " as well. So feel free to check them out at isovenom.com. And if you want to know more", "tokens": [382, 731, 13, 407, 841, 1737, 281, 1520, 552, 484, 412, 307, 78, 553, 298, 13, 1112, 13, 400, 498, 291, 528, 281, 458, 544], "temperature": 0.0, "avg_logprob": -0.2301920006074101, "compression_ratio": 1.5081967213114753, "no_speech_prob": 8.966383757069707e-05}, {"id": 236, "seek": 161960, "start": 1632.6799999999998, "end": 1639.52, "text": " about isovenom.com or you may want to contribute, we also have open positions for engineering", "tokens": [466, 307, 78, 553, 298, 13, 1112, 420, 291, 815, 528, 281, 10586, 11, 321, 611, 362, 1269, 8432, 337, 7043], "temperature": 0.0, "avg_logprob": -0.2301920006074101, "compression_ratio": 1.5081967213114753, "no_speech_prob": 8.966383757069707e-05}, {"id": 237, "seek": 163952, "start": 1639.52, "end": 1650.04, "text": " as such. So if you want to know more, please check us out. I'm happy to take questions.", "tokens": [382, 1270, 13, 407, 498, 291, 528, 281, 458, 544, 11, 1767, 1520, 505, 484, 13, 286, 478, 2055, 281, 747, 1651, 13], "temperature": 0.0, "avg_logprob": -0.23338547531439333, "compression_ratio": 1.3014705882352942, "no_speech_prob": 0.0002296808670507744}, {"id": 238, "seek": 163952, "start": 1650.04, "end": 1662.2, "text": " Any questions? Hello. Thank you for your talk. Is it possible in the service graph of the", "tokens": [2639, 1651, 30, 2425, 13, 1044, 291, 337, 428, 751, 13, 1119, 309, 1944, 294, 264, 2643, 4295, 295, 264], "temperature": 0.0, "avg_logprob": -0.23338547531439333, "compression_ratio": 1.3014705882352942, "no_speech_prob": 0.0002296808670507744}, {"id": 239, "seek": 166220, "start": 1662.2, "end": 1674.64, "text": " Hubbell UI to show transitive dependencies of services with the tracing enabled?", "tokens": [18986, 7100, 15682, 281, 855, 1145, 2187, 36606, 295, 3328, 365, 264, 25262, 15172, 30], "temperature": 0.0, "avg_logprob": -0.2028713544209798, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.00012353097554296255}, {"id": 240, "seek": 166220, "start": 1674.64, "end": 1681.0800000000002, "text": " So with Hubbell UI, the open source version, you will see the service connectivity only.", "tokens": [407, 365, 18986, 7100, 15682, 11, 264, 1269, 4009, 3037, 11, 291, 486, 536, 264, 2643, 21095, 787, 13], "temperature": 0.0, "avg_logprob": -0.2028713544209798, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.00012353097554296255}, {"id": 241, "seek": 166220, "start": 1681.0800000000002, "end": 1688.8, "text": " So that related information is not integrated in Hubbell as such. So you would switch between", "tokens": [407, 300, 4077, 1589, 307, 406, 10919, 294, 18986, 7100, 382, 1270, 13, 407, 291, 576, 3679, 1296], "temperature": 0.0, "avg_logprob": -0.2028713544209798, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.00012353097554296255}, {"id": 242, "seek": 168880, "start": 1688.8, "end": 1694.96, "text": " Hubbell and Grafana to get that information. On the enterprise, we have built in dashboards", "tokens": [18986, 7100, 293, 8985, 69, 2095, 281, 483, 300, 1589, 13, 1282, 264, 14132, 11, 321, 362, 3094, 294, 8240, 17228], "temperature": 0.0, "avg_logprob": -0.1990296672767317, "compression_ratio": 1.55, "no_speech_prob": 0.0005293564754538238}, {"id": 243, "seek": 168880, "start": 1694.96, "end": 1706.1599999999999, "text": " for getting that specific areas of monitoring. So let's say application or node performance", "tokens": [337, 1242, 300, 2685, 3179, 295, 11028, 13, 407, 718, 311, 584, 3861, 420, 9984, 3389], "temperature": 0.0, "avg_logprob": -0.1990296672767317, "compression_ratio": 1.55, "no_speech_prob": 0.0005293564754538238}, {"id": 244, "seek": 168880, "start": 1706.1599999999999, "end": 1711.2, "text": " or cluster-wide performance. We have some dashboards which should quickly highlight performance", "tokens": [420, 13630, 12, 7990, 3389, 13, 492, 362, 512, 8240, 17228, 597, 820, 2661, 5078, 3389], "temperature": 0.0, "avg_logprob": -0.1990296672767317, "compression_ratio": 1.55, "no_speech_prob": 0.0005293564754538238}, {"id": 245, "seek": 168880, "start": 1711.2, "end": 1713.9199999999998, "text": " issues there. Okay. Thank you.", "tokens": [2663, 456, 13, 1033, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.1990296672767317, "compression_ratio": 1.55, "no_speech_prob": 0.0005293564754538238}, {"id": 246, "seek": 171392, "start": 1713.92, "end": 1721.44, "text": " Any other questions? Hello. Did you measure the impact of metrics,", "tokens": [2639, 661, 1651, 30, 2425, 13, 2589, 291, 3481, 264, 2712, 295, 16367, 11], "temperature": 0.0, "avg_logprob": -0.27100533878102023, "compression_ratio": 1.4663677130044843, "no_speech_prob": 0.001185704837553203}, {"id": 247, "seek": 171392, "start": 1721.44, "end": 1727.0, "text": " recollect of metrics on network performance? Yeah. We do have some performance-related", "tokens": [39495, 557, 295, 16367, 322, 3209, 3389, 30, 865, 13, 492, 360, 362, 512, 3389, 12, 12004], "temperature": 0.0, "avg_logprob": -0.27100533878102023, "compression_ratio": 1.4663677130044843, "no_speech_prob": 0.001185704837553203}, {"id": 248, "seek": 171392, "start": 1727.0, "end": 1733.2, "text": " reports on sodium.io. So yes, it comes with a price. Using EBPF, we keep it as low as", "tokens": [7122, 322, 20265, 13, 1004, 13, 407, 2086, 11, 309, 1487, 365, 257, 3218, 13, 11142, 50148, 47, 37, 11, 321, 1066, 309, 382, 2295, 382], "temperature": 0.0, "avg_logprob": -0.27100533878102023, "compression_ratio": 1.4663677130044843, "no_speech_prob": 0.001185704837553203}, {"id": 249, "seek": 171392, "start": 1733.2, "end": 1738.92, "text": " possible. It's a very hard question to answer because it will depend on which flags you", "tokens": [1944, 13, 467, 311, 257, 588, 1152, 1168, 281, 1867, 570, 309, 486, 5672, 322, 597, 23265, 291], "temperature": 0.0, "avg_logprob": -0.27100533878102023, "compression_ratio": 1.4663677130044843, "no_speech_prob": 0.001185704837553203}, {"id": 250, "seek": 173892, "start": 1738.92, "end": 1746.6000000000001, "text": " configure. So if you have full layer 7 visibility across all workloads in your cluster, of course", "tokens": [22162, 13, 407, 498, 291, 362, 1577, 4583, 1614, 19883, 2108, 439, 32452, 294, 428, 13630, 11, 295, 1164], "temperature": 0.0, "avg_logprob": -0.12143844106922978, "compression_ratio": 1.5847457627118644, "no_speech_prob": 3.239251964259893e-05}, {"id": 251, "seek": 173892, "start": 1746.6000000000001, "end": 1753.24, "text": " it will have some performance impact for sure. Yes. Using EBPF, we keep it as low as possible.", "tokens": [309, 486, 362, 512, 3389, 2712, 337, 988, 13, 1079, 13, 11142, 50148, 47, 37, 11, 321, 1066, 309, 382, 2295, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.12143844106922978, "compression_ratio": 1.5847457627118644, "no_speech_prob": 3.239251964259893e-05}, {"id": 252, "seek": 173892, "start": 1753.24, "end": 1756.76, "text": " But yeah, it's a multi-dimensional question. It depends on the amount of traffic, the amount", "tokens": [583, 1338, 11, 309, 311, 257, 4825, 12, 18759, 1168, 13, 467, 5946, 322, 264, 2372, 295, 6419, 11, 264, 2372], "temperature": 0.0, "avg_logprob": -0.12143844106922978, "compression_ratio": 1.5847457627118644, "no_speech_prob": 3.239251964259893e-05}, {"id": 253, "seek": 173892, "start": 1756.76, "end": 1764.5600000000002, "text": " of applications, how big your cluster is, et cetera. So we have some performance reports", "tokens": [295, 5821, 11, 577, 955, 428, 13630, 307, 11, 1030, 11458, 13, 407, 321, 362, 512, 3389, 7122], "temperature": 0.0, "avg_logprob": -0.12143844106922978, "compression_ratio": 1.5847457627118644, "no_speech_prob": 3.239251964259893e-05}, {"id": 254, "seek": 176456, "start": 1764.56, "end": 1770.32, "text": " you can check. So that's 500 nodes, 1,000 network policies, helpful, enabled, and you", "tokens": [291, 393, 1520, 13, 407, 300, 311, 5923, 13891, 11, 502, 11, 1360, 3209, 7657, 11, 4961, 11, 15172, 11, 293, 291], "temperature": 0.0, "avg_logprob": -0.24628104233160253, "compression_ratio": 1.4485981308411215, "no_speech_prob": 0.00040551117854192853}, {"id": 255, "seek": 176456, "start": 1770.32, "end": 1775.6799999999998, "text": " get some feel of how memory consumption and processing is with Selium. So feel free to", "tokens": [483, 512, 841, 295, 577, 4675, 12126, 293, 9007, 307, 365, 10736, 2197, 13, 407, 841, 1737, 281], "temperature": 0.0, "avg_logprob": -0.24628104233160253, "compression_ratio": 1.4485981308411215, "no_speech_prob": 0.00040551117854192853}, {"id": 256, "seek": 176456, "start": 1775.6799999999998, "end": 1782.96, "text": " check them out on the selium.io website. But in practice, it's a multi-dimensional story.", "tokens": [1520, 552, 484, 322, 264, 5851, 2197, 13, 1004, 3144, 13, 583, 294, 3124, 11, 309, 311, 257, 4825, 12, 18759, 1657, 13], "temperature": 0.0, "avg_logprob": -0.24628104233160253, "compression_ratio": 1.4485981308411215, "no_speech_prob": 0.00040551117854192853}, {"id": 257, "seek": 176456, "start": 1782.96, "end": 1787.1599999999999, "text": " Welcome. Any other questions in the background?", "tokens": [4027, 13, 2639, 661, 1651, 294, 264, 3678, 30], "temperature": 0.0, "avg_logprob": -0.24628104233160253, "compression_ratio": 1.4485981308411215, "no_speech_prob": 0.00040551117854192853}, {"id": 258, "seek": 178716, "start": 1787.16, "end": 1796.1200000000001, "text": " Hi. Thanks for the talk. A couple of questions about the integration of Selium on AQS and", "tokens": [2421, 13, 2561, 337, 264, 751, 13, 316, 1916, 295, 1651, 466, 264, 10980, 295, 10736, 2197, 322, 316, 48, 50, 293], "temperature": 0.0, "avg_logprob": -0.2671035853299228, "compression_ratio": 1.288888888888889, "no_speech_prob": 0.0031009982340037823}, {"id": 259, "seek": 178716, "start": 1796.1200000000001, "end": 1805.92, "text": " GKE. Is there anything specific regarding those implementations or are all the tools", "tokens": [460, 8522, 13, 1119, 456, 1340, 2685, 8595, 729, 4445, 763, 420, 366, 439, 264, 3873], "temperature": 0.0, "avg_logprob": -0.2671035853299228, "compression_ratio": 1.288888888888889, "no_speech_prob": 0.0031009982340037823}, {"id": 260, "seek": 180592, "start": 1805.92, "end": 1817.8000000000002, "text": " that work natively on these kind of clusters? And second questions regarding above UI, is", "tokens": [300, 589, 8470, 356, 322, 613, 733, 295, 23313, 30, 400, 1150, 1651, 8595, 3673, 15682, 11, 307], "temperature": 0.0, "avg_logprob": -0.343537992589614, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.0008013829356059432}, {"id": 261, "seek": 180592, "start": 1817.8000000000002, "end": 1823.8400000000001, "text": " it possible to see intern namespace traffic flows or is it limited to intranamespace?", "tokens": [309, 1944, 281, 536, 2154, 5288, 17940, 6419, 12867, 420, 307, 309, 5567, 281, 560, 4257, 1632, 17940, 30], "temperature": 0.0, "avg_logprob": -0.343537992589614, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.0008013829356059432}, {"id": 262, "seek": 180592, "start": 1823.8400000000001, "end": 1829.68, "text": " OK. Good question. So to answer the second question first, yes, you can see that. So", "tokens": [2264, 13, 2205, 1168, 13, 407, 281, 1867, 264, 1150, 1168, 700, 11, 2086, 11, 291, 393, 536, 300, 13, 407], "temperature": 0.0, "avg_logprob": -0.343537992589614, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.0008013829356059432}, {"id": 263, "seek": 180592, "start": 1829.68, "end": 1834.44, "text": " if there is communication between, from a different namespace in regards to your namespace", "tokens": [498, 456, 307, 6101, 1296, 11, 490, 257, 819, 5288, 17940, 294, 14258, 281, 428, 5288, 17940], "temperature": 0.0, "avg_logprob": -0.343537992589614, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.0008013829356059432}, {"id": 264, "seek": 183444, "start": 1834.44, "end": 1839.6000000000001, "text": " and monitoring, you will see that. You will see those labels, and you will see the workloads,", "tokens": [293, 11028, 11, 291, 486, 536, 300, 13, 509, 486, 536, 729, 16949, 11, 293, 291, 486, 536, 264, 32452, 11], "temperature": 0.0, "avg_logprob": -0.16571072415188626, "compression_ratio": 1.6566037735849057, "no_speech_prob": 6.595864397240803e-05}, {"id": 265, "seek": 183444, "start": 1839.6000000000001, "end": 1844.3600000000001, "text": " even across clusters if you enable cluster mesh. So yes, that works out of the box.", "tokens": [754, 2108, 23313, 498, 291, 9528, 13630, 17407, 13, 407, 2086, 11, 300, 1985, 484, 295, 264, 2424, 13], "temperature": 0.0, "avg_logprob": -0.16571072415188626, "compression_ratio": 1.6566037735849057, "no_speech_prob": 6.595864397240803e-05}, {"id": 266, "seek": 183444, "start": 1844.3600000000001, "end": 1850.8, "text": " On the cloud provider side, so if you run AQS with Azure CNI Powered by Selium, you have", "tokens": [1282, 264, 4588, 12398, 1252, 11, 370, 498, 291, 1190, 316, 48, 50, 365, 11969, 14589, 40, 7086, 292, 538, 10736, 2197, 11, 291, 362], "temperature": 0.0, "avg_logprob": -0.16571072415188626, "compression_ratio": 1.6566037735849057, "no_speech_prob": 6.595864397240803e-05}, {"id": 267, "seek": 183444, "start": 1850.8, "end": 1856.96, "text": " a limited set of metrics which are enabled. And that's obviously from support reasons", "tokens": [257, 5567, 992, 295, 16367, 597, 366, 15172, 13, 400, 300, 311, 2745, 490, 1406, 4112], "temperature": 0.0, "avg_logprob": -0.16571072415188626, "compression_ratio": 1.6566037735849057, "no_speech_prob": 6.595864397240803e-05}, {"id": 268, "seek": 183444, "start": 1856.96, "end": 1862.3200000000002, "text": " for Microsoft to support that solution out of the box. However, you can also choose to", "tokens": [337, 8116, 281, 1406, 300, 3827, 484, 295, 264, 2424, 13, 2908, 11, 291, 393, 611, 2826, 281], "temperature": 0.0, "avg_logprob": -0.16571072415188626, "compression_ratio": 1.6566037735849057, "no_speech_prob": 6.595864397240803e-05}, {"id": 269, "seek": 186232, "start": 1862.32, "end": 1869.56, "text": " bring your own CNI with AQS, and that also applies to GKE and AQS, to manage Selium yourself.", "tokens": [1565, 428, 1065, 14589, 40, 365, 316, 48, 50, 11, 293, 300, 611, 13165, 281, 460, 8522, 293, 316, 48, 50, 11, 281, 3067, 10736, 2197, 1803, 13], "temperature": 0.0, "avg_logprob": -0.2377103495801616, "compression_ratio": 1.5801526717557253, "no_speech_prob": 8.676147990627214e-05}, {"id": 270, "seek": 186232, "start": 1869.56, "end": 1876.3999999999999, "text": " Right? So then you have the freedom to configure the flags I just shown and to configure Selium", "tokens": [1779, 30, 407, 550, 291, 362, 264, 5645, 281, 22162, 264, 23265, 286, 445, 4898, 293, 281, 22162, 10736, 2197], "temperature": 0.0, "avg_logprob": -0.2377103495801616, "compression_ratio": 1.5801526717557253, "no_speech_prob": 8.676147990627214e-05}, {"id": 271, "seek": 186232, "start": 1876.3999999999999, "end": 1882.3999999999999, "text": " as such. Keep in mind that you're responsible obviously of monitoring, managing Selium,", "tokens": [382, 1270, 13, 5527, 294, 1575, 300, 291, 434, 6250, 2745, 295, 11028, 11, 11642, 10736, 2197, 11], "temperature": 0.0, "avg_logprob": -0.2377103495801616, "compression_ratio": 1.5801526717557253, "no_speech_prob": 8.676147990627214e-05}, {"id": 272, "seek": 186232, "start": 1882.3999999999999, "end": 1888.28, "text": " and the cloud provider will manage the cluster. Any other question?", "tokens": [293, 264, 4588, 12398, 486, 3067, 264, 13630, 13, 2639, 661, 1168, 30], "temperature": 0.0, "avg_logprob": -0.2377103495801616, "compression_ratio": 1.5801526717557253, "no_speech_prob": 8.676147990627214e-05}, {"id": 273, "seek": 186232, "start": 1888.28, "end": 1889.8, "text": " Cool. We have to cut it in.", "tokens": [8561, 13, 492, 362, 281, 1723, 309, 294, 13], "temperature": 0.0, "avg_logprob": -0.2377103495801616, "compression_ratio": 1.5801526717557253, "no_speech_prob": 8.676147990627214e-05}, {"id": 274, "seek": 186232, "start": 1889.8, "end": 1890.8, "text": " Oh, yes. Sorry.", "tokens": [876, 11, 2086, 13, 4919, 13], "temperature": 0.0, "avg_logprob": -0.2377103495801616, "compression_ratio": 1.5801526717557253, "no_speech_prob": 8.676147990627214e-05}, {"id": 275, "seek": 186232, "start": 1890.8, "end": 1891.8, "text": " OK. Thank you very much.", "tokens": [2264, 13, 1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.2377103495801616, "compression_ratio": 1.5801526717557253, "no_speech_prob": 8.676147990627214e-05}, {"id": 276, "seek": 189180, "start": 1891.8, "end": 1892.8, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.38623402335427026, "compression_ratio": 1.0, "no_speech_prob": 0.00127809785772115}, {"id": 277, "seek": 189280, "start": 1892.8, "end": 1921.8, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 51814], "temperature": 0.0, "avg_logprob": -0.610146681467692, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.00028463793569244444}], "language": "en"}