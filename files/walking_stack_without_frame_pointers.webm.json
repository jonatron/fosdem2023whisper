{"text": " I'm going to talk about walking native stacks in BPF without frame pointers. So yeah. So my name is Weishali. I work at PoloSignals as a software engineer mostly on profiling and eBPF related stuff and before that I have worked in different corner subsystems as part of my job. My name is Javier and I've been working at PoloSignals for a year mostly working on native stack and winding and before I was working on web reliability and depth tooling at Facebook. So before we get into the talk let's talk about the agenda. So we'll first address the first question which is always being asked that why size need for a dwarf based stack walker in eBPF then we will briefly go through the design of our stack walker will also go from like how we went from the prototype to making it production ready and then what are a bunch of the learnings so far especially when we are interacting with the eBPF subsystem of the kernel and then our future plans. So as I said we work on the production profilers. Generally sampling profilers collect the stack traces at like particular intervals and attaches values to it. For that like profilers generally need both user like application stacks and kernel stacks. Stack walking is like part of the process for collecting the stack traces. In simple words like it involves iterating over all the stack frames and like collecting the written addresses. Historically there has been a dedicated frame, dedicated register to store the value of it in both X86 and ARM although it has fallen victim of some of the compiler optimizations so most of the runtime actually sabers it. It's called frame pointer as many of you have heard of it. And when we don't have the frame pointer walking the stack becomes like magnitude of like a lengthy process. So instead of involving a couple of memory accesses per frame which is like quite fast we will have to do like more work in the stack walkers like not like the stack walking is also a common practice in deep workers right. So what's the current state of the world with respect to frame pointers? So it's not a problem for especially hyperscalers as you may know like in the production they are always running the applications which has the frame pointers enabled because whenever they have to inspect the incidents getting like faster and the reliable stack traces is must. Go runtime enables the frame pointers since go 1.7 in X86 and 1.12 in ARM 64. Mac OS is like always compiled with compiled with frame pointers. There's also an amazing work going on for the compact frame format. It's called simple frame format and there has been like support being added in the tool chains and now there is also like a mailing list discussion going on in the kernel about having an unwinded stack walker, sorry, a stack walker for unwind the user stacks. But the thing is that we want it now, we want to support all the distros, we want to support all the runtimes and the one thing that common across a lot of this is dwarf and that's why we are using it. So where does it come from? So like some of you might be wondering about like the exceptions in C++ or for example Rust tool chain which is like always disabling the frame pointers but when you like use the panic it always has the full backtracks. The reason is that it has the .eh frame section which is being used for that or debug frame. So most of the time either of the tool chains have this section and the other ideas that you can also unwind the tables by synthesizing it from the object code. This is like the approach which is being used in orc, one of the kernel second winder which was added I guess five, six years ago. So we'll talk about in detail about .eh frame in a minute but before that let's see who else is using .eh frame. So of course like we are not the first one who are going to use it, Perf does that. Since I think, since when the Perf event, Cyscall Perf event, Open Cyscall was introduced in 3.4 it collects the registers for the profile processes as well as like copy of the stack for every sample. While this approach has been proven to work, that bunch of drawbacks which we wanted to avoid one of the thing is that kernel copies the user stake for every sample and this can be like quite a bit of data especially for the CPU intensive applications. Another thing is that when we are copying the data in the user space the implications of one processes having another processes data can also be complicated. So those are like bunch of the things we wanted to avoid and stack walking using BPF makes sense to us because we don't have to copy the whole stack instead like a lot of the information still stays in the kernel especially like in the case of stack walking mechanism. Once it has been implemented we can leverage the Perf subsystem to like get the samples on CPU cycles, instructions, alt, cache misses, etc. It can also help us to develop other tools like allocation tracers, runtime specific profiles like for the JVM or Ruby, etc. Now some of you might be wondering that why do we want to implement something new when we already have BPF get stack ID? So the reason is that it also uses frame pointers to unwind it so and having a fully featured dwarf unwind in kernel is unlikely to happen there is a mailing list discussion you can go and check it out why. So now before we dive into the design of our stack walker I wanted to give some information on what ES frame has and how we can use it. So ES frame section contains one or more call frame information records. The main goal of the call frame information records is to provide answers on how to restore the register for the previous frame and the locations such as like whether they have been pushed to the stack or not and all of this would actually generate the huge unwind tables and for this reason the format attempts to be compact and it only contains the information that is being needed. The unwind tables encoded in the CFI format are in the form of opcodes and we basically have to evaluate it and then in the case of stack walking once it has been like evaluated we generate the table that contains like for each instruction boundary how to restore the value of the previous register. It has sort of two layers to it. One is this sort of helps with the repetitive patterns for compressing and it allows for a more compact representation of some data. As in some cases they are like a specialized opcodes that consumes one or two or four bytes so it doesn't have to be four bytes all the time. And the second layer is like a spatial opcode that contains under the site of opcode which is like arbitrary expressions and they need to be actually evaluated for that. And this would need like that, this would mean that we will actually have to implement the full-blown VM in the EBPF to evaluate any expression which is not practical. So we are going to also mention what we are doing to actually come over those challenges. For those who are not aware of like what is like the general flow of the EBPF applications generally this is how it would look like very high-level overview. So in the user space we are using the driver program which is written in Go. We usually BPF Go, it creates the map, attaches the map to attaches the BPF program to the CPU cycles of Perf event and then reads, parses and evaluates the EHRM section of the process. And in the BPF program we fetch the table from the current PID and then have an unwinding algorithm which processes the raw information. So we will go in depth for each component but let's see what the algorithm looks like. So first what we are doing is we are just reading three registers. First one is RIP, the second one is StackPointer, RSP and the third one is RBP which is commonly used as frame pointer when they are unable to. Next we are going for the unwind frame count which is less than maximum depth. We find the unwind table row for the program counter, then we go for adding the instruction pointer to the stack, calculate the previous frames, StackPointer, update the registers and continue with the next frame. So this is like a very simple binary search but when it has to scale we need to also think about storing the unwind information and how can it work with all the runtimes etc. So Javier will now talk about that. Cool, so as Vaishali said we need somewhere where to store the unwind information. We are going to look later at how this table looks like. But first let's see what are the possibilities here. So one possibility for example will be to store the unwind information in process. We could do this using a combination of Ptrace, Mmap and Mlock and this will require us to basically hijack the processes execution, introduce a new memory mapping inside of them and then we have to lock the memory because in BPF and in our type of BPF programs page folds are not allowed. The problem with these approaches of course will be altering the execution flow of applications which is something that we never want to do. This complicates things a lot but for example one of the biggest problems is the life cycle right. So for example if our profiler dies before we finish cleaning up who is going to clean up that memory segment or how is this going to be perceived by developers if they see that the memory of their application has increased behind their backs just because some observability tool is doing something that is not great. But also there's another problem that is sharing memories harder. There is same page optimization from the kernel but if you don't think about that it's a problem to have the same information generated over and over for example for a libc for every single process in your machine. So that's why we ended up using another solution which is pretty typical in the BPF space which is using BPF maps. In case you're not familiar BPF maps are data structures that can be written or read from both user and kernel space. We're using hash tables everywhere which in the case of BPF they're basically a mapping of bytes to bytes that store arbitrary information. So some BPF maps, some BPF programs as well are allowed to lazily allocate memory for their data structures but in the case of our tracing program we kind of do that and this has some implications. So we need to mem-lock that, well the kernel, sorry user space, mem-lock that memory and otherwise our program wouldn't be able to run. And by using this approach we are also able to reuse these memory mappings which is great because that means we don't have to do the same work over and over and we use less space. So let's take a look at the logical representation of the unwind tables. So this is not how the layout is in memory but think about for example the unwind tables for libc, mysql, zlib and systemd how they will be laid out in memory if we could allocate a large chunk of memory. But in reality there's limits everywhere obviously and in BPF we have done some tests and in the machines that we want, well the kernels we want to support we can allocate up to 25,000 unwind entries per value of the hash map. So obviously this was a problem for us because in some cases we have some customers that have applications with unwind tables with 3, 4 million unwind rows which is quite ridiculous just to give you an idea libc I think has like 60k entries so having a couple million is significant. But yeah we came up with the same solution that you would use in any other data intensive application which is to partition or shard the data. So the way we're doing this is we have multiple entries that are allocated when our profilers start running. We allocate a different number depending on the available memory on the system and the overhead that you're willing to pay and yeah depending on how many charts you have you have a different CPU to memory trade off because the more memory you use it has to be locked in memory, it can be swapped out which is in some applications not ideal but at the same time that means that you don't have to regenerate the tables if they are full and then you want to give like other processes a third chance to be profiled. So the way this will work for example for a process like system D is that will be like the representation of the size of its unwind tables and because it's bigger than the size of a shard it will have to be chunked. So here we can see how this is chunked in two. The first chunk will go in the shard zero and a bunch of the unwind entries from the tail will go to the shard one and of course because we have this new layer of indirection we need to somehow keep track of you know all these bookkeeping and know what is the state of the worlds and we're doing this of course with more BBF maps. So a process has multiple mappings each mapping has one or more chunks and then each chunk maps to exactly one shard and in particular the region within one shard because you can have from one unwind entry up to 2050k. Of course this has the benefit that I was mentioning before that is because we were sharing the unwind tables that means that we spent actually not that many CPU cycles doing all the work that Shali was mentioning before. We need to find the ELF section where the door of CFI information is but also we need to parse evaluate it. We have two levels of VM that have to run which is not something that is very CPU consuming but still has to happen. It has to process a bunch of information and generate these unwind tables in our custom formats. So by sharing this for example Lipsy will be shared for all the processes so that means that we only need to add the bookkeeping data structures which are really cheap to generate. In some of the tests that we've been running we use less than 0.9% CPU within the total CPU cycles our profiler uses to generate the unwind tables and of course there is a lot of things that we need to take into account like for example what happens if we run out of space right? So what we do is we adaptively decide what to do in the moment. We might wait a little bit until resetting the state or we might decide to give chance up to other processes to be profiled so we wipe the whole thing and start again and as you can see this is very similar to a bump allocator. This is basically a bump allocator that has been chunked up. So the process of unwinding this is we start with a PAD, we check if it has unwind information then we need to find the mapping and for each mapping we know the minimum and the maximum program counter so we need to do a linear search to find it. Then we find the chunk, with the chunk we already have the shard information so once we have the shard information we have to traverse up to 250,000 items. We do this just with a simple binary search. This takes obviously between seven or eight iterations and once we have the unwind action that tells us how to restore the previous frames registers we do those operations and we are ready to go to the next frame. We are pretty much done for that frame. If the stack trace is correct we know this because basically a stack when you have frame pointers the bottom of the stack is defined in applications with frame pointers when you reach RBP equals zero this is defined by the ABI. When you have unwind tables it is defined by not having that program counter covered by any unwind table and having RBP zero these are requirement by the ABI so if some application doesn't respect it it is completely broken. So once we verify that the stack is correct that we have reached the bottom of the stack then we hash the addresses and we hash we add the hash to a map and we bump a counter and we do this I think it is 19 times a second for every single CPU in your box and every couple seconds we collect all this information we generate a profile and we send it to some server for inspection. So of course BPF is an interesting environment to work with it is amazing and we really really like it but we need to be aware of some stuff. First of all because we cannot page in or page out pages of the contained unwind tables that has to be locked in memory so we need to be very careful with how we organize our data and the layout of that data to make it as small as possible so we basically pack every single thing that can be packed and then there are some interesting BPF things that for most people that have written BPF programs this is well known but I just want to talk a little bit about how we are dealing with some of the BPF challenges. So one of it is a stack size which is easy to work around if I am not mistaken we have 512 bytes which is not a lot so we use another BPF map that we use sort of a global data structure and that stores basically like kind of your heap if you will and then for the program size this is a limitation that comes in two ways first there is probably some limitation in the amount of how many opcodes you can load in the kernel but also the BPF verifier that ensures that the BPF code is safe to load for example you don't do any de-reference that could go wrong or that your program terminates it has some limits it could theoretically run forever trying to verify your program but it has some limits and we hit this limit everywhere in our code for example we hit it when running our binary research it complains saying that it is too complex for us to analyze so what we do here is that not only we have sharded our data we have sharded our code our code and data the same thing right so we basically have our program split into many sub-programs and we keep the states and we basically execute one program after each other and continue the state so one of the techniques we use is BPF tail calls two other things that are way more modern and they are amazing to our bounded loops and BPF loop which is a wonderful helper the problem is that while we use bounded loops right now we don't use BPF loop because it's only supported in modern kernels but it's great and if you can use it you should now because we're a profiler and we want to minimize the impact we have on the machines we run I want to talk a little bit about performance in user space so many go applications well our profiler is written in go and many go applications and APIs are in design with performance in mind and this is something that can be seen in the dwarf and elf library that go ships with in the sandal library as well as binary read and binary write that we use everywhere because we're dealing with raw bytes and we read them and write them all the time to the BPF maps so it is interesting to know that both these binary read and binary write low-level APIs actually allocate in the fast path which can be problematic so there's a lot of things that in the future we're going to be reinventing to make faster and then we profile a profiler a lot in production we have found a lot of opportunities and there's a lot more work to do because there's not much time I'm gonna quickly skip through testing but the great idea here is that we try to be pragmatic and we have a lot of unit tests for the core functions and then we use snapshot testing for the unwind tables and we have a git sub repository where we have a visual representation of the unwind tables and then we generate them every time on CI and locally and we verify that there are no changes compared to last time I think there's only like two or three minutes left so let me talk about the different environments and some of the interesting stuff that we have found while we were profiling our profiler in production we realized that we were spending a ridiculous amount of CPU cycles reading files from this I think the total this is just like a bunch a part of the flame graph but I think it was like 20% of the CPU cycles so turns out this was because our cloud provider has very slow disks that are orders of magnitude slower than our fast NVMEs in the team and another thing that is very interesting that is not a new fact and everybody knows about is that different configuration is the biggest source of trouble and we could see this the other day and if you're interested you can check the board request it's our all the whole project is open source which is the interaction between signals and BPF what happened basically go has an embedded profiler and we use it only in production for reasons but it triggers SIGPROF every couple a couple times a second that it was interrupting the process execution and at that time our process of booting app and it was loading our BPF program because it's quite long and complex the verifier takes a couple milliseconds to load it but it was getting interrupted all the time the BPF whenever it detects that the verifier has been interrupted it retries the process basically wasting all the previous CPU cycles because it starts from scratch but then it retries up to five times and then it says I couldn't do it and of course when we can allow the BPF program we are completely useless so we just crash and there is many other considerations such as what do you do with short live processes because you have to generate a data but even though we have an optimize for this and is we are not that bad and we can profile processes that run even for one second on your box and then the important thing here is that this is our format for our custom on wine table but it doesn't matter the important bit here is that it mostly fits in L2 cache so we basically incur on two L2 misses and it is pretty fast on a machine with a bunch of processes with up to 90 frames we can do the full on wine processing 0.5 milliseconds on a CPU that is five years old cool and so we are going to do mixing on wine mode so being able to unwind JIT sections we're applying RM64 support by the end of the year and this feature is going to be enabled by default in a few weeks because right now it's under a feature flag we have many other things that we want to support including high level languages and we are open source so if you want to contribute or you have anything you want to discuss we meet by weekly on Mondays as part of the Parker project so there's a bunch of links that we're going to upload to the presentation in the FOSM websites and yeah thank you. I think we have time for maximum one short question.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.0, "text": " I'm going to talk about walking native stacks in BPF without frame pointers.", "tokens": [50364, 286, 478, 516, 281, 751, 466, 4494, 8470, 30792, 294, 40533, 37, 1553, 3920, 44548, 13, 51064], "temperature": 0.0, "avg_logprob": -0.46591410636901853, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.051518142223358154}, {"id": 1, "seek": 0, "start": 14.0, "end": 17.5, "text": " So yeah.", "tokens": [51064, 407, 1338, 13, 51239], "temperature": 0.0, "avg_logprob": -0.46591410636901853, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.051518142223358154}, {"id": 2, "seek": 0, "start": 17.5, "end": 18.6, "text": " So my name is Weishali.", "tokens": [51239, 407, 452, 1315, 307, 492, 742, 5103, 13, 51294], "temperature": 0.0, "avg_logprob": -0.46591410636901853, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.051518142223358154}, {"id": 3, "seek": 0, "start": 18.6, "end": 24.560000000000002, "text": " I work at PoloSignals as a software engineer mostly on profiling and eBPF related stuff", "tokens": [51294, 286, 589, 412, 3635, 78, 50, 788, 1124, 382, 257, 4722, 11403, 5240, 322, 1740, 4883, 293, 308, 33, 47, 37, 4077, 1507, 51592], "temperature": 0.0, "avg_logprob": -0.46591410636901853, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.051518142223358154}, {"id": 4, "seek": 0, "start": 24.560000000000002, "end": 29.560000000000002, "text": " and before that I have worked in different corner subsystems as part of my job.", "tokens": [51592, 293, 949, 300, 286, 362, 2732, 294, 819, 4538, 2090, 9321, 82, 382, 644, 295, 452, 1691, 13, 51842], "temperature": 0.0, "avg_logprob": -0.46591410636901853, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.051518142223358154}, {"id": 5, "seek": 2956, "start": 29.56, "end": 34.92, "text": " My name is Javier and I've been working at PoloSignals for a year mostly working on native", "tokens": [50364, 1222, 1315, 307, 508, 25384, 293, 286, 600, 668, 1364, 412, 3635, 78, 50, 788, 1124, 337, 257, 1064, 5240, 1364, 322, 8470, 50632], "temperature": 0.0, "avg_logprob": -0.20055456068909283, "compression_ratio": 1.6171875, "no_speech_prob": 0.0020669123623520136}, {"id": 6, "seek": 2956, "start": 34.92, "end": 41.64, "text": " stack and winding and before I was working on web reliability and depth tooling at Facebook.", "tokens": [50632, 8630, 293, 29775, 293, 949, 286, 390, 1364, 322, 3670, 24550, 293, 7161, 46593, 412, 4384, 13, 50968], "temperature": 0.0, "avg_logprob": -0.20055456068909283, "compression_ratio": 1.6171875, "no_speech_prob": 0.0020669123623520136}, {"id": 7, "seek": 2956, "start": 41.64, "end": 44.84, "text": " So before we get into the talk let's talk about the agenda.", "tokens": [50968, 407, 949, 321, 483, 666, 264, 751, 718, 311, 751, 466, 264, 9829, 13, 51128], "temperature": 0.0, "avg_logprob": -0.20055456068909283, "compression_ratio": 1.6171875, "no_speech_prob": 0.0020669123623520136}, {"id": 8, "seek": 2956, "start": 44.84, "end": 49.92, "text": " So we'll first address the first question which is always being asked that why size", "tokens": [51128, 407, 321, 603, 700, 2985, 264, 700, 1168, 597, 307, 1009, 885, 2351, 300, 983, 2744, 51382], "temperature": 0.0, "avg_logprob": -0.20055456068909283, "compression_ratio": 1.6171875, "no_speech_prob": 0.0020669123623520136}, {"id": 9, "seek": 2956, "start": 49.92, "end": 55.8, "text": " need for a dwarf based stack walker in eBPF then we will briefly go through the design", "tokens": [51382, 643, 337, 257, 35527, 2361, 8630, 1792, 260, 294, 308, 33, 47, 37, 550, 321, 486, 10515, 352, 807, 264, 1715, 51676], "temperature": 0.0, "avg_logprob": -0.20055456068909283, "compression_ratio": 1.6171875, "no_speech_prob": 0.0020669123623520136}, {"id": 10, "seek": 5580, "start": 55.8, "end": 61.0, "text": " of our stack walker will also go from like how we went from the prototype to making it", "tokens": [50364, 295, 527, 8630, 1792, 260, 486, 611, 352, 490, 411, 577, 321, 1437, 490, 264, 19475, 281, 1455, 309, 50624], "temperature": 0.0, "avg_logprob": -0.1578155838617004, "compression_ratio": 1.6720647773279351, "no_speech_prob": 0.004041262902319431}, {"id": 11, "seek": 5580, "start": 61.0, "end": 66.32, "text": " production ready and then what are a bunch of the learnings so far especially when we", "tokens": [50624, 4265, 1919, 293, 550, 437, 366, 257, 3840, 295, 264, 2539, 82, 370, 1400, 2318, 562, 321, 50890], "temperature": 0.0, "avg_logprob": -0.1578155838617004, "compression_ratio": 1.6720647773279351, "no_speech_prob": 0.004041262902319431}, {"id": 12, "seek": 5580, "start": 66.32, "end": 73.0, "text": " are interacting with the eBPF subsystem of the kernel and then our future plans.", "tokens": [50890, 366, 18017, 365, 264, 308, 33, 47, 37, 2090, 9321, 295, 264, 28256, 293, 550, 527, 2027, 5482, 13, 51224], "temperature": 0.0, "avg_logprob": -0.1578155838617004, "compression_ratio": 1.6720647773279351, "no_speech_prob": 0.004041262902319431}, {"id": 13, "seek": 5580, "start": 73.0, "end": 76.52, "text": " So as I said we work on the production profilers.", "tokens": [51224, 407, 382, 286, 848, 321, 589, 322, 264, 4265, 1740, 388, 433, 13, 51400], "temperature": 0.0, "avg_logprob": -0.1578155838617004, "compression_ratio": 1.6720647773279351, "no_speech_prob": 0.004041262902319431}, {"id": 14, "seek": 5580, "start": 76.52, "end": 82.24, "text": " Generally sampling profilers collect the stack traces at like particular intervals and attaches", "tokens": [51400, 21082, 21179, 1740, 388, 433, 2500, 264, 8630, 26076, 412, 411, 1729, 26651, 293, 49404, 51686], "temperature": 0.0, "avg_logprob": -0.1578155838617004, "compression_ratio": 1.6720647773279351, "no_speech_prob": 0.004041262902319431}, {"id": 15, "seek": 5580, "start": 82.24, "end": 84.08, "text": " values to it.", "tokens": [51686, 4190, 281, 309, 13, 51778], "temperature": 0.0, "avg_logprob": -0.1578155838617004, "compression_ratio": 1.6720647773279351, "no_speech_prob": 0.004041262902319431}, {"id": 16, "seek": 8408, "start": 84.08, "end": 89.48, "text": " For that like profilers generally need both user like application stacks and kernel stacks.", "tokens": [50364, 1171, 300, 411, 1740, 388, 433, 5101, 643, 1293, 4195, 411, 3861, 30792, 293, 28256, 30792, 13, 50634], "temperature": 0.0, "avg_logprob": -0.2180889892578125, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0009747213334776461}, {"id": 17, "seek": 8408, "start": 89.48, "end": 93.12, "text": " Stack walking is like part of the process for collecting the stack traces.", "tokens": [50634, 37649, 4494, 307, 411, 644, 295, 264, 1399, 337, 12510, 264, 8630, 26076, 13, 50816], "temperature": 0.0, "avg_logprob": -0.2180889892578125, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0009747213334776461}, {"id": 18, "seek": 8408, "start": 93.12, "end": 97.6, "text": " In simple words like it involves iterating over all the stack frames and like collecting", "tokens": [50816, 682, 2199, 2283, 411, 309, 11626, 17138, 990, 670, 439, 264, 8630, 12083, 293, 411, 12510, 51040], "temperature": 0.0, "avg_logprob": -0.2180889892578125, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0009747213334776461}, {"id": 19, "seek": 8408, "start": 97.6, "end": 99.4, "text": " the written addresses.", "tokens": [51040, 264, 3720, 16862, 13, 51130], "temperature": 0.0, "avg_logprob": -0.2180889892578125, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0009747213334776461}, {"id": 20, "seek": 8408, "start": 99.4, "end": 105.72, "text": " Historically there has been a dedicated frame, dedicated register to store the value of it", "tokens": [51130, 25108, 984, 456, 575, 668, 257, 8374, 3920, 11, 8374, 7280, 281, 3531, 264, 2158, 295, 309, 51446], "temperature": 0.0, "avg_logprob": -0.2180889892578125, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0009747213334776461}, {"id": 21, "seek": 8408, "start": 105.72, "end": 113.96, "text": " in both X86 and ARM although it has fallen victim of some of the compiler optimizations", "tokens": [51446, 294, 1293, 1783, 22193, 293, 45209, 4878, 309, 575, 11547, 6760, 295, 512, 295, 264, 31958, 5028, 14455, 51858], "temperature": 0.0, "avg_logprob": -0.2180889892578125, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0009747213334776461}, {"id": 22, "seek": 11396, "start": 114.52, "end": 118.0, "text": " so most of the runtime actually sabers it.", "tokens": [50392, 370, 881, 295, 264, 34474, 767, 5560, 433, 309, 13, 50566], "temperature": 0.0, "avg_logprob": -0.23492149511973062, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0021984651684761047}, {"id": 23, "seek": 11396, "start": 118.0, "end": 122.44, "text": " It's called frame pointer as many of you have heard of it.", "tokens": [50566, 467, 311, 1219, 3920, 23918, 382, 867, 295, 291, 362, 2198, 295, 309, 13, 50788], "temperature": 0.0, "avg_logprob": -0.23492149511973062, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0021984651684761047}, {"id": 24, "seek": 11396, "start": 122.44, "end": 129.51999999999998, "text": " And when we don't have the frame pointer walking the stack becomes like magnitude of like a", "tokens": [50788, 400, 562, 321, 500, 380, 362, 264, 3920, 23918, 4494, 264, 8630, 3643, 411, 15668, 295, 411, 257, 51142], "temperature": 0.0, "avg_logprob": -0.23492149511973062, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0021984651684761047}, {"id": 25, "seek": 11396, "start": 129.51999999999998, "end": 132.12, "text": " lengthy process.", "tokens": [51142, 35374, 1399, 13, 51272], "temperature": 0.0, "avg_logprob": -0.23492149511973062, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0021984651684761047}, {"id": 26, "seek": 11396, "start": 132.12, "end": 136.51999999999998, "text": " So instead of involving a couple of memory accesses per frame which is like quite fast", "tokens": [51272, 407, 2602, 295, 17030, 257, 1916, 295, 4675, 2105, 279, 680, 3920, 597, 307, 411, 1596, 2370, 51492], "temperature": 0.0, "avg_logprob": -0.23492149511973062, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0021984651684761047}, {"id": 27, "seek": 11396, "start": 136.51999999999998, "end": 141.4, "text": " we will have to do like more work in the stack walkers like not like the stack walking is", "tokens": [51492, 321, 486, 362, 281, 360, 411, 544, 589, 294, 264, 8630, 1792, 433, 411, 406, 411, 264, 8630, 4494, 307, 51736], "temperature": 0.0, "avg_logprob": -0.23492149511973062, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0021984651684761047}, {"id": 28, "seek": 14140, "start": 141.44, "end": 144.04, "text": " also a common practice in deep workers right.", "tokens": [50366, 611, 257, 2689, 3124, 294, 2452, 5600, 558, 13, 50496], "temperature": 0.0, "avg_logprob": -0.21757741201491582, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.00137239508330822}, {"id": 29, "seek": 14140, "start": 144.04, "end": 150.12, "text": " So what's the current state of the world with respect to frame pointers?", "tokens": [50496, 407, 437, 311, 264, 2190, 1785, 295, 264, 1002, 365, 3104, 281, 3920, 44548, 30, 50800], "temperature": 0.0, "avg_logprob": -0.21757741201491582, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.00137239508330822}, {"id": 30, "seek": 14140, "start": 150.12, "end": 155.28, "text": " So it's not a problem for especially hyperscalers as you may know like in the production they", "tokens": [50800, 407, 309, 311, 406, 257, 1154, 337, 2318, 7420, 433, 9895, 433, 382, 291, 815, 458, 411, 294, 264, 4265, 436, 51058], "temperature": 0.0, "avg_logprob": -0.21757741201491582, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.00137239508330822}, {"id": 31, "seek": 14140, "start": 155.28, "end": 159.92000000000002, "text": " are always running the applications which has the frame pointers enabled because whenever", "tokens": [51058, 366, 1009, 2614, 264, 5821, 597, 575, 264, 3920, 44548, 15172, 570, 5699, 51290], "temperature": 0.0, "avg_logprob": -0.21757741201491582, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.00137239508330822}, {"id": 32, "seek": 14140, "start": 159.92000000000002, "end": 165.6, "text": " they have to inspect the incidents getting like faster and the reliable stack traces", "tokens": [51290, 436, 362, 281, 15018, 264, 21139, 1242, 411, 4663, 293, 264, 12924, 8630, 26076, 51574], "temperature": 0.0, "avg_logprob": -0.21757741201491582, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.00137239508330822}, {"id": 33, "seek": 16560, "start": 165.68, "end": 167.88, "text": " is must.", "tokens": [50368, 307, 1633, 13, 50478], "temperature": 0.0, "avg_logprob": -0.280205210701364, "compression_ratio": 1.4012738853503184, "no_speech_prob": 0.006106754299253225}, {"id": 34, "seek": 16560, "start": 167.88, "end": 179.07999999999998, "text": " Go runtime enables the frame pointers since go 1.7 in X86 and 1.12 in ARM 64.", "tokens": [50478, 1037, 34474, 17077, 264, 3920, 44548, 1670, 352, 502, 13, 22, 294, 1783, 22193, 293, 502, 13, 4762, 294, 45209, 12145, 13, 51038], "temperature": 0.0, "avg_logprob": -0.280205210701364, "compression_ratio": 1.4012738853503184, "no_speech_prob": 0.006106754299253225}, {"id": 35, "seek": 16560, "start": 179.07999999999998, "end": 184.35999999999999, "text": " Mac OS is like always compiled with compiled with frame pointers.", "tokens": [51038, 5707, 12731, 307, 411, 1009, 36548, 365, 36548, 365, 3920, 44548, 13, 51302], "temperature": 0.0, "avg_logprob": -0.280205210701364, "compression_ratio": 1.4012738853503184, "no_speech_prob": 0.006106754299253225}, {"id": 36, "seek": 16560, "start": 184.35999999999999, "end": 190.0, "text": " There's also an amazing work going on for the compact frame format.", "tokens": [51302, 821, 311, 611, 364, 2243, 589, 516, 322, 337, 264, 14679, 3920, 7877, 13, 51584], "temperature": 0.0, "avg_logprob": -0.280205210701364, "compression_ratio": 1.4012738853503184, "no_speech_prob": 0.006106754299253225}, {"id": 37, "seek": 19000, "start": 190.08, "end": 197.48, "text": " It's called simple frame format and there has been like support being added in the tool", "tokens": [50368, 467, 311, 1219, 2199, 3920, 7877, 293, 456, 575, 668, 411, 1406, 885, 3869, 294, 264, 2290, 50738], "temperature": 0.0, "avg_logprob": -0.22336100460438246, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.001563355210237205}, {"id": 38, "seek": 19000, "start": 197.48, "end": 204.12, "text": " chains and now there is also like a mailing list discussion going on in the kernel about", "tokens": [50738, 12626, 293, 586, 456, 307, 611, 411, 257, 41612, 1329, 5017, 516, 322, 294, 264, 28256, 466, 51070], "temperature": 0.0, "avg_logprob": -0.22336100460438246, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.001563355210237205}, {"id": 39, "seek": 19000, "start": 204.12, "end": 211.6, "text": " having an unwinded stack walker, sorry, a stack walker for unwind the user stacks.", "tokens": [51070, 1419, 364, 517, 12199, 292, 8630, 1792, 260, 11, 2597, 11, 257, 8630, 1792, 260, 337, 517, 12199, 264, 4195, 30792, 13, 51444], "temperature": 0.0, "avg_logprob": -0.22336100460438246, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.001563355210237205}, {"id": 40, "seek": 19000, "start": 211.6, "end": 217.44, "text": " But the thing is that we want it now, we want to support all the distros, we want to support", "tokens": [51444, 583, 264, 551, 307, 300, 321, 528, 309, 586, 11, 321, 528, 281, 1406, 439, 264, 1483, 2635, 11, 321, 528, 281, 1406, 51736], "temperature": 0.0, "avg_logprob": -0.22336100460438246, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.001563355210237205}, {"id": 41, "seek": 21744, "start": 217.44, "end": 225.0, "text": " all the runtimes and the one thing that common across a lot of this is dwarf and that's why", "tokens": [50364, 439, 264, 49435, 1532, 293, 264, 472, 551, 300, 2689, 2108, 257, 688, 295, 341, 307, 35527, 293, 300, 311, 983, 50742], "temperature": 0.0, "avg_logprob": -0.22005411373671666, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0014255924616008997}, {"id": 42, "seek": 21744, "start": 225.0, "end": 226.4, "text": " we are using it.", "tokens": [50742, 321, 366, 1228, 309, 13, 50812], "temperature": 0.0, "avg_logprob": -0.22005411373671666, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0014255924616008997}, {"id": 43, "seek": 21744, "start": 226.4, "end": 228.76, "text": " So where does it come from?", "tokens": [50812, 407, 689, 775, 309, 808, 490, 30, 50930], "temperature": 0.0, "avg_logprob": -0.22005411373671666, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0014255924616008997}, {"id": 44, "seek": 21744, "start": 228.76, "end": 236.4, "text": " So like some of you might be wondering about like the exceptions in C++ or for example Rust", "tokens": [50930, 407, 411, 512, 295, 291, 1062, 312, 6359, 466, 411, 264, 22847, 294, 383, 25472, 420, 337, 1365, 34952, 51312], "temperature": 0.0, "avg_logprob": -0.22005411373671666, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0014255924616008997}, {"id": 45, "seek": 21744, "start": 236.4, "end": 240.72, "text": " tool chain which is like always disabling the frame pointers but when you like use the", "tokens": [51312, 2290, 5021, 597, 307, 411, 1009, 717, 20112, 264, 3920, 44548, 457, 562, 291, 411, 764, 264, 51528], "temperature": 0.0, "avg_logprob": -0.22005411373671666, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0014255924616008997}, {"id": 46, "seek": 21744, "start": 240.72, "end": 244.68, "text": " panic it always has the full backtracks.", "tokens": [51528, 14783, 309, 1009, 575, 264, 1577, 646, 6903, 7424, 13, 51726], "temperature": 0.0, "avg_logprob": -0.22005411373671666, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0014255924616008997}, {"id": 47, "seek": 24468, "start": 244.68, "end": 253.48000000000002, "text": " The reason is that it has the .eh frame section which is being used for that or debug frame.", "tokens": [50364, 440, 1778, 307, 300, 309, 575, 264, 2411, 13301, 3920, 3541, 597, 307, 885, 1143, 337, 300, 420, 24083, 3920, 13, 50804], "temperature": 0.0, "avg_logprob": -0.19907066433928733, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.002031050156801939}, {"id": 48, "seek": 24468, "start": 253.48000000000002, "end": 261.24, "text": " So most of the time either of the tool chains have this section and the other ideas that", "tokens": [50804, 407, 881, 295, 264, 565, 2139, 295, 264, 2290, 12626, 362, 341, 3541, 293, 264, 661, 3487, 300, 51192], "temperature": 0.0, "avg_logprob": -0.19907066433928733, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.002031050156801939}, {"id": 49, "seek": 24468, "start": 261.24, "end": 266.56, "text": " you can also unwind the tables by synthesizing it from the object code.", "tokens": [51192, 291, 393, 611, 517, 12199, 264, 8020, 538, 26617, 3319, 309, 490, 264, 2657, 3089, 13, 51458], "temperature": 0.0, "avg_logprob": -0.19907066433928733, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.002031050156801939}, {"id": 50, "seek": 24468, "start": 266.56, "end": 271.68, "text": " This is like the approach which is being used in orc, one of the kernel second winder which", "tokens": [51458, 639, 307, 411, 264, 3109, 597, 307, 885, 1143, 294, 420, 66, 11, 472, 295, 264, 28256, 1150, 2468, 260, 597, 51714], "temperature": 0.0, "avg_logprob": -0.19907066433928733, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.002031050156801939}, {"id": 51, "seek": 27168, "start": 272.2, "end": 275.96, "text": " was added I guess five, six years ago.", "tokens": [50390, 390, 3869, 286, 2041, 1732, 11, 2309, 924, 2057, 13, 50578], "temperature": 0.0, "avg_logprob": -0.27613039016723634, "compression_ratio": 1.5586854460093897, "no_speech_prob": 0.005444350186735392}, {"id": 52, "seek": 27168, "start": 275.96, "end": 282.72, "text": " So we'll talk about in detail about .eh frame in a minute but before that let's see who", "tokens": [50578, 407, 321, 603, 751, 466, 294, 2607, 466, 2411, 13301, 3920, 294, 257, 3456, 457, 949, 300, 718, 311, 536, 567, 50916], "temperature": 0.0, "avg_logprob": -0.27613039016723634, "compression_ratio": 1.5586854460093897, "no_speech_prob": 0.005444350186735392}, {"id": 53, "seek": 27168, "start": 282.72, "end": 285.0, "text": " else is using .eh frame.", "tokens": [50916, 1646, 307, 1228, 2411, 13301, 3920, 13, 51030], "temperature": 0.0, "avg_logprob": -0.27613039016723634, "compression_ratio": 1.5586854460093897, "no_speech_prob": 0.005444350186735392}, {"id": 54, "seek": 27168, "start": 285.0, "end": 291.64, "text": " So of course like we are not the first one who are going to use it, Perf does that.", "tokens": [51030, 407, 295, 1164, 411, 321, 366, 406, 264, 700, 472, 567, 366, 516, 281, 764, 309, 11, 3026, 69, 775, 300, 13, 51362], "temperature": 0.0, "avg_logprob": -0.27613039016723634, "compression_ratio": 1.5586854460093897, "no_speech_prob": 0.005444350186735392}, {"id": 55, "seek": 27168, "start": 291.64, "end": 299.48, "text": " Since I think, since when the Perf event, Cyscall Perf event, Open Cyscall was introduced in 3.4", "tokens": [51362, 4162, 286, 519, 11, 1670, 562, 264, 3026, 69, 2280, 11, 383, 749, 45459, 3026, 69, 2280, 11, 7238, 383, 749, 45459, 390, 7268, 294, 805, 13, 19, 51754], "temperature": 0.0, "avg_logprob": -0.27613039016723634, "compression_ratio": 1.5586854460093897, "no_speech_prob": 0.005444350186735392}, {"id": 56, "seek": 29948, "start": 299.52000000000004, "end": 303.24, "text": " it collects the registers for the profile processes as well as like copy of the stack", "tokens": [50366, 309, 39897, 264, 38351, 337, 264, 7964, 7555, 382, 731, 382, 411, 5055, 295, 264, 8630, 50552], "temperature": 0.0, "avg_logprob": -0.1927022171020508, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.001141783781349659}, {"id": 57, "seek": 29948, "start": 303.24, "end": 304.76, "text": " for every sample.", "tokens": [50552, 337, 633, 6889, 13, 50628], "temperature": 0.0, "avg_logprob": -0.1927022171020508, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.001141783781349659}, {"id": 58, "seek": 29948, "start": 304.76, "end": 309.68, "text": " While this approach has been proven to work, that bunch of drawbacks which we wanted to", "tokens": [50628, 3987, 341, 3109, 575, 668, 12785, 281, 589, 11, 300, 3840, 295, 2642, 17758, 597, 321, 1415, 281, 50874], "temperature": 0.0, "avg_logprob": -0.1927022171020508, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.001141783781349659}, {"id": 59, "seek": 29948, "start": 309.68, "end": 314.04, "text": " avoid one of the thing is that kernel copies the user stake for every sample and this can", "tokens": [50874, 5042, 472, 295, 264, 551, 307, 300, 28256, 14341, 264, 4195, 10407, 337, 633, 6889, 293, 341, 393, 51092], "temperature": 0.0, "avg_logprob": -0.1927022171020508, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.001141783781349659}, {"id": 60, "seek": 29948, "start": 314.04, "end": 319.04, "text": " be like quite a bit of data especially for the CPU intensive applications.", "tokens": [51092, 312, 411, 1596, 257, 857, 295, 1412, 2318, 337, 264, 13199, 18957, 5821, 13, 51342], "temperature": 0.0, "avg_logprob": -0.1927022171020508, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.001141783781349659}, {"id": 61, "seek": 29948, "start": 319.04, "end": 323.32, "text": " Another thing is that when we are copying the data in the user space the implications", "tokens": [51342, 3996, 551, 307, 300, 562, 321, 366, 27976, 264, 1412, 294, 264, 4195, 1901, 264, 16602, 51556], "temperature": 0.0, "avg_logprob": -0.1927022171020508, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.001141783781349659}, {"id": 62, "seek": 32332, "start": 323.32, "end": 330.2, "text": " of one processes having another processes data can also be complicated.", "tokens": [50364, 295, 472, 7555, 1419, 1071, 7555, 1412, 393, 611, 312, 6179, 13, 50708], "temperature": 0.0, "avg_logprob": -0.1855478286743164, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.000567329116165638}, {"id": 63, "seek": 32332, "start": 330.2, "end": 336.56, "text": " So those are like bunch of the things we wanted to avoid and stack walking using BPF makes", "tokens": [50708, 407, 729, 366, 411, 3840, 295, 264, 721, 321, 1415, 281, 5042, 293, 8630, 4494, 1228, 40533, 37, 1669, 51026], "temperature": 0.0, "avg_logprob": -0.1855478286743164, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.000567329116165638}, {"id": 64, "seek": 32332, "start": 336.56, "end": 341.76, "text": " sense to us because we don't have to copy the whole stack instead like a lot of the", "tokens": [51026, 2020, 281, 505, 570, 321, 500, 380, 362, 281, 5055, 264, 1379, 8630, 2602, 411, 257, 688, 295, 264, 51286], "temperature": 0.0, "avg_logprob": -0.1855478286743164, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.000567329116165638}, {"id": 65, "seek": 32332, "start": 341.76, "end": 347.88, "text": " information still stays in the kernel especially like in the case of stack walking mechanism.", "tokens": [51286, 1589, 920, 10834, 294, 264, 28256, 2318, 411, 294, 264, 1389, 295, 8630, 4494, 7513, 13, 51592], "temperature": 0.0, "avg_logprob": -0.1855478286743164, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.000567329116165638}, {"id": 66, "seek": 32332, "start": 347.88, "end": 352.2, "text": " Once it has been implemented we can leverage the Perf subsystem to like get the samples", "tokens": [51592, 3443, 309, 575, 668, 12270, 321, 393, 13982, 264, 3026, 69, 2090, 9321, 281, 411, 483, 264, 10938, 51808], "temperature": 0.0, "avg_logprob": -0.1855478286743164, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.000567329116165638}, {"id": 67, "seek": 35220, "start": 352.2, "end": 357.44, "text": " on CPU cycles, instructions, alt, cache misses, etc.", "tokens": [50364, 322, 13199, 17796, 11, 9415, 11, 4955, 11, 19459, 29394, 11, 5183, 13, 50626], "temperature": 0.0, "avg_logprob": -0.2592132091522217, "compression_ratio": 1.4258373205741626, "no_speech_prob": 0.0005461063701659441}, {"id": 68, "seek": 35220, "start": 357.44, "end": 362.96, "text": " It can also help us to develop other tools like allocation tracers, runtime specific", "tokens": [50626, 467, 393, 611, 854, 505, 281, 1499, 661, 3873, 411, 27599, 504, 326, 433, 11, 34474, 2685, 50902], "temperature": 0.0, "avg_logprob": -0.2592132091522217, "compression_ratio": 1.4258373205741626, "no_speech_prob": 0.0005461063701659441}, {"id": 69, "seek": 35220, "start": 362.96, "end": 367.88, "text": " profiles like for the JVM or Ruby, etc.", "tokens": [50902, 23693, 411, 337, 264, 508, 53, 44, 420, 19907, 11, 5183, 13, 51148], "temperature": 0.0, "avg_logprob": -0.2592132091522217, "compression_ratio": 1.4258373205741626, "no_speech_prob": 0.0005461063701659441}, {"id": 70, "seek": 35220, "start": 367.88, "end": 373.48, "text": " Now some of you might be wondering that why do we want to implement something new when", "tokens": [51148, 823, 512, 295, 291, 1062, 312, 6359, 300, 983, 360, 321, 528, 281, 4445, 746, 777, 562, 51428], "temperature": 0.0, "avg_logprob": -0.2592132091522217, "compression_ratio": 1.4258373205741626, "no_speech_prob": 0.0005461063701659441}, {"id": 71, "seek": 35220, "start": 373.48, "end": 377.28, "text": " we already have BPF get stack ID?", "tokens": [51428, 321, 1217, 362, 40533, 37, 483, 8630, 7348, 30, 51618], "temperature": 0.0, "avg_logprob": -0.2592132091522217, "compression_ratio": 1.4258373205741626, "no_speech_prob": 0.0005461063701659441}, {"id": 72, "seek": 37728, "start": 377.28, "end": 385.52, "text": " So the reason is that it also uses frame pointers to unwind it so and having a fully", "tokens": [50364, 407, 264, 1778, 307, 300, 309, 611, 4960, 3920, 44548, 281, 517, 12199, 309, 370, 293, 1419, 257, 4498, 50776], "temperature": 0.0, "avg_logprob": -0.17977130576355815, "compression_ratio": 1.5520833333333333, "no_speech_prob": 0.002403771271929145}, {"id": 73, "seek": 37728, "start": 385.52, "end": 391.55999999999995, "text": " featured dwarf unwind in kernel is unlikely to happen there is a mailing list discussion", "tokens": [50776, 13822, 35527, 517, 12199, 294, 28256, 307, 17518, 281, 1051, 456, 307, 257, 41612, 1329, 5017, 51078], "temperature": 0.0, "avg_logprob": -0.17977130576355815, "compression_ratio": 1.5520833333333333, "no_speech_prob": 0.002403771271929145}, {"id": 74, "seek": 37728, "start": 391.55999999999995, "end": 396.4, "text": " you can go and check it out why.", "tokens": [51078, 291, 393, 352, 293, 1520, 309, 484, 983, 13, 51320], "temperature": 0.0, "avg_logprob": -0.17977130576355815, "compression_ratio": 1.5520833333333333, "no_speech_prob": 0.002403771271929145}, {"id": 75, "seek": 37728, "start": 396.4, "end": 401.55999999999995, "text": " So now before we dive into the design of our stack walker I wanted to give some information", "tokens": [51320, 407, 586, 949, 321, 9192, 666, 264, 1715, 295, 527, 8630, 1792, 260, 286, 1415, 281, 976, 512, 1589, 51578], "temperature": 0.0, "avg_logprob": -0.17977130576355815, "compression_ratio": 1.5520833333333333, "no_speech_prob": 0.002403771271929145}, {"id": 76, "seek": 40156, "start": 401.56, "end": 405.84, "text": " on what ES frame has and how we can use it.", "tokens": [50364, 322, 437, 12564, 3920, 575, 293, 577, 321, 393, 764, 309, 13, 50578], "temperature": 0.0, "avg_logprob": -0.20905215089971368, "compression_ratio": 1.7798165137614679, "no_speech_prob": 0.006846457254141569}, {"id": 77, "seek": 40156, "start": 405.84, "end": 414.64, "text": " So ES frame section contains one or more call frame information records.", "tokens": [50578, 407, 12564, 3920, 3541, 8306, 472, 420, 544, 818, 3920, 1589, 7724, 13, 51018], "temperature": 0.0, "avg_logprob": -0.20905215089971368, "compression_ratio": 1.7798165137614679, "no_speech_prob": 0.006846457254141569}, {"id": 78, "seek": 40156, "start": 414.64, "end": 419.28, "text": " The main goal of the call frame information records is to provide answers on how to restore", "tokens": [51018, 440, 2135, 3387, 295, 264, 818, 3920, 1589, 7724, 307, 281, 2893, 6338, 322, 577, 281, 15227, 51250], "temperature": 0.0, "avg_logprob": -0.20905215089971368, "compression_ratio": 1.7798165137614679, "no_speech_prob": 0.006846457254141569}, {"id": 79, "seek": 40156, "start": 419.28, "end": 423.6, "text": " the register for the previous frame and the locations such as like whether they have been", "tokens": [51250, 264, 7280, 337, 264, 3894, 3920, 293, 264, 9253, 1270, 382, 411, 1968, 436, 362, 668, 51466], "temperature": 0.0, "avg_logprob": -0.20905215089971368, "compression_ratio": 1.7798165137614679, "no_speech_prob": 0.006846457254141569}, {"id": 80, "seek": 40156, "start": 423.6, "end": 429.12, "text": " pushed to the stack or not and all of this would actually generate the huge unwind tables", "tokens": [51466, 9152, 281, 264, 8630, 420, 406, 293, 439, 295, 341, 576, 767, 8460, 264, 2603, 517, 12199, 8020, 51742], "temperature": 0.0, "avg_logprob": -0.20905215089971368, "compression_ratio": 1.7798165137614679, "no_speech_prob": 0.006846457254141569}, {"id": 81, "seek": 42912, "start": 429.56, "end": 434.48, "text": " and for this reason the format attempts to be compact and it only contains the information", "tokens": [50386, 293, 337, 341, 1778, 264, 7877, 15257, 281, 312, 14679, 293, 309, 787, 8306, 264, 1589, 50632], "temperature": 0.0, "avg_logprob": -0.19649348656336466, "compression_ratio": 1.7682403433476395, "no_speech_prob": 0.0025547698605805635}, {"id": 82, "seek": 42912, "start": 434.48, "end": 437.04, "text": " that is being needed.", "tokens": [50632, 300, 307, 885, 2978, 13, 50760], "temperature": 0.0, "avg_logprob": -0.19649348656336466, "compression_ratio": 1.7682403433476395, "no_speech_prob": 0.0025547698605805635}, {"id": 83, "seek": 42912, "start": 437.04, "end": 444.72, "text": " The unwind tables encoded in the CFI format are in the form of opcodes and we basically", "tokens": [50760, 440, 517, 12199, 8020, 2058, 12340, 294, 264, 21792, 40, 7877, 366, 294, 264, 1254, 295, 999, 66, 4789, 293, 321, 1936, 51144], "temperature": 0.0, "avg_logprob": -0.19649348656336466, "compression_ratio": 1.7682403433476395, "no_speech_prob": 0.0025547698605805635}, {"id": 84, "seek": 42912, "start": 444.72, "end": 449.88, "text": " have to evaluate it and then in the case of stack walking once it has been like evaluated", "tokens": [51144, 362, 281, 13059, 309, 293, 550, 294, 264, 1389, 295, 8630, 4494, 1564, 309, 575, 668, 411, 25509, 51402], "temperature": 0.0, "avg_logprob": -0.19649348656336466, "compression_ratio": 1.7682403433476395, "no_speech_prob": 0.0025547698605805635}, {"id": 85, "seek": 42912, "start": 449.88, "end": 454.96, "text": " we generate the table that contains like for each instruction boundary how to restore the", "tokens": [51402, 321, 8460, 264, 3199, 300, 8306, 411, 337, 1184, 10951, 12866, 577, 281, 15227, 264, 51656], "temperature": 0.0, "avg_logprob": -0.19649348656336466, "compression_ratio": 1.7682403433476395, "no_speech_prob": 0.0025547698605805635}, {"id": 86, "seek": 42912, "start": 454.96, "end": 456.68, "text": " value of the previous register.", "tokens": [51656, 2158, 295, 264, 3894, 7280, 13, 51742], "temperature": 0.0, "avg_logprob": -0.19649348656336466, "compression_ratio": 1.7682403433476395, "no_speech_prob": 0.0025547698605805635}, {"id": 87, "seek": 45668, "start": 456.72, "end": 458.8, "text": " It has sort of two layers to it.", "tokens": [50366, 467, 575, 1333, 295, 732, 7914, 281, 309, 13, 50470], "temperature": 0.0, "avg_logprob": -0.1843644905090332, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.0008886104915291071}, {"id": 88, "seek": 45668, "start": 458.8, "end": 465.24, "text": " One is this sort of helps with the repetitive patterns for compressing and it allows for", "tokens": [50470, 1485, 307, 341, 1333, 295, 3665, 365, 264, 29404, 8294, 337, 14778, 278, 293, 309, 4045, 337, 50792], "temperature": 0.0, "avg_logprob": -0.1843644905090332, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.0008886104915291071}, {"id": 89, "seek": 45668, "start": 465.24, "end": 468.40000000000003, "text": " a more compact representation of some data.", "tokens": [50792, 257, 544, 14679, 10290, 295, 512, 1412, 13, 50950], "temperature": 0.0, "avg_logprob": -0.1843644905090332, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.0008886104915291071}, {"id": 90, "seek": 45668, "start": 468.40000000000003, "end": 473.6, "text": " As in some cases they are like a specialized opcodes that consumes one or two or four bytes", "tokens": [50950, 1018, 294, 512, 3331, 436, 366, 411, 257, 19813, 999, 66, 4789, 300, 48823, 472, 420, 732, 420, 1451, 36088, 51210], "temperature": 0.0, "avg_logprob": -0.1843644905090332, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.0008886104915291071}, {"id": 91, "seek": 45668, "start": 473.6, "end": 478.4, "text": " so it doesn't have to be four bytes all the time.", "tokens": [51210, 370, 309, 1177, 380, 362, 281, 312, 1451, 36088, 439, 264, 565, 13, 51450], "temperature": 0.0, "avg_logprob": -0.1843644905090332, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.0008886104915291071}, {"id": 92, "seek": 45668, "start": 478.4, "end": 483.64, "text": " And the second layer is like a spatial opcode that contains under the site of opcode which", "tokens": [51450, 400, 264, 1150, 4583, 307, 411, 257, 23598, 999, 22332, 300, 8306, 833, 264, 3621, 295, 999, 22332, 597, 51712], "temperature": 0.0, "avg_logprob": -0.1843644905090332, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.0008886104915291071}, {"id": 93, "seek": 48364, "start": 483.68, "end": 490.0, "text": " is like arbitrary expressions and they need to be actually evaluated for that.", "tokens": [50366, 307, 411, 23211, 15277, 293, 436, 643, 281, 312, 767, 25509, 337, 300, 13, 50682], "temperature": 0.0, "avg_logprob": -0.1653970042361489, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.0015012273797765374}, {"id": 94, "seek": 48364, "start": 490.0, "end": 495.47999999999996, "text": " And this would need like that, this would mean that we will actually have to implement", "tokens": [50682, 400, 341, 576, 643, 411, 300, 11, 341, 576, 914, 300, 321, 486, 767, 362, 281, 4445, 50956], "temperature": 0.0, "avg_logprob": -0.1653970042361489, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.0015012273797765374}, {"id": 95, "seek": 48364, "start": 495.47999999999996, "end": 504.2, "text": " the full-blown VM in the EBPF to evaluate any expression which is not practical.", "tokens": [50956, 264, 1577, 12, 5199, 648, 18038, 294, 264, 50148, 47, 37, 281, 13059, 604, 6114, 597, 307, 406, 8496, 13, 51392], "temperature": 0.0, "avg_logprob": -0.1653970042361489, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.0015012273797765374}, {"id": 96, "seek": 48364, "start": 504.2, "end": 511.2, "text": " So we are going to also mention what we are doing to actually come over those challenges.", "tokens": [51392, 407, 321, 366, 516, 281, 611, 2152, 437, 321, 366, 884, 281, 767, 808, 670, 729, 4759, 13, 51742], "temperature": 0.0, "avg_logprob": -0.1653970042361489, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.0015012273797765374}, {"id": 97, "seek": 51120, "start": 511.24, "end": 516.48, "text": " For those who are not aware of like what is like the general flow of the EBPF applications", "tokens": [50366, 1171, 729, 567, 366, 406, 3650, 295, 411, 437, 307, 411, 264, 2674, 3095, 295, 264, 50148, 47, 37, 5821, 50628], "temperature": 0.0, "avg_logprob": -0.23605610950883613, "compression_ratio": 1.6169154228855722, "no_speech_prob": 0.0010972830932587385}, {"id": 98, "seek": 51120, "start": 516.48, "end": 522.4, "text": " generally this is how it would look like very high-level overview.", "tokens": [50628, 5101, 341, 307, 577, 309, 576, 574, 411, 588, 1090, 12, 12418, 12492, 13, 50924], "temperature": 0.0, "avg_logprob": -0.23605610950883613, "compression_ratio": 1.6169154228855722, "no_speech_prob": 0.0010972830932587385}, {"id": 99, "seek": 51120, "start": 522.4, "end": 527.6, "text": " So in the user space we are using the driver program which is written in Go.", "tokens": [50924, 407, 294, 264, 4195, 1901, 321, 366, 1228, 264, 6787, 1461, 597, 307, 3720, 294, 1037, 13, 51184], "temperature": 0.0, "avg_logprob": -0.23605610950883613, "compression_ratio": 1.6169154228855722, "no_speech_prob": 0.0010972830932587385}, {"id": 100, "seek": 51120, "start": 527.6, "end": 534.6, "text": " We usually BPF Go, it creates the map, attaches the map to attaches the BPF program to the", "tokens": [51184, 492, 2673, 40533, 37, 1037, 11, 309, 7829, 264, 4471, 11, 49404, 264, 4471, 281, 49404, 264, 40533, 37, 1461, 281, 264, 51534], "temperature": 0.0, "avg_logprob": -0.23605610950883613, "compression_ratio": 1.6169154228855722, "no_speech_prob": 0.0010972830932587385}, {"id": 101, "seek": 53460, "start": 534.6, "end": 543.48, "text": " CPU cycles of Perf event and then reads, parses and evaluates the EHRM section of the process.", "tokens": [50364, 13199, 17796, 295, 3026, 69, 2280, 293, 550, 15700, 11, 21156, 279, 293, 6133, 1024, 264, 39416, 49, 44, 3541, 295, 264, 1399, 13, 50808], "temperature": 0.0, "avg_logprob": -0.24949504419700386, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0009897801792249084}, {"id": 102, "seek": 53460, "start": 543.48, "end": 548.32, "text": " And in the BPF program we fetch the table from the current PID and then have an unwinding", "tokens": [50808, 400, 294, 264, 40533, 37, 1461, 321, 23673, 264, 3199, 490, 264, 2190, 430, 2777, 293, 550, 362, 364, 14853, 9245, 51050], "temperature": 0.0, "avg_logprob": -0.24949504419700386, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0009897801792249084}, {"id": 103, "seek": 53460, "start": 548.32, "end": 552.84, "text": " algorithm which processes the raw information.", "tokens": [51050, 9284, 597, 7555, 264, 8936, 1589, 13, 51276], "temperature": 0.0, "avg_logprob": -0.24949504419700386, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0009897801792249084}, {"id": 104, "seek": 53460, "start": 552.84, "end": 560.36, "text": " So we will go in depth for each component but let's see what the algorithm looks like.", "tokens": [51276, 407, 321, 486, 352, 294, 7161, 337, 1184, 6542, 457, 718, 311, 536, 437, 264, 9284, 1542, 411, 13, 51652], "temperature": 0.0, "avg_logprob": -0.24949504419700386, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0009897801792249084}, {"id": 105, "seek": 53460, "start": 560.36, "end": 564.12, "text": " So first what we are doing is we are just reading three registers.", "tokens": [51652, 407, 700, 437, 321, 366, 884, 307, 321, 366, 445, 3760, 1045, 38351, 13, 51840], "temperature": 0.0, "avg_logprob": -0.24949504419700386, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0009897801792249084}, {"id": 106, "seek": 56412, "start": 564.16, "end": 571.16, "text": " First one is RIP, the second one is StackPointer, RSP and the third one is RBP which is commonly", "tokens": [50366, 2386, 472, 307, 497, 9139, 11, 264, 1150, 472, 307, 37649, 47, 78, 5106, 11, 25855, 47, 293, 264, 2636, 472, 307, 40302, 47, 597, 307, 12719, 50716], "temperature": 0.0, "avg_logprob": -0.21377722730914367, "compression_ratio": 1.7327586206896552, "no_speech_prob": 0.0013537786435335875}, {"id": 107, "seek": 56412, "start": 571.16, "end": 576.08, "text": " used as frame pointer when they are unable to.", "tokens": [50716, 1143, 382, 3920, 23918, 562, 436, 366, 11299, 281, 13, 50962], "temperature": 0.0, "avg_logprob": -0.21377722730914367, "compression_ratio": 1.7327586206896552, "no_speech_prob": 0.0013537786435335875}, {"id": 108, "seek": 56412, "start": 576.08, "end": 584.08, "text": " Next we are going for the unwind frame count which is less than maximum depth.", "tokens": [50962, 3087, 321, 366, 516, 337, 264, 517, 12199, 3920, 1207, 597, 307, 1570, 813, 6674, 7161, 13, 51362], "temperature": 0.0, "avg_logprob": -0.21377722730914367, "compression_ratio": 1.7327586206896552, "no_speech_prob": 0.0013537786435335875}, {"id": 109, "seek": 56412, "start": 584.08, "end": 588.44, "text": " We find the unwind table row for the program counter, then we go for adding the instruction", "tokens": [51362, 492, 915, 264, 517, 12199, 3199, 5386, 337, 264, 1461, 5682, 11, 550, 321, 352, 337, 5127, 264, 10951, 51580], "temperature": 0.0, "avg_logprob": -0.21377722730914367, "compression_ratio": 1.7327586206896552, "no_speech_prob": 0.0013537786435335875}, {"id": 110, "seek": 56412, "start": 588.44, "end": 593.08, "text": " pointer to the stack, calculate the previous frames, StackPointer, update the registers", "tokens": [51580, 23918, 281, 264, 8630, 11, 8873, 264, 3894, 12083, 11, 37649, 47, 78, 5106, 11, 5623, 264, 38351, 51812], "temperature": 0.0, "avg_logprob": -0.21377722730914367, "compression_ratio": 1.7327586206896552, "no_speech_prob": 0.0013537786435335875}, {"id": 111, "seek": 59308, "start": 593.08, "end": 596.9200000000001, "text": " and continue with the next frame.", "tokens": [50364, 293, 2354, 365, 264, 958, 3920, 13, 50556], "temperature": 0.0, "avg_logprob": -0.25138206481933595, "compression_ratio": 1.635, "no_speech_prob": 0.0017132159555330873}, {"id": 112, "seek": 59308, "start": 596.9200000000001, "end": 604.6800000000001, "text": " So this is like a very simple binary search but when it has to scale we need to also think", "tokens": [50556, 407, 341, 307, 411, 257, 588, 2199, 17434, 3164, 457, 562, 309, 575, 281, 4373, 321, 643, 281, 611, 519, 50944], "temperature": 0.0, "avg_logprob": -0.25138206481933595, "compression_ratio": 1.635, "no_speech_prob": 0.0017132159555330873}, {"id": 113, "seek": 59308, "start": 604.6800000000001, "end": 611.32, "text": " about storing the unwind information and how can it work with all the runtimes etc.", "tokens": [50944, 466, 26085, 264, 517, 12199, 1589, 293, 577, 393, 309, 589, 365, 439, 264, 49435, 1532, 5183, 13, 51276], "temperature": 0.0, "avg_logprob": -0.25138206481933595, "compression_ratio": 1.635, "no_speech_prob": 0.0017132159555330873}, {"id": 114, "seek": 59308, "start": 611.32, "end": 613.76, "text": " So Javier will now talk about that.", "tokens": [51276, 407, 508, 25384, 486, 586, 751, 466, 300, 13, 51398], "temperature": 0.0, "avg_logprob": -0.25138206481933595, "compression_ratio": 1.635, "no_speech_prob": 0.0017132159555330873}, {"id": 115, "seek": 59308, "start": 613.76, "end": 620.1600000000001, "text": " Cool, so as Vaishali said we need somewhere where to store the unwind information.", "tokens": [51398, 8561, 11, 370, 382, 16822, 742, 5103, 848, 321, 643, 4079, 689, 281, 3531, 264, 517, 12199, 1589, 13, 51718], "temperature": 0.0, "avg_logprob": -0.25138206481933595, "compression_ratio": 1.635, "no_speech_prob": 0.0017132159555330873}, {"id": 116, "seek": 62016, "start": 620.16, "end": 623.92, "text": " We are going to look later at how this table looks like.", "tokens": [50364, 492, 366, 516, 281, 574, 1780, 412, 577, 341, 3199, 1542, 411, 13, 50552], "temperature": 0.0, "avg_logprob": -0.18399198849995932, "compression_ratio": 1.6563573883161513, "no_speech_prob": 0.08168521523475647}, {"id": 117, "seek": 62016, "start": 623.92, "end": 626.7199999999999, "text": " But first let's see what are the possibilities here.", "tokens": [50552, 583, 700, 718, 311, 536, 437, 366, 264, 12178, 510, 13, 50692], "temperature": 0.0, "avg_logprob": -0.18399198849995932, "compression_ratio": 1.6563573883161513, "no_speech_prob": 0.08168521523475647}, {"id": 118, "seek": 62016, "start": 626.7199999999999, "end": 631.0, "text": " So one possibility for example will be to store the unwind information in process.", "tokens": [50692, 407, 472, 7959, 337, 1365, 486, 312, 281, 3531, 264, 517, 12199, 1589, 294, 1399, 13, 50906], "temperature": 0.0, "avg_logprob": -0.18399198849995932, "compression_ratio": 1.6563573883161513, "no_speech_prob": 0.08168521523475647}, {"id": 119, "seek": 62016, "start": 631.0, "end": 636.4, "text": " We could do this using a combination of Ptrace, Mmap and Mlock and this will require us to", "tokens": [50906, 492, 727, 360, 341, 1228, 257, 6562, 295, 430, 6903, 617, 11, 376, 24223, 293, 376, 4102, 293, 341, 486, 3651, 505, 281, 51176], "temperature": 0.0, "avg_logprob": -0.18399198849995932, "compression_ratio": 1.6563573883161513, "no_speech_prob": 0.08168521523475647}, {"id": 120, "seek": 62016, "start": 636.4, "end": 642.04, "text": " basically hijack the processes execution, introduce a new memory mapping inside of them", "tokens": [51176, 1936, 10625, 501, 264, 7555, 15058, 11, 5366, 257, 777, 4675, 18350, 1854, 295, 552, 51458], "temperature": 0.0, "avg_logprob": -0.18399198849995932, "compression_ratio": 1.6563573883161513, "no_speech_prob": 0.08168521523475647}, {"id": 121, "seek": 62016, "start": 642.04, "end": 647.04, "text": " and then we have to lock the memory because in BPF and in our type of BPF programs page", "tokens": [51458, 293, 550, 321, 362, 281, 4017, 264, 4675, 570, 294, 40533, 37, 293, 294, 527, 2010, 295, 40533, 37, 4268, 3028, 51708], "temperature": 0.0, "avg_logprob": -0.18399198849995932, "compression_ratio": 1.6563573883161513, "no_speech_prob": 0.08168521523475647}, {"id": 122, "seek": 62016, "start": 647.04, "end": 648.9599999999999, "text": " folds are not allowed.", "tokens": [51708, 31341, 366, 406, 4350, 13, 51804], "temperature": 0.0, "avg_logprob": -0.18399198849995932, "compression_ratio": 1.6563573883161513, "no_speech_prob": 0.08168521523475647}, {"id": 123, "seek": 64896, "start": 648.96, "end": 653.9200000000001, "text": " The problem with these approaches of course will be altering the execution flow of applications", "tokens": [50364, 440, 1154, 365, 613, 11587, 295, 1164, 486, 312, 11337, 278, 264, 15058, 3095, 295, 5821, 50612], "temperature": 0.0, "avg_logprob": -0.160294288027603, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.02003665082156658}, {"id": 124, "seek": 64896, "start": 653.9200000000001, "end": 656.64, "text": " which is something that we never want to do.", "tokens": [50612, 597, 307, 746, 300, 321, 1128, 528, 281, 360, 13, 50748], "temperature": 0.0, "avg_logprob": -0.160294288027603, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.02003665082156658}, {"id": 125, "seek": 64896, "start": 656.64, "end": 660.96, "text": " This complicates things a lot but for example one of the biggest problems is the life cycle", "tokens": [50748, 639, 16060, 1024, 721, 257, 688, 457, 337, 1365, 472, 295, 264, 3880, 2740, 307, 264, 993, 6586, 50964], "temperature": 0.0, "avg_logprob": -0.160294288027603, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.02003665082156658}, {"id": 126, "seek": 64896, "start": 660.96, "end": 661.96, "text": " right.", "tokens": [50964, 558, 13, 51014], "temperature": 0.0, "avg_logprob": -0.160294288027603, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.02003665082156658}, {"id": 127, "seek": 64896, "start": 661.96, "end": 667.0400000000001, "text": " So for example if our profiler dies before we finish cleaning up who is going to clean", "tokens": [51014, 407, 337, 1365, 498, 527, 1740, 5441, 2714, 949, 321, 2413, 8924, 493, 567, 307, 516, 281, 2541, 51268], "temperature": 0.0, "avg_logprob": -0.160294288027603, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.02003665082156658}, {"id": 128, "seek": 64896, "start": 667.0400000000001, "end": 671.72, "text": " up that memory segment or how is this going to be perceived by developers if they see", "tokens": [51268, 493, 300, 4675, 9469, 420, 577, 307, 341, 516, 281, 312, 19049, 538, 8849, 498, 436, 536, 51502], "temperature": 0.0, "avg_logprob": -0.160294288027603, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.02003665082156658}, {"id": 129, "seek": 64896, "start": 671.72, "end": 676.64, "text": " that the memory of their application has increased behind their backs just because some observability", "tokens": [51502, 300, 264, 4675, 295, 641, 3861, 575, 6505, 2261, 641, 19513, 445, 570, 512, 9951, 2310, 51748], "temperature": 0.0, "avg_logprob": -0.160294288027603, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.02003665082156658}, {"id": 130, "seek": 67664, "start": 676.64, "end": 680.4, "text": " tool is doing something that is not great.", "tokens": [50364, 2290, 307, 884, 746, 300, 307, 406, 869, 13, 50552], "temperature": 0.0, "avg_logprob": -0.15761370029089586, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.008940118364989758}, {"id": 131, "seek": 67664, "start": 680.4, "end": 683.56, "text": " But also there's another problem that is sharing memories harder.", "tokens": [50552, 583, 611, 456, 311, 1071, 1154, 300, 307, 5414, 8495, 6081, 13, 50710], "temperature": 0.0, "avg_logprob": -0.15761370029089586, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.008940118364989758}, {"id": 132, "seek": 67664, "start": 683.56, "end": 690.4399999999999, "text": " There is same page optimization from the kernel but if you don't think about that it's a problem", "tokens": [50710, 821, 307, 912, 3028, 19618, 490, 264, 28256, 457, 498, 291, 500, 380, 519, 466, 300, 309, 311, 257, 1154, 51054], "temperature": 0.0, "avg_logprob": -0.15761370029089586, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.008940118364989758}, {"id": 133, "seek": 67664, "start": 690.4399999999999, "end": 694.8, "text": " to have the same information generated over and over for example for a libc for every single", "tokens": [51054, 281, 362, 264, 912, 1589, 10833, 670, 293, 670, 337, 1365, 337, 257, 22854, 66, 337, 633, 2167, 51272], "temperature": 0.0, "avg_logprob": -0.15761370029089586, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.008940118364989758}, {"id": 134, "seek": 67664, "start": 694.8, "end": 697.04, "text": " process in your machine.", "tokens": [51272, 1399, 294, 428, 3479, 13, 51384], "temperature": 0.0, "avg_logprob": -0.15761370029089586, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.008940118364989758}, {"id": 135, "seek": 67664, "start": 697.04, "end": 701.76, "text": " So that's why we ended up using another solution which is pretty typical in the BPF space which", "tokens": [51384, 407, 300, 311, 983, 321, 4590, 493, 1228, 1071, 3827, 597, 307, 1238, 7476, 294, 264, 40533, 37, 1901, 597, 51620], "temperature": 0.0, "avg_logprob": -0.15761370029089586, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.008940118364989758}, {"id": 136, "seek": 67664, "start": 701.76, "end": 703.96, "text": " is using BPF maps.", "tokens": [51620, 307, 1228, 40533, 37, 11317, 13, 51730], "temperature": 0.0, "avg_logprob": -0.15761370029089586, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.008940118364989758}, {"id": 137, "seek": 70396, "start": 703.96, "end": 708.96, "text": " In case you're not familiar BPF maps are data structures that can be written or read from", "tokens": [50364, 682, 1389, 291, 434, 406, 4963, 40533, 37, 11317, 366, 1412, 9227, 300, 393, 312, 3720, 420, 1401, 490, 50614], "temperature": 0.0, "avg_logprob": -0.19910952828147194, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.007948124781250954}, {"id": 138, "seek": 70396, "start": 708.96, "end": 711.0, "text": " both user and kernel space.", "tokens": [50614, 1293, 4195, 293, 28256, 1901, 13, 50716], "temperature": 0.0, "avg_logprob": -0.19910952828147194, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.007948124781250954}, {"id": 139, "seek": 70396, "start": 711.0, "end": 715.48, "text": " We're using hash tables everywhere which in the case of BPF they're basically a mapping", "tokens": [50716, 492, 434, 1228, 22019, 8020, 5315, 597, 294, 264, 1389, 295, 40533, 37, 436, 434, 1936, 257, 18350, 50940], "temperature": 0.0, "avg_logprob": -0.19910952828147194, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.007948124781250954}, {"id": 140, "seek": 70396, "start": 715.48, "end": 720.6, "text": " of bytes to bytes that store arbitrary information.", "tokens": [50940, 295, 36088, 281, 36088, 300, 3531, 23211, 1589, 13, 51196], "temperature": 0.0, "avg_logprob": -0.19910952828147194, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.007948124781250954}, {"id": 141, "seek": 70396, "start": 720.6, "end": 725.96, "text": " So some BPF maps, some BPF programs as well are allowed to lazily allocate memory for", "tokens": [51196, 407, 512, 40533, 37, 11317, 11, 512, 40533, 37, 4268, 382, 731, 366, 4350, 281, 19320, 953, 35713, 4675, 337, 51464], "temperature": 0.0, "avg_logprob": -0.19910952828147194, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.007948124781250954}, {"id": 142, "seek": 70396, "start": 725.96, "end": 730.4000000000001, "text": " their data structures but in the case of our tracing program we kind of do that and this", "tokens": [51464, 641, 1412, 9227, 457, 294, 264, 1389, 295, 527, 25262, 1461, 321, 733, 295, 360, 300, 293, 341, 51686], "temperature": 0.0, "avg_logprob": -0.19910952828147194, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.007948124781250954}, {"id": 143, "seek": 70396, "start": 730.4000000000001, "end": 731.4000000000001, "text": " has some implications.", "tokens": [51686, 575, 512, 16602, 13, 51736], "temperature": 0.0, "avg_logprob": -0.19910952828147194, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.007948124781250954}, {"id": 144, "seek": 73140, "start": 731.4, "end": 736.48, "text": " So we need to mem-lock that, well the kernel, sorry user space, mem-lock that memory and", "tokens": [50364, 407, 321, 643, 281, 1334, 12, 4102, 300, 11, 731, 264, 28256, 11, 2597, 4195, 1901, 11, 1334, 12, 4102, 300, 4675, 293, 50618], "temperature": 0.0, "avg_logprob": -0.17584770770112346, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.0003728478914126754}, {"id": 145, "seek": 73140, "start": 736.48, "end": 739.9599999999999, "text": " otherwise our program wouldn't be able to run.", "tokens": [50618, 5911, 527, 1461, 2759, 380, 312, 1075, 281, 1190, 13, 50792], "temperature": 0.0, "avg_logprob": -0.17584770770112346, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.0003728478914126754}, {"id": 146, "seek": 73140, "start": 739.9599999999999, "end": 745.4399999999999, "text": " And by using this approach we are also able to reuse these memory mappings which is great", "tokens": [50792, 400, 538, 1228, 341, 3109, 321, 366, 611, 1075, 281, 26225, 613, 4675, 463, 28968, 597, 307, 869, 51066], "temperature": 0.0, "avg_logprob": -0.17584770770112346, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.0003728478914126754}, {"id": 147, "seek": 73140, "start": 745.4399999999999, "end": 751.0799999999999, "text": " because that means we don't have to do the same work over and over and we use less space.", "tokens": [51066, 570, 300, 1355, 321, 500, 380, 362, 281, 360, 264, 912, 589, 670, 293, 670, 293, 321, 764, 1570, 1901, 13, 51348], "temperature": 0.0, "avg_logprob": -0.17584770770112346, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.0003728478914126754}, {"id": 148, "seek": 73140, "start": 751.0799999999999, "end": 754.64, "text": " So let's take a look at the logical representation of the unwind tables.", "tokens": [51348, 407, 718, 311, 747, 257, 574, 412, 264, 14978, 10290, 295, 264, 517, 12199, 8020, 13, 51526], "temperature": 0.0, "avg_logprob": -0.17584770770112346, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.0003728478914126754}, {"id": 149, "seek": 73140, "start": 754.64, "end": 758.8, "text": " So this is not how the layout is in memory but think about for example the unwind tables", "tokens": [51526, 407, 341, 307, 406, 577, 264, 13333, 307, 294, 4675, 457, 519, 466, 337, 1365, 264, 517, 12199, 8020, 51734], "temperature": 0.0, "avg_logprob": -0.17584770770112346, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.0003728478914126754}, {"id": 150, "seek": 75880, "start": 758.8, "end": 764.0799999999999, "text": " for libc, mysql, zlib and systemd how they will be laid out in memory if we could allocate", "tokens": [50364, 337, 22854, 66, 11, 452, 82, 80, 75, 11, 710, 38270, 293, 1185, 67, 577, 436, 486, 312, 9897, 484, 294, 4675, 498, 321, 727, 35713, 50628], "temperature": 0.0, "avg_logprob": -0.16161664326985678, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.004403111059218645}, {"id": 151, "seek": 75880, "start": 764.0799999999999, "end": 767.0, "text": " a large chunk of memory.", "tokens": [50628, 257, 2416, 16635, 295, 4675, 13, 50774], "temperature": 0.0, "avg_logprob": -0.16161664326985678, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.004403111059218645}, {"id": 152, "seek": 75880, "start": 767.0, "end": 773.0799999999999, "text": " But in reality there's limits everywhere obviously and in BPF we have done some tests", "tokens": [50774, 583, 294, 4103, 456, 311, 10406, 5315, 2745, 293, 294, 40533, 37, 321, 362, 1096, 512, 6921, 51078], "temperature": 0.0, "avg_logprob": -0.16161664326985678, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.004403111059218645}, {"id": 153, "seek": 75880, "start": 773.0799999999999, "end": 777.24, "text": " and in the machines that we want, well the kernels we want to support we can allocate", "tokens": [51078, 293, 294, 264, 8379, 300, 321, 528, 11, 731, 264, 23434, 1625, 321, 528, 281, 1406, 321, 393, 35713, 51286], "temperature": 0.0, "avg_logprob": -0.16161664326985678, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.004403111059218645}, {"id": 154, "seek": 75880, "start": 777.24, "end": 783.88, "text": " up to 25,000 unwind entries per value of the hash map.", "tokens": [51286, 493, 281, 3552, 11, 1360, 517, 12199, 23041, 680, 2158, 295, 264, 22019, 4471, 13, 51618], "temperature": 0.0, "avg_logprob": -0.16161664326985678, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.004403111059218645}, {"id": 155, "seek": 75880, "start": 783.88, "end": 788.28, "text": " So obviously this was a problem for us because in some cases we have some customers that", "tokens": [51618, 407, 2745, 341, 390, 257, 1154, 337, 505, 570, 294, 512, 3331, 321, 362, 512, 4581, 300, 51838], "temperature": 0.0, "avg_logprob": -0.16161664326985678, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.004403111059218645}, {"id": 156, "seek": 78828, "start": 788.28, "end": 794.8399999999999, "text": " have applications with unwind tables with 3, 4 million unwind rows which is quite ridiculous", "tokens": [50364, 362, 5821, 365, 517, 12199, 8020, 365, 805, 11, 1017, 2459, 517, 12199, 13241, 597, 307, 1596, 11083, 50692], "temperature": 0.0, "avg_logprob": -0.1474533906349769, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.002310224575921893}, {"id": 157, "seek": 78828, "start": 794.8399999999999, "end": 801.4, "text": " just to give you an idea libc I think has like 60k entries so having a couple million", "tokens": [50692, 445, 281, 976, 291, 364, 1558, 22854, 66, 286, 519, 575, 411, 4060, 74, 23041, 370, 1419, 257, 1916, 2459, 51020], "temperature": 0.0, "avg_logprob": -0.1474533906349769, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.002310224575921893}, {"id": 158, "seek": 78828, "start": 801.4, "end": 803.4, "text": " is significant.", "tokens": [51020, 307, 4776, 13, 51120], "temperature": 0.0, "avg_logprob": -0.1474533906349769, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.002310224575921893}, {"id": 159, "seek": 78828, "start": 803.4, "end": 808.52, "text": " But yeah we came up with the same solution that you would use in any other data intensive", "tokens": [51120, 583, 1338, 321, 1361, 493, 365, 264, 912, 3827, 300, 291, 576, 764, 294, 604, 661, 1412, 18957, 51376], "temperature": 0.0, "avg_logprob": -0.1474533906349769, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.002310224575921893}, {"id": 160, "seek": 78828, "start": 808.52, "end": 812.8, "text": " application which is to partition or shard the data.", "tokens": [51376, 3861, 597, 307, 281, 24808, 420, 402, 515, 264, 1412, 13, 51590], "temperature": 0.0, "avg_logprob": -0.1474533906349769, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.002310224575921893}, {"id": 161, "seek": 78828, "start": 812.8, "end": 817.8, "text": " So the way we're doing this is we have multiple entries that are allocated when our profilers", "tokens": [51590, 407, 264, 636, 321, 434, 884, 341, 307, 321, 362, 3866, 23041, 300, 366, 29772, 562, 527, 1740, 388, 433, 51840], "temperature": 0.0, "avg_logprob": -0.1474533906349769, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.002310224575921893}, {"id": 162, "seek": 81780, "start": 817.8399999999999, "end": 819.24, "text": " start running.", "tokens": [50366, 722, 2614, 13, 50436], "temperature": 0.0, "avg_logprob": -0.19937109064172814, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.005010472144931555}, {"id": 163, "seek": 81780, "start": 819.24, "end": 822.8399999999999, "text": " We allocate a different number depending on the available memory on the system and the", "tokens": [50436, 492, 35713, 257, 819, 1230, 5413, 322, 264, 2435, 4675, 322, 264, 1185, 293, 264, 50616], "temperature": 0.0, "avg_logprob": -0.19937109064172814, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.005010472144931555}, {"id": 164, "seek": 81780, "start": 822.8399999999999, "end": 829.92, "text": " overhead that you're willing to pay and yeah depending on how many charts you have you", "tokens": [50616, 19922, 300, 291, 434, 4950, 281, 1689, 293, 1338, 5413, 322, 577, 867, 17767, 291, 362, 291, 50970], "temperature": 0.0, "avg_logprob": -0.19937109064172814, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.005010472144931555}, {"id": 165, "seek": 81780, "start": 829.92, "end": 835.12, "text": " have a different CPU to memory trade off because the more memory you use it has to be locked", "tokens": [50970, 362, 257, 819, 13199, 281, 4675, 4923, 766, 570, 264, 544, 4675, 291, 764, 309, 575, 281, 312, 9376, 51230], "temperature": 0.0, "avg_logprob": -0.19937109064172814, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.005010472144931555}, {"id": 166, "seek": 81780, "start": 835.12, "end": 840.76, "text": " in memory, it can be swapped out which is in some applications not ideal but at the same", "tokens": [51230, 294, 4675, 11, 309, 393, 312, 50011, 484, 597, 307, 294, 512, 5821, 406, 7157, 457, 412, 264, 912, 51512], "temperature": 0.0, "avg_logprob": -0.19937109064172814, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.005010472144931555}, {"id": 167, "seek": 81780, "start": 840.76, "end": 844.52, "text": " time that means that you don't have to regenerate the tables if they are full and then you want", "tokens": [51512, 565, 300, 1355, 300, 291, 500, 380, 362, 281, 26358, 473, 264, 8020, 498, 436, 366, 1577, 293, 550, 291, 528, 51700], "temperature": 0.0, "avg_logprob": -0.19937109064172814, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.005010472144931555}, {"id": 168, "seek": 84452, "start": 844.52, "end": 848.92, "text": " to give like other processes a third chance to be profiled.", "tokens": [50364, 281, 976, 411, 661, 7555, 257, 2636, 2931, 281, 312, 1740, 7292, 13, 50584], "temperature": 0.0, "avg_logprob": -0.17151382866255735, "compression_ratio": 1.7467811158798283, "no_speech_prob": 0.008104878477752209}, {"id": 169, "seek": 84452, "start": 848.92, "end": 853.64, "text": " So the way this will work for example for a process like system D is that will be like", "tokens": [50584, 407, 264, 636, 341, 486, 589, 337, 1365, 337, 257, 1399, 411, 1185, 413, 307, 300, 486, 312, 411, 50820], "temperature": 0.0, "avg_logprob": -0.17151382866255735, "compression_ratio": 1.7467811158798283, "no_speech_prob": 0.008104878477752209}, {"id": 170, "seek": 84452, "start": 853.64, "end": 859.48, "text": " the representation of the size of its unwind tables and because it's bigger than the size", "tokens": [50820, 264, 10290, 295, 264, 2744, 295, 1080, 517, 12199, 8020, 293, 570, 309, 311, 3801, 813, 264, 2744, 51112], "temperature": 0.0, "avg_logprob": -0.17151382866255735, "compression_ratio": 1.7467811158798283, "no_speech_prob": 0.008104878477752209}, {"id": 171, "seek": 84452, "start": 859.48, "end": 862.92, "text": " of a shard it will have to be chunked.", "tokens": [51112, 295, 257, 402, 515, 309, 486, 362, 281, 312, 16635, 292, 13, 51284], "temperature": 0.0, "avg_logprob": -0.17151382866255735, "compression_ratio": 1.7467811158798283, "no_speech_prob": 0.008104878477752209}, {"id": 172, "seek": 84452, "start": 862.92, "end": 865.4399999999999, "text": " So here we can see how this is chunked in two.", "tokens": [51284, 407, 510, 321, 393, 536, 577, 341, 307, 16635, 292, 294, 732, 13, 51410], "temperature": 0.0, "avg_logprob": -0.17151382866255735, "compression_ratio": 1.7467811158798283, "no_speech_prob": 0.008104878477752209}, {"id": 173, "seek": 84452, "start": 865.4399999999999, "end": 872.36, "text": " The first chunk will go in the shard zero and a bunch of the unwind entries from the", "tokens": [51410, 440, 700, 16635, 486, 352, 294, 264, 402, 515, 4018, 293, 257, 3840, 295, 264, 517, 12199, 23041, 490, 264, 51756], "temperature": 0.0, "avg_logprob": -0.17151382866255735, "compression_ratio": 1.7467811158798283, "no_speech_prob": 0.008104878477752209}, {"id": 174, "seek": 87236, "start": 872.4, "end": 879.9, "text": " tail will go to the shard one and of course because we have this new layer of indirection", "tokens": [50366, 6838, 486, 352, 281, 264, 402, 515, 472, 293, 295, 1164, 570, 321, 362, 341, 777, 4583, 295, 1016, 621, 882, 50741], "temperature": 0.0, "avg_logprob": -0.18261441817650428, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.003056588117033243}, {"id": 175, "seek": 87236, "start": 879.9, "end": 884.72, "text": " we need to somehow keep track of you know all these bookkeeping and know what is the", "tokens": [50741, 321, 643, 281, 6063, 1066, 2837, 295, 291, 458, 439, 613, 1446, 25769, 293, 458, 437, 307, 264, 50982], "temperature": 0.0, "avg_logprob": -0.18261441817650428, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.003056588117033243}, {"id": 176, "seek": 87236, "start": 884.72, "end": 889.6800000000001, "text": " state of the worlds and we're doing this of course with more BBF maps.", "tokens": [50982, 1785, 295, 264, 13401, 293, 321, 434, 884, 341, 295, 1164, 365, 544, 19168, 37, 11317, 13, 51230], "temperature": 0.0, "avg_logprob": -0.18261441817650428, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.003056588117033243}, {"id": 177, "seek": 87236, "start": 889.6800000000001, "end": 897.0, "text": " So a process has multiple mappings each mapping has one or more chunks and then each chunk", "tokens": [51230, 407, 257, 1399, 575, 3866, 463, 28968, 1184, 18350, 575, 472, 420, 544, 24004, 293, 550, 1184, 16635, 51596], "temperature": 0.0, "avg_logprob": -0.18261441817650428, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.003056588117033243}, {"id": 178, "seek": 87236, "start": 897.0, "end": 902.32, "text": " maps to exactly one shard and in particular the region within one shard because you can", "tokens": [51596, 11317, 281, 2293, 472, 402, 515, 293, 294, 1729, 264, 4458, 1951, 472, 402, 515, 570, 291, 393, 51862], "temperature": 0.0, "avg_logprob": -0.18261441817650428, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.003056588117033243}, {"id": 179, "seek": 90232, "start": 902.32, "end": 908.2800000000001, "text": " have from one unwind entry up to 2050k.", "tokens": [50364, 362, 490, 472, 517, 12199, 8729, 493, 281, 38308, 74, 13, 50662], "temperature": 0.0, "avg_logprob": -0.17962848931028133, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.001674513565376401}, {"id": 180, "seek": 90232, "start": 908.2800000000001, "end": 911.4000000000001, "text": " Of course this has the benefit that I was mentioning before that is because we were", "tokens": [50662, 2720, 1164, 341, 575, 264, 5121, 300, 286, 390, 18315, 949, 300, 307, 570, 321, 645, 50818], "temperature": 0.0, "avg_logprob": -0.17962848931028133, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.001674513565376401}, {"id": 181, "seek": 90232, "start": 911.4000000000001, "end": 916.5600000000001, "text": " sharing the unwind tables that means that we spent actually not that many CPU cycles", "tokens": [50818, 5414, 264, 517, 12199, 8020, 300, 1355, 300, 321, 4418, 767, 406, 300, 867, 13199, 17796, 51076], "temperature": 0.0, "avg_logprob": -0.17962848931028133, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.001674513565376401}, {"id": 182, "seek": 90232, "start": 916.5600000000001, "end": 918.6800000000001, "text": " doing all the work that Shali was mentioning before.", "tokens": [51076, 884, 439, 264, 589, 300, 1160, 5103, 390, 18315, 949, 13, 51182], "temperature": 0.0, "avg_logprob": -0.17962848931028133, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.001674513565376401}, {"id": 183, "seek": 90232, "start": 918.6800000000001, "end": 923.44, "text": " We need to find the ELF section where the door of CFI information is but also we need", "tokens": [51182, 492, 643, 281, 915, 264, 14426, 37, 3541, 689, 264, 2853, 295, 21792, 40, 1589, 307, 457, 611, 321, 643, 51420], "temperature": 0.0, "avg_logprob": -0.17962848931028133, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.001674513565376401}, {"id": 184, "seek": 90232, "start": 923.44, "end": 924.6400000000001, "text": " to parse evaluate it.", "tokens": [51420, 281, 48377, 13059, 309, 13, 51480], "temperature": 0.0, "avg_logprob": -0.17962848931028133, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.001674513565376401}, {"id": 185, "seek": 90232, "start": 924.6400000000001, "end": 929.7600000000001, "text": " We have two levels of VM that have to run which is not something that is very CPU consuming", "tokens": [51480, 492, 362, 732, 4358, 295, 18038, 300, 362, 281, 1190, 597, 307, 406, 746, 300, 307, 588, 13199, 19867, 51736], "temperature": 0.0, "avg_logprob": -0.17962848931028133, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.001674513565376401}, {"id": 186, "seek": 92976, "start": 929.76, "end": 930.76, "text": " but still has to happen.", "tokens": [50364, 457, 920, 575, 281, 1051, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2004440211448349, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0012807835591956973}, {"id": 187, "seek": 92976, "start": 930.76, "end": 935.12, "text": " It has to process a bunch of information and generate these unwind tables in our custom", "tokens": [50414, 467, 575, 281, 1399, 257, 3840, 295, 1589, 293, 8460, 613, 517, 12199, 8020, 294, 527, 2375, 50632], "temperature": 0.0, "avg_logprob": -0.2004440211448349, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0012807835591956973}, {"id": 188, "seek": 92976, "start": 935.12, "end": 936.56, "text": " formats.", "tokens": [50632, 25879, 13, 50704], "temperature": 0.0, "avg_logprob": -0.2004440211448349, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0012807835591956973}, {"id": 189, "seek": 92976, "start": 936.56, "end": 942.96, "text": " So by sharing this for example Lipsy will be shared for all the processes so that means", "tokens": [50704, 407, 538, 5414, 341, 337, 1365, 441, 2600, 88, 486, 312, 5507, 337, 439, 264, 7555, 370, 300, 1355, 51024], "temperature": 0.0, "avg_logprob": -0.2004440211448349, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0012807835591956973}, {"id": 190, "seek": 92976, "start": 942.96, "end": 948.16, "text": " that we only need to add the bookkeeping data structures which are really cheap to generate.", "tokens": [51024, 300, 321, 787, 643, 281, 909, 264, 1446, 25769, 1412, 9227, 597, 366, 534, 7084, 281, 8460, 13, 51284], "temperature": 0.0, "avg_logprob": -0.2004440211448349, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0012807835591956973}, {"id": 191, "seek": 92976, "start": 948.16, "end": 952.56, "text": " In some of the tests that we've been running we use less than 0.9% CPU within the total", "tokens": [51284, 682, 512, 295, 264, 6921, 300, 321, 600, 668, 2614, 321, 764, 1570, 813, 1958, 13, 24, 4, 13199, 1951, 264, 3217, 51504], "temperature": 0.0, "avg_logprob": -0.2004440211448349, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0012807835591956973}, {"id": 192, "seek": 92976, "start": 952.56, "end": 958.8, "text": " CPU cycles our profiler uses to generate the unwind tables and of course there is a lot", "tokens": [51504, 13199, 17796, 527, 1740, 5441, 4960, 281, 8460, 264, 517, 12199, 8020, 293, 295, 1164, 456, 307, 257, 688, 51816], "temperature": 0.0, "avg_logprob": -0.2004440211448349, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0012807835591956973}, {"id": 193, "seek": 95880, "start": 958.8, "end": 962.16, "text": " of things that we need to take into account like for example what happens if we run out", "tokens": [50364, 295, 721, 300, 321, 643, 281, 747, 666, 2696, 411, 337, 1365, 437, 2314, 498, 321, 1190, 484, 50532], "temperature": 0.0, "avg_logprob": -0.17143737663656977, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.1846485286951065}, {"id": 194, "seek": 95880, "start": 962.16, "end": 963.76, "text": " of space right?", "tokens": [50532, 295, 1901, 558, 30, 50612], "temperature": 0.0, "avg_logprob": -0.17143737663656977, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.1846485286951065}, {"id": 195, "seek": 95880, "start": 963.76, "end": 968.4399999999999, "text": " So what we do is we adaptively decide what to do in the moment.", "tokens": [50612, 407, 437, 321, 360, 307, 321, 6231, 3413, 4536, 437, 281, 360, 294, 264, 1623, 13, 50846], "temperature": 0.0, "avg_logprob": -0.17143737663656977, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.1846485286951065}, {"id": 196, "seek": 95880, "start": 968.4399999999999, "end": 974.7199999999999, "text": " We might wait a little bit until resetting the state or we might decide to give chance", "tokens": [50846, 492, 1062, 1699, 257, 707, 857, 1826, 14322, 783, 264, 1785, 420, 321, 1062, 4536, 281, 976, 2931, 51160], "temperature": 0.0, "avg_logprob": -0.17143737663656977, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.1846485286951065}, {"id": 197, "seek": 95880, "start": 974.7199999999999, "end": 978.76, "text": " up to other processes to be profiled so we wipe the whole thing and start again and as", "tokens": [51160, 493, 281, 661, 7555, 281, 312, 1740, 7292, 370, 321, 14082, 264, 1379, 551, 293, 722, 797, 293, 382, 51362], "temperature": 0.0, "avg_logprob": -0.17143737663656977, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.1846485286951065}, {"id": 198, "seek": 95880, "start": 978.76, "end": 980.9599999999999, "text": " you can see this is very similar to a bump allocator.", "tokens": [51362, 291, 393, 536, 341, 307, 588, 2531, 281, 257, 9961, 12660, 1639, 13, 51472], "temperature": 0.0, "avg_logprob": -0.17143737663656977, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.1846485286951065}, {"id": 199, "seek": 95880, "start": 980.9599999999999, "end": 985.88, "text": " This is basically a bump allocator that has been chunked up.", "tokens": [51472, 639, 307, 1936, 257, 9961, 12660, 1639, 300, 575, 668, 16635, 292, 493, 13, 51718], "temperature": 0.0, "avg_logprob": -0.17143737663656977, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.1846485286951065}, {"id": 200, "seek": 98588, "start": 985.88, "end": 993.08, "text": " So the process of unwinding this is we start with a PAD, we check if it has unwind information", "tokens": [50364, 407, 264, 1399, 295, 517, 12199, 278, 341, 307, 321, 722, 365, 257, 430, 6112, 11, 321, 1520, 498, 309, 575, 517, 12199, 1589, 50724], "temperature": 0.0, "avg_logprob": -0.1917118516940515, "compression_ratio": 1.8144796380090498, "no_speech_prob": 0.0048547605983912945}, {"id": 201, "seek": 98588, "start": 993.08, "end": 1000.52, "text": " then we need to find the mapping and for each mapping we know the minimum and the maximum", "tokens": [50724, 550, 321, 643, 281, 915, 264, 18350, 293, 337, 1184, 18350, 321, 458, 264, 7285, 293, 264, 6674, 51096], "temperature": 0.0, "avg_logprob": -0.1917118516940515, "compression_ratio": 1.8144796380090498, "no_speech_prob": 0.0048547605983912945}, {"id": 202, "seek": 98588, "start": 1000.52, "end": 1005.0, "text": " program counter so we need to do a linear search to find it.", "tokens": [51096, 1461, 5682, 370, 321, 643, 281, 360, 257, 8213, 3164, 281, 915, 309, 13, 51320], "temperature": 0.0, "avg_logprob": -0.1917118516940515, "compression_ratio": 1.8144796380090498, "no_speech_prob": 0.0048547605983912945}, {"id": 203, "seek": 98588, "start": 1005.0, "end": 1009.8, "text": " Then we find the chunk, with the chunk we already have the shard information so once", "tokens": [51320, 1396, 321, 915, 264, 16635, 11, 365, 264, 16635, 321, 1217, 362, 264, 402, 515, 1589, 370, 1564, 51560], "temperature": 0.0, "avg_logprob": -0.1917118516940515, "compression_ratio": 1.8144796380090498, "no_speech_prob": 0.0048547605983912945}, {"id": 204, "seek": 98588, "start": 1009.8, "end": 1014.48, "text": " we have the shard information we have to traverse up to 250,000 items.", "tokens": [51560, 321, 362, 264, 402, 515, 1589, 321, 362, 281, 45674, 493, 281, 11650, 11, 1360, 4754, 13, 51794], "temperature": 0.0, "avg_logprob": -0.1917118516940515, "compression_ratio": 1.8144796380090498, "no_speech_prob": 0.0048547605983912945}, {"id": 205, "seek": 101448, "start": 1014.48, "end": 1019.72, "text": " We do this just with a simple binary search.", "tokens": [50364, 492, 360, 341, 445, 365, 257, 2199, 17434, 3164, 13, 50626], "temperature": 0.0, "avg_logprob": -0.19627411810906378, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.025280658155679703}, {"id": 206, "seek": 101448, "start": 1019.72, "end": 1026.04, "text": " This takes obviously between seven or eight iterations and once we have the unwind action", "tokens": [50626, 639, 2516, 2745, 1296, 3407, 420, 3180, 36540, 293, 1564, 321, 362, 264, 517, 12199, 3069, 50942], "temperature": 0.0, "avg_logprob": -0.19627411810906378, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.025280658155679703}, {"id": 207, "seek": 101448, "start": 1026.04, "end": 1031.2, "text": " that tells us how to restore the previous frames registers we do those operations and", "tokens": [50942, 300, 5112, 505, 577, 281, 15227, 264, 3894, 12083, 38351, 321, 360, 729, 7705, 293, 51200], "temperature": 0.0, "avg_logprob": -0.19627411810906378, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.025280658155679703}, {"id": 208, "seek": 101448, "start": 1031.2, "end": 1035.48, "text": " we are ready to go to the next frame.", "tokens": [51200, 321, 366, 1919, 281, 352, 281, 264, 958, 3920, 13, 51414], "temperature": 0.0, "avg_logprob": -0.19627411810906378, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.025280658155679703}, {"id": 209, "seek": 101448, "start": 1035.48, "end": 1038.2, "text": " We are pretty much done for that frame.", "tokens": [51414, 492, 366, 1238, 709, 1096, 337, 300, 3920, 13, 51550], "temperature": 0.0, "avg_logprob": -0.19627411810906378, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.025280658155679703}, {"id": 210, "seek": 101448, "start": 1038.2, "end": 1043.88, "text": " If the stack trace is correct we know this because basically a stack when you have frame", "tokens": [51550, 759, 264, 8630, 13508, 307, 3006, 321, 458, 341, 570, 1936, 257, 8630, 562, 291, 362, 3920, 51834], "temperature": 0.0, "avg_logprob": -0.19627411810906378, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.025280658155679703}, {"id": 211, "seek": 104388, "start": 1043.88, "end": 1049.2800000000002, "text": " pointers the bottom of the stack is defined in applications with frame pointers when you", "tokens": [50364, 44548, 264, 2767, 295, 264, 8630, 307, 7642, 294, 5821, 365, 3920, 44548, 562, 291, 50634], "temperature": 0.0, "avg_logprob": -0.20547920802854142, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.02063020132482052}, {"id": 212, "seek": 104388, "start": 1049.2800000000002, "end": 1052.4, "text": " reach RBP equals zero this is defined by the ABI.", "tokens": [50634, 2524, 40302, 47, 6915, 4018, 341, 307, 7642, 538, 264, 316, 11291, 13, 50790], "temperature": 0.0, "avg_logprob": -0.20547920802854142, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.02063020132482052}, {"id": 213, "seek": 104388, "start": 1052.4, "end": 1057.3600000000001, "text": " When you have unwind tables it is defined by not having that program counter covered", "tokens": [50790, 1133, 291, 362, 517, 12199, 8020, 309, 307, 7642, 538, 406, 1419, 300, 1461, 5682, 5343, 51038], "temperature": 0.0, "avg_logprob": -0.20547920802854142, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.02063020132482052}, {"id": 214, "seek": 104388, "start": 1057.3600000000001, "end": 1062.72, "text": " by any unwind table and having RBP zero these are requirement by the ABI so if some application", "tokens": [51038, 538, 604, 517, 12199, 3199, 293, 1419, 40302, 47, 4018, 613, 366, 11695, 538, 264, 316, 11291, 370, 498, 512, 3861, 51306], "temperature": 0.0, "avg_logprob": -0.20547920802854142, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.02063020132482052}, {"id": 215, "seek": 104388, "start": 1062.72, "end": 1065.96, "text": " doesn't respect it it is completely broken.", "tokens": [51306, 1177, 380, 3104, 309, 309, 307, 2584, 5463, 13, 51468], "temperature": 0.0, "avg_logprob": -0.20547920802854142, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.02063020132482052}, {"id": 216, "seek": 104388, "start": 1065.96, "end": 1070.5600000000002, "text": " So once we verify that the stack is correct that we have reached the bottom of the stack", "tokens": [51468, 407, 1564, 321, 16888, 300, 264, 8630, 307, 3006, 300, 321, 362, 6488, 264, 2767, 295, 264, 8630, 51698], "temperature": 0.0, "avg_logprob": -0.20547920802854142, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.02063020132482052}, {"id": 217, "seek": 107056, "start": 1070.6399999999999, "end": 1075.96, "text": " then we hash the addresses and we hash we add the hash to a map and we bump a counter", "tokens": [50368, 550, 321, 22019, 264, 16862, 293, 321, 22019, 321, 909, 264, 22019, 281, 257, 4471, 293, 321, 9961, 257, 5682, 50634], "temperature": 0.0, "avg_logprob": -0.18218027988326885, "compression_ratio": 1.7007874015748032, "no_speech_prob": 0.005350605584681034}, {"id": 218, "seek": 107056, "start": 1075.96, "end": 1082.44, "text": " and we do this I think it is 19 times a second for every single CPU in your box and every", "tokens": [50634, 293, 321, 360, 341, 286, 519, 309, 307, 1294, 1413, 257, 1150, 337, 633, 2167, 13199, 294, 428, 2424, 293, 633, 50958], "temperature": 0.0, "avg_logprob": -0.18218027988326885, "compression_ratio": 1.7007874015748032, "no_speech_prob": 0.005350605584681034}, {"id": 219, "seek": 107056, "start": 1082.44, "end": 1086.56, "text": " couple seconds we collect all this information we generate a profile and we send it to some", "tokens": [50958, 1916, 3949, 321, 2500, 439, 341, 1589, 321, 8460, 257, 7964, 293, 321, 2845, 309, 281, 512, 51164], "temperature": 0.0, "avg_logprob": -0.18218027988326885, "compression_ratio": 1.7007874015748032, "no_speech_prob": 0.005350605584681034}, {"id": 220, "seek": 107056, "start": 1086.56, "end": 1090.24, "text": " server for inspection.", "tokens": [51164, 7154, 337, 22085, 13, 51348], "temperature": 0.0, "avg_logprob": -0.18218027988326885, "compression_ratio": 1.7007874015748032, "no_speech_prob": 0.005350605584681034}, {"id": 221, "seek": 107056, "start": 1090.24, "end": 1095.3999999999999, "text": " So of course BPF is an interesting environment to work with it is amazing and we really really", "tokens": [51348, 407, 295, 1164, 40533, 37, 307, 364, 1880, 2823, 281, 589, 365, 309, 307, 2243, 293, 321, 534, 534, 51606], "temperature": 0.0, "avg_logprob": -0.18218027988326885, "compression_ratio": 1.7007874015748032, "no_speech_prob": 0.005350605584681034}, {"id": 222, "seek": 107056, "start": 1095.3999999999999, "end": 1098.12, "text": " like it but we need to be aware of some stuff.", "tokens": [51606, 411, 309, 457, 321, 643, 281, 312, 3650, 295, 512, 1507, 13, 51742], "temperature": 0.0, "avg_logprob": -0.18218027988326885, "compression_ratio": 1.7007874015748032, "no_speech_prob": 0.005350605584681034}, {"id": 223, "seek": 109812, "start": 1098.1599999999999, "end": 1104.2399999999998, "text": " First of all because we cannot page in or page out pages of the contained unwind tables", "tokens": [50366, 2386, 295, 439, 570, 321, 2644, 3028, 294, 420, 3028, 484, 7183, 295, 264, 16212, 517, 12199, 8020, 50670], "temperature": 0.0, "avg_logprob": -0.1662904723616671, "compression_ratio": 1.7440273037542662, "no_speech_prob": 0.003980326931923628}, {"id": 224, "seek": 109812, "start": 1104.2399999999998, "end": 1108.0, "text": " that has to be locked in memory so we need to be very careful with how we organize our", "tokens": [50670, 300, 575, 281, 312, 9376, 294, 4675, 370, 321, 643, 281, 312, 588, 5026, 365, 577, 321, 13859, 527, 50858], "temperature": 0.0, "avg_logprob": -0.1662904723616671, "compression_ratio": 1.7440273037542662, "no_speech_prob": 0.003980326931923628}, {"id": 225, "seek": 109812, "start": 1108.0, "end": 1113.1999999999998, "text": " data and the layout of that data to make it as small as possible so we basically pack", "tokens": [50858, 1412, 293, 264, 13333, 295, 300, 1412, 281, 652, 309, 382, 1359, 382, 1944, 370, 321, 1936, 2844, 51118], "temperature": 0.0, "avg_logprob": -0.1662904723616671, "compression_ratio": 1.7440273037542662, "no_speech_prob": 0.003980326931923628}, {"id": 226, "seek": 109812, "start": 1113.1999999999998, "end": 1117.52, "text": " every single thing that can be packed and then there are some interesting BPF things", "tokens": [51118, 633, 2167, 551, 300, 393, 312, 13265, 293, 550, 456, 366, 512, 1880, 40533, 37, 721, 51334], "temperature": 0.0, "avg_logprob": -0.1662904723616671, "compression_ratio": 1.7440273037542662, "no_speech_prob": 0.003980326931923628}, {"id": 227, "seek": 109812, "start": 1117.52, "end": 1120.6399999999999, "text": " that for most people that have written BPF programs this is well known but I just want", "tokens": [51334, 300, 337, 881, 561, 300, 362, 3720, 40533, 37, 4268, 341, 307, 731, 2570, 457, 286, 445, 528, 51490], "temperature": 0.0, "avg_logprob": -0.1662904723616671, "compression_ratio": 1.7440273037542662, "no_speech_prob": 0.003980326931923628}, {"id": 228, "seek": 109812, "start": 1120.6399999999999, "end": 1124.9199999999998, "text": " to talk a little bit about how we are dealing with some of the BPF challenges.", "tokens": [51490, 281, 751, 257, 707, 857, 466, 577, 321, 366, 6260, 365, 512, 295, 264, 40533, 37, 4759, 13, 51704], "temperature": 0.0, "avg_logprob": -0.1662904723616671, "compression_ratio": 1.7440273037542662, "no_speech_prob": 0.003980326931923628}, {"id": 229, "seek": 112492, "start": 1124.92, "end": 1130.2, "text": " So one of it is a stack size which is easy to work around if I am not mistaken we have", "tokens": [50364, 407, 472, 295, 309, 307, 257, 8630, 2744, 597, 307, 1858, 281, 589, 926, 498, 286, 669, 406, 21333, 321, 362, 50628], "temperature": 0.0, "avg_logprob": -0.17601522377559117, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006481211166828871}, {"id": 230, "seek": 112492, "start": 1130.2, "end": 1135.3200000000002, "text": " 512 bytes which is not a lot so we use another BPF map that we use sort of a global data", "tokens": [50628, 1025, 4762, 36088, 597, 307, 406, 257, 688, 370, 321, 764, 1071, 40533, 37, 4471, 300, 321, 764, 1333, 295, 257, 4338, 1412, 50884], "temperature": 0.0, "avg_logprob": -0.17601522377559117, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006481211166828871}, {"id": 231, "seek": 112492, "start": 1135.3200000000002, "end": 1142.5600000000002, "text": " structure and that stores basically like kind of your heap if you will and then for the", "tokens": [50884, 3877, 293, 300, 9512, 1936, 411, 733, 295, 428, 33591, 498, 291, 486, 293, 550, 337, 264, 51246], "temperature": 0.0, "avg_logprob": -0.17601522377559117, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006481211166828871}, {"id": 232, "seek": 112492, "start": 1142.5600000000002, "end": 1147.44, "text": " program size this is a limitation that comes in two ways first there is probably some limitation", "tokens": [51246, 1461, 2744, 341, 307, 257, 27432, 300, 1487, 294, 732, 2098, 700, 456, 307, 1391, 512, 27432, 51490], "temperature": 0.0, "avg_logprob": -0.17601522377559117, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006481211166828871}, {"id": 233, "seek": 112492, "start": 1147.44, "end": 1152.24, "text": " in the amount of how many opcodes you can load in the kernel but also the BPF verifier", "tokens": [51490, 294, 264, 2372, 295, 577, 867, 999, 66, 4789, 291, 393, 3677, 294, 264, 28256, 457, 611, 264, 40533, 37, 1306, 9902, 51730], "temperature": 0.0, "avg_logprob": -0.17601522377559117, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006481211166828871}, {"id": 234, "seek": 115224, "start": 1152.32, "end": 1157.88, "text": " that ensures that the BPF code is safe to load for example you don't do any de-reference", "tokens": [50368, 300, 28111, 300, 264, 40533, 37, 3089, 307, 3273, 281, 3677, 337, 1365, 291, 500, 380, 360, 604, 368, 12, 265, 5158, 50646], "temperature": 0.0, "avg_logprob": -0.12466751854374723, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.018964920192956924}, {"id": 235, "seek": 115224, "start": 1157.88, "end": 1165.28, "text": " that could go wrong or that your program terminates it has some limits it could theoretically", "tokens": [50646, 300, 727, 352, 2085, 420, 300, 428, 1461, 10761, 1024, 309, 575, 512, 10406, 309, 727, 29400, 51016], "temperature": 0.0, "avg_logprob": -0.12466751854374723, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.018964920192956924}, {"id": 236, "seek": 115224, "start": 1165.28, "end": 1169.52, "text": " run forever trying to verify your program but it has some limits and we hit this limit", "tokens": [51016, 1190, 5680, 1382, 281, 16888, 428, 1461, 457, 309, 575, 512, 10406, 293, 321, 2045, 341, 4948, 51228], "temperature": 0.0, "avg_logprob": -0.12466751854374723, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.018964920192956924}, {"id": 237, "seek": 115224, "start": 1169.52, "end": 1174.44, "text": " everywhere in our code for example we hit it when running our binary research it complains", "tokens": [51228, 5315, 294, 527, 3089, 337, 1365, 321, 2045, 309, 562, 2614, 527, 17434, 2132, 309, 1209, 2315, 51474], "temperature": 0.0, "avg_logprob": -0.12466751854374723, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.018964920192956924}, {"id": 238, "seek": 115224, "start": 1174.44, "end": 1179.96, "text": " saying that it is too complex for us to analyze so what we do here is that not only we have", "tokens": [51474, 1566, 300, 309, 307, 886, 3997, 337, 505, 281, 12477, 370, 437, 321, 360, 510, 307, 300, 406, 787, 321, 362, 51750], "temperature": 0.0, "avg_logprob": -0.12466751854374723, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.018964920192956924}, {"id": 239, "seek": 117996, "start": 1180.0, "end": 1184.88, "text": " sharded our data we have sharded our code our code and data the same thing right so we", "tokens": [50366, 402, 22803, 527, 1412, 321, 362, 402, 22803, 527, 3089, 527, 3089, 293, 1412, 264, 912, 551, 558, 370, 321, 50610], "temperature": 0.0, "avg_logprob": -0.18277077535981112, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.002406577579677105}, {"id": 240, "seek": 117996, "start": 1184.88, "end": 1189.44, "text": " basically have our program split into many sub-programs and we keep the states and we", "tokens": [50610, 1936, 362, 527, 1461, 7472, 666, 867, 1422, 12, 32726, 82, 293, 321, 1066, 264, 4368, 293, 321, 50838], "temperature": 0.0, "avg_logprob": -0.18277077535981112, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.002406577579677105}, {"id": 241, "seek": 117996, "start": 1189.44, "end": 1195.48, "text": " basically execute one program after each other and continue the state so one of the techniques", "tokens": [50838, 1936, 14483, 472, 1461, 934, 1184, 661, 293, 2354, 264, 1785, 370, 472, 295, 264, 7512, 51140], "temperature": 0.0, "avg_logprob": -0.18277077535981112, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.002406577579677105}, {"id": 242, "seek": 117996, "start": 1195.48, "end": 1201.0, "text": " we use is BPF tail calls two other things that are way more modern and they are amazing", "tokens": [51140, 321, 764, 307, 40533, 37, 6838, 5498, 732, 661, 721, 300, 366, 636, 544, 4363, 293, 436, 366, 2243, 51416], "temperature": 0.0, "avg_logprob": -0.18277077535981112, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.002406577579677105}, {"id": 243, "seek": 117996, "start": 1201.0, "end": 1206.32, "text": " to our bounded loops and BPF loop which is a wonderful helper the problem is that while", "tokens": [51416, 281, 527, 37498, 16121, 293, 40533, 37, 6367, 597, 307, 257, 3715, 36133, 264, 1154, 307, 300, 1339, 51682], "temperature": 0.0, "avg_logprob": -0.18277077535981112, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.002406577579677105}, {"id": 244, "seek": 120632, "start": 1206.36, "end": 1211.6, "text": " we use bounded loops right now we don't use BPF loop because it's only supported in modern", "tokens": [50366, 321, 764, 37498, 16121, 558, 586, 321, 500, 380, 764, 40533, 37, 6367, 570, 309, 311, 787, 8104, 294, 4363, 50628], "temperature": 0.0, "avg_logprob": -0.13825765662237044, "compression_ratio": 1.7490494296577948, "no_speech_prob": 0.0015764250420033932}, {"id": 245, "seek": 120632, "start": 1211.6, "end": 1218.48, "text": " kernels but it's great and if you can use it you should now because we're a profiler and we", "tokens": [50628, 23434, 1625, 457, 309, 311, 869, 293, 498, 291, 393, 764, 309, 291, 820, 586, 570, 321, 434, 257, 1740, 5441, 293, 321, 50972], "temperature": 0.0, "avg_logprob": -0.13825765662237044, "compression_ratio": 1.7490494296577948, "no_speech_prob": 0.0015764250420033932}, {"id": 246, "seek": 120632, "start": 1218.48, "end": 1222.0, "text": " want to minimize the impact we have on the machines we run I want to talk a little bit about", "tokens": [50972, 528, 281, 17522, 264, 2712, 321, 362, 322, 264, 8379, 321, 1190, 286, 528, 281, 751, 257, 707, 857, 466, 51148], "temperature": 0.0, "avg_logprob": -0.13825765662237044, "compression_ratio": 1.7490494296577948, "no_speech_prob": 0.0015764250420033932}, {"id": 247, "seek": 120632, "start": 1222.0, "end": 1226.6, "text": " performance in user space so many go applications well our profiler is written in go and many", "tokens": [51148, 3389, 294, 4195, 1901, 370, 867, 352, 5821, 731, 527, 1740, 5441, 307, 3720, 294, 352, 293, 867, 51378], "temperature": 0.0, "avg_logprob": -0.13825765662237044, "compression_ratio": 1.7490494296577948, "no_speech_prob": 0.0015764250420033932}, {"id": 248, "seek": 120632, "start": 1226.6, "end": 1230.2, "text": " go applications and APIs are in design with performance in mind and this is something that", "tokens": [51378, 352, 5821, 293, 21445, 366, 294, 1715, 365, 3389, 294, 1575, 293, 341, 307, 746, 300, 51558], "temperature": 0.0, "avg_logprob": -0.13825765662237044, "compression_ratio": 1.7490494296577948, "no_speech_prob": 0.0015764250420033932}, {"id": 249, "seek": 123020, "start": 1230.2, "end": 1236.96, "text": " can be seen in the dwarf and elf library that go ships with in the sandal library as well as", "tokens": [50364, 393, 312, 1612, 294, 264, 35527, 293, 35565, 6405, 300, 352, 11434, 365, 294, 264, 4932, 304, 6405, 382, 731, 382, 50702], "temperature": 0.0, "avg_logprob": -0.14311528205871582, "compression_ratio": 1.833976833976834, "no_speech_prob": 0.004954447969794273}, {"id": 250, "seek": 123020, "start": 1236.96, "end": 1240.3600000000001, "text": " binary read and binary write that we use everywhere because we're dealing with raw bytes and we", "tokens": [50702, 17434, 1401, 293, 17434, 2464, 300, 321, 764, 5315, 570, 321, 434, 6260, 365, 8936, 36088, 293, 321, 50872], "temperature": 0.0, "avg_logprob": -0.14311528205871582, "compression_ratio": 1.833976833976834, "no_speech_prob": 0.004954447969794273}, {"id": 251, "seek": 123020, "start": 1240.3600000000001, "end": 1247.6000000000001, "text": " read them and write them all the time to the BPF maps so it is interesting to know that both these", "tokens": [50872, 1401, 552, 293, 2464, 552, 439, 264, 565, 281, 264, 40533, 37, 11317, 370, 309, 307, 1880, 281, 458, 300, 1293, 613, 51234], "temperature": 0.0, "avg_logprob": -0.14311528205871582, "compression_ratio": 1.833976833976834, "no_speech_prob": 0.004954447969794273}, {"id": 252, "seek": 123020, "start": 1247.6000000000001, "end": 1253.8, "text": " binary read and binary write low-level APIs actually allocate in the fast path which can be", "tokens": [51234, 17434, 1401, 293, 17434, 2464, 2295, 12, 12418, 21445, 767, 35713, 294, 264, 2370, 3100, 597, 393, 312, 51544], "temperature": 0.0, "avg_logprob": -0.14311528205871582, "compression_ratio": 1.833976833976834, "no_speech_prob": 0.004954447969794273}, {"id": 253, "seek": 123020, "start": 1253.8, "end": 1257.16, "text": " problematic so there's a lot of things that in the future we're going to be reinventing to make", "tokens": [51544, 19011, 370, 456, 311, 257, 688, 295, 721, 300, 294, 264, 2027, 321, 434, 516, 281, 312, 33477, 278, 281, 652, 51712], "temperature": 0.0, "avg_logprob": -0.14311528205871582, "compression_ratio": 1.833976833976834, "no_speech_prob": 0.004954447969794273}, {"id": 254, "seek": 125716, "start": 1257.16, "end": 1261.4, "text": " faster and then we profile a profiler a lot in production we have found a lot of opportunities", "tokens": [50364, 4663, 293, 550, 321, 7964, 257, 1740, 5441, 257, 688, 294, 4265, 321, 362, 1352, 257, 688, 295, 4786, 50576], "temperature": 0.0, "avg_logprob": -0.17492660995601683, "compression_ratio": 1.9411764705882353, "no_speech_prob": 0.00623215502128005}, {"id": 255, "seek": 125716, "start": 1261.4, "end": 1265.96, "text": " and there's a lot more work to do because there's not much time I'm gonna quickly skip through", "tokens": [50576, 293, 456, 311, 257, 688, 544, 589, 281, 360, 570, 456, 311, 406, 709, 565, 286, 478, 799, 2661, 10023, 807, 50804], "temperature": 0.0, "avg_logprob": -0.17492660995601683, "compression_ratio": 1.9411764705882353, "no_speech_prob": 0.00623215502128005}, {"id": 256, "seek": 125716, "start": 1265.96, "end": 1270.24, "text": " testing but the great idea here is that we try to be pragmatic and we have a lot of unit tests", "tokens": [50804, 4997, 457, 264, 869, 1558, 510, 307, 300, 321, 853, 281, 312, 46904, 293, 321, 362, 257, 688, 295, 4985, 6921, 51018], "temperature": 0.0, "avg_logprob": -0.17492660995601683, "compression_ratio": 1.9411764705882353, "no_speech_prob": 0.00623215502128005}, {"id": 257, "seek": 125716, "start": 1270.24, "end": 1274.92, "text": " for the core functions and then we use snapshot testing for the unwind tables and we have a", "tokens": [51018, 337, 264, 4965, 6828, 293, 550, 321, 764, 30163, 4997, 337, 264, 517, 12199, 8020, 293, 321, 362, 257, 51252], "temperature": 0.0, "avg_logprob": -0.17492660995601683, "compression_ratio": 1.9411764705882353, "no_speech_prob": 0.00623215502128005}, {"id": 258, "seek": 125716, "start": 1274.92, "end": 1280.28, "text": " git sub repository where we have a visual representation of the unwind tables and then we", "tokens": [51252, 18331, 1422, 25841, 689, 321, 362, 257, 5056, 10290, 295, 264, 517, 12199, 8020, 293, 550, 321, 51520], "temperature": 0.0, "avg_logprob": -0.17492660995601683, "compression_ratio": 1.9411764705882353, "no_speech_prob": 0.00623215502128005}, {"id": 259, "seek": 125716, "start": 1280.28, "end": 1284.8400000000001, "text": " generate them every time on CI and locally and we verify that there are no changes compared to", "tokens": [51520, 8460, 552, 633, 565, 322, 37777, 293, 16143, 293, 321, 16888, 300, 456, 366, 572, 2962, 5347, 281, 51748], "temperature": 0.0, "avg_logprob": -0.17492660995601683, "compression_ratio": 1.9411764705882353, "no_speech_prob": 0.00623215502128005}, {"id": 260, "seek": 128484, "start": 1284.84, "end": 1291.8799999999999, "text": " last time I think there's only like two or three minutes left so let me talk about the", "tokens": [50364, 1036, 565, 286, 519, 456, 311, 787, 411, 732, 420, 1045, 2077, 1411, 370, 718, 385, 751, 466, 264, 50716], "temperature": 0.0, "avg_logprob": -0.1821303367614746, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.001968526979908347}, {"id": 261, "seek": 128484, "start": 1291.8799999999999, "end": 1295.84, "text": " different environments and some of the interesting stuff that we have found while we were profiling", "tokens": [50716, 819, 12388, 293, 512, 295, 264, 1880, 1507, 300, 321, 362, 1352, 1339, 321, 645, 1740, 4883, 50914], "temperature": 0.0, "avg_logprob": -0.1821303367614746, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.001968526979908347}, {"id": 262, "seek": 128484, "start": 1295.84, "end": 1300.24, "text": " our profiler in production we realized that we were spending a ridiculous amount of CPU cycles", "tokens": [50914, 527, 1740, 5441, 294, 4265, 321, 5334, 300, 321, 645, 6434, 257, 11083, 2372, 295, 13199, 17796, 51134], "temperature": 0.0, "avg_logprob": -0.1821303367614746, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.001968526979908347}, {"id": 263, "seek": 128484, "start": 1300.24, "end": 1305.4399999999998, "text": " reading files from this I think the total this is just like a bunch a part of the flame graph but", "tokens": [51134, 3760, 7098, 490, 341, 286, 519, 264, 3217, 341, 307, 445, 411, 257, 3840, 257, 644, 295, 264, 13287, 4295, 457, 51394], "temperature": 0.0, "avg_logprob": -0.1821303367614746, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.001968526979908347}, {"id": 264, "seek": 128484, "start": 1305.4399999999998, "end": 1310.72, "text": " I think it was like 20% of the CPU cycles so turns out this was because our cloud provider has very", "tokens": [51394, 286, 519, 309, 390, 411, 945, 4, 295, 264, 13199, 17796, 370, 4523, 484, 341, 390, 570, 527, 4588, 12398, 575, 588, 51658], "temperature": 0.0, "avg_logprob": -0.1821303367614746, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.001968526979908347}, {"id": 265, "seek": 131072, "start": 1310.76, "end": 1317.96, "text": " slow disks that are orders of magnitude slower than our fast NVMEs in the team and another thing", "tokens": [50366, 2964, 41617, 300, 366, 9470, 295, 15668, 14009, 813, 527, 2370, 46512, 15454, 82, 294, 264, 1469, 293, 1071, 551, 50726], "temperature": 0.0, "avg_logprob": -0.19570415721220127, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.01314694993197918}, {"id": 266, "seek": 131072, "start": 1317.96, "end": 1324.2, "text": " that is very interesting that is not a new fact and everybody knows about is that different", "tokens": [50726, 300, 307, 588, 1880, 300, 307, 406, 257, 777, 1186, 293, 2201, 3255, 466, 307, 300, 819, 51038], "temperature": 0.0, "avg_logprob": -0.19570415721220127, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.01314694993197918}, {"id": 267, "seek": 131072, "start": 1324.2, "end": 1329.8, "text": " configuration is the biggest source of trouble and we could see this the other day and if you're", "tokens": [51038, 11694, 307, 264, 3880, 4009, 295, 5253, 293, 321, 727, 536, 341, 264, 661, 786, 293, 498, 291, 434, 51318], "temperature": 0.0, "avg_logprob": -0.19570415721220127, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.01314694993197918}, {"id": 268, "seek": 131072, "start": 1329.8, "end": 1334.72, "text": " interested you can check the board request it's our all the whole project is open source which is", "tokens": [51318, 3102, 291, 393, 1520, 264, 3150, 5308, 309, 311, 527, 439, 264, 1379, 1716, 307, 1269, 4009, 597, 307, 51564], "temperature": 0.0, "avg_logprob": -0.19570415721220127, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.01314694993197918}, {"id": 269, "seek": 133472, "start": 1334.72, "end": 1341.24, "text": " the interaction between signals and BPF what happened basically go has an embedded profiler", "tokens": [50364, 264, 9285, 1296, 12354, 293, 40533, 37, 437, 2011, 1936, 352, 575, 364, 16741, 1740, 5441, 50690], "temperature": 0.0, "avg_logprob": -0.20731507747545155, "compression_ratio": 1.75, "no_speech_prob": 0.006723567843437195}, {"id": 270, "seek": 133472, "start": 1341.24, "end": 1347.2, "text": " and we use it only in production for reasons but it triggers SIGPROF every couple a couple times", "tokens": [50690, 293, 321, 764, 309, 787, 294, 4265, 337, 4112, 457, 309, 22827, 318, 10489, 47, 7142, 37, 633, 1916, 257, 1916, 1413, 50988], "temperature": 0.0, "avg_logprob": -0.20731507747545155, "compression_ratio": 1.75, "no_speech_prob": 0.006723567843437195}, {"id": 271, "seek": 133472, "start": 1347.2, "end": 1352.04, "text": " a second that it was interrupting the process execution and at that time our process of booting", "tokens": [50988, 257, 1150, 300, 309, 390, 49455, 264, 1399, 15058, 293, 412, 300, 565, 527, 1399, 295, 11450, 278, 51230], "temperature": 0.0, "avg_logprob": -0.20731507747545155, "compression_ratio": 1.75, "no_speech_prob": 0.006723567843437195}, {"id": 272, "seek": 133472, "start": 1352.04, "end": 1357.2, "text": " app and it was loading our BPF program because it's quite long and complex the verifier takes a", "tokens": [51230, 724, 293, 309, 390, 15114, 527, 40533, 37, 1461, 570, 309, 311, 1596, 938, 293, 3997, 264, 1306, 9902, 2516, 257, 51488], "temperature": 0.0, "avg_logprob": -0.20731507747545155, "compression_ratio": 1.75, "no_speech_prob": 0.006723567843437195}, {"id": 273, "seek": 133472, "start": 1357.2, "end": 1362.56, "text": " couple milliseconds to load it but it was getting interrupted all the time the BPF whenever it detects", "tokens": [51488, 1916, 34184, 281, 3677, 309, 457, 309, 390, 1242, 30329, 439, 264, 565, 264, 40533, 37, 5699, 309, 5531, 82, 51756], "temperature": 0.0, "avg_logprob": -0.20731507747545155, "compression_ratio": 1.75, "no_speech_prob": 0.006723567843437195}, {"id": 274, "seek": 136256, "start": 1362.56, "end": 1367.32, "text": " that the verifier has been interrupted it retries the process basically wasting all the previous", "tokens": [50364, 300, 264, 1306, 9902, 575, 668, 30329, 309, 1533, 2244, 264, 1399, 1936, 20457, 439, 264, 3894, 50602], "temperature": 0.0, "avg_logprob": -0.18147940202192828, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.0013617264339700341}, {"id": 275, "seek": 136256, "start": 1367.32, "end": 1372.08, "text": " CPU cycles because it starts from scratch but then it retries up to five times and then it says I", "tokens": [50602, 13199, 17796, 570, 309, 3719, 490, 8459, 457, 550, 309, 1533, 2244, 493, 281, 1732, 1413, 293, 550, 309, 1619, 286, 50840], "temperature": 0.0, "avg_logprob": -0.18147940202192828, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.0013617264339700341}, {"id": 276, "seek": 136256, "start": 1372.08, "end": 1376.76, "text": " couldn't do it and of course when we can allow the BPF program we are completely useless so we", "tokens": [50840, 2809, 380, 360, 309, 293, 295, 1164, 562, 321, 393, 2089, 264, 40533, 37, 1461, 321, 366, 2584, 14115, 370, 321, 51074], "temperature": 0.0, "avg_logprob": -0.18147940202192828, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.0013617264339700341}, {"id": 277, "seek": 136256, "start": 1376.76, "end": 1382.28, "text": " just crash and there is many other considerations such as what do you do with short live processes", "tokens": [51074, 445, 8252, 293, 456, 307, 867, 661, 24070, 1270, 382, 437, 360, 291, 360, 365, 2099, 1621, 7555, 51350], "temperature": 0.0, "avg_logprob": -0.18147940202192828, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.0013617264339700341}, {"id": 278, "seek": 136256, "start": 1382.28, "end": 1386.6799999999998, "text": " because you have to generate a data but even though we have an optimize for this and is we are not", "tokens": [51350, 570, 291, 362, 281, 8460, 257, 1412, 457, 754, 1673, 321, 362, 364, 19719, 337, 341, 293, 307, 321, 366, 406, 51570], "temperature": 0.0, "avg_logprob": -0.18147940202192828, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.0013617264339700341}, {"id": 279, "seek": 138668, "start": 1386.8400000000001, "end": 1392.76, "text": " that bad and we can profile processes that run even for one second on your box and then the", "tokens": [50372, 300, 1578, 293, 321, 393, 7964, 7555, 300, 1190, 754, 337, 472, 1150, 322, 428, 2424, 293, 550, 264, 50668], "temperature": 0.0, "avg_logprob": -0.15460138118013422, "compression_ratio": 1.7244444444444444, "no_speech_prob": 0.008666650392115116}, {"id": 280, "seek": 138668, "start": 1392.76, "end": 1396.52, "text": " important thing here is that this is our format for our custom on wine table but it doesn't matter", "tokens": [50668, 1021, 551, 510, 307, 300, 341, 307, 527, 7877, 337, 527, 2375, 322, 7209, 3199, 457, 309, 1177, 380, 1871, 50856], "temperature": 0.0, "avg_logprob": -0.15460138118013422, "compression_ratio": 1.7244444444444444, "no_speech_prob": 0.008666650392115116}, {"id": 281, "seek": 138668, "start": 1396.52, "end": 1402.76, "text": " the important bit here is that it mostly fits in L2 cache so we basically incur on two L2 misses", "tokens": [50856, 264, 1021, 857, 510, 307, 300, 309, 5240, 9001, 294, 441, 17, 19459, 370, 321, 1936, 35774, 322, 732, 441, 17, 29394, 51168], "temperature": 0.0, "avg_logprob": -0.15460138118013422, "compression_ratio": 1.7244444444444444, "no_speech_prob": 0.008666650392115116}, {"id": 282, "seek": 138668, "start": 1402.76, "end": 1410.52, "text": " and it is pretty fast on a machine with a bunch of processes with up to 90 frames we can do the full", "tokens": [51168, 293, 309, 307, 1238, 2370, 322, 257, 3479, 365, 257, 3840, 295, 7555, 365, 493, 281, 4289, 12083, 321, 393, 360, 264, 1577, 51556], "temperature": 0.0, "avg_logprob": -0.15460138118013422, "compression_ratio": 1.7244444444444444, "no_speech_prob": 0.008666650392115116}, {"id": 283, "seek": 141052, "start": 1410.52, "end": 1419.8, "text": " on wine processing 0.5 milliseconds on a CPU that is five years old cool and so we are going to", "tokens": [50364, 322, 7209, 9007, 1958, 13, 20, 34184, 322, 257, 13199, 300, 307, 1732, 924, 1331, 1627, 293, 370, 321, 366, 516, 281, 50828], "temperature": 0.0, "avg_logprob": -0.15828318388565726, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.007013698108494282}, {"id": 284, "seek": 141052, "start": 1419.8, "end": 1424.6, "text": " do mixing on wine mode so being able to unwind JIT sections we're applying RM64 support by the end", "tokens": [50828, 360, 11983, 322, 7209, 4391, 370, 885, 1075, 281, 517, 12199, 508, 3927, 10863, 321, 434, 9275, 23790, 19395, 1406, 538, 264, 917, 51068], "temperature": 0.0, "avg_logprob": -0.15828318388565726, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.007013698108494282}, {"id": 285, "seek": 141052, "start": 1424.6, "end": 1428.92, "text": " of the year and this feature is going to be enabled by default in a few weeks because right now it's", "tokens": [51068, 295, 264, 1064, 293, 341, 4111, 307, 516, 281, 312, 15172, 538, 7576, 294, 257, 1326, 3259, 570, 558, 586, 309, 311, 51284], "temperature": 0.0, "avg_logprob": -0.15828318388565726, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.007013698108494282}, {"id": 286, "seek": 141052, "start": 1428.92, "end": 1432.96, "text": " under a feature flag we have many other things that we want to support including high level", "tokens": [51284, 833, 257, 4111, 7166, 321, 362, 867, 661, 721, 300, 321, 528, 281, 1406, 3009, 1090, 1496, 51486], "temperature": 0.0, "avg_logprob": -0.15828318388565726, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.007013698108494282}, {"id": 287, "seek": 141052, "start": 1432.96, "end": 1438.16, "text": " languages and we are open source so if you want to contribute or you have anything you want to", "tokens": [51486, 8650, 293, 321, 366, 1269, 4009, 370, 498, 291, 528, 281, 10586, 420, 291, 362, 1340, 291, 528, 281, 51746], "temperature": 0.0, "avg_logprob": -0.15828318388565726, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.007013698108494282}, {"id": 288, "seek": 143816, "start": 1438.16, "end": 1443.3600000000001, "text": " discuss we meet by weekly on Mondays as part of the Parker project so there's a bunch of links", "tokens": [50364, 2248, 321, 1677, 538, 12460, 322, 7492, 3772, 382, 644, 295, 264, 20155, 1716, 370, 456, 311, 257, 3840, 295, 6123, 50624], "temperature": 0.0, "avg_logprob": -0.29941636424953655, "compression_ratio": 1.3662790697674418, "no_speech_prob": 0.014660936780273914}, {"id": 289, "seek": 143816, "start": 1443.3600000000001, "end": 1448.48, "text": " that we're going to upload to the presentation in the FOSM websites and yeah thank you.", "tokens": [50624, 300, 321, 434, 516, 281, 6580, 281, 264, 5860, 294, 264, 479, 4367, 44, 12891, 293, 1338, 1309, 291, 13, 50880], "temperature": 0.0, "avg_logprob": -0.29941636424953655, "compression_ratio": 1.3662790697674418, "no_speech_prob": 0.014660936780273914}, {"id": 290, "seek": 143816, "start": 1455.48, "end": 1459.5600000000002, "text": " I think we have time for maximum one short question.", "tokens": [51230, 286, 519, 321, 362, 565, 337, 6674, 472, 2099, 1168, 13, 51434], "temperature": 0.0, "avg_logprob": -0.29941636424953655, "compression_ratio": 1.3662790697674418, "no_speech_prob": 0.014660936780273914}], "language": "en"}