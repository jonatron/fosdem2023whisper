{"text": " So, for this talk, we're going to be learning how to build a plant monitoring app with Influx DB, Python, and Flask with Edge to Cloud Replication being an option onto this project. So first things first, my name is Zoe Steinkamp, I'm a Developer Advocate for Influx Data, which means I have a large empathy for developers myself. I was actually a front-end software engineer for over eight years before I decided that I wanted to actually be able to listen to people's issues and fix them instead of just hear them come down from the product team. So if you guys have any questions, I will be allowing some time for Q&A during this presentation at the end, but if you want to reach out at any point or you just like to be friends with people on LinkedIn, this is my QR code. My name is relatively unique, I'm easy to find. The overview. So in this presentation, we're going to be walking through a few different pieces for this project. The first thing we're going to be walking through is the IoT hardware setup. So if you guys are not super familiar with like IoT devices and stuff, not to worry, I'll break it down and then we can kind of figure it out. Also all of this is available on GitHub, all this code examples, there's lots of instructions, this is a very well fleshed out project. So at the end, I'm going to be linking that as well so you can do it yourself at home very easily. We're going to go over the tools that we're going to be using for this project. We're going to go over a short interview, a short overview of InfluxDB just so that with people who don't understand how it works, we'll understand how it works in this project. The data ingestion setup, Flux and SQL, setting up edge data replication and data request which are kind of comboed together somewhat. And then finally at the end, the GitHub code base, links to other community links and such and then Q&A as well. So setting up your IoT devices. So this is a handy little diagram to show roughly how this is going to work in real life. But basically you have a plant and you're going to be monitoring it, you're going to need some kind of microcontroller to receive this information. I'll show a haphazard photo in a second of how that's going to look. But basically from that plant, we're going to get data roughly about, I like to say, how the plant is feeling. If it's thirsty or hot or just doesn't like you in particular, it'll let us know. From there, we put that data into our open source, our OSS instance. So InfluxDB is available open source so you can just easily download it off GitHub and get it running locally. So in that, we're going to go ahead and store our data. We're going to use a telegraph, that's what that little tiger is, we're going to use a telegraph agent to get the data inside. From there, if we want, we can go ahead and use our edge data replication feature to go ahead and push it to cloud. And then the idea here is that you can also host this locally, like you can host a little website with graphs and such. I'll be showing this as we go and the code is available. But basically the idea here is that you store your data locally, you use edge data replication to push it up into the cloud for longer term storage or just to have less data loss. And then from there, you can pull that data back out to actually start graphing and visualizing it. As promised, haphazard photo. So for this project, you need in no particular order, a plant, preferably alive, those are the best to monitor, a particle boron microcontroller or another compatible one. We have the schematics and the details for an Arduino, if that would be your preference. At least one IoT sensor for your plant and a breadboard with jump wires and terminal strips. As promised, this is what the schematics look like. So basically you can just kind of follow these schematics to the T and that helps you just get everything set up. We especially had certain issues with some of our sensors, what's the word, interfering with other ones. From that, I have four sensors for my project, those are the four that I just happened to buy off Amazon, which we do list, so you can, depending on your country, it will change, but these sensors are like 25 cents a pop, so they're really cheap and easy to get. I have temperature and humidity, I have light, I have soil and moisture, and I have temperature. So with all four of these, I can go ahead and hook them up to my breadboard and my microcontroller and I can start getting some of that data. So the tools we're going to be using today. So we are going to be using Flask, which for those of you guys who are not aware is a micro web framework written in Python. It's going to be doing some of the heavy lifting for the project, specifically it's going to be running the local application and allowing us to have some built in routing. We're going to be using InfluxDB for actually storing the data that we get from our IoT sensors from our plant. It comes with an API and tool set that's going to be easy for ingesting and querying that data back out. It's highly performance, so we don't have to worry about it running up when it's open sourced. It doesn't cost us anything outside of the server we're running on locally, but in general we want our data to be stored efficiently. And then it also has obviously our community and ecosystem. People like me there to help answer questions and come up with these awesome little projects like monitoring your planted home. Telegraph is a completely open source ingestion agent. It has over 300 plus different plugins depending on what you need and desire. For this project we use the exact D processor plugin to get the data into our open source. I'm also going to be showing code for what I'll actually I'm going to explain that later. But basically this is super nice to use. It has a very wide range of open source plugins supported by sometimes companies, sometimes community members. You'll find serious ones like Azure monitoring or AWS monitoring to the more fun ones like Minecraft or CSGO. For some reason you do not want to use Telegraph, maybe it just doesn't have a configuration that works for your device or your project. A lot of people are just going to go to the client libraries which I'll be showing a code example on how to use these as well. And this does live inside the project, so you don't have to worry about like going and finding it. We just left it there just in case people want to use it. So obviously it's got a few different options here. We're going to be using the Python one because that's the one I've worked in and that's what the project is written in. Another thing that I use when I built up this project is the flux extension for VS Code. It's really nice in that it allows me to write my flux queries and it kind of tells me if I'm misspelling or writing things wrong. It's just like any other extension that you're going to get in VS Code. It highlights things and helps you realize when you're making mistakes. Finally, we're going to be using plotly for graphing. It is a completely free and open source graphing library which is always our favorite. And it's really nice and easy to work with and very colorful which I appreciate. So a really quick overview. So for those of you guys who are not quite familiar with it, time series data is a very specific type of data. So it's what we're going to be getting from our plant because IoT sensors tend to give you time series data and the fact that it is metrics regularly intervaled at time. So what that means is that you want to know at what point the plant got thirsty or you want to know how many hours a day did it get sunlight. That's all time series data. That's data that you want to know about on a time scale. We normally see these as metrics at regular time intervals. Occasionally we see things like events. You can think of things also like the stock exchange or weather conditions as other great examples of this type of data. We tend to find these in multiple different applications. The software infrastructure is probably the most common and most people here would understand where that comes from. Obviously for this one we're going to be using IoT data. So one thing to note is if you had multiple plants at home, you might want to store that data like you might want to know that you have six orchids and seven aloe veras. You store that kind of data in a relational. You'd name them. You'd say this is the one that lives in the window on the north side of the house. This is the one that lives in the window on the south. And by the way, one of my coworkers totally did this. He has like a hundred plants in his house. So he organized it in his SQL DB, his relational, because this was a lot of plant data. But then when he was actually monitoring all of these plants, which I really don't know how he set this, his house is just full of cords. It's just cords everywhere. When he set this up to actually start monitoring all of these, that would be time series data. So that's going to be all of those timestamp metrics coming in. So this is kind of how the entire platform looks when it's all put together. So as you can see, you have your data sources, then you have telegraph in the client libraries as well as things like native ecosystems, which we're not going to go into today. And those are the ways of getting the data in. And from there, you can use Inflex DB to set up things like triggers and alerts, things like you can get, I have it set up to send me a text, be it Twilio, if my plant needs some water. I use it quite often at my job and then promptly ignore the text. It doesn't work out very well for the plant or me. But if I actually paid attention, this is very useful to use. And finally, obviously with these kind of data, what's the data stored once we have it being used, maybe down-sampling it, we can actually start seeing some results. Obviously, infrastructure insights isn't quite what this is, but more like plant insights. So when it comes to data ingestion setup. So I'm not going to go super in depth on how to set up your microcontroller, because depending on the one you're using, it's going to be different. They're all going to be very varied. You're just going to have to follow the instructions on that one. If you happen to have an Arduino or a Boron microcontroller, you could probably follow, I mean, you can follow our directions anyways, but those are probably going to be pretty easy to set up because we talk about it. But this is just an example of how the data tends to come in. So as you can see, I've got my port set up and then I start to get these data results. So for example, if I remember correctly, this one is the humidity one, this one is the temperature. As you can see, this is like the first, I'm going to call it the first flush. So sometimes the data comes in as zeros at first and then it starts to actually give you values. One thing to note, and I'm not going to go over it in this presentation, but you can see it in the GitHub, like in the repository in the code. We do tend to do a little bit of cleanup on these values. The data sensors are not exactly friendly in how they send you data, so I'm going to put it. So we did have to do a little bit of our own cleanup in Python, which luckily we supply to you. So if you're using roughly the same ones, you can go ahead and just use what we have. But like, for example, our temperature kind of came in a little bit weird and we had to change it so it actually read in a more human readable way, and we haven't yet fixed the light one. So it just looks really strange. Interesting. I expected my video to show up. Well, oh wait, it is up there. Aha. Well, let's see, can I get this to work? Not quite. Sorry, guys. Little difficulties. Well, go figure. This was working on my own machine, you know, five minutes ago, but that means nothing. I'm going to try and press, is there like a play button or something on here? All right, I'm just going to give up. So basically what this shows is how to set up your bucket in token, which I can actually probably just pull up. I'll do it at the end of this presentation. We're going to do this on the fly. I'll show it at the end, but basically it just shows you in the UI how you set up your bucket, which is just your database. You can pick for how long it wants to have a retention policy. That's how long you want to store the data. Maybe you only want to store it for a day. Maybe you want to store it for 30 days. You pick that at the beginning. And then it also gives you the option to do a explicit or implicit schema. And what that means is implicit just basically builds the schema off what you send us. So if you start streaming in data, we'll build it for you. Explicit is you tell us exactly how you want your data to be formatted, and we will reject any data that doesn't meet that schema. Obviously in a project like this, which I like to call pretty low risk, like it's not a big deal if the data is not quite perfect, just do the implicit, make life easy for yourself. But we give explicit as for more professional projects, I suppose you could say, where it really does matter that you reject that bad schema data. The other thing I showed is just how to make a quick token, because obviously you're going to need a token to actually get your data in and back out, you need those authentications. One thing to note, we do offer a all access token. We kind of warn against it, it even has a big warning on the screen saying, please don't do this, because it allows you full access to all of your buckets, all your databases, and it allows you to delete them. So if that tech, whenever falls into the wrong hands, or maybe you make a mistake, or your coworker makes a mistake, you know, somebody else, that can obviously cause a lot of problems. We like to call it basically creating your own big red button, you don't need to do that. So we also give you the option to pick, write and read tokens where you specify which buckets you want them to have access to. Again, I'll just show this a little bit later. And you can do it in the CLI as well, but normally when the video loads, the UI is a little bit more fun to visually see. So let's see, there we go. So for this code example, it's pretty straightforward as to how to actually set this up. As you can see, we have the influxdbclient.point. The influxdbclient is already set up in this example. Basically all you give it is your bucket and your token. You just basically say, this is where I want my data to go, and I have the authority authorization to actually do it. It's very straightforward and easy to set up. It takes like a second. But basically once you have all your authentication going, you can actually start sending those points up to your database. So with this one, we're calling the point sensor data. We're setting the user. It says it's not visually here, but it says Zoey, just as my name. It's not very special. Then we have the tag, which is the device ID. And then finally the sensor name with the value. So that's going to be something like humidity value 30. And basically from this, this is running in a Python file script that just is pretty much running as long as we're getting data. But basically this is a straightforward way to get it in. And this is using the Python client library. This is part of the Telegraph config file. This file has like, it's computer generated, so you don't need to write 200 lines of code, but the actual config file is like 200 lines of code. This is just a small snippet at the end of it that basically says that we're using the execd processor plugin. And from here, we're just telling it what measurements and what tagged keys to accept. Again, inside of the GitHub project, we kind of go a little bit more in depth. But the big thing is that every Telegraph config file and instructions are slightly different. So there's no necessary reason for me to show you the execd one when you could be using a different one for your own project. But basically, just follow the documentations for this. It's super simple and it's very well documented. Well, I guess I shouldn't say that since it's open source. So some of them are less well documented, but most of them are great. And this is a table example of the resulting data points. So as you can see, we have our sensor data with a field of, but this one we have a light and soil moisture. We have our value. And as I told you before, the values kind of come in a little bit weird. I don't know how soil moisture can be 1,372 point, many zeros and fives, but it can be. And then finally, the actual timestamp value, which says that obviously this value was from last year in like, I can't even think September, August, sometime in the early fall. So flux and sequel. So I've said this word before and I haven't really explained it. But basically what flux is, is it is the querying language of influx DB. So basically what it allows you to do is query for your time series data. It can do a lot of really awesome things. It can do things like the alerts, the management, but for right now we're just going to focus on the querying because that's the most straightforward thing and that's the main thing that you're going to end up doing. So in this versioning right here, basically what it's saying is from bucket, which again is just from database. Go ahead and give me smart city. Give me the range. This is a range of one day. It's got to start and a stop. You do not have to give it a range. You could literally just do from bucket, give me everything. You normally suggest you try to use a range because obviously, I mean if your bucket only has like one day of data, it's probably not a big deal, but if it has the past three years of data, that's going to be a while to come in and that's going to probably crash a lot. And then you have your filters. So with this one, what they're saying in more human terms is they're saying give me all the bicycles that have come through with the neighborhood ID of three. And what they're doing down here at this aggregate window is they're saying give me the mean for every one hour. So because this is one day, this is a one day range, this will return 24 data points. It will give you the mean amount of bikes that came through every hour in this neighborhood with the ID of three. And the one below it is doing the exact same, but it's doing it for the ID neighborhood of four. And then finally at the end, it's comparing them and it's getting a difference value. It's saying how many more bikes go through neighborhood three versus neighborhood four or vice versa. And so that's just one of the quick queries that you can do. The aggregate window is super great, especially for a project like this where you may be, although your IoT sensors will send you data every single nanosecond, let's get real here. Your plant, you don't need to know exactly what was happening to it. It's better to just get an average of how thirsty it is or average amount of light. You could bring it down even to five minutes. Like it does not need to be quite as in depth. And even for this one, they just wanted to know the mean amount of bikes that were coming through the city in these neighborhoods. This is how it actually looks like in our project. So the reason that you're seeing all these empty brackets is this is a reusable query. So we can say from different types of plant buddy buckets, or we can say different device IDs or different fields. So again, the field is going to be things like the humidity, the temperature, the moisture. And device ID, I actually, for my project at least, it's always the same because I only have one setup. But if I had multiple plants with multiple values, I would have the device ID basically being probably really the plant names, but I could say like Arduino one or Arduino two. But for this project, it's relatively smaller, so it's just easier. So change is here. So this doesn't really matter if you decide to do this project all in the open source. It won't matter really for you for a while. But one thing to note is if you do choose to do edge data replication, Influx CB cloud is now going to be allowing SQL. So you're going to be able to query your data back out using SQL instead of Flux. And we're also going to be supporting flight SQL plug-ins, which will allow you to connect to things like Apache superset and Grafana. I'm obviously going to be showing plot leaf for this one, but these are going to be options for you in the future. So it's just something to keep in mind. So let's get into edge data replication. I'm going to leave this up for just one sec. So normally when I say edge data replication, people kind of think of varying things depending on your job or depending on where you've heard it said before. Some people think of a solar panel in the middle of nowhere in the woods. That's the edge device because it's, I don't know, at the edge of civilization basically. But an edge device can be something as simple as a cell phone. It can be an ATM sitting at a bank. It can be a factory that just happens to have intermittent Wi-Fi because today or this week got an ice storm and the internet went out. So an edge device can really be almost, it's more broad than what we normally think of. It can be almost any device that it's important that it always stays connected, but that doesn't mean that it will. Or in the case of some people, it's your work server that happens to be sitting in your office that goes out because the power went out of the office and now somebody's getting the phone call at 2 a.m. to go to that office and fix the server. That's why cloud computing is great. So basically what edge data replication allows is it allows you to run your InfluxDB OSS instance, your edge, and basically it has a dispatch queue which holds that data. So as you can see here, you have your bucket, you have your queue. There are limits to how much data you can hold. You can check out the documentation to find out all the nitty-gritty. But basically from there, if you ever have like, you know, you ever have internet blackouts, you ever have power loss, you will have that data backed up. And then when it reconnects, it goes ahead and sends it to the cloud. Now obviously I would hope that nobody has plants that are so important that they necessarily need to back up their data. But I also like doing this because I monitor these plants at conferences, like they come with me when I'm doing basically what the people outside of this room are doing. Sometimes I have a plant at our booth where I monitor it and although this conference has been really great for Wi-Fi, not all of them are so wonderful. And so it's actually not uncommon for me and my plant to lose Wi-Fi and then I can use the edge data replication to still push that data up to the cloud once I reconnect. Or I close my laptop when I go to lunch and then it stops running, also not super great. But basically this is pretty easy to set up and get going on. So these are part of the setup instructions that are in this project's read me. So as you can see, we're running our InfluxDB OSS edge on Docker, so it's a Docker hosted OSS. And basically what the command in the second portion does is it just sets it up to be a edge device. It's just saying like, hey, do the config create, plant buddy edge, this is going to be where it's coming from, it's the open source version. And then the rest of these instructions are basically just for the USB ports and such. Like I said before, we have some pretty in-depth documentation on how to get this project going. And then these are the two big commands that you run. And they're pretty straightforward. Basically all you need to do is just have all of your information for your OSS, so that's going to be that bucket that we named before. You're going to need to create that remote connection. And then finally you need to do the replication command where you're saying replicate between the local bucket ID and the remote bucket ID. So as I said before, I'll show how you actually create the buckets, but for the cloud as well as the open source is the exact same, you just basically create the bucket, you need to get the ID for it, and then you're basically just saying, this is my local bucket, this is my cloud bucket, please make sure the data goes up in that direction. So data requests and visualizations. So when we are querying data back out, this is using again the Python client library, which although Telegraph does have a few output plugins, they're not relevant for this specific project. You could check them out if you wanted to send your data to a different way, a different website or such. But basically all we're doing here is we are using one of those flux queries, the same one that I showed from an earlier slide where it's basically just saying, give me the data for the past roughly day for this bucket with this value. And from there, you have your params, you have your bucket, your sensor name and your device ID, which can be submitted, like I said before, it's like a drop down that you can pick from, and basically once you do the query and you do the open.read, you're going to receive that data back. And you can receive this data back in different ways, but we're doing it in a data frame because that's the easiest for graphing implotly. This is currently in, what's the word, we're working on it. So we're currently working on getting this project to be integrated with SQL. That's going to be my task when I get home tomorrow on Monday or Tuesday whenever my flight lands. But basically from here, this is how it's going to be instead executed. You're basically just going to be using a SQL command and getting a very similar readback. With this one, we're just getting a, what's the word, like a straight read, we're not doing it into a data frame, but that is going to be something that we're going to set up and be an option. So if you do want to use this in the future, just wait like by the end of the week and we'll have that project up as a part of the plant buddy repo. And finally actually graphing the data. So it's pretty easy to actually graph the data inside of plotly. So as you can see, we have a few different line graphs, which are set for soil moisture, air temperature. And as you can see, we're setting a few, like these are the values that we're setting here, like the graph default device ID, we're sending in that air temperature, and we're getting it back in a graph format. And this is going to be another case where we're going to see if we can get this to work because I really want this one to work, darn it. I actually wonder, we're going to try something a little bit weird, see if we can get this out of the presenter view. Oh no, escape. There we go. Okay, this is not really ideal, but we're just going to have to go with it, I think, maybe. Man, it's really just not liking it, huh? I don't know why, what is this? Oh well, that's not helpful at all, darn. One second, I'm going to drag this onto my screen and just see if I can do it. I guess it just doesn't like the HDMI today. Check the other Wi-Fi, the dual stack one. I'm on the FOSDOM one. Yeah, there's a FOSDOM dual stack, which is IPv4. Try that one. This one? Yes. You think it's internet? Not every Google thing likes IPv6. I'll also refresh this really quick, see if that helps at all. Yeah, just really, it's so funny that, yeah, it was working before, but now it's just not liking me. All right. Oh, you've got to be kidding me. All right. I've got it working. I think I just actually need to change my share settings. All right. We're going to go ahead and change the way this is shared. Do you know how to change the settings by any chance? I thought it would just change it, but it didn't, like, just change it to just look at this. Just look at this screen. Oh, I don't think. No. Okay. Hmm. Fair enough. Yeah, it's just, like, it's not, all right. Here we go. Mirror display. It's all these new updates. I never know where anything is anymore. Okay, so it really is just the display thing, I think. I think it just doesn't want to work. There we go. Okay, cool. So, I'm so sorry, guys. I didn't realize it didn't like my share. Okay, so I'm going to go ahead and full screen this, and we'll just go back to the other video because why not? So this is how it actually looks in the end. So as you can see, it starts to actually make a little bit more sense. But basically, you can pick your fields. So this is, like, a graph where you can kind of change it as you desire. And you could also pick your bucket as well, which I might show in a second here on this video. There we go, yeah. So you could pick one of these many buckets. Most of these are not relevant to my project. They're just the buckets I have in my cloud account, or rather, my open source. And so as you can see, these are the two, I'm going to go back to this part of the video. These are the two hard-coded graphs. So as I said before, the original values sometimes come in really weird. Like, I don't know why the heck humidity went, like, all the way up to 90 and then dropped all the way back down. We normally do a first flush of a lot of this data when it first hits because it just kind of comes in funny. Or maybe I breathed on it. Who knows? They're relatively sensitive. It really does happen. But also, we had to do a little bit of exponential smoothing as well. So like, we smoothed out the soil moisture because it used to look like the air temperature does. It used to just, like, kind of jump around like a crazy thing. The plant did not move between, like, the frigid air to back inside. It's just these sensors can be a little bit temperamental. We bought the cheapest ones off Amazon. We can only expect so much. If you spend a little more money, you're going to get a nicer setup. So let me get at a full screen, please. And I can just not win today. All right. Nope. Now, you just want to play. Okay. So these are some of the new visualization options for Flight Sequel. We're also going to be adding these into the project, so you can check it out. We already have pretty good integration with Grafana as well. So if you would prefer to use them for your visualizations instead of Plotly, you're more than welcome to. And then these are those further resources I mentioned before. So this is the try it yourself. So this is where the actual project lives. This is the QR code as well as the GitHub. If you look up Plant Buddy on the Internet, you'll find this. And then we have a few different versions depending on what you want to do, including the edge data replication version, which I've mentioned here. Oh, I almost forgot about the other video. Let me go back up to it really quick. I like the videos because it means I don't normally have to jump around super crazily and go in and out of the Cloud UI. Too bad it sometimes comes in as like, it's funny, it's set for the high quality, but it never really is. I'd go back to Slideshow if you would be so kind. There we go. So as I was saying before, the create bucket is pretty straightforward. You just name it. And then as you can see, the delete data is set for never or older than a certain amount of days or time. And then that advanced configuration is the schema that you can pick. And then finally, the API tokens, also pretty straightforward. You can do the read-write, which is what I do suggest. This all-accent is the big red button that I mentioned earlier. As you can see, it's got the warning to don't do this. I do it because I don't care. I like to live life on the edge, haha. Horrible jokes. It's a great specialty of mine. But if you decide to do this the right way, this is how you would normally do it. You can pick your buckets for read and write. And you do need to have read and write if you want to use it in this context. Because if you just have read, it won't do you any good. If you don't have, I mean, I guess you could do one, but then your data is stuck inside and you can't do anything with it. So you need both. So that's that video. So I'm going to go back to the end of this. It's great. This thing never escapes. There we go. Awesome. So this is our community Slack. I'm also going to have a slide next that will have all of the, like it's the one to take a photo of. You don't need to take any photos of this one. But basically you can come join us in our Slack community. I'm there. My coworkers are there. We love to hang out and talk to people and take feedback as well as questions. It's pretty active. We get like 100 messages a day. So we're always busy in there. And then for getting started yourself, you can obviously head to the Influx community. It has a lot of projects as well as the Influx code base. So you can go ahead and download that open source versioning. And if you want to get started, that's our website, this is also where you're going to find things like our documentation. And this is that slide that I promised that kind of has like everything. It makes it really easy. So for getting started on cloud, if you would like, the community is both the forums and Slack. Slack is our more active community. Our forums are because we can only pay for such an upgraded amount of Slack history storage. So we put all of our old questions in the forum, so they are a resource that you can kind of search through. And if you don't search through it, that's where I search when I answer questions. And then we also do have the Influx community as well. It's basically the one on GitHub where you can find projects that people have worked on, including ourselves. Our book, which basically just goes into things like why you want to use it, the documentation, which I've mentioned multiple times because it really goes in depth on how to get this project set up and going. That's where you see things. They have some of our new stuff as well as just, in general, we like to highlight some of the projects that people are working on. And finally, just our university where you can learn more. It's completely free and go at your own pace. So now that we've gotten through everything, if anybody has any questions... Yes? Yeah, so I'll go ahead... Oh, that's not what I wanted. No. It's just taking me back to that stupid drive video. There we go. So yeah, so this is that Influx community plant buddy project. So the master branch. And then we also have, so for example, down here we talk about the control boards. So we've got the Arduino or the Boron. And then we have an entire sensor list. So for example, if I click on this one, it harasses me for cookies. It goes into the temperature sensor. So you can go ahead and learn about all the different sensors that we use for this project. You can also obviously search them up on the internet and buy them if you desire. And you can use many different types of sensors, but these just happen to be the four that we just wanted to end up using. And like I said before, in this project, we have, yes, the master branch, and then we also have things like EDR, which is edge data replication, Kafka, and then a few others. I normally end up in the master branch. It's kind of like the main versioning of the project. And yeah, and then in the future, the SQL one that I was telling you about, that's going to be EDR IOX. It's still currently being worked on as I speak, actually. So that one is not to be touched yet, until it's all done. Yes? Yeah. So the question was, how is InfluxDB different than OpenTSB? Sorry, TSTB, there we go. So from what I understand, TSTB is also an open source time series database, just like we are. I think the biggest difference is going to be how much functionality it comes out of the box with. I would obviously have to go to their actual code and check it out a little bit further. But normally the big thing that's our differentiator is the fact that we can, we actually have our own visualizations. We have our own ability with Flux to do things like alerting, like that moisture alerting that I was talking about before. And then with the new SQL integration, that will also be very nice for people who want to query in a language. Most people are already familiar with querying in when it comes to working with databases. But to be honest, a lot of time series DBs can be pretty comparable when it actually comes to the storage. So it's going to depend somewhat on your project and which one you want to, I suppose, work with. A lot of people normally like to, I normally do get told that we have pretty good documentation and a good community where we're very easy to work with and work through problems. And that's not always the case with every open source community. If anybody else has any other questions. If not, that's totally fine too, because that all gives you guys time to run off to the next talks or maybe go grab some lunch from the food trucks. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.3, "text": " So, for this talk, we're going to be learning how to build a plant monitoring app with Influx", "tokens": [407, 11, 337, 341, 751, 11, 321, 434, 516, 281, 312, 2539, 577, 281, 1322, 257, 3709, 11028, 724, 365, 682, 3423, 2449], "temperature": 0.0, "avg_logprob": -0.24855442047119142, "compression_ratio": 1.493212669683258, "no_speech_prob": 0.08361194282770157}, {"id": 1, "seek": 0, "start": 11.3, "end": 19.22, "text": " DB, Python, and Flask with Edge to Cloud Replication being an option onto this project.", "tokens": [26754, 11, 15329, 11, 293, 3235, 3863, 365, 19328, 281, 8061, 1300, 4770, 399, 885, 364, 3614, 3911, 341, 1716, 13], "temperature": 0.0, "avg_logprob": -0.24855442047119142, "compression_ratio": 1.493212669683258, "no_speech_prob": 0.08361194282770157}, {"id": 2, "seek": 0, "start": 19.22, "end": 24.04, "text": " So first things first, my name is Zoe Steinkamp, I'm a Developer Advocate for Influx Data,", "tokens": [407, 700, 721, 700, 11, 452, 1315, 307, 38234, 3592, 475, 1215, 11, 286, 478, 257, 44915, 13634, 42869, 337, 682, 3423, 2449, 11888, 11], "temperature": 0.0, "avg_logprob": -0.24855442047119142, "compression_ratio": 1.493212669683258, "no_speech_prob": 0.08361194282770157}, {"id": 3, "seek": 0, "start": 24.04, "end": 28.240000000000002, "text": " which means I have a large empathy for developers myself.", "tokens": [597, 1355, 286, 362, 257, 2416, 18701, 337, 8849, 2059, 13], "temperature": 0.0, "avg_logprob": -0.24855442047119142, "compression_ratio": 1.493212669683258, "no_speech_prob": 0.08361194282770157}, {"id": 4, "seek": 2824, "start": 28.24, "end": 31.919999999999998, "text": " I was actually a front-end software engineer for over eight years before I decided that", "tokens": [286, 390, 767, 257, 1868, 12, 521, 4722, 11403, 337, 670, 3180, 924, 949, 286, 3047, 300], "temperature": 0.0, "avg_logprob": -0.11295758819580078, "compression_ratio": 1.5974025974025974, "no_speech_prob": 4.8921137931756675e-05}, {"id": 5, "seek": 2824, "start": 31.919999999999998, "end": 36.44, "text": " I wanted to actually be able to listen to people's issues and fix them instead of just", "tokens": [286, 1415, 281, 767, 312, 1075, 281, 2140, 281, 561, 311, 2663, 293, 3191, 552, 2602, 295, 445], "temperature": 0.0, "avg_logprob": -0.11295758819580078, "compression_ratio": 1.5974025974025974, "no_speech_prob": 4.8921137931756675e-05}, {"id": 6, "seek": 2824, "start": 36.44, "end": 39.32, "text": " hear them come down from the product team.", "tokens": [1568, 552, 808, 760, 490, 264, 1674, 1469, 13], "temperature": 0.0, "avg_logprob": -0.11295758819580078, "compression_ratio": 1.5974025974025974, "no_speech_prob": 4.8921137931756675e-05}, {"id": 7, "seek": 2824, "start": 39.32, "end": 43.32, "text": " So if you guys have any questions, I will be allowing some time for Q&A during this", "tokens": [407, 498, 291, 1074, 362, 604, 1651, 11, 286, 486, 312, 8293, 512, 565, 337, 1249, 5, 32, 1830, 341], "temperature": 0.0, "avg_logprob": -0.11295758819580078, "compression_ratio": 1.5974025974025974, "no_speech_prob": 4.8921137931756675e-05}, {"id": 8, "seek": 2824, "start": 43.32, "end": 48.56, "text": " presentation at the end, but if you want to reach out at any point or you just like to", "tokens": [5860, 412, 264, 917, 11, 457, 498, 291, 528, 281, 2524, 484, 412, 604, 935, 420, 291, 445, 411, 281], "temperature": 0.0, "avg_logprob": -0.11295758819580078, "compression_ratio": 1.5974025974025974, "no_speech_prob": 4.8921137931756675e-05}, {"id": 9, "seek": 2824, "start": 48.56, "end": 51.68, "text": " be friends with people on LinkedIn, this is my QR code.", "tokens": [312, 1855, 365, 561, 322, 20657, 11, 341, 307, 452, 32784, 3089, 13], "temperature": 0.0, "avg_logprob": -0.11295758819580078, "compression_ratio": 1.5974025974025974, "no_speech_prob": 4.8921137931756675e-05}, {"id": 10, "seek": 2824, "start": 51.68, "end": 55.92, "text": " My name is relatively unique, I'm easy to find.", "tokens": [1222, 1315, 307, 7226, 3845, 11, 286, 478, 1858, 281, 915, 13], "temperature": 0.0, "avg_logprob": -0.11295758819580078, "compression_ratio": 1.5974025974025974, "no_speech_prob": 4.8921137931756675e-05}, {"id": 11, "seek": 5592, "start": 55.92, "end": 57.68, "text": " The overview.", "tokens": [440, 12492, 13], "temperature": 0.0, "avg_logprob": -0.13764925239499937, "compression_ratio": 1.6992753623188406, "no_speech_prob": 1.9805705960607156e-05}, {"id": 12, "seek": 5592, "start": 57.68, "end": 63.160000000000004, "text": " So in this presentation, we're going to be walking through a few different pieces for", "tokens": [407, 294, 341, 5860, 11, 321, 434, 516, 281, 312, 4494, 807, 257, 1326, 819, 3755, 337], "temperature": 0.0, "avg_logprob": -0.13764925239499937, "compression_ratio": 1.6992753623188406, "no_speech_prob": 1.9805705960607156e-05}, {"id": 13, "seek": 5592, "start": 63.160000000000004, "end": 65.2, "text": " this project.", "tokens": [341, 1716, 13], "temperature": 0.0, "avg_logprob": -0.13764925239499937, "compression_ratio": 1.6992753623188406, "no_speech_prob": 1.9805705960607156e-05}, {"id": 14, "seek": 5592, "start": 65.2, "end": 69.0, "text": " The first thing we're going to be walking through is the IoT hardware setup.", "tokens": [440, 700, 551, 321, 434, 516, 281, 312, 4494, 807, 307, 264, 30112, 8837, 8657, 13], "temperature": 0.0, "avg_logprob": -0.13764925239499937, "compression_ratio": 1.6992753623188406, "no_speech_prob": 1.9805705960607156e-05}, {"id": 15, "seek": 5592, "start": 69.0, "end": 74.16, "text": " So if you guys are not super familiar with like IoT devices and stuff, not to worry,", "tokens": [407, 498, 291, 1074, 366, 406, 1687, 4963, 365, 411, 30112, 5759, 293, 1507, 11, 406, 281, 3292, 11], "temperature": 0.0, "avg_logprob": -0.13764925239499937, "compression_ratio": 1.6992753623188406, "no_speech_prob": 1.9805705960607156e-05}, {"id": 16, "seek": 5592, "start": 74.16, "end": 77.52000000000001, "text": " I'll break it down and then we can kind of figure it out.", "tokens": [286, 603, 1821, 309, 760, 293, 550, 321, 393, 733, 295, 2573, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.13764925239499937, "compression_ratio": 1.6992753623188406, "no_speech_prob": 1.9805705960607156e-05}, {"id": 17, "seek": 5592, "start": 77.52000000000001, "end": 82.2, "text": " Also all of this is available on GitHub, all this code examples, there's lots of instructions,", "tokens": [2743, 439, 295, 341, 307, 2435, 322, 23331, 11, 439, 341, 3089, 5110, 11, 456, 311, 3195, 295, 9415, 11], "temperature": 0.0, "avg_logprob": -0.13764925239499937, "compression_ratio": 1.6992753623188406, "no_speech_prob": 1.9805705960607156e-05}, {"id": 18, "seek": 5592, "start": 82.2, "end": 84.24000000000001, "text": " this is a very well fleshed out project.", "tokens": [341, 307, 257, 588, 731, 12497, 292, 484, 1716, 13], "temperature": 0.0, "avg_logprob": -0.13764925239499937, "compression_ratio": 1.6992753623188406, "no_speech_prob": 1.9805705960607156e-05}, {"id": 19, "seek": 8424, "start": 84.24, "end": 87.75999999999999, "text": " So at the end, I'm going to be linking that as well so you can do it yourself at home", "tokens": [407, 412, 264, 917, 11, 286, 478, 516, 281, 312, 25775, 300, 382, 731, 370, 291, 393, 360, 309, 1803, 412, 1280], "temperature": 0.0, "avg_logprob": -0.16333988100983377, "compression_ratio": 1.7789855072463767, "no_speech_prob": 2.666866930667311e-05}, {"id": 20, "seek": 8424, "start": 87.75999999999999, "end": 89.56, "text": " very easily.", "tokens": [588, 3612, 13], "temperature": 0.0, "avg_logprob": -0.16333988100983377, "compression_ratio": 1.7789855072463767, "no_speech_prob": 2.666866930667311e-05}, {"id": 21, "seek": 8424, "start": 89.56, "end": 93.24, "text": " We're going to go over the tools that we're going to be using for this project.", "tokens": [492, 434, 516, 281, 352, 670, 264, 3873, 300, 321, 434, 516, 281, 312, 1228, 337, 341, 1716, 13], "temperature": 0.0, "avg_logprob": -0.16333988100983377, "compression_ratio": 1.7789855072463767, "no_speech_prob": 2.666866930667311e-05}, {"id": 22, "seek": 8424, "start": 93.24, "end": 98.6, "text": " We're going to go over a short interview, a short overview of InfluxDB just so that", "tokens": [492, 434, 516, 281, 352, 670, 257, 2099, 4049, 11, 257, 2099, 12492, 295, 682, 3423, 2449, 27735, 445, 370, 300], "temperature": 0.0, "avg_logprob": -0.16333988100983377, "compression_ratio": 1.7789855072463767, "no_speech_prob": 2.666866930667311e-05}, {"id": 23, "seek": 8424, "start": 98.6, "end": 103.11999999999999, "text": " with people who don't understand how it works, we'll understand how it works in this project.", "tokens": [365, 561, 567, 500, 380, 1223, 577, 309, 1985, 11, 321, 603, 1223, 577, 309, 1985, 294, 341, 1716, 13], "temperature": 0.0, "avg_logprob": -0.16333988100983377, "compression_ratio": 1.7789855072463767, "no_speech_prob": 2.666866930667311e-05}, {"id": 24, "seek": 8424, "start": 103.11999999999999, "end": 110.36, "text": " The data ingestion setup, Flux and SQL, setting up edge data replication and data request", "tokens": [440, 1412, 3957, 31342, 8657, 11, 3235, 2449, 293, 19200, 11, 3287, 493, 4691, 1412, 39911, 293, 1412, 5308], "temperature": 0.0, "avg_logprob": -0.16333988100983377, "compression_ratio": 1.7789855072463767, "no_speech_prob": 2.666866930667311e-05}, {"id": 25, "seek": 8424, "start": 110.36, "end": 112.88, "text": " which are kind of comboed together somewhat.", "tokens": [597, 366, 733, 295, 16859, 292, 1214, 8344, 13], "temperature": 0.0, "avg_logprob": -0.16333988100983377, "compression_ratio": 1.7789855072463767, "no_speech_prob": 2.666866930667311e-05}, {"id": 26, "seek": 11288, "start": 112.88, "end": 118.92, "text": " And then finally at the end, the GitHub code base, links to other community links and such", "tokens": [400, 550, 2721, 412, 264, 917, 11, 264, 23331, 3089, 3096, 11, 6123, 281, 661, 1768, 6123, 293, 1270], "temperature": 0.0, "avg_logprob": -0.13183106316460502, "compression_ratio": 1.598326359832636, "no_speech_prob": 6.139931883808458e-06}, {"id": 27, "seek": 11288, "start": 118.92, "end": 123.47999999999999, "text": " and then Q&A as well.", "tokens": [293, 550, 1249, 5, 32, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.13183106316460502, "compression_ratio": 1.598326359832636, "no_speech_prob": 6.139931883808458e-06}, {"id": 28, "seek": 11288, "start": 123.47999999999999, "end": 127.84, "text": " So setting up your IoT devices.", "tokens": [407, 3287, 493, 428, 30112, 5759, 13], "temperature": 0.0, "avg_logprob": -0.13183106316460502, "compression_ratio": 1.598326359832636, "no_speech_prob": 6.139931883808458e-06}, {"id": 29, "seek": 11288, "start": 127.84, "end": 133.32, "text": " So this is a handy little diagram to show roughly how this is going to work in real life.", "tokens": [407, 341, 307, 257, 13239, 707, 10686, 281, 855, 9810, 577, 341, 307, 516, 281, 589, 294, 957, 993, 13], "temperature": 0.0, "avg_logprob": -0.13183106316460502, "compression_ratio": 1.598326359832636, "no_speech_prob": 6.139931883808458e-06}, {"id": 30, "seek": 11288, "start": 133.32, "end": 137.07999999999998, "text": " But basically you have a plant and you're going to be monitoring it, you're going to", "tokens": [583, 1936, 291, 362, 257, 3709, 293, 291, 434, 516, 281, 312, 11028, 309, 11, 291, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.13183106316460502, "compression_ratio": 1.598326359832636, "no_speech_prob": 6.139931883808458e-06}, {"id": 31, "seek": 11288, "start": 137.07999999999998, "end": 140.32, "text": " need some kind of microcontroller to receive this information.", "tokens": [643, 512, 733, 295, 4532, 9000, 22922, 281, 4774, 341, 1589, 13], "temperature": 0.0, "avg_logprob": -0.13183106316460502, "compression_ratio": 1.598326359832636, "no_speech_prob": 6.139931883808458e-06}, {"id": 32, "seek": 14032, "start": 140.32, "end": 144.23999999999998, "text": " I'll show a haphazard photo in a second of how that's going to look.", "tokens": [286, 603, 855, 257, 324, 950, 921, 515, 5052, 294, 257, 1150, 295, 577, 300, 311, 516, 281, 574, 13], "temperature": 0.0, "avg_logprob": -0.11416467707207863, "compression_ratio": 1.6734006734006734, "no_speech_prob": 1.4057869520911481e-05}, {"id": 33, "seek": 14032, "start": 144.23999999999998, "end": 148.51999999999998, "text": " But basically from that plant, we're going to get data roughly about, I like to say,", "tokens": [583, 1936, 490, 300, 3709, 11, 321, 434, 516, 281, 483, 1412, 9810, 466, 11, 286, 411, 281, 584, 11], "temperature": 0.0, "avg_logprob": -0.11416467707207863, "compression_ratio": 1.6734006734006734, "no_speech_prob": 1.4057869520911481e-05}, {"id": 34, "seek": 14032, "start": 148.51999999999998, "end": 150.68, "text": " how the plant is feeling.", "tokens": [577, 264, 3709, 307, 2633, 13], "temperature": 0.0, "avg_logprob": -0.11416467707207863, "compression_ratio": 1.6734006734006734, "no_speech_prob": 1.4057869520911481e-05}, {"id": 35, "seek": 14032, "start": 150.68, "end": 156.12, "text": " If it's thirsty or hot or just doesn't like you in particular, it'll let us know.", "tokens": [759, 309, 311, 28115, 420, 2368, 420, 445, 1177, 380, 411, 291, 294, 1729, 11, 309, 603, 718, 505, 458, 13], "temperature": 0.0, "avg_logprob": -0.11416467707207863, "compression_ratio": 1.6734006734006734, "no_speech_prob": 1.4057869520911481e-05}, {"id": 36, "seek": 14032, "start": 156.12, "end": 161.44, "text": " From there, we put that data into our open source, our OSS instance.", "tokens": [3358, 456, 11, 321, 829, 300, 1412, 666, 527, 1269, 4009, 11, 527, 12731, 50, 5197, 13], "temperature": 0.0, "avg_logprob": -0.11416467707207863, "compression_ratio": 1.6734006734006734, "no_speech_prob": 1.4057869520911481e-05}, {"id": 37, "seek": 14032, "start": 161.44, "end": 165.2, "text": " So InfluxDB is available open source so you can just easily download it off GitHub and", "tokens": [407, 682, 3423, 2449, 27735, 307, 2435, 1269, 4009, 370, 291, 393, 445, 3612, 5484, 309, 766, 23331, 293], "temperature": 0.0, "avg_logprob": -0.11416467707207863, "compression_ratio": 1.6734006734006734, "no_speech_prob": 1.4057869520911481e-05}, {"id": 38, "seek": 14032, "start": 165.2, "end": 167.1, "text": " get it running locally.", "tokens": [483, 309, 2614, 16143, 13], "temperature": 0.0, "avg_logprob": -0.11416467707207863, "compression_ratio": 1.6734006734006734, "no_speech_prob": 1.4057869520911481e-05}, {"id": 39, "seek": 14032, "start": 167.1, "end": 169.84, "text": " So in that, we're going to go ahead and store our data.", "tokens": [407, 294, 300, 11, 321, 434, 516, 281, 352, 2286, 293, 3531, 527, 1412, 13], "temperature": 0.0, "avg_logprob": -0.11416467707207863, "compression_ratio": 1.6734006734006734, "no_speech_prob": 1.4057869520911481e-05}, {"id": 40, "seek": 16984, "start": 169.84, "end": 172.8, "text": " We're going to use a telegraph, that's what that little tiger is, we're going to use a", "tokens": [492, 434, 516, 281, 764, 257, 4304, 34091, 11, 300, 311, 437, 300, 707, 21432, 307, 11, 321, 434, 516, 281, 764, 257], "temperature": 0.0, "avg_logprob": -0.11395631013093172, "compression_ratio": 1.9543726235741445, "no_speech_prob": 2.110663081111852e-05}, {"id": 41, "seek": 16984, "start": 172.8, "end": 175.82, "text": " telegraph agent to get the data inside.", "tokens": [4304, 34091, 9461, 281, 483, 264, 1412, 1854, 13], "temperature": 0.0, "avg_logprob": -0.11395631013093172, "compression_ratio": 1.9543726235741445, "no_speech_prob": 2.110663081111852e-05}, {"id": 42, "seek": 16984, "start": 175.82, "end": 180.64000000000001, "text": " From there, if we want, we can go ahead and use our edge data replication feature to go", "tokens": [3358, 456, 11, 498, 321, 528, 11, 321, 393, 352, 2286, 293, 764, 527, 4691, 1412, 39911, 4111, 281, 352], "temperature": 0.0, "avg_logprob": -0.11395631013093172, "compression_ratio": 1.9543726235741445, "no_speech_prob": 2.110663081111852e-05}, {"id": 43, "seek": 16984, "start": 180.64000000000001, "end": 182.76, "text": " ahead and push it to cloud.", "tokens": [2286, 293, 2944, 309, 281, 4588, 13], "temperature": 0.0, "avg_logprob": -0.11395631013093172, "compression_ratio": 1.9543726235741445, "no_speech_prob": 2.110663081111852e-05}, {"id": 44, "seek": 16984, "start": 182.76, "end": 188.0, "text": " And then the idea here is that you can also host this locally, like you can host a little", "tokens": [400, 550, 264, 1558, 510, 307, 300, 291, 393, 611, 3975, 341, 16143, 11, 411, 291, 393, 3975, 257, 707], "temperature": 0.0, "avg_logprob": -0.11395631013093172, "compression_ratio": 1.9543726235741445, "no_speech_prob": 2.110663081111852e-05}, {"id": 45, "seek": 16984, "start": 188.0, "end": 189.44, "text": " website with graphs and such.", "tokens": [3144, 365, 24877, 293, 1270, 13], "temperature": 0.0, "avg_logprob": -0.11395631013093172, "compression_ratio": 1.9543726235741445, "no_speech_prob": 2.110663081111852e-05}, {"id": 46, "seek": 16984, "start": 189.44, "end": 192.48000000000002, "text": " I'll be showing this as we go and the code is available.", "tokens": [286, 603, 312, 4099, 341, 382, 321, 352, 293, 264, 3089, 307, 2435, 13], "temperature": 0.0, "avg_logprob": -0.11395631013093172, "compression_ratio": 1.9543726235741445, "no_speech_prob": 2.110663081111852e-05}, {"id": 47, "seek": 16984, "start": 192.48000000000002, "end": 197.0, "text": " But basically the idea here is that you store your data locally, you use edge data replication", "tokens": [583, 1936, 264, 1558, 510, 307, 300, 291, 3531, 428, 1412, 16143, 11, 291, 764, 4691, 1412, 39911], "temperature": 0.0, "avg_logprob": -0.11395631013093172, "compression_ratio": 1.9543726235741445, "no_speech_prob": 2.110663081111852e-05}, {"id": 48, "seek": 19700, "start": 197.0, "end": 203.08, "text": " to push it up into the cloud for longer term storage or just to have less data loss.", "tokens": [281, 2944, 309, 493, 666, 264, 4588, 337, 2854, 1433, 6725, 420, 445, 281, 362, 1570, 1412, 4470, 13], "temperature": 0.0, "avg_logprob": -0.14606552498013364, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.2810771042713895e-05}, {"id": 49, "seek": 19700, "start": 203.08, "end": 207.84, "text": " And then from there, you can pull that data back out to actually start graphing and visualizing", "tokens": [400, 550, 490, 456, 11, 291, 393, 2235, 300, 1412, 646, 484, 281, 767, 722, 1295, 79, 571, 293, 5056, 3319], "temperature": 0.0, "avg_logprob": -0.14606552498013364, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.2810771042713895e-05}, {"id": 50, "seek": 19700, "start": 207.84, "end": 210.6, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.14606552498013364, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.2810771042713895e-05}, {"id": 51, "seek": 19700, "start": 210.6, "end": 212.88, "text": " As promised, haphazard photo.", "tokens": [1018, 10768, 11, 324, 950, 921, 515, 5052, 13], "temperature": 0.0, "avg_logprob": -0.14606552498013364, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.2810771042713895e-05}, {"id": 52, "seek": 19700, "start": 212.88, "end": 217.88, "text": " So for this project, you need in no particular order, a plant, preferably alive, those are", "tokens": [407, 337, 341, 1716, 11, 291, 643, 294, 572, 1729, 1668, 11, 257, 3709, 11, 45916, 5465, 11, 729, 366], "temperature": 0.0, "avg_logprob": -0.14606552498013364, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.2810771042713895e-05}, {"id": 53, "seek": 19700, "start": 217.88, "end": 222.84, "text": " the best to monitor, a particle boron microcontroller or another compatible one.", "tokens": [264, 1151, 281, 6002, 11, 257, 12359, 14828, 266, 4532, 9000, 22922, 420, 1071, 18218, 472, 13], "temperature": 0.0, "avg_logprob": -0.14606552498013364, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.2810771042713895e-05}, {"id": 54, "seek": 22284, "start": 222.84, "end": 228.8, "text": " We have the schematics and the details for an Arduino, if that would be your preference.", "tokens": [492, 362, 264, 956, 37541, 293, 264, 4365, 337, 364, 39539, 11, 498, 300, 576, 312, 428, 17502, 13], "temperature": 0.0, "avg_logprob": -0.15452734347993294, "compression_ratio": 1.661764705882353, "no_speech_prob": 1.1119155715277884e-05}, {"id": 55, "seek": 22284, "start": 228.8, "end": 233.64000000000001, "text": " At least one IoT sensor for your plant and a breadboard with jump wires and terminal", "tokens": [1711, 1935, 472, 30112, 10200, 337, 428, 3709, 293, 257, 5961, 3787, 365, 3012, 15537, 293, 14709], "temperature": 0.0, "avg_logprob": -0.15452734347993294, "compression_ratio": 1.661764705882353, "no_speech_prob": 1.1119155715277884e-05}, {"id": 56, "seek": 22284, "start": 233.64000000000001, "end": 237.0, "text": " strips.", "tokens": [19842, 13], "temperature": 0.0, "avg_logprob": -0.15452734347993294, "compression_ratio": 1.661764705882353, "no_speech_prob": 1.1119155715277884e-05}, {"id": 57, "seek": 22284, "start": 237.0, "end": 240.52, "text": " As promised, this is what the schematics look like.", "tokens": [1018, 10768, 11, 341, 307, 437, 264, 956, 37541, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.15452734347993294, "compression_ratio": 1.661764705882353, "no_speech_prob": 1.1119155715277884e-05}, {"id": 58, "seek": 22284, "start": 240.52, "end": 244.2, "text": " So basically you can just kind of follow these schematics to the T and that helps you just", "tokens": [407, 1936, 291, 393, 445, 733, 295, 1524, 613, 956, 37541, 281, 264, 314, 293, 300, 3665, 291, 445], "temperature": 0.0, "avg_logprob": -0.15452734347993294, "compression_ratio": 1.661764705882353, "no_speech_prob": 1.1119155715277884e-05}, {"id": 59, "seek": 22284, "start": 244.2, "end": 245.32, "text": " get everything set up.", "tokens": [483, 1203, 992, 493, 13], "temperature": 0.0, "avg_logprob": -0.15452734347993294, "compression_ratio": 1.661764705882353, "no_speech_prob": 1.1119155715277884e-05}, {"id": 60, "seek": 22284, "start": 245.32, "end": 250.0, "text": " We especially had certain issues with some of our sensors, what's the word, interfering", "tokens": [492, 2318, 632, 1629, 2663, 365, 512, 295, 527, 14840, 11, 437, 311, 264, 1349, 11, 48721], "temperature": 0.0, "avg_logprob": -0.15452734347993294, "compression_ratio": 1.661764705882353, "no_speech_prob": 1.1119155715277884e-05}, {"id": 61, "seek": 22284, "start": 250.0, "end": 251.92000000000002, "text": " with other ones.", "tokens": [365, 661, 2306, 13], "temperature": 0.0, "avg_logprob": -0.15452734347993294, "compression_ratio": 1.661764705882353, "no_speech_prob": 1.1119155715277884e-05}, {"id": 62, "seek": 25192, "start": 251.92, "end": 255.83999999999997, "text": " From that, I have four sensors for my project, those are the four that I just happened to", "tokens": [3358, 300, 11, 286, 362, 1451, 14840, 337, 452, 1716, 11, 729, 366, 264, 1451, 300, 286, 445, 2011, 281], "temperature": 0.0, "avg_logprob": -0.12142982803472951, "compression_ratio": 1.6654545454545455, "no_speech_prob": 2.4664490410941653e-05}, {"id": 63, "seek": 25192, "start": 255.83999999999997, "end": 261.03999999999996, "text": " buy off Amazon, which we do list, so you can, depending on your country, it will change,", "tokens": [2256, 766, 6795, 11, 597, 321, 360, 1329, 11, 370, 291, 393, 11, 5413, 322, 428, 1941, 11, 309, 486, 1319, 11], "temperature": 0.0, "avg_logprob": -0.12142982803472951, "compression_ratio": 1.6654545454545455, "no_speech_prob": 2.4664490410941653e-05}, {"id": 64, "seek": 25192, "start": 261.03999999999996, "end": 265.96, "text": " but these sensors are like 25 cents a pop, so they're really cheap and easy to get.", "tokens": [457, 613, 14840, 366, 411, 3552, 14941, 257, 1665, 11, 370, 436, 434, 534, 7084, 293, 1858, 281, 483, 13], "temperature": 0.0, "avg_logprob": -0.12142982803472951, "compression_ratio": 1.6654545454545455, "no_speech_prob": 2.4664490410941653e-05}, {"id": 65, "seek": 25192, "start": 265.96, "end": 272.0, "text": " I have temperature and humidity, I have light, I have soil and moisture, and I have temperature.", "tokens": [286, 362, 4292, 293, 24751, 11, 286, 362, 1442, 11, 286, 362, 6704, 293, 13814, 11, 293, 286, 362, 4292, 13], "temperature": 0.0, "avg_logprob": -0.12142982803472951, "compression_ratio": 1.6654545454545455, "no_speech_prob": 2.4664490410941653e-05}, {"id": 66, "seek": 25192, "start": 272.0, "end": 276.84, "text": " So with all four of these, I can go ahead and hook them up to my breadboard and my microcontroller", "tokens": [407, 365, 439, 1451, 295, 613, 11, 286, 393, 352, 2286, 293, 6328, 552, 493, 281, 452, 5961, 3787, 293, 452, 4532, 9000, 22922], "temperature": 0.0, "avg_logprob": -0.12142982803472951, "compression_ratio": 1.6654545454545455, "no_speech_prob": 2.4664490410941653e-05}, {"id": 67, "seek": 27684, "start": 276.84, "end": 282.11999999999995, "text": " and I can start getting some of that data.", "tokens": [293, 286, 393, 722, 1242, 512, 295, 300, 1412, 13], "temperature": 0.0, "avg_logprob": -0.11289989116579988, "compression_ratio": 1.8168498168498168, "no_speech_prob": 1.472997792006936e-05}, {"id": 68, "seek": 27684, "start": 282.11999999999995, "end": 285.32, "text": " So the tools we're going to be using today.", "tokens": [407, 264, 3873, 321, 434, 516, 281, 312, 1228, 965, 13], "temperature": 0.0, "avg_logprob": -0.11289989116579988, "compression_ratio": 1.8168498168498168, "no_speech_prob": 1.472997792006936e-05}, {"id": 69, "seek": 27684, "start": 285.32, "end": 289.28, "text": " So we are going to be using Flask, which for those of you guys who are not aware is a micro", "tokens": [407, 321, 366, 516, 281, 312, 1228, 3235, 3863, 11, 597, 337, 729, 295, 291, 1074, 567, 366, 406, 3650, 307, 257, 4532], "temperature": 0.0, "avg_logprob": -0.11289989116579988, "compression_ratio": 1.8168498168498168, "no_speech_prob": 1.472997792006936e-05}, {"id": 70, "seek": 27684, "start": 289.28, "end": 291.35999999999996, "text": " web framework written in Python.", "tokens": [3670, 8388, 3720, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.11289989116579988, "compression_ratio": 1.8168498168498168, "no_speech_prob": 1.472997792006936e-05}, {"id": 71, "seek": 27684, "start": 291.35999999999996, "end": 294.91999999999996, "text": " It's going to be doing some of the heavy lifting for the project, specifically it's going", "tokens": [467, 311, 516, 281, 312, 884, 512, 295, 264, 4676, 15798, 337, 264, 1716, 11, 4682, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.11289989116579988, "compression_ratio": 1.8168498168498168, "no_speech_prob": 1.472997792006936e-05}, {"id": 72, "seek": 27684, "start": 294.91999999999996, "end": 300.59999999999997, "text": " to be running the local application and allowing us to have some built in routing.", "tokens": [281, 312, 2614, 264, 2654, 3861, 293, 8293, 505, 281, 362, 512, 3094, 294, 32722, 13], "temperature": 0.0, "avg_logprob": -0.11289989116579988, "compression_ratio": 1.8168498168498168, "no_speech_prob": 1.472997792006936e-05}, {"id": 73, "seek": 27684, "start": 300.59999999999997, "end": 304.96, "text": " We're going to be using InfluxDB for actually storing the data that we get from our IoT", "tokens": [492, 434, 516, 281, 312, 1228, 682, 3423, 2449, 27735, 337, 767, 26085, 264, 1412, 300, 321, 483, 490, 527, 30112], "temperature": 0.0, "avg_logprob": -0.11289989116579988, "compression_ratio": 1.8168498168498168, "no_speech_prob": 1.472997792006936e-05}, {"id": 74, "seek": 27684, "start": 304.96, "end": 306.55999999999995, "text": " sensors from our plant.", "tokens": [14840, 490, 527, 3709, 13], "temperature": 0.0, "avg_logprob": -0.11289989116579988, "compression_ratio": 1.8168498168498168, "no_speech_prob": 1.472997792006936e-05}, {"id": 75, "seek": 30656, "start": 306.56, "end": 310.52, "text": " It comes with an API and tool set that's going to be easy for ingesting and querying that", "tokens": [467, 1487, 365, 364, 9362, 293, 2290, 992, 300, 311, 516, 281, 312, 1858, 337, 3957, 8714, 293, 7083, 1840, 300], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 76, "seek": 30656, "start": 310.52, "end": 312.12, "text": " data back out.", "tokens": [1412, 646, 484, 13], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 77, "seek": 30656, "start": 312.12, "end": 315.44, "text": " It's highly performance, so we don't have to worry about it running up when it's open", "tokens": [467, 311, 5405, 3389, 11, 370, 321, 500, 380, 362, 281, 3292, 466, 309, 2614, 493, 562, 309, 311, 1269], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 78, "seek": 30656, "start": 315.44, "end": 316.44, "text": " sourced.", "tokens": [11006, 1232, 13], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 79, "seek": 30656, "start": 316.44, "end": 319.6, "text": " It doesn't cost us anything outside of the server we're running on locally, but in general", "tokens": [467, 1177, 380, 2063, 505, 1340, 2380, 295, 264, 7154, 321, 434, 2614, 322, 16143, 11, 457, 294, 2674], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 80, "seek": 30656, "start": 319.6, "end": 322.64, "text": " we want our data to be stored efficiently.", "tokens": [321, 528, 527, 1412, 281, 312, 12187, 19621, 13], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 81, "seek": 30656, "start": 322.64, "end": 325.84000000000003, "text": " And then it also has obviously our community and ecosystem.", "tokens": [400, 550, 309, 611, 575, 2745, 527, 1768, 293, 11311, 13], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 82, "seek": 30656, "start": 325.84000000000003, "end": 329.6, "text": " People like me there to help answer questions and come up with these awesome little projects", "tokens": [3432, 411, 385, 456, 281, 854, 1867, 1651, 293, 808, 493, 365, 613, 3476, 707, 4455], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 83, "seek": 30656, "start": 329.6, "end": 333.2, "text": " like monitoring your planted home.", "tokens": [411, 11028, 428, 17395, 1280, 13], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 84, "seek": 30656, "start": 333.2, "end": 336.12, "text": " Telegraph is a completely open source ingestion agent.", "tokens": [1989, 6363, 2662, 307, 257, 2584, 1269, 4009, 3957, 31342, 9461, 13], "temperature": 0.0, "avg_logprob": -0.16078879616477273, "compression_ratio": 1.6793002915451896, "no_speech_prob": 2.8385038604028523e-05}, {"id": 85, "seek": 33612, "start": 336.12, "end": 340.72, "text": " It has over 300 plus different plugins depending on what you need and desire.", "tokens": [467, 575, 670, 6641, 1804, 819, 33759, 5413, 322, 437, 291, 643, 293, 7516, 13], "temperature": 0.0, "avg_logprob": -0.14440832466914735, "compression_ratio": 1.67, "no_speech_prob": 4.750884909299202e-05}, {"id": 86, "seek": 33612, "start": 340.72, "end": 345.92, "text": " For this project we use the exact D processor plugin to get the data into our open source.", "tokens": [1171, 341, 1716, 321, 764, 264, 1900, 413, 15321, 23407, 281, 483, 264, 1412, 666, 527, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.14440832466914735, "compression_ratio": 1.67, "no_speech_prob": 4.750884909299202e-05}, {"id": 87, "seek": 33612, "start": 345.92, "end": 350.2, "text": " I'm also going to be showing code for what I'll actually I'm going to explain that later.", "tokens": [286, 478, 611, 516, 281, 312, 4099, 3089, 337, 437, 286, 603, 767, 286, 478, 516, 281, 2903, 300, 1780, 13], "temperature": 0.0, "avg_logprob": -0.14440832466914735, "compression_ratio": 1.67, "no_speech_prob": 4.750884909299202e-05}, {"id": 88, "seek": 33612, "start": 350.2, "end": 352.2, "text": " But basically this is super nice to use.", "tokens": [583, 1936, 341, 307, 1687, 1481, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.14440832466914735, "compression_ratio": 1.67, "no_speech_prob": 4.750884909299202e-05}, {"id": 89, "seek": 33612, "start": 352.2, "end": 358.08, "text": " It has a very wide range of open source plugins supported by sometimes companies, sometimes", "tokens": [467, 575, 257, 588, 4874, 3613, 295, 1269, 4009, 33759, 8104, 538, 2171, 3431, 11, 2171], "temperature": 0.0, "avg_logprob": -0.14440832466914735, "compression_ratio": 1.67, "no_speech_prob": 4.750884909299202e-05}, {"id": 90, "seek": 33612, "start": 358.08, "end": 359.52, "text": " community members.", "tokens": [1768, 2679, 13], "temperature": 0.0, "avg_logprob": -0.14440832466914735, "compression_ratio": 1.67, "no_speech_prob": 4.750884909299202e-05}, {"id": 91, "seek": 33612, "start": 359.52, "end": 364.72, "text": " You'll find serious ones like Azure monitoring or AWS monitoring to the more fun ones like", "tokens": [509, 603, 915, 3156, 2306, 411, 11969, 11028, 420, 17650, 11028, 281, 264, 544, 1019, 2306, 411], "temperature": 0.0, "avg_logprob": -0.14440832466914735, "compression_ratio": 1.67, "no_speech_prob": 4.750884909299202e-05}, {"id": 92, "seek": 36472, "start": 364.72, "end": 369.20000000000005, "text": " Minecraft or CSGO.", "tokens": [21029, 420, 9460, 11601, 13], "temperature": 0.0, "avg_logprob": -0.12357864671081077, "compression_ratio": 1.6531986531986531, "no_speech_prob": 3.168145485688001e-05}, {"id": 93, "seek": 36472, "start": 369.20000000000005, "end": 373.32000000000005, "text": " For some reason you do not want to use Telegraph, maybe it just doesn't have a configuration", "tokens": [1171, 512, 1778, 291, 360, 406, 528, 281, 764, 1989, 6363, 2662, 11, 1310, 309, 445, 1177, 380, 362, 257, 11694], "temperature": 0.0, "avg_logprob": -0.12357864671081077, "compression_ratio": 1.6531986531986531, "no_speech_prob": 3.168145485688001e-05}, {"id": 94, "seek": 36472, "start": 373.32000000000005, "end": 376.72, "text": " that works for your device or your project.", "tokens": [300, 1985, 337, 428, 4302, 420, 428, 1716, 13], "temperature": 0.0, "avg_logprob": -0.12357864671081077, "compression_ratio": 1.6531986531986531, "no_speech_prob": 3.168145485688001e-05}, {"id": 95, "seek": 36472, "start": 376.72, "end": 380.40000000000003, "text": " A lot of people are just going to go to the client libraries which I'll be showing a code", "tokens": [316, 688, 295, 561, 366, 445, 516, 281, 352, 281, 264, 6423, 15148, 597, 286, 603, 312, 4099, 257, 3089], "temperature": 0.0, "avg_logprob": -0.12357864671081077, "compression_ratio": 1.6531986531986531, "no_speech_prob": 3.168145485688001e-05}, {"id": 96, "seek": 36472, "start": 380.40000000000003, "end": 382.72, "text": " example on how to use these as well.", "tokens": [1365, 322, 577, 281, 764, 613, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.12357864671081077, "compression_ratio": 1.6531986531986531, "no_speech_prob": 3.168145485688001e-05}, {"id": 97, "seek": 36472, "start": 382.72, "end": 386.48, "text": " And this does live inside the project, so you don't have to worry about like going and", "tokens": [400, 341, 775, 1621, 1854, 264, 1716, 11, 370, 291, 500, 380, 362, 281, 3292, 466, 411, 516, 293], "temperature": 0.0, "avg_logprob": -0.12357864671081077, "compression_ratio": 1.6531986531986531, "no_speech_prob": 3.168145485688001e-05}, {"id": 98, "seek": 36472, "start": 386.48, "end": 387.48, "text": " finding it.", "tokens": [5006, 309, 13], "temperature": 0.0, "avg_logprob": -0.12357864671081077, "compression_ratio": 1.6531986531986531, "no_speech_prob": 3.168145485688001e-05}, {"id": 99, "seek": 36472, "start": 387.48, "end": 390.24, "text": " We just left it there just in case people want to use it.", "tokens": [492, 445, 1411, 309, 456, 445, 294, 1389, 561, 528, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.12357864671081077, "compression_ratio": 1.6531986531986531, "no_speech_prob": 3.168145485688001e-05}, {"id": 100, "seek": 36472, "start": 390.24, "end": 393.24, "text": " So obviously it's got a few different options here.", "tokens": [407, 2745, 309, 311, 658, 257, 1326, 819, 3956, 510, 13], "temperature": 0.0, "avg_logprob": -0.12357864671081077, "compression_ratio": 1.6531986531986531, "no_speech_prob": 3.168145485688001e-05}, {"id": 101, "seek": 39324, "start": 393.24, "end": 396.84000000000003, "text": " We're going to be using the Python one because that's the one I've worked in and that's what", "tokens": [492, 434, 516, 281, 312, 1228, 264, 15329, 472, 570, 300, 311, 264, 472, 286, 600, 2732, 294, 293, 300, 311, 437], "temperature": 0.0, "avg_logprob": -0.1403369091926737, "compression_ratio": 1.8141891891891893, "no_speech_prob": 3.70310663129203e-05}, {"id": 102, "seek": 39324, "start": 396.84000000000003, "end": 401.68, "text": " the project is written in.", "tokens": [264, 1716, 307, 3720, 294, 13], "temperature": 0.0, "avg_logprob": -0.1403369091926737, "compression_ratio": 1.8141891891891893, "no_speech_prob": 3.70310663129203e-05}, {"id": 103, "seek": 39324, "start": 401.68, "end": 405.72, "text": " Another thing that I use when I built up this project is the flux extension for VS Code.", "tokens": [3996, 551, 300, 286, 764, 562, 286, 3094, 493, 341, 1716, 307, 264, 19298, 10320, 337, 25091, 15549, 13], "temperature": 0.0, "avg_logprob": -0.1403369091926737, "compression_ratio": 1.8141891891891893, "no_speech_prob": 3.70310663129203e-05}, {"id": 104, "seek": 39324, "start": 405.72, "end": 410.56, "text": " It's really nice in that it allows me to write my flux queries and it kind of tells me if", "tokens": [467, 311, 534, 1481, 294, 300, 309, 4045, 385, 281, 2464, 452, 19298, 24109, 293, 309, 733, 295, 5112, 385, 498], "temperature": 0.0, "avg_logprob": -0.1403369091926737, "compression_ratio": 1.8141891891891893, "no_speech_prob": 3.70310663129203e-05}, {"id": 105, "seek": 39324, "start": 410.56, "end": 412.96000000000004, "text": " I'm misspelling or writing things wrong.", "tokens": [286, 478, 1713, 494, 2669, 420, 3579, 721, 2085, 13], "temperature": 0.0, "avg_logprob": -0.1403369091926737, "compression_ratio": 1.8141891891891893, "no_speech_prob": 3.70310663129203e-05}, {"id": 106, "seek": 39324, "start": 412.96000000000004, "end": 415.40000000000003, "text": " It's just like any other extension that you're going to get in VS Code.", "tokens": [467, 311, 445, 411, 604, 661, 10320, 300, 291, 434, 516, 281, 483, 294, 25091, 15549, 13], "temperature": 0.0, "avg_logprob": -0.1403369091926737, "compression_ratio": 1.8141891891891893, "no_speech_prob": 3.70310663129203e-05}, {"id": 107, "seek": 39324, "start": 415.40000000000003, "end": 419.32, "text": " It highlights things and helps you realize when you're making mistakes.", "tokens": [467, 14254, 721, 293, 3665, 291, 4325, 562, 291, 434, 1455, 8038, 13], "temperature": 0.0, "avg_logprob": -0.1403369091926737, "compression_ratio": 1.8141891891891893, "no_speech_prob": 3.70310663129203e-05}, {"id": 108, "seek": 39324, "start": 419.32, "end": 423.12, "text": " Finally, we're going to be using plotly for graphing.", "tokens": [6288, 11, 321, 434, 516, 281, 312, 1228, 7542, 356, 337, 1295, 79, 571, 13], "temperature": 0.0, "avg_logprob": -0.1403369091926737, "compression_ratio": 1.8141891891891893, "no_speech_prob": 3.70310663129203e-05}, {"id": 109, "seek": 42312, "start": 423.12, "end": 428.48, "text": " It is a completely free and open source graphing library which is always our favorite.", "tokens": [467, 307, 257, 2584, 1737, 293, 1269, 4009, 1295, 79, 571, 6405, 597, 307, 1009, 527, 2954, 13], "temperature": 0.0, "avg_logprob": -0.10773224300808376, "compression_ratio": 1.6040816326530611, "no_speech_prob": 1.3202974514570087e-05}, {"id": 110, "seek": 42312, "start": 428.48, "end": 435.12, "text": " And it's really nice and easy to work with and very colorful which I appreciate.", "tokens": [400, 309, 311, 534, 1481, 293, 1858, 281, 589, 365, 293, 588, 18506, 597, 286, 4449, 13], "temperature": 0.0, "avg_logprob": -0.10773224300808376, "compression_ratio": 1.6040816326530611, "no_speech_prob": 1.3202974514570087e-05}, {"id": 111, "seek": 42312, "start": 435.12, "end": 438.24, "text": " So a really quick overview.", "tokens": [407, 257, 534, 1702, 12492, 13], "temperature": 0.0, "avg_logprob": -0.10773224300808376, "compression_ratio": 1.6040816326530611, "no_speech_prob": 1.3202974514570087e-05}, {"id": 112, "seek": 42312, "start": 438.24, "end": 443.44, "text": " So for those of you guys who are not quite familiar with it, time series data is a very", "tokens": [407, 337, 729, 295, 291, 1074, 567, 366, 406, 1596, 4963, 365, 309, 11, 565, 2638, 1412, 307, 257, 588], "temperature": 0.0, "avg_logprob": -0.10773224300808376, "compression_ratio": 1.6040816326530611, "no_speech_prob": 1.3202974514570087e-05}, {"id": 113, "seek": 42312, "start": 443.44, "end": 445.0, "text": " specific type of data.", "tokens": [2685, 2010, 295, 1412, 13], "temperature": 0.0, "avg_logprob": -0.10773224300808376, "compression_ratio": 1.6040816326530611, "no_speech_prob": 1.3202974514570087e-05}, {"id": 114, "seek": 42312, "start": 445.0, "end": 449.6, "text": " So it's what we're going to be getting from our plant because IoT sensors tend to give", "tokens": [407, 309, 311, 437, 321, 434, 516, 281, 312, 1242, 490, 527, 3709, 570, 30112, 14840, 3928, 281, 976], "temperature": 0.0, "avg_logprob": -0.10773224300808376, "compression_ratio": 1.6040816326530611, "no_speech_prob": 1.3202974514570087e-05}, {"id": 115, "seek": 44960, "start": 449.6, "end": 455.68, "text": " you time series data and the fact that it is metrics regularly intervaled at time.", "tokens": [291, 565, 2638, 1412, 293, 264, 1186, 300, 309, 307, 16367, 11672, 15035, 292, 412, 565, 13], "temperature": 0.0, "avg_logprob": -0.09717999735186177, "compression_ratio": 1.8796992481203008, "no_speech_prob": 2.2459589672507718e-05}, {"id": 116, "seek": 44960, "start": 455.68, "end": 461.08000000000004, "text": " So what that means is that you want to know at what point the plant got thirsty or you", "tokens": [407, 437, 300, 1355, 307, 300, 291, 528, 281, 458, 412, 437, 935, 264, 3709, 658, 28115, 420, 291], "temperature": 0.0, "avg_logprob": -0.09717999735186177, "compression_ratio": 1.8796992481203008, "no_speech_prob": 2.2459589672507718e-05}, {"id": 117, "seek": 44960, "start": 461.08000000000004, "end": 464.68, "text": " want to know how many hours a day did it get sunlight.", "tokens": [528, 281, 458, 577, 867, 2496, 257, 786, 630, 309, 483, 18379, 13], "temperature": 0.0, "avg_logprob": -0.09717999735186177, "compression_ratio": 1.8796992481203008, "no_speech_prob": 2.2459589672507718e-05}, {"id": 118, "seek": 44960, "start": 464.68, "end": 465.8, "text": " That's all time series data.", "tokens": [663, 311, 439, 565, 2638, 1412, 13], "temperature": 0.0, "avg_logprob": -0.09717999735186177, "compression_ratio": 1.8796992481203008, "no_speech_prob": 2.2459589672507718e-05}, {"id": 119, "seek": 44960, "start": 465.8, "end": 470.04, "text": " That's data that you want to know about on a time scale.", "tokens": [663, 311, 1412, 300, 291, 528, 281, 458, 466, 322, 257, 565, 4373, 13], "temperature": 0.0, "avg_logprob": -0.09717999735186177, "compression_ratio": 1.8796992481203008, "no_speech_prob": 2.2459589672507718e-05}, {"id": 120, "seek": 44960, "start": 470.04, "end": 473.72, "text": " We normally see these as metrics at regular time intervals.", "tokens": [492, 5646, 536, 613, 382, 16367, 412, 3890, 565, 26651, 13], "temperature": 0.0, "avg_logprob": -0.09717999735186177, "compression_ratio": 1.8796992481203008, "no_speech_prob": 2.2459589672507718e-05}, {"id": 121, "seek": 44960, "start": 473.72, "end": 475.6, "text": " Occasionally we see things like events.", "tokens": [26191, 6822, 379, 321, 536, 721, 411, 3931, 13], "temperature": 0.0, "avg_logprob": -0.09717999735186177, "compression_ratio": 1.8796992481203008, "no_speech_prob": 2.2459589672507718e-05}, {"id": 122, "seek": 44960, "start": 475.6, "end": 479.36, "text": " You can think of things also like the stock exchange or weather conditions as other great", "tokens": [509, 393, 519, 295, 721, 611, 411, 264, 4127, 7742, 420, 5503, 4487, 382, 661, 869], "temperature": 0.0, "avg_logprob": -0.09717999735186177, "compression_ratio": 1.8796992481203008, "no_speech_prob": 2.2459589672507718e-05}, {"id": 123, "seek": 47936, "start": 479.36, "end": 482.12, "text": " examples of this type of data.", "tokens": [5110, 295, 341, 2010, 295, 1412, 13], "temperature": 0.0, "avg_logprob": -0.14037494170360076, "compression_ratio": 1.7220216606498195, "no_speech_prob": 6.295863568084314e-05}, {"id": 124, "seek": 47936, "start": 482.12, "end": 485.48, "text": " We tend to find these in multiple different applications.", "tokens": [492, 3928, 281, 915, 613, 294, 3866, 819, 5821, 13], "temperature": 0.0, "avg_logprob": -0.14037494170360076, "compression_ratio": 1.7220216606498195, "no_speech_prob": 6.295863568084314e-05}, {"id": 125, "seek": 47936, "start": 485.48, "end": 490.36, "text": " The software infrastructure is probably the most common and most people here would understand", "tokens": [440, 4722, 6896, 307, 1391, 264, 881, 2689, 293, 881, 561, 510, 576, 1223], "temperature": 0.0, "avg_logprob": -0.14037494170360076, "compression_ratio": 1.7220216606498195, "no_speech_prob": 6.295863568084314e-05}, {"id": 126, "seek": 47936, "start": 490.36, "end": 491.76, "text": " where that comes from.", "tokens": [689, 300, 1487, 490, 13], "temperature": 0.0, "avg_logprob": -0.14037494170360076, "compression_ratio": 1.7220216606498195, "no_speech_prob": 6.295863568084314e-05}, {"id": 127, "seek": 47936, "start": 491.76, "end": 496.24, "text": " Obviously for this one we're going to be using IoT data.", "tokens": [7580, 337, 341, 472, 321, 434, 516, 281, 312, 1228, 30112, 1412, 13], "temperature": 0.0, "avg_logprob": -0.14037494170360076, "compression_ratio": 1.7220216606498195, "no_speech_prob": 6.295863568084314e-05}, {"id": 128, "seek": 47936, "start": 496.24, "end": 500.56, "text": " So one thing to note is if you had multiple plants at home, you might want to store that", "tokens": [407, 472, 551, 281, 3637, 307, 498, 291, 632, 3866, 5972, 412, 1280, 11, 291, 1062, 528, 281, 3531, 300], "temperature": 0.0, "avg_logprob": -0.14037494170360076, "compression_ratio": 1.7220216606498195, "no_speech_prob": 6.295863568084314e-05}, {"id": 129, "seek": 47936, "start": 500.56, "end": 506.12, "text": " data like you might want to know that you have six orchids and seven aloe veras.", "tokens": [1412, 411, 291, 1062, 528, 281, 458, 300, 291, 362, 2309, 34850, 3742, 293, 3407, 419, 7921, 1306, 296, 13], "temperature": 0.0, "avg_logprob": -0.14037494170360076, "compression_ratio": 1.7220216606498195, "no_speech_prob": 6.295863568084314e-05}, {"id": 130, "seek": 47936, "start": 506.12, "end": 508.40000000000003, "text": " You store that kind of data in a relational.", "tokens": [509, 3531, 300, 733, 295, 1412, 294, 257, 38444, 13], "temperature": 0.0, "avg_logprob": -0.14037494170360076, "compression_ratio": 1.7220216606498195, "no_speech_prob": 6.295863568084314e-05}, {"id": 131, "seek": 50840, "start": 508.4, "end": 509.4, "text": " You'd name them.", "tokens": [509, 1116, 1315, 552, 13], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 132, "seek": 50840, "start": 509.4, "end": 512.76, "text": " You'd say this is the one that lives in the window on the north side of the house.", "tokens": [509, 1116, 584, 341, 307, 264, 472, 300, 2909, 294, 264, 4910, 322, 264, 6830, 1252, 295, 264, 1782, 13], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 133, "seek": 50840, "start": 512.76, "end": 515.24, "text": " This is the one that lives in the window on the south.", "tokens": [639, 307, 264, 472, 300, 2909, 294, 264, 4910, 322, 264, 7377, 13], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 134, "seek": 50840, "start": 515.24, "end": 517.76, "text": " And by the way, one of my coworkers totally did this.", "tokens": [400, 538, 264, 636, 11, 472, 295, 452, 43465, 3879, 630, 341, 13], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 135, "seek": 50840, "start": 517.76, "end": 520.56, "text": " He has like a hundred plants in his house.", "tokens": [634, 575, 411, 257, 3262, 5972, 294, 702, 1782, 13], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 136, "seek": 50840, "start": 520.56, "end": 525.8, "text": " So he organized it in his SQL DB, his relational, because this was a lot of plant data.", "tokens": [407, 415, 9983, 309, 294, 702, 19200, 26754, 11, 702, 38444, 11, 570, 341, 390, 257, 688, 295, 3709, 1412, 13], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 137, "seek": 50840, "start": 525.8, "end": 529.28, "text": " But then when he was actually monitoring all of these plants, which I really don't know", "tokens": [583, 550, 562, 415, 390, 767, 11028, 439, 295, 613, 5972, 11, 597, 286, 534, 500, 380, 458], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 138, "seek": 50840, "start": 529.28, "end": 531.76, "text": " how he set this, his house is just full of cords.", "tokens": [577, 415, 992, 341, 11, 702, 1782, 307, 445, 1577, 295, 36302, 13], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 139, "seek": 50840, "start": 531.76, "end": 533.72, "text": " It's just cords everywhere.", "tokens": [467, 311, 445, 36302, 5315, 13], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 140, "seek": 50840, "start": 533.72, "end": 538.28, "text": " When he set this up to actually start monitoring all of these, that would be time series data.", "tokens": [1133, 415, 992, 341, 493, 281, 767, 722, 11028, 439, 295, 613, 11, 300, 576, 312, 565, 2638, 1412, 13], "temperature": 0.0, "avg_logprob": -0.13866169852499635, "compression_ratio": 1.8987341772151898, "no_speech_prob": 4.0671358874533325e-05}, {"id": 141, "seek": 53828, "start": 538.28, "end": 543.52, "text": " So that's going to be all of those timestamp metrics coming in.", "tokens": [407, 300, 311, 516, 281, 312, 439, 295, 729, 49108, 1215, 16367, 1348, 294, 13], "temperature": 0.0, "avg_logprob": -0.08981510688518655, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.8329803424421698e-05}, {"id": 142, "seek": 53828, "start": 543.52, "end": 547.3199999999999, "text": " So this is kind of how the entire platform looks when it's all put together.", "tokens": [407, 341, 307, 733, 295, 577, 264, 2302, 3663, 1542, 562, 309, 311, 439, 829, 1214, 13], "temperature": 0.0, "avg_logprob": -0.08981510688518655, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.8329803424421698e-05}, {"id": 143, "seek": 53828, "start": 547.3199999999999, "end": 552.24, "text": " So as you can see, you have your data sources, then you have telegraph in the client libraries", "tokens": [407, 382, 291, 393, 536, 11, 291, 362, 428, 1412, 7139, 11, 550, 291, 362, 4304, 34091, 294, 264, 6423, 15148], "temperature": 0.0, "avg_logprob": -0.08981510688518655, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.8329803424421698e-05}, {"id": 144, "seek": 53828, "start": 552.24, "end": 556.4399999999999, "text": " as well as things like native ecosystems, which we're not going to go into today.", "tokens": [382, 731, 382, 721, 411, 8470, 32647, 11, 597, 321, 434, 406, 516, 281, 352, 666, 965, 13], "temperature": 0.0, "avg_logprob": -0.08981510688518655, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.8329803424421698e-05}, {"id": 145, "seek": 53828, "start": 556.4399999999999, "end": 559.04, "text": " And those are the ways of getting the data in.", "tokens": [400, 729, 366, 264, 2098, 295, 1242, 264, 1412, 294, 13], "temperature": 0.0, "avg_logprob": -0.08981510688518655, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.8329803424421698e-05}, {"id": 146, "seek": 53828, "start": 559.04, "end": 564.36, "text": " And from there, you can use Inflex DB to set up things like triggers and alerts, things", "tokens": [400, 490, 456, 11, 291, 393, 764, 11537, 2021, 26754, 281, 992, 493, 721, 411, 22827, 293, 28061, 11, 721], "temperature": 0.0, "avg_logprob": -0.08981510688518655, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.8329803424421698e-05}, {"id": 147, "seek": 56436, "start": 564.36, "end": 570.32, "text": " like you can get, I have it set up to send me a text, be it Twilio, if my plant needs", "tokens": [411, 291, 393, 483, 11, 286, 362, 309, 992, 493, 281, 2845, 385, 257, 2487, 11, 312, 309, 2574, 388, 1004, 11, 498, 452, 3709, 2203], "temperature": 0.0, "avg_logprob": -0.15382482159522273, "compression_ratio": 1.6131386861313868, "no_speech_prob": 2.1105730411363766e-05}, {"id": 148, "seek": 56436, "start": 570.32, "end": 571.52, "text": " some water.", "tokens": [512, 1281, 13], "temperature": 0.0, "avg_logprob": -0.15382482159522273, "compression_ratio": 1.6131386861313868, "no_speech_prob": 2.1105730411363766e-05}, {"id": 149, "seek": 56436, "start": 571.52, "end": 574.84, "text": " I use it quite often at my job and then promptly ignore the text.", "tokens": [286, 764, 309, 1596, 2049, 412, 452, 1691, 293, 550, 48594, 11200, 264, 2487, 13], "temperature": 0.0, "avg_logprob": -0.15382482159522273, "compression_ratio": 1.6131386861313868, "no_speech_prob": 2.1105730411363766e-05}, {"id": 150, "seek": 56436, "start": 574.84, "end": 577.64, "text": " It doesn't work out very well for the plant or me.", "tokens": [467, 1177, 380, 589, 484, 588, 731, 337, 264, 3709, 420, 385, 13], "temperature": 0.0, "avg_logprob": -0.15382482159522273, "compression_ratio": 1.6131386861313868, "no_speech_prob": 2.1105730411363766e-05}, {"id": 151, "seek": 56436, "start": 577.64, "end": 581.2, "text": " But if I actually paid attention, this is very useful to use.", "tokens": [583, 498, 286, 767, 4835, 3202, 11, 341, 307, 588, 4420, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.15382482159522273, "compression_ratio": 1.6131386861313868, "no_speech_prob": 2.1105730411363766e-05}, {"id": 152, "seek": 56436, "start": 581.2, "end": 585.5600000000001, "text": " And finally, obviously with these kind of data, what's the data stored once we have", "tokens": [400, 2721, 11, 2745, 365, 613, 733, 295, 1412, 11, 437, 311, 264, 1412, 12187, 1564, 321, 362], "temperature": 0.0, "avg_logprob": -0.15382482159522273, "compression_ratio": 1.6131386861313868, "no_speech_prob": 2.1105730411363766e-05}, {"id": 153, "seek": 56436, "start": 585.5600000000001, "end": 591.96, "text": " it being used, maybe down-sampling it, we can actually start seeing some results.", "tokens": [309, 885, 1143, 11, 1310, 760, 12, 19988, 11970, 309, 11, 321, 393, 767, 722, 2577, 512, 3542, 13], "temperature": 0.0, "avg_logprob": -0.15382482159522273, "compression_ratio": 1.6131386861313868, "no_speech_prob": 2.1105730411363766e-05}, {"id": 154, "seek": 59196, "start": 591.96, "end": 598.84, "text": " Obviously, infrastructure insights isn't quite what this is, but more like plant insights.", "tokens": [7580, 11, 6896, 14310, 1943, 380, 1596, 437, 341, 307, 11, 457, 544, 411, 3709, 14310, 13], "temperature": 0.0, "avg_logprob": -0.1079821352098809, "compression_ratio": 1.7065217391304348, "no_speech_prob": 2.353341187699698e-05}, {"id": 155, "seek": 59196, "start": 598.84, "end": 602.6800000000001, "text": " So when it comes to data ingestion setup.", "tokens": [407, 562, 309, 1487, 281, 1412, 3957, 31342, 8657, 13], "temperature": 0.0, "avg_logprob": -0.1079821352098809, "compression_ratio": 1.7065217391304348, "no_speech_prob": 2.353341187699698e-05}, {"id": 156, "seek": 59196, "start": 602.6800000000001, "end": 607.2, "text": " So I'm not going to go super in depth on how to set up your microcontroller, because", "tokens": [407, 286, 478, 406, 516, 281, 352, 1687, 294, 7161, 322, 577, 281, 992, 493, 428, 4532, 9000, 22922, 11, 570], "temperature": 0.0, "avg_logprob": -0.1079821352098809, "compression_ratio": 1.7065217391304348, "no_speech_prob": 2.353341187699698e-05}, {"id": 157, "seek": 59196, "start": 607.2, "end": 610.5600000000001, "text": " depending on the one you're using, it's going to be different.", "tokens": [5413, 322, 264, 472, 291, 434, 1228, 11, 309, 311, 516, 281, 312, 819, 13], "temperature": 0.0, "avg_logprob": -0.1079821352098809, "compression_ratio": 1.7065217391304348, "no_speech_prob": 2.353341187699698e-05}, {"id": 158, "seek": 59196, "start": 610.5600000000001, "end": 612.32, "text": " They're all going to be very varied.", "tokens": [814, 434, 439, 516, 281, 312, 588, 22877, 13], "temperature": 0.0, "avg_logprob": -0.1079821352098809, "compression_ratio": 1.7065217391304348, "no_speech_prob": 2.353341187699698e-05}, {"id": 159, "seek": 59196, "start": 612.32, "end": 614.76, "text": " You're just going to have to follow the instructions on that one.", "tokens": [509, 434, 445, 516, 281, 362, 281, 1524, 264, 9415, 322, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.1079821352098809, "compression_ratio": 1.7065217391304348, "no_speech_prob": 2.353341187699698e-05}, {"id": 160, "seek": 59196, "start": 614.76, "end": 620.64, "text": " If you happen to have an Arduino or a Boron microcontroller, you could probably follow,", "tokens": [759, 291, 1051, 281, 362, 364, 39539, 420, 257, 13739, 266, 4532, 9000, 22922, 11, 291, 727, 1391, 1524, 11], "temperature": 0.0, "avg_logprob": -0.1079821352098809, "compression_ratio": 1.7065217391304348, "no_speech_prob": 2.353341187699698e-05}, {"id": 161, "seek": 62064, "start": 620.64, "end": 623.4399999999999, "text": " I mean, you can follow our directions anyways, but those are probably going to be pretty", "tokens": [286, 914, 11, 291, 393, 1524, 527, 11095, 13448, 11, 457, 729, 366, 1391, 516, 281, 312, 1238], "temperature": 0.0, "avg_logprob": -0.10314822683528978, "compression_ratio": 1.8071895424836601, "no_speech_prob": 2.108495209540706e-05}, {"id": 162, "seek": 62064, "start": 623.4399999999999, "end": 625.64, "text": " easy to set up because we talk about it.", "tokens": [1858, 281, 992, 493, 570, 321, 751, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.10314822683528978, "compression_ratio": 1.8071895424836601, "no_speech_prob": 2.108495209540706e-05}, {"id": 163, "seek": 62064, "start": 625.64, "end": 629.28, "text": " But this is just an example of how the data tends to come in.", "tokens": [583, 341, 307, 445, 364, 1365, 295, 577, 264, 1412, 12258, 281, 808, 294, 13], "temperature": 0.0, "avg_logprob": -0.10314822683528978, "compression_ratio": 1.8071895424836601, "no_speech_prob": 2.108495209540706e-05}, {"id": 164, "seek": 62064, "start": 629.28, "end": 633.76, "text": " So as you can see, I've got my port set up and then I start to get these data results.", "tokens": [407, 382, 291, 393, 536, 11, 286, 600, 658, 452, 2436, 992, 493, 293, 550, 286, 722, 281, 483, 613, 1412, 3542, 13], "temperature": 0.0, "avg_logprob": -0.10314822683528978, "compression_ratio": 1.8071895424836601, "no_speech_prob": 2.108495209540706e-05}, {"id": 165, "seek": 62064, "start": 633.76, "end": 640.16, "text": " So for example, if I remember correctly, this one is the humidity one, this one is the temperature.", "tokens": [407, 337, 1365, 11, 498, 286, 1604, 8944, 11, 341, 472, 307, 264, 24751, 472, 11, 341, 472, 307, 264, 4292, 13], "temperature": 0.0, "avg_logprob": -0.10314822683528978, "compression_ratio": 1.8071895424836601, "no_speech_prob": 2.108495209540706e-05}, {"id": 166, "seek": 62064, "start": 640.16, "end": 644.28, "text": " As you can see, this is like the first, I'm going to call it the first flush.", "tokens": [1018, 291, 393, 536, 11, 341, 307, 411, 264, 700, 11, 286, 478, 516, 281, 818, 309, 264, 700, 19568, 13], "temperature": 0.0, "avg_logprob": -0.10314822683528978, "compression_ratio": 1.8071895424836601, "no_speech_prob": 2.108495209540706e-05}, {"id": 167, "seek": 62064, "start": 644.28, "end": 647.84, "text": " So sometimes the data comes in as zeros at first and then it starts to actually give", "tokens": [407, 2171, 264, 1412, 1487, 294, 382, 35193, 412, 700, 293, 550, 309, 3719, 281, 767, 976], "temperature": 0.0, "avg_logprob": -0.10314822683528978, "compression_ratio": 1.8071895424836601, "no_speech_prob": 2.108495209540706e-05}, {"id": 168, "seek": 62064, "start": 647.84, "end": 649.52, "text": " you values.", "tokens": [291, 4190, 13], "temperature": 0.0, "avg_logprob": -0.10314822683528978, "compression_ratio": 1.8071895424836601, "no_speech_prob": 2.108495209540706e-05}, {"id": 169, "seek": 64952, "start": 649.52, "end": 653.6, "text": " One thing to note, and I'm not going to go over it in this presentation, but you can", "tokens": [1485, 551, 281, 3637, 11, 293, 286, 478, 406, 516, 281, 352, 670, 309, 294, 341, 5860, 11, 457, 291, 393], "temperature": 0.0, "avg_logprob": -0.09851523983863092, "compression_ratio": 1.77602523659306, "no_speech_prob": 2.246191434096545e-05}, {"id": 170, "seek": 64952, "start": 653.6, "end": 657.36, "text": " see it in the GitHub, like in the repository in the code.", "tokens": [536, 309, 294, 264, 23331, 11, 411, 294, 264, 25841, 294, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.09851523983863092, "compression_ratio": 1.77602523659306, "no_speech_prob": 2.246191434096545e-05}, {"id": 171, "seek": 64952, "start": 657.36, "end": 660.56, "text": " We do tend to do a little bit of cleanup on these values.", "tokens": [492, 360, 3928, 281, 360, 257, 707, 857, 295, 40991, 322, 613, 4190, 13], "temperature": 0.0, "avg_logprob": -0.09851523983863092, "compression_ratio": 1.77602523659306, "no_speech_prob": 2.246191434096545e-05}, {"id": 172, "seek": 64952, "start": 660.56, "end": 664.96, "text": " The data sensors are not exactly friendly in how they send you data, so I'm going to", "tokens": [440, 1412, 14840, 366, 406, 2293, 9208, 294, 577, 436, 2845, 291, 1412, 11, 370, 286, 478, 516, 281], "temperature": 0.0, "avg_logprob": -0.09851523983863092, "compression_ratio": 1.77602523659306, "no_speech_prob": 2.246191434096545e-05}, {"id": 173, "seek": 64952, "start": 664.96, "end": 665.96, "text": " put it.", "tokens": [829, 309, 13], "temperature": 0.0, "avg_logprob": -0.09851523983863092, "compression_ratio": 1.77602523659306, "no_speech_prob": 2.246191434096545e-05}, {"id": 174, "seek": 64952, "start": 665.96, "end": 669.76, "text": " So we did have to do a little bit of our own cleanup in Python, which luckily we supply", "tokens": [407, 321, 630, 362, 281, 360, 257, 707, 857, 295, 527, 1065, 40991, 294, 15329, 11, 597, 22880, 321, 5847], "temperature": 0.0, "avg_logprob": -0.09851523983863092, "compression_ratio": 1.77602523659306, "no_speech_prob": 2.246191434096545e-05}, {"id": 175, "seek": 64952, "start": 669.76, "end": 670.76, "text": " to you.", "tokens": [281, 291, 13], "temperature": 0.0, "avg_logprob": -0.09851523983863092, "compression_ratio": 1.77602523659306, "no_speech_prob": 2.246191434096545e-05}, {"id": 176, "seek": 64952, "start": 670.76, "end": 674.84, "text": " So if you're using roughly the same ones, you can go ahead and just use what we have.", "tokens": [407, 498, 291, 434, 1228, 9810, 264, 912, 2306, 11, 291, 393, 352, 2286, 293, 445, 764, 437, 321, 362, 13], "temperature": 0.0, "avg_logprob": -0.09851523983863092, "compression_ratio": 1.77602523659306, "no_speech_prob": 2.246191434096545e-05}, {"id": 177, "seek": 64952, "start": 674.84, "end": 678.56, "text": " But like, for example, our temperature kind of came in a little bit weird and we had to", "tokens": [583, 411, 11, 337, 1365, 11, 527, 4292, 733, 295, 1361, 294, 257, 707, 857, 3657, 293, 321, 632, 281], "temperature": 0.0, "avg_logprob": -0.09851523983863092, "compression_ratio": 1.77602523659306, "no_speech_prob": 2.246191434096545e-05}, {"id": 178, "seek": 67856, "start": 678.56, "end": 682.8, "text": " change it so it actually read in a more human readable way, and we haven't yet fixed the", "tokens": [1319, 309, 370, 309, 767, 1401, 294, 257, 544, 1952, 49857, 636, 11, 293, 321, 2378, 380, 1939, 6806, 264], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 179, "seek": 67856, "start": 682.8, "end": 683.92, "text": " light one.", "tokens": [1442, 472, 13], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 180, "seek": 67856, "start": 683.92, "end": 687.7199999999999, "text": " So it just looks really strange.", "tokens": [407, 309, 445, 1542, 534, 5861, 13], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 181, "seek": 67856, "start": 687.7199999999999, "end": 691.28, "text": " Interesting.", "tokens": [14711, 13], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 182, "seek": 67856, "start": 691.28, "end": 693.9599999999999, "text": " I expected my video to show up.", "tokens": [286, 5176, 452, 960, 281, 855, 493, 13], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 183, "seek": 67856, "start": 693.9599999999999, "end": 697.92, "text": " Well, oh wait, it is up there.", "tokens": [1042, 11, 1954, 1699, 11, 309, 307, 493, 456, 13], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 184, "seek": 67856, "start": 697.92, "end": 698.92, "text": " Aha.", "tokens": [27448, 13], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 185, "seek": 67856, "start": 698.92, "end": 703.04, "text": " Well, let's see, can I get this to work?", "tokens": [1042, 11, 718, 311, 536, 11, 393, 286, 483, 341, 281, 589, 30], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 186, "seek": 67856, "start": 703.04, "end": 704.04, "text": " Not quite.", "tokens": [1726, 1596, 13], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 187, "seek": 67856, "start": 704.04, "end": 706.56, "text": " Sorry, guys.", "tokens": [4919, 11, 1074, 13], "temperature": 0.0, "avg_logprob": -0.30993252612174826, "compression_ratio": 1.4183673469387754, "no_speech_prob": 6.400276470230892e-05}, {"id": 188, "seek": 70656, "start": 706.56, "end": 708.76, "text": " Little difficulties.", "tokens": [8022, 14399, 13], "temperature": 0.0, "avg_logprob": -0.21909726150636752, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.429633059364278e-05}, {"id": 189, "seek": 70656, "start": 708.76, "end": 714.4399999999999, "text": " Well, go figure.", "tokens": [1042, 11, 352, 2573, 13], "temperature": 0.0, "avg_logprob": -0.21909726150636752, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.429633059364278e-05}, {"id": 190, "seek": 70656, "start": 714.4399999999999, "end": 720.56, "text": " This was working on my own machine, you know, five minutes ago, but that means nothing.", "tokens": [639, 390, 1364, 322, 452, 1065, 3479, 11, 291, 458, 11, 1732, 2077, 2057, 11, 457, 300, 1355, 1825, 13], "temperature": 0.0, "avg_logprob": -0.21909726150636752, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.429633059364278e-05}, {"id": 191, "seek": 70656, "start": 720.56, "end": 723.92, "text": " I'm going to try and press, is there like a play button or something on here?", "tokens": [286, 478, 516, 281, 853, 293, 1886, 11, 307, 456, 411, 257, 862, 2960, 420, 746, 322, 510, 30], "temperature": 0.0, "avg_logprob": -0.21909726150636752, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.429633059364278e-05}, {"id": 192, "seek": 70656, "start": 723.92, "end": 726.52, "text": " All right, I'm just going to give up.", "tokens": [1057, 558, 11, 286, 478, 445, 516, 281, 976, 493, 13], "temperature": 0.0, "avg_logprob": -0.21909726150636752, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.429633059364278e-05}, {"id": 193, "seek": 70656, "start": 726.52, "end": 731.76, "text": " So basically what this shows is how to set up your bucket in token, which I can actually", "tokens": [407, 1936, 437, 341, 3110, 307, 577, 281, 992, 493, 428, 13058, 294, 14862, 11, 597, 286, 393, 767], "temperature": 0.0, "avg_logprob": -0.21909726150636752, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.429633059364278e-05}, {"id": 194, "seek": 70656, "start": 731.76, "end": 733.28, "text": " probably just pull up.", "tokens": [1391, 445, 2235, 493, 13], "temperature": 0.0, "avg_logprob": -0.21909726150636752, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.429633059364278e-05}, {"id": 195, "seek": 70656, "start": 733.28, "end": 734.8, "text": " I'll do it at the end of this presentation.", "tokens": [286, 603, 360, 309, 412, 264, 917, 295, 341, 5860, 13], "temperature": 0.0, "avg_logprob": -0.21909726150636752, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.429633059364278e-05}, {"id": 196, "seek": 70656, "start": 734.8, "end": 736.1999999999999, "text": " We're going to do this on the fly.", "tokens": [492, 434, 516, 281, 360, 341, 322, 264, 3603, 13], "temperature": 0.0, "avg_logprob": -0.21909726150636752, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.429633059364278e-05}, {"id": 197, "seek": 73620, "start": 736.2, "end": 739.84, "text": " I'll show it at the end, but basically it just shows you in the UI how you set up your", "tokens": [286, 603, 855, 309, 412, 264, 917, 11, 457, 1936, 309, 445, 3110, 291, 294, 264, 15682, 577, 291, 992, 493, 428], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 198, "seek": 73620, "start": 739.84, "end": 741.96, "text": " bucket, which is just your database.", "tokens": [13058, 11, 597, 307, 445, 428, 8149, 13], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 199, "seek": 73620, "start": 741.96, "end": 745.12, "text": " You can pick for how long it wants to have a retention policy.", "tokens": [509, 393, 1888, 337, 577, 938, 309, 2738, 281, 362, 257, 22871, 3897, 13], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 200, "seek": 73620, "start": 745.12, "end": 746.88, "text": " That's how long you want to store the data.", "tokens": [663, 311, 577, 938, 291, 528, 281, 3531, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 201, "seek": 73620, "start": 746.88, "end": 748.76, "text": " Maybe you only want to store it for a day.", "tokens": [2704, 291, 787, 528, 281, 3531, 309, 337, 257, 786, 13], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 202, "seek": 73620, "start": 748.76, "end": 750.0400000000001, "text": " Maybe you want to store it for 30 days.", "tokens": [2704, 291, 528, 281, 3531, 309, 337, 2217, 1708, 13], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 203, "seek": 73620, "start": 750.0400000000001, "end": 751.96, "text": " You pick that at the beginning.", "tokens": [509, 1888, 300, 412, 264, 2863, 13], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 204, "seek": 73620, "start": 751.96, "end": 756.44, "text": " And then it also gives you the option to do a explicit or implicit schema.", "tokens": [400, 550, 309, 611, 2709, 291, 264, 3614, 281, 360, 257, 13691, 420, 26947, 34078, 13], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 205, "seek": 73620, "start": 756.44, "end": 761.2, "text": " And what that means is implicit just basically builds the schema off what you send us.", "tokens": [400, 437, 300, 1355, 307, 26947, 445, 1936, 15182, 264, 34078, 766, 437, 291, 2845, 505, 13], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 206, "seek": 73620, "start": 761.2, "end": 764.5200000000001, "text": " So if you start streaming in data, we'll build it for you.", "tokens": [407, 498, 291, 722, 11791, 294, 1412, 11, 321, 603, 1322, 309, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.08256045198128893, "compression_ratio": 1.8557377049180328, "no_speech_prob": 2.3913336917757988e-05}, {"id": 207, "seek": 76452, "start": 764.52, "end": 768.72, "text": " Explicit is you tell us exactly how you want your data to be formatted, and we will reject", "tokens": [2111, 4770, 270, 307, 291, 980, 505, 2293, 577, 291, 528, 428, 1412, 281, 312, 1254, 32509, 11, 293, 321, 486, 8248], "temperature": 0.0, "avg_logprob": -0.12520618856388288, "compression_ratio": 1.71875, "no_speech_prob": 1.6695275917300023e-05}, {"id": 208, "seek": 76452, "start": 768.72, "end": 771.4, "text": " any data that doesn't meet that schema.", "tokens": [604, 1412, 300, 1177, 380, 1677, 300, 34078, 13], "temperature": 0.0, "avg_logprob": -0.12520618856388288, "compression_ratio": 1.71875, "no_speech_prob": 1.6695275917300023e-05}, {"id": 209, "seek": 76452, "start": 771.4, "end": 775.36, "text": " Obviously in a project like this, which I like to call pretty low risk, like it's not", "tokens": [7580, 294, 257, 1716, 411, 341, 11, 597, 286, 411, 281, 818, 1238, 2295, 3148, 11, 411, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.12520618856388288, "compression_ratio": 1.71875, "no_speech_prob": 1.6695275917300023e-05}, {"id": 210, "seek": 76452, "start": 775.36, "end": 780.1999999999999, "text": " a big deal if the data is not quite perfect, just do the implicit, make life easy for yourself.", "tokens": [257, 955, 2028, 498, 264, 1412, 307, 406, 1596, 2176, 11, 445, 360, 264, 26947, 11, 652, 993, 1858, 337, 1803, 13], "temperature": 0.0, "avg_logprob": -0.12520618856388288, "compression_ratio": 1.71875, "no_speech_prob": 1.6695275917300023e-05}, {"id": 211, "seek": 76452, "start": 780.1999999999999, "end": 786.1999999999999, "text": " But we give explicit as for more professional projects, I suppose you could say, where it", "tokens": [583, 321, 976, 13691, 382, 337, 544, 4843, 4455, 11, 286, 7297, 291, 727, 584, 11, 689, 309], "temperature": 0.0, "avg_logprob": -0.12520618856388288, "compression_ratio": 1.71875, "no_speech_prob": 1.6695275917300023e-05}, {"id": 212, "seek": 76452, "start": 786.1999999999999, "end": 789.68, "text": " really does matter that you reject that bad schema data.", "tokens": [534, 775, 1871, 300, 291, 8248, 300, 1578, 34078, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12520618856388288, "compression_ratio": 1.71875, "no_speech_prob": 1.6695275917300023e-05}, {"id": 213, "seek": 76452, "start": 789.68, "end": 793.4399999999999, "text": " The other thing I showed is just how to make a quick token, because obviously you're going", "tokens": [440, 661, 551, 286, 4712, 307, 445, 577, 281, 652, 257, 1702, 14862, 11, 570, 2745, 291, 434, 516], "temperature": 0.0, "avg_logprob": -0.12520618856388288, "compression_ratio": 1.71875, "no_speech_prob": 1.6695275917300023e-05}, {"id": 214, "seek": 79344, "start": 793.44, "end": 798.32, "text": " to need a token to actually get your data in and back out, you need those authentications.", "tokens": [281, 643, 257, 14862, 281, 767, 483, 428, 1412, 294, 293, 646, 484, 11, 291, 643, 729, 12466, 763, 13], "temperature": 0.0, "avg_logprob": -0.1296552754134583, "compression_ratio": 1.7606557377049181, "no_speech_prob": 2.667394255695399e-05}, {"id": 215, "seek": 79344, "start": 798.32, "end": 801.6400000000001, "text": " One thing to note, we do offer a all access token.", "tokens": [1485, 551, 281, 3637, 11, 321, 360, 2626, 257, 439, 2105, 14862, 13], "temperature": 0.0, "avg_logprob": -0.1296552754134583, "compression_ratio": 1.7606557377049181, "no_speech_prob": 2.667394255695399e-05}, {"id": 216, "seek": 79344, "start": 801.6400000000001, "end": 804.8800000000001, "text": " We kind of warn against it, it even has a big warning on the screen saying, please don't", "tokens": [492, 733, 295, 12286, 1970, 309, 11, 309, 754, 575, 257, 955, 9164, 322, 264, 2568, 1566, 11, 1767, 500, 380], "temperature": 0.0, "avg_logprob": -0.1296552754134583, "compression_ratio": 1.7606557377049181, "no_speech_prob": 2.667394255695399e-05}, {"id": 217, "seek": 79344, "start": 804.8800000000001, "end": 810.36, "text": " do this, because it allows you full access to all of your buckets, all your databases,", "tokens": [360, 341, 11, 570, 309, 4045, 291, 1577, 2105, 281, 439, 295, 428, 32191, 11, 439, 428, 22380, 11], "temperature": 0.0, "avg_logprob": -0.1296552754134583, "compression_ratio": 1.7606557377049181, "no_speech_prob": 2.667394255695399e-05}, {"id": 218, "seek": 79344, "start": 810.36, "end": 812.0600000000001, "text": " and it allows you to delete them.", "tokens": [293, 309, 4045, 291, 281, 12097, 552, 13], "temperature": 0.0, "avg_logprob": -0.1296552754134583, "compression_ratio": 1.7606557377049181, "no_speech_prob": 2.667394255695399e-05}, {"id": 219, "seek": 79344, "start": 812.0600000000001, "end": 816.9200000000001, "text": " So if that tech, whenever falls into the wrong hands, or maybe you make a mistake, or your", "tokens": [407, 498, 300, 7553, 11, 5699, 8804, 666, 264, 2085, 2377, 11, 420, 1310, 291, 652, 257, 6146, 11, 420, 428], "temperature": 0.0, "avg_logprob": -0.1296552754134583, "compression_ratio": 1.7606557377049181, "no_speech_prob": 2.667394255695399e-05}, {"id": 220, "seek": 79344, "start": 816.9200000000001, "end": 822.4000000000001, "text": " coworker makes a mistake, you know, somebody else, that can obviously cause a lot of problems.", "tokens": [31998, 260, 1669, 257, 6146, 11, 291, 458, 11, 2618, 1646, 11, 300, 393, 2745, 3082, 257, 688, 295, 2740, 13], "temperature": 0.0, "avg_logprob": -0.1296552754134583, "compression_ratio": 1.7606557377049181, "no_speech_prob": 2.667394255695399e-05}, {"id": 221, "seek": 82240, "start": 822.4, "end": 826.4599999999999, "text": " We like to call it basically creating your own big red button, you don't need to do that.", "tokens": [492, 411, 281, 818, 309, 1936, 4084, 428, 1065, 955, 2182, 2960, 11, 291, 500, 380, 643, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1195649752651688, "compression_ratio": 1.6755852842809364, "no_speech_prob": 1.0284737982146908e-05}, {"id": 222, "seek": 82240, "start": 826.4599999999999, "end": 831.0799999999999, "text": " So we also give you the option to pick, write and read tokens where you specify which buckets", "tokens": [407, 321, 611, 976, 291, 264, 3614, 281, 1888, 11, 2464, 293, 1401, 22667, 689, 291, 16500, 597, 32191], "temperature": 0.0, "avg_logprob": -0.1195649752651688, "compression_ratio": 1.6755852842809364, "no_speech_prob": 1.0284737982146908e-05}, {"id": 223, "seek": 82240, "start": 831.0799999999999, "end": 832.68, "text": " you want them to have access to.", "tokens": [291, 528, 552, 281, 362, 2105, 281, 13], "temperature": 0.0, "avg_logprob": -0.1195649752651688, "compression_ratio": 1.6755852842809364, "no_speech_prob": 1.0284737982146908e-05}, {"id": 224, "seek": 82240, "start": 832.68, "end": 835.0799999999999, "text": " Again, I'll just show this a little bit later.", "tokens": [3764, 11, 286, 603, 445, 855, 341, 257, 707, 857, 1780, 13], "temperature": 0.0, "avg_logprob": -0.1195649752651688, "compression_ratio": 1.6755852842809364, "no_speech_prob": 1.0284737982146908e-05}, {"id": 225, "seek": 82240, "start": 835.0799999999999, "end": 838.84, "text": " And you can do it in the CLI as well, but normally when the video loads, the UI is a", "tokens": [400, 291, 393, 360, 309, 294, 264, 12855, 40, 382, 731, 11, 457, 5646, 562, 264, 960, 12668, 11, 264, 15682, 307, 257], "temperature": 0.0, "avg_logprob": -0.1195649752651688, "compression_ratio": 1.6755852842809364, "no_speech_prob": 1.0284737982146908e-05}, {"id": 226, "seek": 82240, "start": 838.84, "end": 842.8, "text": " little bit more fun to visually see.", "tokens": [707, 857, 544, 1019, 281, 19622, 536, 13], "temperature": 0.0, "avg_logprob": -0.1195649752651688, "compression_ratio": 1.6755852842809364, "no_speech_prob": 1.0284737982146908e-05}, {"id": 227, "seek": 82240, "start": 842.8, "end": 844.36, "text": " So let's see, there we go.", "tokens": [407, 718, 311, 536, 11, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.1195649752651688, "compression_ratio": 1.6755852842809364, "no_speech_prob": 1.0284737982146908e-05}, {"id": 228, "seek": 82240, "start": 844.36, "end": 851.0, "text": " So for this code example, it's pretty straightforward as to how to actually set this up.", "tokens": [407, 337, 341, 3089, 1365, 11, 309, 311, 1238, 15325, 382, 281, 577, 281, 767, 992, 341, 493, 13], "temperature": 0.0, "avg_logprob": -0.1195649752651688, "compression_ratio": 1.6755852842809364, "no_speech_prob": 1.0284737982146908e-05}, {"id": 229, "seek": 85100, "start": 851.0, "end": 854.52, "text": " As you can see, we have the influxdbclient.point.", "tokens": [1018, 291, 393, 536, 11, 321, 362, 264, 9922, 2449, 67, 65, 3474, 1196, 13, 6053, 13], "temperature": 0.0, "avg_logprob": -0.10616053640842438, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.18031787982909e-06}, {"id": 230, "seek": 85100, "start": 854.52, "end": 857.72, "text": " The influxdbclient is already set up in this example.", "tokens": [440, 9922, 2449, 67, 65, 3474, 1196, 307, 1217, 992, 493, 294, 341, 1365, 13], "temperature": 0.0, "avg_logprob": -0.10616053640842438, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.18031787982909e-06}, {"id": 231, "seek": 85100, "start": 857.72, "end": 861.92, "text": " Basically all you give it is your bucket and your token.", "tokens": [8537, 439, 291, 976, 309, 307, 428, 13058, 293, 428, 14862, 13], "temperature": 0.0, "avg_logprob": -0.10616053640842438, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.18031787982909e-06}, {"id": 232, "seek": 85100, "start": 861.92, "end": 867.72, "text": " You just basically say, this is where I want my data to go, and I have the authority authorization", "tokens": [509, 445, 1936, 584, 11, 341, 307, 689, 286, 528, 452, 1412, 281, 352, 11, 293, 286, 362, 264, 8281, 33697], "temperature": 0.0, "avg_logprob": -0.10616053640842438, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.18031787982909e-06}, {"id": 233, "seek": 85100, "start": 867.72, "end": 868.94, "text": " to actually do it.", "tokens": [281, 767, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.10616053640842438, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.18031787982909e-06}, {"id": 234, "seek": 85100, "start": 868.94, "end": 871.24, "text": " It's very straightforward and easy to set up.", "tokens": [467, 311, 588, 15325, 293, 1858, 281, 992, 493, 13], "temperature": 0.0, "avg_logprob": -0.10616053640842438, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.18031787982909e-06}, {"id": 235, "seek": 85100, "start": 871.24, "end": 872.92, "text": " It takes like a second.", "tokens": [467, 2516, 411, 257, 1150, 13], "temperature": 0.0, "avg_logprob": -0.10616053640842438, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.18031787982909e-06}, {"id": 236, "seek": 85100, "start": 872.92, "end": 877.24, "text": " But basically once you have all your authentication going, you can actually start sending those", "tokens": [583, 1936, 1564, 291, 362, 439, 428, 26643, 516, 11, 291, 393, 767, 722, 7750, 729], "temperature": 0.0, "avg_logprob": -0.10616053640842438, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.18031787982909e-06}, {"id": 237, "seek": 85100, "start": 877.24, "end": 879.04, "text": " points up to your database.", "tokens": [2793, 493, 281, 428, 8149, 13], "temperature": 0.0, "avg_logprob": -0.10616053640842438, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.18031787982909e-06}, {"id": 238, "seek": 87904, "start": 879.04, "end": 882.48, "text": " So with this one, we're calling the point sensor data.", "tokens": [407, 365, 341, 472, 11, 321, 434, 5141, 264, 935, 10200, 1412, 13], "temperature": 0.0, "avg_logprob": -0.16034944433914988, "compression_ratio": 1.5914396887159532, "no_speech_prob": 9.969603524950799e-06}, {"id": 239, "seek": 87904, "start": 882.48, "end": 883.88, "text": " We're setting the user.", "tokens": [492, 434, 3287, 264, 4195, 13], "temperature": 0.0, "avg_logprob": -0.16034944433914988, "compression_ratio": 1.5914396887159532, "no_speech_prob": 9.969603524950799e-06}, {"id": 240, "seek": 87904, "start": 883.88, "end": 887.8, "text": " It says it's not visually here, but it says Zoey, just as my name.", "tokens": [467, 1619, 309, 311, 406, 19622, 510, 11, 457, 309, 1619, 10337, 2030, 11, 445, 382, 452, 1315, 13], "temperature": 0.0, "avg_logprob": -0.16034944433914988, "compression_ratio": 1.5914396887159532, "no_speech_prob": 9.969603524950799e-06}, {"id": 241, "seek": 87904, "start": 887.8, "end": 890.4399999999999, "text": " It's not very special.", "tokens": [467, 311, 406, 588, 2121, 13], "temperature": 0.0, "avg_logprob": -0.16034944433914988, "compression_ratio": 1.5914396887159532, "no_speech_prob": 9.969603524950799e-06}, {"id": 242, "seek": 87904, "start": 890.4399999999999, "end": 893.76, "text": " Then we have the tag, which is the device ID.", "tokens": [1396, 321, 362, 264, 6162, 11, 597, 307, 264, 4302, 7348, 13], "temperature": 0.0, "avg_logprob": -0.16034944433914988, "compression_ratio": 1.5914396887159532, "no_speech_prob": 9.969603524950799e-06}, {"id": 243, "seek": 87904, "start": 893.76, "end": 896.36, "text": " And then finally the sensor name with the value.", "tokens": [400, 550, 2721, 264, 10200, 1315, 365, 264, 2158, 13], "temperature": 0.0, "avg_logprob": -0.16034944433914988, "compression_ratio": 1.5914396887159532, "no_speech_prob": 9.969603524950799e-06}, {"id": 244, "seek": 87904, "start": 896.36, "end": 901.52, "text": " So that's going to be something like humidity value 30.", "tokens": [407, 300, 311, 516, 281, 312, 746, 411, 24751, 2158, 2217, 13], "temperature": 0.0, "avg_logprob": -0.16034944433914988, "compression_ratio": 1.5914396887159532, "no_speech_prob": 9.969603524950799e-06}, {"id": 245, "seek": 87904, "start": 901.52, "end": 906.04, "text": " And basically from this, this is running in a Python file script that just is pretty much", "tokens": [400, 1936, 490, 341, 11, 341, 307, 2614, 294, 257, 15329, 3991, 5755, 300, 445, 307, 1238, 709], "temperature": 0.0, "avg_logprob": -0.16034944433914988, "compression_ratio": 1.5914396887159532, "no_speech_prob": 9.969603524950799e-06}, {"id": 246, "seek": 90604, "start": 906.04, "end": 912.28, "text": " running as long as we're getting data.", "tokens": [2614, 382, 938, 382, 321, 434, 1242, 1412, 13], "temperature": 0.0, "avg_logprob": -0.13254017013687272, "compression_ratio": 1.7261410788381744, "no_speech_prob": 2.5456603907514364e-05}, {"id": 247, "seek": 90604, "start": 912.28, "end": 915.1999999999999, "text": " But basically this is a straightforward way to get it in.", "tokens": [583, 1936, 341, 307, 257, 15325, 636, 281, 483, 309, 294, 13], "temperature": 0.0, "avg_logprob": -0.13254017013687272, "compression_ratio": 1.7261410788381744, "no_speech_prob": 2.5456603907514364e-05}, {"id": 248, "seek": 90604, "start": 915.1999999999999, "end": 919.28, "text": " And this is using the Python client library.", "tokens": [400, 341, 307, 1228, 264, 15329, 6423, 6405, 13], "temperature": 0.0, "avg_logprob": -0.13254017013687272, "compression_ratio": 1.7261410788381744, "no_speech_prob": 2.5456603907514364e-05}, {"id": 249, "seek": 90604, "start": 919.28, "end": 922.12, "text": " This is part of the Telegraph config file.", "tokens": [639, 307, 644, 295, 264, 1989, 6363, 2662, 6662, 3991, 13], "temperature": 0.0, "avg_logprob": -0.13254017013687272, "compression_ratio": 1.7261410788381744, "no_speech_prob": 2.5456603907514364e-05}, {"id": 250, "seek": 90604, "start": 922.12, "end": 927.12, "text": " This file has like, it's computer generated, so you don't need to write 200 lines of code,", "tokens": [639, 3991, 575, 411, 11, 309, 311, 3820, 10833, 11, 370, 291, 500, 380, 643, 281, 2464, 2331, 3876, 295, 3089, 11], "temperature": 0.0, "avg_logprob": -0.13254017013687272, "compression_ratio": 1.7261410788381744, "no_speech_prob": 2.5456603907514364e-05}, {"id": 251, "seek": 90604, "start": 927.12, "end": 930.4399999999999, "text": " but the actual config file is like 200 lines of code.", "tokens": [457, 264, 3539, 6662, 3991, 307, 411, 2331, 3876, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.13254017013687272, "compression_ratio": 1.7261410788381744, "no_speech_prob": 2.5456603907514364e-05}, {"id": 252, "seek": 90604, "start": 930.4399999999999, "end": 934.5999999999999, "text": " This is just a small snippet at the end of it that basically says that we're using the", "tokens": [639, 307, 445, 257, 1359, 35623, 302, 412, 264, 917, 295, 309, 300, 1936, 1619, 300, 321, 434, 1228, 264], "temperature": 0.0, "avg_logprob": -0.13254017013687272, "compression_ratio": 1.7261410788381744, "no_speech_prob": 2.5456603907514364e-05}, {"id": 253, "seek": 93460, "start": 934.6, "end": 938.2, "text": " execd processor plugin.", "tokens": [4454, 67, 15321, 23407, 13], "temperature": 0.0, "avg_logprob": -0.15601034462451935, "compression_ratio": 1.6506410256410255, "no_speech_prob": 2.5053985154954717e-05}, {"id": 254, "seek": 93460, "start": 938.2, "end": 942.24, "text": " And from here, we're just telling it what measurements and what tagged keys to accept.", "tokens": [400, 490, 510, 11, 321, 434, 445, 3585, 309, 437, 15383, 293, 437, 40239, 9317, 281, 3241, 13], "temperature": 0.0, "avg_logprob": -0.15601034462451935, "compression_ratio": 1.6506410256410255, "no_speech_prob": 2.5053985154954717e-05}, {"id": 255, "seek": 93460, "start": 942.24, "end": 945.88, "text": " Again, inside of the GitHub project, we kind of go a little bit more in depth.", "tokens": [3764, 11, 1854, 295, 264, 23331, 1716, 11, 321, 733, 295, 352, 257, 707, 857, 544, 294, 7161, 13], "temperature": 0.0, "avg_logprob": -0.15601034462451935, "compression_ratio": 1.6506410256410255, "no_speech_prob": 2.5053985154954717e-05}, {"id": 256, "seek": 93460, "start": 945.88, "end": 951.08, "text": " But the big thing is that every Telegraph config file and instructions are slightly different.", "tokens": [583, 264, 955, 551, 307, 300, 633, 1989, 6363, 2662, 6662, 3991, 293, 9415, 366, 4748, 819, 13], "temperature": 0.0, "avg_logprob": -0.15601034462451935, "compression_ratio": 1.6506410256410255, "no_speech_prob": 2.5053985154954717e-05}, {"id": 257, "seek": 93460, "start": 951.08, "end": 955.36, "text": " So there's no necessary reason for me to show you the execd one when you could be using", "tokens": [407, 456, 311, 572, 4818, 1778, 337, 385, 281, 855, 291, 264, 4454, 67, 472, 562, 291, 727, 312, 1228], "temperature": 0.0, "avg_logprob": -0.15601034462451935, "compression_ratio": 1.6506410256410255, "no_speech_prob": 2.5053985154954717e-05}, {"id": 258, "seek": 93460, "start": 955.36, "end": 957.32, "text": " a different one for your own project.", "tokens": [257, 819, 472, 337, 428, 1065, 1716, 13], "temperature": 0.0, "avg_logprob": -0.15601034462451935, "compression_ratio": 1.6506410256410255, "no_speech_prob": 2.5053985154954717e-05}, {"id": 259, "seek": 93460, "start": 957.32, "end": 960.28, "text": " But basically, just follow the documentations for this.", "tokens": [583, 1936, 11, 445, 1524, 264, 4166, 763, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.15601034462451935, "compression_ratio": 1.6506410256410255, "no_speech_prob": 2.5053985154954717e-05}, {"id": 260, "seek": 93460, "start": 960.28, "end": 962.84, "text": " It's super simple and it's very well documented.", "tokens": [467, 311, 1687, 2199, 293, 309, 311, 588, 731, 23007, 13], "temperature": 0.0, "avg_logprob": -0.15601034462451935, "compression_ratio": 1.6506410256410255, "no_speech_prob": 2.5053985154954717e-05}, {"id": 261, "seek": 96284, "start": 962.84, "end": 965.4, "text": " Well, I guess I shouldn't say that since it's open source.", "tokens": [1042, 11, 286, 2041, 286, 4659, 380, 584, 300, 1670, 309, 311, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.11864340566370608, "compression_ratio": 1.6808510638297873, "no_speech_prob": 2.2119387722341344e-05}, {"id": 262, "seek": 96284, "start": 965.4, "end": 969.6, "text": " So some of them are less well documented, but most of them are great.", "tokens": [407, 512, 295, 552, 366, 1570, 731, 23007, 11, 457, 881, 295, 552, 366, 869, 13], "temperature": 0.0, "avg_logprob": -0.11864340566370608, "compression_ratio": 1.6808510638297873, "no_speech_prob": 2.2119387722341344e-05}, {"id": 263, "seek": 96284, "start": 969.6, "end": 972.6800000000001, "text": " And this is a table example of the resulting data points.", "tokens": [400, 341, 307, 257, 3199, 1365, 295, 264, 16505, 1412, 2793, 13], "temperature": 0.0, "avg_logprob": -0.11864340566370608, "compression_ratio": 1.6808510638297873, "no_speech_prob": 2.2119387722341344e-05}, {"id": 264, "seek": 96284, "start": 972.6800000000001, "end": 977.9200000000001, "text": " So as you can see, we have our sensor data with a field of, but this one we have a light", "tokens": [407, 382, 291, 393, 536, 11, 321, 362, 527, 10200, 1412, 365, 257, 2519, 295, 11, 457, 341, 472, 321, 362, 257, 1442], "temperature": 0.0, "avg_logprob": -0.11864340566370608, "compression_ratio": 1.6808510638297873, "no_speech_prob": 2.2119387722341344e-05}, {"id": 265, "seek": 96284, "start": 977.9200000000001, "end": 979.2800000000001, "text": " and soil moisture.", "tokens": [293, 6704, 13814, 13], "temperature": 0.0, "avg_logprob": -0.11864340566370608, "compression_ratio": 1.6808510638297873, "no_speech_prob": 2.2119387722341344e-05}, {"id": 266, "seek": 96284, "start": 979.2800000000001, "end": 981.12, "text": " We have our value.", "tokens": [492, 362, 527, 2158, 13], "temperature": 0.0, "avg_logprob": -0.11864340566370608, "compression_ratio": 1.6808510638297873, "no_speech_prob": 2.2119387722341344e-05}, {"id": 267, "seek": 96284, "start": 981.12, "end": 985.08, "text": " And as I told you before, the values kind of come in a little bit weird.", "tokens": [400, 382, 286, 1907, 291, 949, 11, 264, 4190, 733, 295, 808, 294, 257, 707, 857, 3657, 13], "temperature": 0.0, "avg_logprob": -0.11864340566370608, "compression_ratio": 1.6808510638297873, "no_speech_prob": 2.2119387722341344e-05}, {"id": 268, "seek": 96284, "start": 985.08, "end": 991.6, "text": " I don't know how soil moisture can be 1,372 point, many zeros and fives, but it can be.", "tokens": [286, 500, 380, 458, 577, 6704, 13814, 393, 312, 502, 11, 12851, 17, 935, 11, 867, 35193, 293, 283, 1539, 11, 457, 309, 393, 312, 13], "temperature": 0.0, "avg_logprob": -0.11864340566370608, "compression_ratio": 1.6808510638297873, "no_speech_prob": 2.2119387722341344e-05}, {"id": 269, "seek": 99160, "start": 991.6, "end": 995.64, "text": " And then finally, the actual timestamp value, which says that obviously this value was from", "tokens": [400, 550, 2721, 11, 264, 3539, 49108, 1215, 2158, 11, 597, 1619, 300, 2745, 341, 2158, 390, 490], "temperature": 0.0, "avg_logprob": -0.1532327684305482, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.56789792526979e-05}, {"id": 270, "seek": 99160, "start": 995.64, "end": 1004.6, "text": " last year in like, I can't even think September, August, sometime in the early fall.", "tokens": [1036, 1064, 294, 411, 11, 286, 393, 380, 754, 519, 7216, 11, 6897, 11, 15053, 294, 264, 2440, 2100, 13], "temperature": 0.0, "avg_logprob": -0.1532327684305482, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.56789792526979e-05}, {"id": 271, "seek": 99160, "start": 1004.6, "end": 1006.0400000000001, "text": " So flux and sequel.", "tokens": [407, 19298, 293, 20622, 13], "temperature": 0.0, "avg_logprob": -0.1532327684305482, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.56789792526979e-05}, {"id": 272, "seek": 99160, "start": 1006.0400000000001, "end": 1009.44, "text": " So I've said this word before and I haven't really explained it.", "tokens": [407, 286, 600, 848, 341, 1349, 949, 293, 286, 2378, 380, 534, 8825, 309, 13], "temperature": 0.0, "avg_logprob": -0.1532327684305482, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.56789792526979e-05}, {"id": 273, "seek": 99160, "start": 1009.44, "end": 1013.96, "text": " But basically what flux is, is it is the querying language of influx DB.", "tokens": [583, 1936, 437, 19298, 307, 11, 307, 309, 307, 264, 7083, 1840, 2856, 295, 9922, 2449, 26754, 13], "temperature": 0.0, "avg_logprob": -0.1532327684305482, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.56789792526979e-05}, {"id": 274, "seek": 99160, "start": 1013.96, "end": 1017.9200000000001, "text": " So basically what it allows you to do is query for your time series data.", "tokens": [407, 1936, 437, 309, 4045, 291, 281, 360, 307, 14581, 337, 428, 565, 2638, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1532327684305482, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.56789792526979e-05}, {"id": 275, "seek": 99160, "start": 1017.9200000000001, "end": 1020.36, "text": " It can do a lot of really awesome things.", "tokens": [467, 393, 360, 257, 688, 295, 534, 3476, 721, 13], "temperature": 0.0, "avg_logprob": -0.1532327684305482, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.56789792526979e-05}, {"id": 276, "seek": 102036, "start": 1020.36, "end": 1025.0, "text": " It can do things like the alerts, the management, but for right now we're just going to focus", "tokens": [467, 393, 360, 721, 411, 264, 28061, 11, 264, 4592, 11, 457, 337, 558, 586, 321, 434, 445, 516, 281, 1879], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 277, "seek": 102036, "start": 1025.0, "end": 1028.48, "text": " on the querying because that's the most straightforward thing and that's the main thing that you're", "tokens": [322, 264, 7083, 1840, 570, 300, 311, 264, 881, 15325, 551, 293, 300, 311, 264, 2135, 551, 300, 291, 434], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 278, "seek": 102036, "start": 1028.48, "end": 1029.88, "text": " going to end up doing.", "tokens": [516, 281, 917, 493, 884, 13], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 279, "seek": 102036, "start": 1029.88, "end": 1035.68, "text": " So in this versioning right here, basically what it's saying is from bucket, which again", "tokens": [407, 294, 341, 3037, 278, 558, 510, 11, 1936, 437, 309, 311, 1566, 307, 490, 13058, 11, 597, 797], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 280, "seek": 102036, "start": 1035.68, "end": 1037.32, "text": " is just from database.", "tokens": [307, 445, 490, 8149, 13], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 281, "seek": 102036, "start": 1037.32, "end": 1039.32, "text": " Go ahead and give me smart city.", "tokens": [1037, 2286, 293, 976, 385, 4069, 2307, 13], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 282, "seek": 102036, "start": 1039.32, "end": 1040.32, "text": " Give me the range.", "tokens": [5303, 385, 264, 3613, 13], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 283, "seek": 102036, "start": 1040.32, "end": 1041.32, "text": " This is a range of one day.", "tokens": [639, 307, 257, 3613, 295, 472, 786, 13], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 284, "seek": 102036, "start": 1041.32, "end": 1043.3600000000001, "text": " It's got to start and a stop.", "tokens": [467, 311, 658, 281, 722, 293, 257, 1590, 13], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 285, "seek": 102036, "start": 1043.3600000000001, "end": 1044.76, "text": " You do not have to give it a range.", "tokens": [509, 360, 406, 362, 281, 976, 309, 257, 3613, 13], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 286, "seek": 102036, "start": 1044.76, "end": 1047.76, "text": " You could literally just do from bucket, give me everything.", "tokens": [509, 727, 3736, 445, 360, 490, 13058, 11, 976, 385, 1203, 13], "temperature": 0.0, "avg_logprob": -0.11173786760187474, "compression_ratio": 1.7953020134228188, "no_speech_prob": 1.951944977918174e-05}, {"id": 287, "seek": 104776, "start": 1047.76, "end": 1052.0, "text": " You normally suggest you try to use a range because obviously, I mean if your bucket only", "tokens": [509, 5646, 3402, 291, 853, 281, 764, 257, 3613, 570, 2745, 11, 286, 914, 498, 428, 13058, 787], "temperature": 0.0, "avg_logprob": -0.1111385054507498, "compression_ratio": 1.7228464419475655, "no_speech_prob": 1.0609060154820327e-05}, {"id": 288, "seek": 104776, "start": 1052.0, "end": 1056.32, "text": " has like one day of data, it's probably not a big deal, but if it has the past three years", "tokens": [575, 411, 472, 786, 295, 1412, 11, 309, 311, 1391, 406, 257, 955, 2028, 11, 457, 498, 309, 575, 264, 1791, 1045, 924], "temperature": 0.0, "avg_logprob": -0.1111385054507498, "compression_ratio": 1.7228464419475655, "no_speech_prob": 1.0609060154820327e-05}, {"id": 289, "seek": 104776, "start": 1056.32, "end": 1063.0, "text": " of data, that's going to be a while to come in and that's going to probably crash a lot.", "tokens": [295, 1412, 11, 300, 311, 516, 281, 312, 257, 1339, 281, 808, 294, 293, 300, 311, 516, 281, 1391, 8252, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.1111385054507498, "compression_ratio": 1.7228464419475655, "no_speech_prob": 1.0609060154820327e-05}, {"id": 290, "seek": 104776, "start": 1063.0, "end": 1064.52, "text": " And then you have your filters.", "tokens": [400, 550, 291, 362, 428, 15995, 13], "temperature": 0.0, "avg_logprob": -0.1111385054507498, "compression_ratio": 1.7228464419475655, "no_speech_prob": 1.0609060154820327e-05}, {"id": 291, "seek": 104776, "start": 1064.52, "end": 1070.2, "text": " So with this one, what they're saying in more human terms is they're saying give me all", "tokens": [407, 365, 341, 472, 11, 437, 436, 434, 1566, 294, 544, 1952, 2115, 307, 436, 434, 1566, 976, 385, 439], "temperature": 0.0, "avg_logprob": -0.1111385054507498, "compression_ratio": 1.7228464419475655, "no_speech_prob": 1.0609060154820327e-05}, {"id": 292, "seek": 104776, "start": 1070.2, "end": 1074.12, "text": " the bicycles that have come through with the neighborhood ID of three.", "tokens": [264, 47913, 300, 362, 808, 807, 365, 264, 7630, 7348, 295, 1045, 13], "temperature": 0.0, "avg_logprob": -0.1111385054507498, "compression_ratio": 1.7228464419475655, "no_speech_prob": 1.0609060154820327e-05}, {"id": 293, "seek": 107412, "start": 1074.12, "end": 1078.2399999999998, "text": " And what they're doing down here at this aggregate window is they're saying give me the mean for", "tokens": [400, 437, 436, 434, 884, 760, 510, 412, 341, 26118, 4910, 307, 436, 434, 1566, 976, 385, 264, 914, 337], "temperature": 0.0, "avg_logprob": -0.0732857808470726, "compression_ratio": 1.7805755395683454, "no_speech_prob": 9.512389624433126e-06}, {"id": 294, "seek": 107412, "start": 1078.2399999999998, "end": 1079.76, "text": " every one hour.", "tokens": [633, 472, 1773, 13], "temperature": 0.0, "avg_logprob": -0.0732857808470726, "compression_ratio": 1.7805755395683454, "no_speech_prob": 9.512389624433126e-06}, {"id": 295, "seek": 107412, "start": 1079.76, "end": 1085.04, "text": " So because this is one day, this is a one day range, this will return 24 data points.", "tokens": [407, 570, 341, 307, 472, 786, 11, 341, 307, 257, 472, 786, 3613, 11, 341, 486, 2736, 4022, 1412, 2793, 13], "temperature": 0.0, "avg_logprob": -0.0732857808470726, "compression_ratio": 1.7805755395683454, "no_speech_prob": 9.512389624433126e-06}, {"id": 296, "seek": 107412, "start": 1085.04, "end": 1089.8, "text": " It will give you the mean amount of bikes that came through every hour in this neighborhood", "tokens": [467, 486, 976, 291, 264, 914, 2372, 295, 16035, 300, 1361, 807, 633, 1773, 294, 341, 7630], "temperature": 0.0, "avg_logprob": -0.0732857808470726, "compression_ratio": 1.7805755395683454, "no_speech_prob": 9.512389624433126e-06}, {"id": 297, "seek": 107412, "start": 1089.8, "end": 1091.6399999999999, "text": " with the ID of three.", "tokens": [365, 264, 7348, 295, 1045, 13], "temperature": 0.0, "avg_logprob": -0.0732857808470726, "compression_ratio": 1.7805755395683454, "no_speech_prob": 9.512389624433126e-06}, {"id": 298, "seek": 107412, "start": 1091.6399999999999, "end": 1095.4399999999998, "text": " And the one below it is doing the exact same, but it's doing it for the ID neighborhood", "tokens": [400, 264, 472, 2507, 309, 307, 884, 264, 1900, 912, 11, 457, 309, 311, 884, 309, 337, 264, 7348, 7630], "temperature": 0.0, "avg_logprob": -0.0732857808470726, "compression_ratio": 1.7805755395683454, "no_speech_prob": 9.512389624433126e-06}, {"id": 299, "seek": 107412, "start": 1095.4399999999998, "end": 1096.6399999999999, "text": " of four.", "tokens": [295, 1451, 13], "temperature": 0.0, "avg_logprob": -0.0732857808470726, "compression_ratio": 1.7805755395683454, "no_speech_prob": 9.512389624433126e-06}, {"id": 300, "seek": 107412, "start": 1096.6399999999999, "end": 1102.4399999999998, "text": " And then finally at the end, it's comparing them and it's getting a difference value.", "tokens": [400, 550, 2721, 412, 264, 917, 11, 309, 311, 15763, 552, 293, 309, 311, 1242, 257, 2649, 2158, 13], "temperature": 0.0, "avg_logprob": -0.0732857808470726, "compression_ratio": 1.7805755395683454, "no_speech_prob": 9.512389624433126e-06}, {"id": 301, "seek": 110244, "start": 1102.44, "end": 1106.4, "text": " It's saying how many more bikes go through neighborhood three versus neighborhood four", "tokens": [467, 311, 1566, 577, 867, 544, 16035, 352, 807, 7630, 1045, 5717, 7630, 1451], "temperature": 0.0, "avg_logprob": -0.10362894143631209, "compression_ratio": 1.657492354740061, "no_speech_prob": 6.010117431287654e-05}, {"id": 302, "seek": 110244, "start": 1106.4, "end": 1108.3600000000001, "text": " or vice versa.", "tokens": [420, 11964, 25650, 13], "temperature": 0.0, "avg_logprob": -0.10362894143631209, "compression_ratio": 1.657492354740061, "no_speech_prob": 6.010117431287654e-05}, {"id": 303, "seek": 110244, "start": 1108.3600000000001, "end": 1111.96, "text": " And so that's just one of the quick queries that you can do.", "tokens": [400, 370, 300, 311, 445, 472, 295, 264, 1702, 24109, 300, 291, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.10362894143631209, "compression_ratio": 1.657492354740061, "no_speech_prob": 6.010117431287654e-05}, {"id": 304, "seek": 110244, "start": 1111.96, "end": 1116.3600000000001, "text": " The aggregate window is super great, especially for a project like this where you may be,", "tokens": [440, 26118, 4910, 307, 1687, 869, 11, 2318, 337, 257, 1716, 411, 341, 689, 291, 815, 312, 11], "temperature": 0.0, "avg_logprob": -0.10362894143631209, "compression_ratio": 1.657492354740061, "no_speech_prob": 6.010117431287654e-05}, {"id": 305, "seek": 110244, "start": 1116.3600000000001, "end": 1121.8, "text": " although your IoT sensors will send you data every single nanosecond, let's get real here.", "tokens": [4878, 428, 30112, 14840, 486, 2845, 291, 1412, 633, 2167, 14067, 541, 18882, 11, 718, 311, 483, 957, 510, 13], "temperature": 0.0, "avg_logprob": -0.10362894143631209, "compression_ratio": 1.657492354740061, "no_speech_prob": 6.010117431287654e-05}, {"id": 306, "seek": 110244, "start": 1121.8, "end": 1125.0, "text": " Your plant, you don't need to know exactly what was happening to it.", "tokens": [2260, 3709, 11, 291, 500, 380, 643, 281, 458, 2293, 437, 390, 2737, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.10362894143631209, "compression_ratio": 1.657492354740061, "no_speech_prob": 6.010117431287654e-05}, {"id": 307, "seek": 110244, "start": 1125.0, "end": 1128.96, "text": " It's better to just get an average of how thirsty it is or average amount of light.", "tokens": [467, 311, 1101, 281, 445, 483, 364, 4274, 295, 577, 28115, 309, 307, 420, 4274, 2372, 295, 1442, 13], "temperature": 0.0, "avg_logprob": -0.10362894143631209, "compression_ratio": 1.657492354740061, "no_speech_prob": 6.010117431287654e-05}, {"id": 308, "seek": 110244, "start": 1128.96, "end": 1131.16, "text": " You could bring it down even to five minutes.", "tokens": [509, 727, 1565, 309, 760, 754, 281, 1732, 2077, 13], "temperature": 0.0, "avg_logprob": -0.10362894143631209, "compression_ratio": 1.657492354740061, "no_speech_prob": 6.010117431287654e-05}, {"id": 309, "seek": 113116, "start": 1131.16, "end": 1134.24, "text": " Like it does not need to be quite as in depth.", "tokens": [1743, 309, 775, 406, 643, 281, 312, 1596, 382, 294, 7161, 13], "temperature": 0.0, "avg_logprob": -0.09157693611001069, "compression_ratio": 1.6165413533834587, "no_speech_prob": 4.6793156798230484e-05}, {"id": 310, "seek": 113116, "start": 1134.24, "end": 1137.44, "text": " And even for this one, they just wanted to know the mean amount of bikes that were coming", "tokens": [400, 754, 337, 341, 472, 11, 436, 445, 1415, 281, 458, 264, 914, 2372, 295, 16035, 300, 645, 1348], "temperature": 0.0, "avg_logprob": -0.09157693611001069, "compression_ratio": 1.6165413533834587, "no_speech_prob": 4.6793156798230484e-05}, {"id": 311, "seek": 113116, "start": 1137.44, "end": 1142.16, "text": " through the city in these neighborhoods.", "tokens": [807, 264, 2307, 294, 613, 20052, 13], "temperature": 0.0, "avg_logprob": -0.09157693611001069, "compression_ratio": 1.6165413533834587, "no_speech_prob": 4.6793156798230484e-05}, {"id": 312, "seek": 113116, "start": 1142.16, "end": 1144.3200000000002, "text": " This is how it actually looks like in our project.", "tokens": [639, 307, 577, 309, 767, 1542, 411, 294, 527, 1716, 13], "temperature": 0.0, "avg_logprob": -0.09157693611001069, "compression_ratio": 1.6165413533834587, "no_speech_prob": 4.6793156798230484e-05}, {"id": 313, "seek": 113116, "start": 1144.3200000000002, "end": 1148.88, "text": " So the reason that you're seeing all these empty brackets is this is a reusable query.", "tokens": [407, 264, 1778, 300, 291, 434, 2577, 439, 613, 6707, 26179, 307, 341, 307, 257, 41807, 14581, 13], "temperature": 0.0, "avg_logprob": -0.09157693611001069, "compression_ratio": 1.6165413533834587, "no_speech_prob": 4.6793156798230484e-05}, {"id": 314, "seek": 113116, "start": 1148.88, "end": 1154.3600000000001, "text": " So we can say from different types of plant buddy buckets, or we can say different device", "tokens": [407, 321, 393, 584, 490, 819, 3467, 295, 3709, 10340, 32191, 11, 420, 321, 393, 584, 819, 4302], "temperature": 0.0, "avg_logprob": -0.09157693611001069, "compression_ratio": 1.6165413533834587, "no_speech_prob": 4.6793156798230484e-05}, {"id": 315, "seek": 113116, "start": 1154.3600000000001, "end": 1156.8400000000001, "text": " IDs or different fields.", "tokens": [48212, 420, 819, 7909, 13], "temperature": 0.0, "avg_logprob": -0.09157693611001069, "compression_ratio": 1.6165413533834587, "no_speech_prob": 4.6793156798230484e-05}, {"id": 316, "seek": 115684, "start": 1156.84, "end": 1164.36, "text": " So again, the field is going to be things like the humidity, the temperature, the moisture.", "tokens": [407, 797, 11, 264, 2519, 307, 516, 281, 312, 721, 411, 264, 24751, 11, 264, 4292, 11, 264, 13814, 13], "temperature": 0.0, "avg_logprob": -0.10799806014351222, "compression_ratio": 1.6130434782608696, "no_speech_prob": 1.2795018847100437e-05}, {"id": 317, "seek": 115684, "start": 1164.36, "end": 1168.24, "text": " And device ID, I actually, for my project at least, it's always the same because I only", "tokens": [400, 4302, 7348, 11, 286, 767, 11, 337, 452, 1716, 412, 1935, 11, 309, 311, 1009, 264, 912, 570, 286, 787], "temperature": 0.0, "avg_logprob": -0.10799806014351222, "compression_ratio": 1.6130434782608696, "no_speech_prob": 1.2795018847100437e-05}, {"id": 318, "seek": 115684, "start": 1168.24, "end": 1170.28, "text": " have one setup.", "tokens": [362, 472, 8657, 13], "temperature": 0.0, "avg_logprob": -0.10799806014351222, "compression_ratio": 1.6130434782608696, "no_speech_prob": 1.2795018847100437e-05}, {"id": 319, "seek": 115684, "start": 1170.28, "end": 1174.52, "text": " But if I had multiple plants with multiple values, I would have the device ID basically", "tokens": [583, 498, 286, 632, 3866, 5972, 365, 3866, 4190, 11, 286, 576, 362, 264, 4302, 7348, 1936], "temperature": 0.0, "avg_logprob": -0.10799806014351222, "compression_ratio": 1.6130434782608696, "no_speech_prob": 1.2795018847100437e-05}, {"id": 320, "seek": 115684, "start": 1174.52, "end": 1180.56, "text": " being probably really the plant names, but I could say like Arduino one or Arduino two.", "tokens": [885, 1391, 534, 264, 3709, 5288, 11, 457, 286, 727, 584, 411, 39539, 472, 420, 39539, 732, 13], "temperature": 0.0, "avg_logprob": -0.10799806014351222, "compression_ratio": 1.6130434782608696, "no_speech_prob": 1.2795018847100437e-05}, {"id": 321, "seek": 118056, "start": 1180.56, "end": 1188.3999999999999, "text": " But for this project, it's relatively smaller, so it's just easier.", "tokens": [583, 337, 341, 1716, 11, 309, 311, 7226, 4356, 11, 370, 309, 311, 445, 3571, 13], "temperature": 0.0, "avg_logprob": -0.11344806079206796, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.709779204858933e-06}, {"id": 322, "seek": 118056, "start": 1188.3999999999999, "end": 1191.6799999999998, "text": " So change is here.", "tokens": [407, 1319, 307, 510, 13], "temperature": 0.0, "avg_logprob": -0.11344806079206796, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.709779204858933e-06}, {"id": 323, "seek": 118056, "start": 1191.6799999999998, "end": 1196.08, "text": " So this doesn't really matter if you decide to do this project all in the open source.", "tokens": [407, 341, 1177, 380, 534, 1871, 498, 291, 4536, 281, 360, 341, 1716, 439, 294, 264, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.11344806079206796, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.709779204858933e-06}, {"id": 324, "seek": 118056, "start": 1196.08, "end": 1198.44, "text": " It won't matter really for you for a while.", "tokens": [467, 1582, 380, 1871, 534, 337, 291, 337, 257, 1339, 13], "temperature": 0.0, "avg_logprob": -0.11344806079206796, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.709779204858933e-06}, {"id": 325, "seek": 118056, "start": 1198.44, "end": 1203.28, "text": " But one thing to note is if you do choose to do edge data replication, Influx CB cloud", "tokens": [583, 472, 551, 281, 3637, 307, 498, 291, 360, 2826, 281, 360, 4691, 1412, 39911, 11, 682, 3423, 2449, 18745, 4588], "temperature": 0.0, "avg_logprob": -0.11344806079206796, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.709779204858933e-06}, {"id": 326, "seek": 118056, "start": 1203.28, "end": 1205.28, "text": " is now going to be allowing SQL.", "tokens": [307, 586, 516, 281, 312, 8293, 19200, 13], "temperature": 0.0, "avg_logprob": -0.11344806079206796, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.709779204858933e-06}, {"id": 327, "seek": 118056, "start": 1205.28, "end": 1210.32, "text": " So you're going to be able to query your data back out using SQL instead of Flux.", "tokens": [407, 291, 434, 516, 281, 312, 1075, 281, 14581, 428, 1412, 646, 484, 1228, 19200, 2602, 295, 3235, 2449, 13], "temperature": 0.0, "avg_logprob": -0.11344806079206796, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.709779204858933e-06}, {"id": 328, "seek": 121032, "start": 1210.32, "end": 1213.96, "text": " And we're also going to be supporting flight SQL plug-ins, which will allow you to connect", "tokens": [400, 321, 434, 611, 516, 281, 312, 7231, 7018, 19200, 5452, 12, 1292, 11, 597, 486, 2089, 291, 281, 1745], "temperature": 0.0, "avg_logprob": -0.18326780531141493, "compression_ratio": 1.5348837209302326, "no_speech_prob": 1.833205715229269e-05}, {"id": 329, "seek": 121032, "start": 1213.96, "end": 1217.48, "text": " to things like Apache superset and Grafana.", "tokens": [281, 721, 411, 46597, 37906, 302, 293, 8985, 69, 2095, 13], "temperature": 0.0, "avg_logprob": -0.18326780531141493, "compression_ratio": 1.5348837209302326, "no_speech_prob": 1.833205715229269e-05}, {"id": 330, "seek": 121032, "start": 1217.48, "end": 1221.24, "text": " I'm obviously going to be showing plot leaf for this one, but these are going to be options", "tokens": [286, 478, 2745, 516, 281, 312, 4099, 7542, 10871, 337, 341, 472, 11, 457, 613, 366, 516, 281, 312, 3956], "temperature": 0.0, "avg_logprob": -0.18326780531141493, "compression_ratio": 1.5348837209302326, "no_speech_prob": 1.833205715229269e-05}, {"id": 331, "seek": 121032, "start": 1221.24, "end": 1222.48, "text": " for you in the future.", "tokens": [337, 291, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.18326780531141493, "compression_ratio": 1.5348837209302326, "no_speech_prob": 1.833205715229269e-05}, {"id": 332, "seek": 121032, "start": 1222.48, "end": 1226.08, "text": " So it's just something to keep in mind.", "tokens": [407, 309, 311, 445, 746, 281, 1066, 294, 1575, 13], "temperature": 0.0, "avg_logprob": -0.18326780531141493, "compression_ratio": 1.5348837209302326, "no_speech_prob": 1.833205715229269e-05}, {"id": 333, "seek": 121032, "start": 1226.08, "end": 1229.8799999999999, "text": " So let's get into edge data replication.", "tokens": [407, 718, 311, 483, 666, 4691, 1412, 39911, 13], "temperature": 0.0, "avg_logprob": -0.18326780531141493, "compression_ratio": 1.5348837209302326, "no_speech_prob": 1.833205715229269e-05}, {"id": 334, "seek": 122988, "start": 1229.88, "end": 1247.44, "text": " I'm going to leave this up for just one sec.", "tokens": [286, 478, 516, 281, 1856, 341, 493, 337, 445, 472, 907, 13], "temperature": 0.0, "avg_logprob": -0.07233876808016908, "compression_ratio": 1.393103448275862, "no_speech_prob": 6.707233842462301e-05}, {"id": 335, "seek": 122988, "start": 1247.44, "end": 1253.2, "text": " So normally when I say edge data replication, people kind of think of varying things depending", "tokens": [407, 5646, 562, 286, 584, 4691, 1412, 39911, 11, 561, 733, 295, 519, 295, 22984, 721, 5413], "temperature": 0.0, "avg_logprob": -0.07233876808016908, "compression_ratio": 1.393103448275862, "no_speech_prob": 6.707233842462301e-05}, {"id": 336, "seek": 122988, "start": 1253.2, "end": 1257.3200000000002, "text": " on your job or depending on where you've heard it said before.", "tokens": [322, 428, 1691, 420, 5413, 322, 689, 291, 600, 2198, 309, 848, 949, 13], "temperature": 0.0, "avg_logprob": -0.07233876808016908, "compression_ratio": 1.393103448275862, "no_speech_prob": 6.707233842462301e-05}, {"id": 337, "seek": 125732, "start": 1257.32, "end": 1262.28, "text": " Some people think of a solar panel in the middle of nowhere in the woods.", "tokens": [2188, 561, 519, 295, 257, 7936, 4831, 294, 264, 2808, 295, 11159, 294, 264, 15296, 13], "temperature": 0.0, "avg_logprob": -0.09004780602833581, "compression_ratio": 1.7112676056338028, "no_speech_prob": 2.839352237060666e-05}, {"id": 338, "seek": 125732, "start": 1262.28, "end": 1267.28, "text": " That's the edge device because it's, I don't know, at the edge of civilization basically.", "tokens": [663, 311, 264, 4691, 4302, 570, 309, 311, 11, 286, 500, 380, 458, 11, 412, 264, 4691, 295, 18036, 1936, 13], "temperature": 0.0, "avg_logprob": -0.09004780602833581, "compression_ratio": 1.7112676056338028, "no_speech_prob": 2.839352237060666e-05}, {"id": 339, "seek": 125732, "start": 1267.28, "end": 1270.56, "text": " But an edge device can be something as simple as a cell phone.", "tokens": [583, 364, 4691, 4302, 393, 312, 746, 382, 2199, 382, 257, 2815, 2593, 13], "temperature": 0.0, "avg_logprob": -0.09004780602833581, "compression_ratio": 1.7112676056338028, "no_speech_prob": 2.839352237060666e-05}, {"id": 340, "seek": 125732, "start": 1270.56, "end": 1273.1399999999999, "text": " It can be an ATM sitting at a bank.", "tokens": [467, 393, 312, 364, 46455, 3798, 412, 257, 3765, 13], "temperature": 0.0, "avg_logprob": -0.09004780602833581, "compression_ratio": 1.7112676056338028, "no_speech_prob": 2.839352237060666e-05}, {"id": 341, "seek": 125732, "start": 1273.1399999999999, "end": 1279.36, "text": " It can be a factory that just happens to have intermittent Wi-Fi because today or this week", "tokens": [467, 393, 312, 257, 9265, 300, 445, 2314, 281, 362, 44084, 14035, 12, 13229, 570, 965, 420, 341, 1243], "temperature": 0.0, "avg_logprob": -0.09004780602833581, "compression_ratio": 1.7112676056338028, "no_speech_prob": 2.839352237060666e-05}, {"id": 342, "seek": 125732, "start": 1279.36, "end": 1282.12, "text": " got an ice storm and the internet went out.", "tokens": [658, 364, 4435, 7679, 293, 264, 4705, 1437, 484, 13], "temperature": 0.0, "avg_logprob": -0.09004780602833581, "compression_ratio": 1.7112676056338028, "no_speech_prob": 2.839352237060666e-05}, {"id": 343, "seek": 125732, "start": 1282.12, "end": 1286.6, "text": " So an edge device can really be almost, it's more broad than what we normally think of.", "tokens": [407, 364, 4691, 4302, 393, 534, 312, 1920, 11, 309, 311, 544, 4152, 813, 437, 321, 5646, 519, 295, 13], "temperature": 0.0, "avg_logprob": -0.09004780602833581, "compression_ratio": 1.7112676056338028, "no_speech_prob": 2.839352237060666e-05}, {"id": 344, "seek": 128660, "start": 1286.6, "end": 1290.76, "text": " It can be almost any device that it's important that it always stays connected, but that doesn't", "tokens": [467, 393, 312, 1920, 604, 4302, 300, 309, 311, 1021, 300, 309, 1009, 10834, 4582, 11, 457, 300, 1177, 380], "temperature": 0.0, "avg_logprob": -0.12415711710772176, "compression_ratio": 1.6802721088435375, "no_speech_prob": 3.217685662093572e-05}, {"id": 345, "seek": 128660, "start": 1290.76, "end": 1292.52, "text": " mean that it will.", "tokens": [914, 300, 309, 486, 13], "temperature": 0.0, "avg_logprob": -0.12415711710772176, "compression_ratio": 1.6802721088435375, "no_speech_prob": 3.217685662093572e-05}, {"id": 346, "seek": 128660, "start": 1292.52, "end": 1297.0, "text": " Or in the case of some people, it's your work server that happens to be sitting in your", "tokens": [1610, 294, 264, 1389, 295, 512, 561, 11, 309, 311, 428, 589, 7154, 300, 2314, 281, 312, 3798, 294, 428], "temperature": 0.0, "avg_logprob": -0.12415711710772176, "compression_ratio": 1.6802721088435375, "no_speech_prob": 3.217685662093572e-05}, {"id": 347, "seek": 128660, "start": 1297.0, "end": 1300.8799999999999, "text": " office that goes out because the power went out of the office and now somebody's getting", "tokens": [3398, 300, 1709, 484, 570, 264, 1347, 1437, 484, 295, 264, 3398, 293, 586, 2618, 311, 1242], "temperature": 0.0, "avg_logprob": -0.12415711710772176, "compression_ratio": 1.6802721088435375, "no_speech_prob": 3.217685662093572e-05}, {"id": 348, "seek": 128660, "start": 1300.8799999999999, "end": 1305.04, "text": " the phone call at 2 a.m. to go to that office and fix the server.", "tokens": [264, 2593, 818, 412, 568, 257, 13, 76, 13, 281, 352, 281, 300, 3398, 293, 3191, 264, 7154, 13], "temperature": 0.0, "avg_logprob": -0.12415711710772176, "compression_ratio": 1.6802721088435375, "no_speech_prob": 3.217685662093572e-05}, {"id": 349, "seek": 128660, "start": 1305.04, "end": 1307.8, "text": " That's why cloud computing is great.", "tokens": [663, 311, 983, 4588, 15866, 307, 869, 13], "temperature": 0.0, "avg_logprob": -0.12415711710772176, "compression_ratio": 1.6802721088435375, "no_speech_prob": 3.217685662093572e-05}, {"id": 350, "seek": 128660, "start": 1307.8, "end": 1314.36, "text": " So basically what edge data replication allows is it allows you to run your InfluxDB OSS instance,", "tokens": [407, 1936, 437, 4691, 1412, 39911, 4045, 307, 309, 4045, 291, 281, 1190, 428, 682, 3423, 2449, 27735, 12731, 50, 5197, 11], "temperature": 0.0, "avg_logprob": -0.12415711710772176, "compression_ratio": 1.6802721088435375, "no_speech_prob": 3.217685662093572e-05}, {"id": 351, "seek": 131436, "start": 1314.36, "end": 1320.8, "text": " your edge, and basically it has a dispatch queue which holds that data.", "tokens": [428, 4691, 11, 293, 1936, 309, 575, 257, 36729, 18639, 597, 9190, 300, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1286807656288147, "compression_ratio": 1.7843866171003717, "no_speech_prob": 5.3886364185018465e-05}, {"id": 352, "seek": 131436, "start": 1320.8, "end": 1323.8799999999999, "text": " So as you can see here, you have your bucket, you have your queue.", "tokens": [407, 382, 291, 393, 536, 510, 11, 291, 362, 428, 13058, 11, 291, 362, 428, 18639, 13], "temperature": 0.0, "avg_logprob": -0.1286807656288147, "compression_ratio": 1.7843866171003717, "no_speech_prob": 5.3886364185018465e-05}, {"id": 353, "seek": 131436, "start": 1323.8799999999999, "end": 1326.4399999999998, "text": " There are limits to how much data you can hold.", "tokens": [821, 366, 10406, 281, 577, 709, 1412, 291, 393, 1797, 13], "temperature": 0.0, "avg_logprob": -0.1286807656288147, "compression_ratio": 1.7843866171003717, "no_speech_prob": 5.3886364185018465e-05}, {"id": 354, "seek": 131436, "start": 1326.4399999999998, "end": 1330.08, "text": " You can check out the documentation to find out all the nitty-gritty.", "tokens": [509, 393, 1520, 484, 264, 14333, 281, 915, 484, 439, 264, 297, 10016, 12, 861, 10016, 13], "temperature": 0.0, "avg_logprob": -0.1286807656288147, "compression_ratio": 1.7843866171003717, "no_speech_prob": 5.3886364185018465e-05}, {"id": 355, "seek": 131436, "start": 1330.08, "end": 1336.56, "text": " But basically from there, if you ever have like, you know, you ever have internet blackouts,", "tokens": [583, 1936, 490, 456, 11, 498, 291, 1562, 362, 411, 11, 291, 458, 11, 291, 1562, 362, 4705, 2211, 7711, 11], "temperature": 0.0, "avg_logprob": -0.1286807656288147, "compression_ratio": 1.7843866171003717, "no_speech_prob": 5.3886364185018465e-05}, {"id": 356, "seek": 131436, "start": 1336.56, "end": 1340.36, "text": " you ever have power loss, you will have that data backed up.", "tokens": [291, 1562, 362, 1347, 4470, 11, 291, 486, 362, 300, 1412, 20391, 493, 13], "temperature": 0.0, "avg_logprob": -0.1286807656288147, "compression_ratio": 1.7843866171003717, "no_speech_prob": 5.3886364185018465e-05}, {"id": 357, "seek": 131436, "start": 1340.36, "end": 1344.34, "text": " And then when it reconnects, it goes ahead and sends it to the cloud.", "tokens": [400, 550, 562, 309, 30095, 82, 11, 309, 1709, 2286, 293, 14790, 309, 281, 264, 4588, 13], "temperature": 0.0, "avg_logprob": -0.1286807656288147, "compression_ratio": 1.7843866171003717, "no_speech_prob": 5.3886364185018465e-05}, {"id": 358, "seek": 134434, "start": 1344.34, "end": 1350.04, "text": " Now obviously I would hope that nobody has plants that are so important that they necessarily", "tokens": [823, 2745, 286, 576, 1454, 300, 5079, 575, 5972, 300, 366, 370, 1021, 300, 436, 4725], "temperature": 0.0, "avg_logprob": -0.1171032740519597, "compression_ratio": 1.6754716981132076, "no_speech_prob": 3.760278195841238e-05}, {"id": 359, "seek": 134434, "start": 1350.04, "end": 1351.8799999999999, "text": " need to back up their data.", "tokens": [643, 281, 646, 493, 641, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1171032740519597, "compression_ratio": 1.6754716981132076, "no_speech_prob": 3.760278195841238e-05}, {"id": 360, "seek": 134434, "start": 1351.8799999999999, "end": 1357.84, "text": " But I also like doing this because I monitor these plants at conferences, like they come", "tokens": [583, 286, 611, 411, 884, 341, 570, 286, 6002, 613, 5972, 412, 22032, 11, 411, 436, 808], "temperature": 0.0, "avg_logprob": -0.1171032740519597, "compression_ratio": 1.6754716981132076, "no_speech_prob": 3.760278195841238e-05}, {"id": 361, "seek": 134434, "start": 1357.84, "end": 1362.8799999999999, "text": " with me when I'm doing basically what the people outside of this room are doing.", "tokens": [365, 385, 562, 286, 478, 884, 1936, 437, 264, 561, 2380, 295, 341, 1808, 366, 884, 13], "temperature": 0.0, "avg_logprob": -0.1171032740519597, "compression_ratio": 1.6754716981132076, "no_speech_prob": 3.760278195841238e-05}, {"id": 362, "seek": 134434, "start": 1362.8799999999999, "end": 1367.9199999999998, "text": " Sometimes I have a plant at our booth where I monitor it and although this conference", "tokens": [4803, 286, 362, 257, 3709, 412, 527, 20912, 689, 286, 6002, 309, 293, 4878, 341, 7586], "temperature": 0.0, "avg_logprob": -0.1171032740519597, "compression_ratio": 1.6754716981132076, "no_speech_prob": 3.760278195841238e-05}, {"id": 363, "seek": 134434, "start": 1367.9199999999998, "end": 1372.52, "text": " has been really great for Wi-Fi, not all of them are so wonderful.", "tokens": [575, 668, 534, 869, 337, 14035, 12, 13229, 11, 406, 439, 295, 552, 366, 370, 3715, 13], "temperature": 0.0, "avg_logprob": -0.1171032740519597, "compression_ratio": 1.6754716981132076, "no_speech_prob": 3.760278195841238e-05}, {"id": 364, "seek": 137252, "start": 1372.52, "end": 1376.6, "text": " And so it's actually not uncommon for me and my plant to lose Wi-Fi and then I can use", "tokens": [400, 370, 309, 311, 767, 406, 29289, 337, 385, 293, 452, 3709, 281, 3624, 14035, 12, 13229, 293, 550, 286, 393, 764], "temperature": 0.0, "avg_logprob": -0.1043966441478544, "compression_ratio": 1.604, "no_speech_prob": 8.662014806759544e-06}, {"id": 365, "seek": 137252, "start": 1376.6, "end": 1380.68, "text": " the edge data replication to still push that data up to the cloud once I reconnect.", "tokens": [264, 4691, 1412, 39911, 281, 920, 2944, 300, 1412, 493, 281, 264, 4588, 1564, 286, 30095, 13], "temperature": 0.0, "avg_logprob": -0.1043966441478544, "compression_ratio": 1.604, "no_speech_prob": 8.662014806759544e-06}, {"id": 366, "seek": 137252, "start": 1380.68, "end": 1385.8799999999999, "text": " Or I close my laptop when I go to lunch and then it stops running, also not super great.", "tokens": [1610, 286, 1998, 452, 10732, 562, 286, 352, 281, 6349, 293, 550, 309, 10094, 2614, 11, 611, 406, 1687, 869, 13], "temperature": 0.0, "avg_logprob": -0.1043966441478544, "compression_ratio": 1.604, "no_speech_prob": 8.662014806759544e-06}, {"id": 367, "seek": 137252, "start": 1385.8799999999999, "end": 1391.8799999999999, "text": " But basically this is pretty easy to set up and get going on.", "tokens": [583, 1936, 341, 307, 1238, 1858, 281, 992, 493, 293, 483, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.1043966441478544, "compression_ratio": 1.604, "no_speech_prob": 8.662014806759544e-06}, {"id": 368, "seek": 137252, "start": 1391.8799999999999, "end": 1395.76, "text": " So these are part of the setup instructions that are in this project's read me.", "tokens": [407, 613, 366, 644, 295, 264, 8657, 9415, 300, 366, 294, 341, 1716, 311, 1401, 385, 13], "temperature": 0.0, "avg_logprob": -0.1043966441478544, "compression_ratio": 1.604, "no_speech_prob": 8.662014806759544e-06}, {"id": 369, "seek": 139576, "start": 1395.76, "end": 1403.52, "text": " So as you can see, we're running our InfluxDB OSS edge on Docker, so it's a Docker hosted", "tokens": [407, 382, 291, 393, 536, 11, 321, 434, 2614, 527, 682, 3423, 2449, 27735, 12731, 50, 4691, 322, 33772, 11, 370, 309, 311, 257, 33772, 19204], "temperature": 0.0, "avg_logprob": -0.16856435567391018, "compression_ratio": 1.618320610687023, "no_speech_prob": 1.2596481610671617e-05}, {"id": 370, "seek": 139576, "start": 1403.52, "end": 1404.8799999999999, "text": " OSS.", "tokens": [12731, 50, 13], "temperature": 0.0, "avg_logprob": -0.16856435567391018, "compression_ratio": 1.618320610687023, "no_speech_prob": 1.2596481610671617e-05}, {"id": 371, "seek": 139576, "start": 1404.8799999999999, "end": 1410.48, "text": " And basically what the command in the second portion does is it just sets it up to be a", "tokens": [400, 1936, 437, 264, 5622, 294, 264, 1150, 8044, 775, 307, 309, 445, 6352, 309, 493, 281, 312, 257], "temperature": 0.0, "avg_logprob": -0.16856435567391018, "compression_ratio": 1.618320610687023, "no_speech_prob": 1.2596481610671617e-05}, {"id": 372, "seek": 139576, "start": 1410.48, "end": 1411.48, "text": " edge device.", "tokens": [4691, 4302, 13], "temperature": 0.0, "avg_logprob": -0.16856435567391018, "compression_ratio": 1.618320610687023, "no_speech_prob": 1.2596481610671617e-05}, {"id": 373, "seek": 139576, "start": 1411.48, "end": 1415.6, "text": " It's just saying like, hey, do the config create, plant buddy edge, this is going to be where", "tokens": [467, 311, 445, 1566, 411, 11, 4177, 11, 360, 264, 6662, 1884, 11, 3709, 10340, 4691, 11, 341, 307, 516, 281, 312, 689], "temperature": 0.0, "avg_logprob": -0.16856435567391018, "compression_ratio": 1.618320610687023, "no_speech_prob": 1.2596481610671617e-05}, {"id": 374, "seek": 139576, "start": 1415.6, "end": 1418.68, "text": " it's coming from, it's the open source version.", "tokens": [309, 311, 1348, 490, 11, 309, 311, 264, 1269, 4009, 3037, 13], "temperature": 0.0, "avg_logprob": -0.16856435567391018, "compression_ratio": 1.618320610687023, "no_speech_prob": 1.2596481610671617e-05}, {"id": 375, "seek": 139576, "start": 1418.68, "end": 1424.56, "text": " And then the rest of these instructions are basically just for the USB ports and such.", "tokens": [400, 550, 264, 1472, 295, 613, 9415, 366, 1936, 445, 337, 264, 10109, 18160, 293, 1270, 13], "temperature": 0.0, "avg_logprob": -0.16856435567391018, "compression_ratio": 1.618320610687023, "no_speech_prob": 1.2596481610671617e-05}, {"id": 376, "seek": 142456, "start": 1424.56, "end": 1431.24, "text": " Like I said before, we have some pretty in-depth documentation on how to get this project going.", "tokens": [1743, 286, 848, 949, 11, 321, 362, 512, 1238, 294, 12, 25478, 14333, 322, 577, 281, 483, 341, 1716, 516, 13], "temperature": 0.0, "avg_logprob": -0.10291387939453125, "compression_ratio": 1.8076923076923077, "no_speech_prob": 2.5051376724150032e-05}, {"id": 377, "seek": 142456, "start": 1431.24, "end": 1433.52, "text": " And then these are the two big commands that you run.", "tokens": [400, 550, 613, 366, 264, 732, 955, 16901, 300, 291, 1190, 13], "temperature": 0.0, "avg_logprob": -0.10291387939453125, "compression_ratio": 1.8076923076923077, "no_speech_prob": 2.5051376724150032e-05}, {"id": 378, "seek": 142456, "start": 1433.52, "end": 1435.52, "text": " And they're pretty straightforward.", "tokens": [400, 436, 434, 1238, 15325, 13], "temperature": 0.0, "avg_logprob": -0.10291387939453125, "compression_ratio": 1.8076923076923077, "no_speech_prob": 2.5051376724150032e-05}, {"id": 379, "seek": 142456, "start": 1435.52, "end": 1440.1599999999999, "text": " Basically all you need to do is just have all of your information for your OSS, so that's", "tokens": [8537, 439, 291, 643, 281, 360, 307, 445, 362, 439, 295, 428, 1589, 337, 428, 12731, 50, 11, 370, 300, 311], "temperature": 0.0, "avg_logprob": -0.10291387939453125, "compression_ratio": 1.8076923076923077, "no_speech_prob": 2.5051376724150032e-05}, {"id": 380, "seek": 142456, "start": 1440.1599999999999, "end": 1444.36, "text": " going to be that bucket that we named before.", "tokens": [516, 281, 312, 300, 13058, 300, 321, 4926, 949, 13], "temperature": 0.0, "avg_logprob": -0.10291387939453125, "compression_ratio": 1.8076923076923077, "no_speech_prob": 2.5051376724150032e-05}, {"id": 381, "seek": 142456, "start": 1444.36, "end": 1446.82, "text": " You're going to need to create that remote connection.", "tokens": [509, 434, 516, 281, 643, 281, 1884, 300, 8607, 4984, 13], "temperature": 0.0, "avg_logprob": -0.10291387939453125, "compression_ratio": 1.8076923076923077, "no_speech_prob": 2.5051376724150032e-05}, {"id": 382, "seek": 142456, "start": 1446.82, "end": 1451.28, "text": " And then finally you need to do the replication command where you're saying replicate between", "tokens": [400, 550, 2721, 291, 643, 281, 360, 264, 39911, 5622, 689, 291, 434, 1566, 25356, 1296], "temperature": 0.0, "avg_logprob": -0.10291387939453125, "compression_ratio": 1.8076923076923077, "no_speech_prob": 2.5051376724150032e-05}, {"id": 383, "seek": 142456, "start": 1451.28, "end": 1454.08, "text": " the local bucket ID and the remote bucket ID.", "tokens": [264, 2654, 13058, 7348, 293, 264, 8607, 13058, 7348, 13], "temperature": 0.0, "avg_logprob": -0.10291387939453125, "compression_ratio": 1.8076923076923077, "no_speech_prob": 2.5051376724150032e-05}, {"id": 384, "seek": 145408, "start": 1454.08, "end": 1459.08, "text": " So as I said before, I'll show how you actually create the buckets, but for the cloud as well", "tokens": [407, 382, 286, 848, 949, 11, 286, 603, 855, 577, 291, 767, 1884, 264, 32191, 11, 457, 337, 264, 4588, 382, 731], "temperature": 0.0, "avg_logprob": -0.11935752200097152, "compression_ratio": 1.738532110091743, "no_speech_prob": 1.3623149243358057e-05}, {"id": 385, "seek": 145408, "start": 1459.08, "end": 1463.8, "text": " as the open source is the exact same, you just basically create the bucket, you need", "tokens": [382, 264, 1269, 4009, 307, 264, 1900, 912, 11, 291, 445, 1936, 1884, 264, 13058, 11, 291, 643], "temperature": 0.0, "avg_logprob": -0.11935752200097152, "compression_ratio": 1.738532110091743, "no_speech_prob": 1.3623149243358057e-05}, {"id": 386, "seek": 145408, "start": 1463.8, "end": 1468.48, "text": " to get the ID for it, and then you're basically just saying, this is my local bucket, this", "tokens": [281, 483, 264, 7348, 337, 309, 11, 293, 550, 291, 434, 1936, 445, 1566, 11, 341, 307, 452, 2654, 13058, 11, 341], "temperature": 0.0, "avg_logprob": -0.11935752200097152, "compression_ratio": 1.738532110091743, "no_speech_prob": 1.3623149243358057e-05}, {"id": 387, "seek": 145408, "start": 1468.48, "end": 1474.8799999999999, "text": " is my cloud bucket, please make sure the data goes up in that direction.", "tokens": [307, 452, 4588, 13058, 11, 1767, 652, 988, 264, 1412, 1709, 493, 294, 300, 3513, 13], "temperature": 0.0, "avg_logprob": -0.11935752200097152, "compression_ratio": 1.738532110091743, "no_speech_prob": 1.3623149243358057e-05}, {"id": 388, "seek": 145408, "start": 1474.8799999999999, "end": 1479.72, "text": " So data requests and visualizations.", "tokens": [407, 1412, 12475, 293, 5056, 14455, 13], "temperature": 0.0, "avg_logprob": -0.11935752200097152, "compression_ratio": 1.738532110091743, "no_speech_prob": 1.3623149243358057e-05}, {"id": 389, "seek": 147972, "start": 1479.72, "end": 1485.72, "text": " So when we are querying data back out, this is using again the Python client library,", "tokens": [407, 562, 321, 366, 7083, 1840, 1412, 646, 484, 11, 341, 307, 1228, 797, 264, 15329, 6423, 6405, 11], "temperature": 0.0, "avg_logprob": -0.1454924069918119, "compression_ratio": 1.6344827586206896, "no_speech_prob": 1.3201469300838653e-05}, {"id": 390, "seek": 147972, "start": 1485.72, "end": 1491.4, "text": " which although Telegraph does have a few output plugins, they're not relevant for this specific", "tokens": [597, 4878, 1989, 6363, 2662, 775, 362, 257, 1326, 5598, 33759, 11, 436, 434, 406, 7340, 337, 341, 2685], "temperature": 0.0, "avg_logprob": -0.1454924069918119, "compression_ratio": 1.6344827586206896, "no_speech_prob": 1.3201469300838653e-05}, {"id": 391, "seek": 147972, "start": 1491.4, "end": 1492.4, "text": " project.", "tokens": [1716, 13], "temperature": 0.0, "avg_logprob": -0.1454924069918119, "compression_ratio": 1.6344827586206896, "no_speech_prob": 1.3201469300838653e-05}, {"id": 392, "seek": 147972, "start": 1492.4, "end": 1497.3600000000001, "text": " You could check them out if you wanted to send your data to a different way, a different", "tokens": [509, 727, 1520, 552, 484, 498, 291, 1415, 281, 2845, 428, 1412, 281, 257, 819, 636, 11, 257, 819], "temperature": 0.0, "avg_logprob": -0.1454924069918119, "compression_ratio": 1.6344827586206896, "no_speech_prob": 1.3201469300838653e-05}, {"id": 393, "seek": 147972, "start": 1497.3600000000001, "end": 1498.8, "text": " website or such.", "tokens": [3144, 420, 1270, 13], "temperature": 0.0, "avg_logprob": -0.1454924069918119, "compression_ratio": 1.6344827586206896, "no_speech_prob": 1.3201469300838653e-05}, {"id": 394, "seek": 147972, "start": 1498.8, "end": 1503.92, "text": " But basically all we're doing here is we are using one of those flux queries, the same", "tokens": [583, 1936, 439, 321, 434, 884, 510, 307, 321, 366, 1228, 472, 295, 729, 19298, 24109, 11, 264, 912], "temperature": 0.0, "avg_logprob": -0.1454924069918119, "compression_ratio": 1.6344827586206896, "no_speech_prob": 1.3201469300838653e-05}, {"id": 395, "seek": 147972, "start": 1503.92, "end": 1507.64, "text": " one that I showed from an earlier slide where it's basically just saying, give me the data", "tokens": [472, 300, 286, 4712, 490, 364, 3071, 4137, 689, 309, 311, 1936, 445, 1566, 11, 976, 385, 264, 1412], "temperature": 0.0, "avg_logprob": -0.1454924069918119, "compression_ratio": 1.6344827586206896, "no_speech_prob": 1.3201469300838653e-05}, {"id": 396, "seek": 150764, "start": 1507.64, "end": 1512.24, "text": " for the past roughly day for this bucket with this value.", "tokens": [337, 264, 1791, 9810, 786, 337, 341, 13058, 365, 341, 2158, 13], "temperature": 0.0, "avg_logprob": -0.15702642294076774, "compression_ratio": 1.77007299270073, "no_speech_prob": 1.4965161426516715e-05}, {"id": 397, "seek": 150764, "start": 1512.24, "end": 1515.64, "text": " And from there, you have your params, you have your bucket, your sensor name and your", "tokens": [400, 490, 456, 11, 291, 362, 428, 971, 4070, 11, 291, 362, 428, 13058, 11, 428, 10200, 1315, 293, 428], "temperature": 0.0, "avg_logprob": -0.15702642294076774, "compression_ratio": 1.77007299270073, "no_speech_prob": 1.4965161426516715e-05}, {"id": 398, "seek": 150764, "start": 1515.64, "end": 1520.24, "text": " device ID, which can be submitted, like I said before, it's like a drop down that you", "tokens": [4302, 7348, 11, 597, 393, 312, 14405, 11, 411, 286, 848, 949, 11, 309, 311, 411, 257, 3270, 760, 300, 291], "temperature": 0.0, "avg_logprob": -0.15702642294076774, "compression_ratio": 1.77007299270073, "no_speech_prob": 1.4965161426516715e-05}, {"id": 399, "seek": 150764, "start": 1520.24, "end": 1524.4, "text": " can pick from, and basically once you do the query and you do the open.read, you're going", "tokens": [393, 1888, 490, 11, 293, 1936, 1564, 291, 360, 264, 14581, 293, 291, 360, 264, 1269, 13, 2538, 11, 291, 434, 516], "temperature": 0.0, "avg_logprob": -0.15702642294076774, "compression_ratio": 1.77007299270073, "no_speech_prob": 1.4965161426516715e-05}, {"id": 400, "seek": 150764, "start": 1524.4, "end": 1527.5200000000002, "text": " to receive that data back.", "tokens": [281, 4774, 300, 1412, 646, 13], "temperature": 0.0, "avg_logprob": -0.15702642294076774, "compression_ratio": 1.77007299270073, "no_speech_prob": 1.4965161426516715e-05}, {"id": 401, "seek": 150764, "start": 1527.5200000000002, "end": 1531.24, "text": " And you can receive this data back in different ways, but we're doing it in a data frame because", "tokens": [400, 291, 393, 4774, 341, 1412, 646, 294, 819, 2098, 11, 457, 321, 434, 884, 309, 294, 257, 1412, 3920, 570], "temperature": 0.0, "avg_logprob": -0.15702642294076774, "compression_ratio": 1.77007299270073, "no_speech_prob": 1.4965161426516715e-05}, {"id": 402, "seek": 150764, "start": 1531.24, "end": 1535.68, "text": " that's the easiest for graphing implotly.", "tokens": [300, 311, 264, 12889, 337, 1295, 79, 571, 8484, 310, 356, 13], "temperature": 0.0, "avg_logprob": -0.15702642294076774, "compression_ratio": 1.77007299270073, "no_speech_prob": 1.4965161426516715e-05}, {"id": 403, "seek": 153568, "start": 1535.68, "end": 1541.52, "text": " This is currently in, what's the word, we're working on it.", "tokens": [639, 307, 4362, 294, 11, 437, 311, 264, 1349, 11, 321, 434, 1364, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.12041861670357841, "compression_ratio": 1.8097014925373134, "no_speech_prob": 1.1120069757453166e-05}, {"id": 404, "seek": 153568, "start": 1541.52, "end": 1546.5600000000002, "text": " So we're currently working on getting this project to be integrated with SQL.", "tokens": [407, 321, 434, 4362, 1364, 322, 1242, 341, 1716, 281, 312, 10919, 365, 19200, 13], "temperature": 0.0, "avg_logprob": -0.12041861670357841, "compression_ratio": 1.8097014925373134, "no_speech_prob": 1.1120069757453166e-05}, {"id": 405, "seek": 153568, "start": 1546.5600000000002, "end": 1551.0, "text": " That's going to be my task when I get home tomorrow on Monday or Tuesday whenever my", "tokens": [663, 311, 516, 281, 312, 452, 5633, 562, 286, 483, 1280, 4153, 322, 8138, 420, 10017, 5699, 452], "temperature": 0.0, "avg_logprob": -0.12041861670357841, "compression_ratio": 1.8097014925373134, "no_speech_prob": 1.1120069757453166e-05}, {"id": 406, "seek": 153568, "start": 1551.0, "end": 1552.4, "text": " flight lands.", "tokens": [7018, 5949, 13], "temperature": 0.0, "avg_logprob": -0.12041861670357841, "compression_ratio": 1.8097014925373134, "no_speech_prob": 1.1120069757453166e-05}, {"id": 407, "seek": 153568, "start": 1552.4, "end": 1555.8, "text": " But basically from here, this is how it's going to be instead executed.", "tokens": [583, 1936, 490, 510, 11, 341, 307, 577, 309, 311, 516, 281, 312, 2602, 17577, 13], "temperature": 0.0, "avg_logprob": -0.12041861670357841, "compression_ratio": 1.8097014925373134, "no_speech_prob": 1.1120069757453166e-05}, {"id": 408, "seek": 153568, "start": 1555.8, "end": 1560.76, "text": " You're basically just going to be using a SQL command and getting a very similar readback.", "tokens": [509, 434, 1936, 445, 516, 281, 312, 1228, 257, 19200, 5622, 293, 1242, 257, 588, 2531, 1401, 3207, 13], "temperature": 0.0, "avg_logprob": -0.12041861670357841, "compression_ratio": 1.8097014925373134, "no_speech_prob": 1.1120069757453166e-05}, {"id": 409, "seek": 153568, "start": 1560.76, "end": 1564.92, "text": " With this one, we're just getting a, what's the word, like a straight read, we're not", "tokens": [2022, 341, 472, 11, 321, 434, 445, 1242, 257, 11, 437, 311, 264, 1349, 11, 411, 257, 2997, 1401, 11, 321, 434, 406], "temperature": 0.0, "avg_logprob": -0.12041861670357841, "compression_ratio": 1.8097014925373134, "no_speech_prob": 1.1120069757453166e-05}, {"id": 410, "seek": 156492, "start": 1564.92, "end": 1568.4, "text": " doing it into a data frame, but that is going to be something that we're going to set up", "tokens": [884, 309, 666, 257, 1412, 3920, 11, 457, 300, 307, 516, 281, 312, 746, 300, 321, 434, 516, 281, 992, 493], "temperature": 0.0, "avg_logprob": -0.1007031802983247, "compression_ratio": 1.7518796992481203, "no_speech_prob": 1.5200449524854776e-05}, {"id": 411, "seek": 156492, "start": 1568.4, "end": 1569.4, "text": " and be an option.", "tokens": [293, 312, 364, 3614, 13], "temperature": 0.0, "avg_logprob": -0.1007031802983247, "compression_ratio": 1.7518796992481203, "no_speech_prob": 1.5200449524854776e-05}, {"id": 412, "seek": 156492, "start": 1569.4, "end": 1573.8000000000002, "text": " So if you do want to use this in the future, just wait like by the end of the week and", "tokens": [407, 498, 291, 360, 528, 281, 764, 341, 294, 264, 2027, 11, 445, 1699, 411, 538, 264, 917, 295, 264, 1243, 293], "temperature": 0.0, "avg_logprob": -0.1007031802983247, "compression_ratio": 1.7518796992481203, "no_speech_prob": 1.5200449524854776e-05}, {"id": 413, "seek": 156492, "start": 1573.8000000000002, "end": 1580.04, "text": " we'll have that project up as a part of the plant buddy repo.", "tokens": [321, 603, 362, 300, 1716, 493, 382, 257, 644, 295, 264, 3709, 10340, 49040, 13], "temperature": 0.0, "avg_logprob": -0.1007031802983247, "compression_ratio": 1.7518796992481203, "no_speech_prob": 1.5200449524854776e-05}, {"id": 414, "seek": 156492, "start": 1580.04, "end": 1582.4, "text": " And finally actually graphing the data.", "tokens": [400, 2721, 767, 1295, 79, 571, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1007031802983247, "compression_ratio": 1.7518796992481203, "no_speech_prob": 1.5200449524854776e-05}, {"id": 415, "seek": 156492, "start": 1582.4, "end": 1585.44, "text": " So it's pretty easy to actually graph the data inside of plotly.", "tokens": [407, 309, 311, 1238, 1858, 281, 767, 4295, 264, 1412, 1854, 295, 7542, 356, 13], "temperature": 0.0, "avg_logprob": -0.1007031802983247, "compression_ratio": 1.7518796992481203, "no_speech_prob": 1.5200449524854776e-05}, {"id": 416, "seek": 156492, "start": 1585.44, "end": 1589.88, "text": " So as you can see, we have a few different line graphs, which are set for soil moisture,", "tokens": [407, 382, 291, 393, 536, 11, 321, 362, 257, 1326, 819, 1622, 24877, 11, 597, 366, 992, 337, 6704, 13814, 11], "temperature": 0.0, "avg_logprob": -0.1007031802983247, "compression_ratio": 1.7518796992481203, "no_speech_prob": 1.5200449524854776e-05}, {"id": 417, "seek": 156492, "start": 1589.88, "end": 1591.4, "text": " air temperature.", "tokens": [1988, 4292, 13], "temperature": 0.0, "avg_logprob": -0.1007031802983247, "compression_ratio": 1.7518796992481203, "no_speech_prob": 1.5200449524854776e-05}, {"id": 418, "seek": 159140, "start": 1591.4, "end": 1595.2, "text": " And as you can see, we're setting a few, like these are the values that we're setting here,", "tokens": [400, 382, 291, 393, 536, 11, 321, 434, 3287, 257, 1326, 11, 411, 613, 366, 264, 4190, 300, 321, 434, 3287, 510, 11], "temperature": 0.0, "avg_logprob": -0.12685138343745828, "compression_ratio": 1.8638297872340426, "no_speech_prob": 5.337099992175354e-06}, {"id": 419, "seek": 159140, "start": 1595.2, "end": 1599.44, "text": " like the graph default device ID, we're sending in that air temperature, and we're getting", "tokens": [411, 264, 4295, 7576, 4302, 7348, 11, 321, 434, 7750, 294, 300, 1988, 4292, 11, 293, 321, 434, 1242], "temperature": 0.0, "avg_logprob": -0.12685138343745828, "compression_ratio": 1.8638297872340426, "no_speech_prob": 5.337099992175354e-06}, {"id": 420, "seek": 159140, "start": 1599.44, "end": 1602.64, "text": " it back in a graph format.", "tokens": [309, 646, 294, 257, 4295, 7877, 13], "temperature": 0.0, "avg_logprob": -0.12685138343745828, "compression_ratio": 1.8638297872340426, "no_speech_prob": 5.337099992175354e-06}, {"id": 421, "seek": 159140, "start": 1602.64, "end": 1605.64, "text": " And this is going to be another case where we're going to see if we can get this to work", "tokens": [400, 341, 307, 516, 281, 312, 1071, 1389, 689, 321, 434, 516, 281, 536, 498, 321, 393, 483, 341, 281, 589], "temperature": 0.0, "avg_logprob": -0.12685138343745828, "compression_ratio": 1.8638297872340426, "no_speech_prob": 5.337099992175354e-06}, {"id": 422, "seek": 159140, "start": 1605.64, "end": 1611.48, "text": " because I really want this one to work, darn it.", "tokens": [570, 286, 534, 528, 341, 472, 281, 589, 11, 29063, 309, 13], "temperature": 0.0, "avg_logprob": -0.12685138343745828, "compression_ratio": 1.8638297872340426, "no_speech_prob": 5.337099992175354e-06}, {"id": 423, "seek": 159140, "start": 1611.48, "end": 1620.72, "text": " I actually wonder, we're going to try something a little bit weird, see if we can get this", "tokens": [286, 767, 2441, 11, 321, 434, 516, 281, 853, 746, 257, 707, 857, 3657, 11, 536, 498, 321, 393, 483, 341], "temperature": 0.0, "avg_logprob": -0.12685138343745828, "compression_ratio": 1.8638297872340426, "no_speech_prob": 5.337099992175354e-06}, {"id": 424, "seek": 162072, "start": 1620.72, "end": 1623.32, "text": " out of the presenter view.", "tokens": [484, 295, 264, 35594, 1910, 13], "temperature": 0.0, "avg_logprob": -0.2853947183360224, "compression_ratio": 1.5291479820627802, "no_speech_prob": 2.5464010832365602e-05}, {"id": 425, "seek": 162072, "start": 1623.32, "end": 1627.24, "text": " Oh no, escape.", "tokens": [876, 572, 11, 7615, 13], "temperature": 0.0, "avg_logprob": -0.2853947183360224, "compression_ratio": 1.5291479820627802, "no_speech_prob": 2.5464010832365602e-05}, {"id": 426, "seek": 162072, "start": 1627.24, "end": 1628.24, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.2853947183360224, "compression_ratio": 1.5291479820627802, "no_speech_prob": 2.5464010832365602e-05}, {"id": 427, "seek": 162072, "start": 1628.24, "end": 1634.68, "text": " Okay, this is not really ideal, but we're just going to have to go with it, I think,", "tokens": [1033, 11, 341, 307, 406, 534, 7157, 11, 457, 321, 434, 445, 516, 281, 362, 281, 352, 365, 309, 11, 286, 519, 11], "temperature": 0.0, "avg_logprob": -0.2853947183360224, "compression_ratio": 1.5291479820627802, "no_speech_prob": 2.5464010832365602e-05}, {"id": 428, "seek": 162072, "start": 1634.68, "end": 1635.68, "text": " maybe.", "tokens": [1310, 13], "temperature": 0.0, "avg_logprob": -0.2853947183360224, "compression_ratio": 1.5291479820627802, "no_speech_prob": 2.5464010832365602e-05}, {"id": 429, "seek": 162072, "start": 1635.68, "end": 1637.84, "text": " Man, it's really just not liking it, huh?", "tokens": [2458, 11, 309, 311, 534, 445, 406, 16933, 309, 11, 7020, 30], "temperature": 0.0, "avg_logprob": -0.2853947183360224, "compression_ratio": 1.5291479820627802, "no_speech_prob": 2.5464010832365602e-05}, {"id": 430, "seek": 162072, "start": 1637.84, "end": 1640.72, "text": " I don't know why, what is this?", "tokens": [286, 500, 380, 458, 983, 11, 437, 307, 341, 30], "temperature": 0.0, "avg_logprob": -0.2853947183360224, "compression_ratio": 1.5291479820627802, "no_speech_prob": 2.5464010832365602e-05}, {"id": 431, "seek": 162072, "start": 1640.72, "end": 1647.6000000000001, "text": " Oh well, that's not helpful at all, darn.", "tokens": [876, 731, 11, 300, 311, 406, 4961, 412, 439, 11, 29063, 13], "temperature": 0.0, "avg_logprob": -0.2853947183360224, "compression_ratio": 1.5291479820627802, "no_speech_prob": 2.5464010832365602e-05}, {"id": 432, "seek": 162072, "start": 1647.6000000000001, "end": 1650.6000000000001, "text": " One second, I'm going to drag this onto my screen and just see if I can do it.", "tokens": [1485, 1150, 11, 286, 478, 516, 281, 5286, 341, 3911, 452, 2568, 293, 445, 536, 498, 286, 393, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.2853947183360224, "compression_ratio": 1.5291479820627802, "no_speech_prob": 2.5464010832365602e-05}, {"id": 433, "seek": 165060, "start": 1650.6, "end": 1654.32, "text": " I guess it just doesn't like the HDMI today.", "tokens": [286, 2041, 309, 445, 1177, 380, 411, 264, 30811, 965, 13], "temperature": 0.0, "avg_logprob": -0.3345202596564042, "compression_ratio": 1.398876404494382, "no_speech_prob": 8.747921674512327e-05}, {"id": 434, "seek": 165060, "start": 1654.32, "end": 1659.12, "text": " Check the other Wi-Fi, the dual stack one.", "tokens": [6881, 264, 661, 14035, 12, 13229, 11, 264, 11848, 8630, 472, 13], "temperature": 0.0, "avg_logprob": -0.3345202596564042, "compression_ratio": 1.398876404494382, "no_speech_prob": 8.747921674512327e-05}, {"id": 435, "seek": 165060, "start": 1659.12, "end": 1660.12, "text": " I'm on the FOSDOM one.", "tokens": [286, 478, 322, 264, 479, 4367, 35, 5251, 472, 13], "temperature": 0.0, "avg_logprob": -0.3345202596564042, "compression_ratio": 1.398876404494382, "no_speech_prob": 8.747921674512327e-05}, {"id": 436, "seek": 165060, "start": 1660.12, "end": 1664.4399999999998, "text": " Yeah, there's a FOSDOM dual stack, which is IPv4.", "tokens": [865, 11, 456, 311, 257, 479, 4367, 35, 5251, 11848, 8630, 11, 597, 307, 8671, 85, 19, 13], "temperature": 0.0, "avg_logprob": -0.3345202596564042, "compression_ratio": 1.398876404494382, "no_speech_prob": 8.747921674512327e-05}, {"id": 437, "seek": 165060, "start": 1664.4399999999998, "end": 1666.9599999999998, "text": " Try that one.", "tokens": [6526, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.3345202596564042, "compression_ratio": 1.398876404494382, "no_speech_prob": 8.747921674512327e-05}, {"id": 438, "seek": 165060, "start": 1666.9599999999998, "end": 1667.9599999999998, "text": " This one?", "tokens": [639, 472, 30], "temperature": 0.0, "avg_logprob": -0.3345202596564042, "compression_ratio": 1.398876404494382, "no_speech_prob": 8.747921674512327e-05}, {"id": 439, "seek": 165060, "start": 1667.9599999999998, "end": 1668.9599999999998, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.3345202596564042, "compression_ratio": 1.398876404494382, "no_speech_prob": 8.747921674512327e-05}, {"id": 440, "seek": 165060, "start": 1668.9599999999998, "end": 1669.9599999999998, "text": " You think it's internet?", "tokens": [509, 519, 309, 311, 4705, 30], "temperature": 0.0, "avg_logprob": -0.3345202596564042, "compression_ratio": 1.398876404494382, "no_speech_prob": 8.747921674512327e-05}, {"id": 441, "seek": 165060, "start": 1669.9599999999998, "end": 1673.6, "text": " Not every Google thing likes IPv6.", "tokens": [1726, 633, 3329, 551, 5902, 8671, 85, 21, 13], "temperature": 0.0, "avg_logprob": -0.3345202596564042, "compression_ratio": 1.398876404494382, "no_speech_prob": 8.747921674512327e-05}, {"id": 442, "seek": 167360, "start": 1673.6, "end": 1683.24, "text": " I'll also refresh this really quick, see if that helps at all.", "tokens": [286, 603, 611, 15134, 341, 534, 1702, 11, 536, 498, 300, 3665, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.25663060274991123, "compression_ratio": 1.3384615384615384, "no_speech_prob": 1.8921480659628287e-05}, {"id": 443, "seek": 167360, "start": 1683.24, "end": 1698.28, "text": " Yeah, just really, it's so funny that, yeah, it was working before, but now it's just not", "tokens": [865, 11, 445, 534, 11, 309, 311, 370, 4074, 300, 11, 1338, 11, 309, 390, 1364, 949, 11, 457, 586, 309, 311, 445, 406], "temperature": 0.0, "avg_logprob": -0.25663060274991123, "compression_ratio": 1.3384615384615384, "no_speech_prob": 1.8921480659628287e-05}, {"id": 444, "seek": 167360, "start": 1698.28, "end": 1699.28, "text": " liking me.", "tokens": [16933, 385, 13], "temperature": 0.0, "avg_logprob": -0.25663060274991123, "compression_ratio": 1.3384615384615384, "no_speech_prob": 1.8921480659628287e-05}, {"id": 445, "seek": 167360, "start": 1699.28, "end": 1700.28, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.25663060274991123, "compression_ratio": 1.3384615384615384, "no_speech_prob": 1.8921480659628287e-05}, {"id": 446, "seek": 170028, "start": 1700.28, "end": 1707.6399999999999, "text": " Oh, you've got to be kidding me.", "tokens": [876, 11, 291, 600, 658, 281, 312, 9287, 385, 13], "temperature": 0.0, "avg_logprob": -0.32857055048788747, "compression_ratio": 1.4014598540145986, "no_speech_prob": 4.3304295104462653e-05}, {"id": 447, "seek": 170028, "start": 1707.6399999999999, "end": 1709.84, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.32857055048788747, "compression_ratio": 1.4014598540145986, "no_speech_prob": 4.3304295104462653e-05}, {"id": 448, "seek": 170028, "start": 1709.84, "end": 1710.84, "text": " I've got it working.", "tokens": [286, 600, 658, 309, 1364, 13], "temperature": 0.0, "avg_logprob": -0.32857055048788747, "compression_ratio": 1.4014598540145986, "no_speech_prob": 4.3304295104462653e-05}, {"id": 449, "seek": 170028, "start": 1710.84, "end": 1713.16, "text": " I think I just actually need to change my share settings.", "tokens": [286, 519, 286, 445, 767, 643, 281, 1319, 452, 2073, 6257, 13], "temperature": 0.0, "avg_logprob": -0.32857055048788747, "compression_ratio": 1.4014598540145986, "no_speech_prob": 4.3304295104462653e-05}, {"id": 450, "seek": 170028, "start": 1713.16, "end": 1714.16, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.32857055048788747, "compression_ratio": 1.4014598540145986, "no_speech_prob": 4.3304295104462653e-05}, {"id": 451, "seek": 170028, "start": 1714.16, "end": 1726.6399999999999, "text": " We're going to go ahead and change the way this is shared.", "tokens": [492, 434, 516, 281, 352, 2286, 293, 1319, 264, 636, 341, 307, 5507, 13], "temperature": 0.0, "avg_logprob": -0.32857055048788747, "compression_ratio": 1.4014598540145986, "no_speech_prob": 4.3304295104462653e-05}, {"id": 452, "seek": 172664, "start": 1726.64, "end": 1749.6000000000001, "text": " Do you know how to change the settings by any chance?", "tokens": [1144, 291, 458, 577, 281, 1319, 264, 6257, 538, 604, 2931, 30], "temperature": 0.0, "avg_logprob": -0.14125440670893744, "compression_ratio": 1.4576271186440677, "no_speech_prob": 4.067317786393687e-05}, {"id": 453, "seek": 172664, "start": 1749.6000000000001, "end": 1753.24, "text": " I thought it would just change it, but it didn't, like, just change it to just look", "tokens": [286, 1194, 309, 576, 445, 1319, 309, 11, 457, 309, 994, 380, 11, 411, 11, 445, 1319, 309, 281, 445, 574], "temperature": 0.0, "avg_logprob": -0.14125440670893744, "compression_ratio": 1.4576271186440677, "no_speech_prob": 4.067317786393687e-05}, {"id": 454, "seek": 172664, "start": 1753.24, "end": 1754.24, "text": " at this.", "tokens": [412, 341, 13], "temperature": 0.0, "avg_logprob": -0.14125440670893744, "compression_ratio": 1.4576271186440677, "no_speech_prob": 4.067317786393687e-05}, {"id": 455, "seek": 172664, "start": 1754.24, "end": 1755.24, "text": " Just look at this screen.", "tokens": [1449, 574, 412, 341, 2568, 13], "temperature": 0.0, "avg_logprob": -0.14125440670893744, "compression_ratio": 1.4576271186440677, "no_speech_prob": 4.067317786393687e-05}, {"id": 456, "seek": 175524, "start": 1755.24, "end": 1757.24, "text": " Oh, I don't think.", "tokens": [876, 11, 286, 500, 380, 519, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 457, "seek": 175524, "start": 1757.24, "end": 1758.24, "text": " No.", "tokens": [883, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 458, "seek": 175524, "start": 1758.24, "end": 1759.24, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 459, "seek": 175524, "start": 1759.24, "end": 1760.24, "text": " Hmm.", "tokens": [8239, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 460, "seek": 175524, "start": 1760.24, "end": 1761.24, "text": " Fair enough.", "tokens": [12157, 1547, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 461, "seek": 175524, "start": 1761.24, "end": 1766.6, "text": " Yeah, it's just, like, it's not, all right.", "tokens": [865, 11, 309, 311, 445, 11, 411, 11, 309, 311, 406, 11, 439, 558, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 462, "seek": 175524, "start": 1766.6, "end": 1767.6, "text": " Here we go.", "tokens": [1692, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 463, "seek": 175524, "start": 1767.6, "end": 1768.6, "text": " Mirror display.", "tokens": [34452, 4674, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 464, "seek": 175524, "start": 1768.6, "end": 1770.48, "text": " It's all these new updates.", "tokens": [467, 311, 439, 613, 777, 9205, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 465, "seek": 175524, "start": 1770.48, "end": 1772.28, "text": " I never know where anything is anymore.", "tokens": [286, 1128, 458, 689, 1340, 307, 3602, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 466, "seek": 175524, "start": 1772.28, "end": 1775.28, "text": " Okay, so it really is just the display thing, I think.", "tokens": [1033, 11, 370, 309, 534, 307, 445, 264, 4674, 551, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 467, "seek": 175524, "start": 1775.28, "end": 1779.8, "text": " I think it just doesn't want to work.", "tokens": [286, 519, 309, 445, 1177, 380, 528, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 468, "seek": 175524, "start": 1779.8, "end": 1780.8, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 469, "seek": 175524, "start": 1780.8, "end": 1781.8, "text": " Okay, cool.", "tokens": [1033, 11, 1627, 13], "temperature": 0.0, "avg_logprob": -0.25081951307213823, "compression_ratio": 1.6, "no_speech_prob": 3.7047011574031785e-05}, {"id": 470, "seek": 178180, "start": 1781.8, "end": 1786.72, "text": " So, I'm so sorry, guys.", "tokens": [407, 11, 286, 478, 370, 2597, 11, 1074, 13], "temperature": 0.0, "avg_logprob": -0.15303344196743435, "compression_ratio": 1.6756756756756757, "no_speech_prob": 1.669426819717046e-05}, {"id": 471, "seek": 178180, "start": 1786.72, "end": 1788.56, "text": " I didn't realize it didn't like my share.", "tokens": [286, 994, 380, 4325, 309, 994, 380, 411, 452, 2073, 13], "temperature": 0.0, "avg_logprob": -0.15303344196743435, "compression_ratio": 1.6756756756756757, "no_speech_prob": 1.669426819717046e-05}, {"id": 472, "seek": 178180, "start": 1788.56, "end": 1792.1599999999999, "text": " Okay, so I'm going to go ahead and full screen this, and we'll just go back to the other", "tokens": [1033, 11, 370, 286, 478, 516, 281, 352, 2286, 293, 1577, 2568, 341, 11, 293, 321, 603, 445, 352, 646, 281, 264, 661], "temperature": 0.0, "avg_logprob": -0.15303344196743435, "compression_ratio": 1.6756756756756757, "no_speech_prob": 1.669426819717046e-05}, {"id": 473, "seek": 178180, "start": 1792.1599999999999, "end": 1793.8799999999999, "text": " video because why not?", "tokens": [960, 570, 983, 406, 30], "temperature": 0.0, "avg_logprob": -0.15303344196743435, "compression_ratio": 1.6756756756756757, "no_speech_prob": 1.669426819717046e-05}, {"id": 474, "seek": 178180, "start": 1793.8799999999999, "end": 1796.36, "text": " So this is how it actually looks in the end.", "tokens": [407, 341, 307, 577, 309, 767, 1542, 294, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.15303344196743435, "compression_ratio": 1.6756756756756757, "no_speech_prob": 1.669426819717046e-05}, {"id": 475, "seek": 178180, "start": 1796.36, "end": 1800.0, "text": " So as you can see, it starts to actually make a little bit more sense.", "tokens": [407, 382, 291, 393, 536, 11, 309, 3719, 281, 767, 652, 257, 707, 857, 544, 2020, 13], "temperature": 0.0, "avg_logprob": -0.15303344196743435, "compression_ratio": 1.6756756756756757, "no_speech_prob": 1.669426819717046e-05}, {"id": 476, "seek": 178180, "start": 1800.0, "end": 1802.08, "text": " But basically, you can pick your fields.", "tokens": [583, 1936, 11, 291, 393, 1888, 428, 7909, 13], "temperature": 0.0, "avg_logprob": -0.15303344196743435, "compression_ratio": 1.6756756756756757, "no_speech_prob": 1.669426819717046e-05}, {"id": 477, "seek": 178180, "start": 1802.08, "end": 1805.72, "text": " So this is, like, a graph where you can kind of change it as you desire.", "tokens": [407, 341, 307, 11, 411, 11, 257, 4295, 689, 291, 393, 733, 295, 1319, 309, 382, 291, 7516, 13], "temperature": 0.0, "avg_logprob": -0.15303344196743435, "compression_ratio": 1.6756756756756757, "no_speech_prob": 1.669426819717046e-05}, {"id": 478, "seek": 178180, "start": 1805.72, "end": 1810.76, "text": " And you could also pick your bucket as well, which I might show in a second here on this", "tokens": [400, 291, 727, 611, 1888, 428, 13058, 382, 731, 11, 597, 286, 1062, 855, 294, 257, 1150, 510, 322, 341], "temperature": 0.0, "avg_logprob": -0.15303344196743435, "compression_ratio": 1.6756756756756757, "no_speech_prob": 1.669426819717046e-05}, {"id": 479, "seek": 181076, "start": 1810.76, "end": 1811.76, "text": " video.", "tokens": [960, 13], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 480, "seek": 181076, "start": 1811.76, "end": 1812.76, "text": " There we go, yeah.", "tokens": [821, 321, 352, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 481, "seek": 181076, "start": 1812.76, "end": 1815.08, "text": " So you could pick one of these many buckets.", "tokens": [407, 291, 727, 1888, 472, 295, 613, 867, 32191, 13], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 482, "seek": 181076, "start": 1815.08, "end": 1816.8799999999999, "text": " Most of these are not relevant to my project.", "tokens": [4534, 295, 613, 366, 406, 7340, 281, 452, 1716, 13], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 483, "seek": 181076, "start": 1816.8799999999999, "end": 1821.72, "text": " They're just the buckets I have in my cloud account, or rather, my open source.", "tokens": [814, 434, 445, 264, 32191, 286, 362, 294, 452, 4588, 2696, 11, 420, 2831, 11, 452, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 484, "seek": 181076, "start": 1821.72, "end": 1826.8, "text": " And so as you can see, these are the two, I'm going to go back to this part of the video.", "tokens": [400, 370, 382, 291, 393, 536, 11, 613, 366, 264, 732, 11, 286, 478, 516, 281, 352, 646, 281, 341, 644, 295, 264, 960, 13], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 485, "seek": 181076, "start": 1826.8, "end": 1829.08, "text": " These are the two hard-coded graphs.", "tokens": [1981, 366, 264, 732, 1152, 12, 66, 12340, 24877, 13], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 486, "seek": 181076, "start": 1829.08, "end": 1833.48, "text": " So as I said before, the original values sometimes come in really weird.", "tokens": [407, 382, 286, 848, 949, 11, 264, 3380, 4190, 2171, 808, 294, 534, 3657, 13], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 487, "seek": 181076, "start": 1833.48, "end": 1836.48, "text": " Like, I don't know why the heck humidity went, like, all the way up to 90 and then dropped", "tokens": [1743, 11, 286, 500, 380, 458, 983, 264, 12872, 24751, 1437, 11, 411, 11, 439, 264, 636, 493, 281, 4289, 293, 550, 8119], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 488, "seek": 181076, "start": 1836.48, "end": 1837.92, "text": " all the way back down.", "tokens": [439, 264, 636, 646, 760, 13], "temperature": 0.0, "avg_logprob": -0.11120654441214897, "compression_ratio": 1.683168316831683, "no_speech_prob": 1.7775717424228787e-05}, {"id": 489, "seek": 183792, "start": 1837.92, "end": 1842.3600000000001, "text": " We normally do a first flush of a lot of this data when it first hits because it just kind", "tokens": [492, 5646, 360, 257, 700, 19568, 295, 257, 688, 295, 341, 1412, 562, 309, 700, 8664, 570, 309, 445, 733], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 490, "seek": 183792, "start": 1842.3600000000001, "end": 1843.3600000000001, "text": " of comes in funny.", "tokens": [295, 1487, 294, 4074, 13], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 491, "seek": 183792, "start": 1843.3600000000001, "end": 1844.8000000000002, "text": " Or maybe I breathed on it.", "tokens": [1610, 1310, 286, 6045, 292, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 492, "seek": 183792, "start": 1844.8000000000002, "end": 1845.8000000000002, "text": " Who knows?", "tokens": [2102, 3255, 30], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 493, "seek": 183792, "start": 1845.8000000000002, "end": 1847.5600000000002, "text": " They're relatively sensitive.", "tokens": [814, 434, 7226, 9477, 13], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 494, "seek": 183792, "start": 1847.5600000000002, "end": 1849.0800000000002, "text": " It really does happen.", "tokens": [467, 534, 775, 1051, 13], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 495, "seek": 183792, "start": 1849.0800000000002, "end": 1853.1200000000001, "text": " But also, we had to do a little bit of exponential smoothing as well.", "tokens": [583, 611, 11, 321, 632, 281, 360, 257, 707, 857, 295, 21510, 899, 6259, 571, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 496, "seek": 183792, "start": 1853.1200000000001, "end": 1857.04, "text": " So like, we smoothed out the soil moisture because it used to look like the air temperature", "tokens": [407, 411, 11, 321, 5508, 292, 484, 264, 6704, 13814, 570, 309, 1143, 281, 574, 411, 264, 1988, 4292], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 497, "seek": 183792, "start": 1857.04, "end": 1858.04, "text": " does.", "tokens": [775, 13], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 498, "seek": 183792, "start": 1858.04, "end": 1859.88, "text": " It used to just, like, kind of jump around like a crazy thing.", "tokens": [467, 1143, 281, 445, 11, 411, 11, 733, 295, 3012, 926, 411, 257, 3219, 551, 13], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 499, "seek": 183792, "start": 1859.88, "end": 1863.76, "text": " The plant did not move between, like, the frigid air to back inside.", "tokens": [440, 3709, 630, 406, 1286, 1296, 11, 411, 11, 264, 34697, 327, 1988, 281, 646, 1854, 13], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 500, "seek": 183792, "start": 1863.76, "end": 1866.8000000000002, "text": " It's just these sensors can be a little bit temperamental.", "tokens": [467, 311, 445, 613, 14840, 393, 312, 257, 707, 857, 3393, 44538, 13], "temperature": 0.0, "avg_logprob": -0.10513374911751716, "compression_ratio": 1.736024844720497, "no_speech_prob": 2.768888862192398e-06}, {"id": 501, "seek": 186680, "start": 1866.8, "end": 1868.8, "text": " We bought the cheapest ones off Amazon.", "tokens": [492, 4243, 264, 29167, 2306, 766, 6795, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 502, "seek": 186680, "start": 1868.8, "end": 1870.28, "text": " We can only expect so much.", "tokens": [492, 393, 787, 2066, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 503, "seek": 186680, "start": 1870.28, "end": 1875.76, "text": " If you spend a little more money, you're going to get a nicer setup.", "tokens": [759, 291, 3496, 257, 707, 544, 1460, 11, 291, 434, 516, 281, 483, 257, 22842, 8657, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 504, "seek": 186680, "start": 1875.76, "end": 1881.24, "text": " So let me get at a full screen, please.", "tokens": [407, 718, 385, 483, 412, 257, 1577, 2568, 11, 1767, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 505, "seek": 186680, "start": 1881.24, "end": 1884.24, "text": " And I can just not win today.", "tokens": [400, 286, 393, 445, 406, 1942, 965, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 506, "seek": 186680, "start": 1884.24, "end": 1887.24, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 507, "seek": 186680, "start": 1887.24, "end": 1888.24, "text": " Nope.", "tokens": [12172, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 508, "seek": 186680, "start": 1888.24, "end": 1890.48, "text": " Now, you just want to play.", "tokens": [823, 11, 291, 445, 528, 281, 862, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 509, "seek": 186680, "start": 1890.48, "end": 1891.48, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 510, "seek": 186680, "start": 1891.48, "end": 1894.52, "text": " So these are some of the new visualization options for Flight Sequel.", "tokens": [407, 613, 366, 512, 295, 264, 777, 25801, 3956, 337, 28954, 1100, 20593, 13], "temperature": 0.0, "avg_logprob": -0.26286572101069433, "compression_ratio": 1.4796380090497738, "no_speech_prob": 3.0890862490196014e-06}, {"id": 511, "seek": 189452, "start": 1894.52, "end": 1897.84, "text": " We're also going to be adding these into the project, so you can check it out.", "tokens": [492, 434, 611, 516, 281, 312, 5127, 613, 666, 264, 1716, 11, 370, 291, 393, 1520, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.11393610393728008, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.6822013246128336e-05}, {"id": 512, "seek": 189452, "start": 1897.84, "end": 1900.48, "text": " We already have pretty good integration with Grafana as well.", "tokens": [492, 1217, 362, 1238, 665, 10980, 365, 8985, 69, 2095, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.11393610393728008, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.6822013246128336e-05}, {"id": 513, "seek": 189452, "start": 1900.48, "end": 1904.16, "text": " So if you would prefer to use them for your visualizations instead of Plotly, you're", "tokens": [407, 498, 291, 576, 4382, 281, 764, 552, 337, 428, 5056, 14455, 2602, 295, 2149, 310, 356, 11, 291, 434], "temperature": 0.0, "avg_logprob": -0.11393610393728008, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.6822013246128336e-05}, {"id": 514, "seek": 189452, "start": 1904.16, "end": 1906.8, "text": " more than welcome to.", "tokens": [544, 813, 2928, 281, 13], "temperature": 0.0, "avg_logprob": -0.11393610393728008, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.6822013246128336e-05}, {"id": 515, "seek": 189452, "start": 1906.8, "end": 1912.02, "text": " And then these are those further resources I mentioned before.", "tokens": [400, 550, 613, 366, 729, 3052, 3593, 286, 2835, 949, 13], "temperature": 0.0, "avg_logprob": -0.11393610393728008, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.6822013246128336e-05}, {"id": 516, "seek": 189452, "start": 1912.02, "end": 1913.76, "text": " So this is the try it yourself.", "tokens": [407, 341, 307, 264, 853, 309, 1803, 13], "temperature": 0.0, "avg_logprob": -0.11393610393728008, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.6822013246128336e-05}, {"id": 517, "seek": 189452, "start": 1913.76, "end": 1915.8799999999999, "text": " So this is where the actual project lives.", "tokens": [407, 341, 307, 689, 264, 3539, 1716, 2909, 13], "temperature": 0.0, "avg_logprob": -0.11393610393728008, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.6822013246128336e-05}, {"id": 518, "seek": 189452, "start": 1915.8799999999999, "end": 1919.08, "text": " This is the QR code as well as the GitHub.", "tokens": [639, 307, 264, 32784, 3089, 382, 731, 382, 264, 23331, 13], "temperature": 0.0, "avg_logprob": -0.11393610393728008, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.6822013246128336e-05}, {"id": 519, "seek": 189452, "start": 1919.08, "end": 1922.52, "text": " If you look up Plant Buddy on the Internet, you'll find this.", "tokens": [759, 291, 574, 493, 28995, 27829, 322, 264, 7703, 11, 291, 603, 915, 341, 13], "temperature": 0.0, "avg_logprob": -0.11393610393728008, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.6822013246128336e-05}, {"id": 520, "seek": 192252, "start": 1922.52, "end": 1926.04, "text": " And then we have a few different versions depending on what you want to do, including", "tokens": [400, 550, 321, 362, 257, 1326, 819, 9606, 5413, 322, 437, 291, 528, 281, 360, 11, 3009], "temperature": 0.0, "avg_logprob": -0.13929623463114754, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.4280959476309363e-05}, {"id": 521, "seek": 192252, "start": 1926.04, "end": 1929.56, "text": " the edge data replication version, which I've mentioned here.", "tokens": [264, 4691, 1412, 39911, 3037, 11, 597, 286, 600, 2835, 510, 13], "temperature": 0.0, "avg_logprob": -0.13929623463114754, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.4280959476309363e-05}, {"id": 522, "seek": 192252, "start": 1929.56, "end": 1933.4, "text": " Oh, I almost forgot about the other video.", "tokens": [876, 11, 286, 1920, 5298, 466, 264, 661, 960, 13], "temperature": 0.0, "avg_logprob": -0.13929623463114754, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.4280959476309363e-05}, {"id": 523, "seek": 192252, "start": 1933.4, "end": 1937.12, "text": " Let me go back up to it really quick.", "tokens": [961, 385, 352, 646, 493, 281, 309, 534, 1702, 13], "temperature": 0.0, "avg_logprob": -0.13929623463114754, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.4280959476309363e-05}, {"id": 524, "seek": 192252, "start": 1937.12, "end": 1940.68, "text": " I like the videos because it means I don't normally have to jump around super crazily", "tokens": [286, 411, 264, 2145, 570, 309, 1355, 286, 500, 380, 5646, 362, 281, 3012, 926, 1687, 46348, 953], "temperature": 0.0, "avg_logprob": -0.13929623463114754, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.4280959476309363e-05}, {"id": 525, "seek": 192252, "start": 1940.68, "end": 1943.4, "text": " and go in and out of the Cloud UI.", "tokens": [293, 352, 294, 293, 484, 295, 264, 8061, 15682, 13], "temperature": 0.0, "avg_logprob": -0.13929623463114754, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.4280959476309363e-05}, {"id": 526, "seek": 192252, "start": 1943.4, "end": 1946.76, "text": " Too bad it sometimes comes in as like, it's funny, it's set for the high quality, but", "tokens": [11395, 1578, 309, 2171, 1487, 294, 382, 411, 11, 309, 311, 4074, 11, 309, 311, 992, 337, 264, 1090, 3125, 11, 457], "temperature": 0.0, "avg_logprob": -0.13929623463114754, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.4280959476309363e-05}, {"id": 527, "seek": 192252, "start": 1946.76, "end": 1950.52, "text": " it never really is.", "tokens": [309, 1128, 534, 307, 13], "temperature": 0.0, "avg_logprob": -0.13929623463114754, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.4280959476309363e-05}, {"id": 528, "seek": 195052, "start": 1950.52, "end": 1955.24, "text": " I'd go back to Slideshow if you would be so kind.", "tokens": [286, 1116, 352, 646, 281, 6187, 1875, 4286, 498, 291, 576, 312, 370, 733, 13], "temperature": 0.0, "avg_logprob": -0.15672269681604897, "compression_ratio": 1.6704119850187267, "no_speech_prob": 3.0216970117180608e-05}, {"id": 529, "seek": 195052, "start": 1955.24, "end": 1956.24, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.15672269681604897, "compression_ratio": 1.6704119850187267, "no_speech_prob": 3.0216970117180608e-05}, {"id": 530, "seek": 195052, "start": 1956.24, "end": 1959.24, "text": " So as I was saying before, the create bucket is pretty straightforward.", "tokens": [407, 382, 286, 390, 1566, 949, 11, 264, 1884, 13058, 307, 1238, 15325, 13], "temperature": 0.0, "avg_logprob": -0.15672269681604897, "compression_ratio": 1.6704119850187267, "no_speech_prob": 3.0216970117180608e-05}, {"id": 531, "seek": 195052, "start": 1959.24, "end": 1960.44, "text": " You just name it.", "tokens": [509, 445, 1315, 309, 13], "temperature": 0.0, "avg_logprob": -0.15672269681604897, "compression_ratio": 1.6704119850187267, "no_speech_prob": 3.0216970117180608e-05}, {"id": 532, "seek": 195052, "start": 1960.44, "end": 1965.32, "text": " And then as you can see, the delete data is set for never or older than a certain amount", "tokens": [400, 550, 382, 291, 393, 536, 11, 264, 12097, 1412, 307, 992, 337, 1128, 420, 4906, 813, 257, 1629, 2372], "temperature": 0.0, "avg_logprob": -0.15672269681604897, "compression_ratio": 1.6704119850187267, "no_speech_prob": 3.0216970117180608e-05}, {"id": 533, "seek": 195052, "start": 1965.32, "end": 1966.76, "text": " of days or time.", "tokens": [295, 1708, 420, 565, 13], "temperature": 0.0, "avg_logprob": -0.15672269681604897, "compression_ratio": 1.6704119850187267, "no_speech_prob": 3.0216970117180608e-05}, {"id": 534, "seek": 195052, "start": 1966.76, "end": 1970.72, "text": " And then that advanced configuration is the schema that you can pick.", "tokens": [400, 550, 300, 7339, 11694, 307, 264, 34078, 300, 291, 393, 1888, 13], "temperature": 0.0, "avg_logprob": -0.15672269681604897, "compression_ratio": 1.6704119850187267, "no_speech_prob": 3.0216970117180608e-05}, {"id": 535, "seek": 195052, "start": 1970.72, "end": 1973.92, "text": " And then finally, the API tokens, also pretty straightforward.", "tokens": [400, 550, 2721, 11, 264, 9362, 22667, 11, 611, 1238, 15325, 13], "temperature": 0.0, "avg_logprob": -0.15672269681604897, "compression_ratio": 1.6704119850187267, "no_speech_prob": 3.0216970117180608e-05}, {"id": 536, "seek": 195052, "start": 1973.92, "end": 1977.36, "text": " You can do the read-write, which is what I do suggest.", "tokens": [509, 393, 360, 264, 1401, 12, 21561, 11, 597, 307, 437, 286, 360, 3402, 13], "temperature": 0.0, "avg_logprob": -0.15672269681604897, "compression_ratio": 1.6704119850187267, "no_speech_prob": 3.0216970117180608e-05}, {"id": 537, "seek": 197736, "start": 1977.36, "end": 1980.6399999999999, "text": " This all-accent is the big red button that I mentioned earlier.", "tokens": [639, 439, 12, 326, 2207, 307, 264, 955, 2182, 2960, 300, 286, 2835, 3071, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 538, "seek": 197736, "start": 1980.6399999999999, "end": 1983.24, "text": " As you can see, it's got the warning to don't do this.", "tokens": [1018, 291, 393, 536, 11, 309, 311, 658, 264, 9164, 281, 500, 380, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 539, "seek": 197736, "start": 1983.24, "end": 1986.1999999999998, "text": " I do it because I don't care.", "tokens": [286, 360, 309, 570, 286, 500, 380, 1127, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 540, "seek": 197736, "start": 1986.1999999999998, "end": 1990.6, "text": " I like to live life on the edge, haha.", "tokens": [286, 411, 281, 1621, 993, 322, 264, 4691, 11, 17236, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 541, "seek": 197736, "start": 1990.6, "end": 1991.6, "text": " Horrible jokes.", "tokens": [10691, 4457, 14439, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 542, "seek": 197736, "start": 1991.6, "end": 1992.8, "text": " It's a great specialty of mine.", "tokens": [467, 311, 257, 869, 22000, 295, 3892, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 543, "seek": 197736, "start": 1992.8, "end": 1995.9199999999998, "text": " But if you decide to do this the right way, this is how you would normally do it.", "tokens": [583, 498, 291, 4536, 281, 360, 341, 264, 558, 636, 11, 341, 307, 577, 291, 576, 5646, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 544, "seek": 197736, "start": 1995.9199999999998, "end": 1998.6799999999998, "text": " You can pick your buckets for read and write.", "tokens": [509, 393, 1888, 428, 32191, 337, 1401, 293, 2464, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 545, "seek": 197736, "start": 1998.6799999999998, "end": 2003.08, "text": " And you do need to have read and write if you want to use it in this context.", "tokens": [400, 291, 360, 643, 281, 362, 1401, 293, 2464, 498, 291, 528, 281, 764, 309, 294, 341, 4319, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 546, "seek": 197736, "start": 2003.08, "end": 2004.8799999999999, "text": " Because if you just have read, it won't do you any good.", "tokens": [1436, 498, 291, 445, 362, 1401, 11, 309, 1582, 380, 360, 291, 604, 665, 13], "temperature": 0.0, "avg_logprob": -0.13014554017342178, "compression_ratio": 1.6938775510204083, "no_speech_prob": 1.8621125491335988e-05}, {"id": 547, "seek": 200488, "start": 2004.88, "end": 2008.2800000000002, "text": " If you don't have, I mean, I guess you could do one, but then your data is stuck inside", "tokens": [759, 291, 500, 380, 362, 11, 286, 914, 11, 286, 2041, 291, 727, 360, 472, 11, 457, 550, 428, 1412, 307, 5541, 1854], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 548, "seek": 200488, "start": 2008.2800000000002, "end": 2009.44, "text": " and you can't do anything with it.", "tokens": [293, 291, 393, 380, 360, 1340, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 549, "seek": 200488, "start": 2009.44, "end": 2011.16, "text": " So you need both.", "tokens": [407, 291, 643, 1293, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 550, "seek": 200488, "start": 2011.16, "end": 2012.16, "text": " So that's that video.", "tokens": [407, 300, 311, 300, 960, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 551, "seek": 200488, "start": 2012.16, "end": 2015.96, "text": " So I'm going to go back to the end of this.", "tokens": [407, 286, 478, 516, 281, 352, 646, 281, 264, 917, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 552, "seek": 200488, "start": 2015.96, "end": 2016.96, "text": " It's great.", "tokens": [467, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 553, "seek": 200488, "start": 2016.96, "end": 2018.24, "text": " This thing never escapes.", "tokens": [639, 551, 1128, 43769, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 554, "seek": 200488, "start": 2018.24, "end": 2022.3200000000002, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 555, "seek": 200488, "start": 2022.3200000000002, "end": 2024.6000000000001, "text": " Awesome.", "tokens": [10391, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 556, "seek": 200488, "start": 2024.6000000000001, "end": 2027.1200000000001, "text": " So this is our community Slack.", "tokens": [407, 341, 307, 527, 1768, 37211, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 557, "seek": 200488, "start": 2027.1200000000001, "end": 2031.5200000000002, "text": " I'm also going to have a slide next that will have all of the, like it's the one to take", "tokens": [286, 478, 611, 516, 281, 362, 257, 4137, 958, 300, 486, 362, 439, 295, 264, 11, 411, 309, 311, 264, 472, 281, 747], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 558, "seek": 200488, "start": 2031.5200000000002, "end": 2032.5200000000002, "text": " a photo of.", "tokens": [257, 5052, 295, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 559, "seek": 200488, "start": 2032.5200000000002, "end": 2034.48, "text": " You don't need to take any photos of this one.", "tokens": [509, 500, 380, 643, 281, 747, 604, 5787, 295, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.1728368167219491, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.372702849446796e-05}, {"id": 560, "seek": 203448, "start": 2034.48, "end": 2037.72, "text": " But basically you can come join us in our Slack community.", "tokens": [583, 1936, 291, 393, 808, 3917, 505, 294, 527, 37211, 1768, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 561, "seek": 203448, "start": 2037.72, "end": 2038.72, "text": " I'm there.", "tokens": [286, 478, 456, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 562, "seek": 203448, "start": 2038.72, "end": 2039.72, "text": " My coworkers are there.", "tokens": [1222, 43465, 366, 456, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 563, "seek": 203448, "start": 2039.72, "end": 2043.76, "text": " We love to hang out and talk to people and take feedback as well as questions.", "tokens": [492, 959, 281, 3967, 484, 293, 751, 281, 561, 293, 747, 5824, 382, 731, 382, 1651, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 564, "seek": 203448, "start": 2043.76, "end": 2044.92, "text": " It's pretty active.", "tokens": [467, 311, 1238, 4967, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 565, "seek": 203448, "start": 2044.92, "end": 2046.76, "text": " We get like 100 messages a day.", "tokens": [492, 483, 411, 2319, 7897, 257, 786, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 566, "seek": 203448, "start": 2046.76, "end": 2049.72, "text": " So we're always busy in there.", "tokens": [407, 321, 434, 1009, 5856, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 567, "seek": 203448, "start": 2049.72, "end": 2054.84, "text": " And then for getting started yourself, you can obviously head to the Influx community.", "tokens": [400, 550, 337, 1242, 1409, 1803, 11, 291, 393, 2745, 1378, 281, 264, 682, 3423, 2449, 1768, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 568, "seek": 203448, "start": 2054.84, "end": 2058.6, "text": " It has a lot of projects as well as the Influx code base.", "tokens": [467, 575, 257, 688, 295, 4455, 382, 731, 382, 264, 682, 3423, 2449, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 569, "seek": 203448, "start": 2058.6, "end": 2062.2400000000002, "text": " So you can go ahead and download that open source versioning.", "tokens": [407, 291, 393, 352, 2286, 293, 5484, 300, 1269, 4009, 3037, 278, 13], "temperature": 0.0, "avg_logprob": -0.11635956168174744, "compression_ratio": 1.65, "no_speech_prob": 4.2609004594851285e-05}, {"id": 570, "seek": 206224, "start": 2062.24, "end": 2065.04, "text": " And if you want to get started, that's our website, this is also where you're going to", "tokens": [400, 498, 291, 528, 281, 483, 1409, 11, 300, 311, 527, 3144, 11, 341, 307, 611, 689, 291, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.14169527803148543, "compression_ratio": 1.6729323308270676, "no_speech_prob": 1.3205829418438952e-05}, {"id": 571, "seek": 206224, "start": 2065.04, "end": 2068.4799999999996, "text": " find things like our documentation.", "tokens": [915, 721, 411, 527, 14333, 13], "temperature": 0.0, "avg_logprob": -0.14169527803148543, "compression_ratio": 1.6729323308270676, "no_speech_prob": 1.3205829418438952e-05}, {"id": 572, "seek": 206224, "start": 2068.4799999999996, "end": 2071.16, "text": " And this is that slide that I promised that kind of has like everything.", "tokens": [400, 341, 307, 300, 4137, 300, 286, 10768, 300, 733, 295, 575, 411, 1203, 13], "temperature": 0.0, "avg_logprob": -0.14169527803148543, "compression_ratio": 1.6729323308270676, "no_speech_prob": 1.3205829418438952e-05}, {"id": 573, "seek": 206224, "start": 2071.16, "end": 2072.7999999999997, "text": " It makes it really easy.", "tokens": [467, 1669, 309, 534, 1858, 13], "temperature": 0.0, "avg_logprob": -0.14169527803148543, "compression_ratio": 1.6729323308270676, "no_speech_prob": 1.3205829418438952e-05}, {"id": 574, "seek": 206224, "start": 2072.7999999999997, "end": 2079.64, "text": " So for getting started on cloud, if you would like, the community is both the forums and", "tokens": [407, 337, 1242, 1409, 322, 4588, 11, 498, 291, 576, 411, 11, 264, 1768, 307, 1293, 264, 26998, 293], "temperature": 0.0, "avg_logprob": -0.14169527803148543, "compression_ratio": 1.6729323308270676, "no_speech_prob": 1.3205829418438952e-05}, {"id": 575, "seek": 206224, "start": 2079.64, "end": 2080.64, "text": " Slack.", "tokens": [37211, 13], "temperature": 0.0, "avg_logprob": -0.14169527803148543, "compression_ratio": 1.6729323308270676, "no_speech_prob": 1.3205829418438952e-05}, {"id": 576, "seek": 206224, "start": 2080.64, "end": 2081.9599999999996, "text": " Slack is our more active community.", "tokens": [37211, 307, 527, 544, 4967, 1768, 13], "temperature": 0.0, "avg_logprob": -0.14169527803148543, "compression_ratio": 1.6729323308270676, "no_speech_prob": 1.3205829418438952e-05}, {"id": 577, "seek": 206224, "start": 2081.9599999999996, "end": 2089.04, "text": " Our forums are because we can only pay for such an upgraded amount of Slack history storage.", "tokens": [2621, 26998, 366, 570, 321, 393, 787, 1689, 337, 1270, 364, 24133, 2372, 295, 37211, 2503, 6725, 13], "temperature": 0.0, "avg_logprob": -0.14169527803148543, "compression_ratio": 1.6729323308270676, "no_speech_prob": 1.3205829418438952e-05}, {"id": 578, "seek": 208904, "start": 2089.04, "end": 2093.48, "text": " So we put all of our old questions in the forum, so they are a resource that you can", "tokens": [407, 321, 829, 439, 295, 527, 1331, 1651, 294, 264, 17542, 11, 370, 436, 366, 257, 7684, 300, 291, 393], "temperature": 0.0, "avg_logprob": -0.09642144324074328, "compression_ratio": 1.7546583850931676, "no_speech_prob": 9.965851859305985e-06}, {"id": 579, "seek": 208904, "start": 2093.48, "end": 2094.48, "text": " kind of search through.", "tokens": [733, 295, 3164, 807, 13], "temperature": 0.0, "avg_logprob": -0.09642144324074328, "compression_ratio": 1.7546583850931676, "no_speech_prob": 9.965851859305985e-06}, {"id": 580, "seek": 208904, "start": 2094.48, "end": 2098.52, "text": " And if you don't search through it, that's where I search when I answer questions.", "tokens": [400, 498, 291, 500, 380, 3164, 807, 309, 11, 300, 311, 689, 286, 3164, 562, 286, 1867, 1651, 13], "temperature": 0.0, "avg_logprob": -0.09642144324074328, "compression_ratio": 1.7546583850931676, "no_speech_prob": 9.965851859305985e-06}, {"id": 581, "seek": 208904, "start": 2098.52, "end": 2101.08, "text": " And then we also do have the Influx community as well.", "tokens": [400, 550, 321, 611, 360, 362, 264, 682, 3423, 2449, 1768, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.09642144324074328, "compression_ratio": 1.7546583850931676, "no_speech_prob": 9.965851859305985e-06}, {"id": 582, "seek": 208904, "start": 2101.08, "end": 2104.4, "text": " It's basically the one on GitHub where you can find projects that people have worked", "tokens": [467, 311, 1936, 264, 472, 322, 23331, 689, 291, 393, 915, 4455, 300, 561, 362, 2732], "temperature": 0.0, "avg_logprob": -0.09642144324074328, "compression_ratio": 1.7546583850931676, "no_speech_prob": 9.965851859305985e-06}, {"id": 583, "seek": 208904, "start": 2104.4, "end": 2106.6, "text": " on, including ourselves.", "tokens": [322, 11, 3009, 4175, 13], "temperature": 0.0, "avg_logprob": -0.09642144324074328, "compression_ratio": 1.7546583850931676, "no_speech_prob": 9.965851859305985e-06}, {"id": 584, "seek": 208904, "start": 2106.6, "end": 2112.04, "text": " Our book, which basically just goes into things like why you want to use it, the documentation,", "tokens": [2621, 1446, 11, 597, 1936, 445, 1709, 666, 721, 411, 983, 291, 528, 281, 764, 309, 11, 264, 14333, 11], "temperature": 0.0, "avg_logprob": -0.09642144324074328, "compression_ratio": 1.7546583850931676, "no_speech_prob": 9.965851859305985e-06}, {"id": 585, "seek": 208904, "start": 2112.04, "end": 2115.0, "text": " which I've mentioned multiple times because it really goes in depth on how to get this", "tokens": [597, 286, 600, 2835, 3866, 1413, 570, 309, 534, 1709, 294, 7161, 322, 577, 281, 483, 341], "temperature": 0.0, "avg_logprob": -0.09642144324074328, "compression_ratio": 1.7546583850931676, "no_speech_prob": 9.965851859305985e-06}, {"id": 586, "seek": 208904, "start": 2115.0, "end": 2117.44, "text": " project set up and going.", "tokens": [1716, 992, 493, 293, 516, 13], "temperature": 0.0, "avg_logprob": -0.09642144324074328, "compression_ratio": 1.7546583850931676, "no_speech_prob": 9.965851859305985e-06}, {"id": 587, "seek": 211744, "start": 2117.44, "end": 2119.48, "text": " That's where you see things.", "tokens": [663, 311, 689, 291, 536, 721, 13], "temperature": 0.0, "avg_logprob": -0.20113602551546964, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.7065725589636713e-05}, {"id": 588, "seek": 211744, "start": 2119.48, "end": 2123.76, "text": " They have some of our new stuff as well as just, in general, we like to highlight some", "tokens": [814, 362, 512, 295, 527, 777, 1507, 382, 731, 382, 445, 11, 294, 2674, 11, 321, 411, 281, 5078, 512], "temperature": 0.0, "avg_logprob": -0.20113602551546964, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.7065725589636713e-05}, {"id": 589, "seek": 211744, "start": 2123.76, "end": 2126.2000000000003, "text": " of the projects that people are working on.", "tokens": [295, 264, 4455, 300, 561, 366, 1364, 322, 13], "temperature": 0.0, "avg_logprob": -0.20113602551546964, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.7065725589636713e-05}, {"id": 590, "seek": 211744, "start": 2126.2000000000003, "end": 2129.08, "text": " And finally, just our university where you can learn more.", "tokens": [400, 2721, 11, 445, 527, 5454, 689, 291, 393, 1466, 544, 13], "temperature": 0.0, "avg_logprob": -0.20113602551546964, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.7065725589636713e-05}, {"id": 591, "seek": 211744, "start": 2129.08, "end": 2133.52, "text": " It's completely free and go at your own pace.", "tokens": [467, 311, 2584, 1737, 293, 352, 412, 428, 1065, 11638, 13], "temperature": 0.0, "avg_logprob": -0.20113602551546964, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.7065725589636713e-05}, {"id": 592, "seek": 211744, "start": 2133.52, "end": 2138.56, "text": " So now that we've gotten through everything, if anybody has any questions...", "tokens": [407, 586, 300, 321, 600, 5768, 807, 1203, 11, 498, 4472, 575, 604, 1651, 1097], "temperature": 0.0, "avg_logprob": -0.20113602551546964, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.7065725589636713e-05}, {"id": 593, "seek": 213856, "start": 2138.56, "end": 2148.56, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.34362913637745135, "compression_ratio": 1.1504424778761062, "no_speech_prob": 1.1836497833428439e-05}, {"id": 594, "seek": 213856, "start": 2148.56, "end": 2160.96, "text": " Yeah, so I'll go ahead... Oh, that's not what I wanted.", "tokens": [865, 11, 370, 286, 603, 352, 2286, 1097, 876, 11, 300, 311, 406, 437, 286, 1415, 13], "temperature": 0.0, "avg_logprob": -0.34362913637745135, "compression_ratio": 1.1504424778761062, "no_speech_prob": 1.1836497833428439e-05}, {"id": 595, "seek": 213856, "start": 2160.96, "end": 2161.96, "text": " No.", "tokens": [883, 13], "temperature": 0.0, "avg_logprob": -0.34362913637745135, "compression_ratio": 1.1504424778761062, "no_speech_prob": 1.1836497833428439e-05}, {"id": 596, "seek": 213856, "start": 2161.96, "end": 2163.84, "text": " It's just taking me back to that stupid drive video.", "tokens": [467, 311, 445, 1940, 385, 646, 281, 300, 6631, 3332, 960, 13], "temperature": 0.0, "avg_logprob": -0.34362913637745135, "compression_ratio": 1.1504424778761062, "no_speech_prob": 1.1836497833428439e-05}, {"id": 597, "seek": 213856, "start": 2163.84, "end": 2165.4, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.34362913637745135, "compression_ratio": 1.1504424778761062, "no_speech_prob": 1.1836497833428439e-05}, {"id": 598, "seek": 216540, "start": 2165.4, "end": 2168.96, "text": " So yeah, so this is that Influx community plant buddy project.", "tokens": [407, 1338, 11, 370, 341, 307, 300, 682, 3423, 2449, 1768, 3709, 10340, 1716, 13], "temperature": 0.0, "avg_logprob": -0.13266243422326962, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.776626413629856e-05}, {"id": 599, "seek": 216540, "start": 2168.96, "end": 2170.08, "text": " So the master branch.", "tokens": [407, 264, 4505, 9819, 13], "temperature": 0.0, "avg_logprob": -0.13266243422326962, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.776626413629856e-05}, {"id": 600, "seek": 216540, "start": 2170.08, "end": 2175.64, "text": " And then we also have, so for example, down here we talk about the control boards.", "tokens": [400, 550, 321, 611, 362, 11, 370, 337, 1365, 11, 760, 510, 321, 751, 466, 264, 1969, 13293, 13], "temperature": 0.0, "avg_logprob": -0.13266243422326962, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.776626413629856e-05}, {"id": 601, "seek": 216540, "start": 2175.64, "end": 2177.64, "text": " So we've got the Arduino or the Boron.", "tokens": [407, 321, 600, 658, 264, 39539, 420, 264, 13739, 266, 13], "temperature": 0.0, "avg_logprob": -0.13266243422326962, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.776626413629856e-05}, {"id": 602, "seek": 216540, "start": 2177.64, "end": 2179.8, "text": " And then we have an entire sensor list.", "tokens": [400, 550, 321, 362, 364, 2302, 10200, 1329, 13], "temperature": 0.0, "avg_logprob": -0.13266243422326962, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.776626413629856e-05}, {"id": 603, "seek": 216540, "start": 2179.8, "end": 2184.04, "text": " So for example, if I click on this one, it harasses me for cookies.", "tokens": [407, 337, 1365, 11, 498, 286, 2052, 322, 341, 472, 11, 309, 16910, 279, 385, 337, 13670, 13], "temperature": 0.0, "avg_logprob": -0.13266243422326962, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.776626413629856e-05}, {"id": 604, "seek": 216540, "start": 2184.04, "end": 2186.84, "text": " It goes into the temperature sensor.", "tokens": [467, 1709, 666, 264, 4292, 10200, 13], "temperature": 0.0, "avg_logprob": -0.13266243422326962, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.776626413629856e-05}, {"id": 605, "seek": 216540, "start": 2186.84, "end": 2191.84, "text": " So you can go ahead and learn about all the different sensors that we use for this project.", "tokens": [407, 291, 393, 352, 2286, 293, 1466, 466, 439, 264, 819, 14840, 300, 321, 764, 337, 341, 1716, 13], "temperature": 0.0, "avg_logprob": -0.13266243422326962, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.776626413629856e-05}, {"id": 606, "seek": 219184, "start": 2191.84, "end": 2196.92, "text": " You can also obviously search them up on the internet and buy them if you desire.", "tokens": [509, 393, 611, 2745, 3164, 552, 493, 322, 264, 4705, 293, 2256, 552, 498, 291, 7516, 13], "temperature": 0.0, "avg_logprob": -0.12216191864013672, "compression_ratio": 1.6892857142857143, "no_speech_prob": 4.978598371963017e-05}, {"id": 607, "seek": 219184, "start": 2196.92, "end": 2200.6000000000004, "text": " And you can use many different types of sensors, but these just happen to be the four that", "tokens": [400, 291, 393, 764, 867, 819, 3467, 295, 14840, 11, 457, 613, 445, 1051, 281, 312, 264, 1451, 300], "temperature": 0.0, "avg_logprob": -0.12216191864013672, "compression_ratio": 1.6892857142857143, "no_speech_prob": 4.978598371963017e-05}, {"id": 608, "seek": 219184, "start": 2200.6000000000004, "end": 2203.4, "text": " we just wanted to end up using.", "tokens": [321, 445, 1415, 281, 917, 493, 1228, 13], "temperature": 0.0, "avg_logprob": -0.12216191864013672, "compression_ratio": 1.6892857142857143, "no_speech_prob": 4.978598371963017e-05}, {"id": 609, "seek": 219184, "start": 2203.4, "end": 2206.8, "text": " And like I said before, in this project, we have, yes, the master branch, and then we", "tokens": [400, 411, 286, 848, 949, 11, 294, 341, 1716, 11, 321, 362, 11, 2086, 11, 264, 4505, 9819, 11, 293, 550, 321], "temperature": 0.0, "avg_logprob": -0.12216191864013672, "compression_ratio": 1.6892857142857143, "no_speech_prob": 4.978598371963017e-05}, {"id": 610, "seek": 219184, "start": 2206.8, "end": 2214.08, "text": " also have things like EDR, which is edge data replication, Kafka, and then a few others.", "tokens": [611, 362, 721, 411, 462, 9301, 11, 597, 307, 4691, 1412, 39911, 11, 47064, 11, 293, 550, 257, 1326, 2357, 13], "temperature": 0.0, "avg_logprob": -0.12216191864013672, "compression_ratio": 1.6892857142857143, "no_speech_prob": 4.978598371963017e-05}, {"id": 611, "seek": 219184, "start": 2214.08, "end": 2216.1200000000003, "text": " I normally end up in the master branch.", "tokens": [286, 5646, 917, 493, 294, 264, 4505, 9819, 13], "temperature": 0.0, "avg_logprob": -0.12216191864013672, "compression_ratio": 1.6892857142857143, "no_speech_prob": 4.978598371963017e-05}, {"id": 612, "seek": 219184, "start": 2216.1200000000003, "end": 2219.92, "text": " It's kind of like the main versioning of the project.", "tokens": [467, 311, 733, 295, 411, 264, 2135, 3037, 278, 295, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.12216191864013672, "compression_ratio": 1.6892857142857143, "no_speech_prob": 4.978598371963017e-05}, {"id": 613, "seek": 221992, "start": 2219.92, "end": 2224.7200000000003, "text": " And yeah, and then in the future, the SQL one that I was telling you about, that's going", "tokens": [400, 1338, 11, 293, 550, 294, 264, 2027, 11, 264, 19200, 472, 300, 286, 390, 3585, 291, 466, 11, 300, 311, 516], "temperature": 0.0, "avg_logprob": -0.2465454151755885, "compression_ratio": 1.3727810650887573, "no_speech_prob": 3.757931335712783e-05}, {"id": 614, "seek": 221992, "start": 2224.7200000000003, "end": 2226.12, "text": " to be EDR IOX.", "tokens": [281, 312, 462, 9301, 39839, 55, 13], "temperature": 0.0, "avg_logprob": -0.2465454151755885, "compression_ratio": 1.3727810650887573, "no_speech_prob": 3.757931335712783e-05}, {"id": 615, "seek": 221992, "start": 2226.12, "end": 2229.64, "text": " It's still currently being worked on as I speak, actually.", "tokens": [467, 311, 920, 4362, 885, 2732, 322, 382, 286, 1710, 11, 767, 13], "temperature": 0.0, "avg_logprob": -0.2465454151755885, "compression_ratio": 1.3727810650887573, "no_speech_prob": 3.757931335712783e-05}, {"id": 616, "seek": 221992, "start": 2229.64, "end": 2234.04, "text": " So that one is not to be touched yet, until it's all done.", "tokens": [407, 300, 472, 307, 406, 281, 312, 9828, 1939, 11, 1826, 309, 311, 439, 1096, 13], "temperature": 0.0, "avg_logprob": -0.2465454151755885, "compression_ratio": 1.3727810650887573, "no_speech_prob": 3.757931335712783e-05}, {"id": 617, "seek": 221992, "start": 2234.04, "end": 2235.04, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.2465454151755885, "compression_ratio": 1.3727810650887573, "no_speech_prob": 3.757931335712783e-05}, {"id": 618, "seek": 221992, "start": 2235.04, "end": 2236.04, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2465454151755885, "compression_ratio": 1.3727810650887573, "no_speech_prob": 3.757931335712783e-05}, {"id": 619, "seek": 223604, "start": 2236.04, "end": 2250.88, "text": " So the question was, how is InfluxDB different than OpenTSB?", "tokens": [407, 264, 1168, 390, 11, 577, 307, 682, 3423, 2449, 27735, 819, 813, 7238, 7327, 33, 30], "temperature": 0.0, "avg_logprob": -0.19418900353567942, "compression_ratio": 1.4213197969543148, "no_speech_prob": 2.5834628104348667e-05}, {"id": 620, "seek": 223604, "start": 2250.88, "end": 2255.12, "text": " Sorry, TSTB, there we go.", "tokens": [4919, 11, 314, 6840, 33, 11, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.19418900353567942, "compression_ratio": 1.4213197969543148, "no_speech_prob": 2.5834628104348667e-05}, {"id": 621, "seek": 223604, "start": 2255.12, "end": 2259.6, "text": " So from what I understand, TSTB is also an open source time series database, just like", "tokens": [407, 490, 437, 286, 1223, 11, 314, 6840, 33, 307, 611, 364, 1269, 4009, 565, 2638, 8149, 11, 445, 411], "temperature": 0.0, "avg_logprob": -0.19418900353567942, "compression_ratio": 1.4213197969543148, "no_speech_prob": 2.5834628104348667e-05}, {"id": 622, "seek": 223604, "start": 2259.6, "end": 2260.6, "text": " we are.", "tokens": [321, 366, 13], "temperature": 0.0, "avg_logprob": -0.19418900353567942, "compression_ratio": 1.4213197969543148, "no_speech_prob": 2.5834628104348667e-05}, {"id": 623, "seek": 223604, "start": 2260.6, "end": 2264.48, "text": " I think the biggest difference is going to be how much functionality it comes out of", "tokens": [286, 519, 264, 3880, 2649, 307, 516, 281, 312, 577, 709, 14980, 309, 1487, 484, 295], "temperature": 0.0, "avg_logprob": -0.19418900353567942, "compression_ratio": 1.4213197969543148, "no_speech_prob": 2.5834628104348667e-05}, {"id": 624, "seek": 223604, "start": 2264.48, "end": 2265.48, "text": " the box with.", "tokens": [264, 2424, 365, 13], "temperature": 0.0, "avg_logprob": -0.19418900353567942, "compression_ratio": 1.4213197969543148, "no_speech_prob": 2.5834628104348667e-05}, {"id": 625, "seek": 226548, "start": 2265.48, "end": 2270.2, "text": " I would obviously have to go to their actual code and check it out a little bit further.", "tokens": [286, 576, 2745, 362, 281, 352, 281, 641, 3539, 3089, 293, 1520, 309, 484, 257, 707, 857, 3052, 13], "temperature": 0.0, "avg_logprob": -0.10242134240957407, "compression_ratio": 1.694267515923567, "no_speech_prob": 3.940177339245565e-05}, {"id": 626, "seek": 226548, "start": 2270.2, "end": 2278.04, "text": " But normally the big thing that's our differentiator is the fact that we can, we actually have", "tokens": [583, 5646, 264, 955, 551, 300, 311, 527, 27372, 1639, 307, 264, 1186, 300, 321, 393, 11, 321, 767, 362], "temperature": 0.0, "avg_logprob": -0.10242134240957407, "compression_ratio": 1.694267515923567, "no_speech_prob": 3.940177339245565e-05}, {"id": 627, "seek": 226548, "start": 2278.04, "end": 2279.36, "text": " our own visualizations.", "tokens": [527, 1065, 5056, 14455, 13], "temperature": 0.0, "avg_logprob": -0.10242134240957407, "compression_ratio": 1.694267515923567, "no_speech_prob": 3.940177339245565e-05}, {"id": 628, "seek": 226548, "start": 2279.36, "end": 2283.8, "text": " We have our own ability with Flux to do things like alerting, like that moisture alerting", "tokens": [492, 362, 527, 1065, 3485, 365, 3235, 2449, 281, 360, 721, 411, 419, 27187, 11, 411, 300, 13814, 419, 27187], "temperature": 0.0, "avg_logprob": -0.10242134240957407, "compression_ratio": 1.694267515923567, "no_speech_prob": 3.940177339245565e-05}, {"id": 629, "seek": 226548, "start": 2283.8, "end": 2285.84, "text": " that I was talking about before.", "tokens": [300, 286, 390, 1417, 466, 949, 13], "temperature": 0.0, "avg_logprob": -0.10242134240957407, "compression_ratio": 1.694267515923567, "no_speech_prob": 3.940177339245565e-05}, {"id": 630, "seek": 226548, "start": 2285.84, "end": 2289.4, "text": " And then with the new SQL integration, that will also be very nice for people who want", "tokens": [400, 550, 365, 264, 777, 19200, 10980, 11, 300, 486, 611, 312, 588, 1481, 337, 561, 567, 528], "temperature": 0.0, "avg_logprob": -0.10242134240957407, "compression_ratio": 1.694267515923567, "no_speech_prob": 3.940177339245565e-05}, {"id": 631, "seek": 226548, "start": 2289.4, "end": 2290.92, "text": " to query in a language.", "tokens": [281, 14581, 294, 257, 2856, 13], "temperature": 0.0, "avg_logprob": -0.10242134240957407, "compression_ratio": 1.694267515923567, "no_speech_prob": 3.940177339245565e-05}, {"id": 632, "seek": 226548, "start": 2290.92, "end": 2295.08, "text": " Most people are already familiar with querying in when it comes to working with databases.", "tokens": [4534, 561, 366, 1217, 4963, 365, 7083, 1840, 294, 562, 309, 1487, 281, 1364, 365, 22380, 13], "temperature": 0.0, "avg_logprob": -0.10242134240957407, "compression_ratio": 1.694267515923567, "no_speech_prob": 3.940177339245565e-05}, {"id": 633, "seek": 229508, "start": 2295.08, "end": 2299.64, "text": " But to be honest, a lot of time series DBs can be pretty comparable when it actually", "tokens": [583, 281, 312, 3245, 11, 257, 688, 295, 565, 2638, 26754, 82, 393, 312, 1238, 25323, 562, 309, 767], "temperature": 0.0, "avg_logprob": -0.08660831621715001, "compression_ratio": 1.6779026217228465, "no_speech_prob": 3.530352478264831e-05}, {"id": 634, "seek": 229508, "start": 2299.64, "end": 2301.44, "text": " comes to the storage.", "tokens": [1487, 281, 264, 6725, 13], "temperature": 0.0, "avg_logprob": -0.08660831621715001, "compression_ratio": 1.6779026217228465, "no_speech_prob": 3.530352478264831e-05}, {"id": 635, "seek": 229508, "start": 2301.44, "end": 2306.16, "text": " So it's going to depend somewhat on your project and which one you want to, I suppose, work", "tokens": [407, 309, 311, 516, 281, 5672, 8344, 322, 428, 1716, 293, 597, 472, 291, 528, 281, 11, 286, 7297, 11, 589], "temperature": 0.0, "avg_logprob": -0.08660831621715001, "compression_ratio": 1.6779026217228465, "no_speech_prob": 3.530352478264831e-05}, {"id": 636, "seek": 229508, "start": 2306.16, "end": 2307.16, "text": " with.", "tokens": [365, 13], "temperature": 0.0, "avg_logprob": -0.08660831621715001, "compression_ratio": 1.6779026217228465, "no_speech_prob": 3.530352478264831e-05}, {"id": 637, "seek": 229508, "start": 2307.16, "end": 2311.72, "text": " A lot of people normally like to, I normally do get told that we have pretty good documentation", "tokens": [316, 688, 295, 561, 5646, 411, 281, 11, 286, 5646, 360, 483, 1907, 300, 321, 362, 1238, 665, 14333], "temperature": 0.0, "avg_logprob": -0.08660831621715001, "compression_ratio": 1.6779026217228465, "no_speech_prob": 3.530352478264831e-05}, {"id": 638, "seek": 229508, "start": 2311.72, "end": 2315.4, "text": " and a good community where we're very easy to work with and work through problems.", "tokens": [293, 257, 665, 1768, 689, 321, 434, 588, 1858, 281, 589, 365, 293, 589, 807, 2740, 13], "temperature": 0.0, "avg_logprob": -0.08660831621715001, "compression_ratio": 1.6779026217228465, "no_speech_prob": 3.530352478264831e-05}, {"id": 639, "seek": 229508, "start": 2315.4, "end": 2322.7999999999997, "text": " And that's not always the case with every open source community.", "tokens": [400, 300, 311, 406, 1009, 264, 1389, 365, 633, 1269, 4009, 1768, 13], "temperature": 0.0, "avg_logprob": -0.08660831621715001, "compression_ratio": 1.6779026217228465, "no_speech_prob": 3.530352478264831e-05}, {"id": 640, "seek": 232280, "start": 2322.8, "end": 2330.28, "text": " If anybody else has any other questions.", "tokens": [759, 4472, 1646, 575, 604, 661, 1651, 13], "temperature": 0.0, "avg_logprob": -0.22739139556884766, "compression_ratio": 1.3695652173913044, "no_speech_prob": 2.6623471057973802e-05}, {"id": 641, "seek": 232280, "start": 2330.28, "end": 2335.1200000000003, "text": " If not, that's totally fine too, because that all gives you guys time to run off to the", "tokens": [759, 406, 11, 300, 311, 3879, 2489, 886, 11, 570, 300, 439, 2709, 291, 1074, 565, 281, 1190, 766, 281, 264], "temperature": 0.0, "avg_logprob": -0.22739139556884766, "compression_ratio": 1.3695652173913044, "no_speech_prob": 2.6623471057973802e-05}, {"id": 642, "seek": 232280, "start": 2335.1200000000003, "end": 2341.32, "text": " next talks or maybe go grab some lunch from the food trucks.", "tokens": [958, 6686, 420, 1310, 352, 4444, 512, 6349, 490, 264, 1755, 16156, 13], "temperature": 0.0, "avg_logprob": -0.22739139556884766, "compression_ratio": 1.3695652173913044, "no_speech_prob": 2.6623471057973802e-05}, {"id": 643, "seek": 234132, "start": 2341.32, "end": 2360.4, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 1.0, "avg_logprob": -1.457735470363072, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.0005525900633074343}], "language": "en"}