{"text": " All right, we'll get started with the next talk. Julia Anon from Paratools is going to talk about testing and validation. Hello, everyone. Thanks again for the introduction. So, yes, I'm Julia Anon. I'm going to talk to you about testing. As you may notice, I'm a bit happy to have a mic today. So, please let me know if I'm becoming unreadable. So, first of all, a bit of background, back in some years ago, we were actually, we still had a team developing an MPI runtime, and while developing this runtime, we had the major stake to develop a validation system to assess our software quality, but also to be able to compare our implementation to others. So, like everybody in HPC field at this time, we started to build our own ultra-specific shell scripts to validate our implementation, because we were considering that our implementation were too specific to be able to use some mainstream tools. So, we started with self-scripts, great idea. The fact is that with the team growing, people working in a separate place, working on multiple heterogeneous machines, we had a huge issue to make people continue to validate, to use this validation system, because it was slow, not really efficient, and hard to make it grow. Especially about maintenance, when we wanted to add anything from to the validation process, it was just a nightmare, it was really costly in term of time, but also when our software was evolving, was growing, just adding, just a little test into this non-requestion based was a nightmare. So, we started to consider why not creating a validation system able to take care of HPC environment, and what it implies, like validating on multiple architecture, multiple machine by multiple users, with multiple benchmarks, and we just thought about having a generic tool able to handle all of that at what point. So, what we want in that scenario, we are here in the case of validating an MPI implementation, which means having a standard API, okay, so there is a lot of well-known MPI benchmarks already existing, we don't have to rewrite a whole non-requestion, we have benchmarks, you have proxy applications, and so on, so how to scale these benchmarks to any runtime or any project using them to build a proper validation process. So, what people want, I mean, what users of this validation system want, it's a simple tool. You don't want to have really complex Q, GTK, any kind of complex architecture to deploy to test. So, what we want is just a command line interface, basically, and really, really, really few setup, really, really, really few configuration to deploy to have such test working, because a lot, maybe it's not a generality here, but a lot of people hate tests, basically, so we have to convince them that testing is good for software quality, something really simple, but also able to handle any really complex scenario we may find in HPC, running an MPI application is not that hard, but it may become really, really complex, and we don't want to have to rewrite our, I use this tool every two years, because a new technology, a new approach, a new paradigm is implemented, and the validation process should have to be rewriting. So, from that state, we decided to write a tool to fit our needs, but to be able to be used by people meeting the same requirements. Before going further, I would like to tell you that testing is not a brand new field, and some other projects are tackling such kind of issue until now, and so please take a look at them, if you think that PCVS does not completely fit your needs, they are really, really powerful tools in the field. So today, I'm here to talk to you about PCVS. It's a tool maintained by the CEA, it's retained in Python, yes, everything is in Python now, so we are based on Python, it's a simple command line interface, and with few configuration files, obviously in EML, it's a trend, the design of this framework, the testing framework is to be, to bring simplicity when writing test logic to users, so we want tests to be simple to write, easy to port, okay, and these benchmarks, written by the user, we want to be able to be run in multiple environments, so we don't want to bound a test suite to a given application, let's consider MPI run time, we don't want to have our Lulesh or our IMB benchmark bound to a specific MPI implementation to be run on any kind of architecture. So this is what we call in PCVS, the retargeting approach, the other approach we want to focus on is the fact that we have heterogeneous test environments, we have benchmarks, how to scale, automatically scale this benchmark to the actual test environment, consider, for example, having users wanting to validate the IMB, but they are working on their work session, we don't want to launch up to, I don't know, 100 MPI processes on their work session, they're going to be not happy with you squashing their machine, but once this validation system is run on a real HPC cluster, you want the test suite to automatically scale to this supercomputer resources without having to rewrite 100 of configuration files, or even one file is already too much, okay. So this work is maintained by the CEA, which is a French research administration, and we are collaborating with us, with them, I'm sorry, to make this tool more generic or not generic and attempt to make as many users as possible, as many users as possible. So at Eglance, some feature specificities provide, the idea is to split the test effort into specific fields, the first one is the specification of test, what a benchmark need to expose to build the test, so this kind of information is carried by the benchmark, obviously, how to build, what is the program, what are the parameters, and so on. And the environment, it's a testing environment, here is carried by the people deploying or providing the testing resources, so most of the time it's just a team policy to schedule jobs, or our system admins, right, all of this to pursue two goals, still the retargeting of tests automatically when the user is calling this benchmark, depending on the compiler and run time you want to target, and auto scaling test to test environment. Obviously, as PCVS is a kind of test framework, we add to add some functionality around testing, like in-place reporting, because most users are running their tests on HPC cluster where the set of functionality can be restrained, so they don't have access to all their GitLab, GitHub, Gira and so on stuff, so we add some basic tools to answer these needs, and beyond a single execution validation run, we added a way to build the history of the validation for a given application by storing results over time, and allowing the user to run simple analysis, still in Python, to produce statistics over time. So quickly, the architecture of PCVS, it's based on files, so Bison CLI, so Bison file system, it's parsing some user inputs, and it's run through a dedicated connector to mainly SLURM currently, mainly SLURM, but we are focusing on supporting as a batch manager. So the idea is that the benchmark express job descriptions and resource requirements and the environment will provide resources. Let's consider, for example, a basic component called number of MPI tasks the job is taking, the job will say, okay, my job is only running up to two processes, or it's only taking, I don't know, cubic value of MPI processes, people are aware of users of the Lulech proxy application will know what I mean by cubic, so it will describe constraints, and then we will have environment configuration files called profile in PCVS, where the admin will say, okay, in that context, I will have up to 100 nodes, so you will be able to spawn up to 100 MPI processes to run your application. Based on that, PCVS will cross this information and will say, okay, I have MPI jobs, I can run up to 1000 MPI processes based on this specification, why not running the user benchmark 100 times once for each combination. PCVS is an as an opt out approach, so it will consider that every combination provided by the environment will be used to scale your tests, okay, so if your test is not able to run up to 1000 jobs, it's up to you to specify that you can't reach this limit. So here is a quick example, I don't know if you can see up there, but we have a really, really basic environment configuration where you can see that there is what we call an operator, this is a variadic component, and it can take up to 4 values for the NMPI attributes and when describing a simple job, we're just saying, okay, my job just consists in running a program, PCVS will enroll up to 4 common lines to run 4 independent tests to execute. So PCVS will automatically build your test scenarios based on your specification. So how to basically write a test, but more specifically a compilation test, there is a lot of things to customize or you can build your tests, so it looks complicated, but as you may see on the previous slide, all the keys in that TML are not mandatory, at least the files one, obviously you have to specify which kind of application you want to compile, so the framework will try to auto detect your language to select the proper compiler, obviously you have a manually designed approach also. If you are not based on compiling source files but already using a well-known build system, we have also an interface to invoke directly build system to build your framework. I'm thinking about, for example, Lulesh, which is using a Mac file, DIMB using a Mac file, or even the Mpitch test suite using a Configure Mac-Macon style approach. So you have many options, all of them are optional. What I would like to highlight is a variant. What a variant, it's a capability from PCVS to expose to job, to benchmarks, a specificity or requirement this job has to be run. So in that case, the OpenMP keyword probably means something to everyone here, but it just you know a token saying that to run this job, the variant, the component OpenMP is required to be scheduled and in the environment, the user will say, okay, what is my variant OpenMP in case of GCC, GCC like compiler, it will be dash f OpenMP if it's Intel, it's not the same option. You see the ID? I will add, PCVS will add Flavor depending on what you have specified in your environment. How to write a run test. So this is where the component, the iterative component takes place, we didn't port it yet on CompilationModel because we have issues with the race condition reaching the same file on the file system, but we are planning to containerize, to encapsulate, to isolate such model to be able to support also CompilationTest, I'm sorry. So what as a user have to do to integrate such test in your workflow, just write a PCVS.yml file, you put it anywhere you want in your pass, I mean your benchmark pass, and it looks like just a run node and everything below is totally optional. Here we can see that we restrict, we restrict our add.out program to specific MPI values because as a tester, I know that my test has this constraint. You can even create this variadic component for your own application if you want to programmatically generate a list of scenario that PCVS should integrate to its own process to build multiple scenarios. So in that case, with this, I'm sorry, why am I moving in the program node, you'll see that with this three simple lines, it will be able to build three times the number of scenarios that you were expected to have initially, right? And what a test without having a way to express or validate a test, obviously. So for any test, not only for run, you have a YAML description to say, okay, so I want my job to exit with this particular return code, having an execution time within this range matching or not matching this kind of pattern. Even here is my script, give him the regular output of my test and I will tell you if it's okay or not. Okay, so I just write my test, how to run them now. It's just celibate, so you just have to call PCVS run, but before running my benchmark, I just have to create a profile to express the resources my environment has. Obviously, in case of MPI, we provided some templates, some basic templates to initiate the testing process. So here, we are just creating a profile named my MPI based just on MPI. So by quickly running that, I will have a full profile based on MPI running tests for one, two, three, and four MPI processes, but from that, you can then expand the profile to fit your needs. The whole build of PCVS relies on a single directory. And in that directory, you will find anything required to analyze the results and even rerun in the same condition the tests for reproducibility. You can see on the right, repository we provided alongside with PCVS, which is called PCVS benchmarks, and we attempt to put in that repository many well-known MPI benchmarks, PCVS enabled, right? So here is a fancy view of PCVS. Obviously, there is many options when running a validation. You can have an interactive approach, non-interactive approach, slur enabled, I mean, batch manager enabled, running inside an allocation, outside an allocation, and once the whole configuration has been generated, we have commands, especially a PCVS exec, to interact independently, uniquely with your benchmarks, so for instance, what people are used to do is to run their validation and after maybe 10 seconds, some failures appear, and they would like, without interrupting the non-requestion system. But rerun in an isolated environment, their tests to see why it failed. So we have some extra commands to rerun this special pattern, okay? Obviously, I'm going to just pick it up, obviously, everything is not always perfect, and the static approach of the ML file is not what you need, you would like something more dynamic because you have some stuff to interpret, to read, to process before knowing what you want to test, even within a benchmark. So we have a dynamic approach. Instead of providing a static ML file, you will provide an executable script, an executable file, whatever it is, and it will produce by itself the actual ML file. This way, you can programmatically generate your benchmark suite without having to know it in advance, without knowing in which environment your non-requestion base will be run. Let's consider the NAS framework, where within the name of the binary bit, you have the number of MPI processes, cool. You know, we have run our tests, but we would like to see what it looks like, okay? We have a test framework, not just a job runner. So obviously, we had some tools to report results to the user, spoiler, cannot be compared with real tools for that, okay? And the idea is just to offer a way to users to grab their results directly on their machine, in place, okay? And essentially, it's just a way to look at tests at a glance to be able to rerun if necessary in the process. So as I said, we can isolate and rerun independently jobs, which is pretty convenient when some failure want to be explored right away. And in FINE, we are using a web server to report in a web browser directly, offering more interactivity for your results. So what it looks like, for example, here, gathered by Label, you can see that there is some red, so some failures. Let's dive into it. You can see that some trouble with MPIO, what a surprise. And when clicking a job, you'll see the complete log of this trend, so the command line and the actual, so I truncated, I'm sorry, I truncated the actual error, and you can directly dive into the error without leaving your actual SSH terminal. So a quick overview of how to configure your site, so the test environment configuration part. This is also AML, you will define directly compilers, compiler and run times, and the special variadic component here. It's split in five different modules, why? Because this whole profile can be split up to five blocks, independent blocks, we can be distributed over a cluster because it's not always the same teams who are responsible of this particular block. Let's consider, for example, the variadic component, it's in charge of the team to build this list, while for the compiler and run time, it may be in charge of the C side means of the test environment machine. And after running a single job, what I would like to see is to have a trend over multiple run, all my test suite behave, and in PCVS we integrated a way of using to stack multiple runs over time, and then run analysis on them, to build trends, to have more things than just a test result, but a test result over time. So here is an example of what you can do afterwards, running analysis directly on this storized pass, and this is enabled thanks to, I would like to call that a DSL, but actually just a Python API to interact with that, and you can build such beautiful graphics to see over time the rates of success inside your test benchmark. So finally, just a quick glance at the SPAC plus PCVS. We are not in SPAC, but we are supporting SPAC, especially to do such things by specifying a simple package, a simple spec package, we will be able to check any combination of building this package to see if there is some curiosity into your package recipe. For future work, we have many things scheduled, and most of the most interesting in the capture in metrics, the capacity to PCVS to capture directly some metadata to be able to then run analysis on them, and many other things, but I think I'm running out of time. Thanks for your attention, I have two questions. From your configuration file, I assume you already have control of the cluster, at least you have allocated some nodes or something. Do you have some step that then allocates and deallocates these resources on the fly for each one of the tests? So actually, currently, most of our test scenario has run through an MPI run with slurm enabled or srun commands directly, so they are taking care of the resource allocations. Some other users are just running the whole PCVS inside a given allocation, like resource allocation, just a saloc, for example, and then any test doing srun does not pay the cost of waiting the actual speed. If some tests need some type of CPU, the other tests need other type of CPU, then you need to, and if one of them is unavailable because an other user is using, you have to wait instead of fail. Yes, this is something we still haven't had a solution for, would be to be able to put a job aside while we have the allocation. Yes, this is something we are currently investigating, absolutely. Do you have any questions? Yeah, so one thing that I wanted to ask was kind of for your future work you had mentioned building out a graphical front end using textualize, I was kind of wondering how much assessment have you done into that, because I've done some work like trying to build GUIs with textualize and while I do think that it's very interesting framework and it's great for making textual GUIs, I think that it still has a bit of a way to come before it can really make a standalone or comprehensive seal or a textual interface, so I was just wondering what your thoughts were on that. I'm not sure, I understand the whole question, but you mean, why did we choose textualize? Absolutely, we discovered just recently because we were using Rich to highlight the output of PCVS within the console and we are looking for a solution to present the things graphically in a terminal and we still are looking for the ideal framework and as Rich is already as textualize, I'm sorry, it's based on that, we are considering textualize, but if you have any other offer to propose, I would be happy to discuss with you about that. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.200000000000001, "text": " All right, we'll get started with the next talk.", "tokens": [1057, 558, 11, 321, 603, 483, 1409, 365, 264, 958, 751, 13], "temperature": 0.0, "avg_logprob": -0.30631900283525576, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.2462158352136612}, {"id": 1, "seek": 0, "start": 9.200000000000001, "end": 12.8, "text": " Julia Anon from Paratools is going to talk about testing and validation.", "tokens": [18551, 1107, 266, 490, 3457, 267, 29298, 307, 516, 281, 751, 466, 4997, 293, 24071, 13], "temperature": 0.0, "avg_logprob": -0.30631900283525576, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.2462158352136612}, {"id": 2, "seek": 0, "start": 12.8, "end": 13.8, "text": " Hello, everyone.", "tokens": [2425, 11, 1518, 13], "temperature": 0.0, "avg_logprob": -0.30631900283525576, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.2462158352136612}, {"id": 3, "seek": 0, "start": 13.8, "end": 14.8, "text": " Thanks again for the introduction.", "tokens": [2561, 797, 337, 264, 9339, 13], "temperature": 0.0, "avg_logprob": -0.30631900283525576, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.2462158352136612}, {"id": 4, "seek": 0, "start": 14.8, "end": 15.8, "text": " So, yes, I'm Julia Anon.", "tokens": [407, 11, 2086, 11, 286, 478, 18551, 1107, 266, 13], "temperature": 0.0, "avg_logprob": -0.30631900283525576, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.2462158352136612}, {"id": 5, "seek": 0, "start": 15.8, "end": 16.8, "text": " I'm going to talk to you about testing.", "tokens": [286, 478, 516, 281, 751, 281, 291, 466, 4997, 13], "temperature": 0.0, "avg_logprob": -0.30631900283525576, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.2462158352136612}, {"id": 6, "seek": 0, "start": 16.8, "end": 17.8, "text": " As you may notice, I'm a bit happy to have a mic today.", "tokens": [1018, 291, 815, 3449, 11, 286, 478, 257, 857, 2055, 281, 362, 257, 3123, 965, 13], "temperature": 0.0, "avg_logprob": -0.30631900283525576, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.2462158352136612}, {"id": 7, "seek": 0, "start": 17.8, "end": 18.8, "text": " So, please let me know if I'm becoming unreadable.", "tokens": [407, 11, 1767, 718, 385, 458, 498, 286, 478, 5617, 517, 2538, 712, 13], "temperature": 0.0, "avg_logprob": -0.30631900283525576, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.2462158352136612}, {"id": 8, "seek": 1880, "start": 18.8, "end": 40.92, "text": " So, first of all, a bit of background, back in some years ago, we were actually, we still", "tokens": [407, 11, 700, 295, 439, 11, 257, 857, 295, 3678, 11, 646, 294, 512, 924, 2057, 11, 321, 645, 767, 11, 321, 920], "temperature": 0.0, "avg_logprob": -0.4207671483357747, "compression_ratio": 1.1265822784810127, "no_speech_prob": 0.0027924326714128256}, {"id": 9, "seek": 4092, "start": 40.92, "end": 49.72, "text": " had a team developing an MPI runtime, and while developing this runtime, we had the major", "tokens": [632, 257, 1469, 6416, 364, 14146, 40, 34474, 11, 293, 1339, 6416, 341, 34474, 11, 321, 632, 264, 2563], "temperature": 0.0, "avg_logprob": -0.21586916897747968, "compression_ratio": 1.54, "no_speech_prob": 0.00029937649378553033}, {"id": 10, "seek": 4092, "start": 49.72, "end": 56.68, "text": " stake to develop a validation system to assess our software quality, but also to be able", "tokens": [10407, 281, 1499, 257, 24071, 1185, 281, 5877, 527, 4722, 3125, 11, 457, 611, 281, 312, 1075], "temperature": 0.0, "avg_logprob": -0.21586916897747968, "compression_ratio": 1.54, "no_speech_prob": 0.00029937649378553033}, {"id": 11, "seek": 4092, "start": 56.68, "end": 59.44, "text": " to compare our implementation to others.", "tokens": [281, 6794, 527, 11420, 281, 2357, 13], "temperature": 0.0, "avg_logprob": -0.21586916897747968, "compression_ratio": 1.54, "no_speech_prob": 0.00029937649378553033}, {"id": 12, "seek": 4092, "start": 59.44, "end": 67.48, "text": " So, like everybody in HPC field at this time, we started to build our own ultra-specific", "tokens": [407, 11, 411, 2201, 294, 12557, 34, 2519, 412, 341, 565, 11, 321, 1409, 281, 1322, 527, 1065, 14808, 12, 29258], "temperature": 0.0, "avg_logprob": -0.21586916897747968, "compression_ratio": 1.54, "no_speech_prob": 0.00029937649378553033}, {"id": 13, "seek": 6748, "start": 67.48, "end": 72.84, "text": " shell scripts to validate our implementation, because we were considering that our implementation", "tokens": [8720, 23294, 281, 29562, 527, 11420, 11, 570, 321, 645, 8079, 300, 527, 11420], "temperature": 0.0, "avg_logprob": -0.2061545125554117, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.00015788551536388695}, {"id": 14, "seek": 6748, "start": 72.84, "end": 75.72, "text": " were too specific to be able to use some mainstream tools.", "tokens": [645, 886, 2685, 281, 312, 1075, 281, 764, 512, 15960, 3873, 13], "temperature": 0.0, "avg_logprob": -0.2061545125554117, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.00015788551536388695}, {"id": 15, "seek": 6748, "start": 75.72, "end": 79.68, "text": " So, we started with self-scripts, great idea.", "tokens": [407, 11, 321, 1409, 365, 2698, 12, 82, 5944, 82, 11, 869, 1558, 13], "temperature": 0.0, "avg_logprob": -0.2061545125554117, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.00015788551536388695}, {"id": 16, "seek": 6748, "start": 79.68, "end": 86.12, "text": " The fact is that with the team growing, people working in a separate place, working on multiple", "tokens": [440, 1186, 307, 300, 365, 264, 1469, 4194, 11, 561, 1364, 294, 257, 4994, 1081, 11, 1364, 322, 3866], "temperature": 0.0, "avg_logprob": -0.2061545125554117, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.00015788551536388695}, {"id": 17, "seek": 6748, "start": 86.12, "end": 93.44, "text": " heterogeneous machines, we had a huge issue to make people continue to validate, to use", "tokens": [20789, 31112, 8379, 11, 321, 632, 257, 2603, 2734, 281, 652, 561, 2354, 281, 29562, 11, 281, 764], "temperature": 0.0, "avg_logprob": -0.2061545125554117, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.00015788551536388695}, {"id": 18, "seek": 9344, "start": 93.44, "end": 101.24, "text": " this validation system, because it was slow, not really efficient, and hard to make it", "tokens": [341, 24071, 1185, 11, 570, 309, 390, 2964, 11, 406, 534, 7148, 11, 293, 1152, 281, 652, 309], "temperature": 0.0, "avg_logprob": -0.23268623063058563, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0003553889400791377}, {"id": 19, "seek": 9344, "start": 101.24, "end": 102.24, "text": " grow.", "tokens": [1852, 13], "temperature": 0.0, "avg_logprob": -0.23268623063058563, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0003553889400791377}, {"id": 20, "seek": 9344, "start": 102.24, "end": 108.28, "text": " Especially about maintenance, when we wanted to add anything from to the validation process,", "tokens": [8545, 466, 11258, 11, 562, 321, 1415, 281, 909, 1340, 490, 281, 264, 24071, 1399, 11], "temperature": 0.0, "avg_logprob": -0.23268623063058563, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0003553889400791377}, {"id": 21, "seek": 9344, "start": 108.28, "end": 114.16, "text": " it was just a nightmare, it was really costly in term of time, but also when our software", "tokens": [309, 390, 445, 257, 18724, 11, 309, 390, 534, 28328, 294, 1433, 295, 565, 11, 457, 611, 562, 527, 4722], "temperature": 0.0, "avg_logprob": -0.23268623063058563, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0003553889400791377}, {"id": 22, "seek": 11416, "start": 114.16, "end": 124.03999999999999, "text": " was evolving, was growing, just adding, just a little test into this non-requestion based", "tokens": [390, 21085, 11, 390, 4194, 11, 445, 5127, 11, 445, 257, 707, 1500, 666, 341, 2107, 12, 265, 20343, 313, 2361], "temperature": 0.0, "avg_logprob": -0.3296087513799253, "compression_ratio": 1.5053763440860215, "no_speech_prob": 9.693888569017872e-05}, {"id": 23, "seek": 11416, "start": 124.03999999999999, "end": 125.03999999999999, "text": " was a nightmare.", "tokens": [390, 257, 18724, 13], "temperature": 0.0, "avg_logprob": -0.3296087513799253, "compression_ratio": 1.5053763440860215, "no_speech_prob": 9.693888569017872e-05}, {"id": 24, "seek": 11416, "start": 125.03999999999999, "end": 132.2, "text": " So, we started to consider why not creating a validation system able to take care of", "tokens": [407, 11, 321, 1409, 281, 1949, 983, 406, 4084, 257, 24071, 1185, 1075, 281, 747, 1127, 295], "temperature": 0.0, "avg_logprob": -0.3296087513799253, "compression_ratio": 1.5053763440860215, "no_speech_prob": 9.693888569017872e-05}, {"id": 25, "seek": 11416, "start": 132.2, "end": 137.88, "text": " HPC environment, and what it implies, like validating on multiple architecture, multiple", "tokens": [12557, 34, 2823, 11, 293, 437, 309, 18779, 11, 411, 7363, 990, 322, 3866, 9482, 11, 3866], "temperature": 0.0, "avg_logprob": -0.3296087513799253, "compression_ratio": 1.5053763440860215, "no_speech_prob": 9.693888569017872e-05}, {"id": 26, "seek": 13788, "start": 137.88, "end": 147.32, "text": " machine by multiple users, with multiple benchmarks, and we just thought about having", "tokens": [3479, 538, 3866, 5022, 11, 365, 3866, 43751, 11, 293, 321, 445, 1194, 466, 1419], "temperature": 0.0, "avg_logprob": -0.17045276920969893, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.00012476378469727933}, {"id": 27, "seek": 13788, "start": 147.32, "end": 151.12, "text": " a generic tool able to handle all of that at what point.", "tokens": [257, 19577, 2290, 1075, 281, 4813, 439, 295, 300, 412, 437, 935, 13], "temperature": 0.0, "avg_logprob": -0.17045276920969893, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.00012476378469727933}, {"id": 28, "seek": 13788, "start": 151.12, "end": 158.48, "text": " So, what we want in that scenario, we are here in the case of validating an MPI implementation,", "tokens": [407, 11, 437, 321, 528, 294, 300, 9005, 11, 321, 366, 510, 294, 264, 1389, 295, 7363, 990, 364, 14146, 40, 11420, 11], "temperature": 0.0, "avg_logprob": -0.17045276920969893, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.00012476378469727933}, {"id": 29, "seek": 13788, "start": 158.48, "end": 165.88, "text": " which means having a standard API, okay, so there is a lot of well-known MPI benchmarks", "tokens": [597, 1355, 1419, 257, 3832, 9362, 11, 1392, 11, 370, 456, 307, 257, 688, 295, 731, 12, 6861, 14146, 40, 43751], "temperature": 0.0, "avg_logprob": -0.17045276920969893, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.00012476378469727933}, {"id": 30, "seek": 16588, "start": 165.88, "end": 170.2, "text": " already existing, we don't have to rewrite a whole non-requestion, we have benchmarks,", "tokens": [1217, 6741, 11, 321, 500, 380, 362, 281, 28132, 257, 1379, 2107, 12, 265, 20343, 313, 11, 321, 362, 43751, 11], "temperature": 0.0, "avg_logprob": -0.19730041645191335, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00025802047457545996}, {"id": 31, "seek": 16588, "start": 170.2, "end": 176.64, "text": " you have proxy applications, and so on, so how to scale these benchmarks to any runtime", "tokens": [291, 362, 29690, 5821, 11, 293, 370, 322, 11, 370, 577, 281, 4373, 613, 43751, 281, 604, 34474], "temperature": 0.0, "avg_logprob": -0.19730041645191335, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00025802047457545996}, {"id": 32, "seek": 16588, "start": 176.64, "end": 182.12, "text": " or any project using them to build a proper validation process.", "tokens": [420, 604, 1716, 1228, 552, 281, 1322, 257, 2296, 24071, 1399, 13], "temperature": 0.0, "avg_logprob": -0.19730041645191335, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00025802047457545996}, {"id": 33, "seek": 16588, "start": 182.12, "end": 188.51999999999998, "text": " So, what people want, I mean, what users of this validation system want, it's a simple", "tokens": [407, 11, 437, 561, 528, 11, 286, 914, 11, 437, 5022, 295, 341, 24071, 1185, 528, 11, 309, 311, 257, 2199], "temperature": 0.0, "avg_logprob": -0.19730041645191335, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00025802047457545996}, {"id": 34, "seek": 16588, "start": 188.51999999999998, "end": 189.51999999999998, "text": " tool.", "tokens": [2290, 13], "temperature": 0.0, "avg_logprob": -0.19730041645191335, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00025802047457545996}, {"id": 35, "seek": 16588, "start": 189.51999999999998, "end": 195.6, "text": " You don't want to have really complex Q, GTK, any kind of complex architecture to deploy", "tokens": [509, 500, 380, 528, 281, 362, 534, 3997, 1249, 11, 17530, 42, 11, 604, 733, 295, 3997, 9482, 281, 7274], "temperature": 0.0, "avg_logprob": -0.19730041645191335, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00025802047457545996}, {"id": 36, "seek": 19560, "start": 195.6, "end": 196.6, "text": " to test.", "tokens": [281, 1500, 13], "temperature": 0.0, "avg_logprob": -0.23648318838565907, "compression_ratio": 1.7314814814814814, "no_speech_prob": 9.51286347117275e-05}, {"id": 37, "seek": 19560, "start": 196.6, "end": 202.88, "text": " So, what we want is just a command line interface, basically, and really, really, really few", "tokens": [407, 11, 437, 321, 528, 307, 445, 257, 5622, 1622, 9226, 11, 1936, 11, 293, 534, 11, 534, 11, 534, 1326], "temperature": 0.0, "avg_logprob": -0.23648318838565907, "compression_ratio": 1.7314814814814814, "no_speech_prob": 9.51286347117275e-05}, {"id": 38, "seek": 19560, "start": 202.88, "end": 209.72, "text": " setup, really, really, really few configuration to deploy to have such test working, because", "tokens": [8657, 11, 534, 11, 534, 11, 534, 1326, 11694, 281, 7274, 281, 362, 1270, 1500, 1364, 11, 570], "temperature": 0.0, "avg_logprob": -0.23648318838565907, "compression_ratio": 1.7314814814814814, "no_speech_prob": 9.51286347117275e-05}, {"id": 39, "seek": 19560, "start": 209.72, "end": 216.95999999999998, "text": " a lot, maybe it's not a generality here, but a lot of people hate tests, basically, so", "tokens": [257, 688, 11, 1310, 309, 311, 406, 257, 1337, 1860, 510, 11, 457, 257, 688, 295, 561, 4700, 6921, 11, 1936, 11, 370], "temperature": 0.0, "avg_logprob": -0.23648318838565907, "compression_ratio": 1.7314814814814814, "no_speech_prob": 9.51286347117275e-05}, {"id": 40, "seek": 19560, "start": 216.95999999999998, "end": 222.56, "text": " we have to convince them that testing is good for software quality, something really simple,", "tokens": [321, 362, 281, 13447, 552, 300, 4997, 307, 665, 337, 4722, 3125, 11, 746, 534, 2199, 11], "temperature": 0.0, "avg_logprob": -0.23648318838565907, "compression_ratio": 1.7314814814814814, "no_speech_prob": 9.51286347117275e-05}, {"id": 41, "seek": 22256, "start": 222.56, "end": 229.56, "text": " but also able to handle any really complex scenario we may find in HPC, running an MPI", "tokens": [457, 611, 1075, 281, 4813, 604, 534, 3997, 9005, 321, 815, 915, 294, 12557, 34, 11, 2614, 364, 14146, 40], "temperature": 0.0, "avg_logprob": -0.21339280870225694, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.00020997259707655758}, {"id": 42, "seek": 22256, "start": 229.56, "end": 235.6, "text": " application is not that hard, but it may become really, really complex, and we don't want", "tokens": [3861, 307, 406, 300, 1152, 11, 457, 309, 815, 1813, 534, 11, 534, 3997, 11, 293, 321, 500, 380, 528], "temperature": 0.0, "avg_logprob": -0.21339280870225694, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.00020997259707655758}, {"id": 43, "seek": 22256, "start": 235.6, "end": 240.96, "text": " to have to rewrite our, I use this tool every two years, because a new technology, a new", "tokens": [281, 362, 281, 28132, 527, 11, 286, 764, 341, 2290, 633, 732, 924, 11, 570, 257, 777, 2899, 11, 257, 777], "temperature": 0.0, "avg_logprob": -0.21339280870225694, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.00020997259707655758}, {"id": 44, "seek": 22256, "start": 240.96, "end": 247.48000000000002, "text": " approach, a new paradigm is implemented, and the validation process should have to be rewriting.", "tokens": [3109, 11, 257, 777, 24709, 307, 12270, 11, 293, 264, 24071, 1399, 820, 362, 281, 312, 319, 19868, 13], "temperature": 0.0, "avg_logprob": -0.21339280870225694, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.00020997259707655758}, {"id": 45, "seek": 24748, "start": 247.48, "end": 256.92, "text": " So, from that state, we decided to write a tool to fit our needs, but to be able to be", "tokens": [407, 11, 490, 300, 1785, 11, 321, 3047, 281, 2464, 257, 2290, 281, 3318, 527, 2203, 11, 457, 281, 312, 1075, 281, 312], "temperature": 0.0, "avg_logprob": -0.18758666050898565, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.00023824986419640481}, {"id": 46, "seek": 24748, "start": 256.92, "end": 260.12, "text": " used by people meeting the same requirements.", "tokens": [1143, 538, 561, 3440, 264, 912, 7728, 13], "temperature": 0.0, "avg_logprob": -0.18758666050898565, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.00023824986419640481}, {"id": 47, "seek": 24748, "start": 260.12, "end": 267.08, "text": " Before going further, I would like to tell you that testing is not a brand new field,", "tokens": [4546, 516, 3052, 11, 286, 576, 411, 281, 980, 291, 300, 4997, 307, 406, 257, 3360, 777, 2519, 11], "temperature": 0.0, "avg_logprob": -0.18758666050898565, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.00023824986419640481}, {"id": 48, "seek": 24748, "start": 267.08, "end": 273.08, "text": " and some other projects are tackling such kind of issue until now, and so please take", "tokens": [293, 512, 661, 4455, 366, 34415, 1270, 733, 295, 2734, 1826, 586, 11, 293, 370, 1767, 747], "temperature": 0.0, "avg_logprob": -0.18758666050898565, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.00023824986419640481}, {"id": 49, "seek": 27308, "start": 273.08, "end": 278.08, "text": " a look at them, if you think that PCVS does not completely fit your needs, they are really,", "tokens": [257, 574, 412, 552, 11, 498, 291, 519, 300, 6465, 53, 50, 775, 406, 2584, 3318, 428, 2203, 11, 436, 366, 534, 11], "temperature": 0.0, "avg_logprob": -0.23401006867613974, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.0004362811741884798}, {"id": 50, "seek": 27308, "start": 278.08, "end": 282.24, "text": " really powerful tools in the field.", "tokens": [534, 4005, 3873, 294, 264, 2519, 13], "temperature": 0.0, "avg_logprob": -0.23401006867613974, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.0004362811741884798}, {"id": 51, "seek": 27308, "start": 282.24, "end": 287.52, "text": " So today, I'm here to talk to you about PCVS.", "tokens": [407, 965, 11, 286, 478, 510, 281, 751, 281, 291, 466, 6465, 53, 50, 13], "temperature": 0.0, "avg_logprob": -0.23401006867613974, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.0004362811741884798}, {"id": 52, "seek": 27308, "start": 287.52, "end": 293.56, "text": " It's a tool maintained by the CEA, it's retained in Python, yes, everything is in Python now,", "tokens": [467, 311, 257, 2290, 17578, 538, 264, 28109, 32, 11, 309, 311, 33438, 294, 15329, 11, 2086, 11, 1203, 307, 294, 15329, 586, 11], "temperature": 0.0, "avg_logprob": -0.23401006867613974, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.0004362811741884798}, {"id": 53, "seek": 29356, "start": 293.56, "end": 303.2, "text": " so we are based on Python, it's a simple command line interface, and with few configuration", "tokens": [370, 321, 366, 2361, 322, 15329, 11, 309, 311, 257, 2199, 5622, 1622, 9226, 11, 293, 365, 1326, 11694], "temperature": 0.0, "avg_logprob": -0.228074312210083, "compression_ratio": 1.5371428571428571, "no_speech_prob": 0.0002974569797515869}, {"id": 54, "seek": 29356, "start": 303.2, "end": 310.72, "text": " files, obviously in EML, it's a trend, the design of this framework, the testing framework", "tokens": [7098, 11, 2745, 294, 462, 12683, 11, 309, 311, 257, 6028, 11, 264, 1715, 295, 341, 8388, 11, 264, 4997, 8388], "temperature": 0.0, "avg_logprob": -0.228074312210083, "compression_ratio": 1.5371428571428571, "no_speech_prob": 0.0002974569797515869}, {"id": 55, "seek": 29356, "start": 310.72, "end": 318.84000000000003, "text": " is to be, to bring simplicity when writing test logic to users, so we want tests to be", "tokens": [307, 281, 312, 11, 281, 1565, 25632, 562, 3579, 1500, 9952, 281, 5022, 11, 370, 321, 528, 6921, 281, 312], "temperature": 0.0, "avg_logprob": -0.228074312210083, "compression_ratio": 1.5371428571428571, "no_speech_prob": 0.0002974569797515869}, {"id": 56, "seek": 31884, "start": 318.84, "end": 328.11999999999995, "text": " simple to write, easy to port, okay, and these benchmarks, written by the user, we want to", "tokens": [2199, 281, 2464, 11, 1858, 281, 2436, 11, 1392, 11, 293, 613, 43751, 11, 3720, 538, 264, 4195, 11, 321, 528, 281], "temperature": 0.0, "avg_logprob": -0.2407997733668277, "compression_ratio": 1.6574074074074074, "no_speech_prob": 0.00017497933004051447}, {"id": 57, "seek": 31884, "start": 328.11999999999995, "end": 334.79999999999995, "text": " be able to be run in multiple environments, so we don't want to bound a test suite to", "tokens": [312, 1075, 281, 312, 1190, 294, 3866, 12388, 11, 370, 321, 500, 380, 528, 281, 5472, 257, 1500, 14205, 281], "temperature": 0.0, "avg_logprob": -0.2407997733668277, "compression_ratio": 1.6574074074074074, "no_speech_prob": 0.00017497933004051447}, {"id": 58, "seek": 31884, "start": 334.79999999999995, "end": 340.32, "text": " a given application, let's consider MPI run time, we don't want to have our Lulesh or", "tokens": [257, 2212, 3861, 11, 718, 311, 1949, 14146, 40, 1190, 565, 11, 321, 500, 380, 528, 281, 362, 527, 441, 425, 14935, 420], "temperature": 0.0, "avg_logprob": -0.2407997733668277, "compression_ratio": 1.6574074074074074, "no_speech_prob": 0.00017497933004051447}, {"id": 59, "seek": 31884, "start": 340.32, "end": 348.32, "text": " our IMB benchmark bound to a specific MPI implementation to be run on any kind of architecture.", "tokens": [527, 21463, 33, 18927, 5472, 281, 257, 2685, 14146, 40, 11420, 281, 312, 1190, 322, 604, 733, 295, 9482, 13], "temperature": 0.0, "avg_logprob": -0.2407997733668277, "compression_ratio": 1.6574074074074074, "no_speech_prob": 0.00017497933004051447}, {"id": 60, "seek": 34832, "start": 348.32, "end": 355.24, "text": " So this is what we call in PCVS, the retargeting approach, the other approach we want to focus", "tokens": [407, 341, 307, 437, 321, 818, 294, 6465, 53, 50, 11, 264, 1533, 289, 847, 278, 3109, 11, 264, 661, 3109, 321, 528, 281, 1879], "temperature": 0.0, "avg_logprob": -0.20590249882187955, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.00023796595633029938}, {"id": 61, "seek": 34832, "start": 355.24, "end": 362.71999999999997, "text": " on is the fact that we have heterogeneous test environments, we have benchmarks, how", "tokens": [322, 307, 264, 1186, 300, 321, 362, 20789, 31112, 1500, 12388, 11, 321, 362, 43751, 11, 577], "temperature": 0.0, "avg_logprob": -0.20590249882187955, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.00023796595633029938}, {"id": 62, "seek": 34832, "start": 362.71999999999997, "end": 368.08, "text": " to scale, automatically scale this benchmark to the actual test environment, consider,", "tokens": [281, 4373, 11, 6772, 4373, 341, 18927, 281, 264, 3539, 1500, 2823, 11, 1949, 11], "temperature": 0.0, "avg_logprob": -0.20590249882187955, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.00023796595633029938}, {"id": 63, "seek": 34832, "start": 368.08, "end": 372.84, "text": " for example, having users wanting to validate the IMB, but they are working on their work", "tokens": [337, 1365, 11, 1419, 5022, 7935, 281, 29562, 264, 21463, 33, 11, 457, 436, 366, 1364, 322, 641, 589], "temperature": 0.0, "avg_logprob": -0.20590249882187955, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.00023796595633029938}, {"id": 64, "seek": 37284, "start": 372.84, "end": 378.64, "text": " session, we don't want to launch up to, I don't know, 100 MPI processes on their work", "tokens": [5481, 11, 321, 500, 380, 528, 281, 4025, 493, 281, 11, 286, 500, 380, 458, 11, 2319, 14146, 40, 7555, 322, 641, 589], "temperature": 0.0, "avg_logprob": -0.21278435202205884, "compression_ratio": 1.554585152838428, "no_speech_prob": 7.458584877895191e-05}, {"id": 65, "seek": 37284, "start": 378.64, "end": 385.03999999999996, "text": " session, they're going to be not happy with you squashing their machine, but once this", "tokens": [5481, 11, 436, 434, 516, 281, 312, 406, 2055, 365, 291, 2339, 11077, 641, 3479, 11, 457, 1564, 341], "temperature": 0.0, "avg_logprob": -0.21278435202205884, "compression_ratio": 1.554585152838428, "no_speech_prob": 7.458584877895191e-05}, {"id": 66, "seek": 37284, "start": 385.03999999999996, "end": 391.52, "text": " validation system is run on a real HPC cluster, you want the test suite to automatically scale", "tokens": [24071, 1185, 307, 1190, 322, 257, 957, 12557, 34, 13630, 11, 291, 528, 264, 1500, 14205, 281, 6772, 4373], "temperature": 0.0, "avg_logprob": -0.21278435202205884, "compression_ratio": 1.554585152838428, "no_speech_prob": 7.458584877895191e-05}, {"id": 67, "seek": 37284, "start": 391.52, "end": 398.28, "text": " to this supercomputer resources without having to rewrite 100 of configuration files, or", "tokens": [281, 341, 36708, 3593, 1553, 1419, 281, 28132, 2319, 295, 11694, 7098, 11, 420], "temperature": 0.0, "avg_logprob": -0.21278435202205884, "compression_ratio": 1.554585152838428, "no_speech_prob": 7.458584877895191e-05}, {"id": 68, "seek": 39828, "start": 398.28, "end": 402.84, "text": " even one file is already too much, okay.", "tokens": [754, 472, 3991, 307, 1217, 886, 709, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.24440933528699374, "compression_ratio": 1.5935828877005347, "no_speech_prob": 0.00014652863319497555}, {"id": 69, "seek": 39828, "start": 402.84, "end": 409.4, "text": " So this work is maintained by the CEA, which is a French research administration, and we", "tokens": [407, 341, 589, 307, 17578, 538, 264, 28109, 32, 11, 597, 307, 257, 5522, 2132, 7236, 11, 293, 321], "temperature": 0.0, "avg_logprob": -0.24440933528699374, "compression_ratio": 1.5935828877005347, "no_speech_prob": 0.00014652863319497555}, {"id": 70, "seek": 39828, "start": 409.4, "end": 416.64, "text": " are collaborating with us, with them, I'm sorry, to make this tool more generic or not", "tokens": [366, 30188, 365, 505, 11, 365, 552, 11, 286, 478, 2597, 11, 281, 652, 341, 2290, 544, 19577, 420, 406], "temperature": 0.0, "avg_logprob": -0.24440933528699374, "compression_ratio": 1.5935828877005347, "no_speech_prob": 0.00014652863319497555}, {"id": 71, "seek": 39828, "start": 416.64, "end": 426.52, "text": " generic and attempt to make as many users as possible, as many users as possible.", "tokens": [19577, 293, 5217, 281, 652, 382, 867, 5022, 382, 1944, 11, 382, 867, 5022, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.24440933528699374, "compression_ratio": 1.5935828877005347, "no_speech_prob": 0.00014652863319497555}, {"id": 72, "seek": 42652, "start": 426.52, "end": 434.44, "text": " So at Eglance, some feature specificities provide, the idea is to split the test effort", "tokens": [407, 412, 462, 7191, 719, 11, 512, 4111, 2685, 1088, 2893, 11, 264, 1558, 307, 281, 7472, 264, 1500, 4630], "temperature": 0.0, "avg_logprob": -0.27444282980526197, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.00017149027553386986}, {"id": 73, "seek": 42652, "start": 434.44, "end": 443.76, "text": " into specific fields, the first one is the specification of test, what a benchmark need", "tokens": [666, 2685, 7909, 11, 264, 700, 472, 307, 264, 31256, 295, 1500, 11, 437, 257, 18927, 643], "temperature": 0.0, "avg_logprob": -0.27444282980526197, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.00017149027553386986}, {"id": 74, "seek": 42652, "start": 443.76, "end": 449.15999999999997, "text": " to expose to build the test, so this kind of information is carried by the benchmark,", "tokens": [281, 19219, 281, 1322, 264, 1500, 11, 370, 341, 733, 295, 1589, 307, 9094, 538, 264, 18927, 11], "temperature": 0.0, "avg_logprob": -0.27444282980526197, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.00017149027553386986}, {"id": 75, "seek": 42652, "start": 449.15999999999997, "end": 454.32, "text": " obviously, how to build, what is the program, what are the parameters, and so on.", "tokens": [2745, 11, 577, 281, 1322, 11, 437, 307, 264, 1461, 11, 437, 366, 264, 9834, 11, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.27444282980526197, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.00017149027553386986}, {"id": 76, "seek": 45432, "start": 454.32, "end": 459.92, "text": " And the environment, it's a testing environment, here is carried by the people deploying or", "tokens": [400, 264, 2823, 11, 309, 311, 257, 4997, 2823, 11, 510, 307, 9094, 538, 264, 561, 34198, 420], "temperature": 0.0, "avg_logprob": -0.36037083233104034, "compression_ratio": 1.588235294117647, "no_speech_prob": 9.470801887800917e-05}, {"id": 77, "seek": 45432, "start": 459.92, "end": 467.48, "text": " providing the testing resources, so most of the time it's just a team policy to schedule", "tokens": [6530, 264, 4997, 3593, 11, 370, 881, 295, 264, 565, 309, 311, 445, 257, 1469, 3897, 281, 7567], "temperature": 0.0, "avg_logprob": -0.36037083233104034, "compression_ratio": 1.588235294117647, "no_speech_prob": 9.470801887800917e-05}, {"id": 78, "seek": 45432, "start": 467.48, "end": 478.48, "text": " jobs, or our system admins, right, all of this to pursue two goals, still the retargeting", "tokens": [4782, 11, 420, 527, 1185, 5910, 1292, 11, 558, 11, 439, 295, 341, 281, 12392, 732, 5493, 11, 920, 264, 1533, 289, 847, 278], "temperature": 0.0, "avg_logprob": -0.36037083233104034, "compression_ratio": 1.588235294117647, "no_speech_prob": 9.470801887800917e-05}, {"id": 79, "seek": 47848, "start": 478.48, "end": 486.88, "text": " of tests automatically when the user is calling this benchmark, depending on the compiler and", "tokens": [295, 6921, 6772, 562, 264, 4195, 307, 5141, 341, 18927, 11, 5413, 322, 264, 31958, 293], "temperature": 0.0, "avg_logprob": -0.30047626182681225, "compression_ratio": 1.4636871508379887, "no_speech_prob": 0.00013703928561881185}, {"id": 80, "seek": 47848, "start": 486.88, "end": 492.56, "text": " run time you want to target, and auto scaling test to test environment.", "tokens": [1190, 565, 291, 528, 281, 3779, 11, 293, 8399, 21589, 1500, 281, 1500, 2823, 13], "temperature": 0.0, "avg_logprob": -0.30047626182681225, "compression_ratio": 1.4636871508379887, "no_speech_prob": 0.00013703928561881185}, {"id": 81, "seek": 47848, "start": 492.56, "end": 501.12, "text": " Obviously, as PCVS is a kind of test framework, we add to add some functionality around testing,", "tokens": [7580, 11, 382, 6465, 53, 50, 307, 257, 733, 295, 1500, 8388, 11, 321, 909, 281, 909, 512, 14980, 926, 4997, 11], "temperature": 0.0, "avg_logprob": -0.30047626182681225, "compression_ratio": 1.4636871508379887, "no_speech_prob": 0.00013703928561881185}, {"id": 82, "seek": 50112, "start": 501.12, "end": 508.52, "text": " like in-place reporting, because most users are running their tests on HPC cluster where", "tokens": [411, 294, 12, 6742, 10031, 11, 570, 881, 5022, 366, 2614, 641, 6921, 322, 12557, 34, 13630, 689], "temperature": 0.0, "avg_logprob": -0.2917611495308254, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.0003530036483425647}, {"id": 83, "seek": 50112, "start": 508.52, "end": 513.88, "text": " the set of functionality can be restrained, so they don't have access to all their GitLab,", "tokens": [264, 992, 295, 14980, 393, 312, 25508, 2001, 11, 370, 436, 500, 380, 362, 2105, 281, 439, 641, 16939, 37880, 11], "temperature": 0.0, "avg_logprob": -0.2917611495308254, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.0003530036483425647}, {"id": 84, "seek": 50112, "start": 513.88, "end": 523.44, "text": " GitHub, Gira and so on stuff, so we add some basic tools to answer these needs, and beyond", "tokens": [23331, 11, 460, 4271, 293, 370, 322, 1507, 11, 370, 321, 909, 512, 3875, 3873, 281, 1867, 613, 2203, 11, 293, 4399], "temperature": 0.0, "avg_logprob": -0.2917611495308254, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.0003530036483425647}, {"id": 85, "seek": 52344, "start": 523.44, "end": 532.96, "text": " a single execution validation run, we added a way to build the history of the validation", "tokens": [257, 2167, 15058, 24071, 1190, 11, 321, 3869, 257, 636, 281, 1322, 264, 2503, 295, 264, 24071], "temperature": 0.0, "avg_logprob": -0.19220235612657335, "compression_ratio": 1.5256410256410255, "no_speech_prob": 3.864461541525088e-05}, {"id": 86, "seek": 52344, "start": 532.96, "end": 540.0, "text": " for a given application by storing results over time, and allowing the user to run simple", "tokens": [337, 257, 2212, 3861, 538, 26085, 3542, 670, 565, 11, 293, 8293, 264, 4195, 281, 1190, 2199], "temperature": 0.0, "avg_logprob": -0.19220235612657335, "compression_ratio": 1.5256410256410255, "no_speech_prob": 3.864461541525088e-05}, {"id": 87, "seek": 52344, "start": 540.0, "end": 547.2, "text": " analysis, still in Python, to produce statistics over time.", "tokens": [5215, 11, 920, 294, 15329, 11, 281, 5258, 12523, 670, 565, 13], "temperature": 0.0, "avg_logprob": -0.19220235612657335, "compression_ratio": 1.5256410256410255, "no_speech_prob": 3.864461541525088e-05}, {"id": 88, "seek": 54720, "start": 547.2, "end": 554.2800000000001, "text": " So quickly, the architecture of PCVS, it's based on files, so Bison CLI, so Bison file", "tokens": [407, 2661, 11, 264, 9482, 295, 6465, 53, 50, 11, 309, 311, 2361, 322, 7098, 11, 370, 363, 2770, 12855, 40, 11, 370, 363, 2770, 3991], "temperature": 0.0, "avg_logprob": -0.30338048410939644, "compression_ratio": 1.537117903930131, "no_speech_prob": 0.00013287861656863242}, {"id": 89, "seek": 54720, "start": 554.2800000000001, "end": 562.88, "text": " system, it's parsing some user inputs, and it's run through a dedicated connector to", "tokens": [1185, 11, 309, 311, 21156, 278, 512, 4195, 15743, 11, 293, 309, 311, 1190, 807, 257, 8374, 19127, 281], "temperature": 0.0, "avg_logprob": -0.30338048410939644, "compression_ratio": 1.537117903930131, "no_speech_prob": 0.00013287861656863242}, {"id": 90, "seek": 54720, "start": 562.88, "end": 571.4000000000001, "text": " mainly SLURM currently, mainly SLURM, but we are focusing on supporting as a batch manager.", "tokens": [8704, 22999, 7932, 44, 4362, 11, 8704, 22999, 7932, 44, 11, 457, 321, 366, 8416, 322, 7231, 382, 257, 15245, 6598, 13], "temperature": 0.0, "avg_logprob": -0.30338048410939644, "compression_ratio": 1.537117903930131, "no_speech_prob": 0.00013287861656863242}, {"id": 91, "seek": 54720, "start": 571.4000000000001, "end": 576.6, "text": " So the idea is that the benchmark express job descriptions and resource requirements and", "tokens": [407, 264, 1558, 307, 300, 264, 18927, 5109, 1691, 24406, 293, 7684, 7728, 293], "temperature": 0.0, "avg_logprob": -0.30338048410939644, "compression_ratio": 1.537117903930131, "no_speech_prob": 0.00013287861656863242}, {"id": 92, "seek": 57660, "start": 576.6, "end": 578.96, "text": " the environment will provide resources.", "tokens": [264, 2823, 486, 2893, 3593, 13], "temperature": 0.0, "avg_logprob": -0.2394476970994329, "compression_ratio": 1.555, "no_speech_prob": 0.00041577083175070584}, {"id": 93, "seek": 57660, "start": 578.96, "end": 585.44, "text": " Let's consider, for example, a basic component called number of MPI tasks the job is taking,", "tokens": [961, 311, 1949, 11, 337, 1365, 11, 257, 3875, 6542, 1219, 1230, 295, 14146, 40, 9608, 264, 1691, 307, 1940, 11], "temperature": 0.0, "avg_logprob": -0.2394476970994329, "compression_ratio": 1.555, "no_speech_prob": 0.00041577083175070584}, {"id": 94, "seek": 57660, "start": 585.44, "end": 592.16, "text": " the job will say, okay, my job is only running up to two processes, or it's only taking,", "tokens": [264, 1691, 486, 584, 11, 1392, 11, 452, 1691, 307, 787, 2614, 493, 281, 732, 7555, 11, 420, 309, 311, 787, 1940, 11], "temperature": 0.0, "avg_logprob": -0.2394476970994329, "compression_ratio": 1.555, "no_speech_prob": 0.00041577083175070584}, {"id": 95, "seek": 57660, "start": 592.16, "end": 601.52, "text": " I don't know, cubic value of MPI processes, people are aware of users of the Lulech proxy", "tokens": [286, 500, 380, 458, 11, 28733, 2158, 295, 14146, 40, 7555, 11, 561, 366, 3650, 295, 5022, 295, 264, 441, 2271, 339, 29690], "temperature": 0.0, "avg_logprob": -0.2394476970994329, "compression_ratio": 1.555, "no_speech_prob": 0.00041577083175070584}, {"id": 96, "seek": 60152, "start": 601.52, "end": 607.68, "text": " application will know what I mean by cubic, so it will describe constraints, and then", "tokens": [3861, 486, 458, 437, 286, 914, 538, 28733, 11, 370, 309, 486, 6786, 18491, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.23266041584503958, "compression_ratio": 1.5422885572139304, "no_speech_prob": 9.367517486680299e-05}, {"id": 97, "seek": 60152, "start": 607.68, "end": 614.96, "text": " we will have environment configuration files called profile in PCVS, where the admin will", "tokens": [321, 486, 362, 2823, 11694, 7098, 1219, 7964, 294, 6465, 53, 50, 11, 689, 264, 24236, 486], "temperature": 0.0, "avg_logprob": -0.23266041584503958, "compression_ratio": 1.5422885572139304, "no_speech_prob": 9.367517486680299e-05}, {"id": 98, "seek": 60152, "start": 614.96, "end": 621.84, "text": " say, okay, in that context, I will have up to 100 nodes, so you will be able to spawn", "tokens": [584, 11, 1392, 11, 294, 300, 4319, 11, 286, 486, 362, 493, 281, 2319, 13891, 11, 370, 291, 486, 312, 1075, 281, 17088], "temperature": 0.0, "avg_logprob": -0.23266041584503958, "compression_ratio": 1.5422885572139304, "no_speech_prob": 9.367517486680299e-05}, {"id": 99, "seek": 60152, "start": 621.84, "end": 625.52, "text": " up to 100 MPI processes to run your application.", "tokens": [493, 281, 2319, 14146, 40, 7555, 281, 1190, 428, 3861, 13], "temperature": 0.0, "avg_logprob": -0.23266041584503958, "compression_ratio": 1.5422885572139304, "no_speech_prob": 9.367517486680299e-05}, {"id": 100, "seek": 62552, "start": 625.52, "end": 632.68, "text": " Based on that, PCVS will cross this information and will say, okay, I have MPI jobs, I can", "tokens": [18785, 322, 300, 11, 6465, 53, 50, 486, 3278, 341, 1589, 293, 486, 584, 11, 1392, 11, 286, 362, 14146, 40, 4782, 11, 286, 393], "temperature": 0.0, "avg_logprob": -0.2834372282028198, "compression_ratio": 1.5121951219512195, "no_speech_prob": 8.674479613546282e-05}, {"id": 101, "seek": 62552, "start": 632.68, "end": 640.8, "text": " run up to 1000 MPI processes based on this specification, why not running the user benchmark", "tokens": [1190, 493, 281, 9714, 14146, 40, 7555, 2361, 322, 341, 31256, 11, 983, 406, 2614, 264, 4195, 18927], "temperature": 0.0, "avg_logprob": -0.2834372282028198, "compression_ratio": 1.5121951219512195, "no_speech_prob": 8.674479613546282e-05}, {"id": 102, "seek": 62552, "start": 640.8, "end": 645.4, "text": " 100 times once for each combination.", "tokens": [2319, 1413, 1564, 337, 1184, 6562, 13], "temperature": 0.0, "avg_logprob": -0.2834372282028198, "compression_ratio": 1.5121951219512195, "no_speech_prob": 8.674479613546282e-05}, {"id": 103, "seek": 62552, "start": 645.4, "end": 653.28, "text": " PCVS is an as an opt out approach, so it will consider that every combination provided by", "tokens": [6465, 53, 50, 307, 364, 382, 364, 2427, 484, 3109, 11, 370, 309, 486, 1949, 300, 633, 6562, 5649, 538], "temperature": 0.0, "avg_logprob": -0.2834372282028198, "compression_ratio": 1.5121951219512195, "no_speech_prob": 8.674479613546282e-05}, {"id": 104, "seek": 65328, "start": 653.28, "end": 659.0, "text": " the environment will be used to scale your tests, okay, so if your test is not able to", "tokens": [264, 2823, 486, 312, 1143, 281, 4373, 428, 6921, 11, 1392, 11, 370, 498, 428, 1500, 307, 406, 1075, 281], "temperature": 0.0, "avg_logprob": -0.19520064459906683, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00012766479630954564}, {"id": 105, "seek": 65328, "start": 659.0, "end": 667.76, "text": " run up to 1000 jobs, it's up to you to specify that you can't reach this limit.", "tokens": [1190, 493, 281, 9714, 4782, 11, 309, 311, 493, 281, 291, 281, 16500, 300, 291, 393, 380, 2524, 341, 4948, 13], "temperature": 0.0, "avg_logprob": -0.19520064459906683, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00012766479630954564}, {"id": 106, "seek": 65328, "start": 667.76, "end": 673.0, "text": " So here is a quick example, I don't know if you can see up there, but we have a really,", "tokens": [407, 510, 307, 257, 1702, 1365, 11, 286, 500, 380, 458, 498, 291, 393, 536, 493, 456, 11, 457, 321, 362, 257, 534, 11], "temperature": 0.0, "avg_logprob": -0.19520064459906683, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00012766479630954564}, {"id": 107, "seek": 65328, "start": 673.0, "end": 676.88, "text": " really basic environment configuration where you can see that there is what we call an", "tokens": [534, 3875, 2823, 11694, 689, 291, 393, 536, 300, 456, 307, 437, 321, 818, 364], "temperature": 0.0, "avg_logprob": -0.19520064459906683, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00012766479630954564}, {"id": 108, "seek": 67688, "start": 676.88, "end": 684.8, "text": " operator, this is a variadic component, and it can take up to 4 values for the NMPI attributes", "tokens": [12973, 11, 341, 307, 257, 3034, 43341, 6542, 11, 293, 309, 393, 747, 493, 281, 1017, 4190, 337, 264, 426, 12224, 40, 17212], "temperature": 0.0, "avg_logprob": -0.3232242796156142, "compression_ratio": 1.407216494845361, "no_speech_prob": 0.00013295277312863618}, {"id": 109, "seek": 67688, "start": 684.8, "end": 691.08, "text": " and when describing a simple job, we're just saying, okay, my job just consists in running", "tokens": [293, 562, 16141, 257, 2199, 1691, 11, 321, 434, 445, 1566, 11, 1392, 11, 452, 1691, 445, 14689, 294, 2614], "temperature": 0.0, "avg_logprob": -0.3232242796156142, "compression_ratio": 1.407216494845361, "no_speech_prob": 0.00013295277312863618}, {"id": 110, "seek": 67688, "start": 691.08, "end": 703.48, "text": " a program, PCVS will enroll up to 4 common lines to run 4 independent tests to execute.", "tokens": [257, 1461, 11, 6465, 53, 50, 486, 12266, 493, 281, 1017, 2689, 3876, 281, 1190, 1017, 6695, 6921, 281, 14483, 13], "temperature": 0.0, "avg_logprob": -0.3232242796156142, "compression_ratio": 1.407216494845361, "no_speech_prob": 0.00013295277312863618}, {"id": 111, "seek": 70348, "start": 703.48, "end": 714.08, "text": " So PCVS will automatically build your test scenarios based on your specification.", "tokens": [407, 6465, 53, 50, 486, 6772, 1322, 428, 1500, 15077, 2361, 322, 428, 31256, 13], "temperature": 0.0, "avg_logprob": -0.25885257720947263, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00016976815822999924}, {"id": 112, "seek": 70348, "start": 714.08, "end": 719.5600000000001, "text": " So how to basically write a test, but more specifically a compilation test, there is", "tokens": [407, 577, 281, 1936, 2464, 257, 1500, 11, 457, 544, 4682, 257, 40261, 1500, 11, 456, 307], "temperature": 0.0, "avg_logprob": -0.25885257720947263, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00016976815822999924}, {"id": 113, "seek": 70348, "start": 719.5600000000001, "end": 725.2, "text": " a lot of things to customize or you can build your tests, so it looks complicated, but as", "tokens": [257, 688, 295, 721, 281, 19734, 420, 291, 393, 1322, 428, 6921, 11, 370, 309, 1542, 6179, 11, 457, 382], "temperature": 0.0, "avg_logprob": -0.25885257720947263, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00016976815822999924}, {"id": 114, "seek": 72520, "start": 725.2, "end": 735.1600000000001, "text": " you may see on the previous slide, all the keys in that TML are not mandatory, at least", "tokens": [291, 815, 536, 322, 264, 3894, 4137, 11, 439, 264, 9317, 294, 300, 314, 12683, 366, 406, 22173, 11, 412, 1935], "temperature": 0.0, "avg_logprob": -0.23509709537029266, "compression_ratio": 1.5625, "no_speech_prob": 9.998438326874748e-05}, {"id": 115, "seek": 72520, "start": 735.1600000000001, "end": 742.2800000000001, "text": " the files one, obviously you have to specify which kind of application you want to compile,", "tokens": [264, 7098, 472, 11, 2745, 291, 362, 281, 16500, 597, 733, 295, 3861, 291, 528, 281, 31413, 11], "temperature": 0.0, "avg_logprob": -0.23509709537029266, "compression_ratio": 1.5625, "no_speech_prob": 9.998438326874748e-05}, {"id": 116, "seek": 72520, "start": 742.2800000000001, "end": 752.0400000000001, "text": " so the framework will try to auto detect your language to select the proper compiler, obviously", "tokens": [370, 264, 8388, 486, 853, 281, 8399, 5531, 428, 2856, 281, 3048, 264, 2296, 31958, 11, 2745], "temperature": 0.0, "avg_logprob": -0.23509709537029266, "compression_ratio": 1.5625, "no_speech_prob": 9.998438326874748e-05}, {"id": 117, "seek": 75204, "start": 752.04, "end": 756.1999999999999, "text": " you have a manually designed approach also.", "tokens": [291, 362, 257, 16945, 4761, 3109, 611, 13], "temperature": 0.0, "avg_logprob": -0.3414005241771736, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.00011397071648389101}, {"id": 118, "seek": 75204, "start": 756.1999999999999, "end": 761.92, "text": " If you are not based on compiling source files but already using a well-known build system,", "tokens": [759, 291, 366, 406, 2361, 322, 715, 4883, 4009, 7098, 457, 1217, 1228, 257, 731, 12, 6861, 1322, 1185, 11], "temperature": 0.0, "avg_logprob": -0.3414005241771736, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.00011397071648389101}, {"id": 119, "seek": 75204, "start": 761.92, "end": 767.24, "text": " we have also an interface to invoke directly build system to build your framework.", "tokens": [321, 362, 611, 364, 9226, 281, 41117, 3838, 1322, 1185, 281, 1322, 428, 8388, 13], "temperature": 0.0, "avg_logprob": -0.3414005241771736, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.00011397071648389101}, {"id": 120, "seek": 75204, "start": 767.24, "end": 774.48, "text": " I'm thinking about, for example, Lulesh, which is using a Mac file, DIMB using a Mac file,", "tokens": [286, 478, 1953, 466, 11, 337, 1365, 11, 441, 3473, 71, 11, 597, 307, 1228, 257, 5707, 3991, 11, 413, 6324, 33, 1228, 257, 5707, 3991, 11], "temperature": 0.0, "avg_logprob": -0.3414005241771736, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.00011397071648389101}, {"id": 121, "seek": 75204, "start": 774.48, "end": 779.36, "text": " or even the Mpitch test suite using a Configure Mac-Macon style approach.", "tokens": [420, 754, 264, 376, 79, 1549, 1500, 14205, 1228, 257, 44151, 540, 5707, 12, 44, 18181, 3758, 3109, 13], "temperature": 0.0, "avg_logprob": -0.3414005241771736, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.00011397071648389101}, {"id": 122, "seek": 77936, "start": 779.36, "end": 782.88, "text": " So you have many options, all of them are optional.", "tokens": [407, 291, 362, 867, 3956, 11, 439, 295, 552, 366, 17312, 13], "temperature": 0.0, "avg_logprob": -0.2598878299488741, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00034162402153015137}, {"id": 123, "seek": 77936, "start": 782.88, "end": 785.28, "text": " What I would like to highlight is a variant.", "tokens": [708, 286, 576, 411, 281, 5078, 307, 257, 17501, 13], "temperature": 0.0, "avg_logprob": -0.2598878299488741, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00034162402153015137}, {"id": 124, "seek": 77936, "start": 785.28, "end": 794.16, "text": " What a variant, it's a capability from PCVS to expose to job, to benchmarks, a specificity", "tokens": [708, 257, 17501, 11, 309, 311, 257, 13759, 490, 6465, 53, 50, 281, 19219, 281, 1691, 11, 281, 43751, 11, 257, 2685, 507], "temperature": 0.0, "avg_logprob": -0.2598878299488741, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00034162402153015137}, {"id": 125, "seek": 77936, "start": 794.16, "end": 797.6800000000001, "text": " or requirement this job has to be run.", "tokens": [420, 11695, 341, 1691, 575, 281, 312, 1190, 13], "temperature": 0.0, "avg_logprob": -0.2598878299488741, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00034162402153015137}, {"id": 126, "seek": 77936, "start": 797.6800000000001, "end": 804.2, "text": " So in that case, the OpenMP keyword probably means something to everyone here, but it just", "tokens": [407, 294, 300, 1389, 11, 264, 7238, 12224, 20428, 1391, 1355, 746, 281, 1518, 510, 11, 457, 309, 445], "temperature": 0.0, "avg_logprob": -0.2598878299488741, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00034162402153015137}, {"id": 127, "seek": 80420, "start": 804.2, "end": 810.12, "text": " you know a token saying that to run this job, the variant, the component OpenMP is required", "tokens": [291, 458, 257, 14862, 1566, 300, 281, 1190, 341, 1691, 11, 264, 17501, 11, 264, 6542, 7238, 12224, 307, 4739], "temperature": 0.0, "avg_logprob": -0.2974597140475436, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00020804461382795125}, {"id": 128, "seek": 80420, "start": 810.12, "end": 816.2, "text": " to be scheduled and in the environment, the user will say, okay, what is my variant OpenMP", "tokens": [281, 312, 15678, 293, 294, 264, 2823, 11, 264, 4195, 486, 584, 11, 1392, 11, 437, 307, 452, 17501, 7238, 12224], "temperature": 0.0, "avg_logprob": -0.2974597140475436, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00020804461382795125}, {"id": 129, "seek": 80420, "start": 816.2, "end": 823.2, "text": " in case of GCC, GCC like compiler, it will be dash f OpenMP if it's Intel, it's not", "tokens": [294, 1389, 295, 460, 11717, 11, 460, 11717, 411, 31958, 11, 309, 486, 312, 8240, 283, 7238, 12224, 498, 309, 311, 19762, 11, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.2974597140475436, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00020804461382795125}, {"id": 130, "seek": 80420, "start": 823.2, "end": 824.2, "text": " the same option.", "tokens": [264, 912, 3614, 13], "temperature": 0.0, "avg_logprob": -0.2974597140475436, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00020804461382795125}, {"id": 131, "seek": 80420, "start": 824.2, "end": 825.2, "text": " You see the ID?", "tokens": [509, 536, 264, 7348, 30], "temperature": 0.0, "avg_logprob": -0.2974597140475436, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00020804461382795125}, {"id": 132, "seek": 80420, "start": 825.2, "end": 832.2, "text": " I will add, PCVS will add Flavor depending on what you have specified in your environment.", "tokens": [286, 486, 909, 11, 6465, 53, 50, 486, 909, 3235, 1924, 5413, 322, 437, 291, 362, 22206, 294, 428, 2823, 13], "temperature": 0.0, "avg_logprob": -0.2974597140475436, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00020804461382795125}, {"id": 133, "seek": 83220, "start": 832.2, "end": 837.0400000000001, "text": " How to write a run test.", "tokens": [1012, 281, 2464, 257, 1190, 1500, 13], "temperature": 0.0, "avg_logprob": -0.3220148217188169, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0005258251912891865}, {"id": 134, "seek": 83220, "start": 837.0400000000001, "end": 841.72, "text": " So this is where the component, the iterative component takes place, we didn't port it yet", "tokens": [407, 341, 307, 689, 264, 6542, 11, 264, 17138, 1166, 6542, 2516, 1081, 11, 321, 994, 380, 2436, 309, 1939], "temperature": 0.0, "avg_logprob": -0.3220148217188169, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0005258251912891865}, {"id": 135, "seek": 83220, "start": 841.72, "end": 850.5200000000001, "text": " on CompilationModel because we have issues with the race condition reaching the same", "tokens": [322, 6620, 16067, 44, 41147, 570, 321, 362, 2663, 365, 264, 4569, 4188, 9906, 264, 912], "temperature": 0.0, "avg_logprob": -0.3220148217188169, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0005258251912891865}, {"id": 136, "seek": 83220, "start": 850.5200000000001, "end": 855.8000000000001, "text": " file on the file system, but we are planning to containerize, to encapsulate, to isolate", "tokens": [3991, 322, 264, 3991, 1185, 11, 457, 321, 366, 5038, 281, 10129, 1125, 11, 281, 38745, 5256, 11, 281, 25660], "temperature": 0.0, "avg_logprob": -0.3220148217188169, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0005258251912891865}, {"id": 137, "seek": 85580, "start": 855.8, "end": 863.3599999999999, "text": " such model to be able to support also CompilationTest, I'm sorry.", "tokens": [1270, 2316, 281, 312, 1075, 281, 1406, 611, 6620, 16067, 51, 377, 11, 286, 478, 2597, 13], "temperature": 0.0, "avg_logprob": -0.259543654497932, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.00023251429956872016}, {"id": 138, "seek": 85580, "start": 863.3599999999999, "end": 870.88, "text": " So what as a user have to do to integrate such test in your workflow, just write a PCVS.yml", "tokens": [407, 437, 382, 257, 4195, 362, 281, 360, 281, 13365, 1270, 1500, 294, 428, 20993, 11, 445, 2464, 257, 6465, 53, 50, 13, 4199, 75], "temperature": 0.0, "avg_logprob": -0.259543654497932, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.00023251429956872016}, {"id": 139, "seek": 85580, "start": 870.88, "end": 879.24, "text": " file, you put it anywhere you want in your pass, I mean your benchmark pass, and it looks", "tokens": [3991, 11, 291, 829, 309, 4992, 291, 528, 294, 428, 1320, 11, 286, 914, 428, 18927, 1320, 11, 293, 309, 1542], "temperature": 0.0, "avg_logprob": -0.259543654497932, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.00023251429956872016}, {"id": 140, "seek": 85580, "start": 879.24, "end": 885.4799999999999, "text": " like just a run node and everything below is totally optional.", "tokens": [411, 445, 257, 1190, 9984, 293, 1203, 2507, 307, 3879, 17312, 13], "temperature": 0.0, "avg_logprob": -0.259543654497932, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.00023251429956872016}, {"id": 141, "seek": 88548, "start": 885.48, "end": 891.64, "text": " Here we can see that we restrict, we restrict our add.out program to specific MPI values", "tokens": [1692, 321, 393, 536, 300, 321, 7694, 11, 321, 7694, 527, 909, 13, 346, 1461, 281, 2685, 14146, 40, 4190], "temperature": 0.0, "avg_logprob": -0.21918299198150634, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001296220871154219}, {"id": 142, "seek": 88548, "start": 891.64, "end": 898.24, "text": " because as a tester, I know that my test has this constraint.", "tokens": [570, 382, 257, 36101, 11, 286, 458, 300, 452, 1500, 575, 341, 25534, 13], "temperature": 0.0, "avg_logprob": -0.21918299198150634, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001296220871154219}, {"id": 143, "seek": 88548, "start": 898.24, "end": 906.96, "text": " You can even create this variadic component for your own application if you want to programmatically", "tokens": [509, 393, 754, 1884, 341, 3034, 43341, 6542, 337, 428, 1065, 3861, 498, 291, 528, 281, 37648, 5030], "temperature": 0.0, "avg_logprob": -0.21918299198150634, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001296220871154219}, {"id": 144, "seek": 88548, "start": 906.96, "end": 915.4, "text": " generate a list of scenario that PCVS should integrate to its own process to build multiple", "tokens": [8460, 257, 1329, 295, 9005, 300, 6465, 53, 50, 820, 13365, 281, 1080, 1065, 1399, 281, 1322, 3866], "temperature": 0.0, "avg_logprob": -0.21918299198150634, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001296220871154219}, {"id": 145, "seek": 91540, "start": 915.4, "end": 916.4, "text": " scenarios.", "tokens": [15077, 13], "temperature": 0.0, "avg_logprob": -0.22622203826904297, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00013437647430691868}, {"id": 146, "seek": 91540, "start": 916.4, "end": 922.04, "text": " So in that case, with this, I'm sorry, why am I moving in the program node, you'll see", "tokens": [407, 294, 300, 1389, 11, 365, 341, 11, 286, 478, 2597, 11, 983, 669, 286, 2684, 294, 264, 1461, 9984, 11, 291, 603, 536], "temperature": 0.0, "avg_logprob": -0.22622203826904297, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00013437647430691868}, {"id": 147, "seek": 91540, "start": 922.04, "end": 929.92, "text": " that with this three simple lines, it will be able to build three times the number of", "tokens": [300, 365, 341, 1045, 2199, 3876, 11, 309, 486, 312, 1075, 281, 1322, 1045, 1413, 264, 1230, 295], "temperature": 0.0, "avg_logprob": -0.22622203826904297, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00013437647430691868}, {"id": 148, "seek": 91540, "start": 929.92, "end": 936.76, "text": " scenarios that you were expected to have initially, right?", "tokens": [15077, 300, 291, 645, 5176, 281, 362, 9105, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.22622203826904297, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00013437647430691868}, {"id": 149, "seek": 91540, "start": 936.76, "end": 942.52, "text": " And what a test without having a way to express or validate a test, obviously.", "tokens": [400, 437, 257, 1500, 1553, 1419, 257, 636, 281, 5109, 420, 29562, 257, 1500, 11, 2745, 13], "temperature": 0.0, "avg_logprob": -0.22622203826904297, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00013437647430691868}, {"id": 150, "seek": 94252, "start": 942.52, "end": 949.4, "text": " So for any test, not only for run, you have a YAML description to say, okay, so I want", "tokens": [407, 337, 604, 1500, 11, 406, 787, 337, 1190, 11, 291, 362, 257, 398, 2865, 43, 3855, 281, 584, 11, 1392, 11, 370, 286, 528], "temperature": 0.0, "avg_logprob": -0.19922546019037085, "compression_ratio": 1.5119617224880382, "no_speech_prob": 0.0001979298540391028}, {"id": 151, "seek": 94252, "start": 949.4, "end": 957.36, "text": " my job to exit with this particular return code, having an execution time within this", "tokens": [452, 1691, 281, 11043, 365, 341, 1729, 2736, 3089, 11, 1419, 364, 15058, 565, 1951, 341], "temperature": 0.0, "avg_logprob": -0.19922546019037085, "compression_ratio": 1.5119617224880382, "no_speech_prob": 0.0001979298540391028}, {"id": 152, "seek": 94252, "start": 957.36, "end": 962.12, "text": " range matching or not matching this kind of pattern.", "tokens": [3613, 14324, 420, 406, 14324, 341, 733, 295, 5102, 13], "temperature": 0.0, "avg_logprob": -0.19922546019037085, "compression_ratio": 1.5119617224880382, "no_speech_prob": 0.0001979298540391028}, {"id": 153, "seek": 94252, "start": 962.12, "end": 969.1999999999999, "text": " Even here is my script, give him the regular output of my test and I will tell you if it's", "tokens": [2754, 510, 307, 452, 5755, 11, 976, 796, 264, 3890, 5598, 295, 452, 1500, 293, 286, 486, 980, 291, 498, 309, 311], "temperature": 0.0, "avg_logprob": -0.19922546019037085, "compression_ratio": 1.5119617224880382, "no_speech_prob": 0.0001979298540391028}, {"id": 154, "seek": 96920, "start": 969.2, "end": 972.84, "text": " okay or not.", "tokens": [1392, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.31362221088815245, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.00015752318722661585}, {"id": 155, "seek": 96920, "start": 972.84, "end": 977.9200000000001, "text": " Okay, so I just write my test, how to run them now.", "tokens": [1033, 11, 370, 286, 445, 2464, 452, 1500, 11, 577, 281, 1190, 552, 586, 13], "temperature": 0.0, "avg_logprob": -0.31362221088815245, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.00015752318722661585}, {"id": 156, "seek": 96920, "start": 977.9200000000001, "end": 984.0400000000001, "text": " It's just celibate, so you just have to call PCVS run, but before running my benchmark,", "tokens": [467, 311, 445, 9277, 897, 473, 11, 370, 291, 445, 362, 281, 818, 6465, 53, 50, 1190, 11, 457, 949, 2614, 452, 18927, 11], "temperature": 0.0, "avg_logprob": -0.31362221088815245, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.00015752318722661585}, {"id": 157, "seek": 96920, "start": 984.0400000000001, "end": 989.9200000000001, "text": " I just have to create a profile to express the resources my environment has.", "tokens": [286, 445, 362, 281, 1884, 257, 7964, 281, 5109, 264, 3593, 452, 2823, 575, 13], "temperature": 0.0, "avg_logprob": -0.31362221088815245, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.00015752318722661585}, {"id": 158, "seek": 96920, "start": 989.9200000000001, "end": 995.5200000000001, "text": " Obviously, in case of MPI, we provided some templates, some basic templates to initiate", "tokens": [7580, 11, 294, 1389, 295, 14146, 40, 11, 321, 5649, 512, 21165, 11, 512, 3875, 21165, 281, 31574], "temperature": 0.0, "avg_logprob": -0.31362221088815245, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.00015752318722661585}, {"id": 159, "seek": 96920, "start": 995.5200000000001, "end": 997.76, "text": " the testing process.", "tokens": [264, 4997, 1399, 13], "temperature": 0.0, "avg_logprob": -0.31362221088815245, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.00015752318722661585}, {"id": 160, "seek": 99776, "start": 997.76, "end": 1002.64, "text": " So here, we are just creating a profile named my MPI based just on MPI.", "tokens": [407, 510, 11, 321, 366, 445, 4084, 257, 7964, 4926, 452, 14146, 40, 2361, 445, 322, 14146, 40, 13], "temperature": 0.0, "avg_logprob": -0.24832494523790147, "compression_ratio": 1.551219512195122, "no_speech_prob": 6.65409243083559e-05}, {"id": 161, "seek": 99776, "start": 1002.64, "end": 1010.0, "text": " So by quickly running that, I will have a full profile based on MPI running tests for", "tokens": [407, 538, 2661, 2614, 300, 11, 286, 486, 362, 257, 1577, 7964, 2361, 322, 14146, 40, 2614, 6921, 337], "temperature": 0.0, "avg_logprob": -0.24832494523790147, "compression_ratio": 1.551219512195122, "no_speech_prob": 6.65409243083559e-05}, {"id": 162, "seek": 99776, "start": 1010.0, "end": 1017.36, "text": " one, two, three, and four MPI processes, but from that, you can then expand the profile", "tokens": [472, 11, 732, 11, 1045, 11, 293, 1451, 14146, 40, 7555, 11, 457, 490, 300, 11, 291, 393, 550, 5268, 264, 7964], "temperature": 0.0, "avg_logprob": -0.24832494523790147, "compression_ratio": 1.551219512195122, "no_speech_prob": 6.65409243083559e-05}, {"id": 163, "seek": 99776, "start": 1017.36, "end": 1019.6, "text": " to fit your needs.", "tokens": [281, 3318, 428, 2203, 13], "temperature": 0.0, "avg_logprob": -0.24832494523790147, "compression_ratio": 1.551219512195122, "no_speech_prob": 6.65409243083559e-05}, {"id": 164, "seek": 99776, "start": 1019.6, "end": 1024.68, "text": " The whole build of PCVS relies on a single directory.", "tokens": [440, 1379, 1322, 295, 6465, 53, 50, 30910, 322, 257, 2167, 21120, 13], "temperature": 0.0, "avg_logprob": -0.24832494523790147, "compression_ratio": 1.551219512195122, "no_speech_prob": 6.65409243083559e-05}, {"id": 165, "seek": 102468, "start": 1024.68, "end": 1032.76, "text": " And in that directory, you will find anything required to analyze the results and even rerun", "tokens": [400, 294, 300, 21120, 11, 291, 486, 915, 1340, 4739, 281, 12477, 264, 3542, 293, 754, 43819, 409], "temperature": 0.0, "avg_logprob": -0.1683321937185819, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.00016042096831370145}, {"id": 166, "seek": 102468, "start": 1032.76, "end": 1037.92, "text": " in the same condition the tests for reproducibility.", "tokens": [294, 264, 912, 4188, 264, 6921, 337, 11408, 537, 39802, 13], "temperature": 0.0, "avg_logprob": -0.1683321937185819, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.00016042096831370145}, {"id": 167, "seek": 102468, "start": 1037.92, "end": 1045.2, "text": " You can see on the right, repository we provided alongside with PCVS, which is called PCVS benchmarks,", "tokens": [509, 393, 536, 322, 264, 558, 11, 25841, 321, 5649, 12385, 365, 6465, 53, 50, 11, 597, 307, 1219, 6465, 53, 50, 43751, 11], "temperature": 0.0, "avg_logprob": -0.1683321937185819, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.00016042096831370145}, {"id": 168, "seek": 104520, "start": 1045.2, "end": 1056.8, "text": " and we attempt to put in that repository many well-known MPI benchmarks, PCVS enabled, right?", "tokens": [293, 321, 5217, 281, 829, 294, 300, 25841, 867, 731, 12, 6861, 14146, 40, 43751, 11, 6465, 53, 50, 15172, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.23788055816254058, "compression_ratio": 1.4591836734693877, "no_speech_prob": 8.893152698874474e-05}, {"id": 169, "seek": 104520, "start": 1056.8, "end": 1058.72, "text": " So here is a fancy view of PCVS.", "tokens": [407, 510, 307, 257, 10247, 1910, 295, 6465, 53, 50, 13], "temperature": 0.0, "avg_logprob": -0.23788055816254058, "compression_ratio": 1.4591836734693877, "no_speech_prob": 8.893152698874474e-05}, {"id": 170, "seek": 104520, "start": 1058.72, "end": 1063.72, "text": " Obviously, there is many options when running a validation.", "tokens": [7580, 11, 456, 307, 867, 3956, 562, 2614, 257, 24071, 13], "temperature": 0.0, "avg_logprob": -0.23788055816254058, "compression_ratio": 1.4591836734693877, "no_speech_prob": 8.893152698874474e-05}, {"id": 171, "seek": 104520, "start": 1063.72, "end": 1069.68, "text": " You can have an interactive approach, non-interactive approach, slur enabled, I mean, batch manager", "tokens": [509, 393, 362, 364, 15141, 3109, 11, 2107, 12, 5106, 12596, 3109, 11, 1061, 374, 15172, 11, 286, 914, 11, 15245, 6598], "temperature": 0.0, "avg_logprob": -0.23788055816254058, "compression_ratio": 1.4591836734693877, "no_speech_prob": 8.893152698874474e-05}, {"id": 172, "seek": 106968, "start": 1069.68, "end": 1078.52, "text": " enabled, running inside an allocation, outside an allocation, and once the whole configuration", "tokens": [15172, 11, 2614, 1854, 364, 27599, 11, 2380, 364, 27599, 11, 293, 1564, 264, 1379, 11694], "temperature": 0.0, "avg_logprob": -0.21675858290299124, "compression_ratio": 1.5905511811023623, "no_speech_prob": 0.00011172398080816492}, {"id": 173, "seek": 106968, "start": 1078.52, "end": 1085.28, "text": " has been generated, we have commands, especially a PCVS exec, to interact independently, uniquely", "tokens": [575, 668, 10833, 11, 321, 362, 16901, 11, 2318, 257, 6465, 53, 50, 4454, 11, 281, 4648, 21761, 11, 31474], "temperature": 0.0, "avg_logprob": -0.21675858290299124, "compression_ratio": 1.5905511811023623, "no_speech_prob": 0.00011172398080816492}, {"id": 174, "seek": 106968, "start": 1085.28, "end": 1090.96, "text": " with your benchmarks, so for instance, what people are used to do is to run their validation", "tokens": [365, 428, 43751, 11, 370, 337, 5197, 11, 437, 561, 366, 1143, 281, 360, 307, 281, 1190, 641, 24071], "temperature": 0.0, "avg_logprob": -0.21675858290299124, "compression_ratio": 1.5905511811023623, "no_speech_prob": 0.00011172398080816492}, {"id": 175, "seek": 106968, "start": 1090.96, "end": 1096.8400000000001, "text": " and after maybe 10 seconds, some failures appear, and they would like, without interrupting", "tokens": [293, 934, 1310, 1266, 3949, 11, 512, 20774, 4204, 11, 293, 436, 576, 411, 11, 1553, 49455], "temperature": 0.0, "avg_logprob": -0.21675858290299124, "compression_ratio": 1.5905511811023623, "no_speech_prob": 0.00011172398080816492}, {"id": 176, "seek": 106968, "start": 1096.8400000000001, "end": 1099.0, "text": " the non-requestion system.", "tokens": [264, 2107, 12, 265, 20343, 313, 1185, 13], "temperature": 0.0, "avg_logprob": -0.21675858290299124, "compression_ratio": 1.5905511811023623, "no_speech_prob": 0.00011172398080816492}, {"id": 177, "seek": 109900, "start": 1099.0, "end": 1105.96, "text": " But rerun in an isolated environment, their tests to see why it failed.", "tokens": [583, 43819, 409, 294, 364, 14621, 2823, 11, 641, 6921, 281, 536, 983, 309, 7612, 13], "temperature": 0.0, "avg_logprob": -0.31903140544891356, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.00018854679365176708}, {"id": 178, "seek": 109900, "start": 1105.96, "end": 1116.0, "text": " So we have some extra commands to rerun this special pattern, okay?", "tokens": [407, 321, 362, 512, 2857, 16901, 281, 43819, 409, 341, 2121, 5102, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.31903140544891356, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.00018854679365176708}, {"id": 179, "seek": 109900, "start": 1116.0, "end": 1123.88, "text": " Obviously, I'm going to just pick it up, obviously, everything is not always perfect, and the", "tokens": [7580, 11, 286, 478, 516, 281, 445, 1888, 309, 493, 11, 2745, 11, 1203, 307, 406, 1009, 2176, 11, 293, 264], "temperature": 0.0, "avg_logprob": -0.31903140544891356, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.00018854679365176708}, {"id": 180, "seek": 109900, "start": 1123.88, "end": 1127.44, "text": " static approach of the ML file is not what you need, you would like something more dynamic", "tokens": [13437, 3109, 295, 264, 21601, 3991, 307, 406, 437, 291, 643, 11, 291, 576, 411, 746, 544, 8546], "temperature": 0.0, "avg_logprob": -0.31903140544891356, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.00018854679365176708}, {"id": 181, "seek": 112744, "start": 1127.44, "end": 1132.04, "text": " because you have some stuff to interpret, to read, to process before knowing what you", "tokens": [570, 291, 362, 512, 1507, 281, 7302, 11, 281, 1401, 11, 281, 1399, 949, 5276, 437, 291], "temperature": 0.0, "avg_logprob": -0.18616371390260297, "compression_ratio": 1.5792079207920793, "no_speech_prob": 0.00014360033674165606}, {"id": 182, "seek": 112744, "start": 1132.04, "end": 1134.8400000000001, "text": " want to test, even within a benchmark.", "tokens": [528, 281, 1500, 11, 754, 1951, 257, 18927, 13], "temperature": 0.0, "avg_logprob": -0.18616371390260297, "compression_ratio": 1.5792079207920793, "no_speech_prob": 0.00014360033674165606}, {"id": 183, "seek": 112744, "start": 1134.8400000000001, "end": 1136.52, "text": " So we have a dynamic approach.", "tokens": [407, 321, 362, 257, 8546, 3109, 13], "temperature": 0.0, "avg_logprob": -0.18616371390260297, "compression_ratio": 1.5792079207920793, "no_speech_prob": 0.00014360033674165606}, {"id": 184, "seek": 112744, "start": 1136.52, "end": 1143.16, "text": " Instead of providing a static ML file, you will provide an executable script, an executable", "tokens": [7156, 295, 6530, 257, 13437, 21601, 3991, 11, 291, 486, 2893, 364, 7568, 712, 5755, 11, 364, 7568, 712], "temperature": 0.0, "avg_logprob": -0.18616371390260297, "compression_ratio": 1.5792079207920793, "no_speech_prob": 0.00014360033674165606}, {"id": 185, "seek": 112744, "start": 1143.16, "end": 1149.3600000000001, "text": " file, whatever it is, and it will produce by itself the actual ML file.", "tokens": [3991, 11, 2035, 309, 307, 11, 293, 309, 486, 5258, 538, 2564, 264, 3539, 21601, 3991, 13], "temperature": 0.0, "avg_logprob": -0.18616371390260297, "compression_ratio": 1.5792079207920793, "no_speech_prob": 0.00014360033674165606}, {"id": 186, "seek": 114936, "start": 1149.36, "end": 1157.32, "text": " This way, you can programmatically generate your benchmark suite without having to know", "tokens": [639, 636, 11, 291, 393, 37648, 5030, 8460, 428, 18927, 14205, 1553, 1419, 281, 458], "temperature": 0.0, "avg_logprob": -0.2449397775861952, "compression_ratio": 1.4509803921568627, "no_speech_prob": 0.000104223181551788}, {"id": 187, "seek": 114936, "start": 1157.32, "end": 1162.56, "text": " it in advance, without knowing in which environment your non-requestion base will be run.", "tokens": [309, 294, 7295, 11, 1553, 5276, 294, 597, 2823, 428, 2107, 12, 265, 20343, 313, 3096, 486, 312, 1190, 13], "temperature": 0.0, "avg_logprob": -0.2449397775861952, "compression_ratio": 1.4509803921568627, "no_speech_prob": 0.000104223181551788}, {"id": 188, "seek": 114936, "start": 1162.56, "end": 1170.52, "text": " Let's consider the NAS framework, where within the name of the binary bit, you have the number", "tokens": [961, 311, 1949, 264, 10182, 8388, 11, 689, 1951, 264, 1315, 295, 264, 17434, 857, 11, 291, 362, 264, 1230], "temperature": 0.0, "avg_logprob": -0.2449397775861952, "compression_ratio": 1.4509803921568627, "no_speech_prob": 0.000104223181551788}, {"id": 189, "seek": 114936, "start": 1170.52, "end": 1175.84, "text": " of MPI processes, cool.", "tokens": [295, 14146, 40, 7555, 11, 1627, 13], "temperature": 0.0, "avg_logprob": -0.2449397775861952, "compression_ratio": 1.4509803921568627, "no_speech_prob": 0.000104223181551788}, {"id": 190, "seek": 117584, "start": 1175.84, "end": 1181.84, "text": " You know, we have run our tests, but we would like to see what it looks like, okay?", "tokens": [509, 458, 11, 321, 362, 1190, 527, 6921, 11, 457, 321, 576, 411, 281, 536, 437, 309, 1542, 411, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.24459019513197347, "compression_ratio": 1.5, "no_speech_prob": 0.00038130194297991693}, {"id": 191, "seek": 117584, "start": 1181.84, "end": 1184.6, "text": " We have a test framework, not just a job runner.", "tokens": [492, 362, 257, 1500, 8388, 11, 406, 445, 257, 1691, 24376, 13], "temperature": 0.0, "avg_logprob": -0.24459019513197347, "compression_ratio": 1.5, "no_speech_prob": 0.00038130194297991693}, {"id": 192, "seek": 117584, "start": 1184.6, "end": 1195.8799999999999, "text": " So obviously, we had some tools to report results to the user, spoiler, cannot be compared", "tokens": [407, 2745, 11, 321, 632, 512, 3873, 281, 2275, 3542, 281, 264, 4195, 11, 26927, 11, 2644, 312, 5347], "temperature": 0.0, "avg_logprob": -0.24459019513197347, "compression_ratio": 1.5, "no_speech_prob": 0.00038130194297991693}, {"id": 193, "seek": 117584, "start": 1195.8799999999999, "end": 1198.28, "text": " with real tools for that, okay?", "tokens": [365, 957, 3873, 337, 300, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.24459019513197347, "compression_ratio": 1.5, "no_speech_prob": 0.00038130194297991693}, {"id": 194, "seek": 119828, "start": 1198.28, "end": 1206.04, "text": " And the idea is just to offer a way to users to grab their results directly on their machine,", "tokens": [400, 264, 1558, 307, 445, 281, 2626, 257, 636, 281, 5022, 281, 4444, 641, 3542, 3838, 322, 641, 3479, 11], "temperature": 0.0, "avg_logprob": -0.21486021223522367, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.0002583051100373268}, {"id": 195, "seek": 119828, "start": 1206.04, "end": 1207.36, "text": " in place, okay?", "tokens": [294, 1081, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.21486021223522367, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.0002583051100373268}, {"id": 196, "seek": 119828, "start": 1207.36, "end": 1213.84, "text": " And essentially, it's just a way to look at tests at a glance to be able to rerun if", "tokens": [400, 4476, 11, 309, 311, 445, 257, 636, 281, 574, 412, 6921, 412, 257, 21094, 281, 312, 1075, 281, 43819, 409, 498], "temperature": 0.0, "avg_logprob": -0.21486021223522367, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.0002583051100373268}, {"id": 197, "seek": 119828, "start": 1213.84, "end": 1217.68, "text": " necessary in the process.", "tokens": [4818, 294, 264, 1399, 13], "temperature": 0.0, "avg_logprob": -0.21486021223522367, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.0002583051100373268}, {"id": 198, "seek": 119828, "start": 1217.68, "end": 1226.36, "text": " So as I said, we can isolate and rerun independently jobs, which is pretty convenient when some", "tokens": [407, 382, 286, 848, 11, 321, 393, 25660, 293, 43819, 409, 21761, 4782, 11, 597, 307, 1238, 10851, 562, 512], "temperature": 0.0, "avg_logprob": -0.21486021223522367, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.0002583051100373268}, {"id": 199, "seek": 122636, "start": 1226.36, "end": 1229.7199999999998, "text": " failure want to be explored right away.", "tokens": [7763, 528, 281, 312, 24016, 558, 1314, 13], "temperature": 0.0, "avg_logprob": -0.2171554131941362, "compression_ratio": 1.4, "no_speech_prob": 0.00018551679386291653}, {"id": 200, "seek": 122636, "start": 1229.7199999999998, "end": 1246.8, "text": " And in FINE, we are using a web server to report in a web browser directly, offering", "tokens": [400, 294, 479, 16258, 11, 321, 366, 1228, 257, 3670, 7154, 281, 2275, 294, 257, 3670, 11185, 3838, 11, 8745], "temperature": 0.0, "avg_logprob": -0.2171554131941362, "compression_ratio": 1.4, "no_speech_prob": 0.00018551679386291653}, {"id": 201, "seek": 122636, "start": 1246.8, "end": 1249.36, "text": " more interactivity for your results.", "tokens": [544, 4648, 4253, 337, 428, 3542, 13], "temperature": 0.0, "avg_logprob": -0.2171554131941362, "compression_ratio": 1.4, "no_speech_prob": 0.00018551679386291653}, {"id": 202, "seek": 122636, "start": 1249.36, "end": 1253.56, "text": " So what it looks like, for example, here, gathered by Label, you can see that there", "tokens": [407, 437, 309, 1542, 411, 11, 337, 1365, 11, 510, 11, 13032, 538, 10137, 338, 11, 291, 393, 536, 300, 456], "temperature": 0.0, "avg_logprob": -0.2171554131941362, "compression_ratio": 1.4, "no_speech_prob": 0.00018551679386291653}, {"id": 203, "seek": 125356, "start": 1253.56, "end": 1258.6, "text": " is some red, so some failures.", "tokens": [307, 512, 2182, 11, 370, 512, 20774, 13], "temperature": 0.0, "avg_logprob": -0.2245636173323089, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.00015535160491708666}, {"id": 204, "seek": 125356, "start": 1258.6, "end": 1259.6, "text": " Let's dive into it.", "tokens": [961, 311, 9192, 666, 309, 13], "temperature": 0.0, "avg_logprob": -0.2245636173323089, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.00015535160491708666}, {"id": 205, "seek": 125356, "start": 1259.6, "end": 1263.32, "text": " You can see that some trouble with MPIO, what a surprise.", "tokens": [509, 393, 536, 300, 512, 5253, 365, 14146, 15167, 11, 437, 257, 6365, 13], "temperature": 0.0, "avg_logprob": -0.2245636173323089, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.00015535160491708666}, {"id": 206, "seek": 125356, "start": 1263.32, "end": 1268.8, "text": " And when clicking a job, you'll see the complete log of this trend, so the command line and", "tokens": [400, 562, 9697, 257, 1691, 11, 291, 603, 536, 264, 3566, 3565, 295, 341, 6028, 11, 370, 264, 5622, 1622, 293], "temperature": 0.0, "avg_logprob": -0.2245636173323089, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.00015535160491708666}, {"id": 207, "seek": 125356, "start": 1268.8, "end": 1274.6799999999998, "text": " the actual, so I truncated, I'm sorry, I truncated the actual error, and you can directly dive", "tokens": [264, 3539, 11, 370, 286, 504, 409, 66, 770, 11, 286, 478, 2597, 11, 286, 504, 409, 66, 770, 264, 3539, 6713, 11, 293, 291, 393, 3838, 9192], "temperature": 0.0, "avg_logprob": -0.2245636173323089, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.00015535160491708666}, {"id": 208, "seek": 125356, "start": 1274.6799999999998, "end": 1281.04, "text": " into the error without leaving your actual SSH terminal.", "tokens": [666, 264, 6713, 1553, 5012, 428, 3539, 12238, 39, 14709, 13], "temperature": 0.0, "avg_logprob": -0.2245636173323089, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.00015535160491708666}, {"id": 209, "seek": 128104, "start": 1281.04, "end": 1286.84, "text": " So a quick overview of how to configure your site, so the test environment configuration", "tokens": [407, 257, 1702, 12492, 295, 577, 281, 22162, 428, 3621, 11, 370, 264, 1500, 2823, 11694], "temperature": 0.0, "avg_logprob": -0.25911527605199103, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0002547740004956722}, {"id": 210, "seek": 128104, "start": 1286.84, "end": 1287.84, "text": " part.", "tokens": [644, 13], "temperature": 0.0, "avg_logprob": -0.25911527605199103, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0002547740004956722}, {"id": 211, "seek": 128104, "start": 1287.84, "end": 1296.92, "text": " This is also AML, you will define directly compilers, compiler and run times, and the", "tokens": [639, 307, 611, 6475, 43, 11, 291, 486, 6964, 3838, 715, 388, 433, 11, 31958, 293, 1190, 1413, 11, 293, 264], "temperature": 0.0, "avg_logprob": -0.25911527605199103, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0002547740004956722}, {"id": 212, "seek": 128104, "start": 1296.92, "end": 1302.2, "text": " special variadic component here.", "tokens": [2121, 3034, 43341, 6542, 510, 13], "temperature": 0.0, "avg_logprob": -0.25911527605199103, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0002547740004956722}, {"id": 213, "seek": 128104, "start": 1302.2, "end": 1306.0, "text": " It's split in five different modules, why?", "tokens": [467, 311, 7472, 294, 1732, 819, 16679, 11, 983, 30], "temperature": 0.0, "avg_logprob": -0.25911527605199103, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0002547740004956722}, {"id": 214, "seek": 130600, "start": 1306.0, "end": 1311.32, "text": " Because this whole profile can be split up to five blocks, independent blocks, we can", "tokens": [1436, 341, 1379, 7964, 393, 312, 7472, 493, 281, 1732, 8474, 11, 6695, 8474, 11, 321, 393], "temperature": 0.0, "avg_logprob": -0.21007413449494736, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00015642504149582237}, {"id": 215, "seek": 130600, "start": 1311.32, "end": 1317.36, "text": " be distributed over a cluster because it's not always the same teams who are responsible", "tokens": [312, 12631, 670, 257, 13630, 570, 309, 311, 406, 1009, 264, 912, 5491, 567, 366, 6250], "temperature": 0.0, "avg_logprob": -0.21007413449494736, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00015642504149582237}, {"id": 216, "seek": 130600, "start": 1317.36, "end": 1318.88, "text": " of this particular block.", "tokens": [295, 341, 1729, 3461, 13], "temperature": 0.0, "avg_logprob": -0.21007413449494736, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00015642504149582237}, {"id": 217, "seek": 130600, "start": 1318.88, "end": 1326.24, "text": " Let's consider, for example, the variadic component, it's in charge of the team to build", "tokens": [961, 311, 1949, 11, 337, 1365, 11, 264, 3034, 43341, 6542, 11, 309, 311, 294, 4602, 295, 264, 1469, 281, 1322], "temperature": 0.0, "avg_logprob": -0.21007413449494736, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00015642504149582237}, {"id": 218, "seek": 130600, "start": 1326.24, "end": 1331.92, "text": " this list, while for the compiler and run time, it may be in charge of the C side means", "tokens": [341, 1329, 11, 1339, 337, 264, 31958, 293, 1190, 565, 11, 309, 815, 312, 294, 4602, 295, 264, 383, 1252, 1355], "temperature": 0.0, "avg_logprob": -0.21007413449494736, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00015642504149582237}, {"id": 219, "seek": 133192, "start": 1331.92, "end": 1336.76, "text": " of the test environment machine.", "tokens": [295, 264, 1500, 2823, 3479, 13], "temperature": 0.0, "avg_logprob": -0.2999140875680106, "compression_ratio": 1.3766233766233766, "no_speech_prob": 0.00024943772586993873}, {"id": 220, "seek": 133192, "start": 1336.76, "end": 1343.5600000000002, "text": " And after running a single job, what I would like to see is to have a trend over multiple", "tokens": [400, 934, 2614, 257, 2167, 1691, 11, 437, 286, 576, 411, 281, 536, 307, 281, 362, 257, 6028, 670, 3866], "temperature": 0.0, "avg_logprob": -0.2999140875680106, "compression_ratio": 1.3766233766233766, "no_speech_prob": 0.00024943772586993873}, {"id": 221, "seek": 133192, "start": 1343.5600000000002, "end": 1355.0, "text": " run, all my test suite behave, and in PCVS we integrated a way of using to stack multiple", "tokens": [1190, 11, 439, 452, 1500, 14205, 15158, 11, 293, 294, 6465, 53, 50, 321, 10919, 257, 636, 295, 1228, 281, 8630, 3866], "temperature": 0.0, "avg_logprob": -0.2999140875680106, "compression_ratio": 1.3766233766233766, "no_speech_prob": 0.00024943772586993873}, {"id": 222, "seek": 135500, "start": 1355.0, "end": 1364.2, "text": " runs over time, and then run analysis on them, to build trends, to have more things than", "tokens": [6676, 670, 565, 11, 293, 550, 1190, 5215, 322, 552, 11, 281, 1322, 13892, 11, 281, 362, 544, 721, 813], "temperature": 0.0, "avg_logprob": -0.2892161586828399, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.337207064963877e-05}, {"id": 223, "seek": 135500, "start": 1364.2, "end": 1369.4, "text": " just a test result, but a test result over time.", "tokens": [445, 257, 1500, 1874, 11, 457, 257, 1500, 1874, 670, 565, 13], "temperature": 0.0, "avg_logprob": -0.2892161586828399, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.337207064963877e-05}, {"id": 224, "seek": 135500, "start": 1369.4, "end": 1380.64, "text": " So here is an example of what you can do afterwards, running analysis directly on this", "tokens": [407, 510, 307, 364, 1365, 295, 437, 291, 393, 360, 10543, 11, 2614, 5215, 3838, 322, 341], "temperature": 0.0, "avg_logprob": -0.2892161586828399, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.337207064963877e-05}, {"id": 225, "seek": 138064, "start": 1380.64, "end": 1390.96, "text": " storized pass, and this is enabled thanks to, I would like to call that a DSL, but actually", "tokens": [5967, 1602, 1320, 11, 293, 341, 307, 15172, 3231, 281, 11, 286, 576, 411, 281, 818, 300, 257, 15816, 43, 11, 457, 767], "temperature": 0.0, "avg_logprob": -0.24405937194824218, "compression_ratio": 1.3953488372093024, "no_speech_prob": 0.00013293953088577837}, {"id": 226, "seek": 138064, "start": 1390.96, "end": 1399.0400000000002, "text": " just a Python API to interact with that, and you can build such beautiful graphics to see", "tokens": [445, 257, 15329, 9362, 281, 4648, 365, 300, 11, 293, 291, 393, 1322, 1270, 2238, 11837, 281, 536], "temperature": 0.0, "avg_logprob": -0.24405937194824218, "compression_ratio": 1.3953488372093024, "no_speech_prob": 0.00013293953088577837}, {"id": 227, "seek": 138064, "start": 1399.0400000000002, "end": 1409.0400000000002, "text": " over time the rates of success inside your test benchmark.", "tokens": [670, 565, 264, 6846, 295, 2245, 1854, 428, 1500, 18927, 13], "temperature": 0.0, "avg_logprob": -0.24405937194824218, "compression_ratio": 1.3953488372093024, "no_speech_prob": 0.00013293953088577837}, {"id": 228, "seek": 140904, "start": 1409.04, "end": 1414.0, "text": " So finally, just a quick glance at the SPAC plus PCVS.", "tokens": [407, 2721, 11, 445, 257, 1702, 21094, 412, 264, 8420, 4378, 1804, 6465, 53, 50, 13], "temperature": 0.0, "avg_logprob": -0.1672209398246106, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.0001933936873683706}, {"id": 229, "seek": 140904, "start": 1414.0, "end": 1419.24, "text": " We are not in SPAC, but we are supporting SPAC, especially to do such things by specifying", "tokens": [492, 366, 406, 294, 8420, 4378, 11, 457, 321, 366, 7231, 8420, 4378, 11, 2318, 281, 360, 1270, 721, 538, 1608, 5489], "temperature": 0.0, "avg_logprob": -0.1672209398246106, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.0001933936873683706}, {"id": 230, "seek": 140904, "start": 1419.24, "end": 1427.48, "text": " a simple package, a simple spec package, we will be able to check any combination of building", "tokens": [257, 2199, 7372, 11, 257, 2199, 1608, 7372, 11, 321, 486, 312, 1075, 281, 1520, 604, 6562, 295, 2390], "temperature": 0.0, "avg_logprob": -0.1672209398246106, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.0001933936873683706}, {"id": 231, "seek": 140904, "start": 1427.48, "end": 1433.8, "text": " this package to see if there is some curiosity into your package recipe.", "tokens": [341, 7372, 281, 536, 498, 456, 307, 512, 18769, 666, 428, 7372, 6782, 13], "temperature": 0.0, "avg_logprob": -0.1672209398246106, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.0001933936873683706}, {"id": 232, "seek": 143380, "start": 1433.8, "end": 1442.1599999999999, "text": " For future work, we have many things scheduled, and most of the most interesting in the capture", "tokens": [1171, 2027, 589, 11, 321, 362, 867, 721, 15678, 11, 293, 881, 295, 264, 881, 1880, 294, 264, 7983], "temperature": 0.0, "avg_logprob": -0.2562582998564749, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.0003828234039247036}, {"id": 233, "seek": 143380, "start": 1442.1599999999999, "end": 1449.9199999999998, "text": " in metrics, the capacity to PCVS to capture directly some metadata to be able to then", "tokens": [294, 16367, 11, 264, 6042, 281, 6465, 53, 50, 281, 7983, 3838, 512, 26603, 281, 312, 1075, 281, 550], "temperature": 0.0, "avg_logprob": -0.2562582998564749, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.0003828234039247036}, {"id": 234, "seek": 143380, "start": 1449.9199999999998, "end": 1457.1599999999999, "text": " run analysis on them, and many other things, but I think I'm running out of time.", "tokens": [1190, 5215, 322, 552, 11, 293, 867, 661, 721, 11, 457, 286, 519, 286, 478, 2614, 484, 295, 565, 13], "temperature": 0.0, "avg_logprob": -0.2562582998564749, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.0003828234039247036}, {"id": 235, "seek": 145716, "start": 1457.16, "end": 1472.6000000000001, "text": " Thanks for your attention, I have two questions.", "tokens": [2561, 337, 428, 3202, 11, 286, 362, 732, 1651, 13], "temperature": 0.0, "avg_logprob": -0.24474400036955532, "compression_ratio": 1.6010928961748634, "no_speech_prob": 0.004464192781597376}, {"id": 236, "seek": 145716, "start": 1472.6000000000001, "end": 1477.3600000000001, "text": " From your configuration file, I assume you already have control of the cluster, at least", "tokens": [3358, 428, 11694, 3991, 11, 286, 6552, 291, 1217, 362, 1969, 295, 264, 13630, 11, 412, 1935], "temperature": 0.0, "avg_logprob": -0.24474400036955532, "compression_ratio": 1.6010928961748634, "no_speech_prob": 0.004464192781597376}, {"id": 237, "seek": 145716, "start": 1477.3600000000001, "end": 1479.92, "text": " you have allocated some nodes or something.", "tokens": [291, 362, 29772, 512, 13891, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.24474400036955532, "compression_ratio": 1.6010928961748634, "no_speech_prob": 0.004464192781597376}, {"id": 238, "seek": 145716, "start": 1479.92, "end": 1485.0, "text": " Do you have some step that then allocates and deallocates these resources on the fly", "tokens": [1144, 291, 362, 512, 1823, 300, 550, 12660, 1024, 293, 368, 336, 905, 1024, 613, 3593, 322, 264, 3603], "temperature": 0.0, "avg_logprob": -0.24474400036955532, "compression_ratio": 1.6010928961748634, "no_speech_prob": 0.004464192781597376}, {"id": 239, "seek": 145716, "start": 1485.0, "end": 1486.68, "text": " for each one of the tests?", "tokens": [337, 1184, 472, 295, 264, 6921, 30], "temperature": 0.0, "avg_logprob": -0.24474400036955532, "compression_ratio": 1.6010928961748634, "no_speech_prob": 0.004464192781597376}, {"id": 240, "seek": 148668, "start": 1486.68, "end": 1493.16, "text": " So actually, currently, most of our test scenario has run through an MPI run with slurm enabled", "tokens": [407, 767, 11, 4362, 11, 881, 295, 527, 1500, 9005, 575, 1190, 807, 364, 14146, 40, 1190, 365, 1061, 26717, 15172], "temperature": 0.0, "avg_logprob": -0.3043285409609477, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.0011278220918029547}, {"id": 241, "seek": 148668, "start": 1493.16, "end": 1499.16, "text": " or srun commands directly, so they are taking care of the resource allocations.", "tokens": [420, 262, 12997, 16901, 3838, 11, 370, 436, 366, 1940, 1127, 295, 264, 7684, 12660, 763, 13], "temperature": 0.0, "avg_logprob": -0.3043285409609477, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.0011278220918029547}, {"id": 242, "seek": 148668, "start": 1499.16, "end": 1506.6000000000001, "text": " Some other users are just running the whole PCVS inside a given allocation, like resource", "tokens": [2188, 661, 5022, 366, 445, 2614, 264, 1379, 6465, 53, 50, 1854, 257, 2212, 27599, 11, 411, 7684], "temperature": 0.0, "avg_logprob": -0.3043285409609477, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.0011278220918029547}, {"id": 243, "seek": 148668, "start": 1506.6000000000001, "end": 1511.5600000000002, "text": " allocation, just a saloc, for example, and then any test doing srun does not pay the", "tokens": [27599, 11, 445, 257, 1845, 905, 11, 337, 1365, 11, 293, 550, 604, 1500, 884, 262, 12997, 775, 406, 1689, 264], "temperature": 0.0, "avg_logprob": -0.3043285409609477, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.0011278220918029547}, {"id": 244, "seek": 148668, "start": 1511.5600000000002, "end": 1513.8400000000001, "text": " cost of waiting the actual speed.", "tokens": [2063, 295, 3806, 264, 3539, 3073, 13], "temperature": 0.0, "avg_logprob": -0.3043285409609477, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.0011278220918029547}, {"id": 245, "seek": 151384, "start": 1513.84, "end": 1518.6, "text": " If some tests need some type of CPU, the other tests need other type of CPU, then you need", "tokens": [759, 512, 6921, 643, 512, 2010, 295, 13199, 11, 264, 661, 6921, 643, 661, 2010, 295, 13199, 11, 550, 291, 643], "temperature": 0.0, "avg_logprob": -0.22537811129700905, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0026311837136745453}, {"id": 246, "seek": 151384, "start": 1518.6, "end": 1524.08, "text": " to, and if one of them is unavailable because an other user is using, you have to wait instead", "tokens": [281, 11, 293, 498, 472, 295, 552, 307, 36541, 32699, 570, 364, 661, 4195, 307, 1228, 11, 291, 362, 281, 1699, 2602], "temperature": 0.0, "avg_logprob": -0.22537811129700905, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0026311837136745453}, {"id": 247, "seek": 151384, "start": 1524.08, "end": 1525.08, "text": " of fail.", "tokens": [295, 3061, 13], "temperature": 0.0, "avg_logprob": -0.22537811129700905, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0026311837136745453}, {"id": 248, "seek": 151384, "start": 1525.08, "end": 1531.9199999999998, "text": " Yes, this is something we still haven't had a solution for, would be to be able to put", "tokens": [1079, 11, 341, 307, 746, 321, 920, 2378, 380, 632, 257, 3827, 337, 11, 576, 312, 281, 312, 1075, 281, 829], "temperature": 0.0, "avg_logprob": -0.22537811129700905, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0026311837136745453}, {"id": 249, "seek": 151384, "start": 1531.9199999999998, "end": 1535.52, "text": " a job aside while we have the allocation.", "tokens": [257, 1691, 7359, 1339, 321, 362, 264, 27599, 13], "temperature": 0.0, "avg_logprob": -0.22537811129700905, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0026311837136745453}, {"id": 250, "seek": 151384, "start": 1535.52, "end": 1538.52, "text": " Yes, this is something we are currently investigating, absolutely.", "tokens": [1079, 11, 341, 307, 746, 321, 366, 4362, 22858, 11, 3122, 13], "temperature": 0.0, "avg_logprob": -0.22537811129700905, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0026311837136745453}, {"id": 251, "seek": 153852, "start": 1538.52, "end": 1545.52, "text": " Do you have any questions?", "tokens": [1144, 291, 362, 604, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2604194740196327, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.0005414928891696036}, {"id": 252, "seek": 153852, "start": 1545.52, "end": 1556.32, "text": " Yeah, so one thing that I wanted to ask was kind of for your future work you had mentioned", "tokens": [865, 11, 370, 472, 551, 300, 286, 1415, 281, 1029, 390, 733, 295, 337, 428, 2027, 589, 291, 632, 2835], "temperature": 0.0, "avg_logprob": -0.2604194740196327, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.0005414928891696036}, {"id": 253, "seek": 153852, "start": 1556.32, "end": 1563.12, "text": " building out a graphical front end using textualize, I was kind of wondering how much assessment", "tokens": [2390, 484, 257, 35942, 1868, 917, 1228, 2487, 901, 1125, 11, 286, 390, 733, 295, 6359, 577, 709, 9687], "temperature": 0.0, "avg_logprob": -0.2604194740196327, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.0005414928891696036}, {"id": 254, "seek": 153852, "start": 1563.12, "end": 1567.12, "text": " have you done into that, because I've done some work like trying to build GUIs with textualize", "tokens": [362, 291, 1096, 666, 300, 11, 570, 286, 600, 1096, 512, 589, 411, 1382, 281, 1322, 17917, 6802, 365, 2487, 901, 1125], "temperature": 0.0, "avg_logprob": -0.2604194740196327, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.0005414928891696036}, {"id": 255, "seek": 156712, "start": 1567.12, "end": 1573.3999999999999, "text": " and while I do think that it's very interesting framework and it's great for making textual", "tokens": [293, 1339, 286, 360, 519, 300, 309, 311, 588, 1880, 8388, 293, 309, 311, 869, 337, 1455, 2487, 901], "temperature": 0.0, "avg_logprob": -0.23114114878128986, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.0004265069728717208}, {"id": 256, "seek": 156712, "start": 1573.3999999999999, "end": 1579.0, "text": " GUIs, I think that it still has a bit of a way to come before it can really make a standalone", "tokens": [17917, 6802, 11, 286, 519, 300, 309, 920, 575, 257, 857, 295, 257, 636, 281, 808, 949, 309, 393, 534, 652, 257, 37454], "temperature": 0.0, "avg_logprob": -0.23114114878128986, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.0004265069728717208}, {"id": 257, "seek": 156712, "start": 1579.0, "end": 1584.4799999999998, "text": " or comprehensive seal or a textual interface, so I was just wondering what your thoughts", "tokens": [420, 13914, 12185, 420, 257, 2487, 901, 9226, 11, 370, 286, 390, 445, 6359, 437, 428, 4598], "temperature": 0.0, "avg_logprob": -0.23114114878128986, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.0004265069728717208}, {"id": 258, "seek": 156712, "start": 1584.4799999999998, "end": 1585.4799999999998, "text": " were on that.", "tokens": [645, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.23114114878128986, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.0004265069728717208}, {"id": 259, "seek": 156712, "start": 1585.4799999999998, "end": 1591.4799999999998, "text": " I'm not sure, I understand the whole question, but you mean, why did we choose textualize?", "tokens": [286, 478, 406, 988, 11, 286, 1223, 264, 1379, 1168, 11, 457, 291, 914, 11, 983, 630, 321, 2826, 2487, 901, 1125, 30], "temperature": 0.0, "avg_logprob": -0.23114114878128986, "compression_ratio": 1.5791666666666666, "no_speech_prob": 0.0004265069728717208}, {"id": 260, "seek": 159148, "start": 1591.48, "end": 1600.24, "text": " Absolutely, we discovered just recently because we were using Rich to highlight the output", "tokens": [7021, 11, 321, 6941, 445, 3938, 570, 321, 645, 1228, 6781, 281, 5078, 264, 5598], "temperature": 0.0, "avg_logprob": -0.230774450302124, "compression_ratio": 1.5139664804469273, "no_speech_prob": 0.0009045129409059882}, {"id": 261, "seek": 159148, "start": 1600.24, "end": 1608.44, "text": " of PCVS within the console and we are looking for a solution to present the things graphically", "tokens": [295, 6465, 53, 50, 1951, 264, 11076, 293, 321, 366, 1237, 337, 257, 3827, 281, 1974, 264, 721, 4295, 984], "temperature": 0.0, "avg_logprob": -0.230774450302124, "compression_ratio": 1.5139664804469273, "no_speech_prob": 0.0009045129409059882}, {"id": 262, "seek": 159148, "start": 1608.44, "end": 1617.4, "text": " in a terminal and we still are looking for the ideal framework and as Rich is already", "tokens": [294, 257, 14709, 293, 321, 920, 366, 1237, 337, 264, 7157, 8388, 293, 382, 6781, 307, 1217], "temperature": 0.0, "avg_logprob": -0.230774450302124, "compression_ratio": 1.5139664804469273, "no_speech_prob": 0.0009045129409059882}, {"id": 263, "seek": 161740, "start": 1617.4, "end": 1621.96, "text": " as textualize, I'm sorry, it's based on that, we are considering textualize, but if you", "tokens": [382, 2487, 901, 1125, 11, 286, 478, 2597, 11, 309, 311, 2361, 322, 300, 11, 321, 366, 8079, 2487, 901, 1125, 11, 457, 498, 291], "temperature": 0.0, "avg_logprob": -0.3036165417365308, "compression_ratio": 1.3432835820895523, "no_speech_prob": 0.005599722731858492}, {"id": 264, "seek": 161740, "start": 1621.96, "end": 1627.0400000000002, "text": " have any other offer to propose, I would be happy to discuss with you about that.", "tokens": [362, 604, 661, 2626, 281, 17421, 11, 286, 576, 312, 2055, 281, 2248, 365, 291, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.3036165417365308, "compression_ratio": 1.3432835820895523, "no_speech_prob": 0.005599722731858492}, {"id": 265, "seek": 162704, "start": 1627.04, "end": 1648.84, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 51454], "temperature": 0.0, "avg_logprob": -0.7807378768920898, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.00097639299929142}], "language": "en"}