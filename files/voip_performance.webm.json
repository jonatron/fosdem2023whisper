{"text": " Thank you, thank you for joining the talk, welcome to my lightning talk. I want to talk today about performance optimization for voice of IP services. If you want to go out, please do it quietly, thank you very much. Quick to the agenda, just one example how to not achieve great performance. This is a real-life customer example, you probably will spot it immediately, what is the problem, just some guidelines on to approach performance problems. A few areas where you might want to look, some general examples for tools that you could use, that are interesting to use, of course for ten minutes it's not possible to go to a in-deep analysis of both performance topics, but nevertheless I hope it will be useful for you. My name is Henning, I started some time ago a company, we provide services for real-time communication services, work mostly with Camalio, do also a lot of other stuff, but I said mostly Camalio, if you're interested in the new stuff that's going on for the upcoming release in Camalio, please have a look to our website camalio.org, I didn't include it in this talk because it's not too much time. To the example, how to not achieve great performance, this is a real-life customer example, we were called to debug it during Covid, of course a lot of communications platform broke down during that time because of the increased demand, so the customer needed to make a routing decision in a SIP proxy in Camalio and what he did was basically use the exec module, exec module is generally a bad idea, you can use this to execute code or scripts on the system, use this to start a Perl script, the Perl script was then using a database layer in the Perl to access remote database, this database result would be reported back to Camalio, Camalio would pass it somehow into some JSON operations, process the message and this of course it works if you don't have a large load, but as soon as you get a higher concurrent call ratio on the system, of course this breaks down for obvious reasons because for every call you start a Perl script and this this will not going to work, this will not going to scale and if you have latency on the database all these Perl script invocations will take a long time, of course it will completely break down. Generally how to address performance problems, if you are an experienced operator experiences admin, this are probably no news for you, nevertheless of course most performance issues are not that obvious as in this example you should formulate a goal, okay I want to achieve that many concurrent calls, I need to support that many register messages on the platform, that many devices, I want to have I don't know 50,000, 100,000 concurrent connected user agent over TLS, whatever protocol you are using, WebRTC and in the best case of course you have some statistics, later we see some presentations about statistic projects from production load, maybe you have incidents where the system broke down or in the best case of course you have some performance test result. Generally speaking if you have performance issues we can cluster them in several performance related areas mostly related to machines, virtual machines, first side on the first hand you have CPU, Camelio in particular is really performant, normally you don't have performance issues there, Asterix is done in another story free switch as well, normally one frequent issue you might encounter is that if you have like a two large other commitment on your virtual system, virtual infrastructure, just keep in mind the physical core is not a virtual core of course, sometimes you have issues with other services running on the system, configuration management, maybe some void monitoring whatever you're using also in the system which causes a lot of CPU congestion, maybe you should adapt the Camelio worker configuration, the defaults are usually fine but nevertheless sometimes you need to adapt it. Related to the memory, Camelio if you install it from the default installation you definitely should increase the memory pool, the defaults are not really meant for production use, if you have a database of course normal tuning guidelines apply here, you should give the database plenty of memory, memory is cheap nowadays, if you have an HTTP API service maybe written in some Java service whatever Java language you should give them as well of course a lot of memory to perform correctly. In really special cases it's also might be a good idea to look to the Camelio memory manager default, it uses a bit the memory manager which is more suited for which has some debugging support built in, there's another memory manager without this debugging support but like a 99% of all infrastructure and scenarios you'd never use it, no never never need to change it but in some cases it might be beneficial to look into that. Most problems are usually related to IO, IO performance, yeah of course voice over PESIP is the protocol, it's relayed on DNS as most of the protocols out there, if the DNS is slow then also your server will be slow, Camelio uses an internal DNS cache, if you use Astrix there is no cache unfortunately so you should use DNS mask or something similar or keep some local DNS server in your data center in your infrastructure. For zip for real-time communication you need to write usually user registration this is something you can of course optimize, you can cache it, for Astrix there's something called Qualify which you use real-time infrastructure, this makes sense to tune maybe to deactivate it because it will basically scale with the number of your user and the write load will be also scale as well. Logging of course you need to look to it if you really need to log everything or maybe you can tune it to adapt to your scenario it makes sense to restrict it also with not only with Camelio of course with Astrix or other servers as well, if you have a lot of read operations they can usually cache quite well on Camelio, there's a htable module for Camelio you can use caching the data, you can also use something like read only replication, read is memcache whatever to scale that. The same for remote HTTP API requests this is also something you can cache of course. CDR writing we just saw call talk about CG rates, great project that offer these CDR capabilities, Camelio can also write CDRs internally but of course for highly loaded platforms it might sense to move it to another process to another system to have some asynchronous process doing the CDRs and not to affect the server operation and of course as we just saw in the beginning you should not fork processes if you rely on performance. What you could use for performance test one thing which is still used a lot is the old classical zp, there's pjwa you can script it a lot with Python or other bindings, they are dedicated to performance test frameworks usually they are homegrown or closed source unfortunately but they are the stuff you can pay or you can of course build by yourself. If you have a database hdp which is actually the bottleneck you can of course use custom tools to test the database to test the hdp API. Then for a start of course you see common tools to get inside about the cpu, the IO, the network situation, that can give you a lot of information if there's some pressure on the sockets for udp especially in particular. If you have tools like Humair we see a talk later about that as well, wipe monitor another tool of course the classical Isengar, Grafana, whatever statistics you have in house. Camelio offers also some benchmarks module and you can also adapt the logging a lot to your requirements. Okay that's all from my side thank you very much, just a quick pointer, we're doing Camelio world this year in presence again I'm really happy about that, it will happen at the beginning of June in Berlin called for papers was open so if you're interested in presenting something interesting there go ahead we are looking forward to your contributions there as well. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 25.560000000000002, "text": " Thank you, thank you for joining the talk, welcome to my lightning talk.", "tokens": [50364, 1044, 291, 11, 1309, 291, 337, 5549, 264, 751, 11, 2928, 281, 452, 16589, 751, 13, 51642], "temperature": 0.0, "avg_logprob": -0.35771100521087645, "compression_ratio": 1.0909090909090908, "no_speech_prob": 0.3185620605945587}, {"id": 1, "seek": 2556, "start": 25.56, "end": 32.2, "text": " I want to talk today about performance optimization for voice of IP services.", "tokens": [50364, 286, 528, 281, 751, 965, 466, 3389, 19618, 337, 3177, 295, 8671, 3328, 13, 50696], "temperature": 0.0, "avg_logprob": -0.3065267692912709, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.3747992515563965}, {"id": 2, "seek": 2556, "start": 35.2, "end": 37.6, "text": " If you want to go out, please do it quietly, thank you very much.", "tokens": [50846, 759, 291, 528, 281, 352, 484, 11, 1767, 360, 309, 19141, 11, 1309, 291, 588, 709, 13, 50966], "temperature": 0.0, "avg_logprob": -0.3065267692912709, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.3747992515563965}, {"id": 3, "seek": 2556, "start": 39.84, "end": 44.44, "text": " Quick to the agenda, just one example how to not achieve great performance.", "tokens": [51078, 12101, 281, 264, 9829, 11, 445, 472, 1365, 577, 281, 406, 4584, 869, 3389, 13, 51308], "temperature": 0.0, "avg_logprob": -0.3065267692912709, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.3747992515563965}, {"id": 4, "seek": 2556, "start": 44.44, "end": 47.519999999999996, "text": " This is a real-life customer example, you probably will spot it immediately,", "tokens": [51308, 639, 307, 257, 957, 12, 9073, 5474, 1365, 11, 291, 1391, 486, 4008, 309, 4258, 11, 51462], "temperature": 0.0, "avg_logprob": -0.3065267692912709, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.3747992515563965}, {"id": 5, "seek": 2556, "start": 47.519999999999996, "end": 53.16, "text": " what is the problem, just some guidelines on to approach performance problems.", "tokens": [51462, 437, 307, 264, 1154, 11, 445, 512, 12470, 322, 281, 3109, 3389, 2740, 13, 51744], "temperature": 0.0, "avg_logprob": -0.3065267692912709, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.3747992515563965}, {"id": 6, "seek": 5316, "start": 54.12, "end": 61.48, "text": " A few areas where you might want to look, some general examples for tools that you could use,", "tokens": [50412, 316, 1326, 3179, 689, 291, 1062, 528, 281, 574, 11, 512, 2674, 5110, 337, 3873, 300, 291, 727, 764, 11, 50780], "temperature": 0.0, "avg_logprob": -0.2954792658487956, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.06329936534166336}, {"id": 7, "seek": 5316, "start": 61.48, "end": 65.6, "text": " that are interesting to use, of course for ten minutes it's not possible to go to a", "tokens": [50780, 300, 366, 1880, 281, 764, 11, 295, 1164, 337, 2064, 2077, 309, 311, 406, 1944, 281, 352, 281, 257, 50986], "temperature": 0.0, "avg_logprob": -0.2954792658487956, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.06329936534166336}, {"id": 8, "seek": 5316, "start": 65.6, "end": 70.96, "text": " in-deep analysis of both performance topics, but nevertheless I hope it will be useful for you.", "tokens": [50986, 294, 12, 38422, 5215, 295, 1293, 3389, 8378, 11, 457, 26924, 286, 1454, 309, 486, 312, 4420, 337, 291, 13, 51254], "temperature": 0.0, "avg_logprob": -0.2954792658487956, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.06329936534166336}, {"id": 9, "seek": 5316, "start": 70.96, "end": 78.67999999999999, "text": " My name is Henning, I started some time ago a company, we provide services for real-time", "tokens": [51254, 1222, 1315, 307, 8651, 773, 11, 286, 1409, 512, 565, 2057, 257, 2237, 11, 321, 2893, 3328, 337, 957, 12, 3766, 51640], "temperature": 0.0, "avg_logprob": -0.2954792658487956, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.06329936534166336}, {"id": 10, "seek": 7868, "start": 78.68, "end": 83.28, "text": " communication services, work mostly with Camalio, do also a lot of other stuff,", "tokens": [50364, 6101, 3328, 11, 589, 5240, 365, 6886, 304, 1004, 11, 360, 611, 257, 688, 295, 661, 1507, 11, 50594], "temperature": 0.0, "avg_logprob": -0.2124456032035277, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.13872896134853363}, {"id": 11, "seek": 7868, "start": 83.28, "end": 88.64000000000001, "text": " but I said mostly Camalio, if you're interested in the new stuff that's going on for the upcoming", "tokens": [50594, 457, 286, 848, 5240, 6886, 304, 1004, 11, 498, 291, 434, 3102, 294, 264, 777, 1507, 300, 311, 516, 322, 337, 264, 11500, 50862], "temperature": 0.0, "avg_logprob": -0.2124456032035277, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.13872896134853363}, {"id": 12, "seek": 7868, "start": 88.64000000000001, "end": 95.72, "text": " release in Camalio, please have a look to our website camalio.org, I didn't include it in this", "tokens": [50862, 4374, 294, 6886, 304, 1004, 11, 1767, 362, 257, 574, 281, 527, 3144, 1945, 304, 1004, 13, 4646, 11, 286, 994, 380, 4090, 309, 294, 341, 51216], "temperature": 0.0, "avg_logprob": -0.2124456032035277, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.13872896134853363}, {"id": 13, "seek": 7868, "start": 95.72, "end": 104.12, "text": " talk because it's not too much time. To the example, how to not achieve great performance,", "tokens": [51216, 751, 570, 309, 311, 406, 886, 709, 565, 13, 1407, 264, 1365, 11, 577, 281, 406, 4584, 869, 3389, 11, 51636], "temperature": 0.0, "avg_logprob": -0.2124456032035277, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.13872896134853363}, {"id": 14, "seek": 10412, "start": 104.12, "end": 108.0, "text": " this is a real-life customer example, we were called to debug it during Covid,", "tokens": [50364, 341, 307, 257, 957, 12, 9073, 5474, 1365, 11, 321, 645, 1219, 281, 24083, 309, 1830, 14633, 11, 50558], "temperature": 0.0, "avg_logprob": -0.19730560801853644, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.03554380685091019}, {"id": 15, "seek": 10412, "start": 108.0, "end": 112.44, "text": " of course a lot of communications platform broke down during that time because of the", "tokens": [50558, 295, 1164, 257, 688, 295, 15163, 3663, 6902, 760, 1830, 300, 565, 570, 295, 264, 50780], "temperature": 0.0, "avg_logprob": -0.19730560801853644, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.03554380685091019}, {"id": 16, "seek": 10412, "start": 112.44, "end": 117.84, "text": " increased demand, so the customer needed to make a routing decision in a SIP proxy in", "tokens": [50780, 6505, 4733, 11, 370, 264, 5474, 2978, 281, 652, 257, 32722, 3537, 294, 257, 318, 9139, 29690, 294, 51050], "temperature": 0.0, "avg_logprob": -0.19730560801853644, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.03554380685091019}, {"id": 17, "seek": 10412, "start": 117.84, "end": 122.60000000000001, "text": " Camalio and what he did was basically use the exec module, exec module is generally a bad idea,", "tokens": [51050, 6886, 304, 1004, 293, 437, 415, 630, 390, 1936, 764, 264, 4454, 10088, 11, 4454, 10088, 307, 5101, 257, 1578, 1558, 11, 51288], "temperature": 0.0, "avg_logprob": -0.19730560801853644, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.03554380685091019}, {"id": 18, "seek": 10412, "start": 122.60000000000001, "end": 129.32, "text": " you can use this to execute code or scripts on the system, use this to start a Perl script,", "tokens": [51288, 291, 393, 764, 341, 281, 14483, 3089, 420, 23294, 322, 264, 1185, 11, 764, 341, 281, 722, 257, 3026, 75, 5755, 11, 51624], "temperature": 0.0, "avg_logprob": -0.19730560801853644, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.03554380685091019}, {"id": 19, "seek": 12932, "start": 129.32, "end": 134.84, "text": " the Perl script was then using a database layer in the Perl to access remote database,", "tokens": [50364, 264, 3026, 75, 5755, 390, 550, 1228, 257, 8149, 4583, 294, 264, 3026, 75, 281, 2105, 8607, 8149, 11, 50640], "temperature": 0.0, "avg_logprob": -0.18352994212397822, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.0078111072070896626}, {"id": 20, "seek": 12932, "start": 134.84, "end": 140.35999999999999, "text": " this database result would be reported back to Camalio, Camalio would pass it somehow into", "tokens": [50640, 341, 8149, 1874, 576, 312, 7055, 646, 281, 6886, 304, 1004, 11, 6886, 304, 1004, 576, 1320, 309, 6063, 666, 50916], "temperature": 0.0, "avg_logprob": -0.18352994212397822, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.0078111072070896626}, {"id": 21, "seek": 12932, "start": 140.35999999999999, "end": 145.44, "text": " some JSON operations, process the message and this of course it works if you don't have a", "tokens": [50916, 512, 31828, 7705, 11, 1399, 264, 3636, 293, 341, 295, 1164, 309, 1985, 498, 291, 500, 380, 362, 257, 51170], "temperature": 0.0, "avg_logprob": -0.18352994212397822, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.0078111072070896626}, {"id": 22, "seek": 12932, "start": 145.44, "end": 151.64, "text": " large load, but as soon as you get a higher concurrent call ratio on the system, of course", "tokens": [51170, 2416, 3677, 11, 457, 382, 2321, 382, 291, 483, 257, 2946, 37702, 818, 8509, 322, 264, 1185, 11, 295, 1164, 51480], "temperature": 0.0, "avg_logprob": -0.18352994212397822, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.0078111072070896626}, {"id": 23, "seek": 12932, "start": 151.64, "end": 156.84, "text": " this breaks down for obvious reasons because for every call you start a Perl script and this", "tokens": [51480, 341, 9857, 760, 337, 6322, 4112, 570, 337, 633, 818, 291, 722, 257, 3026, 75, 5755, 293, 341, 51740], "temperature": 0.0, "avg_logprob": -0.18352994212397822, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.0078111072070896626}, {"id": 24, "seek": 15684, "start": 157.24, "end": 163.16, "text": " this will not going to work, this will not going to scale and if you have latency on the database", "tokens": [50384, 341, 486, 406, 516, 281, 589, 11, 341, 486, 406, 516, 281, 4373, 293, 498, 291, 362, 27043, 322, 264, 8149, 50680], "temperature": 0.0, "avg_logprob": -0.17937485568494682, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.0010154134361073375}, {"id": 25, "seek": 15684, "start": 163.16, "end": 167.96, "text": " all these Perl script invocations will take a long time, of course it will completely break down.", "tokens": [50680, 439, 613, 3026, 75, 5755, 1048, 905, 763, 486, 747, 257, 938, 565, 11, 295, 1164, 309, 486, 2584, 1821, 760, 13, 50920], "temperature": 0.0, "avg_logprob": -0.17937485568494682, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.0010154134361073375}, {"id": 26, "seek": 15684, "start": 171.56, "end": 176.68, "text": " Generally how to address performance problems, if you are an experienced operator experiences", "tokens": [51100, 21082, 577, 281, 2985, 3389, 2740, 11, 498, 291, 366, 364, 6751, 12973, 5235, 51356], "temperature": 0.0, "avg_logprob": -0.17937485568494682, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.0010154134361073375}, {"id": 27, "seek": 15684, "start": 176.68, "end": 181.72, "text": " admin, this are probably no news for you, nevertheless of course most performance issues", "tokens": [51356, 24236, 11, 341, 366, 1391, 572, 2583, 337, 291, 11, 26924, 295, 1164, 881, 3389, 2663, 51608], "temperature": 0.0, "avg_logprob": -0.17937485568494682, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.0010154134361073375}, {"id": 28, "seek": 18172, "start": 181.72, "end": 186.92, "text": " are not that obvious as in this example you should formulate a goal, okay I want to achieve", "tokens": [50364, 366, 406, 300, 6322, 382, 294, 341, 1365, 291, 820, 47881, 257, 3387, 11, 1392, 286, 528, 281, 4584, 50624], "temperature": 0.0, "avg_logprob": -0.13989552391899956, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.018254686146974564}, {"id": 29, "seek": 18172, "start": 186.92, "end": 191.88, "text": " that many concurrent calls, I need to support that many register messages on the platform,", "tokens": [50624, 300, 867, 37702, 5498, 11, 286, 643, 281, 1406, 300, 867, 7280, 7897, 322, 264, 3663, 11, 50872], "temperature": 0.0, "avg_logprob": -0.13989552391899956, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.018254686146974564}, {"id": 30, "seek": 18172, "start": 191.88, "end": 197.72, "text": " that many devices, I want to have I don't know 50,000, 100,000 concurrent connected", "tokens": [50872, 300, 867, 5759, 11, 286, 528, 281, 362, 286, 500, 380, 458, 2625, 11, 1360, 11, 2319, 11, 1360, 37702, 4582, 51164], "temperature": 0.0, "avg_logprob": -0.13989552391899956, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.018254686146974564}, {"id": 31, "seek": 18172, "start": 197.72, "end": 204.2, "text": " user agent over TLS, whatever protocol you are using, WebRTC and in the best case of course you", "tokens": [51164, 4195, 9461, 670, 314, 19198, 11, 2035, 10336, 291, 366, 1228, 11, 9573, 49, 18238, 293, 294, 264, 1151, 1389, 295, 1164, 291, 51488], "temperature": 0.0, "avg_logprob": -0.13989552391899956, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.018254686146974564}, {"id": 32, "seek": 20420, "start": 204.2, "end": 211.48, "text": " have some statistics, later we see some presentations about statistic projects", "tokens": [50364, 362, 512, 12523, 11, 1780, 321, 536, 512, 18964, 466, 29588, 4455, 50728], "temperature": 0.0, "avg_logprob": -0.19317504151226722, "compression_ratio": 1.7605633802816902, "no_speech_prob": 0.0007095683831721544}, {"id": 33, "seek": 20420, "start": 211.48, "end": 217.48, "text": " from production load, maybe you have incidents where the system broke down or in the best case", "tokens": [50728, 490, 4265, 3677, 11, 1310, 291, 362, 21139, 689, 264, 1185, 6902, 760, 420, 294, 264, 1151, 1389, 51028], "temperature": 0.0, "avg_logprob": -0.19317504151226722, "compression_ratio": 1.7605633802816902, "no_speech_prob": 0.0007095683831721544}, {"id": 34, "seek": 20420, "start": 217.48, "end": 223.0, "text": " of course you have some performance test result. Generally speaking if you have performance issues", "tokens": [51028, 295, 1164, 291, 362, 512, 3389, 1500, 1874, 13, 21082, 4124, 498, 291, 362, 3389, 2663, 51304], "temperature": 0.0, "avg_logprob": -0.19317504151226722, "compression_ratio": 1.7605633802816902, "no_speech_prob": 0.0007095683831721544}, {"id": 35, "seek": 20420, "start": 223.64, "end": 229.64, "text": " we can cluster them in several performance related areas mostly related to machines, virtual machines,", "tokens": [51336, 321, 393, 13630, 552, 294, 2940, 3389, 4077, 3179, 5240, 4077, 281, 8379, 11, 6374, 8379, 11, 51636], "temperature": 0.0, "avg_logprob": -0.19317504151226722, "compression_ratio": 1.7605633802816902, "no_speech_prob": 0.0007095683831721544}, {"id": 36, "seek": 22964, "start": 229.88, "end": 236.27999999999997, "text": " first side on the first hand you have CPU, Camelio in particular is really", "tokens": [50376, 700, 1252, 322, 264, 700, 1011, 291, 362, 13199, 11, 6886, 338, 1004, 294, 1729, 307, 534, 50696], "temperature": 0.0, "avg_logprob": -0.24638958366549746, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.0053808786906301975}, {"id": 37, "seek": 22964, "start": 237.0, "end": 241.23999999999998, "text": " performant, normally you don't have performance issues there, Asterix is done in another story", "tokens": [50732, 2042, 394, 11, 5646, 291, 500, 380, 362, 3389, 2663, 456, 11, 316, 3120, 970, 307, 1096, 294, 1071, 1657, 50944], "temperature": 0.0, "avg_logprob": -0.24638958366549746, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.0053808786906301975}, {"id": 38, "seek": 22964, "start": 241.23999999999998, "end": 248.27999999999997, "text": " free switch as well, normally one frequent issue you might encounter is that if you have", "tokens": [50944, 1737, 3679, 382, 731, 11, 5646, 472, 18004, 2734, 291, 1062, 8593, 307, 300, 498, 291, 362, 51296], "temperature": 0.0, "avg_logprob": -0.24638958366549746, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.0053808786906301975}, {"id": 39, "seek": 22964, "start": 248.27999999999997, "end": 253.0, "text": " like a two large other commitment on your virtual system, virtual infrastructure,", "tokens": [51296, 411, 257, 732, 2416, 661, 8371, 322, 428, 6374, 1185, 11, 6374, 6896, 11, 51532], "temperature": 0.0, "avg_logprob": -0.24638958366549746, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.0053808786906301975}, {"id": 40, "seek": 22964, "start": 253.0, "end": 258.68, "text": " just keep in mind the physical core is not a virtual core of course, sometimes you have", "tokens": [51532, 445, 1066, 294, 1575, 264, 4001, 4965, 307, 406, 257, 6374, 4965, 295, 1164, 11, 2171, 291, 362, 51816], "temperature": 0.0, "avg_logprob": -0.24638958366549746, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.0053808786906301975}, {"id": 41, "seek": 25868, "start": 258.68, "end": 262.52, "text": " issues with other services running on the system, configuration management,", "tokens": [50364, 2663, 365, 661, 3328, 2614, 322, 264, 1185, 11, 11694, 4592, 11, 50556], "temperature": 0.0, "avg_logprob": -0.17807475431465808, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.001015639747492969}, {"id": 42, "seek": 25868, "start": 262.52, "end": 267.24, "text": " maybe some void monitoring whatever you're using also in the system which causes a lot of CPU", "tokens": [50556, 1310, 512, 22009, 11028, 2035, 291, 434, 1228, 611, 294, 264, 1185, 597, 7700, 257, 688, 295, 13199, 50792], "temperature": 0.0, "avg_logprob": -0.17807475431465808, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.001015639747492969}, {"id": 43, "seek": 25868, "start": 268.2, "end": 275.8, "text": " congestion, maybe you should adapt the Camelio worker configuration, the defaults are usually fine", "tokens": [50840, 40816, 11, 1310, 291, 820, 6231, 264, 6886, 338, 1004, 11346, 11694, 11, 264, 7576, 82, 366, 2673, 2489, 51220], "temperature": 0.0, "avg_logprob": -0.17807475431465808, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.001015639747492969}, {"id": 44, "seek": 25868, "start": 275.8, "end": 284.28000000000003, "text": " but nevertheless sometimes you need to adapt it. Related to the memory, Camelio if you install it", "tokens": [51220, 457, 26924, 2171, 291, 643, 281, 6231, 309, 13, 8738, 770, 281, 264, 4675, 11, 6886, 338, 1004, 498, 291, 3625, 309, 51644], "temperature": 0.0, "avg_logprob": -0.17807475431465808, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.001015639747492969}, {"id": 45, "seek": 28428, "start": 284.28, "end": 289.96, "text": " from the default installation you definitely should increase the memory pool, the defaults are", "tokens": [50364, 490, 264, 7576, 13260, 291, 2138, 820, 3488, 264, 4675, 7005, 11, 264, 7576, 82, 366, 50648], "temperature": 0.0, "avg_logprob": -0.1125904365822121, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.0031713428907096386}, {"id": 46, "seek": 28428, "start": 289.96, "end": 296.11999999999995, "text": " not really meant for production use, if you have a database of course normal tuning guidelines", "tokens": [50648, 406, 534, 4140, 337, 4265, 764, 11, 498, 291, 362, 257, 8149, 295, 1164, 2710, 15164, 12470, 50956], "temperature": 0.0, "avg_logprob": -0.1125904365822121, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.0031713428907096386}, {"id": 47, "seek": 28428, "start": 296.11999999999995, "end": 301.4, "text": " apply here, you should give the database plenty of memory, memory is cheap nowadays, if you have an", "tokens": [50956, 3079, 510, 11, 291, 820, 976, 264, 8149, 7140, 295, 4675, 11, 4675, 307, 7084, 13434, 11, 498, 291, 362, 364, 51220], "temperature": 0.0, "avg_logprob": -0.1125904365822121, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.0031713428907096386}, {"id": 48, "seek": 28428, "start": 301.4, "end": 308.11999999999995, "text": " HTTP API service maybe written in some Java service whatever Java language you should give them as", "tokens": [51220, 33283, 9362, 2643, 1310, 3720, 294, 512, 10745, 2643, 2035, 10745, 2856, 291, 820, 976, 552, 382, 51556], "temperature": 0.0, "avg_logprob": -0.1125904365822121, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.0031713428907096386}, {"id": 49, "seek": 30812, "start": 308.12, "end": 315.08, "text": " well of course a lot of memory to perform correctly. In really special cases it's also", "tokens": [50364, 731, 295, 1164, 257, 688, 295, 4675, 281, 2042, 8944, 13, 682, 534, 2121, 3331, 309, 311, 611, 50712], "temperature": 0.0, "avg_logprob": -0.1534988424751196, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0018373298225924373}, {"id": 50, "seek": 30812, "start": 315.88, "end": 321.32, "text": " might be a good idea to look to the Camelio memory manager default, it uses a bit the memory manager", "tokens": [50752, 1062, 312, 257, 665, 1558, 281, 574, 281, 264, 6886, 338, 1004, 4675, 6598, 7576, 11, 309, 4960, 257, 857, 264, 4675, 6598, 51024], "temperature": 0.0, "avg_logprob": -0.1534988424751196, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0018373298225924373}, {"id": 51, "seek": 30812, "start": 321.32, "end": 328.84000000000003, "text": " which is more suited for which has some debugging support built in, there's another memory manager", "tokens": [51024, 597, 307, 544, 24736, 337, 597, 575, 512, 45592, 1406, 3094, 294, 11, 456, 311, 1071, 4675, 6598, 51400], "temperature": 0.0, "avg_logprob": -0.1534988424751196, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0018373298225924373}, {"id": 52, "seek": 30812, "start": 328.84000000000003, "end": 333.8, "text": " without this debugging support but like a 99% of all infrastructure and scenarios you'd never use it,", "tokens": [51400, 1553, 341, 45592, 1406, 457, 411, 257, 11803, 4, 295, 439, 6896, 293, 15077, 291, 1116, 1128, 764, 309, 11, 51648], "temperature": 0.0, "avg_logprob": -0.1534988424751196, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0018373298225924373}, {"id": 53, "seek": 33380, "start": 333.8, "end": 338.04, "text": " no never never need to change it but in some cases it might be beneficial to look into that.", "tokens": [50364, 572, 1128, 1128, 643, 281, 1319, 309, 457, 294, 512, 3331, 309, 1062, 312, 14072, 281, 574, 666, 300, 13, 50576], "temperature": 0.0, "avg_logprob": -0.18356182615635758, "compression_ratio": 1.67595818815331, "no_speech_prob": 0.0007095524342730641}, {"id": 54, "seek": 33380, "start": 340.36, "end": 346.04, "text": " Most problems are usually related to IO, IO performance, yeah of course voice over PESIP is", "tokens": [50692, 4534, 2740, 366, 2673, 4077, 281, 39839, 11, 39839, 3389, 11, 1338, 295, 1164, 3177, 670, 430, 2358, 9139, 307, 50976], "temperature": 0.0, "avg_logprob": -0.18356182615635758, "compression_ratio": 1.67595818815331, "no_speech_prob": 0.0007095524342730641}, {"id": 55, "seek": 33380, "start": 346.04, "end": 351.16, "text": " the protocol, it's relayed on DNS as most of the protocols out there, if the DNS is slow then also", "tokens": [50976, 264, 10336, 11, 309, 311, 24214, 292, 322, 35153, 382, 881, 295, 264, 20618, 484, 456, 11, 498, 264, 35153, 307, 2964, 550, 611, 51232], "temperature": 0.0, "avg_logprob": -0.18356182615635758, "compression_ratio": 1.67595818815331, "no_speech_prob": 0.0007095524342730641}, {"id": 56, "seek": 33380, "start": 351.16, "end": 357.56, "text": " your server will be slow, Camelio uses an internal DNS cache, if you use Astrix there is no cache", "tokens": [51232, 428, 7154, 486, 312, 2964, 11, 6886, 338, 1004, 4960, 364, 6920, 35153, 19459, 11, 498, 291, 764, 12884, 6579, 456, 307, 572, 19459, 51552], "temperature": 0.0, "avg_logprob": -0.18356182615635758, "compression_ratio": 1.67595818815331, "no_speech_prob": 0.0007095524342730641}, {"id": 57, "seek": 33380, "start": 357.56, "end": 363.08000000000004, "text": " unfortunately so you should use DNS mask or something similar or keep some local DNS server in your", "tokens": [51552, 7015, 370, 291, 820, 764, 35153, 6094, 420, 746, 2531, 420, 1066, 512, 2654, 35153, 7154, 294, 428, 51828], "temperature": 0.0, "avg_logprob": -0.18356182615635758, "compression_ratio": 1.67595818815331, "no_speech_prob": 0.0007095524342730641}, {"id": 58, "seek": 36308, "start": 363.15999999999997, "end": 370.2, "text": " data center in your infrastructure. For zip for real-time communication you need to write", "tokens": [50368, 1412, 3056, 294, 428, 6896, 13, 1171, 20730, 337, 957, 12, 3766, 6101, 291, 643, 281, 2464, 50720], "temperature": 0.0, "avg_logprob": -0.14176020849318732, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004877464671153575}, {"id": 59, "seek": 36308, "start": 370.2, "end": 375.0, "text": " usually user registration this is something you can of course optimize, you can cache it,", "tokens": [50720, 2673, 4195, 16847, 341, 307, 746, 291, 393, 295, 1164, 19719, 11, 291, 393, 19459, 309, 11, 50960], "temperature": 0.0, "avg_logprob": -0.14176020849318732, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004877464671153575}, {"id": 60, "seek": 36308, "start": 375.0, "end": 378.59999999999997, "text": " for Astrix there's something called Qualify which you use real-time infrastructure,", "tokens": [50960, 337, 12884, 6579, 456, 311, 746, 1219, 13616, 2505, 597, 291, 764, 957, 12, 3766, 6896, 11, 51140], "temperature": 0.0, "avg_logprob": -0.14176020849318732, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004877464671153575}, {"id": 61, "seek": 36308, "start": 379.71999999999997, "end": 383.88, "text": " this makes sense to tune maybe to deactivate it because it will basically scale with the number", "tokens": [51196, 341, 1669, 2020, 281, 10864, 1310, 281, 45428, 473, 309, 570, 309, 486, 1936, 4373, 365, 264, 1230, 51404], "temperature": 0.0, "avg_logprob": -0.14176020849318732, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004877464671153575}, {"id": 62, "seek": 36308, "start": 383.88, "end": 391.24, "text": " of your user and the write load will be also scale as well. Logging of course you need to look to it", "tokens": [51404, 295, 428, 4195, 293, 264, 2464, 3677, 486, 312, 611, 4373, 382, 731, 13, 10824, 3249, 295, 1164, 291, 643, 281, 574, 281, 309, 51772], "temperature": 0.0, "avg_logprob": -0.14176020849318732, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004877464671153575}, {"id": 63, "seek": 39124, "start": 391.24, "end": 397.08, "text": " if you really need to log everything or maybe you can tune it to adapt to your scenario it makes", "tokens": [50364, 498, 291, 534, 643, 281, 3565, 1203, 420, 1310, 291, 393, 10864, 309, 281, 6231, 281, 428, 9005, 309, 1669, 50656], "temperature": 0.0, "avg_logprob": -0.13761219382286072, "compression_ratio": 1.6875, "no_speech_prob": 0.0008555687963962555}, {"id": 64, "seek": 39124, "start": 397.08, "end": 401.16, "text": " sense to restrict it also with not only with Camelio of course with Astrix or other servers as", "tokens": [50656, 2020, 281, 7694, 309, 611, 365, 406, 787, 365, 6886, 338, 1004, 295, 1164, 365, 12884, 6579, 420, 661, 15909, 382, 50860], "temperature": 0.0, "avg_logprob": -0.13761219382286072, "compression_ratio": 1.6875, "no_speech_prob": 0.0008555687963962555}, {"id": 65, "seek": 39124, "start": 401.16, "end": 406.92, "text": " well, if you have a lot of read operations they can usually cache quite well on Camelio,", "tokens": [50860, 731, 11, 498, 291, 362, 257, 688, 295, 1401, 7705, 436, 393, 2673, 19459, 1596, 731, 322, 6886, 338, 1004, 11, 51148], "temperature": 0.0, "avg_logprob": -0.13761219382286072, "compression_ratio": 1.6875, "no_speech_prob": 0.0008555687963962555}, {"id": 66, "seek": 39124, "start": 406.92, "end": 413.88, "text": " there's a htable module for Camelio you can use caching the data, you can also use something like", "tokens": [51148, 456, 311, 257, 276, 23811, 10088, 337, 6886, 338, 1004, 291, 393, 764, 269, 2834, 264, 1412, 11, 291, 393, 611, 764, 746, 411, 51496], "temperature": 0.0, "avg_logprob": -0.13761219382286072, "compression_ratio": 1.6875, "no_speech_prob": 0.0008555687963962555}, {"id": 67, "seek": 41388, "start": 413.96, "end": 420.6, "text": " read only replication, read is memcache whatever to scale that. The same for remote", "tokens": [50368, 1401, 787, 39911, 11, 1401, 307, 1334, 66, 6000, 2035, 281, 4373, 300, 13, 440, 912, 337, 8607, 50700], "temperature": 0.0, "avg_logprob": -0.21969955268947558, "compression_ratio": 1.5313807531380754, "no_speech_prob": 0.006188953295350075}, {"id": 68, "seek": 41388, "start": 420.6, "end": 427.8, "text": " HTTP API requests this is also something you can cache of course. CDR writing we just saw", "tokens": [50700, 33283, 9362, 12475, 341, 307, 611, 746, 291, 393, 19459, 295, 1164, 13, 6743, 49, 3579, 321, 445, 1866, 51060], "temperature": 0.0, "avg_logprob": -0.21969955268947558, "compression_ratio": 1.5313807531380754, "no_speech_prob": 0.006188953295350075}, {"id": 69, "seek": 41388, "start": 427.8, "end": 434.76, "text": " call talk about CG rates, great project that offer these CDR capabilities, Camelio can also", "tokens": [51060, 818, 751, 466, 38007, 6846, 11, 869, 1716, 300, 2626, 613, 6743, 49, 10862, 11, 6886, 338, 1004, 393, 611, 51408], "temperature": 0.0, "avg_logprob": -0.21969955268947558, "compression_ratio": 1.5313807531380754, "no_speech_prob": 0.006188953295350075}, {"id": 70, "seek": 41388, "start": 434.76, "end": 441.88, "text": " write CDRs internally but of course for highly loaded platforms it might sense to move it to another", "tokens": [51408, 2464, 6743, 49, 82, 19501, 457, 295, 1164, 337, 5405, 13210, 9473, 309, 1062, 2020, 281, 1286, 309, 281, 1071, 51764], "temperature": 0.0, "avg_logprob": -0.21969955268947558, "compression_ratio": 1.5313807531380754, "no_speech_prob": 0.006188953295350075}, {"id": 71, "seek": 44188, "start": 441.88, "end": 448.12, "text": " process to another system to have some asynchronous process doing the CDRs and not to affect the", "tokens": [50364, 1399, 281, 1071, 1185, 281, 362, 512, 49174, 1399, 884, 264, 6743, 49, 82, 293, 406, 281, 3345, 264, 50676], "temperature": 0.0, "avg_logprob": -0.17439074949784714, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.00032498897053301334}, {"id": 72, "seek": 44188, "start": 448.12, "end": 453.08, "text": " server operation and of course as we just saw in the beginning you should not fork processes", "tokens": [50676, 7154, 6916, 293, 295, 1164, 382, 321, 445, 1866, 294, 264, 2863, 291, 820, 406, 17716, 7555, 50924], "temperature": 0.0, "avg_logprob": -0.17439074949784714, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.00032498897053301334}, {"id": 73, "seek": 44188, "start": 454.12, "end": 460.84, "text": " if you rely on performance. What you could use for performance test one thing which is still", "tokens": [50976, 498, 291, 10687, 322, 3389, 13, 708, 291, 727, 764, 337, 3389, 1500, 472, 551, 597, 307, 920, 51312], "temperature": 0.0, "avg_logprob": -0.17439074949784714, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.00032498897053301334}, {"id": 74, "seek": 44188, "start": 462.12, "end": 468.84, "text": " used a lot is the old classical zp, there's pjwa you can script it a lot with Python or", "tokens": [51376, 1143, 257, 688, 307, 264, 1331, 13735, 710, 79, 11, 456, 311, 280, 73, 4151, 291, 393, 5755, 309, 257, 688, 365, 15329, 420, 51712], "temperature": 0.0, "avg_logprob": -0.17439074949784714, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.00032498897053301334}, {"id": 75, "seek": 46884, "start": 468.84, "end": 473.56, "text": " other bindings, they are dedicated to performance test frameworks usually they are homegrown", "tokens": [50364, 661, 14786, 1109, 11, 436, 366, 8374, 281, 3389, 1500, 29834, 2673, 436, 366, 1280, 38413, 50600], "temperature": 0.0, "avg_logprob": -0.1214458400552923, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0007094428292475641}, {"id": 76, "seek": 46884, "start": 473.56, "end": 478.76, "text": " or closed source unfortunately but they are the stuff you can pay or you can of course build by", "tokens": [50600, 420, 5395, 4009, 7015, 457, 436, 366, 264, 1507, 291, 393, 1689, 420, 291, 393, 295, 1164, 1322, 538, 50860], "temperature": 0.0, "avg_logprob": -0.1214458400552923, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0007094428292475641}, {"id": 77, "seek": 46884, "start": 478.76, "end": 484.12, "text": " yourself. If you have a database hdp which is actually the bottleneck you can of course", "tokens": [50860, 1803, 13, 759, 291, 362, 257, 8149, 276, 67, 79, 597, 307, 767, 264, 44641, 547, 291, 393, 295, 1164, 51128], "temperature": 0.0, "avg_logprob": -0.1214458400552923, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0007094428292475641}, {"id": 78, "seek": 46884, "start": 484.12, "end": 491.23999999999995, "text": " use custom tools to test the database to test the hdp API. Then for a start of course you see", "tokens": [51128, 764, 2375, 3873, 281, 1500, 264, 8149, 281, 1500, 264, 276, 67, 79, 9362, 13, 1396, 337, 257, 722, 295, 1164, 291, 536, 51484], "temperature": 0.0, "avg_logprob": -0.1214458400552923, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0007094428292475641}, {"id": 79, "seek": 49124, "start": 491.24, "end": 499.16, "text": " common tools to get inside about the cpu, the IO, the network situation, that can give you a", "tokens": [50364, 2689, 3873, 281, 483, 1854, 466, 264, 269, 34859, 11, 264, 39839, 11, 264, 3209, 2590, 11, 300, 393, 976, 291, 257, 50760], "temperature": 0.0, "avg_logprob": -0.22008441356902428, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.031577788293361664}, {"id": 80, "seek": 49124, "start": 499.16, "end": 504.04, "text": " lot of information if there's some pressure on the sockets for udp especially in particular.", "tokens": [50760, 688, 295, 1589, 498, 456, 311, 512, 3321, 322, 264, 370, 11984, 337, 11727, 79, 2318, 294, 1729, 13, 51004], "temperature": 0.0, "avg_logprob": -0.22008441356902428, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.031577788293361664}, {"id": 81, "seek": 49124, "start": 506.36, "end": 511.88, "text": " If you have tools like Humair we see a talk later about that as well, wipe monitor another tool", "tokens": [51120, 759, 291, 362, 3873, 411, 12877, 1246, 321, 536, 257, 751, 1780, 466, 300, 382, 731, 11, 14082, 6002, 1071, 2290, 51396], "temperature": 0.0, "avg_logprob": -0.22008441356902428, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.031577788293361664}, {"id": 82, "seek": 49124, "start": 511.88, "end": 517.4, "text": " of course the classical Isengar, Grafana, whatever statistics you have in house. Camelio", "tokens": [51396, 295, 1164, 264, 13735, 1119, 1501, 289, 11, 8985, 69, 2095, 11, 2035, 12523, 291, 362, 294, 1782, 13, 6886, 338, 1004, 51672], "temperature": 0.0, "avg_logprob": -0.22008441356902428, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.031577788293361664}, {"id": 83, "seek": 51740, "start": 517.4, "end": 523.88, "text": " offers also some benchmarks module and you can also adapt the logging a lot to your requirements.", "tokens": [50364, 7736, 611, 512, 43751, 10088, 293, 291, 393, 611, 6231, 264, 27991, 257, 688, 281, 428, 7728, 13, 50688], "temperature": 0.0, "avg_logprob": -0.21104548527644232, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0021136493887752295}, {"id": 84, "seek": 51740, "start": 526.4399999999999, "end": 533.3199999999999, "text": " Okay that's all from my side thank you very much, just a quick pointer, we're doing Camelio world", "tokens": [50816, 1033, 300, 311, 439, 490, 452, 1252, 1309, 291, 588, 709, 11, 445, 257, 1702, 23918, 11, 321, 434, 884, 6886, 338, 1004, 1002, 51160], "temperature": 0.0, "avg_logprob": -0.21104548527644232, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0021136493887752295}, {"id": 85, "seek": 51740, "start": 533.3199999999999, "end": 537.3199999999999, "text": " this year in presence again I'm really happy about that, it will happen at the beginning of", "tokens": [51160, 341, 1064, 294, 6814, 797, 286, 478, 534, 2055, 466, 300, 11, 309, 486, 1051, 412, 264, 2863, 295, 51360], "temperature": 0.0, "avg_logprob": -0.21104548527644232, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0021136493887752295}, {"id": 86, "seek": 51740, "start": 537.3199999999999, "end": 542.52, "text": " June in Berlin called for papers was open so if you're interested in presenting something", "tokens": [51360, 6928, 294, 13848, 1219, 337, 10577, 390, 1269, 370, 498, 291, 434, 3102, 294, 15578, 746, 51620], "temperature": 0.0, "avg_logprob": -0.21104548527644232, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0021136493887752295}, {"id": 87, "seek": 51740, "start": 542.52, "end": 546.76, "text": " interesting there go ahead we are looking forward to your contributions there as well.", "tokens": [51620, 1880, 456, 352, 2286, 321, 366, 1237, 2128, 281, 428, 15725, 456, 382, 731, 13, 51832], "temperature": 0.0, "avg_logprob": -0.21104548527644232, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0021136493887752295}, {"id": 88, "seek": 54676, "start": 546.76, "end": 554.12, "text": " Thank you very much.", "tokens": [50368, 1044, 291, 588, 709, 13, 50732], "temperature": 0.0, "avg_logprob": -0.32587558031082153, "compression_ratio": 0.7142857142857143, "no_speech_prob": 0.012995143420994282}], "language": "en"}