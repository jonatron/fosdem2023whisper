{"text": " You're going to talk about cluster API operating Kubernetes with Kubernetes. How? Hello. Thank you for coming. My name is Alex. I'm a software engineer. I work at Susie on the run chair. I do a lot of stuff related to cluster lifecycle. And today I'm going to talk about cluster API and operating Kubernetes with Kubernetes. Hope it will be fun. Here is a short summary of what we are going to talk about today. I'll try to explain the problem of managing the Kubernetes cluster lifecycle. I'll try to explain what is cluster API, how does it approach this problem, and we'll take a look at some building blocks of cluster API. And also I'll be doing a demo, and because I don't have enough time, the demo will be done simultaneously with the talk. So it's a live demo, nothing is recorded, hopefully everything will be fine. I already had some problems with networking today, but let's see. So let's move on to the next slide. So cluster lifecycle is complicated, and why is that? But if you have to manage more than one cluster, say you have 10 Kubernetes cluster or maybe 100 Kubernetes clusters, then the problem becomes similar to managing containers and why we invented Kubernetes. And cluster API tries to solve this problem of managing multiple clusters, and also sometimes you have to manage the underlying infrastructure, and that also somehow needs to be done in a nice and consistent way. Then you also have to upgrade clusters, sometimes you have to upgrade multiple clusters, and upgrading clusters is not always easy, especially when it comes to control planes. And you want to deploy your clusters on different infrastructure, let's say you have something running on AWS, when you have some bare metal things running, and you also need to somehow manage that. And you don't want to use different tools that depend on your infrastructure, you want to use something that is a single point of management and it's consistent, it provides some nice experience, and it's easy to use and automate. So what is cluster API? Cluster API takes this approach where we install it, it's an extension to Kubernetes API that allows you to provision, upgrade, and operate your cluster, and you install it on your Kubernetes, then you use what we call management cluster to manage workload clusters. Yes, you can do this on a different infrastructure provider, you can have one management cluster managing stuff running on AWS, and you can have the same cluster managing your clusters on Azure. So this is the basic idea of cluster API, and next we are going to take a look at the building blocks of CAPI, and I will start my demo. But before this, let me switch to the terminal and show you what I have prepared in advance. So I deployed a management cluster where I already installed CAPI so we don't lose time, everything should be up and running, and yeah, let's move on. The main entity in the cluster API is called cluster, and it represents a Kubernetes cluster, it's not tied to some kind of infrastructure, so it's just a generic Kubernetes cluster. And to make it more clear, I will show you how it looks like. As you can see, it's a normal Kubernetes object that has some kind, metadata, but what's interesting for us is the spec here, you can see the spec references, two things, yeah, the first reference is a reference to infrastructure, and for this demo I'm going to use Docker as infrastructure provider because I don't want to make any requests to some cloud because of a network, I wasn't sure if it's going to work properly, so I decided to use Docker as our infrastructure provider, it's an infrastructure provider we use for development and testing, and the second interesting reference is a reference to what we call control pane providers, and because control planes are harder to manage than worker machines, we require a specific resource for that, and this control pane provider is based on a tool called QPADM, which is a default that you can use with CAPI, so let me create this cluster, and we can take a look at the objects that are referenced inside. The first reference you saw is a reference to Docker cluster, it's also what we call an infrastructure cluster, and it's responsible for all prerequisites that are required to run your cluster on any infrastructure, so for example, if you're running it on public cloud, it will provision all networks, load balancer, security groups, VPCs, and whatever else you need, and this reference is actually what makes cluster API plugable, so if you want to add your own provider, you just have to follow a documentation implement API with some rules and then you can reference it, and that's how you plug in your own provider. Let me show you how Docker cluster looks in our case, it's pretty simple, there is no real infrastructure to run, so I'm going to create it too, okay, it's done, then the next reference we saw in cluster object was a reference to what we call a control pane provider, what it does, it creates a control pane machine, generates cloud config, and also is responsible for any other actions related to control pane management, stuff like, you know, HCD, Core DNS, or whatever you implement or want to enable. Let me show you how it looks like, this will be so far the biggest object we have there, because it contains some configurations we require for our control pane, but as you can see, you can customize some Kubernetes components there using Kubernetes API, so if you would like, you can just specify anything you need here to provision control planes, you can also specify replica set, and you also need Kubernetes version there. Now, maybe I forgot to create it. Yeah. Okay, so let's talk about worker machines and how does KPI approach managing machines. It's important first to note that machine is just a host for your Kubernetes nodes, so it can be virtual machine, can be bare metal, can be anything your infrastructure provider means, and I'd like to show an example with bots, you don't manage bots manually, right? You don't use them as a standalone resource, you use something else. If you want to manage replicas count for your bots, you use something called replica set that has just one purpose, create your certain count of bots, and then if you want to do more complex stuff like rolling upgrades, you use a deployment on top of this that manages replica set, so KPI followed the same pattern and created machines, then there is a machine set that manages replica count, and there is a machine deployment on top of that, that does more complicated things. Let's go back to the terminal. I will show you a machine deployment, you can see similar to normal deployment has replica count, then it has a selector, has a template, and inside the spec is similar to what we saw with cluster object, it has two references, one is for our infrastructure template, which is Docker for this demo, and the second one is a bootstrap provider, which is based on QPADM. So the infrastructure template or Docker template that we saw there in the reference are just specifications for your host depending on your cloud provider, it can be an instance type, storage size, anything you put there, and the second reference to bootstrap provider is just a reference to an API that generates user data with proper cloud config, so you can configure your Kubernetes components as you want. Let me show you how it looks like. For Docker machine, it's just an image in this case and some extra mounts, and for bootstrap provider, we just have some arguments for our Kubernetes components, and this is it. Okay, so this was it. Let me now check if everything works fine. Yeah, everything works fine. As you can see, we have three control pane machines that are running inside Docker containers that we created before and after some time, we should get a worker machine that we just created. Let's take a look at how it all works together. We have a cluster object that represents the cluster, then it has to reference an infrastructure provider, which is Docker in this case, and it also has to reference a control pane provider, which is based on QPADM, and once these two are done with a job, you can connect your machine deployments that have to reference a machine template, so Kapi knows what specifications you want, and also a QPADM config template where you can configure your Kubernetes components, and this is all you need to create a basic Kapi cluster. Unfortunately, I don't have enough time to talk about other things that exist in Kapi like machine health checks that help you track and remediate unhealthy machines when there are cluster classes, which are powerful templates for creating clusters. You can also connect cluster autoscalar if you want, and there are day two operations coming, so you can think of KPS like SwissKnife for everything related to cluster lifecycle. And we still have time. I'm going to show you how we can upgrade the cluster. Let's check its state again. Yeah, so if you... Now you can see that we have three control planes, and they all are running Kubernetes v125, and let me upgrade them to Kubernetes v126, so how do I do this? In order to do this, we have to change the version in the control pane provider object, and we also have to change the image reference in the machine template. So just by doing so, I will start upgrading the cluster. As you can see, cluster API started to spin up new control pane machine with v126 that is going to replace old ones, and it's going to take care for us like insuring a CD quorum and all sorts of things, so we don't have to take care about this. I'm going to go back to the summary, and let's go once again for what we saw today. So I try to explain the problem of managing Kubernetes clusters, and the main idea, we wanted to have a tool that provides a declarative and consistent API, and will allow you provision and manage your clusters on different infrastructure in some nice way so you can have a single point of managing your clusters for all the possible infrastructures you're running, and this approach is like use Kubernetes because Kubernetes already provides a lot of tools for building a powerful API. I think with us it, maybe I was a bit quick, but I don't have anything else. I'm ready to answer questions if someone has. Okay, we have ample time for questions. Hi, thanks for the nice demo. This allows you to manage the workload clusters. Can it also manage the life cycle of the management cluster, or how do you do that? Yes, you can. So what if it destroys itself, so what happens then? It shouldn't. Depends on how you use it, but yeah. Works on local clusters, thank you. Thank you. The question about updates, is it possible to update components like cobalates without recreating virtual machines? Yes. And how is it working? It's done through your bootstrap or control pane provider. Yeah, and you also have to provide an image that will be used for your new instances. No, no, I mean if you need to update cobalates and you don't want to reorder new... Yeah, okay. Costa API doesn't support in-place upgrades. It will be creating a new machine with new image, new everything, and then replacing old one. Okay, got it. And can you tell a little more about control pane updates? Sorry? Control pane updates, updates of control pane nodes and components. So I just showed one, like when you change the version it will start replacing old machines with newer ones. You just have to provide all the specifications. You have to provide a new Kubernetes version you want and also a new image. So we try to bake everything inside the machine image so you don't have to download new things and it will just replace old machine with a new one, with new versions. So it's a replace upgrade. It's not in place. The same as POTS, if you change, for example, reference to image, it will destroy old one and create a newer one. So it's the same concept. There's an online question is in the chat. Are there any latency requirements between the management cluster and the workload cluster? It depends on your use case, but yeah, ideally you should take care of your management cluster with somewhere near workload clusters or is able to reach it within some limits. And one more. Does the management cluster need to run at all the time or can it be shut off when not doing life cycle work? So here is the thing. If you disable it nothing will manage your Kubernetes cluster so they will be basically unmanaged. Yeah, your workload cluster will continue running but there is nothing that will keep track of them. For example, if you use cluster autoscaler or machine health checks you need your management cluster to be running all the time because it constantly looks at the state of your workload clusters. Okay. If there are no more questions and we can end a few minutes early. Thank you for the talk. Thank you all for attending.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.68, "text": " You're going to talk about cluster API operating Kubernetes with Kubernetes.", "tokens": [50364, 509, 434, 516, 281, 751, 466, 13630, 9362, 7447, 23145, 365, 23145, 13, 50898], "temperature": 0.0, "avg_logprob": -0.3108382489946153, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.253569096326828}, {"id": 1, "seek": 0, "start": 10.68, "end": 11.68, "text": " How?", "tokens": [50898, 1012, 30, 50948], "temperature": 0.0, "avg_logprob": -0.3108382489946153, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.253569096326828}, {"id": 2, "seek": 0, "start": 11.68, "end": 12.68, "text": " Hello.", "tokens": [50948, 2425, 13, 50998], "temperature": 0.0, "avg_logprob": -0.3108382489946153, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.253569096326828}, {"id": 3, "seek": 0, "start": 12.68, "end": 14.16, "text": " Thank you for coming.", "tokens": [50998, 1044, 291, 337, 1348, 13, 51072], "temperature": 0.0, "avg_logprob": -0.3108382489946153, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.253569096326828}, {"id": 4, "seek": 0, "start": 14.16, "end": 15.16, "text": " My name is Alex.", "tokens": [51072, 1222, 1315, 307, 5202, 13, 51122], "temperature": 0.0, "avg_logprob": -0.3108382489946153, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.253569096326828}, {"id": 5, "seek": 0, "start": 15.16, "end": 16.6, "text": " I'm a software engineer.", "tokens": [51122, 286, 478, 257, 4722, 11403, 13, 51194], "temperature": 0.0, "avg_logprob": -0.3108382489946153, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.253569096326828}, {"id": 6, "seek": 0, "start": 16.6, "end": 18.92, "text": " I work at Susie on the run chair.", "tokens": [51194, 286, 589, 412, 9545, 414, 322, 264, 1190, 6090, 13, 51310], "temperature": 0.0, "avg_logprob": -0.3108382489946153, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.253569096326828}, {"id": 7, "seek": 0, "start": 18.92, "end": 23.2, "text": " I do a lot of stuff related to cluster lifecycle.", "tokens": [51310, 286, 360, 257, 688, 295, 1507, 4077, 281, 13630, 45722, 13, 51524], "temperature": 0.0, "avg_logprob": -0.3108382489946153, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.253569096326828}, {"id": 8, "seek": 2320, "start": 23.2, "end": 30.24, "text": " And today I'm going to talk about cluster API and operating Kubernetes with Kubernetes.", "tokens": [50364, 400, 965, 286, 478, 516, 281, 751, 466, 13630, 9362, 293, 7447, 23145, 365, 23145, 13, 50716], "temperature": 0.0, "avg_logprob": -0.18829588663010371, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0588030107319355}, {"id": 9, "seek": 2320, "start": 30.24, "end": 31.759999999999998, "text": " Hope it will be fun.", "tokens": [50716, 6483, 309, 486, 312, 1019, 13, 50792], "temperature": 0.0, "avg_logprob": -0.18829588663010371, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0588030107319355}, {"id": 10, "seek": 2320, "start": 31.759999999999998, "end": 36.36, "text": " Here is a short summary of what we are going to talk about today.", "tokens": [50792, 1692, 307, 257, 2099, 12691, 295, 437, 321, 366, 516, 281, 751, 466, 965, 13, 51022], "temperature": 0.0, "avg_logprob": -0.18829588663010371, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0588030107319355}, {"id": 11, "seek": 2320, "start": 36.36, "end": 43.16, "text": " I'll try to explain the problem of managing the Kubernetes cluster lifecycle.", "tokens": [51022, 286, 603, 853, 281, 2903, 264, 1154, 295, 11642, 264, 23145, 13630, 45722, 13, 51362], "temperature": 0.0, "avg_logprob": -0.18829588663010371, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0588030107319355}, {"id": 12, "seek": 2320, "start": 43.16, "end": 49.8, "text": " I'll try to explain what is cluster API, how does it approach this problem, and we'll take", "tokens": [51362, 286, 603, 853, 281, 2903, 437, 307, 13630, 9362, 11, 577, 775, 309, 3109, 341, 1154, 11, 293, 321, 603, 747, 51694], "temperature": 0.0, "avg_logprob": -0.18829588663010371, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0588030107319355}, {"id": 13, "seek": 4980, "start": 49.8, "end": 53.0, "text": " a look at some building blocks of cluster API.", "tokens": [50364, 257, 574, 412, 512, 2390, 8474, 295, 13630, 9362, 13, 50524], "temperature": 0.0, "avg_logprob": -0.16031189684597952, "compression_ratio": 1.606425702811245, "no_speech_prob": 0.0175546295940876}, {"id": 14, "seek": 4980, "start": 53.0, "end": 58.12, "text": " And also I'll be doing a demo, and because I don't have enough time, the demo will be", "tokens": [50524, 400, 611, 286, 603, 312, 884, 257, 10723, 11, 293, 570, 286, 500, 380, 362, 1547, 565, 11, 264, 10723, 486, 312, 50780], "temperature": 0.0, "avg_logprob": -0.16031189684597952, "compression_ratio": 1.606425702811245, "no_speech_prob": 0.0175546295940876}, {"id": 15, "seek": 4980, "start": 58.12, "end": 61.12, "text": " done simultaneously with the talk.", "tokens": [50780, 1096, 16561, 365, 264, 751, 13, 50930], "temperature": 0.0, "avg_logprob": -0.16031189684597952, "compression_ratio": 1.606425702811245, "no_speech_prob": 0.0175546295940876}, {"id": 16, "seek": 4980, "start": 61.12, "end": 65.75999999999999, "text": " So it's a live demo, nothing is recorded, hopefully everything will be fine.", "tokens": [50930, 407, 309, 311, 257, 1621, 10723, 11, 1825, 307, 8287, 11, 4696, 1203, 486, 312, 2489, 13, 51162], "temperature": 0.0, "avg_logprob": -0.16031189684597952, "compression_ratio": 1.606425702811245, "no_speech_prob": 0.0175546295940876}, {"id": 17, "seek": 4980, "start": 65.75999999999999, "end": 71.6, "text": " I already had some problems with networking today, but let's see.", "tokens": [51162, 286, 1217, 632, 512, 2740, 365, 17985, 965, 11, 457, 718, 311, 536, 13, 51454], "temperature": 0.0, "avg_logprob": -0.16031189684597952, "compression_ratio": 1.606425702811245, "no_speech_prob": 0.0175546295940876}, {"id": 18, "seek": 4980, "start": 71.6, "end": 74.56, "text": " So let's move on to the next slide.", "tokens": [51454, 407, 718, 311, 1286, 322, 281, 264, 958, 4137, 13, 51602], "temperature": 0.0, "avg_logprob": -0.16031189684597952, "compression_ratio": 1.606425702811245, "no_speech_prob": 0.0175546295940876}, {"id": 19, "seek": 4980, "start": 74.56, "end": 79.12, "text": " So cluster lifecycle is complicated, and why is that?", "tokens": [51602, 407, 13630, 45722, 307, 6179, 11, 293, 983, 307, 300, 30, 51830], "temperature": 0.0, "avg_logprob": -0.16031189684597952, "compression_ratio": 1.606425702811245, "no_speech_prob": 0.0175546295940876}, {"id": 20, "seek": 7912, "start": 79.12, "end": 83.92, "text": " But if you have to manage more than one cluster, say you have 10 Kubernetes cluster or maybe", "tokens": [50364, 583, 498, 291, 362, 281, 3067, 544, 813, 472, 13630, 11, 584, 291, 362, 1266, 23145, 13630, 420, 1310, 50604], "temperature": 0.0, "avg_logprob": -0.22158316960410465, "compression_ratio": 1.6988636363636365, "no_speech_prob": 0.004025601781904697}, {"id": 21, "seek": 7912, "start": 83.92, "end": 91.24000000000001, "text": " 100 Kubernetes clusters, then the problem becomes similar to managing containers and", "tokens": [50604, 2319, 23145, 23313, 11, 550, 264, 1154, 3643, 2531, 281, 11642, 17089, 293, 50970], "temperature": 0.0, "avg_logprob": -0.22158316960410465, "compression_ratio": 1.6988636363636365, "no_speech_prob": 0.004025601781904697}, {"id": 22, "seek": 7912, "start": 91.24000000000001, "end": 94.12, "text": " why we invented Kubernetes.", "tokens": [50970, 983, 321, 14479, 23145, 13, 51114], "temperature": 0.0, "avg_logprob": -0.22158316960410465, "compression_ratio": 1.6988636363636365, "no_speech_prob": 0.004025601781904697}, {"id": 23, "seek": 7912, "start": 94.12, "end": 105.44, "text": " And cluster API tries to solve this problem of managing multiple clusters, and also sometimes", "tokens": [51114, 400, 13630, 9362, 9898, 281, 5039, 341, 1154, 295, 11642, 3866, 23313, 11, 293, 611, 2171, 51680], "temperature": 0.0, "avg_logprob": -0.22158316960410465, "compression_ratio": 1.6988636363636365, "no_speech_prob": 0.004025601781904697}, {"id": 24, "seek": 10544, "start": 105.44, "end": 112.03999999999999, "text": " you have to manage the underlying infrastructure, and that also somehow needs to be done in", "tokens": [50364, 291, 362, 281, 3067, 264, 14217, 6896, 11, 293, 300, 611, 6063, 2203, 281, 312, 1096, 294, 50694], "temperature": 0.0, "avg_logprob": -0.1629822503952753, "compression_ratio": 1.867704280155642, "no_speech_prob": 0.06952697783708572}, {"id": 25, "seek": 10544, "start": 112.03999999999999, "end": 114.4, "text": " a nice and consistent way.", "tokens": [50694, 257, 1481, 293, 8398, 636, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1629822503952753, "compression_ratio": 1.867704280155642, "no_speech_prob": 0.06952697783708572}, {"id": 26, "seek": 10544, "start": 114.4, "end": 118.56, "text": " Then you also have to upgrade clusters, sometimes you have to upgrade multiple clusters, and", "tokens": [50812, 1396, 291, 611, 362, 281, 11484, 23313, 11, 2171, 291, 362, 281, 11484, 3866, 23313, 11, 293, 51020], "temperature": 0.0, "avg_logprob": -0.1629822503952753, "compression_ratio": 1.867704280155642, "no_speech_prob": 0.06952697783708572}, {"id": 27, "seek": 10544, "start": 118.56, "end": 124.16, "text": " upgrading clusters is not always easy, especially when it comes to control planes.", "tokens": [51020, 36249, 23313, 307, 406, 1009, 1858, 11, 2318, 562, 309, 1487, 281, 1969, 14952, 13, 51300], "temperature": 0.0, "avg_logprob": -0.1629822503952753, "compression_ratio": 1.867704280155642, "no_speech_prob": 0.06952697783708572}, {"id": 28, "seek": 10544, "start": 124.16, "end": 128.76, "text": " And you want to deploy your clusters on different infrastructure, let's say you have something", "tokens": [51300, 400, 291, 528, 281, 7274, 428, 23313, 322, 819, 6896, 11, 718, 311, 584, 291, 362, 746, 51530], "temperature": 0.0, "avg_logprob": -0.1629822503952753, "compression_ratio": 1.867704280155642, "no_speech_prob": 0.06952697783708572}, {"id": 29, "seek": 10544, "start": 128.76, "end": 135.24, "text": " running on AWS, when you have some bare metal things running, and you also need to somehow", "tokens": [51530, 2614, 322, 17650, 11, 562, 291, 362, 512, 6949, 5760, 721, 2614, 11, 293, 291, 611, 643, 281, 6063, 51854], "temperature": 0.0, "avg_logprob": -0.1629822503952753, "compression_ratio": 1.867704280155642, "no_speech_prob": 0.06952697783708572}, {"id": 30, "seek": 13524, "start": 135.24, "end": 136.56, "text": " manage that.", "tokens": [50364, 3067, 300, 13, 50430], "temperature": 0.0, "avg_logprob": -0.1713974770535244, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0027407268062233925}, {"id": 31, "seek": 13524, "start": 136.56, "end": 140.76000000000002, "text": " And you don't want to use different tools that depend on your infrastructure, you want", "tokens": [50430, 400, 291, 500, 380, 528, 281, 764, 819, 3873, 300, 5672, 322, 428, 6896, 11, 291, 528, 50640], "temperature": 0.0, "avg_logprob": -0.1713974770535244, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0027407268062233925}, {"id": 32, "seek": 13524, "start": 140.76000000000002, "end": 145.88, "text": " to use something that is a single point of management and it's consistent, it provides", "tokens": [50640, 281, 764, 746, 300, 307, 257, 2167, 935, 295, 4592, 293, 309, 311, 8398, 11, 309, 6417, 50896], "temperature": 0.0, "avg_logprob": -0.1713974770535244, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0027407268062233925}, {"id": 33, "seek": 13524, "start": 145.88, "end": 151.96, "text": " some nice experience, and it's easy to use and automate.", "tokens": [50896, 512, 1481, 1752, 11, 293, 309, 311, 1858, 281, 764, 293, 31605, 13, 51200], "temperature": 0.0, "avg_logprob": -0.1713974770535244, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0027407268062233925}, {"id": 34, "seek": 13524, "start": 151.96, "end": 153.68, "text": " So what is cluster API?", "tokens": [51200, 407, 437, 307, 13630, 9362, 30, 51286], "temperature": 0.0, "avg_logprob": -0.1713974770535244, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0027407268062233925}, {"id": 35, "seek": 13524, "start": 153.68, "end": 162.56, "text": " Cluster API takes this approach where we install it, it's an extension to Kubernetes API that", "tokens": [51286, 2033, 8393, 9362, 2516, 341, 3109, 689, 321, 3625, 309, 11, 309, 311, 364, 10320, 281, 23145, 9362, 300, 51730], "temperature": 0.0, "avg_logprob": -0.1713974770535244, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0027407268062233925}, {"id": 36, "seek": 16256, "start": 162.56, "end": 168.96, "text": " allows you to provision, upgrade, and operate your cluster, and you install it on your Kubernetes,", "tokens": [50364, 4045, 291, 281, 17225, 11, 11484, 11, 293, 9651, 428, 13630, 11, 293, 291, 3625, 309, 322, 428, 23145, 11, 50684], "temperature": 0.0, "avg_logprob": -0.22760751770763862, "compression_ratio": 1.7990196078431373, "no_speech_prob": 0.06211040914058685}, {"id": 37, "seek": 16256, "start": 168.96, "end": 174.52, "text": " then you use what we call management cluster to manage workload clusters.", "tokens": [50684, 550, 291, 764, 437, 321, 818, 4592, 13630, 281, 3067, 20139, 23313, 13, 50962], "temperature": 0.0, "avg_logprob": -0.22760751770763862, "compression_ratio": 1.7990196078431373, "no_speech_prob": 0.06211040914058685}, {"id": 38, "seek": 16256, "start": 174.52, "end": 179.96, "text": " Yes, you can do this on a different infrastructure provider, you can have one management cluster", "tokens": [50962, 1079, 11, 291, 393, 360, 341, 322, 257, 819, 6896, 12398, 11, 291, 393, 362, 472, 4592, 13630, 51234], "temperature": 0.0, "avg_logprob": -0.22760751770763862, "compression_ratio": 1.7990196078431373, "no_speech_prob": 0.06211040914058685}, {"id": 39, "seek": 16256, "start": 179.96, "end": 184.92000000000002, "text": " managing stuff running on AWS, and you can have the same cluster managing your clusters", "tokens": [51234, 11642, 1507, 2614, 322, 17650, 11, 293, 291, 393, 362, 264, 912, 13630, 11642, 428, 23313, 51482], "temperature": 0.0, "avg_logprob": -0.22760751770763862, "compression_ratio": 1.7990196078431373, "no_speech_prob": 0.06211040914058685}, {"id": 40, "seek": 16256, "start": 184.92000000000002, "end": 187.6, "text": " on Azure.", "tokens": [51482, 322, 11969, 13, 51616], "temperature": 0.0, "avg_logprob": -0.22760751770763862, "compression_ratio": 1.7990196078431373, "no_speech_prob": 0.06211040914058685}, {"id": 41, "seek": 18760, "start": 187.6, "end": 196.48, "text": " So this is the basic idea of cluster API, and next we are going to take a look at the", "tokens": [50364, 407, 341, 307, 264, 3875, 1558, 295, 13630, 9362, 11, 293, 958, 321, 366, 516, 281, 747, 257, 574, 412, 264, 50808], "temperature": 0.0, "avg_logprob": -0.12383959370274697, "compression_ratio": 1.396341463414634, "no_speech_prob": 0.013719933107495308}, {"id": 42, "seek": 18760, "start": 196.48, "end": 202.16, "text": " building blocks of CAPI, and I will start my demo.", "tokens": [50808, 2390, 8474, 295, 33636, 40, 11, 293, 286, 486, 722, 452, 10723, 13, 51092], "temperature": 0.0, "avg_logprob": -0.12383959370274697, "compression_ratio": 1.396341463414634, "no_speech_prob": 0.013719933107495308}, {"id": 43, "seek": 18760, "start": 202.16, "end": 209.48, "text": " But before this, let me switch to the terminal and show you what I have prepared in advance.", "tokens": [51092, 583, 949, 341, 11, 718, 385, 3679, 281, 264, 14709, 293, 855, 291, 437, 286, 362, 4927, 294, 7295, 13, 51458], "temperature": 0.0, "avg_logprob": -0.12383959370274697, "compression_ratio": 1.396341463414634, "no_speech_prob": 0.013719933107495308}, {"id": 44, "seek": 20948, "start": 209.48, "end": 218.0, "text": " So I deployed a management cluster where I already installed CAPI so we don't lose time,", "tokens": [50364, 407, 286, 17826, 257, 4592, 13630, 689, 286, 1217, 8899, 33636, 40, 370, 321, 500, 380, 3624, 565, 11, 50790], "temperature": 0.0, "avg_logprob": -0.1691600422800323, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.03669485077261925}, {"id": 45, "seek": 20948, "start": 218.0, "end": 224.56, "text": " everything should be up and running, and yeah, let's move on.", "tokens": [50790, 1203, 820, 312, 493, 293, 2614, 11, 293, 1338, 11, 718, 311, 1286, 322, 13, 51118], "temperature": 0.0, "avg_logprob": -0.1691600422800323, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.03669485077261925}, {"id": 46, "seek": 20948, "start": 224.56, "end": 230.32, "text": " The main entity in the cluster API is called cluster, and it represents a Kubernetes cluster,", "tokens": [51118, 440, 2135, 13977, 294, 264, 13630, 9362, 307, 1219, 13630, 11, 293, 309, 8855, 257, 23145, 13630, 11, 51406], "temperature": 0.0, "avg_logprob": -0.1691600422800323, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.03669485077261925}, {"id": 47, "seek": 20948, "start": 230.32, "end": 235.92, "text": " it's not tied to some kind of infrastructure, so it's just a generic Kubernetes cluster.", "tokens": [51406, 309, 311, 406, 9601, 281, 512, 733, 295, 6896, 11, 370, 309, 311, 445, 257, 19577, 23145, 13630, 13, 51686], "temperature": 0.0, "avg_logprob": -0.1691600422800323, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.03669485077261925}, {"id": 48, "seek": 23592, "start": 235.92, "end": 242.95999999999998, "text": " And to make it more clear, I will show you how it looks like.", "tokens": [50364, 400, 281, 652, 309, 544, 1850, 11, 286, 486, 855, 291, 577, 309, 1542, 411, 13, 50716], "temperature": 0.0, "avg_logprob": -0.20974489699962529, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.03878682479262352}, {"id": 49, "seek": 23592, "start": 242.95999999999998, "end": 248.48, "text": " As you can see, it's a normal Kubernetes object that has some kind, metadata, but what's", "tokens": [50716, 1018, 291, 393, 536, 11, 309, 311, 257, 2710, 23145, 2657, 300, 575, 512, 733, 11, 26603, 11, 457, 437, 311, 50992], "temperature": 0.0, "avg_logprob": -0.20974489699962529, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.03878682479262352}, {"id": 50, "seek": 23592, "start": 248.48, "end": 260.03999999999996, "text": " interesting for us is the spec here, you can see the spec references, two things, yeah,", "tokens": [50992, 1880, 337, 505, 307, 264, 1608, 510, 11, 291, 393, 536, 264, 1608, 15400, 11, 732, 721, 11, 1338, 11, 51570], "temperature": 0.0, "avg_logprob": -0.20974489699962529, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.03878682479262352}, {"id": 51, "seek": 23592, "start": 260.03999999999996, "end": 265.48, "text": " the first reference is a reference to infrastructure, and for this demo I'm going to use Docker", "tokens": [51570, 264, 700, 6408, 307, 257, 6408, 281, 6896, 11, 293, 337, 341, 10723, 286, 478, 516, 281, 764, 33772, 51842], "temperature": 0.0, "avg_logprob": -0.20974489699962529, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.03878682479262352}, {"id": 52, "seek": 26548, "start": 265.48, "end": 272.40000000000003, "text": " as infrastructure provider because I don't want to make any requests to some cloud because", "tokens": [50364, 382, 6896, 12398, 570, 286, 500, 380, 528, 281, 652, 604, 12475, 281, 512, 4588, 570, 50710], "temperature": 0.0, "avg_logprob": -0.142046469229239, "compression_ratio": 1.8088235294117647, "no_speech_prob": 0.00870016310364008}, {"id": 53, "seek": 26548, "start": 272.40000000000003, "end": 277.48, "text": " of a network, I wasn't sure if it's going to work properly, so I decided to use Docker", "tokens": [50710, 295, 257, 3209, 11, 286, 2067, 380, 988, 498, 309, 311, 516, 281, 589, 6108, 11, 370, 286, 3047, 281, 764, 33772, 50964], "temperature": 0.0, "avg_logprob": -0.142046469229239, "compression_ratio": 1.8088235294117647, "no_speech_prob": 0.00870016310364008}, {"id": 54, "seek": 26548, "start": 277.48, "end": 283.72, "text": " as our infrastructure provider, it's an infrastructure provider we use for development and testing,", "tokens": [50964, 382, 527, 6896, 12398, 11, 309, 311, 364, 6896, 12398, 321, 764, 337, 3250, 293, 4997, 11, 51276], "temperature": 0.0, "avg_logprob": -0.142046469229239, "compression_ratio": 1.8088235294117647, "no_speech_prob": 0.00870016310364008}, {"id": 55, "seek": 26548, "start": 283.72, "end": 289.84000000000003, "text": " and the second interesting reference is a reference to what we call control pane providers,", "tokens": [51276, 293, 264, 1150, 1880, 6408, 307, 257, 6408, 281, 437, 321, 818, 1969, 32605, 11330, 11, 51582], "temperature": 0.0, "avg_logprob": -0.142046469229239, "compression_ratio": 1.8088235294117647, "no_speech_prob": 0.00870016310364008}, {"id": 56, "seek": 28984, "start": 289.84, "end": 295.08, "text": " and because control planes are harder to manage than worker machines, we require a", "tokens": [50364, 293, 570, 1969, 14952, 366, 6081, 281, 3067, 813, 11346, 8379, 11, 321, 3651, 257, 50626], "temperature": 0.0, "avg_logprob": -0.22795174997064133, "compression_ratio": 1.5071090047393365, "no_speech_prob": 0.019823381677269936}, {"id": 57, "seek": 28984, "start": 295.08, "end": 301.08, "text": " specific resource for that, and this control pane provider is based on a tool called QPADM,", "tokens": [50626, 2685, 7684, 337, 300, 11, 293, 341, 1969, 32605, 12398, 307, 2361, 322, 257, 2290, 1219, 1249, 47, 6112, 44, 11, 50926], "temperature": 0.0, "avg_logprob": -0.22795174997064133, "compression_ratio": 1.5071090047393365, "no_speech_prob": 0.019823381677269936}, {"id": 58, "seek": 28984, "start": 301.08, "end": 309.4, "text": " which is a default that you can use with CAPI, so let me create this cluster, and we can", "tokens": [50926, 597, 307, 257, 7576, 300, 291, 393, 764, 365, 33636, 40, 11, 370, 718, 385, 1884, 341, 13630, 11, 293, 321, 393, 51342], "temperature": 0.0, "avg_logprob": -0.22795174997064133, "compression_ratio": 1.5071090047393365, "no_speech_prob": 0.019823381677269936}, {"id": 59, "seek": 28984, "start": 309.4, "end": 317.28, "text": " take a look at the objects that are referenced inside.", "tokens": [51342, 747, 257, 574, 412, 264, 6565, 300, 366, 32734, 1854, 13, 51736], "temperature": 0.0, "avg_logprob": -0.22795174997064133, "compression_ratio": 1.5071090047393365, "no_speech_prob": 0.019823381677269936}, {"id": 60, "seek": 31728, "start": 317.28, "end": 321.35999999999996, "text": " The first reference you saw is a reference to Docker cluster, it's also what we call", "tokens": [50364, 440, 700, 6408, 291, 1866, 307, 257, 6408, 281, 33772, 13630, 11, 309, 311, 611, 437, 321, 818, 50568], "temperature": 0.0, "avg_logprob": -0.18686300232296899, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.018254313617944717}, {"id": 61, "seek": 31728, "start": 321.35999999999996, "end": 329.35999999999996, "text": " an infrastructure cluster, and it's responsible for all prerequisites that are required to", "tokens": [50568, 364, 6896, 13630, 11, 293, 309, 311, 6250, 337, 439, 38333, 15398, 3324, 300, 366, 4739, 281, 50968], "temperature": 0.0, "avg_logprob": -0.18686300232296899, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.018254313617944717}, {"id": 62, "seek": 31728, "start": 329.35999999999996, "end": 334.28, "text": " run your cluster on any infrastructure, so for example, if you're running it on public", "tokens": [50968, 1190, 428, 13630, 322, 604, 6896, 11, 370, 337, 1365, 11, 498, 291, 434, 2614, 309, 322, 1908, 51214], "temperature": 0.0, "avg_logprob": -0.18686300232296899, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.018254313617944717}, {"id": 63, "seek": 31728, "start": 334.28, "end": 339.91999999999996, "text": " cloud, it will provision all networks, load balancer, security groups, VPCs, and whatever", "tokens": [51214, 4588, 11, 309, 486, 17225, 439, 9590, 11, 3677, 3119, 28347, 11, 3825, 3935, 11, 691, 12986, 82, 11, 293, 2035, 51496], "temperature": 0.0, "avg_logprob": -0.18686300232296899, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.018254313617944717}, {"id": 64, "seek": 33992, "start": 340.0, "end": 349.5, "text": " else you need, and this reference is actually what makes cluster API plugable, so if you", "tokens": [50368, 1646, 291, 643, 11, 293, 341, 6408, 307, 767, 437, 1669, 13630, 9362, 5452, 712, 11, 370, 498, 291, 50843], "temperature": 0.0, "avg_logprob": -0.15613532620807027, "compression_ratio": 1.6525821596244132, "no_speech_prob": 0.20645672082901}, {"id": 65, "seek": 33992, "start": 349.5, "end": 355.08000000000004, "text": " want to add your own provider, you just have to follow a documentation implement API with", "tokens": [50843, 528, 281, 909, 428, 1065, 12398, 11, 291, 445, 362, 281, 1524, 257, 14333, 4445, 9362, 365, 51122], "temperature": 0.0, "avg_logprob": -0.15613532620807027, "compression_ratio": 1.6525821596244132, "no_speech_prob": 0.20645672082901}, {"id": 66, "seek": 33992, "start": 355.08000000000004, "end": 361.76, "text": " some rules and then you can reference it, and that's how you plug in your own provider.", "tokens": [51122, 512, 4474, 293, 550, 291, 393, 6408, 309, 11, 293, 300, 311, 577, 291, 5452, 294, 428, 1065, 12398, 13, 51456], "temperature": 0.0, "avg_logprob": -0.15613532620807027, "compression_ratio": 1.6525821596244132, "no_speech_prob": 0.20645672082901}, {"id": 67, "seek": 33992, "start": 361.76, "end": 366.64, "text": " Let me show you how Docker cluster looks in our case, it's pretty simple, there is no", "tokens": [51456, 961, 385, 855, 291, 577, 33772, 13630, 1542, 294, 527, 1389, 11, 309, 311, 1238, 2199, 11, 456, 307, 572, 51700], "temperature": 0.0, "avg_logprob": -0.15613532620807027, "compression_ratio": 1.6525821596244132, "no_speech_prob": 0.20645672082901}, {"id": 68, "seek": 36664, "start": 366.71999999999997, "end": 379.56, "text": " real infrastructure to run, so I'm going to create it too, okay, it's done, then the next", "tokens": [50368, 957, 6896, 281, 1190, 11, 370, 286, 478, 516, 281, 1884, 309, 886, 11, 1392, 11, 309, 311, 1096, 11, 550, 264, 958, 51010], "temperature": 0.0, "avg_logprob": -0.20415527680340936, "compression_ratio": 1.5617977528089888, "no_speech_prob": 0.0019312931690365076}, {"id": 69, "seek": 36664, "start": 379.56, "end": 385.36, "text": " reference we saw in cluster object was a reference to what we call a control pane provider,", "tokens": [51010, 6408, 321, 1866, 294, 13630, 2657, 390, 257, 6408, 281, 437, 321, 818, 257, 1969, 32605, 12398, 11, 51300], "temperature": 0.0, "avg_logprob": -0.20415527680340936, "compression_ratio": 1.5617977528089888, "no_speech_prob": 0.0019312931690365076}, {"id": 70, "seek": 36664, "start": 385.36, "end": 392.15999999999997, "text": " what it does, it creates a control pane machine, generates cloud config, and also is responsible", "tokens": [51300, 437, 309, 775, 11, 309, 7829, 257, 1969, 32605, 3479, 11, 23815, 4588, 6662, 11, 293, 611, 307, 6250, 51640], "temperature": 0.0, "avg_logprob": -0.20415527680340936, "compression_ratio": 1.5617977528089888, "no_speech_prob": 0.0019312931690365076}, {"id": 71, "seek": 39216, "start": 392.20000000000005, "end": 397.84000000000003, "text": " for any other actions related to control pane management, stuff like, you know, HCD,", "tokens": [50366, 337, 604, 661, 5909, 4077, 281, 1969, 32605, 4592, 11, 1507, 411, 11, 291, 458, 11, 389, 16508, 11, 50648], "temperature": 0.0, "avg_logprob": -0.22512554841883042, "compression_ratio": 1.5502183406113537, "no_speech_prob": 0.007503637578338385}, {"id": 72, "seek": 39216, "start": 397.84000000000003, "end": 404.64000000000004, "text": " Core DNS, or whatever you implement or want to enable. Let me show you how it looks like,", "tokens": [50648, 14798, 35153, 11, 420, 2035, 291, 4445, 420, 528, 281, 9528, 13, 961, 385, 855, 291, 577, 309, 1542, 411, 11, 50988], "temperature": 0.0, "avg_logprob": -0.22512554841883042, "compression_ratio": 1.5502183406113537, "no_speech_prob": 0.007503637578338385}, {"id": 73, "seek": 39216, "start": 404.64000000000004, "end": 410.24, "text": " this will be so far the biggest object we have there, because it contains some configurations", "tokens": [50988, 341, 486, 312, 370, 1400, 264, 3880, 2657, 321, 362, 456, 11, 570, 309, 8306, 512, 31493, 51268], "temperature": 0.0, "avg_logprob": -0.22512554841883042, "compression_ratio": 1.5502183406113537, "no_speech_prob": 0.007503637578338385}, {"id": 74, "seek": 39216, "start": 410.24, "end": 418.6, "text": " we require for our control pane, but as you can see, you can customize some Kubernetes", "tokens": [51268, 321, 3651, 337, 527, 1969, 32605, 11, 457, 382, 291, 393, 536, 11, 291, 393, 19734, 512, 23145, 51686], "temperature": 0.0, "avg_logprob": -0.22512554841883042, "compression_ratio": 1.5502183406113537, "no_speech_prob": 0.007503637578338385}, {"id": 75, "seek": 41860, "start": 418.68, "end": 424.44, "text": " components there using Kubernetes API, so if you would like, you can just specify anything", "tokens": [50368, 6677, 456, 1228, 23145, 9362, 11, 370, 498, 291, 576, 411, 11, 291, 393, 445, 16500, 1340, 50656], "temperature": 0.0, "avg_logprob": -0.27404541628701345, "compression_ratio": 1.5123456790123457, "no_speech_prob": 0.0012640488566830754}, {"id": 76, "seek": 41860, "start": 424.44, "end": 431.44, "text": " you need here to provision control planes, you can also specify replica set, and you also", "tokens": [50656, 291, 643, 510, 281, 17225, 1969, 14952, 11, 291, 393, 611, 16500, 35456, 992, 11, 293, 291, 611, 51006], "temperature": 0.0, "avg_logprob": -0.27404541628701345, "compression_ratio": 1.5123456790123457, "no_speech_prob": 0.0012640488566830754}, {"id": 77, "seek": 41860, "start": 431.44, "end": 435.44, "text": " need Kubernetes version there. Now, maybe I forgot to create it.", "tokens": [51006, 643, 23145, 3037, 456, 13, 823, 11, 1310, 286, 5298, 281, 1884, 309, 13, 51206], "temperature": 0.0, "avg_logprob": -0.27404541628701345, "compression_ratio": 1.5123456790123457, "no_speech_prob": 0.0012640488566830754}, {"id": 78, "seek": 44860, "start": 449.56, "end": 460.08000000000004, "text": " Yeah. Okay, so let's talk about worker machines and how does KPI approach managing machines. It's", "tokens": [50412, 865, 13, 1033, 11, 370, 718, 311, 751, 466, 11346, 8379, 293, 577, 775, 591, 31701, 3109, 11642, 8379, 13, 467, 311, 50938], "temperature": 0.0, "avg_logprob": -0.25745795429616736, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.006710265297442675}, {"id": 79, "seek": 44860, "start": 460.08000000000004, "end": 469.0, "text": " important first to note that machine is just a host for your Kubernetes nodes, so it can be", "tokens": [50938, 1021, 700, 281, 3637, 300, 3479, 307, 445, 257, 3975, 337, 428, 23145, 13891, 11, 370, 309, 393, 312, 51384], "temperature": 0.0, "avg_logprob": -0.25745795429616736, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.006710265297442675}, {"id": 80, "seek": 44860, "start": 469.0, "end": 475.56, "text": " virtual machine, can be bare metal, can be anything your infrastructure provider means, and I'd like", "tokens": [51384, 6374, 3479, 11, 393, 312, 6949, 5760, 11, 393, 312, 1340, 428, 6896, 12398, 1355, 11, 293, 286, 1116, 411, 51712], "temperature": 0.0, "avg_logprob": -0.25745795429616736, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.006710265297442675}, {"id": 81, "seek": 47556, "start": 475.6, "end": 481.88, "text": " to show an example with bots, you don't manage bots manually, right? You don't use them as a", "tokens": [50366, 281, 855, 364, 1365, 365, 35410, 11, 291, 500, 380, 3067, 35410, 16945, 11, 558, 30, 509, 500, 380, 764, 552, 382, 257, 50680], "temperature": 0.0, "avg_logprob": -0.1924103328159877, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.025476275011897087}, {"id": 82, "seek": 47556, "start": 481.88, "end": 487.36, "text": " standalone resource, you use something else. If you want to manage replicas count for your", "tokens": [50680, 37454, 7684, 11, 291, 764, 746, 1646, 13, 759, 291, 528, 281, 3067, 3248, 9150, 1207, 337, 428, 50954], "temperature": 0.0, "avg_logprob": -0.1924103328159877, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.025476275011897087}, {"id": 83, "seek": 47556, "start": 487.36, "end": 492.8, "text": " bots, you use something called replica set that has just one purpose, create your certain count", "tokens": [50954, 35410, 11, 291, 764, 746, 1219, 35456, 992, 300, 575, 445, 472, 4334, 11, 1884, 428, 1629, 1207, 51226], "temperature": 0.0, "avg_logprob": -0.1924103328159877, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.025476275011897087}, {"id": 84, "seek": 47556, "start": 492.8, "end": 498.28, "text": " of bots, and then if you want to do more complex stuff like rolling upgrades, you use a deployment", "tokens": [51226, 295, 35410, 11, 293, 550, 498, 291, 528, 281, 360, 544, 3997, 1507, 411, 9439, 24868, 11, 291, 764, 257, 19317, 51500], "temperature": 0.0, "avg_logprob": -0.1924103328159877, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.025476275011897087}, {"id": 85, "seek": 47556, "start": 498.28, "end": 504.52, "text": " on top of this that manages replica set, so KPI followed the same pattern and created machines,", "tokens": [51500, 322, 1192, 295, 341, 300, 22489, 35456, 992, 11, 370, 591, 31701, 6263, 264, 912, 5102, 293, 2942, 8379, 11, 51812], "temperature": 0.0, "avg_logprob": -0.1924103328159877, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.025476275011897087}, {"id": 86, "seek": 50452, "start": 504.56, "end": 509.24, "text": " then there is a machine set that manages replica count, and there is a machine deployment on", "tokens": [50366, 550, 456, 307, 257, 3479, 992, 300, 22489, 35456, 1207, 11, 293, 456, 307, 257, 3479, 19317, 322, 50600], "temperature": 0.0, "avg_logprob": -0.22726406268219448, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.0034569529816508293}, {"id": 87, "seek": 50452, "start": 509.24, "end": 522.48, "text": " top of that, that does more complicated things. Let's go back to the terminal. I will show you a", "tokens": [50600, 1192, 295, 300, 11, 300, 775, 544, 6179, 721, 13, 961, 311, 352, 646, 281, 264, 14709, 13, 286, 486, 855, 291, 257, 51262], "temperature": 0.0, "avg_logprob": -0.22726406268219448, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.0034569529816508293}, {"id": 88, "seek": 50452, "start": 522.48, "end": 529.28, "text": " machine deployment, you can see similar to normal deployment has replica count, then it has a", "tokens": [51262, 3479, 19317, 11, 291, 393, 536, 2531, 281, 2710, 19317, 575, 35456, 1207, 11, 550, 309, 575, 257, 51602], "temperature": 0.0, "avg_logprob": -0.22726406268219448, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.0034569529816508293}, {"id": 89, "seek": 52928, "start": 529.3199999999999, "end": 536.04, "text": " selector, has a template, and inside the spec is similar to what we saw with cluster object, it has", "tokens": [50366, 23264, 1672, 11, 575, 257, 12379, 11, 293, 1854, 264, 1608, 307, 2531, 281, 437, 321, 1866, 365, 13630, 2657, 11, 309, 575, 50702], "temperature": 0.0, "avg_logprob": -0.24214969464202427, "compression_ratio": 1.5, "no_speech_prob": 0.027186965569853783}, {"id": 90, "seek": 52928, "start": 536.04, "end": 543.88, "text": " two references, one is for our infrastructure template, which is Docker for this demo, and the", "tokens": [50702, 732, 15400, 11, 472, 307, 337, 527, 6896, 12379, 11, 597, 307, 33772, 337, 341, 10723, 11, 293, 264, 51094], "temperature": 0.0, "avg_logprob": -0.24214969464202427, "compression_ratio": 1.5, "no_speech_prob": 0.027186965569853783}, {"id": 91, "seek": 52928, "start": 543.88, "end": 548.48, "text": " second one is a bootstrap provider, which is based on QPADM.", "tokens": [51094, 1150, 472, 307, 257, 11450, 372, 4007, 12398, 11, 597, 307, 2361, 322, 1249, 47, 6112, 44, 13, 51324], "temperature": 0.0, "avg_logprob": -0.24214969464202427, "compression_ratio": 1.5, "no_speech_prob": 0.027186965569853783}, {"id": 92, "seek": 55928, "start": 560.28, "end": 569.68, "text": " So the infrastructure template or Docker template that we saw there in the reference are just", "tokens": [50414, 407, 264, 6896, 12379, 420, 33772, 12379, 300, 321, 1866, 456, 294, 264, 6408, 366, 445, 50884], "temperature": 0.0, "avg_logprob": -0.2519181251525879, "compression_ratio": 1.5919540229885059, "no_speech_prob": 0.0034006827045232058}, {"id": 93, "seek": 55928, "start": 569.68, "end": 574.76, "text": " specifications for your host depending on your cloud provider, it can be an instance type,", "tokens": [50884, 29448, 337, 428, 3975, 5413, 322, 428, 4588, 12398, 11, 309, 393, 312, 364, 5197, 2010, 11, 51138], "temperature": 0.0, "avg_logprob": -0.2519181251525879, "compression_ratio": 1.5919540229885059, "no_speech_prob": 0.0034006827045232058}, {"id": 94, "seek": 55928, "start": 574.76, "end": 582.88, "text": " storage size, anything you put there, and the second reference to bootstrap provider is just", "tokens": [51138, 6725, 2744, 11, 1340, 291, 829, 456, 11, 293, 264, 1150, 6408, 281, 11450, 372, 4007, 12398, 307, 445, 51544], "temperature": 0.0, "avg_logprob": -0.2519181251525879, "compression_ratio": 1.5919540229885059, "no_speech_prob": 0.0034006827045232058}, {"id": 95, "seek": 58288, "start": 583.28, "end": 589.84, "text": " a reference to an API that generates user data with proper cloud config, so you can configure", "tokens": [50384, 257, 6408, 281, 364, 9362, 300, 23815, 4195, 1412, 365, 2296, 4588, 6662, 11, 370, 291, 393, 22162, 50712], "temperature": 0.0, "avg_logprob": -0.20074839708281728, "compression_ratio": 1.6018518518518519, "no_speech_prob": 0.01719770021736622}, {"id": 96, "seek": 58288, "start": 589.84, "end": 596.36, "text": " your Kubernetes components as you want. Let me show you how it looks like. For Docker machine,", "tokens": [50712, 428, 23145, 6677, 382, 291, 528, 13, 961, 385, 855, 291, 577, 309, 1542, 411, 13, 1171, 33772, 3479, 11, 51038], "temperature": 0.0, "avg_logprob": -0.20074839708281728, "compression_ratio": 1.6018518518518519, "no_speech_prob": 0.01719770021736622}, {"id": 97, "seek": 58288, "start": 596.36, "end": 604.96, "text": " it's just an image in this case and some extra mounts, and for bootstrap provider, we just have", "tokens": [51038, 309, 311, 445, 364, 3256, 294, 341, 1389, 293, 512, 2857, 40982, 11, 293, 337, 11450, 372, 4007, 12398, 11, 321, 445, 362, 51468], "temperature": 0.0, "avg_logprob": -0.20074839708281728, "compression_ratio": 1.6018518518518519, "no_speech_prob": 0.01719770021736622}, {"id": 98, "seek": 58288, "start": 604.96, "end": 609.16, "text": " some arguments for our Kubernetes components, and this is it.", "tokens": [51468, 512, 12869, 337, 527, 23145, 6677, 11, 293, 341, 307, 309, 13, 51678], "temperature": 0.0, "avg_logprob": -0.20074839708281728, "compression_ratio": 1.6018518518518519, "no_speech_prob": 0.01719770021736622}, {"id": 99, "seek": 61288, "start": 612.88, "end": 633.68, "text": " Okay, so this was it. Let me now check if everything works fine. Yeah, everything works fine. As you", "tokens": [50364, 1033, 11, 370, 341, 390, 309, 13, 961, 385, 586, 1520, 498, 1203, 1985, 2489, 13, 865, 11, 1203, 1985, 2489, 13, 1018, 291, 51404], "temperature": 0.0, "avg_logprob": -0.20985968569491772, "compression_ratio": 1.4661654135338347, "no_speech_prob": 0.005606219172477722}, {"id": 100, "seek": 61288, "start": 633.68, "end": 640.0, "text": " can see, we have three control pane machines that are running inside Docker containers that we", "tokens": [51404, 393, 536, 11, 321, 362, 1045, 1969, 32605, 8379, 300, 366, 2614, 1854, 33772, 17089, 300, 321, 51720], "temperature": 0.0, "avg_logprob": -0.20985968569491772, "compression_ratio": 1.4661654135338347, "no_speech_prob": 0.005606219172477722}, {"id": 101, "seek": 64000, "start": 640.0, "end": 645.68, "text": " created before and after some time, we should get a worker machine that we just created.", "tokens": [50364, 2942, 949, 293, 934, 512, 565, 11, 321, 820, 483, 257, 11346, 3479, 300, 321, 445, 2942, 13, 50648], "temperature": 0.0, "avg_logprob": -0.16408900938172272, "compression_ratio": 1.5449735449735449, "no_speech_prob": 0.0018309318693354726}, {"id": 102, "seek": 64000, "start": 645.68, "end": 657.88, "text": " Let's take a look at how it all works together. We have a cluster object that represents the cluster,", "tokens": [50648, 961, 311, 747, 257, 574, 412, 577, 309, 439, 1985, 1214, 13, 492, 362, 257, 13630, 2657, 300, 8855, 264, 13630, 11, 51258], "temperature": 0.0, "avg_logprob": -0.16408900938172272, "compression_ratio": 1.5449735449735449, "no_speech_prob": 0.0018309318693354726}, {"id": 103, "seek": 64000, "start": 657.88, "end": 665.08, "text": " then it has to reference an infrastructure provider, which is Docker in this case, and it also has to", "tokens": [51258, 550, 309, 575, 281, 6408, 364, 6896, 12398, 11, 597, 307, 33772, 294, 341, 1389, 11, 293, 309, 611, 575, 281, 51618], "temperature": 0.0, "avg_logprob": -0.16408900938172272, "compression_ratio": 1.5449735449735449, "no_speech_prob": 0.0018309318693354726}, {"id": 104, "seek": 66508, "start": 665.08, "end": 673.1600000000001, "text": " reference a control pane provider, which is based on QPADM, and once these two are done with a job,", "tokens": [50364, 6408, 257, 1969, 32605, 12398, 11, 597, 307, 2361, 322, 1249, 47, 6112, 44, 11, 293, 1564, 613, 732, 366, 1096, 365, 257, 1691, 11, 50768], "temperature": 0.0, "avg_logprob": -0.2703820618105606, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.021376697346568108}, {"id": 105, "seek": 66508, "start": 673.1600000000001, "end": 680.1600000000001, "text": " you can connect your machine deployments that have to reference a machine template, so Kapi knows", "tokens": [50768, 291, 393, 1745, 428, 3479, 7274, 1117, 300, 362, 281, 6408, 257, 3479, 12379, 11, 370, 591, 35891, 3255, 51118], "temperature": 0.0, "avg_logprob": -0.2703820618105606, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.021376697346568108}, {"id": 106, "seek": 66508, "start": 680.1600000000001, "end": 688.44, "text": " what specifications you want, and also a QPADM config template where you can configure your", "tokens": [51118, 437, 29448, 291, 528, 11, 293, 611, 257, 1249, 47, 6112, 44, 6662, 12379, 689, 291, 393, 22162, 428, 51532], "temperature": 0.0, "avg_logprob": -0.2703820618105606, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.021376697346568108}, {"id": 107, "seek": 68844, "start": 688.48, "end": 703.12, "text": " Kubernetes components, and this is all you need to create a basic Kapi cluster. Unfortunately, I don't have enough", "tokens": [50366, 23145, 6677, 11, 293, 341, 307, 439, 291, 643, 281, 1884, 257, 3875, 591, 35891, 13630, 13, 8590, 11, 286, 500, 380, 362, 1547, 51098], "temperature": 0.0, "avg_logprob": -0.21200448188228885, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0303943008184433}, {"id": 108, "seek": 68844, "start": 703.12, "end": 711.2, "text": " time to talk about other things that exist in Kapi like machine health checks that help you track and", "tokens": [51098, 565, 281, 751, 466, 661, 721, 300, 2514, 294, 591, 35891, 411, 3479, 1585, 13834, 300, 854, 291, 2837, 293, 51502], "temperature": 0.0, "avg_logprob": -0.21200448188228885, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0303943008184433}, {"id": 109, "seek": 68844, "start": 711.2, "end": 717.36, "text": " remediate unhealthy machines when there are cluster classes, which are powerful templates for creating", "tokens": [51502, 890, 10323, 473, 29147, 8379, 562, 456, 366, 13630, 5359, 11, 597, 366, 4005, 21165, 337, 4084, 51810], "temperature": 0.0, "avg_logprob": -0.21200448188228885, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0303943008184433}, {"id": 110, "seek": 71736, "start": 717.48, "end": 723.32, "text": " clusters. You can also connect cluster autoscalar if you want, and there are day two operations coming,", "tokens": [50370, 23313, 13, 509, 393, 611, 1745, 13630, 1476, 10466, 12031, 498, 291, 528, 11, 293, 456, 366, 786, 732, 7705, 1348, 11, 50662], "temperature": 0.0, "avg_logprob": -0.3263401340793919, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0035621076822280884}, {"id": 111, "seek": 71736, "start": 723.32, "end": 728.92, "text": " so you can think of KPS like SwissKnife for everything related to cluster lifecycle.", "tokens": [50662, 370, 291, 393, 519, 295, 591, 6273, 411, 21965, 49276, 863, 337, 1203, 4077, 281, 13630, 45722, 13, 50942], "temperature": 0.0, "avg_logprob": -0.3263401340793919, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0035621076822280884}, {"id": 112, "seek": 71736, "start": 732.8000000000001, "end": 742.96, "text": " And we still have time. I'm going to show you how we can upgrade the cluster. Let's check its state again.", "tokens": [51136, 400, 321, 920, 362, 565, 13, 286, 478, 516, 281, 855, 291, 577, 321, 393, 11484, 264, 13630, 13, 961, 311, 1520, 1080, 1785, 797, 13, 51644], "temperature": 0.0, "avg_logprob": -0.3263401340793919, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0035621076822280884}, {"id": 113, "seek": 74296, "start": 743.9200000000001, "end": 745.9200000000001, "text": " Yeah, so if you...", "tokens": [50412, 865, 11, 370, 498, 291, 485, 50512], "temperature": 0.0, "avg_logprob": -0.2985537648200989, "compression_ratio": 1.4458598726114649, "no_speech_prob": 0.0036447367165237665}, {"id": 114, "seek": 74296, "start": 749.88, "end": 759.88, "text": " Now you can see that we have three control planes, and they all are running Kubernetes v125, and let me", "tokens": [50710, 823, 291, 393, 536, 300, 321, 362, 1045, 1969, 14952, 11, 293, 436, 439, 366, 2614, 23145, 371, 48804, 11, 293, 718, 385, 51210], "temperature": 0.0, "avg_logprob": -0.2985537648200989, "compression_ratio": 1.4458598726114649, "no_speech_prob": 0.0036447367165237665}, {"id": 115, "seek": 74296, "start": 759.88, "end": 768.88, "text": " upgrade them to Kubernetes v126, so how do I do this? In order to do this, we have to change the version", "tokens": [51210, 11484, 552, 281, 23145, 371, 4762, 21, 11, 370, 577, 360, 286, 360, 341, 30, 682, 1668, 281, 360, 341, 11, 321, 362, 281, 1319, 264, 3037, 51660], "temperature": 0.0, "avg_logprob": -0.2985537648200989, "compression_ratio": 1.4458598726114649, "no_speech_prob": 0.0036447367165237665}, {"id": 116, "seek": 76888, "start": 769.8, "end": 775.8, "text": " in the control pane provider object, and we also have to change the image reference in the machine", "tokens": [50410, 294, 264, 1969, 32605, 12398, 2657, 11, 293, 321, 611, 362, 281, 1319, 264, 3256, 6408, 294, 264, 3479, 50710], "temperature": 0.0, "avg_logprob": -0.19623847374549278, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.002750282408669591}, {"id": 117, "seek": 76888, "start": 775.8, "end": 781.8, "text": " template. So just by doing so, I will start upgrading the cluster.", "tokens": [50710, 12379, 13, 407, 445, 538, 884, 370, 11, 286, 486, 722, 36249, 264, 13630, 13, 51010], "temperature": 0.0, "avg_logprob": -0.19623847374549278, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.002750282408669591}, {"id": 118, "seek": 76888, "start": 790.8, "end": 797.8, "text": " As you can see, cluster API started to spin up new control pane machine with v126 that is going to", "tokens": [51460, 1018, 291, 393, 536, 11, 13630, 9362, 1409, 281, 6060, 493, 777, 1969, 32605, 3479, 365, 371, 4762, 21, 300, 307, 516, 281, 51810], "temperature": 0.0, "avg_logprob": -0.19623847374549278, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.002750282408669591}, {"id": 119, "seek": 79780, "start": 798.7199999999999, "end": 804.7199999999999, "text": " replace old ones, and it's going to take care for us like insuring a CD quorum and all sorts of things,", "tokens": [50410, 7406, 1331, 2306, 11, 293, 309, 311, 516, 281, 747, 1127, 337, 505, 411, 1028, 1345, 257, 6743, 421, 36543, 293, 439, 7527, 295, 721, 11, 50710], "temperature": 0.0, "avg_logprob": -0.22081168492635092, "compression_ratio": 1.4910179640718564, "no_speech_prob": 0.009119352325797081}, {"id": 120, "seek": 79780, "start": 804.7199999999999, "end": 806.7199999999999, "text": " so we don't have to take care about this.", "tokens": [50710, 370, 321, 500, 380, 362, 281, 747, 1127, 466, 341, 13, 50810], "temperature": 0.0, "avg_logprob": -0.22081168492635092, "compression_ratio": 1.4910179640718564, "no_speech_prob": 0.009119352325797081}, {"id": 121, "seek": 79780, "start": 815.7199999999999, "end": 825.7199999999999, "text": " I'm going to go back to the summary, and let's go once again for what we saw today. So I try to explain", "tokens": [51260, 286, 478, 516, 281, 352, 646, 281, 264, 12691, 11, 293, 718, 311, 352, 1564, 797, 337, 437, 321, 1866, 965, 13, 407, 286, 853, 281, 2903, 51760], "temperature": 0.0, "avg_logprob": -0.22081168492635092, "compression_ratio": 1.4910179640718564, "no_speech_prob": 0.009119352325797081}, {"id": 122, "seek": 82572, "start": 826.64, "end": 833.64, "text": " the problem of managing Kubernetes clusters, and the main idea, we wanted to have a tool that provides", "tokens": [50410, 264, 1154, 295, 11642, 23145, 23313, 11, 293, 264, 2135, 1558, 11, 321, 1415, 281, 362, 257, 2290, 300, 6417, 50760], "temperature": 0.0, "avg_logprob": -0.11801549792289734, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.008601009845733643}, {"id": 123, "seek": 82572, "start": 833.64, "end": 839.64, "text": " a declarative and consistent API, and will allow you provision and manage your clusters on different", "tokens": [50760, 257, 16694, 1166, 293, 8398, 9362, 11, 293, 486, 2089, 291, 17225, 293, 3067, 428, 23313, 322, 819, 51060], "temperature": 0.0, "avg_logprob": -0.11801549792289734, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.008601009845733643}, {"id": 124, "seek": 82572, "start": 839.64, "end": 847.64, "text": " infrastructure in some nice way so you can have a single point of managing your clusters for all", "tokens": [51060, 6896, 294, 512, 1481, 636, 370, 291, 393, 362, 257, 2167, 935, 295, 11642, 428, 23313, 337, 439, 51460], "temperature": 0.0, "avg_logprob": -0.11801549792289734, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.008601009845733643}, {"id": 125, "seek": 84764, "start": 848.56, "end": 855.56, "text": " the possible infrastructures you're running, and this approach is like use Kubernetes because", "tokens": [50410, 264, 1944, 6534, 44513, 291, 434, 2614, 11, 293, 341, 3109, 307, 411, 764, 23145, 570, 50760], "temperature": 0.0, "avg_logprob": -0.211040330969769, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.021599259227514267}, {"id": 126, "seek": 84764, "start": 855.56, "end": 861.56, "text": " Kubernetes already provides a lot of tools for building a powerful API.", "tokens": [50760, 23145, 1217, 6417, 257, 688, 295, 3873, 337, 2390, 257, 4005, 9362, 13, 51060], "temperature": 0.0, "avg_logprob": -0.211040330969769, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.021599259227514267}, {"id": 127, "seek": 84764, "start": 865.56, "end": 871.56, "text": " I think with us it, maybe I was a bit quick, but I don't have anything else. I'm ready to answer", "tokens": [51260, 286, 519, 365, 505, 309, 11, 1310, 286, 390, 257, 857, 1702, 11, 457, 286, 500, 380, 362, 1340, 1646, 13, 286, 478, 1919, 281, 1867, 51560], "temperature": 0.0, "avg_logprob": -0.211040330969769, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.021599259227514267}, {"id": 128, "seek": 84764, "start": 871.56, "end": 873.56, "text": " questions if someone has.", "tokens": [51560, 1651, 498, 1580, 575, 13, 51660], "temperature": 0.0, "avg_logprob": -0.211040330969769, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.021599259227514267}, {"id": 129, "seek": 87764, "start": 878.56, "end": 883.56, "text": " Okay, we have ample time for questions.", "tokens": [50410, 1033, 11, 321, 362, 42857, 565, 337, 1651, 13, 50660], "temperature": 0.0, "avg_logprob": -0.23813765119798114, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.011234176345169544}, {"id": 130, "seek": 87764, "start": 887.56, "end": 893.56, "text": " Hi, thanks for the nice demo. This allows you to manage the workload clusters. Can it also", "tokens": [50860, 2421, 11, 3231, 337, 264, 1481, 10723, 13, 639, 4045, 291, 281, 3067, 264, 20139, 23313, 13, 1664, 309, 611, 51160], "temperature": 0.0, "avg_logprob": -0.23813765119798114, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.011234176345169544}, {"id": 131, "seek": 87764, "start": 893.56, "end": 897.56, "text": " manage the life cycle of the management cluster, or how do you do that?", "tokens": [51160, 3067, 264, 993, 6586, 295, 264, 4592, 13630, 11, 420, 577, 360, 291, 360, 300, 30, 51360], "temperature": 0.0, "avg_logprob": -0.23813765119798114, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.011234176345169544}, {"id": 132, "seek": 87764, "start": 897.56, "end": 898.56, "text": " Yes, you can.", "tokens": [51360, 1079, 11, 291, 393, 13, 51410], "temperature": 0.0, "avg_logprob": -0.23813765119798114, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.011234176345169544}, {"id": 133, "seek": 87764, "start": 898.56, "end": 900.56, "text": " So what if it destroys itself, so what happens then?", "tokens": [51410, 407, 437, 498, 309, 36714, 2564, 11, 370, 437, 2314, 550, 30, 51510], "temperature": 0.0, "avg_logprob": -0.23813765119798114, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.011234176345169544}, {"id": 134, "seek": 87764, "start": 900.56, "end": 903.56, "text": " It shouldn't. Depends on how you use it, but yeah.", "tokens": [51510, 467, 4659, 380, 13, 4056, 2581, 322, 577, 291, 764, 309, 11, 457, 1338, 13, 51660], "temperature": 0.0, "avg_logprob": -0.23813765119798114, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.011234176345169544}, {"id": 135, "seek": 87764, "start": 903.56, "end": 905.56, "text": " Works on local clusters, thank you.", "tokens": [51660, 27914, 322, 2654, 23313, 11, 1309, 291, 13, 51760], "temperature": 0.0, "avg_logprob": -0.23813765119798114, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.011234176345169544}, {"id": 136, "seek": 90556, "start": 906.4799999999999, "end": 911.4799999999999, "text": " Thank you.", "tokens": [50410, 1044, 291, 13, 50660], "temperature": 0.0, "avg_logprob": -0.2535649538040161, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.01010542269796133}, {"id": 137, "seek": 90556, "start": 911.4799999999999, "end": 916.4799999999999, "text": " The question about updates, is it possible to update components like cobalates without", "tokens": [50660, 440, 1168, 466, 9205, 11, 307, 309, 1944, 281, 5623, 6677, 411, 598, 2645, 1024, 1553, 50910], "temperature": 0.0, "avg_logprob": -0.2535649538040161, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.01010542269796133}, {"id": 138, "seek": 90556, "start": 916.4799999999999, "end": 918.4799999999999, "text": " recreating virtual machines?", "tokens": [50910, 850, 44613, 6374, 8379, 30, 51010], "temperature": 0.0, "avg_logprob": -0.2535649538040161, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.01010542269796133}, {"id": 139, "seek": 90556, "start": 918.4799999999999, "end": 919.4799999999999, "text": " Yes.", "tokens": [51010, 1079, 13, 51060], "temperature": 0.0, "avg_logprob": -0.2535649538040161, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.01010542269796133}, {"id": 140, "seek": 90556, "start": 919.4799999999999, "end": 920.4799999999999, "text": " And how is it working?", "tokens": [51060, 400, 577, 307, 309, 1364, 30, 51110], "temperature": 0.0, "avg_logprob": -0.2535649538040161, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.01010542269796133}, {"id": 141, "seek": 90556, "start": 920.4799999999999, "end": 925.4799999999999, "text": " It's done through your bootstrap or control pane provider.", "tokens": [51110, 467, 311, 1096, 807, 428, 11450, 372, 4007, 420, 1969, 32605, 12398, 13, 51360], "temperature": 0.0, "avg_logprob": -0.2535649538040161, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.01010542269796133}, {"id": 142, "seek": 90556, "start": 925.4799999999999, "end": 932.4799999999999, "text": " Yeah, and you also have to provide an image that will be used for your new instances.", "tokens": [51360, 865, 11, 293, 291, 611, 362, 281, 2893, 364, 3256, 300, 486, 312, 1143, 337, 428, 777, 14519, 13, 51710], "temperature": 0.0, "avg_logprob": -0.2535649538040161, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.01010542269796133}, {"id": 143, "seek": 93248, "start": 933.4, "end": 938.4, "text": " No, no, I mean if you need to update cobalates and you don't want to reorder new...", "tokens": [50410, 883, 11, 572, 11, 286, 914, 498, 291, 643, 281, 5623, 598, 2645, 1024, 293, 291, 500, 380, 528, 281, 319, 4687, 777, 485, 50660], "temperature": 0.0, "avg_logprob": -0.1956106976764958, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.011754210107028484}, {"id": 144, "seek": 93248, "start": 938.4, "end": 943.4, "text": " Yeah, okay. Costa API doesn't support in-place upgrades. It will be creating a new machine", "tokens": [50660, 865, 11, 1392, 13, 28440, 9362, 1177, 380, 1406, 294, 12, 6742, 24868, 13, 467, 486, 312, 4084, 257, 777, 3479, 50910], "temperature": 0.0, "avg_logprob": -0.1956106976764958, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.011754210107028484}, {"id": 145, "seek": 93248, "start": 943.4, "end": 946.4, "text": " with new image, new everything, and then replacing old one.", "tokens": [50910, 365, 777, 3256, 11, 777, 1203, 11, 293, 550, 19139, 1331, 472, 13, 51060], "temperature": 0.0, "avg_logprob": -0.1956106976764958, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.011754210107028484}, {"id": 146, "seek": 93248, "start": 946.4, "end": 950.4, "text": " Okay, got it. And can you tell a little more about control pane updates?", "tokens": [51060, 1033, 11, 658, 309, 13, 400, 393, 291, 980, 257, 707, 544, 466, 1969, 32605, 9205, 30, 51260], "temperature": 0.0, "avg_logprob": -0.1956106976764958, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.011754210107028484}, {"id": 147, "seek": 93248, "start": 950.4, "end": 951.4, "text": " Sorry?", "tokens": [51260, 4919, 30, 51310], "temperature": 0.0, "avg_logprob": -0.1956106976764958, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.011754210107028484}, {"id": 148, "seek": 93248, "start": 951.4, "end": 956.4, "text": " Control pane updates, updates of control pane nodes and components.", "tokens": [51310, 12912, 32605, 9205, 11, 9205, 295, 1969, 32605, 13891, 293, 6677, 13, 51560], "temperature": 0.0, "avg_logprob": -0.1956106976764958, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.011754210107028484}, {"id": 149, "seek": 93248, "start": 956.4, "end": 962.4, "text": " So I just showed one, like when you change the version it will start replacing old machines", "tokens": [51560, 407, 286, 445, 4712, 472, 11, 411, 562, 291, 1319, 264, 3037, 309, 486, 722, 19139, 1331, 8379, 51860], "temperature": 0.0, "avg_logprob": -0.1956106976764958, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.011754210107028484}, {"id": 150, "seek": 96240, "start": 962.4, "end": 965.4, "text": " with newer ones. You just have to provide all the specifications. You have to provide", "tokens": [50364, 365, 17628, 2306, 13, 509, 445, 362, 281, 2893, 439, 264, 29448, 13, 509, 362, 281, 2893, 50514], "temperature": 0.0, "avg_logprob": -0.19669444220406668, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.019744612276554108}, {"id": 151, "seek": 96240, "start": 965.4, "end": 970.4, "text": " a new Kubernetes version you want and also a new image. So we try to bake everything", "tokens": [50514, 257, 777, 23145, 3037, 291, 528, 293, 611, 257, 777, 3256, 13, 407, 321, 853, 281, 16562, 1203, 50764], "temperature": 0.0, "avg_logprob": -0.19669444220406668, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.019744612276554108}, {"id": 152, "seek": 96240, "start": 970.4, "end": 976.4, "text": " inside the machine image so you don't have to download new things and it will just replace", "tokens": [50764, 1854, 264, 3479, 3256, 370, 291, 500, 380, 362, 281, 5484, 777, 721, 293, 309, 486, 445, 7406, 51064], "temperature": 0.0, "avg_logprob": -0.19669444220406668, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.019744612276554108}, {"id": 153, "seek": 96240, "start": 976.4, "end": 983.4, "text": " old machine with a new one, with new versions. So it's a replace upgrade. It's not in place.", "tokens": [51064, 1331, 3479, 365, 257, 777, 472, 11, 365, 777, 9606, 13, 407, 309, 311, 257, 7406, 11484, 13, 467, 311, 406, 294, 1081, 13, 51414], "temperature": 0.0, "avg_logprob": -0.19669444220406668, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.019744612276554108}, {"id": 154, "seek": 96240, "start": 984.4, "end": 989.4, "text": " The same as POTS, if you change, for example, reference to image, it will destroy old one", "tokens": [51464, 440, 912, 382, 430, 5068, 50, 11, 498, 291, 1319, 11, 337, 1365, 11, 6408, 281, 3256, 11, 309, 486, 5293, 1331, 472, 51714], "temperature": 0.0, "avg_logprob": -0.19669444220406668, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.019744612276554108}, {"id": 155, "seek": 98940, "start": 989.4, "end": 993.4, "text": " and create a newer one. So it's the same concept.", "tokens": [50364, 293, 1884, 257, 17628, 472, 13, 407, 309, 311, 264, 912, 3410, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17546584389426492, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.020617123693227768}, {"id": 156, "seek": 98940, "start": 993.4, "end": 998.4, "text": " There's an online question is in the chat. Are there any latency requirements between", "tokens": [50564, 821, 311, 364, 2950, 1168, 307, 294, 264, 5081, 13, 2014, 456, 604, 27043, 7728, 1296, 50814], "temperature": 0.0, "avg_logprob": -0.17546584389426492, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.020617123693227768}, {"id": 157, "seek": 98940, "start": 998.4, "end": 1002.4, "text": " the management cluster and the workload cluster?", "tokens": [50814, 264, 4592, 13630, 293, 264, 20139, 13630, 30, 51014], "temperature": 0.0, "avg_logprob": -0.17546584389426492, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.020617123693227768}, {"id": 158, "seek": 98940, "start": 1002.4, "end": 1012.4, "text": " It depends on your use case, but yeah, ideally you should take care of your management cluster", "tokens": [51014, 467, 5946, 322, 428, 764, 1389, 11, 457, 1338, 11, 22915, 291, 820, 747, 1127, 295, 428, 4592, 13630, 51514], "temperature": 0.0, "avg_logprob": -0.17546584389426492, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.020617123693227768}, {"id": 159, "seek": 101240, "start": 1012.4, "end": 1022.4, "text": " with somewhere near workload clusters or is able to reach it within some limits.", "tokens": [50364, 365, 4079, 2651, 20139, 23313, 420, 307, 1075, 281, 2524, 309, 1951, 512, 10406, 13, 50864], "temperature": 0.0, "avg_logprob": -0.16089059304499972, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.025326408445835114}, {"id": 160, "seek": 101240, "start": 1026.4, "end": 1032.4, "text": " And one more. Does the management cluster need to run at all the time or can it be shut off", "tokens": [51064, 400, 472, 544, 13, 4402, 264, 4592, 13630, 643, 281, 1190, 412, 439, 264, 565, 420, 393, 309, 312, 5309, 766, 51364], "temperature": 0.0, "avg_logprob": -0.16089059304499972, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.025326408445835114}, {"id": 161, "seek": 101240, "start": 1032.4, "end": 1035.4, "text": " when not doing life cycle work?", "tokens": [51364, 562, 406, 884, 993, 6586, 589, 30, 51514], "temperature": 0.0, "avg_logprob": -0.16089059304499972, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.025326408445835114}, {"id": 162, "seek": 101240, "start": 1035.4, "end": 1041.4, "text": " So here is the thing. If you disable it nothing will manage your Kubernetes cluster", "tokens": [51514, 407, 510, 307, 264, 551, 13, 759, 291, 28362, 309, 1825, 486, 3067, 428, 23145, 13630, 51814], "temperature": 0.0, "avg_logprob": -0.16089059304499972, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.025326408445835114}, {"id": 163, "seek": 104140, "start": 1041.4, "end": 1045.4, "text": " so they will be basically unmanaged. Yeah, your workload cluster will continue running", "tokens": [50364, 370, 436, 486, 312, 1936, 517, 1601, 2980, 13, 865, 11, 428, 20139, 13630, 486, 2354, 2614, 50564], "temperature": 0.0, "avg_logprob": -0.12636911492598685, "compression_ratio": 1.6846473029045643, "no_speech_prob": 0.0072470493614673615}, {"id": 164, "seek": 104140, "start": 1045.4, "end": 1050.4, "text": " but there is nothing that will keep track of them. For example, if you use cluster autoscaler", "tokens": [50564, 457, 456, 307, 1825, 300, 486, 1066, 2837, 295, 552, 13, 1171, 1365, 11, 498, 291, 764, 13630, 1476, 329, 9895, 260, 50814], "temperature": 0.0, "avg_logprob": -0.12636911492598685, "compression_ratio": 1.6846473029045643, "no_speech_prob": 0.0072470493614673615}, {"id": 165, "seek": 104140, "start": 1050.4, "end": 1054.4, "text": " or machine health checks you need your management cluster to be running all the time", "tokens": [50814, 420, 3479, 1585, 13834, 291, 643, 428, 4592, 13630, 281, 312, 2614, 439, 264, 565, 51014], "temperature": 0.0, "avg_logprob": -0.12636911492598685, "compression_ratio": 1.6846473029045643, "no_speech_prob": 0.0072470493614673615}, {"id": 166, "seek": 104140, "start": 1054.4, "end": 1058.4, "text": " because it constantly looks at the state of your workload clusters.", "tokens": [51014, 570, 309, 6460, 1542, 412, 264, 1785, 295, 428, 20139, 23313, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12636911492598685, "compression_ratio": 1.6846473029045643, "no_speech_prob": 0.0072470493614673615}, {"id": 167, "seek": 104140, "start": 1062.4, "end": 1067.4, "text": " Okay. If there are no more questions and we can end a few minutes early.", "tokens": [51414, 1033, 13, 759, 456, 366, 572, 544, 1651, 293, 321, 393, 917, 257, 1326, 2077, 2440, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12636911492598685, "compression_ratio": 1.6846473029045643, "no_speech_prob": 0.0072470493614673615}, {"id": 168, "seek": 106740, "start": 1067.4, "end": 1070.4, "text": " Thank you for the talk. Thank you all for attending.", "tokens": [50364, 1044, 291, 337, 264, 751, 13, 1044, 291, 439, 337, 15862, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08076639970143636, "compression_ratio": 1.0612244897959184, "no_speech_prob": 0.03091253526508808}], "language": "en"}