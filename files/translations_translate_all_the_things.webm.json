{"text": " So let's dive right into it. LibreTranslate is a software that's a bit like Google Translate, but open-source. It is AGPL3 license, so it's a strongly open-source. In fact, we're going to keep it that way forever, and let's you do natural language translation. It runs on your computer. This is one of the goals of the project. There are several other projects in the open-source realm that have aimed to provide natural language translation, except sometimes that they require a very large servers or a lot of memory, and our goal is to have this running on something as low as a Raspberry Pi. So that is very important to the project. The program has lots of clients and integrations. We'll cover some of those in the upcoming slides. Like many projects, it's available on GitHub, so you can go and check it out. But we're going to give you today a brief overview of how to get started and start using it today. Let's talk briefly about why we decided to create it, and there was a need for the project to exist. We could not find a project that had all the variables that LibreTranslate can offer. These are a simple and open-res API that you can use to programmatically do translations, so help automate part of the translation work that we need for the work. It offers pre-trained and openly licensed language models. There are other projects that do machine translation, but again, sometimes they do not make the AI models for the translation openly available, and we have that. Finally, it runs again on commodity hardware, so it does now require server-scale power to make the software work, and finally, it is very easy to get started as you will see. So talking about getting started, there are primarily two ways that you can get LibreTranslate to work on your computer. The first one is if you have Python, you can simply run a pip install command, LibreTranslate, and afterwards you run the program, and that's it. If you have Docker, which many developers like to use, we also have an option for that. We pre-build images for LibreTranslate that you can use, and we have a convenient script that will run it for you and take care of a few details that let you have things like persistent volumes for downloading language models and some technical stuff. But to get started, all you need to do is go on GitHub, get a copy of our source code, and press Run. We also have scripts for Windows and Mac OS and Linux, so we try to support all major platforms. We're hoping to get other platforms in there as well, so things like FreeBSD and others are on the to-do list. So we'll get there. So let's actually try to run it, and I'm always a little scared of doing live demos, but bear with me, we're going to try it. What could go wrong? So here is a console. I'm going to quickly activate a Python environment where I have LibreTranslate already installed, and I'm going to try to run it. On Mac OS, I have to specify a different port than the default of 5,000. I'm going to try to run it. Okay, it seems to be working. So I'm going to jump back right into Chrome, and if I refresh the page, you will be presented with a friendly user interface that you can use to test the system and even use it. It allows programmatic access to the software via an API, but you can also use it as an alternative to Google Translate if you want to. So we're going to try to say something. Okay, so obviously English to English is not going to be helpful. How about French? Okay. So we translated Hello World, Bonjour Le Monde, and it worked. But that's not too impressive, right? I'm like, okay, Hello World. Let's try to look at something a little more realistic. Before looking at something more realistic, you can also, of course, use it from an API. In this case, I can invoke a Cura command and ask Libre Translate to perform a translation. I wanted to automatically detect the language, where the translation is coming from, and finally, I want to translate into the target language. I get a JSON response. Everything in the API is JSON-based. So that will be familiar with many developers. But let's look at a more realistic example. In this case, we have a longer piece of text, and it also contains HTML. The software is capable of translating the parts that need translation while leaving the HTML part intact. So things like hyperlinks do not get mistakenly translated, which would be really bad. This code that we saw here roughly gets represented as this piece of HTML in a browser, and the translation is pretty good. Kind of. This word should have been filidae. It decided to keep the translation in French. We will improve that with time. But otherwise, the context and the meaning of the sentence is pretty darn good. We will look at accuracy in the upcoming slides. So as an overview of the list of features, it can do text translation, it can do markup translation that includes HTML, XML, and other formats that use a markup. It can do several formats for file translation. So you can upload things like open office, LibreOffice, Word documents, and PowerPoint slides, and able to translate those as well. It can perform a language detection. So you give it a piece of text, and it will give you an estimate of which language the program thinks it is. It also has a built-in system for doing rate limiting. If you're planning to host this on a public server, you will find out that it's a very useful feature, because people really like free resources, and it's difficult to give everything for free without some limits. So if your translation instance up in the Cloud gets really popular, having some limit by saying, do a maximum of 60 translation per minute, will come really handy and it's all built in into the software. You can further issue API keys to give to people that can change those limits. So you can set up the system in a way where you allow anonymous users to translate up to 20 translations per minute, and you can allow a subset of people that you've issued API keys to have however many they want. You decide those limits. It also has a localized UI. We're using WebLater to do that, which is awesome, and it has been currently translated into four languages, and we're looking to verify and add more. One cool neat feature is that a Libre translator has a ability to translate itself roughly, so we have done that of course, but we haven't displayed all the languages that it has tried to translate itself. We are waiting for a native speaker to review the actual translation and correct it. But if you run in debug mode, you will see all the work that it has done, which is neat. So it translates itself or at least it helps. It finally has the ability to monitor itself. So it can generate the usage metrics, so you can monitor the usage of the server using Prometheus and Grafana. These are tools to do monitoring that are very popular. Inside the software, there is really just a few packages, so it's very lightweight. Most of the translation work is done by another package called Argos Translate. This is really the core engine that performs the hard work in the translation, which is an awesome project, and we collaborate with them on Libre Translate. Inside Argo Translate, there is also other software which is built on the shoulder of giants. C-Translate, which is an inference engine that does neural translation using transformers models, which is a state-of-the-art. It's the same type of architecture that chatGPT3 uses. There is a sentence piece, which is a piece of code from Google that does the word tokenization and the stanza which comes out of Stanford, which does a sentence analysis. Argos Translate uses all these three to perform the translation work. Now, that's not all it does. Argos Translate also takes care of the very important Argos package manager index. This is where all the language models are handled, installed, and distributed. So the first time that you run Libre Translate, Argos Translate will take care of querying the Argos package manager index, and will download the languages that you need. This allows us to also create instances where, say, you only need to translate between French and English. You do not need to download the entire 26 gigabytes of models. You can simply say, I just need those two models, and the program will download simply those two models. We also have a small module that does the file translation which connects again to Argos Translate. That's the Argos Translate files package, and then some common Python packages that allow us to put the web interface and coordinate the application as a whole. So it's really an ecosystem that's built with other open source software, and together it creates this complete translation solution. Talking about language models, we have 58 of them that gives you translation support for about 30 languages. It does automatic pivot via English. We are currently looking to transition to using multi-language models. But for the moment when you translate, say, from Italian to French, the program will automatically do the pivoting via English. So I will translate Italian to English and English to French. If there is a language missing, there is a very cool repository under the Argos OpenTech organization, which builds Argos Translate called Argos Train. That is a repository that has very good instructions on how you can train your own models. So if a language is missing, go check it out. It has very clear instructions, and you could contribute a language that is missing and you want to see integrated into the software. Speaking of the models, when a model is downloaded, it has a Argos model extension, and these are simply zip files. It's a zip file and it's inside, has a little bit of metadata. It has a folder that contains the CTranslate model. It has the sentence piece model and finally the stanza model. So it has the information for all the three packages that we discussed earlier to perform the translation. It's very interesting to check it out. Let's talk a little bit of accuracy, right? Like the question like, okay, it's a translation sorry, but how good is it really? For that, there is a metric that can be used to assess roughly the accuracy of the translation. It's called a Blue Score acronym for bilingual evaluation under study. It measures the similarity of text to a reference corpus. It has values that go from 0 to 1, or if you express it as a percentage from 0 to 100. The best translators in the world, human translators do not get a score of 100 ever. So anything that is above a 40 is considered understandable to good. Something that is above 50 tends to be very high quality. Sorry, up to 50 is high quality and above 60 is very high. We had a community contributor actually go and a few weeks ago, he ran the evaluation on our different models, and we found that 83 percent of the models currently in Libre Translate are scoring above 40 percent. So 83 of them are good. Now, to make it into perspective, when people ask me directly how good is Libre Translate, I like to tell them that it's roughly as good as Google Translate was four years ago. So I want to make the expectations clear at this stage in the project that it is not as good as some of the proprietary alternatives. But we are improving and we will continue to improve. The way to improve it lies into mostly getting better training data. So as we find more and more sources of open data that can be used for translation, we include those into the training of the models and that results into better models. This is also an interesting point to note, is that because the project is open source and we have a way to train models, you can also train models that are specific to a certain domain. For example, in the context of software translation, you could imagine the case where instead of training the data on a general corpus like Wikipedia or the EU Parliament translation documents, you could train a model that is specific to software. For example, you could take a set of existing translations from existing software that has licensed the translation work under an open permissible license and train a model onto those existing translations. Because we have the knowledge, a lot of software has commonalities in terms. When you have a file menu, it's always called file and then edit. So those menus are specific to a context. By training models that are specific to a context, you could get, for example, software translation model that is more accurate in the context of software, rather than say poetry. So it's a very interesting thing to think about. One more thing about accuracy, we do have the occasional rare quirk. This is something that we are aware of and we are working to fix it. We like to call it the salad issue. We joke, I will demonstrate this slide because it always sparks a little bit of a giggle. It's a little bit rare, but it happens. So in Spanish, the word for salad is ensalada. Now, let's try to translate the word for salads plural. So I'm going to type ensaladas. So in French, that's saladas. Is that correct? Any French people in the room? Fantastic. Now let's try the singular form. I'm going to remove the S and it crunches for a little bit. In a second, it really likes salad. Salad, salad, salad, salad, salad. This is a quirk. We are aware of it. It's very rare, but we've found a few reports here and there and we're working to fix it. Just something to be aware of. Yes, it really likes salad. Me too. Let's talk a little bit about integrations. You can find the client libraries for about 11 programming languages that includes the most common ones like Java, Python, whatever your favorite language is, it's probably in the list of bindings. And if it's not there, adding new bindings for LibreTranslate is fairly easy. So we welcome contributions, of course. As far as software, LibreTranslate has found adoption in several existing open-source software that you may recognize. Mastodon recently added support for translating topics using LibreTranslate. Weblate has the ability to use LibreTranslate to suggest and help translators perform translations as an alternative to using proprietary software. The forum software discourse has a plugin that lets you make your forum software accessible from different locales and lets you translate the posts on the fly. LibreOffice, I found, has an extension. I didn't know this until a week ago when I was looking who has integrated stuff with LibreTranslate. But somebody wrote an extension to LibreOffice where you can translate documents on the fly using LibreTranslate. There is an add-on for the multimedia software code. There is an add-on also for Firefox. And there's probably a lot of other things that I haven't found myself. But a lot of people seem to be finding the API useful and they're doing integration work, which is fantastic. And there's finally client applications that you can use LibreTranslate with without using the web UI. And we found we have clients for Android, iOS and desktop. And there's more being built by the week. As far as comparison to proprietary alternatives, you can see that there is a clear monetary advantage, aside from the philosophical reason for why you might want to use open-source software, of course. But it could also be a really sustainable way to perform translations in that people often ask me, why should I use LibreTranslate? I can use Google Translate for free. I just go on translate.google.com and it doesn't charge me anything. So why should I care? Google Translate is free so long as you're using it by hand. If you want to do any automation work and you have to tap into their API, you're going to pay dearly. And you can see here a list of the prices and I can assure you that one million characters seem like a lot, that's six zeros, but they actually run pretty fast and so could the bill on your credit card. So if you have a lot of text to translate, LibreTranslate could really help in that regard. As far as funding goes, the project is on the path to become fully self-funded. And we really care about this because we want the project to continue living on. We, of course, accept sponsorships and donations, but honestly, we would rather prefer that you get something back if you decide to contribute financially to the project. This is why if you are in the position where you say, I have some finances to spare and help support the project, you also get something back and we do that in the form of offering you an API key to use a host distance at LibreTranslate.com. So you are free to run the infrastructure on your own server, on your Raspberry Pi, on any machine that you'd like. If you don't want to handle that, you can just get an API key and you can support the project at the same time. So it's really a good way to contribute back. And we found that that model has been helping us grow and sustain the project. So we hope to continue growing as much next year. Again, to get involved, I'll give you a few quick numbers. We've had about 70 people contribute to the code base over the last few years. The project is still very young, but it has really received a lot of attention, so we're very excited about that. You can help with code. If you're a Python programmer, if you know HTML, CSS, any of the technologies that we use, you're welcome to contribute. We are open to everybody and all ideas. You can also help us translate. If you understand English and you don't see your language in the list of languages that we currently support for your user interface, you are welcome to contribute. It's on a web late, you can simply translate and it will get included into the project every 24 hours. So that is really amazing. You can also help us train more language models. If your language is not available or a language that you care about is not available, you can yourself create a new model for a language and add that into the list. So that is also another way that people can help. You can report bugs, of course. If you don't report salad, we are aware of it. Or just come say hi. We have a community forum that is quickly growing and we love to hear what you're building with it, what you're using, or if you have any questions. So we're very, very open and we're excited to hear what you will do with it. That said, this was the last slide. I think we have some time left over, right? So I will. So thank you very much. I will open the floor for questions and discussion. So yes. Hi, my best friend cannot miss the Vice President of the Austrian Society for Artificial Intelligence sitting with Foster to find volunteers to do exactly what you're doing. Thank you. We're glad to be able to help. You're welcome. How do we find, well, I just named the thing Open Language Model Training Army. How do we find more volunteers? Unemployed people, maybe have the government fund people running training models, maybe suggest that to all politicians, everybody to their member of parliament. How many people do we have here? Should be all of Europe at least, maybe South America. I think if we multiply this, it can go viral. Thank you very much. This is awesome work. Thank you. I appreciate it. Yes, but you speak of our language that have the same link, the same structure of the language. We have French, English, Spanish, Portuguese, maybe Russian and Ukrainian. I do not have the same structure, but the language not far away from here. That's the difference. German also. Correct. And so taking this in account, it's not easy for a translator, for them to translate it. It is not. There's also maybe a problem with Chinese or Japanese. Correct. There was a problem, there was a thing I went to say, it's a dictionary in line or in the program to have the good word because it's not translated every time the good word. And so I thought also the most efficient people's language is Esperanto, not English. Oh, that is very interesting. Yes. Okay. Yeah, that's a great insight. Yeah, thank you for sharing that. And you're completely right, some languages don't share the same semantical structure and Dutch, for example, currently doesn't score super high. It's actually one of the bottom 17% of the language models in the blue score. Dutch scored around 38%. So it's almost good, but we've had some Dutch speaking people come to us and say, you know, it's like equal use improvement. So Dutch, yes, it is a language that needs improvement. And I talked to the maintainer of Argus translate about the languages that need improvement. And he pretty much suggested that better training data will help greatly. So it is mainly a problem, not of the architecture of the AI. It's a matter that we don't have sufficient quality, high quality data between, say, English and Dutch to get above 38% currently. But again, nobody has really focused on Dutch as a language. If anybody has an interest in improving Dutch, we can do better. Surprisingly, fantastic. But as far as, for example, languages like German, LibreTranslate currently does very well with German. It's above 50, if I remember correctly. Is it because German is the similar language to Dutch? It is. That is because I believe, and I think PJ, that's the name of the maintainer of Argus translate, because the German model has had a larger amount of training data, and so it tends to perform better. Yes? Yeah, just a quick question around the translation process, I suppose, touched on the structure. But how does it work with different dialects? So if you write in dialects, will you write in slang? That's a very good question. Dialects would probably, and that's my guess, because I've never inquired this myself, but I believe that a dialect to perform good as a target or source language for translation would also need its fair amount of training data. And that is the problem with dialects. I actually speak a local Italian dialect, that is my first language, and I wanted to make a model for my dialect. And I started looking online for references of data that I could use to create a model for my dialect, because it would be cool. And it was really challenging. Not being an official language, it really lacks the status of official languages, and finding training data is extremely difficult. But it could be possible, right? If you gather enough people that can create a ground truth data set of examples in the dialect with sufficient samples, you could get good results, I believe. So it's a matter, again, of training data. Yes? How much does it cost to get a model to a good level? In terms of computing power or in terms of computing power? So if I remember correctly what PJ told me about the cost of training the models, it costs maybe a few, between $12 and $30. You can rent instances on several cloud providers. You do need a GPU to train these models, and it might take a few days for it to crunch and get sufficient number of iterations to train the model. But it's absolutely affordable. Anybody can do it, and if you are willing to wait and you just have a gaming laptop sitting at home, if you're OK waiting 20 days for it to finish, it will train the model for you. So I guess it could be free to you if you're willing to wait a sufficient amount of time, and if you have a gaming laptop lying around. Yes? So you mentioned the need for a data availability for doing the model, right? Well, do you need the data to be available under a certain license? What's your problem? The world's full of things, right? Yes. What's the requirement you have? You want it to be public domain? It has to be licensed under a permissive license, so creative comments that also includes commercial use. And we give references and we give attribution to all the sources that we use. If you go into the Argos Package Manager repository, where all the models are hosted, we do give the appropriate licensing credits to all those. But yes, we cannot go on, say, the Internet and start scraping results, because everything, you just have to assume that everything is covered by copyright until they tell you that you can use it freely. So it's only trained on openly available and freely licensed sources. Do you need it to be translated as well or just a single language? It has to be translated. So very briefly, the format of the input that goes into the training is a file that has, say, the English sentences and a separate file that has the translation on the same line. So it's very basic. And somebody could do the work by hand, right? You start from the English translation and you start doing the translation. So it will take a lot of work, but it's doable, especially in a crowd-formed... Are we out of time? Okay. I'll be around if you have other questions. Our time is up, unfortunately. They're kicking me out. But the next speaker will deliver something awesome as well next talk. Thank you again.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.44, "text": " So let's dive right into it.", "tokens": [407, 718, 311, 9192, 558, 666, 309, 13], "temperature": 0.0, "avg_logprob": -0.2490172429915962, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.10287223756313324}, {"id": 1, "seek": 0, "start": 7.44, "end": 11.84, "text": " LibreTranslate is a software that's a bit like Google Translate,", "tokens": [15834, 265, 33339, 17593, 307, 257, 4722, 300, 311, 257, 857, 411, 3329, 6531, 17593, 11], "temperature": 0.0, "avg_logprob": -0.2490172429915962, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.10287223756313324}, {"id": 2, "seek": 0, "start": 11.84, "end": 15.200000000000001, "text": " but open-source. It is AGPL3 license,", "tokens": [457, 1269, 12, 41676, 13, 467, 307, 28406, 21593, 18, 10476, 11], "temperature": 0.0, "avg_logprob": -0.2490172429915962, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.10287223756313324}, {"id": 3, "seek": 0, "start": 15.200000000000001, "end": 17.04, "text": " so it's a strongly open-source.", "tokens": [370, 309, 311, 257, 10613, 1269, 12, 41676, 13], "temperature": 0.0, "avg_logprob": -0.2490172429915962, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.10287223756313324}, {"id": 4, "seek": 0, "start": 17.04, "end": 19.96, "text": " In fact, we're going to keep it that way forever,", "tokens": [682, 1186, 11, 321, 434, 516, 281, 1066, 309, 300, 636, 5680, 11], "temperature": 0.0, "avg_logprob": -0.2490172429915962, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.10287223756313324}, {"id": 5, "seek": 0, "start": 19.96, "end": 22.84, "text": " and let's you do natural language translation.", "tokens": [293, 718, 311, 291, 360, 3303, 2856, 12853, 13], "temperature": 0.0, "avg_logprob": -0.2490172429915962, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.10287223756313324}, {"id": 6, "seek": 0, "start": 22.84, "end": 25.44, "text": " It runs on your computer.", "tokens": [467, 6676, 322, 428, 3820, 13], "temperature": 0.0, "avg_logprob": -0.2490172429915962, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.10287223756313324}, {"id": 7, "seek": 0, "start": 25.44, "end": 27.240000000000002, "text": " This is one of the goals of the project.", "tokens": [639, 307, 472, 295, 264, 5493, 295, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.2490172429915962, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.10287223756313324}, {"id": 8, "seek": 0, "start": 27.240000000000002, "end": 29.44, "text": " There are several other projects in", "tokens": [821, 366, 2940, 661, 4455, 294], "temperature": 0.0, "avg_logprob": -0.2490172429915962, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.10287223756313324}, {"id": 9, "seek": 2944, "start": 29.44, "end": 31.520000000000003, "text": " the open-source realm that have aimed to", "tokens": [264, 1269, 12, 41676, 15355, 300, 362, 20540, 281], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 10, "seek": 2944, "start": 31.520000000000003, "end": 34.800000000000004, "text": " provide natural language translation,", "tokens": [2893, 3303, 2856, 12853, 11], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 11, "seek": 2944, "start": 34.800000000000004, "end": 37.04, "text": " except sometimes that they require", "tokens": [3993, 2171, 300, 436, 3651], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 12, "seek": 2944, "start": 37.04, "end": 39.160000000000004, "text": " a very large servers or a lot of memory,", "tokens": [257, 588, 2416, 15909, 420, 257, 688, 295, 4675, 11], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 13, "seek": 2944, "start": 39.160000000000004, "end": 41.44, "text": " and our goal is to have this running on", "tokens": [293, 527, 3387, 307, 281, 362, 341, 2614, 322], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 14, "seek": 2944, "start": 41.44, "end": 42.84, "text": " something as low as a Raspberry Pi.", "tokens": [746, 382, 2295, 382, 257, 41154, 17741, 13], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 15, "seek": 2944, "start": 42.84, "end": 45.56, "text": " So that is very important to the project.", "tokens": [407, 300, 307, 588, 1021, 281, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 16, "seek": 2944, "start": 45.56, "end": 49.44, "text": " The program has lots of clients and integrations.", "tokens": [440, 1461, 575, 3195, 295, 6982, 293, 3572, 763, 13], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 17, "seek": 2944, "start": 49.44, "end": 52.92, "text": " We'll cover some of those in the upcoming slides.", "tokens": [492, 603, 2060, 512, 295, 729, 294, 264, 11500, 9788, 13], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 18, "seek": 2944, "start": 52.92, "end": 55.84, "text": " Like many projects, it's available on GitHub,", "tokens": [1743, 867, 4455, 11, 309, 311, 2435, 322, 23331, 11], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 19, "seek": 2944, "start": 55.84, "end": 58.08, "text": " so you can go and check it out.", "tokens": [370, 291, 393, 352, 293, 1520, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.17461515474720163, "compression_ratio": 1.601423487544484, "no_speech_prob": 0.00010510534775676206}, {"id": 20, "seek": 5808, "start": 58.08, "end": 60.64, "text": " But we're going to give you today a brief overview of", "tokens": [583, 321, 434, 516, 281, 976, 291, 965, 257, 5353, 12492, 295], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 21, "seek": 5808, "start": 60.64, "end": 63.92, "text": " how to get started and start using it today.", "tokens": [577, 281, 483, 1409, 293, 722, 1228, 309, 965, 13], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 22, "seek": 5808, "start": 63.92, "end": 67.6, "text": " Let's talk briefly about why we decided to create it,", "tokens": [961, 311, 751, 10515, 466, 983, 321, 3047, 281, 1884, 309, 11], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 23, "seek": 5808, "start": 67.6, "end": 70.4, "text": " and there was a need for the project to exist.", "tokens": [293, 456, 390, 257, 643, 337, 264, 1716, 281, 2514, 13], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 24, "seek": 5808, "start": 70.4, "end": 73.56, "text": " We could not find a project that had", "tokens": [492, 727, 406, 915, 257, 1716, 300, 632], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 25, "seek": 5808, "start": 73.56, "end": 76.4, "text": " all the variables that LibreTranslate can offer.", "tokens": [439, 264, 9102, 300, 15834, 265, 33339, 17593, 393, 2626, 13], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 26, "seek": 5808, "start": 76.4, "end": 79.48, "text": " These are a simple and open-res API that you can", "tokens": [1981, 366, 257, 2199, 293, 1269, 12, 495, 9362, 300, 291, 393], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 27, "seek": 5808, "start": 79.48, "end": 81.96, "text": " use to programmatically do translations,", "tokens": [764, 281, 37648, 5030, 360, 37578, 11], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 28, "seek": 5808, "start": 81.96, "end": 84.0, "text": " so help automate part of", "tokens": [370, 854, 31605, 644, 295], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 29, "seek": 5808, "start": 84.0, "end": 87.75999999999999, "text": " the translation work that we need for the work.", "tokens": [264, 12853, 589, 300, 321, 643, 337, 264, 589, 13], "temperature": 0.0, "avg_logprob": -0.1563882350921631, "compression_ratio": 1.6531365313653137, "no_speech_prob": 3.3664102375041693e-05}, {"id": 30, "seek": 8776, "start": 87.76, "end": 92.60000000000001, "text": " It offers pre-trained and openly licensed language models.", "tokens": [467, 7736, 659, 12, 17227, 2001, 293, 23109, 25225, 2856, 5245, 13], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 31, "seek": 8776, "start": 92.60000000000001, "end": 95.72, "text": " There are other projects that do machine translation,", "tokens": [821, 366, 661, 4455, 300, 360, 3479, 12853, 11], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 32, "seek": 8776, "start": 95.72, "end": 97.60000000000001, "text": " but again, sometimes they do not make", "tokens": [457, 797, 11, 2171, 436, 360, 406, 652], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 33, "seek": 8776, "start": 97.60000000000001, "end": 101.88000000000001, "text": " the AI models for the translation openly available,", "tokens": [264, 7318, 5245, 337, 264, 12853, 23109, 2435, 11], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 34, "seek": 8776, "start": 101.88000000000001, "end": 103.2, "text": " and we have that.", "tokens": [293, 321, 362, 300, 13], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 35, "seek": 8776, "start": 103.2, "end": 105.92, "text": " Finally, it runs again on commodity hardware,", "tokens": [6288, 11, 309, 6676, 797, 322, 29125, 8837, 11], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 36, "seek": 8776, "start": 105.92, "end": 108.32000000000001, "text": " so it does now require server-scale power", "tokens": [370, 309, 775, 586, 3651, 7154, 12, 20033, 1347], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 37, "seek": 8776, "start": 108.32000000000001, "end": 110.12, "text": " to make the software work,", "tokens": [281, 652, 264, 4722, 589, 11], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 38, "seek": 8776, "start": 110.12, "end": 113.92, "text": " and finally, it is very easy to get started as you will see.", "tokens": [293, 2721, 11, 309, 307, 588, 1858, 281, 483, 1409, 382, 291, 486, 536, 13], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 39, "seek": 8776, "start": 113.92, "end": 116.60000000000001, "text": " So talking about getting started,", "tokens": [407, 1417, 466, 1242, 1409, 11], "temperature": 0.0, "avg_logprob": -0.1830866900357333, "compression_ratio": 1.6412213740458015, "no_speech_prob": 3.819151606876403e-05}, {"id": 40, "seek": 11660, "start": 116.6, "end": 118.6, "text": " there are primarily two ways that you can", "tokens": [456, 366, 10029, 732, 2098, 300, 291, 393], "temperature": 0.0, "avg_logprob": -0.1323144649102436, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.9024802137864754e-05}, {"id": 41, "seek": 11660, "start": 118.6, "end": 120.91999999999999, "text": " get LibreTranslate to work on your computer.", "tokens": [483, 15834, 265, 33339, 17593, 281, 589, 322, 428, 3820, 13], "temperature": 0.0, "avg_logprob": -0.1323144649102436, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.9024802137864754e-05}, {"id": 42, "seek": 11660, "start": 120.91999999999999, "end": 123.19999999999999, "text": " The first one is if you have Python,", "tokens": [440, 700, 472, 307, 498, 291, 362, 15329, 11], "temperature": 0.0, "avg_logprob": -0.1323144649102436, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.9024802137864754e-05}, {"id": 43, "seek": 11660, "start": 123.19999999999999, "end": 126.6, "text": " you can simply run a pip install command,", "tokens": [291, 393, 2935, 1190, 257, 8489, 3625, 5622, 11], "temperature": 0.0, "avg_logprob": -0.1323144649102436, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.9024802137864754e-05}, {"id": 44, "seek": 11660, "start": 126.6, "end": 131.35999999999999, "text": " LibreTranslate, and afterwards you run the program, and that's it.", "tokens": [15834, 265, 33339, 17593, 11, 293, 10543, 291, 1190, 264, 1461, 11, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.1323144649102436, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.9024802137864754e-05}, {"id": 45, "seek": 11660, "start": 131.35999999999999, "end": 134.84, "text": " If you have Docker, which many developers like to use,", "tokens": [759, 291, 362, 33772, 11, 597, 867, 8849, 411, 281, 764, 11], "temperature": 0.0, "avg_logprob": -0.1323144649102436, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.9024802137864754e-05}, {"id": 46, "seek": 11660, "start": 134.84, "end": 136.07999999999998, "text": " we also have an option for that.", "tokens": [321, 611, 362, 364, 3614, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.1323144649102436, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.9024802137864754e-05}, {"id": 47, "seek": 11660, "start": 136.07999999999998, "end": 140.12, "text": " We pre-build images for LibreTranslate that you can use,", "tokens": [492, 659, 12, 11516, 5267, 337, 15834, 265, 33339, 17593, 300, 291, 393, 764, 11], "temperature": 0.0, "avg_logprob": -0.1323144649102436, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.9024802137864754e-05}, {"id": 48, "seek": 11660, "start": 140.12, "end": 144.68, "text": " and we have a convenient script that will run it for you and take", "tokens": [293, 321, 362, 257, 10851, 5755, 300, 486, 1190, 309, 337, 291, 293, 747], "temperature": 0.0, "avg_logprob": -0.1323144649102436, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.9024802137864754e-05}, {"id": 49, "seek": 14468, "start": 144.68, "end": 147.68, "text": " care of a few details that let you have things like", "tokens": [1127, 295, 257, 1326, 4365, 300, 718, 291, 362, 721, 411], "temperature": 0.0, "avg_logprob": -0.1519936857552364, "compression_ratio": 1.5927272727272728, "no_speech_prob": 5.643026452162303e-05}, {"id": 50, "seek": 14468, "start": 147.68, "end": 151.64000000000001, "text": " persistent volumes for downloading language models and some technical stuff.", "tokens": [24315, 22219, 337, 32529, 2856, 5245, 293, 512, 6191, 1507, 13], "temperature": 0.0, "avg_logprob": -0.1519936857552364, "compression_ratio": 1.5927272727272728, "no_speech_prob": 5.643026452162303e-05}, {"id": 51, "seek": 14468, "start": 151.64000000000001, "end": 154.8, "text": " But to get started, all you need to do is go on GitHub,", "tokens": [583, 281, 483, 1409, 11, 439, 291, 643, 281, 360, 307, 352, 322, 23331, 11], "temperature": 0.0, "avg_logprob": -0.1519936857552364, "compression_ratio": 1.5927272727272728, "no_speech_prob": 5.643026452162303e-05}, {"id": 52, "seek": 14468, "start": 154.8, "end": 159.24, "text": " get a copy of our source code, and press Run.", "tokens": [483, 257, 5055, 295, 527, 4009, 3089, 11, 293, 1886, 8950, 13], "temperature": 0.0, "avg_logprob": -0.1519936857552364, "compression_ratio": 1.5927272727272728, "no_speech_prob": 5.643026452162303e-05}, {"id": 53, "seek": 14468, "start": 159.24, "end": 163.92000000000002, "text": " We also have scripts for Windows and Mac OS and Linux,", "tokens": [492, 611, 362, 23294, 337, 8591, 293, 5707, 12731, 293, 18734, 11], "temperature": 0.0, "avg_logprob": -0.1519936857552364, "compression_ratio": 1.5927272727272728, "no_speech_prob": 5.643026452162303e-05}, {"id": 54, "seek": 14468, "start": 163.92000000000002, "end": 166.56, "text": " so we try to support all major platforms.", "tokens": [370, 321, 853, 281, 1406, 439, 2563, 9473, 13], "temperature": 0.0, "avg_logprob": -0.1519936857552364, "compression_ratio": 1.5927272727272728, "no_speech_prob": 5.643026452162303e-05}, {"id": 55, "seek": 14468, "start": 166.56, "end": 169.24, "text": " We're hoping to get other platforms in there as well,", "tokens": [492, 434, 7159, 281, 483, 661, 9473, 294, 456, 382, 731, 11], "temperature": 0.0, "avg_logprob": -0.1519936857552364, "compression_ratio": 1.5927272727272728, "no_speech_prob": 5.643026452162303e-05}, {"id": 56, "seek": 14468, "start": 169.24, "end": 173.96, "text": " so things like FreeBSD and others are on the to-do list.", "tokens": [370, 721, 411, 11551, 8176, 35, 293, 2357, 366, 322, 264, 281, 12, 2595, 1329, 13], "temperature": 0.0, "avg_logprob": -0.1519936857552364, "compression_ratio": 1.5927272727272728, "no_speech_prob": 5.643026452162303e-05}, {"id": 57, "seek": 17396, "start": 173.96, "end": 175.68, "text": " So we'll get there.", "tokens": [407, 321, 603, 483, 456, 13], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 58, "seek": 17396, "start": 175.68, "end": 178.28, "text": " So let's actually try to run it,", "tokens": [407, 718, 311, 767, 853, 281, 1190, 309, 11], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 59, "seek": 17396, "start": 178.28, "end": 181.36, "text": " and I'm always a little scared of doing live demos,", "tokens": [293, 286, 478, 1009, 257, 707, 5338, 295, 884, 1621, 33788, 11], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 60, "seek": 17396, "start": 181.36, "end": 183.92000000000002, "text": " but bear with me, we're going to try it.", "tokens": [457, 6155, 365, 385, 11, 321, 434, 516, 281, 853, 309, 13], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 61, "seek": 17396, "start": 183.92000000000002, "end": 185.8, "text": " What could go wrong?", "tokens": [708, 727, 352, 2085, 30], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 62, "seek": 17396, "start": 185.8, "end": 188.92000000000002, "text": " So here is a console.", "tokens": [407, 510, 307, 257, 11076, 13], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 63, "seek": 17396, "start": 188.92000000000002, "end": 191.24, "text": " I'm going to quickly activate", "tokens": [286, 478, 516, 281, 2661, 13615], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 64, "seek": 17396, "start": 191.24, "end": 194.76000000000002, "text": " a Python environment where I have LibreTranslate already installed,", "tokens": [257, 15329, 2823, 689, 286, 362, 15834, 265, 33339, 17593, 1217, 8899, 11], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 65, "seek": 17396, "start": 194.76000000000002, "end": 196.72, "text": " and I'm going to try to run it.", "tokens": [293, 286, 478, 516, 281, 853, 281, 1190, 309, 13], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 66, "seek": 17396, "start": 196.72, "end": 198.64000000000001, "text": " On Mac OS, I have to specify", "tokens": [1282, 5707, 12731, 11, 286, 362, 281, 16500], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 67, "seek": 17396, "start": 198.64000000000001, "end": 201.84, "text": " a different port than the default of 5,000.", "tokens": [257, 819, 2436, 813, 264, 7576, 295, 1025, 11, 1360, 13], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 68, "seek": 17396, "start": 201.84, "end": 203.20000000000002, "text": " I'm going to try to run it.", "tokens": [286, 478, 516, 281, 853, 281, 1190, 309, 13], "temperature": 0.0, "avg_logprob": -0.2102878255055363, "compression_ratio": 1.6303501945525292, "no_speech_prob": 1.8909275240730494e-05}, {"id": 69, "seek": 20320, "start": 203.2, "end": 205.0, "text": " Okay, it seems to be working.", "tokens": [1033, 11, 309, 2544, 281, 312, 1364, 13], "temperature": 0.0, "avg_logprob": -0.15526073950308342, "compression_ratio": 1.5826446280991735, "no_speech_prob": 2.1434449081425555e-05}, {"id": 70, "seek": 20320, "start": 205.0, "end": 209.39999999999998, "text": " So I'm going to jump back right into Chrome,", "tokens": [407, 286, 478, 516, 281, 3012, 646, 558, 666, 15327, 11], "temperature": 0.0, "avg_logprob": -0.15526073950308342, "compression_ratio": 1.5826446280991735, "no_speech_prob": 2.1434449081425555e-05}, {"id": 71, "seek": 20320, "start": 209.39999999999998, "end": 212.28, "text": " and if I refresh the page,", "tokens": [293, 498, 286, 15134, 264, 3028, 11], "temperature": 0.0, "avg_logprob": -0.15526073950308342, "compression_ratio": 1.5826446280991735, "no_speech_prob": 2.1434449081425555e-05}, {"id": 72, "seek": 20320, "start": 212.28, "end": 215.88, "text": " you will be presented with a friendly user interface that you can use", "tokens": [291, 486, 312, 8212, 365, 257, 9208, 4195, 9226, 300, 291, 393, 764], "temperature": 0.0, "avg_logprob": -0.15526073950308342, "compression_ratio": 1.5826446280991735, "no_speech_prob": 2.1434449081425555e-05}, {"id": 73, "seek": 20320, "start": 215.88, "end": 218.92, "text": " to test the system and even use it.", "tokens": [281, 1500, 264, 1185, 293, 754, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.15526073950308342, "compression_ratio": 1.5826446280991735, "no_speech_prob": 2.1434449081425555e-05}, {"id": 74, "seek": 20320, "start": 218.92, "end": 223.79999999999998, "text": " It allows programmatic access to the software via an API,", "tokens": [467, 4045, 1461, 25915, 2105, 281, 264, 4722, 5766, 364, 9362, 11], "temperature": 0.0, "avg_logprob": -0.15526073950308342, "compression_ratio": 1.5826446280991735, "no_speech_prob": 2.1434449081425555e-05}, {"id": 75, "seek": 20320, "start": 223.79999999999998, "end": 225.28, "text": " but you can also use it as", "tokens": [457, 291, 393, 611, 764, 309, 382], "temperature": 0.0, "avg_logprob": -0.15526073950308342, "compression_ratio": 1.5826446280991735, "no_speech_prob": 2.1434449081425555e-05}, {"id": 76, "seek": 20320, "start": 225.28, "end": 227.67999999999998, "text": " an alternative to Google Translate if you want to.", "tokens": [364, 8535, 281, 3329, 6531, 17593, 498, 291, 528, 281, 13], "temperature": 0.0, "avg_logprob": -0.15526073950308342, "compression_ratio": 1.5826446280991735, "no_speech_prob": 2.1434449081425555e-05}, {"id": 77, "seek": 20320, "start": 227.67999999999998, "end": 231.72, "text": " So we're going to try to say something.", "tokens": [407, 321, 434, 516, 281, 853, 281, 584, 746, 13], "temperature": 0.0, "avg_logprob": -0.15526073950308342, "compression_ratio": 1.5826446280991735, "no_speech_prob": 2.1434449081425555e-05}, {"id": 78, "seek": 23172, "start": 231.72, "end": 235.72, "text": " Okay, so obviously English to English is not going to be helpful.", "tokens": [1033, 11, 370, 2745, 3669, 281, 3669, 307, 406, 516, 281, 312, 4961, 13], "temperature": 0.0, "avg_logprob": -0.25320252312554253, "compression_ratio": 1.519047619047619, "no_speech_prob": 7.351046951953322e-05}, {"id": 79, "seek": 23172, "start": 235.72, "end": 237.35999999999999, "text": " How about French?", "tokens": [1012, 466, 5522, 30], "temperature": 0.0, "avg_logprob": -0.25320252312554253, "compression_ratio": 1.519047619047619, "no_speech_prob": 7.351046951953322e-05}, {"id": 80, "seek": 23172, "start": 237.35999999999999, "end": 240.76, "text": " Okay. So we translated Hello World,", "tokens": [1033, 13, 407, 321, 16805, 2425, 3937, 11], "temperature": 0.0, "avg_logprob": -0.25320252312554253, "compression_ratio": 1.519047619047619, "no_speech_prob": 7.351046951953322e-05}, {"id": 81, "seek": 23172, "start": 240.76, "end": 244.88, "text": " Bonjour Le Monde, and it worked.", "tokens": [25431, 1456, 376, 7259, 11, 293, 309, 2732, 13], "temperature": 0.0, "avg_logprob": -0.25320252312554253, "compression_ratio": 1.519047619047619, "no_speech_prob": 7.351046951953322e-05}, {"id": 82, "seek": 23172, "start": 244.88, "end": 247.76, "text": " But that's not too impressive, right?", "tokens": [583, 300, 311, 406, 886, 8992, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.25320252312554253, "compression_ratio": 1.519047619047619, "no_speech_prob": 7.351046951953322e-05}, {"id": 83, "seek": 23172, "start": 247.76, "end": 249.32, "text": " I'm like, okay, Hello World.", "tokens": [286, 478, 411, 11, 1392, 11, 2425, 3937, 13], "temperature": 0.0, "avg_logprob": -0.25320252312554253, "compression_ratio": 1.519047619047619, "no_speech_prob": 7.351046951953322e-05}, {"id": 84, "seek": 23172, "start": 249.32, "end": 254.32, "text": " Let's try to look at something a little more realistic.", "tokens": [961, 311, 853, 281, 574, 412, 746, 257, 707, 544, 12465, 13], "temperature": 0.0, "avg_logprob": -0.25320252312554253, "compression_ratio": 1.519047619047619, "no_speech_prob": 7.351046951953322e-05}, {"id": 85, "seek": 23172, "start": 256.64, "end": 259.04, "text": " Before looking at something more realistic,", "tokens": [4546, 1237, 412, 746, 544, 12465, 11], "temperature": 0.0, "avg_logprob": -0.25320252312554253, "compression_ratio": 1.519047619047619, "no_speech_prob": 7.351046951953322e-05}, {"id": 86, "seek": 25904, "start": 259.04, "end": 262.96000000000004, "text": " you can also, of course, use it from an API.", "tokens": [291, 393, 611, 11, 295, 1164, 11, 764, 309, 490, 364, 9362, 13], "temperature": 0.0, "avg_logprob": -0.2760767395963374, "compression_ratio": 1.566820276497696, "no_speech_prob": 3.53260911651887e-05}, {"id": 87, "seek": 25904, "start": 262.96000000000004, "end": 266.36, "text": " In this case, I can invoke a Cura command and", "tokens": [682, 341, 1389, 11, 286, 393, 41117, 257, 383, 2991, 5622, 293], "temperature": 0.0, "avg_logprob": -0.2760767395963374, "compression_ratio": 1.566820276497696, "no_speech_prob": 3.53260911651887e-05}, {"id": 88, "seek": 25904, "start": 266.36, "end": 269.52000000000004, "text": " ask Libre Translate to perform a translation.", "tokens": [1029, 15834, 265, 6531, 17593, 281, 2042, 257, 12853, 13], "temperature": 0.0, "avg_logprob": -0.2760767395963374, "compression_ratio": 1.566820276497696, "no_speech_prob": 3.53260911651887e-05}, {"id": 89, "seek": 25904, "start": 269.52000000000004, "end": 272.84000000000003, "text": " I wanted to automatically detect the language,", "tokens": [286, 1415, 281, 6772, 5531, 264, 2856, 11], "temperature": 0.0, "avg_logprob": -0.2760767395963374, "compression_ratio": 1.566820276497696, "no_speech_prob": 3.53260911651887e-05}, {"id": 90, "seek": 25904, "start": 272.84000000000003, "end": 274.72, "text": " where the translation is coming from,", "tokens": [689, 264, 12853, 307, 1348, 490, 11], "temperature": 0.0, "avg_logprob": -0.2760767395963374, "compression_ratio": 1.566820276497696, "no_speech_prob": 3.53260911651887e-05}, {"id": 91, "seek": 25904, "start": 274.72, "end": 278.08000000000004, "text": " and finally, I want to translate", "tokens": [293, 2721, 11, 286, 528, 281, 13799], "temperature": 0.0, "avg_logprob": -0.2760767395963374, "compression_ratio": 1.566820276497696, "no_speech_prob": 3.53260911651887e-05}, {"id": 92, "seek": 25904, "start": 278.08000000000004, "end": 282.8, "text": " into the target language.", "tokens": [666, 264, 3779, 2856, 13], "temperature": 0.0, "avg_logprob": -0.2760767395963374, "compression_ratio": 1.566820276497696, "no_speech_prob": 3.53260911651887e-05}, {"id": 93, "seek": 25904, "start": 282.8, "end": 284.8, "text": " I get a JSON response.", "tokens": [286, 483, 257, 31828, 4134, 13], "temperature": 0.0, "avg_logprob": -0.2760767395963374, "compression_ratio": 1.566820276497696, "no_speech_prob": 3.53260911651887e-05}, {"id": 94, "seek": 25904, "start": 284.8, "end": 287.24, "text": " Everything in the API is JSON-based.", "tokens": [5471, 294, 264, 9362, 307, 31828, 12, 6032, 13], "temperature": 0.0, "avg_logprob": -0.2760767395963374, "compression_ratio": 1.566820276497696, "no_speech_prob": 3.53260911651887e-05}, {"id": 95, "seek": 28724, "start": 287.24, "end": 290.32, "text": " So that will be familiar with many developers.", "tokens": [407, 300, 486, 312, 4963, 365, 867, 8849, 13], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 96, "seek": 28724, "start": 290.32, "end": 293.36, "text": " But let's look at a more realistic example.", "tokens": [583, 718, 311, 574, 412, 257, 544, 12465, 1365, 13], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 97, "seek": 28724, "start": 293.36, "end": 295.92, "text": " In this case, we have a longer piece of text,", "tokens": [682, 341, 1389, 11, 321, 362, 257, 2854, 2522, 295, 2487, 11], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 98, "seek": 28724, "start": 295.92, "end": 299.04, "text": " and it also contains HTML.", "tokens": [293, 309, 611, 8306, 17995, 13], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 99, "seek": 28724, "start": 299.04, "end": 302.08, "text": " The software is capable of translating", "tokens": [440, 4722, 307, 8189, 295, 35030], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 100, "seek": 28724, "start": 302.08, "end": 303.72, "text": " the parts that need translation while", "tokens": [264, 3166, 300, 643, 12853, 1339], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 101, "seek": 28724, "start": 303.72, "end": 305.84000000000003, "text": " leaving the HTML part intact.", "tokens": [5012, 264, 17995, 644, 23493, 13], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 102, "seek": 28724, "start": 305.84000000000003, "end": 310.16, "text": " So things like hyperlinks do not get mistakenly translated,", "tokens": [407, 721, 411, 9848, 75, 16431, 360, 406, 483, 21333, 356, 16805, 11], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 103, "seek": 28724, "start": 310.16, "end": 313.2, "text": " which would be really bad.", "tokens": [597, 576, 312, 534, 1578, 13], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 104, "seek": 28724, "start": 313.2, "end": 316.76, "text": " This code that we saw here roughly gets", "tokens": [639, 3089, 300, 321, 1866, 510, 9810, 2170], "temperature": 0.0, "avg_logprob": -0.20117823894207293, "compression_ratio": 1.5691699604743083, "no_speech_prob": 1.722716842778027e-05}, {"id": 105, "seek": 31676, "start": 316.76, "end": 321.28, "text": " represented as this piece of HTML in a browser,", "tokens": [10379, 382, 341, 2522, 295, 17995, 294, 257, 11185, 11], "temperature": 0.0, "avg_logprob": -0.19986594125126186, "compression_ratio": 1.5654205607476634, "no_speech_prob": 0.00010349840158596635}, {"id": 106, "seek": 31676, "start": 321.28, "end": 325.36, "text": " and the translation is pretty good.", "tokens": [293, 264, 12853, 307, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.19986594125126186, "compression_ratio": 1.5654205607476634, "no_speech_prob": 0.00010349840158596635}, {"id": 107, "seek": 31676, "start": 325.36, "end": 328.96, "text": " Kind of. This word should have been filidae.", "tokens": [9242, 295, 13, 639, 1349, 820, 362, 668, 1387, 2887, 68, 13], "temperature": 0.0, "avg_logprob": -0.19986594125126186, "compression_ratio": 1.5654205607476634, "no_speech_prob": 0.00010349840158596635}, {"id": 108, "seek": 31676, "start": 328.96, "end": 332.88, "text": " It decided to keep the translation in French.", "tokens": [467, 3047, 281, 1066, 264, 12853, 294, 5522, 13], "temperature": 0.0, "avg_logprob": -0.19986594125126186, "compression_ratio": 1.5654205607476634, "no_speech_prob": 0.00010349840158596635}, {"id": 109, "seek": 31676, "start": 332.88, "end": 336.08, "text": " We will improve that with time.", "tokens": [492, 486, 3470, 300, 365, 565, 13], "temperature": 0.0, "avg_logprob": -0.19986594125126186, "compression_ratio": 1.5654205607476634, "no_speech_prob": 0.00010349840158596635}, {"id": 110, "seek": 31676, "start": 336.08, "end": 338.96, "text": " But otherwise, the context and", "tokens": [583, 5911, 11, 264, 4319, 293], "temperature": 0.0, "avg_logprob": -0.19986594125126186, "compression_ratio": 1.5654205607476634, "no_speech_prob": 0.00010349840158596635}, {"id": 111, "seek": 31676, "start": 338.96, "end": 341.68, "text": " the meaning of the sentence is pretty darn good.", "tokens": [264, 3620, 295, 264, 8174, 307, 1238, 29063, 665, 13], "temperature": 0.0, "avg_logprob": -0.19986594125126186, "compression_ratio": 1.5654205607476634, "no_speech_prob": 0.00010349840158596635}, {"id": 112, "seek": 31676, "start": 341.68, "end": 345.24, "text": " We will look at accuracy in the upcoming slides.", "tokens": [492, 486, 574, 412, 14170, 294, 264, 11500, 9788, 13], "temperature": 0.0, "avg_logprob": -0.19986594125126186, "compression_ratio": 1.5654205607476634, "no_speech_prob": 0.00010349840158596635}, {"id": 113, "seek": 34524, "start": 345.24, "end": 349.32, "text": " So as an overview of the list of features,", "tokens": [407, 382, 364, 12492, 295, 264, 1329, 295, 4122, 11], "temperature": 0.0, "avg_logprob": -0.18165040267141241, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.00014571499195881188}, {"id": 114, "seek": 34524, "start": 349.32, "end": 350.92, "text": " it can do text translation,", "tokens": [309, 393, 360, 2487, 12853, 11], "temperature": 0.0, "avg_logprob": -0.18165040267141241, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.00014571499195881188}, {"id": 115, "seek": 34524, "start": 350.92, "end": 354.12, "text": " it can do markup translation that includes HTML,", "tokens": [309, 393, 360, 1491, 1010, 12853, 300, 5974, 17995, 11], "temperature": 0.0, "avg_logprob": -0.18165040267141241, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.00014571499195881188}, {"id": 116, "seek": 34524, "start": 354.12, "end": 357.48, "text": " XML, and other formats that use a markup.", "tokens": [43484, 11, 293, 661, 25879, 300, 764, 257, 1491, 1010, 13], "temperature": 0.0, "avg_logprob": -0.18165040267141241, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.00014571499195881188}, {"id": 117, "seek": 34524, "start": 357.48, "end": 361.52, "text": " It can do several formats for file translation.", "tokens": [467, 393, 360, 2940, 25879, 337, 3991, 12853, 13], "temperature": 0.0, "avg_logprob": -0.18165040267141241, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.00014571499195881188}, {"id": 118, "seek": 34524, "start": 361.52, "end": 363.76, "text": " So you can upload things like", "tokens": [407, 291, 393, 6580, 721, 411], "temperature": 0.0, "avg_logprob": -0.18165040267141241, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.00014571499195881188}, {"id": 119, "seek": 34524, "start": 363.76, "end": 366.0, "text": " open office, LibreOffice,", "tokens": [1269, 3398, 11, 15834, 265, 29745, 573, 11], "temperature": 0.0, "avg_logprob": -0.18165040267141241, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.00014571499195881188}, {"id": 120, "seek": 34524, "start": 366.0, "end": 370.24, "text": " Word documents, and PowerPoint slides,", "tokens": [8725, 8512, 11, 293, 25584, 9788, 11], "temperature": 0.0, "avg_logprob": -0.18165040267141241, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.00014571499195881188}, {"id": 121, "seek": 34524, "start": 370.24, "end": 373.08, "text": " and able to translate those as well.", "tokens": [293, 1075, 281, 13799, 729, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.18165040267141241, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.00014571499195881188}, {"id": 122, "seek": 37308, "start": 373.08, "end": 376.08, "text": " It can perform a language detection.", "tokens": [467, 393, 2042, 257, 2856, 17784, 13], "temperature": 0.0, "avg_logprob": -0.13648820373247256, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.00015256695041898638}, {"id": 123, "seek": 37308, "start": 376.08, "end": 378.2, "text": " So you give it a piece of text,", "tokens": [407, 291, 976, 309, 257, 2522, 295, 2487, 11], "temperature": 0.0, "avg_logprob": -0.13648820373247256, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.00015256695041898638}, {"id": 124, "seek": 37308, "start": 378.2, "end": 380.0, "text": " and it will give you", "tokens": [293, 309, 486, 976, 291], "temperature": 0.0, "avg_logprob": -0.13648820373247256, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.00015256695041898638}, {"id": 125, "seek": 37308, "start": 380.0, "end": 383.91999999999996, "text": " an estimate of which language the program thinks it is.", "tokens": [364, 12539, 295, 597, 2856, 264, 1461, 7309, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.13648820373247256, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.00015256695041898638}, {"id": 126, "seek": 37308, "start": 383.91999999999996, "end": 388.4, "text": " It also has a built-in system for doing rate limiting.", "tokens": [467, 611, 575, 257, 3094, 12, 259, 1185, 337, 884, 3314, 22083, 13], "temperature": 0.0, "avg_logprob": -0.13648820373247256, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.00015256695041898638}, {"id": 127, "seek": 37308, "start": 388.4, "end": 390.84, "text": " If you're planning to host this on a public server,", "tokens": [759, 291, 434, 5038, 281, 3975, 341, 322, 257, 1908, 7154, 11], "temperature": 0.0, "avg_logprob": -0.13648820373247256, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.00015256695041898638}, {"id": 128, "seek": 37308, "start": 390.84, "end": 392.91999999999996, "text": " you will find out that it's a very useful feature,", "tokens": [291, 486, 915, 484, 300, 309, 311, 257, 588, 4420, 4111, 11], "temperature": 0.0, "avg_logprob": -0.13648820373247256, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.00015256695041898638}, {"id": 129, "seek": 37308, "start": 392.91999999999996, "end": 397.4, "text": " because people really like free resources,", "tokens": [570, 561, 534, 411, 1737, 3593, 11], "temperature": 0.0, "avg_logprob": -0.13648820373247256, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.00015256695041898638}, {"id": 130, "seek": 37308, "start": 397.4, "end": 402.47999999999996, "text": " and it's difficult to give everything for free without", "tokens": [293, 309, 311, 2252, 281, 976, 1203, 337, 1737, 1553], "temperature": 0.0, "avg_logprob": -0.13648820373247256, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.00015256695041898638}, {"id": 131, "seek": 40248, "start": 402.48, "end": 406.84000000000003, "text": " some limits. So if your translation instance up in", "tokens": [512, 10406, 13, 407, 498, 428, 12853, 5197, 493, 294], "temperature": 0.0, "avg_logprob": -0.16125784568416263, "compression_ratio": 1.6788617886178863, "no_speech_prob": 0.00010362997272750363}, {"id": 132, "seek": 40248, "start": 406.84000000000003, "end": 408.36, "text": " the Cloud gets really popular,", "tokens": [264, 8061, 2170, 534, 3743, 11], "temperature": 0.0, "avg_logprob": -0.16125784568416263, "compression_ratio": 1.6788617886178863, "no_speech_prob": 0.00010362997272750363}, {"id": 133, "seek": 40248, "start": 408.36, "end": 410.84000000000003, "text": " having some limit by saying,", "tokens": [1419, 512, 4948, 538, 1566, 11], "temperature": 0.0, "avg_logprob": -0.16125784568416263, "compression_ratio": 1.6788617886178863, "no_speech_prob": 0.00010362997272750363}, {"id": 134, "seek": 40248, "start": 410.84000000000003, "end": 413.96000000000004, "text": " do a maximum of 60 translation per minute,", "tokens": [360, 257, 6674, 295, 4060, 12853, 680, 3456, 11], "temperature": 0.0, "avg_logprob": -0.16125784568416263, "compression_ratio": 1.6788617886178863, "no_speech_prob": 0.00010362997272750363}, {"id": 135, "seek": 40248, "start": 413.96000000000004, "end": 416.8, "text": " will come really handy and it's all built in into the software.", "tokens": [486, 808, 534, 13239, 293, 309, 311, 439, 3094, 294, 666, 264, 4722, 13], "temperature": 0.0, "avg_logprob": -0.16125784568416263, "compression_ratio": 1.6788617886178863, "no_speech_prob": 0.00010362997272750363}, {"id": 136, "seek": 40248, "start": 416.8, "end": 422.36, "text": " You can further issue API keys to give to people that can change those limits.", "tokens": [509, 393, 3052, 2734, 9362, 9317, 281, 976, 281, 561, 300, 393, 1319, 729, 10406, 13], "temperature": 0.0, "avg_logprob": -0.16125784568416263, "compression_ratio": 1.6788617886178863, "no_speech_prob": 0.00010362997272750363}, {"id": 137, "seek": 40248, "start": 422.36, "end": 425.28000000000003, "text": " So you can set up the system in a way where you", "tokens": [407, 291, 393, 992, 493, 264, 1185, 294, 257, 636, 689, 291], "temperature": 0.0, "avg_logprob": -0.16125784568416263, "compression_ratio": 1.6788617886178863, "no_speech_prob": 0.00010362997272750363}, {"id": 138, "seek": 40248, "start": 425.28000000000003, "end": 430.56, "text": " allow anonymous users to translate up to 20 translations per minute,", "tokens": [2089, 24932, 5022, 281, 13799, 493, 281, 945, 37578, 680, 3456, 11], "temperature": 0.0, "avg_logprob": -0.16125784568416263, "compression_ratio": 1.6788617886178863, "no_speech_prob": 0.00010362997272750363}, {"id": 139, "seek": 43056, "start": 430.56, "end": 433.8, "text": " and you can allow a subset of people that you've issued", "tokens": [293, 291, 393, 2089, 257, 25993, 295, 561, 300, 291, 600, 14379], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 140, "seek": 43056, "start": 433.8, "end": 437.16, "text": " API keys to have however many they want.", "tokens": [9362, 9317, 281, 362, 4461, 867, 436, 528, 13], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 141, "seek": 43056, "start": 437.16, "end": 438.72, "text": " You decide those limits.", "tokens": [509, 4536, 729, 10406, 13], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 142, "seek": 43056, "start": 438.72, "end": 441.72, "text": " It also has a localized UI.", "tokens": [467, 611, 575, 257, 44574, 15682, 13], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 143, "seek": 43056, "start": 441.72, "end": 443.64, "text": " We're using WebLater to do that,", "tokens": [492, 434, 1228, 9573, 43, 771, 281, 360, 300, 11], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 144, "seek": 43056, "start": 443.64, "end": 447.16, "text": " which is awesome, and it has been", "tokens": [597, 307, 3476, 11, 293, 309, 575, 668], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 145, "seek": 43056, "start": 447.16, "end": 449.8, "text": " currently translated into four languages,", "tokens": [4362, 16805, 666, 1451, 8650, 11], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 146, "seek": 43056, "start": 449.8, "end": 452.4, "text": " and we're looking to verify and add more.", "tokens": [293, 321, 434, 1237, 281, 16888, 293, 909, 544, 13], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 147, "seek": 43056, "start": 452.4, "end": 454.56, "text": " One cool neat feature is that", "tokens": [1485, 1627, 10654, 4111, 307, 300], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 148, "seek": 43056, "start": 454.56, "end": 460.4, "text": " a Libre translator has a ability to translate itself roughly,", "tokens": [257, 15834, 265, 35223, 575, 257, 3485, 281, 13799, 2564, 9810, 11], "temperature": 0.0, "avg_logprob": -0.20260579118104738, "compression_ratio": 1.5252918287937742, "no_speech_prob": 6.001197107252665e-05}, {"id": 149, "seek": 46040, "start": 460.4, "end": 462.91999999999996, "text": " so we have done that of course,", "tokens": [370, 321, 362, 1096, 300, 295, 1164, 11], "temperature": 0.0, "avg_logprob": -0.17223902615633876, "compression_ratio": 1.6951219512195121, "no_speech_prob": 3.068521255045198e-05}, {"id": 150, "seek": 46040, "start": 462.91999999999996, "end": 468.08, "text": " but we haven't displayed all the languages that it has tried to translate itself.", "tokens": [457, 321, 2378, 380, 16372, 439, 264, 8650, 300, 309, 575, 3031, 281, 13799, 2564, 13], "temperature": 0.0, "avg_logprob": -0.17223902615633876, "compression_ratio": 1.6951219512195121, "no_speech_prob": 3.068521255045198e-05}, {"id": 151, "seek": 46040, "start": 468.08, "end": 471.35999999999996, "text": " We are waiting for a native speaker to review", "tokens": [492, 366, 3806, 337, 257, 8470, 8145, 281, 3131], "temperature": 0.0, "avg_logprob": -0.17223902615633876, "compression_ratio": 1.6951219512195121, "no_speech_prob": 3.068521255045198e-05}, {"id": 152, "seek": 46040, "start": 471.35999999999996, "end": 473.91999999999996, "text": " the actual translation and correct it.", "tokens": [264, 3539, 12853, 293, 3006, 309, 13], "temperature": 0.0, "avg_logprob": -0.17223902615633876, "compression_ratio": 1.6951219512195121, "no_speech_prob": 3.068521255045198e-05}, {"id": 153, "seek": 46040, "start": 473.91999999999996, "end": 475.52, "text": " But if you run in debug mode,", "tokens": [583, 498, 291, 1190, 294, 24083, 4391, 11], "temperature": 0.0, "avg_logprob": -0.17223902615633876, "compression_ratio": 1.6951219512195121, "no_speech_prob": 3.068521255045198e-05}, {"id": 154, "seek": 46040, "start": 475.52, "end": 478.28, "text": " you will see all the work that it has done, which is neat.", "tokens": [291, 486, 536, 439, 264, 589, 300, 309, 575, 1096, 11, 597, 307, 10654, 13], "temperature": 0.0, "avg_logprob": -0.17223902615633876, "compression_ratio": 1.6951219512195121, "no_speech_prob": 3.068521255045198e-05}, {"id": 155, "seek": 46040, "start": 478.28, "end": 482.23999999999995, "text": " So it translates itself or at least it helps.", "tokens": [407, 309, 28468, 2564, 420, 412, 1935, 309, 3665, 13], "temperature": 0.0, "avg_logprob": -0.17223902615633876, "compression_ratio": 1.6951219512195121, "no_speech_prob": 3.068521255045198e-05}, {"id": 156, "seek": 46040, "start": 482.23999999999995, "end": 484.64, "text": " It finally has the ability to monitor itself.", "tokens": [467, 2721, 575, 264, 3485, 281, 6002, 2564, 13], "temperature": 0.0, "avg_logprob": -0.17223902615633876, "compression_ratio": 1.6951219512195121, "no_speech_prob": 3.068521255045198e-05}, {"id": 157, "seek": 46040, "start": 484.64, "end": 487.96, "text": " So it can generate the usage metrics,", "tokens": [407, 309, 393, 8460, 264, 14924, 16367, 11], "temperature": 0.0, "avg_logprob": -0.17223902615633876, "compression_ratio": 1.6951219512195121, "no_speech_prob": 3.068521255045198e-05}, {"id": 158, "seek": 48796, "start": 487.96, "end": 493.52, "text": " so you can monitor the usage of the server using Prometheus and Grafana.", "tokens": [370, 291, 393, 6002, 264, 14924, 295, 264, 7154, 1228, 2114, 649, 42209, 293, 8985, 69, 2095, 13], "temperature": 0.0, "avg_logprob": -0.1353777005122258, "compression_ratio": 1.6597510373443984, "no_speech_prob": 1.890620478661731e-05}, {"id": 159, "seek": 48796, "start": 493.52, "end": 497.52, "text": " These are tools to do monitoring that are very popular.", "tokens": [1981, 366, 3873, 281, 360, 11028, 300, 366, 588, 3743, 13], "temperature": 0.0, "avg_logprob": -0.1353777005122258, "compression_ratio": 1.6597510373443984, "no_speech_prob": 1.890620478661731e-05}, {"id": 160, "seek": 48796, "start": 497.52, "end": 501.91999999999996, "text": " Inside the software, there is really just a few packages,", "tokens": [15123, 264, 4722, 11, 456, 307, 534, 445, 257, 1326, 17401, 11], "temperature": 0.0, "avg_logprob": -0.1353777005122258, "compression_ratio": 1.6597510373443984, "no_speech_prob": 1.890620478661731e-05}, {"id": 161, "seek": 48796, "start": 501.91999999999996, "end": 503.68, "text": " so it's very lightweight.", "tokens": [370, 309, 311, 588, 22052, 13], "temperature": 0.0, "avg_logprob": -0.1353777005122258, "compression_ratio": 1.6597510373443984, "no_speech_prob": 1.890620478661731e-05}, {"id": 162, "seek": 48796, "start": 503.68, "end": 507.35999999999996, "text": " Most of the translation work is done by", "tokens": [4534, 295, 264, 12853, 589, 307, 1096, 538], "temperature": 0.0, "avg_logprob": -0.1353777005122258, "compression_ratio": 1.6597510373443984, "no_speech_prob": 1.890620478661731e-05}, {"id": 163, "seek": 48796, "start": 507.35999999999996, "end": 509.88, "text": " another package called Argos Translate.", "tokens": [1071, 7372, 1219, 1587, 18674, 6531, 17593, 13], "temperature": 0.0, "avg_logprob": -0.1353777005122258, "compression_ratio": 1.6597510373443984, "no_speech_prob": 1.890620478661731e-05}, {"id": 164, "seek": 48796, "start": 509.88, "end": 512.36, "text": " This is really the core engine that", "tokens": [639, 307, 534, 264, 4965, 2848, 300], "temperature": 0.0, "avg_logprob": -0.1353777005122258, "compression_ratio": 1.6597510373443984, "no_speech_prob": 1.890620478661731e-05}, {"id": 165, "seek": 48796, "start": 512.36, "end": 515.16, "text": " performs the hard work in the translation,", "tokens": [26213, 264, 1152, 589, 294, 264, 12853, 11], "temperature": 0.0, "avg_logprob": -0.1353777005122258, "compression_ratio": 1.6597510373443984, "no_speech_prob": 1.890620478661731e-05}, {"id": 166, "seek": 48796, "start": 515.16, "end": 516.92, "text": " which is an awesome project,", "tokens": [597, 307, 364, 3476, 1716, 11], "temperature": 0.0, "avg_logprob": -0.1353777005122258, "compression_ratio": 1.6597510373443984, "no_speech_prob": 1.890620478661731e-05}, {"id": 167, "seek": 51692, "start": 516.92, "end": 520.4799999999999, "text": " and we collaborate with them on Libre Translate.", "tokens": [293, 321, 18338, 365, 552, 322, 15834, 265, 6531, 17593, 13], "temperature": 0.0, "avg_logprob": -0.2152951615197318, "compression_ratio": 1.6936170212765957, "no_speech_prob": 9.663294622441754e-05}, {"id": 168, "seek": 51692, "start": 520.4799999999999, "end": 522.28, "text": " Inside Argo Translate,", "tokens": [15123, 1587, 1571, 6531, 17593, 11], "temperature": 0.0, "avg_logprob": -0.2152951615197318, "compression_ratio": 1.6936170212765957, "no_speech_prob": 9.663294622441754e-05}, {"id": 169, "seek": 51692, "start": 522.28, "end": 527.0799999999999, "text": " there is also other software which is built on the shoulder of giants.", "tokens": [456, 307, 611, 661, 4722, 597, 307, 3094, 322, 264, 7948, 295, 31894, 13], "temperature": 0.0, "avg_logprob": -0.2152951615197318, "compression_ratio": 1.6936170212765957, "no_speech_prob": 9.663294622441754e-05}, {"id": 170, "seek": 51692, "start": 527.0799999999999, "end": 529.8399999999999, "text": " C-Translate, which is an inference engine that", "tokens": [383, 12, 33339, 17593, 11, 597, 307, 364, 38253, 2848, 300], "temperature": 0.0, "avg_logprob": -0.2152951615197318, "compression_ratio": 1.6936170212765957, "no_speech_prob": 9.663294622441754e-05}, {"id": 171, "seek": 51692, "start": 529.8399999999999, "end": 533.1999999999999, "text": " does neural translation using transformers models,", "tokens": [775, 18161, 12853, 1228, 4088, 433, 5245, 11], "temperature": 0.0, "avg_logprob": -0.2152951615197318, "compression_ratio": 1.6936170212765957, "no_speech_prob": 9.663294622441754e-05}, {"id": 172, "seek": 51692, "start": 533.1999999999999, "end": 534.5999999999999, "text": " which is a state-of-the-art.", "tokens": [597, 307, 257, 1785, 12, 2670, 12, 3322, 12, 446, 13], "temperature": 0.0, "avg_logprob": -0.2152951615197318, "compression_ratio": 1.6936170212765957, "no_speech_prob": 9.663294622441754e-05}, {"id": 173, "seek": 51692, "start": 534.5999999999999, "end": 538.56, "text": " It's the same type of architecture that chatGPT3 uses.", "tokens": [467, 311, 264, 912, 2010, 295, 9482, 300, 5081, 38, 47, 51, 18, 4960, 13], "temperature": 0.0, "avg_logprob": -0.2152951615197318, "compression_ratio": 1.6936170212765957, "no_speech_prob": 9.663294622441754e-05}, {"id": 174, "seek": 51692, "start": 538.56, "end": 540.4399999999999, "text": " There is a sentence piece,", "tokens": [821, 307, 257, 8174, 2522, 11], "temperature": 0.0, "avg_logprob": -0.2152951615197318, "compression_ratio": 1.6936170212765957, "no_speech_prob": 9.663294622441754e-05}, {"id": 175, "seek": 51692, "start": 540.4399999999999, "end": 543.1999999999999, "text": " which is a piece of code from Google that does", "tokens": [597, 307, 257, 2522, 295, 3089, 490, 3329, 300, 775], "temperature": 0.0, "avg_logprob": -0.2152951615197318, "compression_ratio": 1.6936170212765957, "no_speech_prob": 9.663294622441754e-05}, {"id": 176, "seek": 54320, "start": 543.2, "end": 548.0400000000001, "text": " the word tokenization and the stanza which comes out of Stanford,", "tokens": [264, 1349, 14862, 2144, 293, 264, 342, 20030, 597, 1487, 484, 295, 20374, 11], "temperature": 0.0, "avg_logprob": -0.18705822597040195, "compression_ratio": 1.6437246963562753, "no_speech_prob": 5.290569242788479e-05}, {"id": 177, "seek": 54320, "start": 548.0400000000001, "end": 550.48, "text": " which does a sentence analysis.", "tokens": [597, 775, 257, 8174, 5215, 13], "temperature": 0.0, "avg_logprob": -0.18705822597040195, "compression_ratio": 1.6437246963562753, "no_speech_prob": 5.290569242788479e-05}, {"id": 178, "seek": 54320, "start": 550.48, "end": 555.36, "text": " Argos Translate uses all these three to perform the translation work.", "tokens": [1587, 18674, 6531, 17593, 4960, 439, 613, 1045, 281, 2042, 264, 12853, 589, 13], "temperature": 0.0, "avg_logprob": -0.18705822597040195, "compression_ratio": 1.6437246963562753, "no_speech_prob": 5.290569242788479e-05}, {"id": 179, "seek": 54320, "start": 555.36, "end": 557.24, "text": " Now, that's not all it does.", "tokens": [823, 11, 300, 311, 406, 439, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.18705822597040195, "compression_ratio": 1.6437246963562753, "no_speech_prob": 5.290569242788479e-05}, {"id": 180, "seek": 54320, "start": 557.24, "end": 558.96, "text": " Argos Translate also takes care of", "tokens": [1587, 18674, 6531, 17593, 611, 2516, 1127, 295], "temperature": 0.0, "avg_logprob": -0.18705822597040195, "compression_ratio": 1.6437246963562753, "no_speech_prob": 5.290569242788479e-05}, {"id": 181, "seek": 54320, "start": 558.96, "end": 563.24, "text": " the very important Argos package manager index.", "tokens": [264, 588, 1021, 1587, 18674, 7372, 6598, 8186, 13], "temperature": 0.0, "avg_logprob": -0.18705822597040195, "compression_ratio": 1.6437246963562753, "no_speech_prob": 5.290569242788479e-05}, {"id": 182, "seek": 54320, "start": 563.24, "end": 567.0400000000001, "text": " This is where all the language models are handled,", "tokens": [639, 307, 689, 439, 264, 2856, 5245, 366, 18033, 11], "temperature": 0.0, "avg_logprob": -0.18705822597040195, "compression_ratio": 1.6437246963562753, "no_speech_prob": 5.290569242788479e-05}, {"id": 183, "seek": 54320, "start": 567.0400000000001, "end": 568.5200000000001, "text": " installed, and distributed.", "tokens": [8899, 11, 293, 12631, 13], "temperature": 0.0, "avg_logprob": -0.18705822597040195, "compression_ratio": 1.6437246963562753, "no_speech_prob": 5.290569242788479e-05}, {"id": 184, "seek": 54320, "start": 568.5200000000001, "end": 571.88, "text": " So the first time that you run Libre Translate,", "tokens": [407, 264, 700, 565, 300, 291, 1190, 15834, 265, 6531, 17593, 11], "temperature": 0.0, "avg_logprob": -0.18705822597040195, "compression_ratio": 1.6437246963562753, "no_speech_prob": 5.290569242788479e-05}, {"id": 185, "seek": 57188, "start": 571.88, "end": 574.08, "text": " Argos Translate will take care of", "tokens": [1587, 18674, 6531, 17593, 486, 747, 1127, 295], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 186, "seek": 57188, "start": 574.08, "end": 576.76, "text": " querying the Argos package manager index,", "tokens": [7083, 1840, 264, 1587, 18674, 7372, 6598, 8186, 11], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 187, "seek": 57188, "start": 576.76, "end": 579.28, "text": " and will download the languages that you need.", "tokens": [293, 486, 5484, 264, 8650, 300, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 188, "seek": 57188, "start": 579.28, "end": 582.84, "text": " This allows us to also create instances where,", "tokens": [639, 4045, 505, 281, 611, 1884, 14519, 689, 11], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 189, "seek": 57188, "start": 582.84, "end": 586.56, "text": " say, you only need to translate between French and English.", "tokens": [584, 11, 291, 787, 643, 281, 13799, 1296, 5522, 293, 3669, 13], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 190, "seek": 57188, "start": 586.56, "end": 591.72, "text": " You do not need to download the entire 26 gigabytes of models.", "tokens": [509, 360, 406, 643, 281, 5484, 264, 2302, 7551, 42741, 295, 5245, 13], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 191, "seek": 57188, "start": 591.72, "end": 592.84, "text": " You can simply say,", "tokens": [509, 393, 2935, 584, 11], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 192, "seek": 57188, "start": 592.84, "end": 594.56, "text": " I just need those two models,", "tokens": [286, 445, 643, 729, 732, 5245, 11], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 193, "seek": 57188, "start": 594.56, "end": 598.52, "text": " and the program will download simply those two models.", "tokens": [293, 264, 1461, 486, 5484, 2935, 729, 732, 5245, 13], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 194, "seek": 57188, "start": 598.52, "end": 601.2, "text": " We also have a small module that does", "tokens": [492, 611, 362, 257, 1359, 10088, 300, 775], "temperature": 0.0, "avg_logprob": -0.1335306167602539, "compression_ratio": 1.7193675889328064, "no_speech_prob": 2.5455659852013923e-05}, {"id": 195, "seek": 60120, "start": 601.2, "end": 605.32, "text": " the file translation which connects again to Argos Translate.", "tokens": [264, 3991, 12853, 597, 16967, 797, 281, 1587, 18674, 6531, 17593, 13], "temperature": 0.0, "avg_logprob": -0.16019813666182958, "compression_ratio": 1.668103448275862, "no_speech_prob": 1.981648529181257e-05}, {"id": 196, "seek": 60120, "start": 605.32, "end": 608.08, "text": " That's the Argos Translate files package,", "tokens": [663, 311, 264, 1587, 18674, 6531, 17593, 7098, 7372, 11], "temperature": 0.0, "avg_logprob": -0.16019813666182958, "compression_ratio": 1.668103448275862, "no_speech_prob": 1.981648529181257e-05}, {"id": 197, "seek": 60120, "start": 608.08, "end": 611.2800000000001, "text": " and then some common Python packages that allow us to put", "tokens": [293, 550, 512, 2689, 15329, 17401, 300, 2089, 505, 281, 829], "temperature": 0.0, "avg_logprob": -0.16019813666182958, "compression_ratio": 1.668103448275862, "no_speech_prob": 1.981648529181257e-05}, {"id": 198, "seek": 60120, "start": 611.2800000000001, "end": 615.5600000000001, "text": " the web interface and coordinate the application as a whole.", "tokens": [264, 3670, 9226, 293, 15670, 264, 3861, 382, 257, 1379, 13], "temperature": 0.0, "avg_logprob": -0.16019813666182958, "compression_ratio": 1.668103448275862, "no_speech_prob": 1.981648529181257e-05}, {"id": 199, "seek": 60120, "start": 615.5600000000001, "end": 621.44, "text": " So it's really an ecosystem that's built with other open source software,", "tokens": [407, 309, 311, 534, 364, 11311, 300, 311, 3094, 365, 661, 1269, 4009, 4722, 11], "temperature": 0.0, "avg_logprob": -0.16019813666182958, "compression_ratio": 1.668103448275862, "no_speech_prob": 1.981648529181257e-05}, {"id": 200, "seek": 60120, "start": 621.44, "end": 627.32, "text": " and together it creates this complete translation solution.", "tokens": [293, 1214, 309, 7829, 341, 3566, 12853, 3827, 13], "temperature": 0.0, "avg_logprob": -0.16019813666182958, "compression_ratio": 1.668103448275862, "no_speech_prob": 1.981648529181257e-05}, {"id": 201, "seek": 60120, "start": 627.32, "end": 629.32, "text": " Talking about language models,", "tokens": [22445, 466, 2856, 5245, 11], "temperature": 0.0, "avg_logprob": -0.16019813666182958, "compression_ratio": 1.668103448275862, "no_speech_prob": 1.981648529181257e-05}, {"id": 202, "seek": 62932, "start": 629.32, "end": 632.08, "text": " we have 58 of them that gives you", "tokens": [321, 362, 21786, 295, 552, 300, 2709, 291], "temperature": 0.0, "avg_logprob": -0.15141976233756188, "compression_ratio": 1.7319148936170212, "no_speech_prob": 2.968654371215962e-05}, {"id": 203, "seek": 62932, "start": 632.08, "end": 634.5600000000001, "text": " translation support for about 30 languages.", "tokens": [12853, 1406, 337, 466, 2217, 8650, 13], "temperature": 0.0, "avg_logprob": -0.15141976233756188, "compression_ratio": 1.7319148936170212, "no_speech_prob": 2.968654371215962e-05}, {"id": 204, "seek": 62932, "start": 634.5600000000001, "end": 638.72, "text": " It does automatic pivot via English.", "tokens": [467, 775, 12509, 14538, 5766, 3669, 13], "temperature": 0.0, "avg_logprob": -0.15141976233756188, "compression_ratio": 1.7319148936170212, "no_speech_prob": 2.968654371215962e-05}, {"id": 205, "seek": 62932, "start": 638.72, "end": 643.44, "text": " We are currently looking to transition to using multi-language models.", "tokens": [492, 366, 4362, 1237, 281, 6034, 281, 1228, 4825, 12, 25241, 20473, 5245, 13], "temperature": 0.0, "avg_logprob": -0.15141976233756188, "compression_ratio": 1.7319148936170212, "no_speech_prob": 2.968654371215962e-05}, {"id": 206, "seek": 62932, "start": 643.44, "end": 645.8000000000001, "text": " But for the moment when you translate,", "tokens": [583, 337, 264, 1623, 562, 291, 13799, 11], "temperature": 0.0, "avg_logprob": -0.15141976233756188, "compression_ratio": 1.7319148936170212, "no_speech_prob": 2.968654371215962e-05}, {"id": 207, "seek": 62932, "start": 645.8000000000001, "end": 647.6400000000001, "text": " say, from Italian to French,", "tokens": [584, 11, 490, 10003, 281, 5522, 11], "temperature": 0.0, "avg_logprob": -0.15141976233756188, "compression_ratio": 1.7319148936170212, "no_speech_prob": 2.968654371215962e-05}, {"id": 208, "seek": 62932, "start": 647.6400000000001, "end": 651.2, "text": " the program will automatically do the pivoting via English.", "tokens": [264, 1461, 486, 6772, 360, 264, 14538, 278, 5766, 3669, 13], "temperature": 0.0, "avg_logprob": -0.15141976233756188, "compression_ratio": 1.7319148936170212, "no_speech_prob": 2.968654371215962e-05}, {"id": 209, "seek": 62932, "start": 651.2, "end": 655.36, "text": " So I will translate Italian to English and English to French.", "tokens": [407, 286, 486, 13799, 10003, 281, 3669, 293, 3669, 281, 5522, 13], "temperature": 0.0, "avg_logprob": -0.15141976233756188, "compression_ratio": 1.7319148936170212, "no_speech_prob": 2.968654371215962e-05}, {"id": 210, "seek": 62932, "start": 655.36, "end": 657.6, "text": " If there is a language missing,", "tokens": [759, 456, 307, 257, 2856, 5361, 11], "temperature": 0.0, "avg_logprob": -0.15141976233756188, "compression_ratio": 1.7319148936170212, "no_speech_prob": 2.968654371215962e-05}, {"id": 211, "seek": 65760, "start": 657.6, "end": 661.5600000000001, "text": " there is a very cool repository", "tokens": [456, 307, 257, 588, 1627, 25841], "temperature": 0.0, "avg_logprob": -0.19475437164306642, "compression_ratio": 1.7105263157894737, "no_speech_prob": 5.210144445300102e-05}, {"id": 212, "seek": 65760, "start": 661.5600000000001, "end": 664.52, "text": " under the Argos OpenTech organization,", "tokens": [833, 264, 1587, 18674, 7238, 36050, 4475, 11], "temperature": 0.0, "avg_logprob": -0.19475437164306642, "compression_ratio": 1.7105263157894737, "no_speech_prob": 5.210144445300102e-05}, {"id": 213, "seek": 65760, "start": 664.52, "end": 667.84, "text": " which builds Argos Translate called Argos Train.", "tokens": [597, 15182, 1587, 18674, 6531, 17593, 1219, 1587, 18674, 28029, 13], "temperature": 0.0, "avg_logprob": -0.19475437164306642, "compression_ratio": 1.7105263157894737, "no_speech_prob": 5.210144445300102e-05}, {"id": 214, "seek": 65760, "start": 667.84, "end": 669.8000000000001, "text": " That is a repository that has", "tokens": [663, 307, 257, 25841, 300, 575], "temperature": 0.0, "avg_logprob": -0.19475437164306642, "compression_ratio": 1.7105263157894737, "no_speech_prob": 5.210144445300102e-05}, {"id": 215, "seek": 65760, "start": 669.8000000000001, "end": 673.52, "text": " very good instructions on how you can train your own models.", "tokens": [588, 665, 9415, 322, 577, 291, 393, 3847, 428, 1065, 5245, 13], "temperature": 0.0, "avg_logprob": -0.19475437164306642, "compression_ratio": 1.7105263157894737, "no_speech_prob": 5.210144445300102e-05}, {"id": 216, "seek": 65760, "start": 673.52, "end": 677.52, "text": " So if a language is missing, go check it out.", "tokens": [407, 498, 257, 2856, 307, 5361, 11, 352, 1520, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.19475437164306642, "compression_ratio": 1.7105263157894737, "no_speech_prob": 5.210144445300102e-05}, {"id": 217, "seek": 65760, "start": 677.52, "end": 680.28, "text": " It has very clear instructions,", "tokens": [467, 575, 588, 1850, 9415, 11], "temperature": 0.0, "avg_logprob": -0.19475437164306642, "compression_ratio": 1.7105263157894737, "no_speech_prob": 5.210144445300102e-05}, {"id": 218, "seek": 65760, "start": 680.28, "end": 682.88, "text": " and you could contribute a language that is", "tokens": [293, 291, 727, 10586, 257, 2856, 300, 307], "temperature": 0.0, "avg_logprob": -0.19475437164306642, "compression_ratio": 1.7105263157894737, "no_speech_prob": 5.210144445300102e-05}, {"id": 219, "seek": 65760, "start": 682.88, "end": 686.48, "text": " missing and you want to see integrated into the software.", "tokens": [5361, 293, 291, 528, 281, 536, 10919, 666, 264, 4722, 13], "temperature": 0.0, "avg_logprob": -0.19475437164306642, "compression_ratio": 1.7105263157894737, "no_speech_prob": 5.210144445300102e-05}, {"id": 220, "seek": 68648, "start": 686.48, "end": 689.9200000000001, "text": " Speaking of the models,", "tokens": [13069, 295, 264, 5245, 11], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 221, "seek": 68648, "start": 689.9200000000001, "end": 692.04, "text": " when a model is downloaded,", "tokens": [562, 257, 2316, 307, 21748, 11], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 222, "seek": 68648, "start": 692.04, "end": 694.44, "text": " it has a Argos model extension,", "tokens": [309, 575, 257, 1587, 18674, 2316, 10320, 11], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 223, "seek": 68648, "start": 694.44, "end": 696.88, "text": " and these are simply zip files.", "tokens": [293, 613, 366, 2935, 20730, 7098, 13], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 224, "seek": 68648, "start": 696.88, "end": 699.44, "text": " It's a zip file and it's inside,", "tokens": [467, 311, 257, 20730, 3991, 293, 309, 311, 1854, 11], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 225, "seek": 68648, "start": 699.44, "end": 702.44, "text": " has a little bit of metadata.", "tokens": [575, 257, 707, 857, 295, 26603, 13], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 226, "seek": 68648, "start": 702.44, "end": 706.48, "text": " It has a folder that contains the CTranslate model.", "tokens": [467, 575, 257, 10820, 300, 8306, 264, 383, 33339, 17593, 2316, 13], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 227, "seek": 68648, "start": 706.48, "end": 709.96, "text": " It has the sentence piece model and finally the stanza model.", "tokens": [467, 575, 264, 8174, 2522, 2316, 293, 2721, 264, 342, 20030, 2316, 13], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 228, "seek": 68648, "start": 709.96, "end": 712.5600000000001, "text": " So it has the information for all the three packages that we", "tokens": [407, 309, 575, 264, 1589, 337, 439, 264, 1045, 17401, 300, 321], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 229, "seek": 68648, "start": 712.5600000000001, "end": 715.2, "text": " discussed earlier to perform the translation.", "tokens": [7152, 3071, 281, 2042, 264, 12853, 13], "temperature": 0.0, "avg_logprob": -0.2080712624646108, "compression_ratio": 1.7347826086956522, "no_speech_prob": 4.1236176912207156e-05}, {"id": 230, "seek": 71520, "start": 715.2, "end": 718.0, "text": " It's very interesting to check it out.", "tokens": [467, 311, 588, 1880, 281, 1520, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.25769402640206474, "compression_ratio": 1.5725806451612903, "no_speech_prob": 5.296087692840956e-05}, {"id": 231, "seek": 71520, "start": 718.0, "end": 720.36, "text": " Let's talk a little bit of accuracy, right?", "tokens": [961, 311, 751, 257, 707, 857, 295, 14170, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.25769402640206474, "compression_ratio": 1.5725806451612903, "no_speech_prob": 5.296087692840956e-05}, {"id": 232, "seek": 71520, "start": 720.36, "end": 721.88, "text": " Like the question like, okay,", "tokens": [1743, 264, 1168, 411, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.25769402640206474, "compression_ratio": 1.5725806451612903, "no_speech_prob": 5.296087692840956e-05}, {"id": 233, "seek": 71520, "start": 721.88, "end": 725.32, "text": " it's a translation sorry, but how good is it really?", "tokens": [309, 311, 257, 12853, 2597, 11, 457, 577, 665, 307, 309, 534, 30], "temperature": 0.0, "avg_logprob": -0.25769402640206474, "compression_ratio": 1.5725806451612903, "no_speech_prob": 5.296087692840956e-05}, {"id": 234, "seek": 71520, "start": 725.32, "end": 729.5600000000001, "text": " For that, there is a metric that can be used to", "tokens": [1171, 300, 11, 456, 307, 257, 20678, 300, 393, 312, 1143, 281], "temperature": 0.0, "avg_logprob": -0.25769402640206474, "compression_ratio": 1.5725806451612903, "no_speech_prob": 5.296087692840956e-05}, {"id": 235, "seek": 71520, "start": 729.5600000000001, "end": 733.8000000000001, "text": " assess roughly the accuracy of the translation.", "tokens": [5877, 9810, 264, 14170, 295, 264, 12853, 13], "temperature": 0.0, "avg_logprob": -0.25769402640206474, "compression_ratio": 1.5725806451612903, "no_speech_prob": 5.296087692840956e-05}, {"id": 236, "seek": 71520, "start": 733.8000000000001, "end": 735.9200000000001, "text": " It's called a Blue Score acronym", "tokens": [467, 311, 1219, 257, 8510, 47901, 39195], "temperature": 0.0, "avg_logprob": -0.25769402640206474, "compression_ratio": 1.5725806451612903, "no_speech_prob": 5.296087692840956e-05}, {"id": 237, "seek": 71520, "start": 735.9200000000001, "end": 738.72, "text": " for bilingual evaluation under study.", "tokens": [337, 48757, 13344, 833, 2979, 13], "temperature": 0.0, "avg_logprob": -0.25769402640206474, "compression_ratio": 1.5725806451612903, "no_speech_prob": 5.296087692840956e-05}, {"id": 238, "seek": 71520, "start": 738.72, "end": 745.1600000000001, "text": " It measures the similarity of text to a reference corpus.", "tokens": [467, 8000, 264, 32194, 295, 2487, 281, 257, 6408, 1181, 31624, 13], "temperature": 0.0, "avg_logprob": -0.25769402640206474, "compression_ratio": 1.5725806451612903, "no_speech_prob": 5.296087692840956e-05}, {"id": 239, "seek": 74516, "start": 745.16, "end": 748.16, "text": " It has values that go from 0 to 1,", "tokens": [467, 575, 4190, 300, 352, 490, 1958, 281, 502, 11], "temperature": 0.0, "avg_logprob": -0.1894293681229695, "compression_ratio": 1.6682242990654206, "no_speech_prob": 2.109530942107085e-05}, {"id": 240, "seek": 74516, "start": 748.16, "end": 751.9599999999999, "text": " or if you express it as a percentage from 0 to 100.", "tokens": [420, 498, 291, 5109, 309, 382, 257, 9668, 490, 1958, 281, 2319, 13], "temperature": 0.0, "avg_logprob": -0.1894293681229695, "compression_ratio": 1.6682242990654206, "no_speech_prob": 2.109530942107085e-05}, {"id": 241, "seek": 74516, "start": 751.9599999999999, "end": 754.24, "text": " The best translators in the world,", "tokens": [440, 1151, 5105, 3391, 294, 264, 1002, 11], "temperature": 0.0, "avg_logprob": -0.1894293681229695, "compression_ratio": 1.6682242990654206, "no_speech_prob": 2.109530942107085e-05}, {"id": 242, "seek": 74516, "start": 754.24, "end": 757.8399999999999, "text": " human translators do not get a score of 100 ever.", "tokens": [1952, 5105, 3391, 360, 406, 483, 257, 6175, 295, 2319, 1562, 13], "temperature": 0.0, "avg_logprob": -0.1894293681229695, "compression_ratio": 1.6682242990654206, "no_speech_prob": 2.109530942107085e-05}, {"id": 243, "seek": 74516, "start": 757.8399999999999, "end": 761.4, "text": " So anything that is above", "tokens": [407, 1340, 300, 307, 3673], "temperature": 0.0, "avg_logprob": -0.1894293681229695, "compression_ratio": 1.6682242990654206, "no_speech_prob": 2.109530942107085e-05}, {"id": 244, "seek": 74516, "start": 761.4, "end": 765.04, "text": " a 40 is considered understandable to good.", "tokens": [257, 3356, 307, 4888, 25648, 281, 665, 13], "temperature": 0.0, "avg_logprob": -0.1894293681229695, "compression_ratio": 1.6682242990654206, "no_speech_prob": 2.109530942107085e-05}, {"id": 245, "seek": 74516, "start": 765.04, "end": 769.72, "text": " Something that is above 50 tends to be very high quality.", "tokens": [6595, 300, 307, 3673, 2625, 12258, 281, 312, 588, 1090, 3125, 13], "temperature": 0.0, "avg_logprob": -0.1894293681229695, "compression_ratio": 1.6682242990654206, "no_speech_prob": 2.109530942107085e-05}, {"id": 246, "seek": 74516, "start": 769.72, "end": 775.12, "text": " Sorry, up to 50 is high quality and above 60 is very high.", "tokens": [4919, 11, 493, 281, 2625, 307, 1090, 3125, 293, 3673, 4060, 307, 588, 1090, 13], "temperature": 0.0, "avg_logprob": -0.1894293681229695, "compression_ratio": 1.6682242990654206, "no_speech_prob": 2.109530942107085e-05}, {"id": 247, "seek": 77512, "start": 775.12, "end": 778.24, "text": " We had a community contributor", "tokens": [492, 632, 257, 1768, 42859], "temperature": 0.0, "avg_logprob": -0.1577530221624689, "compression_ratio": 1.52803738317757, "no_speech_prob": 2.4668224796187133e-05}, {"id": 248, "seek": 77512, "start": 778.24, "end": 780.84, "text": " actually go and a few weeks ago,", "tokens": [767, 352, 293, 257, 1326, 3259, 2057, 11], "temperature": 0.0, "avg_logprob": -0.1577530221624689, "compression_ratio": 1.52803738317757, "no_speech_prob": 2.4668224796187133e-05}, {"id": 249, "seek": 77512, "start": 780.84, "end": 786.08, "text": " he ran the evaluation on our different models,", "tokens": [415, 5872, 264, 13344, 322, 527, 819, 5245, 11], "temperature": 0.0, "avg_logprob": -0.1577530221624689, "compression_ratio": 1.52803738317757, "no_speech_prob": 2.4668224796187133e-05}, {"id": 250, "seek": 77512, "start": 786.08, "end": 788.84, "text": " and we found that 83 percent of", "tokens": [293, 321, 1352, 300, 30997, 3043, 295], "temperature": 0.0, "avg_logprob": -0.1577530221624689, "compression_ratio": 1.52803738317757, "no_speech_prob": 2.4668224796187133e-05}, {"id": 251, "seek": 77512, "start": 788.84, "end": 790.48, "text": " the models currently in", "tokens": [264, 5245, 4362, 294], "temperature": 0.0, "avg_logprob": -0.1577530221624689, "compression_ratio": 1.52803738317757, "no_speech_prob": 2.4668224796187133e-05}, {"id": 252, "seek": 77512, "start": 790.48, "end": 793.72, "text": " Libre Translate are scoring above 40 percent.", "tokens": [15834, 265, 6531, 17593, 366, 22358, 3673, 3356, 3043, 13], "temperature": 0.0, "avg_logprob": -0.1577530221624689, "compression_ratio": 1.52803738317757, "no_speech_prob": 2.4668224796187133e-05}, {"id": 253, "seek": 77512, "start": 793.72, "end": 796.88, "text": " So 83 of them are good.", "tokens": [407, 30997, 295, 552, 366, 665, 13], "temperature": 0.0, "avg_logprob": -0.1577530221624689, "compression_ratio": 1.52803738317757, "no_speech_prob": 2.4668224796187133e-05}, {"id": 254, "seek": 77512, "start": 796.88, "end": 799.84, "text": " Now, to make it into perspective,", "tokens": [823, 11, 281, 652, 309, 666, 4585, 11], "temperature": 0.0, "avg_logprob": -0.1577530221624689, "compression_ratio": 1.52803738317757, "no_speech_prob": 2.4668224796187133e-05}, {"id": 255, "seek": 77512, "start": 799.84, "end": 803.28, "text": " when people ask me directly how good is Libre Translate,", "tokens": [562, 561, 1029, 385, 3838, 577, 665, 307, 15834, 265, 6531, 17593, 11], "temperature": 0.0, "avg_logprob": -0.1577530221624689, "compression_ratio": 1.52803738317757, "no_speech_prob": 2.4668224796187133e-05}, {"id": 256, "seek": 80328, "start": 803.28, "end": 806.0, "text": " I like to tell them that it's roughly as good as", "tokens": [286, 411, 281, 980, 552, 300, 309, 311, 9810, 382, 665, 382], "temperature": 0.0, "avg_logprob": -0.16381461467217961, "compression_ratio": 1.6798418972332017, "no_speech_prob": 2.428706648061052e-05}, {"id": 257, "seek": 80328, "start": 806.0, "end": 808.6, "text": " Google Translate was four years ago.", "tokens": [3329, 6531, 17593, 390, 1451, 924, 2057, 13], "temperature": 0.0, "avg_logprob": -0.16381461467217961, "compression_ratio": 1.6798418972332017, "no_speech_prob": 2.428706648061052e-05}, {"id": 258, "seek": 80328, "start": 808.6, "end": 811.4399999999999, "text": " So I want to make the expectations clear at this stage in", "tokens": [407, 286, 528, 281, 652, 264, 9843, 1850, 412, 341, 3233, 294], "temperature": 0.0, "avg_logprob": -0.16381461467217961, "compression_ratio": 1.6798418972332017, "no_speech_prob": 2.428706648061052e-05}, {"id": 259, "seek": 80328, "start": 811.4399999999999, "end": 813.64, "text": " the project that it is not as good as some of", "tokens": [264, 1716, 300, 309, 307, 406, 382, 665, 382, 512, 295], "temperature": 0.0, "avg_logprob": -0.16381461467217961, "compression_ratio": 1.6798418972332017, "no_speech_prob": 2.428706648061052e-05}, {"id": 260, "seek": 80328, "start": 813.64, "end": 816.0, "text": " the proprietary alternatives.", "tokens": [264, 38992, 20478, 13], "temperature": 0.0, "avg_logprob": -0.16381461467217961, "compression_ratio": 1.6798418972332017, "no_speech_prob": 2.428706648061052e-05}, {"id": 261, "seek": 80328, "start": 816.0, "end": 820.4, "text": " But we are improving and we will continue to improve.", "tokens": [583, 321, 366, 11470, 293, 321, 486, 2354, 281, 3470, 13], "temperature": 0.0, "avg_logprob": -0.16381461467217961, "compression_ratio": 1.6798418972332017, "no_speech_prob": 2.428706648061052e-05}, {"id": 262, "seek": 80328, "start": 821.6, "end": 827.3199999999999, "text": " The way to improve it lies into mostly getting better training data.", "tokens": [440, 636, 281, 3470, 309, 9134, 666, 5240, 1242, 1101, 3097, 1412, 13], "temperature": 0.0, "avg_logprob": -0.16381461467217961, "compression_ratio": 1.6798418972332017, "no_speech_prob": 2.428706648061052e-05}, {"id": 263, "seek": 80328, "start": 827.3199999999999, "end": 830.1999999999999, "text": " So as we find more and more sources of", "tokens": [407, 382, 321, 915, 544, 293, 544, 7139, 295], "temperature": 0.0, "avg_logprob": -0.16381461467217961, "compression_ratio": 1.6798418972332017, "no_speech_prob": 2.428706648061052e-05}, {"id": 264, "seek": 80328, "start": 830.1999999999999, "end": 832.48, "text": " open data that can be used for translation,", "tokens": [1269, 1412, 300, 393, 312, 1143, 337, 12853, 11], "temperature": 0.0, "avg_logprob": -0.16381461467217961, "compression_ratio": 1.6798418972332017, "no_speech_prob": 2.428706648061052e-05}, {"id": 265, "seek": 83248, "start": 832.48, "end": 834.5600000000001, "text": " we include those into the training of", "tokens": [321, 4090, 729, 666, 264, 3097, 295], "temperature": 0.0, "avg_logprob": -0.134033203125, "compression_ratio": 1.7366071428571428, "no_speech_prob": 2.246266376459971e-05}, {"id": 266, "seek": 83248, "start": 834.5600000000001, "end": 838.48, "text": " the models and that results into better models.", "tokens": [264, 5245, 293, 300, 3542, 666, 1101, 5245, 13], "temperature": 0.0, "avg_logprob": -0.134033203125, "compression_ratio": 1.7366071428571428, "no_speech_prob": 2.246266376459971e-05}, {"id": 267, "seek": 83248, "start": 838.48, "end": 843.08, "text": " This is also an interesting point to note,", "tokens": [639, 307, 611, 364, 1880, 935, 281, 3637, 11], "temperature": 0.0, "avg_logprob": -0.134033203125, "compression_ratio": 1.7366071428571428, "no_speech_prob": 2.246266376459971e-05}, {"id": 268, "seek": 83248, "start": 843.08, "end": 848.5600000000001, "text": " is that because the project is open source and we have a way to train models,", "tokens": [307, 300, 570, 264, 1716, 307, 1269, 4009, 293, 321, 362, 257, 636, 281, 3847, 5245, 11], "temperature": 0.0, "avg_logprob": -0.134033203125, "compression_ratio": 1.7366071428571428, "no_speech_prob": 2.246266376459971e-05}, {"id": 269, "seek": 83248, "start": 848.5600000000001, "end": 852.44, "text": " you can also train models that are specific to a certain domain.", "tokens": [291, 393, 611, 3847, 5245, 300, 366, 2685, 281, 257, 1629, 9274, 13], "temperature": 0.0, "avg_logprob": -0.134033203125, "compression_ratio": 1.7366071428571428, "no_speech_prob": 2.246266376459971e-05}, {"id": 270, "seek": 83248, "start": 852.44, "end": 855.04, "text": " For example, in the context of software translation,", "tokens": [1171, 1365, 11, 294, 264, 4319, 295, 4722, 12853, 11], "temperature": 0.0, "avg_logprob": -0.134033203125, "compression_ratio": 1.7366071428571428, "no_speech_prob": 2.246266376459971e-05}, {"id": 271, "seek": 83248, "start": 855.04, "end": 858.96, "text": " you could imagine the case where instead of training the data on", "tokens": [291, 727, 3811, 264, 1389, 689, 2602, 295, 3097, 264, 1412, 322], "temperature": 0.0, "avg_logprob": -0.134033203125, "compression_ratio": 1.7366071428571428, "no_speech_prob": 2.246266376459971e-05}, {"id": 272, "seek": 85896, "start": 858.96, "end": 867.48, "text": " a general corpus like Wikipedia or the EU Parliament translation documents,", "tokens": [257, 2674, 1181, 31624, 411, 28999, 420, 264, 10887, 15538, 12853, 8512, 11], "temperature": 0.0, "avg_logprob": -0.12330227682035264, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.903876808588393e-05}, {"id": 273, "seek": 85896, "start": 867.48, "end": 871.32, "text": " you could train a model that is specific to software.", "tokens": [291, 727, 3847, 257, 2316, 300, 307, 2685, 281, 4722, 13], "temperature": 0.0, "avg_logprob": -0.12330227682035264, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.903876808588393e-05}, {"id": 274, "seek": 85896, "start": 871.32, "end": 876.4000000000001, "text": " For example, you could take a set of existing translations from", "tokens": [1171, 1365, 11, 291, 727, 747, 257, 992, 295, 6741, 37578, 490], "temperature": 0.0, "avg_logprob": -0.12330227682035264, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.903876808588393e-05}, {"id": 275, "seek": 85896, "start": 876.4000000000001, "end": 879.32, "text": " existing software that has licensed", "tokens": [6741, 4722, 300, 575, 25225], "temperature": 0.0, "avg_logprob": -0.12330227682035264, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.903876808588393e-05}, {"id": 276, "seek": 85896, "start": 879.32, "end": 883.76, "text": " the translation work under an open permissible license and train", "tokens": [264, 12853, 589, 833, 364, 1269, 4784, 41073, 10476, 293, 3847], "temperature": 0.0, "avg_logprob": -0.12330227682035264, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.903876808588393e-05}, {"id": 277, "seek": 85896, "start": 883.76, "end": 887.24, "text": " a model onto those existing translations.", "tokens": [257, 2316, 3911, 729, 6741, 37578, 13], "temperature": 0.0, "avg_logprob": -0.12330227682035264, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.903876808588393e-05}, {"id": 278, "seek": 88724, "start": 887.24, "end": 889.64, "text": " Because we have the knowledge,", "tokens": [1436, 321, 362, 264, 3601, 11], "temperature": 0.0, "avg_logprob": -0.1745830774307251, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.0445118934731e-05}, {"id": 279, "seek": 88724, "start": 889.64, "end": 891.96, "text": " a lot of software has commonalities in terms.", "tokens": [257, 688, 295, 4722, 575, 2689, 16110, 294, 2115, 13], "temperature": 0.0, "avg_logprob": -0.1745830774307251, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.0445118934731e-05}, {"id": 280, "seek": 88724, "start": 891.96, "end": 893.72, "text": " When you have a file menu,", "tokens": [1133, 291, 362, 257, 3991, 6510, 11], "temperature": 0.0, "avg_logprob": -0.1745830774307251, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.0445118934731e-05}, {"id": 281, "seek": 88724, "start": 893.72, "end": 896.28, "text": " it's always called file and then edit.", "tokens": [309, 311, 1009, 1219, 3991, 293, 550, 8129, 13], "temperature": 0.0, "avg_logprob": -0.1745830774307251, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.0445118934731e-05}, {"id": 282, "seek": 88724, "start": 896.28, "end": 900.44, "text": " So those menus are specific to a context.", "tokens": [407, 729, 30347, 366, 2685, 281, 257, 4319, 13], "temperature": 0.0, "avg_logprob": -0.1745830774307251, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.0445118934731e-05}, {"id": 283, "seek": 88724, "start": 900.44, "end": 904.12, "text": " By training models that are specific to a context,", "tokens": [3146, 3097, 5245, 300, 366, 2685, 281, 257, 4319, 11], "temperature": 0.0, "avg_logprob": -0.1745830774307251, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.0445118934731e-05}, {"id": 284, "seek": 88724, "start": 904.12, "end": 906.96, "text": " you could get, for example,", "tokens": [291, 727, 483, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.1745830774307251, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.0445118934731e-05}, {"id": 285, "seek": 88724, "start": 906.96, "end": 912.2, "text": " software translation model that is more accurate in the context of software,", "tokens": [4722, 12853, 2316, 300, 307, 544, 8559, 294, 264, 4319, 295, 4722, 11], "temperature": 0.0, "avg_logprob": -0.1745830774307251, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.0445118934731e-05}, {"id": 286, "seek": 88724, "start": 912.2, "end": 913.84, "text": " rather than say poetry.", "tokens": [2831, 813, 584, 15155, 13], "temperature": 0.0, "avg_logprob": -0.1745830774307251, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.0445118934731e-05}, {"id": 287, "seek": 91384, "start": 913.84, "end": 918.88, "text": " So it's a very interesting thing to think about.", "tokens": [407, 309, 311, 257, 588, 1880, 551, 281, 519, 466, 13], "temperature": 0.0, "avg_logprob": -0.25122975329963526, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.4216762287542224e-05}, {"id": 288, "seek": 91384, "start": 918.88, "end": 921.0, "text": " One more thing about accuracy,", "tokens": [1485, 544, 551, 466, 14170, 11], "temperature": 0.0, "avg_logprob": -0.25122975329963526, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.4216762287542224e-05}, {"id": 289, "seek": 91384, "start": 921.0, "end": 923.5600000000001, "text": " we do have the occasional rare quirk.", "tokens": [321, 360, 362, 264, 31644, 5892, 421, 18610, 13], "temperature": 0.0, "avg_logprob": -0.25122975329963526, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.4216762287542224e-05}, {"id": 290, "seek": 91384, "start": 923.5600000000001, "end": 927.4, "text": " This is something that we are aware of and we are working to fix it.", "tokens": [639, 307, 746, 300, 321, 366, 3650, 295, 293, 321, 366, 1364, 281, 3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.25122975329963526, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.4216762287542224e-05}, {"id": 291, "seek": 91384, "start": 927.4, "end": 931.4, "text": " We like to call it the salad issue.", "tokens": [492, 411, 281, 818, 309, 264, 12604, 2734, 13], "temperature": 0.0, "avg_logprob": -0.25122975329963526, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.4216762287542224e-05}, {"id": 292, "seek": 91384, "start": 931.4, "end": 938.24, "text": " We joke, I will demonstrate this slide because it always sparks a little bit of a giggle.", "tokens": [492, 7647, 11, 286, 486, 11698, 341, 4137, 570, 309, 1009, 44102, 257, 707, 857, 295, 257, 290, 19694, 13], "temperature": 0.0, "avg_logprob": -0.25122975329963526, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.4216762287542224e-05}, {"id": 293, "seek": 91384, "start": 940.8000000000001, "end": 943.36, "text": " It's a little bit rare, but it happens.", "tokens": [467, 311, 257, 707, 857, 5892, 11, 457, 309, 2314, 13], "temperature": 0.0, "avg_logprob": -0.25122975329963526, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.4216762287542224e-05}, {"id": 294, "seek": 94336, "start": 943.36, "end": 946.88, "text": " So in Spanish, the word for salad is ensalada.", "tokens": [407, 294, 8058, 11, 264, 1349, 337, 12604, 307, 3489, 304, 1538, 13], "temperature": 0.0, "avg_logprob": -0.2646380043029785, "compression_ratio": 1.6808510638297873, "no_speech_prob": 9.135349682765082e-05}, {"id": 295, "seek": 94336, "start": 946.88, "end": 951.52, "text": " Now, let's try to translate the word for salads plural.", "tokens": [823, 11, 718, 311, 853, 281, 13799, 264, 1349, 337, 48025, 25377, 13], "temperature": 0.0, "avg_logprob": -0.2646380043029785, "compression_ratio": 1.6808510638297873, "no_speech_prob": 9.135349682765082e-05}, {"id": 296, "seek": 94336, "start": 951.52, "end": 955.08, "text": " So I'm going to type ensaladas.", "tokens": [407, 286, 478, 516, 281, 2010, 3489, 304, 6872, 13], "temperature": 0.0, "avg_logprob": -0.2646380043029785, "compression_ratio": 1.6808510638297873, "no_speech_prob": 9.135349682765082e-05}, {"id": 297, "seek": 94336, "start": 955.08, "end": 958.36, "text": " So in French, that's saladas.", "tokens": [407, 294, 5522, 11, 300, 311, 1845, 6872, 13], "temperature": 0.0, "avg_logprob": -0.2646380043029785, "compression_ratio": 1.6808510638297873, "no_speech_prob": 9.135349682765082e-05}, {"id": 298, "seek": 94336, "start": 958.36, "end": 960.08, "text": " Is that correct? Any French people in the room?", "tokens": [1119, 300, 3006, 30, 2639, 5522, 561, 294, 264, 1808, 30], "temperature": 0.0, "avg_logprob": -0.2646380043029785, "compression_ratio": 1.6808510638297873, "no_speech_prob": 9.135349682765082e-05}, {"id": 299, "seek": 94336, "start": 960.08, "end": 962.32, "text": " Fantastic.", "tokens": [21320, 13], "temperature": 0.0, "avg_logprob": -0.2646380043029785, "compression_ratio": 1.6808510638297873, "no_speech_prob": 9.135349682765082e-05}, {"id": 300, "seek": 94336, "start": 962.32, "end": 965.32, "text": " Now let's try the singular form.", "tokens": [823, 718, 311, 853, 264, 20010, 1254, 13], "temperature": 0.0, "avg_logprob": -0.2646380043029785, "compression_ratio": 1.6808510638297873, "no_speech_prob": 9.135349682765082e-05}, {"id": 301, "seek": 94336, "start": 965.32, "end": 970.04, "text": " I'm going to remove the S and it crunches for a little bit.", "tokens": [286, 478, 516, 281, 4159, 264, 318, 293, 309, 13386, 279, 337, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.2646380043029785, "compression_ratio": 1.6808510638297873, "no_speech_prob": 9.135349682765082e-05}, {"id": 302, "seek": 97004, "start": 970.04, "end": 978.8399999999999, "text": " In a second, it really likes salad.", "tokens": [682, 257, 1150, 11, 309, 534, 5902, 12604, 13], "temperature": 0.0, "avg_logprob": -0.26949211042754506, "compression_ratio": 1.6559139784946237, "no_speech_prob": 7.006005762377754e-05}, {"id": 303, "seek": 97004, "start": 978.8399999999999, "end": 981.8399999999999, "text": " Salad, salad, salad, salad, salad.", "tokens": [5996, 345, 11, 12604, 11, 12604, 11, 12604, 11, 12604, 13], "temperature": 0.0, "avg_logprob": -0.26949211042754506, "compression_ratio": 1.6559139784946237, "no_speech_prob": 7.006005762377754e-05}, {"id": 304, "seek": 97004, "start": 981.8399999999999, "end": 984.56, "text": " This is a quirk. We are aware of it.", "tokens": [639, 307, 257, 421, 18610, 13, 492, 366, 3650, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.26949211042754506, "compression_ratio": 1.6559139784946237, "no_speech_prob": 7.006005762377754e-05}, {"id": 305, "seek": 97004, "start": 984.56, "end": 989.64, "text": " It's very rare, but we've found a few reports here and there and we're working to fix it.", "tokens": [467, 311, 588, 5892, 11, 457, 321, 600, 1352, 257, 1326, 7122, 510, 293, 456, 293, 321, 434, 1364, 281, 3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.26949211042754506, "compression_ratio": 1.6559139784946237, "no_speech_prob": 7.006005762377754e-05}, {"id": 306, "seek": 97004, "start": 989.64, "end": 991.9599999999999, "text": " Just something to be aware of.", "tokens": [1449, 746, 281, 312, 3650, 295, 13], "temperature": 0.0, "avg_logprob": -0.26949211042754506, "compression_ratio": 1.6559139784946237, "no_speech_prob": 7.006005762377754e-05}, {"id": 307, "seek": 97004, "start": 993.16, "end": 995.64, "text": " Yes, it really likes salad.", "tokens": [1079, 11, 309, 534, 5902, 12604, 13], "temperature": 0.0, "avg_logprob": -0.26949211042754506, "compression_ratio": 1.6559139784946237, "no_speech_prob": 7.006005762377754e-05}, {"id": 308, "seek": 97004, "start": 995.64, "end": 1000.0, "text": " Me too. Let's talk a little bit about integrations.", "tokens": [1923, 886, 13, 961, 311, 751, 257, 707, 857, 466, 3572, 763, 13], "temperature": 0.0, "avg_logprob": -0.26949211042754506, "compression_ratio": 1.6559139784946237, "no_speech_prob": 7.006005762377754e-05}, {"id": 309, "seek": 100000, "start": 1000.0, "end": 1007.36, "text": " You can find the client libraries for about 11 programming languages that includes the most common ones like Java, Python,", "tokens": [509, 393, 915, 264, 6423, 15148, 337, 466, 2975, 9410, 8650, 300, 5974, 264, 881, 2689, 2306, 411, 10745, 11, 15329, 11], "temperature": 0.0, "avg_logprob": -0.20888375300987094, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.0005855952040292323}, {"id": 310, "seek": 100000, "start": 1007.36, "end": 1012.4, "text": " whatever your favorite language is, it's probably in the list of bindings.", "tokens": [2035, 428, 2954, 2856, 307, 11, 309, 311, 1391, 294, 264, 1329, 295, 14786, 1109, 13], "temperature": 0.0, "avg_logprob": -0.20888375300987094, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.0005855952040292323}, {"id": 311, "seek": 100000, "start": 1012.4, "end": 1017.2, "text": " And if it's not there, adding new bindings for LibreTranslate is fairly easy.", "tokens": [400, 498, 309, 311, 406, 456, 11, 5127, 777, 14786, 1109, 337, 15834, 265, 33339, 17593, 307, 6457, 1858, 13], "temperature": 0.0, "avg_logprob": -0.20888375300987094, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.0005855952040292323}, {"id": 312, "seek": 100000, "start": 1017.2, "end": 1020.0, "text": " So we welcome contributions, of course.", "tokens": [407, 321, 2928, 15725, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.20888375300987094, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.0005855952040292323}, {"id": 313, "seek": 100000, "start": 1020.0, "end": 1027.0, "text": " As far as software, LibreTranslate has found adoption in several existing open-source software that you may recognize.", "tokens": [1018, 1400, 382, 4722, 11, 15834, 265, 33339, 17593, 575, 1352, 19215, 294, 2940, 6741, 1269, 12, 41676, 4722, 300, 291, 815, 5521, 13], "temperature": 0.0, "avg_logprob": -0.20888375300987094, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.0005855952040292323}, {"id": 314, "seek": 102700, "start": 1027.0, "end": 1031.76, "text": " Mastodon recently added support for translating topics using LibreTranslate.", "tokens": [376, 525, 378, 266, 3938, 3869, 1406, 337, 35030, 8378, 1228, 15834, 265, 33339, 17593, 13], "temperature": 0.0, "avg_logprob": -0.1661737604839046, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00011203671601833776}, {"id": 315, "seek": 102700, "start": 1031.76, "end": 1041.16, "text": " Weblate has the ability to use LibreTranslate to suggest and help translators perform translations as an alternative to using proprietary software.", "tokens": [9573, 17593, 575, 264, 3485, 281, 764, 15834, 265, 33339, 17593, 281, 3402, 293, 854, 5105, 3391, 2042, 37578, 382, 364, 8535, 281, 1228, 38992, 4722, 13], "temperature": 0.0, "avg_logprob": -0.1661737604839046, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00011203671601833776}, {"id": 316, "seek": 102700, "start": 1041.16, "end": 1050.72, "text": " The forum software discourse has a plugin that lets you make your forum software accessible from different locales", "tokens": [440, 17542, 4722, 23938, 575, 257, 23407, 300, 6653, 291, 652, 428, 17542, 4722, 9515, 490, 819, 2654, 279], "temperature": 0.0, "avg_logprob": -0.1661737604839046, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00011203671601833776}, {"id": 317, "seek": 102700, "start": 1050.72, "end": 1054.52, "text": " and lets you translate the posts on the fly.", "tokens": [293, 6653, 291, 13799, 264, 12300, 322, 264, 3603, 13], "temperature": 0.0, "avg_logprob": -0.1661737604839046, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00011203671601833776}, {"id": 318, "seek": 105452, "start": 1054.52, "end": 1060.96, "text": " LibreOffice, I found, has an extension. I didn't know this until a week ago when I was looking who has integrated stuff with LibreTranslate.", "tokens": [15834, 265, 29745, 573, 11, 286, 1352, 11, 575, 364, 10320, 13, 286, 994, 380, 458, 341, 1826, 257, 1243, 2057, 562, 286, 390, 1237, 567, 575, 10919, 1507, 365, 15834, 265, 33339, 17593, 13], "temperature": 0.0, "avg_logprob": -0.12794456197254694, "compression_ratio": 1.7077922077922079, "no_speech_prob": 9.156924352282658e-05}, {"id": 319, "seek": 105452, "start": 1060.96, "end": 1065.96, "text": " But somebody wrote an extension to LibreOffice where you can translate documents on the fly using LibreTranslate.", "tokens": [583, 2618, 4114, 364, 10320, 281, 15834, 265, 29745, 573, 689, 291, 393, 13799, 8512, 322, 264, 3603, 1228, 15834, 265, 33339, 17593, 13], "temperature": 0.0, "avg_logprob": -0.12794456197254694, "compression_ratio": 1.7077922077922079, "no_speech_prob": 9.156924352282658e-05}, {"id": 320, "seek": 105452, "start": 1065.96, "end": 1069.36, "text": " There is an add-on for the multimedia software code.", "tokens": [821, 307, 364, 909, 12, 266, 337, 264, 49202, 4722, 3089, 13], "temperature": 0.0, "avg_logprob": -0.12794456197254694, "compression_ratio": 1.7077922077922079, "no_speech_prob": 9.156924352282658e-05}, {"id": 321, "seek": 105452, "start": 1069.36, "end": 1071.96, "text": " There is an add-on also for Firefox.", "tokens": [821, 307, 364, 909, 12, 266, 611, 337, 46613, 13], "temperature": 0.0, "avg_logprob": -0.12794456197254694, "compression_ratio": 1.7077922077922079, "no_speech_prob": 9.156924352282658e-05}, {"id": 322, "seek": 105452, "start": 1071.96, "end": 1075.56, "text": " And there's probably a lot of other things that I haven't found myself.", "tokens": [400, 456, 311, 1391, 257, 688, 295, 661, 721, 300, 286, 2378, 380, 1352, 2059, 13], "temperature": 0.0, "avg_logprob": -0.12794456197254694, "compression_ratio": 1.7077922077922079, "no_speech_prob": 9.156924352282658e-05}, {"id": 323, "seek": 105452, "start": 1075.56, "end": 1081.76, "text": " But a lot of people seem to be finding the API useful and they're doing integration work, which is fantastic.", "tokens": [583, 257, 688, 295, 561, 1643, 281, 312, 5006, 264, 9362, 4420, 293, 436, 434, 884, 10980, 589, 11, 597, 307, 5456, 13], "temperature": 0.0, "avg_logprob": -0.12794456197254694, "compression_ratio": 1.7077922077922079, "no_speech_prob": 9.156924352282658e-05}, {"id": 324, "seek": 108176, "start": 1081.76, "end": 1088.32, "text": " And there's finally client applications that you can use LibreTranslate with without using the web UI.", "tokens": [400, 456, 311, 2721, 6423, 5821, 300, 291, 393, 764, 15834, 265, 33339, 17593, 365, 1553, 1228, 264, 3670, 15682, 13], "temperature": 0.0, "avg_logprob": -0.19668221147093054, "compression_ratio": 1.5198019801980198, "no_speech_prob": 6.386525637935847e-05}, {"id": 325, "seek": 108176, "start": 1088.32, "end": 1092.32, "text": " And we found we have clients for Android, iOS and desktop.", "tokens": [400, 321, 1352, 321, 362, 6982, 337, 8853, 11, 17430, 293, 14502, 13], "temperature": 0.0, "avg_logprob": -0.19668221147093054, "compression_ratio": 1.5198019801980198, "no_speech_prob": 6.386525637935847e-05}, {"id": 326, "seek": 108176, "start": 1092.32, "end": 1097.32, "text": " And there's more being built by the week.", "tokens": [400, 456, 311, 544, 885, 3094, 538, 264, 1243, 13], "temperature": 0.0, "avg_logprob": -0.19668221147093054, "compression_ratio": 1.5198019801980198, "no_speech_prob": 6.386525637935847e-05}, {"id": 327, "seek": 108176, "start": 1097.32, "end": 1105.76, "text": " As far as comparison to proprietary alternatives, you can see that there is a clear monetary advantage,", "tokens": [1018, 1400, 382, 9660, 281, 38992, 20478, 11, 291, 393, 536, 300, 456, 307, 257, 1850, 26388, 5002, 11], "temperature": 0.0, "avg_logprob": -0.19668221147093054, "compression_ratio": 1.5198019801980198, "no_speech_prob": 6.386525637935847e-05}, {"id": 328, "seek": 110576, "start": 1105.76, "end": 1112.16, "text": " aside from the philosophical reason for why you might want to use open-source software, of course.", "tokens": [7359, 490, 264, 25066, 1778, 337, 983, 291, 1062, 528, 281, 764, 1269, 12, 41676, 4722, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.16438251071506077, "compression_ratio": 1.63671875, "no_speech_prob": 0.00012137122394051403}, {"id": 329, "seek": 110576, "start": 1112.16, "end": 1120.16, "text": " But it could also be a really sustainable way to perform translations in that people often ask me,", "tokens": [583, 309, 727, 611, 312, 257, 534, 11235, 636, 281, 2042, 37578, 294, 300, 561, 2049, 1029, 385, 11], "temperature": 0.0, "avg_logprob": -0.16438251071506077, "compression_ratio": 1.63671875, "no_speech_prob": 0.00012137122394051403}, {"id": 330, "seek": 110576, "start": 1120.16, "end": 1123.36, "text": " why should I use LibreTranslate? I can use Google Translate for free.", "tokens": [983, 820, 286, 764, 15834, 265, 33339, 17593, 30, 286, 393, 764, 3329, 6531, 17593, 337, 1737, 13], "temperature": 0.0, "avg_logprob": -0.16438251071506077, "compression_ratio": 1.63671875, "no_speech_prob": 0.00012137122394051403}, {"id": 331, "seek": 110576, "start": 1123.36, "end": 1128.16, "text": " I just go on translate.google.com and it doesn't charge me anything. So why should I care?", "tokens": [286, 445, 352, 322, 13799, 13, 1571, 3127, 13, 1112, 293, 309, 1177, 380, 4602, 385, 1340, 13, 407, 983, 820, 286, 1127, 30], "temperature": 0.0, "avg_logprob": -0.16438251071506077, "compression_ratio": 1.63671875, "no_speech_prob": 0.00012137122394051403}, {"id": 332, "seek": 110576, "start": 1128.16, "end": 1132.16, "text": " Google Translate is free so long as you're using it by hand.", "tokens": [3329, 6531, 17593, 307, 1737, 370, 938, 382, 291, 434, 1228, 309, 538, 1011, 13], "temperature": 0.0, "avg_logprob": -0.16438251071506077, "compression_ratio": 1.63671875, "no_speech_prob": 0.00012137122394051403}, {"id": 333, "seek": 113216, "start": 1132.16, "end": 1137.76, "text": " If you want to do any automation work and you have to tap into their API, you're going to pay dearly.", "tokens": [759, 291, 528, 281, 360, 604, 17769, 589, 293, 291, 362, 281, 5119, 666, 641, 9362, 11, 291, 434, 516, 281, 1689, 6875, 356, 13], "temperature": 0.0, "avg_logprob": -0.1064609920277315, "compression_ratio": 1.616326530612245, "no_speech_prob": 6.00423663854599e-05}, {"id": 334, "seek": 113216, "start": 1137.76, "end": 1143.96, "text": " And you can see here a list of the prices and I can assure you that one million characters seem like a lot,", "tokens": [400, 291, 393, 536, 510, 257, 1329, 295, 264, 7901, 293, 286, 393, 20968, 291, 300, 472, 2459, 4342, 1643, 411, 257, 688, 11], "temperature": 0.0, "avg_logprob": -0.1064609920277315, "compression_ratio": 1.616326530612245, "no_speech_prob": 6.00423663854599e-05}, {"id": 335, "seek": 113216, "start": 1143.96, "end": 1152.96, "text": " that's six zeros, but they actually run pretty fast and so could the bill on your credit card.", "tokens": [300, 311, 2309, 35193, 11, 457, 436, 767, 1190, 1238, 2370, 293, 370, 727, 264, 2961, 322, 428, 5397, 2920, 13], "temperature": 0.0, "avg_logprob": -0.1064609920277315, "compression_ratio": 1.616326530612245, "no_speech_prob": 6.00423663854599e-05}, {"id": 336, "seek": 113216, "start": 1152.96, "end": 1160.76, "text": " So if you have a lot of text to translate, LibreTranslate could really help in that regard.", "tokens": [407, 498, 291, 362, 257, 688, 295, 2487, 281, 13799, 11, 15834, 265, 33339, 17593, 727, 534, 854, 294, 300, 3843, 13], "temperature": 0.0, "avg_logprob": -0.1064609920277315, "compression_ratio": 1.616326530612245, "no_speech_prob": 6.00423663854599e-05}, {"id": 337, "seek": 116076, "start": 1160.76, "end": 1166.56, "text": " As far as funding goes, the project is on the path to become fully self-funded.", "tokens": [1018, 1400, 382, 6137, 1709, 11, 264, 1716, 307, 322, 264, 3100, 281, 1813, 4498, 2698, 12, 43589, 13], "temperature": 0.0, "avg_logprob": -0.06213735852922712, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.00011558824917301536}, {"id": 338, "seek": 116076, "start": 1166.56, "end": 1171.36, "text": " And we really care about this because we want the project to continue living on.", "tokens": [400, 321, 534, 1127, 466, 341, 570, 321, 528, 264, 1716, 281, 2354, 2647, 322, 13], "temperature": 0.0, "avg_logprob": -0.06213735852922712, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.00011558824917301536}, {"id": 339, "seek": 116076, "start": 1171.36, "end": 1176.16, "text": " We, of course, accept sponsorships and donations, but honestly,", "tokens": [492, 11, 295, 1164, 11, 3241, 22593, 7640, 293, 22705, 11, 457, 6095, 11], "temperature": 0.0, "avg_logprob": -0.06213735852922712, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.00011558824917301536}, {"id": 340, "seek": 116076, "start": 1176.16, "end": 1181.36, "text": " we would rather prefer that you get something back if you decide to contribute financially to the project.", "tokens": [321, 576, 2831, 4382, 300, 291, 483, 746, 646, 498, 291, 4536, 281, 10586, 20469, 281, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.06213735852922712, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.00011558824917301536}, {"id": 341, "seek": 116076, "start": 1181.36, "end": 1188.36, "text": " This is why if you are in the position where you say, I have some finances to spare and help support the project,", "tokens": [639, 307, 983, 498, 291, 366, 294, 264, 2535, 689, 291, 584, 11, 286, 362, 512, 25123, 281, 13798, 293, 854, 1406, 264, 1716, 11], "temperature": 0.0, "avg_logprob": -0.06213735852922712, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.00011558824917301536}, {"id": 342, "seek": 118836, "start": 1188.36, "end": 1198.1599999999999, "text": " you also get something back and we do that in the form of offering you an API key to use a host distance at LibreTranslate.com.", "tokens": [291, 611, 483, 746, 646, 293, 321, 360, 300, 294, 264, 1254, 295, 8745, 291, 364, 9362, 2141, 281, 764, 257, 3975, 4560, 412, 15834, 265, 33339, 17593, 13, 1112, 13], "temperature": 0.0, "avg_logprob": -0.06142704373314267, "compression_ratio": 1.604, "no_speech_prob": 3.1177471100818366e-05}, {"id": 343, "seek": 118836, "start": 1198.1599999999999, "end": 1204.9599999999998, "text": " So you are free to run the infrastructure on your own server, on your Raspberry Pi, on any machine that you'd like.", "tokens": [407, 291, 366, 1737, 281, 1190, 264, 6896, 322, 428, 1065, 7154, 11, 322, 428, 41154, 17741, 11, 322, 604, 3479, 300, 291, 1116, 411, 13], "temperature": 0.0, "avg_logprob": -0.06142704373314267, "compression_ratio": 1.604, "no_speech_prob": 3.1177471100818366e-05}, {"id": 344, "seek": 118836, "start": 1204.9599999999998, "end": 1212.36, "text": " If you don't want to handle that, you can just get an API key and you can support the project at the same time.", "tokens": [759, 291, 500, 380, 528, 281, 4813, 300, 11, 291, 393, 445, 483, 364, 9362, 2141, 293, 291, 393, 1406, 264, 1716, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.06142704373314267, "compression_ratio": 1.604, "no_speech_prob": 3.1177471100818366e-05}, {"id": 345, "seek": 118836, "start": 1212.36, "end": 1215.56, "text": " So it's really a good way to contribute back.", "tokens": [407, 309, 311, 534, 257, 665, 636, 281, 10586, 646, 13], "temperature": 0.0, "avg_logprob": -0.06142704373314267, "compression_ratio": 1.604, "no_speech_prob": 3.1177471100818366e-05}, {"id": 346, "seek": 121556, "start": 1215.56, "end": 1220.96, "text": " And we found that that model has been helping us grow and sustain the project.", "tokens": [400, 321, 1352, 300, 300, 2316, 575, 668, 4315, 505, 1852, 293, 6769, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.07220147053400676, "compression_ratio": 1.5510204081632653, "no_speech_prob": 3.5303768527228385e-05}, {"id": 347, "seek": 121556, "start": 1220.96, "end": 1226.1599999999999, "text": " So we hope to continue growing as much next year.", "tokens": [407, 321, 1454, 281, 2354, 4194, 382, 709, 958, 1064, 13], "temperature": 0.0, "avg_logprob": -0.07220147053400676, "compression_ratio": 1.5510204081632653, "no_speech_prob": 3.5303768527228385e-05}, {"id": 348, "seek": 121556, "start": 1226.1599999999999, "end": 1229.96, "text": " Again, to get involved, I'll give you a few quick numbers.", "tokens": [3764, 11, 281, 483, 3288, 11, 286, 603, 976, 291, 257, 1326, 1702, 3547, 13], "temperature": 0.0, "avg_logprob": -0.07220147053400676, "compression_ratio": 1.5510204081632653, "no_speech_prob": 3.5303768527228385e-05}, {"id": 349, "seek": 121556, "start": 1229.96, "end": 1234.1599999999999, "text": " We've had about 70 people contribute to the code base over the last few years.", "tokens": [492, 600, 632, 466, 5285, 561, 10586, 281, 264, 3089, 3096, 670, 264, 1036, 1326, 924, 13], "temperature": 0.0, "avg_logprob": -0.07220147053400676, "compression_ratio": 1.5510204081632653, "no_speech_prob": 3.5303768527228385e-05}, {"id": 350, "seek": 121556, "start": 1234.1599999999999, "end": 1240.96, "text": " The project is still very young, but it has really received a lot of attention, so we're very excited about that.", "tokens": [440, 1716, 307, 920, 588, 2037, 11, 457, 309, 575, 534, 4613, 257, 688, 295, 3202, 11, 370, 321, 434, 588, 2919, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.07220147053400676, "compression_ratio": 1.5510204081632653, "no_speech_prob": 3.5303768527228385e-05}, {"id": 351, "seek": 124096, "start": 1240.96, "end": 1248.76, "text": " You can help with code. If you're a Python programmer, if you know HTML, CSS, any of the technologies that we use, you're welcome to contribute.", "tokens": [509, 393, 854, 365, 3089, 13, 759, 291, 434, 257, 15329, 32116, 11, 498, 291, 458, 17995, 11, 24387, 11, 604, 295, 264, 7943, 300, 321, 764, 11, 291, 434, 2928, 281, 10586, 13], "temperature": 0.0, "avg_logprob": -0.06924291757436898, "compression_ratio": 1.6282051282051282, "no_speech_prob": 9.58185555646196e-05}, {"id": 352, "seek": 124096, "start": 1248.76, "end": 1251.8600000000001, "text": " We are open to everybody and all ideas.", "tokens": [492, 366, 1269, 281, 2201, 293, 439, 3487, 13], "temperature": 0.0, "avg_logprob": -0.06924291757436898, "compression_ratio": 1.6282051282051282, "no_speech_prob": 9.58185555646196e-05}, {"id": 353, "seek": 124096, "start": 1251.8600000000001, "end": 1254.56, "text": " You can also help us translate.", "tokens": [509, 393, 611, 854, 505, 13799, 13], "temperature": 0.0, "avg_logprob": -0.06924291757436898, "compression_ratio": 1.6282051282051282, "no_speech_prob": 9.58185555646196e-05}, {"id": 354, "seek": 124096, "start": 1254.56, "end": 1265.16, "text": " If you understand English and you don't see your language in the list of languages that we currently support for your user interface, you are welcome to contribute.", "tokens": [759, 291, 1223, 3669, 293, 291, 500, 380, 536, 428, 2856, 294, 264, 1329, 295, 8650, 300, 321, 4362, 1406, 337, 428, 4195, 9226, 11, 291, 366, 2928, 281, 10586, 13], "temperature": 0.0, "avg_logprob": -0.06924291757436898, "compression_ratio": 1.6282051282051282, "no_speech_prob": 9.58185555646196e-05}, {"id": 355, "seek": 126516, "start": 1265.16, "end": 1272.3600000000001, "text": " It's on a web late, you can simply translate and it will get included into the project every 24 hours.", "tokens": [467, 311, 322, 257, 3670, 3469, 11, 291, 393, 2935, 13799, 293, 309, 486, 483, 5556, 666, 264, 1716, 633, 4022, 2496, 13], "temperature": 0.0, "avg_logprob": -0.08481207489967346, "compression_ratio": 1.7623318385650224, "no_speech_prob": 3.58769902959466e-05}, {"id": 356, "seek": 126516, "start": 1272.3600000000001, "end": 1274.96, "text": " So that is really amazing.", "tokens": [407, 300, 307, 534, 2243, 13], "temperature": 0.0, "avg_logprob": -0.08481207489967346, "compression_ratio": 1.7623318385650224, "no_speech_prob": 3.58769902959466e-05}, {"id": 357, "seek": 126516, "start": 1274.96, "end": 1278.16, "text": " You can also help us train more language models.", "tokens": [509, 393, 611, 854, 505, 3847, 544, 2856, 5245, 13], "temperature": 0.0, "avg_logprob": -0.08481207489967346, "compression_ratio": 1.7623318385650224, "no_speech_prob": 3.58769902959466e-05}, {"id": 358, "seek": 126516, "start": 1278.16, "end": 1288.46, "text": " If your language is not available or a language that you care about is not available, you can yourself create a new model for a language and add that into the list.", "tokens": [759, 428, 2856, 307, 406, 2435, 420, 257, 2856, 300, 291, 1127, 466, 307, 406, 2435, 11, 291, 393, 1803, 1884, 257, 777, 2316, 337, 257, 2856, 293, 909, 300, 666, 264, 1329, 13], "temperature": 0.0, "avg_logprob": -0.08481207489967346, "compression_ratio": 1.7623318385650224, "no_speech_prob": 3.58769902959466e-05}, {"id": 359, "seek": 126516, "start": 1288.46, "end": 1291.0600000000002, "text": " So that is also another way that people can help.", "tokens": [407, 300, 307, 611, 1071, 636, 300, 561, 393, 854, 13], "temperature": 0.0, "avg_logprob": -0.08481207489967346, "compression_ratio": 1.7623318385650224, "no_speech_prob": 3.58769902959466e-05}, {"id": 360, "seek": 129106, "start": 1291.06, "end": 1297.56, "text": " You can report bugs, of course. If you don't report salad, we are aware of it.", "tokens": [509, 393, 2275, 15120, 11, 295, 1164, 13, 759, 291, 500, 380, 2275, 12604, 11, 321, 366, 3650, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.11326451050607782, "compression_ratio": 1.6330645161290323, "no_speech_prob": 7.814028504071757e-05}, {"id": 361, "seek": 129106, "start": 1297.56, "end": 1298.76, "text": " Or just come say hi.", "tokens": [1610, 445, 808, 584, 4879, 13], "temperature": 0.0, "avg_logprob": -0.11326451050607782, "compression_ratio": 1.6330645161290323, "no_speech_prob": 7.814028504071757e-05}, {"id": 362, "seek": 129106, "start": 1298.76, "end": 1306.36, "text": " We have a community forum that is quickly growing and we love to hear what you're building with it, what you're using, or if you have any questions.", "tokens": [492, 362, 257, 1768, 17542, 300, 307, 2661, 4194, 293, 321, 959, 281, 1568, 437, 291, 434, 2390, 365, 309, 11, 437, 291, 434, 1228, 11, 420, 498, 291, 362, 604, 1651, 13], "temperature": 0.0, "avg_logprob": -0.11326451050607782, "compression_ratio": 1.6330645161290323, "no_speech_prob": 7.814028504071757e-05}, {"id": 363, "seek": 129106, "start": 1306.36, "end": 1311.76, "text": " So we're very, very open and we're excited to hear what you will do with it.", "tokens": [407, 321, 434, 588, 11, 588, 1269, 293, 321, 434, 2919, 281, 1568, 437, 291, 486, 360, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.11326451050607782, "compression_ratio": 1.6330645161290323, "no_speech_prob": 7.814028504071757e-05}, {"id": 364, "seek": 129106, "start": 1311.76, "end": 1314.36, "text": " That said, this was the last slide.", "tokens": [663, 848, 11, 341, 390, 264, 1036, 4137, 13], "temperature": 0.0, "avg_logprob": -0.11326451050607782, "compression_ratio": 1.6330645161290323, "no_speech_prob": 7.814028504071757e-05}, {"id": 365, "seek": 129106, "start": 1314.36, "end": 1317.1599999999999, "text": " I think we have some time left over, right?", "tokens": [286, 519, 321, 362, 512, 565, 1411, 670, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.11326451050607782, "compression_ratio": 1.6330645161290323, "no_speech_prob": 7.814028504071757e-05}, {"id": 366, "seek": 131716, "start": 1317.16, "end": 1322.16, "text": " So I will.", "tokens": [407, 286, 486, 13], "temperature": 0.0, "avg_logprob": -0.376011150986401, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.0015059070428833365}, {"id": 367, "seek": 131716, "start": 1322.16, "end": 1323.76, "text": " So thank you very much.", "tokens": [407, 1309, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.376011150986401, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.0015059070428833365}, {"id": 368, "seek": 131716, "start": 1323.76, "end": 1325.96, "text": " I will open the floor for questions and discussion.", "tokens": [286, 486, 1269, 264, 4123, 337, 1651, 293, 5017, 13], "temperature": 0.0, "avg_logprob": -0.376011150986401, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.0015059070428833365}, {"id": 369, "seek": 131716, "start": 1325.96, "end": 1328.3600000000001, "text": " So yes.", "tokens": [407, 2086, 13], "temperature": 0.0, "avg_logprob": -0.376011150986401, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.0015059070428833365}, {"id": 370, "seek": 131716, "start": 1328.3600000000001, "end": 1340.76, "text": " Hi, my best friend cannot miss the Vice President of the Austrian Society for Artificial Intelligence sitting with Foster to find volunteers to do exactly what you're doing.", "tokens": [2421, 11, 452, 1151, 1277, 2644, 1713, 264, 13276, 3117, 295, 264, 41507, 13742, 337, 5735, 10371, 27274, 3798, 365, 38756, 281, 915, 14352, 281, 360, 2293, 437, 291, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.376011150986401, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.0015059070428833365}, {"id": 371, "seek": 134076, "start": 1340.76, "end": 1347.76, "text": " Thank you. We're glad to be able to help.", "tokens": [1044, 291, 13, 492, 434, 5404, 281, 312, 1075, 281, 854, 13], "temperature": 0.0, "avg_logprob": -0.38976804221548683, "compression_ratio": 1.518348623853211, "no_speech_prob": 0.0017273558769375086}, {"id": 372, "seek": 134076, "start": 1347.76, "end": 1348.76, "text": " You're welcome.", "tokens": [509, 434, 2928, 13], "temperature": 0.0, "avg_logprob": -0.38976804221548683, "compression_ratio": 1.518348623853211, "no_speech_prob": 0.0017273558769375086}, {"id": 373, "seek": 134076, "start": 1348.76, "end": 1354.56, "text": " How do we find, well, I just named the thing Open Language Model Training Army.", "tokens": [1012, 360, 321, 915, 11, 731, 11, 286, 445, 4926, 264, 551, 7238, 24445, 17105, 20620, 9583, 13], "temperature": 0.0, "avg_logprob": -0.38976804221548683, "compression_ratio": 1.518348623853211, "no_speech_prob": 0.0017273558769375086}, {"id": 374, "seek": 134076, "start": 1354.56, "end": 1356.96, "text": " How do we find more volunteers?", "tokens": [1012, 360, 321, 915, 544, 14352, 30], "temperature": 0.0, "avg_logprob": -0.38976804221548683, "compression_ratio": 1.518348623853211, "no_speech_prob": 0.0017273558769375086}, {"id": 375, "seek": 134076, "start": 1356.96, "end": 1367.26, "text": " Unemployed people, maybe have the government fund people running training models, maybe suggest that to all politicians, everybody to their member of parliament.", "tokens": [1156, 12112, 292, 561, 11, 1310, 362, 264, 2463, 2374, 561, 2614, 3097, 5245, 11, 1310, 3402, 300, 281, 439, 14756, 11, 2201, 281, 641, 4006, 295, 19520, 13], "temperature": 0.0, "avg_logprob": -0.38976804221548683, "compression_ratio": 1.518348623853211, "no_speech_prob": 0.0017273558769375086}, {"id": 376, "seek": 136726, "start": 1367.26, "end": 1371.66, "text": " How many people do we have here?", "tokens": [1012, 867, 561, 360, 321, 362, 510, 30], "temperature": 0.0, "avg_logprob": -0.21634361630394344, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.003957546316087246}, {"id": 377, "seek": 136726, "start": 1371.66, "end": 1375.06, "text": " Should be all of Europe at least, maybe South America.", "tokens": [6454, 312, 439, 295, 3315, 412, 1935, 11, 1310, 4242, 3374, 13], "temperature": 0.0, "avg_logprob": -0.21634361630394344, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.003957546316087246}, {"id": 378, "seek": 136726, "start": 1375.06, "end": 1378.76, "text": " I think if we multiply this, it can go viral.", "tokens": [286, 519, 498, 321, 12972, 341, 11, 309, 393, 352, 16132, 13], "temperature": 0.0, "avg_logprob": -0.21634361630394344, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.003957546316087246}, {"id": 379, "seek": 136726, "start": 1378.76, "end": 1379.96, "text": " Thank you very much.", "tokens": [1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.21634361630394344, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.003957546316087246}, {"id": 380, "seek": 136726, "start": 1379.96, "end": 1381.06, "text": " This is awesome work.", "tokens": [639, 307, 3476, 589, 13], "temperature": 0.0, "avg_logprob": -0.21634361630394344, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.003957546316087246}, {"id": 381, "seek": 136726, "start": 1381.06, "end": 1381.36, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.21634361630394344, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.003957546316087246}, {"id": 382, "seek": 136726, "start": 1381.36, "end": 1383.36, "text": " I appreciate it.", "tokens": [286, 4449, 309, 13], "temperature": 0.0, "avg_logprob": -0.21634361630394344, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.003957546316087246}, {"id": 383, "seek": 136726, "start": 1383.36, "end": 1390.26, "text": " Yes, but you speak of our language that have the same link, the same structure of the language.", "tokens": [1079, 11, 457, 291, 1710, 295, 527, 2856, 300, 362, 264, 912, 2113, 11, 264, 912, 3877, 295, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.21634361630394344, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.003957546316087246}, {"id": 384, "seek": 136726, "start": 1390.26, "end": 1395.46, "text": " We have French, English, Spanish, Portuguese, maybe Russian and Ukrainian.", "tokens": [492, 362, 5522, 11, 3669, 11, 8058, 11, 22759, 11, 1310, 7220, 293, 24682, 13], "temperature": 0.0, "avg_logprob": -0.21634361630394344, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.003957546316087246}, {"id": 385, "seek": 139546, "start": 1395.46, "end": 1400.56, "text": " I do not have the same structure, but the language not far away from here.", "tokens": [286, 360, 406, 362, 264, 912, 3877, 11, 457, 264, 2856, 406, 1400, 1314, 490, 510, 13], "temperature": 0.0, "avg_logprob": -0.41999899622905684, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0033131937962025404}, {"id": 386, "seek": 139546, "start": 1400.56, "end": 1402.46, "text": " That's the difference.", "tokens": [663, 311, 264, 2649, 13], "temperature": 0.0, "avg_logprob": -0.41999899622905684, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0033131937962025404}, {"id": 387, "seek": 139546, "start": 1402.46, "end": 1404.66, "text": " German also.", "tokens": [6521, 611, 13], "temperature": 0.0, "avg_logprob": -0.41999899622905684, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0033131937962025404}, {"id": 388, "seek": 139546, "start": 1404.66, "end": 1406.16, "text": " Correct.", "tokens": [12753, 13], "temperature": 0.0, "avg_logprob": -0.41999899622905684, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0033131937962025404}, {"id": 389, "seek": 139546, "start": 1406.16, "end": 1412.56, "text": " And so taking this in account, it's not easy for a translator, for them to translate it.", "tokens": [400, 370, 1940, 341, 294, 2696, 11, 309, 311, 406, 1858, 337, 257, 35223, 11, 337, 552, 281, 13799, 309, 13], "temperature": 0.0, "avg_logprob": -0.41999899622905684, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0033131937962025404}, {"id": 390, "seek": 139546, "start": 1412.56, "end": 1413.16, "text": " It is not.", "tokens": [467, 307, 406, 13], "temperature": 0.0, "avg_logprob": -0.41999899622905684, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0033131937962025404}, {"id": 391, "seek": 139546, "start": 1413.16, "end": 1418.3600000000001, "text": " There's also maybe a problem with Chinese or Japanese.", "tokens": [821, 311, 611, 1310, 257, 1154, 365, 4649, 420, 5433, 13], "temperature": 0.0, "avg_logprob": -0.41999899622905684, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0033131937962025404}, {"id": 392, "seek": 139546, "start": 1418.3600000000001, "end": 1419.26, "text": " Correct.", "tokens": [12753, 13], "temperature": 0.0, "avg_logprob": -0.41999899622905684, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0033131937962025404}, {"id": 393, "seek": 141926, "start": 1419.26, "end": 1430.76, "text": " There was a problem, there was a thing I went to say, it's a dictionary in line or in the program to have the good word because it's not translated every time the good word.", "tokens": [821, 390, 257, 1154, 11, 456, 390, 257, 551, 286, 1437, 281, 584, 11, 309, 311, 257, 25890, 294, 1622, 420, 294, 264, 1461, 281, 362, 264, 665, 1349, 570, 309, 311, 406, 16805, 633, 565, 264, 665, 1349, 13], "temperature": 0.0, "avg_logprob": -0.20324499300210783, "compression_ratio": 1.625, "no_speech_prob": 0.0010885114315897226}, {"id": 394, "seek": 141926, "start": 1430.76, "end": 1437.16, "text": " And so I thought also the most efficient people's language is Esperanto, not English.", "tokens": [400, 370, 286, 1194, 611, 264, 881, 7148, 561, 311, 2856, 307, 24142, 5857, 11, 406, 3669, 13], "temperature": 0.0, "avg_logprob": -0.20324499300210783, "compression_ratio": 1.625, "no_speech_prob": 0.0010885114315897226}, {"id": 395, "seek": 141926, "start": 1437.16, "end": 1438.86, "text": " Oh, that is very interesting.", "tokens": [876, 11, 300, 307, 588, 1880, 13], "temperature": 0.0, "avg_logprob": -0.20324499300210783, "compression_ratio": 1.625, "no_speech_prob": 0.0010885114315897226}, {"id": 396, "seek": 141926, "start": 1438.86, "end": 1439.46, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.20324499300210783, "compression_ratio": 1.625, "no_speech_prob": 0.0010885114315897226}, {"id": 397, "seek": 141926, "start": 1439.46, "end": 1440.16, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.20324499300210783, "compression_ratio": 1.625, "no_speech_prob": 0.0010885114315897226}, {"id": 398, "seek": 141926, "start": 1440.16, "end": 1442.36, "text": " Yeah, that's a great insight.", "tokens": [865, 11, 300, 311, 257, 869, 11269, 13], "temperature": 0.0, "avg_logprob": -0.20324499300210783, "compression_ratio": 1.625, "no_speech_prob": 0.0010885114315897226}, {"id": 399, "seek": 141926, "start": 1442.36, "end": 1444.76, "text": " Yeah, thank you for sharing that.", "tokens": [865, 11, 1309, 291, 337, 5414, 300, 13], "temperature": 0.0, "avg_logprob": -0.20324499300210783, "compression_ratio": 1.625, "no_speech_prob": 0.0010885114315897226}, {"id": 400, "seek": 144476, "start": 1444.76, "end": 1453.56, "text": " And you're completely right, some languages don't share the same semantical structure and Dutch, for example, currently doesn't score super high.", "tokens": [400, 291, 434, 2584, 558, 11, 512, 8650, 500, 380, 2073, 264, 912, 4361, 394, 804, 3877, 293, 15719, 11, 337, 1365, 11, 4362, 1177, 380, 6175, 1687, 1090, 13], "temperature": 0.0, "avg_logprob": -0.1137803660498725, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.0005098680849187076}, {"id": 401, "seek": 144476, "start": 1453.56, "end": 1458.16, "text": " It's actually one of the bottom 17% of the language models in the blue score.", "tokens": [467, 311, 767, 472, 295, 264, 2767, 3282, 4, 295, 264, 2856, 5245, 294, 264, 3344, 6175, 13], "temperature": 0.0, "avg_logprob": -0.1137803660498725, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.0005098680849187076}, {"id": 402, "seek": 144476, "start": 1458.16, "end": 1460.66, "text": " Dutch scored around 38%.", "tokens": [15719, 18139, 926, 12843, 6856], "temperature": 0.0, "avg_logprob": -0.1137803660498725, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.0005098680849187076}, {"id": 403, "seek": 144476, "start": 1460.66, "end": 1468.86, "text": " So it's almost good, but we've had some Dutch speaking people come to us and say, you know, it's like equal use improvement.", "tokens": [407, 309, 311, 1920, 665, 11, 457, 321, 600, 632, 512, 15719, 4124, 561, 808, 281, 505, 293, 584, 11, 291, 458, 11, 309, 311, 411, 2681, 764, 10444, 13], "temperature": 0.0, "avg_logprob": -0.1137803660498725, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.0005098680849187076}, {"id": 404, "seek": 144476, "start": 1468.86, "end": 1471.46, "text": " So Dutch, yes, it is a language that needs improvement.", "tokens": [407, 15719, 11, 2086, 11, 309, 307, 257, 2856, 300, 2203, 10444, 13], "temperature": 0.0, "avg_logprob": -0.1137803660498725, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.0005098680849187076}, {"id": 405, "seek": 147146, "start": 1471.46, "end": 1480.06, "text": " And I talked to the maintainer of Argus translate about the languages that need improvement.", "tokens": [400, 286, 2825, 281, 264, 6909, 260, 295, 1587, 21956, 13799, 466, 264, 8650, 300, 643, 10444, 13], "temperature": 0.0, "avg_logprob": -0.11743594098974157, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.00016691768541932106}, {"id": 406, "seek": 147146, "start": 1480.06, "end": 1486.3600000000001, "text": " And he pretty much suggested that better training data will help greatly.", "tokens": [400, 415, 1238, 709, 10945, 300, 1101, 3097, 1412, 486, 854, 14147, 13], "temperature": 0.0, "avg_logprob": -0.11743594098974157, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.00016691768541932106}, {"id": 407, "seek": 147146, "start": 1486.3600000000001, "end": 1491.66, "text": " So it is mainly a problem, not of the architecture of the AI.", "tokens": [407, 309, 307, 8704, 257, 1154, 11, 406, 295, 264, 9482, 295, 264, 7318, 13], "temperature": 0.0, "avg_logprob": -0.11743594098974157, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.00016691768541932106}, {"id": 408, "seek": 149166, "start": 1491.66, "end": 1501.76, "text": " It's a matter that we don't have sufficient quality, high quality data between, say, English and Dutch to get above 38% currently.", "tokens": [467, 311, 257, 1871, 300, 321, 500, 380, 362, 11563, 3125, 11, 1090, 3125, 1412, 1296, 11, 584, 11, 3669, 293, 15719, 281, 483, 3673, 12843, 4, 4362, 13], "temperature": 0.0, "avg_logprob": -0.1360231263296945, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.0001051174258464016}, {"id": 409, "seek": 149166, "start": 1501.76, "end": 1504.96, "text": " But again, nobody has really focused on Dutch as a language.", "tokens": [583, 797, 11, 5079, 575, 534, 5178, 322, 15719, 382, 257, 2856, 13], "temperature": 0.0, "avg_logprob": -0.1360231263296945, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.0001051174258464016}, {"id": 410, "seek": 149166, "start": 1504.96, "end": 1510.8600000000001, "text": " If anybody has an interest in improving Dutch, we can do better.", "tokens": [759, 4472, 575, 364, 1179, 294, 11470, 15719, 11, 321, 393, 360, 1101, 13], "temperature": 0.0, "avg_logprob": -0.1360231263296945, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.0001051174258464016}, {"id": 411, "seek": 149166, "start": 1510.8600000000001, "end": 1516.46, "text": " Surprisingly, fantastic.", "tokens": [49908, 11, 5456, 13], "temperature": 0.0, "avg_logprob": -0.1360231263296945, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.0001051174258464016}, {"id": 412, "seek": 151646, "start": 1516.46, "end": 1521.96, "text": " But as far as, for example, languages like German, LibreTranslate currently does very well with German.", "tokens": [583, 382, 1400, 382, 11, 337, 1365, 11, 8650, 411, 6521, 11, 15834, 265, 33339, 17593, 4362, 775, 588, 731, 365, 6521, 13], "temperature": 0.0, "avg_logprob": -0.2198664647228313, "compression_ratio": 1.565891472868217, "no_speech_prob": 9.882193990051746e-05}, {"id": 413, "seek": 151646, "start": 1521.96, "end": 1524.46, "text": " It's above 50, if I remember correctly.", "tokens": [467, 311, 3673, 2625, 11, 498, 286, 1604, 8944, 13], "temperature": 0.0, "avg_logprob": -0.2198664647228313, "compression_ratio": 1.565891472868217, "no_speech_prob": 9.882193990051746e-05}, {"id": 414, "seek": 151646, "start": 1524.46, "end": 1527.3600000000001, "text": " Is it because German is the similar language to Dutch?", "tokens": [1119, 309, 570, 6521, 307, 264, 2531, 2856, 281, 15719, 30], "temperature": 0.0, "avg_logprob": -0.2198664647228313, "compression_ratio": 1.565891472868217, "no_speech_prob": 9.882193990051746e-05}, {"id": 415, "seek": 151646, "start": 1527.3600000000001, "end": 1528.3600000000001, "text": " It is.", "tokens": [467, 307, 13], "temperature": 0.0, "avg_logprob": -0.2198664647228313, "compression_ratio": 1.565891472868217, "no_speech_prob": 9.882193990051746e-05}, {"id": 416, "seek": 151646, "start": 1528.3600000000001, "end": 1535.56, "text": " That is because I believe, and I think PJ, that's the name of the maintainer of Argus translate,", "tokens": [663, 307, 570, 286, 1697, 11, 293, 286, 519, 30549, 11, 300, 311, 264, 1315, 295, 264, 6909, 260, 295, 1587, 21956, 13799, 11], "temperature": 0.0, "avg_logprob": -0.2198664647228313, "compression_ratio": 1.565891472868217, "no_speech_prob": 9.882193990051746e-05}, {"id": 417, "seek": 151646, "start": 1535.56, "end": 1545.46, "text": " because the German model has had a larger amount of training data, and so it tends to perform better.", "tokens": [570, 264, 6521, 2316, 575, 632, 257, 4833, 2372, 295, 3097, 1412, 11, 293, 370, 309, 12258, 281, 2042, 1101, 13], "temperature": 0.0, "avg_logprob": -0.2198664647228313, "compression_ratio": 1.565891472868217, "no_speech_prob": 9.882193990051746e-05}, {"id": 418, "seek": 154546, "start": 1545.46, "end": 1546.46, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.24415111541748047, "compression_ratio": 1.623015873015873, "no_speech_prob": 0.0009630542481318116}, {"id": 419, "seek": 154546, "start": 1546.46, "end": 1551.46, "text": " Yeah, just a quick question around the translation process, I suppose, touched on the structure.", "tokens": [865, 11, 445, 257, 1702, 1168, 926, 264, 12853, 1399, 11, 286, 7297, 11, 9828, 322, 264, 3877, 13], "temperature": 0.0, "avg_logprob": -0.24415111541748047, "compression_ratio": 1.623015873015873, "no_speech_prob": 0.0009630542481318116}, {"id": 420, "seek": 154546, "start": 1551.46, "end": 1554.46, "text": " But how does it work with different dialects?", "tokens": [583, 577, 775, 309, 589, 365, 819, 24652, 82, 30], "temperature": 0.0, "avg_logprob": -0.24415111541748047, "compression_ratio": 1.623015873015873, "no_speech_prob": 0.0009630542481318116}, {"id": 421, "seek": 154546, "start": 1554.46, "end": 1557.46, "text": " So if you write in dialects, will you write in slang?", "tokens": [407, 498, 291, 2464, 294, 24652, 82, 11, 486, 291, 2464, 294, 42517, 30], "temperature": 0.0, "avg_logprob": -0.24415111541748047, "compression_ratio": 1.623015873015873, "no_speech_prob": 0.0009630542481318116}, {"id": 422, "seek": 154546, "start": 1557.46, "end": 1558.96, "text": " That's a very good question.", "tokens": [663, 311, 257, 588, 665, 1168, 13], "temperature": 0.0, "avg_logprob": -0.24415111541748047, "compression_ratio": 1.623015873015873, "no_speech_prob": 0.0009630542481318116}, {"id": 423, "seek": 154546, "start": 1558.96, "end": 1565.46, "text": " Dialects would probably, and that's my guess, because I've never inquired this myself,", "tokens": [29658, 557, 82, 576, 1391, 11, 293, 300, 311, 452, 2041, 11, 570, 286, 600, 1128, 13570, 1824, 341, 2059, 11], "temperature": 0.0, "avg_logprob": -0.24415111541748047, "compression_ratio": 1.623015873015873, "no_speech_prob": 0.0009630542481318116}, {"id": 424, "seek": 154546, "start": 1565.46, "end": 1572.46, "text": " but I believe that a dialect to perform good as a target or source language for translation", "tokens": [457, 286, 1697, 300, 257, 24652, 281, 2042, 665, 382, 257, 3779, 420, 4009, 2856, 337, 12853], "temperature": 0.0, "avg_logprob": -0.24415111541748047, "compression_ratio": 1.623015873015873, "no_speech_prob": 0.0009630542481318116}, {"id": 425, "seek": 157246, "start": 1572.46, "end": 1576.46, "text": " would also need its fair amount of training data.", "tokens": [576, 611, 643, 1080, 3143, 2372, 295, 3097, 1412, 13], "temperature": 0.0, "avg_logprob": -0.08437987240878018, "compression_ratio": 1.8048780487804879, "no_speech_prob": 8.18594780866988e-05}, {"id": 426, "seek": 157246, "start": 1576.46, "end": 1578.46, "text": " And that is the problem with dialects.", "tokens": [400, 300, 307, 264, 1154, 365, 24652, 82, 13], "temperature": 0.0, "avg_logprob": -0.08437987240878018, "compression_ratio": 1.8048780487804879, "no_speech_prob": 8.18594780866988e-05}, {"id": 427, "seek": 157246, "start": 1578.46, "end": 1582.46, "text": " I actually speak a local Italian dialect, that is my first language,", "tokens": [286, 767, 1710, 257, 2654, 10003, 24652, 11, 300, 307, 452, 700, 2856, 11], "temperature": 0.0, "avg_logprob": -0.08437987240878018, "compression_ratio": 1.8048780487804879, "no_speech_prob": 8.18594780866988e-05}, {"id": 428, "seek": 157246, "start": 1582.46, "end": 1586.46, "text": " and I wanted to make a model for my dialect.", "tokens": [293, 286, 1415, 281, 652, 257, 2316, 337, 452, 24652, 13], "temperature": 0.0, "avg_logprob": -0.08437987240878018, "compression_ratio": 1.8048780487804879, "no_speech_prob": 8.18594780866988e-05}, {"id": 429, "seek": 157246, "start": 1586.46, "end": 1591.46, "text": " And I started looking online for references of data that I could use to create a model for my dialect,", "tokens": [400, 286, 1409, 1237, 2950, 337, 15400, 295, 1412, 300, 286, 727, 764, 281, 1884, 257, 2316, 337, 452, 24652, 11], "temperature": 0.0, "avg_logprob": -0.08437987240878018, "compression_ratio": 1.8048780487804879, "no_speech_prob": 8.18594780866988e-05}, {"id": 430, "seek": 157246, "start": 1591.46, "end": 1593.46, "text": " because it would be cool.", "tokens": [570, 309, 576, 312, 1627, 13], "temperature": 0.0, "avg_logprob": -0.08437987240878018, "compression_ratio": 1.8048780487804879, "no_speech_prob": 8.18594780866988e-05}, {"id": 431, "seek": 157246, "start": 1593.46, "end": 1596.46, "text": " And it was really challenging.", "tokens": [400, 309, 390, 534, 7595, 13], "temperature": 0.0, "avg_logprob": -0.08437987240878018, "compression_ratio": 1.8048780487804879, "no_speech_prob": 8.18594780866988e-05}, {"id": 432, "seek": 157246, "start": 1596.46, "end": 1600.46, "text": " Not being an official language, it really lacks the status of official languages,", "tokens": [1726, 885, 364, 4783, 2856, 11, 309, 534, 31132, 264, 6558, 295, 4783, 8650, 11], "temperature": 0.0, "avg_logprob": -0.08437987240878018, "compression_ratio": 1.8048780487804879, "no_speech_prob": 8.18594780866988e-05}, {"id": 433, "seek": 160046, "start": 1600.46, "end": 1604.46, "text": " and finding training data is extremely difficult.", "tokens": [293, 5006, 3097, 1412, 307, 4664, 2252, 13], "temperature": 0.0, "avg_logprob": -0.07346514817122575, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001633040519664064}, {"id": 434, "seek": 160046, "start": 1604.46, "end": 1606.46, "text": " But it could be possible, right?", "tokens": [583, 309, 727, 312, 1944, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.07346514817122575, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001633040519664064}, {"id": 435, "seek": 160046, "start": 1606.46, "end": 1614.46, "text": " If you gather enough people that can create a ground truth data set of examples in the dialect", "tokens": [759, 291, 5448, 1547, 561, 300, 393, 1884, 257, 2727, 3494, 1412, 992, 295, 5110, 294, 264, 24652], "temperature": 0.0, "avg_logprob": -0.07346514817122575, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001633040519664064}, {"id": 436, "seek": 160046, "start": 1614.46, "end": 1618.46, "text": " with sufficient samples, you could get good results, I believe.", "tokens": [365, 11563, 10938, 11, 291, 727, 483, 665, 3542, 11, 286, 1697, 13], "temperature": 0.0, "avg_logprob": -0.07346514817122575, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001633040519664064}, {"id": 437, "seek": 160046, "start": 1618.46, "end": 1622.46, "text": " So it's a matter, again, of training data.", "tokens": [407, 309, 311, 257, 1871, 11, 797, 11, 295, 3097, 1412, 13], "temperature": 0.0, "avg_logprob": -0.07346514817122575, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001633040519664064}, {"id": 438, "seek": 160046, "start": 1622.46, "end": 1623.46, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.07346514817122575, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001633040519664064}, {"id": 439, "seek": 160046, "start": 1623.46, "end": 1626.46, "text": " How much does it cost to get a model to a good level?", "tokens": [1012, 709, 775, 309, 2063, 281, 483, 257, 2316, 281, 257, 665, 1496, 30], "temperature": 0.0, "avg_logprob": -0.07346514817122575, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0001633040519664064}, {"id": 440, "seek": 162646, "start": 1626.46, "end": 1632.46, "text": " In terms of computing power or in terms of computing power?", "tokens": [682, 2115, 295, 15866, 1347, 420, 294, 2115, 295, 15866, 1347, 30], "temperature": 0.0, "avg_logprob": -0.10748692734600747, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.00011895478382939473}, {"id": 441, "seek": 162646, "start": 1632.46, "end": 1639.46, "text": " So if I remember correctly what PJ told me about the cost of training the models,", "tokens": [407, 498, 286, 1604, 8944, 437, 30549, 1907, 385, 466, 264, 2063, 295, 3097, 264, 5245, 11], "temperature": 0.0, "avg_logprob": -0.10748692734600747, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.00011895478382939473}, {"id": 442, "seek": 162646, "start": 1639.46, "end": 1646.46, "text": " it costs maybe a few, between $12 and $30.", "tokens": [309, 5497, 1310, 257, 1326, 11, 1296, 1848, 4762, 293, 1848, 3446, 13], "temperature": 0.0, "avg_logprob": -0.10748692734600747, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.00011895478382939473}, {"id": 443, "seek": 162646, "start": 1646.46, "end": 1649.46, "text": " You can rent instances on several cloud providers.", "tokens": [509, 393, 6214, 14519, 322, 2940, 4588, 11330, 13], "temperature": 0.0, "avg_logprob": -0.10748692734600747, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.00011895478382939473}, {"id": 444, "seek": 162646, "start": 1649.46, "end": 1651.46, "text": " You do need a GPU to train these models,", "tokens": [509, 360, 643, 257, 18407, 281, 3847, 613, 5245, 11], "temperature": 0.0, "avg_logprob": -0.10748692734600747, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.00011895478382939473}, {"id": 445, "seek": 165146, "start": 1651.46, "end": 1657.46, "text": " and it might take a few days for it to crunch and get sufficient number of iterations to train the model.", "tokens": [293, 309, 1062, 747, 257, 1326, 1708, 337, 309, 281, 13386, 293, 483, 11563, 1230, 295, 36540, 281, 3847, 264, 2316, 13], "temperature": 0.0, "avg_logprob": -0.072968856493632, "compression_ratio": 1.8, "no_speech_prob": 0.0001707292249193415}, {"id": 446, "seek": 165146, "start": 1657.46, "end": 1660.46, "text": " But it's absolutely affordable.", "tokens": [583, 309, 311, 3122, 12028, 13], "temperature": 0.0, "avg_logprob": -0.072968856493632, "compression_ratio": 1.8, "no_speech_prob": 0.0001707292249193415}, {"id": 447, "seek": 165146, "start": 1660.46, "end": 1665.46, "text": " Anybody can do it, and if you are willing to wait and you just have a gaming laptop sitting at home,", "tokens": [19082, 393, 360, 309, 11, 293, 498, 291, 366, 4950, 281, 1699, 293, 291, 445, 362, 257, 9703, 10732, 3798, 412, 1280, 11], "temperature": 0.0, "avg_logprob": -0.072968856493632, "compression_ratio": 1.8, "no_speech_prob": 0.0001707292249193415}, {"id": 448, "seek": 165146, "start": 1665.46, "end": 1670.46, "text": " if you're OK waiting 20 days for it to finish, it will train the model for you.", "tokens": [498, 291, 434, 2264, 3806, 945, 1708, 337, 309, 281, 2413, 11, 309, 486, 3847, 264, 2316, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.072968856493632, "compression_ratio": 1.8, "no_speech_prob": 0.0001707292249193415}, {"id": 449, "seek": 165146, "start": 1670.46, "end": 1675.46, "text": " So I guess it could be free to you if you're willing to wait a sufficient amount of time,", "tokens": [407, 286, 2041, 309, 727, 312, 1737, 281, 291, 498, 291, 434, 4950, 281, 1699, 257, 11563, 2372, 295, 565, 11], "temperature": 0.0, "avg_logprob": -0.072968856493632, "compression_ratio": 1.8, "no_speech_prob": 0.0001707292249193415}, {"id": 450, "seek": 165146, "start": 1675.46, "end": 1679.46, "text": " and if you have a gaming laptop lying around.", "tokens": [293, 498, 291, 362, 257, 9703, 10732, 8493, 926, 13], "temperature": 0.0, "avg_logprob": -0.072968856493632, "compression_ratio": 1.8, "no_speech_prob": 0.0001707292249193415}, {"id": 451, "seek": 165146, "start": 1679.46, "end": 1680.46, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.072968856493632, "compression_ratio": 1.8, "no_speech_prob": 0.0001707292249193415}, {"id": 452, "seek": 168046, "start": 1680.46, "end": 1686.46, "text": " So you mentioned the need for a data availability for doing the model, right?", "tokens": [407, 291, 2835, 264, 643, 337, 257, 1412, 17945, 337, 884, 264, 2316, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2537083992591271, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.00017987725732382387}, {"id": 453, "seek": 168046, "start": 1686.46, "end": 1693.46, "text": " Well, do you need the data to be available under a certain license?", "tokens": [1042, 11, 360, 291, 643, 264, 1412, 281, 312, 2435, 833, 257, 1629, 10476, 30], "temperature": 0.0, "avg_logprob": -0.2537083992591271, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.00017987725732382387}, {"id": 454, "seek": 168046, "start": 1693.46, "end": 1695.46, "text": " What's your problem?", "tokens": [708, 311, 428, 1154, 30], "temperature": 0.0, "avg_logprob": -0.2537083992591271, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.00017987725732382387}, {"id": 455, "seek": 168046, "start": 1695.46, "end": 1699.46, "text": " The world's full of things, right?", "tokens": [440, 1002, 311, 1577, 295, 721, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2537083992591271, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.00017987725732382387}, {"id": 456, "seek": 168046, "start": 1699.46, "end": 1700.46, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.2537083992591271, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.00017987725732382387}, {"id": 457, "seek": 168046, "start": 1700.46, "end": 1701.46, "text": " What's the requirement you have?", "tokens": [708, 311, 264, 11695, 291, 362, 30], "temperature": 0.0, "avg_logprob": -0.2537083992591271, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.00017987725732382387}, {"id": 458, "seek": 168046, "start": 1701.46, "end": 1704.46, "text": " You want it to be public domain?", "tokens": [509, 528, 309, 281, 312, 1908, 9274, 30], "temperature": 0.0, "avg_logprob": -0.2537083992591271, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.00017987725732382387}, {"id": 459, "seek": 170446, "start": 1704.46, "end": 1714.46, "text": " It has to be licensed under a permissive license, so creative comments that also includes commercial use.", "tokens": [467, 575, 281, 312, 25225, 833, 257, 4784, 891, 488, 10476, 11, 370, 5880, 3053, 300, 611, 5974, 6841, 764, 13], "temperature": 0.0, "avg_logprob": -0.13971519470214844, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0002512548817321658}, {"id": 460, "seek": 170446, "start": 1714.46, "end": 1722.46, "text": " And we give references and we give attribution to all the sources that we use.", "tokens": [400, 321, 976, 15400, 293, 321, 976, 9080, 1448, 281, 439, 264, 7139, 300, 321, 764, 13], "temperature": 0.0, "avg_logprob": -0.13971519470214844, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0002512548817321658}, {"id": 461, "seek": 170446, "start": 1722.46, "end": 1730.46, "text": " If you go into the Argos Package Manager repository, where all the models are hosted,", "tokens": [759, 291, 352, 666, 264, 1587, 18674, 18466, 609, 13821, 25841, 11, 689, 439, 264, 5245, 366, 19204, 11], "temperature": 0.0, "avg_logprob": -0.13971519470214844, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0002512548817321658}, {"id": 462, "seek": 170446, "start": 1730.46, "end": 1733.46, "text": " we do give the appropriate licensing credits to all those.", "tokens": [321, 360, 976, 264, 6854, 29759, 16816, 281, 439, 729, 13], "temperature": 0.0, "avg_logprob": -0.13971519470214844, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0002512548817321658}, {"id": 463, "seek": 173346, "start": 1733.46, "end": 1738.46, "text": " But yes, we cannot go on, say, the Internet and start scraping results,", "tokens": [583, 2086, 11, 321, 2644, 352, 322, 11, 584, 11, 264, 7703, 293, 722, 43738, 3542, 11], "temperature": 0.0, "avg_logprob": -0.11915950775146485, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.00040366267785429955}, {"id": 464, "seek": 173346, "start": 1738.46, "end": 1744.46, "text": " because everything, you just have to assume that everything is covered by copyright", "tokens": [570, 1203, 11, 291, 445, 362, 281, 6552, 300, 1203, 307, 5343, 538, 17996], "temperature": 0.0, "avg_logprob": -0.11915950775146485, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.00040366267785429955}, {"id": 465, "seek": 173346, "start": 1744.46, "end": 1746.46, "text": " until they tell you that you can use it freely.", "tokens": [1826, 436, 980, 291, 300, 291, 393, 764, 309, 16433, 13], "temperature": 0.0, "avg_logprob": -0.11915950775146485, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.00040366267785429955}, {"id": 466, "seek": 173346, "start": 1746.46, "end": 1752.46, "text": " So it's only trained on openly available and freely licensed sources.", "tokens": [407, 309, 311, 787, 8895, 322, 23109, 2435, 293, 16433, 25225, 7139, 13], "temperature": 0.0, "avg_logprob": -0.11915950775146485, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.00040366267785429955}, {"id": 467, "seek": 173346, "start": 1752.46, "end": 1757.46, "text": " Do you need it to be translated as well or just a single language?", "tokens": [1144, 291, 643, 309, 281, 312, 16805, 382, 731, 420, 445, 257, 2167, 2856, 30], "temperature": 0.0, "avg_logprob": -0.11915950775146485, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.00040366267785429955}, {"id": 468, "seek": 173346, "start": 1757.46, "end": 1759.46, "text": " It has to be translated.", "tokens": [467, 575, 281, 312, 16805, 13], "temperature": 0.0, "avg_logprob": -0.11915950775146485, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.00040366267785429955}, {"id": 469, "seek": 175946, "start": 1759.46, "end": 1767.46, "text": " So very briefly, the format of the input that goes into the training is a file that has,", "tokens": [407, 588, 10515, 11, 264, 7877, 295, 264, 4846, 300, 1709, 666, 264, 3097, 307, 257, 3991, 300, 575, 11], "temperature": 0.0, "avg_logprob": -0.11888663768768311, "compression_ratio": 1.6806282722513088, "no_speech_prob": 0.00021790247410535812}, {"id": 470, "seek": 175946, "start": 1767.46, "end": 1773.46, "text": " say, the English sentences and a separate file that has the translation on the same line.", "tokens": [584, 11, 264, 3669, 16579, 293, 257, 4994, 3991, 300, 575, 264, 12853, 322, 264, 912, 1622, 13], "temperature": 0.0, "avg_logprob": -0.11888663768768311, "compression_ratio": 1.6806282722513088, "no_speech_prob": 0.00021790247410535812}, {"id": 471, "seek": 175946, "start": 1773.46, "end": 1776.46, "text": " So it's very basic.", "tokens": [407, 309, 311, 588, 3875, 13], "temperature": 0.0, "avg_logprob": -0.11888663768768311, "compression_ratio": 1.6806282722513088, "no_speech_prob": 0.00021790247410535812}, {"id": 472, "seek": 175946, "start": 1776.46, "end": 1779.46, "text": " And somebody could do the work by hand, right?", "tokens": [400, 2618, 727, 360, 264, 589, 538, 1011, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.11888663768768311, "compression_ratio": 1.6806282722513088, "no_speech_prob": 0.00021790247410535812}, {"id": 473, "seek": 175946, "start": 1779.46, "end": 1783.46, "text": " You start from the English translation and you start doing the translation.", "tokens": [509, 722, 490, 264, 3669, 12853, 293, 291, 722, 884, 264, 12853, 13], "temperature": 0.0, "avg_logprob": -0.11888663768768311, "compression_ratio": 1.6806282722513088, "no_speech_prob": 0.00021790247410535812}, {"id": 474, "seek": 178346, "start": 1783.46, "end": 1789.46, "text": " So it will take a lot of work, but it's doable, especially in a crowd-formed...", "tokens": [407, 309, 486, 747, 257, 688, 295, 589, 11, 457, 309, 311, 41183, 11, 2318, 294, 257, 6919, 12, 22892, 485], "temperature": 0.0, "avg_logprob": -0.1327921220625954, "compression_ratio": 1.4251207729468598, "no_speech_prob": 8.283260831376538e-05}, {"id": 475, "seek": 178346, "start": 1789.46, "end": 1791.46, "text": " Are we out of time?", "tokens": [2014, 321, 484, 295, 565, 30], "temperature": 0.0, "avg_logprob": -0.1327921220625954, "compression_ratio": 1.4251207729468598, "no_speech_prob": 8.283260831376538e-05}, {"id": 476, "seek": 178346, "start": 1791.46, "end": 1792.46, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.1327921220625954, "compression_ratio": 1.4251207729468598, "no_speech_prob": 8.283260831376538e-05}, {"id": 477, "seek": 178346, "start": 1792.46, "end": 1793.46, "text": " I'll be around if you have other questions.", "tokens": [286, 603, 312, 926, 498, 291, 362, 661, 1651, 13], "temperature": 0.0, "avg_logprob": -0.1327921220625954, "compression_ratio": 1.4251207729468598, "no_speech_prob": 8.283260831376538e-05}, {"id": 478, "seek": 178346, "start": 1793.46, "end": 1795.46, "text": " Our time is up, unfortunately.", "tokens": [2621, 565, 307, 493, 11, 7015, 13], "temperature": 0.0, "avg_logprob": -0.1327921220625954, "compression_ratio": 1.4251207729468598, "no_speech_prob": 8.283260831376538e-05}, {"id": 479, "seek": 178346, "start": 1795.46, "end": 1796.46, "text": " They're kicking me out.", "tokens": [814, 434, 19137, 385, 484, 13], "temperature": 0.0, "avg_logprob": -0.1327921220625954, "compression_ratio": 1.4251207729468598, "no_speech_prob": 8.283260831376538e-05}, {"id": 480, "seek": 178346, "start": 1796.46, "end": 1800.46, "text": " But the next speaker will deliver something awesome as well next talk.", "tokens": [583, 264, 958, 8145, 486, 4239, 746, 3476, 382, 731, 958, 751, 13], "temperature": 0.0, "avg_logprob": -0.1327921220625954, "compression_ratio": 1.4251207729468598, "no_speech_prob": 8.283260831376538e-05}, {"id": 481, "seek": 180046, "start": 1800.46, "end": 1815.46, "text": " Thank you again.", "tokens": [50364, 1044, 291, 797, 13, 51114], "temperature": 0.0, "avg_logprob": -0.26920935085841585, "compression_ratio": 0.6666666666666666, "no_speech_prob": 0.0004695356183219701}], "language": "en"}