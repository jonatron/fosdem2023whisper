{"text": " Okay, welcome everyone, as you can see from Adam, typical notebooks are a very important tool in each data scientist, but using graphs, refer to notebook as a challenge, for instance visualization. And so Bjornville talked about, I pie Zygma today, which is a tool to use ZygmaJas as a component in a Jupyter notebook. So I'm really looking forward to that and without further ado. Where I'm from this time, I'm actually not Guillaume, I'm sick. So I apologize in advance, because I'm not the creator of the tool and so I will do as much as I can to present it, but Guillaume can answer that by email or by Twitter or any other means if you have more questions than what I can actually answer myself. And so I will just start by a brief remember of why we sometimes want to use graphs and actually visualize them and not only do statistics on notebooks and actually visualize graphs. And so why do we do visual network analysis? It actually goes back very old to 1736 and the Bridges of Collector, which is a classical mathematical problem that was solved thanks to visualizing the graph that it was showing. Later on in France, Moreno did a social graph where he tried to visualize how a connective where students in a classroom. And recently, thanks to the community assisting tools, we can do those kind of visualizations but with massive graphs and we can try to do a computed processing to try and automatically specialize nodes on the map and on the plane and also identify clusters within it. So that brings a different mean to actually analyze graphs and actually visualize this helps a lot understanding. And we are coming from the field of social sciences and we use a lot of graphs to interpret social issues in general. And we use them actually as maps. So it's not maps in which coordinates make sense. X and Y don't mean anything. You can just take the map. But basically what you see on the plane indicates information on the, I mean the localization of each node that makes a sense compared to the other nodes. So, but I guess most of them are not. That's another example of a map that was made a long time ago. So to do that, there has been over the past years a lot of tools that have been developed including the first desktop ones. So this tool is the direct heritage of this long lineage which started with Gezi. I believe later today there will be a presentation of Gezi version 1 which finally will go out soon after so many versions already. So you probably already know Gezi. But recently we could switch from the actual desktop analysis to actual web representations thanks to a variety of libraries. D3.js proposes to do it. But there's also a site escape and a bunch of others. But so our community works with Simba. And Simba has been developed by people who are actually close to the people of Gezi. I don't think Alexi is here today. But Alexi Jacomi is the small brother of Mathieu Jacomi who speaks about Gezi. He's the one who invented Simba and Guillaume is the co-host of Simba with Alexi. So please take a look at Simba. I will put the slides to the conference and you will find links to all the tools around. And then thanks to Simba, we could build a lot of Gezi-like tools but for the web. So that we could do all those interactions that we do directly in a web page. There's been a long history at Miguelab and around of trying to build such tools. Minivan was one of them. There's also Nancy which is a very small, very publishing-oriented way of displaying a graph with very few options so that you can just put your Gezi-like search file or GraphML file and very easily do what you do on your Gezi. Retina is the one developed by people at Westware right now and is very rich, proposing a lot of features. And soon I think Mathieu and Mathieu will talk about it briefly also in the later talk about Gezi version 1. There's a Gezi-like version that's currently being developed and that should come in soon. Which brings me to all of those tools are very nice. We have all those that are interactive and you can visualize, explore, publish, manipulate all those graphs but they all require pre-processed graphs. You cannot just work with your graph while you're visualizing it. You have to pre-code in your file, usually JSON or JXF or GraphML, then you load it into the tool and then you can explore it. But we would like to be able to do that at the same time. And so that's where the idea of I by Sigma came from, to try and put within Jupyter a notebook, a widget that would display the graph using SigmaJS. So it's really easy to install as long as you have Jupyter. You usually need a tool to work with graphs under Python. There's two main ones that you might know already about, I by Sigma is built to handle both formats of graphs from both networks and I by Sigma. And so you just install I by Sigma in addition, and then I just switch to the brief demo. Maybe at the seat. So we'll do two small explorations of graphs. There's the first one that we're working on right now, which is on the, what I call the open source, I mean, actually larger than that, open access, open world. It's like for them, but just in France and the French communities working on that. And so we built this network of websites, links together of those French communities of free software. And let's take a look at it as well. So first, I will import the projects. Then I'm reading the graph that I built already. So that's all this first example. So here we have a graph with 621 nodes and 7000 edges. Let's look at the node. So the first node, I don't see that information. It's April.org. I don't know if the French people are in the room, but people should know that April is from France. It's the main NGO in France about open source and just the graph. So we have this whole page. That's all the data that was collected while making the graph. And then let's try to just visualize it by just loading i5 sigma, importing sigma and applying it to the graph. Here, just by the widget with the graph, which is randomly specialized. We have metadata information. So we can run for FATAS on it. So very easy. You see your specialized graph. Just a few seconds, and then we can also apply some... The graph is too dense for that. And suddenly no effect. So yeah, but right now it's just a graph and we don't have much information. It's very complicated readable. So let's go down and try to add a few other options to the sigma code. So we can set the outside standards. Let's use the number of pages for. So here I can see that for this graph use, we put a lot of pages on some specific websites. Let's put a little bit more and try to adjust the sizes of the nodes. So we can adjust the range of the values for instance. Here it's really readable. Okay, so we got sizes. Let's add some colors. So iBuySigma proposes some internal metrics that you can compute on the fly. So for instance, as a result, it generates clusters. And we will apply colors to the map. I mean we will apply those color communities as colors. So here we get a set graph of colors. Let's see that there are a lot of communities. As knowing this network and knowing this community, I can tell you that basically what this is. Here we got the open data, open command community. Here we got uphill and basically the NGOs working on the open source. Here we got GIL and it's mostly a lot of softwares. Fedora and all the Linux distributions. Here we got FFDL, MaproductionDenets, and all those activists working with the open internet. And I guess here is more the... Oh, it's also a mobilization. It's a form of formigated old form of food. I'll just speak a little bit. Okay, so now that we got this, let's try to make it a little bit nicer. We can add, for instance, some border colors. So it just proposes to see a stronger border of colors. Graphs are a little bit sexier. We can also try to do like Gephi, like curled edges. All of those are in options. I guess I'll show you briefly later on a list of the different options. Here we also put the recursive font to the level. So basically you can do a lot of things. But all of that so far is mostly like Gephi. There's no real new thing. But here's something that actually proposes something else. So right now we can see one graph. But let's try and see multiple ones. So I buy similar properties, what we call a similar grid. And so I will put the same graph, but it will trickle out. And those will be common options that I set for all versions of the graph. But then, within the grid, I will add three different versions of the graph using different metrics for the size of the load. So here's one on the left one. And we see it's on the middle of the degree. And the right one on the bottom. Now I'm going to add this. So here are the three graphs, which are all synchronized. If I visualize it, it happens at the same time. If I over-enode, I will see it on the three different versions. And then if I zoom a little bit, I guess we can see that... Wow. What can we see? We can see that PharmaSoft, for instance, is very connected most globally, but especially it has a very strong in-degree and not so big out-degree. Why is that? PharmaSoft is such a reference in France for open-source tools that it gets a lot of links from the whole community. And all websites of the Free Software community point to it, because it's like a resource. Whereas, of course, they cannot point to the whole rest of the community. On another note, I guess we could find... I think there was Linux... Linux-affair.org is the opposite. It's a media that pretty much talks about anything that happens on open-source in France. And, of course, they're the ones having the most outlinks. All right, so that's just a small example. Then I can show you maybe another notebook that will show other things. So this one is a notebook that was built out of data collected by Laura Miguel, which is a trainee at Media Lab right now. And she scraped the first-day website, the agendas, to try and get all speakers and rooms over the past 15 years. So here we will have to build the graph progressively. We just had a CSV that she scraped of the data of one speaker and one room. Disclaimer, the speakers have been anonymized. So you won't find a name that you know about, but they represent actual people. So let's take a look at, for instance, three examples of the data. So those are the three first lines. I mean, that's one line and two other lines that I picked specifically. This one is one speaker, and she talked about within this track. Here it was a stock that was shared between two speakers. So sometimes we get speakers separated by a pipe. And here is obviously someone that was still anonymized, but that should be in my seat right now. And we did many talks in the past, including in this room. So we will build the graph using NetworkX. So for those who know NetworkX, it's quite simple. You just create a new graph, and then for each row in our CSV, we will, if there's no speaker, we don't take it. Then we take the track and the year. We add a node for each track, and for each speaker inside the talk, we add a node for the speaker. And then we had an edge in between those two, and we increment it as a count if it's the second time that we meet him, for instance. And we also upgrade the year to get, for the edge, the last year that was used. So by doing that, I built a new graph that has 5,000 nodes and 6,000 links. Let's take a look at my alternate speaker here. It was supposed to be a speaker, and apparently, so it's linked to, in year 2018, to two talks in the graph room. Yeah, he spoke twice in the room, back then. In JavaScript in 2019, and in 2020 in the Open Research Tools and Technology Room. So let's take a look at this graph now. Oh, it was broken. Yes, there's a comma missing here. Here it is. Still, I tried to add this earlier, but I'm not expert enough with it, so I'll remove this. So here it is. So this time, it's a bipartite graph, since we got two kinds of nodes, the tracks and the speakers. So I decided that the node color will be attached to the part type. And if I take a look at it, we should see all big dots in blue are the rooms at first then, and all pink ones are actually speakers. And so we can see that there are a lot of lightning talks, of course, every year, but there are some rooms that have way more speakers than others, probably also because they exist for way longer. So maybe we can try and explore that, and that's the main idea. So sorry, I don't remember what this one is. Let's just run it briefly. I guess it's the same. Yeah, it's the same. Sorry, it's a copy-paste. So what we could do is try and apply other things. So let's do a grid again. But this time, we'll try and display for each node a gradient of color. That will indicate the intensity of the node at this moment. So to do that, we will, for instance, take a look at the year 2012 and the year 2022, and use the strength of the ALO, depending on how many talks were associated to this node for this specific year. So both graphs should show the intensity of the talks during those two years. So let's show it again. And here we can see that in 2012, the main rooms that were filled were actually more on desktops, Mozilla, Lightning Talks, and Embedded, whereas in 2022, there are way more rooms that are actually filled and spoken. Then what we could do is continue working on our graph and continue exploring while working with it. So at Medialab, we also have a tool called Pelot, which allows us to do a bunch of metrics and calculation on a, so it's already installed, it's going faster. And for instance, it can do a monopartite projection out of a bipartite graph. So I'm just running this, and then we can try and display it. And here, just in a few lines in Python, I can just see the alternate graph that is the monopartite version of the graph, and just see the links between the rooms depending on when they are co-spoken by speakers. Let's continue. And the problem is that if I look at this graph, I can see there are a bunch of nodes isolated. And so usually when I want to visualize a graph, those are a bit annoying because they take a lot of space in the visualization, and I don't want to see that. So let's just use Pelot's Crop to Largest Component function that will keep only the biggest component of the graph. So then I can re-displace this graph without all of those single nodes. And that's a rough idea of what could be done. Then we can work with the graph and just visualize on the fly. And I guess I'll conclude by just showing inside the GitHub page of the tool. There's all the visual variables that are available. So I showed you already node color, but you can also play on the saturation of the nodes. You can play on the size we saw, but you can play with the label size, of course, the label color. You can adjust the border ratio, how big it is. So basically all visual ways to better help you interpret your graph can be proposed. You can also add pictograms, use shapes for each node. You can use halos like I showed earlier. And play also a lot of those applied to edges. So you can play on the colors, the form of them, and so on and so on. And I guess that will be it for me. And I will take all of your questions. Sorry, I'm just scrolling back to things that are nicer. All of you. Yes. Can you preserve the layout between the different steps so you can execute the layout every time you go to a new cell and preserve it? That's a good question. I don't think it has been planned yet. Can you repeat the question? Yes, sorry. So the question was can we maintain the layout from one cell to the other and not having to re-click to apply the layout every time? I don't think so. And what I know is that the layout, the way Forza class works, has some chaos. But here it's always instantiated on the same seed. So whenever you run it, it will always generate the same exact layout. So that's something. But it won't reuse the one from the previous cells. No. That could be something that could be an idea. Yes? Do you have any numbers on the upper limits of this system? And the size of the graph that you're going to run here? So can you run the values of noting this one or the limits? So the question is about volume and amplitude and how big of a graph we can display with this. So I believe the limit is actually the one of your browser. So it will depend on your GPU and your CPU and your RAM. But I know that SigmaJS properly endows graphs with, I would say, 100,000 of nodes and links. I guess I know I already displayed one with a few million links and 100,000 of nodes. It takes a bit more time, of course. Do you support something like collapsing nodes and expanding them? For instance, in these kind of power graphs where the communities could collapse if you want to put height once, and they could be selectively expanded as well. So the question is, can we aggregate and split nodes that have, for instance, the same group? For me, it would be, I don't think it's built-in within Sigma for sure. Maybe in Pelot, the library I was showing, like the monopartite projection is pretty much this kind of ID. And I don't know, but it might be in Pelot. Yeah. You might try the GPU. Yeah, SigmaJS, sorry. So the question is, does this use the GPU to display the graph? Yes. SigmaJS is heavily relying on WebGL. The previous version of SigmaJS was proposing to choose between Canvas and WebGL. Right now, it's only WebGL, so it won't work with all browsers. But nowadays, most browsers know to work with the GPU. So, yes. Thank you so much. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 22.0, "text": " Okay, welcome everyone, as you can see from Adam, typical notebooks are a very important", "tokens": [1033, 11, 2928, 1518, 11, 382, 291, 393, 536, 490, 7938, 11, 7476, 43782, 366, 257, 588, 1021], "temperature": 0.0, "avg_logprob": -0.6398599364540793, "compression_ratio": 1.0731707317073171, "no_speech_prob": 0.5742870569229126}, {"id": 1, "seek": 2200, "start": 22.0, "end": 32.0, "text": " tool in each data scientist, but using graphs, refer to notebook as a challenge, for instance", "tokens": [2290, 294, 1184, 1412, 12662, 11, 457, 1228, 24877, 11, 2864, 281, 21060, 382, 257, 3430, 11, 337, 5197], "temperature": 0.0, "avg_logprob": -0.5825715413907679, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.005994698964059353}, {"id": 2, "seek": 2200, "start": 32.0, "end": 33.0, "text": " visualization.", "tokens": [25801, 13], "temperature": 0.0, "avg_logprob": -0.5825715413907679, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.005994698964059353}, {"id": 3, "seek": 2200, "start": 33.0, "end": 41.0, "text": " And so Bjornville talked about, I pie Zygma today, which is a tool to use ZygmaJas as", "tokens": [400, 370, 49660, 1865, 8386, 2825, 466, 11, 286, 1730, 1176, 18103, 1696, 965, 11, 597, 307, 257, 2290, 281, 764, 1176, 18103, 1696, 41, 296, 382], "temperature": 0.0, "avg_logprob": -0.5825715413907679, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.005994698964059353}, {"id": 4, "seek": 2200, "start": 41.0, "end": 43.0, "text": " a component in a Jupyter notebook.", "tokens": [257, 6542, 294, 257, 22125, 88, 391, 21060, 13], "temperature": 0.0, "avg_logprob": -0.5825715413907679, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.005994698964059353}, {"id": 5, "seek": 2200, "start": 43.0, "end": 47.0, "text": " So I'm really looking forward to that and without further ado.", "tokens": [407, 286, 478, 534, 1237, 2128, 281, 300, 293, 1553, 3052, 22450, 13], "temperature": 0.0, "avg_logprob": -0.5825715413907679, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.005994698964059353}, {"id": 6, "seek": 4700, "start": 47.0, "end": 53.0, "text": " Where I'm from this time, I'm actually not Guillaume, I'm sick.", "tokens": [2305, 286, 478, 490, 341, 565, 11, 286, 478, 767, 406, 2694, 5291, 2540, 11, 286, 478, 4998, 13], "temperature": 0.0, "avg_logprob": -0.282589769911492, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.008524603210389614}, {"id": 7, "seek": 4700, "start": 53.0, "end": 61.0, "text": " So I apologize in advance, because I'm not the creator of the tool and so I will do as", "tokens": [407, 286, 12328, 294, 7295, 11, 570, 286, 478, 406, 264, 14181, 295, 264, 2290, 293, 370, 286, 486, 360, 382], "temperature": 0.0, "avg_logprob": -0.282589769911492, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.008524603210389614}, {"id": 8, "seek": 4700, "start": 61.0, "end": 68.0, "text": " much as I can to present it, but Guillaume can answer that by email or by Twitter or any", "tokens": [709, 382, 286, 393, 281, 1974, 309, 11, 457, 2694, 5291, 2540, 393, 1867, 300, 538, 3796, 420, 538, 5794, 420, 604], "temperature": 0.0, "avg_logprob": -0.282589769911492, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.008524603210389614}, {"id": 9, "seek": 4700, "start": 68.0, "end": 73.0, "text": " other means if you have more questions than what I can actually answer myself.", "tokens": [661, 1355, 498, 291, 362, 544, 1651, 813, 437, 286, 393, 767, 1867, 2059, 13], "temperature": 0.0, "avg_logprob": -0.282589769911492, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.008524603210389614}, {"id": 10, "seek": 7300, "start": 73.0, "end": 81.0, "text": " And so I will just start by a brief remember of why we sometimes want to use graphs and", "tokens": [400, 370, 286, 486, 445, 722, 538, 257, 5353, 1604, 295, 983, 321, 2171, 528, 281, 764, 24877, 293], "temperature": 0.0, "avg_logprob": -0.23131731669108072, "compression_ratio": 1.5463414634146342, "no_speech_prob": 0.0014862625394016504}, {"id": 11, "seek": 7300, "start": 81.0, "end": 88.0, "text": " actually visualize them and not only do statistics on notebooks and actually visualize graphs.", "tokens": [767, 23273, 552, 293, 406, 787, 360, 12523, 322, 43782, 293, 767, 23273, 24877, 13], "temperature": 0.0, "avg_logprob": -0.23131731669108072, "compression_ratio": 1.5463414634146342, "no_speech_prob": 0.0014862625394016504}, {"id": 12, "seek": 7300, "start": 88.0, "end": 90.0, "text": " And so why do we do visual network analysis?", "tokens": [400, 370, 983, 360, 321, 360, 5056, 3209, 5215, 30], "temperature": 0.0, "avg_logprob": -0.23131731669108072, "compression_ratio": 1.5463414634146342, "no_speech_prob": 0.0014862625394016504}, {"id": 13, "seek": 7300, "start": 90.0, "end": 97.0, "text": " It actually goes back very old to 1736 and the Bridges of Collector, which is a classical", "tokens": [467, 767, 1709, 646, 588, 1331, 281, 3282, 11309, 293, 264, 30552, 2880, 295, 4586, 20814, 11, 597, 307, 257, 13735], "temperature": 0.0, "avg_logprob": -0.23131731669108072, "compression_ratio": 1.5463414634146342, "no_speech_prob": 0.0014862625394016504}, {"id": 14, "seek": 9700, "start": 97.0, "end": 104.0, "text": " mathematical problem that was solved thanks to visualizing the graph that it was showing.", "tokens": [18894, 1154, 300, 390, 13041, 3231, 281, 5056, 3319, 264, 4295, 300, 309, 390, 4099, 13], "temperature": 0.0, "avg_logprob": -0.19725546155657087, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.0010926297400146723}, {"id": 15, "seek": 9700, "start": 104.0, "end": 113.0, "text": " Later on in France, Moreno did a social graph where he tried to visualize how a connective", "tokens": [11965, 322, 294, 6190, 11, 5048, 1771, 630, 257, 2093, 4295, 689, 415, 3031, 281, 23273, 577, 257, 1745, 488], "temperature": 0.0, "avg_logprob": -0.19725546155657087, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.0010926297400146723}, {"id": 16, "seek": 9700, "start": 113.0, "end": 116.0, "text": " where students in a classroom.", "tokens": [689, 1731, 294, 257, 7419, 13], "temperature": 0.0, "avg_logprob": -0.19725546155657087, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.0010926297400146723}, {"id": 17, "seek": 9700, "start": 116.0, "end": 126.0, "text": " And recently, thanks to the community assisting tools, we can do those kind of visualizations", "tokens": [400, 3938, 11, 3231, 281, 264, 1768, 40368, 3873, 11, 321, 393, 360, 729, 733, 295, 5056, 14455], "temperature": 0.0, "avg_logprob": -0.19725546155657087, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.0010926297400146723}, {"id": 18, "seek": 12600, "start": 126.0, "end": 135.0, "text": " but with massive graphs and we can try to do a computed processing to try and automatically", "tokens": [457, 365, 5994, 24877, 293, 321, 393, 853, 281, 360, 257, 40610, 9007, 281, 853, 293, 6772], "temperature": 0.0, "avg_logprob": -0.2524514659758537, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.0015428784536197782}, {"id": 19, "seek": 12600, "start": 135.0, "end": 144.0, "text": " specialize nodes on the map and on the plane and also identify clusters within it.", "tokens": [37938, 13891, 322, 264, 4471, 293, 322, 264, 5720, 293, 611, 5876, 23313, 1951, 309, 13], "temperature": 0.0, "avg_logprob": -0.2524514659758537, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.0015428784536197782}, {"id": 20, "seek": 12600, "start": 144.0, "end": 152.0, "text": " So that brings a different mean to actually analyze graphs and actually visualize this", "tokens": [407, 300, 5607, 257, 819, 914, 281, 767, 12477, 24877, 293, 767, 23273, 341], "temperature": 0.0, "avg_logprob": -0.2524514659758537, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.0015428784536197782}, {"id": 21, "seek": 12600, "start": 152.0, "end": 154.0, "text": " helps a lot understanding.", "tokens": [3665, 257, 688, 3701, 13], "temperature": 0.0, "avg_logprob": -0.2524514659758537, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.0015428784536197782}, {"id": 22, "seek": 15400, "start": 154.0, "end": 161.0, "text": " And we are coming from the field of social sciences and we use a lot of graphs to interpret", "tokens": [400, 321, 366, 1348, 490, 264, 2519, 295, 2093, 17677, 293, 321, 764, 257, 688, 295, 24877, 281, 7302], "temperature": 0.0, "avg_logprob": -0.23508289585942807, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003105776384472847}, {"id": 23, "seek": 15400, "start": 161.0, "end": 164.0, "text": " social issues in general.", "tokens": [2093, 2663, 294, 2674, 13], "temperature": 0.0, "avg_logprob": -0.23508289585942807, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003105776384472847}, {"id": 24, "seek": 15400, "start": 164.0, "end": 167.0, "text": " And we use them actually as maps.", "tokens": [400, 321, 764, 552, 767, 382, 11317, 13], "temperature": 0.0, "avg_logprob": -0.23508289585942807, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003105776384472847}, {"id": 25, "seek": 15400, "start": 167.0, "end": 171.0, "text": " So it's not maps in which coordinates make sense.", "tokens": [407, 309, 311, 406, 11317, 294, 597, 21056, 652, 2020, 13], "temperature": 0.0, "avg_logprob": -0.23508289585942807, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003105776384472847}, {"id": 26, "seek": 15400, "start": 171.0, "end": 173.0, "text": " X and Y don't mean anything.", "tokens": [1783, 293, 398, 500, 380, 914, 1340, 13], "temperature": 0.0, "avg_logprob": -0.23508289585942807, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003105776384472847}, {"id": 27, "seek": 15400, "start": 173.0, "end": 175.0, "text": " You can just take the map.", "tokens": [509, 393, 445, 747, 264, 4471, 13], "temperature": 0.0, "avg_logprob": -0.23508289585942807, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003105776384472847}, {"id": 28, "seek": 15400, "start": 175.0, "end": 183.0, "text": " But basically what you see on the plane indicates information on the, I mean the localization", "tokens": [583, 1936, 437, 291, 536, 322, 264, 5720, 16203, 1589, 322, 264, 11, 286, 914, 264, 2654, 2144], "temperature": 0.0, "avg_logprob": -0.23508289585942807, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003105776384472847}, {"id": 29, "seek": 18300, "start": 183.0, "end": 187.0, "text": " of each node that makes a sense compared to the other nodes.", "tokens": [295, 1184, 9984, 300, 1669, 257, 2020, 5347, 281, 264, 661, 13891, 13], "temperature": 0.0, "avg_logprob": -0.2793105732310902, "compression_ratio": 1.5573770491803278, "no_speech_prob": 0.002150715561583638}, {"id": 30, "seek": 18300, "start": 187.0, "end": 190.0, "text": " So, but I guess most of them are not.", "tokens": [407, 11, 457, 286, 2041, 881, 295, 552, 366, 406, 13], "temperature": 0.0, "avg_logprob": -0.2793105732310902, "compression_ratio": 1.5573770491803278, "no_speech_prob": 0.002150715561583638}, {"id": 31, "seek": 18300, "start": 190.0, "end": 196.0, "text": " That's another example of a map that was made a long time ago.", "tokens": [663, 311, 1071, 1365, 295, 257, 4471, 300, 390, 1027, 257, 938, 565, 2057, 13], "temperature": 0.0, "avg_logprob": -0.2793105732310902, "compression_ratio": 1.5573770491803278, "no_speech_prob": 0.002150715561583638}, {"id": 32, "seek": 18300, "start": 196.0, "end": 207.0, "text": " So to do that, there has been over the past years a lot of tools that have been developed", "tokens": [407, 281, 360, 300, 11, 456, 575, 668, 670, 264, 1791, 924, 257, 688, 295, 3873, 300, 362, 668, 4743], "temperature": 0.0, "avg_logprob": -0.2793105732310902, "compression_ratio": 1.5573770491803278, "no_speech_prob": 0.002150715561583638}, {"id": 33, "seek": 18300, "start": 207.0, "end": 209.0, "text": " including the first desktop ones.", "tokens": [3009, 264, 700, 14502, 2306, 13], "temperature": 0.0, "avg_logprob": -0.2793105732310902, "compression_ratio": 1.5573770491803278, "no_speech_prob": 0.002150715561583638}, {"id": 34, "seek": 20900, "start": 209.0, "end": 218.0, "text": " So this tool is the direct heritage of this long lineage which started with Gezi.", "tokens": [407, 341, 2290, 307, 264, 2047, 16040, 295, 341, 938, 38257, 597, 1409, 365, 2876, 3992, 13], "temperature": 0.0, "avg_logprob": -0.15859299201469917, "compression_ratio": 1.6113744075829384, "no_speech_prob": 0.0012718901271000504}, {"id": 35, "seek": 20900, "start": 218.0, "end": 224.0, "text": " I believe later today there will be a presentation of Gezi version 1 which finally will go out", "tokens": [286, 1697, 1780, 965, 456, 486, 312, 257, 5860, 295, 2876, 3992, 3037, 502, 597, 2721, 486, 352, 484], "temperature": 0.0, "avg_logprob": -0.15859299201469917, "compression_ratio": 1.6113744075829384, "no_speech_prob": 0.0012718901271000504}, {"id": 36, "seek": 20900, "start": 224.0, "end": 228.0, "text": " soon after so many versions already.", "tokens": [2321, 934, 370, 867, 9606, 1217, 13], "temperature": 0.0, "avg_logprob": -0.15859299201469917, "compression_ratio": 1.6113744075829384, "no_speech_prob": 0.0012718901271000504}, {"id": 37, "seek": 20900, "start": 228.0, "end": 230.0, "text": " So you probably already know Gezi.", "tokens": [407, 291, 1391, 1217, 458, 2876, 3992, 13], "temperature": 0.0, "avg_logprob": -0.15859299201469917, "compression_ratio": 1.6113744075829384, "no_speech_prob": 0.0012718901271000504}, {"id": 38, "seek": 20900, "start": 230.0, "end": 238.0, "text": " But recently we could switch from the actual desktop analysis to actual web representations", "tokens": [583, 3938, 321, 727, 3679, 490, 264, 3539, 14502, 5215, 281, 3539, 3670, 33358], "temperature": 0.0, "avg_logprob": -0.15859299201469917, "compression_ratio": 1.6113744075829384, "no_speech_prob": 0.0012718901271000504}, {"id": 39, "seek": 23800, "start": 238.0, "end": 241.0, "text": " thanks to a variety of libraries.", "tokens": [3231, 281, 257, 5673, 295, 15148, 13], "temperature": 0.0, "avg_logprob": -0.32726115446824294, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.004565157927572727}, {"id": 40, "seek": 23800, "start": 241.0, "end": 244.0, "text": " D3.js proposes to do it.", "tokens": [413, 18, 13, 25530, 2365, 4201, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.32726115446824294, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.004565157927572727}, {"id": 41, "seek": 23800, "start": 244.0, "end": 247.0, "text": " But there's also a site escape and a bunch of others.", "tokens": [583, 456, 311, 611, 257, 3621, 7615, 293, 257, 3840, 295, 2357, 13], "temperature": 0.0, "avg_logprob": -0.32726115446824294, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.004565157927572727}, {"id": 42, "seek": 23800, "start": 247.0, "end": 251.0, "text": " But so our community works with Simba.", "tokens": [583, 370, 527, 1768, 1985, 365, 3998, 4231, 13], "temperature": 0.0, "avg_logprob": -0.32726115446824294, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.004565157927572727}, {"id": 43, "seek": 23800, "start": 251.0, "end": 257.0, "text": " And Simba has been developed by people who are actually close to the people of Gezi.", "tokens": [400, 3998, 4231, 575, 668, 4743, 538, 561, 567, 366, 767, 1998, 281, 264, 561, 295, 2876, 3992, 13], "temperature": 0.0, "avg_logprob": -0.32726115446824294, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.004565157927572727}, {"id": 44, "seek": 23800, "start": 257.0, "end": 259.0, "text": " I don't think Alexi is here today.", "tokens": [286, 500, 380, 519, 5202, 72, 307, 510, 965, 13], "temperature": 0.0, "avg_logprob": -0.32726115446824294, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.004565157927572727}, {"id": 45, "seek": 23800, "start": 259.0, "end": 264.0, "text": " But Alexi Jacomi is the small brother of Mathieu Jacomi who speaks about Gezi.", "tokens": [583, 5202, 72, 9538, 9220, 307, 264, 1359, 3708, 295, 15776, 19347, 9538, 9220, 567, 10789, 466, 2876, 3992, 13], "temperature": 0.0, "avg_logprob": -0.32726115446824294, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.004565157927572727}, {"id": 46, "seek": 26400, "start": 264.0, "end": 271.0, "text": " He's the one who invented Simba and Guillaume is the co-host of Simba with Alexi.", "tokens": [634, 311, 264, 472, 567, 14479, 3998, 4231, 293, 2694, 5291, 2540, 307, 264, 598, 12, 6037, 295, 3998, 4231, 365, 5202, 72, 13], "temperature": 0.0, "avg_logprob": -0.2381133666405311, "compression_ratio": 1.665137614678899, "no_speech_prob": 0.004434671718627214}, {"id": 47, "seek": 26400, "start": 271.0, "end": 273.0, "text": " So please take a look at Simba.", "tokens": [407, 1767, 747, 257, 574, 412, 3998, 4231, 13], "temperature": 0.0, "avg_logprob": -0.2381133666405311, "compression_ratio": 1.665137614678899, "no_speech_prob": 0.004434671718627214}, {"id": 48, "seek": 26400, "start": 273.0, "end": 279.0, "text": " I will put the slides to the conference and you will find links to all the tools around.", "tokens": [286, 486, 829, 264, 9788, 281, 264, 7586, 293, 291, 486, 915, 6123, 281, 439, 264, 3873, 926, 13], "temperature": 0.0, "avg_logprob": -0.2381133666405311, "compression_ratio": 1.665137614678899, "no_speech_prob": 0.004434671718627214}, {"id": 49, "seek": 26400, "start": 279.0, "end": 286.0, "text": " And then thanks to Simba, we could build a lot of Gezi-like tools but for the web.", "tokens": [400, 550, 3231, 281, 3998, 4231, 11, 321, 727, 1322, 257, 688, 295, 2876, 3992, 12, 4092, 3873, 457, 337, 264, 3670, 13], "temperature": 0.0, "avg_logprob": -0.2381133666405311, "compression_ratio": 1.665137614678899, "no_speech_prob": 0.004434671718627214}, {"id": 50, "seek": 26400, "start": 286.0, "end": 291.0, "text": " So that we could do all those interactions that we do directly in a web page.", "tokens": [407, 300, 321, 727, 360, 439, 729, 13280, 300, 321, 360, 3838, 294, 257, 3670, 3028, 13], "temperature": 0.0, "avg_logprob": -0.2381133666405311, "compression_ratio": 1.665137614678899, "no_speech_prob": 0.004434671718627214}, {"id": 51, "seek": 29100, "start": 291.0, "end": 297.0, "text": " There's been a long history at Miguelab and around of trying to build such tools.", "tokens": [821, 311, 668, 257, 938, 2503, 412, 29150, 455, 293, 926, 295, 1382, 281, 1322, 1270, 3873, 13], "temperature": 0.0, "avg_logprob": -0.23923515319824218, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.0055117555893957615}, {"id": 52, "seek": 29100, "start": 297.0, "end": 299.0, "text": " Minivan was one of them.", "tokens": [2829, 24193, 390, 472, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.23923515319824218, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.0055117555893957615}, {"id": 53, "seek": 29100, "start": 299.0, "end": 308.0, "text": " There's also Nancy which is a very small, very publishing-oriented way of displaying a graph", "tokens": [821, 311, 611, 18154, 597, 307, 257, 588, 1359, 11, 588, 17832, 12, 27414, 636, 295, 36834, 257, 4295], "temperature": 0.0, "avg_logprob": -0.23923515319824218, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.0055117555893957615}, {"id": 54, "seek": 29100, "start": 308.0, "end": 316.0, "text": " with very few options so that you can just put your Gezi-like search file or GraphML file", "tokens": [365, 588, 1326, 3956, 370, 300, 291, 393, 445, 829, 428, 2876, 3992, 12, 4092, 3164, 3991, 420, 21884, 12683, 3991], "temperature": 0.0, "avg_logprob": -0.23923515319824218, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.0055117555893957615}, {"id": 55, "seek": 31600, "start": 316.0, "end": 321.0, "text": " and very easily do what you do on your Gezi.", "tokens": [293, 588, 3612, 360, 437, 291, 360, 322, 428, 2876, 3992, 13], "temperature": 0.0, "avg_logprob": -0.1667137502509857, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.002023071516305208}, {"id": 56, "seek": 31600, "start": 321.0, "end": 325.0, "text": " Retina is the one developed by people at Westware right now and is very rich,", "tokens": [11495, 1426, 307, 264, 472, 4743, 538, 561, 412, 4055, 3039, 558, 586, 293, 307, 588, 4593, 11], "temperature": 0.0, "avg_logprob": -0.1667137502509857, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.002023071516305208}, {"id": 57, "seek": 31600, "start": 325.0, "end": 327.0, "text": " proposing a lot of features.", "tokens": [29939, 257, 688, 295, 4122, 13], "temperature": 0.0, "avg_logprob": -0.1667137502509857, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.002023071516305208}, {"id": 58, "seek": 31600, "start": 327.0, "end": 335.0, "text": " And soon I think Mathieu and Mathieu will talk about it briefly also in the later talk about Gezi version 1.", "tokens": [400, 2321, 286, 519, 15776, 19347, 293, 15776, 19347, 486, 751, 466, 309, 10515, 611, 294, 264, 1780, 751, 466, 2876, 3992, 3037, 502, 13], "temperature": 0.0, "avg_logprob": -0.1667137502509857, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.002023071516305208}, {"id": 59, "seek": 31600, "start": 335.0, "end": 341.0, "text": " There's a Gezi-like version that's currently being developed and that should come in soon.", "tokens": [821, 311, 257, 2876, 3992, 12, 4092, 3037, 300, 311, 4362, 885, 4743, 293, 300, 820, 808, 294, 2321, 13], "temperature": 0.0, "avg_logprob": -0.1667137502509857, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.002023071516305208}, {"id": 60, "seek": 31600, "start": 341.0, "end": 345.0, "text": " Which brings me to all of those tools are very nice.", "tokens": [3013, 5607, 385, 281, 439, 295, 729, 3873, 366, 588, 1481, 13], "temperature": 0.0, "avg_logprob": -0.1667137502509857, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.002023071516305208}, {"id": 61, "seek": 34500, "start": 345.0, "end": 351.0, "text": " We have all those that are interactive and you can visualize, explore, publish,", "tokens": [492, 362, 439, 729, 300, 366, 15141, 293, 291, 393, 23273, 11, 6839, 11, 11374, 11], "temperature": 0.0, "avg_logprob": -0.19653542836507162, "compression_ratio": 1.587962962962963, "no_speech_prob": 0.0007852627313695848}, {"id": 62, "seek": 34500, "start": 351.0, "end": 358.0, "text": " manipulate all those graphs but they all require pre-processed graphs.", "tokens": [20459, 439, 729, 24877, 457, 436, 439, 3651, 659, 12, 41075, 292, 24877, 13], "temperature": 0.0, "avg_logprob": -0.19653542836507162, "compression_ratio": 1.587962962962963, "no_speech_prob": 0.0007852627313695848}, {"id": 63, "seek": 34500, "start": 358.0, "end": 364.0, "text": " You cannot just work with your graph while you're visualizing it.", "tokens": [509, 2644, 445, 589, 365, 428, 4295, 1339, 291, 434, 5056, 3319, 309, 13], "temperature": 0.0, "avg_logprob": -0.19653542836507162, "compression_ratio": 1.587962962962963, "no_speech_prob": 0.0007852627313695848}, {"id": 64, "seek": 34500, "start": 364.0, "end": 371.0, "text": " You have to pre-code in your file, usually JSON or JXF or GraphML,", "tokens": [509, 362, 281, 659, 12, 22332, 294, 428, 3991, 11, 2673, 31828, 420, 508, 55, 37, 420, 21884, 12683, 11], "temperature": 0.0, "avg_logprob": -0.19653542836507162, "compression_ratio": 1.587962962962963, "no_speech_prob": 0.0007852627313695848}, {"id": 65, "seek": 34500, "start": 371.0, "end": 374.0, "text": " then you load it into the tool and then you can explore it.", "tokens": [550, 291, 3677, 309, 666, 264, 2290, 293, 550, 291, 393, 6839, 309, 13], "temperature": 0.0, "avg_logprob": -0.19653542836507162, "compression_ratio": 1.587962962962963, "no_speech_prob": 0.0007852627313695848}, {"id": 66, "seek": 37400, "start": 374.0, "end": 377.0, "text": " But we would like to be able to do that at the same time.", "tokens": [583, 321, 576, 411, 281, 312, 1075, 281, 360, 300, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.16272938926264924, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0014147554757073522}, {"id": 67, "seek": 37400, "start": 377.0, "end": 381.0, "text": " And so that's where the idea of I by Sigma came from,", "tokens": [400, 370, 300, 311, 689, 264, 1558, 295, 286, 538, 36595, 1361, 490, 11], "temperature": 0.0, "avg_logprob": -0.16272938926264924, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0014147554757073522}, {"id": 68, "seek": 37400, "start": 381.0, "end": 389.0, "text": " to try and put within Jupyter a notebook, a widget that would display the graph using SigmaJS.", "tokens": [281, 853, 293, 829, 1951, 22125, 88, 391, 257, 21060, 11, 257, 34047, 300, 576, 4674, 264, 4295, 1228, 36595, 41, 50, 13], "temperature": 0.0, "avg_logprob": -0.16272938926264924, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0014147554757073522}, {"id": 69, "seek": 37400, "start": 389.0, "end": 394.0, "text": " So it's really easy to install as long as you have Jupyter.", "tokens": [407, 309, 311, 534, 1858, 281, 3625, 382, 938, 382, 291, 362, 22125, 88, 391, 13], "temperature": 0.0, "avg_logprob": -0.16272938926264924, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0014147554757073522}, {"id": 70, "seek": 37400, "start": 394.0, "end": 399.0, "text": " You usually need a tool to work with graphs under Python.", "tokens": [509, 2673, 643, 257, 2290, 281, 589, 365, 24877, 833, 15329, 13], "temperature": 0.0, "avg_logprob": -0.16272938926264924, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0014147554757073522}, {"id": 71, "seek": 37400, "start": 399.0, "end": 403.0, "text": " There's two main ones that you might know already about,", "tokens": [821, 311, 732, 2135, 2306, 300, 291, 1062, 458, 1217, 466, 11], "temperature": 0.0, "avg_logprob": -0.16272938926264924, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0014147554757073522}, {"id": 72, "seek": 40300, "start": 403.0, "end": 413.0, "text": " I by Sigma is built to handle both formats of graphs from both networks and I by Sigma.", "tokens": [286, 538, 36595, 307, 3094, 281, 4813, 1293, 25879, 295, 24877, 490, 1293, 9590, 293, 286, 538, 36595, 13], "temperature": 0.0, "avg_logprob": -0.393540577716138, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0028020760510116816}, {"id": 73, "seek": 40300, "start": 413.0, "end": 416.0, "text": " And so you just install I by Sigma in addition,", "tokens": [400, 370, 291, 445, 3625, 286, 538, 36595, 294, 4500, 11], "temperature": 0.0, "avg_logprob": -0.393540577716138, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0028020760510116816}, {"id": 74, "seek": 40300, "start": 416.0, "end": 419.0, "text": " and then I just switch to the brief demo.", "tokens": [293, 550, 286, 445, 3679, 281, 264, 5353, 10723, 13], "temperature": 0.0, "avg_logprob": -0.393540577716138, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0028020760510116816}, {"id": 75, "seek": 40300, "start": 419.0, "end": 422.0, "text": " Maybe at the seat.", "tokens": [2704, 412, 264, 6121, 13], "temperature": 0.0, "avg_logprob": -0.393540577716138, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0028020760510116816}, {"id": 76, "seek": 40300, "start": 422.0, "end": 427.0, "text": " So we'll do two small explorations of graphs.", "tokens": [407, 321, 603, 360, 732, 1359, 24765, 763, 295, 24877, 13], "temperature": 0.0, "avg_logprob": -0.393540577716138, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0028020760510116816}, {"id": 77, "seek": 40300, "start": 427.0, "end": 431.0, "text": " There's the first one that we're working on right now,", "tokens": [821, 311, 264, 700, 472, 300, 321, 434, 1364, 322, 558, 586, 11], "temperature": 0.0, "avg_logprob": -0.393540577716138, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0028020760510116816}, {"id": 78, "seek": 43100, "start": 431.0, "end": 436.0, "text": " which is on the, what I call the open source,", "tokens": [597, 307, 322, 264, 11, 437, 286, 818, 264, 1269, 4009, 11], "temperature": 0.0, "avg_logprob": -0.2434412490489871, "compression_ratio": 1.5922330097087378, "no_speech_prob": 0.0013357991119846702}, {"id": 79, "seek": 43100, "start": 436.0, "end": 441.0, "text": " I mean, actually larger than that, open access, open world.", "tokens": [286, 914, 11, 767, 4833, 813, 300, 11, 1269, 2105, 11, 1269, 1002, 13], "temperature": 0.0, "avg_logprob": -0.2434412490489871, "compression_ratio": 1.5922330097087378, "no_speech_prob": 0.0013357991119846702}, {"id": 80, "seek": 43100, "start": 441.0, "end": 448.0, "text": " It's like for them, but just in France and the French communities working on that.", "tokens": [467, 311, 411, 337, 552, 11, 457, 445, 294, 6190, 293, 264, 5522, 4456, 1364, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.2434412490489871, "compression_ratio": 1.5922330097087378, "no_speech_prob": 0.0013357991119846702}, {"id": 81, "seek": 43100, "start": 448.0, "end": 456.0, "text": " And so we built this network of websites, links together of those French communities of free software.", "tokens": [400, 370, 321, 3094, 341, 3209, 295, 12891, 11, 6123, 1214, 295, 729, 5522, 4456, 295, 1737, 4722, 13], "temperature": 0.0, "avg_logprob": -0.2434412490489871, "compression_ratio": 1.5922330097087378, "no_speech_prob": 0.0013357991119846702}, {"id": 82, "seek": 43100, "start": 456.0, "end": 458.0, "text": " And let's take a look at it as well.", "tokens": [400, 718, 311, 747, 257, 574, 412, 309, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.2434412490489871, "compression_ratio": 1.5922330097087378, "no_speech_prob": 0.0013357991119846702}, {"id": 83, "seek": 45800, "start": 458.0, "end": 461.0, "text": " So first, I will import the projects.", "tokens": [407, 700, 11, 286, 486, 974, 264, 4455, 13], "temperature": 0.0, "avg_logprob": -0.26133645547402873, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.005648541264235973}, {"id": 84, "seek": 45800, "start": 461.0, "end": 464.0, "text": " Then I'm reading the graph that I built already.", "tokens": [1396, 286, 478, 3760, 264, 4295, 300, 286, 3094, 1217, 13], "temperature": 0.0, "avg_logprob": -0.26133645547402873, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.005648541264235973}, {"id": 85, "seek": 45800, "start": 464.0, "end": 466.0, "text": " So that's all this first example.", "tokens": [407, 300, 311, 439, 341, 700, 1365, 13], "temperature": 0.0, "avg_logprob": -0.26133645547402873, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.005648541264235973}, {"id": 86, "seek": 45800, "start": 466.0, "end": 472.0, "text": " So here we have a graph with 621 nodes and 7000 edges.", "tokens": [407, 510, 321, 362, 257, 4295, 365, 1386, 4436, 13891, 293, 1614, 1360, 8819, 13], "temperature": 0.0, "avg_logprob": -0.26133645547402873, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.005648541264235973}, {"id": 87, "seek": 45800, "start": 472.0, "end": 474.0, "text": " Let's look at the node.", "tokens": [961, 311, 574, 412, 264, 9984, 13], "temperature": 0.0, "avg_logprob": -0.26133645547402873, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.005648541264235973}, {"id": 88, "seek": 45800, "start": 474.0, "end": 478.0, "text": " So the first node, I don't see that information.", "tokens": [407, 264, 700, 9984, 11, 286, 500, 380, 536, 300, 1589, 13], "temperature": 0.0, "avg_logprob": -0.26133645547402873, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.005648541264235973}, {"id": 89, "seek": 45800, "start": 478.0, "end": 479.0, "text": " It's April.org.", "tokens": [467, 311, 6929, 13, 4646, 13], "temperature": 0.0, "avg_logprob": -0.26133645547402873, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.005648541264235973}, {"id": 90, "seek": 45800, "start": 479.0, "end": 482.0, "text": " I don't know if the French people are in the room,", "tokens": [286, 500, 380, 458, 498, 264, 5522, 561, 366, 294, 264, 1808, 11], "temperature": 0.0, "avg_logprob": -0.26133645547402873, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.005648541264235973}, {"id": 91, "seek": 45800, "start": 482.0, "end": 487.0, "text": " but people should know that April is from France.", "tokens": [457, 561, 820, 458, 300, 6929, 307, 490, 6190, 13], "temperature": 0.0, "avg_logprob": -0.26133645547402873, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.005648541264235973}, {"id": 92, "seek": 48700, "start": 487.0, "end": 494.0, "text": " It's the main NGO in France about open source and just the graph.", "tokens": [467, 311, 264, 2135, 31456, 294, 6190, 466, 1269, 4009, 293, 445, 264, 4295, 13], "temperature": 0.0, "avg_logprob": -0.29613645871480304, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.003622592892497778}, {"id": 93, "seek": 48700, "start": 494.0, "end": 496.0, "text": " So we have this whole page.", "tokens": [407, 321, 362, 341, 1379, 3028, 13], "temperature": 0.0, "avg_logprob": -0.29613645871480304, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.003622592892497778}, {"id": 94, "seek": 48700, "start": 496.0, "end": 499.0, "text": " That's all the data that was collected while making the graph.", "tokens": [663, 311, 439, 264, 1412, 300, 390, 11087, 1339, 1455, 264, 4295, 13], "temperature": 0.0, "avg_logprob": -0.29613645871480304, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.003622592892497778}, {"id": 95, "seek": 48700, "start": 499.0, "end": 505.0, "text": " And then let's try to just visualize it by just loading i5 sigma,", "tokens": [400, 550, 718, 311, 853, 281, 445, 23273, 309, 538, 445, 15114, 741, 20, 12771, 11], "temperature": 0.0, "avg_logprob": -0.29613645871480304, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.003622592892497778}, {"id": 96, "seek": 48700, "start": 505.0, "end": 508.0, "text": " importing sigma and applying it to the graph.", "tokens": [43866, 12771, 293, 9275, 309, 281, 264, 4295, 13], "temperature": 0.0, "avg_logprob": -0.29613645871480304, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.003622592892497778}, {"id": 97, "seek": 50800, "start": 508.0, "end": 517.0, "text": " Here, just by the widget with the graph, which is randomly specialized.", "tokens": [1692, 11, 445, 538, 264, 34047, 365, 264, 4295, 11, 597, 307, 16979, 19813, 13], "temperature": 0.0, "avg_logprob": -0.37547996808897777, "compression_ratio": 1.2992700729927007, "no_speech_prob": 0.00194405613001436}, {"id": 98, "seek": 50800, "start": 517.0, "end": 520.0, "text": " We have metadata information.", "tokens": [492, 362, 26603, 1589, 13], "temperature": 0.0, "avg_logprob": -0.37547996808897777, "compression_ratio": 1.2992700729927007, "no_speech_prob": 0.00194405613001436}, {"id": 99, "seek": 50800, "start": 526.0, "end": 529.0, "text": " So we can run for FATAS on it.", "tokens": [407, 321, 393, 1190, 337, 479, 2218, 3160, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.37547996808897777, "compression_ratio": 1.2992700729927007, "no_speech_prob": 0.00194405613001436}, {"id": 100, "seek": 50800, "start": 529.0, "end": 531.0, "text": " So very easy.", "tokens": [407, 588, 1858, 13], "temperature": 0.0, "avg_logprob": -0.37547996808897777, "compression_ratio": 1.2992700729927007, "no_speech_prob": 0.00194405613001436}, {"id": 101, "seek": 50800, "start": 531.0, "end": 534.0, "text": " You see your specialized graph.", "tokens": [509, 536, 428, 19813, 4295, 13], "temperature": 0.0, "avg_logprob": -0.37547996808897777, "compression_ratio": 1.2992700729927007, "no_speech_prob": 0.00194405613001436}, {"id": 102, "seek": 53400, "start": 534.0, "end": 541.0, "text": " Just a few seconds, and then we can also apply some...", "tokens": [1449, 257, 1326, 3949, 11, 293, 550, 321, 393, 611, 3079, 512, 485], "temperature": 0.0, "avg_logprob": -0.29835656004131966, "compression_ratio": 1.5646551724137931, "no_speech_prob": 0.0013451663544401526}, {"id": 103, "seek": 53400, "start": 541.0, "end": 545.0, "text": " The graph is too dense for that.", "tokens": [440, 4295, 307, 886, 18011, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.29835656004131966, "compression_ratio": 1.5646551724137931, "no_speech_prob": 0.0013451663544401526}, {"id": 104, "seek": 53400, "start": 545.0, "end": 547.0, "text": " And suddenly no effect.", "tokens": [400, 5800, 572, 1802, 13], "temperature": 0.0, "avg_logprob": -0.29835656004131966, "compression_ratio": 1.5646551724137931, "no_speech_prob": 0.0013451663544401526}, {"id": 105, "seek": 53400, "start": 547.0, "end": 549.0, "text": " So yeah, but right now it's just a graph", "tokens": [407, 1338, 11, 457, 558, 586, 309, 311, 445, 257, 4295], "temperature": 0.0, "avg_logprob": -0.29835656004131966, "compression_ratio": 1.5646551724137931, "no_speech_prob": 0.0013451663544401526}, {"id": 106, "seek": 53400, "start": 549.0, "end": 551.0, "text": " and we don't have much information.", "tokens": [293, 321, 500, 380, 362, 709, 1589, 13], "temperature": 0.0, "avg_logprob": -0.29835656004131966, "compression_ratio": 1.5646551724137931, "no_speech_prob": 0.0013451663544401526}, {"id": 107, "seek": 53400, "start": 551.0, "end": 553.0, "text": " It's very complicated readable.", "tokens": [467, 311, 588, 6179, 49857, 13], "temperature": 0.0, "avg_logprob": -0.29835656004131966, "compression_ratio": 1.5646551724137931, "no_speech_prob": 0.0013451663544401526}, {"id": 108, "seek": 53400, "start": 553.0, "end": 558.0, "text": " So let's go down and try to add a few other options to the sigma code.", "tokens": [407, 718, 311, 352, 760, 293, 853, 281, 909, 257, 1326, 661, 3956, 281, 264, 12771, 3089, 13], "temperature": 0.0, "avg_logprob": -0.29835656004131966, "compression_ratio": 1.5646551724137931, "no_speech_prob": 0.0013451663544401526}, {"id": 109, "seek": 53400, "start": 558.0, "end": 561.0, "text": " So we can set the outside standards.", "tokens": [407, 321, 393, 992, 264, 2380, 7787, 13], "temperature": 0.0, "avg_logprob": -0.29835656004131966, "compression_ratio": 1.5646551724137931, "no_speech_prob": 0.0013451663544401526}, {"id": 110, "seek": 53400, "start": 561.0, "end": 563.0, "text": " Let's use the number of pages for.", "tokens": [961, 311, 764, 264, 1230, 295, 7183, 337, 13], "temperature": 0.0, "avg_logprob": -0.29835656004131966, "compression_ratio": 1.5646551724137931, "no_speech_prob": 0.0013451663544401526}, {"id": 111, "seek": 56300, "start": 563.0, "end": 567.0, "text": " So here I can see that for this graph use,", "tokens": [407, 510, 286, 393, 536, 300, 337, 341, 4295, 764, 11], "temperature": 0.0, "avg_logprob": -0.20791812275731286, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.001423321315087378}, {"id": 112, "seek": 56300, "start": 567.0, "end": 571.0, "text": " we put a lot of pages on some specific websites.", "tokens": [321, 829, 257, 688, 295, 7183, 322, 512, 2685, 12891, 13], "temperature": 0.0, "avg_logprob": -0.20791812275731286, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.001423321315087378}, {"id": 113, "seek": 56300, "start": 571.0, "end": 576.0, "text": " Let's put a little bit more and try to adjust the sizes of the nodes.", "tokens": [961, 311, 829, 257, 707, 857, 544, 293, 853, 281, 4369, 264, 11602, 295, 264, 13891, 13], "temperature": 0.0, "avg_logprob": -0.20791812275731286, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.001423321315087378}, {"id": 114, "seek": 56300, "start": 576.0, "end": 579.0, "text": " So we can adjust the range of the values for instance.", "tokens": [407, 321, 393, 4369, 264, 3613, 295, 264, 4190, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.20791812275731286, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.001423321315087378}, {"id": 115, "seek": 56300, "start": 579.0, "end": 582.0, "text": " Here it's really readable.", "tokens": [1692, 309, 311, 534, 49857, 13], "temperature": 0.0, "avg_logprob": -0.20791812275731286, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.001423321315087378}, {"id": 116, "seek": 56300, "start": 585.0, "end": 587.0, "text": " Okay, so we got sizes.", "tokens": [1033, 11, 370, 321, 658, 11602, 13], "temperature": 0.0, "avg_logprob": -0.20791812275731286, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.001423321315087378}, {"id": 117, "seek": 56300, "start": 587.0, "end": 589.0, "text": " Let's add some colors.", "tokens": [961, 311, 909, 512, 4577, 13], "temperature": 0.0, "avg_logprob": -0.20791812275731286, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.001423321315087378}, {"id": 118, "seek": 58900, "start": 589.0, "end": 595.0, "text": " So iBuySigma proposes some internal metrics that you can compute on the fly.", "tokens": [407, 741, 33, 7493, 50, 16150, 2365, 4201, 512, 6920, 16367, 300, 291, 393, 14722, 322, 264, 3603, 13], "temperature": 0.0, "avg_logprob": -0.4832309456758721, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.006183096207678318}, {"id": 119, "seek": 58900, "start": 595.0, "end": 600.0, "text": " So for instance, as a result, it generates clusters.", "tokens": [407, 337, 5197, 11, 382, 257, 1874, 11, 309, 23815, 23313, 13], "temperature": 0.0, "avg_logprob": -0.4832309456758721, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.006183096207678318}, {"id": 120, "seek": 58900, "start": 600.0, "end": 603.0, "text": " And we will apply colors to the map.", "tokens": [400, 321, 486, 3079, 4577, 281, 264, 4471, 13], "temperature": 0.0, "avg_logprob": -0.4832309456758721, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.006183096207678318}, {"id": 121, "seek": 58900, "start": 603.0, "end": 607.0, "text": " I mean we will apply those color communities as colors.", "tokens": [286, 914, 321, 486, 3079, 729, 2017, 4456, 382, 4577, 13], "temperature": 0.0, "avg_logprob": -0.4832309456758721, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.006183096207678318}, {"id": 122, "seek": 58900, "start": 607.0, "end": 610.0, "text": " So here we get a set graph of colors.", "tokens": [407, 510, 321, 483, 257, 992, 4295, 295, 4577, 13], "temperature": 0.0, "avg_logprob": -0.4832309456758721, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.006183096207678318}, {"id": 123, "seek": 58900, "start": 610.0, "end": 614.0, "text": " Let's see that there are a lot of communities.", "tokens": [961, 311, 536, 300, 456, 366, 257, 688, 295, 4456, 13], "temperature": 0.0, "avg_logprob": -0.4832309456758721, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.006183096207678318}, {"id": 124, "seek": 61400, "start": 614.0, "end": 619.0, "text": " As knowing this network and knowing this community,", "tokens": [1018, 5276, 341, 3209, 293, 5276, 341, 1768, 11], "temperature": 0.0, "avg_logprob": -0.26338978166933413, "compression_ratio": 1.6, "no_speech_prob": 0.002418157644569874}, {"id": 125, "seek": 61400, "start": 619.0, "end": 623.0, "text": " I can tell you that basically what this is.", "tokens": [286, 393, 980, 291, 300, 1936, 437, 341, 307, 13], "temperature": 0.0, "avg_logprob": -0.26338978166933413, "compression_ratio": 1.6, "no_speech_prob": 0.002418157644569874}, {"id": 126, "seek": 61400, "start": 628.0, "end": 635.0, "text": " Here we got the open data, open command community.", "tokens": [1692, 321, 658, 264, 1269, 1412, 11, 1269, 5622, 1768, 13], "temperature": 0.0, "avg_logprob": -0.26338978166933413, "compression_ratio": 1.6, "no_speech_prob": 0.002418157644569874}, {"id": 127, "seek": 61400, "start": 635.0, "end": 641.0, "text": " Here we got uphill and basically the NGOs working on the open source.", "tokens": [1692, 321, 658, 39132, 293, 1936, 264, 46454, 1364, 322, 264, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.26338978166933413, "compression_ratio": 1.6, "no_speech_prob": 0.002418157644569874}, {"id": 128, "seek": 64100, "start": 641.0, "end": 647.0, "text": " Here we got GIL and it's mostly a lot of softwares.", "tokens": [1692, 321, 658, 460, 4620, 293, 309, 311, 5240, 257, 688, 295, 2787, 4151, 495, 13], "temperature": 0.0, "avg_logprob": -0.4178476333618164, "compression_ratio": 1.4195402298850575, "no_speech_prob": 0.0023908577859401703}, {"id": 129, "seek": 64100, "start": 647.0, "end": 651.0, "text": " Fedora and all the Linux distributions.", "tokens": [7772, 3252, 293, 439, 264, 18734, 37870, 13], "temperature": 0.0, "avg_logprob": -0.4178476333618164, "compression_ratio": 1.4195402298850575, "no_speech_prob": 0.0023908577859401703}, {"id": 130, "seek": 64100, "start": 651.0, "end": 654.0, "text": " Here we got FFDL, MaproductionDenets,", "tokens": [1692, 321, 658, 479, 37, 35, 43, 11, 22053, 2323, 882, 35, 268, 1385, 11], "temperature": 0.0, "avg_logprob": -0.4178476333618164, "compression_ratio": 1.4195402298850575, "no_speech_prob": 0.0023908577859401703}, {"id": 131, "seek": 64100, "start": 654.0, "end": 659.0, "text": " and all those activists working with the open internet.", "tokens": [293, 439, 729, 23042, 1364, 365, 264, 1269, 4705, 13], "temperature": 0.0, "avg_logprob": -0.4178476333618164, "compression_ratio": 1.4195402298850575, "no_speech_prob": 0.0023908577859401703}, {"id": 132, "seek": 64100, "start": 659.0, "end": 663.0, "text": " And I guess here is more the...", "tokens": [400, 286, 2041, 510, 307, 544, 264, 485], "temperature": 0.0, "avg_logprob": -0.4178476333618164, "compression_ratio": 1.4195402298850575, "no_speech_prob": 0.0023908577859401703}, {"id": 133, "seek": 64100, "start": 663.0, "end": 666.0, "text": " Oh, it's also a mobilization.", "tokens": [876, 11, 309, 311, 611, 257, 15891, 2144, 13], "temperature": 0.0, "avg_logprob": -0.4178476333618164, "compression_ratio": 1.4195402298850575, "no_speech_prob": 0.0023908577859401703}, {"id": 134, "seek": 66600, "start": 666.0, "end": 671.0, "text": " It's a form of formigated old form of food.", "tokens": [467, 311, 257, 1254, 295, 1254, 328, 770, 1331, 1254, 295, 1755, 13], "temperature": 0.0, "avg_logprob": -0.4534938552162864, "compression_ratio": 1.5674157303370786, "no_speech_prob": 0.007101466879248619}, {"id": 135, "seek": 66600, "start": 671.0, "end": 674.0, "text": " I'll just speak a little bit.", "tokens": [286, 603, 445, 1710, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.4534938552162864, "compression_ratio": 1.5674157303370786, "no_speech_prob": 0.007101466879248619}, {"id": 136, "seek": 66600, "start": 674.0, "end": 679.0, "text": " Okay, so now that we got this, let's try to make it a little bit nicer.", "tokens": [1033, 11, 370, 586, 300, 321, 658, 341, 11, 718, 311, 853, 281, 652, 309, 257, 707, 857, 22842, 13], "temperature": 0.0, "avg_logprob": -0.4534938552162864, "compression_ratio": 1.5674157303370786, "no_speech_prob": 0.007101466879248619}, {"id": 137, "seek": 66600, "start": 679.0, "end": 685.0, "text": " We can add, for instance, some border colors.", "tokens": [492, 393, 909, 11, 337, 5197, 11, 512, 7838, 4577, 13], "temperature": 0.0, "avg_logprob": -0.4534938552162864, "compression_ratio": 1.5674157303370786, "no_speech_prob": 0.007101466879248619}, {"id": 138, "seek": 66600, "start": 685.0, "end": 691.0, "text": " So it just proposes to see a stronger border of colors.", "tokens": [407, 309, 445, 2365, 4201, 281, 536, 257, 7249, 7838, 295, 4577, 13], "temperature": 0.0, "avg_logprob": -0.4534938552162864, "compression_ratio": 1.5674157303370786, "no_speech_prob": 0.007101466879248619}, {"id": 139, "seek": 66600, "start": 691.0, "end": 694.0, "text": " Graphs are a little bit sexier.", "tokens": [21884, 82, 366, 257, 707, 857, 3260, 811, 13], "temperature": 0.0, "avg_logprob": -0.4534938552162864, "compression_ratio": 1.5674157303370786, "no_speech_prob": 0.007101466879248619}, {"id": 140, "seek": 69400, "start": 694.0, "end": 699.0, "text": " We can also try to do like Gephi, like curled edges.", "tokens": [492, 393, 611, 853, 281, 360, 411, 460, 595, 4954, 11, 411, 1262, 1493, 8819, 13], "temperature": 0.0, "avg_logprob": -0.23870705691250887, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0018587716622278094}, {"id": 141, "seek": 69400, "start": 699.0, "end": 701.0, "text": " All of those are in options.", "tokens": [1057, 295, 729, 366, 294, 3956, 13], "temperature": 0.0, "avg_logprob": -0.23870705691250887, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0018587716622278094}, {"id": 142, "seek": 69400, "start": 701.0, "end": 705.0, "text": " I guess I'll show you briefly later on a list of the different options.", "tokens": [286, 2041, 286, 603, 855, 291, 10515, 1780, 322, 257, 1329, 295, 264, 819, 3956, 13], "temperature": 0.0, "avg_logprob": -0.23870705691250887, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0018587716622278094}, {"id": 143, "seek": 69400, "start": 705.0, "end": 709.0, "text": " Here we also put the recursive font to the level.", "tokens": [1692, 321, 611, 829, 264, 20560, 488, 10703, 281, 264, 1496, 13], "temperature": 0.0, "avg_logprob": -0.23870705691250887, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0018587716622278094}, {"id": 144, "seek": 69400, "start": 709.0, "end": 712.0, "text": " So basically you can do a lot of things.", "tokens": [407, 1936, 291, 393, 360, 257, 688, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.23870705691250887, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0018587716622278094}, {"id": 145, "seek": 69400, "start": 712.0, "end": 715.0, "text": " But all of that so far is mostly like Gephi.", "tokens": [583, 439, 295, 300, 370, 1400, 307, 5240, 411, 460, 595, 4954, 13], "temperature": 0.0, "avg_logprob": -0.23870705691250887, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0018587716622278094}, {"id": 146, "seek": 69400, "start": 715.0, "end": 718.0, "text": " There's no real new thing.", "tokens": [821, 311, 572, 957, 777, 551, 13], "temperature": 0.0, "avg_logprob": -0.23870705691250887, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0018587716622278094}, {"id": 147, "seek": 69400, "start": 718.0, "end": 723.0, "text": " But here's something that actually proposes something else.", "tokens": [583, 510, 311, 746, 300, 767, 2365, 4201, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.23870705691250887, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0018587716622278094}, {"id": 148, "seek": 72300, "start": 723.0, "end": 726.0, "text": " So right now we can see one graph.", "tokens": [407, 558, 586, 321, 393, 536, 472, 4295, 13], "temperature": 0.0, "avg_logprob": -0.16278599330357144, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.0011499440297484398}, {"id": 149, "seek": 72300, "start": 726.0, "end": 730.0, "text": " But let's try and see multiple ones.", "tokens": [583, 718, 311, 853, 293, 536, 3866, 2306, 13], "temperature": 0.0, "avg_logprob": -0.16278599330357144, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.0011499440297484398}, {"id": 150, "seek": 72300, "start": 730.0, "end": 734.0, "text": " So I buy similar properties, what we call a similar grid.", "tokens": [407, 286, 2256, 2531, 7221, 11, 437, 321, 818, 257, 2531, 10748, 13], "temperature": 0.0, "avg_logprob": -0.16278599330357144, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.0011499440297484398}, {"id": 151, "seek": 72300, "start": 734.0, "end": 739.0, "text": " And so I will put the same graph, but it will trickle out.", "tokens": [400, 370, 286, 486, 829, 264, 912, 4295, 11, 457, 309, 486, 4282, 306, 484, 13], "temperature": 0.0, "avg_logprob": -0.16278599330357144, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.0011499440297484398}, {"id": 152, "seek": 72300, "start": 739.0, "end": 744.0, "text": " And those will be common options that I set for all versions of the graph.", "tokens": [400, 729, 486, 312, 2689, 3956, 300, 286, 992, 337, 439, 9606, 295, 264, 4295, 13], "temperature": 0.0, "avg_logprob": -0.16278599330357144, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.0011499440297484398}, {"id": 153, "seek": 72300, "start": 744.0, "end": 748.0, "text": " But then, within the grid, I will add three different versions of the graph", "tokens": [583, 550, 11, 1951, 264, 10748, 11, 286, 486, 909, 1045, 819, 9606, 295, 264, 4295], "temperature": 0.0, "avg_logprob": -0.16278599330357144, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.0011499440297484398}, {"id": 154, "seek": 72300, "start": 748.0, "end": 752.0, "text": " using different metrics for the size of the load.", "tokens": [1228, 819, 16367, 337, 264, 2744, 295, 264, 3677, 13], "temperature": 0.0, "avg_logprob": -0.16278599330357144, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.0011499440297484398}, {"id": 155, "seek": 75200, "start": 752.0, "end": 754.0, "text": " So here's one on the left one.", "tokens": [407, 510, 311, 472, 322, 264, 1411, 472, 13], "temperature": 0.0, "avg_logprob": -0.4484021638569079, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.00048609141958877444}, {"id": 156, "seek": 75200, "start": 754.0, "end": 757.0, "text": " And we see it's on the middle of the degree.", "tokens": [400, 321, 536, 309, 311, 322, 264, 2808, 295, 264, 4314, 13], "temperature": 0.0, "avg_logprob": -0.4484021638569079, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.00048609141958877444}, {"id": 157, "seek": 75200, "start": 757.0, "end": 761.0, "text": " And the right one on the bottom.", "tokens": [400, 264, 558, 472, 322, 264, 2767, 13], "temperature": 0.0, "avg_logprob": -0.4484021638569079, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.00048609141958877444}, {"id": 158, "seek": 75200, "start": 761.0, "end": 766.0, "text": " Now I'm going to add this.", "tokens": [823, 286, 478, 516, 281, 909, 341, 13], "temperature": 0.0, "avg_logprob": -0.4484021638569079, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.00048609141958877444}, {"id": 159, "seek": 75200, "start": 766.0, "end": 773.0, "text": " So here are the three graphs, which are all synchronized.", "tokens": [407, 510, 366, 264, 1045, 24877, 11, 597, 366, 439, 19331, 1602, 13], "temperature": 0.0, "avg_logprob": -0.4484021638569079, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.00048609141958877444}, {"id": 160, "seek": 75200, "start": 773.0, "end": 776.0, "text": " If I visualize it, it happens at the same time.", "tokens": [759, 286, 23273, 309, 11, 309, 2314, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.4484021638569079, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.00048609141958877444}, {"id": 161, "seek": 75200, "start": 776.0, "end": 781.0, "text": " If I over-enode, I will see it on the three different versions.", "tokens": [759, 286, 670, 12, 268, 1429, 11, 286, 486, 536, 309, 322, 264, 1045, 819, 9606, 13], "temperature": 0.0, "avg_logprob": -0.4484021638569079, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.00048609141958877444}, {"id": 162, "seek": 78100, "start": 781.0, "end": 787.0, "text": " And then if I zoom a little bit, I guess we can see that...", "tokens": [400, 550, 498, 286, 8863, 257, 707, 857, 11, 286, 2041, 321, 393, 536, 300, 485], "temperature": 0.0, "avg_logprob": -0.1987566142887264, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00036976710543967783}, {"id": 163, "seek": 78100, "start": 787.0, "end": 789.0, "text": " Wow.", "tokens": [3153, 13], "temperature": 0.0, "avg_logprob": -0.1987566142887264, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00036976710543967783}, {"id": 164, "seek": 78100, "start": 789.0, "end": 791.0, "text": " What can we see?", "tokens": [708, 393, 321, 536, 30], "temperature": 0.0, "avg_logprob": -0.1987566142887264, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00036976710543967783}, {"id": 165, "seek": 78100, "start": 791.0, "end": 798.0, "text": " We can see that PharmaSoft, for instance, is very connected most globally,", "tokens": [492, 393, 536, 300, 2623, 36159, 6455, 844, 11, 337, 5197, 11, 307, 588, 4582, 881, 18958, 11], "temperature": 0.0, "avg_logprob": -0.1987566142887264, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00036976710543967783}, {"id": 166, "seek": 78100, "start": 798.0, "end": 804.0, "text": " but especially it has a very strong in-degree and not so big out-degree.", "tokens": [457, 2318, 309, 575, 257, 588, 2068, 294, 12, 34368, 293, 406, 370, 955, 484, 12, 34368, 13], "temperature": 0.0, "avg_logprob": -0.1987566142887264, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00036976710543967783}, {"id": 167, "seek": 78100, "start": 804.0, "end": 806.0, "text": " Why is that?", "tokens": [1545, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.1987566142887264, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00036976710543967783}, {"id": 168, "seek": 80600, "start": 806.0, "end": 811.0, "text": " PharmaSoft is such a reference in France for open-source tools", "tokens": [2623, 36159, 6455, 844, 307, 1270, 257, 6408, 294, 6190, 337, 1269, 12, 41676, 3873], "temperature": 0.0, "avg_logprob": -0.15632842449431725, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.0008305483497679234}, {"id": 169, "seek": 80600, "start": 811.0, "end": 814.0, "text": " that it gets a lot of links from the whole community.", "tokens": [300, 309, 2170, 257, 688, 295, 6123, 490, 264, 1379, 1768, 13], "temperature": 0.0, "avg_logprob": -0.15632842449431725, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.0008305483497679234}, {"id": 170, "seek": 80600, "start": 814.0, "end": 817.0, "text": " And all websites of the Free Software community point to it,", "tokens": [400, 439, 12891, 295, 264, 11551, 27428, 1768, 935, 281, 309, 11], "temperature": 0.0, "avg_logprob": -0.15632842449431725, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.0008305483497679234}, {"id": 171, "seek": 80600, "start": 817.0, "end": 820.0, "text": " because it's like a resource.", "tokens": [570, 309, 311, 411, 257, 7684, 13], "temperature": 0.0, "avg_logprob": -0.15632842449431725, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.0008305483497679234}, {"id": 172, "seek": 80600, "start": 820.0, "end": 826.0, "text": " Whereas, of course, they cannot point to the whole rest of the community.", "tokens": [13813, 11, 295, 1164, 11, 436, 2644, 935, 281, 264, 1379, 1472, 295, 264, 1768, 13], "temperature": 0.0, "avg_logprob": -0.15632842449431725, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.0008305483497679234}, {"id": 173, "seek": 80600, "start": 826.0, "end": 830.0, "text": " On another note, I guess we could find...", "tokens": [1282, 1071, 3637, 11, 286, 2041, 321, 727, 915, 485], "temperature": 0.0, "avg_logprob": -0.15632842449431725, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.0008305483497679234}, {"id": 174, "seek": 80600, "start": 830.0, "end": 833.0, "text": " I think there was Linux...", "tokens": [286, 519, 456, 390, 18734, 485], "temperature": 0.0, "avg_logprob": -0.15632842449431725, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.0008305483497679234}, {"id": 175, "seek": 83300, "start": 833.0, "end": 836.0, "text": " Linux-affair.org is the opposite.", "tokens": [18734, 12, 2518, 1246, 13, 4646, 307, 264, 6182, 13], "temperature": 0.0, "avg_logprob": -0.1502442459265391, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00035784399369731545}, {"id": 176, "seek": 83300, "start": 836.0, "end": 843.0, "text": " It's a media that pretty much talks about anything that happens on open-source in France.", "tokens": [467, 311, 257, 3021, 300, 1238, 709, 6686, 466, 1340, 300, 2314, 322, 1269, 12, 41676, 294, 6190, 13], "temperature": 0.0, "avg_logprob": -0.1502442459265391, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00035784399369731545}, {"id": 177, "seek": 83300, "start": 843.0, "end": 847.0, "text": " And, of course, they're the ones having the most outlinks.", "tokens": [400, 11, 295, 1164, 11, 436, 434, 264, 2306, 1419, 264, 881, 484, 75, 16431, 13], "temperature": 0.0, "avg_logprob": -0.1502442459265391, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00035784399369731545}, {"id": 178, "seek": 83300, "start": 847.0, "end": 850.0, "text": " All right, so that's just a small example.", "tokens": [1057, 558, 11, 370, 300, 311, 445, 257, 1359, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1502442459265391, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00035784399369731545}, {"id": 179, "seek": 83300, "start": 850.0, "end": 856.0, "text": " Then I can show you maybe another notebook that will show other things.", "tokens": [1396, 286, 393, 855, 291, 1310, 1071, 21060, 300, 486, 855, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.1502442459265391, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00035784399369731545}, {"id": 180, "seek": 83300, "start": 856.0, "end": 861.0, "text": " So this one is a notebook that was built out of data", "tokens": [407, 341, 472, 307, 257, 21060, 300, 390, 3094, 484, 295, 1412], "temperature": 0.0, "avg_logprob": -0.1502442459265391, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00035784399369731545}, {"id": 181, "seek": 86100, "start": 861.0, "end": 864.0, "text": " collected by Laura Miguel, which is a trainee at Media Lab right now.", "tokens": [11087, 538, 13220, 29150, 11, 597, 307, 257, 40350, 412, 14741, 10137, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.11967562645980992, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00023679841251578182}, {"id": 182, "seek": 86100, "start": 864.0, "end": 869.0, "text": " And she scraped the first-day website, the agendas,", "tokens": [400, 750, 13943, 3452, 264, 700, 12, 810, 3144, 11, 264, 623, 45252, 11], "temperature": 0.0, "avg_logprob": -0.11967562645980992, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00023679841251578182}, {"id": 183, "seek": 86100, "start": 869.0, "end": 875.0, "text": " to try and get all speakers and rooms over the past 15 years.", "tokens": [281, 853, 293, 483, 439, 9518, 293, 9396, 670, 264, 1791, 2119, 924, 13], "temperature": 0.0, "avg_logprob": -0.11967562645980992, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00023679841251578182}, {"id": 184, "seek": 86100, "start": 875.0, "end": 880.0, "text": " So here we will have to build the graph progressively.", "tokens": [407, 510, 321, 486, 362, 281, 1322, 264, 4295, 46667, 13], "temperature": 0.0, "avg_logprob": -0.11967562645980992, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00023679841251578182}, {"id": 185, "seek": 86100, "start": 880.0, "end": 886.0, "text": " We just had a CSV that she scraped of the data of one speaker and one room.", "tokens": [492, 445, 632, 257, 48814, 300, 750, 13943, 3452, 295, 264, 1412, 295, 472, 8145, 293, 472, 1808, 13], "temperature": 0.0, "avg_logprob": -0.11967562645980992, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00023679841251578182}, {"id": 186, "seek": 86100, "start": 886.0, "end": 889.0, "text": " Disclaimer, the speakers have been anonymized.", "tokens": [19839, 35220, 11, 264, 9518, 362, 668, 37293, 1602, 13], "temperature": 0.0, "avg_logprob": -0.11967562645980992, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00023679841251578182}, {"id": 187, "seek": 88900, "start": 889.0, "end": 893.0, "text": " So you won't find a name that you know about,", "tokens": [407, 291, 1582, 380, 915, 257, 1315, 300, 291, 458, 466, 11], "temperature": 0.0, "avg_logprob": -0.11281867074494314, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.00032418305636383593}, {"id": 188, "seek": 88900, "start": 893.0, "end": 897.0, "text": " but they represent actual people.", "tokens": [457, 436, 2906, 3539, 561, 13], "temperature": 0.0, "avg_logprob": -0.11281867074494314, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.00032418305636383593}, {"id": 189, "seek": 88900, "start": 897.0, "end": 901.0, "text": " So let's take a look at, for instance, three examples of the data.", "tokens": [407, 718, 311, 747, 257, 574, 412, 11, 337, 5197, 11, 1045, 5110, 295, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.11281867074494314, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.00032418305636383593}, {"id": 190, "seek": 88900, "start": 901.0, "end": 904.0, "text": " So those are the three first lines.", "tokens": [407, 729, 366, 264, 1045, 700, 3876, 13], "temperature": 0.0, "avg_logprob": -0.11281867074494314, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.00032418305636383593}, {"id": 191, "seek": 88900, "start": 904.0, "end": 908.0, "text": " I mean, that's one line and two other lines that I picked specifically.", "tokens": [286, 914, 11, 300, 311, 472, 1622, 293, 732, 661, 3876, 300, 286, 6183, 4682, 13], "temperature": 0.0, "avg_logprob": -0.11281867074494314, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.00032418305636383593}, {"id": 192, "seek": 88900, "start": 908.0, "end": 913.0, "text": " This one is one speaker, and she talked about within this track.", "tokens": [639, 472, 307, 472, 8145, 11, 293, 750, 2825, 466, 1951, 341, 2837, 13], "temperature": 0.0, "avg_logprob": -0.11281867074494314, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.00032418305636383593}, {"id": 193, "seek": 88900, "start": 913.0, "end": 917.0, "text": " Here it was a stock that was shared between two speakers.", "tokens": [1692, 309, 390, 257, 4127, 300, 390, 5507, 1296, 732, 9518, 13], "temperature": 0.0, "avg_logprob": -0.11281867074494314, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.00032418305636383593}, {"id": 194, "seek": 91700, "start": 917.0, "end": 920.0, "text": " So sometimes we get speakers separated by a pipe.", "tokens": [407, 2171, 321, 483, 9518, 12005, 538, 257, 11240, 13], "temperature": 0.0, "avg_logprob": -0.09796684265136718, "compression_ratio": 1.5316455696202531, "no_speech_prob": 9.831104398472235e-05}, {"id": 195, "seek": 91700, "start": 920.0, "end": 925.0, "text": " And here is obviously someone that was still anonymized,", "tokens": [400, 510, 307, 2745, 1580, 300, 390, 920, 37293, 1602, 11], "temperature": 0.0, "avg_logprob": -0.09796684265136718, "compression_ratio": 1.5316455696202531, "no_speech_prob": 9.831104398472235e-05}, {"id": 196, "seek": 91700, "start": 925.0, "end": 930.0, "text": " but that should be in my seat right now.", "tokens": [457, 300, 820, 312, 294, 452, 6121, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.09796684265136718, "compression_ratio": 1.5316455696202531, "no_speech_prob": 9.831104398472235e-05}, {"id": 197, "seek": 91700, "start": 930.0, "end": 935.0, "text": " And we did many talks in the past, including in this room.", "tokens": [400, 321, 630, 867, 6686, 294, 264, 1791, 11, 3009, 294, 341, 1808, 13], "temperature": 0.0, "avg_logprob": -0.09796684265136718, "compression_ratio": 1.5316455696202531, "no_speech_prob": 9.831104398472235e-05}, {"id": 198, "seek": 91700, "start": 935.0, "end": 938.0, "text": " So we will build the graph using NetworkX.", "tokens": [407, 321, 486, 1322, 264, 4295, 1228, 12640, 55, 13], "temperature": 0.0, "avg_logprob": -0.09796684265136718, "compression_ratio": 1.5316455696202531, "no_speech_prob": 9.831104398472235e-05}, {"id": 199, "seek": 91700, "start": 938.0, "end": 941.0, "text": " So for those who know NetworkX, it's quite simple.", "tokens": [407, 337, 729, 567, 458, 12640, 55, 11, 309, 311, 1596, 2199, 13], "temperature": 0.0, "avg_logprob": -0.09796684265136718, "compression_ratio": 1.5316455696202531, "no_speech_prob": 9.831104398472235e-05}, {"id": 200, "seek": 91700, "start": 941.0, "end": 945.0, "text": " You just create a new graph, and then for each row in our CSV,", "tokens": [509, 445, 1884, 257, 777, 4295, 11, 293, 550, 337, 1184, 5386, 294, 527, 48814, 11], "temperature": 0.0, "avg_logprob": -0.09796684265136718, "compression_ratio": 1.5316455696202531, "no_speech_prob": 9.831104398472235e-05}, {"id": 201, "seek": 94500, "start": 945.0, "end": 949.0, "text": " we will, if there's no speaker, we don't take it.", "tokens": [321, 486, 11, 498, 456, 311, 572, 8145, 11, 321, 500, 380, 747, 309, 13], "temperature": 0.0, "avg_logprob": -0.10346149890980821, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0001771105162333697}, {"id": 202, "seek": 94500, "start": 949.0, "end": 951.0, "text": " Then we take the track and the year.", "tokens": [1396, 321, 747, 264, 2837, 293, 264, 1064, 13], "temperature": 0.0, "avg_logprob": -0.10346149890980821, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0001771105162333697}, {"id": 203, "seek": 94500, "start": 951.0, "end": 956.0, "text": " We add a node for each track, and for each speaker inside the talk,", "tokens": [492, 909, 257, 9984, 337, 1184, 2837, 11, 293, 337, 1184, 8145, 1854, 264, 751, 11], "temperature": 0.0, "avg_logprob": -0.10346149890980821, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0001771105162333697}, {"id": 204, "seek": 94500, "start": 956.0, "end": 959.0, "text": " we add a node for the speaker.", "tokens": [321, 909, 257, 9984, 337, 264, 8145, 13], "temperature": 0.0, "avg_logprob": -0.10346149890980821, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0001771105162333697}, {"id": 205, "seek": 94500, "start": 959.0, "end": 964.0, "text": " And then we had an edge in between those two,", "tokens": [400, 550, 321, 632, 364, 4691, 294, 1296, 729, 732, 11], "temperature": 0.0, "avg_logprob": -0.10346149890980821, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0001771105162333697}, {"id": 206, "seek": 94500, "start": 964.0, "end": 970.0, "text": " and we increment it as a count if it's the second time that we meet him, for instance.", "tokens": [293, 321, 26200, 309, 382, 257, 1207, 498, 309, 311, 264, 1150, 565, 300, 321, 1677, 796, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.10346149890980821, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0001771105162333697}, {"id": 207, "seek": 97000, "start": 970.0, "end": 975.0, "text": " And we also upgrade the year to get, for the edge,", "tokens": [400, 321, 611, 11484, 264, 1064, 281, 483, 11, 337, 264, 4691, 11], "temperature": 0.0, "avg_logprob": -0.12068693261397512, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.000134333546156995}, {"id": 208, "seek": 97000, "start": 975.0, "end": 978.0, "text": " the last year that was used.", "tokens": [264, 1036, 1064, 300, 390, 1143, 13], "temperature": 0.0, "avg_logprob": -0.12068693261397512, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.000134333546156995}, {"id": 209, "seek": 97000, "start": 978.0, "end": 985.0, "text": " So by doing that, I built a new graph that has 5,000 nodes and 6,000 links.", "tokens": [407, 538, 884, 300, 11, 286, 3094, 257, 777, 4295, 300, 575, 1025, 11, 1360, 13891, 293, 1386, 11, 1360, 6123, 13], "temperature": 0.0, "avg_logprob": -0.12068693261397512, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.000134333546156995}, {"id": 210, "seek": 97000, "start": 985.0, "end": 991.0, "text": " Let's take a look at my alternate speaker here.", "tokens": [961, 311, 747, 257, 574, 412, 452, 18873, 8145, 510, 13], "temperature": 0.0, "avg_logprob": -0.12068693261397512, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.000134333546156995}, {"id": 211, "seek": 97000, "start": 991.0, "end": 994.0, "text": " It was supposed to be a speaker, and apparently,", "tokens": [467, 390, 3442, 281, 312, 257, 8145, 11, 293, 7970, 11], "temperature": 0.0, "avg_logprob": -0.12068693261397512, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.000134333546156995}, {"id": 212, "seek": 99400, "start": 994.0, "end": 1001.0, "text": " so it's linked to, in year 2018, to two talks in the graph room.", "tokens": [370, 309, 311, 9408, 281, 11, 294, 1064, 6096, 11, 281, 732, 6686, 294, 264, 4295, 1808, 13], "temperature": 0.0, "avg_logprob": -0.22429929753785494, "compression_ratio": 1.4536585365853658, "no_speech_prob": 0.00029160690610297024}, {"id": 213, "seek": 99400, "start": 1001.0, "end": 1005.0, "text": " Yeah, he spoke twice in the room, back then.", "tokens": [865, 11, 415, 7179, 6091, 294, 264, 1808, 11, 646, 550, 13], "temperature": 0.0, "avg_logprob": -0.22429929753785494, "compression_ratio": 1.4536585365853658, "no_speech_prob": 0.00029160690610297024}, {"id": 214, "seek": 99400, "start": 1005.0, "end": 1012.0, "text": " In JavaScript in 2019, and in 2020 in the Open Research Tools and Technology Room.", "tokens": [682, 15778, 294, 6071, 11, 293, 294, 4808, 294, 264, 7238, 10303, 30302, 293, 15037, 19190, 13], "temperature": 0.0, "avg_logprob": -0.22429929753785494, "compression_ratio": 1.4536585365853658, "no_speech_prob": 0.00029160690610297024}, {"id": 215, "seek": 99400, "start": 1012.0, "end": 1015.0, "text": " So let's take a look at this graph now.", "tokens": [407, 718, 311, 747, 257, 574, 412, 341, 4295, 586, 13], "temperature": 0.0, "avg_logprob": -0.22429929753785494, "compression_ratio": 1.4536585365853658, "no_speech_prob": 0.00029160690610297024}, {"id": 216, "seek": 99400, "start": 1015.0, "end": 1016.0, "text": " Oh, it was broken.", "tokens": [876, 11, 309, 390, 5463, 13], "temperature": 0.0, "avg_logprob": -0.22429929753785494, "compression_ratio": 1.4536585365853658, "no_speech_prob": 0.00029160690610297024}, {"id": 217, "seek": 99400, "start": 1016.0, "end": 1019.0, "text": " Yes, there's a comma missing here.", "tokens": [1079, 11, 456, 311, 257, 22117, 5361, 510, 13], "temperature": 0.0, "avg_logprob": -0.22429929753785494, "compression_ratio": 1.4536585365853658, "no_speech_prob": 0.00029160690610297024}, {"id": 218, "seek": 99400, "start": 1019.0, "end": 1020.0, "text": " Here it is.", "tokens": [1692, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.22429929753785494, "compression_ratio": 1.4536585365853658, "no_speech_prob": 0.00029160690610297024}, {"id": 219, "seek": 102000, "start": 1020.0, "end": 1027.0, "text": " Still, I tried to add this earlier, but I'm not expert enough with it, so I'll remove this.", "tokens": [8291, 11, 286, 3031, 281, 909, 341, 3071, 11, 457, 286, 478, 406, 5844, 1547, 365, 309, 11, 370, 286, 603, 4159, 341, 13], "temperature": 0.0, "avg_logprob": -0.1599723556895315, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.00014435991761274636}, {"id": 220, "seek": 102000, "start": 1027.0, "end": 1029.0, "text": " So here it is.", "tokens": [407, 510, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.1599723556895315, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.00014435991761274636}, {"id": 221, "seek": 102000, "start": 1029.0, "end": 1034.0, "text": " So this time, it's a bipartite graph, since we got two kinds of nodes,", "tokens": [407, 341, 565, 11, 309, 311, 257, 28741, 642, 4295, 11, 1670, 321, 658, 732, 3685, 295, 13891, 11], "temperature": 0.0, "avg_logprob": -0.1599723556895315, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.00014435991761274636}, {"id": 222, "seek": 102000, "start": 1034.0, "end": 1036.0, "text": " the tracks and the speakers.", "tokens": [264, 10218, 293, 264, 9518, 13], "temperature": 0.0, "avg_logprob": -0.1599723556895315, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.00014435991761274636}, {"id": 223, "seek": 102000, "start": 1036.0, "end": 1042.0, "text": " So I decided that the node color will be attached to the part type.", "tokens": [407, 286, 3047, 300, 264, 9984, 2017, 486, 312, 8570, 281, 264, 644, 2010, 13], "temperature": 0.0, "avg_logprob": -0.1599723556895315, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.00014435991761274636}, {"id": 224, "seek": 104200, "start": 1042.0, "end": 1051.0, "text": " And if I take a look at it, we should see all big dots in blue are the rooms at first then,", "tokens": [400, 498, 286, 747, 257, 574, 412, 309, 11, 321, 820, 536, 439, 955, 15026, 294, 3344, 366, 264, 9396, 412, 700, 550, 11], "temperature": 0.0, "avg_logprob": -0.11804845721222633, "compression_ratio": 1.6127450980392157, "no_speech_prob": 9.230081195710227e-05}, {"id": 225, "seek": 104200, "start": 1051.0, "end": 1054.0, "text": " and all pink ones are actually speakers.", "tokens": [293, 439, 7022, 2306, 366, 767, 9518, 13], "temperature": 0.0, "avg_logprob": -0.11804845721222633, "compression_ratio": 1.6127450980392157, "no_speech_prob": 9.230081195710227e-05}, {"id": 226, "seek": 104200, "start": 1054.0, "end": 1059.0, "text": " And so we can see that there are a lot of lightning talks, of course, every year,", "tokens": [400, 370, 321, 393, 536, 300, 456, 366, 257, 688, 295, 16589, 6686, 11, 295, 1164, 11, 633, 1064, 11], "temperature": 0.0, "avg_logprob": -0.11804845721222633, "compression_ratio": 1.6127450980392157, "no_speech_prob": 9.230081195710227e-05}, {"id": 227, "seek": 104200, "start": 1059.0, "end": 1065.0, "text": " but there are some rooms that have way more speakers than others,", "tokens": [457, 456, 366, 512, 9396, 300, 362, 636, 544, 9518, 813, 2357, 11], "temperature": 0.0, "avg_logprob": -0.11804845721222633, "compression_ratio": 1.6127450980392157, "no_speech_prob": 9.230081195710227e-05}, {"id": 228, "seek": 104200, "start": 1065.0, "end": 1068.0, "text": " probably also because they exist for way longer.", "tokens": [1391, 611, 570, 436, 2514, 337, 636, 2854, 13], "temperature": 0.0, "avg_logprob": -0.11804845721222633, "compression_ratio": 1.6127450980392157, "no_speech_prob": 9.230081195710227e-05}, {"id": 229, "seek": 106800, "start": 1068.0, "end": 1073.0, "text": " So maybe we can try and explore that, and that's the main idea.", "tokens": [407, 1310, 321, 393, 853, 293, 6839, 300, 11, 293, 300, 311, 264, 2135, 1558, 13], "temperature": 0.0, "avg_logprob": -0.09177550776251431, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0001354879786958918}, {"id": 230, "seek": 106800, "start": 1073.0, "end": 1078.0, "text": " So sorry, I don't remember what this one is.", "tokens": [407, 2597, 11, 286, 500, 380, 1604, 437, 341, 472, 307, 13], "temperature": 0.0, "avg_logprob": -0.09177550776251431, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0001354879786958918}, {"id": 231, "seek": 106800, "start": 1078.0, "end": 1080.0, "text": " Let's just run it briefly.", "tokens": [961, 311, 445, 1190, 309, 10515, 13], "temperature": 0.0, "avg_logprob": -0.09177550776251431, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0001354879786958918}, {"id": 232, "seek": 106800, "start": 1080.0, "end": 1084.0, "text": " I guess it's the same.", "tokens": [286, 2041, 309, 311, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.09177550776251431, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0001354879786958918}, {"id": 233, "seek": 106800, "start": 1084.0, "end": 1085.0, "text": " Yeah, it's the same.", "tokens": [865, 11, 309, 311, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.09177550776251431, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0001354879786958918}, {"id": 234, "seek": 106800, "start": 1085.0, "end": 1087.0, "text": " Sorry, it's a copy-paste.", "tokens": [4919, 11, 309, 311, 257, 5055, 12, 79, 9079, 13], "temperature": 0.0, "avg_logprob": -0.09177550776251431, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0001354879786958918}, {"id": 235, "seek": 106800, "start": 1087.0, "end": 1091.0, "text": " So what we could do is try and apply other things.", "tokens": [407, 437, 321, 727, 360, 307, 853, 293, 3079, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.09177550776251431, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0001354879786958918}, {"id": 236, "seek": 106800, "start": 1091.0, "end": 1093.0, "text": " So let's do a grid again.", "tokens": [407, 718, 311, 360, 257, 10748, 797, 13], "temperature": 0.0, "avg_logprob": -0.09177550776251431, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0001354879786958918}, {"id": 237, "seek": 106800, "start": 1093.0, "end": 1097.0, "text": " But this time, we'll try and display for each node a gradient of color.", "tokens": [583, 341, 565, 11, 321, 603, 853, 293, 4674, 337, 1184, 9984, 257, 16235, 295, 2017, 13], "temperature": 0.0, "avg_logprob": -0.09177550776251431, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0001354879786958918}, {"id": 238, "seek": 109700, "start": 1097.0, "end": 1101.0, "text": " That will indicate the intensity of the node at this moment.", "tokens": [663, 486, 13330, 264, 13749, 295, 264, 9984, 412, 341, 1623, 13], "temperature": 0.0, "avg_logprob": -0.10070662165797034, "compression_ratio": 1.6328502415458936, "no_speech_prob": 0.00023932135081849992}, {"id": 239, "seek": 109700, "start": 1101.0, "end": 1109.0, "text": " So to do that, we will, for instance, take a look at the year 2012 and the year 2022,", "tokens": [407, 281, 360, 300, 11, 321, 486, 11, 337, 5197, 11, 747, 257, 574, 412, 264, 1064, 9125, 293, 264, 1064, 20229, 11], "temperature": 0.0, "avg_logprob": -0.10070662165797034, "compression_ratio": 1.6328502415458936, "no_speech_prob": 0.00023932135081849992}, {"id": 240, "seek": 109700, "start": 1109.0, "end": 1115.0, "text": " and use the strength of the ALO, depending on how many talks were associated", "tokens": [293, 764, 264, 3800, 295, 264, 7056, 46, 11, 5413, 322, 577, 867, 6686, 645, 6615], "temperature": 0.0, "avg_logprob": -0.10070662165797034, "compression_ratio": 1.6328502415458936, "no_speech_prob": 0.00023932135081849992}, {"id": 241, "seek": 109700, "start": 1115.0, "end": 1117.0, "text": " to this node for this specific year.", "tokens": [281, 341, 9984, 337, 341, 2685, 1064, 13], "temperature": 0.0, "avg_logprob": -0.10070662165797034, "compression_ratio": 1.6328502415458936, "no_speech_prob": 0.00023932135081849992}, {"id": 242, "seek": 109700, "start": 1117.0, "end": 1124.0, "text": " So both graphs should show the intensity of the talks during those two years.", "tokens": [407, 1293, 24877, 820, 855, 264, 13749, 295, 264, 6686, 1830, 729, 732, 924, 13], "temperature": 0.0, "avg_logprob": -0.10070662165797034, "compression_ratio": 1.6328502415458936, "no_speech_prob": 0.00023932135081849992}, {"id": 243, "seek": 112400, "start": 1124.0, "end": 1132.0, "text": " So let's show it again.", "tokens": [407, 718, 311, 855, 309, 797, 13], "temperature": 0.0, "avg_logprob": -0.14438500816439404, "compression_ratio": 1.528497409326425, "no_speech_prob": 5.8153324062004685e-05}, {"id": 244, "seek": 112400, "start": 1132.0, "end": 1138.0, "text": " And here we can see that in 2012, the main rooms that were filled were actually more", "tokens": [400, 510, 321, 393, 536, 300, 294, 9125, 11, 264, 2135, 9396, 300, 645, 6412, 645, 767, 544], "temperature": 0.0, "avg_logprob": -0.14438500816439404, "compression_ratio": 1.528497409326425, "no_speech_prob": 5.8153324062004685e-05}, {"id": 245, "seek": 112400, "start": 1138.0, "end": 1141.0, "text": " on desktops, Mozilla, Lightning Talks, and Embedded,", "tokens": [322, 730, 2320, 3370, 11, 3335, 26403, 11, 28848, 8780, 82, 11, 293, 24234, 292, 9207, 11], "temperature": 0.0, "avg_logprob": -0.14438500816439404, "compression_ratio": 1.528497409326425, "no_speech_prob": 5.8153324062004685e-05}, {"id": 246, "seek": 112400, "start": 1141.0, "end": 1149.0, "text": " whereas in 2022, there are way more rooms that are actually filled and spoken.", "tokens": [9735, 294, 20229, 11, 456, 366, 636, 544, 9396, 300, 366, 767, 6412, 293, 10759, 13], "temperature": 0.0, "avg_logprob": -0.14438500816439404, "compression_ratio": 1.528497409326425, "no_speech_prob": 5.8153324062004685e-05}, {"id": 247, "seek": 112400, "start": 1149.0, "end": 1152.0, "text": " Then what we could do is continue working on our graph", "tokens": [1396, 437, 321, 727, 360, 307, 2354, 1364, 322, 527, 4295], "temperature": 0.0, "avg_logprob": -0.14438500816439404, "compression_ratio": 1.528497409326425, "no_speech_prob": 5.8153324062004685e-05}, {"id": 248, "seek": 115200, "start": 1152.0, "end": 1154.0, "text": " and continue exploring while working with it.", "tokens": [293, 2354, 12736, 1339, 1364, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.12863255355317713, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00012965212226845324}, {"id": 249, "seek": 115200, "start": 1154.0, "end": 1157.0, "text": " So at Medialab, we also have a tool called Pelot,", "tokens": [407, 412, 3982, 831, 455, 11, 321, 611, 362, 257, 2290, 1219, 21083, 310, 11], "temperature": 0.0, "avg_logprob": -0.12863255355317713, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00012965212226845324}, {"id": 250, "seek": 115200, "start": 1157.0, "end": 1161.0, "text": " which allows us to do a bunch of metrics and calculation on a,", "tokens": [597, 4045, 505, 281, 360, 257, 3840, 295, 16367, 293, 17108, 322, 257, 11], "temperature": 0.0, "avg_logprob": -0.12863255355317713, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00012965212226845324}, {"id": 251, "seek": 115200, "start": 1161.0, "end": 1163.0, "text": " so it's already installed, it's going faster.", "tokens": [370, 309, 311, 1217, 8899, 11, 309, 311, 516, 4663, 13], "temperature": 0.0, "avg_logprob": -0.12863255355317713, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00012965212226845324}, {"id": 252, "seek": 115200, "start": 1163.0, "end": 1168.0, "text": " And for instance, it can do a monopartite projection out of a bipartite graph.", "tokens": [400, 337, 5197, 11, 309, 393, 360, 257, 1108, 404, 446, 642, 22743, 484, 295, 257, 28741, 642, 4295, 13], "temperature": 0.0, "avg_logprob": -0.12863255355317713, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00012965212226845324}, {"id": 253, "seek": 115200, "start": 1168.0, "end": 1173.0, "text": " So I'm just running this, and then we can try and display it.", "tokens": [407, 286, 478, 445, 2614, 341, 11, 293, 550, 321, 393, 853, 293, 4674, 309, 13], "temperature": 0.0, "avg_logprob": -0.12863255355317713, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00012965212226845324}, {"id": 254, "seek": 115200, "start": 1173.0, "end": 1180.0, "text": " And here, just in a few lines in Python, I can just see the alternate graph", "tokens": [400, 510, 11, 445, 294, 257, 1326, 3876, 294, 15329, 11, 286, 393, 445, 536, 264, 18873, 4295], "temperature": 0.0, "avg_logprob": -0.12863255355317713, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00012965212226845324}, {"id": 255, "seek": 118000, "start": 1180.0, "end": 1183.0, "text": " that is the monopartite version of the graph,", "tokens": [300, 307, 264, 1108, 404, 446, 642, 3037, 295, 264, 4295, 11], "temperature": 0.0, "avg_logprob": -0.09375204733752329, "compression_ratio": 1.702928870292887, "no_speech_prob": 9.494862024439499e-05}, {"id": 256, "seek": 118000, "start": 1183.0, "end": 1191.0, "text": " and just see the links between the rooms depending on when they are co-spoken by speakers.", "tokens": [293, 445, 536, 264, 6123, 1296, 264, 9396, 5413, 322, 562, 436, 366, 598, 12, 4952, 8406, 538, 9518, 13], "temperature": 0.0, "avg_logprob": -0.09375204733752329, "compression_ratio": 1.702928870292887, "no_speech_prob": 9.494862024439499e-05}, {"id": 257, "seek": 118000, "start": 1191.0, "end": 1193.0, "text": " Let's continue.", "tokens": [961, 311, 2354, 13], "temperature": 0.0, "avg_logprob": -0.09375204733752329, "compression_ratio": 1.702928870292887, "no_speech_prob": 9.494862024439499e-05}, {"id": 258, "seek": 118000, "start": 1193.0, "end": 1199.0, "text": " And the problem is that if I look at this graph, I can see there are a bunch of nodes isolated.", "tokens": [400, 264, 1154, 307, 300, 498, 286, 574, 412, 341, 4295, 11, 286, 393, 536, 456, 366, 257, 3840, 295, 13891, 14621, 13], "temperature": 0.0, "avg_logprob": -0.09375204733752329, "compression_ratio": 1.702928870292887, "no_speech_prob": 9.494862024439499e-05}, {"id": 259, "seek": 118000, "start": 1199.0, "end": 1204.0, "text": " And so usually when I want to visualize a graph, those are a bit annoying", "tokens": [400, 370, 2673, 562, 286, 528, 281, 23273, 257, 4295, 11, 729, 366, 257, 857, 11304], "temperature": 0.0, "avg_logprob": -0.09375204733752329, "compression_ratio": 1.702928870292887, "no_speech_prob": 9.494862024439499e-05}, {"id": 260, "seek": 118000, "start": 1204.0, "end": 1208.0, "text": " because they take a lot of space in the visualization, and I don't want to see that.", "tokens": [570, 436, 747, 257, 688, 295, 1901, 294, 264, 25801, 11, 293, 286, 500, 380, 528, 281, 536, 300, 13], "temperature": 0.0, "avg_logprob": -0.09375204733752329, "compression_ratio": 1.702928870292887, "no_speech_prob": 9.494862024439499e-05}, {"id": 261, "seek": 120800, "start": 1208.0, "end": 1213.0, "text": " So let's just use Pelot's Crop to Largest Component function", "tokens": [407, 718, 311, 445, 764, 21083, 310, 311, 383, 1513, 281, 11569, 2629, 6620, 30365, 2445], "temperature": 0.0, "avg_logprob": -0.15276551969123608, "compression_ratio": 1.4417177914110428, "no_speech_prob": 9.812702046474442e-05}, {"id": 262, "seek": 120800, "start": 1213.0, "end": 1219.0, "text": " that will keep only the biggest component of the graph.", "tokens": [300, 486, 1066, 787, 264, 3880, 6542, 295, 264, 4295, 13], "temperature": 0.0, "avg_logprob": -0.15276551969123608, "compression_ratio": 1.4417177914110428, "no_speech_prob": 9.812702046474442e-05}, {"id": 263, "seek": 120800, "start": 1219.0, "end": 1230.0, "text": " So then I can re-displace this graph without all of those single nodes.", "tokens": [407, 550, 286, 393, 319, 12, 13731, 6742, 341, 4295, 1553, 439, 295, 729, 2167, 13891, 13], "temperature": 0.0, "avg_logprob": -0.15276551969123608, "compression_ratio": 1.4417177914110428, "no_speech_prob": 9.812702046474442e-05}, {"id": 264, "seek": 120800, "start": 1230.0, "end": 1234.0, "text": " And that's a rough idea of what could be done.", "tokens": [400, 300, 311, 257, 5903, 1558, 295, 437, 727, 312, 1096, 13], "temperature": 0.0, "avg_logprob": -0.15276551969123608, "compression_ratio": 1.4417177914110428, "no_speech_prob": 9.812702046474442e-05}, {"id": 265, "seek": 123400, "start": 1234.0, "end": 1239.0, "text": " Then we can work with the graph and just visualize on the fly.", "tokens": [1396, 321, 393, 589, 365, 264, 4295, 293, 445, 23273, 322, 264, 3603, 13], "temperature": 0.0, "avg_logprob": -0.10917591041242572, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.00015708124556113034}, {"id": 266, "seek": 123400, "start": 1239.0, "end": 1246.0, "text": " And I guess I'll conclude by just showing inside the GitHub page of the tool.", "tokens": [400, 286, 2041, 286, 603, 16886, 538, 445, 4099, 1854, 264, 23331, 3028, 295, 264, 2290, 13], "temperature": 0.0, "avg_logprob": -0.10917591041242572, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.00015708124556113034}, {"id": 267, "seek": 123400, "start": 1246.0, "end": 1250.0, "text": " There's all the visual variables that are available.", "tokens": [821, 311, 439, 264, 5056, 9102, 300, 366, 2435, 13], "temperature": 0.0, "avg_logprob": -0.10917591041242572, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.00015708124556113034}, {"id": 268, "seek": 123400, "start": 1250.0, "end": 1256.0, "text": " So I showed you already node color, but you can also play on the saturation of the nodes.", "tokens": [407, 286, 4712, 291, 1217, 9984, 2017, 11, 457, 291, 393, 611, 862, 322, 264, 27090, 295, 264, 13891, 13], "temperature": 0.0, "avg_logprob": -0.10917591041242572, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.00015708124556113034}, {"id": 269, "seek": 125600, "start": 1256.0, "end": 1264.0, "text": " You can play on the size we saw, but you can play with the label size, of course, the label color.", "tokens": [509, 393, 862, 322, 264, 2744, 321, 1866, 11, 457, 291, 393, 862, 365, 264, 7645, 2744, 11, 295, 1164, 11, 264, 7645, 2017, 13], "temperature": 0.0, "avg_logprob": -0.09116424498010854, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.00012829809566028416}, {"id": 270, "seek": 125600, "start": 1264.0, "end": 1270.0, "text": " You can adjust the border ratio, how big it is.", "tokens": [509, 393, 4369, 264, 7838, 8509, 11, 577, 955, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.09116424498010854, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.00012829809566028416}, {"id": 271, "seek": 125600, "start": 1270.0, "end": 1283.0, "text": " So basically all visual ways to better help you interpret your graph can be proposed.", "tokens": [407, 1936, 439, 5056, 2098, 281, 1101, 854, 291, 7302, 428, 4295, 393, 312, 10348, 13], "temperature": 0.0, "avg_logprob": -0.09116424498010854, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.00012829809566028416}, {"id": 272, "seek": 128300, "start": 1283.0, "end": 1289.0, "text": " You can also add pictograms, use shapes for each node.", "tokens": [509, 393, 611, 909, 2317, 12820, 82, 11, 764, 10854, 337, 1184, 9984, 13], "temperature": 0.0, "avg_logprob": -0.1520196988985136, "compression_ratio": 1.5308641975308641, "no_speech_prob": 0.00011135242675663903}, {"id": 273, "seek": 128300, "start": 1289.0, "end": 1295.0, "text": " You can use halos like I showed earlier.", "tokens": [509, 393, 764, 7523, 329, 411, 286, 4712, 3071, 13], "temperature": 0.0, "avg_logprob": -0.1520196988985136, "compression_ratio": 1.5308641975308641, "no_speech_prob": 0.00011135242675663903}, {"id": 274, "seek": 128300, "start": 1295.0, "end": 1300.0, "text": " And play also a lot of those applied to edges.", "tokens": [400, 862, 611, 257, 688, 295, 729, 6456, 281, 8819, 13], "temperature": 0.0, "avg_logprob": -0.1520196988985136, "compression_ratio": 1.5308641975308641, "no_speech_prob": 0.00011135242675663903}, {"id": 275, "seek": 128300, "start": 1300.0, "end": 1306.0, "text": " So you can play on the colors, the form of them, and so on and so on.", "tokens": [407, 291, 393, 862, 322, 264, 4577, 11, 264, 1254, 295, 552, 11, 293, 370, 322, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.1520196988985136, "compression_ratio": 1.5308641975308641, "no_speech_prob": 0.00011135242675663903}, {"id": 276, "seek": 128300, "start": 1306.0, "end": 1310.0, "text": " And I guess that will be it for me.", "tokens": [400, 286, 2041, 300, 486, 312, 309, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.1520196988985136, "compression_ratio": 1.5308641975308641, "no_speech_prob": 0.00011135242675663903}, {"id": 277, "seek": 131000, "start": 1310.0, "end": 1313.0, "text": " And I will take all of your questions.", "tokens": [400, 286, 486, 747, 439, 295, 428, 1651, 13], "temperature": 0.0, "avg_logprob": -0.24898759942305715, "compression_ratio": 1.1313131313131313, "no_speech_prob": 0.0007486796821467578}, {"id": 278, "seek": 131000, "start": 1327.0, "end": 1332.0, "text": " Sorry, I'm just scrolling back to things that are nicer.", "tokens": [4919, 11, 286, 478, 445, 29053, 646, 281, 721, 300, 366, 22842, 13], "temperature": 0.0, "avg_logprob": -0.24898759942305715, "compression_ratio": 1.1313131313131313, "no_speech_prob": 0.0007486796821467578}, {"id": 279, "seek": 131000, "start": 1332.0, "end": 1333.0, "text": " All of you.", "tokens": [1057, 295, 291, 13], "temperature": 0.0, "avg_logprob": -0.24898759942305715, "compression_ratio": 1.1313131313131313, "no_speech_prob": 0.0007486796821467578}, {"id": 280, "seek": 131000, "start": 1333.0, "end": 1334.0, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.24898759942305715, "compression_ratio": 1.1313131313131313, "no_speech_prob": 0.0007486796821467578}, {"id": 281, "seek": 133400, "start": 1334.0, "end": 1343.0, "text": " Can you preserve the layout between the different steps so you can execute the layout every time you go to a new cell and preserve it?", "tokens": [1664, 291, 15665, 264, 13333, 1296, 264, 819, 4439, 370, 291, 393, 14483, 264, 13333, 633, 565, 291, 352, 281, 257, 777, 2815, 293, 15665, 309, 30], "temperature": 0.0, "avg_logprob": -0.1106115121107835, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0013422206975519657}, {"id": 282, "seek": 133400, "start": 1343.0, "end": 1344.0, "text": " That's a good question.", "tokens": [663, 311, 257, 665, 1168, 13], "temperature": 0.0, "avg_logprob": -0.1106115121107835, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0013422206975519657}, {"id": 283, "seek": 133400, "start": 1344.0, "end": 1347.0, "text": " I don't think it has been planned yet.", "tokens": [286, 500, 380, 519, 309, 575, 668, 8589, 1939, 13], "temperature": 0.0, "avg_logprob": -0.1106115121107835, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0013422206975519657}, {"id": 284, "seek": 133400, "start": 1347.0, "end": 1349.0, "text": " Can you repeat the question?", "tokens": [1664, 291, 7149, 264, 1168, 30], "temperature": 0.0, "avg_logprob": -0.1106115121107835, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0013422206975519657}, {"id": 285, "seek": 133400, "start": 1349.0, "end": 1350.0, "text": " Yes, sorry.", "tokens": [1079, 11, 2597, 13], "temperature": 0.0, "avg_logprob": -0.1106115121107835, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0013422206975519657}, {"id": 286, "seek": 133400, "start": 1350.0, "end": 1360.0, "text": " So the question was can we maintain the layout from one cell to the other and not having to re-click to apply the layout every time?", "tokens": [407, 264, 1168, 390, 393, 321, 6909, 264, 13333, 490, 472, 2815, 281, 264, 661, 293, 406, 1419, 281, 319, 12, 18548, 281, 3079, 264, 13333, 633, 565, 30], "temperature": 0.0, "avg_logprob": -0.1106115121107835, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0013422206975519657}, {"id": 287, "seek": 133400, "start": 1360.0, "end": 1362.0, "text": " I don't think so.", "tokens": [286, 500, 380, 519, 370, 13], "temperature": 0.0, "avg_logprob": -0.1106115121107835, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0013422206975519657}, {"id": 288, "seek": 136200, "start": 1362.0, "end": 1371.0, "text": " And what I know is that the layout, the way Forza class works, has some chaos.", "tokens": [400, 437, 286, 458, 307, 300, 264, 13333, 11, 264, 636, 1171, 2394, 1508, 1985, 11, 575, 512, 14158, 13], "temperature": 0.0, "avg_logprob": -0.14037382971380175, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.000711531494744122}, {"id": 289, "seek": 136200, "start": 1371.0, "end": 1375.0, "text": " But here it's always instantiated on the same seed.", "tokens": [583, 510, 309, 311, 1009, 9836, 72, 770, 322, 264, 912, 8871, 13], "temperature": 0.0, "avg_logprob": -0.14037382971380175, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.000711531494744122}, {"id": 290, "seek": 136200, "start": 1375.0, "end": 1380.0, "text": " So whenever you run it, it will always generate the same exact layout.", "tokens": [407, 5699, 291, 1190, 309, 11, 309, 486, 1009, 8460, 264, 912, 1900, 13333, 13], "temperature": 0.0, "avg_logprob": -0.14037382971380175, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.000711531494744122}, {"id": 291, "seek": 136200, "start": 1380.0, "end": 1382.0, "text": " So that's something.", "tokens": [407, 300, 311, 746, 13], "temperature": 0.0, "avg_logprob": -0.14037382971380175, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.000711531494744122}, {"id": 292, "seek": 136200, "start": 1382.0, "end": 1385.0, "text": " But it won't reuse the one from the previous cells.", "tokens": [583, 309, 1582, 380, 26225, 264, 472, 490, 264, 3894, 5438, 13], "temperature": 0.0, "avg_logprob": -0.14037382971380175, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.000711531494744122}, {"id": 293, "seek": 136200, "start": 1385.0, "end": 1386.0, "text": " No.", "tokens": [883, 13], "temperature": 0.0, "avg_logprob": -0.14037382971380175, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.000711531494744122}, {"id": 294, "seek": 136200, "start": 1386.0, "end": 1388.0, "text": " That could be something that could be an idea.", "tokens": [663, 727, 312, 746, 300, 727, 312, 364, 1558, 13], "temperature": 0.0, "avg_logprob": -0.14037382971380175, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.000711531494744122}, {"id": 295, "seek": 136200, "start": 1388.0, "end": 1389.0, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.14037382971380175, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.000711531494744122}, {"id": 296, "seek": 138900, "start": 1389.0, "end": 1392.0, "text": " Do you have any numbers on the upper limits of this system?", "tokens": [1144, 291, 362, 604, 3547, 322, 264, 6597, 10406, 295, 341, 1185, 30], "temperature": 0.0, "avg_logprob": -0.1990517634971469, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001019626040942967}, {"id": 297, "seek": 138900, "start": 1392.0, "end": 1395.0, "text": " And the size of the graph that you're going to run here?", "tokens": [400, 264, 2744, 295, 264, 4295, 300, 291, 434, 516, 281, 1190, 510, 30], "temperature": 0.0, "avg_logprob": -0.1990517634971469, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001019626040942967}, {"id": 298, "seek": 138900, "start": 1395.0, "end": 1400.0, "text": " So can you run the values of noting this one or the limits?", "tokens": [407, 393, 291, 1190, 264, 4190, 295, 26801, 341, 472, 420, 264, 10406, 30], "temperature": 0.0, "avg_logprob": -0.1990517634971469, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001019626040942967}, {"id": 299, "seek": 138900, "start": 1400.0, "end": 1408.0, "text": " So the question is about volume and amplitude and how big of a graph we can display with this.", "tokens": [407, 264, 1168, 307, 466, 5523, 293, 27433, 293, 577, 955, 295, 257, 4295, 321, 393, 4674, 365, 341, 13], "temperature": 0.0, "avg_logprob": -0.1990517634971469, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001019626040942967}, {"id": 300, "seek": 138900, "start": 1408.0, "end": 1412.0, "text": " So I believe the limit is actually the one of your browser.", "tokens": [407, 286, 1697, 264, 4948, 307, 767, 264, 472, 295, 428, 11185, 13], "temperature": 0.0, "avg_logprob": -0.1990517634971469, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001019626040942967}, {"id": 301, "seek": 138900, "start": 1412.0, "end": 1418.0, "text": " So it will depend on your GPU and your CPU and your RAM.", "tokens": [407, 309, 486, 5672, 322, 428, 18407, 293, 428, 13199, 293, 428, 14561, 13], "temperature": 0.0, "avg_logprob": -0.1990517634971469, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001019626040942967}, {"id": 302, "seek": 141800, "start": 1418.0, "end": 1431.0, "text": " But I know that SigmaJS properly endows graphs with, I would say, 100,000 of nodes and links.", "tokens": [583, 286, 458, 300, 36595, 41, 50, 6108, 917, 1509, 24877, 365, 11, 286, 576, 584, 11, 2319, 11, 1360, 295, 13891, 293, 6123, 13], "temperature": 0.0, "avg_logprob": -0.15568551563081287, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.00021276948973536491}, {"id": 303, "seek": 141800, "start": 1431.0, "end": 1438.0, "text": " I guess I know I already displayed one with a few million links and 100,000 of nodes.", "tokens": [286, 2041, 286, 458, 286, 1217, 16372, 472, 365, 257, 1326, 2459, 6123, 293, 2319, 11, 1360, 295, 13891, 13], "temperature": 0.0, "avg_logprob": -0.15568551563081287, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.00021276948973536491}, {"id": 304, "seek": 141800, "start": 1438.0, "end": 1443.0, "text": " It takes a bit more time, of course.", "tokens": [467, 2516, 257, 857, 544, 565, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.15568551563081287, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.00021276948973536491}, {"id": 305, "seek": 144300, "start": 1443.0, "end": 1448.0, "text": " Do you support something like collapsing nodes and expanding them?", "tokens": [1144, 291, 1406, 746, 411, 45339, 13891, 293, 14702, 552, 30], "temperature": 0.0, "avg_logprob": -0.2978202974474108, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00024373960332013667}, {"id": 306, "seek": 144300, "start": 1448.0, "end": 1453.0, "text": " For instance, in these kind of power graphs where the communities could collapse if you want to put height once,", "tokens": [1171, 5197, 11, 294, 613, 733, 295, 1347, 24877, 689, 264, 4456, 727, 15584, 498, 291, 528, 281, 829, 6681, 1564, 11], "temperature": 0.0, "avg_logprob": -0.2978202974474108, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00024373960332013667}, {"id": 307, "seek": 144300, "start": 1453.0, "end": 1457.0, "text": " and they could be selectively expanded as well.", "tokens": [293, 436, 727, 312, 3048, 3413, 14342, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.2978202974474108, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00024373960332013667}, {"id": 308, "seek": 144300, "start": 1457.0, "end": 1467.0, "text": " So the question is, can we aggregate and split nodes that have, for instance, the same group?", "tokens": [407, 264, 1168, 307, 11, 393, 321, 26118, 293, 7472, 13891, 300, 362, 11, 337, 5197, 11, 264, 912, 1594, 30], "temperature": 0.0, "avg_logprob": -0.2978202974474108, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00024373960332013667}, {"id": 309, "seek": 146700, "start": 1467.0, "end": 1473.0, "text": " For me, it would be, I don't think it's built-in within Sigma for sure.", "tokens": [1171, 385, 11, 309, 576, 312, 11, 286, 500, 380, 519, 309, 311, 3094, 12, 259, 1951, 36595, 337, 988, 13], "temperature": 0.0, "avg_logprob": -0.28958181687343265, "compression_ratio": 1.3867403314917126, "no_speech_prob": 0.0004051262803841382}, {"id": 310, "seek": 146700, "start": 1473.0, "end": 1478.0, "text": " Maybe in Pelot, the library I was showing, like the monopartite projection is pretty much this kind of ID.", "tokens": [2704, 294, 21083, 310, 11, 264, 6405, 286, 390, 4099, 11, 411, 264, 1108, 404, 446, 642, 22743, 307, 1238, 709, 341, 733, 295, 7348, 13], "temperature": 0.0, "avg_logprob": -0.28958181687343265, "compression_ratio": 1.3867403314917126, "no_speech_prob": 0.0004051262803841382}, {"id": 311, "seek": 146700, "start": 1478.0, "end": 1484.0, "text": " And I don't know, but it might be in Pelot.", "tokens": [400, 286, 500, 380, 458, 11, 457, 309, 1062, 312, 294, 21083, 310, 13], "temperature": 0.0, "avg_logprob": -0.28958181687343265, "compression_ratio": 1.3867403314917126, "no_speech_prob": 0.0004051262803841382}, {"id": 312, "seek": 146700, "start": 1484.0, "end": 1488.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.28958181687343265, "compression_ratio": 1.3867403314917126, "no_speech_prob": 0.0004051262803841382}, {"id": 313, "seek": 146700, "start": 1488.0, "end": 1492.0, "text": " You might try the GPU.", "tokens": [509, 1062, 853, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.28958181687343265, "compression_ratio": 1.3867403314917126, "no_speech_prob": 0.0004051262803841382}, {"id": 314, "seek": 149200, "start": 1492.0, "end": 1497.0, "text": " Yeah, SigmaJS, sorry.", "tokens": [865, 11, 36595, 41, 50, 11, 2597, 13], "temperature": 0.0, "avg_logprob": -0.11503847440083821, "compression_ratio": 1.407216494845361, "no_speech_prob": 0.00024174430291168392}, {"id": 315, "seek": 149200, "start": 1497.0, "end": 1501.0, "text": " So the question is, does this use the GPU to display the graph?", "tokens": [407, 264, 1168, 307, 11, 775, 341, 764, 264, 18407, 281, 4674, 264, 4295, 30], "temperature": 0.0, "avg_logprob": -0.11503847440083821, "compression_ratio": 1.407216494845361, "no_speech_prob": 0.00024174430291168392}, {"id": 316, "seek": 149200, "start": 1501.0, "end": 1503.0, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.11503847440083821, "compression_ratio": 1.407216494845361, "no_speech_prob": 0.00024174430291168392}, {"id": 317, "seek": 149200, "start": 1503.0, "end": 1507.0, "text": " SigmaJS is heavily relying on WebGL.", "tokens": [36595, 41, 50, 307, 10950, 24140, 322, 9573, 19440, 13], "temperature": 0.0, "avg_logprob": -0.11503847440083821, "compression_ratio": 1.407216494845361, "no_speech_prob": 0.00024174430291168392}, {"id": 318, "seek": 149200, "start": 1507.0, "end": 1513.0, "text": " The previous version of SigmaJS was proposing to choose between Canvas and WebGL.", "tokens": [440, 3894, 3037, 295, 36595, 41, 50, 390, 29939, 281, 2826, 1296, 25725, 293, 9573, 19440, 13], "temperature": 0.0, "avg_logprob": -0.11503847440083821, "compression_ratio": 1.407216494845361, "no_speech_prob": 0.00024174430291168392}, {"id": 319, "seek": 149200, "start": 1513.0, "end": 1518.0, "text": " Right now, it's only WebGL, so it won't work with all browsers.", "tokens": [1779, 586, 11, 309, 311, 787, 9573, 19440, 11, 370, 309, 1582, 380, 589, 365, 439, 36069, 13], "temperature": 0.0, "avg_logprob": -0.11503847440083821, "compression_ratio": 1.407216494845361, "no_speech_prob": 0.00024174430291168392}, {"id": 320, "seek": 151800, "start": 1518.0, "end": 1524.0, "text": " But nowadays, most browsers know to work with the GPU.", "tokens": [583, 13434, 11, 881, 36069, 458, 281, 589, 365, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.2541497259429007, "compression_ratio": 1.0941176470588236, "no_speech_prob": 0.00045075631351210177}, {"id": 321, "seek": 151800, "start": 1524.0, "end": 1528.0, "text": " So, yes.", "tokens": [407, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.2541497259429007, "compression_ratio": 1.0941176470588236, "no_speech_prob": 0.00045075631351210177}, {"id": 322, "seek": 151800, "start": 1528.0, "end": 1530.0, "text": " Thank you so much.", "tokens": [1044, 291, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.2541497259429007, "compression_ratio": 1.0941176470588236, "no_speech_prob": 0.00045075631351210177}, {"id": 323, "seek": 153000, "start": 1530.0, "end": 1549.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 51314], "temperature": 0.0, "avg_logprob": -0.43282965819040936, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.0009286878048442304}], "language": "en"}