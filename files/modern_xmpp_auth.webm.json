{"text": " Okay, so yeah, my name is Matthew Wilde and I'm going to talk about, it's a, hopefully not too technical talk, but the topics are technical, but I'm trying to keep it general. So who am I? I founded the Prosody XMPP server. XMPP is an open chat protocol, so the idea is you can choose the software that you use to chat with, you can choose your service provider, or the providers federate using a server-to-server protocol, so this is like some other open federated networks. There's email, which we're all familiar with, where you can choose your provider, choose your software, there's the phone network, which kind of works, and many of you here have probably heard of Matrix, and that's another very similar like goals to XMPP, where we have an open protocol, and we're doing federation, and we're bridging to proprietary networks. So Prosody is an XMPP server that you can self-host, it's all open source. Snicket is a newer thing, which is kind of an all-in-one XMPP setup, it's kind of more like a self-hosted WhatsApp, I actually created it for my family, because they were still using WhatsApp, even though I'd been working on XMPP for a long time. And so yeah, so Snicket has apps and stuff, that's all just working out of the box with voice and video calls and things. As part of this, I worked on a modern XMPP, which is a set of guidelines, UI guidelines, because the XMPP Standards Foundation, of which I'm one of the directors, we publish protocols, and we say, this is how you send a file, this is how you send a chat message or make a call, but we don't say this is how you should structure the UI. So I wanted to bring some consistency and some good guidelines and help developers with that. So yeah, I'm also part of the XMPP Standards Foundation, I'm the executive director, I work on the board, but I've also been on the technical council, and so yeah, I'm involved in a lot of XMPP things. So this talk is focusing on something that I had a grant for from NGI Assure via NLNet, and it was to work on modernizing XMPP authentication and authorization. So, authentication, you start out connecting to the server, and you then have to prove your identity to the server. You can't just say, hey, I'm Matthew, because every TCP connection has to be authenticated somehow. So how do we do that? Traditionally, you make the connection, and you send a username and your password, and the server tells you if it's correct, and then you can proceed to do authenticated stuff. This is actually how the web works, pretty much. So you have this HTML form, you put in your username, you put in your password, your password gets sent to the web server, and the server verifies it, and usually on the server side, the password is hashed, which means, I mean, if it's a good place, then it's hashed on the server side, so then they hash the incoming password, and they compare it with the hash that they have stored. So XMPP uses a standard authentication protocol called SASL. It's actually used by a bunch of different protocols, and there's currently work to try and implement it in HTTP as well. And so SASL defines a bunch of mechanisms, and the mechanism says what you send. And so the simplest one probably is plain, and this is exactly what we just saw with the, you know, the Hi, I'm Matthew, my password is, and the web is very similar. You're just sending a username and your password. And so sending passwords across the wire is absolutely fine because of all these reasons, and nobody ever reuses passwords, and they are, you know, frequently rotated and updated, and they never contain personal information, so if they're leaked, then, you know, no bad consequences. And, yeah, they're never also reused across services, which means this is just great because if passwords ever do get leaked, and those hashes maybe, you know, brute forced, then, you know, no one gets access to any other service than the compromised one, which was already compromised anyway. Okay. Yeah, that was just a joke. So in XMPP, we don't really use plain. We use another SASL mechanism that someone defined called Scram. It's not just, hey, my password is, it's a challenge response thing, so there's a bit of magic going on with hashing, and it has some really nice features. It does involve multiple round trips, so, yeah, you're going backwards and forwards, but these by you that the client and the server can only store hashes, so previously, we couldn't have the client store a hash because it has to send the raw password for the server to hash. If you only send a hash, then the hash becomes your password, which is kind of weird. So Scram has multiple iterations of hashing. It allows the client to store a hash. It allows the server to still store a hash, and only hashes exchanged over the wire. It's pretty magic, and the mutual authentication part means that at the end of the authentication exchange, both the server has authenticated the client and proven, yes, this person originally had the password, and they are who they say they are, but importantly, it allows the client to verify that the server also knows the original password, which in the past, with the plain mechanisms and like the web, the server can just lie and say, yeah, I have your password, carry on, send me more sensitive information, and so we have this mutual authentication, so when you connect over XMPP and you use Scram, you have this verification that also the server you're connecting to is the right one, and yes, we do have this with TLS, obviously, but there are certain cases where TLS isn't always reliable, and that's where channel binding comes in, which is a bit more magic, and this binds your authentication, that mutual authentication stuff to your TLS channel, and so if you reach the end and the mutual authentication checks out, but you find a little mismatch, this TLS magic can tell you that actually there is someone listening in on your TLS connection, and that can be because, for example, your certificate authority was compromised or whatever, so someone installed a different trust route on your system without you knowing, and so we can actually detect this, and it's pretty smart, all this security comes at a cost, obviously we just talked about why it's necessary, but it's also still password based, so what can we do? So there's been a lot of interesting development on the web ecosystem in recent years, they're trying to, they've tried fixing stuff, and it's basically hard, users are always going to be users, they're always going to choose memorable passwords, and there has been some progress, there are password managers and so on, but although they're best practice, they're not widely used, I mean amongst normal people, probably everyone here, I hope has a password manager, so WebOrthN 502, it's basically a combination of things, they allow the browser to do some special stuff and help with the authentication, you can do that with an external hardware token, but these days also browsers are supporting TPM chips inside the hardware, which allows you to link that authentication securely to a single device, and pass keys are like Apple's thing that they're really pushing, which is based on all this, and allows you to basically create an account without a password, and authenticate using this special key that is only on your device, except it's also synchronized via iCloud, and so you can access your account from all your devices without ever needing a password, which is as long as you can access your iCloud account, now that's just one implementation, there are other things, WebOrthN 502, and it's all based on open standards, but XMPP uses Sassel, which is focused on passwords, so what can we do, I've been working on this new mechanism in XMPP, which is token based, and it builds on some earlier work, which introduces a new Sassel mechanism, or a family of mechanisms, which allow you to exchange a hash of the token over the wire, so we're not sending the raw token, so it's a bit scram-like in that sense, it still provides mutual authentication, and it still supports channel binding, so you still have all those nice features of scram, it is a single round trip, so there's no back and forth like with scram, the things that we are weakening in that sense don't matter because the tokens are not passwords, and so although there is a slightly reduced level of security around the token compared to scram, the tokens are temporary, so if they get leaked, then you can easily revoke them, rotate them, and they are unique to that service, and I would hope that if a service is compromised, you know, they're obviously going to revoke all their tokens straight away, it's harder to get users to reset all their passwords straight away, so there's many benefits to using tokens, and we still get all the nice features of scram, but users aren't going to generate tokens and enter them themselves, so this opens the door to two-factor authentication in XMPP as well, previously we've had this problem where you can kind of do two-factor authentication, but every time you drive through a tunnel, then your XMPP app is re-authenticating on the other side because it's reconnecting to the server and has to re-prove who it is, if it uses the password, then the server is going to say, well, you know, you have the password, but the whole point of two-factor authentication is to make the password not enough because of all the weaknesses that passwords entail, so if you authenticate with a token instead, then the server knows it issued this token once, it issued it to that device, and it knows who you are, and there's a higher security guarantee around that. So by using the new Sassel mechanism, servers won't, they'll see that you're authenticating with a secure token, and they won't send the two-factor authentication prompts that they usually send. This is basically how two-factor auth on the web already works. You provide that web form or whatever, maybe you're using pass keys, but once you do that initial authentication step, the web service is going to send back a cookie that gets stored in your browser in plain text, and with every request, yes, it's going over HTTPS, but it's still sending that, you know, plain text string, and it doesn't have all the protections of the channel binding and the mutual authentication that the FAST and Sassel mechanisms are supporting. So in this sense, using FAST over, for example, the new HTTP Sassel stuff would be an interesting security improvement for many secure web applications. And so the other thing is it opens the door to having passwordless accounts. So instead of exchanging your password for a token, you could exchange your password plus a two-factor auth for a token, or you could do something entirely different, something came up just at the real-time stand downstairs, someone wants to do SMS authentication, so they verify SMS, kind of like how WhatsApp or Signal work, and then you will just be given a FAST token, and then you can reconnect to the server using that. And that will last for as long as you keep your device active. If you have an inactive device, then that token will stop being refreshed, it will eventually expire, and you will have to reauthenticate using SMS or maybe some recovery mechanism. And once you've breached up this passwordless account, then obviously you can add other recovery mechanisms as a backup if you need to. And yeah, that was kind of the summary of my talk. I hope there's still time for many questions if you are interested. So this talk is kind of a complement to a blog post that I wrote on the Presley blog about all this stuff, but the blog post focus mostly on the performance optimizations because that matters to people, they want to be reconnected to the server as quickly as possible because responsiveness and all this. And so the blog post focus on the optimization aspects of this, today the talk focuses on the security aspects. And yeah, there's some more XMPP talks coming up later on, I am downstairs also in the real time lounge, which is just down around the corner, and you can reach me on XMPP or email and yeah, happy to answer any questions. Can you tell us where they overlap, where they differ, can fast be used in scenarios where JSON web tokens already exist as something better, or is it more divergent as a difference? It's pretty different. Yeah, sorry, so the question is ultimately, are JWT, JSON web tokens similar overlapping with fast tokens? Fast tokens are essentially opaque random strings of a good length for security reasons. JSON web tokens, they are also embedding stuff inside that token. A server could do similar, and when it issues the token, use a JWT instead. There's not really much benefit to that. JSON web tokens, they are still useful for some cases, definitely, but they have a bad reputation with regards to security. Yeah, it's complicated, but there's not really much overlap. They can be kind of used in the same situation, but not entirely. If you were doing a distributed network where you didn't really necessarily want to have a backend communication, could you authenticate a fast token against one service, and then that contains information that could authenticate with a trusted system that's not sharing a backend? Yeah, absolutely. Any way that the server can verify the token is valid? Sorry, the question is, if you were working on a decentralized system where the authentication system is separate to the place where the user is logging in, then can you use JWT in that situation? The answer is yes, you could use it. Two questions, are you attempting to standardize fast within the standards body, and second, do you set the tokens that are disused, decayed by what mechanism? The first question was, are we attempting to standardize fast? Yes, so the sassel mechanism that it is based on is already a draft at the IETF, it's been going a while. We had a meeting with the sassel working group at the IETF just last month, and they agreed that this is stuff that is interesting and they want to move forward with, because it is also useful for other protocols, the email ecosystem and many others. So yes, we are the XMPP layer of this, the whole fast stuff. That is being standardized at the XMPP Standards Foundation, so that layer, if another protocol wanted to use it, they would have to define their own, because the fast stuff specifically is XMPP specific. They can copy how we have done it, but it has to be translated to a different protocol. The second question was, how do disused tokens decay? That is basically up to the server, there is an algorithm in the fast specification, which is linked from the blog post, which tells you how to implement the server in a way that is going to securely rotate tokens, without having to check every possible token on the server, because we don't necessarily know the user's identity until we verified the token. So it can be a bit complex, but essentially it's just the server knows the expiry time of a token when the token was last seen, and some interesting stuff came up with how to refresh tokens, because if the client authenticates and then you provide it with a new token and immediately expire the old one, so that's one way of doing the rotation, there are cases where the client actually reconnected, used the old token, and then did not receive the new token, got disconnected, and then it gets logged out, basically, because it can no longer access. So the server has to store the last token that the client used, and also the new replacement token, it's expecting it to use next. And if the client never uses that token, then it will eventually issue a new one and work out. And that's the moment you see it authenticate with the new token. That's when you expire the old one completely, and obviously there is a time limit to that, because otherwise someone can carry on using the old one indefinitely, and we don't want that either. So there's kind of two timeouts built in, okay, excellent. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 15.68, "text": " Okay, so yeah, my name is Matthew Wilde and I'm going to talk about, it's a, hopefully", "tokens": [1033, 11, 370, 1338, 11, 452, 1315, 307, 12434, 10904, 68, 293, 286, 478, 516, 281, 751, 466, 11, 309, 311, 257, 11, 4696], "temperature": 0.0, "avg_logprob": -0.3119694328308105, "compression_ratio": 1.3461538461538463, "no_speech_prob": 0.2904978394508362}, {"id": 1, "seek": 0, "start": 15.68, "end": 22.8, "text": " not too technical talk, but the topics are technical, but I'm trying to keep it general.", "tokens": [406, 886, 6191, 751, 11, 457, 264, 8378, 366, 6191, 11, 457, 286, 478, 1382, 281, 1066, 309, 2674, 13], "temperature": 0.0, "avg_logprob": -0.3119694328308105, "compression_ratio": 1.3461538461538463, "no_speech_prob": 0.2904978394508362}, {"id": 2, "seek": 2280, "start": 22.8, "end": 31.68, "text": " So who am I? I founded the Prosody XMPP server. XMPP is an open chat protocol, so the idea", "tokens": [407, 567, 669, 286, 30, 286, 13234, 264, 26024, 843, 1783, 12224, 47, 7154, 13, 1783, 12224, 47, 307, 364, 1269, 5081, 10336, 11, 370, 264, 1558], "temperature": 0.0, "avg_logprob": -0.17469891999897205, "compression_ratio": 1.6714285714285715, "no_speech_prob": 2.954789306386374e-05}, {"id": 3, "seek": 2280, "start": 31.68, "end": 37.66, "text": " is you can choose the software that you use to chat with, you can choose your service", "tokens": [307, 291, 393, 2826, 264, 4722, 300, 291, 764, 281, 5081, 365, 11, 291, 393, 2826, 428, 2643], "temperature": 0.0, "avg_logprob": -0.17469891999897205, "compression_ratio": 1.6714285714285715, "no_speech_prob": 2.954789306386374e-05}, {"id": 4, "seek": 2280, "start": 37.66, "end": 42.760000000000005, "text": " provider, or the providers federate using a server-to-server protocol, so this is like", "tokens": [12398, 11, 420, 264, 11330, 38024, 473, 1228, 257, 7154, 12, 1353, 12, 12484, 331, 10336, 11, 370, 341, 307, 411], "temperature": 0.0, "avg_logprob": -0.17469891999897205, "compression_ratio": 1.6714285714285715, "no_speech_prob": 2.954789306386374e-05}, {"id": 5, "seek": 2280, "start": 42.760000000000005, "end": 47.84, "text": " some other open federated networks. There's email, which we're all familiar with, where", "tokens": [512, 661, 1269, 38024, 770, 9590, 13, 821, 311, 3796, 11, 597, 321, 434, 439, 4963, 365, 11, 689], "temperature": 0.0, "avg_logprob": -0.17469891999897205, "compression_ratio": 1.6714285714285715, "no_speech_prob": 2.954789306386374e-05}, {"id": 6, "seek": 4784, "start": 47.84, "end": 53.120000000000005, "text": " you can choose your provider, choose your software, there's the phone network, which", "tokens": [291, 393, 2826, 428, 12398, 11, 2826, 428, 4722, 11, 456, 311, 264, 2593, 3209, 11, 597], "temperature": 0.0, "avg_logprob": -0.13236015800416, "compression_ratio": 1.739622641509434, "no_speech_prob": 2.413575566606596e-05}, {"id": 7, "seek": 4784, "start": 53.120000000000005, "end": 59.6, "text": " kind of works, and many of you here have probably heard of Matrix, and that's another very similar", "tokens": [733, 295, 1985, 11, 293, 867, 295, 291, 510, 362, 1391, 2198, 295, 36274, 11, 293, 300, 311, 1071, 588, 2531], "temperature": 0.0, "avg_logprob": -0.13236015800416, "compression_ratio": 1.739622641509434, "no_speech_prob": 2.413575566606596e-05}, {"id": 8, "seek": 4784, "start": 59.6, "end": 64.36, "text": " like goals to XMPP, where we have an open protocol, and we're doing federation, and we're bridging", "tokens": [411, 5493, 281, 1783, 12224, 47, 11, 689, 321, 362, 364, 1269, 10336, 11, 293, 321, 434, 884, 4636, 5053, 11, 293, 321, 434, 16362, 3249], "temperature": 0.0, "avg_logprob": -0.13236015800416, "compression_ratio": 1.739622641509434, "no_speech_prob": 2.413575566606596e-05}, {"id": 9, "seek": 4784, "start": 64.36, "end": 69.48, "text": " to proprietary networks. So Prosody is an XMPP server that you can self-host, it's all open", "tokens": [281, 38992, 9590, 13, 407, 26024, 843, 307, 364, 1783, 12224, 47, 7154, 300, 291, 393, 2698, 12, 6037, 11, 309, 311, 439, 1269], "temperature": 0.0, "avg_logprob": -0.13236015800416, "compression_ratio": 1.739622641509434, "no_speech_prob": 2.413575566606596e-05}, {"id": 10, "seek": 4784, "start": 69.48, "end": 76.16, "text": " source. Snicket is a newer thing, which is kind of an all-in-one XMPP setup, it's kind", "tokens": [4009, 13, 9264, 20551, 307, 257, 17628, 551, 11, 597, 307, 733, 295, 364, 439, 12, 259, 12, 546, 1783, 12224, 47, 8657, 11, 309, 311, 733], "temperature": 0.0, "avg_logprob": -0.13236015800416, "compression_ratio": 1.739622641509434, "no_speech_prob": 2.413575566606596e-05}, {"id": 11, "seek": 7616, "start": 76.16, "end": 81.47999999999999, "text": " of more like a self-hosted WhatsApp, I actually created it for my family, because they were", "tokens": [295, 544, 411, 257, 2698, 12, 6037, 292, 30513, 11, 286, 767, 2942, 309, 337, 452, 1605, 11, 570, 436, 645], "temperature": 0.0, "avg_logprob": -0.1587250653435202, "compression_ratio": 1.6185185185185185, "no_speech_prob": 6.472862878581509e-05}, {"id": 12, "seek": 7616, "start": 81.47999999999999, "end": 87.92, "text": " still using WhatsApp, even though I'd been working on XMPP for a long time. And so yeah,", "tokens": [920, 1228, 30513, 11, 754, 1673, 286, 1116, 668, 1364, 322, 1783, 12224, 47, 337, 257, 938, 565, 13, 400, 370, 1338, 11], "temperature": 0.0, "avg_logprob": -0.1587250653435202, "compression_ratio": 1.6185185185185185, "no_speech_prob": 6.472862878581509e-05}, {"id": 13, "seek": 7616, "start": 87.92, "end": 92.56, "text": " so Snicket has apps and stuff, that's all just working out of the box with voice and", "tokens": [370, 9264, 20551, 575, 7733, 293, 1507, 11, 300, 311, 439, 445, 1364, 484, 295, 264, 2424, 365, 3177, 293], "temperature": 0.0, "avg_logprob": -0.1587250653435202, "compression_ratio": 1.6185185185185185, "no_speech_prob": 6.472862878581509e-05}, {"id": 14, "seek": 7616, "start": 92.56, "end": 98.28, "text": " video calls and things. As part of this, I worked on a modern XMPP, which is a set of", "tokens": [960, 5498, 293, 721, 13, 1018, 644, 295, 341, 11, 286, 2732, 322, 257, 4363, 1783, 12224, 47, 11, 597, 307, 257, 992, 295], "temperature": 0.0, "avg_logprob": -0.1587250653435202, "compression_ratio": 1.6185185185185185, "no_speech_prob": 6.472862878581509e-05}, {"id": 15, "seek": 7616, "start": 98.28, "end": 104.32, "text": " guidelines, UI guidelines, because the XMPP Standards Foundation, of which I'm one of", "tokens": [12470, 11, 15682, 12470, 11, 570, 264, 1783, 12224, 47, 44546, 10335, 11, 295, 597, 286, 478, 472, 295], "temperature": 0.0, "avg_logprob": -0.1587250653435202, "compression_ratio": 1.6185185185185185, "no_speech_prob": 6.472862878581509e-05}, {"id": 16, "seek": 10432, "start": 104.32, "end": 109.36, "text": " the directors, we publish protocols, and we say, this is how you send a file, this is", "tokens": [264, 17307, 11, 321, 11374, 20618, 11, 293, 321, 584, 11, 341, 307, 577, 291, 2845, 257, 3991, 11, 341, 307], "temperature": 0.0, "avg_logprob": -0.13528758921521775, "compression_ratio": 1.7450980392156863, "no_speech_prob": 8.635369886178523e-05}, {"id": 17, "seek": 10432, "start": 109.36, "end": 114.55999999999999, "text": " how you send a chat message or make a call, but we don't say this is how you should structure", "tokens": [577, 291, 2845, 257, 5081, 3636, 420, 652, 257, 818, 11, 457, 321, 500, 380, 584, 341, 307, 577, 291, 820, 3877], "temperature": 0.0, "avg_logprob": -0.13528758921521775, "compression_ratio": 1.7450980392156863, "no_speech_prob": 8.635369886178523e-05}, {"id": 18, "seek": 10432, "start": 114.55999999999999, "end": 119.24, "text": " the UI. So I wanted to bring some consistency and some good guidelines and help developers", "tokens": [264, 15682, 13, 407, 286, 1415, 281, 1565, 512, 14416, 293, 512, 665, 12470, 293, 854, 8849], "temperature": 0.0, "avg_logprob": -0.13528758921521775, "compression_ratio": 1.7450980392156863, "no_speech_prob": 8.635369886178523e-05}, {"id": 19, "seek": 10432, "start": 119.24, "end": 122.83999999999999, "text": " with that. So yeah, I'm also part of the XMPP Standards Foundation, I'm the executive", "tokens": [365, 300, 13, 407, 1338, 11, 286, 478, 611, 644, 295, 264, 1783, 12224, 47, 44546, 10335, 11, 286, 478, 264, 10140], "temperature": 0.0, "avg_logprob": -0.13528758921521775, "compression_ratio": 1.7450980392156863, "no_speech_prob": 8.635369886178523e-05}, {"id": 20, "seek": 10432, "start": 122.83999999999999, "end": 128.07999999999998, "text": " director, I work on the board, but I've also been on the technical council, and so yeah,", "tokens": [5391, 11, 286, 589, 322, 264, 3150, 11, 457, 286, 600, 611, 668, 322, 264, 6191, 9209, 11, 293, 370, 1338, 11], "temperature": 0.0, "avg_logprob": -0.13528758921521775, "compression_ratio": 1.7450980392156863, "no_speech_prob": 8.635369886178523e-05}, {"id": 21, "seek": 10432, "start": 128.07999999999998, "end": 132.79999999999998, "text": " I'm involved in a lot of XMPP things. So this talk is focusing on something that I had a", "tokens": [286, 478, 3288, 294, 257, 688, 295, 1783, 12224, 47, 721, 13, 407, 341, 751, 307, 8416, 322, 746, 300, 286, 632, 257], "temperature": 0.0, "avg_logprob": -0.13528758921521775, "compression_ratio": 1.7450980392156863, "no_speech_prob": 8.635369886178523e-05}, {"id": 22, "seek": 13280, "start": 132.8, "end": 142.16000000000003, "text": " grant for from NGI Assure via NLNet, and it was to work on modernizing XMPP authentication", "tokens": [6386, 337, 490, 426, 26252, 6281, 540, 5766, 426, 43, 31890, 11, 293, 309, 390, 281, 589, 322, 4363, 3319, 1783, 12224, 47, 26643], "temperature": 0.0, "avg_logprob": -0.17481213427604514, "compression_ratio": 1.567099567099567, "no_speech_prob": 4.312318560550921e-05}, {"id": 23, "seek": 13280, "start": 142.16000000000003, "end": 150.64000000000001, "text": " and authorization. So, authentication, you start out connecting to the server, and you", "tokens": [293, 33697, 13, 407, 11, 26643, 11, 291, 722, 484, 11015, 281, 264, 7154, 11, 293, 291], "temperature": 0.0, "avg_logprob": -0.17481213427604514, "compression_ratio": 1.567099567099567, "no_speech_prob": 4.312318560550921e-05}, {"id": 24, "seek": 13280, "start": 150.64000000000001, "end": 155.52, "text": " then have to prove your identity to the server. You can't just say, hey, I'm Matthew, because", "tokens": [550, 362, 281, 7081, 428, 6575, 281, 264, 7154, 13, 509, 393, 380, 445, 584, 11, 4177, 11, 286, 478, 12434, 11, 570], "temperature": 0.0, "avg_logprob": -0.17481213427604514, "compression_ratio": 1.567099567099567, "no_speech_prob": 4.312318560550921e-05}, {"id": 25, "seek": 13280, "start": 155.52, "end": 162.28, "text": " every TCP connection has to be authenticated somehow. So how do we do that? Traditionally,", "tokens": [633, 48965, 4984, 575, 281, 312, 9214, 3587, 6063, 13, 407, 577, 360, 321, 360, 300, 30, 22017, 15899, 11], "temperature": 0.0, "avg_logprob": -0.17481213427604514, "compression_ratio": 1.567099567099567, "no_speech_prob": 4.312318560550921e-05}, {"id": 26, "seek": 16228, "start": 162.28, "end": 167.4, "text": " you make the connection, and you send a username and your password, and the server tells you", "tokens": [291, 652, 264, 4984, 11, 293, 291, 2845, 257, 30351, 293, 428, 11524, 11, 293, 264, 7154, 5112, 291], "temperature": 0.0, "avg_logprob": -0.11894457527760709, "compression_ratio": 1.7673267326732673, "no_speech_prob": 2.825436240527779e-05}, {"id": 27, "seek": 16228, "start": 167.4, "end": 173.44, "text": " if it's correct, and then you can proceed to do authenticated stuff. This is actually", "tokens": [498, 309, 311, 3006, 11, 293, 550, 291, 393, 8991, 281, 360, 9214, 3587, 1507, 13, 639, 307, 767], "temperature": 0.0, "avg_logprob": -0.11894457527760709, "compression_ratio": 1.7673267326732673, "no_speech_prob": 2.825436240527779e-05}, {"id": 28, "seek": 16228, "start": 173.44, "end": 180.84, "text": " how the web works, pretty much. So you have this HTML form, you put in your username,", "tokens": [577, 264, 3670, 1985, 11, 1238, 709, 13, 407, 291, 362, 341, 17995, 1254, 11, 291, 829, 294, 428, 30351, 11], "temperature": 0.0, "avg_logprob": -0.11894457527760709, "compression_ratio": 1.7673267326732673, "no_speech_prob": 2.825436240527779e-05}, {"id": 29, "seek": 16228, "start": 180.84, "end": 186.0, "text": " you put in your password, your password gets sent to the web server, and the server verifies", "tokens": [291, 829, 294, 428, 11524, 11, 428, 11524, 2170, 2279, 281, 264, 3670, 7154, 11, 293, 264, 7154, 1306, 11221], "temperature": 0.0, "avg_logprob": -0.11894457527760709, "compression_ratio": 1.7673267326732673, "no_speech_prob": 2.825436240527779e-05}, {"id": 30, "seek": 18600, "start": 186.0, "end": 192.36, "text": " it, and usually on the server side, the password is hashed, which means, I mean, if it's a good", "tokens": [309, 11, 293, 2673, 322, 264, 7154, 1252, 11, 264, 11524, 307, 22019, 292, 11, 597, 1355, 11, 286, 914, 11, 498, 309, 311, 257, 665], "temperature": 0.0, "avg_logprob": -0.12634042438707854, "compression_ratio": 1.6851851851851851, "no_speech_prob": 2.9353061108849943e-05}, {"id": 31, "seek": 18600, "start": 192.36, "end": 196.76, "text": " place, then it's hashed on the server side, so then they hash the incoming password, and", "tokens": [1081, 11, 550, 309, 311, 22019, 292, 322, 264, 7154, 1252, 11, 370, 550, 436, 22019, 264, 22341, 11524, 11, 293], "temperature": 0.0, "avg_logprob": -0.12634042438707854, "compression_ratio": 1.6851851851851851, "no_speech_prob": 2.9353061108849943e-05}, {"id": 32, "seek": 18600, "start": 196.76, "end": 206.12, "text": " they compare it with the hash that they have stored. So XMPP uses a standard authentication", "tokens": [436, 6794, 309, 365, 264, 22019, 300, 436, 362, 12187, 13, 407, 1783, 12224, 47, 4960, 257, 3832, 26643], "temperature": 0.0, "avg_logprob": -0.12634042438707854, "compression_ratio": 1.6851851851851851, "no_speech_prob": 2.9353061108849943e-05}, {"id": 33, "seek": 18600, "start": 206.12, "end": 213.0, "text": " protocol called SASL. It's actually used by a bunch of different protocols, and there's", "tokens": [10336, 1219, 33441, 43, 13, 467, 311, 767, 1143, 538, 257, 3840, 295, 819, 20618, 11, 293, 456, 311], "temperature": 0.0, "avg_logprob": -0.12634042438707854, "compression_ratio": 1.6851851851851851, "no_speech_prob": 2.9353061108849943e-05}, {"id": 34, "seek": 21300, "start": 213.0, "end": 219.16, "text": " currently work to try and implement it in HTTP as well. And so SASL defines a bunch", "tokens": [4362, 589, 281, 853, 293, 4445, 309, 294, 33283, 382, 731, 13, 400, 370, 33441, 43, 23122, 257, 3840], "temperature": 0.0, "avg_logprob": -0.13276370541080013, "compression_ratio": 1.5644444444444445, "no_speech_prob": 2.794473221001681e-05}, {"id": 35, "seek": 21300, "start": 219.16, "end": 226.04, "text": " of mechanisms, and the mechanism says what you send. And so the simplest one probably", "tokens": [295, 15902, 11, 293, 264, 7513, 1619, 437, 291, 2845, 13, 400, 370, 264, 22811, 472, 1391], "temperature": 0.0, "avg_logprob": -0.13276370541080013, "compression_ratio": 1.5644444444444445, "no_speech_prob": 2.794473221001681e-05}, {"id": 36, "seek": 21300, "start": 226.04, "end": 231.28, "text": " is plain, and this is exactly what we just saw with the, you know, the Hi, I'm Matthew,", "tokens": [307, 11121, 11, 293, 341, 307, 2293, 437, 321, 445, 1866, 365, 264, 11, 291, 458, 11, 264, 2421, 11, 286, 478, 12434, 11], "temperature": 0.0, "avg_logprob": -0.13276370541080013, "compression_ratio": 1.5644444444444445, "no_speech_prob": 2.794473221001681e-05}, {"id": 37, "seek": 21300, "start": 231.28, "end": 239.72, "text": " my password is, and the web is very similar. You're just sending a username and your password.", "tokens": [452, 11524, 307, 11, 293, 264, 3670, 307, 588, 2531, 13, 509, 434, 445, 7750, 257, 30351, 293, 428, 11524, 13], "temperature": 0.0, "avg_logprob": -0.13276370541080013, "compression_ratio": 1.5644444444444445, "no_speech_prob": 2.794473221001681e-05}, {"id": 38, "seek": 23972, "start": 239.72, "end": 247.12, "text": " And so sending passwords across the wire is absolutely fine because of all these reasons,", "tokens": [400, 370, 7750, 33149, 2108, 264, 6234, 307, 3122, 2489, 570, 295, 439, 613, 4112, 11], "temperature": 0.0, "avg_logprob": -0.14054060881992556, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.5716604795888998e-05}, {"id": 39, "seek": 23972, "start": 247.12, "end": 252.6, "text": " and nobody ever reuses passwords, and they are, you know, frequently rotated and updated,", "tokens": [293, 5079, 1562, 319, 8355, 33149, 11, 293, 436, 366, 11, 291, 458, 11, 10374, 42146, 293, 10588, 11], "temperature": 0.0, "avg_logprob": -0.14054060881992556, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.5716604795888998e-05}, {"id": 40, "seek": 23972, "start": 252.6, "end": 256.52, "text": " and they never contain personal information, so if they're leaked, then, you know, no bad", "tokens": [293, 436, 1128, 5304, 2973, 1589, 11, 370, 498, 436, 434, 31779, 11, 550, 11, 291, 458, 11, 572, 1578], "temperature": 0.0, "avg_logprob": -0.14054060881992556, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.5716604795888998e-05}, {"id": 41, "seek": 23972, "start": 256.52, "end": 261.84, "text": " consequences. And, yeah, they're never also reused across services, which means this is", "tokens": [10098, 13, 400, 11, 1338, 11, 436, 434, 1128, 611, 319, 4717, 2108, 3328, 11, 597, 1355, 341, 307], "temperature": 0.0, "avg_logprob": -0.14054060881992556, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.5716604795888998e-05}, {"id": 42, "seek": 23972, "start": 261.84, "end": 266.52, "text": " just great because if passwords ever do get leaked, and those hashes maybe, you know, brute", "tokens": [445, 869, 570, 498, 33149, 1562, 360, 483, 31779, 11, 293, 729, 575, 8076, 1310, 11, 291, 458, 11, 47909], "temperature": 0.0, "avg_logprob": -0.14054060881992556, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.5716604795888998e-05}, {"id": 43, "seek": 26652, "start": 266.52, "end": 271.12, "text": " forced, then, you know, no one gets access to any other service than the compromised", "tokens": [7579, 11, 550, 11, 291, 458, 11, 572, 472, 2170, 2105, 281, 604, 661, 2643, 813, 264, 32463], "temperature": 0.0, "avg_logprob": -0.15280598607556573, "compression_ratio": 1.589090909090909, "no_speech_prob": 5.134052844368853e-05}, {"id": 44, "seek": 26652, "start": 271.12, "end": 278.08, "text": " one, which was already compromised anyway. Okay. Yeah, that was just a joke. So in XMPP,", "tokens": [472, 11, 597, 390, 1217, 32463, 4033, 13, 1033, 13, 865, 11, 300, 390, 445, 257, 7647, 13, 407, 294, 1783, 12224, 47, 11], "temperature": 0.0, "avg_logprob": -0.15280598607556573, "compression_ratio": 1.589090909090909, "no_speech_prob": 5.134052844368853e-05}, {"id": 45, "seek": 26652, "start": 278.08, "end": 282.64, "text": " we don't really use plain. We use another SASL mechanism that someone defined called", "tokens": [321, 500, 380, 534, 764, 11121, 13, 492, 764, 1071, 33441, 43, 7513, 300, 1580, 7642, 1219], "temperature": 0.0, "avg_logprob": -0.15280598607556573, "compression_ratio": 1.589090909090909, "no_speech_prob": 5.134052844368853e-05}, {"id": 46, "seek": 26652, "start": 282.64, "end": 289.28, "text": " Scram. It's not just, hey, my password is, it's a challenge response thing, so there's", "tokens": [2747, 2356, 13, 467, 311, 406, 445, 11, 4177, 11, 452, 11524, 307, 11, 309, 311, 257, 3430, 4134, 551, 11, 370, 456, 311], "temperature": 0.0, "avg_logprob": -0.15280598607556573, "compression_ratio": 1.589090909090909, "no_speech_prob": 5.134052844368853e-05}, {"id": 47, "seek": 26652, "start": 289.28, "end": 296.12, "text": " a bit of magic going on with hashing, and it has some really nice features. It does involve", "tokens": [257, 857, 295, 5585, 516, 322, 365, 575, 571, 11, 293, 309, 575, 512, 534, 1481, 4122, 13, 467, 775, 9494], "temperature": 0.0, "avg_logprob": -0.15280598607556573, "compression_ratio": 1.589090909090909, "no_speech_prob": 5.134052844368853e-05}, {"id": 48, "seek": 29612, "start": 296.12, "end": 300.84000000000003, "text": " multiple round trips, so, yeah, you're going backwards and forwards, but these by you that", "tokens": [3866, 3098, 16051, 11, 370, 11, 1338, 11, 291, 434, 516, 12204, 293, 30126, 11, 457, 613, 538, 291, 300], "temperature": 0.0, "avg_logprob": -0.11605210053293329, "compression_ratio": 1.8693877551020408, "no_speech_prob": 5.545867679757066e-05}, {"id": 49, "seek": 29612, "start": 300.84000000000003, "end": 305.52, "text": " the client and the server can only store hashes, so previously, we couldn't have the client", "tokens": [264, 6423, 293, 264, 7154, 393, 787, 3531, 575, 8076, 11, 370, 8046, 11, 321, 2809, 380, 362, 264, 6423], "temperature": 0.0, "avg_logprob": -0.11605210053293329, "compression_ratio": 1.8693877551020408, "no_speech_prob": 5.545867679757066e-05}, {"id": 50, "seek": 29612, "start": 305.52, "end": 309.64, "text": " store a hash because it has to send the raw password for the server to hash. If you only", "tokens": [3531, 257, 22019, 570, 309, 575, 281, 2845, 264, 8936, 11524, 337, 264, 7154, 281, 22019, 13, 759, 291, 787], "temperature": 0.0, "avg_logprob": -0.11605210053293329, "compression_ratio": 1.8693877551020408, "no_speech_prob": 5.545867679757066e-05}, {"id": 51, "seek": 29612, "start": 309.64, "end": 316.04, "text": " send a hash, then the hash becomes your password, which is kind of weird. So Scram has multiple", "tokens": [2845, 257, 22019, 11, 550, 264, 22019, 3643, 428, 11524, 11, 597, 307, 733, 295, 3657, 13, 407, 2747, 2356, 575, 3866], "temperature": 0.0, "avg_logprob": -0.11605210053293329, "compression_ratio": 1.8693877551020408, "no_speech_prob": 5.545867679757066e-05}, {"id": 52, "seek": 29612, "start": 316.04, "end": 320.2, "text": " iterations of hashing. It allows the client to store a hash. It allows the server to still", "tokens": [36540, 295, 575, 571, 13, 467, 4045, 264, 6423, 281, 3531, 257, 22019, 13, 467, 4045, 264, 7154, 281, 920], "temperature": 0.0, "avg_logprob": -0.11605210053293329, "compression_ratio": 1.8693877551020408, "no_speech_prob": 5.545867679757066e-05}, {"id": 53, "seek": 32020, "start": 320.2, "end": 326.76, "text": " store a hash, and only hashes exchanged over the wire. It's pretty magic, and the mutual", "tokens": [3531, 257, 22019, 11, 293, 787, 575, 8076, 38378, 670, 264, 6234, 13, 467, 311, 1238, 5585, 11, 293, 264, 16917], "temperature": 0.0, "avg_logprob": -0.14620580025089597, "compression_ratio": 1.9113924050632911, "no_speech_prob": 1.3748700439464301e-05}, {"id": 54, "seek": 32020, "start": 326.76, "end": 333.32, "text": " authentication part means that at the end of the authentication exchange, both the server", "tokens": [26643, 644, 1355, 300, 412, 264, 917, 295, 264, 26643, 7742, 11, 1293, 264, 7154], "temperature": 0.0, "avg_logprob": -0.14620580025089597, "compression_ratio": 1.9113924050632911, "no_speech_prob": 1.3748700439464301e-05}, {"id": 55, "seek": 32020, "start": 333.32, "end": 339.76, "text": " has authenticated the client and proven, yes, this person originally had the password, and", "tokens": [575, 9214, 3587, 264, 6423, 293, 12785, 11, 2086, 11, 341, 954, 7993, 632, 264, 11524, 11, 293], "temperature": 0.0, "avg_logprob": -0.14620580025089597, "compression_ratio": 1.9113924050632911, "no_speech_prob": 1.3748700439464301e-05}, {"id": 56, "seek": 32020, "start": 339.76, "end": 343.68, "text": " they are who they say they are, but importantly, it allows the client to verify that the server", "tokens": [436, 366, 567, 436, 584, 436, 366, 11, 457, 8906, 11, 309, 4045, 264, 6423, 281, 16888, 300, 264, 7154], "temperature": 0.0, "avg_logprob": -0.14620580025089597, "compression_ratio": 1.9113924050632911, "no_speech_prob": 1.3748700439464301e-05}, {"id": 57, "seek": 32020, "start": 343.68, "end": 349.8, "text": " also knows the original password, which in the past, with the plain mechanisms and like", "tokens": [611, 3255, 264, 3380, 11524, 11, 597, 294, 264, 1791, 11, 365, 264, 11121, 15902, 293, 411], "temperature": 0.0, "avg_logprob": -0.14620580025089597, "compression_ratio": 1.9113924050632911, "no_speech_prob": 1.3748700439464301e-05}, {"id": 58, "seek": 34980, "start": 349.8, "end": 353.72, "text": " the web, the server can just lie and say, yeah, I have your password, carry on, send", "tokens": [264, 3670, 11, 264, 7154, 393, 445, 4544, 293, 584, 11, 1338, 11, 286, 362, 428, 11524, 11, 3985, 322, 11, 2845], "temperature": 0.0, "avg_logprob": -0.1366188842638404, "compression_ratio": 1.7076923076923076, "no_speech_prob": 5.0616508815437555e-05}, {"id": 59, "seek": 34980, "start": 353.72, "end": 358.8, "text": " me more sensitive information, and so we have this mutual authentication, so when you connect", "tokens": [385, 544, 9477, 1589, 11, 293, 370, 321, 362, 341, 16917, 26643, 11, 370, 562, 291, 1745], "temperature": 0.0, "avg_logprob": -0.1366188842638404, "compression_ratio": 1.7076923076923076, "no_speech_prob": 5.0616508815437555e-05}, {"id": 60, "seek": 34980, "start": 358.8, "end": 366.08000000000004, "text": " over XMPP and you use Scram, you have this verification that also the server you're", "tokens": [670, 1783, 12224, 47, 293, 291, 764, 2747, 2356, 11, 291, 362, 341, 30206, 300, 611, 264, 7154, 291, 434], "temperature": 0.0, "avg_logprob": -0.1366188842638404, "compression_ratio": 1.7076923076923076, "no_speech_prob": 5.0616508815437555e-05}, {"id": 61, "seek": 34980, "start": 366.08000000000004, "end": 370.76, "text": " connecting to is the right one, and yes, we do have this with TLS, obviously, but there", "tokens": [11015, 281, 307, 264, 558, 472, 11, 293, 2086, 11, 321, 360, 362, 341, 365, 314, 19198, 11, 2745, 11, 457, 456], "temperature": 0.0, "avg_logprob": -0.1366188842638404, "compression_ratio": 1.7076923076923076, "no_speech_prob": 5.0616508815437555e-05}, {"id": 62, "seek": 34980, "start": 370.76, "end": 376.12, "text": " are certain cases where TLS isn't always reliable, and that's where channel binding comes in,", "tokens": [366, 1629, 3331, 689, 314, 19198, 1943, 380, 1009, 12924, 11, 293, 300, 311, 689, 2269, 17359, 1487, 294, 11], "temperature": 0.0, "avg_logprob": -0.1366188842638404, "compression_ratio": 1.7076923076923076, "no_speech_prob": 5.0616508815437555e-05}, {"id": 63, "seek": 37612, "start": 376.12, "end": 381.44, "text": " which is a bit more magic, and this binds your authentication, that mutual authentication", "tokens": [597, 307, 257, 857, 544, 5585, 11, 293, 341, 41515, 428, 26643, 11, 300, 16917, 26643], "temperature": 0.0, "avg_logprob": -0.1434427582391418, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.020304863341153e-05}, {"id": 64, "seek": 37612, "start": 381.44, "end": 387.6, "text": " stuff to your TLS channel, and so if you reach the end and the mutual authentication checks", "tokens": [1507, 281, 428, 314, 19198, 2269, 11, 293, 370, 498, 291, 2524, 264, 917, 293, 264, 16917, 26643, 13834], "temperature": 0.0, "avg_logprob": -0.1434427582391418, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.020304863341153e-05}, {"id": 65, "seek": 37612, "start": 387.6, "end": 395.24, "text": " out, but you find a little mismatch, this TLS magic can tell you that actually there", "tokens": [484, 11, 457, 291, 915, 257, 707, 23220, 852, 11, 341, 314, 19198, 5585, 393, 980, 291, 300, 767, 456], "temperature": 0.0, "avg_logprob": -0.1434427582391418, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.020304863341153e-05}, {"id": 66, "seek": 37612, "start": 395.24, "end": 399.44, "text": " is someone listening in on your TLS connection, and that can be because, for example, your", "tokens": [307, 1580, 4764, 294, 322, 428, 314, 19198, 4984, 11, 293, 300, 393, 312, 570, 11, 337, 1365, 11, 428], "temperature": 0.0, "avg_logprob": -0.1434427582391418, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.020304863341153e-05}, {"id": 67, "seek": 37612, "start": 399.44, "end": 405.48, "text": " certificate authority was compromised or whatever, so someone installed a different trust route", "tokens": [15953, 8281, 390, 32463, 420, 2035, 11, 370, 1580, 8899, 257, 819, 3361, 7955], "temperature": 0.0, "avg_logprob": -0.1434427582391418, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.020304863341153e-05}, {"id": 68, "seek": 40548, "start": 405.48, "end": 409.52000000000004, "text": " on your system without you knowing, and so we can actually detect this, and it's pretty", "tokens": [322, 428, 1185, 1553, 291, 5276, 11, 293, 370, 321, 393, 767, 5531, 341, 11, 293, 309, 311, 1238], "temperature": 0.0, "avg_logprob": -0.13929421693375968, "compression_ratio": 1.62890625, "no_speech_prob": 7.017027382971719e-05}, {"id": 69, "seek": 40548, "start": 409.52000000000004, "end": 415.04, "text": " smart, all this security comes at a cost, obviously we just talked about why it's necessary,", "tokens": [4069, 11, 439, 341, 3825, 1487, 412, 257, 2063, 11, 2745, 321, 445, 2825, 466, 983, 309, 311, 4818, 11], "temperature": 0.0, "avg_logprob": -0.13929421693375968, "compression_ratio": 1.62890625, "no_speech_prob": 7.017027382971719e-05}, {"id": 70, "seek": 40548, "start": 415.04, "end": 420.56, "text": " but it's also still password based, so what can we do?", "tokens": [457, 309, 311, 611, 920, 11524, 2361, 11, 370, 437, 393, 321, 360, 30], "temperature": 0.0, "avg_logprob": -0.13929421693375968, "compression_ratio": 1.62890625, "no_speech_prob": 7.017027382971719e-05}, {"id": 71, "seek": 40548, "start": 420.56, "end": 425.12, "text": " So there's been a lot of interesting development on the web ecosystem in recent years, they're", "tokens": [407, 456, 311, 668, 257, 688, 295, 1880, 3250, 322, 264, 3670, 11311, 294, 5162, 924, 11, 436, 434], "temperature": 0.0, "avg_logprob": -0.13929421693375968, "compression_ratio": 1.62890625, "no_speech_prob": 7.017027382971719e-05}, {"id": 72, "seek": 40548, "start": 425.12, "end": 431.44, "text": " trying to, they've tried fixing stuff, and it's basically hard, users are always going", "tokens": [1382, 281, 11, 436, 600, 3031, 19442, 1507, 11, 293, 309, 311, 1936, 1152, 11, 5022, 366, 1009, 516], "temperature": 0.0, "avg_logprob": -0.13929421693375968, "compression_ratio": 1.62890625, "no_speech_prob": 7.017027382971719e-05}, {"id": 73, "seek": 43144, "start": 431.44, "end": 436.32, "text": " to be users, they're always going to choose memorable passwords, and there has been some", "tokens": [281, 312, 5022, 11, 436, 434, 1009, 516, 281, 2826, 20723, 33149, 11, 293, 456, 575, 668, 512], "temperature": 0.0, "avg_logprob": -0.19672600428263345, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.665904609486461e-05}, {"id": 74, "seek": 43144, "start": 436.32, "end": 439.96, "text": " progress, there are password managers and so on, but although they're best practice,", "tokens": [4205, 11, 456, 366, 11524, 14084, 293, 370, 322, 11, 457, 4878, 436, 434, 1151, 3124, 11], "temperature": 0.0, "avg_logprob": -0.19672600428263345, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.665904609486461e-05}, {"id": 75, "seek": 43144, "start": 439.96, "end": 444.64, "text": " they're not widely used, I mean amongst normal people, probably everyone here, I hope has", "tokens": [436, 434, 406, 13371, 1143, 11, 286, 914, 12918, 2710, 561, 11, 1391, 1518, 510, 11, 286, 1454, 575], "temperature": 0.0, "avg_logprob": -0.19672600428263345, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.665904609486461e-05}, {"id": 76, "seek": 43144, "start": 444.64, "end": 454.6, "text": " a password manager, so WebOrthN 502, it's basically a combination of things, they allow the browser", "tokens": [257, 11524, 6598, 11, 370, 9573, 21520, 392, 45, 2625, 17, 11, 309, 311, 1936, 257, 6562, 295, 721, 11, 436, 2089, 264, 11185], "temperature": 0.0, "avg_logprob": -0.19672600428263345, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.665904609486461e-05}, {"id": 77, "seek": 43144, "start": 454.6, "end": 459.92, "text": " to do some special stuff and help with the authentication, you can do that with an external", "tokens": [281, 360, 512, 2121, 1507, 293, 854, 365, 264, 26643, 11, 291, 393, 360, 300, 365, 364, 8320], "temperature": 0.0, "avg_logprob": -0.19672600428263345, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.665904609486461e-05}, {"id": 78, "seek": 45992, "start": 459.92, "end": 465.6, "text": " hardware token, but these days also browsers are supporting TPM chips inside the hardware,", "tokens": [8837, 14862, 11, 457, 613, 1708, 611, 36069, 366, 7231, 314, 18819, 11583, 1854, 264, 8837, 11], "temperature": 0.0, "avg_logprob": -0.13632459266513003, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.243176615796983e-05}, {"id": 79, "seek": 45992, "start": 465.6, "end": 469.78000000000003, "text": " which allows you to link that authentication securely to a single device, and pass keys", "tokens": [597, 4045, 291, 281, 2113, 300, 26643, 38348, 281, 257, 2167, 4302, 11, 293, 1320, 9317], "temperature": 0.0, "avg_logprob": -0.13632459266513003, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.243176615796983e-05}, {"id": 80, "seek": 45992, "start": 469.78000000000003, "end": 474.40000000000003, "text": " are like Apple's thing that they're really pushing, which is based on all this, and allows", "tokens": [366, 411, 6373, 311, 551, 300, 436, 434, 534, 7380, 11, 597, 307, 2361, 322, 439, 341, 11, 293, 4045], "temperature": 0.0, "avg_logprob": -0.13632459266513003, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.243176615796983e-05}, {"id": 81, "seek": 45992, "start": 474.40000000000003, "end": 484.28000000000003, "text": " you to basically create an account without a password, and authenticate using this special", "tokens": [291, 281, 1936, 1884, 364, 2696, 1553, 257, 11524, 11, 293, 9214, 8700, 1228, 341, 2121], "temperature": 0.0, "avg_logprob": -0.13632459266513003, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.243176615796983e-05}, {"id": 82, "seek": 45992, "start": 484.28000000000003, "end": 488.12, "text": " key that is only on your device, except it's also synchronized via iCloud, and so you", "tokens": [2141, 300, 307, 787, 322, 428, 4302, 11, 3993, 309, 311, 611, 19331, 1602, 5766, 741, 32787, 11, 293, 370, 291], "temperature": 0.0, "avg_logprob": -0.13632459266513003, "compression_ratio": 1.722007722007722, "no_speech_prob": 3.243176615796983e-05}, {"id": 83, "seek": 48812, "start": 488.12, "end": 493.32, "text": " can access your account from all your devices without ever needing a password, which is", "tokens": [393, 2105, 428, 2696, 490, 439, 428, 5759, 1553, 1562, 18006, 257, 11524, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.15729340086592006, "compression_ratio": 1.5565217391304347, "no_speech_prob": 4.3216441554250196e-05}, {"id": 84, "seek": 48812, "start": 493.32, "end": 498.2, "text": " as long as you can access your iCloud account, now that's just one implementation, there", "tokens": [382, 938, 382, 291, 393, 2105, 428, 741, 32787, 2696, 11, 586, 300, 311, 445, 472, 11420, 11, 456], "temperature": 0.0, "avg_logprob": -0.15729340086592006, "compression_ratio": 1.5565217391304347, "no_speech_prob": 4.3216441554250196e-05}, {"id": 85, "seek": 48812, "start": 498.2, "end": 506.64, "text": " are other things, WebOrthN 502, and it's all based on open standards, but XMPP uses Sassel,", "tokens": [366, 661, 721, 11, 9573, 21520, 392, 45, 2625, 17, 11, 293, 309, 311, 439, 2361, 322, 1269, 7787, 11, 457, 1783, 12224, 47, 4960, 318, 640, 338, 11], "temperature": 0.0, "avg_logprob": -0.15729340086592006, "compression_ratio": 1.5565217391304347, "no_speech_prob": 4.3216441554250196e-05}, {"id": 86, "seek": 48812, "start": 506.64, "end": 514.4, "text": " which is focused on passwords, so what can we do, I've been working on this new mechanism", "tokens": [597, 307, 5178, 322, 33149, 11, 370, 437, 393, 321, 360, 11, 286, 600, 668, 1364, 322, 341, 777, 7513], "temperature": 0.0, "avg_logprob": -0.15729340086592006, "compression_ratio": 1.5565217391304347, "no_speech_prob": 4.3216441554250196e-05}, {"id": 87, "seek": 51440, "start": 514.4, "end": 522.68, "text": " in XMPP, which is token based, and it builds on some earlier work, which introduces a new", "tokens": [294, 1783, 12224, 47, 11, 597, 307, 14862, 2361, 11, 293, 309, 15182, 322, 512, 3071, 589, 11, 597, 31472, 257, 777], "temperature": 0.0, "avg_logprob": -0.12185587934268419, "compression_ratio": 1.6108597285067874, "no_speech_prob": 5.1410232117632404e-05}, {"id": 88, "seek": 51440, "start": 522.68, "end": 529.88, "text": " Sassel mechanism, or a family of mechanisms, which allow you to exchange a hash of the", "tokens": [318, 640, 338, 7513, 11, 420, 257, 1605, 295, 15902, 11, 597, 2089, 291, 281, 7742, 257, 22019, 295, 264], "temperature": 0.0, "avg_logprob": -0.12185587934268419, "compression_ratio": 1.6108597285067874, "no_speech_prob": 5.1410232117632404e-05}, {"id": 89, "seek": 51440, "start": 529.88, "end": 535.88, "text": " token over the wire, so we're not sending the raw token, so it's a bit scram-like in", "tokens": [14862, 670, 264, 6234, 11, 370, 321, 434, 406, 7750, 264, 8936, 14862, 11, 370, 309, 311, 257, 857, 795, 2356, 12, 4092, 294], "temperature": 0.0, "avg_logprob": -0.12185587934268419, "compression_ratio": 1.6108597285067874, "no_speech_prob": 5.1410232117632404e-05}, {"id": 90, "seek": 51440, "start": 535.88, "end": 542.4, "text": " that sense, it still provides mutual authentication, and it still supports channel binding, so", "tokens": [300, 2020, 11, 309, 920, 6417, 16917, 26643, 11, 293, 309, 920, 9346, 2269, 17359, 11, 370], "temperature": 0.0, "avg_logprob": -0.12185587934268419, "compression_ratio": 1.6108597285067874, "no_speech_prob": 5.1410232117632404e-05}, {"id": 91, "seek": 54240, "start": 542.4, "end": 549.84, "text": " you still have all those nice features of scram, it is a single round trip, so there's", "tokens": [291, 920, 362, 439, 729, 1481, 4122, 295, 795, 2356, 11, 309, 307, 257, 2167, 3098, 4931, 11, 370, 456, 311], "temperature": 0.0, "avg_logprob": -0.10946239427078602, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.00010316100815543905}, {"id": 92, "seek": 54240, "start": 549.84, "end": 556.28, "text": " no back and forth like with scram, the things that we are weakening in that sense don't", "tokens": [572, 646, 293, 5220, 411, 365, 795, 2356, 11, 264, 721, 300, 321, 366, 5336, 4559, 294, 300, 2020, 500, 380], "temperature": 0.0, "avg_logprob": -0.10946239427078602, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.00010316100815543905}, {"id": 93, "seek": 54240, "start": 556.28, "end": 562.12, "text": " matter because the tokens are not passwords, and so although there is a slightly reduced", "tokens": [1871, 570, 264, 22667, 366, 406, 33149, 11, 293, 370, 4878, 456, 307, 257, 4748, 9212], "temperature": 0.0, "avg_logprob": -0.10946239427078602, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.00010316100815543905}, {"id": 94, "seek": 54240, "start": 562.12, "end": 570.4, "text": " level of security around the token compared to scram, the tokens are temporary, so if", "tokens": [1496, 295, 3825, 926, 264, 14862, 5347, 281, 795, 2356, 11, 264, 22667, 366, 13413, 11, 370, 498], "temperature": 0.0, "avg_logprob": -0.10946239427078602, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.00010316100815543905}, {"id": 95, "seek": 57040, "start": 570.4, "end": 576.52, "text": " they get leaked, then you can easily revoke them, rotate them, and they are unique to", "tokens": [436, 483, 31779, 11, 550, 291, 393, 3612, 3698, 2949, 552, 11, 13121, 552, 11, 293, 436, 366, 3845, 281], "temperature": 0.0, "avg_logprob": -0.15578837761512168, "compression_ratio": 1.8006872852233677, "no_speech_prob": 6.786634185118601e-05}, {"id": 96, "seek": 57040, "start": 576.52, "end": 579.92, "text": " that service, and I would hope that if a service is compromised, you know, they're obviously", "tokens": [300, 2643, 11, 293, 286, 576, 1454, 300, 498, 257, 2643, 307, 32463, 11, 291, 458, 11, 436, 434, 2745], "temperature": 0.0, "avg_logprob": -0.15578837761512168, "compression_ratio": 1.8006872852233677, "no_speech_prob": 6.786634185118601e-05}, {"id": 97, "seek": 57040, "start": 579.92, "end": 584.3199999999999, "text": " going to revoke all their tokens straight away, it's harder to get users to reset all", "tokens": [516, 281, 3698, 2949, 439, 641, 22667, 2997, 1314, 11, 309, 311, 6081, 281, 483, 5022, 281, 14322, 439], "temperature": 0.0, "avg_logprob": -0.15578837761512168, "compression_ratio": 1.8006872852233677, "no_speech_prob": 6.786634185118601e-05}, {"id": 98, "seek": 57040, "start": 584.3199999999999, "end": 589.6, "text": " their passwords straight away, so there's many benefits to using tokens, and we still", "tokens": [641, 33149, 2997, 1314, 11, 370, 456, 311, 867, 5311, 281, 1228, 22667, 11, 293, 321, 920], "temperature": 0.0, "avg_logprob": -0.15578837761512168, "compression_ratio": 1.8006872852233677, "no_speech_prob": 6.786634185118601e-05}, {"id": 99, "seek": 57040, "start": 589.6, "end": 593.68, "text": " get all the nice features of scram, but users aren't going to generate tokens and enter", "tokens": [483, 439, 264, 1481, 4122, 295, 795, 2356, 11, 457, 5022, 3212, 380, 516, 281, 8460, 22667, 293, 3242], "temperature": 0.0, "avg_logprob": -0.15578837761512168, "compression_ratio": 1.8006872852233677, "no_speech_prob": 6.786634185118601e-05}, {"id": 100, "seek": 57040, "start": 593.68, "end": 600.3199999999999, "text": " them themselves, so this opens the door to two-factor authentication in XMPP as well,", "tokens": [552, 2969, 11, 370, 341, 9870, 264, 2853, 281, 732, 12, 69, 15104, 26643, 294, 1783, 12224, 47, 382, 731, 11], "temperature": 0.0, "avg_logprob": -0.15578837761512168, "compression_ratio": 1.8006872852233677, "no_speech_prob": 6.786634185118601e-05}, {"id": 101, "seek": 60032, "start": 600.32, "end": 604.4000000000001, "text": " previously we've had this problem where you can kind of do two-factor authentication,", "tokens": [8046, 321, 600, 632, 341, 1154, 689, 291, 393, 733, 295, 360, 732, 12, 69, 15104, 26643, 11], "temperature": 0.0, "avg_logprob": -0.14061726868607616, "compression_ratio": 1.8827838827838828, "no_speech_prob": 6.864593888167292e-05}, {"id": 102, "seek": 60032, "start": 604.4000000000001, "end": 609.72, "text": " but every time you drive through a tunnel, then your XMPP app is re-authenticating on", "tokens": [457, 633, 565, 291, 3332, 807, 257, 13186, 11, 550, 428, 1783, 12224, 47, 724, 307, 319, 12, 40198, 317, 30541, 322], "temperature": 0.0, "avg_logprob": -0.14061726868607616, "compression_ratio": 1.8827838827838828, "no_speech_prob": 6.864593888167292e-05}, {"id": 103, "seek": 60032, "start": 609.72, "end": 613.6800000000001, "text": " the other side because it's reconnecting to the server and has to re-prove who it is,", "tokens": [264, 661, 1252, 570, 309, 311, 30095, 278, 281, 264, 7154, 293, 575, 281, 319, 12, 46955, 567, 309, 307, 11], "temperature": 0.0, "avg_logprob": -0.14061726868607616, "compression_ratio": 1.8827838827838828, "no_speech_prob": 6.864593888167292e-05}, {"id": 104, "seek": 60032, "start": 613.6800000000001, "end": 618.44, "text": " if it uses the password, then the server is going to say, well, you know, you have the", "tokens": [498, 309, 4960, 264, 11524, 11, 550, 264, 7154, 307, 516, 281, 584, 11, 731, 11, 291, 458, 11, 291, 362, 264], "temperature": 0.0, "avg_logprob": -0.14061726868607616, "compression_ratio": 1.8827838827838828, "no_speech_prob": 6.864593888167292e-05}, {"id": 105, "seek": 60032, "start": 618.44, "end": 622.12, "text": " password, but the whole point of two-factor authentication is to make the password not", "tokens": [11524, 11, 457, 264, 1379, 935, 295, 732, 12, 69, 15104, 26643, 307, 281, 652, 264, 11524, 406], "temperature": 0.0, "avg_logprob": -0.14061726868607616, "compression_ratio": 1.8827838827838828, "no_speech_prob": 6.864593888167292e-05}, {"id": 106, "seek": 60032, "start": 622.12, "end": 627.84, "text": " enough because of all the weaknesses that passwords entail, so if you authenticate", "tokens": [1547, 570, 295, 439, 264, 24381, 300, 33149, 948, 864, 11, 370, 498, 291, 9214, 8700], "temperature": 0.0, "avg_logprob": -0.14061726868607616, "compression_ratio": 1.8827838827838828, "no_speech_prob": 6.864593888167292e-05}, {"id": 107, "seek": 62784, "start": 627.84, "end": 631.36, "text": " with a token instead, then the server knows it issued this token once, it issued it to", "tokens": [365, 257, 14862, 2602, 11, 550, 264, 7154, 3255, 309, 14379, 341, 14862, 1564, 11, 309, 14379, 309, 281], "temperature": 0.0, "avg_logprob": -0.17432381813986259, "compression_ratio": 1.7983539094650205, "no_speech_prob": 2.541342291806359e-05}, {"id": 108, "seek": 62784, "start": 631.36, "end": 636.32, "text": " that device, and it knows who you are, and there's a higher security guarantee around", "tokens": [300, 4302, 11, 293, 309, 3255, 567, 291, 366, 11, 293, 456, 311, 257, 2946, 3825, 10815, 926], "temperature": 0.0, "avg_logprob": -0.17432381813986259, "compression_ratio": 1.7983539094650205, "no_speech_prob": 2.541342291806359e-05}, {"id": 109, "seek": 62784, "start": 636.32, "end": 637.6800000000001, "text": " that.", "tokens": [300, 13], "temperature": 0.0, "avg_logprob": -0.17432381813986259, "compression_ratio": 1.7983539094650205, "no_speech_prob": 2.541342291806359e-05}, {"id": 110, "seek": 62784, "start": 637.6800000000001, "end": 642.96, "text": " So by using the new Sassel mechanism, servers won't, they'll see that you're authenticating", "tokens": [407, 538, 1228, 264, 777, 318, 640, 338, 7513, 11, 15909, 1582, 380, 11, 436, 603, 536, 300, 291, 434, 12466, 990], "temperature": 0.0, "avg_logprob": -0.17432381813986259, "compression_ratio": 1.7983539094650205, "no_speech_prob": 2.541342291806359e-05}, {"id": 111, "seek": 62784, "start": 642.96, "end": 647.4, "text": " with a secure token, and they won't send the two-factor authentication prompts that", "tokens": [365, 257, 7144, 14862, 11, 293, 436, 1582, 380, 2845, 264, 732, 12, 69, 15104, 26643, 41095, 300], "temperature": 0.0, "avg_logprob": -0.17432381813986259, "compression_ratio": 1.7983539094650205, "no_speech_prob": 2.541342291806359e-05}, {"id": 112, "seek": 62784, "start": 647.4, "end": 650.52, "text": " they usually send.", "tokens": [436, 2673, 2845, 13], "temperature": 0.0, "avg_logprob": -0.17432381813986259, "compression_ratio": 1.7983539094650205, "no_speech_prob": 2.541342291806359e-05}, {"id": 113, "seek": 62784, "start": 650.52, "end": 653.5600000000001, "text": " This is basically how two-factor auth on the web already works.", "tokens": [639, 307, 1936, 577, 732, 12, 69, 15104, 6979, 322, 264, 3670, 1217, 1985, 13], "temperature": 0.0, "avg_logprob": -0.17432381813986259, "compression_ratio": 1.7983539094650205, "no_speech_prob": 2.541342291806359e-05}, {"id": 114, "seek": 65356, "start": 653.56, "end": 658.0, "text": " You provide that web form or whatever, maybe you're using pass keys, but once you do that", "tokens": [509, 2893, 300, 3670, 1254, 420, 2035, 11, 1310, 291, 434, 1228, 1320, 9317, 11, 457, 1564, 291, 360, 300], "temperature": 0.0, "avg_logprob": -0.11191314089614733, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.507733658305369e-05}, {"id": 115, "seek": 65356, "start": 658.0, "end": 662.16, "text": " initial authentication step, the web service is going to send back a cookie that gets stored", "tokens": [5883, 26643, 1823, 11, 264, 3670, 2643, 307, 516, 281, 2845, 646, 257, 14417, 300, 2170, 12187], "temperature": 0.0, "avg_logprob": -0.11191314089614733, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.507733658305369e-05}, {"id": 116, "seek": 65356, "start": 662.16, "end": 666.92, "text": " in your browser in plain text, and with every request, yes, it's going over HTTPS, but it's", "tokens": [294, 428, 11185, 294, 11121, 2487, 11, 293, 365, 633, 5308, 11, 2086, 11, 309, 311, 516, 670, 11751, 51, 6273, 11, 457, 309, 311], "temperature": 0.0, "avg_logprob": -0.11191314089614733, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.507733658305369e-05}, {"id": 117, "seek": 65356, "start": 666.92, "end": 671.8399999999999, "text": " still sending that, you know, plain text string, and it doesn't have all the protections of", "tokens": [920, 7750, 300, 11, 291, 458, 11, 11121, 2487, 6798, 11, 293, 309, 1177, 380, 362, 439, 264, 29031, 295], "temperature": 0.0, "avg_logprob": -0.11191314089614733, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.507733658305369e-05}, {"id": 118, "seek": 65356, "start": 671.8399999999999, "end": 678.8, "text": " the channel binding and the mutual authentication that the FAST and Sassel mechanisms are supporting.", "tokens": [264, 2269, 17359, 293, 264, 16917, 26643, 300, 264, 479, 20398, 293, 318, 640, 338, 15902, 366, 7231, 13], "temperature": 0.0, "avg_logprob": -0.11191314089614733, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.507733658305369e-05}, {"id": 119, "seek": 67880, "start": 678.8, "end": 684.28, "text": " So in this sense, using FAST over, for example, the new HTTP Sassel stuff would be an interesting", "tokens": [407, 294, 341, 2020, 11, 1228, 479, 20398, 670, 11, 337, 1365, 11, 264, 777, 33283, 318, 640, 338, 1507, 576, 312, 364, 1880], "temperature": 0.0, "avg_logprob": -0.11790960033734639, "compression_ratio": 1.6707818930041152, "no_speech_prob": 1.6387873984058388e-05}, {"id": 120, "seek": 67880, "start": 684.28, "end": 689.76, "text": " security improvement for many secure web applications.", "tokens": [3825, 10444, 337, 867, 7144, 3670, 5821, 13], "temperature": 0.0, "avg_logprob": -0.11790960033734639, "compression_ratio": 1.6707818930041152, "no_speech_prob": 1.6387873984058388e-05}, {"id": 121, "seek": 67880, "start": 689.76, "end": 694.28, "text": " And so the other thing is it opens the door to having passwordless accounts.", "tokens": [400, 370, 264, 661, 551, 307, 309, 9870, 264, 2853, 281, 1419, 11524, 1832, 9402, 13], "temperature": 0.0, "avg_logprob": -0.11790960033734639, "compression_ratio": 1.6707818930041152, "no_speech_prob": 1.6387873984058388e-05}, {"id": 122, "seek": 67880, "start": 694.28, "end": 700.5999999999999, "text": " So instead of exchanging your password for a token, you could exchange your password", "tokens": [407, 2602, 295, 6210, 9741, 428, 11524, 337, 257, 14862, 11, 291, 727, 7742, 428, 11524], "temperature": 0.0, "avg_logprob": -0.11790960033734639, "compression_ratio": 1.6707818930041152, "no_speech_prob": 1.6387873984058388e-05}, {"id": 123, "seek": 67880, "start": 700.5999999999999, "end": 705.12, "text": " plus a two-factor auth for a token, or you could do something entirely different, something", "tokens": [1804, 257, 732, 12, 69, 15104, 6979, 337, 257, 14862, 11, 420, 291, 727, 360, 746, 7696, 819, 11, 746], "temperature": 0.0, "avg_logprob": -0.11790960033734639, "compression_ratio": 1.6707818930041152, "no_speech_prob": 1.6387873984058388e-05}, {"id": 124, "seek": 70512, "start": 705.12, "end": 710.16, "text": " came up just at the real-time stand downstairs, someone wants to do SMS authentication, so", "tokens": [1361, 493, 445, 412, 264, 957, 12, 3766, 1463, 20148, 11, 1580, 2738, 281, 360, 38107, 26643, 11, 370], "temperature": 0.0, "avg_logprob": -0.12549591064453125, "compression_ratio": 1.62, "no_speech_prob": 3.63274994015228e-05}, {"id": 125, "seek": 70512, "start": 710.16, "end": 715.88, "text": " they verify SMS, kind of like how WhatsApp or Signal work, and then you will just be", "tokens": [436, 16888, 38107, 11, 733, 295, 411, 577, 30513, 420, 43414, 589, 11, 293, 550, 291, 486, 445, 312], "temperature": 0.0, "avg_logprob": -0.12549591064453125, "compression_ratio": 1.62, "no_speech_prob": 3.63274994015228e-05}, {"id": 126, "seek": 70512, "start": 715.88, "end": 721.6, "text": " given a FAST token, and then you can reconnect to the server using that.", "tokens": [2212, 257, 479, 20398, 14862, 11, 293, 550, 291, 393, 30095, 281, 264, 7154, 1228, 300, 13], "temperature": 0.0, "avg_logprob": -0.12549591064453125, "compression_ratio": 1.62, "no_speech_prob": 3.63274994015228e-05}, {"id": 127, "seek": 70512, "start": 721.6, "end": 723.96, "text": " And that will last for as long as you keep your device active.", "tokens": [400, 300, 486, 1036, 337, 382, 938, 382, 291, 1066, 428, 4302, 4967, 13], "temperature": 0.0, "avg_logprob": -0.12549591064453125, "compression_ratio": 1.62, "no_speech_prob": 3.63274994015228e-05}, {"id": 128, "seek": 70512, "start": 723.96, "end": 729.28, "text": " If you have an inactive device, then that token will stop being refreshed, it will eventually", "tokens": [759, 291, 362, 364, 294, 12596, 4302, 11, 550, 300, 14862, 486, 1590, 885, 46330, 11, 309, 486, 4728], "temperature": 0.0, "avg_logprob": -0.12549591064453125, "compression_ratio": 1.62, "no_speech_prob": 3.63274994015228e-05}, {"id": 129, "seek": 72928, "start": 729.28, "end": 738.0, "text": " expire, and you will have to reauthenticate using SMS or maybe some recovery mechanism.", "tokens": [45447, 11, 293, 291, 486, 362, 281, 319, 40198, 317, 8700, 1228, 38107, 420, 1310, 512, 8597, 7513, 13], "temperature": 0.0, "avg_logprob": -0.12861359396646188, "compression_ratio": 1.5475113122171946, "no_speech_prob": 7.329196523642167e-05}, {"id": 130, "seek": 72928, "start": 738.0, "end": 742.0799999999999, "text": " And once you've breached up this passwordless account, then obviously you can add other", "tokens": [400, 1564, 291, 600, 1403, 15095, 493, 341, 11524, 1832, 2696, 11, 550, 2745, 291, 393, 909, 661], "temperature": 0.0, "avg_logprob": -0.12861359396646188, "compression_ratio": 1.5475113122171946, "no_speech_prob": 7.329196523642167e-05}, {"id": 131, "seek": 72928, "start": 742.0799999999999, "end": 747.8399999999999, "text": " recovery mechanisms as a backup if you need to.", "tokens": [8597, 15902, 382, 257, 14807, 498, 291, 643, 281, 13], "temperature": 0.0, "avg_logprob": -0.12861359396646188, "compression_ratio": 1.5475113122171946, "no_speech_prob": 7.329196523642167e-05}, {"id": 132, "seek": 72928, "start": 747.8399999999999, "end": 749.8399999999999, "text": " And yeah, that was kind of the summary of my talk.", "tokens": [400, 1338, 11, 300, 390, 733, 295, 264, 12691, 295, 452, 751, 13], "temperature": 0.0, "avg_logprob": -0.12861359396646188, "compression_ratio": 1.5475113122171946, "no_speech_prob": 7.329196523642167e-05}, {"id": 133, "seek": 72928, "start": 749.8399999999999, "end": 755.0, "text": " I hope there's still time for many questions if you are interested.", "tokens": [286, 1454, 456, 311, 920, 565, 337, 867, 1651, 498, 291, 366, 3102, 13], "temperature": 0.0, "avg_logprob": -0.12861359396646188, "compression_ratio": 1.5475113122171946, "no_speech_prob": 7.329196523642167e-05}, {"id": 134, "seek": 75500, "start": 755.0, "end": 758.92, "text": " So this talk is kind of a complement to a blog post that I wrote on the Presley blog", "tokens": [407, 341, 751, 307, 733, 295, 257, 17103, 281, 257, 6968, 2183, 300, 286, 4114, 322, 264, 2718, 3420, 6968], "temperature": 0.0, "avg_logprob": -0.22860281808035715, "compression_ratio": 1.7854077253218885, "no_speech_prob": 3.797149838646874e-05}, {"id": 135, "seek": 75500, "start": 758.92, "end": 764.08, "text": " about all this stuff, but the blog post focus mostly on the performance optimizations because", "tokens": [466, 439, 341, 1507, 11, 457, 264, 6968, 2183, 1879, 5240, 322, 264, 3389, 5028, 14455, 570], "temperature": 0.0, "avg_logprob": -0.22860281808035715, "compression_ratio": 1.7854077253218885, "no_speech_prob": 3.797149838646874e-05}, {"id": 136, "seek": 75500, "start": 764.08, "end": 770.56, "text": " that matters to people, they want to be reconnected to the server as quickly as possible because", "tokens": [300, 7001, 281, 561, 11, 436, 528, 281, 312, 30095, 292, 281, 264, 7154, 382, 2661, 382, 1944, 570], "temperature": 0.0, "avg_logprob": -0.22860281808035715, "compression_ratio": 1.7854077253218885, "no_speech_prob": 3.797149838646874e-05}, {"id": 137, "seek": 75500, "start": 770.56, "end": 773.0, "text": " responsiveness and all this.", "tokens": [2914, 8477, 293, 439, 341, 13], "temperature": 0.0, "avg_logprob": -0.22860281808035715, "compression_ratio": 1.7854077253218885, "no_speech_prob": 3.797149838646874e-05}, {"id": 138, "seek": 75500, "start": 773.0, "end": 779.0, "text": " And so the blog post focus on the optimization aspects of this, today the talk focuses on", "tokens": [400, 370, 264, 6968, 2183, 1879, 322, 264, 19618, 7270, 295, 341, 11, 965, 264, 751, 16109, 322], "temperature": 0.0, "avg_logprob": -0.22860281808035715, "compression_ratio": 1.7854077253218885, "no_speech_prob": 3.797149838646874e-05}, {"id": 139, "seek": 75500, "start": 779.0, "end": 781.96, "text": " the security aspects.", "tokens": [264, 3825, 7270, 13], "temperature": 0.0, "avg_logprob": -0.22860281808035715, "compression_ratio": 1.7854077253218885, "no_speech_prob": 3.797149838646874e-05}, {"id": 140, "seek": 78196, "start": 781.96, "end": 786.44, "text": " And yeah, there's some more XMPP talks coming up later on, I am downstairs also in the real", "tokens": [400, 1338, 11, 456, 311, 512, 544, 1783, 12224, 47, 6686, 1348, 493, 1780, 322, 11, 286, 669, 20148, 611, 294, 264, 957], "temperature": 0.0, "avg_logprob": -0.23770715344336726, "compression_ratio": 1.4076433121019107, "no_speech_prob": 0.00014695922436658293}, {"id": 141, "seek": 78196, "start": 786.44, "end": 793.24, "text": " time lounge, which is just down around the corner, and you can reach me on XMPP or email", "tokens": [565, 33408, 11, 597, 307, 445, 760, 926, 264, 4538, 11, 293, 291, 393, 2524, 385, 322, 1783, 12224, 47, 420, 3796], "temperature": 0.0, "avg_logprob": -0.23770715344336726, "compression_ratio": 1.4076433121019107, "no_speech_prob": 0.00014695922436658293}, {"id": 142, "seek": 78196, "start": 793.24, "end": 799.4000000000001, "text": " and yeah, happy to answer any questions.", "tokens": [293, 1338, 11, 2055, 281, 1867, 604, 1651, 13], "temperature": 0.0, "avg_logprob": -0.23770715344336726, "compression_ratio": 1.4076433121019107, "no_speech_prob": 0.00014695922436658293}, {"id": 143, "seek": 79940, "start": 799.4, "end": 816.36, "text": " Can you tell us where they overlap, where they differ, can fast be used in scenarios where", "tokens": [1664, 291, 980, 505, 689, 436, 19959, 11, 689, 436, 743, 11, 393, 2370, 312, 1143, 294, 15077, 689], "temperature": 0.0, "avg_logprob": -0.4086119333902995, "compression_ratio": 1.404109589041096, "no_speech_prob": 0.00041803563362918794}, {"id": 144, "seek": 79940, "start": 816.36, "end": 822.6, "text": " JSON web tokens already exist as something better, or is it more divergent as a difference?", "tokens": [31828, 3670, 22667, 1217, 2514, 382, 746, 1101, 11, 420, 307, 309, 544, 18558, 6930, 382, 257, 2649, 30], "temperature": 0.0, "avg_logprob": -0.4086119333902995, "compression_ratio": 1.404109589041096, "no_speech_prob": 0.00041803563362918794}, {"id": 145, "seek": 79940, "start": 822.6, "end": 823.6, "text": " It's pretty different.", "tokens": [467, 311, 1238, 819, 13], "temperature": 0.0, "avg_logprob": -0.4086119333902995, "compression_ratio": 1.404109589041096, "no_speech_prob": 0.00041803563362918794}, {"id": 146, "seek": 82360, "start": 823.6, "end": 830.84, "text": " Yeah, sorry, so the question is ultimately, are JWT, JSON web tokens similar overlapping", "tokens": [865, 11, 2597, 11, 370, 264, 1168, 307, 6284, 11, 366, 49885, 51, 11, 31828, 3670, 22667, 2531, 33535], "temperature": 0.0, "avg_logprob": -0.19026194423078055, "compression_ratio": 1.538812785388128, "no_speech_prob": 0.00020405591931194067}, {"id": 147, "seek": 82360, "start": 830.84, "end": 833.12, "text": " with fast tokens?", "tokens": [365, 2370, 22667, 30], "temperature": 0.0, "avg_logprob": -0.19026194423078055, "compression_ratio": 1.538812785388128, "no_speech_prob": 0.00020405591931194067}, {"id": 148, "seek": 82360, "start": 833.12, "end": 841.16, "text": " Fast tokens are essentially opaque random strings of a good length for security reasons.", "tokens": [15968, 22667, 366, 4476, 42687, 4974, 13985, 295, 257, 665, 4641, 337, 3825, 4112, 13], "temperature": 0.0, "avg_logprob": -0.19026194423078055, "compression_ratio": 1.538812785388128, "no_speech_prob": 0.00020405591931194067}, {"id": 149, "seek": 82360, "start": 841.16, "end": 845.6, "text": " JSON web tokens, they are also embedding stuff inside that token.", "tokens": [31828, 3670, 22667, 11, 436, 366, 611, 12240, 3584, 1507, 1854, 300, 14862, 13], "temperature": 0.0, "avg_logprob": -0.19026194423078055, "compression_ratio": 1.538812785388128, "no_speech_prob": 0.00020405591931194067}, {"id": 150, "seek": 82360, "start": 845.6, "end": 851.24, "text": " A server could do similar, and when it issues the token, use a JWT instead.", "tokens": [316, 7154, 727, 360, 2531, 11, 293, 562, 309, 2663, 264, 14862, 11, 764, 257, 49885, 51, 2602, 13], "temperature": 0.0, "avg_logprob": -0.19026194423078055, "compression_ratio": 1.538812785388128, "no_speech_prob": 0.00020405591931194067}, {"id": 151, "seek": 85124, "start": 851.24, "end": 854.28, "text": " There's not really much benefit to that.", "tokens": [821, 311, 406, 534, 709, 5121, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.23896444997479838, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0001756231940817088}, {"id": 152, "seek": 85124, "start": 854.28, "end": 859.84, "text": " JSON web tokens, they are still useful for some cases, definitely, but they have a bad", "tokens": [31828, 3670, 22667, 11, 436, 366, 920, 4420, 337, 512, 3331, 11, 2138, 11, 457, 436, 362, 257, 1578], "temperature": 0.0, "avg_logprob": -0.23896444997479838, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0001756231940817088}, {"id": 153, "seek": 85124, "start": 859.84, "end": 862.24, "text": " reputation with regards to security.", "tokens": [13061, 365, 14258, 281, 3825, 13], "temperature": 0.0, "avg_logprob": -0.23896444997479838, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0001756231940817088}, {"id": 154, "seek": 85124, "start": 862.24, "end": 867.8, "text": " Yeah, it's complicated, but there's not really much overlap.", "tokens": [865, 11, 309, 311, 6179, 11, 457, 456, 311, 406, 534, 709, 19959, 13], "temperature": 0.0, "avg_logprob": -0.23896444997479838, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0001756231940817088}, {"id": 155, "seek": 85124, "start": 867.8, "end": 873.2, "text": " They can be kind of used in the same situation, but not entirely.", "tokens": [814, 393, 312, 733, 295, 1143, 294, 264, 912, 2590, 11, 457, 406, 7696, 13], "temperature": 0.0, "avg_logprob": -0.23896444997479838, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0001756231940817088}, {"id": 156, "seek": 85124, "start": 873.2, "end": 877.92, "text": " If you were doing a distributed network where you didn't really necessarily want to have", "tokens": [759, 291, 645, 884, 257, 12631, 3209, 689, 291, 994, 380, 534, 4725, 528, 281, 362], "temperature": 0.0, "avg_logprob": -0.23896444997479838, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0001756231940817088}, {"id": 157, "seek": 87792, "start": 877.92, "end": 882.4799999999999, "text": " a backend communication, could you authenticate a fast token against one service, and then", "tokens": [257, 38087, 6101, 11, 727, 291, 9214, 8700, 257, 2370, 14862, 1970, 472, 2643, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.2652488848484984, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.00016238176613114774}, {"id": 158, "seek": 87792, "start": 882.4799999999999, "end": 888.24, "text": " that contains information that could authenticate with a trusted system that's not sharing a", "tokens": [300, 8306, 1589, 300, 727, 9214, 8700, 365, 257, 16034, 1185, 300, 311, 406, 5414, 257], "temperature": 0.0, "avg_logprob": -0.2652488848484984, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.00016238176613114774}, {"id": 159, "seek": 87792, "start": 888.24, "end": 889.24, "text": " backend?", "tokens": [38087, 30], "temperature": 0.0, "avg_logprob": -0.2652488848484984, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.00016238176613114774}, {"id": 160, "seek": 87792, "start": 889.24, "end": 890.24, "text": " Yeah, absolutely.", "tokens": [865, 11, 3122, 13], "temperature": 0.0, "avg_logprob": -0.2652488848484984, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.00016238176613114774}, {"id": 161, "seek": 87792, "start": 890.24, "end": 892.1999999999999, "text": " Any way that the server can verify the token is valid?", "tokens": [2639, 636, 300, 264, 7154, 393, 16888, 264, 14862, 307, 7363, 30], "temperature": 0.0, "avg_logprob": -0.2652488848484984, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.00016238176613114774}, {"id": 162, "seek": 87792, "start": 892.1999999999999, "end": 900.12, "text": " Sorry, the question is, if you were working on a decentralized system where the authentication", "tokens": [4919, 11, 264, 1168, 307, 11, 498, 291, 645, 1364, 322, 257, 32870, 1185, 689, 264, 26643], "temperature": 0.0, "avg_logprob": -0.2652488848484984, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.00016238176613114774}, {"id": 163, "seek": 87792, "start": 900.12, "end": 904.36, "text": " system is separate to the place where the user is logging in, then can you use JWT in", "tokens": [1185, 307, 4994, 281, 264, 1081, 689, 264, 4195, 307, 27991, 294, 11, 550, 393, 291, 764, 49885, 51, 294], "temperature": 0.0, "avg_logprob": -0.2652488848484984, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.00016238176613114774}, {"id": 164, "seek": 87792, "start": 904.36, "end": 905.36, "text": " that situation?", "tokens": [300, 2590, 30], "temperature": 0.0, "avg_logprob": -0.2652488848484984, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.00016238176613114774}, {"id": 165, "seek": 90536, "start": 905.36, "end": 908.36, "text": " The answer is yes, you could use it.", "tokens": [440, 1867, 307, 2086, 11, 291, 727, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.39272079467773435, "compression_ratio": 1.6826923076923077, "no_speech_prob": 7.32710977899842e-05}, {"id": 166, "seek": 90536, "start": 908.36, "end": 915.36, "text": " Two questions, are you attempting to standardize fast within the standards body, and second,", "tokens": [4453, 1651, 11, 366, 291, 22001, 281, 3832, 1125, 2370, 1951, 264, 7787, 1772, 11, 293, 1150, 11], "temperature": 0.0, "avg_logprob": -0.39272079467773435, "compression_ratio": 1.6826923076923077, "no_speech_prob": 7.32710977899842e-05}, {"id": 167, "seek": 90536, "start": 915.36, "end": 923.12, "text": " do you set the tokens that are disused, decayed by what mechanism?", "tokens": [360, 291, 992, 264, 22667, 300, 366, 717, 4717, 11, 21039, 292, 538, 437, 7513, 30], "temperature": 0.0, "avg_logprob": -0.39272079467773435, "compression_ratio": 1.6826923076923077, "no_speech_prob": 7.32710977899842e-05}, {"id": 168, "seek": 90536, "start": 923.12, "end": 927.48, "text": " The first question was, are we attempting to standardize fast?", "tokens": [440, 700, 1168, 390, 11, 366, 321, 22001, 281, 3832, 1125, 2370, 30], "temperature": 0.0, "avg_logprob": -0.39272079467773435, "compression_ratio": 1.6826923076923077, "no_speech_prob": 7.32710977899842e-05}, {"id": 169, "seek": 90536, "start": 927.48, "end": 934.24, "text": " Yes, so the sassel mechanism that it is based on is already a draft at the IETF, it's been", "tokens": [1079, 11, 370, 264, 262, 640, 338, 7513, 300, 309, 307, 2361, 322, 307, 1217, 257, 11206, 412, 264, 286, 4850, 37, 11, 309, 311, 668], "temperature": 0.0, "avg_logprob": -0.39272079467773435, "compression_ratio": 1.6826923076923077, "no_speech_prob": 7.32710977899842e-05}, {"id": 170, "seek": 93424, "start": 934.24, "end": 935.84, "text": " going a while.", "tokens": [516, 257, 1339, 13], "temperature": 0.0, "avg_logprob": -0.13802482010027683, "compression_ratio": 1.6812749003984064, "no_speech_prob": 7.0601912739221e-05}, {"id": 171, "seek": 93424, "start": 935.84, "end": 942.36, "text": " We had a meeting with the sassel working group at the IETF just last month, and they agreed", "tokens": [492, 632, 257, 3440, 365, 264, 262, 640, 338, 1364, 1594, 412, 264, 286, 4850, 37, 445, 1036, 1618, 11, 293, 436, 9166], "temperature": 0.0, "avg_logprob": -0.13802482010027683, "compression_ratio": 1.6812749003984064, "no_speech_prob": 7.0601912739221e-05}, {"id": 172, "seek": 93424, "start": 942.36, "end": 945.6800000000001, "text": " that this is stuff that is interesting and they want to move forward with, because it", "tokens": [300, 341, 307, 1507, 300, 307, 1880, 293, 436, 528, 281, 1286, 2128, 365, 11, 570, 309], "temperature": 0.0, "avg_logprob": -0.13802482010027683, "compression_ratio": 1.6812749003984064, "no_speech_prob": 7.0601912739221e-05}, {"id": 173, "seek": 93424, "start": 945.6800000000001, "end": 950.6, "text": " is also useful for other protocols, the email ecosystem and many others.", "tokens": [307, 611, 4420, 337, 661, 20618, 11, 264, 3796, 11311, 293, 867, 2357, 13], "temperature": 0.0, "avg_logprob": -0.13802482010027683, "compression_ratio": 1.6812749003984064, "no_speech_prob": 7.0601912739221e-05}, {"id": 174, "seek": 93424, "start": 950.6, "end": 956.24, "text": " So yes, we are the XMPP layer of this, the whole fast stuff.", "tokens": [407, 2086, 11, 321, 366, 264, 1783, 12224, 47, 4583, 295, 341, 11, 264, 1379, 2370, 1507, 13], "temperature": 0.0, "avg_logprob": -0.13802482010027683, "compression_ratio": 1.6812749003984064, "no_speech_prob": 7.0601912739221e-05}, {"id": 175, "seek": 93424, "start": 956.24, "end": 962.92, "text": " That is being standardized at the XMPP Standards Foundation, so that layer, if another protocol", "tokens": [663, 307, 885, 31677, 412, 264, 1783, 12224, 47, 44546, 10335, 11, 370, 300, 4583, 11, 498, 1071, 10336], "temperature": 0.0, "avg_logprob": -0.13802482010027683, "compression_ratio": 1.6812749003984064, "no_speech_prob": 7.0601912739221e-05}, {"id": 176, "seek": 96292, "start": 962.92, "end": 966.4, "text": " wanted to use it, they would have to define their own, because the fast stuff specifically", "tokens": [1415, 281, 764, 309, 11, 436, 576, 362, 281, 6964, 641, 1065, 11, 570, 264, 2370, 1507, 4682], "temperature": 0.0, "avg_logprob": -0.16272228785923548, "compression_ratio": 1.68, "no_speech_prob": 0.00014656262646894902}, {"id": 177, "seek": 96292, "start": 966.4, "end": 968.16, "text": " is XMPP specific.", "tokens": [307, 1783, 12224, 47, 2685, 13], "temperature": 0.0, "avg_logprob": -0.16272228785923548, "compression_ratio": 1.68, "no_speech_prob": 0.00014656262646894902}, {"id": 178, "seek": 96292, "start": 968.16, "end": 972.4399999999999, "text": " They can copy how we have done it, but it has to be translated to a different protocol.", "tokens": [814, 393, 5055, 577, 321, 362, 1096, 309, 11, 457, 309, 575, 281, 312, 16805, 281, 257, 819, 10336, 13], "temperature": 0.0, "avg_logprob": -0.16272228785923548, "compression_ratio": 1.68, "no_speech_prob": 0.00014656262646894902}, {"id": 179, "seek": 96292, "start": 972.4399999999999, "end": 978.7199999999999, "text": " The second question was, how do disused tokens decay?", "tokens": [440, 1150, 1168, 390, 11, 577, 360, 717, 4717, 22667, 21039, 30], "temperature": 0.0, "avg_logprob": -0.16272228785923548, "compression_ratio": 1.68, "no_speech_prob": 0.00014656262646894902}, {"id": 180, "seek": 96292, "start": 978.7199999999999, "end": 983.16, "text": " That is basically up to the server, there is an algorithm in the fast specification,", "tokens": [663, 307, 1936, 493, 281, 264, 7154, 11, 456, 307, 364, 9284, 294, 264, 2370, 31256, 11], "temperature": 0.0, "avg_logprob": -0.16272228785923548, "compression_ratio": 1.68, "no_speech_prob": 0.00014656262646894902}, {"id": 181, "seek": 96292, "start": 983.16, "end": 987.5999999999999, "text": " which is linked from the blog post, which tells you how to implement the server in a", "tokens": [597, 307, 9408, 490, 264, 6968, 2183, 11, 597, 5112, 291, 577, 281, 4445, 264, 7154, 294, 257], "temperature": 0.0, "avg_logprob": -0.16272228785923548, "compression_ratio": 1.68, "no_speech_prob": 0.00014656262646894902}, {"id": 182, "seek": 98760, "start": 987.6, "end": 994.4, "text": " way that is going to securely rotate tokens, without having to check every possible token", "tokens": [636, 300, 307, 516, 281, 38348, 13121, 22667, 11, 1553, 1419, 281, 1520, 633, 1944, 14862], "temperature": 0.0, "avg_logprob": -0.13205206505606107, "compression_ratio": 1.7300380228136882, "no_speech_prob": 5.1601695304270834e-05}, {"id": 183, "seek": 98760, "start": 994.4, "end": 997.64, "text": " on the server, because we don't necessarily know the user's identity until we verified", "tokens": [322, 264, 7154, 11, 570, 321, 500, 380, 4725, 458, 264, 4195, 311, 6575, 1826, 321, 31197], "temperature": 0.0, "avg_logprob": -0.13205206505606107, "compression_ratio": 1.7300380228136882, "no_speech_prob": 5.1601695304270834e-05}, {"id": 184, "seek": 98760, "start": 997.64, "end": 998.64, "text": " the token.", "tokens": [264, 14862, 13], "temperature": 0.0, "avg_logprob": -0.13205206505606107, "compression_ratio": 1.7300380228136882, "no_speech_prob": 5.1601695304270834e-05}, {"id": 185, "seek": 98760, "start": 998.64, "end": 1003.24, "text": " So it can be a bit complex, but essentially it's just the server knows the expiry time", "tokens": [407, 309, 393, 312, 257, 857, 3997, 11, 457, 4476, 309, 311, 445, 264, 7154, 3255, 264, 1278, 12781, 565], "temperature": 0.0, "avg_logprob": -0.13205206505606107, "compression_ratio": 1.7300380228136882, "no_speech_prob": 5.1601695304270834e-05}, {"id": 186, "seek": 98760, "start": 1003.24, "end": 1008.72, "text": " of a token when the token was last seen, and some interesting stuff came up with how to", "tokens": [295, 257, 14862, 562, 264, 14862, 390, 1036, 1612, 11, 293, 512, 1880, 1507, 1361, 493, 365, 577, 281], "temperature": 0.0, "avg_logprob": -0.13205206505606107, "compression_ratio": 1.7300380228136882, "no_speech_prob": 5.1601695304270834e-05}, {"id": 187, "seek": 98760, "start": 1008.72, "end": 1014.12, "text": " refresh tokens, because if the client authenticates and then you provide it with a new token", "tokens": [15134, 22667, 11, 570, 498, 264, 6423, 12466, 1024, 293, 550, 291, 2893, 309, 365, 257, 777, 14862], "temperature": 0.0, "avg_logprob": -0.13205206505606107, "compression_ratio": 1.7300380228136882, "no_speech_prob": 5.1601695304270834e-05}, {"id": 188, "seek": 101412, "start": 1014.12, "end": 1018.88, "text": " and immediately expire the old one, so that's one way of doing the rotation, there are", "tokens": [293, 4258, 45447, 264, 1331, 472, 11, 370, 300, 311, 472, 636, 295, 884, 264, 12447, 11, 456, 366], "temperature": 0.0, "avg_logprob": -0.13134497980917653, "compression_ratio": 1.876865671641791, "no_speech_prob": 2.7181442419532686e-05}, {"id": 189, "seek": 101412, "start": 1018.88, "end": 1025.2, "text": " cases where the client actually reconnected, used the old token, and then did not receive", "tokens": [3331, 689, 264, 6423, 767, 30095, 292, 11, 1143, 264, 1331, 14862, 11, 293, 550, 630, 406, 4774], "temperature": 0.0, "avg_logprob": -0.13134497980917653, "compression_ratio": 1.876865671641791, "no_speech_prob": 2.7181442419532686e-05}, {"id": 190, "seek": 101412, "start": 1025.2, "end": 1030.56, "text": " the new token, got disconnected, and then it gets logged out, basically, because it", "tokens": [264, 777, 14862, 11, 658, 29426, 11, 293, 550, 309, 2170, 27231, 484, 11, 1936, 11, 570, 309], "temperature": 0.0, "avg_logprob": -0.13134497980917653, "compression_ratio": 1.876865671641791, "no_speech_prob": 2.7181442419532686e-05}, {"id": 191, "seek": 101412, "start": 1030.56, "end": 1032.48, "text": " can no longer access.", "tokens": [393, 572, 2854, 2105, 13], "temperature": 0.0, "avg_logprob": -0.13134497980917653, "compression_ratio": 1.876865671641791, "no_speech_prob": 2.7181442419532686e-05}, {"id": 192, "seek": 101412, "start": 1032.48, "end": 1037.44, "text": " So the server has to store the last token that the client used, and also the new replacement", "tokens": [407, 264, 7154, 575, 281, 3531, 264, 1036, 14862, 300, 264, 6423, 1143, 11, 293, 611, 264, 777, 14419], "temperature": 0.0, "avg_logprob": -0.13134497980917653, "compression_ratio": 1.876865671641791, "no_speech_prob": 2.7181442419532686e-05}, {"id": 193, "seek": 101412, "start": 1037.44, "end": 1039.64, "text": " token, it's expecting it to use next.", "tokens": [14862, 11, 309, 311, 9650, 309, 281, 764, 958, 13], "temperature": 0.0, "avg_logprob": -0.13134497980917653, "compression_ratio": 1.876865671641791, "no_speech_prob": 2.7181442419532686e-05}, {"id": 194, "seek": 101412, "start": 1039.64, "end": 1043.68, "text": " And if the client never uses that token, then it will eventually issue a new one and work", "tokens": [400, 498, 264, 6423, 1128, 4960, 300, 14862, 11, 550, 309, 486, 4728, 2734, 257, 777, 472, 293, 589], "temperature": 0.0, "avg_logprob": -0.13134497980917653, "compression_ratio": 1.876865671641791, "no_speech_prob": 2.7181442419532686e-05}, {"id": 195, "seek": 104368, "start": 1043.68, "end": 1044.68, "text": " out.", "tokens": [484, 13], "temperature": 0.0, "avg_logprob": -0.25198161083719006, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.00034334714291617274}, {"id": 196, "seek": 104368, "start": 1044.68, "end": 1048.0800000000002, "text": " And that's the moment you see it authenticate with the new token.", "tokens": [400, 300, 311, 264, 1623, 291, 536, 309, 9214, 8700, 365, 264, 777, 14862, 13], "temperature": 0.0, "avg_logprob": -0.25198161083719006, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.00034334714291617274}, {"id": 197, "seek": 104368, "start": 1048.0800000000002, "end": 1052.0, "text": " That's when you expire the old one completely, and obviously there is a time limit to that,", "tokens": [663, 311, 562, 291, 45447, 264, 1331, 472, 2584, 11, 293, 2745, 456, 307, 257, 565, 4948, 281, 300, 11], "temperature": 0.0, "avg_logprob": -0.25198161083719006, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.00034334714291617274}, {"id": 198, "seek": 104368, "start": 1052.0, "end": 1054.96, "text": " because otherwise someone can carry on using the old one indefinitely, and we don't want", "tokens": [570, 5911, 1580, 393, 3985, 322, 1228, 264, 1331, 472, 24162, 10925, 11, 293, 321, 500, 380, 528], "temperature": 0.0, "avg_logprob": -0.25198161083719006, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.00034334714291617274}, {"id": 199, "seek": 104368, "start": 1054.96, "end": 1055.96, "text": " that either.", "tokens": [300, 2139, 13], "temperature": 0.0, "avg_logprob": -0.25198161083719006, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.00034334714291617274}, {"id": 200, "seek": 104368, "start": 1055.96, "end": 1063.44, "text": " So there's kind of two timeouts built in, okay, excellent.", "tokens": [407, 456, 311, 733, 295, 732, 565, 7711, 3094, 294, 11, 1392, 11, 7103, 13], "temperature": 0.0, "avg_logprob": -0.25198161083719006, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.00034334714291617274}, {"id": 201, "seek": 104368, "start": 1063.44, "end": 1064.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.25198161083719006, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.00034334714291617274}, {"id": 202, "seek": 106444, "start": 1064.44, "end": 1074.56, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.8421117464701334, "compression_ratio": 1.0, "no_speech_prob": 0.0018591516418382525}, {"id": 203, "seek": 106444, "start": 1074.56, "end": 1082.24, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.8421117464701334, "compression_ratio": 1.0, "no_speech_prob": 0.0018591516418382525}], "language": "en"}