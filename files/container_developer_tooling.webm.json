{"text": " our next talk. I guess I don't have to give a big introduction. A lot of you know Phil, right? He's going to talk about Turing the container developer tooling landscape. All right. Hi everybody. I think I'm on. Yeah, you're on. Yeah, so thanks for coming. It seems like Fossum is back. We've got a packed containers room. I think my talk is mostly a warm-up for Akahiro after me. So a lot of familiar faces here. A lot of good talk so far. Maybe this will be a little bit different than the last few talks. We've been talking a lot about containers and various environments, but we haven't really talked about tools. You've seen a few tools used in some of the demos. And so I'm just going to talk through where we are these days with development tooling. Interesting that it's 2023 and interesting year in that we're now 10 years since Solomon Hikes gave this demo during a lightning talk at PyCon. I think it was like April. So getting pretty close to 10 years since someone saw Docker being run at the command line for the first time. And what an interesting demo was because he misspelled Hello World and that's now permanently in the history of the Internet forever. We've been using containers for a long time now. Apologies to those who are big Solaris fans or BSD, obviously containers and the technologies behind them existed in other operating systems before Docker. But essentially, at this point, everything that's been demoed today has been on Linux. There was a great kind of intro in one of the earlier talks about namespaces and C groups. This picture is old because people keep creating new namespaces. So it doesn't work anymore. This was a cool image way back in the day because it was the perfect number to create like a flat packed box. So you create your box out of the namespaces and then you shape your box with C groups. What size do you want it to be? What limits do you want to place on that? And apologies to my friends at Microsoft again. There are containers on Windows as well these days. But again, for the lion's share of use cases, these are the features and the technologies we've been using to create containers. But let's not forget there's other pieces to the puzzle, whether you're using Docker or some other runtime. There's SE Linux or App Armor in use. There's Setcom profiles. The images we've been constructing, millions of them are constructed around Linux concepts, libraries, binaries that are basically Linux user space file systems. And then there's the Linux capabilities that we add or remove or default in our container runtimes. So again, all these things are very Linux specific. And yet, you know, where are developers developing these containers? What tools are they using on what platforms? And I got a little nervous coming to FOSDOM because I thought, oh boy, everybody in this room, there's Linux on the laptop actually is alive and well at FOSDOM, but not so much other places in the world as many of you know. I spent way, way too long trying to create this slide because I kept trying to find better data on the split of who's using what operating systems for developers. It's pretty easy to find that Windows is still very heavily used if you work for a large company. They may hand you a laptop and enforce that you use a very specific image of Windows locked down in various ways. Mac has been growing in popularity for a long time now. A lot of developers use Macs, myself included at the moment. The problem is it's really hard to gauge how many people use Linux. If you look at the Stack Overflow developer surveys, you get numbers as high as 30 or 40% in the past few years, but the way they're asking the questions, it's hard to know if people are saying I'm developing in a Linux instance somewhere in the cloud or I'm actually running Linux on my laptop. And since we're in Brussels, if you're at dinner somewhere, it turns out someone might overhear your conversation at dinner and they're also at Fosdum, so someone point me at a new data source, JetBrains has a developer survey that they've been doing for a number of years and they had slightly different numbers. They had 60% for Windows and Mac and Linux were actually almost exactly the same at around 25 or 26% each. So regardless, we know that people are on various platforms and they're wanting to develop Linux containers. The easy solution is, hey, we have tons of virtualization options. I don't know, it looks like a lot of younger people here. When I was a developer and VMware came out, I was like, wow, this is magic. I'm like able to run this other operating system on my laptop, Parallels is out there, KVM, VirtualBox, Vagrant, all these options to be able to run a VM. And obviously that's one very simple solution to, I need to run Linux, but my physical thing that I have that my manager gave me or that my work provides can't run Linux, so I'll just run a VM. But this solution brings about some new problems because now I have another OS image to manage and it's got updates and maybe security issues. And so now I'm managing my laptop or my desktop and also this other OS. I have these VM boundary issues. So I'm on my host and I've checked out some source code, but it's not in my VM and I got to figure out this file sharing and figure out how to do networking. I want to run a container in the VM and I want to access it. And now I figure out how this works with the network. And there's also just my kind of developer workflow. There's some inhibitors, the fact that this thing's in a VM and I have a tool I want to run, but it's only on my host. And so again, this becomes potentially clunky to operate in these two worlds. Way back in the early days of Docker, one of the solutions that someone came up with was Docker Machine. It was this really nice simple way to sort of do this VM management on your behalf. You export your Docker host variable and point to the right place. And all of a sudden it seems like you're using Docker on the host and all the magic of the VM management is done for you. It was fairly simplistic and so over the years pieces of that are what became Docker desktop. This is a screen grab, I think, from one of the Windows versions. But again, 2016, 2017 and beyond for Mac and Windows, a more complete solution was developed. It also included a ton of other tools. So you didn't just have your runtime. Runtime you had Docker compose, you had image signing from Notary. You had a full Kubernetes cluster that you could access that was also being managed by this VM. So again, there were people sort of trying to make this easier for the developer who wasn't on Linux to develop their Linux containers that maybe they were going to deploy into a production environment that ran Linux somewhere in the cloud or in a data center. So this was great. It felt seamless to the developer. It felt like I was running my container commands locally. I'm doing Docker build, Docker run. The file and networking, people smarter than me had figured out the magic of all this pass-through that just seemed seamless and easy to use. And now there was bundling of these other tools, you know, relevant things that I needed to use were already there in the VM for me. Meanwhile, everyone wasn't using Docker. We had the ContainerD project, which I'm wearing my ContainerD t-shirt, but also a sweater so you can't see it. We have Podman. There's been some demos today that have used Podman. Red Hat was building their own suite of tools with Creo and Podman. And I don't know if we have any high-performance computing HPC folks in the room, but Singularity was gaining popularity now known as AppTainer. So again, there was these other technologies, other runtimes, other tools that people were using, and maybe Docker Desktop was really not meaningful to that group of people. And so over the years, other solutions for those other runtimes have been developed. And so obviously Podman Desktop is one of those. There was just a new release lately. I think it's been around for about a year, although pieces of how to run Podman on your Mac and Windows have existed maybe more than that, but the official Podman Desktop project has been around for about a year. You get Windows, Linux, and Mac OS support. And it has Kubernetes. It has a plugin system. They just recently developed a new DNS and networking service that is a little more amenable to desktop, laptop environments than using CNI plugins. And again, it's built around tools that have been in development for many years. Podman, Builda, Scopio, and the containers, libraries that these are built around. And again, because those things were built with certain features, like the rootless and unprivileged work, the demolus runtime with Podman and CRUN, you get all those same features, but now you can run it on your Mac or your Windows system if that's your local developer environment, and you get all the same capabilities if you were using Podman on a Linux system. So you get both all the Docker command line compatibility that Podman originally developed, but with Libpod, you also get the Docker API, which may be important for tools you're using that try and integrate directly with the Docker API. If you're not in that world, there's Lima, NerdCTL, and ContainerD as sort of a stack of projects. NerdCTL, similar to Podman, provides you that same Docker command line API with composed support. It uses QMU for virtualization, so this is the Lima component. That handles, again, the file sharing, the network pass-through via some additional projects that are part of that Lima scope. Again, this is all focused on macOS so far today. I think there's some discussions around Windows support and AkaHero is here and may be able to speak more to that than I can. One of the benefits of being built around ContainerD is that this stack can also expose experimental features like lazy loading snapshotters, image encryption, and other sort of sub-projects of ContainerD that are out there today. NerdCTL, as it's packaged by default, gives you rootless unprivileged mode, so if you run it through Lima, you're getting, again, rootless unprivileged containers running underneath that on Mac. A few projects that are built on top of that are Rancher Desktop and CoLima. Rancher Desktop, obviously many of you have heard of the Rancher suite of projects and products. They created a desktop platform that built on the Lima foundation for their macOS support. Both of these projects also found that some of their user base either needed the Docker API or had very specific ties to Docker. So you can get both of these projects, not just with ContainerD and NerdCTL, but also get the Docker engine. In fact, CoLima, if you install it by default, does install Docker. They both provide Kubernetes clusters. So again, if local development environments and Kubernetes, that combination is important to you. They both provide that. Rancher Desktop also adds Windows and Linux support in addition, and that's not using Lima underneath. So the last project I wanted to talk about came out of my team, AWS. This is a project we just launched in November last year. So just a few months ago, it's called Finch, and it builds on the same stack as Rancher Desktop and CoLima, where we're using Lima, NerdCTL, and BuildKit to provide that Docker command line, Docker build support, Docker compose support inside of VM on your Mac. And so there's Homebrew Packaging and Apple Sign Installer packages for that. It supports ARM64 and Intel. And also because of QMU and its capabilities, you can build containers. No matter what your host CPU is, you can build containers for Intel or ARM64. And again, the host CPU itself can be any of the either Apple Silicon, M1, M2, or the Intel-based Mac. So again, we're a young project. Our plans for an extension framework similar to Podman Desktop and Docker Desktop, so that we want that same model of you can add features and add capabilities without having to add them to the Finch project itself to extend it to other use cases. And we're also planning similar to Rancher Desktop for adding Windows and Linux support. Obviously, we're not really building a completely new tool. We're packaging most of these existing components. So we're working upstream. There's myself and a few other container demaintainers. We're working in Lima. We have a few pull requests merged in Lima. We had in the latest Nerd CTL release a few weeks ago, we had five different Amazon folks mentioned in the release notes. We're planning to add some features to BuildKit. And we also have several people working in the OCI specs, like the recent reference type work. So again, a lot of the work we do in Finch is really building out capabilities in these underlying projects, not so much building a brand new interface on top. And we want it to be a community open source project. So we're working on a public roadmap. Obviously, there's a GitHub repository here where you can go and see what we're doing, open to external contribution. And what we'd really love collaboration on is this added operating system support. Again, some of that work might be in Lima or elsewhere. But we'd love to add Windows and Linux support. And then understanding the best way to design this extension system that you can already use with other tools that I mentioned. We're also on the CNCF Slack in the channel Finch. So with that, that was a whirlwind tour through what's available for desktop tooling today with containers. And I think we have a few minutes for questions. APPLAUSE Yeah, any questions? Hi. What was the motivation to create Finch when there was already this whole ecosystem? If I think I understood the question, why create Finch when there was Rancher Desktop or Colema or Lima? Yeah, that's a good question. So each of those tools kind of has its own natural inclination. With Rancher Desktop, the focus was great local Kubernetes environment and a GUI and some management around it and including Docker. We wanted something simpler that's just the command line tool. And so we talked to the Rancher folks about maybe having a common upstream. Maybe Finch becomes that common upstream of Lima, container D, nerd CTL, build kit. So that might still be in the works. And then Colema is a very small project. There's one maintainer. He's kind of working on his own. And again, we were looking at, you know, he's got Docker in there. He's got Kubernetes. And we wanted to, again, focus just on the container interloop lifecycle, build containers, run containers, push containers to registries. And so essentially it's just a simplification that we think there's still lots of ability for collaboration with those other projects because we're all using the same stack below us. We have time for one more fairly quick question. How easy it is to pick up Finch for someone who's just started working as a developer? Yeah, how easy to use? What's the learning curve compared to Docker? Yeah, so again, most of these tools are built around the sort of understood Docker command line tool. So if you've already used Docker, like it's the same commands, the same flags. So in that sense, there's no real learning curve. Now, if you're just brand new to containers, it's really the same effort that you'd have to do to learn Docker or Podman or Finch or anything else. So it's really about your understanding of kind of the existing developer tooling space built around Docker. Okay, thank you. Please leave quietly when we are still asking questions. Other than that, thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.0, "text": " our next talk. I guess I don't have to give a big introduction. A lot of you know Phil,", "tokens": [527, 958, 751, 13, 286, 2041, 286, 500, 380, 362, 281, 976, 257, 955, 9339, 13, 316, 688, 295, 291, 458, 7777, 11], "temperature": 0.0, "avg_logprob": -0.3703509860568576, "compression_ratio": 1.2611940298507462, "no_speech_prob": 0.5013529062271118}, {"id": 1, "seek": 0, "start": 10.0, "end": 16.0, "text": " right? He's going to talk about Turing the container developer tooling landscape.", "tokens": [558, 30, 634, 311, 516, 281, 751, 466, 314, 1345, 264, 10129, 10754, 46593, 9661, 13], "temperature": 0.0, "avg_logprob": -0.3703509860568576, "compression_ratio": 1.2611940298507462, "no_speech_prob": 0.5013529062271118}, {"id": 2, "seek": 1600, "start": 16.0, "end": 33.0, "text": " All right. Hi everybody. I think I'm on. Yeah, you're on. Yeah, so thanks for coming.", "tokens": [1057, 558, 13, 2421, 2201, 13, 286, 519, 286, 478, 322, 13, 865, 11, 291, 434, 322, 13, 865, 11, 370, 3231, 337, 1348, 13], "temperature": 0.0, "avg_logprob": -0.21226256469200397, "compression_ratio": 1.326241134751773, "no_speech_prob": 0.0007657134556211531}, {"id": 3, "seek": 1600, "start": 33.0, "end": 40.0, "text": " It seems like Fossum is back. We've got a packed containers room. I think my talk is mostly a warm-up", "tokens": [467, 2544, 411, 479, 772, 449, 307, 646, 13, 492, 600, 658, 257, 13265, 17089, 1808, 13, 286, 519, 452, 751, 307, 5240, 257, 4561, 12, 1010], "temperature": 0.0, "avg_logprob": -0.21226256469200397, "compression_ratio": 1.326241134751773, "no_speech_prob": 0.0007657134556211531}, {"id": 4, "seek": 4000, "start": 40.0, "end": 50.0, "text": " for Akahiro after me. So a lot of familiar faces here. A lot of good talk so far. Maybe this will be a little bit different", "tokens": [337, 9629, 545, 5182, 934, 385, 13, 407, 257, 688, 295, 4963, 8475, 510, 13, 316, 688, 295, 665, 751, 370, 1400, 13, 2704, 341, 486, 312, 257, 707, 857, 819], "temperature": 0.0, "avg_logprob": -0.15213131648237987, "compression_ratio": 1.5588235294117647, "no_speech_prob": 3.586530510801822e-05}, {"id": 5, "seek": 4000, "start": 50.0, "end": 58.0, "text": " than the last few talks. We've been talking a lot about containers and various environments, but we haven't really talked", "tokens": [813, 264, 1036, 1326, 6686, 13, 492, 600, 668, 1417, 257, 688, 466, 17089, 293, 3683, 12388, 11, 457, 321, 2378, 380, 534, 2825], "temperature": 0.0, "avg_logprob": -0.15213131648237987, "compression_ratio": 1.5588235294117647, "no_speech_prob": 3.586530510801822e-05}, {"id": 6, "seek": 4000, "start": 58.0, "end": 66.0, "text": " about tools. You've seen a few tools used in some of the demos. And so I'm just going to talk through where we are these days", "tokens": [466, 3873, 13, 509, 600, 1612, 257, 1326, 3873, 1143, 294, 512, 295, 264, 33788, 13, 400, 370, 286, 478, 445, 516, 281, 751, 807, 689, 321, 366, 613, 1708], "temperature": 0.0, "avg_logprob": -0.15213131648237987, "compression_ratio": 1.5588235294117647, "no_speech_prob": 3.586530510801822e-05}, {"id": 7, "seek": 6600, "start": 66.0, "end": 76.0, "text": " with development tooling. Interesting that it's 2023 and interesting year in that we're now 10 years since Solomon", "tokens": [365, 3250, 46593, 13, 14711, 300, 309, 311, 44377, 293, 1880, 1064, 294, 300, 321, 434, 586, 1266, 924, 1670, 32209], "temperature": 0.0, "avg_logprob": -0.13335635445334695, "compression_ratio": 1.566820276497696, "no_speech_prob": 4.902714863419533e-05}, {"id": 8, "seek": 6600, "start": 76.0, "end": 83.0, "text": " Hikes gave this demo during a lightning talk at PyCon. I think it was like April. So getting pretty close to 10 years", "tokens": [389, 8916, 2729, 341, 10723, 1830, 257, 16589, 751, 412, 9953, 9838, 13, 286, 519, 309, 390, 411, 6929, 13, 407, 1242, 1238, 1998, 281, 1266, 924], "temperature": 0.0, "avg_logprob": -0.13335635445334695, "compression_ratio": 1.566820276497696, "no_speech_prob": 4.902714863419533e-05}, {"id": 9, "seek": 6600, "start": 83.0, "end": 91.0, "text": " since someone saw Docker being run at the command line for the first time. And what an interesting demo was", "tokens": [1670, 1580, 1866, 33772, 885, 1190, 412, 264, 5622, 1622, 337, 264, 700, 565, 13, 400, 437, 364, 1880, 10723, 390], "temperature": 0.0, "avg_logprob": -0.13335635445334695, "compression_ratio": 1.566820276497696, "no_speech_prob": 4.902714863419533e-05}, {"id": 10, "seek": 9100, "start": 91.0, "end": 99.0, "text": " because he misspelled Hello World and that's now permanently in the history of the Internet forever.", "tokens": [570, 415, 1713, 33000, 2425, 3937, 293, 300, 311, 586, 24042, 294, 264, 2503, 295, 264, 7703, 5680, 13], "temperature": 0.0, "avg_logprob": -0.11889621373769399, "compression_ratio": 1.5044642857142858, "no_speech_prob": 0.0001021737334667705}, {"id": 11, "seek": 9100, "start": 99.0, "end": 108.0, "text": " We've been using containers for a long time now. Apologies to those who are big Solaris fans or BSD, obviously containers", "tokens": [492, 600, 668, 1228, 17089, 337, 257, 938, 565, 586, 13, 8723, 6204, 281, 729, 567, 366, 955, 22385, 271, 4499, 420, 363, 23969, 11, 2745, 17089], "temperature": 0.0, "avg_logprob": -0.11889621373769399, "compression_ratio": 1.5044642857142858, "no_speech_prob": 0.0001021737334667705}, {"id": 12, "seek": 9100, "start": 108.0, "end": 118.0, "text": " and the technologies behind them existed in other operating systems before Docker. But essentially, at this point,", "tokens": [293, 264, 7943, 2261, 552, 13135, 294, 661, 7447, 3652, 949, 33772, 13, 583, 4476, 11, 412, 341, 935, 11], "temperature": 0.0, "avg_logprob": -0.11889621373769399, "compression_ratio": 1.5044642857142858, "no_speech_prob": 0.0001021737334667705}, {"id": 13, "seek": 11800, "start": 118.0, "end": 126.0, "text": " everything that's been demoed today has been on Linux. There was a great kind of intro in one of the earlier talks", "tokens": [1203, 300, 311, 668, 10723, 292, 965, 575, 668, 322, 18734, 13, 821, 390, 257, 869, 733, 295, 12897, 294, 472, 295, 264, 3071, 6686], "temperature": 0.0, "avg_logprob": -0.10018546160529641, "compression_ratio": 1.5746606334841629, "no_speech_prob": 2.7091975425719284e-05}, {"id": 14, "seek": 11800, "start": 126.0, "end": 135.0, "text": " about namespaces and C groups. This picture is old because people keep creating new namespaces. So it doesn't work anymore.", "tokens": [466, 5288, 79, 2116, 293, 383, 3935, 13, 639, 3036, 307, 1331, 570, 561, 1066, 4084, 777, 5288, 79, 2116, 13, 407, 309, 1177, 380, 589, 3602, 13], "temperature": 0.0, "avg_logprob": -0.10018546160529641, "compression_ratio": 1.5746606334841629, "no_speech_prob": 2.7091975425719284e-05}, {"id": 15, "seek": 11800, "start": 135.0, "end": 141.0, "text": " This was a cool image way back in the day because it was the perfect number to create like a flat packed box.", "tokens": [639, 390, 257, 1627, 3256, 636, 646, 294, 264, 786, 570, 309, 390, 264, 2176, 1230, 281, 1884, 411, 257, 4962, 13265, 2424, 13], "temperature": 0.0, "avg_logprob": -0.10018546160529641, "compression_ratio": 1.5746606334841629, "no_speech_prob": 2.7091975425719284e-05}, {"id": 16, "seek": 14100, "start": 141.0, "end": 148.0, "text": " So you create your box out of the namespaces and then you shape your box with C groups. What size do you want it to be?", "tokens": [407, 291, 1884, 428, 2424, 484, 295, 264, 5288, 79, 2116, 293, 550, 291, 3909, 428, 2424, 365, 383, 3935, 13, 708, 2744, 360, 291, 528, 309, 281, 312, 30], "temperature": 0.0, "avg_logprob": -0.05481369550838027, "compression_ratio": 1.5954545454545455, "no_speech_prob": 4.3289306631777436e-05}, {"id": 17, "seek": 14100, "start": 148.0, "end": 156.0, "text": " What limits do you want to place on that? And apologies to my friends at Microsoft again. There are containers on Windows", "tokens": [708, 10406, 360, 291, 528, 281, 1081, 322, 300, 30, 400, 34929, 281, 452, 1855, 412, 8116, 797, 13, 821, 366, 17089, 322, 8591], "temperature": 0.0, "avg_logprob": -0.05481369550838027, "compression_ratio": 1.5954545454545455, "no_speech_prob": 4.3289306631777436e-05}, {"id": 18, "seek": 14100, "start": 156.0, "end": 164.0, "text": " as well these days. But again, for the lion's share of use cases, these are the features and the technologies", "tokens": [382, 731, 613, 1708, 13, 583, 797, 11, 337, 264, 17226, 311, 2073, 295, 764, 3331, 11, 613, 366, 264, 4122, 293, 264, 7943], "temperature": 0.0, "avg_logprob": -0.05481369550838027, "compression_ratio": 1.5954545454545455, "no_speech_prob": 4.3289306631777436e-05}, {"id": 19, "seek": 16400, "start": 164.0, "end": 171.0, "text": " we've been using to create containers. But let's not forget there's other pieces to the puzzle, whether you're using Docker", "tokens": [321, 600, 668, 1228, 281, 1884, 17089, 13, 583, 718, 311, 406, 2870, 456, 311, 661, 3755, 281, 264, 12805, 11, 1968, 291, 434, 1228, 33772], "temperature": 0.0, "avg_logprob": -0.13653953870137533, "compression_ratio": 1.6415929203539823, "no_speech_prob": 5.733563011744991e-05}, {"id": 20, "seek": 16400, "start": 171.0, "end": 179.0, "text": " or some other runtime. There's SE Linux or App Armor in use. There's Setcom profiles. The images we've been constructing,", "tokens": [420, 512, 661, 34474, 13, 821, 311, 10269, 18734, 420, 3132, 44679, 294, 764, 13, 821, 311, 8928, 1112, 23693, 13, 440, 5267, 321, 600, 668, 39969, 11], "temperature": 0.0, "avg_logprob": -0.13653953870137533, "compression_ratio": 1.6415929203539823, "no_speech_prob": 5.733563011744991e-05}, {"id": 21, "seek": 16400, "start": 179.0, "end": 190.0, "text": " millions of them are constructed around Linux concepts, libraries, binaries that are basically Linux user space file systems.", "tokens": [6803, 295, 552, 366, 17083, 926, 18734, 10392, 11, 15148, 11, 5171, 4889, 300, 366, 1936, 18734, 4195, 1901, 3991, 3652, 13], "temperature": 0.0, "avg_logprob": -0.13653953870137533, "compression_ratio": 1.6415929203539823, "no_speech_prob": 5.733563011744991e-05}, {"id": 22, "seek": 19000, "start": 190.0, "end": 196.0, "text": " And then there's the Linux capabilities that we add or remove or default in our container runtimes.", "tokens": [400, 550, 456, 311, 264, 18734, 10862, 300, 321, 909, 420, 4159, 420, 7576, 294, 527, 10129, 49435, 1532, 13], "temperature": 0.0, "avg_logprob": -0.15361967647776884, "compression_ratio": 1.506276150627615, "no_speech_prob": 5.642723408527672e-05}, {"id": 23, "seek": 19000, "start": 196.0, "end": 204.0, "text": " So again, all these things are very Linux specific. And yet, you know, where are developers developing these containers?", "tokens": [407, 797, 11, 439, 613, 721, 366, 588, 18734, 2685, 13, 400, 1939, 11, 291, 458, 11, 689, 366, 8849, 6416, 613, 17089, 30], "temperature": 0.0, "avg_logprob": -0.15361967647776884, "compression_ratio": 1.506276150627615, "no_speech_prob": 5.642723408527672e-05}, {"id": 24, "seek": 19000, "start": 204.0, "end": 213.0, "text": " What tools are they using on what platforms? And I got a little nervous coming to FOSDOM because I thought, oh boy, everybody in this room,", "tokens": [708, 3873, 366, 436, 1228, 322, 437, 9473, 30, 400, 286, 658, 257, 707, 6296, 1348, 281, 479, 4367, 35, 5251, 570, 286, 1194, 11, 1954, 3237, 11, 2201, 294, 341, 1808, 11], "temperature": 0.0, "avg_logprob": -0.15361967647776884, "compression_ratio": 1.506276150627615, "no_speech_prob": 5.642723408527672e-05}, {"id": 25, "seek": 21300, "start": 213.0, "end": 222.0, "text": " there's Linux on the laptop actually is alive and well at FOSDOM, but not so much other places in the world as many of you know.", "tokens": [456, 311, 18734, 322, 264, 10732, 767, 307, 5465, 293, 731, 412, 479, 4367, 35, 5251, 11, 457, 406, 370, 709, 661, 3190, 294, 264, 1002, 382, 867, 295, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.06698607880136241, "compression_ratio": 1.5447154471544715, "no_speech_prob": 4.003326466772705e-05}, {"id": 26, "seek": 21300, "start": 222.0, "end": 231.0, "text": " I spent way, way too long trying to create this slide because I kept trying to find better data on the split of who's using", "tokens": [286, 4418, 636, 11, 636, 886, 938, 1382, 281, 1884, 341, 4137, 570, 286, 4305, 1382, 281, 915, 1101, 1412, 322, 264, 7472, 295, 567, 311, 1228], "temperature": 0.0, "avg_logprob": -0.06698607880136241, "compression_ratio": 1.5447154471544715, "no_speech_prob": 4.003326466772705e-05}, {"id": 27, "seek": 21300, "start": 231.0, "end": 240.0, "text": " what operating systems for developers. It's pretty easy to find that Windows is still very heavily used if you work for a large", "tokens": [437, 7447, 3652, 337, 8849, 13, 467, 311, 1238, 1858, 281, 915, 300, 8591, 307, 920, 588, 10950, 1143, 498, 291, 589, 337, 257, 2416], "temperature": 0.0, "avg_logprob": -0.06698607880136241, "compression_ratio": 1.5447154471544715, "no_speech_prob": 4.003326466772705e-05}, {"id": 28, "seek": 24000, "start": 240.0, "end": 249.0, "text": " company. They may hand you a laptop and enforce that you use a very specific image of Windows locked down in various ways.", "tokens": [2237, 13, 814, 815, 1011, 291, 257, 10732, 293, 24825, 300, 291, 764, 257, 588, 2685, 3256, 295, 8591, 9376, 760, 294, 3683, 2098, 13], "temperature": 0.0, "avg_logprob": -0.08834411396699793, "compression_ratio": 1.5, "no_speech_prob": 8.607881318312138e-05}, {"id": 29, "seek": 24000, "start": 249.0, "end": 257.0, "text": " Mac has been growing in popularity for a long time now. A lot of developers use Macs, myself included at the moment.", "tokens": [5707, 575, 668, 4194, 294, 19301, 337, 257, 938, 565, 586, 13, 316, 688, 295, 8849, 764, 5707, 82, 11, 2059, 5556, 412, 264, 1623, 13], "temperature": 0.0, "avg_logprob": -0.08834411396699793, "compression_ratio": 1.5, "no_speech_prob": 8.607881318312138e-05}, {"id": 30, "seek": 24000, "start": 257.0, "end": 265.0, "text": " The problem is it's really hard to gauge how many people use Linux. If you look at the Stack Overflow developer surveys,", "tokens": [440, 1154, 307, 309, 311, 534, 1152, 281, 17924, 577, 867, 561, 764, 18734, 13, 759, 291, 574, 412, 264, 37649, 4886, 10565, 10754, 22711, 11], "temperature": 0.0, "avg_logprob": -0.08834411396699793, "compression_ratio": 1.5, "no_speech_prob": 8.607881318312138e-05}, {"id": 31, "seek": 26500, "start": 265.0, "end": 272.0, "text": " you get numbers as high as 30 or 40% in the past few years, but the way they're asking the questions, it's hard to know if people are", "tokens": [291, 483, 3547, 382, 1090, 382, 2217, 420, 3356, 4, 294, 264, 1791, 1326, 924, 11, 457, 264, 636, 436, 434, 3365, 264, 1651, 11, 309, 311, 1152, 281, 458, 498, 561, 366], "temperature": 0.0, "avg_logprob": -0.08652968840165572, "compression_ratio": 1.564102564102564, "no_speech_prob": 6.810633203713223e-05}, {"id": 32, "seek": 26500, "start": 272.0, "end": 280.0, "text": " saying I'm developing in a Linux instance somewhere in the cloud or I'm actually running Linux on my laptop.", "tokens": [1566, 286, 478, 6416, 294, 257, 18734, 5197, 4079, 294, 264, 4588, 420, 286, 478, 767, 2614, 18734, 322, 452, 10732, 13], "temperature": 0.0, "avg_logprob": -0.08652968840165572, "compression_ratio": 1.564102564102564, "no_speech_prob": 6.810633203713223e-05}, {"id": 33, "seek": 26500, "start": 280.0, "end": 286.0, "text": " And since we're in Brussels, if you're at dinner somewhere, it turns out someone might overhear your conversation at dinner", "tokens": [400, 1670, 321, 434, 294, 38717, 11, 498, 291, 434, 412, 6148, 4079, 11, 309, 4523, 484, 1580, 1062, 29807, 289, 428, 3761, 412, 6148], "temperature": 0.0, "avg_logprob": -0.08652968840165572, "compression_ratio": 1.564102564102564, "no_speech_prob": 6.810633203713223e-05}, {"id": 34, "seek": 28600, "start": 286.0, "end": 295.0, "text": " and they're also at Fosdum, so someone point me at a new data source, JetBrains has a developer survey that they've been doing", "tokens": [293, 436, 434, 611, 412, 479, 329, 67, 449, 11, 370, 1580, 935, 385, 412, 257, 777, 1412, 4009, 11, 28730, 45606, 1292, 575, 257, 10754, 8984, 300, 436, 600, 668, 884], "temperature": 0.0, "avg_logprob": -0.15617417765187694, "compression_ratio": 1.5100401606425702, "no_speech_prob": 5.734704973292537e-05}, {"id": 35, "seek": 28600, "start": 295.0, "end": 304.0, "text": " for a number of years and they had slightly different numbers. They had 60% for Windows and Mac and Linux were actually almost", "tokens": [337, 257, 1230, 295, 924, 293, 436, 632, 4748, 819, 3547, 13, 814, 632, 4060, 4, 337, 8591, 293, 5707, 293, 18734, 645, 767, 1920], "temperature": 0.0, "avg_logprob": -0.15617417765187694, "compression_ratio": 1.5100401606425702, "no_speech_prob": 5.734704973292537e-05}, {"id": 36, "seek": 28600, "start": 304.0, "end": 315.0, "text": " exactly the same at around 25 or 26% each. So regardless, we know that people are on various platforms and they're wanting", "tokens": [2293, 264, 912, 412, 926, 3552, 420, 7551, 4, 1184, 13, 407, 10060, 11, 321, 458, 300, 561, 366, 322, 3683, 9473, 293, 436, 434, 7935], "temperature": 0.0, "avg_logprob": -0.15617417765187694, "compression_ratio": 1.5100401606425702, "no_speech_prob": 5.734704973292537e-05}, {"id": 37, "seek": 31500, "start": 315.0, "end": 325.0, "text": " to develop Linux containers. The easy solution is, hey, we have tons of virtualization options. I don't know,", "tokens": [281, 1499, 18734, 17089, 13, 440, 1858, 3827, 307, 11, 4177, 11, 321, 362, 9131, 295, 6374, 2144, 3956, 13, 286, 500, 380, 458, 11], "temperature": 0.0, "avg_logprob": -0.09948787689208985, "compression_ratio": 1.5066079295154184, "no_speech_prob": 0.00011219305451959372}, {"id": 38, "seek": 31500, "start": 325.0, "end": 332.0, "text": " it looks like a lot of younger people here. When I was a developer and VMware came out, I was like, wow, this is magic.", "tokens": [309, 1542, 411, 257, 688, 295, 7037, 561, 510, 13, 1133, 286, 390, 257, 10754, 293, 40146, 1361, 484, 11, 286, 390, 411, 11, 6076, 11, 341, 307, 5585, 13], "temperature": 0.0, "avg_logprob": -0.09948787689208985, "compression_ratio": 1.5066079295154184, "no_speech_prob": 0.00011219305451959372}, {"id": 39, "seek": 31500, "start": 332.0, "end": 340.0, "text": " I'm like able to run this other operating system on my laptop, Parallels is out there, KVM, VirtualBox, Vagrant,", "tokens": [286, 478, 411, 1075, 281, 1190, 341, 661, 7447, 1185, 322, 452, 10732, 11, 3457, 336, 1625, 307, 484, 456, 11, 591, 53, 44, 11, 23887, 34980, 11, 691, 559, 7541, 11], "temperature": 0.0, "avg_logprob": -0.09948787689208985, "compression_ratio": 1.5066079295154184, "no_speech_prob": 0.00011219305451959372}, {"id": 40, "seek": 34000, "start": 340.0, "end": 348.0, "text": " all these options to be able to run a VM. And obviously that's one very simple solution to, I need to run Linux,", "tokens": [439, 613, 3956, 281, 312, 1075, 281, 1190, 257, 18038, 13, 400, 2745, 300, 311, 472, 588, 2199, 3827, 281, 11, 286, 643, 281, 1190, 18734, 11], "temperature": 0.0, "avg_logprob": -0.08749749194616559, "compression_ratio": 1.6027397260273972, "no_speech_prob": 3.7026220525149256e-05}, {"id": 41, "seek": 34000, "start": 348.0, "end": 359.0, "text": " but my physical thing that I have that my manager gave me or that my work provides can't run Linux, so I'll just run a VM.", "tokens": [457, 452, 4001, 551, 300, 286, 362, 300, 452, 6598, 2729, 385, 420, 300, 452, 589, 6417, 393, 380, 1190, 18734, 11, 370, 286, 603, 445, 1190, 257, 18038, 13], "temperature": 0.0, "avg_logprob": -0.08749749194616559, "compression_ratio": 1.6027397260273972, "no_speech_prob": 3.7026220525149256e-05}, {"id": 42, "seek": 34000, "start": 359.0, "end": 367.0, "text": " But this solution brings about some new problems because now I have another OS image to manage and it's got updates", "tokens": [583, 341, 3827, 5607, 466, 512, 777, 2740, 570, 586, 286, 362, 1071, 12731, 3256, 281, 3067, 293, 309, 311, 658, 9205], "temperature": 0.0, "avg_logprob": -0.08749749194616559, "compression_ratio": 1.6027397260273972, "no_speech_prob": 3.7026220525149256e-05}, {"id": 43, "seek": 36700, "start": 367.0, "end": 375.0, "text": " and maybe security issues. And so now I'm managing my laptop or my desktop and also this other OS.", "tokens": [293, 1310, 3825, 2663, 13, 400, 370, 586, 286, 478, 11642, 452, 10732, 420, 452, 14502, 293, 611, 341, 661, 12731, 13], "temperature": 0.0, "avg_logprob": -0.0937044192583133, "compression_ratio": 1.7376425855513309, "no_speech_prob": 4.984204497304745e-05}, {"id": 44, "seek": 36700, "start": 375.0, "end": 383.0, "text": " I have these VM boundary issues. So I'm on my host and I've checked out some source code, but it's not in my VM", "tokens": [286, 362, 613, 18038, 12866, 2663, 13, 407, 286, 478, 322, 452, 3975, 293, 286, 600, 10033, 484, 512, 4009, 3089, 11, 457, 309, 311, 406, 294, 452, 18038], "temperature": 0.0, "avg_logprob": -0.0937044192583133, "compression_ratio": 1.7376425855513309, "no_speech_prob": 4.984204497304745e-05}, {"id": 45, "seek": 36700, "start": 383.0, "end": 389.0, "text": " and I got to figure out this file sharing and figure out how to do networking. I want to run a container in the VM", "tokens": [293, 286, 658, 281, 2573, 484, 341, 3991, 5414, 293, 2573, 484, 577, 281, 360, 17985, 13, 286, 528, 281, 1190, 257, 10129, 294, 264, 18038], "temperature": 0.0, "avg_logprob": -0.0937044192583133, "compression_ratio": 1.7376425855513309, "no_speech_prob": 4.984204497304745e-05}, {"id": 46, "seek": 36700, "start": 389.0, "end": 396.0, "text": " and I want to access it. And now I figure out how this works with the network. And there's also just my kind of developer workflow.", "tokens": [293, 286, 528, 281, 2105, 309, 13, 400, 586, 286, 2573, 484, 577, 341, 1985, 365, 264, 3209, 13, 400, 456, 311, 611, 445, 452, 733, 295, 10754, 20993, 13], "temperature": 0.0, "avg_logprob": -0.0937044192583133, "compression_ratio": 1.7376425855513309, "no_speech_prob": 4.984204497304745e-05}, {"id": 47, "seek": 39600, "start": 396.0, "end": 403.0, "text": " There's some inhibitors, the fact that this thing's in a VM and I have a tool I want to run, but it's only on my host.", "tokens": [821, 311, 512, 20406, 9862, 11, 264, 1186, 300, 341, 551, 311, 294, 257, 18038, 293, 286, 362, 257, 2290, 286, 528, 281, 1190, 11, 457, 309, 311, 787, 322, 452, 3975, 13], "temperature": 0.0, "avg_logprob": -0.09082042809688684, "compression_ratio": 1.565040650406504, "no_speech_prob": 6.009522621752694e-05}, {"id": 48, "seek": 39600, "start": 403.0, "end": 409.0, "text": " And so again, this becomes potentially clunky to operate in these two worlds.", "tokens": [400, 370, 797, 11, 341, 3643, 7263, 596, 25837, 281, 9651, 294, 613, 732, 13401, 13], "temperature": 0.0, "avg_logprob": -0.09082042809688684, "compression_ratio": 1.565040650406504, "no_speech_prob": 6.009522621752694e-05}, {"id": 49, "seek": 39600, "start": 409.0, "end": 417.0, "text": " Way back in the early days of Docker, one of the solutions that someone came up with was Docker Machine.", "tokens": [9558, 646, 294, 264, 2440, 1708, 295, 33772, 11, 472, 295, 264, 6547, 300, 1580, 1361, 493, 365, 390, 33772, 22155, 13], "temperature": 0.0, "avg_logprob": -0.09082042809688684, "compression_ratio": 1.565040650406504, "no_speech_prob": 6.009522621752694e-05}, {"id": 50, "seek": 39600, "start": 417.0, "end": 422.0, "text": " It was this really nice simple way to sort of do this VM management on your behalf.", "tokens": [467, 390, 341, 534, 1481, 2199, 636, 281, 1333, 295, 360, 341, 18038, 4592, 322, 428, 9490, 13], "temperature": 0.0, "avg_logprob": -0.09082042809688684, "compression_ratio": 1.565040650406504, "no_speech_prob": 6.009522621752694e-05}, {"id": 51, "seek": 42200, "start": 422.0, "end": 426.0, "text": " You export your Docker host variable and point to the right place.", "tokens": [509, 10725, 428, 33772, 3975, 7006, 293, 935, 281, 264, 558, 1081, 13], "temperature": 0.0, "avg_logprob": -0.08896382275749655, "compression_ratio": 1.5263157894736843, "no_speech_prob": 3.1675717764301226e-05}, {"id": 52, "seek": 42200, "start": 426.0, "end": 434.0, "text": " And all of a sudden it seems like you're using Docker on the host and all the magic of the VM management is done for you.", "tokens": [400, 439, 295, 257, 3990, 309, 2544, 411, 291, 434, 1228, 33772, 322, 264, 3975, 293, 439, 264, 5585, 295, 264, 18038, 4592, 307, 1096, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.08896382275749655, "compression_ratio": 1.5263157894736843, "no_speech_prob": 3.1675717764301226e-05}, {"id": 53, "seek": 42200, "start": 434.0, "end": 441.0, "text": " It was fairly simplistic and so over the years pieces of that are what became Docker desktop.", "tokens": [467, 390, 6457, 44199, 293, 370, 670, 264, 924, 3755, 295, 300, 366, 437, 3062, 33772, 14502, 13], "temperature": 0.0, "avg_logprob": -0.08896382275749655, "compression_ratio": 1.5263157894736843, "no_speech_prob": 3.1675717764301226e-05}, {"id": 54, "seek": 42200, "start": 441.0, "end": 446.0, "text": " This is a screen grab, I think, from one of the Windows versions.", "tokens": [639, 307, 257, 2568, 4444, 11, 286, 519, 11, 490, 472, 295, 264, 8591, 9606, 13], "temperature": 0.0, "avg_logprob": -0.08896382275749655, "compression_ratio": 1.5263157894736843, "no_speech_prob": 3.1675717764301226e-05}, {"id": 55, "seek": 44600, "start": 446.0, "end": 455.0, "text": " But again, 2016, 2017 and beyond for Mac and Windows, a more complete solution was developed.", "tokens": [583, 797, 11, 6549, 11, 6591, 293, 4399, 337, 5707, 293, 8591, 11, 257, 544, 3566, 3827, 390, 4743, 13], "temperature": 0.0, "avg_logprob": -0.11289032396063747, "compression_ratio": 1.4478260869565218, "no_speech_prob": 2.391149064351339e-05}, {"id": 56, "seek": 44600, "start": 455.0, "end": 459.0, "text": " It also included a ton of other tools. So you didn't just have your runtime.", "tokens": [467, 611, 5556, 257, 2952, 295, 661, 3873, 13, 407, 291, 994, 380, 445, 362, 428, 34474, 13], "temperature": 0.0, "avg_logprob": -0.11289032396063747, "compression_ratio": 1.4478260869565218, "no_speech_prob": 2.391149064351339e-05}, {"id": 57, "seek": 44600, "start": 459.0, "end": 464.0, "text": " Runtime you had Docker compose, you had image signing from Notary.", "tokens": [497, 2760, 1312, 291, 632, 33772, 35925, 11, 291, 632, 3256, 13393, 490, 1726, 822, 13], "temperature": 0.0, "avg_logprob": -0.11289032396063747, "compression_ratio": 1.4478260869565218, "no_speech_prob": 2.391149064351339e-05}, {"id": 58, "seek": 44600, "start": 464.0, "end": 470.0, "text": " You had a full Kubernetes cluster that you could access that was also being managed by this VM.", "tokens": [509, 632, 257, 1577, 23145, 13630, 300, 291, 727, 2105, 300, 390, 611, 885, 6453, 538, 341, 18038, 13], "temperature": 0.0, "avg_logprob": -0.11289032396063747, "compression_ratio": 1.4478260869565218, "no_speech_prob": 2.391149064351339e-05}, {"id": 59, "seek": 47000, "start": 470.0, "end": 476.0, "text": " So again, there were people sort of trying to make this easier for the developer who wasn't on Linux", "tokens": [407, 797, 11, 456, 645, 561, 1333, 295, 1382, 281, 652, 341, 3571, 337, 264, 10754, 567, 2067, 380, 322, 18734], "temperature": 0.0, "avg_logprob": -0.06023631989955902, "compression_ratio": 1.7, "no_speech_prob": 2.1435183953144588e-05}, {"id": 60, "seek": 47000, "start": 476.0, "end": 482.0, "text": " to develop their Linux containers that maybe they were going to deploy into a production environment", "tokens": [281, 1499, 641, 18734, 17089, 300, 1310, 436, 645, 516, 281, 7274, 666, 257, 4265, 2823], "temperature": 0.0, "avg_logprob": -0.06023631989955902, "compression_ratio": 1.7, "no_speech_prob": 2.1435183953144588e-05}, {"id": 61, "seek": 47000, "start": 482.0, "end": 486.0, "text": " that ran Linux somewhere in the cloud or in a data center.", "tokens": [300, 5872, 18734, 4079, 294, 264, 4588, 420, 294, 257, 1412, 3056, 13], "temperature": 0.0, "avg_logprob": -0.06023631989955902, "compression_ratio": 1.7, "no_speech_prob": 2.1435183953144588e-05}, {"id": 62, "seek": 47000, "start": 486.0, "end": 490.0, "text": " So this was great. It felt seamless to the developer.", "tokens": [407, 341, 390, 869, 13, 467, 2762, 28677, 281, 264, 10754, 13], "temperature": 0.0, "avg_logprob": -0.06023631989955902, "compression_ratio": 1.7, "no_speech_prob": 2.1435183953144588e-05}, {"id": 63, "seek": 47000, "start": 490.0, "end": 493.0, "text": " It felt like I was running my container commands locally.", "tokens": [467, 2762, 411, 286, 390, 2614, 452, 10129, 16901, 16143, 13], "temperature": 0.0, "avg_logprob": -0.06023631989955902, "compression_ratio": 1.7, "no_speech_prob": 2.1435183953144588e-05}, {"id": 64, "seek": 47000, "start": 493.0, "end": 496.0, "text": " I'm doing Docker build, Docker run.", "tokens": [286, 478, 884, 33772, 1322, 11, 33772, 1190, 13], "temperature": 0.0, "avg_logprob": -0.06023631989955902, "compression_ratio": 1.7, "no_speech_prob": 2.1435183953144588e-05}, {"id": 65, "seek": 49600, "start": 496.0, "end": 501.0, "text": " The file and networking, people smarter than me had figured out the magic of all this pass-through", "tokens": [440, 3991, 293, 17985, 11, 561, 20294, 813, 385, 632, 8932, 484, 264, 5585, 295, 439, 341, 1320, 12, 11529], "temperature": 0.0, "avg_logprob": -0.11587510250582553, "compression_ratio": 1.560483870967742, "no_speech_prob": 3.217492121621035e-05}, {"id": 66, "seek": 49600, "start": 501.0, "end": 505.0, "text": " that just seemed seamless and easy to use.", "tokens": [300, 445, 6576, 28677, 293, 1858, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.11587510250582553, "compression_ratio": 1.560483870967742, "no_speech_prob": 3.217492121621035e-05}, {"id": 67, "seek": 49600, "start": 505.0, "end": 510.0, "text": " And now there was bundling of these other tools, you know, relevant things that I needed to use", "tokens": [400, 586, 456, 390, 13882, 1688, 295, 613, 661, 3873, 11, 291, 458, 11, 7340, 721, 300, 286, 2978, 281, 764], "temperature": 0.0, "avg_logprob": -0.11587510250582553, "compression_ratio": 1.560483870967742, "no_speech_prob": 3.217492121621035e-05}, {"id": 68, "seek": 49600, "start": 510.0, "end": 514.0, "text": " were already there in the VM for me.", "tokens": [645, 1217, 456, 294, 264, 18038, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.11587510250582553, "compression_ratio": 1.560483870967742, "no_speech_prob": 3.217492121621035e-05}, {"id": 69, "seek": 49600, "start": 514.0, "end": 518.0, "text": " Meanwhile, everyone wasn't using Docker.", "tokens": [13879, 11, 1518, 2067, 380, 1228, 33772, 13], "temperature": 0.0, "avg_logprob": -0.11587510250582553, "compression_ratio": 1.560483870967742, "no_speech_prob": 3.217492121621035e-05}, {"id": 70, "seek": 49600, "start": 518.0, "end": 523.0, "text": " We had the ContainerD project, which I'm wearing my ContainerD t-shirt,", "tokens": [492, 632, 264, 43732, 260, 35, 1716, 11, 597, 286, 478, 4769, 452, 43732, 260, 35, 256, 12, 15313, 11], "temperature": 0.0, "avg_logprob": -0.11587510250582553, "compression_ratio": 1.560483870967742, "no_speech_prob": 3.217492121621035e-05}, {"id": 71, "seek": 52300, "start": 523.0, "end": 526.0, "text": " but also a sweater so you can't see it.", "tokens": [457, 611, 257, 26550, 370, 291, 393, 380, 536, 309, 13], "temperature": 0.0, "avg_logprob": -0.08465577023369926, "compression_ratio": 1.624031007751938, "no_speech_prob": 6.499022856587544e-05}, {"id": 72, "seek": 52300, "start": 526.0, "end": 530.0, "text": " We have Podman. There's been some demos today that have used Podman.", "tokens": [492, 362, 12646, 1601, 13, 821, 311, 668, 512, 33788, 965, 300, 362, 1143, 12646, 1601, 13], "temperature": 0.0, "avg_logprob": -0.08465577023369926, "compression_ratio": 1.624031007751938, "no_speech_prob": 6.499022856587544e-05}, {"id": 73, "seek": 52300, "start": 530.0, "end": 535.0, "text": " Red Hat was building their own suite of tools with Creo and Podman.", "tokens": [4477, 15867, 390, 2390, 641, 1065, 14205, 295, 3873, 365, 40640, 293, 12646, 1601, 13], "temperature": 0.0, "avg_logprob": -0.08465577023369926, "compression_ratio": 1.624031007751938, "no_speech_prob": 6.499022856587544e-05}, {"id": 74, "seek": 52300, "start": 535.0, "end": 539.0, "text": " And I don't know if we have any high-performance computing HPC folks in the room,", "tokens": [400, 286, 500, 380, 458, 498, 321, 362, 604, 1090, 12, 50242, 15866, 12557, 34, 4024, 294, 264, 1808, 11], "temperature": 0.0, "avg_logprob": -0.08465577023369926, "compression_ratio": 1.624031007751938, "no_speech_prob": 6.499022856587544e-05}, {"id": 75, "seek": 52300, "start": 539.0, "end": 544.0, "text": " but Singularity was gaining popularity now known as AppTainer.", "tokens": [457, 7474, 1040, 507, 390, 19752, 19301, 586, 2570, 382, 3132, 51, 491, 260, 13], "temperature": 0.0, "avg_logprob": -0.08465577023369926, "compression_ratio": 1.624031007751938, "no_speech_prob": 6.499022856587544e-05}, {"id": 76, "seek": 52300, "start": 544.0, "end": 550.0, "text": " So again, there was these other technologies, other runtimes, other tools that people were using,", "tokens": [407, 797, 11, 456, 390, 613, 661, 7943, 11, 661, 49435, 1532, 11, 661, 3873, 300, 561, 645, 1228, 11], "temperature": 0.0, "avg_logprob": -0.08465577023369926, "compression_ratio": 1.624031007751938, "no_speech_prob": 6.499022856587544e-05}, {"id": 77, "seek": 55000, "start": 550.0, "end": 556.0, "text": " and maybe Docker Desktop was really not meaningful to that group of people.", "tokens": [293, 1310, 33772, 49044, 390, 534, 406, 10995, 281, 300, 1594, 295, 561, 13], "temperature": 0.0, "avg_logprob": -0.06693907578786214, "compression_ratio": 1.5294117647058822, "no_speech_prob": 5.303356010699645e-05}, {"id": 78, "seek": 55000, "start": 556.0, "end": 564.0, "text": " And so over the years, other solutions for those other runtimes have been developed.", "tokens": [400, 370, 670, 264, 924, 11, 661, 6547, 337, 729, 661, 49435, 1532, 362, 668, 4743, 13], "temperature": 0.0, "avg_logprob": -0.06693907578786214, "compression_ratio": 1.5294117647058822, "no_speech_prob": 5.303356010699645e-05}, {"id": 79, "seek": 55000, "start": 564.0, "end": 568.0, "text": " And so obviously Podman Desktop is one of those.", "tokens": [400, 370, 2745, 12646, 1601, 49044, 307, 472, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.06693907578786214, "compression_ratio": 1.5294117647058822, "no_speech_prob": 5.303356010699645e-05}, {"id": 80, "seek": 55000, "start": 568.0, "end": 570.0, "text": " There was just a new release lately.", "tokens": [821, 390, 445, 257, 777, 4374, 12881, 13], "temperature": 0.0, "avg_logprob": -0.06693907578786214, "compression_ratio": 1.5294117647058822, "no_speech_prob": 5.303356010699645e-05}, {"id": 81, "seek": 55000, "start": 570.0, "end": 576.0, "text": " I think it's been around for about a year, although pieces of how to run Podman on your Mac", "tokens": [286, 519, 309, 311, 668, 926, 337, 466, 257, 1064, 11, 4878, 3755, 295, 577, 281, 1190, 12646, 1601, 322, 428, 5707], "temperature": 0.0, "avg_logprob": -0.06693907578786214, "compression_ratio": 1.5294117647058822, "no_speech_prob": 5.303356010699645e-05}, {"id": 82, "seek": 57600, "start": 576.0, "end": 583.0, "text": " and Windows have existed maybe more than that, but the official Podman Desktop project", "tokens": [293, 8591, 362, 13135, 1310, 544, 813, 300, 11, 457, 264, 4783, 12646, 1601, 49044, 1716], "temperature": 0.0, "avg_logprob": -0.14270124202821313, "compression_ratio": 1.44206008583691, "no_speech_prob": 2.5849334633676335e-05}, {"id": 83, "seek": 57600, "start": 583.0, "end": 585.0, "text": " has been around for about a year.", "tokens": [575, 668, 926, 337, 466, 257, 1064, 13], "temperature": 0.0, "avg_logprob": -0.14270124202821313, "compression_ratio": 1.44206008583691, "no_speech_prob": 2.5849334633676335e-05}, {"id": 84, "seek": 57600, "start": 585.0, "end": 589.0, "text": " You get Windows, Linux, and Mac OS support.", "tokens": [509, 483, 8591, 11, 18734, 11, 293, 5707, 12731, 1406, 13], "temperature": 0.0, "avg_logprob": -0.14270124202821313, "compression_ratio": 1.44206008583691, "no_speech_prob": 2.5849334633676335e-05}, {"id": 85, "seek": 57600, "start": 589.0, "end": 595.0, "text": " And it has Kubernetes. It has a plugin system.", "tokens": [400, 309, 575, 23145, 13, 467, 575, 257, 23407, 1185, 13], "temperature": 0.0, "avg_logprob": -0.14270124202821313, "compression_ratio": 1.44206008583691, "no_speech_prob": 2.5849334633676335e-05}, {"id": 86, "seek": 57600, "start": 595.0, "end": 599.0, "text": " They just recently developed a new DNS and networking service", "tokens": [814, 445, 3938, 4743, 257, 777, 35153, 293, 17985, 2643], "temperature": 0.0, "avg_logprob": -0.14270124202821313, "compression_ratio": 1.44206008583691, "no_speech_prob": 2.5849334633676335e-05}, {"id": 87, "seek": 57600, "start": 599.0, "end": 603.0, "text": " that is a little more amenable to desktop, laptop environments", "tokens": [300, 307, 257, 707, 544, 18497, 712, 281, 14502, 11, 10732, 12388], "temperature": 0.0, "avg_logprob": -0.14270124202821313, "compression_ratio": 1.44206008583691, "no_speech_prob": 2.5849334633676335e-05}, {"id": 88, "seek": 60300, "start": 603.0, "end": 606.0, "text": " than using CNI plugins.", "tokens": [813, 1228, 14589, 40, 33759, 13], "temperature": 0.0, "avg_logprob": -0.13462086905420353, "compression_ratio": 1.6297709923664123, "no_speech_prob": 5.30472825630568e-05}, {"id": 89, "seek": 60300, "start": 606.0, "end": 610.0, "text": " And again, it's built around tools that have been in development for many years.", "tokens": [400, 797, 11, 309, 311, 3094, 926, 3873, 300, 362, 668, 294, 3250, 337, 867, 924, 13], "temperature": 0.0, "avg_logprob": -0.13462086905420353, "compression_ratio": 1.6297709923664123, "no_speech_prob": 5.30472825630568e-05}, {"id": 90, "seek": 60300, "start": 610.0, "end": 617.0, "text": " Podman, Builda, Scopio, and the containers, libraries that these are built around.", "tokens": [12646, 1601, 11, 11875, 64, 11, 2747, 404, 1004, 11, 293, 264, 17089, 11, 15148, 300, 613, 366, 3094, 926, 13], "temperature": 0.0, "avg_logprob": -0.13462086905420353, "compression_ratio": 1.6297709923664123, "no_speech_prob": 5.30472825630568e-05}, {"id": 91, "seek": 60300, "start": 617.0, "end": 620.0, "text": " And again, because those things were built with certain features,", "tokens": [400, 797, 11, 570, 729, 721, 645, 3094, 365, 1629, 4122, 11], "temperature": 0.0, "avg_logprob": -0.13462086905420353, "compression_ratio": 1.6297709923664123, "no_speech_prob": 5.30472825630568e-05}, {"id": 92, "seek": 60300, "start": 620.0, "end": 627.0, "text": " like the rootless and unprivileged work, the demolus runtime with Podman and CRUN,", "tokens": [411, 264, 5593, 1832, 293, 20994, 29994, 794, 3004, 589, 11, 264, 1371, 401, 301, 34474, 365, 12646, 1601, 293, 14123, 3979, 11], "temperature": 0.0, "avg_logprob": -0.13462086905420353, "compression_ratio": 1.6297709923664123, "no_speech_prob": 5.30472825630568e-05}, {"id": 93, "seek": 60300, "start": 627.0, "end": 632.0, "text": " you get all those same features, but now you can run it on your Mac or your Windows system", "tokens": [291, 483, 439, 729, 912, 4122, 11, 457, 586, 291, 393, 1190, 309, 322, 428, 5707, 420, 428, 8591, 1185], "temperature": 0.0, "avg_logprob": -0.13462086905420353, "compression_ratio": 1.6297709923664123, "no_speech_prob": 5.30472825630568e-05}, {"id": 94, "seek": 63200, "start": 632.0, "end": 636.0, "text": " if that's your local developer environment, and you get all the same capabilities", "tokens": [498, 300, 311, 428, 2654, 10754, 2823, 11, 293, 291, 483, 439, 264, 912, 10862], "temperature": 0.0, "avg_logprob": -0.11320772732005399, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.825297557748854e-05}, {"id": 95, "seek": 63200, "start": 636.0, "end": 640.0, "text": " if you were using Podman on a Linux system.", "tokens": [498, 291, 645, 1228, 12646, 1601, 322, 257, 18734, 1185, 13], "temperature": 0.0, "avg_logprob": -0.11320772732005399, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.825297557748854e-05}, {"id": 96, "seek": 63200, "start": 640.0, "end": 646.0, "text": " So you get both all the Docker command line compatibility that Podman originally developed,", "tokens": [407, 291, 483, 1293, 439, 264, 33772, 5622, 1622, 34237, 300, 12646, 1601, 7993, 4743, 11], "temperature": 0.0, "avg_logprob": -0.11320772732005399, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.825297557748854e-05}, {"id": 97, "seek": 63200, "start": 646.0, "end": 651.0, "text": " but with Libpod, you also get the Docker API, which may be important for tools you're using", "tokens": [457, 365, 15834, 43388, 11, 291, 611, 483, 264, 33772, 9362, 11, 597, 815, 312, 1021, 337, 3873, 291, 434, 1228], "temperature": 0.0, "avg_logprob": -0.11320772732005399, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.825297557748854e-05}, {"id": 98, "seek": 63200, "start": 651.0, "end": 656.0, "text": " that try and integrate directly with the Docker API.", "tokens": [300, 853, 293, 13365, 3838, 365, 264, 33772, 9362, 13], "temperature": 0.0, "avg_logprob": -0.11320772732005399, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.825297557748854e-05}, {"id": 99, "seek": 65600, "start": 656.0, "end": 665.0, "text": " If you're not in that world, there's Lima, NerdCTL, and ContainerD as sort of a stack of projects.", "tokens": [759, 291, 434, 406, 294, 300, 1002, 11, 456, 311, 50217, 11, 38367, 10259, 43, 11, 293, 43732, 260, 35, 382, 1333, 295, 257, 8630, 295, 4455, 13], "temperature": 0.0, "avg_logprob": -0.09838633994533591, "compression_ratio": 1.3703703703703705, "no_speech_prob": 4.0039543819148093e-05}, {"id": 100, "seek": 65600, "start": 665.0, "end": 674.0, "text": " NerdCTL, similar to Podman, provides you that same Docker command line API with composed support.", "tokens": [38367, 10259, 43, 11, 2531, 281, 12646, 1601, 11, 6417, 291, 300, 912, 33772, 5622, 1622, 9362, 365, 18204, 1406, 13], "temperature": 0.0, "avg_logprob": -0.09838633994533591, "compression_ratio": 1.3703703703703705, "no_speech_prob": 4.0039543819148093e-05}, {"id": 101, "seek": 65600, "start": 674.0, "end": 680.0, "text": " It uses QMU for virtualization, so this is the Lima component.", "tokens": [467, 4960, 1249, 44, 52, 337, 6374, 2144, 11, 370, 341, 307, 264, 50217, 6542, 13], "temperature": 0.0, "avg_logprob": -0.09838633994533591, "compression_ratio": 1.3703703703703705, "no_speech_prob": 4.0039543819148093e-05}, {"id": 102, "seek": 68000, "start": 680.0, "end": 686.0, "text": " That handles, again, the file sharing, the network pass-through via some additional projects", "tokens": [663, 18722, 11, 797, 11, 264, 3991, 5414, 11, 264, 3209, 1320, 12, 11529, 5766, 512, 4497, 4455], "temperature": 0.0, "avg_logprob": -0.10432621002197266, "compression_ratio": 1.541501976284585, "no_speech_prob": 4.904749584966339e-05}, {"id": 103, "seek": 68000, "start": 686.0, "end": 689.0, "text": " that are part of that Lima scope.", "tokens": [300, 366, 644, 295, 300, 50217, 11923, 13], "temperature": 0.0, "avg_logprob": -0.10432621002197266, "compression_ratio": 1.541501976284585, "no_speech_prob": 4.904749584966339e-05}, {"id": 104, "seek": 68000, "start": 689.0, "end": 693.0, "text": " Again, this is all focused on macOS so far today.", "tokens": [3764, 11, 341, 307, 439, 5178, 322, 7912, 4367, 370, 1400, 965, 13], "temperature": 0.0, "avg_logprob": -0.10432621002197266, "compression_ratio": 1.541501976284585, "no_speech_prob": 4.904749584966339e-05}, {"id": 105, "seek": 68000, "start": 693.0, "end": 697.0, "text": " I think there's some discussions around Windows support and AkaHero is here", "tokens": [286, 519, 456, 311, 512, 11088, 926, 8591, 1406, 293, 316, 2330, 39, 2032, 307, 510], "temperature": 0.0, "avg_logprob": -0.10432621002197266, "compression_ratio": 1.541501976284585, "no_speech_prob": 4.904749584966339e-05}, {"id": 106, "seek": 68000, "start": 697.0, "end": 701.0, "text": " and may be able to speak more to that than I can.", "tokens": [293, 815, 312, 1075, 281, 1710, 544, 281, 300, 813, 286, 393, 13], "temperature": 0.0, "avg_logprob": -0.10432621002197266, "compression_ratio": 1.541501976284585, "no_speech_prob": 4.904749584966339e-05}, {"id": 107, "seek": 68000, "start": 701.0, "end": 706.0, "text": " One of the benefits of being built around ContainerD is that this stack can also expose", "tokens": [1485, 295, 264, 5311, 295, 885, 3094, 926, 43732, 260, 35, 307, 300, 341, 8630, 393, 611, 19219], "temperature": 0.0, "avg_logprob": -0.10432621002197266, "compression_ratio": 1.541501976284585, "no_speech_prob": 4.904749584966339e-05}, {"id": 108, "seek": 70600, "start": 706.0, "end": 711.0, "text": " experimental features like lazy loading snapshotters, image encryption,", "tokens": [17069, 4122, 411, 14847, 15114, 30163, 1559, 11, 3256, 29575, 11], "temperature": 0.0, "avg_logprob": -0.082108826107449, "compression_ratio": 1.5248868778280542, "no_speech_prob": 4.0045757486950606e-05}, {"id": 109, "seek": 70600, "start": 711.0, "end": 716.0, "text": " and other sort of sub-projects of ContainerD that are out there today.", "tokens": [293, 661, 1333, 295, 1422, 12, 4318, 1020, 82, 295, 43732, 260, 35, 300, 366, 484, 456, 965, 13], "temperature": 0.0, "avg_logprob": -0.082108826107449, "compression_ratio": 1.5248868778280542, "no_speech_prob": 4.0045757486950606e-05}, {"id": 110, "seek": 70600, "start": 716.0, "end": 722.0, "text": " NerdCTL, as it's packaged by default, gives you rootless unprivileged mode,", "tokens": [38367, 10259, 43, 11, 382, 309, 311, 38162, 538, 7576, 11, 2709, 291, 5593, 1832, 20994, 29994, 794, 3004, 4391, 11], "temperature": 0.0, "avg_logprob": -0.082108826107449, "compression_ratio": 1.5248868778280542, "no_speech_prob": 4.0045757486950606e-05}, {"id": 111, "seek": 70600, "start": 722.0, "end": 727.0, "text": " so if you run it through Lima, you're getting, again, rootless unprivileged containers", "tokens": [370, 498, 291, 1190, 309, 807, 50217, 11, 291, 434, 1242, 11, 797, 11, 5593, 1832, 20994, 29994, 794, 3004, 17089], "temperature": 0.0, "avg_logprob": -0.082108826107449, "compression_ratio": 1.5248868778280542, "no_speech_prob": 4.0045757486950606e-05}, {"id": 112, "seek": 70600, "start": 727.0, "end": 730.0, "text": " running underneath that on Mac.", "tokens": [2614, 7223, 300, 322, 5707, 13], "temperature": 0.0, "avg_logprob": -0.082108826107449, "compression_ratio": 1.5248868778280542, "no_speech_prob": 4.0045757486950606e-05}, {"id": 113, "seek": 73000, "start": 730.0, "end": 736.0, "text": " A few projects that are built on top of that are Rancher Desktop and CoLima.", "tokens": [316, 1326, 4455, 300, 366, 3094, 322, 1192, 295, 300, 366, 37740, 260, 49044, 293, 3066, 43, 4775, 13], "temperature": 0.0, "avg_logprob": -0.08082382937511766, "compression_ratio": 1.7033492822966507, "no_speech_prob": 2.3537340894108638e-05}, {"id": 114, "seek": 73000, "start": 736.0, "end": 743.0, "text": " Rancher Desktop, obviously many of you have heard of the Rancher suite of projects and products.", "tokens": [37740, 260, 49044, 11, 2745, 867, 295, 291, 362, 2198, 295, 264, 37740, 260, 14205, 295, 4455, 293, 3383, 13], "temperature": 0.0, "avg_logprob": -0.08082382937511766, "compression_ratio": 1.7033492822966507, "no_speech_prob": 2.3537340894108638e-05}, {"id": 115, "seek": 73000, "start": 743.0, "end": 752.0, "text": " They created a desktop platform that built on the Lima foundation for their macOS support.", "tokens": [814, 2942, 257, 14502, 3663, 300, 3094, 322, 264, 50217, 7030, 337, 641, 7912, 4367, 1406, 13], "temperature": 0.0, "avg_logprob": -0.08082382937511766, "compression_ratio": 1.7033492822966507, "no_speech_prob": 2.3537340894108638e-05}, {"id": 116, "seek": 73000, "start": 752.0, "end": 759.0, "text": " Both of these projects also found that some of their user base either needed the Docker API", "tokens": [6767, 295, 613, 4455, 611, 1352, 300, 512, 295, 641, 4195, 3096, 2139, 2978, 264, 33772, 9362], "temperature": 0.0, "avg_logprob": -0.08082382937511766, "compression_ratio": 1.7033492822966507, "no_speech_prob": 2.3537340894108638e-05}, {"id": 117, "seek": 75900, "start": 759.0, "end": 761.0, "text": " or had very specific ties to Docker.", "tokens": [420, 632, 588, 2685, 14039, 281, 33772, 13], "temperature": 0.0, "avg_logprob": -0.07941222835231472, "compression_ratio": 1.625925925925926, "no_speech_prob": 3.217541961930692e-05}, {"id": 118, "seek": 75900, "start": 761.0, "end": 766.0, "text": " So you can get both of these projects, not just with ContainerD and NerdCTL,", "tokens": [407, 291, 393, 483, 1293, 295, 613, 4455, 11, 406, 445, 365, 43732, 260, 35, 293, 38367, 10259, 43, 11], "temperature": 0.0, "avg_logprob": -0.07941222835231472, "compression_ratio": 1.625925925925926, "no_speech_prob": 3.217541961930692e-05}, {"id": 119, "seek": 75900, "start": 766.0, "end": 768.0, "text": " but also get the Docker engine.", "tokens": [457, 611, 483, 264, 33772, 2848, 13], "temperature": 0.0, "avg_logprob": -0.07941222835231472, "compression_ratio": 1.625925925925926, "no_speech_prob": 3.217541961930692e-05}, {"id": 120, "seek": 75900, "start": 768.0, "end": 773.0, "text": " In fact, CoLima, if you install it by default, does install Docker.", "tokens": [682, 1186, 11, 3066, 43, 4775, 11, 498, 291, 3625, 309, 538, 7576, 11, 775, 3625, 33772, 13], "temperature": 0.0, "avg_logprob": -0.07941222835231472, "compression_ratio": 1.625925925925926, "no_speech_prob": 3.217541961930692e-05}, {"id": 121, "seek": 75900, "start": 773.0, "end": 775.0, "text": " They both provide Kubernetes clusters.", "tokens": [814, 1293, 2893, 23145, 23313, 13], "temperature": 0.0, "avg_logprob": -0.07941222835231472, "compression_ratio": 1.625925925925926, "no_speech_prob": 3.217541961930692e-05}, {"id": 122, "seek": 75900, "start": 775.0, "end": 781.0, "text": " So again, if local development environments and Kubernetes, that combination is important to you.", "tokens": [407, 797, 11, 498, 2654, 3250, 12388, 293, 23145, 11, 300, 6562, 307, 1021, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.07941222835231472, "compression_ratio": 1.625925925925926, "no_speech_prob": 3.217541961930692e-05}, {"id": 123, "seek": 75900, "start": 781.0, "end": 783.0, "text": " They both provide that.", "tokens": [814, 1293, 2893, 300, 13], "temperature": 0.0, "avg_logprob": -0.07941222835231472, "compression_ratio": 1.625925925925926, "no_speech_prob": 3.217541961930692e-05}, {"id": 124, "seek": 75900, "start": 783.0, "end": 788.0, "text": " Rancher Desktop also adds Windows and Linux support in addition,", "tokens": [37740, 260, 49044, 611, 10860, 8591, 293, 18734, 1406, 294, 4500, 11], "temperature": 0.0, "avg_logprob": -0.07941222835231472, "compression_ratio": 1.625925925925926, "no_speech_prob": 3.217541961930692e-05}, {"id": 125, "seek": 78800, "start": 788.0, "end": 792.0, "text": " and that's not using Lima underneath.", "tokens": [293, 300, 311, 406, 1228, 50217, 7223, 13], "temperature": 0.0, "avg_logprob": -0.07719078063964843, "compression_ratio": 1.4915966386554622, "no_speech_prob": 3.0699353374075145e-05}, {"id": 126, "seek": 78800, "start": 792.0, "end": 798.0, "text": " So the last project I wanted to talk about came out of my team, AWS.", "tokens": [407, 264, 1036, 1716, 286, 1415, 281, 751, 466, 1361, 484, 295, 452, 1469, 11, 17650, 13], "temperature": 0.0, "avg_logprob": -0.07719078063964843, "compression_ratio": 1.4915966386554622, "no_speech_prob": 3.0699353374075145e-05}, {"id": 127, "seek": 78800, "start": 798.0, "end": 802.0, "text": " This is a project we just launched in November last year.", "tokens": [639, 307, 257, 1716, 321, 445, 8730, 294, 7674, 1036, 1064, 13], "temperature": 0.0, "avg_logprob": -0.07719078063964843, "compression_ratio": 1.4915966386554622, "no_speech_prob": 3.0699353374075145e-05}, {"id": 128, "seek": 78800, "start": 802.0, "end": 805.0, "text": " So just a few months ago, it's called Finch,", "tokens": [407, 445, 257, 1326, 2493, 2057, 11, 309, 311, 1219, 3773, 339, 11], "temperature": 0.0, "avg_logprob": -0.07719078063964843, "compression_ratio": 1.4915966386554622, "no_speech_prob": 3.0699353374075145e-05}, {"id": 129, "seek": 78800, "start": 805.0, "end": 810.0, "text": " and it builds on the same stack as Rancher Desktop and CoLima,", "tokens": [293, 309, 15182, 322, 264, 912, 8630, 382, 37740, 260, 49044, 293, 3066, 43, 4775, 11], "temperature": 0.0, "avg_logprob": -0.07719078063964843, "compression_ratio": 1.4915966386554622, "no_speech_prob": 3.0699353374075145e-05}, {"id": 130, "seek": 78800, "start": 810.0, "end": 816.0, "text": " where we're using Lima, NerdCTL, and BuildKit to provide that Docker command line,", "tokens": [689, 321, 434, 1228, 50217, 11, 38367, 10259, 43, 11, 293, 11875, 45626, 281, 2893, 300, 33772, 5622, 1622, 11], "temperature": 0.0, "avg_logprob": -0.07719078063964843, "compression_ratio": 1.4915966386554622, "no_speech_prob": 3.0699353374075145e-05}, {"id": 131, "seek": 81600, "start": 816.0, "end": 822.0, "text": " Docker build support, Docker compose support inside of VM on your Mac.", "tokens": [33772, 1322, 1406, 11, 33772, 35925, 1406, 1854, 295, 18038, 322, 428, 5707, 13], "temperature": 0.0, "avg_logprob": -0.14799447901108687, "compression_ratio": 1.5645933014354068, "no_speech_prob": 5.062033960712142e-05}, {"id": 132, "seek": 81600, "start": 822.0, "end": 827.0, "text": " And so there's Homebrew Packaging and Apple Sign Installer packages for that.", "tokens": [400, 370, 456, 311, 8719, 65, 2236, 18466, 3568, 293, 6373, 13515, 2730, 22414, 17401, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.14799447901108687, "compression_ratio": 1.5645933014354068, "no_speech_prob": 5.062033960712142e-05}, {"id": 133, "seek": 81600, "start": 827.0, "end": 830.0, "text": " It supports ARM64 and Intel.", "tokens": [467, 9346, 45209, 19395, 293, 19762, 13], "temperature": 0.0, "avg_logprob": -0.14799447901108687, "compression_ratio": 1.5645933014354068, "no_speech_prob": 5.062033960712142e-05}, {"id": 134, "seek": 81600, "start": 830.0, "end": 836.0, "text": " And also because of QMU and its capabilities, you can build containers.", "tokens": [400, 611, 570, 295, 1249, 44, 52, 293, 1080, 10862, 11, 291, 393, 1322, 17089, 13], "temperature": 0.0, "avg_logprob": -0.14799447901108687, "compression_ratio": 1.5645933014354068, "no_speech_prob": 5.062033960712142e-05}, {"id": 135, "seek": 81600, "start": 836.0, "end": 844.0, "text": " No matter what your host CPU is, you can build containers for Intel or ARM64.", "tokens": [883, 1871, 437, 428, 3975, 13199, 307, 11, 291, 393, 1322, 17089, 337, 19762, 420, 45209, 19395, 13], "temperature": 0.0, "avg_logprob": -0.14799447901108687, "compression_ratio": 1.5645933014354068, "no_speech_prob": 5.062033960712142e-05}, {"id": 136, "seek": 84400, "start": 844.0, "end": 851.0, "text": " And again, the host CPU itself can be any of the either Apple Silicon, M1, M2,", "tokens": [400, 797, 11, 264, 3975, 13199, 2564, 393, 312, 604, 295, 264, 2139, 6373, 25351, 11, 376, 16, 11, 376, 17, 11], "temperature": 0.0, "avg_logprob": -0.09968653032856603, "compression_ratio": 1.4705882352941178, "no_speech_prob": 3.7600235373247415e-05}, {"id": 137, "seek": 84400, "start": 851.0, "end": 853.0, "text": " or the Intel-based Mac.", "tokens": [420, 264, 19762, 12, 6032, 5707, 13], "temperature": 0.0, "avg_logprob": -0.09968653032856603, "compression_ratio": 1.4705882352941178, "no_speech_prob": 3.7600235373247415e-05}, {"id": 138, "seek": 84400, "start": 853.0, "end": 855.0, "text": " So again, we're a young project.", "tokens": [407, 797, 11, 321, 434, 257, 2037, 1716, 13], "temperature": 0.0, "avg_logprob": -0.09968653032856603, "compression_ratio": 1.4705882352941178, "no_speech_prob": 3.7600235373247415e-05}, {"id": 139, "seek": 84400, "start": 855.0, "end": 862.0, "text": " Our plans for an extension framework similar to Podman Desktop and Docker Desktop,", "tokens": [2621, 5482, 337, 364, 10320, 8388, 2531, 281, 12646, 1601, 49044, 293, 33772, 49044, 11], "temperature": 0.0, "avg_logprob": -0.09968653032856603, "compression_ratio": 1.4705882352941178, "no_speech_prob": 3.7600235373247415e-05}, {"id": 140, "seek": 84400, "start": 862.0, "end": 868.0, "text": " so that we want that same model of you can add features and add capabilities", "tokens": [370, 300, 321, 528, 300, 912, 2316, 295, 291, 393, 909, 4122, 293, 909, 10862], "temperature": 0.0, "avg_logprob": -0.09968653032856603, "compression_ratio": 1.4705882352941178, "no_speech_prob": 3.7600235373247415e-05}, {"id": 141, "seek": 84400, "start": 868.0, "end": 871.0, "text": " without having to add them to the Finch project itself", "tokens": [1553, 1419, 281, 909, 552, 281, 264, 3773, 339, 1716, 2564], "temperature": 0.0, "avg_logprob": -0.09968653032856603, "compression_ratio": 1.4705882352941178, "no_speech_prob": 3.7600235373247415e-05}, {"id": 142, "seek": 87100, "start": 871.0, "end": 874.0, "text": " to extend it to other use cases.", "tokens": [281, 10101, 309, 281, 661, 764, 3331, 13], "temperature": 0.0, "avg_logprob": -0.06259347453261867, "compression_ratio": 1.5916666666666666, "no_speech_prob": 4.8298865294782445e-05}, {"id": 143, "seek": 87100, "start": 874.0, "end": 882.0, "text": " And we're also planning similar to Rancher Desktop for adding Windows and Linux support.", "tokens": [400, 321, 434, 611, 5038, 2531, 281, 37740, 260, 49044, 337, 5127, 8591, 293, 18734, 1406, 13], "temperature": 0.0, "avg_logprob": -0.06259347453261867, "compression_ratio": 1.5916666666666666, "no_speech_prob": 4.8298865294782445e-05}, {"id": 144, "seek": 87100, "start": 882.0, "end": 886.0, "text": " Obviously, we're not really building a completely new tool.", "tokens": [7580, 11, 321, 434, 406, 534, 2390, 257, 2584, 777, 2290, 13], "temperature": 0.0, "avg_logprob": -0.06259347453261867, "compression_ratio": 1.5916666666666666, "no_speech_prob": 4.8298865294782445e-05}, {"id": 145, "seek": 87100, "start": 886.0, "end": 889.0, "text": " We're packaging most of these existing components.", "tokens": [492, 434, 16836, 881, 295, 613, 6741, 6677, 13], "temperature": 0.0, "avg_logprob": -0.06259347453261867, "compression_ratio": 1.5916666666666666, "no_speech_prob": 4.8298865294782445e-05}, {"id": 146, "seek": 87100, "start": 889.0, "end": 891.0, "text": " So we're working upstream.", "tokens": [407, 321, 434, 1364, 33915, 13], "temperature": 0.0, "avg_logprob": -0.06259347453261867, "compression_ratio": 1.5916666666666666, "no_speech_prob": 4.8298865294782445e-05}, {"id": 147, "seek": 87100, "start": 891.0, "end": 895.0, "text": " There's myself and a few other container demaintainers.", "tokens": [821, 311, 2059, 293, 257, 1326, 661, 10129, 1371, 5114, 491, 433, 13], "temperature": 0.0, "avg_logprob": -0.06259347453261867, "compression_ratio": 1.5916666666666666, "no_speech_prob": 4.8298865294782445e-05}, {"id": 148, "seek": 87100, "start": 895.0, "end": 896.0, "text": " We're working in Lima.", "tokens": [492, 434, 1364, 294, 50217, 13], "temperature": 0.0, "avg_logprob": -0.06259347453261867, "compression_ratio": 1.5916666666666666, "no_speech_prob": 4.8298865294782445e-05}, {"id": 149, "seek": 87100, "start": 896.0, "end": 899.0, "text": " We have a few pull requests merged in Lima.", "tokens": [492, 362, 257, 1326, 2235, 12475, 36427, 294, 50217, 13], "temperature": 0.0, "avg_logprob": -0.06259347453261867, "compression_ratio": 1.5916666666666666, "no_speech_prob": 4.8298865294782445e-05}, {"id": 150, "seek": 89900, "start": 899.0, "end": 903.0, "text": " We had in the latest Nerd CTL release a few weeks ago,", "tokens": [492, 632, 294, 264, 6792, 38367, 19529, 43, 4374, 257, 1326, 3259, 2057, 11], "temperature": 0.0, "avg_logprob": -0.10558814803759257, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2683230529073626e-05}, {"id": 151, "seek": 89900, "start": 903.0, "end": 909.0, "text": " we had five different Amazon folks mentioned in the release notes.", "tokens": [321, 632, 1732, 819, 6795, 4024, 2835, 294, 264, 4374, 5570, 13], "temperature": 0.0, "avg_logprob": -0.10558814803759257, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2683230529073626e-05}, {"id": 152, "seek": 89900, "start": 909.0, "end": 912.0, "text": " We're planning to add some features to BuildKit.", "tokens": [492, 434, 5038, 281, 909, 512, 4122, 281, 11875, 45626, 13], "temperature": 0.0, "avg_logprob": -0.10558814803759257, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2683230529073626e-05}, {"id": 153, "seek": 89900, "start": 912.0, "end": 915.0, "text": " And we also have several people working in the OCI specs,", "tokens": [400, 321, 611, 362, 2940, 561, 1364, 294, 264, 422, 25240, 27911, 11], "temperature": 0.0, "avg_logprob": -0.10558814803759257, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2683230529073626e-05}, {"id": 154, "seek": 89900, "start": 915.0, "end": 918.0, "text": " like the recent reference type work.", "tokens": [411, 264, 5162, 6408, 2010, 589, 13], "temperature": 0.0, "avg_logprob": -0.10558814803759257, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2683230529073626e-05}, {"id": 155, "seek": 89900, "start": 918.0, "end": 922.0, "text": " So again, a lot of the work we do in Finch is really building out capabilities", "tokens": [407, 797, 11, 257, 688, 295, 264, 589, 321, 360, 294, 3773, 339, 307, 534, 2390, 484, 10862], "temperature": 0.0, "avg_logprob": -0.10558814803759257, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2683230529073626e-05}, {"id": 156, "seek": 89900, "start": 922.0, "end": 924.0, "text": " in these underlying projects,", "tokens": [294, 613, 14217, 4455, 11], "temperature": 0.0, "avg_logprob": -0.10558814803759257, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2683230529073626e-05}, {"id": 157, "seek": 92400, "start": 924.0, "end": 929.0, "text": " not so much building a brand new interface on top.", "tokens": [406, 370, 709, 2390, 257, 3360, 777, 9226, 322, 1192, 13], "temperature": 0.0, "avg_logprob": -0.06423280239105225, "compression_ratio": 1.55859375, "no_speech_prob": 4.395941141410731e-05}, {"id": 158, "seek": 92400, "start": 929.0, "end": 932.0, "text": " And we want it to be a community open source project.", "tokens": [400, 321, 528, 309, 281, 312, 257, 1768, 1269, 4009, 1716, 13], "temperature": 0.0, "avg_logprob": -0.06423280239105225, "compression_ratio": 1.55859375, "no_speech_prob": 4.395941141410731e-05}, {"id": 159, "seek": 92400, "start": 932.0, "end": 935.0, "text": " So we're working on a public roadmap.", "tokens": [407, 321, 434, 1364, 322, 257, 1908, 35738, 13], "temperature": 0.0, "avg_logprob": -0.06423280239105225, "compression_ratio": 1.55859375, "no_speech_prob": 4.395941141410731e-05}, {"id": 160, "seek": 92400, "start": 935.0, "end": 940.0, "text": " Obviously, there's a GitHub repository here where you can go", "tokens": [7580, 11, 456, 311, 257, 23331, 25841, 510, 689, 291, 393, 352], "temperature": 0.0, "avg_logprob": -0.06423280239105225, "compression_ratio": 1.55859375, "no_speech_prob": 4.395941141410731e-05}, {"id": 161, "seek": 92400, "start": 940.0, "end": 944.0, "text": " and see what we're doing, open to external contribution.", "tokens": [293, 536, 437, 321, 434, 884, 11, 1269, 281, 8320, 13150, 13], "temperature": 0.0, "avg_logprob": -0.06423280239105225, "compression_ratio": 1.55859375, "no_speech_prob": 4.395941141410731e-05}, {"id": 162, "seek": 92400, "start": 944.0, "end": 950.0, "text": " And what we'd really love collaboration on is this added operating system support.", "tokens": [400, 437, 321, 1116, 534, 959, 9363, 322, 307, 341, 3869, 7447, 1185, 1406, 13], "temperature": 0.0, "avg_logprob": -0.06423280239105225, "compression_ratio": 1.55859375, "no_speech_prob": 4.395941141410731e-05}, {"id": 163, "seek": 92400, "start": 950.0, "end": 953.0, "text": " Again, some of that work might be in Lima or elsewhere.", "tokens": [3764, 11, 512, 295, 300, 589, 1062, 312, 294, 50217, 420, 14517, 13], "temperature": 0.0, "avg_logprob": -0.06423280239105225, "compression_ratio": 1.55859375, "no_speech_prob": 4.395941141410731e-05}, {"id": 164, "seek": 95300, "start": 953.0, "end": 957.0, "text": " But we'd love to add Windows and Linux support.", "tokens": [583, 321, 1116, 959, 281, 909, 8591, 293, 18734, 1406, 13], "temperature": 0.0, "avg_logprob": -0.06916830937067668, "compression_ratio": 1.532, "no_speech_prob": 5.726840390707366e-05}, {"id": 165, "seek": 95300, "start": 957.0, "end": 961.0, "text": " And then understanding the best way to design this extension system", "tokens": [400, 550, 3701, 264, 1151, 636, 281, 1715, 341, 10320, 1185], "temperature": 0.0, "avg_logprob": -0.06916830937067668, "compression_ratio": 1.532, "no_speech_prob": 5.726840390707366e-05}, {"id": 166, "seek": 95300, "start": 961.0, "end": 965.0, "text": " that you can already use with other tools that I mentioned.", "tokens": [300, 291, 393, 1217, 764, 365, 661, 3873, 300, 286, 2835, 13], "temperature": 0.0, "avg_logprob": -0.06916830937067668, "compression_ratio": 1.532, "no_speech_prob": 5.726840390707366e-05}, {"id": 167, "seek": 95300, "start": 965.0, "end": 969.0, "text": " We're also on the CNCF Slack in the channel Finch.", "tokens": [492, 434, 611, 322, 264, 48714, 37, 37211, 294, 264, 2269, 3773, 339, 13], "temperature": 0.0, "avg_logprob": -0.06916830937067668, "compression_ratio": 1.532, "no_speech_prob": 5.726840390707366e-05}, {"id": 168, "seek": 95300, "start": 969.0, "end": 973.0, "text": " So with that, that was a whirlwind tour", "tokens": [407, 365, 300, 11, 300, 390, 257, 35706, 12199, 3512], "temperature": 0.0, "avg_logprob": -0.06916830937067668, "compression_ratio": 1.532, "no_speech_prob": 5.726840390707366e-05}, {"id": 169, "seek": 95300, "start": 973.0, "end": 977.0, "text": " through what's available for desktop tooling today with containers.", "tokens": [807, 437, 311, 2435, 337, 14502, 46593, 965, 365, 17089, 13], "temperature": 0.0, "avg_logprob": -0.06916830937067668, "compression_ratio": 1.532, "no_speech_prob": 5.726840390707366e-05}, {"id": 170, "seek": 95300, "start": 977.0, "end": 980.0, "text": " And I think we have a few minutes for questions.", "tokens": [400, 286, 519, 321, 362, 257, 1326, 2077, 337, 1651, 13], "temperature": 0.0, "avg_logprob": -0.06916830937067668, "compression_ratio": 1.532, "no_speech_prob": 5.726840390707366e-05}, {"id": 171, "seek": 98000, "start": 980.0, "end": 989.0, "text": " APPLAUSE", "tokens": [35298], "temperature": 0.0, "avg_logprob": -0.24117767109590418, "compression_ratio": 1.0925925925925926, "no_speech_prob": 0.0006111394031904638}, {"id": 172, "seek": 98000, "start": 989.0, "end": 991.0, "text": " Yeah, any questions?", "tokens": [865, 11, 604, 1651, 30], "temperature": 0.0, "avg_logprob": -0.24117767109590418, "compression_ratio": 1.0925925925925926, "no_speech_prob": 0.0006111394031904638}, {"id": 173, "seek": 98000, "start": 999.0, "end": 1000.0, "text": " Hi.", "tokens": [2421, 13], "temperature": 0.0, "avg_logprob": -0.24117767109590418, "compression_ratio": 1.0925925925925926, "no_speech_prob": 0.0006111394031904638}, {"id": 174, "seek": 98000, "start": 1000.0, "end": 1007.0, "text": " What was the motivation to create Finch when there was already this whole ecosystem?", "tokens": [708, 390, 264, 12335, 281, 1884, 3773, 339, 562, 456, 390, 1217, 341, 1379, 11311, 30], "temperature": 0.0, "avg_logprob": -0.24117767109590418, "compression_ratio": 1.0925925925925926, "no_speech_prob": 0.0006111394031904638}, {"id": 175, "seek": 100700, "start": 1007.0, "end": 1010.0, "text": " If I think I understood the question, why create Finch", "tokens": [759, 286, 519, 286, 7320, 264, 1168, 11, 983, 1884, 3773, 339], "temperature": 0.0, "avg_logprob": -0.1161679836234661, "compression_ratio": 1.5823293172690762, "no_speech_prob": 6.59736615489237e-05}, {"id": 176, "seek": 100700, "start": 1010.0, "end": 1013.0, "text": " when there was Rancher Desktop or Colema or Lima?", "tokens": [562, 456, 390, 37740, 260, 49044, 420, 20394, 1696, 420, 50217, 30], "temperature": 0.0, "avg_logprob": -0.1161679836234661, "compression_ratio": 1.5823293172690762, "no_speech_prob": 6.59736615489237e-05}, {"id": 177, "seek": 100700, "start": 1013.0, "end": 1015.0, "text": " Yeah, that's a good question.", "tokens": [865, 11, 300, 311, 257, 665, 1168, 13], "temperature": 0.0, "avg_logprob": -0.1161679836234661, "compression_ratio": 1.5823293172690762, "no_speech_prob": 6.59736615489237e-05}, {"id": 178, "seek": 100700, "start": 1015.0, "end": 1019.0, "text": " So each of those tools kind of has its own natural inclination.", "tokens": [407, 1184, 295, 729, 3873, 733, 295, 575, 1080, 1065, 3303, 37070, 2486, 13], "temperature": 0.0, "avg_logprob": -0.1161679836234661, "compression_ratio": 1.5823293172690762, "no_speech_prob": 6.59736615489237e-05}, {"id": 179, "seek": 100700, "start": 1019.0, "end": 1024.0, "text": " With Rancher Desktop, the focus was great local Kubernetes environment", "tokens": [2022, 37740, 260, 49044, 11, 264, 1879, 390, 869, 2654, 23145, 2823], "temperature": 0.0, "avg_logprob": -0.1161679836234661, "compression_ratio": 1.5823293172690762, "no_speech_prob": 6.59736615489237e-05}, {"id": 180, "seek": 100700, "start": 1024.0, "end": 1028.0, "text": " and a GUI and some management around it and including Docker.", "tokens": [293, 257, 17917, 40, 293, 512, 4592, 926, 309, 293, 3009, 33772, 13], "temperature": 0.0, "avg_logprob": -0.1161679836234661, "compression_ratio": 1.5823293172690762, "no_speech_prob": 6.59736615489237e-05}, {"id": 181, "seek": 100700, "start": 1028.0, "end": 1032.0, "text": " We wanted something simpler that's just the command line tool.", "tokens": [492, 1415, 746, 18587, 300, 311, 445, 264, 5622, 1622, 2290, 13], "temperature": 0.0, "avg_logprob": -0.1161679836234661, "compression_ratio": 1.5823293172690762, "no_speech_prob": 6.59736615489237e-05}, {"id": 182, "seek": 103200, "start": 1032.0, "end": 1038.0, "text": " And so we talked to the Rancher folks about maybe having a common upstream.", "tokens": [400, 370, 321, 2825, 281, 264, 37740, 260, 4024, 466, 1310, 1419, 257, 2689, 33915, 13], "temperature": 0.0, "avg_logprob": -0.09542631548504497, "compression_ratio": 1.4482758620689655, "no_speech_prob": 5.138693086337298e-05}, {"id": 183, "seek": 103200, "start": 1038.0, "end": 1042.0, "text": " Maybe Finch becomes that common upstream of Lima,", "tokens": [2704, 3773, 339, 3643, 300, 2689, 33915, 295, 50217, 11], "temperature": 0.0, "avg_logprob": -0.09542631548504497, "compression_ratio": 1.4482758620689655, "no_speech_prob": 5.138693086337298e-05}, {"id": 184, "seek": 103200, "start": 1042.0, "end": 1045.0, "text": " container D, nerd CTL, build kit.", "tokens": [10129, 413, 11, 23229, 19529, 43, 11, 1322, 8260, 13], "temperature": 0.0, "avg_logprob": -0.09542631548504497, "compression_ratio": 1.4482758620689655, "no_speech_prob": 5.138693086337298e-05}, {"id": 185, "seek": 103200, "start": 1045.0, "end": 1049.0, "text": " So that might still be in the works.", "tokens": [407, 300, 1062, 920, 312, 294, 264, 1985, 13], "temperature": 0.0, "avg_logprob": -0.09542631548504497, "compression_ratio": 1.4482758620689655, "no_speech_prob": 5.138693086337298e-05}, {"id": 186, "seek": 103200, "start": 1049.0, "end": 1054.0, "text": " And then Colema is a very small project.", "tokens": [400, 550, 20394, 1696, 307, 257, 588, 1359, 1716, 13], "temperature": 0.0, "avg_logprob": -0.09542631548504497, "compression_ratio": 1.4482758620689655, "no_speech_prob": 5.138693086337298e-05}, {"id": 187, "seek": 103200, "start": 1054.0, "end": 1057.0, "text": " There's one maintainer.", "tokens": [821, 311, 472, 6909, 260, 13], "temperature": 0.0, "avg_logprob": -0.09542631548504497, "compression_ratio": 1.4482758620689655, "no_speech_prob": 5.138693086337298e-05}, {"id": 188, "seek": 103200, "start": 1057.0, "end": 1059.0, "text": " He's kind of working on his own.", "tokens": [634, 311, 733, 295, 1364, 322, 702, 1065, 13], "temperature": 0.0, "avg_logprob": -0.09542631548504497, "compression_ratio": 1.4482758620689655, "no_speech_prob": 5.138693086337298e-05}, {"id": 189, "seek": 105900, "start": 1059.0, "end": 1063.0, "text": " And again, we were looking at, you know, he's got Docker in there.", "tokens": [400, 797, 11, 321, 645, 1237, 412, 11, 291, 458, 11, 415, 311, 658, 33772, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.09764961714155218, "compression_ratio": 1.6289592760180995, "no_speech_prob": 3.0680763302370906e-05}, {"id": 190, "seek": 105900, "start": 1063.0, "end": 1066.0, "text": " He's got Kubernetes.", "tokens": [634, 311, 658, 23145, 13], "temperature": 0.0, "avg_logprob": -0.09764961714155218, "compression_ratio": 1.6289592760180995, "no_speech_prob": 3.0680763302370906e-05}, {"id": 191, "seek": 105900, "start": 1066.0, "end": 1071.0, "text": " And we wanted to, again, focus just on the container interloop lifecycle,", "tokens": [400, 321, 1415, 281, 11, 797, 11, 1879, 445, 322, 264, 10129, 728, 46623, 45722, 11], "temperature": 0.0, "avg_logprob": -0.09764961714155218, "compression_ratio": 1.6289592760180995, "no_speech_prob": 3.0680763302370906e-05}, {"id": 192, "seek": 105900, "start": 1071.0, "end": 1075.0, "text": " build containers, run containers, push containers to registries.", "tokens": [1322, 17089, 11, 1190, 17089, 11, 2944, 17089, 281, 11376, 2244, 13], "temperature": 0.0, "avg_logprob": -0.09764961714155218, "compression_ratio": 1.6289592760180995, "no_speech_prob": 3.0680763302370906e-05}, {"id": 193, "seek": 105900, "start": 1075.0, "end": 1080.0, "text": " And so essentially it's just a simplification that we think", "tokens": [400, 370, 4476, 309, 311, 445, 257, 6883, 3774, 300, 321, 519], "temperature": 0.0, "avg_logprob": -0.09764961714155218, "compression_ratio": 1.6289592760180995, "no_speech_prob": 3.0680763302370906e-05}, {"id": 194, "seek": 105900, "start": 1080.0, "end": 1084.0, "text": " there's still lots of ability for collaboration with those other projects", "tokens": [456, 311, 920, 3195, 295, 3485, 337, 9363, 365, 729, 661, 4455], "temperature": 0.0, "avg_logprob": -0.09764961714155218, "compression_ratio": 1.6289592760180995, "no_speech_prob": 3.0680763302370906e-05}, {"id": 195, "seek": 108400, "start": 1084.0, "end": 1091.0, "text": " because we're all using the same stack below us.", "tokens": [570, 321, 434, 439, 1228, 264, 912, 8630, 2507, 505, 13], "temperature": 0.0, "avg_logprob": -0.04140445921156141, "compression_ratio": 1.1149425287356323, "no_speech_prob": 0.0002554779057390988}, {"id": 196, "seek": 108400, "start": 1091.0, "end": 1108.0, "text": " We have time for one more fairly quick question.", "tokens": [492, 362, 565, 337, 472, 544, 6457, 1702, 1168, 13], "temperature": 0.0, "avg_logprob": -0.04140445921156141, "compression_ratio": 1.1149425287356323, "no_speech_prob": 0.0002554779057390988}, {"id": 197, "seek": 110800, "start": 1108.0, "end": 1116.0, "text": " How easy it is to pick up Finch for someone who's just started working as a developer?", "tokens": [1012, 1858, 309, 307, 281, 1888, 493, 3773, 339, 337, 1580, 567, 311, 445, 1409, 1364, 382, 257, 10754, 30], "temperature": 0.0, "avg_logprob": -0.08725451506101169, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0005264715291559696}, {"id": 198, "seek": 110800, "start": 1116.0, "end": 1118.0, "text": " Yeah, how easy to use?", "tokens": [865, 11, 577, 1858, 281, 764, 30], "temperature": 0.0, "avg_logprob": -0.08725451506101169, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0005264715291559696}, {"id": 199, "seek": 110800, "start": 1118.0, "end": 1121.0, "text": " What's the learning curve compared to Docker?", "tokens": [708, 311, 264, 2539, 7605, 5347, 281, 33772, 30], "temperature": 0.0, "avg_logprob": -0.08725451506101169, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0005264715291559696}, {"id": 200, "seek": 110800, "start": 1121.0, "end": 1126.0, "text": " Yeah, so again, most of these tools are built around the sort of", "tokens": [865, 11, 370, 797, 11, 881, 295, 613, 3873, 366, 3094, 926, 264, 1333, 295], "temperature": 0.0, "avg_logprob": -0.08725451506101169, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0005264715291559696}, {"id": 201, "seek": 110800, "start": 1126.0, "end": 1128.0, "text": " understood Docker command line tool.", "tokens": [7320, 33772, 5622, 1622, 2290, 13], "temperature": 0.0, "avg_logprob": -0.08725451506101169, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0005264715291559696}, {"id": 202, "seek": 110800, "start": 1128.0, "end": 1134.0, "text": " So if you've already used Docker, like it's the same commands, the same flags.", "tokens": [407, 498, 291, 600, 1217, 1143, 33772, 11, 411, 309, 311, 264, 912, 16901, 11, 264, 912, 23265, 13], "temperature": 0.0, "avg_logprob": -0.08725451506101169, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0005264715291559696}, {"id": 203, "seek": 110800, "start": 1134.0, "end": 1136.0, "text": " So in that sense, there's no real learning curve.", "tokens": [407, 294, 300, 2020, 11, 456, 311, 572, 957, 2539, 7605, 13], "temperature": 0.0, "avg_logprob": -0.08725451506101169, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0005264715291559696}, {"id": 204, "seek": 113600, "start": 1136.0, "end": 1140.0, "text": " Now, if you're just brand new to containers, it's really the same effort", "tokens": [823, 11, 498, 291, 434, 445, 3360, 777, 281, 17089, 11, 309, 311, 534, 264, 912, 4630], "temperature": 0.0, "avg_logprob": -0.08063104075770225, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.00010548274440225214}, {"id": 205, "seek": 113600, "start": 1140.0, "end": 1146.0, "text": " that you'd have to do to learn Docker or Podman or Finch or anything else.", "tokens": [300, 291, 1116, 362, 281, 360, 281, 1466, 33772, 420, 12646, 1601, 420, 3773, 339, 420, 1340, 1646, 13], "temperature": 0.0, "avg_logprob": -0.08063104075770225, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.00010548274440225214}, {"id": 206, "seek": 113600, "start": 1146.0, "end": 1151.0, "text": " So it's really about your understanding of kind of the existing developer", "tokens": [407, 309, 311, 534, 466, 428, 3701, 295, 733, 295, 264, 6741, 10754], "temperature": 0.0, "avg_logprob": -0.08063104075770225, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.00010548274440225214}, {"id": 207, "seek": 113600, "start": 1151.0, "end": 1155.0, "text": " tooling space built around Docker.", "tokens": [46593, 1901, 3094, 926, 33772, 13], "temperature": 0.0, "avg_logprob": -0.08063104075770225, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.00010548274440225214}, {"id": 208, "seek": 113600, "start": 1155.0, "end": 1156.0, "text": " Okay, thank you.", "tokens": [1033, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.08063104075770225, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.00010548274440225214}, {"id": 209, "seek": 113600, "start": 1156.0, "end": 1160.0, "text": " Please leave quietly when we are still asking questions.", "tokens": [2555, 1856, 19141, 562, 321, 366, 920, 3365, 1651, 13], "temperature": 0.0, "avg_logprob": -0.08063104075770225, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.00010548274440225214}, {"id": 210, "seek": 113600, "start": 1160.0, "end": 1162.0, "text": " Other than that, thank you.", "tokens": [5358, 813, 300, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.08063104075770225, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.00010548274440225214}, {"id": 211, "seek": 116200, "start": 1162.0, "end": 1167.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50614], "temperature": 0.0, "avg_logprob": -0.3833528757095337, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.00017676976858638227}], "language": "en"}