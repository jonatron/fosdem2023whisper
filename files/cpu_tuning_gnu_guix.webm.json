{"text": " Okay, final lightning talk for today is Ludovic talking about geeks. All right, thank you. Hello HPC people. So my name is Ludovic Cortes. I work at INRIER, which is a French research institute in France in computer science. And I work as a research engineer. So I'm very much concerned about engineering issues in general. And in particular, I'm concerned about deployment. So if you're an HPC dev room aficionado, we've probably made before. I gave a couple of talks, I guess, in this room, more specifically about geeks. So maybe you're afraid about geeks. It's a software deployment tool. So we have Easy Builds Pack, also RPM, well, you know, app, et cetera. And this is yet another deployment tool, if you will. But we have this very particular vision where, you know, the grand vision where we're trying to build a tool for reproducible research and HPC. So the thing here that you see is the vision, so to speak. So at one end of the spectrum, we have, you know, research articles and we want the research to be solid. So we want the computational workflows to be reproducible. And at the other end of the spectrum on the left, we have archives, source code archives like software heritage, which we really need to have if we want that scientific source code to, you know, to remain available over time. And in the middle, while we need a bunch of tools, in particular, deployment tool like geeks to reproduce, well, to deploy software reproducibly. Yes. So in a nutshell, yes, geeks provides actual tools for reproducible research people. I'm not going to go into details, but basically you can say, all right, I've made an experiment, a computational experiment. So now I'm going to pin the exact revision of geeks that I used. This is the first command here. And the second command is, you know, some time later or some colleague wants to reproduce the results. And so they use the time machine to jump to that specific revision of geeks. And from there, they deploy the exact same packages that I have done in that manifest file, bit for bit. That's the idea. All right. So in HPC, I guess most people in this room would agree. We have two obsessions. That's MPI and AVX, well, vector instructions. We want things to run fast, right? We have those fancy clusters. So we want to make sure that the communications are going to be fast. We want to make sure we're going to use the latest vector instructions of our CPUs. And that makes a lot of sense. But sometimes we're going, maybe we have preconceptions about the implications of all this. So here I'm creating Todd Gamblin, who's maybe in this room actually. Hi, Todd, if you see me. This is an example where we, well, Todd here was saying, you know, binaries, distributions like Debian or Geeks or Fedora, for example, are just targeting the baseline of the CPU, like A6664 without AVX, for example. And that's a problem for performance. Because of course, if you have that latest fancy Intel processor, then you probably want to use those vector instructions. But the conclusion that because of this, we cannot use, you know, binary distributions. Distributions like Geeks or Debian that provide binaries is not entirely accurate. That's the point I'm trying to make in this talk. So yeah, as most of you know, there's a whole bunch of vector extensions. It keeps growing, you know, like every, every few years we have new vector extensions in Intel or AMD CPUs or even AH64 CPUs, Power 9, et cetera. And it's even worse if you look at the actual CPU models, for example, this is just for Intel, there's a whole bunch of things. It's not always a superset of the previous CPU, you know, we're discussing it the other day for dinner. And yeah, sometimes it's complicated. You cannot tell that Skylake AVX is exactly a superset of Skylake. It's complicated. And yet you want to be able to target these CPUs specifically, these micro-architectures. And it makes a big deal of a difference. So this is an example from an Agen benchmark. So Agen is a C++ library for linear algebra, specifically targeting small matrices. And well, you know, if on my laptop, if I'm targeting, if I'm compiling with MR equals to Skylake, then I get a throughput that's three times the baseline performance. So it's a pretty big deal. So we definitely want to use that. We want to be able to compile specifically for the CPU micro-architecture that we have. But so the good news is that to a large extent, that's a solved problem for a long time. So there is this thing called function multi-versioning that is already used in a number of performance critical libraries. So if you look at LeapSea for string comparison, or if you look at OpenBLAST, if you look at FFTW, GMP for multi-precision arithmetic, you know, many libraries, programming languages, runtimes, already use function multi-versioning. So what's the deal here? Well, roughly when you have function multi-versioning, you can say, well, I have one function that does some linear algebra stuff, for example, and I'm actually providing several variants of that function. And when I start my program at runtime, the loader or, you know, the runtime system is going to pick the most optimized one for the CPU I have at hand, right? So if I use GMP, for example, for multi-precision arithmetic, it's going to pick the fastest implementation it has, you know. So you can compile GMP once, and then it's going to use the writing at runtime. And even if you're using GCC or Clang, you can specify in your C code, well, I want this particular function to be cloned, so to have several variants for each CPU microarchitectures, and GCC or Clang is going to create several variants of that function so that it can pick the right one at runtime. So kind of a solved problem, in a way, well, except in some cases. Well, one particular case where we have a problem is C++ template libraries, like Agen, which I was mentioning before, they are not able to benefit from function multi-versioning in any way. So when you compile your Agen benchmark, well, you really have to use mRch equals to Skylake, for example, if you were targeting a Skylake CPU. And this is because if you look at Agen headers, for example, where there are many places where you have if depths, do I have AVX 512 at compilation time? If yes, then I'm going to use the optimized implementation, otherwise, I'm going to use the baseline implementation. And this is all happening at compilation time, so you really have to have a solution at compilation time to address this. And so this is where Geeks comes in. So Geeks is, you know, it's a distribution, like Debian, like I was saying, that's targeting the baseline instruction set, but we came up with a new thing that's called package multi-versioning. It's actually one year old or something, which is roughly the idea is taking the same idea of function as function multi-versioning, but applying it at the level of entire packages. So let's say I have those Agen benchmarks, I can run them using just the baseline X8664 architecture, using this Geeks shell command. It's, you know, it's taking the Agen benchmarks package, and in that package running the Bench plus gem command, right, on a small matrix. And then I can say, all right, now I want to tune that code specifically for my CPU, and then I just put that extra, that extra dash dash tune option, and it's selling Geeks, all right, please optimize that Agen benchmarks package directly for the CPU I'm on, which is Skylake in this case, and this is it. And what happens behind the scenes is that on the flag, Geeks is creating a new package variant. So it's taking that Agen benchmarks package, creating a new package variant that is built specifically with a compiler wrapper that passes the MRT equals to Skylake flag. And I get the performance, and I'm happy, right, so this is in Geeks since 2022, and it's still reproducible, you know, because we can still say, all right, what precise option did I use, what dash dash tune option did I use, and it's Skylake, all right, so the build process of the package remains reproducible, right, I'm still getting the same binary if I use dash dash tune equals to Skylake on my laptop or on some HPC cluster, whatever. And there are no world rebuilds, which means that the build farm, for example, the official build farm of the project is providing several variants of those packages, those, you know, performance sensitive packages built for Skylake, Skylake, AVX, 512, you know, different things. So if you install them, most likely you're going to get a pre-built binary that's specifically optimized for that CPU. And if not, well, that's fine, it's going to be to build it for you, that's okay. So my conclusion here is, you know, we keep talking about performance of MPI, vector instruction and so forth. Well, I think we can have performance, we can have portable performance, that's what we should aim for, and we can still have reproducibility, we don't have to sacrifice reproducibility for performance, that's my take on the message. Thank you. Thank you very much. Again, time for one question. Okay, yeah, this whole dash tune thing looks awesome. But what if the majority of the computation time is spent in libraries that that library is actually using? How do I tell it to optimize those instead as well? Right. So the way it works in Geeks, you can annotate packages that really need to be tunable, right? So you can add a property to a package like, so it would be egg and benchmarks in this case where it could be the GNU Scientific Library, GSL, and you said this package needs to be tunable, so if I use dash, dash, tune, please tune specifically this package. And it's going to work even if you're installing, you know, an application that actually depends on GSL, for example. All right, thanks a lot Ludovic. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.36, "text": " Okay, final lightning talk for today is Ludovic talking about geeks.", "tokens": [1033, 11, 2572, 16589, 751, 337, 965, 307, 30550, 5179, 299, 1417, 466, 1519, 24785, 13], "temperature": 0.0, "avg_logprob": -0.28974079049151874, "compression_ratio": 1.5093457943925233, "no_speech_prob": 0.32126396894454956}, {"id": 1, "seek": 0, "start": 11.36, "end": 14.0, "text": " All right, thank you.", "tokens": [1057, 558, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.28974079049151874, "compression_ratio": 1.5093457943925233, "no_speech_prob": 0.32126396894454956}, {"id": 2, "seek": 0, "start": 14.0, "end": 15.68, "text": " Hello HPC people.", "tokens": [2425, 12557, 34, 561, 13], "temperature": 0.0, "avg_logprob": -0.28974079049151874, "compression_ratio": 1.5093457943925233, "no_speech_prob": 0.32126396894454956}, {"id": 3, "seek": 0, "start": 15.68, "end": 17.2, "text": " So my name is Ludovic Cortes.", "tokens": [407, 452, 1315, 307, 30550, 5179, 299, 28522, 279, 13], "temperature": 0.0, "avg_logprob": -0.28974079049151874, "compression_ratio": 1.5093457943925233, "no_speech_prob": 0.32126396894454956}, {"id": 4, "seek": 0, "start": 17.2, "end": 23.0, "text": " I work at INRIER, which is a French research institute in France in computer science.", "tokens": [286, 589, 412, 6892, 5577, 1598, 11, 597, 307, 257, 5522, 2132, 26860, 294, 6190, 294, 3820, 3497, 13], "temperature": 0.0, "avg_logprob": -0.28974079049151874, "compression_ratio": 1.5093457943925233, "no_speech_prob": 0.32126396894454956}, {"id": 5, "seek": 0, "start": 23.0, "end": 24.6, "text": " And I work as a research engineer.", "tokens": [400, 286, 589, 382, 257, 2132, 11403, 13], "temperature": 0.0, "avg_logprob": -0.28974079049151874, "compression_ratio": 1.5093457943925233, "no_speech_prob": 0.32126396894454956}, {"id": 6, "seek": 0, "start": 24.6, "end": 29.04, "text": " So I'm very much concerned about engineering issues in general.", "tokens": [407, 286, 478, 588, 709, 5922, 466, 7043, 2663, 294, 2674, 13], "temperature": 0.0, "avg_logprob": -0.28974079049151874, "compression_ratio": 1.5093457943925233, "no_speech_prob": 0.32126396894454956}, {"id": 7, "seek": 2904, "start": 29.04, "end": 31.52, "text": " And in particular, I'm concerned about deployment.", "tokens": [400, 294, 1729, 11, 286, 478, 5922, 466, 19317, 13], "temperature": 0.0, "avg_logprob": -0.19521041538404382, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.00034659734228625894}, {"id": 8, "seek": 2904, "start": 31.52, "end": 37.519999999999996, "text": " So if you're an HPC dev room aficionado, we've probably made before.", "tokens": [407, 498, 291, 434, 364, 12557, 34, 1905, 1808, 257, 1786, 313, 1573, 11, 321, 600, 1391, 1027, 949, 13], "temperature": 0.0, "avg_logprob": -0.19521041538404382, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.00034659734228625894}, {"id": 9, "seek": 2904, "start": 37.519999999999996, "end": 43.16, "text": " I gave a couple of talks, I guess, in this room, more specifically about geeks.", "tokens": [286, 2729, 257, 1916, 295, 6686, 11, 286, 2041, 11, 294, 341, 1808, 11, 544, 4682, 466, 1519, 24785, 13], "temperature": 0.0, "avg_logprob": -0.19521041538404382, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.00034659734228625894}, {"id": 10, "seek": 2904, "start": 43.16, "end": 44.92, "text": " So maybe you're afraid about geeks.", "tokens": [407, 1310, 291, 434, 4638, 466, 1519, 24785, 13], "temperature": 0.0, "avg_logprob": -0.19521041538404382, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.00034659734228625894}, {"id": 11, "seek": 2904, "start": 44.92, "end": 46.480000000000004, "text": " It's a software deployment tool.", "tokens": [467, 311, 257, 4722, 19317, 2290, 13], "temperature": 0.0, "avg_logprob": -0.19521041538404382, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.00034659734228625894}, {"id": 12, "seek": 2904, "start": 46.480000000000004, "end": 52.04, "text": " So we have Easy Builds Pack, also RPM, well, you know, app, et cetera.", "tokens": [407, 321, 362, 16002, 11875, 82, 18466, 11, 611, 37389, 11, 731, 11, 291, 458, 11, 724, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.19521041538404382, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.00034659734228625894}, {"id": 13, "seek": 2904, "start": 52.04, "end": 55.36, "text": " And this is yet another deployment tool, if you will.", "tokens": [400, 341, 307, 1939, 1071, 19317, 2290, 11, 498, 291, 486, 13], "temperature": 0.0, "avg_logprob": -0.19521041538404382, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.00034659734228625894}, {"id": 14, "seek": 5536, "start": 55.36, "end": 59.6, "text": " But we have this very particular vision where, you know, the grand vision where we're trying", "tokens": [583, 321, 362, 341, 588, 1729, 5201, 689, 11, 291, 458, 11, 264, 2697, 5201, 689, 321, 434, 1382], "temperature": 0.0, "avg_logprob": -0.1480653061826005, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.000171335632330738}, {"id": 15, "seek": 5536, "start": 59.6, "end": 64.44, "text": " to build a tool for reproducible research and HPC.", "tokens": [281, 1322, 257, 2290, 337, 11408, 32128, 2132, 293, 12557, 34, 13], "temperature": 0.0, "avg_logprob": -0.1480653061826005, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.000171335632330738}, {"id": 16, "seek": 5536, "start": 64.44, "end": 67.6, "text": " So the thing here that you see is the vision, so to speak.", "tokens": [407, 264, 551, 510, 300, 291, 536, 307, 264, 5201, 11, 370, 281, 1710, 13], "temperature": 0.0, "avg_logprob": -0.1480653061826005, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.000171335632330738}, {"id": 17, "seek": 5536, "start": 67.6, "end": 72.0, "text": " So at one end of the spectrum, we have, you know, research articles and we want the research", "tokens": [407, 412, 472, 917, 295, 264, 11143, 11, 321, 362, 11, 291, 458, 11, 2132, 11290, 293, 321, 528, 264, 2132], "temperature": 0.0, "avg_logprob": -0.1480653061826005, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.000171335632330738}, {"id": 18, "seek": 5536, "start": 72.0, "end": 73.48, "text": " to be solid.", "tokens": [281, 312, 5100, 13], "temperature": 0.0, "avg_logprob": -0.1480653061826005, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.000171335632330738}, {"id": 19, "seek": 5536, "start": 73.48, "end": 77.0, "text": " So we want the computational workflows to be reproducible.", "tokens": [407, 321, 528, 264, 28270, 43461, 281, 312, 11408, 32128, 13], "temperature": 0.0, "avg_logprob": -0.1480653061826005, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.000171335632330738}, {"id": 20, "seek": 5536, "start": 77.0, "end": 81.08, "text": " And at the other end of the spectrum on the left, we have archives, source code archives", "tokens": [400, 412, 264, 661, 917, 295, 264, 11143, 322, 264, 1411, 11, 321, 362, 25607, 11, 4009, 3089, 25607], "temperature": 0.0, "avg_logprob": -0.1480653061826005, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.000171335632330738}, {"id": 21, "seek": 8108, "start": 81.08, "end": 85.84, "text": " like software heritage, which we really need to have if we want that scientific source", "tokens": [411, 4722, 16040, 11, 597, 321, 534, 643, 281, 362, 498, 321, 528, 300, 8134, 4009], "temperature": 0.0, "avg_logprob": -0.1755010649913878, "compression_ratio": 1.6847457627118645, "no_speech_prob": 9.288051660405472e-05}, {"id": 22, "seek": 8108, "start": 85.84, "end": 89.32, "text": " code to, you know, to remain available over time.", "tokens": [3089, 281, 11, 291, 458, 11, 281, 6222, 2435, 670, 565, 13], "temperature": 0.0, "avg_logprob": -0.1755010649913878, "compression_ratio": 1.6847457627118645, "no_speech_prob": 9.288051660405472e-05}, {"id": 23, "seek": 8108, "start": 89.32, "end": 94.0, "text": " And in the middle, while we need a bunch of tools, in particular, deployment tool like", "tokens": [400, 294, 264, 2808, 11, 1339, 321, 643, 257, 3840, 295, 3873, 11, 294, 1729, 11, 19317, 2290, 411], "temperature": 0.0, "avg_logprob": -0.1755010649913878, "compression_ratio": 1.6847457627118645, "no_speech_prob": 9.288051660405472e-05}, {"id": 24, "seek": 8108, "start": 94.0, "end": 97.96, "text": " geeks to reproduce, well, to deploy software reproducibly.", "tokens": [1519, 24785, 281, 29501, 11, 731, 11, 281, 7274, 4722, 11408, 537, 25021, 13], "temperature": 0.0, "avg_logprob": -0.1755010649913878, "compression_ratio": 1.6847457627118645, "no_speech_prob": 9.288051660405472e-05}, {"id": 25, "seek": 8108, "start": 97.96, "end": 99.72, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.1755010649913878, "compression_ratio": 1.6847457627118645, "no_speech_prob": 9.288051660405472e-05}, {"id": 26, "seek": 8108, "start": 99.72, "end": 104.92, "text": " So in a nutshell, yes, geeks provides actual tools for reproducible research people.", "tokens": [407, 294, 257, 37711, 11, 2086, 11, 1519, 24785, 6417, 3539, 3873, 337, 11408, 32128, 2132, 561, 13], "temperature": 0.0, "avg_logprob": -0.1755010649913878, "compression_ratio": 1.6847457627118645, "no_speech_prob": 9.288051660405472e-05}, {"id": 27, "seek": 8108, "start": 104.92, "end": 109.4, "text": " I'm not going to go into details, but basically you can say, all right, I've made an experiment,", "tokens": [286, 478, 406, 516, 281, 352, 666, 4365, 11, 457, 1936, 291, 393, 584, 11, 439, 558, 11, 286, 600, 1027, 364, 5120, 11], "temperature": 0.0, "avg_logprob": -0.1755010649913878, "compression_ratio": 1.6847457627118645, "no_speech_prob": 9.288051660405472e-05}, {"id": 28, "seek": 8108, "start": 109.4, "end": 110.8, "text": " a computational experiment.", "tokens": [257, 28270, 5120, 13], "temperature": 0.0, "avg_logprob": -0.1755010649913878, "compression_ratio": 1.6847457627118645, "no_speech_prob": 9.288051660405472e-05}, {"id": 29, "seek": 11080, "start": 110.8, "end": 114.2, "text": " So now I'm going to pin the exact revision of geeks that I used.", "tokens": [407, 586, 286, 478, 516, 281, 5447, 264, 1900, 34218, 295, 1519, 24785, 300, 286, 1143, 13], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 30, "seek": 11080, "start": 114.2, "end": 116.36, "text": " This is the first command here.", "tokens": [639, 307, 264, 700, 5622, 510, 13], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 31, "seek": 11080, "start": 116.36, "end": 120.96, "text": " And the second command is, you know, some time later or some colleague wants to reproduce", "tokens": [400, 264, 1150, 5622, 307, 11, 291, 458, 11, 512, 565, 1780, 420, 512, 13532, 2738, 281, 29501], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 32, "seek": 11080, "start": 120.96, "end": 122.12, "text": " the results.", "tokens": [264, 3542, 13], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 33, "seek": 11080, "start": 122.12, "end": 126.0, "text": " And so they use the time machine to jump to that specific revision of geeks.", "tokens": [400, 370, 436, 764, 264, 565, 3479, 281, 3012, 281, 300, 2685, 34218, 295, 1519, 24785, 13], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 34, "seek": 11080, "start": 126.0, "end": 130.56, "text": " And from there, they deploy the exact same packages that I have done in that manifest", "tokens": [400, 490, 456, 11, 436, 7274, 264, 1900, 912, 17401, 300, 286, 362, 1096, 294, 300, 10067], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 35, "seek": 11080, "start": 130.56, "end": 132.96, "text": " file, bit for bit.", "tokens": [3991, 11, 857, 337, 857, 13], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 36, "seek": 11080, "start": 132.96, "end": 134.48, "text": " That's the idea.", "tokens": [663, 311, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 37, "seek": 11080, "start": 134.48, "end": 135.72, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 38, "seek": 11080, "start": 135.72, "end": 139.68, "text": " So in HPC, I guess most people in this room would agree.", "tokens": [407, 294, 12557, 34, 11, 286, 2041, 881, 561, 294, 341, 1808, 576, 3986, 13], "temperature": 0.0, "avg_logprob": -0.1923575181227464, "compression_ratio": 1.6823104693140793, "no_speech_prob": 9.125319047598168e-05}, {"id": 39, "seek": 13968, "start": 139.68, "end": 142.52, "text": " We have two obsessions.", "tokens": [492, 362, 732, 3181, 9069, 13], "temperature": 0.0, "avg_logprob": -0.13339168684823172, "compression_ratio": 1.7238493723849373, "no_speech_prob": 7.352360262302682e-05}, {"id": 40, "seek": 13968, "start": 142.52, "end": 146.88, "text": " That's MPI and AVX, well, vector instructions.", "tokens": [663, 311, 14146, 40, 293, 30198, 55, 11, 731, 11, 8062, 9415, 13], "temperature": 0.0, "avg_logprob": -0.13339168684823172, "compression_ratio": 1.7238493723849373, "no_speech_prob": 7.352360262302682e-05}, {"id": 41, "seek": 13968, "start": 146.88, "end": 148.64000000000001, "text": " We want things to run fast, right?", "tokens": [492, 528, 721, 281, 1190, 2370, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.13339168684823172, "compression_ratio": 1.7238493723849373, "no_speech_prob": 7.352360262302682e-05}, {"id": 42, "seek": 13968, "start": 148.64000000000001, "end": 149.96, "text": " We have those fancy clusters.", "tokens": [492, 362, 729, 10247, 23313, 13], "temperature": 0.0, "avg_logprob": -0.13339168684823172, "compression_ratio": 1.7238493723849373, "no_speech_prob": 7.352360262302682e-05}, {"id": 43, "seek": 13968, "start": 149.96, "end": 153.20000000000002, "text": " So we want to make sure that the communications are going to be fast.", "tokens": [407, 321, 528, 281, 652, 988, 300, 264, 15163, 366, 516, 281, 312, 2370, 13], "temperature": 0.0, "avg_logprob": -0.13339168684823172, "compression_ratio": 1.7238493723849373, "no_speech_prob": 7.352360262302682e-05}, {"id": 44, "seek": 13968, "start": 153.20000000000002, "end": 157.60000000000002, "text": " We want to make sure we're going to use the latest vector instructions of our CPUs.", "tokens": [492, 528, 281, 652, 988, 321, 434, 516, 281, 764, 264, 6792, 8062, 9415, 295, 527, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.13339168684823172, "compression_ratio": 1.7238493723849373, "no_speech_prob": 7.352360262302682e-05}, {"id": 45, "seek": 13968, "start": 157.60000000000002, "end": 159.72, "text": " And that makes a lot of sense.", "tokens": [400, 300, 1669, 257, 688, 295, 2020, 13], "temperature": 0.0, "avg_logprob": -0.13339168684823172, "compression_ratio": 1.7238493723849373, "no_speech_prob": 7.352360262302682e-05}, {"id": 46, "seek": 13968, "start": 159.72, "end": 165.8, "text": " But sometimes we're going, maybe we have preconceptions about the implications of all this.", "tokens": [583, 2171, 321, 434, 516, 11, 1310, 321, 362, 47473, 22393, 466, 264, 16602, 295, 439, 341, 13], "temperature": 0.0, "avg_logprob": -0.13339168684823172, "compression_ratio": 1.7238493723849373, "no_speech_prob": 7.352360262302682e-05}, {"id": 47, "seek": 16580, "start": 165.8, "end": 169.92000000000002, "text": " So here I'm creating Todd Gamblin, who's maybe in this room actually.", "tokens": [407, 510, 286, 478, 4084, 21488, 44643, 5045, 11, 567, 311, 1310, 294, 341, 1808, 767, 13], "temperature": 0.0, "avg_logprob": -0.17409413359885992, "compression_ratio": 1.5681063122923589, "no_speech_prob": 7.453488069586456e-05}, {"id": 48, "seek": 16580, "start": 169.92000000000002, "end": 172.4, "text": " Hi, Todd, if you see me.", "tokens": [2421, 11, 21488, 11, 498, 291, 536, 385, 13], "temperature": 0.0, "avg_logprob": -0.17409413359885992, "compression_ratio": 1.5681063122923589, "no_speech_prob": 7.453488069586456e-05}, {"id": 49, "seek": 16580, "start": 172.4, "end": 177.12, "text": " This is an example where we, well, Todd here was saying, you know, binaries, distributions", "tokens": [639, 307, 364, 1365, 689, 321, 11, 731, 11, 21488, 510, 390, 1566, 11, 291, 458, 11, 5171, 4889, 11, 37870], "temperature": 0.0, "avg_logprob": -0.17409413359885992, "compression_ratio": 1.5681063122923589, "no_speech_prob": 7.453488069586456e-05}, {"id": 50, "seek": 16580, "start": 177.12, "end": 182.8, "text": " like Debian or Geeks or Fedora, for example, are just targeting the baseline of the CPU,", "tokens": [411, 1346, 20196, 420, 2876, 24785, 420, 7772, 3252, 11, 337, 1365, 11, 366, 445, 17918, 264, 20518, 295, 264, 13199, 11], "temperature": 0.0, "avg_logprob": -0.17409413359885992, "compression_ratio": 1.5681063122923589, "no_speech_prob": 7.453488069586456e-05}, {"id": 51, "seek": 16580, "start": 182.8, "end": 186.92000000000002, "text": " like A6664 without AVX, for example.", "tokens": [411, 316, 15237, 19395, 1553, 30198, 55, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.17409413359885992, "compression_ratio": 1.5681063122923589, "no_speech_prob": 7.453488069586456e-05}, {"id": 52, "seek": 16580, "start": 186.92000000000002, "end": 189.36, "text": " And that's a problem for performance.", "tokens": [400, 300, 311, 257, 1154, 337, 3389, 13], "temperature": 0.0, "avg_logprob": -0.17409413359885992, "compression_ratio": 1.5681063122923589, "no_speech_prob": 7.453488069586456e-05}, {"id": 53, "seek": 16580, "start": 189.36, "end": 193.04000000000002, "text": " Because of course, if you have that latest fancy Intel processor, then you probably want", "tokens": [1436, 295, 1164, 11, 498, 291, 362, 300, 6792, 10247, 19762, 15321, 11, 550, 291, 1391, 528], "temperature": 0.0, "avg_logprob": -0.17409413359885992, "compression_ratio": 1.5681063122923589, "no_speech_prob": 7.453488069586456e-05}, {"id": 54, "seek": 16580, "start": 193.04000000000002, "end": 195.76000000000002, "text": " to use those vector instructions.", "tokens": [281, 764, 729, 8062, 9415, 13], "temperature": 0.0, "avg_logprob": -0.17409413359885992, "compression_ratio": 1.5681063122923589, "no_speech_prob": 7.453488069586456e-05}, {"id": 55, "seek": 19576, "start": 195.76, "end": 202.44, "text": " But the conclusion that because of this, we cannot use, you know, binary distributions.", "tokens": [583, 264, 10063, 300, 570, 295, 341, 11, 321, 2644, 764, 11, 291, 458, 11, 17434, 37870, 13], "temperature": 0.0, "avg_logprob": -0.14116117905597297, "compression_ratio": 1.6437768240343347, "no_speech_prob": 4.979617733624764e-05}, {"id": 56, "seek": 19576, "start": 202.44, "end": 206.95999999999998, "text": " Distributions like Geeks or Debian that provide binaries is not entirely accurate.", "tokens": [9840, 2024, 3666, 411, 2876, 24785, 420, 1346, 20196, 300, 2893, 5171, 4889, 307, 406, 7696, 8559, 13], "temperature": 0.0, "avg_logprob": -0.14116117905597297, "compression_ratio": 1.6437768240343347, "no_speech_prob": 4.979617733624764e-05}, {"id": 57, "seek": 19576, "start": 206.95999999999998, "end": 210.84, "text": " That's the point I'm trying to make in this talk.", "tokens": [663, 311, 264, 935, 286, 478, 1382, 281, 652, 294, 341, 751, 13], "temperature": 0.0, "avg_logprob": -0.14116117905597297, "compression_ratio": 1.6437768240343347, "no_speech_prob": 4.979617733624764e-05}, {"id": 58, "seek": 19576, "start": 210.84, "end": 215.76, "text": " So yeah, as most of you know, there's a whole bunch of vector extensions.", "tokens": [407, 1338, 11, 382, 881, 295, 291, 458, 11, 456, 311, 257, 1379, 3840, 295, 8062, 25129, 13], "temperature": 0.0, "avg_logprob": -0.14116117905597297, "compression_ratio": 1.6437768240343347, "no_speech_prob": 4.979617733624764e-05}, {"id": 59, "seek": 19576, "start": 215.76, "end": 220.72, "text": " It keeps growing, you know, like every, every few years we have new vector extensions in", "tokens": [467, 5965, 4194, 11, 291, 458, 11, 411, 633, 11, 633, 1326, 924, 321, 362, 777, 8062, 25129, 294], "temperature": 0.0, "avg_logprob": -0.14116117905597297, "compression_ratio": 1.6437768240343347, "no_speech_prob": 4.979617733624764e-05}, {"id": 60, "seek": 22072, "start": 220.72, "end": 226.4, "text": " Intel or AMD CPUs or even AH64 CPUs, Power 9, et cetera.", "tokens": [19762, 420, 34808, 13199, 82, 420, 754, 25888, 19395, 13199, 82, 11, 7086, 1722, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.1874268523648254, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.0001552743196953088}, {"id": 61, "seek": 22072, "start": 226.4, "end": 232.8, "text": " And it's even worse if you look at the actual CPU models, for example, this is just for", "tokens": [400, 309, 311, 754, 5324, 498, 291, 574, 412, 264, 3539, 13199, 5245, 11, 337, 1365, 11, 341, 307, 445, 337], "temperature": 0.0, "avg_logprob": -0.1874268523648254, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.0001552743196953088}, {"id": 62, "seek": 22072, "start": 232.8, "end": 235.36, "text": " Intel, there's a whole bunch of things.", "tokens": [19762, 11, 456, 311, 257, 1379, 3840, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.1874268523648254, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.0001552743196953088}, {"id": 63, "seek": 22072, "start": 235.36, "end": 241.44, "text": " It's not always a superset of the previous CPU, you know, we're discussing it the other", "tokens": [467, 311, 406, 1009, 257, 37906, 302, 295, 264, 3894, 13199, 11, 291, 458, 11, 321, 434, 10850, 309, 264, 661], "temperature": 0.0, "avg_logprob": -0.1874268523648254, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.0001552743196953088}, {"id": 64, "seek": 22072, "start": 241.44, "end": 242.44, "text": " day for dinner.", "tokens": [786, 337, 6148, 13], "temperature": 0.0, "avg_logprob": -0.1874268523648254, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.0001552743196953088}, {"id": 65, "seek": 22072, "start": 242.44, "end": 244.4, "text": " And yeah, sometimes it's complicated.", "tokens": [400, 1338, 11, 2171, 309, 311, 6179, 13], "temperature": 0.0, "avg_logprob": -0.1874268523648254, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.0001552743196953088}, {"id": 66, "seek": 22072, "start": 244.4, "end": 249.28, "text": " You cannot tell that Skylake AVX is exactly a superset of Skylake.", "tokens": [509, 2644, 980, 300, 9879, 75, 619, 30198, 55, 307, 2293, 257, 37906, 302, 295, 9879, 75, 619, 13], "temperature": 0.0, "avg_logprob": -0.1874268523648254, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.0001552743196953088}, {"id": 67, "seek": 24928, "start": 249.28, "end": 250.8, "text": " It's complicated.", "tokens": [467, 311, 6179, 13], "temperature": 0.0, "avg_logprob": -0.21858685559565477, "compression_ratio": 1.5466101694915255, "no_speech_prob": 8.448788139503449e-05}, {"id": 68, "seek": 24928, "start": 250.8, "end": 255.12, "text": " And yet you want to be able to target these CPUs specifically, these micro-architectures.", "tokens": [400, 1939, 291, 528, 281, 312, 1075, 281, 3779, 613, 13199, 82, 4682, 11, 613, 4532, 12, 1178, 5739, 1303, 13], "temperature": 0.0, "avg_logprob": -0.21858685559565477, "compression_ratio": 1.5466101694915255, "no_speech_prob": 8.448788139503449e-05}, {"id": 69, "seek": 24928, "start": 255.12, "end": 257.68, "text": " And it makes a big deal of a difference.", "tokens": [400, 309, 1669, 257, 955, 2028, 295, 257, 2649, 13], "temperature": 0.0, "avg_logprob": -0.21858685559565477, "compression_ratio": 1.5466101694915255, "no_speech_prob": 8.448788139503449e-05}, {"id": 70, "seek": 24928, "start": 257.68, "end": 260.36, "text": " So this is an example from an Agen benchmark.", "tokens": [407, 341, 307, 364, 1365, 490, 364, 316, 1766, 18927, 13], "temperature": 0.0, "avg_logprob": -0.21858685559565477, "compression_ratio": 1.5466101694915255, "no_speech_prob": 8.448788139503449e-05}, {"id": 71, "seek": 24928, "start": 260.36, "end": 267.52, "text": " So Agen is a C++ library for linear algebra, specifically targeting small matrices.", "tokens": [407, 316, 1766, 307, 257, 383, 25472, 6405, 337, 8213, 21989, 11, 4682, 17918, 1359, 32284, 13], "temperature": 0.0, "avg_logprob": -0.21858685559565477, "compression_ratio": 1.5466101694915255, "no_speech_prob": 8.448788139503449e-05}, {"id": 72, "seek": 24928, "start": 267.52, "end": 272.84, "text": " And well, you know, if on my laptop, if I'm targeting, if I'm compiling with MR equals", "tokens": [400, 731, 11, 291, 458, 11, 498, 322, 452, 10732, 11, 498, 286, 478, 17918, 11, 498, 286, 478, 715, 4883, 365, 9808, 6915], "temperature": 0.0, "avg_logprob": -0.21858685559565477, "compression_ratio": 1.5466101694915255, "no_speech_prob": 8.448788139503449e-05}, {"id": 73, "seek": 27284, "start": 272.84, "end": 279.4, "text": " to Skylake, then I get a throughput that's three times the baseline performance.", "tokens": [281, 9879, 75, 619, 11, 550, 286, 483, 257, 44629, 300, 311, 1045, 1413, 264, 20518, 3389, 13], "temperature": 0.0, "avg_logprob": -0.10937996777621183, "compression_ratio": 1.6332046332046333, "no_speech_prob": 1.5418268958455883e-05}, {"id": 74, "seek": 27284, "start": 279.4, "end": 280.84, "text": " So it's a pretty big deal.", "tokens": [407, 309, 311, 257, 1238, 955, 2028, 13], "temperature": 0.0, "avg_logprob": -0.10937996777621183, "compression_ratio": 1.6332046332046333, "no_speech_prob": 1.5418268958455883e-05}, {"id": 75, "seek": 27284, "start": 280.84, "end": 282.44, "text": " So we definitely want to use that.", "tokens": [407, 321, 2138, 528, 281, 764, 300, 13], "temperature": 0.0, "avg_logprob": -0.10937996777621183, "compression_ratio": 1.6332046332046333, "no_speech_prob": 1.5418268958455883e-05}, {"id": 76, "seek": 27284, "start": 282.44, "end": 289.08, "text": " We want to be able to compile specifically for the CPU micro-architecture that we have.", "tokens": [492, 528, 281, 312, 1075, 281, 31413, 4682, 337, 264, 13199, 4532, 12, 1178, 5739, 540, 300, 321, 362, 13], "temperature": 0.0, "avg_logprob": -0.10937996777621183, "compression_ratio": 1.6332046332046333, "no_speech_prob": 1.5418268958455883e-05}, {"id": 77, "seek": 27284, "start": 289.08, "end": 295.23999999999995, "text": " But so the good news is that to a large extent, that's a solved problem for a long time.", "tokens": [583, 370, 264, 665, 2583, 307, 300, 281, 257, 2416, 8396, 11, 300, 311, 257, 13041, 1154, 337, 257, 938, 565, 13], "temperature": 0.0, "avg_logprob": -0.10937996777621183, "compression_ratio": 1.6332046332046333, "no_speech_prob": 1.5418268958455883e-05}, {"id": 78, "seek": 27284, "start": 295.23999999999995, "end": 302.12, "text": " So there is this thing called function multi-versioning that is already used in a number of performance", "tokens": [407, 456, 307, 341, 551, 1219, 2445, 4825, 12, 29153, 278, 300, 307, 1217, 1143, 294, 257, 1230, 295, 3389], "temperature": 0.0, "avg_logprob": -0.10937996777621183, "compression_ratio": 1.6332046332046333, "no_speech_prob": 1.5418268958455883e-05}, {"id": 79, "seek": 30212, "start": 302.12, "end": 303.12, "text": " critical libraries.", "tokens": [4924, 15148, 13], "temperature": 0.0, "avg_logprob": -0.18533357497184508, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.8024656027555466e-05}, {"id": 80, "seek": 30212, "start": 303.12, "end": 307.52, "text": " So if you look at LeapSea for string comparison, or if you look at OpenBLAST, if you look", "tokens": [407, 498, 291, 574, 412, 1456, 569, 10637, 64, 337, 6798, 9660, 11, 420, 498, 291, 574, 412, 7238, 17624, 20398, 11, 498, 291, 574], "temperature": 0.0, "avg_logprob": -0.18533357497184508, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.8024656027555466e-05}, {"id": 81, "seek": 30212, "start": 307.52, "end": 315.08, "text": " at FFTW, GMP for multi-precision arithmetic, you know, many libraries, programming languages,", "tokens": [412, 479, 25469, 54, 11, 460, 12224, 337, 4825, 12, 3712, 40832, 42973, 11, 291, 458, 11, 867, 15148, 11, 9410, 8650, 11], "temperature": 0.0, "avg_logprob": -0.18533357497184508, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.8024656027555466e-05}, {"id": 82, "seek": 30212, "start": 315.08, "end": 318.56, "text": " runtimes, already use function multi-versioning.", "tokens": [49435, 1532, 11, 1217, 764, 2445, 4825, 12, 29153, 278, 13], "temperature": 0.0, "avg_logprob": -0.18533357497184508, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.8024656027555466e-05}, {"id": 83, "seek": 30212, "start": 318.56, "end": 319.96, "text": " So what's the deal here?", "tokens": [407, 437, 311, 264, 2028, 510, 30], "temperature": 0.0, "avg_logprob": -0.18533357497184508, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.8024656027555466e-05}, {"id": 84, "seek": 30212, "start": 319.96, "end": 324.88, "text": " Well, roughly when you have function multi-versioning, you can say, well, I have one function that", "tokens": [1042, 11, 9810, 562, 291, 362, 2445, 4825, 12, 29153, 278, 11, 291, 393, 584, 11, 731, 11, 286, 362, 472, 2445, 300], "temperature": 0.0, "avg_logprob": -0.18533357497184508, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.8024656027555466e-05}, {"id": 85, "seek": 30212, "start": 324.88, "end": 330.52, "text": " does some linear algebra stuff, for example, and I'm actually providing several variants", "tokens": [775, 512, 8213, 21989, 1507, 11, 337, 1365, 11, 293, 286, 478, 767, 6530, 2940, 21669], "temperature": 0.0, "avg_logprob": -0.18533357497184508, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.8024656027555466e-05}, {"id": 86, "seek": 33052, "start": 330.52, "end": 332.08, "text": " of that function.", "tokens": [295, 300, 2445, 13], "temperature": 0.0, "avg_logprob": -0.10975884945593148, "compression_ratio": 1.6324786324786325, "no_speech_prob": 3.0179115128703415e-05}, {"id": 87, "seek": 33052, "start": 332.08, "end": 337.08, "text": " And when I start my program at runtime, the loader or, you know, the runtime system is", "tokens": [400, 562, 286, 722, 452, 1461, 412, 34474, 11, 264, 3677, 260, 420, 11, 291, 458, 11, 264, 34474, 1185, 307], "temperature": 0.0, "avg_logprob": -0.10975884945593148, "compression_ratio": 1.6324786324786325, "no_speech_prob": 3.0179115128703415e-05}, {"id": 88, "seek": 33052, "start": 337.08, "end": 341.4, "text": " going to pick the most optimized one for the CPU I have at hand, right?", "tokens": [516, 281, 1888, 264, 881, 26941, 472, 337, 264, 13199, 286, 362, 412, 1011, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.10975884945593148, "compression_ratio": 1.6324786324786325, "no_speech_prob": 3.0179115128703415e-05}, {"id": 89, "seek": 33052, "start": 341.4, "end": 347.52, "text": " So if I use GMP, for example, for multi-precision arithmetic, it's going to pick the fastest", "tokens": [407, 498, 286, 764, 460, 12224, 11, 337, 1365, 11, 337, 4825, 12, 3712, 40832, 42973, 11, 309, 311, 516, 281, 1888, 264, 14573], "temperature": 0.0, "avg_logprob": -0.10975884945593148, "compression_ratio": 1.6324786324786325, "no_speech_prob": 3.0179115128703415e-05}, {"id": 90, "seek": 33052, "start": 347.52, "end": 349.88, "text": " implementation it has, you know.", "tokens": [11420, 309, 575, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.10975884945593148, "compression_ratio": 1.6324786324786325, "no_speech_prob": 3.0179115128703415e-05}, {"id": 91, "seek": 33052, "start": 349.88, "end": 355.03999999999996, "text": " So you can compile GMP once, and then it's going to use the writing at runtime.", "tokens": [407, 291, 393, 31413, 460, 12224, 1564, 11, 293, 550, 309, 311, 516, 281, 764, 264, 3579, 412, 34474, 13], "temperature": 0.0, "avg_logprob": -0.10975884945593148, "compression_ratio": 1.6324786324786325, "no_speech_prob": 3.0179115128703415e-05}, {"id": 92, "seek": 35504, "start": 355.04, "end": 360.84000000000003, "text": " And even if you're using GCC or Clang, you can specify in your C code, well, I want this", "tokens": [400, 754, 498, 291, 434, 1228, 460, 11717, 420, 2033, 656, 11, 291, 393, 16500, 294, 428, 383, 3089, 11, 731, 11, 286, 528, 341], "temperature": 0.0, "avg_logprob": -0.14480442575889058, "compression_ratio": 1.5844155844155845, "no_speech_prob": 4.182492193649523e-05}, {"id": 93, "seek": 35504, "start": 360.84000000000003, "end": 367.04, "text": " particular function to be cloned, so to have several variants for each CPU microarchitectures,", "tokens": [1729, 2445, 281, 312, 596, 19009, 11, 370, 281, 362, 2940, 21669, 337, 1184, 13199, 4532, 1178, 5739, 1303, 11], "temperature": 0.0, "avg_logprob": -0.14480442575889058, "compression_ratio": 1.5844155844155845, "no_speech_prob": 4.182492193649523e-05}, {"id": 94, "seek": 35504, "start": 367.04, "end": 371.68, "text": " and GCC or Clang is going to create several variants of that function so that it can pick", "tokens": [293, 460, 11717, 420, 2033, 656, 307, 516, 281, 1884, 2940, 21669, 295, 300, 2445, 370, 300, 309, 393, 1888], "temperature": 0.0, "avg_logprob": -0.14480442575889058, "compression_ratio": 1.5844155844155845, "no_speech_prob": 4.182492193649523e-05}, {"id": 95, "seek": 35504, "start": 371.68, "end": 375.28000000000003, "text": " the right one at runtime.", "tokens": [264, 558, 472, 412, 34474, 13], "temperature": 0.0, "avg_logprob": -0.14480442575889058, "compression_ratio": 1.5844155844155845, "no_speech_prob": 4.182492193649523e-05}, {"id": 96, "seek": 35504, "start": 375.28000000000003, "end": 381.28000000000003, "text": " So kind of a solved problem, in a way, well, except in some cases.", "tokens": [407, 733, 295, 257, 13041, 1154, 11, 294, 257, 636, 11, 731, 11, 3993, 294, 512, 3331, 13], "temperature": 0.0, "avg_logprob": -0.14480442575889058, "compression_ratio": 1.5844155844155845, "no_speech_prob": 4.182492193649523e-05}, {"id": 97, "seek": 38128, "start": 381.28, "end": 388.76, "text": " Well, one particular case where we have a problem is C++ template libraries, like Agen,", "tokens": [1042, 11, 472, 1729, 1389, 689, 321, 362, 257, 1154, 307, 383, 25472, 12379, 15148, 11, 411, 316, 1766, 11], "temperature": 0.0, "avg_logprob": -0.17425663160241167, "compression_ratio": 1.6104868913857677, "no_speech_prob": 3.474545155768283e-05}, {"id": 98, "seek": 38128, "start": 388.76, "end": 394.52, "text": " which I was mentioning before, they are not able to benefit from function multi-versioning", "tokens": [597, 286, 390, 18315, 949, 11, 436, 366, 406, 1075, 281, 5121, 490, 2445, 4825, 12, 29153, 278], "temperature": 0.0, "avg_logprob": -0.17425663160241167, "compression_ratio": 1.6104868913857677, "no_speech_prob": 3.474545155768283e-05}, {"id": 99, "seek": 38128, "start": 394.52, "end": 395.52, "text": " in any way.", "tokens": [294, 604, 636, 13], "temperature": 0.0, "avg_logprob": -0.17425663160241167, "compression_ratio": 1.6104868913857677, "no_speech_prob": 3.474545155768283e-05}, {"id": 100, "seek": 38128, "start": 395.52, "end": 401.03999999999996, "text": " So when you compile your Agen benchmark, well, you really have to use mRch equals to Skylake,", "tokens": [407, 562, 291, 31413, 428, 316, 1766, 18927, 11, 731, 11, 291, 534, 362, 281, 764, 275, 49, 339, 6915, 281, 9879, 75, 619, 11], "temperature": 0.0, "avg_logprob": -0.17425663160241167, "compression_ratio": 1.6104868913857677, "no_speech_prob": 3.474545155768283e-05}, {"id": 101, "seek": 38128, "start": 401.03999999999996, "end": 404.67999999999995, "text": " for example, if you were targeting a Skylake CPU.", "tokens": [337, 1365, 11, 498, 291, 645, 17918, 257, 9879, 75, 619, 13199, 13], "temperature": 0.0, "avg_logprob": -0.17425663160241167, "compression_ratio": 1.6104868913857677, "no_speech_prob": 3.474545155768283e-05}, {"id": 102, "seek": 38128, "start": 404.67999999999995, "end": 409.4, "text": " And this is because if you look at Agen headers, for example, where there are many places where", "tokens": [400, 341, 307, 570, 498, 291, 574, 412, 316, 1766, 45101, 11, 337, 1365, 11, 689, 456, 366, 867, 3190, 689], "temperature": 0.0, "avg_logprob": -0.17425663160241167, "compression_ratio": 1.6104868913857677, "no_speech_prob": 3.474545155768283e-05}, {"id": 103, "seek": 40940, "start": 409.4, "end": 414.76, "text": " you have if depths, do I have AVX 512 at compilation time?", "tokens": [291, 362, 498, 28439, 11, 360, 286, 362, 30198, 55, 1025, 4762, 412, 40261, 565, 30], "temperature": 0.0, "avg_logprob": -0.19756758316703465, "compression_ratio": 1.7791666666666666, "no_speech_prob": 3.3106825867434964e-05}, {"id": 104, "seek": 40940, "start": 414.76, "end": 418.44, "text": " If yes, then I'm going to use the optimized implementation, otherwise, I'm going to use", "tokens": [759, 2086, 11, 550, 286, 478, 516, 281, 764, 264, 26941, 11420, 11, 5911, 11, 286, 478, 516, 281, 764], "temperature": 0.0, "avg_logprob": -0.19756758316703465, "compression_ratio": 1.7791666666666666, "no_speech_prob": 3.3106825867434964e-05}, {"id": 105, "seek": 40940, "start": 418.44, "end": 420.64, "text": " the baseline implementation.", "tokens": [264, 20518, 11420, 13], "temperature": 0.0, "avg_logprob": -0.19756758316703465, "compression_ratio": 1.7791666666666666, "no_speech_prob": 3.3106825867434964e-05}, {"id": 106, "seek": 40940, "start": 420.64, "end": 425.4, "text": " And this is all happening at compilation time, so you really have to have a solution at compilation", "tokens": [400, 341, 307, 439, 2737, 412, 40261, 565, 11, 370, 291, 534, 362, 281, 362, 257, 3827, 412, 40261], "temperature": 0.0, "avg_logprob": -0.19756758316703465, "compression_ratio": 1.7791666666666666, "no_speech_prob": 3.3106825867434964e-05}, {"id": 107, "seek": 40940, "start": 425.4, "end": 428.35999999999996, "text": " time to address this.", "tokens": [565, 281, 2985, 341, 13], "temperature": 0.0, "avg_logprob": -0.19756758316703465, "compression_ratio": 1.7791666666666666, "no_speech_prob": 3.3106825867434964e-05}, {"id": 108, "seek": 40940, "start": 428.35999999999996, "end": 431.79999999999995, "text": " And so this is where Geeks comes in.", "tokens": [400, 370, 341, 307, 689, 2876, 24785, 1487, 294, 13], "temperature": 0.0, "avg_logprob": -0.19756758316703465, "compression_ratio": 1.7791666666666666, "no_speech_prob": 3.3106825867434964e-05}, {"id": 109, "seek": 40940, "start": 431.79999999999995, "end": 436.35999999999996, "text": " So Geeks is, you know, it's a distribution, like Debian, like I was saying, that's targeting", "tokens": [407, 2876, 24785, 307, 11, 291, 458, 11, 309, 311, 257, 7316, 11, 411, 1346, 20196, 11, 411, 286, 390, 1566, 11, 300, 311, 17918], "temperature": 0.0, "avg_logprob": -0.19756758316703465, "compression_ratio": 1.7791666666666666, "no_speech_prob": 3.3106825867434964e-05}, {"id": 110, "seek": 43636, "start": 436.36, "end": 442.36, "text": " the baseline instruction set, but we came up with a new thing that's called package multi-versioning.", "tokens": [264, 20518, 10951, 992, 11, 457, 321, 1361, 493, 365, 257, 777, 551, 300, 311, 1219, 7372, 4825, 12, 29153, 278, 13], "temperature": 0.0, "avg_logprob": -0.17575408417044333, "compression_ratio": 1.62890625, "no_speech_prob": 3.937021756428294e-05}, {"id": 111, "seek": 43636, "start": 442.36, "end": 447.84000000000003, "text": " It's actually one year old or something, which is roughly the idea is taking the same idea", "tokens": [467, 311, 767, 472, 1064, 1331, 420, 746, 11, 597, 307, 9810, 264, 1558, 307, 1940, 264, 912, 1558], "temperature": 0.0, "avg_logprob": -0.17575408417044333, "compression_ratio": 1.62890625, "no_speech_prob": 3.937021756428294e-05}, {"id": 112, "seek": 43636, "start": 447.84000000000003, "end": 454.32, "text": " of function as function multi-versioning, but applying it at the level of entire packages.", "tokens": [295, 2445, 382, 2445, 4825, 12, 29153, 278, 11, 457, 9275, 309, 412, 264, 1496, 295, 2302, 17401, 13], "temperature": 0.0, "avg_logprob": -0.17575408417044333, "compression_ratio": 1.62890625, "no_speech_prob": 3.937021756428294e-05}, {"id": 113, "seek": 43636, "start": 454.32, "end": 461.08000000000004, "text": " So let's say I have those Agen benchmarks, I can run them using just the baseline X8664", "tokens": [407, 718, 311, 584, 286, 362, 729, 316, 1766, 43751, 11, 286, 393, 1190, 552, 1228, 445, 264, 20518, 1783, 22193, 19395], "temperature": 0.0, "avg_logprob": -0.17575408417044333, "compression_ratio": 1.62890625, "no_speech_prob": 3.937021756428294e-05}, {"id": 114, "seek": 43636, "start": 461.08000000000004, "end": 464.16, "text": " architecture, using this Geeks shell command.", "tokens": [9482, 11, 1228, 341, 2876, 24785, 8720, 5622, 13], "temperature": 0.0, "avg_logprob": -0.17575408417044333, "compression_ratio": 1.62890625, "no_speech_prob": 3.937021756428294e-05}, {"id": 115, "seek": 46416, "start": 464.16, "end": 469.76000000000005, "text": " It's, you know, it's taking the Agen benchmarks package, and in that package running the Bench", "tokens": [467, 311, 11, 291, 458, 11, 309, 311, 1940, 264, 316, 1766, 43751, 7372, 11, 293, 294, 300, 7372, 2614, 264, 3964, 339], "temperature": 0.0, "avg_logprob": -0.2535004451357085, "compression_ratio": 1.541871921182266, "no_speech_prob": 8.436550706392154e-05}, {"id": 116, "seek": 46416, "start": 469.76000000000005, "end": 475.12, "text": " plus gem command, right, on a small matrix.", "tokens": [1804, 7173, 5622, 11, 558, 11, 322, 257, 1359, 8141, 13], "temperature": 0.0, "avg_logprob": -0.2535004451357085, "compression_ratio": 1.541871921182266, "no_speech_prob": 8.436550706392154e-05}, {"id": 117, "seek": 46416, "start": 475.12, "end": 481.16, "text": " And then I can say, all right, now I want to tune that code specifically for my CPU,", "tokens": [400, 550, 286, 393, 584, 11, 439, 558, 11, 586, 286, 528, 281, 10864, 300, 3089, 4682, 337, 452, 13199, 11], "temperature": 0.0, "avg_logprob": -0.2535004451357085, "compression_ratio": 1.541871921182266, "no_speech_prob": 8.436550706392154e-05}, {"id": 118, "seek": 46416, "start": 481.16, "end": 488.24, "text": " and then I just put that extra, that extra dash dash tune option, and it's selling Geeks,", "tokens": [293, 550, 286, 445, 829, 300, 2857, 11, 300, 2857, 8240, 8240, 10864, 3614, 11, 293, 309, 311, 6511, 2876, 24785, 11], "temperature": 0.0, "avg_logprob": -0.2535004451357085, "compression_ratio": 1.541871921182266, "no_speech_prob": 8.436550706392154e-05}, {"id": 119, "seek": 48824, "start": 488.24, "end": 495.2, "text": " all right, please optimize that Agen benchmarks package directly for the CPU I'm on, which", "tokens": [439, 558, 11, 1767, 19719, 300, 316, 1766, 43751, 7372, 3838, 337, 264, 13199, 286, 478, 322, 11, 597], "temperature": 0.0, "avg_logprob": -0.18863967820709826, "compression_ratio": 1.7198275862068966, "no_speech_prob": 3.876954360748641e-05}, {"id": 120, "seek": 48824, "start": 495.2, "end": 499.24, "text": " is Skylake in this case, and this is it.", "tokens": [307, 9879, 75, 619, 294, 341, 1389, 11, 293, 341, 307, 309, 13], "temperature": 0.0, "avg_logprob": -0.18863967820709826, "compression_ratio": 1.7198275862068966, "no_speech_prob": 3.876954360748641e-05}, {"id": 121, "seek": 48824, "start": 499.24, "end": 503.56, "text": " And what happens behind the scenes is that on the flag, Geeks is creating a new package", "tokens": [400, 437, 2314, 2261, 264, 8026, 307, 300, 322, 264, 7166, 11, 2876, 24785, 307, 4084, 257, 777, 7372], "temperature": 0.0, "avg_logprob": -0.18863967820709826, "compression_ratio": 1.7198275862068966, "no_speech_prob": 3.876954360748641e-05}, {"id": 122, "seek": 48824, "start": 503.56, "end": 504.56, "text": " variant.", "tokens": [17501, 13], "temperature": 0.0, "avg_logprob": -0.18863967820709826, "compression_ratio": 1.7198275862068966, "no_speech_prob": 3.876954360748641e-05}, {"id": 123, "seek": 48824, "start": 504.56, "end": 509.8, "text": " So it's taking that Agen benchmarks package, creating a new package variant that is built", "tokens": [407, 309, 311, 1940, 300, 316, 1766, 43751, 7372, 11, 4084, 257, 777, 7372, 17501, 300, 307, 3094], "temperature": 0.0, "avg_logprob": -0.18863967820709826, "compression_ratio": 1.7198275862068966, "no_speech_prob": 3.876954360748641e-05}, {"id": 124, "seek": 48824, "start": 509.8, "end": 516.96, "text": " specifically with a compiler wrapper that passes the MRT equals to Skylake flag.", "tokens": [4682, 365, 257, 31958, 46906, 300, 11335, 264, 9808, 51, 6915, 281, 9879, 75, 619, 7166, 13], "temperature": 0.0, "avg_logprob": -0.18863967820709826, "compression_ratio": 1.7198275862068966, "no_speech_prob": 3.876954360748641e-05}, {"id": 125, "seek": 51696, "start": 516.96, "end": 523.6, "text": " And I get the performance, and I'm happy, right, so this is in Geeks since 2022, and", "tokens": [400, 286, 483, 264, 3389, 11, 293, 286, 478, 2055, 11, 558, 11, 370, 341, 307, 294, 2876, 24785, 1670, 20229, 11, 293], "temperature": 0.0, "avg_logprob": -0.17217406288522188, "compression_ratio": 1.768, "no_speech_prob": 7.123022805899382e-05}, {"id": 126, "seek": 51696, "start": 523.6, "end": 528.36, "text": " it's still reproducible, you know, because we can still say, all right, what precise option", "tokens": [309, 311, 920, 11408, 32128, 11, 291, 458, 11, 570, 321, 393, 920, 584, 11, 439, 558, 11, 437, 13600, 3614], "temperature": 0.0, "avg_logprob": -0.17217406288522188, "compression_ratio": 1.768, "no_speech_prob": 7.123022805899382e-05}, {"id": 127, "seek": 51696, "start": 528.36, "end": 533.12, "text": " did I use, what dash dash tune option did I use, and it's Skylake, all right, so the", "tokens": [630, 286, 764, 11, 437, 8240, 8240, 10864, 3614, 630, 286, 764, 11, 293, 309, 311, 9879, 75, 619, 11, 439, 558, 11, 370, 264], "temperature": 0.0, "avg_logprob": -0.17217406288522188, "compression_ratio": 1.768, "no_speech_prob": 7.123022805899382e-05}, {"id": 128, "seek": 51696, "start": 533.12, "end": 537.96, "text": " build process of the package remains reproducible, right, I'm still getting the same binary if", "tokens": [1322, 1399, 295, 264, 7372, 7023, 11408, 32128, 11, 558, 11, 286, 478, 920, 1242, 264, 912, 17434, 498], "temperature": 0.0, "avg_logprob": -0.17217406288522188, "compression_ratio": 1.768, "no_speech_prob": 7.123022805899382e-05}, {"id": 129, "seek": 51696, "start": 537.96, "end": 545.8000000000001, "text": " I use dash dash tune equals to Skylake on my laptop or on some HPC cluster, whatever.", "tokens": [286, 764, 8240, 8240, 10864, 6915, 281, 9879, 75, 619, 322, 452, 10732, 420, 322, 512, 12557, 34, 13630, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.17217406288522188, "compression_ratio": 1.768, "no_speech_prob": 7.123022805899382e-05}, {"id": 130, "seek": 54580, "start": 545.8, "end": 550.0, "text": " And there are no world rebuilds, which means that the build farm, for example, the official", "tokens": [400, 456, 366, 572, 1002, 16877, 82, 11, 597, 1355, 300, 264, 1322, 5421, 11, 337, 1365, 11, 264, 4783], "temperature": 0.0, "avg_logprob": -0.1733066588640213, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.903863686602563e-05}, {"id": 131, "seek": 54580, "start": 550.0, "end": 556.28, "text": " build farm of the project is providing several variants of those packages, those, you know,", "tokens": [1322, 5421, 295, 264, 1716, 307, 6530, 2940, 21669, 295, 729, 17401, 11, 729, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1733066588640213, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.903863686602563e-05}, {"id": 132, "seek": 54580, "start": 556.28, "end": 561.4799999999999, "text": " performance sensitive packages built for Skylake, Skylake, AVX, 512, you know, different things.", "tokens": [3389, 9477, 17401, 3094, 337, 9879, 75, 619, 11, 9879, 75, 619, 11, 30198, 55, 11, 1025, 4762, 11, 291, 458, 11, 819, 721, 13], "temperature": 0.0, "avg_logprob": -0.1733066588640213, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.903863686602563e-05}, {"id": 133, "seek": 54580, "start": 561.4799999999999, "end": 566.56, "text": " So if you install them, most likely you're going to get a pre-built binary that's specifically", "tokens": [407, 498, 291, 3625, 552, 11, 881, 3700, 291, 434, 516, 281, 483, 257, 659, 12, 23018, 17434, 300, 311, 4682], "temperature": 0.0, "avg_logprob": -0.1733066588640213, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.903863686602563e-05}, {"id": 134, "seek": 54580, "start": 566.56, "end": 568.64, "text": " optimized for that CPU.", "tokens": [26941, 337, 300, 13199, 13], "temperature": 0.0, "avg_logprob": -0.1733066588640213, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.903863686602563e-05}, {"id": 135, "seek": 54580, "start": 568.64, "end": 574.5999999999999, "text": " And if not, well, that's fine, it's going to be to build it for you, that's okay.", "tokens": [400, 498, 406, 11, 731, 11, 300, 311, 2489, 11, 309, 311, 516, 281, 312, 281, 1322, 309, 337, 291, 11, 300, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.1733066588640213, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.903863686602563e-05}, {"id": 136, "seek": 57460, "start": 574.6, "end": 582.2, "text": " So my conclusion here is, you know, we keep talking about performance of MPI, vector instruction", "tokens": [407, 452, 10063, 510, 307, 11, 291, 458, 11, 321, 1066, 1417, 466, 3389, 295, 14146, 40, 11, 8062, 10951], "temperature": 0.0, "avg_logprob": -0.2014502395283092, "compression_ratio": 1.702970297029703, "no_speech_prob": 3.9359889342449605e-05}, {"id": 137, "seek": 57460, "start": 582.2, "end": 583.2, "text": " and so forth.", "tokens": [293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.2014502395283092, "compression_ratio": 1.702970297029703, "no_speech_prob": 3.9359889342449605e-05}, {"id": 138, "seek": 57460, "start": 583.2, "end": 587.6800000000001, "text": " Well, I think we can have performance, we can have portable performance, that's what", "tokens": [1042, 11, 286, 519, 321, 393, 362, 3389, 11, 321, 393, 362, 21800, 3389, 11, 300, 311, 437], "temperature": 0.0, "avg_logprob": -0.2014502395283092, "compression_ratio": 1.702970297029703, "no_speech_prob": 3.9359889342449605e-05}, {"id": 139, "seek": 57460, "start": 587.6800000000001, "end": 593.8000000000001, "text": " we should aim for, and we can still have reproducibility, we don't have to sacrifice reproducibility", "tokens": [321, 820, 5939, 337, 11, 293, 321, 393, 920, 362, 11408, 537, 39802, 11, 321, 500, 380, 362, 281, 11521, 11408, 537, 39802], "temperature": 0.0, "avg_logprob": -0.2014502395283092, "compression_ratio": 1.702970297029703, "no_speech_prob": 3.9359889342449605e-05}, {"id": 140, "seek": 57460, "start": 593.8000000000001, "end": 597.12, "text": " for performance, that's my take on the message.", "tokens": [337, 3389, 11, 300, 311, 452, 747, 322, 264, 3636, 13], "temperature": 0.0, "avg_logprob": -0.2014502395283092, "compression_ratio": 1.702970297029703, "no_speech_prob": 3.9359889342449605e-05}, {"id": 141, "seek": 59712, "start": 597.12, "end": 605.0, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.2664249275304094, "compression_ratio": 1.4387755102040816, "no_speech_prob": 0.0016353890532627702}, {"id": 142, "seek": 59712, "start": 605.0, "end": 606.0, "text": " Thank you very much.", "tokens": [1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.2664249275304094, "compression_ratio": 1.4387755102040816, "no_speech_prob": 0.0016353890532627702}, {"id": 143, "seek": 59712, "start": 606.0, "end": 608.84, "text": " Again, time for one question.", "tokens": [3764, 11, 565, 337, 472, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2664249275304094, "compression_ratio": 1.4387755102040816, "no_speech_prob": 0.0016353890532627702}, {"id": 144, "seek": 59712, "start": 608.84, "end": 614.64, "text": " Okay, yeah, this whole dash tune thing looks awesome.", "tokens": [1033, 11, 1338, 11, 341, 1379, 8240, 10864, 551, 1542, 3476, 13], "temperature": 0.0, "avg_logprob": -0.2664249275304094, "compression_ratio": 1.4387755102040816, "no_speech_prob": 0.0016353890532627702}, {"id": 145, "seek": 59712, "start": 614.64, "end": 618.84, "text": " But what if the majority of the computation time is spent in libraries that that library", "tokens": [583, 437, 498, 264, 6286, 295, 264, 24903, 565, 307, 4418, 294, 15148, 300, 300, 6405], "temperature": 0.0, "avg_logprob": -0.2664249275304094, "compression_ratio": 1.4387755102040816, "no_speech_prob": 0.0016353890532627702}, {"id": 146, "seek": 59712, "start": 618.84, "end": 620.0, "text": " is actually using?", "tokens": [307, 767, 1228, 30], "temperature": 0.0, "avg_logprob": -0.2664249275304094, "compression_ratio": 1.4387755102040816, "no_speech_prob": 0.0016353890532627702}, {"id": 147, "seek": 59712, "start": 620.0, "end": 622.96, "text": " How do I tell it to optimize those instead as well?", "tokens": [1012, 360, 286, 980, 309, 281, 19719, 729, 2602, 382, 731, 30], "temperature": 0.0, "avg_logprob": -0.2664249275304094, "compression_ratio": 1.4387755102040816, "no_speech_prob": 0.0016353890532627702}, {"id": 148, "seek": 59712, "start": 622.96, "end": 623.96, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2664249275304094, "compression_ratio": 1.4387755102040816, "no_speech_prob": 0.0016353890532627702}, {"id": 149, "seek": 62396, "start": 623.96, "end": 629.52, "text": " So the way it works in Geeks, you can annotate packages that really need to be tunable, right?", "tokens": [407, 264, 636, 309, 1985, 294, 2876, 24785, 11, 291, 393, 25339, 473, 17401, 300, 534, 643, 281, 312, 4267, 712, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.24719569796607607, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0007623908459208906}, {"id": 150, "seek": 62396, "start": 629.52, "end": 633.6800000000001, "text": " So you can add a property to a package like, so it would be egg and benchmarks in this", "tokens": [407, 291, 393, 909, 257, 4707, 281, 257, 7372, 411, 11, 370, 309, 576, 312, 3777, 293, 43751, 294, 341], "temperature": 0.0, "avg_logprob": -0.24719569796607607, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0007623908459208906}, {"id": 151, "seek": 62396, "start": 633.6800000000001, "end": 638.64, "text": " case where it could be the GNU Scientific Library, GSL, and you said this package needs", "tokens": [1389, 689, 309, 727, 312, 264, 46411, 52, 47437, 12806, 11, 32047, 43, 11, 293, 291, 848, 341, 7372, 2203], "temperature": 0.0, "avg_logprob": -0.24719569796607607, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0007623908459208906}, {"id": 152, "seek": 62396, "start": 638.64, "end": 643.9200000000001, "text": " to be tunable, so if I use dash, dash, tune, please tune specifically this package.", "tokens": [281, 312, 4267, 712, 11, 370, 498, 286, 764, 8240, 11, 8240, 11, 10864, 11, 1767, 10864, 4682, 341, 7372, 13], "temperature": 0.0, "avg_logprob": -0.24719569796607607, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0007623908459208906}, {"id": 153, "seek": 62396, "start": 643.9200000000001, "end": 648.0400000000001, "text": " And it's going to work even if you're installing, you know, an application that actually depends", "tokens": [400, 309, 311, 516, 281, 589, 754, 498, 291, 434, 20762, 11, 291, 458, 11, 364, 3861, 300, 767, 5946], "temperature": 0.0, "avg_logprob": -0.24719569796607607, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0007623908459208906}, {"id": 154, "seek": 62396, "start": 648.0400000000001, "end": 650.84, "text": " on GSL, for example.", "tokens": [322, 32047, 43, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.24719569796607607, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0007623908459208906}, {"id": 155, "seek": 65084, "start": 650.84, "end": 654.44, "text": " All right, thanks a lot Ludovic.", "tokens": [1057, 558, 11, 3231, 257, 688, 30550, 5179, 299, 13], "temperature": 0.0, "avg_logprob": -0.4222350742505944, "compression_ratio": 1.1020408163265305, "no_speech_prob": 0.011984070762991905}, {"id": 156, "seek": 65084, "start": 654.44, "end": 655.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.4222350742505944, "compression_ratio": 1.1020408163265305, "no_speech_prob": 0.011984070762991905}, {"id": 157, "seek": 65544, "start": 655.44, "end": 681.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.9625262532915387, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.00013688723265659064}], "language": "en"}