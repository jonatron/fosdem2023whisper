{"text": " So, we're ready for our next talk. Alex is going to talk about the new file system that they're proposing, ComposerVest, and opportunistically sharing verified image file system. Thank you. All right. Thank you. Can you hear me? Yeah. All right. All right. I'm Alex. You may also know me from hits such as Flatpak, FlatHub, GNOME, GTK, all such a stuff. But this here is my first kernel file system, which I proposed on the list a couple of months ago. It's not actually like a file system, a real file system. It's more targeted for read-only images such that you would typically have many of them running on the system. Maybe in a container host or in my case, my primary concern is the OSTree verified boot use case. So rather than talking about ComposeFS first, I'm going to talk about OSTree because it kind of explains where this comes from. So in OSTree, we have images. Normally the images are not simple like this, but actually the full-root file system for your boot system that you want to boot. But they're used to a bunch of files, and they have metadata and permissions and names and whatnot. So they're basically images. And we have this repository format, which is the core format of OSTree. And what we do is we take all the files, like the regular files, in the image, and we hash them. And we store them by the hash name in this repository format. So if you look at any of those files, they're just the same file with the name of their own content. And then we take all the directories we have, such as the sub-dir thing, and we make a small descriptor of them, the names of the file in there, their permissions and whatnot, and a reference to the content of the file by the checksum. And we do the same for the root directory. And this time, we refer to the sub-director by the checksum of the descriptor. And then we add a final commit description, which describes, well, it has a pointer, meaning the checksum of the root directory, and a parent doesn't have a parent, because this is the first commit, some metadata. And then we add the breaths file, which is basically just a file that says, we have a branch called image, and this is the current head. So if anyone thinks this looks like the.get directory in any of your checkouts, that's true. It's basically get for operating systems. There are some details in exactly how the object files are stored, but basically, the entire structure is get, right, just a copy of get. And you can see even more clearly, if you create a new commit, the new version, we added the readme. So all we have to do is add the file, the new root directory, and the new commit that points to the previous one, and then we update the ref to the latest head. So basically, re-implementing get for large binary trees. But you can't use this directly, like you can't boot from a repository like this. So what you do, deploy, we call it deploy, when we run a new version of something, typically you have a pre-existing version, so download the new version of the thing you want to run, which is very simple, because you can just iterate over these recursive descriptions of the image, and whenever you have a reference to an object you already have downloaded, you can just stop because recursively you know you have all the previous things, so it's very efficient to get the new version. And then we create a deploy directory, which is basically a hard-linked form that points back into the objects, like the regular file objects. So we create the directories for the right permissions and whatnot, and whenever there's a regular file, we just point it at the file, the same file, by using a hard-link to the one in the repository. And then we somehow set some boot configuration that points to this particular commit, which names this directory, and somewhere in the Unitardee we find this directory, bind-monit, read-only on the root, on top of the root, and then we boot into that. And there are some clear advantages over this over what would be the alternative, which is the traditional AB, like block device, you have two block devices, then you flash new image on B, and then you boot into B. First of all, it's very easy to do efficient downloads, and like deltas are very small. You can easily store however many versions of things you want, whether they're related or not, like if it's multiple versions of the same branch. You can keep the last 10 or whatever, plus you can also have completely unrelated, you can have botan, fedora, nrl, or debbian or whatever, and you can easily switch between them atomically. And all the updates are atomical, we never modify an existing thing that you're running, we always create a new deploy directory, and we boot into that. And also the format is very, it's very, very viable, like it's recursively describing itself, and all you need is the signature, and there's a GPG signature on the commit object. So if you trust the commit object, you trust the root hash, which you trust the hash of the subdirectories and the files and what not. The problem that I want to address is that this doesn't do runtime verification, like we verify, when we download things, we can verify when we do the deploy or rather like the fact that we're deploying, it's going to cause us to verify things. But if after some point after that something modifies, say we have a random bit flip on the disk, or we have a malicious, like, evil made style attack, someone could easily just remove or modify a file in the deploy directory. And to protect against this, the kernel has two features, de-inverity and fsverity. De-inverity is what you use in the typical ABE image system, because it's block-based, but it's completely a read-only block device, there's no way we can do OSTry-like updates to its file system, you just cannot write to it. So the other thing is fsverity, and fsverity sort of matches very well with the OSTry repository format, because if you enable fsverity on a particular file, it essentially makes it immutable. And immutable is exactly what these things, content the rest files are, so it's good. But the problem is that fsverity doesn't go all the way, it only protects the content of the file, while you can easily make it set UID or replace it with a different one that has a different fsverity, or just add a new file or whatever. So it doesn't protect structure. So that's why ComposeFS was created, to have another layer that does the structure. And now I'm sort of going away from the OSTry use case, and this is the native way to use ComposeFS, where you just have a directory with some data, this is the same kind of example that I had in the repository format, and you just run mkcomposeFS on that directory, and it creates this image file that contains all the metadata for the structure of the thing. And this objects directory, which is just copies of these files stored by their fsverity commit, or fsverity digest. And they obviously use pure files, you can cat them, and they're just regular files with the same contents. They're actually pure data files, you can see they don't have like the executable rights or if you have some complex metadata, extended attributes or whatever, these are just regular files with content. And then you mount the thing using ComposeFS, pointing it at this objects directory, and then you get a reproduction of the original image that you can look at. Whatever you cat this, it will just do overlay fsstyle stacking, read the backing file. So everything is always from the page cache, and also the actual mount is not a loopback mount, we just do stacking style, direct access of the file from the page cache. So that gives you the general ability to reproduce this image, but to get the fsverity or complete structural verification, you actually use fsverity on the descriptor itself. So if you enable safe as in that, that makes it immutable, so the file system cannot change or the file can't change on the file system, at least the kernel API doesn't allow you and if it's somehow otherwise modified on disk or whatnot, it will detect it. And you can see like, I actually passed the digest, the expected digest, and whenever it mounts it, it starts by verifying before it does any IO, does it actually have the expected fsverity digest? And if so, we can rely on the kernel to basically do all our verification from us, and if you replace something, we have in the metadata for all these backing files, the expected verity digest. So if you replace something, or if there's a random bit flip, it will detect it. And actually the descriptor itself is very simple, like this is not a traditional file system where we have to update things at run time, we can just compute a very simple descriptor of this. It's basically a fixed-size header followed by a table of fixed-size INO data, like if the file system has N and INOs, then there are N copies of that structure, and some of them point into the variable-size data at the end, which we found with the VData offset in the header, and that's basically all there is to it, right? We can, INO zero is the root file system, or is the root INODE, you can look at that, and you can, if it's a type directory, then the variable data points to a table of dirants, which is basically a pre-sorted table of dirants plus names, that you use binary search, you get a new INO, then you just look at that offset, and all this is just done by mapping the page cache directly. So it's very simple in terms of structure. If you want to use this actually with OSTree, it's slightly different, like we can't just, we don't want to take the OSTree repository, create this directory, and then run MKComposeFS on it. Instead, we ship a library, LibComposeFS, where you basically link OSTree with this library, and it can generate these images directly from the metadata that exists in the repository. So we don't have to do any kind of expensive IO to create these images, because it's just the metadata, right? It's not very large. You can put it on into memory, generate these, optimize them, and just write a single file, and the way we can do it, it's very flexible, so we can ensure that we can use the existing repository for the backing files. And it's also designed so that it's a standardized way. We put everything, so every time you create a new image based on the same OSTree commit, we will be creating the exact same binary file, bit by bit. So what you do is that when you create the commit on the server, you basically generate one of these, take the digest of it, like the F is very digest of it, put it in the assigned commit, and then whenever you recreate, there's no need to extend the OSTree format on the network or anything, what you do is when you deploy a commit, instead of making this hardling farm, you recreate one of these, and then you use the supply digest as the expected digest when you mount it, so if anything anywhere went wrong or was attacked or whatever, it will refuse to mount it. So obviously you have to put that trusted digest somewhere in your secure boot stack or whatever, something would have to, it has to be trusted, but that's outside exactly of the scope of ComposeFS, and it's very similar to what you would do with DMVarity in a pure image based system. But another interesting use case is the container use case, and Giuseppe, who is not here actually, but he is one of the other people behind the ComposeFS developers, he is more, he's one of the podmem developers, so his use case is to use this for containers, because containers are also used in images, right, and it would be nice if we can get this very, what I call opportunistic sharing of files, like if you use layers and stuff, you can sort of share stuff between different containers, but you have to manually ensure you do the right thing, whereas with this opportunistic style of sharing, whenever you happen to have a file that is identical, it just automatically gets shared, both on disk and in page cache, because of the way these things work. So we also don't want to change the container format, there was a talk yesterday about using DMVarity in SquashFS, for, it's not sharing, but like the similar kind of way you can mount an image, but we don't want to, that forces all the users to create a new form of container, but we want to use, allow this for all existing, tarble based layered BOSIAI images. So an image in the OSIAI world is a list of tarbles that you extract in order, and then you're mounting using over the AFS. There is an extension of this called ETAR, ETARGC, which is some weird ass hack where you put an index at the end of the G-SIP, and then you can use partial HTTP downloads to just get the index, and you can see which part of the layer you already have, and you can just range HTTP gets to only download those parts. So if you happen to have one of those archives in your layers, we can in combination with the locally stored content of the storage, avoid downloading the parts that we don't need. If you don't have them, we have to download everything, which is what we do now, but we can do better. But even then, you can still hash them locally and get all the sharing, and then you combine this with creating an overly composed FS for the entire image, so you mount, this is for the local storage of images, you can use, instead of storing these layers, you store the repository, or content store repository, plus these generated composed FS images, and then whenever you run this, you just mount it, and it goes. It's also nice, you can easily combine all the layers, so if you have a 10-layer container, and you want to resolve libc, which is in the base layer, you have to do a negative entry lookup in every layer before you reach the bottom most, but since the image is metadata, it's very cheap to create a completely squashed composed FS image for single-layer lookups. And I don't know if anyone is following the list, but there are some discussions about this. We're trying to get it merged upstream, and one alternative has appeared, that there's ways that you can actually use some of overlay FS features to sort of get these features. If you use the not super well-known or documented features called overlay redirect and overlay meta-copy, you can create an overlay FS layer that does a similar style of here or the metadata for this attribute redirected to a different path, which would be the content address name in the lower layer, and then you can use some kind of read-only file system for the upper layer where you store all these extended attribute files that just contain this structure. So this combination of overlay FS plus right now ERO FS is probably the best approach for those for the upper layer. You can sort of create this. Unfortunately, that doesn't do the verification. You can use the overlay or read-only file system itself, but you need some kind of extension to overlay itself to allow this recording of the expected FS variety of the backing file. But that does seem like a trivial thing. The less trivial part, and this is where opinions on the list vary, is I think this kind of combination of things is way more complicated than the simple one. Compose FS is, I think, 1,800 lines of code. It's very direct. It doesn't use loopback devices, device wrapper devices. When you do a lookup in this combined thing of a particular file, you would do a lookup in the overlay layer in the read-only system and in all the backing layers. So there's like four times more inodes around, there's four times more decash lookups, and it just uses more memory and performs worse. So I ran some simple lookups. These are just some people complain about the measurements here. I'm just comparing like a recursive find or LSDTR, which is basically just measuring the performance of lookups and readers. But on the other hand, that's all that Compose FS does. I mean, all the actual IO performance is left to the backing file system. So wherever you store your read files, that's where like streaming performance and things like that would appear. So I'm personally in the automotive use case right now, so we have very harsh requirements on cool boot performance, so the cold cache numbers are very important to me. I mean, you might not, this is like listing recursively a large developer snapshot, like a three gigabyte Centro Stream 9 image. So it's not an operation you might do, but just looking at the numbers, the recursive listing is more than like three times slower for the cold cache situation, because it has to do multiple lookups. And even for the cached case, where most things should be from the decad anyway, I think I've seen better numbers than this, but there's at least 10% difference in the warm cache situation. I hope that was useful to do something on it. Yeah, we have some time for questions. So you said about halfway through that one of the goals was to actually keep the reading the OCI image format, but I think everybody pretty much agrees the OCI image format is crap for lazy pulling of container images, basically because it has an end-to-end hash so you can't do the hash until you pull the whole image, and that means signatures are completely rubbish anyway. In order to fix this, we have to do a Merkle tree or something else anyway, so the image format is going to have to change radically to something that will be much more suitable for your image. So I think trying to keep the image compatibility, which is partly what the argument over this versus the in kernel alternatives is not going to be a good argument for that, and I think you should consider it. I agree and I don't agree. And I think I'm not a fan of OCI, I've been part of the OCI specification team for a bit. I used to be one of the Docker maintainers a long time ago. It is not nice, but it is what we have, and it's everywhere. It's so easy as a developer sitting around thinking this is bullshit, we should just fix it, but there are like trillions of dollars invested in the existing containers, it's going to be a long time. But even when we replace it, this will still do the right thing. But there are trillions of dollars invested in the hosting cart, so it doesn't stop us going to the OCI. True, true, but like there are discussions of OCI V2, I don't follow them because the whole thing is bullshit, but even then, if we just had a better way to get partial updates for an image file, you could still use this, to use it. Before taking the next question, I'm obliged to point out from the chat that these performance numbers are before optimizing overlay FS and E-Rofs. Yeah, yeah, so yeah, there's been some work in that and optimizing like there, there's ideas to make the overlays stuff work better. Would that be possible, Joe? Maybe. Oh, I actually still had a question. So here in the back. So what's not really a question, more a remark. I think there's sort of like one missing slide in your deck, namely one use case that you haven't considered at all, but still really worth calling out. Many remote build systems, such as like GOMA, Bazel, et cetera, are all nowadays converging on the single remote execution protocol called REV2, and that one is actually also using a CAS as a data store for storing both input files for like compiler, binary, source files, header files, but also output files, object files that are generated. I actually maintain one of the implementations, and like one of the hard parts of implementing such a build cluster is instantiating the data that's stored in the CAS in the form of like an input route on disk, where you can just like run a compiler against certain source files, and a tool like Composives would also really help in such an implementation. That's just something I wanted to call out, and you should really like also market it towards those kinds of use cases, and it makes a lot of sense. Yeah, I'm sure images are used for all sorts of stuff, I'm sure there are many use cases other than the ones I've mainly focused on. Okay, then since you already ended the Q&A a bit early, then the next talk is going to be recorded. It gives us a bit more time to prepare. Thank you very much for the talk. Thank you for all the questions, and being here.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.32, "text": " So, we're ready for our next talk.", "tokens": [407, 11, 321, 434, 1919, 337, 527, 958, 751, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 1, "seek": 0, "start": 7.32, "end": 10.64, "text": " Alex is going to talk about the new file system that they're proposing, ComposerVest, and", "tokens": [5202, 307, 516, 281, 751, 466, 264, 777, 3991, 1185, 300, 436, 434, 29939, 11, 6620, 22150, 53, 377, 11, 293], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 2, "seek": 0, "start": 10.64, "end": 13.200000000000001, "text": " opportunistically sharing verified image file system.", "tokens": [2070, 20458, 5414, 31197, 3256, 3991, 1185, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 3, "seek": 0, "start": 13.200000000000001, "end": 14.200000000000001, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 4, "seek": 0, "start": 14.200000000000001, "end": 15.200000000000001, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 5, "seek": 0, "start": 15.200000000000001, "end": 16.2, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 6, "seek": 0, "start": 16.2, "end": 17.2, "text": " Can you hear me?", "tokens": [1664, 291, 1568, 385, 30], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 7, "seek": 0, "start": 17.2, "end": 18.2, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 8, "seek": 0, "start": 18.2, "end": 19.2, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 9, "seek": 0, "start": 19.2, "end": 20.2, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 10, "seek": 0, "start": 20.2, "end": 21.2, "text": " I'm Alex.", "tokens": [286, 478, 5202, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 11, "seek": 0, "start": 21.2, "end": 24.76, "text": " You may also know me from hits such as Flatpak, FlatHub, GNOME, GTK, all such a stuff.", "tokens": [509, 815, 611, 458, 385, 490, 8664, 1270, 382, 36172, 45944, 11, 36172, 21150, 11, 46411, 23344, 11, 17530, 42, 11, 439, 1270, 257, 1507, 13], "temperature": 0.0, "avg_logprob": -0.222452636457916, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.11928768455982208}, {"id": 12, "seek": 2476, "start": 24.76, "end": 31.400000000000002, "text": " But this here is my first kernel file system, which I proposed on the list a couple of months", "tokens": [583, 341, 510, 307, 452, 700, 28256, 3991, 1185, 11, 597, 286, 10348, 322, 264, 1329, 257, 1916, 295, 2493], "temperature": 0.0, "avg_logprob": -0.1888458874760842, "compression_ratio": 1.6008771929824561, "no_speech_prob": 2.8360609576338902e-05}, {"id": 13, "seek": 2476, "start": 31.400000000000002, "end": 33.04, "text": " ago.", "tokens": [2057, 13], "temperature": 0.0, "avg_logprob": -0.1888458874760842, "compression_ratio": 1.6008771929824561, "no_speech_prob": 2.8360609576338902e-05}, {"id": 14, "seek": 2476, "start": 33.04, "end": 36.120000000000005, "text": " It's not actually like a file system, a real file system.", "tokens": [467, 311, 406, 767, 411, 257, 3991, 1185, 11, 257, 957, 3991, 1185, 13], "temperature": 0.0, "avg_logprob": -0.1888458874760842, "compression_ratio": 1.6008771929824561, "no_speech_prob": 2.8360609576338902e-05}, {"id": 15, "seek": 2476, "start": 36.120000000000005, "end": 41.08, "text": " It's more targeted for read-only images such that you would typically have many of them", "tokens": [467, 311, 544, 15045, 337, 1401, 12, 25202, 5267, 1270, 300, 291, 576, 5850, 362, 867, 295, 552], "temperature": 0.0, "avg_logprob": -0.1888458874760842, "compression_ratio": 1.6008771929824561, "no_speech_prob": 2.8360609576338902e-05}, {"id": 16, "seek": 2476, "start": 41.08, "end": 42.68000000000001, "text": " running on the system.", "tokens": [2614, 322, 264, 1185, 13], "temperature": 0.0, "avg_logprob": -0.1888458874760842, "compression_ratio": 1.6008771929824561, "no_speech_prob": 2.8360609576338902e-05}, {"id": 17, "seek": 2476, "start": 42.68000000000001, "end": 50.32000000000001, "text": " Maybe in a container host or in my case, my primary concern is the OSTree verified boot", "tokens": [2704, 294, 257, 10129, 3975, 420, 294, 452, 1389, 11, 452, 6194, 3136, 307, 264, 422, 6840, 701, 31197, 11450], "temperature": 0.0, "avg_logprob": -0.1888458874760842, "compression_ratio": 1.6008771929824561, "no_speech_prob": 2.8360609576338902e-05}, {"id": 18, "seek": 2476, "start": 50.32000000000001, "end": 52.2, "text": " use case.", "tokens": [764, 1389, 13], "temperature": 0.0, "avg_logprob": -0.1888458874760842, "compression_ratio": 1.6008771929824561, "no_speech_prob": 2.8360609576338902e-05}, {"id": 19, "seek": 5220, "start": 52.2, "end": 58.68000000000001, "text": " So rather than talking about ComposeFS first, I'm going to talk about OSTree because it", "tokens": [407, 2831, 813, 1417, 466, 6620, 541, 29318, 700, 11, 286, 478, 516, 281, 751, 466, 422, 6840, 701, 570, 309], "temperature": 0.0, "avg_logprob": -0.1732449402680268, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.4987483559234533e-06}, {"id": 20, "seek": 5220, "start": 58.68000000000001, "end": 61.84, "text": " kind of explains where this comes from.", "tokens": [733, 295, 13948, 689, 341, 1487, 490, 13], "temperature": 0.0, "avg_logprob": -0.1732449402680268, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.4987483559234533e-06}, {"id": 21, "seek": 5220, "start": 61.84, "end": 66.92, "text": " So in OSTree, we have images.", "tokens": [407, 294, 422, 6840, 701, 11, 321, 362, 5267, 13], "temperature": 0.0, "avg_logprob": -0.1732449402680268, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.4987483559234533e-06}, {"id": 22, "seek": 5220, "start": 66.92, "end": 70.28, "text": " Normally the images are not simple like this, but actually the full-root file system for", "tokens": [17424, 264, 5267, 366, 406, 2199, 411, 341, 11, 457, 767, 264, 1577, 12, 44147, 3991, 1185, 337], "temperature": 0.0, "avg_logprob": -0.1732449402680268, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.4987483559234533e-06}, {"id": 23, "seek": 5220, "start": 70.28, "end": 72.80000000000001, "text": " your boot system that you want to boot.", "tokens": [428, 11450, 1185, 300, 291, 528, 281, 11450, 13], "temperature": 0.0, "avg_logprob": -0.1732449402680268, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.4987483559234533e-06}, {"id": 24, "seek": 5220, "start": 72.80000000000001, "end": 76.48, "text": " But they're used to a bunch of files, and they have metadata and permissions and names", "tokens": [583, 436, 434, 1143, 281, 257, 3840, 295, 7098, 11, 293, 436, 362, 26603, 293, 32723, 293, 5288], "temperature": 0.0, "avg_logprob": -0.1732449402680268, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.4987483559234533e-06}, {"id": 25, "seek": 5220, "start": 76.48, "end": 77.48, "text": " and whatnot.", "tokens": [293, 25882, 13], "temperature": 0.0, "avg_logprob": -0.1732449402680268, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.4987483559234533e-06}, {"id": 26, "seek": 5220, "start": 77.48, "end": 80.12, "text": " So they're basically images.", "tokens": [407, 436, 434, 1936, 5267, 13], "temperature": 0.0, "avg_logprob": -0.1732449402680268, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.4987483559234533e-06}, {"id": 27, "seek": 8012, "start": 80.12, "end": 86.52000000000001, "text": " And we have this repository format, which is the core format of OSTree.", "tokens": [400, 321, 362, 341, 25841, 7877, 11, 597, 307, 264, 4965, 7877, 295, 422, 6840, 701, 13], "temperature": 0.0, "avg_logprob": -0.1740713039366137, "compression_ratio": 1.8275862068965518, "no_speech_prob": 5.5069144764274824e-06}, {"id": 28, "seek": 8012, "start": 86.52000000000001, "end": 91.84, "text": " And what we do is we take all the files, like the regular files, in the image, and we hash", "tokens": [400, 437, 321, 360, 307, 321, 747, 439, 264, 7098, 11, 411, 264, 3890, 7098, 11, 294, 264, 3256, 11, 293, 321, 22019], "temperature": 0.0, "avg_logprob": -0.1740713039366137, "compression_ratio": 1.8275862068965518, "no_speech_prob": 5.5069144764274824e-06}, {"id": 29, "seek": 8012, "start": 91.84, "end": 93.16000000000001, "text": " them.", "tokens": [552, 13], "temperature": 0.0, "avg_logprob": -0.1740713039366137, "compression_ratio": 1.8275862068965518, "no_speech_prob": 5.5069144764274824e-06}, {"id": 30, "seek": 8012, "start": 93.16000000000001, "end": 98.32000000000001, "text": " And we store them by the hash name in this repository format.", "tokens": [400, 321, 3531, 552, 538, 264, 22019, 1315, 294, 341, 25841, 7877, 13], "temperature": 0.0, "avg_logprob": -0.1740713039366137, "compression_ratio": 1.8275862068965518, "no_speech_prob": 5.5069144764274824e-06}, {"id": 31, "seek": 8012, "start": 98.32000000000001, "end": 102.36000000000001, "text": " So if you look at any of those files, they're just the same file with the name of their", "tokens": [407, 498, 291, 574, 412, 604, 295, 729, 7098, 11, 436, 434, 445, 264, 912, 3991, 365, 264, 1315, 295, 641], "temperature": 0.0, "avg_logprob": -0.1740713039366137, "compression_ratio": 1.8275862068965518, "no_speech_prob": 5.5069144764274824e-06}, {"id": 32, "seek": 8012, "start": 102.36000000000001, "end": 104.4, "text": " own content.", "tokens": [1065, 2701, 13], "temperature": 0.0, "avg_logprob": -0.1740713039366137, "compression_ratio": 1.8275862068965518, "no_speech_prob": 5.5069144764274824e-06}, {"id": 33, "seek": 8012, "start": 104.4, "end": 109.96000000000001, "text": " And then we take all the directories we have, such as the sub-dir thing, and we make a small", "tokens": [400, 550, 321, 747, 439, 264, 5391, 530, 321, 362, 11, 1270, 382, 264, 1422, 12, 35043, 551, 11, 293, 321, 652, 257, 1359], "temperature": 0.0, "avg_logprob": -0.1740713039366137, "compression_ratio": 1.8275862068965518, "no_speech_prob": 5.5069144764274824e-06}, {"id": 34, "seek": 10996, "start": 109.96, "end": 117.0, "text": " descriptor of them, the names of the file in there, their permissions and whatnot, and", "tokens": [31280, 284, 295, 552, 11, 264, 5288, 295, 264, 3991, 294, 456, 11, 641, 32723, 293, 25882, 11, 293], "temperature": 0.0, "avg_logprob": -0.16909629420230263, "compression_ratio": 1.8307692307692307, "no_speech_prob": 4.493846972764004e-06}, {"id": 35, "seek": 10996, "start": 117.0, "end": 121.44, "text": " a reference to the content of the file by the checksum.", "tokens": [257, 6408, 281, 264, 2701, 295, 264, 3991, 538, 264, 13834, 449, 13], "temperature": 0.0, "avg_logprob": -0.16909629420230263, "compression_ratio": 1.8307692307692307, "no_speech_prob": 4.493846972764004e-06}, {"id": 36, "seek": 10996, "start": 121.44, "end": 124.6, "text": " And we do the same for the root directory.", "tokens": [400, 321, 360, 264, 912, 337, 264, 5593, 21120, 13], "temperature": 0.0, "avg_logprob": -0.16909629420230263, "compression_ratio": 1.8307692307692307, "no_speech_prob": 4.493846972764004e-06}, {"id": 37, "seek": 10996, "start": 124.6, "end": 129.6, "text": " And this time, we refer to the sub-director by the checksum of the descriptor.", "tokens": [400, 341, 565, 11, 321, 2864, 281, 264, 1422, 12, 18267, 1672, 538, 264, 13834, 449, 295, 264, 31280, 284, 13], "temperature": 0.0, "avg_logprob": -0.16909629420230263, "compression_ratio": 1.8307692307692307, "no_speech_prob": 4.493846972764004e-06}, {"id": 38, "seek": 10996, "start": 129.6, "end": 136.48, "text": " And then we add a final commit description, which describes, well, it has a pointer, meaning", "tokens": [400, 550, 321, 909, 257, 2572, 5599, 3855, 11, 597, 15626, 11, 731, 11, 309, 575, 257, 23918, 11, 3620], "temperature": 0.0, "avg_logprob": -0.16909629420230263, "compression_ratio": 1.8307692307692307, "no_speech_prob": 4.493846972764004e-06}, {"id": 39, "seek": 13648, "start": 136.48, "end": 141.76, "text": " the checksum of the root directory, and a parent doesn't have a parent, because this", "tokens": [264, 13834, 449, 295, 264, 5593, 21120, 11, 293, 257, 2596, 1177, 380, 362, 257, 2596, 11, 570, 341], "temperature": 0.0, "avg_logprob": -0.21074430759136492, "compression_ratio": 1.6680851063829787, "no_speech_prob": 2.856173750842572e-06}, {"id": 40, "seek": 13648, "start": 141.76, "end": 145.32, "text": " is the first commit, some metadata.", "tokens": [307, 264, 700, 5599, 11, 512, 26603, 13], "temperature": 0.0, "avg_logprob": -0.21074430759136492, "compression_ratio": 1.6680851063829787, "no_speech_prob": 2.856173750842572e-06}, {"id": 41, "seek": 13648, "start": 145.32, "end": 150.2, "text": " And then we add the breaths file, which is basically just a file that says, we have a", "tokens": [400, 550, 321, 909, 264, 33769, 3991, 11, 597, 307, 1936, 445, 257, 3991, 300, 1619, 11, 321, 362, 257], "temperature": 0.0, "avg_logprob": -0.21074430759136492, "compression_ratio": 1.6680851063829787, "no_speech_prob": 2.856173750842572e-06}, {"id": 42, "seek": 13648, "start": 150.2, "end": 154.56, "text": " branch called image, and this is the current head.", "tokens": [9819, 1219, 3256, 11, 293, 341, 307, 264, 2190, 1378, 13], "temperature": 0.0, "avg_logprob": -0.21074430759136492, "compression_ratio": 1.6680851063829787, "no_speech_prob": 2.856173750842572e-06}, {"id": 43, "seek": 13648, "start": 154.56, "end": 160.16, "text": " So if anyone thinks this looks like the.get directory in any of your checkouts, that's", "tokens": [407, 498, 2878, 7309, 341, 1542, 411, 264, 2411, 847, 21120, 294, 604, 295, 428, 1520, 7711, 11, 300, 311], "temperature": 0.0, "avg_logprob": -0.21074430759136492, "compression_ratio": 1.6680851063829787, "no_speech_prob": 2.856173750842572e-06}, {"id": 44, "seek": 13648, "start": 160.16, "end": 161.16, "text": " true.", "tokens": [2074, 13], "temperature": 0.0, "avg_logprob": -0.21074430759136492, "compression_ratio": 1.6680851063829787, "no_speech_prob": 2.856173750842572e-06}, {"id": 45, "seek": 13648, "start": 161.16, "end": 164.23999999999998, "text": " It's basically get for operating systems.", "tokens": [467, 311, 1936, 483, 337, 7447, 3652, 13], "temperature": 0.0, "avg_logprob": -0.21074430759136492, "compression_ratio": 1.6680851063829787, "no_speech_prob": 2.856173750842572e-06}, {"id": 46, "seek": 16424, "start": 164.24, "end": 169.52, "text": " There are some details in exactly how the object files are stored, but basically, the", "tokens": [821, 366, 512, 4365, 294, 2293, 577, 264, 2657, 7098, 366, 12187, 11, 457, 1936, 11, 264], "temperature": 0.0, "avg_logprob": -0.17493301462904315, "compression_ratio": 1.6906779661016949, "no_speech_prob": 3.6672570331575116e-06}, {"id": 47, "seek": 16424, "start": 169.52, "end": 173.0, "text": " entire structure is get, right, just a copy of get.", "tokens": [2302, 3877, 307, 483, 11, 558, 11, 445, 257, 5055, 295, 483, 13], "temperature": 0.0, "avg_logprob": -0.17493301462904315, "compression_ratio": 1.6906779661016949, "no_speech_prob": 3.6672570331575116e-06}, {"id": 48, "seek": 16424, "start": 173.0, "end": 177.20000000000002, "text": " And you can see even more clearly, if you create a new commit, the new version, we added", "tokens": [400, 291, 393, 536, 754, 544, 4448, 11, 498, 291, 1884, 257, 777, 5599, 11, 264, 777, 3037, 11, 321, 3869], "temperature": 0.0, "avg_logprob": -0.17493301462904315, "compression_ratio": 1.6906779661016949, "no_speech_prob": 3.6672570331575116e-06}, {"id": 49, "seek": 16424, "start": 177.20000000000002, "end": 178.20000000000002, "text": " the readme.", "tokens": [264, 1401, 1398, 13], "temperature": 0.0, "avg_logprob": -0.17493301462904315, "compression_ratio": 1.6906779661016949, "no_speech_prob": 3.6672570331575116e-06}, {"id": 50, "seek": 16424, "start": 178.20000000000002, "end": 184.08, "text": " So all we have to do is add the file, the new root directory, and the new commit that", "tokens": [407, 439, 321, 362, 281, 360, 307, 909, 264, 3991, 11, 264, 777, 5593, 21120, 11, 293, 264, 777, 5599, 300], "temperature": 0.0, "avg_logprob": -0.17493301462904315, "compression_ratio": 1.6906779661016949, "no_speech_prob": 3.6672570331575116e-06}, {"id": 51, "seek": 16424, "start": 184.08, "end": 190.36, "text": " points to the previous one, and then we update the ref to the latest head.", "tokens": [2793, 281, 264, 3894, 472, 11, 293, 550, 321, 5623, 264, 1895, 281, 264, 6792, 1378, 13], "temperature": 0.0, "avg_logprob": -0.17493301462904315, "compression_ratio": 1.6906779661016949, "no_speech_prob": 3.6672570331575116e-06}, {"id": 52, "seek": 19036, "start": 190.36, "end": 196.68, "text": " So basically, re-implementing get for large binary trees.", "tokens": [407, 1936, 11, 319, 12, 332, 43704, 278, 483, 337, 2416, 17434, 5852, 13], "temperature": 0.0, "avg_logprob": -0.1727509915250019, "compression_ratio": 1.6859504132231404, "no_speech_prob": 3.784675072893151e-06}, {"id": 53, "seek": 19036, "start": 196.68, "end": 201.68, "text": " But you can't use this directly, like you can't boot from a repository like this.", "tokens": [583, 291, 393, 380, 764, 341, 3838, 11, 411, 291, 393, 380, 11450, 490, 257, 25841, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1727509915250019, "compression_ratio": 1.6859504132231404, "no_speech_prob": 3.784675072893151e-06}, {"id": 54, "seek": 19036, "start": 201.68, "end": 209.08, "text": " So what you do, deploy, we call it deploy, when we run a new version of something, typically", "tokens": [407, 437, 291, 360, 11, 7274, 11, 321, 818, 309, 7274, 11, 562, 321, 1190, 257, 777, 3037, 295, 746, 11, 5850], "temperature": 0.0, "avg_logprob": -0.1727509915250019, "compression_ratio": 1.6859504132231404, "no_speech_prob": 3.784675072893151e-06}, {"id": 55, "seek": 19036, "start": 209.08, "end": 214.44000000000003, "text": " you have a pre-existing version, so download the new version of the thing you want to run,", "tokens": [291, 362, 257, 659, 12, 36447, 3037, 11, 370, 5484, 264, 777, 3037, 295, 264, 551, 291, 528, 281, 1190, 11], "temperature": 0.0, "avg_logprob": -0.1727509915250019, "compression_ratio": 1.6859504132231404, "no_speech_prob": 3.784675072893151e-06}, {"id": 56, "seek": 19036, "start": 214.44000000000003, "end": 219.60000000000002, "text": " which is very simple, because you can just iterate over these recursive descriptions", "tokens": [597, 307, 588, 2199, 11, 570, 291, 393, 445, 44497, 670, 613, 20560, 488, 24406], "temperature": 0.0, "avg_logprob": -0.1727509915250019, "compression_ratio": 1.6859504132231404, "no_speech_prob": 3.784675072893151e-06}, {"id": 57, "seek": 21960, "start": 219.6, "end": 226.72, "text": " of the image, and whenever you have a reference to an object you already have downloaded,", "tokens": [295, 264, 3256, 11, 293, 5699, 291, 362, 257, 6408, 281, 364, 2657, 291, 1217, 362, 21748, 11], "temperature": 0.0, "avg_logprob": -0.15046770819302263, "compression_ratio": 1.592920353982301, "no_speech_prob": 6.959955953789176e-06}, {"id": 58, "seek": 21960, "start": 226.72, "end": 230.72, "text": " you can just stop because recursively you know you have all the previous things, so it's", "tokens": [291, 393, 445, 1590, 570, 20560, 3413, 291, 458, 291, 362, 439, 264, 3894, 721, 11, 370, 309, 311], "temperature": 0.0, "avg_logprob": -0.15046770819302263, "compression_ratio": 1.592920353982301, "no_speech_prob": 6.959955953789176e-06}, {"id": 59, "seek": 21960, "start": 230.72, "end": 233.28, "text": " very efficient to get the new version.", "tokens": [588, 7148, 281, 483, 264, 777, 3037, 13], "temperature": 0.0, "avg_logprob": -0.15046770819302263, "compression_ratio": 1.592920353982301, "no_speech_prob": 6.959955953789176e-06}, {"id": 60, "seek": 21960, "start": 233.28, "end": 241.07999999999998, "text": " And then we create a deploy directory, which is basically a hard-linked form that points", "tokens": [400, 550, 321, 1884, 257, 7274, 21120, 11, 597, 307, 1936, 257, 1152, 12, 22473, 292, 1254, 300, 2793], "temperature": 0.0, "avg_logprob": -0.15046770819302263, "compression_ratio": 1.592920353982301, "no_speech_prob": 6.959955953789176e-06}, {"id": 61, "seek": 21960, "start": 241.07999999999998, "end": 247.68, "text": " back into the objects, like the regular file objects.", "tokens": [646, 666, 264, 6565, 11, 411, 264, 3890, 3991, 6565, 13], "temperature": 0.0, "avg_logprob": -0.15046770819302263, "compression_ratio": 1.592920353982301, "no_speech_prob": 6.959955953789176e-06}, {"id": 62, "seek": 24768, "start": 247.68, "end": 252.24, "text": " So we create the directories for the right permissions and whatnot, and whenever there's", "tokens": [407, 321, 1884, 264, 5391, 530, 337, 264, 558, 32723, 293, 25882, 11, 293, 5699, 456, 311], "temperature": 0.0, "avg_logprob": -0.2415713617357157, "compression_ratio": 1.812, "no_speech_prob": 1.2027452612528577e-05}, {"id": 63, "seek": 24768, "start": 252.24, "end": 258.12, "text": " a regular file, we just point it at the file, the same file, by using a hard-link to the", "tokens": [257, 3890, 3991, 11, 321, 445, 935, 309, 412, 264, 3991, 11, 264, 912, 3991, 11, 538, 1228, 257, 1152, 12, 22473, 281, 264], "temperature": 0.0, "avg_logprob": -0.2415713617357157, "compression_ratio": 1.812, "no_speech_prob": 1.2027452612528577e-05}, {"id": 64, "seek": 24768, "start": 258.12, "end": 260.16, "text": " one in the repository.", "tokens": [472, 294, 264, 25841, 13], "temperature": 0.0, "avg_logprob": -0.2415713617357157, "compression_ratio": 1.812, "no_speech_prob": 1.2027452612528577e-05}, {"id": 65, "seek": 24768, "start": 260.16, "end": 265.32, "text": " And then we somehow set some boot configuration that points to this particular commit, which", "tokens": [400, 550, 321, 6063, 992, 512, 11450, 11694, 300, 2793, 281, 341, 1729, 5599, 11, 597], "temperature": 0.0, "avg_logprob": -0.2415713617357157, "compression_ratio": 1.812, "no_speech_prob": 1.2027452612528577e-05}, {"id": 66, "seek": 24768, "start": 265.32, "end": 271.6, "text": " names this directory, and somewhere in the Unitardee we find this directory, bind-monit,", "tokens": [5288, 341, 21120, 11, 293, 4079, 294, 264, 1156, 270, 515, 1653, 321, 915, 341, 21120, 11, 14786, 12, 3317, 270, 11], "temperature": 0.0, "avg_logprob": -0.2415713617357157, "compression_ratio": 1.812, "no_speech_prob": 1.2027452612528577e-05}, {"id": 67, "seek": 24768, "start": 271.6, "end": 277.52, "text": " read-only on the root, on top of the root, and then we boot into that.", "tokens": [1401, 12, 25202, 322, 264, 5593, 11, 322, 1192, 295, 264, 5593, 11, 293, 550, 321, 11450, 666, 300, 13], "temperature": 0.0, "avg_logprob": -0.2415713617357157, "compression_ratio": 1.812, "no_speech_prob": 1.2027452612528577e-05}, {"id": 68, "seek": 27752, "start": 277.52, "end": 283.79999999999995, "text": " And there are some clear advantages over this over what would be the alternative, which", "tokens": [400, 456, 366, 512, 1850, 14906, 670, 341, 670, 437, 576, 312, 264, 8535, 11, 597], "temperature": 0.0, "avg_logprob": -0.16529083251953125, "compression_ratio": 1.6141078838174274, "no_speech_prob": 7.641927368240431e-06}, {"id": 69, "seek": 27752, "start": 283.79999999999995, "end": 289.44, "text": " is the traditional AB, like block device, you have two block devices, then you flash", "tokens": [307, 264, 5164, 13838, 11, 411, 3461, 4302, 11, 291, 362, 732, 3461, 5759, 11, 550, 291, 7319], "temperature": 0.0, "avg_logprob": -0.16529083251953125, "compression_ratio": 1.6141078838174274, "no_speech_prob": 7.641927368240431e-06}, {"id": 70, "seek": 27752, "start": 289.44, "end": 295.44, "text": " new image on B, and then you boot into B. First of all, it's very easy to do efficient", "tokens": [777, 3256, 322, 363, 11, 293, 550, 291, 11450, 666, 363, 13, 2386, 295, 439, 11, 309, 311, 588, 1858, 281, 360, 7148], "temperature": 0.0, "avg_logprob": -0.16529083251953125, "compression_ratio": 1.6141078838174274, "no_speech_prob": 7.641927368240431e-06}, {"id": 71, "seek": 27752, "start": 295.44, "end": 299.84, "text": " downloads, and like deltas are very small.", "tokens": [36553, 11, 293, 411, 1103, 83, 296, 366, 588, 1359, 13], "temperature": 0.0, "avg_logprob": -0.16529083251953125, "compression_ratio": 1.6141078838174274, "no_speech_prob": 7.641927368240431e-06}, {"id": 72, "seek": 27752, "start": 299.84, "end": 305.0, "text": " You can easily store however many versions of things you want, whether they're related", "tokens": [509, 393, 3612, 3531, 4461, 867, 9606, 295, 721, 291, 528, 11, 1968, 436, 434, 4077], "temperature": 0.0, "avg_logprob": -0.16529083251953125, "compression_ratio": 1.6141078838174274, "no_speech_prob": 7.641927368240431e-06}, {"id": 73, "seek": 30500, "start": 305.0, "end": 310.76, "text": " or not, like if it's multiple versions of the same branch.", "tokens": [420, 406, 11, 411, 498, 309, 311, 3866, 9606, 295, 264, 912, 9819, 13], "temperature": 0.0, "avg_logprob": -0.1944169196012978, "compression_ratio": 1.6475409836065573, "no_speech_prob": 6.23940650257282e-06}, {"id": 74, "seek": 30500, "start": 310.76, "end": 314.8, "text": " You can keep the last 10 or whatever, plus you can also have completely unrelated, you", "tokens": [509, 393, 1066, 264, 1036, 1266, 420, 2035, 11, 1804, 291, 393, 611, 362, 2584, 38967, 11, 291], "temperature": 0.0, "avg_logprob": -0.1944169196012978, "compression_ratio": 1.6475409836065573, "no_speech_prob": 6.23940650257282e-06}, {"id": 75, "seek": 30500, "start": 314.8, "end": 322.04, "text": " can have botan, fedora, nrl, or debbian or whatever, and you can easily switch between", "tokens": [393, 362, 10592, 282, 11, 4636, 3252, 11, 297, 81, 75, 11, 420, 3001, 20196, 420, 2035, 11, 293, 291, 393, 3612, 3679, 1296], "temperature": 0.0, "avg_logprob": -0.1944169196012978, "compression_ratio": 1.6475409836065573, "no_speech_prob": 6.23940650257282e-06}, {"id": 76, "seek": 30500, "start": 322.04, "end": 324.64, "text": " them atomically.", "tokens": [552, 12018, 984, 13], "temperature": 0.0, "avg_logprob": -0.1944169196012978, "compression_ratio": 1.6475409836065573, "no_speech_prob": 6.23940650257282e-06}, {"id": 77, "seek": 30500, "start": 324.64, "end": 330.24, "text": " And all the updates are atomical, we never modify an existing thing that you're running,", "tokens": [400, 439, 264, 9205, 366, 12018, 804, 11, 321, 1128, 16927, 364, 6741, 551, 300, 291, 434, 2614, 11], "temperature": 0.0, "avg_logprob": -0.1944169196012978, "compression_ratio": 1.6475409836065573, "no_speech_prob": 6.23940650257282e-06}, {"id": 78, "seek": 30500, "start": 330.24, "end": 334.84, "text": " we always create a new deploy directory, and we boot into that.", "tokens": [321, 1009, 1884, 257, 777, 7274, 21120, 11, 293, 321, 11450, 666, 300, 13], "temperature": 0.0, "avg_logprob": -0.1944169196012978, "compression_ratio": 1.6475409836065573, "no_speech_prob": 6.23940650257282e-06}, {"id": 79, "seek": 33484, "start": 334.84, "end": 341.4, "text": " And also the format is very, it's very, very viable, like it's recursively describing itself,", "tokens": [400, 611, 264, 7877, 307, 588, 11, 309, 311, 588, 11, 588, 22024, 11, 411, 309, 311, 20560, 3413, 16141, 2564, 11], "temperature": 0.0, "avg_logprob": -0.17446993855596746, "compression_ratio": 1.74235807860262, "no_speech_prob": 9.079548362933565e-06}, {"id": 80, "seek": 33484, "start": 341.4, "end": 347.35999999999996, "text": " and all you need is the signature, and there's a GPG signature on the commit object.", "tokens": [293, 439, 291, 643, 307, 264, 13397, 11, 293, 456, 311, 257, 26039, 38, 13397, 322, 264, 5599, 2657, 13], "temperature": 0.0, "avg_logprob": -0.17446993855596746, "compression_ratio": 1.74235807860262, "no_speech_prob": 9.079548362933565e-06}, {"id": 81, "seek": 33484, "start": 347.35999999999996, "end": 352.79999999999995, "text": " So if you trust the commit object, you trust the root hash, which you trust the hash of", "tokens": [407, 498, 291, 3361, 264, 5599, 2657, 11, 291, 3361, 264, 5593, 22019, 11, 597, 291, 3361, 264, 22019, 295], "temperature": 0.0, "avg_logprob": -0.17446993855596746, "compression_ratio": 1.74235807860262, "no_speech_prob": 9.079548362933565e-06}, {"id": 82, "seek": 33484, "start": 352.79999999999995, "end": 356.71999999999997, "text": " the subdirectories and the files and what not.", "tokens": [264, 1422, 18267, 1672, 530, 293, 264, 7098, 293, 437, 406, 13], "temperature": 0.0, "avg_logprob": -0.17446993855596746, "compression_ratio": 1.74235807860262, "no_speech_prob": 9.079548362933565e-06}, {"id": 83, "seek": 33484, "start": 356.71999999999997, "end": 362.03999999999996, "text": " The problem that I want to address is that this doesn't do runtime verification, like", "tokens": [440, 1154, 300, 286, 528, 281, 2985, 307, 300, 341, 1177, 380, 360, 34474, 30206, 11, 411], "temperature": 0.0, "avg_logprob": -0.17446993855596746, "compression_ratio": 1.74235807860262, "no_speech_prob": 9.079548362933565e-06}, {"id": 84, "seek": 36204, "start": 362.04, "end": 369.12, "text": " we verify, when we download things, we can verify when we do the deploy or rather like", "tokens": [321, 16888, 11, 562, 321, 5484, 721, 11, 321, 393, 16888, 562, 321, 360, 264, 7274, 420, 2831, 411], "temperature": 0.0, "avg_logprob": -0.14572348875157973, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.6694841178832576e-05}, {"id": 85, "seek": 36204, "start": 369.12, "end": 373.96000000000004, "text": " the fact that we're deploying, it's going to cause us to verify things.", "tokens": [264, 1186, 300, 321, 434, 34198, 11, 309, 311, 516, 281, 3082, 505, 281, 16888, 721, 13], "temperature": 0.0, "avg_logprob": -0.14572348875157973, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.6694841178832576e-05}, {"id": 86, "seek": 36204, "start": 373.96000000000004, "end": 380.12, "text": " But if after some point after that something modifies, say we have a random bit flip on", "tokens": [583, 498, 934, 512, 935, 934, 300, 746, 1072, 11221, 11, 584, 321, 362, 257, 4974, 857, 7929, 322], "temperature": 0.0, "avg_logprob": -0.14572348875157973, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.6694841178832576e-05}, {"id": 87, "seek": 36204, "start": 380.12, "end": 388.56, "text": " the disk, or we have a malicious, like, evil made style attack, someone could easily just", "tokens": [264, 12355, 11, 420, 321, 362, 257, 33496, 11, 411, 11, 6724, 1027, 3758, 2690, 11, 1580, 727, 3612, 445], "temperature": 0.0, "avg_logprob": -0.14572348875157973, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.6694841178832576e-05}, {"id": 88, "seek": 38856, "start": 388.56, "end": 394.44, "text": " remove or modify a file in the deploy directory.", "tokens": [4159, 420, 16927, 257, 3991, 294, 264, 7274, 21120, 13], "temperature": 0.0, "avg_logprob": -0.22547169639950707, "compression_ratio": 1.543103448275862, "no_speech_prob": 6.741835932189133e-06}, {"id": 89, "seek": 38856, "start": 394.44, "end": 399.96, "text": " And to protect against this, the kernel has two features, de-inverity and fsverity.", "tokens": [400, 281, 2371, 1970, 341, 11, 264, 28256, 575, 732, 4122, 11, 368, 12, 259, 331, 507, 293, 283, 82, 331, 507, 13], "temperature": 0.0, "avg_logprob": -0.22547169639950707, "compression_ratio": 1.543103448275862, "no_speech_prob": 6.741835932189133e-06}, {"id": 90, "seek": 38856, "start": 399.96, "end": 405.68, "text": " De-inverity is what you use in the typical ABE image system, because it's block-based,", "tokens": [1346, 12, 259, 331, 507, 307, 437, 291, 764, 294, 264, 7476, 316, 10207, 3256, 1185, 11, 570, 309, 311, 3461, 12, 6032, 11], "temperature": 0.0, "avg_logprob": -0.22547169639950707, "compression_ratio": 1.543103448275862, "no_speech_prob": 6.741835932189133e-06}, {"id": 91, "seek": 38856, "start": 405.68, "end": 411.04, "text": " but it's completely a read-only block device, there's no way we can do OSTry-like updates", "tokens": [457, 309, 311, 2584, 257, 1401, 12, 25202, 3461, 4302, 11, 456, 311, 572, 636, 321, 393, 360, 422, 6840, 627, 12, 4092, 9205], "temperature": 0.0, "avg_logprob": -0.22547169639950707, "compression_ratio": 1.543103448275862, "no_speech_prob": 6.741835932189133e-06}, {"id": 92, "seek": 38856, "start": 411.04, "end": 415.12, "text": " to its file system, you just cannot write to it.", "tokens": [281, 1080, 3991, 1185, 11, 291, 445, 2644, 2464, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.22547169639950707, "compression_ratio": 1.543103448275862, "no_speech_prob": 6.741835932189133e-06}, {"id": 93, "seek": 41512, "start": 415.12, "end": 422.0, "text": " So the other thing is fsverity, and fsverity sort of matches very well with the OSTry repository", "tokens": [407, 264, 661, 551, 307, 283, 82, 331, 507, 11, 293, 283, 82, 331, 507, 1333, 295, 10676, 588, 731, 365, 264, 422, 6840, 627, 25841], "temperature": 0.0, "avg_logprob": -0.15124489562680024, "compression_ratio": 1.6396396396396395, "no_speech_prob": 1.5775362953718286e-06}, {"id": 94, "seek": 41512, "start": 422.0, "end": 430.08, "text": " format, because if you enable fsverity on a particular file, it essentially makes it immutable.", "tokens": [7877, 11, 570, 498, 291, 9528, 283, 82, 331, 507, 322, 257, 1729, 3991, 11, 309, 4476, 1669, 309, 3397, 32148, 13], "temperature": 0.0, "avg_logprob": -0.15124489562680024, "compression_ratio": 1.6396396396396395, "no_speech_prob": 1.5775362953718286e-06}, {"id": 95, "seek": 41512, "start": 430.08, "end": 437.36, "text": " And immutable is exactly what these things, content the rest files are, so it's good.", "tokens": [400, 3397, 32148, 307, 2293, 437, 613, 721, 11, 2701, 264, 1472, 7098, 366, 11, 370, 309, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.15124489562680024, "compression_ratio": 1.6396396396396395, "no_speech_prob": 1.5775362953718286e-06}, {"id": 96, "seek": 41512, "start": 437.36, "end": 442.12, "text": " But the problem is that fsverity doesn't go all the way, it only protects the content", "tokens": [583, 264, 1154, 307, 300, 283, 82, 331, 507, 1177, 380, 352, 439, 264, 636, 11, 309, 787, 22583, 264, 2701], "temperature": 0.0, "avg_logprob": -0.15124489562680024, "compression_ratio": 1.6396396396396395, "no_speech_prob": 1.5775362953718286e-06}, {"id": 97, "seek": 44212, "start": 442.12, "end": 447.44, "text": " of the file, while you can easily make it set UID or replace it with a different one", "tokens": [295, 264, 3991, 11, 1339, 291, 393, 3612, 652, 309, 992, 624, 2777, 420, 7406, 309, 365, 257, 819, 472], "temperature": 0.0, "avg_logprob": -0.16269920349121095, "compression_ratio": 1.5497835497835497, "no_speech_prob": 1.4734457181475591e-05}, {"id": 98, "seek": 44212, "start": 447.44, "end": 453.56, "text": " that has a different fsverity, or just add a new file or whatever.", "tokens": [300, 575, 257, 819, 283, 82, 331, 507, 11, 420, 445, 909, 257, 777, 3991, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.16269920349121095, "compression_ratio": 1.5497835497835497, "no_speech_prob": 1.4734457181475591e-05}, {"id": 99, "seek": 44212, "start": 453.56, "end": 456.72, "text": " So it doesn't protect structure.", "tokens": [407, 309, 1177, 380, 2371, 3877, 13], "temperature": 0.0, "avg_logprob": -0.16269920349121095, "compression_ratio": 1.5497835497835497, "no_speech_prob": 1.4734457181475591e-05}, {"id": 100, "seek": 44212, "start": 456.72, "end": 464.88, "text": " So that's why ComposeFS was created, to have another layer that does the structure.", "tokens": [407, 300, 311, 983, 6620, 541, 29318, 390, 2942, 11, 281, 362, 1071, 4583, 300, 775, 264, 3877, 13], "temperature": 0.0, "avg_logprob": -0.16269920349121095, "compression_ratio": 1.5497835497835497, "no_speech_prob": 1.4734457181475591e-05}, {"id": 101, "seek": 44212, "start": 464.88, "end": 472.08, "text": " And now I'm sort of going away from the OSTry use case, and this is the native way to use", "tokens": [400, 586, 286, 478, 1333, 295, 516, 1314, 490, 264, 422, 6840, 627, 764, 1389, 11, 293, 341, 307, 264, 8470, 636, 281, 764], "temperature": 0.0, "avg_logprob": -0.16269920349121095, "compression_ratio": 1.5497835497835497, "no_speech_prob": 1.4734457181475591e-05}, {"id": 102, "seek": 47208, "start": 472.08, "end": 477.84, "text": " ComposeFS, where you just have a directory with some data, this is the same kind of example", "tokens": [6620, 541, 29318, 11, 689, 291, 445, 362, 257, 21120, 365, 512, 1412, 11, 341, 307, 264, 912, 733, 295, 1365], "temperature": 0.0, "avg_logprob": -0.18724544525146483, "compression_ratio": 1.7123893805309736, "no_speech_prob": 6.3386223700945266e-06}, {"id": 103, "seek": 47208, "start": 477.84, "end": 483.88, "text": " that I had in the repository format, and you just run mkcomposeFS on that directory, and", "tokens": [300, 286, 632, 294, 264, 25841, 7877, 11, 293, 291, 445, 1190, 275, 74, 21541, 541, 29318, 322, 300, 21120, 11, 293], "temperature": 0.0, "avg_logprob": -0.18724544525146483, "compression_ratio": 1.7123893805309736, "no_speech_prob": 6.3386223700945266e-06}, {"id": 104, "seek": 47208, "start": 483.88, "end": 490.15999999999997, "text": " it creates this image file that contains all the metadata for the structure of the thing.", "tokens": [309, 7829, 341, 3256, 3991, 300, 8306, 439, 264, 26603, 337, 264, 3877, 295, 264, 551, 13], "temperature": 0.0, "avg_logprob": -0.18724544525146483, "compression_ratio": 1.7123893805309736, "no_speech_prob": 6.3386223700945266e-06}, {"id": 105, "seek": 47208, "start": 490.15999999999997, "end": 497.79999999999995, "text": " And this objects directory, which is just copies of these files stored by their fsverity commit,", "tokens": [400, 341, 6565, 21120, 11, 597, 307, 445, 14341, 295, 613, 7098, 12187, 538, 641, 283, 82, 331, 507, 5599, 11], "temperature": 0.0, "avg_logprob": -0.18724544525146483, "compression_ratio": 1.7123893805309736, "no_speech_prob": 6.3386223700945266e-06}, {"id": 106, "seek": 47208, "start": 497.79999999999995, "end": 500.36, "text": " or fsverity digest.", "tokens": [420, 283, 82, 331, 507, 13884, 13], "temperature": 0.0, "avg_logprob": -0.18724544525146483, "compression_ratio": 1.7123893805309736, "no_speech_prob": 6.3386223700945266e-06}, {"id": 107, "seek": 50036, "start": 500.36, "end": 504.44, "text": " And they obviously use pure files, you can cat them, and they're just regular files with", "tokens": [400, 436, 2745, 764, 6075, 7098, 11, 291, 393, 3857, 552, 11, 293, 436, 434, 445, 3890, 7098, 365], "temperature": 0.0, "avg_logprob": -0.19774082487663336, "compression_ratio": 1.7640449438202248, "no_speech_prob": 2.443612629576819e-06}, {"id": 108, "seek": 50036, "start": 504.44, "end": 505.44, "text": " the same contents.", "tokens": [264, 912, 15768, 13], "temperature": 0.0, "avg_logprob": -0.19774082487663336, "compression_ratio": 1.7640449438202248, "no_speech_prob": 2.443612629576819e-06}, {"id": 109, "seek": 50036, "start": 505.44, "end": 510.16, "text": " They're actually pure data files, you can see they don't have like the executable rights", "tokens": [814, 434, 767, 6075, 1412, 7098, 11, 291, 393, 536, 436, 500, 380, 362, 411, 264, 7568, 712, 4601], "temperature": 0.0, "avg_logprob": -0.19774082487663336, "compression_ratio": 1.7640449438202248, "no_speech_prob": 2.443612629576819e-06}, {"id": 110, "seek": 50036, "start": 510.16, "end": 515.88, "text": " or if you have some complex metadata, extended attributes or whatever, these are just regular", "tokens": [420, 498, 291, 362, 512, 3997, 26603, 11, 10913, 17212, 420, 2035, 11, 613, 366, 445, 3890], "temperature": 0.0, "avg_logprob": -0.19774082487663336, "compression_ratio": 1.7640449438202248, "no_speech_prob": 2.443612629576819e-06}, {"id": 111, "seek": 50036, "start": 515.88, "end": 518.44, "text": " files with content.", "tokens": [7098, 365, 2701, 13], "temperature": 0.0, "avg_logprob": -0.19774082487663336, "compression_ratio": 1.7640449438202248, "no_speech_prob": 2.443612629576819e-06}, {"id": 112, "seek": 50036, "start": 518.44, "end": 525.12, "text": " And then you mount the thing using ComposeFS, pointing it at this objects directory, and", "tokens": [400, 550, 291, 3746, 264, 551, 1228, 6620, 541, 29318, 11, 12166, 309, 412, 341, 6565, 21120, 11, 293], "temperature": 0.0, "avg_logprob": -0.19774082487663336, "compression_ratio": 1.7640449438202248, "no_speech_prob": 2.443612629576819e-06}, {"id": 113, "seek": 50036, "start": 525.12, "end": 529.64, "text": " then you get a reproduction of the original image that you can look at.", "tokens": [550, 291, 483, 257, 33934, 295, 264, 3380, 3256, 300, 291, 393, 574, 412, 13], "temperature": 0.0, "avg_logprob": -0.19774082487663336, "compression_ratio": 1.7640449438202248, "no_speech_prob": 2.443612629576819e-06}, {"id": 114, "seek": 52964, "start": 529.64, "end": 537.56, "text": " Whatever you cat this, it will just do overlay fsstyle stacking, read the backing file.", "tokens": [8541, 291, 3857, 341, 11, 309, 486, 445, 360, 31741, 283, 82, 15014, 41376, 11, 1401, 264, 19373, 3991, 13], "temperature": 0.0, "avg_logprob": -0.15797753280468202, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.9041019590513315e-06}, {"id": 115, "seek": 52964, "start": 537.56, "end": 542.24, "text": " So everything is always from the page cache, and also the actual mount is not a loopback", "tokens": [407, 1203, 307, 1009, 490, 264, 3028, 19459, 11, 293, 611, 264, 3539, 3746, 307, 406, 257, 6367, 3207], "temperature": 0.0, "avg_logprob": -0.15797753280468202, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.9041019590513315e-06}, {"id": 116, "seek": 52964, "start": 542.24, "end": 550.28, "text": " mount, we just do stacking style, direct access of the file from the page cache.", "tokens": [3746, 11, 321, 445, 360, 41376, 3758, 11, 2047, 2105, 295, 264, 3991, 490, 264, 3028, 19459, 13], "temperature": 0.0, "avg_logprob": -0.15797753280468202, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.9041019590513315e-06}, {"id": 117, "seek": 52964, "start": 550.28, "end": 559.24, "text": " So that gives you the general ability to reproduce this image, but to get the fsverity or complete", "tokens": [407, 300, 2709, 291, 264, 2674, 3485, 281, 29501, 341, 3256, 11, 457, 281, 483, 264, 283, 82, 331, 507, 420, 3566], "temperature": 0.0, "avg_logprob": -0.15797753280468202, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.9041019590513315e-06}, {"id": 118, "seek": 55924, "start": 559.24, "end": 565.36, "text": " structural verification, you actually use fsverity on the descriptor itself.", "tokens": [15067, 30206, 11, 291, 767, 764, 283, 82, 331, 507, 322, 264, 31280, 284, 2564, 13], "temperature": 0.0, "avg_logprob": -0.19247838429042272, "compression_ratio": 1.5857142857142856, "no_speech_prob": 9.068148756341543e-06}, {"id": 119, "seek": 55924, "start": 565.36, "end": 571.44, "text": " So if you enable safe as in that, that makes it immutable, so the file system cannot change", "tokens": [407, 498, 291, 9528, 3273, 382, 294, 300, 11, 300, 1669, 309, 3397, 32148, 11, 370, 264, 3991, 1185, 2644, 1319], "temperature": 0.0, "avg_logprob": -0.19247838429042272, "compression_ratio": 1.5857142857142856, "no_speech_prob": 9.068148756341543e-06}, {"id": 120, "seek": 55924, "start": 571.44, "end": 578.12, "text": " or the file can't change on the file system, at least the kernel API doesn't allow you", "tokens": [420, 264, 3991, 393, 380, 1319, 322, 264, 3991, 1185, 11, 412, 1935, 264, 28256, 9362, 1177, 380, 2089, 291], "temperature": 0.0, "avg_logprob": -0.19247838429042272, "compression_ratio": 1.5857142857142856, "no_speech_prob": 9.068148756341543e-06}, {"id": 121, "seek": 55924, "start": 578.12, "end": 585.88, "text": " and if it's somehow otherwise modified on disk or whatnot, it will detect it.", "tokens": [293, 498, 309, 311, 6063, 5911, 15873, 322, 12355, 420, 25882, 11, 309, 486, 5531, 309, 13], "temperature": 0.0, "avg_logprob": -0.19247838429042272, "compression_ratio": 1.5857142857142856, "no_speech_prob": 9.068148756341543e-06}, {"id": 122, "seek": 58588, "start": 585.88, "end": 591.28, "text": " And you can see like, I actually passed the digest, the expected digest, and whenever", "tokens": [400, 291, 393, 536, 411, 11, 286, 767, 4678, 264, 13884, 11, 264, 5176, 13884, 11, 293, 5699], "temperature": 0.0, "avg_logprob": -0.178609829137821, "compression_ratio": 1.7533632286995515, "no_speech_prob": 4.354876182333101e-06}, {"id": 123, "seek": 58588, "start": 591.28, "end": 595.36, "text": " it mounts it, it starts by verifying before it does any IO, does it actually have the", "tokens": [309, 40982, 309, 11, 309, 3719, 538, 1306, 5489, 949, 309, 775, 604, 39839, 11, 775, 309, 767, 362, 264], "temperature": 0.0, "avg_logprob": -0.178609829137821, "compression_ratio": 1.7533632286995515, "no_speech_prob": 4.354876182333101e-06}, {"id": 124, "seek": 58588, "start": 595.36, "end": 597.8, "text": " expected fsverity digest?", "tokens": [5176, 283, 82, 331, 507, 13884, 30], "temperature": 0.0, "avg_logprob": -0.178609829137821, "compression_ratio": 1.7533632286995515, "no_speech_prob": 4.354876182333101e-06}, {"id": 125, "seek": 58588, "start": 597.8, "end": 603.64, "text": " And if so, we can rely on the kernel to basically do all our verification from us, and if you", "tokens": [400, 498, 370, 11, 321, 393, 10687, 322, 264, 28256, 281, 1936, 360, 439, 527, 30206, 490, 505, 11, 293, 498, 291], "temperature": 0.0, "avg_logprob": -0.178609829137821, "compression_ratio": 1.7533632286995515, "no_speech_prob": 4.354876182333101e-06}, {"id": 126, "seek": 58588, "start": 603.64, "end": 609.64, "text": " replace something, we have in the metadata for all these backing files, the expected", "tokens": [7406, 746, 11, 321, 362, 294, 264, 26603, 337, 439, 613, 19373, 7098, 11, 264, 5176], "temperature": 0.0, "avg_logprob": -0.178609829137821, "compression_ratio": 1.7533632286995515, "no_speech_prob": 4.354876182333101e-06}, {"id": 127, "seek": 58588, "start": 609.64, "end": 611.72, "text": " verity digest.", "tokens": [1306, 507, 13884, 13], "temperature": 0.0, "avg_logprob": -0.178609829137821, "compression_ratio": 1.7533632286995515, "no_speech_prob": 4.354876182333101e-06}, {"id": 128, "seek": 61172, "start": 611.72, "end": 620.2, "text": " So if you replace something, or if there's a random bit flip, it will detect it.", "tokens": [407, 498, 291, 7406, 746, 11, 420, 498, 456, 311, 257, 4974, 857, 7929, 11, 309, 486, 5531, 309, 13], "temperature": 0.0, "avg_logprob": -0.16651005063738142, "compression_ratio": 1.5027624309392265, "no_speech_prob": 5.013760073779849e-06}, {"id": 129, "seek": 61172, "start": 620.2, "end": 625.5600000000001, "text": " And actually the descriptor itself is very simple, like this is not a traditional file", "tokens": [400, 767, 264, 31280, 284, 2564, 307, 588, 2199, 11, 411, 341, 307, 406, 257, 5164, 3991], "temperature": 0.0, "avg_logprob": -0.16651005063738142, "compression_ratio": 1.5027624309392265, "no_speech_prob": 5.013760073779849e-06}, {"id": 130, "seek": 61172, "start": 625.5600000000001, "end": 633.52, "text": " system where we have to update things at run time, we can just compute a very simple descriptor", "tokens": [1185, 689, 321, 362, 281, 5623, 721, 412, 1190, 565, 11, 321, 393, 445, 14722, 257, 588, 2199, 31280, 284], "temperature": 0.0, "avg_logprob": -0.16651005063738142, "compression_ratio": 1.5027624309392265, "no_speech_prob": 5.013760073779849e-06}, {"id": 131, "seek": 61172, "start": 633.52, "end": 634.52, "text": " of this.", "tokens": [295, 341, 13], "temperature": 0.0, "avg_logprob": -0.16651005063738142, "compression_ratio": 1.5027624309392265, "no_speech_prob": 5.013760073779849e-06}, {"id": 132, "seek": 63452, "start": 634.52, "end": 642.0799999999999, "text": " It's basically a fixed-size header followed by a table of fixed-size INO data, like if", "tokens": [467, 311, 1936, 257, 6806, 12, 27553, 23117, 6263, 538, 257, 3199, 295, 6806, 12, 27553, 6892, 46, 1412, 11, 411, 498], "temperature": 0.0, "avg_logprob": -0.27171919080946183, "compression_ratio": 1.6119402985074627, "no_speech_prob": 3.6111491681367625e-06}, {"id": 133, "seek": 63452, "start": 642.0799999999999, "end": 649.28, "text": " the file system has N and INOs, then there are N copies of that structure, and some of", "tokens": [264, 3991, 1185, 575, 426, 293, 6892, 31376, 11, 550, 456, 366, 426, 14341, 295, 300, 3877, 11, 293, 512, 295], "temperature": 0.0, "avg_logprob": -0.27171919080946183, "compression_ratio": 1.6119402985074627, "no_speech_prob": 3.6111491681367625e-06}, {"id": 134, "seek": 63452, "start": 649.28, "end": 656.72, "text": " them point into the variable-size data at the end, which we found with the VData offset", "tokens": [552, 935, 666, 264, 7006, 12, 27553, 1412, 412, 264, 917, 11, 597, 321, 1352, 365, 264, 691, 35, 3274, 18687], "temperature": 0.0, "avg_logprob": -0.27171919080946183, "compression_ratio": 1.6119402985074627, "no_speech_prob": 3.6111491681367625e-06}, {"id": 135, "seek": 63452, "start": 656.72, "end": 660.3199999999999, "text": " in the header, and that's basically all there is to it, right?", "tokens": [294, 264, 23117, 11, 293, 300, 311, 1936, 439, 456, 307, 281, 309, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.27171919080946183, "compression_ratio": 1.6119402985074627, "no_speech_prob": 3.6111491681367625e-06}, {"id": 136, "seek": 66032, "start": 660.32, "end": 666.9200000000001, "text": " We can, INO zero is the root file system, or is the root INODE, you can look at that,", "tokens": [492, 393, 11, 6892, 46, 4018, 307, 264, 5593, 3991, 1185, 11, 420, 307, 264, 5593, 6892, 14632, 36, 11, 291, 393, 574, 412, 300, 11], "temperature": 0.0, "avg_logprob": -0.20081783641468395, "compression_ratio": 1.6977777777777778, "no_speech_prob": 3.039642479052418e-06}, {"id": 137, "seek": 66032, "start": 666.9200000000001, "end": 673.36, "text": " and you can, if it's a type directory, then the variable data points to a table of dirants,", "tokens": [293, 291, 393, 11, 498, 309, 311, 257, 2010, 21120, 11, 550, 264, 7006, 1412, 2793, 281, 257, 3199, 295, 4746, 1719, 11], "temperature": 0.0, "avg_logprob": -0.20081783641468395, "compression_ratio": 1.6977777777777778, "no_speech_prob": 3.039642479052418e-06}, {"id": 138, "seek": 66032, "start": 673.36, "end": 678.6800000000001, "text": " which is basically a pre-sorted table of dirants plus names, that you use binary search, you", "tokens": [597, 307, 1936, 257, 659, 12, 82, 14813, 3199, 295, 4746, 1719, 1804, 5288, 11, 300, 291, 764, 17434, 3164, 11, 291], "temperature": 0.0, "avg_logprob": -0.20081783641468395, "compression_ratio": 1.6977777777777778, "no_speech_prob": 3.039642479052418e-06}, {"id": 139, "seek": 66032, "start": 678.6800000000001, "end": 683.4000000000001, "text": " get a new INO, then you just look at that offset, and all this is just done by mapping", "tokens": [483, 257, 777, 6892, 46, 11, 550, 291, 445, 574, 412, 300, 18687, 11, 293, 439, 341, 307, 445, 1096, 538, 18350], "temperature": 0.0, "avg_logprob": -0.20081783641468395, "compression_ratio": 1.6977777777777778, "no_speech_prob": 3.039642479052418e-06}, {"id": 140, "seek": 66032, "start": 683.4000000000001, "end": 685.7600000000001, "text": " the page cache directly.", "tokens": [264, 3028, 19459, 3838, 13], "temperature": 0.0, "avg_logprob": -0.20081783641468395, "compression_ratio": 1.6977777777777778, "no_speech_prob": 3.039642479052418e-06}, {"id": 141, "seek": 68576, "start": 685.76, "end": 692.24, "text": " So it's very simple in terms of structure.", "tokens": [407, 309, 311, 588, 2199, 294, 2115, 295, 3877, 13], "temperature": 0.0, "avg_logprob": -0.1510717769463857, "compression_ratio": 1.5598086124401913, "no_speech_prob": 8.936964150052518e-06}, {"id": 142, "seek": 68576, "start": 692.24, "end": 696.64, "text": " If you want to use this actually with OSTree, it's slightly different, like we can't just,", "tokens": [759, 291, 528, 281, 764, 341, 767, 365, 422, 6840, 701, 11, 309, 311, 4748, 819, 11, 411, 321, 393, 380, 445, 11], "temperature": 0.0, "avg_logprob": -0.1510717769463857, "compression_ratio": 1.5598086124401913, "no_speech_prob": 8.936964150052518e-06}, {"id": 143, "seek": 68576, "start": 696.64, "end": 702.28, "text": " we don't want to take the OSTree repository, create this directory, and then run MKComposeFS", "tokens": [321, 500, 380, 528, 281, 747, 264, 422, 6840, 701, 25841, 11, 1884, 341, 21120, 11, 293, 550, 1190, 30770, 34, 8586, 541, 29318], "temperature": 0.0, "avg_logprob": -0.1510717769463857, "compression_ratio": 1.5598086124401913, "no_speech_prob": 8.936964150052518e-06}, {"id": 144, "seek": 68576, "start": 702.28, "end": 703.28, "text": " on it.", "tokens": [322, 309, 13], "temperature": 0.0, "avg_logprob": -0.1510717769463857, "compression_ratio": 1.5598086124401913, "no_speech_prob": 8.936964150052518e-06}, {"id": 145, "seek": 68576, "start": 703.28, "end": 711.28, "text": " Instead, we ship a library, LibComposeFS, where you basically link OSTree with this library,", "tokens": [7156, 11, 321, 5374, 257, 6405, 11, 15834, 34, 8586, 541, 29318, 11, 689, 291, 1936, 2113, 422, 6840, 701, 365, 341, 6405, 11], "temperature": 0.0, "avg_logprob": -0.1510717769463857, "compression_ratio": 1.5598086124401913, "no_speech_prob": 8.936964150052518e-06}, {"id": 146, "seek": 71128, "start": 711.28, "end": 717.24, "text": " and it can generate these images directly from the metadata that exists in the repository.", "tokens": [293, 309, 393, 8460, 613, 5267, 3838, 490, 264, 26603, 300, 8198, 294, 264, 25841, 13], "temperature": 0.0, "avg_logprob": -0.13435403877329605, "compression_ratio": 1.7130801687763713, "no_speech_prob": 3.7837642139493255e-06}, {"id": 147, "seek": 71128, "start": 717.24, "end": 724.8399999999999, "text": " So we don't have to do any kind of expensive IO to create these images, because it's just", "tokens": [407, 321, 500, 380, 362, 281, 360, 604, 733, 295, 5124, 286, 46, 281, 1884, 613, 5267, 11, 570, 309, 311, 445], "temperature": 0.0, "avg_logprob": -0.13435403877329605, "compression_ratio": 1.7130801687763713, "no_speech_prob": 3.7837642139493255e-06}, {"id": 148, "seek": 71128, "start": 724.8399999999999, "end": 725.8399999999999, "text": " the metadata, right?", "tokens": [264, 26603, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.13435403877329605, "compression_ratio": 1.7130801687763713, "no_speech_prob": 3.7837642139493255e-06}, {"id": 149, "seek": 71128, "start": 725.8399999999999, "end": 726.8399999999999, "text": " It's not very large.", "tokens": [467, 311, 406, 588, 2416, 13], "temperature": 0.0, "avg_logprob": -0.13435403877329605, "compression_ratio": 1.7130801687763713, "no_speech_prob": 3.7837642139493255e-06}, {"id": 150, "seek": 71128, "start": 726.8399999999999, "end": 732.16, "text": " You can put it on into memory, generate these, optimize them, and just write a single file,", "tokens": [509, 393, 829, 309, 322, 666, 4675, 11, 8460, 613, 11, 19719, 552, 11, 293, 445, 2464, 257, 2167, 3991, 11], "temperature": 0.0, "avg_logprob": -0.13435403877329605, "compression_ratio": 1.7130801687763713, "no_speech_prob": 3.7837642139493255e-06}, {"id": 151, "seek": 71128, "start": 732.16, "end": 737.56, "text": " and the way we can do it, it's very flexible, so we can ensure that we can use the existing", "tokens": [293, 264, 636, 321, 393, 360, 309, 11, 309, 311, 588, 11358, 11, 370, 321, 393, 5586, 300, 321, 393, 764, 264, 6741], "temperature": 0.0, "avg_logprob": -0.13435403877329605, "compression_ratio": 1.7130801687763713, "no_speech_prob": 3.7837642139493255e-06}, {"id": 152, "seek": 73756, "start": 737.56, "end": 741.4399999999999, "text": " repository for the backing files.", "tokens": [25841, 337, 264, 19373, 7098, 13], "temperature": 0.0, "avg_logprob": -0.1540402403665245, "compression_ratio": 1.7012448132780082, "no_speech_prob": 5.506282832357101e-06}, {"id": 153, "seek": 73756, "start": 741.4399999999999, "end": 744.04, "text": " And it's also designed so that it's a standardized way.", "tokens": [400, 309, 311, 611, 4761, 370, 300, 309, 311, 257, 31677, 636, 13], "temperature": 0.0, "avg_logprob": -0.1540402403665245, "compression_ratio": 1.7012448132780082, "no_speech_prob": 5.506282832357101e-06}, {"id": 154, "seek": 73756, "start": 744.04, "end": 750.04, "text": " We put everything, so every time you create a new image based on the same OSTree commit,", "tokens": [492, 829, 1203, 11, 370, 633, 565, 291, 1884, 257, 777, 3256, 2361, 322, 264, 912, 422, 6840, 701, 5599, 11], "temperature": 0.0, "avg_logprob": -0.1540402403665245, "compression_ratio": 1.7012448132780082, "no_speech_prob": 5.506282832357101e-06}, {"id": 155, "seek": 73756, "start": 750.04, "end": 755.16, "text": " we will be creating the exact same binary file, bit by bit.", "tokens": [321, 486, 312, 4084, 264, 1900, 912, 17434, 3991, 11, 857, 538, 857, 13], "temperature": 0.0, "avg_logprob": -0.1540402403665245, "compression_ratio": 1.7012448132780082, "no_speech_prob": 5.506282832357101e-06}, {"id": 156, "seek": 73756, "start": 755.16, "end": 760.88, "text": " So what you do is that when you create the commit on the server, you basically generate", "tokens": [407, 437, 291, 360, 307, 300, 562, 291, 1884, 264, 5599, 322, 264, 7154, 11, 291, 1936, 8460], "temperature": 0.0, "avg_logprob": -0.1540402403665245, "compression_ratio": 1.7012448132780082, "no_speech_prob": 5.506282832357101e-06}, {"id": 157, "seek": 73756, "start": 760.88, "end": 766.1199999999999, "text": " one of these, take the digest of it, like the F is very digest of it, put it in the", "tokens": [472, 295, 613, 11, 747, 264, 13884, 295, 309, 11, 411, 264, 479, 307, 588, 13884, 295, 309, 11, 829, 309, 294, 264], "temperature": 0.0, "avg_logprob": -0.1540402403665245, "compression_ratio": 1.7012448132780082, "no_speech_prob": 5.506282832357101e-06}, {"id": 158, "seek": 76612, "start": 766.12, "end": 773.84, "text": " assigned commit, and then whenever you recreate, there's no need to extend the OSTree format", "tokens": [13279, 5599, 11, 293, 550, 5699, 291, 25833, 11, 456, 311, 572, 643, 281, 10101, 264, 422, 6840, 701, 7877], "temperature": 0.0, "avg_logprob": -0.16079319629472555, "compression_ratio": 1.7400881057268722, "no_speech_prob": 1.6958121705101803e-05}, {"id": 159, "seek": 76612, "start": 773.84, "end": 779.24, "text": " on the network or anything, what you do is when you deploy a commit, instead of making", "tokens": [322, 264, 3209, 420, 1340, 11, 437, 291, 360, 307, 562, 291, 7274, 257, 5599, 11, 2602, 295, 1455], "temperature": 0.0, "avg_logprob": -0.16079319629472555, "compression_ratio": 1.7400881057268722, "no_speech_prob": 1.6958121705101803e-05}, {"id": 160, "seek": 76612, "start": 779.24, "end": 784.88, "text": " this hardling farm, you recreate one of these, and then you use the supply digest as the", "tokens": [341, 1152, 1688, 5421, 11, 291, 25833, 472, 295, 613, 11, 293, 550, 291, 764, 264, 5847, 13884, 382, 264], "temperature": 0.0, "avg_logprob": -0.16079319629472555, "compression_ratio": 1.7400881057268722, "no_speech_prob": 1.6958121705101803e-05}, {"id": 161, "seek": 76612, "start": 784.88, "end": 792.32, "text": " expected digest when you mount it, so if anything anywhere went wrong or was attacked or whatever,", "tokens": [5176, 13884, 562, 291, 3746, 309, 11, 370, 498, 1340, 4992, 1437, 2085, 420, 390, 12692, 420, 2035, 11], "temperature": 0.0, "avg_logprob": -0.16079319629472555, "compression_ratio": 1.7400881057268722, "no_speech_prob": 1.6958121705101803e-05}, {"id": 162, "seek": 76612, "start": 792.32, "end": 794.76, "text": " it will refuse to mount it.", "tokens": [309, 486, 16791, 281, 3746, 309, 13], "temperature": 0.0, "avg_logprob": -0.16079319629472555, "compression_ratio": 1.7400881057268722, "no_speech_prob": 1.6958121705101803e-05}, {"id": 163, "seek": 79476, "start": 794.76, "end": 801.56, "text": " So obviously you have to put that trusted digest somewhere in your secure boot stack", "tokens": [407, 2745, 291, 362, 281, 829, 300, 16034, 13884, 4079, 294, 428, 7144, 11450, 8630], "temperature": 0.0, "avg_logprob": -0.1386625545541036, "compression_ratio": 1.5843621399176955, "no_speech_prob": 1.0056891369458754e-05}, {"id": 164, "seek": 79476, "start": 801.56, "end": 807.36, "text": " or whatever, something would have to, it has to be trusted, but that's outside exactly", "tokens": [420, 2035, 11, 746, 576, 362, 281, 11, 309, 575, 281, 312, 16034, 11, 457, 300, 311, 2380, 2293], "temperature": 0.0, "avg_logprob": -0.1386625545541036, "compression_ratio": 1.5843621399176955, "no_speech_prob": 1.0056891369458754e-05}, {"id": 165, "seek": 79476, "start": 807.36, "end": 815.48, "text": " of the scope of ComposeFS, and it's very similar to what you would do with DMVarity in a pure", "tokens": [295, 264, 11923, 295, 6620, 541, 29318, 11, 293, 309, 311, 588, 2531, 281, 437, 291, 576, 360, 365, 15322, 53, 17409, 294, 257, 6075], "temperature": 0.0, "avg_logprob": -0.1386625545541036, "compression_ratio": 1.5843621399176955, "no_speech_prob": 1.0056891369458754e-05}, {"id": 166, "seek": 79476, "start": 815.48, "end": 818.4, "text": " image based system.", "tokens": [3256, 2361, 1185, 13], "temperature": 0.0, "avg_logprob": -0.1386625545541036, "compression_ratio": 1.5843621399176955, "no_speech_prob": 1.0056891369458754e-05}, {"id": 167, "seek": 79476, "start": 818.4, "end": 823.56, "text": " But another interesting use case is the container use case, and Giuseppe, who is not here actually,", "tokens": [583, 1071, 1880, 764, 1389, 307, 264, 10129, 764, 1389, 11, 293, 15334, 438, 19833, 11, 567, 307, 406, 510, 767, 11], "temperature": 0.0, "avg_logprob": -0.1386625545541036, "compression_ratio": 1.5843621399176955, "no_speech_prob": 1.0056891369458754e-05}, {"id": 168, "seek": 82356, "start": 823.56, "end": 829.28, "text": " but he is one of the other people behind the ComposeFS developers, he is more, he's one", "tokens": [457, 415, 307, 472, 295, 264, 661, 561, 2261, 264, 6620, 541, 29318, 8849, 11, 415, 307, 544, 11, 415, 311, 472], "temperature": 0.0, "avg_logprob": -0.15352658302553238, "compression_ratio": 1.6919431279620853, "no_speech_prob": 8.340463682543486e-05}, {"id": 169, "seek": 82356, "start": 829.28, "end": 836.4, "text": " of the podmem developers, so his use case is to use this for containers, because containers", "tokens": [295, 264, 2497, 17886, 8849, 11, 370, 702, 764, 1389, 307, 281, 764, 341, 337, 17089, 11, 570, 17089], "temperature": 0.0, "avg_logprob": -0.15352658302553238, "compression_ratio": 1.6919431279620853, "no_speech_prob": 8.340463682543486e-05}, {"id": 170, "seek": 82356, "start": 836.4, "end": 843.68, "text": " are also used in images, right, and it would be nice if we can get this very, what I call", "tokens": [366, 611, 1143, 294, 5267, 11, 558, 11, 293, 309, 576, 312, 1481, 498, 321, 393, 483, 341, 588, 11, 437, 286, 818], "temperature": 0.0, "avg_logprob": -0.15352658302553238, "compression_ratio": 1.6919431279620853, "no_speech_prob": 8.340463682543486e-05}, {"id": 171, "seek": 82356, "start": 843.68, "end": 849.64, "text": " opportunistic sharing of files, like if you use layers and stuff, you can sort of share", "tokens": [2070, 3142, 5414, 295, 7098, 11, 411, 498, 291, 764, 7914, 293, 1507, 11, 291, 393, 1333, 295, 2073], "temperature": 0.0, "avg_logprob": -0.15352658302553238, "compression_ratio": 1.6919431279620853, "no_speech_prob": 8.340463682543486e-05}, {"id": 172, "seek": 84964, "start": 849.64, "end": 855.36, "text": " stuff between different containers, but you have to manually ensure you do the right thing,", "tokens": [1507, 1296, 819, 17089, 11, 457, 291, 362, 281, 16945, 5586, 291, 360, 264, 558, 551, 11], "temperature": 0.0, "avg_logprob": -0.1651145511203342, "compression_ratio": 1.610655737704918, "no_speech_prob": 1.466420235374244e-05}, {"id": 173, "seek": 84964, "start": 855.36, "end": 860.88, "text": " whereas with this opportunistic style of sharing, whenever you happen to have a file that is", "tokens": [9735, 365, 341, 2070, 3142, 3758, 295, 5414, 11, 5699, 291, 1051, 281, 362, 257, 3991, 300, 307], "temperature": 0.0, "avg_logprob": -0.1651145511203342, "compression_ratio": 1.610655737704918, "no_speech_prob": 1.466420235374244e-05}, {"id": 174, "seek": 84964, "start": 860.88, "end": 867.24, "text": " identical, it just automatically gets shared, both on disk and in page cache, because of", "tokens": [14800, 11, 309, 445, 6772, 2170, 5507, 11, 1293, 322, 12355, 293, 294, 3028, 19459, 11, 570, 295], "temperature": 0.0, "avg_logprob": -0.1651145511203342, "compression_ratio": 1.610655737704918, "no_speech_prob": 1.466420235374244e-05}, {"id": 175, "seek": 84964, "start": 867.24, "end": 871.8, "text": " the way these things work.", "tokens": [264, 636, 613, 721, 589, 13], "temperature": 0.0, "avg_logprob": -0.1651145511203342, "compression_ratio": 1.610655737704918, "no_speech_prob": 1.466420235374244e-05}, {"id": 176, "seek": 84964, "start": 871.8, "end": 878.3199999999999, "text": " So we also don't want to change the container format, there was a talk yesterday about using", "tokens": [407, 321, 611, 500, 380, 528, 281, 1319, 264, 10129, 7877, 11, 456, 390, 257, 751, 5186, 466, 1228], "temperature": 0.0, "avg_logprob": -0.1651145511203342, "compression_ratio": 1.610655737704918, "no_speech_prob": 1.466420235374244e-05}, {"id": 177, "seek": 87832, "start": 878.32, "end": 884.72, "text": " DMVarity in SquashFS, for, it's not sharing, but like the similar kind of way you can mount", "tokens": [15322, 53, 17409, 294, 8683, 1299, 29318, 11, 337, 11, 309, 311, 406, 5414, 11, 457, 411, 264, 2531, 733, 295, 636, 291, 393, 3746], "temperature": 0.0, "avg_logprob": -0.2483071058224409, "compression_ratio": 1.4385026737967914, "no_speech_prob": 2.9740118407062255e-05}, {"id": 178, "seek": 87832, "start": 884.72, "end": 893.5600000000001, "text": " an image, but we don't want to, that forces all the users to create a new form of container,", "tokens": [364, 3256, 11, 457, 321, 500, 380, 528, 281, 11, 300, 5874, 439, 264, 5022, 281, 1884, 257, 777, 1254, 295, 10129, 11], "temperature": 0.0, "avg_logprob": -0.2483071058224409, "compression_ratio": 1.4385026737967914, "no_speech_prob": 2.9740118407062255e-05}, {"id": 179, "seek": 87832, "start": 893.5600000000001, "end": 903.96, "text": " but we want to use, allow this for all existing, tarble based layered BOSIAI images.", "tokens": [457, 321, 528, 281, 764, 11, 2089, 341, 337, 439, 6741, 11, 3112, 638, 2361, 34666, 363, 4367, 6914, 40, 5267, 13], "temperature": 0.0, "avg_logprob": -0.2483071058224409, "compression_ratio": 1.4385026737967914, "no_speech_prob": 2.9740118407062255e-05}, {"id": 180, "seek": 90396, "start": 903.96, "end": 910.96, "text": " So an image in the OSIAI world is a list of tarbles that you extract in order, and then", "tokens": [407, 364, 3256, 294, 264, 12731, 6914, 40, 1002, 307, 257, 1329, 295, 3112, 8806, 300, 291, 8947, 294, 1668, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.2515247939923488, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.709806489699986e-06}, {"id": 181, "seek": 90396, "start": 910.96, "end": 914.52, "text": " you're mounting using over the AFS.", "tokens": [291, 434, 22986, 1228, 670, 264, 20389, 50, 13], "temperature": 0.0, "avg_logprob": -0.2515247939923488, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.709806489699986e-06}, {"id": 182, "seek": 90396, "start": 914.52, "end": 920.96, "text": " There is an extension of this called ETAR, ETARGC, which is some weird ass hack where", "tokens": [821, 307, 364, 10320, 295, 341, 1219, 36953, 1899, 11, 36953, 1899, 38, 34, 11, 597, 307, 512, 3657, 1256, 10339, 689], "temperature": 0.0, "avg_logprob": -0.2515247939923488, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.709806489699986e-06}, {"id": 183, "seek": 90396, "start": 920.96, "end": 926.44, "text": " you put an index at the end of the G-SIP, and then you can use partial HTTP downloads", "tokens": [291, 829, 364, 8186, 412, 264, 917, 295, 264, 460, 12, 50, 9139, 11, 293, 550, 291, 393, 764, 14641, 33283, 36553], "temperature": 0.0, "avg_logprob": -0.2515247939923488, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.709806489699986e-06}, {"id": 184, "seek": 90396, "start": 926.44, "end": 930.8000000000001, "text": " to just get the index, and you can see which part of the layer you already have, and you", "tokens": [281, 445, 483, 264, 8186, 11, 293, 291, 393, 536, 597, 644, 295, 264, 4583, 291, 1217, 362, 11, 293, 291], "temperature": 0.0, "avg_logprob": -0.2515247939923488, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.709806489699986e-06}, {"id": 185, "seek": 93080, "start": 930.8, "end": 935.4799999999999, "text": " can just range HTTP gets to only download those parts.", "tokens": [393, 445, 3613, 33283, 2170, 281, 787, 5484, 729, 3166, 13], "temperature": 0.0, "avg_logprob": -0.14379180561412463, "compression_ratio": 1.625, "no_speech_prob": 1.0285917596775107e-05}, {"id": 186, "seek": 93080, "start": 935.4799999999999, "end": 941.4799999999999, "text": " So if you happen to have one of those archives in your layers, we can in combination with", "tokens": [407, 498, 291, 1051, 281, 362, 472, 295, 729, 25607, 294, 428, 7914, 11, 321, 393, 294, 6562, 365], "temperature": 0.0, "avg_logprob": -0.14379180561412463, "compression_ratio": 1.625, "no_speech_prob": 1.0285917596775107e-05}, {"id": 187, "seek": 93080, "start": 941.4799999999999, "end": 947.68, "text": " the locally stored content of the storage, avoid downloading the parts that we don't", "tokens": [264, 16143, 12187, 2701, 295, 264, 6725, 11, 5042, 32529, 264, 3166, 300, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.14379180561412463, "compression_ratio": 1.625, "no_speech_prob": 1.0285917596775107e-05}, {"id": 188, "seek": 93080, "start": 947.68, "end": 948.68, "text": " need.", "tokens": [643, 13], "temperature": 0.0, "avg_logprob": -0.14379180561412463, "compression_ratio": 1.625, "no_speech_prob": 1.0285917596775107e-05}, {"id": 189, "seek": 93080, "start": 948.68, "end": 955.04, "text": " If you don't have them, we have to download everything, which is what we do now, but we", "tokens": [759, 291, 500, 380, 362, 552, 11, 321, 362, 281, 5484, 1203, 11, 597, 307, 437, 321, 360, 586, 11, 457, 321], "temperature": 0.0, "avg_logprob": -0.14379180561412463, "compression_ratio": 1.625, "no_speech_prob": 1.0285917596775107e-05}, {"id": 190, "seek": 93080, "start": 955.04, "end": 956.04, "text": " can do better.", "tokens": [393, 360, 1101, 13], "temperature": 0.0, "avg_logprob": -0.14379180561412463, "compression_ratio": 1.625, "no_speech_prob": 1.0285917596775107e-05}, {"id": 191, "seek": 95604, "start": 956.04, "end": 963.64, "text": " But even then, you can still hash them locally and get all the sharing, and then you combine", "tokens": [583, 754, 550, 11, 291, 393, 920, 22019, 552, 16143, 293, 483, 439, 264, 5414, 11, 293, 550, 291, 10432], "temperature": 0.0, "avg_logprob": -0.2597661825326773, "compression_ratio": 1.612121212121212, "no_speech_prob": 2.1750967789557762e-05}, {"id": 192, "seek": 95604, "start": 963.64, "end": 975.5999999999999, "text": " this with creating an overly composed FS for the entire image, so you mount, this is for", "tokens": [341, 365, 4084, 364, 24324, 18204, 41138, 337, 264, 2302, 3256, 11, 370, 291, 3746, 11, 341, 307, 337], "temperature": 0.0, "avg_logprob": -0.2597661825326773, "compression_ratio": 1.612121212121212, "no_speech_prob": 2.1750967789557762e-05}, {"id": 193, "seek": 95604, "start": 975.5999999999999, "end": 981.76, "text": " the local storage of images, you can use, instead of storing these layers, you store", "tokens": [264, 2654, 6725, 295, 5267, 11, 291, 393, 764, 11, 2602, 295, 26085, 613, 7914, 11, 291, 3531], "temperature": 0.0, "avg_logprob": -0.2597661825326773, "compression_ratio": 1.612121212121212, "no_speech_prob": 2.1750967789557762e-05}, {"id": 194, "seek": 98176, "start": 981.76, "end": 991.76, "text": " the repository, or content store repository, plus these generated composed FS images, and", "tokens": [264, 25841, 11, 420, 2701, 3531, 25841, 11, 1804, 613, 10833, 18204, 41138, 5267, 11, 293], "temperature": 0.0, "avg_logprob": -0.21163148658220157, "compression_ratio": 1.6009852216748768, "no_speech_prob": 1.2216555660415906e-05}, {"id": 195, "seek": 98176, "start": 991.76, "end": 996.12, "text": " then whenever you run this, you just mount it, and it goes.", "tokens": [550, 5699, 291, 1190, 341, 11, 291, 445, 3746, 309, 11, 293, 309, 1709, 13], "temperature": 0.0, "avg_logprob": -0.21163148658220157, "compression_ratio": 1.6009852216748768, "no_speech_prob": 1.2216555660415906e-05}, {"id": 196, "seek": 98176, "start": 996.12, "end": 1003.76, "text": " It's also nice, you can easily combine all the layers, so if you have a 10-layer container,", "tokens": [467, 311, 611, 1481, 11, 291, 393, 3612, 10432, 439, 264, 7914, 11, 370, 498, 291, 362, 257, 1266, 12, 8376, 260, 10129, 11], "temperature": 0.0, "avg_logprob": -0.21163148658220157, "compression_ratio": 1.6009852216748768, "no_speech_prob": 1.2216555660415906e-05}, {"id": 197, "seek": 98176, "start": 1003.76, "end": 1008.4399999999999, "text": " and you want to resolve libc, which is in the base layer, you have to do a negative", "tokens": [293, 291, 528, 281, 14151, 22854, 66, 11, 597, 307, 294, 264, 3096, 4583, 11, 291, 362, 281, 360, 257, 3671], "temperature": 0.0, "avg_logprob": -0.21163148658220157, "compression_ratio": 1.6009852216748768, "no_speech_prob": 1.2216555660415906e-05}, {"id": 198, "seek": 100844, "start": 1008.44, "end": 1014.8800000000001, "text": " entry lookup in every layer before you reach the bottom most, but since the image is metadata,", "tokens": [8729, 574, 1010, 294, 633, 4583, 949, 291, 2524, 264, 2767, 881, 11, 457, 1670, 264, 3256, 307, 26603, 11], "temperature": 0.0, "avg_logprob": -0.21368105982390928, "compression_ratio": 1.5, "no_speech_prob": 1.280147353099892e-05}, {"id": 199, "seek": 100844, "start": 1014.8800000000001, "end": 1026.8, "text": " it's very cheap to create a completely squashed composed FS image for single-layer lookups.", "tokens": [309, 311, 588, 7084, 281, 1884, 257, 2584, 2339, 12219, 18204, 41138, 3256, 337, 2167, 12, 8376, 260, 574, 7528, 13], "temperature": 0.0, "avg_logprob": -0.21368105982390928, "compression_ratio": 1.5, "no_speech_prob": 1.280147353099892e-05}, {"id": 200, "seek": 100844, "start": 1026.8, "end": 1031.52, "text": " And I don't know if anyone is following the list, but there are some discussions about", "tokens": [400, 286, 500, 380, 458, 498, 2878, 307, 3480, 264, 1329, 11, 457, 456, 366, 512, 11088, 466], "temperature": 0.0, "avg_logprob": -0.21368105982390928, "compression_ratio": 1.5, "no_speech_prob": 1.280147353099892e-05}, {"id": 201, "seek": 100844, "start": 1031.52, "end": 1032.52, "text": " this.", "tokens": [341, 13], "temperature": 0.0, "avg_logprob": -0.21368105982390928, "compression_ratio": 1.5, "no_speech_prob": 1.280147353099892e-05}, {"id": 202, "seek": 103252, "start": 1032.52, "end": 1038.6, "text": " We're trying to get it merged upstream, and one alternative has appeared, that there's", "tokens": [492, 434, 1382, 281, 483, 309, 36427, 33915, 11, 293, 472, 8535, 575, 8516, 11, 300, 456, 311], "temperature": 0.0, "avg_logprob": -0.2401229185216567, "compression_ratio": 1.6457399103139014, "no_speech_prob": 2.4289440261782147e-05}, {"id": 203, "seek": 103252, "start": 1038.6, "end": 1046.76, "text": " ways that you can actually use some of overlay FS features to sort of get these features.", "tokens": [2098, 300, 291, 393, 767, 764, 512, 295, 31741, 41138, 4122, 281, 1333, 295, 483, 613, 4122, 13], "temperature": 0.0, "avg_logprob": -0.2401229185216567, "compression_ratio": 1.6457399103139014, "no_speech_prob": 2.4289440261782147e-05}, {"id": 204, "seek": 103252, "start": 1046.76, "end": 1053.44, "text": " If you use the not super well-known or documented features called overlay redirect and overlay", "tokens": [759, 291, 764, 264, 406, 1687, 731, 12, 6861, 420, 23007, 4122, 1219, 31741, 29066, 293, 31741], "temperature": 0.0, "avg_logprob": -0.2401229185216567, "compression_ratio": 1.6457399103139014, "no_speech_prob": 2.4289440261782147e-05}, {"id": 205, "seek": 103252, "start": 1053.44, "end": 1062.44, "text": " meta-copy, you can create an overlay FS layer that does a similar style of here or the metadata", "tokens": [19616, 12, 13084, 88, 11, 291, 393, 1884, 364, 31741, 41138, 4583, 300, 775, 257, 2531, 3758, 295, 510, 420, 264, 26603], "temperature": 0.0, "avg_logprob": -0.2401229185216567, "compression_ratio": 1.6457399103139014, "no_speech_prob": 2.4289440261782147e-05}, {"id": 206, "seek": 106244, "start": 1062.44, "end": 1069.8400000000001, "text": " for this attribute redirected to a different path, which would be the content address name", "tokens": [337, 341, 19667, 29066, 292, 281, 257, 819, 3100, 11, 597, 576, 312, 264, 2701, 2985, 1315], "temperature": 0.0, "avg_logprob": -0.1488181254902824, "compression_ratio": 1.5664739884393064, "no_speech_prob": 9.36603555601323e-06}, {"id": 207, "seek": 106244, "start": 1069.8400000000001, "end": 1076.3600000000001, "text": " in the lower layer, and then you can use some kind of read-only file system for the upper", "tokens": [294, 264, 3126, 4583, 11, 293, 550, 291, 393, 764, 512, 733, 295, 1401, 12, 25202, 3991, 1185, 337, 264, 6597], "temperature": 0.0, "avg_logprob": -0.1488181254902824, "compression_ratio": 1.5664739884393064, "no_speech_prob": 9.36603555601323e-06}, {"id": 208, "seek": 106244, "start": 1076.3600000000001, "end": 1082.6000000000001, "text": " layer where you store all these extended attribute files that just contain this structure.", "tokens": [4583, 689, 291, 3531, 439, 613, 10913, 19667, 7098, 300, 445, 5304, 341, 3877, 13], "temperature": 0.0, "avg_logprob": -0.1488181254902824, "compression_ratio": 1.5664739884393064, "no_speech_prob": 9.36603555601323e-06}, {"id": 209, "seek": 108260, "start": 1082.6, "end": 1093.0, "text": " So this combination of overlay FS plus right now ERO FS is probably the best approach for", "tokens": [407, 341, 6562, 295, 31741, 41138, 1804, 558, 586, 462, 7142, 41138, 307, 1391, 264, 1151, 3109, 337], "temperature": 0.0, "avg_logprob": -0.2440509796142578, "compression_ratio": 1.4870466321243523, "no_speech_prob": 7.223432021419285e-07}, {"id": 210, "seek": 108260, "start": 1093.0, "end": 1096.8, "text": " those for the upper layer.", "tokens": [729, 337, 264, 6597, 4583, 13], "temperature": 0.0, "avg_logprob": -0.2440509796142578, "compression_ratio": 1.4870466321243523, "no_speech_prob": 7.223432021419285e-07}, {"id": 211, "seek": 108260, "start": 1096.8, "end": 1098.76, "text": " You can sort of create this.", "tokens": [509, 393, 1333, 295, 1884, 341, 13], "temperature": 0.0, "avg_logprob": -0.2440509796142578, "compression_ratio": 1.4870466321243523, "no_speech_prob": 7.223432021419285e-07}, {"id": 212, "seek": 108260, "start": 1098.76, "end": 1101.8, "text": " Unfortunately, that doesn't do the verification.", "tokens": [8590, 11, 300, 1177, 380, 360, 264, 30206, 13], "temperature": 0.0, "avg_logprob": -0.2440509796142578, "compression_ratio": 1.4870466321243523, "no_speech_prob": 7.223432021419285e-07}, {"id": 213, "seek": 108260, "start": 1101.8, "end": 1109.98, "text": " You can use the overlay or read-only file system itself, but you need some kind of extension", "tokens": [509, 393, 764, 264, 670, 8376, 420, 1401, 12, 25202, 3991, 1185, 2564, 11, 457, 291, 643, 512, 733, 295, 10320], "temperature": 0.0, "avg_logprob": -0.2440509796142578, "compression_ratio": 1.4870466321243523, "no_speech_prob": 7.223432021419285e-07}, {"id": 214, "seek": 110998, "start": 1109.98, "end": 1117.76, "text": " to overlay itself to allow this recording of the expected FS variety of the backing file.", "tokens": [281, 31741, 2564, 281, 2089, 341, 6613, 295, 264, 5176, 41138, 5673, 295, 264, 19373, 3991, 13], "temperature": 0.0, "avg_logprob": -0.19437567392985025, "compression_ratio": 1.5372340425531914, "no_speech_prob": 1.9023175354959676e-06}, {"id": 215, "seek": 110998, "start": 1117.76, "end": 1121.08, "text": " But that does seem like a trivial thing.", "tokens": [583, 300, 775, 1643, 411, 257, 26703, 551, 13], "temperature": 0.0, "avg_logprob": -0.19437567392985025, "compression_ratio": 1.5372340425531914, "no_speech_prob": 1.9023175354959676e-06}, {"id": 216, "seek": 110998, "start": 1121.08, "end": 1128.4, "text": " The less trivial part, and this is where opinions on the list vary, is I think this kind of combination", "tokens": [440, 1570, 26703, 644, 11, 293, 341, 307, 689, 11819, 322, 264, 1329, 10559, 11, 307, 286, 519, 341, 733, 295, 6562], "temperature": 0.0, "avg_logprob": -0.19437567392985025, "compression_ratio": 1.5372340425531914, "no_speech_prob": 1.9023175354959676e-06}, {"id": 217, "seek": 110998, "start": 1128.4, "end": 1134.52, "text": " of things is way more complicated than the simple one.", "tokens": [295, 721, 307, 636, 544, 6179, 813, 264, 2199, 472, 13], "temperature": 0.0, "avg_logprob": -0.19437567392985025, "compression_ratio": 1.5372340425531914, "no_speech_prob": 1.9023175354959676e-06}, {"id": 218, "seek": 113452, "start": 1134.52, "end": 1141.12, "text": " Compose FS is, I think, 1,800 lines of code.", "tokens": [6620, 541, 41138, 307, 11, 286, 519, 11, 502, 11, 14423, 3876, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.20988029386939072, "compression_ratio": 1.5053191489361701, "no_speech_prob": 3.040931687792181e-06}, {"id": 219, "seek": 113452, "start": 1141.12, "end": 1142.12, "text": " It's very direct.", "tokens": [467, 311, 588, 2047, 13], "temperature": 0.0, "avg_logprob": -0.20988029386939072, "compression_ratio": 1.5053191489361701, "no_speech_prob": 3.040931687792181e-06}, {"id": 220, "seek": 113452, "start": 1142.12, "end": 1145.2, "text": " It doesn't use loopback devices, device wrapper devices.", "tokens": [467, 1177, 380, 764, 6367, 3207, 5759, 11, 4302, 46906, 5759, 13], "temperature": 0.0, "avg_logprob": -0.20988029386939072, "compression_ratio": 1.5053191489361701, "no_speech_prob": 3.040931687792181e-06}, {"id": 221, "seek": 113452, "start": 1145.2, "end": 1152.92, "text": " When you do a lookup in this combined thing of a particular file, you would do a lookup", "tokens": [1133, 291, 360, 257, 574, 1010, 294, 341, 9354, 551, 295, 257, 1729, 3991, 11, 291, 576, 360, 257, 574, 1010], "temperature": 0.0, "avg_logprob": -0.20988029386939072, "compression_ratio": 1.5053191489361701, "no_speech_prob": 3.040931687792181e-06}, {"id": 222, "seek": 113452, "start": 1152.92, "end": 1162.56, "text": " in the overlay layer in the read-only system and in all the backing layers.", "tokens": [294, 264, 31741, 4583, 294, 264, 1401, 12, 25202, 1185, 293, 294, 439, 264, 19373, 7914, 13], "temperature": 0.0, "avg_logprob": -0.20988029386939072, "compression_ratio": 1.5053191489361701, "no_speech_prob": 3.040931687792181e-06}, {"id": 223, "seek": 116256, "start": 1162.56, "end": 1170.28, "text": " So there's like four times more inodes around, there's four times more decash lookups, and", "tokens": [407, 456, 311, 411, 1451, 1413, 544, 294, 4789, 926, 11, 456, 311, 1451, 1413, 544, 979, 1299, 574, 7528, 11, 293], "temperature": 0.0, "avg_logprob": -0.24828399099954745, "compression_ratio": 1.595, "no_speech_prob": 5.7700153774931096e-06}, {"id": 224, "seek": 116256, "start": 1170.28, "end": 1175.0, "text": " it just uses more memory and performs worse.", "tokens": [309, 445, 4960, 544, 4675, 293, 26213, 5324, 13], "temperature": 0.0, "avg_logprob": -0.24828399099954745, "compression_ratio": 1.595, "no_speech_prob": 5.7700153774931096e-06}, {"id": 225, "seek": 116256, "start": 1175.0, "end": 1177.32, "text": " So I ran some simple lookups.", "tokens": [407, 286, 5872, 512, 2199, 574, 7528, 13], "temperature": 0.0, "avg_logprob": -0.24828399099954745, "compression_ratio": 1.595, "no_speech_prob": 5.7700153774931096e-06}, {"id": 226, "seek": 116256, "start": 1177.32, "end": 1180.6799999999998, "text": " These are just some people complain about the measurements here.", "tokens": [1981, 366, 445, 512, 561, 11024, 466, 264, 15383, 510, 13], "temperature": 0.0, "avg_logprob": -0.24828399099954745, "compression_ratio": 1.595, "no_speech_prob": 5.7700153774931096e-06}, {"id": 227, "seek": 116256, "start": 1180.6799999999998, "end": 1189.76, "text": " I'm just comparing like a recursive find or LSDTR, which is basically just measuring the", "tokens": [286, 478, 445, 15763, 411, 257, 20560, 488, 915, 420, 441, 23969, 25936, 11, 597, 307, 1936, 445, 13389, 264], "temperature": 0.0, "avg_logprob": -0.24828399099954745, "compression_ratio": 1.595, "no_speech_prob": 5.7700153774931096e-06}, {"id": 228, "seek": 118976, "start": 1189.76, "end": 1194.16, "text": " performance of lookups and readers.", "tokens": [3389, 295, 574, 7528, 293, 17147, 13], "temperature": 0.0, "avg_logprob": -0.1981837932880108, "compression_ratio": 1.6017316017316017, "no_speech_prob": 3.137600060654222e-06}, {"id": 229, "seek": 118976, "start": 1194.16, "end": 1197.2, "text": " But on the other hand, that's all that Compose FS does.", "tokens": [583, 322, 264, 661, 1011, 11, 300, 311, 439, 300, 6620, 541, 41138, 775, 13], "temperature": 0.0, "avg_logprob": -0.1981837932880108, "compression_ratio": 1.6017316017316017, "no_speech_prob": 3.137600060654222e-06}, {"id": 230, "seek": 118976, "start": 1197.2, "end": 1202.56, "text": " I mean, all the actual IO performance is left to the backing file system.", "tokens": [286, 914, 11, 439, 264, 3539, 39839, 3389, 307, 1411, 281, 264, 19373, 3991, 1185, 13], "temperature": 0.0, "avg_logprob": -0.1981837932880108, "compression_ratio": 1.6017316017316017, "no_speech_prob": 3.137600060654222e-06}, {"id": 231, "seek": 118976, "start": 1202.56, "end": 1207.12, "text": " So wherever you store your read files, that's where like streaming performance and things", "tokens": [407, 8660, 291, 3531, 428, 1401, 7098, 11, 300, 311, 689, 411, 11791, 3389, 293, 721], "temperature": 0.0, "avg_logprob": -0.1981837932880108, "compression_ratio": 1.6017316017316017, "no_speech_prob": 3.137600060654222e-06}, {"id": 232, "seek": 118976, "start": 1207.12, "end": 1208.8799999999999, "text": " like that would appear.", "tokens": [411, 300, 576, 4204, 13], "temperature": 0.0, "avg_logprob": -0.1981837932880108, "compression_ratio": 1.6017316017316017, "no_speech_prob": 3.137600060654222e-06}, {"id": 233, "seek": 118976, "start": 1208.8799999999999, "end": 1217.24, "text": " So I'm personally in the automotive use case right now, so we have very harsh requirements", "tokens": [407, 286, 478, 5665, 294, 264, 32866, 764, 1389, 558, 586, 11, 370, 321, 362, 588, 14897, 7728], "temperature": 0.0, "avg_logprob": -0.1981837932880108, "compression_ratio": 1.6017316017316017, "no_speech_prob": 3.137600060654222e-06}, {"id": 234, "seek": 121724, "start": 1217.24, "end": 1224.84, "text": " on cool boot performance, so the cold cache numbers are very important to me.", "tokens": [322, 1627, 11450, 3389, 11, 370, 264, 3554, 19459, 3547, 366, 588, 1021, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.17174680182274352, "compression_ratio": 1.646551724137931, "no_speech_prob": 1.4278456546890084e-05}, {"id": 235, "seek": 121724, "start": 1224.84, "end": 1230.1200000000001, "text": " I mean, you might not, this is like listing recursively a large developer snapshot, like", "tokens": [286, 914, 11, 291, 1062, 406, 11, 341, 307, 411, 22161, 20560, 3413, 257, 2416, 10754, 30163, 11, 411], "temperature": 0.0, "avg_logprob": -0.17174680182274352, "compression_ratio": 1.646551724137931, "no_speech_prob": 1.4278456546890084e-05}, {"id": 236, "seek": 121724, "start": 1230.1200000000001, "end": 1233.4, "text": " a three gigabyte Centro Stream 9 image.", "tokens": [257, 1045, 8741, 34529, 3408, 340, 24904, 1722, 3256, 13], "temperature": 0.0, "avg_logprob": -0.17174680182274352, "compression_ratio": 1.646551724137931, "no_speech_prob": 1.4278456546890084e-05}, {"id": 237, "seek": 121724, "start": 1233.4, "end": 1239.72, "text": " So it's not an operation you might do, but just looking at the numbers, the recursive", "tokens": [407, 309, 311, 406, 364, 6916, 291, 1062, 360, 11, 457, 445, 1237, 412, 264, 3547, 11, 264, 20560, 488], "temperature": 0.0, "avg_logprob": -0.17174680182274352, "compression_ratio": 1.646551724137931, "no_speech_prob": 1.4278456546890084e-05}, {"id": 238, "seek": 121724, "start": 1239.72, "end": 1246.2, "text": " listing is more than like three times slower for the cold cache situation, because it has", "tokens": [22161, 307, 544, 813, 411, 1045, 1413, 14009, 337, 264, 3554, 19459, 2590, 11, 570, 309, 575], "temperature": 0.0, "avg_logprob": -0.17174680182274352, "compression_ratio": 1.646551724137931, "no_speech_prob": 1.4278456546890084e-05}, {"id": 239, "seek": 124620, "start": 1246.2, "end": 1250.04, "text": " to do multiple lookups.", "tokens": [281, 360, 3866, 574, 7528, 13], "temperature": 0.0, "avg_logprob": -0.31811338000827366, "compression_ratio": 1.4230769230769231, "no_speech_prob": 7.645149162271991e-05}, {"id": 240, "seek": 124620, "start": 1250.04, "end": 1258.56, "text": " And even for the cached case, where most things should be from the decad anyway, I think I've", "tokens": [400, 754, 337, 264, 269, 15095, 1389, 11, 689, 881, 721, 820, 312, 490, 264, 979, 345, 4033, 11, 286, 519, 286, 600], "temperature": 0.0, "avg_logprob": -0.31811338000827366, "compression_ratio": 1.4230769230769231, "no_speech_prob": 7.645149162271991e-05}, {"id": 241, "seek": 124620, "start": 1258.56, "end": 1263.76, "text": " seen better numbers than this, but there's at least 10% difference in the warm cache", "tokens": [1612, 1101, 3547, 813, 341, 11, 457, 456, 311, 412, 1935, 1266, 4, 2649, 294, 264, 4561, 19459], "temperature": 0.0, "avg_logprob": -0.31811338000827366, "compression_ratio": 1.4230769230769231, "no_speech_prob": 7.645149162271991e-05}, {"id": 242, "seek": 124620, "start": 1263.76, "end": 1267.24, "text": " situation.", "tokens": [2590, 13], "temperature": 0.0, "avg_logprob": -0.31811338000827366, "compression_ratio": 1.4230769230769231, "no_speech_prob": 7.645149162271991e-05}, {"id": 243, "seek": 124620, "start": 1267.24, "end": 1273.0800000000002, "text": " I hope that was useful to do something on it.", "tokens": [286, 1454, 300, 390, 4420, 281, 360, 746, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.31811338000827366, "compression_ratio": 1.4230769230769231, "no_speech_prob": 7.645149162271991e-05}, {"id": 244, "seek": 127308, "start": 1273.08, "end": 1277.28, "text": " Yeah, we have some time for questions.", "tokens": [865, 11, 321, 362, 512, 565, 337, 1651, 13], "temperature": 0.0, "avg_logprob": -0.14956928479789508, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.00039043964352458715}, {"id": 245, "seek": 127308, "start": 1277.28, "end": 1282.8799999999999, "text": " So you said about halfway through that one of the goals was to actually keep the reading", "tokens": [407, 291, 848, 466, 15461, 807, 300, 472, 295, 264, 5493, 390, 281, 767, 1066, 264, 3760], "temperature": 0.0, "avg_logprob": -0.14956928479789508, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.00039043964352458715}, {"id": 246, "seek": 127308, "start": 1282.8799999999999, "end": 1288.24, "text": " the OCI image format, but I think everybody pretty much agrees the OCI image format is", "tokens": [264, 422, 25240, 3256, 7877, 11, 457, 286, 519, 2201, 1238, 709, 26383, 264, 422, 25240, 3256, 7877, 307], "temperature": 0.0, "avg_logprob": -0.14956928479789508, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.00039043964352458715}, {"id": 247, "seek": 127308, "start": 1288.24, "end": 1295.12, "text": " crap for lazy pulling of container images, basically because it has an end-to-end hash", "tokens": [12426, 337, 14847, 8407, 295, 10129, 5267, 11, 1936, 570, 309, 575, 364, 917, 12, 1353, 12, 521, 22019], "temperature": 0.0, "avg_logprob": -0.14956928479789508, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.00039043964352458715}, {"id": 248, "seek": 127308, "start": 1295.12, "end": 1298.84, "text": " so you can't do the hash until you pull the whole image, and that means signatures are", "tokens": [370, 291, 393, 380, 360, 264, 22019, 1826, 291, 2235, 264, 1379, 3256, 11, 293, 300, 1355, 32322, 366], "temperature": 0.0, "avg_logprob": -0.14956928479789508, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.00039043964352458715}, {"id": 249, "seek": 127308, "start": 1298.84, "end": 1300.1999999999998, "text": " completely rubbish anyway.", "tokens": [2584, 29978, 4033, 13], "temperature": 0.0, "avg_logprob": -0.14956928479789508, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.00039043964352458715}, {"id": 250, "seek": 130020, "start": 1300.2, "end": 1304.76, "text": " In order to fix this, we have to do a Merkle tree or something else anyway, so the image", "tokens": [682, 1668, 281, 3191, 341, 11, 321, 362, 281, 360, 257, 6124, 14677, 4230, 420, 746, 1646, 4033, 11, 370, 264, 3256], "temperature": 0.0, "avg_logprob": -0.13499809194494178, "compression_ratio": 1.7131474103585658, "no_speech_prob": 5.764938396168873e-05}, {"id": 251, "seek": 130020, "start": 1304.76, "end": 1309.04, "text": " format is going to have to change radically to something that will be much more suitable", "tokens": [7877, 307, 516, 281, 362, 281, 1319, 35508, 281, 746, 300, 486, 312, 709, 544, 12873], "temperature": 0.0, "avg_logprob": -0.13499809194494178, "compression_ratio": 1.7131474103585658, "no_speech_prob": 5.764938396168873e-05}, {"id": 252, "seek": 130020, "start": 1309.04, "end": 1310.24, "text": " for your image.", "tokens": [337, 428, 3256, 13], "temperature": 0.0, "avg_logprob": -0.13499809194494178, "compression_ratio": 1.7131474103585658, "no_speech_prob": 5.764938396168873e-05}, {"id": 253, "seek": 130020, "start": 1310.24, "end": 1315.48, "text": " So I think trying to keep the image compatibility, which is partly what the argument over this", "tokens": [407, 286, 519, 1382, 281, 1066, 264, 3256, 34237, 11, 597, 307, 17031, 437, 264, 6770, 670, 341], "temperature": 0.0, "avg_logprob": -0.13499809194494178, "compression_ratio": 1.7131474103585658, "no_speech_prob": 5.764938396168873e-05}, {"id": 254, "seek": 130020, "start": 1315.48, "end": 1322.44, "text": " versus the in kernel alternatives is not going to be a good argument for that, and I think", "tokens": [5717, 264, 294, 28256, 20478, 307, 406, 516, 281, 312, 257, 665, 6770, 337, 300, 11, 293, 286, 519], "temperature": 0.0, "avg_logprob": -0.13499809194494178, "compression_ratio": 1.7131474103585658, "no_speech_prob": 5.764938396168873e-05}, {"id": 255, "seek": 130020, "start": 1322.44, "end": 1323.44, "text": " you should consider it.", "tokens": [291, 820, 1949, 309, 13], "temperature": 0.0, "avg_logprob": -0.13499809194494178, "compression_ratio": 1.7131474103585658, "no_speech_prob": 5.764938396168873e-05}, {"id": 256, "seek": 130020, "start": 1323.44, "end": 1324.44, "text": " I agree and I don't agree.", "tokens": [286, 3986, 293, 286, 500, 380, 3986, 13], "temperature": 0.0, "avg_logprob": -0.13499809194494178, "compression_ratio": 1.7131474103585658, "no_speech_prob": 5.764938396168873e-05}, {"id": 257, "seek": 132444, "start": 1324.44, "end": 1331.64, "text": " And I think I'm not a fan of OCI, I've been part of the OCI specification team for a", "tokens": [400, 286, 519, 286, 478, 406, 257, 3429, 295, 422, 25240, 11, 286, 600, 668, 644, 295, 264, 422, 25240, 31256, 1469, 337, 257], "temperature": 0.0, "avg_logprob": -0.21763588016868657, "compression_ratio": 1.626984126984127, "no_speech_prob": 8.93529340828536e-06}, {"id": 258, "seek": 132444, "start": 1331.64, "end": 1332.64, "text": " bit.", "tokens": [857, 13], "temperature": 0.0, "avg_logprob": -0.21763588016868657, "compression_ratio": 1.626984126984127, "no_speech_prob": 8.93529340828536e-06}, {"id": 259, "seek": 132444, "start": 1332.64, "end": 1335.8, "text": " I used to be one of the Docker maintainers a long time ago.", "tokens": [286, 1143, 281, 312, 472, 295, 264, 33772, 6909, 433, 257, 938, 565, 2057, 13], "temperature": 0.0, "avg_logprob": -0.21763588016868657, "compression_ratio": 1.626984126984127, "no_speech_prob": 8.93529340828536e-06}, {"id": 260, "seek": 132444, "start": 1335.8, "end": 1341.56, "text": " It is not nice, but it is what we have, and it's everywhere.", "tokens": [467, 307, 406, 1481, 11, 457, 309, 307, 437, 321, 362, 11, 293, 309, 311, 5315, 13], "temperature": 0.0, "avg_logprob": -0.21763588016868657, "compression_ratio": 1.626984126984127, "no_speech_prob": 8.93529340828536e-06}, {"id": 261, "seek": 132444, "start": 1341.56, "end": 1346.28, "text": " It's so easy as a developer sitting around thinking this is bullshit, we should just", "tokens": [467, 311, 370, 1858, 382, 257, 10754, 3798, 926, 1953, 341, 307, 22676, 11, 321, 820, 445], "temperature": 0.0, "avg_logprob": -0.21763588016868657, "compression_ratio": 1.626984126984127, "no_speech_prob": 8.93529340828536e-06}, {"id": 262, "seek": 132444, "start": 1346.28, "end": 1352.6000000000001, "text": " fix it, but there are like trillions of dollars invested in the existing containers, it's", "tokens": [3191, 309, 11, 457, 456, 366, 411, 504, 46279, 295, 3808, 13104, 294, 264, 6741, 17089, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.21763588016868657, "compression_ratio": 1.626984126984127, "no_speech_prob": 8.93529340828536e-06}, {"id": 263, "seek": 132444, "start": 1352.6000000000001, "end": 1354.0800000000002, "text": " going to be a long time.", "tokens": [516, 281, 312, 257, 938, 565, 13], "temperature": 0.0, "avg_logprob": -0.21763588016868657, "compression_ratio": 1.626984126984127, "no_speech_prob": 8.93529340828536e-06}, {"id": 264, "seek": 135408, "start": 1354.08, "end": 1357.8, "text": " But even when we replace it, this will still do the right thing.", "tokens": [583, 754, 562, 321, 7406, 309, 11, 341, 486, 920, 360, 264, 558, 551, 13], "temperature": 0.0, "avg_logprob": -0.437857707341512, "compression_ratio": 1.5515695067264574, "no_speech_prob": 1.9779394278884865e-05}, {"id": 265, "seek": 135408, "start": 1357.8, "end": 1361.8, "text": " But there are trillions of dollars invested in the hosting cart, so it doesn't stop us", "tokens": [583, 456, 366, 504, 46279, 295, 3808, 13104, 294, 264, 16058, 5467, 11, 370, 309, 1177, 380, 1590, 505], "temperature": 0.0, "avg_logprob": -0.437857707341512, "compression_ratio": 1.5515695067264574, "no_speech_prob": 1.9779394278884865e-05}, {"id": 266, "seek": 135408, "start": 1361.8, "end": 1361.08, "text": " going to the", "tokens": [516, 281, 264], "temperature": 0.0, "avg_logprob": -0.437857707341512, "compression_ratio": 1.5515695067264574, "no_speech_prob": 1.9779394278884865e-05}, {"id": 267, "seek": 135408, "start": 1361.08, "end": 1362.08, "text": " OCI.", "tokens": [422, 25240, 13], "temperature": 0.0, "avg_logprob": -0.437857707341512, "compression_ratio": 1.5515695067264574, "no_speech_prob": 1.9779394278884865e-05}, {"id": 268, "seek": 135408, "start": 1362.08, "end": 1369.6, "text": " True, true, but like there are discussions of OCI V2, I don't follow them because the", "tokens": [13587, 11, 2074, 11, 457, 411, 456, 366, 11088, 295, 422, 25240, 691, 17, 11, 286, 500, 380, 1524, 552, 570, 264], "temperature": 0.0, "avg_logprob": -0.437857707341512, "compression_ratio": 1.5515695067264574, "no_speech_prob": 1.9779394278884865e-05}, {"id": 269, "seek": 135408, "start": 1369.6, "end": 1378.1999999999998, "text": " whole thing is bullshit, but even then, if we just had a better way to get partial updates", "tokens": [1379, 551, 307, 22676, 11, 457, 754, 550, 11, 498, 321, 445, 632, 257, 1101, 636, 281, 483, 14641, 9205], "temperature": 0.0, "avg_logprob": -0.437857707341512, "compression_ratio": 1.5515695067264574, "no_speech_prob": 1.9779394278884865e-05}, {"id": 270, "seek": 137820, "start": 1378.2, "end": 1385.04, "text": " for an image file, you could still use this, to use it.", "tokens": [337, 364, 3256, 3991, 11, 291, 727, 920, 764, 341, 11, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.29940472292096426, "compression_ratio": 1.5774647887323943, "no_speech_prob": 6.472457607742399e-05}, {"id": 271, "seek": 137820, "start": 1385.04, "end": 1390.24, "text": " Before taking the next question, I'm obliged to point out from the chat that these performance", "tokens": [4546, 1940, 264, 958, 1168, 11, 286, 478, 47194, 281, 935, 484, 490, 264, 5081, 300, 613, 3389], "temperature": 0.0, "avg_logprob": -0.29940472292096426, "compression_ratio": 1.5774647887323943, "no_speech_prob": 6.472457607742399e-05}, {"id": 272, "seek": 137820, "start": 1390.24, "end": 1393.72, "text": " numbers are before optimizing overlay FS and E-Rofs.", "tokens": [3547, 366, 949, 40425, 31741, 41138, 293, 462, 12, 49, 2670, 82, 13], "temperature": 0.0, "avg_logprob": -0.29940472292096426, "compression_ratio": 1.5774647887323943, "no_speech_prob": 6.472457607742399e-05}, {"id": 273, "seek": 137820, "start": 1393.72, "end": 1400.24, "text": " Yeah, yeah, so yeah, there's been some work in that and optimizing like there, there's", "tokens": [865, 11, 1338, 11, 370, 1338, 11, 456, 311, 668, 512, 589, 294, 300, 293, 40425, 411, 456, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.29940472292096426, "compression_ratio": 1.5774647887323943, "no_speech_prob": 6.472457607742399e-05}, {"id": 274, "seek": 137820, "start": 1400.24, "end": 1406.56, "text": " ideas to make the overlays stuff work better.", "tokens": [3487, 281, 652, 264, 15986, 3772, 1507, 589, 1101, 13], "temperature": 0.0, "avg_logprob": -0.29940472292096426, "compression_ratio": 1.5774647887323943, "no_speech_prob": 6.472457607742399e-05}, {"id": 275, "seek": 140656, "start": 1406.56, "end": 1408.56, "text": " Would that be possible, Joe?", "tokens": [6068, 300, 312, 1944, 11, 6807, 30], "temperature": 0.0, "avg_logprob": -0.2756359324735754, "compression_ratio": 1.4773869346733668, "no_speech_prob": 6.724594277329743e-05}, {"id": 276, "seek": 140656, "start": 1408.56, "end": 1409.56, "text": " Maybe.", "tokens": [2704, 13], "temperature": 0.0, "avg_logprob": -0.2756359324735754, "compression_ratio": 1.4773869346733668, "no_speech_prob": 6.724594277329743e-05}, {"id": 277, "seek": 140656, "start": 1409.56, "end": 1419.28, "text": " Oh, I actually still had a question.", "tokens": [876, 11, 286, 767, 920, 632, 257, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2756359324735754, "compression_ratio": 1.4773869346733668, "no_speech_prob": 6.724594277329743e-05}, {"id": 278, "seek": 140656, "start": 1419.28, "end": 1420.72, "text": " So here in the back.", "tokens": [407, 510, 294, 264, 646, 13], "temperature": 0.0, "avg_logprob": -0.2756359324735754, "compression_ratio": 1.4773869346733668, "no_speech_prob": 6.724594277329743e-05}, {"id": 279, "seek": 140656, "start": 1420.72, "end": 1424.52, "text": " So what's not really a question, more a remark.", "tokens": [407, 437, 311, 406, 534, 257, 1168, 11, 544, 257, 7942, 13], "temperature": 0.0, "avg_logprob": -0.2756359324735754, "compression_ratio": 1.4773869346733668, "no_speech_prob": 6.724594277329743e-05}, {"id": 280, "seek": 140656, "start": 1424.52, "end": 1428.52, "text": " I think there's sort of like one missing slide in your deck, namely one use case that you", "tokens": [286, 519, 456, 311, 1333, 295, 411, 472, 5361, 4137, 294, 428, 9341, 11, 20926, 472, 764, 1389, 300, 291], "temperature": 0.0, "avg_logprob": -0.2756359324735754, "compression_ratio": 1.4773869346733668, "no_speech_prob": 6.724594277329743e-05}, {"id": 281, "seek": 140656, "start": 1428.52, "end": 1433.08, "text": " haven't considered at all, but still really worth calling out.", "tokens": [2378, 380, 4888, 412, 439, 11, 457, 920, 534, 3163, 5141, 484, 13], "temperature": 0.0, "avg_logprob": -0.2756359324735754, "compression_ratio": 1.4773869346733668, "no_speech_prob": 6.724594277329743e-05}, {"id": 282, "seek": 143308, "start": 1433.08, "end": 1440.48, "text": " Many remote build systems, such as like GOMA, Bazel, et cetera, are all nowadays converging", "tokens": [5126, 8607, 1322, 3652, 11, 1270, 382, 411, 460, 5251, 32, 11, 42220, 338, 11, 1030, 11458, 11, 366, 439, 13434, 9652, 3249], "temperature": 0.0, "avg_logprob": -0.2112052009219215, "compression_ratio": 1.6553030303030303, "no_speech_prob": 0.00018373664352111518}, {"id": 283, "seek": 143308, "start": 1440.48, "end": 1446.1999999999998, "text": " on the single remote execution protocol called REV2, and that one is actually also using", "tokens": [322, 264, 2167, 8607, 15058, 10336, 1219, 10869, 53, 17, 11, 293, 300, 472, 307, 767, 611, 1228], "temperature": 0.0, "avg_logprob": -0.2112052009219215, "compression_ratio": 1.6553030303030303, "no_speech_prob": 0.00018373664352111518}, {"id": 284, "seek": 143308, "start": 1446.1999999999998, "end": 1451.28, "text": " a CAS as a data store for storing both input files for like compiler, binary, source files,", "tokens": [257, 43268, 382, 257, 1412, 3531, 337, 26085, 1293, 4846, 7098, 337, 411, 31958, 11, 17434, 11, 4009, 7098, 11], "temperature": 0.0, "avg_logprob": -0.2112052009219215, "compression_ratio": 1.6553030303030303, "no_speech_prob": 0.00018373664352111518}, {"id": 285, "seek": 143308, "start": 1451.28, "end": 1455.72, "text": " header files, but also output files, object files that are generated.", "tokens": [23117, 7098, 11, 457, 611, 5598, 7098, 11, 2657, 7098, 300, 366, 10833, 13], "temperature": 0.0, "avg_logprob": -0.2112052009219215, "compression_ratio": 1.6553030303030303, "no_speech_prob": 0.00018373664352111518}, {"id": 286, "seek": 143308, "start": 1455.72, "end": 1460.8799999999999, "text": " I actually maintain one of the implementations, and like one of the hard parts of implementing", "tokens": [286, 767, 6909, 472, 295, 264, 4445, 763, 11, 293, 411, 472, 295, 264, 1152, 3166, 295, 18114], "temperature": 0.0, "avg_logprob": -0.2112052009219215, "compression_ratio": 1.6553030303030303, "no_speech_prob": 0.00018373664352111518}, {"id": 287, "seek": 146088, "start": 1460.88, "end": 1466.8000000000002, "text": " such a build cluster is instantiating the data that's stored in the CAS in the form", "tokens": [1270, 257, 1322, 13630, 307, 9836, 72, 990, 264, 1412, 300, 311, 12187, 294, 264, 43268, 294, 264, 1254], "temperature": 0.0, "avg_logprob": -0.21751161193847657, "compression_ratio": 1.6972789115646258, "no_speech_prob": 2.7014581064577214e-05}, {"id": 288, "seek": 146088, "start": 1466.8000000000002, "end": 1470.8000000000002, "text": " of like an input route on disk, where you can just like run a compiler against certain", "tokens": [295, 411, 364, 4846, 7955, 322, 12355, 11, 689, 291, 393, 445, 411, 1190, 257, 31958, 1970, 1629], "temperature": 0.0, "avg_logprob": -0.21751161193847657, "compression_ratio": 1.6972789115646258, "no_speech_prob": 2.7014581064577214e-05}, {"id": 289, "seek": 146088, "start": 1470.8000000000002, "end": 1475.3200000000002, "text": " source files, and a tool like Composives would also really help in such an implementation.", "tokens": [4009, 7098, 11, 293, 257, 2290, 411, 6620, 329, 1539, 576, 611, 534, 854, 294, 1270, 364, 11420, 13], "temperature": 0.0, "avg_logprob": -0.21751161193847657, "compression_ratio": 1.6972789115646258, "no_speech_prob": 2.7014581064577214e-05}, {"id": 290, "seek": 146088, "start": 1475.3200000000002, "end": 1478.4, "text": " That's just something I wanted to call out, and you should really like also market it", "tokens": [663, 311, 445, 746, 286, 1415, 281, 818, 484, 11, 293, 291, 820, 534, 411, 611, 2142, 309], "temperature": 0.0, "avg_logprob": -0.21751161193847657, "compression_ratio": 1.6972789115646258, "no_speech_prob": 2.7014581064577214e-05}, {"id": 291, "seek": 146088, "start": 1478.4, "end": 1481.5200000000002, "text": " towards those kinds of use cases, and it makes a lot of sense.", "tokens": [3030, 729, 3685, 295, 764, 3331, 11, 293, 309, 1669, 257, 688, 295, 2020, 13], "temperature": 0.0, "avg_logprob": -0.21751161193847657, "compression_ratio": 1.6972789115646258, "no_speech_prob": 2.7014581064577214e-05}, {"id": 292, "seek": 146088, "start": 1481.5200000000002, "end": 1487.3200000000002, "text": " Yeah, I'm sure images are used for all sorts of stuff, I'm sure there are many use cases", "tokens": [865, 11, 286, 478, 988, 5267, 366, 1143, 337, 439, 7527, 295, 1507, 11, 286, 478, 988, 456, 366, 867, 764, 3331], "temperature": 0.0, "avg_logprob": -0.21751161193847657, "compression_ratio": 1.6972789115646258, "no_speech_prob": 2.7014581064577214e-05}, {"id": 293, "seek": 148732, "start": 1487.32, "end": 1491.08, "text": " other than the ones I've mainly focused on.", "tokens": [661, 813, 264, 2306, 286, 600, 8704, 5178, 322, 13], "temperature": 0.0, "avg_logprob": -0.21597867262990852, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.000692470115609467}, {"id": 294, "seek": 148732, "start": 1491.08, "end": 1499.6399999999999, "text": " Okay, then since you already ended the Q&A a bit early, then the next talk is going to", "tokens": [1033, 11, 550, 1670, 291, 1217, 4590, 264, 1249, 5, 32, 257, 857, 2440, 11, 550, 264, 958, 751, 307, 516, 281], "temperature": 0.0, "avg_logprob": -0.21597867262990852, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.000692470115609467}, {"id": 295, "seek": 148732, "start": 1499.6399999999999, "end": 1500.6399999999999, "text": " be recorded.", "tokens": [312, 8287, 13], "temperature": 0.0, "avg_logprob": -0.21597867262990852, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.000692470115609467}, {"id": 296, "seek": 148732, "start": 1500.6399999999999, "end": 1502.6399999999999, "text": " It gives us a bit more time to prepare.", "tokens": [467, 2709, 505, 257, 857, 544, 565, 281, 5940, 13], "temperature": 0.0, "avg_logprob": -0.21597867262990852, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.000692470115609467}, {"id": 297, "seek": 148732, "start": 1502.6399999999999, "end": 1503.9199999999998, "text": " Thank you very much for the talk.", "tokens": [1044, 291, 588, 709, 337, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.21597867262990852, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.000692470115609467}, {"id": 298, "seek": 150392, "start": 1503.92, "end": 1519.44, "text": " Thank you for all the questions, and being here.", "tokens": [50364, 1044, 291, 337, 439, 264, 1651, 11, 293, 885, 510, 13, 51140], "temperature": 0.0, "avg_logprob": -0.3724678243909563, "compression_ratio": 0.8571428571428571, "no_speech_prob": 0.0007949573337100446}], "language": "en"}