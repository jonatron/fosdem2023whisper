{"text": " Hecate is a Haskell from the trenches with an interest in resilient systems and documentation. When not at work or in the Haskell community, they are a trombonist in various orchestras and brass bands. Hecate uses they and them pronouns and farcical amounts of caffeine to retain human form. And they're going to present to us a presentation entitled Web Application Architecture in Haskell with flora.pm. Thank you Hecate. Thank you very much. Can everyone hear me? Perfect. So welcome to this talk entitled Web Application Architecture in Haskell when the domain drives the types and types drives the program. So this talk is intended for a missed audience of software engineers who are acquainted with the practice of domain driven design and Haskell programmers who are interested in crafting better systems. The goal is to create a bridge between the practitioners of domain driven design and the users of Haskell. So my name is Th\u00e9ophile Choutry aka Hecate to the community. I am a backend engineer at Scrive. We are a Swedish company and we have a e-signature platform for contracts and various documents as well as a digital identity hub where we aggregate various national identity providers like It's Me in Belgium for example or Bank ID, France Connect for the French people here. I am also privileged to be a board member of the Haskell Foundation and this is one of my numerous implications in the community. So Haskell, the pure functional programming language, so these are words and words mean nothing until we can practically apply them and these words bring us concrete features like native supports for recursion for example without blowing your stack type system that doesn't hate you, higher order functions that almost every language has today and many other features. There are two features especially that I want to talk about and it is going to be its ability of the language to adequately represent business domains and the ability to track side effects in a semantic way. For example, the adequate representation of business domain we can use algebraic data types to allow us to model with more precision the real world and its nuances. Encoding rules by construction at the type level is something that we can easily do and in this example for example the members of the excess data type visitor and admin are promoted to the type level for this user type which means that for example there can only be two values in the privileges parameter of this user type and also it means that I am going to get rejected if I pass a visitor user to this function called view back office but I'm going to get rejected at the compilation. This is something that is trivial to implement at the value level I could have a check on a member of you know the object of a property of the object that would be is admin with a Boolean but I have to write the check manually and possibly for every function that needs to have such a check. If I encode this immutable property at the type system, at the level of the types the compiler then is tasked with checking if I'm doing my job correctly. Checking side effects semantically. If we check the previous example we can see that view back office has a result type of IO HTML which more or less means you know I am doing observable side effects and I return you a value 8 in HTML but that's you know it doesn't adequately represent the reality of the function and for example here we have a way of tracking side effects that are being executed you know in a more human readable form and we can declare them at the type level. So here we have we have a function that so the signature is we get an int which is an identifier and we return a function that returns you know text and this f monad this f return type has also a list of effects so what are these effects basically I declare that I'm going to perform database access and possibly you know mutation I am going to access a ready server for the caching and I'm also going to ship my logs to an external platform or at least to perform the loading effect whatever that means. So and then we can have you know more useful breakdown of which functions have which effect so get entity name is composed of first we get the entity from the cache if we have it and then if we don't we can switch to the database to perform a perhaps more costly access and then finally we log the effects so logging db redis all of them are then unified in this list of effects at the type level. So one type system is both strong and expressive we get a lot closer to feel as refactoring and what does that mean because many languages today claim to provide such a thing. So feel as refactoring you more or less get vibe check by the compiler which is pretty cool because then the compiler keeps you in check regarding the changes in your program and how they affect the program's behavior you have also to come to terms with the fact that your worst enemy is now yourself you can't blame you know errors in production because undefined is not a function. So there are limits of course to correct by construction and I think it's especially important to be intellectually honest with that Haskell is not a prover you can prove you know lemmas or you know and theorems with it so you have to write tests and tests coming come in many shapes and forms you write tests for your integrations your properties and end to end tests tests are not optional unlike maybe. So functional application architecture so this that I showed you gives us a tool to focus now on the topic of functional application architecture and this time we arrive at in the land of domain design and there is there will be a brief overview of the terminology and the techniques that were created in the discipline and how they apply to us. So we have without surprise the concept of a bounded context it's a context there are workflow in there so what is it really it's an autonomous subsystem so it's responsible for one or multiple workflows and it has well-defined boundaries which is extremely important so we have to formalize or at least be very explicit how we talk to it its inputs and its outputs. If we take the example of flora.pm which is a community website an alternative package index for the Haskell community the schema is fairly simple we have the web component that goes to the core component which is tasked then to interface with database and we have a jobs worker for the jobs queue that also talks to the core components and to the database but we know that it's not going to talk with the web components so this is the kind of you know setting boundaries because they are in a healthy relationship and you know we know they will not talk to each other. One more step forward philas refactoring. Now something that the Java and C sharp world gave us are the concepts of data transfer objects data access object and business object. Sometimes they're the same thing sometimes you are lucky that the JSON payload you receive is the same object upon which you will perform your business computations and which you will store in your database but sometimes they are not and really it is pure luck that sometimes these types align. An example of how this bit me when I was young and hopeful obvious without much practice during meeting with other people we would try to define a json based format for data exchange between several systems and we had elixir systems php ruby python and these all you know give you several slight differences in how you can you know have data types encoded in these languages and for example if you are dealing with rubies or php users they will try and push heterogeneous lists in the data format so you can have a nint a string and natively in Haskell we don't do that so we would have to create some abstraction on top of it and I was realizing that I was constraining myself with the capacity of each language to create this data format based on json but you don't have to do it you can have your fully external way to talk to your mates your other systems and have a different representation inside your core components for example if we apply this to flora we can see that actually I have my business objects living inside my bounded context when I need to store them I serialize them I serialize them to a data access object that will be compliant with what my database expects so it means no fancy mutually recursive types for example or something like that and when I need to send that on the wire I will serialize that to a format that is easily representable by xml, json and other you know various cursed binary representations that we may find especially in the banking system so in the end if I was to summarize bounded context you know I showed you a very simple diagram earlier of flora but now how does it interface with each other so we have details between each component and especially between the clients and us daos for storage access and inside each component we operate on our business objects it so happens that the business object can be extremely similar between the web and the core components but sometimes they are not and I think it's very liberating to know that you don't have to keep to a single representation from a to z all the way you really can have conversion layers between your components between your interfaces and it's perfectly all right for example the retrieval but reading configuration the 12 factor application model tells us to read configuration from the environment from the shell so what we have on the left is the conflict type which models what I get from the environment with a twist because you know I can force some types it's not all text base I can force my parsing of HTTP ports to be a word 16 for example because I'm not so interested in you know having port number of one million and unless not without overflow so I've got my xml configuration that describes for example the first member is db config with a pool configuration so it's all the information I need for the pool the database pool and then internal configuration it's the pool itself and it's it's very useful because then I have this very explicit conversion and it's perfectly all right then to change something inside or outside my core components because then I only have you know this bottleneck that I can easily change and one more step towards fearless refactoring separating commands and queries so this has practical effects in terms of operation infrastructure and also in terms of ergonomics for the people who read our code you know in a practical way if we know that we have a recurrent fairly heavy processing query that runs and can take significant lock or CPUs on our server we have the option to have these queries run on a read-only replica for our database and put this replica on another machine so postgresql for example very specific example but I can talk about that you can have read-only replicas which take read-only queries and will be very angry at you if you ever try to mutate the state of this replica so you have your primary server which upon which you perform mutating commands and then it will stream these changes to the read-only replica and then the replica will provide you with a read-only interface that is like not only enforced at the type and at the level of the types for example in your applications but fundamentally on the protocol itself you will get a runtime error if you try to mutate this state so you can't like unsafe performance unsafe course you weigh you know behind that so something I learned at my current place of employment scrive is to have a separation like a physical separation in the code between types the commands and the queries so the dialect the idiom that we have here is that we have these dot query and dot update modules in which we put the read-only and mutating queries and then when we import them we qualify them for example import qualified as query and then there is a visual indicator so you know it's very bare bones but it does work that this is a query that is going to be read-only it's not going to increment a counter in a site table because you have performed something that is seemingly read-only a a good example for example it's LinkedIn when you view someone's page on LinkedIn they have a notification so you would think that viewing something it's a fundamentally read-only even the terms reading viewing you know you would think it's read-only but perhaps there is a counter that is increased with you know user tracking so that you can later report who has viewed your page but if you can you know bring one step more into separating the queries and the commands then it's much more it's much easier to know what which kind of operation you're performing at which place in the code so we could go further even and declare queries and commands as effects and with their own connection pools so for example I don't only have the db effect in my stack I'm declaring that I'm performing a read-only operation on the read-only replica of my PostgreSQL database so one more step towards you know more so of course it can be a technical detail but also I think it's very important to be able to say to the readers of your code what are you performing which side effect does it have especially in the system that you have ownership of now that's my anarchist tendencies coming up let's keep our distance from the state the state is best contained so the cache of our application is actually a bounded context in its own it has its own lifecycle data storage and api and by decoupling our application monolith from its state we have worked a significant portion of the path to having a setup where we can have multiple instances of our application and serving data from the same database in cache so at this point by ensuring that the database server keeps operations in sync we've got you know higher consistency of the application so that's the the cap theorem for the systems you've got cap is your application consistent is it available or is it tolerant to partition and in you know some industries where you work in very sensitive with very sensitive data if you have a production incident you can't risk having inconsistent data or having an inconsistent state where people can read someone else's private folder so it's better to shut things down for a bit we you know we keep our count we take a deep long breath and then we restart the system but it's because availability has to take you know one for the team in order to keep consistent and you know partition tolerance sorry to partition can go out the window so for flora for example very simple we can have our clients that talk to our nginx gateway and then the multiple instances of flora that still speak to the same database server for mutating operations and the same replica for read only commands you know i'm not selling you microservice architectures and you know scale to the moon type of stuff but i think it's a very decent way to start a monolith we all know that you know a good distributed system has to start as a monolith and then you know split it further and further if you start with a microservice based you know architecture you might end up with a distributed monolith but the the whole thing of a microservice based application is to have you know independent context that can still run so here we don't take you know the bet that every component is fully independent we acknowledge boundaries that we have some boundaries between the web the core and the job workers components and then themselves they have their own context so it's also about realism like do you want to scale to the moon and raise like hundreds of thousand of dollars from venture capitalists or do you want to create a nice community website that indexes packages for the haskell environment i'm going to make a short detour here and it's directing our workflows with types so it's a technique that brings together type safety and ergonomics which is one of my favorite subjects to create type directed state machines very fancy word basically it's it's really the way that your operation are composed together and you will be driven to compose these operations via their types it can be a bit scary sometimes to think of your business operations as a state machine but it gives us a terminology and a literature to take from and to think of how we organize and compose our operations so for example here we have a workflow state which can have three values arrival processed and departure and a workflow that has this state type parameter so we have a new workflow value that creates a workflow w1 and then the process workflow function takes a workflow but not any kind of workflow it has to to be set to arrival it can only take newly arrived workflows and then sets them as processed again this could be in quotes trivially implemented at the value level with you know properties of the workflow objects and we could very easily verify check these property at in the value level in the code but here I factorize all these checks and I put them really at a place where the compiler can guide my hand and tell me where I went wrong with that and finally the send back workflow can only take processed workflows by the laws of the types and then sets the workflow as departed so if I compose the functions in the good order so new workflow and then you know a pipeline of functions and then I pipe it into process workflow and send back workflow everything is good if I try to skip a step I will get a compiler error that says you wanted me to take a processed workflow but actually you know I need sorry you wanted me to take an arrival workflow but actually I need the processed workflow and this code you know you're not sending that code to production because you cannot compile this code in terms of web application development there are also some for us hastalers we like to put everything at the level of types you know and think of our code as being you know formally proven or code by construction but sometimes you know we must not drink all the cool aid or all the climatic for example database layers that promise type safe SQL if you ever find a database layer that promise type safety either it's the kind of type safety that is trivial to implement and it's totally expected of the tool to have it or it has encoded the semantics of SQL at the type level and we've either found the golden goose you know or someone who has clearly underestimated the difficulties of SQL semantics. Also SQLite for development and PostgreSQL for production that's something that the python community has popularized in the 20s 2000s and 2010s so we can accomplish great things by lying to the universe but we carefully accomplish anything by lying to ourselves and SQLite is its own system and unless you somehow perfectly code in the common subset of SQL supported by both implementations you will be maintaining two sets of database migrations and sometimes of code so PostgreSQL has very good features SQLite has difference but also good features not its type system of course but if you get used to one locally and then discover the second one once you're deployed you're going to have a bad time and also the muscle memory because brain is a muscle that you will have accumulated with SQLite will be fairly useless with PostgreSQL. So where to go from here documentation you produce documentation we have many ways of producing documentation and we hold also tremendous power in the types and coupled with introspection it means that the algebraic data types like the sem types and the product types the product types so the enums and the records they can serve as the backbone for further even documentation the types themselves are not documentation but they can be used to guide the reader and you remember how I told you to write the tests so the best tests are those that can describe real-world behaviors and if you can even produce you know a summary web page that shows the behaviors and the high-level paths taken by your program according to some input this is very particularly helpful for less technical people like product managers who want to know the behavior of your program if you can present a nice interface of how the code is executed according to some high-level business you know operation it's even better. So I have a couple of sources for what I'm saying I'm not pulling that out of my arse the first one is domain modeling made functional by Scott Vlaschen it's an excellent book written in F-sharp for the functional and DDD practitioners it's excellent I encourage you to read it as well as living documentation by Cyril Maertere and that one is also excellent really it puts the documentation as its own living system that for which you will have real clients because you know PMs and other engineers in your organization or consumers of documentation and of course here's amounts of caffeine as Fraser told earlier so that would be the end of my talk. Do we have a couple of minutes for questions perhaps? Yes thank you Akate and we do have about 10 minutes for questions. Yes Youngman there. This is this is on this is more of a comment than a question. So one little detail that I think that sort of you could have sold also right is the fact that when you do this when you do the data kind annotation on your workflow you know instead of you know checking that during runtime we do the type annotation and that's actually more efficient right because because of type erasure that there's no runtime data or check that has to happen right. Yes so what Bj\u00f6rn says is that indeed there is a matter of efficiency because the data kinds when we encode you know the nature of parameters in our workflow these all goes away at code generation so you if you are in a setup where you need some you know very minimal code that is being generated if you are in tight loop for example this code is completely raised at the level at the time of code generation and indeed you you spread some CPU cycles. Any other question? You can also call me out on my bullshit. I won't be offended. Yes Do I need a mic or am I? I can repeat your question. The libraries that offer type safe database access that are I'm sure hideously incomplete also offer abstraction over different database backends which is one of the problems you were talking about like why you're using Postgres to develop locally. So my question is are there really situations for Flora PM where those libraries didn't provide a feature that you needed? Yes so the question is those libraries that encode you know all of the semantics of SQL at the type level are there situations where they don't provide features that I would need for Flora PM? Yes so as I told earlier I'm very preoccupied by ergonomics. 20 minutes of compilation time and you know 20 gigabytes of half interface files on disk I would consider that a problem in terms of feedback loop for contributors. My previous place of employment we used the toolkit squeal for type level encoded SQL queries because they were business critical so we wanted to invest in something very much type safe because of the critical aspects of these queries. It was hell, it was horrendous, it was not only to view and to review but also because it took so much time to compile like unironically 20 minutes and we had some problems with stack because the interface files on this were taking way too much space. Type families in Haskell are best consumed with you know responsibly and I'm a servants user so you know I can't you know shit too much on type families but in some cases very specific cases is best to rely on the expertise of outside systems. For example my best friend who's here actually in FOSDEM is my database administrator at work and you know I keep him close you know. Do you ever have experience to need on board like a newer developer that to maintain or even do new feature to the project if so what's the experience especially if they don't have any Haskell experience or especially this kind of yes very good question do we have any experience on boarding new developers on the project actually with this this talk was supposed to be the continuation of the different on boarding sessions rather than on floor at the pm so sometimes if you find me on discord or matrix I will share my screen and introduce people to the codebase and I think that's one of the most important aspects of flora as a project not only it is a community tool that has you know aims to satisfy the users but also it's a vessel for teaching so I have got many tech techniques that I explained in this talk implementing flora and flora is my the factor codebase to teach these techniques and I had very bad you know experience with community tools that have badly aged and the code is only known by you know the 10% of maintainers that stick around even if the majority the vast majority of contributors of a project or the 90% of people who just make one pull request and then go away forever so it's very hard to retain institutional knowledge and also is very hard not to aim to please the 10% of people who stick around and submit patches you know on the regular so yes I would think that and that's the goal of flora onboarding new contributors easily is actually a feature and if it can't be done anymore it's a bug any other question nope oh sure such a representation is it possible to write a function that say generate a diagram it technically is I have references for you so the question is can we generate diagrams from such representations because indeed we have the possible values that we have at a type level and we can do many things with our types including inspecting them so yes I believe there are several libraries on hackage that aim to for example provenance it's a library that gives you the the path that the data takes and the provenance of your data throughout the code I would say it's the it's one of the the greatest thing to be able to do is to represent your code and to extract facts and movements from your code in a higher you know level representation so yeah I believe we can do it today I don't do it personally I think it's possible there's time for more questions or you can like duel me if you want to challenge my beliefs okay that seems like it so thank you again Ikate thank you very much you", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.52, "text": " Hecate is a Haskell from the trenches with an interest in resilient systems and documentation.", "tokens": [50364, 634, 66, 473, 307, 257, 8646, 43723, 490, 264, 48245, 365, 364, 1179, 294, 23699, 3652, 293, 14333, 13, 50940], "temperature": 0.0, "avg_logprob": -0.1743924617767334, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.10380510240793228}, {"id": 1, "seek": 0, "start": 11.52, "end": 16.34, "text": " When not at work or in the Haskell community, they are a trombonist in various orchestras", "tokens": [50940, 1133, 406, 412, 589, 420, 294, 264, 8646, 43723, 1768, 11, 436, 366, 257, 504, 3548, 266, 468, 294, 3683, 14161, 3906, 51181], "temperature": 0.0, "avg_logprob": -0.1743924617767334, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.10380510240793228}, {"id": 2, "seek": 0, "start": 16.34, "end": 23.2, "text": " and brass bands. Hecate uses they and them pronouns and farcical amounts of caffeine to", "tokens": [51181, 293, 26257, 13543, 13, 634, 66, 473, 4960, 436, 293, 552, 35883, 293, 1400, 66, 804, 11663, 295, 31261, 281, 51524], "temperature": 0.0, "avg_logprob": -0.1743924617767334, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.10380510240793228}, {"id": 3, "seek": 0, "start": 23.2, "end": 29.52, "text": " retain human form. And they're going to present to us a presentation entitled Web Application", "tokens": [51524, 18340, 1952, 1254, 13, 400, 436, 434, 516, 281, 1974, 281, 505, 257, 5860, 17838, 9573, 39512, 51840], "temperature": 0.0, "avg_logprob": -0.1743924617767334, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.10380510240793228}, {"id": 4, "seek": 2952, "start": 29.52, "end": 34.76, "text": " Architecture in Haskell with flora.pm. Thank you Hecate.", "tokens": [50364, 43049, 294, 8646, 43723, 365, 932, 3252, 13, 14395, 13, 1044, 291, 634, 66, 473, 13, 50626], "temperature": 0.0, "avg_logprob": -0.21707253927712913, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.02782505564391613}, {"id": 5, "seek": 2952, "start": 34.76, "end": 40.96, "text": " Thank you very much. Can everyone hear me? Perfect. So welcome to this talk entitled", "tokens": [50626, 1044, 291, 588, 709, 13, 1664, 1518, 1568, 385, 30, 10246, 13, 407, 2928, 281, 341, 751, 17838, 50936], "temperature": 0.0, "avg_logprob": -0.21707253927712913, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.02782505564391613}, {"id": 6, "seek": 2952, "start": 40.96, "end": 47.16, "text": " Web Application Architecture in Haskell when the domain drives the types and types drives", "tokens": [50936, 9573, 39512, 43049, 294, 8646, 43723, 562, 264, 9274, 11754, 264, 3467, 293, 3467, 11754, 51246], "temperature": 0.0, "avg_logprob": -0.21707253927712913, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.02782505564391613}, {"id": 7, "seek": 2952, "start": 47.16, "end": 52.760000000000005, "text": " the program. So this talk is intended for a missed audience of software engineers who", "tokens": [51246, 264, 1461, 13, 407, 341, 751, 307, 10226, 337, 257, 6721, 4034, 295, 4722, 11955, 567, 51526], "temperature": 0.0, "avg_logprob": -0.21707253927712913, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.02782505564391613}, {"id": 8, "seek": 2952, "start": 52.760000000000005, "end": 58.760000000000005, "text": " are acquainted with the practice of domain driven design and Haskell programmers who", "tokens": [51526, 366, 50224, 365, 264, 3124, 295, 9274, 9555, 1715, 293, 8646, 43723, 41504, 567, 51826], "temperature": 0.0, "avg_logprob": -0.21707253927712913, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.02782505564391613}, {"id": 9, "seek": 5876, "start": 58.76, "end": 64.6, "text": " are interested in crafting better systems. The goal is to create a bridge between the", "tokens": [50364, 366, 3102, 294, 29048, 1101, 3652, 13, 440, 3387, 307, 281, 1884, 257, 7283, 1296, 264, 50656], "temperature": 0.0, "avg_logprob": -0.20429983593168713, "compression_ratio": 1.4794520547945205, "no_speech_prob": 0.010485314764082432}, {"id": 10, "seek": 5876, "start": 64.6, "end": 70.67999999999999, "text": " practitioners of domain driven design and the users of Haskell.", "tokens": [50656, 25742, 295, 9274, 9555, 1715, 293, 264, 5022, 295, 8646, 43723, 13, 50960], "temperature": 0.0, "avg_logprob": -0.20429983593168713, "compression_ratio": 1.4794520547945205, "no_speech_prob": 0.010485314764082432}, {"id": 11, "seek": 5876, "start": 70.67999999999999, "end": 77.88, "text": " So my name is Th\u00e9ophile Choutry aka Hecate to the community. I am a backend engineer", "tokens": [50960, 407, 452, 1315, 307, 334, 526, 49242, 761, 346, 627, 28042, 634, 66, 473, 281, 264, 1768, 13, 286, 669, 257, 38087, 11403, 51320], "temperature": 0.0, "avg_logprob": -0.20429983593168713, "compression_ratio": 1.4794520547945205, "no_speech_prob": 0.010485314764082432}, {"id": 12, "seek": 5876, "start": 77.88, "end": 85.84, "text": " at Scrive. We are a Swedish company and we have a e-signature platform for contracts and", "tokens": [51320, 412, 318, 1142, 303, 13, 492, 366, 257, 23523, 2237, 293, 321, 362, 257, 308, 12, 82, 788, 1503, 3663, 337, 13952, 293, 51718], "temperature": 0.0, "avg_logprob": -0.20429983593168713, "compression_ratio": 1.4794520547945205, "no_speech_prob": 0.010485314764082432}, {"id": 13, "seek": 8584, "start": 85.84, "end": 92.44, "text": " various documents as well as a digital identity hub where we aggregate various national identity", "tokens": [50364, 3683, 8512, 382, 731, 382, 257, 4562, 6575, 11838, 689, 321, 26118, 3683, 4048, 6575, 50694], "temperature": 0.0, "avg_logprob": -0.2187271383073595, "compression_ratio": 1.5, "no_speech_prob": 0.16211743652820587}, {"id": 14, "seek": 8584, "start": 92.44, "end": 97.92, "text": " providers like It's Me in Belgium for example or Bank ID, France Connect for the French", "tokens": [50694, 11330, 411, 467, 311, 1923, 294, 28094, 337, 1365, 420, 8915, 7348, 11, 6190, 11653, 337, 264, 5522, 50968], "temperature": 0.0, "avg_logprob": -0.2187271383073595, "compression_ratio": 1.5, "no_speech_prob": 0.16211743652820587}, {"id": 15, "seek": 8584, "start": 97.92, "end": 106.88, "text": " people here. I am also privileged to be a board member of the Haskell Foundation and", "tokens": [50968, 561, 510, 13, 286, 669, 611, 25293, 281, 312, 257, 3150, 4006, 295, 264, 8646, 43723, 10335, 293, 51416], "temperature": 0.0, "avg_logprob": -0.2187271383073595, "compression_ratio": 1.5, "no_speech_prob": 0.16211743652820587}, {"id": 16, "seek": 8584, "start": 106.88, "end": 113.12, "text": " this is one of my numerous implications in the community.", "tokens": [51416, 341, 307, 472, 295, 452, 12546, 16602, 294, 264, 1768, 13, 51728], "temperature": 0.0, "avg_logprob": -0.2187271383073595, "compression_ratio": 1.5, "no_speech_prob": 0.16211743652820587}, {"id": 17, "seek": 11312, "start": 113.12, "end": 119.04, "text": " So Haskell, the pure functional programming language, so these are words and words mean", "tokens": [50364, 407, 8646, 43723, 11, 264, 6075, 11745, 9410, 2856, 11, 370, 613, 366, 2283, 293, 2283, 914, 50660], "temperature": 0.0, "avg_logprob": -0.19302652193152386, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.15266923606395721}, {"id": 18, "seek": 11312, "start": 119.04, "end": 124.52000000000001, "text": " nothing until we can practically apply them and these words bring us concrete features", "tokens": [50660, 1825, 1826, 321, 393, 15667, 3079, 552, 293, 613, 2283, 1565, 505, 9859, 4122, 50934], "temperature": 0.0, "avg_logprob": -0.19302652193152386, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.15266923606395721}, {"id": 19, "seek": 11312, "start": 124.52000000000001, "end": 129.84, "text": " like native supports for recursion for example without blowing your stack type system that", "tokens": [50934, 411, 8470, 9346, 337, 20560, 313, 337, 1365, 1553, 15068, 428, 8630, 2010, 1185, 300, 51200], "temperature": 0.0, "avg_logprob": -0.19302652193152386, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.15266923606395721}, {"id": 20, "seek": 11312, "start": 129.84, "end": 135.4, "text": " doesn't hate you, higher order functions that almost every language has today and many", "tokens": [51200, 1177, 380, 4700, 291, 11, 2946, 1668, 6828, 300, 1920, 633, 2856, 575, 965, 293, 867, 51478], "temperature": 0.0, "avg_logprob": -0.19302652193152386, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.15266923606395721}, {"id": 21, "seek": 11312, "start": 135.4, "end": 141.4, "text": " other features. There are two features especially that I want to talk about and it is going", "tokens": [51478, 661, 4122, 13, 821, 366, 732, 4122, 2318, 300, 286, 528, 281, 751, 466, 293, 309, 307, 516, 51778], "temperature": 0.0, "avg_logprob": -0.19302652193152386, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.15266923606395721}, {"id": 22, "seek": 14140, "start": 141.4, "end": 147.32, "text": " to be its ability of the language to adequately represent business domains and the ability", "tokens": [50364, 281, 312, 1080, 3485, 295, 264, 2856, 281, 41822, 2906, 1606, 25514, 293, 264, 3485, 50660], "temperature": 0.0, "avg_logprob": -0.1078955078125, "compression_ratio": 1.6492890995260663, "no_speech_prob": 0.022568093612790108}, {"id": 23, "seek": 14140, "start": 147.32, "end": 155.04000000000002, "text": " to track side effects in a semantic way. For example, the adequate representation of", "tokens": [50660, 281, 2837, 1252, 5065, 294, 257, 47982, 636, 13, 1171, 1365, 11, 264, 20927, 10290, 295, 51046], "temperature": 0.0, "avg_logprob": -0.1078955078125, "compression_ratio": 1.6492890995260663, "no_speech_prob": 0.022568093612790108}, {"id": 24, "seek": 14140, "start": 155.04000000000002, "end": 161.96, "text": " business domain we can use algebraic data types to allow us to model with more precision", "tokens": [51046, 1606, 9274, 321, 393, 764, 21989, 299, 1412, 3467, 281, 2089, 505, 281, 2316, 365, 544, 18356, 51392], "temperature": 0.0, "avg_logprob": -0.1078955078125, "compression_ratio": 1.6492890995260663, "no_speech_prob": 0.022568093612790108}, {"id": 25, "seek": 14140, "start": 161.96, "end": 167.12, "text": " the real world and its nuances. Encoding rules by construction at the type level is", "tokens": [51392, 264, 957, 1002, 293, 1080, 38775, 13, 29584, 8616, 4474, 538, 6435, 412, 264, 2010, 1496, 307, 51650], "temperature": 0.0, "avg_logprob": -0.1078955078125, "compression_ratio": 1.6492890995260663, "no_speech_prob": 0.022568093612790108}, {"id": 26, "seek": 16712, "start": 167.12, "end": 173.92000000000002, "text": " something that we can easily do and in this example for example the members of the excess", "tokens": [50364, 746, 300, 321, 393, 3612, 360, 293, 294, 341, 1365, 337, 1365, 264, 2679, 295, 264, 9310, 50704], "temperature": 0.0, "avg_logprob": -0.17743146217475503, "compression_ratio": 1.7151898734177216, "no_speech_prob": 0.07140903174877167}, {"id": 27, "seek": 16712, "start": 173.92000000000002, "end": 180.68, "text": " data type visitor and admin are promoted to the type level for this user type which means", "tokens": [50704, 1412, 2010, 28222, 293, 24236, 366, 21162, 281, 264, 2010, 1496, 337, 341, 4195, 2010, 597, 1355, 51042], "temperature": 0.0, "avg_logprob": -0.17743146217475503, "compression_ratio": 1.7151898734177216, "no_speech_prob": 0.07140903174877167}, {"id": 28, "seek": 16712, "start": 180.68, "end": 190.20000000000002, "text": " that for example there can only be two values in the privileges parameter of this user type", "tokens": [51042, 300, 337, 1365, 456, 393, 787, 312, 732, 4190, 294, 264, 32588, 13075, 295, 341, 4195, 2010, 51518], "temperature": 0.0, "avg_logprob": -0.17743146217475503, "compression_ratio": 1.7151898734177216, "no_speech_prob": 0.07140903174877167}, {"id": 29, "seek": 19020, "start": 190.2, "end": 198.35999999999999, "text": " and also it means that I am going to get rejected if I pass a visitor user to this function", "tokens": [50364, 293, 611, 309, 1355, 300, 286, 669, 516, 281, 483, 15749, 498, 286, 1320, 257, 28222, 4195, 281, 341, 2445, 50772], "temperature": 0.0, "avg_logprob": -0.17875590435294217, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.13268835842609406}, {"id": 30, "seek": 19020, "start": 198.35999999999999, "end": 204.2, "text": " called view back office but I'm going to get rejected at the compilation. This is something", "tokens": [50772, 1219, 1910, 646, 3398, 457, 286, 478, 516, 281, 483, 15749, 412, 264, 40261, 13, 639, 307, 746, 51064], "temperature": 0.0, "avg_logprob": -0.17875590435294217, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.13268835842609406}, {"id": 31, "seek": 19020, "start": 204.2, "end": 210.0, "text": " that is trivial to implement at the value level I could have a check on a member of", "tokens": [51064, 300, 307, 26703, 281, 4445, 412, 264, 2158, 1496, 286, 727, 362, 257, 1520, 322, 257, 4006, 295, 51354], "temperature": 0.0, "avg_logprob": -0.17875590435294217, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.13268835842609406}, {"id": 32, "seek": 19020, "start": 210.0, "end": 215.12, "text": " you know the object of a property of the object that would be is admin with a Boolean but", "tokens": [51354, 291, 458, 264, 2657, 295, 257, 4707, 295, 264, 2657, 300, 576, 312, 307, 24236, 365, 257, 23351, 28499, 457, 51610], "temperature": 0.0, "avg_logprob": -0.17875590435294217, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.13268835842609406}, {"id": 33, "seek": 21512, "start": 215.12, "end": 220.48000000000002, "text": " I have to write the check manually and possibly for every function that needs to have such", "tokens": [50364, 286, 362, 281, 2464, 264, 1520, 16945, 293, 6264, 337, 633, 2445, 300, 2203, 281, 362, 1270, 50632], "temperature": 0.0, "avg_logprob": -0.17492159675149357, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.001470811665058136}, {"id": 34, "seek": 21512, "start": 220.48000000000002, "end": 228.12, "text": " a check. If I encode this immutable property at the type system, at the level of the types", "tokens": [50632, 257, 1520, 13, 759, 286, 2058, 1429, 341, 3397, 32148, 4707, 412, 264, 2010, 1185, 11, 412, 264, 1496, 295, 264, 3467, 51014], "temperature": 0.0, "avg_logprob": -0.17492159675149357, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.001470811665058136}, {"id": 35, "seek": 21512, "start": 228.12, "end": 236.20000000000002, "text": " the compiler then is tasked with checking if I'm doing my job correctly. Checking side", "tokens": [51014, 264, 31958, 550, 307, 38621, 365, 8568, 498, 286, 478, 884, 452, 1691, 8944, 13, 6881, 278, 1252, 51418], "temperature": 0.0, "avg_logprob": -0.17492159675149357, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.001470811665058136}, {"id": 36, "seek": 21512, "start": 236.20000000000002, "end": 241.92000000000002, "text": " effects semantically. If we check the previous example we can see that view back office has", "tokens": [51418, 5065, 4361, 49505, 13, 759, 321, 1520, 264, 3894, 1365, 321, 393, 536, 300, 1910, 646, 3398, 575, 51704], "temperature": 0.0, "avg_logprob": -0.17492159675149357, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.001470811665058136}, {"id": 37, "seek": 24192, "start": 241.92, "end": 247.67999999999998, "text": " a result type of IO HTML which more or less means you know I am doing observable side", "tokens": [50364, 257, 1874, 2010, 295, 39839, 17995, 597, 544, 420, 1570, 1355, 291, 458, 286, 669, 884, 9951, 712, 1252, 50652], "temperature": 0.0, "avg_logprob": -0.1504070816970453, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.004384102299809456}, {"id": 38, "seek": 24192, "start": 247.67999999999998, "end": 254.16, "text": " effects and I return you a value 8 in HTML but that's you know it doesn't adequately", "tokens": [50652, 5065, 293, 286, 2736, 291, 257, 2158, 1649, 294, 17995, 457, 300, 311, 291, 458, 309, 1177, 380, 41822, 50976], "temperature": 0.0, "avg_logprob": -0.1504070816970453, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.004384102299809456}, {"id": 39, "seek": 24192, "start": 254.16, "end": 261.68, "text": " represent the reality of the function and for example here we have a way of tracking", "tokens": [50976, 2906, 264, 4103, 295, 264, 2445, 293, 337, 1365, 510, 321, 362, 257, 636, 295, 11603, 51352], "temperature": 0.0, "avg_logprob": -0.1504070816970453, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.004384102299809456}, {"id": 40, "seek": 24192, "start": 261.68, "end": 268.4, "text": " side effects that are being executed you know in a more human readable form and we can declare", "tokens": [51352, 1252, 5065, 300, 366, 885, 17577, 291, 458, 294, 257, 544, 1952, 49857, 1254, 293, 321, 393, 19710, 51688], "temperature": 0.0, "avg_logprob": -0.1504070816970453, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.004384102299809456}, {"id": 41, "seek": 26840, "start": 268.4, "end": 276.03999999999996, "text": " them at the type level. So here we have we have a function that so the signature is we", "tokens": [50364, 552, 412, 264, 2010, 1496, 13, 407, 510, 321, 362, 321, 362, 257, 2445, 300, 370, 264, 13397, 307, 321, 50746], "temperature": 0.0, "avg_logprob": -0.21335484431340143, "compression_ratio": 1.6948051948051948, "no_speech_prob": 0.0021525458432734013}, {"id": 42, "seek": 26840, "start": 276.03999999999996, "end": 282.79999999999995, "text": " get an int which is an identifier and we return a function that returns you know text and", "tokens": [50746, 483, 364, 560, 597, 307, 364, 45690, 293, 321, 2736, 257, 2445, 300, 11247, 291, 458, 2487, 293, 51084], "temperature": 0.0, "avg_logprob": -0.21335484431340143, "compression_ratio": 1.6948051948051948, "no_speech_prob": 0.0021525458432734013}, {"id": 43, "seek": 26840, "start": 282.79999999999995, "end": 292.08, "text": " this f monad this f return type has also a list of effects so what are these effects", "tokens": [51084, 341, 283, 1108, 345, 341, 283, 2736, 2010, 575, 611, 257, 1329, 295, 5065, 370, 437, 366, 613, 5065, 51548], "temperature": 0.0, "avg_logprob": -0.21335484431340143, "compression_ratio": 1.6948051948051948, "no_speech_prob": 0.0021525458432734013}, {"id": 44, "seek": 29208, "start": 292.08, "end": 298.64, "text": " basically I declare that I'm going to perform database access and possibly you know mutation", "tokens": [50364, 1936, 286, 19710, 300, 286, 478, 516, 281, 2042, 8149, 2105, 293, 6264, 291, 458, 27960, 50692], "temperature": 0.0, "avg_logprob": -0.17097076177597045, "compression_ratio": 1.6966824644549763, "no_speech_prob": 0.012722271494567394}, {"id": 45, "seek": 29208, "start": 298.64, "end": 303.4, "text": " I am going to access a ready server for the caching and I'm also going to ship my logs", "tokens": [50692, 286, 669, 516, 281, 2105, 257, 1919, 7154, 337, 264, 269, 2834, 293, 286, 478, 611, 516, 281, 5374, 452, 20820, 50930], "temperature": 0.0, "avg_logprob": -0.17097076177597045, "compression_ratio": 1.6966824644549763, "no_speech_prob": 0.012722271494567394}, {"id": 46, "seek": 29208, "start": 303.4, "end": 311.59999999999997, "text": " to an external platform or at least to perform the loading effect whatever that means. So", "tokens": [50930, 281, 364, 8320, 3663, 420, 412, 1935, 281, 2042, 264, 15114, 1802, 2035, 300, 1355, 13, 407, 51340], "temperature": 0.0, "avg_logprob": -0.17097076177597045, "compression_ratio": 1.6966824644549763, "no_speech_prob": 0.012722271494567394}, {"id": 47, "seek": 29208, "start": 311.59999999999997, "end": 318.56, "text": " and then we can have you know more useful breakdown of which functions have which effect", "tokens": [51340, 293, 550, 321, 393, 362, 291, 458, 544, 4420, 18188, 295, 597, 6828, 362, 597, 1802, 51688], "temperature": 0.0, "avg_logprob": -0.17097076177597045, "compression_ratio": 1.6966824644549763, "no_speech_prob": 0.012722271494567394}, {"id": 48, "seek": 31856, "start": 318.64, "end": 323.92, "text": " so get entity name is composed of first we get the entity from the cache if we have it", "tokens": [50368, 370, 483, 13977, 1315, 307, 18204, 295, 700, 321, 483, 264, 13977, 490, 264, 19459, 498, 321, 362, 309, 50632], "temperature": 0.0, "avg_logprob": -0.156270273993997, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.020036635920405388}, {"id": 49, "seek": 31856, "start": 323.92, "end": 329.68, "text": " and then if we don't we can switch to the database to perform a perhaps more costly", "tokens": [50632, 293, 550, 498, 321, 500, 380, 321, 393, 3679, 281, 264, 8149, 281, 2042, 257, 4317, 544, 28328, 50920], "temperature": 0.0, "avg_logprob": -0.156270273993997, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.020036635920405388}, {"id": 50, "seek": 31856, "start": 329.68, "end": 338.72, "text": " access and then finally we log the effects so logging db redis all of them are then unified", "tokens": [50920, 2105, 293, 550, 2721, 321, 3565, 264, 5065, 370, 27991, 274, 65, 2182, 271, 439, 295, 552, 366, 550, 26787, 51372], "temperature": 0.0, "avg_logprob": -0.156270273993997, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.020036635920405388}, {"id": 51, "seek": 31856, "start": 338.72, "end": 348.24, "text": " in this list of effects at the type level. So one type system is both strong and expressive", "tokens": [51372, 294, 341, 1329, 295, 5065, 412, 264, 2010, 1496, 13, 407, 472, 2010, 1185, 307, 1293, 2068, 293, 40189, 51848], "temperature": 0.0, "avg_logprob": -0.156270273993997, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.020036635920405388}, {"id": 52, "seek": 34856, "start": 348.72, "end": 354.72, "text": " we get a lot closer to feel as refactoring and what does that mean because many languages today", "tokens": [50372, 321, 483, 257, 688, 4966, 281, 841, 382, 1895, 578, 3662, 293, 437, 775, 300, 914, 570, 867, 8650, 965, 50672], "temperature": 0.0, "avg_logprob": -0.12885273334591887, "compression_ratio": 1.728110599078341, "no_speech_prob": 0.004104895517230034}, {"id": 53, "seek": 34856, "start": 355.6, "end": 362.88, "text": " claim to provide such a thing. So feel as refactoring you more or less get vibe check by", "tokens": [50716, 3932, 281, 2893, 1270, 257, 551, 13, 407, 841, 382, 1895, 578, 3662, 291, 544, 420, 1570, 483, 14606, 1520, 538, 51080], "temperature": 0.0, "avg_logprob": -0.12885273334591887, "compression_ratio": 1.728110599078341, "no_speech_prob": 0.004104895517230034}, {"id": 54, "seek": 34856, "start": 362.88, "end": 368.32, "text": " the compiler which is pretty cool because then the compiler keeps you in check regarding the", "tokens": [51080, 264, 31958, 597, 307, 1238, 1627, 570, 550, 264, 31958, 5965, 291, 294, 1520, 8595, 264, 51352], "temperature": 0.0, "avg_logprob": -0.12885273334591887, "compression_ratio": 1.728110599078341, "no_speech_prob": 0.004104895517230034}, {"id": 55, "seek": 34856, "start": 368.32, "end": 373.52, "text": " changes in your program and how they affect the program's behavior you have also to come to terms", "tokens": [51352, 2962, 294, 428, 1461, 293, 577, 436, 3345, 264, 1461, 311, 5223, 291, 362, 611, 281, 808, 281, 2115, 51612], "temperature": 0.0, "avg_logprob": -0.12885273334591887, "compression_ratio": 1.728110599078341, "no_speech_prob": 0.004104895517230034}, {"id": 56, "seek": 37352, "start": 373.52, "end": 379.76, "text": " with the fact that your worst enemy is now yourself you can't blame you know errors in production", "tokens": [50364, 365, 264, 1186, 300, 428, 5855, 5945, 307, 586, 1803, 291, 393, 380, 10127, 291, 458, 13603, 294, 4265, 50676], "temperature": 0.0, "avg_logprob": -0.12294019811293658, "compression_ratio": 1.6948356807511737, "no_speech_prob": 0.00569281168282032}, {"id": 57, "seek": 37352, "start": 379.76, "end": 388.08, "text": " because undefined is not a function. So there are limits of course to correct by construction", "tokens": [50676, 570, 674, 5666, 2001, 307, 406, 257, 2445, 13, 407, 456, 366, 10406, 295, 1164, 281, 3006, 538, 6435, 51092], "temperature": 0.0, "avg_logprob": -0.12294019811293658, "compression_ratio": 1.6948356807511737, "no_speech_prob": 0.00569281168282032}, {"id": 58, "seek": 37352, "start": 388.79999999999995, "end": 392.79999999999995, "text": " and I think it's especially important to be intellectually honest with that", "tokens": [51128, 293, 286, 519, 309, 311, 2318, 1021, 281, 312, 46481, 3245, 365, 300, 51328], "temperature": 0.0, "avg_logprob": -0.12294019811293658, "compression_ratio": 1.6948356807511737, "no_speech_prob": 0.00569281168282032}, {"id": 59, "seek": 37352, "start": 393.44, "end": 401.2, "text": " Haskell is not a prover you can prove you know lemmas or you know and theorems with it so you", "tokens": [51360, 8646, 43723, 307, 406, 257, 447, 331, 291, 393, 7081, 291, 458, 7495, 3799, 420, 291, 458, 293, 10299, 2592, 365, 309, 370, 291, 51748], "temperature": 0.0, "avg_logprob": -0.12294019811293658, "compression_ratio": 1.6948356807511737, "no_speech_prob": 0.00569281168282032}, {"id": 60, "seek": 40120, "start": 401.2, "end": 406.24, "text": " have to write tests and tests coming come in many shapes and forms you write tests for your", "tokens": [50364, 362, 281, 2464, 6921, 293, 6921, 1348, 808, 294, 867, 10854, 293, 6422, 291, 2464, 6921, 337, 428, 50616], "temperature": 0.0, "avg_logprob": -0.1502493242674236, "compression_ratio": 1.855721393034826, "no_speech_prob": 0.00039953753002919257}, {"id": 61, "seek": 40120, "start": 406.24, "end": 411.44, "text": " integrations your properties and end to end tests tests are not optional unlike maybe.", "tokens": [50616, 3572, 763, 428, 7221, 293, 917, 281, 917, 6921, 6921, 366, 406, 17312, 8343, 1310, 13, 50876], "temperature": 0.0, "avg_logprob": -0.1502493242674236, "compression_ratio": 1.855721393034826, "no_speech_prob": 0.00039953753002919257}, {"id": 62, "seek": 40120, "start": 413.76, "end": 420.8, "text": " So functional application architecture so this that I showed you gives us a tool to focus now on", "tokens": [50992, 407, 11745, 3861, 9482, 370, 341, 300, 286, 4712, 291, 2709, 505, 257, 2290, 281, 1879, 586, 322, 51344], "temperature": 0.0, "avg_logprob": -0.1502493242674236, "compression_ratio": 1.855721393034826, "no_speech_prob": 0.00039953753002919257}, {"id": 63, "seek": 40120, "start": 420.8, "end": 426.0, "text": " the topic of functional application architecture and this time we arrive at in the land of domain", "tokens": [51344, 264, 4829, 295, 11745, 3861, 9482, 293, 341, 565, 321, 8881, 412, 294, 264, 2117, 295, 9274, 51604], "temperature": 0.0, "avg_logprob": -0.1502493242674236, "compression_ratio": 1.855721393034826, "no_speech_prob": 0.00039953753002919257}, {"id": 64, "seek": 42600, "start": 426.56, "end": 431.52, "text": " design and there is there will be a brief overview of the terminology and the techniques that were", "tokens": [50392, 1715, 293, 456, 307, 456, 486, 312, 257, 5353, 12492, 295, 264, 27575, 293, 264, 7512, 300, 645, 50640], "temperature": 0.0, "avg_logprob": -0.15315537069035673, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.009479331783950329}, {"id": 65, "seek": 42600, "start": 431.52, "end": 438.48, "text": " created in the discipline and how they apply to us. So we have without surprise the concept of a", "tokens": [50640, 2942, 294, 264, 13635, 293, 577, 436, 3079, 281, 505, 13, 407, 321, 362, 1553, 6365, 264, 3410, 295, 257, 50988], "temperature": 0.0, "avg_logprob": -0.15315537069035673, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.009479331783950329}, {"id": 66, "seek": 42600, "start": 438.48, "end": 446.64, "text": " bounded context it's a context there are workflow in there so what is it really it's an autonomous", "tokens": [50988, 37498, 4319, 309, 311, 257, 4319, 456, 366, 20993, 294, 456, 370, 437, 307, 309, 534, 309, 311, 364, 23797, 51396], "temperature": 0.0, "avg_logprob": -0.15315537069035673, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.009479331783950329}, {"id": 67, "seek": 42600, "start": 446.64, "end": 453.2, "text": " subsystem so it's responsible for one or multiple workflows and it has well-defined boundaries which", "tokens": [51396, 2090, 9321, 370, 309, 311, 6250, 337, 472, 420, 3866, 43461, 293, 309, 575, 731, 12, 37716, 13180, 597, 51724], "temperature": 0.0, "avg_logprob": -0.15315537069035673, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.009479331783950329}, {"id": 68, "seek": 45320, "start": 453.2, "end": 459.92, "text": " is extremely important so we have to formalize or at least be very explicit how we talk to it", "tokens": [50364, 307, 4664, 1021, 370, 321, 362, 281, 9860, 1125, 420, 412, 1935, 312, 588, 13691, 577, 321, 751, 281, 309, 50700], "temperature": 0.0, "avg_logprob": -0.0884597415015811, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0022021448239684105}, {"id": 69, "seek": 45320, "start": 459.92, "end": 466.48, "text": " its inputs and its outputs. If we take the example of flora.pm which is a community website", "tokens": [50700, 1080, 15743, 293, 1080, 23930, 13, 759, 321, 747, 264, 1365, 295, 932, 3252, 13, 14395, 597, 307, 257, 1768, 3144, 51028], "temperature": 0.0, "avg_logprob": -0.0884597415015811, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0022021448239684105}, {"id": 70, "seek": 45320, "start": 467.2, "end": 473.12, "text": " an alternative package index for the Haskell community the schema is fairly simple we have", "tokens": [51064, 364, 8535, 7372, 8186, 337, 264, 8646, 43723, 1768, 264, 34078, 307, 6457, 2199, 321, 362, 51360], "temperature": 0.0, "avg_logprob": -0.0884597415015811, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0022021448239684105}, {"id": 71, "seek": 45320, "start": 473.12, "end": 478.15999999999997, "text": " the web component that goes to the core component which is tasked then to interface with database", "tokens": [51360, 264, 3670, 6542, 300, 1709, 281, 264, 4965, 6542, 597, 307, 38621, 550, 281, 9226, 365, 8149, 51612], "temperature": 0.0, "avg_logprob": -0.0884597415015811, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0022021448239684105}, {"id": 72, "seek": 47816, "start": 478.16, "end": 484.32000000000005, "text": " and we have a jobs worker for the jobs queue that also talks to the core components and to the", "tokens": [50364, 293, 321, 362, 257, 4782, 11346, 337, 264, 4782, 18639, 300, 611, 6686, 281, 264, 4965, 6677, 293, 281, 264, 50672], "temperature": 0.0, "avg_logprob": -0.10746911855844352, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.002307659247890115}, {"id": 73, "seek": 47816, "start": 484.32000000000005, "end": 493.44000000000005, "text": " database but we know that it's not going to talk with the web components so this is the kind of", "tokens": [50672, 8149, 457, 321, 458, 300, 309, 311, 406, 516, 281, 751, 365, 264, 3670, 6677, 370, 341, 307, 264, 733, 295, 51128], "temperature": 0.0, "avg_logprob": -0.10746911855844352, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.002307659247890115}, {"id": 74, "seek": 47816, "start": 493.44000000000005, "end": 499.28000000000003, "text": " you know setting boundaries because they are in a healthy relationship and you know we know", "tokens": [51128, 291, 458, 3287, 13180, 570, 436, 366, 294, 257, 4627, 2480, 293, 291, 458, 321, 458, 51420], "temperature": 0.0, "avg_logprob": -0.10746911855844352, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.002307659247890115}, {"id": 75, "seek": 49928, "start": 499.28, "end": 509.03999999999996, "text": " they will not talk to each other. One more step forward philas refactoring. Now something that", "tokens": [50364, 436, 486, 406, 751, 281, 1184, 661, 13, 1485, 544, 1823, 2128, 903, 388, 296, 1895, 578, 3662, 13, 823, 746, 300, 50852], "temperature": 0.0, "avg_logprob": -0.24436984956264496, "compression_ratio": 1.538888888888889, "no_speech_prob": 0.009435802698135376}, {"id": 76, "seek": 49928, "start": 509.03999999999996, "end": 515.6, "text": " the Java and C sharp world gave us are the concepts of data transfer objects data access", "tokens": [50852, 264, 10745, 293, 383, 8199, 1002, 2729, 505, 366, 264, 10392, 295, 1412, 5003, 6565, 1412, 2105, 51180], "temperature": 0.0, "avg_logprob": -0.24436984956264496, "compression_ratio": 1.538888888888889, "no_speech_prob": 0.009435802698135376}, {"id": 77, "seek": 49928, "start": 515.6, "end": 522.4, "text": " object and business object. Sometimes they're the same thing sometimes you are lucky that the", "tokens": [51180, 2657, 293, 1606, 2657, 13, 4803, 436, 434, 264, 912, 551, 2171, 291, 366, 6356, 300, 264, 51520], "temperature": 0.0, "avg_logprob": -0.24436984956264496, "compression_ratio": 1.538888888888889, "no_speech_prob": 0.009435802698135376}, {"id": 78, "seek": 52240, "start": 522.4, "end": 529.12, "text": " JSON payload you receive is the same object upon which you will perform your business computations", "tokens": [50364, 31828, 30918, 291, 4774, 307, 264, 912, 2657, 3564, 597, 291, 486, 2042, 428, 1606, 2807, 763, 50700], "temperature": 0.0, "avg_logprob": -0.10538168651301687, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.014268252067267895}, {"id": 79, "seek": 52240, "start": 529.12, "end": 535.28, "text": " and which you will store in your database but sometimes they are not and really it is pure luck", "tokens": [50700, 293, 597, 291, 486, 3531, 294, 428, 8149, 457, 2171, 436, 366, 406, 293, 534, 309, 307, 6075, 3668, 51008], "temperature": 0.0, "avg_logprob": -0.10538168651301687, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.014268252067267895}, {"id": 80, "seek": 52240, "start": 535.28, "end": 541.04, "text": " that sometimes these types align. An example of how this bit me when I was young and hopeful", "tokens": [51008, 300, 2171, 613, 3467, 7975, 13, 1107, 1365, 295, 577, 341, 857, 385, 562, 286, 390, 2037, 293, 20531, 51296], "temperature": 0.0, "avg_logprob": -0.10538168651301687, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.014268252067267895}, {"id": 81, "seek": 52240, "start": 541.04, "end": 547.1999999999999, "text": " obvious without much practice during meeting with other people we would try to define a json", "tokens": [51296, 6322, 1553, 709, 3124, 1830, 3440, 365, 661, 561, 321, 576, 853, 281, 6964, 257, 361, 3015, 51604], "temperature": 0.0, "avg_logprob": -0.10538168651301687, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.014268252067267895}, {"id": 82, "seek": 54720, "start": 547.2, "end": 554.6400000000001, "text": " based format for data exchange between several systems and we had elixir systems php ruby python", "tokens": [50364, 2361, 7877, 337, 1412, 7742, 1296, 2940, 3652, 293, 321, 632, 806, 970, 347, 3652, 903, 79, 5915, 88, 38797, 50736], "temperature": 0.0, "avg_logprob": -0.11866676673460543, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.026722745969891548}, {"id": 83, "seek": 54720, "start": 554.6400000000001, "end": 561.44, "text": " and these all you know give you several slight differences in how you can you know have data", "tokens": [50736, 293, 613, 439, 291, 458, 976, 291, 2940, 4036, 7300, 294, 577, 291, 393, 291, 458, 362, 1412, 51076], "temperature": 0.0, "avg_logprob": -0.11866676673460543, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.026722745969891548}, {"id": 84, "seek": 54720, "start": 561.44, "end": 568.48, "text": " types encoded in these languages and for example if you are dealing with rubies or php users they", "tokens": [51076, 3467, 2058, 12340, 294, 613, 8650, 293, 337, 1365, 498, 291, 366, 6260, 365, 5915, 530, 420, 903, 79, 5022, 436, 51428], "temperature": 0.0, "avg_logprob": -0.11866676673460543, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.026722745969891548}, {"id": 85, "seek": 54720, "start": 568.48, "end": 574.32, "text": " will try and push heterogeneous lists in the data format so you can have a nint a string", "tokens": [51428, 486, 853, 293, 2944, 20789, 31112, 14511, 294, 264, 1412, 7877, 370, 291, 393, 362, 257, 297, 686, 257, 6798, 51720], "temperature": 0.0, "avg_logprob": -0.11866676673460543, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.026722745969891548}, {"id": 86, "seek": 57432, "start": 575.0400000000001, "end": 580.0, "text": " and natively in Haskell we don't do that so we would have to create some abstraction on top of it", "tokens": [50400, 293, 8470, 356, 294, 8646, 43723, 321, 500, 380, 360, 300, 370, 321, 576, 362, 281, 1884, 512, 37765, 322, 1192, 295, 309, 50648], "temperature": 0.0, "avg_logprob": -0.1150131669155387, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0051221479661762714}, {"id": 87, "seek": 57432, "start": 580.8000000000001, "end": 588.0, "text": " and I was realizing that I was constraining myself with the capacity of each language", "tokens": [50688, 293, 286, 390, 16734, 300, 286, 390, 11525, 1760, 2059, 365, 264, 6042, 295, 1184, 2856, 51048], "temperature": 0.0, "avg_logprob": -0.1150131669155387, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0051221479661762714}, {"id": 88, "seek": 57432, "start": 588.0, "end": 595.12, "text": " to create this data format based on json but you don't have to do it you can have your fully", "tokens": [51048, 281, 1884, 341, 1412, 7877, 2361, 322, 361, 3015, 457, 291, 500, 380, 362, 281, 360, 309, 291, 393, 362, 428, 4498, 51404], "temperature": 0.0, "avg_logprob": -0.1150131669155387, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0051221479661762714}, {"id": 89, "seek": 57432, "start": 595.12, "end": 603.2, "text": " external way to talk to your mates your other systems and have a different representation", "tokens": [51404, 8320, 636, 281, 751, 281, 428, 31488, 428, 661, 3652, 293, 362, 257, 819, 10290, 51808], "temperature": 0.0, "avg_logprob": -0.1150131669155387, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0051221479661762714}, {"id": 90, "seek": 60320, "start": 603.2, "end": 611.2800000000001, "text": " inside your core components for example if we apply this to flora we can see that actually", "tokens": [50364, 1854, 428, 4965, 6677, 337, 1365, 498, 321, 3079, 341, 281, 932, 3252, 321, 393, 536, 300, 767, 50768], "temperature": 0.0, "avg_logprob": -0.06731442283181584, "compression_ratio": 1.7695852534562213, "no_speech_prob": 0.003113553626462817}, {"id": 91, "seek": 60320, "start": 611.2800000000001, "end": 617.5200000000001, "text": " I have my business objects living inside my bounded context when I need to store them I serialize", "tokens": [50768, 286, 362, 452, 1606, 6565, 2647, 1854, 452, 37498, 4319, 562, 286, 643, 281, 3531, 552, 286, 17436, 1125, 51080], "temperature": 0.0, "avg_logprob": -0.06731442283181584, "compression_ratio": 1.7695852534562213, "no_speech_prob": 0.003113553626462817}, {"id": 92, "seek": 60320, "start": 617.5200000000001, "end": 624.32, "text": " them I serialize them to a data access object that will be compliant with what my database expects", "tokens": [51080, 552, 286, 17436, 1125, 552, 281, 257, 1412, 2105, 2657, 300, 486, 312, 36248, 365, 437, 452, 8149, 33280, 51420], "temperature": 0.0, "avg_logprob": -0.06731442283181584, "compression_ratio": 1.7695852534562213, "no_speech_prob": 0.003113553626462817}, {"id": 93, "seek": 60320, "start": 624.32, "end": 629.5200000000001, "text": " so it means no fancy mutually recursive types for example or something like that and when I need", "tokens": [51420, 370, 309, 1355, 572, 10247, 39144, 20560, 488, 3467, 337, 1365, 420, 746, 411, 300, 293, 562, 286, 643, 51680], "temperature": 0.0, "avg_logprob": -0.06731442283181584, "compression_ratio": 1.7695852534562213, "no_speech_prob": 0.003113553626462817}, {"id": 94, "seek": 62952, "start": 629.52, "end": 636.0799999999999, "text": " to send that on the wire I will serialize that to a format that is easily representable by xml,", "tokens": [50364, 281, 2845, 300, 322, 264, 6234, 286, 486, 17436, 1125, 300, 281, 257, 7877, 300, 307, 3612, 2906, 712, 538, 2031, 15480, 11, 50692], "temperature": 0.0, "avg_logprob": -0.0877617597579956, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0016601714305579662}, {"id": 95, "seek": 62952, "start": 636.0799999999999, "end": 641.04, "text": " json and other you know various cursed binary representations that we may find especially", "tokens": [50692, 361, 3015, 293, 661, 291, 458, 3683, 29498, 17434, 33358, 300, 321, 815, 915, 2318, 50940], "temperature": 0.0, "avg_logprob": -0.0877617597579956, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0016601714305579662}, {"id": 96, "seek": 62952, "start": 641.04, "end": 648.8, "text": " in the banking system so in the end if I was to summarize bounded context you know I showed you", "tokens": [50940, 294, 264, 18261, 1185, 370, 294, 264, 917, 498, 286, 390, 281, 20858, 37498, 4319, 291, 458, 286, 4712, 291, 51328], "temperature": 0.0, "avg_logprob": -0.0877617597579956, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0016601714305579662}, {"id": 97, "seek": 62952, "start": 650.16, "end": 656.4, "text": " a very simple diagram earlier of flora but now how does it interface with each other so we have", "tokens": [51396, 257, 588, 2199, 10686, 3071, 295, 932, 3252, 457, 586, 577, 775, 309, 9226, 365, 1184, 661, 370, 321, 362, 51708], "temperature": 0.0, "avg_logprob": -0.0877617597579956, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0016601714305579662}, {"id": 98, "seek": 65640, "start": 656.4, "end": 663.4399999999999, "text": " details between each component and especially between the clients and us daos for storage access", "tokens": [50364, 4365, 1296, 1184, 6542, 293, 2318, 1296, 264, 6982, 293, 505, 1120, 329, 337, 6725, 2105, 50716], "temperature": 0.0, "avg_logprob": -0.04666038751602173, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.013709863647818565}, {"id": 99, "seek": 65640, "start": 663.4399999999999, "end": 671.36, "text": " and inside each component we operate on our business objects it so happens that the business", "tokens": [50716, 293, 1854, 1184, 6542, 321, 9651, 322, 527, 1606, 6565, 309, 370, 2314, 300, 264, 1606, 51112], "temperature": 0.0, "avg_logprob": -0.04666038751602173, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.013709863647818565}, {"id": 100, "seek": 65640, "start": 671.36, "end": 676.8, "text": " object can be extremely similar between the web and the core components but sometimes they are not", "tokens": [51112, 2657, 393, 312, 4664, 2531, 1296, 264, 3670, 293, 264, 4965, 6677, 457, 2171, 436, 366, 406, 51384], "temperature": 0.0, "avg_logprob": -0.04666038751602173, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.013709863647818565}, {"id": 101, "seek": 65640, "start": 676.8, "end": 684.0, "text": " and I think it's very liberating to know that you don't have to keep to a single representation", "tokens": [51384, 293, 286, 519, 309, 311, 588, 6774, 990, 281, 458, 300, 291, 500, 380, 362, 281, 1066, 281, 257, 2167, 10290, 51744], "temperature": 0.0, "avg_logprob": -0.04666038751602173, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.013709863647818565}, {"id": 102, "seek": 68400, "start": 684.0, "end": 690.56, "text": " from a to z all the way you really can have conversion layers between your components between", "tokens": [50364, 490, 257, 281, 710, 439, 264, 636, 291, 534, 393, 362, 14298, 7914, 1296, 428, 6677, 1296, 50692], "temperature": 0.0, "avg_logprob": -0.0780804218390049, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.002335191471502185}, {"id": 103, "seek": 68400, "start": 690.56, "end": 696.56, "text": " your interfaces and it's perfectly all right for example the retrieval but reading configuration", "tokens": [50692, 428, 28416, 293, 309, 311, 6239, 439, 558, 337, 1365, 264, 19817, 3337, 457, 3760, 11694, 50992], "temperature": 0.0, "avg_logprob": -0.0780804218390049, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.002335191471502185}, {"id": 104, "seek": 68400, "start": 697.36, "end": 702.72, "text": " the 12 factor application model tells us to read configuration from the environment from the shell", "tokens": [51032, 264, 2272, 5952, 3861, 2316, 5112, 505, 281, 1401, 11694, 490, 264, 2823, 490, 264, 8720, 51300], "temperature": 0.0, "avg_logprob": -0.0780804218390049, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.002335191471502185}, {"id": 105, "seek": 68400, "start": 702.72, "end": 710.48, "text": " so what we have on the left is the conflict type which models what I get from the environment", "tokens": [51300, 370, 437, 321, 362, 322, 264, 1411, 307, 264, 6596, 2010, 597, 5245, 437, 286, 483, 490, 264, 2823, 51688], "temperature": 0.0, "avg_logprob": -0.0780804218390049, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.002335191471502185}, {"id": 106, "seek": 71048, "start": 710.48, "end": 716.64, "text": " with a twist because you know I can force some types it's not all text base I can force my", "tokens": [50364, 365, 257, 8203, 570, 291, 458, 286, 393, 3464, 512, 3467, 309, 311, 406, 439, 2487, 3096, 286, 393, 3464, 452, 50672], "temperature": 0.0, "avg_logprob": -0.11777513105790693, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.0037394810933619738}, {"id": 107, "seek": 71048, "start": 716.64, "end": 724.5600000000001, "text": " parsing of HTTP ports to be a word 16 for example because I'm not so interested in you know having", "tokens": [50672, 21156, 278, 295, 33283, 18160, 281, 312, 257, 1349, 3165, 337, 1365, 570, 286, 478, 406, 370, 3102, 294, 291, 458, 1419, 51068], "temperature": 0.0, "avg_logprob": -0.11777513105790693, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.0037394810933619738}, {"id": 108, "seek": 71048, "start": 724.5600000000001, "end": 733.2, "text": " port number of one million and unless not without overflow so I've got my xml configuration that", "tokens": [51068, 2436, 1230, 295, 472, 2459, 293, 5969, 406, 1553, 37772, 370, 286, 600, 658, 452, 2031, 15480, 11694, 300, 51500], "temperature": 0.0, "avg_logprob": -0.11777513105790693, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.0037394810933619738}, {"id": 109, "seek": 71048, "start": 733.2, "end": 737.84, "text": " describes for example the first member is db config with a pool configuration so it's all the", "tokens": [51500, 15626, 337, 1365, 264, 700, 4006, 307, 274, 65, 6662, 365, 257, 7005, 11694, 370, 309, 311, 439, 264, 51732], "temperature": 0.0, "avg_logprob": -0.11777513105790693, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.0037394810933619738}, {"id": 110, "seek": 73784, "start": 737.84, "end": 743.36, "text": " information I need for the pool the database pool and then internal configuration it's the pool", "tokens": [50364, 1589, 286, 643, 337, 264, 7005, 264, 8149, 7005, 293, 550, 6920, 11694, 309, 311, 264, 7005, 50640], "temperature": 0.0, "avg_logprob": -0.050819716876066186, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.0021102966275066137}, {"id": 111, "seek": 73784, "start": 743.36, "end": 752.24, "text": " itself and it's it's very useful because then I have this very explicit conversion and it's", "tokens": [50640, 2564, 293, 309, 311, 309, 311, 588, 4420, 570, 550, 286, 362, 341, 588, 13691, 14298, 293, 309, 311, 51084], "temperature": 0.0, "avg_logprob": -0.050819716876066186, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.0021102966275066137}, {"id": 112, "seek": 73784, "start": 752.24, "end": 758.48, "text": " perfectly all right then to change something inside or outside my core components because", "tokens": [51084, 6239, 439, 558, 550, 281, 1319, 746, 1854, 420, 2380, 452, 4965, 6677, 570, 51396], "temperature": 0.0, "avg_logprob": -0.050819716876066186, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.0021102966275066137}, {"id": 113, "seek": 73784, "start": 758.48, "end": 764.1600000000001, "text": " then I only have you know this bottleneck that I can easily change and one more step towards", "tokens": [51396, 550, 286, 787, 362, 291, 458, 341, 44641, 547, 300, 286, 393, 3612, 1319, 293, 472, 544, 1823, 3030, 51680], "temperature": 0.0, "avg_logprob": -0.050819716876066186, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.0021102966275066137}, {"id": 114, "seek": 76416, "start": 764.16, "end": 774.3199999999999, "text": " fearless refactoring separating commands and queries so this has practical effects in terms of", "tokens": [50364, 44139, 1895, 578, 3662, 29279, 16901, 293, 24109, 370, 341, 575, 8496, 5065, 294, 2115, 295, 50872], "temperature": 0.0, "avg_logprob": -0.0881290853023529, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.0005465832073241472}, {"id": 115, "seek": 76416, "start": 774.3199999999999, "end": 780.56, "text": " operation infrastructure and also in terms of ergonomics for the people who read our code", "tokens": [50872, 6916, 6896, 293, 611, 294, 2115, 295, 42735, 29884, 337, 264, 561, 567, 1401, 527, 3089, 51184], "temperature": 0.0, "avg_logprob": -0.0881290853023529, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.0005465832073241472}, {"id": 116, "seek": 76416, "start": 782.48, "end": 787.12, "text": " you know in a practical way if we know that we have a recurrent fairly heavy processing", "tokens": [51280, 291, 458, 294, 257, 8496, 636, 498, 321, 458, 300, 321, 362, 257, 18680, 1753, 6457, 4676, 9007, 51512], "temperature": 0.0, "avg_logprob": -0.0881290853023529, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.0005465832073241472}, {"id": 117, "seek": 76416, "start": 787.12, "end": 794.0799999999999, "text": " query that runs and can take significant lock or CPUs on our server we have the option to have", "tokens": [51512, 14581, 300, 6676, 293, 393, 747, 4776, 4017, 420, 13199, 82, 322, 527, 7154, 321, 362, 264, 3614, 281, 362, 51860], "temperature": 0.0, "avg_logprob": -0.0881290853023529, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.0005465832073241472}, {"id": 118, "seek": 79408, "start": 794.08, "end": 801.76, "text": " these queries run on a read-only replica for our database and put this replica on another machine", "tokens": [50364, 613, 24109, 1190, 322, 257, 1401, 12, 25202, 35456, 337, 527, 8149, 293, 829, 341, 35456, 322, 1071, 3479, 50748], "temperature": 0.0, "avg_logprob": -0.09831720849742061, "compression_ratio": 1.8194444444444444, "no_speech_prob": 0.0021239137277007103}, {"id": 119, "seek": 79408, "start": 801.76, "end": 807.5200000000001, "text": " so postgresql for example very specific example but I can talk about that you can have read-only", "tokens": [50748, 370, 2183, 45189, 80, 75, 337, 1365, 588, 2685, 1365, 457, 286, 393, 751, 466, 300, 291, 393, 362, 1401, 12, 25202, 51036], "temperature": 0.0, "avg_logprob": -0.09831720849742061, "compression_ratio": 1.8194444444444444, "no_speech_prob": 0.0021239137277007103}, {"id": 120, "seek": 79408, "start": 807.5200000000001, "end": 813.44, "text": " replicas which take read-only queries and will be very angry at you if you ever try to mutate the", "tokens": [51036, 3248, 9150, 597, 747, 1401, 12, 25202, 24109, 293, 486, 312, 588, 6884, 412, 291, 498, 291, 1562, 853, 281, 5839, 473, 264, 51332], "temperature": 0.0, "avg_logprob": -0.09831720849742061, "compression_ratio": 1.8194444444444444, "no_speech_prob": 0.0021239137277007103}, {"id": 121, "seek": 79408, "start": 813.44, "end": 820.6400000000001, "text": " state of this replica so you have your primary server which upon which you perform mutating commands", "tokens": [51332, 1785, 295, 341, 35456, 370, 291, 362, 428, 6194, 7154, 597, 3564, 597, 291, 2042, 5839, 990, 16901, 51692], "temperature": 0.0, "avg_logprob": -0.09831720849742061, "compression_ratio": 1.8194444444444444, "no_speech_prob": 0.0021239137277007103}, {"id": 122, "seek": 82064, "start": 821.1999999999999, "end": 826.24, "text": " and then it will stream these changes to the read-only replica and then the replica will", "tokens": [50392, 293, 550, 309, 486, 4309, 613, 2962, 281, 264, 1401, 12, 25202, 35456, 293, 550, 264, 35456, 486, 50644], "temperature": 0.0, "avg_logprob": -0.12106205168224517, "compression_ratio": 1.7630331753554502, "no_speech_prob": 0.004035754594951868}, {"id": 123, "seek": 82064, "start": 827.04, "end": 833.28, "text": " provide you with a read-only interface that is like not only enforced at the type and at the", "tokens": [50684, 2893, 291, 365, 257, 1401, 12, 25202, 9226, 300, 307, 411, 406, 787, 40953, 412, 264, 2010, 293, 412, 264, 50996], "temperature": 0.0, "avg_logprob": -0.12106205168224517, "compression_ratio": 1.7630331753554502, "no_speech_prob": 0.004035754594951868}, {"id": 124, "seek": 82064, "start": 833.28, "end": 839.04, "text": " level of the types for example in your applications but fundamentally on the protocol itself you will", "tokens": [50996, 1496, 295, 264, 3467, 337, 1365, 294, 428, 5821, 457, 17879, 322, 264, 10336, 2564, 291, 486, 51284], "temperature": 0.0, "avg_logprob": -0.12106205168224517, "compression_ratio": 1.7630331753554502, "no_speech_prob": 0.004035754594951868}, {"id": 125, "seek": 82064, "start": 839.04, "end": 844.96, "text": " get a runtime error if you try to mutate this state so you can't like unsafe performance", "tokens": [51284, 483, 257, 34474, 6713, 498, 291, 853, 281, 5839, 473, 341, 1785, 370, 291, 393, 380, 411, 35948, 3389, 51580], "temperature": 0.0, "avg_logprob": -0.12106205168224517, "compression_ratio": 1.7630331753554502, "no_speech_prob": 0.004035754594951868}, {"id": 126, "seek": 84496, "start": 845.76, "end": 853.6800000000001, "text": " unsafe course you weigh you know behind that so something I learned at my current place of", "tokens": [50404, 35948, 1164, 291, 13843, 291, 458, 2261, 300, 370, 746, 286, 3264, 412, 452, 2190, 1081, 295, 50800], "temperature": 0.0, "avg_logprob": -0.14888548081920994, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0012966954382136464}, {"id": 127, "seek": 84496, "start": 853.6800000000001, "end": 860.96, "text": " employment scrive is to have a separation like a physical separation in the code between types", "tokens": [50800, 11949, 5545, 303, 307, 281, 362, 257, 14634, 411, 257, 4001, 14634, 294, 264, 3089, 1296, 3467, 51164], "temperature": 0.0, "avg_logprob": -0.14888548081920994, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0012966954382136464}, {"id": 128, "seek": 84496, "start": 860.96, "end": 869.2800000000001, "text": " the commands and the queries so the dialect the idiom that we have here is that we have these", "tokens": [51164, 264, 16901, 293, 264, 24109, 370, 264, 24652, 264, 18014, 298, 300, 321, 362, 510, 307, 300, 321, 362, 613, 51580], "temperature": 0.0, "avg_logprob": -0.14888548081920994, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0012966954382136464}, {"id": 129, "seek": 86928, "start": 869.28, "end": 877.8399999999999, "text": " dot query and dot update modules in which we put the read-only and mutating queries and then when", "tokens": [50364, 5893, 14581, 293, 5893, 5623, 16679, 294, 597, 321, 829, 264, 1401, 12, 25202, 293, 5839, 990, 24109, 293, 550, 562, 50792], "temperature": 0.0, "avg_logprob": -0.11346096577851669, "compression_ratio": 1.747787610619469, "no_speech_prob": 0.019783753901720047}, {"id": 130, "seek": 86928, "start": 877.8399999999999, "end": 884.8, "text": " we import them we qualify them for example import qualified as query and then there is a visual", "tokens": [50792, 321, 974, 552, 321, 20276, 552, 337, 1365, 974, 15904, 382, 14581, 293, 550, 456, 307, 257, 5056, 51140], "temperature": 0.0, "avg_logprob": -0.11346096577851669, "compression_ratio": 1.747787610619469, "no_speech_prob": 0.019783753901720047}, {"id": 131, "seek": 86928, "start": 884.8, "end": 891.6, "text": " indicator so you know it's very bare bones but it does work that this is a query that is going to be", "tokens": [51140, 16961, 370, 291, 458, 309, 311, 588, 6949, 10491, 457, 309, 775, 589, 300, 341, 307, 257, 14581, 300, 307, 516, 281, 312, 51480], "temperature": 0.0, "avg_logprob": -0.11346096577851669, "compression_ratio": 1.747787610619469, "no_speech_prob": 0.019783753901720047}, {"id": 132, "seek": 86928, "start": 891.6, "end": 898.0, "text": " read-only it's not going to increment a counter in a site table because you have performed something", "tokens": [51480, 1401, 12, 25202, 309, 311, 406, 516, 281, 26200, 257, 5682, 294, 257, 3621, 3199, 570, 291, 362, 10332, 746, 51800], "temperature": 0.0, "avg_logprob": -0.11346096577851669, "compression_ratio": 1.747787610619469, "no_speech_prob": 0.019783753901720047}, {"id": 133, "seek": 89800, "start": 898.0, "end": 907.04, "text": " that is seemingly read-only a a good example for example it's LinkedIn when you view someone's", "tokens": [50364, 300, 307, 18709, 1401, 12, 25202, 257, 257, 665, 1365, 337, 1365, 309, 311, 20657, 562, 291, 1910, 1580, 311, 50816], "temperature": 0.0, "avg_logprob": -0.04755717445822323, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.003096488770097494}, {"id": 134, "seek": 89800, "start": 907.04, "end": 913.6, "text": " page on LinkedIn they have a notification so you would think that viewing something it's a", "tokens": [50816, 3028, 322, 20657, 436, 362, 257, 11554, 370, 291, 576, 519, 300, 17480, 746, 309, 311, 257, 51144], "temperature": 0.0, "avg_logprob": -0.04755717445822323, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.003096488770097494}, {"id": 135, "seek": 89800, "start": 913.6, "end": 919.04, "text": " fundamentally read-only even the terms reading viewing you know you would think it's read-only", "tokens": [51144, 17879, 1401, 12, 25202, 754, 264, 2115, 3760, 17480, 291, 458, 291, 576, 519, 309, 311, 1401, 12, 25202, 51416], "temperature": 0.0, "avg_logprob": -0.04755717445822323, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.003096488770097494}, {"id": 136, "seek": 89800, "start": 919.04, "end": 924.08, "text": " but perhaps there is a counter that is increased with you know user tracking so that you can later", "tokens": [51416, 457, 4317, 456, 307, 257, 5682, 300, 307, 6505, 365, 291, 458, 4195, 11603, 370, 300, 291, 393, 1780, 51668], "temperature": 0.0, "avg_logprob": -0.04755717445822323, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.003096488770097494}, {"id": 137, "seek": 92408, "start": 924.08, "end": 932.4000000000001, "text": " report who has viewed your page but if you can you know bring one step more into separating the", "tokens": [50364, 2275, 567, 575, 19174, 428, 3028, 457, 498, 291, 393, 291, 458, 1565, 472, 1823, 544, 666, 29279, 264, 50780], "temperature": 0.0, "avg_logprob": -0.07367740926288423, "compression_ratio": 1.7361111111111112, "no_speech_prob": 0.003401480382308364}, {"id": 138, "seek": 92408, "start": 932.4000000000001, "end": 938.0, "text": " queries and the commands then it's much more it's much easier to know what which kind of", "tokens": [50780, 24109, 293, 264, 16901, 550, 309, 311, 709, 544, 309, 311, 709, 3571, 281, 458, 437, 597, 733, 295, 51060], "temperature": 0.0, "avg_logprob": -0.07367740926288423, "compression_ratio": 1.7361111111111112, "no_speech_prob": 0.003401480382308364}, {"id": 139, "seek": 92408, "start": 938.0, "end": 946.72, "text": " operation you're performing at which place in the code so we could go further even and declare", "tokens": [51060, 6916, 291, 434, 10205, 412, 597, 1081, 294, 264, 3089, 370, 321, 727, 352, 3052, 754, 293, 19710, 51496], "temperature": 0.0, "avg_logprob": -0.07367740926288423, "compression_ratio": 1.7361111111111112, "no_speech_prob": 0.003401480382308364}, {"id": 140, "seek": 92408, "start": 946.72, "end": 953.44, "text": " queries and commands as effects and with their own connection pools so for example I don't only", "tokens": [51496, 24109, 293, 16901, 382, 5065, 293, 365, 641, 1065, 4984, 28688, 370, 337, 1365, 286, 500, 380, 787, 51832], "temperature": 0.0, "avg_logprob": -0.07367740926288423, "compression_ratio": 1.7361111111111112, "no_speech_prob": 0.003401480382308364}, {"id": 141, "seek": 95344, "start": 953.5200000000001, "end": 963.2800000000001, "text": " have the db effect in my stack I'm declaring that I'm performing a read-only operation on the", "tokens": [50368, 362, 264, 274, 65, 1802, 294, 452, 8630, 286, 478, 40374, 300, 286, 478, 10205, 257, 1401, 12, 25202, 6916, 322, 264, 50856], "temperature": 0.0, "avg_logprob": -0.08940456991326319, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.0019733679946511984}, {"id": 142, "seek": 95344, "start": 963.2800000000001, "end": 972.08, "text": " read-only replica of my PostgreSQL database so one more step towards you know more so of course it", "tokens": [50856, 1401, 12, 25202, 35456, 295, 452, 10223, 33248, 39934, 8149, 370, 472, 544, 1823, 3030, 291, 458, 544, 370, 295, 1164, 309, 51296], "temperature": 0.0, "avg_logprob": -0.08940456991326319, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.0019733679946511984}, {"id": 143, "seek": 95344, "start": 972.08, "end": 978.48, "text": " can be a technical detail but also I think it's very important to be able to say to the readers", "tokens": [51296, 393, 312, 257, 6191, 2607, 457, 611, 286, 519, 309, 311, 588, 1021, 281, 312, 1075, 281, 584, 281, 264, 17147, 51616], "temperature": 0.0, "avg_logprob": -0.08940456991326319, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.0019733679946511984}, {"id": 144, "seek": 97848, "start": 978.48, "end": 984.24, "text": " of your code what are you performing which side effect does it have especially in the system", "tokens": [50364, 295, 428, 3089, 437, 366, 291, 10205, 597, 1252, 1802, 775, 309, 362, 2318, 294, 264, 1185, 50652], "temperature": 0.0, "avg_logprob": -0.06928022702534993, "compression_ratio": 1.6701570680628273, "no_speech_prob": 0.0012662399094551802}, {"id": 145, "seek": 97848, "start": 984.24, "end": 991.9200000000001, "text": " that you have ownership of now that's my anarchist tendencies coming up", "tokens": [50652, 300, 291, 362, 15279, 295, 586, 300, 311, 452, 41957, 468, 45488, 1348, 493, 51036], "temperature": 0.0, "avg_logprob": -0.06928022702534993, "compression_ratio": 1.6701570680628273, "no_speech_prob": 0.0012662399094551802}, {"id": 146, "seek": 97848, "start": 993.36, "end": 997.36, "text": " let's keep our distance from the state the state is best contained", "tokens": [51108, 718, 311, 1066, 527, 4560, 490, 264, 1785, 264, 1785, 307, 1151, 16212, 51308], "temperature": 0.0, "avg_logprob": -0.06928022702534993, "compression_ratio": 1.6701570680628273, "no_speech_prob": 0.0012662399094551802}, {"id": 147, "seek": 97848, "start": 999.84, "end": 1006.0, "text": " so the cache of our application is actually a bounded context in its own it has its own", "tokens": [51432, 370, 264, 19459, 295, 527, 3861, 307, 767, 257, 37498, 4319, 294, 1080, 1065, 309, 575, 1080, 1065, 51740], "temperature": 0.0, "avg_logprob": -0.06928022702534993, "compression_ratio": 1.6701570680628273, "no_speech_prob": 0.0012662399094551802}, {"id": 148, "seek": 100600, "start": 1006.0, "end": 1013.28, "text": " lifecycle data storage and api and by decoupling our application monolith from its state we have", "tokens": [50364, 45722, 1412, 6725, 293, 1882, 72, 293, 538, 979, 263, 11970, 527, 3861, 1108, 29131, 490, 1080, 1785, 321, 362, 50728], "temperature": 0.0, "avg_logprob": -0.058337653124773944, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.0010425237705931067}, {"id": 149, "seek": 100600, "start": 1013.28, "end": 1018.96, "text": " worked a significant portion of the path to having a setup where we can have multiple instances of", "tokens": [50728, 2732, 257, 4776, 8044, 295, 264, 3100, 281, 1419, 257, 8657, 689, 321, 393, 362, 3866, 14519, 295, 51012], "temperature": 0.0, "avg_logprob": -0.058337653124773944, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.0010425237705931067}, {"id": 150, "seek": 100600, "start": 1018.96, "end": 1025.92, "text": " our application and serving data from the same database in cache so at this point by ensuring", "tokens": [51012, 527, 3861, 293, 8148, 1412, 490, 264, 912, 8149, 294, 19459, 370, 412, 341, 935, 538, 16882, 51360], "temperature": 0.0, "avg_logprob": -0.058337653124773944, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.0010425237705931067}, {"id": 151, "seek": 100600, "start": 1025.92, "end": 1032.08, "text": " that the database server keeps operations in sync we've got you know higher consistency of", "tokens": [51360, 300, 264, 8149, 7154, 5965, 7705, 294, 20271, 321, 600, 658, 291, 458, 2946, 14416, 295, 51668], "temperature": 0.0, "avg_logprob": -0.058337653124773944, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.0010425237705931067}, {"id": 152, "seek": 103208, "start": 1033.04, "end": 1040.96, "text": " the application so that's the the cap theorem for the systems you've got cap is your application", "tokens": [50412, 264, 3861, 370, 300, 311, 264, 264, 1410, 20904, 337, 264, 3652, 291, 600, 658, 1410, 307, 428, 3861, 50808], "temperature": 0.0, "avg_logprob": -0.1746335337238927, "compression_ratio": 1.7245508982035929, "no_speech_prob": 0.0008916443330235779}, {"id": 153, "seek": 103208, "start": 1040.96, "end": 1048.56, "text": " consistent is it available or is it tolerant to partition and in you know some industries where", "tokens": [50808, 8398, 307, 309, 2435, 420, 307, 309, 45525, 281, 24808, 293, 294, 291, 458, 512, 13284, 689, 51188], "temperature": 0.0, "avg_logprob": -0.1746335337238927, "compression_ratio": 1.7245508982035929, "no_speech_prob": 0.0008916443330235779}, {"id": 154, "seek": 103208, "start": 1048.56, "end": 1055.6799999999998, "text": " you work in very sensitive with very sensitive data if you have a production incident you can't", "tokens": [51188, 291, 589, 294, 588, 9477, 365, 588, 9477, 1412, 498, 291, 362, 257, 4265, 9348, 291, 393, 380, 51544], "temperature": 0.0, "avg_logprob": -0.1746335337238927, "compression_ratio": 1.7245508982035929, "no_speech_prob": 0.0008916443330235779}, {"id": 155, "seek": 105568, "start": 1055.68, "end": 1063.8400000000001, "text": " risk having inconsistent data or having an inconsistent state where people can read someone", "tokens": [50364, 3148, 1419, 36891, 1412, 420, 1419, 364, 36891, 1785, 689, 561, 393, 1401, 1580, 50772], "temperature": 0.0, "avg_logprob": -0.0859265798403893, "compression_ratio": 1.7464114832535884, "no_speech_prob": 0.020635124295949936}, {"id": 156, "seek": 105568, "start": 1063.8400000000001, "end": 1069.44, "text": " else's private folder so it's better to shut things down for a bit we you know we keep our", "tokens": [50772, 1646, 311, 4551, 10820, 370, 309, 311, 1101, 281, 5309, 721, 760, 337, 257, 857, 321, 291, 458, 321, 1066, 527, 51052], "temperature": 0.0, "avg_logprob": -0.0859265798403893, "compression_ratio": 1.7464114832535884, "no_speech_prob": 0.020635124295949936}, {"id": 157, "seek": 105568, "start": 1069.44, "end": 1075.3600000000001, "text": " count we take a deep long breath and then we restart the system but it's because availability", "tokens": [51052, 1207, 321, 747, 257, 2452, 938, 6045, 293, 550, 321, 21022, 264, 1185, 457, 309, 311, 570, 17945, 51348], "temperature": 0.0, "avg_logprob": -0.0859265798403893, "compression_ratio": 1.7464114832535884, "no_speech_prob": 0.020635124295949936}, {"id": 158, "seek": 105568, "start": 1076.48, "end": 1082.8, "text": " has to take you know one for the team in order to keep consistent and you know partition", "tokens": [51404, 575, 281, 747, 291, 458, 472, 337, 264, 1469, 294, 1668, 281, 1066, 8398, 293, 291, 458, 24808, 51720], "temperature": 0.0, "avg_logprob": -0.0859265798403893, "compression_ratio": 1.7464114832535884, "no_speech_prob": 0.020635124295949936}, {"id": 159, "seek": 108280, "start": 1083.44, "end": 1090.6399999999999, "text": " tolerance sorry to partition can go out the window so for flora for example very simple we can have", "tokens": [50396, 23368, 2597, 281, 24808, 393, 352, 484, 264, 4910, 370, 337, 932, 3252, 337, 1365, 588, 2199, 321, 393, 362, 50756], "temperature": 0.0, "avg_logprob": -0.1128745855287064, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.0038835001178085804}, {"id": 160, "seek": 108280, "start": 1090.6399999999999, "end": 1097.04, "text": " our clients that talk to our nginx gateway and then the multiple instances of flora that still", "tokens": [50756, 527, 6982, 300, 751, 281, 527, 297, 1494, 87, 28532, 293, 550, 264, 3866, 14519, 295, 932, 3252, 300, 920, 51076], "temperature": 0.0, "avg_logprob": -0.1128745855287064, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.0038835001178085804}, {"id": 161, "seek": 108280, "start": 1097.04, "end": 1103.12, "text": " speak to the same database server for mutating operations and the same replica for read only", "tokens": [51076, 1710, 281, 264, 912, 8149, 7154, 337, 5839, 990, 7705, 293, 264, 912, 35456, 337, 1401, 787, 51380], "temperature": 0.0, "avg_logprob": -0.1128745855287064, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.0038835001178085804}, {"id": 162, "seek": 108280, "start": 1103.12, "end": 1109.04, "text": " commands you know i'm not selling you microservice architectures and you know scale to the moon", "tokens": [51380, 16901, 291, 458, 741, 478, 406, 6511, 291, 15547, 25006, 6331, 1303, 293, 291, 458, 4373, 281, 264, 7135, 51676], "temperature": 0.0, "avg_logprob": -0.1128745855287064, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.0038835001178085804}, {"id": 163, "seek": 110904, "start": 1109.04, "end": 1117.6, "text": " type of stuff but i think it's a very decent way to start a monolith we all know that you know", "tokens": [50364, 2010, 295, 1507, 457, 741, 519, 309, 311, 257, 588, 8681, 636, 281, 722, 257, 1108, 29131, 321, 439, 458, 300, 291, 458, 50792], "temperature": 0.0, "avg_logprob": -0.07868629693984985, "compression_ratio": 1.9035532994923858, "no_speech_prob": 0.006791066378355026}, {"id": 164, "seek": 110904, "start": 1117.6, "end": 1122.96, "text": " a good distributed system has to start as a monolith and then you know split it further and", "tokens": [50792, 257, 665, 12631, 1185, 575, 281, 722, 382, 257, 1108, 29131, 293, 550, 291, 458, 7472, 309, 3052, 293, 51060], "temperature": 0.0, "avg_logprob": -0.07868629693984985, "compression_ratio": 1.9035532994923858, "no_speech_prob": 0.006791066378355026}, {"id": 165, "seek": 110904, "start": 1122.96, "end": 1129.92, "text": " further if you start with a microservice based you know architecture you might end up with", "tokens": [51060, 3052, 498, 291, 722, 365, 257, 15547, 25006, 2361, 291, 458, 9482, 291, 1062, 917, 493, 365, 51408], "temperature": 0.0, "avg_logprob": -0.07868629693984985, "compression_ratio": 1.9035532994923858, "no_speech_prob": 0.006791066378355026}, {"id": 166, "seek": 110904, "start": 1129.92, "end": 1135.68, "text": " a distributed monolith but the the whole thing of a microservice based application is to have you", "tokens": [51408, 257, 12631, 1108, 29131, 457, 264, 264, 1379, 551, 295, 257, 15547, 25006, 2361, 3861, 307, 281, 362, 291, 51696], "temperature": 0.0, "avg_logprob": -0.07868629693984985, "compression_ratio": 1.9035532994923858, "no_speech_prob": 0.006791066378355026}, {"id": 167, "seek": 113568, "start": 1135.76, "end": 1142.0800000000002, "text": " know independent context that can still run so here we don't take you know the bet that every", "tokens": [50368, 458, 6695, 4319, 300, 393, 920, 1190, 370, 510, 321, 500, 380, 747, 291, 458, 264, 778, 300, 633, 50684], "temperature": 0.0, "avg_logprob": -0.08937334108956252, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.0066567035391926765}, {"id": 168, "seek": 113568, "start": 1142.0800000000002, "end": 1148.24, "text": " component is fully independent we acknowledge boundaries that we have some boundaries between", "tokens": [50684, 6542, 307, 4498, 6695, 321, 10692, 13180, 300, 321, 362, 512, 13180, 1296, 50992], "temperature": 0.0, "avg_logprob": -0.08937334108956252, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.0066567035391926765}, {"id": 169, "seek": 113568, "start": 1148.24, "end": 1155.52, "text": " the web the core and the job workers components and then themselves they have their own context so", "tokens": [50992, 264, 3670, 264, 4965, 293, 264, 1691, 5600, 6677, 293, 550, 2969, 436, 362, 641, 1065, 4319, 370, 51356], "temperature": 0.0, "avg_logprob": -0.08937334108956252, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.0066567035391926765}, {"id": 170, "seek": 113568, "start": 1156.8, "end": 1160.96, "text": " it's also about realism like do you want to scale to the moon and raise like hundreds of", "tokens": [51420, 309, 311, 611, 466, 38484, 411, 360, 291, 528, 281, 4373, 281, 264, 7135, 293, 5300, 411, 6779, 295, 51628], "temperature": 0.0, "avg_logprob": -0.08937334108956252, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.0066567035391926765}, {"id": 171, "seek": 116096, "start": 1161.04, "end": 1165.92, "text": " thousand of dollars from venture capitalists or do you want to create a nice community website", "tokens": [50368, 4714, 295, 3808, 490, 18474, 4238, 1751, 420, 360, 291, 528, 281, 1884, 257, 1481, 1768, 3144, 50612], "temperature": 0.0, "avg_logprob": -0.09622949957847596, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.001829946064390242}, {"id": 172, "seek": 116096, "start": 1165.92, "end": 1173.68, "text": " that indexes packages for the haskell environment i'm going to make a short detour here and it's", "tokens": [50612, 300, 8186, 279, 17401, 337, 264, 575, 43723, 2823, 741, 478, 516, 281, 652, 257, 2099, 1141, 396, 510, 293, 309, 311, 51000], "temperature": 0.0, "avg_logprob": -0.09622949957847596, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.001829946064390242}, {"id": 173, "seek": 116096, "start": 1173.68, "end": 1180.88, "text": " directing our workflows with types so it's a technique that brings together type safety", "tokens": [51000, 26979, 527, 43461, 365, 3467, 370, 309, 311, 257, 6532, 300, 5607, 1214, 2010, 4514, 51360], "temperature": 0.0, "avg_logprob": -0.09622949957847596, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.001829946064390242}, {"id": 174, "seek": 116096, "start": 1180.88, "end": 1185.68, "text": " and ergonomics which is one of my favorite subjects to create type directed state machines", "tokens": [51360, 293, 42735, 29884, 597, 307, 472, 295, 452, 2954, 13066, 281, 1884, 2010, 12898, 1785, 8379, 51600], "temperature": 0.0, "avg_logprob": -0.09622949957847596, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.001829946064390242}, {"id": 175, "seek": 118568, "start": 1185.68, "end": 1193.92, "text": " very fancy word basically it's it's really the way that your operation are composed together", "tokens": [50364, 588, 10247, 1349, 1936, 309, 311, 309, 311, 534, 264, 636, 300, 428, 6916, 366, 18204, 1214, 50776], "temperature": 0.0, "avg_logprob": -0.06645908588316382, "compression_ratio": 1.780373831775701, "no_speech_prob": 0.005876036360859871}, {"id": 176, "seek": 118568, "start": 1193.92, "end": 1199.92, "text": " and you will be driven to compose these operations via their types it can be a bit scary sometimes", "tokens": [50776, 293, 291, 486, 312, 9555, 281, 35925, 613, 7705, 5766, 641, 3467, 309, 393, 312, 257, 857, 6958, 2171, 51076], "temperature": 0.0, "avg_logprob": -0.06645908588316382, "compression_ratio": 1.780373831775701, "no_speech_prob": 0.005876036360859871}, {"id": 177, "seek": 118568, "start": 1199.92, "end": 1206.0, "text": " to think of your business operations as a state machine but it gives us a terminology and a", "tokens": [51076, 281, 519, 295, 428, 1606, 7705, 382, 257, 1785, 3479, 457, 309, 2709, 505, 257, 27575, 293, 257, 51380], "temperature": 0.0, "avg_logprob": -0.06645908588316382, "compression_ratio": 1.780373831775701, "no_speech_prob": 0.005876036360859871}, {"id": 178, "seek": 118568, "start": 1206.0, "end": 1213.92, "text": " literature to take from and to think of how we organize and compose our operations so for example", "tokens": [51380, 10394, 281, 747, 490, 293, 281, 519, 295, 577, 321, 13859, 293, 35925, 527, 7705, 370, 337, 1365, 51776], "temperature": 0.0, "avg_logprob": -0.06645908588316382, "compression_ratio": 1.780373831775701, "no_speech_prob": 0.005876036360859871}, {"id": 179, "seek": 121392, "start": 1213.92, "end": 1220.5600000000002, "text": " here we have a workflow state which can have three values arrival processed and departure", "tokens": [50364, 510, 321, 362, 257, 20993, 1785, 597, 393, 362, 1045, 4190, 18365, 18846, 293, 25866, 50696], "temperature": 0.0, "avg_logprob": -0.0723348211069576, "compression_ratio": 1.881578947368421, "no_speech_prob": 0.001509599736891687}, {"id": 180, "seek": 121392, "start": 1220.5600000000002, "end": 1228.96, "text": " and a workflow that has this state type parameter so we have a new workflow value that creates a", "tokens": [50696, 293, 257, 20993, 300, 575, 341, 1785, 2010, 13075, 370, 321, 362, 257, 777, 20993, 2158, 300, 7829, 257, 51116], "temperature": 0.0, "avg_logprob": -0.0723348211069576, "compression_ratio": 1.881578947368421, "no_speech_prob": 0.001509599736891687}, {"id": 181, "seek": 121392, "start": 1228.96, "end": 1235.92, "text": " workflow w1 and then the process workflow function takes a workflow but not any kind of workflow it", "tokens": [51116, 20993, 261, 16, 293, 550, 264, 1399, 20993, 2445, 2516, 257, 20993, 457, 406, 604, 733, 295, 20993, 309, 51464], "temperature": 0.0, "avg_logprob": -0.0723348211069576, "compression_ratio": 1.881578947368421, "no_speech_prob": 0.001509599736891687}, {"id": 182, "seek": 123592, "start": 1235.92, "end": 1244.4, "text": " has to to be set to arrival it can only take newly arrived workflows and then sets them as", "tokens": [50364, 575, 281, 281, 312, 992, 281, 18365, 309, 393, 787, 747, 15109, 6678, 43461, 293, 550, 6352, 552, 382, 50788], "temperature": 0.0, "avg_logprob": -0.11658813185611014, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.002575804479420185}, {"id": 183, "seek": 123592, "start": 1244.4, "end": 1251.04, "text": " processed again this could be in quotes trivially implemented at the value level with you know", "tokens": [50788, 18846, 797, 341, 727, 312, 294, 19963, 1376, 85, 2270, 12270, 412, 264, 2158, 1496, 365, 291, 458, 51120], "temperature": 0.0, "avg_logprob": -0.11658813185611014, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.002575804479420185}, {"id": 184, "seek": 123592, "start": 1251.76, "end": 1259.76, "text": " properties of the workflow objects and we could very easily verify check these property", "tokens": [51156, 7221, 295, 264, 20993, 6565, 293, 321, 727, 588, 3612, 16888, 1520, 613, 4707, 51556], "temperature": 0.0, "avg_logprob": -0.11658813185611014, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.002575804479420185}, {"id": 185, "seek": 125976, "start": 1259.76, "end": 1266.72, "text": " at in the value level in the code but here I factorize all these checks and I put them really", "tokens": [50364, 412, 294, 264, 2158, 1496, 294, 264, 3089, 457, 510, 286, 5952, 1125, 439, 613, 13834, 293, 286, 829, 552, 534, 50712], "temperature": 0.0, "avg_logprob": -0.08961256812600528, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.004113859962671995}, {"id": 186, "seek": 125976, "start": 1266.72, "end": 1273.52, "text": " at a place where the compiler can guide my hand and tell me where I went wrong with that and", "tokens": [50712, 412, 257, 1081, 689, 264, 31958, 393, 5934, 452, 1011, 293, 980, 385, 689, 286, 1437, 2085, 365, 300, 293, 51052], "temperature": 0.0, "avg_logprob": -0.08961256812600528, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.004113859962671995}, {"id": 187, "seek": 125976, "start": 1273.52, "end": 1280.48, "text": " finally the send back workflow can only take processed workflows by the laws of the types", "tokens": [51052, 2721, 264, 2845, 646, 20993, 393, 787, 747, 18846, 43461, 538, 264, 6064, 295, 264, 3467, 51400], "temperature": 0.0, "avg_logprob": -0.08961256812600528, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.004113859962671995}, {"id": 188, "seek": 125976, "start": 1280.48, "end": 1288.32, "text": " and then sets the workflow as departed so if I compose the functions in the good order so", "tokens": [51400, 293, 550, 6352, 264, 20993, 382, 47018, 370, 498, 286, 35925, 264, 6828, 294, 264, 665, 1668, 370, 51792], "temperature": 0.0, "avg_logprob": -0.08961256812600528, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.004113859962671995}, {"id": 189, "seek": 128832, "start": 1288.32, "end": 1293.84, "text": " new workflow and then you know a pipeline of functions and then I pipe it into process workflow", "tokens": [50364, 777, 20993, 293, 550, 291, 458, 257, 15517, 295, 6828, 293, 550, 286, 11240, 309, 666, 1399, 20993, 50640], "temperature": 0.0, "avg_logprob": -0.06036403633299328, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.0019968191627413034}, {"id": 190, "seek": 128832, "start": 1293.84, "end": 1300.8799999999999, "text": " and send back workflow everything is good if I try to skip a step I will get a compiler error", "tokens": [50640, 293, 2845, 646, 20993, 1203, 307, 665, 498, 286, 853, 281, 10023, 257, 1823, 286, 486, 483, 257, 31958, 6713, 50992], "temperature": 0.0, "avg_logprob": -0.06036403633299328, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.0019968191627413034}, {"id": 191, "seek": 128832, "start": 1300.8799999999999, "end": 1309.6799999999998, "text": " that says you wanted me to take a processed workflow but actually you know I need sorry you", "tokens": [50992, 300, 1619, 291, 1415, 385, 281, 747, 257, 18846, 20993, 457, 767, 291, 458, 286, 643, 2597, 291, 51432], "temperature": 0.0, "avg_logprob": -0.06036403633299328, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.0019968191627413034}, {"id": 192, "seek": 128832, "start": 1309.6799999999998, "end": 1317.04, "text": " wanted me to take an arrival workflow but actually I need the processed workflow and this code you", "tokens": [51432, 1415, 385, 281, 747, 364, 18365, 20993, 457, 767, 286, 643, 264, 18846, 20993, 293, 341, 3089, 291, 51800], "temperature": 0.0, "avg_logprob": -0.06036403633299328, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.0019968191627413034}, {"id": 193, "seek": 131704, "start": 1317.04, "end": 1323.52, "text": " know you're not sending that code to production because you cannot compile this code in terms of", "tokens": [50364, 458, 291, 434, 406, 7750, 300, 3089, 281, 4265, 570, 291, 2644, 31413, 341, 3089, 294, 2115, 295, 50688], "temperature": 0.0, "avg_logprob": -0.16638669200327205, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.00230002636089921}, {"id": 194, "seek": 131704, "start": 1324.1599999999999, "end": 1331.36, "text": " web application development there are also some for us hastalers we like to put everything at the", "tokens": [50720, 3670, 3861, 3250, 456, 366, 611, 512, 337, 505, 6581, 304, 433, 321, 411, 281, 829, 1203, 412, 264, 51080], "temperature": 0.0, "avg_logprob": -0.16638669200327205, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.00230002636089921}, {"id": 195, "seek": 131704, "start": 1331.36, "end": 1336.0, "text": " level of types you know and think of our code as being you know formally proven or code by construction", "tokens": [51080, 1496, 295, 3467, 291, 458, 293, 519, 295, 527, 3089, 382, 885, 291, 458, 25983, 12785, 420, 3089, 538, 6435, 51312], "temperature": 0.0, "avg_logprob": -0.16638669200327205, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.00230002636089921}, {"id": 196, "seek": 131704, "start": 1336.56, "end": 1342.96, "text": " but sometimes you know we must not drink all the cool aid or all the climatic for example database", "tokens": [51340, 457, 2171, 291, 458, 321, 1633, 406, 2822, 439, 264, 1627, 9418, 420, 439, 264, 5644, 2399, 337, 1365, 8149, 51660], "temperature": 0.0, "avg_logprob": -0.16638669200327205, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.00230002636089921}, {"id": 197, "seek": 134296, "start": 1342.96, "end": 1349.92, "text": " layers that promise type safe SQL if you ever find a database layer that promise type safety", "tokens": [50364, 7914, 300, 6228, 2010, 3273, 19200, 498, 291, 1562, 915, 257, 8149, 4583, 300, 6228, 2010, 4514, 50712], "temperature": 0.0, "avg_logprob": -0.08696639537811279, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.003783854888752103}, {"id": 198, "seek": 134296, "start": 1350.88, "end": 1355.44, "text": " either it's the kind of type safety that is trivial to implement and it's totally expected", "tokens": [50760, 2139, 309, 311, 264, 733, 295, 2010, 4514, 300, 307, 26703, 281, 4445, 293, 309, 311, 3879, 5176, 50988], "temperature": 0.0, "avg_logprob": -0.08696639537811279, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.003783854888752103}, {"id": 199, "seek": 134296, "start": 1356.0, "end": 1361.8400000000001, "text": " of the tool to have it or it has encoded the semantics of SQL at the type level and we've", "tokens": [51016, 295, 264, 2290, 281, 362, 309, 420, 309, 575, 2058, 12340, 264, 4361, 45298, 295, 19200, 412, 264, 2010, 1496, 293, 321, 600, 51308], "temperature": 0.0, "avg_logprob": -0.08696639537811279, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.003783854888752103}, {"id": 200, "seek": 134296, "start": 1361.8400000000001, "end": 1367.1200000000001, "text": " either found the golden goose you know or someone who has clearly underestimated the difficulties", "tokens": [51308, 2139, 1352, 264, 9729, 24717, 291, 458, 420, 1580, 567, 575, 4448, 24612, 33008, 264, 14399, 51572], "temperature": 0.0, "avg_logprob": -0.08696639537811279, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.003783854888752103}, {"id": 201, "seek": 136712, "start": 1367.12, "end": 1374.8, "text": " of SQL semantics. Also SQLite for development and PostgreSQL for production that's something that", "tokens": [50364, 295, 19200, 4361, 45298, 13, 2743, 19200, 642, 337, 3250, 293, 10223, 33248, 39934, 337, 4265, 300, 311, 746, 300, 50748], "temperature": 0.0, "avg_logprob": -0.15454802455672298, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.005847092717885971}, {"id": 202, "seek": 136712, "start": 1374.8, "end": 1383.12, "text": " the python community has popularized in the 20s 2000s and 2010s so we can accomplish great things", "tokens": [50748, 264, 38797, 1768, 575, 3743, 1602, 294, 264, 945, 82, 8132, 82, 293, 9657, 82, 370, 321, 393, 9021, 869, 721, 51164], "temperature": 0.0, "avg_logprob": -0.15454802455672298, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.005847092717885971}, {"id": 203, "seek": 136712, "start": 1383.12, "end": 1387.6799999999998, "text": " by lying to the universe but we carefully accomplish anything by lying to ourselves", "tokens": [51164, 538, 8493, 281, 264, 6445, 457, 321, 7500, 9021, 1340, 538, 8493, 281, 4175, 51392], "temperature": 0.0, "avg_logprob": -0.15454802455672298, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.005847092717885971}, {"id": 204, "seek": 136712, "start": 1387.6799999999998, "end": 1395.52, "text": " and SQLite is its own system and unless you somehow perfectly code in the common subset of", "tokens": [51392, 293, 19200, 642, 307, 1080, 1065, 1185, 293, 5969, 291, 6063, 6239, 3089, 294, 264, 2689, 25993, 295, 51784], "temperature": 0.0, "avg_logprob": -0.15454802455672298, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.005847092717885971}, {"id": 205, "seek": 139552, "start": 1395.52, "end": 1401.92, "text": " SQL supported by both implementations you will be maintaining two sets of database migrations", "tokens": [50364, 19200, 8104, 538, 1293, 4445, 763, 291, 486, 312, 14916, 732, 6352, 295, 8149, 6186, 12154, 50684], "temperature": 0.0, "avg_logprob": -0.07209854240877082, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.0012757022632285953}, {"id": 206, "seek": 139552, "start": 1401.92, "end": 1409.04, "text": " and sometimes of code so PostgreSQL has very good features SQLite has difference but also", "tokens": [50684, 293, 2171, 295, 3089, 370, 10223, 33248, 39934, 575, 588, 665, 4122, 19200, 642, 575, 2649, 457, 611, 51040], "temperature": 0.0, "avg_logprob": -0.07209854240877082, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.0012757022632285953}, {"id": 207, "seek": 139552, "start": 1409.04, "end": 1415.68, "text": " good features not its type system of course but if you get used to one locally and then discover", "tokens": [51040, 665, 4122, 406, 1080, 2010, 1185, 295, 1164, 457, 498, 291, 483, 1143, 281, 472, 16143, 293, 550, 4411, 51372], "temperature": 0.0, "avg_logprob": -0.07209854240877082, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.0012757022632285953}, {"id": 208, "seek": 139552, "start": 1415.68, "end": 1421.12, "text": " the second one once you're deployed you're going to have a bad time and also the muscle memory", "tokens": [51372, 264, 1150, 472, 1564, 291, 434, 17826, 291, 434, 516, 281, 362, 257, 1578, 565, 293, 611, 264, 8679, 4675, 51644], "temperature": 0.0, "avg_logprob": -0.07209854240877082, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.0012757022632285953}, {"id": 209, "seek": 142112, "start": 1421.12, "end": 1426.3999999999999, "text": " because brain is a muscle that you will have accumulated with SQLite will be fairly useless", "tokens": [50364, 570, 3567, 307, 257, 8679, 300, 291, 486, 362, 31346, 365, 19200, 642, 486, 312, 6457, 14115, 50628], "temperature": 0.0, "avg_logprob": -0.09359838366508484, "compression_ratio": 1.7652582159624413, "no_speech_prob": 0.0009166738018393517}, {"id": 210, "seek": 142112, "start": 1426.3999999999999, "end": 1433.6, "text": " with PostgreSQL. So where to go from here documentation you produce documentation we have", "tokens": [50628, 365, 10223, 33248, 39934, 13, 407, 689, 281, 352, 490, 510, 14333, 291, 5258, 14333, 321, 362, 50988], "temperature": 0.0, "avg_logprob": -0.09359838366508484, "compression_ratio": 1.7652582159624413, "no_speech_prob": 0.0009166738018393517}, {"id": 211, "seek": 142112, "start": 1433.6, "end": 1440.4799999999998, "text": " many ways of producing documentation and we hold also tremendous power in the types and coupled", "tokens": [50988, 867, 2098, 295, 10501, 14333, 293, 321, 1797, 611, 10048, 1347, 294, 264, 3467, 293, 29482, 51332], "temperature": 0.0, "avg_logprob": -0.09359838366508484, "compression_ratio": 1.7652582159624413, "no_speech_prob": 0.0009166738018393517}, {"id": 212, "seek": 142112, "start": 1440.4799999999998, "end": 1445.6799999999998, "text": " with introspection it means that the algebraic data types like the sem types and the product types", "tokens": [51332, 365, 560, 2635, 19997, 309, 1355, 300, 264, 21989, 299, 1412, 3467, 411, 264, 4361, 3467, 293, 264, 1674, 3467, 51592], "temperature": 0.0, "avg_logprob": -0.09359838366508484, "compression_ratio": 1.7652582159624413, "no_speech_prob": 0.0009166738018393517}, {"id": 213, "seek": 144568, "start": 1445.68, "end": 1451.52, "text": " the product types so the enums and the records they can serve as the backbone for further even", "tokens": [50364, 264, 1674, 3467, 370, 264, 465, 8099, 293, 264, 7724, 436, 393, 4596, 382, 264, 34889, 337, 3052, 754, 50656], "temperature": 0.0, "avg_logprob": -0.1070446221225233, "compression_ratio": 1.778301886792453, "no_speech_prob": 0.006507102865725756}, {"id": 214, "seek": 144568, "start": 1451.52, "end": 1456.5600000000002, "text": " documentation the types themselves are not documentation but they can be used to guide the", "tokens": [50656, 14333, 264, 3467, 2969, 366, 406, 14333, 457, 436, 393, 312, 1143, 281, 5934, 264, 50908], "temperature": 0.0, "avg_logprob": -0.1070446221225233, "compression_ratio": 1.778301886792453, "no_speech_prob": 0.006507102865725756}, {"id": 215, "seek": 144568, "start": 1456.5600000000002, "end": 1463.52, "text": " reader and you remember how I told you to write the tests so the best tests are those that can", "tokens": [50908, 15149, 293, 291, 1604, 577, 286, 1907, 291, 281, 2464, 264, 6921, 370, 264, 1151, 6921, 366, 729, 300, 393, 51256], "temperature": 0.0, "avg_logprob": -0.1070446221225233, "compression_ratio": 1.778301886792453, "no_speech_prob": 0.006507102865725756}, {"id": 216, "seek": 144568, "start": 1463.52, "end": 1472.4, "text": " describe real-world behaviors and if you can even produce you know a summary web page that shows", "tokens": [51256, 6786, 957, 12, 13217, 15501, 293, 498, 291, 393, 754, 5258, 291, 458, 257, 12691, 3670, 3028, 300, 3110, 51700], "temperature": 0.0, "avg_logprob": -0.1070446221225233, "compression_ratio": 1.778301886792453, "no_speech_prob": 0.006507102865725756}, {"id": 217, "seek": 147240, "start": 1472.4, "end": 1478.64, "text": " the behaviors and the high-level paths taken by your program according to some input this is very", "tokens": [50364, 264, 15501, 293, 264, 1090, 12, 12418, 14518, 2726, 538, 428, 1461, 4650, 281, 512, 4846, 341, 307, 588, 50676], "temperature": 0.0, "avg_logprob": -0.08278095154535203, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.003903115401044488}, {"id": 218, "seek": 147240, "start": 1478.64, "end": 1484.96, "text": " particularly helpful for less technical people like product managers who want to know the behavior", "tokens": [50676, 4098, 4961, 337, 1570, 6191, 561, 411, 1674, 14084, 567, 528, 281, 458, 264, 5223, 50992], "temperature": 0.0, "avg_logprob": -0.08278095154535203, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.003903115401044488}, {"id": 219, "seek": 147240, "start": 1484.96, "end": 1490.5600000000002, "text": " of your program if you can present a nice interface of how the code is executed according to some", "tokens": [50992, 295, 428, 1461, 498, 291, 393, 1974, 257, 1481, 9226, 295, 577, 264, 3089, 307, 17577, 4650, 281, 512, 51272], "temperature": 0.0, "avg_logprob": -0.08278095154535203, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.003903115401044488}, {"id": 220, "seek": 147240, "start": 1490.5600000000002, "end": 1499.52, "text": " high-level business you know operation it's even better. So I have a couple of sources for what", "tokens": [51272, 1090, 12, 12418, 1606, 291, 458, 6916, 309, 311, 754, 1101, 13, 407, 286, 362, 257, 1916, 295, 7139, 337, 437, 51720], "temperature": 0.0, "avg_logprob": -0.08278095154535203, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.003903115401044488}, {"id": 221, "seek": 149952, "start": 1499.52, "end": 1505.04, "text": " I'm saying I'm not pulling that out of my arse the first one is domain modeling made functional", "tokens": [50364, 286, 478, 1566, 286, 478, 406, 8407, 300, 484, 295, 452, 594, 405, 264, 700, 472, 307, 9274, 15983, 1027, 11745, 50640], "temperature": 0.0, "avg_logprob": -0.19291783383018093, "compression_ratio": 1.6778242677824269, "no_speech_prob": 0.022368086501955986}, {"id": 222, "seek": 149952, "start": 1505.04, "end": 1512.48, "text": " by Scott Vlaschen it's an excellent book written in F-sharp for the functional and DDD practitioners", "tokens": [50640, 538, 6659, 691, 7743, 2470, 309, 311, 364, 7103, 1446, 3720, 294, 479, 12, 2716, 6529, 337, 264, 11745, 293, 413, 20818, 25742, 51012], "temperature": 0.0, "avg_logprob": -0.19291783383018093, "compression_ratio": 1.6778242677824269, "no_speech_prob": 0.022368086501955986}, {"id": 223, "seek": 149952, "start": 1513.04, "end": 1519.84, "text": " it's excellent I encourage you to read it as well as living documentation by Cyril Maertere and that", "tokens": [51040, 309, 311, 7103, 286, 5373, 291, 281, 1401, 309, 382, 731, 382, 2647, 14333, 538, 33146, 388, 4042, 911, 323, 293, 300, 51380], "temperature": 0.0, "avg_logprob": -0.19291783383018093, "compression_ratio": 1.6778242677824269, "no_speech_prob": 0.022368086501955986}, {"id": 224, "seek": 149952, "start": 1519.84, "end": 1526.8799999999999, "text": " one is also excellent really it puts the documentation as its own living system that for which you will", "tokens": [51380, 472, 307, 611, 7103, 534, 309, 8137, 264, 14333, 382, 1080, 1065, 2647, 1185, 300, 337, 597, 291, 486, 51732], "temperature": 0.0, "avg_logprob": -0.19291783383018093, "compression_ratio": 1.6778242677824269, "no_speech_prob": 0.022368086501955986}, {"id": 225, "seek": 152688, "start": 1526.96, "end": 1532.64, "text": " have real clients because you know PMs and other engineers in your organization or consumers of", "tokens": [50368, 362, 957, 6982, 570, 291, 458, 12499, 82, 293, 661, 11955, 294, 428, 4475, 420, 11883, 295, 50652], "temperature": 0.0, "avg_logprob": -0.1580499013264974, "compression_ratio": 1.4846938775510203, "no_speech_prob": 0.004633834585547447}, {"id": 226, "seek": 152688, "start": 1532.64, "end": 1539.68, "text": " documentation and of course here's amounts of caffeine as Fraser told earlier so that would be", "tokens": [50652, 14333, 293, 295, 1164, 510, 311, 11663, 295, 31261, 382, 49119, 1907, 3071, 370, 300, 576, 312, 51004], "temperature": 0.0, "avg_logprob": -0.1580499013264974, "compression_ratio": 1.4846938775510203, "no_speech_prob": 0.004633834585547447}, {"id": 227, "seek": 152688, "start": 1539.68, "end": 1552.72, "text": " the end of my talk. Do we have a couple of minutes for questions perhaps? Yes thank you Akate and we", "tokens": [51004, 264, 917, 295, 452, 751, 13, 1144, 321, 362, 257, 1916, 295, 2077, 337, 1651, 4317, 30, 1079, 1309, 291, 9629, 473, 293, 321, 51656], "temperature": 0.0, "avg_logprob": -0.1580499013264974, "compression_ratio": 1.4846938775510203, "no_speech_prob": 0.004633834585547447}, {"id": 228, "seek": 155272, "start": 1552.72, "end": 1563.84, "text": " do have about 10 minutes for questions. Yes Youngman there. This is this is on this is more of a", "tokens": [50364, 360, 362, 466, 1266, 2077, 337, 1651, 13, 1079, 8160, 1601, 456, 13, 639, 307, 341, 307, 322, 341, 307, 544, 295, 257, 50920], "temperature": 0.0, "avg_logprob": -0.13946910699208578, "compression_ratio": 1.6174863387978142, "no_speech_prob": 0.009363259188830853}, {"id": 229, "seek": 155272, "start": 1563.84, "end": 1573.3600000000001, "text": " comment than a question. So one little detail that I think that sort of you could have sold also right", "tokens": [50920, 2871, 813, 257, 1168, 13, 407, 472, 707, 2607, 300, 286, 519, 300, 1333, 295, 291, 727, 362, 3718, 611, 558, 51396], "temperature": 0.0, "avg_logprob": -0.13946910699208578, "compression_ratio": 1.6174863387978142, "no_speech_prob": 0.009363259188830853}, {"id": 230, "seek": 155272, "start": 1573.3600000000001, "end": 1580.72, "text": " is the fact that when you do this when you do the data kind annotation on your workflow you know", "tokens": [51396, 307, 264, 1186, 300, 562, 291, 360, 341, 562, 291, 360, 264, 1412, 733, 48654, 322, 428, 20993, 291, 458, 51764], "temperature": 0.0, "avg_logprob": -0.13946910699208578, "compression_ratio": 1.6174863387978142, "no_speech_prob": 0.009363259188830853}, {"id": 231, "seek": 158072, "start": 1580.72, "end": 1586.0, "text": " instead of you know checking that during runtime we do the type annotation and that's actually", "tokens": [50364, 2602, 295, 291, 458, 8568, 300, 1830, 34474, 321, 360, 264, 2010, 48654, 293, 300, 311, 767, 50628], "temperature": 0.0, "avg_logprob": -0.0739600317818778, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0032948816660791636}, {"id": 232, "seek": 158072, "start": 1586.0, "end": 1591.52, "text": " more efficient right because because of type erasure that there's no runtime data or check", "tokens": [50628, 544, 7148, 558, 570, 570, 295, 2010, 1189, 2508, 300, 456, 311, 572, 34474, 1412, 420, 1520, 50904], "temperature": 0.0, "avg_logprob": -0.0739600317818778, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0032948816660791636}, {"id": 233, "seek": 158072, "start": 1591.52, "end": 1597.44, "text": " that has to happen right. Yes so what Bj\u00f6rn says is that indeed there is a matter of efficiency", "tokens": [50904, 300, 575, 281, 1051, 558, 13, 1079, 370, 437, 49660, 2311, 77, 1619, 307, 300, 6451, 456, 307, 257, 1871, 295, 10493, 51200], "temperature": 0.0, "avg_logprob": -0.0739600317818778, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0032948816660791636}, {"id": 234, "seek": 158072, "start": 1597.44, "end": 1604.88, "text": " because the data kinds when we encode you know the nature of parameters in our workflow these", "tokens": [51200, 570, 264, 1412, 3685, 562, 321, 2058, 1429, 291, 458, 264, 3687, 295, 9834, 294, 527, 20993, 613, 51572], "temperature": 0.0, "avg_logprob": -0.0739600317818778, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0032948816660791636}, {"id": 235, "seek": 160488, "start": 1604.88, "end": 1614.24, "text": " all goes away at code generation so you if you are in a setup where you need some you know very", "tokens": [50364, 439, 1709, 1314, 412, 3089, 5125, 370, 291, 498, 291, 366, 294, 257, 8657, 689, 291, 643, 512, 291, 458, 588, 50832], "temperature": 0.0, "avg_logprob": -0.1646031476138683, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0008724457584321499}, {"id": 236, "seek": 160488, "start": 1614.24, "end": 1618.72, "text": " minimal code that is being generated if you are in tight loop for example this code is completely", "tokens": [50832, 13206, 3089, 300, 307, 885, 10833, 498, 291, 366, 294, 4524, 6367, 337, 1365, 341, 3089, 307, 2584, 51056], "temperature": 0.0, "avg_logprob": -0.1646031476138683, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0008724457584321499}, {"id": 237, "seek": 160488, "start": 1618.72, "end": 1624.0, "text": " raised at the level at the time of code generation and indeed you you spread some CPU cycles.", "tokens": [51056, 6005, 412, 264, 1496, 412, 264, 565, 295, 3089, 5125, 293, 6451, 291, 291, 3974, 512, 13199, 17796, 13, 51320], "temperature": 0.0, "avg_logprob": -0.1646031476138683, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0008724457584321499}, {"id": 238, "seek": 160488, "start": 1626.5600000000002, "end": 1631.92, "text": " Any other question? You can also call me out on my bullshit. I won't be offended. Yes", "tokens": [51448, 2639, 661, 1168, 30, 509, 393, 611, 818, 385, 484, 322, 452, 22676, 13, 286, 1582, 380, 312, 26776, 13, 1079, 51716], "temperature": 0.0, "avg_logprob": -0.1646031476138683, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0008724457584321499}, {"id": 239, "seek": 163192, "start": 1632.16, "end": 1635.3600000000001, "text": " Do I need a mic or am I? I can repeat your question.", "tokens": [50376, 1144, 286, 643, 257, 3123, 420, 669, 286, 30, 286, 393, 7149, 428, 1168, 13, 50536], "temperature": 0.0, "avg_logprob": -0.25138369473544037, "compression_ratio": 1.5412844036697249, "no_speech_prob": 0.00554553372785449}, {"id": 240, "seek": 163192, "start": 1637.92, "end": 1647.28, "text": " The libraries that offer type safe database access that are I'm sure hideously incomplete also offer", "tokens": [50664, 440, 15148, 300, 2626, 2010, 3273, 8149, 2105, 300, 366, 286, 478, 988, 6479, 5098, 31709, 611, 2626, 51132], "temperature": 0.0, "avg_logprob": -0.25138369473544037, "compression_ratio": 1.5412844036697249, "no_speech_prob": 0.00554553372785449}, {"id": 241, "seek": 163192, "start": 1647.92, "end": 1653.92, "text": " abstraction over different database backends which is one of the problems you were talking about", "tokens": [51164, 37765, 670, 819, 8149, 646, 2581, 597, 307, 472, 295, 264, 2740, 291, 645, 1417, 466, 51464], "temperature": 0.0, "avg_logprob": -0.25138369473544037, "compression_ratio": 1.5412844036697249, "no_speech_prob": 0.00554553372785449}, {"id": 242, "seek": 163192, "start": 1653.92, "end": 1659.6000000000001, "text": " like why you're using Postgres to develop locally. So my question is are there really", "tokens": [51464, 411, 983, 291, 434, 1228, 10223, 45189, 281, 1499, 16143, 13, 407, 452, 1168, 307, 366, 456, 534, 51748], "temperature": 0.0, "avg_logprob": -0.25138369473544037, "compression_ratio": 1.5412844036697249, "no_speech_prob": 0.00554553372785449}, {"id": 243, "seek": 165960, "start": 1659.6, "end": 1666.3999999999999, "text": " situations for Flora PM where those libraries didn't provide a feature that you needed? Yes so the", "tokens": [50364, 6851, 337, 3235, 3252, 12499, 689, 729, 15148, 994, 380, 2893, 257, 4111, 300, 291, 2978, 30, 1079, 370, 264, 50704], "temperature": 0.0, "avg_logprob": -0.146892811878618, "compression_ratio": 1.6798029556650247, "no_speech_prob": 0.0023794015869498253}, {"id": 244, "seek": 165960, "start": 1666.3999999999999, "end": 1673.52, "text": " question is those libraries that encode you know all of the semantics of SQL at the type level", "tokens": [50704, 1168, 307, 729, 15148, 300, 2058, 1429, 291, 458, 439, 295, 264, 4361, 45298, 295, 19200, 412, 264, 2010, 1496, 51060], "temperature": 0.0, "avg_logprob": -0.146892811878618, "compression_ratio": 1.6798029556650247, "no_speech_prob": 0.0023794015869498253}, {"id": 245, "seek": 165960, "start": 1674.8, "end": 1679.52, "text": " are there situations where they don't provide features that I would need for Flora PM? Yes", "tokens": [51124, 366, 456, 6851, 689, 436, 500, 380, 2893, 4122, 300, 286, 576, 643, 337, 3235, 3252, 12499, 30, 1079, 51360], "temperature": 0.0, "avg_logprob": -0.146892811878618, "compression_ratio": 1.6798029556650247, "no_speech_prob": 0.0023794015869498253}, {"id": 246, "seek": 165960, "start": 1680.1599999999999, "end": 1684.6399999999999, "text": " so as I told earlier I'm very preoccupied by ergonomics.", "tokens": [51392, 370, 382, 286, 1907, 3071, 286, 478, 588, 44388, 1091, 538, 42735, 29884, 13, 51616], "temperature": 0.0, "avg_logprob": -0.146892811878618, "compression_ratio": 1.6798029556650247, "no_speech_prob": 0.0023794015869498253}, {"id": 247, "seek": 168464, "start": 1685.6000000000001, "end": 1692.8000000000002, "text": " 20 minutes of compilation time and you know 20 gigabytes of half interface files on disk", "tokens": [50412, 945, 2077, 295, 40261, 565, 293, 291, 458, 945, 42741, 295, 1922, 9226, 7098, 322, 12355, 50772], "temperature": 0.0, "avg_logprob": -0.16073281235165066, "compression_ratio": 1.4912280701754386, "no_speech_prob": 0.006443515419960022}, {"id": 248, "seek": 168464, "start": 1693.5200000000002, "end": 1698.4, "text": " I would consider that a problem in terms of feedback loop for contributors.", "tokens": [50808, 286, 576, 1949, 300, 257, 1154, 294, 2115, 295, 5824, 6367, 337, 45627, 13, 51052], "temperature": 0.0, "avg_logprob": -0.16073281235165066, "compression_ratio": 1.4912280701754386, "no_speech_prob": 0.006443515419960022}, {"id": 249, "seek": 168464, "start": 1699.5200000000002, "end": 1706.0, "text": " My previous place of employment we used the toolkit squeal for type level encoded SQL queries", "tokens": [51108, 1222, 3894, 1081, 295, 11949, 321, 1143, 264, 40167, 8447, 304, 337, 2010, 1496, 2058, 12340, 19200, 24109, 51432], "temperature": 0.0, "avg_logprob": -0.16073281235165066, "compression_ratio": 1.4912280701754386, "no_speech_prob": 0.006443515419960022}, {"id": 250, "seek": 168464, "start": 1706.96, "end": 1712.0800000000002, "text": " because they were business critical so we wanted to invest in something very much", "tokens": [51480, 570, 436, 645, 1606, 4924, 370, 321, 1415, 281, 1963, 294, 746, 588, 709, 51736], "temperature": 0.0, "avg_logprob": -0.16073281235165066, "compression_ratio": 1.4912280701754386, "no_speech_prob": 0.006443515419960022}, {"id": 251, "seek": 171208, "start": 1712.08, "end": 1718.8, "text": " type safe because of the critical aspects of these queries. It was hell, it was horrendous,", "tokens": [50364, 2010, 3273, 570, 295, 264, 4924, 7270, 295, 613, 24109, 13, 467, 390, 4921, 11, 309, 390, 49520, 563, 11, 50700], "temperature": 0.0, "avg_logprob": -0.13994672686554666, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.004600126761943102}, {"id": 252, "seek": 171208, "start": 1718.8, "end": 1725.84, "text": " it was not only to view and to review but also because it took so much time to compile like", "tokens": [50700, 309, 390, 406, 787, 281, 1910, 293, 281, 3131, 457, 611, 570, 309, 1890, 370, 709, 565, 281, 31413, 411, 51052], "temperature": 0.0, "avg_logprob": -0.13994672686554666, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.004600126761943102}, {"id": 253, "seek": 171208, "start": 1725.84, "end": 1733.52, "text": " unironically 20 minutes and we had some problems with stack because the interface files on this", "tokens": [51052, 517, 2088, 984, 945, 2077, 293, 321, 632, 512, 2740, 365, 8630, 570, 264, 9226, 7098, 322, 341, 51436], "temperature": 0.0, "avg_logprob": -0.13994672686554666, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.004600126761943102}, {"id": 254, "seek": 171208, "start": 1733.52, "end": 1741.1999999999998, "text": " were taking way too much space. Type families in Haskell are best consumed with you know", "tokens": [51436, 645, 1940, 636, 886, 709, 1901, 13, 15576, 4466, 294, 8646, 43723, 366, 1151, 21226, 365, 291, 458, 51820], "temperature": 0.0, "avg_logprob": -0.13994672686554666, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.004600126761943102}, {"id": 255, "seek": 174120, "start": 1741.28, "end": 1748.32, "text": " responsibly and I'm a servants user so you know I can't you know shit too much on type families", "tokens": [50368, 2914, 3545, 293, 286, 478, 257, 21705, 4195, 370, 291, 458, 286, 393, 380, 291, 458, 4611, 886, 709, 322, 2010, 4466, 50720], "temperature": 0.0, "avg_logprob": -0.16019517248803442, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.006307324860244989}, {"id": 256, "seek": 174120, "start": 1748.32, "end": 1754.0, "text": " but in some cases very specific cases is best to rely on the expertise of outside systems.", "tokens": [50720, 457, 294, 512, 3331, 588, 2685, 3331, 307, 1151, 281, 10687, 322, 264, 11769, 295, 2380, 3652, 13, 51004], "temperature": 0.0, "avg_logprob": -0.16019517248803442, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.006307324860244989}, {"id": 257, "seek": 174120, "start": 1754.56, "end": 1760.48, "text": " For example my best friend who's here actually in FOSDEM is my database administrator at work", "tokens": [51032, 1171, 1365, 452, 1151, 1277, 567, 311, 510, 767, 294, 479, 4367, 35, 6683, 307, 452, 8149, 25529, 412, 589, 51328], "temperature": 0.0, "avg_logprob": -0.16019517248803442, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.006307324860244989}, {"id": 258, "seek": 174120, "start": 1761.76, "end": 1769.2, "text": " and you know I keep him close you know. Do you ever have experience to need on board like a", "tokens": [51392, 293, 291, 458, 286, 1066, 796, 1998, 291, 458, 13, 1144, 291, 1562, 362, 1752, 281, 643, 322, 3150, 411, 257, 51764], "temperature": 0.0, "avg_logprob": -0.16019517248803442, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.006307324860244989}, {"id": 259, "seek": 176920, "start": 1769.2, "end": 1775.68, "text": " newer developer that to maintain or even do new feature to the project if so what's the", "tokens": [50364, 17628, 10754, 300, 281, 6909, 420, 754, 360, 777, 4111, 281, 264, 1716, 498, 370, 437, 311, 264, 50688], "temperature": 0.0, "avg_logprob": -0.17268392418612952, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.015514901839196682}, {"id": 260, "seek": 176920, "start": 1775.68, "end": 1779.1200000000001, "text": " experience especially if they don't have any Haskell experience or especially this kind of", "tokens": [50688, 1752, 2318, 498, 436, 500, 380, 362, 604, 8646, 43723, 1752, 420, 2318, 341, 733, 295, 50860], "temperature": 0.0, "avg_logprob": -0.17268392418612952, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.015514901839196682}, {"id": 261, "seek": 176920, "start": 1779.1200000000001, "end": 1783.1200000000001, "text": " yes very good question do we have any experience on boarding new developers on the project", "tokens": [50860, 2086, 588, 665, 1168, 360, 321, 362, 604, 1752, 322, 30528, 777, 8849, 322, 264, 1716, 51060], "temperature": 0.0, "avg_logprob": -0.17268392418612952, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.015514901839196682}, {"id": 262, "seek": 176920, "start": 1783.1200000000001, "end": 1787.92, "text": " actually with this this talk was supposed to be the continuation of the different on boarding", "tokens": [51060, 767, 365, 341, 341, 751, 390, 3442, 281, 312, 264, 29357, 295, 264, 819, 322, 30528, 51300], "temperature": 0.0, "avg_logprob": -0.17268392418612952, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.015514901839196682}, {"id": 263, "seek": 176920, "start": 1787.92, "end": 1793.8400000000001, "text": " sessions rather than on floor at the pm so sometimes if you find me on discord or matrix", "tokens": [51300, 11081, 2831, 813, 322, 4123, 412, 264, 23023, 370, 2171, 498, 291, 915, 385, 322, 32989, 420, 8141, 51596], "temperature": 0.0, "avg_logprob": -0.17268392418612952, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.015514901839196682}, {"id": 264, "seek": 176920, "start": 1793.8400000000001, "end": 1798.8, "text": " I will share my screen and introduce people to the codebase and I think that's one of the most", "tokens": [51596, 286, 486, 2073, 452, 2568, 293, 5366, 561, 281, 264, 3089, 17429, 293, 286, 519, 300, 311, 472, 295, 264, 881, 51844], "temperature": 0.0, "avg_logprob": -0.17268392418612952, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.015514901839196682}, {"id": 265, "seek": 179880, "start": 1798.8799999999999, "end": 1805.52, "text": " important aspects of flora as a project not only it is a community tool that has you know", "tokens": [50368, 1021, 7270, 295, 932, 3252, 382, 257, 1716, 406, 787, 309, 307, 257, 1768, 2290, 300, 575, 291, 458, 50700], "temperature": 0.0, "avg_logprob": -0.1007830642518543, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.002840758068487048}, {"id": 266, "seek": 179880, "start": 1805.52, "end": 1812.08, "text": " aims to satisfy the users but also it's a vessel for teaching so I have got many tech techniques", "tokens": [50700, 24683, 281, 19319, 264, 5022, 457, 611, 309, 311, 257, 18098, 337, 4571, 370, 286, 362, 658, 867, 7553, 7512, 51028], "temperature": 0.0, "avg_logprob": -0.1007830642518543, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.002840758068487048}, {"id": 267, "seek": 179880, "start": 1812.08, "end": 1817.9199999999998, "text": " that I explained in this talk implementing flora and flora is my the factor codebase", "tokens": [51028, 300, 286, 8825, 294, 341, 751, 18114, 932, 3252, 293, 932, 3252, 307, 452, 264, 5952, 3089, 17429, 51320], "temperature": 0.0, "avg_logprob": -0.1007830642518543, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.002840758068487048}, {"id": 268, "seek": 179880, "start": 1817.9199999999998, "end": 1824.72, "text": " to teach these techniques and I had very bad you know experience with community tools that have", "tokens": [51320, 281, 2924, 613, 7512, 293, 286, 632, 588, 1578, 291, 458, 1752, 365, 1768, 3873, 300, 362, 51660], "temperature": 0.0, "avg_logprob": -0.1007830642518543, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.002840758068487048}, {"id": 269, "seek": 182472, "start": 1824.72, "end": 1831.44, "text": " badly aged and the code is only known by you know the 10% of maintainers that stick around", "tokens": [50364, 13425, 21213, 293, 264, 3089, 307, 787, 2570, 538, 291, 458, 264, 1266, 4, 295, 6909, 433, 300, 2897, 926, 50700], "temperature": 0.0, "avg_logprob": -0.048210944252452634, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.008465862832963467}, {"id": 270, "seek": 182472, "start": 1832.56, "end": 1839.28, "text": " even if the majority the vast majority of contributors of a project or the 90% of people", "tokens": [50756, 754, 498, 264, 6286, 264, 8369, 6286, 295, 45627, 295, 257, 1716, 420, 264, 4289, 4, 295, 561, 51092], "temperature": 0.0, "avg_logprob": -0.048210944252452634, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.008465862832963467}, {"id": 271, "seek": 182472, "start": 1839.28, "end": 1844.96, "text": " who just make one pull request and then go away forever so it's very hard to retain institutional", "tokens": [51092, 567, 445, 652, 472, 2235, 5308, 293, 550, 352, 1314, 5680, 370, 309, 311, 588, 1152, 281, 18340, 18391, 51376], "temperature": 0.0, "avg_logprob": -0.048210944252452634, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.008465862832963467}, {"id": 272, "seek": 182472, "start": 1844.96, "end": 1852.88, "text": " knowledge and also is very hard not to aim to please the 10% of people who stick around and", "tokens": [51376, 3601, 293, 611, 307, 588, 1152, 406, 281, 5939, 281, 1767, 264, 1266, 4, 295, 561, 567, 2897, 926, 293, 51772], "temperature": 0.0, "avg_logprob": -0.048210944252452634, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.008465862832963467}, {"id": 273, "seek": 185288, "start": 1852.88, "end": 1860.64, "text": " submit patches you know on the regular so yes I would think that and that's the goal of flora", "tokens": [50364, 10315, 26531, 291, 458, 322, 264, 3890, 370, 2086, 286, 576, 519, 300, 293, 300, 311, 264, 3387, 295, 932, 3252, 50752], "temperature": 0.0, "avg_logprob": -0.22341719989118905, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0018051071092486382}, {"id": 274, "seek": 185288, "start": 1860.64, "end": 1865.7600000000002, "text": " onboarding new contributors easily is actually a feature and if it can't be done anymore it's a bug", "tokens": [50752, 24033, 278, 777, 45627, 3612, 307, 767, 257, 4111, 293, 498, 309, 393, 380, 312, 1096, 3602, 309, 311, 257, 7426, 51008], "temperature": 0.0, "avg_logprob": -0.22341719989118905, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0018051071092486382}, {"id": 275, "seek": 185288, "start": 1869.6000000000001, "end": 1872.64, "text": " any other question nope", "tokens": [51200, 604, 661, 1168, 23444, 51352], "temperature": 0.0, "avg_logprob": -0.22341719989118905, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0018051071092486382}, {"id": 276, "seek": 185288, "start": 1874.0800000000002, "end": 1874.8000000000002, "text": " oh sure", "tokens": [51424, 1954, 988, 51460], "temperature": 0.0, "avg_logprob": -0.22341719989118905, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0018051071092486382}, {"id": 277, "seek": 187480, "start": 1875.52, "end": 1880.72, "text": " such a representation is it possible to write a function that say generate a diagram", "tokens": [50400, 1270, 257, 10290, 307, 309, 1944, 281, 2464, 257, 2445, 300, 584, 8460, 257, 10686, 50660], "temperature": 0.0, "avg_logprob": -0.13437862885303986, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.006015520542860031}, {"id": 278, "seek": 187480, "start": 1883.04, "end": 1890.32, "text": " it technically is I have references for you so the question is can we generate diagrams", "tokens": [50776, 309, 12120, 307, 286, 362, 15400, 337, 291, 370, 264, 1168, 307, 393, 321, 8460, 36709, 51140], "temperature": 0.0, "avg_logprob": -0.13437862885303986, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.006015520542860031}, {"id": 279, "seek": 187480, "start": 1890.32, "end": 1895.9199999999998, "text": " from such representations because indeed we have the possible values that we have at a type level", "tokens": [51140, 490, 1270, 33358, 570, 6451, 321, 362, 264, 1944, 4190, 300, 321, 362, 412, 257, 2010, 1496, 51420], "temperature": 0.0, "avg_logprob": -0.13437862885303986, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.006015520542860031}, {"id": 280, "seek": 187480, "start": 1895.9199999999998, "end": 1901.12, "text": " and we can do many things with our types including inspecting them so yes I believe there are several", "tokens": [51420, 293, 321, 393, 360, 867, 721, 365, 527, 3467, 3009, 15018, 278, 552, 370, 2086, 286, 1697, 456, 366, 2940, 51680], "temperature": 0.0, "avg_logprob": -0.13437862885303986, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.006015520542860031}, {"id": 281, "seek": 190112, "start": 1902.08, "end": 1907.9199999999998, "text": " libraries on hackage that aim to for example provenance it's a library that gives you the", "tokens": [50412, 15148, 322, 10339, 609, 300, 5939, 281, 337, 1365, 12785, 719, 309, 311, 257, 6405, 300, 2709, 291, 264, 50704], "temperature": 0.0, "avg_logprob": -0.14581844105440028, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0014540499541908503}, {"id": 282, "seek": 190112, "start": 1908.8, "end": 1913.4399999999998, "text": " the path that the data takes and the provenance of your data throughout the code", "tokens": [50748, 264, 3100, 300, 264, 1412, 2516, 293, 264, 12785, 719, 295, 428, 1412, 3710, 264, 3089, 50980], "temperature": 0.0, "avg_logprob": -0.14581844105440028, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0014540499541908503}, {"id": 283, "seek": 190112, "start": 1915.12, "end": 1922.1599999999999, "text": " I would say it's the it's one of the the greatest thing to be able to do is to represent your code", "tokens": [51064, 286, 576, 584, 309, 311, 264, 309, 311, 472, 295, 264, 264, 6636, 551, 281, 312, 1075, 281, 360, 307, 281, 2906, 428, 3089, 51416], "temperature": 0.0, "avg_logprob": -0.14581844105440028, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0014540499541908503}, {"id": 284, "seek": 190112, "start": 1922.1599999999999, "end": 1928.32, "text": " and to extract facts and movements from your code in a higher you know level representation", "tokens": [51416, 293, 281, 8947, 9130, 293, 9981, 490, 428, 3089, 294, 257, 2946, 291, 458, 1496, 10290, 51724], "temperature": 0.0, "avg_logprob": -0.14581844105440028, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0014540499541908503}, {"id": 285, "seek": 192832, "start": 1928.48, "end": 1934.8799999999999, "text": " so yeah I believe we can do it today I don't do it personally I think it's possible", "tokens": [50372, 370, 1338, 286, 1697, 321, 393, 360, 309, 965, 286, 500, 380, 360, 309, 5665, 286, 519, 309, 311, 1944, 50692], "temperature": 0.0, "avg_logprob": -0.20801961617391618, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.001885350444354117}, {"id": 286, "seek": 192832, "start": 1939.4399999999998, "end": 1944.96, "text": " there's time for more questions or you can like duel me if you want to challenge my beliefs", "tokens": [50920, 456, 311, 565, 337, 544, 1651, 420, 291, 393, 411, 36296, 385, 498, 291, 528, 281, 3430, 452, 13585, 51196], "temperature": 0.0, "avg_logprob": -0.20801961617391618, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.001885350444354117}, {"id": 287, "seek": 192832, "start": 1949.52, "end": 1957.84, "text": " okay that seems like it so thank you again Ikate thank you very much", "tokens": [51424, 1392, 300, 2544, 411, 309, 370, 1309, 291, 797, 8316, 473, 1309, 291, 588, 709, 51840], "temperature": 0.0, "avg_logprob": -0.20801961617391618, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.001885350444354117}, {"id": 288, "seek": 195832, "start": 1958.32, "end": 1958.82, "text": " you", "tokens": [50364, 291, 50389], "temperature": 0.0, "avg_logprob": -0.7925100326538086, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.3895651400089264}], "language": "en"}