{"text": " So, hello everyone, pleasure to be here. I'm Ithamar Holder and I'm a senior software engineer working for Red Hat. And this is a talk about the journey through supporting VMs with dedicated CPUs and Kubernetes. And the reason that there's a journey word in the subject is that this was a true journey for me. And I'm going to guide you through the journey until we reach the actual problems and solutions. And there are two reasons for that. So first reason is that we need to understand the problems and solutions. So we need to understand the background for it. But the second reason is that I've gained a lot of insights and takeaways during that journey. And I think that I hope that you could find is also valuable for your journeys. And yeah, that you can take the same takeaways for whatever you're doing and whatever you're interested in. So we're going to talk about all sorts of stuff like dedicated CPUs and CPU manager, C groups, spot isolation and namespaces, Kubernetes resource allocation. And so let's begin. So first of all, an introduction to Kuber. So Kubernetes is designed to run containers, which are designed very differently than VMs. And running VMs on one platform and containers on another platform is not the best approach. And this is where Kuber comes into play. This is basically an add-on or extension to Kubernetes, which lets you run VMs on top of Kubernetes as a first-class citizen, as a completely cloud native. And I'm not going to dive into all the architectural details here, but the trick is basically to run a VM within a container, like this picture tries to illustrate. And that's basically what you need to know for this talk. So what's the deal with dedicated CPUs? So basically, the key word here is avoiding preemption or context switches, right? These are crucial, this is crucial for certain use cases like real-time VMs or VMs that depend on very low latency. So as a naive example, let's think about a VM that hot loops over some condition. And when this condition becomes true, it has to react really, really fast. So if we context switch this workload out, then it would take more time. Because once the condition becomes true, it would take time to context switch back, and only then the VM could react. So this is very crucial for some use cases. Also it's supported by most hyper-hypervisors, and it's a pretty standard feature. And we aim to bring this also to Kubernetes. So a question to the crowd. Who recognizes this section? Who knows what this is? Okay, so most of you. And another question, who can say that he's confident about how this is implemented behind the scenes, or how Kubernetes actually does that? A lot less of you, right? So that's good, it means that this is relevant, right? So obviously, this is taken from the pods manifest. This is the place when we specify resources. We have, of course, requests and limits. We can specify CPU, memory, a firmware storage, and a bunch of other stuff. And so let's talk about containers for a second. So containers are actually a conceptual concept that can be implemented in many ways. So from the Linux kernel perspective, there isn't such a thing as a container, really. There are basically a couple of main kernel features that serve as the building blocks for containers. One of them is C groups. C groups is very important, and is one of the main building blocks for containers. So let's talk about C groups a bit. So basically, the idea is that the architecture is a tree of resources, right? We have the root C group, which is basically all of the resources on the node. So for example, 100 CPUs. And then we divide them into groups, like for example, 70 CPUs, 20 CPUs, 10 CPUs, and so on. The idea is that every process on the system is attached to a C group. And that basically the C groups limits the resources for this group of processes. And in Kubernetes, there is usually one C group per container. This actually depends on the CRI that you're using. But the most common approach is to use one C group per container. So in Kubernetes, all of the values are always absolute, right? When we specify CPU, for example, we can specify 100M, which stands for milli-CPUs, which is similar to 0.1 CPUs, 1.3, whatever, but these are always absolute values. In C groups, it's all relative, right? It's called CPU shares. The default is 1024, but it doesn't really matter. So if we'll look on a very naive example again, let's say that we have a node with two pods running on the system, pod A and pod B. And let's say that pod A has one CPU share and pod B has two CPU shares. What it would mean is that pod B would have twice as CPU time as pod A. It doesn't really matter how many CPUs the nodes have, because this is all relative, right? So how does Kubernetes convert between the absolute values and the relative shares? So we can think about one CPU as 1024 shares, just because it's the default in C groups. So let's say that a pod asks for 200M CPUs. So this is actually a fifth of a CPU. So what we can do is divide 1024 by 5 and we get approximately 205 shares. And this would work, but remember that shares are still relative. So what happens, for example, if the node has 100 CPUs and one pod with 200M CPUs request runs on that pod? Since it's relative, it would just use all of the node's resources, right? So this has a nice side effect. The spare resources on the node can be used by the pod relatively to their request. So basically the request is the minimum amount that is actually allocated and all of the spare resources are being split relatively to their request. So let's talk about Kubernetes QoS for a second. There are three quality of service levels. The first one is best effort. That means that I don't specify anything. I don't have request, I don't have limits, not for memory and not for CPU. The last one, guaranteed, is kind of the opposite from that. I specify both request and limits to both CPUs and memory and the request and limits are equal. Now if you're not best effort and you're not guaranteed, you'd be burstable. So this is just an example, but the idea is that you can specify either only request, only limits, you can specify them both, but they're not equal. So any other than best effort and guaranteed. Now basically the trade-off here is predictability in order to get stability. So basically Kubernetes tells you, if you want me to guarantee you stability, you have to be predictable or if you will be more predictable, you'll gain more stability. Like one example for that, if we're talking about memory for example, are node pressures. So when the node would have high memory pressure, it would evict guaranteed QoS pods last. And after that it would get to burstable, after that it would get to best efforts. So this is true by the way, as long as you keep your promises. If you say that you're limited to a certain amount of memory and then you exceed this memory, then on most CRIs we'll just kill the pod. So can we use dedicated CPUs on Kubernetes? So the answer is yes. This is possible with CPU manager. And in order to do that, we have two requirements. First of all, the pod needs to be of guaranteed QoS. Second of all, the CPU request, which equals the limit because it's a guaranteed QoS, has to be an integer. It cannot be a floating point value. Also an interesting fact is that only a single container or some of the containers in a pod can have dedicated CPUs, but the whole pod needs to be of a guaranteed QoS. So let's talk about namespaces for a second. So remember this little diagram from before, so namespaces is another building block for containers and it basically is responsible for the isolation of the containers. So when I'm picturing a pod, this is what I think about. Like it's a box with some containers in it. The containers are absolutely isolated from one another. And as we said, container is a concept. So if we will take some of the namespaces out and we will break some of the isolations between the containers. Are there still containers? How do we need to, how layers of isolation do we need to strip before it stops being a container? This is more of a philosophical question, but is it possible on Kubernetes and the answer is yes. So for example, it's possible to share the pod namespace between containers or the process namespace between containers. And what it means is that inside the container, if you will do something like PS, you would see all of the processes from all of the containers. This isolation will not exist anymore. Another interesting fact is that as a side effect, the file systems are also shared. Now they're not shared directly, but you can use that trick to use them indirectly. We'll get you to the root file system of another process that now can be in another container. So to actually enable that, that's what you need to do. In the pod, in the spec, share process namespace, true, and that's it. So now a word about KVM. So who knows KVM, by the way? Oh, a lot of you, okay. So this is a kernel model which turns the Linux into a hypervisor. Basically we have two kinds of hypervisors, type one and type two. Type one means that it's also called a bare metal hypervisor because it's being installed on a bare metal. There's no OS benefit. And what it means is that it's really fast, but the downside is that it has to implement stuff like a scheduler, a virtual memory, and a lot of stuff that already exists on every OS. Type two hypervisors are being installed on top of the OS, so they don't have to re-implement all of those stuff, but they're usually a lot slower. So KVM is really incredible because it turns Linux into a type one hypervisor. And this is what Qvert is using to gain native performance. An interesting fact about a KVM is that its main purpose is CPU virtualization because this is the performance part. It's also backed by QEMU, which does things like IO and stuff like that, which are usually less related to performance. So how does KVM actually works? So from the guest perspective, it will have, for example, four CPUs. But these aren't real CPUs, right? They are virtual CPUs or VCPUs. And from the kernel perspective, these are just threads, VCPU threads. So what the guest sees as a physical CPU is actually from the host perspective is just another thread on the system. Okay, so now back to Qvert after all of these introductions. In Qvert, we have the VRT Launcher pod. It has some containers in it. The compute container is the main container. Inside the compute container, we run the QEMU process, which actually runs the guest. And this is the main container that we're using. So first attempt to support dedicated CPUs. So the idea was let's allocate the compute container that we talked about with dedicated CPUs. So this is possible with CPU manager as we talked about. All we need is to do is to have a pod that's guaranteed QS and to have an integer amount of CPUs on the compute container. So by the way, is it a good approach, do you think? This is a problem and let me explain you why. So let's zoom into the compute container for a second. The list here is all of the processes and threads that run inside the compute container. You don't need to understand everything that's running here. But let me show you the interesting part. So you see the QEMU KVM process. All of the red ones are threads. Now as you can see, we have two threads, which are the actual vCPU threads, like I said earlier. So the problem is that we have a lot of threads with different priorities. And if we let all of the compute container run with dedicated CPUs, this aren't really dedicated CPUs because we said that the keyword here is avoiding preemption, right? But with the previous setting, we're basically, we will context switch out the vCPUs in order for other threads inside the compute containers. So the vCPUs aren't running on dedicated CPUs really. We actually lie to the guest. So that's a problem. Now the second approach is called the housekeeping C-group. And the idea is that we will make a child C-group for all of the low priority threads or processes. So how would it work? So let's say that the user asks for XCPUs. We would actually allocate X plus one dedicated CPUs. And one dedicated CPU will serve all of the housekeeping tasks. And when I say housekeeping tasks, I basically mean everything but the vCPUs themselves. Then what we can do is move all of the threads that aren't vCPUs into the housekeeping C-groups. And then the vCPUs would be with two dedicated CPUs. So this is how it looks like. We have the vert launcher pod inside of we have the compute container with X plus one dedicated CPUs. One dedicated CPU is for everything but the vCPUs themselves. And the X dedicated CPUs are for the vCPUs. So this approach is much better because it lets us, this basically supports two dedicated CPUs for the vCPUs. But this also has a problem. So first problem is that we waste one dedicated CPU for stuff that are of low priority. This is a huge waste. Ideally, we would have wanted to do something like give me like four or X amount of dedicated CPUs and another amount of shared CPUs for everything else. And this is actually possible on C-groups but it's not possible on Kubernetes because what we said earlier. If we're going to ask like 3.2 CPUs or something like that, they won't be dedicated. That would be all shared. So basically Kubernetes goes for an all or nothing approach. Either all of the CPUs are dedicated or all of the CPUs are shared. Another problem which is more of a design problem is that we're focused around the lowest priority processes. And this kind of should be reversed, right? I mean we want to configure the vCPUs to have dedicated CPUs. So we configure everything that is not the vCPUs. And this is problematic because we would ideally want to only change the vCPUs threads and leave everything as is to keep it open for extensions in the future and stuff like that. There are more problems related to C-groups v1 and v2. I'll not dive into details here but two words about it is for example in v2 we have the threaded C-group concept which doesn't exist in v1. And in a threaded C-group we have a lot of limitations. Some of the controllers and some systems of C-groups cannot work at all. So just know that there are more problems with this solution. So a third attempt, I'm calling it the dedicated CPU C-group approach and here's the idea. So the compute container stays completely as it is. We won't touch it at all. We would allocate it with CPUs that are not a dedicated, sorry they are shared CPUs but remember that the pods still need to be with guaranteed QoS and I'll explain why. So what we will do is add another container which is basically a blank container with X dedicated CPUs and as I said every container creates a new C-group so it will create a new C-group for us. So what do I mean by a blank container? I mean a container doesn't really run anything. It could run for example a sleep forever process just to keep the container alive but that's it. It would be entire the blank. And then what we will do is move only the VCPUs into another container, right, into another C-group. All of the compute containers stays as is and only the VCPUs are configured. So this is how it looks like. So as the VM starts or before it starts, we have the VRT launcher. Now we have two different containers. One of them is the compute container with Y shared CPUs. These are not dedicated CPUs. The other one is a container with dedicated CPUs. X dedicated CPUs, exactly the amount we need, not X plus one as before. So in the compute container everything is being run when the VM is being started. But right after it's being started or right before it's being started, what we will do is move the VCPUs into the different container. And that basically solves our problem because now all of the housekeeping tasks are being run with shared CPUs, the VCPUs are running on dedicated CPUs. So can we actually do that? I mean, we actually moved some threads of a process to another container. This looks extremely weird, right? But this is possible because we shared the PID namespace. So you can think about it like the processes are not isolated anymore. They're not really being moved from one container to another because the container does not isolate processes anymore. So we only change C groups. So from the VCPUs perspective, they just stay the same. They can communicate with all of the threads and processes in the system. So only the relevant threads are being configured, as I said, shared CPUs for the housekeeping test so we don't waste one dedicated core anymore. And we keep things open for extensions in the future. Maybe we would want to do more plays with C groups in the future. So we want everything in the compute container to stay completely as is. OK, so summary and takeaways. There were a lot of introductions here. And I've scratched the surface of a lot of cool facts and technologies that I've seen along the way. So we've seen CPU allocation, implementation in Kubernetes, how C group uses relative shares and not absolute values, and how the CPUs and the resources are being spread along the pods relatively to their requests. We've seen how to enable dedicated CPUs and Kubernetes. We've seen namespaces and how to break the isolation within a pod. We've talked a bit about KVM and how it uses threads to run the actual CPUs. And of course, we talked about Kuvert. And again, I really hope that these takeaways would serve you in your journeys in the future. And I hope that you find this interesting. So thanks a lot, and you're always welcome to send questions or feedback or anything else to my mail and I'll also be outside for questions. OK. So thank you. And if you have any questions. OK. So the question is, do we need to do something like this? OK, so the question is, do we need more permission to divert launcher pod, or is it being done by the vert handler? And the answer is, it's being done by the vert handler. So just a bit of context, a vert handler is another pod that Kuvert uses. It's a pod with high privileges, and therefore, we don't need any extra privileges for it to configure that. Yeah. Does this allow for easier networking communication if you talk in service communication in the Kubernetes sense? You could do it VM to VM, presumably with the exact same mechanism, so resolving service names from what VM to whatever VM is using Kubernetes, does that work at the moment? So that's a question about Kuvert in general, right? But in Kubernetes, I can do it, but presumably I can do the same thing from a VM running inside the pod. Right. Yeah, so the answer is yes. OK. Yeah. Any other question? Yeah. I have a question. You are dedicating the CPUs separately, but about other threads, which are, for some of these cases, highly CPU consuming like network threads or IO threads, is there a network thread as well? Right. So the question is, what about IO threads or network related threads, what about them? And, actually, in the VM manifest, we have configurations for that. So you can ask, for example, for an IO thread to run on a dedicated CPU. That is also supported. Yeah. I focused solely on the CPUs themselves, but this is entirely possible in Kuvert today. Yes. Can I combine it with new machines, so dual machine machines can be used by the same machine, and what's running with it? So the question is, can we support NUMA with this? The answer is yes. I'm not sure if it works right now outside of the box, but I think it should be possible with, especially with C-groups V2. But this is an interesting question. I will have to think about it a little more. I think it is possible. Anyone else? Time's up. Sorry, but I'll be out here if you want to ask further questions. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.36, "text": " So, hello everyone, pleasure to be here.", "tokens": [407, 11, 7751, 1518, 11, 6834, 281, 312, 510, 13], "temperature": 0.0, "avg_logprob": -0.23674783361963478, "compression_ratio": 1.4927536231884058, "no_speech_prob": 0.1663486659526825}, {"id": 1, "seek": 0, "start": 9.36, "end": 14.32, "text": " I'm Ithamar Holder and I'm a senior software engineer working for Red Hat.", "tokens": [286, 478, 286, 392, 335, 289, 6962, 260, 293, 286, 478, 257, 7965, 4722, 11403, 1364, 337, 4477, 15867, 13], "temperature": 0.0, "avg_logprob": -0.23674783361963478, "compression_ratio": 1.4927536231884058, "no_speech_prob": 0.1663486659526825}, {"id": 2, "seek": 0, "start": 14.32, "end": 20.400000000000002, "text": " And this is a talk about the journey through supporting VMs with dedicated CPUs and Kubernetes.", "tokens": [400, 341, 307, 257, 751, 466, 264, 4671, 807, 7231, 18038, 82, 365, 8374, 13199, 82, 293, 23145, 13], "temperature": 0.0, "avg_logprob": -0.23674783361963478, "compression_ratio": 1.4927536231884058, "no_speech_prob": 0.1663486659526825}, {"id": 3, "seek": 0, "start": 20.400000000000002, "end": 26.400000000000002, "text": " And the reason that there's a journey word in the subject is that this was a true journey", "tokens": [400, 264, 1778, 300, 456, 311, 257, 4671, 1349, 294, 264, 3983, 307, 300, 341, 390, 257, 2074, 4671], "temperature": 0.0, "avg_logprob": -0.23674783361963478, "compression_ratio": 1.4927536231884058, "no_speech_prob": 0.1663486659526825}, {"id": 4, "seek": 0, "start": 26.400000000000002, "end": 27.400000000000002, "text": " for me.", "tokens": [337, 385, 13], "temperature": 0.0, "avg_logprob": -0.23674783361963478, "compression_ratio": 1.4927536231884058, "no_speech_prob": 0.1663486659526825}, {"id": 5, "seek": 2740, "start": 27.4, "end": 33.6, "text": " And I'm going to guide you through the journey until we reach the actual problems and solutions.", "tokens": [400, 286, 478, 516, 281, 5934, 291, 807, 264, 4671, 1826, 321, 2524, 264, 3539, 2740, 293, 6547, 13], "temperature": 0.0, "avg_logprob": -0.12332055175188676, "compression_ratio": 1.8491379310344827, "no_speech_prob": 5.262134436634369e-05}, {"id": 6, "seek": 2740, "start": 33.6, "end": 34.76, "text": " And there are two reasons for that.", "tokens": [400, 456, 366, 732, 4112, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.12332055175188676, "compression_ratio": 1.8491379310344827, "no_speech_prob": 5.262134436634369e-05}, {"id": 7, "seek": 2740, "start": 34.76, "end": 40.36, "text": " So first reason is that we need to understand the problems and solutions.", "tokens": [407, 700, 1778, 307, 300, 321, 643, 281, 1223, 264, 2740, 293, 6547, 13], "temperature": 0.0, "avg_logprob": -0.12332055175188676, "compression_ratio": 1.8491379310344827, "no_speech_prob": 5.262134436634369e-05}, {"id": 8, "seek": 2740, "start": 40.36, "end": 43.959999999999994, "text": " So we need to understand the background for it.", "tokens": [407, 321, 643, 281, 1223, 264, 3678, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.12332055175188676, "compression_ratio": 1.8491379310344827, "no_speech_prob": 5.262134436634369e-05}, {"id": 9, "seek": 2740, "start": 43.959999999999994, "end": 48.959999999999994, "text": " But the second reason is that I've gained a lot of insights and takeaways during that", "tokens": [583, 264, 1150, 1778, 307, 300, 286, 600, 12634, 257, 688, 295, 14310, 293, 45584, 1830, 300], "temperature": 0.0, "avg_logprob": -0.12332055175188676, "compression_ratio": 1.8491379310344827, "no_speech_prob": 5.262134436634369e-05}, {"id": 10, "seek": 2740, "start": 48.959999999999994, "end": 49.959999999999994, "text": " journey.", "tokens": [4671, 13], "temperature": 0.0, "avg_logprob": -0.12332055175188676, "compression_ratio": 1.8491379310344827, "no_speech_prob": 5.262134436634369e-05}, {"id": 11, "seek": 2740, "start": 49.959999999999994, "end": 55.16, "text": " And I think that I hope that you could find is also valuable for your journeys.", "tokens": [400, 286, 519, 300, 286, 1454, 300, 291, 727, 915, 307, 611, 8263, 337, 428, 36736, 13], "temperature": 0.0, "avg_logprob": -0.12332055175188676, "compression_ratio": 1.8491379310344827, "no_speech_prob": 5.262134436634369e-05}, {"id": 12, "seek": 5516, "start": 55.16, "end": 60.68, "text": " And yeah, that you can take the same takeaways for whatever you're doing and whatever you're", "tokens": [400, 1338, 11, 300, 291, 393, 747, 264, 912, 45584, 337, 2035, 291, 434, 884, 293, 2035, 291, 434], "temperature": 0.0, "avg_logprob": -0.18845158953999364, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.00024234502052422613}, {"id": 13, "seek": 5516, "start": 60.68, "end": 62.12, "text": " interested in.", "tokens": [3102, 294, 13], "temperature": 0.0, "avg_logprob": -0.18845158953999364, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.00024234502052422613}, {"id": 14, "seek": 5516, "start": 62.12, "end": 68.44, "text": " So we're going to talk about all sorts of stuff like dedicated CPUs and CPU manager,", "tokens": [407, 321, 434, 516, 281, 751, 466, 439, 7527, 295, 1507, 411, 8374, 13199, 82, 293, 13199, 6598, 11], "temperature": 0.0, "avg_logprob": -0.18845158953999364, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.00024234502052422613}, {"id": 15, "seek": 5516, "start": 68.44, "end": 73.64, "text": " C groups, spot isolation and namespaces, Kubernetes resource allocation.", "tokens": [383, 3935, 11, 4008, 16001, 293, 5288, 79, 2116, 11, 23145, 7684, 27599, 13], "temperature": 0.0, "avg_logprob": -0.18845158953999364, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.00024234502052422613}, {"id": 16, "seek": 5516, "start": 73.64, "end": 76.44, "text": " And so let's begin.", "tokens": [400, 370, 718, 311, 1841, 13], "temperature": 0.0, "avg_logprob": -0.18845158953999364, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.00024234502052422613}, {"id": 17, "seek": 5516, "start": 76.44, "end": 79.52, "text": " So first of all, an introduction to Kuber.", "tokens": [407, 700, 295, 439, 11, 364, 9339, 281, 591, 10261, 13], "temperature": 0.0, "avg_logprob": -0.18845158953999364, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.00024234502052422613}, {"id": 18, "seek": 7952, "start": 79.52, "end": 87.32, "text": " So Kubernetes is designed to run containers, which are designed very differently than VMs.", "tokens": [407, 23145, 307, 4761, 281, 1190, 17089, 11, 597, 366, 4761, 588, 7614, 813, 18038, 82, 13], "temperature": 0.0, "avg_logprob": -0.13599796917127527, "compression_ratio": 1.6814159292035398, "no_speech_prob": 0.00027025502640753984}, {"id": 19, "seek": 7952, "start": 87.32, "end": 94.28, "text": " And running VMs on one platform and containers on another platform is not the best approach.", "tokens": [400, 2614, 18038, 82, 322, 472, 3663, 293, 17089, 322, 1071, 3663, 307, 406, 264, 1151, 3109, 13], "temperature": 0.0, "avg_logprob": -0.13599796917127527, "compression_ratio": 1.6814159292035398, "no_speech_prob": 0.00027025502640753984}, {"id": 20, "seek": 7952, "start": 94.28, "end": 97.52, "text": " And this is where Kuber comes into play.", "tokens": [400, 341, 307, 689, 591, 10261, 1487, 666, 862, 13], "temperature": 0.0, "avg_logprob": -0.13599796917127527, "compression_ratio": 1.6814159292035398, "no_speech_prob": 0.00027025502640753984}, {"id": 21, "seek": 7952, "start": 97.52, "end": 102.72, "text": " This is basically an add-on or extension to Kubernetes, which lets you run VMs on top", "tokens": [639, 307, 1936, 364, 909, 12, 266, 420, 10320, 281, 23145, 11, 597, 6653, 291, 1190, 18038, 82, 322, 1192], "temperature": 0.0, "avg_logprob": -0.13599796917127527, "compression_ratio": 1.6814159292035398, "no_speech_prob": 0.00027025502640753984}, {"id": 22, "seek": 7952, "start": 102.72, "end": 107.88, "text": " of Kubernetes as a first-class citizen, as a completely cloud native.", "tokens": [295, 23145, 382, 257, 700, 12, 11665, 13326, 11, 382, 257, 2584, 4588, 8470, 13], "temperature": 0.0, "avg_logprob": -0.13599796917127527, "compression_ratio": 1.6814159292035398, "no_speech_prob": 0.00027025502640753984}, {"id": 23, "seek": 10788, "start": 107.88, "end": 113.11999999999999, "text": " And I'm not going to dive into all the architectural details here, but the trick is basically to", "tokens": [400, 286, 478, 406, 516, 281, 9192, 666, 439, 264, 26621, 4365, 510, 11, 457, 264, 4282, 307, 1936, 281], "temperature": 0.0, "avg_logprob": -0.14144350761591, "compression_ratio": 1.5401785714285714, "no_speech_prob": 0.00011162801820319146}, {"id": 24, "seek": 10788, "start": 113.11999999999999, "end": 119.88, "text": " run a VM within a container, like this picture tries to illustrate.", "tokens": [1190, 257, 18038, 1951, 257, 10129, 11, 411, 341, 3036, 9898, 281, 23221, 13], "temperature": 0.0, "avg_logprob": -0.14144350761591, "compression_ratio": 1.5401785714285714, "no_speech_prob": 0.00011162801820319146}, {"id": 25, "seek": 10788, "start": 119.88, "end": 125.19999999999999, "text": " And that's basically what you need to know for this talk.", "tokens": [400, 300, 311, 1936, 437, 291, 643, 281, 458, 337, 341, 751, 13], "temperature": 0.0, "avg_logprob": -0.14144350761591, "compression_ratio": 1.5401785714285714, "no_speech_prob": 0.00011162801820319146}, {"id": 26, "seek": 10788, "start": 125.19999999999999, "end": 128.04, "text": " So what's the deal with dedicated CPUs?", "tokens": [407, 437, 311, 264, 2028, 365, 8374, 13199, 82, 30], "temperature": 0.0, "avg_logprob": -0.14144350761591, "compression_ratio": 1.5401785714285714, "no_speech_prob": 0.00011162801820319146}, {"id": 27, "seek": 10788, "start": 128.04, "end": 134.64, "text": " So basically, the key word here is avoiding preemption or context switches, right?", "tokens": [407, 1936, 11, 264, 2141, 1349, 510, 307, 20220, 659, 26033, 420, 4319, 19458, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14144350761591, "compression_ratio": 1.5401785714285714, "no_speech_prob": 0.00011162801820319146}, {"id": 28, "seek": 13464, "start": 134.64, "end": 140.0, "text": " These are crucial, this is crucial for certain use cases like real-time VMs or VMs that", "tokens": [1981, 366, 11462, 11, 341, 307, 11462, 337, 1629, 764, 3331, 411, 957, 12, 3766, 18038, 82, 420, 18038, 82, 300], "temperature": 0.0, "avg_logprob": -0.11161731579981812, "compression_ratio": 1.7250996015936255, "no_speech_prob": 0.00010494425805518404}, {"id": 29, "seek": 13464, "start": 140.0, "end": 141.92, "text": " depend on very low latency.", "tokens": [5672, 322, 588, 2295, 27043, 13], "temperature": 0.0, "avg_logprob": -0.11161731579981812, "compression_ratio": 1.7250996015936255, "no_speech_prob": 0.00010494425805518404}, {"id": 30, "seek": 13464, "start": 141.92, "end": 147.64, "text": " So as a naive example, let's think about a VM that hot loops over some condition.", "tokens": [407, 382, 257, 29052, 1365, 11, 718, 311, 519, 466, 257, 18038, 300, 2368, 16121, 670, 512, 4188, 13], "temperature": 0.0, "avg_logprob": -0.11161731579981812, "compression_ratio": 1.7250996015936255, "no_speech_prob": 0.00010494425805518404}, {"id": 31, "seek": 13464, "start": 147.64, "end": 151.67999999999998, "text": " And when this condition becomes true, it has to react really, really fast.", "tokens": [400, 562, 341, 4188, 3643, 2074, 11, 309, 575, 281, 4515, 534, 11, 534, 2370, 13], "temperature": 0.0, "avg_logprob": -0.11161731579981812, "compression_ratio": 1.7250996015936255, "no_speech_prob": 0.00010494425805518404}, {"id": 32, "seek": 13464, "start": 151.67999999999998, "end": 156.79999999999998, "text": " So if we context switch this workload out, then it would take more time.", "tokens": [407, 498, 321, 4319, 3679, 341, 20139, 484, 11, 550, 309, 576, 747, 544, 565, 13], "temperature": 0.0, "avg_logprob": -0.11161731579981812, "compression_ratio": 1.7250996015936255, "no_speech_prob": 0.00010494425805518404}, {"id": 33, "seek": 13464, "start": 156.79999999999998, "end": 161.51999999999998, "text": " Because once the condition becomes true, it would take time to context switch back, and", "tokens": [1436, 1564, 264, 4188, 3643, 2074, 11, 309, 576, 747, 565, 281, 4319, 3679, 646, 11, 293], "temperature": 0.0, "avg_logprob": -0.11161731579981812, "compression_ratio": 1.7250996015936255, "no_speech_prob": 0.00010494425805518404}, {"id": 34, "seek": 16152, "start": 161.52, "end": 165.04000000000002, "text": " only then the VM could react.", "tokens": [787, 550, 264, 18038, 727, 4515, 13], "temperature": 0.0, "avg_logprob": -0.16786494621863732, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0001581347460160032}, {"id": 35, "seek": 16152, "start": 165.04000000000002, "end": 168.20000000000002, "text": " So this is very crucial for some use cases.", "tokens": [407, 341, 307, 588, 11462, 337, 512, 764, 3331, 13], "temperature": 0.0, "avg_logprob": -0.16786494621863732, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0001581347460160032}, {"id": 36, "seek": 16152, "start": 168.20000000000002, "end": 174.56, "text": " Also it's supported by most hyper-hypervisors, and it's a pretty standard feature.", "tokens": [2743, 309, 311, 8104, 538, 881, 9848, 12, 3495, 610, 4938, 830, 11, 293, 309, 311, 257, 1238, 3832, 4111, 13], "temperature": 0.0, "avg_logprob": -0.16786494621863732, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0001581347460160032}, {"id": 37, "seek": 16152, "start": 174.56, "end": 178.92000000000002, "text": " And we aim to bring this also to Kubernetes.", "tokens": [400, 321, 5939, 281, 1565, 341, 611, 281, 23145, 13], "temperature": 0.0, "avg_logprob": -0.16786494621863732, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0001581347460160032}, {"id": 38, "seek": 16152, "start": 178.92000000000002, "end": 180.28, "text": " So a question to the crowd.", "tokens": [407, 257, 1168, 281, 264, 6919, 13], "temperature": 0.0, "avg_logprob": -0.16786494621863732, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0001581347460160032}, {"id": 39, "seek": 16152, "start": 180.28, "end": 182.12, "text": " Who recognizes this section?", "tokens": [2102, 26564, 341, 3541, 30], "temperature": 0.0, "avg_logprob": -0.16786494621863732, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0001581347460160032}, {"id": 40, "seek": 16152, "start": 182.12, "end": 183.84, "text": " Who knows what this is?", "tokens": [2102, 3255, 437, 341, 307, 30], "temperature": 0.0, "avg_logprob": -0.16786494621863732, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0001581347460160032}, {"id": 41, "seek": 16152, "start": 183.84, "end": 186.60000000000002, "text": " Okay, so most of you.", "tokens": [1033, 11, 370, 881, 295, 291, 13], "temperature": 0.0, "avg_logprob": -0.16786494621863732, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0001581347460160032}, {"id": 42, "seek": 18660, "start": 186.6, "end": 192.68, "text": " And another question, who can say that he's confident about how this is implemented behind", "tokens": [400, 1071, 1168, 11, 567, 393, 584, 300, 415, 311, 6679, 466, 577, 341, 307, 12270, 2261], "temperature": 0.0, "avg_logprob": -0.14417254799290707, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0001644389849388972}, {"id": 43, "seek": 18660, "start": 192.68, "end": 196.68, "text": " the scenes, or how Kubernetes actually does that?", "tokens": [264, 8026, 11, 420, 577, 23145, 767, 775, 300, 30], "temperature": 0.0, "avg_logprob": -0.14417254799290707, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0001644389849388972}, {"id": 44, "seek": 18660, "start": 196.68, "end": 198.72, "text": " A lot less of you, right?", "tokens": [316, 688, 1570, 295, 291, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14417254799290707, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0001644389849388972}, {"id": 45, "seek": 18660, "start": 198.72, "end": 203.92, "text": " So that's good, it means that this is relevant, right?", "tokens": [407, 300, 311, 665, 11, 309, 1355, 300, 341, 307, 7340, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14417254799290707, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0001644389849388972}, {"id": 46, "seek": 18660, "start": 203.92, "end": 207.56, "text": " So obviously, this is taken from the pods manifest.", "tokens": [407, 2745, 11, 341, 307, 2726, 490, 264, 31925, 10067, 13], "temperature": 0.0, "avg_logprob": -0.14417254799290707, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0001644389849388972}, {"id": 47, "seek": 18660, "start": 207.56, "end": 210.35999999999999, "text": " This is the place when we specify resources.", "tokens": [639, 307, 264, 1081, 562, 321, 16500, 3593, 13], "temperature": 0.0, "avg_logprob": -0.14417254799290707, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0001644389849388972}, {"id": 48, "seek": 18660, "start": 210.35999999999999, "end": 213.16, "text": " We have, of course, requests and limits.", "tokens": [492, 362, 11, 295, 1164, 11, 12475, 293, 10406, 13], "temperature": 0.0, "avg_logprob": -0.14417254799290707, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0001644389849388972}, {"id": 49, "seek": 21316, "start": 213.16, "end": 220.96, "text": " We can specify CPU, memory, a firmware storage, and a bunch of other stuff.", "tokens": [492, 393, 16500, 13199, 11, 4675, 11, 257, 30289, 6725, 11, 293, 257, 3840, 295, 661, 1507, 13], "temperature": 0.0, "avg_logprob": -0.13683206741123982, "compression_ratio": 1.485, "no_speech_prob": 9.535018762107939e-05}, {"id": 50, "seek": 21316, "start": 220.96, "end": 223.92, "text": " And so let's talk about containers for a second.", "tokens": [400, 370, 718, 311, 751, 466, 17089, 337, 257, 1150, 13], "temperature": 0.0, "avg_logprob": -0.13683206741123982, "compression_ratio": 1.485, "no_speech_prob": 9.535018762107939e-05}, {"id": 51, "seek": 21316, "start": 223.92, "end": 230.2, "text": " So containers are actually a conceptual concept that can be implemented in many ways.", "tokens": [407, 17089, 366, 767, 257, 24106, 3410, 300, 393, 312, 12270, 294, 867, 2098, 13], "temperature": 0.0, "avg_logprob": -0.13683206741123982, "compression_ratio": 1.485, "no_speech_prob": 9.535018762107939e-05}, {"id": 52, "seek": 21316, "start": 230.2, "end": 236.51999999999998, "text": " So from the Linux kernel perspective, there isn't such a thing as a container, really.", "tokens": [407, 490, 264, 18734, 28256, 4585, 11, 456, 1943, 380, 1270, 257, 551, 382, 257, 10129, 11, 534, 13], "temperature": 0.0, "avg_logprob": -0.13683206741123982, "compression_ratio": 1.485, "no_speech_prob": 9.535018762107939e-05}, {"id": 53, "seek": 23652, "start": 236.52, "end": 243.04000000000002, "text": " There are basically a couple of main kernel features that serve as the building blocks", "tokens": [821, 366, 1936, 257, 1916, 295, 2135, 28256, 4122, 300, 4596, 382, 264, 2390, 8474], "temperature": 0.0, "avg_logprob": -0.12404807217149849, "compression_ratio": 1.7015706806282722, "no_speech_prob": 2.5300305424025282e-05}, {"id": 54, "seek": 23652, "start": 243.04000000000002, "end": 244.96, "text": " for containers.", "tokens": [337, 17089, 13], "temperature": 0.0, "avg_logprob": -0.12404807217149849, "compression_ratio": 1.7015706806282722, "no_speech_prob": 2.5300305424025282e-05}, {"id": 55, "seek": 23652, "start": 244.96, "end": 246.88, "text": " One of them is C groups.", "tokens": [1485, 295, 552, 307, 383, 3935, 13], "temperature": 0.0, "avg_logprob": -0.12404807217149849, "compression_ratio": 1.7015706806282722, "no_speech_prob": 2.5300305424025282e-05}, {"id": 56, "seek": 23652, "start": 246.88, "end": 252.32000000000002, "text": " C groups is very important, and is one of the main building blocks for containers.", "tokens": [383, 3935, 307, 588, 1021, 11, 293, 307, 472, 295, 264, 2135, 2390, 8474, 337, 17089, 13], "temperature": 0.0, "avg_logprob": -0.12404807217149849, "compression_ratio": 1.7015706806282722, "no_speech_prob": 2.5300305424025282e-05}, {"id": 57, "seek": 23652, "start": 252.32000000000002, "end": 255.76000000000002, "text": " So let's talk about C groups a bit.", "tokens": [407, 718, 311, 751, 466, 383, 3935, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.12404807217149849, "compression_ratio": 1.7015706806282722, "no_speech_prob": 2.5300305424025282e-05}, {"id": 58, "seek": 23652, "start": 255.76000000000002, "end": 262.28000000000003, "text": " So basically, the idea is that the architecture is a tree of resources, right?", "tokens": [407, 1936, 11, 264, 1558, 307, 300, 264, 9482, 307, 257, 4230, 295, 3593, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.12404807217149849, "compression_ratio": 1.7015706806282722, "no_speech_prob": 2.5300305424025282e-05}, {"id": 59, "seek": 26228, "start": 262.28, "end": 266.59999999999997, "text": " We have the root C group, which is basically all of the resources on the node.", "tokens": [492, 362, 264, 5593, 383, 1594, 11, 597, 307, 1936, 439, 295, 264, 3593, 322, 264, 9984, 13], "temperature": 0.0, "avg_logprob": -0.12087583541870117, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0001282998127862811}, {"id": 60, "seek": 26228, "start": 266.59999999999997, "end": 269.0, "text": " So for example, 100 CPUs.", "tokens": [407, 337, 1365, 11, 2319, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.12087583541870117, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0001282998127862811}, {"id": 61, "seek": 26228, "start": 269.0, "end": 275.28, "text": " And then we divide them into groups, like for example, 70 CPUs, 20 CPUs, 10 CPUs, and", "tokens": [400, 550, 321, 9845, 552, 666, 3935, 11, 411, 337, 1365, 11, 5285, 13199, 82, 11, 945, 13199, 82, 11, 1266, 13199, 82, 11, 293], "temperature": 0.0, "avg_logprob": -0.12087583541870117, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0001282998127862811}, {"id": 62, "seek": 26228, "start": 275.28, "end": 277.52, "text": " so on.", "tokens": [370, 322, 13], "temperature": 0.0, "avg_logprob": -0.12087583541870117, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0001282998127862811}, {"id": 63, "seek": 26228, "start": 277.52, "end": 284.55999999999995, "text": " The idea is that every process on the system is attached to a C group.", "tokens": [440, 1558, 307, 300, 633, 1399, 322, 264, 1185, 307, 8570, 281, 257, 383, 1594, 13], "temperature": 0.0, "avg_logprob": -0.12087583541870117, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0001282998127862811}, {"id": 64, "seek": 28456, "start": 284.56, "end": 294.16, "text": " And that basically the C groups limits the resources for this group of processes.", "tokens": [400, 300, 1936, 264, 383, 3935, 10406, 264, 3593, 337, 341, 1594, 295, 7555, 13], "temperature": 0.0, "avg_logprob": -0.11559468507766724, "compression_ratio": 1.5975609756097562, "no_speech_prob": 2.740245145105291e-05}, {"id": 65, "seek": 28456, "start": 294.16, "end": 297.56, "text": " And in Kubernetes, there is usually one C group per container.", "tokens": [400, 294, 23145, 11, 456, 307, 2673, 472, 383, 1594, 680, 10129, 13], "temperature": 0.0, "avg_logprob": -0.11559468507766724, "compression_ratio": 1.5975609756097562, "no_speech_prob": 2.740245145105291e-05}, {"id": 66, "seek": 28456, "start": 297.56, "end": 301.24, "text": " This actually depends on the CRI that you're using.", "tokens": [639, 767, 5946, 322, 264, 383, 5577, 300, 291, 434, 1228, 13], "temperature": 0.0, "avg_logprob": -0.11559468507766724, "compression_ratio": 1.5975609756097562, "no_speech_prob": 2.740245145105291e-05}, {"id": 67, "seek": 28456, "start": 301.24, "end": 309.72, "text": " But the most common approach is to use one C group per container.", "tokens": [583, 264, 881, 2689, 3109, 307, 281, 764, 472, 383, 1594, 680, 10129, 13], "temperature": 0.0, "avg_logprob": -0.11559468507766724, "compression_ratio": 1.5975609756097562, "no_speech_prob": 2.740245145105291e-05}, {"id": 68, "seek": 30972, "start": 309.72, "end": 314.64000000000004, "text": " So in Kubernetes, all of the values are always absolute, right?", "tokens": [407, 294, 23145, 11, 439, 295, 264, 4190, 366, 1009, 8236, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14114373463850755, "compression_ratio": 1.5357142857142858, "no_speech_prob": 1.4718967577209696e-05}, {"id": 69, "seek": 30972, "start": 314.64000000000004, "end": 320.92, "text": " When we specify CPU, for example, we can specify 100M, which stands for milli-CPUs, which is", "tokens": [1133, 321, 16500, 13199, 11, 337, 1365, 11, 321, 393, 16500, 2319, 44, 11, 597, 7382, 337, 26176, 12, 34, 8115, 82, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.14114373463850755, "compression_ratio": 1.5357142857142858, "no_speech_prob": 1.4718967577209696e-05}, {"id": 70, "seek": 30972, "start": 320.92, "end": 327.24, "text": " similar to 0.1 CPUs, 1.3, whatever, but these are always absolute values.", "tokens": [2531, 281, 1958, 13, 16, 13199, 82, 11, 502, 13, 18, 11, 2035, 11, 457, 613, 366, 1009, 8236, 4190, 13], "temperature": 0.0, "avg_logprob": -0.14114373463850755, "compression_ratio": 1.5357142857142858, "no_speech_prob": 1.4718967577209696e-05}, {"id": 71, "seek": 30972, "start": 327.24, "end": 329.88000000000005, "text": " In C groups, it's all relative, right?", "tokens": [682, 383, 3935, 11, 309, 311, 439, 4972, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14114373463850755, "compression_ratio": 1.5357142857142858, "no_speech_prob": 1.4718967577209696e-05}, {"id": 72, "seek": 30972, "start": 329.88000000000005, "end": 331.48, "text": " It's called CPU shares.", "tokens": [467, 311, 1219, 13199, 12182, 13], "temperature": 0.0, "avg_logprob": -0.14114373463850755, "compression_ratio": 1.5357142857142858, "no_speech_prob": 1.4718967577209696e-05}, {"id": 73, "seek": 30972, "start": 331.48, "end": 334.56, "text": " The default is 1024, but it doesn't really matter.", "tokens": [440, 7576, 307, 1266, 7911, 11, 457, 309, 1177, 380, 534, 1871, 13], "temperature": 0.0, "avg_logprob": -0.14114373463850755, "compression_ratio": 1.5357142857142858, "no_speech_prob": 1.4718967577209696e-05}, {"id": 74, "seek": 33456, "start": 334.56, "end": 343.04, "text": " So if we'll look on a very naive example again, let's say that we have a node with two pods", "tokens": [407, 498, 321, 603, 574, 322, 257, 588, 29052, 1365, 797, 11, 718, 311, 584, 300, 321, 362, 257, 9984, 365, 732, 31925], "temperature": 0.0, "avg_logprob": -0.11203610897064209, "compression_ratio": 1.6502242152466369, "no_speech_prob": 5.6261113059008494e-05}, {"id": 75, "seek": 33456, "start": 343.04, "end": 345.0, "text": " running on the system, pod A and pod B.", "tokens": [2614, 322, 264, 1185, 11, 2497, 316, 293, 2497, 363, 13], "temperature": 0.0, "avg_logprob": -0.11203610897064209, "compression_ratio": 1.6502242152466369, "no_speech_prob": 5.6261113059008494e-05}, {"id": 76, "seek": 33456, "start": 345.0, "end": 349.92, "text": " And let's say that pod A has one CPU share and pod B has two CPU shares.", "tokens": [400, 718, 311, 584, 300, 2497, 316, 575, 472, 13199, 2073, 293, 2497, 363, 575, 732, 13199, 12182, 13], "temperature": 0.0, "avg_logprob": -0.11203610897064209, "compression_ratio": 1.6502242152466369, "no_speech_prob": 5.6261113059008494e-05}, {"id": 77, "seek": 33456, "start": 349.92, "end": 357.28, "text": " What it would mean is that pod B would have twice as CPU time as pod A. It doesn't really", "tokens": [708, 309, 576, 914, 307, 300, 2497, 363, 576, 362, 6091, 382, 13199, 565, 382, 2497, 316, 13, 467, 1177, 380, 534], "temperature": 0.0, "avg_logprob": -0.11203610897064209, "compression_ratio": 1.6502242152466369, "no_speech_prob": 5.6261113059008494e-05}, {"id": 78, "seek": 33456, "start": 357.28, "end": 362.28, "text": " matter how many CPUs the nodes have, because this is all relative, right?", "tokens": [1871, 577, 867, 13199, 82, 264, 13891, 362, 11, 570, 341, 307, 439, 4972, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.11203610897064209, "compression_ratio": 1.6502242152466369, "no_speech_prob": 5.6261113059008494e-05}, {"id": 79, "seek": 36228, "start": 362.28, "end": 370.2, "text": " So how does Kubernetes convert between the absolute values and the relative shares?", "tokens": [407, 577, 775, 23145, 7620, 1296, 264, 8236, 4190, 293, 264, 4972, 12182, 30], "temperature": 0.0, "avg_logprob": -0.07470008305140904, "compression_ratio": 1.3804347826086956, "no_speech_prob": 5.723414142266847e-05}, {"id": 80, "seek": 36228, "start": 370.2, "end": 377.32, "text": " So we can think about one CPU as 1024 shares, just because it's the default in C groups.", "tokens": [407, 321, 393, 519, 466, 472, 13199, 382, 1266, 7911, 12182, 11, 445, 570, 309, 311, 264, 7576, 294, 383, 3935, 13], "temperature": 0.0, "avg_logprob": -0.07470008305140904, "compression_ratio": 1.3804347826086956, "no_speech_prob": 5.723414142266847e-05}, {"id": 81, "seek": 36228, "start": 377.32, "end": 380.67999999999995, "text": " So let's say that a pod asks for 200M CPUs.", "tokens": [407, 718, 311, 584, 300, 257, 2497, 8962, 337, 2331, 44, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.07470008305140904, "compression_ratio": 1.3804347826086956, "no_speech_prob": 5.723414142266847e-05}, {"id": 82, "seek": 36228, "start": 380.67999999999995, "end": 383.32, "text": " So this is actually a fifth of a CPU.", "tokens": [407, 341, 307, 767, 257, 9266, 295, 257, 13199, 13], "temperature": 0.0, "avg_logprob": -0.07470008305140904, "compression_ratio": 1.3804347826086956, "no_speech_prob": 5.723414142266847e-05}, {"id": 83, "seek": 38332, "start": 383.32, "end": 392.96, "text": " So what we can do is divide 1024 by 5 and we get approximately 205 shares.", "tokens": [407, 437, 321, 393, 360, 307, 9845, 1266, 7911, 538, 1025, 293, 321, 483, 10447, 945, 20, 12182, 13], "temperature": 0.0, "avg_logprob": -0.09860771179199218, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.1467479453131091e-05}, {"id": 84, "seek": 38332, "start": 392.96, "end": 396.8, "text": " And this would work, but remember that shares are still relative.", "tokens": [400, 341, 576, 589, 11, 457, 1604, 300, 12182, 366, 920, 4972, 13], "temperature": 0.0, "avg_logprob": -0.09860771179199218, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.1467479453131091e-05}, {"id": 85, "seek": 38332, "start": 396.8, "end": 404.76, "text": " So what happens, for example, if the node has 100 CPUs and one pod with 200M CPUs request", "tokens": [407, 437, 2314, 11, 337, 1365, 11, 498, 264, 9984, 575, 2319, 13199, 82, 293, 472, 2497, 365, 2331, 44, 13199, 82, 5308], "temperature": 0.0, "avg_logprob": -0.09860771179199218, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.1467479453131091e-05}, {"id": 86, "seek": 38332, "start": 404.76, "end": 406.52, "text": " runs on that pod?", "tokens": [6676, 322, 300, 2497, 30], "temperature": 0.0, "avg_logprob": -0.09860771179199218, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.1467479453131091e-05}, {"id": 87, "seek": 38332, "start": 406.52, "end": 410.1, "text": " Since it's relative, it would just use all of the node's resources, right?", "tokens": [4162, 309, 311, 4972, 11, 309, 576, 445, 764, 439, 295, 264, 9984, 311, 3593, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.09860771179199218, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.1467479453131091e-05}, {"id": 88, "seek": 38332, "start": 410.1, "end": 412.32, "text": " So this has a nice side effect.", "tokens": [407, 341, 575, 257, 1481, 1252, 1802, 13], "temperature": 0.0, "avg_logprob": -0.09860771179199218, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.1467479453131091e-05}, {"id": 89, "seek": 41232, "start": 412.32, "end": 421.52, "text": " The spare resources on the node can be used by the pod relatively to their request.", "tokens": [440, 13798, 3593, 322, 264, 9984, 393, 312, 1143, 538, 264, 2497, 7226, 281, 641, 5308, 13], "temperature": 0.0, "avg_logprob": -0.13911894748085424, "compression_ratio": 1.7105263157894737, "no_speech_prob": 8.692579285707325e-05}, {"id": 90, "seek": 41232, "start": 421.52, "end": 425.8, "text": " So basically the request is the minimum amount that is actually allocated and all of the", "tokens": [407, 1936, 264, 5308, 307, 264, 7285, 2372, 300, 307, 767, 29772, 293, 439, 295, 264], "temperature": 0.0, "avg_logprob": -0.13911894748085424, "compression_ratio": 1.7105263157894737, "no_speech_prob": 8.692579285707325e-05}, {"id": 91, "seek": 41232, "start": 425.8, "end": 434.28, "text": " spare resources are being split relatively to their request.", "tokens": [13798, 3593, 366, 885, 7472, 7226, 281, 641, 5308, 13], "temperature": 0.0, "avg_logprob": -0.13911894748085424, "compression_ratio": 1.7105263157894737, "no_speech_prob": 8.692579285707325e-05}, {"id": 92, "seek": 41232, "start": 434.28, "end": 438.08, "text": " So let's talk about Kubernetes QoS for a second.", "tokens": [407, 718, 311, 751, 466, 23145, 1249, 78, 50, 337, 257, 1150, 13], "temperature": 0.0, "avg_logprob": -0.13911894748085424, "compression_ratio": 1.7105263157894737, "no_speech_prob": 8.692579285707325e-05}, {"id": 93, "seek": 41232, "start": 438.08, "end": 441.28, "text": " There are three quality of service levels.", "tokens": [821, 366, 1045, 3125, 295, 2643, 4358, 13], "temperature": 0.0, "avg_logprob": -0.13911894748085424, "compression_ratio": 1.7105263157894737, "no_speech_prob": 8.692579285707325e-05}, {"id": 94, "seek": 44128, "start": 441.28, "end": 443.08, "text": " The first one is best effort.", "tokens": [440, 700, 472, 307, 1151, 4630, 13], "temperature": 0.0, "avg_logprob": -0.1214435062711201, "compression_ratio": 1.864, "no_speech_prob": 7.125167030608281e-05}, {"id": 95, "seek": 44128, "start": 443.08, "end": 445.08, "text": " That means that I don't specify anything.", "tokens": [663, 1355, 300, 286, 500, 380, 16500, 1340, 13], "temperature": 0.0, "avg_logprob": -0.1214435062711201, "compression_ratio": 1.864, "no_speech_prob": 7.125167030608281e-05}, {"id": 96, "seek": 44128, "start": 445.08, "end": 450.76, "text": " I don't have request, I don't have limits, not for memory and not for CPU.", "tokens": [286, 500, 380, 362, 5308, 11, 286, 500, 380, 362, 10406, 11, 406, 337, 4675, 293, 406, 337, 13199, 13], "temperature": 0.0, "avg_logprob": -0.1214435062711201, "compression_ratio": 1.864, "no_speech_prob": 7.125167030608281e-05}, {"id": 97, "seek": 44128, "start": 450.76, "end": 454.08, "text": " The last one, guaranteed, is kind of the opposite from that.", "tokens": [440, 1036, 472, 11, 18031, 11, 307, 733, 295, 264, 6182, 490, 300, 13], "temperature": 0.0, "avg_logprob": -0.1214435062711201, "compression_ratio": 1.864, "no_speech_prob": 7.125167030608281e-05}, {"id": 98, "seek": 44128, "start": 454.08, "end": 458.76, "text": " I specify both request and limits to both CPUs and memory and the request and limits", "tokens": [286, 16500, 1293, 5308, 293, 10406, 281, 1293, 13199, 82, 293, 4675, 293, 264, 5308, 293, 10406], "temperature": 0.0, "avg_logprob": -0.1214435062711201, "compression_ratio": 1.864, "no_speech_prob": 7.125167030608281e-05}, {"id": 99, "seek": 44128, "start": 458.76, "end": 460.67999999999995, "text": " are equal.", "tokens": [366, 2681, 13], "temperature": 0.0, "avg_logprob": -0.1214435062711201, "compression_ratio": 1.864, "no_speech_prob": 7.125167030608281e-05}, {"id": 100, "seek": 44128, "start": 460.67999999999995, "end": 464.76, "text": " Now if you're not best effort and you're not guaranteed, you'd be burstable.", "tokens": [823, 498, 291, 434, 406, 1151, 4630, 293, 291, 434, 406, 18031, 11, 291, 1116, 312, 12712, 712, 13], "temperature": 0.0, "avg_logprob": -0.1214435062711201, "compression_ratio": 1.864, "no_speech_prob": 7.125167030608281e-05}, {"id": 101, "seek": 44128, "start": 464.76, "end": 470.44, "text": " So this is just an example, but the idea is that you can specify either only request,", "tokens": [407, 341, 307, 445, 364, 1365, 11, 457, 264, 1558, 307, 300, 291, 393, 16500, 2139, 787, 5308, 11], "temperature": 0.0, "avg_logprob": -0.1214435062711201, "compression_ratio": 1.864, "no_speech_prob": 7.125167030608281e-05}, {"id": 102, "seek": 47044, "start": 470.44, "end": 473.0, "text": " only limits, you can specify them both, but they're not equal.", "tokens": [787, 10406, 11, 291, 393, 16500, 552, 1293, 11, 457, 436, 434, 406, 2681, 13], "temperature": 0.0, "avg_logprob": -0.14212945450183956, "compression_ratio": 1.748768472906404, "no_speech_prob": 5.8975339925382286e-05}, {"id": 103, "seek": 47044, "start": 473.0, "end": 480.08, "text": " So any other than best effort and guaranteed.", "tokens": [407, 604, 661, 813, 1151, 4630, 293, 18031, 13], "temperature": 0.0, "avg_logprob": -0.14212945450183956, "compression_ratio": 1.748768472906404, "no_speech_prob": 5.8975339925382286e-05}, {"id": 104, "seek": 47044, "start": 480.08, "end": 485.32, "text": " Now basically the trade-off here is predictability in order to get stability.", "tokens": [823, 1936, 264, 4923, 12, 4506, 510, 307, 6069, 2310, 294, 1668, 281, 483, 11826, 13], "temperature": 0.0, "avg_logprob": -0.14212945450183956, "compression_ratio": 1.748768472906404, "no_speech_prob": 5.8975339925382286e-05}, {"id": 105, "seek": 47044, "start": 485.32, "end": 490.88, "text": " So basically Kubernetes tells you, if you want me to guarantee you stability, you have", "tokens": [407, 1936, 23145, 5112, 291, 11, 498, 291, 528, 385, 281, 10815, 291, 11826, 11, 291, 362], "temperature": 0.0, "avg_logprob": -0.14212945450183956, "compression_ratio": 1.748768472906404, "no_speech_prob": 5.8975339925382286e-05}, {"id": 106, "seek": 47044, "start": 490.88, "end": 496.96, "text": " to be predictable or if you will be more predictable, you'll gain more stability.", "tokens": [281, 312, 27737, 420, 498, 291, 486, 312, 544, 27737, 11, 291, 603, 6052, 544, 11826, 13], "temperature": 0.0, "avg_logprob": -0.14212945450183956, "compression_ratio": 1.748768472906404, "no_speech_prob": 5.8975339925382286e-05}, {"id": 107, "seek": 49696, "start": 496.96, "end": 502.35999999999996, "text": " Like one example for that, if we're talking about memory for example, are node pressures.", "tokens": [1743, 472, 1365, 337, 300, 11, 498, 321, 434, 1417, 466, 4675, 337, 1365, 11, 366, 9984, 23573, 13], "temperature": 0.0, "avg_logprob": -0.1561316898890904, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.2211118701088708e-05}, {"id": 108, "seek": 49696, "start": 502.35999999999996, "end": 509.84, "text": " So when the node would have high memory pressure, it would evict guaranteed QoS pods last.", "tokens": [407, 562, 264, 9984, 576, 362, 1090, 4675, 3321, 11, 309, 576, 1073, 985, 18031, 1249, 78, 50, 31925, 1036, 13], "temperature": 0.0, "avg_logprob": -0.1561316898890904, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.2211118701088708e-05}, {"id": 109, "seek": 49696, "start": 509.84, "end": 515.6, "text": " And after that it would get to burstable, after that it would get to best efforts.", "tokens": [400, 934, 300, 309, 576, 483, 281, 12712, 712, 11, 934, 300, 309, 576, 483, 281, 1151, 6484, 13], "temperature": 0.0, "avg_logprob": -0.1561316898890904, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.2211118701088708e-05}, {"id": 110, "seek": 49696, "start": 515.6, "end": 519.24, "text": " So this is true by the way, as long as you keep your promises.", "tokens": [407, 341, 307, 2074, 538, 264, 636, 11, 382, 938, 382, 291, 1066, 428, 16403, 13], "temperature": 0.0, "avg_logprob": -0.1561316898890904, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.2211118701088708e-05}, {"id": 111, "seek": 49696, "start": 519.24, "end": 523.28, "text": " If you say that you're limited to a certain amount of memory and then you exceed this", "tokens": [759, 291, 584, 300, 291, 434, 5567, 281, 257, 1629, 2372, 295, 4675, 293, 550, 291, 14048, 341], "temperature": 0.0, "avg_logprob": -0.1561316898890904, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.2211118701088708e-05}, {"id": 112, "seek": 52328, "start": 523.28, "end": 533.16, "text": " memory, then on most CRIs we'll just kill the pod.", "tokens": [4675, 11, 550, 322, 881, 383, 5577, 82, 321, 603, 445, 1961, 264, 2497, 13], "temperature": 0.0, "avg_logprob": -0.19651924809323082, "compression_ratio": 1.3636363636363635, "no_speech_prob": 2.075521115330048e-05}, {"id": 113, "seek": 52328, "start": 533.16, "end": 536.0799999999999, "text": " So can we use dedicated CPUs on Kubernetes?", "tokens": [407, 393, 321, 764, 8374, 13199, 82, 322, 23145, 30], "temperature": 0.0, "avg_logprob": -0.19651924809323082, "compression_ratio": 1.3636363636363635, "no_speech_prob": 2.075521115330048e-05}, {"id": 114, "seek": 52328, "start": 536.0799999999999, "end": 537.76, "text": " So the answer is yes.", "tokens": [407, 264, 1867, 307, 2086, 13], "temperature": 0.0, "avg_logprob": -0.19651924809323082, "compression_ratio": 1.3636363636363635, "no_speech_prob": 2.075521115330048e-05}, {"id": 115, "seek": 52328, "start": 537.76, "end": 541.16, "text": " This is possible with CPU manager.", "tokens": [639, 307, 1944, 365, 13199, 6598, 13], "temperature": 0.0, "avg_logprob": -0.19651924809323082, "compression_ratio": 1.3636363636363635, "no_speech_prob": 2.075521115330048e-05}, {"id": 116, "seek": 52328, "start": 541.16, "end": 545.76, "text": " And in order to do that, we have two requirements.", "tokens": [400, 294, 1668, 281, 360, 300, 11, 321, 362, 732, 7728, 13], "temperature": 0.0, "avg_logprob": -0.19651924809323082, "compression_ratio": 1.3636363636363635, "no_speech_prob": 2.075521115330048e-05}, {"id": 117, "seek": 52328, "start": 545.76, "end": 549.6, "text": " First of all, the pod needs to be of guaranteed QoS.", "tokens": [2386, 295, 439, 11, 264, 2497, 2203, 281, 312, 295, 18031, 1249, 78, 50, 13], "temperature": 0.0, "avg_logprob": -0.19651924809323082, "compression_ratio": 1.3636363636363635, "no_speech_prob": 2.075521115330048e-05}, {"id": 118, "seek": 54960, "start": 549.6, "end": 554.08, "text": " Second of all, the CPU request, which equals the limit because it's a guaranteed QoS, has", "tokens": [5736, 295, 439, 11, 264, 13199, 5308, 11, 597, 6915, 264, 4948, 570, 309, 311, 257, 18031, 1249, 78, 50, 11, 575], "temperature": 0.0, "avg_logprob": -0.10740455473312224, "compression_ratio": 1.5866666666666667, "no_speech_prob": 2.251331170555204e-05}, {"id": 119, "seek": 54960, "start": 554.08, "end": 555.28, "text": " to be an integer.", "tokens": [281, 312, 364, 24922, 13], "temperature": 0.0, "avg_logprob": -0.10740455473312224, "compression_ratio": 1.5866666666666667, "no_speech_prob": 2.251331170555204e-05}, {"id": 120, "seek": 54960, "start": 555.28, "end": 560.44, "text": " It cannot be a floating point value.", "tokens": [467, 2644, 312, 257, 12607, 935, 2158, 13], "temperature": 0.0, "avg_logprob": -0.10740455473312224, "compression_ratio": 1.5866666666666667, "no_speech_prob": 2.251331170555204e-05}, {"id": 121, "seek": 54960, "start": 560.44, "end": 564.72, "text": " Also an interesting fact is that only a single container or some of the containers in a pod", "tokens": [2743, 364, 1880, 1186, 307, 300, 787, 257, 2167, 10129, 420, 512, 295, 264, 17089, 294, 257, 2497], "temperature": 0.0, "avg_logprob": -0.10740455473312224, "compression_ratio": 1.5866666666666667, "no_speech_prob": 2.251331170555204e-05}, {"id": 122, "seek": 54960, "start": 564.72, "end": 574.0600000000001, "text": " can have dedicated CPUs, but the whole pod needs to be of a guaranteed QoS.", "tokens": [393, 362, 8374, 13199, 82, 11, 457, 264, 1379, 2497, 2203, 281, 312, 295, 257, 18031, 1249, 78, 50, 13], "temperature": 0.0, "avg_logprob": -0.10740455473312224, "compression_ratio": 1.5866666666666667, "no_speech_prob": 2.251331170555204e-05}, {"id": 123, "seek": 54960, "start": 574.0600000000001, "end": 576.88, "text": " So let's talk about namespaces for a second.", "tokens": [407, 718, 311, 751, 466, 5288, 79, 2116, 337, 257, 1150, 13], "temperature": 0.0, "avg_logprob": -0.10740455473312224, "compression_ratio": 1.5866666666666667, "no_speech_prob": 2.251331170555204e-05}, {"id": 124, "seek": 57688, "start": 576.88, "end": 581.56, "text": " So remember this little diagram from before, so namespaces is another building block for", "tokens": [407, 1604, 341, 707, 10686, 490, 949, 11, 370, 5288, 79, 2116, 307, 1071, 2390, 3461, 337], "temperature": 0.0, "avg_logprob": -0.13842496871948243, "compression_ratio": 1.6266666666666667, "no_speech_prob": 9.002211299957708e-05}, {"id": 125, "seek": 57688, "start": 581.56, "end": 586.0, "text": " containers and it basically is responsible for the isolation of the containers.", "tokens": [17089, 293, 309, 1936, 307, 6250, 337, 264, 16001, 295, 264, 17089, 13], "temperature": 0.0, "avg_logprob": -0.13842496871948243, "compression_ratio": 1.6266666666666667, "no_speech_prob": 9.002211299957708e-05}, {"id": 126, "seek": 57688, "start": 586.0, "end": 590.2, "text": " So when I'm picturing a pod, this is what I think about.", "tokens": [407, 562, 286, 478, 2317, 1345, 257, 2497, 11, 341, 307, 437, 286, 519, 466, 13], "temperature": 0.0, "avg_logprob": -0.13842496871948243, "compression_ratio": 1.6266666666666667, "no_speech_prob": 9.002211299957708e-05}, {"id": 127, "seek": 57688, "start": 590.2, "end": 593.16, "text": " Like it's a box with some containers in it.", "tokens": [1743, 309, 311, 257, 2424, 365, 512, 17089, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.13842496871948243, "compression_ratio": 1.6266666666666667, "no_speech_prob": 9.002211299957708e-05}, {"id": 128, "seek": 57688, "start": 593.16, "end": 597.68, "text": " The containers are absolutely isolated from one another.", "tokens": [440, 17089, 366, 3122, 14621, 490, 472, 1071, 13], "temperature": 0.0, "avg_logprob": -0.13842496871948243, "compression_ratio": 1.6266666666666667, "no_speech_prob": 9.002211299957708e-05}, {"id": 129, "seek": 57688, "start": 597.68, "end": 603.88, "text": " And as we said, container is a concept.", "tokens": [400, 382, 321, 848, 11, 10129, 307, 257, 3410, 13], "temperature": 0.0, "avg_logprob": -0.13842496871948243, "compression_ratio": 1.6266666666666667, "no_speech_prob": 9.002211299957708e-05}, {"id": 130, "seek": 60388, "start": 603.88, "end": 611.08, "text": " So if we will take some of the namespaces out and we will break some of the isolations", "tokens": [407, 498, 321, 486, 747, 512, 295, 264, 5288, 79, 2116, 484, 293, 321, 486, 1821, 512, 295, 264, 7381, 763], "temperature": 0.0, "avg_logprob": -0.17502865967927156, "compression_ratio": 1.8008474576271187, "no_speech_prob": 3.6798970540985465e-05}, {"id": 131, "seek": 60388, "start": 611.08, "end": 612.08, "text": " between the containers.", "tokens": [1296, 264, 17089, 13], "temperature": 0.0, "avg_logprob": -0.17502865967927156, "compression_ratio": 1.8008474576271187, "no_speech_prob": 3.6798970540985465e-05}, {"id": 132, "seek": 60388, "start": 612.08, "end": 614.04, "text": " Are there still containers?", "tokens": [2014, 456, 920, 17089, 30], "temperature": 0.0, "avg_logprob": -0.17502865967927156, "compression_ratio": 1.8008474576271187, "no_speech_prob": 3.6798970540985465e-05}, {"id": 133, "seek": 60388, "start": 614.04, "end": 619.28, "text": " How do we need to, how layers of isolation do we need to strip before it stops being", "tokens": [1012, 360, 321, 643, 281, 11, 577, 7914, 295, 16001, 360, 321, 643, 281, 12828, 949, 309, 10094, 885], "temperature": 0.0, "avg_logprob": -0.17502865967927156, "compression_ratio": 1.8008474576271187, "no_speech_prob": 3.6798970540985465e-05}, {"id": 134, "seek": 60388, "start": 619.28, "end": 620.78, "text": " a container?", "tokens": [257, 10129, 30], "temperature": 0.0, "avg_logprob": -0.17502865967927156, "compression_ratio": 1.8008474576271187, "no_speech_prob": 3.6798970540985465e-05}, {"id": 135, "seek": 60388, "start": 620.78, "end": 625.52, "text": " This is more of a philosophical question, but is it possible on Kubernetes and the answer", "tokens": [639, 307, 544, 295, 257, 25066, 1168, 11, 457, 307, 309, 1944, 322, 23145, 293, 264, 1867], "temperature": 0.0, "avg_logprob": -0.17502865967927156, "compression_ratio": 1.8008474576271187, "no_speech_prob": 3.6798970540985465e-05}, {"id": 136, "seek": 60388, "start": 625.52, "end": 627.04, "text": " is yes.", "tokens": [307, 2086, 13], "temperature": 0.0, "avg_logprob": -0.17502865967927156, "compression_ratio": 1.8008474576271187, "no_speech_prob": 3.6798970540985465e-05}, {"id": 137, "seek": 60388, "start": 627.04, "end": 632.84, "text": " So for example, it's possible to share the pod namespace between containers or the process", "tokens": [407, 337, 1365, 11, 309, 311, 1944, 281, 2073, 264, 2497, 5288, 17940, 1296, 17089, 420, 264, 1399], "temperature": 0.0, "avg_logprob": -0.17502865967927156, "compression_ratio": 1.8008474576271187, "no_speech_prob": 3.6798970540985465e-05}, {"id": 138, "seek": 63284, "start": 632.84, "end": 634.0, "text": " namespace between containers.", "tokens": [5288, 17940, 1296, 17089, 13], "temperature": 0.0, "avg_logprob": -0.1791508094124172, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0001173603450297378}, {"id": 139, "seek": 63284, "start": 634.0, "end": 639.5600000000001, "text": " And what it means is that inside the container, if you will do something like PS, you would", "tokens": [400, 437, 309, 1355, 307, 300, 1854, 264, 10129, 11, 498, 291, 486, 360, 746, 411, 8168, 11, 291, 576], "temperature": 0.0, "avg_logprob": -0.1791508094124172, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0001173603450297378}, {"id": 140, "seek": 63284, "start": 639.5600000000001, "end": 642.44, "text": " see all of the processes from all of the containers.", "tokens": [536, 439, 295, 264, 7555, 490, 439, 295, 264, 17089, 13], "temperature": 0.0, "avg_logprob": -0.1791508094124172, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0001173603450297378}, {"id": 141, "seek": 63284, "start": 642.44, "end": 646.0400000000001, "text": " This isolation will not exist anymore.", "tokens": [639, 16001, 486, 406, 2514, 3602, 13], "temperature": 0.0, "avg_logprob": -0.1791508094124172, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0001173603450297378}, {"id": 142, "seek": 63284, "start": 646.0400000000001, "end": 651.0400000000001, "text": " Another interesting fact is that as a side effect, the file systems are also shared.", "tokens": [3996, 1880, 1186, 307, 300, 382, 257, 1252, 1802, 11, 264, 3991, 3652, 366, 611, 5507, 13], "temperature": 0.0, "avg_logprob": -0.1791508094124172, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0001173603450297378}, {"id": 143, "seek": 63284, "start": 651.0400000000001, "end": 657.84, "text": " Now they're not shared directly, but you can use that trick to use them indirectly.", "tokens": [823, 436, 434, 406, 5507, 3838, 11, 457, 291, 393, 764, 300, 4282, 281, 764, 552, 37779, 13], "temperature": 0.0, "avg_logprob": -0.1791508094124172, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0001173603450297378}, {"id": 144, "seek": 65784, "start": 657.84, "end": 666.72, "text": " We'll get you to the root file system of another process that now can be in another container.", "tokens": [492, 603, 483, 291, 281, 264, 5593, 3991, 1185, 295, 1071, 1399, 300, 586, 393, 312, 294, 1071, 10129, 13], "temperature": 0.0, "avg_logprob": -0.2083282470703125, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0001417159364791587}, {"id": 145, "seek": 65784, "start": 666.72, "end": 671.36, "text": " So to actually enable that, that's what you need to do.", "tokens": [407, 281, 767, 9528, 300, 11, 300, 311, 437, 291, 643, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.2083282470703125, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0001417159364791587}, {"id": 146, "seek": 65784, "start": 671.36, "end": 679.6, "text": " In the pod, in the spec, share process namespace, true, and that's it.", "tokens": [682, 264, 2497, 11, 294, 264, 1608, 11, 2073, 1399, 5288, 17940, 11, 2074, 11, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.2083282470703125, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0001417159364791587}, {"id": 147, "seek": 65784, "start": 679.6, "end": 681.88, "text": " So now a word about KVM.", "tokens": [407, 586, 257, 1349, 466, 591, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.2083282470703125, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0001417159364791587}, {"id": 148, "seek": 65784, "start": 681.88, "end": 684.32, "text": " So who knows KVM, by the way?", "tokens": [407, 567, 3255, 591, 53, 44, 11, 538, 264, 636, 30], "temperature": 0.0, "avg_logprob": -0.2083282470703125, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0001417159364791587}, {"id": 149, "seek": 65784, "start": 684.32, "end": 686.88, "text": " Oh, a lot of you, okay.", "tokens": [876, 11, 257, 688, 295, 291, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.2083282470703125, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0001417159364791587}, {"id": 150, "seek": 68688, "start": 686.88, "end": 691.28, "text": " So this is a kernel model which turns the Linux into a hypervisor.", "tokens": [407, 341, 307, 257, 28256, 2316, 597, 4523, 264, 18734, 666, 257, 9848, 16457, 13], "temperature": 0.0, "avg_logprob": -0.12436851660410563, "compression_ratio": 1.7153846153846153, "no_speech_prob": 8.588632772443816e-05}, {"id": 151, "seek": 68688, "start": 691.28, "end": 694.88, "text": " Basically we have two kinds of hypervisors, type one and type two.", "tokens": [8537, 321, 362, 732, 3685, 295, 9848, 4938, 830, 11, 2010, 472, 293, 2010, 732, 13], "temperature": 0.0, "avg_logprob": -0.12436851660410563, "compression_ratio": 1.7153846153846153, "no_speech_prob": 8.588632772443816e-05}, {"id": 152, "seek": 68688, "start": 694.88, "end": 699.36, "text": " Type one means that it's also called a bare metal hypervisor because it's being installed", "tokens": [15576, 472, 1355, 300, 309, 311, 611, 1219, 257, 6949, 5760, 9848, 16457, 570, 309, 311, 885, 8899], "temperature": 0.0, "avg_logprob": -0.12436851660410563, "compression_ratio": 1.7153846153846153, "no_speech_prob": 8.588632772443816e-05}, {"id": 153, "seek": 68688, "start": 699.36, "end": 700.36, "text": " on a bare metal.", "tokens": [322, 257, 6949, 5760, 13], "temperature": 0.0, "avg_logprob": -0.12436851660410563, "compression_ratio": 1.7153846153846153, "no_speech_prob": 8.588632772443816e-05}, {"id": 154, "seek": 68688, "start": 700.36, "end": 702.76, "text": " There's no OS benefit.", "tokens": [821, 311, 572, 12731, 5121, 13], "temperature": 0.0, "avg_logprob": -0.12436851660410563, "compression_ratio": 1.7153846153846153, "no_speech_prob": 8.588632772443816e-05}, {"id": 155, "seek": 68688, "start": 702.76, "end": 707.8, "text": " And what it means is that it's really fast, but the downside is that it has to implement", "tokens": [400, 437, 309, 1355, 307, 300, 309, 311, 534, 2370, 11, 457, 264, 25060, 307, 300, 309, 575, 281, 4445], "temperature": 0.0, "avg_logprob": -0.12436851660410563, "compression_ratio": 1.7153846153846153, "no_speech_prob": 8.588632772443816e-05}, {"id": 156, "seek": 68688, "start": 707.8, "end": 712.28, "text": " stuff like a scheduler, a virtual memory, and a lot of stuff that already exists on every", "tokens": [1507, 411, 257, 12000, 260, 11, 257, 6374, 4675, 11, 293, 257, 688, 295, 1507, 300, 1217, 8198, 322, 633], "temperature": 0.0, "avg_logprob": -0.12436851660410563, "compression_ratio": 1.7153846153846153, "no_speech_prob": 8.588632772443816e-05}, {"id": 157, "seek": 68688, "start": 712.28, "end": 713.72, "text": " OS.", "tokens": [12731, 13], "temperature": 0.0, "avg_logprob": -0.12436851660410563, "compression_ratio": 1.7153846153846153, "no_speech_prob": 8.588632772443816e-05}, {"id": 158, "seek": 71372, "start": 713.72, "end": 718.28, "text": " Type two hypervisors are being installed on top of the OS, so they don't have to re-implement", "tokens": [15576, 732, 9848, 4938, 830, 366, 885, 8899, 322, 1192, 295, 264, 12731, 11, 370, 436, 500, 380, 362, 281, 319, 12, 332, 43704], "temperature": 0.0, "avg_logprob": -0.14323821157779335, "compression_ratio": 1.5866141732283465, "no_speech_prob": 3.1656854844186455e-05}, {"id": 159, "seek": 71372, "start": 718.28, "end": 721.6, "text": " all of those stuff, but they're usually a lot slower.", "tokens": [439, 295, 729, 1507, 11, 457, 436, 434, 2673, 257, 688, 14009, 13], "temperature": 0.0, "avg_logprob": -0.14323821157779335, "compression_ratio": 1.5866141732283465, "no_speech_prob": 3.1656854844186455e-05}, {"id": 160, "seek": 71372, "start": 721.6, "end": 726.96, "text": " So KVM is really incredible because it turns Linux into a type one hypervisor.", "tokens": [407, 591, 53, 44, 307, 534, 4651, 570, 309, 4523, 18734, 666, 257, 2010, 472, 9848, 16457, 13], "temperature": 0.0, "avg_logprob": -0.14323821157779335, "compression_ratio": 1.5866141732283465, "no_speech_prob": 3.1656854844186455e-05}, {"id": 161, "seek": 71372, "start": 726.96, "end": 734.1600000000001, "text": " And this is what Qvert is using to gain native performance.", "tokens": [400, 341, 307, 437, 1249, 3281, 307, 1228, 281, 6052, 8470, 3389, 13], "temperature": 0.0, "avg_logprob": -0.14323821157779335, "compression_ratio": 1.5866141732283465, "no_speech_prob": 3.1656854844186455e-05}, {"id": 162, "seek": 71372, "start": 734.1600000000001, "end": 738.8000000000001, "text": " An interesting fact about a KVM is that its main purpose is CPU virtualization because", "tokens": [1107, 1880, 1186, 466, 257, 591, 53, 44, 307, 300, 1080, 2135, 4334, 307, 13199, 6374, 2144, 570], "temperature": 0.0, "avg_logprob": -0.14323821157779335, "compression_ratio": 1.5866141732283465, "no_speech_prob": 3.1656854844186455e-05}, {"id": 163, "seek": 71372, "start": 738.8000000000001, "end": 742.0400000000001, "text": " this is the performance part.", "tokens": [341, 307, 264, 3389, 644, 13], "temperature": 0.0, "avg_logprob": -0.14323821157779335, "compression_ratio": 1.5866141732283465, "no_speech_prob": 3.1656854844186455e-05}, {"id": 164, "seek": 74204, "start": 742.04, "end": 748.16, "text": " It's also backed by QEMU, which does things like IO and stuff like that, which are usually", "tokens": [467, 311, 611, 20391, 538, 1249, 6683, 52, 11, 597, 775, 721, 411, 39839, 293, 1507, 411, 300, 11, 597, 366, 2673], "temperature": 0.0, "avg_logprob": -0.1490032809904252, "compression_ratio": 1.427860696517413, "no_speech_prob": 3.9376278436975554e-05}, {"id": 165, "seek": 74204, "start": 748.16, "end": 753.48, "text": " less related to performance.", "tokens": [1570, 4077, 281, 3389, 13], "temperature": 0.0, "avg_logprob": -0.1490032809904252, "compression_ratio": 1.427860696517413, "no_speech_prob": 3.9376278436975554e-05}, {"id": 166, "seek": 74204, "start": 753.48, "end": 756.64, "text": " So how does KVM actually works?", "tokens": [407, 577, 775, 591, 53, 44, 767, 1985, 30], "temperature": 0.0, "avg_logprob": -0.1490032809904252, "compression_ratio": 1.427860696517413, "no_speech_prob": 3.9376278436975554e-05}, {"id": 167, "seek": 74204, "start": 756.64, "end": 761.9599999999999, "text": " So from the guest perspective, it will have, for example, four CPUs.", "tokens": [407, 490, 264, 8341, 4585, 11, 309, 486, 362, 11, 337, 1365, 11, 1451, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.1490032809904252, "compression_ratio": 1.427860696517413, "no_speech_prob": 3.9376278436975554e-05}, {"id": 168, "seek": 74204, "start": 761.9599999999999, "end": 764.12, "text": " But these aren't real CPUs, right?", "tokens": [583, 613, 3212, 380, 957, 13199, 82, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1490032809904252, "compression_ratio": 1.427860696517413, "no_speech_prob": 3.9376278436975554e-05}, {"id": 169, "seek": 74204, "start": 764.12, "end": 766.8, "text": " They are virtual CPUs or VCPUs.", "tokens": [814, 366, 6374, 13199, 82, 420, 41922, 8115, 82, 13], "temperature": 0.0, "avg_logprob": -0.1490032809904252, "compression_ratio": 1.427860696517413, "no_speech_prob": 3.9376278436975554e-05}, {"id": 170, "seek": 76680, "start": 766.8, "end": 772.68, "text": " And from the kernel perspective, these are just threads, VCPU threads.", "tokens": [400, 490, 264, 28256, 4585, 11, 613, 366, 445, 19314, 11, 41922, 8115, 19314, 13], "temperature": 0.0, "avg_logprob": -0.18139497439066568, "compression_ratio": 1.6278026905829597, "no_speech_prob": 2.7429565307102166e-05}, {"id": 171, "seek": 76680, "start": 772.68, "end": 778.8399999999999, "text": " So what the guest sees as a physical CPU is actually from the host perspective is just", "tokens": [407, 437, 264, 8341, 8194, 382, 257, 4001, 13199, 307, 767, 490, 264, 3975, 4585, 307, 445], "temperature": 0.0, "avg_logprob": -0.18139497439066568, "compression_ratio": 1.6278026905829597, "no_speech_prob": 2.7429565307102166e-05}, {"id": 172, "seek": 76680, "start": 778.8399999999999, "end": 780.92, "text": " another thread on the system.", "tokens": [1071, 7207, 322, 264, 1185, 13], "temperature": 0.0, "avg_logprob": -0.18139497439066568, "compression_ratio": 1.6278026905829597, "no_speech_prob": 2.7429565307102166e-05}, {"id": 173, "seek": 76680, "start": 780.92, "end": 787.0, "text": " Okay, so now back to Qvert after all of these introductions.", "tokens": [1033, 11, 370, 586, 646, 281, 1249, 3281, 934, 439, 295, 613, 48032, 13], "temperature": 0.0, "avg_logprob": -0.18139497439066568, "compression_ratio": 1.6278026905829597, "no_speech_prob": 2.7429565307102166e-05}, {"id": 174, "seek": 76680, "start": 787.0, "end": 789.38, "text": " In Qvert, we have the VRT Launcher pod.", "tokens": [682, 1249, 3281, 11, 321, 362, 264, 13722, 51, 28119, 260, 2497, 13], "temperature": 0.0, "avg_logprob": -0.18139497439066568, "compression_ratio": 1.6278026905829597, "no_speech_prob": 2.7429565307102166e-05}, {"id": 175, "seek": 76680, "start": 789.38, "end": 791.56, "text": " It has some containers in it.", "tokens": [467, 575, 512, 17089, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.18139497439066568, "compression_ratio": 1.6278026905829597, "no_speech_prob": 2.7429565307102166e-05}, {"id": 176, "seek": 76680, "start": 791.56, "end": 794.3599999999999, "text": " The compute container is the main container.", "tokens": [440, 14722, 10129, 307, 264, 2135, 10129, 13], "temperature": 0.0, "avg_logprob": -0.18139497439066568, "compression_ratio": 1.6278026905829597, "no_speech_prob": 2.7429565307102166e-05}, {"id": 177, "seek": 79436, "start": 794.36, "end": 800.84, "text": " Inside the compute container, we run the QEMU process, which actually runs the guest.", "tokens": [15123, 264, 14722, 10129, 11, 321, 1190, 264, 1249, 6683, 52, 1399, 11, 597, 767, 6676, 264, 8341, 13], "temperature": 0.0, "avg_logprob": -0.15538675444466726, "compression_ratio": 1.7010309278350515, "no_speech_prob": 1.8320166418561712e-05}, {"id": 178, "seek": 79436, "start": 800.84, "end": 806.04, "text": " And this is the main container that we're using.", "tokens": [400, 341, 307, 264, 2135, 10129, 300, 321, 434, 1228, 13], "temperature": 0.0, "avg_logprob": -0.15538675444466726, "compression_ratio": 1.7010309278350515, "no_speech_prob": 1.8320166418561712e-05}, {"id": 179, "seek": 79436, "start": 806.04, "end": 809.04, "text": " So first attempt to support dedicated CPUs.", "tokens": [407, 700, 5217, 281, 1406, 8374, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.15538675444466726, "compression_ratio": 1.7010309278350515, "no_speech_prob": 1.8320166418561712e-05}, {"id": 180, "seek": 79436, "start": 809.04, "end": 816.8000000000001, "text": " So the idea was let's allocate the compute container that we talked about with dedicated", "tokens": [407, 264, 1558, 390, 718, 311, 35713, 264, 14722, 10129, 300, 321, 2825, 466, 365, 8374], "temperature": 0.0, "avg_logprob": -0.15538675444466726, "compression_ratio": 1.7010309278350515, "no_speech_prob": 1.8320166418561712e-05}, {"id": 181, "seek": 79436, "start": 816.8000000000001, "end": 818.0, "text": " CPUs.", "tokens": [13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.15538675444466726, "compression_ratio": 1.7010309278350515, "no_speech_prob": 1.8320166418561712e-05}, {"id": 182, "seek": 79436, "start": 818.0, "end": 820.48, "text": " So this is possible with CPU manager as we talked about.", "tokens": [407, 341, 307, 1944, 365, 13199, 6598, 382, 321, 2825, 466, 13], "temperature": 0.0, "avg_logprob": -0.15538675444466726, "compression_ratio": 1.7010309278350515, "no_speech_prob": 1.8320166418561712e-05}, {"id": 183, "seek": 82048, "start": 820.48, "end": 825.5600000000001, "text": " All we need is to do is to have a pod that's guaranteed QS and to have an integer amount", "tokens": [1057, 321, 643, 307, 281, 360, 307, 281, 362, 257, 2497, 300, 311, 18031, 1249, 50, 293, 281, 362, 364, 24922, 2372], "temperature": 0.0, "avg_logprob": -0.1275485549310241, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.555407890118659e-05}, {"id": 184, "seek": 82048, "start": 825.5600000000001, "end": 831.32, "text": " of CPUs on the compute container.", "tokens": [295, 13199, 82, 322, 264, 14722, 10129, 13], "temperature": 0.0, "avg_logprob": -0.1275485549310241, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.555407890118659e-05}, {"id": 185, "seek": 82048, "start": 831.32, "end": 837.32, "text": " So by the way, is it a good approach, do you think?", "tokens": [407, 538, 264, 636, 11, 307, 309, 257, 665, 3109, 11, 360, 291, 519, 30], "temperature": 0.0, "avg_logprob": -0.1275485549310241, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.555407890118659e-05}, {"id": 186, "seek": 82048, "start": 837.32, "end": 840.6, "text": " This is a problem and let me explain you why.", "tokens": [639, 307, 257, 1154, 293, 718, 385, 2903, 291, 983, 13], "temperature": 0.0, "avg_logprob": -0.1275485549310241, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.555407890118659e-05}, {"id": 187, "seek": 82048, "start": 840.6, "end": 844.24, "text": " So let's zoom into the compute container for a second.", "tokens": [407, 718, 311, 8863, 666, 264, 14722, 10129, 337, 257, 1150, 13], "temperature": 0.0, "avg_logprob": -0.1275485549310241, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.555407890118659e-05}, {"id": 188, "seek": 82048, "start": 844.24, "end": 849.32, "text": " The list here is all of the processes and threads that run inside the compute container.", "tokens": [440, 1329, 510, 307, 439, 295, 264, 7555, 293, 19314, 300, 1190, 1854, 264, 14722, 10129, 13], "temperature": 0.0, "avg_logprob": -0.1275485549310241, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.555407890118659e-05}, {"id": 189, "seek": 84932, "start": 849.32, "end": 853.48, "text": " You don't need to understand everything that's running here.", "tokens": [509, 500, 380, 643, 281, 1223, 1203, 300, 311, 2614, 510, 13], "temperature": 0.0, "avg_logprob": -0.1729874058773643, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00014824036043137312}, {"id": 190, "seek": 84932, "start": 853.48, "end": 855.44, "text": " But let me show you the interesting part.", "tokens": [583, 718, 385, 855, 291, 264, 1880, 644, 13], "temperature": 0.0, "avg_logprob": -0.1729874058773643, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00014824036043137312}, {"id": 191, "seek": 84932, "start": 855.44, "end": 858.4000000000001, "text": " So you see the QEMU KVM process.", "tokens": [407, 291, 536, 264, 1249, 6683, 52, 591, 53, 44, 1399, 13], "temperature": 0.0, "avg_logprob": -0.1729874058773643, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00014824036043137312}, {"id": 192, "seek": 84932, "start": 858.4000000000001, "end": 862.0400000000001, "text": " All of the red ones are threads.", "tokens": [1057, 295, 264, 2182, 2306, 366, 19314, 13], "temperature": 0.0, "avg_logprob": -0.1729874058773643, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00014824036043137312}, {"id": 193, "seek": 84932, "start": 862.0400000000001, "end": 869.5600000000001, "text": " Now as you can see, we have two threads, which are the actual vCPU threads, like I said earlier.", "tokens": [823, 382, 291, 393, 536, 11, 321, 362, 732, 19314, 11, 597, 366, 264, 3539, 371, 34, 8115, 19314, 11, 411, 286, 848, 3071, 13], "temperature": 0.0, "avg_logprob": -0.1729874058773643, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00014824036043137312}, {"id": 194, "seek": 84932, "start": 869.5600000000001, "end": 877.7600000000001, "text": " So the problem is that we have a lot of threads with different priorities.", "tokens": [407, 264, 1154, 307, 300, 321, 362, 257, 688, 295, 19314, 365, 819, 15503, 13], "temperature": 0.0, "avg_logprob": -0.1729874058773643, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00014824036043137312}, {"id": 195, "seek": 87776, "start": 877.76, "end": 885.12, "text": " And if we let all of the compute container run with dedicated CPUs, this aren't really", "tokens": [400, 498, 321, 718, 439, 295, 264, 14722, 10129, 1190, 365, 8374, 13199, 82, 11, 341, 3212, 380, 534], "temperature": 0.0, "avg_logprob": -0.14739440469180837, "compression_ratio": 1.7112068965517242, "no_speech_prob": 1.0441995073051658e-05}, {"id": 196, "seek": 87776, "start": 885.12, "end": 890.12, "text": " dedicated CPUs because we said that the keyword here is avoiding preemption, right?", "tokens": [8374, 13199, 82, 570, 321, 848, 300, 264, 20428, 510, 307, 20220, 659, 26033, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14739440469180837, "compression_ratio": 1.7112068965517242, "no_speech_prob": 1.0441995073051658e-05}, {"id": 197, "seek": 87776, "start": 890.12, "end": 895.12, "text": " But with the previous setting, we're basically, we will context switch out the vCPUs in order", "tokens": [583, 365, 264, 3894, 3287, 11, 321, 434, 1936, 11, 321, 486, 4319, 3679, 484, 264, 371, 34, 8115, 82, 294, 1668], "temperature": 0.0, "avg_logprob": -0.14739440469180837, "compression_ratio": 1.7112068965517242, "no_speech_prob": 1.0441995073051658e-05}, {"id": 198, "seek": 87776, "start": 895.12, "end": 898.12, "text": " for other threads inside the compute containers.", "tokens": [337, 661, 19314, 1854, 264, 14722, 17089, 13], "temperature": 0.0, "avg_logprob": -0.14739440469180837, "compression_ratio": 1.7112068965517242, "no_speech_prob": 1.0441995073051658e-05}, {"id": 199, "seek": 87776, "start": 898.12, "end": 902.76, "text": " So the vCPUs aren't running on dedicated CPUs really.", "tokens": [407, 264, 371, 34, 8115, 82, 3212, 380, 2614, 322, 8374, 13199, 82, 534, 13], "temperature": 0.0, "avg_logprob": -0.14739440469180837, "compression_ratio": 1.7112068965517242, "no_speech_prob": 1.0441995073051658e-05}, {"id": 200, "seek": 87776, "start": 902.76, "end": 905.4399999999999, "text": " We actually lie to the guest.", "tokens": [492, 767, 4544, 281, 264, 8341, 13], "temperature": 0.0, "avg_logprob": -0.14739440469180837, "compression_ratio": 1.7112068965517242, "no_speech_prob": 1.0441995073051658e-05}, {"id": 201, "seek": 90544, "start": 905.44, "end": 909.9200000000001, "text": " So that's a problem.", "tokens": [407, 300, 311, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.14992524302282997, "compression_ratio": 1.5025125628140703, "no_speech_prob": 1.803002305678092e-05}, {"id": 202, "seek": 90544, "start": 909.9200000000001, "end": 912.8800000000001, "text": " Now the second approach is called the housekeeping C-group.", "tokens": [823, 264, 1150, 3109, 307, 1219, 264, 48033, 383, 12, 17377, 13], "temperature": 0.0, "avg_logprob": -0.14992524302282997, "compression_ratio": 1.5025125628140703, "no_speech_prob": 1.803002305678092e-05}, {"id": 203, "seek": 90544, "start": 912.8800000000001, "end": 921.4000000000001, "text": " And the idea is that we will make a child C-group for all of the low priority threads or processes.", "tokens": [400, 264, 1558, 307, 300, 321, 486, 652, 257, 1440, 383, 12, 17377, 337, 439, 295, 264, 2295, 9365, 19314, 420, 7555, 13], "temperature": 0.0, "avg_logprob": -0.14992524302282997, "compression_ratio": 1.5025125628140703, "no_speech_prob": 1.803002305678092e-05}, {"id": 204, "seek": 90544, "start": 921.4000000000001, "end": 922.6800000000001, "text": " So how would it work?", "tokens": [407, 577, 576, 309, 589, 30], "temperature": 0.0, "avg_logprob": -0.14992524302282997, "compression_ratio": 1.5025125628140703, "no_speech_prob": 1.803002305678092e-05}, {"id": 205, "seek": 90544, "start": 922.6800000000001, "end": 926.5200000000001, "text": " So let's say that the user asks for XCPUs.", "tokens": [407, 718, 311, 584, 300, 264, 4195, 8962, 337, 1783, 34, 8115, 82, 13], "temperature": 0.0, "avg_logprob": -0.14992524302282997, "compression_ratio": 1.5025125628140703, "no_speech_prob": 1.803002305678092e-05}, {"id": 206, "seek": 90544, "start": 926.5200000000001, "end": 930.5600000000001, "text": " We would actually allocate X plus one dedicated CPUs.", "tokens": [492, 576, 767, 35713, 1783, 1804, 472, 8374, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.14992524302282997, "compression_ratio": 1.5025125628140703, "no_speech_prob": 1.803002305678092e-05}, {"id": 207, "seek": 93056, "start": 930.56, "end": 936.28, "text": " And one dedicated CPU will serve all of the housekeeping tasks.", "tokens": [400, 472, 8374, 13199, 486, 4596, 439, 295, 264, 48033, 9608, 13], "temperature": 0.0, "avg_logprob": -0.07473159872967264, "compression_ratio": 1.6683417085427135, "no_speech_prob": 2.6094010536326095e-05}, {"id": 208, "seek": 93056, "start": 936.28, "end": 944.2399999999999, "text": " And when I say housekeeping tasks, I basically mean everything but the vCPUs themselves.", "tokens": [400, 562, 286, 584, 48033, 9608, 11, 286, 1936, 914, 1203, 457, 264, 371, 34, 8115, 82, 2969, 13], "temperature": 0.0, "avg_logprob": -0.07473159872967264, "compression_ratio": 1.6683417085427135, "no_speech_prob": 2.6094010536326095e-05}, {"id": 209, "seek": 93056, "start": 944.2399999999999, "end": 951.0, "text": " Then what we can do is move all of the threads that aren't vCPUs into the housekeeping C-groups.", "tokens": [1396, 437, 321, 393, 360, 307, 1286, 439, 295, 264, 19314, 300, 3212, 380, 371, 34, 8115, 82, 666, 264, 48033, 383, 12, 17377, 82, 13], "temperature": 0.0, "avg_logprob": -0.07473159872967264, "compression_ratio": 1.6683417085427135, "no_speech_prob": 2.6094010536326095e-05}, {"id": 210, "seek": 93056, "start": 951.0, "end": 956.28, "text": " And then the vCPUs would be with two dedicated CPUs.", "tokens": [400, 550, 264, 371, 34, 8115, 82, 576, 312, 365, 732, 8374, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.07473159872967264, "compression_ratio": 1.6683417085427135, "no_speech_prob": 2.6094010536326095e-05}, {"id": 211, "seek": 93056, "start": 956.28, "end": 957.28, "text": " So this is how it looks like.", "tokens": [407, 341, 307, 577, 309, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.07473159872967264, "compression_ratio": 1.6683417085427135, "no_speech_prob": 2.6094010536326095e-05}, {"id": 212, "seek": 95728, "start": 957.28, "end": 962.24, "text": " We have the vert launcher pod inside of we have the compute container with X plus one", "tokens": [492, 362, 264, 6509, 36805, 2497, 1854, 295, 321, 362, 264, 14722, 10129, 365, 1783, 1804, 472], "temperature": 0.0, "avg_logprob": -0.13157525996571964, "compression_ratio": 1.7213930348258706, "no_speech_prob": 9.122448682319373e-05}, {"id": 213, "seek": 95728, "start": 962.24, "end": 964.0, "text": " dedicated CPUs.", "tokens": [8374, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.13157525996571964, "compression_ratio": 1.7213930348258706, "no_speech_prob": 9.122448682319373e-05}, {"id": 214, "seek": 95728, "start": 964.0, "end": 968.12, "text": " One dedicated CPU is for everything but the vCPUs themselves.", "tokens": [1485, 8374, 13199, 307, 337, 1203, 457, 264, 371, 34, 8115, 82, 2969, 13], "temperature": 0.0, "avg_logprob": -0.13157525996571964, "compression_ratio": 1.7213930348258706, "no_speech_prob": 9.122448682319373e-05}, {"id": 215, "seek": 95728, "start": 968.12, "end": 974.6, "text": " And the X dedicated CPUs are for the vCPUs.", "tokens": [400, 264, 1783, 8374, 13199, 82, 366, 337, 264, 371, 34, 8115, 82, 13], "temperature": 0.0, "avg_logprob": -0.13157525996571964, "compression_ratio": 1.7213930348258706, "no_speech_prob": 9.122448682319373e-05}, {"id": 216, "seek": 95728, "start": 974.6, "end": 979.68, "text": " So this approach is much better because it lets us, this basically supports two dedicated", "tokens": [407, 341, 3109, 307, 709, 1101, 570, 309, 6653, 505, 11, 341, 1936, 9346, 732, 8374], "temperature": 0.0, "avg_logprob": -0.13157525996571964, "compression_ratio": 1.7213930348258706, "no_speech_prob": 9.122448682319373e-05}, {"id": 217, "seek": 95728, "start": 979.68, "end": 982.28, "text": " CPUs for the vCPUs.", "tokens": [13199, 82, 337, 264, 371, 34, 8115, 82, 13], "temperature": 0.0, "avg_logprob": -0.13157525996571964, "compression_ratio": 1.7213930348258706, "no_speech_prob": 9.122448682319373e-05}, {"id": 218, "seek": 95728, "start": 982.28, "end": 984.64, "text": " But this also has a problem.", "tokens": [583, 341, 611, 575, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.13157525996571964, "compression_ratio": 1.7213930348258706, "no_speech_prob": 9.122448682319373e-05}, {"id": 219, "seek": 98464, "start": 984.64, "end": 993.0, "text": " So first problem is that we waste one dedicated CPU for stuff that are of low priority.", "tokens": [407, 700, 1154, 307, 300, 321, 5964, 472, 8374, 13199, 337, 1507, 300, 366, 295, 2295, 9365, 13], "temperature": 0.0, "avg_logprob": -0.14777752660935925, "compression_ratio": 1.6130434782608696, "no_speech_prob": 2.2772244847146794e-05}, {"id": 220, "seek": 98464, "start": 993.0, "end": 995.3199999999999, "text": " This is a huge waste.", "tokens": [639, 307, 257, 2603, 5964, 13], "temperature": 0.0, "avg_logprob": -0.14777752660935925, "compression_ratio": 1.6130434782608696, "no_speech_prob": 2.2772244847146794e-05}, {"id": 221, "seek": 98464, "start": 995.3199999999999, "end": 1003.24, "text": " Ideally, we would have wanted to do something like give me like four or X amount of dedicated", "tokens": [40817, 11, 321, 576, 362, 1415, 281, 360, 746, 411, 976, 385, 411, 1451, 420, 1783, 2372, 295, 8374], "temperature": 0.0, "avg_logprob": -0.14777752660935925, "compression_ratio": 1.6130434782608696, "no_speech_prob": 2.2772244847146794e-05}, {"id": 222, "seek": 98464, "start": 1003.24, "end": 1007.84, "text": " CPUs and another amount of shared CPUs for everything else.", "tokens": [13199, 82, 293, 1071, 2372, 295, 5507, 13199, 82, 337, 1203, 1646, 13], "temperature": 0.0, "avg_logprob": -0.14777752660935925, "compression_ratio": 1.6130434782608696, "no_speech_prob": 2.2772244847146794e-05}, {"id": 223, "seek": 98464, "start": 1007.84, "end": 1011.48, "text": " And this is actually possible on C-groups but it's not possible on Kubernetes because", "tokens": [400, 341, 307, 767, 1944, 322, 383, 12, 17377, 82, 457, 309, 311, 406, 1944, 322, 23145, 570], "temperature": 0.0, "avg_logprob": -0.14777752660935925, "compression_ratio": 1.6130434782608696, "no_speech_prob": 2.2772244847146794e-05}, {"id": 224, "seek": 98464, "start": 1011.48, "end": 1012.84, "text": " what we said earlier.", "tokens": [437, 321, 848, 3071, 13], "temperature": 0.0, "avg_logprob": -0.14777752660935925, "compression_ratio": 1.6130434782608696, "no_speech_prob": 2.2772244847146794e-05}, {"id": 225, "seek": 101284, "start": 1012.84, "end": 1017.6800000000001, "text": " If we're going to ask like 3.2 CPUs or something like that, they won't be dedicated.", "tokens": [759, 321, 434, 516, 281, 1029, 411, 805, 13, 17, 13199, 82, 420, 746, 411, 300, 11, 436, 1582, 380, 312, 8374, 13], "temperature": 0.0, "avg_logprob": -0.14684699345560906, "compression_ratio": 1.6375, "no_speech_prob": 3.3173586416523904e-05}, {"id": 226, "seek": 101284, "start": 1017.6800000000001, "end": 1019.44, "text": " That would be all shared.", "tokens": [663, 576, 312, 439, 5507, 13], "temperature": 0.0, "avg_logprob": -0.14684699345560906, "compression_ratio": 1.6375, "no_speech_prob": 3.3173586416523904e-05}, {"id": 227, "seek": 101284, "start": 1019.44, "end": 1023.12, "text": " So basically Kubernetes goes for an all or nothing approach.", "tokens": [407, 1936, 23145, 1709, 337, 364, 439, 420, 1825, 3109, 13], "temperature": 0.0, "avg_logprob": -0.14684699345560906, "compression_ratio": 1.6375, "no_speech_prob": 3.3173586416523904e-05}, {"id": 228, "seek": 101284, "start": 1023.12, "end": 1029.56, "text": " Either all of the CPUs are dedicated or all of the CPUs are shared.", "tokens": [13746, 439, 295, 264, 13199, 82, 366, 8374, 420, 439, 295, 264, 13199, 82, 366, 5507, 13], "temperature": 0.0, "avg_logprob": -0.14684699345560906, "compression_ratio": 1.6375, "no_speech_prob": 3.3173586416523904e-05}, {"id": 229, "seek": 101284, "start": 1029.56, "end": 1033.68, "text": " Another problem which is more of a design problem is that we're focused around the lowest", "tokens": [3996, 1154, 597, 307, 544, 295, 257, 1715, 1154, 307, 300, 321, 434, 5178, 926, 264, 12437], "temperature": 0.0, "avg_logprob": -0.14684699345560906, "compression_ratio": 1.6375, "no_speech_prob": 3.3173586416523904e-05}, {"id": 230, "seek": 101284, "start": 1033.68, "end": 1035.6000000000001, "text": " priority processes.", "tokens": [9365, 7555, 13], "temperature": 0.0, "avg_logprob": -0.14684699345560906, "compression_ratio": 1.6375, "no_speech_prob": 3.3173586416523904e-05}, {"id": 231, "seek": 101284, "start": 1035.6000000000001, "end": 1038.2, "text": " And this kind of should be reversed, right?", "tokens": [400, 341, 733, 295, 820, 312, 30563, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14684699345560906, "compression_ratio": 1.6375, "no_speech_prob": 3.3173586416523904e-05}, {"id": 232, "seek": 103820, "start": 1038.2, "end": 1044.56, "text": " I mean we want to configure the vCPUs to have dedicated CPUs.", "tokens": [286, 914, 321, 528, 281, 22162, 264, 371, 34, 8115, 82, 281, 362, 8374, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.13293953945762232, "compression_ratio": 1.6018518518518519, "no_speech_prob": 9.728203440317884e-05}, {"id": 233, "seek": 103820, "start": 1044.56, "end": 1047.76, "text": " So we configure everything that is not the vCPUs.", "tokens": [407, 321, 22162, 1203, 300, 307, 406, 264, 371, 34, 8115, 82, 13], "temperature": 0.0, "avg_logprob": -0.13293953945762232, "compression_ratio": 1.6018518518518519, "no_speech_prob": 9.728203440317884e-05}, {"id": 234, "seek": 103820, "start": 1047.76, "end": 1054.68, "text": " And this is problematic because we would ideally want to only change the vCPUs threads and", "tokens": [400, 341, 307, 19011, 570, 321, 576, 22915, 528, 281, 787, 1319, 264, 371, 34, 8115, 82, 19314, 293], "temperature": 0.0, "avg_logprob": -0.13293953945762232, "compression_ratio": 1.6018518518518519, "no_speech_prob": 9.728203440317884e-05}, {"id": 235, "seek": 103820, "start": 1054.68, "end": 1062.04, "text": " leave everything as is to keep it open for extensions in the future and stuff like that.", "tokens": [1856, 1203, 382, 307, 281, 1066, 309, 1269, 337, 25129, 294, 264, 2027, 293, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.13293953945762232, "compression_ratio": 1.6018518518518519, "no_speech_prob": 9.728203440317884e-05}, {"id": 236, "seek": 103820, "start": 1062.04, "end": 1065.8400000000001, "text": " There are more problems related to C-groups v1 and v2.", "tokens": [821, 366, 544, 2740, 4077, 281, 383, 12, 17377, 82, 371, 16, 293, 371, 17, 13], "temperature": 0.0, "avg_logprob": -0.13293953945762232, "compression_ratio": 1.6018518518518519, "no_speech_prob": 9.728203440317884e-05}, {"id": 237, "seek": 106584, "start": 1065.84, "end": 1074.04, "text": " I'll not dive into details here but two words about it is for example in v2 we have the", "tokens": [286, 603, 406, 9192, 666, 4365, 510, 457, 732, 2283, 466, 309, 307, 337, 1365, 294, 371, 17, 321, 362, 264], "temperature": 0.0, "avg_logprob": -0.14548392778032282, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.00016520176723133773}, {"id": 238, "seek": 106584, "start": 1074.04, "end": 1077.56, "text": " threaded C-group concept which doesn't exist in v1.", "tokens": [47493, 383, 12, 17377, 3410, 597, 1177, 380, 2514, 294, 371, 16, 13], "temperature": 0.0, "avg_logprob": -0.14548392778032282, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.00016520176723133773}, {"id": 239, "seek": 106584, "start": 1077.56, "end": 1081.1599999999999, "text": " And in a threaded C-group we have a lot of limitations.", "tokens": [400, 294, 257, 47493, 383, 12, 17377, 321, 362, 257, 688, 295, 15705, 13], "temperature": 0.0, "avg_logprob": -0.14548392778032282, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.00016520176723133773}, {"id": 240, "seek": 106584, "start": 1081.1599999999999, "end": 1086.48, "text": " Some of the controllers and some systems of C-groups cannot work at all.", "tokens": [2188, 295, 264, 26903, 293, 512, 3652, 295, 383, 12, 17377, 82, 2644, 589, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.14548392778032282, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.00016520176723133773}, {"id": 241, "seek": 106584, "start": 1086.48, "end": 1091.8, "text": " So just know that there are more problems with this solution.", "tokens": [407, 445, 458, 300, 456, 366, 544, 2740, 365, 341, 3827, 13], "temperature": 0.0, "avg_logprob": -0.14548392778032282, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.00016520176723133773}, {"id": 242, "seek": 109180, "start": 1091.8, "end": 1098.36, "text": " So a third attempt, I'm calling it the dedicated CPU C-group approach and here's the idea.", "tokens": [407, 257, 2636, 5217, 11, 286, 478, 5141, 309, 264, 8374, 13199, 383, 12, 17377, 3109, 293, 510, 311, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.15923687651917173, "compression_ratio": 1.5504587155963303, "no_speech_prob": 4.374612035462633e-05}, {"id": 243, "seek": 109180, "start": 1098.36, "end": 1103.28, "text": " So the compute container stays completely as it is.", "tokens": [407, 264, 14722, 10129, 10834, 2584, 382, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.15923687651917173, "compression_ratio": 1.5504587155963303, "no_speech_prob": 4.374612035462633e-05}, {"id": 244, "seek": 109180, "start": 1103.28, "end": 1104.96, "text": " We won't touch it at all.", "tokens": [492, 1582, 380, 2557, 309, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.15923687651917173, "compression_ratio": 1.5504587155963303, "no_speech_prob": 4.374612035462633e-05}, {"id": 245, "seek": 109180, "start": 1104.96, "end": 1112.3999999999999, "text": " We would allocate it with CPUs that are not a dedicated, sorry they are shared CPUs but", "tokens": [492, 576, 35713, 309, 365, 13199, 82, 300, 366, 406, 257, 8374, 11, 2597, 436, 366, 5507, 13199, 82, 457], "temperature": 0.0, "avg_logprob": -0.15923687651917173, "compression_ratio": 1.5504587155963303, "no_speech_prob": 4.374612035462633e-05}, {"id": 246, "seek": 109180, "start": 1112.3999999999999, "end": 1118.2, "text": " remember that the pods still need to be with guaranteed QoS and I'll explain why.", "tokens": [1604, 300, 264, 31925, 920, 643, 281, 312, 365, 18031, 1249, 78, 50, 293, 286, 603, 2903, 983, 13], "temperature": 0.0, "avg_logprob": -0.15923687651917173, "compression_ratio": 1.5504587155963303, "no_speech_prob": 4.374612035462633e-05}, {"id": 247, "seek": 111820, "start": 1118.2, "end": 1124.8400000000001, "text": " So what we will do is add another container which is basically a blank container with", "tokens": [407, 437, 321, 486, 360, 307, 909, 1071, 10129, 597, 307, 1936, 257, 8247, 10129, 365], "temperature": 0.0, "avg_logprob": -0.17027840920544546, "compression_ratio": 1.7478632478632479, "no_speech_prob": 1.0606149771774653e-05}, {"id": 248, "seek": 111820, "start": 1124.8400000000001, "end": 1130.6000000000001, "text": " X dedicated CPUs and as I said every container creates a new C-group so it will create a new", "tokens": [1783, 8374, 13199, 82, 293, 382, 286, 848, 633, 10129, 7829, 257, 777, 383, 12, 17377, 370, 309, 486, 1884, 257, 777], "temperature": 0.0, "avg_logprob": -0.17027840920544546, "compression_ratio": 1.7478632478632479, "no_speech_prob": 1.0606149771774653e-05}, {"id": 249, "seek": 111820, "start": 1130.6000000000001, "end": 1131.96, "text": " C-group for us.", "tokens": [383, 12, 17377, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.17027840920544546, "compression_ratio": 1.7478632478632479, "no_speech_prob": 1.0606149771774653e-05}, {"id": 250, "seek": 111820, "start": 1131.96, "end": 1133.8400000000001, "text": " So what do I mean by a blank container?", "tokens": [407, 437, 360, 286, 914, 538, 257, 8247, 10129, 30], "temperature": 0.0, "avg_logprob": -0.17027840920544546, "compression_ratio": 1.7478632478632479, "no_speech_prob": 1.0606149771774653e-05}, {"id": 251, "seek": 111820, "start": 1133.8400000000001, "end": 1136.24, "text": " I mean a container doesn't really run anything.", "tokens": [286, 914, 257, 10129, 1177, 380, 534, 1190, 1340, 13], "temperature": 0.0, "avg_logprob": -0.17027840920544546, "compression_ratio": 1.7478632478632479, "no_speech_prob": 1.0606149771774653e-05}, {"id": 252, "seek": 111820, "start": 1136.24, "end": 1141.24, "text": " It could run for example a sleep forever process just to keep the container alive but that's", "tokens": [467, 727, 1190, 337, 1365, 257, 2817, 5680, 1399, 445, 281, 1066, 264, 10129, 5465, 457, 300, 311], "temperature": 0.0, "avg_logprob": -0.17027840920544546, "compression_ratio": 1.7478632478632479, "no_speech_prob": 1.0606149771774653e-05}, {"id": 253, "seek": 111820, "start": 1141.24, "end": 1142.24, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.17027840920544546, "compression_ratio": 1.7478632478632479, "no_speech_prob": 1.0606149771774653e-05}, {"id": 254, "seek": 111820, "start": 1142.24, "end": 1144.16, "text": " It would be entire the blank.", "tokens": [467, 576, 312, 2302, 264, 8247, 13], "temperature": 0.0, "avg_logprob": -0.17027840920544546, "compression_ratio": 1.7478632478632479, "no_speech_prob": 1.0606149771774653e-05}, {"id": 255, "seek": 114416, "start": 1144.16, "end": 1150.16, "text": " And then what we will do is move only the VCPUs into another container, right, into", "tokens": [400, 550, 437, 321, 486, 360, 307, 1286, 787, 264, 691, 34, 8115, 82, 666, 1071, 10129, 11, 558, 11, 666], "temperature": 0.0, "avg_logprob": -0.1942758106050037, "compression_ratio": 1.716279069767442, "no_speech_prob": 3.408400880289264e-05}, {"id": 256, "seek": 114416, "start": 1150.16, "end": 1151.8400000000001, "text": " another C-group.", "tokens": [1071, 383, 12, 17377, 13], "temperature": 0.0, "avg_logprob": -0.1942758106050037, "compression_ratio": 1.716279069767442, "no_speech_prob": 3.408400880289264e-05}, {"id": 257, "seek": 114416, "start": 1151.8400000000001, "end": 1159.52, "text": " All of the compute containers stays as is and only the VCPUs are configured.", "tokens": [1057, 295, 264, 14722, 17089, 10834, 382, 307, 293, 787, 264, 691, 34, 8115, 82, 366, 30538, 13], "temperature": 0.0, "avg_logprob": -0.1942758106050037, "compression_ratio": 1.716279069767442, "no_speech_prob": 3.408400880289264e-05}, {"id": 258, "seek": 114416, "start": 1159.52, "end": 1162.48, "text": " So this is how it looks like.", "tokens": [407, 341, 307, 577, 309, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.1942758106050037, "compression_ratio": 1.716279069767442, "no_speech_prob": 3.408400880289264e-05}, {"id": 259, "seek": 114416, "start": 1162.48, "end": 1167.44, "text": " So as the VM starts or before it starts, we have the VRT launcher.", "tokens": [407, 382, 264, 18038, 3719, 420, 949, 309, 3719, 11, 321, 362, 264, 13722, 51, 36805, 13], "temperature": 0.0, "avg_logprob": -0.1942758106050037, "compression_ratio": 1.716279069767442, "no_speech_prob": 3.408400880289264e-05}, {"id": 260, "seek": 114416, "start": 1167.44, "end": 1169.3200000000002, "text": " Now we have two different containers.", "tokens": [823, 321, 362, 732, 819, 17089, 13], "temperature": 0.0, "avg_logprob": -0.1942758106050037, "compression_ratio": 1.716279069767442, "no_speech_prob": 3.408400880289264e-05}, {"id": 261, "seek": 114416, "start": 1169.3200000000002, "end": 1172.28, "text": " One of them is the compute container with Y shared CPUs.", "tokens": [1485, 295, 552, 307, 264, 14722, 10129, 365, 398, 5507, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.1942758106050037, "compression_ratio": 1.716279069767442, "no_speech_prob": 3.408400880289264e-05}, {"id": 262, "seek": 117228, "start": 1172.28, "end": 1174.36, "text": " These are not dedicated CPUs.", "tokens": [1981, 366, 406, 8374, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.13761104505086683, "compression_ratio": 1.7864077669902914, "no_speech_prob": 6.38927158433944e-05}, {"id": 263, "seek": 117228, "start": 1174.36, "end": 1177.28, "text": " The other one is a container with dedicated CPUs.", "tokens": [440, 661, 472, 307, 257, 10129, 365, 8374, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.13761104505086683, "compression_ratio": 1.7864077669902914, "no_speech_prob": 6.38927158433944e-05}, {"id": 264, "seek": 117228, "start": 1177.28, "end": 1182.92, "text": " X dedicated CPUs, exactly the amount we need, not X plus one as before.", "tokens": [1783, 8374, 13199, 82, 11, 2293, 264, 2372, 321, 643, 11, 406, 1783, 1804, 472, 382, 949, 13], "temperature": 0.0, "avg_logprob": -0.13761104505086683, "compression_ratio": 1.7864077669902914, "no_speech_prob": 6.38927158433944e-05}, {"id": 265, "seek": 117228, "start": 1182.92, "end": 1189.12, "text": " So in the compute container everything is being run when the VM is being started.", "tokens": [407, 294, 264, 14722, 10129, 1203, 307, 885, 1190, 562, 264, 18038, 307, 885, 1409, 13], "temperature": 0.0, "avg_logprob": -0.13761104505086683, "compression_ratio": 1.7864077669902914, "no_speech_prob": 6.38927158433944e-05}, {"id": 266, "seek": 117228, "start": 1189.12, "end": 1193.92, "text": " But right after it's being started or right before it's being started, what we will do", "tokens": [583, 558, 934, 309, 311, 885, 1409, 420, 558, 949, 309, 311, 885, 1409, 11, 437, 321, 486, 360], "temperature": 0.0, "avg_logprob": -0.13761104505086683, "compression_ratio": 1.7864077669902914, "no_speech_prob": 6.38927158433944e-05}, {"id": 267, "seek": 117228, "start": 1193.92, "end": 1198.08, "text": " is move the VCPUs into the different container.", "tokens": [307, 1286, 264, 691, 34, 8115, 82, 666, 264, 819, 10129, 13], "temperature": 0.0, "avg_logprob": -0.13761104505086683, "compression_ratio": 1.7864077669902914, "no_speech_prob": 6.38927158433944e-05}, {"id": 268, "seek": 119808, "start": 1198.08, "end": 1203.32, "text": " And that basically solves our problem because now all of the housekeeping tasks are being", "tokens": [400, 300, 1936, 39890, 527, 1154, 570, 586, 439, 295, 264, 48033, 9608, 366, 885], "temperature": 0.0, "avg_logprob": -0.1365249612358179, "compression_ratio": 1.52863436123348, "no_speech_prob": 3.0604347557527944e-05}, {"id": 269, "seek": 119808, "start": 1203.32, "end": 1210.04, "text": " run with shared CPUs, the VCPUs are running on dedicated CPUs.", "tokens": [1190, 365, 5507, 13199, 82, 11, 264, 691, 34, 8115, 82, 366, 2614, 322, 8374, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.1365249612358179, "compression_ratio": 1.52863436123348, "no_speech_prob": 3.0604347557527944e-05}, {"id": 270, "seek": 119808, "start": 1210.04, "end": 1211.8, "text": " So can we actually do that?", "tokens": [407, 393, 321, 767, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.1365249612358179, "compression_ratio": 1.52863436123348, "no_speech_prob": 3.0604347557527944e-05}, {"id": 271, "seek": 119808, "start": 1211.8, "end": 1218.6, "text": " I mean, we actually moved some threads of a process to another container.", "tokens": [286, 914, 11, 321, 767, 4259, 512, 19314, 295, 257, 1399, 281, 1071, 10129, 13], "temperature": 0.0, "avg_logprob": -0.1365249612358179, "compression_ratio": 1.52863436123348, "no_speech_prob": 3.0604347557527944e-05}, {"id": 272, "seek": 119808, "start": 1218.6, "end": 1221.1599999999999, "text": " This looks extremely weird, right?", "tokens": [639, 1542, 4664, 3657, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1365249612358179, "compression_ratio": 1.52863436123348, "no_speech_prob": 3.0604347557527944e-05}, {"id": 273, "seek": 119808, "start": 1221.1599999999999, "end": 1224.8799999999999, "text": " But this is possible because we shared the PID namespace.", "tokens": [583, 341, 307, 1944, 570, 321, 5507, 264, 430, 2777, 5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.1365249612358179, "compression_ratio": 1.52863436123348, "no_speech_prob": 3.0604347557527944e-05}, {"id": 274, "seek": 122488, "start": 1224.88, "end": 1231.5200000000002, "text": " So you can think about it like the processes are not isolated anymore.", "tokens": [407, 291, 393, 519, 466, 309, 411, 264, 7555, 366, 406, 14621, 3602, 13], "temperature": 0.0, "avg_logprob": -0.12681154977707637, "compression_ratio": 1.6602870813397128, "no_speech_prob": 2.075858174066525e-05}, {"id": 275, "seek": 122488, "start": 1231.5200000000002, "end": 1236.16, "text": " They're not really being moved from one container to another because the container does not", "tokens": [814, 434, 406, 534, 885, 4259, 490, 472, 10129, 281, 1071, 570, 264, 10129, 775, 406], "temperature": 0.0, "avg_logprob": -0.12681154977707637, "compression_ratio": 1.6602870813397128, "no_speech_prob": 2.075858174066525e-05}, {"id": 276, "seek": 122488, "start": 1236.16, "end": 1238.16, "text": " isolate processes anymore.", "tokens": [25660, 7555, 3602, 13], "temperature": 0.0, "avg_logprob": -0.12681154977707637, "compression_ratio": 1.6602870813397128, "no_speech_prob": 2.075858174066525e-05}, {"id": 277, "seek": 122488, "start": 1238.16, "end": 1240.72, "text": " So we only change C groups.", "tokens": [407, 321, 787, 1319, 383, 3935, 13], "temperature": 0.0, "avg_logprob": -0.12681154977707637, "compression_ratio": 1.6602870813397128, "no_speech_prob": 2.075858174066525e-05}, {"id": 278, "seek": 122488, "start": 1240.72, "end": 1246.92, "text": " So from the VCPUs perspective, they just stay the same.", "tokens": [407, 490, 264, 691, 34, 8115, 82, 4585, 11, 436, 445, 1754, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.12681154977707637, "compression_ratio": 1.6602870813397128, "no_speech_prob": 2.075858174066525e-05}, {"id": 279, "seek": 122488, "start": 1246.92, "end": 1252.7600000000002, "text": " They can communicate with all of the threads and processes in the system.", "tokens": [814, 393, 7890, 365, 439, 295, 264, 19314, 293, 7555, 294, 264, 1185, 13], "temperature": 0.0, "avg_logprob": -0.12681154977707637, "compression_ratio": 1.6602870813397128, "no_speech_prob": 2.075858174066525e-05}, {"id": 280, "seek": 125276, "start": 1252.76, "end": 1257.32, "text": " So only the relevant threads are being configured, as I said, shared CPUs for the housekeeping", "tokens": [407, 787, 264, 7340, 19314, 366, 885, 30538, 11, 382, 286, 848, 11, 5507, 13199, 82, 337, 264, 48033], "temperature": 0.0, "avg_logprob": -0.17083745899766978, "compression_ratio": 1.59375, "no_speech_prob": 2.7499057978275232e-05}, {"id": 281, "seek": 125276, "start": 1257.32, "end": 1261.68, "text": " test so we don't waste one dedicated core anymore.", "tokens": [1500, 370, 321, 500, 380, 5964, 472, 8374, 4965, 3602, 13], "temperature": 0.0, "avg_logprob": -0.17083745899766978, "compression_ratio": 1.59375, "no_speech_prob": 2.7499057978275232e-05}, {"id": 282, "seek": 125276, "start": 1261.68, "end": 1264.2, "text": " And we keep things open for extensions in the future.", "tokens": [400, 321, 1066, 721, 1269, 337, 25129, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.17083745899766978, "compression_ratio": 1.59375, "no_speech_prob": 2.7499057978275232e-05}, {"id": 283, "seek": 125276, "start": 1264.2, "end": 1268.92, "text": " Maybe we would want to do more plays with C groups in the future.", "tokens": [2704, 321, 576, 528, 281, 360, 544, 5749, 365, 383, 3935, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.17083745899766978, "compression_ratio": 1.59375, "no_speech_prob": 2.7499057978275232e-05}, {"id": 284, "seek": 125276, "start": 1268.92, "end": 1274.08, "text": " So we want everything in the compute container to stay completely as is.", "tokens": [407, 321, 528, 1203, 294, 264, 14722, 10129, 281, 1754, 2584, 382, 307, 13], "temperature": 0.0, "avg_logprob": -0.17083745899766978, "compression_ratio": 1.59375, "no_speech_prob": 2.7499057978275232e-05}, {"id": 285, "seek": 125276, "start": 1274.08, "end": 1278.12, "text": " OK, so summary and takeaways.", "tokens": [2264, 11, 370, 12691, 293, 45584, 13], "temperature": 0.0, "avg_logprob": -0.17083745899766978, "compression_ratio": 1.59375, "no_speech_prob": 2.7499057978275232e-05}, {"id": 286, "seek": 125276, "start": 1278.12, "end": 1279.76, "text": " There were a lot of introductions here.", "tokens": [821, 645, 257, 688, 295, 48032, 510, 13], "temperature": 0.0, "avg_logprob": -0.17083745899766978, "compression_ratio": 1.59375, "no_speech_prob": 2.7499057978275232e-05}, {"id": 287, "seek": 127976, "start": 1279.76, "end": 1285.72, "text": " And I've scratched the surface of a lot of cool facts and technologies that I've seen", "tokens": [400, 286, 600, 40513, 264, 3753, 295, 257, 688, 295, 1627, 9130, 293, 7943, 300, 286, 600, 1612], "temperature": 0.0, "avg_logprob": -0.10174856185913086, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.0002878294326364994}, {"id": 288, "seek": 127976, "start": 1285.72, "end": 1287.92, "text": " along the way.", "tokens": [2051, 264, 636, 13], "temperature": 0.0, "avg_logprob": -0.10174856185913086, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.0002878294326364994}, {"id": 289, "seek": 127976, "start": 1287.92, "end": 1295.4, "text": " So we've seen CPU allocation, implementation in Kubernetes, how C group uses relative shares", "tokens": [407, 321, 600, 1612, 13199, 27599, 11, 11420, 294, 23145, 11, 577, 383, 1594, 4960, 4972, 12182], "temperature": 0.0, "avg_logprob": -0.10174856185913086, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.0002878294326364994}, {"id": 290, "seek": 127976, "start": 1295.4, "end": 1304.36, "text": " and not absolute values, and how the CPUs and the resources are being spread along the", "tokens": [293, 406, 8236, 4190, 11, 293, 577, 264, 13199, 82, 293, 264, 3593, 366, 885, 3974, 2051, 264], "temperature": 0.0, "avg_logprob": -0.10174856185913086, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.0002878294326364994}, {"id": 291, "seek": 127976, "start": 1304.36, "end": 1308.08, "text": " pods relatively to their requests.", "tokens": [31925, 7226, 281, 641, 12475, 13], "temperature": 0.0, "avg_logprob": -0.10174856185913086, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.0002878294326364994}, {"id": 292, "seek": 130808, "start": 1308.08, "end": 1310.9199999999998, "text": " We've seen how to enable dedicated CPUs and Kubernetes.", "tokens": [492, 600, 1612, 577, 281, 9528, 8374, 13199, 82, 293, 23145, 13], "temperature": 0.0, "avg_logprob": -0.12186103292030863, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.00019141045049764216}, {"id": 293, "seek": 130808, "start": 1310.9199999999998, "end": 1316.72, "text": " We've seen namespaces and how to break the isolation within a pod.", "tokens": [492, 600, 1612, 5288, 79, 2116, 293, 577, 281, 1821, 264, 16001, 1951, 257, 2497, 13], "temperature": 0.0, "avg_logprob": -0.12186103292030863, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.00019141045049764216}, {"id": 294, "seek": 130808, "start": 1316.72, "end": 1325.6399999999999, "text": " We've talked a bit about KVM and how it uses threads to run the actual CPUs.", "tokens": [492, 600, 2825, 257, 857, 466, 591, 53, 44, 293, 577, 309, 4960, 19314, 281, 1190, 264, 3539, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.12186103292030863, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.00019141045049764216}, {"id": 295, "seek": 130808, "start": 1325.6399999999999, "end": 1327.28, "text": " And of course, we talked about Kuvert.", "tokens": [400, 295, 1164, 11, 321, 2825, 466, 20311, 3281, 13], "temperature": 0.0, "avg_logprob": -0.12186103292030863, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.00019141045049764216}, {"id": 296, "seek": 130808, "start": 1327.28, "end": 1333.1999999999998, "text": " And again, I really hope that these takeaways would serve you in your journeys in the future.", "tokens": [400, 797, 11, 286, 534, 1454, 300, 613, 45584, 576, 4596, 291, 294, 428, 36736, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.12186103292030863, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.00019141045049764216}, {"id": 297, "seek": 130808, "start": 1333.1999999999998, "end": 1335.8, "text": " And I hope that you find this interesting.", "tokens": [400, 286, 1454, 300, 291, 915, 341, 1880, 13], "temperature": 0.0, "avg_logprob": -0.12186103292030863, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.00019141045049764216}, {"id": 298, "seek": 133580, "start": 1335.8, "end": 1340.8, "text": " So thanks a lot, and you're always welcome to send questions or feedback or anything", "tokens": [407, 3231, 257, 688, 11, 293, 291, 434, 1009, 2928, 281, 2845, 1651, 420, 5824, 420, 1340], "temperature": 0.0, "avg_logprob": -0.43697184244791665, "compression_ratio": 1.539877300613497, "no_speech_prob": 0.00027046827017329633}, {"id": 299, "seek": 133580, "start": 1340.8, "end": 1346.84, "text": " else to my mail and I'll also be outside for questions.", "tokens": [1646, 281, 452, 10071, 293, 286, 603, 611, 312, 2380, 337, 1651, 13], "temperature": 0.0, "avg_logprob": -0.43697184244791665, "compression_ratio": 1.539877300613497, "no_speech_prob": 0.00027046827017329633}, {"id": 300, "seek": 133580, "start": 1346.84, "end": 1347.84, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.43697184244791665, "compression_ratio": 1.539877300613497, "no_speech_prob": 0.00027046827017329633}, {"id": 301, "seek": 133580, "start": 1347.84, "end": 1348.84, "text": " So thank you.", "tokens": [407, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.43697184244791665, "compression_ratio": 1.539877300613497, "no_speech_prob": 0.00027046827017329633}, {"id": 302, "seek": 133580, "start": 1348.84, "end": 1349.84, "text": " And if you have any questions.", "tokens": [400, 498, 291, 362, 604, 1651, 13], "temperature": 0.0, "avg_logprob": -0.43697184244791665, "compression_ratio": 1.539877300613497, "no_speech_prob": 0.00027046827017329633}, {"id": 303, "seek": 133580, "start": 1349.84, "end": 1350.84, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.43697184244791665, "compression_ratio": 1.539877300613497, "no_speech_prob": 0.00027046827017329633}, {"id": 304, "seek": 133580, "start": 1350.84, "end": 1362.84, "text": " So the question is, do we need to do something like this?", "tokens": [407, 264, 1168, 307, 11, 360, 321, 643, 281, 360, 746, 411, 341, 30], "temperature": 0.0, "avg_logprob": -0.43697184244791665, "compression_ratio": 1.539877300613497, "no_speech_prob": 0.00027046827017329633}, {"id": 305, "seek": 136284, "start": 1362.84, "end": 1369.08, "text": " OK, so the question is, do we need more permission to divert launcher pod, or is it being done", "tokens": [2264, 11, 370, 264, 1168, 307, 11, 360, 321, 643, 544, 11226, 281, 23781, 36805, 2497, 11, 420, 307, 309, 885, 1096], "temperature": 0.0, "avg_logprob": -0.20900038917465966, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00034724545548669994}, {"id": 306, "seek": 136284, "start": 1369.08, "end": 1370.1599999999999, "text": " by the vert handler?", "tokens": [538, 264, 6509, 41967, 30], "temperature": 0.0, "avg_logprob": -0.20900038917465966, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00034724545548669994}, {"id": 307, "seek": 136284, "start": 1370.1599999999999, "end": 1373.48, "text": " And the answer is, it's being done by the vert handler.", "tokens": [400, 264, 1867, 307, 11, 309, 311, 885, 1096, 538, 264, 6509, 41967, 13], "temperature": 0.0, "avg_logprob": -0.20900038917465966, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00034724545548669994}, {"id": 308, "seek": 136284, "start": 1373.48, "end": 1378.9599999999998, "text": " So just a bit of context, a vert handler is another pod that Kuvert uses.", "tokens": [407, 445, 257, 857, 295, 4319, 11, 257, 6509, 41967, 307, 1071, 2497, 300, 20311, 3281, 4960, 13], "temperature": 0.0, "avg_logprob": -0.20900038917465966, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00034724545548669994}, {"id": 309, "seek": 136284, "start": 1378.9599999999998, "end": 1384.0, "text": " It's a pod with high privileges, and therefore, we don't need any extra privileges for it", "tokens": [467, 311, 257, 2497, 365, 1090, 32588, 11, 293, 4412, 11, 321, 500, 380, 643, 604, 2857, 32588, 337, 309], "temperature": 0.0, "avg_logprob": -0.20900038917465966, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00034724545548669994}, {"id": 310, "seek": 136284, "start": 1384.0, "end": 1385.0, "text": " to configure that.", "tokens": [281, 22162, 300, 13], "temperature": 0.0, "avg_logprob": -0.20900038917465966, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00034724545548669994}, {"id": 311, "seek": 136284, "start": 1385.0, "end": 1386.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.20900038917465966, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00034724545548669994}, {"id": 312, "seek": 138600, "start": 1386.0, "end": 1395.0, "text": " Does this allow for easier networking communication if you talk in service communication in the", "tokens": [4402, 341, 2089, 337, 3571, 17985, 6101, 498, 291, 751, 294, 2643, 6101, 294, 264], "temperature": 0.0, "avg_logprob": -0.3681413105555943, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0002831576857715845}, {"id": 313, "seek": 138600, "start": 1395.0, "end": 1396.0, "text": " Kubernetes sense?", "tokens": [23145, 2020, 30], "temperature": 0.0, "avg_logprob": -0.3681413105555943, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0002831576857715845}, {"id": 314, "seek": 138600, "start": 1396.0, "end": 1400.8, "text": " You could do it VM to VM, presumably with the exact same mechanism, so resolving service", "tokens": [509, 727, 360, 309, 18038, 281, 18038, 11, 26742, 365, 264, 1900, 912, 7513, 11, 370, 49940, 2643], "temperature": 0.0, "avg_logprob": -0.3681413105555943, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0002831576857715845}, {"id": 315, "seek": 138600, "start": 1400.8, "end": 1405.64, "text": " names from what VM to whatever VM is using Kubernetes, does that work at the moment?", "tokens": [5288, 490, 437, 18038, 281, 2035, 18038, 307, 1228, 23145, 11, 775, 300, 589, 412, 264, 1623, 30], "temperature": 0.0, "avg_logprob": -0.3681413105555943, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0002831576857715845}, {"id": 316, "seek": 138600, "start": 1405.64, "end": 1407.64, "text": " So that's a question about Kuvert in general, right?", "tokens": [407, 300, 311, 257, 1168, 466, 20311, 3281, 294, 2674, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.3681413105555943, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0002831576857715845}, {"id": 317, "seek": 138600, "start": 1407.64, "end": 1412.64, "text": " But in Kubernetes, I can do it, but presumably I can do the same thing from a VM running", "tokens": [583, 294, 23145, 11, 286, 393, 360, 309, 11, 457, 26742, 286, 393, 360, 264, 912, 551, 490, 257, 18038, 2614], "temperature": 0.0, "avg_logprob": -0.3681413105555943, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0002831576857715845}, {"id": 318, "seek": 138600, "start": 1412.64, "end": 1413.64, "text": " inside the pod.", "tokens": [1854, 264, 2497, 13], "temperature": 0.0, "avg_logprob": -0.3681413105555943, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0002831576857715845}, {"id": 319, "seek": 138600, "start": 1413.64, "end": 1414.64, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.3681413105555943, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0002831576857715845}, {"id": 320, "seek": 141464, "start": 1414.64, "end": 1417.76, "text": " Yeah, so the answer is yes.", "tokens": [865, 11, 370, 264, 1867, 307, 2086, 13], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 321, "seek": 141464, "start": 1417.76, "end": 1418.76, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 322, "seek": 141464, "start": 1418.76, "end": 1419.76, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 323, "seek": 141464, "start": 1419.76, "end": 1420.76, "text": " Any other question?", "tokens": [2639, 661, 1168, 30], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 324, "seek": 141464, "start": 1420.76, "end": 1421.76, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 325, "seek": 141464, "start": 1421.76, "end": 1422.76, "text": " I have a question.", "tokens": [286, 362, 257, 1168, 13], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 326, "seek": 141464, "start": 1422.76, "end": 1425.76, "text": " You are dedicating the CPUs separately, but about other threads, which are, for some", "tokens": [509, 366, 4172, 30541, 264, 13199, 82, 14759, 11, 457, 466, 661, 19314, 11, 597, 366, 11, 337, 512], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 327, "seek": 141464, "start": 1425.76, "end": 1430.76, "text": " of these cases, highly CPU consuming like network threads or IO threads, is there a network", "tokens": [295, 613, 3331, 11, 5405, 13199, 19867, 411, 3209, 19314, 420, 39839, 19314, 11, 307, 456, 257, 3209], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 328, "seek": 141464, "start": 1430.76, "end": 1431.76, "text": " thread as well?", "tokens": [7207, 382, 731, 30], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 329, "seek": 141464, "start": 1431.76, "end": 1432.76, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 330, "seek": 141464, "start": 1432.76, "end": 1444.5600000000002, "text": " So the question is, what about IO threads or network related threads, what about them?", "tokens": [407, 264, 1168, 307, 11, 437, 466, 39839, 19314, 420, 3209, 4077, 19314, 11, 437, 466, 552, 30], "temperature": 0.0, "avg_logprob": -0.4361517517654984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0003217783523723483}, {"id": 331, "seek": 144456, "start": 1444.56, "end": 1449.2, "text": " And, actually, in the VM manifest, we have configurations for that.", "tokens": [400, 11, 767, 11, 294, 264, 18038, 10067, 11, 321, 362, 31493, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.3933650652567546, "compression_ratio": 1.4935622317596566, "no_speech_prob": 9.26597640500404e-05}, {"id": 332, "seek": 144456, "start": 1449.2, "end": 1453.72, "text": " So you can ask, for example, for an IO thread to run on a dedicated CPU.", "tokens": [407, 291, 393, 1029, 11, 337, 1365, 11, 337, 364, 39839, 7207, 281, 1190, 322, 257, 8374, 13199, 13], "temperature": 0.0, "avg_logprob": -0.3933650652567546, "compression_ratio": 1.4935622317596566, "no_speech_prob": 9.26597640500404e-05}, {"id": 333, "seek": 144456, "start": 1453.72, "end": 1454.72, "text": " That is also supported.", "tokens": [663, 307, 611, 8104, 13], "temperature": 0.0, "avg_logprob": -0.3933650652567546, "compression_ratio": 1.4935622317596566, "no_speech_prob": 9.26597640500404e-05}, {"id": 334, "seek": 144456, "start": 1454.72, "end": 1455.72, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3933650652567546, "compression_ratio": 1.4935622317596566, "no_speech_prob": 9.26597640500404e-05}, {"id": 335, "seek": 144456, "start": 1455.72, "end": 1463.1599999999999, "text": " I focused solely on the CPUs themselves, but this is entirely possible in Kuvert today.", "tokens": [286, 5178, 23309, 322, 264, 13199, 82, 2969, 11, 457, 341, 307, 7696, 1944, 294, 20311, 3281, 965, 13], "temperature": 0.0, "avg_logprob": -0.3933650652567546, "compression_ratio": 1.4935622317596566, "no_speech_prob": 9.26597640500404e-05}, {"id": 336, "seek": 144456, "start": 1463.1599999999999, "end": 1464.1599999999999, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.3933650652567546, "compression_ratio": 1.4935622317596566, "no_speech_prob": 9.26597640500404e-05}, {"id": 337, "seek": 144456, "start": 1464.1599999999999, "end": 1468.8799999999999, "text": " Can I combine it with new machines, so dual machine machines can be used by the same", "tokens": [1664, 286, 10432, 309, 365, 777, 8379, 11, 370, 11848, 3479, 8379, 393, 312, 1143, 538, 264, 912], "temperature": 0.0, "avg_logprob": -0.3933650652567546, "compression_ratio": 1.4935622317596566, "no_speech_prob": 9.26597640500404e-05}, {"id": 338, "seek": 146888, "start": 1468.88, "end": 1474.72, "text": " machine, and what's running with it?", "tokens": [3479, 11, 293, 437, 311, 2614, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.3472944624880527, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.00019041166524402797}, {"id": 339, "seek": 146888, "start": 1474.72, "end": 1478.16, "text": " So the question is, can we support NUMA with this?", "tokens": [407, 264, 1168, 307, 11, 393, 321, 1406, 426, 52, 9998, 365, 341, 30], "temperature": 0.0, "avg_logprob": -0.3472944624880527, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.00019041166524402797}, {"id": 340, "seek": 146888, "start": 1478.16, "end": 1479.92, "text": " The answer is yes.", "tokens": [440, 1867, 307, 2086, 13], "temperature": 0.0, "avg_logprob": -0.3472944624880527, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.00019041166524402797}, {"id": 341, "seek": 146888, "start": 1479.92, "end": 1489.3200000000002, "text": " I'm not sure if it works right now outside of the box, but I think it should be possible", "tokens": [286, 478, 406, 988, 498, 309, 1985, 558, 586, 2380, 295, 264, 2424, 11, 457, 286, 519, 309, 820, 312, 1944], "temperature": 0.0, "avg_logprob": -0.3472944624880527, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.00019041166524402797}, {"id": 342, "seek": 146888, "start": 1489.3200000000002, "end": 1492.1200000000001, "text": " with, especially with C-groups V2.", "tokens": [365, 11, 2318, 365, 383, 12, 17377, 82, 691, 17, 13], "temperature": 0.0, "avg_logprob": -0.3472944624880527, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.00019041166524402797}, {"id": 343, "seek": 146888, "start": 1492.1200000000001, "end": 1493.64, "text": " But this is an interesting question.", "tokens": [583, 341, 307, 364, 1880, 1168, 13], "temperature": 0.0, "avg_logprob": -0.3472944624880527, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.00019041166524402797}, {"id": 344, "seek": 146888, "start": 1493.64, "end": 1496.16, "text": " I will have to think about it a little more.", "tokens": [286, 486, 362, 281, 519, 466, 309, 257, 707, 544, 13], "temperature": 0.0, "avg_logprob": -0.3472944624880527, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.00019041166524402797}, {"id": 345, "seek": 149616, "start": 1496.16, "end": 1500.64, "text": " I think it is possible.", "tokens": [286, 519, 309, 307, 1944, 13], "temperature": 0.0, "avg_logprob": -0.2549546957015991, "compression_ratio": 1.2162162162162162, "no_speech_prob": 0.00018960899615194649}, {"id": 346, "seek": 149616, "start": 1500.64, "end": 1501.64, "text": " Anyone else?", "tokens": [14643, 1646, 30], "temperature": 0.0, "avg_logprob": -0.2549546957015991, "compression_ratio": 1.2162162162162162, "no_speech_prob": 0.00018960899615194649}, {"id": 347, "seek": 149616, "start": 1501.64, "end": 1502.64, "text": " Time's up.", "tokens": [6161, 311, 493, 13], "temperature": 0.0, "avg_logprob": -0.2549546957015991, "compression_ratio": 1.2162162162162162, "no_speech_prob": 0.00018960899615194649}, {"id": 348, "seek": 149616, "start": 1502.64, "end": 1505.16, "text": " Sorry, but I'll be out here if you want to ask further questions.", "tokens": [4919, 11, 457, 286, 603, 312, 484, 510, 498, 291, 528, 281, 1029, 3052, 1651, 13], "temperature": 0.0, "avg_logprob": -0.2549546957015991, "compression_ratio": 1.2162162162162162, "no_speech_prob": 0.00018960899615194649}, {"id": 349, "seek": 149616, "start": 1505.16, "end": 1506.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.2549546957015991, "compression_ratio": 1.2162162162162162, "no_speech_prob": 0.00018960899615194649}, {"id": 350, "seek": 150616, "start": 1506.16, "end": 1530.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.8874392509460449, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.0005208786460570991}], "language": "en"}