{"text": " First lightning talk is Christian. Yeah, thanks, Dennis. Corn has said that he has a relaxed talk. I have only 10 minutes, so I need to speed up. What I would like to talk today is about HPC container conformance, which is a project that came out of the HPC container advisory council, which is every first Thursday. And we try to provide guidance on how to build and annotate HPC containers. So conformance, what you might ask, so what are we trying to achieve? We focus on two applications, maybe a third, but mainly Gromax and PyTorch, and we want to go through an exercise of providing best practices on how to build or shape the container and also how to annotate the container. And I think that's the most important part, is the annotation part, by the way, anyhow. What we don't want to achieve is we don't want to boil the ocean by making everything work everywhere. So that's why we focus on these two applications. And we want also to allow for generic and also highly optimized images and make with annotations, make sure that people can actually discover those and also provide some expectation management for those. We are going to focus on OCI images, and most likely on Docker files. I mean, if people throw a lot of singularity build recipes at me, then maybe I will change my mind, but for starters, we are going with Docker files and OCI images. And if we have a Docker file that is derived from other artifacts, like a spec YAML file or an easy build recipe or an HPCCM recipe, then of course we also want to include those to make it easy for people to reproduce and tweak the actual container. When going through this research or this project, I was like, I'm in touch with the biocontainer community, and they created a paper in 2019, which is pretty interesting, where they provide some recommendation on how to package and containerize bioinformatics software. Of course, they don't compile for different targets, and they don't use MPI a lot. So it's just a baseline, I think, for our work in HPC, but it's a good baseline, and I highly recommend this paper to be read by people. So the first thing in the HPC container conformance project is the expected image behavior. So I think we have all been there, where we have different images, we want you to swap out and then we realize, oh, the entry point is different, or the container does not use an entry point, but the application name. And so we want to make sure that at the end of the day, all the containers that we produce in the HPC world are built in a way that they behave the same way, so that you can just swap out the container, you want to run Gromax, you try out multiple different containers, and you don't need to change your submit script but only the name. So at the end of the day, the container should drop you into a shell, like you're logging into an SSH node, and it should also have a very small, ideally small, or even no entry point so that it's easy to debug as well. So if the entry point takes forever or makes a lot of changes, then it's hard to debug the container. So the container should be, has a very small or even no entry point, and maybe it changes some environment variables to pick up the application that is installed maybe by Easy Build or Spec, but it should be very small. The main part is annotations for this project, and why annotations are the basic ideas, and we have all been there, so everyone who's done HPC containers, that we encode the information about the specific implementations of the image in the tag or in the name, and we don't want to do this anymore, right? So we want the information to be annotated to the image and not part of the name, because the name might change. So what do we want to do with these annotations? We want two things. First, kind of describe the image, the content of the image, and how the image is expected to be used so that sysadmins and end users know what to expect. So what user land is provided by the image? What tools are installed on the image? How is the main application compiled, like for what target, for what microarchitecture of the CPU, for which GPU, which MPI is used and so on, so that we can take this information and make maybe configuration examples for different container runtimes that hooks can react to those annotations, like potman and seros, for instance, they can already react to annotations. So depending on what the image provides as information, the runtime can adapt and say, okay, I have an open MPI container, I do this hook, I have an MPI base container, I take this hook. So I think that would be great if we can agree on certain annotations and agreeing on certain annotations. I think it's a huge task, but I'm hopeful that we can achieve this, and then make sure that the configuration is done so that the application is tweaked the right way. And another piece that we can achieve here is that we create maybe a smoke test that looks at the host that is running on, looks at the annotations of the container that you want to run, and just tells you, okay, this thing will sack fault anyway, you are on a send too and you have an application that's compiled for Skylake, it won't work. So that you don't download 30 gigabytes of images of layers just to realize that your image won't work. So I think that's also a very important part that we can do this. Another part as well is not just describe the image, but make it easy for end users to discover what images are around. So you want to run Gromax, and you know or don't know the system you are on. So maybe you can just run a tool or have a website that tells you you want to run Gromax. I have looked through all the annotations, I know a little bit about your system. Here we go, this is the image that you want to use. So also for discovery, I think that's important. Of course, we will have mandatory and optional annotations. So mandatory ones might be what CPU architecture is it compiled for, I think that's the obvious one. And optional ones, of course, if you want to add a CUDA version because your image has CUDA installed, then of course that's an optional one. Or you want to annotate the whole software bill of material. Maybe it's too much information, but maybe not. So there are optional and mandatory annotations, I think that's pretty clear. And I created a couple of groups, like annotation groups that I think we should think about. I won't go through every single line item here because I only have 10 minutes and it's only 3 minutes left, so just maybe grab the slides afterwards and then go through it and it's not written in stone, it's just a proposal, so happy to have feedback on this as well. So the first big one, and I talked about it already, is of course hardware annotations. So what is the target optimized for, the architecture, generic architecture or the real microarchitecture and then a key version, a value for this. As I said CUDA versions, driver versions and so on, I think that's obvious that we need to annotate the container so that it defines what the actual execution environment should look like. Also obvious HPC things like the MPI and interconnect annotations so that you define what the implementation of the container is, is it open MPI, is it image based, is it even thread MPI because you only want to run single node. Not framework is used, libfabrics, ucx, what have you and now I'm going through all the line items so maybe I should stop, but at the end I think the last line is also important. What is the container, 2 minutes left even, what is the container actually, how is it expecting to be tweaked, so is the MPI being replaced, libfabric injected and so on, that's also I think important so that the sysadmin or the runtime knows what to do with the container to make it work on line speed. Sysadmin annotations I think is also important so that we know what the container expects from the kernel, what the modules are introduced and so on and also what the end user can expect what tools are installed, is jq installed, is wget installed and so on. Another annotation is of course documentation would be nice as well, base64 encoded markdown would be great so that you can render how-tos and build tweaks and so on directly. Okay, one minute, how to annotate, I think that's obvious as well that's a layered approach, of course the base image should have annotations that we can carry over and if you build subsequent images at the annotations that are important and after the image is already built you can use things like crane or builder or podman I think or builder to annotate images at the end without even rebuilding them, just repurposing them or we could also collect annotations offline in another format and then annotate it. Okay, ideally and that's like Kenneth and of course Todd as well, easy build, spec, they should annotate it correctly so that we don't need to teach everyone to annotate but the tools just annotate the image for us. And that's the external piece so I created a tool MetaHub where we define images for different use cases and we can also annotate those images without actually changing the image but just with this. So okay, 10 seconds, last one. We need of course a fingerprint of the system to match the annotations against the host itself so there needs to be a tool, time is up and yeah, so we need to discover the right image, need to have a smoke test and help tweak the container. That's like the last bit so I think that's it. Thank you for the excellent example on how to do a lightning talk on time, we'll take one question, any questions for Christian? Do you need the clicker? Thank you for your presentation, I would like to ask how does this relate to like existing software supply chain method databases like GraphiS, does this complement their functionality, is this completely something different? I mean we are good at HPC to build our own thing and then just say that everyone should adopt it. We want to complement it, we want to use these two applications and go to the exercise and then maybe learn from what we did with this project and try to push these ideas also in other things. But I think the AIML folks maybe didn't realize that they won't have this problem so we try also to not only think about HPC here but also think about other communities as well. So I'm open to everyone and the project is as well. Thank you very much Christian, if you want to chat with Christian he'll be around probably outside the door for the rest of the day or in the room and we'll switch it over to the next.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.2, "text": " First lightning talk is Christian.", "tokens": [2386, 16589, 751, 307, 5778, 13], "temperature": 0.0, "avg_logprob": -0.25857987770667445, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.478859007358551}, {"id": 1, "seek": 0, "start": 7.2, "end": 9.28, "text": " Yeah, thanks, Dennis.", "tokens": [865, 11, 3231, 11, 23376, 13], "temperature": 0.0, "avg_logprob": -0.25857987770667445, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.478859007358551}, {"id": 2, "seek": 0, "start": 9.28, "end": 11.28, "text": " Corn has said that he has a relaxed talk.", "tokens": [21590, 575, 848, 300, 415, 575, 257, 14628, 751, 13], "temperature": 0.0, "avg_logprob": -0.25857987770667445, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.478859007358551}, {"id": 3, "seek": 0, "start": 11.28, "end": 14.36, "text": " I have only 10 minutes, so I need to speed up.", "tokens": [286, 362, 787, 1266, 2077, 11, 370, 286, 643, 281, 3073, 493, 13], "temperature": 0.0, "avg_logprob": -0.25857987770667445, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.478859007358551}, {"id": 4, "seek": 0, "start": 14.36, "end": 18.92, "text": " What I would like to talk today is about HPC container conformance, which is a project", "tokens": [708, 286, 576, 411, 281, 751, 965, 307, 466, 12557, 34, 10129, 18975, 719, 11, 597, 307, 257, 1716], "temperature": 0.0, "avg_logprob": -0.25857987770667445, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.478859007358551}, {"id": 5, "seek": 0, "start": 18.92, "end": 24.6, "text": " that came out of the HPC container advisory council, which is every first Thursday.", "tokens": [300, 1361, 484, 295, 264, 12557, 34, 10129, 26289, 9209, 11, 597, 307, 633, 700, 10383, 13], "temperature": 0.0, "avg_logprob": -0.25857987770667445, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.478859007358551}, {"id": 6, "seek": 0, "start": 24.6, "end": 29.28, "text": " And we try to provide guidance on how to build and annotate HPC containers.", "tokens": [400, 321, 853, 281, 2893, 10056, 322, 577, 281, 1322, 293, 25339, 473, 12557, 34, 17089, 13], "temperature": 0.0, "avg_logprob": -0.25857987770667445, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.478859007358551}, {"id": 7, "seek": 2928, "start": 29.28, "end": 32.76, "text": " So conformance, what you might ask, so what are we trying to achieve?", "tokens": [407, 18975, 719, 11, 437, 291, 1062, 1029, 11, 370, 437, 366, 321, 1382, 281, 4584, 30], "temperature": 0.0, "avg_logprob": -0.1370372772216797, "compression_ratio": 1.687719298245614, "no_speech_prob": 8.083800639724359e-05}, {"id": 8, "seek": 2928, "start": 32.76, "end": 37.96, "text": " We focus on two applications, maybe a third, but mainly Gromax and PyTorch, and we want", "tokens": [492, 1879, 322, 732, 5821, 11, 1310, 257, 2636, 11, 457, 8704, 2606, 298, 2797, 293, 9953, 51, 284, 339, 11, 293, 321, 528], "temperature": 0.0, "avg_logprob": -0.1370372772216797, "compression_ratio": 1.687719298245614, "no_speech_prob": 8.083800639724359e-05}, {"id": 9, "seek": 2928, "start": 37.96, "end": 46.120000000000005, "text": " to go through an exercise of providing best practices on how to build or shape the container", "tokens": [281, 352, 807, 364, 5380, 295, 6530, 1151, 7525, 322, 577, 281, 1322, 420, 3909, 264, 10129], "temperature": 0.0, "avg_logprob": -0.1370372772216797, "compression_ratio": 1.687719298245614, "no_speech_prob": 8.083800639724359e-05}, {"id": 10, "seek": 2928, "start": 46.120000000000005, "end": 48.120000000000005, "text": " and also how to annotate the container.", "tokens": [293, 611, 577, 281, 25339, 473, 264, 10129, 13], "temperature": 0.0, "avg_logprob": -0.1370372772216797, "compression_ratio": 1.687719298245614, "no_speech_prob": 8.083800639724359e-05}, {"id": 11, "seek": 2928, "start": 48.120000000000005, "end": 52.24, "text": " And I think that's the most important part, is the annotation part, by the way, anyhow.", "tokens": [400, 286, 519, 300, 311, 264, 881, 1021, 644, 11, 307, 264, 48654, 644, 11, 538, 264, 636, 11, 44995, 13], "temperature": 0.0, "avg_logprob": -0.1370372772216797, "compression_ratio": 1.687719298245614, "no_speech_prob": 8.083800639724359e-05}, {"id": 12, "seek": 2928, "start": 52.24, "end": 56.8, "text": " What we don't want to achieve is we don't want to boil the ocean by making everything", "tokens": [708, 321, 500, 380, 528, 281, 4584, 307, 321, 500, 380, 528, 281, 13329, 264, 7810, 538, 1455, 1203], "temperature": 0.0, "avg_logprob": -0.1370372772216797, "compression_ratio": 1.687719298245614, "no_speech_prob": 8.083800639724359e-05}, {"id": 13, "seek": 2928, "start": 56.8, "end": 57.8, "text": " work everywhere.", "tokens": [589, 5315, 13], "temperature": 0.0, "avg_logprob": -0.1370372772216797, "compression_ratio": 1.687719298245614, "no_speech_prob": 8.083800639724359e-05}, {"id": 14, "seek": 5780, "start": 57.8, "end": 60.4, "text": " So that's why we focus on these two applications.", "tokens": [407, 300, 311, 983, 321, 1879, 322, 613, 732, 5821, 13], "temperature": 0.0, "avg_logprob": -0.13951307354551373, "compression_ratio": 1.5984555984555984, "no_speech_prob": 7.248143811011687e-05}, {"id": 15, "seek": 5780, "start": 60.4, "end": 65.88, "text": " And we want also to allow for generic and also highly optimized images and make with annotations,", "tokens": [400, 321, 528, 611, 281, 2089, 337, 19577, 293, 611, 5405, 26941, 5267, 293, 652, 365, 25339, 763, 11], "temperature": 0.0, "avg_logprob": -0.13951307354551373, "compression_ratio": 1.5984555984555984, "no_speech_prob": 7.248143811011687e-05}, {"id": 16, "seek": 5780, "start": 65.88, "end": 72.52, "text": " make sure that people can actually discover those and also provide some expectation management", "tokens": [652, 988, 300, 561, 393, 767, 4411, 729, 293, 611, 2893, 512, 14334, 4592], "temperature": 0.0, "avg_logprob": -0.13951307354551373, "compression_ratio": 1.5984555984555984, "no_speech_prob": 7.248143811011687e-05}, {"id": 17, "seek": 5780, "start": 72.52, "end": 73.52, "text": " for those.", "tokens": [337, 729, 13], "temperature": 0.0, "avg_logprob": -0.13951307354551373, "compression_ratio": 1.5984555984555984, "no_speech_prob": 7.248143811011687e-05}, {"id": 18, "seek": 5780, "start": 73.52, "end": 78.24, "text": " We are going to focus on OCI images, and most likely on Docker files.", "tokens": [492, 366, 516, 281, 1879, 322, 422, 25240, 5267, 11, 293, 881, 3700, 322, 33772, 7098, 13], "temperature": 0.0, "avg_logprob": -0.13951307354551373, "compression_ratio": 1.5984555984555984, "no_speech_prob": 7.248143811011687e-05}, {"id": 19, "seek": 5780, "start": 78.24, "end": 82.8, "text": " I mean, if people throw a lot of singularity build recipes at me, then maybe I will change", "tokens": [286, 914, 11, 498, 561, 3507, 257, 688, 295, 20010, 507, 1322, 13035, 412, 385, 11, 550, 1310, 286, 486, 1319], "temperature": 0.0, "avg_logprob": -0.13951307354551373, "compression_ratio": 1.5984555984555984, "no_speech_prob": 7.248143811011687e-05}, {"id": 20, "seek": 8280, "start": 82.8, "end": 88.47999999999999, "text": " my mind, but for starters, we are going with Docker files and OCI images.", "tokens": [452, 1575, 11, 457, 337, 35131, 11, 321, 366, 516, 365, 33772, 7098, 293, 422, 25240, 5267, 13], "temperature": 0.0, "avg_logprob": -0.14920436314174107, "compression_ratio": 1.5593869731800767, "no_speech_prob": 7.136634667403996e-05}, {"id": 21, "seek": 8280, "start": 88.47999999999999, "end": 93.92, "text": " And if we have a Docker file that is derived from other artifacts, like a spec YAML file", "tokens": [400, 498, 321, 362, 257, 33772, 3991, 300, 307, 18949, 490, 661, 24617, 11, 411, 257, 1608, 398, 2865, 43, 3991], "temperature": 0.0, "avg_logprob": -0.14920436314174107, "compression_ratio": 1.5593869731800767, "no_speech_prob": 7.136634667403996e-05}, {"id": 22, "seek": 8280, "start": 93.92, "end": 99.16, "text": " or an easy build recipe or an HPCCM recipe, then of course we also want to include those", "tokens": [420, 364, 1858, 1322, 6782, 420, 364, 12557, 11717, 44, 6782, 11, 550, 295, 1164, 321, 611, 528, 281, 4090, 729], "temperature": 0.0, "avg_logprob": -0.14920436314174107, "compression_ratio": 1.5593869731800767, "no_speech_prob": 7.136634667403996e-05}, {"id": 23, "seek": 8280, "start": 99.16, "end": 104.44, "text": " to make it easy for people to reproduce and tweak the actual container.", "tokens": [281, 652, 309, 1858, 337, 561, 281, 29501, 293, 29879, 264, 3539, 10129, 13], "temperature": 0.0, "avg_logprob": -0.14920436314174107, "compression_ratio": 1.5593869731800767, "no_speech_prob": 7.136634667403996e-05}, {"id": 24, "seek": 8280, "start": 104.44, "end": 109.96, "text": " When going through this research or this project, I was like, I'm in touch with the", "tokens": [1133, 516, 807, 341, 2132, 420, 341, 1716, 11, 286, 390, 411, 11, 286, 478, 294, 2557, 365, 264], "temperature": 0.0, "avg_logprob": -0.14920436314174107, "compression_ratio": 1.5593869731800767, "no_speech_prob": 7.136634667403996e-05}, {"id": 25, "seek": 10996, "start": 109.96, "end": 114.72, "text": " biocontainer community, and they created a paper in 2019, which is pretty interesting,", "tokens": [12198, 9000, 491, 260, 1768, 11, 293, 436, 2942, 257, 3035, 294, 6071, 11, 597, 307, 1238, 1880, 11], "temperature": 0.0, "avg_logprob": -0.1534930255925544, "compression_ratio": 1.58203125, "no_speech_prob": 5.061912816017866e-05}, {"id": 26, "seek": 10996, "start": 114.72, "end": 119.24, "text": " where they provide some recommendation on how to package and containerize bioinformatics", "tokens": [689, 436, 2893, 512, 11879, 322, 577, 281, 7372, 293, 10129, 1125, 12198, 37811, 30292], "temperature": 0.0, "avg_logprob": -0.1534930255925544, "compression_ratio": 1.58203125, "no_speech_prob": 5.061912816017866e-05}, {"id": 27, "seek": 10996, "start": 119.24, "end": 120.24, "text": " software.", "tokens": [4722, 13], "temperature": 0.0, "avg_logprob": -0.1534930255925544, "compression_ratio": 1.58203125, "no_speech_prob": 5.061912816017866e-05}, {"id": 28, "seek": 10996, "start": 120.24, "end": 124.63999999999999, "text": " Of course, they don't compile for different targets, and they don't use MPI a lot.", "tokens": [2720, 1164, 11, 436, 500, 380, 31413, 337, 819, 12911, 11, 293, 436, 500, 380, 764, 14146, 40, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.1534930255925544, "compression_ratio": 1.58203125, "no_speech_prob": 5.061912816017866e-05}, {"id": 29, "seek": 10996, "start": 124.63999999999999, "end": 129.6, "text": " So it's just a baseline, I think, for our work in HPC, but it's a good baseline, and", "tokens": [407, 309, 311, 445, 257, 20518, 11, 286, 519, 11, 337, 527, 589, 294, 12557, 34, 11, 457, 309, 311, 257, 665, 20518, 11, 293], "temperature": 0.0, "avg_logprob": -0.1534930255925544, "compression_ratio": 1.58203125, "no_speech_prob": 5.061912816017866e-05}, {"id": 30, "seek": 10996, "start": 129.6, "end": 134.72, "text": " I highly recommend this paper to be read by people.", "tokens": [286, 5405, 2748, 341, 3035, 281, 312, 1401, 538, 561, 13], "temperature": 0.0, "avg_logprob": -0.1534930255925544, "compression_ratio": 1.58203125, "no_speech_prob": 5.061912816017866e-05}, {"id": 31, "seek": 13472, "start": 134.72, "end": 140.35999999999999, "text": " So the first thing in the HPC container conformance project is the expected image behavior.", "tokens": [407, 264, 700, 551, 294, 264, 12557, 34, 10129, 18975, 719, 1716, 307, 264, 5176, 3256, 5223, 13], "temperature": 0.0, "avg_logprob": -0.1080132771313675, "compression_ratio": 1.8089887640449438, "no_speech_prob": 1.722174056340009e-05}, {"id": 32, "seek": 13472, "start": 140.35999999999999, "end": 143.44, "text": " So I think we have all been there, where we have different images, we want you to swap", "tokens": [407, 286, 519, 321, 362, 439, 668, 456, 11, 689, 321, 362, 819, 5267, 11, 321, 528, 291, 281, 18135], "temperature": 0.0, "avg_logprob": -0.1080132771313675, "compression_ratio": 1.8089887640449438, "no_speech_prob": 1.722174056340009e-05}, {"id": 33, "seek": 13472, "start": 143.44, "end": 148.2, "text": " out and then we realize, oh, the entry point is different, or the container does not use", "tokens": [484, 293, 550, 321, 4325, 11, 1954, 11, 264, 8729, 935, 307, 819, 11, 420, 264, 10129, 775, 406, 764], "temperature": 0.0, "avg_logprob": -0.1080132771313675, "compression_ratio": 1.8089887640449438, "no_speech_prob": 1.722174056340009e-05}, {"id": 34, "seek": 13472, "start": 148.2, "end": 150.2, "text": " an entry point, but the application name.", "tokens": [364, 8729, 935, 11, 457, 264, 3861, 1315, 13], "temperature": 0.0, "avg_logprob": -0.1080132771313675, "compression_ratio": 1.8089887640449438, "no_speech_prob": 1.722174056340009e-05}, {"id": 35, "seek": 13472, "start": 150.2, "end": 155.36, "text": " And so we want to make sure that at the end of the day, all the containers that we produce", "tokens": [400, 370, 321, 528, 281, 652, 988, 300, 412, 264, 917, 295, 264, 786, 11, 439, 264, 17089, 300, 321, 5258], "temperature": 0.0, "avg_logprob": -0.1080132771313675, "compression_ratio": 1.8089887640449438, "no_speech_prob": 1.722174056340009e-05}, {"id": 36, "seek": 13472, "start": 155.36, "end": 160.12, "text": " in the HPC world are built in a way that they behave the same way, so that you can", "tokens": [294, 264, 12557, 34, 1002, 366, 3094, 294, 257, 636, 300, 436, 15158, 264, 912, 636, 11, 370, 300, 291, 393], "temperature": 0.0, "avg_logprob": -0.1080132771313675, "compression_ratio": 1.8089887640449438, "no_speech_prob": 1.722174056340009e-05}, {"id": 37, "seek": 16012, "start": 160.12, "end": 165.32, "text": " just swap out the container, you want to run Gromax, you try out multiple different", "tokens": [445, 18135, 484, 264, 10129, 11, 291, 528, 281, 1190, 2606, 298, 2797, 11, 291, 853, 484, 3866, 819], "temperature": 0.0, "avg_logprob": -0.11763821091762809, "compression_ratio": 1.8059701492537314, "no_speech_prob": 4.984646511729807e-05}, {"id": 38, "seek": 16012, "start": 165.32, "end": 168.36, "text": " containers, and you don't need to change your submit script but only the name.", "tokens": [17089, 11, 293, 291, 500, 380, 643, 281, 1319, 428, 10315, 5755, 457, 787, 264, 1315, 13], "temperature": 0.0, "avg_logprob": -0.11763821091762809, "compression_ratio": 1.8059701492537314, "no_speech_prob": 4.984646511729807e-05}, {"id": 39, "seek": 16012, "start": 168.36, "end": 172.6, "text": " So at the end of the day, the container should drop you into a shell, like you're logging", "tokens": [407, 412, 264, 917, 295, 264, 786, 11, 264, 10129, 820, 3270, 291, 666, 257, 8720, 11, 411, 291, 434, 27991], "temperature": 0.0, "avg_logprob": -0.11763821091762809, "compression_ratio": 1.8059701492537314, "no_speech_prob": 4.984646511729807e-05}, {"id": 40, "seek": 16012, "start": 172.6, "end": 180.24, "text": " into an SSH node, and it should also have a very small, ideally small, or even no entry", "tokens": [666, 364, 12238, 39, 9984, 11, 293, 309, 820, 611, 362, 257, 588, 1359, 11, 22915, 1359, 11, 420, 754, 572, 8729], "temperature": 0.0, "avg_logprob": -0.11763821091762809, "compression_ratio": 1.8059701492537314, "no_speech_prob": 4.984646511729807e-05}, {"id": 41, "seek": 16012, "start": 180.24, "end": 182.92000000000002, "text": " point so that it's easy to debug as well.", "tokens": [935, 370, 300, 309, 311, 1858, 281, 24083, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.11763821091762809, "compression_ratio": 1.8059701492537314, "no_speech_prob": 4.984646511729807e-05}, {"id": 42, "seek": 16012, "start": 182.92000000000002, "end": 188.6, "text": " So if the entry point takes forever or makes a lot of changes, then it's hard to debug", "tokens": [407, 498, 264, 8729, 935, 2516, 5680, 420, 1669, 257, 688, 295, 2962, 11, 550, 309, 311, 1152, 281, 24083], "temperature": 0.0, "avg_logprob": -0.11763821091762809, "compression_ratio": 1.8059701492537314, "no_speech_prob": 4.984646511729807e-05}, {"id": 43, "seek": 16012, "start": 188.6, "end": 189.6, "text": " the container.", "tokens": [264, 10129, 13], "temperature": 0.0, "avg_logprob": -0.11763821091762809, "compression_ratio": 1.8059701492537314, "no_speech_prob": 4.984646511729807e-05}, {"id": 44, "seek": 18960, "start": 189.6, "end": 197.68, "text": " So the container should be, has a very small or even no entry point, and maybe it changes", "tokens": [407, 264, 10129, 820, 312, 11, 575, 257, 588, 1359, 420, 754, 572, 8729, 935, 11, 293, 1310, 309, 2962], "temperature": 0.0, "avg_logprob": -0.16996068370585538, "compression_ratio": 1.653061224489796, "no_speech_prob": 2.013955236179754e-05}, {"id": 45, "seek": 18960, "start": 197.68, "end": 201.32, "text": " some environment variables to pick up the application that is installed maybe by Easy", "tokens": [512, 2823, 9102, 281, 1888, 493, 264, 3861, 300, 307, 8899, 1310, 538, 16002], "temperature": 0.0, "avg_logprob": -0.16996068370585538, "compression_ratio": 1.653061224489796, "no_speech_prob": 2.013955236179754e-05}, {"id": 46, "seek": 18960, "start": 201.32, "end": 204.79999999999998, "text": " Build or Spec, but it should be very small.", "tokens": [11875, 420, 20484, 11, 457, 309, 820, 312, 588, 1359, 13], "temperature": 0.0, "avg_logprob": -0.16996068370585538, "compression_ratio": 1.653061224489796, "no_speech_prob": 2.013955236179754e-05}, {"id": 47, "seek": 18960, "start": 204.79999999999998, "end": 211.48, "text": " The main part is annotations for this project, and why annotations are the basic ideas, and", "tokens": [440, 2135, 644, 307, 25339, 763, 337, 341, 1716, 11, 293, 983, 25339, 763, 366, 264, 3875, 3487, 11, 293], "temperature": 0.0, "avg_logprob": -0.16996068370585538, "compression_ratio": 1.653061224489796, "no_speech_prob": 2.013955236179754e-05}, {"id": 48, "seek": 18960, "start": 211.48, "end": 217.56, "text": " we have all been there, so everyone who's done HPC containers, that we encode the information", "tokens": [321, 362, 439, 668, 456, 11, 370, 1518, 567, 311, 1096, 12557, 34, 17089, 11, 300, 321, 2058, 1429, 264, 1589], "temperature": 0.0, "avg_logprob": -0.16996068370585538, "compression_ratio": 1.653061224489796, "no_speech_prob": 2.013955236179754e-05}, {"id": 49, "seek": 21756, "start": 217.56, "end": 222.8, "text": " about the specific implementations of the image in the tag or in the name, and we don't", "tokens": [466, 264, 2685, 4445, 763, 295, 264, 3256, 294, 264, 6162, 420, 294, 264, 1315, 11, 293, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.13598985520620194, "compression_ratio": 1.8688524590163935, "no_speech_prob": 3.5895795008400455e-05}, {"id": 50, "seek": 21756, "start": 222.8, "end": 224.08, "text": " want to do this anymore, right?", "tokens": [528, 281, 360, 341, 3602, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.13598985520620194, "compression_ratio": 1.8688524590163935, "no_speech_prob": 3.5895795008400455e-05}, {"id": 51, "seek": 21756, "start": 224.08, "end": 228.88, "text": " So we want the information to be annotated to the image and not part of the name, because", "tokens": [407, 321, 528, 264, 1589, 281, 312, 25339, 770, 281, 264, 3256, 293, 406, 644, 295, 264, 1315, 11, 570], "temperature": 0.0, "avg_logprob": -0.13598985520620194, "compression_ratio": 1.8688524590163935, "no_speech_prob": 3.5895795008400455e-05}, {"id": 52, "seek": 21756, "start": 228.88, "end": 230.68, "text": " the name might change.", "tokens": [264, 1315, 1062, 1319, 13], "temperature": 0.0, "avg_logprob": -0.13598985520620194, "compression_ratio": 1.8688524590163935, "no_speech_prob": 3.5895795008400455e-05}, {"id": 53, "seek": 21756, "start": 230.68, "end": 233.5, "text": " So what do we want to do with these annotations?", "tokens": [407, 437, 360, 321, 528, 281, 360, 365, 613, 25339, 763, 30], "temperature": 0.0, "avg_logprob": -0.13598985520620194, "compression_ratio": 1.8688524590163935, "no_speech_prob": 3.5895795008400455e-05}, {"id": 54, "seek": 21756, "start": 233.5, "end": 236.12, "text": " We want two things.", "tokens": [492, 528, 732, 721, 13], "temperature": 0.0, "avg_logprob": -0.13598985520620194, "compression_ratio": 1.8688524590163935, "no_speech_prob": 3.5895795008400455e-05}, {"id": 55, "seek": 21756, "start": 236.12, "end": 240.84, "text": " First, kind of describe the image, the content of the image, and how the image is expected", "tokens": [2386, 11, 733, 295, 6786, 264, 3256, 11, 264, 2701, 295, 264, 3256, 11, 293, 577, 264, 3256, 307, 5176], "temperature": 0.0, "avg_logprob": -0.13598985520620194, "compression_ratio": 1.8688524590163935, "no_speech_prob": 3.5895795008400455e-05}, {"id": 56, "seek": 21756, "start": 240.84, "end": 245.32, "text": " to be used so that sysadmins and end users know what to expect.", "tokens": [281, 312, 1143, 370, 300, 262, 749, 345, 76, 1292, 293, 917, 5022, 458, 437, 281, 2066, 13], "temperature": 0.0, "avg_logprob": -0.13598985520620194, "compression_ratio": 1.8688524590163935, "no_speech_prob": 3.5895795008400455e-05}, {"id": 57, "seek": 24532, "start": 245.32, "end": 248.51999999999998, "text": " So what user land is provided by the image?", "tokens": [407, 437, 4195, 2117, 307, 5649, 538, 264, 3256, 30], "temperature": 0.0, "avg_logprob": -0.1995257209329044, "compression_ratio": 1.5890410958904109, "no_speech_prob": 1.8334751075599343e-05}, {"id": 58, "seek": 24532, "start": 248.51999999999998, "end": 252.28, "text": " What tools are installed on the image?", "tokens": [708, 3873, 366, 8899, 322, 264, 3256, 30], "temperature": 0.0, "avg_logprob": -0.1995257209329044, "compression_ratio": 1.5890410958904109, "no_speech_prob": 1.8334751075599343e-05}, {"id": 59, "seek": 24532, "start": 252.28, "end": 257.52, "text": " How is the main application compiled, like for what target, for what microarchitecture", "tokens": [1012, 307, 264, 2135, 3861, 36548, 11, 411, 337, 437, 3779, 11, 337, 437, 4532, 1178, 5739, 540], "temperature": 0.0, "avg_logprob": -0.1995257209329044, "compression_ratio": 1.5890410958904109, "no_speech_prob": 1.8334751075599343e-05}, {"id": 60, "seek": 24532, "start": 257.52, "end": 263.15999999999997, "text": " of the CPU, for which GPU, which MPI is used and so on, so that we can take this information", "tokens": [295, 264, 13199, 11, 337, 597, 18407, 11, 597, 14146, 40, 307, 1143, 293, 370, 322, 11, 370, 300, 321, 393, 747, 341, 1589], "temperature": 0.0, "avg_logprob": -0.1995257209329044, "compression_ratio": 1.5890410958904109, "no_speech_prob": 1.8334751075599343e-05}, {"id": 61, "seek": 24532, "start": 263.15999999999997, "end": 271.03999999999996, "text": " and make maybe configuration examples for different container runtimes that hooks can", "tokens": [293, 652, 1310, 11694, 5110, 337, 819, 10129, 49435, 1532, 300, 26485, 393], "temperature": 0.0, "avg_logprob": -0.1995257209329044, "compression_ratio": 1.5890410958904109, "no_speech_prob": 1.8334751075599343e-05}, {"id": 62, "seek": 27104, "start": 271.04, "end": 275.6, "text": " react to those annotations, like potman and seros, for instance, they can already react", "tokens": [4515, 281, 729, 25339, 763, 11, 411, 1847, 1601, 293, 816, 329, 11, 337, 5197, 11, 436, 393, 1217, 4515], "temperature": 0.0, "avg_logprob": -0.1888843274298515, "compression_ratio": 1.8544061302681993, "no_speech_prob": 5.559582496061921e-05}, {"id": 63, "seek": 27104, "start": 275.6, "end": 276.6, "text": " to annotations.", "tokens": [281, 25339, 763, 13], "temperature": 0.0, "avg_logprob": -0.1888843274298515, "compression_ratio": 1.8544061302681993, "no_speech_prob": 5.559582496061921e-05}, {"id": 64, "seek": 27104, "start": 276.6, "end": 281.28000000000003, "text": " So depending on what the image provides as information, the runtime can adapt and say,", "tokens": [407, 5413, 322, 437, 264, 3256, 6417, 382, 1589, 11, 264, 34474, 393, 6231, 293, 584, 11], "temperature": 0.0, "avg_logprob": -0.1888843274298515, "compression_ratio": 1.8544061302681993, "no_speech_prob": 5.559582496061921e-05}, {"id": 65, "seek": 27104, "start": 281.28000000000003, "end": 285.92, "text": " okay, I have an open MPI container, I do this hook, I have an MPI base container, I take", "tokens": [1392, 11, 286, 362, 364, 1269, 14146, 40, 10129, 11, 286, 360, 341, 6328, 11, 286, 362, 364, 14146, 40, 3096, 10129, 11, 286, 747], "temperature": 0.0, "avg_logprob": -0.1888843274298515, "compression_ratio": 1.8544061302681993, "no_speech_prob": 5.559582496061921e-05}, {"id": 66, "seek": 27104, "start": 285.92, "end": 286.92, "text": " this hook.", "tokens": [341, 6328, 13], "temperature": 0.0, "avg_logprob": -0.1888843274298515, "compression_ratio": 1.8544061302681993, "no_speech_prob": 5.559582496061921e-05}, {"id": 67, "seek": 27104, "start": 286.92, "end": 293.32000000000005, "text": " So I think that would be great if we can agree on certain annotations and agreeing on certain", "tokens": [407, 286, 519, 300, 576, 312, 869, 498, 321, 393, 3986, 322, 1629, 25339, 763, 293, 36900, 322, 1629], "temperature": 0.0, "avg_logprob": -0.1888843274298515, "compression_ratio": 1.8544061302681993, "no_speech_prob": 5.559582496061921e-05}, {"id": 68, "seek": 27104, "start": 293.32000000000005, "end": 294.32000000000005, "text": " annotations.", "tokens": [25339, 763, 13], "temperature": 0.0, "avg_logprob": -0.1888843274298515, "compression_ratio": 1.8544061302681993, "no_speech_prob": 5.559582496061921e-05}, {"id": 69, "seek": 27104, "start": 294.32000000000005, "end": 298.8, "text": " I think it's a huge task, but I'm hopeful that we can achieve this, and then make sure", "tokens": [286, 519, 309, 311, 257, 2603, 5633, 11, 457, 286, 478, 20531, 300, 321, 393, 4584, 341, 11, 293, 550, 652, 988], "temperature": 0.0, "avg_logprob": -0.1888843274298515, "compression_ratio": 1.8544061302681993, "no_speech_prob": 5.559582496061921e-05}, {"id": 70, "seek": 29880, "start": 298.8, "end": 304.96000000000004, "text": " that the configuration is done so that the application is tweaked the right way.", "tokens": [300, 264, 11694, 307, 1096, 370, 300, 264, 3861, 307, 6986, 7301, 264, 558, 636, 13], "temperature": 0.0, "avg_logprob": -0.13442354382209057, "compression_ratio": 1.743801652892562, "no_speech_prob": 5.060357216279954e-05}, {"id": 71, "seek": 29880, "start": 304.96000000000004, "end": 309.96000000000004, "text": " And another piece that we can achieve here is that we create maybe a smoke test that", "tokens": [400, 1071, 2522, 300, 321, 393, 4584, 510, 307, 300, 321, 1884, 1310, 257, 8439, 1500, 300], "temperature": 0.0, "avg_logprob": -0.13442354382209057, "compression_ratio": 1.743801652892562, "no_speech_prob": 5.060357216279954e-05}, {"id": 72, "seek": 29880, "start": 309.96000000000004, "end": 314.8, "text": " looks at the host that is running on, looks at the annotations of the container that you", "tokens": [1542, 412, 264, 3975, 300, 307, 2614, 322, 11, 1542, 412, 264, 25339, 763, 295, 264, 10129, 300, 291], "temperature": 0.0, "avg_logprob": -0.13442354382209057, "compression_ratio": 1.743801652892562, "no_speech_prob": 5.060357216279954e-05}, {"id": 73, "seek": 29880, "start": 314.8, "end": 319.08000000000004, "text": " want to run, and just tells you, okay, this thing will sack fault anyway, you are on a", "tokens": [528, 281, 1190, 11, 293, 445, 5112, 291, 11, 1392, 11, 341, 551, 486, 33209, 7441, 4033, 11, 291, 366, 322, 257], "temperature": 0.0, "avg_logprob": -0.13442354382209057, "compression_ratio": 1.743801652892562, "no_speech_prob": 5.060357216279954e-05}, {"id": 74, "seek": 29880, "start": 319.08000000000004, "end": 323.76, "text": " send too and you have an application that's compiled for Skylake, it won't work.", "tokens": [2845, 886, 293, 291, 362, 364, 3861, 300, 311, 36548, 337, 9879, 75, 619, 11, 309, 1582, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.13442354382209057, "compression_ratio": 1.743801652892562, "no_speech_prob": 5.060357216279954e-05}, {"id": 75, "seek": 32376, "start": 323.76, "end": 329.92, "text": " So that you don't download 30 gigabytes of images of layers just to realize that your", "tokens": [407, 300, 291, 500, 380, 5484, 2217, 42741, 295, 5267, 295, 7914, 445, 281, 4325, 300, 428], "temperature": 0.0, "avg_logprob": -0.10830517738096175, "compression_ratio": 1.7338403041825095, "no_speech_prob": 3.70232664863579e-05}, {"id": 76, "seek": 32376, "start": 329.92, "end": 330.92, "text": " image won't work.", "tokens": [3256, 1582, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.10830517738096175, "compression_ratio": 1.7338403041825095, "no_speech_prob": 3.70232664863579e-05}, {"id": 77, "seek": 32376, "start": 330.92, "end": 334.2, "text": " So I think that's also a very important part that we can do this.", "tokens": [407, 286, 519, 300, 311, 611, 257, 588, 1021, 644, 300, 321, 393, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.10830517738096175, "compression_ratio": 1.7338403041825095, "no_speech_prob": 3.70232664863579e-05}, {"id": 78, "seek": 32376, "start": 334.2, "end": 340.03999999999996, "text": " Another part as well is not just describe the image, but make it easy for end users", "tokens": [3996, 644, 382, 731, 307, 406, 445, 6786, 264, 3256, 11, 457, 652, 309, 1858, 337, 917, 5022], "temperature": 0.0, "avg_logprob": -0.10830517738096175, "compression_ratio": 1.7338403041825095, "no_speech_prob": 3.70232664863579e-05}, {"id": 79, "seek": 32376, "start": 340.03999999999996, "end": 341.76, "text": " to discover what images are around.", "tokens": [281, 4411, 437, 5267, 366, 926, 13], "temperature": 0.0, "avg_logprob": -0.10830517738096175, "compression_ratio": 1.7338403041825095, "no_speech_prob": 3.70232664863579e-05}, {"id": 80, "seek": 32376, "start": 341.76, "end": 346.64, "text": " So you want to run Gromax, and you know or don't know the system you are on.", "tokens": [407, 291, 528, 281, 1190, 2606, 298, 2797, 11, 293, 291, 458, 420, 500, 380, 458, 264, 1185, 291, 366, 322, 13], "temperature": 0.0, "avg_logprob": -0.10830517738096175, "compression_ratio": 1.7338403041825095, "no_speech_prob": 3.70232664863579e-05}, {"id": 81, "seek": 32376, "start": 346.64, "end": 352.03999999999996, "text": " So maybe you can just run a tool or have a website that tells you you want to run Gromax.", "tokens": [407, 1310, 291, 393, 445, 1190, 257, 2290, 420, 362, 257, 3144, 300, 5112, 291, 291, 528, 281, 1190, 2606, 298, 2797, 13], "temperature": 0.0, "avg_logprob": -0.10830517738096175, "compression_ratio": 1.7338403041825095, "no_speech_prob": 3.70232664863579e-05}, {"id": 82, "seek": 35204, "start": 352.04, "end": 355.88, "text": " I have looked through all the annotations, I know a little bit about your system.", "tokens": [286, 362, 2956, 807, 439, 264, 25339, 763, 11, 286, 458, 257, 707, 857, 466, 428, 1185, 13], "temperature": 0.0, "avg_logprob": -0.14898720688707245, "compression_ratio": 1.7572463768115942, "no_speech_prob": 3.9420920074917376e-05}, {"id": 83, "seek": 35204, "start": 355.88, "end": 357.6, "text": " Here we go, this is the image that you want to use.", "tokens": [1692, 321, 352, 11, 341, 307, 264, 3256, 300, 291, 528, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.14898720688707245, "compression_ratio": 1.7572463768115942, "no_speech_prob": 3.9420920074917376e-05}, {"id": 84, "seek": 35204, "start": 357.6, "end": 360.96000000000004, "text": " So also for discovery, I think that's important.", "tokens": [407, 611, 337, 12114, 11, 286, 519, 300, 311, 1021, 13], "temperature": 0.0, "avg_logprob": -0.14898720688707245, "compression_ratio": 1.7572463768115942, "no_speech_prob": 3.9420920074917376e-05}, {"id": 85, "seek": 35204, "start": 360.96000000000004, "end": 365.04, "text": " Of course, we will have mandatory and optional annotations.", "tokens": [2720, 1164, 11, 321, 486, 362, 22173, 293, 17312, 25339, 763, 13], "temperature": 0.0, "avg_logprob": -0.14898720688707245, "compression_ratio": 1.7572463768115942, "no_speech_prob": 3.9420920074917376e-05}, {"id": 86, "seek": 35204, "start": 365.04, "end": 369.68, "text": " So mandatory ones might be what CPU architecture is it compiled for, I think that's the obvious", "tokens": [407, 22173, 2306, 1062, 312, 437, 13199, 9482, 307, 309, 36548, 337, 11, 286, 519, 300, 311, 264, 6322], "temperature": 0.0, "avg_logprob": -0.14898720688707245, "compression_ratio": 1.7572463768115942, "no_speech_prob": 3.9420920074917376e-05}, {"id": 87, "seek": 35204, "start": 369.68, "end": 370.68, "text": " one.", "tokens": [472, 13], "temperature": 0.0, "avg_logprob": -0.14898720688707245, "compression_ratio": 1.7572463768115942, "no_speech_prob": 3.9420920074917376e-05}, {"id": 88, "seek": 35204, "start": 370.68, "end": 376.16, "text": " And optional ones, of course, if you want to add a CUDA version because your image has", "tokens": [400, 17312, 2306, 11, 295, 1164, 11, 498, 291, 528, 281, 909, 257, 29777, 7509, 3037, 570, 428, 3256, 575], "temperature": 0.0, "avg_logprob": -0.14898720688707245, "compression_ratio": 1.7572463768115942, "no_speech_prob": 3.9420920074917376e-05}, {"id": 89, "seek": 35204, "start": 376.16, "end": 378.92, "text": " CUDA installed, then of course that's an optional one.", "tokens": [29777, 7509, 8899, 11, 550, 295, 1164, 300, 311, 364, 17312, 472, 13], "temperature": 0.0, "avg_logprob": -0.14898720688707245, "compression_ratio": 1.7572463768115942, "no_speech_prob": 3.9420920074917376e-05}, {"id": 90, "seek": 37892, "start": 378.92, "end": 383.96000000000004, "text": " Or you want to annotate the whole software bill of material.", "tokens": [1610, 291, 528, 281, 25339, 473, 264, 1379, 4722, 2961, 295, 2527, 13], "temperature": 0.0, "avg_logprob": -0.15888551076253254, "compression_ratio": 1.5574468085106383, "no_speech_prob": 3.479607403278351e-05}, {"id": 91, "seek": 37892, "start": 383.96000000000004, "end": 385.96000000000004, "text": " Maybe it's too much information, but maybe not.", "tokens": [2704, 309, 311, 886, 709, 1589, 11, 457, 1310, 406, 13], "temperature": 0.0, "avg_logprob": -0.15888551076253254, "compression_ratio": 1.5574468085106383, "no_speech_prob": 3.479607403278351e-05}, {"id": 92, "seek": 37892, "start": 385.96000000000004, "end": 391.32, "text": " So there are optional and mandatory annotations, I think that's pretty clear.", "tokens": [407, 456, 366, 17312, 293, 22173, 25339, 763, 11, 286, 519, 300, 311, 1238, 1850, 13], "temperature": 0.0, "avg_logprob": -0.15888551076253254, "compression_ratio": 1.5574468085106383, "no_speech_prob": 3.479607403278351e-05}, {"id": 93, "seek": 37892, "start": 391.32, "end": 397.68, "text": " And I created a couple of groups, like annotation groups that I think we should think about.", "tokens": [400, 286, 2942, 257, 1916, 295, 3935, 11, 411, 48654, 3935, 300, 286, 519, 321, 820, 519, 466, 13], "temperature": 0.0, "avg_logprob": -0.15888551076253254, "compression_ratio": 1.5574468085106383, "no_speech_prob": 3.479607403278351e-05}, {"id": 94, "seek": 37892, "start": 397.68, "end": 403.32, "text": " I won't go through every single line item here because I only have 10 minutes and it's", "tokens": [286, 1582, 380, 352, 807, 633, 2167, 1622, 3174, 510, 570, 286, 787, 362, 1266, 2077, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.15888551076253254, "compression_ratio": 1.5574468085106383, "no_speech_prob": 3.479607403278351e-05}, {"id": 95, "seek": 40332, "start": 403.32, "end": 408.92, "text": " only 3 minutes left, so just maybe grab the slides afterwards and then go through it and", "tokens": [787, 805, 2077, 1411, 11, 370, 445, 1310, 4444, 264, 9788, 10543, 293, 550, 352, 807, 309, 293], "temperature": 0.0, "avg_logprob": -0.1956008397615873, "compression_ratio": 1.657370517928287, "no_speech_prob": 5.644845441565849e-05}, {"id": 96, "seek": 40332, "start": 408.92, "end": 415.48, "text": " it's not written in stone, it's just a proposal, so happy to have feedback on this as well.", "tokens": [309, 311, 406, 3720, 294, 7581, 11, 309, 311, 445, 257, 11494, 11, 370, 2055, 281, 362, 5824, 322, 341, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1956008397615873, "compression_ratio": 1.657370517928287, "no_speech_prob": 5.644845441565849e-05}, {"id": 97, "seek": 40332, "start": 415.48, "end": 418.92, "text": " So the first big one, and I talked about it already, is of course hardware annotations.", "tokens": [407, 264, 700, 955, 472, 11, 293, 286, 2825, 466, 309, 1217, 11, 307, 295, 1164, 8837, 25339, 763, 13], "temperature": 0.0, "avg_logprob": -0.1956008397615873, "compression_ratio": 1.657370517928287, "no_speech_prob": 5.644845441565849e-05}, {"id": 98, "seek": 40332, "start": 418.92, "end": 426.24, "text": " So what is the target optimized for, the architecture, generic architecture or the real microarchitecture", "tokens": [407, 437, 307, 264, 3779, 26941, 337, 11, 264, 9482, 11, 19577, 9482, 420, 264, 957, 4532, 1178, 5739, 540], "temperature": 0.0, "avg_logprob": -0.1956008397615873, "compression_ratio": 1.657370517928287, "no_speech_prob": 5.644845441565849e-05}, {"id": 99, "seek": 40332, "start": 426.24, "end": 430.48, "text": " and then a key version, a value for this.", "tokens": [293, 550, 257, 2141, 3037, 11, 257, 2158, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.1956008397615873, "compression_ratio": 1.657370517928287, "no_speech_prob": 5.644845441565849e-05}, {"id": 100, "seek": 43048, "start": 430.48, "end": 435.56, "text": " As I said CUDA versions, driver versions and so on, I think that's obvious that we need", "tokens": [1018, 286, 848, 29777, 7509, 9606, 11, 6787, 9606, 293, 370, 322, 11, 286, 519, 300, 311, 6322, 300, 321, 643], "temperature": 0.0, "avg_logprob": -0.15839143899770883, "compression_ratio": 1.6951219512195121, "no_speech_prob": 4.0647679270477965e-05}, {"id": 101, "seek": 43048, "start": 435.56, "end": 440.92, "text": " to annotate the container so that it defines what the actual execution environment should", "tokens": [281, 25339, 473, 264, 10129, 370, 300, 309, 23122, 437, 264, 3539, 15058, 2823, 820], "temperature": 0.0, "avg_logprob": -0.15839143899770883, "compression_ratio": 1.6951219512195121, "no_speech_prob": 4.0647679270477965e-05}, {"id": 102, "seek": 43048, "start": 440.92, "end": 442.88, "text": " look like.", "tokens": [574, 411, 13], "temperature": 0.0, "avg_logprob": -0.15839143899770883, "compression_ratio": 1.6951219512195121, "no_speech_prob": 4.0647679270477965e-05}, {"id": 103, "seek": 43048, "start": 442.88, "end": 449.0, "text": " Also obvious HPC things like the MPI and interconnect annotations so that you define", "tokens": [2743, 6322, 12557, 34, 721, 411, 264, 14146, 40, 293, 26253, 25339, 763, 370, 300, 291, 6964], "temperature": 0.0, "avg_logprob": -0.15839143899770883, "compression_ratio": 1.6951219512195121, "no_speech_prob": 4.0647679270477965e-05}, {"id": 104, "seek": 43048, "start": 449.0, "end": 453.28000000000003, "text": " what the implementation of the container is, is it open MPI, is it image based, is it even", "tokens": [437, 264, 11420, 295, 264, 10129, 307, 11, 307, 309, 1269, 14146, 40, 11, 307, 309, 3256, 2361, 11, 307, 309, 754], "temperature": 0.0, "avg_logprob": -0.15839143899770883, "compression_ratio": 1.6951219512195121, "no_speech_prob": 4.0647679270477965e-05}, {"id": 105, "seek": 43048, "start": 453.28000000000003, "end": 457.12, "text": " thread MPI because you only want to run single node.", "tokens": [7207, 14146, 40, 570, 291, 787, 528, 281, 1190, 2167, 9984, 13], "temperature": 0.0, "avg_logprob": -0.15839143899770883, "compression_ratio": 1.6951219512195121, "no_speech_prob": 4.0647679270477965e-05}, {"id": 106, "seek": 45712, "start": 457.12, "end": 461.16, "text": " Not framework is used, libfabrics, ucx, what have you and now I'm going through all the", "tokens": [1726, 8388, 307, 1143, 11, 22854, 69, 455, 10716, 11, 344, 66, 87, 11, 437, 362, 291, 293, 586, 286, 478, 516, 807, 439, 264], "temperature": 0.0, "avg_logprob": -0.17265493349921435, "compression_ratio": 1.7275985663082438, "no_speech_prob": 4.827855445910245e-05}, {"id": 107, "seek": 45712, "start": 461.16, "end": 465.96, "text": " line items so maybe I should stop, but at the end I think the last line is also important.", "tokens": [1622, 4754, 370, 1310, 286, 820, 1590, 11, 457, 412, 264, 917, 286, 519, 264, 1036, 1622, 307, 611, 1021, 13], "temperature": 0.0, "avg_logprob": -0.17265493349921435, "compression_ratio": 1.7275985663082438, "no_speech_prob": 4.827855445910245e-05}, {"id": 108, "seek": 45712, "start": 465.96, "end": 471.96, "text": " What is the container, 2 minutes left even, what is the container actually, how is it", "tokens": [708, 307, 264, 10129, 11, 568, 2077, 1411, 754, 11, 437, 307, 264, 10129, 767, 11, 577, 307, 309], "temperature": 0.0, "avg_logprob": -0.17265493349921435, "compression_ratio": 1.7275985663082438, "no_speech_prob": 4.827855445910245e-05}, {"id": 109, "seek": 45712, "start": 471.96, "end": 477.8, "text": " expecting to be tweaked, so is the MPI being replaced, libfabric injected and so on, that's", "tokens": [9650, 281, 312, 6986, 7301, 11, 370, 307, 264, 14146, 40, 885, 10772, 11, 22854, 69, 455, 1341, 36967, 293, 370, 322, 11, 300, 311], "temperature": 0.0, "avg_logprob": -0.17265493349921435, "compression_ratio": 1.7275985663082438, "no_speech_prob": 4.827855445910245e-05}, {"id": 110, "seek": 45712, "start": 477.8, "end": 482.56, "text": " also I think important so that the sysadmin or the runtime knows what to do with the container", "tokens": [611, 286, 519, 1021, 370, 300, 264, 262, 749, 345, 2367, 420, 264, 34474, 3255, 437, 281, 360, 365, 264, 10129], "temperature": 0.0, "avg_logprob": -0.17265493349921435, "compression_ratio": 1.7275985663082438, "no_speech_prob": 4.827855445910245e-05}, {"id": 111, "seek": 45712, "start": 482.56, "end": 485.88, "text": " to make it work on line speed.", "tokens": [281, 652, 309, 589, 322, 1622, 3073, 13], "temperature": 0.0, "avg_logprob": -0.17265493349921435, "compression_ratio": 1.7275985663082438, "no_speech_prob": 4.827855445910245e-05}, {"id": 112, "seek": 48588, "start": 485.88, "end": 490.2, "text": " Sysadmin annotations I think is also important so that we know what the container expects", "tokens": [318, 749, 345, 2367, 25339, 763, 286, 519, 307, 611, 1021, 370, 300, 321, 458, 437, 264, 10129, 33280], "temperature": 0.0, "avg_logprob": -0.17500921944591485, "compression_ratio": 1.8008298755186722, "no_speech_prob": 6.104645581217483e-05}, {"id": 113, "seek": 48588, "start": 490.2, "end": 496.48, "text": " from the kernel, what the modules are introduced and so on and also what the end user can expect", "tokens": [490, 264, 28256, 11, 437, 264, 16679, 366, 7268, 293, 370, 322, 293, 611, 437, 264, 917, 4195, 393, 2066], "temperature": 0.0, "avg_logprob": -0.17500921944591485, "compression_ratio": 1.8008298755186722, "no_speech_prob": 6.104645581217483e-05}, {"id": 114, "seek": 48588, "start": 496.48, "end": 501.2, "text": " what tools are installed, is jq installed, is wget installed and so on.", "tokens": [437, 3873, 366, 8899, 11, 307, 361, 80, 8899, 11, 307, 261, 847, 8899, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.17500921944591485, "compression_ratio": 1.8008298755186722, "no_speech_prob": 6.104645581217483e-05}, {"id": 115, "seek": 48588, "start": 501.2, "end": 506.52, "text": " Another annotation is of course documentation would be nice as well, base64 encoded markdown", "tokens": [3996, 48654, 307, 295, 1164, 14333, 576, 312, 1481, 382, 731, 11, 3096, 19395, 2058, 12340, 1491, 5093], "temperature": 0.0, "avg_logprob": -0.17500921944591485, "compression_ratio": 1.8008298755186722, "no_speech_prob": 6.104645581217483e-05}, {"id": 116, "seek": 48588, "start": 506.52, "end": 512.44, "text": " would be great so that you can render how-tos and build tweaks and so on directly.", "tokens": [576, 312, 869, 370, 300, 291, 393, 15529, 577, 12, 83, 329, 293, 1322, 46664, 293, 370, 322, 3838, 13], "temperature": 0.0, "avg_logprob": -0.17500921944591485, "compression_ratio": 1.8008298755186722, "no_speech_prob": 6.104645581217483e-05}, {"id": 117, "seek": 51244, "start": 512.44, "end": 518.5200000000001, "text": " Okay, one minute, how to annotate, I think that's obvious as well that's a layered approach,", "tokens": [1033, 11, 472, 3456, 11, 577, 281, 25339, 473, 11, 286, 519, 300, 311, 6322, 382, 731, 300, 311, 257, 34666, 3109, 11], "temperature": 0.0, "avg_logprob": -0.14189823395615325, "compression_ratio": 1.8470588235294119, "no_speech_prob": 9.164976654574275e-05}, {"id": 118, "seek": 51244, "start": 518.5200000000001, "end": 523.6, "text": " of course the base image should have annotations that we can carry over and if you build subsequent", "tokens": [295, 1164, 264, 3096, 3256, 820, 362, 25339, 763, 300, 321, 393, 3985, 670, 293, 498, 291, 1322, 19962], "temperature": 0.0, "avg_logprob": -0.14189823395615325, "compression_ratio": 1.8470588235294119, "no_speech_prob": 9.164976654574275e-05}, {"id": 119, "seek": 51244, "start": 523.6, "end": 530.6800000000001, "text": " images at the annotations that are important and after the image is already built you can", "tokens": [5267, 412, 264, 25339, 763, 300, 366, 1021, 293, 934, 264, 3256, 307, 1217, 3094, 291, 393], "temperature": 0.0, "avg_logprob": -0.14189823395615325, "compression_ratio": 1.8470588235294119, "no_speech_prob": 9.164976654574275e-05}, {"id": 120, "seek": 51244, "start": 530.6800000000001, "end": 536.32, "text": " use things like crane or builder or podman I think or builder to annotate images at the", "tokens": [764, 721, 411, 36345, 420, 27377, 420, 2497, 1601, 286, 519, 420, 27377, 281, 25339, 473, 5267, 412, 264], "temperature": 0.0, "avg_logprob": -0.14189823395615325, "compression_ratio": 1.8470588235294119, "no_speech_prob": 9.164976654574275e-05}, {"id": 121, "seek": 51244, "start": 536.32, "end": 542.4000000000001, "text": " end without even rebuilding them, just repurposing them or we could also collect annotations offline", "tokens": [917, 1553, 754, 36717, 552, 11, 445, 1085, 20130, 6110, 552, 420, 321, 727, 611, 2500, 25339, 763, 21857], "temperature": 0.0, "avg_logprob": -0.14189823395615325, "compression_ratio": 1.8470588235294119, "no_speech_prob": 9.164976654574275e-05}, {"id": 122, "seek": 54240, "start": 542.4, "end": 546.1999999999999, "text": " in another format and then annotate it.", "tokens": [294, 1071, 7877, 293, 550, 25339, 473, 309, 13], "temperature": 0.0, "avg_logprob": -0.16500069050306684, "compression_ratio": 1.619047619047619, "no_speech_prob": 3.8216727261897177e-05}, {"id": 123, "seek": 54240, "start": 546.1999999999999, "end": 552.52, "text": " Okay, ideally and that's like Kenneth and of course Todd as well, easy build, spec,", "tokens": [1033, 11, 22915, 293, 300, 311, 411, 33735, 293, 295, 1164, 21488, 382, 731, 11, 1858, 1322, 11, 1608, 11], "temperature": 0.0, "avg_logprob": -0.16500069050306684, "compression_ratio": 1.619047619047619, "no_speech_prob": 3.8216727261897177e-05}, {"id": 124, "seek": 54240, "start": 552.52, "end": 557.36, "text": " they should annotate it correctly so that we don't need to teach everyone to annotate", "tokens": [436, 820, 25339, 473, 309, 8944, 370, 300, 321, 500, 380, 643, 281, 2924, 1518, 281, 25339, 473], "temperature": 0.0, "avg_logprob": -0.16500069050306684, "compression_ratio": 1.619047619047619, "no_speech_prob": 3.8216727261897177e-05}, {"id": 125, "seek": 54240, "start": 557.36, "end": 560.68, "text": " but the tools just annotate the image for us.", "tokens": [457, 264, 3873, 445, 25339, 473, 264, 3256, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.16500069050306684, "compression_ratio": 1.619047619047619, "no_speech_prob": 3.8216727261897177e-05}, {"id": 126, "seek": 54240, "start": 560.68, "end": 567.76, "text": " And that's the external piece so I created a tool MetaHub where we define images for", "tokens": [400, 300, 311, 264, 8320, 2522, 370, 286, 2942, 257, 2290, 6377, 64, 21150, 689, 321, 6964, 5267, 337], "temperature": 0.0, "avg_logprob": -0.16500069050306684, "compression_ratio": 1.619047619047619, "no_speech_prob": 3.8216727261897177e-05}, {"id": 127, "seek": 56776, "start": 567.76, "end": 572.68, "text": " different use cases and we can also annotate those images without actually changing the", "tokens": [819, 764, 3331, 293, 321, 393, 611, 25339, 473, 729, 5267, 1553, 767, 4473, 264], "temperature": 0.0, "avg_logprob": -0.17433287773603273, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.0616610678844154e-05}, {"id": 128, "seek": 56776, "start": 572.68, "end": 573.92, "text": " image but just with this.", "tokens": [3256, 457, 445, 365, 341, 13], "temperature": 0.0, "avg_logprob": -0.17433287773603273, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.0616610678844154e-05}, {"id": 129, "seek": 56776, "start": 573.92, "end": 577.4399999999999, "text": " So okay, 10 seconds, last one.", "tokens": [407, 1392, 11, 1266, 3949, 11, 1036, 472, 13], "temperature": 0.0, "avg_logprob": -0.17433287773603273, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.0616610678844154e-05}, {"id": 130, "seek": 56776, "start": 577.4399999999999, "end": 584.8, "text": " We need of course a fingerprint of the system to match the annotations against the host", "tokens": [492, 643, 295, 1164, 257, 30715, 295, 264, 1185, 281, 2995, 264, 25339, 763, 1970, 264, 3975], "temperature": 0.0, "avg_logprob": -0.17433287773603273, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.0616610678844154e-05}, {"id": 131, "seek": 56776, "start": 584.8, "end": 590.88, "text": " itself so there needs to be a tool, time is up and yeah, so we need to discover the right", "tokens": [2564, 370, 456, 2203, 281, 312, 257, 2290, 11, 565, 307, 493, 293, 1338, 11, 370, 321, 643, 281, 4411, 264, 558], "temperature": 0.0, "avg_logprob": -0.17433287773603273, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.0616610678844154e-05}, {"id": 132, "seek": 59088, "start": 590.88, "end": 598.0, "text": " image, need to have a smoke test and help tweak the container.", "tokens": [3256, 11, 643, 281, 362, 257, 8439, 1500, 293, 854, 29879, 264, 10129, 13], "temperature": 0.0, "avg_logprob": -0.3027760982513428, "compression_ratio": 1.4691358024691359, "no_speech_prob": 0.00017258545267395675}, {"id": 133, "seek": 59088, "start": 598.0, "end": 606.16, "text": " That's like the last bit so I think that's it.", "tokens": [663, 311, 411, 264, 1036, 857, 370, 286, 519, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.3027760982513428, "compression_ratio": 1.4691358024691359, "no_speech_prob": 0.00017258545267395675}, {"id": 134, "seek": 59088, "start": 606.16, "end": 611.6, "text": " Thank you for the excellent example on how to do a lightning talk on time, we'll take", "tokens": [1044, 291, 337, 264, 7103, 1365, 322, 577, 281, 360, 257, 16589, 751, 322, 565, 11, 321, 603, 747], "temperature": 0.0, "avg_logprob": -0.3027760982513428, "compression_ratio": 1.4691358024691359, "no_speech_prob": 0.00017258545267395675}, {"id": 135, "seek": 59088, "start": 611.6, "end": 614.68, "text": " one question, any questions for Christian?", "tokens": [472, 1168, 11, 604, 1651, 337, 5778, 30], "temperature": 0.0, "avg_logprob": -0.3027760982513428, "compression_ratio": 1.4691358024691359, "no_speech_prob": 0.00017258545267395675}, {"id": 136, "seek": 61468, "start": 614.68, "end": 622.68, "text": " Do you need the clicker?", "tokens": [1144, 291, 643, 264, 2052, 260, 30], "temperature": 0.0, "avg_logprob": -0.2912289301554362, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.00025528197875246406}, {"id": 137, "seek": 61468, "start": 622.68, "end": 628.04, "text": " Thank you for your presentation, I would like to ask how does this relate to like existing", "tokens": [1044, 291, 337, 428, 5860, 11, 286, 576, 411, 281, 1029, 577, 775, 341, 10961, 281, 411, 6741], "temperature": 0.0, "avg_logprob": -0.2912289301554362, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.00025528197875246406}, {"id": 138, "seek": 61468, "start": 628.04, "end": 634.68, "text": " software supply chain method databases like GraphiS, does this complement their functionality,", "tokens": [4722, 5847, 5021, 3170, 22380, 411, 21884, 72, 50, 11, 775, 341, 17103, 641, 14980, 11], "temperature": 0.0, "avg_logprob": -0.2912289301554362, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.00025528197875246406}, {"id": 139, "seek": 61468, "start": 634.68, "end": 636.68, "text": " is this completely something different?", "tokens": [307, 341, 2584, 746, 819, 30], "temperature": 0.0, "avg_logprob": -0.2912289301554362, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.00025528197875246406}, {"id": 140, "seek": 61468, "start": 636.68, "end": 640.8, "text": " I mean we are good at HPC to build our own thing and then just say that everyone should", "tokens": [286, 914, 321, 366, 665, 412, 12557, 34, 281, 1322, 527, 1065, 551, 293, 550, 445, 584, 300, 1518, 820], "temperature": 0.0, "avg_logprob": -0.2912289301554362, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.00025528197875246406}, {"id": 141, "seek": 61468, "start": 640.8, "end": 641.8, "text": " adopt it.", "tokens": [6878, 309, 13], "temperature": 0.0, "avg_logprob": -0.2912289301554362, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.00025528197875246406}, {"id": 142, "seek": 64180, "start": 641.8, "end": 647.64, "text": " We want to complement it, we want to use these two applications and go to the exercise and", "tokens": [492, 528, 281, 17103, 309, 11, 321, 528, 281, 764, 613, 732, 5821, 293, 352, 281, 264, 5380, 293], "temperature": 0.0, "avg_logprob": -0.15667056146069108, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0016123552341014147}, {"id": 143, "seek": 64180, "start": 647.64, "end": 653.1999999999999, "text": " then maybe learn from what we did with this project and try to push these ideas also in", "tokens": [550, 1310, 1466, 490, 437, 321, 630, 365, 341, 1716, 293, 853, 281, 2944, 613, 3487, 611, 294], "temperature": 0.0, "avg_logprob": -0.15667056146069108, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0016123552341014147}, {"id": 144, "seek": 64180, "start": 653.1999999999999, "end": 654.1999999999999, "text": " other things.", "tokens": [661, 721, 13], "temperature": 0.0, "avg_logprob": -0.15667056146069108, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0016123552341014147}, {"id": 145, "seek": 64180, "start": 654.1999999999999, "end": 659.9599999999999, "text": " But I think the AIML folks maybe didn't realize that they won't have this problem so we try", "tokens": [583, 286, 519, 264, 316, 6324, 43, 4024, 1310, 994, 380, 4325, 300, 436, 1582, 380, 362, 341, 1154, 370, 321, 853], "temperature": 0.0, "avg_logprob": -0.15667056146069108, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0016123552341014147}, {"id": 146, "seek": 64180, "start": 659.9599999999999, "end": 665.04, "text": " also to not only think about HPC here but also think about other communities as well.", "tokens": [611, 281, 406, 787, 519, 466, 12557, 34, 510, 457, 611, 519, 466, 661, 4456, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.15667056146069108, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0016123552341014147}, {"id": 147, "seek": 64180, "start": 665.04, "end": 671.0, "text": " So I'm open to everyone and the project is as well.", "tokens": [407, 286, 478, 1269, 281, 1518, 293, 264, 1716, 307, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.15667056146069108, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0016123552341014147}, {"id": 148, "seek": 67100, "start": 671.0, "end": 674.72, "text": " Thank you very much Christian, if you want to chat with Christian he'll be around probably", "tokens": [1044, 291, 588, 709, 5778, 11, 498, 291, 528, 281, 5081, 365, 5778, 415, 603, 312, 926, 1391], "temperature": 0.0, "avg_logprob": -0.17061503728230795, "compression_ratio": 1.3834586466165413, "no_speech_prob": 0.006757647264748812}, {"id": 149, "seek": 67100, "start": 674.72, "end": 679.52, "text": " outside the door for the rest of the day or in the room and we'll switch it over to the", "tokens": [2380, 264, 2853, 337, 264, 1472, 295, 264, 786, 420, 294, 264, 1808, 293, 321, 603, 3679, 309, 670, 281, 264], "temperature": 0.0, "avg_logprob": -0.17061503728230795, "compression_ratio": 1.3834586466165413, "no_speech_prob": 0.006757647264748812}, {"id": 150, "seek": 67952, "start": 679.52, "end": 708.54, "text": " next.", "tokens": [50364, 958, 13, 51815], "temperature": 1.0, "avg_logprob": -1.2803842544555664, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.0008322678040713072}], "language": "en"}