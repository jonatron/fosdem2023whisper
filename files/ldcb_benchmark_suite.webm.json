{"text": " Hello, HPC Room, my name is Gabor Sarnas. I work at CWI Amsterdam as a researcher, and today I'm here on behalf of the LDBC. The LDBC stands for the Linked Data Benchmark Council. We are a non-profit company founded in 2012, and we design graph benchmarks and govern their use. Additionally, we do research on graph schemas and modern graph queue languages, and everything we do is available under the Apache V2 license. Organizationally, LDBC consists of more than 20 companies. These are companies interested in graph data management. We have financial service providers, database vendors, cloud vendors, hardware vendors, and consultancy companies, as well as individual contributors like me. So we design benchmarks, the first one being the LDBC social network benchmark, which targets database systems. Let's go through this benchmark by a series of examples. I will touch on datasets, queries, and updates that we use in this benchmark. As the name social network benchmark suggests, we have a social network that consists of person nodes who know each other via a distribution that mimics the Facebook career social network. The content that these people create is messages. These form little three-shaped subgraphs and are connected via author edges to the people. On this graph, we can run queries like the following. Let's have a given person enumerate their friends and their friends of friends, get the messages that these people created, and then filter them based on some condition on their dates. So a potential substitution could be on this graph that we are interested in this query for Bob and the date set on Saturday. And if we evaluate this query, we start with Bob. We traverse the nose edges to Ada and Carl, then continue to Finn, Eve, and then we move along the author edges. And then finally, we apply the filter condition, which will cut message three and will leave us messages one, two, and four. So obviously, a social network is not a static environment. There are always changes. For example, people become friends, even Gia may add each other as a friend. That will result in a new nose edge. That's simple enough. Gia can decide to create a message. This message will be replied to message M3. So we add a new node and connect it to the existing graph via two edges. The heavy hitting updates are the deletes. A person may decide to delete their account, and that will result in a cascade of deletes. For example, if we remove the node Eve, that will result in the removal of their direct edges, all the messages they created. And in some social network, this will even trigger the deletion of all the message trees and, of course, all the edges that point to those messages. So this is quite a hard operation for systems to execute. It stresses their garbage collectors, and this allows certain append-only data structures. So if you want to weave these three components together, the data set, the queries, and the updates, we need a benchmark driver that schedules the operations to be executable. It runs the updates and the queries concurrently, and, of course, it collects the results. The system under test that we run the benchmark on is provided by our members who are the database vendors, and we go to great lengths to allow as many candidate systems as possible, so graph databases, triple stores, and relational databases can all compete on this benchmark. Speaking of relational databases, some of you may think is SQL sufficient to express these queries, and the answer is that in most cases it is. So the query that we have just seen can be formulated in a reasonably simple SQL query. It is a bit unwieldy, but it is certainly doable, and the performance will be okay. However, this being a graph benchmark, it lends itself quite naturally to other query languages. There are two new query languages that are going to be coming out, and both of them adopted a visual graph syntax inspired by Neo4j's Cypher language. The first one is called SQL-PGQ, where PGQ stands for property graph queries. This will be released this summer, and as you can see, it's an extension to SQL, so you can use select and from, but it adds the graph table construct, and the query can be formulated in a very concise and readable manner. There is GQL, the graph query language, which is a standalone language that is going to be released next year, and it shares the same pattern matching language as SQL-PGQ. So the social network benchmark has multiple workloads to cover the diverse challenges that are created by graph workloads. The first one, the older one, is the social network benchmark interactive workload. This is transactional in nature, and it has queries like the one I have shown before. So these queries typically start in one or two person nodes. They are not very heavy hitting. They only touch on a limited amount of data. They have concurrent reads and updates, and systems are competing on achieving high throughputs. So this benchmark has been around for a few years, and we have seen actually very good results. In the last three years, we witnessed an exponential increase in throughput, starting from a little above 5,000 operations per second to almost 17,000 operations per second this year. Our newer benchmark is the social network benchmark business intelligence workload. This is analytical in nature, and it has queries that touch on large portions of the data. For example, the query on this slide enumerates all triangles of friendships in a given country which can potentially reach billions of edges, and is a very difficult computational problem. Systems here are allowed to do either a bulk or a concurrent update approach, but they should strive to get both a high throughput and low individual query runtimes. This benchmark being relatively new, we only have a single result, so it's a bit difficult to put it into context. But it allows me to highlight one thing. Many of our benchmarks use different CPUs. We actually have quite a healthy diversity in the CPUs. We have results with the AMD Epic Genoa, like this one achieved by TigerGraph. We have results using Intel Xeon Ice Lakes and the ETN 710s, which use an ARM architecture. We have more and larger scale results expected this year, and we are also quite interested in some graph and machine learning accelerators that are going to be released soon. So our benchmark process is quite involved. For each workload, we release a specification. We have an academic paper that motivates the benchmark. We have data generators, pre-generated data sets, as well as a benchmark driver and at least two reference implementations. We do this because we have an auditing process that allows the vendors to implement this benchmark to actually go through a rigorous test, and if they do so, they can claim that they have an official benchmark result. So we trademark the term ADBC such that the vendors have to go through these hoops of auditing, and we still allow researchers and developers to do unofficial benchmarks, but they have to say that this is not unofficial ADBC benchmark result. Another benchmark I would like to touch upon briefly is the Graph Analytics benchmark. This casts a wider net, so it targets graph databases, graph processing framework, embedded graph libraries like NetworkX and so on. This uses untyped, unattributed graphs, so it's only the person knows person graphs of the social network benchmark or other well-known graphs like Graph 500. We have six algorithms. Many of these are textbook algorithms like BFS, which just traverses the graph from a given source node, or we have PageRank, which selects the most important nodes in the network. We also have clustering coefficient, community detection, connected components, and shortest paths. This benchmark is a bit simpler to implement. We have a leaderboard that we update periodically. The next one is going to come out in Spring 2023, so talk to us if you're interested. So wrapping up, you should consider becoming an ADBC member because members can participate in the benchmark design and have a say in where we go, they can commission audits of their benchmarks, and they can also gain early access to the ISO standard drafts, SQL, PGQ, and GQ that I have shown. It's free for individuals and has a yearly fee for companies. So to sum up, these are our three main benchmarks. We have other benchmarks and many future ideas. If you're interested, please reach out. Again we have time for one question. Any questions for Gabor? This is a newbie question. I'm not into graphs. Apart from advertisement, optimization, mass surveillance, and perhaps content distribution, which I don't know if they're the major applications, but it's just what my naive minds come with. What other applications are those benchmarks meant to optimize? So the big one this year is supply chain optimization, like strengthening supply chains, ensuring that they are ethical, ensuring that they are not passing conflict zones. It's something that is very important these days. You can also track CO2 emissions and other aspects of labor and manufacturing. So that's certainly a big one, and that's something that we have seen. And there are, of course, all the graphic problems like power grid, a lot of e-commerce programs, and the financial fraud detection, which is going to be part of our financial benchmark this year.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.8, "text": " Hello, HPC Room, my name is Gabor Sarnas.", "tokens": [2425, 11, 12557, 34, 19190, 11, 452, 1315, 307, 460, 3816, 318, 1083, 296, 13], "temperature": 0.0, "avg_logprob": -0.21301501005598641, "compression_ratio": 1.488, "no_speech_prob": 0.26845431327819824}, {"id": 1, "seek": 0, "start": 7.8, "end": 14.24, "text": " I work at CWI Amsterdam as a researcher, and today I'm here on behalf of the LDBC.", "tokens": [286, 589, 412, 383, 54, 40, 28291, 382, 257, 21751, 11, 293, 965, 286, 478, 510, 322, 9490, 295, 264, 33936, 7869, 13], "temperature": 0.0, "avg_logprob": -0.21301501005598641, "compression_ratio": 1.488, "no_speech_prob": 0.26845431327819824}, {"id": 2, "seek": 0, "start": 14.24, "end": 17.36, "text": " The LDBC stands for the Linked Data Benchmark Council.", "tokens": [440, 33936, 7869, 7382, 337, 264, 19322, 11888, 3964, 339, 5638, 7076, 13], "temperature": 0.0, "avg_logprob": -0.21301501005598641, "compression_ratio": 1.488, "no_speech_prob": 0.26845431327819824}, {"id": 3, "seek": 0, "start": 17.36, "end": 22.56, "text": " We are a non-profit company founded in 2012, and we design graph benchmarks and govern", "tokens": [492, 366, 257, 2107, 12, 14583, 2237, 13234, 294, 9125, 11, 293, 321, 1715, 4295, 43751, 293, 1980], "temperature": 0.0, "avg_logprob": -0.21301501005598641, "compression_ratio": 1.488, "no_speech_prob": 0.26845431327819824}, {"id": 4, "seek": 0, "start": 22.56, "end": 23.56, "text": " their use.", "tokens": [641, 764, 13], "temperature": 0.0, "avg_logprob": -0.21301501005598641, "compression_ratio": 1.488, "no_speech_prob": 0.26845431327819824}, {"id": 5, "seek": 0, "start": 23.56, "end": 28.16, "text": " Additionally, we do research on graph schemas and modern graph queue languages, and everything", "tokens": [19927, 11, 321, 360, 2132, 322, 4295, 22627, 296, 293, 4363, 4295, 18639, 8650, 11, 293, 1203], "temperature": 0.0, "avg_logprob": -0.21301501005598641, "compression_ratio": 1.488, "no_speech_prob": 0.26845431327819824}, {"id": 6, "seek": 2816, "start": 28.16, "end": 32.68, "text": " we do is available under the Apache V2 license.", "tokens": [321, 360, 307, 2435, 833, 264, 46597, 691, 17, 10476, 13], "temperature": 0.0, "avg_logprob": -0.1791940669423526, "compression_ratio": 1.6133828996282529, "no_speech_prob": 0.00022343828459270298}, {"id": 7, "seek": 2816, "start": 32.68, "end": 36.2, "text": " Organizationally, LDBC consists of more than 20 companies.", "tokens": [23979, 379, 11, 33936, 7869, 14689, 295, 544, 813, 945, 3431, 13], "temperature": 0.0, "avg_logprob": -0.1791940669423526, "compression_ratio": 1.6133828996282529, "no_speech_prob": 0.00022343828459270298}, {"id": 8, "seek": 2816, "start": 36.2, "end": 39.04, "text": " These are companies interested in graph data management.", "tokens": [1981, 366, 3431, 3102, 294, 4295, 1412, 4592, 13], "temperature": 0.0, "avg_logprob": -0.1791940669423526, "compression_ratio": 1.6133828996282529, "no_speech_prob": 0.00022343828459270298}, {"id": 9, "seek": 2816, "start": 39.04, "end": 44.36, "text": " We have financial service providers, database vendors, cloud vendors, hardware vendors, and", "tokens": [492, 362, 4669, 2643, 11330, 11, 8149, 22056, 11, 4588, 22056, 11, 8837, 22056, 11, 293], "temperature": 0.0, "avg_logprob": -0.1791940669423526, "compression_ratio": 1.6133828996282529, "no_speech_prob": 0.00022343828459270298}, {"id": 10, "seek": 2816, "start": 44.36, "end": 49.08, "text": " consultancy companies, as well as individual contributors like me.", "tokens": [7189, 6717, 3431, 11, 382, 731, 382, 2609, 45627, 411, 385, 13], "temperature": 0.0, "avg_logprob": -0.1791940669423526, "compression_ratio": 1.6133828996282529, "no_speech_prob": 0.00022343828459270298}, {"id": 11, "seek": 2816, "start": 49.08, "end": 54.44, "text": " So we design benchmarks, the first one being the LDBC social network benchmark, which targets", "tokens": [407, 321, 1715, 43751, 11, 264, 700, 472, 885, 264, 33936, 7869, 2093, 3209, 18927, 11, 597, 12911], "temperature": 0.0, "avg_logprob": -0.1791940669423526, "compression_ratio": 1.6133828996282529, "no_speech_prob": 0.00022343828459270298}, {"id": 12, "seek": 2816, "start": 54.44, "end": 56.6, "text": " database systems.", "tokens": [8149, 3652, 13], "temperature": 0.0, "avg_logprob": -0.1791940669423526, "compression_ratio": 1.6133828996282529, "no_speech_prob": 0.00022343828459270298}, {"id": 13, "seek": 5660, "start": 56.6, "end": 60.52, "text": " Let's go through this benchmark by a series of examples.", "tokens": [961, 311, 352, 807, 341, 18927, 538, 257, 2638, 295, 5110, 13], "temperature": 0.0, "avg_logprob": -0.1115391595023019, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.000359626516001299}, {"id": 14, "seek": 5660, "start": 60.52, "end": 65.48, "text": " I will touch on datasets, queries, and updates that we use in this benchmark.", "tokens": [286, 486, 2557, 322, 42856, 11, 24109, 11, 293, 9205, 300, 321, 764, 294, 341, 18927, 13], "temperature": 0.0, "avg_logprob": -0.1115391595023019, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.000359626516001299}, {"id": 15, "seek": 5660, "start": 65.48, "end": 70.6, "text": " As the name social network benchmark suggests, we have a social network that consists of", "tokens": [1018, 264, 1315, 2093, 3209, 18927, 13409, 11, 321, 362, 257, 2093, 3209, 300, 14689, 295], "temperature": 0.0, "avg_logprob": -0.1115391595023019, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.000359626516001299}, {"id": 16, "seek": 5660, "start": 70.6, "end": 77.04, "text": " person nodes who know each other via a distribution that mimics the Facebook career social network.", "tokens": [954, 13891, 567, 458, 1184, 661, 5766, 257, 7316, 300, 12247, 1167, 264, 4384, 3988, 2093, 3209, 13], "temperature": 0.0, "avg_logprob": -0.1115391595023019, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.000359626516001299}, {"id": 17, "seek": 5660, "start": 77.04, "end": 80.08, "text": " The content that these people create is messages.", "tokens": [440, 2701, 300, 613, 561, 1884, 307, 7897, 13], "temperature": 0.0, "avg_logprob": -0.1115391595023019, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.000359626516001299}, {"id": 18, "seek": 5660, "start": 80.08, "end": 85.68, "text": " These form little three-shaped subgraphs and are connected via author edges to the people.", "tokens": [1981, 1254, 707, 1045, 12, 23103, 1422, 34091, 82, 293, 366, 4582, 5766, 3793, 8819, 281, 264, 561, 13], "temperature": 0.0, "avg_logprob": -0.1115391595023019, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.000359626516001299}, {"id": 19, "seek": 8568, "start": 85.68, "end": 88.76, "text": " On this graph, we can run queries like the following.", "tokens": [1282, 341, 4295, 11, 321, 393, 1190, 24109, 411, 264, 3480, 13], "temperature": 0.0, "avg_logprob": -0.11246260474709903, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.00033682549837976694}, {"id": 20, "seek": 8568, "start": 88.76, "end": 94.12, "text": " Let's have a given person enumerate their friends and their friends of friends, get", "tokens": [961, 311, 362, 257, 2212, 954, 465, 15583, 473, 641, 1855, 293, 641, 1855, 295, 1855, 11, 483], "temperature": 0.0, "avg_logprob": -0.11246260474709903, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.00033682549837976694}, {"id": 21, "seek": 8568, "start": 94.12, "end": 98.64000000000001, "text": " the messages that these people created, and then filter them based on some condition on", "tokens": [264, 7897, 300, 613, 561, 2942, 11, 293, 550, 6608, 552, 2361, 322, 512, 4188, 322], "temperature": 0.0, "avg_logprob": -0.11246260474709903, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.00033682549837976694}, {"id": 22, "seek": 8568, "start": 98.64000000000001, "end": 99.76, "text": " their dates.", "tokens": [641, 11691, 13], "temperature": 0.0, "avg_logprob": -0.11246260474709903, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.00033682549837976694}, {"id": 23, "seek": 8568, "start": 99.76, "end": 104.44000000000001, "text": " So a potential substitution could be on this graph that we are interested in this query", "tokens": [407, 257, 3995, 35827, 727, 312, 322, 341, 4295, 300, 321, 366, 3102, 294, 341, 14581], "temperature": 0.0, "avg_logprob": -0.11246260474709903, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.00033682549837976694}, {"id": 24, "seek": 8568, "start": 104.44000000000001, "end": 107.64000000000001, "text": " for Bob and the date set on Saturday.", "tokens": [337, 6085, 293, 264, 4002, 992, 322, 8803, 13], "temperature": 0.0, "avg_logprob": -0.11246260474709903, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.00033682549837976694}, {"id": 25, "seek": 8568, "start": 107.64000000000001, "end": 110.60000000000001, "text": " And if we evaluate this query, we start with Bob.", "tokens": [400, 498, 321, 13059, 341, 14581, 11, 321, 722, 365, 6085, 13], "temperature": 0.0, "avg_logprob": -0.11246260474709903, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.00033682549837976694}, {"id": 26, "seek": 11060, "start": 110.6, "end": 116.67999999999999, "text": " We traverse the nose edges to Ada and Carl, then continue to Finn, Eve, and then we move", "tokens": [492, 45674, 264, 6690, 8819, 281, 32276, 293, 14256, 11, 550, 2354, 281, 21066, 11, 15544, 11, 293, 550, 321, 1286], "temperature": 0.0, "avg_logprob": -0.1970727795460185, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.0006058955332264304}, {"id": 27, "seek": 11060, "start": 116.67999999999999, "end": 118.36, "text": " along the author edges.", "tokens": [2051, 264, 3793, 8819, 13], "temperature": 0.0, "avg_logprob": -0.1970727795460185, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.0006058955332264304}, {"id": 28, "seek": 11060, "start": 118.36, "end": 123.6, "text": " And then finally, we apply the filter condition, which will cut message three and will leave", "tokens": [400, 550, 2721, 11, 321, 3079, 264, 6608, 4188, 11, 597, 486, 1723, 3636, 1045, 293, 486, 1856], "temperature": 0.0, "avg_logprob": -0.1970727795460185, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.0006058955332264304}, {"id": 29, "seek": 11060, "start": 123.6, "end": 126.84, "text": " us messages one, two, and four.", "tokens": [505, 7897, 472, 11, 732, 11, 293, 1451, 13], "temperature": 0.0, "avg_logprob": -0.1970727795460185, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.0006058955332264304}, {"id": 30, "seek": 11060, "start": 126.84, "end": 129.84, "text": " So obviously, a social network is not a static environment.", "tokens": [407, 2745, 11, 257, 2093, 3209, 307, 406, 257, 13437, 2823, 13], "temperature": 0.0, "avg_logprob": -0.1970727795460185, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.0006058955332264304}, {"id": 31, "seek": 11060, "start": 129.84, "end": 131.12, "text": " There are always changes.", "tokens": [821, 366, 1009, 2962, 13], "temperature": 0.0, "avg_logprob": -0.1970727795460185, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.0006058955332264304}, {"id": 32, "seek": 11060, "start": 131.12, "end": 135.79999999999998, "text": " For example, people become friends, even Gia may add each other as a friend.", "tokens": [1171, 1365, 11, 561, 1813, 1855, 11, 754, 460, 654, 815, 909, 1184, 661, 382, 257, 1277, 13], "temperature": 0.0, "avg_logprob": -0.1970727795460185, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.0006058955332264304}, {"id": 33, "seek": 11060, "start": 135.79999999999998, "end": 138.28, "text": " That will result in a new nose edge.", "tokens": [663, 486, 1874, 294, 257, 777, 6690, 4691, 13], "temperature": 0.0, "avg_logprob": -0.1970727795460185, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.0006058955332264304}, {"id": 34, "seek": 11060, "start": 138.28, "end": 140.0, "text": " That's simple enough.", "tokens": [663, 311, 2199, 1547, 13], "temperature": 0.0, "avg_logprob": -0.1970727795460185, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.0006058955332264304}, {"id": 35, "seek": 14000, "start": 140.0, "end": 142.12, "text": " Gia can decide to create a message.", "tokens": [460, 654, 393, 4536, 281, 1884, 257, 3636, 13], "temperature": 0.0, "avg_logprob": -0.11097462232722792, "compression_ratio": 1.8218181818181818, "no_speech_prob": 0.0004564518458209932}, {"id": 36, "seek": 14000, "start": 142.12, "end": 144.8, "text": " This message will be replied to message M3.", "tokens": [639, 3636, 486, 312, 20345, 281, 3636, 376, 18, 13], "temperature": 0.0, "avg_logprob": -0.11097462232722792, "compression_ratio": 1.8218181818181818, "no_speech_prob": 0.0004564518458209932}, {"id": 37, "seek": 14000, "start": 144.8, "end": 149.16, "text": " So we add a new node and connect it to the existing graph via two edges.", "tokens": [407, 321, 909, 257, 777, 9984, 293, 1745, 309, 281, 264, 6741, 4295, 5766, 732, 8819, 13], "temperature": 0.0, "avg_logprob": -0.11097462232722792, "compression_ratio": 1.8218181818181818, "no_speech_prob": 0.0004564518458209932}, {"id": 38, "seek": 14000, "start": 149.16, "end": 151.64, "text": " The heavy hitting updates are the deletes.", "tokens": [440, 4676, 8850, 9205, 366, 264, 1103, 37996, 13], "temperature": 0.0, "avg_logprob": -0.11097462232722792, "compression_ratio": 1.8218181818181818, "no_speech_prob": 0.0004564518458209932}, {"id": 39, "seek": 14000, "start": 151.64, "end": 156.76, "text": " A person may decide to delete their account, and that will result in a cascade of deletes.", "tokens": [316, 954, 815, 4536, 281, 12097, 641, 2696, 11, 293, 300, 486, 1874, 294, 257, 50080, 295, 1103, 37996, 13], "temperature": 0.0, "avg_logprob": -0.11097462232722792, "compression_ratio": 1.8218181818181818, "no_speech_prob": 0.0004564518458209932}, {"id": 40, "seek": 14000, "start": 156.76, "end": 162.88, "text": " For example, if we remove the node Eve, that will result in the removal of their direct", "tokens": [1171, 1365, 11, 498, 321, 4159, 264, 9984, 15544, 11, 300, 486, 1874, 294, 264, 17933, 295, 641, 2047], "temperature": 0.0, "avg_logprob": -0.11097462232722792, "compression_ratio": 1.8218181818181818, "no_speech_prob": 0.0004564518458209932}, {"id": 41, "seek": 14000, "start": 162.88, "end": 165.12, "text": " edges, all the messages they created.", "tokens": [8819, 11, 439, 264, 7897, 436, 2942, 13], "temperature": 0.0, "avg_logprob": -0.11097462232722792, "compression_ratio": 1.8218181818181818, "no_speech_prob": 0.0004564518458209932}, {"id": 42, "seek": 14000, "start": 165.12, "end": 169.56, "text": " And in some social network, this will even trigger the deletion of all the message trees", "tokens": [400, 294, 512, 2093, 3209, 11, 341, 486, 754, 7875, 264, 1103, 302, 313, 295, 439, 264, 3636, 5852], "temperature": 0.0, "avg_logprob": -0.11097462232722792, "compression_ratio": 1.8218181818181818, "no_speech_prob": 0.0004564518458209932}, {"id": 43, "seek": 16956, "start": 169.56, "end": 173.36, "text": " and, of course, all the edges that point to those messages.", "tokens": [293, 11, 295, 1164, 11, 439, 264, 8819, 300, 935, 281, 729, 7897, 13], "temperature": 0.0, "avg_logprob": -0.11702502625329154, "compression_ratio": 1.7992424242424243, "no_speech_prob": 0.00012335569772403687}, {"id": 44, "seek": 16956, "start": 173.36, "end": 176.88, "text": " So this is quite a hard operation for systems to execute.", "tokens": [407, 341, 307, 1596, 257, 1152, 6916, 337, 3652, 281, 14483, 13], "temperature": 0.0, "avg_logprob": -0.11702502625329154, "compression_ratio": 1.7992424242424243, "no_speech_prob": 0.00012335569772403687}, {"id": 45, "seek": 16956, "start": 176.88, "end": 182.92000000000002, "text": " It stresses their garbage collectors, and this allows certain append-only data structures.", "tokens": [467, 27732, 641, 14150, 35384, 11, 293, 341, 4045, 1629, 34116, 12, 25202, 1412, 9227, 13], "temperature": 0.0, "avg_logprob": -0.11702502625329154, "compression_ratio": 1.7992424242424243, "no_speech_prob": 0.00012335569772403687}, {"id": 46, "seek": 16956, "start": 182.92000000000002, "end": 186.88, "text": " So if you want to weave these three components together, the data set, the queries, and", "tokens": [407, 498, 291, 528, 281, 29145, 613, 1045, 6677, 1214, 11, 264, 1412, 992, 11, 264, 24109, 11, 293], "temperature": 0.0, "avg_logprob": -0.11702502625329154, "compression_ratio": 1.7992424242424243, "no_speech_prob": 0.00012335569772403687}, {"id": 47, "seek": 16956, "start": 186.88, "end": 191.6, "text": " the updates, we need a benchmark driver that schedules the operations to be executable.", "tokens": [264, 9205, 11, 321, 643, 257, 18927, 6787, 300, 28078, 264, 7705, 281, 312, 7568, 712, 13], "temperature": 0.0, "avg_logprob": -0.11702502625329154, "compression_ratio": 1.7992424242424243, "no_speech_prob": 0.00012335569772403687}, {"id": 48, "seek": 16956, "start": 191.6, "end": 196.08, "text": " It runs the updates and the queries concurrently, and, of course, it collects the results.", "tokens": [467, 6676, 264, 9205, 293, 264, 24109, 37702, 356, 11, 293, 11, 295, 1164, 11, 309, 39897, 264, 3542, 13], "temperature": 0.0, "avg_logprob": -0.11702502625329154, "compression_ratio": 1.7992424242424243, "no_speech_prob": 0.00012335569772403687}, {"id": 49, "seek": 19608, "start": 196.08, "end": 201.68, "text": " The system under test that we run the benchmark on is provided by our members who are the", "tokens": [440, 1185, 833, 1500, 300, 321, 1190, 264, 18927, 322, 307, 5649, 538, 527, 2679, 567, 366, 264], "temperature": 0.0, "avg_logprob": -0.12546842656237014, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0001864658552221954}, {"id": 50, "seek": 19608, "start": 201.68, "end": 207.92000000000002, "text": " database vendors, and we go to great lengths to allow as many candidate systems as possible,", "tokens": [8149, 22056, 11, 293, 321, 352, 281, 869, 26329, 281, 2089, 382, 867, 11532, 3652, 382, 1944, 11], "temperature": 0.0, "avg_logprob": -0.12546842656237014, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0001864658552221954}, {"id": 51, "seek": 19608, "start": 207.92000000000002, "end": 214.36, "text": " so graph databases, triple stores, and relational databases can all compete on this benchmark.", "tokens": [370, 4295, 22380, 11, 15508, 9512, 11, 293, 38444, 22380, 393, 439, 11831, 322, 341, 18927, 13], "temperature": 0.0, "avg_logprob": -0.12546842656237014, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0001864658552221954}, {"id": 52, "seek": 19608, "start": 214.36, "end": 219.72000000000003, "text": " Speaking of relational databases, some of you may think is SQL sufficient to express", "tokens": [13069, 295, 38444, 22380, 11, 512, 295, 291, 815, 519, 307, 19200, 11563, 281, 5109], "temperature": 0.0, "avg_logprob": -0.12546842656237014, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0001864658552221954}, {"id": 53, "seek": 19608, "start": 219.72000000000003, "end": 222.88000000000002, "text": " these queries, and the answer is that in most cases it is.", "tokens": [613, 24109, 11, 293, 264, 1867, 307, 300, 294, 881, 3331, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.12546842656237014, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0001864658552221954}, {"id": 54, "seek": 22288, "start": 222.88, "end": 228.79999999999998, "text": " So the query that we have just seen can be formulated in a reasonably simple SQL query.", "tokens": [407, 264, 14581, 300, 321, 362, 445, 1612, 393, 312, 48936, 294, 257, 23551, 2199, 19200, 14581, 13], "temperature": 0.0, "avg_logprob": -0.09775590896606445, "compression_ratio": 1.5692883895131087, "no_speech_prob": 0.00023024179972708225}, {"id": 55, "seek": 22288, "start": 228.79999999999998, "end": 233.96, "text": " It is a bit unwieldy, but it is certainly doable, and the performance will be okay.", "tokens": [467, 307, 257, 857, 14853, 1789, 88, 11, 457, 309, 307, 3297, 41183, 11, 293, 264, 3389, 486, 312, 1392, 13], "temperature": 0.0, "avg_logprob": -0.09775590896606445, "compression_ratio": 1.5692883895131087, "no_speech_prob": 0.00023024179972708225}, {"id": 56, "seek": 22288, "start": 233.96, "end": 239.0, "text": " However, this being a graph benchmark, it lends itself quite naturally to other query", "tokens": [2908, 11, 341, 885, 257, 4295, 18927, 11, 309, 287, 2581, 2564, 1596, 8195, 281, 661, 14581], "temperature": 0.0, "avg_logprob": -0.09775590896606445, "compression_ratio": 1.5692883895131087, "no_speech_prob": 0.00023024179972708225}, {"id": 57, "seek": 22288, "start": 239.0, "end": 240.0, "text": " languages.", "tokens": [8650, 13], "temperature": 0.0, "avg_logprob": -0.09775590896606445, "compression_ratio": 1.5692883895131087, "no_speech_prob": 0.00023024179972708225}, {"id": 58, "seek": 22288, "start": 240.0, "end": 244.12, "text": " There are two new query languages that are going to be coming out, and both of them adopted", "tokens": [821, 366, 732, 777, 14581, 8650, 300, 366, 516, 281, 312, 1348, 484, 11, 293, 1293, 295, 552, 12175], "temperature": 0.0, "avg_logprob": -0.09775590896606445, "compression_ratio": 1.5692883895131087, "no_speech_prob": 0.00023024179972708225}, {"id": 59, "seek": 22288, "start": 244.12, "end": 248.07999999999998, "text": " a visual graph syntax inspired by Neo4j's Cypher language.", "tokens": [257, 5056, 4295, 28431, 7547, 538, 24458, 19, 73, 311, 10295, 79, 511, 2856, 13], "temperature": 0.0, "avg_logprob": -0.09775590896606445, "compression_ratio": 1.5692883895131087, "no_speech_prob": 0.00023024179972708225}, {"id": 60, "seek": 24808, "start": 248.08, "end": 253.0, "text": " The first one is called SQL-PGQ, where PGQ stands for property graph queries.", "tokens": [440, 700, 472, 307, 1219, 19200, 12, 47, 38, 48, 11, 689, 40975, 48, 7382, 337, 4707, 4295, 24109, 13], "temperature": 0.0, "avg_logprob": -0.10885674391335588, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0001956781925400719}, {"id": 61, "seek": 24808, "start": 253.0, "end": 257.76, "text": " This will be released this summer, and as you can see, it's an extension to SQL, so", "tokens": [639, 486, 312, 4736, 341, 4266, 11, 293, 382, 291, 393, 536, 11, 309, 311, 364, 10320, 281, 19200, 11, 370], "temperature": 0.0, "avg_logprob": -0.10885674391335588, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0001956781925400719}, {"id": 62, "seek": 24808, "start": 257.76, "end": 262.24, "text": " you can use select and from, but it adds the graph table construct, and the query can", "tokens": [291, 393, 764, 3048, 293, 490, 11, 457, 309, 10860, 264, 4295, 3199, 7690, 11, 293, 264, 14581, 393], "temperature": 0.0, "avg_logprob": -0.10885674391335588, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0001956781925400719}, {"id": 63, "seek": 24808, "start": 262.24, "end": 265.68, "text": " be formulated in a very concise and readable manner.", "tokens": [312, 48936, 294, 257, 588, 44882, 293, 49857, 9060, 13], "temperature": 0.0, "avg_logprob": -0.10885674391335588, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0001956781925400719}, {"id": 64, "seek": 24808, "start": 265.68, "end": 270.2, "text": " There is GQL, the graph query language, which is a standalone language that is going to", "tokens": [821, 307, 460, 13695, 11, 264, 4295, 14581, 2856, 11, 597, 307, 257, 37454, 2856, 300, 307, 516, 281], "temperature": 0.0, "avg_logprob": -0.10885674391335588, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0001956781925400719}, {"id": 65, "seek": 24808, "start": 270.2, "end": 276.04, "text": " be released next year, and it shares the same pattern matching language as SQL-PGQ.", "tokens": [312, 4736, 958, 1064, 11, 293, 309, 12182, 264, 912, 5102, 14324, 2856, 382, 19200, 12, 47, 38, 48, 13], "temperature": 0.0, "avg_logprob": -0.10885674391335588, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0001956781925400719}, {"id": 66, "seek": 27604, "start": 276.04, "end": 281.0, "text": " So the social network benchmark has multiple workloads to cover the diverse challenges", "tokens": [407, 264, 2093, 3209, 18927, 575, 3866, 32452, 281, 2060, 264, 9521, 4759], "temperature": 0.0, "avg_logprob": -0.1060947036743164, "compression_ratio": 1.7560975609756098, "no_speech_prob": 7.761850429233164e-05}, {"id": 67, "seek": 27604, "start": 281.0, "end": 284.84000000000003, "text": " that are created by graph workloads.", "tokens": [300, 366, 2942, 538, 4295, 32452, 13], "temperature": 0.0, "avg_logprob": -0.1060947036743164, "compression_ratio": 1.7560975609756098, "no_speech_prob": 7.761850429233164e-05}, {"id": 68, "seek": 27604, "start": 284.84000000000003, "end": 289.12, "text": " The first one, the older one, is the social network benchmark interactive workload.", "tokens": [440, 700, 472, 11, 264, 4906, 472, 11, 307, 264, 2093, 3209, 18927, 15141, 20139, 13], "temperature": 0.0, "avg_logprob": -0.1060947036743164, "compression_ratio": 1.7560975609756098, "no_speech_prob": 7.761850429233164e-05}, {"id": 69, "seek": 27604, "start": 289.12, "end": 293.32000000000005, "text": " This is transactional in nature, and it has queries like the one I have shown before.", "tokens": [639, 307, 46688, 1966, 294, 3687, 11, 293, 309, 575, 24109, 411, 264, 472, 286, 362, 4898, 949, 13], "temperature": 0.0, "avg_logprob": -0.1060947036743164, "compression_ratio": 1.7560975609756098, "no_speech_prob": 7.761850429233164e-05}, {"id": 70, "seek": 27604, "start": 293.32000000000005, "end": 297.12, "text": " So these queries typically start in one or two person nodes.", "tokens": [407, 613, 24109, 5850, 722, 294, 472, 420, 732, 954, 13891, 13], "temperature": 0.0, "avg_logprob": -0.1060947036743164, "compression_ratio": 1.7560975609756098, "no_speech_prob": 7.761850429233164e-05}, {"id": 71, "seek": 27604, "start": 297.12, "end": 298.96000000000004, "text": " They are not very heavy hitting.", "tokens": [814, 366, 406, 588, 4676, 8850, 13], "temperature": 0.0, "avg_logprob": -0.1060947036743164, "compression_ratio": 1.7560975609756098, "no_speech_prob": 7.761850429233164e-05}, {"id": 72, "seek": 27604, "start": 298.96000000000004, "end": 301.32000000000005, "text": " They only touch on a limited amount of data.", "tokens": [814, 787, 2557, 322, 257, 5567, 2372, 295, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1060947036743164, "compression_ratio": 1.7560975609756098, "no_speech_prob": 7.761850429233164e-05}, {"id": 73, "seek": 30132, "start": 301.32, "end": 306.71999999999997, "text": " They have concurrent reads and updates, and systems are competing on achieving high throughputs.", "tokens": [814, 362, 37702, 15700, 293, 9205, 11, 293, 3652, 366, 15439, 322, 19626, 1090, 44629, 82, 13], "temperature": 0.0, "avg_logprob": -0.08715988891293304, "compression_ratio": 1.6974169741697418, "no_speech_prob": 9.24401028896682e-05}, {"id": 74, "seek": 30132, "start": 306.71999999999997, "end": 310.2, "text": " So this benchmark has been around for a few years, and we have seen actually very good", "tokens": [407, 341, 18927, 575, 668, 926, 337, 257, 1326, 924, 11, 293, 321, 362, 1612, 767, 588, 665], "temperature": 0.0, "avg_logprob": -0.08715988891293304, "compression_ratio": 1.6974169741697418, "no_speech_prob": 9.24401028896682e-05}, {"id": 75, "seek": 30132, "start": 310.2, "end": 311.2, "text": " results.", "tokens": [3542, 13], "temperature": 0.0, "avg_logprob": -0.08715988891293304, "compression_ratio": 1.6974169741697418, "no_speech_prob": 9.24401028896682e-05}, {"id": 76, "seek": 30132, "start": 311.2, "end": 316.2, "text": " In the last three years, we witnessed an exponential increase in throughput, starting from a little", "tokens": [682, 264, 1036, 1045, 924, 11, 321, 21519, 364, 21510, 3488, 294, 44629, 11, 2891, 490, 257, 707], "temperature": 0.0, "avg_logprob": -0.08715988891293304, "compression_ratio": 1.6974169741697418, "no_speech_prob": 9.24401028896682e-05}, {"id": 77, "seek": 30132, "start": 316.2, "end": 322.88, "text": " above 5,000 operations per second to almost 17,000 operations per second this year.", "tokens": [3673, 1025, 11, 1360, 7705, 680, 1150, 281, 1920, 3282, 11, 1360, 7705, 680, 1150, 341, 1064, 13], "temperature": 0.0, "avg_logprob": -0.08715988891293304, "compression_ratio": 1.6974169741697418, "no_speech_prob": 9.24401028896682e-05}, {"id": 78, "seek": 30132, "start": 322.88, "end": 327.32, "text": " Our newer benchmark is the social network benchmark business intelligence workload.", "tokens": [2621, 17628, 18927, 307, 264, 2093, 3209, 18927, 1606, 7599, 20139, 13], "temperature": 0.0, "avg_logprob": -0.08715988891293304, "compression_ratio": 1.6974169741697418, "no_speech_prob": 9.24401028896682e-05}, {"id": 79, "seek": 32732, "start": 327.32, "end": 332.24, "text": " This is analytical in nature, and it has queries that touch on large portions of the data.", "tokens": [639, 307, 29579, 294, 3687, 11, 293, 309, 575, 24109, 300, 2557, 322, 2416, 25070, 295, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.08290274289189553, "compression_ratio": 1.5928571428571427, "no_speech_prob": 6.887166091473773e-05}, {"id": 80, "seek": 32732, "start": 332.24, "end": 337.8, "text": " For example, the query on this slide enumerates all triangles of friendships in a given country", "tokens": [1171, 1365, 11, 264, 14581, 322, 341, 4137, 465, 15583, 1024, 439, 29896, 295, 30003, 294, 257, 2212, 1941], "temperature": 0.0, "avg_logprob": -0.08290274289189553, "compression_ratio": 1.5928571428571427, "no_speech_prob": 6.887166091473773e-05}, {"id": 81, "seek": 32732, "start": 337.8, "end": 344.15999999999997, "text": " which can potentially reach billions of edges, and is a very difficult computational problem.", "tokens": [597, 393, 7263, 2524, 17375, 295, 8819, 11, 293, 307, 257, 588, 2252, 28270, 1154, 13], "temperature": 0.0, "avg_logprob": -0.08290274289189553, "compression_ratio": 1.5928571428571427, "no_speech_prob": 6.887166091473773e-05}, {"id": 82, "seek": 32732, "start": 344.15999999999997, "end": 348.71999999999997, "text": " Systems here are allowed to do either a bulk or a concurrent update approach, but they", "tokens": [27059, 510, 366, 4350, 281, 360, 2139, 257, 16139, 420, 257, 37702, 5623, 3109, 11, 457, 436], "temperature": 0.0, "avg_logprob": -0.08290274289189553, "compression_ratio": 1.5928571428571427, "no_speech_prob": 6.887166091473773e-05}, {"id": 83, "seek": 32732, "start": 348.71999999999997, "end": 354.08, "text": " should strive to get both a high throughput and low individual query runtimes.", "tokens": [820, 23829, 281, 483, 1293, 257, 1090, 44629, 293, 2295, 2609, 14581, 49435, 1532, 13], "temperature": 0.0, "avg_logprob": -0.08290274289189553, "compression_ratio": 1.5928571428571427, "no_speech_prob": 6.887166091473773e-05}, {"id": 84, "seek": 35408, "start": 354.08, "end": 358.03999999999996, "text": " This benchmark being relatively new, we only have a single result, so it's a bit difficult", "tokens": [639, 18927, 885, 7226, 777, 11, 321, 787, 362, 257, 2167, 1874, 11, 370, 309, 311, 257, 857, 2252], "temperature": 0.0, "avg_logprob": -0.1592436933939436, "compression_ratio": 1.551094890510949, "no_speech_prob": 0.00029363902285695076}, {"id": 85, "seek": 35408, "start": 358.03999999999996, "end": 359.8, "text": " to put it into context.", "tokens": [281, 829, 309, 666, 4319, 13], "temperature": 0.0, "avg_logprob": -0.1592436933939436, "compression_ratio": 1.551094890510949, "no_speech_prob": 0.00029363902285695076}, {"id": 86, "seek": 35408, "start": 359.8, "end": 362.08, "text": " But it allows me to highlight one thing.", "tokens": [583, 309, 4045, 385, 281, 5078, 472, 551, 13], "temperature": 0.0, "avg_logprob": -0.1592436933939436, "compression_ratio": 1.551094890510949, "no_speech_prob": 0.00029363902285695076}, {"id": 87, "seek": 35408, "start": 362.08, "end": 364.24, "text": " Many of our benchmarks use different CPUs.", "tokens": [5126, 295, 527, 43751, 764, 819, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.1592436933939436, "compression_ratio": 1.551094890510949, "no_speech_prob": 0.00029363902285695076}, {"id": 88, "seek": 35408, "start": 364.24, "end": 368.56, "text": " We actually have quite a healthy diversity in the CPUs.", "tokens": [492, 767, 362, 1596, 257, 4627, 8811, 294, 264, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.1592436933939436, "compression_ratio": 1.551094890510949, "no_speech_prob": 0.00029363902285695076}, {"id": 89, "seek": 35408, "start": 368.56, "end": 373.4, "text": " We have results with the AMD Epic Genoa, like this one achieved by TigerGraph.", "tokens": [492, 362, 3542, 365, 264, 34808, 26785, 3632, 23254, 11, 411, 341, 472, 11042, 538, 22025, 38, 2662, 13], "temperature": 0.0, "avg_logprob": -0.1592436933939436, "compression_ratio": 1.551094890510949, "no_speech_prob": 0.00029363902285695076}, {"id": 90, "seek": 35408, "start": 373.4, "end": 379.64, "text": " We have results using Intel Xeon Ice Lakes and the ETN 710s, which use an ARM architecture.", "tokens": [492, 362, 3542, 1228, 19762, 1783, 27015, 15332, 36932, 293, 264, 36953, 45, 1614, 3279, 82, 11, 597, 764, 364, 45209, 9482, 13], "temperature": 0.0, "avg_logprob": -0.1592436933939436, "compression_ratio": 1.551094890510949, "no_speech_prob": 0.00029363902285695076}, {"id": 91, "seek": 37964, "start": 379.64, "end": 384.52, "text": " We have more and larger scale results expected this year, and we are also quite interested", "tokens": [492, 362, 544, 293, 4833, 4373, 3542, 5176, 341, 1064, 11, 293, 321, 366, 611, 1596, 3102], "temperature": 0.0, "avg_logprob": -0.10941038879693724, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.00011340373748680577}, {"id": 92, "seek": 37964, "start": 384.52, "end": 389.28, "text": " in some graph and machine learning accelerators that are going to be released soon.", "tokens": [294, 512, 4295, 293, 3479, 2539, 10172, 3391, 300, 366, 516, 281, 312, 4736, 2321, 13], "temperature": 0.0, "avg_logprob": -0.10941038879693724, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.00011340373748680577}, {"id": 93, "seek": 37964, "start": 389.28, "end": 391.56, "text": " So our benchmark process is quite involved.", "tokens": [407, 527, 18927, 1399, 307, 1596, 3288, 13], "temperature": 0.0, "avg_logprob": -0.10941038879693724, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.00011340373748680577}, {"id": 94, "seek": 37964, "start": 391.56, "end": 394.36, "text": " For each workload, we release a specification.", "tokens": [1171, 1184, 20139, 11, 321, 4374, 257, 31256, 13], "temperature": 0.0, "avg_logprob": -0.10941038879693724, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.00011340373748680577}, {"id": 95, "seek": 37964, "start": 394.36, "end": 396.84, "text": " We have an academic paper that motivates the benchmark.", "tokens": [492, 362, 364, 7778, 3035, 300, 42569, 264, 18927, 13], "temperature": 0.0, "avg_logprob": -0.10941038879693724, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.00011340373748680577}, {"id": 96, "seek": 37964, "start": 396.84, "end": 401.4, "text": " We have data generators, pre-generated data sets, as well as a benchmark driver and at", "tokens": [492, 362, 1412, 38662, 11, 659, 12, 21848, 770, 1412, 6352, 11, 382, 731, 382, 257, 18927, 6787, 293, 412], "temperature": 0.0, "avg_logprob": -0.10941038879693724, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.00011340373748680577}, {"id": 97, "seek": 37964, "start": 401.4, "end": 404.52, "text": " least two reference implementations.", "tokens": [1935, 732, 6408, 4445, 763, 13], "temperature": 0.0, "avg_logprob": -0.10941038879693724, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.00011340373748680577}, {"id": 98, "seek": 40452, "start": 404.52, "end": 410.52, "text": " We do this because we have an auditing process that allows the vendors to implement this benchmark", "tokens": [492, 360, 341, 570, 321, 362, 364, 2379, 1748, 1399, 300, 4045, 264, 22056, 281, 4445, 341, 18927], "temperature": 0.0, "avg_logprob": -0.12692930963304308, "compression_ratio": 1.9087136929460582, "no_speech_prob": 0.0001843812206061557}, {"id": 99, "seek": 40452, "start": 410.52, "end": 416.2, "text": " to actually go through a rigorous test, and if they do so, they can claim that they have", "tokens": [281, 767, 352, 807, 257, 29882, 1500, 11, 293, 498, 436, 360, 370, 11, 436, 393, 3932, 300, 436, 362], "temperature": 0.0, "avg_logprob": -0.12692930963304308, "compression_ratio": 1.9087136929460582, "no_speech_prob": 0.0001843812206061557}, {"id": 100, "seek": 40452, "start": 416.2, "end": 418.32, "text": " an official benchmark result.", "tokens": [364, 4783, 18927, 1874, 13], "temperature": 0.0, "avg_logprob": -0.12692930963304308, "compression_ratio": 1.9087136929460582, "no_speech_prob": 0.0001843812206061557}, {"id": 101, "seek": 40452, "start": 418.32, "end": 424.52, "text": " So we trademark the term ADBC such that the vendors have to go through these hoops of", "tokens": [407, 321, 31361, 264, 1433, 9135, 7869, 1270, 300, 264, 22056, 362, 281, 352, 807, 613, 1106, 3370, 295], "temperature": 0.0, "avg_logprob": -0.12692930963304308, "compression_ratio": 1.9087136929460582, "no_speech_prob": 0.0001843812206061557}, {"id": 102, "seek": 40452, "start": 424.52, "end": 429.44, "text": " auditing, and we still allow researchers and developers to do unofficial benchmarks,", "tokens": [2379, 1748, 11, 293, 321, 920, 2089, 10309, 293, 8849, 281, 360, 8526, 37661, 43751, 11], "temperature": 0.0, "avg_logprob": -0.12692930963304308, "compression_ratio": 1.9087136929460582, "no_speech_prob": 0.0001843812206061557}, {"id": 103, "seek": 40452, "start": 429.44, "end": 434.35999999999996, "text": " but they have to say that this is not unofficial ADBC benchmark result.", "tokens": [457, 436, 362, 281, 584, 300, 341, 307, 406, 8526, 37661, 9135, 7869, 18927, 1874, 13], "temperature": 0.0, "avg_logprob": -0.12692930963304308, "compression_ratio": 1.9087136929460582, "no_speech_prob": 0.0001843812206061557}, {"id": 104, "seek": 43436, "start": 434.36, "end": 438.2, "text": " Another benchmark I would like to touch upon briefly is the Graph Analytics benchmark.", "tokens": [3996, 18927, 286, 576, 411, 281, 2557, 3564, 10515, 307, 264, 21884, 25944, 18927, 13], "temperature": 0.0, "avg_logprob": -0.1605046977167544, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.00012404333392623812}, {"id": 105, "seek": 43436, "start": 438.2, "end": 442.68, "text": " This casts a wider net, so it targets graph databases, graph processing framework, embedded", "tokens": [639, 41921, 257, 11842, 2533, 11, 370, 309, 12911, 4295, 22380, 11, 4295, 9007, 8388, 11, 16741], "temperature": 0.0, "avg_logprob": -0.1605046977167544, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.00012404333392623812}, {"id": 106, "seek": 43436, "start": 442.68, "end": 446.6, "text": " graph libraries like NetworkX and so on.", "tokens": [4295, 15148, 411, 12640, 55, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.1605046977167544, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.00012404333392623812}, {"id": 107, "seek": 43436, "start": 446.6, "end": 451.92, "text": " This uses untyped, unattributed graphs, so it's only the person knows person graphs", "tokens": [639, 4960, 517, 874, 3452, 11, 47316, 2024, 4866, 24877, 11, 370, 309, 311, 787, 264, 954, 3255, 954, 24877], "temperature": 0.0, "avg_logprob": -0.1605046977167544, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.00012404333392623812}, {"id": 108, "seek": 43436, "start": 451.92, "end": 456.08000000000004, "text": " of the social network benchmark or other well-known graphs like Graph 500.", "tokens": [295, 264, 2093, 3209, 18927, 420, 661, 731, 12, 6861, 24877, 411, 21884, 5923, 13], "temperature": 0.0, "avg_logprob": -0.1605046977167544, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.00012404333392623812}, {"id": 109, "seek": 43436, "start": 456.08000000000004, "end": 457.40000000000003, "text": " We have six algorithms.", "tokens": [492, 362, 2309, 14642, 13], "temperature": 0.0, "avg_logprob": -0.1605046977167544, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.00012404333392623812}, {"id": 110, "seek": 43436, "start": 457.40000000000003, "end": 461.52000000000004, "text": " Many of these are textbook algorithms like BFS, which just traverses the graph from a", "tokens": [5126, 295, 613, 366, 25591, 14642, 411, 363, 29318, 11, 597, 445, 23149, 279, 264, 4295, 490, 257], "temperature": 0.0, "avg_logprob": -0.1605046977167544, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.00012404333392623812}, {"id": 111, "seek": 46152, "start": 461.52, "end": 467.15999999999997, "text": " given source node, or we have PageRank, which selects the most important nodes in the network.", "tokens": [2212, 4009, 9984, 11, 420, 321, 362, 21217, 49, 657, 11, 597, 3048, 82, 264, 881, 1021, 13891, 294, 264, 3209, 13], "temperature": 0.0, "avg_logprob": -0.13053296922563432, "compression_ratio": 1.568561872909699, "no_speech_prob": 0.00014073711645323783}, {"id": 112, "seek": 46152, "start": 467.15999999999997, "end": 471.2, "text": " We also have clustering coefficient, community detection, connected components, and shortest", "tokens": [492, 611, 362, 596, 48673, 17619, 11, 1768, 17784, 11, 4582, 6677, 11, 293, 31875], "temperature": 0.0, "avg_logprob": -0.13053296922563432, "compression_ratio": 1.568561872909699, "no_speech_prob": 0.00014073711645323783}, {"id": 113, "seek": 46152, "start": 471.2, "end": 473.35999999999996, "text": " paths.", "tokens": [14518, 13], "temperature": 0.0, "avg_logprob": -0.13053296922563432, "compression_ratio": 1.568561872909699, "no_speech_prob": 0.00014073711645323783}, {"id": 114, "seek": 46152, "start": 473.35999999999996, "end": 474.91999999999996, "text": " This benchmark is a bit simpler to implement.", "tokens": [639, 18927, 307, 257, 857, 18587, 281, 4445, 13], "temperature": 0.0, "avg_logprob": -0.13053296922563432, "compression_ratio": 1.568561872909699, "no_speech_prob": 0.00014073711645323783}, {"id": 115, "seek": 46152, "start": 474.91999999999996, "end": 477.59999999999997, "text": " We have a leaderboard that we update periodically.", "tokens": [492, 362, 257, 5263, 3787, 300, 321, 5623, 38916, 13], "temperature": 0.0, "avg_logprob": -0.13053296922563432, "compression_ratio": 1.568561872909699, "no_speech_prob": 0.00014073711645323783}, {"id": 116, "seek": 46152, "start": 477.59999999999997, "end": 482.68, "text": " The next one is going to come out in Spring 2023, so talk to us if you're interested.", "tokens": [440, 958, 472, 307, 516, 281, 808, 484, 294, 14013, 44377, 11, 370, 751, 281, 505, 498, 291, 434, 3102, 13], "temperature": 0.0, "avg_logprob": -0.13053296922563432, "compression_ratio": 1.568561872909699, "no_speech_prob": 0.00014073711645323783}, {"id": 117, "seek": 46152, "start": 482.68, "end": 487.28, "text": " So wrapping up, you should consider becoming an ADBC member because members can participate", "tokens": [407, 21993, 493, 11, 291, 820, 1949, 5617, 364, 9135, 7869, 4006, 570, 2679, 393, 8197], "temperature": 0.0, "avg_logprob": -0.13053296922563432, "compression_ratio": 1.568561872909699, "no_speech_prob": 0.00014073711645323783}, {"id": 118, "seek": 48728, "start": 487.28, "end": 491.88, "text": " in the benchmark design and have a say in where we go, they can commission audits of", "tokens": [294, 264, 18927, 1715, 293, 362, 257, 584, 294, 689, 321, 352, 11, 436, 393, 9221, 2379, 1208, 295], "temperature": 0.0, "avg_logprob": -0.1873800729967884, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0002818800858221948}, {"id": 119, "seek": 48728, "start": 491.88, "end": 497.0, "text": " their benchmarks, and they can also gain early access to the ISO standard drafts, SQL, PGQ,", "tokens": [641, 43751, 11, 293, 436, 393, 611, 6052, 2440, 2105, 281, 264, 25042, 3832, 11206, 82, 11, 19200, 11, 40975, 48, 11], "temperature": 0.0, "avg_logprob": -0.1873800729967884, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0002818800858221948}, {"id": 120, "seek": 48728, "start": 497.0, "end": 498.71999999999997, "text": " and GQ that I have shown.", "tokens": [293, 460, 48, 300, 286, 362, 4898, 13], "temperature": 0.0, "avg_logprob": -0.1873800729967884, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0002818800858221948}, {"id": 121, "seek": 48728, "start": 498.71999999999997, "end": 503.2, "text": " It's free for individuals and has a yearly fee for companies.", "tokens": [467, 311, 1737, 337, 5346, 293, 575, 257, 39102, 12054, 337, 3431, 13], "temperature": 0.0, "avg_logprob": -0.1873800729967884, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0002818800858221948}, {"id": 122, "seek": 48728, "start": 503.2, "end": 505.4, "text": " So to sum up, these are our three main benchmarks.", "tokens": [407, 281, 2408, 493, 11, 613, 366, 527, 1045, 2135, 43751, 13], "temperature": 0.0, "avg_logprob": -0.1873800729967884, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0002818800858221948}, {"id": 123, "seek": 48728, "start": 505.4, "end": 508.15999999999997, "text": " We have other benchmarks and many future ideas.", "tokens": [492, 362, 661, 43751, 293, 867, 2027, 3487, 13], "temperature": 0.0, "avg_logprob": -0.1873800729967884, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0002818800858221948}, {"id": 124, "seek": 50816, "start": 508.16, "end": 519.64, "text": " If you're interested, please reach out.", "tokens": [759, 291, 434, 3102, 11, 1767, 2524, 484, 13], "temperature": 0.0, "avg_logprob": -0.2518740693728129, "compression_ratio": 1.2627118644067796, "no_speech_prob": 0.007814490236341953}, {"id": 125, "seek": 50816, "start": 519.64, "end": 522.6, "text": " Again we have time for one question.", "tokens": [3764, 321, 362, 565, 337, 472, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2518740693728129, "compression_ratio": 1.2627118644067796, "no_speech_prob": 0.007814490236341953}, {"id": 126, "seek": 50816, "start": 522.6, "end": 531.8000000000001, "text": " Any questions for Gabor?", "tokens": [2639, 1651, 337, 460, 3816, 30], "temperature": 0.0, "avg_logprob": -0.2518740693728129, "compression_ratio": 1.2627118644067796, "no_speech_prob": 0.007814490236341953}, {"id": 127, "seek": 50816, "start": 531.8000000000001, "end": 533.1600000000001, "text": " This is a newbie question.", "tokens": [639, 307, 257, 777, 7392, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2518740693728129, "compression_ratio": 1.2627118644067796, "no_speech_prob": 0.007814490236341953}, {"id": 128, "seek": 50816, "start": 533.1600000000001, "end": 537.2, "text": " I'm not into graphs.", "tokens": [286, 478, 406, 666, 24877, 13], "temperature": 0.0, "avg_logprob": -0.2518740693728129, "compression_ratio": 1.2627118644067796, "no_speech_prob": 0.007814490236341953}, {"id": 129, "seek": 53720, "start": 537.2, "end": 548.2, "text": " Apart from advertisement, optimization, mass surveillance, and perhaps content distribution,", "tokens": [24111, 490, 31370, 11, 19618, 11, 2758, 18475, 11, 293, 4317, 2701, 7316, 11], "temperature": 0.0, "avg_logprob": -0.1757834666484111, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.005442561116069555}, {"id": 130, "seek": 53720, "start": 548.2, "end": 554.88, "text": " which I don't know if they're the major applications, but it's just what my naive minds come with.", "tokens": [597, 286, 500, 380, 458, 498, 436, 434, 264, 2563, 5821, 11, 457, 309, 311, 445, 437, 452, 29052, 9634, 808, 365, 13], "temperature": 0.0, "avg_logprob": -0.1757834666484111, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.005442561116069555}, {"id": 131, "seek": 53720, "start": 554.88, "end": 560.12, "text": " What other applications are those benchmarks meant to optimize?", "tokens": [708, 661, 5821, 366, 729, 43751, 4140, 281, 19719, 30], "temperature": 0.0, "avg_logprob": -0.1757834666484111, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.005442561116069555}, {"id": 132, "seek": 53720, "start": 560.12, "end": 566.4000000000001, "text": " So the big one this year is supply chain optimization, like strengthening supply chains, ensuring", "tokens": [407, 264, 955, 472, 341, 1064, 307, 5847, 5021, 19618, 11, 411, 28224, 5847, 12626, 11, 16882], "temperature": 0.0, "avg_logprob": -0.1757834666484111, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.005442561116069555}, {"id": 133, "seek": 56640, "start": 566.4, "end": 571.4, "text": " that they are ethical, ensuring that they are not passing conflict zones.", "tokens": [300, 436, 366, 18890, 11, 16882, 300, 436, 366, 406, 8437, 6596, 16025, 13], "temperature": 0.0, "avg_logprob": -0.11486637458372652, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0006503017502836883}, {"id": 134, "seek": 56640, "start": 571.4, "end": 574.12, "text": " It's something that is very important these days.", "tokens": [467, 311, 746, 300, 307, 588, 1021, 613, 1708, 13], "temperature": 0.0, "avg_logprob": -0.11486637458372652, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0006503017502836883}, {"id": 135, "seek": 56640, "start": 574.12, "end": 582.52, "text": " You can also track CO2 emissions and other aspects of labor and manufacturing.", "tokens": [509, 393, 611, 2837, 3002, 17, 14607, 293, 661, 7270, 295, 5938, 293, 11096, 13], "temperature": 0.0, "avg_logprob": -0.11486637458372652, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0006503017502836883}, {"id": 136, "seek": 56640, "start": 582.52, "end": 586.16, "text": " So that's certainly a big one, and that's something that we have seen.", "tokens": [407, 300, 311, 3297, 257, 955, 472, 11, 293, 300, 311, 746, 300, 321, 362, 1612, 13], "temperature": 0.0, "avg_logprob": -0.11486637458372652, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0006503017502836883}, {"id": 137, "seek": 56640, "start": 586.16, "end": 591.72, "text": " And there are, of course, all the graphic problems like power grid, a lot of e-commerce", "tokens": [400, 456, 366, 11, 295, 1164, 11, 439, 264, 14089, 2740, 411, 1347, 10748, 11, 257, 688, 295, 308, 12, 26926], "temperature": 0.0, "avg_logprob": -0.11486637458372652, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0006503017502836883}, {"id": 138, "seek": 59172, "start": 591.72, "end": 595.96, "text": " programs, and the financial fraud detection, which is going to be part of our financial", "tokens": [4268, 11, 293, 264, 4669, 14560, 17784, 11, 597, 307, 516, 281, 312, 644, 295, 527, 4669], "temperature": 0.0, "avg_logprob": -0.23848665677584135, "compression_ratio": 1.2272727272727273, "no_speech_prob": 0.0015183005016297102}, {"id": 139, "seek": 59596, "start": 595.96, "end": 622.24, "text": " benchmark this year.", "tokens": [50364, 18927, 341, 1064, 13, 51678], "temperature": 0.0, "avg_logprob": -0.6999031475612095, "compression_ratio": 0.7142857142857143, "no_speech_prob": 0.002638953970745206}], "language": "en"}