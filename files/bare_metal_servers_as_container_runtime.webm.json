{"text": " So, hello everyone, my name is Florian, I work at Scaleway and I'm an engineering manager software developer there and today we'll talk about how we use servers to handle our production workload just like if there were containers. So a quick slide of context, Scaleway is a European cloud provider, we do a lot of tests, data centers, shared host, collocation, shared hosting, whatever instances, databases, we have physical locations in France, Amsterdam and in Poland and I work in the storage team as I said, we are a team of ten people, we handle pretty much everything storage-ish related at Scaleway, so being the block and object storage products and also some order systems like the RfNSAN and the data backup in the online ecosystem and we have around a thousand servers in production and more than a hundred bitabytes of storage. So when I joined the team five years ago, the intro was what it was, it was drawn organically over the years and the versions were over the places, everything was a bit custom for the team needs at the time, so some servers were locally installed, some were PXC but everything was not homogeneous and we had an old pearl-based automation system that suffered a lot because not so much people had fluency in pearl, so it was pretty much a huge happen-only script that did stuff. So we wanted to start something fresh, something new, something we could work on for a few years, so we started considering stuff, everybody at the time started to use containers but we were not a fan because at that time they were not as material, the tooling and ecosystem was not that great and also we wanted to try something different. We still use containers for developer purposes, CI and whatever but we decided to do pixie live booting. It comes with some great advantages, first of all you just plug the server to the network, you put your discovery image and you are pretty much set up, nothing else to do. Reboot is just like taking down a container to update it and it's when you have thousands of servers in production, reboot is not that big of a deal, it's just life. The only downside is that you need to have a solid network and working the HCP. As a cloud provider you don't have network, don't do anything, so not really a downside. So let's talk about automation. After using the Perl stuff we started on salt, it worked okay but it was really hard to test modifications before putting them in production and at the time it was nobody's job, pretty much, like no one had clear in-house responsibility for it, so it was not that well maintained. So one day we decided to move to Ansible, mostly because everyone else at the time was moving to Ansible in the company, so we wanted to share our efforts and small libraries so that everybody can like do stuff cleaner and not have something where everyone does things on the side. It's easier to write, easier to test, the learning curve is not as steep as with salt and you don't have a central controller that has to be maintained by a sentencing team, you just can keep that in-house. But ultimately we wrote something along the lines of a controller, but some really dumb stuff, around 250 lines of go for the server and just a shy of 100 for the client, it's written in Python, it's pretty dumb just an API that when a server boots it calls it the API ID. Okay, here you are, here's your configuration. Just to have something a bit cleaner that works well with pixie images, we have split up the automation in two parts, we have one part that's our deployment playbooks, the only job in the life is to install and update all the software stacks and that's pretty much it, and afterwards we have the runtime playbooks, which job is to set up networking, because basically when you boot it in the lifeboots you just have the basic one interface DHCP address and you need some network configuration to make your service work, it assembles the raids, mount fire system, tune the OS like sysatel, separate governor or whatever, and after that just configure and start your services. One quick note, the installed playbooks are run on prediction server and during image creations and some are there just to remove default packages that we do not want to have in the built image. Now just a little bit about how we handle pixie image creations, basically a pixie image is a squash of s that you download over the internet just after having booted your kernel, it's literally a rootfes of your server that's inside the RAM, the first ways that were used before arrived was just a snapshot of the rootfes of a VM, afterwards there were Docker to pixie.pl, basically a huge power strip that was extracting the file system of a container, it came with some limitations, because basically the way that base image of containers are made make that not a fully functional OS, afterwards we use Ashko Parker and now we use a small trick with sshd and uncivilized ssh port that basically traps the uncivilization inside the ashrut on the build server. The advantage of this is that the same playbooks for the deployments of software are used for both the creation of the image and updating servers and predictions, and the build system is based on the ubuntu server image, nothing fancy, and we are using the default LiveBooty Neutron fs package that comes up with dbian and ubuntu with a few tweaks to allow for retries and to avoid boot storms, like you have 30 or 40 servers that reboot at the same time that do not fetch the squash fs on the same machines to avoid any networking issues. Here's the fun part, there is a small playbook that's called pixiemagic.tml that handles a lot of stuff, that's cool because the ubuntu default packages are not all meant to be run inside a LiveBoot environment, first we avoid triggering the packages triggers during kernel install because it saves a lot of time during the creation of an image, but afterwards you have to rebuild all the dkms and custom kernel models to specifically target the kernel version that is inside the shoot because it's not the same as the host necessarily, all the hypermorph profiles are to be patched because they limit what software can access which files, but as you are running from ram, you have some kind of overlay fs above it, so apparently that's ntp for example, it's not targeting the ntp drift file in slashvar but in somewhere like varlib, live, medium, something, overlay fs, so you have to patch all those, here's the flag, just like two weeks to find in another main learning list of the kernel, like 2.4 or something, you have that support for the overlay fs, so you don't break the default in your td before configuration, and as the system is amnesiac after each reboot, you have to take into account that we do not use any network configuration utility, so no network d, no if and down, nothing, so you have to take that into account because some simulink are broken by default. So we've been doing that for five years and well, pretty much nothing to say, just works, we have the convenience of containers, so we have all the systems into production that are pretty much homogeneous, with pretty much some version everywhere, and we have the comfort of using just plain bare metal servers without having any issues, like a long time ago when you updated Docker, it had the bad habits of restarting every container on the host without asking you anything, we can scale from 100 servers to a thousand, with only pretty much three to four people handling deployment in installation of servers, and new servers are deployed quite fast, like it takes like one hour to deploy 10 new servers maximum, because you just have to collect the max, update the DHCP, and put the machines, and it just works, and if you want to update anything, you just have to reboot, it's pretty simple. I think that's supposed to be fast. Does anyone have questions? Yes? That doesn't mean that the operating system has basically never written the disk on the client. Excuse me. Does that essentially mean that you have diskless servers there? Yeah. Okay, cool. So the only data that's written on physical disk are the question. So I was saying that we did that install pretty much the servers, that there was no OS installed on servers, and yes, we do have a few ones, like the one that handles the images, the installation, the DHCP, and so on, but every other servers inside our infrastructure is diskless for the OS parts, because we do have data from clients, and we tend to store that in memory, but that pretty much every disk is used for clients. Yes? Did you consider using live build or building your images instead of packer? So the question was, did we consider using live build from packer? We did use that, but at the time we were running on public virtual machines, and the building of images was pretty slow, so we moved to this solution using shrewd and a big-ass build server, and just really, really fast, so that's why we use that now. Yes? By swapping out self-master, that means that now Ansible needs to be run like ad hoc. What kind of automation do you have on top of that? Because having to run Ansible every time from your laptop? Yeah, so as I said, the playbooks are run at boot time on the servers. Basically, on every servers you have a small client written in pittons that's like 80 lines, but pretty much half of it is commentaries, and you just call an API saying, hey, my IP is that, can you deploy me? And we have multiple services everywhere that just have a copy of all the deployment files and the configuration files, and it's a reverse Ansible deployment from a server inside there, so you don't have any human interaction to redeploy a server. Any other questions? So thanks for your time. you", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.16, "text": " So, hello everyone, my name is Florian, I work at Scaleway and I'm an engineering manager", "tokens": [50364, 407, 11, 7751, 1518, 11, 452, 1315, 307, 8328, 952, 11, 286, 589, 412, 42999, 676, 293, 286, 478, 364, 7043, 6598, 51022], "temperature": 0.0, "avg_logprob": -0.3398293928666548, "compression_ratio": 1.393939393939394, "no_speech_prob": 0.0628402903676033}, {"id": 1, "seek": 0, "start": 13.16, "end": 20.44, "text": " software developer there and today we'll talk about how we use servers to handle our production", "tokens": [51022, 4722, 10754, 456, 293, 965, 321, 603, 751, 466, 577, 321, 764, 15909, 281, 4813, 527, 4265, 51386], "temperature": 0.0, "avg_logprob": -0.3398293928666548, "compression_ratio": 1.393939393939394, "no_speech_prob": 0.0628402903676033}, {"id": 2, "seek": 0, "start": 20.44, "end": 26.240000000000002, "text": " workload just like if there were containers.", "tokens": [51386, 20139, 445, 411, 498, 456, 645, 17089, 13, 51676], "temperature": 0.0, "avg_logprob": -0.3398293928666548, "compression_ratio": 1.393939393939394, "no_speech_prob": 0.0628402903676033}, {"id": 3, "seek": 2624, "start": 26.24, "end": 32.199999999999996, "text": " So a quick slide of context, Scaleway is a European cloud provider, we do a lot of tests,", "tokens": [50364, 407, 257, 1702, 4137, 295, 4319, 11, 42999, 676, 307, 257, 6473, 4588, 12398, 11, 321, 360, 257, 688, 295, 6921, 11, 50662], "temperature": 0.0, "avg_logprob": -0.30312099676022586, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.05366235971450806}, {"id": 4, "seek": 2624, "start": 32.199999999999996, "end": 40.839999999999996, "text": " data centers, shared host, collocation, shared hosting, whatever instances, databases, we", "tokens": [50662, 1412, 10898, 11, 5507, 3975, 11, 1263, 27943, 11, 5507, 16058, 11, 2035, 14519, 11, 22380, 11, 321, 51094], "temperature": 0.0, "avg_logprob": -0.30312099676022586, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.05366235971450806}, {"id": 5, "seek": 2624, "start": 40.839999999999996, "end": 46.32, "text": " have physical locations in France, Amsterdam and in Poland and I work in the storage team", "tokens": [51094, 362, 4001, 9253, 294, 6190, 11, 28291, 293, 294, 15950, 293, 286, 589, 294, 264, 6725, 1469, 51368], "temperature": 0.0, "avg_logprob": -0.30312099676022586, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.05366235971450806}, {"id": 6, "seek": 2624, "start": 46.32, "end": 50.84, "text": " as I said, we are a team of ten people, we handle pretty much everything storage-ish", "tokens": [51368, 382, 286, 848, 11, 321, 366, 257, 1469, 295, 2064, 561, 11, 321, 4813, 1238, 709, 1203, 6725, 12, 742, 51594], "temperature": 0.0, "avg_logprob": -0.30312099676022586, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.05366235971450806}, {"id": 7, "seek": 5084, "start": 51.160000000000004, "end": 58.6, "text": " related at Scaleway, so being the block and object storage products and also some order", "tokens": [50380, 4077, 412, 42999, 676, 11, 370, 885, 264, 3461, 293, 2657, 6725, 3383, 293, 611, 512, 1668, 50752], "temperature": 0.2, "avg_logprob": -0.4061613976955414, "compression_ratio": 1.5, "no_speech_prob": 0.09723514318466187}, {"id": 8, "seek": 5084, "start": 58.6, "end": 64.2, "text": " systems like the RfNSAN and the data backup in the online ecosystem and we have around", "tokens": [50752, 3652, 411, 264, 497, 69, 45, 50, 1770, 293, 264, 1412, 14807, 294, 264, 2950, 11311, 293, 321, 362, 926, 51032], "temperature": 0.2, "avg_logprob": -0.4061613976955414, "compression_ratio": 1.5, "no_speech_prob": 0.09723514318466187}, {"id": 9, "seek": 5084, "start": 64.2, "end": 73.32000000000001, "text": " a thousand servers in production and more than a hundred bitabytes of storage. So when I joined", "tokens": [51032, 257, 4714, 15909, 294, 4265, 293, 544, 813, 257, 3262, 857, 24538, 295, 6725, 13, 407, 562, 286, 6869, 51488], "temperature": 0.2, "avg_logprob": -0.4061613976955414, "compression_ratio": 1.5, "no_speech_prob": 0.09723514318466187}, {"id": 10, "seek": 7332, "start": 73.32, "end": 81.44, "text": " the team five years ago, the intro was what it was, it was drawn organically over the years", "tokens": [50364, 264, 1469, 1732, 924, 2057, 11, 264, 12897, 390, 437, 309, 390, 11, 309, 390, 10117, 1798, 984, 670, 264, 924, 50770], "temperature": 0.0, "avg_logprob": -0.29241713924684387, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.10344263166189194}, {"id": 11, "seek": 7332, "start": 81.44, "end": 92.16, "text": " and the versions were over the places, everything was a bit custom for the team needs at the time,", "tokens": [50770, 293, 264, 9606, 645, 670, 264, 3190, 11, 1203, 390, 257, 857, 2375, 337, 264, 1469, 2203, 412, 264, 565, 11, 51306], "temperature": 0.0, "avg_logprob": -0.29241713924684387, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.10344263166189194}, {"id": 12, "seek": 7332, "start": 92.16, "end": 101.75999999999999, "text": " so some servers were locally installed, some were PXC but everything was not homogeneous and we", "tokens": [51306, 370, 512, 15909, 645, 16143, 8899, 11, 512, 645, 430, 55, 34, 457, 1203, 390, 406, 42632, 293, 321, 51786], "temperature": 0.0, "avg_logprob": -0.29241713924684387, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.10344263166189194}, {"id": 13, "seek": 10176, "start": 101.76, "end": 108.32000000000001, "text": " had an old pearl-based automation system that suffered a lot because not so much people had", "tokens": [50364, 632, 364, 1331, 20287, 12, 6032, 17769, 1185, 300, 12770, 257, 688, 570, 406, 370, 709, 561, 632, 50692], "temperature": 0.0, "avg_logprob": -0.19655125935872395, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.014120950363576412}, {"id": 14, "seek": 10176, "start": 108.32000000000001, "end": 115.88000000000001, "text": " fluency in pearl, so it was pretty much a huge happen-only script that did stuff. So we wanted", "tokens": [50692, 5029, 3020, 294, 20287, 11, 370, 309, 390, 1238, 709, 257, 2603, 1051, 12, 25202, 5755, 300, 630, 1507, 13, 407, 321, 1415, 51070], "temperature": 0.0, "avg_logprob": -0.19655125935872395, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.014120950363576412}, {"id": 15, "seek": 10176, "start": 115.88000000000001, "end": 122.64, "text": " to start something fresh, something new, something we could work on for a few years, so we started", "tokens": [51070, 281, 722, 746, 4451, 11, 746, 777, 11, 746, 321, 727, 589, 322, 337, 257, 1326, 924, 11, 370, 321, 1409, 51408], "temperature": 0.0, "avg_logprob": -0.19655125935872395, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.014120950363576412}, {"id": 16, "seek": 10176, "start": 122.64, "end": 128.84, "text": " considering stuff, everybody at the time started to use containers but we were not a fan because", "tokens": [51408, 8079, 1507, 11, 2201, 412, 264, 565, 1409, 281, 764, 17089, 457, 321, 645, 406, 257, 3429, 570, 51718], "temperature": 0.0, "avg_logprob": -0.19655125935872395, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.014120950363576412}, {"id": 17, "seek": 12884, "start": 128.84, "end": 133.96, "text": " at that time they were not as material, the tooling and ecosystem was not that great and also we", "tokens": [50364, 412, 300, 565, 436, 645, 406, 382, 2527, 11, 264, 46593, 293, 11311, 390, 406, 300, 869, 293, 611, 321, 50620], "temperature": 0.0, "avg_logprob": -0.20406044854058158, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.005839098710566759}, {"id": 18, "seek": 12884, "start": 133.96, "end": 140.0, "text": " wanted to try something different. We still use containers for developer purposes, CI and whatever", "tokens": [50620, 1415, 281, 853, 746, 819, 13, 492, 920, 764, 17089, 337, 10754, 9932, 11, 37777, 293, 2035, 50922], "temperature": 0.0, "avg_logprob": -0.20406044854058158, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.005839098710566759}, {"id": 19, "seek": 12884, "start": 140.0, "end": 147.4, "text": " but we decided to do pixie live booting. It comes with some great advantages, first of all you", "tokens": [50922, 457, 321, 3047, 281, 360, 11273, 414, 1621, 11450, 278, 13, 467, 1487, 365, 512, 869, 14906, 11, 700, 295, 439, 291, 51292], "temperature": 0.0, "avg_logprob": -0.20406044854058158, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.005839098710566759}, {"id": 20, "seek": 12884, "start": 147.4, "end": 152.0, "text": " just plug the server to the network, you put your discovery image and you are pretty much set up,", "tokens": [51292, 445, 5452, 264, 7154, 281, 264, 3209, 11, 291, 829, 428, 12114, 3256, 293, 291, 366, 1238, 709, 992, 493, 11, 51522], "temperature": 0.0, "avg_logprob": -0.20406044854058158, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.005839098710566759}, {"id": 21, "seek": 15200, "start": 152.16, "end": 160.4, "text": " nothing else to do. Reboot is just like taking down a container to update it and it's when you", "tokens": [50372, 1825, 1646, 281, 360, 13, 1300, 1763, 310, 307, 445, 411, 1940, 760, 257, 10129, 281, 5623, 309, 293, 309, 311, 562, 291, 50784], "temperature": 0.0, "avg_logprob": -0.24122728347778322, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.04280640929937363}, {"id": 22, "seek": 15200, "start": 160.4, "end": 166.64, "text": " have thousands of servers in production, reboot is not that big of a deal, it's just life. The only", "tokens": [50784, 362, 5383, 295, 15909, 294, 4265, 11, 33818, 307, 406, 300, 955, 295, 257, 2028, 11, 309, 311, 445, 993, 13, 440, 787, 51096], "temperature": 0.0, "avg_logprob": -0.24122728347778322, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.04280640929937363}, {"id": 23, "seek": 15200, "start": 166.64, "end": 172.8, "text": " downside is that you need to have a solid network and working the HCP. As a cloud provider you", "tokens": [51096, 25060, 307, 300, 291, 643, 281, 362, 257, 5100, 3209, 293, 1364, 264, 389, 20049, 13, 1018, 257, 4588, 12398, 291, 51404], "temperature": 0.0, "avg_logprob": -0.24122728347778322, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.04280640929937363}, {"id": 24, "seek": 15200, "start": 172.8, "end": 181.56, "text": " don't have network, don't do anything, so not really a downside. So let's talk about automation.", "tokens": [51404, 500, 380, 362, 3209, 11, 500, 380, 360, 1340, 11, 370, 406, 534, 257, 25060, 13, 407, 718, 311, 751, 466, 17769, 13, 51842], "temperature": 0.0, "avg_logprob": -0.24122728347778322, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.04280640929937363}, {"id": 25, "seek": 18156, "start": 182.28, "end": 190.76, "text": " After using the Perl stuff we started on salt, it worked okay but it was really hard to test", "tokens": [50400, 2381, 1228, 264, 3026, 75, 1507, 321, 1409, 322, 5139, 11, 309, 2732, 1392, 457, 309, 390, 534, 1152, 281, 1500, 50824], "temperature": 0.0, "avg_logprob": -0.21446072924268114, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.009687399491667747}, {"id": 26, "seek": 18156, "start": 190.76, "end": 196.68, "text": " modifications before putting them in production and at the time it was nobody's job, pretty much,", "tokens": [50824, 26881, 949, 3372, 552, 294, 4265, 293, 412, 264, 565, 309, 390, 5079, 311, 1691, 11, 1238, 709, 11, 51120], "temperature": 0.0, "avg_logprob": -0.21446072924268114, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.009687399491667747}, {"id": 27, "seek": 18156, "start": 196.68, "end": 202.84, "text": " like no one had clear in-house responsibility for it, so it was not that well maintained.", "tokens": [51120, 411, 572, 472, 632, 1850, 294, 12, 6410, 6357, 337, 309, 11, 370, 309, 390, 406, 300, 731, 17578, 13, 51428], "temperature": 0.0, "avg_logprob": -0.21446072924268114, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.009687399491667747}, {"id": 28, "seek": 18156, "start": 203.72, "end": 209.4, "text": " So one day we decided to move to Ansible, mostly because everyone else at the time was moving to", "tokens": [51472, 407, 472, 786, 321, 3047, 281, 1286, 281, 14590, 964, 11, 5240, 570, 1518, 1646, 412, 264, 565, 390, 2684, 281, 51756], "temperature": 0.0, "avg_logprob": -0.21446072924268114, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.009687399491667747}, {"id": 29, "seek": 20940, "start": 209.48000000000002, "end": 217.08, "text": " Ansible in the company, so we wanted to share our efforts and small libraries so that everybody can", "tokens": [50368, 14590, 964, 294, 264, 2237, 11, 370, 321, 1415, 281, 2073, 527, 6484, 293, 1359, 15148, 370, 300, 2201, 393, 50748], "temperature": 0.0, "avg_logprob": -0.1777664601117715, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.0040826257318258286}, {"id": 30, "seek": 20940, "start": 218.92000000000002, "end": 226.52, "text": " like do stuff cleaner and not have something where everyone does things on the side. It's", "tokens": [50840, 411, 360, 1507, 16532, 293, 406, 362, 746, 689, 1518, 775, 721, 322, 264, 1252, 13, 467, 311, 51220], "temperature": 0.0, "avg_logprob": -0.1777664601117715, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.0040826257318258286}, {"id": 31, "seek": 20940, "start": 226.52, "end": 232.28, "text": " easier to write, easier to test, the learning curve is not as steep as with salt and you don't", "tokens": [51220, 3571, 281, 2464, 11, 3571, 281, 1500, 11, 264, 2539, 7605, 307, 406, 382, 16841, 382, 365, 5139, 293, 291, 500, 380, 51508], "temperature": 0.0, "avg_logprob": -0.1777664601117715, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.0040826257318258286}, {"id": 32, "seek": 20940, "start": 232.28, "end": 235.88, "text": " have a central controller that has to be maintained by a sentencing team, you just", "tokens": [51508, 362, 257, 5777, 10561, 300, 575, 281, 312, 17578, 538, 257, 2279, 13644, 1469, 11, 291, 445, 51688], "temperature": 0.0, "avg_logprob": -0.1777664601117715, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.0040826257318258286}, {"id": 33, "seek": 23588, "start": 235.88, "end": 241.16, "text": " can keep that in-house. But ultimately we wrote something along the lines of a controller,", "tokens": [50364, 393, 1066, 300, 294, 12, 6410, 13, 583, 6284, 321, 4114, 746, 2051, 264, 3876, 295, 257, 10561, 11, 50628], "temperature": 0.0, "avg_logprob": -0.21435138157435826, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.006683669984340668}, {"id": 34, "seek": 23588, "start": 241.16, "end": 251.16, "text": " but some really dumb stuff, around 250 lines of go for the server and just a shy of 100", "tokens": [50628, 457, 512, 534, 10316, 1507, 11, 926, 11650, 3876, 295, 352, 337, 264, 7154, 293, 445, 257, 12685, 295, 2319, 51128], "temperature": 0.0, "avg_logprob": -0.21435138157435826, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.006683669984340668}, {"id": 35, "seek": 23588, "start": 251.16, "end": 257.15999999999997, "text": " for the client, it's written in Python, it's pretty dumb just an API that when a server boots it", "tokens": [51128, 337, 264, 6423, 11, 309, 311, 3720, 294, 15329, 11, 309, 311, 1238, 10316, 445, 364, 9362, 300, 562, 257, 7154, 15194, 309, 51428], "temperature": 0.0, "avg_logprob": -0.21435138157435826, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.006683669984340668}, {"id": 36, "seek": 25716, "start": 257.16, "end": 261.40000000000003, "text": " calls it the API ID. Okay, here you are, here's your configuration.", "tokens": [50364, 5498, 309, 264, 9362, 7348, 13, 1033, 11, 510, 291, 366, 11, 510, 311, 428, 11694, 13, 50576], "temperature": 0.0, "avg_logprob": -0.22515995582837736, "compression_ratio": 1.5745614035087718, "no_speech_prob": 0.006558263208717108}, {"id": 37, "seek": 25716, "start": 264.6, "end": 270.6, "text": " Just to have something a bit cleaner that works well with pixie images, we have split up the", "tokens": [50736, 1449, 281, 362, 746, 257, 857, 16532, 300, 1985, 731, 365, 11273, 414, 5267, 11, 321, 362, 7472, 493, 264, 51036], "temperature": 0.0, "avg_logprob": -0.22515995582837736, "compression_ratio": 1.5745614035087718, "no_speech_prob": 0.006558263208717108}, {"id": 38, "seek": 25716, "start": 270.6, "end": 276.36, "text": " automation in two parts, we have one part that's our deployment playbooks, the only job in the life", "tokens": [51036, 17769, 294, 732, 3166, 11, 321, 362, 472, 644, 300, 311, 527, 19317, 862, 15170, 11, 264, 787, 1691, 294, 264, 993, 51324], "temperature": 0.0, "avg_logprob": -0.22515995582837736, "compression_ratio": 1.5745614035087718, "no_speech_prob": 0.006558263208717108}, {"id": 39, "seek": 25716, "start": 276.36, "end": 283.0, "text": " is to install and update all the software stacks and that's pretty much it, and afterwards we have", "tokens": [51324, 307, 281, 3625, 293, 5623, 439, 264, 4722, 30792, 293, 300, 311, 1238, 709, 309, 11, 293, 10543, 321, 362, 51656], "temperature": 0.0, "avg_logprob": -0.22515995582837736, "compression_ratio": 1.5745614035087718, "no_speech_prob": 0.006558263208717108}, {"id": 40, "seek": 28300, "start": 283.0, "end": 288.76, "text": " the runtime playbooks, which job is to set up networking, because basically when you boot it", "tokens": [50364, 264, 34474, 862, 15170, 11, 597, 1691, 307, 281, 992, 493, 17985, 11, 570, 1936, 562, 291, 11450, 309, 50652], "temperature": 0.0, "avg_logprob": -0.3437430911593967, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.007088143844157457}, {"id": 41, "seek": 28300, "start": 288.76, "end": 295.56, "text": " in the lifeboots you just have the basic one interface DHCP address and you need some network", "tokens": [50652, 294, 264, 993, 1763, 1971, 291, 445, 362, 264, 3875, 472, 9226, 28606, 20049, 2985, 293, 291, 643, 512, 3209, 50992], "temperature": 0.0, "avg_logprob": -0.3437430911593967, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.007088143844157457}, {"id": 42, "seek": 28300, "start": 295.56, "end": 300.12, "text": " configuration to make your service work, it assembles the raids, mount fire system, tune", "tokens": [50992, 11694, 281, 652, 428, 2643, 589, 11, 309, 8438, 904, 264, 45740, 11, 3746, 2610, 1185, 11, 10864, 51220], "temperature": 0.0, "avg_logprob": -0.3437430911593967, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.007088143844157457}, {"id": 43, "seek": 28300, "start": 300.12, "end": 306.2, "text": " the OS like sysatel, separate governor or whatever, and after that just configure and start your services.", "tokens": [51220, 264, 12731, 411, 262, 749, 267, 338, 11, 4994, 12965, 420, 2035, 11, 293, 934, 300, 445, 22162, 293, 722, 428, 3328, 13, 51524], "temperature": 0.0, "avg_logprob": -0.3437430911593967, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.007088143844157457}, {"id": 44, "seek": 30620, "start": 306.59999999999997, "end": 315.96, "text": " One quick note, the installed playbooks are run on prediction server and during image", "tokens": [50384, 1485, 1702, 3637, 11, 264, 8899, 862, 15170, 366, 1190, 322, 17630, 7154, 293, 1830, 3256, 50852], "temperature": 0.0, "avg_logprob": -0.1731547236442566, "compression_ratio": 1.6445497630331753, "no_speech_prob": 0.014427989721298218}, {"id": 45, "seek": 30620, "start": 315.96, "end": 321.24, "text": " creations and some are there just to remove default packages that we do not want to have", "tokens": [50852, 37836, 293, 512, 366, 456, 445, 281, 4159, 7576, 17401, 300, 321, 360, 406, 528, 281, 362, 51116], "temperature": 0.0, "avg_logprob": -0.1731547236442566, "compression_ratio": 1.6445497630331753, "no_speech_prob": 0.014427989721298218}, {"id": 46, "seek": 30620, "start": 322.2, "end": 330.2, "text": " in the built image. Now just a little bit about how we handle pixie image creations,", "tokens": [51164, 294, 264, 3094, 3256, 13, 823, 445, 257, 707, 857, 466, 577, 321, 4813, 11273, 414, 3256, 37836, 11, 51564], "temperature": 0.0, "avg_logprob": -0.1731547236442566, "compression_ratio": 1.6445497630331753, "no_speech_prob": 0.014427989721298218}, {"id": 47, "seek": 30620, "start": 331.08, "end": 335.56, "text": " basically a pixie image is a squash of s that you download over the internet just after", "tokens": [51608, 1936, 257, 11273, 414, 3256, 307, 257, 30725, 295, 262, 300, 291, 5484, 670, 264, 4705, 445, 934, 51832], "temperature": 0.0, "avg_logprob": -0.1731547236442566, "compression_ratio": 1.6445497630331753, "no_speech_prob": 0.014427989721298218}, {"id": 48, "seek": 33556, "start": 335.56, "end": 342.04, "text": " having booted your kernel, it's literally a rootfes of your server that's inside the RAM,", "tokens": [50364, 1419, 11450, 292, 428, 28256, 11, 309, 311, 3736, 257, 5593, 69, 279, 295, 428, 7154, 300, 311, 1854, 264, 14561, 11, 50688], "temperature": 0.0, "avg_logprob": -0.2693041408763212, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.005839224439114332}, {"id": 49, "seek": 33556, "start": 343.56, "end": 349.08, "text": " the first ways that were used before arrived was just a snapshot of the rootfes of a VM,", "tokens": [50764, 264, 700, 2098, 300, 645, 1143, 949, 6678, 390, 445, 257, 30163, 295, 264, 5593, 69, 279, 295, 257, 18038, 11, 51040], "temperature": 0.0, "avg_logprob": -0.2693041408763212, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.005839224439114332}, {"id": 50, "seek": 33556, "start": 349.96, "end": 356.2, "text": " afterwards there were Docker to pixie.pl, basically a huge power strip that was extracting the", "tokens": [51084, 10543, 456, 645, 33772, 281, 11273, 414, 13, 564, 11, 1936, 257, 2603, 1347, 12828, 300, 390, 49844, 264, 51396], "temperature": 0.0, "avg_logprob": -0.2693041408763212, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.005839224439114332}, {"id": 51, "seek": 33556, "start": 357.56, "end": 363.24, "text": " file system of a container, it came with some limitations, because basically", "tokens": [51464, 3991, 1185, 295, 257, 10129, 11, 309, 1361, 365, 512, 15705, 11, 570, 1936, 51748], "temperature": 0.0, "avg_logprob": -0.2693041408763212, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.005839224439114332}, {"id": 52, "seek": 36556, "start": 365.72, "end": 370.52, "text": " the way that base image of containers are made make that not a fully functional OS,", "tokens": [50372, 264, 636, 300, 3096, 3256, 295, 17089, 366, 1027, 652, 300, 406, 257, 4498, 11745, 12731, 11, 50612], "temperature": 0.0, "avg_logprob": -0.26339901818169487, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0036968414206057787}, {"id": 53, "seek": 36556, "start": 371.64, "end": 379.08, "text": " afterwards we use Ashko Parker and now we use a small trick with sshd and uncivilized ssh port", "tokens": [50668, 10543, 321, 764, 10279, 4093, 20155, 293, 586, 321, 764, 257, 1359, 4282, 365, 262, 2716, 67, 293, 517, 537, 20202, 1602, 262, 2716, 2436, 51040], "temperature": 0.0, "avg_logprob": -0.26339901818169487, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0036968414206057787}, {"id": 54, "seek": 36556, "start": 379.08, "end": 384.6, "text": " that basically traps the uncivilization inside the ashrut on the build server.", "tokens": [51040, 300, 1936, 24173, 264, 517, 537, 20202, 2144, 1854, 264, 382, 1703, 325, 322, 264, 1322, 7154, 13, 51316], "temperature": 0.0, "avg_logprob": -0.26339901818169487, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0036968414206057787}, {"id": 55, "seek": 36556, "start": 386.04, "end": 391.64, "text": " The advantage of this is that the same playbooks for the deployments of software are used for both", "tokens": [51388, 440, 5002, 295, 341, 307, 300, 264, 912, 862, 15170, 337, 264, 7274, 1117, 295, 4722, 366, 1143, 337, 1293, 51668], "temperature": 0.0, "avg_logprob": -0.26339901818169487, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0036968414206057787}, {"id": 56, "seek": 39164, "start": 391.64, "end": 398.2, "text": " the creation of the image and updating servers and predictions, and the build system is based", "tokens": [50364, 264, 8016, 295, 264, 3256, 293, 25113, 15909, 293, 21264, 11, 293, 264, 1322, 1185, 307, 2361, 50692], "temperature": 0.0, "avg_logprob": -0.23873158718677276, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0055442978627979755}, {"id": 57, "seek": 39164, "start": 398.2, "end": 403.64, "text": " on the ubuntu server image, nothing fancy, and we are using the default LiveBooty Neutron fs", "tokens": [50692, 322, 264, 26709, 45605, 7154, 3256, 11, 1825, 10247, 11, 293, 321, 366, 1228, 264, 7576, 10385, 33, 6259, 88, 1734, 325, 2044, 283, 82, 50964], "temperature": 0.0, "avg_logprob": -0.23873158718677276, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0055442978627979755}, {"id": 58, "seek": 39164, "start": 403.64, "end": 411.24, "text": " package that comes up with dbian and ubuntu with a few tweaks to allow for retries and to avoid", "tokens": [50964, 7372, 300, 1487, 493, 365, 274, 20196, 293, 26709, 45605, 365, 257, 1326, 46664, 281, 2089, 337, 1533, 2244, 293, 281, 5042, 51344], "temperature": 0.0, "avg_logprob": -0.23873158718677276, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0055442978627979755}, {"id": 59, "seek": 39164, "start": 411.24, "end": 418.12, "text": " boot storms, like you have 30 or 40 servers that reboot at the same time that do not fetch", "tokens": [51344, 11450, 23288, 11, 411, 291, 362, 2217, 420, 3356, 15909, 300, 33818, 412, 264, 912, 565, 300, 360, 406, 23673, 51688], "temperature": 0.0, "avg_logprob": -0.23873158718677276, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0055442978627979755}, {"id": 60, "seek": 41812, "start": 418.92, "end": 423.48, "text": " the squash fs on the same machines to avoid any networking issues.", "tokens": [50404, 264, 30725, 283, 82, 322, 264, 912, 8379, 281, 5042, 604, 17985, 2663, 13, 50632], "temperature": 0.0, "avg_logprob": -0.23775355021158853, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.007198110222816467}, {"id": 61, "seek": 41812, "start": 426.2, "end": 431.56, "text": " Here's the fun part, there is a small playbook that's called pixiemagic.tml that handles a lot of", "tokens": [50768, 1692, 311, 264, 1019, 644, 11, 456, 307, 257, 1359, 862, 2939, 300, 311, 1219, 11273, 414, 37941, 299, 13, 83, 76, 75, 300, 18722, 257, 688, 295, 51036], "temperature": 0.0, "avg_logprob": -0.23775355021158853, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.007198110222816467}, {"id": 62, "seek": 41812, "start": 431.56, "end": 439.72, "text": " stuff, that's cool because the ubuntu default packages are not all meant to be run inside", "tokens": [51036, 1507, 11, 300, 311, 1627, 570, 264, 26709, 45605, 7576, 17401, 366, 406, 439, 4140, 281, 312, 1190, 1854, 51444], "temperature": 0.0, "avg_logprob": -0.23775355021158853, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.007198110222816467}, {"id": 63, "seek": 41812, "start": 439.72, "end": 446.12, "text": " a LiveBoot environment, first we avoid triggering the packages triggers during kernel install", "tokens": [51444, 257, 10385, 33, 6259, 2823, 11, 700, 321, 5042, 40406, 264, 17401, 22827, 1830, 28256, 3625, 51764], "temperature": 0.0, "avg_logprob": -0.23775355021158853, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.007198110222816467}, {"id": 64, "seek": 44612, "start": 446.12, "end": 451.0, "text": " because it saves a lot of time during the creation of an image, but afterwards you have to rebuild", "tokens": [50364, 570, 309, 19155, 257, 688, 295, 565, 1830, 264, 8016, 295, 364, 3256, 11, 457, 10543, 291, 362, 281, 16877, 50608], "temperature": 0.0, "avg_logprob": -0.1660764299590012, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.006304877810180187}, {"id": 65, "seek": 44612, "start": 451.0, "end": 456.44, "text": " all the dkms and custom kernel models to specifically target the kernel version that is", "tokens": [50608, 439, 264, 274, 74, 2592, 293, 2375, 28256, 5245, 281, 4682, 3779, 264, 28256, 3037, 300, 307, 50880], "temperature": 0.0, "avg_logprob": -0.1660764299590012, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.006304877810180187}, {"id": 66, "seek": 44612, "start": 456.44, "end": 461.8, "text": " inside the shoot because it's not the same as the host necessarily, all the hypermorph profiles", "tokens": [50880, 1854, 264, 3076, 570, 309, 311, 406, 264, 912, 382, 264, 3975, 4725, 11, 439, 264, 9848, 76, 18191, 23693, 51148], "temperature": 0.0, "avg_logprob": -0.1660764299590012, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.006304877810180187}, {"id": 67, "seek": 44612, "start": 461.8, "end": 471.64, "text": " are to be patched because they limit what software can access which files, but as you are running", "tokens": [51148, 366, 281, 312, 9972, 292, 570, 436, 4948, 437, 4722, 393, 2105, 597, 7098, 11, 457, 382, 291, 366, 2614, 51640], "temperature": 0.0, "avg_logprob": -0.1660764299590012, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.006304877810180187}, {"id": 68, "seek": 47164, "start": 471.64, "end": 478.36, "text": " from ram, you have some kind of overlay fs above it, so apparently that's ntp for example,", "tokens": [50364, 490, 10211, 11, 291, 362, 512, 733, 295, 31741, 283, 82, 3673, 309, 11, 370, 7970, 300, 311, 297, 83, 79, 337, 1365, 11, 50700], "temperature": 0.0, "avg_logprob": -0.2440027090219351, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.023175742477178574}, {"id": 69, "seek": 47164, "start": 478.36, "end": 487.8, "text": " it's not targeting the ntp drift file in slashvar but in somewhere like varlib, live, medium,", "tokens": [50700, 309, 311, 406, 17918, 264, 297, 83, 79, 19699, 3991, 294, 17330, 8517, 457, 294, 4079, 411, 1374, 38270, 11, 1621, 11, 6399, 11, 51172], "temperature": 0.0, "avg_logprob": -0.2440027090219351, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.023175742477178574}, {"id": 70, "seek": 47164, "start": 487.8, "end": 493.88, "text": " something, overlay fs, so you have to patch all those, here's the flag, just like two weeks to", "tokens": [51172, 746, 11, 31741, 283, 82, 11, 370, 291, 362, 281, 9972, 439, 729, 11, 510, 311, 264, 7166, 11, 445, 411, 732, 3259, 281, 51476], "temperature": 0.0, "avg_logprob": -0.2440027090219351, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.023175742477178574}, {"id": 71, "seek": 47164, "start": 493.88, "end": 501.15999999999997, "text": " find in another main learning list of the kernel, like 2.4 or something, you have that support for", "tokens": [51476, 915, 294, 1071, 2135, 2539, 1329, 295, 264, 28256, 11, 411, 568, 13, 19, 420, 746, 11, 291, 362, 300, 1406, 337, 51840], "temperature": 0.0, "avg_logprob": -0.2440027090219351, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.023175742477178574}, {"id": 72, "seek": 50116, "start": 501.24, "end": 507.40000000000003, "text": " the overlay fs, so you don't break the default in your td before configuration, and as the system", "tokens": [50368, 264, 31741, 283, 82, 11, 370, 291, 500, 380, 1821, 264, 7576, 294, 428, 256, 67, 949, 11694, 11, 293, 382, 264, 1185, 50676], "temperature": 0.0, "avg_logprob": -0.23478529625332234, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.007075989153236151}, {"id": 73, "seek": 50116, "start": 507.40000000000003, "end": 513.32, "text": " is amnesiac after each reboot, you have to take into account that we do not use any network", "tokens": [50676, 307, 669, 4081, 13921, 934, 1184, 33818, 11, 291, 362, 281, 747, 666, 2696, 300, 321, 360, 406, 764, 604, 3209, 50972], "temperature": 0.0, "avg_logprob": -0.23478529625332234, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.007075989153236151}, {"id": 74, "seek": 50116, "start": 513.32, "end": 520.0400000000001, "text": " configuration utility, so no network d, no if and down, nothing, so you have to take that into", "tokens": [50972, 11694, 14877, 11, 370, 572, 3209, 274, 11, 572, 498, 293, 760, 11, 1825, 11, 370, 291, 362, 281, 747, 300, 666, 51308], "temperature": 0.0, "avg_logprob": -0.23478529625332234, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.007075989153236151}, {"id": 75, "seek": 50116, "start": 520.0400000000001, "end": 529.48, "text": " account because some simulink are broken by default. So we've been doing that for five years and", "tokens": [51308, 2696, 570, 512, 1034, 425, 475, 366, 5463, 538, 7576, 13, 407, 321, 600, 668, 884, 300, 337, 1732, 924, 293, 51780], "temperature": 0.0, "avg_logprob": -0.23478529625332234, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.007075989153236151}, {"id": 76, "seek": 52948, "start": 529.72, "end": 538.12, "text": " well, pretty much nothing to say, just works, we have the convenience of containers, so we have", "tokens": [50376, 731, 11, 1238, 709, 1825, 281, 584, 11, 445, 1985, 11, 321, 362, 264, 19283, 295, 17089, 11, 370, 321, 362, 50796], "temperature": 0.0, "avg_logprob": -0.1750047816786655, "compression_ratio": 1.7377777777777779, "no_speech_prob": 0.002158503048121929}, {"id": 77, "seek": 52948, "start": 538.9200000000001, "end": 544.6, "text": " all the systems into production that are pretty much homogeneous, with pretty much some version", "tokens": [50836, 439, 264, 3652, 666, 4265, 300, 366, 1238, 709, 42632, 11, 365, 1238, 709, 512, 3037, 51120], "temperature": 0.0, "avg_logprob": -0.1750047816786655, "compression_ratio": 1.7377777777777779, "no_speech_prob": 0.002158503048121929}, {"id": 78, "seek": 52948, "start": 544.6, "end": 550.84, "text": " everywhere, and we have the comfort of using just plain bare metal servers without having any issues,", "tokens": [51120, 5315, 11, 293, 321, 362, 264, 3400, 295, 1228, 445, 11121, 6949, 5760, 15909, 1553, 1419, 604, 2663, 11, 51432], "temperature": 0.0, "avg_logprob": -0.1750047816786655, "compression_ratio": 1.7377777777777779, "no_speech_prob": 0.002158503048121929}, {"id": 79, "seek": 52948, "start": 551.5600000000001, "end": 557.48, "text": " like a long time ago when you updated Docker, it had the bad habits of restarting every container", "tokens": [51468, 411, 257, 938, 565, 2057, 562, 291, 10588, 33772, 11, 309, 632, 264, 1578, 14100, 295, 21022, 278, 633, 10129, 51764], "temperature": 0.0, "avg_logprob": -0.1750047816786655, "compression_ratio": 1.7377777777777779, "no_speech_prob": 0.002158503048121929}, {"id": 80, "seek": 55748, "start": 557.5600000000001, "end": 565.48, "text": " on the host without asking you anything, we can scale from 100 servers to a thousand,", "tokens": [50368, 322, 264, 3975, 1553, 3365, 291, 1340, 11, 321, 393, 4373, 490, 2319, 15909, 281, 257, 4714, 11, 50764], "temperature": 0.0, "avg_logprob": -0.18028472190679506, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.00833201128989458}, {"id": 81, "seek": 55748, "start": 566.6800000000001, "end": 571.32, "text": " with only pretty much three to four people handling deployment in installation of servers,", "tokens": [50824, 365, 787, 1238, 709, 1045, 281, 1451, 561, 13175, 19317, 294, 13260, 295, 15909, 11, 51056], "temperature": 0.0, "avg_logprob": -0.18028472190679506, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.00833201128989458}, {"id": 82, "seek": 55748, "start": 572.76, "end": 579.5600000000001, "text": " and new servers are deployed quite fast, like it takes like one hour to deploy 10 new servers", "tokens": [51128, 293, 777, 15909, 366, 17826, 1596, 2370, 11, 411, 309, 2516, 411, 472, 1773, 281, 7274, 1266, 777, 15909, 51468], "temperature": 0.0, "avg_logprob": -0.18028472190679506, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.00833201128989458}, {"id": 83, "seek": 55748, "start": 579.5600000000001, "end": 585.5600000000001, "text": " maximum, because you just have to collect the max, update the DHCP, and put the machines, and it just", "tokens": [51468, 6674, 11, 570, 291, 445, 362, 281, 2500, 264, 11469, 11, 5623, 264, 28606, 20049, 11, 293, 829, 264, 8379, 11, 293, 309, 445, 51768], "temperature": 0.0, "avg_logprob": -0.18028472190679506, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.00833201128989458}, {"id": 84, "seek": 58556, "start": 585.56, "end": 590.3599999999999, "text": " works, and if you want to update anything, you just have to reboot, it's pretty simple.", "tokens": [50364, 1985, 11, 293, 498, 291, 528, 281, 5623, 1340, 11, 291, 445, 362, 281, 33818, 11, 309, 311, 1238, 2199, 13, 50604], "temperature": 0.0, "avg_logprob": -0.2971489164564345, "compression_ratio": 1.5515695067264574, "no_speech_prob": 0.00796907301992178}, {"id": 85, "seek": 58556, "start": 593.0, "end": 599.0799999999999, "text": " I think that's supposed to be fast. Does anyone have questions? Yes?", "tokens": [50736, 286, 519, 300, 311, 3442, 281, 312, 2370, 13, 4402, 2878, 362, 1651, 30, 1079, 30, 51040], "temperature": 0.0, "avg_logprob": -0.2971489164564345, "compression_ratio": 1.5515695067264574, "no_speech_prob": 0.00796907301992178}, {"id": 86, "seek": 58556, "start": 599.0799999999999, "end": 603.7199999999999, "text": " That doesn't mean that the operating system has basically never written the disk on the client.", "tokens": [51040, 663, 1177, 380, 914, 300, 264, 7447, 1185, 575, 1936, 1128, 3720, 264, 12355, 322, 264, 6423, 13, 51272], "temperature": 0.0, "avg_logprob": -0.2971489164564345, "compression_ratio": 1.5515695067264574, "no_speech_prob": 0.00796907301992178}, {"id": 87, "seek": 58556, "start": 604.4399999999999, "end": 605.0799999999999, "text": " Excuse me.", "tokens": [51308, 11359, 385, 13, 51340], "temperature": 0.0, "avg_logprob": -0.2971489164564345, "compression_ratio": 1.5515695067264574, "no_speech_prob": 0.00796907301992178}, {"id": 88, "seek": 58556, "start": 605.0799999999999, "end": 608.52, "text": " Does that essentially mean that you have diskless servers there?", "tokens": [51340, 4402, 300, 4476, 914, 300, 291, 362, 12355, 1832, 15909, 456, 30, 51512], "temperature": 0.0, "avg_logprob": -0.2971489164564345, "compression_ratio": 1.5515695067264574, "no_speech_prob": 0.00796907301992178}, {"id": 89, "seek": 58556, "start": 608.52, "end": 610.04, "text": " Yeah. Okay, cool.", "tokens": [51512, 865, 13, 1033, 11, 1627, 13, 51588], "temperature": 0.0, "avg_logprob": -0.2971489164564345, "compression_ratio": 1.5515695067264574, "no_speech_prob": 0.00796907301992178}, {"id": 90, "seek": 61004, "start": 610.04, "end": 617.24, "text": " So the only data that's written on physical disk are the question.", "tokens": [50364, 407, 264, 787, 1412, 300, 311, 3720, 322, 4001, 12355, 366, 264, 1168, 13, 50724], "temperature": 0.0, "avg_logprob": -0.23568128985027934, "compression_ratio": 1.6634615384615385, "no_speech_prob": 0.005383357871323824}, {"id": 91, "seek": 61004, "start": 618.04, "end": 622.52, "text": " So I was saying that we did that install pretty much the servers, that there was no", "tokens": [50764, 407, 286, 390, 1566, 300, 321, 630, 300, 3625, 1238, 709, 264, 15909, 11, 300, 456, 390, 572, 50988], "temperature": 0.0, "avg_logprob": -0.23568128985027934, "compression_ratio": 1.6634615384615385, "no_speech_prob": 0.005383357871323824}, {"id": 92, "seek": 61004, "start": 622.52, "end": 628.5999999999999, "text": " OS installed on servers, and yes, we do have a few ones, like the one that handles the images,", "tokens": [50988, 12731, 8899, 322, 15909, 11, 293, 2086, 11, 321, 360, 362, 257, 1326, 2306, 11, 411, 264, 472, 300, 18722, 264, 5267, 11, 51292], "temperature": 0.0, "avg_logprob": -0.23568128985027934, "compression_ratio": 1.6634615384615385, "no_speech_prob": 0.005383357871323824}, {"id": 93, "seek": 61004, "start": 628.5999999999999, "end": 634.92, "text": " the installation, the DHCP, and so on, but every other servers inside our infrastructure is diskless", "tokens": [51292, 264, 13260, 11, 264, 28606, 20049, 11, 293, 370, 322, 11, 457, 633, 661, 15909, 1854, 527, 6896, 307, 12355, 1832, 51608], "temperature": 0.0, "avg_logprob": -0.23568128985027934, "compression_ratio": 1.6634615384615385, "no_speech_prob": 0.005383357871323824}, {"id": 94, "seek": 63492, "start": 635.64, "end": 640.36, "text": " for the OS parts, because we do have data from clients, and we tend to store that in memory,", "tokens": [50400, 337, 264, 12731, 3166, 11, 570, 321, 360, 362, 1412, 490, 6982, 11, 293, 321, 3928, 281, 3531, 300, 294, 4675, 11, 50636], "temperature": 0.0, "avg_logprob": -0.21903938200415635, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.016051407903432846}, {"id": 95, "seek": 63492, "start": 641.4, "end": 644.36, "text": " but that pretty much every disk is used for clients.", "tokens": [50688, 457, 300, 1238, 709, 633, 12355, 307, 1143, 337, 6982, 13, 50836], "temperature": 0.0, "avg_logprob": -0.21903938200415635, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.016051407903432846}, {"id": 96, "seek": 63492, "start": 646.28, "end": 647.28, "text": " Yes?", "tokens": [50932, 1079, 30, 50982], "temperature": 0.0, "avg_logprob": -0.21903938200415635, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.016051407903432846}, {"id": 97, "seek": 63492, "start": 647.28, "end": 651.8, "text": " Did you consider using live build or building your images instead of packer?", "tokens": [50982, 2589, 291, 1949, 1228, 1621, 1322, 420, 2390, 428, 5267, 2602, 295, 2844, 260, 30, 51208], "temperature": 0.0, "avg_logprob": -0.21903938200415635, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.016051407903432846}, {"id": 98, "seek": 63492, "start": 653.4, "end": 659.16, "text": " So the question was, did we consider using live build from packer? We did use that,", "tokens": [51288, 407, 264, 1168, 390, 11, 630, 321, 1949, 1228, 1621, 1322, 490, 2844, 260, 30, 492, 630, 764, 300, 11, 51576], "temperature": 0.0, "avg_logprob": -0.21903938200415635, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.016051407903432846}, {"id": 99, "seek": 65916, "start": 659.8, "end": 665.7199999999999, "text": " but at the time we were running on public virtual machines, and the building of images was pretty", "tokens": [50396, 457, 412, 264, 565, 321, 645, 2614, 322, 1908, 6374, 8379, 11, 293, 264, 2390, 295, 5267, 390, 1238, 50692], "temperature": 0.0, "avg_logprob": -0.20978628622519002, "compression_ratio": 1.6328125, "no_speech_prob": 0.021106772124767303}, {"id": 100, "seek": 65916, "start": 665.7199999999999, "end": 672.8399999999999, "text": " slow, so we moved to this solution using shrewd and a big-ass build server, and just really,", "tokens": [50692, 2964, 11, 370, 321, 4259, 281, 341, 3827, 1228, 402, 2236, 67, 293, 257, 955, 12, 640, 1322, 7154, 11, 293, 445, 534, 11, 51048], "temperature": 0.0, "avg_logprob": -0.20978628622519002, "compression_ratio": 1.6328125, "no_speech_prob": 0.021106772124767303}, {"id": 101, "seek": 65916, "start": 672.8399999999999, "end": 676.12, "text": " really fast, so that's why we use that now. Yes?", "tokens": [51048, 534, 2370, 11, 370, 300, 311, 983, 321, 764, 300, 586, 13, 1079, 30, 51212], "temperature": 0.0, "avg_logprob": -0.20978628622519002, "compression_ratio": 1.6328125, "no_speech_prob": 0.021106772124767303}, {"id": 102, "seek": 65916, "start": 676.12, "end": 681.24, "text": " By swapping out self-master, that means that now Ansible needs to be run like ad hoc.", "tokens": [51212, 3146, 1693, 10534, 484, 2698, 12, 21640, 11, 300, 1355, 300, 586, 14590, 964, 2203, 281, 312, 1190, 411, 614, 16708, 13, 51468], "temperature": 0.0, "avg_logprob": -0.20978628622519002, "compression_ratio": 1.6328125, "no_speech_prob": 0.021106772124767303}, {"id": 103, "seek": 65916, "start": 681.24, "end": 686.1999999999999, "text": " What kind of automation do you have on top of that? Because having to run Ansible every time", "tokens": [51468, 708, 733, 295, 17769, 360, 291, 362, 322, 1192, 295, 300, 30, 1436, 1419, 281, 1190, 14590, 964, 633, 565, 51716], "temperature": 0.0, "avg_logprob": -0.20978628622519002, "compression_ratio": 1.6328125, "no_speech_prob": 0.021106772124767303}, {"id": 104, "seek": 68620, "start": 686.2, "end": 694.12, "text": " from your laptop? Yeah, so as I said, the playbooks are run at boot time on the servers.", "tokens": [50364, 490, 428, 10732, 30, 865, 11, 370, 382, 286, 848, 11, 264, 862, 15170, 366, 1190, 412, 11450, 565, 322, 264, 15909, 13, 50760], "temperature": 0.0, "avg_logprob": -0.2010305438722883, "compression_ratio": 1.6329588014981273, "no_speech_prob": 0.0038536975625902414}, {"id": 105, "seek": 68620, "start": 694.12, "end": 698.36, "text": " Basically, on every servers you have a small client written in pittons that's like", "tokens": [50760, 8537, 11, 322, 633, 15909, 291, 362, 257, 1359, 6423, 3720, 294, 280, 593, 892, 300, 311, 411, 50972], "temperature": 0.0, "avg_logprob": -0.2010305438722883, "compression_ratio": 1.6329588014981273, "no_speech_prob": 0.0038536975625902414}, {"id": 106, "seek": 68620, "start": 698.36, "end": 704.2, "text": " 80 lines, but pretty much half of it is commentaries, and you just call an API saying,", "tokens": [50972, 4688, 3876, 11, 457, 1238, 709, 1922, 295, 309, 307, 2871, 4889, 11, 293, 291, 445, 818, 364, 9362, 1566, 11, 51264], "temperature": 0.0, "avg_logprob": -0.2010305438722883, "compression_ratio": 1.6329588014981273, "no_speech_prob": 0.0038536975625902414}, {"id": 107, "seek": 68620, "start": 704.2, "end": 709.96, "text": " hey, my IP is that, can you deploy me? And we have multiple services everywhere that just", "tokens": [51264, 4177, 11, 452, 8671, 307, 300, 11, 393, 291, 7274, 385, 30, 400, 321, 362, 3866, 3328, 5315, 300, 445, 51552], "temperature": 0.0, "avg_logprob": -0.2010305438722883, "compression_ratio": 1.6329588014981273, "no_speech_prob": 0.0038536975625902414}, {"id": 108, "seek": 68620, "start": 709.96, "end": 714.84, "text": " have a copy of all the deployment files and the configuration files, and it's a reverse", "tokens": [51552, 362, 257, 5055, 295, 439, 264, 19317, 7098, 293, 264, 11694, 7098, 11, 293, 309, 311, 257, 9943, 51796], "temperature": 0.0, "avg_logprob": -0.2010305438722883, "compression_ratio": 1.6329588014981273, "no_speech_prob": 0.0038536975625902414}, {"id": 109, "seek": 71484, "start": 714.9200000000001, "end": 719.4, "text": " Ansible deployment from a server inside there, so you don't have any human interaction to redeploy", "tokens": [50368, 14590, 964, 19317, 490, 257, 7154, 1854, 456, 11, 370, 291, 500, 380, 362, 604, 1952, 9285, 281, 14328, 2384, 50592], "temperature": 0.0, "avg_logprob": -0.25658261148553146, "compression_ratio": 1.3162393162393162, "no_speech_prob": 0.003365586744621396}, {"id": 110, "seek": 71484, "start": 719.4, "end": 740.76, "text": " a server. Any other questions? So thanks for your time.", "tokens": [50592, 257, 7154, 13, 2639, 661, 1651, 30, 407, 3231, 337, 428, 565, 13, 51660], "temperature": 0.0, "avg_logprob": -0.25658261148553146, "compression_ratio": 1.3162393162393162, "no_speech_prob": 0.003365586744621396}, {"id": 111, "seek": 74484, "start": 744.84, "end": 746.22, "text": " you", "tokens": [50404, 291, 50433], "temperature": 0.0, "avg_logprob": -0.8971539735794067, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.9065274596214294}], "language": "en"}