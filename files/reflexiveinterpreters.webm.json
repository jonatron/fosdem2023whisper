{"text": " Hi, I'm Wilberd. This talk is on self-conscious reflexive interpreters, and is joint work with Nada Amin. The talk is largely inspired by John Doyle's 1978 MIT PhD thesis proposal entitled Reflexive Interpreters, but also incorporates ideas from John McCarthy, Marvin Minsky, and Doug Lenit. It's very much work in progress. I hope you'll bear that in mind as you listen to the talk. However, we're hoping that ideas in this talk will encourage you to explore some of the space and ideas of reflexive or self-conscious interpreters, which both Nada and I find very intriguing and inspiring. So, in 1959, John McCarthy, who is known for many things, including being the originator of the list programming language, wrote a paper called Programs with Common Sense. This is one of the early papers in our symbolic artificial intelligence, or artificial intelligence in general, and he proposes this idea of writing a problem solver that can learn from its experience and also accept advice from an external entity and communicate with an external entity. So, he calls this software an advice taker, or the advice taker. So, when I talk about advice taker, I'm talking about the software he envisions in this 1959 paper, Programs with Common Sense. And in particular, his notion of common sense is far beyond what you see in almost any piece of software today, maybe with large language models very recently, you could argue that there's some common sense, even that's, I think, highly debatable. However, interacting with a compiler, or a text editor, or word processor, or things like that, I think there's really no common sense in those programs, even many decades after this original proposal. McCarthy describes this notion of a advice taker, and he proposes features of the advice taker that he thinks would be critical for building something. So, for example, all the behaviors of the system have to be representable in the system itself. So, this is a system that to some extent understands its own capabilities and behaviors. And also, the system has to be extensible in a simple way. And the system has to be able to improve its behavior. And there are other features of this program that McCarthy considers important. And then in the paper, he talks about different ways you could describe such a system using imperative or declarative sentences or language. And he also talks about how you might go about constructing an advice taker. It's important to understand that in 1959, John McCarthy hadn't attempted to create such a system. This is basically a white paper describing how you might go about building a system, or what the design might look like, or what the desired features of such a system would be. But he certainly hadn't implemented anything like advice taker at this point. And as far as I can tell, no one has succeeded in building something like advice taker today. He talks about the main features, representing expressions in the computer and so forth. When you read this paper, it is from 1959. So, it's fairly early on in the history of computing, at least as we see it in 2023. But you can see a kernel of an idea here. So, for example, he has this notion of an immediate deduction routine. So, if you're familiar with Kahneman's idea of system one and system two thinking, McCarthy in this paper proposes something very similar where there's fast thinking and slow thinking. You can have slow thinking that's more reflective or introspective. And you can have fast thinking, which is sort of automatic thinking. And so, part of the idea in this paper is that a smart system or common sense system, like the advice taker, would have access to what we might now call solvers. For example, SAT solvers, SMT solvers, things like that, or program synthesis tools or whatever, that for solving particular problems might be fast, but in some sense at a global level, aren't very introspective, not very smart. So, this overall software, which is supposed to display intelligent behavior, would be capable of using these lower level solvers in an intelligent way because the overall system would understand what the different solvers are good for and have some at least, you know, rough notion of how long it takes a solver to run, if it's going to finish roughly, things like that, what sort of resource usages it might have, and also what resources the overall system, the overall advice taker has available to it. For example, how much memory, how much RAM, how much nowadays flash drive space, you know, how much CPU horsepower, you know, is it running on a parallel supercomputer, is it running on a pocket calculator, so forth. So, the overall advice taker would be built in this kind of layered fashion, where there'd actually be a hierarchy of reasoning tasks and problem solving tasks going all the way down to calling out to these solvers, which probably can't be introspected into. So, in other words, the overall advice taker program can't look into these solvers necessarily to understand exactly how they're working, but it has some high level description of how they work or can learn over time through observation how they work. And the paper also presents a language here, logic based language basically for, you know, describing how a system might reason about going to the airport, for example, that kind of thing. Now, I'll say that I find this paper very inspiring. However, when read today, the paper can seem a little goofy or anachronistic, I guess, something like that, old fashioned. Part of the idea, part of the reason for that, I think, is that this example is not very inspiring. And I don't know where this came from. I don't think this is the greatest use of logic ever. And McCarthy later did a lot of work on frames and you know, logics where you could talk about what's changing and so forth, having to do with the frame problem, and these sorts of things. And you can maybe see some of his early reasoning, or thinking about these problems in this logical description. However, I don't think it's a particularly exciting example. And so a modern reader may read this example and think there's nothing really here. But I would encourage you if you read this paper to think a bit in terms of what McCarthy was trying to accomplish, not in terms of his encoding, or that particular logic he was using. Instead, you know, focus at the level of these five facets of a system, or his overall design where you'd have a fast system that you can't introspect into. And then you'd have high level, you know, a system that could represent aspects of itself and its behavior. So I think that's the important part of this paper, understanding that. One thing I found interesting about this paper also, which is definitely different from how most papers work today, is that at the very end, there's a description of when McCarthy presented the paper. And he's catching a little flak here from one of the pioneers of natural language processing, who says Dr. McCarthy's paper belongs in a journal of half-baked ideas. And part of this, I think, was because McCarthy hadn't even attempted to implement this. You know, if you think about the computing resources available in 1959, this is a pretty optimistic you know, system, or the idea that he could build a system, or anyone could build a system like this in 1959 was pretty amazing given that, you know, they were still basically waiting for transistorized computers and all that. But anyway, this paper, I think, if read by a modern reader focusing on the intent of McCarthy and the high level of concepts, is still inspiring today. And I think it's also true that, as McCarthy points out, computer programs don't have common sense. And the programs I use day in, day out, don't really learn from me. I can't converse with them and have a conversation. You know, McCarthy wanted to be able to use some sort of natural language processing, or maybe stylized language to converse with the program, and have the program be able to communicate its internal state, or aspects of its internal state, to an outside advisor, which would have been a human, I think, in McCarthy's day, but now potentially could be another program. And so he's got a lot of interesting ideas here. And, you know, I felt his frustration with the state of software, or reading this, and I feel that same frustration today, which I think is probably one reason why people get so excited by signing like chat GPT, which does appear to maybe have some common sense, or to be able to have a conversation with a user. So, this is a foundational paper in the history of artificial intelligence. It's full of interesting ideas, if you read it, I think, with the right mindset. And I think we haven't made that much progress even today on what McCarthy was proposing in 1959. So part of what Nada and I are trying to figure out is, well, why don't programs today have common sense in the way McCarthy was talking about? Why can't a program determine when it's stuck and ask for help, or have a human or other external agent, you know, provide heuristics, something like that. McCarthy wanted one of these problem-solving advice takers to be able to learn how to become good at a new domain, such as playing chess, let's say, by, you know, asking questions when it got stuck, getting advice from an entity that's more skilled than it was, with the idea that they can improve over time from its experience. Now, of course, today we have programs that play Go and chess and board games like that extremely well. And there's been a lot of work on reinforcement learning, and there's the work on alpha zero and so forth. However, if you think about the staggering amount of computation required to create, you know, superhuman play with one of those systems, I think that's not at all in the spirit of what McCarthy had in mind. McCarthy, I think, was talking about how humans learn and the idea that for humans learning how to play chess, someone more experienced can sit there and watch and give pithy advice. And a beginner can learn in real time with relatively limited communication and bandwidth and without, you know, playing against themselves 100 billion times or whatever happens with these reinforcement learning systems. There's a sort of relatively small amount of computation in some sense. Now, I'm not saying that the brain isn't very complicated and doesn't do all sorts of things we don't understand. I'm not saying the brain isn't capable of lots of computation, but in terms of symbolic manipulation and things like that, we know our brains are relatively limited. So certainly human beginner doesn't learn how to play chess the same way that alpha zero would. And the human learning some skill with an expert setting next to them to guide them learns in a different way. And that's really what McCarthy is talking about. And so that's what Nata and I are interested in exploring. You know, could we, now computers or millions of times more capable, try to take another crack at building one of these systems. Now, another person who was very interested in building this sort of system was John Doyle. And so John Doyle was studying at MIT in the late 70s. And he was working with Jerry Sussman. And, you know, this was an era where he had Marvin Minsky and Sussman and this very strong AI lab that was, you know, interested in things like, you know, scheme programming, the scheme programming language, you know, came out of this environment. And also symbolic representation, how do you represent information? And also things like metacircular interpreters. So here's an area where you're seeing a combination of programming languages and ideas about programming languages and interpreters and metacircular interpreters, but also connected to symbolic artificial intelligence. And it doesn't actually have to be symbolic. You could have neural networks helping out, you could have machine learning or reinforcement learning, things like that, that interact with the symbolic systems. But there is some notion of a symbolic system inside of, of what we're talking about here with Doyle and McCarthy. Whether that be functional programming based or imperative programming based or logic programming based, there's still some sort of symbolic information and some notion of explainability, which turns out to be important in these ideas. In case Doyle was interested in this idea of a self conscious, metacircular interpreter. So the idea that you could have a problem solver, you could, you know, sort of take a crack at building McCarthy's advice taker, if you had a metacircular interpreter that was augmented with information about the programming language, it can interpret and its own code and so forth, and could reason about that. So, and also part of this is that, you know, the system has to be able to control itself and try to deal with this exponentially growing search base that comes up over and over again, when you're doing reasoning. So MacArthur, sorry, Doyle proposes a whole bunch of interesting ideas. And this is linked to a bunch of work that was going on at MIT lab at that time by, you know, people like Guy Steele and Drew McDermott and so forth, in addition to Minsky and Sussman and so forth, you know, a whole bunch of other people. I won't get into all of them, but I definitely recommend reading these AI memos from that time period and things like the Amor interpreter. Lots of very interesting papers back then. And McCarthy, sorry, Doyle talks about, you know, the language you might have and it gives examples of reasoning and compilation efficiency turns out to be a major idea. Once again, I think if you read this thesis proposal, which is from around 1979, 1980, it's important to keep in mind the intention and where Doyle was trying to go instead of, you know, overly criticizing specific examples that maybe aren't very exciting today. Okay, so I think it's important to keep in mind what he was trying to accomplish. And he wrote a PhD thesis, you know, on related ideas, a model for deliberation action and introspection, which was published as a AI tech report number 581. So those are really interesting ideas to me. Doyle also talked about what he called a truth maintenance system, which later probably should be called a belief maintenance system. But he proposed this architecture, which I think was largely inspired by work by Sussman and other people, but more formalized in a particular architecture, this truth maintenance systems or TMSs. And this paper, this AI memo 521 is full of interesting ideas, including things like arguing truth maintenance systems that could, you know, argue in front of other truth maintenance systems, and other truth maintenance systems observing the arguments between two TMSs could update their own beliefs. So these, these were systems that could update their own beliefs over time. And there are all sorts of interesting work here, including default logics and things like that. And, and one of the things that came out of the work on TMSs was this book, Building Problem Solvers, by Ken Forbes and Johan DeClerre. And this is basically a book on AI patterns and how they can be AI programming patterns and how they can be applied to various problems. But it talks about things like the different types of truth maintenance systems. An early piece of work that's related is, you know, Jerry Sussman's a computational model skill acquisition where he tries to understand how a program could learn some complex domain like a human could. And, and so this was really foundational to a lot of the work that came later by people like Doyle. So this was also very interesting. This is describing his hacker system. So the hacker system, and you can, I think if you look at the hacker system, you can see something like a TMS inside of it. But this hacker system could learn basically how to program or learn how to debug programs and things like that. And so this was an early attempt to, you know, try to deal with problem solving domain having to do with software development or programming. That was similar in some sense to McCarthy's advice taker, although as far as I know, there wasn't this notion of, of interaction in the same way that McCarthy had talked about. So you could see something like the TMS is coming out of this hacker approach. Another piece of work that came out of the MIT AI lab around that time was this notion of a Lisp programmers apprentice by Charles Rich and Howie Shrobe. And there was actually a book that was published by ACM Press on the programmers apprentice project which ran for, for quite a while at MIT. And the idea was to build a system that could learn the needs of a software engineer over time. And this, this was an extremely ambitious project at the time when it started in the 70s, included things like natural language processing and voice recognition and, and so forth. And different types of program synthesis at the architectural level, not just at the synthesis at the level of individual functions. So that was also, you know, an interesting set of ideas that that were going around. Okay, so the last set of ideas I'll talk about that I think are in this vein, we're from Doug Lennett, who worked on several important programs. And one was called AM. This is like an automated mathematician. And there was another one called Eurisco. And here's Eurisco, a plan, a program that learns new heuristics and domain concepts. And this is part three of that series. And you can find these papers, the nature of heuristics, so this heuristic based theory formation. Okay, so here's number two. And, you know, as followed up by this paper, why AM and Eurisco appear to work. And this is also a very interesting line of reasoning. And so you have this idea of heuristic guided systems, systems that can invent their own heuristics, and so forth. And you can see that all of these systems, along with the work by, say, you know, Minsky on Society of Mine, are similar in that they go to a certain notion of intelligence, which is the ability to get unstuck, the ability to either ask for help, or to recognize when a system is stuck, or to be able to use heuristics to get unstuck, or even to use meta heuristics to develop new heuristics to get stuck, or to use meta meta heuristics to develop meta heuristics to develop meta meta, you know, develop heuristics to get unstuck, that sort of thing. So, you know, that that is, I think, core at understanding all of this work, you know, the notion of intelligence, which has to do with getting unstuck. Now, I could talk a lot more about these ideas, but I would like to change gears into what Nada and I have been exploring. And, you know, so we've decided, we want to try to understand why something like AdviceTaker doesn't seem to exist today, at least to our knowledge. There have been projects, there are projects like the SOAR project, that's OAR, and other projects have been running a long time for, you know, symbolic AI type things. But as far as I know, there isn't anything I think that McCarthy would recognize as his AdviceTaker. And so, the question we have is, why is that? Is it because the basic idea is fundamentally flawed? Is it because the idea is not well defined enough, and you couldn't tell if it had been built or not? Is it because that there's some fundamental limitation, like there's some notion of self-introspection or self-consciousness that we can't describe or runs into the halting problem or something like that? Or is it just because, you know, people have abandoned that idea? You know, it's been, let's see, 60 years, plus since that paper was proposed, computers are millions of times faster, you know, in terms of memory usage and so forth. Our memory availability, and there's been lots of progress in algorithms and programming languages and solvers and large language models and so forth. So, maybe it's possible today to try to build something like AdviceTaker, or at least if it's not, to try to understand maybe why that's not possible. Now, of course, it could be that the reason AdviceTaker hasn't been built is that it would take, you know, maybe a thousand people, you know, 20 years to build it. So, that might be possible. Or it may be that, you know, something could be built today using off-the-shelf components or the solvers we have and things like that. Combining those things that already exist in the creative way, maybe that would be possible for a small number of people to make a lot of progress. So, we're not sure. So, we want to explore, and we want to explore by trying to build things and figuring out what we find hard, what we find easy, and with nothing else, you know, no other objective, at least we hope that by exploring this space, we will encounter interesting things we want to explore more, even if we can't build something like AdviceTaker. Now, the line of research that I'm starting from has to do with this language called mini-canron that I've been working on with many people, including Nada and Dan Friedman, Oleg Kostrov, Michael Ballantyne, Rick Rosenblatt, many, many others. I can't name everyone. But a whole bunch of people have worked on this language, going back to Dan Friedman's original implementation of it. And this is a mini-canron has basically turned into a constraint logic language, a pure constraint logic language, for doing things like writing interpreters, type inferences, parsers, as pure relations. And that allows you to do types of program synthesis. So, one of the things that came out of that was this paper, Unified Approach to Solving Seven Programming Problems, where we show how by writing an interpreter for a subset of scheme as a pure relation, and then combining that with constraint solving and a special type of search, Oleg Kostrov came up with, it's possible to solve various program synthesis problems in a unified way. And another thing that came out of this is a barlerman, this barlerman tool. And so with barlerman, we can do little synthesis problems. So, for example, here I want to maybe define append in scheme. So, I can say append of the empty list to the empty list is the empty list. All right, so I'm giving you an example. And then the system is going to try to fill in basically a template where comma a, comma b, and comma c are holes or logic variables with no value associated with them, representing holes. And then, in this case, the, this is the constant function that always returns the empty list has been synthesized, which is correct, but not very interesting. So, we can try, say, what happens if we append the list cat to list dog, we should get back the list cat dog. And now, barlerman has to do a little more work and tries to come up with something a little more complicated, but it still is missing the recursion. So, we can try doing one more call. So, let's do how about ABC to DE to get ABCDE. And hopefully, barlerman will be able to synthesize the recursion. In any case, you can see that we're doing a type of example directed synthesis. And, you know, under the hood, barlerman uses constraint solving, unification, things like that, also has type constraints with numbers and, and symbols, and does a, a type of complete interleaving search. And sometimes barlerman gets stuck. You know, so barlerman is not an example of smart software, we're in, in the McCarthy notion. Barlerman will often get stuck. However, in certain cases, at least when there's enough context filled in, barlerman can be relatively fast. So, right now, it's taking barlerman a while. So, let's just fill in a little more of the template here. So, I'll, I'll say that we're defying a function called a pen, which takes two arguments, call them L and S, see if this speeds it up any. And, you know, a human can look at these examples and figure out things like the name of the function should be append. A human could also look at the fact that all three of these examples include two arguments. Now, in this case, they're both lists, although append in general and scheme, the second argument doesn't have to be a list, but that might help. Another thing we can give is a help, it's help if we want to is, you know, we might say, hey, because this appears to be a recursive function, we maybe can give it a barlerman a little more help like that and say that, well, since we have a list in the first position, we're going to guess that we're going to check if the list is empty. Otherwise, we're going to do one of two recursive calls. So, that might help. Might need more help. How much help does it need? Let's see. Okay. So, in this case, it figured it out. I think the fact that I'm recording a video right now is slowing down the the processor enough that we're using enough memory that the barlomens having a little more trouble than usual. There are some tricks we can use to give barlerman hints. But you could see part of it was I was able to fill out some of the structure. So, I could guess, you know, even a beginning scheme programmer, we would teach certain heuristics to. So, for example, all right, given these examples, well, we know we're defining a function called append, we can guess at least that the function takes two arguments. It might take more than two arguments, or it might take a variable number of arguments. You know, so maybe it takes zero or more arguments. In fact, the full scheme append can take any number of lists. In this case, we could do a two argument synthesis. And if we guess that append should be recursive because we have lists of different lengths, then if we also guess that we're recurring on the first argument, then we can probably figure out a lot of the structure of the program automatically. And then we might also be able to figure out things like, well, maybe we don't know what the base case is. And so, in this case, it's still still can synthesize the program, even not knowing what the base case is. So, we could, you know, create a little bit of a skeleton of a program, just from looking at these examples and following a few heuristics. And then Barleman, even though it's dealing with this exponential search, could get enough of a hint that it can finish synthesizing the rest of the program. Okay, so that's an example of how Barleman, which isn't very smart, could be called from a smarter program that can do introspection on the examples. And the smarter program could then provide a template or skeleton or sketch of the program to be synthesized based on what it observes from things like the tests or some sort of specification provided maybe by human or by another computer program. So, this idea of using Barleman basically as an external solver is part of what we're trying to explore as well. I should also mention that the software that we're developing might also benefit from some of the ideas in Chris Hansen and Jerry Sussman's software designed for flexibility. And this book is, in some ways, the intellectual successor to structure an interpretation of computer programs by Abelson and Sussman, but can also be thought of as lessons taken from artificial intelligence programming out of MIT and in the corporate world as well, distilled so you can use them in various other software projects. And Jerry Sussman gave a nice talk in 2022 at the Scheme Workshop, which is available on YouTube, where he talks about one of these patterns, which is called layering, where you can add things like meta information you want to keep track to in an intelligent piece of software through this layering technique. So, that's worth looking at. Okay, so let's look at BAT, which is the Barleman advice taker. Now, BAT itself, even though if we ever release it, we're probably going to release it under an MIT license. This BAT project, the Barleman advice taker that Nada and I are working on, has not yet been released, and we're not sure if or when we will release it. Right now, it's in very early stages, and we're just exploring some of the ideas that I've been talking about. And I'll walk you through some of the code and some of the examples to see where we're trying to go. But it is the case that we're still very early in the development of the software, and it's quite messy. A number of the files here need to be removed or cleaned up. We need to have documentation and more tests and things like that. And so, it'll just be a while before we'd be in a position where we want to release it, and we'd also want it to be more capable. But the other part, the other reason, at least I'm hesitant to release it right now, is that the ideas and the papers that I've been showing, those ideas have existed for a long time, and anyone who's smart and creative and thinks hard about those ideas and is inspired by them, could use their own approach to try to build something like AdviceTaker or build something like what Doyle was envisioning with a metacircular reflexive interpreter. And so, the fact that we're building something that uses scheme, shea scheme, mini-canron, barlerman, you know, scheme interpreter written as a relation and mini-canron and all those sorts of things, that doesn't mean that that's the only way to approach what McCarthy was thinking of or Doyle was thinking of. That doesn't mean that we're on the right track at all. In fact, we could be totally on the wrong track. So, I'm a little hesitant to release what we have just because, you know, people might just decide that they want to play around with this and use it, and that this is a starting point for exploration rather than looking at the problem you know, fresh and reading those papers and just thinking really hard and then using the techniques that maybe you're familiar with. So, you know, it may be just better for people who are interested in this area to work independently a little bit and then we could exchange notes or things like that, maybe hold a workshop or something to talk about ideas. Whereas, you know, just sharing code may actually not be beneficial. And so, anyway, if you have thoughts on that, let me know. I think it is a little double edge to share this code right now, given that I don't think we really understand the special sauce that be required yet. And so, if you start from this code, you may be heading down the wrong path. Okay. So, I am going to load bat and chase game. All right. Okay, so that seemed to be running some tests. Okay, you can see it's applying heuristics and it's calling barlament and things like that. Okay, so let's just look at this bat software a little bit. And maybe talk about the organization of the software. So, the current version of that. So, bat stands for barlament advice taker. So, the idea, the original idea was that we were going to build an advice taker program that was oriented around barlament, which was the program I just showed you. Now, barlament is not very smart. Okay, it's not capable of recognizing when it's stuck. It doesn't know anything about its resource utilization. It can't ask for help. It can't explain its own internal state. So, you could think of barlament in a sense as a opaque solver that might be called by an introspective system. Other solvers that might be called from an introspective system would be things like SAT solvers or SMT solvers, maybe something like Z3, or maybe a solver written using answer set programming, or maybe something neural based, reinforcement learning based, statistics based, as long as the answer, you know, could be verified in the end or the system could reason about its confidence in the answer. So, you have this idea of a solver, something that's fast, but not introspective, that can be called from the advice taking program. So, bat is the advice taking program, and barlament is one solver that it could use, and over time we may add additional solvers. McCarthy also had the idea of a problem domain because advice taker is supposed to be a problem solver with common sense. That means that you're trying to solve problems in some domain, whether that being playing a good game of chess or trying to write a program or whatever, there has to be some problem domain or maybe an advice taker could handle multiple problem domains. Even all the way back to McCarthy in 1959, McCarthy was looking at generating programs as a problem domain. John Doyle also looked at this domain. In fact, many of the people in this area of AI, you'll see, looking at those papers I showed you, they look at programming, reasoning about programs, generating programs, fixing or repairing programs as a problem domain. And I think that's natural for two reasons. One is anyone who's exploring these areas probably is a pretty good programmer or at least has had to go through the process of learning how to program and knows either how to teach programming or how to learn about programming has gone through that experience. And also, the other reason is that because the advice taker itself is a program, in this case, bat is written in Scheme and mini-canon, if you could build a system that can reason about software and that generate software, repair software, then there's at least the potential of applying the advice taker to itself and therefore having the system improve itself. And so I think this is at the heart of Doyle's idea of this introspective, you know, or reflexive, meta-circular interpreter is that the interpreter for some problem-solving domain could understand its own code, at least to some extent, have access to its own code, maybe know semantics of its own code. So you can imagine maybe a problem-solving interpreter that had access to its own operational semantics for its own interpreter or denotational semantics or axiomatic semantics, things like that. Formal representations of itself or that could do abstract interpretation of programs that can interpret things like that. So that would be an example of an interpreter that had access to some smarts about its own behavior or capabilities. In addition, you could also have the system have access to information about the hardware it's running on, how much memory it has available, the processors, things like that. And furthermore, you could have this information organized in a way, along with other information about the problem domain. So if the problem domain is about chess, maybe their concepts related to playing chess. And one way to organize this information is in an ontology, which is often represented as a tree or a graph or a forest, often trees or forests of information. So hierarchical information, you can think of this often as sort of an object-oriented type thing where you have parent-child relationships. And so you can represent all sorts of information, including heuristics and meta heuristics in an ontology. So in BAT, we have this idea of an ontology. So we have concepts. And you can see here we have a syntax rules macro. And we have instances of concepts. So we have a concept in fields. And so we have a notion of an instance and the types of instance and so forth. And so here are a bunch of helpers. And because we want to be reflective or as meta-circular as possible, the notion of a concept is itself a concept. The notion of an ontology is also a concept or an instance is also a concept. So this is a little small talky in a way, if you want to think of it that way. We also have the notion of a solver. So we have various types of solvers. And we have the notion of history and the delta or change between two different states and things like that. So we have a whole bunch of different concepts here. If I go down here and look at, so initially we had an empty list of concepts. If I have the system list, the concepts that currently knows about, you can see that there is information about things like tail position, or I shouldn't say information, but concepts like things like tail position, which is a grammatical property of software. And also there are concepts like advice or the fact that there's a user or BAT itself. So BAT has a concept referring to itself and also has explicit notions of history using a Blackboard architecture, which I won't get into what a Blackboard architecture is, but that was a traditional style 1980s AI system approach where you could write different things to memory and that would trigger certain types of actions. But also notions of resources and things like for the arity of a function, whether or not the function is variadic and take any number of arguments, or maybe it's fixed, fixed arity, and we know exactly how many arguments, or maybe it's fixed arity with at least a certain number of arguments, but we don't know what those are and things like that. And so the notion of arity itself, the notion of a program template or a sketch, the notion of variables and expressions. So we're getting into things like, you know, notions of the programming language that are represented, and the notion of a synthesis problem or a synthesis solution. You know, all of these sorts of things, including heuristics and meta heuristics, are important to be able to represent in the system. So those are ideas or concepts represented in an ontology. And the important part, the most important part is that the system can represent things about itself. It has a representation of itself as representation of a user or a conversation, those sorts of things. In addition to an ontology, there's also a notion of communication between the advice taker and a user or an external entity. So currently, we have sort of a high level sketch of how we might imagine a conversation. We don't have a working implementation yet. But you can see some examples of what the conversation with BAT may be. If BAT gets stuck, you know, trying to synthesize something like factorial, there may be a suggestion to try to do something like use an accumulator. And so synthesize an accumulator called factorial AC. And then, you know, there may be a sketch there that the system is able to come up with. And then you can imagine this sort of conversation going backwards and forwards between some entity and external entity in BAT itself. So, you know, at this point, we're still trying to figure out how we would represent that communication. In McCarthy's advice taker paper, he talks about sort of a stylized language that could be used. And we're definitely figuring that one out. We also have the notion of an erity. So that was sort of the first thing we wanted to do, similar to when I tried to, for Barleman, figure out what the erity is for the append function. That turns out to speed up the Barleman synthesis quite a lot, usually. So you can see that we have, in this case, the notion of trying to append, to synthesize append. And we have heuristics that have to do with erity. So here, we have a notion of guessing erity. And then, we have various helpers to try to help, you know, help us with this notion of guessing the erity of a function. But you can see here is a heuristic, you know, fine erity sketch from input output examples. And so here you can see we have an instance in our, our ontology. So we have a heuristic in the name of the heuristic and when it's applicable and how do you apply it and so forth. There also is a heuristic having to do with Barleman itself. So, you know, there is a Barleman heuristic. So you can actually see that, you know, if, if it's possible to invoke Barleman, that is a heuristic that's available to the Barleman advice taker. So that's one of the heuristics. And, and we have code here to transform problems into something that Barleman can handle. So, let's see what else. Engines are something that we're not currently using, but that's a way to deal with timeouts. Let's see, we have append examples here. So we have input output examples. So these are, you know, similar to what I was showing with Barleman. And then we have more sophisticated examples where we might have notions of logic variables or holes, even in the input output examples themselves, and so forth. And you can see that there are different types of sketches that might be guessed. And in fact, we can also do things like, you know, have, have the system, if the system guesses that the base case is not recursive, we can use a minicanrin absento constraint saying that the name append can't appear in the body of the base case, if we think that there's a base case. And, and also there's no Lebrecht, no recursive definitions in the base case. So we can use some of the constraints in minicanrin and Barleman to enforce certain notions like the idea that we have a base case. And, you know, we can imagine sort of the internal state of Barleman, how it would work through different aspects of this program as it's trying to interpret it. And part of the idea is to be able to simulate what a student learning how to program in a language like scheme might think. And so there, there are heuristics that we teach to beginning pre scheme programmers, like if Dan Friedman always teaches, if you write a recursive function and there's no question asked about a certain argument, like is it null or a pair, then that argument will be passed in any recursions without being changed. So that would be an example of a heuristic that we could add to that. Let's see. We also have information like, you know, tail recursion, which we're still working on. But we have some heuristics with tail recursion that we're working on as well. And then we have some code that can take one of our templates and turn it into a mini can run example that Barleman can handle. And we've also, we also have been exploring notions of types that we can, that we might find useful in the future. And I think, yeah, yeah, so we also have some notes and, and motivating examples that we care about. And so high level questions that we have are, what are the sorts of things that we want to, to have a system like that be able to reason about explicitly, and what information needs or what concepts have to go in the ontology, like what does that need to know about itself, what does that need to know about potential resource usage, how is that going to communicate with external entities concisely and represent concisely its own internal state, and also know when it's stuck or recognize when it's stuck and ask for heuristics or meta heuristics and have that conversation. So those are things that we're, we're thinking about. If you find this interesting and you'd like to talk to us, you know, please drop me an email. And maybe we can do a call. And I also encourage you to try hacking on something like, like advice taker yourself, I think it's a very interesting set of problems. And a minimum, I think it's worth reading these papers and trying to understand where a lot of these, you know, 1980s, late 70s systems were headed towards. And, you know, it was worth rethinking in modern day, whether or not we could take another shot at it. And if you also think that, well, everything now is neural, or machine learning, you just remember that neural networks had multiple times where they were in vogue and then went out of vogue and so forth. So, you know, maybe time that symbolic systems or at least neuro symbolic combinations of systems are revisited in the spirit of things like advice taker and McCarthy and Doyle and Minsky and Sussman and so forth. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 16.240000000000002, "text": " Hi, I'm Wilberd. This talk is on self-conscious reflexive interpreters, and is joint work", "tokens": [50364, 2421, 11, 286, 478, 9483, 607, 67, 13, 639, 751, 307, 322, 2698, 12, 19877, 23802, 488, 17489, 1559, 11, 293, 307, 7225, 589, 51176], "temperature": 0.0, "avg_logprob": -0.2364896774291992, "compression_ratio": 1.1933333333333334, "no_speech_prob": 0.018825078383088112}, {"id": 1, "seek": 0, "start": 16.240000000000002, "end": 25.48, "text": " with Nada Amin. The talk is largely inspired by John Doyle's 1978 MIT PhD thesis proposal", "tokens": [51176, 365, 40992, 2012, 259, 13, 440, 751, 307, 11611, 7547, 538, 2619, 40059, 306, 311, 33191, 13100, 14476, 22288, 11494, 51638], "temperature": 0.0, "avg_logprob": -0.2364896774291992, "compression_ratio": 1.1933333333333334, "no_speech_prob": 0.018825078383088112}, {"id": 2, "seek": 2548, "start": 25.48, "end": 31.12, "text": " entitled Reflexive Interpreters, but also incorporates ideas from John McCarthy, Marvin", "tokens": [50364, 17838, 16957, 2021, 488, 5751, 3712, 1559, 11, 457, 611, 50193, 3487, 490, 2619, 44085, 11, 48722, 50646], "temperature": 0.0, "avg_logprob": -0.14748392385594986, "compression_ratio": 1.382198952879581, "no_speech_prob": 0.03512419015169144}, {"id": 3, "seek": 2548, "start": 31.12, "end": 38.4, "text": " Minsky, and Doug Lenit. It's very much work in progress. I hope you'll bear that in mind", "tokens": [50646, 376, 44153, 11, 293, 12742, 23009, 270, 13, 467, 311, 588, 709, 589, 294, 4205, 13, 286, 1454, 291, 603, 6155, 300, 294, 1575, 51010], "temperature": 0.0, "avg_logprob": -0.14748392385594986, "compression_ratio": 1.382198952879581, "no_speech_prob": 0.03512419015169144}, {"id": 4, "seek": 2548, "start": 38.4, "end": 47.28, "text": " as you listen to the talk. However, we're hoping that ideas in this talk will encourage", "tokens": [51010, 382, 291, 2140, 281, 264, 751, 13, 2908, 11, 321, 434, 7159, 300, 3487, 294, 341, 751, 486, 5373, 51454], "temperature": 0.0, "avg_logprob": -0.14748392385594986, "compression_ratio": 1.382198952879581, "no_speech_prob": 0.03512419015169144}, {"id": 5, "seek": 4728, "start": 47.28, "end": 56.2, "text": " you to explore some of the space and ideas of reflexive or self-conscious interpreters,", "tokens": [50364, 291, 281, 6839, 512, 295, 264, 1901, 293, 3487, 295, 23802, 488, 420, 2698, 12, 19877, 17489, 1559, 11, 50810], "temperature": 0.0, "avg_logprob": -0.19574669003486633, "compression_ratio": 1.38860103626943, "no_speech_prob": 0.004903262481093407}, {"id": 6, "seek": 4728, "start": 56.2, "end": 67.52000000000001, "text": " which both Nada and I find very intriguing and inspiring. So, in 1959, John McCarthy,", "tokens": [50810, 597, 1293, 40992, 293, 286, 915, 588, 32503, 293, 15883, 13, 407, 11, 294, 45608, 11, 2619, 44085, 11, 51376], "temperature": 0.0, "avg_logprob": -0.19574669003486633, "compression_ratio": 1.38860103626943, "no_speech_prob": 0.004903262481093407}, {"id": 7, "seek": 4728, "start": 67.52000000000001, "end": 75.12, "text": " who is known for many things, including being the originator of the list programming language,", "tokens": [51376, 567, 307, 2570, 337, 867, 721, 11, 3009, 885, 264, 4957, 1639, 295, 264, 1329, 9410, 2856, 11, 51756], "temperature": 0.0, "avg_logprob": -0.19574669003486633, "compression_ratio": 1.38860103626943, "no_speech_prob": 0.004903262481093407}, {"id": 8, "seek": 7512, "start": 75.12, "end": 80.08, "text": " wrote a paper called Programs with Common Sense. This is one of the early papers in", "tokens": [50364, 4114, 257, 3035, 1219, 44762, 365, 18235, 33123, 13, 639, 307, 472, 295, 264, 2440, 10577, 294, 50612], "temperature": 0.0, "avg_logprob": -0.2175107683454241, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.016905134543776512}, {"id": 9, "seek": 7512, "start": 80.08, "end": 86.56, "text": " our symbolic artificial intelligence, or artificial intelligence in general, and he proposes this", "tokens": [50612, 527, 25755, 11677, 7599, 11, 420, 11677, 7599, 294, 2674, 11, 293, 415, 2365, 4201, 341, 50936], "temperature": 0.0, "avg_logprob": -0.2175107683454241, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.016905134543776512}, {"id": 10, "seek": 7512, "start": 86.56, "end": 97.68, "text": " idea of writing a problem solver that can learn from its experience and also accept advice", "tokens": [50936, 1558, 295, 3579, 257, 1154, 1404, 331, 300, 393, 1466, 490, 1080, 1752, 293, 611, 3241, 5192, 51492], "temperature": 0.0, "avg_logprob": -0.2175107683454241, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.016905134543776512}, {"id": 11, "seek": 7512, "start": 97.68, "end": 104.76, "text": " from an external entity and communicate with an external entity. So, he calls this software", "tokens": [51492, 490, 364, 8320, 13977, 293, 7890, 365, 364, 8320, 13977, 13, 407, 11, 415, 5498, 341, 4722, 51846], "temperature": 0.0, "avg_logprob": -0.2175107683454241, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.016905134543776512}, {"id": 12, "seek": 10476, "start": 105.4, "end": 111.08000000000001, "text": " an advice taker, or the advice taker. So, when I talk about advice taker, I'm talking about the", "tokens": [50396, 364, 5192, 991, 260, 11, 420, 264, 5192, 991, 260, 13, 407, 11, 562, 286, 751, 466, 5192, 991, 260, 11, 286, 478, 1417, 466, 264, 50680], "temperature": 0.0, "avg_logprob": -0.1622742244175502, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.0020502896513789892}, {"id": 13, "seek": 10476, "start": 111.08000000000001, "end": 117.48, "text": " software he envisions in this 1959 paper, Programs with Common Sense. And in particular,", "tokens": [50680, 4722, 415, 2267, 4252, 294, 341, 45608, 3035, 11, 44762, 365, 18235, 33123, 13, 400, 294, 1729, 11, 51000], "temperature": 0.0, "avg_logprob": -0.1622742244175502, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.0020502896513789892}, {"id": 14, "seek": 10476, "start": 118.36, "end": 125.08000000000001, "text": " his notion of common sense is far beyond what you see in almost any piece of software today,", "tokens": [51044, 702, 10710, 295, 2689, 2020, 307, 1400, 4399, 437, 291, 536, 294, 1920, 604, 2522, 295, 4722, 965, 11, 51380], "temperature": 0.0, "avg_logprob": -0.1622742244175502, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.0020502896513789892}, {"id": 15, "seek": 10476, "start": 125.96000000000001, "end": 133.16, "text": " maybe with large language models very recently, you could argue that there's some common sense,", "tokens": [51424, 1310, 365, 2416, 2856, 5245, 588, 3938, 11, 291, 727, 9695, 300, 456, 311, 512, 2689, 2020, 11, 51784], "temperature": 0.0, "avg_logprob": -0.1622742244175502, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.0020502896513789892}, {"id": 16, "seek": 13316, "start": 133.16, "end": 140.35999999999999, "text": " even that's, I think, highly debatable. However, interacting with a compiler, or a text editor,", "tokens": [50364, 754, 300, 311, 11, 286, 519, 11, 5405, 3001, 31415, 13, 2908, 11, 18017, 365, 257, 31958, 11, 420, 257, 2487, 9839, 11, 50724], "temperature": 0.0, "avg_logprob": -0.11706928525652205, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.00033528052153997123}, {"id": 17, "seek": 13316, "start": 141.0, "end": 149.4, "text": " or word processor, or things like that, I think there's really no common sense in those programs,", "tokens": [50756, 420, 1349, 15321, 11, 420, 721, 411, 300, 11, 286, 519, 456, 311, 534, 572, 2689, 2020, 294, 729, 4268, 11, 51176], "temperature": 0.0, "avg_logprob": -0.11706928525652205, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.00033528052153997123}, {"id": 18, "seek": 13316, "start": 149.4, "end": 160.68, "text": " even many decades after this original proposal. McCarthy describes this notion of a advice taker,", "tokens": [51176, 754, 867, 7878, 934, 341, 3380, 11494, 13, 44085, 15626, 341, 10710, 295, 257, 5192, 991, 260, 11, 51740], "temperature": 0.0, "avg_logprob": -0.11706928525652205, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.00033528052153997123}, {"id": 19, "seek": 16068, "start": 161.48000000000002, "end": 169.48000000000002, "text": " and he proposes features of the advice taker that he thinks would be critical for building something.", "tokens": [50404, 293, 415, 2365, 4201, 4122, 295, 264, 5192, 991, 260, 300, 415, 7309, 576, 312, 4924, 337, 2390, 746, 13, 50804], "temperature": 0.0, "avg_logprob": -0.08657931118476682, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0005882492987439036}, {"id": 20, "seek": 16068, "start": 171.16, "end": 176.04000000000002, "text": " So, for example, all the behaviors of the system have to be representable", "tokens": [50888, 407, 11, 337, 1365, 11, 439, 264, 15501, 295, 264, 1185, 362, 281, 312, 2906, 712, 51132], "temperature": 0.0, "avg_logprob": -0.08657931118476682, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0005882492987439036}, {"id": 21, "seek": 16068, "start": 176.04000000000002, "end": 180.92000000000002, "text": " in the system itself. So, this is a system that to some extent understands its own", "tokens": [51132, 294, 264, 1185, 2564, 13, 407, 11, 341, 307, 257, 1185, 300, 281, 512, 8396, 15146, 1080, 1065, 51376], "temperature": 0.0, "avg_logprob": -0.08657931118476682, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0005882492987439036}, {"id": 22, "seek": 16068, "start": 180.92000000000002, "end": 189.56, "text": " capabilities and behaviors. And also, the system has to be extensible in a simple way.", "tokens": [51376, 10862, 293, 15501, 13, 400, 611, 11, 264, 1185, 575, 281, 312, 1279, 30633, 294, 257, 2199, 636, 13, 51808], "temperature": 0.0, "avg_logprob": -0.08657931118476682, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0005882492987439036}, {"id": 23, "seek": 19068, "start": 191.24, "end": 197.56, "text": " And the system has to be able to improve its behavior.", "tokens": [50392, 400, 264, 1185, 575, 281, 312, 1075, 281, 3470, 1080, 5223, 13, 50708], "temperature": 0.0, "avg_logprob": -0.10374880704012784, "compression_ratio": 1.5089820359281436, "no_speech_prob": 7.253944204421714e-05}, {"id": 24, "seek": 19068, "start": 199.48000000000002, "end": 208.04000000000002, "text": " And there are other features of this program that McCarthy considers important. And then in the paper,", "tokens": [50804, 400, 456, 366, 661, 4122, 295, 341, 1461, 300, 44085, 33095, 1021, 13, 400, 550, 294, 264, 3035, 11, 51232], "temperature": 0.0, "avg_logprob": -0.10374880704012784, "compression_ratio": 1.5089820359281436, "no_speech_prob": 7.253944204421714e-05}, {"id": 25, "seek": 19068, "start": 208.04000000000002, "end": 215.24, "text": " he talks about different ways you could describe such a system using imperative or declarative", "tokens": [51232, 415, 6686, 466, 819, 2098, 291, 727, 6786, 1270, 257, 1185, 1228, 32490, 420, 16694, 1166, 51592], "temperature": 0.0, "avg_logprob": -0.10374880704012784, "compression_ratio": 1.5089820359281436, "no_speech_prob": 7.253944204421714e-05}, {"id": 26, "seek": 21524, "start": 216.04000000000002, "end": 221.32000000000002, "text": " sentences or language. And he also talks about how you might go about constructing", "tokens": [50404, 16579, 420, 2856, 13, 400, 415, 611, 6686, 466, 577, 291, 1062, 352, 466, 39969, 50668], "temperature": 0.0, "avg_logprob": -0.05036438897598621, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.00014883496623951942}, {"id": 27, "seek": 21524, "start": 221.32000000000002, "end": 227.64000000000001, "text": " an advice taker. It's important to understand that in 1959, John McCarthy hadn't attempted to", "tokens": [50668, 364, 5192, 991, 260, 13, 467, 311, 1021, 281, 1223, 300, 294, 45608, 11, 2619, 44085, 8782, 380, 18997, 281, 50984], "temperature": 0.0, "avg_logprob": -0.05036438897598621, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.00014883496623951942}, {"id": 28, "seek": 21524, "start": 227.64000000000001, "end": 234.92000000000002, "text": " create such a system. This is basically a white paper describing how you might go about building", "tokens": [50984, 1884, 1270, 257, 1185, 13, 639, 307, 1936, 257, 2418, 3035, 16141, 577, 291, 1062, 352, 466, 2390, 51348], "temperature": 0.0, "avg_logprob": -0.05036438897598621, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.00014883496623951942}, {"id": 29, "seek": 21524, "start": 234.92000000000002, "end": 241.56, "text": " a system, or what the design might look like, or what the desired features of such a system would be.", "tokens": [51348, 257, 1185, 11, 420, 437, 264, 1715, 1062, 574, 411, 11, 420, 437, 264, 14721, 4122, 295, 1270, 257, 1185, 576, 312, 13, 51680], "temperature": 0.0, "avg_logprob": -0.05036438897598621, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.00014883496623951942}, {"id": 30, "seek": 24156, "start": 242.36, "end": 248.12, "text": " But he certainly hadn't implemented anything like advice taker at this point.", "tokens": [50404, 583, 415, 3297, 8782, 380, 12270, 1340, 411, 5192, 991, 260, 412, 341, 935, 13, 50692], "temperature": 0.0, "avg_logprob": -0.1406461471735045, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.00019109896675217897}, {"id": 31, "seek": 24156, "start": 249.32, "end": 254.28, "text": " And as far as I can tell, no one has succeeded in building something like advice taker today.", "tokens": [50752, 400, 382, 1400, 382, 286, 393, 980, 11, 572, 472, 575, 20263, 294, 2390, 746, 411, 5192, 991, 260, 965, 13, 51000], "temperature": 0.0, "avg_logprob": -0.1406461471735045, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.00019109896675217897}, {"id": 32, "seek": 24156, "start": 256.28000000000003, "end": 261.56, "text": " He talks about the main features, representing expressions in the computer and so forth.", "tokens": [51100, 634, 6686, 466, 264, 2135, 4122, 11, 13460, 15277, 294, 264, 3820, 293, 370, 5220, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1406461471735045, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.00019109896675217897}, {"id": 33, "seek": 24156, "start": 262.36, "end": 268.44, "text": " When you read this paper, it is from 1959. So, it's fairly early on in the history of computing,", "tokens": [51404, 1133, 291, 1401, 341, 3035, 11, 309, 307, 490, 45608, 13, 407, 11, 309, 311, 6457, 2440, 322, 294, 264, 2503, 295, 15866, 11, 51708], "temperature": 0.0, "avg_logprob": -0.1406461471735045, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.00019109896675217897}, {"id": 34, "seek": 26844, "start": 269.4, "end": 278.6, "text": " at least as we see it in 2023. But you can see a kernel of an idea here. So, for example,", "tokens": [50412, 412, 1935, 382, 321, 536, 309, 294, 44377, 13, 583, 291, 393, 536, 257, 28256, 295, 364, 1558, 510, 13, 407, 11, 337, 1365, 11, 50872], "temperature": 0.0, "avg_logprob": -0.10275821685791016, "compression_ratio": 1.6017699115044248, "no_speech_prob": 0.0005702400230802596}, {"id": 35, "seek": 26844, "start": 279.4, "end": 285.72, "text": " he has this notion of an immediate deduction routine. So, if you're familiar with Kahneman's", "tokens": [50912, 415, 575, 341, 10710, 295, 364, 11629, 46385, 9927, 13, 407, 11, 498, 291, 434, 4963, 365, 591, 12140, 15023, 311, 51228], "temperature": 0.0, "avg_logprob": -0.10275821685791016, "compression_ratio": 1.6017699115044248, "no_speech_prob": 0.0005702400230802596}, {"id": 36, "seek": 26844, "start": 285.72, "end": 291.48, "text": " idea of system one and system two thinking, McCarthy in this paper proposes something very", "tokens": [51228, 1558, 295, 1185, 472, 293, 1185, 732, 1953, 11, 44085, 294, 341, 3035, 2365, 4201, 746, 588, 51516], "temperature": 0.0, "avg_logprob": -0.10275821685791016, "compression_ratio": 1.6017699115044248, "no_speech_prob": 0.0005702400230802596}, {"id": 37, "seek": 26844, "start": 291.48, "end": 297.64, "text": " similar where there's fast thinking and slow thinking. You can have slow thinking that's", "tokens": [51516, 2531, 689, 456, 311, 2370, 1953, 293, 2964, 1953, 13, 509, 393, 362, 2964, 1953, 300, 311, 51824], "temperature": 0.0, "avg_logprob": -0.10275821685791016, "compression_ratio": 1.6017699115044248, "no_speech_prob": 0.0005702400230802596}, {"id": 38, "seek": 29764, "start": 297.64, "end": 303.08, "text": " more reflective or introspective. And you can have fast thinking, which is sort of automatic", "tokens": [50364, 544, 28931, 420, 560, 28713, 488, 13, 400, 291, 393, 362, 2370, 1953, 11, 597, 307, 1333, 295, 12509, 50636], "temperature": 0.0, "avg_logprob": -0.10318495637627058, "compression_ratio": 1.6339285714285714, "no_speech_prob": 8.219493611250073e-05}, {"id": 39, "seek": 29764, "start": 303.08, "end": 311.24, "text": " thinking. And so, part of the idea in this paper is that a smart system or common sense system,", "tokens": [50636, 1953, 13, 400, 370, 11, 644, 295, 264, 1558, 294, 341, 3035, 307, 300, 257, 4069, 1185, 420, 2689, 2020, 1185, 11, 51044], "temperature": 0.0, "avg_logprob": -0.10318495637627058, "compression_ratio": 1.6339285714285714, "no_speech_prob": 8.219493611250073e-05}, {"id": 40, "seek": 29764, "start": 311.24, "end": 317.8, "text": " like the advice taker, would have access to what we might now call solvers. For example,", "tokens": [51044, 411, 264, 5192, 991, 260, 11, 576, 362, 2105, 281, 437, 321, 1062, 586, 818, 1404, 840, 13, 1171, 1365, 11, 51372], "temperature": 0.0, "avg_logprob": -0.10318495637627058, "compression_ratio": 1.6339285714285714, "no_speech_prob": 8.219493611250073e-05}, {"id": 41, "seek": 29764, "start": 317.8, "end": 323.08, "text": " SAT solvers, SMT solvers, things like that, or program synthesis tools or whatever, that", "tokens": [51372, 31536, 1404, 840, 11, 13115, 51, 1404, 840, 11, 721, 411, 300, 11, 420, 1461, 30252, 3873, 420, 2035, 11, 300, 51636], "temperature": 0.0, "avg_logprob": -0.10318495637627058, "compression_ratio": 1.6339285714285714, "no_speech_prob": 8.219493611250073e-05}, {"id": 42, "seek": 32308, "start": 323.88, "end": 330.76, "text": " for solving particular problems might be fast, but in some sense at a global level,", "tokens": [50404, 337, 12606, 1729, 2740, 1062, 312, 2370, 11, 457, 294, 512, 2020, 412, 257, 4338, 1496, 11, 50748], "temperature": 0.0, "avg_logprob": -0.07085072805011083, "compression_ratio": 1.5138121546961325, "no_speech_prob": 8.219977462431416e-05}, {"id": 43, "seek": 32308, "start": 330.76, "end": 339.32, "text": " aren't very introspective, not very smart. So, this overall software, which is supposed to", "tokens": [50748, 3212, 380, 588, 560, 28713, 488, 11, 406, 588, 4069, 13, 407, 11, 341, 4787, 4722, 11, 597, 307, 3442, 281, 51176], "temperature": 0.0, "avg_logprob": -0.07085072805011083, "compression_ratio": 1.5138121546961325, "no_speech_prob": 8.219977462431416e-05}, {"id": 44, "seek": 32308, "start": 339.32, "end": 348.2, "text": " display intelligent behavior, would be capable of using these lower level solvers in an intelligent", "tokens": [51176, 4674, 13232, 5223, 11, 576, 312, 8189, 295, 1228, 613, 3126, 1496, 1404, 840, 294, 364, 13232, 51620], "temperature": 0.0, "avg_logprob": -0.07085072805011083, "compression_ratio": 1.5138121546961325, "no_speech_prob": 8.219977462431416e-05}, {"id": 45, "seek": 34820, "start": 348.2, "end": 356.2, "text": " way because the overall system would understand what the different solvers are good for and have", "tokens": [50364, 636, 570, 264, 4787, 1185, 576, 1223, 437, 264, 819, 1404, 840, 366, 665, 337, 293, 362, 50764], "temperature": 0.0, "avg_logprob": -0.10004214023021941, "compression_ratio": 1.668103448275862, "no_speech_prob": 0.0006878250860609114}, {"id": 46, "seek": 34820, "start": 356.2, "end": 363.71999999999997, "text": " some at least, you know, rough notion of how long it takes a solver to run, if it's going to finish", "tokens": [50764, 512, 412, 1935, 11, 291, 458, 11, 5903, 10710, 295, 577, 938, 309, 2516, 257, 1404, 331, 281, 1190, 11, 498, 309, 311, 516, 281, 2413, 51140], "temperature": 0.0, "avg_logprob": -0.10004214023021941, "compression_ratio": 1.668103448275862, "no_speech_prob": 0.0006878250860609114}, {"id": 47, "seek": 34820, "start": 363.71999999999997, "end": 370.59999999999997, "text": " roughly, things like that, what sort of resource usages it might have, and also what resources", "tokens": [51140, 9810, 11, 721, 411, 300, 11, 437, 1333, 295, 7684, 505, 1660, 309, 1062, 362, 11, 293, 611, 437, 3593, 51484], "temperature": 0.0, "avg_logprob": -0.10004214023021941, "compression_ratio": 1.668103448275862, "no_speech_prob": 0.0006878250860609114}, {"id": 48, "seek": 34820, "start": 370.59999999999997, "end": 376.03999999999996, "text": " the overall system, the overall advice taker has available to it. For example, how much memory,", "tokens": [51484, 264, 4787, 1185, 11, 264, 4787, 5192, 991, 260, 575, 2435, 281, 309, 13, 1171, 1365, 11, 577, 709, 4675, 11, 51756], "temperature": 0.0, "avg_logprob": -0.10004214023021941, "compression_ratio": 1.668103448275862, "no_speech_prob": 0.0006878250860609114}, {"id": 49, "seek": 37604, "start": 376.04, "end": 382.44, "text": " how much RAM, how much nowadays flash drive space, you know, how much CPU horsepower,", "tokens": [50364, 577, 709, 14561, 11, 577, 709, 13434, 7319, 3332, 1901, 11, 291, 458, 11, 577, 709, 13199, 25250, 11, 50684], "temperature": 0.0, "avg_logprob": -0.07776593613898618, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.000487829907797277}, {"id": 50, "seek": 37604, "start": 382.44, "end": 387.24, "text": " you know, is it running on a parallel supercomputer, is it running on a pocket calculator, so forth.", "tokens": [50684, 291, 458, 11, 307, 309, 2614, 322, 257, 8952, 36708, 11, 307, 309, 2614, 322, 257, 8963, 24993, 11, 370, 5220, 13, 50924], "temperature": 0.0, "avg_logprob": -0.07776593613898618, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.000487829907797277}, {"id": 51, "seek": 37604, "start": 387.96000000000004, "end": 395.8, "text": " So, the overall advice taker would be built in this kind of layered fashion, where there'd", "tokens": [50960, 407, 11, 264, 4787, 5192, 991, 260, 576, 312, 3094, 294, 341, 733, 295, 34666, 6700, 11, 689, 456, 1116, 51352], "temperature": 0.0, "avg_logprob": -0.07776593613898618, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.000487829907797277}, {"id": 52, "seek": 37604, "start": 395.8, "end": 403.0, "text": " actually be a hierarchy of reasoning tasks and problem solving tasks going all the way down", "tokens": [51352, 767, 312, 257, 22333, 295, 21577, 9608, 293, 1154, 12606, 9608, 516, 439, 264, 636, 760, 51712], "temperature": 0.0, "avg_logprob": -0.07776593613898618, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.000487829907797277}, {"id": 53, "seek": 40300, "start": 403.0, "end": 410.04, "text": " to calling out to these solvers, which probably can't be introspected into. So, in other words,", "tokens": [50364, 281, 5141, 484, 281, 613, 1404, 840, 11, 597, 1391, 393, 380, 312, 560, 28713, 292, 666, 13, 407, 11, 294, 661, 2283, 11, 50716], "temperature": 0.0, "avg_logprob": -0.09272810341655344, "compression_ratio": 1.559782608695652, "no_speech_prob": 0.0004878136969637126}, {"id": 54, "seek": 40300, "start": 410.04, "end": 415.88, "text": " the overall advice taker program can't look into these solvers necessarily to understand exactly", "tokens": [50716, 264, 4787, 5192, 991, 260, 1461, 393, 380, 574, 666, 613, 1404, 840, 4725, 281, 1223, 2293, 51008], "temperature": 0.0, "avg_logprob": -0.09272810341655344, "compression_ratio": 1.559782608695652, "no_speech_prob": 0.0004878136969637126}, {"id": 55, "seek": 40300, "start": 415.88, "end": 422.2, "text": " how they're working, but it has some high level description of how they work or can learn over", "tokens": [51008, 577, 436, 434, 1364, 11, 457, 309, 575, 512, 1090, 1496, 3855, 295, 577, 436, 589, 420, 393, 1466, 670, 51324], "temperature": 0.0, "avg_logprob": -0.09272810341655344, "compression_ratio": 1.559782608695652, "no_speech_prob": 0.0004878136969637126}, {"id": 56, "seek": 42220, "start": 422.2, "end": 432.12, "text": " time through observation how they work. And the paper also presents a language here,", "tokens": [50364, 565, 807, 14816, 577, 436, 589, 13, 400, 264, 3035, 611, 13533, 257, 2856, 510, 11, 50860], "temperature": 0.0, "avg_logprob": -0.09077905473254975, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.003945057280361652}, {"id": 57, "seek": 42220, "start": 432.84, "end": 439.32, "text": " logic based language basically for, you know, describing how a system might reason about", "tokens": [50896, 9952, 2361, 2856, 1936, 337, 11, 291, 458, 11, 16141, 577, 257, 1185, 1062, 1778, 466, 51220], "temperature": 0.0, "avg_logprob": -0.09077905473254975, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.003945057280361652}, {"id": 58, "seek": 42220, "start": 439.32, "end": 446.28, "text": " going to the airport, for example, that kind of thing. Now, I'll say that I find this paper", "tokens": [51220, 516, 281, 264, 10155, 11, 337, 1365, 11, 300, 733, 295, 551, 13, 823, 11, 286, 603, 584, 300, 286, 915, 341, 3035, 51568], "temperature": 0.0, "avg_logprob": -0.09077905473254975, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.003945057280361652}, {"id": 59, "seek": 44628, "start": 446.28, "end": 457.88, "text": " very inspiring. However, when read today, the paper can seem a little goofy or anachronistic,", "tokens": [50364, 588, 15883, 13, 2908, 11, 562, 1401, 965, 11, 264, 3035, 393, 1643, 257, 707, 42995, 420, 364, 608, 2044, 3142, 11, 50944], "temperature": 0.0, "avg_logprob": -0.09697917219880339, "compression_ratio": 1.5240641711229947, "no_speech_prob": 0.012051773257553577}, {"id": 60, "seek": 44628, "start": 457.88, "end": 464.11999999999995, "text": " I guess, something like that, old fashioned. Part of the idea, part of the reason for that,", "tokens": [50944, 286, 2041, 11, 746, 411, 300, 11, 1331, 40646, 13, 4100, 295, 264, 1558, 11, 644, 295, 264, 1778, 337, 300, 11, 51256], "temperature": 0.0, "avg_logprob": -0.09697917219880339, "compression_ratio": 1.5240641711229947, "no_speech_prob": 0.012051773257553577}, {"id": 61, "seek": 44628, "start": 464.11999999999995, "end": 471.71999999999997, "text": " I think, is that this example is not very inspiring. And I don't know where this came from. I don't", "tokens": [51256, 286, 519, 11, 307, 300, 341, 1365, 307, 406, 588, 15883, 13, 400, 286, 500, 380, 458, 689, 341, 1361, 490, 13, 286, 500, 380, 51636], "temperature": 0.0, "avg_logprob": -0.09697917219880339, "compression_ratio": 1.5240641711229947, "no_speech_prob": 0.012051773257553577}, {"id": 62, "seek": 47172, "start": 471.72, "end": 478.52000000000004, "text": " think this is the greatest use of logic ever. And McCarthy later did a lot of work on frames and", "tokens": [50364, 519, 341, 307, 264, 6636, 764, 295, 9952, 1562, 13, 400, 44085, 1780, 630, 257, 688, 295, 589, 322, 12083, 293, 50704], "temperature": 0.0, "avg_logprob": -0.11289166843189913, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.001206472865305841}, {"id": 63, "seek": 47172, "start": 480.04, "end": 483.96000000000004, "text": " you know, logics where you could talk about what's changing and so forth,", "tokens": [50780, 291, 458, 11, 3565, 1167, 689, 291, 727, 751, 466, 437, 311, 4473, 293, 370, 5220, 11, 50976], "temperature": 0.0, "avg_logprob": -0.11289166843189913, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.001206472865305841}, {"id": 64, "seek": 47172, "start": 485.40000000000003, "end": 491.08000000000004, "text": " having to do with the frame problem, and these sorts of things. And you can maybe see some of", "tokens": [51048, 1419, 281, 360, 365, 264, 3920, 1154, 11, 293, 613, 7527, 295, 721, 13, 400, 291, 393, 1310, 536, 512, 295, 51332], "temperature": 0.0, "avg_logprob": -0.11289166843189913, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.001206472865305841}, {"id": 65, "seek": 47172, "start": 491.08000000000004, "end": 497.24, "text": " his early reasoning, or thinking about these problems in this logical description. However,", "tokens": [51332, 702, 2440, 21577, 11, 420, 1953, 466, 613, 2740, 294, 341, 14978, 3855, 13, 2908, 11, 51640], "temperature": 0.0, "avg_logprob": -0.11289166843189913, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.001206472865305841}, {"id": 66, "seek": 49724, "start": 498.12, "end": 505.0, "text": " I don't think it's a particularly exciting example. And so a modern reader may read this", "tokens": [50408, 286, 500, 380, 519, 309, 311, 257, 4098, 4670, 1365, 13, 400, 370, 257, 4363, 15149, 815, 1401, 341, 50752], "temperature": 0.0, "avg_logprob": -0.07216929293226922, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.00020341866184026003}, {"id": 67, "seek": 49724, "start": 505.0, "end": 510.52, "text": " example and think there's nothing really here. But I would encourage you if you read this paper", "tokens": [50752, 1365, 293, 519, 456, 311, 1825, 534, 510, 13, 583, 286, 576, 5373, 291, 498, 291, 1401, 341, 3035, 51028], "temperature": 0.0, "avg_logprob": -0.07216929293226922, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.00020341866184026003}, {"id": 68, "seek": 49724, "start": 511.32, "end": 519.08, "text": " to think a bit in terms of what McCarthy was trying to accomplish, not in terms of his encoding,", "tokens": [51068, 281, 519, 257, 857, 294, 2115, 295, 437, 44085, 390, 1382, 281, 9021, 11, 406, 294, 2115, 295, 702, 43430, 11, 51456], "temperature": 0.0, "avg_logprob": -0.07216929293226922, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.00020341866184026003}, {"id": 69, "seek": 49724, "start": 519.08, "end": 524.12, "text": " or that particular logic he was using. Instead, you know, focus at the level of", "tokens": [51456, 420, 300, 1729, 9952, 415, 390, 1228, 13, 7156, 11, 291, 458, 11, 1879, 412, 264, 1496, 295, 51708], "temperature": 0.0, "avg_logprob": -0.07216929293226922, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.00020341866184026003}, {"id": 70, "seek": 52412, "start": 524.68, "end": 532.84, "text": " these five facets of a system, or his overall design where you'd have a fast system that you", "tokens": [50392, 613, 1732, 49752, 295, 257, 1185, 11, 420, 702, 4787, 1715, 689, 291, 1116, 362, 257, 2370, 1185, 300, 291, 50800], "temperature": 0.0, "avg_logprob": -0.06580717643994964, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.00017951814515981823}, {"id": 71, "seek": 52412, "start": 532.84, "end": 540.04, "text": " can't introspect into. And then you'd have high level, you know, a system that could represent", "tokens": [50800, 393, 380, 560, 28713, 666, 13, 400, 550, 291, 1116, 362, 1090, 1496, 11, 291, 458, 11, 257, 1185, 300, 727, 2906, 51160], "temperature": 0.0, "avg_logprob": -0.06580717643994964, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.00017951814515981823}, {"id": 72, "seek": 52412, "start": 540.04, "end": 545.48, "text": " aspects of itself and its behavior. So I think that's the important part of this paper, understanding", "tokens": [51160, 7270, 295, 2564, 293, 1080, 5223, 13, 407, 286, 519, 300, 311, 264, 1021, 644, 295, 341, 3035, 11, 3701, 51432], "temperature": 0.0, "avg_logprob": -0.06580717643994964, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.00017951814515981823}, {"id": 73, "seek": 52412, "start": 545.48, "end": 551.4, "text": " that. One thing I found interesting about this paper also, which is definitely different from", "tokens": [51432, 300, 13, 1485, 551, 286, 1352, 1880, 466, 341, 3035, 611, 11, 597, 307, 2138, 819, 490, 51728], "temperature": 0.0, "avg_logprob": -0.06580717643994964, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.00017951814515981823}, {"id": 74, "seek": 55140, "start": 551.4, "end": 558.76, "text": " how most papers work today, is that at the very end, there's a description of when McCarthy", "tokens": [50364, 577, 881, 10577, 589, 965, 11, 307, 300, 412, 264, 588, 917, 11, 456, 311, 257, 3855, 295, 562, 44085, 50732], "temperature": 0.0, "avg_logprob": -0.10423389557869203, "compression_ratio": 1.551440329218107, "no_speech_prob": 0.0003459536819718778}, {"id": 75, "seek": 55140, "start": 559.4, "end": 566.92, "text": " presented the paper. And he's catching a little flak here from one of the pioneers of", "tokens": [50764, 8212, 264, 3035, 13, 400, 415, 311, 16124, 257, 707, 932, 514, 510, 490, 472, 295, 264, 47381, 295, 51140], "temperature": 0.0, "avg_logprob": -0.10423389557869203, "compression_ratio": 1.551440329218107, "no_speech_prob": 0.0003459536819718778}, {"id": 76, "seek": 55140, "start": 566.92, "end": 575.64, "text": " natural language processing, who says Dr. McCarthy's paper belongs in a journal of half-baked ideas.", "tokens": [51140, 3303, 2856, 9007, 11, 567, 1619, 2491, 13, 44085, 311, 3035, 12953, 294, 257, 6708, 295, 1922, 12, 65, 7301, 3487, 13, 51576], "temperature": 0.0, "avg_logprob": -0.10423389557869203, "compression_ratio": 1.551440329218107, "no_speech_prob": 0.0003459536819718778}, {"id": 77, "seek": 55140, "start": 575.64, "end": 580.52, "text": " And part of this, I think, was because McCarthy hadn't even attempted to implement this. You know,", "tokens": [51576, 400, 644, 295, 341, 11, 286, 519, 11, 390, 570, 44085, 8782, 380, 754, 18997, 281, 4445, 341, 13, 509, 458, 11, 51820], "temperature": 0.0, "avg_logprob": -0.10423389557869203, "compression_ratio": 1.551440329218107, "no_speech_prob": 0.0003459536819718778}, {"id": 78, "seek": 58052, "start": 580.52, "end": 585.72, "text": " if you think about the computing resources available in 1959, this is a pretty optimistic", "tokens": [50364, 498, 291, 519, 466, 264, 15866, 3593, 2435, 294, 45608, 11, 341, 307, 257, 1238, 19397, 50624], "temperature": 0.0, "avg_logprob": -0.1164357548668271, "compression_ratio": 1.6527777777777777, "no_speech_prob": 8.480821270495653e-05}, {"id": 79, "seek": 58052, "start": 587.56, "end": 592.36, "text": " you know, system, or the idea that he could build a system, or anyone could build a system like this", "tokens": [50716, 291, 458, 11, 1185, 11, 420, 264, 1558, 300, 415, 727, 1322, 257, 1185, 11, 420, 2878, 727, 1322, 257, 1185, 411, 341, 50956], "temperature": 0.0, "avg_logprob": -0.1164357548668271, "compression_ratio": 1.6527777777777777, "no_speech_prob": 8.480821270495653e-05}, {"id": 80, "seek": 58052, "start": 592.36, "end": 598.92, "text": " in 1959 was pretty amazing given that, you know, they were still basically waiting for", "tokens": [50956, 294, 45608, 390, 1238, 2243, 2212, 300, 11, 291, 458, 11, 436, 645, 920, 1936, 3806, 337, 51284], "temperature": 0.0, "avg_logprob": -0.1164357548668271, "compression_ratio": 1.6527777777777777, "no_speech_prob": 8.480821270495653e-05}, {"id": 81, "seek": 58052, "start": 598.92, "end": 604.92, "text": " transistorized computers and all that. But anyway, this paper, I think, if read", "tokens": [51284, 34750, 1602, 10807, 293, 439, 300, 13, 583, 4033, 11, 341, 3035, 11, 286, 519, 11, 498, 1401, 51584], "temperature": 0.0, "avg_logprob": -0.1164357548668271, "compression_ratio": 1.6527777777777777, "no_speech_prob": 8.480821270495653e-05}, {"id": 82, "seek": 60492, "start": 605.4799999999999, "end": 613.0, "text": " by a modern reader focusing on the intent of McCarthy and the high level of concepts,", "tokens": [50392, 538, 257, 4363, 15149, 8416, 322, 264, 8446, 295, 44085, 293, 264, 1090, 1496, 295, 10392, 11, 50768], "temperature": 0.0, "avg_logprob": -0.1872685615052568, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0003150165139231831}, {"id": 83, "seek": 60492, "start": 613.0, "end": 620.92, "text": " is still inspiring today. And I think it's also true that, as McCarthy points out, computer programs", "tokens": [50768, 307, 920, 15883, 965, 13, 400, 286, 519, 309, 311, 611, 2074, 300, 11, 382, 44085, 2793, 484, 11, 3820, 4268, 51164], "temperature": 0.0, "avg_logprob": -0.1872685615052568, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0003150165139231831}, {"id": 84, "seek": 60492, "start": 620.92, "end": 626.92, "text": " don't have common sense. And the programs I use day in, day out, don't really learn from me. I can't", "tokens": [51164, 500, 380, 362, 2689, 2020, 13, 400, 264, 4268, 286, 764, 786, 294, 11, 786, 484, 11, 500, 380, 534, 1466, 490, 385, 13, 286, 393, 380, 51464], "temperature": 0.0, "avg_logprob": -0.1872685615052568, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0003150165139231831}, {"id": 85, "seek": 60492, "start": 626.92, "end": 631.8, "text": " converse with them and have a conversation. You know, McCarthy wanted to be able to use", "tokens": [51464, 416, 4308, 365, 552, 293, 362, 257, 3761, 13, 509, 458, 11, 44085, 1415, 281, 312, 1075, 281, 764, 51708], "temperature": 0.0, "avg_logprob": -0.1872685615052568, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0003150165139231831}, {"id": 86, "seek": 63180, "start": 632.76, "end": 638.8399999999999, "text": " some sort of natural language processing, or maybe stylized language to converse with the program,", "tokens": [50412, 512, 1333, 295, 3303, 2856, 9007, 11, 420, 1310, 23736, 1602, 2856, 281, 416, 4308, 365, 264, 1461, 11, 50716], "temperature": 0.0, "avg_logprob": -0.13836141066117721, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.00031499285250902176}, {"id": 87, "seek": 63180, "start": 638.8399999999999, "end": 644.52, "text": " and have the program be able to communicate its internal state, or aspects of its internal state,", "tokens": [50716, 293, 362, 264, 1461, 312, 1075, 281, 7890, 1080, 6920, 1785, 11, 420, 7270, 295, 1080, 6920, 1785, 11, 51000], "temperature": 0.0, "avg_logprob": -0.13836141066117721, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.00031499285250902176}, {"id": 88, "seek": 63180, "start": 647.56, "end": 651.88, "text": " to an outside advisor, which would have been a human, I think, in McCarthy's day,", "tokens": [51152, 281, 364, 2380, 19161, 11, 597, 576, 362, 668, 257, 1952, 11, 286, 519, 11, 294, 44085, 311, 786, 11, 51368], "temperature": 0.0, "avg_logprob": -0.13836141066117721, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.00031499285250902176}, {"id": 89, "seek": 63180, "start": 651.88, "end": 657.9599999999999, "text": " but now potentially could be another program. And so he's got a lot of interesting ideas here.", "tokens": [51368, 457, 586, 7263, 727, 312, 1071, 1461, 13, 400, 370, 415, 311, 658, 257, 688, 295, 1880, 3487, 510, 13, 51672], "temperature": 0.0, "avg_logprob": -0.13836141066117721, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.00031499285250902176}, {"id": 90, "seek": 65796, "start": 658.76, "end": 665.24, "text": " And, you know, I felt his frustration with the state of software, or reading this,", "tokens": [50404, 400, 11, 291, 458, 11, 286, 2762, 702, 20491, 365, 264, 1785, 295, 4722, 11, 420, 3760, 341, 11, 50728], "temperature": 0.0, "avg_logprob": -0.12199831008911133, "compression_ratio": 1.5369458128078817, "no_speech_prob": 0.0005032828194089234}, {"id": 91, "seek": 65796, "start": 665.24, "end": 671.88, "text": " and I feel that same frustration today, which I think is probably one reason why people get", "tokens": [50728, 293, 286, 841, 300, 912, 20491, 965, 11, 597, 286, 519, 307, 1391, 472, 1778, 983, 561, 483, 51060], "temperature": 0.0, "avg_logprob": -0.12199831008911133, "compression_ratio": 1.5369458128078817, "no_speech_prob": 0.0005032828194089234}, {"id": 92, "seek": 65796, "start": 671.88, "end": 678.6800000000001, "text": " so excited by signing like chat GPT, which does appear to maybe have some common sense,", "tokens": [51060, 370, 2919, 538, 13393, 411, 5081, 26039, 51, 11, 597, 775, 4204, 281, 1310, 362, 512, 2689, 2020, 11, 51400], "temperature": 0.0, "avg_logprob": -0.12199831008911133, "compression_ratio": 1.5369458128078817, "no_speech_prob": 0.0005032828194089234}, {"id": 93, "seek": 65796, "start": 678.6800000000001, "end": 681.72, "text": " or to be able to have a conversation with a user.", "tokens": [51400, 420, 281, 312, 1075, 281, 362, 257, 3761, 365, 257, 4195, 13, 51552], "temperature": 0.0, "avg_logprob": -0.12199831008911133, "compression_ratio": 1.5369458128078817, "no_speech_prob": 0.0005032828194089234}, {"id": 94, "seek": 68172, "start": 682.44, "end": 691.32, "text": " So, this is a foundational paper in the history of artificial intelligence. It's full of interesting", "tokens": [50400, 407, 11, 341, 307, 257, 32195, 3035, 294, 264, 2503, 295, 11677, 7599, 13, 467, 311, 1577, 295, 1880, 50844], "temperature": 0.0, "avg_logprob": -0.18471027745140922, "compression_ratio": 1.4532019704433496, "no_speech_prob": 0.001098570297472179}, {"id": 95, "seek": 68172, "start": 691.32, "end": 699.0, "text": " ideas, if you read it, I think, with the right mindset. And I think we haven't made that much", "tokens": [50844, 3487, 11, 498, 291, 1401, 309, 11, 286, 519, 11, 365, 264, 558, 12543, 13, 400, 286, 519, 321, 2378, 380, 1027, 300, 709, 51228], "temperature": 0.0, "avg_logprob": -0.18471027745140922, "compression_ratio": 1.4532019704433496, "no_speech_prob": 0.001098570297472179}, {"id": 96, "seek": 68172, "start": 699.0, "end": 708.6, "text": " progress even today on what McCarthy was proposing in 1959. So part of what Nada and I are trying to", "tokens": [51228, 4205, 754, 965, 322, 437, 44085, 390, 29939, 294, 45608, 13, 407, 644, 295, 437, 40992, 293, 286, 366, 1382, 281, 51708], "temperature": 0.0, "avg_logprob": -0.18471027745140922, "compression_ratio": 1.4532019704433496, "no_speech_prob": 0.001098570297472179}, {"id": 97, "seek": 70860, "start": 708.76, "end": 715.32, "text": " figure out is, well, why don't programs today have common sense in the way McCarthy was talking", "tokens": [50372, 2573, 484, 307, 11, 731, 11, 983, 500, 380, 4268, 965, 362, 2689, 2020, 294, 264, 636, 44085, 390, 1417, 50700], "temperature": 0.0, "avg_logprob": -0.19075708186372797, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.00021653156727552414}, {"id": 98, "seek": 70860, "start": 715.32, "end": 723.0, "text": " about? Why can't a program determine when it's stuck and ask for help, or have a human or other", "tokens": [50700, 466, 30, 1545, 393, 380, 257, 1461, 6997, 562, 309, 311, 5541, 293, 1029, 337, 854, 11, 420, 362, 257, 1952, 420, 661, 51084], "temperature": 0.0, "avg_logprob": -0.19075708186372797, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.00021653156727552414}, {"id": 99, "seek": 70860, "start": 723.0, "end": 728.84, "text": " external agent, you know, provide heuristics, something like that. McCarthy wanted one of", "tokens": [51084, 8320, 9461, 11, 291, 458, 11, 2893, 415, 374, 6006, 11, 746, 411, 300, 13, 44085, 1415, 472, 295, 51376], "temperature": 0.0, "avg_logprob": -0.19075708186372797, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.00021653156727552414}, {"id": 100, "seek": 70860, "start": 728.84, "end": 734.9200000000001, "text": " these problem-solving advice takers to be able to learn how to become good at a new domain,", "tokens": [51376, 613, 1154, 12, 30926, 798, 5192, 991, 433, 281, 312, 1075, 281, 1466, 577, 281, 1813, 665, 412, 257, 777, 9274, 11, 51680], "temperature": 0.0, "avg_logprob": -0.19075708186372797, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.00021653156727552414}, {"id": 101, "seek": 73492, "start": 735.4799999999999, "end": 742.5999999999999, "text": " such as playing chess, let's say, by, you know, asking questions when it got stuck,", "tokens": [50392, 1270, 382, 2433, 24122, 11, 718, 311, 584, 11, 538, 11, 291, 458, 11, 3365, 1651, 562, 309, 658, 5541, 11, 50748], "temperature": 0.0, "avg_logprob": -0.2141679566482018, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.0006461615557782352}, {"id": 102, "seek": 73492, "start": 742.5999999999999, "end": 748.68, "text": " getting advice from an entity that's more skilled than it was, with the idea that they", "tokens": [50748, 1242, 5192, 490, 364, 13977, 300, 311, 544, 19690, 813, 309, 390, 11, 365, 264, 1558, 300, 436, 51052], "temperature": 0.0, "avg_logprob": -0.2141679566482018, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.0006461615557782352}, {"id": 103, "seek": 73492, "start": 748.68, "end": 754.68, "text": " can improve over time from its experience. Now, of course, today we have programs that", "tokens": [51052, 393, 3470, 670, 565, 490, 1080, 1752, 13, 823, 11, 295, 1164, 11, 965, 321, 362, 4268, 300, 51352], "temperature": 0.0, "avg_logprob": -0.2141679566482018, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.0006461615557782352}, {"id": 104, "seek": 73492, "start": 754.68, "end": 760.92, "text": " play Go and chess and board games like that extremely well. And there's been a lot of work", "tokens": [51352, 862, 1037, 293, 24122, 293, 3150, 2813, 411, 300, 4664, 731, 13, 400, 456, 311, 668, 257, 688, 295, 589, 51664], "temperature": 0.0, "avg_logprob": -0.2141679566482018, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.0006461615557782352}, {"id": 105, "seek": 76092, "start": 761.56, "end": 766.92, "text": " on reinforcement learning, and there's the work on alpha zero and so forth. However,", "tokens": [50396, 322, 29280, 2539, 11, 293, 456, 311, 264, 589, 322, 8961, 4018, 293, 370, 5220, 13, 2908, 11, 50664], "temperature": 0.0, "avg_logprob": -0.16895787856158087, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.0013247908791527152}, {"id": 106, "seek": 76092, "start": 766.92, "end": 774.52, "text": " if you think about the staggering amount of computation required to create, you know,", "tokens": [50664, 498, 291, 519, 466, 264, 42974, 2372, 295, 24903, 4739, 281, 1884, 11, 291, 458, 11, 51044], "temperature": 0.0, "avg_logprob": -0.16895787856158087, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.0013247908791527152}, {"id": 107, "seek": 76092, "start": 774.52, "end": 779.88, "text": " superhuman play with one of those systems, I think that's not at all in the spirit of", "tokens": [51044, 1687, 18796, 862, 365, 472, 295, 729, 3652, 11, 286, 519, 300, 311, 406, 412, 439, 294, 264, 3797, 295, 51312], "temperature": 0.0, "avg_logprob": -0.16895787856158087, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.0013247908791527152}, {"id": 108, "seek": 76092, "start": 779.88, "end": 784.5999999999999, "text": " what McCarthy had in mind. McCarthy, I think, was talking about how humans learn and the idea", "tokens": [51312, 437, 44085, 632, 294, 1575, 13, 44085, 11, 286, 519, 11, 390, 1417, 466, 577, 6255, 1466, 293, 264, 1558, 51548], "temperature": 0.0, "avg_logprob": -0.16895787856158087, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.0013247908791527152}, {"id": 109, "seek": 76092, "start": 784.5999999999999, "end": 789.0799999999999, "text": " that for humans learning how to play chess, someone more experienced can sit there and", "tokens": [51548, 300, 337, 6255, 2539, 577, 281, 862, 24122, 11, 1580, 544, 6751, 393, 1394, 456, 293, 51772], "temperature": 0.0, "avg_logprob": -0.16895787856158087, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.0013247908791527152}, {"id": 110, "seek": 78908, "start": 789.48, "end": 799.48, "text": " watch and give pithy advice. And a beginner can learn in real time with relatively limited", "tokens": [50384, 1159, 293, 976, 280, 355, 88, 5192, 13, 400, 257, 22080, 393, 1466, 294, 957, 565, 365, 7226, 5567, 50884], "temperature": 0.0, "avg_logprob": -0.2186347484588623, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0002377998607698828}, {"id": 111, "seek": 78908, "start": 799.48, "end": 803.96, "text": " communication and bandwidth and without, you know, playing against themselves 100 billion", "tokens": [50884, 6101, 293, 23647, 293, 1553, 11, 291, 458, 11, 2433, 1970, 2969, 2319, 5218, 51108], "temperature": 0.0, "avg_logprob": -0.2186347484588623, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0002377998607698828}, {"id": 112, "seek": 78908, "start": 803.96, "end": 810.5200000000001, "text": " times or whatever happens with these reinforcement learning systems. There's a sort of relatively", "tokens": [51108, 1413, 420, 2035, 2314, 365, 613, 29280, 2539, 3652, 13, 821, 311, 257, 1333, 295, 7226, 51436], "temperature": 0.0, "avg_logprob": -0.2186347484588623, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0002377998607698828}, {"id": 113, "seek": 78908, "start": 810.5200000000001, "end": 816.5200000000001, "text": " small amount of computation in some sense. Now, I'm not saying that the brain isn't very complicated", "tokens": [51436, 1359, 2372, 295, 24903, 294, 512, 2020, 13, 823, 11, 286, 478, 406, 1566, 300, 264, 3567, 1943, 380, 588, 6179, 51736], "temperature": 0.0, "avg_logprob": -0.2186347484588623, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0002377998607698828}, {"id": 114, "seek": 81652, "start": 816.84, "end": 821.96, "text": " and doesn't do all sorts of things we don't understand. I'm not saying the brain isn't", "tokens": [50380, 293, 1177, 380, 360, 439, 7527, 295, 721, 321, 500, 380, 1223, 13, 286, 478, 406, 1566, 264, 3567, 1943, 380, 50636], "temperature": 0.0, "avg_logprob": -0.08733550139835902, "compression_ratio": 1.5913043478260869, "no_speech_prob": 0.00020341189519967884}, {"id": 115, "seek": 81652, "start": 821.96, "end": 827.4, "text": " capable of lots of computation, but in terms of symbolic manipulation and things like that,", "tokens": [50636, 8189, 295, 3195, 295, 24903, 11, 457, 294, 2115, 295, 25755, 26475, 293, 721, 411, 300, 11, 50908], "temperature": 0.0, "avg_logprob": -0.08733550139835902, "compression_ratio": 1.5913043478260869, "no_speech_prob": 0.00020341189519967884}, {"id": 116, "seek": 81652, "start": 827.4, "end": 834.1999999999999, "text": " we know our brains are relatively limited. So certainly human beginner doesn't learn how to", "tokens": [50908, 321, 458, 527, 15442, 366, 7226, 5567, 13, 407, 3297, 1952, 22080, 1177, 380, 1466, 577, 281, 51248], "temperature": 0.0, "avg_logprob": -0.08733550139835902, "compression_ratio": 1.5913043478260869, "no_speech_prob": 0.00020341189519967884}, {"id": 117, "seek": 81652, "start": 834.1999999999999, "end": 842.1999999999999, "text": " play chess the same way that alpha zero would. And the human learning some skill with an expert", "tokens": [51248, 862, 24122, 264, 912, 636, 300, 8961, 4018, 576, 13, 400, 264, 1952, 2539, 512, 5389, 365, 364, 5844, 51648], "temperature": 0.0, "avg_logprob": -0.08733550139835902, "compression_ratio": 1.5913043478260869, "no_speech_prob": 0.00020341189519967884}, {"id": 118, "seek": 84220, "start": 842.2, "end": 846.84, "text": " setting next to them to guide them learns in a different way. And that's really what McCarthy", "tokens": [50364, 3287, 958, 281, 552, 281, 5934, 552, 27152, 294, 257, 819, 636, 13, 400, 300, 311, 534, 437, 44085, 50596], "temperature": 0.0, "avg_logprob": -0.1134541222218717, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.00032501970417797565}, {"id": 119, "seek": 84220, "start": 846.84, "end": 852.12, "text": " is talking about. And so that's what Nata and I are interested in exploring. You know, could we,", "tokens": [50596, 307, 1417, 466, 13, 400, 370, 300, 311, 437, 426, 3274, 293, 286, 366, 3102, 294, 12736, 13, 509, 458, 11, 727, 321, 11, 50860], "temperature": 0.0, "avg_logprob": -0.1134541222218717, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.00032501970417797565}, {"id": 120, "seek": 84220, "start": 852.12, "end": 858.6800000000001, "text": " now computers or millions of times more capable, try to take another crack at building one of", "tokens": [50860, 586, 10807, 420, 6803, 295, 1413, 544, 8189, 11, 853, 281, 747, 1071, 6226, 412, 2390, 472, 295, 51188], "temperature": 0.0, "avg_logprob": -0.1134541222218717, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.00032501970417797565}, {"id": 121, "seek": 84220, "start": 858.6800000000001, "end": 867.48, "text": " these systems. Now, another person who was very interested in building this sort of system was", "tokens": [51188, 613, 3652, 13, 823, 11, 1071, 954, 567, 390, 588, 3102, 294, 2390, 341, 1333, 295, 1185, 390, 51628], "temperature": 0.0, "avg_logprob": -0.1134541222218717, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.00032501970417797565}, {"id": 122, "seek": 86748, "start": 867.48, "end": 877.5600000000001, "text": " John Doyle. And so John Doyle was studying at MIT in the late 70s. And he was working with Jerry", "tokens": [50364, 2619, 40059, 306, 13, 400, 370, 2619, 40059, 306, 390, 7601, 412, 13100, 294, 264, 3469, 5285, 82, 13, 400, 415, 390, 1364, 365, 17454, 50868], "temperature": 0.0, "avg_logprob": -0.11756858119258175, "compression_ratio": 1.564516129032258, "no_speech_prob": 0.0010318621061742306}, {"id": 123, "seek": 86748, "start": 877.5600000000001, "end": 884.6800000000001, "text": " Sussman. And, you know, this was an era where he had Marvin Minsky and Sussman and this very strong", "tokens": [50868, 318, 2023, 1601, 13, 400, 11, 291, 458, 11, 341, 390, 364, 4249, 689, 415, 632, 48722, 376, 44153, 293, 318, 2023, 1601, 293, 341, 588, 2068, 51224], "temperature": 0.0, "avg_logprob": -0.11756858119258175, "compression_ratio": 1.564516129032258, "no_speech_prob": 0.0010318621061742306}, {"id": 124, "seek": 86748, "start": 885.32, "end": 894.2, "text": " AI lab that was, you know, interested in things like, you know, scheme programming, the scheme", "tokens": [51256, 7318, 2715, 300, 390, 11, 291, 458, 11, 3102, 294, 721, 411, 11, 291, 458, 11, 12232, 9410, 11, 264, 12232, 51700], "temperature": 0.0, "avg_logprob": -0.11756858119258175, "compression_ratio": 1.564516129032258, "no_speech_prob": 0.0010318621061742306}, {"id": 125, "seek": 89420, "start": 894.2, "end": 902.84, "text": " programming language, you know, came out of this environment. And also symbolic representation,", "tokens": [50364, 9410, 2856, 11, 291, 458, 11, 1361, 484, 295, 341, 2823, 13, 400, 611, 25755, 10290, 11, 50796], "temperature": 0.0, "avg_logprob": -0.1005216121673584, "compression_ratio": 1.854368932038835, "no_speech_prob": 0.0008294624276459217}, {"id": 126, "seek": 89420, "start": 902.84, "end": 909.5600000000001, "text": " how do you represent information? And also things like metacircular interpreters. So here's an area", "tokens": [50796, 577, 360, 291, 2906, 1589, 30, 400, 611, 721, 411, 1131, 326, 347, 17792, 17489, 1559, 13, 407, 510, 311, 364, 1859, 51132], "temperature": 0.0, "avg_logprob": -0.1005216121673584, "compression_ratio": 1.854368932038835, "no_speech_prob": 0.0008294624276459217}, {"id": 127, "seek": 89420, "start": 909.5600000000001, "end": 916.2, "text": " where you're seeing a combination of programming languages and ideas about programming languages", "tokens": [51132, 689, 291, 434, 2577, 257, 6562, 295, 9410, 8650, 293, 3487, 466, 9410, 8650, 51464], "temperature": 0.0, "avg_logprob": -0.1005216121673584, "compression_ratio": 1.854368932038835, "no_speech_prob": 0.0008294624276459217}, {"id": 128, "seek": 89420, "start": 916.2, "end": 922.5200000000001, "text": " and interpreters and metacircular interpreters, but also connected to symbolic artificial", "tokens": [51464, 293, 17489, 1559, 293, 1131, 326, 347, 17792, 17489, 1559, 11, 457, 611, 4582, 281, 25755, 11677, 51780], "temperature": 0.0, "avg_logprob": -0.1005216121673584, "compression_ratio": 1.854368932038835, "no_speech_prob": 0.0008294624276459217}, {"id": 129, "seek": 92252, "start": 922.52, "end": 927.72, "text": " intelligence. And it doesn't actually have to be symbolic. You could have neural networks", "tokens": [50364, 7599, 13, 400, 309, 1177, 380, 767, 362, 281, 312, 25755, 13, 509, 727, 362, 18161, 9590, 50624], "temperature": 0.0, "avg_logprob": -0.09497256181677993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0002780095674097538}, {"id": 130, "seek": 92252, "start": 927.72, "end": 932.36, "text": " helping out, you could have machine learning or reinforcement learning, things like that,", "tokens": [50624, 4315, 484, 11, 291, 727, 362, 3479, 2539, 420, 29280, 2539, 11, 721, 411, 300, 11, 50856], "temperature": 0.0, "avg_logprob": -0.09497256181677993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0002780095674097538}, {"id": 131, "seek": 92252, "start": 932.36, "end": 938.76, "text": " that interact with the symbolic systems. But there is some notion of a symbolic system inside of,", "tokens": [50856, 300, 4648, 365, 264, 25755, 3652, 13, 583, 456, 307, 512, 10710, 295, 257, 25755, 1185, 1854, 295, 11, 51176], "temperature": 0.0, "avg_logprob": -0.09497256181677993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0002780095674097538}, {"id": 132, "seek": 92252, "start": 938.76, "end": 944.76, "text": " of what we're talking about here with Doyle and McCarthy. Whether that be functional programming", "tokens": [51176, 295, 437, 321, 434, 1417, 466, 510, 365, 40059, 306, 293, 44085, 13, 8503, 300, 312, 11745, 9410, 51476], "temperature": 0.0, "avg_logprob": -0.09497256181677993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0002780095674097538}, {"id": 133, "seek": 92252, "start": 944.76, "end": 949.0, "text": " based or imperative programming based or logic programming based, there's still some sort of", "tokens": [51476, 2361, 420, 32490, 9410, 2361, 420, 9952, 9410, 2361, 11, 456, 311, 920, 512, 1333, 295, 51688], "temperature": 0.0, "avg_logprob": -0.09497256181677993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0002780095674097538}, {"id": 134, "seek": 94900, "start": 949.0, "end": 954.68, "text": " symbolic information and some notion of explainability, which turns out to be important in these", "tokens": [50364, 25755, 1589, 293, 512, 10710, 295, 2903, 2310, 11, 597, 4523, 484, 281, 312, 1021, 294, 613, 50648], "temperature": 0.0, "avg_logprob": -0.1058578388665312, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.00017951872723642737}, {"id": 135, "seek": 94900, "start": 954.68, "end": 963.4, "text": " ideas. In case Doyle was interested in this idea of a self conscious, metacircular interpreter.", "tokens": [50648, 3487, 13, 682, 1389, 40059, 306, 390, 3102, 294, 341, 1558, 295, 257, 2698, 6648, 11, 1131, 326, 347, 17792, 34132, 13, 51084], "temperature": 0.0, "avg_logprob": -0.1058578388665312, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.00017951872723642737}, {"id": 136, "seek": 94900, "start": 964.36, "end": 970.12, "text": " So the idea that you could have a problem solver, you could, you know, sort of take a crack at", "tokens": [51132, 407, 264, 1558, 300, 291, 727, 362, 257, 1154, 1404, 331, 11, 291, 727, 11, 291, 458, 11, 1333, 295, 747, 257, 6226, 412, 51420], "temperature": 0.0, "avg_logprob": -0.1058578388665312, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.00017951872723642737}, {"id": 137, "seek": 94900, "start": 970.12, "end": 976.44, "text": " building McCarthy's advice taker, if you had a metacircular interpreter that was augmented with", "tokens": [51420, 2390, 44085, 311, 5192, 991, 260, 11, 498, 291, 632, 257, 1131, 326, 347, 17792, 34132, 300, 390, 36155, 365, 51736], "temperature": 0.0, "avg_logprob": -0.1058578388665312, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.00017951872723642737}, {"id": 138, "seek": 97644, "start": 976.44, "end": 981.32, "text": " information about the programming language, it can interpret and its own code and so forth,", "tokens": [50364, 1589, 466, 264, 9410, 2856, 11, 309, 393, 7302, 293, 1080, 1065, 3089, 293, 370, 5220, 11, 50608], "temperature": 0.0, "avg_logprob": -0.11645713893846533, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.00026945199351757765}, {"id": 139, "seek": 97644, "start": 981.32, "end": 988.44, "text": " and could reason about that. So, and also part of this is that, you know, the system has to", "tokens": [50608, 293, 727, 1778, 466, 300, 13, 407, 11, 293, 611, 644, 295, 341, 307, 300, 11, 291, 458, 11, 264, 1185, 575, 281, 50964], "temperature": 0.0, "avg_logprob": -0.11645713893846533, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.00026945199351757765}, {"id": 140, "seek": 97644, "start": 989.4000000000001, "end": 995.48, "text": " be able to control itself and try to deal with this exponentially growing search base that", "tokens": [51012, 312, 1075, 281, 1969, 2564, 293, 853, 281, 2028, 365, 341, 37330, 4194, 3164, 3096, 300, 51316], "temperature": 0.0, "avg_logprob": -0.11645713893846533, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.00026945199351757765}, {"id": 141, "seek": 97644, "start": 995.48, "end": 1002.2, "text": " comes up over and over again, when you're doing reasoning. So MacArthur, sorry, Doyle", "tokens": [51316, 1487, 493, 670, 293, 670, 797, 11, 562, 291, 434, 884, 21577, 13, 407, 5707, 42646, 11, 2597, 11, 40059, 306, 51652], "temperature": 0.0, "avg_logprob": -0.11645713893846533, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.00026945199351757765}, {"id": 142, "seek": 100220, "start": 1002.5200000000001, "end": 1008.36, "text": " proposes a whole bunch of interesting ideas. And this is linked to a bunch of work that was going", "tokens": [50380, 2365, 4201, 257, 1379, 3840, 295, 1880, 3487, 13, 400, 341, 307, 9408, 281, 257, 3840, 295, 589, 300, 390, 516, 50672], "temperature": 0.0, "avg_logprob": -0.12120045041575016, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.001648262026719749}, {"id": 143, "seek": 100220, "start": 1008.36, "end": 1014.6800000000001, "text": " on at MIT lab at that time by, you know, people like Guy Steele and Drew McDermott and so forth,", "tokens": [50672, 322, 412, 13100, 2715, 412, 300, 565, 538, 11, 291, 458, 11, 561, 411, 14690, 745, 1653, 306, 293, 25550, 49269, 966, 1521, 293, 370, 5220, 11, 50988], "temperature": 0.0, "avg_logprob": -0.12120045041575016, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.001648262026719749}, {"id": 144, "seek": 100220, "start": 1014.6800000000001, "end": 1021.8000000000001, "text": " in addition to Minsky and Sussman and so forth, you know, a whole bunch of other people. I won't", "tokens": [50988, 294, 4500, 281, 376, 44153, 293, 318, 2023, 1601, 293, 370, 5220, 11, 291, 458, 11, 257, 1379, 3840, 295, 661, 561, 13, 286, 1582, 380, 51344], "temperature": 0.0, "avg_logprob": -0.12120045041575016, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.001648262026719749}, {"id": 145, "seek": 100220, "start": 1021.8000000000001, "end": 1028.76, "text": " get into all of them, but I definitely recommend reading these AI memos from that time period", "tokens": [51344, 483, 666, 439, 295, 552, 11, 457, 286, 2138, 2748, 3760, 613, 7318, 1334, 329, 490, 300, 565, 2896, 51692], "temperature": 0.0, "avg_logprob": -0.12120045041575016, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.001648262026719749}, {"id": 146, "seek": 102876, "start": 1028.84, "end": 1033.0, "text": " and things like the Amor interpreter. Lots of very interesting papers back then.", "tokens": [50368, 293, 721, 411, 264, 2012, 284, 34132, 13, 15908, 295, 588, 1880, 10577, 646, 550, 13, 50576], "temperature": 0.0, "avg_logprob": -0.16851505952722887, "compression_ratio": 1.4549180327868851, "no_speech_prob": 0.0005883296835236251}, {"id": 147, "seek": 102876, "start": 1034.28, "end": 1039.64, "text": " And McCarthy, sorry, Doyle talks about, you know, the language you might have and", "tokens": [50640, 400, 44085, 11, 2597, 11, 40059, 306, 6686, 466, 11, 291, 458, 11, 264, 2856, 291, 1062, 362, 293, 50908], "temperature": 0.0, "avg_logprob": -0.16851505952722887, "compression_ratio": 1.4549180327868851, "no_speech_prob": 0.0005883296835236251}, {"id": 148, "seek": 102876, "start": 1040.28, "end": 1046.92, "text": " it gives examples of reasoning and compilation efficiency turns out to be a major idea. Once", "tokens": [50940, 309, 2709, 5110, 295, 21577, 293, 40261, 10493, 4523, 484, 281, 312, 257, 2563, 1558, 13, 3443, 51272], "temperature": 0.0, "avg_logprob": -0.16851505952722887, "compression_ratio": 1.4549180327868851, "no_speech_prob": 0.0005883296835236251}, {"id": 149, "seek": 102876, "start": 1046.92, "end": 1056.44, "text": " again, I think if you read this thesis proposal, which is from around 1979, 1980, it's important to", "tokens": [51272, 797, 11, 286, 519, 498, 291, 1401, 341, 22288, 11494, 11, 597, 307, 490, 926, 30595, 11, 13626, 11, 309, 311, 1021, 281, 51748], "temperature": 0.0, "avg_logprob": -0.16851505952722887, "compression_ratio": 1.4549180327868851, "no_speech_prob": 0.0005883296835236251}, {"id": 150, "seek": 105644, "start": 1056.52, "end": 1064.52, "text": " keep in mind the intention and where Doyle was trying to go instead of, you know, overly criticizing", "tokens": [50368, 1066, 294, 1575, 264, 7789, 293, 689, 40059, 306, 390, 1382, 281, 352, 2602, 295, 11, 291, 458, 11, 24324, 45474, 50768], "temperature": 0.0, "avg_logprob": -0.1146281427807278, "compression_ratio": 1.53125, "no_speech_prob": 0.00019108619017060846}, {"id": 151, "seek": 105644, "start": 1064.52, "end": 1071.4, "text": " specific examples that maybe aren't very exciting today. Okay, so I think it's important to keep", "tokens": [50768, 2685, 5110, 300, 1310, 3212, 380, 588, 4670, 965, 13, 1033, 11, 370, 286, 519, 309, 311, 1021, 281, 1066, 51112], "temperature": 0.0, "avg_logprob": -0.1146281427807278, "compression_ratio": 1.53125, "no_speech_prob": 0.00019108619017060846}, {"id": 152, "seek": 105644, "start": 1071.4, "end": 1081.4, "text": " in mind what he was trying to accomplish. And he wrote a PhD thesis, you know, on related ideas,", "tokens": [51112, 294, 1575, 437, 415, 390, 1382, 281, 9021, 13, 400, 415, 4114, 257, 14476, 22288, 11, 291, 458, 11, 322, 4077, 3487, 11, 51612], "temperature": 0.0, "avg_logprob": -0.1146281427807278, "compression_ratio": 1.53125, "no_speech_prob": 0.00019108619017060846}, {"id": 153, "seek": 108140, "start": 1081.4, "end": 1088.6000000000001, "text": " a model for deliberation action and introspection, which was published as a AI tech report number 581.", "tokens": [50364, 257, 2316, 337, 14207, 399, 3069, 293, 560, 2635, 19997, 11, 597, 390, 6572, 382, 257, 7318, 7553, 2275, 1230, 21786, 16, 13, 50724], "temperature": 0.0, "avg_logprob": -0.11329752748662775, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.000607036636210978}, {"id": 154, "seek": 108140, "start": 1090.2800000000002, "end": 1101.88, "text": " So those are really interesting ideas to me. Doyle also talked about what he called a truth", "tokens": [50808, 407, 729, 366, 534, 1880, 3487, 281, 385, 13, 40059, 306, 611, 2825, 466, 437, 415, 1219, 257, 3494, 51388], "temperature": 0.0, "avg_logprob": -0.11329752748662775, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.000607036636210978}, {"id": 155, "seek": 108140, "start": 1101.88, "end": 1107.4, "text": " maintenance system, which later probably should be called a belief maintenance system. But he", "tokens": [51388, 11258, 1185, 11, 597, 1780, 1391, 820, 312, 1219, 257, 7107, 11258, 1185, 13, 583, 415, 51664], "temperature": 0.0, "avg_logprob": -0.11329752748662775, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.000607036636210978}, {"id": 156, "seek": 110740, "start": 1107.4, "end": 1114.8400000000001, "text": " proposed this architecture, which I think was largely inspired by work by Sussman and other", "tokens": [50364, 10348, 341, 9482, 11, 597, 286, 519, 390, 11611, 7547, 538, 589, 538, 318, 2023, 1601, 293, 661, 50736], "temperature": 0.0, "avg_logprob": -0.07747312635183334, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.00024535259581170976}, {"id": 157, "seek": 110740, "start": 1114.8400000000001, "end": 1121.24, "text": " people, but more formalized in a particular architecture, this truth maintenance systems", "tokens": [50736, 561, 11, 457, 544, 9860, 1602, 294, 257, 1729, 9482, 11, 341, 3494, 11258, 3652, 51056], "temperature": 0.0, "avg_logprob": -0.07747312635183334, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.00024535259581170976}, {"id": 158, "seek": 110740, "start": 1121.24, "end": 1131.0, "text": " or TMSs. And this paper, this AI memo 521 is full of interesting ideas, including things like", "tokens": [51056, 420, 314, 10288, 82, 13, 400, 341, 3035, 11, 341, 7318, 35900, 1025, 4436, 307, 1577, 295, 1880, 3487, 11, 3009, 721, 411, 51544], "temperature": 0.0, "avg_logprob": -0.07747312635183334, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.00024535259581170976}, {"id": 159, "seek": 113100, "start": 1131.64, "end": 1139.0, "text": " arguing truth maintenance systems that could, you know, argue in front of other truth maintenance", "tokens": [50396, 19697, 3494, 11258, 3652, 300, 727, 11, 291, 458, 11, 9695, 294, 1868, 295, 661, 3494, 11258, 50764], "temperature": 0.0, "avg_logprob": -0.11259355545043945, "compression_ratio": 1.91, "no_speech_prob": 0.0004305399488657713}, {"id": 160, "seek": 113100, "start": 1139.0, "end": 1145.56, "text": " systems, and other truth maintenance systems observing the arguments between two TMSs could", "tokens": [50764, 3652, 11, 293, 661, 3494, 11258, 3652, 22107, 264, 12869, 1296, 732, 314, 10288, 82, 727, 51092], "temperature": 0.0, "avg_logprob": -0.11259355545043945, "compression_ratio": 1.91, "no_speech_prob": 0.0004305399488657713}, {"id": 161, "seek": 113100, "start": 1145.56, "end": 1150.6, "text": " update their own beliefs. So these, these were systems that could update their own beliefs over", "tokens": [51092, 5623, 641, 1065, 13585, 13, 407, 613, 11, 613, 645, 3652, 300, 727, 5623, 641, 1065, 13585, 670, 51344], "temperature": 0.0, "avg_logprob": -0.11259355545043945, "compression_ratio": 1.91, "no_speech_prob": 0.0004305399488657713}, {"id": 162, "seek": 113100, "start": 1150.6, "end": 1157.88, "text": " time. And there are all sorts of interesting work here, including default logics and things like", "tokens": [51344, 565, 13, 400, 456, 366, 439, 7527, 295, 1880, 589, 510, 11, 3009, 7576, 3565, 1167, 293, 721, 411, 51708], "temperature": 0.0, "avg_logprob": -0.11259355545043945, "compression_ratio": 1.91, "no_speech_prob": 0.0004305399488657713}, {"id": 163, "seek": 115788, "start": 1157.88, "end": 1164.68, "text": " that. And, and one of the things that came out of the work on TMSs was this book, Building Problem", "tokens": [50364, 300, 13, 400, 11, 293, 472, 295, 264, 721, 300, 1361, 484, 295, 264, 589, 322, 314, 10288, 82, 390, 341, 1446, 11, 18974, 11676, 50704], "temperature": 0.0, "avg_logprob": -0.11470718973690701, "compression_ratio": 1.6208333333333333, "no_speech_prob": 0.001169340219348669}, {"id": 164, "seek": 115788, "start": 1164.68, "end": 1172.92, "text": " Solvers, by Ken Forbes and Johan DeClerre. And this is basically a book on AI patterns and how", "tokens": [50704, 7026, 840, 11, 538, 8273, 45950, 293, 19180, 282, 1346, 34, 1918, 265, 13, 400, 341, 307, 1936, 257, 1446, 322, 7318, 8294, 293, 577, 51116], "temperature": 0.0, "avg_logprob": -0.11470718973690701, "compression_ratio": 1.6208333333333333, "no_speech_prob": 0.001169340219348669}, {"id": 165, "seek": 115788, "start": 1172.92, "end": 1177.96, "text": " they can be AI programming patterns and how they can be applied to various problems. But it talks", "tokens": [51116, 436, 393, 312, 7318, 9410, 8294, 293, 577, 436, 393, 312, 6456, 281, 3683, 2740, 13, 583, 309, 6686, 51368], "temperature": 0.0, "avg_logprob": -0.11470718973690701, "compression_ratio": 1.6208333333333333, "no_speech_prob": 0.001169340219348669}, {"id": 166, "seek": 115788, "start": 1177.96, "end": 1183.4, "text": " about things like the different types of truth maintenance systems. An early piece of work that's", "tokens": [51368, 466, 721, 411, 264, 819, 3467, 295, 3494, 11258, 3652, 13, 1107, 2440, 2522, 295, 589, 300, 311, 51640], "temperature": 0.0, "avg_logprob": -0.11470718973690701, "compression_ratio": 1.6208333333333333, "no_speech_prob": 0.001169340219348669}, {"id": 167, "seek": 118340, "start": 1183.4, "end": 1193.5600000000002, "text": " related is, you know, Jerry Sussman's a computational model skill acquisition where he tries to", "tokens": [50364, 4077, 307, 11, 291, 458, 11, 17454, 318, 2023, 1601, 311, 257, 28270, 2316, 5389, 21668, 689, 415, 9898, 281, 50872], "temperature": 0.0, "avg_logprob": -0.10167064528534378, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0005527164321392775}, {"id": 168, "seek": 118340, "start": 1193.5600000000002, "end": 1203.64, "text": " understand how a program could learn some complex domain like a human could. And, and so this was", "tokens": [50872, 1223, 577, 257, 1461, 727, 1466, 512, 3997, 9274, 411, 257, 1952, 727, 13, 400, 11, 293, 370, 341, 390, 51376], "temperature": 0.0, "avg_logprob": -0.10167064528534378, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0005527164321392775}, {"id": 169, "seek": 118340, "start": 1204.2800000000002, "end": 1212.2, "text": " really foundational to a lot of the work that came later by people like Doyle. So this was also", "tokens": [51408, 534, 32195, 281, 257, 688, 295, 264, 589, 300, 1361, 1780, 538, 561, 411, 40059, 306, 13, 407, 341, 390, 611, 51804], "temperature": 0.0, "avg_logprob": -0.10167064528534378, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0005527164321392775}, {"id": 170, "seek": 121220, "start": 1212.2, "end": 1218.68, "text": " very interesting. This is describing his hacker system. So the hacker system, and you can, I think", "tokens": [50364, 588, 1880, 13, 639, 307, 16141, 702, 38155, 1185, 13, 407, 264, 38155, 1185, 11, 293, 291, 393, 11, 286, 519, 50688], "temperature": 0.0, "avg_logprob": -0.09194521193808698, "compression_ratio": 1.757847533632287, "no_speech_prob": 0.0028889807872474194}, {"id": 171, "seek": 121220, "start": 1218.68, "end": 1223.4, "text": " if you look at the hacker system, you can see something like a TMS inside of it. But this hacker", "tokens": [50688, 498, 291, 574, 412, 264, 38155, 1185, 11, 291, 393, 536, 746, 411, 257, 314, 10288, 1854, 295, 309, 13, 583, 341, 38155, 50924], "temperature": 0.0, "avg_logprob": -0.09194521193808698, "compression_ratio": 1.757847533632287, "no_speech_prob": 0.0028889807872474194}, {"id": 172, "seek": 121220, "start": 1223.4, "end": 1230.2, "text": " system could learn basically how to program or learn how to debug programs and things like that.", "tokens": [50924, 1185, 727, 1466, 1936, 577, 281, 1461, 420, 1466, 577, 281, 24083, 4268, 293, 721, 411, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09194521193808698, "compression_ratio": 1.757847533632287, "no_speech_prob": 0.0028889807872474194}, {"id": 173, "seek": 121220, "start": 1230.2, "end": 1237.0800000000002, "text": " And so this was an early attempt to, you know, try to deal with problem solving domain having to do", "tokens": [51264, 400, 370, 341, 390, 364, 2440, 5217, 281, 11, 291, 458, 11, 853, 281, 2028, 365, 1154, 12606, 9274, 1419, 281, 360, 51608], "temperature": 0.0, "avg_logprob": -0.09194521193808698, "compression_ratio": 1.757847533632287, "no_speech_prob": 0.0028889807872474194}, {"id": 174, "seek": 123708, "start": 1237.08, "end": 1243.72, "text": " with software development or programming. That was similar in some sense to McCarthy's advice", "tokens": [50364, 365, 4722, 3250, 420, 9410, 13, 663, 390, 2531, 294, 512, 2020, 281, 44085, 311, 5192, 50696], "temperature": 0.0, "avg_logprob": -0.14000532520351125, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.0009398075635544956}, {"id": 175, "seek": 123708, "start": 1243.72, "end": 1250.6799999999998, "text": " taker, although as far as I know, there wasn't this notion of, of interaction in the same way", "tokens": [50696, 991, 260, 11, 4878, 382, 1400, 382, 286, 458, 11, 456, 2067, 380, 341, 10710, 295, 11, 295, 9285, 294, 264, 912, 636, 51044], "temperature": 0.0, "avg_logprob": -0.14000532520351125, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.0009398075635544956}, {"id": 176, "seek": 123708, "start": 1250.6799999999998, "end": 1258.12, "text": " that McCarthy had talked about. So you could see something like the TMS is coming out of this", "tokens": [51044, 300, 44085, 632, 2825, 466, 13, 407, 291, 727, 536, 746, 411, 264, 314, 10288, 307, 1348, 484, 295, 341, 51416], "temperature": 0.0, "avg_logprob": -0.14000532520351125, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.0009398075635544956}, {"id": 177, "seek": 125812, "start": 1258.52, "end": 1268.6799999999998, "text": " hacker approach. Another piece of work that came out of the MIT AI lab around that time", "tokens": [50384, 38155, 3109, 13, 3996, 2522, 295, 589, 300, 1361, 484, 295, 264, 13100, 7318, 2715, 926, 300, 565, 50892], "temperature": 0.0, "avg_logprob": -0.17239393293857574, "compression_ratio": 1.530054644808743, "no_speech_prob": 0.011329801753163338}, {"id": 178, "seek": 125812, "start": 1268.6799999999998, "end": 1275.9599999999998, "text": " was this notion of a Lisp programmers apprentice by Charles Rich and Howie Shrobe. And there was", "tokens": [50892, 390, 341, 10710, 295, 257, 441, 7631, 41504, 40207, 538, 10523, 6781, 293, 1012, 414, 1160, 24489, 13, 400, 456, 390, 51256], "temperature": 0.0, "avg_logprob": -0.17239393293857574, "compression_ratio": 1.530054644808743, "no_speech_prob": 0.011329801753163338}, {"id": 179, "seek": 125812, "start": 1275.9599999999998, "end": 1281.32, "text": " actually a book that was published by ACM Press on the programmers apprentice project which ran", "tokens": [51256, 767, 257, 1446, 300, 390, 6572, 538, 8157, 44, 6776, 322, 264, 41504, 40207, 1716, 597, 5872, 51524], "temperature": 0.0, "avg_logprob": -0.17239393293857574, "compression_ratio": 1.530054644808743, "no_speech_prob": 0.011329801753163338}, {"id": 180, "seek": 128132, "start": 1282.2, "end": 1291.48, "text": " for, for quite a while at MIT. And the idea was to build a system that could learn the needs of a", "tokens": [50408, 337, 11, 337, 1596, 257, 1339, 412, 13100, 13, 400, 264, 1558, 390, 281, 1322, 257, 1185, 300, 727, 1466, 264, 2203, 295, 257, 50872], "temperature": 0.0, "avg_logprob": -0.10449625895573543, "compression_ratio": 1.4627659574468086, "no_speech_prob": 0.0017005203990265727}, {"id": 181, "seek": 128132, "start": 1291.48, "end": 1299.0, "text": " software engineer over time. And this, this was an extremely ambitious project at the time", "tokens": [50872, 4722, 11403, 670, 565, 13, 400, 341, 11, 341, 390, 364, 4664, 20239, 1716, 412, 264, 565, 51248], "temperature": 0.0, "avg_logprob": -0.10449625895573543, "compression_ratio": 1.4627659574468086, "no_speech_prob": 0.0017005203990265727}, {"id": 182, "seek": 128132, "start": 1299.0, "end": 1306.36, "text": " when it started in the 70s, included things like natural language processing and voice", "tokens": [51248, 562, 309, 1409, 294, 264, 5285, 82, 11, 5556, 721, 411, 3303, 2856, 9007, 293, 3177, 51616], "temperature": 0.0, "avg_logprob": -0.10449625895573543, "compression_ratio": 1.4627659574468086, "no_speech_prob": 0.0017005203990265727}, {"id": 183, "seek": 130636, "start": 1306.36, "end": 1312.52, "text": " recognition and, and so forth. And different types of program synthesis at the architectural", "tokens": [50364, 11150, 293, 11, 293, 370, 5220, 13, 400, 819, 3467, 295, 1461, 30252, 412, 264, 26621, 50672], "temperature": 0.0, "avg_logprob": -0.15158389596378102, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.0003149951226077974}, {"id": 184, "seek": 130636, "start": 1312.52, "end": 1319.8799999999999, "text": " level, not just at the synthesis at the level of individual functions. So that was also, you know,", "tokens": [50672, 1496, 11, 406, 445, 412, 264, 30252, 412, 264, 1496, 295, 2609, 6828, 13, 407, 300, 390, 611, 11, 291, 458, 11, 51040], "temperature": 0.0, "avg_logprob": -0.15158389596378102, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.0003149951226077974}, {"id": 185, "seek": 130636, "start": 1319.8799999999999, "end": 1328.4399999999998, "text": " an interesting set of ideas that that were going around. Okay, so the last set of ideas I'll talk", "tokens": [51040, 364, 1880, 992, 295, 3487, 300, 300, 645, 516, 926, 13, 1033, 11, 370, 264, 1036, 992, 295, 3487, 286, 603, 751, 51468], "temperature": 0.0, "avg_logprob": -0.15158389596378102, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.0003149951226077974}, {"id": 186, "seek": 132844, "start": 1328.44, "end": 1337.24, "text": " about that I think are in this vein, we're from Doug Lennett, who worked on several important", "tokens": [50364, 466, 300, 286, 519, 366, 294, 341, 30669, 11, 321, 434, 490, 12742, 441, 1857, 3093, 11, 567, 2732, 322, 2940, 1021, 50804], "temperature": 0.0, "avg_logprob": -0.16975194295247395, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.007344541139900684}, {"id": 187, "seek": 132844, "start": 1337.24, "end": 1344.92, "text": " programs. And one was called AM. This is like an automated mathematician. And there was another one", "tokens": [50804, 4268, 13, 400, 472, 390, 1219, 6475, 13, 639, 307, 411, 364, 18473, 48281, 13, 400, 456, 390, 1071, 472, 51188], "temperature": 0.0, "avg_logprob": -0.16975194295247395, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.007344541139900684}, {"id": 188, "seek": 132844, "start": 1345.8, "end": 1352.3600000000001, "text": " called Eurisco. And here's Eurisco, a plan, a program that learns new heuristics and domain", "tokens": [51232, 1219, 462, 374, 8610, 13, 400, 510, 311, 462, 374, 8610, 11, 257, 1393, 11, 257, 1461, 300, 27152, 777, 415, 374, 6006, 293, 9274, 51560], "temperature": 0.0, "avg_logprob": -0.16975194295247395, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.007344541139900684}, {"id": 189, "seek": 135236, "start": 1352.36, "end": 1360.12, "text": " concepts. And this is part three of that series. And you can find these papers, the nature of", "tokens": [50364, 10392, 13, 400, 341, 307, 644, 1045, 295, 300, 2638, 13, 400, 291, 393, 915, 613, 10577, 11, 264, 3687, 295, 50752], "temperature": 0.0, "avg_logprob": -0.14044809341430664, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.00017399968055542558}, {"id": 190, "seek": 135236, "start": 1360.12, "end": 1368.28, "text": " heuristics, so this heuristic based theory formation. Okay, so here's number two. And,", "tokens": [50752, 415, 374, 6006, 11, 370, 341, 415, 374, 3142, 2361, 5261, 11723, 13, 1033, 11, 370, 510, 311, 1230, 732, 13, 400, 11, 51160], "temperature": 0.0, "avg_logprob": -0.14044809341430664, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.00017399968055542558}, {"id": 191, "seek": 135236, "start": 1369.08, "end": 1373.8799999999999, "text": " you know, as followed up by this paper, why AM and Eurisco appear to work.", "tokens": [51200, 291, 458, 11, 382, 6263, 493, 538, 341, 3035, 11, 983, 6475, 293, 462, 374, 8610, 4204, 281, 589, 13, 51440], "temperature": 0.0, "avg_logprob": -0.14044809341430664, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.00017399968055542558}, {"id": 192, "seek": 137388, "start": 1374.7600000000002, "end": 1385.0800000000002, "text": " And this is also a very interesting line of reasoning. And so you have this idea of heuristic", "tokens": [50408, 400, 341, 307, 611, 257, 588, 1880, 1622, 295, 21577, 13, 400, 370, 291, 362, 341, 1558, 295, 415, 374, 3142, 50924], "temperature": 0.0, "avg_logprob": -0.10723070840577821, "compression_ratio": 1.606936416184971, "no_speech_prob": 0.0030271538998931646}, {"id": 193, "seek": 137388, "start": 1385.0800000000002, "end": 1391.48, "text": " guided systems, systems that can invent their own heuristics, and so forth. And you can see that", "tokens": [50924, 19663, 3652, 11, 3652, 300, 393, 7962, 641, 1065, 415, 374, 6006, 11, 293, 370, 5220, 13, 400, 291, 393, 536, 300, 51244], "temperature": 0.0, "avg_logprob": -0.10723070840577821, "compression_ratio": 1.606936416184971, "no_speech_prob": 0.0030271538998931646}, {"id": 194, "seek": 137388, "start": 1392.0400000000002, "end": 1401.3200000000002, "text": " all of these systems, along with the work by, say, you know, Minsky on Society of Mine,", "tokens": [51272, 439, 295, 613, 3652, 11, 2051, 365, 264, 589, 538, 11, 584, 11, 291, 458, 11, 376, 44153, 322, 13742, 295, 11620, 11, 51736], "temperature": 0.0, "avg_logprob": -0.10723070840577821, "compression_ratio": 1.606936416184971, "no_speech_prob": 0.0030271538998931646}, {"id": 195, "seek": 140132, "start": 1402.28, "end": 1409.48, "text": " are similar in that they go to a certain notion of intelligence, which is the ability to get", "tokens": [50412, 366, 2531, 294, 300, 436, 352, 281, 257, 1629, 10710, 295, 7599, 11, 597, 307, 264, 3485, 281, 483, 50772], "temperature": 0.0, "avg_logprob": -0.0780814920814292, "compression_ratio": 2.168539325842697, "no_speech_prob": 0.0008558208355680108}, {"id": 196, "seek": 140132, "start": 1409.48, "end": 1417.24, "text": " unstuck, the ability to either ask for help, or to recognize when a system is stuck, or to be able", "tokens": [50772, 18799, 1134, 11, 264, 3485, 281, 2139, 1029, 337, 854, 11, 420, 281, 5521, 562, 257, 1185, 307, 5541, 11, 420, 281, 312, 1075, 51160], "temperature": 0.0, "avg_logprob": -0.0780814920814292, "compression_ratio": 2.168539325842697, "no_speech_prob": 0.0008558208355680108}, {"id": 197, "seek": 140132, "start": 1417.24, "end": 1423.1599999999999, "text": " to use heuristics to get unstuck, or even to use meta heuristics to develop new heuristics to get", "tokens": [51160, 281, 764, 415, 374, 6006, 281, 483, 18799, 1134, 11, 420, 754, 281, 764, 19616, 415, 374, 6006, 281, 1499, 777, 415, 374, 6006, 281, 483, 51456], "temperature": 0.0, "avg_logprob": -0.0780814920814292, "compression_ratio": 2.168539325842697, "no_speech_prob": 0.0008558208355680108}, {"id": 198, "seek": 140132, "start": 1423.1599999999999, "end": 1428.2, "text": " stuck, or to use meta meta heuristics to develop meta heuristics to develop meta meta, you know,", "tokens": [51456, 5541, 11, 420, 281, 764, 19616, 19616, 415, 374, 6006, 281, 1499, 19616, 415, 374, 6006, 281, 1499, 19616, 19616, 11, 291, 458, 11, 51708], "temperature": 0.0, "avg_logprob": -0.0780814920814292, "compression_ratio": 2.168539325842697, "no_speech_prob": 0.0008558208355680108}, {"id": 199, "seek": 142820, "start": 1428.2, "end": 1434.68, "text": " develop heuristics to get unstuck, that sort of thing. So, you know, that that is, I think,", "tokens": [50364, 1499, 415, 374, 6006, 281, 483, 18799, 1134, 11, 300, 1333, 295, 551, 13, 407, 11, 291, 458, 11, 300, 300, 307, 11, 286, 519, 11, 50688], "temperature": 0.0, "avg_logprob": -0.07060914161877754, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0004305125621613115}, {"id": 200, "seek": 142820, "start": 1434.68, "end": 1440.52, "text": " core at understanding all of this work, you know, the notion of intelligence, which has to do with", "tokens": [50688, 4965, 412, 3701, 439, 295, 341, 589, 11, 291, 458, 11, 264, 10710, 295, 7599, 11, 597, 575, 281, 360, 365, 50980], "temperature": 0.0, "avg_logprob": -0.07060914161877754, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0004305125621613115}, {"id": 201, "seek": 142820, "start": 1440.52, "end": 1450.68, "text": " getting unstuck. Now, I could talk a lot more about these ideas, but I would like to change gears", "tokens": [50980, 1242, 18799, 1134, 13, 823, 11, 286, 727, 751, 257, 688, 544, 466, 613, 3487, 11, 457, 286, 576, 411, 281, 1319, 20915, 51488], "temperature": 0.0, "avg_logprob": -0.07060914161877754, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0004305125621613115}, {"id": 202, "seek": 145068, "start": 1450.68, "end": 1458.04, "text": " into what Nada and I have been exploring. And, you know, so we've decided, we want to try to", "tokens": [50364, 666, 437, 40992, 293, 286, 362, 668, 12736, 13, 400, 11, 291, 458, 11, 370, 321, 600, 3047, 11, 321, 528, 281, 853, 281, 50732], "temperature": 0.0, "avg_logprob": -0.1066796588897705, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.020327402278780937}, {"id": 203, "seek": 145068, "start": 1458.04, "end": 1465.64, "text": " understand why something like AdviceTaker doesn't seem to exist today, at least to our knowledge.", "tokens": [50732, 1223, 983, 746, 411, 13634, 573, 51, 4003, 1177, 380, 1643, 281, 2514, 965, 11, 412, 1935, 281, 527, 3601, 13, 51112], "temperature": 0.0, "avg_logprob": -0.1066796588897705, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.020327402278780937}, {"id": 204, "seek": 145068, "start": 1465.64, "end": 1471.48, "text": " There have been projects, there are projects like the SOAR project, that's OAR, and other projects", "tokens": [51112, 821, 362, 668, 4455, 11, 456, 366, 4455, 411, 264, 10621, 1899, 1716, 11, 300, 311, 422, 1899, 11, 293, 661, 4455, 51404], "temperature": 0.0, "avg_logprob": -0.1066796588897705, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.020327402278780937}, {"id": 205, "seek": 145068, "start": 1471.48, "end": 1476.68, "text": " have been running a long time for, you know, symbolic AI type things. But as far as I know,", "tokens": [51404, 362, 668, 2614, 257, 938, 565, 337, 11, 291, 458, 11, 25755, 7318, 2010, 721, 13, 583, 382, 1400, 382, 286, 458, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1066796588897705, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.020327402278780937}, {"id": 206, "seek": 147668, "start": 1476.68, "end": 1485.0, "text": " there isn't anything I think that McCarthy would recognize as his AdviceTaker. And so,", "tokens": [50364, 456, 1943, 380, 1340, 286, 519, 300, 44085, 576, 5521, 382, 702, 13634, 573, 51, 4003, 13, 400, 370, 11, 50780], "temperature": 0.0, "avg_logprob": -0.09822094175550673, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.00043046317296102643}, {"id": 207, "seek": 147668, "start": 1485.0, "end": 1491.96, "text": " the question we have is, why is that? Is it because the basic idea is fundamentally flawed? Is it", "tokens": [50780, 264, 1168, 321, 362, 307, 11, 983, 307, 300, 30, 1119, 309, 570, 264, 3875, 1558, 307, 17879, 38823, 30, 1119, 309, 51128], "temperature": 0.0, "avg_logprob": -0.09822094175550673, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.00043046317296102643}, {"id": 208, "seek": 147668, "start": 1491.96, "end": 1496.92, "text": " because the idea is not well defined enough, and you couldn't tell if it had been built or not?", "tokens": [51128, 570, 264, 1558, 307, 406, 731, 7642, 1547, 11, 293, 291, 2809, 380, 980, 498, 309, 632, 668, 3094, 420, 406, 30, 51376], "temperature": 0.0, "avg_logprob": -0.09822094175550673, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.00043046317296102643}, {"id": 209, "seek": 147668, "start": 1497.64, "end": 1502.8400000000001, "text": " Is it because that there's some fundamental limitation, like there's some notion of", "tokens": [51412, 1119, 309, 570, 300, 456, 311, 512, 8088, 27432, 11, 411, 456, 311, 512, 10710, 295, 51672], "temperature": 0.0, "avg_logprob": -0.09822094175550673, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.00043046317296102643}, {"id": 210, "seek": 150284, "start": 1502.84, "end": 1509.8799999999999, "text": " self-introspection or self-consciousness that we can't describe or runs into the halting problem", "tokens": [50364, 2698, 12, 686, 2635, 19997, 420, 2698, 12, 19877, 1287, 300, 321, 393, 380, 6786, 420, 6676, 666, 264, 7523, 783, 1154, 50716], "temperature": 0.0, "avg_logprob": -0.1434673433718474, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.0003459647996351123}, {"id": 211, "seek": 150284, "start": 1509.8799999999999, "end": 1516.1999999999998, "text": " or something like that? Or is it just because, you know, people have abandoned that idea? You know,", "tokens": [50716, 420, 746, 411, 300, 30, 1610, 307, 309, 445, 570, 11, 291, 458, 11, 561, 362, 13732, 300, 1558, 30, 509, 458, 11, 51032], "temperature": 0.0, "avg_logprob": -0.1434673433718474, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.0003459647996351123}, {"id": 212, "seek": 150284, "start": 1516.1999999999998, "end": 1524.36, "text": " it's been, let's see, 60 years, plus since that paper was proposed, computers are millions of times", "tokens": [51032, 309, 311, 668, 11, 718, 311, 536, 11, 4060, 924, 11, 1804, 1670, 300, 3035, 390, 10348, 11, 10807, 366, 6803, 295, 1413, 51440], "temperature": 0.0, "avg_logprob": -0.1434673433718474, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.0003459647996351123}, {"id": 213, "seek": 150284, "start": 1524.9199999999998, "end": 1528.28, "text": " faster, you know, in terms of memory usage and so forth.", "tokens": [51468, 4663, 11, 291, 458, 11, 294, 2115, 295, 4675, 14924, 293, 370, 5220, 13, 51636], "temperature": 0.0, "avg_logprob": -0.1434673433718474, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.0003459647996351123}, {"id": 214, "seek": 152828, "start": 1528.76, "end": 1535.8799999999999, "text": " Our memory availability, and there's been lots of progress in algorithms and programming languages", "tokens": [50388, 2621, 4675, 17945, 11, 293, 456, 311, 668, 3195, 295, 4205, 294, 14642, 293, 9410, 8650, 50744], "temperature": 0.0, "avg_logprob": -0.1229436198870341, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.003483165055513382}, {"id": 215, "seek": 152828, "start": 1535.8799999999999, "end": 1543.3999999999999, "text": " and solvers and large language models and so forth. So, maybe it's possible today to try to build", "tokens": [50744, 293, 1404, 840, 293, 2416, 2856, 5245, 293, 370, 5220, 13, 407, 11, 1310, 309, 311, 1944, 965, 281, 853, 281, 1322, 51120], "temperature": 0.0, "avg_logprob": -0.1229436198870341, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.003483165055513382}, {"id": 216, "seek": 152828, "start": 1543.3999999999999, "end": 1549.8, "text": " something like AdviceTaker, or at least if it's not, to try to understand maybe why that's not", "tokens": [51120, 746, 411, 13634, 573, 51, 4003, 11, 420, 412, 1935, 498, 309, 311, 406, 11, 281, 853, 281, 1223, 1310, 983, 300, 311, 406, 51440], "temperature": 0.0, "avg_logprob": -0.1229436198870341, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.003483165055513382}, {"id": 217, "seek": 152828, "start": 1549.8, "end": 1555.16, "text": " possible. Now, of course, it could be that the reason AdviceTaker hasn't been built is that it", "tokens": [51440, 1944, 13, 823, 11, 295, 1164, 11, 309, 727, 312, 300, 264, 1778, 13634, 573, 51, 4003, 6132, 380, 668, 3094, 307, 300, 309, 51708], "temperature": 0.0, "avg_logprob": -0.1229436198870341, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.003483165055513382}, {"id": 218, "seek": 155516, "start": 1555.16, "end": 1560.28, "text": " would take, you know, maybe a thousand people, you know, 20 years to build it. So, that might be", "tokens": [50364, 576, 747, 11, 291, 458, 11, 1310, 257, 4714, 561, 11, 291, 458, 11, 945, 924, 281, 1322, 309, 13, 407, 11, 300, 1062, 312, 50620], "temperature": 0.0, "avg_logprob": -0.08802403344048394, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.0005527464090846479}, {"id": 219, "seek": 155516, "start": 1560.28, "end": 1568.28, "text": " possible. Or it may be that, you know, something could be built today using off-the-shelf components", "tokens": [50620, 1944, 13, 1610, 309, 815, 312, 300, 11, 291, 458, 11, 746, 727, 312, 3094, 965, 1228, 766, 12, 3322, 12, 46626, 6677, 51020], "temperature": 0.0, "avg_logprob": -0.08802403344048394, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.0005527464090846479}, {"id": 220, "seek": 155516, "start": 1568.28, "end": 1573.5600000000002, "text": " or the solvers we have and things like that. Combining those things that already exist in the", "tokens": [51020, 420, 264, 1404, 840, 321, 362, 293, 721, 411, 300, 13, 25939, 1760, 729, 721, 300, 1217, 2514, 294, 264, 51284], "temperature": 0.0, "avg_logprob": -0.08802403344048394, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.0005527464090846479}, {"id": 221, "seek": 155516, "start": 1573.5600000000002, "end": 1579.96, "text": " creative way, maybe that would be possible for a small number of people to make a lot of progress.", "tokens": [51284, 5880, 636, 11, 1310, 300, 576, 312, 1944, 337, 257, 1359, 1230, 295, 561, 281, 652, 257, 688, 295, 4205, 13, 51604], "temperature": 0.0, "avg_logprob": -0.08802403344048394, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.0005527464090846479}, {"id": 222, "seek": 157996, "start": 1580.04, "end": 1585.32, "text": " So, we're not sure. So, we want to explore, and we want to explore by trying to build things and", "tokens": [50368, 407, 11, 321, 434, 406, 988, 13, 407, 11, 321, 528, 281, 6839, 11, 293, 321, 528, 281, 6839, 538, 1382, 281, 1322, 721, 293, 50632], "temperature": 0.0, "avg_logprob": -0.10664413413222955, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.00041729435906745493}, {"id": 223, "seek": 157996, "start": 1585.32, "end": 1592.2, "text": " figuring out what we find hard, what we find easy, and with nothing else, you know, no other", "tokens": [50632, 15213, 484, 437, 321, 915, 1152, 11, 437, 321, 915, 1858, 11, 293, 365, 1825, 1646, 11, 291, 458, 11, 572, 661, 50976], "temperature": 0.0, "avg_logprob": -0.10664413413222955, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.00041729435906745493}, {"id": 224, "seek": 157996, "start": 1592.2, "end": 1598.04, "text": " objective, at least we hope that by exploring this space, we will encounter interesting things we", "tokens": [50976, 10024, 11, 412, 1935, 321, 1454, 300, 538, 12736, 341, 1901, 11, 321, 486, 8593, 1880, 721, 321, 51268], "temperature": 0.0, "avg_logprob": -0.10664413413222955, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.00041729435906745493}, {"id": 225, "seek": 157996, "start": 1598.04, "end": 1606.92, "text": " want to explore more, even if we can't build something like AdviceTaker. Now, the line of", "tokens": [51268, 528, 281, 6839, 544, 11, 754, 498, 321, 393, 380, 1322, 746, 411, 13634, 573, 51, 4003, 13, 823, 11, 264, 1622, 295, 51712], "temperature": 0.0, "avg_logprob": -0.10664413413222955, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.00041729435906745493}, {"id": 226, "seek": 160692, "start": 1607.0, "end": 1612.3600000000001, "text": " research that I'm starting from has to do with this language called mini-canron that I've been", "tokens": [50368, 2132, 300, 286, 478, 2891, 490, 575, 281, 360, 365, 341, 2856, 1219, 8382, 12, 7035, 2044, 300, 286, 600, 668, 50636], "temperature": 0.0, "avg_logprob": -0.16129993438720702, "compression_ratio": 1.548780487804878, "no_speech_prob": 0.003482942935079336}, {"id": 227, "seek": 160692, "start": 1612.3600000000001, "end": 1620.68, "text": " working on with many people, including Nada and Dan Friedman, Oleg Kostrov, Michael Ballantyne,", "tokens": [50636, 1364, 322, 365, 867, 561, 11, 3009, 40992, 293, 3394, 17605, 1601, 11, 422, 6363, 591, 555, 24088, 11, 5116, 10744, 394, 88, 716, 11, 51052], "temperature": 0.0, "avg_logprob": -0.16129993438720702, "compression_ratio": 1.548780487804878, "no_speech_prob": 0.003482942935079336}, {"id": 228, "seek": 160692, "start": 1620.68, "end": 1626.2, "text": " Rick Rosenblatt, many, many others. I can't name everyone. But a whole bunch of people have worked", "tokens": [51052, 11224, 33630, 5199, 1591, 11, 867, 11, 867, 2357, 13, 286, 393, 380, 1315, 1518, 13, 583, 257, 1379, 3840, 295, 561, 362, 2732, 51328], "temperature": 0.0, "avg_logprob": -0.16129993438720702, "compression_ratio": 1.548780487804878, "no_speech_prob": 0.003482942935079336}, {"id": 229, "seek": 160692, "start": 1626.2, "end": 1636.2, "text": " on this language, going back to Dan Friedman's original implementation of it. And this is a", "tokens": [51328, 322, 341, 2856, 11, 516, 646, 281, 3394, 17605, 1601, 311, 3380, 11420, 295, 309, 13, 400, 341, 307, 257, 51828], "temperature": 0.0, "avg_logprob": -0.16129993438720702, "compression_ratio": 1.548780487804878, "no_speech_prob": 0.003482942935079336}, {"id": 230, "seek": 163620, "start": 1636.2, "end": 1642.44, "text": " mini-canron has basically turned into a constraint logic language, a pure constraint logic language,", "tokens": [50364, 8382, 12, 7035, 2044, 575, 1936, 3574, 666, 257, 25534, 9952, 2856, 11, 257, 6075, 25534, 9952, 2856, 11, 50676], "temperature": 0.0, "avg_logprob": -0.10767646546059466, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.0005032592453062534}, {"id": 231, "seek": 163620, "start": 1642.44, "end": 1649.48, "text": " for doing things like writing interpreters, type inferences, parsers, as pure relations. And that", "tokens": [50676, 337, 884, 721, 411, 3579, 17489, 1559, 11, 2010, 13596, 2667, 11, 21156, 433, 11, 382, 6075, 2299, 13, 400, 300, 51028], "temperature": 0.0, "avg_logprob": -0.10767646546059466, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.0005032592453062534}, {"id": 232, "seek": 163620, "start": 1649.48, "end": 1656.2, "text": " allows you to do types of program synthesis. So, one of the things that came out of that was this", "tokens": [51028, 4045, 291, 281, 360, 3467, 295, 1461, 30252, 13, 407, 11, 472, 295, 264, 721, 300, 1361, 484, 295, 300, 390, 341, 51364], "temperature": 0.0, "avg_logprob": -0.10767646546059466, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.0005032592453062534}, {"id": 233, "seek": 163620, "start": 1656.2, "end": 1664.76, "text": " paper, Unified Approach to Solving Seven Programming Problems, where we show how by writing an", "tokens": [51364, 3035, 11, 1156, 2587, 29551, 608, 281, 7026, 798, 14868, 8338, 2810, 11676, 82, 11, 689, 321, 855, 577, 538, 3579, 364, 51792], "temperature": 0.0, "avg_logprob": -0.10767646546059466, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.0005032592453062534}, {"id": 234, "seek": 166476, "start": 1664.76, "end": 1670.12, "text": " interpreter for a subset of scheme as a pure relation, and then combining that with constraint", "tokens": [50364, 34132, 337, 257, 25993, 295, 12232, 382, 257, 6075, 9721, 11, 293, 550, 21928, 300, 365, 25534, 50632], "temperature": 0.0, "avg_logprob": -0.11422419548034668, "compression_ratio": 1.6986301369863013, "no_speech_prob": 6.204807868925855e-05}, {"id": 235, "seek": 166476, "start": 1670.12, "end": 1677.08, "text": " solving and a special type of search, Oleg Kostrov came up with, it's possible to solve various", "tokens": [50632, 12606, 293, 257, 2121, 2010, 295, 3164, 11, 422, 6363, 591, 555, 24088, 1361, 493, 365, 11, 309, 311, 1944, 281, 5039, 3683, 50980], "temperature": 0.0, "avg_logprob": -0.11422419548034668, "compression_ratio": 1.6986301369863013, "no_speech_prob": 6.204807868925855e-05}, {"id": 236, "seek": 166476, "start": 1677.08, "end": 1683.72, "text": " program synthesis problems in a unified way. And another thing that came out of this is a", "tokens": [50980, 1461, 30252, 2740, 294, 257, 26787, 636, 13, 400, 1071, 551, 300, 1361, 484, 295, 341, 307, 257, 51312], "temperature": 0.0, "avg_logprob": -0.11422419548034668, "compression_ratio": 1.6986301369863013, "no_speech_prob": 6.204807868925855e-05}, {"id": 237, "seek": 166476, "start": 1683.72, "end": 1691.96, "text": " barlerman, this barlerman tool. And so with barlerman, we can do little synthesis problems.", "tokens": [51312, 2159, 75, 11821, 11, 341, 2159, 75, 11821, 2290, 13, 400, 370, 365, 2159, 75, 11821, 11, 321, 393, 360, 707, 30252, 2740, 13, 51724], "temperature": 0.0, "avg_logprob": -0.11422419548034668, "compression_ratio": 1.6986301369863013, "no_speech_prob": 6.204807868925855e-05}, {"id": 238, "seek": 169196, "start": 1691.96, "end": 1699.8, "text": " So, for example, here I want to maybe define append in scheme. So, I can say append of the", "tokens": [50364, 407, 11, 337, 1365, 11, 510, 286, 528, 281, 1310, 6964, 34116, 294, 12232, 13, 407, 11, 286, 393, 584, 34116, 295, 264, 50756], "temperature": 0.0, "avg_logprob": -0.1572786331176758, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00013551754818763584}, {"id": 239, "seek": 169196, "start": 1699.8, "end": 1706.04, "text": " empty list to the empty list is the empty list. All right, so I'm giving you an example. And then", "tokens": [50756, 6707, 1329, 281, 264, 6707, 1329, 307, 264, 6707, 1329, 13, 1057, 558, 11, 370, 286, 478, 2902, 291, 364, 1365, 13, 400, 550, 51068], "temperature": 0.0, "avg_logprob": -0.1572786331176758, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00013551754818763584}, {"id": 240, "seek": 169196, "start": 1706.04, "end": 1711.64, "text": " the system is going to try to fill in basically a template where comma a, comma b, and comma c", "tokens": [51068, 264, 1185, 307, 516, 281, 853, 281, 2836, 294, 1936, 257, 12379, 689, 22117, 257, 11, 22117, 272, 11, 293, 22117, 269, 51348], "temperature": 0.0, "avg_logprob": -0.1572786331176758, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00013551754818763584}, {"id": 241, "seek": 169196, "start": 1712.28, "end": 1720.2, "text": " are holes or logic variables with no value associated with them, representing holes. And", "tokens": [51380, 366, 8118, 420, 9952, 9102, 365, 572, 2158, 6615, 365, 552, 11, 13460, 8118, 13, 400, 51776], "temperature": 0.0, "avg_logprob": -0.1572786331176758, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00013551754818763584}, {"id": 242, "seek": 172020, "start": 1720.8400000000001, "end": 1727.4, "text": " then, in this case, the, this is the constant function that always returns the empty list has", "tokens": [50396, 550, 11, 294, 341, 1389, 11, 264, 11, 341, 307, 264, 5754, 2445, 300, 1009, 11247, 264, 6707, 1329, 575, 50724], "temperature": 0.0, "avg_logprob": -0.15264338443153783, "compression_ratio": 1.665137614678899, "no_speech_prob": 8.7501342932228e-05}, {"id": 243, "seek": 172020, "start": 1727.4, "end": 1734.68, "text": " been synthesized, which is correct, but not very interesting. So, we can try, say, what happens", "tokens": [50724, 668, 26617, 1602, 11, 597, 307, 3006, 11, 457, 406, 588, 1880, 13, 407, 11, 321, 393, 853, 11, 584, 11, 437, 2314, 51088], "temperature": 0.0, "avg_logprob": -0.15264338443153783, "compression_ratio": 1.665137614678899, "no_speech_prob": 8.7501342932228e-05}, {"id": 244, "seek": 172020, "start": 1734.68, "end": 1741.96, "text": " if we append the list cat to list dog, we should get back the list cat dog. And now,", "tokens": [51088, 498, 321, 34116, 264, 1329, 3857, 281, 1329, 3000, 11, 321, 820, 483, 646, 264, 1329, 3857, 3000, 13, 400, 586, 11, 51452], "temperature": 0.0, "avg_logprob": -0.15264338443153783, "compression_ratio": 1.665137614678899, "no_speech_prob": 8.7501342932228e-05}, {"id": 245, "seek": 172020, "start": 1743.24, "end": 1746.6000000000001, "text": " barlerman has to do a little more work and tries to come up with something a little more", "tokens": [51516, 2159, 75, 11821, 575, 281, 360, 257, 707, 544, 589, 293, 9898, 281, 808, 493, 365, 746, 257, 707, 544, 51684], "temperature": 0.0, "avg_logprob": -0.15264338443153783, "compression_ratio": 1.665137614678899, "no_speech_prob": 8.7501342932228e-05}, {"id": 246, "seek": 174660, "start": 1746.6, "end": 1752.6799999999998, "text": " complicated, but it still is missing the recursion. So, we can try doing one more call. So, let's do", "tokens": [50364, 6179, 11, 457, 309, 920, 307, 5361, 264, 20560, 313, 13, 407, 11, 321, 393, 853, 884, 472, 544, 818, 13, 407, 11, 718, 311, 360, 50668], "temperature": 0.0, "avg_logprob": -0.11411613073104467, "compression_ratio": 1.5026737967914439, "no_speech_prob": 8.75016994541511e-05}, {"id": 247, "seek": 174660, "start": 1753.48, "end": 1766.6799999999998, "text": " how about ABC to DE to get ABCDE. And hopefully, barlerman will be able to synthesize the recursion.", "tokens": [50708, 577, 466, 22342, 281, 10113, 281, 483, 22342, 22296, 13, 400, 4696, 11, 2159, 75, 11821, 486, 312, 1075, 281, 26617, 1125, 264, 20560, 313, 13, 51368], "temperature": 0.0, "avg_logprob": -0.11411613073104467, "compression_ratio": 1.5026737967914439, "no_speech_prob": 8.75016994541511e-05}, {"id": 248, "seek": 174660, "start": 1767.7199999999998, "end": 1771.8799999999999, "text": " In any case, you can see that we're doing a type of example directed synthesis.", "tokens": [51420, 682, 604, 1389, 11, 291, 393, 536, 300, 321, 434, 884, 257, 2010, 295, 1365, 12898, 30252, 13, 51628], "temperature": 0.0, "avg_logprob": -0.11411613073104467, "compression_ratio": 1.5026737967914439, "no_speech_prob": 8.75016994541511e-05}, {"id": 249, "seek": 177188, "start": 1772.8400000000001, "end": 1779.8000000000002, "text": " And, you know, under the hood, barlerman uses constraint solving, unification, things like that,", "tokens": [50412, 400, 11, 291, 458, 11, 833, 264, 13376, 11, 2159, 75, 11821, 4960, 25534, 12606, 11, 517, 3774, 11, 721, 411, 300, 11, 50760], "temperature": 0.0, "avg_logprob": -0.20406716748287804, "compression_ratio": 1.5815217391304348, "no_speech_prob": 0.0003682890092022717}, {"id": 250, "seek": 177188, "start": 1779.8000000000002, "end": 1790.44, "text": " also has type constraints with numbers and, and symbols, and does a, a type of complete interleaving", "tokens": [50760, 611, 575, 2010, 18491, 365, 3547, 293, 11, 293, 16944, 11, 293, 775, 257, 11, 257, 2010, 295, 3566, 728, 306, 6152, 51292], "temperature": 0.0, "avg_logprob": -0.20406716748287804, "compression_ratio": 1.5815217391304348, "no_speech_prob": 0.0003682890092022717}, {"id": 251, "seek": 177188, "start": 1790.44, "end": 1800.0400000000002, "text": " search. And sometimes barlerman gets stuck. You know, so barlerman is not an example of smart", "tokens": [51292, 3164, 13, 400, 2171, 2159, 75, 11821, 2170, 5541, 13, 509, 458, 11, 370, 2159, 75, 11821, 307, 406, 364, 1365, 295, 4069, 51772], "temperature": 0.0, "avg_logprob": -0.20406716748287804, "compression_ratio": 1.5815217391304348, "no_speech_prob": 0.0003682890092022717}, {"id": 252, "seek": 180004, "start": 1800.12, "end": 1807.0, "text": " software, we're in, in the McCarthy notion. Barlerman will often get stuck. However,", "tokens": [50368, 4722, 11, 321, 434, 294, 11, 294, 264, 44085, 10710, 13, 4156, 75, 11821, 486, 2049, 483, 5541, 13, 2908, 11, 50712], "temperature": 0.0, "avg_logprob": -0.10676815440353837, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0008040572865866125}, {"id": 253, "seek": 180004, "start": 1808.12, "end": 1814.6, "text": " in certain cases, at least when there's enough context filled in, barlerman can be relatively", "tokens": [50768, 294, 1629, 3331, 11, 412, 1935, 562, 456, 311, 1547, 4319, 6412, 294, 11, 2159, 75, 11821, 393, 312, 7226, 51092], "temperature": 0.0, "avg_logprob": -0.10676815440353837, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0008040572865866125}, {"id": 254, "seek": 180004, "start": 1814.6, "end": 1819.0, "text": " fast. So, right now, it's taking barlerman a while. So, let's just fill in a little more", "tokens": [51092, 2370, 13, 407, 11, 558, 586, 11, 309, 311, 1940, 2159, 75, 11821, 257, 1339, 13, 407, 11, 718, 311, 445, 2836, 294, 257, 707, 544, 51312], "temperature": 0.0, "avg_logprob": -0.10676815440353837, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0008040572865866125}, {"id": 255, "seek": 180004, "start": 1820.52, "end": 1826.76, "text": " of the template here. So, I'll, I'll say that we're defying a function called a pen, which takes", "tokens": [51388, 295, 264, 12379, 510, 13, 407, 11, 286, 603, 11, 286, 603, 584, 300, 321, 434, 1060, 1840, 257, 2445, 1219, 257, 3435, 11, 597, 2516, 51700], "temperature": 0.0, "avg_logprob": -0.10676815440353837, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0008040572865866125}, {"id": 256, "seek": 182676, "start": 1826.76, "end": 1834.12, "text": " two arguments, call them L and S, see if this speeds it up any. And, you know, a human can look", "tokens": [50364, 732, 12869, 11, 818, 552, 441, 293, 318, 11, 536, 498, 341, 16411, 309, 493, 604, 13, 400, 11, 291, 458, 11, 257, 1952, 393, 574, 50732], "temperature": 0.0, "avg_logprob": -0.09921269721173226, "compression_ratio": 1.7085201793721974, "no_speech_prob": 9.915030386764556e-05}, {"id": 257, "seek": 182676, "start": 1834.12, "end": 1839.96, "text": " at these examples and figure out things like the name of the function should be append. A human", "tokens": [50732, 412, 613, 5110, 293, 2573, 484, 721, 411, 264, 1315, 295, 264, 2445, 820, 312, 34116, 13, 316, 1952, 51024], "temperature": 0.0, "avg_logprob": -0.09921269721173226, "compression_ratio": 1.7085201793721974, "no_speech_prob": 9.915030386764556e-05}, {"id": 258, "seek": 182676, "start": 1839.96, "end": 1847.48, "text": " could also look at the fact that all three of these examples include two arguments. Now, in this", "tokens": [51024, 727, 611, 574, 412, 264, 1186, 300, 439, 1045, 295, 613, 5110, 4090, 732, 12869, 13, 823, 11, 294, 341, 51400], "temperature": 0.0, "avg_logprob": -0.09921269721173226, "compression_ratio": 1.7085201793721974, "no_speech_prob": 9.915030386764556e-05}, {"id": 259, "seek": 182676, "start": 1847.48, "end": 1852.12, "text": " case, they're both lists, although append in general and scheme, the second argument doesn't", "tokens": [51400, 1389, 11, 436, 434, 1293, 14511, 11, 4878, 34116, 294, 2674, 293, 12232, 11, 264, 1150, 6770, 1177, 380, 51632], "temperature": 0.0, "avg_logprob": -0.09921269721173226, "compression_ratio": 1.7085201793721974, "no_speech_prob": 9.915030386764556e-05}, {"id": 260, "seek": 185212, "start": 1852.12, "end": 1859.32, "text": " have to be a list, but that might help. Another thing we can give is a help, it's help if we want", "tokens": [50364, 362, 281, 312, 257, 1329, 11, 457, 300, 1062, 854, 13, 3996, 551, 321, 393, 976, 307, 257, 854, 11, 309, 311, 854, 498, 321, 528, 50724], "temperature": 0.0, "avg_logprob": -0.1193070295380383, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.0009399031405337155}, {"id": 261, "seek": 185212, "start": 1859.32, "end": 1869.1599999999999, "text": " to is, you know, we might say, hey, because this appears to be a recursive function, we maybe can", "tokens": [50724, 281, 307, 11, 291, 458, 11, 321, 1062, 584, 11, 4177, 11, 570, 341, 7038, 281, 312, 257, 20560, 488, 2445, 11, 321, 1310, 393, 51216], "temperature": 0.0, "avg_logprob": -0.1193070295380383, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.0009399031405337155}, {"id": 262, "seek": 185212, "start": 1869.1599999999999, "end": 1876.1999999999998, "text": " give it a barlerman a little more help like that and say that, well, since we have a list", "tokens": [51216, 976, 309, 257, 2159, 75, 11821, 257, 707, 544, 854, 411, 300, 293, 584, 300, 11, 731, 11, 1670, 321, 362, 257, 1329, 51568], "temperature": 0.0, "avg_logprob": -0.1193070295380383, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.0009399031405337155}, {"id": 263, "seek": 187620, "start": 1876.8400000000001, "end": 1882.2, "text": " in the first position, we're going to guess that we're going to check if the list is empty.", "tokens": [50396, 294, 264, 700, 2535, 11, 321, 434, 516, 281, 2041, 300, 321, 434, 516, 281, 1520, 498, 264, 1329, 307, 6707, 13, 50664], "temperature": 0.0, "avg_logprob": -0.15999188246550383, "compression_ratio": 1.4921875, "no_speech_prob": 0.002980816876515746}, {"id": 264, "seek": 187620, "start": 1882.92, "end": 1892.28, "text": " Otherwise, we're going to do one of two recursive calls. So, that might help.", "tokens": [50700, 10328, 11, 321, 434, 516, 281, 360, 472, 295, 732, 20560, 488, 5498, 13, 407, 11, 300, 1062, 854, 13, 51168], "temperature": 0.0, "avg_logprob": -0.15999188246550383, "compression_ratio": 1.4921875, "no_speech_prob": 0.002980816876515746}, {"id": 265, "seek": 187620, "start": 1899.64, "end": 1904.28, "text": " Might need more help.", "tokens": [51536, 23964, 643, 544, 854, 13, 51768], "temperature": 0.0, "avg_logprob": -0.15999188246550383, "compression_ratio": 1.4921875, "no_speech_prob": 0.002980816876515746}, {"id": 266, "seek": 190620, "start": 1907.16, "end": 1908.52, "text": " How much help does it need?", "tokens": [50412, 1012, 709, 854, 775, 309, 643, 30, 50480], "temperature": 0.0, "avg_logprob": -0.17355176879138481, "compression_ratio": 1.477832512315271, "no_speech_prob": 6.81468955008313e-05}, {"id": 267, "seek": 190620, "start": 1911.8, "end": 1912.3600000000001, "text": " Let's see.", "tokens": [50644, 961, 311, 536, 13, 50672], "temperature": 0.0, "avg_logprob": -0.17355176879138481, "compression_ratio": 1.477832512315271, "no_speech_prob": 6.81468955008313e-05}, {"id": 268, "seek": 190620, "start": 1915.4, "end": 1922.52, "text": " Okay. So, in this case, it figured it out. I think the fact that I'm recording a video right now", "tokens": [50824, 1033, 13, 407, 11, 294, 341, 1389, 11, 309, 8932, 309, 484, 13, 286, 519, 264, 1186, 300, 286, 478, 6613, 257, 960, 558, 586, 51180], "temperature": 0.0, "avg_logprob": -0.17355176879138481, "compression_ratio": 1.477832512315271, "no_speech_prob": 6.81468955008313e-05}, {"id": 269, "seek": 190620, "start": 1922.52, "end": 1927.32, "text": " is slowing down the the processor enough that we're using enough memory that", "tokens": [51180, 307, 26958, 760, 264, 264, 15321, 1547, 300, 321, 434, 1228, 1547, 4675, 300, 51420], "temperature": 0.0, "avg_logprob": -0.17355176879138481, "compression_ratio": 1.477832512315271, "no_speech_prob": 6.81468955008313e-05}, {"id": 270, "seek": 190620, "start": 1928.3600000000001, "end": 1933.0800000000002, "text": " the barlomens having a little more trouble than usual. There are some tricks we can use", "tokens": [51472, 264, 2159, 75, 298, 694, 1419, 257, 707, 544, 5253, 813, 7713, 13, 821, 366, 512, 11733, 321, 393, 764, 51708], "temperature": 0.0, "avg_logprob": -0.17355176879138481, "compression_ratio": 1.477832512315271, "no_speech_prob": 6.81468955008313e-05}, {"id": 271, "seek": 193308, "start": 1933.1599999999999, "end": 1938.6799999999998, "text": " to give barlerman hints. But you could see part of it was I was able to fill out", "tokens": [50368, 281, 976, 2159, 75, 11821, 27271, 13, 583, 291, 727, 536, 644, 295, 309, 390, 286, 390, 1075, 281, 2836, 484, 50644], "temperature": 0.0, "avg_logprob": -0.0945169614708942, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.0009109824313782156}, {"id": 272, "seek": 193308, "start": 1939.72, "end": 1946.76, "text": " some of the structure. So, I could guess, you know, even a beginning scheme programmer,", "tokens": [50696, 512, 295, 264, 3877, 13, 407, 11, 286, 727, 2041, 11, 291, 458, 11, 754, 257, 2863, 12232, 32116, 11, 51048], "temperature": 0.0, "avg_logprob": -0.0945169614708942, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.0009109824313782156}, {"id": 273, "seek": 193308, "start": 1946.76, "end": 1952.1999999999998, "text": " we would teach certain heuristics to. So, for example, all right, given these examples,", "tokens": [51048, 321, 576, 2924, 1629, 415, 374, 6006, 281, 13, 407, 11, 337, 1365, 11, 439, 558, 11, 2212, 613, 5110, 11, 51320], "temperature": 0.0, "avg_logprob": -0.0945169614708942, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.0009109824313782156}, {"id": 274, "seek": 193308, "start": 1952.1999999999998, "end": 1957.3999999999999, "text": " well, we know we're defining a function called append, we can guess at least that the function", "tokens": [51320, 731, 11, 321, 458, 321, 434, 17827, 257, 2445, 1219, 34116, 11, 321, 393, 2041, 412, 1935, 300, 264, 2445, 51580], "temperature": 0.0, "avg_logprob": -0.0945169614708942, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.0009109824313782156}, {"id": 275, "seek": 195740, "start": 1957.4, "end": 1962.92, "text": " takes two arguments. It might take more than two arguments, or it might take a variable number of", "tokens": [50364, 2516, 732, 12869, 13, 467, 1062, 747, 544, 813, 732, 12869, 11, 420, 309, 1062, 747, 257, 7006, 1230, 295, 50640], "temperature": 0.0, "avg_logprob": -0.1433026624280353, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0010649210307747126}, {"id": 276, "seek": 195740, "start": 1962.92, "end": 1968.1200000000001, "text": " arguments. You know, so maybe it takes zero or more arguments. In fact, the full scheme append", "tokens": [50640, 12869, 13, 509, 458, 11, 370, 1310, 309, 2516, 4018, 420, 544, 12869, 13, 682, 1186, 11, 264, 1577, 12232, 34116, 50900], "temperature": 0.0, "avg_logprob": -0.1433026624280353, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0010649210307747126}, {"id": 277, "seek": 195740, "start": 1969.0, "end": 1974.1200000000001, "text": " can take any number of lists. In this case, we could do a two argument", "tokens": [50944, 393, 747, 604, 1230, 295, 14511, 13, 682, 341, 1389, 11, 321, 727, 360, 257, 732, 6770, 51200], "temperature": 0.0, "avg_logprob": -0.1433026624280353, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0010649210307747126}, {"id": 278, "seek": 195740, "start": 1975.5600000000002, "end": 1983.5600000000002, "text": " synthesis. And if we guess that append should be recursive because we have lists of different", "tokens": [51272, 30252, 13, 400, 498, 321, 2041, 300, 34116, 820, 312, 20560, 488, 570, 321, 362, 14511, 295, 819, 51672], "temperature": 0.0, "avg_logprob": -0.1433026624280353, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0010649210307747126}, {"id": 279, "seek": 198356, "start": 1983.56, "end": 1990.12, "text": " lengths, then if we also guess that we're recurring on the first argument, then we can", "tokens": [50364, 26329, 11, 550, 498, 321, 611, 2041, 300, 321, 434, 32279, 322, 264, 700, 6770, 11, 550, 321, 393, 50692], "temperature": 0.0, "avg_logprob": -0.08612349692811357, "compression_ratio": 1.7511737089201878, "no_speech_prob": 0.00019109768618363887}, {"id": 280, "seek": 198356, "start": 1990.12, "end": 1994.04, "text": " probably figure out a lot of the structure of the program automatically. And then we might also", "tokens": [50692, 1391, 2573, 484, 257, 688, 295, 264, 3877, 295, 264, 1461, 6772, 13, 400, 550, 321, 1062, 611, 50888], "temperature": 0.0, "avg_logprob": -0.08612349692811357, "compression_ratio": 1.7511737089201878, "no_speech_prob": 0.00019109768618363887}, {"id": 281, "seek": 198356, "start": 1994.04, "end": 2000.12, "text": " be able to figure out things like, well, maybe we don't know what the base case is. And so,", "tokens": [50888, 312, 1075, 281, 2573, 484, 721, 411, 11, 731, 11, 1310, 321, 500, 380, 458, 437, 264, 3096, 1389, 307, 13, 400, 370, 11, 51192], "temperature": 0.0, "avg_logprob": -0.08612349692811357, "compression_ratio": 1.7511737089201878, "no_speech_prob": 0.00019109768618363887}, {"id": 282, "seek": 198356, "start": 2000.12, "end": 2004.6799999999998, "text": " in this case, it's still still can synthesize the program, even not knowing what the base case is.", "tokens": [51192, 294, 341, 1389, 11, 309, 311, 920, 920, 393, 26617, 1125, 264, 1461, 11, 754, 406, 5276, 437, 264, 3096, 1389, 307, 13, 51420], "temperature": 0.0, "avg_logprob": -0.08612349692811357, "compression_ratio": 1.7511737089201878, "no_speech_prob": 0.00019109768618363887}, {"id": 283, "seek": 200468, "start": 2005.64, "end": 2010.04, "text": " So, we could, you know, create a little bit of a skeleton of a program,", "tokens": [50412, 407, 11, 321, 727, 11, 291, 458, 11, 1884, 257, 707, 857, 295, 257, 25204, 295, 257, 1461, 11, 50632], "temperature": 0.0, "avg_logprob": -0.14057429631551108, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0001398194144712761}, {"id": 284, "seek": 200468, "start": 2011.88, "end": 2017.5600000000002, "text": " just from looking at these examples and following a few heuristics. And then Barleman,", "tokens": [50724, 445, 490, 1237, 412, 613, 5110, 293, 3480, 257, 1326, 415, 374, 6006, 13, 400, 550, 4156, 306, 1601, 11, 51008], "temperature": 0.0, "avg_logprob": -0.14057429631551108, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0001398194144712761}, {"id": 285, "seek": 200468, "start": 2017.5600000000002, "end": 2024.76, "text": " even though it's dealing with this exponential search, could get enough of a hint that it", "tokens": [51008, 754, 1673, 309, 311, 6260, 365, 341, 21510, 3164, 11, 727, 483, 1547, 295, 257, 12075, 300, 309, 51368], "temperature": 0.0, "avg_logprob": -0.14057429631551108, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0001398194144712761}, {"id": 286, "seek": 200468, "start": 2024.76, "end": 2031.0, "text": " can finish synthesizing the rest of the program. Okay, so that's an example of how Barleman,", "tokens": [51368, 393, 2413, 26617, 3319, 264, 1472, 295, 264, 1461, 13, 1033, 11, 370, 300, 311, 364, 1365, 295, 577, 4156, 306, 1601, 11, 51680], "temperature": 0.0, "avg_logprob": -0.14057429631551108, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0001398194144712761}, {"id": 287, "seek": 203100, "start": 2031.08, "end": 2037.8, "text": " which isn't very smart, could be called from a smarter program that can do introspection on", "tokens": [50368, 597, 1943, 380, 588, 4069, 11, 727, 312, 1219, 490, 257, 20294, 1461, 300, 393, 360, 560, 2635, 19997, 322, 50704], "temperature": 0.0, "avg_logprob": -0.0920952000195467, "compression_ratio": 1.6729857819905214, "no_speech_prob": 0.0001852183195296675}, {"id": 288, "seek": 203100, "start": 2037.8, "end": 2044.2, "text": " the examples. And the smarter program could then provide a template or skeleton or sketch", "tokens": [50704, 264, 5110, 13, 400, 264, 20294, 1461, 727, 550, 2893, 257, 12379, 420, 25204, 420, 12325, 51024], "temperature": 0.0, "avg_logprob": -0.0920952000195467, "compression_ratio": 1.6729857819905214, "no_speech_prob": 0.0001852183195296675}, {"id": 289, "seek": 203100, "start": 2044.2, "end": 2049.24, "text": " of the program to be synthesized based on what it observes from things like the tests or", "tokens": [51024, 295, 264, 1461, 281, 312, 26617, 1602, 2361, 322, 437, 309, 3181, 9054, 490, 721, 411, 264, 6921, 420, 51276], "temperature": 0.0, "avg_logprob": -0.0920952000195467, "compression_ratio": 1.6729857819905214, "no_speech_prob": 0.0001852183195296675}, {"id": 290, "seek": 203100, "start": 2050.28, "end": 2055.08, "text": " some sort of specification provided maybe by human or by another computer program.", "tokens": [51328, 512, 1333, 295, 31256, 5649, 1310, 538, 1952, 420, 538, 1071, 3820, 1461, 13, 51568], "temperature": 0.0, "avg_logprob": -0.0920952000195467, "compression_ratio": 1.6729857819905214, "no_speech_prob": 0.0001852183195296675}, {"id": 291, "seek": 205508, "start": 2055.96, "end": 2063.56, "text": " So, this idea of using Barleman basically as an external solver is part of what we're trying", "tokens": [50408, 407, 11, 341, 1558, 295, 1228, 4156, 306, 1601, 1936, 382, 364, 8320, 1404, 331, 307, 644, 295, 437, 321, 434, 1382, 50788], "temperature": 0.0, "avg_logprob": -0.0893200580890362, "compression_ratio": 1.458100558659218, "no_speech_prob": 0.0001123414549510926}, {"id": 292, "seek": 205508, "start": 2063.56, "end": 2074.84, "text": " to explore as well. I should also mention that the software that we're developing", "tokens": [50788, 281, 6839, 382, 731, 13, 286, 820, 611, 2152, 300, 264, 4722, 300, 321, 434, 6416, 51352], "temperature": 0.0, "avg_logprob": -0.0893200580890362, "compression_ratio": 1.458100558659218, "no_speech_prob": 0.0001123414549510926}, {"id": 293, "seek": 205508, "start": 2075.7999999999997, "end": 2082.52, "text": " might also benefit from some of the ideas in Chris Hansen and Jerry Sussman's software", "tokens": [51400, 1062, 611, 5121, 490, 512, 295, 264, 3487, 294, 6688, 17926, 268, 293, 17454, 318, 2023, 1601, 311, 4722, 51736], "temperature": 0.0, "avg_logprob": -0.0893200580890362, "compression_ratio": 1.458100558659218, "no_speech_prob": 0.0001123414549510926}, {"id": 294, "seek": 208252, "start": 2082.52, "end": 2090.44, "text": " designed for flexibility. And this book is, in some ways, the intellectual successor to", "tokens": [50364, 4761, 337, 12635, 13, 400, 341, 1446, 307, 11, 294, 512, 2098, 11, 264, 12576, 31864, 281, 50760], "temperature": 0.0, "avg_logprob": -0.13538113286939718, "compression_ratio": 1.4578947368421054, "no_speech_prob": 0.00037996305036358535}, {"id": 295, "seek": 208252, "start": 2090.44, "end": 2097.16, "text": " structure an interpretation of computer programs by Abelson and Sussman, but can also be thought of", "tokens": [50760, 3877, 364, 14174, 295, 3820, 4268, 538, 2847, 20471, 293, 318, 2023, 1601, 11, 457, 393, 611, 312, 1194, 295, 51096], "temperature": 0.0, "avg_logprob": -0.13538113286939718, "compression_ratio": 1.4578947368421054, "no_speech_prob": 0.00037996305036358535}, {"id": 296, "seek": 208252, "start": 2097.16, "end": 2106.44, "text": " as lessons taken from artificial intelligence programming out of MIT and in the corporate", "tokens": [51096, 382, 8820, 2726, 490, 11677, 7599, 9410, 484, 295, 13100, 293, 294, 264, 10896, 51560], "temperature": 0.0, "avg_logprob": -0.13538113286939718, "compression_ratio": 1.4578947368421054, "no_speech_prob": 0.00037996305036358535}, {"id": 297, "seek": 210644, "start": 2106.44, "end": 2115.48, "text": " world as well, distilled so you can use them in various other software projects. And Jerry Sussman", "tokens": [50364, 1002, 382, 731, 11, 1483, 6261, 370, 291, 393, 764, 552, 294, 3683, 661, 4722, 4455, 13, 400, 17454, 318, 2023, 1601, 50816], "temperature": 0.0, "avg_logprob": -0.10311769757952009, "compression_ratio": 1.475, "no_speech_prob": 0.016398239880800247}, {"id": 298, "seek": 210644, "start": 2115.48, "end": 2123.0, "text": " gave a nice talk in 2022 at the Scheme Workshop, which is available on YouTube, where he talks about", "tokens": [50816, 2729, 257, 1481, 751, 294, 20229, 412, 264, 2065, 5729, 48366, 11, 597, 307, 2435, 322, 3088, 11, 689, 415, 6686, 466, 51192], "temperature": 0.0, "avg_logprob": -0.10311769757952009, "compression_ratio": 1.475, "no_speech_prob": 0.016398239880800247}, {"id": 299, "seek": 210644, "start": 2123.0, "end": 2128.76, "text": " one of these patterns, which is called layering, where you can add things like meta information", "tokens": [51192, 472, 295, 613, 8294, 11, 597, 307, 1219, 40754, 11, 689, 291, 393, 909, 721, 411, 19616, 1589, 51480], "temperature": 0.0, "avg_logprob": -0.10311769757952009, "compression_ratio": 1.475, "no_speech_prob": 0.016398239880800247}, {"id": 300, "seek": 212876, "start": 2128.76, "end": 2137.0, "text": " you want to keep track to in an intelligent piece of software through this layering technique. So,", "tokens": [50364, 291, 528, 281, 1066, 2837, 281, 294, 364, 13232, 2522, 295, 4722, 807, 341, 40754, 6532, 13, 407, 11, 50776], "temperature": 0.0, "avg_logprob": -0.15062369552313112, "compression_ratio": 1.2986111111111112, "no_speech_prob": 0.01032583974301815}, {"id": 301, "seek": 212876, "start": 2137.0, "end": 2150.92, "text": " that's worth looking at. Okay, so let's look at BAT, which is the Barleman advice taker.", "tokens": [50776, 300, 311, 3163, 1237, 412, 13, 1033, 11, 370, 718, 311, 574, 412, 363, 2218, 11, 597, 307, 264, 4156, 306, 1601, 5192, 991, 260, 13, 51472], "temperature": 0.0, "avg_logprob": -0.15062369552313112, "compression_ratio": 1.2986111111111112, "no_speech_prob": 0.01032583974301815}, {"id": 302, "seek": 215092, "start": 2151.7200000000003, "end": 2159.7200000000003, "text": " Now, BAT itself, even though if we ever release it, we're probably going to release it under an MIT", "tokens": [50404, 823, 11, 363, 2218, 2564, 11, 754, 1673, 498, 321, 1562, 4374, 309, 11, 321, 434, 1391, 516, 281, 4374, 309, 833, 364, 13100, 50804], "temperature": 0.0, "avg_logprob": -0.1472069092516629, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.028000619262456894}, {"id": 303, "seek": 215092, "start": 2159.7200000000003, "end": 2165.8, "text": " license. This BAT project, the Barleman advice taker that Nada and I are working on, has not yet", "tokens": [50804, 10476, 13, 639, 363, 2218, 1716, 11, 264, 4156, 306, 1601, 5192, 991, 260, 300, 40992, 293, 286, 366, 1364, 322, 11, 575, 406, 1939, 51108], "temperature": 0.0, "avg_logprob": -0.1472069092516629, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.028000619262456894}, {"id": 304, "seek": 215092, "start": 2165.8, "end": 2171.7200000000003, "text": " been released, and we're not sure if or when we will release it. Right now, it's in very early", "tokens": [51108, 668, 4736, 11, 293, 321, 434, 406, 988, 498, 420, 562, 321, 486, 4374, 309, 13, 1779, 586, 11, 309, 311, 294, 588, 2440, 51404], "temperature": 0.0, "avg_logprob": -0.1472069092516629, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.028000619262456894}, {"id": 305, "seek": 215092, "start": 2171.7200000000003, "end": 2178.04, "text": " stages, and we're just exploring some of the ideas that I've been talking about. And I'll walk you", "tokens": [51404, 10232, 11, 293, 321, 434, 445, 12736, 512, 295, 264, 3487, 300, 286, 600, 668, 1417, 466, 13, 400, 286, 603, 1792, 291, 51720], "temperature": 0.0, "avg_logprob": -0.1472069092516629, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.028000619262456894}, {"id": 306, "seek": 217804, "start": 2178.84, "end": 2185.64, "text": " through some of the code and some of the examples to see where we're trying to go. But it is the case", "tokens": [50404, 807, 512, 295, 264, 3089, 293, 512, 295, 264, 5110, 281, 536, 689, 321, 434, 1382, 281, 352, 13, 583, 309, 307, 264, 1389, 50744], "temperature": 0.0, "avg_logprob": -0.09865150451660157, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.00035694142570719123}, {"id": 307, "seek": 217804, "start": 2185.64, "end": 2193.32, "text": " that we're still very early in the development of the software, and it's quite messy. A number of", "tokens": [50744, 300, 321, 434, 920, 588, 2440, 294, 264, 3250, 295, 264, 4722, 11, 293, 309, 311, 1596, 16191, 13, 316, 1230, 295, 51128], "temperature": 0.0, "avg_logprob": -0.09865150451660157, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.00035694142570719123}, {"id": 308, "seek": 217804, "start": 2193.32, "end": 2199.48, "text": " the files here need to be removed or cleaned up. We need to have documentation and more tests and", "tokens": [51128, 264, 7098, 510, 643, 281, 312, 7261, 420, 16146, 493, 13, 492, 643, 281, 362, 14333, 293, 544, 6921, 293, 51436], "temperature": 0.0, "avg_logprob": -0.09865150451660157, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.00035694142570719123}, {"id": 309, "seek": 217804, "start": 2199.48, "end": 2205.4, "text": " things like that. And so, it'll just be a while before we'd be in a position where we want to", "tokens": [51436, 721, 411, 300, 13, 400, 370, 11, 309, 603, 445, 312, 257, 1339, 949, 321, 1116, 312, 294, 257, 2535, 689, 321, 528, 281, 51732], "temperature": 0.0, "avg_logprob": -0.09865150451660157, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.00035694142570719123}, {"id": 310, "seek": 220540, "start": 2205.48, "end": 2211.96, "text": " release it, and we'd also want it to be more capable. But the other part, the other reason,", "tokens": [50368, 4374, 309, 11, 293, 321, 1116, 611, 528, 309, 281, 312, 544, 8189, 13, 583, 264, 661, 644, 11, 264, 661, 1778, 11, 50692], "temperature": 0.0, "avg_logprob": -0.08984876448108305, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.0008039972162805498}, {"id": 311, "seek": 220540, "start": 2211.96, "end": 2219.0, "text": " at least I'm hesitant to release it right now, is that the ideas and the papers that I've been", "tokens": [50692, 412, 1935, 286, 478, 36290, 281, 4374, 309, 558, 586, 11, 307, 300, 264, 3487, 293, 264, 10577, 300, 286, 600, 668, 51044], "temperature": 0.0, "avg_logprob": -0.08984876448108305, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.0008039972162805498}, {"id": 312, "seek": 220540, "start": 2219.0, "end": 2227.96, "text": " showing, those ideas have existed for a long time, and anyone who's smart and creative and", "tokens": [51044, 4099, 11, 729, 3487, 362, 13135, 337, 257, 938, 565, 11, 293, 2878, 567, 311, 4069, 293, 5880, 293, 51492], "temperature": 0.0, "avg_logprob": -0.08984876448108305, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.0008039972162805498}, {"id": 313, "seek": 220540, "start": 2227.96, "end": 2233.8, "text": " thinks hard about those ideas and is inspired by them, could use their own approach to try to", "tokens": [51492, 7309, 1152, 466, 729, 3487, 293, 307, 7547, 538, 552, 11, 727, 764, 641, 1065, 3109, 281, 853, 281, 51784], "temperature": 0.0, "avg_logprob": -0.08984876448108305, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.0008039972162805498}, {"id": 314, "seek": 223380, "start": 2233.8, "end": 2239.7200000000003, "text": " build something like AdviceTaker or build something like what Doyle was envisioning with a", "tokens": [50364, 1322, 746, 411, 13634, 573, 51, 4003, 420, 1322, 746, 411, 437, 40059, 306, 390, 24739, 278, 365, 257, 50660], "temperature": 0.0, "avg_logprob": -0.15202441657941365, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.00020985535229556262}, {"id": 315, "seek": 223380, "start": 2239.7200000000003, "end": 2247.7200000000003, "text": " metacircular reflexive interpreter. And so, the fact that we're building something that uses scheme,", "tokens": [50660, 1131, 326, 347, 17792, 23802, 488, 34132, 13, 400, 370, 11, 264, 1186, 300, 321, 434, 2390, 746, 300, 4960, 12232, 11, 51060], "temperature": 0.0, "avg_logprob": -0.15202441657941365, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.00020985535229556262}, {"id": 316, "seek": 223380, "start": 2247.7200000000003, "end": 2255.4, "text": " shea scheme, mini-canron, barlerman, you know, scheme interpreter written as a relation and", "tokens": [51060, 750, 64, 12232, 11, 8382, 12, 7035, 2044, 11, 2159, 75, 11821, 11, 291, 458, 11, 12232, 34132, 3720, 382, 257, 9721, 293, 51444], "temperature": 0.0, "avg_logprob": -0.15202441657941365, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.00020985535229556262}, {"id": 317, "seek": 223380, "start": 2255.4, "end": 2260.36, "text": " mini-canron and all those sorts of things, that doesn't mean that that's the only way to approach", "tokens": [51444, 8382, 12, 7035, 2044, 293, 439, 729, 7527, 295, 721, 11, 300, 1177, 380, 914, 300, 300, 311, 264, 787, 636, 281, 3109, 51692], "temperature": 0.0, "avg_logprob": -0.15202441657941365, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.00020985535229556262}, {"id": 318, "seek": 226036, "start": 2260.36, "end": 2265.08, "text": " what McCarthy was thinking of or Doyle was thinking of. That doesn't mean that we're on the right", "tokens": [50364, 437, 44085, 390, 1953, 295, 420, 40059, 306, 390, 1953, 295, 13, 663, 1177, 380, 914, 300, 321, 434, 322, 264, 558, 50600], "temperature": 0.0, "avg_logprob": -0.09274361797214783, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0003053353284485638}, {"id": 319, "seek": 226036, "start": 2265.08, "end": 2272.6800000000003, "text": " track at all. In fact, we could be totally on the wrong track. So, I'm a little hesitant to release", "tokens": [50600, 2837, 412, 439, 13, 682, 1186, 11, 321, 727, 312, 3879, 322, 264, 2085, 2837, 13, 407, 11, 286, 478, 257, 707, 36290, 281, 4374, 50980], "temperature": 0.0, "avg_logprob": -0.09274361797214783, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0003053353284485638}, {"id": 320, "seek": 226036, "start": 2272.6800000000003, "end": 2278.6, "text": " what we have just because, you know, people might just decide that they want to play around with", "tokens": [50980, 437, 321, 362, 445, 570, 11, 291, 458, 11, 561, 1062, 445, 4536, 300, 436, 528, 281, 862, 926, 365, 51276], "temperature": 0.0, "avg_logprob": -0.09274361797214783, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0003053353284485638}, {"id": 321, "seek": 226036, "start": 2278.6, "end": 2286.36, "text": " this and use it, and that this is a starting point for exploration rather than looking at the problem", "tokens": [51276, 341, 293, 764, 309, 11, 293, 300, 341, 307, 257, 2891, 935, 337, 16197, 2831, 813, 1237, 412, 264, 1154, 51664], "temperature": 0.0, "avg_logprob": -0.09274361797214783, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0003053353284485638}, {"id": 322, "seek": 228636, "start": 2287.2400000000002, "end": 2292.2000000000003, "text": " you know, fresh and reading those papers and just thinking really hard and then using the", "tokens": [50408, 291, 458, 11, 4451, 293, 3760, 729, 10577, 293, 445, 1953, 534, 1152, 293, 550, 1228, 264, 50656], "temperature": 0.0, "avg_logprob": -0.1235839995470914, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.0005883422563783824}, {"id": 323, "seek": 228636, "start": 2292.2000000000003, "end": 2298.76, "text": " techniques that maybe you're familiar with. So, you know, it may be just better for people who", "tokens": [50656, 7512, 300, 1310, 291, 434, 4963, 365, 13, 407, 11, 291, 458, 11, 309, 815, 312, 445, 1101, 337, 561, 567, 50984], "temperature": 0.0, "avg_logprob": -0.1235839995470914, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.0005883422563783824}, {"id": 324, "seek": 228636, "start": 2298.76, "end": 2303.8, "text": " are interested in this area to work independently a little bit and then we could exchange notes or", "tokens": [50984, 366, 3102, 294, 341, 1859, 281, 589, 21761, 257, 707, 857, 293, 550, 321, 727, 7742, 5570, 420, 51236], "temperature": 0.0, "avg_logprob": -0.1235839995470914, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.0005883422563783824}, {"id": 325, "seek": 228636, "start": 2303.8, "end": 2311.8, "text": " things like that, maybe hold a workshop or something to talk about ideas. Whereas, you know, just sharing", "tokens": [51236, 721, 411, 300, 11, 1310, 1797, 257, 13541, 420, 746, 281, 751, 466, 3487, 13, 13813, 11, 291, 458, 11, 445, 5414, 51636], "temperature": 0.0, "avg_logprob": -0.1235839995470914, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.0005883422563783824}, {"id": 326, "seek": 231180, "start": 2311.8, "end": 2321.48, "text": " code may actually not be beneficial. And so, anyway, if you have thoughts on that, let me know.", "tokens": [50364, 3089, 815, 767, 406, 312, 14072, 13, 400, 370, 11, 4033, 11, 498, 291, 362, 4598, 322, 300, 11, 718, 385, 458, 13, 50848], "temperature": 0.0, "avg_logprob": -0.12435397348905865, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0045368121936917305}, {"id": 327, "seek": 231180, "start": 2322.6000000000004, "end": 2329.96, "text": " I think it is a little double edge to share this code right now, given that I don't think we really", "tokens": [50904, 286, 519, 309, 307, 257, 707, 3834, 4691, 281, 2073, 341, 3089, 558, 586, 11, 2212, 300, 286, 500, 380, 519, 321, 534, 51272], "temperature": 0.0, "avg_logprob": -0.12435397348905865, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0045368121936917305}, {"id": 328, "seek": 231180, "start": 2329.96, "end": 2335.0, "text": " understand the special sauce that be required yet. And so, if you start from this code, you may be", "tokens": [51272, 1223, 264, 2121, 4880, 300, 312, 4739, 1939, 13, 400, 370, 11, 498, 291, 722, 490, 341, 3089, 11, 291, 815, 312, 51524], "temperature": 0.0, "avg_logprob": -0.12435397348905865, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0045368121936917305}, {"id": 329, "seek": 233500, "start": 2335.0, "end": 2344.36, "text": " heading down the wrong path. Okay. So, I am going to load bat and chase game.", "tokens": [50364, 9864, 760, 264, 2085, 3100, 13, 1033, 13, 407, 11, 286, 669, 516, 281, 3677, 7362, 293, 15359, 1216, 13, 50832], "temperature": 0.0, "avg_logprob": -0.22787779294527494, "compression_ratio": 1.4458598726114649, "no_speech_prob": 0.01640162244439125}, {"id": 330, "seek": 233500, "start": 2348.84, "end": 2355.72, "text": " All right. Okay, so that seemed to be running some tests.", "tokens": [51056, 1057, 558, 13, 1033, 11, 370, 300, 6576, 281, 312, 2614, 512, 6921, 13, 51400], "temperature": 0.0, "avg_logprob": -0.22787779294527494, "compression_ratio": 1.4458598726114649, "no_speech_prob": 0.01640162244439125}, {"id": 331, "seek": 233500, "start": 2358.92, "end": 2363.56, "text": " Okay, you can see it's applying heuristics and it's calling barlament and things like that.", "tokens": [51560, 1033, 11, 291, 393, 536, 309, 311, 9275, 415, 374, 6006, 293, 309, 311, 5141, 2159, 75, 2466, 293, 721, 411, 300, 13, 51792], "temperature": 0.0, "avg_logprob": -0.22787779294527494, "compression_ratio": 1.4458598726114649, "no_speech_prob": 0.01640162244439125}, {"id": 332, "seek": 236356, "start": 2364.52, "end": 2373.0, "text": " Okay, so let's just look at this bat software a little bit. And maybe talk about the organization", "tokens": [50412, 1033, 11, 370, 718, 311, 445, 574, 412, 341, 7362, 4722, 257, 707, 857, 13, 400, 1310, 751, 466, 264, 4475, 50836], "temperature": 0.0, "avg_logprob": -0.13682204798648231, "compression_ratio": 1.6, "no_speech_prob": 0.0001634590298635885}, {"id": 333, "seek": 236356, "start": 2373.0, "end": 2379.48, "text": " of the software. So, the current version of that. So, bat stands for barlament advice taker. So, the", "tokens": [50836, 295, 264, 4722, 13, 407, 11, 264, 2190, 3037, 295, 300, 13, 407, 11, 7362, 7382, 337, 2159, 75, 2466, 5192, 991, 260, 13, 407, 11, 264, 51160], "temperature": 0.0, "avg_logprob": -0.13682204798648231, "compression_ratio": 1.6, "no_speech_prob": 0.0001634590298635885}, {"id": 334, "seek": 236356, "start": 2379.48, "end": 2385.72, "text": " idea, the original idea was that we were going to build an advice taker program that was oriented", "tokens": [51160, 1558, 11, 264, 3380, 1558, 390, 300, 321, 645, 516, 281, 1322, 364, 5192, 991, 260, 1461, 300, 390, 21841, 51472], "temperature": 0.0, "avg_logprob": -0.13682204798648231, "compression_ratio": 1.6, "no_speech_prob": 0.0001634590298635885}, {"id": 335, "seek": 238572, "start": 2385.72, "end": 2393.16, "text": " around barlament, which was the program I just showed you. Now, barlament is not very smart.", "tokens": [50364, 926, 2159, 75, 2466, 11, 597, 390, 264, 1461, 286, 445, 4712, 291, 13, 823, 11, 2159, 75, 2466, 307, 406, 588, 4069, 13, 50736], "temperature": 0.0, "avg_logprob": -0.11200508514007965, "compression_ratio": 1.4771573604060915, "no_speech_prob": 0.006096938159316778}, {"id": 336, "seek": 238572, "start": 2393.16, "end": 2400.8399999999997, "text": " Okay, it's not capable of recognizing when it's stuck. It doesn't know anything about its resource", "tokens": [50736, 1033, 11, 309, 311, 406, 8189, 295, 18538, 562, 309, 311, 5541, 13, 467, 1177, 380, 458, 1340, 466, 1080, 7684, 51120], "temperature": 0.0, "avg_logprob": -0.11200508514007965, "compression_ratio": 1.4771573604060915, "no_speech_prob": 0.006096938159316778}, {"id": 337, "seek": 238572, "start": 2400.8399999999997, "end": 2408.2, "text": " utilization. It can't ask for help. It can't explain its own internal state. So, you could think of", "tokens": [51120, 37074, 13, 467, 393, 380, 1029, 337, 854, 13, 467, 393, 380, 2903, 1080, 1065, 6920, 1785, 13, 407, 11, 291, 727, 519, 295, 51488], "temperature": 0.0, "avg_logprob": -0.11200508514007965, "compression_ratio": 1.4771573604060915, "no_speech_prob": 0.006096938159316778}, {"id": 338, "seek": 240820, "start": 2408.2, "end": 2415.72, "text": " barlament in a sense as a opaque solver that might be called by an introspective system.", "tokens": [50364, 2159, 75, 2466, 294, 257, 2020, 382, 257, 42687, 1404, 331, 300, 1062, 312, 1219, 538, 364, 560, 28713, 488, 1185, 13, 50740], "temperature": 0.0, "avg_logprob": -0.10692657123912465, "compression_ratio": 1.7881773399014778, "no_speech_prob": 0.009411843493580818}, {"id": 339, "seek": 240820, "start": 2416.4399999999996, "end": 2421.3999999999996, "text": " Other solvers that might be called from an introspective system would be things like", "tokens": [50776, 5358, 1404, 840, 300, 1062, 312, 1219, 490, 364, 560, 28713, 488, 1185, 576, 312, 721, 411, 51024], "temperature": 0.0, "avg_logprob": -0.10692657123912465, "compression_ratio": 1.7881773399014778, "no_speech_prob": 0.009411843493580818}, {"id": 340, "seek": 240820, "start": 2421.3999999999996, "end": 2428.8399999999997, "text": " SAT solvers or SMT solvers, maybe something like Z3, or maybe a solver written using answer set", "tokens": [51024, 31536, 1404, 840, 420, 13115, 51, 1404, 840, 11, 1310, 746, 411, 1176, 18, 11, 420, 1310, 257, 1404, 331, 3720, 1228, 1867, 992, 51396], "temperature": 0.0, "avg_logprob": -0.10692657123912465, "compression_ratio": 1.7881773399014778, "no_speech_prob": 0.009411843493580818}, {"id": 341, "seek": 240820, "start": 2428.8399999999997, "end": 2435.96, "text": " programming, or maybe something neural based, reinforcement learning based, statistics based,", "tokens": [51396, 9410, 11, 420, 1310, 746, 18161, 2361, 11, 29280, 2539, 2361, 11, 12523, 2361, 11, 51752], "temperature": 0.0, "avg_logprob": -0.10692657123912465, "compression_ratio": 1.7881773399014778, "no_speech_prob": 0.009411843493580818}, {"id": 342, "seek": 243596, "start": 2435.96, "end": 2440.04, "text": " as long as the answer, you know, could be verified in the end or the system", "tokens": [50364, 382, 938, 382, 264, 1867, 11, 291, 458, 11, 727, 312, 31197, 294, 264, 917, 420, 264, 1185, 50568], "temperature": 0.0, "avg_logprob": -0.09337879930223737, "compression_ratio": 1.7714285714285714, "no_speech_prob": 4.400042962515727e-05}, {"id": 343, "seek": 243596, "start": 2440.04, "end": 2446.12, "text": " could reason about its confidence in the answer. So, you have this idea of a solver,", "tokens": [50568, 727, 1778, 466, 1080, 6687, 294, 264, 1867, 13, 407, 11, 291, 362, 341, 1558, 295, 257, 1404, 331, 11, 50872], "temperature": 0.0, "avg_logprob": -0.09337879930223737, "compression_ratio": 1.7714285714285714, "no_speech_prob": 4.400042962515727e-05}, {"id": 344, "seek": 243596, "start": 2446.12, "end": 2452.92, "text": " something that's fast, but not introspective, that can be called from the advice taking program.", "tokens": [50872, 746, 300, 311, 2370, 11, 457, 406, 560, 28713, 488, 11, 300, 393, 312, 1219, 490, 264, 5192, 1940, 1461, 13, 51212], "temperature": 0.0, "avg_logprob": -0.09337879930223737, "compression_ratio": 1.7714285714285714, "no_speech_prob": 4.400042962515727e-05}, {"id": 345, "seek": 243596, "start": 2452.92, "end": 2458.6, "text": " So, bat is the advice taking program, and barlament is one solver that it could use,", "tokens": [51212, 407, 11, 7362, 307, 264, 5192, 1940, 1461, 11, 293, 2159, 75, 2466, 307, 472, 1404, 331, 300, 309, 727, 764, 11, 51496], "temperature": 0.0, "avg_logprob": -0.09337879930223737, "compression_ratio": 1.7714285714285714, "no_speech_prob": 4.400042962515727e-05}, {"id": 346, "seek": 243596, "start": 2458.6, "end": 2464.76, "text": " and over time we may add additional solvers. McCarthy also had the idea of a problem domain", "tokens": [51496, 293, 670, 565, 321, 815, 909, 4497, 1404, 840, 13, 44085, 611, 632, 264, 1558, 295, 257, 1154, 9274, 51804], "temperature": 0.0, "avg_logprob": -0.09337879930223737, "compression_ratio": 1.7714285714285714, "no_speech_prob": 4.400042962515727e-05}, {"id": 347, "seek": 246476, "start": 2464.76, "end": 2470.92, "text": " because advice taker is supposed to be a problem solver with common sense. That means that you're", "tokens": [50364, 570, 5192, 991, 260, 307, 3442, 281, 312, 257, 1154, 1404, 331, 365, 2689, 2020, 13, 663, 1355, 300, 291, 434, 50672], "temperature": 0.0, "avg_logprob": -0.08061339688855548, "compression_ratio": 1.65625, "no_speech_prob": 0.0001233915245393291}, {"id": 348, "seek": 246476, "start": 2470.92, "end": 2477.88, "text": " trying to solve problems in some domain, whether that being playing a good game of chess or trying", "tokens": [50672, 1382, 281, 5039, 2740, 294, 512, 9274, 11, 1968, 300, 885, 2433, 257, 665, 1216, 295, 24122, 420, 1382, 51020], "temperature": 0.0, "avg_logprob": -0.08061339688855548, "compression_ratio": 1.65625, "no_speech_prob": 0.0001233915245393291}, {"id": 349, "seek": 246476, "start": 2477.88, "end": 2484.76, "text": " to write a program or whatever, there has to be some problem domain or maybe an advice taker", "tokens": [51020, 281, 2464, 257, 1461, 420, 2035, 11, 456, 575, 281, 312, 512, 1154, 9274, 420, 1310, 364, 5192, 991, 260, 51364], "temperature": 0.0, "avg_logprob": -0.08061339688855548, "compression_ratio": 1.65625, "no_speech_prob": 0.0001233915245393291}, {"id": 350, "seek": 246476, "start": 2484.76, "end": 2491.88, "text": " could handle multiple problem domains. Even all the way back to McCarthy in 1959,", "tokens": [51364, 727, 4813, 3866, 1154, 25514, 13, 2754, 439, 264, 636, 646, 281, 44085, 294, 45608, 11, 51720], "temperature": 0.0, "avg_logprob": -0.08061339688855548, "compression_ratio": 1.65625, "no_speech_prob": 0.0001233915245393291}, {"id": 351, "seek": 249188, "start": 2492.76, "end": 2499.96, "text": " McCarthy was looking at generating programs as a problem domain. John Doyle also looked", "tokens": [50408, 44085, 390, 1237, 412, 17746, 4268, 382, 257, 1154, 9274, 13, 2619, 40059, 306, 611, 2956, 50768], "temperature": 0.0, "avg_logprob": -0.08727633953094482, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0012842377182096243}, {"id": 352, "seek": 249188, "start": 2499.96, "end": 2507.2400000000002, "text": " at this domain. In fact, many of the people in this area of AI, you'll see, looking at those", "tokens": [50768, 412, 341, 9274, 13, 682, 1186, 11, 867, 295, 264, 561, 294, 341, 1859, 295, 7318, 11, 291, 603, 536, 11, 1237, 412, 729, 51132], "temperature": 0.0, "avg_logprob": -0.08727633953094482, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0012842377182096243}, {"id": 353, "seek": 249188, "start": 2507.2400000000002, "end": 2513.96, "text": " papers I showed you, they look at programming, reasoning about programs, generating programs,", "tokens": [51132, 10577, 286, 4712, 291, 11, 436, 574, 412, 9410, 11, 21577, 466, 4268, 11, 17746, 4268, 11, 51468], "temperature": 0.0, "avg_logprob": -0.08727633953094482, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0012842377182096243}, {"id": 354, "seek": 249188, "start": 2513.96, "end": 2519.96, "text": " fixing or repairing programs as a problem domain. And I think that's natural for two reasons. One is", "tokens": [51468, 19442, 420, 46158, 4268, 382, 257, 1154, 9274, 13, 400, 286, 519, 300, 311, 3303, 337, 732, 4112, 13, 1485, 307, 51768], "temperature": 0.0, "avg_logprob": -0.08727633953094482, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0012842377182096243}, {"id": 355, "seek": 251996, "start": 2520.6, "end": 2527.16, "text": " anyone who's exploring these areas probably is a pretty good programmer or at least has had to go", "tokens": [50396, 2878, 567, 311, 12736, 613, 3179, 1391, 307, 257, 1238, 665, 32116, 420, 412, 1935, 575, 632, 281, 352, 50724], "temperature": 0.0, "avg_logprob": -0.09114093780517578, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0005883654812350869}, {"id": 356, "seek": 251996, "start": 2527.16, "end": 2533.56, "text": " through the process of learning how to program and knows either how to teach programming or how to", "tokens": [50724, 807, 264, 1399, 295, 2539, 577, 281, 1461, 293, 3255, 2139, 577, 281, 2924, 9410, 420, 577, 281, 51044], "temperature": 0.0, "avg_logprob": -0.09114093780517578, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0005883654812350869}, {"id": 357, "seek": 251996, "start": 2533.56, "end": 2540.84, "text": " learn about programming has gone through that experience. And also, the other reason is that", "tokens": [51044, 1466, 466, 9410, 575, 2780, 807, 300, 1752, 13, 400, 611, 11, 264, 661, 1778, 307, 300, 51408], "temperature": 0.0, "avg_logprob": -0.09114093780517578, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0005883654812350869}, {"id": 358, "seek": 251996, "start": 2540.84, "end": 2547.4, "text": " because the advice taker itself is a program, in this case, bat is written in Scheme and", "tokens": [51408, 570, 264, 5192, 991, 260, 2564, 307, 257, 1461, 11, 294, 341, 1389, 11, 7362, 307, 3720, 294, 2065, 5729, 293, 51736], "temperature": 0.0, "avg_logprob": -0.09114093780517578, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0005883654812350869}, {"id": 359, "seek": 254740, "start": 2547.4, "end": 2553.56, "text": " mini-canon, if you could build a system that can reason about software and that generate software,", "tokens": [50364, 8382, 12, 7035, 266, 11, 498, 291, 727, 1322, 257, 1185, 300, 393, 1778, 466, 4722, 293, 300, 8460, 4722, 11, 50672], "temperature": 0.0, "avg_logprob": -0.12924170750443653, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.000803995004389435}, {"id": 360, "seek": 254740, "start": 2553.56, "end": 2560.92, "text": " repair software, then there's at least the potential of applying the advice taker to itself", "tokens": [50672, 10535, 4722, 11, 550, 456, 311, 412, 1935, 264, 3995, 295, 9275, 264, 5192, 991, 260, 281, 2564, 51040], "temperature": 0.0, "avg_logprob": -0.12924170750443653, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.000803995004389435}, {"id": 361, "seek": 254740, "start": 2560.92, "end": 2568.36, "text": " and therefore having the system improve itself. And so I think this is at the heart of Doyle's idea", "tokens": [51040, 293, 4412, 1419, 264, 1185, 3470, 2564, 13, 400, 370, 286, 519, 341, 307, 412, 264, 1917, 295, 40059, 306, 311, 1558, 51412], "temperature": 0.0, "avg_logprob": -0.12924170750443653, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.000803995004389435}, {"id": 362, "seek": 254740, "start": 2568.36, "end": 2575.7200000000003, "text": " of this introspective, you know, or reflexive, meta-circular interpreter is that the interpreter", "tokens": [51412, 295, 341, 560, 28713, 488, 11, 291, 458, 11, 420, 23802, 488, 11, 19616, 12, 23568, 17792, 34132, 307, 300, 264, 34132, 51780], "temperature": 0.0, "avg_logprob": -0.12924170750443653, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.000803995004389435}, {"id": 363, "seek": 257572, "start": 2575.72, "end": 2582.2799999999997, "text": " for some problem-solving domain could understand its own code, at least to some extent, have access", "tokens": [50364, 337, 512, 1154, 12, 30926, 798, 9274, 727, 1223, 1080, 1065, 3089, 11, 412, 1935, 281, 512, 8396, 11, 362, 2105, 50692], "temperature": 0.0, "avg_logprob": -0.11937488022670951, "compression_ratio": 1.9166666666666667, "no_speech_prob": 0.0008295137085951865}, {"id": 364, "seek": 257572, "start": 2582.2799999999997, "end": 2589.56, "text": " to its own code, maybe know semantics of its own code. So you can imagine maybe a problem-solving", "tokens": [50692, 281, 1080, 1065, 3089, 11, 1310, 458, 4361, 45298, 295, 1080, 1065, 3089, 13, 407, 291, 393, 3811, 1310, 257, 1154, 12, 30926, 798, 51056], "temperature": 0.0, "avg_logprob": -0.11937488022670951, "compression_ratio": 1.9166666666666667, "no_speech_prob": 0.0008295137085951865}, {"id": 365, "seek": 257572, "start": 2589.56, "end": 2596.9199999999996, "text": " interpreter that had access to its own operational semantics for its own interpreter or denotational", "tokens": [51056, 34132, 300, 632, 2105, 281, 1080, 1065, 16607, 4361, 45298, 337, 1080, 1065, 34132, 420, 1441, 310, 1478, 51424], "temperature": 0.0, "avg_logprob": -0.11937488022670951, "compression_ratio": 1.9166666666666667, "no_speech_prob": 0.0008295137085951865}, {"id": 366, "seek": 257572, "start": 2596.9199999999996, "end": 2603.8799999999997, "text": " semantics or axiomatic semantics, things like that. Formal representations of itself or that", "tokens": [51424, 4361, 45298, 420, 6360, 72, 13143, 4361, 45298, 11, 721, 411, 300, 13, 10126, 304, 33358, 295, 2564, 420, 300, 51772], "temperature": 0.0, "avg_logprob": -0.11937488022670951, "compression_ratio": 1.9166666666666667, "no_speech_prob": 0.0008295137085951865}, {"id": 367, "seek": 260388, "start": 2603.96, "end": 2609.4, "text": " could do abstract interpretation of programs that can interpret things like that.", "tokens": [50368, 727, 360, 12649, 14174, 295, 4268, 300, 393, 7302, 721, 411, 300, 13, 50640], "temperature": 0.0, "avg_logprob": -0.0947812996901475, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.00015842102584429085}, {"id": 368, "seek": 260388, "start": 2610.36, "end": 2617.08, "text": " So that would be an example of an interpreter that had access to some smarts about its own", "tokens": [50688, 407, 300, 576, 312, 364, 1365, 295, 364, 34132, 300, 632, 2105, 281, 512, 4069, 82, 466, 1080, 1065, 51024], "temperature": 0.0, "avg_logprob": -0.0947812996901475, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.00015842102584429085}, {"id": 369, "seek": 260388, "start": 2617.08, "end": 2624.28, "text": " behavior or capabilities. In addition, you could also have the system have access to", "tokens": [51024, 5223, 420, 10862, 13, 682, 4500, 11, 291, 727, 611, 362, 264, 1185, 362, 2105, 281, 51384], "temperature": 0.0, "avg_logprob": -0.0947812996901475, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.00015842102584429085}, {"id": 370, "seek": 260388, "start": 2624.92, "end": 2630.6, "text": " information about the hardware it's running on, how much memory it has available, the processors,", "tokens": [51416, 1589, 466, 264, 8837, 309, 311, 2614, 322, 11, 577, 709, 4675, 309, 575, 2435, 11, 264, 27751, 11, 51700], "temperature": 0.0, "avg_logprob": -0.0947812996901475, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.00015842102584429085}, {"id": 371, "seek": 263060, "start": 2630.6, "end": 2636.68, "text": " things like that. And furthermore, you could have this information organized in a way,", "tokens": [50364, 721, 411, 300, 13, 400, 3052, 3138, 11, 291, 727, 362, 341, 1589, 9983, 294, 257, 636, 11, 50668], "temperature": 0.0, "avg_logprob": -0.09179932089412914, "compression_ratio": 1.7677725118483412, "no_speech_prob": 0.00011234819248784333}, {"id": 372, "seek": 263060, "start": 2638.68, "end": 2644.2799999999997, "text": " along with other information about the problem domain. So if the problem domain is about chess,", "tokens": [50768, 2051, 365, 661, 1589, 466, 264, 1154, 9274, 13, 407, 498, 264, 1154, 9274, 307, 466, 24122, 11, 51048], "temperature": 0.0, "avg_logprob": -0.09179932089412914, "compression_ratio": 1.7677725118483412, "no_speech_prob": 0.00011234819248784333}, {"id": 373, "seek": 263060, "start": 2644.2799999999997, "end": 2651.0, "text": " maybe their concepts related to playing chess. And one way to organize this information is in", "tokens": [51048, 1310, 641, 10392, 4077, 281, 2433, 24122, 13, 400, 472, 636, 281, 13859, 341, 1589, 307, 294, 51384], "temperature": 0.0, "avg_logprob": -0.09179932089412914, "compression_ratio": 1.7677725118483412, "no_speech_prob": 0.00011234819248784333}, {"id": 374, "seek": 263060, "start": 2651.0, "end": 2659.96, "text": " an ontology, which is often represented as a tree or a graph or a forest, often trees or forests", "tokens": [51384, 364, 6592, 1793, 11, 597, 307, 2049, 10379, 382, 257, 4230, 420, 257, 4295, 420, 257, 6719, 11, 2049, 5852, 420, 21700, 51832], "temperature": 0.0, "avg_logprob": -0.09179932089412914, "compression_ratio": 1.7677725118483412, "no_speech_prob": 0.00011234819248784333}, {"id": 375, "seek": 265996, "start": 2660.04, "end": 2666.84, "text": " of information. So hierarchical information, you can think of this often as sort of an object-oriented", "tokens": [50368, 295, 1589, 13, 407, 35250, 804, 1589, 11, 291, 393, 519, 295, 341, 2049, 382, 1333, 295, 364, 2657, 12, 27414, 50708], "temperature": 0.0, "avg_logprob": -0.12636868158976236, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.00020341647905297577}, {"id": 376, "seek": 265996, "start": 2666.84, "end": 2672.28, "text": " type thing where you have parent-child relationships. And so you can represent all", "tokens": [50708, 2010, 551, 689, 291, 362, 2596, 12, 15129, 6159, 13, 400, 370, 291, 393, 2906, 439, 50980], "temperature": 0.0, "avg_logprob": -0.12636868158976236, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.00020341647905297577}, {"id": 377, "seek": 265996, "start": 2672.28, "end": 2679.56, "text": " sorts of information, including heuristics and meta heuristics in an ontology. So in BAT, we have", "tokens": [50980, 7527, 295, 1589, 11, 3009, 415, 374, 6006, 293, 19616, 415, 374, 6006, 294, 364, 6592, 1793, 13, 407, 294, 363, 2218, 11, 321, 362, 51344], "temperature": 0.0, "avg_logprob": -0.12636868158976236, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.00020341647905297577}, {"id": 378, "seek": 265996, "start": 2679.56, "end": 2687.32, "text": " this idea of an ontology. So we have concepts. And you can see here we have a syntax rules macro.", "tokens": [51344, 341, 1558, 295, 364, 6592, 1793, 13, 407, 321, 362, 10392, 13, 400, 291, 393, 536, 510, 321, 362, 257, 28431, 4474, 18887, 13, 51732], "temperature": 0.0, "avg_logprob": -0.12636868158976236, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.00020341647905297577}, {"id": 379, "seek": 268732, "start": 2688.04, "end": 2695.56, "text": " And we have instances of concepts. So we have a concept in fields. And so we have a notion of an", "tokens": [50400, 400, 321, 362, 14519, 295, 10392, 13, 407, 321, 362, 257, 3410, 294, 7909, 13, 400, 370, 321, 362, 257, 10710, 295, 364, 50776], "temperature": 0.0, "avg_logprob": -0.10846301487513951, "compression_ratio": 1.9947089947089947, "no_speech_prob": 0.00010229429608443752}, {"id": 380, "seek": 268732, "start": 2695.56, "end": 2703.1600000000003, "text": " instance and the types of instance and so forth. And so here are a bunch of helpers. And because we", "tokens": [50776, 5197, 293, 264, 3467, 295, 5197, 293, 370, 5220, 13, 400, 370, 510, 366, 257, 3840, 295, 854, 433, 13, 400, 570, 321, 51156], "temperature": 0.0, "avg_logprob": -0.10846301487513951, "compression_ratio": 1.9947089947089947, "no_speech_prob": 0.00010229429608443752}, {"id": 381, "seek": 268732, "start": 2703.1600000000003, "end": 2710.84, "text": " want to be reflective or as meta-circular as possible, the notion of a concept is itself a", "tokens": [51156, 528, 281, 312, 28931, 420, 382, 19616, 12, 23568, 17792, 382, 1944, 11, 264, 10710, 295, 257, 3410, 307, 2564, 257, 51540], "temperature": 0.0, "avg_logprob": -0.10846301487513951, "compression_ratio": 1.9947089947089947, "no_speech_prob": 0.00010229429608443752}, {"id": 382, "seek": 268732, "start": 2710.84, "end": 2716.44, "text": " concept. The notion of an ontology is also a concept or an instance is also a concept. So", "tokens": [51540, 3410, 13, 440, 10710, 295, 364, 6592, 1793, 307, 611, 257, 3410, 420, 364, 5197, 307, 611, 257, 3410, 13, 407, 51820], "temperature": 0.0, "avg_logprob": -0.10846301487513951, "compression_ratio": 1.9947089947089947, "no_speech_prob": 0.00010229429608443752}, {"id": 383, "seek": 271644, "start": 2716.44, "end": 2722.04, "text": " this is a little small talky in a way, if you want to think of it that way. We also have the", "tokens": [50364, 341, 307, 257, 707, 1359, 751, 88, 294, 257, 636, 11, 498, 291, 528, 281, 519, 295, 309, 300, 636, 13, 492, 611, 362, 264, 50644], "temperature": 0.0, "avg_logprob": -0.0571877891952927, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.00010889155964832753}, {"id": 384, "seek": 271644, "start": 2722.04, "end": 2731.08, "text": " notion of a solver. So we have various types of solvers. And we have the notion of history", "tokens": [50644, 10710, 295, 257, 1404, 331, 13, 407, 321, 362, 3683, 3467, 295, 1404, 840, 13, 400, 321, 362, 264, 10710, 295, 2503, 51096], "temperature": 0.0, "avg_logprob": -0.0571877891952927, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.00010889155964832753}, {"id": 385, "seek": 271644, "start": 2731.08, "end": 2738.76, "text": " and the delta or change between two different states and things like that. So we have a whole", "tokens": [51096, 293, 264, 8289, 420, 1319, 1296, 732, 819, 4368, 293, 721, 411, 300, 13, 407, 321, 362, 257, 1379, 51480], "temperature": 0.0, "avg_logprob": -0.0571877891952927, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.00010889155964832753}, {"id": 386, "seek": 273876, "start": 2738.76, "end": 2748.0400000000004, "text": " bunch of different concepts here. If I go down here and look at, so initially we had an empty list", "tokens": [50364, 3840, 295, 819, 10392, 510, 13, 759, 286, 352, 760, 510, 293, 574, 412, 11, 370, 9105, 321, 632, 364, 6707, 1329, 50828], "temperature": 0.0, "avg_logprob": -0.08551452351712632, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.003376009175553918}, {"id": 387, "seek": 273876, "start": 2748.0400000000004, "end": 2754.1200000000003, "text": " of concepts. If I have the system list, the concepts that currently knows about, you can see", "tokens": [50828, 295, 10392, 13, 759, 286, 362, 264, 1185, 1329, 11, 264, 10392, 300, 4362, 3255, 466, 11, 291, 393, 536, 51132], "temperature": 0.0, "avg_logprob": -0.08551452351712632, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.003376009175553918}, {"id": 388, "seek": 273876, "start": 2754.1200000000003, "end": 2760.0400000000004, "text": " that there is information about things like tail position, or I shouldn't say information, but", "tokens": [51132, 300, 456, 307, 1589, 466, 721, 411, 6838, 2535, 11, 420, 286, 4659, 380, 584, 1589, 11, 457, 51428], "temperature": 0.0, "avg_logprob": -0.08551452351712632, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.003376009175553918}, {"id": 389, "seek": 273876, "start": 2760.0400000000004, "end": 2764.28, "text": " concepts like things like tail position, which is a grammatical property of software.", "tokens": [51428, 10392, 411, 721, 411, 6838, 2535, 11, 597, 307, 257, 17570, 267, 804, 4707, 295, 4722, 13, 51640], "temperature": 0.0, "avg_logprob": -0.08551452351712632, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.003376009175553918}, {"id": 390, "seek": 276428, "start": 2764.36, "end": 2775.0800000000004, "text": " And also there are concepts like advice or the fact that there's a user or BAT itself. So BAT", "tokens": [50368, 400, 611, 456, 366, 10392, 411, 5192, 420, 264, 1186, 300, 456, 311, 257, 4195, 420, 363, 2218, 2564, 13, 407, 363, 2218, 50904], "temperature": 0.0, "avg_logprob": -0.16261995539945714, "compression_ratio": 1.625, "no_speech_prob": 0.00032500960514880717}, {"id": 391, "seek": 276428, "start": 2775.0800000000004, "end": 2783.96, "text": " has a concept referring to itself and also has explicit notions of history using a Blackboard", "tokens": [50904, 575, 257, 3410, 13761, 281, 2564, 293, 611, 575, 13691, 35799, 295, 2503, 1228, 257, 4076, 3787, 51348], "temperature": 0.0, "avg_logprob": -0.16261995539945714, "compression_ratio": 1.625, "no_speech_prob": 0.00032500960514880717}, {"id": 392, "seek": 276428, "start": 2783.96, "end": 2791.1600000000003, "text": " architecture, which I won't get into what a Blackboard architecture is, but that was a traditional", "tokens": [51348, 9482, 11, 597, 286, 1582, 380, 483, 666, 437, 257, 4076, 3787, 9482, 307, 11, 457, 300, 390, 257, 5164, 51708], "temperature": 0.0, "avg_logprob": -0.16261995539945714, "compression_ratio": 1.625, "no_speech_prob": 0.00032500960514880717}, {"id": 393, "seek": 279116, "start": 2791.16, "end": 2798.52, "text": " style 1980s AI system approach where you could write different things to memory and that would", "tokens": [50364, 3758, 13626, 82, 7318, 1185, 3109, 689, 291, 727, 2464, 819, 721, 281, 4675, 293, 300, 576, 50732], "temperature": 0.0, "avg_logprob": -0.14022501583757072, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.00017399759963154793}, {"id": 394, "seek": 279116, "start": 2798.52, "end": 2806.68, "text": " trigger certain types of actions. But also notions of resources and things like for the", "tokens": [50732, 7875, 1629, 3467, 295, 5909, 13, 583, 611, 35799, 295, 3593, 293, 721, 411, 337, 264, 51140], "temperature": 0.0, "avg_logprob": -0.14022501583757072, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.00017399759963154793}, {"id": 395, "seek": 279116, "start": 2806.68, "end": 2812.12, "text": " arity of a function, whether or not the function is variadic and take any number of arguments,", "tokens": [51140, 594, 507, 295, 257, 2445, 11, 1968, 420, 406, 264, 2445, 307, 3034, 43341, 293, 747, 604, 1230, 295, 12869, 11, 51412], "temperature": 0.0, "avg_logprob": -0.14022501583757072, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.00017399759963154793}, {"id": 396, "seek": 279116, "start": 2812.12, "end": 2819.3199999999997, "text": " or maybe it's fixed, fixed arity, and we know exactly how many arguments, or maybe it's fixed", "tokens": [51412, 420, 1310, 309, 311, 6806, 11, 6806, 594, 507, 11, 293, 321, 458, 2293, 577, 867, 12869, 11, 420, 1310, 309, 311, 6806, 51772], "temperature": 0.0, "avg_logprob": -0.14022501583757072, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.00017399759963154793}, {"id": 397, "seek": 281932, "start": 2819.32, "end": 2824.04, "text": " arity with at least a certain number of arguments, but we don't know what those are and things like", "tokens": [50364, 594, 507, 365, 412, 1935, 257, 1629, 1230, 295, 12869, 11, 457, 321, 500, 380, 458, 437, 729, 366, 293, 721, 411, 50600], "temperature": 0.0, "avg_logprob": -0.10416435158771017, "compression_ratio": 1.7863636363636364, "no_speech_prob": 0.00026115935179404914}, {"id": 398, "seek": 281932, "start": 2824.04, "end": 2831.0800000000004, "text": " that. And so the notion of arity itself, the notion of a program template or a sketch, the notion", "tokens": [50600, 300, 13, 400, 370, 264, 10710, 295, 594, 507, 2564, 11, 264, 10710, 295, 257, 1461, 12379, 420, 257, 12325, 11, 264, 10710, 50952], "temperature": 0.0, "avg_logprob": -0.10416435158771017, "compression_ratio": 1.7863636363636364, "no_speech_prob": 0.00026115935179404914}, {"id": 399, "seek": 281932, "start": 2831.0800000000004, "end": 2838.1200000000003, "text": " of variables and expressions. So we're getting into things like, you know, notions of the programming", "tokens": [50952, 295, 9102, 293, 15277, 13, 407, 321, 434, 1242, 666, 721, 411, 11, 291, 458, 11, 35799, 295, 264, 9410, 51304], "temperature": 0.0, "avg_logprob": -0.10416435158771017, "compression_ratio": 1.7863636363636364, "no_speech_prob": 0.00026115935179404914}, {"id": 400, "seek": 281932, "start": 2838.1200000000003, "end": 2845.0, "text": " language that are represented, and the notion of a synthesis problem or a synthesis solution.", "tokens": [51304, 2856, 300, 366, 10379, 11, 293, 264, 10710, 295, 257, 30252, 1154, 420, 257, 30252, 3827, 13, 51648], "temperature": 0.0, "avg_logprob": -0.10416435158771017, "compression_ratio": 1.7863636363636364, "no_speech_prob": 0.00026115935179404914}, {"id": 401, "seek": 284500, "start": 2845.8, "end": 2850.2, "text": " You know, all of these sorts of things, including heuristics and meta heuristics,", "tokens": [50404, 509, 458, 11, 439, 295, 613, 7527, 295, 721, 11, 3009, 415, 374, 6006, 293, 19616, 415, 374, 6006, 11, 50624], "temperature": 0.0, "avg_logprob": -0.1119149635578024, "compression_ratio": 1.8341463414634147, "no_speech_prob": 0.0005357032059691846}, {"id": 402, "seek": 284500, "start": 2850.76, "end": 2856.68, "text": " are important to be able to represent in the system. So those are ideas or concepts represented", "tokens": [50652, 366, 1021, 281, 312, 1075, 281, 2906, 294, 264, 1185, 13, 407, 729, 366, 3487, 420, 10392, 10379, 50948], "temperature": 0.0, "avg_logprob": -0.1119149635578024, "compression_ratio": 1.8341463414634147, "no_speech_prob": 0.0005357032059691846}, {"id": 403, "seek": 284500, "start": 2856.68, "end": 2863.24, "text": " in an ontology. And the important part, the most important part is that the system can represent", "tokens": [50948, 294, 364, 6592, 1793, 13, 400, 264, 1021, 644, 11, 264, 881, 1021, 644, 307, 300, 264, 1185, 393, 2906, 51276], "temperature": 0.0, "avg_logprob": -0.1119149635578024, "compression_ratio": 1.8341463414634147, "no_speech_prob": 0.0005357032059691846}, {"id": 404, "seek": 284500, "start": 2863.24, "end": 2868.76, "text": " things about itself. It has a representation of itself as representation of a user or a conversation,", "tokens": [51276, 721, 466, 2564, 13, 467, 575, 257, 10290, 295, 2564, 382, 10290, 295, 257, 4195, 420, 257, 3761, 11, 51552], "temperature": 0.0, "avg_logprob": -0.1119149635578024, "compression_ratio": 1.8341463414634147, "no_speech_prob": 0.0005357032059691846}, {"id": 405, "seek": 286876, "start": 2869.32, "end": 2878.36, "text": " those sorts of things. In addition to an ontology, there's also a notion of communication", "tokens": [50392, 729, 7527, 295, 721, 13, 682, 4500, 281, 364, 6592, 1793, 11, 456, 311, 611, 257, 10710, 295, 6101, 50844], "temperature": 0.0, "avg_logprob": -0.10825278208805965, "compression_ratio": 1.4886363636363635, "no_speech_prob": 0.00028683271375484765}, {"id": 406, "seek": 286876, "start": 2878.36, "end": 2886.92, "text": " between the advice taker and a user or an external entity. So currently, we have sort of", "tokens": [50844, 1296, 264, 5192, 991, 260, 293, 257, 4195, 420, 364, 8320, 13977, 13, 407, 4362, 11, 321, 362, 1333, 295, 51272], "temperature": 0.0, "avg_logprob": -0.10825278208805965, "compression_ratio": 1.4886363636363635, "no_speech_prob": 0.00028683271375484765}, {"id": 407, "seek": 286876, "start": 2888.2000000000003, "end": 2892.28, "text": " a high level sketch of how we might imagine a conversation. We don't have a working", "tokens": [51336, 257, 1090, 1496, 12325, 295, 577, 321, 1062, 3811, 257, 3761, 13, 492, 500, 380, 362, 257, 1364, 51540], "temperature": 0.0, "avg_logprob": -0.10825278208805965, "compression_ratio": 1.4886363636363635, "no_speech_prob": 0.00028683271375484765}, {"id": 408, "seek": 289228, "start": 2892.36, "end": 2900.76, "text": " implementation yet. But you can see some examples of what the conversation with BAT may be. If BAT", "tokens": [50368, 11420, 1939, 13, 583, 291, 393, 536, 512, 5110, 295, 437, 264, 3761, 365, 363, 2218, 815, 312, 13, 759, 363, 2218, 50788], "temperature": 0.0, "avg_logprob": -0.11508769989013672, "compression_ratio": 1.786046511627907, "no_speech_prob": 0.0017544287256896496}, {"id": 409, "seek": 289228, "start": 2900.76, "end": 2906.44, "text": " gets stuck, you know, trying to synthesize something like factorial, there may be a suggestion to try", "tokens": [50788, 2170, 5541, 11, 291, 458, 11, 1382, 281, 26617, 1125, 746, 411, 36916, 11, 456, 815, 312, 257, 16541, 281, 853, 51072], "temperature": 0.0, "avg_logprob": -0.11508769989013672, "compression_ratio": 1.786046511627907, "no_speech_prob": 0.0017544287256896496}, {"id": 410, "seek": 289228, "start": 2906.44, "end": 2914.28, "text": " to do something like use an accumulator. And so synthesize an accumulator called factorial", "tokens": [51072, 281, 360, 746, 411, 764, 364, 12989, 16381, 13, 400, 370, 26617, 1125, 364, 12989, 16381, 1219, 36916, 51464], "temperature": 0.0, "avg_logprob": -0.11508769989013672, "compression_ratio": 1.786046511627907, "no_speech_prob": 0.0017544287256896496}, {"id": 411, "seek": 289228, "start": 2914.28, "end": 2920.1200000000003, "text": " AC. And then, you know, there may be a sketch there that the system is able to come up with.", "tokens": [51464, 8157, 13, 400, 550, 11, 291, 458, 11, 456, 815, 312, 257, 12325, 456, 300, 264, 1185, 307, 1075, 281, 808, 493, 365, 13, 51756], "temperature": 0.0, "avg_logprob": -0.11508769989013672, "compression_ratio": 1.786046511627907, "no_speech_prob": 0.0017544287256896496}, {"id": 412, "seek": 292012, "start": 2920.12, "end": 2925.16, "text": " And then you can imagine this sort of conversation going backwards and forwards between", "tokens": [50364, 400, 550, 291, 393, 3811, 341, 1333, 295, 3761, 516, 12204, 293, 30126, 1296, 50616], "temperature": 0.0, "avg_logprob": -0.07939493128683715, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.00011234604608034715}, {"id": 413, "seek": 292012, "start": 2925.96, "end": 2932.2799999999997, "text": " some entity and external entity in BAT itself. So, you know, at this point, we're still trying to", "tokens": [50656, 512, 13977, 293, 8320, 13977, 294, 363, 2218, 2564, 13, 407, 11, 291, 458, 11, 412, 341, 935, 11, 321, 434, 920, 1382, 281, 50972], "temperature": 0.0, "avg_logprob": -0.07939493128683715, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.00011234604608034715}, {"id": 414, "seek": 292012, "start": 2932.2799999999997, "end": 2940.2, "text": " figure out how we would represent that communication. In McCarthy's advice taker paper, he talks about", "tokens": [50972, 2573, 484, 577, 321, 576, 2906, 300, 6101, 13, 682, 44085, 311, 5192, 991, 260, 3035, 11, 415, 6686, 466, 51368], "temperature": 0.0, "avg_logprob": -0.07939493128683715, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.00011234604608034715}, {"id": 415, "seek": 292012, "start": 2940.2, "end": 2944.6, "text": " sort of a stylized language that could be used. And we're definitely figuring that one out.", "tokens": [51368, 1333, 295, 257, 23736, 1602, 2856, 300, 727, 312, 1143, 13, 400, 321, 434, 2138, 15213, 300, 472, 484, 13, 51588], "temperature": 0.0, "avg_logprob": -0.07939493128683715, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.00011234604608034715}, {"id": 416, "seek": 292012, "start": 2945.4, "end": 2949.3199999999997, "text": " We also have the notion of an erity. So that was sort of the first thing we wanted to do,", "tokens": [51628, 492, 611, 362, 264, 10710, 295, 364, 1189, 507, 13, 407, 300, 390, 1333, 295, 264, 700, 551, 321, 1415, 281, 360, 11, 51824], "temperature": 0.0, "avg_logprob": -0.07939493128683715, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.00011234604608034715}, {"id": 417, "seek": 294932, "start": 2949.32, "end": 2957.1600000000003, "text": " similar to when I tried to, for Barleman, figure out what the erity is for the append function.", "tokens": [50364, 2531, 281, 562, 286, 3031, 281, 11, 337, 4156, 306, 1601, 11, 2573, 484, 437, 264, 1189, 507, 307, 337, 264, 34116, 2445, 13, 50756], "temperature": 0.0, "avg_logprob": -0.14142428636550902, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00022339072893373668}, {"id": 418, "seek": 294932, "start": 2957.1600000000003, "end": 2963.56, "text": " That turns out to speed up the Barleman synthesis quite a lot, usually. So you can see that we have,", "tokens": [50756, 663, 4523, 484, 281, 3073, 493, 264, 4156, 306, 1601, 30252, 1596, 257, 688, 11, 2673, 13, 407, 291, 393, 536, 300, 321, 362, 11, 51076], "temperature": 0.0, "avg_logprob": -0.14142428636550902, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00022339072893373668}, {"id": 419, "seek": 294932, "start": 2965.8, "end": 2973.4, "text": " in this case, the notion of trying to append, to synthesize append. And we have heuristics that", "tokens": [51188, 294, 341, 1389, 11, 264, 10710, 295, 1382, 281, 34116, 11, 281, 26617, 1125, 34116, 13, 400, 321, 362, 415, 374, 6006, 300, 51568], "temperature": 0.0, "avg_logprob": -0.14142428636550902, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00022339072893373668}, {"id": 420, "seek": 297340, "start": 2973.4, "end": 2982.52, "text": " have to do with erity. So here, we have a notion of guessing erity. And then, we have various", "tokens": [50364, 362, 281, 360, 365, 1189, 507, 13, 407, 510, 11, 321, 362, 257, 10710, 295, 17939, 1189, 507, 13, 400, 550, 11, 321, 362, 3683, 50820], "temperature": 0.0, "avg_logprob": -0.13700051307678224, "compression_ratio": 1.688622754491018, "no_speech_prob": 0.0017545029986649752}, {"id": 421, "seek": 297340, "start": 2982.52, "end": 2989.08, "text": " helpers to try to help, you know, help us with this notion of guessing the erity of a function.", "tokens": [50820, 854, 433, 281, 853, 281, 854, 11, 291, 458, 11, 854, 505, 365, 341, 10710, 295, 17939, 264, 1189, 507, 295, 257, 2445, 13, 51148], "temperature": 0.0, "avg_logprob": -0.13700051307678224, "compression_ratio": 1.688622754491018, "no_speech_prob": 0.0017545029986649752}, {"id": 422, "seek": 297340, "start": 2990.36, "end": 2996.36, "text": " But you can see here is a heuristic, you know, fine erity sketch from input output examples.", "tokens": [51212, 583, 291, 393, 536, 510, 307, 257, 415, 374, 3142, 11, 291, 458, 11, 2489, 1189, 507, 12325, 490, 4846, 5598, 5110, 13, 51512], "temperature": 0.0, "avg_logprob": -0.13700051307678224, "compression_ratio": 1.688622754491018, "no_speech_prob": 0.0017545029986649752}, {"id": 423, "seek": 299636, "start": 2996.36, "end": 3003.6400000000003, "text": " And so here you can see we have an instance in our, our ontology. So we have a heuristic in the", "tokens": [50364, 400, 370, 510, 291, 393, 536, 321, 362, 364, 5197, 294, 527, 11, 527, 6592, 1793, 13, 407, 321, 362, 257, 415, 374, 3142, 294, 264, 50728], "temperature": 0.0, "avg_logprob": -0.1050244597501533, "compression_ratio": 1.653179190751445, "no_speech_prob": 0.0010004020296037197}, {"id": 424, "seek": 299636, "start": 3003.6400000000003, "end": 3010.2000000000003, "text": " name of the heuristic and when it's applicable and how do you apply it and so forth. There also", "tokens": [50728, 1315, 295, 264, 415, 374, 3142, 293, 562, 309, 311, 21142, 293, 577, 360, 291, 3079, 309, 293, 370, 5220, 13, 821, 611, 51056], "temperature": 0.0, "avg_logprob": -0.1050244597501533, "compression_ratio": 1.653179190751445, "no_speech_prob": 0.0010004020296037197}, {"id": 425, "seek": 299636, "start": 3010.2000000000003, "end": 3020.44, "text": " is a heuristic having to do with Barleman itself. So, you know, there is a Barleman heuristic.", "tokens": [51056, 307, 257, 415, 374, 3142, 1419, 281, 360, 365, 4156, 306, 1601, 2564, 13, 407, 11, 291, 458, 11, 456, 307, 257, 4156, 306, 1601, 415, 374, 3142, 13, 51568], "temperature": 0.0, "avg_logprob": -0.1050244597501533, "compression_ratio": 1.653179190751445, "no_speech_prob": 0.0010004020296037197}, {"id": 426, "seek": 302044, "start": 3021.16, "end": 3028.92, "text": " So you can actually see that, you know, if, if it's possible to invoke Barleman,", "tokens": [50400, 407, 291, 393, 767, 536, 300, 11, 291, 458, 11, 498, 11, 498, 309, 311, 1944, 281, 41117, 4156, 306, 1601, 11, 50788], "temperature": 0.0, "avg_logprob": -0.11736148946425494, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.0006262646638788283}, {"id": 427, "seek": 302044, "start": 3028.92, "end": 3033.96, "text": " that is a heuristic that's available to the Barleman advice taker. So that's one of the", "tokens": [50788, 300, 307, 257, 415, 374, 3142, 300, 311, 2435, 281, 264, 4156, 306, 1601, 5192, 991, 260, 13, 407, 300, 311, 472, 295, 264, 51040], "temperature": 0.0, "avg_logprob": -0.11736148946425494, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.0006262646638788283}, {"id": 428, "seek": 302044, "start": 3033.96, "end": 3040.52, "text": " heuristics. And, and we have code here to transform problems into something that Barleman can handle.", "tokens": [51040, 415, 374, 6006, 13, 400, 11, 293, 321, 362, 3089, 510, 281, 4088, 2740, 666, 746, 300, 4156, 306, 1601, 393, 4813, 13, 51368], "temperature": 0.0, "avg_logprob": -0.11736148946425494, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.0006262646638788283}, {"id": 429, "seek": 302044, "start": 3041.96, "end": 3048.28, "text": " So, let's see what else. Engines are something that we're not currently using, but that's a", "tokens": [51440, 407, 11, 718, 311, 536, 437, 1646, 13, 2469, 1652, 366, 746, 300, 321, 434, 406, 4362, 1228, 11, 457, 300, 311, 257, 51756], "temperature": 0.0, "avg_logprob": -0.11736148946425494, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.0006262646638788283}, {"id": 430, "seek": 304828, "start": 3048.28, "end": 3056.76, "text": " way to deal with timeouts. Let's see, we have append examples here. So we have input output", "tokens": [50364, 636, 281, 2028, 365, 565, 7711, 13, 961, 311, 536, 11, 321, 362, 34116, 5110, 510, 13, 407, 321, 362, 4846, 5598, 50788], "temperature": 0.0, "avg_logprob": -0.05649690628051758, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.00018521583115216345}, {"id": 431, "seek": 304828, "start": 3056.76, "end": 3062.2000000000003, "text": " examples. So these are, you know, similar to what I was showing with Barleman. And then we", "tokens": [50788, 5110, 13, 407, 613, 366, 11, 291, 458, 11, 2531, 281, 437, 286, 390, 4099, 365, 4156, 306, 1601, 13, 400, 550, 321, 51060], "temperature": 0.0, "avg_logprob": -0.05649690628051758, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.00018521583115216345}, {"id": 432, "seek": 304828, "start": 3062.2000000000003, "end": 3068.6800000000003, "text": " have more sophisticated examples where we might have notions of logic variables or holes, even", "tokens": [51060, 362, 544, 16950, 5110, 689, 321, 1062, 362, 35799, 295, 9952, 9102, 420, 8118, 11, 754, 51384], "temperature": 0.0, "avg_logprob": -0.05649690628051758, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.00018521583115216345}, {"id": 433, "seek": 304828, "start": 3068.6800000000003, "end": 3075.1600000000003, "text": " in the input output examples themselves, and so forth. And you can see that there are different", "tokens": [51384, 294, 264, 4846, 5598, 5110, 2969, 11, 293, 370, 5220, 13, 400, 291, 393, 536, 300, 456, 366, 819, 51708], "temperature": 0.0, "avg_logprob": -0.05649690628051758, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.00018521583115216345}, {"id": 434, "seek": 307516, "start": 3075.16, "end": 3082.44, "text": " types of sketches that might be guessed. And in fact, we can also do things like, you know,", "tokens": [50364, 3467, 295, 34547, 300, 1062, 312, 21852, 13, 400, 294, 1186, 11, 321, 393, 611, 360, 721, 411, 11, 291, 458, 11, 50728], "temperature": 0.0, "avg_logprob": -0.1568322668270189, "compression_ratio": 1.7475728155339805, "no_speech_prob": 0.001244621118530631}, {"id": 435, "seek": 307516, "start": 3082.44, "end": 3088.44, "text": " have, have the system, if the system guesses that the base case is not recursive, we can use a minicanrin", "tokens": [50728, 362, 11, 362, 264, 1185, 11, 498, 264, 1185, 42703, 300, 264, 3096, 1389, 307, 406, 20560, 488, 11, 321, 393, 764, 257, 923, 8914, 12629, 51028], "temperature": 0.0, "avg_logprob": -0.1568322668270189, "compression_ratio": 1.7475728155339805, "no_speech_prob": 0.001244621118530631}, {"id": 436, "seek": 307516, "start": 3088.44, "end": 3098.04, "text": " absento constraint saying that the name append can't appear in the body of the base case,", "tokens": [51028, 1950, 15467, 25534, 1566, 300, 264, 1315, 34116, 393, 380, 4204, 294, 264, 1772, 295, 264, 3096, 1389, 11, 51508], "temperature": 0.0, "avg_logprob": -0.1568322668270189, "compression_ratio": 1.7475728155339805, "no_speech_prob": 0.001244621118530631}, {"id": 437, "seek": 307516, "start": 3098.04, "end": 3101.16, "text": " if we think that there's a base case. And, and also there's no Lebrecht,", "tokens": [51508, 498, 321, 519, 300, 456, 311, 257, 3096, 1389, 13, 400, 11, 293, 611, 456, 311, 572, 1456, 2672, 4701, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1568322668270189, "compression_ratio": 1.7475728155339805, "no_speech_prob": 0.001244621118530631}, {"id": 438, "seek": 310116, "start": 3102.12, "end": 3108.3599999999997, "text": " no recursive definitions in the base case. So we can use some of the constraints in minicanrin and", "tokens": [50412, 572, 20560, 488, 21988, 294, 264, 3096, 1389, 13, 407, 321, 393, 764, 512, 295, 264, 18491, 294, 923, 8914, 12629, 293, 50724], "temperature": 0.0, "avg_logprob": -0.08301182716123519, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.00040445587364956737}, {"id": 439, "seek": 310116, "start": 3108.3599999999997, "end": 3115.96, "text": " Barleman to enforce certain notions like the idea that we have a base case. And, you know,", "tokens": [50724, 4156, 306, 1601, 281, 24825, 1629, 35799, 411, 264, 1558, 300, 321, 362, 257, 3096, 1389, 13, 400, 11, 291, 458, 11, 51104], "temperature": 0.0, "avg_logprob": -0.08301182716123519, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.00040445587364956737}, {"id": 440, "seek": 310116, "start": 3115.96, "end": 3121.48, "text": " we can imagine sort of the internal state of Barleman, how it would work through", "tokens": [51104, 321, 393, 3811, 1333, 295, 264, 6920, 1785, 295, 4156, 306, 1601, 11, 577, 309, 576, 589, 807, 51380], "temperature": 0.0, "avg_logprob": -0.08301182716123519, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.00040445587364956737}, {"id": 441, "seek": 310116, "start": 3122.3599999999997, "end": 3126.92, "text": " different aspects of this program as it's trying to interpret it. And part of the idea is to be", "tokens": [51424, 819, 7270, 295, 341, 1461, 382, 309, 311, 1382, 281, 7302, 309, 13, 400, 644, 295, 264, 1558, 307, 281, 312, 51652], "temperature": 0.0, "avg_logprob": -0.08301182716123519, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.00040445587364956737}, {"id": 442, "seek": 312692, "start": 3127.0, "end": 3132.84, "text": " able to simulate what a student learning how to program in a language like scheme might think.", "tokens": [50368, 1075, 281, 27817, 437, 257, 3107, 2539, 577, 281, 1461, 294, 257, 2856, 411, 12232, 1062, 519, 13, 50660], "temperature": 0.0, "avg_logprob": -0.14895311991373697, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.0008558239787817001}, {"id": 443, "seek": 312692, "start": 3133.48, "end": 3140.6800000000003, "text": " And so there, there are heuristics that we teach to beginning pre scheme programmers,", "tokens": [50692, 400, 370, 456, 11, 456, 366, 415, 374, 6006, 300, 321, 2924, 281, 2863, 659, 12232, 41504, 11, 51052], "temperature": 0.0, "avg_logprob": -0.14895311991373697, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.0008558239787817001}, {"id": 444, "seek": 312692, "start": 3140.6800000000003, "end": 3146.36, "text": " like if Dan Friedman always teaches, if you write a recursive function and there's no question", "tokens": [51052, 411, 498, 3394, 17605, 1601, 1009, 16876, 11, 498, 291, 2464, 257, 20560, 488, 2445, 293, 456, 311, 572, 1168, 51336], "temperature": 0.0, "avg_logprob": -0.14895311991373697, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.0008558239787817001}, {"id": 445, "seek": 312692, "start": 3146.36, "end": 3152.52, "text": " asked about a certain argument, like is it null or a pair, then that argument will be passed in", "tokens": [51336, 2351, 466, 257, 1629, 6770, 11, 411, 307, 309, 18184, 420, 257, 6119, 11, 550, 300, 6770, 486, 312, 4678, 294, 51644], "temperature": 0.0, "avg_logprob": -0.14895311991373697, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.0008558239787817001}, {"id": 446, "seek": 315252, "start": 3152.52, "end": 3158.52, "text": " any recursions without being changed. So that would be an example of a heuristic that we could add to", "tokens": [50364, 604, 20560, 626, 1553, 885, 3105, 13, 407, 300, 576, 312, 364, 1365, 295, 257, 415, 374, 3142, 300, 321, 727, 909, 281, 50664], "temperature": 0.0, "avg_logprob": -0.08643925189971924, "compression_ratio": 1.6358695652173914, "no_speech_prob": 0.00013134651817381382}, {"id": 447, "seek": 315252, "start": 3158.52, "end": 3169.32, "text": " that. Let's see. We also have information like, you know, tail recursion, which we're still working", "tokens": [50664, 300, 13, 961, 311, 536, 13, 492, 611, 362, 1589, 411, 11, 291, 458, 11, 6838, 20560, 313, 11, 597, 321, 434, 920, 1364, 51204], "temperature": 0.0, "avg_logprob": -0.08643925189971924, "compression_ratio": 1.6358695652173914, "no_speech_prob": 0.00013134651817381382}, {"id": 448, "seek": 315252, "start": 3169.32, "end": 3176.84, "text": " on. But we have some heuristics with tail recursion that we're working on as well. And then we have", "tokens": [51204, 322, 13, 583, 321, 362, 512, 415, 374, 6006, 365, 6838, 20560, 313, 300, 321, 434, 1364, 322, 382, 731, 13, 400, 550, 321, 362, 51580], "temperature": 0.0, "avg_logprob": -0.08643925189971924, "compression_ratio": 1.6358695652173914, "no_speech_prob": 0.00013134651817381382}, {"id": 449, "seek": 317684, "start": 3176.84, "end": 3183.7200000000003, "text": " some code that can take one of our templates and turn it into a mini can run example that Barleman", "tokens": [50364, 512, 3089, 300, 393, 747, 472, 295, 527, 21165, 293, 1261, 309, 666, 257, 8382, 393, 1190, 1365, 300, 4156, 306, 1601, 50708], "temperature": 0.0, "avg_logprob": -0.11901523590087891, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0007553119212388992}, {"id": 450, "seek": 317684, "start": 3183.7200000000003, "end": 3192.6000000000004, "text": " can handle. And we've also, we also have been exploring notions of types that we can, that we", "tokens": [50708, 393, 4813, 13, 400, 321, 600, 611, 11, 321, 611, 362, 668, 12736, 35799, 295, 3467, 300, 321, 393, 11, 300, 321, 51152], "temperature": 0.0, "avg_logprob": -0.11901523590087891, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0007553119212388992}, {"id": 451, "seek": 317684, "start": 3192.6000000000004, "end": 3205.2400000000002, "text": " might find useful in the future. And I think, yeah, yeah, so we also have some notes and,", "tokens": [51152, 1062, 915, 4420, 294, 264, 2027, 13, 400, 286, 519, 11, 1338, 11, 1338, 11, 370, 321, 611, 362, 512, 5570, 293, 11, 51784], "temperature": 0.0, "avg_logprob": -0.11901523590087891, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0007553119212388992}, {"id": 452, "seek": 320524, "start": 3205.24, "end": 3212.3599999999997, "text": " and motivating examples that we care about. And so high level questions that we have are,", "tokens": [50364, 293, 41066, 5110, 300, 321, 1127, 466, 13, 400, 370, 1090, 1496, 1651, 300, 321, 362, 366, 11, 50720], "temperature": 0.0, "avg_logprob": -0.11440649593577665, "compression_ratio": 1.814070351758794, "no_speech_prob": 0.001032044063322246}, {"id": 453, "seek": 320524, "start": 3212.3599999999997, "end": 3218.68, "text": " what are the sorts of things that we want to, to have a system like that be able to reason", "tokens": [50720, 437, 366, 264, 7527, 295, 721, 300, 321, 528, 281, 11, 281, 362, 257, 1185, 411, 300, 312, 1075, 281, 1778, 51036], "temperature": 0.0, "avg_logprob": -0.11440649593577665, "compression_ratio": 1.814070351758794, "no_speech_prob": 0.001032044063322246}, {"id": 454, "seek": 320524, "start": 3218.68, "end": 3224.3599999999997, "text": " about explicitly, and what information needs or what concepts have to go in the ontology,", "tokens": [51036, 466, 20803, 11, 293, 437, 1589, 2203, 420, 437, 10392, 362, 281, 352, 294, 264, 6592, 1793, 11, 51320], "temperature": 0.0, "avg_logprob": -0.11440649593577665, "compression_ratio": 1.814070351758794, "no_speech_prob": 0.001032044063322246}, {"id": 455, "seek": 320524, "start": 3224.3599999999997, "end": 3228.7599999999998, "text": " like what does that need to know about itself, what does that need to know about potential", "tokens": [51320, 411, 437, 775, 300, 643, 281, 458, 466, 2564, 11, 437, 775, 300, 643, 281, 458, 466, 3995, 51540], "temperature": 0.0, "avg_logprob": -0.11440649593577665, "compression_ratio": 1.814070351758794, "no_speech_prob": 0.001032044063322246}, {"id": 456, "seek": 322876, "start": 3228.76, "end": 3237.2400000000002, "text": " resource usage, how is that going to communicate with external entities concisely and represent", "tokens": [50364, 7684, 14924, 11, 577, 307, 300, 516, 281, 7890, 365, 8320, 16667, 1588, 271, 736, 293, 2906, 50788], "temperature": 0.0, "avg_logprob": -0.08855974297774466, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.033077843487262726}, {"id": 457, "seek": 322876, "start": 3237.2400000000002, "end": 3243.0800000000004, "text": " concisely its own internal state, and also know when it's stuck or recognize when it's stuck and", "tokens": [50788, 1588, 271, 736, 1080, 1065, 6920, 1785, 11, 293, 611, 458, 562, 309, 311, 5541, 420, 5521, 562, 309, 311, 5541, 293, 51080], "temperature": 0.0, "avg_logprob": -0.08855974297774466, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.033077843487262726}, {"id": 458, "seek": 322876, "start": 3243.0800000000004, "end": 3249.8, "text": " ask for heuristics or meta heuristics and have that conversation. So those are things that we're,", "tokens": [51080, 1029, 337, 415, 374, 6006, 420, 19616, 415, 374, 6006, 293, 362, 300, 3761, 13, 407, 729, 366, 721, 300, 321, 434, 11, 51416], "temperature": 0.0, "avg_logprob": -0.08855974297774466, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.033077843487262726}, {"id": 459, "seek": 322876, "start": 3249.8, "end": 3255.6400000000003, "text": " we're thinking about. If you find this interesting and you'd like to talk to us, you know, please", "tokens": [51416, 321, 434, 1953, 466, 13, 759, 291, 915, 341, 1880, 293, 291, 1116, 411, 281, 751, 281, 505, 11, 291, 458, 11, 1767, 51708], "temperature": 0.0, "avg_logprob": -0.08855974297774466, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.033077843487262726}, {"id": 460, "seek": 325564, "start": 3255.64, "end": 3264.2799999999997, "text": " drop me an email. And maybe we can do a call. And I also encourage you to try hacking on something", "tokens": [50364, 3270, 385, 364, 3796, 13, 400, 1310, 321, 393, 360, 257, 818, 13, 400, 286, 611, 5373, 291, 281, 853, 31422, 322, 746, 50796], "temperature": 0.0, "avg_logprob": -0.11202495925280513, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.00348250032402575}, {"id": 461, "seek": 325564, "start": 3264.2799999999997, "end": 3270.8399999999997, "text": " like, like advice taker yourself, I think it's a very interesting set of problems. And a minimum,", "tokens": [50796, 411, 11, 411, 5192, 991, 260, 1803, 11, 286, 519, 309, 311, 257, 588, 1880, 992, 295, 2740, 13, 400, 257, 7285, 11, 51124], "temperature": 0.0, "avg_logprob": -0.11202495925280513, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.00348250032402575}, {"id": 462, "seek": 325564, "start": 3270.8399999999997, "end": 3274.7599999999998, "text": " I think it's worth reading these papers and trying to understand where a lot of these,", "tokens": [51124, 286, 519, 309, 311, 3163, 3760, 613, 10577, 293, 1382, 281, 1223, 689, 257, 688, 295, 613, 11, 51320], "temperature": 0.0, "avg_logprob": -0.11202495925280513, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.00348250032402575}, {"id": 463, "seek": 325564, "start": 3275.8799999999997, "end": 3283.3199999999997, "text": " you know, 1980s, late 70s systems were headed towards. And, you know, it was worth rethinking", "tokens": [51376, 291, 458, 11, 13626, 82, 11, 3469, 5285, 82, 3652, 645, 12798, 3030, 13, 400, 11, 291, 458, 11, 309, 390, 3163, 319, 39873, 51748], "temperature": 0.0, "avg_logprob": -0.11202495925280513, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.00348250032402575}, {"id": 464, "seek": 328332, "start": 3283.6400000000003, "end": 3290.6000000000004, "text": " in modern day, whether or not we could take another shot at it. And if you also think that,", "tokens": [50380, 294, 4363, 786, 11, 1968, 420, 406, 321, 727, 747, 1071, 3347, 412, 309, 13, 400, 498, 291, 611, 519, 300, 11, 50728], "temperature": 0.0, "avg_logprob": -0.11726396933369253, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.00032501600799150765}, {"id": 465, "seek": 328332, "start": 3290.6000000000004, "end": 3296.52, "text": " well, everything now is neural, or machine learning, you just remember that neural networks", "tokens": [50728, 731, 11, 1203, 586, 307, 18161, 11, 420, 3479, 2539, 11, 291, 445, 1604, 300, 18161, 9590, 51024], "temperature": 0.0, "avg_logprob": -0.11726396933369253, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.00032501600799150765}, {"id": 466, "seek": 328332, "start": 3296.52, "end": 3301.1600000000003, "text": " had multiple times where they were in vogue and then went out of vogue and so forth. So,", "tokens": [51024, 632, 3866, 1413, 689, 436, 645, 294, 371, 7213, 293, 550, 1437, 484, 295, 371, 7213, 293, 370, 5220, 13, 407, 11, 51256], "temperature": 0.0, "avg_logprob": -0.11726396933369253, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.00032501600799150765}, {"id": 467, "seek": 328332, "start": 3301.1600000000003, "end": 3306.92, "text": " you know, maybe time that symbolic systems or at least neuro symbolic combinations of systems", "tokens": [51256, 291, 458, 11, 1310, 565, 300, 25755, 3652, 420, 412, 1935, 16499, 25755, 21267, 295, 3652, 51544], "temperature": 0.0, "avg_logprob": -0.11726396933369253, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.00032501600799150765}, {"id": 468, "seek": 330692, "start": 3307.8, "end": 3313.8, "text": " are revisited in the spirit of things like advice taker and McCarthy and Doyle and Minsky", "tokens": [50408, 366, 20767, 1226, 294, 264, 3797, 295, 721, 411, 5192, 991, 260, 293, 44085, 293, 40059, 306, 293, 376, 44153, 50708], "temperature": 0.0, "avg_logprob": -0.1564094392876876, "compression_ratio": 1.2592592592592593, "no_speech_prob": 0.00734510226175189}, {"id": 469, "seek": 330692, "start": 3313.8, "end": 3321.16, "text": " and Sussman and so forth. Thank you very much.", "tokens": [50708, 293, 318, 2023, 1601, 293, 370, 5220, 13, 1044, 291, 588, 709, 13, 51076], "temperature": 0.0, "avg_logprob": -0.1564094392876876, "compression_ratio": 1.2592592592592593, "no_speech_prob": 0.00734510226175189}], "language": "en"}