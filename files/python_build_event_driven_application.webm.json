{"text": " Hi, everyone. I would like you to give a big welcome to Yaniv, who is coming from Israel to speak about building event-driven applications. Thank you. The floor is yours. Thank you very much for this warm hospitality and for the clapping. First time in Amsterdam, first time in Belgium, so I'm not sure how many locals from here, but one of the most beautiful places I've ever seen. I'm really happy that I got the chance to visit both, both Amsterdam and Belgium. My name is Yaniv. I'm coming from Israel and Memphis, Dev. I prepared a short and sweet tutorial about how to build an event-driven application, the main building blocks. And I also prepared a short code tutorial, not sure how much time we would have for this part of the talk, but we will try to reach there. So just a quick intro about Memphis, Dev. Basically, simple as rabbit, robust as Kafka, and perfect for busy developers. So it's a next generation of messaging brokers and messaging queues, and that's what we try to build. A bit about our open source. We are an open source project under Apache 2.0 license, so 2.2K stars on GitHub, 500 community members, contributors, production users. And if anyone is looking for an open source project to participate and maintain, we are always open and welcome new members. And that's it. What is an event? I mean, probably I'll go over some very basic stuff that you probably all know all about, but I find event-driven architecture a bit frightening. I mean, the terminology itself can be a bit frightening, but probably most of us are already participating or doing some event-driven architecture application. So just to create a baseline about what an event is, so it's a short update about something. It can be an order that took place. It can be a Kubernetes resource issue. Unfamiliar login. We see a lot of use cases around cybersecurity regarding cloud events and things that are not supposed to happen around our environment or premise or VPC. So we do a lot of event-driven application or event-driven workflows around that area. A network endpoint that got disconnected. All of that are basically events. And it would most probably look like that structure of day description and status. And it's important to save the status because we will see in the tutorial overview that we want to keep the state of the event because usually that event will go through several consumers, several processors, and we want to make sure that we are completely aware to the different stages of that event as it goes along through the pipeline. Event-driven architecture, EDA. All of a sudden, I think in the past two years, it's sort of turned into a buzzword. We see a lot of EDA articles and tutorials and features and companies that goes around EDA, so just to create a baseline on that part. So event-driven architecture is basically you have an event, something happened in our environment, and we trigger an action based on that. And when I say event, it's not that. So change the background to red and then all of a sudden the background is turned into red. It's most like order received and then we need to prepare the order. If, for example, we're talking about Deliveroo or DoorDash or Uber, chain of reaction happens based on that event. So it's not just like creating a trigger or a meet that does something on that event. It's basically an entire pipeline, an entire flow that goes, the trigger because of that event. So act on events on real time and usually more than one action per event. So it's not the changing background to red. It usually will be preparing the order notification for the customer, for the client, BI delivery. Again, according to the use case, but more than one action per event. I thought this one would be funny. Anyway, I managed to get some. So main building blocks of EDA. So first of all, defining the events, right? We need to understand what are the events that require certain actions. So we're defining the events and then we're defining the actions, right? So preparing the order, push to delivery, report to some executive about the BI or revenue, the change or something like that. Update databases. If it's, for example, the Kubernetes example that I gave, we need to trigger more resources. We need to create more EBSs, more EC2s, auto scaling of resources. So that would be the actions per event. So we usually start with mapping the events that are important to our use case, to our organization, to our platform, and then define the actions. And then we go for coding. And the building blocks or the infrastructure that supports that architecture is basically microservices and queue. We'll go in a second, why microservices and why queue. I know there is a long debate about microservices. I thought that we got over it about like two years ago. And microservices won the big debate of monolith or microservices. But apparently not. I mean, there are many, many debates in the social about it. I'm completely with microservices. So definitely doing a monolith would get you faster to what you or where you want to get. But definitely regarding scale, decoupling, event-driven architecture, microservices is your answer. And when we have microservices, we need a queue to create the asynchronous or the buffering layer between the microservices that will be responsible for the async transportation between the different services. So decoupling services, queue will basically enable us to decouple different services. So service A, not really aware if there is something on the other side that is waiting to consume. The data is just push it and then acknowledge back to the client or to the front-end or whatever that event started to be handled. Thread pool, if we have, for example, the need for scale. So if our restaurant or Uber app or food delivery app all of a sudden from one order per day got to scale into one million orders per day. So we need to scale the different microservices and a queue is perfect for that part. And real-time pipelines. So queues started as a buffering layer between services, between applications. But in the past three years, I would say, it also started to enable different parts. You probably read about them in event streaming or event processing in Kafka. But these days, you also can use queues as a temporary database for real-time pipelines, for example. What do I mean by real-time, by temporary databases, basically that your queue in the middle or actually a message broker, because the queue most of the time implements one-to-one pattern and message broker is one-to-many. So if, for example, a queue or a broker in the middle, if we have it and we have a bunch of or chain of reactions that needs to take place and process the data as it flows between services. So we basically push the data or the raw event into the queue and then Microservice B will take it, process the data, throw it to Microservice C that will process the data and then at the end will preserve it in some database or do finalize action to end the workflow and it's all enabled by the queue in the middle and the entire transportation and orchestration of the data between the different microservices. So yeah, tutorial, how much time do we have left? 10 minutes, something like that? 15 minutes, okay, awesome, thank you. So quickly about the tutorial that I've prepared, nothing fancy just to explain the real-time pipeline and how it implemented using a queue or a broker. So we have the customer on the left side, it's sort of like an Uber Eats sort of application. The customer creates an order through the front end and the front end preserve the data onto a MongoDB and push the events of that order into Memphis queue orders and then we have another service that creates the processing. Again, preserving the state, if you remember at the first slide I talked about preserving the state as it goes along through the different services because if, for example, all of a sudden something happened to the processing service or the delivery service, we know when or from where to process or to reprocess that order because we don't want to create and duplicate orders because processing or delivery all of a sudden crashed or something like that which happens a lot in real-time pipelines. So that's the general idea, so it goes through processing saving the state or updating the state on MongoDB again, push that order to Memphis queue deliveries where we have some delivery person that takes that order and create a delivery to the happy customer on the left. So let's see some code and how it looks like in reality. So again, nothing fancy. This is what it looks like if we had like a Flask API using Flask framework to create that API endpoints. It starts with an index which gives the rendered frontend and then we have the order food API endpoint and that would be like the MVP to create the ball of prey. Sorry. Oh, and to increase, like most zoom. Okay, thanks. One second. Is it big enough? Yes. Okay, thanks. So, sorry. One more. One more? One more. Okay. Big enough. Thanks. Okay. So that would be our boilerplate, but if we want to take it to the next level, let me just remove that part, but if we want to take it to the next level and add a queue into it. So let's quickly go over the different parts. Let's start from the main. So we basically have the order food endpoint. So a trigger will go to the order food endpoint and then we basically print some output for that new order received, we'll print it, then we'll create a current time, we'll stamp the order with the current time, order date with that current time, status means the state of it, so it's a new order, generate ID, and then create a new document inside our NoSQL database and then push the order towards processing, so meaning the part that the event goes through Memphis for further processing, that would be the part that handles that. Let's see, for one second, it goes all the way up, so we basically connect to Memphis, connect to the cluster itself, create a producer, and then produce that event to the station. We'll see it in a minute, like in a more visual way. And then afterwards comes the part three. I mean, part two, actually, the process itself. So the process itself, basically there is a component that listens to events coming from Memphis. So Memphis implements the paradigm of produce and consume, so it's not pushing the events into the processing part, but actually the processing service consume that event and start acting based on that. So it's an event-driven architecture that we describe. It's idle until something happened or some order got into the queue. So new order received, just short parsing into JSON, also creating a quarantine for that part, preparing the dish. It's a pretty fast restaurant. Order is ready for delivery. And we're changing the state to delivery and hack the message. The acknowledging message in every queue or broker means that I received the message, I did my processing, my handling, and it's okay to send me more messages. So that's the asynchronous part. So we do some filtering, new values, according to what MongoDB asked us to do, and we update that document, the state of it, so it goes from new order to delivery, so it's ready for delivery, and then we send the delivery, or we send the order to the delivery part. And that's, I would say, that's the main idea of doing asynchronous movement, because at the moment we are a young startup, we have only one delivery person, and all of a sudden we got scaled. And we need more delivery person. We don't want to add, like, more power into that compute, but we want to add more, to scale out our resources and add more threads, add more workers. So we would scale the delivery part, so instead of using just one service for delivery, all of a sudden we can just scale out to 10 or 100 different delivery persons, which is a delivery services. So we send the delivery event into the delivery queue, which looks pretty the same as the processing, so we will start with consuming, and then hacking the message, actually on that part right in the beginning. I just wanted to show two different ways to doing so. So in streaming, or in data streaming, basically we want to acknowledge the message really, really fast, because streaming is made for scale when we got to the place that we want to queue, or a message worker would probably handle or handling large scale of data, so we want to quickly acknowledge the message to free up our buffer and receive more messages. So at the previous service, at the processing service, we acknowledge the message only after the preparing, which is perfectly fine, but in this part, again, if all of a sudden we have massive scale that we need to handle, in order to avoid back pressure on our broker, we absorb that back pressure and doing a fast acknowledging on our client, it's just another way to doing things, and it based on your use case and how much your use case is sensitive to avoid, for example, a message or an event. Thanks. A message or event, because if, for example, we acknowledge the message, and all of a sudden, on that part, our service will go down for some reason, we basically will lost that event and we will not deliver it, and the customer will not be so happy and we will need to re-trigger the entire workflow. So just another way to doing stuff, when we work with massive scale like Uber, like Netflix, like Deliver or something like that, it definitely needs to be in that way and here will maybe come another action or a usage of a cache database like Redis that will preserve that event just for that time, just for the processing time. So again, as we did in the previous services, we print some output, we update the database with the status delivered, that's that part, and we basically print everything to our own logging and auditing and everything will be also updated inside the database, so we will be able to observe that order and the entire life cycle of ordering, processing and delivery. So I will do, I will just run it really, really quickly because I also, and by the way, everything is written in medium and you have a GitHub repo if you want to just check out the code a bit and play with it, so you have a Docker Compose, you just need to run it. It's a live demo, so I hope that it will be all right right now. Okay, so we started everything, all the services are up. Let's see, we have the front end, the process and the delivery are up and we have a local community Mongo that we used just for the preparation but we could use Atlas or any other Mongo that we wanted and just shoot an event or order some food and see what happened. So I have Memphis Sandbox here, Hope End, which emphasized the queues within it, so if I'll go to orders new, I should see our new order here. Let's see, it's a bit small, it's small here as well. So we have the status of the order, we see the order itself, we see on the other side the processing service that takes the data, do something, sorry, something that does something and push it towards the delivery queue and we should see the same event here, so ready date, order date, exactly. So we'll go to the MongoDB and refresh it a bit. We should see our order here as well, so we can see the entire state as it goes or as it updated through the different services. We have the order date and three seconds after the dish is ready and four seconds after it's already sent to the customer. So that's the main event and it happened entirely as synchronously and it's a great hamburger and yeah. So that's what I wanted to show and again as we talked about the debate of microservices versus monoliths so I wrote a lot of articles about it. I started my journey with data many years ago, four years ago, something like that, especially with data streaming. We built a data streaming based AI project that basically analyzed using LDA, Twitter and Facebook to get the general conversation of the public and the need for scale and agility really takes place very, very, very fast so I really recommend everyone to start even not to build with microservices and queues and asynchronous patterns but at least try or think about the refactor that you will need to do if you decided to go with the monolith and not even driven architecture. So that's it. Thank you very much for this opportunity. Really happy to be here.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.0, "text": " Hi, everyone. I would like you to give a big welcome to Yaniv, who is coming from Israel", "tokens": [50364, 2421, 11, 1518, 13, 286, 576, 411, 291, 281, 976, 257, 955, 2928, 281, 13633, 592, 11, 567, 307, 1348, 490, 5674, 50914], "temperature": 0.0, "avg_logprob": -0.2936214323966734, "compression_ratio": 1.4424242424242424, "no_speech_prob": 0.5573369860649109}, {"id": 1, "seek": 0, "start": 11.0, "end": 15.0, "text": " to speak about building event-driven applications.", "tokens": [50914, 281, 1710, 466, 2390, 2280, 12, 25456, 5821, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2936214323966734, "compression_ratio": 1.4424242424242424, "no_speech_prob": 0.5573369860649109}, {"id": 2, "seek": 0, "start": 15.0, "end": 21.0, "text": " Thank you. The floor is yours.", "tokens": [51114, 1044, 291, 13, 440, 4123, 307, 6342, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2936214323966734, "compression_ratio": 1.4424242424242424, "no_speech_prob": 0.5573369860649109}, {"id": 3, "seek": 0, "start": 21.0, "end": 26.0, "text": " Thank you very much for this warm hospitality and for the clapping.", "tokens": [51414, 1044, 291, 588, 709, 337, 341, 4561, 31207, 293, 337, 264, 19978, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2936214323966734, "compression_ratio": 1.4424242424242424, "no_speech_prob": 0.5573369860649109}, {"id": 4, "seek": 2600, "start": 26.0, "end": 30.0, "text": " First time in Amsterdam, first time in Belgium, so I'm not sure how many locals from here,", "tokens": [50364, 2386, 565, 294, 28291, 11, 700, 565, 294, 28094, 11, 370, 286, 478, 406, 988, 577, 867, 23335, 490, 510, 11, 50564], "temperature": 0.0, "avg_logprob": -0.1566686352479805, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.7216067314147949}, {"id": 5, "seek": 2600, "start": 30.0, "end": 34.0, "text": " but one of the most beautiful places I've ever seen.", "tokens": [50564, 457, 472, 295, 264, 881, 2238, 3190, 286, 600, 1562, 1612, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1566686352479805, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.7216067314147949}, {"id": 6, "seek": 2600, "start": 34.0, "end": 40.0, "text": " I'm really happy that I got the chance to visit both, both Amsterdam and Belgium.", "tokens": [50764, 286, 478, 534, 2055, 300, 286, 658, 264, 2931, 281, 3441, 1293, 11, 1293, 28291, 293, 28094, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1566686352479805, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.7216067314147949}, {"id": 7, "seek": 2600, "start": 40.0, "end": 44.0, "text": " My name is Yaniv. I'm coming from Israel and Memphis, Dev.", "tokens": [51064, 1222, 1315, 307, 13633, 592, 13, 286, 478, 1348, 490, 5674, 293, 26743, 11, 9096, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1566686352479805, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.7216067314147949}, {"id": 8, "seek": 2600, "start": 44.0, "end": 50.0, "text": " I prepared a short and sweet tutorial about how to build an event-driven application,", "tokens": [51264, 286, 4927, 257, 2099, 293, 3844, 7073, 466, 577, 281, 1322, 364, 2280, 12, 25456, 3861, 11, 51564], "temperature": 0.0, "avg_logprob": -0.1566686352479805, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.7216067314147949}, {"id": 9, "seek": 2600, "start": 50.0, "end": 52.0, "text": " the main building blocks.", "tokens": [51564, 264, 2135, 2390, 8474, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1566686352479805, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.7216067314147949}, {"id": 10, "seek": 5200, "start": 52.0, "end": 59.0, "text": " And I also prepared a short code tutorial, not sure how much time we would have", "tokens": [50364, 400, 286, 611, 4927, 257, 2099, 3089, 7073, 11, 406, 988, 577, 709, 565, 321, 576, 362, 50714], "temperature": 0.0, "avg_logprob": -0.1625077383858817, "compression_ratio": 1.4708520179372198, "no_speech_prob": 0.05749405175447464}, {"id": 11, "seek": 5200, "start": 59.0, "end": 65.0, "text": " for this part of the talk, but we will try to reach there.", "tokens": [50714, 337, 341, 644, 295, 264, 751, 11, 457, 321, 486, 853, 281, 2524, 456, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1625077383858817, "compression_ratio": 1.4708520179372198, "no_speech_prob": 0.05749405175447464}, {"id": 12, "seek": 5200, "start": 65.0, "end": 68.0, "text": " So just a quick intro about Memphis, Dev.", "tokens": [51014, 407, 445, 257, 1702, 12897, 466, 26743, 11, 9096, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1625077383858817, "compression_ratio": 1.4708520179372198, "no_speech_prob": 0.05749405175447464}, {"id": 13, "seek": 5200, "start": 68.0, "end": 74.0, "text": " Basically, simple as rabbit, robust as Kafka, and perfect for busy developers.", "tokens": [51164, 8537, 11, 2199, 382, 19509, 11, 13956, 382, 47064, 11, 293, 2176, 337, 5856, 8849, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1625077383858817, "compression_ratio": 1.4708520179372198, "no_speech_prob": 0.05749405175447464}, {"id": 14, "seek": 5200, "start": 74.0, "end": 79.0, "text": " So it's a next generation of messaging brokers and messaging queues,", "tokens": [51464, 407, 309, 311, 257, 958, 5125, 295, 21812, 47549, 293, 21812, 631, 1247, 11, 51714], "temperature": 0.0, "avg_logprob": -0.1625077383858817, "compression_ratio": 1.4708520179372198, "no_speech_prob": 0.05749405175447464}, {"id": 15, "seek": 7900, "start": 79.0, "end": 82.0, "text": " and that's what we try to build.", "tokens": [50364, 293, 300, 311, 437, 321, 853, 281, 1322, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10747678544786242, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.08479198813438416}, {"id": 16, "seek": 7900, "start": 82.0, "end": 87.0, "text": " A bit about our open source. We are an open source project under Apache 2.0 license,", "tokens": [50514, 316, 857, 466, 527, 1269, 4009, 13, 492, 366, 364, 1269, 4009, 1716, 833, 46597, 568, 13, 15, 10476, 11, 50764], "temperature": 0.0, "avg_logprob": -0.10747678544786242, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.08479198813438416}, {"id": 17, "seek": 7900, "start": 87.0, "end": 94.0, "text": " so 2.2K stars on GitHub, 500 community members, contributors, production users.", "tokens": [50764, 370, 568, 13, 17, 42, 6105, 322, 23331, 11, 5923, 1768, 2679, 11, 45627, 11, 4265, 5022, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10747678544786242, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.08479198813438416}, {"id": 18, "seek": 7900, "start": 94.0, "end": 99.0, "text": " And if anyone is looking for an open source project to participate and maintain,", "tokens": [51114, 400, 498, 2878, 307, 1237, 337, 364, 1269, 4009, 1716, 281, 8197, 293, 6909, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10747678544786242, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.08479198813438416}, {"id": 19, "seek": 7900, "start": 99.0, "end": 104.0, "text": " we are always open and welcome new members.", "tokens": [51364, 321, 366, 1009, 1269, 293, 2928, 777, 2679, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10747678544786242, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.08479198813438416}, {"id": 20, "seek": 7900, "start": 104.0, "end": 106.0, "text": " And that's it.", "tokens": [51614, 400, 300, 311, 309, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10747678544786242, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.08479198813438416}, {"id": 21, "seek": 10600, "start": 106.0, "end": 111.0, "text": " What is an event? I mean, probably I'll go over some very basic stuff", "tokens": [50364, 708, 307, 364, 2280, 30, 286, 914, 11, 1391, 286, 603, 352, 670, 512, 588, 3875, 1507, 50614], "temperature": 0.0, "avg_logprob": -0.09934577163384885, "compression_ratio": 1.7552742616033756, "no_speech_prob": 0.04173998162150383}, {"id": 22, "seek": 10600, "start": 111.0, "end": 118.0, "text": " that you probably all know all about, but I find event-driven architecture a bit frightening.", "tokens": [50614, 300, 291, 1391, 439, 458, 439, 466, 11, 457, 286, 915, 2280, 12, 25456, 9482, 257, 857, 31043, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09934577163384885, "compression_ratio": 1.7552742616033756, "no_speech_prob": 0.04173998162150383}, {"id": 23, "seek": 10600, "start": 118.0, "end": 121.0, "text": " I mean, the terminology itself can be a bit frightening,", "tokens": [50964, 286, 914, 11, 264, 27575, 2564, 393, 312, 257, 857, 31043, 11, 51114], "temperature": 0.0, "avg_logprob": -0.09934577163384885, "compression_ratio": 1.7552742616033756, "no_speech_prob": 0.04173998162150383}, {"id": 24, "seek": 10600, "start": 121.0, "end": 127.0, "text": " but probably most of us are already participating or doing some event-driven architecture application.", "tokens": [51114, 457, 1391, 881, 295, 505, 366, 1217, 13950, 420, 884, 512, 2280, 12, 25456, 9482, 3861, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09934577163384885, "compression_ratio": 1.7552742616033756, "no_speech_prob": 0.04173998162150383}, {"id": 25, "seek": 10600, "start": 127.0, "end": 133.0, "text": " So just to create a baseline about what an event is, so it's a short update about something.", "tokens": [51414, 407, 445, 281, 1884, 257, 20518, 466, 437, 364, 2280, 307, 11, 370, 309, 311, 257, 2099, 5623, 466, 746, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09934577163384885, "compression_ratio": 1.7552742616033756, "no_speech_prob": 0.04173998162150383}, {"id": 26, "seek": 13300, "start": 133.0, "end": 139.0, "text": " It can be an order that took place. It can be a Kubernetes resource issue.", "tokens": [50364, 467, 393, 312, 364, 1668, 300, 1890, 1081, 13, 467, 393, 312, 257, 23145, 7684, 2734, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09683356104017812, "compression_ratio": 1.5829383886255923, "no_speech_prob": 0.02778625302016735}, {"id": 27, "seek": 13300, "start": 139.0, "end": 145.0, "text": " Unfamiliar login. We see a lot of use cases around cybersecurity regarding cloud events", "tokens": [50664, 8170, 27393, 24276, 13, 492, 536, 257, 688, 295, 764, 3331, 926, 38765, 8595, 4588, 3931, 50964], "temperature": 0.0, "avg_logprob": -0.09683356104017812, "compression_ratio": 1.5829383886255923, "no_speech_prob": 0.02778625302016735}, {"id": 28, "seek": 13300, "start": 145.0, "end": 152.0, "text": " and things that are not supposed to happen around our environment or premise or VPC.", "tokens": [50964, 293, 721, 300, 366, 406, 3442, 281, 1051, 926, 527, 2823, 420, 22045, 420, 691, 12986, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09683356104017812, "compression_ratio": 1.5829383886255923, "no_speech_prob": 0.02778625302016735}, {"id": 29, "seek": 13300, "start": 152.0, "end": 159.0, "text": " So we do a lot of event-driven application or event-driven workflows around that area.", "tokens": [51314, 407, 321, 360, 257, 688, 295, 2280, 12, 25456, 3861, 420, 2280, 12, 25456, 43461, 926, 300, 1859, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09683356104017812, "compression_ratio": 1.5829383886255923, "no_speech_prob": 0.02778625302016735}, {"id": 30, "seek": 15900, "start": 160.0, "end": 165.0, "text": " A network endpoint that got disconnected. All of that are basically events.", "tokens": [50414, 316, 3209, 35795, 300, 658, 29426, 13, 1057, 295, 300, 366, 1936, 3931, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09096402592129177, "compression_ratio": 1.690721649484536, "no_speech_prob": 0.03960121050477028}, {"id": 31, "seek": 15900, "start": 165.0, "end": 172.0, "text": " And it would most probably look like that structure of day description and status.", "tokens": [50664, 400, 309, 576, 881, 1391, 574, 411, 300, 3877, 295, 786, 3855, 293, 6558, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09096402592129177, "compression_ratio": 1.690721649484536, "no_speech_prob": 0.03960121050477028}, {"id": 32, "seek": 15900, "start": 172.0, "end": 178.0, "text": " And it's important to save the status because we will see in the tutorial overview", "tokens": [51014, 400, 309, 311, 1021, 281, 3155, 264, 6558, 570, 321, 486, 536, 294, 264, 7073, 12492, 51314], "temperature": 0.0, "avg_logprob": -0.09096402592129177, "compression_ratio": 1.690721649484536, "no_speech_prob": 0.03960121050477028}, {"id": 33, "seek": 15900, "start": 178.0, "end": 185.0, "text": " that we want to keep the state of the event because usually that event will go through", "tokens": [51314, 300, 321, 528, 281, 1066, 264, 1785, 295, 264, 2280, 570, 2673, 300, 2280, 486, 352, 807, 51664], "temperature": 0.0, "avg_logprob": -0.09096402592129177, "compression_ratio": 1.690721649484536, "no_speech_prob": 0.03960121050477028}, {"id": 34, "seek": 18500, "start": 185.0, "end": 190.0, "text": " several consumers, several processors, and we want to make sure that we are completely aware", "tokens": [50364, 2940, 11883, 11, 2940, 27751, 11, 293, 321, 528, 281, 652, 988, 300, 321, 366, 2584, 3650, 50614], "temperature": 0.0, "avg_logprob": -0.09074745408023696, "compression_ratio": 1.5022831050228311, "no_speech_prob": 0.003841944970190525}, {"id": 35, "seek": 18500, "start": 190.0, "end": 196.0, "text": " to the different stages of that event as it goes along through the pipeline.", "tokens": [50614, 281, 264, 819, 10232, 295, 300, 2280, 382, 309, 1709, 2051, 807, 264, 15517, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09074745408023696, "compression_ratio": 1.5022831050228311, "no_speech_prob": 0.003841944970190525}, {"id": 36, "seek": 18500, "start": 196.0, "end": 204.0, "text": " Event-driven architecture, EDA. All of a sudden, I think in the past two years,", "tokens": [50914, 13222, 12, 25456, 9482, 11, 462, 7509, 13, 1057, 295, 257, 3990, 11, 286, 519, 294, 264, 1791, 732, 924, 11, 51314], "temperature": 0.0, "avg_logprob": -0.09074745408023696, "compression_ratio": 1.5022831050228311, "no_speech_prob": 0.003841944970190525}, {"id": 37, "seek": 18500, "start": 204.0, "end": 212.0, "text": " it's sort of turned into a buzzword. We see a lot of EDA articles and tutorials", "tokens": [51314, 309, 311, 1333, 295, 3574, 666, 257, 13036, 7462, 13, 492, 536, 257, 688, 295, 462, 7509, 11290, 293, 17616, 51714], "temperature": 0.0, "avg_logprob": -0.09074745408023696, "compression_ratio": 1.5022831050228311, "no_speech_prob": 0.003841944970190525}, {"id": 38, "seek": 21200, "start": 212.0, "end": 219.0, "text": " and features and companies that goes around EDA, so just to create a baseline on that part.", "tokens": [50364, 293, 4122, 293, 3431, 300, 1709, 926, 462, 7509, 11, 370, 445, 281, 1884, 257, 20518, 322, 300, 644, 13, 50714], "temperature": 0.0, "avg_logprob": -0.10634006851020901, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.00992607232183218}, {"id": 39, "seek": 21200, "start": 219.0, "end": 226.0, "text": " So event-driven architecture is basically you have an event, something happened in our environment,", "tokens": [50714, 407, 2280, 12, 25456, 9482, 307, 1936, 291, 362, 364, 2280, 11, 746, 2011, 294, 527, 2823, 11, 51064], "temperature": 0.0, "avg_logprob": -0.10634006851020901, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.00992607232183218}, {"id": 40, "seek": 21200, "start": 226.0, "end": 232.0, "text": " and we trigger an action based on that. And when I say event, it's not that.", "tokens": [51064, 293, 321, 7875, 364, 3069, 2361, 322, 300, 13, 400, 562, 286, 584, 2280, 11, 309, 311, 406, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10634006851020901, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.00992607232183218}, {"id": 41, "seek": 21200, "start": 232.0, "end": 237.0, "text": " So change the background to red and then all of a sudden the background is turned into red.", "tokens": [51364, 407, 1319, 264, 3678, 281, 2182, 293, 550, 439, 295, 257, 3990, 264, 3678, 307, 3574, 666, 2182, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10634006851020901, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.00992607232183218}, {"id": 42, "seek": 23700, "start": 237.0, "end": 242.0, "text": " It's most like order received and then we need to prepare the order.", "tokens": [50364, 467, 311, 881, 411, 1668, 4613, 293, 550, 321, 643, 281, 5940, 264, 1668, 13, 50614], "temperature": 0.0, "avg_logprob": -0.12809615439557015, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.03385460376739502}, {"id": 43, "seek": 23700, "start": 242.0, "end": 248.0, "text": " If, for example, we're talking about Deliveroo or DoorDash or Uber,", "tokens": [50614, 759, 11, 337, 1365, 11, 321, 434, 1417, 466, 5831, 1837, 1986, 420, 29636, 35, 1299, 420, 21839, 11, 50914], "temperature": 0.0, "avg_logprob": -0.12809615439557015, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.03385460376739502}, {"id": 44, "seek": 23700, "start": 248.0, "end": 252.0, "text": " chain of reaction happens based on that event.", "tokens": [50914, 5021, 295, 5480, 2314, 2361, 322, 300, 2280, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12809615439557015, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.03385460376739502}, {"id": 45, "seek": 23700, "start": 252.0, "end": 258.0, "text": " So it's not just like creating a trigger or a meet that does something on that event.", "tokens": [51114, 407, 309, 311, 406, 445, 411, 4084, 257, 7875, 420, 257, 1677, 300, 775, 746, 322, 300, 2280, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12809615439557015, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.03385460376739502}, {"id": 46, "seek": 23700, "start": 258.0, "end": 266.0, "text": " It's basically an entire pipeline, an entire flow that goes, the trigger because of that event.", "tokens": [51414, 467, 311, 1936, 364, 2302, 15517, 11, 364, 2302, 3095, 300, 1709, 11, 264, 7875, 570, 295, 300, 2280, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12809615439557015, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.03385460376739502}, {"id": 47, "seek": 26600, "start": 266.0, "end": 271.0, "text": " So act on events on real time and usually more than one action per event.", "tokens": [50364, 407, 605, 322, 3931, 322, 957, 565, 293, 2673, 544, 813, 472, 3069, 680, 2280, 13, 50614], "temperature": 0.0, "avg_logprob": -0.13620799264790098, "compression_ratio": 1.6546391752577319, "no_speech_prob": 0.004432590678334236}, {"id": 48, "seek": 26600, "start": 271.0, "end": 274.0, "text": " So it's not the changing background to red.", "tokens": [50614, 407, 309, 311, 406, 264, 4473, 3678, 281, 2182, 13, 50764], "temperature": 0.0, "avg_logprob": -0.13620799264790098, "compression_ratio": 1.6546391752577319, "no_speech_prob": 0.004432590678334236}, {"id": 49, "seek": 26600, "start": 274.0, "end": 281.0, "text": " It usually will be preparing the order notification for the customer, for the client, BI delivery.", "tokens": [50764, 467, 2673, 486, 312, 10075, 264, 1668, 11554, 337, 264, 5474, 11, 337, 264, 6423, 11, 23524, 8982, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13620799264790098, "compression_ratio": 1.6546391752577319, "no_speech_prob": 0.004432590678334236}, {"id": 50, "seek": 26600, "start": 281.0, "end": 287.0, "text": " Again, according to the use case, but more than one action per event.", "tokens": [51114, 3764, 11, 4650, 281, 264, 764, 1389, 11, 457, 544, 813, 472, 3069, 680, 2280, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13620799264790098, "compression_ratio": 1.6546391752577319, "no_speech_prob": 0.004432590678334236}, {"id": 51, "seek": 26600, "start": 290.0, "end": 292.0, "text": " I thought this one would be funny.", "tokens": [51564, 286, 1194, 341, 472, 576, 312, 4074, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13620799264790098, "compression_ratio": 1.6546391752577319, "no_speech_prob": 0.004432590678334236}, {"id": 52, "seek": 29200, "start": 293.0, "end": 297.0, "text": " Anyway, I managed to get some.", "tokens": [50414, 5684, 11, 286, 6453, 281, 483, 512, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11763364813301001, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0026481549721211195}, {"id": 53, "seek": 29200, "start": 297.0, "end": 299.0, "text": " So main building blocks of EDA.", "tokens": [50614, 407, 2135, 2390, 8474, 295, 462, 7509, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11763364813301001, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0026481549721211195}, {"id": 54, "seek": 29200, "start": 299.0, "end": 301.0, "text": " So first of all, defining the events, right?", "tokens": [50714, 407, 700, 295, 439, 11, 17827, 264, 3931, 11, 558, 30, 50814], "temperature": 0.0, "avg_logprob": -0.11763364813301001, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0026481549721211195}, {"id": 55, "seek": 29200, "start": 301.0, "end": 305.0, "text": " We need to understand what are the events that require certain actions.", "tokens": [50814, 492, 643, 281, 1223, 437, 366, 264, 3931, 300, 3651, 1629, 5909, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11763364813301001, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0026481549721211195}, {"id": 56, "seek": 29200, "start": 305.0, "end": 309.0, "text": " So we're defining the events and then we're defining the actions, right?", "tokens": [51014, 407, 321, 434, 17827, 264, 3931, 293, 550, 321, 434, 17827, 264, 5909, 11, 558, 30, 51214], "temperature": 0.0, "avg_logprob": -0.11763364813301001, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0026481549721211195}, {"id": 57, "seek": 29200, "start": 309.0, "end": 316.0, "text": " So preparing the order, push to delivery, report to some executive about the BI or revenue,", "tokens": [51214, 407, 10075, 264, 1668, 11, 2944, 281, 8982, 11, 2275, 281, 512, 10140, 466, 264, 23524, 420, 9324, 11, 51564], "temperature": 0.0, "avg_logprob": -0.11763364813301001, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0026481549721211195}, {"id": 58, "seek": 31600, "start": 316.0, "end": 318.0, "text": " the change or something like that.", "tokens": [50364, 264, 1319, 420, 746, 411, 300, 13, 50464], "temperature": 0.0, "avg_logprob": -0.106214968363444, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0265412125736475}, {"id": 59, "seek": 31600, "start": 318.0, "end": 320.0, "text": " Update databases.", "tokens": [50464, 28923, 22380, 13, 50564], "temperature": 0.0, "avg_logprob": -0.106214968363444, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0265412125736475}, {"id": 60, "seek": 31600, "start": 320.0, "end": 326.0, "text": " If it's, for example, the Kubernetes example that I gave, we need to trigger more resources.", "tokens": [50564, 759, 309, 311, 11, 337, 1365, 11, 264, 23145, 1365, 300, 286, 2729, 11, 321, 643, 281, 7875, 544, 3593, 13, 50864], "temperature": 0.0, "avg_logprob": -0.106214968363444, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0265412125736475}, {"id": 61, "seek": 31600, "start": 326.0, "end": 330.0, "text": " We need to create more EBSs, more EC2s, auto scaling of resources.", "tokens": [50864, 492, 643, 281, 1884, 544, 462, 8176, 82, 11, 544, 19081, 17, 82, 11, 8399, 21589, 295, 3593, 13, 51064], "temperature": 0.0, "avg_logprob": -0.106214968363444, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0265412125736475}, {"id": 62, "seek": 31600, "start": 330.0, "end": 332.0, "text": " So that would be the actions per event.", "tokens": [51064, 407, 300, 576, 312, 264, 5909, 680, 2280, 13, 51164], "temperature": 0.0, "avg_logprob": -0.106214968363444, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0265412125736475}, {"id": 63, "seek": 31600, "start": 332.0, "end": 336.0, "text": " So we usually start with mapping the events that are important to our use case,", "tokens": [51164, 407, 321, 2673, 722, 365, 18350, 264, 3931, 300, 366, 1021, 281, 527, 764, 1389, 11, 51364], "temperature": 0.0, "avg_logprob": -0.106214968363444, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0265412125736475}, {"id": 64, "seek": 31600, "start": 336.0, "end": 340.0, "text": " to our organization, to our platform, and then define the actions.", "tokens": [51364, 281, 527, 4475, 11, 281, 527, 3663, 11, 293, 550, 6964, 264, 5909, 13, 51564], "temperature": 0.0, "avg_logprob": -0.106214968363444, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0265412125736475}, {"id": 65, "seek": 34000, "start": 340.0, "end": 343.0, "text": " And then we go for coding.", "tokens": [50364, 400, 550, 321, 352, 337, 17720, 13, 50514], "temperature": 0.0, "avg_logprob": -0.13743038177490235, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.02673129178583622}, {"id": 66, "seek": 34000, "start": 343.0, "end": 352.0, "text": " And the building blocks or the infrastructure that supports that architecture is basically microservices and queue.", "tokens": [50514, 400, 264, 2390, 8474, 420, 264, 6896, 300, 9346, 300, 9482, 307, 1936, 15547, 47480, 293, 18639, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13743038177490235, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.02673129178583622}, {"id": 67, "seek": 34000, "start": 352.0, "end": 357.0, "text": " We'll go in a second, why microservices and why queue.", "tokens": [50964, 492, 603, 352, 294, 257, 1150, 11, 983, 15547, 47480, 293, 983, 18639, 13, 51214], "temperature": 0.0, "avg_logprob": -0.13743038177490235, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.02673129178583622}, {"id": 68, "seek": 34000, "start": 357.0, "end": 361.0, "text": " I know there is a long debate about microservices.", "tokens": [51214, 286, 458, 456, 307, 257, 938, 7958, 466, 15547, 47480, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13743038177490235, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.02673129178583622}, {"id": 69, "seek": 34000, "start": 361.0, "end": 365.0, "text": " I thought that we got over it about like two years ago.", "tokens": [51414, 286, 1194, 300, 321, 658, 670, 309, 466, 411, 732, 924, 2057, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13743038177490235, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.02673129178583622}, {"id": 70, "seek": 36500, "start": 365.0, "end": 371.0, "text": " And microservices won the big debate of monolith or microservices.", "tokens": [50364, 400, 15547, 47480, 1582, 264, 955, 7958, 295, 1108, 29131, 420, 15547, 47480, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09893419387492727, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.01189638115465641}, {"id": 71, "seek": 36500, "start": 371.0, "end": 373.0, "text": " But apparently not.", "tokens": [50664, 583, 7970, 406, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09893419387492727, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.01189638115465641}, {"id": 72, "seek": 36500, "start": 373.0, "end": 376.0, "text": " I mean, there are many, many debates in the social about it.", "tokens": [50764, 286, 914, 11, 456, 366, 867, 11, 867, 24203, 294, 264, 2093, 466, 309, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09893419387492727, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.01189638115465641}, {"id": 73, "seek": 36500, "start": 376.0, "end": 379.0, "text": " I'm completely with microservices.", "tokens": [50914, 286, 478, 2584, 365, 15547, 47480, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09893419387492727, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.01189638115465641}, {"id": 74, "seek": 36500, "start": 379.0, "end": 386.0, "text": " So definitely doing a monolith would get you faster to what you or where you want to get.", "tokens": [51064, 407, 2138, 884, 257, 1108, 29131, 576, 483, 291, 4663, 281, 437, 291, 420, 689, 291, 528, 281, 483, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09893419387492727, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.01189638115465641}, {"id": 75, "seek": 36500, "start": 386.0, "end": 393.0, "text": " But definitely regarding scale, decoupling, event-driven architecture, microservices is your answer.", "tokens": [51414, 583, 2138, 8595, 4373, 11, 979, 263, 11970, 11, 2280, 12, 25456, 9482, 11, 15547, 47480, 307, 428, 1867, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09893419387492727, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.01189638115465641}, {"id": 76, "seek": 39300, "start": 393.0, "end": 402.0, "text": " And when we have microservices, we need a queue to create the asynchronous or the buffering layer between the microservices", "tokens": [50364, 400, 562, 321, 362, 15547, 47480, 11, 321, 643, 257, 18639, 281, 1884, 264, 49174, 420, 264, 9204, 1794, 4583, 1296, 264, 15547, 47480, 50814], "temperature": 0.0, "avg_logprob": -0.10347548298452092, "compression_ratio": 1.8372093023255813, "no_speech_prob": 0.007689051330089569}, {"id": 77, "seek": 39300, "start": 402.0, "end": 407.0, "text": " that will be responsible for the async transportation between the different services.", "tokens": [50814, 300, 486, 312, 6250, 337, 264, 382, 34015, 11328, 1296, 264, 819, 3328, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10347548298452092, "compression_ratio": 1.8372093023255813, "no_speech_prob": 0.007689051330089569}, {"id": 78, "seek": 39300, "start": 407.0, "end": 414.0, "text": " So decoupling services, queue will basically enable us to decouple different services.", "tokens": [51064, 407, 979, 263, 11970, 3328, 11, 18639, 486, 1936, 9528, 505, 281, 979, 263, 781, 819, 3328, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10347548298452092, "compression_ratio": 1.8372093023255813, "no_speech_prob": 0.007689051330089569}, {"id": 79, "seek": 39300, "start": 414.0, "end": 421.0, "text": " So service A, not really aware if there is something on the other side that is waiting to consume.", "tokens": [51414, 407, 2643, 316, 11, 406, 534, 3650, 498, 456, 307, 746, 322, 264, 661, 1252, 300, 307, 3806, 281, 14732, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10347548298452092, "compression_ratio": 1.8372093023255813, "no_speech_prob": 0.007689051330089569}, {"id": 80, "seek": 42100, "start": 421.0, "end": 428.0, "text": " The data is just push it and then acknowledge back to the client or to the front-end or whatever", "tokens": [50364, 440, 1412, 307, 445, 2944, 309, 293, 550, 10692, 646, 281, 264, 6423, 420, 281, 264, 1868, 12, 521, 420, 2035, 50714], "temperature": 0.0, "avg_logprob": -0.1213430360306141, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.045161232352256775}, {"id": 81, "seek": 42100, "start": 428.0, "end": 431.0, "text": " that event started to be handled.", "tokens": [50714, 300, 2280, 1409, 281, 312, 18033, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1213430360306141, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.045161232352256775}, {"id": 82, "seek": 42100, "start": 431.0, "end": 435.0, "text": " Thread pool, if we have, for example, the need for scale.", "tokens": [50864, 334, 2538, 7005, 11, 498, 321, 362, 11, 337, 1365, 11, 264, 643, 337, 4373, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1213430360306141, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.045161232352256775}, {"id": 83, "seek": 42100, "start": 435.0, "end": 445.0, "text": " So if our restaurant or Uber app or food delivery app all of a sudden from one order per day", "tokens": [51064, 407, 498, 527, 6383, 420, 21839, 724, 420, 1755, 8982, 724, 439, 295, 257, 3990, 490, 472, 1668, 680, 786, 51564], "temperature": 0.0, "avg_logprob": -0.1213430360306141, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.045161232352256775}, {"id": 84, "seek": 42100, "start": 445.0, "end": 449.0, "text": " got to scale into one million orders per day.", "tokens": [51564, 658, 281, 4373, 666, 472, 2459, 9470, 680, 786, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1213430360306141, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.045161232352256775}, {"id": 85, "seek": 44900, "start": 449.0, "end": 454.0, "text": " So we need to scale the different microservices and a queue is perfect for that part.", "tokens": [50364, 407, 321, 643, 281, 4373, 264, 819, 15547, 47480, 293, 257, 18639, 307, 2176, 337, 300, 644, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07102909542265393, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.01120852306485176}, {"id": 86, "seek": 44900, "start": 454.0, "end": 456.0, "text": " And real-time pipelines.", "tokens": [50614, 400, 957, 12, 3766, 40168, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07102909542265393, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.01120852306485176}, {"id": 87, "seek": 44900, "start": 456.0, "end": 464.0, "text": " So queues started as a buffering layer between services, between applications.", "tokens": [50714, 407, 631, 1247, 1409, 382, 257, 9204, 1794, 4583, 1296, 3328, 11, 1296, 5821, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07102909542265393, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.01120852306485176}, {"id": 88, "seek": 44900, "start": 464.0, "end": 471.0, "text": " But in the past three years, I would say, it also started to enable different parts.", "tokens": [51114, 583, 294, 264, 1791, 1045, 924, 11, 286, 576, 584, 11, 309, 611, 1409, 281, 9528, 819, 3166, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07102909542265393, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.01120852306485176}, {"id": 89, "seek": 44900, "start": 471.0, "end": 476.0, "text": " You probably read about them in event streaming or event processing in Kafka.", "tokens": [51464, 509, 1391, 1401, 466, 552, 294, 2280, 11791, 420, 2280, 9007, 294, 47064, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07102909542265393, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.01120852306485176}, {"id": 90, "seek": 47600, "start": 476.0, "end": 486.0, "text": " But these days, you also can use queues as a temporary database for real-time pipelines, for example.", "tokens": [50364, 583, 613, 1708, 11, 291, 611, 393, 764, 631, 1247, 382, 257, 13413, 8149, 337, 957, 12, 3766, 40168, 11, 337, 1365, 13, 50864], "temperature": 0.0, "avg_logprob": -0.14511539234834558, "compression_ratio": 1.6701030927835052, "no_speech_prob": 0.046304699033498764}, {"id": 91, "seek": 47600, "start": 486.0, "end": 491.0, "text": " What do I mean by real-time, by temporary databases, basically that your queue in the middle", "tokens": [50864, 708, 360, 286, 914, 538, 957, 12, 3766, 11, 538, 13413, 22380, 11, 1936, 300, 428, 18639, 294, 264, 2808, 51114], "temperature": 0.0, "avg_logprob": -0.14511539234834558, "compression_ratio": 1.6701030927835052, "no_speech_prob": 0.046304699033498764}, {"id": 92, "seek": 47600, "start": 491.0, "end": 497.0, "text": " or actually a message broker, because the queue most of the time implements one-to-one pattern", "tokens": [51114, 420, 767, 257, 3636, 26502, 11, 570, 264, 18639, 881, 295, 264, 565, 704, 17988, 472, 12, 1353, 12, 546, 5102, 51414], "temperature": 0.0, "avg_logprob": -0.14511539234834558, "compression_ratio": 1.6701030927835052, "no_speech_prob": 0.046304699033498764}, {"id": 93, "seek": 47600, "start": 497.0, "end": 499.0, "text": " and message broker is one-to-many.", "tokens": [51414, 293, 3636, 26502, 307, 472, 12, 1353, 12, 76, 1325, 13, 51514], "temperature": 0.0, "avg_logprob": -0.14511539234834558, "compression_ratio": 1.6701030927835052, "no_speech_prob": 0.046304699033498764}, {"id": 94, "seek": 49900, "start": 499.0, "end": 505.0, "text": " So if, for example, a queue or a broker in the middle, if we have it", "tokens": [50364, 407, 498, 11, 337, 1365, 11, 257, 18639, 420, 257, 26502, 294, 264, 2808, 11, 498, 321, 362, 309, 50664], "temperature": 0.0, "avg_logprob": -0.10753792656792535, "compression_ratio": 1.67, "no_speech_prob": 0.02752789482474327}, {"id": 95, "seek": 49900, "start": 505.0, "end": 510.0, "text": " and we have a bunch of or chain of reactions that needs to take place", "tokens": [50664, 293, 321, 362, 257, 3840, 295, 420, 5021, 295, 12215, 300, 2203, 281, 747, 1081, 50914], "temperature": 0.0, "avg_logprob": -0.10753792656792535, "compression_ratio": 1.67, "no_speech_prob": 0.02752789482474327}, {"id": 96, "seek": 49900, "start": 510.0, "end": 513.0, "text": " and process the data as it flows between services.", "tokens": [50914, 293, 1399, 264, 1412, 382, 309, 12867, 1296, 3328, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10753792656792535, "compression_ratio": 1.67, "no_speech_prob": 0.02752789482474327}, {"id": 97, "seek": 49900, "start": 513.0, "end": 518.0, "text": " So we basically push the data or the raw event into the queue", "tokens": [51064, 407, 321, 1936, 2944, 264, 1412, 420, 264, 8936, 2280, 666, 264, 18639, 51314], "temperature": 0.0, "avg_logprob": -0.10753792656792535, "compression_ratio": 1.67, "no_speech_prob": 0.02752789482474327}, {"id": 98, "seek": 49900, "start": 518.0, "end": 525.0, "text": " and then Microservice B will take it, process the data, throw it to Microservice C", "tokens": [51314, 293, 550, 5818, 2635, 25006, 363, 486, 747, 309, 11, 1399, 264, 1412, 11, 3507, 309, 281, 5818, 2635, 25006, 383, 51664], "temperature": 0.0, "avg_logprob": -0.10753792656792535, "compression_ratio": 1.67, "no_speech_prob": 0.02752789482474327}, {"id": 99, "seek": 52500, "start": 525.0, "end": 532.0, "text": " that will process the data and then at the end will preserve it in some database", "tokens": [50364, 300, 486, 1399, 264, 1412, 293, 550, 412, 264, 917, 486, 15665, 309, 294, 512, 8149, 50714], "temperature": 0.0, "avg_logprob": -0.14149430510285613, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.004225744865834713}, {"id": 100, "seek": 52500, "start": 532.0, "end": 538.0, "text": " or do finalize action to end the workflow", "tokens": [50714, 420, 360, 2572, 1125, 3069, 281, 917, 264, 20993, 51014], "temperature": 0.0, "avg_logprob": -0.14149430510285613, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.004225744865834713}, {"id": 101, "seek": 52500, "start": 538.0, "end": 541.0, "text": " and it's all enabled by the queue in the middle", "tokens": [51014, 293, 309, 311, 439, 15172, 538, 264, 18639, 294, 264, 2808, 51164], "temperature": 0.0, "avg_logprob": -0.14149430510285613, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.004225744865834713}, {"id": 102, "seek": 52500, "start": 541.0, "end": 546.0, "text": " and the entire transportation and orchestration of the data between the different microservices.", "tokens": [51164, 293, 264, 2302, 11328, 293, 14161, 2405, 295, 264, 1412, 1296, 264, 819, 15547, 47480, 13, 51414], "temperature": 0.0, "avg_logprob": -0.14149430510285613, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.004225744865834713}, {"id": 103, "seek": 52500, "start": 546.0, "end": 552.0, "text": " So yeah, tutorial, how much time do we have left?", "tokens": [51414, 407, 1338, 11, 7073, 11, 577, 709, 565, 360, 321, 362, 1411, 30, 51714], "temperature": 0.0, "avg_logprob": -0.14149430510285613, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.004225744865834713}, {"id": 104, "seek": 55200, "start": 552.0, "end": 554.0, "text": " 10 minutes, something like that?", "tokens": [50364, 1266, 2077, 11, 746, 411, 300, 30, 50464], "temperature": 0.0, "avg_logprob": -0.1393272905464632, "compression_ratio": 1.4952830188679245, "no_speech_prob": 0.030960291624069214}, {"id": 105, "seek": 55200, "start": 554.0, "end": 557.0, "text": " 15 minutes, okay, awesome, thank you.", "tokens": [50464, 2119, 2077, 11, 1392, 11, 3476, 11, 1309, 291, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1393272905464632, "compression_ratio": 1.4952830188679245, "no_speech_prob": 0.030960291624069214}, {"id": 106, "seek": 55200, "start": 557.0, "end": 562.0, "text": " So quickly about the tutorial that I've prepared, nothing fancy", "tokens": [50614, 407, 2661, 466, 264, 7073, 300, 286, 600, 4927, 11, 1825, 10247, 50864], "temperature": 0.0, "avg_logprob": -0.1393272905464632, "compression_ratio": 1.4952830188679245, "no_speech_prob": 0.030960291624069214}, {"id": 107, "seek": 55200, "start": 562.0, "end": 569.0, "text": " just to explain the real-time pipeline and how it implemented using a queue or a broker.", "tokens": [50864, 445, 281, 2903, 264, 957, 12, 3766, 15517, 293, 577, 309, 12270, 1228, 257, 18639, 420, 257, 26502, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1393272905464632, "compression_ratio": 1.4952830188679245, "no_speech_prob": 0.030960291624069214}, {"id": 108, "seek": 55200, "start": 569.0, "end": 576.0, "text": " So we have the customer on the left side, it's sort of like an Uber Eats sort of application.", "tokens": [51214, 407, 321, 362, 264, 5474, 322, 264, 1411, 1252, 11, 309, 311, 1333, 295, 411, 364, 21839, 462, 1720, 1333, 295, 3861, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1393272905464632, "compression_ratio": 1.4952830188679245, "no_speech_prob": 0.030960291624069214}, {"id": 109, "seek": 57600, "start": 576.0, "end": 579.0, "text": " The customer creates an order through the front end", "tokens": [50364, 440, 5474, 7829, 364, 1668, 807, 264, 1868, 917, 50514], "temperature": 0.0, "avg_logprob": -0.12151312540812664, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.034619081765413284}, {"id": 110, "seek": 57600, "start": 579.0, "end": 583.0, "text": " and the front end preserve the data onto a MongoDB", "tokens": [50514, 293, 264, 1868, 917, 15665, 264, 1412, 3911, 257, 48380, 27735, 50714], "temperature": 0.0, "avg_logprob": -0.12151312540812664, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.034619081765413284}, {"id": 111, "seek": 57600, "start": 583.0, "end": 588.0, "text": " and push the events of that order into Memphis queue orders", "tokens": [50714, 293, 2944, 264, 3931, 295, 300, 1668, 666, 26743, 18639, 9470, 50964], "temperature": 0.0, "avg_logprob": -0.12151312540812664, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.034619081765413284}, {"id": 112, "seek": 57600, "start": 588.0, "end": 592.0, "text": " and then we have another service that creates the processing.", "tokens": [50964, 293, 550, 321, 362, 1071, 2643, 300, 7829, 264, 9007, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12151312540812664, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.034619081765413284}, {"id": 113, "seek": 57600, "start": 592.0, "end": 597.0, "text": " Again, preserving the state, if you remember at the first slide", "tokens": [51164, 3764, 11, 33173, 264, 1785, 11, 498, 291, 1604, 412, 264, 700, 4137, 51414], "temperature": 0.0, "avg_logprob": -0.12151312540812664, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.034619081765413284}, {"id": 114, "seek": 57600, "start": 597.0, "end": 603.0, "text": " I talked about preserving the state as it goes along through the different services", "tokens": [51414, 286, 2825, 466, 33173, 264, 1785, 382, 309, 1709, 2051, 807, 264, 819, 3328, 51714], "temperature": 0.0, "avg_logprob": -0.12151312540812664, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.034619081765413284}, {"id": 115, "seek": 60300, "start": 603.0, "end": 607.0, "text": " because if, for example, all of a sudden something happened to the processing service", "tokens": [50364, 570, 498, 11, 337, 1365, 11, 439, 295, 257, 3990, 746, 2011, 281, 264, 9007, 2643, 50564], "temperature": 0.0, "avg_logprob": -0.07812508623650734, "compression_ratio": 1.7973568281938326, "no_speech_prob": 0.00792048592120409}, {"id": 116, "seek": 60300, "start": 607.0, "end": 612.0, "text": " or the delivery service, we know when or from where to process", "tokens": [50564, 420, 264, 8982, 2643, 11, 321, 458, 562, 420, 490, 689, 281, 1399, 50814], "temperature": 0.0, "avg_logprob": -0.07812508623650734, "compression_ratio": 1.7973568281938326, "no_speech_prob": 0.00792048592120409}, {"id": 117, "seek": 60300, "start": 612.0, "end": 618.0, "text": " or to reprocess that order because we don't want to create and duplicate orders", "tokens": [50814, 420, 281, 35257, 780, 300, 1668, 570, 321, 500, 380, 528, 281, 1884, 293, 23976, 9470, 51114], "temperature": 0.0, "avg_logprob": -0.07812508623650734, "compression_ratio": 1.7973568281938326, "no_speech_prob": 0.00792048592120409}, {"id": 118, "seek": 60300, "start": 618.0, "end": 622.0, "text": " because processing or delivery all of a sudden crashed or something like that", "tokens": [51114, 570, 9007, 420, 8982, 439, 295, 257, 3990, 24190, 420, 746, 411, 300, 51314], "temperature": 0.0, "avg_logprob": -0.07812508623650734, "compression_ratio": 1.7973568281938326, "no_speech_prob": 0.00792048592120409}, {"id": 119, "seek": 60300, "start": 622.0, "end": 625.0, "text": " which happens a lot in real-time pipelines.", "tokens": [51314, 597, 2314, 257, 688, 294, 957, 12, 3766, 40168, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07812508623650734, "compression_ratio": 1.7973568281938326, "no_speech_prob": 0.00792048592120409}, {"id": 120, "seek": 60300, "start": 625.0, "end": 630.0, "text": " So that's the general idea, so it goes through processing", "tokens": [51464, 407, 300, 311, 264, 2674, 1558, 11, 370, 309, 1709, 807, 9007, 51714], "temperature": 0.0, "avg_logprob": -0.07812508623650734, "compression_ratio": 1.7973568281938326, "no_speech_prob": 0.00792048592120409}, {"id": 121, "seek": 63000, "start": 630.0, "end": 634.0, "text": " saving the state or updating the state on MongoDB", "tokens": [50364, 6816, 264, 1785, 420, 25113, 264, 1785, 322, 48380, 27735, 50564], "temperature": 0.0, "avg_logprob": -0.13744041442871094, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.01938551478087902}, {"id": 122, "seek": 63000, "start": 634.0, "end": 639.0, "text": " again, push that order to Memphis queue deliveries", "tokens": [50564, 797, 11, 2944, 300, 1668, 281, 26743, 18639, 46448, 50814], "temperature": 0.0, "avg_logprob": -0.13744041442871094, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.01938551478087902}, {"id": 123, "seek": 63000, "start": 639.0, "end": 642.0, "text": " where we have some delivery person that takes that order", "tokens": [50814, 689, 321, 362, 512, 8982, 954, 300, 2516, 300, 1668, 50964], "temperature": 0.0, "avg_logprob": -0.13744041442871094, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.01938551478087902}, {"id": 124, "seek": 63000, "start": 642.0, "end": 646.0, "text": " and create a delivery to the happy customer on the left.", "tokens": [50964, 293, 1884, 257, 8982, 281, 264, 2055, 5474, 322, 264, 1411, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13744041442871094, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.01938551478087902}, {"id": 125, "seek": 63000, "start": 646.0, "end": 653.0, "text": " So let's see some code and how it looks like in reality.", "tokens": [51164, 407, 718, 311, 536, 512, 3089, 293, 577, 309, 1542, 411, 294, 4103, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13744041442871094, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.01938551478087902}, {"id": 126, "seek": 63000, "start": 653.0, "end": 655.0, "text": " So again, nothing fancy.", "tokens": [51514, 407, 797, 11, 1825, 10247, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13744041442871094, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.01938551478087902}, {"id": 127, "seek": 65500, "start": 655.0, "end": 660.0, "text": " This is what it looks like if we had like a Flask API", "tokens": [50364, 639, 307, 437, 309, 1542, 411, 498, 321, 632, 411, 257, 3235, 3863, 9362, 50614], "temperature": 0.0, "avg_logprob": -0.2221594064132027, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.019647689536213875}, {"id": 128, "seek": 65500, "start": 660.0, "end": 664.0, "text": " using Flask framework to create that API endpoints.", "tokens": [50614, 1228, 3235, 3863, 8388, 281, 1884, 300, 9362, 917, 20552, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2221594064132027, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.019647689536213875}, {"id": 129, "seek": 65500, "start": 664.0, "end": 669.0, "text": " It starts with an index which gives the rendered frontend", "tokens": [50814, 467, 3719, 365, 364, 8186, 597, 2709, 264, 28748, 1868, 521, 51064], "temperature": 0.0, "avg_logprob": -0.2221594064132027, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.019647689536213875}, {"id": 130, "seek": 65500, "start": 669.0, "end": 672.0, "text": " and then we have the order food API endpoint", "tokens": [51064, 293, 550, 321, 362, 264, 1668, 1755, 9362, 35795, 51214], "temperature": 0.0, "avg_logprob": -0.2221594064132027, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.019647689536213875}, {"id": 131, "seek": 65500, "start": 672.0, "end": 676.0, "text": " and that would be like the MVP to create the ball of prey.", "tokens": [51214, 293, 300, 576, 312, 411, 264, 37151, 281, 1884, 264, 2594, 295, 21107, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2221594064132027, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.019647689536213875}, {"id": 132, "seek": 65500, "start": 676.0, "end": 677.0, "text": " Sorry.", "tokens": [51414, 4919, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2221594064132027, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.019647689536213875}, {"id": 133, "seek": 65500, "start": 677.0, "end": 682.0, "text": " Oh, and to increase, like most zoom.", "tokens": [51464, 876, 11, 293, 281, 3488, 11, 411, 881, 8863, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2221594064132027, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.019647689536213875}, {"id": 134, "seek": 65500, "start": 682.0, "end": 684.0, "text": " Okay, thanks.", "tokens": [51714, 1033, 11, 3231, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2221594064132027, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.019647689536213875}, {"id": 135, "seek": 68500, "start": 686.0, "end": 689.0, "text": " One second.", "tokens": [50414, 1485, 1150, 13, 50564], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 136, "seek": 68500, "start": 689.0, "end": 691.0, "text": " Is it big enough?", "tokens": [50564, 1119, 309, 955, 1547, 30, 50664], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 137, "seek": 68500, "start": 691.0, "end": 692.0, "text": " Yes.", "tokens": [50664, 1079, 13, 50714], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 138, "seek": 68500, "start": 692.0, "end": 694.0, "text": " Okay, thanks.", "tokens": [50714, 1033, 11, 3231, 13, 50814], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 139, "seek": 68500, "start": 694.0, "end": 696.0, "text": " So, sorry.", "tokens": [50814, 407, 11, 2597, 13, 50914], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 140, "seek": 68500, "start": 696.0, "end": 697.0, "text": " One more.", "tokens": [50914, 1485, 544, 13, 50964], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 141, "seek": 68500, "start": 697.0, "end": 699.0, "text": " One more?", "tokens": [50964, 1485, 544, 30, 51064], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 142, "seek": 68500, "start": 699.0, "end": 703.0, "text": " One more.", "tokens": [51064, 1485, 544, 13, 51264], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 143, "seek": 68500, "start": 703.0, "end": 705.0, "text": " Okay.", "tokens": [51264, 1033, 13, 51364], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 144, "seek": 68500, "start": 705.0, "end": 707.0, "text": " Big enough.", "tokens": [51364, 5429, 1547, 13, 51464], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 145, "seek": 68500, "start": 707.0, "end": 709.0, "text": " Thanks.", "tokens": [51464, 2561, 13, 51564], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 146, "seek": 68500, "start": 709.0, "end": 710.0, "text": " Okay.", "tokens": [51564, 1033, 13, 51614], "temperature": 0.0, "avg_logprob": -0.22734609726936586, "compression_ratio": 1.3296703296703296, "no_speech_prob": 0.02074752002954483}, {"id": 147, "seek": 71000, "start": 710.0, "end": 714.0, "text": " So that would be our boilerplate,", "tokens": [50364, 407, 300, 576, 312, 527, 39228, 37008, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09014370417830968, "compression_ratio": 1.782383419689119, "no_speech_prob": 0.009316281415522099}, {"id": 148, "seek": 71000, "start": 714.0, "end": 717.0, "text": " but if we want to take it to the next level,", "tokens": [50564, 457, 498, 321, 528, 281, 747, 309, 281, 264, 958, 1496, 11, 50714], "temperature": 0.0, "avg_logprob": -0.09014370417830968, "compression_ratio": 1.782383419689119, "no_speech_prob": 0.009316281415522099}, {"id": 149, "seek": 71000, "start": 717.0, "end": 721.0, "text": " let me just remove that part,", "tokens": [50714, 718, 385, 445, 4159, 300, 644, 11, 50914], "temperature": 0.0, "avg_logprob": -0.09014370417830968, "compression_ratio": 1.782383419689119, "no_speech_prob": 0.009316281415522099}, {"id": 150, "seek": 71000, "start": 721.0, "end": 723.0, "text": " but if we want to take it to the next level", "tokens": [50914, 457, 498, 321, 528, 281, 747, 309, 281, 264, 958, 1496, 51014], "temperature": 0.0, "avg_logprob": -0.09014370417830968, "compression_ratio": 1.782383419689119, "no_speech_prob": 0.009316281415522099}, {"id": 151, "seek": 71000, "start": 723.0, "end": 725.0, "text": " and add a queue into it.", "tokens": [51014, 293, 909, 257, 18639, 666, 309, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09014370417830968, "compression_ratio": 1.782383419689119, "no_speech_prob": 0.009316281415522099}, {"id": 152, "seek": 71000, "start": 725.0, "end": 728.0, "text": " So let's quickly go over the different parts.", "tokens": [51114, 407, 718, 311, 2661, 352, 670, 264, 819, 3166, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09014370417830968, "compression_ratio": 1.782383419689119, "no_speech_prob": 0.009316281415522099}, {"id": 153, "seek": 71000, "start": 728.0, "end": 729.0, "text": " Let's start from the main.", "tokens": [51264, 961, 311, 722, 490, 264, 2135, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09014370417830968, "compression_ratio": 1.782383419689119, "no_speech_prob": 0.009316281415522099}, {"id": 154, "seek": 71000, "start": 729.0, "end": 732.0, "text": " So we basically have the order food endpoint.", "tokens": [51314, 407, 321, 1936, 362, 264, 1668, 1755, 35795, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09014370417830968, "compression_ratio": 1.782383419689119, "no_speech_prob": 0.009316281415522099}, {"id": 155, "seek": 71000, "start": 732.0, "end": 736.0, "text": " So a trigger will go to the order food endpoint", "tokens": [51464, 407, 257, 7875, 486, 352, 281, 264, 1668, 1755, 35795, 51664], "temperature": 0.0, "avg_logprob": -0.09014370417830968, "compression_ratio": 1.782383419689119, "no_speech_prob": 0.009316281415522099}, {"id": 156, "seek": 73600, "start": 736.0, "end": 740.0, "text": " and then we basically print some output for that", "tokens": [50364, 293, 550, 321, 1936, 4482, 512, 5598, 337, 300, 50564], "temperature": 0.0, "avg_logprob": -0.14344960029679116, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.021940618753433228}, {"id": 157, "seek": 73600, "start": 740.0, "end": 742.0, "text": " new order received, we'll print it,", "tokens": [50564, 777, 1668, 4613, 11, 321, 603, 4482, 309, 11, 50664], "temperature": 0.0, "avg_logprob": -0.14344960029679116, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.021940618753433228}, {"id": 158, "seek": 73600, "start": 742.0, "end": 744.0, "text": " then we'll create a current time,", "tokens": [50664, 550, 321, 603, 1884, 257, 2190, 565, 11, 50764], "temperature": 0.0, "avg_logprob": -0.14344960029679116, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.021940618753433228}, {"id": 159, "seek": 73600, "start": 744.0, "end": 747.0, "text": " we'll stamp the order with the current time,", "tokens": [50764, 321, 603, 9921, 264, 1668, 365, 264, 2190, 565, 11, 50914], "temperature": 0.0, "avg_logprob": -0.14344960029679116, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.021940618753433228}, {"id": 160, "seek": 73600, "start": 747.0, "end": 749.0, "text": " order date with that current time,", "tokens": [50914, 1668, 4002, 365, 300, 2190, 565, 11, 51014], "temperature": 0.0, "avg_logprob": -0.14344960029679116, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.021940618753433228}, {"id": 161, "seek": 73600, "start": 749.0, "end": 751.0, "text": " status means the state of it,", "tokens": [51014, 6558, 1355, 264, 1785, 295, 309, 11, 51114], "temperature": 0.0, "avg_logprob": -0.14344960029679116, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.021940618753433228}, {"id": 162, "seek": 73600, "start": 751.0, "end": 754.0, "text": " so it's a new order, generate ID,", "tokens": [51114, 370, 309, 311, 257, 777, 1668, 11, 8460, 7348, 11, 51264], "temperature": 0.0, "avg_logprob": -0.14344960029679116, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.021940618753433228}, {"id": 163, "seek": 73600, "start": 754.0, "end": 761.0, "text": " and then create a new document inside our NoSQL database", "tokens": [51264, 293, 550, 1884, 257, 777, 4166, 1854, 527, 883, 39934, 8149, 51614], "temperature": 0.0, "avg_logprob": -0.14344960029679116, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.021940618753433228}, {"id": 164, "seek": 73600, "start": 761.0, "end": 764.0, "text": " and then push the order towards processing,", "tokens": [51614, 293, 550, 2944, 264, 1668, 3030, 9007, 11, 51764], "temperature": 0.0, "avg_logprob": -0.14344960029679116, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.021940618753433228}, {"id": 165, "seek": 76400, "start": 764.0, "end": 768.0, "text": " so meaning the part that the event goes through Memphis", "tokens": [50364, 370, 3620, 264, 644, 300, 264, 2280, 1709, 807, 26743, 50564], "temperature": 0.0, "avg_logprob": -0.13409850753356364, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.013028238900005817}, {"id": 166, "seek": 76400, "start": 768.0, "end": 771.0, "text": " for further processing,", "tokens": [50564, 337, 3052, 9007, 11, 50714], "temperature": 0.0, "avg_logprob": -0.13409850753356364, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.013028238900005817}, {"id": 167, "seek": 76400, "start": 771.0, "end": 773.0, "text": " that would be the part that handles that.", "tokens": [50714, 300, 576, 312, 264, 644, 300, 18722, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13409850753356364, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.013028238900005817}, {"id": 168, "seek": 76400, "start": 773.0, "end": 777.0, "text": " Let's see, for one second, it goes all the way up,", "tokens": [50814, 961, 311, 536, 11, 337, 472, 1150, 11, 309, 1709, 439, 264, 636, 493, 11, 51014], "temperature": 0.0, "avg_logprob": -0.13409850753356364, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.013028238900005817}, {"id": 169, "seek": 76400, "start": 777.0, "end": 779.0, "text": " so we basically connect to Memphis,", "tokens": [51014, 370, 321, 1936, 1745, 281, 26743, 11, 51114], "temperature": 0.0, "avg_logprob": -0.13409850753356364, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.013028238900005817}, {"id": 170, "seek": 76400, "start": 779.0, "end": 782.0, "text": " connect to the cluster itself, create a producer,", "tokens": [51114, 1745, 281, 264, 13630, 2564, 11, 1884, 257, 12314, 11, 51264], "temperature": 0.0, "avg_logprob": -0.13409850753356364, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.013028238900005817}, {"id": 171, "seek": 76400, "start": 782.0, "end": 786.0, "text": " and then produce that event to the station.", "tokens": [51264, 293, 550, 5258, 300, 2280, 281, 264, 5214, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13409850753356364, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.013028238900005817}, {"id": 172, "seek": 76400, "start": 786.0, "end": 789.0, "text": " We'll see it in a minute, like in a more visual way.", "tokens": [51464, 492, 603, 536, 309, 294, 257, 3456, 11, 411, 294, 257, 544, 5056, 636, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13409850753356364, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.013028238900005817}, {"id": 173, "seek": 76400, "start": 789.0, "end": 792.0, "text": " And then afterwards comes the part three.", "tokens": [51614, 400, 550, 10543, 1487, 264, 644, 1045, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13409850753356364, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.013028238900005817}, {"id": 174, "seek": 79200, "start": 792.0, "end": 795.0, "text": " I mean, part two, actually, the process itself.", "tokens": [50364, 286, 914, 11, 644, 732, 11, 767, 11, 264, 1399, 2564, 13, 50514], "temperature": 0.0, "avg_logprob": -0.11209819754775689, "compression_ratio": 1.8153153153153154, "no_speech_prob": 0.013192595914006233}, {"id": 175, "seek": 79200, "start": 795.0, "end": 799.0, "text": " So the process itself, basically there is a component", "tokens": [50514, 407, 264, 1399, 2564, 11, 1936, 456, 307, 257, 6542, 50714], "temperature": 0.0, "avg_logprob": -0.11209819754775689, "compression_ratio": 1.8153153153153154, "no_speech_prob": 0.013192595914006233}, {"id": 176, "seek": 79200, "start": 799.0, "end": 802.0, "text": " that listens to events coming from Memphis.", "tokens": [50714, 300, 35959, 281, 3931, 1348, 490, 26743, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11209819754775689, "compression_ratio": 1.8153153153153154, "no_speech_prob": 0.013192595914006233}, {"id": 177, "seek": 79200, "start": 802.0, "end": 806.0, "text": " So Memphis implements the paradigm of produce and consume,", "tokens": [50864, 407, 26743, 704, 17988, 264, 24709, 295, 5258, 293, 14732, 11, 51064], "temperature": 0.0, "avg_logprob": -0.11209819754775689, "compression_ratio": 1.8153153153153154, "no_speech_prob": 0.013192595914006233}, {"id": 178, "seek": 79200, "start": 806.0, "end": 811.0, "text": " so it's not pushing the events into the processing part,", "tokens": [51064, 370, 309, 311, 406, 7380, 264, 3931, 666, 264, 9007, 644, 11, 51314], "temperature": 0.0, "avg_logprob": -0.11209819754775689, "compression_ratio": 1.8153153153153154, "no_speech_prob": 0.013192595914006233}, {"id": 179, "seek": 79200, "start": 811.0, "end": 813.0, "text": " but actually the processing service", "tokens": [51314, 457, 767, 264, 9007, 2643, 51414], "temperature": 0.0, "avg_logprob": -0.11209819754775689, "compression_ratio": 1.8153153153153154, "no_speech_prob": 0.013192595914006233}, {"id": 180, "seek": 79200, "start": 813.0, "end": 817.0, "text": " consume that event and start acting based on that.", "tokens": [51414, 14732, 300, 2280, 293, 722, 6577, 2361, 322, 300, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11209819754775689, "compression_ratio": 1.8153153153153154, "no_speech_prob": 0.013192595914006233}, {"id": 181, "seek": 79200, "start": 817.0, "end": 821.0, "text": " So it's an event-driven architecture that we describe.", "tokens": [51614, 407, 309, 311, 364, 2280, 12, 25456, 9482, 300, 321, 6786, 13, 51814], "temperature": 0.0, "avg_logprob": -0.11209819754775689, "compression_ratio": 1.8153153153153154, "no_speech_prob": 0.013192595914006233}, {"id": 182, "seek": 82100, "start": 821.0, "end": 824.0, "text": " It's idle until something happened", "tokens": [50364, 467, 311, 30650, 1826, 746, 2011, 50514], "temperature": 0.0, "avg_logprob": -0.14551116171337308, "compression_ratio": 1.53, "no_speech_prob": 0.0042880382388830185}, {"id": 183, "seek": 82100, "start": 824.0, "end": 828.0, "text": " or some order got into the queue.", "tokens": [50514, 420, 512, 1668, 658, 666, 264, 18639, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14551116171337308, "compression_ratio": 1.53, "no_speech_prob": 0.0042880382388830185}, {"id": 184, "seek": 82100, "start": 828.0, "end": 835.0, "text": " So new order received, just short parsing into JSON,", "tokens": [50714, 407, 777, 1668, 4613, 11, 445, 2099, 21156, 278, 666, 31828, 11, 51064], "temperature": 0.0, "avg_logprob": -0.14551116171337308, "compression_ratio": 1.53, "no_speech_prob": 0.0042880382388830185}, {"id": 185, "seek": 82100, "start": 835.0, "end": 838.0, "text": " also creating a quarantine for that part,", "tokens": [51064, 611, 4084, 257, 18138, 337, 300, 644, 11, 51214], "temperature": 0.0, "avg_logprob": -0.14551116171337308, "compression_ratio": 1.53, "no_speech_prob": 0.0042880382388830185}, {"id": 186, "seek": 82100, "start": 838.0, "end": 840.0, "text": " preparing the dish.", "tokens": [51214, 10075, 264, 5025, 13, 51314], "temperature": 0.0, "avg_logprob": -0.14551116171337308, "compression_ratio": 1.53, "no_speech_prob": 0.0042880382388830185}, {"id": 187, "seek": 82100, "start": 840.0, "end": 842.0, "text": " It's a pretty fast restaurant.", "tokens": [51314, 467, 311, 257, 1238, 2370, 6383, 13, 51414], "temperature": 0.0, "avg_logprob": -0.14551116171337308, "compression_ratio": 1.53, "no_speech_prob": 0.0042880382388830185}, {"id": 188, "seek": 82100, "start": 842.0, "end": 844.0, "text": " Order is ready for delivery.", "tokens": [51414, 16321, 307, 1919, 337, 8982, 13, 51514], "temperature": 0.0, "avg_logprob": -0.14551116171337308, "compression_ratio": 1.53, "no_speech_prob": 0.0042880382388830185}, {"id": 189, "seek": 82100, "start": 844.0, "end": 847.0, "text": " And we're changing the state to delivery", "tokens": [51514, 400, 321, 434, 4473, 264, 1785, 281, 8982, 51664], "temperature": 0.0, "avg_logprob": -0.14551116171337308, "compression_ratio": 1.53, "no_speech_prob": 0.0042880382388830185}, {"id": 190, "seek": 82100, "start": 847.0, "end": 849.0, "text": " and hack the message.", "tokens": [51664, 293, 10339, 264, 3636, 13, 51764], "temperature": 0.0, "avg_logprob": -0.14551116171337308, "compression_ratio": 1.53, "no_speech_prob": 0.0042880382388830185}, {"id": 191, "seek": 84900, "start": 849.0, "end": 852.0, "text": " The acknowledging message in every queue or broker", "tokens": [50364, 440, 30904, 3636, 294, 633, 18639, 420, 26502, 50514], "temperature": 0.0, "avg_logprob": -0.13098939982327548, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.016391893848776817}, {"id": 192, "seek": 84900, "start": 852.0, "end": 854.0, "text": " means that I received the message,", "tokens": [50514, 1355, 300, 286, 4613, 264, 3636, 11, 50614], "temperature": 0.0, "avg_logprob": -0.13098939982327548, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.016391893848776817}, {"id": 193, "seek": 84900, "start": 854.0, "end": 857.0, "text": " I did my processing, my handling,", "tokens": [50614, 286, 630, 452, 9007, 11, 452, 13175, 11, 50764], "temperature": 0.0, "avg_logprob": -0.13098939982327548, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.016391893848776817}, {"id": 194, "seek": 84900, "start": 857.0, "end": 860.0, "text": " and it's okay to send me more messages.", "tokens": [50764, 293, 309, 311, 1392, 281, 2845, 385, 544, 7897, 13, 50914], "temperature": 0.0, "avg_logprob": -0.13098939982327548, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.016391893848776817}, {"id": 195, "seek": 84900, "start": 860.0, "end": 862.0, "text": " So that's the asynchronous part.", "tokens": [50914, 407, 300, 311, 264, 49174, 644, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13098939982327548, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.016391893848776817}, {"id": 196, "seek": 84900, "start": 862.0, "end": 866.0, "text": " So we do some filtering, new values,", "tokens": [51014, 407, 321, 360, 512, 30822, 11, 777, 4190, 11, 51214], "temperature": 0.0, "avg_logprob": -0.13098939982327548, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.016391893848776817}, {"id": 197, "seek": 84900, "start": 866.0, "end": 870.0, "text": " according to what MongoDB asked us to do,", "tokens": [51214, 4650, 281, 437, 48380, 27735, 2351, 505, 281, 360, 11, 51414], "temperature": 0.0, "avg_logprob": -0.13098939982327548, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.016391893848776817}, {"id": 198, "seek": 84900, "start": 870.0, "end": 875.0, "text": " and we update that document, the state of it,", "tokens": [51414, 293, 321, 5623, 300, 4166, 11, 264, 1785, 295, 309, 11, 51664], "temperature": 0.0, "avg_logprob": -0.13098939982327548, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.016391893848776817}, {"id": 199, "seek": 87500, "start": 875.0, "end": 878.0, "text": " so it goes from new order to delivery,", "tokens": [50364, 370, 309, 1709, 490, 777, 1668, 281, 8982, 11, 50514], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 200, "seek": 87500, "start": 878.0, "end": 880.0, "text": " so it's ready for delivery,", "tokens": [50514, 370, 309, 311, 1919, 337, 8982, 11, 50614], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 201, "seek": 87500, "start": 880.0, "end": 882.0, "text": " and then we send the delivery,", "tokens": [50614, 293, 550, 321, 2845, 264, 8982, 11, 50714], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 202, "seek": 87500, "start": 882.0, "end": 885.0, "text": " or we send the order to the delivery part.", "tokens": [50714, 420, 321, 2845, 264, 1668, 281, 264, 8982, 644, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 203, "seek": 87500, "start": 885.0, "end": 887.0, "text": " And that's, I would say,", "tokens": [50864, 400, 300, 311, 11, 286, 576, 584, 11, 50964], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 204, "seek": 87500, "start": 887.0, "end": 891.0, "text": " that's the main idea of doing asynchronous movement,", "tokens": [50964, 300, 311, 264, 2135, 1558, 295, 884, 49174, 3963, 11, 51164], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 205, "seek": 87500, "start": 891.0, "end": 895.0, "text": " because at the moment we are a young startup,", "tokens": [51164, 570, 412, 264, 1623, 321, 366, 257, 2037, 18578, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 206, "seek": 87500, "start": 895.0, "end": 897.0, "text": " we have only one delivery person,", "tokens": [51364, 321, 362, 787, 472, 8982, 954, 11, 51464], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 207, "seek": 87500, "start": 897.0, "end": 899.0, "text": " and all of a sudden we got scaled.", "tokens": [51464, 293, 439, 295, 257, 3990, 321, 658, 36039, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 208, "seek": 87500, "start": 899.0, "end": 901.0, "text": " And we need more delivery person.", "tokens": [51564, 400, 321, 643, 544, 8982, 954, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10301096934192586, "compression_ratio": 1.8442211055276383, "no_speech_prob": 0.006481303367763758}, {"id": 209, "seek": 90100, "start": 901.0, "end": 906.0, "text": " We don't want to add, like, more power into that compute,", "tokens": [50364, 492, 500, 380, 528, 281, 909, 11, 411, 11, 544, 1347, 666, 300, 14722, 11, 50614], "temperature": 0.0, "avg_logprob": -0.10678182903089022, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.004951729904860258}, {"id": 210, "seek": 90100, "start": 906.0, "end": 910.0, "text": " but we want to add more, to scale out our resources", "tokens": [50614, 457, 321, 528, 281, 909, 544, 11, 281, 4373, 484, 527, 3593, 50814], "temperature": 0.0, "avg_logprob": -0.10678182903089022, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.004951729904860258}, {"id": 211, "seek": 90100, "start": 910.0, "end": 913.0, "text": " and add more threads, add more workers.", "tokens": [50814, 293, 909, 544, 19314, 11, 909, 544, 5600, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10678182903089022, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.004951729904860258}, {"id": 212, "seek": 90100, "start": 913.0, "end": 915.0, "text": " So we would scale the delivery part,", "tokens": [50964, 407, 321, 576, 4373, 264, 8982, 644, 11, 51064], "temperature": 0.0, "avg_logprob": -0.10678182903089022, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.004951729904860258}, {"id": 213, "seek": 90100, "start": 915.0, "end": 918.0, "text": " so instead of using just one service for delivery,", "tokens": [51064, 370, 2602, 295, 1228, 445, 472, 2643, 337, 8982, 11, 51214], "temperature": 0.0, "avg_logprob": -0.10678182903089022, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.004951729904860258}, {"id": 214, "seek": 90100, "start": 918.0, "end": 921.0, "text": " all of a sudden we can just scale out", "tokens": [51214, 439, 295, 257, 3990, 321, 393, 445, 4373, 484, 51364], "temperature": 0.0, "avg_logprob": -0.10678182903089022, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.004951729904860258}, {"id": 215, "seek": 90100, "start": 921.0, "end": 924.0, "text": " to 10 or 100 different delivery persons,", "tokens": [51364, 281, 1266, 420, 2319, 819, 8982, 14453, 11, 51514], "temperature": 0.0, "avg_logprob": -0.10678182903089022, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.004951729904860258}, {"id": 216, "seek": 90100, "start": 924.0, "end": 927.0, "text": " which is a delivery services.", "tokens": [51514, 597, 307, 257, 8982, 3328, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10678182903089022, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.004951729904860258}, {"id": 217, "seek": 92700, "start": 928.0, "end": 933.0, "text": " So we send the delivery event into the delivery queue,", "tokens": [50414, 407, 321, 2845, 264, 8982, 2280, 666, 264, 8982, 18639, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1284083354322216, "compression_ratio": 1.6117021276595744, "no_speech_prob": 0.0010354252299293876}, {"id": 218, "seek": 92700, "start": 933.0, "end": 936.0, "text": " which looks pretty the same as the processing,", "tokens": [50664, 597, 1542, 1238, 264, 912, 382, 264, 9007, 11, 50814], "temperature": 0.0, "avg_logprob": -0.1284083354322216, "compression_ratio": 1.6117021276595744, "no_speech_prob": 0.0010354252299293876}, {"id": 219, "seek": 92700, "start": 936.0, "end": 939.0, "text": " so we will start with consuming,", "tokens": [50814, 370, 321, 486, 722, 365, 19867, 11, 50964], "temperature": 0.0, "avg_logprob": -0.1284083354322216, "compression_ratio": 1.6117021276595744, "no_speech_prob": 0.0010354252299293876}, {"id": 220, "seek": 92700, "start": 941.0, "end": 944.0, "text": " and then hacking the message,", "tokens": [51064, 293, 550, 31422, 264, 3636, 11, 51214], "temperature": 0.0, "avg_logprob": -0.1284083354322216, "compression_ratio": 1.6117021276595744, "no_speech_prob": 0.0010354252299293876}, {"id": 221, "seek": 92700, "start": 944.0, "end": 948.0, "text": " actually on that part right in the beginning.", "tokens": [51214, 767, 322, 300, 644, 558, 294, 264, 2863, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1284083354322216, "compression_ratio": 1.6117021276595744, "no_speech_prob": 0.0010354252299293876}, {"id": 222, "seek": 92700, "start": 948.0, "end": 954.0, "text": " I just wanted to show two different ways to doing so.", "tokens": [51414, 286, 445, 1415, 281, 855, 732, 819, 2098, 281, 884, 370, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1284083354322216, "compression_ratio": 1.6117021276595744, "no_speech_prob": 0.0010354252299293876}, {"id": 223, "seek": 92700, "start": 954.0, "end": 956.0, "text": " So in streaming, or in data streaming,", "tokens": [51714, 407, 294, 11791, 11, 420, 294, 1412, 11791, 11, 51814], "temperature": 0.0, "avg_logprob": -0.1284083354322216, "compression_ratio": 1.6117021276595744, "no_speech_prob": 0.0010354252299293876}, {"id": 224, "seek": 95600, "start": 956.0, "end": 959.0, "text": " basically we want to acknowledge the message really, really fast,", "tokens": [50364, 1936, 321, 528, 281, 10692, 264, 3636, 534, 11, 534, 2370, 11, 50514], "temperature": 0.0, "avg_logprob": -0.10015794342639399, "compression_ratio": 1.9234234234234233, "no_speech_prob": 0.003987917676568031}, {"id": 225, "seek": 95600, "start": 959.0, "end": 962.0, "text": " because streaming is made for scale", "tokens": [50514, 570, 11791, 307, 1027, 337, 4373, 50664], "temperature": 0.0, "avg_logprob": -0.10015794342639399, "compression_ratio": 1.9234234234234233, "no_speech_prob": 0.003987917676568031}, {"id": 226, "seek": 95600, "start": 962.0, "end": 965.0, "text": " when we got to the place that we want to queue,", "tokens": [50664, 562, 321, 658, 281, 264, 1081, 300, 321, 528, 281, 18639, 11, 50814], "temperature": 0.0, "avg_logprob": -0.10015794342639399, "compression_ratio": 1.9234234234234233, "no_speech_prob": 0.003987917676568031}, {"id": 227, "seek": 95600, "start": 965.0, "end": 967.0, "text": " or a message worker would probably handle", "tokens": [50814, 420, 257, 3636, 11346, 576, 1391, 4813, 50914], "temperature": 0.0, "avg_logprob": -0.10015794342639399, "compression_ratio": 1.9234234234234233, "no_speech_prob": 0.003987917676568031}, {"id": 228, "seek": 95600, "start": 967.0, "end": 970.0, "text": " or handling large scale of data,", "tokens": [50914, 420, 13175, 2416, 4373, 295, 1412, 11, 51064], "temperature": 0.0, "avg_logprob": -0.10015794342639399, "compression_ratio": 1.9234234234234233, "no_speech_prob": 0.003987917676568031}, {"id": 229, "seek": 95600, "start": 970.0, "end": 973.0, "text": " so we want to quickly acknowledge the message", "tokens": [51064, 370, 321, 528, 281, 2661, 10692, 264, 3636, 51214], "temperature": 0.0, "avg_logprob": -0.10015794342639399, "compression_ratio": 1.9234234234234233, "no_speech_prob": 0.003987917676568031}, {"id": 230, "seek": 95600, "start": 973.0, "end": 976.0, "text": " to free up our buffer and receive more messages.", "tokens": [51214, 281, 1737, 493, 527, 21762, 293, 4774, 544, 7897, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10015794342639399, "compression_ratio": 1.9234234234234233, "no_speech_prob": 0.003987917676568031}, {"id": 231, "seek": 95600, "start": 976.0, "end": 981.0, "text": " So at the previous service, at the processing service,", "tokens": [51364, 407, 412, 264, 3894, 2643, 11, 412, 264, 9007, 2643, 11, 51614], "temperature": 0.0, "avg_logprob": -0.10015794342639399, "compression_ratio": 1.9234234234234233, "no_speech_prob": 0.003987917676568031}, {"id": 232, "seek": 95600, "start": 981.0, "end": 984.0, "text": " we acknowledge the message only after the preparing,", "tokens": [51614, 321, 10692, 264, 3636, 787, 934, 264, 10075, 11, 51764], "temperature": 0.0, "avg_logprob": -0.10015794342639399, "compression_ratio": 1.9234234234234233, "no_speech_prob": 0.003987917676568031}, {"id": 233, "seek": 98400, "start": 984.0, "end": 986.0, "text": " which is perfectly fine,", "tokens": [50364, 597, 307, 6239, 2489, 11, 50464], "temperature": 0.0, "avg_logprob": -0.12395724180702851, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010911021381616592}, {"id": 234, "seek": 98400, "start": 986.0, "end": 988.0, "text": " but in this part, again,", "tokens": [50464, 457, 294, 341, 644, 11, 797, 11, 50564], "temperature": 0.0, "avg_logprob": -0.12395724180702851, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010911021381616592}, {"id": 235, "seek": 98400, "start": 988.0, "end": 992.0, "text": " if all of a sudden we have massive scale that we need to handle,", "tokens": [50564, 498, 439, 295, 257, 3990, 321, 362, 5994, 4373, 300, 321, 643, 281, 4813, 11, 50764], "temperature": 0.0, "avg_logprob": -0.12395724180702851, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010911021381616592}, {"id": 236, "seek": 98400, "start": 992.0, "end": 996.0, "text": " in order to avoid back pressure on our broker,", "tokens": [50764, 294, 1668, 281, 5042, 646, 3321, 322, 527, 26502, 11, 50964], "temperature": 0.0, "avg_logprob": -0.12395724180702851, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010911021381616592}, {"id": 237, "seek": 98400, "start": 996.0, "end": 998.0, "text": " we absorb that back pressure", "tokens": [50964, 321, 15631, 300, 646, 3321, 51064], "temperature": 0.0, "avg_logprob": -0.12395724180702851, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010911021381616592}, {"id": 238, "seek": 98400, "start": 998.0, "end": 1001.0, "text": " and doing a fast acknowledging on our client,", "tokens": [51064, 293, 884, 257, 2370, 30904, 322, 527, 6423, 11, 51214], "temperature": 0.0, "avg_logprob": -0.12395724180702851, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010911021381616592}, {"id": 239, "seek": 98400, "start": 1001.0, "end": 1003.0, "text": " it's just another way to doing things,", "tokens": [51214, 309, 311, 445, 1071, 636, 281, 884, 721, 11, 51314], "temperature": 0.0, "avg_logprob": -0.12395724180702851, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010911021381616592}, {"id": 240, "seek": 98400, "start": 1003.0, "end": 1009.0, "text": " and it based on your use case and how much your use case is sensitive", "tokens": [51314, 293, 309, 2361, 322, 428, 764, 1389, 293, 577, 709, 428, 764, 1389, 307, 9477, 51614], "temperature": 0.0, "avg_logprob": -0.12395724180702851, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010911021381616592}, {"id": 241, "seek": 98400, "start": 1009.0, "end": 1013.0, "text": " to avoid, for example, a message or an event.", "tokens": [51614, 281, 5042, 11, 337, 1365, 11, 257, 3636, 420, 364, 2280, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12395724180702851, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010911021381616592}, {"id": 242, "seek": 101300, "start": 1013.0, "end": 1015.0, "text": " Thanks.", "tokens": [50364, 2561, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 243, "seek": 101300, "start": 1015.0, "end": 1018.0, "text": " A message or event, because if, for example,", "tokens": [50464, 316, 3636, 420, 2280, 11, 570, 498, 11, 337, 1365, 11, 50614], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 244, "seek": 101300, "start": 1018.0, "end": 1020.0, "text": " we acknowledge the message,", "tokens": [50614, 321, 10692, 264, 3636, 11, 50714], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 245, "seek": 101300, "start": 1020.0, "end": 1022.0, "text": " and all of a sudden, on that part,", "tokens": [50714, 293, 439, 295, 257, 3990, 11, 322, 300, 644, 11, 50814], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 246, "seek": 101300, "start": 1022.0, "end": 1026.0, "text": " our service will go down for some reason,", "tokens": [50814, 527, 2643, 486, 352, 760, 337, 512, 1778, 11, 51014], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 247, "seek": 101300, "start": 1026.0, "end": 1029.0, "text": " we basically will lost that event", "tokens": [51014, 321, 1936, 486, 2731, 300, 2280, 51164], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 248, "seek": 101300, "start": 1029.0, "end": 1031.0, "text": " and we will not deliver it,", "tokens": [51164, 293, 321, 486, 406, 4239, 309, 11, 51264], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 249, "seek": 101300, "start": 1031.0, "end": 1034.0, "text": " and the customer will not be so happy", "tokens": [51264, 293, 264, 5474, 486, 406, 312, 370, 2055, 51414], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 250, "seek": 101300, "start": 1034.0, "end": 1037.0, "text": " and we will need to re-trigger the entire workflow.", "tokens": [51414, 293, 321, 486, 643, 281, 319, 12, 6903, 6812, 264, 2302, 20993, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 251, "seek": 101300, "start": 1037.0, "end": 1039.0, "text": " So just another way to doing stuff,", "tokens": [51564, 407, 445, 1071, 636, 281, 884, 1507, 11, 51664], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 252, "seek": 101300, "start": 1039.0, "end": 1042.0, "text": " when we work with massive scale like Uber,", "tokens": [51664, 562, 321, 589, 365, 5994, 4373, 411, 21839, 11, 51814], "temperature": 0.0, "avg_logprob": -0.10940642867769514, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0015268669230863452}, {"id": 253, "seek": 104200, "start": 1042.0, "end": 1044.0, "text": " like Netflix,", "tokens": [50364, 411, 12778, 11, 50464], "temperature": 0.0, "avg_logprob": -0.10303340174935081, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.004479866940528154}, {"id": 254, "seek": 104200, "start": 1044.0, "end": 1047.0, "text": " like Deliver or something like that,", "tokens": [50464, 411, 5831, 1837, 420, 746, 411, 300, 11, 50614], "temperature": 0.0, "avg_logprob": -0.10303340174935081, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.004479866940528154}, {"id": 255, "seek": 104200, "start": 1047.0, "end": 1050.0, "text": " it definitely needs to be in that way", "tokens": [50614, 309, 2138, 2203, 281, 312, 294, 300, 636, 50764], "temperature": 0.0, "avg_logprob": -0.10303340174935081, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.004479866940528154}, {"id": 256, "seek": 104200, "start": 1050.0, "end": 1054.0, "text": " and here will maybe come another action", "tokens": [50764, 293, 510, 486, 1310, 808, 1071, 3069, 50964], "temperature": 0.0, "avg_logprob": -0.10303340174935081, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.004479866940528154}, {"id": 257, "seek": 104200, "start": 1054.0, "end": 1058.0, "text": " or a usage of a cache database like Redis", "tokens": [50964, 420, 257, 14924, 295, 257, 19459, 8149, 411, 4477, 271, 51164], "temperature": 0.0, "avg_logprob": -0.10303340174935081, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.004479866940528154}, {"id": 258, "seek": 104200, "start": 1058.0, "end": 1062.0, "text": " that will preserve that event just for that time,", "tokens": [51164, 300, 486, 15665, 300, 2280, 445, 337, 300, 565, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10303340174935081, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.004479866940528154}, {"id": 259, "seek": 104200, "start": 1062.0, "end": 1064.0, "text": " just for the processing time.", "tokens": [51364, 445, 337, 264, 9007, 565, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10303340174935081, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.004479866940528154}, {"id": 260, "seek": 104200, "start": 1064.0, "end": 1068.0, "text": " So again, as we did in the previous services,", "tokens": [51464, 407, 797, 11, 382, 321, 630, 294, 264, 3894, 3328, 11, 51664], "temperature": 0.0, "avg_logprob": -0.10303340174935081, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.004479866940528154}, {"id": 261, "seek": 104200, "start": 1068.0, "end": 1070.0, "text": " we print some output,", "tokens": [51664, 321, 4482, 512, 5598, 11, 51764], "temperature": 0.0, "avg_logprob": -0.10303340174935081, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.004479866940528154}, {"id": 262, "seek": 107000, "start": 1070.0, "end": 1074.0, "text": " we update the database with the status delivered,", "tokens": [50364, 321, 5623, 264, 8149, 365, 264, 6558, 10144, 11, 50564], "temperature": 0.0, "avg_logprob": -0.13165638997004583, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.019782869145274162}, {"id": 263, "seek": 107000, "start": 1074.0, "end": 1076.0, "text": " that's that part,", "tokens": [50564, 300, 311, 300, 644, 11, 50664], "temperature": 0.0, "avg_logprob": -0.13165638997004583, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.019782869145274162}, {"id": 264, "seek": 107000, "start": 1076.0, "end": 1082.0, "text": " and we basically print everything to our own logging and auditing", "tokens": [50664, 293, 321, 1936, 4482, 1203, 281, 527, 1065, 27991, 293, 2379, 1748, 50964], "temperature": 0.0, "avg_logprob": -0.13165638997004583, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.019782869145274162}, {"id": 265, "seek": 107000, "start": 1082.0, "end": 1087.0, "text": " and everything will be also updated inside the database,", "tokens": [50964, 293, 1203, 486, 312, 611, 10588, 1854, 264, 8149, 11, 51214], "temperature": 0.0, "avg_logprob": -0.13165638997004583, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.019782869145274162}, {"id": 266, "seek": 107000, "start": 1087.0, "end": 1089.0, "text": " so we will be able to observe that order", "tokens": [51214, 370, 321, 486, 312, 1075, 281, 11441, 300, 1668, 51314], "temperature": 0.0, "avg_logprob": -0.13165638997004583, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.019782869145274162}, {"id": 267, "seek": 107000, "start": 1089.0, "end": 1094.0, "text": " and the entire life cycle of ordering, processing and delivery.", "tokens": [51314, 293, 264, 2302, 993, 6586, 295, 21739, 11, 9007, 293, 8982, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13165638997004583, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.019782869145274162}, {"id": 268, "seek": 107000, "start": 1094.0, "end": 1097.0, "text": " So I will do,", "tokens": [51564, 407, 286, 486, 360, 11, 51714], "temperature": 0.0, "avg_logprob": -0.13165638997004583, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.019782869145274162}, {"id": 269, "seek": 109700, "start": 1097.0, "end": 1100.0, "text": " I will just run it really, really quickly", "tokens": [50364, 286, 486, 445, 1190, 309, 534, 11, 534, 2661, 50514], "temperature": 0.0, "avg_logprob": -0.17428631478167594, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.012842795811593533}, {"id": 270, "seek": 109700, "start": 1100.0, "end": 1103.0, "text": " because I also, and by the way, everything is written in medium", "tokens": [50514, 570, 286, 611, 11, 293, 538, 264, 636, 11, 1203, 307, 3720, 294, 6399, 50664], "temperature": 0.0, "avg_logprob": -0.17428631478167594, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.012842795811593533}, {"id": 271, "seek": 109700, "start": 1103.0, "end": 1107.0, "text": " and you have a GitHub repo if you want to just check out the code a bit", "tokens": [50664, 293, 291, 362, 257, 23331, 49040, 498, 291, 528, 281, 445, 1520, 484, 264, 3089, 257, 857, 50864], "temperature": 0.0, "avg_logprob": -0.17428631478167594, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.012842795811593533}, {"id": 272, "seek": 109700, "start": 1107.0, "end": 1109.0, "text": " and play with it, so you have a Docker Compose,", "tokens": [50864, 293, 862, 365, 309, 11, 370, 291, 362, 257, 33772, 6620, 541, 11, 50964], "temperature": 0.0, "avg_logprob": -0.17428631478167594, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.012842795811593533}, {"id": 273, "seek": 109700, "start": 1109.0, "end": 1111.0, "text": " you just need to run it.", "tokens": [50964, 291, 445, 643, 281, 1190, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17428631478167594, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.012842795811593533}, {"id": 274, "seek": 109700, "start": 1111.0, "end": 1116.0, "text": " It's a live demo,", "tokens": [51064, 467, 311, 257, 1621, 10723, 11, 51314], "temperature": 0.0, "avg_logprob": -0.17428631478167594, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.012842795811593533}, {"id": 275, "seek": 109700, "start": 1116.0, "end": 1124.0, "text": " so I hope that it will be all right right now.", "tokens": [51314, 370, 286, 1454, 300, 309, 486, 312, 439, 558, 558, 586, 13, 51714], "temperature": 0.0, "avg_logprob": -0.17428631478167594, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.012842795811593533}, {"id": 276, "seek": 112400, "start": 1124.0, "end": 1130.0, "text": " Okay, so we started everything, all the services are up.", "tokens": [50364, 1033, 11, 370, 321, 1409, 1203, 11, 439, 264, 3328, 366, 493, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13405460299867572, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.01029781624674797}, {"id": 277, "seek": 112400, "start": 1130.0, "end": 1135.0, "text": " Let's see, we have the front end, the process and the delivery are up", "tokens": [50664, 961, 311, 536, 11, 321, 362, 264, 1868, 917, 11, 264, 1399, 293, 264, 8982, 366, 493, 50914], "temperature": 0.0, "avg_logprob": -0.13405460299867572, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.01029781624674797}, {"id": 278, "seek": 112400, "start": 1135.0, "end": 1141.0, "text": " and we have a local community Mongo that we used just for the preparation", "tokens": [50914, 293, 321, 362, 257, 2654, 1768, 48380, 300, 321, 1143, 445, 337, 264, 13081, 51214], "temperature": 0.0, "avg_logprob": -0.13405460299867572, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.01029781624674797}, {"id": 279, "seek": 112400, "start": 1141.0, "end": 1147.0, "text": " but we could use Atlas or any other Mongo that we wanted", "tokens": [51214, 457, 321, 727, 764, 32485, 420, 604, 661, 48380, 300, 321, 1415, 51514], "temperature": 0.0, "avg_logprob": -0.13405460299867572, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.01029781624674797}, {"id": 280, "seek": 114700, "start": 1147.0, "end": 1156.0, "text": " and just shoot an event or order some food and see what happened.", "tokens": [50364, 293, 445, 3076, 364, 2280, 420, 1668, 512, 1755, 293, 536, 437, 2011, 13, 50814], "temperature": 0.0, "avg_logprob": -0.18596372725088386, "compression_ratio": 1.4719101123595506, "no_speech_prob": 0.12793685495853424}, {"id": 281, "seek": 114700, "start": 1156.0, "end": 1160.0, "text": " So I have Memphis Sandbox here, Hope End,", "tokens": [50814, 407, 286, 362, 26743, 7985, 4995, 510, 11, 6483, 6967, 11, 51014], "temperature": 0.0, "avg_logprob": -0.18596372725088386, "compression_ratio": 1.4719101123595506, "no_speech_prob": 0.12793685495853424}, {"id": 282, "seek": 114700, "start": 1160.0, "end": 1164.0, "text": " which emphasized the queues within it,", "tokens": [51014, 597, 34068, 264, 631, 1247, 1951, 309, 11, 51214], "temperature": 0.0, "avg_logprob": -0.18596372725088386, "compression_ratio": 1.4719101123595506, "no_speech_prob": 0.12793685495853424}, {"id": 283, "seek": 114700, "start": 1164.0, "end": 1168.0, "text": " so if I'll go to orders new, I should see our new order here.", "tokens": [51214, 370, 498, 286, 603, 352, 281, 9470, 777, 11, 286, 820, 536, 527, 777, 1668, 510, 13, 51414], "temperature": 0.0, "avg_logprob": -0.18596372725088386, "compression_ratio": 1.4719101123595506, "no_speech_prob": 0.12793685495853424}, {"id": 284, "seek": 114700, "start": 1168.0, "end": 1173.0, "text": " Let's see, it's a bit small, it's small here as well.", "tokens": [51414, 961, 311, 536, 11, 309, 311, 257, 857, 1359, 11, 309, 311, 1359, 510, 382, 731, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18596372725088386, "compression_ratio": 1.4719101123595506, "no_speech_prob": 0.12793685495853424}, {"id": 285, "seek": 117300, "start": 1173.0, "end": 1178.0, "text": " So we have the status of the order, we see the order itself,", "tokens": [50364, 407, 321, 362, 264, 6558, 295, 264, 1668, 11, 321, 536, 264, 1668, 2564, 11, 50614], "temperature": 0.0, "avg_logprob": -0.13024585278003248, "compression_ratio": 1.75, "no_speech_prob": 0.0035884969402104616}, {"id": 286, "seek": 117300, "start": 1178.0, "end": 1183.0, "text": " we see on the other side the processing service that takes the data,", "tokens": [50614, 321, 536, 322, 264, 661, 1252, 264, 9007, 2643, 300, 2516, 264, 1412, 11, 50864], "temperature": 0.0, "avg_logprob": -0.13024585278003248, "compression_ratio": 1.75, "no_speech_prob": 0.0035884969402104616}, {"id": 287, "seek": 117300, "start": 1183.0, "end": 1189.0, "text": " do something, sorry, something that does something", "tokens": [50864, 360, 746, 11, 2597, 11, 746, 300, 775, 746, 51164], "temperature": 0.0, "avg_logprob": -0.13024585278003248, "compression_ratio": 1.75, "no_speech_prob": 0.0035884969402104616}, {"id": 288, "seek": 117300, "start": 1189.0, "end": 1193.0, "text": " and push it towards the delivery queue", "tokens": [51164, 293, 2944, 309, 3030, 264, 8982, 18639, 51364], "temperature": 0.0, "avg_logprob": -0.13024585278003248, "compression_ratio": 1.75, "no_speech_prob": 0.0035884969402104616}, {"id": 289, "seek": 117300, "start": 1193.0, "end": 1198.0, "text": " and we should see the same event here,", "tokens": [51364, 293, 321, 820, 536, 264, 912, 2280, 510, 11, 51614], "temperature": 0.0, "avg_logprob": -0.13024585278003248, "compression_ratio": 1.75, "no_speech_prob": 0.0035884969402104616}, {"id": 290, "seek": 117300, "start": 1198.0, "end": 1202.0, "text": " so ready date, order date, exactly.", "tokens": [51614, 370, 1919, 4002, 11, 1668, 4002, 11, 2293, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13024585278003248, "compression_ratio": 1.75, "no_speech_prob": 0.0035884969402104616}, {"id": 291, "seek": 120200, "start": 1202.0, "end": 1210.0, "text": " So we'll go to the MongoDB and refresh it a bit.", "tokens": [50364, 407, 321, 603, 352, 281, 264, 48380, 27735, 293, 15134, 309, 257, 857, 13, 50764], "temperature": 0.0, "avg_logprob": -0.13465272927586036, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.016641560941934586}, {"id": 292, "seek": 120200, "start": 1210.0, "end": 1213.0, "text": " We should see our order here as well,", "tokens": [50764, 492, 820, 536, 527, 1668, 510, 382, 731, 11, 50914], "temperature": 0.0, "avg_logprob": -0.13465272927586036, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.016641560941934586}, {"id": 293, "seek": 120200, "start": 1213.0, "end": 1219.0, "text": " so we can see the entire state as it goes or as it updated through the different services.", "tokens": [50914, 370, 321, 393, 536, 264, 2302, 1785, 382, 309, 1709, 420, 382, 309, 10588, 807, 264, 819, 3328, 13, 51214], "temperature": 0.0, "avg_logprob": -0.13465272927586036, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.016641560941934586}, {"id": 294, "seek": 120200, "start": 1219.0, "end": 1224.0, "text": " We have the order date and three seconds after the dish is ready", "tokens": [51214, 492, 362, 264, 1668, 4002, 293, 1045, 3949, 934, 264, 5025, 307, 1919, 51464], "temperature": 0.0, "avg_logprob": -0.13465272927586036, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.016641560941934586}, {"id": 295, "seek": 120200, "start": 1224.0, "end": 1229.0, "text": " and four seconds after it's already sent to the customer.", "tokens": [51464, 293, 1451, 3949, 934, 309, 311, 1217, 2279, 281, 264, 5474, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13465272927586036, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.016641560941934586}, {"id": 296, "seek": 122900, "start": 1229.0, "end": 1235.0, "text": " So that's the main event and it happened entirely as synchronously", "tokens": [50364, 407, 300, 311, 264, 2135, 2280, 293, 309, 2011, 7696, 382, 19331, 5098, 50664], "temperature": 0.0, "avg_logprob": -0.13727667361875123, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.006043744273483753}, {"id": 297, "seek": 122900, "start": 1235.0, "end": 1238.0, "text": " and it's a great hamburger and yeah.", "tokens": [50664, 293, 309, 311, 257, 869, 34575, 293, 1338, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13727667361875123, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.006043744273483753}, {"id": 298, "seek": 122900, "start": 1238.0, "end": 1242.0, "text": " So that's what I wanted to show", "tokens": [50814, 407, 300, 311, 437, 286, 1415, 281, 855, 51014], "temperature": 0.0, "avg_logprob": -0.13727667361875123, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.006043744273483753}, {"id": 299, "seek": 122900, "start": 1242.0, "end": 1248.0, "text": " and again as we talked about the debate of microservices versus monoliths", "tokens": [51014, 293, 797, 382, 321, 2825, 466, 264, 7958, 295, 15547, 47480, 5717, 1108, 29131, 82, 51314], "temperature": 0.0, "avg_logprob": -0.13727667361875123, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.006043744273483753}, {"id": 300, "seek": 122900, "start": 1248.0, "end": 1250.0, "text": " so I wrote a lot of articles about it.", "tokens": [51314, 370, 286, 4114, 257, 688, 295, 11290, 466, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13727667361875123, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.006043744273483753}, {"id": 301, "seek": 122900, "start": 1250.0, "end": 1256.0, "text": " I started my journey with data many years ago,", "tokens": [51414, 286, 1409, 452, 4671, 365, 1412, 867, 924, 2057, 11, 51714], "temperature": 0.0, "avg_logprob": -0.13727667361875123, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.006043744273483753}, {"id": 302, "seek": 125600, "start": 1256.0, "end": 1261.0, "text": " four years ago, something like that, especially with data streaming.", "tokens": [50364, 1451, 924, 2057, 11, 746, 411, 300, 11, 2318, 365, 1412, 11791, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10230386790944569, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.01485306303948164}, {"id": 303, "seek": 125600, "start": 1261.0, "end": 1266.0, "text": " We built a data streaming based AI project", "tokens": [50614, 492, 3094, 257, 1412, 11791, 2361, 7318, 1716, 50864], "temperature": 0.0, "avg_logprob": -0.10230386790944569, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.01485306303948164}, {"id": 304, "seek": 125600, "start": 1266.0, "end": 1272.0, "text": " that basically analyzed using LDA, Twitter and Facebook", "tokens": [50864, 300, 1936, 28181, 1228, 441, 7509, 11, 5794, 293, 4384, 51164], "temperature": 0.0, "avg_logprob": -0.10230386790944569, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.01485306303948164}, {"id": 305, "seek": 125600, "start": 1272.0, "end": 1275.0, "text": " to get the general conversation of the public", "tokens": [51164, 281, 483, 264, 2674, 3761, 295, 264, 1908, 51314], "temperature": 0.0, "avg_logprob": -0.10230386790944569, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.01485306303948164}, {"id": 306, "seek": 125600, "start": 1275.0, "end": 1283.0, "text": " and the need for scale and agility really takes place very, very, very fast", "tokens": [51314, 293, 264, 643, 337, 4373, 293, 39794, 534, 2516, 1081, 588, 11, 588, 11, 588, 2370, 51714], "temperature": 0.0, "avg_logprob": -0.10230386790944569, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.01485306303948164}, {"id": 307, "seek": 128300, "start": 1283.0, "end": 1289.0, "text": " so I really recommend everyone to start even not to build with microservices", "tokens": [50364, 370, 286, 534, 2748, 1518, 281, 722, 754, 406, 281, 1322, 365, 15547, 47480, 50664], "temperature": 0.0, "avg_logprob": -0.13332211343865646, "compression_ratio": 1.5678391959798994, "no_speech_prob": 0.004714654758572578}, {"id": 308, "seek": 128300, "start": 1289.0, "end": 1293.0, "text": " and queues and asynchronous patterns", "tokens": [50664, 293, 631, 1247, 293, 49174, 8294, 50864], "temperature": 0.0, "avg_logprob": -0.13332211343865646, "compression_ratio": 1.5678391959798994, "no_speech_prob": 0.004714654758572578}, {"id": 309, "seek": 128300, "start": 1293.0, "end": 1298.0, "text": " but at least try or think about the refactor that you will need to do", "tokens": [50864, 457, 412, 1935, 853, 420, 519, 466, 264, 1895, 15104, 300, 291, 486, 643, 281, 360, 51114], "temperature": 0.0, "avg_logprob": -0.13332211343865646, "compression_ratio": 1.5678391959798994, "no_speech_prob": 0.004714654758572578}, {"id": 310, "seek": 128300, "start": 1298.0, "end": 1303.0, "text": " if you decided to go with the monolith and not even driven architecture.", "tokens": [51114, 498, 291, 3047, 281, 352, 365, 264, 1108, 29131, 293, 406, 754, 9555, 9482, 13, 51364], "temperature": 0.0, "avg_logprob": -0.13332211343865646, "compression_ratio": 1.5678391959798994, "no_speech_prob": 0.004714654758572578}, {"id": 311, "seek": 128300, "start": 1303.0, "end": 1306.0, "text": " So that's it. Thank you very much for this opportunity.", "tokens": [51364, 407, 300, 311, 309, 13, 1044, 291, 588, 709, 337, 341, 2650, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13332211343865646, "compression_ratio": 1.5678391959798994, "no_speech_prob": 0.004714654758572578}, {"id": 312, "seek": 130600, "start": 1306.0, "end": 1308.0, "text": " Really happy to be here.", "tokens": [50364, 4083, 2055, 281, 312, 510, 13, 50464], "temperature": 0.0, "avg_logprob": -0.24298874537150064, "compression_ratio": 0.75, "no_speech_prob": 0.5265307426452637}], "language": "en"}