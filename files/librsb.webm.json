{"text": " Alright, we're going to start the next talk. If you're going to stay in the room, please take a seat. If you want to leave, please leave. Okay, so next speaker is Michele, who's going to talk about a universal sparse glass library. So, yes, at the core of many technical or scientific computing problems, we end up, we reduce the problem to solving a system of linear equations. If the system of linear equations were a simple one, like a two by two one, the method of solving would be pretty simple. And in any case, it would involve representing the linear systems by the data structure of a matrix, so a table of symbols or usually numbers and a few vectors of numbers. So, the matrix is the basic structure of scientific computing. In the case of such toy problems or school problems, we have exact direct solutions at our disposal, which works fine. However, once we go into the problems involving simulation of larger domains, so engineering problems, those linear systems to be solved become large. And also, the methods that we use for smaller systems are not applyable here anymore because the numerical stability of, let's say, toy problems or small problems, the stability is not here anymore. Simply, those methods, numbers, results, they verge. And the time to solution also increases more than exponentially. So, they're simply infeasible and don't make sense. So, it's a different, it was completed different techniques for large linear systems. So, furthermore, if the systems were not only large, but also full of zeros in the matrices, so how do we call the systems or what do we have to do with here? We have to do perhaps with sparse systems or sparse problems. This is the way we call it. So, in this acoustics matrix or matrix coming from acoustics, we observe that less than half percent of each row on the average has a non-zero element. So, we would call this sparse systems, perhaps, so the system coming from this matrix. Indeed, usually we use, we are happy with the definition of Jim Wilkinson, where we say a problem or a matrix is sparse. If we can, with our technology, which our technique, we can make use of the amount of zeros there to our advantage. So, this is the definition. It's not about numbers. It's really about what we are able to do with the way the matrix looks like. So, among the different matrices we can encounter, we could have matrices from a circuit simulation, which looks like this, and have such clustered elements in them. Sometimes the elements are more clustered around the diagonal, like in this quantum, I think quantum chromodynamics, I think, matrix. Computational fluid dynamics matrices a bit more regular, I could say. So, it means that you can exploit all of those matrices, perhaps, in different ways. This is what I'm showing you, this gallery. This is another CFD, so computational fluid dynamics matrix, a structural matrix, another material problem matrix, structural and so on. This is also CFD1. So, this was just to tell you that sparsity really is related to the technologies, the technology we use to deal with it. So, usually, we are happy using iterative methods with sparse systems. Iterative methods, because something is being iterated. So, there is a loop, and with the most common methods, Krilov methods, the loop usually has a bottleneck, has a core operation, which is prominently multiplying the system matrix by one vector or many vectors. It depends a bit on the technique. There are several of them. Here, I'm showing a new octave implementation of such one iterative method. So, there are two kernel operations, or main operations, multiplication of the matrix by many vectors, or let's say, another dense matrix, or the triangular solve, so the solving of matrices which are called preconditioner matrices, but are spars. And these are the core operations which we are interested in. And I want to mention that those operations for the sparse matrix vector or multi-vector operation can have many variants. The variants can be on the matrix, which could be perhaps complex and Hermitian, or symmetric. It doesn't have always to be square. It could be any rectangular. And perhaps it has already a unit diagonal, and we can exploit this. This is what I'm saying. Many things change if the matrix has a complex numbers, or long complex numbers like a speaker before me spoke about. So, that changes the balances in the performance profile here. And other things might change. And all of this have influence on the specific kernels. And if you think like Ludovic has spoken about the different variants that one might want to build over different architectures, you see that this is, you end up with code bloat if you really want to optimize each subcase. Also, the operands have their own variants. So, in the way the data are laid in the dense matrix. Yeah. Similarly, for the triangular solve operation, there also you have different variants, which lead to a multitude of different kernels or ways you wish to write them, kernels of code. So, this leads to a committee of people, end of the 90s, to meet together. It was mostly US people, but also from delegations from Europe to standardize an API, which they called sparse blasts, sparse basically algebra subroutines, to somehow just give an API to the different variations of the operations that I spoke about. So, it's mostly, it's not like full blast if you know the dense blast. It's mostly about creating sparse matrices, destroying them, and doing a few operations, not only those one, but these are really the core operations. And they talked about C and Fortran, because the, yeah, 20 years ago, 20 something years ago was the final document which they finalized. Now, after 20 years, we could say that, well, what they've wrote, especially this is especially in my opinion, is perfectly portable, allows some parallelization, even if it's not specified at all. They didn't foresee extensions, but it's possible. If you look at the API, you see that you can have extensions. So, they're not blocked somehow. The namesake of sparse blast has been copied by every major vendor you can imagine. The sad thing that each major vendor has completely violated their API. So, they changed something in a slightly incompatible way, which is sad, simply sad. And the original sparse blast didn't think about the GPUs, but actually, in my experience, looking at how people program code, I see so much technical depth that I think you can do compromises. And with small adaptions, you could adapt the sparse blast to the GPU, to the GPU computations to some extent. So, I think you can save this API to a good extent. And this is the reason why I'm here. So, I wrote a library which respects the original sparse blast. So, I see sparse blast program can look like this, where you have a notation for the sparse blast operations, which is logical if you know blasts a bit, so you can understand it a bit. And going in the direction of my library, it's centered, it's around a data format, a sparse matrix format, which I came up with. It's called recursive sparse blocks, because there is a recursive subdivisions. There are blocks which are sparse. And the reason, the motivation for this data structure is to not exclude the sparse blast operations. So, I have made compromises in order to allow sparse blast operations to be there. I didn't want to preclude these operations. So, it's a compromise. And the core idea here is to have, let's say, cache size blocks, more or less, and a way to give each multi-core core something to work with. So, it's oriented towards multi-core. It's not for GPUs, or not at the moment, at least. So, the matrices which you have seen before, with this data format, the data structure looks a bit like this. The color is based on the population, on the amount of matrices are there. Then there is another core coding with other information. But this is just to tell you that the irregular aspect of those matrices is reflected also here, to some extent. Yeah. So, the library itself wants to provide sparse blast. So, building blocks for iterative solvers. It's pretty compatible at the library. It works with C++, Fortune, Octave, and Python. I say it's quite compatible. So, it uses, let's say, established technologies. And it's quite compatible also in the sense with your software. It doesn't require you to use the only data structure which is custom is the matrix. You don't need extra data structures for vectors. And the program I saw before written in the sparse blast, for using RSV, uses just one extra init and finalized function. So, I really respect that API. But, however, it's nice to write also the 15th standard. Or joking. This is not the 15th standard, but just the internal API. So, if you want, perhaps you can exploit the internal API of Libre Sb, or not internal, but the native one. Please tell me when I'm at 10 minutes. Yeah. Which is primarily in C. Then you have wrappers with C++. And there's also the Fortune one. These are the native APIs. And what is specific about RSV is that the blocking is not so clear which blocking is best. Because, yeah, depending on how you block, you could have better or worse performance. And for this reason, there is an idea of using automated empirical optimization in this library. There is a special call, a function which you call when you invest time to ask the library to optimize a bit the data structure. So, you sacrifice a minute, perhaps, for optimizing the data structure a bit. And you do this in the hope that the many hours which we'll be using this matrix afterwards will be, will profit, will be decreased, thanks to the optimization. Because, as I said, this is meant to be used for iterative methods. So, you will be running this for many hours. And, therefore, spending a few minutes in automated optimization, it's something that should pay off. No guarantee, but that's the idea and that is usually how it goes. To give an idea, this C++ API is what you would expect. So, there is a class templated on the type. So, there is type safety here. When you say, this is my library, sorry, this is my matrix. These are my non-zeros because this is what we are representing here. We, you have flags, C-style flags for options like symmetry or asking for discarding zeros rather than keeping the zeros because sometimes you want to keep structural zeros for modifying them later, for instance. So, you have many such options here. And this is the way, this is why I'm showing this slide to tell you that there are many options which I'm not showing you here. Yeah. And the only data structure here is the RSB matrix, no other custom stuff. And you can exploit, you can enjoy the spam interface of C++ 20 that doesn't really force you to have any weird custom vector type apart from the standard C++ ones. If you want to use, for instance, GNU Octave and enjoy the multi-core speedup from Libar SB, you can use the sparse RSB plug-in which I wrote, which uses C++ Libar SB pretty efficiently. So apart from a few conversions, it should be, it should have almost native performance. Similarly for Python, the PyRSB plug-in for standalone, sorry, package has an interface which is copied from CSR matrix. So you use it mostly the same way. But underneath, Libar SB runs. You don't see it. Or you see it if you ask it to use the auto-tuning routine. Because as I said, in all of those language implementations, you can also use all of the functionality of Libar SB which includes the auto-tuning also here in Octave. And I want to stress this. GNU Octave doesn't have multi-threaded sparse operations. With Libar SB, you can have them. Same for SciPy sparse. As far as I know, it's not multi-threaded. With Libar SB, you get it. Libar SB is by default licensed as lesser GPL3. Which means you can, if you don't, as long as you don't modify it, you can distribute it with your proprietary code. If you modify it, well, it's more complicated. You have to release the modified version. The Libar SB library, if you want to learn to use it, it makes absolutely sense to use a packaged version from Debian Ubuntu or most of Linux distributions. Or if you use Windows and you can use Siegwin. Or once you want the performance, I mean, you can just compile it by yourself because it's quite trivial. Or enjoy what our colleagues here from Spark and EasyBuild have done and use the packaged version from those distributions. And some people have written wrappers for Rust and Julia. I don't know these languages, so I didn't use them. I think the Rust one is like the entire API. I think Julia is more in Julia style, so it's just what is, the core functionality is there, I think. Yeah, that was everything. I don't know how much time did I take. Oh, 50 minutes. So, thanks.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 18.12, "text": " Alright, we're going to start the next talk. If you're going to stay in the room, please", "tokens": [2798, 11, 321, 434, 516, 281, 722, 264, 958, 751, 13, 759, 291, 434, 516, 281, 1754, 294, 264, 1808, 11, 1767], "temperature": 0.0, "avg_logprob": -0.28838674838726336, "compression_ratio": 1.1282051282051282, "no_speech_prob": 0.6056598424911499}, {"id": 1, "seek": 1812, "start": 18.12, "end": 35.64, "text": " take a seat. If you want to leave, please leave. Okay, so next speaker is Michele, who's", "tokens": [747, 257, 6121, 13, 759, 291, 528, 281, 1856, 11, 1767, 1856, 13, 1033, 11, 370, 958, 8145, 307, 3392, 16884, 11, 567, 311], "temperature": 0.0, "avg_logprob": -0.218023419380188, "compression_ratio": 1.0602409638554218, "no_speech_prob": 0.0037491414695978165}, {"id": 2, "seek": 3564, "start": 35.64, "end": 51.32, "text": " going to talk about a universal sparse glass library. So, yes, at the core of many technical", "tokens": [516, 281, 751, 466, 257, 11455, 637, 11668, 4276, 6405, 13, 407, 11, 2086, 11, 412, 264, 4965, 295, 867, 6191], "temperature": 0.0, "avg_logprob": -0.1691558144309304, "compression_ratio": 1.366412213740458, "no_speech_prob": 0.0027156041469424963}, {"id": 3, "seek": 3564, "start": 51.32, "end": 58.44, "text": " or scientific computing problems, we end up, we reduce the problem to solving a system", "tokens": [420, 8134, 15866, 2740, 11, 321, 917, 493, 11, 321, 5407, 264, 1154, 281, 12606, 257, 1185], "temperature": 0.0, "avg_logprob": -0.1691558144309304, "compression_ratio": 1.366412213740458, "no_speech_prob": 0.0027156041469424963}, {"id": 4, "seek": 5844, "start": 58.44, "end": 64.03999999999999, "text": " of linear equations. If the system of linear equations were a simple one, like a two by", "tokens": [295, 8213, 11787, 13, 759, 264, 1185, 295, 8213, 11787, 645, 257, 2199, 472, 11, 411, 257, 732, 538], "temperature": 0.0, "avg_logprob": -0.18645159403483072, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.0002693676797207445}, {"id": 5, "seek": 5844, "start": 64.03999999999999, "end": 77.36, "text": " two one, the method of solving would be pretty simple. And in any case, it would involve representing", "tokens": [732, 472, 11, 264, 3170, 295, 12606, 576, 312, 1238, 2199, 13, 400, 294, 604, 1389, 11, 309, 576, 9494, 13460], "temperature": 0.0, "avg_logprob": -0.18645159403483072, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.0002693676797207445}, {"id": 6, "seek": 5844, "start": 77.36, "end": 85.24, "text": " the linear systems by the data structure of a matrix, so a table of symbols or usually", "tokens": [264, 8213, 3652, 538, 264, 1412, 3877, 295, 257, 8141, 11, 370, 257, 3199, 295, 16944, 420, 2673], "temperature": 0.0, "avg_logprob": -0.18645159403483072, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.0002693676797207445}, {"id": 7, "seek": 8524, "start": 85.24, "end": 94.24, "text": " numbers and a few vectors of numbers. So, the matrix is the basic structure of scientific", "tokens": [3547, 293, 257, 1326, 18875, 295, 3547, 13, 407, 11, 264, 8141, 307, 264, 3875, 3877, 295, 8134], "temperature": 0.0, "avg_logprob": -0.144027586906187, "compression_ratio": 1.5191256830601092, "no_speech_prob": 1.756393066898454e-05}, {"id": 8, "seek": 8524, "start": 94.24, "end": 104.44, "text": " computing. In the case of such toy problems or school problems, we have exact direct solutions", "tokens": [15866, 13, 682, 264, 1389, 295, 1270, 12058, 2740, 420, 1395, 2740, 11, 321, 362, 1900, 2047, 6547], "temperature": 0.0, "avg_logprob": -0.144027586906187, "compression_ratio": 1.5191256830601092, "no_speech_prob": 1.756393066898454e-05}, {"id": 9, "seek": 8524, "start": 104.44, "end": 114.67999999999999, "text": " at our disposal, which works fine. However, once we go into the problems involving simulation", "tokens": [412, 527, 26400, 11, 597, 1985, 2489, 13, 2908, 11, 1564, 321, 352, 666, 264, 2740, 17030, 16575], "temperature": 0.0, "avg_logprob": -0.144027586906187, "compression_ratio": 1.5191256830601092, "no_speech_prob": 1.756393066898454e-05}, {"id": 10, "seek": 11468, "start": 114.68, "end": 121.92, "text": " of larger domains, so engineering problems, those linear systems to be solved become", "tokens": [295, 4833, 25514, 11, 370, 7043, 2740, 11, 729, 8213, 3652, 281, 312, 13041, 1813], "temperature": 0.0, "avg_logprob": -0.18175687789916992, "compression_ratio": 1.6303030303030304, "no_speech_prob": 8.630951924715191e-05}, {"id": 11, "seek": 11468, "start": 121.92, "end": 132.68, "text": " large. And also, the methods that we use for smaller systems are not applyable here anymore", "tokens": [2416, 13, 400, 611, 11, 264, 7150, 300, 321, 764, 337, 4356, 3652, 366, 406, 3079, 712, 510, 3602], "temperature": 0.0, "avg_logprob": -0.18175687789916992, "compression_ratio": 1.6303030303030304, "no_speech_prob": 8.630951924715191e-05}, {"id": 12, "seek": 11468, "start": 132.68, "end": 140.08, "text": " because the numerical stability of, let's say, toy problems or small problems, the stability", "tokens": [570, 264, 29054, 11826, 295, 11, 718, 311, 584, 11, 12058, 2740, 420, 1359, 2740, 11, 264, 11826], "temperature": 0.0, "avg_logprob": -0.18175687789916992, "compression_ratio": 1.6303030303030304, "no_speech_prob": 8.630951924715191e-05}, {"id": 13, "seek": 14008, "start": 140.08, "end": 147.64000000000001, "text": " is not here anymore. Simply, those methods, numbers, results, they verge. And the time", "tokens": [307, 406, 510, 3602, 13, 19596, 11, 729, 7150, 11, 3547, 11, 3542, 11, 436, 37164, 13, 400, 264, 565], "temperature": 0.0, "avg_logprob": -0.29207313761991616, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0005614585825242102}, {"id": 14, "seek": 14008, "start": 147.64000000000001, "end": 155.04000000000002, "text": " to solution also increases more than exponentially. So, they're simply infeasible and don't make", "tokens": [281, 3827, 611, 8637, 544, 813, 37330, 13, 407, 11, 436, 434, 2935, 1536, 68, 296, 964, 293, 500, 380, 652], "temperature": 0.0, "avg_logprob": -0.29207313761991616, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0005614585825242102}, {"id": 15, "seek": 14008, "start": 155.04000000000002, "end": 164.48000000000002, "text": " sense. So, it's a different, it was completed different techniques for large linear systems.", "tokens": [2020, 13, 407, 11, 309, 311, 257, 819, 11, 309, 390, 7365, 819, 7512, 337, 2416, 8213, 3652, 13], "temperature": 0.0, "avg_logprob": -0.29207313761991616, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0005614585825242102}, {"id": 16, "seek": 16448, "start": 164.48, "end": 176.04, "text": " So, furthermore, if the systems were not only large, but also full of zeros in the matrices,", "tokens": [407, 11, 3052, 3138, 11, 498, 264, 3652, 645, 406, 787, 2416, 11, 457, 611, 1577, 295, 35193, 294, 264, 32284, 11], "temperature": 0.0, "avg_logprob": -0.1892098617553711, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00028078557807020843}, {"id": 17, "seek": 16448, "start": 176.04, "end": 182.16, "text": " so how do we call the systems or what do we have to do with here? We have to do perhaps", "tokens": [370, 577, 360, 321, 818, 264, 3652, 420, 437, 360, 321, 362, 281, 360, 365, 510, 30, 492, 362, 281, 360, 4317], "temperature": 0.0, "avg_logprob": -0.1892098617553711, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00028078557807020843}, {"id": 18, "seek": 16448, "start": 182.16, "end": 190.6, "text": " with sparse systems or sparse problems. This is the way we call it. So, in this acoustics", "tokens": [365, 637, 11668, 3652, 420, 637, 11668, 2740, 13, 639, 307, 264, 636, 321, 818, 309, 13, 407, 11, 294, 341, 22740, 1167], "temperature": 0.0, "avg_logprob": -0.1892098617553711, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00028078557807020843}, {"id": 19, "seek": 19060, "start": 190.6, "end": 200.79999999999998, "text": " matrix or matrix coming from acoustics, we observe that less than half percent of each", "tokens": [8141, 420, 8141, 1348, 490, 22740, 1167, 11, 321, 11441, 300, 1570, 813, 1922, 3043, 295, 1184], "temperature": 0.0, "avg_logprob": -0.19605100856107824, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0002716985472943634}, {"id": 20, "seek": 19060, "start": 200.79999999999998, "end": 211.28, "text": " row on the average has a non-zero element. So, we would call this sparse systems, perhaps,", "tokens": [5386, 322, 264, 4274, 575, 257, 2107, 12, 32226, 4478, 13, 407, 11, 321, 576, 818, 341, 637, 11668, 3652, 11, 4317, 11], "temperature": 0.0, "avg_logprob": -0.19605100856107824, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0002716985472943634}, {"id": 21, "seek": 19060, "start": 211.28, "end": 218.95999999999998, "text": " so the system coming from this matrix. Indeed, usually we use, we are happy with the definition", "tokens": [370, 264, 1185, 1348, 490, 341, 8141, 13, 15061, 11, 2673, 321, 764, 11, 321, 366, 2055, 365, 264, 7123], "temperature": 0.0, "avg_logprob": -0.19605100856107824, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0002716985472943634}, {"id": 22, "seek": 21896, "start": 218.96, "end": 229.16, "text": " of Jim Wilkinson, where we say a problem or a matrix is sparse. If we can, with our technology,", "tokens": [295, 6637, 9483, 10277, 266, 11, 689, 321, 584, 257, 1154, 420, 257, 8141, 307, 637, 11668, 13, 759, 321, 393, 11, 365, 527, 2899, 11], "temperature": 0.0, "avg_logprob": -0.16534152783845601, "compression_ratio": 1.5303867403314917, "no_speech_prob": 2.9850221835658886e-05}, {"id": 23, "seek": 21896, "start": 229.16, "end": 237.08, "text": " which our technique, we can make use of the amount of zeros there to our advantage. So,", "tokens": [597, 527, 6532, 11, 321, 393, 652, 764, 295, 264, 2372, 295, 35193, 456, 281, 527, 5002, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.16534152783845601, "compression_ratio": 1.5303867403314917, "no_speech_prob": 2.9850221835658886e-05}, {"id": 24, "seek": 21896, "start": 237.08, "end": 242.32, "text": " this is the definition. It's not about numbers. It's really about what we are able to do with", "tokens": [341, 307, 264, 7123, 13, 467, 311, 406, 466, 3547, 13, 467, 311, 534, 466, 437, 321, 366, 1075, 281, 360, 365], "temperature": 0.0, "avg_logprob": -0.16534152783845601, "compression_ratio": 1.5303867403314917, "no_speech_prob": 2.9850221835658886e-05}, {"id": 25, "seek": 24232, "start": 242.32, "end": 250.51999999999998, "text": " the way the matrix looks like. So, among the different matrices we can encounter, we could", "tokens": [264, 636, 264, 8141, 1542, 411, 13, 407, 11, 3654, 264, 819, 32284, 321, 393, 8593, 11, 321, 727], "temperature": 0.0, "avg_logprob": -0.17679055035114288, "compression_ratio": 1.6529411764705881, "no_speech_prob": 8.729915134608746e-05}, {"id": 26, "seek": 24232, "start": 250.51999999999998, "end": 258.12, "text": " have matrices from a circuit simulation, which looks like this, and have such clustered elements", "tokens": [362, 32284, 490, 257, 9048, 16575, 11, 597, 1542, 411, 341, 11, 293, 362, 1270, 596, 38624, 4959], "temperature": 0.0, "avg_logprob": -0.17679055035114288, "compression_ratio": 1.6529411764705881, "no_speech_prob": 8.729915134608746e-05}, {"id": 27, "seek": 24232, "start": 258.12, "end": 265.12, "text": " in them. Sometimes the elements are more clustered around the diagonal, like in this quantum,", "tokens": [294, 552, 13, 4803, 264, 4959, 366, 544, 596, 38624, 926, 264, 21539, 11, 411, 294, 341, 13018, 11], "temperature": 0.0, "avg_logprob": -0.17679055035114288, "compression_ratio": 1.6529411764705881, "no_speech_prob": 8.729915134608746e-05}, {"id": 28, "seek": 26512, "start": 265.12, "end": 272.76, "text": " I think quantum chromodynamics, I think, matrix. Computational fluid dynamics matrices a bit", "tokens": [286, 519, 13018, 16209, 35483, 11, 286, 519, 11, 8141, 13, 37804, 1478, 9113, 15679, 32284, 257, 857], "temperature": 0.0, "avg_logprob": -0.23261572300702676, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0001467492984374985}, {"id": 29, "seek": 26512, "start": 272.76, "end": 278.48, "text": " more regular, I could say. So, it means that you can exploit all of those matrices, perhaps,", "tokens": [544, 3890, 11, 286, 727, 584, 13, 407, 11, 309, 1355, 300, 291, 393, 25924, 439, 295, 729, 32284, 11, 4317, 11], "temperature": 0.0, "avg_logprob": -0.23261572300702676, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0001467492984374985}, {"id": 30, "seek": 26512, "start": 278.48, "end": 283.4, "text": " in different ways. This is what I'm showing you, this gallery. This is another CFD, so", "tokens": [294, 819, 2098, 13, 639, 307, 437, 286, 478, 4099, 291, 11, 341, 18378, 13, 639, 307, 1071, 21792, 35, 11, 370], "temperature": 0.0, "avg_logprob": -0.23261572300702676, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0001467492984374985}, {"id": 31, "seek": 26512, "start": 283.4, "end": 293.4, "text": " computational fluid dynamics matrix, a structural matrix, another material problem matrix, structural", "tokens": [28270, 9113, 15679, 8141, 11, 257, 15067, 8141, 11, 1071, 2527, 1154, 8141, 11, 15067], "temperature": 0.0, "avg_logprob": -0.23261572300702676, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0001467492984374985}, {"id": 32, "seek": 29340, "start": 293.4, "end": 301.32, "text": " and so on. This is also CFD1. So, this was just to tell you that sparsity really is related", "tokens": [293, 370, 322, 13, 639, 307, 611, 21792, 35, 16, 13, 407, 11, 341, 390, 445, 281, 980, 291, 300, 637, 685, 507, 534, 307, 4077], "temperature": 0.0, "avg_logprob": -0.2090248399310642, "compression_ratio": 1.576470588235294, "no_speech_prob": 3.37767087330576e-05}, {"id": 33, "seek": 29340, "start": 301.32, "end": 309.52, "text": " to the technologies, the technology we use to deal with it. So, usually, we are happy", "tokens": [281, 264, 7943, 11, 264, 2899, 321, 764, 281, 2028, 365, 309, 13, 407, 11, 2673, 11, 321, 366, 2055], "temperature": 0.0, "avg_logprob": -0.2090248399310642, "compression_ratio": 1.576470588235294, "no_speech_prob": 3.37767087330576e-05}, {"id": 34, "seek": 29340, "start": 309.52, "end": 315.52, "text": " using iterative methods with sparse systems. Iterative methods, because something is being", "tokens": [1228, 17138, 1166, 7150, 365, 637, 11668, 3652, 13, 286, 391, 1166, 7150, 11, 570, 746, 307, 885], "temperature": 0.0, "avg_logprob": -0.2090248399310642, "compression_ratio": 1.576470588235294, "no_speech_prob": 3.37767087330576e-05}, {"id": 35, "seek": 31552, "start": 315.52, "end": 323.64, "text": " iterated. So, there is a loop, and with the most common methods, Krilov methods, the loop", "tokens": [17138, 770, 13, 407, 11, 456, 307, 257, 6367, 11, 293, 365, 264, 881, 2689, 7150, 11, 6332, 388, 5179, 7150, 11, 264, 6367], "temperature": 0.0, "avg_logprob": -0.14822489973427594, "compression_ratio": 1.5195530726256983, "no_speech_prob": 5.202364991419017e-05}, {"id": 36, "seek": 31552, "start": 323.64, "end": 332.44, "text": " usually has a bottleneck, has a core operation, which is prominently multiplying the system", "tokens": [2673, 575, 257, 44641, 547, 11, 575, 257, 4965, 6916, 11, 597, 307, 39225, 2276, 30955, 264, 1185], "temperature": 0.0, "avg_logprob": -0.14822489973427594, "compression_ratio": 1.5195530726256983, "no_speech_prob": 5.202364991419017e-05}, {"id": 37, "seek": 31552, "start": 332.44, "end": 339.47999999999996, "text": " matrix by one vector or many vectors. It depends a bit on the technique. There are several", "tokens": [8141, 538, 472, 8062, 420, 867, 18875, 13, 467, 5946, 257, 857, 322, 264, 6532, 13, 821, 366, 2940], "temperature": 0.0, "avg_logprob": -0.14822489973427594, "compression_ratio": 1.5195530726256983, "no_speech_prob": 5.202364991419017e-05}, {"id": 38, "seek": 33948, "start": 339.48, "end": 347.0, "text": " of them. Here, I'm showing a new octave implementation of such one iterative method. So, there are", "tokens": [295, 552, 13, 1692, 11, 286, 478, 4099, 257, 777, 44441, 11420, 295, 1270, 472, 17138, 1166, 3170, 13, 407, 11, 456, 366], "temperature": 0.0, "avg_logprob": -0.25754651156338776, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.00011428254947531968}, {"id": 39, "seek": 33948, "start": 347.0, "end": 353.68, "text": " two kernel operations, or main operations, multiplication of the matrix by many vectors,", "tokens": [732, 28256, 7705, 11, 420, 2135, 7705, 11, 27290, 295, 264, 8141, 538, 867, 18875, 11], "temperature": 0.0, "avg_logprob": -0.25754651156338776, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.00011428254947531968}, {"id": 40, "seek": 33948, "start": 353.68, "end": 360.28000000000003, "text": " or let's say, another dense matrix, or the triangular solve, so the solving of matrices", "tokens": [420, 718, 311, 584, 11, 1071, 18011, 8141, 11, 420, 264, 38190, 5039, 11, 370, 264, 12606, 295, 32284], "temperature": 0.0, "avg_logprob": -0.25754651156338776, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.00011428254947531968}, {"id": 41, "seek": 33948, "start": 360.28000000000003, "end": 367.92, "text": " which are called preconditioner matrices, but are spars. And these are the core operations", "tokens": [597, 366, 1219, 4346, 684, 849, 260, 32284, 11, 457, 366, 637, 685, 13, 400, 613, 366, 264, 4965, 7705], "temperature": 0.0, "avg_logprob": -0.25754651156338776, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.00011428254947531968}, {"id": 42, "seek": 36792, "start": 367.92, "end": 373.68, "text": " which we are interested in. And I want to mention that those operations for the sparse", "tokens": [597, 321, 366, 3102, 294, 13, 400, 286, 528, 281, 2152, 300, 729, 7705, 337, 264, 637, 11668], "temperature": 0.0, "avg_logprob": -0.1984763699908589, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.00020092999329790473}, {"id": 43, "seek": 36792, "start": 373.68, "end": 381.68, "text": " matrix vector or multi-vector operation can have many variants. The variants can be on", "tokens": [8141, 8062, 420, 4825, 12, 303, 1672, 6916, 393, 362, 867, 21669, 13, 440, 21669, 393, 312, 322], "temperature": 0.0, "avg_logprob": -0.1984763699908589, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.00020092999329790473}, {"id": 44, "seek": 36792, "start": 381.68, "end": 389.72, "text": " the matrix, which could be perhaps complex and Hermitian, or symmetric. It doesn't have", "tokens": [264, 8141, 11, 597, 727, 312, 4317, 3997, 293, 21842, 270, 952, 11, 420, 32330, 13, 467, 1177, 380, 362], "temperature": 0.0, "avg_logprob": -0.1984763699908589, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.00020092999329790473}, {"id": 45, "seek": 36792, "start": 389.72, "end": 397.84000000000003, "text": " always to be square. It could be any rectangular. And perhaps it has already a unit diagonal,", "tokens": [1009, 281, 312, 3732, 13, 467, 727, 312, 604, 31167, 13, 400, 4317, 309, 575, 1217, 257, 4985, 21539, 11], "temperature": 0.0, "avg_logprob": -0.1984763699908589, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.00020092999329790473}, {"id": 46, "seek": 39784, "start": 397.84, "end": 407.84, "text": " and we can exploit this. This is what I'm saying. Many things change if the matrix has", "tokens": [293, 321, 393, 25924, 341, 13, 639, 307, 437, 286, 478, 1566, 13, 5126, 721, 1319, 498, 264, 8141, 575], "temperature": 0.0, "avg_logprob": -0.2090424722240817, "compression_ratio": 1.4914285714285713, "no_speech_prob": 0.0007621338008902967}, {"id": 47, "seek": 39784, "start": 407.84, "end": 415.23999999999995, "text": " a complex numbers, or long complex numbers like a speaker before me spoke about. So,", "tokens": [257, 3997, 3547, 11, 420, 938, 3997, 3547, 411, 257, 8145, 949, 385, 7179, 466, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.2090424722240817, "compression_ratio": 1.4914285714285713, "no_speech_prob": 0.0007621338008902967}, {"id": 48, "seek": 39784, "start": 415.23999999999995, "end": 421.15999999999997, "text": " that changes the balances in the performance profile here. And other things might change.", "tokens": [300, 2962, 264, 33993, 294, 264, 3389, 7964, 510, 13, 400, 661, 721, 1062, 1319, 13], "temperature": 0.0, "avg_logprob": -0.2090424722240817, "compression_ratio": 1.4914285714285713, "no_speech_prob": 0.0007621338008902967}, {"id": 49, "seek": 42116, "start": 421.16, "end": 427.8, "text": " And all of this have influence on the specific kernels. And if you think like Ludovic has", "tokens": [400, 439, 295, 341, 362, 6503, 322, 264, 2685, 23434, 1625, 13, 400, 498, 291, 519, 411, 30550, 5179, 299, 575], "temperature": 0.0, "avg_logprob": -0.19256536076577863, "compression_ratio": 1.628440366972477, "no_speech_prob": 7.128657307475805e-05}, {"id": 50, "seek": 42116, "start": 427.8, "end": 433.6, "text": " spoken about the different variants that one might want to build over different architectures,", "tokens": [10759, 466, 264, 819, 21669, 300, 472, 1062, 528, 281, 1322, 670, 819, 6331, 1303, 11], "temperature": 0.0, "avg_logprob": -0.19256536076577863, "compression_ratio": 1.628440366972477, "no_speech_prob": 7.128657307475805e-05}, {"id": 51, "seek": 42116, "start": 433.6, "end": 438.40000000000003, "text": " you see that this is, you end up with code bloat if you really want to optimize each", "tokens": [291, 536, 300, 341, 307, 11, 291, 917, 493, 365, 3089, 1749, 267, 498, 291, 534, 528, 281, 19719, 1184], "temperature": 0.0, "avg_logprob": -0.19256536076577863, "compression_ratio": 1.628440366972477, "no_speech_prob": 7.128657307475805e-05}, {"id": 52, "seek": 42116, "start": 438.40000000000003, "end": 447.20000000000005, "text": " subcase. Also, the operands have their own variants. So, in the way the data are laid", "tokens": [1422, 9765, 13, 2743, 11, 264, 2208, 2967, 362, 641, 1065, 21669, 13, 407, 11, 294, 264, 636, 264, 1412, 366, 9897], "temperature": 0.0, "avg_logprob": -0.19256536076577863, "compression_ratio": 1.628440366972477, "no_speech_prob": 7.128657307475805e-05}, {"id": 53, "seek": 44720, "start": 447.2, "end": 455.56, "text": " in the dense matrix. Yeah. Similarly, for the triangular solve operation, there also", "tokens": [294, 264, 18011, 8141, 13, 865, 13, 13157, 11, 337, 264, 38190, 5039, 6916, 11, 456, 611], "temperature": 0.0, "avg_logprob": -0.23438865837009473, "compression_ratio": 1.563063063063063, "no_speech_prob": 1.0628241398080718e-05}, {"id": 54, "seek": 44720, "start": 455.56, "end": 461.0, "text": " you have different variants, which lead to a multitude of different kernels or ways", "tokens": [291, 362, 819, 21669, 11, 597, 1477, 281, 257, 36358, 295, 819, 23434, 1625, 420, 2098], "temperature": 0.0, "avg_logprob": -0.23438865837009473, "compression_ratio": 1.563063063063063, "no_speech_prob": 1.0628241398080718e-05}, {"id": 55, "seek": 44720, "start": 461.0, "end": 467.88, "text": " you wish to write them, kernels of code. So, this leads to a committee of people, end of", "tokens": [291, 3172, 281, 2464, 552, 11, 23434, 1625, 295, 3089, 13, 407, 11, 341, 6689, 281, 257, 7482, 295, 561, 11, 917, 295], "temperature": 0.0, "avg_logprob": -0.23438865837009473, "compression_ratio": 1.563063063063063, "no_speech_prob": 1.0628241398080718e-05}, {"id": 56, "seek": 44720, "start": 467.88, "end": 474.76, "text": " the 90s, to meet together. It was mostly US people, but also from delegations from Europe", "tokens": [264, 4289, 82, 11, 281, 1677, 1214, 13, 467, 390, 5240, 2546, 561, 11, 457, 611, 490, 15824, 763, 490, 3315], "temperature": 0.0, "avg_logprob": -0.23438865837009473, "compression_ratio": 1.563063063063063, "no_speech_prob": 1.0628241398080718e-05}, {"id": 57, "seek": 47476, "start": 474.76, "end": 484.28, "text": " to standardize an API, which they called sparse blasts, sparse basically algebra subroutines,", "tokens": [281, 3832, 1125, 364, 9362, 11, 597, 436, 1219, 637, 11668, 12035, 82, 11, 637, 11668, 1936, 21989, 1422, 81, 346, 1652, 11], "temperature": 0.0, "avg_logprob": -0.24320617251926, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.00018970599921885878}, {"id": 58, "seek": 47476, "start": 484.28, "end": 490.52, "text": " to somehow just give an API to the different variations of the operations that I spoke", "tokens": [281, 6063, 445, 976, 364, 9362, 281, 264, 819, 17840, 295, 264, 7705, 300, 286, 7179], "temperature": 0.0, "avg_logprob": -0.24320617251926, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.00018970599921885878}, {"id": 59, "seek": 47476, "start": 490.52, "end": 495.48, "text": " about. So, it's mostly, it's not like full blast if you know the dense blast. It's mostly", "tokens": [466, 13, 407, 11, 309, 311, 5240, 11, 309, 311, 406, 411, 1577, 12035, 498, 291, 458, 264, 18011, 12035, 13, 467, 311, 5240], "temperature": 0.0, "avg_logprob": -0.24320617251926, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.00018970599921885878}, {"id": 60, "seek": 47476, "start": 495.48, "end": 500.68, "text": " about creating sparse matrices, destroying them, and doing a few operations, not only", "tokens": [466, 4084, 637, 11668, 32284, 11, 19926, 552, 11, 293, 884, 257, 1326, 7705, 11, 406, 787], "temperature": 0.0, "avg_logprob": -0.24320617251926, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.00018970599921885878}, {"id": 61, "seek": 50068, "start": 500.68, "end": 506.68, "text": " those one, but these are really the core operations. And they talked about C and Fortran, because", "tokens": [729, 472, 11, 457, 613, 366, 534, 264, 4965, 7705, 13, 400, 436, 2825, 466, 383, 293, 11002, 4257, 11, 570], "temperature": 0.0, "avg_logprob": -0.22631831835674984, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0003102960472460836}, {"id": 62, "seek": 50068, "start": 506.68, "end": 513.12, "text": " the, yeah, 20 years ago, 20 something years ago was the final document which they finalized.", "tokens": [264, 11, 1338, 11, 945, 924, 2057, 11, 945, 746, 924, 2057, 390, 264, 2572, 4166, 597, 436, 2572, 1602, 13], "temperature": 0.0, "avg_logprob": -0.22631831835674984, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0003102960472460836}, {"id": 63, "seek": 50068, "start": 513.12, "end": 518.88, "text": " Now, after 20 years, we could say that, well, what they've wrote, especially this is especially", "tokens": [823, 11, 934, 945, 924, 11, 321, 727, 584, 300, 11, 731, 11, 437, 436, 600, 4114, 11, 2318, 341, 307, 2318], "temperature": 0.0, "avg_logprob": -0.22631831835674984, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0003102960472460836}, {"id": 64, "seek": 50068, "start": 518.88, "end": 524.92, "text": " in my opinion, is perfectly portable, allows some parallelization, even if it's not specified", "tokens": [294, 452, 4800, 11, 307, 6239, 21800, 11, 4045, 512, 8952, 2144, 11, 754, 498, 309, 311, 406, 22206], "temperature": 0.0, "avg_logprob": -0.22631831835674984, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0003102960472460836}, {"id": 65, "seek": 52492, "start": 524.92, "end": 533.56, "text": " at all. They didn't foresee extensions, but it's possible. If you look at the API, you", "tokens": [412, 439, 13, 814, 994, 380, 38736, 25129, 11, 457, 309, 311, 1944, 13, 759, 291, 574, 412, 264, 9362, 11, 291], "temperature": 0.0, "avg_logprob": -0.16518342093135532, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.00010891892452491447}, {"id": 66, "seek": 52492, "start": 533.56, "end": 541.4, "text": " see that you can have extensions. So, they're not blocked somehow. The namesake of sparse", "tokens": [536, 300, 291, 393, 362, 25129, 13, 407, 11, 436, 434, 406, 15470, 6063, 13, 440, 5288, 619, 295, 637, 11668], "temperature": 0.0, "avg_logprob": -0.16518342093135532, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.00010891892452491447}, {"id": 67, "seek": 52492, "start": 541.4, "end": 546.88, "text": " blast has been copied by every major vendor you can imagine. The sad thing that each major", "tokens": [12035, 575, 668, 25365, 538, 633, 2563, 24321, 291, 393, 3811, 13, 440, 4227, 551, 300, 1184, 2563], "temperature": 0.0, "avg_logprob": -0.16518342093135532, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.00010891892452491447}, {"id": 68, "seek": 52492, "start": 546.88, "end": 552.12, "text": " vendor has completely violated their API. So, they changed something in a slightly incompatible", "tokens": [24321, 575, 2584, 33239, 641, 9362, 13, 407, 11, 436, 3105, 746, 294, 257, 4748, 40393, 267, 964], "temperature": 0.0, "avg_logprob": -0.16518342093135532, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.00010891892452491447}, {"id": 69, "seek": 55212, "start": 552.12, "end": 558.48, "text": " way, which is sad, simply sad. And the original sparse blast didn't think about the GPUs,", "tokens": [636, 11, 597, 307, 4227, 11, 2935, 4227, 13, 400, 264, 3380, 637, 11668, 12035, 994, 380, 519, 466, 264, 18407, 82, 11], "temperature": 0.0, "avg_logprob": -0.21386047204335532, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.00045610129018314183}, {"id": 70, "seek": 55212, "start": 558.48, "end": 563.08, "text": " but actually, in my experience, looking at how people program code, I see so much technical", "tokens": [457, 767, 11, 294, 452, 1752, 11, 1237, 412, 577, 561, 1461, 3089, 11, 286, 536, 370, 709, 6191], "temperature": 0.0, "avg_logprob": -0.21386047204335532, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.00045610129018314183}, {"id": 71, "seek": 55212, "start": 563.08, "end": 569.88, "text": " depth that I think you can do compromises. And with small adaptions, you could adapt", "tokens": [7161, 300, 286, 519, 291, 393, 360, 11482, 3598, 13, 400, 365, 1359, 6231, 626, 11, 291, 727, 6231], "temperature": 0.0, "avg_logprob": -0.21386047204335532, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.00045610129018314183}, {"id": 72, "seek": 55212, "start": 569.88, "end": 579.16, "text": " the sparse blast to the GPU, to the GPU computations to some extent. So, I think you can save this", "tokens": [264, 637, 11668, 12035, 281, 264, 18407, 11, 281, 264, 18407, 2807, 763, 281, 512, 8396, 13, 407, 11, 286, 519, 291, 393, 3155, 341], "temperature": 0.0, "avg_logprob": -0.21386047204335532, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.00045610129018314183}, {"id": 73, "seek": 57916, "start": 579.16, "end": 586.0799999999999, "text": " API to a good extent. And this is the reason why I'm here. So, I wrote a library which", "tokens": [9362, 281, 257, 665, 8396, 13, 400, 341, 307, 264, 1778, 983, 286, 478, 510, 13, 407, 11, 286, 4114, 257, 6405, 597], "temperature": 0.0, "avg_logprob": -0.14323992370277322, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.00014951139746699482}, {"id": 74, "seek": 57916, "start": 586.0799999999999, "end": 592.24, "text": " respects the original sparse blast. So, I see sparse blast program can look like this,", "tokens": [24126, 264, 3380, 637, 11668, 12035, 13, 407, 11, 286, 536, 637, 11668, 12035, 1461, 393, 574, 411, 341, 11], "temperature": 0.0, "avg_logprob": -0.14323992370277322, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.00014951139746699482}, {"id": 75, "seek": 57916, "start": 592.24, "end": 598.7199999999999, "text": " where you have a notation for the sparse blast operations, which is logical if you know", "tokens": [689, 291, 362, 257, 24657, 337, 264, 637, 11668, 12035, 7705, 11, 597, 307, 14978, 498, 291, 458], "temperature": 0.0, "avg_logprob": -0.14323992370277322, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.00014951139746699482}, {"id": 76, "seek": 57916, "start": 598.7199999999999, "end": 605.4, "text": " blasts a bit, so you can understand it a bit. And going in the direction of my library,", "tokens": [12035, 82, 257, 857, 11, 370, 291, 393, 1223, 309, 257, 857, 13, 400, 516, 294, 264, 3513, 295, 452, 6405, 11], "temperature": 0.0, "avg_logprob": -0.14323992370277322, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.00014951139746699482}, {"id": 77, "seek": 60540, "start": 605.4, "end": 612.64, "text": " it's centered, it's around a data format, a sparse matrix format, which I came up with.", "tokens": [309, 311, 18988, 11, 309, 311, 926, 257, 1412, 7877, 11, 257, 637, 11668, 8141, 7877, 11, 597, 286, 1361, 493, 365, 13], "temperature": 0.0, "avg_logprob": -0.14711777023647143, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0003366491000633687}, {"id": 78, "seek": 60540, "start": 612.64, "end": 617.68, "text": " It's called recursive sparse blocks, because there is a recursive subdivisions. There are", "tokens": [467, 311, 1219, 20560, 488, 637, 11668, 8474, 11, 570, 456, 307, 257, 20560, 488, 45331, 4252, 13, 821, 366], "temperature": 0.0, "avg_logprob": -0.14711777023647143, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0003366491000633687}, {"id": 79, "seek": 60540, "start": 617.68, "end": 625.04, "text": " blocks which are sparse. And the reason, the motivation for this data structure is to not", "tokens": [8474, 597, 366, 637, 11668, 13, 400, 264, 1778, 11, 264, 12335, 337, 341, 1412, 3877, 307, 281, 406], "temperature": 0.0, "avg_logprob": -0.14711777023647143, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0003366491000633687}, {"id": 80, "seek": 60540, "start": 625.04, "end": 631.36, "text": " exclude the sparse blast operations. So, I have made compromises in order to allow sparse", "tokens": [33536, 264, 637, 11668, 12035, 7705, 13, 407, 11, 286, 362, 1027, 11482, 3598, 294, 1668, 281, 2089, 637, 11668], "temperature": 0.0, "avg_logprob": -0.14711777023647143, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0003366491000633687}, {"id": 81, "seek": 63136, "start": 631.36, "end": 639.48, "text": " blast operations to be there. I didn't want to preclude these operations. So, it's a compromise.", "tokens": [12035, 7705, 281, 312, 456, 13, 286, 994, 380, 528, 281, 4346, 32334, 613, 7705, 13, 407, 11, 309, 311, 257, 18577, 13], "temperature": 0.0, "avg_logprob": -0.15815881010773894, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00024196627782657743}, {"id": 82, "seek": 63136, "start": 639.48, "end": 647.0, "text": " And the core idea here is to have, let's say, cache size blocks, more or less, and a way", "tokens": [400, 264, 4965, 1558, 510, 307, 281, 362, 11, 718, 311, 584, 11, 19459, 2744, 8474, 11, 544, 420, 1570, 11, 293, 257, 636], "temperature": 0.0, "avg_logprob": -0.15815881010773894, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00024196627782657743}, {"id": 83, "seek": 63136, "start": 647.0, "end": 655.16, "text": " to give each multi-core core something to work with. So, it's oriented towards multi-core.", "tokens": [281, 976, 1184, 4825, 12, 12352, 4965, 746, 281, 589, 365, 13, 407, 11, 309, 311, 21841, 3030, 4825, 12, 12352, 13], "temperature": 0.0, "avg_logprob": -0.15815881010773894, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00024196627782657743}, {"id": 84, "seek": 65516, "start": 655.16, "end": 661.48, "text": " It's not for GPUs, or not at the moment, at least. So, the matrices which you have seen", "tokens": [467, 311, 406, 337, 18407, 82, 11, 420, 406, 412, 264, 1623, 11, 412, 1935, 13, 407, 11, 264, 32284, 597, 291, 362, 1612], "temperature": 0.0, "avg_logprob": -0.17341185151860955, "compression_ratio": 1.6227272727272728, "no_speech_prob": 5.329833220457658e-05}, {"id": 85, "seek": 65516, "start": 661.48, "end": 667.52, "text": " before, with this data format, the data structure looks a bit like this. The color is based", "tokens": [949, 11, 365, 341, 1412, 7877, 11, 264, 1412, 3877, 1542, 257, 857, 411, 341, 13, 440, 2017, 307, 2361], "temperature": 0.0, "avg_logprob": -0.17341185151860955, "compression_ratio": 1.6227272727272728, "no_speech_prob": 5.329833220457658e-05}, {"id": 86, "seek": 65516, "start": 667.52, "end": 675.76, "text": " on the population, on the amount of matrices are there. Then there is another core coding", "tokens": [322, 264, 4415, 11, 322, 264, 2372, 295, 32284, 366, 456, 13, 1396, 456, 307, 1071, 4965, 17720], "temperature": 0.0, "avg_logprob": -0.17341185151860955, "compression_ratio": 1.6227272727272728, "no_speech_prob": 5.329833220457658e-05}, {"id": 87, "seek": 65516, "start": 675.76, "end": 680.0799999999999, "text": " with other information. But this is just to tell you that the irregular aspect of those", "tokens": [365, 661, 1589, 13, 583, 341, 307, 445, 281, 980, 291, 300, 264, 29349, 4171, 295, 729], "temperature": 0.0, "avg_logprob": -0.17341185151860955, "compression_ratio": 1.6227272727272728, "no_speech_prob": 5.329833220457658e-05}, {"id": 88, "seek": 68008, "start": 680.08, "end": 693.1600000000001, "text": " matrices is reflected also here, to some extent. Yeah. So, the library itself wants to provide", "tokens": [32284, 307, 15502, 611, 510, 11, 281, 512, 8396, 13, 865, 13, 407, 11, 264, 6405, 2564, 2738, 281, 2893], "temperature": 0.0, "avg_logprob": -0.2039015669571726, "compression_ratio": 1.4583333333333333, "no_speech_prob": 3.241587910451926e-05}, {"id": 89, "seek": 68008, "start": 693.1600000000001, "end": 701.36, "text": " sparse blast. So, building blocks for iterative solvers. It's pretty compatible at the library.", "tokens": [637, 11668, 12035, 13, 407, 11, 2390, 8474, 337, 17138, 1166, 1404, 840, 13, 467, 311, 1238, 18218, 412, 264, 6405, 13], "temperature": 0.0, "avg_logprob": -0.2039015669571726, "compression_ratio": 1.4583333333333333, "no_speech_prob": 3.241587910451926e-05}, {"id": 90, "seek": 68008, "start": 701.36, "end": 709.12, "text": " It works with C++, Fortune, Octave, and Python. I say it's quite compatible. So, it uses,", "tokens": [467, 1985, 365, 383, 25472, 11, 38508, 11, 6788, 946, 11, 293, 15329, 13, 286, 584, 309, 311, 1596, 18218, 13, 407, 11, 309, 4960, 11], "temperature": 0.0, "avg_logprob": -0.2039015669571726, "compression_ratio": 1.4583333333333333, "no_speech_prob": 3.241587910451926e-05}, {"id": 91, "seek": 70912, "start": 709.12, "end": 714.24, "text": " let's say, established technologies. And it's quite compatible also in the sense with your", "tokens": [718, 311, 584, 11, 7545, 7943, 13, 400, 309, 311, 1596, 18218, 611, 294, 264, 2020, 365, 428], "temperature": 0.0, "avg_logprob": -0.21379728095476017, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5579725843272172e-05}, {"id": 92, "seek": 70912, "start": 714.24, "end": 718.6, "text": " software. It doesn't require you to use the only data structure which is custom is the", "tokens": [4722, 13, 467, 1177, 380, 3651, 291, 281, 764, 264, 787, 1412, 3877, 597, 307, 2375, 307, 264], "temperature": 0.0, "avg_logprob": -0.21379728095476017, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5579725843272172e-05}, {"id": 93, "seek": 70912, "start": 718.6, "end": 727.88, "text": " matrix. You don't need extra data structures for vectors. And the program I saw before", "tokens": [8141, 13, 509, 500, 380, 643, 2857, 1412, 9227, 337, 18875, 13, 400, 264, 1461, 286, 1866, 949], "temperature": 0.0, "avg_logprob": -0.21379728095476017, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5579725843272172e-05}, {"id": 94, "seek": 70912, "start": 727.88, "end": 734.76, "text": " written in the sparse blast, for using RSV, uses just one extra init and finalized function.", "tokens": [3720, 294, 264, 637, 11668, 12035, 11, 337, 1228, 25855, 53, 11, 4960, 445, 472, 2857, 3157, 293, 2572, 1602, 2445, 13], "temperature": 0.0, "avg_logprob": -0.21379728095476017, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5579725843272172e-05}, {"id": 95, "seek": 73476, "start": 734.76, "end": 740.72, "text": " So, I really respect that API. But, however, it's nice to write also the 15th standard.", "tokens": [407, 11, 286, 534, 3104, 300, 9362, 13, 583, 11, 4461, 11, 309, 311, 1481, 281, 2464, 611, 264, 2119, 392, 3832, 13], "temperature": 0.0, "avg_logprob": -0.284909527711194, "compression_ratio": 1.5263157894736843, "no_speech_prob": 7.271021604537964e-05}, {"id": 96, "seek": 73476, "start": 740.72, "end": 748.4399999999999, "text": " Or joking. This is not the 15th standard, but just the internal API. So, if you want,", "tokens": [1610, 17396, 13, 639, 307, 406, 264, 2119, 392, 3832, 11, 457, 445, 264, 6920, 9362, 13, 407, 11, 498, 291, 528, 11], "temperature": 0.0, "avg_logprob": -0.284909527711194, "compression_ratio": 1.5263157894736843, "no_speech_prob": 7.271021604537964e-05}, {"id": 97, "seek": 73476, "start": 748.4399999999999, "end": 753.36, "text": " perhaps you can exploit the internal API of Libre Sb, or not internal, but the native", "tokens": [4317, 291, 393, 25924, 264, 6920, 9362, 295, 15834, 265, 318, 65, 11, 420, 406, 6920, 11, 457, 264, 8470], "temperature": 0.0, "avg_logprob": -0.284909527711194, "compression_ratio": 1.5263157894736843, "no_speech_prob": 7.271021604537964e-05}, {"id": 98, "seek": 73476, "start": 753.36, "end": 762.64, "text": " one. Please tell me when I'm at 10 minutes. Yeah. Which is primarily in C. Then you have", "tokens": [472, 13, 2555, 980, 385, 562, 286, 478, 412, 1266, 2077, 13, 865, 13, 3013, 307, 10029, 294, 383, 13, 1396, 291, 362], "temperature": 0.0, "avg_logprob": -0.284909527711194, "compression_ratio": 1.5263157894736843, "no_speech_prob": 7.271021604537964e-05}, {"id": 99, "seek": 76264, "start": 762.64, "end": 773.64, "text": " wrappers with C++. And there's also the Fortune one. These are the native APIs. And what is", "tokens": [7843, 15226, 365, 383, 25472, 13, 400, 456, 311, 611, 264, 38508, 472, 13, 1981, 366, 264, 8470, 21445, 13, 400, 437, 307], "temperature": 0.0, "avg_logprob": -0.2092294833239387, "compression_ratio": 1.4378378378378378, "no_speech_prob": 0.00015145080396905541}, {"id": 100, "seek": 76264, "start": 773.64, "end": 782.76, "text": " specific about RSV is that the blocking is not so clear which blocking is best. Because,", "tokens": [2685, 466, 25855, 53, 307, 300, 264, 17776, 307, 406, 370, 1850, 597, 17776, 307, 1151, 13, 1436, 11], "temperature": 0.0, "avg_logprob": -0.2092294833239387, "compression_ratio": 1.4378378378378378, "no_speech_prob": 0.00015145080396905541}, {"id": 101, "seek": 76264, "start": 782.76, "end": 791.24, "text": " yeah, depending on how you block, you could have better or worse performance. And for", "tokens": [1338, 11, 5413, 322, 577, 291, 3461, 11, 291, 727, 362, 1101, 420, 5324, 3389, 13, 400, 337], "temperature": 0.0, "avg_logprob": -0.2092294833239387, "compression_ratio": 1.4378378378378378, "no_speech_prob": 0.00015145080396905541}, {"id": 102, "seek": 79124, "start": 791.24, "end": 797.5600000000001, "text": " this reason, there is an idea of using automated empirical optimization in this library. There", "tokens": [341, 1778, 11, 456, 307, 364, 1558, 295, 1228, 18473, 31886, 19618, 294, 341, 6405, 13, 821], "temperature": 0.0, "avg_logprob": -0.17791100471250473, "compression_ratio": 1.5917159763313609, "no_speech_prob": 9.688318095868453e-05}, {"id": 103, "seek": 79124, "start": 797.5600000000001, "end": 806.72, "text": " is a special call, a function which you call when you invest time to ask the library to", "tokens": [307, 257, 2121, 818, 11, 257, 2445, 597, 291, 818, 562, 291, 1963, 565, 281, 1029, 264, 6405, 281], "temperature": 0.0, "avg_logprob": -0.17791100471250473, "compression_ratio": 1.5917159763313609, "no_speech_prob": 9.688318095868453e-05}, {"id": 104, "seek": 79124, "start": 806.72, "end": 814.72, "text": " optimize a bit the data structure. So, you sacrifice a minute, perhaps, for optimizing", "tokens": [19719, 257, 857, 264, 1412, 3877, 13, 407, 11, 291, 11521, 257, 3456, 11, 4317, 11, 337, 40425], "temperature": 0.0, "avg_logprob": -0.17791100471250473, "compression_ratio": 1.5917159763313609, "no_speech_prob": 9.688318095868453e-05}, {"id": 105, "seek": 81472, "start": 814.72, "end": 821.44, "text": " the data structure a bit. And you do this in the hope that the many hours which we'll", "tokens": [264, 1412, 3877, 257, 857, 13, 400, 291, 360, 341, 294, 264, 1454, 300, 264, 867, 2496, 597, 321, 603], "temperature": 0.0, "avg_logprob": -0.17907909725023352, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.00017966559971682727}, {"id": 106, "seek": 81472, "start": 821.44, "end": 829.76, "text": " be using this matrix afterwards will be, will profit, will be decreased, thanks to the optimization.", "tokens": [312, 1228, 341, 8141, 10543, 486, 312, 11, 486, 7475, 11, 486, 312, 24436, 11, 3231, 281, 264, 19618, 13], "temperature": 0.0, "avg_logprob": -0.17907909725023352, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.00017966559971682727}, {"id": 107, "seek": 81472, "start": 829.76, "end": 834.72, "text": " Because, as I said, this is meant to be used for iterative methods. So, you will be running", "tokens": [1436, 11, 382, 286, 848, 11, 341, 307, 4140, 281, 312, 1143, 337, 17138, 1166, 7150, 13, 407, 11, 291, 486, 312, 2614], "temperature": 0.0, "avg_logprob": -0.17907909725023352, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.00017966559971682727}, {"id": 108, "seek": 81472, "start": 834.72, "end": 840.36, "text": " this for many hours. And, therefore, spending a few minutes in automated optimization, it's", "tokens": [341, 337, 867, 2496, 13, 400, 11, 4412, 11, 6434, 257, 1326, 2077, 294, 18473, 19618, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.17907909725023352, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.00017966559971682727}, {"id": 109, "seek": 84036, "start": 840.36, "end": 846.48, "text": " something that should pay off. No guarantee, but that's the idea and that is usually how", "tokens": [746, 300, 820, 1689, 766, 13, 883, 10815, 11, 457, 300, 311, 264, 1558, 293, 300, 307, 2673, 577], "temperature": 0.0, "avg_logprob": -0.21896196615816366, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.0004689143388532102}, {"id": 110, "seek": 84036, "start": 846.48, "end": 855.44, "text": " it goes. To give an idea, this C++ API is what you would expect. So, there is a class", "tokens": [309, 1709, 13, 1407, 976, 364, 1558, 11, 341, 383, 25472, 9362, 307, 437, 291, 576, 2066, 13, 407, 11, 456, 307, 257, 1508], "temperature": 0.0, "avg_logprob": -0.21896196615816366, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.0004689143388532102}, {"id": 111, "seek": 84036, "start": 855.44, "end": 861.64, "text": " templated on the type. So, there is type safety here. When you say, this is my library, sorry,", "tokens": [9100, 770, 322, 264, 2010, 13, 407, 11, 456, 307, 2010, 4514, 510, 13, 1133, 291, 584, 11, 341, 307, 452, 6405, 11, 2597, 11], "temperature": 0.0, "avg_logprob": -0.21896196615816366, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.0004689143388532102}, {"id": 112, "seek": 84036, "start": 861.64, "end": 868.12, "text": " this is my matrix. These are my non-zeros because this is what we are representing here.", "tokens": [341, 307, 452, 8141, 13, 1981, 366, 452, 2107, 12, 4527, 329, 570, 341, 307, 437, 321, 366, 13460, 510, 13], "temperature": 0.0, "avg_logprob": -0.21896196615816366, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.0004689143388532102}, {"id": 113, "seek": 86812, "start": 868.12, "end": 878.16, "text": " We, you have flags, C-style flags for options like symmetry or asking for discarding zeros", "tokens": [492, 11, 291, 362, 23265, 11, 383, 12, 15014, 23265, 337, 3956, 411, 25440, 420, 3365, 337, 31597, 278, 35193], "temperature": 0.0, "avg_logprob": -0.16870933108859593, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.00043182398076169193}, {"id": 114, "seek": 86812, "start": 878.16, "end": 883.08, "text": " rather than keeping the zeros because sometimes you want to keep structural zeros for modifying", "tokens": [2831, 813, 5145, 264, 35193, 570, 2171, 291, 528, 281, 1066, 15067, 35193, 337, 42626], "temperature": 0.0, "avg_logprob": -0.16870933108859593, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.00043182398076169193}, {"id": 115, "seek": 86812, "start": 883.08, "end": 887.5600000000001, "text": " them later, for instance. So, you have many such options here. And this is the way, this", "tokens": [552, 1780, 11, 337, 5197, 13, 407, 11, 291, 362, 867, 1270, 3956, 510, 13, 400, 341, 307, 264, 636, 11, 341], "temperature": 0.0, "avg_logprob": -0.16870933108859593, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.00043182398076169193}, {"id": 116, "seek": 86812, "start": 887.5600000000001, "end": 890.4, "text": " is why I'm showing this slide to tell you that there are many options which I'm not", "tokens": [307, 983, 286, 478, 4099, 341, 4137, 281, 980, 291, 300, 456, 366, 867, 3956, 597, 286, 478, 406], "temperature": 0.0, "avg_logprob": -0.16870933108859593, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.00043182398076169193}, {"id": 117, "seek": 86812, "start": 890.4, "end": 895.4, "text": " showing you here. Yeah. And the only data structure here is the RSB matrix, no other", "tokens": [4099, 291, 510, 13, 865, 13, 400, 264, 787, 1412, 3877, 510, 307, 264, 25855, 33, 8141, 11, 572, 661], "temperature": 0.0, "avg_logprob": -0.16870933108859593, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.00043182398076169193}, {"id": 118, "seek": 89540, "start": 895.4, "end": 902.88, "text": " custom stuff. And you can exploit, you can enjoy the spam interface of C++ 20 that doesn't", "tokens": [2375, 1507, 13, 400, 291, 393, 25924, 11, 291, 393, 2103, 264, 24028, 9226, 295, 383, 25472, 945, 300, 1177, 380], "temperature": 0.0, "avg_logprob": -0.17684794143891672, "compression_ratio": 1.435483870967742, "no_speech_prob": 4.199225804768503e-05}, {"id": 119, "seek": 89540, "start": 902.88, "end": 910.48, "text": " really force you to have any weird custom vector type apart from the standard C++ ones.", "tokens": [534, 3464, 291, 281, 362, 604, 3657, 2375, 8062, 2010, 4936, 490, 264, 3832, 383, 25472, 2306, 13], "temperature": 0.0, "avg_logprob": -0.17684794143891672, "compression_ratio": 1.435483870967742, "no_speech_prob": 4.199225804768503e-05}, {"id": 120, "seek": 89540, "start": 910.48, "end": 918.36, "text": " If you want to use, for instance, GNU Octave and enjoy the multi-core speedup from Libar", "tokens": [759, 291, 528, 281, 764, 11, 337, 5197, 11, 46411, 52, 6788, 946, 293, 2103, 264, 4825, 12, 12352, 3073, 1010, 490, 15834, 289], "temperature": 0.0, "avg_logprob": -0.17684794143891672, "compression_ratio": 1.435483870967742, "no_speech_prob": 4.199225804768503e-05}, {"id": 121, "seek": 91836, "start": 918.36, "end": 928.44, "text": " SB, you can use the sparse RSB plug-in which I wrote, which uses C++ Libar SB pretty efficiently.", "tokens": [26944, 11, 291, 393, 764, 264, 637, 11668, 25855, 33, 5452, 12, 259, 597, 286, 4114, 11, 597, 4960, 383, 25472, 15834, 289, 26944, 1238, 19621, 13], "temperature": 0.0, "avg_logprob": -0.2269014667820286, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.0002530048950575292}, {"id": 122, "seek": 91836, "start": 928.44, "end": 935.4, "text": " So apart from a few conversions, it should be, it should have almost native performance.", "tokens": [407, 4936, 490, 257, 1326, 42256, 11, 309, 820, 312, 11, 309, 820, 362, 1920, 8470, 3389, 13], "temperature": 0.0, "avg_logprob": -0.2269014667820286, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.0002530048950575292}, {"id": 123, "seek": 91836, "start": 935.4, "end": 947.04, "text": " Similarly for Python, the PyRSB plug-in for standalone, sorry, package has an interface", "tokens": [13157, 337, 15329, 11, 264, 9953, 49, 50, 33, 5452, 12, 259, 337, 37454, 11, 2597, 11, 7372, 575, 364, 9226], "temperature": 0.0, "avg_logprob": -0.2269014667820286, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.0002530048950575292}, {"id": 124, "seek": 94704, "start": 947.04, "end": 957.68, "text": " which is copied from CSR matrix. So you use it mostly the same way. But underneath, Libar", "tokens": [597, 307, 25365, 490, 9460, 49, 8141, 13, 407, 291, 764, 309, 5240, 264, 912, 636, 13, 583, 7223, 11, 15834, 289], "temperature": 0.0, "avg_logprob": -0.15717837685032895, "compression_ratio": 1.440217391304348, "no_speech_prob": 7.9717741755303e-05}, {"id": 125, "seek": 94704, "start": 957.68, "end": 966.48, "text": " SB runs. You don't see it. Or you see it if you ask it to use the auto-tuning routine.", "tokens": [26944, 6676, 13, 509, 500, 380, 536, 309, 13, 1610, 291, 536, 309, 498, 291, 1029, 309, 281, 764, 264, 8399, 12, 83, 37726, 9927, 13], "temperature": 0.0, "avg_logprob": -0.15717837685032895, "compression_ratio": 1.440217391304348, "no_speech_prob": 7.9717741755303e-05}, {"id": 126, "seek": 94704, "start": 966.48, "end": 973.04, "text": " Because as I said, in all of those language implementations, you can also use all of the", "tokens": [1436, 382, 286, 848, 11, 294, 439, 295, 729, 2856, 4445, 763, 11, 291, 393, 611, 764, 439, 295, 264], "temperature": 0.0, "avg_logprob": -0.15717837685032895, "compression_ratio": 1.440217391304348, "no_speech_prob": 7.9717741755303e-05}, {"id": 127, "seek": 97304, "start": 973.04, "end": 979.36, "text": " functionality of Libar SB which includes the auto-tuning also here in Octave. And I want", "tokens": [14980, 295, 15834, 289, 26944, 597, 5974, 264, 8399, 12, 83, 37726, 611, 510, 294, 6788, 946, 13, 400, 286, 528], "temperature": 0.0, "avg_logprob": -0.18757807787726907, "compression_ratio": 1.4756756756756757, "no_speech_prob": 6.896063860040158e-05}, {"id": 128, "seek": 97304, "start": 979.36, "end": 985.88, "text": " to stress this. GNU Octave doesn't have multi-threaded sparse operations. With Libar SB, you can", "tokens": [281, 4244, 341, 13, 46411, 52, 6788, 946, 1177, 380, 362, 4825, 12, 392, 2538, 292, 637, 11668, 7705, 13, 2022, 15834, 289, 26944, 11, 291, 393], "temperature": 0.0, "avg_logprob": -0.18757807787726907, "compression_ratio": 1.4756756756756757, "no_speech_prob": 6.896063860040158e-05}, {"id": 129, "seek": 97304, "start": 985.88, "end": 993.4, "text": " have them. Same for SciPy sparse. As far as I know, it's not multi-threaded. With Libar", "tokens": [362, 552, 13, 10635, 337, 16942, 47, 88, 637, 11668, 13, 1018, 1400, 382, 286, 458, 11, 309, 311, 406, 4825, 12, 392, 2538, 292, 13, 2022, 15834, 289], "temperature": 0.0, "avg_logprob": -0.18757807787726907, "compression_ratio": 1.4756756756756757, "no_speech_prob": 6.896063860040158e-05}, {"id": 130, "seek": 99340, "start": 993.4, "end": 1003.92, "text": " SB, you get it. Libar SB is by default licensed as lesser GPL3. Which means you can, if you", "tokens": [26944, 11, 291, 483, 309, 13, 15834, 289, 26944, 307, 538, 7576, 25225, 382, 22043, 460, 21593, 18, 13, 3013, 1355, 291, 393, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.20242952982584636, "compression_ratio": 1.4385026737967914, "no_speech_prob": 7.858047320041806e-05}, {"id": 131, "seek": 99340, "start": 1003.92, "end": 1012.28, "text": " don't, as long as you don't modify it, you can distribute it with your proprietary code.", "tokens": [500, 380, 11, 382, 938, 382, 291, 500, 380, 16927, 309, 11, 291, 393, 20594, 309, 365, 428, 38992, 3089, 13], "temperature": 0.0, "avg_logprob": -0.20242952982584636, "compression_ratio": 1.4385026737967914, "no_speech_prob": 7.858047320041806e-05}, {"id": 132, "seek": 99340, "start": 1012.28, "end": 1019.52, "text": " If you modify it, well, it's more complicated. You have to release the modified version.", "tokens": [759, 291, 16927, 309, 11, 731, 11, 309, 311, 544, 6179, 13, 509, 362, 281, 4374, 264, 15873, 3037, 13], "temperature": 0.0, "avg_logprob": -0.20242952982584636, "compression_ratio": 1.4385026737967914, "no_speech_prob": 7.858047320041806e-05}, {"id": 133, "seek": 101952, "start": 1019.52, "end": 1026.6, "text": " The Libar SB library, if you want to learn to use it, it makes absolutely sense to use", "tokens": [440, 15834, 289, 26944, 6405, 11, 498, 291, 528, 281, 1466, 281, 764, 309, 11, 309, 1669, 3122, 2020, 281, 764], "temperature": 0.0, "avg_logprob": -0.21058273315429688, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.00020830034918617457}, {"id": 134, "seek": 101952, "start": 1026.6, "end": 1035.72, "text": " a packaged version from Debian Ubuntu or most of Linux distributions. Or if you use Windows", "tokens": [257, 38162, 3037, 490, 1346, 20196, 30230, 45605, 420, 881, 295, 18734, 37870, 13, 1610, 498, 291, 764, 8591], "temperature": 0.0, "avg_logprob": -0.21058273315429688, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.00020830034918617457}, {"id": 135, "seek": 101952, "start": 1035.72, "end": 1043.32, "text": " and you can use Siegwin. Or once you want the performance, I mean, you can just compile", "tokens": [293, 291, 393, 764, 3559, 70, 9136, 13, 1610, 1564, 291, 528, 264, 3389, 11, 286, 914, 11, 291, 393, 445, 31413], "temperature": 0.0, "avg_logprob": -0.21058273315429688, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.00020830034918617457}, {"id": 136, "seek": 101952, "start": 1043.32, "end": 1048.8, "text": " it by yourself because it's quite trivial. Or enjoy what our colleagues here from Spark", "tokens": [309, 538, 1803, 570, 309, 311, 1596, 26703, 13, 1610, 2103, 437, 527, 7734, 510, 490, 23424], "temperature": 0.0, "avg_logprob": -0.21058273315429688, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.00020830034918617457}, {"id": 137, "seek": 104880, "start": 1048.8, "end": 1056.28, "text": " and EasyBuild have done and use the packaged version from those distributions. And some", "tokens": [293, 16002, 28110, 793, 362, 1096, 293, 764, 264, 38162, 3037, 490, 729, 37870, 13, 400, 512], "temperature": 0.0, "avg_logprob": -0.16042131452418085, "compression_ratio": 1.5, "no_speech_prob": 0.0004656030214391649}, {"id": 138, "seek": 104880, "start": 1056.28, "end": 1065.2, "text": " people have written wrappers for Rust and Julia. I don't know these languages, so I", "tokens": [561, 362, 3720, 7843, 15226, 337, 34952, 293, 18551, 13, 286, 500, 380, 458, 613, 8650, 11, 370, 286], "temperature": 0.0, "avg_logprob": -0.16042131452418085, "compression_ratio": 1.5, "no_speech_prob": 0.0004656030214391649}, {"id": 139, "seek": 104880, "start": 1065.2, "end": 1073.56, "text": " didn't use them. I think the Rust one is like the entire API. I think Julia is more in Julia", "tokens": [994, 380, 764, 552, 13, 286, 519, 264, 34952, 472, 307, 411, 264, 2302, 9362, 13, 286, 519, 18551, 307, 544, 294, 18551], "temperature": 0.0, "avg_logprob": -0.16042131452418085, "compression_ratio": 1.5, "no_speech_prob": 0.0004656030214391649}, {"id": 140, "seek": 107356, "start": 1073.56, "end": 1083.2, "text": " style, so it's just what is, the core functionality is there, I think. Yeah, that was everything.", "tokens": [3758, 11, 370, 309, 311, 445, 437, 307, 11, 264, 4965, 14980, 307, 456, 11, 286, 519, 13, 865, 11, 300, 390, 1203, 13], "temperature": 0.0, "avg_logprob": -0.3002410616193499, "compression_ratio": 1.1022727272727273, "no_speech_prob": 0.0013227735180407763}, {"id": 141, "seek": 108320, "start": 1083.2, "end": 1104.68, "text": " I don't know how much time did I take. Oh, 50 minutes. So, thanks.", "tokens": [286, 500, 380, 458, 577, 709, 565, 630, 286, 747, 13, 876, 11, 2625, 2077, 13, 407, 11, 3231, 13], "temperature": 0.0, "avg_logprob": -0.35983705520629883, "compression_ratio": 0.9166666666666666, "no_speech_prob": 0.008202836848795414}], "language": "en"}