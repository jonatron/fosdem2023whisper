{"text": " Okay, thank you. We have two traditions here in the Go Dev Room. That is that we start with a state of Go, and then it's around lunchtime. We always have the next state, which is the state of Delph. So let's all get into Delph. Let's go debugging. Let's try this again. Hello, everybody. My name is Derek Parker. I am the author of Delph, and I continue to maintain the project along with my lead co-maintainer, Alessandro, who is also in the crowd today. And as mentioned, it's been kind of a tradition here at Bosdom to piggyback on the state of Go and talk about the state of Delph. So this talk will be kind of a two-parter. I'll start with the state of Delph, and then I'll go into the main talk, which is debugging Go programs with EBPF. Now, if you're unfamiliar with what EBPF is as a technology, fret not, I will go in and kind of explain it in more detail throughout the course of the talk as we kind of get into the real meat of everything. So just to introduce myself a little bit more, again, my name is Derek Parker. I'm a senior software engineer at Red Hat. If you would like to follow me, I am Derek the Daring on Twitter. And at Red Hat, I work on Delph and Go itself. So the first thing that I want to start and talk about is the state of Delph. So what I'll go through is essentially what's changed since the last Bosdom, and actually since the last in-person Bosdom. So I was actually here in 2020 presenting a different talk before the world ended. And I'm happy to be here again in-person with everybody and being able to kind of talk and catch up and present these things. So thanks everybody for coming and for attending this talk. I really appreciate it. So one of the big milestones that I kind of want to call out is that Delph turns nine this year. So to celebrate that on the count of three, everybody in the room, we're going to sing happy birthday. One, two, I'm just kidding. Maybe next year for the 10th anniversary. I'll hold that off for a little bit. But the Delph project was started in 2014. And yeah, it turns nine, still going strong. And I appreciate everybody who uses it, contributes to it. It's just really fantastic to see. So I'll go into some statistics a little bit about what's happened in the last couple of years. So since the last in-person Bosdom, we've done 18 different releases. Now, the way we do releases of Delph is somewhat scheduled, somewhat ad hoc. So we always produce a new release when the first release candidate of the new Go version comes out. So anytime a new Go version comes out, we ensure that the day that it's released, you can debug it. So once you compile your code, do everything, you have a debugger that's going to work with that version. And then aside from that, we have kind of minor releases that come out throughout the year. And in between the releases to fix bugs, add new features, things like that. So within that time frame, we've added support for numerous different Go versions. So 114 all the way through 120. And as 120 was just released the other day, we've supported it since the first RC. So you always have a debugger to kind of go through your code even before the official release actually comes out. During that time, we've also added four new operating system and architecture combinations. So with Delph, we strive to enable you to debug on any operating system and architecture that Go itself supports. We're getting closer and closer to that goal with each passing release. So I'm proud to say within the last few years, we added support for four new platforms. And there's a few more already in the works and we'll be releasing later this year. So I want to call out a few major new features that have been developed. The first is we've integrated a DAP server into Delph, which is probably not something that's super relevant to everybody here unless you're like the author of like an editor or something like that. It's really for editor integration, but from a user's perspective, it really improves the usability of Delph within editors such as VS Code and things like that. We've added support for Apple Silicon and that happened really quickly once we were able to kind of get our hands on the hardware and everything like that. We added the ability to generate core dumps from running processes. So while you're in a debug session, you can ad hoc, generate a core dump, save that away and use that and debug it later. We've added support for hardware watchpoints, which I think is a really, really cool feature. And kind of difficult to do with Go due to some kind of internal things of how Go kind of looks at the stack and changes stack and stuff like changes go routine stacks as the stack grows and things like that, but we were able to implement them and get them working. So if you're unaware of what hardware watchpoints are, it's a really cool feature where you can say like, I want to watch this particular variable or this particular address and memory and I want to know, I want the debugger to stop any time that value is read or changed. So you're basically just saying like telling the debugger what you want to do and letting it do the heavy lifting for you. Really cool feature. And as was just shown in the previous talk, we've improved some of the filtering and grouping for Go routine output. So you can filter by label, you can filter by all different kinds of things. So in like massively concurrent and parallel programs where you might have tons and tons of different Go routines, we've improved a lot of the introspection on that and being able to kind of filter out and get the information that you really need. We've also added an experimental EBPF based tracing back in. So that's what I'm going to be talking about today. And we also added support for debug info find. So this is really cool for a lot of operating systems where maybe you're debugging a package that you installed via your package manager and the like the door, the debug information is not included with the binary. Maybe it's in a different package or something like that. We've integrated with debug info find to be able to automatically download those debug packages for you so that you can have a fruitful and successful debugging session. And there's also been a lot more. If you want a look at all of the details, go ahead and check out the change log in the repo. It'll detail all of the changes that we've made. Next thing I want to talk about is a few little upcoming features that I want to tease. So one of the biggest ones is we're working on support for two new architectures. So PowerPC64LE and S390X. My colleague Alejandro is working on the PowerPC64LE port and he's in the crowd as well. So thank you for your work on that. We're looking at some more improvements to the EBPF tracing back end. I'll go into some more detail on that as well during this talk. We're also working on the ability to debug multiple processes simultaneously. My co-maintenor Alejandro is working on that and we're hoping to land that pretty soon. So that would be if your process forks or anything like that creates new child processes, you can debug all of them within a single session. Another thing that we want to work on this year is improved function call support across architectures. So that was a big feature that landed in Delve as well, the ability to call a function while you're debugging your program. It's very architecture specific. So one of the things that we want to do throughout this year is improve support for that across different architectures. There's tons more. We're always working on new things and we also always try to gather community feedback and user feedback and stuff like that. So since I'm here and other maintainers of Delve are here, if you want to come and tell us something that you would like us to implement or something that you would like to focus on, feel free to come chat with us. So now with that said and done, I want to move on to the real portion of this talk which is debugging and tracing go programs with EBPF. Now it's really cool that this talk comes after the talk right before because I think the tracing feature in Delve is somewhat underutilized and I think it's really good for debugging concurrent programs and seeing the interactions between go routines as your program is actually running. So if you're unfamiliar with what tracing is, I'll show a little demo but essentially what we're talking about here is instead of going into a full on debug session, what you're really doing is spying on your program. So if you're familiar with STrace, it's the same concept except for the functions that you're writing as opposed to the interactions with the kernel, like the system calls and things like that. So you can kind of spy and see what functions are being executed, what are their inputs, what are the outputs, what go routines are executing that function, so on and so forth. So to show a little demo of it real quick, let me increase my screen size a little bit. It may still be hard for folks in the back to see but hopefully that's good enough. So what I've done here is instead of typing everything directly on the console, I've created a little make file just so that you can see kind of the commands up there and they don't disappear as I run them. But the first thing that we're going to do is we're just going to run a simple trace. So to do this, we use the trace sub-command of delve and what you provide to it as an argument is a regular expression and what delve will do internally is set a trace point on any function that matches that regular expression. So you can do something like main.star to trace anything in the main package, extrapolate that out to any other package and it's a really cool feature. So just to kind of show how it works, we can go here and say make trace and we see the output there. So to explain the output a little bit, you have like the single line or the single arrow is the call, the double arrow is the return. You can see there it labels what go routine is running and calling that function. You can see the arguments to that function and then you can also see the return value. So again, really cool and useful for like if you have a bunch of different go routines, you can kind of see the interactions of them and see what go routines are doing at any given time. Another option that you can do is you can say if you pass the stack flag and give it an argument, you can get a stack trace anytime one of the trace points are hit. So if we say trace with stack, you see we get kind of a similar output but we get a stack trace as well. So you can kind of see a little bit more detailed information as your program is being traced. So the real meat of this talk is how we improve the tracing back end to make it more efficient because what you, especially when you're doing something like tracing and things like that, the lower overhead the better. We don't want to make your program run significantly slower because that's just going to frustrate you and it's going to take longer to get to root cause analysis which is what you're really trying to do if you're using a debugger in the first place. So we'll talk about quickly how things are currently implemented and then how we can improve upon that using EBPF. So right now Delve uses, or traditionally Delve uses ptrace syscall to implement the tracing back end. It's how ptrace is useful for, like it's used by pretty much every debugger, every kind of tool like this. Delve is no exception. And if you look at the man page it'll explain a little bit more about what it is but it essentially allows you to control the execution of another process and kind of examine the state of it, memory and things like that. So the problem is ptrace is slow and it can be very slow. So I ran some tests kind of a while ago when I was implementing the first iteration of this EBPF back end and I measured like a simple program execution that executed in 23.7 microseconds. And then the overhead with the ptrace based tracing, the traditional based tracing, it went up to 2.3 seconds. So that's several orders of magnitude of overhead, which is definitely not what you want. But why is ptrace so slow? So part of the reason is syscall overhead. We have to, ptrace is a syscall so whenever you invoke a syscall, you trap into the kernel, you switch context. So that has its own kind of overhead which can be pretty significant. And as I mentioned, the user space kernel context switching, the overhead of that can be really expensive. And it's amplified by the fact that ptrace is in a sense very directed. So when we're tracing these functions, we often have to make multiple ptrace calls per function entry and function exit. So if you think about it, we need to read the registers, we need to read all of the different function arguments that are there. There's a bunch of different things that we need to do. So it kind of balloons up really, really quickly where we get into this situation where we're doing a ton of these user space kernel context switching per every time you hit one of these trace points. And on top of that, all of these operations have to happen twice per function, right? So the entry and the exit. So it's a lot of overhead, a lot of context switching, essentially a lot of unnecessary work and a lot of work that just slows down your program and adds a lot of overhead. So the way that we can improve upon this and work around this is by using EBPF. So EBPF is a lot more effective and efficient, a lot quicker to do this kind of work. So with the same task, again, as I mentioned before, the original program, 23 microseconds with ptrace 2.3 actual seconds and with the EBPF based tracing, we have like 683 microseconds, which is still measurable overhead but significantly less than the traditional method of doing it. So I've been talking about this technology a lot, EBPF, EBPF, EBPF, right? But what actually is it? So EBPF is a technology that enables the kernel to run sandbox programs directly. So EBPF programs are written primarily in like a limited C. I'll get into some of the limitations later. But it gets compiled to a bytecode, loaded into the kernel where it's executed and jaded as it's ran. And it has a lot of use cases, observability, networking, debugging and a lot more. So you'll hear a lot about EBPF. I'm sure a lot of folks in this room have already heard of it in some shape or another. Typically, it started as a technology for networking and kind of ballooned from there. So originally it was like BPF, which is Berkeley packet filtering, and it came into extended Berkeley packet filtering. And now the acronym doesn't really mean anything anymore. EBPF is just EBPF because it's way more than just what it originally was. And the cool thing is these programs that are loaded in the kernel, they can be triggered by certain events. And I'll talk about how we can trigger those events ourselves, but they run in response to something happening. So why is EBPF so fast in comparison to the way that we're traditionally doing things? The first thing is these EBPF programs run in the kernel. So there's a lot less context switching overhead. We're already in the kernel, so we don't have to keep asking the kernel for more and more and more information to get what we actually want. Relative to traditional sys call and a bunch of sys calls, the context switching is a lot cheaper. You get small targeted programs that, again, execute really quickly and can do everything that you need or want to do in essentially one shot. And a single program can execute many tasks that we would traditionally use multiple ptrace calls for. So you have access to the current registers, you can read memory, and a lot of other things like that. Now, when I was looking to implement this backend, I had a few requirements that I wanted to make sure can be satisfied with this EBPF-based approach. So the first one was the ability to trace arbitrary functions. As a user, you just want to say, I want to trace everything in the main package or I want to trace this specific function or whatever. This new backend had to be able to satisfy that requirement as well. We had to be able to retrieve the GoRoutine ID from within the EBPF program. We had to be able to read function input arguments and we had to be able to read function return arguments. Now, let's talk a little bit about tracing arbitrary functions. So, just as a little bit of background, how DELV has been used is EBPF from the Go side of things is we use the Cilium EBPF package. There's a few other Go-based EBPF packages out there. Originally, I implemented using one from Aqua Security but ended up switching to Cilium for a few various different reasons. But the first thing that we need to do when we're tracing these arbitrary functions is we need to first load the EBPF program into the kernel so that we can start triggering it with some of these events. Once we've loaded the EBPF program, we attach U-probes to each symbol. This slide is actually a little bit outdated because we don't actually use U-rep probes. U-probes can be attached arbitrarily to different addresses and things like that within the binary. U-rep probes are typically used to hook into the return of a function, which seems like something that would be super, super useful. In theory, it is, but with Go, it doesn't work very well because of how Go manages Go-routine stacks. When Go has to inspect the stack, it reads up the stack to unwind it a little bit, and then we can if it sees anything that doesn't look right, it'll panic. U-rep probes work by overwriting the return address of the function that we're trying to probe. Go notices that during its runtime work and freaks out. We just use U-probes. Again, we want to do as much in the kernel as possible to limit overhead. We have to communicate function argument and return values to the EBPF program and get those values back from the EBPF program. First, we load it. First thing we have to do is write the EBPF program. Second thing, compile the program and generate some helpers. This is what the Sillian package helps us with. Then we have to load the programs into the kernel. These are actually links. I'll publish these slides. You can follow along at home, but I'll show a little bit of the code here. This is an example of the EBPF program that we use, written in C, basically. We have access to a bunch of different EBPF-based data structures, like maps, ring buffers. These are just different ways to be able to communicate with the EBPF program running in the kernel and the Go program that's running in user space. I won't go through all of this exhaustively for time, but again, if you want to look at it yourself, go ahead and follow the link. The second thing that we have to do is go ahead and actually compile this EBPF program and make it usable from Go. The Sillian EBPF package has a really nice helper that you can just use with Go Generate to be able to compile the object file that is your EBPF program. It generates a bunch of helpers for you that you can call to be able to load it and interact with that EBPF program. Then finally, we have to load the EBPF program into the kernel. Again, the Sillian EBPF library has a ton of helpers to be able to facilitate that. We open up the executable that represents the process that we're debugging. We call this helper that the package generated for us. Then we initialize some of the things that we need to do, like the ring buffer and the map data structure that we use to pass values back and forth. The next thing we have to do is attach our U probes. First, we find an offset to attach to, we attach the probe to that offset, and then we go from there. We have a little helper here to take an address within the program to an offset. The offset is just like an offset within the binary itself as it's loaded into memory. Then from there, we attach our probe. Then from there, we attach our probe. It's as simple as the executable that we opened earlier. We have that attached to this EBPF context here. We just call this U probe method and pass it the offset and the PID. The nice thing about this is you pass along the PID so that this EBPF program is constrained to just the process that you're trying to debug, because these programs that you load in are actually global, so they're not really by themselves attached to any specific process. Then from there, we need to actually communicate with this program. We need to store function parameter information, and then we need to communicate that information with the program. I won't go too much into the code in this for the sake of time, but essentially we need to tell the EBPF program all of the function argument information, the return value information, where they're located, are they on the stack, are they in registers, and let it know where to find it so that it can read all of this information and send it back to the user space program. When we want to get the data back, we use a ring buffer to again communicate between user space and our program running in kernel space, and essentially it's just a stream of all of the information coming back, so all of the information that's being read and picked up by the EBPF program. That's ultimately what gets displayed to you as we run the trace command. I'll go through another quick demo of actually using the EBPF backend, so all you have to do to enable it for now is just add dash dash EBPF to the trace command, so if I run our make command here, nobody looking at my password. We see that the trace happens, and from here you can't really tell that it's significantly faster, but the output is a little bit different. As I mentioned, this is still kind of like an experimental work in progress backend, so some of the output is a little bit different, and it doesn't have exact parity with the traditional more established tracing backend, but you can see it works. You see the arguments, the return values, and everything like that, and this is all happening with significantly less overhead. So a few downsides of the EBPF approach. The programs are written in a constrained version of C, so you're not writing go. You end up having to fight the verifier a lot. If you don't know what that means, that's great for you. Congratulations. There's a lot of constraints on stack sizes and stuff like that within EBPF programs, which can be kind of gnarly to deal with. It's different to write some control flow, like loops and stuff like that, and as I mentioned, UREP probes do not play well with go programs at all, do not use them, do not try. And that's it. Thank you very much. Thank you. Unfortunately, we do not have time for questions, but if you see him in the hallway track, you can always ask him any questions, improvements, bug fixes, et cetera. If you leave, it's better to do so on this side. You may pause the stage, and there is also a swag table diagram.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.200000000000001, "text": " Okay, thank you. We have two traditions here in the Go Dev Room. That is that we start", "tokens": [50364, 1033, 11, 1309, 291, 13, 492, 362, 732, 15643, 510, 294, 264, 1037, 9096, 19190, 13, 663, 307, 300, 321, 722, 50974], "temperature": 0.0, "avg_logprob": -0.247045013639662, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.4506201148033142}, {"id": 1, "seek": 0, "start": 12.200000000000001, "end": 16.04, "text": " with a state of Go, and then it's around lunchtime. We always have the next state, which is the", "tokens": [50974, 365, 257, 1785, 295, 1037, 11, 293, 550, 309, 311, 926, 6349, 3766, 13, 492, 1009, 362, 264, 958, 1785, 11, 597, 307, 264, 51166], "temperature": 0.0, "avg_logprob": -0.247045013639662, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.4506201148033142}, {"id": 2, "seek": 0, "start": 16.04, "end": 29.92, "text": " state of Delph. So let's all get into Delph. Let's go debugging.", "tokens": [51166, 1785, 295, 5831, 950, 13, 407, 718, 311, 439, 483, 666, 5831, 950, 13, 961, 311, 352, 45592, 13, 51860], "temperature": 0.0, "avg_logprob": -0.247045013639662, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.4506201148033142}, {"id": 3, "seek": 2992, "start": 30.840000000000003, "end": 42.760000000000005, "text": " Let's try this again. Hello, everybody. My name is Derek Parker. I am the author of", "tokens": [50410, 961, 311, 853, 341, 797, 13, 2425, 11, 2201, 13, 1222, 1315, 307, 22887, 20155, 13, 286, 669, 264, 3793, 295, 51006], "temperature": 0.0, "avg_logprob": -0.2574463881455459, "compression_ratio": 1.3989637305699483, "no_speech_prob": 0.06408606469631195}, {"id": 4, "seek": 2992, "start": 42.760000000000005, "end": 49.8, "text": " Delph, and I continue to maintain the project along with my lead co-maintainer, Alessandro,", "tokens": [51006, 5831, 950, 11, 293, 286, 2354, 281, 6909, 264, 1716, 2051, 365, 452, 1477, 598, 12, 76, 5114, 491, 260, 11, 967, 442, 29173, 11, 51358], "temperature": 0.0, "avg_logprob": -0.2574463881455459, "compression_ratio": 1.3989637305699483, "no_speech_prob": 0.06408606469631195}, {"id": 5, "seek": 2992, "start": 49.8, "end": 58.72, "text": " who is also in the crowd today. And as mentioned, it's been kind of a tradition here at Bosdom", "tokens": [51358, 567, 307, 611, 294, 264, 6919, 965, 13, 400, 382, 2835, 11, 309, 311, 668, 733, 295, 257, 6994, 510, 412, 22264, 4121, 51804], "temperature": 0.0, "avg_logprob": -0.2574463881455459, "compression_ratio": 1.3989637305699483, "no_speech_prob": 0.06408606469631195}, {"id": 6, "seek": 5872, "start": 58.839999999999996, "end": 64.64, "text": " to piggyback on the state of Go and talk about the state of Delph. So this talk will", "tokens": [50370, 281, 39349, 3207, 322, 264, 1785, 295, 1037, 293, 751, 466, 264, 1785, 295, 5831, 950, 13, 407, 341, 751, 486, 50660], "temperature": 0.0, "avg_logprob": -0.1278966771494044, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.004000829998403788}, {"id": 7, "seek": 5872, "start": 64.64, "end": 69.56, "text": " be kind of a two-parter. I'll start with the state of Delph, and then I'll go into the", "tokens": [50660, 312, 733, 295, 257, 732, 12, 2181, 391, 13, 286, 603, 722, 365, 264, 1785, 295, 5831, 950, 11, 293, 550, 286, 603, 352, 666, 264, 50906], "temperature": 0.0, "avg_logprob": -0.1278966771494044, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.004000829998403788}, {"id": 8, "seek": 5872, "start": 69.56, "end": 75.96000000000001, "text": " main talk, which is debugging Go programs with EBPF. Now, if you're unfamiliar with what", "tokens": [50906, 2135, 751, 11, 597, 307, 45592, 1037, 4268, 365, 50148, 47, 37, 13, 823, 11, 498, 291, 434, 29415, 365, 437, 51226], "temperature": 0.0, "avg_logprob": -0.1278966771494044, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.004000829998403788}, {"id": 9, "seek": 5872, "start": 75.96000000000001, "end": 83.36, "text": " EBPF is as a technology, fret not, I will go in and kind of explain it in more detail", "tokens": [51226, 50148, 47, 37, 307, 382, 257, 2899, 11, 24189, 406, 11, 286, 486, 352, 294, 293, 733, 295, 2903, 309, 294, 544, 2607, 51596], "temperature": 0.0, "avg_logprob": -0.1278966771494044, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.004000829998403788}, {"id": 10, "seek": 8336, "start": 83.84, "end": 90.92, "text": " throughout the course of the talk as we kind of get into the real meat of everything. So", "tokens": [50388, 3710, 264, 1164, 295, 264, 751, 382, 321, 733, 295, 483, 666, 264, 957, 4615, 295, 1203, 13, 407, 50742], "temperature": 0.0, "avg_logprob": -0.1469592236457987, "compression_ratio": 1.5194805194805194, "no_speech_prob": 0.014947466552257538}, {"id": 11, "seek": 8336, "start": 90.92, "end": 95.16, "text": " just to introduce myself a little bit more, again, my name is Derek Parker. I'm a senior", "tokens": [50742, 445, 281, 5366, 2059, 257, 707, 857, 544, 11, 797, 11, 452, 1315, 307, 22887, 20155, 13, 286, 478, 257, 7965, 50954], "temperature": 0.0, "avg_logprob": -0.1469592236457987, "compression_ratio": 1.5194805194805194, "no_speech_prob": 0.014947466552257538}, {"id": 12, "seek": 8336, "start": 95.16, "end": 100.32, "text": " software engineer at Red Hat. If you would like to follow me, I am Derek the Daring on", "tokens": [50954, 4722, 11403, 412, 4477, 15867, 13, 759, 291, 576, 411, 281, 1524, 385, 11, 286, 669, 22887, 264, 413, 1921, 322, 51212], "temperature": 0.0, "avg_logprob": -0.1469592236457987, "compression_ratio": 1.5194805194805194, "no_speech_prob": 0.014947466552257538}, {"id": 13, "seek": 8336, "start": 100.32, "end": 111.0, "text": " Twitter. And at Red Hat, I work on Delph and Go itself. So the first thing that I want", "tokens": [51212, 5794, 13, 400, 412, 4477, 15867, 11, 286, 589, 322, 5831, 950, 293, 1037, 2564, 13, 407, 264, 700, 551, 300, 286, 528, 51746], "temperature": 0.0, "avg_logprob": -0.1469592236457987, "compression_ratio": 1.5194805194805194, "no_speech_prob": 0.014947466552257538}, {"id": 14, "seek": 11100, "start": 111.04, "end": 118.72, "text": " to start and talk about is the state of Delph. So what I'll go through is essentially what's", "tokens": [50366, 281, 722, 293, 751, 466, 307, 264, 1785, 295, 5831, 950, 13, 407, 437, 286, 603, 352, 807, 307, 4476, 437, 311, 50750], "temperature": 0.0, "avg_logprob": -0.1345318354917376, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.01824229396879673}, {"id": 15, "seek": 11100, "start": 118.72, "end": 125.12, "text": " changed since the last Bosdom, and actually since the last in-person Bosdom. So I was", "tokens": [50750, 3105, 1670, 264, 1036, 22264, 4121, 11, 293, 767, 1670, 264, 1036, 294, 12, 10813, 22264, 4121, 13, 407, 286, 390, 51070], "temperature": 0.0, "avg_logprob": -0.1345318354917376, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.01824229396879673}, {"id": 16, "seek": 11100, "start": 125.12, "end": 131.84, "text": " actually here in 2020 presenting a different talk before the world ended. And I'm happy", "tokens": [51070, 767, 510, 294, 4808, 15578, 257, 819, 751, 949, 264, 1002, 4590, 13, 400, 286, 478, 2055, 51406], "temperature": 0.0, "avg_logprob": -0.1345318354917376, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.01824229396879673}, {"id": 17, "seek": 11100, "start": 131.84, "end": 137.32, "text": " to be here again in-person with everybody and being able to kind of talk and catch up", "tokens": [51406, 281, 312, 510, 797, 294, 12, 10813, 365, 2201, 293, 885, 1075, 281, 733, 295, 751, 293, 3745, 493, 51680], "temperature": 0.0, "avg_logprob": -0.1345318354917376, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.01824229396879673}, {"id": 18, "seek": 13732, "start": 137.4, "end": 141.84, "text": " and present these things. So thanks everybody for coming and for attending this talk. I", "tokens": [50368, 293, 1974, 613, 721, 13, 407, 3231, 2201, 337, 1348, 293, 337, 15862, 341, 751, 13, 286, 50590], "temperature": 0.0, "avg_logprob": -0.1437895953000247, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.0055474815890192986}, {"id": 19, "seek": 13732, "start": 141.84, "end": 154.28, "text": " really appreciate it. So one of the big milestones that I kind of want to call out is that Delph", "tokens": [50590, 534, 4449, 309, 13, 407, 472, 295, 264, 955, 42038, 300, 286, 733, 295, 528, 281, 818, 484, 307, 300, 5831, 950, 51212], "temperature": 0.0, "avg_logprob": -0.1437895953000247, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.0055474815890192986}, {"id": 20, "seek": 13732, "start": 154.28, "end": 160.0, "text": " turns nine this year. So to celebrate that on the count of three, everybody in the room,", "tokens": [51212, 4523, 4949, 341, 1064, 13, 407, 281, 8098, 300, 322, 264, 1207, 295, 1045, 11, 2201, 294, 264, 1808, 11, 51498], "temperature": 0.0, "avg_logprob": -0.1437895953000247, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.0055474815890192986}, {"id": 21, "seek": 13732, "start": 160.0, "end": 165.88, "text": " we're going to sing happy birthday. One, two, I'm just kidding. Maybe next year for the", "tokens": [51498, 321, 434, 516, 281, 1522, 2055, 6154, 13, 1485, 11, 732, 11, 286, 478, 445, 9287, 13, 2704, 958, 1064, 337, 264, 51792], "temperature": 0.0, "avg_logprob": -0.1437895953000247, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.0055474815890192986}, {"id": 22, "seek": 16588, "start": 165.88, "end": 171.0, "text": " 10th anniversary. I'll hold that off for a little bit. But the Delph project was started", "tokens": [50364, 1266, 392, 12962, 13, 286, 603, 1797, 300, 766, 337, 257, 707, 857, 13, 583, 264, 5831, 950, 1716, 390, 1409, 50620], "temperature": 0.0, "avg_logprob": -0.17833434360128053, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.0016996964113786817}, {"id": 23, "seek": 16588, "start": 171.0, "end": 180.72, "text": " in 2014. And yeah, it turns nine, still going strong. And I appreciate everybody who uses", "tokens": [50620, 294, 8227, 13, 400, 1338, 11, 309, 4523, 4949, 11, 920, 516, 2068, 13, 400, 286, 4449, 2201, 567, 4960, 51106], "temperature": 0.0, "avg_logprob": -0.17833434360128053, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.0016996964113786817}, {"id": 24, "seek": 16588, "start": 180.72, "end": 190.12, "text": " it, contributes to it. It's just really fantastic to see. So I'll go into some statistics a", "tokens": [51106, 309, 11, 32035, 281, 309, 13, 467, 311, 445, 534, 5456, 281, 536, 13, 407, 286, 603, 352, 666, 512, 12523, 257, 51576], "temperature": 0.0, "avg_logprob": -0.17833434360128053, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.0016996964113786817}, {"id": 25, "seek": 19012, "start": 190.16, "end": 195.4, "text": " little bit about what's happened in the last couple of years. So since the last in-person", "tokens": [50366, 707, 857, 466, 437, 311, 2011, 294, 264, 1036, 1916, 295, 924, 13, 407, 1670, 264, 1036, 294, 12, 10813, 50628], "temperature": 0.0, "avg_logprob": -0.13096136121607538, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.10496728867292404}, {"id": 26, "seek": 19012, "start": 195.4, "end": 206.0, "text": " Bosdom, we've done 18 different releases. Now, the way we do releases of Delph is somewhat", "tokens": [50628, 22264, 4121, 11, 321, 600, 1096, 2443, 819, 16952, 13, 823, 11, 264, 636, 321, 360, 16952, 295, 5831, 950, 307, 8344, 51158], "temperature": 0.0, "avg_logprob": -0.13096136121607538, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.10496728867292404}, {"id": 27, "seek": 19012, "start": 206.0, "end": 213.88, "text": " scheduled, somewhat ad hoc. So we always produce a new release when the first release", "tokens": [51158, 15678, 11, 8344, 614, 16708, 13, 407, 321, 1009, 5258, 257, 777, 4374, 562, 264, 700, 4374, 51552], "temperature": 0.0, "avg_logprob": -0.13096136121607538, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.10496728867292404}, {"id": 28, "seek": 21388, "start": 213.88, "end": 219.56, "text": " candidate of the new Go version comes out. So anytime a new Go version comes out, we", "tokens": [50364, 11532, 295, 264, 777, 1037, 3037, 1487, 484, 13, 407, 13038, 257, 777, 1037, 3037, 1487, 484, 11, 321, 50648], "temperature": 0.0, "avg_logprob": -0.11895339577286332, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.07153056561946869}, {"id": 29, "seek": 21388, "start": 219.56, "end": 225.48, "text": " ensure that the day that it's released, you can debug it. So once you compile your code,", "tokens": [50648, 5586, 300, 264, 786, 300, 309, 311, 4736, 11, 291, 393, 24083, 309, 13, 407, 1564, 291, 31413, 428, 3089, 11, 50944], "temperature": 0.0, "avg_logprob": -0.11895339577286332, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.07153056561946869}, {"id": 30, "seek": 21388, "start": 225.48, "end": 229.96, "text": " do everything, you have a debugger that's going to work with that version. And then", "tokens": [50944, 360, 1203, 11, 291, 362, 257, 24083, 1321, 300, 311, 516, 281, 589, 365, 300, 3037, 13, 400, 550, 51168], "temperature": 0.0, "avg_logprob": -0.11895339577286332, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.07153056561946869}, {"id": 31, "seek": 21388, "start": 229.96, "end": 235.24, "text": " aside from that, we have kind of minor releases that come out throughout the year. And in", "tokens": [51168, 7359, 490, 300, 11, 321, 362, 733, 295, 6696, 16952, 300, 808, 484, 3710, 264, 1064, 13, 400, 294, 51432], "temperature": 0.0, "avg_logprob": -0.11895339577286332, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.07153056561946869}, {"id": 32, "seek": 21388, "start": 235.24, "end": 242.8, "text": " between the releases to fix bugs, add new features, things like that. So within that", "tokens": [51432, 1296, 264, 16952, 281, 3191, 15120, 11, 909, 777, 4122, 11, 721, 411, 300, 13, 407, 1951, 300, 51810], "temperature": 0.0, "avg_logprob": -0.11895339577286332, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.07153056561946869}, {"id": 33, "seek": 24280, "start": 242.84, "end": 249.32000000000002, "text": " time frame, we've added support for numerous different Go versions. So 114 all the way", "tokens": [50366, 565, 3920, 11, 321, 600, 3869, 1406, 337, 12546, 819, 1037, 9606, 13, 407, 2975, 19, 439, 264, 636, 50690], "temperature": 0.0, "avg_logprob": -0.1308969883691697, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.000841786852106452}, {"id": 34, "seek": 24280, "start": 249.32000000000002, "end": 256.92, "text": " through 120. And as 120 was just released the other day, we've supported it since the", "tokens": [50690, 807, 10411, 13, 400, 382, 10411, 390, 445, 4736, 264, 661, 786, 11, 321, 600, 8104, 309, 1670, 264, 51070], "temperature": 0.0, "avg_logprob": -0.1308969883691697, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.000841786852106452}, {"id": 35, "seek": 24280, "start": 256.92, "end": 264.0, "text": " first RC. So you always have a debugger to kind of go through your code even before", "tokens": [51070, 700, 28987, 13, 407, 291, 1009, 362, 257, 24083, 1321, 281, 733, 295, 352, 807, 428, 3089, 754, 949, 51424], "temperature": 0.0, "avg_logprob": -0.1308969883691697, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.000841786852106452}, {"id": 36, "seek": 24280, "start": 264.0, "end": 271.12, "text": " the official release actually comes out. During that time, we've also added four new", "tokens": [51424, 264, 4783, 4374, 767, 1487, 484, 13, 6842, 300, 565, 11, 321, 600, 611, 3869, 1451, 777, 51780], "temperature": 0.0, "avg_logprob": -0.1308969883691697, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.000841786852106452}, {"id": 37, "seek": 27112, "start": 271.2, "end": 278.36, "text": " operating system and architecture combinations. So with Delph, we strive to enable you to debug", "tokens": [50368, 7447, 1185, 293, 9482, 21267, 13, 407, 365, 5831, 950, 11, 321, 23829, 281, 9528, 291, 281, 24083, 50726], "temperature": 0.0, "avg_logprob": -0.11108756927122553, "compression_ratio": 1.6743119266055047, "no_speech_prob": 0.0014539575204253197}, {"id": 38, "seek": 27112, "start": 278.36, "end": 283.32, "text": " on any operating system and architecture that Go itself supports. We're getting closer", "tokens": [50726, 322, 604, 7447, 1185, 293, 9482, 300, 1037, 2564, 9346, 13, 492, 434, 1242, 4966, 50974], "temperature": 0.0, "avg_logprob": -0.11108756927122553, "compression_ratio": 1.6743119266055047, "no_speech_prob": 0.0014539575204253197}, {"id": 39, "seek": 27112, "start": 283.32, "end": 289.76, "text": " and closer to that goal with each passing release. So I'm proud to say within the last", "tokens": [50974, 293, 4966, 281, 300, 3387, 365, 1184, 8437, 4374, 13, 407, 286, 478, 4570, 281, 584, 1951, 264, 1036, 51296], "temperature": 0.0, "avg_logprob": -0.11108756927122553, "compression_ratio": 1.6743119266055047, "no_speech_prob": 0.0014539575204253197}, {"id": 40, "seek": 27112, "start": 289.76, "end": 297.24, "text": " few years, we added support for four new platforms. And there's a few more already in the works", "tokens": [51296, 1326, 924, 11, 321, 3869, 1406, 337, 1451, 777, 9473, 13, 400, 456, 311, 257, 1326, 544, 1217, 294, 264, 1985, 51670], "temperature": 0.0, "avg_logprob": -0.11108756927122553, "compression_ratio": 1.6743119266055047, "no_speech_prob": 0.0014539575204253197}, {"id": 41, "seek": 29724, "start": 297.24, "end": 304.96000000000004, "text": " and we'll be releasing later this year. So I want to call out a few major new features", "tokens": [50364, 293, 321, 603, 312, 16327, 1780, 341, 1064, 13, 407, 286, 528, 281, 818, 484, 257, 1326, 2563, 777, 4122, 50750], "temperature": 0.0, "avg_logprob": -0.15354658014634076, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.0005695606814697385}, {"id": 42, "seek": 29724, "start": 304.96000000000004, "end": 312.36, "text": " that have been developed. The first is we've integrated a DAP server into Delph, which", "tokens": [50750, 300, 362, 668, 4743, 13, 440, 700, 307, 321, 600, 10919, 257, 413, 4715, 7154, 666, 5831, 950, 11, 597, 51120], "temperature": 0.0, "avg_logprob": -0.15354658014634076, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.0005695606814697385}, {"id": 43, "seek": 29724, "start": 312.36, "end": 318.88, "text": " is probably not something that's super relevant to everybody here unless you're like the author", "tokens": [51120, 307, 1391, 406, 746, 300, 311, 1687, 7340, 281, 2201, 510, 5969, 291, 434, 411, 264, 3793, 51446], "temperature": 0.0, "avg_logprob": -0.15354658014634076, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.0005695606814697385}, {"id": 44, "seek": 29724, "start": 318.88, "end": 325.08, "text": " of like an editor or something like that. It's really for editor integration, but from", "tokens": [51446, 295, 411, 364, 9839, 420, 746, 411, 300, 13, 467, 311, 534, 337, 9839, 10980, 11, 457, 490, 51756], "temperature": 0.0, "avg_logprob": -0.15354658014634076, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.0005695606814697385}, {"id": 45, "seek": 32508, "start": 325.08, "end": 331.24, "text": " a user's perspective, it really improves the usability of Delph within editors such", "tokens": [50364, 257, 4195, 311, 4585, 11, 309, 534, 24771, 264, 46878, 295, 5831, 950, 1951, 31446, 1270, 50672], "temperature": 0.0, "avg_logprob": -0.15155973313729973, "compression_ratio": 1.551111111111111, "no_speech_prob": 7.720287248957902e-05}, {"id": 46, "seek": 32508, "start": 331.24, "end": 341.24, "text": " as VS Code and things like that. We've added support for Apple Silicon and that happened", "tokens": [50672, 382, 25091, 15549, 293, 721, 411, 300, 13, 492, 600, 3869, 1406, 337, 6373, 25351, 293, 300, 2011, 51172], "temperature": 0.0, "avg_logprob": -0.15155973313729973, "compression_ratio": 1.551111111111111, "no_speech_prob": 7.720287248957902e-05}, {"id": 47, "seek": 32508, "start": 341.24, "end": 345.56, "text": " really quickly once we were able to kind of get our hands on the hardware and everything", "tokens": [51172, 534, 2661, 1564, 321, 645, 1075, 281, 733, 295, 483, 527, 2377, 322, 264, 8837, 293, 1203, 51388], "temperature": 0.0, "avg_logprob": -0.15155973313729973, "compression_ratio": 1.551111111111111, "no_speech_prob": 7.720287248957902e-05}, {"id": 48, "seek": 32508, "start": 345.56, "end": 351.64, "text": " like that. We added the ability to generate core dumps from running processes. So while", "tokens": [51388, 411, 300, 13, 492, 3869, 264, 3485, 281, 8460, 4965, 11430, 82, 490, 2614, 7555, 13, 407, 1339, 51692], "temperature": 0.0, "avg_logprob": -0.15155973313729973, "compression_ratio": 1.551111111111111, "no_speech_prob": 7.720287248957902e-05}, {"id": 49, "seek": 35164, "start": 351.68, "end": 356.8, "text": " you're in a debug session, you can ad hoc, generate a core dump, save that away and use", "tokens": [50366, 291, 434, 294, 257, 24083, 5481, 11, 291, 393, 614, 16708, 11, 8460, 257, 4965, 11430, 11, 3155, 300, 1314, 293, 764, 50622], "temperature": 0.0, "avg_logprob": -0.17228290167721835, "compression_ratio": 1.5746606334841629, "no_speech_prob": 0.029284566640853882}, {"id": 50, "seek": 35164, "start": 356.8, "end": 363.56, "text": " that and debug it later. We've added support for hardware watchpoints, which I think is", "tokens": [50622, 300, 293, 24083, 309, 1780, 13, 492, 600, 3869, 1406, 337, 8837, 1159, 20552, 11, 597, 286, 519, 307, 50960], "temperature": 0.0, "avg_logprob": -0.17228290167721835, "compression_ratio": 1.5746606334841629, "no_speech_prob": 0.029284566640853882}, {"id": 51, "seek": 35164, "start": 363.56, "end": 371.0, "text": " a really, really cool feature. And kind of difficult to do with Go due to some kind of", "tokens": [50960, 257, 534, 11, 534, 1627, 4111, 13, 400, 733, 295, 2252, 281, 360, 365, 1037, 3462, 281, 512, 733, 295, 51332], "temperature": 0.0, "avg_logprob": -0.17228290167721835, "compression_ratio": 1.5746606334841629, "no_speech_prob": 0.029284566640853882}, {"id": 52, "seek": 35164, "start": 371.0, "end": 376.91999999999996, "text": " internal things of how Go kind of looks at the stack and changes stack and stuff like", "tokens": [51332, 6920, 721, 295, 577, 1037, 733, 295, 1542, 412, 264, 8630, 293, 2962, 8630, 293, 1507, 411, 51628], "temperature": 0.0, "avg_logprob": -0.17228290167721835, "compression_ratio": 1.5746606334841629, "no_speech_prob": 0.029284566640853882}, {"id": 53, "seek": 37692, "start": 377.0, "end": 381.76, "text": " changes go routine stacks as the stack grows and things like that, but we were able to", "tokens": [50368, 2962, 352, 9927, 30792, 382, 264, 8630, 13156, 293, 721, 411, 300, 11, 457, 321, 645, 1075, 281, 50606], "temperature": 0.0, "avg_logprob": -0.13485925931196946, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0062871817499399185}, {"id": 54, "seek": 37692, "start": 381.76, "end": 387.0, "text": " implement them and get them working. So if you're unaware of what hardware watchpoints", "tokens": [50606, 4445, 552, 293, 483, 552, 1364, 13, 407, 498, 291, 434, 32065, 295, 437, 8837, 1159, 20552, 50868], "temperature": 0.0, "avg_logprob": -0.13485925931196946, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0062871817499399185}, {"id": 55, "seek": 37692, "start": 387.0, "end": 391.64000000000004, "text": " are, it's a really cool feature where you can say like, I want to watch this particular", "tokens": [50868, 366, 11, 309, 311, 257, 534, 1627, 4111, 689, 291, 393, 584, 411, 11, 286, 528, 281, 1159, 341, 1729, 51100], "temperature": 0.0, "avg_logprob": -0.13485925931196946, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0062871817499399185}, {"id": 56, "seek": 37692, "start": 391.64000000000004, "end": 395.64, "text": " variable or this particular address and memory and I want to know, I want the debugger to", "tokens": [51100, 7006, 420, 341, 1729, 2985, 293, 4675, 293, 286, 528, 281, 458, 11, 286, 528, 264, 24083, 1321, 281, 51300], "temperature": 0.0, "avg_logprob": -0.13485925931196946, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0062871817499399185}, {"id": 57, "seek": 37692, "start": 395.64, "end": 402.84000000000003, "text": " stop any time that value is read or changed. So you're basically just saying like telling", "tokens": [51300, 1590, 604, 565, 300, 2158, 307, 1401, 420, 3105, 13, 407, 291, 434, 1936, 445, 1566, 411, 3585, 51660], "temperature": 0.0, "avg_logprob": -0.13485925931196946, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0062871817499399185}, {"id": 58, "seek": 40284, "start": 402.91999999999996, "end": 408.0, "text": " the debugger what you want to do and letting it do the heavy lifting for you. Really cool", "tokens": [50368, 264, 24083, 1321, 437, 291, 528, 281, 360, 293, 8295, 309, 360, 264, 4676, 15798, 337, 291, 13, 4083, 1627, 50622], "temperature": 0.0, "avg_logprob": -0.1332332520257859, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.002885625697672367}, {"id": 59, "seek": 40284, "start": 408.0, "end": 415.56, "text": " feature. And as was just shown in the previous talk, we've improved some of the filtering", "tokens": [50622, 4111, 13, 400, 382, 390, 445, 4898, 294, 264, 3894, 751, 11, 321, 600, 9689, 512, 295, 264, 30822, 51000], "temperature": 0.0, "avg_logprob": -0.1332332520257859, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.002885625697672367}, {"id": 60, "seek": 40284, "start": 415.56, "end": 420.71999999999997, "text": " and grouping for Go routine output. So you can filter by label, you can filter by all", "tokens": [51000, 293, 40149, 337, 1037, 9927, 5598, 13, 407, 291, 393, 6608, 538, 7645, 11, 291, 393, 6608, 538, 439, 51258], "temperature": 0.0, "avg_logprob": -0.1332332520257859, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.002885625697672367}, {"id": 61, "seek": 40284, "start": 420.71999999999997, "end": 425.59999999999997, "text": " different kinds of things. So in like massively concurrent and parallel programs where you", "tokens": [51258, 819, 3685, 295, 721, 13, 407, 294, 411, 29379, 37702, 293, 8952, 4268, 689, 291, 51502], "temperature": 0.0, "avg_logprob": -0.1332332520257859, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.002885625697672367}, {"id": 62, "seek": 40284, "start": 425.59999999999997, "end": 432.4, "text": " might have tons and tons of different Go routines, we've improved a lot of the introspection", "tokens": [51502, 1062, 362, 9131, 293, 9131, 295, 819, 1037, 33827, 11, 321, 600, 9689, 257, 688, 295, 264, 560, 2635, 19997, 51842], "temperature": 0.0, "avg_logprob": -0.1332332520257859, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.002885625697672367}, {"id": 63, "seek": 43240, "start": 432.4, "end": 436.15999999999997, "text": " on that and being able to kind of filter out and get the information that you really", "tokens": [50364, 322, 300, 293, 885, 1075, 281, 733, 295, 6608, 484, 293, 483, 264, 1589, 300, 291, 534, 50552], "temperature": 0.0, "avg_logprob": -0.14861573524845456, "compression_ratio": 1.6795366795366795, "no_speech_prob": 0.00032471687882207334}, {"id": 64, "seek": 43240, "start": 436.15999999999997, "end": 442.67999999999995, "text": " need. We've also added an experimental EBPF based tracing back in. So that's what I'm", "tokens": [50552, 643, 13, 492, 600, 611, 3869, 364, 17069, 50148, 47, 37, 2361, 25262, 646, 294, 13, 407, 300, 311, 437, 286, 478, 50878], "temperature": 0.0, "avg_logprob": -0.14861573524845456, "compression_ratio": 1.6795366795366795, "no_speech_prob": 0.00032471687882207334}, {"id": 65, "seek": 43240, "start": 442.67999999999995, "end": 449.76, "text": " going to be talking about today. And we also added support for debug info find. So this", "tokens": [50878, 516, 281, 312, 1417, 466, 965, 13, 400, 321, 611, 3869, 1406, 337, 24083, 13614, 915, 13, 407, 341, 51232], "temperature": 0.0, "avg_logprob": -0.14861573524845456, "compression_ratio": 1.6795366795366795, "no_speech_prob": 0.00032471687882207334}, {"id": 66, "seek": 43240, "start": 449.76, "end": 454.2, "text": " is really cool for a lot of operating systems where maybe you're debugging a package that", "tokens": [51232, 307, 534, 1627, 337, 257, 688, 295, 7447, 3652, 689, 1310, 291, 434, 45592, 257, 7372, 300, 51454], "temperature": 0.0, "avg_logprob": -0.14861573524845456, "compression_ratio": 1.6795366795366795, "no_speech_prob": 0.00032471687882207334}, {"id": 67, "seek": 43240, "start": 454.2, "end": 460.0, "text": " you installed via your package manager and the like the door, the debug information is", "tokens": [51454, 291, 8899, 5766, 428, 7372, 6598, 293, 264, 411, 264, 2853, 11, 264, 24083, 1589, 307, 51744], "temperature": 0.0, "avg_logprob": -0.14861573524845456, "compression_ratio": 1.6795366795366795, "no_speech_prob": 0.00032471687882207334}, {"id": 68, "seek": 46000, "start": 460.04, "end": 463.96, "text": " not included with the binary. Maybe it's in a different package or something like that.", "tokens": [50366, 406, 5556, 365, 264, 17434, 13, 2704, 309, 311, 294, 257, 819, 7372, 420, 746, 411, 300, 13, 50562], "temperature": 0.0, "avg_logprob": -0.13072370133309993, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.0017543273279443383}, {"id": 69, "seek": 46000, "start": 463.96, "end": 468.32, "text": " We've integrated with debug info find to be able to automatically download those debug", "tokens": [50562, 492, 600, 10919, 365, 24083, 13614, 915, 281, 312, 1075, 281, 6772, 5484, 729, 24083, 50780], "temperature": 0.0, "avg_logprob": -0.13072370133309993, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.0017543273279443383}, {"id": 70, "seek": 46000, "start": 468.32, "end": 474.52, "text": " packages for you so that you can have a fruitful and successful debugging session. And there's", "tokens": [50780, 17401, 337, 291, 370, 300, 291, 393, 362, 257, 49795, 293, 4406, 45592, 5481, 13, 400, 456, 311, 51090], "temperature": 0.0, "avg_logprob": -0.13072370133309993, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.0017543273279443383}, {"id": 71, "seek": 46000, "start": 474.52, "end": 479.92, "text": " also been a lot more. If you want a look at all of the details, go ahead and check out", "tokens": [51090, 611, 668, 257, 688, 544, 13, 759, 291, 528, 257, 574, 412, 439, 295, 264, 4365, 11, 352, 2286, 293, 1520, 484, 51360], "temperature": 0.0, "avg_logprob": -0.13072370133309993, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.0017543273279443383}, {"id": 72, "seek": 46000, "start": 479.92, "end": 485.64, "text": " the change log in the repo. It'll detail all of the changes that we've made. Next thing", "tokens": [51360, 264, 1319, 3565, 294, 264, 49040, 13, 467, 603, 2607, 439, 295, 264, 2962, 300, 321, 600, 1027, 13, 3087, 551, 51646], "temperature": 0.0, "avg_logprob": -0.13072370133309993, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.0017543273279443383}, {"id": 73, "seek": 48564, "start": 485.68, "end": 493.4, "text": " I want to talk about is a few little upcoming features that I want to tease. So one of the", "tokens": [50366, 286, 528, 281, 751, 466, 307, 257, 1326, 707, 11500, 4122, 300, 286, 528, 281, 30444, 13, 407, 472, 295, 264, 50752], "temperature": 0.0, "avg_logprob": -0.17398209767798856, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.016140153631567955}, {"id": 74, "seek": 48564, "start": 493.4, "end": 501.4, "text": " biggest ones is we're working on support for two new architectures. So PowerPC64LE and", "tokens": [50752, 3880, 2306, 307, 321, 434, 1364, 322, 1406, 337, 732, 777, 6331, 1303, 13, 407, 7086, 12986, 19395, 2634, 293, 51152], "temperature": 0.0, "avg_logprob": -0.17398209767798856, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.016140153631567955}, {"id": 75, "seek": 48564, "start": 501.4, "end": 508.84, "text": " S390X. My colleague Alejandro is working on the PowerPC64LE port and he's in the crowd", "tokens": [51152, 318, 18, 7771, 55, 13, 1222, 13532, 44568, 29173, 307, 1364, 322, 264, 7086, 12986, 19395, 2634, 2436, 293, 415, 311, 294, 264, 6919, 51524], "temperature": 0.0, "avg_logprob": -0.17398209767798856, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.016140153631567955}, {"id": 76, "seek": 50884, "start": 508.88, "end": 516.04, "text": " as well. So thank you for your work on that. We're looking at some more improvements to", "tokens": [50366, 382, 731, 13, 407, 1309, 291, 337, 428, 589, 322, 300, 13, 492, 434, 1237, 412, 512, 544, 13797, 281, 50724], "temperature": 0.0, "avg_logprob": -0.19750456188036047, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.048817358911037445}, {"id": 77, "seek": 50884, "start": 516.04, "end": 519.76, "text": " the EBPF tracing back end. I'll go into some more detail on that as well during this talk.", "tokens": [50724, 264, 50148, 47, 37, 25262, 646, 917, 13, 286, 603, 352, 666, 512, 544, 2607, 322, 300, 382, 731, 1830, 341, 751, 13, 50910], "temperature": 0.0, "avg_logprob": -0.19750456188036047, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.048817358911037445}, {"id": 78, "seek": 50884, "start": 519.76, "end": 528.76, "text": " We're also working on the ability to debug multiple processes simultaneously. My co-maintenor", "tokens": [50910, 492, 434, 611, 1364, 322, 264, 3485, 281, 24083, 3866, 7555, 16561, 13, 1222, 598, 12, 49417, 1147, 284, 51360], "temperature": 0.0, "avg_logprob": -0.19750456188036047, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.048817358911037445}, {"id": 79, "seek": 50884, "start": 528.76, "end": 534.8399999999999, "text": " Alejandro is working on that and we're hoping to land that pretty soon. So that would be", "tokens": [51360, 44568, 29173, 307, 1364, 322, 300, 293, 321, 434, 7159, 281, 2117, 300, 1238, 2321, 13, 407, 300, 576, 312, 51664], "temperature": 0.0, "avg_logprob": -0.19750456188036047, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.048817358911037445}, {"id": 80, "seek": 53484, "start": 535.72, "end": 541.08, "text": " if your process forks or anything like that creates new child processes, you can debug", "tokens": [50408, 498, 428, 1399, 337, 1694, 420, 1340, 411, 300, 7829, 777, 1440, 7555, 11, 291, 393, 24083, 50676], "temperature": 0.0, "avg_logprob": -0.152299251371217, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.0016472024144604802}, {"id": 81, "seek": 53484, "start": 541.08, "end": 548.08, "text": " all of them within a single session. Another thing that we want to work on this year is", "tokens": [50676, 439, 295, 552, 1951, 257, 2167, 5481, 13, 3996, 551, 300, 321, 528, 281, 589, 322, 341, 1064, 307, 51026], "temperature": 0.0, "avg_logprob": -0.152299251371217, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.0016472024144604802}, {"id": 82, "seek": 53484, "start": 548.08, "end": 553.88, "text": " improved function call support across architectures. So that was a big feature that landed in Delve", "tokens": [51026, 9689, 2445, 818, 1406, 2108, 6331, 1303, 13, 407, 300, 390, 257, 955, 4111, 300, 15336, 294, 5831, 303, 51316], "temperature": 0.0, "avg_logprob": -0.152299251371217, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.0016472024144604802}, {"id": 83, "seek": 53484, "start": 553.88, "end": 558.52, "text": " as well, the ability to call a function while you're debugging your program. It's very", "tokens": [51316, 382, 731, 11, 264, 3485, 281, 818, 257, 2445, 1339, 291, 434, 45592, 428, 1461, 13, 467, 311, 588, 51548], "temperature": 0.0, "avg_logprob": -0.152299251371217, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.0016472024144604802}, {"id": 84, "seek": 53484, "start": 558.52, "end": 563.48, "text": " architecture specific. So one of the things that we want to do throughout this year is", "tokens": [51548, 9482, 2685, 13, 407, 472, 295, 264, 721, 300, 321, 528, 281, 360, 3710, 341, 1064, 307, 51796], "temperature": 0.0, "avg_logprob": -0.152299251371217, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.0016472024144604802}, {"id": 85, "seek": 56348, "start": 563.52, "end": 569.2, "text": " improve support for that across different architectures. There's tons more. We're always", "tokens": [50366, 3470, 1406, 337, 300, 2108, 819, 6331, 1303, 13, 821, 311, 9131, 544, 13, 492, 434, 1009, 50650], "temperature": 0.0, "avg_logprob": -0.14416465526673852, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.001673324266448617}, {"id": 86, "seek": 56348, "start": 569.2, "end": 576.2, "text": " working on new things and we also always try to gather community feedback and user feedback", "tokens": [50650, 1364, 322, 777, 721, 293, 321, 611, 1009, 853, 281, 5448, 1768, 5824, 293, 4195, 5824, 51000], "temperature": 0.0, "avg_logprob": -0.14416465526673852, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.001673324266448617}, {"id": 87, "seek": 56348, "start": 576.44, "end": 582.08, "text": " and stuff like that. So since I'm here and other maintainers of Delve are here, if you", "tokens": [51012, 293, 1507, 411, 300, 13, 407, 1670, 286, 478, 510, 293, 661, 6909, 433, 295, 5831, 303, 366, 510, 11, 498, 291, 51294], "temperature": 0.0, "avg_logprob": -0.14416465526673852, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.001673324266448617}, {"id": 88, "seek": 56348, "start": 582.08, "end": 586.48, "text": " want to come and tell us something that you would like us to implement or something that", "tokens": [51294, 528, 281, 808, 293, 980, 505, 746, 300, 291, 576, 411, 505, 281, 4445, 420, 746, 300, 51514], "temperature": 0.0, "avg_logprob": -0.14416465526673852, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.001673324266448617}, {"id": 89, "seek": 58648, "start": 586.48, "end": 593.48, "text": " you would like to focus on, feel free to come chat with us. So now with that said and done,", "tokens": [50364, 291, 576, 411, 281, 1879, 322, 11, 841, 1737, 281, 808, 5081, 365, 505, 13, 407, 586, 365, 300, 848, 293, 1096, 11, 50714], "temperature": 0.0, "avg_logprob": -0.1586276448291281, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.02030758745968342}, {"id": 90, "seek": 58648, "start": 595.44, "end": 601.64, "text": " I want to move on to the real portion of this talk which is debugging and tracing go programs", "tokens": [50812, 286, 528, 281, 1286, 322, 281, 264, 957, 8044, 295, 341, 751, 597, 307, 45592, 293, 25262, 352, 4268, 51122], "temperature": 0.0, "avg_logprob": -0.1586276448291281, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.02030758745968342}, {"id": 91, "seek": 58648, "start": 601.64, "end": 608.64, "text": " with EBPF. Now it's really cool that this talk comes after the talk right before because", "tokens": [51122, 365, 50148, 47, 37, 13, 823, 309, 311, 534, 1627, 300, 341, 751, 1487, 934, 264, 751, 558, 949, 570, 51472], "temperature": 0.0, "avg_logprob": -0.1586276448291281, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.02030758745968342}, {"id": 92, "seek": 58648, "start": 608.96, "end": 614.84, "text": " I think the tracing feature in Delve is somewhat underutilized and I think it's really good", "tokens": [51488, 286, 519, 264, 25262, 4111, 294, 5831, 303, 307, 8344, 833, 20835, 1602, 293, 286, 519, 309, 311, 534, 665, 51782], "temperature": 0.0, "avg_logprob": -0.1586276448291281, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.02030758745968342}, {"id": 93, "seek": 61484, "start": 614.84, "end": 619.9200000000001, "text": " for debugging concurrent programs and seeing the interactions between go routines as your", "tokens": [50364, 337, 45592, 37702, 4268, 293, 2577, 264, 13280, 1296, 352, 33827, 382, 428, 50618], "temperature": 0.0, "avg_logprob": -0.13254720089482327, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0010983326938003302}, {"id": 94, "seek": 61484, "start": 619.9200000000001, "end": 626.84, "text": " program is actually running. So if you're unfamiliar with what tracing is, I'll show", "tokens": [50618, 1461, 307, 767, 2614, 13, 407, 498, 291, 434, 29415, 365, 437, 25262, 307, 11, 286, 603, 855, 50964], "temperature": 0.0, "avg_logprob": -0.13254720089482327, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0010983326938003302}, {"id": 95, "seek": 61484, "start": 626.84, "end": 632.52, "text": " a little demo but essentially what we're talking about here is instead of going into a full", "tokens": [50964, 257, 707, 10723, 457, 4476, 437, 321, 434, 1417, 466, 510, 307, 2602, 295, 516, 666, 257, 1577, 51248], "temperature": 0.0, "avg_logprob": -0.13254720089482327, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0010983326938003302}, {"id": 96, "seek": 61484, "start": 632.52, "end": 636.88, "text": " on debug session, what you're really doing is spying on your program. So if you're familiar", "tokens": [51248, 322, 24083, 5481, 11, 437, 291, 434, 534, 884, 307, 637, 1840, 322, 428, 1461, 13, 407, 498, 291, 434, 4963, 51466], "temperature": 0.0, "avg_logprob": -0.13254720089482327, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0010983326938003302}, {"id": 97, "seek": 61484, "start": 636.88, "end": 641.72, "text": " with STrace, it's the same concept except for the functions that you're writing as opposed", "tokens": [51466, 365, 318, 14252, 617, 11, 309, 311, 264, 912, 3410, 3993, 337, 264, 6828, 300, 291, 434, 3579, 382, 8851, 51708], "temperature": 0.0, "avg_logprob": -0.13254720089482327, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0010983326938003302}, {"id": 98, "seek": 64172, "start": 641.72, "end": 647.8000000000001, "text": " to the interactions with the kernel, like the system calls and things like that. So", "tokens": [50364, 281, 264, 13280, 365, 264, 28256, 11, 411, 264, 1185, 5498, 293, 721, 411, 300, 13, 407, 50668], "temperature": 0.0, "avg_logprob": -0.1354668336756089, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.005218522623181343}, {"id": 99, "seek": 64172, "start": 647.8000000000001, "end": 652.44, "text": " you can kind of spy and see what functions are being executed, what are their inputs,", "tokens": [50668, 291, 393, 733, 295, 20752, 293, 536, 437, 6828, 366, 885, 17577, 11, 437, 366, 641, 15743, 11, 50900], "temperature": 0.0, "avg_logprob": -0.1354668336756089, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.005218522623181343}, {"id": 100, "seek": 64172, "start": 652.44, "end": 658.08, "text": " what are the outputs, what go routines are executing that function, so on and so forth.", "tokens": [50900, 437, 366, 264, 23930, 11, 437, 352, 33827, 366, 32368, 300, 2445, 11, 370, 322, 293, 370, 5220, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1354668336756089, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.005218522623181343}, {"id": 101, "seek": 64172, "start": 658.08, "end": 665.08, "text": " So to show a little demo of it real quick, let me increase my screen size a little bit.", "tokens": [51182, 407, 281, 855, 257, 707, 10723, 295, 309, 957, 1702, 11, 718, 385, 3488, 452, 2568, 2744, 257, 707, 857, 13, 51532], "temperature": 0.0, "avg_logprob": -0.1354668336756089, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.005218522623181343}, {"id": 102, "seek": 66508, "start": 665.36, "end": 672.36, "text": " It may still be hard for folks in the back to see but hopefully that's good enough.", "tokens": [50378, 467, 815, 920, 312, 1152, 337, 4024, 294, 264, 646, 281, 536, 457, 4696, 300, 311, 665, 1547, 13, 50728], "temperature": 0.0, "avg_logprob": -0.16907466931289503, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.004069148097187281}, {"id": 103, "seek": 66508, "start": 675.84, "end": 680.6800000000001, "text": " So what I've done here is instead of typing everything directly on the console, I've created", "tokens": [50902, 407, 437, 286, 600, 1096, 510, 307, 2602, 295, 18444, 1203, 3838, 322, 264, 11076, 11, 286, 600, 2942, 51144], "temperature": 0.0, "avg_logprob": -0.16907466931289503, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.004069148097187281}, {"id": 104, "seek": 66508, "start": 680.6800000000001, "end": 685.32, "text": " a little make file just so that you can see kind of the commands up there and they don't", "tokens": [51144, 257, 707, 652, 3991, 445, 370, 300, 291, 393, 536, 733, 295, 264, 16901, 493, 456, 293, 436, 500, 380, 51376], "temperature": 0.0, "avg_logprob": -0.16907466931289503, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.004069148097187281}, {"id": 105, "seek": 66508, "start": 685.32, "end": 689.08, "text": " disappear as I run them. But the first thing that we're going to do is we're just going", "tokens": [51376, 11596, 382, 286, 1190, 552, 13, 583, 264, 700, 551, 300, 321, 434, 516, 281, 360, 307, 321, 434, 445, 516, 51564], "temperature": 0.0, "avg_logprob": -0.16907466931289503, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.004069148097187281}, {"id": 106, "seek": 68908, "start": 689.08, "end": 695.64, "text": " to run a simple trace. So to do this, we use the trace sub-command of delve and what you", "tokens": [50364, 281, 1190, 257, 2199, 13508, 13, 407, 281, 360, 341, 11, 321, 764, 264, 13508, 1422, 12, 13278, 474, 295, 43098, 293, 437, 291, 50692], "temperature": 0.0, "avg_logprob": -0.14535942077636718, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08871572464704514}, {"id": 107, "seek": 68908, "start": 695.64, "end": 702.64, "text": " provide to it as an argument is a regular expression and what delve will do internally", "tokens": [50692, 2893, 281, 309, 382, 364, 6770, 307, 257, 3890, 6114, 293, 437, 43098, 486, 360, 19501, 51042], "temperature": 0.0, "avg_logprob": -0.14535942077636718, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08871572464704514}, {"id": 108, "seek": 68908, "start": 702.76, "end": 706.14, "text": " is set a trace point on any function that matches that regular expression. So you can", "tokens": [51048, 307, 992, 257, 13508, 935, 322, 604, 2445, 300, 10676, 300, 3890, 6114, 13, 407, 291, 393, 51217], "temperature": 0.0, "avg_logprob": -0.14535942077636718, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08871572464704514}, {"id": 109, "seek": 68908, "start": 706.14, "end": 713.1400000000001, "text": " do something like main.star to trace anything in the main package, extrapolate that out", "tokens": [51217, 360, 746, 411, 2135, 13, 9710, 281, 13508, 1340, 294, 264, 2135, 7372, 11, 48224, 473, 300, 484, 51567], "temperature": 0.0, "avg_logprob": -0.14535942077636718, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08871572464704514}, {"id": 110, "seek": 71314, "start": 713.42, "end": 719.74, "text": " to any other package and it's a really cool feature. So just to kind of show how it works,", "tokens": [50378, 281, 604, 661, 7372, 293, 309, 311, 257, 534, 1627, 4111, 13, 407, 445, 281, 733, 295, 855, 577, 309, 1985, 11, 50694], "temperature": 0.0, "avg_logprob": -0.11317023171318902, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0024719417560845613}, {"id": 111, "seek": 71314, "start": 719.74, "end": 725.74, "text": " we can go here and say make trace and we see the output there. So to explain the output", "tokens": [50694, 321, 393, 352, 510, 293, 584, 652, 13508, 293, 321, 536, 264, 5598, 456, 13, 407, 281, 2903, 264, 5598, 50994], "temperature": 0.0, "avg_logprob": -0.11317023171318902, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0024719417560845613}, {"id": 112, "seek": 71314, "start": 725.74, "end": 732.74, "text": " a little bit, you have like the single line or the single arrow is the call, the double", "tokens": [50994, 257, 707, 857, 11, 291, 362, 411, 264, 2167, 1622, 420, 264, 2167, 11610, 307, 264, 818, 11, 264, 3834, 51344], "temperature": 0.0, "avg_logprob": -0.11317023171318902, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0024719417560845613}, {"id": 113, "seek": 71314, "start": 732.98, "end": 739.98, "text": " arrow is the return. You can see there it labels what go routine is running and calling", "tokens": [51356, 11610, 307, 264, 2736, 13, 509, 393, 536, 456, 309, 16949, 437, 352, 9927, 307, 2614, 293, 5141, 51706], "temperature": 0.0, "avg_logprob": -0.11317023171318902, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0024719417560845613}, {"id": 114, "seek": 73998, "start": 739.98, "end": 743.66, "text": " that function. You can see the arguments to that function and then you can also see", "tokens": [50364, 300, 2445, 13, 509, 393, 536, 264, 12869, 281, 300, 2445, 293, 550, 291, 393, 611, 536, 50548], "temperature": 0.0, "avg_logprob": -0.11543603701012156, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.0005883662961423397}, {"id": 115, "seek": 73998, "start": 743.66, "end": 748.26, "text": " the return value. So again, really cool and useful for like if you have a bunch of different", "tokens": [50548, 264, 2736, 2158, 13, 407, 797, 11, 534, 1627, 293, 4420, 337, 411, 498, 291, 362, 257, 3840, 295, 819, 50778], "temperature": 0.0, "avg_logprob": -0.11543603701012156, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.0005883662961423397}, {"id": 116, "seek": 73998, "start": 748.26, "end": 753.9, "text": " go routines, you can kind of see the interactions of them and see what go routines are doing", "tokens": [50778, 352, 33827, 11, 291, 393, 733, 295, 536, 264, 13280, 295, 552, 293, 536, 437, 352, 33827, 366, 884, 51060], "temperature": 0.0, "avg_logprob": -0.11543603701012156, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.0005883662961423397}, {"id": 117, "seek": 73998, "start": 753.9, "end": 760.9, "text": " at any given time. Another option that you can do is you can say if you pass the stack", "tokens": [51060, 412, 604, 2212, 565, 13, 3996, 3614, 300, 291, 393, 360, 307, 291, 393, 584, 498, 291, 1320, 264, 8630, 51410], "temperature": 0.0, "avg_logprob": -0.11543603701012156, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.0005883662961423397}, {"id": 118, "seek": 73998, "start": 760.9, "end": 766.22, "text": " flag and give it an argument, you can get a stack trace anytime one of the trace points", "tokens": [51410, 7166, 293, 976, 309, 364, 6770, 11, 291, 393, 483, 257, 8630, 13508, 13038, 472, 295, 264, 13508, 2793, 51676], "temperature": 0.0, "avg_logprob": -0.11543603701012156, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.0005883662961423397}, {"id": 119, "seek": 76622, "start": 766.22, "end": 774.46, "text": " are hit. So if we say trace with stack, you see we get kind of a similar output but we", "tokens": [50364, 366, 2045, 13, 407, 498, 321, 584, 13508, 365, 8630, 11, 291, 536, 321, 483, 733, 295, 257, 2531, 5598, 457, 321, 50776], "temperature": 0.0, "avg_logprob": -0.1104235027147376, "compression_ratio": 1.6047904191616766, "no_speech_prob": 0.0008557590772397816}, {"id": 120, "seek": 76622, "start": 774.46, "end": 780.22, "text": " get a stack trace as well. So you can kind of see a little bit more detailed information", "tokens": [50776, 483, 257, 8630, 13508, 382, 731, 13, 407, 291, 393, 733, 295, 536, 257, 707, 857, 544, 9942, 1589, 51064], "temperature": 0.0, "avg_logprob": -0.1104235027147376, "compression_ratio": 1.6047904191616766, "no_speech_prob": 0.0008557590772397816}, {"id": 121, "seek": 76622, "start": 780.22, "end": 787.22, "text": " as your program is being traced. So the real meat of this talk is how we improve the tracing", "tokens": [51064, 382, 428, 1461, 307, 885, 38141, 13, 407, 264, 957, 4615, 295, 341, 751, 307, 577, 321, 3470, 264, 25262, 51414], "temperature": 0.0, "avg_logprob": -0.1104235027147376, "compression_ratio": 1.6047904191616766, "no_speech_prob": 0.0008557590772397816}, {"id": 122, "seek": 78722, "start": 787.46, "end": 794.46, "text": " back end to make it more efficient because what you, especially when you're doing something", "tokens": [50376, 646, 917, 281, 652, 309, 544, 7148, 570, 437, 291, 11, 2318, 562, 291, 434, 884, 746, 50726], "temperature": 0.0, "avg_logprob": -0.16796876192092897, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0012839563423767686}, {"id": 123, "seek": 78722, "start": 800.9, "end": 806.14, "text": " like tracing and things like that, the lower overhead the better. We don't want to make", "tokens": [51048, 411, 25262, 293, 721, 411, 300, 11, 264, 3126, 19922, 264, 1101, 13, 492, 500, 380, 528, 281, 652, 51310], "temperature": 0.0, "avg_logprob": -0.16796876192092897, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0012839563423767686}, {"id": 124, "seek": 78722, "start": 806.14, "end": 811.22, "text": " your program run significantly slower because that's just going to frustrate you and it's", "tokens": [51310, 428, 1461, 1190, 10591, 14009, 570, 300, 311, 445, 516, 281, 7454, 4404, 291, 293, 309, 311, 51564], "temperature": 0.0, "avg_logprob": -0.16796876192092897, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0012839563423767686}, {"id": 125, "seek": 78722, "start": 811.22, "end": 814.1800000000001, "text": " going to take longer to get to root cause analysis which is what you're really trying", "tokens": [51564, 516, 281, 747, 2854, 281, 483, 281, 5593, 3082, 5215, 597, 307, 437, 291, 434, 534, 1382, 51712], "temperature": 0.0, "avg_logprob": -0.16796876192092897, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0012839563423767686}, {"id": 126, "seek": 81418, "start": 814.18, "end": 818.7399999999999, "text": " to do if you're using a debugger in the first place. So we'll talk about quickly how things", "tokens": [50364, 281, 360, 498, 291, 434, 1228, 257, 24083, 1321, 294, 264, 700, 1081, 13, 407, 321, 603, 751, 466, 2661, 577, 721, 50592], "temperature": 0.0, "avg_logprob": -0.16306633196379008, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.004608691670000553}, {"id": 127, "seek": 81418, "start": 818.7399999999999, "end": 825.5, "text": " are currently implemented and then how we can improve upon that using EBPF. So right", "tokens": [50592, 366, 4362, 12270, 293, 550, 577, 321, 393, 3470, 3564, 300, 1228, 50148, 47, 37, 13, 407, 558, 50930], "temperature": 0.0, "avg_logprob": -0.16306633196379008, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.004608691670000553}, {"id": 128, "seek": 81418, "start": 825.5, "end": 832.5, "text": " now Delve uses, or traditionally Delve uses ptrace syscall to implement the tracing back", "tokens": [50930, 586, 5831, 303, 4960, 11, 420, 19067, 5831, 303, 4960, 280, 6903, 617, 262, 749, 45459, 281, 4445, 264, 25262, 646, 51280], "temperature": 0.0, "avg_logprob": -0.16306633196379008, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.004608691670000553}, {"id": 129, "seek": 81418, "start": 833.38, "end": 839.42, "text": " end. It's how ptrace is useful for, like it's used by pretty much every debugger, every", "tokens": [51324, 917, 13, 467, 311, 577, 280, 6903, 617, 307, 4420, 337, 11, 411, 309, 311, 1143, 538, 1238, 709, 633, 24083, 1321, 11, 633, 51626], "temperature": 0.0, "avg_logprob": -0.16306633196379008, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.004608691670000553}, {"id": 130, "seek": 83942, "start": 839.54, "end": 846.3, "text": " kind of tool like this. Delve is no exception. And if you look at the man page it'll explain", "tokens": [50370, 733, 295, 2290, 411, 341, 13, 5831, 303, 307, 572, 11183, 13, 400, 498, 291, 574, 412, 264, 587, 3028, 309, 603, 2903, 50708], "temperature": 0.0, "avg_logprob": -0.10885008088834994, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.0037052342668175697}, {"id": 131, "seek": 83942, "start": 846.3, "end": 850.26, "text": " a little bit more about what it is but it essentially allows you to control the execution", "tokens": [50708, 257, 707, 857, 544, 466, 437, 309, 307, 457, 309, 4476, 4045, 291, 281, 1969, 264, 15058, 50906], "temperature": 0.0, "avg_logprob": -0.10885008088834994, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.0037052342668175697}, {"id": 132, "seek": 83942, "start": 850.26, "end": 856.06, "text": " of another process and kind of examine the state of it, memory and things like that.", "tokens": [50906, 295, 1071, 1399, 293, 733, 295, 17496, 264, 1785, 295, 309, 11, 4675, 293, 721, 411, 300, 13, 51196], "temperature": 0.0, "avg_logprob": -0.10885008088834994, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.0037052342668175697}, {"id": 133, "seek": 83942, "start": 856.06, "end": 863.06, "text": " So the problem is ptrace is slow and it can be very slow. So I ran some tests kind of", "tokens": [51196, 407, 264, 1154, 307, 280, 6903, 617, 307, 2964, 293, 309, 393, 312, 588, 2964, 13, 407, 286, 5872, 512, 6921, 733, 295, 51546], "temperature": 0.0, "avg_logprob": -0.10885008088834994, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.0037052342668175697}, {"id": 134, "seek": 86306, "start": 863.5799999999999, "end": 870.5799999999999, "text": " a while ago when I was implementing the first iteration of this EBPF back end and I measured", "tokens": [50390, 257, 1339, 2057, 562, 286, 390, 18114, 264, 700, 24784, 295, 341, 50148, 47, 37, 646, 917, 293, 286, 12690, 50740], "temperature": 0.0, "avg_logprob": -0.16944822735256618, "compression_ratio": 1.5466101694915255, "no_speech_prob": 0.00027788220904767513}, {"id": 135, "seek": 86306, "start": 873.92, "end": 880.42, "text": " like a simple program execution that executed in 23.7 microseconds. And then the overhead", "tokens": [50907, 411, 257, 2199, 1461, 15058, 300, 17577, 294, 6673, 13, 22, 3123, 37841, 28750, 13, 400, 550, 264, 19922, 51232], "temperature": 0.0, "avg_logprob": -0.16944822735256618, "compression_ratio": 1.5466101694915255, "no_speech_prob": 0.00027788220904767513}, {"id": 136, "seek": 86306, "start": 880.42, "end": 885.5799999999999, "text": " with the ptrace based tracing, the traditional based tracing, it went up to 2.3 seconds.", "tokens": [51232, 365, 264, 280, 6903, 617, 2361, 25262, 11, 264, 5164, 2361, 25262, 11, 309, 1437, 493, 281, 568, 13, 18, 3949, 13, 51490], "temperature": 0.0, "avg_logprob": -0.16944822735256618, "compression_ratio": 1.5466101694915255, "no_speech_prob": 0.00027788220904767513}, {"id": 137, "seek": 86306, "start": 885.5799999999999, "end": 891.6199999999999, "text": " So that's several orders of magnitude of overhead, which is definitely not what you want. But", "tokens": [51490, 407, 300, 311, 2940, 9470, 295, 15668, 295, 19922, 11, 597, 307, 2138, 406, 437, 291, 528, 13, 583, 51792], "temperature": 0.0, "avg_logprob": -0.16944822735256618, "compression_ratio": 1.5466101694915255, "no_speech_prob": 0.00027788220904767513}, {"id": 138, "seek": 89162, "start": 891.66, "end": 898.66, "text": " why is ptrace so slow? So part of the reason is syscall overhead. We have to, ptrace is", "tokens": [50366, 983, 307, 280, 6903, 617, 370, 2964, 30, 407, 644, 295, 264, 1778, 307, 262, 749, 45459, 19922, 13, 492, 362, 281, 11, 280, 6903, 617, 307, 50716], "temperature": 0.0, "avg_logprob": -0.17907898147384843, "compression_ratio": 1.552325581395349, "no_speech_prob": 0.00021643907530233264}, {"id": 139, "seek": 89162, "start": 907.0600000000001, "end": 912.26, "text": " a syscall so whenever you invoke a syscall, you trap into the kernel, you switch context.", "tokens": [51136, 257, 262, 749, 45459, 370, 5699, 291, 41117, 257, 262, 749, 45459, 11, 291, 11487, 666, 264, 28256, 11, 291, 3679, 4319, 13, 51396], "temperature": 0.0, "avg_logprob": -0.17907898147384843, "compression_ratio": 1.552325581395349, "no_speech_prob": 0.00021643907530233264}, {"id": 140, "seek": 89162, "start": 912.26, "end": 919.26, "text": " So that has its own kind of overhead which can be pretty significant. And as I mentioned,", "tokens": [51396, 407, 300, 575, 1080, 1065, 733, 295, 19922, 597, 393, 312, 1238, 4776, 13, 400, 382, 286, 2835, 11, 51746], "temperature": 0.0, "avg_logprob": -0.17907898147384843, "compression_ratio": 1.552325581395349, "no_speech_prob": 0.00021643907530233264}, {"id": 141, "seek": 91926, "start": 920.26, "end": 926.38, "text": " the user space kernel context switching, the overhead of that can be really expensive.", "tokens": [50414, 264, 4195, 1901, 28256, 4319, 16493, 11, 264, 19922, 295, 300, 393, 312, 534, 5124, 13, 50720], "temperature": 0.0, "avg_logprob": -0.15388107299804688, "compression_ratio": 1.4689265536723164, "no_speech_prob": 0.0002611157833598554}, {"id": 142, "seek": 91926, "start": 926.38, "end": 933.38, "text": " And it's amplified by the fact that ptrace is in a sense very directed. So when we're", "tokens": [50720, 400, 309, 311, 49237, 538, 264, 1186, 300, 280, 6903, 617, 307, 294, 257, 2020, 588, 12898, 13, 407, 562, 321, 434, 51070], "temperature": 0.0, "avg_logprob": -0.15388107299804688, "compression_ratio": 1.4689265536723164, "no_speech_prob": 0.0002611157833598554}, {"id": 143, "seek": 91926, "start": 938.26, "end": 943.9, "text": " tracing these functions, we often have to make multiple ptrace calls per function entry", "tokens": [51314, 25262, 613, 6828, 11, 321, 2049, 362, 281, 652, 3866, 280, 6903, 617, 5498, 680, 2445, 8729, 51596], "temperature": 0.0, "avg_logprob": -0.15388107299804688, "compression_ratio": 1.4689265536723164, "no_speech_prob": 0.0002611157833598554}, {"id": 144, "seek": 94390, "start": 943.98, "end": 948.8199999999999, "text": " and function exit. So if you think about it, we need to read the registers, we need to", "tokens": [50368, 293, 2445, 11043, 13, 407, 498, 291, 519, 466, 309, 11, 321, 643, 281, 1401, 264, 38351, 11, 321, 643, 281, 50610], "temperature": 0.0, "avg_logprob": -0.10546897492318782, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.01853027381002903}, {"id": 145, "seek": 94390, "start": 948.8199999999999, "end": 955.42, "text": " read all of the different function arguments that are there. There's a bunch of different", "tokens": [50610, 1401, 439, 295, 264, 819, 2445, 12869, 300, 366, 456, 13, 821, 311, 257, 3840, 295, 819, 50940], "temperature": 0.0, "avg_logprob": -0.10546897492318782, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.01853027381002903}, {"id": 146, "seek": 94390, "start": 955.42, "end": 960.5, "text": " things that we need to do. So it kind of balloons up really, really quickly where we get into", "tokens": [50940, 721, 300, 321, 643, 281, 360, 13, 407, 309, 733, 295, 26193, 493, 534, 11, 534, 2661, 689, 321, 483, 666, 51194], "temperature": 0.0, "avg_logprob": -0.10546897492318782, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.01853027381002903}, {"id": 147, "seek": 94390, "start": 960.5, "end": 965.02, "text": " this situation where we're doing a ton of these user space kernel context switching", "tokens": [51194, 341, 2590, 689, 321, 434, 884, 257, 2952, 295, 613, 4195, 1901, 28256, 4319, 16493, 51420], "temperature": 0.0, "avg_logprob": -0.10546897492318782, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.01853027381002903}, {"id": 148, "seek": 94390, "start": 965.02, "end": 972.02, "text": " per every time you hit one of these trace points. And on top of that, all of these operations", "tokens": [51420, 680, 633, 565, 291, 2045, 472, 295, 613, 13508, 2793, 13, 400, 322, 1192, 295, 300, 11, 439, 295, 613, 7705, 51770], "temperature": 0.0, "avg_logprob": -0.10546897492318782, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.01853027381002903}, {"id": 149, "seek": 97390, "start": 974.18, "end": 980.18, "text": " have to happen twice per function, right? So the entry and the exit. So it's a lot of", "tokens": [50378, 362, 281, 1051, 6091, 680, 2445, 11, 558, 30, 407, 264, 8729, 293, 264, 11043, 13, 407, 309, 311, 257, 688, 295, 50678], "temperature": 0.0, "avg_logprob": -0.11849981805552608, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.0006664555985480547}, {"id": 150, "seek": 97390, "start": 980.18, "end": 986.22, "text": " overhead, a lot of context switching, essentially a lot of unnecessary work and a lot of work", "tokens": [50678, 19922, 11, 257, 688, 295, 4319, 16493, 11, 4476, 257, 688, 295, 19350, 589, 293, 257, 688, 295, 589, 50980], "temperature": 0.0, "avg_logprob": -0.11849981805552608, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.0006664555985480547}, {"id": 151, "seek": 97390, "start": 986.22, "end": 993.22, "text": " that just slows down your program and adds a lot of overhead. So the way that we can", "tokens": [50980, 300, 445, 35789, 760, 428, 1461, 293, 10860, 257, 688, 295, 19922, 13, 407, 264, 636, 300, 321, 393, 51330], "temperature": 0.0, "avg_logprob": -0.11849981805552608, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.0006664555985480547}, {"id": 152, "seek": 97390, "start": 995.5, "end": 1002.5, "text": " improve upon this and work around this is by using EBPF. So EBPF is a lot more effective", "tokens": [51444, 3470, 3564, 341, 293, 589, 926, 341, 307, 538, 1228, 50148, 47, 37, 13, 407, 50148, 47, 37, 307, 257, 688, 544, 4942, 51794], "temperature": 0.0, "avg_logprob": -0.11849981805552608, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.0006664555985480547}, {"id": 153, "seek": 100390, "start": 1004.22, "end": 1011.22, "text": " and efficient, a lot quicker to do this kind of work. So with the same task, again, as", "tokens": [50380, 293, 7148, 11, 257, 688, 16255, 281, 360, 341, 733, 295, 589, 13, 407, 365, 264, 912, 5633, 11, 797, 11, 382, 50730], "temperature": 0.0, "avg_logprob": -0.17151862972385282, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.000709273386746645}, {"id": 154, "seek": 100390, "start": 1011.5, "end": 1018.5, "text": " I mentioned before, the original program, 23 microseconds with ptrace 2.3 actual seconds", "tokens": [50744, 286, 2835, 949, 11, 264, 3380, 1461, 11, 6673, 3123, 37841, 28750, 365, 280, 6903, 617, 568, 13, 18, 3539, 3949, 51094], "temperature": 0.0, "avg_logprob": -0.17151862972385282, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.000709273386746645}, {"id": 155, "seek": 100390, "start": 1018.54, "end": 1024.58, "text": " and with the EBPF based tracing, we have like 683 microseconds, which is still measurable", "tokens": [51096, 293, 365, 264, 50148, 47, 37, 2361, 25262, 11, 321, 362, 411, 23317, 18, 3123, 37841, 28750, 11, 597, 307, 920, 43615, 51398], "temperature": 0.0, "avg_logprob": -0.17151862972385282, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.000709273386746645}, {"id": 156, "seek": 100390, "start": 1024.58, "end": 1031.58, "text": " overhead but significantly less than the traditional method of doing it. So I've been", "tokens": [51398, 19922, 457, 10591, 1570, 813, 264, 5164, 3170, 295, 884, 309, 13, 407, 286, 600, 668, 51748], "temperature": 0.0, "avg_logprob": -0.17151862972385282, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.000709273386746645}, {"id": 157, "seek": 103158, "start": 1032.22, "end": 1039.22, "text": " talking about this technology a lot, EBPF, EBPF, EBPF, right? But what actually is it?", "tokens": [50396, 1417, 466, 341, 2899, 257, 688, 11, 50148, 47, 37, 11, 50148, 47, 37, 11, 50148, 47, 37, 11, 558, 30, 583, 437, 767, 307, 309, 30, 50746], "temperature": 0.0, "avg_logprob": -0.16626730480709592, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.000588292779866606}, {"id": 158, "seek": 103158, "start": 1040.3799999999999, "end": 1047.3799999999999, "text": " So EBPF is a technology that enables the kernel to run sandbox programs directly. So EBPF", "tokens": [50804, 407, 50148, 47, 37, 307, 257, 2899, 300, 17077, 264, 28256, 281, 1190, 42115, 4268, 3838, 13, 407, 50148, 47, 37, 51154], "temperature": 0.0, "avg_logprob": -0.16626730480709592, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.000588292779866606}, {"id": 159, "seek": 103158, "start": 1050.74, "end": 1056.78, "text": " programs are written primarily in like a limited C. I'll get into some of the limitations", "tokens": [51322, 4268, 366, 3720, 10029, 294, 411, 257, 5567, 383, 13, 286, 603, 483, 666, 512, 295, 264, 15705, 51624], "temperature": 0.0, "avg_logprob": -0.16626730480709592, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.000588292779866606}, {"id": 160, "seek": 105678, "start": 1056.78, "end": 1063.78, "text": " later. But it gets compiled to a bytecode, loaded into the kernel where it's executed", "tokens": [50364, 1780, 13, 583, 309, 2170, 36548, 281, 257, 40846, 22332, 11, 13210, 666, 264, 28256, 689, 309, 311, 17577, 50714], "temperature": 0.0, "avg_logprob": -0.12855709592501322, "compression_ratio": 1.5, "no_speech_prob": 0.001987204886972904}, {"id": 161, "seek": 105678, "start": 1064.1, "end": 1071.1, "text": " and jaded as it's ran. And it has a lot of use cases, observability, networking, debugging", "tokens": [50730, 293, 361, 12777, 382, 309, 311, 5872, 13, 400, 309, 575, 257, 688, 295, 764, 3331, 11, 9951, 2310, 11, 17985, 11, 45592, 51080], "temperature": 0.0, "avg_logprob": -0.12855709592501322, "compression_ratio": 1.5, "no_speech_prob": 0.001987204886972904}, {"id": 162, "seek": 105678, "start": 1072.26, "end": 1076.22, "text": " and a lot more. So you'll hear a lot about EBPF. I'm sure a lot of folks in this room", "tokens": [51138, 293, 257, 688, 544, 13, 407, 291, 603, 1568, 257, 688, 466, 50148, 47, 37, 13, 286, 478, 988, 257, 688, 295, 4024, 294, 341, 1808, 51336], "temperature": 0.0, "avg_logprob": -0.12855709592501322, "compression_ratio": 1.5, "no_speech_prob": 0.001987204886972904}, {"id": 163, "seek": 105678, "start": 1076.22, "end": 1083.22, "text": " have already heard of it in some shape or another. Typically, it started as a technology", "tokens": [51336, 362, 1217, 2198, 295, 309, 294, 512, 3909, 420, 1071, 13, 23129, 11, 309, 1409, 382, 257, 2899, 51686], "temperature": 0.0, "avg_logprob": -0.12855709592501322, "compression_ratio": 1.5, "no_speech_prob": 0.001987204886972904}, {"id": 164, "seek": 108322, "start": 1083.3, "end": 1089.8, "text": " for networking and kind of ballooned from there. So originally it was like BPF, which", "tokens": [50368, 337, 17985, 293, 733, 295, 16994, 292, 490, 456, 13, 407, 7993, 309, 390, 411, 40533, 37, 11, 597, 50693], "temperature": 0.0, "avg_logprob": -0.12697432591364935, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.001431731041520834}, {"id": 165, "seek": 108322, "start": 1089.8, "end": 1096.8, "text": " is Berkeley packet filtering, and it came into extended Berkeley packet filtering. And", "tokens": [50693, 307, 23684, 20300, 30822, 11, 293, 309, 1361, 666, 10913, 23684, 20300, 30822, 13, 400, 51043], "temperature": 0.0, "avg_logprob": -0.12697432591364935, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.001431731041520834}, {"id": 166, "seek": 108322, "start": 1097.38, "end": 1101.42, "text": " now the acronym doesn't really mean anything anymore. EBPF is just EBPF because it's way", "tokens": [51072, 586, 264, 39195, 1177, 380, 534, 914, 1340, 3602, 13, 50148, 47, 37, 307, 445, 50148, 47, 37, 570, 309, 311, 636, 51274], "temperature": 0.0, "avg_logprob": -0.12697432591364935, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.001431731041520834}, {"id": 167, "seek": 108322, "start": 1101.42, "end": 1107.78, "text": " more than just what it originally was. And the cool thing is these programs that are", "tokens": [51274, 544, 813, 445, 437, 309, 7993, 390, 13, 400, 264, 1627, 551, 307, 613, 4268, 300, 366, 51592], "temperature": 0.0, "avg_logprob": -0.12697432591364935, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.001431731041520834}, {"id": 168, "seek": 108322, "start": 1107.78, "end": 1111.22, "text": " loaded in the kernel, they can be triggered by certain events. And I'll talk about how", "tokens": [51592, 13210, 294, 264, 28256, 11, 436, 393, 312, 21710, 538, 1629, 3931, 13, 400, 286, 603, 751, 466, 577, 51764], "temperature": 0.0, "avg_logprob": -0.12697432591364935, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.001431731041520834}, {"id": 169, "seek": 111122, "start": 1111.9, "end": 1118.9, "text": " we can trigger those events ourselves, but they run in response to something happening.", "tokens": [50398, 321, 393, 7875, 729, 3931, 4175, 11, 457, 436, 1190, 294, 4134, 281, 746, 2737, 13, 50748], "temperature": 0.0, "avg_logprob": -0.1149219586299016, "compression_ratio": 1.4395604395604396, "no_speech_prob": 0.0002165136393159628}, {"id": 170, "seek": 111122, "start": 1121.74, "end": 1128.24, "text": " So why is EBPF so fast in comparison to the way that we're traditionally doing things?", "tokens": [50890, 407, 983, 307, 50148, 47, 37, 370, 2370, 294, 9660, 281, 264, 636, 300, 321, 434, 19067, 884, 721, 30, 51215], "temperature": 0.0, "avg_logprob": -0.1149219586299016, "compression_ratio": 1.4395604395604396, "no_speech_prob": 0.0002165136393159628}, {"id": 171, "seek": 111122, "start": 1128.24, "end": 1135.24, "text": " The first thing is these EBPF programs run in the kernel. So there's a lot less context", "tokens": [51215, 440, 700, 551, 307, 613, 50148, 47, 37, 4268, 1190, 294, 264, 28256, 13, 407, 456, 311, 257, 688, 1570, 4319, 51565], "temperature": 0.0, "avg_logprob": -0.1149219586299016, "compression_ratio": 1.4395604395604396, "no_speech_prob": 0.0002165136393159628}, {"id": 172, "seek": 113524, "start": 1135.44, "end": 1142.44, "text": " switching overhead. We're already in the kernel, so we don't have to keep asking the kernel", "tokens": [50374, 16493, 19922, 13, 492, 434, 1217, 294, 264, 28256, 11, 370, 321, 500, 380, 362, 281, 1066, 3365, 264, 28256, 50724], "temperature": 0.0, "avg_logprob": -0.12278490288313045, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.0003150025149807334}, {"id": 173, "seek": 113524, "start": 1142.44, "end": 1149.44, "text": " for more and more and more information to get what we actually want. Relative to traditional", "tokens": [50724, 337, 544, 293, 544, 293, 544, 1589, 281, 483, 437, 321, 767, 528, 13, 8738, 1166, 281, 5164, 51074], "temperature": 0.0, "avg_logprob": -0.12278490288313045, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.0003150025149807334}, {"id": 174, "seek": 113524, "start": 1149.44, "end": 1156.24, "text": " sys call and a bunch of sys calls, the context switching is a lot cheaper. You get small", "tokens": [51074, 262, 749, 818, 293, 257, 3840, 295, 262, 749, 5498, 11, 264, 4319, 16493, 307, 257, 688, 12284, 13, 509, 483, 1359, 51414], "temperature": 0.0, "avg_logprob": -0.12278490288313045, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.0003150025149807334}, {"id": 175, "seek": 113524, "start": 1156.24, "end": 1163.24, "text": " targeted programs that, again, execute really quickly and can do everything that you need", "tokens": [51414, 15045, 4268, 300, 11, 797, 11, 14483, 534, 2661, 293, 393, 360, 1203, 300, 291, 643, 51764], "temperature": 0.0, "avg_logprob": -0.12278490288313045, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.0003150025149807334}, {"id": 176, "seek": 116324, "start": 1164.24, "end": 1171.24, "text": " or want to do in essentially one shot. And a single program can execute many tasks that", "tokens": [50414, 420, 528, 281, 360, 294, 4476, 472, 3347, 13, 400, 257, 2167, 1461, 393, 14483, 867, 9608, 300, 50764], "temperature": 0.0, "avg_logprob": -0.1688023567199707, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.0007552303723059595}, {"id": 177, "seek": 116324, "start": 1171.8, "end": 1178.8, "text": " we would traditionally use multiple ptrace calls for. So you have access to the current", "tokens": [50792, 321, 576, 19067, 764, 3866, 280, 6903, 617, 5498, 337, 13, 407, 291, 362, 2105, 281, 264, 2190, 51142], "temperature": 0.0, "avg_logprob": -0.1688023567199707, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.0007552303723059595}, {"id": 178, "seek": 116324, "start": 1178.92, "end": 1185.92, "text": " registers, you can read memory, and a lot of other things like that.", "tokens": [51148, 38351, 11, 291, 393, 1401, 4675, 11, 293, 257, 688, 295, 661, 721, 411, 300, 13, 51498], "temperature": 0.0, "avg_logprob": -0.1688023567199707, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.0007552303723059595}, {"id": 179, "seek": 118592, "start": 1186.92, "end": 1193.92, "text": " Now, when I was looking to implement this backend, I had a few requirements that I wanted", "tokens": [50414, 823, 11, 562, 286, 390, 1237, 281, 4445, 341, 38087, 11, 286, 632, 257, 1326, 7728, 300, 286, 1415, 50764], "temperature": 0.0, "avg_logprob": -0.13210419858439584, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.0007319962605834007}, {"id": 180, "seek": 118592, "start": 1194.16, "end": 1200.92, "text": " to make sure can be satisfied with this EBPF-based approach. So the first one was the ability", "tokens": [50776, 281, 652, 988, 393, 312, 11239, 365, 341, 50148, 47, 37, 12, 6032, 3109, 13, 407, 264, 700, 472, 390, 264, 3485, 51114], "temperature": 0.0, "avg_logprob": -0.13210419858439584, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.0007319962605834007}, {"id": 181, "seek": 118592, "start": 1200.92, "end": 1206.24, "text": " to trace arbitrary functions. As a user, you just want to say, I want to trace everything", "tokens": [51114, 281, 13508, 23211, 6828, 13, 1018, 257, 4195, 11, 291, 445, 528, 281, 584, 11, 286, 528, 281, 13508, 1203, 51380], "temperature": 0.0, "avg_logprob": -0.13210419858439584, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.0007319962605834007}, {"id": 182, "seek": 118592, "start": 1206.24, "end": 1213.24, "text": " in the main package or I want to trace this specific function or whatever. This new backend", "tokens": [51380, 294, 264, 2135, 7372, 420, 286, 528, 281, 13508, 341, 2685, 2445, 420, 2035, 13, 639, 777, 38087, 51730], "temperature": 0.0, "avg_logprob": -0.13210419858439584, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.0007319962605834007}, {"id": 183, "seek": 121324, "start": 1213.4, "end": 1218.8, "text": " had to be able to satisfy that requirement as well. We had to be able to retrieve the", "tokens": [50372, 632, 281, 312, 1075, 281, 19319, 300, 11695, 382, 731, 13, 492, 632, 281, 312, 1075, 281, 30254, 264, 50642], "temperature": 0.0, "avg_logprob": -0.19099222958742917, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0003799154656007886}, {"id": 184, "seek": 121324, "start": 1218.8, "end": 1225.8, "text": " GoRoutine ID from within the EBPF program. We had to be able to read function input arguments", "tokens": [50642, 1037, 49, 45075, 7348, 490, 1951, 264, 50148, 47, 37, 1461, 13, 492, 632, 281, 312, 1075, 281, 1401, 2445, 4846, 12869, 50992], "temperature": 0.0, "avg_logprob": -0.19099222958742917, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0003799154656007886}, {"id": 185, "seek": 121324, "start": 1226.84, "end": 1233.84, "text": " and we had to be able to read function return arguments. Now, let's talk a little bit about", "tokens": [51044, 293, 321, 632, 281, 312, 1075, 281, 1401, 2445, 2736, 12869, 13, 823, 11, 718, 311, 751, 257, 707, 857, 466, 51394], "temperature": 0.0, "avg_logprob": -0.19099222958742917, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0003799154656007886}, {"id": 186, "seek": 121324, "start": 1235.08, "end": 1242.08, "text": " tracing arbitrary functions. So, just as a little bit of background, how DELV has been", "tokens": [51456, 25262, 23211, 6828, 13, 407, 11, 445, 382, 257, 707, 857, 295, 3678, 11, 577, 413, 3158, 53, 575, 668, 51806], "temperature": 0.0, "avg_logprob": -0.19099222958742917, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0003799154656007886}, {"id": 187, "seek": 124324, "start": 1243.24, "end": 1248.84, "text": " used is EBPF from the Go side of things is we use the Cilium EBPF package. There's a", "tokens": [50364, 1143, 307, 50148, 47, 37, 490, 264, 1037, 1252, 295, 721, 307, 321, 764, 264, 383, 388, 2197, 50148, 47, 37, 7372, 13, 821, 311, 257, 50644], "temperature": 0.0, "avg_logprob": -0.2297976567195012, "compression_ratio": 1.5605381165919283, "no_speech_prob": 0.0023585399612784386}, {"id": 188, "seek": 124324, "start": 1248.84, "end": 1255.84, "text": " few other Go-based EBPF packages out there. Originally, I implemented using one from", "tokens": [50644, 1326, 661, 1037, 12, 6032, 50148, 47, 37, 17401, 484, 456, 13, 28696, 11, 286, 12270, 1228, 472, 490, 50994], "temperature": 0.0, "avg_logprob": -0.2297976567195012, "compression_ratio": 1.5605381165919283, "no_speech_prob": 0.0023585399612784386}, {"id": 189, "seek": 124324, "start": 1257.8, "end": 1264.8, "text": " Aqua Security but ended up switching to Cilium for a few various different reasons. But the", "tokens": [51092, 45591, 11164, 457, 4590, 493, 16493, 281, 383, 388, 2197, 337, 257, 1326, 3683, 819, 4112, 13, 583, 264, 51442], "temperature": 0.0, "avg_logprob": -0.2297976567195012, "compression_ratio": 1.5605381165919283, "no_speech_prob": 0.0023585399612784386}, {"id": 190, "seek": 124324, "start": 1266.64, "end": 1269.88, "text": " first thing that we need to do when we're tracing these arbitrary functions is we need", "tokens": [51534, 700, 551, 300, 321, 643, 281, 360, 562, 321, 434, 25262, 613, 23211, 6828, 307, 321, 643, 51696], "temperature": 0.0, "avg_logprob": -0.2297976567195012, "compression_ratio": 1.5605381165919283, "no_speech_prob": 0.0023585399612784386}, {"id": 191, "seek": 126988, "start": 1269.92, "end": 1275.0400000000002, "text": " to first load the EBPF program into the kernel so that we can start triggering it with some", "tokens": [50366, 281, 700, 3677, 264, 50148, 47, 37, 1461, 666, 264, 28256, 370, 300, 321, 393, 722, 40406, 309, 365, 512, 50622], "temperature": 0.0, "avg_logprob": -0.18400770684947138, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.0008827651618048549}, {"id": 192, "seek": 126988, "start": 1275.0400000000002, "end": 1282.0400000000002, "text": " of these events. Once we've loaded the EBPF program, we attach U-probes to each symbol.", "tokens": [50622, 295, 613, 3931, 13, 3443, 321, 600, 13210, 264, 50148, 47, 37, 1461, 11, 321, 5085, 624, 12, 4318, 6446, 281, 1184, 5986, 13, 50972], "temperature": 0.0, "avg_logprob": -0.18400770684947138, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.0008827651618048549}, {"id": 193, "seek": 126988, "start": 1283.3200000000002, "end": 1288.5600000000002, "text": " This slide is actually a little bit outdated because we don't actually use U-rep probes.", "tokens": [51036, 639, 4137, 307, 767, 257, 707, 857, 36313, 570, 321, 500, 380, 767, 764, 624, 12, 19919, 1239, 279, 13, 51298], "temperature": 0.0, "avg_logprob": -0.18400770684947138, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.0008827651618048549}, {"id": 194, "seek": 126988, "start": 1288.5600000000002, "end": 1295.5600000000002, "text": " U-probes can be attached arbitrarily to different addresses and things like that within the", "tokens": [51298, 624, 12, 4318, 6446, 393, 312, 8570, 19071, 3289, 281, 819, 16862, 293, 721, 411, 300, 1951, 264, 51648], "temperature": 0.0, "avg_logprob": -0.18400770684947138, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.0008827651618048549}, {"id": 195, "seek": 129556, "start": 1295.96, "end": 1302.96, "text": " binary. U-rep probes are typically used to hook into the return of a function, which", "tokens": [50384, 17434, 13, 624, 12, 19919, 1239, 279, 366, 5850, 1143, 281, 6328, 666, 264, 2736, 295, 257, 2445, 11, 597, 50734], "temperature": 0.0, "avg_logprob": -0.21914019791976266, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.0035913779865950346}, {"id": 196, "seek": 129556, "start": 1303.56, "end": 1307.76, "text": " seems like something that would be super, super useful. In theory, it is, but with Go,", "tokens": [50764, 2544, 411, 746, 300, 576, 312, 1687, 11, 1687, 4420, 13, 682, 5261, 11, 309, 307, 11, 457, 365, 1037, 11, 50974], "temperature": 0.0, "avg_logprob": -0.21914019791976266, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.0035913779865950346}, {"id": 197, "seek": 129556, "start": 1307.76, "end": 1314.76, "text": " it doesn't work very well because of how Go manages Go-routine stacks. When Go has to", "tokens": [50974, 309, 1177, 380, 589, 588, 731, 570, 295, 577, 1037, 22489, 1037, 12, 81, 45075, 30792, 13, 1133, 1037, 575, 281, 51324], "temperature": 0.0, "avg_logprob": -0.21914019791976266, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.0035913779865950346}, {"id": 198, "seek": 129556, "start": 1316.96, "end": 1323.96, "text": " inspect the stack, it reads up the stack to unwind it a little bit, and then we can", "tokens": [51434, 15018, 264, 8630, 11, 309, 15700, 493, 264, 8630, 281, 517, 12199, 309, 257, 707, 857, 11, 293, 550, 321, 393, 51784], "temperature": 0.0, "avg_logprob": -0.21914019791976266, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.0035913779865950346}, {"id": 199, "seek": 132556, "start": 1325.9199999999998, "end": 1331.52, "text": " if it sees anything that doesn't look right, it'll panic. U-rep probes work by overwriting", "tokens": [50382, 498, 309, 8194, 1340, 300, 1177, 380, 574, 558, 11, 309, 603, 14783, 13, 624, 12, 19919, 1239, 279, 589, 538, 670, 19868, 50662], "temperature": 0.0, "avg_logprob": -0.14198206807230854, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0003100730828009546}, {"id": 200, "seek": 132556, "start": 1331.52, "end": 1338.52, "text": " the return address of the function that we're trying to probe. Go notices that during its", "tokens": [50662, 264, 2736, 2985, 295, 264, 2445, 300, 321, 434, 1382, 281, 22715, 13, 1037, 32978, 300, 1830, 1080, 51012], "temperature": 0.0, "avg_logprob": -0.14198206807230854, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0003100730828009546}, {"id": 201, "seek": 132556, "start": 1341.76, "end": 1348.76, "text": " runtime work and freaks out. We just use U-probes. Again, we want to do as much in the kernel", "tokens": [51174, 34474, 589, 293, 2130, 5461, 484, 13, 492, 445, 764, 624, 12, 4318, 6446, 13, 3764, 11, 321, 528, 281, 360, 382, 709, 294, 264, 28256, 51524], "temperature": 0.0, "avg_logprob": -0.14198206807230854, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0003100730828009546}, {"id": 202, "seek": 132556, "start": 1349.2, "end": 1355.2, "text": " as possible to limit overhead. We have to communicate function argument and return values", "tokens": [51546, 382, 1944, 281, 4948, 19922, 13, 492, 362, 281, 7890, 2445, 6770, 293, 2736, 4190, 51846], "temperature": 0.0, "avg_logprob": -0.14198206807230854, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0003100730828009546}, {"id": 203, "seek": 135556, "start": 1356.32, "end": 1363.32, "text": " to the EBPF program and get those values back from the EBPF program. First, we load", "tokens": [50402, 281, 264, 50148, 47, 37, 1461, 293, 483, 729, 4190, 646, 490, 264, 50148, 47, 37, 1461, 13, 2386, 11, 321, 3677, 50752], "temperature": 0.0, "avg_logprob": -0.1457227443126922, "compression_ratio": 1.7135922330097086, "no_speech_prob": 0.000511131074745208}, {"id": 204, "seek": 135556, "start": 1363.72, "end": 1369.3999999999999, "text": " it. First thing we have to do is write the EBPF program. Second thing, compile the program", "tokens": [50772, 309, 13, 2386, 551, 321, 362, 281, 360, 307, 2464, 264, 50148, 47, 37, 1461, 13, 5736, 551, 11, 31413, 264, 1461, 51056], "temperature": 0.0, "avg_logprob": -0.1457227443126922, "compression_ratio": 1.7135922330097086, "no_speech_prob": 0.000511131074745208}, {"id": 205, "seek": 135556, "start": 1369.3999999999999, "end": 1374.44, "text": " and generate some helpers. This is what the Sillian package helps us with. Then we have", "tokens": [51056, 293, 8460, 512, 854, 433, 13, 639, 307, 437, 264, 318, 373, 952, 7372, 3665, 505, 365, 13, 1396, 321, 362, 51308], "temperature": 0.0, "avg_logprob": -0.1457227443126922, "compression_ratio": 1.7135922330097086, "no_speech_prob": 0.000511131074745208}, {"id": 206, "seek": 135556, "start": 1374.44, "end": 1379.6799999999998, "text": " to load the programs into the kernel. These are actually links. I'll publish these slides.", "tokens": [51308, 281, 3677, 264, 4268, 666, 264, 28256, 13, 1981, 366, 767, 6123, 13, 286, 603, 11374, 613, 9788, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1457227443126922, "compression_ratio": 1.7135922330097086, "no_speech_prob": 0.000511131074745208}, {"id": 207, "seek": 137968, "start": 1379.68, "end": 1386.68, "text": " You can follow along at home, but I'll show a little bit of the code here. This is an", "tokens": [50364, 509, 393, 1524, 2051, 412, 1280, 11, 457, 286, 603, 855, 257, 707, 857, 295, 264, 3089, 510, 13, 639, 307, 364, 50714], "temperature": 0.0, "avg_logprob": -0.15257853269577026, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.0062885582447052}, {"id": 208, "seek": 137968, "start": 1386.76, "end": 1393.76, "text": " example of the EBPF program that we use, written in C, basically. We have access to a bunch", "tokens": [50718, 1365, 295, 264, 50148, 47, 37, 1461, 300, 321, 764, 11, 3720, 294, 383, 11, 1936, 13, 492, 362, 2105, 281, 257, 3840, 51068], "temperature": 0.0, "avg_logprob": -0.15257853269577026, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.0062885582447052}, {"id": 209, "seek": 137968, "start": 1398.24, "end": 1404.48, "text": " of different EBPF-based data structures, like maps, ring buffers. These are just different", "tokens": [51292, 295, 819, 50148, 47, 37, 12, 6032, 1412, 9227, 11, 411, 11317, 11, 4875, 9204, 433, 13, 1981, 366, 445, 819, 51604], "temperature": 0.0, "avg_logprob": -0.15257853269577026, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.0062885582447052}, {"id": 210, "seek": 137968, "start": 1404.48, "end": 1408.5600000000002, "text": " ways to be able to communicate with the EBPF program running in the kernel and the Go program", "tokens": [51604, 2098, 281, 312, 1075, 281, 7890, 365, 264, 50148, 47, 37, 1461, 2614, 294, 264, 28256, 293, 264, 1037, 1461, 51808], "temperature": 0.0, "avg_logprob": -0.15257853269577026, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.0062885582447052}, {"id": 211, "seek": 140856, "start": 1408.96, "end": 1415.96, "text": " that's running in user space. I won't go through all of this exhaustively for time, but again,", "tokens": [50384, 300, 311, 2614, 294, 4195, 1901, 13, 286, 1582, 380, 352, 807, 439, 295, 341, 14687, 3413, 337, 565, 11, 457, 797, 11, 50734], "temperature": 0.0, "avg_logprob": -0.1730736782676295, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.0004654006042983383}, {"id": 212, "seek": 140856, "start": 1416.44, "end": 1422.48, "text": " if you want to look at it yourself, go ahead and follow the link. The second thing that", "tokens": [50758, 498, 291, 528, 281, 574, 412, 309, 1803, 11, 352, 2286, 293, 1524, 264, 2113, 13, 440, 1150, 551, 300, 51060], "temperature": 0.0, "avg_logprob": -0.1730736782676295, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.0004654006042983383}, {"id": 213, "seek": 140856, "start": 1422.48, "end": 1427.32, "text": " we have to do is go ahead and actually compile this EBPF program and make it usable from", "tokens": [51060, 321, 362, 281, 360, 307, 352, 2286, 293, 767, 31413, 341, 50148, 47, 37, 1461, 293, 652, 309, 29975, 490, 51302], "temperature": 0.0, "avg_logprob": -0.1730736782676295, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.0004654006042983383}, {"id": 214, "seek": 140856, "start": 1427.32, "end": 1433.04, "text": " Go. The Sillian EBPF package has a really nice helper that you can just use with Go", "tokens": [51302, 1037, 13, 440, 318, 373, 952, 50148, 47, 37, 7372, 575, 257, 534, 1481, 36133, 300, 291, 393, 445, 764, 365, 1037, 51588], "temperature": 0.0, "avg_logprob": -0.1730736782676295, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.0004654006042983383}, {"id": 215, "seek": 143304, "start": 1433.12, "end": 1438.28, "text": " Generate to be able to compile the object file that is your EBPF program. It generates", "tokens": [50368, 15409, 473, 281, 312, 1075, 281, 31413, 264, 2657, 3991, 300, 307, 428, 50148, 47, 37, 1461, 13, 467, 23815, 50626], "temperature": 0.0, "avg_logprob": -0.1474453186502262, "compression_ratio": 1.7192118226600985, "no_speech_prob": 0.0037635299377143383}, {"id": 216, "seek": 143304, "start": 1438.28, "end": 1442.6399999999999, "text": " a bunch of helpers for you that you can call to be able to load it and interact with that", "tokens": [50626, 257, 3840, 295, 854, 433, 337, 291, 300, 291, 393, 818, 281, 312, 1075, 281, 3677, 309, 293, 4648, 365, 300, 50844], "temperature": 0.0, "avg_logprob": -0.1474453186502262, "compression_ratio": 1.7192118226600985, "no_speech_prob": 0.0037635299377143383}, {"id": 217, "seek": 143304, "start": 1442.6399999999999, "end": 1449.6399999999999, "text": " EBPF program. Then finally, we have to load the EBPF program into the kernel. Again, the", "tokens": [50844, 50148, 47, 37, 1461, 13, 1396, 2721, 11, 321, 362, 281, 3677, 264, 50148, 47, 37, 1461, 666, 264, 28256, 13, 3764, 11, 264, 51194], "temperature": 0.0, "avg_logprob": -0.1474453186502262, "compression_ratio": 1.7192118226600985, "no_speech_prob": 0.0037635299377143383}, {"id": 218, "seek": 143304, "start": 1454.72, "end": 1461.72, "text": " Sillian EBPF library has a ton of helpers to be able to facilitate that. We open up", "tokens": [51448, 318, 373, 952, 50148, 47, 37, 6405, 575, 257, 2952, 295, 854, 433, 281, 312, 1075, 281, 20207, 300, 13, 492, 1269, 493, 51798], "temperature": 0.0, "avg_logprob": -0.1474453186502262, "compression_ratio": 1.7192118226600985, "no_speech_prob": 0.0037635299377143383}, {"id": 219, "seek": 146172, "start": 1462.4, "end": 1469.4, "text": " the executable that represents the process that we're debugging. We call this helper that", "tokens": [50398, 264, 7568, 712, 300, 8855, 264, 1399, 300, 321, 434, 45592, 13, 492, 818, 341, 36133, 300, 50748], "temperature": 0.0, "avg_logprob": -0.1600672114979137, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.00014418929640669376}, {"id": 220, "seek": 146172, "start": 1469.68, "end": 1475.1200000000001, "text": " the package generated for us. Then we initialize some of the things that we need to do, like", "tokens": [50762, 264, 7372, 10833, 337, 505, 13, 1396, 321, 5883, 1125, 512, 295, 264, 721, 300, 321, 643, 281, 360, 11, 411, 51034], "temperature": 0.0, "avg_logprob": -0.1600672114979137, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.00014418929640669376}, {"id": 221, "seek": 146172, "start": 1475.1200000000001, "end": 1482.1200000000001, "text": " the ring buffer and the map data structure that we use to pass values back and forth.", "tokens": [51034, 264, 4875, 21762, 293, 264, 4471, 1412, 3877, 300, 321, 764, 281, 1320, 4190, 646, 293, 5220, 13, 51384], "temperature": 0.0, "avg_logprob": -0.1600672114979137, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.00014418929640669376}, {"id": 222, "seek": 146172, "start": 1484.88, "end": 1491.38, "text": " The next thing we have to do is attach our U probes. First, we find an offset to attach", "tokens": [51522, 440, 958, 551, 321, 362, 281, 360, 307, 5085, 527, 624, 1239, 279, 13, 2386, 11, 321, 915, 364, 18687, 281, 5085, 51847], "temperature": 0.0, "avg_logprob": -0.1600672114979137, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.00014418929640669376}, {"id": 223, "seek": 149138, "start": 1491.5800000000002, "end": 1498.5800000000002, "text": " to, we attach the probe to that offset, and then we go from there. We have a little helper", "tokens": [50374, 281, 11, 321, 5085, 264, 22715, 281, 300, 18687, 11, 293, 550, 321, 352, 490, 456, 13, 492, 362, 257, 707, 36133, 50724], "temperature": 0.0, "avg_logprob": -0.21935201727825662, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.00021988483786117285}, {"id": 224, "seek": 149138, "start": 1501.18, "end": 1508.18, "text": " here to take an address within the program to an offset. The offset is just like an offset", "tokens": [50854, 510, 281, 747, 364, 2985, 1951, 264, 1461, 281, 364, 18687, 13, 440, 18687, 307, 445, 411, 364, 18687, 51204], "temperature": 0.0, "avg_logprob": -0.21935201727825662, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.00021988483786117285}, {"id": 225, "seek": 149138, "start": 1508.66, "end": 1515.66, "text": " within the binary itself as it's loaded into memory. Then from there, we attach our probe.", "tokens": [51228, 1951, 264, 17434, 2564, 382, 309, 311, 13210, 666, 4675, 13, 1396, 490, 456, 11, 321, 5085, 527, 22715, 13, 51578], "temperature": 0.0, "avg_logprob": -0.21935201727825662, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.00021988483786117285}, {"id": 226, "seek": 151566, "start": 1516.66, "end": 1523.66, "text": " Then from there, we attach our probe. It's as simple as the executable that we opened", "tokens": [50414, 1396, 490, 456, 11, 321, 5085, 527, 22715, 13, 467, 311, 382, 2199, 382, 264, 7568, 712, 300, 321, 5625, 50764], "temperature": 0.0, "avg_logprob": -0.1434696761655136, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.0005975638050585985}, {"id": 227, "seek": 151566, "start": 1524.1000000000001, "end": 1531.1000000000001, "text": " earlier. We have that attached to this EBPF context here. We just call this U probe method", "tokens": [50786, 3071, 13, 492, 362, 300, 8570, 281, 341, 50148, 47, 37, 4319, 510, 13, 492, 445, 818, 341, 624, 22715, 3170, 51136], "temperature": 0.0, "avg_logprob": -0.1434696761655136, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.0005975638050585985}, {"id": 228, "seek": 151566, "start": 1531.8600000000001, "end": 1538.8600000000001, "text": " and pass it the offset and the PID. The nice thing about this is you pass along the PID", "tokens": [51174, 293, 1320, 309, 264, 18687, 293, 264, 430, 2777, 13, 440, 1481, 551, 466, 341, 307, 291, 1320, 2051, 264, 430, 2777, 51524], "temperature": 0.0, "avg_logprob": -0.1434696761655136, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.0005975638050585985}, {"id": 229, "seek": 153886, "start": 1539.86, "end": 1545.86, "text": " so that this EBPF program is constrained to just the process that you're trying to debug,", "tokens": [50414, 370, 300, 341, 50148, 47, 37, 1461, 307, 38901, 281, 445, 264, 1399, 300, 291, 434, 1382, 281, 24083, 11, 50714], "temperature": 0.0, "avg_logprob": -0.16759222972242138, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.0002531283535063267}, {"id": 230, "seek": 153886, "start": 1545.86, "end": 1551.86, "text": " because these programs that you load in are actually global, so they're not really by", "tokens": [50714, 570, 613, 4268, 300, 291, 3677, 294, 366, 767, 4338, 11, 370, 436, 434, 406, 534, 538, 51014], "temperature": 0.0, "avg_logprob": -0.16759222972242138, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.0002531283535063267}, {"id": 231, "seek": 153886, "start": 1551.86, "end": 1558.86, "text": " themselves attached to any specific process. Then from there, we need to actually communicate", "tokens": [51014, 2969, 8570, 281, 604, 2685, 1399, 13, 1396, 490, 456, 11, 321, 643, 281, 767, 7890, 51364], "temperature": 0.0, "avg_logprob": -0.16759222972242138, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.0002531283535063267}, {"id": 232, "seek": 153886, "start": 1561.5, "end": 1568.5, "text": " with this program. We need to store function parameter information, and then we need to", "tokens": [51496, 365, 341, 1461, 13, 492, 643, 281, 3531, 2445, 13075, 1589, 11, 293, 550, 321, 643, 281, 51846], "temperature": 0.0, "avg_logprob": -0.16759222972242138, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.0002531283535063267}, {"id": 233, "seek": 156886, "start": 1568.86, "end": 1574.26, "text": " communicate that information with the program. I won't go too much into the code in this", "tokens": [50364, 7890, 300, 1589, 365, 264, 1461, 13, 286, 1582, 380, 352, 886, 709, 666, 264, 3089, 294, 341, 50634], "temperature": 0.0, "avg_logprob": -0.12858937295635095, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.00013132340973243117}, {"id": 234, "seek": 156886, "start": 1574.26, "end": 1581.26, "text": " for the sake of time, but essentially we need to tell the EBPF program all of the function", "tokens": [50634, 337, 264, 9717, 295, 565, 11, 457, 4476, 321, 643, 281, 980, 264, 50148, 47, 37, 1461, 439, 295, 264, 2445, 50984], "temperature": 0.0, "avg_logprob": -0.12858937295635095, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.00013132340973243117}, {"id": 235, "seek": 156886, "start": 1583.4599999999998, "end": 1588.9799999999998, "text": " argument information, the return value information, where they're located, are they on the stack,", "tokens": [51094, 6770, 1589, 11, 264, 2736, 2158, 1589, 11, 689, 436, 434, 6870, 11, 366, 436, 322, 264, 8630, 11, 51370], "temperature": 0.0, "avg_logprob": -0.12858937295635095, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.00013132340973243117}, {"id": 236, "seek": 156886, "start": 1588.9799999999998, "end": 1594.34, "text": " are they in registers, and let it know where to find it so that it can read all of this", "tokens": [51370, 366, 436, 294, 38351, 11, 293, 718, 309, 458, 689, 281, 915, 309, 370, 300, 309, 393, 1401, 439, 295, 341, 51638], "temperature": 0.0, "avg_logprob": -0.12858937295635095, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.00013132340973243117}, {"id": 237, "seek": 159434, "start": 1594.34, "end": 1601.34, "text": " information and send it back to the user space program. When we want to get the data", "tokens": [50364, 1589, 293, 2845, 309, 646, 281, 264, 4195, 1901, 1461, 13, 1133, 321, 528, 281, 483, 264, 1412, 50714], "temperature": 0.0, "avg_logprob": -0.13153397055233226, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.002471927087754011}, {"id": 238, "seek": 159434, "start": 1601.34, "end": 1607.54, "text": " back, we use a ring buffer to again communicate between user space and our program running", "tokens": [50714, 646, 11, 321, 764, 257, 4875, 21762, 281, 797, 7890, 1296, 4195, 1901, 293, 527, 1461, 2614, 51024], "temperature": 0.0, "avg_logprob": -0.13153397055233226, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.002471927087754011}, {"id": 239, "seek": 159434, "start": 1607.54, "end": 1612.4199999999998, "text": " in kernel space, and essentially it's just a stream of all of the information coming", "tokens": [51024, 294, 28256, 1901, 11, 293, 4476, 309, 311, 445, 257, 4309, 295, 439, 295, 264, 1589, 1348, 51268], "temperature": 0.0, "avg_logprob": -0.13153397055233226, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.002471927087754011}, {"id": 240, "seek": 159434, "start": 1612.4199999999998, "end": 1617.1399999999999, "text": " back, so all of the information that's being read and picked up by the EBPF program. That's", "tokens": [51268, 646, 11, 370, 439, 295, 264, 1589, 300, 311, 885, 1401, 293, 6183, 493, 538, 264, 50148, 47, 37, 1461, 13, 663, 311, 51504], "temperature": 0.0, "avg_logprob": -0.13153397055233226, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.002471927087754011}, {"id": 241, "seek": 161714, "start": 1617.14, "end": 1624.14, "text": " ultimately what gets displayed to you as we run the trace command. I'll go through another", "tokens": [50364, 6284, 437, 2170, 16372, 281, 291, 382, 321, 1190, 264, 13508, 5622, 13, 286, 603, 352, 807, 1071, 50714], "temperature": 0.0, "avg_logprob": -0.12701739727611272, "compression_ratio": 1.4972375690607735, "no_speech_prob": 0.014724750071763992}, {"id": 242, "seek": 161714, "start": 1625.8600000000001, "end": 1631.5400000000002, "text": " quick demo of actually using the EBPF backend, so all you have to do to enable it for now", "tokens": [50800, 1702, 10723, 295, 767, 1228, 264, 50148, 47, 37, 38087, 11, 370, 439, 291, 362, 281, 360, 281, 9528, 309, 337, 586, 51084], "temperature": 0.0, "avg_logprob": -0.12701739727611272, "compression_ratio": 1.4972375690607735, "no_speech_prob": 0.014724750071763992}, {"id": 243, "seek": 161714, "start": 1631.5400000000002, "end": 1638.5400000000002, "text": " is just add dash dash EBPF to the trace command, so if I run our make command here, nobody", "tokens": [51084, 307, 445, 909, 8240, 8240, 50148, 47, 37, 281, 264, 13508, 5622, 11, 370, 498, 286, 1190, 527, 652, 5622, 510, 11, 5079, 51434], "temperature": 0.0, "avg_logprob": -0.12701739727611272, "compression_ratio": 1.4972375690607735, "no_speech_prob": 0.014724750071763992}, {"id": 244, "seek": 163854, "start": 1639.1399999999999, "end": 1646.1399999999999, "text": " looking at my password. We see that the trace happens, and from here you can't really tell", "tokens": [50394, 1237, 412, 452, 11524, 13, 492, 536, 300, 264, 13508, 2314, 11, 293, 490, 510, 291, 393, 380, 534, 980, 50744], "temperature": 0.0, "avg_logprob": -0.18527542977106004, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.003648869227617979}, {"id": 245, "seek": 163854, "start": 1649.6599999999999, "end": 1654.62, "text": " that it's significantly faster, but the output is a little bit different. As I mentioned,", "tokens": [50920, 300, 309, 311, 10591, 4663, 11, 457, 264, 5598, 307, 257, 707, 857, 819, 13, 1018, 286, 2835, 11, 51168], "temperature": 0.0, "avg_logprob": -0.18527542977106004, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.003648869227617979}, {"id": 246, "seek": 163854, "start": 1654.62, "end": 1660.1, "text": " this is still kind of like an experimental work in progress backend, so some of the output", "tokens": [51168, 341, 307, 920, 733, 295, 411, 364, 17069, 589, 294, 4205, 38087, 11, 370, 512, 295, 264, 5598, 51442], "temperature": 0.0, "avg_logprob": -0.18527542977106004, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.003648869227617979}, {"id": 247, "seek": 163854, "start": 1660.1, "end": 1666.26, "text": " is a little bit different, and it doesn't have exact parity with the traditional more", "tokens": [51442, 307, 257, 707, 857, 819, 11, 293, 309, 1177, 380, 362, 1900, 44747, 365, 264, 5164, 544, 51750], "temperature": 0.0, "avg_logprob": -0.18527542977106004, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.003648869227617979}, {"id": 248, "seek": 166626, "start": 1666.3, "end": 1672.46, "text": " established tracing backend, but you can see it works. You see the arguments, the return", "tokens": [50366, 7545, 25262, 38087, 11, 457, 291, 393, 536, 309, 1985, 13, 509, 536, 264, 12869, 11, 264, 2736, 50674], "temperature": 0.0, "avg_logprob": -0.11908582623085279, "compression_ratio": 1.502092050209205, "no_speech_prob": 0.0006665924447588623}, {"id": 249, "seek": 166626, "start": 1672.46, "end": 1679.54, "text": " values, and everything like that, and this is all happening with significantly less overhead.", "tokens": [50674, 4190, 11, 293, 1203, 411, 300, 11, 293, 341, 307, 439, 2737, 365, 10591, 1570, 19922, 13, 51028], "temperature": 0.0, "avg_logprob": -0.11908582623085279, "compression_ratio": 1.502092050209205, "no_speech_prob": 0.0006665924447588623}, {"id": 250, "seek": 166626, "start": 1679.54, "end": 1684.46, "text": " So a few downsides of the EBPF approach. The programs are written in a constrained version", "tokens": [51028, 407, 257, 1326, 21554, 1875, 295, 264, 50148, 47, 37, 3109, 13, 440, 4268, 366, 3720, 294, 257, 38901, 3037, 51274], "temperature": 0.0, "avg_logprob": -0.11908582623085279, "compression_ratio": 1.502092050209205, "no_speech_prob": 0.0006665924447588623}, {"id": 251, "seek": 166626, "start": 1684.46, "end": 1690.54, "text": " of C, so you're not writing go. You end up having to fight the verifier a lot. If you", "tokens": [51274, 295, 383, 11, 370, 291, 434, 406, 3579, 352, 13, 509, 917, 493, 1419, 281, 2092, 264, 1306, 9902, 257, 688, 13, 759, 291, 51578], "temperature": 0.0, "avg_logprob": -0.11908582623085279, "compression_ratio": 1.502092050209205, "no_speech_prob": 0.0006665924447588623}, {"id": 252, "seek": 169054, "start": 1690.54, "end": 1697.54, "text": " don't know what that means, that's great for you. Congratulations. There's a lot of constraints", "tokens": [50364, 500, 380, 458, 437, 300, 1355, 11, 300, 311, 869, 337, 291, 13, 9694, 13, 821, 311, 257, 688, 295, 18491, 50714], "temperature": 0.0, "avg_logprob": -0.15373227030960554, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0024720027577131987}, {"id": 253, "seek": 169054, "start": 1699.86, "end": 1705.3799999999999, "text": " on stack sizes and stuff like that within EBPF programs, which can be kind of gnarly", "tokens": [50830, 322, 8630, 11602, 293, 1507, 411, 300, 1951, 50148, 47, 37, 4268, 11, 597, 393, 312, 733, 295, 290, 20062, 356, 51106], "temperature": 0.0, "avg_logprob": -0.15373227030960554, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0024720027577131987}, {"id": 254, "seek": 169054, "start": 1705.3799999999999, "end": 1712.3799999999999, "text": " to deal with. It's different to write some control flow, like loops and stuff like that,", "tokens": [51106, 281, 2028, 365, 13, 467, 311, 819, 281, 2464, 512, 1969, 3095, 11, 411, 16121, 293, 1507, 411, 300, 11, 51456], "temperature": 0.0, "avg_logprob": -0.15373227030960554, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0024720027577131987}, {"id": 255, "seek": 169054, "start": 1713.5, "end": 1718.94, "text": " and as I mentioned, UREP probes do not play well with go programs at all, do not use them,", "tokens": [51512, 293, 382, 286, 2835, 11, 624, 3850, 47, 1239, 279, 360, 406, 862, 731, 365, 352, 4268, 412, 439, 11, 360, 406, 764, 552, 11, 51784], "temperature": 0.0, "avg_logprob": -0.15373227030960554, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0024720027577131987}, {"id": 256, "seek": 171894, "start": 1718.94, "end": 1725.94, "text": " do not try. And that's it. Thank you very much.", "tokens": [50364, 360, 406, 853, 13, 400, 300, 311, 309, 13, 1044, 291, 588, 709, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2249449888865153, "compression_ratio": 1.4671052631578947, "no_speech_prob": 0.002169754821807146}, {"id": 257, "seek": 171894, "start": 1727.7, "end": 1734.7, "text": " Thank you. Unfortunately, we do not have time for questions, but if you see him in the hallway", "tokens": [50802, 1044, 291, 13, 8590, 11, 321, 360, 406, 362, 565, 337, 1651, 11, 457, 498, 291, 536, 796, 294, 264, 23903, 51152], "temperature": 0.0, "avg_logprob": -0.2249449888865153, "compression_ratio": 1.4671052631578947, "no_speech_prob": 0.002169754821807146}, {"id": 258, "seek": 171894, "start": 1735.66, "end": 1742.66, "text": " track, you can always ask him any questions, improvements, bug fixes, et cetera.", "tokens": [51200, 2837, 11, 291, 393, 1009, 1029, 796, 604, 1651, 11, 13797, 11, 7426, 32539, 11, 1030, 11458, 13, 51550], "temperature": 0.0, "avg_logprob": -0.2249449888865153, "compression_ratio": 1.4671052631578947, "no_speech_prob": 0.002169754821807146}, {"id": 259, "seek": 174894, "start": 1748.94, "end": 1755.94, "text": " If you leave, it's better to do so on this side. You may pause the stage, and there is", "tokens": [50364, 759, 291, 1856, 11, 309, 311, 1101, 281, 360, 370, 322, 341, 1252, 13, 509, 815, 10465, 264, 3233, 11, 293, 456, 307, 50714], "temperature": 0.0, "avg_logprob": -0.2785629945642808, "compression_ratio": 1.1649484536082475, "no_speech_prob": 0.12235967069864273}, {"id": 260, "seek": 174894, "start": 1758.26, "end": 1760.14, "text": " also a swag table diagram.", "tokens": [50830, 611, 257, 42064, 3199, 10686, 13, 50924], "temperature": 0.0, "avg_logprob": -0.2785629945642808, "compression_ratio": 1.1649484536082475, "no_speech_prob": 0.12235967069864273}], "language": "en"}