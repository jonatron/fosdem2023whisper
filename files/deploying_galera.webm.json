{"text": " So, I'm going to talk to you a little bit about deploying your Galera clusters in the real world. I'm actually very pleasantly pleased to note that a lot of you are using Galera cluster already, so that's great. I work at Codership, and before this I was also with MariaDB, MySQL, Fedora, etc. Codership makes Galera clusters, so obviously there's support, training, consulting, and so forth. The company's been around since 2007, three founders, all engineers, fully-services business model, and it's used in lots of places, from your gaming, aka gambling, also gaming, telecoms, banking, insurance, SaaS, Paz, IAS, it's literally everywhere. Since many of you already use Galera cluster, I don't actually have to maybe introduce it to all of you, but it is highly scalable. You can add nodes on the fly, you can delete nodes on the fly, this is as simple as actually just pointing the IP address of your new node to an existing node, and it should be able to sync via something known as SSD, state snapshot transfer. And from an application point of view, it still looks like one very large database. Naturally, we like you to have a minimum of three nodes, even though some have two, and some have three separated across two data centers, even though they'll claim they have very, very fast network. So if you have three databases, as we suggest, you'll have three copies of the same data as well, and so it looks like one very big database from the application point of view. You can't have any number of parallel applyer threads as well. So we have actually renamed things like, we don't call it the WSRAP slave threads any longer, we call it applyer threads. So we are following exactly what MySQL and MariaDB is doing in terms of being politically correct, I guess, though we are in Europe, so maybe this is less of a concern. So this is a point to note, because if you are actually in your config files using older configurations, when you're moving to something new, you should rename it, otherwise you're going to find that Galera will fail to start with a very poor error message in your error log, and maybe that's the other pro tip is to never disable the error log, ever, because Galera writes all messages to the error log. In fact, if you're using MySQL 57 or 80, which I presume most of you should be using in terms of a newer version of MySQL, the temporary password is inside your error log. So if you disabled it, how do you plan to start? So the error log is actually very crucial. So MariaDB, on the other hand, you can start with passwordless logins by default, but MySQL requires it. So I suggest if you're using Galera, never disable the error log like ever. We also, of course, have parallel replications, so it makes state transfers quick for new nodes. So you can actually consider just increasing the applied threads. Don't use a value of WSRAP applied threads that is higher than the average given number of what is known as the cert depth distance, the certification depth distance. You can actually see this in the status variables. We probably, as an improvement, should be able to spend more time actually going through all the WSRAP stuff that you should be paying attention to. But to some extent, we've also given that off to GUI tools to manage. Of course, we have an optimized network protocol, so packets are only exchanged over the when a transaction can be time. We have topology-aware applications, so you can actually segment things. So each transaction is sent to a separate data center actually only once. We also detect and automatically evict unreliable nodes. This has improved tremendously in Galera 4, actually. So if you have a flappy network or node failure, you don't actually need any manual intervention. We will eject. In the very unlikely event that you've configured Galera to ignore split brains, we aim to actually recover from these problems. Again, we provide these options for you, but we don't recommend you to use them. Why would you want to cause yourself grief? MySQL and MariaDB don't allow you to sync data. So if you have a split brain situation with two different sets of data, how do you plan to sync this data later? Well, you can, of course, turn on the binary logs, which we actually do recommend, at least for a short period of time, and then maybe do some replaying. If you have MariaDB, you can use the flashback capability. If you have MySQL, you can actually just replay the bin logs. So if you happen to actually lose data, and, of course, traffic encryption is something we also support, it's not turned on by default in all distributions except Percona XDB Cluster 8. If you get Percona XDB Cluster 8, traffic encryption is enabled by default. And if you're using the cloud, this is kind of key, right? Because it turns out that everything happens in, replication happens in plain text, basically. This is true even for asynchronous replication or even semi-synchronous replication. So did I just promise you a panacea for the whole world? Of course not. It does come with trade-offs, right? You are not going to be as fast as asynchronous because you're not just committing to the primary, you're committing to the primary and to other nodes. It's obviously not going to be as fast as semi-synchronous because it's not committing to one primary and one secondary. So we can't really beat the laws of physics even though you're in the same data center, which is, again, why it's such a bad idea, and we see this a lot in production where people say, we have a three-node Galera cluster in two data centers. If you want high availability, you really should invest in the money that comes from running high availability. So we've now found out that basically none of you use Code of Ships Galera cluster. And as Monty says, a lot of the features are actually pretty much inside of MariaDB Galera cluster, but there is this one interesting feature that is not made it to any other distribution that's clone SSD. SSDs that happen via the clone plugin as opposed to using the likes of Maria backup, extra backup, and unfortunately, the clone plugin doesn't run on MariaDB. So on MariaDB, you use Maria backup, which is also fast. On Percona XDB cluster, you use extra backup, which is also fast, but we found that clone is actually also pretty amazing. So we do open up a new port for it. And if you use Galera Manager, by default, if you deploy MySQL 8, we actually use clone SSD to provision your new nodes. So you should be able to see some good speed up there. It works extremely closely with MariaDB PLC, I have to say not MariaDB Corporation any longer because the company has a new name, to make a MariaDB Galera cluster. In fact, it's been around inside a developer tree since 10.1, which is around October 2014. So then it got released as a GA in October 2015 in 10.18. And you get all the features of MariaDB that work with Galera, basically. This is your Oracle support. I know there's no generic MariaDB feature talk in this entire FOSDAM, but go check out the knowledge base. I have another talk on the ecosystem later, which will give you a quick overview. But you also get the things like system version tables, sequences, all those optimizer features that Monty talked about that are coming in MariaDB 11, you just get benefit of it as well. And it was actually the first to include Galera 4 in 10.4. So if you're using 10.4, 10.5, 10.6, you're already getting Galera 4. And then, of course, there's a Pocona actually DB cluster, which another half of you actually use. Base is Pocona server. It comes with proxy SQL, including an administrative tool. It has a strict mode, which disallows MyISM tables to be replicated via Galera. Now this is an interesting thing because while Pocona actually DB cluster disallows it, MariaDB, later versions of MariaDB actually allows this. You can, since 10.6, have ARIA and MyISM replication inside of Galera cluster. We consider this kind of experimental, but it works. It's feature modes that are available. Of course, it disables tables without primary keys. Again with something like MariaDB, you can also force primary key creation. And Galera also has an option where you can sort of insert one, ensures using the row bin log format, logging to a file, obviously not tables. So there's some interesting things, setting the inner DB auto increment log mode to two, and of course, out of the box encryption. So there are some feature highlights, like intelligent donor selection. So now with Galera 3 and 4, we 3.x where we have introduced new features. You can actually now prefer a donor to do an ISD. When it comes to cluster crash recovery, we've actually by default turned on PC.recovery equals on, so all nodes will maintain the cluster information persistently, not requiring necessarily to bootstrap. We have full GTID compatibility in Galera 4 with either MariaDB or MySQL, so actually using the native GTIDs as opposed to the Galera GTIDs. So previously this was a bit of a point of contention, so this is actually a good thing. Foreign key support. When I say improved foreign key support, you'd actually, if you looked in your arrow logs and used foreign keys, you may have found that there were lots and lots of errors that were not actually errors. So cleaning up the error reporting was actually how we improved foreign key support, because lots of people were complaining like, hey, we're seeing this in the arrow logs, but it was running just fine. So it was just maybe a bit too verbose, and then we added a couple of new tables inside of the MySQL table as well. It's the WSJAP cluster, cluster members, and streaming log. Very important to remember that streaming replication, which I'll talk about probably in the next slide, actually does make use of chunking your data and putting it inside the MySQL table, so this actually improves the ability for you to use long-running transactions or large transactions, so to speak. And that's why it's in the MySQL table because permissions, right, otherwise other people are going to see what's being streamed. Next slide. So previously, you'd have to play with WSJAP Max WS rows and WSJAP Max WS size, limiting the transaction rows between 128 kilobytes to a gigabyte, maximum of two gigabytes, but now you can actually cut those large transactions by setting fragment sizes. This can be done literally at runtime, so you can set them around 10,000 rows to 20,000 rows, and your application can also obviously set streaming replication on and off on a need-by-need basis. Again, this doesn't come for free. There is naturally replication overhead, which is being improved on in every release that we come. So if you're always looking for the latest, greatest streaming replication, naturally you'd want to take a look at what's inside of MariaDB. And then, of course, there is better error handling for poor networks, so cluster error voting is a feature that has a protocol for nodes to decide how the cluster will react to problems inside of replication. So when one or several nodes have an issue to apply an incoming transaction, like a suspected inconsistency, this feature basically helps. So in a five-node cluster, if two nodes basically fail to apply a transaction, they get removed, and of course, now your DBA could go into fix to see what went wrong and then rejoin the cluster. So I know we had forced them, so this is an apology slide because, unfortunately, there are enterprise features, but I will not talk about them. This is for you to go check them out yourself. Both MariaDB and Codeship have these options. The biggest hurdle to upgrades that I hear from consulting is we don't want to migrate to MySQL 8. I don't know why people say this a lot, but if you are using MySQL, last I checked, it's going to EOL fairly soon, 5.7, so it's time to upgrade. You've got eight more months to get working. And if you want Galera 4, remember, MariaDB's had it since 10.4, but again, a lot of you are not even on the 10.4 or 10.5 train yet. So upgrading from 10.2 or 10.3 is probably something that is ideal if you can find the time to do it. Okay. Common setups. Three Galera cluster nodes in one data center. This is the highly recommended common setup. Nine Galera cluster nodes in three data centers. Also, of course, another recommended setup. And if you are doing this, make sure you are ensuring your database operations are kept local by setting each data center that GMCAST segment equals 0, 1, 2. And of course, the flow control is fully configurable. And we want to have minimal latency penalty. Remember that latency penalty only occurs during commit time, so then actually no communication between these remote nodes and Galera doesn't use distributed locking, so each row-level lock does not have to be communicated across data centers. So in very, very high latency situations where complete avoidance of secondary lag is required, we can also support asynchronous replication between two otherwise independent Galera clusters, each running in its own data center. Now I put an asterisk there with recommended because I know Marco Tusa is not here today, but he was on Friday and he has written a lot about why you should never run your Galera clusters in a wide area network. Or I guess even your group replication in IndieBee clusters in a wide area network to some extent. And he's spent quite a lot of blogs and including a video. So basically whenever you need a solution based on a tightly coupled database cluster, you can't obviously locate your nodes at a distance that is longer than the largest round-trip time of the shortest desired period of commit. Wow, five more minutes. We're going to go fast now. You should always remember that we like the minimum of three nodes basically in terms of a quorum because a quorum is greater than 50 percent, so if one node goes away you still have two thirds, 66.7. And you always want to ensure the primary component is there because otherwise if it splits due to network failure you have split brain. So this is very bad. You can fine-tune this with evs.suspectTimeout as a parameter. Very realistic common setups that we end up seeing. Two node Galera cluster, really not recommended. Even though we documented, we tell you how to shoot yourself in the foot, it doesn't mean you should. Three node Galera cluster across two data centers also common. Three node across three data centers also common. Five nodes, seven nodes. So you always have to remember the trade-offs of scalability, reliability, resilience and performance. This is a sample of my.cnf that one would want to maybe pay a bit of attention to where we actually include a WSR provider options because by default we don't put a segment for example, but you also want more than just a segment. You want to, if you're doing wide area network stuff, consider increasing the replication windows. You want to increase the timeouts above max round trip time. Look at the flow control which you can actually monitor inside. And then pay attention to the FC limit, the master slave yes, causal read, timeouts and the evs settings where you can actually set the send window to 512, the user send window to 512. You can look at the keep alive periods. We have all this actually in blogs and documentation to some extent. So I'd highly recommend you pay attention to galeracluster.com slash blog. Always set your GCash size. Potentially also set your retry autocommit, something like five. You may want to certify non-primary key stuff, but really you should use primary keys. You tell the developers to use primary keys. In fact, if you're using MariaDB, you can say in a DBforce primary key equals one. Make it such that they can't create tables any longer. Make the developers suffer a little bit. Replicate my ISM, replicate ARIA, these are all things that are very MariaDB specific. I'd like to actually talk about the ring buffer file as well as the on demand page store which is the GCash.page underscore size. But I don't think we have so much time, so consider this blog post that we will write maybe next week. Another one that I should probably mention really quickly is the arbitrator. So the arbitrator is a member of your cluster that can participate in voting, but not in the actual application. So if you want to save money, you want to have two data center setups, three nodes each. You can actually just set up the arbitrator daemon in digital ocean or line node. It doesn't have to be a powerful machine. It can just basically read traffic and act as an arbitrator. Don't use things like ignore split brain and so forth. So Garbdy can act as the odd node and he can also of course help you do backups. Plenty of proxies available. There's Galera load balancer. There's HA proxy. We have documentation for that. There's proxy SQL or talk coming up later today evening. And of course MariaDB max scale. To provision new nodes, 8.0 gives you clone SSD. Maria gives you Maria backup. Percona extra backup is still the choice inside of Percona, actually be cluster. Very common setup and runtime issues, S Linux firewall. You can't get your, you can't get a IST. Well it turns out you've probably got a port closed. Make sure port 4444 TCP is open. If you want to avoid long running queries, MySQL and MariaDB as, you know, max execution time, MariaDB as enhance kill. You've got DNS giving you problems, switch to IPs. Couple of functions for developers that may be useful. Again, you can tell the developers to check this out. It's well documented. It's widely adopted. So lots of people are going, you know, you could use it in Xflower, PowerDNS, lots of Kubernetes operators. All right, so the most exciting thing for me in MariaDB 11 from a Galera standpoint is WSWAP provider options is now a plugin. So you can actually use this from a more automated thing. I presume from a MariaDB standpoint, this helps automatically reconfigure SkySQL. So this is better for you because otherwise you have to put in my.cnf, some of it's dynamic, not all of it's dynamic, resetting a server, horrible. Got more granular, you know, few things to improve on, makes schema changes, upgrades easier. Lots of further reading. I know we've literally run out of time, 20 minutes is not a lot of time. So you can tweet me, you can send me an email, we're hiring, and yeah, we have lots of services. Thank you for listening. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.44, "text": " So, I'm going to talk to you a little bit about deploying your Galera clusters in the", "tokens": [50364, 407, 11, 286, 478, 516, 281, 751, 281, 291, 257, 707, 857, 466, 34198, 428, 7336, 1663, 23313, 294, 264, 50886], "temperature": 0.0, "avg_logprob": -0.1850603717868611, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.20917673408985138}, {"id": 1, "seek": 0, "start": 10.44, "end": 11.84, "text": " real world.", "tokens": [50886, 957, 1002, 13, 50956], "temperature": 0.0, "avg_logprob": -0.1850603717868611, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.20917673408985138}, {"id": 2, "seek": 0, "start": 11.84, "end": 16.48, "text": " I'm actually very pleasantly pleased to note that a lot of you are using Galera cluster", "tokens": [50956, 286, 478, 767, 588, 35122, 3627, 10587, 281, 3637, 300, 257, 688, 295, 291, 366, 1228, 7336, 1663, 13630, 51188], "temperature": 0.0, "avg_logprob": -0.1850603717868611, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.20917673408985138}, {"id": 3, "seek": 0, "start": 16.48, "end": 20.88, "text": " already, so that's great.", "tokens": [51188, 1217, 11, 370, 300, 311, 869, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1850603717868611, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.20917673408985138}, {"id": 4, "seek": 2088, "start": 20.88, "end": 32.44, "text": " I work at Codership, and before this I was also with MariaDB, MySQL, Fedora, etc.", "tokens": [50364, 286, 589, 412, 383, 378, 433, 1210, 11, 293, 949, 341, 286, 390, 611, 365, 12734, 27735, 11, 1222, 39934, 11, 7772, 3252, 11, 5183, 13, 50942], "temperature": 0.0, "avg_logprob": -0.22578806754870293, "compression_ratio": 1.3582089552238805, "no_speech_prob": 0.20025737583637238}, {"id": 5, "seek": 2088, "start": 32.44, "end": 38.16, "text": " Codership makes Galera clusters, so obviously there's support, training, consulting, and", "tokens": [50942, 383, 378, 433, 1210, 1669, 7336, 1663, 23313, 11, 370, 2745, 456, 311, 1406, 11, 3097, 11, 23682, 11, 293, 51228], "temperature": 0.0, "avg_logprob": -0.22578806754870293, "compression_ratio": 1.3582089552238805, "no_speech_prob": 0.20025737583637238}, {"id": 6, "seek": 2088, "start": 38.16, "end": 39.16, "text": " so forth.", "tokens": [51228, 370, 5220, 13, 51278], "temperature": 0.0, "avg_logprob": -0.22578806754870293, "compression_ratio": 1.3582089552238805, "no_speech_prob": 0.20025737583637238}, {"id": 7, "seek": 2088, "start": 39.16, "end": 44.4, "text": " The company's been around since 2007, three founders, all engineers, fully-services business", "tokens": [51278, 440, 2237, 311, 668, 926, 1670, 12656, 11, 1045, 25608, 11, 439, 11955, 11, 4498, 12, 82, 47480, 1606, 51540], "temperature": 0.0, "avg_logprob": -0.22578806754870293, "compression_ratio": 1.3582089552238805, "no_speech_prob": 0.20025737583637238}, {"id": 8, "seek": 4440, "start": 44.4, "end": 53.64, "text": " model, and it's used in lots of places, from your gaming, aka gambling, also gaming, telecoms,", "tokens": [50364, 2316, 11, 293, 309, 311, 1143, 294, 3195, 295, 3190, 11, 490, 428, 9703, 11, 28042, 27077, 11, 611, 9703, 11, 4304, 1112, 82, 11, 50826], "temperature": 0.0, "avg_logprob": -0.22059612739376905, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.5761207938194275}, {"id": 9, "seek": 4440, "start": 53.64, "end": 61.32, "text": " banking, insurance, SaaS, Paz, IAS, it's literally everywhere.", "tokens": [50826, 18261, 11, 7214, 11, 49733, 11, 430, 921, 11, 286, 3160, 11, 309, 311, 3736, 5315, 13, 51210], "temperature": 0.0, "avg_logprob": -0.22059612739376905, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.5761207938194275}, {"id": 10, "seek": 4440, "start": 61.32, "end": 67.24, "text": " Since many of you already use Galera cluster, I don't actually have to maybe introduce it", "tokens": [51210, 4162, 867, 295, 291, 1217, 764, 7336, 1663, 13630, 11, 286, 500, 380, 767, 362, 281, 1310, 5366, 309, 51506], "temperature": 0.0, "avg_logprob": -0.22059612739376905, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.5761207938194275}, {"id": 11, "seek": 4440, "start": 67.24, "end": 71.24, "text": " to all of you, but it is highly scalable.", "tokens": [51506, 281, 439, 295, 291, 11, 457, 309, 307, 5405, 38481, 13, 51706], "temperature": 0.0, "avg_logprob": -0.22059612739376905, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.5761207938194275}, {"id": 12, "seek": 7124, "start": 71.24, "end": 76.83999999999999, "text": " You can add nodes on the fly, you can delete nodes on the fly, this is as simple as actually", "tokens": [50364, 509, 393, 909, 13891, 322, 264, 3603, 11, 291, 393, 12097, 13891, 322, 264, 3603, 11, 341, 307, 382, 2199, 382, 767, 50644], "temperature": 0.0, "avg_logprob": -0.1472243070602417, "compression_ratio": 1.5450236966824644, "no_speech_prob": 0.08365681022405624}, {"id": 13, "seek": 7124, "start": 76.83999999999999, "end": 85.36, "text": " just pointing the IP address of your new node to an existing node, and it should be able", "tokens": [50644, 445, 12166, 264, 8671, 2985, 295, 428, 777, 9984, 281, 364, 6741, 9984, 11, 293, 309, 820, 312, 1075, 51070], "temperature": 0.0, "avg_logprob": -0.1472243070602417, "compression_ratio": 1.5450236966824644, "no_speech_prob": 0.08365681022405624}, {"id": 14, "seek": 7124, "start": 85.36, "end": 90.64, "text": " to sync via something known as SSD, state snapshot transfer.", "tokens": [51070, 281, 20271, 5766, 746, 2570, 382, 30262, 11, 1785, 30163, 5003, 13, 51334], "temperature": 0.0, "avg_logprob": -0.1472243070602417, "compression_ratio": 1.5450236966824644, "no_speech_prob": 0.08365681022405624}, {"id": 15, "seek": 7124, "start": 90.64, "end": 95.11999999999999, "text": " And from an application point of view, it still looks like one very large database.", "tokens": [51334, 400, 490, 364, 3861, 935, 295, 1910, 11, 309, 920, 1542, 411, 472, 588, 2416, 8149, 13, 51558], "temperature": 0.0, "avg_logprob": -0.1472243070602417, "compression_ratio": 1.5450236966824644, "no_speech_prob": 0.08365681022405624}, {"id": 16, "seek": 9512, "start": 95.84, "end": 101.64, "text": " Naturally, we like you to have a minimum of three nodes, even though some have two, and", "tokens": [50400, 34304, 11, 321, 411, 291, 281, 362, 257, 7285, 295, 1045, 13891, 11, 754, 1673, 512, 362, 732, 11, 293, 50690], "temperature": 0.0, "avg_logprob": -0.16491944302794753, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.280206561088562}, {"id": 17, "seek": 9512, "start": 101.64, "end": 107.04, "text": " some have three separated across two data centers, even though they'll claim they have", "tokens": [50690, 512, 362, 1045, 12005, 2108, 732, 1412, 10898, 11, 754, 1673, 436, 603, 3932, 436, 362, 50960], "temperature": 0.0, "avg_logprob": -0.16491944302794753, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.280206561088562}, {"id": 18, "seek": 9512, "start": 107.04, "end": 109.96000000000001, "text": " very, very fast network.", "tokens": [50960, 588, 11, 588, 2370, 3209, 13, 51106], "temperature": 0.0, "avg_logprob": -0.16491944302794753, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.280206561088562}, {"id": 19, "seek": 9512, "start": 109.96000000000001, "end": 116.16, "text": " So if you have three databases, as we suggest, you'll have three copies of the same data", "tokens": [51106, 407, 498, 291, 362, 1045, 22380, 11, 382, 321, 3402, 11, 291, 603, 362, 1045, 14341, 295, 264, 912, 1412, 51416], "temperature": 0.0, "avg_logprob": -0.16491944302794753, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.280206561088562}, {"id": 20, "seek": 9512, "start": 116.16, "end": 121.80000000000001, "text": " as well, and so it looks like one very big database from the application point of view.", "tokens": [51416, 382, 731, 11, 293, 370, 309, 1542, 411, 472, 588, 955, 8149, 490, 264, 3861, 935, 295, 1910, 13, 51698], "temperature": 0.0, "avg_logprob": -0.16491944302794753, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.280206561088562}, {"id": 21, "seek": 12180, "start": 121.8, "end": 126.24, "text": " You can't have any number of parallel applyer threads as well.", "tokens": [50364, 509, 393, 380, 362, 604, 1230, 295, 8952, 3079, 260, 19314, 382, 731, 13, 50586], "temperature": 0.0, "avg_logprob": -0.193085548725534, "compression_ratio": 1.5482456140350878, "no_speech_prob": 0.4026733636856079}, {"id": 22, "seek": 12180, "start": 126.24, "end": 134.32, "text": " So we have actually renamed things like, we don't call it the WSRAP slave threads any", "tokens": [50586, 407, 321, 362, 767, 40949, 721, 411, 11, 321, 500, 380, 818, 309, 264, 343, 50, 3750, 47, 14777, 19314, 604, 50990], "temperature": 0.0, "avg_logprob": -0.193085548725534, "compression_ratio": 1.5482456140350878, "no_speech_prob": 0.4026733636856079}, {"id": 23, "seek": 12180, "start": 134.32, "end": 136.44, "text": " longer, we call it applyer threads.", "tokens": [50990, 2854, 11, 321, 818, 309, 3079, 260, 19314, 13, 51096], "temperature": 0.0, "avg_logprob": -0.193085548725534, "compression_ratio": 1.5482456140350878, "no_speech_prob": 0.4026733636856079}, {"id": 24, "seek": 12180, "start": 136.44, "end": 142.64, "text": " So we are following exactly what MySQL and MariaDB is doing in terms of being politically", "tokens": [51096, 407, 321, 366, 3480, 2293, 437, 1222, 39934, 293, 12734, 27735, 307, 884, 294, 2115, 295, 885, 21154, 51406], "temperature": 0.0, "avg_logprob": -0.193085548725534, "compression_ratio": 1.5482456140350878, "no_speech_prob": 0.4026733636856079}, {"id": 25, "seek": 12180, "start": 142.64, "end": 151.72, "text": " correct, I guess, though we are in Europe, so maybe this is less of a concern.", "tokens": [51406, 3006, 11, 286, 2041, 11, 1673, 321, 366, 294, 3315, 11, 370, 1310, 341, 307, 1570, 295, 257, 3136, 13, 51860], "temperature": 0.0, "avg_logprob": -0.193085548725534, "compression_ratio": 1.5482456140350878, "no_speech_prob": 0.4026733636856079}, {"id": 26, "seek": 15172, "start": 151.72, "end": 156.6, "text": " So this is a point to note, because if you are actually in your config files using older", "tokens": [50364, 407, 341, 307, 257, 935, 281, 3637, 11, 570, 498, 291, 366, 767, 294, 428, 6662, 7098, 1228, 4906, 50608], "temperature": 0.0, "avg_logprob": -0.17387742143336352, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.01613772101700306}, {"id": 27, "seek": 15172, "start": 156.6, "end": 161.68, "text": " configurations, when you're moving to something new, you should rename it, otherwise you're", "tokens": [50608, 31493, 11, 562, 291, 434, 2684, 281, 746, 777, 11, 291, 820, 36741, 309, 11, 5911, 291, 434, 50862], "temperature": 0.0, "avg_logprob": -0.17387742143336352, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.01613772101700306}, {"id": 28, "seek": 15172, "start": 161.68, "end": 166.76, "text": " going to find that Galera will fail to start with a very poor error message in your error", "tokens": [50862, 516, 281, 915, 300, 7336, 1663, 486, 3061, 281, 722, 365, 257, 588, 4716, 6713, 3636, 294, 428, 6713, 51116], "temperature": 0.0, "avg_logprob": -0.17387742143336352, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.01613772101700306}, {"id": 29, "seek": 15172, "start": 166.76, "end": 173.32, "text": " log, and maybe that's the other pro tip is to never disable the error log, ever, because", "tokens": [51116, 3565, 11, 293, 1310, 300, 311, 264, 661, 447, 4125, 307, 281, 1128, 28362, 264, 6713, 3565, 11, 1562, 11, 570, 51444], "temperature": 0.0, "avg_logprob": -0.17387742143336352, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.01613772101700306}, {"id": 30, "seek": 15172, "start": 173.32, "end": 176.44, "text": " Galera writes all messages to the error log.", "tokens": [51444, 7336, 1663, 13657, 439, 7897, 281, 264, 6713, 3565, 13, 51600], "temperature": 0.0, "avg_logprob": -0.17387742143336352, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.01613772101700306}, {"id": 31, "seek": 15172, "start": 176.44, "end": 181.68, "text": " In fact, if you're using MySQL 57 or 80, which I presume most of you should be using", "tokens": [51600, 682, 1186, 11, 498, 291, 434, 1228, 1222, 39934, 21423, 420, 4688, 11, 597, 286, 43283, 881, 295, 291, 820, 312, 1228, 51862], "temperature": 0.0, "avg_logprob": -0.17387742143336352, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.01613772101700306}, {"id": 32, "seek": 18168, "start": 182.4, "end": 187.96, "text": " in terms of a newer version of MySQL, the temporary password is inside your error log.", "tokens": [50400, 294, 2115, 295, 257, 17628, 3037, 295, 1222, 39934, 11, 264, 13413, 11524, 307, 1854, 428, 6713, 3565, 13, 50678], "temperature": 0.0, "avg_logprob": -0.12522596301454486, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.030176399275660515}, {"id": 33, "seek": 18168, "start": 187.96, "end": 192.20000000000002, "text": " So if you disabled it, how do you plan to start?", "tokens": [50678, 407, 498, 291, 15191, 309, 11, 577, 360, 291, 1393, 281, 722, 30, 50890], "temperature": 0.0, "avg_logprob": -0.12522596301454486, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.030176399275660515}, {"id": 34, "seek": 18168, "start": 192.20000000000002, "end": 194.96, "text": " So the error log is actually very crucial.", "tokens": [50890, 407, 264, 6713, 3565, 307, 767, 588, 11462, 13, 51028], "temperature": 0.0, "avg_logprob": -0.12522596301454486, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.030176399275660515}, {"id": 35, "seek": 18168, "start": 194.96, "end": 202.08, "text": " So MariaDB, on the other hand, you can start with passwordless logins by default, but MySQL", "tokens": [51028, 407, 12734, 27735, 11, 322, 264, 661, 1011, 11, 291, 393, 722, 365, 11524, 1832, 3565, 1292, 538, 7576, 11, 457, 1222, 39934, 51384], "temperature": 0.0, "avg_logprob": -0.12522596301454486, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.030176399275660515}, {"id": 36, "seek": 18168, "start": 202.08, "end": 203.08, "text": " requires it.", "tokens": [51384, 7029, 309, 13, 51434], "temperature": 0.0, "avg_logprob": -0.12522596301454486, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.030176399275660515}, {"id": 37, "seek": 18168, "start": 203.08, "end": 210.56, "text": " So I suggest if you're using Galera, never disable the error log like ever.", "tokens": [51434, 407, 286, 3402, 498, 291, 434, 1228, 7336, 1663, 11, 1128, 28362, 264, 6713, 3565, 411, 1562, 13, 51808], "temperature": 0.0, "avg_logprob": -0.12522596301454486, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.030176399275660515}, {"id": 38, "seek": 21056, "start": 210.56, "end": 215.72, "text": " We also, of course, have parallel replications, so it makes state transfers quick for new nodes.", "tokens": [50364, 492, 611, 11, 295, 1164, 11, 362, 8952, 3248, 24847, 11, 370, 309, 1669, 1785, 29137, 1702, 337, 777, 13891, 13, 50622], "temperature": 0.0, "avg_logprob": -0.18428113725450304, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.050812311470508575}, {"id": 39, "seek": 21056, "start": 215.72, "end": 219.68, "text": " So you can actually consider just increasing the applied threads.", "tokens": [50622, 407, 291, 393, 767, 1949, 445, 5662, 264, 6456, 19314, 13, 50820], "temperature": 0.0, "avg_logprob": -0.18428113725450304, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.050812311470508575}, {"id": 40, "seek": 21056, "start": 219.68, "end": 224.28, "text": " Don't use a value of WSRAP applied threads that is higher than the average given number", "tokens": [50820, 1468, 380, 764, 257, 2158, 295, 343, 50, 3750, 47, 6456, 19314, 300, 307, 2946, 813, 264, 4274, 2212, 1230, 51050], "temperature": 0.0, "avg_logprob": -0.18428113725450304, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.050812311470508575}, {"id": 41, "seek": 21056, "start": 224.28, "end": 228.52, "text": " of what is known as the cert depth distance, the certification depth distance.", "tokens": [51050, 295, 437, 307, 2570, 382, 264, 5351, 7161, 4560, 11, 264, 21775, 7161, 4560, 13, 51262], "temperature": 0.0, "avg_logprob": -0.18428113725450304, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.050812311470508575}, {"id": 42, "seek": 21056, "start": 228.52, "end": 231.88, "text": " You can actually see this in the status variables.", "tokens": [51262, 509, 393, 767, 536, 341, 294, 264, 6558, 9102, 13, 51430], "temperature": 0.0, "avg_logprob": -0.18428113725450304, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.050812311470508575}, {"id": 43, "seek": 21056, "start": 231.88, "end": 236.76, "text": " We probably, as an improvement, should be able to spend more time actually going through", "tokens": [51430, 492, 1391, 11, 382, 364, 10444, 11, 820, 312, 1075, 281, 3496, 544, 565, 767, 516, 807, 51674], "temperature": 0.0, "avg_logprob": -0.18428113725450304, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.050812311470508575}, {"id": 44, "seek": 23676, "start": 236.76, "end": 240.51999999999998, "text": " all the WSRAP stuff that you should be paying attention to.", "tokens": [50364, 439, 264, 343, 50, 3750, 47, 1507, 300, 291, 820, 312, 6229, 3202, 281, 13, 50552], "temperature": 0.0, "avg_logprob": -0.15799152641965633, "compression_ratio": 1.5985915492957747, "no_speech_prob": 0.01060444861650467}, {"id": 45, "seek": 23676, "start": 240.51999999999998, "end": 245.56, "text": " But to some extent, we've also given that off to GUI tools to manage.", "tokens": [50552, 583, 281, 512, 8396, 11, 321, 600, 611, 2212, 300, 766, 281, 17917, 40, 3873, 281, 3067, 13, 50804], "temperature": 0.0, "avg_logprob": -0.15799152641965633, "compression_ratio": 1.5985915492957747, "no_speech_prob": 0.01060444861650467}, {"id": 46, "seek": 23676, "start": 245.56, "end": 249.92, "text": " Of course, we have an optimized network protocol, so packets are only exchanged over the when", "tokens": [50804, 2720, 1164, 11, 321, 362, 364, 26941, 3209, 10336, 11, 370, 30364, 366, 787, 38378, 670, 264, 562, 51022], "temperature": 0.0, "avg_logprob": -0.15799152641965633, "compression_ratio": 1.5985915492957747, "no_speech_prob": 0.01060444861650467}, {"id": 47, "seek": 23676, "start": 249.92, "end": 252.2, "text": " a transaction can be time.", "tokens": [51022, 257, 14425, 393, 312, 565, 13, 51136], "temperature": 0.0, "avg_logprob": -0.15799152641965633, "compression_ratio": 1.5985915492957747, "no_speech_prob": 0.01060444861650467}, {"id": 48, "seek": 23676, "start": 252.2, "end": 256.14, "text": " We have topology-aware applications, so you can actually segment things.", "tokens": [51136, 492, 362, 1192, 1793, 12, 17074, 5821, 11, 370, 291, 393, 767, 9469, 721, 13, 51333], "temperature": 0.0, "avg_logprob": -0.15799152641965633, "compression_ratio": 1.5985915492957747, "no_speech_prob": 0.01060444861650467}, {"id": 49, "seek": 23676, "start": 256.14, "end": 261.24, "text": " So each transaction is sent to a separate data center actually only once.", "tokens": [51333, 407, 1184, 14425, 307, 2279, 281, 257, 4994, 1412, 3056, 767, 787, 1564, 13, 51588], "temperature": 0.0, "avg_logprob": -0.15799152641965633, "compression_ratio": 1.5985915492957747, "no_speech_prob": 0.01060444861650467}, {"id": 50, "seek": 23676, "start": 261.24, "end": 266.24, "text": " We also detect and automatically evict unreliable nodes.", "tokens": [51588, 492, 611, 5531, 293, 6772, 1073, 985, 20584, 2081, 712, 13891, 13, 51838], "temperature": 0.0, "avg_logprob": -0.15799152641965633, "compression_ratio": 1.5985915492957747, "no_speech_prob": 0.01060444861650467}, {"id": 51, "seek": 26624, "start": 266.24, "end": 269.64, "text": " This has improved tremendously in Galera 4, actually.", "tokens": [50364, 639, 575, 9689, 27985, 294, 7336, 1663, 1017, 11, 767, 13, 50534], "temperature": 0.0, "avg_logprob": -0.17614285489346118, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.005463290028274059}, {"id": 52, "seek": 26624, "start": 269.64, "end": 274.32, "text": " So if you have a flappy network or node failure, you don't actually need any manual intervention.", "tokens": [50534, 407, 498, 291, 362, 257, 46338, 7966, 3209, 420, 9984, 7763, 11, 291, 500, 380, 767, 643, 604, 9688, 13176, 13, 50768], "temperature": 0.0, "avg_logprob": -0.17614285489346118, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.005463290028274059}, {"id": 53, "seek": 26624, "start": 274.32, "end": 277.28000000000003, "text": " We will eject.", "tokens": [50768, 492, 486, 32520, 13, 50916], "temperature": 0.0, "avg_logprob": -0.17614285489346118, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.005463290028274059}, {"id": 54, "seek": 26624, "start": 277.28000000000003, "end": 283.28000000000003, "text": " In the very unlikely event that you've configured Galera to ignore split brains, we aim to actually", "tokens": [50916, 682, 264, 588, 17518, 2280, 300, 291, 600, 30538, 7336, 1663, 281, 11200, 7472, 15442, 11, 321, 5939, 281, 767, 51216], "temperature": 0.0, "avg_logprob": -0.17614285489346118, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.005463290028274059}, {"id": 55, "seek": 26624, "start": 283.28000000000003, "end": 286.56, "text": " recover from these problems.", "tokens": [51216, 8114, 490, 613, 2740, 13, 51380], "temperature": 0.0, "avg_logprob": -0.17614285489346118, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.005463290028274059}, {"id": 56, "seek": 26624, "start": 286.56, "end": 295.76, "text": " Again, we provide these options for you, but we don't recommend you to use them.", "tokens": [51380, 3764, 11, 321, 2893, 613, 3956, 337, 291, 11, 457, 321, 500, 380, 2748, 291, 281, 764, 552, 13, 51840], "temperature": 0.0, "avg_logprob": -0.17614285489346118, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.005463290028274059}, {"id": 57, "seek": 29576, "start": 296.76, "end": 299.59999999999997, "text": " Why would you want to cause yourself grief?", "tokens": [50414, 1545, 576, 291, 528, 281, 3082, 1803, 18998, 30, 50556], "temperature": 0.0, "avg_logprob": -0.2126955304827009, "compression_ratio": 1.510548523206751, "no_speech_prob": 0.07437467575073242}, {"id": 58, "seek": 29576, "start": 299.59999999999997, "end": 302.36, "text": " MySQL and MariaDB don't allow you to sync data.", "tokens": [50556, 1222, 39934, 293, 12734, 27735, 500, 380, 2089, 291, 281, 20271, 1412, 13, 50694], "temperature": 0.0, "avg_logprob": -0.2126955304827009, "compression_ratio": 1.510548523206751, "no_speech_prob": 0.07437467575073242}, {"id": 59, "seek": 29576, "start": 302.36, "end": 307.88, "text": " So if you have a split brain situation with two different sets of data, how do you plan", "tokens": [50694, 407, 498, 291, 362, 257, 7472, 3567, 2590, 365, 732, 819, 6352, 295, 1412, 11, 577, 360, 291, 1393, 50970], "temperature": 0.0, "avg_logprob": -0.2126955304827009, "compression_ratio": 1.510548523206751, "no_speech_prob": 0.07437467575073242}, {"id": 60, "seek": 29576, "start": 307.88, "end": 310.4, "text": " to sync this data later?", "tokens": [50970, 281, 20271, 341, 1412, 1780, 30, 51096], "temperature": 0.0, "avg_logprob": -0.2126955304827009, "compression_ratio": 1.510548523206751, "no_speech_prob": 0.07437467575073242}, {"id": 61, "seek": 29576, "start": 310.4, "end": 315.4, "text": " Well, you can, of course, turn on the binary logs, which we actually do recommend, at least", "tokens": [51096, 1042, 11, 291, 393, 11, 295, 1164, 11, 1261, 322, 264, 17434, 20820, 11, 597, 321, 767, 360, 2748, 11, 412, 1935, 51346], "temperature": 0.0, "avg_logprob": -0.2126955304827009, "compression_ratio": 1.510548523206751, "no_speech_prob": 0.07437467575073242}, {"id": 62, "seek": 29576, "start": 315.4, "end": 318.36, "text": " for a short period of time, and then maybe do some replaying.", "tokens": [51346, 337, 257, 2099, 2896, 295, 565, 11, 293, 550, 1310, 360, 512, 23836, 278, 13, 51494], "temperature": 0.0, "avg_logprob": -0.2126955304827009, "compression_ratio": 1.510548523206751, "no_speech_prob": 0.07437467575073242}, {"id": 63, "seek": 31836, "start": 318.8, "end": 324.12, "text": " If you have MariaDB, you can use the flashback capability.", "tokens": [50386, 759, 291, 362, 12734, 27735, 11, 291, 393, 764, 264, 7319, 3207, 13759, 13, 50652], "temperature": 0.0, "avg_logprob": -0.20048362088490682, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1450568437576294}, {"id": 64, "seek": 31836, "start": 324.12, "end": 329.2, "text": " If you have MySQL, you can actually just replay the bin logs.", "tokens": [50652, 759, 291, 362, 1222, 39934, 11, 291, 393, 767, 445, 23836, 264, 5171, 20820, 13, 50906], "temperature": 0.0, "avg_logprob": -0.20048362088490682, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1450568437576294}, {"id": 65, "seek": 31836, "start": 329.2, "end": 333.24, "text": " So if you happen to actually lose data, and, of course, traffic encryption is something", "tokens": [50906, 407, 498, 291, 1051, 281, 767, 3624, 1412, 11, 293, 11, 295, 1164, 11, 6419, 29575, 307, 746, 51108], "temperature": 0.0, "avg_logprob": -0.20048362088490682, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1450568437576294}, {"id": 66, "seek": 31836, "start": 333.24, "end": 342.0, "text": " we also support, it's not turned on by default in all distributions except Percona XDB Cluster", "tokens": [51108, 321, 611, 1406, 11, 309, 311, 406, 3574, 322, 538, 7576, 294, 439, 37870, 3993, 3026, 1671, 64, 1783, 27735, 2033, 8393, 51546], "temperature": 0.0, "avg_logprob": -0.20048362088490682, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1450568437576294}, {"id": 67, "seek": 31836, "start": 342.0, "end": 343.0, "text": " 8.", "tokens": [51546, 1649, 13, 51596], "temperature": 0.0, "avg_logprob": -0.20048362088490682, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1450568437576294}, {"id": 68, "seek": 34300, "start": 343.24, "end": 348.4, "text": " If you get Percona XDB Cluster 8, traffic encryption is enabled by default.", "tokens": [50376, 759, 291, 483, 3026, 1671, 64, 1783, 27735, 2033, 8393, 1649, 11, 6419, 29575, 307, 15172, 538, 7576, 13, 50634], "temperature": 0.0, "avg_logprob": -0.18209393149928044, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.005376612301915884}, {"id": 69, "seek": 34300, "start": 348.4, "end": 351.6, "text": " And if you're using the cloud, this is kind of key, right?", "tokens": [50634, 400, 498, 291, 434, 1228, 264, 4588, 11, 341, 307, 733, 295, 2141, 11, 558, 30, 50794], "temperature": 0.0, "avg_logprob": -0.18209393149928044, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.005376612301915884}, {"id": 70, "seek": 34300, "start": 351.6, "end": 359.68, "text": " Because it turns out that everything happens in, replication happens in plain text, basically.", "tokens": [50794, 1436, 309, 4523, 484, 300, 1203, 2314, 294, 11, 39911, 2314, 294, 11121, 2487, 11, 1936, 13, 51198], "temperature": 0.0, "avg_logprob": -0.18209393149928044, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.005376612301915884}, {"id": 71, "seek": 34300, "start": 359.68, "end": 367.0, "text": " This is true even for asynchronous replication or even semi-synchronous replication.", "tokens": [51198, 639, 307, 2074, 754, 337, 49174, 39911, 420, 754, 12909, 12, 82, 36420, 563, 39911, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18209393149928044, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.005376612301915884}, {"id": 72, "seek": 34300, "start": 367.0, "end": 372.08, "text": " So did I just promise you a panacea for the whole world?", "tokens": [51564, 407, 630, 286, 445, 6228, 291, 257, 2462, 617, 64, 337, 264, 1379, 1002, 30, 51818], "temperature": 0.0, "avg_logprob": -0.18209393149928044, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.005376612301915884}, {"id": 73, "seek": 37208, "start": 372.08, "end": 373.08, "text": " Of course not.", "tokens": [50364, 2720, 1164, 406, 13, 50414], "temperature": 0.0, "avg_logprob": -0.14013905958695846, "compression_ratio": 1.8614232209737829, "no_speech_prob": 0.24749310314655304}, {"id": 74, "seek": 37208, "start": 373.08, "end": 375.08, "text": " It does come with trade-offs, right?", "tokens": [50414, 467, 775, 808, 365, 4923, 12, 19231, 11, 558, 30, 50514], "temperature": 0.0, "avg_logprob": -0.14013905958695846, "compression_ratio": 1.8614232209737829, "no_speech_prob": 0.24749310314655304}, {"id": 75, "seek": 37208, "start": 375.08, "end": 379.88, "text": " You are not going to be as fast as asynchronous because you're not just committing to the", "tokens": [50514, 509, 366, 406, 516, 281, 312, 382, 2370, 382, 49174, 570, 291, 434, 406, 445, 26659, 281, 264, 50754], "temperature": 0.0, "avg_logprob": -0.14013905958695846, "compression_ratio": 1.8614232209737829, "no_speech_prob": 0.24749310314655304}, {"id": 76, "seek": 37208, "start": 379.88, "end": 383.59999999999997, "text": " primary, you're committing to the primary and to other nodes.", "tokens": [50754, 6194, 11, 291, 434, 26659, 281, 264, 6194, 293, 281, 661, 13891, 13, 50940], "temperature": 0.0, "avg_logprob": -0.14013905958695846, "compression_ratio": 1.8614232209737829, "no_speech_prob": 0.24749310314655304}, {"id": 77, "seek": 37208, "start": 383.59999999999997, "end": 386.36, "text": " It's obviously not going to be as fast as semi-synchronous because it's not committing", "tokens": [50940, 467, 311, 2745, 406, 516, 281, 312, 382, 2370, 382, 12909, 12, 82, 36420, 563, 570, 309, 311, 406, 26659, 51078], "temperature": 0.0, "avg_logprob": -0.14013905958695846, "compression_ratio": 1.8614232209737829, "no_speech_prob": 0.24749310314655304}, {"id": 78, "seek": 37208, "start": 386.36, "end": 388.79999999999995, "text": " to one primary and one secondary.", "tokens": [51078, 281, 472, 6194, 293, 472, 11396, 13, 51200], "temperature": 0.0, "avg_logprob": -0.14013905958695846, "compression_ratio": 1.8614232209737829, "no_speech_prob": 0.24749310314655304}, {"id": 79, "seek": 37208, "start": 388.79999999999995, "end": 393.15999999999997, "text": " So we can't really beat the laws of physics even though you're in the same data center,", "tokens": [51200, 407, 321, 393, 380, 534, 4224, 264, 6064, 295, 10649, 754, 1673, 291, 434, 294, 264, 912, 1412, 3056, 11, 51418], "temperature": 0.0, "avg_logprob": -0.14013905958695846, "compression_ratio": 1.8614232209737829, "no_speech_prob": 0.24749310314655304}, {"id": 80, "seek": 37208, "start": 393.15999999999997, "end": 398.28, "text": " which is, again, why it's such a bad idea, and we see this a lot in production where", "tokens": [51418, 597, 307, 11, 797, 11, 983, 309, 311, 1270, 257, 1578, 1558, 11, 293, 321, 536, 341, 257, 688, 294, 4265, 689, 51674], "temperature": 0.0, "avg_logprob": -0.14013905958695846, "compression_ratio": 1.8614232209737829, "no_speech_prob": 0.24749310314655304}, {"id": 81, "seek": 39828, "start": 398.28, "end": 404.29999999999995, "text": " people say, we have a three-node Galera cluster in two data centers.", "tokens": [50364, 561, 584, 11, 321, 362, 257, 1045, 12, 77, 1429, 7336, 1663, 13630, 294, 732, 1412, 10898, 13, 50665], "temperature": 0.0, "avg_logprob": -0.17840007181917683, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.059940263628959656}, {"id": 82, "seek": 39828, "start": 404.29999999999995, "end": 409.67999999999995, "text": " If you want high availability, you really should invest in the money that comes from", "tokens": [50665, 759, 291, 528, 1090, 17945, 11, 291, 534, 820, 1963, 294, 264, 1460, 300, 1487, 490, 50934], "temperature": 0.0, "avg_logprob": -0.17840007181917683, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.059940263628959656}, {"id": 83, "seek": 39828, "start": 409.67999999999995, "end": 413.67999999999995, "text": " running high availability.", "tokens": [50934, 2614, 1090, 17945, 13, 51134], "temperature": 0.0, "avg_logprob": -0.17840007181917683, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.059940263628959656}, {"id": 84, "seek": 39828, "start": 413.67999999999995, "end": 420.59999999999997, "text": " So we've now found out that basically none of you use Code of Ships Galera cluster.", "tokens": [51134, 407, 321, 600, 586, 1352, 484, 300, 1936, 6022, 295, 291, 764, 15549, 295, 1160, 2600, 7336, 1663, 13630, 13, 51480], "temperature": 0.0, "avg_logprob": -0.17840007181917683, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.059940263628959656}, {"id": 85, "seek": 39828, "start": 420.59999999999997, "end": 424.05999999999995, "text": " And as Monty says, a lot of the features are actually pretty much inside of MariaDB", "tokens": [51480, 400, 382, 4713, 874, 1619, 11, 257, 688, 295, 264, 4122, 366, 767, 1238, 709, 1854, 295, 12734, 27735, 51653], "temperature": 0.0, "avg_logprob": -0.17840007181917683, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.059940263628959656}, {"id": 86, "seek": 42406, "start": 424.06, "end": 430.34, "text": " Galera cluster, but there is this one interesting feature that is not made it to any other distribution", "tokens": [50364, 7336, 1663, 13630, 11, 457, 456, 307, 341, 472, 1880, 4111, 300, 307, 406, 1027, 309, 281, 604, 661, 7316, 50678], "temperature": 0.0, "avg_logprob": -0.29805285688759625, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.05009561404585838}, {"id": 87, "seek": 42406, "start": 430.34, "end": 432.14, "text": " that's clone SSD.", "tokens": [50678, 300, 311, 26506, 30262, 13, 50768], "temperature": 0.0, "avg_logprob": -0.29805285688759625, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.05009561404585838}, {"id": 88, "seek": 42406, "start": 432.14, "end": 439.14, "text": " SSDs that happen via the clone plugin as opposed to using the likes of Maria backup, extra", "tokens": [50768, 30262, 82, 300, 1051, 5766, 264, 26506, 23407, 382, 8851, 281, 1228, 264, 5902, 295, 12734, 14807, 11, 2857, 51118], "temperature": 0.0, "avg_logprob": -0.29805285688759625, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.05009561404585838}, {"id": 89, "seek": 42406, "start": 439.14, "end": 449.5, "text": " backup, and unfortunately, the clone plugin doesn't run on MariaDB.", "tokens": [51118, 14807, 11, 293, 7015, 11, 264, 26506, 23407, 1177, 380, 1190, 322, 12734, 27735, 13, 51636], "temperature": 0.0, "avg_logprob": -0.29805285688759625, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.05009561404585838}, {"id": 90, "seek": 44950, "start": 449.5, "end": 453.9, "text": " So on MariaDB, you use Maria backup, which is also fast.", "tokens": [50364, 407, 322, 12734, 27735, 11, 291, 764, 12734, 14807, 11, 597, 307, 611, 2370, 13, 50584], "temperature": 0.0, "avg_logprob": -0.1749975997789771, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.06748996675014496}, {"id": 91, "seek": 44950, "start": 453.9, "end": 458.3, "text": " On Percona XDB cluster, you use extra backup, which is also fast, but we found that clone", "tokens": [50584, 1282, 3026, 1671, 64, 1783, 27735, 13630, 11, 291, 764, 2857, 14807, 11, 597, 307, 611, 2370, 11, 457, 321, 1352, 300, 26506, 50804], "temperature": 0.0, "avg_logprob": -0.1749975997789771, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.06748996675014496}, {"id": 92, "seek": 44950, "start": 458.3, "end": 461.58, "text": " is actually also pretty amazing.", "tokens": [50804, 307, 767, 611, 1238, 2243, 13, 50968], "temperature": 0.0, "avg_logprob": -0.1749975997789771, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.06748996675014496}, {"id": 93, "seek": 44950, "start": 461.58, "end": 463.5, "text": " So we do open up a new port for it.", "tokens": [50968, 407, 321, 360, 1269, 493, 257, 777, 2436, 337, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1749975997789771, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.06748996675014496}, {"id": 94, "seek": 44950, "start": 463.5, "end": 468.74, "text": " And if you use Galera Manager, by default, if you deploy MySQL 8, we actually use clone", "tokens": [51064, 400, 498, 291, 764, 7336, 1663, 13821, 11, 538, 7576, 11, 498, 291, 7274, 1222, 39934, 1649, 11, 321, 767, 764, 26506, 51326], "temperature": 0.0, "avg_logprob": -0.1749975997789771, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.06748996675014496}, {"id": 95, "seek": 44950, "start": 468.74, "end": 471.26, "text": " SSD to provision your new nodes.", "tokens": [51326, 30262, 281, 17225, 428, 777, 13891, 13, 51452], "temperature": 0.0, "avg_logprob": -0.1749975997789771, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.06748996675014496}, {"id": 96, "seek": 44950, "start": 471.26, "end": 476.5, "text": " So you should be able to see some good speed up there.", "tokens": [51452, 407, 291, 820, 312, 1075, 281, 536, 512, 665, 3073, 493, 456, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1749975997789771, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.06748996675014496}, {"id": 97, "seek": 47650, "start": 476.5, "end": 483.02, "text": " It works extremely closely with MariaDB PLC, I have to say not MariaDB Corporation any", "tokens": [50364, 467, 1985, 4664, 8185, 365, 12734, 27735, 6999, 34, 11, 286, 362, 281, 584, 406, 12734, 27735, 26464, 604, 50690], "temperature": 0.0, "avg_logprob": -0.16594571506275851, "compression_ratio": 1.4292237442922375, "no_speech_prob": 0.41319531202316284}, {"id": 98, "seek": 47650, "start": 483.02, "end": 487.7, "text": " longer because the company has a new name, to make a MariaDB Galera cluster.", "tokens": [50690, 2854, 570, 264, 2237, 575, 257, 777, 1315, 11, 281, 652, 257, 12734, 27735, 7336, 1663, 13630, 13, 50924], "temperature": 0.0, "avg_logprob": -0.16594571506275851, "compression_ratio": 1.4292237442922375, "no_speech_prob": 0.41319531202316284}, {"id": 99, "seek": 47650, "start": 487.7, "end": 496.18, "text": " In fact, it's been around inside a developer tree since 10.1, which is around October 2014.", "tokens": [50924, 682, 1186, 11, 309, 311, 668, 926, 1854, 257, 10754, 4230, 1670, 1266, 13, 16, 11, 597, 307, 926, 7617, 8227, 13, 51348], "temperature": 0.0, "avg_logprob": -0.16594571506275851, "compression_ratio": 1.4292237442922375, "no_speech_prob": 0.41319531202316284}, {"id": 100, "seek": 47650, "start": 496.18, "end": 501.9, "text": " So then it got released as a GA in October 2015 in 10.18.", "tokens": [51348, 407, 550, 309, 658, 4736, 382, 257, 22841, 294, 7617, 7546, 294, 1266, 13, 6494, 13, 51634], "temperature": 0.0, "avg_logprob": -0.16594571506275851, "compression_ratio": 1.4292237442922375, "no_speech_prob": 0.41319531202316284}, {"id": 101, "seek": 50190, "start": 501.9, "end": 506.82, "text": " And you get all the features of MariaDB that work with Galera, basically.", "tokens": [50364, 400, 291, 483, 439, 264, 4122, 295, 12734, 27735, 300, 589, 365, 7336, 1663, 11, 1936, 13, 50610], "temperature": 0.0, "avg_logprob": -0.15990834333458726, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.6481680870056152}, {"id": 102, "seek": 50190, "start": 506.82, "end": 508.73999999999995, "text": " This is your Oracle support.", "tokens": [50610, 639, 307, 428, 25654, 1406, 13, 50706], "temperature": 0.0, "avg_logprob": -0.15990834333458726, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.6481680870056152}, {"id": 103, "seek": 50190, "start": 508.73999999999995, "end": 517.3, "text": " I know there's no generic MariaDB feature talk in this entire FOSDAM, but go check out", "tokens": [50706, 286, 458, 456, 311, 572, 19577, 12734, 27735, 4111, 751, 294, 341, 2302, 479, 4367, 35, 2865, 11, 457, 352, 1520, 484, 51134], "temperature": 0.0, "avg_logprob": -0.15990834333458726, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.6481680870056152}, {"id": 104, "seek": 50190, "start": 517.3, "end": 519.9, "text": " the knowledge base.", "tokens": [51134, 264, 3601, 3096, 13, 51264], "temperature": 0.0, "avg_logprob": -0.15990834333458726, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.6481680870056152}, {"id": 105, "seek": 50190, "start": 519.9, "end": 523.9, "text": " I have another talk on the ecosystem later, which will give you a quick overview.", "tokens": [51264, 286, 362, 1071, 751, 322, 264, 11311, 1780, 11, 597, 486, 976, 291, 257, 1702, 12492, 13, 51464], "temperature": 0.0, "avg_logprob": -0.15990834333458726, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.6481680870056152}, {"id": 106, "seek": 50190, "start": 523.9, "end": 529.26, "text": " But you also get the things like system version tables, sequences, all those optimizer features", "tokens": [51464, 583, 291, 611, 483, 264, 721, 411, 1185, 3037, 8020, 11, 22978, 11, 439, 729, 5028, 6545, 4122, 51732], "temperature": 0.0, "avg_logprob": -0.15990834333458726, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.6481680870056152}, {"id": 107, "seek": 52926, "start": 529.26, "end": 534.34, "text": " that Monty talked about that are coming in MariaDB 11, you just get benefit of it as", "tokens": [50364, 300, 4713, 874, 2825, 466, 300, 366, 1348, 294, 12734, 27735, 2975, 11, 291, 445, 483, 5121, 295, 309, 382, 50618], "temperature": 0.0, "avg_logprob": -0.2270241869174368, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.02156425453722477}, {"id": 108, "seek": 52926, "start": 534.34, "end": 535.34, "text": " well.", "tokens": [50618, 731, 13, 50668], "temperature": 0.0, "avg_logprob": -0.2270241869174368, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.02156425453722477}, {"id": 109, "seek": 52926, "start": 535.34, "end": 539.22, "text": " And it was actually the first to include Galera 4 in 10.4.", "tokens": [50668, 400, 309, 390, 767, 264, 700, 281, 4090, 7336, 1663, 1017, 294, 1266, 13, 19, 13, 50862], "temperature": 0.0, "avg_logprob": -0.2270241869174368, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.02156425453722477}, {"id": 110, "seek": 52926, "start": 539.22, "end": 545.58, "text": " So if you're using 10.4, 10.5, 10.6, you're already getting Galera 4.", "tokens": [50862, 407, 498, 291, 434, 1228, 1266, 13, 19, 11, 1266, 13, 20, 11, 1266, 13, 21, 11, 291, 434, 1217, 1242, 7336, 1663, 1017, 13, 51180], "temperature": 0.0, "avg_logprob": -0.2270241869174368, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.02156425453722477}, {"id": 111, "seek": 52926, "start": 545.58, "end": 550.46, "text": " And then, of course, there's a Pocona actually DB cluster, which another half of you actually", "tokens": [51180, 400, 550, 11, 295, 1164, 11, 456, 311, 257, 430, 905, 4037, 767, 26754, 13630, 11, 597, 1071, 1922, 295, 291, 767, 51424], "temperature": 0.0, "avg_logprob": -0.2270241869174368, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.02156425453722477}, {"id": 112, "seek": 52926, "start": 550.46, "end": 551.46, "text": " use.", "tokens": [51424, 764, 13, 51474], "temperature": 0.0, "avg_logprob": -0.2270241869174368, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.02156425453722477}, {"id": 113, "seek": 52926, "start": 551.46, "end": 552.98, "text": " Base is Pocona server.", "tokens": [51474, 21054, 307, 430, 905, 4037, 7154, 13, 51550], "temperature": 0.0, "avg_logprob": -0.2270241869174368, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.02156425453722477}, {"id": 114, "seek": 52926, "start": 552.98, "end": 556.58, "text": " It comes with proxy SQL, including an administrative tool.", "tokens": [51550, 467, 1487, 365, 29690, 19200, 11, 3009, 364, 17900, 2290, 13, 51730], "temperature": 0.0, "avg_logprob": -0.2270241869174368, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.02156425453722477}, {"id": 115, "seek": 55658, "start": 556.9000000000001, "end": 563.94, "text": " It has a strict mode, which disallows MyISM tables to be replicated via Galera.", "tokens": [50380, 467, 575, 257, 10910, 4391, 11, 597, 717, 38811, 1222, 2343, 44, 8020, 281, 312, 46365, 5766, 7336, 1663, 13, 50732], "temperature": 0.0, "avg_logprob": -0.22470618457328984, "compression_ratio": 1.5, "no_speech_prob": 0.07887358963489532}, {"id": 116, "seek": 55658, "start": 563.94, "end": 571.7, "text": " Now this is an interesting thing because while Pocona actually DB cluster disallows it, MariaDB,", "tokens": [50732, 823, 341, 307, 364, 1880, 551, 570, 1339, 430, 905, 4037, 767, 26754, 13630, 717, 38811, 309, 11, 12734, 27735, 11, 51120], "temperature": 0.0, "avg_logprob": -0.22470618457328984, "compression_ratio": 1.5, "no_speech_prob": 0.07887358963489532}, {"id": 117, "seek": 55658, "start": 571.7, "end": 573.86, "text": " later versions of MariaDB actually allows this.", "tokens": [51120, 1780, 9606, 295, 12734, 27735, 767, 4045, 341, 13, 51228], "temperature": 0.0, "avg_logprob": -0.22470618457328984, "compression_ratio": 1.5, "no_speech_prob": 0.07887358963489532}, {"id": 118, "seek": 55658, "start": 573.86, "end": 582.0600000000001, "text": " You can, since 10.6, have ARIA and MyISM replication inside of Galera cluster.", "tokens": [51228, 509, 393, 11, 1670, 1266, 13, 21, 11, 362, 316, 41125, 293, 1222, 2343, 44, 39911, 1854, 295, 7336, 1663, 13630, 13, 51638], "temperature": 0.0, "avg_logprob": -0.22470618457328984, "compression_ratio": 1.5, "no_speech_prob": 0.07887358963489532}, {"id": 119, "seek": 58206, "start": 582.06, "end": 587.3399999999999, "text": " We consider this kind of experimental, but it works.", "tokens": [50364, 492, 1949, 341, 733, 295, 17069, 11, 457, 309, 1985, 13, 50628], "temperature": 0.0, "avg_logprob": -0.17117518121069605, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.2646598517894745}, {"id": 120, "seek": 58206, "start": 587.3399999999999, "end": 589.9799999999999, "text": " It's feature modes that are available.", "tokens": [50628, 467, 311, 4111, 14068, 300, 366, 2435, 13, 50760], "temperature": 0.0, "avg_logprob": -0.17117518121069605, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.2646598517894745}, {"id": 121, "seek": 58206, "start": 589.9799999999999, "end": 592.9799999999999, "text": " Of course, it disables tables without primary keys.", "tokens": [50760, 2720, 1164, 11, 309, 717, 2965, 8020, 1553, 6194, 9317, 13, 50910], "temperature": 0.0, "avg_logprob": -0.17117518121069605, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.2646598517894745}, {"id": 122, "seek": 58206, "start": 592.9799999999999, "end": 597.42, "text": " Again with something like MariaDB, you can also force primary key creation.", "tokens": [50910, 3764, 365, 746, 411, 12734, 27735, 11, 291, 393, 611, 3464, 6194, 2141, 8016, 13, 51132], "temperature": 0.0, "avg_logprob": -0.17117518121069605, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.2646598517894745}, {"id": 123, "seek": 58206, "start": 597.42, "end": 603.26, "text": " And Galera also has an option where you can sort of insert one, ensures using the row", "tokens": [51132, 400, 7336, 1663, 611, 575, 364, 3614, 689, 291, 393, 1333, 295, 8969, 472, 11, 28111, 1228, 264, 5386, 51424], "temperature": 0.0, "avg_logprob": -0.17117518121069605, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.2646598517894745}, {"id": 124, "seek": 58206, "start": 603.26, "end": 608.3, "text": " bin log format, logging to a file, obviously not tables.", "tokens": [51424, 5171, 3565, 7877, 11, 27991, 281, 257, 3991, 11, 2745, 406, 8020, 13, 51676], "temperature": 0.0, "avg_logprob": -0.17117518121069605, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.2646598517894745}, {"id": 125, "seek": 60830, "start": 608.3, "end": 612.74, "text": " So there's some interesting things, setting the inner DB auto increment log mode to two,", "tokens": [50364, 407, 456, 311, 512, 1880, 721, 11, 3287, 264, 7284, 26754, 8399, 26200, 3565, 4391, 281, 732, 11, 50586], "temperature": 0.0, "avg_logprob": -0.19275454755099314, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.00129983969964087}, {"id": 126, "seek": 60830, "start": 612.74, "end": 617.3, "text": " and of course, out of the box encryption.", "tokens": [50586, 293, 295, 1164, 11, 484, 295, 264, 2424, 29575, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19275454755099314, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.00129983969964087}, {"id": 127, "seek": 60830, "start": 617.3, "end": 621.8199999999999, "text": " So there are some feature highlights, like intelligent donor selection.", "tokens": [50814, 407, 456, 366, 512, 4111, 14254, 11, 411, 13232, 25493, 9450, 13, 51040], "temperature": 0.0, "avg_logprob": -0.19275454755099314, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.00129983969964087}, {"id": 128, "seek": 60830, "start": 621.8199999999999, "end": 630.66, "text": " So now with Galera 3 and 4, we 3.x where we have introduced new features.", "tokens": [51040, 407, 586, 365, 7336, 1663, 805, 293, 1017, 11, 321, 805, 13, 87, 689, 321, 362, 7268, 777, 4122, 13, 51482], "temperature": 0.0, "avg_logprob": -0.19275454755099314, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.00129983969964087}, {"id": 129, "seek": 60830, "start": 630.66, "end": 633.14, "text": " You can actually now prefer a donor to do an ISD.", "tokens": [51482, 509, 393, 767, 586, 4382, 257, 25493, 281, 360, 364, 6205, 35, 13, 51606], "temperature": 0.0, "avg_logprob": -0.19275454755099314, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.00129983969964087}, {"id": 130, "seek": 60830, "start": 633.14, "end": 638.14, "text": " When it comes to cluster crash recovery, we've actually by default turned on PC.recovery", "tokens": [51606, 1133, 309, 1487, 281, 13630, 8252, 8597, 11, 321, 600, 767, 538, 7576, 3574, 322, 6465, 13, 265, 21352, 51856], "temperature": 0.0, "avg_logprob": -0.19275454755099314, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.00129983969964087}, {"id": 131, "seek": 63814, "start": 638.14, "end": 643.06, "text": " equals on, so all nodes will maintain the cluster information persistently, not requiring", "tokens": [50364, 6915, 322, 11, 370, 439, 13891, 486, 6909, 264, 13630, 1589, 13233, 2276, 11, 406, 24165, 50610], "temperature": 0.0, "avg_logprob": -0.14499102916914164, "compression_ratio": 1.512396694214876, "no_speech_prob": 0.027549557387828827}, {"id": 132, "seek": 63814, "start": 643.06, "end": 645.14, "text": " necessarily to bootstrap.", "tokens": [50610, 4725, 281, 11450, 372, 4007, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14499102916914164, "compression_ratio": 1.512396694214876, "no_speech_prob": 0.027549557387828827}, {"id": 133, "seek": 63814, "start": 645.14, "end": 651.34, "text": " We have full GTID compatibility in Galera 4 with either MariaDB or MySQL, so actually", "tokens": [50714, 492, 362, 1577, 17530, 2777, 34237, 294, 7336, 1663, 1017, 365, 2139, 12734, 27735, 420, 1222, 39934, 11, 370, 767, 51024], "temperature": 0.0, "avg_logprob": -0.14499102916914164, "compression_ratio": 1.512396694214876, "no_speech_prob": 0.027549557387828827}, {"id": 134, "seek": 63814, "start": 651.34, "end": 655.5, "text": " using the native GTIDs as opposed to the Galera GTIDs.", "tokens": [51024, 1228, 264, 8470, 17530, 2777, 82, 382, 8851, 281, 264, 7336, 1663, 17530, 2777, 82, 13, 51232], "temperature": 0.0, "avg_logprob": -0.14499102916914164, "compression_ratio": 1.512396694214876, "no_speech_prob": 0.027549557387828827}, {"id": 135, "seek": 63814, "start": 655.5, "end": 662.78, "text": " So previously this was a bit of a point of contention, so this is actually a good thing.", "tokens": [51232, 407, 8046, 341, 390, 257, 857, 295, 257, 935, 295, 660, 1251, 11, 370, 341, 307, 767, 257, 665, 551, 13, 51596], "temperature": 0.0, "avg_logprob": -0.14499102916914164, "compression_ratio": 1.512396694214876, "no_speech_prob": 0.027549557387828827}, {"id": 136, "seek": 63814, "start": 662.78, "end": 663.78, "text": " Foreign key support.", "tokens": [51596, 20430, 2141, 1406, 13, 51646], "temperature": 0.0, "avg_logprob": -0.14499102916914164, "compression_ratio": 1.512396694214876, "no_speech_prob": 0.027549557387828827}, {"id": 137, "seek": 66378, "start": 663.9, "end": 669.02, "text": " When I say improved foreign key support, you'd actually, if you looked in your arrow logs", "tokens": [50370, 1133, 286, 584, 9689, 5329, 2141, 1406, 11, 291, 1116, 767, 11, 498, 291, 2956, 294, 428, 11610, 20820, 50626], "temperature": 0.0, "avg_logprob": -0.1598645528157552, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.20853345096111298}, {"id": 138, "seek": 66378, "start": 669.02, "end": 672.5, "text": " and used foreign keys, you may have found that there were lots and lots of errors that", "tokens": [50626, 293, 1143, 5329, 9317, 11, 291, 815, 362, 1352, 300, 456, 645, 3195, 293, 3195, 295, 13603, 300, 50800], "temperature": 0.0, "avg_logprob": -0.1598645528157552, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.20853345096111298}, {"id": 139, "seek": 66378, "start": 672.5, "end": 674.74, "text": " were not actually errors.", "tokens": [50800, 645, 406, 767, 13603, 13, 50912], "temperature": 0.0, "avg_logprob": -0.1598645528157552, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.20853345096111298}, {"id": 140, "seek": 66378, "start": 674.74, "end": 679.54, "text": " So cleaning up the error reporting was actually how we improved foreign key support, because", "tokens": [50912, 407, 8924, 493, 264, 6713, 10031, 390, 767, 577, 321, 9689, 5329, 2141, 1406, 11, 570, 51152], "temperature": 0.0, "avg_logprob": -0.1598645528157552, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.20853345096111298}, {"id": 141, "seek": 66378, "start": 679.54, "end": 683.22, "text": " lots of people were complaining like, hey, we're seeing this in the arrow logs, but it", "tokens": [51152, 3195, 295, 561, 645, 20740, 411, 11, 4177, 11, 321, 434, 2577, 341, 294, 264, 11610, 20820, 11, 457, 309, 51336], "temperature": 0.0, "avg_logprob": -0.1598645528157552, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.20853345096111298}, {"id": 142, "seek": 66378, "start": 683.22, "end": 684.98, "text": " was running just fine.", "tokens": [51336, 390, 2614, 445, 2489, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1598645528157552, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.20853345096111298}, {"id": 143, "seek": 66378, "start": 684.98, "end": 690.22, "text": " So it was just maybe a bit too verbose, and then we added a couple of new tables inside", "tokens": [51424, 407, 309, 390, 445, 1310, 257, 857, 886, 9595, 541, 11, 293, 550, 321, 3869, 257, 1916, 295, 777, 8020, 1854, 51686], "temperature": 0.0, "avg_logprob": -0.1598645528157552, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.20853345096111298}, {"id": 144, "seek": 69022, "start": 690.22, "end": 693.94, "text": " of the MySQL table as well.", "tokens": [50364, 295, 264, 1222, 39934, 3199, 382, 731, 13, 50550], "temperature": 0.0, "avg_logprob": -0.16009301654363084, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.07894748449325562}, {"id": 145, "seek": 69022, "start": 693.94, "end": 697.9, "text": " It's the WSJAP cluster, cluster members, and streaming log.", "tokens": [50550, 467, 311, 264, 343, 50, 41, 4715, 13630, 11, 13630, 2679, 11, 293, 11791, 3565, 13, 50748], "temperature": 0.0, "avg_logprob": -0.16009301654363084, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.07894748449325562}, {"id": 146, "seek": 69022, "start": 697.9, "end": 701.3000000000001, "text": " Very important to remember that streaming replication, which I'll talk about probably", "tokens": [50748, 4372, 1021, 281, 1604, 300, 11791, 39911, 11, 597, 286, 603, 751, 466, 1391, 50918], "temperature": 0.0, "avg_logprob": -0.16009301654363084, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.07894748449325562}, {"id": 147, "seek": 69022, "start": 701.3000000000001, "end": 706.46, "text": " in the next slide, actually does make use of chunking your data and putting it inside", "tokens": [50918, 294, 264, 958, 4137, 11, 767, 775, 652, 764, 295, 16635, 278, 428, 1412, 293, 3372, 309, 1854, 51176], "temperature": 0.0, "avg_logprob": -0.16009301654363084, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.07894748449325562}, {"id": 148, "seek": 69022, "start": 706.46, "end": 711.46, "text": " the MySQL table, so this actually improves the ability for you to use long-running transactions", "tokens": [51176, 264, 1222, 39934, 3199, 11, 370, 341, 767, 24771, 264, 3485, 337, 291, 281, 764, 938, 12, 45482, 16856, 51426], "temperature": 0.0, "avg_logprob": -0.16009301654363084, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.07894748449325562}, {"id": 149, "seek": 69022, "start": 711.46, "end": 714.6600000000001, "text": " or large transactions, so to speak.", "tokens": [51426, 420, 2416, 16856, 11, 370, 281, 1710, 13, 51586], "temperature": 0.0, "avg_logprob": -0.16009301654363084, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.07894748449325562}, {"id": 150, "seek": 69022, "start": 714.6600000000001, "end": 719.58, "text": " And that's why it's in the MySQL table because permissions, right, otherwise other people", "tokens": [51586, 400, 300, 311, 983, 309, 311, 294, 264, 1222, 39934, 3199, 570, 32723, 11, 558, 11, 5911, 661, 561, 51832], "temperature": 0.0, "avg_logprob": -0.16009301654363084, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.07894748449325562}, {"id": 151, "seek": 71958, "start": 719.58, "end": 723.0200000000001, "text": " are going to see what's being streamed.", "tokens": [50364, 366, 516, 281, 536, 437, 311, 885, 4309, 292, 13, 50536], "temperature": 0.0, "avg_logprob": -0.1759432696421212, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0673045739531517}, {"id": 152, "seek": 71958, "start": 723.0200000000001, "end": 724.34, "text": " Next slide.", "tokens": [50536, 3087, 4137, 13, 50602], "temperature": 0.0, "avg_logprob": -0.1759432696421212, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0673045739531517}, {"id": 153, "seek": 71958, "start": 724.34, "end": 730.7, "text": " So previously, you'd have to play with WSJAP Max WS rows and WSJAP Max WS size, limiting", "tokens": [50602, 407, 8046, 11, 291, 1116, 362, 281, 862, 365, 343, 50, 41, 4715, 7402, 343, 50, 13241, 293, 343, 50, 41, 4715, 7402, 343, 50, 2744, 11, 22083, 50920], "temperature": 0.0, "avg_logprob": -0.1759432696421212, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0673045739531517}, {"id": 154, "seek": 71958, "start": 730.7, "end": 736.5400000000001, "text": " the transaction rows between 128 kilobytes to a gigabyte, maximum of two gigabytes, but", "tokens": [50920, 264, 14425, 13241, 1296, 29810, 5128, 996, 43673, 281, 257, 8741, 34529, 11, 6674, 295, 732, 42741, 11, 457, 51212], "temperature": 0.0, "avg_logprob": -0.1759432696421212, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0673045739531517}, {"id": 155, "seek": 71958, "start": 736.5400000000001, "end": 741.0200000000001, "text": " now you can actually cut those large transactions by setting fragment sizes.", "tokens": [51212, 586, 291, 393, 767, 1723, 729, 2416, 16856, 538, 3287, 26424, 11602, 13, 51436], "temperature": 0.0, "avg_logprob": -0.1759432696421212, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0673045739531517}, {"id": 156, "seek": 71958, "start": 741.0200000000001, "end": 746.7, "text": " This can be done literally at runtime, so you can set them around 10,000 rows to 20,000", "tokens": [51436, 639, 393, 312, 1096, 3736, 412, 34474, 11, 370, 291, 393, 992, 552, 926, 1266, 11, 1360, 13241, 281, 945, 11, 1360, 51720], "temperature": 0.0, "avg_logprob": -0.1759432696421212, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0673045739531517}, {"id": 157, "seek": 74670, "start": 746.7, "end": 751.94, "text": " rows, and your application can also obviously set streaming replication on and off on a", "tokens": [50364, 13241, 11, 293, 428, 3861, 393, 611, 2745, 992, 11791, 39911, 322, 293, 766, 322, 257, 50626], "temperature": 0.0, "avg_logprob": -0.16613609770424345, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.13543705642223358}, {"id": 158, "seek": 74670, "start": 751.94, "end": 753.3000000000001, "text": " need-by-need basis.", "tokens": [50626, 643, 12, 2322, 12, 716, 292, 5143, 13, 50694], "temperature": 0.0, "avg_logprob": -0.16613609770424345, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.13543705642223358}, {"id": 159, "seek": 74670, "start": 753.3000000000001, "end": 755.5400000000001, "text": " Again, this doesn't come for free.", "tokens": [50694, 3764, 11, 341, 1177, 380, 808, 337, 1737, 13, 50806], "temperature": 0.0, "avg_logprob": -0.16613609770424345, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.13543705642223358}, {"id": 160, "seek": 74670, "start": 755.5400000000001, "end": 760.94, "text": " There is naturally replication overhead, which is being improved on in every release that", "tokens": [50806, 821, 307, 8195, 39911, 19922, 11, 597, 307, 885, 9689, 322, 294, 633, 4374, 300, 51076], "temperature": 0.0, "avg_logprob": -0.16613609770424345, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.13543705642223358}, {"id": 161, "seek": 74670, "start": 760.94, "end": 761.94, "text": " we come.", "tokens": [51076, 321, 808, 13, 51126], "temperature": 0.0, "avg_logprob": -0.16613609770424345, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.13543705642223358}, {"id": 162, "seek": 74670, "start": 761.94, "end": 766.38, "text": " So if you're always looking for the latest, greatest streaming replication, naturally", "tokens": [51126, 407, 498, 291, 434, 1009, 1237, 337, 264, 6792, 11, 6636, 11791, 39911, 11, 8195, 51348], "temperature": 0.0, "avg_logprob": -0.16613609770424345, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.13543705642223358}, {"id": 163, "seek": 74670, "start": 766.38, "end": 769.7800000000001, "text": " you'd want to take a look at what's inside of MariaDB.", "tokens": [51348, 291, 1116, 528, 281, 747, 257, 574, 412, 437, 311, 1854, 295, 12734, 27735, 13, 51518], "temperature": 0.0, "avg_logprob": -0.16613609770424345, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.13543705642223358}, {"id": 164, "seek": 74670, "start": 769.7800000000001, "end": 773.86, "text": " And then, of course, there is better error handling for poor networks, so cluster error", "tokens": [51518, 400, 550, 11, 295, 1164, 11, 456, 307, 1101, 6713, 13175, 337, 4716, 9590, 11, 370, 13630, 6713, 51722], "temperature": 0.0, "avg_logprob": -0.16613609770424345, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.13543705642223358}, {"id": 165, "seek": 77386, "start": 773.86, "end": 780.94, "text": " voting is a feature that has a protocol for nodes to decide how the cluster will react", "tokens": [50364, 10419, 307, 257, 4111, 300, 575, 257, 10336, 337, 13891, 281, 4536, 577, 264, 13630, 486, 4515, 50718], "temperature": 0.0, "avg_logprob": -0.11436862439180898, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.16419877111911774}, {"id": 166, "seek": 77386, "start": 780.94, "end": 782.9, "text": " to problems inside of replication.", "tokens": [50718, 281, 2740, 1854, 295, 39911, 13, 50816], "temperature": 0.0, "avg_logprob": -0.11436862439180898, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.16419877111911774}, {"id": 167, "seek": 77386, "start": 782.9, "end": 788.5, "text": " So when one or several nodes have an issue to apply an incoming transaction, like a suspected", "tokens": [50816, 407, 562, 472, 420, 2940, 13891, 362, 364, 2734, 281, 3079, 364, 22341, 14425, 11, 411, 257, 26439, 51096], "temperature": 0.0, "avg_logprob": -0.11436862439180898, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.16419877111911774}, {"id": 168, "seek": 77386, "start": 788.5, "end": 791.26, "text": " inconsistency, this feature basically helps.", "tokens": [51096, 22039, 468, 3020, 11, 341, 4111, 1936, 3665, 13, 51234], "temperature": 0.0, "avg_logprob": -0.11436862439180898, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.16419877111911774}, {"id": 169, "seek": 77386, "start": 791.26, "end": 796.58, "text": " So in a five-node cluster, if two nodes basically fail to apply a transaction, they get removed,", "tokens": [51234, 407, 294, 257, 1732, 12, 77, 1429, 13630, 11, 498, 732, 13891, 1936, 3061, 281, 3079, 257, 14425, 11, 436, 483, 7261, 11, 51500], "temperature": 0.0, "avg_logprob": -0.11436862439180898, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.16419877111911774}, {"id": 170, "seek": 77386, "start": 796.58, "end": 801.02, "text": " and of course, now your DBA could go into fix to see what went wrong and then rejoin", "tokens": [51500, 293, 295, 1164, 11, 586, 428, 413, 9295, 727, 352, 666, 3191, 281, 536, 437, 1437, 2085, 293, 550, 22087, 259, 51722], "temperature": 0.0, "avg_logprob": -0.11436862439180898, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.16419877111911774}, {"id": 171, "seek": 77386, "start": 801.02, "end": 803.7, "text": " the cluster.", "tokens": [51722, 264, 13630, 13, 51856], "temperature": 0.0, "avg_logprob": -0.11436862439180898, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.16419877111911774}, {"id": 172, "seek": 80370, "start": 803.7, "end": 809.38, "text": " So I know we had forced them, so this is an apology slide because, unfortunately, there", "tokens": [50364, 407, 286, 458, 321, 632, 7579, 552, 11, 370, 341, 307, 364, 28006, 4137, 570, 11, 7015, 11, 456, 50648], "temperature": 0.0, "avg_logprob": -0.1570645365221747, "compression_ratio": 1.5567765567765568, "no_speech_prob": 0.06715705245733261}, {"id": 173, "seek": 80370, "start": 809.38, "end": 811.62, "text": " are enterprise features, but I will not talk about them.", "tokens": [50648, 366, 14132, 4122, 11, 457, 286, 486, 406, 751, 466, 552, 13, 50760], "temperature": 0.0, "avg_logprob": -0.1570645365221747, "compression_ratio": 1.5567765567765568, "no_speech_prob": 0.06715705245733261}, {"id": 174, "seek": 80370, "start": 811.62, "end": 813.94, "text": " This is for you to go check them out yourself.", "tokens": [50760, 639, 307, 337, 291, 281, 352, 1520, 552, 484, 1803, 13, 50876], "temperature": 0.0, "avg_logprob": -0.1570645365221747, "compression_ratio": 1.5567765567765568, "no_speech_prob": 0.06715705245733261}, {"id": 175, "seek": 80370, "start": 813.94, "end": 819.98, "text": " Both MariaDB and Codeship have these options.", "tokens": [50876, 6767, 12734, 27735, 293, 383, 4789, 1210, 362, 613, 3956, 13, 51178], "temperature": 0.0, "avg_logprob": -0.1570645365221747, "compression_ratio": 1.5567765567765568, "no_speech_prob": 0.06715705245733261}, {"id": 176, "seek": 80370, "start": 819.98, "end": 824.6600000000001, "text": " The biggest hurdle to upgrades that I hear from consulting is we don't want to migrate", "tokens": [51178, 440, 3880, 47423, 281, 24868, 300, 286, 1568, 490, 23682, 307, 321, 500, 380, 528, 281, 31821, 51412], "temperature": 0.0, "avg_logprob": -0.1570645365221747, "compression_ratio": 1.5567765567765568, "no_speech_prob": 0.06715705245733261}, {"id": 177, "seek": 80370, "start": 824.6600000000001, "end": 826.0200000000001, "text": " to MySQL 8.", "tokens": [51412, 281, 1222, 39934, 1649, 13, 51480], "temperature": 0.0, "avg_logprob": -0.1570645365221747, "compression_ratio": 1.5567765567765568, "no_speech_prob": 0.06715705245733261}, {"id": 178, "seek": 80370, "start": 826.0200000000001, "end": 832.26, "text": " I don't know why people say this a lot, but if you are using MySQL, last I checked, it's", "tokens": [51480, 286, 500, 380, 458, 983, 561, 584, 341, 257, 688, 11, 457, 498, 291, 366, 1228, 1222, 39934, 11, 1036, 286, 10033, 11, 309, 311, 51792], "temperature": 0.0, "avg_logprob": -0.1570645365221747, "compression_ratio": 1.5567765567765568, "no_speech_prob": 0.06715705245733261}, {"id": 179, "seek": 83226, "start": 832.3, "end": 835.98, "text": " going to EOL fairly soon, 5.7, so it's time to upgrade.", "tokens": [50366, 516, 281, 462, 5046, 6457, 2321, 11, 1025, 13, 22, 11, 370, 309, 311, 565, 281, 11484, 13, 50550], "temperature": 0.0, "avg_logprob": -0.17136065743186257, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.14379273355007172}, {"id": 180, "seek": 83226, "start": 835.98, "end": 838.1, "text": " You've got eight more months to get working.", "tokens": [50550, 509, 600, 658, 3180, 544, 2493, 281, 483, 1364, 13, 50656], "temperature": 0.0, "avg_logprob": -0.17136065743186257, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.14379273355007172}, {"id": 181, "seek": 83226, "start": 838.1, "end": 843.9, "text": " And if you want Galera 4, remember, MariaDB's had it since 10.4, but again, a lot of you", "tokens": [50656, 400, 498, 291, 528, 7336, 1663, 1017, 11, 1604, 11, 12734, 27735, 311, 632, 309, 1670, 1266, 13, 19, 11, 457, 797, 11, 257, 688, 295, 291, 50946], "temperature": 0.0, "avg_logprob": -0.17136065743186257, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.14379273355007172}, {"id": 182, "seek": 83226, "start": 843.9, "end": 847.34, "text": " are not even on the 10.4 or 10.5 train yet.", "tokens": [50946, 366, 406, 754, 322, 264, 1266, 13, 19, 420, 1266, 13, 20, 3847, 1939, 13, 51118], "temperature": 0.0, "avg_logprob": -0.17136065743186257, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.14379273355007172}, {"id": 183, "seek": 83226, "start": 847.34, "end": 854.9, "text": " So upgrading from 10.2 or 10.3 is probably something that is ideal if you can find the", "tokens": [51118, 407, 36249, 490, 1266, 13, 17, 420, 1266, 13, 18, 307, 1391, 746, 300, 307, 7157, 498, 291, 393, 915, 264, 51496], "temperature": 0.0, "avg_logprob": -0.17136065743186257, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.14379273355007172}, {"id": 184, "seek": 83226, "start": 854.9, "end": 855.9, "text": " time to do it.", "tokens": [51496, 565, 281, 360, 309, 13, 51546], "temperature": 0.0, "avg_logprob": -0.17136065743186257, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.14379273355007172}, {"id": 185, "seek": 85590, "start": 855.9, "end": 864.34, "text": " Okay.", "tokens": [50364, 1033, 13, 50786], "temperature": 0.0, "avg_logprob": -0.2466624704996745, "compression_ratio": 1.7034883720930232, "no_speech_prob": 0.029820797964930534}, {"id": 186, "seek": 85590, "start": 864.34, "end": 866.86, "text": " Common setups.", "tokens": [50786, 18235, 46832, 13, 50912], "temperature": 0.0, "avg_logprob": -0.2466624704996745, "compression_ratio": 1.7034883720930232, "no_speech_prob": 0.029820797964930534}, {"id": 187, "seek": 85590, "start": 866.86, "end": 869.54, "text": " Three Galera cluster nodes in one data center.", "tokens": [50912, 6244, 7336, 1663, 13630, 13891, 294, 472, 1412, 3056, 13, 51046], "temperature": 0.0, "avg_logprob": -0.2466624704996745, "compression_ratio": 1.7034883720930232, "no_speech_prob": 0.029820797964930534}, {"id": 188, "seek": 85590, "start": 869.54, "end": 873.5799999999999, "text": " This is the highly recommended common setup.", "tokens": [51046, 639, 307, 264, 5405, 9628, 2689, 8657, 13, 51248], "temperature": 0.0, "avg_logprob": -0.2466624704996745, "compression_ratio": 1.7034883720930232, "no_speech_prob": 0.029820797964930534}, {"id": 189, "seek": 85590, "start": 873.5799999999999, "end": 875.98, "text": " Nine Galera cluster nodes in three data centers.", "tokens": [51248, 18939, 7336, 1663, 13630, 13891, 294, 1045, 1412, 10898, 13, 51368], "temperature": 0.0, "avg_logprob": -0.2466624704996745, "compression_ratio": 1.7034883720930232, "no_speech_prob": 0.029820797964930534}, {"id": 190, "seek": 85590, "start": 875.98, "end": 878.78, "text": " Also, of course, another recommended setup.", "tokens": [51368, 2743, 11, 295, 1164, 11, 1071, 9628, 8657, 13, 51508], "temperature": 0.0, "avg_logprob": -0.2466624704996745, "compression_ratio": 1.7034883720930232, "no_speech_prob": 0.029820797964930534}, {"id": 191, "seek": 85590, "start": 878.78, "end": 883.34, "text": " And if you are doing this, make sure you are ensuring your database operations are kept", "tokens": [51508, 400, 498, 291, 366, 884, 341, 11, 652, 988, 291, 366, 16882, 428, 8149, 7705, 366, 4305, 51736], "temperature": 0.0, "avg_logprob": -0.2466624704996745, "compression_ratio": 1.7034883720930232, "no_speech_prob": 0.029820797964930534}, {"id": 192, "seek": 88334, "start": 883.34, "end": 888.7800000000001, "text": " local by setting each data center that GMCAST segment equals 0, 1, 2.", "tokens": [50364, 2654, 538, 3287, 1184, 1412, 3056, 300, 16609, 34, 20398, 9469, 6915, 1958, 11, 502, 11, 568, 13, 50636], "temperature": 0.0, "avg_logprob": -0.19782784058875644, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.006383994594216347}, {"id": 193, "seek": 88334, "start": 888.7800000000001, "end": 892.5, "text": " And of course, the flow control is fully configurable.", "tokens": [50636, 400, 295, 1164, 11, 264, 3095, 1969, 307, 4498, 22192, 712, 13, 50822], "temperature": 0.0, "avg_logprob": -0.19782784058875644, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.006383994594216347}, {"id": 194, "seek": 88334, "start": 892.5, "end": 895.58, "text": " And we want to have minimal latency penalty.", "tokens": [50822, 400, 321, 528, 281, 362, 13206, 27043, 16263, 13, 50976], "temperature": 0.0, "avg_logprob": -0.19782784058875644, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.006383994594216347}, {"id": 195, "seek": 88334, "start": 895.58, "end": 902.94, "text": " Remember that latency penalty only occurs during commit time, so then actually no communication", "tokens": [50976, 5459, 300, 27043, 16263, 787, 11843, 1830, 5599, 565, 11, 370, 550, 767, 572, 6101, 51344], "temperature": 0.0, "avg_logprob": -0.19782784058875644, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.006383994594216347}, {"id": 196, "seek": 88334, "start": 902.94, "end": 907.26, "text": " between these remote nodes and Galera doesn't use distributed locking, so each row-level", "tokens": [51344, 1296, 613, 8607, 13891, 293, 7336, 1663, 1177, 380, 764, 12631, 23954, 11, 370, 1184, 5386, 12, 12418, 51560], "temperature": 0.0, "avg_logprob": -0.19782784058875644, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.006383994594216347}, {"id": 197, "seek": 88334, "start": 907.26, "end": 911.22, "text": " lock does not have to be communicated across data centers.", "tokens": [51560, 4017, 775, 406, 362, 281, 312, 34989, 2108, 1412, 10898, 13, 51758], "temperature": 0.0, "avg_logprob": -0.19782784058875644, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.006383994594216347}, {"id": 198, "seek": 91122, "start": 911.22, "end": 915.9, "text": " So in very, very high latency situations where complete avoidance of secondary lag", "tokens": [50364, 407, 294, 588, 11, 588, 1090, 27043, 6851, 689, 3566, 5042, 719, 295, 11396, 8953, 50598], "temperature": 0.0, "avg_logprob": -0.14649132186291264, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.0524662546813488}, {"id": 199, "seek": 91122, "start": 915.9, "end": 921.1, "text": " is required, we can also support asynchronous replication between two otherwise independent", "tokens": [50598, 307, 4739, 11, 321, 393, 611, 1406, 49174, 39911, 1296, 732, 5911, 6695, 50858], "temperature": 0.0, "avg_logprob": -0.14649132186291264, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.0524662546813488}, {"id": 200, "seek": 91122, "start": 921.1, "end": 924.46, "text": " Galera clusters, each running in its own data center.", "tokens": [50858, 7336, 1663, 23313, 11, 1184, 2614, 294, 1080, 1065, 1412, 3056, 13, 51026], "temperature": 0.0, "avg_logprob": -0.14649132186291264, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.0524662546813488}, {"id": 201, "seek": 91122, "start": 924.46, "end": 930.5400000000001, "text": " Now I put an asterisk there with recommended because I know Marco Tusa is not here today,", "tokens": [51026, 823, 286, 829, 364, 257, 3120, 7797, 456, 365, 9628, 570, 286, 458, 26535, 314, 20318, 307, 406, 510, 965, 11, 51330], "temperature": 0.0, "avg_logprob": -0.14649132186291264, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.0524662546813488}, {"id": 202, "seek": 91122, "start": 930.5400000000001, "end": 937.6600000000001, "text": " but he was on Friday and he has written a lot about why you should never run your Galera", "tokens": [51330, 457, 415, 390, 322, 6984, 293, 415, 575, 3720, 257, 688, 466, 983, 291, 820, 1128, 1190, 428, 7336, 1663, 51686], "temperature": 0.0, "avg_logprob": -0.14649132186291264, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.0524662546813488}, {"id": 203, "seek": 91122, "start": 937.6600000000001, "end": 941.0600000000001, "text": " clusters in a wide area network.", "tokens": [51686, 23313, 294, 257, 4874, 1859, 3209, 13, 51856], "temperature": 0.0, "avg_logprob": -0.14649132186291264, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.0524662546813488}, {"id": 204, "seek": 94106, "start": 941.06, "end": 945.0999999999999, "text": " Or I guess even your group replication in IndieBee clusters in a wide area network to", "tokens": [50364, 1610, 286, 2041, 754, 428, 1594, 39911, 294, 2333, 414, 33, 1653, 23313, 294, 257, 4874, 1859, 3209, 281, 50566], "temperature": 0.0, "avg_logprob": -0.2256910445842337, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.1414038985967636}, {"id": 205, "seek": 94106, "start": 945.0999999999999, "end": 946.54, "text": " some extent.", "tokens": [50566, 512, 8396, 13, 50638], "temperature": 0.0, "avg_logprob": -0.2256910445842337, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.1414038985967636}, {"id": 206, "seek": 94106, "start": 946.54, "end": 952.3399999999999, "text": " And he's spent quite a lot of blogs and including a video.", "tokens": [50638, 400, 415, 311, 4418, 1596, 257, 688, 295, 31038, 293, 3009, 257, 960, 13, 50928], "temperature": 0.0, "avg_logprob": -0.2256910445842337, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.1414038985967636}, {"id": 207, "seek": 94106, "start": 952.3399999999999, "end": 959.5799999999999, "text": " So basically whenever you need a solution based on a tightly coupled database cluster,", "tokens": [50928, 407, 1936, 5699, 291, 643, 257, 3827, 2361, 322, 257, 21952, 29482, 8149, 13630, 11, 51290], "temperature": 0.0, "avg_logprob": -0.2256910445842337, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.1414038985967636}, {"id": 208, "seek": 94106, "start": 959.5799999999999, "end": 963.42, "text": " you can't obviously locate your nodes at a distance that is longer than the largest", "tokens": [51290, 291, 393, 380, 2745, 22370, 428, 13891, 412, 257, 4560, 300, 307, 2854, 813, 264, 6443, 51482], "temperature": 0.0, "avg_logprob": -0.2256910445842337, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.1414038985967636}, {"id": 209, "seek": 94106, "start": 963.42, "end": 968.5, "text": " round-trip time of the shortest desired period of commit.", "tokens": [51482, 3098, 12, 83, 8400, 565, 295, 264, 31875, 14721, 2896, 295, 5599, 13, 51736], "temperature": 0.0, "avg_logprob": -0.2256910445842337, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.1414038985967636}, {"id": 210, "seek": 96850, "start": 969.5, "end": 971.38, "text": " Wow, five more minutes.", "tokens": [50414, 3153, 11, 1732, 544, 2077, 13, 50508], "temperature": 0.0, "avg_logprob": -0.19079296677200883, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.18191561102867126}, {"id": 211, "seek": 96850, "start": 971.38, "end": 974.46, "text": " We're going to go fast now.", "tokens": [50508, 492, 434, 516, 281, 352, 2370, 586, 13, 50662], "temperature": 0.0, "avg_logprob": -0.19079296677200883, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.18191561102867126}, {"id": 212, "seek": 96850, "start": 974.46, "end": 979.38, "text": " You should always remember that we like the minimum of three nodes basically in terms", "tokens": [50662, 509, 820, 1009, 1604, 300, 321, 411, 264, 7285, 295, 1045, 13891, 1936, 294, 2115, 50908], "temperature": 0.0, "avg_logprob": -0.19079296677200883, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.18191561102867126}, {"id": 213, "seek": 96850, "start": 979.38, "end": 983.86, "text": " of a quorum because a quorum is greater than 50 percent, so if one node goes away you still", "tokens": [50908, 295, 257, 421, 36543, 570, 257, 421, 36543, 307, 5044, 813, 2625, 3043, 11, 370, 498, 472, 9984, 1709, 1314, 291, 920, 51132], "temperature": 0.0, "avg_logprob": -0.19079296677200883, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.18191561102867126}, {"id": 214, "seek": 96850, "start": 983.86, "end": 986.82, "text": " have two thirds, 66.7.", "tokens": [51132, 362, 732, 34552, 11, 21126, 13, 22, 13, 51280], "temperature": 0.0, "avg_logprob": -0.19079296677200883, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.18191561102867126}, {"id": 215, "seek": 96850, "start": 986.82, "end": 990.5, "text": " And you always want to ensure the primary component is there because otherwise if it", "tokens": [51280, 400, 291, 1009, 528, 281, 5586, 264, 6194, 6542, 307, 456, 570, 5911, 498, 309, 51464], "temperature": 0.0, "avg_logprob": -0.19079296677200883, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.18191561102867126}, {"id": 216, "seek": 96850, "start": 990.5, "end": 993.7, "text": " splits due to network failure you have split brain.", "tokens": [51464, 37741, 3462, 281, 3209, 7763, 291, 362, 7472, 3567, 13, 51624], "temperature": 0.0, "avg_logprob": -0.19079296677200883, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.18191561102867126}, {"id": 217, "seek": 96850, "start": 993.7, "end": 995.42, "text": " So this is very bad.", "tokens": [51624, 407, 341, 307, 588, 1578, 13, 51710], "temperature": 0.0, "avg_logprob": -0.19079296677200883, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.18191561102867126}, {"id": 218, "seek": 99542, "start": 995.42, "end": 1002.18, "text": " You can fine-tune this with evs.suspectTimeout as a parameter.", "tokens": [50364, 509, 393, 2489, 12, 83, 2613, 341, 365, 1073, 82, 13, 82, 301, 1043, 22233, 346, 382, 257, 13075, 13, 50702], "temperature": 0.0, "avg_logprob": -0.1762295475712529, "compression_ratio": 1.7296137339055795, "no_speech_prob": 0.0026309078093618155}, {"id": 219, "seek": 99542, "start": 1002.18, "end": 1005.2199999999999, "text": " Very realistic common setups that we end up seeing.", "tokens": [50702, 4372, 12465, 2689, 46832, 300, 321, 917, 493, 2577, 13, 50854], "temperature": 0.0, "avg_logprob": -0.1762295475712529, "compression_ratio": 1.7296137339055795, "no_speech_prob": 0.0026309078093618155}, {"id": 220, "seek": 99542, "start": 1005.2199999999999, "end": 1008.3, "text": " Two node Galera cluster, really not recommended.", "tokens": [50854, 4453, 9984, 7336, 1663, 13630, 11, 534, 406, 9628, 13, 51008], "temperature": 0.0, "avg_logprob": -0.1762295475712529, "compression_ratio": 1.7296137339055795, "no_speech_prob": 0.0026309078093618155}, {"id": 221, "seek": 99542, "start": 1008.3, "end": 1011.4599999999999, "text": " Even though we documented, we tell you how to shoot yourself in the foot, it doesn't", "tokens": [51008, 2754, 1673, 321, 23007, 11, 321, 980, 291, 577, 281, 3076, 1803, 294, 264, 2671, 11, 309, 1177, 380, 51166], "temperature": 0.0, "avg_logprob": -0.1762295475712529, "compression_ratio": 1.7296137339055795, "no_speech_prob": 0.0026309078093618155}, {"id": 222, "seek": 99542, "start": 1011.4599999999999, "end": 1013.6999999999999, "text": " mean you should.", "tokens": [51166, 914, 291, 820, 13, 51278], "temperature": 0.0, "avg_logprob": -0.1762295475712529, "compression_ratio": 1.7296137339055795, "no_speech_prob": 0.0026309078093618155}, {"id": 223, "seek": 99542, "start": 1013.6999999999999, "end": 1017.5, "text": " Three node Galera cluster across two data centers also common.", "tokens": [51278, 6244, 9984, 7336, 1663, 13630, 2108, 732, 1412, 10898, 611, 2689, 13, 51468], "temperature": 0.0, "avg_logprob": -0.1762295475712529, "compression_ratio": 1.7296137339055795, "no_speech_prob": 0.0026309078093618155}, {"id": 224, "seek": 99542, "start": 1017.5, "end": 1020.9, "text": " Three node across three data centers also common.", "tokens": [51468, 6244, 9984, 2108, 1045, 1412, 10898, 611, 2689, 13, 51638], "temperature": 0.0, "avg_logprob": -0.1762295475712529, "compression_ratio": 1.7296137339055795, "no_speech_prob": 0.0026309078093618155}, {"id": 225, "seek": 99542, "start": 1020.9, "end": 1023.26, "text": " Five nodes, seven nodes.", "tokens": [51638, 9436, 13891, 11, 3407, 13891, 13, 51756], "temperature": 0.0, "avg_logprob": -0.1762295475712529, "compression_ratio": 1.7296137339055795, "no_speech_prob": 0.0026309078093618155}, {"id": 226, "seek": 102326, "start": 1023.26, "end": 1026.78, "text": " So you always have to remember the trade-offs of scalability, reliability, resilience and", "tokens": [50364, 407, 291, 1009, 362, 281, 1604, 264, 4923, 12, 19231, 295, 15664, 2310, 11, 24550, 11, 19980, 293, 50540], "temperature": 0.0, "avg_logprob": -0.194486105883563, "compression_ratio": 1.6082089552238805, "no_speech_prob": 0.006468288600444794}, {"id": 227, "seek": 102326, "start": 1026.78, "end": 1027.78, "text": " performance.", "tokens": [50540, 3389, 13, 50590], "temperature": 0.0, "avg_logprob": -0.194486105883563, "compression_ratio": 1.6082089552238805, "no_speech_prob": 0.006468288600444794}, {"id": 228, "seek": 102326, "start": 1027.78, "end": 1034.22, "text": " This is a sample of my.cnf that one would want to maybe pay a bit of attention to where", "tokens": [50590, 639, 307, 257, 6889, 295, 452, 13, 16279, 69, 300, 472, 576, 528, 281, 1310, 1689, 257, 857, 295, 3202, 281, 689, 50912], "temperature": 0.0, "avg_logprob": -0.194486105883563, "compression_ratio": 1.6082089552238805, "no_speech_prob": 0.006468288600444794}, {"id": 229, "seek": 102326, "start": 1034.22, "end": 1038.78, "text": " we actually include a WSR provider options because by default we don't put a segment", "tokens": [50912, 321, 767, 4090, 257, 343, 50, 49, 12398, 3956, 570, 538, 7576, 321, 500, 380, 829, 257, 9469, 51140], "temperature": 0.0, "avg_logprob": -0.194486105883563, "compression_ratio": 1.6082089552238805, "no_speech_prob": 0.006468288600444794}, {"id": 230, "seek": 102326, "start": 1038.78, "end": 1042.18, "text": " for example, but you also want more than just a segment.", "tokens": [51140, 337, 1365, 11, 457, 291, 611, 528, 544, 813, 445, 257, 9469, 13, 51310], "temperature": 0.0, "avg_logprob": -0.194486105883563, "compression_ratio": 1.6082089552238805, "no_speech_prob": 0.006468288600444794}, {"id": 231, "seek": 102326, "start": 1042.18, "end": 1048.06, "text": " You want to, if you're doing wide area network stuff, consider increasing the replication", "tokens": [51310, 509, 528, 281, 11, 498, 291, 434, 884, 4874, 1859, 3209, 1507, 11, 1949, 5662, 264, 39911, 51604], "temperature": 0.0, "avg_logprob": -0.194486105883563, "compression_ratio": 1.6082089552238805, "no_speech_prob": 0.006468288600444794}, {"id": 232, "seek": 102326, "start": 1048.06, "end": 1049.18, "text": " windows.", "tokens": [51604, 9309, 13, 51660], "temperature": 0.0, "avg_logprob": -0.194486105883563, "compression_ratio": 1.6082089552238805, "no_speech_prob": 0.006468288600444794}, {"id": 233, "seek": 104918, "start": 1049.18, "end": 1053.1000000000001, "text": " You want to increase the timeouts above max round trip time.", "tokens": [50364, 509, 528, 281, 3488, 264, 565, 7711, 3673, 11469, 3098, 4931, 565, 13, 50560], "temperature": 0.0, "avg_logprob": -0.21527543469010113, "compression_ratio": 1.6991869918699187, "no_speech_prob": 0.3683684468269348}, {"id": 234, "seek": 104918, "start": 1053.1000000000001, "end": 1056.5800000000002, "text": " Look at the flow control which you can actually monitor inside.", "tokens": [50560, 2053, 412, 264, 3095, 1969, 597, 291, 393, 767, 6002, 1854, 13, 50734], "temperature": 0.0, "avg_logprob": -0.21527543469010113, "compression_ratio": 1.6991869918699187, "no_speech_prob": 0.3683684468269348}, {"id": 235, "seek": 104918, "start": 1056.5800000000002, "end": 1063.54, "text": " And then pay attention to the FC limit, the master slave yes, causal read, timeouts and", "tokens": [50734, 400, 550, 1689, 3202, 281, 264, 27168, 4948, 11, 264, 4505, 14777, 2086, 11, 38755, 1401, 11, 565, 7711, 293, 51082], "temperature": 0.0, "avg_logprob": -0.21527543469010113, "compression_ratio": 1.6991869918699187, "no_speech_prob": 0.3683684468269348}, {"id": 236, "seek": 104918, "start": 1063.54, "end": 1068.7, "text": " the evs settings where you can actually set the send window to 512, the user send window", "tokens": [51082, 264, 1073, 82, 6257, 689, 291, 393, 767, 992, 264, 2845, 4910, 281, 1025, 4762, 11, 264, 4195, 2845, 4910, 51340], "temperature": 0.0, "avg_logprob": -0.21527543469010113, "compression_ratio": 1.6991869918699187, "no_speech_prob": 0.3683684468269348}, {"id": 237, "seek": 104918, "start": 1068.7, "end": 1070.46, "text": " to 512.", "tokens": [51340, 281, 1025, 4762, 13, 51428], "temperature": 0.0, "avg_logprob": -0.21527543469010113, "compression_ratio": 1.6991869918699187, "no_speech_prob": 0.3683684468269348}, {"id": 238, "seek": 104918, "start": 1070.46, "end": 1073.0600000000002, "text": " You can look at the keep alive periods.", "tokens": [51428, 509, 393, 574, 412, 264, 1066, 5465, 13804, 13, 51558], "temperature": 0.0, "avg_logprob": -0.21527543469010113, "compression_ratio": 1.6991869918699187, "no_speech_prob": 0.3683684468269348}, {"id": 239, "seek": 104918, "start": 1073.0600000000002, "end": 1077.78, "text": " We have all this actually in blogs and documentation to some extent.", "tokens": [51558, 492, 362, 439, 341, 767, 294, 31038, 293, 14333, 281, 512, 8396, 13, 51794], "temperature": 0.0, "avg_logprob": -0.21527543469010113, "compression_ratio": 1.6991869918699187, "no_speech_prob": 0.3683684468269348}, {"id": 240, "seek": 107778, "start": 1077.78, "end": 1083.74, "text": " So I'd highly recommend you pay attention to galeracluster.com slash blog.", "tokens": [50364, 407, 286, 1116, 5405, 2748, 291, 1689, 3202, 281, 7660, 260, 326, 75, 8393, 13, 1112, 17330, 6968, 13, 50662], "temperature": 0.0, "avg_logprob": -0.2736986654776114, "compression_ratio": 1.5720164609053497, "no_speech_prob": 0.41654589772224426}, {"id": 241, "seek": 107778, "start": 1083.74, "end": 1087.7, "text": " Always set your GCash size.", "tokens": [50662, 11270, 992, 428, 29435, 1299, 2744, 13, 50860], "temperature": 0.0, "avg_logprob": -0.2736986654776114, "compression_ratio": 1.5720164609053497, "no_speech_prob": 0.41654589772224426}, {"id": 242, "seek": 107778, "start": 1087.7, "end": 1091.74, "text": " Potentially also set your retry autocommit, something like five.", "tokens": [50860, 9145, 3137, 611, 992, 428, 1533, 627, 45833, 1204, 270, 11, 746, 411, 1732, 13, 51062], "temperature": 0.0, "avg_logprob": -0.2736986654776114, "compression_ratio": 1.5720164609053497, "no_speech_prob": 0.41654589772224426}, {"id": 243, "seek": 107778, "start": 1091.74, "end": 1096.7, "text": " You may want to certify non-primary key stuff, but really you should use primary keys.", "tokens": [51062, 509, 815, 528, 281, 5351, 2505, 2107, 12, 1424, 332, 822, 2141, 1507, 11, 457, 534, 291, 820, 764, 6194, 9317, 13, 51310], "temperature": 0.0, "avg_logprob": -0.2736986654776114, "compression_ratio": 1.5720164609053497, "no_speech_prob": 0.41654589772224426}, {"id": 244, "seek": 107778, "start": 1096.7, "end": 1098.62, "text": " You tell the developers to use primary keys.", "tokens": [51310, 509, 980, 264, 8849, 281, 764, 6194, 9317, 13, 51406], "temperature": 0.0, "avg_logprob": -0.2736986654776114, "compression_ratio": 1.5720164609053497, "no_speech_prob": 0.41654589772224426}, {"id": 245, "seek": 107778, "start": 1098.62, "end": 1105.94, "text": " In fact, if you're using MariaDB, you can say in a DBforce primary key equals one.", "tokens": [51406, 682, 1186, 11, 498, 291, 434, 1228, 12734, 27735, 11, 291, 393, 584, 294, 257, 26754, 5156, 6194, 2141, 6915, 472, 13, 51772], "temperature": 0.0, "avg_logprob": -0.2736986654776114, "compression_ratio": 1.5720164609053497, "no_speech_prob": 0.41654589772224426}, {"id": 246, "seek": 110594, "start": 1105.94, "end": 1109.78, "text": " Make it such that they can't create tables any longer.", "tokens": [50364, 4387, 309, 1270, 300, 436, 393, 380, 1884, 8020, 604, 2854, 13, 50556], "temperature": 0.0, "avg_logprob": -0.17824966793968564, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.21158583462238312}, {"id": 247, "seek": 110594, "start": 1109.78, "end": 1113.5800000000002, "text": " Make the developers suffer a little bit.", "tokens": [50556, 4387, 264, 8849, 9753, 257, 707, 857, 13, 50746], "temperature": 0.0, "avg_logprob": -0.17824966793968564, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.21158583462238312}, {"id": 248, "seek": 110594, "start": 1113.5800000000002, "end": 1118.6200000000001, "text": " Replicate my ISM, replicate ARIA, these are all things that are very MariaDB specific.", "tokens": [50746, 1300, 4770, 473, 452, 6205, 44, 11, 25356, 316, 41125, 11, 613, 366, 439, 721, 300, 366, 588, 12734, 27735, 2685, 13, 50998], "temperature": 0.0, "avg_logprob": -0.17824966793968564, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.21158583462238312}, {"id": 249, "seek": 110594, "start": 1118.6200000000001, "end": 1123.6200000000001, "text": " I'd like to actually talk about the ring buffer file as well as the on demand page store which", "tokens": [50998, 286, 1116, 411, 281, 767, 751, 466, 264, 4875, 21762, 3991, 382, 731, 382, 264, 322, 4733, 3028, 3531, 597, 51248], "temperature": 0.0, "avg_logprob": -0.17824966793968564, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.21158583462238312}, {"id": 250, "seek": 110594, "start": 1123.6200000000001, "end": 1128.1000000000001, "text": " is the GCash.page underscore size.", "tokens": [51248, 307, 264, 29435, 1299, 13, 15161, 37556, 2744, 13, 51472], "temperature": 0.0, "avg_logprob": -0.17824966793968564, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.21158583462238312}, {"id": 251, "seek": 110594, "start": 1128.1000000000001, "end": 1133.9, "text": " But I don't think we have so much time, so consider this blog post that we will write", "tokens": [51472, 583, 286, 500, 380, 519, 321, 362, 370, 709, 565, 11, 370, 1949, 341, 6968, 2183, 300, 321, 486, 2464, 51762], "temperature": 0.0, "avg_logprob": -0.17824966793968564, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.21158583462238312}, {"id": 252, "seek": 113390, "start": 1133.9, "end": 1137.38, "text": " maybe next week.", "tokens": [50364, 1310, 958, 1243, 13, 50538], "temperature": 0.0, "avg_logprob": -0.16775269941850143, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.09388686716556549}, {"id": 253, "seek": 113390, "start": 1137.38, "end": 1140.66, "text": " Another one that I should probably mention really quickly is the arbitrator.", "tokens": [50538, 3996, 472, 300, 286, 820, 1391, 2152, 534, 2661, 307, 264, 19071, 1639, 13, 50702], "temperature": 0.0, "avg_logprob": -0.16775269941850143, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.09388686716556549}, {"id": 254, "seek": 113390, "start": 1140.66, "end": 1145.18, "text": " So the arbitrator is a member of your cluster that can participate in voting, but not in", "tokens": [50702, 407, 264, 19071, 1639, 307, 257, 4006, 295, 428, 13630, 300, 393, 8197, 294, 10419, 11, 457, 406, 294, 50928], "temperature": 0.0, "avg_logprob": -0.16775269941850143, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.09388686716556549}, {"id": 255, "seek": 113390, "start": 1145.18, "end": 1146.26, "text": " the actual application.", "tokens": [50928, 264, 3539, 3861, 13, 50982], "temperature": 0.0, "avg_logprob": -0.16775269941850143, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.09388686716556549}, {"id": 256, "seek": 113390, "start": 1146.26, "end": 1150.8600000000001, "text": " So if you want to save money, you want to have two data center setups, three nodes each.", "tokens": [50982, 407, 498, 291, 528, 281, 3155, 1460, 11, 291, 528, 281, 362, 732, 1412, 3056, 46832, 11, 1045, 13891, 1184, 13, 51212], "temperature": 0.0, "avg_logprob": -0.16775269941850143, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.09388686716556549}, {"id": 257, "seek": 113390, "start": 1150.8600000000001, "end": 1154.8600000000001, "text": " You can actually just set up the arbitrator daemon in digital ocean or line node.", "tokens": [51212, 509, 393, 767, 445, 992, 493, 264, 19071, 1639, 1120, 36228, 294, 4562, 7810, 420, 1622, 9984, 13, 51412], "temperature": 0.0, "avg_logprob": -0.16775269941850143, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.09388686716556549}, {"id": 258, "seek": 113390, "start": 1154.8600000000001, "end": 1158.3400000000001, "text": " It doesn't have to be a powerful machine.", "tokens": [51412, 467, 1177, 380, 362, 281, 312, 257, 4005, 3479, 13, 51586], "temperature": 0.0, "avg_logprob": -0.16775269941850143, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.09388686716556549}, {"id": 259, "seek": 113390, "start": 1158.3400000000001, "end": 1163.5400000000002, "text": " It can just basically read traffic and act as an arbitrator.", "tokens": [51586, 467, 393, 445, 1936, 1401, 6419, 293, 605, 382, 364, 19071, 1639, 13, 51846], "temperature": 0.0, "avg_logprob": -0.16775269941850143, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.09388686716556549}, {"id": 260, "seek": 116354, "start": 1164.1399999999999, "end": 1167.58, "text": " Don't use things like ignore split brain and so forth.", "tokens": [50394, 1468, 380, 764, 721, 411, 11200, 7472, 3567, 293, 370, 5220, 13, 50566], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 261, "seek": 116354, "start": 1167.58, "end": 1173.82, "text": " So Garbdy can act as the odd node and he can also of course help you do backups.", "tokens": [50566, 407, 7995, 65, 3173, 393, 605, 382, 264, 7401, 9984, 293, 415, 393, 611, 295, 1164, 854, 291, 360, 50160, 13, 50878], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 262, "seek": 116354, "start": 1173.82, "end": 1175.34, "text": " Plenty of proxies available.", "tokens": [50878, 2149, 4179, 295, 447, 87, 530, 2435, 13, 50954], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 263, "seek": 116354, "start": 1175.34, "end": 1177.3799999999999, "text": " There's Galera load balancer.", "tokens": [50954, 821, 311, 7336, 1663, 3677, 3119, 28347, 13, 51056], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 264, "seek": 116354, "start": 1177.3799999999999, "end": 1178.3799999999999, "text": " There's HA proxy.", "tokens": [51056, 821, 311, 11979, 29690, 13, 51106], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 265, "seek": 116354, "start": 1178.3799999999999, "end": 1179.3799999999999, "text": " We have documentation for that.", "tokens": [51106, 492, 362, 14333, 337, 300, 13, 51156], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 266, "seek": 116354, "start": 1179.3799999999999, "end": 1183.5, "text": " There's proxy SQL or talk coming up later today evening.", "tokens": [51156, 821, 311, 29690, 19200, 420, 751, 1348, 493, 1780, 965, 5634, 13, 51362], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 267, "seek": 116354, "start": 1183.5, "end": 1186.46, "text": " And of course MariaDB max scale.", "tokens": [51362, 400, 295, 1164, 12734, 27735, 11469, 4373, 13, 51510], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 268, "seek": 116354, "start": 1186.46, "end": 1190.7, "text": " To provision new nodes, 8.0 gives you clone SSD.", "tokens": [51510, 1407, 17225, 777, 13891, 11, 1649, 13, 15, 2709, 291, 26506, 30262, 13, 51722], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 269, "seek": 116354, "start": 1190.7, "end": 1192.5, "text": " Maria gives you Maria backup.", "tokens": [51722, 12734, 2709, 291, 12734, 14807, 13, 51812], "temperature": 0.0, "avg_logprob": -0.290017593005472, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.1035488098859787}, {"id": 270, "seek": 119250, "start": 1192.5, "end": 1197.94, "text": " Percona extra backup is still the choice inside of Percona, actually be cluster.", "tokens": [50364, 3026, 1671, 64, 2857, 14807, 307, 920, 264, 3922, 1854, 295, 3026, 1671, 64, 11, 767, 312, 13630, 13, 50636], "temperature": 0.0, "avg_logprob": -0.3382966668756158, "compression_ratio": 1.4730769230769232, "no_speech_prob": 0.004751733969897032}, {"id": 271, "seek": 119250, "start": 1197.94, "end": 1203.06, "text": " Very common setup and runtime issues, S Linux firewall.", "tokens": [50636, 4372, 2689, 8657, 293, 34474, 2663, 11, 318, 18734, 36109, 13, 50892], "temperature": 0.0, "avg_logprob": -0.3382966668756158, "compression_ratio": 1.4730769230769232, "no_speech_prob": 0.004751733969897032}, {"id": 272, "seek": 119250, "start": 1203.06, "end": 1205.46, "text": " You can't get your, you can't get a IST.", "tokens": [50892, 509, 393, 380, 483, 428, 11, 291, 393, 380, 483, 257, 6205, 51, 13, 51012], "temperature": 0.0, "avg_logprob": -0.3382966668756158, "compression_ratio": 1.4730769230769232, "no_speech_prob": 0.004751733969897032}, {"id": 273, "seek": 119250, "start": 1205.46, "end": 1208.1, "text": " Well it turns out you've probably got a port closed.", "tokens": [51012, 1042, 309, 4523, 484, 291, 600, 1391, 658, 257, 2436, 5395, 13, 51144], "temperature": 0.0, "avg_logprob": -0.3382966668756158, "compression_ratio": 1.4730769230769232, "no_speech_prob": 0.004751733969897032}, {"id": 274, "seek": 119250, "start": 1208.1, "end": 1212.3, "text": " Make sure port 4444 TCP is open.", "tokens": [51144, 4387, 988, 2436, 1017, 13912, 19, 48965, 307, 1269, 13, 51354], "temperature": 0.0, "avg_logprob": -0.3382966668756158, "compression_ratio": 1.4730769230769232, "no_speech_prob": 0.004751733969897032}, {"id": 275, "seek": 119250, "start": 1212.3, "end": 1217.02, "text": " If you want to avoid long running queries, MySQL and MariaDB as, you know, max execution", "tokens": [51354, 759, 291, 528, 281, 5042, 938, 2614, 24109, 11, 1222, 39934, 293, 12734, 27735, 382, 11, 291, 458, 11, 11469, 15058, 51590], "temperature": 0.0, "avg_logprob": -0.3382966668756158, "compression_ratio": 1.4730769230769232, "no_speech_prob": 0.004751733969897032}, {"id": 276, "seek": 119250, "start": 1217.02, "end": 1219.94, "text": " time, MariaDB as enhance kill.", "tokens": [51590, 565, 11, 12734, 27735, 382, 11985, 1961, 13, 51736], "temperature": 0.0, "avg_logprob": -0.3382966668756158, "compression_ratio": 1.4730769230769232, "no_speech_prob": 0.004751733969897032}, {"id": 277, "seek": 121994, "start": 1219.94, "end": 1225.22, "text": " You've got DNS giving you problems, switch to IPs.", "tokens": [50364, 509, 600, 658, 35153, 2902, 291, 2740, 11, 3679, 281, 8671, 82, 13, 50628], "temperature": 0.0, "avg_logprob": -0.30290937423706055, "compression_ratio": 1.4622641509433962, "no_speech_prob": 0.05575036630034447}, {"id": 278, "seek": 121994, "start": 1225.22, "end": 1229.18, "text": " Couple of functions for developers that may be useful.", "tokens": [50628, 38266, 295, 6828, 337, 8849, 300, 815, 312, 4420, 13, 50826], "temperature": 0.0, "avg_logprob": -0.30290937423706055, "compression_ratio": 1.4622641509433962, "no_speech_prob": 0.05575036630034447}, {"id": 279, "seek": 121994, "start": 1229.18, "end": 1232.5, "text": " Again, you can tell the developers to check this out.", "tokens": [50826, 3764, 11, 291, 393, 980, 264, 8849, 281, 1520, 341, 484, 13, 50992], "temperature": 0.0, "avg_logprob": -0.30290937423706055, "compression_ratio": 1.4622641509433962, "no_speech_prob": 0.05575036630034447}, {"id": 280, "seek": 121994, "start": 1232.5, "end": 1236.5800000000002, "text": " It's well documented.", "tokens": [50992, 467, 311, 731, 23007, 13, 51196], "temperature": 0.0, "avg_logprob": -0.30290937423706055, "compression_ratio": 1.4622641509433962, "no_speech_prob": 0.05575036630034447}, {"id": 281, "seek": 121994, "start": 1236.5800000000002, "end": 1237.74, "text": " It's widely adopted.", "tokens": [51196, 467, 311, 13371, 12175, 13, 51254], "temperature": 0.0, "avg_logprob": -0.30290937423706055, "compression_ratio": 1.4622641509433962, "no_speech_prob": 0.05575036630034447}, {"id": 282, "seek": 121994, "start": 1237.74, "end": 1242.38, "text": " So lots of people are going, you know, you could use it in Xflower, PowerDNS, lots of", "tokens": [51254, 407, 3195, 295, 561, 366, 516, 11, 291, 458, 11, 291, 727, 764, 309, 294, 1783, 30794, 11, 7086, 35, 42003, 11, 3195, 295, 51486], "temperature": 0.0, "avg_logprob": -0.30290937423706055, "compression_ratio": 1.4622641509433962, "no_speech_prob": 0.05575036630034447}, {"id": 283, "seek": 121994, "start": 1242.38, "end": 1244.9, "text": " Kubernetes operators.", "tokens": [51486, 23145, 19077, 13, 51612], "temperature": 0.0, "avg_logprob": -0.30290937423706055, "compression_ratio": 1.4622641509433962, "no_speech_prob": 0.05575036630034447}, {"id": 284, "seek": 124490, "start": 1244.9, "end": 1249.94, "text": " All right, so the most exciting thing for me in MariaDB 11 from a Galera standpoint", "tokens": [50364, 1057, 558, 11, 370, 264, 881, 4670, 551, 337, 385, 294, 12734, 27735, 2975, 490, 257, 7336, 1663, 15827, 50616], "temperature": 0.0, "avg_logprob": -0.27316022552220165, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.296767920255661}, {"id": 285, "seek": 124490, "start": 1249.94, "end": 1252.22, "text": " is WSWAP provider options is now a plugin.", "tokens": [50616, 307, 343, 50, 54, 4715, 12398, 3956, 307, 586, 257, 23407, 13, 50730], "temperature": 0.0, "avg_logprob": -0.27316022552220165, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.296767920255661}, {"id": 286, "seek": 124490, "start": 1252.22, "end": 1255.46, "text": " So you can actually use this from a more automated thing.", "tokens": [50730, 407, 291, 393, 767, 764, 341, 490, 257, 544, 18473, 551, 13, 50892], "temperature": 0.0, "avg_logprob": -0.27316022552220165, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.296767920255661}, {"id": 287, "seek": 124490, "start": 1255.46, "end": 1261.3400000000001, "text": " I presume from a MariaDB standpoint, this helps automatically reconfigure SkySQL.", "tokens": [50892, 286, 43283, 490, 257, 12734, 27735, 15827, 11, 341, 3665, 6772, 9993, 20646, 540, 9879, 39934, 13, 51186], "temperature": 0.0, "avg_logprob": -0.27316022552220165, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.296767920255661}, {"id": 288, "seek": 124490, "start": 1261.3400000000001, "end": 1267.14, "text": " So this is better for you because otherwise you have to put in my.cnf, some of it's dynamic,", "tokens": [51186, 407, 341, 307, 1101, 337, 291, 570, 5911, 291, 362, 281, 829, 294, 452, 13, 16279, 69, 11, 512, 295, 309, 311, 8546, 11, 51476], "temperature": 0.0, "avg_logprob": -0.27316022552220165, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.296767920255661}, {"id": 289, "seek": 124490, "start": 1267.14, "end": 1271.8600000000001, "text": " not all of it's dynamic, resetting a server, horrible.", "tokens": [51476, 406, 439, 295, 309, 311, 8546, 11, 725, 302, 783, 257, 7154, 11, 9263, 13, 51712], "temperature": 0.0, "avg_logprob": -0.27316022552220165, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.296767920255661}, {"id": 290, "seek": 127186, "start": 1271.86, "end": 1276.8999999999999, "text": " Got more granular, you know, few things to improve on, makes schema changes, upgrades", "tokens": [50364, 5803, 544, 39962, 11, 291, 458, 11, 1326, 721, 281, 3470, 322, 11, 1669, 34078, 2962, 11, 24868, 50616], "temperature": 0.0, "avg_logprob": -0.24751684882424094, "compression_ratio": 1.5048076923076923, "no_speech_prob": 0.11250285804271698}, {"id": 291, "seek": 127186, "start": 1276.8999999999999, "end": 1277.8999999999999, "text": " easier.", "tokens": [50616, 3571, 13, 50666], "temperature": 0.0, "avg_logprob": -0.24751684882424094, "compression_ratio": 1.5048076923076923, "no_speech_prob": 0.11250285804271698}, {"id": 292, "seek": 127186, "start": 1277.8999999999999, "end": 1279.8999999999999, "text": " Lots of further reading.", "tokens": [50666, 15908, 295, 3052, 3760, 13, 50766], "temperature": 0.0, "avg_logprob": -0.24751684882424094, "compression_ratio": 1.5048076923076923, "no_speech_prob": 0.11250285804271698}, {"id": 293, "seek": 127186, "start": 1279.8999999999999, "end": 1283.58, "text": " I know we've literally run out of time, 20 minutes is not a lot of time.", "tokens": [50766, 286, 458, 321, 600, 3736, 1190, 484, 295, 565, 11, 945, 2077, 307, 406, 257, 688, 295, 565, 13, 50950], "temperature": 0.0, "avg_logprob": -0.24751684882424094, "compression_ratio": 1.5048076923076923, "no_speech_prob": 0.11250285804271698}, {"id": 294, "seek": 127186, "start": 1283.58, "end": 1291.62, "text": " So you can tweet me, you can send me an email, we're hiring, and yeah, we have lots of services.", "tokens": [50950, 407, 291, 393, 15258, 385, 11, 291, 393, 2845, 385, 364, 3796, 11, 321, 434, 15335, 11, 293, 1338, 11, 321, 362, 3195, 295, 3328, 13, 51352], "temperature": 0.0, "avg_logprob": -0.24751684882424094, "compression_ratio": 1.5048076923076923, "no_speech_prob": 0.11250285804271698}, {"id": 295, "seek": 127186, "start": 1291.62, "end": 1293.1, "text": " Thank you for listening.", "tokens": [51352, 1044, 291, 337, 4764, 13, 51426], "temperature": 0.0, "avg_logprob": -0.24751684882424094, "compression_ratio": 1.5048076923076923, "no_speech_prob": 0.11250285804271698}, {"id": 296, "seek": 130186, "start": 1301.86, "end": 1302.86, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.9639227867126465, "compression_ratio": 0.6521739130434783, "no_speech_prob": 0.9989665746688843}, {"id": 297, "seek": 130186, "start": 1302.86, "end": 1302.86, "text": "", "tokens": [], "temperature": 0.0, "avg_logprob": -0.9639227867126465, "compression_ratio": 0.6521739130434783, "no_speech_prob": 0.9989665746688843, "words": []}], "language": "en"}