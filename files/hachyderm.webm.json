{"text": " How's everybody feeling? Good. So if you haven't figured it out yet, I'm Chris Nova. Some people call me Chris. Some people call me Nova. Just don't call me Shirley. So we're going to get started with a few quick questions. There's a lot of people here. So I just want to get a feel for who's in the audience. So who here knows what mastodon is? Show of your hands. Okay. For folks at home, literally everybody just put their hand up. Who here knows what hackaderm is? Oh, God. Sorry. So pretty much the same number of people. Who here knows how to denial a service? Dadosa service? Okay. And how about just general abuse? How to like just use a service? Okay. So for those of you on the camera, literally the entire stadium of people just put all of their hands up. I can't believe I'm about to do this. You have 45 minutes starting now. You have my full permission to DOS my shit. Take down the service. You can do whatever you want. There are three known things I know of today that should make this pretty easy. I think if you knew exactly what you were doing, you could probably do it in about five minutes. So anyway, that's how we're going to start the talk off today. So the goal of this is to wake my partner up. So she's asleep right now. She's at home in Seattle. And if you're successful in disrupting the service, she will get some discord notifications and we have a team of volunteers. Their phones will go off. My phone will start going off. And hopefully, hopefully my puppy greets her with a smile and wakes her up as there's inevitably a crisis. Okay. So the reason I wanted to start this off is because we have had to do a tremendous amount of work to bring Hack Derm to where it is today. So just to kind of start the slides off with some basic numbers here. I don't know if y'all can see this, but this is just a public glimpse into the service that's online today, just serving mastodon. And there's 44,000 users. It looks like we had 200 people sign up today. I don't know how many of those people were here at Fosnum. I don't really know very much about them at all. We've had 20,000 toots. Sorry, we've had 789,000 toots. And we have 20,000 monthly active users. So there's been 20,000 people who signed into the service in the past 30 days alone. And we are currently federating with another 20,000 instances, which in my opinion is yet another attack vector for the internet at large that we should probably spend more time discussing. So if you are successful in flooding the service, hopefully by the end of my talk, we should see some spikes in these two middle graphs here. The HTTP response time is probably the most sensitive part of our entire system today. Cool. So let's get back into it. So about me, I work at GitHub. I'm a principal engineer at GitHub. I'm also an author. I've written some mediocre quality books. And as of four days ago, I'm also the president and a board member of a foundation I'll tell you about here shortly. And if you want to follow me on decentralized social media, there's my links there. Okay. So we're going to start off and we're going to do some basic context studying. And then we're going to go into like a little bit of an incident report of a situation we found ourselves in last November. And then we'll talk a little bit about what this means to me, what this means to the United States economy, the legal situation in the United States, and how we're kind of navigating all of this that we really kind of just stumbled upon earlier last year. So the short story here is my little mastodon server that was used for me in about 100 of my friends, if maybe not even 100, maybe 50 of my friends, had very quickly turned into what I consider medium size scale. And when we reached medium size scale, a lot of the problems aren't necessarily related to the technology. Although, as you're about to find out, operating a Ruby monolith at scale does come with a substantial amount of concerns, which we'll dig more into that in a moment. Okay. So just for folks at home who are watching the video after the fact, I want to give a little bit of context on mastodon in general. And I want to be clear. I am not a mastodon. Well, I guess it depends what you define as a contributor, but I don't work on mastodon that much. I've written a few issues. I've helped talk to some folks who do contribute to the project. But for the most part, this is probably the most detached I am from any of the open source projects I work on. I literally am a consumer of mastodon. The most involved I have gotten with this particular project has been going to GitHub and going to the release tab and downloading the latest versions for me to go and install on my server. So it's kind of nice, not going to lie, to just be on the consumer side of the open source for a change. But mastodon is ultimately social networking that's not for sale. It's built on the activity pub W3C protocol. And it's an alternative to familiar social media sites like Twitter. And it gives you much more ownership and control of your data from both an operator and a user perspective. Okay. So this is probably the number one question I get asked, which is how did we come up with the name Hackaderm? And if you talk to my friends in Italy, it's hashaderm or hashadermio or I've heard a lot of different variations of it. It's my partner came up with the name. It's ultimately a plan words with hacky and packaderm. So hacky is a clumsy, temporal or in elegant solution to a technical problem. And packaderm is a large thick skinned mammal such as an elephant rhinoceros or hippopotamus, obviously mastodon. You see where we're going with this. And so we like to say that hackaderm is a clumsy, temporary or in elegant thick skinned social media server. And depending on how successful some of these people with their laptops are, we're going to see how thick the skin really is. So again, right now we have roughly 45,000 hackadermians is what we refer to the people in the community, which is a lot of people. I wasn't prepared for the sheer number of people and the sheer number of like bizarre things that we would be getting into as we approach the size scale. And we have 20,000 people who are active. And so this is, there's a lot of implications of that specific ratio. But for the most part we see a lot of traffic go through our network every day. And I think at least once a day there's some sort of crisis. So we have all of the major problems of Jurassic Park, of a major theme park, of a normal technical shop, which has been fascinating to kind of watch this whole thing grow. The hackaderm community is pretty interesting. And to be completely honest, I'm still not really sure how it ended up the way it did. But it's mostly composed of technical and open source professionals, such as people here. It's similar to Fostodon, who here has heard of the Fostodon MasterDawn server. That one's also great. Also, I have some colleagues who work on the InfoSec one. That's also another good one. But I see a lot of like SREs, such style people, a lot of senior engineers who work on the InfoSec style people, a lot of senior engineers, directors. We even have some executives. And then we also have like honestly just some very beautiful anonymous hackers who keep everybody in check. And so it's a good blend of people. And we see a lot of interesting things come through our various servers. So our about page reads, here we are trying to build a curated network of respectful professionals in the tech industry around the globe. And the around the globe part is the interesting part, especially when we start looking at the legal implications of this, which again, we weren't necessarily prepared for. And we welcome anyone who follows the rules and needs a safe home or a fresh start. I think this was personally a big one for me. And I think this is also very relevant to a lot of the folks that I know who have joined in the last few months. I do think that there's like some pretty, in my opinion anyway, some pretty toxic mental health situations that folks find themselves in using Twitter. And I think that this is kind of an opportunity to just like rip the Band-Aid off and start fresh and kind of establish some new habits for people and some new self image for people. And so I do see a lot of people kind of reimagining themselves and reinventing themselves when they come to Hackaderm. But yeah, ultimately, it's hackers, professionals, enthusiasts, and we're passionate about life, respect, and digital freedom, and we believe in peace and balance. And I wrote this very casually like on a Twitch stream, and those words are actually pretty important now that we're continuing to dive a little deeper into what they actually mean. I think the thing that kind of comes to mind right now, the word professionals and enthusiasts right next to each other, when you come to a certain scale, having a lot of enthusiasts sit alongside professionals comes with some consequences and balancing these two things is actually pretty challenging from an operation standpoint. But ultimately, we want to be a safe space for the tech industry, for people who want to talk about the economy, open source intelligence, news. We talk a lot about Rust, we talk about Linux. Who here was at my talk on Aura yesterday? Awesome, thank you. So a few folks here. So that's a new project that I'm trying to get more people to talk about. We talk about Kubernetes, Go, et cetera, et cetera. So anyway, we're going to spend a little bit of time talking about this blog post that I wrote called Leaving the Basement. And to set the context a little bit, Hackaderm literally started running in my basement. And this is the story of how we kind of ended up moving out of the basement and dealing with some pretty substantial scale problems. I think it was in the middle of November, we started to, the service started to degrade. And there was a lot of consequences of just shutting the service down. And so people were getting very aggressive on the internet. As it turns out, the internet is full of grown men with opinions. I don't know if any of y'all have noticed this or not. But yeah, sometimes these grown men with opinions have very toxic opinions, and they like to say a lot of things about people's services. And so we tried to do our best to keep a positive attitude and just continue to move forward. So this is the story of what actually happened behind the scenes and how we ended up there. And I think there's some really good takeaways in this from a technical perspective. Okay, so we'll begin our story on November 27th of last year, 2022. And also keep in mind that, you know, this is one month before the holidays. So this is about the most burnt out I ever get every year. So usually around the end of November, I'm honestly, I'm about the most I can say to anyone is like fuck off, like I just really need some space. And I need a break and I want to go relax and I want to sleep in. And this is when our new service decided just to completely go down. And this was a really good growing opportunity for people. So we have some really interesting numbers here. And I tried to do my best to build a graph. And this is like, it looks like a very stereotypical stock graph that's like pointing up into the right. So I feel like I should just, you know, do like a good, like, hi, guys, we're here to talk about business. And look, our business is going up into the right. And like business numbers are important because growth and strategy and impact and business. But honestly, this is just the amount of people who were leaving Twitter. And really, I think they were just kind of looking for a new home. And we just happened to be one that that met their needs for the time being. So up until November 1st, we had less than 700 people. The prior six months, the service was online. That's how we gained those 700 people. So it was roughly 100 people a month for the first six months. And then this happened. And this was very unexpected for both myself and everybody in my immediate circle. So one of the things I talk about as a professional SRE. So let me back up. When I'm not keeping the masted on Ruby monoliths online, my other job is keeping the GitHub Ruby monoliths online. So some of you use GitHub. Some of you use Hackaderm. I work on both of them. And I have two different UB keys here in my backpack, one for each service. And so anyway, one of the things I often say is when I enter a conversation with someone, this is the most important thing. And I honestly want to get this as like my next tattoo because I say this at least once a week, which is what is the current state of the systems? And if you can't answer this question very confidently at any given moment, especially in a crisis, we should be having other conversations at that point because this is the starting point of every conversation in my opinion. So we'll start our service off our service discussion off here. So we had a rack of hardware in my basement. And these are the specs that we had running in the basement. So it was a hobby rack that I've collected over the past 10 years or so, you know, pieces of hardware that have been donated to me or that I found for a cheap price that were used. In fact, the star of the show, Alice, over here on the far left, I've literally carried her across Market Street in San Francisco and dropped her in a pile of like pee on the side of the road. The hardware has been through a lot to say the least, but it's what we had and this is what I was using for kind of a home lab at the time. I think the important thing here to notice though is that these are not trivial computers. These are proper rack mounted servers with proper specs and most, for the most part, these worked fine. It got the name the water tower because we had Alice, who was our main compute node, and then we had three identical Dell PowerEdge R620s named Yacko, Wacko, and Dot, respectively, and all three of them seemed to just be up to shenanigans at any given point in time, from memory failure to broken boot loaders to just bizarre networking behavior and having to go flip out Nix to try to get a better network connection. There was just a lot of obscure things that was happening at the hardware level. So, Meet Alice. She's a very infamous server, especially if you've read any of our posts or if you've ever watched my Twitch stream, but there she is there, and that's in my basement, and that's the Dell R630, and you can see she's got eight SSDs in the front of the carriage there, and she was sitting behind a firewall of my own design, and that was our main endpoint for pretty much everything I ran in my home lab, and that just so happened to be the main endpoint for our mastodon service up until the month of November. So, yes, it was a home lab, and I think the whole point of this is that we used it for a lot of things, and so the mastodon service was running on the home lab, and I do a lot of really bizarre things on Twitch, so if you follow me on Twitch, you probably have seen me work on kernel modules and experimental EBPF probes, and I've experimented with adding some features to the ZFS file system and compiling my own version of ZFS from scratch, and I've been doing a lot, and I also installed mastodon on that same server, and that's the key part of this. So, here's a list of things from my home lab that have not blown up. There has not been a billionaire who decided to buy a company that decided to insult the broader technical community and encourage them to move off to a decentralized service, and so you've probably never heard of any of these, and that all of these also run in that same home lab, so I think it's important to realize that this was a very unexpected event, and that these servers were in a pretty high state of entropy, and we didn't really have a good idea of the state of the systems. This was a home lab. So, as it turns out, 50,000 people trust me and really dislike a certain billionaire, and this was the one thing I kept hearing. We kept having large to medium size and smaller size name people with substantial Twitter following, like shoot us an e-mail and be like, yo, Nova, I'm done with Twitter, we're going to come to your mastodon server, and I'm like, okay, sounds cool, and then they have, you know, 350,000 Twitter followers, and it's not about the followers, but from an operator's perspective, I'm like, holy shit, that's a lot of traffic. That's a lot of people that we're going to have to open up web sockets against, and there's a lot to deal with there if you're going to be sending all of these messages out to all of these people who are going to be following you, and they all continue to say the one thing, which is like, well, we trust you to not screw this up, and like, you know, you can probably do better than he can, so we're just going to move over to your server anyway. Okay, so what had ended up happening is, it's a long story, and how we ended up finding it, I think ultimately took about three weeks, but we don't say root cause anymore, we say core cause, and the core cause of the incident is ultimately we had a bad disk on Alice. I don't know why the disk was bad, this really bothers me, so I'm just going to chop it up to like, it was just like a bad one in the batch, but we were able to actually isolate it after the fact, and determine that like a basic reader write to this SSD was in fact the problem. I also think an interesting takeaway here is that these were not consumer SSDs, these were actual proper enterprise SSDs, one of which either just decided to get slow IO, or I don't know what happened to it, but even in an isolation zone writing directly to an EXT4 system, we were still able to prove that this disk was substantially slower than another one of the same make and model. So it wasn't always bad, and it started to go bad, and this ultimately led to a cascading failure across our CDN and our geographic edge nodes, and so the interesting thing, and this is just one of those things, this is the aforementioned bad disk, and it also for some reason has a broken chassis in the front, so part of me kind of has to wonder, did the movers drop the server, or did something happen? I'm not really totally sure, but these are the woes of operating your own hardware in your basement. So here's a model of the cascading failure. Who here has dealt with cascading failures in production before? Okay, so 15 or 20, 30 hands or so. These are fascinating, how you get into these situations, and usually when you're dealing with one of these cascading failures, you're not really starting at the database, or at least you glance at the database and you think maybe something's wrong, and you usually blame DNS, but in our case, we were working back from our CDN. So imagine you are operating a mastodon server in your basement, and 50,000 people on the internet decide to join, and all of a sudden you can't even join a zoom call the next morning, because your internet pipeline is so throttled from your ISP, who's like, bro, why are you bringing this much traffic to your house? I don't understand what's going on, this is very bizarre. So what we did is the very first thing we did to offset the problem was we set up these CDN nodes around the world, and these basically served as reverse engine X proxies that had media cash on them, and we would then route the traffic through a dedicated connection from one of these CDN nodes back to YACO in my rack, and then YACO would then proxy the data over to Alice, and Alice was our main, our primary database running in the rack. So when things started to fail, it was like very intermittent failures in Frankfurt, and then we would get like some very intermittent failures in Fremont, and it all looked like engine X was the problem, we were getting timeouts and slow requests, and this whole incident is what later inspired us to build that dashboard that you see today, and the reason I was like we should be looking at those HTTP request times when I very politely asked you all to please DDoS my server, and so that transferred all the way back to Alice, and we learned entirely too much about Mastodon at scale, retracing everything back through the rack, and we had to go and trace Redis logs, and Sidekick queues, and Mastodon Ruby servers with the Puma server, and ultimately we found out that it was simply just Postgres unable to read and write from the database as fast as we would like. So these are what the graphs looked like the day of the outage, so we grabbed some screenshots, and I'm really glad we did because these make for some interesting takeaways here. On the left side you can see our HTTP response time, and so these are our get 200s, so in some cases the response time was actually, they were returning a 200, but we were having like 40 second responses. Was anybody here on Hackaderm when it was like in this weird like hangy stage where you kind of could upload media, but you kind of couldn't, and you're like what the heck is NovaPan's doing, she doesn't know how to operate a service? So this is what we were working on, we were working backwards from these graphs, and it was interesting to see the behavior of Mastodon under these conditions because you very quickly realized that different parts of the user interface were coupled with different parts of the back end, and so, and they all assumed that the entire user interface would work. So if the database started to go slow, maybe you could upload the image, but we couldn't actually write the image key to MySQL, and the UI would just kind of just exist in this in-between stage for like five minutes at a time. It was very interesting behavior. But ultimately, we isolated out the IO on disk, and we were able to determine it was old SDG and old SDH down here in the bottom right. You can see these numbers are closer to 100% for IO on our disks, and this was what was causing those cascading failures. So ultimately, this was a very exciting time. People were joining Mastodon around the clock, and our little group of people that hung out on Discord very quickly turned into a more serious group of people who hung out on Discord, and it was really fascinating to watch friends of the Twitch stream and my partner Quintessence, and there's even people here in the room. Malte and DMA, are you right here in the front? We are now best friends, and we wouldn't necessarily be friends if it wouldn't have been for this whole incident in the first place. So we were definitely working around the clock. I think Malte and DMA would kind of hand the service off to us when we woke up in the morning, and we would work until they woke up the following morning, and it was just this constant game of providing quick summaries of our work and then just like crashing and going to sleep for a few hours and trying to hold down a day job while we dealt with the service. And this is for the most part what it felt like behind the scenes. We had a dedicated channel where we were trying hard to work through things, and I think this is Malte just sent to the image. This is the moment where we finally realized what was going on, and we were starting to isolate the problems on the disks, and I think Malte was just like, okay, we finally found the problem. It's exactly what we thought it was, and everything is fine. This is going to be fine. And meanwhile, we have, you know, main names and technology joining the service, and things are kind of burning down all around us. From the human perspective, I wanted to share two interesting failure modes that we got into as people that I think are just an interesting takeaway for anybody who operates a production service. So the first failure mode was in a state of panic, I tried to just throw more computers at the problem, and so my response was like, we're going to go put more computers in the rack, and I turned on dot for the first time, and gave dot a public IP address, and I think the other big takeaway here was we got very good at doing the wrong things, and I think this is a very, very familiar trap for a lot of the organizations that I work with every day, is there will be some crisis, and they will respond to the crisis by doing something. In our case, it was creating a spreadsheet, and the spreadsheet helped us do some quick math, and that math helped us inform how we needed to provision our different system D services, and then when we changed the system D service, the rule was you needed to go update the spreadsheet, and this was a reaction to a crisis that allowed us to move forward, and then it was very difficult to get out of this situation, so I do think that there's a very interesting takeaway of you get in the habit of doing the wrong thing or doing a bad behavior during a crisis, and that can actually persist in the last longer than the actual incident itself, so we had all the major problems of a normal SRE team, and this was a volunteer open source project to begin with. Okay, so I have a friend in Boulder, his name's Gabe, him and I have known each other for a long time, he's grown very quickly in his career, he's now the Chief Product Officer of Digital Ocean, and Gabe texted me one day and says, hey Nova, so I bought this farm, and I'm trying to upload rooster pictures on your website, and I can't upload my rooster pictures on Hackaderm today. What's going on, and is there anything Digital Ocean can do to help? And so we were in a situation where we were trying to come up with a plan, we had just identified that the disks were the bottleneck and the single cause of our infrastructure problems, and I think this was the first time I kind of realized like, oh, we have 50,000 really smart, well-connected people who can more than obviously help us with our problems, and really the problem is how do we reach out to them, give them access to production, form a plan, and execute on that plan, and it became very obvious that our main problem wasn't necessarily fixing the disks in the basement, it was managing people, and it was organizing people to work on the service and making sure that we were in a good position to accept help from a corporation such as Digital Ocean in the first place. So Malte here, he's going to get embarrassed, but can we just give him a round of applause for this plan? He's smiling, but honestly, like if there was a Malte saved the day kind of moment, like straight up Malte saved the day. He came up with this very interesting engine X pattern that allowed us to effectively move our data off of the bad disks in the basement to the Digital Ocean service without taking the service offline, which you're like, okay, that's pretty cool, you can keep the service up, and you can start to fix the problem at the same time. Additionally, what this did was this actually gave us a means of getting the data out, and everybody who used the service contributed to the data migration. And so what we did is we set up this, who's here familiar with the try files directive in engine X config, a few people, you should, if you get time, go read about try files. This is a fascinating thing that engine X does, and what we were able to do was point media.hackaderm.io on Alice. We were able to point all of the CDN nodes towards Alice, and Alice would first try to resource the file from S3 running in Digital Ocean. If it could find it, it would then return that directly as basically a reverse proxy from S3 to the client, and otherwise it would resource it from the disks locally in the rack. So every time somebody read, whether it was an image or a post or something coming from the rack, it would then persist into S3 on the back end, and we would never have to serve that image ever again from Alice. So this was a clever solution, and it gave us a means to slowly start transferring the data, and every minute we transferred the data was another minute that it was likely going to be served from a cloud provider and not from my really crappy hardware running in my basement. So the disks were so slow, I mean, in my mind, these disks could be personified. They were like, they were beaten, they were tired, they have been through hell and back again, and it took eight days for us to arclone all of the data, which was about two terabytes of data, of Rooster videos and cat pictures and catter-day hashtags and all kinds of mastodon things over to Digital Ocean S3, and this was all courtesy of Gabe, who was like, bro, I just want to upload my Rooster pictures. So as we moved the files out of the basement, it became obvious that running this service in my basement was no longer going to work for us and that enough people had joined that we had reached critical mass. So our next decision was, okay, where do we actually want to move the compute to? And I think we all kind of have been like a little bit traumatized from like the vendor lock-in and the tech industry as it exists today. And so I think looking at Hackaderm, there was a lot of people who were very critical, myself included, of a dependency on various corporations. So we definitely didn't want to just go throw money at Amazon, right? Amazon has enough money. We're good taking our little community and putting it there. And we didn't want to go do the same thing at another cloud provider. So ultimately, we made the decision to go to Hetzner in Germany. Whoo, Hetzner. Another good caveat here is that from a legal perspective, Germany has some of the most restrictive privacy laws. And so this is going to be about the most isolated zone we're going to get in today. And a quick glance and a quick consultation with a lawyer told us that Germany was going to be the safest place to start the service from. So again, our biggest concerns had almost nothing to do with the crappy disks in my basement and almost everything to do with like international privacy law and user data. And we've very quickly found ourselves having discussions about the complications and implications of operating a global service. So here is our most recent diagram of how we kind of set things up. You can see that we had to balance things in my basement with things in Germany. And you can see that we have a set of CDN or point of presence nodes around the world. So it was very exciting for me when I flew across the ocean from Seattle to come here to Brussels, because for the first time our service, since the outage, was actually fast and responsive again because I am now being proxied through another server now that I am here on a different continent. So now what? Okay, so we've reached the point of stability. Our servers are stable. People are able to send their Rooster videos again. And we're still very much not out of the weeds. We still have a lot of concerns we need to deal with. So in general, the top Ruby monolith problems that we have solved to date is sidekick scaling, which if you've ever, who's here has operated sidekick before? It's a Ruby thing, show of hands. It's like a Ruby daemon that you have to specify the amount of threads and concurrent workers at runtime. And mastodon is built on this. So like every time we federate with a server, there's a whole queue that runs in the background that does the federation for us. We've also had to tackle network scaling, and we have a global CDN with reverse nginx proxies that has a cache on the edge so that the more people who look at an image, the more it's served from the cache. And all of those have legal implications. And it's just been a lot of work that we've had to get into to just operate a basic service so that we can all sit here in this room and I can make the joke, please go DDoS my web server on the back end. So here's a graph of our egress data. So the top of the graph here is roughly one terabyte of data per day. So you can see that looks like over on January 26th, we peaked over a terabyte of egress data. So that's honestly from an enterprise and scale perspective, this is no trivial amount of data, right? We're moving a lot of data across the wire and the fact that Hetzner can support us is very nice and seems to be working well for our needs today. Another interesting thing about just federation in general that we've had to kind of learn as a community is there's actually a lot of moderation consequences. And there's a pretty big user data and user privacy risk with operating mastodon. And so I put this sort of diagram together to just illustrate some of the consequences that we've had to deal with. In this case, we have three instances, one friendly, one neutral, and one evil. And even if the friendly instance decided to block the evil instance for whatever reason they deemed to be a cause for that blocking, it's still able for content to get out and to end up federating with another instance. I think what's important about this is this means that we can end up with content that is potentially illegal in the United States or illegal to have without like an 18 and up warning that puts myself, my family, and everybody who works on Hackaderm at risk. And so we've been trying hard to figure out how do we actually manage content and actually get to a point where we can manage this in an effective way. And let me just say I cannot thank the content warning feature on mastodon enough because that actually gives us a lot of insight into the types of things that could potentially be harmful. So ultimately, we had a lot of top non-Ruby monolith problems. So obviously, there was illegal concern. We have a team of moderators working around the clock who just deal with trolls and people who are causing problems and bad actors, and they're having to make judgment calls. And we have to establish rules, and these rules need to be enforced, and we have to respond to people, and people have really good reasons. There's videos out there that are very disruptive, and we have to go respond to them. And it takes a lot of work just to balance that on the back end. And the whole thing is ran by volunteers. And ultimately, where we are right now is we're spending roughly 1000 euro a month in hosting costs alone between the digital ocean bill, the Hetzner bill. We have an email API. So every time you go and you sign up for the service, you have to get an email so we can validate who you are. And all of this is coming from donations as they exist today. Okay. So if you want to learn more about Hackaderm, the community, and how we run things, we have a dedicated community resource. If you want to go grab and check it out, that's where we do things like announce our rules and our policies, and we document how we make moderation decisions in general. So the consequence of all of this is we've decided to found a new foundation called the Nivenly Foundation, which that's very exciting. So the name is just it's just the name of my blog that we turned into a 501c3. And I kind of like most things in my life, I kind of want this foundation to be relatively boring, but this will be the legal entity that will be used to protect Hackaderm and to hopefully fund the process moving forward. So right now the Nivenly Foundation has two projects, one of which I talked about yesterday called Aura, which is a distributed runtime written in Rust, and we also have Hackaderm. This is exciting because we this feels like the 90s. We have an open source service. This isn't an open source project that you can go download. We like legit have an open source service with graphs and people with pagers that we have to go and operate. And so that's an exciting thing that the Nivenly Foundation gets to do. So I want to introduce my wonderful partner who's not here, who is the executive director of the Nivenly Foundation, and also the person that we hopefully didn't just wake up by d-dossing the server. Anyway, she does the majority of the work and she couldn't be here today, but can we just give her a round of applause? Because she is actually the one who gets everything done. So she manages the infrastructure team right now. She's managing the moderator team right now. She even created these teams in the first place because people were freaking out and didn't know what to do. And so she wakes up every morning and deals with everything that Hackaderm throws at her, and I honestly thank her enough for the hard work that she's done. So one of the problems we've had to solve is a governance model for this whole thing. So we now have an open source service. There's legal risks and how are we going to make decisions as a nonprofit. And so we started to look at some of the consequences of modern day social media and some of the consequences of how corporations are navigating different open source spaces. And some of the things I noticed was for the most part, on Twitter especially, communities are very isolated from decisions. Users are detached from the technology and how things are done. And people are usually unable to impact change. So I had gotten into some trouble with Twitter. They banned my account. I wasn't able to talk to anyone. I had no avenue in which I could go and actually communicate with this corporation. And that became very problematic for me because I kind of used Twitter for a lot of things professionally. So what I started to realize was actually corporations usually have more influence and a better standing in the fabric of the economy than just a regular person does. And so as soon as I was able to interface with a corporation, I realized that I was no longer isolated from decisions. And I found that corporations often are not detached from the technology and corporations are in fact able to impact change. And I became obsessed with this idea. And I wrote a whole book about it. And I could, everywhere I looked, I saw this idea that ultimately corporations seem to have more rights than people. And that was very difficult for me to reconcile. I also think that this general observation explains why we see a lot of this on the Fediverse today. I think that there is this culture of cyberbullying and assuming that the people operating servers are inherently evil. And I see a lot of criticism instead of a lot of contribution. And somebody who comes from open source and I've worked on Linux and FreeBSD and Kubernetes, the Go programming language, the Rust programming language, it's very difficult for me not to intuitively walk up to a project and want to contribute. And so I guess this is just my way of saying that Mastodon gives us an opportunity and the Fediverse gives us an opportunity to no longer isolate people from the folks who are operating their services they use every day. And that's very exciting for me. So in our governing model, we want to figure out a way to balance communities and corporations. And this is the hybrid model that I'm hoping will actually be able to create a sustainable governing model for what we're doing. So right now, while we think corporate sponsorships are important, we're actually going to have two forms of non-corporate sponsorship, which are project members that you can achieve that status to simply by rolling up your sleeves and either contributing a project or becoming a contributor to one of our existing projects, or a general member, which is a small opt-in monthly fee that we have a few hundred people paying for right now. And the beauty of this is all general members are going to have a vote in how we do things. So if Hackaderm, the Mastodon server, wanted to, let's say, let a tech company have an account and that became controversial, anybody who makes a monthly donation to the service now is going to be able to have a vote in how we do things. And we're actually going to introduce a concept of open-source democracy. And we're going to be leveraging open W3C protocols to make this happen. And we still have some math to figure out exactly how much this is going to cost. However, this model is all built around the idea of a cooperation, which you see a lot of successful global companies do this and balance the different laws and trade-offs of different economies around the world. So my hope is that this will be slightly more sustainable and break down the sort of barrier between corporations and people because people now have a vote in influence and authority in how we do things. So we're still in very early stages of this. If you want to talk more, I'll be here at Fosdham. If you want to talk about Mastodon. And very specifically, if anybody here has any opinions on open-source democracy or how to build an open-source democratic model such that users can vote, I would love to talk to you. I want to learn as much as I can, and I want to help get Nivenly to a point where we actually have a sustainable model, and maybe we can learn some things from the various policy and legal efforts going on here in Belgium and in the EU. So now what? Now, really, it's just keeping Hackaderm online, which we're about to see if it is. Hopefully it is because I really feel like y'all would have been able to do a lot of damage if I would have been giving this presentation last November. And we just want to work towards a democratic model so that people who use the social media service have a vote and have influence in how that social media service is running so that it becomes everybody's social media service and not my social media service or somebody else's. So thank you to everyone who's been working on the service so far, and thank you to DMA and Malte who are here in the front, and specifically to the infrastructure team who helped us get out of the basement and keep the service online so that we can all have cat pictures and all the wonderful things that come with Mastodon. So thanks, everyone. Cool. And I grabbed a photo. So the test here is going to be to see, I'm going to try to upload the photo during questions, and we'll see how it goes. So here's a public resource. If you want to go check out the graph and see if there was a spike, you can go to grafana.hakaderm.io. And if you want to go to find out links to my slides and a recording of the video in the future, please go to github.com. And thanks again. And I guess we can do questions if anybody has questions. There's one over here. Right here. He's got his hand up. Okay, okay. I'm sorry. Could you start to interrupt, everybody? If you could please leave quietly, we are going to do Q&A right now. So we're just going to have a bit of Q&A. Please leave quietly. Thank you. I'm sorry, Chris. Can you show us the grafana panel? I can't hear you. I'm sorry. Okay, okay, okay. My questions. Thank you. Okay, right now. So the question was, can we see again the grafana table? Sure. Awesome. Grab a photo of this. Whoever did this round of applause. That's awesome. Hi. I was wondering, you were saying you could contribute skills or money to help. What are some ways that we as developers, engineers, SREs can help in the near future with keeping the video? It's a really good question. So the question was, how could we potentially volunteer or help out other than just throwing money at the problem? So the person to talk to is Quintessence. And we have a whole mod team right now that's working on onboarding docs. And I think we have 12 people right now. And these are folks from various tech companies around the world. And we have a Discord. So there's a link in the public resources I put. And there's a section on volunteering. And you can just interface with the team and get plugged in that way. Yeah, of course. Okay. More questions? Yes. You mentioned a thousand euros a month for the hosting. But I was wondering if you had an idea of what your total cost of ownership is now. And if the increase is linear with the increase of users in traffic. Sorry. The total cost of what? You mentioned a thousand euros per month for the hosting. But I guess your cost is much, much higher than that. So I was wondering if you know what your total cost is now monthly. And if it's been a linear increase with the number of users or? So the question is, is the cost of operating the Mastodon server, does it grow linearly with users? And the answer is no. It does increase with users. But I definitely think there's a threshold where you move from a small size to a medium size. And I think the traffic was really the deciding factor from us. So earlier it was just a few servers that we could operate on a small pipe. And now that we have a much larger footprint, we have to pay for a more enterprise and potentially a CDN and DDoS protection here in the future. And so that's grown up quite a bit. And that's probably our biggest cost right now is just the network. Cool. Any other questions? Hey, great talk. Did you evaluate, did you or any of your friends evaluate any other Mastodon compatible solution like Pluroma, Coma or any of that? Say, sorry, say again. Did you or any or when, when, when setting up, when setting up Hackaderm, did you or any of your friends evaluate any of the Mastodon compatible servers like Pluroma, Coma or any of that? So this, this is a really good question. So the question was, when we were setting up Hackaderm, did we look at any of the other Mastodon services like Pluroma or anything else? So the answer is no. And again, like, it's not like there was one day where I woke up and said, I'm going to go build a Mastodon server and I'm going to try to get all of the tech industry to come join us, right? Like I set it up for like me and my friends to just try out and Mastodon was the easiest one to get running on Arch Linux. And that was about the most thought that went into setting up Mastodon originally. And I think that like it had just continued to grow organically. And so like in hindsight, I mean, I like, I think there's opportunity to rewrite parts of Mastodon. I think there's a lot of opportunity to like have alternative dashboards as well. And so I'm not opposed to like operating different services for Hackaderm. I like to think of Hackaderm as a social media service where we just are on Mastodon mostly right now for today. So I don't have any personal experience operating the others, but I suspect that you know, as we move forward, the community might decide to switch over or run a different version or who knows, right? That's that's going to be up to the community now. All right. I have a further question. How fast was your internet speed at home to serve the Mastodon server? Sorry, say again? How fast was your internet speed at home to serve the Mastodon server? So like you showed the stats of your server setup with like 40 gigabits of possible network bandwidth, but how fast was actually the provided bandwidth from your ISP? Yeah. So this is a good question, which is how much bandwidth were we going through at my house? So in there's an official write up of the situation where we have some screenshots of the firewall at the house. And ultimately, we had pushed I think one terabyte was our busiest day in the middle of November over the ISP. So I had two connections, one of which was symmetrical 1G up and down that we were able to use and we like it maxed out our pipeline. We were like we were being startled by the ISP at one time. Yeah. Yeah. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.4, "text": " How's everybody feeling? Good. So if you haven't figured it out yet, I'm Chris Nova. Some people", "tokens": [50364, 1012, 311, 2201, 2633, 30, 2205, 13, 407, 498, 291, 2378, 380, 8932, 309, 484, 1939, 11, 286, 478, 6688, 27031, 13, 2188, 561, 51034], "temperature": 0.0, "avg_logprob": -0.1805915205102218, "compression_ratio": 1.4945652173913044, "no_speech_prob": 0.11072941869497299}, {"id": 1, "seek": 0, "start": 13.4, "end": 21.18, "text": " call me Chris. Some people call me Nova. Just don't call me Shirley. So we're going to get", "tokens": [51034, 818, 385, 6688, 13, 2188, 561, 818, 385, 27031, 13, 1449, 500, 380, 818, 385, 43275, 13, 407, 321, 434, 516, 281, 483, 51423], "temperature": 0.0, "avg_logprob": -0.1805915205102218, "compression_ratio": 1.4945652173913044, "no_speech_prob": 0.11072941869497299}, {"id": 2, "seek": 0, "start": 21.18, "end": 25.0, "text": " started with a few quick questions. There's a lot of people here. So I just want to get", "tokens": [51423, 1409, 365, 257, 1326, 1702, 1651, 13, 821, 311, 257, 688, 295, 561, 510, 13, 407, 286, 445, 528, 281, 483, 51614], "temperature": 0.0, "avg_logprob": -0.1805915205102218, "compression_ratio": 1.4945652173913044, "no_speech_prob": 0.11072941869497299}, {"id": 3, "seek": 2500, "start": 25.0, "end": 30.12, "text": " a feel for who's in the audience. So who here knows what mastodon is? Show of your hands.", "tokens": [50364, 257, 841, 337, 567, 311, 294, 264, 4034, 13, 407, 567, 510, 3255, 437, 27055, 378, 266, 307, 30, 6895, 295, 428, 2377, 13, 50620], "temperature": 0.0, "avg_logprob": -0.22135923703511556, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.5419089794158936}, {"id": 4, "seek": 2500, "start": 30.12, "end": 35.2, "text": " Okay. For folks at home, literally everybody just put their hand up. Who here knows what", "tokens": [50620, 1033, 13, 1171, 4024, 412, 1280, 11, 3736, 2201, 445, 829, 641, 1011, 493, 13, 2102, 510, 3255, 437, 50874], "temperature": 0.0, "avg_logprob": -0.22135923703511556, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.5419089794158936}, {"id": 5, "seek": 2500, "start": 35.2, "end": 43.04, "text": " hackaderm is? Oh, God. Sorry. So pretty much the same number of people. Who here knows", "tokens": [50874, 10339, 345, 966, 307, 30, 876, 11, 1265, 13, 4919, 13, 407, 1238, 709, 264, 912, 1230, 295, 561, 13, 2102, 510, 3255, 51266], "temperature": 0.0, "avg_logprob": -0.22135923703511556, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.5419089794158936}, {"id": 6, "seek": 2500, "start": 43.04, "end": 49.16, "text": " how to denial a service? Dadosa service? Okay. And how about just general abuse? How", "tokens": [51266, 577, 281, 28754, 257, 2643, 30, 413, 4181, 64, 2643, 30, 1033, 13, 400, 577, 466, 445, 2674, 9852, 30, 1012, 51572], "temperature": 0.0, "avg_logprob": -0.22135923703511556, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.5419089794158936}, {"id": 7, "seek": 2500, "start": 49.16, "end": 54.24, "text": " to like just use a service? Okay. So for those of you on the camera, literally the entire", "tokens": [51572, 281, 411, 445, 764, 257, 2643, 30, 1033, 13, 407, 337, 729, 295, 291, 322, 264, 2799, 11, 3736, 264, 2302, 51826], "temperature": 0.0, "avg_logprob": -0.22135923703511556, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.5419089794158936}, {"id": 8, "seek": 5424, "start": 54.24, "end": 61.480000000000004, "text": " stadium of people just put all of their hands up. I can't believe I'm about to do this.", "tokens": [50364, 18585, 295, 561, 445, 829, 439, 295, 641, 2377, 493, 13, 286, 393, 380, 1697, 286, 478, 466, 281, 360, 341, 13, 50726], "temperature": 0.0, "avg_logprob": -0.11450720893012153, "compression_ratio": 1.5394736842105263, "no_speech_prob": 0.008056174032390118}, {"id": 9, "seek": 5424, "start": 61.480000000000004, "end": 69.68, "text": " You have 45 minutes starting now. You have my full permission to DOS my shit. Take down", "tokens": [50726, 509, 362, 6905, 2077, 2891, 586, 13, 509, 362, 452, 1577, 11226, 281, 413, 4367, 452, 4611, 13, 3664, 760, 51136], "temperature": 0.0, "avg_logprob": -0.11450720893012153, "compression_ratio": 1.5394736842105263, "no_speech_prob": 0.008056174032390118}, {"id": 10, "seek": 5424, "start": 69.68, "end": 76.68, "text": " the service. You can do whatever you want. There are three known things I know of today", "tokens": [51136, 264, 2643, 13, 509, 393, 360, 2035, 291, 528, 13, 821, 366, 1045, 2570, 721, 286, 458, 295, 965, 51486], "temperature": 0.0, "avg_logprob": -0.11450720893012153, "compression_ratio": 1.5394736842105263, "no_speech_prob": 0.008056174032390118}, {"id": 11, "seek": 5424, "start": 76.68, "end": 80.84, "text": " that should make this pretty easy. I think if you knew exactly what you were doing, you", "tokens": [51486, 300, 820, 652, 341, 1238, 1858, 13, 286, 519, 498, 291, 2586, 2293, 437, 291, 645, 884, 11, 291, 51694], "temperature": 0.0, "avg_logprob": -0.11450720893012153, "compression_ratio": 1.5394736842105263, "no_speech_prob": 0.008056174032390118}, {"id": 12, "seek": 8084, "start": 80.88000000000001, "end": 85.2, "text": " could probably do it in about five minutes. So anyway, that's how we're going to start", "tokens": [50366, 727, 1391, 360, 309, 294, 466, 1732, 2077, 13, 407, 4033, 11, 300, 311, 577, 321, 434, 516, 281, 722, 50582], "temperature": 0.0, "avg_logprob": -0.12616130743133888, "compression_ratio": 1.530701754385965, "no_speech_prob": 0.27737897634506226}, {"id": 13, "seek": 8084, "start": 85.2, "end": 92.92, "text": " the talk off today. So the goal of this is to wake my partner up. So she's asleep right", "tokens": [50582, 264, 751, 766, 965, 13, 407, 264, 3387, 295, 341, 307, 281, 6634, 452, 4975, 493, 13, 407, 750, 311, 11039, 558, 50968], "temperature": 0.0, "avg_logprob": -0.12616130743133888, "compression_ratio": 1.530701754385965, "no_speech_prob": 0.27737897634506226}, {"id": 14, "seek": 8084, "start": 92.92, "end": 99.80000000000001, "text": " now. She's at home in Seattle. And if you're successful in disrupting the service, she", "tokens": [50968, 586, 13, 1240, 311, 412, 1280, 294, 15721, 13, 400, 498, 291, 434, 4406, 294, 14124, 278, 264, 2643, 11, 750, 51312], "temperature": 0.0, "avg_logprob": -0.12616130743133888, "compression_ratio": 1.530701754385965, "no_speech_prob": 0.27737897634506226}, {"id": 15, "seek": 8084, "start": 99.80000000000001, "end": 104.52000000000001, "text": " will get some discord notifications and we have a team of volunteers. Their phones will", "tokens": [51312, 486, 483, 512, 32989, 13426, 293, 321, 362, 257, 1469, 295, 14352, 13, 6710, 10216, 486, 51548], "temperature": 0.0, "avg_logprob": -0.12616130743133888, "compression_ratio": 1.530701754385965, "no_speech_prob": 0.27737897634506226}, {"id": 16, "seek": 10452, "start": 104.52, "end": 111.84, "text": " go off. My phone will start going off. And hopefully, hopefully my puppy greets her with", "tokens": [50364, 352, 766, 13, 1222, 2593, 486, 722, 516, 766, 13, 400, 4696, 11, 4696, 452, 18196, 6066, 1385, 720, 365, 50730], "temperature": 0.0, "avg_logprob": -0.14449627134535048, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.0495106466114521}, {"id": 17, "seek": 10452, "start": 111.84, "end": 119.0, "text": " a smile and wakes her up as there's inevitably a crisis. Okay. So the reason I wanted to", "tokens": [50730, 257, 7563, 293, 29610, 720, 493, 382, 456, 311, 28171, 257, 5869, 13, 1033, 13, 407, 264, 1778, 286, 1415, 281, 51088], "temperature": 0.0, "avg_logprob": -0.14449627134535048, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.0495106466114521}, {"id": 18, "seek": 10452, "start": 119.0, "end": 125.03999999999999, "text": " start this off is because we have had to do a tremendous amount of work to bring Hack", "tokens": [51088, 722, 341, 766, 307, 570, 321, 362, 632, 281, 360, 257, 10048, 2372, 295, 589, 281, 1565, 35170, 51390], "temperature": 0.0, "avg_logprob": -0.14449627134535048, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.0495106466114521}, {"id": 19, "seek": 10452, "start": 125.03999999999999, "end": 132.35999999999999, "text": " Derm to where it is today. So just to kind of start the slides off with some basic numbers", "tokens": [51390, 413, 966, 281, 689, 309, 307, 965, 13, 407, 445, 281, 733, 295, 722, 264, 9788, 766, 365, 512, 3875, 3547, 51756], "temperature": 0.0, "avg_logprob": -0.14449627134535048, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.0495106466114521}, {"id": 20, "seek": 13236, "start": 132.4, "end": 137.08, "text": " here. I don't know if y'all can see this, but this is just a public glimpse into the", "tokens": [50366, 510, 13, 286, 500, 380, 458, 498, 288, 6, 336, 393, 536, 341, 11, 457, 341, 307, 445, 257, 1908, 25838, 666, 264, 50600], "temperature": 0.0, "avg_logprob": -0.16755996073099008, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.057347510010004044}, {"id": 21, "seek": 13236, "start": 137.08, "end": 144.28, "text": " service that's online today, just serving mastodon. And there's 44,000 users. It looks", "tokens": [50600, 2643, 300, 311, 2950, 965, 11, 445, 8148, 27055, 378, 266, 13, 400, 456, 311, 16408, 11, 1360, 5022, 13, 467, 1542, 50960], "temperature": 0.0, "avg_logprob": -0.16755996073099008, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.057347510010004044}, {"id": 22, "seek": 13236, "start": 144.28, "end": 148.44000000000003, "text": " like we had 200 people sign up today. I don't know how many of those people were here at", "tokens": [50960, 411, 321, 632, 2331, 561, 1465, 493, 965, 13, 286, 500, 380, 458, 577, 867, 295, 729, 561, 645, 510, 412, 51168], "temperature": 0.0, "avg_logprob": -0.16755996073099008, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.057347510010004044}, {"id": 23, "seek": 13236, "start": 148.44000000000003, "end": 154.64000000000001, "text": " Fosnum. I don't really know very much about them at all. We've had 20,000 toots. Sorry,", "tokens": [51168, 479, 329, 77, 449, 13, 286, 500, 380, 534, 458, 588, 709, 466, 552, 412, 439, 13, 492, 600, 632, 945, 11, 1360, 281, 1971, 13, 4919, 11, 51478], "temperature": 0.0, "avg_logprob": -0.16755996073099008, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.057347510010004044}, {"id": 24, "seek": 13236, "start": 154.64000000000001, "end": 161.64000000000001, "text": " we've had 789,000 toots. And we have 20,000 monthly active users. So there's been 20,000", "tokens": [51478, 321, 600, 632, 1614, 21115, 11, 1360, 281, 1971, 13, 400, 321, 362, 945, 11, 1360, 12878, 4967, 5022, 13, 407, 456, 311, 668, 945, 11, 1360, 51828], "temperature": 0.0, "avg_logprob": -0.16755996073099008, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.057347510010004044}, {"id": 25, "seek": 16164, "start": 162.04, "end": 167.2, "text": " people who signed into the service in the past 30 days alone. And we are currently federating", "tokens": [50384, 561, 567, 8175, 666, 264, 2643, 294, 264, 1791, 2217, 1708, 3312, 13, 400, 321, 366, 4362, 38024, 990, 50642], "temperature": 0.0, "avg_logprob": -0.1338855837598259, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.0016465364024043083}, {"id": 26, "seek": 16164, "start": 167.2, "end": 174.7, "text": " with another 20,000 instances, which in my opinion is yet another attack vector for the", "tokens": [50642, 365, 1071, 945, 11, 1360, 14519, 11, 597, 294, 452, 4800, 307, 1939, 1071, 2690, 8062, 337, 264, 51017], "temperature": 0.0, "avg_logprob": -0.1338855837598259, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.0016465364024043083}, {"id": 27, "seek": 16164, "start": 174.7, "end": 180.48, "text": " internet at large that we should probably spend more time discussing. So if you are", "tokens": [51017, 4705, 412, 2416, 300, 321, 820, 1391, 3496, 544, 565, 10850, 13, 407, 498, 291, 366, 51306], "temperature": 0.0, "avg_logprob": -0.1338855837598259, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.0016465364024043083}, {"id": 28, "seek": 16164, "start": 180.48, "end": 185.92, "text": " successful in flooding the service, hopefully by the end of my talk, we should see some", "tokens": [51306, 4406, 294, 24132, 264, 2643, 11, 4696, 538, 264, 917, 295, 452, 751, 11, 321, 820, 536, 512, 51578], "temperature": 0.0, "avg_logprob": -0.1338855837598259, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.0016465364024043083}, {"id": 29, "seek": 18592, "start": 185.92, "end": 192.92, "text": " spikes in these two middle graphs here. The HTTP response time is probably the most sensitive", "tokens": [50364, 28997, 294, 613, 732, 2808, 24877, 510, 13, 440, 33283, 4134, 565, 307, 1391, 264, 881, 9477, 50714], "temperature": 0.0, "avg_logprob": -0.11218278748648507, "compression_ratio": 1.452127659574468, "no_speech_prob": 0.016619611531496048}, {"id": 30, "seek": 18592, "start": 193.11999999999998, "end": 200.11999999999998, "text": " part of our entire system today. Cool. So let's get back into it. So about me, I work", "tokens": [50724, 644, 295, 527, 2302, 1185, 965, 13, 8561, 13, 407, 718, 311, 483, 646, 666, 309, 13, 407, 466, 385, 11, 286, 589, 51074], "temperature": 0.0, "avg_logprob": -0.11218278748648507, "compression_ratio": 1.452127659574468, "no_speech_prob": 0.016619611531496048}, {"id": 31, "seek": 18592, "start": 204.95999999999998, "end": 209.92, "text": " at GitHub. I'm a principal engineer at GitHub. I'm also an author. I've written some mediocre", "tokens": [51316, 412, 23331, 13, 286, 478, 257, 9716, 11403, 412, 23331, 13, 286, 478, 611, 364, 3793, 13, 286, 600, 3720, 512, 45415, 51564], "temperature": 0.0, "avg_logprob": -0.11218278748648507, "compression_ratio": 1.452127659574468, "no_speech_prob": 0.016619611531496048}, {"id": 32, "seek": 20992, "start": 209.92, "end": 216.16, "text": " quality books. And as of four days ago, I'm also the president and a board member of a", "tokens": [50364, 3125, 3642, 13, 400, 382, 295, 1451, 1708, 2057, 11, 286, 478, 611, 264, 3868, 293, 257, 3150, 4006, 295, 257, 50676], "temperature": 0.0, "avg_logprob": -0.12774038314819336, "compression_ratio": 1.7081712062256809, "no_speech_prob": 0.0452362485229969}, {"id": 33, "seek": 20992, "start": 216.16, "end": 222.66, "text": " foundation I'll tell you about here shortly. And if you want to follow me on decentralized", "tokens": [50676, 7030, 286, 603, 980, 291, 466, 510, 13392, 13, 400, 498, 291, 528, 281, 1524, 385, 322, 32870, 51001], "temperature": 0.0, "avg_logprob": -0.12774038314819336, "compression_ratio": 1.7081712062256809, "no_speech_prob": 0.0452362485229969}, {"id": 34, "seek": 20992, "start": 222.66, "end": 228.35999999999999, "text": " social media, there's my links there. Okay. So we're going to start off and we're going", "tokens": [51001, 2093, 3021, 11, 456, 311, 452, 6123, 456, 13, 1033, 13, 407, 321, 434, 516, 281, 722, 766, 293, 321, 434, 516, 51286], "temperature": 0.0, "avg_logprob": -0.12774038314819336, "compression_ratio": 1.7081712062256809, "no_speech_prob": 0.0452362485229969}, {"id": 35, "seek": 20992, "start": 228.35999999999999, "end": 232.6, "text": " to do some basic context studying. And then we're going to go into like a little bit of", "tokens": [51286, 281, 360, 512, 3875, 4319, 7601, 13, 400, 550, 321, 434, 516, 281, 352, 666, 411, 257, 707, 857, 295, 51498], "temperature": 0.0, "avg_logprob": -0.12774038314819336, "compression_ratio": 1.7081712062256809, "no_speech_prob": 0.0452362485229969}, {"id": 36, "seek": 20992, "start": 232.6, "end": 239.04, "text": " an incident report of a situation we found ourselves in last November. And then we'll", "tokens": [51498, 364, 9348, 2275, 295, 257, 2590, 321, 1352, 4175, 294, 1036, 7674, 13, 400, 550, 321, 603, 51820], "temperature": 0.0, "avg_logprob": -0.12774038314819336, "compression_ratio": 1.7081712062256809, "no_speech_prob": 0.0452362485229969}, {"id": 37, "seek": 23904, "start": 239.07999999999998, "end": 244.2, "text": " talk a little bit about what this means to me, what this means to the United States economy,", "tokens": [50366, 751, 257, 707, 857, 466, 437, 341, 1355, 281, 385, 11, 437, 341, 1355, 281, 264, 2824, 3040, 5010, 11, 50622], "temperature": 0.0, "avg_logprob": -0.12902405106018636, "compression_ratio": 1.75, "no_speech_prob": 0.0038201191928237677}, {"id": 38, "seek": 23904, "start": 244.2, "end": 248.79999999999998, "text": " the legal situation in the United States, and how we're kind of navigating all of this", "tokens": [50622, 264, 5089, 2590, 294, 264, 2824, 3040, 11, 293, 577, 321, 434, 733, 295, 32054, 439, 295, 341, 50852], "temperature": 0.0, "avg_logprob": -0.12902405106018636, "compression_ratio": 1.75, "no_speech_prob": 0.0038201191928237677}, {"id": 39, "seek": 23904, "start": 248.79999999999998, "end": 255.79999999999998, "text": " that we really kind of just stumbled upon earlier last year. So the short story here", "tokens": [50852, 300, 321, 534, 733, 295, 445, 36668, 3564, 3071, 1036, 1064, 13, 407, 264, 2099, 1657, 510, 51202], "temperature": 0.0, "avg_logprob": -0.12902405106018636, "compression_ratio": 1.75, "no_speech_prob": 0.0038201191928237677}, {"id": 40, "seek": 23904, "start": 256.76, "end": 262.03999999999996, "text": " is my little mastodon server that was used for me in about 100 of my friends, if maybe", "tokens": [51250, 307, 452, 707, 27055, 378, 266, 7154, 300, 390, 1143, 337, 385, 294, 466, 2319, 295, 452, 1855, 11, 498, 1310, 51514], "temperature": 0.0, "avg_logprob": -0.12902405106018636, "compression_ratio": 1.75, "no_speech_prob": 0.0038201191928237677}, {"id": 41, "seek": 23904, "start": 262.03999999999996, "end": 268.96, "text": " not even 100, maybe 50 of my friends, had very quickly turned into what I consider medium", "tokens": [51514, 406, 754, 2319, 11, 1310, 2625, 295, 452, 1855, 11, 632, 588, 2661, 3574, 666, 437, 286, 1949, 6399, 51860], "temperature": 0.0, "avg_logprob": -0.12902405106018636, "compression_ratio": 1.75, "no_speech_prob": 0.0038201191928237677}, {"id": 42, "seek": 26896, "start": 269.0, "end": 274.79999999999995, "text": " size scale. And when we reached medium size scale, a lot of the problems aren't necessarily", "tokens": [50366, 2744, 4373, 13, 400, 562, 321, 6488, 6399, 2744, 4373, 11, 257, 688, 295, 264, 2740, 3212, 380, 4725, 50656], "temperature": 0.0, "avg_logprob": -0.14172692732377487, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.0005270185647532344}, {"id": 43, "seek": 26896, "start": 274.79999999999995, "end": 280.44, "text": " related to the technology. Although, as you're about to find out, operating a Ruby monolith", "tokens": [50656, 4077, 281, 264, 2899, 13, 5780, 11, 382, 291, 434, 466, 281, 915, 484, 11, 7447, 257, 19907, 1108, 29131, 50938], "temperature": 0.0, "avg_logprob": -0.14172692732377487, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.0005270185647532344}, {"id": 44, "seek": 26896, "start": 280.44, "end": 287.2, "text": " at scale does come with a substantial amount of concerns, which we'll dig more into that", "tokens": [50938, 412, 4373, 775, 808, 365, 257, 16726, 2372, 295, 7389, 11, 597, 321, 603, 2528, 544, 666, 300, 51276], "temperature": 0.0, "avg_logprob": -0.14172692732377487, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.0005270185647532344}, {"id": 45, "seek": 26896, "start": 287.2, "end": 294.2, "text": " in a moment. Okay. So just for folks at home who are watching the video after the fact,", "tokens": [51276, 294, 257, 1623, 13, 1033, 13, 407, 445, 337, 4024, 412, 1280, 567, 366, 1976, 264, 960, 934, 264, 1186, 11, 51626], "temperature": 0.0, "avg_logprob": -0.14172692732377487, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.0005270185647532344}, {"id": 46, "seek": 29420, "start": 294.44, "end": 300.44, "text": " I want to give a little bit of context on mastodon in general. And I want to be clear.", "tokens": [50376, 286, 528, 281, 976, 257, 707, 857, 295, 4319, 322, 27055, 378, 266, 294, 2674, 13, 400, 286, 528, 281, 312, 1850, 13, 50676], "temperature": 0.0, "avg_logprob": -0.09710688542838049, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00406761234626174}, {"id": 47, "seek": 29420, "start": 300.44, "end": 305.96, "text": " I am not a mastodon. Well, I guess it depends what you define as a contributor, but I don't", "tokens": [50676, 286, 669, 406, 257, 27055, 378, 266, 13, 1042, 11, 286, 2041, 309, 5946, 437, 291, 6964, 382, 257, 42859, 11, 457, 286, 500, 380, 50952], "temperature": 0.0, "avg_logprob": -0.09710688542838049, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00406761234626174}, {"id": 48, "seek": 29420, "start": 305.96, "end": 312.96, "text": " work on mastodon that much. I've written a few issues. I've helped talk to some folks", "tokens": [50952, 589, 322, 27055, 378, 266, 300, 709, 13, 286, 600, 3720, 257, 1326, 2663, 13, 286, 600, 4254, 751, 281, 512, 4024, 51302], "temperature": 0.0, "avg_logprob": -0.09710688542838049, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00406761234626174}, {"id": 49, "seek": 29420, "start": 312.96, "end": 318.96, "text": " who do contribute to the project. But for the most part, this is probably the most detached", "tokens": [51302, 567, 360, 10586, 281, 264, 1716, 13, 583, 337, 264, 881, 644, 11, 341, 307, 1391, 264, 881, 42050, 51602], "temperature": 0.0, "avg_logprob": -0.09710688542838049, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00406761234626174}, {"id": 50, "seek": 31896, "start": 319.0, "end": 325.5, "text": " I am from any of the open source projects I work on. I literally am a consumer of mastodon.", "tokens": [50366, 286, 669, 490, 604, 295, 264, 1269, 4009, 4455, 286, 589, 322, 13, 286, 3736, 669, 257, 9711, 295, 27055, 378, 266, 13, 50691], "temperature": 0.0, "avg_logprob": -0.11732760263145517, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.008301399648189545}, {"id": 51, "seek": 31896, "start": 325.5, "end": 330.32, "text": " The most involved I have gotten with this particular project has been going to GitHub", "tokens": [50691, 440, 881, 3288, 286, 362, 5768, 365, 341, 1729, 1716, 575, 668, 516, 281, 23331, 50932], "temperature": 0.0, "avg_logprob": -0.11732760263145517, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.008301399648189545}, {"id": 52, "seek": 31896, "start": 330.32, "end": 335.47999999999996, "text": " and going to the release tab and downloading the latest versions for me to go and install", "tokens": [50932, 293, 516, 281, 264, 4374, 4421, 293, 32529, 264, 6792, 9606, 337, 385, 281, 352, 293, 3625, 51190], "temperature": 0.0, "avg_logprob": -0.11732760263145517, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.008301399648189545}, {"id": 53, "seek": 31896, "start": 335.47999999999996, "end": 342.0, "text": " on my server. So it's kind of nice, not going to lie, to just be on the consumer side of", "tokens": [51190, 322, 452, 7154, 13, 407, 309, 311, 733, 295, 1481, 11, 406, 516, 281, 4544, 11, 281, 445, 312, 322, 264, 9711, 1252, 295, 51516], "temperature": 0.0, "avg_logprob": -0.11732760263145517, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.008301399648189545}, {"id": 54, "seek": 31896, "start": 342.0, "end": 347.71999999999997, "text": " the open source for a change. But mastodon is ultimately social networking that's not", "tokens": [51516, 264, 1269, 4009, 337, 257, 1319, 13, 583, 27055, 378, 266, 307, 6284, 2093, 17985, 300, 311, 406, 51802], "temperature": 0.0, "avg_logprob": -0.11732760263145517, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.008301399648189545}, {"id": 55, "seek": 34772, "start": 347.76000000000005, "end": 354.68, "text": " for sale. It's built on the activity pub W3C protocol. And it's an alternative to familiar", "tokens": [50366, 337, 8680, 13, 467, 311, 3094, 322, 264, 5191, 1535, 343, 18, 34, 10336, 13, 400, 309, 311, 364, 8535, 281, 4963, 50712], "temperature": 0.0, "avg_logprob": -0.1507176611158583, "compression_ratio": 1.4793388429752066, "no_speech_prob": 0.00266927108168602}, {"id": 56, "seek": 34772, "start": 354.68, "end": 360.68, "text": " social media sites like Twitter. And it gives you much more ownership and control of your", "tokens": [50712, 2093, 3021, 7533, 411, 5794, 13, 400, 309, 2709, 291, 709, 544, 15279, 293, 1969, 295, 428, 51012], "temperature": 0.0, "avg_logprob": -0.1507176611158583, "compression_ratio": 1.4793388429752066, "no_speech_prob": 0.00266927108168602}, {"id": 57, "seek": 34772, "start": 360.68, "end": 367.68, "text": " data from both an operator and a user perspective. Okay. So this is probably the number one", "tokens": [51012, 1412, 490, 1293, 364, 12973, 293, 257, 4195, 4585, 13, 1033, 13, 407, 341, 307, 1391, 264, 1230, 472, 51362], "temperature": 0.0, "avg_logprob": -0.1507176611158583, "compression_ratio": 1.4793388429752066, "no_speech_prob": 0.00266927108168602}, {"id": 58, "seek": 34772, "start": 367.72, "end": 372.28000000000003, "text": " question I get asked, which is how did we come up with the name Hackaderm? And if you", "tokens": [51364, 1168, 286, 483, 2351, 11, 597, 307, 577, 630, 321, 808, 493, 365, 264, 1315, 35170, 345, 966, 30, 400, 498, 291, 51592], "temperature": 0.0, "avg_logprob": -0.1507176611158583, "compression_ratio": 1.4793388429752066, "no_speech_prob": 0.00266927108168602}, {"id": 59, "seek": 37228, "start": 372.32, "end": 377.76, "text": " talk to my friends in Italy, it's hashaderm or hashadermio or I've heard a lot of different", "tokens": [50366, 751, 281, 452, 1855, 294, 10705, 11, 309, 311, 22019, 345, 966, 420, 22019, 345, 966, 1004, 420, 286, 600, 2198, 257, 688, 295, 819, 50638], "temperature": 0.0, "avg_logprob": -0.19671050948326033, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.15542519092559814}, {"id": 60, "seek": 37228, "start": 377.76, "end": 382.76, "text": " variations of it. It's my partner came up with the name. It's ultimately a plan words", "tokens": [50638, 17840, 295, 309, 13, 467, 311, 452, 4975, 1361, 493, 365, 264, 1315, 13, 467, 311, 6284, 257, 1393, 2283, 50888], "temperature": 0.0, "avg_logprob": -0.19671050948326033, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.15542519092559814}, {"id": 61, "seek": 37228, "start": 382.76, "end": 389.76, "text": " with hacky and packaderm. So hacky is a clumsy, temporal or in elegant solution to a technical", "tokens": [50888, 365, 10339, 88, 293, 2844, 345, 966, 13, 407, 10339, 88, 307, 257, 44640, 11, 30881, 420, 294, 21117, 3827, 281, 257, 6191, 51238], "temperature": 0.0, "avg_logprob": -0.19671050948326033, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.15542519092559814}, {"id": 62, "seek": 37228, "start": 390.2, "end": 397.2, "text": " problem. And packaderm is a large thick skinned mammal such as an elephant rhinoceros or", "tokens": [51260, 1154, 13, 400, 2844, 345, 966, 307, 257, 2416, 5060, 3178, 9232, 49312, 1270, 382, 364, 19791, 49030, 905, 16771, 420, 51610], "temperature": 0.0, "avg_logprob": -0.19671050948326033, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.15542519092559814}, {"id": 63, "seek": 39720, "start": 397.92, "end": 403.36, "text": " hippopotamus, obviously mastodon. You see where we're going with this. And so we like", "tokens": [50400, 27745, 45225, 45897, 11, 2745, 27055, 378, 266, 13, 509, 536, 689, 321, 434, 516, 365, 341, 13, 400, 370, 321, 411, 50672], "temperature": 0.0, "avg_logprob": -0.13206838039641686, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0060892957262694836}, {"id": 64, "seek": 39720, "start": 403.36, "end": 410.36, "text": " to say that hackaderm is a clumsy, temporary or in elegant thick skinned social media server.", "tokens": [50672, 281, 584, 300, 10339, 345, 966, 307, 257, 44640, 11, 13413, 420, 294, 21117, 5060, 3178, 9232, 2093, 3021, 7154, 13, 51022], "temperature": 0.0, "avg_logprob": -0.13206838039641686, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0060892957262694836}, {"id": 65, "seek": 39720, "start": 411.96, "end": 416.32, "text": " And depending on how successful some of these people with their laptops are, we're going", "tokens": [51102, 400, 5413, 322, 577, 4406, 512, 295, 613, 561, 365, 641, 27642, 366, 11, 321, 434, 516, 51320], "temperature": 0.0, "avg_logprob": -0.13206838039641686, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0060892957262694836}, {"id": 66, "seek": 39720, "start": 416.32, "end": 423.32, "text": " to see how thick the skin really is. So again, right now we have roughly 45,000 hackadermians", "tokens": [51320, 281, 536, 577, 5060, 264, 3178, 534, 307, 13, 407, 797, 11, 558, 586, 321, 362, 9810, 6905, 11, 1360, 10339, 345, 966, 2567, 51670], "temperature": 0.0, "avg_logprob": -0.13206838039641686, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0060892957262694836}, {"id": 67, "seek": 42332, "start": 423.88, "end": 430.88, "text": " is what we refer to the people in the community, which is a lot of people. I wasn't prepared", "tokens": [50392, 307, 437, 321, 2864, 281, 264, 561, 294, 264, 1768, 11, 597, 307, 257, 688, 295, 561, 13, 286, 2067, 380, 4927, 50742], "temperature": 0.0, "avg_logprob": -0.15327357197855854, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.004581678193062544}, {"id": 68, "seek": 42332, "start": 433.4, "end": 439.46, "text": " for the sheer number of people and the sheer number of like bizarre things that we would", "tokens": [50868, 337, 264, 23061, 1230, 295, 561, 293, 264, 23061, 1230, 295, 411, 18265, 721, 300, 321, 576, 51171], "temperature": 0.0, "avg_logprob": -0.15327357197855854, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.004581678193062544}, {"id": 69, "seek": 42332, "start": 439.46, "end": 446.36, "text": " be getting into as we approach the size scale. And we have 20,000 people who are active.", "tokens": [51171, 312, 1242, 666, 382, 321, 3109, 264, 2744, 4373, 13, 400, 321, 362, 945, 11, 1360, 561, 567, 366, 4967, 13, 51516], "temperature": 0.0, "avg_logprob": -0.15327357197855854, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.004581678193062544}, {"id": 70, "seek": 42332, "start": 446.36, "end": 452.32, "text": " And so this is, there's a lot of implications of that specific ratio. But for the most part", "tokens": [51516, 400, 370, 341, 307, 11, 456, 311, 257, 688, 295, 16602, 295, 300, 2685, 8509, 13, 583, 337, 264, 881, 644, 51814], "temperature": 0.0, "avg_logprob": -0.15327357197855854, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.004581678193062544}, {"id": 71, "seek": 45232, "start": 452.32, "end": 459.32, "text": " we see a lot of traffic go through our network every day. And I think at least once a day", "tokens": [50364, 321, 536, 257, 688, 295, 6419, 352, 807, 527, 3209, 633, 786, 13, 400, 286, 519, 412, 1935, 1564, 257, 786, 50714], "temperature": 0.0, "avg_logprob": -0.12192614325161638, "compression_ratio": 1.519650655021834, "no_speech_prob": 0.0005264488281682134}, {"id": 72, "seek": 45232, "start": 459.76, "end": 465.68, "text": " there's some sort of crisis. So we have all of the major problems of Jurassic Park, of", "tokens": [50736, 456, 311, 512, 1333, 295, 5869, 13, 407, 321, 362, 439, 295, 264, 2563, 2740, 295, 44730, 4964, 11, 295, 51032], "temperature": 0.0, "avg_logprob": -0.12192614325161638, "compression_ratio": 1.519650655021834, "no_speech_prob": 0.0005264488281682134}, {"id": 73, "seek": 45232, "start": 465.68, "end": 471.24, "text": " a major theme park, of a normal technical shop, which has been fascinating to kind of", "tokens": [51032, 257, 2563, 6314, 3884, 11, 295, 257, 2710, 6191, 3945, 11, 597, 575, 668, 10343, 281, 733, 295, 51310], "temperature": 0.0, "avg_logprob": -0.12192614325161638, "compression_ratio": 1.519650655021834, "no_speech_prob": 0.0005264488281682134}, {"id": 74, "seek": 45232, "start": 471.24, "end": 478.24, "text": " watch this whole thing grow. The hackaderm community is pretty interesting. And to be", "tokens": [51310, 1159, 341, 1379, 551, 1852, 13, 440, 10339, 345, 966, 1768, 307, 1238, 1880, 13, 400, 281, 312, 51660], "temperature": 0.0, "avg_logprob": -0.12192614325161638, "compression_ratio": 1.519650655021834, "no_speech_prob": 0.0005264488281682134}, {"id": 75, "seek": 47824, "start": 478.28000000000003, "end": 484.28000000000003, "text": " completely honest, I'm still not really sure how it ended up the way it did. But it's mostly", "tokens": [50366, 2584, 3245, 11, 286, 478, 920, 406, 534, 988, 577, 309, 4590, 493, 264, 636, 309, 630, 13, 583, 309, 311, 5240, 50666], "temperature": 0.0, "avg_logprob": -0.24735926068018352, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.006188074126839638}, {"id": 76, "seek": 47824, "start": 484.28000000000003, "end": 490.28000000000003, "text": " composed of technical and open source professionals, such as people here. It's similar to Fostodon,", "tokens": [50666, 18204, 295, 6191, 293, 1269, 4009, 11954, 11, 1270, 382, 561, 510, 13, 467, 311, 2531, 281, 479, 555, 378, 266, 11, 50966], "temperature": 0.0, "avg_logprob": -0.24735926068018352, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.006188074126839638}, {"id": 77, "seek": 47824, "start": 490.28000000000003, "end": 495.28000000000003, "text": " who here has heard of the Fostodon MasterDawn server. That one's also great. Also, I have", "tokens": [50966, 567, 510, 575, 2198, 295, 264, 479, 555, 378, 266, 6140, 35, 11251, 7154, 13, 663, 472, 311, 611, 869, 13, 2743, 11, 286, 362, 51216], "temperature": 0.0, "avg_logprob": -0.24735926068018352, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.006188074126839638}, {"id": 78, "seek": 47824, "start": 495.28000000000003, "end": 500.28000000000003, "text": " some colleagues who work on the InfoSec one. That's also another good one. But I see a", "tokens": [51216, 512, 7734, 567, 589, 322, 264, 11537, 78, 29511, 472, 13, 663, 311, 611, 1071, 665, 472, 13, 583, 286, 536, 257, 51466], "temperature": 0.0, "avg_logprob": -0.24735926068018352, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.006188074126839638}, {"id": 79, "seek": 47824, "start": 500.28000000000003, "end": 505.28000000000003, "text": " lot of like SREs, such style people, a lot of senior engineers who work on the InfoSec", "tokens": [51466, 688, 295, 411, 318, 3850, 82, 11, 1270, 3758, 561, 11, 257, 688, 295, 7965, 11955, 567, 589, 322, 264, 11537, 78, 29511, 51716], "temperature": 0.0, "avg_logprob": -0.24735926068018352, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.006188074126839638}, {"id": 80, "seek": 50528, "start": 505.32, "end": 512.3199999999999, "text": " style people, a lot of senior engineers, directors. We even have some executives. And then we", "tokens": [50366, 3758, 561, 11, 257, 688, 295, 7965, 11955, 11, 17307, 13, 492, 754, 362, 512, 28485, 13, 400, 550, 321, 50716], "temperature": 0.0, "avg_logprob": -0.15426275589886834, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.005459694657474756}, {"id": 81, "seek": 50528, "start": 512.3199999999999, "end": 518.3199999999999, "text": " also have like honestly just some very beautiful anonymous hackers who keep everybody in check.", "tokens": [50716, 611, 362, 411, 6095, 445, 512, 588, 2238, 24932, 39766, 567, 1066, 2201, 294, 1520, 13, 51016], "temperature": 0.0, "avg_logprob": -0.15426275589886834, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.005459694657474756}, {"id": 82, "seek": 50528, "start": 518.3199999999999, "end": 524.3199999999999, "text": " And so it's a good blend of people. And we see a lot of interesting things come through", "tokens": [51016, 400, 370, 309, 311, 257, 665, 10628, 295, 561, 13, 400, 321, 536, 257, 688, 295, 1880, 721, 808, 807, 51316], "temperature": 0.0, "avg_logprob": -0.15426275589886834, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.005459694657474756}, {"id": 83, "seek": 50528, "start": 524.3199999999999, "end": 531.3199999999999, "text": " our various servers. So our about page reads, here we are trying to build a curated network", "tokens": [51316, 527, 3683, 15909, 13, 407, 527, 466, 3028, 15700, 11, 510, 321, 366, 1382, 281, 1322, 257, 47851, 3209, 51666], "temperature": 0.0, "avg_logprob": -0.15426275589886834, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.005459694657474756}, {"id": 84, "seek": 53132, "start": 531.36, "end": 537.36, "text": " of respectful professionals in the tech industry around the globe. And the around the globe part", "tokens": [50366, 295, 26205, 11954, 294, 264, 7553, 3518, 926, 264, 15371, 13, 400, 264, 926, 264, 15371, 644, 50666], "temperature": 0.0, "avg_logprob": -0.10189508508752894, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.006576967425644398}, {"id": 85, "seek": 53132, "start": 537.36, "end": 542.36, "text": " is the interesting part, especially when we start looking at the legal implications of this,", "tokens": [50666, 307, 264, 1880, 644, 11, 2318, 562, 321, 722, 1237, 412, 264, 5089, 16602, 295, 341, 11, 50916], "temperature": 0.0, "avg_logprob": -0.10189508508752894, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.006576967425644398}, {"id": 86, "seek": 53132, "start": 542.36, "end": 548.36, "text": " which again, we weren't necessarily prepared for. And we welcome anyone who follows the rules", "tokens": [50916, 597, 797, 11, 321, 4999, 380, 4725, 4927, 337, 13, 400, 321, 2928, 2878, 567, 10002, 264, 4474, 51216], "temperature": 0.0, "avg_logprob": -0.10189508508752894, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.006576967425644398}, {"id": 87, "seek": 53132, "start": 548.36, "end": 555.36, "text": " and needs a safe home or a fresh start. I think this was personally a big one for me. And I", "tokens": [51216, 293, 2203, 257, 3273, 1280, 420, 257, 4451, 722, 13, 286, 519, 341, 390, 5665, 257, 955, 472, 337, 385, 13, 400, 286, 51566], "temperature": 0.0, "avg_logprob": -0.10189508508752894, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.006576967425644398}, {"id": 88, "seek": 53132, "start": 555.36, "end": 560.36, "text": " think this is also very relevant to a lot of the folks that I know who have joined in the last", "tokens": [51566, 519, 341, 307, 611, 588, 7340, 281, 257, 688, 295, 264, 4024, 300, 286, 458, 567, 362, 6869, 294, 264, 1036, 51816], "temperature": 0.0, "avg_logprob": -0.10189508508752894, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.006576967425644398}, {"id": 89, "seek": 56036, "start": 560.4, "end": 566.4, "text": " few months. I do think that there's like some pretty, in my opinion anyway, some pretty toxic", "tokens": [50366, 1326, 2493, 13, 286, 360, 519, 300, 456, 311, 411, 512, 1238, 11, 294, 452, 4800, 4033, 11, 512, 1238, 12786, 50666], "temperature": 0.0, "avg_logprob": -0.102418167250497, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.00608918908983469}, {"id": 90, "seek": 56036, "start": 566.4, "end": 572.4, "text": " mental health situations that folks find themselves in using Twitter. And I think that this is", "tokens": [50666, 4973, 1585, 6851, 300, 4024, 915, 2969, 294, 1228, 5794, 13, 400, 286, 519, 300, 341, 307, 50966], "temperature": 0.0, "avg_logprob": -0.102418167250497, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.00608918908983469}, {"id": 91, "seek": 56036, "start": 572.4, "end": 577.4, "text": " kind of an opportunity to just like rip the Band-Aid off and start fresh and kind of establish", "tokens": [50966, 733, 295, 364, 2650, 281, 445, 411, 12782, 264, 15462, 12, 32, 327, 766, 293, 722, 4451, 293, 733, 295, 8327, 51216], "temperature": 0.0, "avg_logprob": -0.102418167250497, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.00608918908983469}, {"id": 92, "seek": 56036, "start": 577.4, "end": 583.4, "text": " some new habits for people and some new self image for people. And so I do see a lot of people", "tokens": [51216, 512, 777, 14100, 337, 561, 293, 512, 777, 2698, 3256, 337, 561, 13, 400, 370, 286, 360, 536, 257, 688, 295, 561, 51516], "temperature": 0.0, "avg_logprob": -0.102418167250497, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.00608918908983469}, {"id": 93, "seek": 56036, "start": 583.4, "end": 588.4, "text": " kind of reimagining themselves and reinventing themselves when they come to Hackaderm. But", "tokens": [51516, 733, 295, 319, 25228, 1760, 2969, 293, 33477, 278, 2969, 562, 436, 808, 281, 35170, 345, 966, 13, 583, 51766], "temperature": 0.0, "avg_logprob": -0.102418167250497, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.00608918908983469}, {"id": 94, "seek": 58840, "start": 588.4399999999999, "end": 593.4399999999999, "text": " yeah, ultimately, it's hackers, professionals, enthusiasts, and we're passionate about life,", "tokens": [50366, 1338, 11, 6284, 11, 309, 311, 39766, 11, 11954, 11, 45873, 11, 293, 321, 434, 11410, 466, 993, 11, 50616], "temperature": 0.0, "avg_logprob": -0.14847763453688578, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.000895119272172451}, {"id": 95, "seek": 58840, "start": 593.4399999999999, "end": 599.4399999999999, "text": " respect, and digital freedom, and we believe in peace and balance. And I wrote this very casually", "tokens": [50616, 3104, 11, 293, 4562, 5645, 11, 293, 321, 1697, 294, 4336, 293, 4772, 13, 400, 286, 4114, 341, 588, 34872, 50916], "temperature": 0.0, "avg_logprob": -0.14847763453688578, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.000895119272172451}, {"id": 96, "seek": 58840, "start": 599.4399999999999, "end": 604.4399999999999, "text": " like on a Twitch stream, and those words are actually pretty important now that we're continuing", "tokens": [50916, 411, 322, 257, 22222, 4309, 11, 293, 729, 2283, 366, 767, 1238, 1021, 586, 300, 321, 434, 9289, 51166], "temperature": 0.0, "avg_logprob": -0.14847763453688578, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.000895119272172451}, {"id": 97, "seek": 58840, "start": 604.4399999999999, "end": 609.4399999999999, "text": " to dive a little deeper into what they actually mean. I think the thing that kind of comes to mind", "tokens": [51166, 281, 9192, 257, 707, 7731, 666, 437, 436, 767, 914, 13, 286, 519, 264, 551, 300, 733, 295, 1487, 281, 1575, 51416], "temperature": 0.0, "avg_logprob": -0.14847763453688578, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.000895119272172451}, {"id": 98, "seek": 58840, "start": 609.4399999999999, "end": 615.4399999999999, "text": " right now, the word professionals and enthusiasts right next to each other, when you come to", "tokens": [51416, 558, 586, 11, 264, 1349, 11954, 293, 45873, 558, 958, 281, 1184, 661, 11, 562, 291, 808, 281, 51716], "temperature": 0.0, "avg_logprob": -0.14847763453688578, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.000895119272172451}, {"id": 99, "seek": 61840, "start": 618.4399999999999, "end": 624.4399999999999, "text": " a certain scale, having a lot of enthusiasts sit alongside professionals comes with some consequences", "tokens": [50366, 257, 1629, 4373, 11, 1419, 257, 688, 295, 45873, 1394, 12385, 11954, 1487, 365, 512, 10098, 50666], "temperature": 0.0, "avg_logprob": -0.11323246655163464, "compression_ratio": 1.6360544217687074, "no_speech_prob": 0.0017811659490689635}, {"id": 100, "seek": 61840, "start": 624.4399999999999, "end": 629.4399999999999, "text": " and balancing these two things is actually pretty challenging from an operation standpoint.", "tokens": [50666, 293, 22495, 613, 732, 721, 307, 767, 1238, 7595, 490, 364, 6916, 15827, 13, 50916], "temperature": 0.0, "avg_logprob": -0.11323246655163464, "compression_ratio": 1.6360544217687074, "no_speech_prob": 0.0017811659490689635}, {"id": 101, "seek": 61840, "start": 629.4399999999999, "end": 634.4399999999999, "text": " But ultimately, we want to be a safe space for the tech industry, for people who want to talk", "tokens": [50916, 583, 6284, 11, 321, 528, 281, 312, 257, 3273, 1901, 337, 264, 7553, 3518, 11, 337, 561, 567, 528, 281, 751, 51166], "temperature": 0.0, "avg_logprob": -0.11323246655163464, "compression_ratio": 1.6360544217687074, "no_speech_prob": 0.0017811659490689635}, {"id": 102, "seek": 61840, "start": 634.4399999999999, "end": 640.4399999999999, "text": " about the economy, open source intelligence, news. We talk a lot about Rust, we talk about Linux.", "tokens": [51166, 466, 264, 5010, 11, 1269, 4009, 7599, 11, 2583, 13, 492, 751, 257, 688, 466, 34952, 11, 321, 751, 466, 18734, 13, 51466], "temperature": 0.0, "avg_logprob": -0.11323246655163464, "compression_ratio": 1.6360544217687074, "no_speech_prob": 0.0017811659490689635}, {"id": 103, "seek": 61840, "start": 640.4399999999999, "end": 646.4399999999999, "text": " Who here was at my talk on Aura yesterday? Awesome, thank you. So a few folks here. So that's a", "tokens": [51466, 2102, 510, 390, 412, 452, 751, 322, 316, 2991, 5186, 30, 10391, 11, 1309, 291, 13, 407, 257, 1326, 4024, 510, 13, 407, 300, 311, 257, 51766], "temperature": 0.0, "avg_logprob": -0.11323246655163464, "compression_ratio": 1.6360544217687074, "no_speech_prob": 0.0017811659490689635}, {"id": 104, "seek": 64644, "start": 646.48, "end": 652.48, "text": " new project that I'm trying to get more people to talk about. We talk about Kubernetes, Go, et cetera,", "tokens": [50366, 777, 1716, 300, 286, 478, 1382, 281, 483, 544, 561, 281, 751, 466, 13, 492, 751, 466, 23145, 11, 1037, 11, 1030, 11458, 11, 50666], "temperature": 0.0, "avg_logprob": -0.12222241719563802, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.01096913032233715}, {"id": 105, "seek": 64644, "start": 652.48, "end": 661.48, "text": " et cetera. So anyway, we're going to spend a little bit of time talking about this blog post that", "tokens": [50666, 1030, 11458, 13, 407, 4033, 11, 321, 434, 516, 281, 3496, 257, 707, 857, 295, 565, 1417, 466, 341, 6968, 2183, 300, 51116], "temperature": 0.0, "avg_logprob": -0.12222241719563802, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.01096913032233715}, {"id": 106, "seek": 64644, "start": 661.48, "end": 669.48, "text": " I wrote called Leaving the Basement. And to set the context a little bit, Hackaderm literally", "tokens": [51116, 286, 4114, 1219, 41253, 264, 5859, 1712, 13, 400, 281, 992, 264, 4319, 257, 707, 857, 11, 35170, 345, 966, 3736, 51516], "temperature": 0.0, "avg_logprob": -0.12222241719563802, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.01096913032233715}, {"id": 107, "seek": 66948, "start": 669.52, "end": 676.52, "text": " started running in my basement. And this is the story of how we kind of ended up moving out of the", "tokens": [50366, 1409, 2614, 294, 452, 16893, 13, 400, 341, 307, 264, 1657, 295, 577, 321, 733, 295, 4590, 493, 2684, 484, 295, 264, 50716], "temperature": 0.0, "avg_logprob": -0.12505709330240886, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.36519724130630493}, {"id": 108, "seek": 66948, "start": 676.52, "end": 682.52, "text": " basement and dealing with some pretty substantial scale problems. I think it was in the middle of", "tokens": [50716, 16893, 293, 6260, 365, 512, 1238, 16726, 4373, 2740, 13, 286, 519, 309, 390, 294, 264, 2808, 295, 51016], "temperature": 0.0, "avg_logprob": -0.12505709330240886, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.36519724130630493}, {"id": 109, "seek": 66948, "start": 682.52, "end": 689.52, "text": " November, we started to, the service started to degrade. And there was a lot of consequences of", "tokens": [51016, 7674, 11, 321, 1409, 281, 11, 264, 2643, 1409, 281, 368, 8692, 13, 400, 456, 390, 257, 688, 295, 10098, 295, 51366], "temperature": 0.0, "avg_logprob": -0.12505709330240886, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.36519724130630493}, {"id": 110, "seek": 66948, "start": 689.52, "end": 697.52, "text": " just shutting the service down. And so people were getting very aggressive on the internet. As it", "tokens": [51366, 445, 36057, 264, 2643, 760, 13, 400, 370, 561, 645, 1242, 588, 10762, 322, 264, 4705, 13, 1018, 309, 51766], "temperature": 0.0, "avg_logprob": -0.12505709330240886, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.36519724130630493}, {"id": 111, "seek": 69752, "start": 697.56, "end": 701.56, "text": " turns out, the internet is full of grown men with opinions. I don't know if any of y'all have noticed", "tokens": [50366, 4523, 484, 11, 264, 4705, 307, 1577, 295, 7709, 1706, 365, 11819, 13, 286, 500, 380, 458, 498, 604, 295, 288, 6, 336, 362, 5694, 50566], "temperature": 0.0, "avg_logprob": -0.0913731311929637, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.007680427748709917}, {"id": 112, "seek": 69752, "start": 701.56, "end": 708.56, "text": " this or not. But yeah, sometimes these grown men with opinions have very toxic opinions, and they", "tokens": [50566, 341, 420, 406, 13, 583, 1338, 11, 2171, 613, 7709, 1706, 365, 11819, 362, 588, 12786, 11819, 11, 293, 436, 50916], "temperature": 0.0, "avg_logprob": -0.0913731311929637, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.007680427748709917}, {"id": 113, "seek": 69752, "start": 708.56, "end": 713.56, "text": " like to say a lot of things about people's services. And so we tried to do our best to keep a", "tokens": [50916, 411, 281, 584, 257, 688, 295, 721, 466, 561, 311, 3328, 13, 400, 370, 321, 3031, 281, 360, 527, 1151, 281, 1066, 257, 51166], "temperature": 0.0, "avg_logprob": -0.0913731311929637, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.007680427748709917}, {"id": 114, "seek": 69752, "start": 713.56, "end": 719.56, "text": " positive attitude and just continue to move forward. So this is the story of what actually", "tokens": [51166, 3353, 10157, 293, 445, 2354, 281, 1286, 2128, 13, 407, 341, 307, 264, 1657, 295, 437, 767, 51466], "temperature": 0.0, "avg_logprob": -0.0913731311929637, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.007680427748709917}, {"id": 115, "seek": 69752, "start": 719.56, "end": 724.56, "text": " happened behind the scenes and how we ended up there. And I think there's some really good", "tokens": [51466, 2011, 2261, 264, 8026, 293, 577, 321, 4590, 493, 456, 13, 400, 286, 519, 456, 311, 512, 534, 665, 51716], "temperature": 0.0, "avg_logprob": -0.0913731311929637, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.007680427748709917}, {"id": 116, "seek": 72456, "start": 724.5999999999999, "end": 733.5999999999999, "text": " takeaways in this from a technical perspective. Okay, so we'll begin our story on November 27th", "tokens": [50366, 45584, 294, 341, 490, 257, 6191, 4585, 13, 1033, 11, 370, 321, 603, 1841, 527, 1657, 322, 7674, 7634, 392, 50816], "temperature": 0.0, "avg_logprob": -0.107660551071167, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.004895765800029039}, {"id": 117, "seek": 72456, "start": 733.5999999999999, "end": 740.5999999999999, "text": " of last year, 2022. And also keep in mind that, you know, this is one month before the holidays. So", "tokens": [50816, 295, 1036, 1064, 11, 20229, 13, 400, 611, 1066, 294, 1575, 300, 11, 291, 458, 11, 341, 307, 472, 1618, 949, 264, 15734, 13, 407, 51166], "temperature": 0.0, "avg_logprob": -0.107660551071167, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.004895765800029039}, {"id": 118, "seek": 72456, "start": 740.5999999999999, "end": 746.5999999999999, "text": " this is about the most burnt out I ever get every year. So usually around the end of November,", "tokens": [51166, 341, 307, 466, 264, 881, 18901, 484, 286, 1562, 483, 633, 1064, 13, 407, 2673, 926, 264, 917, 295, 7674, 11, 51466], "temperature": 0.0, "avg_logprob": -0.107660551071167, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.004895765800029039}, {"id": 119, "seek": 72456, "start": 746.5999999999999, "end": 751.5999999999999, "text": " I'm honestly, I'm about the most I can say to anyone is like fuck off, like I just really need", "tokens": [51466, 286, 478, 6095, 11, 286, 478, 466, 264, 881, 286, 393, 584, 281, 2878, 307, 411, 3275, 766, 11, 411, 286, 445, 534, 643, 51716], "temperature": 0.0, "avg_logprob": -0.107660551071167, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.004895765800029039}, {"id": 120, "seek": 75160, "start": 751.64, "end": 756.64, "text": " some space. And I need a break and I want to go relax and I want to sleep in. And this is when", "tokens": [50366, 512, 1901, 13, 400, 286, 643, 257, 1821, 293, 286, 528, 281, 352, 5789, 293, 286, 528, 281, 2817, 294, 13, 400, 341, 307, 562, 50616], "temperature": 0.0, "avg_logprob": -0.1090811292330424, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.014267663471400738}, {"id": 121, "seek": 75160, "start": 756.64, "end": 762.64, "text": " our new service decided just to completely go down. And this was a really good growing opportunity", "tokens": [50616, 527, 777, 2643, 3047, 445, 281, 2584, 352, 760, 13, 400, 341, 390, 257, 534, 665, 4194, 2650, 50916], "temperature": 0.0, "avg_logprob": -0.1090811292330424, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.014267663471400738}, {"id": 122, "seek": 75160, "start": 762.64, "end": 769.64, "text": " for people. So we have some really interesting numbers here. And I tried to do my best to build a", "tokens": [50916, 337, 561, 13, 407, 321, 362, 512, 534, 1880, 3547, 510, 13, 400, 286, 3031, 281, 360, 452, 1151, 281, 1322, 257, 51266], "temperature": 0.0, "avg_logprob": -0.1090811292330424, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.014267663471400738}, {"id": 123, "seek": 75160, "start": 769.64, "end": 775.64, "text": " graph. And this is like, it looks like a very stereotypical stock graph that's like pointing up", "tokens": [51266, 4295, 13, 400, 341, 307, 411, 11, 309, 1542, 411, 257, 588, 41182, 34061, 4127, 4295, 300, 311, 411, 12166, 493, 51566], "temperature": 0.0, "avg_logprob": -0.1090811292330424, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.014267663471400738}, {"id": 124, "seek": 77564, "start": 775.68, "end": 780.68, "text": " into the right. So I feel like I should just, you know, do like a good, like, hi, guys, we're here", "tokens": [50366, 666, 264, 558, 13, 407, 286, 841, 411, 286, 820, 445, 11, 291, 458, 11, 360, 411, 257, 665, 11, 411, 11, 4879, 11, 1074, 11, 321, 434, 510, 50616], "temperature": 0.0, "avg_logprob": -0.10435468150723365, "compression_ratio": 1.7282229965156795, "no_speech_prob": 0.039610590785741806}, {"id": 125, "seek": 77564, "start": 780.68, "end": 784.68, "text": " to talk about business. And look, our business is going up into the right. And like business numbers", "tokens": [50616, 281, 751, 466, 1606, 13, 400, 574, 11, 527, 1606, 307, 516, 493, 666, 264, 558, 13, 400, 411, 1606, 3547, 50816], "temperature": 0.0, "avg_logprob": -0.10435468150723365, "compression_ratio": 1.7282229965156795, "no_speech_prob": 0.039610590785741806}, {"id": 126, "seek": 77564, "start": 784.68, "end": 789.68, "text": " are important because growth and strategy and impact and business. But honestly, this is just the", "tokens": [50816, 366, 1021, 570, 4599, 293, 5206, 293, 2712, 293, 1606, 13, 583, 6095, 11, 341, 307, 445, 264, 51066], "temperature": 0.0, "avg_logprob": -0.10435468150723365, "compression_ratio": 1.7282229965156795, "no_speech_prob": 0.039610590785741806}, {"id": 127, "seek": 77564, "start": 789.68, "end": 794.68, "text": " amount of people who were leaving Twitter. And really, I think they were just kind of looking for a", "tokens": [51066, 2372, 295, 561, 567, 645, 5012, 5794, 13, 400, 534, 11, 286, 519, 436, 645, 445, 733, 295, 1237, 337, 257, 51316], "temperature": 0.0, "avg_logprob": -0.10435468150723365, "compression_ratio": 1.7282229965156795, "no_speech_prob": 0.039610590785741806}, {"id": 128, "seek": 77564, "start": 794.68, "end": 803.68, "text": " new home. And we just happened to be one that that met their needs for the time being. So up until", "tokens": [51316, 777, 1280, 13, 400, 321, 445, 2011, 281, 312, 472, 300, 300, 1131, 641, 2203, 337, 264, 565, 885, 13, 407, 493, 1826, 51766], "temperature": 0.0, "avg_logprob": -0.10435468150723365, "compression_ratio": 1.7282229965156795, "no_speech_prob": 0.039610590785741806}, {"id": 129, "seek": 80368, "start": 803.7199999999999, "end": 811.7199999999999, "text": " November 1st, we had less than 700 people. The prior six months, the service was online. That's how", "tokens": [50366, 7674, 502, 372, 11, 321, 632, 1570, 813, 15204, 561, 13, 440, 4059, 2309, 2493, 11, 264, 2643, 390, 2950, 13, 663, 311, 577, 50766], "temperature": 0.0, "avg_logprob": -0.09603913189613655, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.0003511607937980443}, {"id": 130, "seek": 80368, "start": 811.7199999999999, "end": 818.7199999999999, "text": " we gained those 700 people. So it was roughly 100 people a month for the first six months. And then", "tokens": [50766, 321, 12634, 729, 15204, 561, 13, 407, 309, 390, 9810, 2319, 561, 257, 1618, 337, 264, 700, 2309, 2493, 13, 400, 550, 51116], "temperature": 0.0, "avg_logprob": -0.09603913189613655, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.0003511607937980443}, {"id": 131, "seek": 80368, "start": 818.7199999999999, "end": 828.7199999999999, "text": " this happened. And this was very unexpected for both myself and everybody in my immediate circle. So", "tokens": [51116, 341, 2011, 13, 400, 341, 390, 588, 13106, 337, 1293, 2059, 293, 2201, 294, 452, 11629, 6329, 13, 407, 51616], "temperature": 0.0, "avg_logprob": -0.09603913189613655, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.0003511607937980443}, {"id": 132, "seek": 82872, "start": 828.76, "end": 834.76, "text": " one of the things I talk about as a professional SRE. So let me back up. When I'm not keeping the", "tokens": [50366, 472, 295, 264, 721, 286, 751, 466, 382, 257, 4843, 318, 3850, 13, 407, 718, 385, 646, 493, 13, 1133, 286, 478, 406, 5145, 264, 50666], "temperature": 0.0, "avg_logprob": -0.12923356152455742, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.0049768113531172276}, {"id": 133, "seek": 82872, "start": 834.76, "end": 840.76, "text": " masted on Ruby monoliths online, my other job is keeping the GitHub Ruby monoliths online. So", "tokens": [50666, 27055, 292, 322, 19907, 1108, 29131, 82, 2950, 11, 452, 661, 1691, 307, 5145, 264, 23331, 19907, 1108, 29131, 82, 2950, 13, 407, 50966], "temperature": 0.0, "avg_logprob": -0.12923356152455742, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.0049768113531172276}, {"id": 134, "seek": 82872, "start": 840.76, "end": 846.76, "text": " some of you use GitHub. Some of you use Hackaderm. I work on both of them. And I have two different", "tokens": [50966, 512, 295, 291, 764, 23331, 13, 2188, 295, 291, 764, 35170, 345, 966, 13, 286, 589, 322, 1293, 295, 552, 13, 400, 286, 362, 732, 819, 51266], "temperature": 0.0, "avg_logprob": -0.12923356152455742, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.0049768113531172276}, {"id": 135, "seek": 82872, "start": 846.76, "end": 852.76, "text": " UB keys here in my backpack, one for each service. And so anyway, one of the things I often say is", "tokens": [51266, 624, 33, 9317, 510, 294, 452, 17969, 11, 472, 337, 1184, 2643, 13, 400, 370, 4033, 11, 472, 295, 264, 721, 286, 2049, 584, 307, 51566], "temperature": 0.0, "avg_logprob": -0.12923356152455742, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.0049768113531172276}, {"id": 136, "seek": 85276, "start": 852.8, "end": 857.8, "text": " when I enter a conversation with someone, this is the most important thing. And I honestly want to", "tokens": [50366, 562, 286, 3242, 257, 3761, 365, 1580, 11, 341, 307, 264, 881, 1021, 551, 13, 400, 286, 6095, 528, 281, 50616], "temperature": 0.0, "avg_logprob": -0.11263461585517402, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.07040216028690338}, {"id": 137, "seek": 85276, "start": 857.8, "end": 862.8, "text": " get this as like my next tattoo because I say this at least once a week, which is what is the current", "tokens": [50616, 483, 341, 382, 411, 452, 958, 15080, 570, 286, 584, 341, 412, 1935, 1564, 257, 1243, 11, 597, 307, 437, 307, 264, 2190, 50866], "temperature": 0.0, "avg_logprob": -0.11263461585517402, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.07040216028690338}, {"id": 138, "seek": 85276, "start": 862.8, "end": 867.8, "text": " state of the systems? And if you can't answer this question very confidently at any given moment,", "tokens": [50866, 1785, 295, 264, 3652, 30, 400, 498, 291, 393, 380, 1867, 341, 1168, 588, 41956, 412, 604, 2212, 1623, 11, 51116], "temperature": 0.0, "avg_logprob": -0.11263461585517402, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.07040216028690338}, {"id": 139, "seek": 85276, "start": 867.8, "end": 872.8, "text": " especially in a crisis, we should be having other conversations at that point because this is the", "tokens": [51116, 2318, 294, 257, 5869, 11, 321, 820, 312, 1419, 661, 7315, 412, 300, 935, 570, 341, 307, 264, 51366], "temperature": 0.0, "avg_logprob": -0.11263461585517402, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.07040216028690338}, {"id": 140, "seek": 85276, "start": 872.8, "end": 878.8, "text": " starting point of every conversation in my opinion. So we'll start our service off our service", "tokens": [51366, 2891, 935, 295, 633, 3761, 294, 452, 4800, 13, 407, 321, 603, 722, 527, 2643, 766, 527, 2643, 51666], "temperature": 0.0, "avg_logprob": -0.11263461585517402, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.07040216028690338}, {"id": 141, "seek": 87880, "start": 878.8399999999999, "end": 885.8399999999999, "text": " discussion off here. So we had a rack of hardware in my basement. And these are the specs that we had", "tokens": [50366, 5017, 766, 510, 13, 407, 321, 632, 257, 14788, 295, 8837, 294, 452, 16893, 13, 400, 613, 366, 264, 27911, 300, 321, 632, 50716], "temperature": 0.0, "avg_logprob": -0.12565200805664062, "compression_ratio": 1.566137566137566, "no_speech_prob": 0.0007430867990478873}, {"id": 142, "seek": 87880, "start": 889.8399999999999, "end": 895.8399999999999, "text": " running in the basement. So it was a hobby rack that I've collected over the past 10 years or so,", "tokens": [50916, 2614, 294, 264, 16893, 13, 407, 309, 390, 257, 18240, 14788, 300, 286, 600, 11087, 670, 264, 1791, 1266, 924, 420, 370, 11, 51216], "temperature": 0.0, "avg_logprob": -0.12565200805664062, "compression_ratio": 1.566137566137566, "no_speech_prob": 0.0007430867990478873}, {"id": 143, "seek": 87880, "start": 895.8399999999999, "end": 902.8399999999999, "text": " you know, pieces of hardware that have been donated to me or that I found for a cheap price that", "tokens": [51216, 291, 458, 11, 3755, 295, 8837, 300, 362, 668, 23723, 281, 385, 420, 300, 286, 1352, 337, 257, 7084, 3218, 300, 51566], "temperature": 0.0, "avg_logprob": -0.12565200805664062, "compression_ratio": 1.566137566137566, "no_speech_prob": 0.0007430867990478873}, {"id": 144, "seek": 90284, "start": 902.88, "end": 908.88, "text": " were used. In fact, the star of the show, Alice, over here on the far left, I've literally carried her", "tokens": [50366, 645, 1143, 13, 682, 1186, 11, 264, 3543, 295, 264, 855, 11, 16004, 11, 670, 510, 322, 264, 1400, 1411, 11, 286, 600, 3736, 9094, 720, 50666], "temperature": 0.0, "avg_logprob": -0.13904525683476374, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.035096071660518646}, {"id": 145, "seek": 90284, "start": 908.88, "end": 915.88, "text": " across Market Street in San Francisco and dropped her in a pile of like pee on the side of the road.", "tokens": [50666, 2108, 15596, 7638, 294, 5271, 12279, 293, 8119, 720, 294, 257, 14375, 295, 411, 21343, 322, 264, 1252, 295, 264, 3060, 13, 51016], "temperature": 0.0, "avg_logprob": -0.13904525683476374, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.035096071660518646}, {"id": 146, "seek": 90284, "start": 915.88, "end": 920.88, "text": " The hardware has been through a lot to say the least, but it's what we had and this is what I was", "tokens": [51016, 440, 8837, 575, 668, 807, 257, 688, 281, 584, 264, 1935, 11, 457, 309, 311, 437, 321, 632, 293, 341, 307, 437, 286, 390, 51266], "temperature": 0.0, "avg_logprob": -0.13904525683476374, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.035096071660518646}, {"id": 147, "seek": 90284, "start": 920.88, "end": 926.88, "text": " using for kind of a home lab at the time. I think the important thing here to notice though is that", "tokens": [51266, 1228, 337, 733, 295, 257, 1280, 2715, 412, 264, 565, 13, 286, 519, 264, 1021, 551, 510, 281, 3449, 1673, 307, 300, 51566], "temperature": 0.0, "avg_logprob": -0.13904525683476374, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.035096071660518646}, {"id": 148, "seek": 92688, "start": 926.92, "end": 932.92, "text": " these are not trivial computers. These are proper rack mounted servers with proper specs and most,", "tokens": [50366, 613, 366, 406, 26703, 10807, 13, 1981, 366, 2296, 14788, 19138, 15909, 365, 2296, 27911, 293, 881, 11, 50666], "temperature": 0.0, "avg_logprob": -0.17477007473216338, "compression_ratio": 1.5697211155378485, "no_speech_prob": 0.1223376989364624}, {"id": 149, "seek": 92688, "start": 932.92, "end": 938.92, "text": " for the most part, these worked fine. It got the name the water tower because we had Alice, who was", "tokens": [50666, 337, 264, 881, 644, 11, 613, 2732, 2489, 13, 467, 658, 264, 1315, 264, 1281, 10567, 570, 321, 632, 16004, 11, 567, 390, 50966], "temperature": 0.0, "avg_logprob": -0.17477007473216338, "compression_ratio": 1.5697211155378485, "no_speech_prob": 0.1223376989364624}, {"id": 150, "seek": 92688, "start": 938.92, "end": 944.92, "text": " our main compute node, and then we had three identical Dell PowerEdge R620s named Yacko, Wacko,", "tokens": [50966, 527, 2135, 14722, 9984, 11, 293, 550, 321, 632, 1045, 14800, 33319, 7086, 27061, 432, 497, 21, 2009, 82, 4926, 398, 501, 78, 11, 343, 501, 78, 11, 51266], "temperature": 0.0, "avg_logprob": -0.17477007473216338, "compression_ratio": 1.5697211155378485, "no_speech_prob": 0.1223376989364624}, {"id": 151, "seek": 92688, "start": 944.92, "end": 950.92, "text": " and Dot, respectively, and all three of them seemed to just be up to shenanigans at any given point", "tokens": [51266, 293, 38753, 11, 25009, 11, 293, 439, 1045, 295, 552, 6576, 281, 445, 312, 493, 281, 402, 45008, 49088, 412, 604, 2212, 935, 51566], "temperature": 0.0, "avg_logprob": -0.17477007473216338, "compression_ratio": 1.5697211155378485, "no_speech_prob": 0.1223376989364624}, {"id": 152, "seek": 95092, "start": 950.9599999999999, "end": 957.9599999999999, "text": " in time, from memory failure to broken boot loaders to just bizarre networking behavior and having", "tokens": [50366, 294, 565, 11, 490, 4675, 7763, 281, 5463, 11450, 3677, 433, 281, 445, 18265, 17985, 5223, 293, 1419, 50716], "temperature": 0.0, "avg_logprob": -0.12591144886422664, "compression_ratio": 1.564, "no_speech_prob": 0.015642406418919563}, {"id": 153, "seek": 95092, "start": 957.9599999999999, "end": 962.9599999999999, "text": " to go flip out Nix to try to get a better network connection. There was just a lot of obscure things", "tokens": [50716, 281, 352, 7929, 484, 426, 970, 281, 853, 281, 483, 257, 1101, 3209, 4984, 13, 821, 390, 445, 257, 688, 295, 34443, 721, 50966], "temperature": 0.0, "avg_logprob": -0.12591144886422664, "compression_ratio": 1.564, "no_speech_prob": 0.015642406418919563}, {"id": 154, "seek": 95092, "start": 962.9599999999999, "end": 971.9599999999999, "text": " that was happening at the hardware level. So, Meet Alice. She's a very infamous server, especially", "tokens": [50966, 300, 390, 2737, 412, 264, 8837, 1496, 13, 407, 11, 22963, 16004, 13, 1240, 311, 257, 588, 30769, 7154, 11, 2318, 51416], "temperature": 0.0, "avg_logprob": -0.12591144886422664, "compression_ratio": 1.564, "no_speech_prob": 0.015642406418919563}, {"id": 155, "seek": 95092, "start": 971.9599999999999, "end": 977.9599999999999, "text": " if you've read any of our posts or if you've ever watched my Twitch stream, but there she is", "tokens": [51416, 498, 291, 600, 1401, 604, 295, 527, 12300, 420, 498, 291, 600, 1562, 6337, 452, 22222, 4309, 11, 457, 456, 750, 307, 51716], "temperature": 0.0, "avg_logprob": -0.12591144886422664, "compression_ratio": 1.564, "no_speech_prob": 0.015642406418919563}, {"id": 156, "seek": 97796, "start": 978.0, "end": 984.0, "text": " there, and that's in my basement, and that's the Dell R630, and you can see she's got eight SSDs", "tokens": [50366, 456, 11, 293, 300, 311, 294, 452, 16893, 11, 293, 300, 311, 264, 33319, 497, 21, 3446, 11, 293, 291, 393, 536, 750, 311, 658, 3180, 30262, 82, 50666], "temperature": 0.0, "avg_logprob": -0.09442532792383311, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.003819272154942155}, {"id": 157, "seek": 97796, "start": 984.0, "end": 992.0, "text": " in the front of the carriage there, and she was sitting behind a firewall of my own design,", "tokens": [50666, 294, 264, 1868, 295, 264, 31811, 456, 11, 293, 750, 390, 3798, 2261, 257, 36109, 295, 452, 1065, 1715, 11, 51066], "temperature": 0.0, "avg_logprob": -0.09442532792383311, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.003819272154942155}, {"id": 158, "seek": 97796, "start": 992.0, "end": 999.0, "text": " and that was our main endpoint for pretty much everything I ran in my home lab, and that just", "tokens": [51066, 293, 300, 390, 527, 2135, 35795, 337, 1238, 709, 1203, 286, 5872, 294, 452, 1280, 2715, 11, 293, 300, 445, 51416], "temperature": 0.0, "avg_logprob": -0.09442532792383311, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.003819272154942155}, {"id": 159, "seek": 97796, "start": 999.0, "end": 1005.0, "text": " so happened to be the main endpoint for our mastodon service up until the month of November.", "tokens": [51416, 370, 2011, 281, 312, 264, 2135, 35795, 337, 527, 27055, 378, 266, 2643, 493, 1826, 264, 1618, 295, 7674, 13, 51716], "temperature": 0.0, "avg_logprob": -0.09442532792383311, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.003819272154942155}, {"id": 160, "seek": 100500, "start": 1005.04, "end": 1015.04, "text": " So, yes, it was a home lab, and I think the whole point of this is that we used it for a lot of", "tokens": [50366, 407, 11, 2086, 11, 309, 390, 257, 1280, 2715, 11, 293, 286, 519, 264, 1379, 935, 295, 341, 307, 300, 321, 1143, 309, 337, 257, 688, 295, 50866], "temperature": 0.0, "avg_logprob": -0.11202477216720581, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.000645742635242641}, {"id": 161, "seek": 100500, "start": 1015.04, "end": 1022.04, "text": " things, and so the mastodon service was running on the home lab, and I do a lot of really bizarre", "tokens": [50866, 721, 11, 293, 370, 264, 27055, 378, 266, 2643, 390, 2614, 322, 264, 1280, 2715, 11, 293, 286, 360, 257, 688, 295, 534, 18265, 51216], "temperature": 0.0, "avg_logprob": -0.11202477216720581, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.000645742635242641}, {"id": 162, "seek": 100500, "start": 1022.04, "end": 1028.04, "text": " things on Twitch, so if you follow me on Twitch, you probably have seen me work on kernel modules", "tokens": [51216, 721, 322, 22222, 11, 370, 498, 291, 1524, 385, 322, 22222, 11, 291, 1391, 362, 1612, 385, 589, 322, 28256, 16679, 51516], "temperature": 0.0, "avg_logprob": -0.11202477216720581, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.000645742635242641}, {"id": 163, "seek": 102804, "start": 1028.08, "end": 1034.08, "text": " and experimental EBPF probes, and I've experimented with adding some features to the ZFS file", "tokens": [50366, 293, 17069, 50148, 47, 37, 1239, 279, 11, 293, 286, 600, 5120, 292, 365, 5127, 512, 4122, 281, 264, 1176, 29318, 3991, 50666], "temperature": 0.0, "avg_logprob": -0.09501360902691831, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.023306284099817276}, {"id": 164, "seek": 102804, "start": 1034.08, "end": 1041.08, "text": " system and compiling my own version of ZFS from scratch, and I've been doing a lot, and I also", "tokens": [50666, 1185, 293, 715, 4883, 452, 1065, 3037, 295, 1176, 29318, 490, 8459, 11, 293, 286, 600, 668, 884, 257, 688, 11, 293, 286, 611, 51016], "temperature": 0.0, "avg_logprob": -0.09501360902691831, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.023306284099817276}, {"id": 165, "seek": 102804, "start": 1041.08, "end": 1048.08, "text": " installed mastodon on that same server, and that's the key part of this. So, here's a list of", "tokens": [51016, 8899, 27055, 378, 266, 322, 300, 912, 7154, 11, 293, 300, 311, 264, 2141, 644, 295, 341, 13, 407, 11, 510, 311, 257, 1329, 295, 51366], "temperature": 0.0, "avg_logprob": -0.09501360902691831, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.023306284099817276}, {"id": 166, "seek": 102804, "start": 1048.08, "end": 1054.08, "text": " things from my home lab that have not blown up. There has not been a billionaire who decided to", "tokens": [51366, 721, 490, 452, 1280, 2715, 300, 362, 406, 16479, 493, 13, 821, 575, 406, 668, 257, 42358, 567, 3047, 281, 51666], "temperature": 0.0, "avg_logprob": -0.09501360902691831, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.023306284099817276}, {"id": 167, "seek": 105408, "start": 1054.12, "end": 1060.12, "text": " buy a company that decided to insult the broader technical community and encourage them to move", "tokens": [50366, 2256, 257, 2237, 300, 3047, 281, 15285, 264, 13227, 6191, 1768, 293, 5373, 552, 281, 1286, 50666], "temperature": 0.0, "avg_logprob": -0.08211618661880493, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.0036419592797756195}, {"id": 168, "seek": 105408, "start": 1060.12, "end": 1065.12, "text": " off to a decentralized service, and so you've probably never heard of any of these, and that all", "tokens": [50666, 766, 281, 257, 32870, 2643, 11, 293, 370, 291, 600, 1391, 1128, 2198, 295, 604, 295, 613, 11, 293, 300, 439, 50916], "temperature": 0.0, "avg_logprob": -0.08211618661880493, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.0036419592797756195}, {"id": 169, "seek": 105408, "start": 1065.12, "end": 1071.12, "text": " of these also run in that same home lab, so I think it's important to realize that this was a", "tokens": [50916, 295, 613, 611, 1190, 294, 300, 912, 1280, 2715, 11, 370, 286, 519, 309, 311, 1021, 281, 4325, 300, 341, 390, 257, 51216], "temperature": 0.0, "avg_logprob": -0.08211618661880493, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.0036419592797756195}, {"id": 170, "seek": 105408, "start": 1071.12, "end": 1078.12, "text": " very unexpected event, and that these servers were in a pretty high state of entropy, and we", "tokens": [51216, 588, 13106, 2280, 11, 293, 300, 613, 15909, 645, 294, 257, 1238, 1090, 1785, 295, 30867, 11, 293, 321, 51566], "temperature": 0.0, "avg_logprob": -0.08211618661880493, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.0036419592797756195}, {"id": 171, "seek": 107812, "start": 1078.1599999999999, "end": 1085.1599999999999, "text": " didn't really have a good idea of the state of the systems. This was a home lab. So, as it turns out,", "tokens": [50366, 994, 380, 534, 362, 257, 665, 1558, 295, 264, 1785, 295, 264, 3652, 13, 639, 390, 257, 1280, 2715, 13, 407, 11, 382, 309, 4523, 484, 11, 50716], "temperature": 0.0, "avg_logprob": -0.14120233535766602, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.0033217978198081255}, {"id": 172, "seek": 107812, "start": 1085.1599999999999, "end": 1092.1599999999999, "text": " 50,000 people trust me and really dislike a certain billionaire, and this was the one thing I", "tokens": [50716, 2625, 11, 1360, 561, 3361, 385, 293, 534, 26006, 257, 1629, 42358, 11, 293, 341, 390, 264, 472, 551, 286, 51066], "temperature": 0.0, "avg_logprob": -0.14120233535766602, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.0033217978198081255}, {"id": 173, "seek": 107812, "start": 1092.1599999999999, "end": 1099.1599999999999, "text": " kept hearing. We kept having large to medium size and smaller size name people with substantial", "tokens": [51066, 4305, 4763, 13, 492, 4305, 1419, 2416, 281, 6399, 2744, 293, 4356, 2744, 1315, 561, 365, 16726, 51416], "temperature": 0.0, "avg_logprob": -0.14120233535766602, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.0033217978198081255}, {"id": 174, "seek": 107812, "start": 1099.1599999999999, "end": 1104.1599999999999, "text": " Twitter following, like shoot us an e-mail and be like, yo, Nova, I'm done with Twitter, we're", "tokens": [51416, 5794, 3480, 11, 411, 3076, 505, 364, 308, 12, 11799, 293, 312, 411, 11, 5290, 11, 27031, 11, 286, 478, 1096, 365, 5794, 11, 321, 434, 51666], "temperature": 0.0, "avg_logprob": -0.14120233535766602, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.0033217978198081255}, {"id": 175, "seek": 110416, "start": 1104.2, "end": 1108.2, "text": " going to come to your mastodon server, and I'm like, okay, sounds cool, and then they have, you", "tokens": [50366, 516, 281, 808, 281, 428, 27055, 378, 266, 7154, 11, 293, 286, 478, 411, 11, 1392, 11, 3263, 1627, 11, 293, 550, 436, 362, 11, 291, 50566], "temperature": 0.0, "avg_logprob": -0.10098173104080499, "compression_ratio": 1.867986798679868, "no_speech_prob": 0.054145872592926025}, {"id": 176, "seek": 110416, "start": 1108.2, "end": 1114.2, "text": " know, 350,000 Twitter followers, and it's not about the followers, but from an operator's", "tokens": [50566, 458, 11, 18065, 11, 1360, 5794, 13071, 11, 293, 309, 311, 406, 466, 264, 13071, 11, 457, 490, 364, 12973, 311, 50866], "temperature": 0.0, "avg_logprob": -0.10098173104080499, "compression_ratio": 1.867986798679868, "no_speech_prob": 0.054145872592926025}, {"id": 177, "seek": 110416, "start": 1114.2, "end": 1119.2, "text": " perspective, I'm like, holy shit, that's a lot of traffic. That's a lot of people that we're", "tokens": [50866, 4585, 11, 286, 478, 411, 11, 10622, 4611, 11, 300, 311, 257, 688, 295, 6419, 13, 663, 311, 257, 688, 295, 561, 300, 321, 434, 51116], "temperature": 0.0, "avg_logprob": -0.10098173104080499, "compression_ratio": 1.867986798679868, "no_speech_prob": 0.054145872592926025}, {"id": 178, "seek": 110416, "start": 1119.2, "end": 1123.2, "text": " going to have to open up web sockets against, and there's a lot to deal with there if you're", "tokens": [51116, 516, 281, 362, 281, 1269, 493, 3670, 370, 11984, 1970, 11, 293, 456, 311, 257, 688, 281, 2028, 365, 456, 498, 291, 434, 51316], "temperature": 0.0, "avg_logprob": -0.10098173104080499, "compression_ratio": 1.867986798679868, "no_speech_prob": 0.054145872592926025}, {"id": 179, "seek": 110416, "start": 1123.2, "end": 1127.2, "text": " going to be sending all of these messages out to all of these people who are going to be following", "tokens": [51316, 516, 281, 312, 7750, 439, 295, 613, 7897, 484, 281, 439, 295, 613, 561, 567, 366, 516, 281, 312, 3480, 51516], "temperature": 0.0, "avg_logprob": -0.10098173104080499, "compression_ratio": 1.867986798679868, "no_speech_prob": 0.054145872592926025}, {"id": 180, "seek": 110416, "start": 1127.2, "end": 1131.2, "text": " you, and they all continue to say the one thing, which is like, well, we trust you to not screw", "tokens": [51516, 291, 11, 293, 436, 439, 2354, 281, 584, 264, 472, 551, 11, 597, 307, 411, 11, 731, 11, 321, 3361, 291, 281, 406, 5630, 51716], "temperature": 0.0, "avg_logprob": -0.10098173104080499, "compression_ratio": 1.867986798679868, "no_speech_prob": 0.054145872592926025}, {"id": 181, "seek": 113120, "start": 1131.24, "end": 1135.24, "text": " this up, and like, you know, you can probably do better than he can, so we're just going to move", "tokens": [50366, 341, 493, 11, 293, 411, 11, 291, 458, 11, 291, 393, 1391, 360, 1101, 813, 415, 393, 11, 370, 321, 434, 445, 516, 281, 1286, 50566], "temperature": 0.0, "avg_logprob": -0.1145114307255708, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00781289953738451}, {"id": 182, "seek": 113120, "start": 1135.24, "end": 1143.24, "text": " over to your server anyway. Okay, so what had ended up happening is, it's a long story, and how we", "tokens": [50566, 670, 281, 428, 7154, 4033, 13, 1033, 11, 370, 437, 632, 4590, 493, 2737, 307, 11, 309, 311, 257, 938, 1657, 11, 293, 577, 321, 50966], "temperature": 0.0, "avg_logprob": -0.1145114307255708, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00781289953738451}, {"id": 183, "seek": 113120, "start": 1143.24, "end": 1148.24, "text": " ended up finding it, I think ultimately took about three weeks, but we don't say root cause", "tokens": [50966, 4590, 493, 5006, 309, 11, 286, 519, 6284, 1890, 466, 1045, 3259, 11, 457, 321, 500, 380, 584, 5593, 3082, 51216], "temperature": 0.0, "avg_logprob": -0.1145114307255708, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00781289953738451}, {"id": 184, "seek": 113120, "start": 1148.24, "end": 1153.24, "text": " anymore, we say core cause, and the core cause of the incident is ultimately we had a bad disk", "tokens": [51216, 3602, 11, 321, 584, 4965, 3082, 11, 293, 264, 4965, 3082, 295, 264, 9348, 307, 6284, 321, 632, 257, 1578, 12355, 51466], "temperature": 0.0, "avg_logprob": -0.1145114307255708, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00781289953738451}, {"id": 185, "seek": 113120, "start": 1153.24, "end": 1159.24, "text": " on Alice. I don't know why the disk was bad, this really bothers me, so I'm just going to chop it", "tokens": [51466, 322, 16004, 13, 286, 500, 380, 458, 983, 264, 12355, 390, 1578, 11, 341, 534, 33980, 385, 11, 370, 286, 478, 445, 516, 281, 7931, 309, 51766], "temperature": 0.0, "avg_logprob": -0.1145114307255708, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00781289953738451}, {"id": 186, "seek": 115924, "start": 1159.28, "end": 1164.28, "text": " up to like, it was just like a bad one in the batch, but we were able to actually isolate it", "tokens": [50366, 493, 281, 411, 11, 309, 390, 445, 411, 257, 1578, 472, 294, 264, 15245, 11, 457, 321, 645, 1075, 281, 767, 25660, 309, 50616], "temperature": 0.0, "avg_logprob": -0.13226448592319284, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.008839881978929043}, {"id": 187, "seek": 115924, "start": 1164.28, "end": 1171.28, "text": " after the fact, and determine that like a basic reader write to this SSD was in fact the problem.", "tokens": [50616, 934, 264, 1186, 11, 293, 6997, 300, 411, 257, 3875, 15149, 2464, 281, 341, 30262, 390, 294, 1186, 264, 1154, 13, 50966], "temperature": 0.0, "avg_logprob": -0.13226448592319284, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.008839881978929043}, {"id": 188, "seek": 115924, "start": 1171.28, "end": 1178.28, "text": " I also think an interesting takeaway here is that these were not consumer SSDs, these were", "tokens": [50966, 286, 611, 519, 364, 1880, 30681, 510, 307, 300, 613, 645, 406, 9711, 30262, 82, 11, 613, 645, 51316], "temperature": 0.0, "avg_logprob": -0.13226448592319284, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.008839881978929043}, {"id": 189, "seek": 115924, "start": 1178.28, "end": 1185.28, "text": " actual proper enterprise SSDs, one of which either just decided to get slow IO, or I don't", "tokens": [51316, 3539, 2296, 14132, 30262, 82, 11, 472, 295, 597, 2139, 445, 3047, 281, 483, 2964, 39839, 11, 420, 286, 500, 380, 51666], "temperature": 0.0, "avg_logprob": -0.13226448592319284, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.008839881978929043}, {"id": 190, "seek": 118528, "start": 1185.32, "end": 1191.32, "text": " know what happened to it, but even in an isolation zone writing directly to an EXT4 system, we were", "tokens": [50366, 458, 437, 2011, 281, 309, 11, 457, 754, 294, 364, 16001, 6668, 3579, 3838, 281, 364, 16385, 51, 19, 1185, 11, 321, 645, 50666], "temperature": 0.0, "avg_logprob": -0.12164254439504522, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0011333002476021647}, {"id": 191, "seek": 118528, "start": 1191.32, "end": 1196.32, "text": " still able to prove that this disk was substantially slower than another one of the same make and", "tokens": [50666, 920, 1075, 281, 7081, 300, 341, 12355, 390, 30797, 14009, 813, 1071, 472, 295, 264, 912, 652, 293, 50916], "temperature": 0.0, "avg_logprob": -0.12164254439504522, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0011333002476021647}, {"id": 192, "seek": 118528, "start": 1196.32, "end": 1203.32, "text": " model. So it wasn't always bad, and it started to go bad, and this ultimately led to a cascading", "tokens": [50916, 2316, 13, 407, 309, 2067, 380, 1009, 1578, 11, 293, 309, 1409, 281, 352, 1578, 11, 293, 341, 6284, 4684, 281, 257, 3058, 66, 8166, 51266], "temperature": 0.0, "avg_logprob": -0.12164254439504522, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0011333002476021647}, {"id": 193, "seek": 118528, "start": 1203.32, "end": 1210.32, "text": " failure across our CDN and our geographic edge nodes, and so the interesting thing, and this", "tokens": [51266, 7763, 2108, 527, 6743, 45, 293, 527, 32318, 4691, 13891, 11, 293, 370, 264, 1880, 551, 11, 293, 341, 51616], "temperature": 0.0, "avg_logprob": -0.12164254439504522, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0011333002476021647}, {"id": 194, "seek": 121032, "start": 1210.36, "end": 1216.36, "text": " is just one of those things, this is the aforementioned bad disk, and it also for some reason", "tokens": [50366, 307, 445, 472, 295, 729, 721, 11, 341, 307, 264, 48927, 46842, 1578, 12355, 11, 293, 309, 611, 337, 512, 1778, 50666], "temperature": 0.0, "avg_logprob": -0.1080804018630195, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.003882594173774123}, {"id": 195, "seek": 121032, "start": 1216.36, "end": 1223.36, "text": " has a broken chassis in the front, so part of me kind of has to wonder, did the movers drop", "tokens": [50666, 575, 257, 5463, 28262, 294, 264, 1868, 11, 370, 644, 295, 385, 733, 295, 575, 281, 2441, 11, 630, 264, 705, 840, 3270, 51016], "temperature": 0.0, "avg_logprob": -0.1080804018630195, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.003882594173774123}, {"id": 196, "seek": 121032, "start": 1223.36, "end": 1228.36, "text": " the server, or did something happen? I'm not really totally sure, but these are the woes of", "tokens": [51016, 264, 7154, 11, 420, 630, 746, 1051, 30, 286, 478, 406, 534, 3879, 988, 11, 457, 613, 366, 264, 6020, 279, 295, 51266], "temperature": 0.0, "avg_logprob": -0.1080804018630195, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.003882594173774123}, {"id": 197, "seek": 121032, "start": 1228.36, "end": 1236.36, "text": " operating your own hardware in your basement. So here's a model of the cascading failure. Who", "tokens": [51266, 7447, 428, 1065, 8837, 294, 428, 16893, 13, 407, 510, 311, 257, 2316, 295, 264, 3058, 66, 8166, 7763, 13, 2102, 51666], "temperature": 0.0, "avg_logprob": -0.1080804018630195, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.003882594173774123}, {"id": 198, "seek": 123636, "start": 1236.3999999999999, "end": 1242.3999999999999, "text": " here has dealt with cascading failures in production before? Okay, so 15 or 20, 30 hands", "tokens": [50366, 510, 575, 15991, 365, 3058, 66, 8166, 20774, 294, 4265, 949, 30, 1033, 11, 370, 2119, 420, 945, 11, 2217, 2377, 50666], "temperature": 0.0, "avg_logprob": -0.15730218777711363, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.004066819325089455}, {"id": 199, "seek": 123636, "start": 1242.3999999999999, "end": 1249.3999999999999, "text": " or so. These are fascinating, how you get into these situations, and usually when you're", "tokens": [50666, 420, 370, 13, 1981, 366, 10343, 11, 577, 291, 483, 666, 613, 6851, 11, 293, 2673, 562, 291, 434, 51016], "temperature": 0.0, "avg_logprob": -0.15730218777711363, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.004066819325089455}, {"id": 200, "seek": 123636, "start": 1250.6399999999999, "end": 1255.6399999999999, "text": " dealing with one of these cascading failures, you're not really starting at the database,", "tokens": [51078, 6260, 365, 472, 295, 613, 3058, 66, 8166, 20774, 11, 291, 434, 406, 534, 2891, 412, 264, 8149, 11, 51328], "temperature": 0.0, "avg_logprob": -0.15730218777711363, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.004066819325089455}, {"id": 201, "seek": 123636, "start": 1255.6399999999999, "end": 1260.6399999999999, "text": " or at least you glance at the database and you think maybe something's wrong, and you", "tokens": [51328, 420, 412, 1935, 291, 21094, 412, 264, 8149, 293, 291, 519, 1310, 746, 311, 2085, 11, 293, 291, 51578], "temperature": 0.0, "avg_logprob": -0.15730218777711363, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.004066819325089455}, {"id": 202, "seek": 126064, "start": 1260.76, "end": 1267.76, "text": " usually blame DNS, but in our case, we were working back from our CDN. So imagine you", "tokens": [50370, 2673, 10127, 35153, 11, 457, 294, 527, 1389, 11, 321, 645, 1364, 646, 490, 527, 6743, 45, 13, 407, 3811, 291, 50720], "temperature": 0.0, "avg_logprob": -0.12365691661834717, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.003270744811743498}, {"id": 203, "seek": 126064, "start": 1268.24, "end": 1272.68, "text": " are operating a mastodon server in your basement, and 50,000 people on the internet decide to", "tokens": [50744, 366, 7447, 257, 27055, 378, 266, 7154, 294, 428, 16893, 11, 293, 2625, 11, 1360, 561, 322, 264, 4705, 4536, 281, 50966], "temperature": 0.0, "avg_logprob": -0.12365691661834717, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.003270744811743498}, {"id": 204, "seek": 126064, "start": 1272.68, "end": 1276.1200000000001, "text": " join, and all of a sudden you can't even join a zoom call the next morning, because your", "tokens": [50966, 3917, 11, 293, 439, 295, 257, 3990, 291, 393, 380, 754, 3917, 257, 8863, 818, 264, 958, 2446, 11, 570, 428, 51138], "temperature": 0.0, "avg_logprob": -0.12365691661834717, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.003270744811743498}, {"id": 205, "seek": 126064, "start": 1276.1200000000001, "end": 1281.5600000000002, "text": " internet pipeline is so throttled from your ISP, who's like, bro, why are you bringing", "tokens": [51138, 4705, 15517, 307, 370, 739, 1521, 1493, 490, 428, 6205, 47, 11, 567, 311, 411, 11, 2006, 11, 983, 366, 291, 5062, 51410], "temperature": 0.0, "avg_logprob": -0.12365691661834717, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.003270744811743498}, {"id": 206, "seek": 126064, "start": 1281.5600000000002, "end": 1286.6000000000001, "text": " this much traffic to your house? I don't understand what's going on, this is very bizarre. So what", "tokens": [51410, 341, 709, 6419, 281, 428, 1782, 30, 286, 500, 380, 1223, 437, 311, 516, 322, 11, 341, 307, 588, 18265, 13, 407, 437, 51662], "temperature": 0.0, "avg_logprob": -0.12365691661834717, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.003270744811743498}, {"id": 207, "seek": 128660, "start": 1286.6799999999998, "end": 1293.1799999999998, "text": " we did is the very first thing we did to offset the problem was we set up these CDN nodes", "tokens": [50368, 321, 630, 307, 264, 588, 700, 551, 321, 630, 281, 18687, 264, 1154, 390, 321, 992, 493, 613, 6743, 45, 13891, 50693], "temperature": 0.0, "avg_logprob": -0.18155445522732205, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.0017811397556215525}, {"id": 208, "seek": 128660, "start": 1293.1799999999998, "end": 1298.7199999999998, "text": " around the world, and these basically served as reverse engine X proxies that had media", "tokens": [50693, 926, 264, 1002, 11, 293, 613, 1936, 7584, 382, 9943, 2848, 1783, 447, 87, 530, 300, 632, 3021, 50970], "temperature": 0.0, "avg_logprob": -0.18155445522732205, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.0017811397556215525}, {"id": 209, "seek": 128660, "start": 1298.7199999999998, "end": 1303.7199999999998, "text": " cash on them, and we would then route the traffic through a dedicated connection from", "tokens": [50970, 6388, 322, 552, 11, 293, 321, 576, 550, 7955, 264, 6419, 807, 257, 8374, 4984, 490, 51220], "temperature": 0.0, "avg_logprob": -0.18155445522732205, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.0017811397556215525}, {"id": 210, "seek": 128660, "start": 1303.7199999999998, "end": 1310.7199999999998, "text": " one of these CDN nodes back to YACO in my rack, and then YACO would then proxy the data", "tokens": [51220, 472, 295, 613, 6743, 45, 13891, 646, 281, 398, 4378, 46, 294, 452, 14788, 11, 293, 550, 398, 4378, 46, 576, 550, 29690, 264, 1412, 51570], "temperature": 0.0, "avg_logprob": -0.18155445522732205, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.0017811397556215525}, {"id": 211, "seek": 131072, "start": 1311.3600000000001, "end": 1317.3600000000001, "text": " over to Alice, and Alice was our main, our primary database running in the rack. So when", "tokens": [50396, 670, 281, 16004, 11, 293, 16004, 390, 527, 2135, 11, 527, 6194, 8149, 2614, 294, 264, 14788, 13, 407, 562, 50696], "temperature": 0.0, "avg_logprob": -0.11047220667567823, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.012219181284308434}, {"id": 212, "seek": 131072, "start": 1317.3600000000001, "end": 1322.3600000000001, "text": " things started to fail, it was like very intermittent failures in Frankfurt, and then we would get", "tokens": [50696, 721, 1409, 281, 3061, 11, 309, 390, 411, 588, 44084, 20774, 294, 36530, 11, 293, 550, 321, 576, 483, 50946], "temperature": 0.0, "avg_logprob": -0.11047220667567823, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.012219181284308434}, {"id": 213, "seek": 131072, "start": 1322.3600000000001, "end": 1327.28, "text": " like some very intermittent failures in Fremont, and it all looked like engine X was the problem,", "tokens": [50946, 411, 512, 588, 44084, 20774, 294, 479, 2579, 896, 11, 293, 309, 439, 2956, 411, 2848, 1783, 390, 264, 1154, 11, 51192], "temperature": 0.0, "avg_logprob": -0.11047220667567823, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.012219181284308434}, {"id": 214, "seek": 131072, "start": 1327.28, "end": 1332.16, "text": " we were getting timeouts and slow requests, and this whole incident is what later inspired", "tokens": [51192, 321, 645, 1242, 565, 7711, 293, 2964, 12475, 11, 293, 341, 1379, 9348, 307, 437, 1780, 7547, 51436], "temperature": 0.0, "avg_logprob": -0.11047220667567823, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.012219181284308434}, {"id": 215, "seek": 131072, "start": 1332.16, "end": 1335.88, "text": " us to build that dashboard that you see today, and the reason I was like we should be looking", "tokens": [51436, 505, 281, 1322, 300, 18342, 300, 291, 536, 965, 11, 293, 264, 1778, 286, 390, 411, 321, 820, 312, 1237, 51622], "temperature": 0.0, "avg_logprob": -0.11047220667567823, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.012219181284308434}, {"id": 216, "seek": 133588, "start": 1335.92, "end": 1342.92, "text": " at those HTTP request times when I very politely asked you all to please DDoS my server, and", "tokens": [50366, 412, 729, 33283, 5308, 1413, 562, 286, 588, 1180, 1959, 2351, 291, 439, 281, 1767, 413, 7653, 50, 452, 7154, 11, 293, 50716], "temperature": 0.0, "avg_logprob": -0.17427819967269897, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0292389877140522}, {"id": 217, "seek": 133588, "start": 1343.2800000000002, "end": 1348.8400000000001, "text": " so that transferred all the way back to Alice, and we learned entirely too much about Mastodon", "tokens": [50734, 370, 300, 15809, 439, 264, 636, 646, 281, 16004, 11, 293, 321, 3264, 7696, 886, 709, 466, 376, 525, 378, 266, 51012], "temperature": 0.0, "avg_logprob": -0.17427819967269897, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0292389877140522}, {"id": 218, "seek": 133588, "start": 1348.8400000000001, "end": 1354.5200000000002, "text": " at scale, retracing everything back through the rack, and we had to go and trace Redis", "tokens": [51012, 412, 4373, 11, 23106, 5615, 1203, 646, 807, 264, 14788, 11, 293, 321, 632, 281, 352, 293, 13508, 4477, 271, 51296], "temperature": 0.0, "avg_logprob": -0.17427819967269897, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0292389877140522}, {"id": 219, "seek": 133588, "start": 1354.5200000000002, "end": 1361.5200000000002, "text": " logs, and Sidekick queues, and Mastodon Ruby servers with the Puma server, and ultimately", "tokens": [51296, 20820, 11, 293, 19026, 42427, 631, 1247, 11, 293, 376, 525, 378, 266, 19907, 15909, 365, 264, 430, 5544, 7154, 11, 293, 6284, 51646], "temperature": 0.0, "avg_logprob": -0.17427819967269897, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0292389877140522}, {"id": 220, "seek": 136152, "start": 1361.76, "end": 1367.96, "text": " we found out that it was simply just Postgres unable to read and write from the database", "tokens": [50376, 321, 1352, 484, 300, 309, 390, 2935, 445, 10223, 45189, 11299, 281, 1401, 293, 2464, 490, 264, 8149, 50686], "temperature": 0.0, "avg_logprob": -0.12967897265144948, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.0018371563637629151}, {"id": 221, "seek": 136152, "start": 1367.96, "end": 1374.96, "text": " as fast as we would like. So these are what the graphs looked like the day of the outage,", "tokens": [50686, 382, 2370, 382, 321, 576, 411, 13, 407, 613, 366, 437, 264, 24877, 2956, 411, 264, 786, 295, 264, 484, 609, 11, 51036], "temperature": 0.0, "avg_logprob": -0.12967897265144948, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.0018371563637629151}, {"id": 222, "seek": 136152, "start": 1375.8, "end": 1380.16, "text": " so we grabbed some screenshots, and I'm really glad we did because these make for some interesting", "tokens": [51078, 370, 321, 18607, 512, 40661, 11, 293, 286, 478, 534, 5404, 321, 630, 570, 613, 652, 337, 512, 1880, 51296], "temperature": 0.0, "avg_logprob": -0.12967897265144948, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.0018371563637629151}, {"id": 223, "seek": 136152, "start": 1380.16, "end": 1386.2, "text": " takeaways here. On the left side you can see our HTTP response time, and so these are our", "tokens": [51296, 45584, 510, 13, 1282, 264, 1411, 1252, 291, 393, 536, 527, 33283, 4134, 565, 11, 293, 370, 613, 366, 527, 51598], "temperature": 0.0, "avg_logprob": -0.12967897265144948, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.0018371563637629151}, {"id": 224, "seek": 138620, "start": 1386.28, "end": 1393.28, "text": " get 200s, so in some cases the response time was actually, they were returning a 200, but", "tokens": [50368, 483, 2331, 82, 11, 370, 294, 512, 3331, 264, 4134, 565, 390, 767, 11, 436, 645, 12678, 257, 2331, 11, 457, 50718], "temperature": 0.0, "avg_logprob": -0.18457388266538963, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.023299874737858772}, {"id": 225, "seek": 138620, "start": 1395.04, "end": 1400.64, "text": " we were having like 40 second responses. Was anybody here on Hackaderm when it was like", "tokens": [50806, 321, 645, 1419, 411, 3356, 1150, 13019, 13, 3027, 4472, 510, 322, 35170, 345, 966, 562, 309, 390, 411, 51086], "temperature": 0.0, "avg_logprob": -0.18457388266538963, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.023299874737858772}, {"id": 226, "seek": 138620, "start": 1400.64, "end": 1406.2, "text": " in this weird like hangy stage where you kind of could upload media, but you kind of couldn't,", "tokens": [51086, 294, 341, 3657, 411, 3967, 88, 3233, 689, 291, 733, 295, 727, 6580, 3021, 11, 457, 291, 733, 295, 2809, 380, 11, 51364], "temperature": 0.0, "avg_logprob": -0.18457388266538963, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.023299874737858772}, {"id": 227, "seek": 138620, "start": 1406.2, "end": 1410.96, "text": " and you're like what the heck is NovaPan's doing, she doesn't know how to operate a service?", "tokens": [51364, 293, 291, 434, 411, 437, 264, 12872, 307, 27031, 47, 282, 311, 884, 11, 750, 1177, 380, 458, 577, 281, 9651, 257, 2643, 30, 51602], "temperature": 0.0, "avg_logprob": -0.18457388266538963, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.023299874737858772}, {"id": 228, "seek": 138620, "start": 1410.96, "end": 1415.88, "text": " So this is what we were working on, we were working backwards from these graphs, and it", "tokens": [51602, 407, 341, 307, 437, 321, 645, 1364, 322, 11, 321, 645, 1364, 12204, 490, 613, 24877, 11, 293, 309, 51848], "temperature": 0.0, "avg_logprob": -0.18457388266538963, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.023299874737858772}, {"id": 229, "seek": 141588, "start": 1415.88, "end": 1420.5200000000002, "text": " was interesting to see the behavior of Mastodon under these conditions because you very quickly", "tokens": [50364, 390, 1880, 281, 536, 264, 5223, 295, 376, 525, 378, 266, 833, 613, 4487, 570, 291, 588, 2661, 50596], "temperature": 0.0, "avg_logprob": -0.13312851510396817, "compression_ratio": 1.77, "no_speech_prob": 0.0005879715317860246}, {"id": 230, "seek": 141588, "start": 1420.5200000000002, "end": 1424.8400000000001, "text": " realized that different parts of the user interface were coupled with different parts", "tokens": [50596, 5334, 300, 819, 3166, 295, 264, 4195, 9226, 645, 29482, 365, 819, 3166, 50812], "temperature": 0.0, "avg_logprob": -0.13312851510396817, "compression_ratio": 1.77, "no_speech_prob": 0.0005879715317860246}, {"id": 231, "seek": 141588, "start": 1424.8400000000001, "end": 1429.68, "text": " of the back end, and so, and they all assumed that the entire user interface would work.", "tokens": [50812, 295, 264, 646, 917, 11, 293, 370, 11, 293, 436, 439, 15895, 300, 264, 2302, 4195, 9226, 576, 589, 13, 51054], "temperature": 0.0, "avg_logprob": -0.13312851510396817, "compression_ratio": 1.77, "no_speech_prob": 0.0005879715317860246}, {"id": 232, "seek": 141588, "start": 1429.68, "end": 1433.64, "text": " So if the database started to go slow, maybe you could upload the image, but we couldn't", "tokens": [51054, 407, 498, 264, 8149, 1409, 281, 352, 2964, 11, 1310, 291, 727, 6580, 264, 3256, 11, 457, 321, 2809, 380, 51252], "temperature": 0.0, "avg_logprob": -0.13312851510396817, "compression_ratio": 1.77, "no_speech_prob": 0.0005879715317860246}, {"id": 233, "seek": 141588, "start": 1433.64, "end": 1438.92, "text": " actually write the image key to MySQL, and the UI would just kind of just exist in this", "tokens": [51252, 767, 2464, 264, 3256, 2141, 281, 1222, 39934, 11, 293, 264, 15682, 576, 445, 733, 295, 445, 2514, 294, 341, 51516], "temperature": 0.0, "avg_logprob": -0.13312851510396817, "compression_ratio": 1.77, "no_speech_prob": 0.0005879715317860246}, {"id": 234, "seek": 141588, "start": 1438.92, "end": 1445.0800000000002, "text": " in-between stage for like five minutes at a time. It was very interesting behavior.", "tokens": [51516, 294, 12, 32387, 3233, 337, 411, 1732, 2077, 412, 257, 565, 13, 467, 390, 588, 1880, 5223, 13, 51824], "temperature": 0.0, "avg_logprob": -0.13312851510396817, "compression_ratio": 1.77, "no_speech_prob": 0.0005879715317860246}, {"id": 235, "seek": 144508, "start": 1445.08, "end": 1449.9199999999998, "text": " But ultimately, we isolated out the IO on disk, and we were able to determine it was", "tokens": [50364, 583, 6284, 11, 321, 14621, 484, 264, 39839, 322, 12355, 11, 293, 321, 645, 1075, 281, 6997, 309, 390, 50606], "temperature": 0.0, "avg_logprob": -0.14464095364446225, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0001442275388399139}, {"id": 236, "seek": 144508, "start": 1449.9199999999998, "end": 1456.32, "text": " old SDG and old SDH down here in the bottom right. You can see these numbers are closer", "tokens": [50606, 1331, 14638, 38, 293, 1331, 14638, 39, 760, 510, 294, 264, 2767, 558, 13, 509, 393, 536, 613, 3547, 366, 4966, 50926], "temperature": 0.0, "avg_logprob": -0.14464095364446225, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0001442275388399139}, {"id": 237, "seek": 144508, "start": 1456.32, "end": 1463.32, "text": " to 100% for IO on our disks, and this was what was causing those cascading failures.", "tokens": [50926, 281, 2319, 4, 337, 39839, 322, 527, 41617, 11, 293, 341, 390, 437, 390, 9853, 729, 3058, 66, 8166, 20774, 13, 51276], "temperature": 0.0, "avg_logprob": -0.14464095364446225, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0001442275388399139}, {"id": 238, "seek": 144508, "start": 1465.36, "end": 1471.3999999999999, "text": " So ultimately, this was a very exciting time. People were joining Mastodon around the clock,", "tokens": [51378, 407, 6284, 11, 341, 390, 257, 588, 4670, 565, 13, 3432, 645, 5549, 376, 525, 378, 266, 926, 264, 7830, 11, 51680], "temperature": 0.0, "avg_logprob": -0.14464095364446225, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0001442275388399139}, {"id": 239, "seek": 147140, "start": 1471.4, "end": 1477.24, "text": " and our little group of people that hung out on Discord very quickly turned into a more", "tokens": [50364, 293, 527, 707, 1594, 295, 561, 300, 5753, 484, 322, 32623, 588, 2661, 3574, 666, 257, 544, 50656], "temperature": 0.0, "avg_logprob": -0.15783761857866166, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.01852281019091606}, {"id": 240, "seek": 147140, "start": 1477.24, "end": 1483.0400000000002, "text": " serious group of people who hung out on Discord, and it was really fascinating to watch friends", "tokens": [50656, 3156, 1594, 295, 561, 567, 5753, 484, 322, 32623, 11, 293, 309, 390, 534, 10343, 281, 1159, 1855, 50946], "temperature": 0.0, "avg_logprob": -0.15783761857866166, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.01852281019091606}, {"id": 241, "seek": 147140, "start": 1483.0400000000002, "end": 1487.88, "text": " of the Twitch stream and my partner Quintessence, and there's even people here in the room.", "tokens": [50946, 295, 264, 22222, 4309, 293, 452, 4975, 2326, 686, 442, 655, 11, 293, 456, 311, 754, 561, 510, 294, 264, 1808, 13, 51188], "temperature": 0.0, "avg_logprob": -0.15783761857866166, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.01852281019091606}, {"id": 242, "seek": 147140, "start": 1487.88, "end": 1495.3600000000001, "text": " Malte and DMA, are you right here in the front? We are now best friends, and we wouldn't necessarily", "tokens": [51188, 5746, 975, 293, 413, 9998, 11, 366, 291, 558, 510, 294, 264, 1868, 30, 492, 366, 586, 1151, 1855, 11, 293, 321, 2759, 380, 4725, 51562], "temperature": 0.0, "avg_logprob": -0.15783761857866166, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.01852281019091606}, {"id": 243, "seek": 147140, "start": 1495.3600000000001, "end": 1500.48, "text": " be friends if it wouldn't have been for this whole incident in the first place.", "tokens": [51562, 312, 1855, 498, 309, 2759, 380, 362, 668, 337, 341, 1379, 9348, 294, 264, 700, 1081, 13, 51818], "temperature": 0.0, "avg_logprob": -0.15783761857866166, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.01852281019091606}, {"id": 244, "seek": 150048, "start": 1500.52, "end": 1505.32, "text": " So we were definitely working around the clock. I think Malte and DMA would kind of hand the", "tokens": [50366, 407, 321, 645, 2138, 1364, 926, 264, 7830, 13, 286, 519, 5746, 975, 293, 413, 9998, 576, 733, 295, 1011, 264, 50606], "temperature": 0.0, "avg_logprob": -0.11637466870821439, "compression_ratio": 1.7491961414790997, "no_speech_prob": 0.002753332955762744}, {"id": 245, "seek": 150048, "start": 1505.32, "end": 1509.52, "text": " service off to us when we woke up in the morning, and we would work until they woke up the", "tokens": [50606, 2643, 766, 281, 505, 562, 321, 12852, 493, 294, 264, 2446, 11, 293, 321, 576, 589, 1826, 436, 12852, 493, 264, 50816], "temperature": 0.0, "avg_logprob": -0.11637466870821439, "compression_ratio": 1.7491961414790997, "no_speech_prob": 0.002753332955762744}, {"id": 246, "seek": 150048, "start": 1509.52, "end": 1513.96, "text": " following morning, and it was just this constant game of providing quick summaries of our work", "tokens": [50816, 3480, 2446, 11, 293, 309, 390, 445, 341, 5754, 1216, 295, 6530, 1702, 8367, 4889, 295, 527, 589, 51038], "temperature": 0.0, "avg_logprob": -0.11637466870821439, "compression_ratio": 1.7491961414790997, "no_speech_prob": 0.002753332955762744}, {"id": 247, "seek": 150048, "start": 1513.96, "end": 1517.48, "text": " and then just like crashing and going to sleep for a few hours and trying to hold down a", "tokens": [51038, 293, 550, 445, 411, 26900, 293, 516, 281, 2817, 337, 257, 1326, 2496, 293, 1382, 281, 1797, 760, 257, 51214], "temperature": 0.0, "avg_logprob": -0.11637466870821439, "compression_ratio": 1.7491961414790997, "no_speech_prob": 0.002753332955762744}, {"id": 248, "seek": 150048, "start": 1517.48, "end": 1523.4, "text": " day job while we dealt with the service. And this is for the most part what it felt like", "tokens": [51214, 786, 1691, 1339, 321, 15991, 365, 264, 2643, 13, 400, 341, 307, 337, 264, 881, 644, 437, 309, 2762, 411, 51510], "temperature": 0.0, "avg_logprob": -0.11637466870821439, "compression_ratio": 1.7491961414790997, "no_speech_prob": 0.002753332955762744}, {"id": 249, "seek": 150048, "start": 1523.4, "end": 1527.64, "text": " behind the scenes. We had a dedicated channel where we were trying hard to work through", "tokens": [51510, 2261, 264, 8026, 13, 492, 632, 257, 8374, 2269, 689, 321, 645, 1382, 1152, 281, 589, 807, 51722], "temperature": 0.0, "avg_logprob": -0.11637466870821439, "compression_ratio": 1.7491961414790997, "no_speech_prob": 0.002753332955762744}, {"id": 250, "seek": 152764, "start": 1527.68, "end": 1533.8400000000001, "text": " things, and I think this is Malte just sent to the image. This is the moment where we finally", "tokens": [50366, 721, 11, 293, 286, 519, 341, 307, 5746, 975, 445, 2279, 281, 264, 3256, 13, 639, 307, 264, 1623, 689, 321, 2721, 50674], "temperature": 0.0, "avg_logprob": -0.13314708612732967, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.014020346105098724}, {"id": 251, "seek": 152764, "start": 1533.8400000000001, "end": 1539.2800000000002, "text": " realized what was going on, and we were starting to isolate the problems on the disks, and I", "tokens": [50674, 5334, 437, 390, 516, 322, 11, 293, 321, 645, 2891, 281, 25660, 264, 2740, 322, 264, 41617, 11, 293, 286, 50946], "temperature": 0.0, "avg_logprob": -0.13314708612732967, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.014020346105098724}, {"id": 252, "seek": 152764, "start": 1539.2800000000002, "end": 1543.0400000000002, "text": " think Malte was just like, okay, we finally found the problem. It's exactly what we thought it was,", "tokens": [50946, 519, 5746, 975, 390, 445, 411, 11, 1392, 11, 321, 2721, 1352, 264, 1154, 13, 467, 311, 2293, 437, 321, 1194, 309, 390, 11, 51134], "temperature": 0.0, "avg_logprob": -0.13314708612732967, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.014020346105098724}, {"id": 253, "seek": 152764, "start": 1543.0400000000002, "end": 1548.72, "text": " and everything is fine. This is going to be fine. And meanwhile, we have, you know,", "tokens": [51134, 293, 1203, 307, 2489, 13, 639, 307, 516, 281, 312, 2489, 13, 400, 29252, 11, 321, 362, 11, 291, 458, 11, 51418], "temperature": 0.0, "avg_logprob": -0.13314708612732967, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.014020346105098724}, {"id": 254, "seek": 152764, "start": 1548.72, "end": 1553.6000000000001, "text": " main names and technology joining the service, and things are kind of burning down all around us.", "tokens": [51418, 2135, 5288, 293, 2899, 5549, 264, 2643, 11, 293, 721, 366, 733, 295, 9488, 760, 439, 926, 505, 13, 51662], "temperature": 0.0, "avg_logprob": -0.13314708612732967, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.014020346105098724}, {"id": 255, "seek": 155360, "start": 1554.6, "end": 1561.1999999999998, "text": " From the human perspective, I wanted to share two interesting failure modes that we got into as", "tokens": [50414, 3358, 264, 1952, 4585, 11, 286, 1415, 281, 2073, 732, 1880, 7763, 14068, 300, 321, 658, 666, 382, 50744], "temperature": 0.0, "avg_logprob": -0.13741025157358455, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.004260182846337557}, {"id": 256, "seek": 155360, "start": 1561.1999999999998, "end": 1565.9599999999998, "text": " people that I think are just an interesting takeaway for anybody who operates a production", "tokens": [50744, 561, 300, 286, 519, 366, 445, 364, 1880, 30681, 337, 4472, 567, 22577, 257, 4265, 50982], "temperature": 0.0, "avg_logprob": -0.13741025157358455, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.004260182846337557}, {"id": 257, "seek": 155360, "start": 1565.9599999999998, "end": 1573.9599999999998, "text": " service. So the first failure mode was in a state of panic, I tried to just throw more computers", "tokens": [50982, 2643, 13, 407, 264, 700, 7763, 4391, 390, 294, 257, 1785, 295, 14783, 11, 286, 3031, 281, 445, 3507, 544, 10807, 51382], "temperature": 0.0, "avg_logprob": -0.13741025157358455, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.004260182846337557}, {"id": 258, "seek": 155360, "start": 1573.9599999999998, "end": 1579.28, "text": " at the problem, and so my response was like, we're going to go put more computers in the rack,", "tokens": [51382, 412, 264, 1154, 11, 293, 370, 452, 4134, 390, 411, 11, 321, 434, 516, 281, 352, 829, 544, 10807, 294, 264, 14788, 11, 51648], "temperature": 0.0, "avg_logprob": -0.13741025157358455, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.004260182846337557}, {"id": 259, "seek": 157928, "start": 1579.52, "end": 1584.6, "text": " and I turned on dot for the first time, and gave dot a public IP address, and I think the other", "tokens": [50376, 293, 286, 3574, 322, 5893, 337, 264, 700, 565, 11, 293, 2729, 5893, 257, 1908, 8671, 2985, 11, 293, 286, 519, 264, 661, 50630], "temperature": 0.0, "avg_logprob": -0.13764547690367088, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.09490404278039932}, {"id": 260, "seek": 157928, "start": 1584.6, "end": 1590.68, "text": " big takeaway here was we got very good at doing the wrong things, and I think this is a very,", "tokens": [50630, 955, 30681, 510, 390, 321, 658, 588, 665, 412, 884, 264, 2085, 721, 11, 293, 286, 519, 341, 307, 257, 588, 11, 50934], "temperature": 0.0, "avg_logprob": -0.13764547690367088, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.09490404278039932}, {"id": 261, "seek": 157928, "start": 1590.68, "end": 1598.12, "text": " very familiar trap for a lot of the organizations that I work with every day, is there will be", "tokens": [50934, 588, 4963, 11487, 337, 257, 688, 295, 264, 6150, 300, 286, 589, 365, 633, 786, 11, 307, 456, 486, 312, 51306], "temperature": 0.0, "avg_logprob": -0.13764547690367088, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.09490404278039932}, {"id": 262, "seek": 157928, "start": 1598.12, "end": 1604.2, "text": " some crisis, and they will respond to the crisis by doing something. In our case, it was creating a", "tokens": [51306, 512, 5869, 11, 293, 436, 486, 4196, 281, 264, 5869, 538, 884, 746, 13, 682, 527, 1389, 11, 309, 390, 4084, 257, 51610], "temperature": 0.0, "avg_logprob": -0.13764547690367088, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.09490404278039932}, {"id": 263, "seek": 157928, "start": 1604.2, "end": 1609.0, "text": " spreadsheet, and the spreadsheet helped us do some quick math, and that math helped us inform", "tokens": [51610, 27733, 11, 293, 264, 27733, 4254, 505, 360, 512, 1702, 5221, 11, 293, 300, 5221, 4254, 505, 1356, 51850], "temperature": 0.0, "avg_logprob": -0.13764547690367088, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.09490404278039932}, {"id": 264, "seek": 160900, "start": 1609.24, "end": 1614.32, "text": " how we needed to provision our different system D services, and then when we changed the system D", "tokens": [50376, 577, 321, 2978, 281, 17225, 527, 819, 1185, 413, 3328, 11, 293, 550, 562, 321, 3105, 264, 1185, 413, 50630], "temperature": 0.0, "avg_logprob": -0.16317568327251233, "compression_ratio": 1.8674242424242424, "no_speech_prob": 0.0011680732714012265}, {"id": 265, "seek": 160900, "start": 1614.32, "end": 1619.8, "text": " service, the rule was you needed to go update the spreadsheet, and this was a reaction to a crisis", "tokens": [50630, 2643, 11, 264, 4978, 390, 291, 2978, 281, 352, 5623, 264, 27733, 11, 293, 341, 390, 257, 5480, 281, 257, 5869, 50904], "temperature": 0.0, "avg_logprob": -0.16317568327251233, "compression_ratio": 1.8674242424242424, "no_speech_prob": 0.0011680732714012265}, {"id": 266, "seek": 160900, "start": 1619.8, "end": 1626.72, "text": " that allowed us to move forward, and then it was very difficult to get out of this situation, so I", "tokens": [50904, 300, 4350, 505, 281, 1286, 2128, 11, 293, 550, 309, 390, 588, 2252, 281, 483, 484, 295, 341, 2590, 11, 370, 286, 51250], "temperature": 0.0, "avg_logprob": -0.16317568327251233, "compression_ratio": 1.8674242424242424, "no_speech_prob": 0.0011680732714012265}, {"id": 267, "seek": 160900, "start": 1626.72, "end": 1631.52, "text": " do think that there's a very interesting takeaway of you get in the habit of doing the wrong thing", "tokens": [51250, 360, 519, 300, 456, 311, 257, 588, 1880, 30681, 295, 291, 483, 294, 264, 7164, 295, 884, 264, 2085, 551, 51490], "temperature": 0.0, "avg_logprob": -0.16317568327251233, "compression_ratio": 1.8674242424242424, "no_speech_prob": 0.0011680732714012265}, {"id": 268, "seek": 160900, "start": 1631.52, "end": 1637.92, "text": " or doing a bad behavior during a crisis, and that can actually persist in the last longer than the", "tokens": [51490, 420, 884, 257, 1578, 5223, 1830, 257, 5869, 11, 293, 300, 393, 767, 13233, 294, 264, 1036, 2854, 813, 264, 51810], "temperature": 0.0, "avg_logprob": -0.16317568327251233, "compression_ratio": 1.8674242424242424, "no_speech_prob": 0.0011680732714012265}, {"id": 269, "seek": 163792, "start": 1637.96, "end": 1643.0800000000002, "text": " actual incident itself, so we had all the major problems of a normal SRE team, and this was a", "tokens": [50366, 3539, 9348, 2564, 11, 370, 321, 632, 439, 264, 2563, 2740, 295, 257, 2710, 318, 3850, 1469, 11, 293, 341, 390, 257, 50622], "temperature": 0.0, "avg_logprob": -0.14157936360576365, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.0025477732997387648}, {"id": 270, "seek": 163792, "start": 1643.0800000000002, "end": 1651.76, "text": " volunteer open source project to begin with. Okay, so I have a friend in Boulder, his name's Gabe,", "tokens": [50622, 13835, 1269, 4009, 1716, 281, 1841, 365, 13, 1033, 11, 370, 286, 362, 257, 1277, 294, 48052, 11, 702, 1315, 311, 39524, 11, 51056], "temperature": 0.0, "avg_logprob": -0.14157936360576365, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.0025477732997387648}, {"id": 271, "seek": 163792, "start": 1651.76, "end": 1657.4, "text": " him and I have known each other for a long time, he's grown very quickly in his career, he's now", "tokens": [51056, 796, 293, 286, 362, 2570, 1184, 661, 337, 257, 938, 565, 11, 415, 311, 7709, 588, 2661, 294, 702, 3988, 11, 415, 311, 586, 51338], "temperature": 0.0, "avg_logprob": -0.14157936360576365, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.0025477732997387648}, {"id": 272, "seek": 163792, "start": 1657.4, "end": 1664.8400000000001, "text": " the Chief Product Officer of Digital Ocean, and Gabe texted me one day and says, hey Nova, so I", "tokens": [51338, 264, 10068, 22005, 15434, 295, 15522, 18101, 11, 293, 39524, 42553, 385, 472, 786, 293, 1619, 11, 4177, 27031, 11, 370, 286, 51710], "temperature": 0.0, "avg_logprob": -0.14157936360576365, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.0025477732997387648}, {"id": 273, "seek": 166484, "start": 1664.8799999999999, "end": 1672.1999999999998, "text": " bought this farm, and I'm trying to upload rooster pictures on your website, and I can't upload my", "tokens": [50366, 4243, 341, 5421, 11, 293, 286, 478, 1382, 281, 6580, 744, 7096, 5242, 322, 428, 3144, 11, 293, 286, 393, 380, 6580, 452, 50732], "temperature": 0.0, "avg_logprob": -0.1351098120212555, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.004397261422127485}, {"id": 274, "seek": 166484, "start": 1672.1999999999998, "end": 1677.28, "text": " rooster pictures on Hackaderm today. What's going on, and is there anything Digital Ocean can do", "tokens": [50732, 744, 7096, 5242, 322, 35170, 345, 966, 965, 13, 708, 311, 516, 322, 11, 293, 307, 456, 1340, 15522, 18101, 393, 360, 50986], "temperature": 0.0, "avg_logprob": -0.1351098120212555, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.004397261422127485}, {"id": 275, "seek": 166484, "start": 1677.28, "end": 1683.76, "text": " to help? And so we were in a situation where we were trying to come up with a plan, we had just", "tokens": [50986, 281, 854, 30, 400, 370, 321, 645, 294, 257, 2590, 689, 321, 645, 1382, 281, 808, 493, 365, 257, 1393, 11, 321, 632, 445, 51310], "temperature": 0.0, "avg_logprob": -0.1351098120212555, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.004397261422127485}, {"id": 276, "seek": 166484, "start": 1683.76, "end": 1690.12, "text": " identified that the disks were the bottleneck and the single cause of our infrastructure problems,", "tokens": [51310, 9234, 300, 264, 41617, 645, 264, 44641, 547, 293, 264, 2167, 3082, 295, 527, 6896, 2740, 11, 51628], "temperature": 0.0, "avg_logprob": -0.1351098120212555, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.004397261422127485}, {"id": 277, "seek": 169012, "start": 1690.7199999999998, "end": 1697.56, "text": " and I think this was the first time I kind of realized like, oh, we have 50,000 really smart,", "tokens": [50394, 293, 286, 519, 341, 390, 264, 700, 565, 286, 733, 295, 5334, 411, 11, 1954, 11, 321, 362, 2625, 11, 1360, 534, 4069, 11, 50736], "temperature": 0.0, "avg_logprob": -0.10264963981432793, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.026306021958589554}, {"id": 278, "seek": 169012, "start": 1697.56, "end": 1703.9599999999998, "text": " well-connected people who can more than obviously help us with our problems, and really the problem", "tokens": [50736, 731, 12, 9826, 292, 561, 567, 393, 544, 813, 2745, 854, 505, 365, 527, 2740, 11, 293, 534, 264, 1154, 51056], "temperature": 0.0, "avg_logprob": -0.10264963981432793, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.026306021958589554}, {"id": 279, "seek": 169012, "start": 1703.9599999999998, "end": 1709.7199999999998, "text": " is how do we reach out to them, give them access to production, form a plan, and execute on that", "tokens": [51056, 307, 577, 360, 321, 2524, 484, 281, 552, 11, 976, 552, 2105, 281, 4265, 11, 1254, 257, 1393, 11, 293, 14483, 322, 300, 51344], "temperature": 0.0, "avg_logprob": -0.10264963981432793, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.026306021958589554}, {"id": 280, "seek": 169012, "start": 1709.7199999999998, "end": 1714.6399999999999, "text": " plan, and it became very obvious that our main problem wasn't necessarily fixing the disks in", "tokens": [51344, 1393, 11, 293, 309, 3062, 588, 6322, 300, 527, 2135, 1154, 2067, 380, 4725, 19442, 264, 41617, 294, 51590], "temperature": 0.0, "avg_logprob": -0.10264963981432793, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.026306021958589554}, {"id": 281, "seek": 169012, "start": 1714.6399999999999, "end": 1719.9599999999998, "text": " the basement, it was managing people, and it was organizing people to work on the service and making", "tokens": [51590, 264, 16893, 11, 309, 390, 11642, 561, 11, 293, 309, 390, 17608, 561, 281, 589, 322, 264, 2643, 293, 1455, 51856], "temperature": 0.0, "avg_logprob": -0.10264963981432793, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.026306021958589554}, {"id": 282, "seek": 171996, "start": 1719.96, "end": 1725.68, "text": " sure that we were in a good position to accept help from a corporation such as Digital Ocean in", "tokens": [50364, 988, 300, 321, 645, 294, 257, 665, 2535, 281, 3241, 854, 490, 257, 22197, 1270, 382, 15522, 18101, 294, 50650], "temperature": 0.0, "avg_logprob": -0.16320039096631503, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.0020454125478863716}, {"id": 283, "seek": 171996, "start": 1725.68, "end": 1732.92, "text": " the first place. So Malte here, he's going to get embarrassed, but can we just give him a round of", "tokens": [50650, 264, 700, 1081, 13, 407, 5746, 975, 510, 11, 415, 311, 516, 281, 483, 16843, 11, 457, 393, 321, 445, 976, 796, 257, 3098, 295, 51012], "temperature": 0.0, "avg_logprob": -0.16320039096631503, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.0020454125478863716}, {"id": 284, "seek": 171996, "start": 1732.92, "end": 1745.1200000000001, "text": " applause for this plan? He's smiling, but honestly, like if there was a Malte saved the day kind of", "tokens": [51012, 9969, 337, 341, 1393, 30, 634, 311, 16005, 11, 457, 6095, 11, 411, 498, 456, 390, 257, 5746, 975, 6624, 264, 786, 733, 295, 51622], "temperature": 0.0, "avg_logprob": -0.16320039096631503, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.0020454125478863716}, {"id": 285, "seek": 174512, "start": 1745.12, "end": 1750.84, "text": " moment, like straight up Malte saved the day. He came up with this very interesting engine X pattern", "tokens": [50364, 1623, 11, 411, 2997, 493, 5746, 975, 6624, 264, 786, 13, 634, 1361, 493, 365, 341, 588, 1880, 2848, 1783, 5102, 50650], "temperature": 0.0, "avg_logprob": -0.1565612659119723, "compression_ratio": 1.6701030927835052, "no_speech_prob": 0.06456335633993149}, {"id": 286, "seek": 174512, "start": 1750.84, "end": 1758.4799999999998, "text": " that allowed us to effectively move our data off of the bad disks in the basement to the Digital", "tokens": [50650, 300, 4350, 505, 281, 8659, 1286, 527, 1412, 766, 295, 264, 1578, 41617, 294, 264, 16893, 281, 264, 15522, 51032], "temperature": 0.0, "avg_logprob": -0.1565612659119723, "compression_ratio": 1.6701030927835052, "no_speech_prob": 0.06456335633993149}, {"id": 287, "seek": 174512, "start": 1758.4799999999998, "end": 1763.4799999999998, "text": " Ocean service without taking the service offline, which you're like, okay, that's pretty cool,", "tokens": [51032, 18101, 2643, 1553, 1940, 264, 2643, 21857, 11, 597, 291, 434, 411, 11, 1392, 11, 300, 311, 1238, 1627, 11, 51282], "temperature": 0.0, "avg_logprob": -0.1565612659119723, "compression_ratio": 1.6701030927835052, "no_speech_prob": 0.06456335633993149}, {"id": 288, "seek": 174512, "start": 1763.4799999999998, "end": 1768.8799999999999, "text": " you can keep the service up, and you can start to fix the problem at the same time. Additionally,", "tokens": [51282, 291, 393, 1066, 264, 2643, 493, 11, 293, 291, 393, 722, 281, 3191, 264, 1154, 412, 264, 912, 565, 13, 19927, 11, 51552], "temperature": 0.0, "avg_logprob": -0.1565612659119723, "compression_ratio": 1.6701030927835052, "no_speech_prob": 0.06456335633993149}, {"id": 289, "seek": 174512, "start": 1768.8799999999999, "end": 1774.6799999999998, "text": " what this did was this actually gave us a means of getting the data out, and everybody who used", "tokens": [51552, 437, 341, 630, 390, 341, 767, 2729, 505, 257, 1355, 295, 1242, 264, 1412, 484, 11, 293, 2201, 567, 1143, 51842], "temperature": 0.0, "avg_logprob": -0.1565612659119723, "compression_ratio": 1.6701030927835052, "no_speech_prob": 0.06456335633993149}, {"id": 290, "seek": 177468, "start": 1774.72, "end": 1781.64, "text": " the service contributed to the data migration. And so what we did is we set up this, who's here", "tokens": [50366, 264, 2643, 18434, 281, 264, 1412, 17011, 13, 400, 370, 437, 321, 630, 307, 321, 992, 493, 341, 11, 567, 311, 510, 50712], "temperature": 0.0, "avg_logprob": -0.2116194043840681, "compression_ratio": 1.6016260162601625, "no_speech_prob": 0.0023210057988762856}, {"id": 291, "seek": 177468, "start": 1781.64, "end": 1788.0800000000002, "text": " familiar with the try files directive in engine X config, a few people, you should, if you get time,", "tokens": [50712, 4963, 365, 264, 853, 7098, 45444, 294, 2848, 1783, 6662, 11, 257, 1326, 561, 11, 291, 820, 11, 498, 291, 483, 565, 11, 51034], "temperature": 0.0, "avg_logprob": -0.2116194043840681, "compression_ratio": 1.6016260162601625, "no_speech_prob": 0.0023210057988762856}, {"id": 292, "seek": 177468, "start": 1788.0800000000002, "end": 1795.1200000000001, "text": " go read about try files. This is a fascinating thing that engine X does, and what we were able to do", "tokens": [51034, 352, 1401, 466, 853, 7098, 13, 639, 307, 257, 10343, 551, 300, 2848, 1783, 775, 11, 293, 437, 321, 645, 1075, 281, 360, 51386], "temperature": 0.0, "avg_logprob": -0.2116194043840681, "compression_ratio": 1.6016260162601625, "no_speech_prob": 0.0023210057988762856}, {"id": 293, "seek": 177468, "start": 1795.1200000000001, "end": 1802.52, "text": " was point media.hackaderm.io on Alice. We were able to point all of the CDN nodes towards Alice,", "tokens": [51386, 390, 935, 3021, 13, 71, 501, 345, 966, 13, 1004, 322, 16004, 13, 492, 645, 1075, 281, 935, 439, 295, 264, 6743, 45, 13891, 3030, 16004, 11, 51756], "temperature": 0.0, "avg_logprob": -0.2116194043840681, "compression_ratio": 1.6016260162601625, "no_speech_prob": 0.0023210057988762856}, {"id": 294, "seek": 180252, "start": 1803.16, "end": 1809.52, "text": " and Alice would first try to resource the file from S3 running in Digital Ocean. If it could find", "tokens": [50396, 293, 16004, 576, 700, 853, 281, 7684, 264, 3991, 490, 318, 18, 2614, 294, 15522, 18101, 13, 759, 309, 727, 915, 50714], "temperature": 0.0, "avg_logprob": -0.12890747615269252, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0038200418930500746}, {"id": 295, "seek": 180252, "start": 1809.52, "end": 1815.84, "text": " it, it would then return that directly as basically a reverse proxy from S3 to the client, and", "tokens": [50714, 309, 11, 309, 576, 550, 2736, 300, 3838, 382, 1936, 257, 9943, 29690, 490, 318, 18, 281, 264, 6423, 11, 293, 51030], "temperature": 0.0, "avg_logprob": -0.12890747615269252, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0038200418930500746}, {"id": 296, "seek": 180252, "start": 1815.84, "end": 1822.04, "text": " otherwise it would resource it from the disks locally in the rack. So every time somebody read,", "tokens": [51030, 5911, 309, 576, 7684, 309, 490, 264, 41617, 16143, 294, 264, 14788, 13, 407, 633, 565, 2618, 1401, 11, 51340], "temperature": 0.0, "avg_logprob": -0.12890747615269252, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0038200418930500746}, {"id": 297, "seek": 180252, "start": 1822.04, "end": 1827.6, "text": " whether it was an image or a post or something coming from the rack, it would then persist into", "tokens": [51340, 1968, 309, 390, 364, 3256, 420, 257, 2183, 420, 746, 1348, 490, 264, 14788, 11, 309, 576, 550, 13233, 666, 51618], "temperature": 0.0, "avg_logprob": -0.12890747615269252, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0038200418930500746}, {"id": 298, "seek": 182760, "start": 1827.6399999999999, "end": 1833.9599999999998, "text": " S3 on the back end, and we would never have to serve that image ever again from Alice. So this was", "tokens": [50366, 318, 18, 322, 264, 646, 917, 11, 293, 321, 576, 1128, 362, 281, 4596, 300, 3256, 1562, 797, 490, 16004, 13, 407, 341, 390, 50682], "temperature": 0.0, "avg_logprob": -0.14513112476893833, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.002113720402121544}, {"id": 299, "seek": 182760, "start": 1833.9599999999998, "end": 1839.8, "text": " a clever solution, and it gave us a means to slowly start transferring the data, and every minute", "tokens": [50682, 257, 13494, 3827, 11, 293, 309, 2729, 505, 257, 1355, 281, 5692, 722, 31437, 264, 1412, 11, 293, 633, 3456, 50974], "temperature": 0.0, "avg_logprob": -0.14513112476893833, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.002113720402121544}, {"id": 300, "seek": 182760, "start": 1839.8, "end": 1843.7199999999998, "text": " we transferred the data was another minute that it was likely going to be served from a cloud", "tokens": [50974, 321, 15809, 264, 1412, 390, 1071, 3456, 300, 309, 390, 3700, 516, 281, 312, 7584, 490, 257, 4588, 51170], "temperature": 0.0, "avg_logprob": -0.14513112476893833, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.002113720402121544}, {"id": 301, "seek": 184372, "start": 1843.72, "end": 1858.84, "text": " provider and not from my really crappy hardware running in my basement. So the disks were so slow,", "tokens": [50364, 12398, 293, 406, 490, 452, 534, 36531, 8837, 2614, 294, 452, 16893, 13, 407, 264, 41617, 645, 370, 2964, 11, 51120], "temperature": 0.0, "avg_logprob": -0.22207059086980047, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.012216967530548573}, {"id": 302, "seek": 184372, "start": 1858.84, "end": 1863.32, "text": " I mean, in my mind, these disks could be personified. They were like, they were beaten,", "tokens": [51120, 286, 914, 11, 294, 452, 1575, 11, 613, 41617, 727, 312, 954, 2587, 13, 814, 645, 411, 11, 436, 645, 17909, 11, 51344], "temperature": 0.0, "avg_logprob": -0.22207059086980047, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.012216967530548573}, {"id": 303, "seek": 184372, "start": 1863.32, "end": 1870.28, "text": " they were tired, they have been through hell and back again, and it took eight days for us to arclone", "tokens": [51344, 436, 645, 5868, 11, 436, 362, 668, 807, 4921, 293, 646, 797, 11, 293, 309, 1890, 3180, 1708, 337, 505, 281, 10346, 75, 546, 51692], "temperature": 0.0, "avg_logprob": -0.22207059086980047, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.012216967530548573}, {"id": 304, "seek": 187028, "start": 1870.6, "end": 1876.28, "text": " all of the data, which was about two terabytes of data, of Rooster videos and cat pictures and", "tokens": [50380, 439, 295, 264, 1412, 11, 597, 390, 466, 732, 1796, 24538, 295, 1412, 11, 295, 3101, 7096, 2145, 293, 3857, 5242, 293, 50664], "temperature": 0.0, "avg_logprob": -0.15688018798828124, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.01637865975499153}, {"id": 305, "seek": 187028, "start": 1876.28, "end": 1883.04, "text": " catter-day hashtags and all kinds of mastodon things over to Digital Ocean S3, and this was all", "tokens": [50664, 269, 1161, 12, 810, 50016, 293, 439, 3685, 295, 27055, 378, 266, 721, 670, 281, 15522, 18101, 318, 18, 11, 293, 341, 390, 439, 51002], "temperature": 0.0, "avg_logprob": -0.15688018798828124, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.01637865975499153}, {"id": 306, "seek": 187028, "start": 1883.04, "end": 1891.92, "text": " courtesy of Gabe, who was like, bro, I just want to upload my Rooster pictures. So as we moved the", "tokens": [51002, 41704, 295, 39524, 11, 567, 390, 411, 11, 2006, 11, 286, 445, 528, 281, 6580, 452, 3101, 7096, 5242, 13, 407, 382, 321, 4259, 264, 51446], "temperature": 0.0, "avg_logprob": -0.15688018798828124, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.01637865975499153}, {"id": 307, "seek": 187028, "start": 1891.92, "end": 1898.28, "text": " files out of the basement, it became obvious that running this service in my basement was no longer", "tokens": [51446, 7098, 484, 295, 264, 16893, 11, 309, 3062, 6322, 300, 2614, 341, 2643, 294, 452, 16893, 390, 572, 2854, 51764], "temperature": 0.0, "avg_logprob": -0.15688018798828124, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.01637865975499153}, {"id": 308, "seek": 189828, "start": 1898.28, "end": 1904.04, "text": " going to work for us and that enough people had joined that we had reached critical mass. So our", "tokens": [50364, 516, 281, 589, 337, 505, 293, 300, 1547, 561, 632, 6869, 300, 321, 632, 6488, 4924, 2758, 13, 407, 527, 50652], "temperature": 0.0, "avg_logprob": -0.13124709210153354, "compression_ratio": 1.62, "no_speech_prob": 0.03721529245376587}, {"id": 309, "seek": 189828, "start": 1904.04, "end": 1909.56, "text": " next decision was, okay, where do we actually want to move the compute to? And I think we all kind", "tokens": [50652, 958, 3537, 390, 11, 1392, 11, 689, 360, 321, 767, 528, 281, 1286, 264, 14722, 281, 30, 400, 286, 519, 321, 439, 733, 50928], "temperature": 0.0, "avg_logprob": -0.13124709210153354, "compression_ratio": 1.62, "no_speech_prob": 0.03721529245376587}, {"id": 310, "seek": 189828, "start": 1909.56, "end": 1914.48, "text": " of have been like a little bit traumatized from like the vendor lock-in and the tech industry as", "tokens": [50928, 295, 362, 668, 411, 257, 707, 857, 35099, 1602, 490, 411, 264, 24321, 4017, 12, 259, 293, 264, 7553, 3518, 382, 51174], "temperature": 0.0, "avg_logprob": -0.13124709210153354, "compression_ratio": 1.62, "no_speech_prob": 0.03721529245376587}, {"id": 311, "seek": 189828, "start": 1914.48, "end": 1920.08, "text": " it exists today. And so I think looking at Hackaderm, there was a lot of people who were very critical,", "tokens": [51174, 309, 8198, 965, 13, 400, 370, 286, 519, 1237, 412, 35170, 345, 966, 11, 456, 390, 257, 688, 295, 561, 567, 645, 588, 4924, 11, 51454], "temperature": 0.0, "avg_logprob": -0.13124709210153354, "compression_ratio": 1.62, "no_speech_prob": 0.03721529245376587}, {"id": 312, "seek": 189828, "start": 1920.08, "end": 1926.36, "text": " myself included, of a dependency on various corporations. So we definitely didn't want to", "tokens": [51454, 2059, 5556, 11, 295, 257, 33621, 322, 3683, 17676, 13, 407, 321, 2138, 994, 380, 528, 281, 51768], "temperature": 0.0, "avg_logprob": -0.13124709210153354, "compression_ratio": 1.62, "no_speech_prob": 0.03721529245376587}, {"id": 313, "seek": 192636, "start": 1926.36, "end": 1930.9599999999998, "text": " just go throw money at Amazon, right? Amazon has enough money. We're good taking our little", "tokens": [50364, 445, 352, 3507, 1460, 412, 6795, 11, 558, 30, 6795, 575, 1547, 1460, 13, 492, 434, 665, 1940, 527, 707, 50594], "temperature": 0.0, "avg_logprob": -0.16735877338637653, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.003426757175475359}, {"id": 314, "seek": 192636, "start": 1930.9599999999998, "end": 1934.3999999999999, "text": " community and putting it there. And we didn't want to go do the same thing at another cloud", "tokens": [50594, 1768, 293, 3372, 309, 456, 13, 400, 321, 994, 380, 528, 281, 352, 360, 264, 912, 551, 412, 1071, 4588, 50766], "temperature": 0.0, "avg_logprob": -0.16735877338637653, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.003426757175475359}, {"id": 315, "seek": 192636, "start": 1934.3999999999999, "end": 1939.6, "text": " provider. So ultimately, we made the decision to go to Hetzner in Germany. Whoo, Hetzner.", "tokens": [50766, 12398, 13, 407, 6284, 11, 321, 1027, 264, 3537, 281, 352, 281, 389, 10074, 1193, 294, 7244, 13, 23381, 11, 389, 10074, 1193, 13, 51026], "temperature": 0.0, "avg_logprob": -0.16735877338637653, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.003426757175475359}, {"id": 316, "seek": 192636, "start": 1939.6, "end": 1950.9199999999998, "text": " Another good caveat here is that from a legal perspective, Germany has some of the most restrictive", "tokens": [51026, 3996, 665, 43012, 510, 307, 300, 490, 257, 5089, 4585, 11, 7244, 575, 512, 295, 264, 881, 43220, 51592], "temperature": 0.0, "avg_logprob": -0.16735877338637653, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.003426757175475359}, {"id": 317, "seek": 192636, "start": 1950.9199999999998, "end": 1955.6399999999999, "text": " privacy laws. And so this is going to be about the most isolated zone we're going to get in today.", "tokens": [51592, 11427, 6064, 13, 400, 370, 341, 307, 516, 281, 312, 466, 264, 881, 14621, 6668, 321, 434, 516, 281, 483, 294, 965, 13, 51828], "temperature": 0.0, "avg_logprob": -0.16735877338637653, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.003426757175475359}, {"id": 318, "seek": 195564, "start": 1956.0400000000002, "end": 1961.24, "text": " And a quick glance and a quick consultation with a lawyer told us that Germany was going to be the", "tokens": [50384, 400, 257, 1702, 21094, 293, 257, 1702, 20932, 365, 257, 11613, 1907, 505, 300, 7244, 390, 516, 281, 312, 264, 50644], "temperature": 0.0, "avg_logprob": -0.11668162229584485, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.01062631607055664}, {"id": 319, "seek": 195564, "start": 1961.24, "end": 1967.1200000000001, "text": " safest place to start the service from. So again, our biggest concerns had almost nothing to do", "tokens": [50644, 37558, 1081, 281, 722, 264, 2643, 490, 13, 407, 797, 11, 527, 3880, 7389, 632, 1920, 1825, 281, 360, 50938], "temperature": 0.0, "avg_logprob": -0.11668162229584485, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.01062631607055664}, {"id": 320, "seek": 195564, "start": 1967.1200000000001, "end": 1972.3600000000001, "text": " with the crappy disks in my basement and almost everything to do with like international privacy", "tokens": [50938, 365, 264, 36531, 41617, 294, 452, 16893, 293, 1920, 1203, 281, 360, 365, 411, 5058, 11427, 51200], "temperature": 0.0, "avg_logprob": -0.11668162229584485, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.01062631607055664}, {"id": 321, "seek": 195564, "start": 1972.3600000000001, "end": 1978.1200000000001, "text": " law and user data. And we've very quickly found ourselves having discussions about the complications", "tokens": [51200, 2101, 293, 4195, 1412, 13, 400, 321, 600, 588, 2661, 1352, 4175, 1419, 11088, 466, 264, 26566, 51488], "temperature": 0.0, "avg_logprob": -0.11668162229584485, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.01062631607055664}, {"id": 322, "seek": 197812, "start": 1978.12, "end": 1986.84, "text": " and implications of operating a global service. So here is our most recent diagram of how we", "tokens": [50364, 293, 16602, 295, 7447, 257, 4338, 2643, 13, 407, 510, 307, 527, 881, 5162, 10686, 295, 577, 321, 50800], "temperature": 0.0, "avg_logprob": -0.09820880684801327, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.21883922815322876}, {"id": 323, "seek": 197812, "start": 1986.84, "end": 1991.84, "text": " kind of set things up. You can see that we had to balance things in my basement with things in", "tokens": [50800, 733, 295, 992, 721, 493, 13, 509, 393, 536, 300, 321, 632, 281, 4772, 721, 294, 452, 16893, 365, 721, 294, 51050], "temperature": 0.0, "avg_logprob": -0.09820880684801327, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.21883922815322876}, {"id": 324, "seek": 197812, "start": 1991.84, "end": 1998.28, "text": " Germany. And you can see that we have a set of CDN or point of presence nodes around the world. So", "tokens": [51050, 7244, 13, 400, 291, 393, 536, 300, 321, 362, 257, 992, 295, 6743, 45, 420, 935, 295, 6814, 13891, 926, 264, 1002, 13, 407, 51372], "temperature": 0.0, "avg_logprob": -0.09820880684801327, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.21883922815322876}, {"id": 325, "seek": 197812, "start": 1998.28, "end": 2003.04, "text": " it was very exciting for me when I flew across the ocean from Seattle to come here to Brussels,", "tokens": [51372, 309, 390, 588, 4670, 337, 385, 562, 286, 15728, 2108, 264, 7810, 490, 15721, 281, 808, 510, 281, 38717, 11, 51610], "temperature": 0.0, "avg_logprob": -0.09820880684801327, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.21883922815322876}, {"id": 326, "seek": 200304, "start": 2003.72, "end": 2008.52, "text": " because for the first time our service, since the outage, was actually fast and responsive again", "tokens": [50398, 570, 337, 264, 700, 565, 527, 2643, 11, 1670, 264, 484, 609, 11, 390, 767, 2370, 293, 21826, 797, 50638], "temperature": 0.0, "avg_logprob": -0.12300465232447574, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.015390259213745594}, {"id": 327, "seek": 200304, "start": 2008.52, "end": 2014.48, "text": " because I am now being proxied through another server now that I am here on a different continent.", "tokens": [50638, 570, 286, 669, 586, 885, 447, 87, 1091, 807, 1071, 7154, 586, 300, 286, 669, 510, 322, 257, 819, 18932, 13, 50936], "temperature": 0.0, "avg_logprob": -0.12300465232447574, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.015390259213745594}, {"id": 328, "seek": 200304, "start": 2016.24, "end": 2021.04, "text": " So now what? Okay, so we've reached the point of stability. Our servers are stable. People are", "tokens": [51024, 407, 586, 437, 30, 1033, 11, 370, 321, 600, 6488, 264, 935, 295, 11826, 13, 2621, 15909, 366, 8351, 13, 3432, 366, 51264], "temperature": 0.0, "avg_logprob": -0.12300465232447574, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.015390259213745594}, {"id": 329, "seek": 200304, "start": 2021.04, "end": 2026.44, "text": " able to send their Rooster videos again. And we're still very much not out of the weeds. We still", "tokens": [51264, 1075, 281, 2845, 641, 3101, 7096, 2145, 797, 13, 400, 321, 434, 920, 588, 709, 406, 484, 295, 264, 26370, 13, 492, 920, 51534], "temperature": 0.0, "avg_logprob": -0.12300465232447574, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.015390259213745594}, {"id": 330, "seek": 202644, "start": 2026.48, "end": 2033.76, "text": " have a lot of concerns we need to deal with. So in general, the top Ruby monolith problems that", "tokens": [50366, 362, 257, 688, 295, 7389, 321, 643, 281, 2028, 365, 13, 407, 294, 2674, 11, 264, 1192, 19907, 1108, 29131, 2740, 300, 50730], "temperature": 0.0, "avg_logprob": -0.14270960800046842, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.017962731420993805}, {"id": 331, "seek": 202644, "start": 2033.76, "end": 2040.48, "text": " we have solved to date is sidekick scaling, which if you've ever, who's here has operated sidekick", "tokens": [50730, 321, 362, 13041, 281, 4002, 307, 1252, 42427, 21589, 11, 597, 498, 291, 600, 1562, 11, 567, 311, 510, 575, 20826, 1252, 42427, 51066], "temperature": 0.0, "avg_logprob": -0.14270960800046842, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.017962731420993805}, {"id": 332, "seek": 202644, "start": 2040.48, "end": 2046.24, "text": " before? It's a Ruby thing, show of hands. It's like a Ruby daemon that you have to specify the", "tokens": [51066, 949, 30, 467, 311, 257, 19907, 551, 11, 855, 295, 2377, 13, 467, 311, 411, 257, 19907, 1120, 36228, 300, 291, 362, 281, 16500, 264, 51354], "temperature": 0.0, "avg_logprob": -0.14270960800046842, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.017962731420993805}, {"id": 333, "seek": 202644, "start": 2046.24, "end": 2050.84, "text": " amount of threads and concurrent workers at runtime. And mastodon is built on this. So like", "tokens": [51354, 2372, 295, 19314, 293, 37702, 5600, 412, 34474, 13, 400, 27055, 378, 266, 307, 3094, 322, 341, 13, 407, 411, 51584], "temperature": 0.0, "avg_logprob": -0.14270960800046842, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.017962731420993805}, {"id": 334, "seek": 202644, "start": 2050.84, "end": 2055.12, "text": " every time we federate with a server, there's a whole queue that runs in the background that does", "tokens": [51584, 633, 565, 321, 38024, 473, 365, 257, 7154, 11, 456, 311, 257, 1379, 18639, 300, 6676, 294, 264, 3678, 300, 775, 51798], "temperature": 0.0, "avg_logprob": -0.14270960800046842, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.017962731420993805}, {"id": 335, "seek": 205512, "start": 2055.16, "end": 2060.16, "text": " the federation for us. We've also had to tackle network scaling, and we have a global CDN with", "tokens": [50366, 264, 4636, 5053, 337, 505, 13, 492, 600, 611, 632, 281, 14896, 3209, 21589, 11, 293, 321, 362, 257, 4338, 6743, 45, 365, 50616], "temperature": 0.0, "avg_logprob": -0.13993459893751514, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.004257093649357557}, {"id": 336, "seek": 205512, "start": 2060.16, "end": 2065.52, "text": " reverse nginx proxies that has a cache on the edge so that the more people who look at an image,", "tokens": [50616, 9943, 297, 1494, 87, 447, 87, 530, 300, 575, 257, 19459, 322, 264, 4691, 370, 300, 264, 544, 561, 567, 574, 412, 364, 3256, 11, 50884], "temperature": 0.0, "avg_logprob": -0.13993459893751514, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.004257093649357557}, {"id": 337, "seek": 205512, "start": 2065.52, "end": 2070.24, "text": " the more it's served from the cache. And all of those have legal implications. And it's just", "tokens": [50884, 264, 544, 309, 311, 7584, 490, 264, 19459, 13, 400, 439, 295, 729, 362, 5089, 16602, 13, 400, 309, 311, 445, 51120], "temperature": 0.0, "avg_logprob": -0.13993459893751514, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.004257093649357557}, {"id": 338, "seek": 205512, "start": 2070.24, "end": 2074.88, "text": " been a lot of work that we've had to get into to just operate a basic service so that we can all", "tokens": [51120, 668, 257, 688, 295, 589, 300, 321, 600, 632, 281, 483, 666, 281, 445, 9651, 257, 3875, 2643, 370, 300, 321, 393, 439, 51352], "temperature": 0.0, "avg_logprob": -0.13993459893751514, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.004257093649357557}, {"id": 339, "seek": 205512, "start": 2074.88, "end": 2079.6, "text": " sit here in this room and I can make the joke, please go DDoS my web server on the back end.", "tokens": [51352, 1394, 510, 294, 341, 1808, 293, 286, 393, 652, 264, 7647, 11, 1767, 352, 413, 7653, 50, 452, 3670, 7154, 322, 264, 646, 917, 13, 51588], "temperature": 0.0, "avg_logprob": -0.13993459893751514, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.004257093649357557}, {"id": 340, "seek": 207960, "start": 2080.3199999999997, "end": 2087.2, "text": " So here's a graph of our egress data. So the top of the graph here is roughly one terabyte of", "tokens": [50400, 407, 510, 311, 257, 4295, 295, 527, 308, 3091, 1412, 13, 407, 264, 1192, 295, 264, 4295, 510, 307, 9810, 472, 1796, 34529, 295, 50744], "temperature": 0.0, "avg_logprob": -0.17961557629038988, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.0029790233820676804}, {"id": 341, "seek": 207960, "start": 2087.2, "end": 2094.72, "text": " data per day. So you can see that looks like over on January 26th, we peaked over a terabyte of", "tokens": [50744, 1412, 680, 786, 13, 407, 291, 393, 536, 300, 1542, 411, 670, 322, 7061, 7551, 392, 11, 321, 520, 7301, 670, 257, 1796, 34529, 295, 51120], "temperature": 0.0, "avg_logprob": -0.17961557629038988, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.0029790233820676804}, {"id": 342, "seek": 207960, "start": 2094.72, "end": 2101.2, "text": " egress data. So that's honestly from an enterprise and scale perspective, this is no trivial amount", "tokens": [51120, 308, 3091, 1412, 13, 407, 300, 311, 6095, 490, 364, 14132, 293, 4373, 4585, 11, 341, 307, 572, 26703, 2372, 51444], "temperature": 0.0, "avg_logprob": -0.17961557629038988, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.0029790233820676804}, {"id": 343, "seek": 207960, "start": 2101.2, "end": 2106.08, "text": " of data, right? We're moving a lot of data across the wire and the fact that Hetzner can support", "tokens": [51444, 295, 1412, 11, 558, 30, 492, 434, 2684, 257, 688, 295, 1412, 2108, 264, 6234, 293, 264, 1186, 300, 389, 10074, 1193, 393, 1406, 51688], "temperature": 0.0, "avg_logprob": -0.17961557629038988, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.0029790233820676804}, {"id": 344, "seek": 210608, "start": 2106.08, "end": 2114.24, "text": " us is very nice and seems to be working well for our needs today. Another interesting thing", "tokens": [50364, 505, 307, 588, 1481, 293, 2544, 281, 312, 1364, 731, 337, 527, 2203, 965, 13, 3996, 1880, 551, 50772], "temperature": 0.0, "avg_logprob": -0.07671581302677188, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.0018082543974742293}, {"id": 345, "seek": 210608, "start": 2114.24, "end": 2119.2, "text": " about just federation in general that we've had to kind of learn as a community is there's actually", "tokens": [50772, 466, 445, 4636, 5053, 294, 2674, 300, 321, 600, 632, 281, 733, 295, 1466, 382, 257, 1768, 307, 456, 311, 767, 51020], "temperature": 0.0, "avg_logprob": -0.07671581302677188, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.0018082543974742293}, {"id": 346, "seek": 210608, "start": 2119.2, "end": 2124.7999999999997, "text": " a lot of moderation consequences. And there's a pretty big user data and user privacy risk", "tokens": [51020, 257, 688, 295, 49471, 10098, 13, 400, 456, 311, 257, 1238, 955, 4195, 1412, 293, 4195, 11427, 3148, 51300], "temperature": 0.0, "avg_logprob": -0.07671581302677188, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.0018082543974742293}, {"id": 347, "seek": 210608, "start": 2124.7999999999997, "end": 2130.56, "text": " with operating mastodon. And so I put this sort of diagram together to just illustrate some of", "tokens": [51300, 365, 7447, 27055, 378, 266, 13, 400, 370, 286, 829, 341, 1333, 295, 10686, 1214, 281, 445, 23221, 512, 295, 51588], "temperature": 0.0, "avg_logprob": -0.07671581302677188, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.0018082543974742293}, {"id": 348, "seek": 210608, "start": 2130.56, "end": 2135.2799999999997, "text": " the consequences that we've had to deal with. In this case, we have three instances, one friendly,", "tokens": [51588, 264, 10098, 300, 321, 600, 632, 281, 2028, 365, 13, 682, 341, 1389, 11, 321, 362, 1045, 14519, 11, 472, 9208, 11, 51824], "temperature": 0.0, "avg_logprob": -0.07671581302677188, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.0018082543974742293}, {"id": 349, "seek": 213528, "start": 2135.28, "end": 2140.4, "text": " one neutral, and one evil. And even if the friendly instance decided to block the evil", "tokens": [50364, 472, 10598, 11, 293, 472, 6724, 13, 400, 754, 498, 264, 9208, 5197, 3047, 281, 3461, 264, 6724, 50620], "temperature": 0.0, "avg_logprob": -0.062182199123293855, "compression_ratio": 1.695067264573991, "no_speech_prob": 0.005378041882067919}, {"id": 350, "seek": 213528, "start": 2140.4, "end": 2146.88, "text": " instance for whatever reason they deemed to be a cause for that blocking, it's still able for", "tokens": [50620, 5197, 337, 2035, 1778, 436, 27637, 281, 312, 257, 3082, 337, 300, 17776, 11, 309, 311, 920, 1075, 337, 50944], "temperature": 0.0, "avg_logprob": -0.062182199123293855, "compression_ratio": 1.695067264573991, "no_speech_prob": 0.005378041882067919}, {"id": 351, "seek": 213528, "start": 2146.88, "end": 2152.4, "text": " content to get out and to end up federating with another instance. I think what's important about", "tokens": [50944, 2701, 281, 483, 484, 293, 281, 917, 493, 38024, 990, 365, 1071, 5197, 13, 286, 519, 437, 311, 1021, 466, 51220], "temperature": 0.0, "avg_logprob": -0.062182199123293855, "compression_ratio": 1.695067264573991, "no_speech_prob": 0.005378041882067919}, {"id": 352, "seek": 213528, "start": 2152.4, "end": 2158.7200000000003, "text": " this is this means that we can end up with content that is potentially illegal in the United States", "tokens": [51220, 341, 307, 341, 1355, 300, 321, 393, 917, 493, 365, 2701, 300, 307, 7263, 11905, 294, 264, 2824, 3040, 51536], "temperature": 0.0, "avg_logprob": -0.062182199123293855, "compression_ratio": 1.695067264573991, "no_speech_prob": 0.005378041882067919}, {"id": 353, "seek": 215872, "start": 2159.52, "end": 2165.6, "text": " or illegal to have without like an 18 and up warning that puts myself, my family, and everybody", "tokens": [50404, 420, 11905, 281, 362, 1553, 411, 364, 2443, 293, 493, 9164, 300, 8137, 2059, 11, 452, 1605, 11, 293, 2201, 50708], "temperature": 0.0, "avg_logprob": -0.08875632719560103, "compression_ratio": 1.675, "no_speech_prob": 0.3808135390281677}, {"id": 354, "seek": 215872, "start": 2165.6, "end": 2171.04, "text": " who works on Hackaderm at risk. And so we've been trying hard to figure out how do we actually", "tokens": [50708, 567, 1985, 322, 35170, 345, 966, 412, 3148, 13, 400, 370, 321, 600, 668, 1382, 1152, 281, 2573, 484, 577, 360, 321, 767, 50980], "temperature": 0.0, "avg_logprob": -0.08875632719560103, "compression_ratio": 1.675, "no_speech_prob": 0.3808135390281677}, {"id": 355, "seek": 215872, "start": 2171.04, "end": 2176.16, "text": " manage content and actually get to a point where we can manage this in an effective way. And let", "tokens": [50980, 3067, 2701, 293, 767, 483, 281, 257, 935, 689, 321, 393, 3067, 341, 294, 364, 4942, 636, 13, 400, 718, 51236], "temperature": 0.0, "avg_logprob": -0.08875632719560103, "compression_ratio": 1.675, "no_speech_prob": 0.3808135390281677}, {"id": 356, "seek": 215872, "start": 2176.16, "end": 2182.8799999999997, "text": " me just say I cannot thank the content warning feature on mastodon enough because that actually", "tokens": [51236, 385, 445, 584, 286, 2644, 1309, 264, 2701, 9164, 4111, 322, 27055, 378, 266, 1547, 570, 300, 767, 51572], "temperature": 0.0, "avg_logprob": -0.08875632719560103, "compression_ratio": 1.675, "no_speech_prob": 0.3808135390281677}, {"id": 357, "seek": 215872, "start": 2182.8799999999997, "end": 2186.16, "text": " gives us a lot of insight into the types of things that could potentially be harmful.", "tokens": [51572, 2709, 505, 257, 688, 295, 11269, 666, 264, 3467, 295, 721, 300, 727, 7263, 312, 19727, 13, 51736], "temperature": 0.0, "avg_logprob": -0.08875632719560103, "compression_ratio": 1.675, "no_speech_prob": 0.3808135390281677}, {"id": 358, "seek": 218616, "start": 2186.8799999999997, "end": 2193.68, "text": " So ultimately, we had a lot of top non-Ruby monolith problems. So obviously, there was illegal", "tokens": [50400, 407, 6284, 11, 321, 632, 257, 688, 295, 1192, 2107, 12, 49, 836, 88, 1108, 29131, 2740, 13, 407, 2745, 11, 456, 390, 11905, 50740], "temperature": 0.0, "avg_logprob": -0.1277631573972449, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0030264840461313725}, {"id": 359, "seek": 218616, "start": 2193.68, "end": 2200.24, "text": " concern. We have a team of moderators working around the clock who just deal with trolls and", "tokens": [50740, 3136, 13, 492, 362, 257, 1469, 295, 10494, 3391, 1364, 926, 264, 7830, 567, 445, 2028, 365, 47749, 293, 51068], "temperature": 0.0, "avg_logprob": -0.1277631573972449, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0030264840461313725}, {"id": 360, "seek": 218616, "start": 2200.24, "end": 2205.52, "text": " people who are causing problems and bad actors, and they're having to make judgment calls. And we", "tokens": [51068, 561, 567, 366, 9853, 2740, 293, 1578, 10037, 11, 293, 436, 434, 1419, 281, 652, 12216, 5498, 13, 400, 321, 51332], "temperature": 0.0, "avg_logprob": -0.1277631573972449, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0030264840461313725}, {"id": 361, "seek": 218616, "start": 2205.52, "end": 2210.48, "text": " have to establish rules, and these rules need to be enforced, and we have to respond to people,", "tokens": [51332, 362, 281, 8327, 4474, 11, 293, 613, 4474, 643, 281, 312, 40953, 11, 293, 321, 362, 281, 4196, 281, 561, 11, 51580], "temperature": 0.0, "avg_logprob": -0.1277631573972449, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0030264840461313725}, {"id": 362, "seek": 218616, "start": 2210.48, "end": 2215.6, "text": " and people have really good reasons. There's videos out there that are very disruptive,", "tokens": [51580, 293, 561, 362, 534, 665, 4112, 13, 821, 311, 2145, 484, 456, 300, 366, 588, 37865, 11, 51836], "temperature": 0.0, "avg_logprob": -0.1277631573972449, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0030264840461313725}, {"id": 363, "seek": 221560, "start": 2215.6, "end": 2219.6, "text": " and we have to go respond to them. And it takes a lot of work just to balance that on the back end.", "tokens": [50364, 293, 321, 362, 281, 352, 4196, 281, 552, 13, 400, 309, 2516, 257, 688, 295, 589, 445, 281, 4772, 300, 322, 264, 646, 917, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1017654803620667, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.004603344481438398}, {"id": 364, "seek": 221560, "start": 2220.24, "end": 2224.48, "text": " And the whole thing is ran by volunteers. And ultimately, where we are right now is we're", "tokens": [50596, 400, 264, 1379, 551, 307, 5872, 538, 14352, 13, 400, 6284, 11, 689, 321, 366, 558, 586, 307, 321, 434, 50808], "temperature": 0.0, "avg_logprob": -0.1017654803620667, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.004603344481438398}, {"id": 365, "seek": 221560, "start": 2224.48, "end": 2231.7599999999998, "text": " spending roughly 1000 euro a month in hosting costs alone between the digital ocean bill,", "tokens": [50808, 6434, 9810, 9714, 14206, 257, 1618, 294, 16058, 5497, 3312, 1296, 264, 4562, 7810, 2961, 11, 51172], "temperature": 0.0, "avg_logprob": -0.1017654803620667, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.004603344481438398}, {"id": 366, "seek": 221560, "start": 2231.7599999999998, "end": 2236.7999999999997, "text": " the Hetzner bill. We have an email API. So every time you go and you sign up for the service,", "tokens": [51172, 264, 389, 10074, 1193, 2961, 13, 492, 362, 364, 3796, 9362, 13, 407, 633, 565, 291, 352, 293, 291, 1465, 493, 337, 264, 2643, 11, 51424], "temperature": 0.0, "avg_logprob": -0.1017654803620667, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.004603344481438398}, {"id": 367, "seek": 221560, "start": 2236.7999999999997, "end": 2242.56, "text": " you have to get an email so we can validate who you are. And all of this is coming from", "tokens": [51424, 291, 362, 281, 483, 364, 3796, 370, 321, 393, 29562, 567, 291, 366, 13, 400, 439, 295, 341, 307, 1348, 490, 51712], "temperature": 0.0, "avg_logprob": -0.1017654803620667, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.004603344481438398}, {"id": 368, "seek": 224256, "start": 2242.64, "end": 2249.6, "text": " donations as they exist today. Okay. So if you want to learn more about Hackaderm,", "tokens": [50368, 22705, 382, 436, 2514, 965, 13, 1033, 13, 407, 498, 291, 528, 281, 1466, 544, 466, 35170, 345, 966, 11, 50716], "temperature": 0.0, "avg_logprob": -0.10877918160480002, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.003531013149768114}, {"id": 369, "seek": 224256, "start": 2249.6, "end": 2254.08, "text": " the community, and how we run things, we have a dedicated community resource. If you want to go", "tokens": [50716, 264, 1768, 11, 293, 577, 321, 1190, 721, 11, 321, 362, 257, 8374, 1768, 7684, 13, 759, 291, 528, 281, 352, 50940], "temperature": 0.0, "avg_logprob": -0.10877918160480002, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.003531013149768114}, {"id": 370, "seek": 224256, "start": 2254.08, "end": 2258.4, "text": " grab and check it out, that's where we do things like announce our rules and our policies, and we", "tokens": [50940, 4444, 293, 1520, 309, 484, 11, 300, 311, 689, 321, 360, 721, 411, 7478, 527, 4474, 293, 527, 7657, 11, 293, 321, 51156], "temperature": 0.0, "avg_logprob": -0.10877918160480002, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.003531013149768114}, {"id": 371, "seek": 224256, "start": 2258.4, "end": 2266.0, "text": " document how we make moderation decisions in general. So the consequence of all of this is we've", "tokens": [51156, 4166, 577, 321, 652, 49471, 5327, 294, 2674, 13, 407, 264, 18326, 295, 439, 295, 341, 307, 321, 600, 51536], "temperature": 0.0, "avg_logprob": -0.10877918160480002, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.003531013149768114}, {"id": 372, "seek": 226600, "start": 2266.0, "end": 2272.4, "text": " decided to found a new foundation called the Nivenly Foundation, which that's very exciting.", "tokens": [50364, 3047, 281, 1352, 257, 777, 7030, 1219, 264, 426, 5709, 356, 10335, 11, 597, 300, 311, 588, 4670, 13, 50684], "temperature": 0.0, "avg_logprob": -0.14147276519447244, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.022189849987626076}, {"id": 373, "seek": 226600, "start": 2277.12, "end": 2282.16, "text": " So the name is just it's just the name of my blog that we turned into a 501c3.", "tokens": [50920, 407, 264, 1315, 307, 445, 309, 311, 445, 264, 1315, 295, 452, 6968, 300, 321, 3574, 666, 257, 2625, 16, 66, 18, 13, 51172], "temperature": 0.0, "avg_logprob": -0.14147276519447244, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.022189849987626076}, {"id": 374, "seek": 226600, "start": 2282.8, "end": 2287.36, "text": " And I kind of like most things in my life, I kind of want this foundation to be relatively boring,", "tokens": [51204, 400, 286, 733, 295, 411, 881, 721, 294, 452, 993, 11, 286, 733, 295, 528, 341, 7030, 281, 312, 7226, 9989, 11, 51432], "temperature": 0.0, "avg_logprob": -0.14147276519447244, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.022189849987626076}, {"id": 375, "seek": 226600, "start": 2287.36, "end": 2293.44, "text": " but this will be the legal entity that will be used to protect Hackaderm and to hopefully", "tokens": [51432, 457, 341, 486, 312, 264, 5089, 13977, 300, 486, 312, 1143, 281, 2371, 35170, 345, 966, 293, 281, 4696, 51736], "temperature": 0.0, "avg_logprob": -0.14147276519447244, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.022189849987626076}, {"id": 376, "seek": 229344, "start": 2293.52, "end": 2299.04, "text": " fund the process moving forward. So right now the Nivenly Foundation has two projects, one of", "tokens": [50368, 2374, 264, 1399, 2684, 2128, 13, 407, 558, 586, 264, 426, 5709, 356, 10335, 575, 732, 4455, 11, 472, 295, 50644], "temperature": 0.0, "avg_logprob": -0.09730250434537904, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.014488822780549526}, {"id": 377, "seek": 229344, "start": 2299.04, "end": 2303.68, "text": " which I talked about yesterday called Aura, which is a distributed runtime written in Rust,", "tokens": [50644, 597, 286, 2825, 466, 5186, 1219, 316, 2991, 11, 597, 307, 257, 12631, 34474, 3720, 294, 34952, 11, 50876], "temperature": 0.0, "avg_logprob": -0.09730250434537904, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.014488822780549526}, {"id": 378, "seek": 229344, "start": 2303.68, "end": 2310.2400000000002, "text": " and we also have Hackaderm. This is exciting because we this feels like the 90s. We have an", "tokens": [50876, 293, 321, 611, 362, 35170, 345, 966, 13, 639, 307, 4670, 570, 321, 341, 3417, 411, 264, 4289, 82, 13, 492, 362, 364, 51204], "temperature": 0.0, "avg_logprob": -0.09730250434537904, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.014488822780549526}, {"id": 379, "seek": 229344, "start": 2310.2400000000002, "end": 2315.44, "text": " open source service. This isn't an open source project that you can go download. We like legit", "tokens": [51204, 1269, 4009, 2643, 13, 639, 1943, 380, 364, 1269, 4009, 1716, 300, 291, 393, 352, 5484, 13, 492, 411, 10275, 51464], "temperature": 0.0, "avg_logprob": -0.09730250434537904, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.014488822780549526}, {"id": 380, "seek": 229344, "start": 2315.44, "end": 2320.64, "text": " have an open source service with graphs and people with pagers that we have to go and operate.", "tokens": [51464, 362, 364, 1269, 4009, 2643, 365, 24877, 293, 561, 365, 280, 8776, 300, 321, 362, 281, 352, 293, 9651, 13, 51724], "temperature": 0.0, "avg_logprob": -0.09730250434537904, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.014488822780549526}, {"id": 381, "seek": 232064, "start": 2321.52, "end": 2326.56, "text": " And so that's an exciting thing that the Nivenly Foundation gets to do. So I want to introduce", "tokens": [50408, 400, 370, 300, 311, 364, 4670, 551, 300, 264, 426, 5709, 356, 10335, 2170, 281, 360, 13, 407, 286, 528, 281, 5366, 50660], "temperature": 0.0, "avg_logprob": -0.09898295844953085, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.001408430514857173}, {"id": 382, "seek": 232064, "start": 2326.56, "end": 2331.7599999999998, "text": " my wonderful partner who's not here, who is the executive director of the Nivenly Foundation,", "tokens": [50660, 452, 3715, 4975, 567, 311, 406, 510, 11, 567, 307, 264, 10140, 5391, 295, 264, 426, 5709, 356, 10335, 11, 50920], "temperature": 0.0, "avg_logprob": -0.09898295844953085, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.001408430514857173}, {"id": 383, "seek": 232064, "start": 2331.7599999999998, "end": 2338.48, "text": " and also the person that we hopefully didn't just wake up by d-dossing the server. Anyway,", "tokens": [50920, 293, 611, 264, 954, 300, 321, 4696, 994, 380, 445, 6634, 493, 538, 274, 12, 67, 35652, 264, 7154, 13, 5684, 11, 51256], "temperature": 0.0, "avg_logprob": -0.09898295844953085, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.001408430514857173}, {"id": 384, "seek": 232064, "start": 2338.48, "end": 2343.52, "text": " she does the majority of the work and she couldn't be here today, but can we just give her a round", "tokens": [51256, 750, 775, 264, 6286, 295, 264, 589, 293, 750, 2809, 380, 312, 510, 965, 11, 457, 393, 321, 445, 976, 720, 257, 3098, 51508], "temperature": 0.0, "avg_logprob": -0.09898295844953085, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.001408430514857173}, {"id": 385, "seek": 234352, "start": 2343.6, "end": 2355.6, "text": " of applause? Because she is actually the one who gets everything done. So she manages the", "tokens": [50368, 295, 9969, 30, 1436, 750, 307, 767, 264, 472, 567, 2170, 1203, 1096, 13, 407, 750, 22489, 264, 50968], "temperature": 0.0, "avg_logprob": -0.0830402318821397, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.09252707660198212}, {"id": 386, "seek": 234352, "start": 2355.6, "end": 2360.24, "text": " infrastructure team right now. She's managing the moderator team right now. She even created these", "tokens": [50968, 6896, 1469, 558, 586, 13, 1240, 311, 11642, 264, 37778, 1469, 558, 586, 13, 1240, 754, 2942, 613, 51200], "temperature": 0.0, "avg_logprob": -0.0830402318821397, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.09252707660198212}, {"id": 387, "seek": 234352, "start": 2360.24, "end": 2364.64, "text": " teams in the first place because people were freaking out and didn't know what to do. And so", "tokens": [51200, 5491, 294, 264, 700, 1081, 570, 561, 645, 14612, 484, 293, 994, 380, 458, 437, 281, 360, 13, 400, 370, 51420], "temperature": 0.0, "avg_logprob": -0.0830402318821397, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.09252707660198212}, {"id": 388, "seek": 234352, "start": 2364.64, "end": 2369.52, "text": " she wakes up every morning and deals with everything that Hackaderm throws at her, and I honestly", "tokens": [51420, 750, 29610, 493, 633, 2446, 293, 11215, 365, 1203, 300, 35170, 345, 966, 19251, 412, 720, 11, 293, 286, 6095, 51664], "temperature": 0.0, "avg_logprob": -0.0830402318821397, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.09252707660198212}, {"id": 389, "seek": 236952, "start": 2370.16, "end": 2375.12, "text": " thank her enough for the hard work that she's done. So one of the problems we've had to solve is a", "tokens": [50396, 1309, 720, 1547, 337, 264, 1152, 589, 300, 750, 311, 1096, 13, 407, 472, 295, 264, 2740, 321, 600, 632, 281, 5039, 307, 257, 50644], "temperature": 0.0, "avg_logprob": -0.0895456416266305, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.008308077231049538}, {"id": 390, "seek": 236952, "start": 2375.12, "end": 2379.7599999999998, "text": " governance model for this whole thing. So we now have an open source service. There's legal risks", "tokens": [50644, 17449, 2316, 337, 341, 1379, 551, 13, 407, 321, 586, 362, 364, 1269, 4009, 2643, 13, 821, 311, 5089, 10888, 50876], "temperature": 0.0, "avg_logprob": -0.0895456416266305, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.008308077231049538}, {"id": 391, "seek": 236952, "start": 2379.7599999999998, "end": 2386.24, "text": " and how are we going to make decisions as a nonprofit. And so we started to look at some of", "tokens": [50876, 293, 577, 366, 321, 516, 281, 652, 5327, 382, 257, 23348, 13, 400, 370, 321, 1409, 281, 574, 412, 512, 295, 51200], "temperature": 0.0, "avg_logprob": -0.0895456416266305, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.008308077231049538}, {"id": 392, "seek": 236952, "start": 2386.24, "end": 2393.7599999999998, "text": " the consequences of modern day social media and some of the consequences of how corporations are", "tokens": [51200, 264, 10098, 295, 4363, 786, 2093, 3021, 293, 512, 295, 264, 10098, 295, 577, 17676, 366, 51576], "temperature": 0.0, "avg_logprob": -0.0895456416266305, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.008308077231049538}, {"id": 393, "seek": 236952, "start": 2393.7599999999998, "end": 2399.04, "text": " navigating different open source spaces. And some of the things I noticed was for the most part,", "tokens": [51576, 32054, 819, 1269, 4009, 7673, 13, 400, 512, 295, 264, 721, 286, 5694, 390, 337, 264, 881, 644, 11, 51840], "temperature": 0.0, "avg_logprob": -0.0895456416266305, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.008308077231049538}, {"id": 394, "seek": 239904, "start": 2399.2799999999997, "end": 2405.36, "text": " on Twitter especially, communities are very isolated from decisions. Users are detached from", "tokens": [50376, 322, 5794, 2318, 11, 4456, 366, 588, 14621, 490, 5327, 13, 47092, 366, 42050, 490, 50680], "temperature": 0.0, "avg_logprob": -0.0659102751658513, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.001726416521705687}, {"id": 395, "seek": 239904, "start": 2405.36, "end": 2411.6, "text": " the technology and how things are done. And people are usually unable to impact change. So I had", "tokens": [50680, 264, 2899, 293, 577, 721, 366, 1096, 13, 400, 561, 366, 2673, 11299, 281, 2712, 1319, 13, 407, 286, 632, 50992], "temperature": 0.0, "avg_logprob": -0.0659102751658513, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.001726416521705687}, {"id": 396, "seek": 239904, "start": 2411.6, "end": 2416.8, "text": " gotten into some trouble with Twitter. They banned my account. I wasn't able to talk to anyone. I had", "tokens": [50992, 5768, 666, 512, 5253, 365, 5794, 13, 814, 19564, 452, 2696, 13, 286, 2067, 380, 1075, 281, 751, 281, 2878, 13, 286, 632, 51252], "temperature": 0.0, "avg_logprob": -0.0659102751658513, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.001726416521705687}, {"id": 397, "seek": 239904, "start": 2416.8, "end": 2421.68, "text": " no avenue in which I could go and actually communicate with this corporation. And that became", "tokens": [51252, 572, 39230, 294, 597, 286, 727, 352, 293, 767, 7890, 365, 341, 22197, 13, 400, 300, 3062, 51496], "temperature": 0.0, "avg_logprob": -0.0659102751658513, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.001726416521705687}, {"id": 398, "seek": 239904, "start": 2421.68, "end": 2425.36, "text": " very problematic for me because I kind of used Twitter for a lot of things professionally.", "tokens": [51496, 588, 19011, 337, 385, 570, 286, 733, 295, 1143, 5794, 337, 257, 688, 295, 721, 27941, 13, 51680], "temperature": 0.0, "avg_logprob": -0.0659102751658513, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.001726416521705687}, {"id": 399, "seek": 242536, "start": 2425.76, "end": 2433.1200000000003, "text": " So what I started to realize was actually corporations usually have more influence and", "tokens": [50384, 407, 437, 286, 1409, 281, 4325, 390, 767, 17676, 2673, 362, 544, 6503, 293, 50752], "temperature": 0.0, "avg_logprob": -0.10049583338483979, "compression_ratio": 1.6891891891891893, "no_speech_prob": 0.0009999459143728018}, {"id": 400, "seek": 242536, "start": 2433.1200000000003, "end": 2439.04, "text": " a better standing in the fabric of the economy than just a regular person does. And so as soon", "tokens": [50752, 257, 1101, 4877, 294, 264, 7253, 295, 264, 5010, 813, 445, 257, 3890, 954, 775, 13, 400, 370, 382, 2321, 51048], "temperature": 0.0, "avg_logprob": -0.10049583338483979, "compression_ratio": 1.6891891891891893, "no_speech_prob": 0.0009999459143728018}, {"id": 401, "seek": 242536, "start": 2439.04, "end": 2445.52, "text": " as I was able to interface with a corporation, I realized that I was no longer isolated from", "tokens": [51048, 382, 286, 390, 1075, 281, 9226, 365, 257, 22197, 11, 286, 5334, 300, 286, 390, 572, 2854, 14621, 490, 51372], "temperature": 0.0, "avg_logprob": -0.10049583338483979, "compression_ratio": 1.6891891891891893, "no_speech_prob": 0.0009999459143728018}, {"id": 402, "seek": 242536, "start": 2445.52, "end": 2451.04, "text": " decisions. And I found that corporations often are not detached from the technology and corporations", "tokens": [51372, 5327, 13, 400, 286, 1352, 300, 17676, 2049, 366, 406, 42050, 490, 264, 2899, 293, 17676, 51648], "temperature": 0.0, "avg_logprob": -0.10049583338483979, "compression_ratio": 1.6891891891891893, "no_speech_prob": 0.0009999459143728018}, {"id": 403, "seek": 245104, "start": 2451.04, "end": 2455.52, "text": " are in fact able to impact change. And I became obsessed with this idea. And I wrote a whole", "tokens": [50364, 366, 294, 1186, 1075, 281, 2712, 1319, 13, 400, 286, 3062, 16923, 365, 341, 1558, 13, 400, 286, 4114, 257, 1379, 50588], "temperature": 0.0, "avg_logprob": -0.09299360622059215, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0055512432008981705}, {"id": 404, "seek": 245104, "start": 2455.52, "end": 2460.32, "text": " book about it. And I could, everywhere I looked, I saw this idea that ultimately corporations seem", "tokens": [50588, 1446, 466, 309, 13, 400, 286, 727, 11, 5315, 286, 2956, 11, 286, 1866, 341, 1558, 300, 6284, 17676, 1643, 50828], "temperature": 0.0, "avg_logprob": -0.09299360622059215, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0055512432008981705}, {"id": 405, "seek": 245104, "start": 2460.32, "end": 2467.6, "text": " to have more rights than people. And that was very difficult for me to reconcile. I also think", "tokens": [50828, 281, 362, 544, 4601, 813, 561, 13, 400, 300, 390, 588, 2252, 337, 385, 281, 41059, 13, 286, 611, 519, 51192], "temperature": 0.0, "avg_logprob": -0.09299360622059215, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0055512432008981705}, {"id": 406, "seek": 245104, "start": 2467.6, "end": 2475.2, "text": " that this general observation explains why we see a lot of this on the Fediverse today. I think", "tokens": [51192, 300, 341, 2674, 14816, 13948, 983, 321, 536, 257, 688, 295, 341, 322, 264, 7772, 5376, 965, 13, 286, 519, 51572], "temperature": 0.0, "avg_logprob": -0.09299360622059215, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0055512432008981705}, {"id": 407, "seek": 245104, "start": 2475.2, "end": 2479.68, "text": " that there is this culture of cyberbullying and assuming that the people operating servers are", "tokens": [51572, 300, 456, 307, 341, 3713, 295, 13411, 37290, 1840, 293, 11926, 300, 264, 561, 7447, 15909, 366, 51796], "temperature": 0.0, "avg_logprob": -0.09299360622059215, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0055512432008981705}, {"id": 408, "seek": 247968, "start": 2479.68, "end": 2485.04, "text": " inherently evil. And I see a lot of criticism instead of a lot of contribution. And somebody", "tokens": [50364, 27993, 6724, 13, 400, 286, 536, 257, 688, 295, 15835, 2602, 295, 257, 688, 295, 13150, 13, 400, 2618, 50632], "temperature": 0.0, "avg_logprob": -0.09498524021457981, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.005628981627523899}, {"id": 409, "seek": 247968, "start": 2485.04, "end": 2490.48, "text": " who comes from open source and I've worked on Linux and FreeBSD and Kubernetes, the Go programming", "tokens": [50632, 567, 1487, 490, 1269, 4009, 293, 286, 600, 2732, 322, 18734, 293, 11551, 8176, 35, 293, 23145, 11, 264, 1037, 9410, 50904], "temperature": 0.0, "avg_logprob": -0.09498524021457981, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.005628981627523899}, {"id": 410, "seek": 247968, "start": 2490.48, "end": 2496.3999999999996, "text": " language, the Rust programming language, it's very difficult for me not to intuitively walk up", "tokens": [50904, 2856, 11, 264, 34952, 9410, 2856, 11, 309, 311, 588, 2252, 337, 385, 406, 281, 46506, 1792, 493, 51200], "temperature": 0.0, "avg_logprob": -0.09498524021457981, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.005628981627523899}, {"id": 411, "seek": 247968, "start": 2496.3999999999996, "end": 2502.16, "text": " to a project and want to contribute. And so I guess this is just my way of saying that Mastodon", "tokens": [51200, 281, 257, 1716, 293, 528, 281, 10586, 13, 400, 370, 286, 2041, 341, 307, 445, 452, 636, 295, 1566, 300, 376, 525, 378, 266, 51488], "temperature": 0.0, "avg_logprob": -0.09498524021457981, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.005628981627523899}, {"id": 412, "seek": 247968, "start": 2502.16, "end": 2507.52, "text": " gives us an opportunity and the Fediverse gives us an opportunity to no longer isolate people", "tokens": [51488, 2709, 505, 364, 2650, 293, 264, 7772, 5376, 2709, 505, 364, 2650, 281, 572, 2854, 25660, 561, 51756], "temperature": 0.0, "avg_logprob": -0.09498524021457981, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.005628981627523899}, {"id": 413, "seek": 250752, "start": 2507.6, "end": 2511.84, "text": " from the folks who are operating their services they use every day. And that's very exciting for", "tokens": [50368, 490, 264, 4024, 567, 366, 7447, 641, 3328, 436, 764, 633, 786, 13, 400, 300, 311, 588, 4670, 337, 50580], "temperature": 0.0, "avg_logprob": -0.05122156143188476, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.00254812091588974}, {"id": 414, "seek": 250752, "start": 2511.84, "end": 2517.92, "text": " me. So in our governing model, we want to figure out a way to balance communities and corporations.", "tokens": [50580, 385, 13, 407, 294, 527, 30054, 2316, 11, 321, 528, 281, 2573, 484, 257, 636, 281, 4772, 4456, 293, 17676, 13, 50884], "temperature": 0.0, "avg_logprob": -0.05122156143188476, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.00254812091588974}, {"id": 415, "seek": 250752, "start": 2517.92, "end": 2522.8, "text": " And this is the hybrid model that I'm hoping will actually be able to create a sustainable", "tokens": [50884, 400, 341, 307, 264, 13051, 2316, 300, 286, 478, 7159, 486, 767, 312, 1075, 281, 1884, 257, 11235, 51128], "temperature": 0.0, "avg_logprob": -0.05122156143188476, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.00254812091588974}, {"id": 416, "seek": 250752, "start": 2522.8, "end": 2528.48, "text": " governing model for what we're doing. So right now, while we think corporate sponsorships are", "tokens": [51128, 30054, 2316, 337, 437, 321, 434, 884, 13, 407, 558, 586, 11, 1339, 321, 519, 10896, 22593, 7640, 366, 51412], "temperature": 0.0, "avg_logprob": -0.05122156143188476, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.00254812091588974}, {"id": 417, "seek": 250752, "start": 2528.48, "end": 2534.08, "text": " important, we're actually going to have two forms of non-corporate sponsorship, which are project", "tokens": [51412, 1021, 11, 321, 434, 767, 516, 281, 362, 732, 6422, 295, 2107, 12, 19558, 2816, 473, 42922, 11, 597, 366, 1716, 51692], "temperature": 0.0, "avg_logprob": -0.05122156143188476, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.00254812091588974}, {"id": 418, "seek": 253408, "start": 2534.08, "end": 2538.96, "text": " members that you can achieve that status to simply by rolling up your sleeves and either", "tokens": [50364, 2679, 300, 291, 393, 4584, 300, 6558, 281, 2935, 538, 9439, 493, 428, 24555, 293, 2139, 50608], "temperature": 0.0, "avg_logprob": -0.07870523203974185, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.014477442018687725}, {"id": 419, "seek": 253408, "start": 2538.96, "end": 2544.24, "text": " contributing a project or becoming a contributor to one of our existing projects, or a general", "tokens": [50608, 19270, 257, 1716, 420, 5617, 257, 42859, 281, 472, 295, 527, 6741, 4455, 11, 420, 257, 2674, 50872], "temperature": 0.0, "avg_logprob": -0.07870523203974185, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.014477442018687725}, {"id": 420, "seek": 253408, "start": 2544.24, "end": 2549.6, "text": " member, which is a small opt-in monthly fee that we have a few hundred people paying for", "tokens": [50872, 4006, 11, 597, 307, 257, 1359, 2427, 12, 259, 12878, 12054, 300, 321, 362, 257, 1326, 3262, 561, 6229, 337, 51140], "temperature": 0.0, "avg_logprob": -0.07870523203974185, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.014477442018687725}, {"id": 421, "seek": 253408, "start": 2549.6, "end": 2554.88, "text": " right now. And the beauty of this is all general members are going to have a vote in how we do", "tokens": [51140, 558, 586, 13, 400, 264, 6643, 295, 341, 307, 439, 2674, 2679, 366, 516, 281, 362, 257, 4740, 294, 577, 321, 360, 51404], "temperature": 0.0, "avg_logprob": -0.07870523203974185, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.014477442018687725}, {"id": 422, "seek": 253408, "start": 2554.88, "end": 2562.0, "text": " things. So if Hackaderm, the Mastodon server, wanted to, let's say, let a tech company have an", "tokens": [51404, 721, 13, 407, 498, 35170, 345, 966, 11, 264, 376, 525, 378, 266, 7154, 11, 1415, 281, 11, 718, 311, 584, 11, 718, 257, 7553, 2237, 362, 364, 51760], "temperature": 0.0, "avg_logprob": -0.07870523203974185, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.014477442018687725}, {"id": 423, "seek": 256200, "start": 2562.0, "end": 2567.52, "text": " account and that became controversial, anybody who makes a monthly donation to the service now", "tokens": [50364, 2696, 293, 300, 3062, 17323, 11, 4472, 567, 1669, 257, 12878, 19724, 281, 264, 2643, 586, 50640], "temperature": 0.0, "avg_logprob": -0.077877508855499, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0022827039938420057}, {"id": 424, "seek": 256200, "start": 2567.52, "end": 2571.04, "text": " is going to be able to have a vote in how we do things. And we're actually going to introduce", "tokens": [50640, 307, 516, 281, 312, 1075, 281, 362, 257, 4740, 294, 577, 321, 360, 721, 13, 400, 321, 434, 767, 516, 281, 5366, 50816], "temperature": 0.0, "avg_logprob": -0.077877508855499, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0022827039938420057}, {"id": 425, "seek": 256200, "start": 2571.04, "end": 2577.12, "text": " a concept of open-source democracy. And we're going to be leveraging open W3C protocols", "tokens": [50816, 257, 3410, 295, 1269, 12, 41676, 10528, 13, 400, 321, 434, 516, 281, 312, 32666, 1269, 343, 18, 34, 20618, 51120], "temperature": 0.0, "avg_logprob": -0.077877508855499, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0022827039938420057}, {"id": 426, "seek": 256200, "start": 2577.12, "end": 2582.0, "text": " to make this happen. And we still have some math to figure out exactly how much this is going to", "tokens": [51120, 281, 652, 341, 1051, 13, 400, 321, 920, 362, 512, 5221, 281, 2573, 484, 2293, 577, 709, 341, 307, 516, 281, 51364], "temperature": 0.0, "avg_logprob": -0.077877508855499, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0022827039938420057}, {"id": 427, "seek": 256200, "start": 2582.0, "end": 2587.28, "text": " cost. However, this model is all built around the idea of a cooperation, which you see a lot of", "tokens": [51364, 2063, 13, 2908, 11, 341, 2316, 307, 439, 3094, 926, 264, 1558, 295, 257, 14968, 11, 597, 291, 536, 257, 688, 295, 51628], "temperature": 0.0, "avg_logprob": -0.077877508855499, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0022827039938420057}, {"id": 428, "seek": 258728, "start": 2587.28, "end": 2592.2400000000002, "text": " successful global companies do this and balance the different laws and trade-offs of different", "tokens": [50364, 4406, 4338, 3431, 360, 341, 293, 4772, 264, 819, 6064, 293, 4923, 12, 19231, 295, 819, 50612], "temperature": 0.0, "avg_logprob": -0.09590900153444525, "compression_ratio": 1.6643598615916955, "no_speech_prob": 0.004130370914936066}, {"id": 429, "seek": 258728, "start": 2592.2400000000002, "end": 2596.96, "text": " economies around the world. So my hope is that this will be slightly more sustainable and break", "tokens": [50612, 23158, 926, 264, 1002, 13, 407, 452, 1454, 307, 300, 341, 486, 312, 4748, 544, 11235, 293, 1821, 50848], "temperature": 0.0, "avg_logprob": -0.09590900153444525, "compression_ratio": 1.6643598615916955, "no_speech_prob": 0.004130370914936066}, {"id": 430, "seek": 258728, "start": 2596.96, "end": 2602.2400000000002, "text": " down the sort of barrier between corporations and people because people now have a vote in", "tokens": [50848, 760, 264, 1333, 295, 13357, 1296, 17676, 293, 561, 570, 561, 586, 362, 257, 4740, 294, 51112], "temperature": 0.0, "avg_logprob": -0.09590900153444525, "compression_ratio": 1.6643598615916955, "no_speech_prob": 0.004130370914936066}, {"id": 431, "seek": 258728, "start": 2602.2400000000002, "end": 2608.5600000000004, "text": " influence and authority in how we do things. So we're still in very early stages of this. If you", "tokens": [51112, 6503, 293, 8281, 294, 577, 321, 360, 721, 13, 407, 321, 434, 920, 294, 588, 2440, 10232, 295, 341, 13, 759, 291, 51428], "temperature": 0.0, "avg_logprob": -0.09590900153444525, "compression_ratio": 1.6643598615916955, "no_speech_prob": 0.004130370914936066}, {"id": 432, "seek": 258728, "start": 2608.5600000000004, "end": 2614.32, "text": " want to talk more, I'll be here at Fosdham. If you want to talk about Mastodon. And very specifically,", "tokens": [51428, 528, 281, 751, 544, 11, 286, 603, 312, 510, 412, 479, 329, 67, 4822, 13, 759, 291, 528, 281, 751, 466, 376, 525, 378, 266, 13, 400, 588, 4682, 11, 51716], "temperature": 0.0, "avg_logprob": -0.09590900153444525, "compression_ratio": 1.6643598615916955, "no_speech_prob": 0.004130370914936066}, {"id": 433, "seek": 261432, "start": 2614.4, "end": 2620.2400000000002, "text": " if anybody here has any opinions on open-source democracy or how to build an open-source democratic", "tokens": [50368, 498, 4472, 510, 575, 604, 11819, 322, 1269, 12, 41676, 10528, 420, 577, 281, 1322, 364, 1269, 12, 41676, 15337, 50660], "temperature": 0.0, "avg_logprob": -0.08388136200985666, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.012018944136798382}, {"id": 434, "seek": 261432, "start": 2620.2400000000002, "end": 2625.6000000000004, "text": " model such that users can vote, I would love to talk to you. I want to learn as much as I can,", "tokens": [50660, 2316, 1270, 300, 5022, 393, 4740, 11, 286, 576, 959, 281, 751, 281, 291, 13, 286, 528, 281, 1466, 382, 709, 382, 286, 393, 11, 50928], "temperature": 0.0, "avg_logprob": -0.08388136200985666, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.012018944136798382}, {"id": 435, "seek": 261432, "start": 2625.6000000000004, "end": 2629.76, "text": " and I want to help get Nivenly to a point where we actually have a sustainable model,", "tokens": [50928, 293, 286, 528, 281, 854, 483, 426, 5709, 356, 281, 257, 935, 689, 321, 767, 362, 257, 11235, 2316, 11, 51136], "temperature": 0.0, "avg_logprob": -0.08388136200985666, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.012018944136798382}, {"id": 436, "seek": 261432, "start": 2629.76, "end": 2634.0800000000004, "text": " and maybe we can learn some things from the various policy and legal efforts going on here", "tokens": [51136, 293, 1310, 321, 393, 1466, 512, 721, 490, 264, 3683, 3897, 293, 5089, 6484, 516, 322, 510, 51352], "temperature": 0.0, "avg_logprob": -0.08388136200985666, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.012018944136798382}, {"id": 437, "seek": 261432, "start": 2634.7200000000003, "end": 2640.96, "text": " in Belgium and in the EU. So now what? Now, really, it's just keeping Hackaderm online,", "tokens": [51384, 294, 28094, 293, 294, 264, 10887, 13, 407, 586, 437, 30, 823, 11, 534, 11, 309, 311, 445, 5145, 35170, 345, 966, 2950, 11, 51696], "temperature": 0.0, "avg_logprob": -0.08388136200985666, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.012018944136798382}, {"id": 438, "seek": 264096, "start": 2640.96, "end": 2645.92, "text": " which we're about to see if it is. Hopefully it is because I really feel like y'all would have", "tokens": [50364, 597, 321, 434, 466, 281, 536, 498, 309, 307, 13, 10429, 309, 307, 570, 286, 534, 841, 411, 288, 6, 336, 576, 362, 50612], "temperature": 0.0, "avg_logprob": -0.06756157441572709, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.011194841004908085}, {"id": 439, "seek": 264096, "start": 2645.92, "end": 2650.64, "text": " been able to do a lot of damage if I would have been giving this presentation last November.", "tokens": [50612, 668, 1075, 281, 360, 257, 688, 295, 4344, 498, 286, 576, 362, 668, 2902, 341, 5860, 1036, 7674, 13, 50848], "temperature": 0.0, "avg_logprob": -0.06756157441572709, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.011194841004908085}, {"id": 440, "seek": 264096, "start": 2650.64, "end": 2655.12, "text": " And we just want to work towards a democratic model so that people who use the social media", "tokens": [50848, 400, 321, 445, 528, 281, 589, 3030, 257, 15337, 2316, 370, 300, 561, 567, 764, 264, 2093, 3021, 51072], "temperature": 0.0, "avg_logprob": -0.06756157441572709, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.011194841004908085}, {"id": 441, "seek": 264096, "start": 2655.12, "end": 2660.64, "text": " service have a vote and have influence in how that social media service is running so that it becomes", "tokens": [51072, 2643, 362, 257, 4740, 293, 362, 6503, 294, 577, 300, 2093, 3021, 2643, 307, 2614, 370, 300, 309, 3643, 51348], "temperature": 0.0, "avg_logprob": -0.06756157441572709, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.011194841004908085}, {"id": 442, "seek": 264096, "start": 2660.64, "end": 2668.4, "text": " everybody's social media service and not my social media service or somebody else's. So thank you", "tokens": [51348, 2201, 311, 2093, 3021, 2643, 293, 406, 452, 2093, 3021, 2643, 420, 2618, 1646, 311, 13, 407, 1309, 291, 51736], "temperature": 0.0, "avg_logprob": -0.06756157441572709, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.011194841004908085}, {"id": 443, "seek": 266840, "start": 2668.4, "end": 2675.12, "text": " to everyone who's been working on the service so far, and thank you to DMA and Malte who are here", "tokens": [50364, 281, 1518, 567, 311, 668, 1364, 322, 264, 2643, 370, 1400, 11, 293, 1309, 291, 281, 413, 9998, 293, 5746, 975, 567, 366, 510, 50700], "temperature": 0.0, "avg_logprob": -0.1192891770514889, "compression_ratio": 1.5956284153005464, "no_speech_prob": 0.015827706083655357}, {"id": 444, "seek": 266840, "start": 2675.12, "end": 2679.52, "text": " in the front, and specifically to the infrastructure team who helped us get out of the basement", "tokens": [50700, 294, 264, 1868, 11, 293, 4682, 281, 264, 6896, 1469, 567, 4254, 505, 483, 484, 295, 264, 16893, 50920], "temperature": 0.0, "avg_logprob": -0.1192891770514889, "compression_ratio": 1.5956284153005464, "no_speech_prob": 0.015827706083655357}, {"id": 445, "seek": 266840, "start": 2679.52, "end": 2686.7200000000003, "text": " and keep the service online so that we can all have cat pictures and all the wonderful things that", "tokens": [50920, 293, 1066, 264, 2643, 2950, 370, 300, 321, 393, 439, 362, 3857, 5242, 293, 439, 264, 3715, 721, 300, 51280], "temperature": 0.0, "avg_logprob": -0.1192891770514889, "compression_ratio": 1.5956284153005464, "no_speech_prob": 0.015827706083655357}, {"id": 446, "seek": 268672, "start": 2686.72, "end": 2689.12, "text": " come with Mastodon. So thanks, everyone.", "tokens": [50364, 808, 365, 376, 525, 378, 266, 13, 407, 3231, 11, 1518, 13, 50484], "temperature": 0.0, "avg_logprob": -0.18215244838169642, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.014892739243805408}, {"id": 447, "seek": 268672, "start": 2700.56, "end": 2704.3999999999996, "text": " Cool. And I grabbed a photo. So the test here is going to be to see, I'm going to try to upload", "tokens": [51056, 8561, 13, 400, 286, 18607, 257, 5052, 13, 407, 264, 1500, 510, 307, 516, 281, 312, 281, 536, 11, 286, 478, 516, 281, 853, 281, 6580, 51248], "temperature": 0.0, "avg_logprob": -0.18215244838169642, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.014892739243805408}, {"id": 448, "seek": 268672, "start": 2704.3999999999996, "end": 2712.48, "text": " the photo during questions, and we'll see how it goes. So here's a public resource. If you want to", "tokens": [51248, 264, 5052, 1830, 1651, 11, 293, 321, 603, 536, 577, 309, 1709, 13, 407, 510, 311, 257, 1908, 7684, 13, 759, 291, 528, 281, 51652], "temperature": 0.0, "avg_logprob": -0.18215244838169642, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.014892739243805408}, {"id": 449, "seek": 271248, "start": 2712.56, "end": 2716.64, "text": " go check out the graph and see if there was a spike, you can go to grafana.hakaderm.io.", "tokens": [50368, 352, 1520, 484, 264, 4295, 293, 536, 498, 456, 390, 257, 21053, 11, 291, 393, 352, 281, 1295, 69, 2095, 13, 37253, 345, 966, 13, 1004, 13, 50572], "temperature": 0.0, "avg_logprob": -0.2154416356767927, "compression_ratio": 1.5033112582781456, "no_speech_prob": 0.11704719811677933}, {"id": 450, "seek": 271248, "start": 2718.32, "end": 2724.48, "text": " And if you want to go to find out links to my slides and a recording of the video in the future,", "tokens": [50656, 400, 498, 291, 528, 281, 352, 281, 915, 484, 6123, 281, 452, 9788, 293, 257, 6613, 295, 264, 960, 294, 264, 2027, 11, 50964], "temperature": 0.0, "avg_logprob": -0.2154416356767927, "compression_ratio": 1.5033112582781456, "no_speech_prob": 0.11704719811677933}, {"id": 451, "seek": 271248, "start": 2724.48, "end": 2728.2400000000002, "text": " please go to github.com. And thanks again.", "tokens": [50964, 1767, 352, 281, 290, 355, 836, 13, 1112, 13, 400, 3231, 797, 13, 51152], "temperature": 0.0, "avg_logprob": -0.2154416356767927, "compression_ratio": 1.5033112582781456, "no_speech_prob": 0.11704719811677933}, {"id": 452, "seek": 274248, "start": 2742.64, "end": 2752.4, "text": " And I guess we can do questions if anybody has questions. There's one over here.", "tokens": [50372, 400, 286, 2041, 321, 393, 360, 1651, 498, 4472, 575, 1651, 13, 821, 311, 472, 670, 510, 13, 50860], "temperature": 0.0, "avg_logprob": -0.29682305279900045, "compression_ratio": 1.2127659574468086, "no_speech_prob": 0.04796656221151352}, {"id": 453, "seek": 274248, "start": 2753.76, "end": 2758.2400000000002, "text": " Right here. He's got his hand up.", "tokens": [50928, 1779, 510, 13, 634, 311, 658, 702, 1011, 493, 13, 51152], "temperature": 0.0, "avg_logprob": -0.29682305279900045, "compression_ratio": 1.2127659574468086, "no_speech_prob": 0.04796656221151352}, {"id": 454, "seek": 275824, "start": 2758.56, "end": 2772.0, "text": " Okay, okay. I'm sorry.", "tokens": [50380, 1033, 11, 1392, 13, 286, 478, 2597, 13, 51052], "temperature": 0.0, "avg_logprob": -0.3647198548188081, "compression_ratio": 1.1203703703703705, "no_speech_prob": 0.11299939453601837}, {"id": 455, "seek": 275824, "start": 2781.6, "end": 2786.3199999999997, "text": " Could you start to interrupt, everybody? If you could please leave quietly, we are going to do Q&A", "tokens": [51532, 7497, 291, 722, 281, 12729, 11, 2201, 30, 759, 291, 727, 1767, 1856, 19141, 11, 321, 366, 516, 281, 360, 1249, 5, 32, 51768], "temperature": 0.0, "avg_logprob": -0.3647198548188081, "compression_ratio": 1.1203703703703705, "no_speech_prob": 0.11299939453601837}, {"id": 456, "seek": 278632, "start": 2786.32, "end": 2789.92, "text": " right now. So we're just going to have a bit of Q&A. Please leave quietly. Thank you.", "tokens": [50364, 558, 586, 13, 407, 321, 434, 445, 516, 281, 362, 257, 857, 295, 1249, 5, 32, 13, 2555, 1856, 19141, 13, 1044, 291, 13, 50544], "temperature": 0.0, "avg_logprob": -0.2643754686628069, "compression_ratio": 1.4, "no_speech_prob": 0.05898765102028847}, {"id": 457, "seek": 278632, "start": 2791.04, "end": 2797.84, "text": " I'm sorry, Chris. Can you show us the grafana panel? I can't hear you. I'm sorry. Okay, okay, okay.", "tokens": [50600, 286, 478, 2597, 11, 6688, 13, 1664, 291, 855, 505, 264, 1295, 69, 2095, 4831, 30, 286, 393, 380, 1568, 291, 13, 286, 478, 2597, 13, 1033, 11, 1392, 11, 1392, 13, 50940], "temperature": 0.0, "avg_logprob": -0.2643754686628069, "compression_ratio": 1.4, "no_speech_prob": 0.05898765102028847}, {"id": 458, "seek": 278632, "start": 2799.44, "end": 2800.4, "text": " My questions. Thank you.", "tokens": [51020, 1222, 1651, 13, 1044, 291, 13, 51068], "temperature": 0.0, "avg_logprob": -0.2643754686628069, "compression_ratio": 1.4, "no_speech_prob": 0.05898765102028847}, {"id": 459, "seek": 280040, "start": 2801.2000000000003, "end": 2816.1600000000003, "text": " Okay, right now. So the question was, can we see again the grafana table?", "tokens": [50404, 1033, 11, 558, 586, 13, 407, 264, 1168, 390, 11, 393, 321, 536, 797, 264, 1295, 69, 2095, 3199, 30, 51152], "temperature": 0.0, "avg_logprob": -0.41898004213968915, "compression_ratio": 0.9605263157894737, "no_speech_prob": 0.010156497359275818}, {"id": 460, "seek": 281616, "start": 2816.16, "end": 2824.64, "text": " Sure. Awesome.", "tokens": [50364, 4894, 13, 10391, 13, 50788], "temperature": 0.0, "avg_logprob": -0.31436356254245923, "compression_ratio": 0.9863013698630136, "no_speech_prob": 0.020603463053703308}, {"id": 461, "seek": 281616, "start": 2827.8399999999997, "end": 2841.92, "text": " Grab a photo of this. Whoever did this round of applause.", "tokens": [50948, 20357, 257, 5052, 295, 341, 13, 24743, 630, 341, 3098, 295, 9969, 13, 51652], "temperature": 0.0, "avg_logprob": -0.31436356254245923, "compression_ratio": 0.9863013698630136, "no_speech_prob": 0.020603463053703308}, {"id": 462, "seek": 284192, "start": 2842.0, "end": 2849.12, "text": " That's awesome. Hi. I was wondering, you were saying you could contribute skills or money to help.", "tokens": [50368, 663, 311, 3476, 13, 2421, 13, 286, 390, 6359, 11, 291, 645, 1566, 291, 727, 10586, 3942, 420, 1460, 281, 854, 13, 50724], "temperature": 0.0, "avg_logprob": -0.18101675169808523, "compression_ratio": 1.6, "no_speech_prob": 0.10639602690935135}, {"id": 463, "seek": 284192, "start": 2849.12, "end": 2856.32, "text": " What are some ways that we as developers, engineers, SREs can help in the near future", "tokens": [50724, 708, 366, 512, 2098, 300, 321, 382, 8849, 11, 11955, 11, 318, 3850, 82, 393, 854, 294, 264, 2651, 2027, 51084], "temperature": 0.0, "avg_logprob": -0.18101675169808523, "compression_ratio": 1.6, "no_speech_prob": 0.10639602690935135}, {"id": 464, "seek": 284192, "start": 2856.32, "end": 2859.92, "text": " with keeping the video? It's a really good question. So the question was,", "tokens": [51084, 365, 5145, 264, 960, 30, 467, 311, 257, 534, 665, 1168, 13, 407, 264, 1168, 390, 11, 51264], "temperature": 0.0, "avg_logprob": -0.18101675169808523, "compression_ratio": 1.6, "no_speech_prob": 0.10639602690935135}, {"id": 465, "seek": 284192, "start": 2859.92, "end": 2864.4, "text": " how could we potentially volunteer or help out other than just throwing money at the problem?", "tokens": [51264, 577, 727, 321, 7263, 13835, 420, 854, 484, 661, 813, 445, 10238, 1460, 412, 264, 1154, 30, 51488], "temperature": 0.0, "avg_logprob": -0.18101675169808523, "compression_ratio": 1.6, "no_speech_prob": 0.10639602690935135}, {"id": 466, "seek": 284192, "start": 2865.2000000000003, "end": 2870.16, "text": " So the person to talk to is Quintessence. And we have a whole mod team right now that's working", "tokens": [51528, 407, 264, 954, 281, 751, 281, 307, 2326, 686, 442, 655, 13, 400, 321, 362, 257, 1379, 1072, 1469, 558, 586, 300, 311, 1364, 51776], "temperature": 0.0, "avg_logprob": -0.18101675169808523, "compression_ratio": 1.6, "no_speech_prob": 0.10639602690935135}, {"id": 467, "seek": 287016, "start": 2870.24, "end": 2874.7999999999997, "text": " on onboarding docs. And I think we have 12 people right now. And these are folks from", "tokens": [50368, 322, 24033, 278, 45623, 13, 400, 286, 519, 321, 362, 2272, 561, 558, 586, 13, 400, 613, 366, 4024, 490, 50596], "temperature": 0.0, "avg_logprob": -0.1352928706577846, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.011108895763754845}, {"id": 468, "seek": 287016, "start": 2874.7999999999997, "end": 2880.08, "text": " various tech companies around the world. And we have a Discord. So there's a link in the public", "tokens": [50596, 3683, 7553, 3431, 926, 264, 1002, 13, 400, 321, 362, 257, 32623, 13, 407, 456, 311, 257, 2113, 294, 264, 1908, 50860], "temperature": 0.0, "avg_logprob": -0.1352928706577846, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.011108895763754845}, {"id": 469, "seek": 287016, "start": 2880.08, "end": 2884.48, "text": " resources I put. And there's a section on volunteering. And you can just interface with the team and", "tokens": [50860, 3593, 286, 829, 13, 400, 456, 311, 257, 3541, 322, 33237, 13, 400, 291, 393, 445, 9226, 365, 264, 1469, 293, 51080], "temperature": 0.0, "avg_logprob": -0.1352928706577846, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.011108895763754845}, {"id": 470, "seek": 288448, "start": 2884.48, "end": 2900.8, "text": " get plugged in that way. Yeah, of course. Okay. More questions?", "tokens": [50364, 483, 25679, 294, 300, 636, 13, 865, 11, 295, 1164, 13, 1033, 13, 5048, 1651, 30, 51180], "temperature": 0.0, "avg_logprob": -0.21835320494895757, "compression_ratio": 1.264, "no_speech_prob": 0.04357195273041725}, {"id": 471, "seek": 288448, "start": 2905.2, "end": 2912.2400000000002, "text": " Yes. You mentioned a thousand euros a month for the hosting. But I was wondering if you had an", "tokens": [51400, 1079, 13, 509, 2835, 257, 4714, 14160, 257, 1618, 337, 264, 16058, 13, 583, 286, 390, 6359, 498, 291, 632, 364, 51752], "temperature": 0.0, "avg_logprob": -0.21835320494895757, "compression_ratio": 1.264, "no_speech_prob": 0.04357195273041725}, {"id": 472, "seek": 291224, "start": 2912.24, "end": 2919.4399999999996, "text": " idea of what your total cost of ownership is now. And if the increase is linear with the increase", "tokens": [50364, 1558, 295, 437, 428, 3217, 2063, 295, 15279, 307, 586, 13, 400, 498, 264, 3488, 307, 8213, 365, 264, 3488, 50724], "temperature": 0.0, "avg_logprob": -0.11180179677111038, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.04351995885372162}, {"id": 473, "seek": 291224, "start": 2919.4399999999996, "end": 2927.2799999999997, "text": " of users in traffic. Sorry. The total cost of what? You mentioned a thousand euros per month", "tokens": [50724, 295, 5022, 294, 6419, 13, 4919, 13, 440, 3217, 2063, 295, 437, 30, 509, 2835, 257, 4714, 14160, 680, 1618, 51116], "temperature": 0.0, "avg_logprob": -0.11180179677111038, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.04351995885372162}, {"id": 474, "seek": 291224, "start": 2927.2799999999997, "end": 2932.3199999999997, "text": " for the hosting. But I guess your cost is much, much higher than that. So I was wondering if you", "tokens": [51116, 337, 264, 16058, 13, 583, 286, 2041, 428, 2063, 307, 709, 11, 709, 2946, 813, 300, 13, 407, 286, 390, 6359, 498, 291, 51368], "temperature": 0.0, "avg_logprob": -0.11180179677111038, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.04351995885372162}, {"id": 475, "seek": 291224, "start": 2932.3199999999997, "end": 2938.56, "text": " know what your total cost is now monthly. And if it's been a linear increase with the number of", "tokens": [51368, 458, 437, 428, 3217, 2063, 307, 586, 12878, 13, 400, 498, 309, 311, 668, 257, 8213, 3488, 365, 264, 1230, 295, 51680], "temperature": 0.0, "avg_logprob": -0.11180179677111038, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.04351995885372162}, {"id": 476, "seek": 293856, "start": 2938.64, "end": 2945.2799999999997, "text": " users or? So the question is, is the cost of operating the Mastodon server, does it grow", "tokens": [50368, 5022, 420, 30, 407, 264, 1168, 307, 11, 307, 264, 2063, 295, 7447, 264, 376, 525, 378, 266, 7154, 11, 775, 309, 1852, 50700], "temperature": 0.0, "avg_logprob": -0.09130789869922702, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.007226479239761829}, {"id": 477, "seek": 293856, "start": 2945.2799999999997, "end": 2951.04, "text": " linearly with users? And the answer is no. It does increase with users. But I definitely think", "tokens": [50700, 43586, 365, 5022, 30, 400, 264, 1867, 307, 572, 13, 467, 775, 3488, 365, 5022, 13, 583, 286, 2138, 519, 50988], "temperature": 0.0, "avg_logprob": -0.09130789869922702, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.007226479239761829}, {"id": 478, "seek": 293856, "start": 2951.04, "end": 2955.7599999999998, "text": " there's a threshold where you move from a small size to a medium size. And I think the traffic", "tokens": [50988, 456, 311, 257, 14678, 689, 291, 1286, 490, 257, 1359, 2744, 281, 257, 6399, 2744, 13, 400, 286, 519, 264, 6419, 51224], "temperature": 0.0, "avg_logprob": -0.09130789869922702, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.007226479239761829}, {"id": 479, "seek": 293856, "start": 2955.7599999999998, "end": 2960.96, "text": " was really the deciding factor from us. So earlier it was just a few servers that we could operate", "tokens": [51224, 390, 534, 264, 17990, 5952, 490, 505, 13, 407, 3071, 309, 390, 445, 257, 1326, 15909, 300, 321, 727, 9651, 51484], "temperature": 0.0, "avg_logprob": -0.09130789869922702, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.007226479239761829}, {"id": 480, "seek": 293856, "start": 2960.96, "end": 2966.08, "text": " on a small pipe. And now that we have a much larger footprint, we have to pay for a more", "tokens": [51484, 322, 257, 1359, 11240, 13, 400, 586, 300, 321, 362, 257, 709, 4833, 24222, 11, 321, 362, 281, 1689, 337, 257, 544, 51740], "temperature": 0.0, "avg_logprob": -0.09130789869922702, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.007226479239761829}, {"id": 481, "seek": 296608, "start": 2966.08, "end": 2972.88, "text": " enterprise and potentially a CDN and DDoS protection here in the future. And so that's", "tokens": [50364, 14132, 293, 7263, 257, 6743, 45, 293, 413, 7653, 50, 6334, 510, 294, 264, 2027, 13, 400, 370, 300, 311, 50704], "temperature": 0.0, "avg_logprob": -0.12903332710266113, "compression_ratio": 1.380952380952381, "no_speech_prob": 0.0038723303005099297}, {"id": 482, "seek": 296608, "start": 2972.88, "end": 2976.4, "text": " grown up quite a bit. And that's probably our biggest cost right now is just the network.", "tokens": [50704, 7709, 493, 1596, 257, 857, 13, 400, 300, 311, 1391, 527, 3880, 2063, 558, 586, 307, 445, 264, 3209, 13, 50880], "temperature": 0.0, "avg_logprob": -0.12903332710266113, "compression_ratio": 1.380952380952381, "no_speech_prob": 0.0038723303005099297}, {"id": 483, "seek": 296608, "start": 2979.7599999999998, "end": 2980.7999999999997, "text": " Cool. Any other questions?", "tokens": [51048, 8561, 13, 2639, 661, 1651, 30, 51100], "temperature": 0.0, "avg_logprob": -0.12903332710266113, "compression_ratio": 1.380952380952381, "no_speech_prob": 0.0038723303005099297}, {"id": 484, "seek": 298080, "start": 2980.96, "end": 2996.0, "text": " Hey, great talk. Did you evaluate, did you or any of your friends evaluate any other", "tokens": [50372, 1911, 11, 869, 751, 13, 2589, 291, 13059, 11, 630, 291, 420, 604, 295, 428, 1855, 13059, 604, 661, 51124], "temperature": 0.0, "avg_logprob": -0.23557572032130042, "compression_ratio": 1.2758620689655173, "no_speech_prob": 0.02898172102868557}, {"id": 485, "seek": 298080, "start": 2997.84, "end": 3002.6400000000003, "text": " Mastodon compatible solution like Pluroma, Coma or any of that?", "tokens": [51216, 376, 525, 378, 266, 18218, 3827, 411, 2149, 374, 6440, 11, 2432, 64, 420, 604, 295, 300, 30, 51456], "temperature": 0.0, "avg_logprob": -0.23557572032130042, "compression_ratio": 1.2758620689655173, "no_speech_prob": 0.02898172102868557}, {"id": 486, "seek": 300264, "start": 3003.6, "end": 3009.68, "text": " Say, sorry, say again. Did you or any or when, when, when setting up,", "tokens": [50412, 6463, 11, 2597, 11, 584, 797, 13, 2589, 291, 420, 604, 420, 562, 11, 562, 11, 562, 3287, 493, 11, 50716], "temperature": 0.0, "avg_logprob": -0.18843443128797743, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.03885821998119354}, {"id": 487, "seek": 300264, "start": 3011.3599999999997, "end": 3015.52, "text": " when setting up Hackaderm, did you or any of your friends", "tokens": [50800, 562, 3287, 493, 35170, 345, 966, 11, 630, 291, 420, 604, 295, 428, 1855, 51008], "temperature": 0.0, "avg_logprob": -0.18843443128797743, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.03885821998119354}, {"id": 488, "seek": 300264, "start": 3016.8799999999997, "end": 3025.04, "text": " evaluate any of the Mastodon compatible servers like Pluroma, Coma or any of that?", "tokens": [51076, 13059, 604, 295, 264, 376, 525, 378, 266, 18218, 15909, 411, 2149, 374, 6440, 11, 2432, 64, 420, 604, 295, 300, 30, 51484], "temperature": 0.0, "avg_logprob": -0.18843443128797743, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.03885821998119354}, {"id": 489, "seek": 300264, "start": 3025.68, "end": 3029.8399999999997, "text": " So this, this is a really good question. So the question was, when we were setting up Hackaderm,", "tokens": [51516, 407, 341, 11, 341, 307, 257, 534, 665, 1168, 13, 407, 264, 1168, 390, 11, 562, 321, 645, 3287, 493, 35170, 345, 966, 11, 51724], "temperature": 0.0, "avg_logprob": -0.18843443128797743, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.03885821998119354}, {"id": 490, "seek": 302984, "start": 3029.84, "end": 3034.08, "text": " did we look at any of the other Mastodon services like Pluroma or anything else?", "tokens": [50364, 630, 321, 574, 412, 604, 295, 264, 661, 376, 525, 378, 266, 3328, 411, 2149, 374, 6440, 420, 1340, 1646, 30, 50576], "temperature": 0.0, "avg_logprob": -0.07029448938733748, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.003758240956813097}, {"id": 491, "seek": 302984, "start": 3034.96, "end": 3040.1600000000003, "text": " So the answer is no. And again, like, it's not like there was one day where I woke up and said,", "tokens": [50620, 407, 264, 1867, 307, 572, 13, 400, 797, 11, 411, 11, 309, 311, 406, 411, 456, 390, 472, 786, 689, 286, 12852, 493, 293, 848, 11, 50880], "temperature": 0.0, "avg_logprob": -0.07029448938733748, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.003758240956813097}, {"id": 492, "seek": 302984, "start": 3040.1600000000003, "end": 3044.1600000000003, "text": " I'm going to go build a Mastodon server and I'm going to try to get all of the tech industry to", "tokens": [50880, 286, 478, 516, 281, 352, 1322, 257, 376, 525, 378, 266, 7154, 293, 286, 478, 516, 281, 853, 281, 483, 439, 295, 264, 7553, 3518, 281, 51080], "temperature": 0.0, "avg_logprob": -0.07029448938733748, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.003758240956813097}, {"id": 493, "seek": 302984, "start": 3044.1600000000003, "end": 3049.6000000000004, "text": " come join us, right? Like I set it up for like me and my friends to just try out and Mastodon was", "tokens": [51080, 808, 3917, 505, 11, 558, 30, 1743, 286, 992, 309, 493, 337, 411, 385, 293, 452, 1855, 281, 445, 853, 484, 293, 376, 525, 378, 266, 390, 51352], "temperature": 0.0, "avg_logprob": -0.07029448938733748, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.003758240956813097}, {"id": 494, "seek": 302984, "start": 3049.6000000000004, "end": 3054.32, "text": " the easiest one to get running on Arch Linux. And that was about the most thought that went", "tokens": [51352, 264, 12889, 472, 281, 483, 2614, 322, 10984, 18734, 13, 400, 300, 390, 466, 264, 881, 1194, 300, 1437, 51588], "temperature": 0.0, "avg_logprob": -0.07029448938733748, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.003758240956813097}, {"id": 495, "seek": 305432, "start": 3054.32, "end": 3060.2400000000002, "text": " into setting up Mastodon originally. And I think that like it had just continued to grow organically.", "tokens": [50364, 666, 3287, 493, 376, 525, 378, 266, 7993, 13, 400, 286, 519, 300, 411, 309, 632, 445, 7014, 281, 1852, 1798, 984, 13, 50660], "temperature": 0.0, "avg_logprob": -0.07325872046048523, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.04528818279504776}, {"id": 496, "seek": 305432, "start": 3060.2400000000002, "end": 3066.0, "text": " And so like in hindsight, I mean, I like, I think there's opportunity to rewrite parts of Mastodon.", "tokens": [50660, 400, 370, 411, 294, 44357, 11, 286, 914, 11, 286, 411, 11, 286, 519, 456, 311, 2650, 281, 28132, 3166, 295, 376, 525, 378, 266, 13, 50948], "temperature": 0.0, "avg_logprob": -0.07325872046048523, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.04528818279504776}, {"id": 497, "seek": 305432, "start": 3066.0, "end": 3069.76, "text": " I think there's a lot of opportunity to like have alternative dashboards as well.", "tokens": [50948, 286, 519, 456, 311, 257, 688, 295, 2650, 281, 411, 362, 8535, 8240, 17228, 382, 731, 13, 51136], "temperature": 0.0, "avg_logprob": -0.07325872046048523, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.04528818279504776}, {"id": 498, "seek": 305432, "start": 3070.8, "end": 3075.76, "text": " And so I'm not opposed to like operating different services for Hackaderm. I like to think of", "tokens": [51188, 400, 370, 286, 478, 406, 8851, 281, 411, 7447, 819, 3328, 337, 35170, 345, 966, 13, 286, 411, 281, 519, 295, 51436], "temperature": 0.0, "avg_logprob": -0.07325872046048523, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.04528818279504776}, {"id": 499, "seek": 305432, "start": 3075.76, "end": 3080.96, "text": " Hackaderm as a social media service where we just are on Mastodon mostly right now for today.", "tokens": [51436, 35170, 345, 966, 382, 257, 2093, 3021, 2643, 689, 321, 445, 366, 322, 376, 525, 378, 266, 5240, 558, 586, 337, 965, 13, 51696], "temperature": 0.0, "avg_logprob": -0.07325872046048523, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.04528818279504776}, {"id": 500, "seek": 308096, "start": 3081.84, "end": 3086.2400000000002, "text": " So I don't have any personal experience operating the others, but I suspect that", "tokens": [50408, 407, 286, 500, 380, 362, 604, 2973, 1752, 7447, 264, 2357, 11, 457, 286, 9091, 300, 50628], "temperature": 0.0, "avg_logprob": -0.10168057610006893, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.005132636521011591}, {"id": 501, "seek": 308096, "start": 3086.96, "end": 3091.76, "text": " you know, as we move forward, the community might decide to switch over or run a different version", "tokens": [50664, 291, 458, 11, 382, 321, 1286, 2128, 11, 264, 1768, 1062, 4536, 281, 3679, 670, 420, 1190, 257, 819, 3037, 50904], "temperature": 0.0, "avg_logprob": -0.10168057610006893, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.005132636521011591}, {"id": 502, "seek": 308096, "start": 3091.76, "end": 3094.64, "text": " or who knows, right? That's that's going to be up to the community now.", "tokens": [50904, 420, 567, 3255, 11, 558, 30, 663, 311, 300, 311, 516, 281, 312, 493, 281, 264, 1768, 586, 13, 51048], "temperature": 0.0, "avg_logprob": -0.10168057610006893, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.005132636521011591}, {"id": 503, "seek": 308096, "start": 3097.76, "end": 3103.6, "text": " All right. I have a further question. How fast was your internet speed at home to serve the", "tokens": [51204, 1057, 558, 13, 286, 362, 257, 3052, 1168, 13, 1012, 2370, 390, 428, 4705, 3073, 412, 1280, 281, 4596, 264, 51496], "temperature": 0.0, "avg_logprob": -0.10168057610006893, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.005132636521011591}, {"id": 504, "seek": 310360, "start": 3103.68, "end": 3110.56, "text": " Mastodon server? Sorry, say again? How fast was your internet speed at home to serve the", "tokens": [50368, 376, 525, 378, 266, 7154, 30, 4919, 11, 584, 797, 30, 1012, 2370, 390, 428, 4705, 3073, 412, 1280, 281, 4596, 264, 50712], "temperature": 0.0, "avg_logprob": -0.1117638956036484, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.0163596011698246}, {"id": 505, "seek": 310360, "start": 3110.56, "end": 3117.6, "text": " Mastodon server? So like you showed the stats of your server setup with like 40 gigabits of", "tokens": [50712, 376, 525, 378, 266, 7154, 30, 407, 411, 291, 4712, 264, 18152, 295, 428, 7154, 8657, 365, 411, 3356, 8741, 455, 1208, 295, 51064], "temperature": 0.0, "avg_logprob": -0.1117638956036484, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.0163596011698246}, {"id": 506, "seek": 310360, "start": 3118.16, "end": 3124.72, "text": " possible network bandwidth, but how fast was actually the provided bandwidth from your ISP?", "tokens": [51092, 1944, 3209, 23647, 11, 457, 577, 2370, 390, 767, 264, 5649, 23647, 490, 428, 6205, 47, 30, 51420], "temperature": 0.0, "avg_logprob": -0.1117638956036484, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.0163596011698246}, {"id": 507, "seek": 310360, "start": 3124.72, "end": 3128.3199999999997, "text": " Yeah. So this is a good question, which is how much bandwidth were we going through at my house?", "tokens": [51420, 865, 13, 407, 341, 307, 257, 665, 1168, 11, 597, 307, 577, 709, 23647, 645, 321, 516, 807, 412, 452, 1782, 30, 51600], "temperature": 0.0, "avg_logprob": -0.1117638956036484, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.0163596011698246}, {"id": 508, "seek": 310360, "start": 3129.04, "end": 3132.7999999999997, "text": " So in there's an official write up of the situation where we have some screenshots of the", "tokens": [51636, 407, 294, 456, 311, 364, 4783, 2464, 493, 295, 264, 2590, 689, 321, 362, 512, 40661, 295, 264, 51824], "temperature": 0.0, "avg_logprob": -0.1117638956036484, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.0163596011698246}, {"id": 509, "seek": 313280, "start": 3132.8, "end": 3140.2400000000002, "text": " firewall at the house. And ultimately, we had pushed I think one terabyte was our busiest day", "tokens": [50364, 36109, 412, 264, 1782, 13, 400, 6284, 11, 321, 632, 9152, 286, 519, 472, 1796, 34529, 390, 527, 1255, 6495, 786, 50736], "temperature": 0.0, "avg_logprob": -0.12391100431743421, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.0023179936688393354}, {"id": 510, "seek": 313280, "start": 3140.2400000000002, "end": 3146.0800000000004, "text": " in the middle of November over the ISP. So I had two connections, one of which was symmetrical 1G", "tokens": [50736, 294, 264, 2808, 295, 7674, 670, 264, 6205, 47, 13, 407, 286, 632, 732, 9271, 11, 472, 295, 597, 390, 40360, 502, 38, 51028], "temperature": 0.0, "avg_logprob": -0.12391100431743421, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.0023179936688393354}, {"id": 511, "seek": 313280, "start": 3146.0800000000004, "end": 3150.48, "text": " up and down that we were able to use and we like it maxed out our pipeline. We were like we were", "tokens": [51028, 493, 293, 760, 300, 321, 645, 1075, 281, 764, 293, 321, 411, 309, 11469, 292, 484, 527, 15517, 13, 492, 645, 411, 321, 645, 51248], "temperature": 0.0, "avg_logprob": -0.12391100431743421, "compression_ratio": 1.4619289340101522, "no_speech_prob": 0.0023179936688393354}, {"id": 512, "seek": 315048, "start": 3150.48, "end": 3161.12, "text": " being startled by the ISP at one time. Yeah. Yeah. Thank you.", "tokens": [50364, 885, 48898, 538, 264, 6205, 47, 412, 472, 565, 13, 865, 13, 865, 13, 1044, 291, 13, 50896], "temperature": 0.0, "avg_logprob": -0.4064681053161621, "compression_ratio": 0.9838709677419355, "no_speech_prob": 0.023853544145822525}], "language": "en"}