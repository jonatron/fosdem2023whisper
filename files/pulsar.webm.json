{"text": " So, hello everyone. So, welcome to our talk and really thank you so much for staying for this long. This is like the second last of the session of the day. So, really appreciate you being here. So, today we're going to be talking about modernizing legacy messaging system with Apache Pulsar. And here, you know, we have Enrico and then myself too. We're from Datastax. Okay. So, but before we start, if you like a copy of our, you know, slide deck, here's the QR code and also the short link if you want. I'll let you take a moment. Good. Okay. Okay. Well, even if you missed, don't worry, we'll be sharing with you our connection info. Then you can connect with us. We can always be there to answer your questions too. So, with that, let me start. First, just a quick introduction. Who's Mary? So, I'm a streaming developer advocate at Datastax. And Datastax is a company based in California. Starting in Apache Cassandra, Managed Cloud. And then now we also have the Managed Cloud for streaming, which is Apache Pulsar. And I was also a developer advocate before joining Datastax last year. And I'm based in Chicago. I'm also the president of the Chicago Java users group. And I'm also a Java champion. And before this, I was spending over 20 years or so being a developer myself too. So, that's me. And then this is Enrico. Enrico. Oh, yes. Sure. Sure. I'm Enrico. I work with Mary. I really enjoy working with open source communities. So I'm involved in a few Apache projects like Pulsar, but all the big Datastax or ZooKeeper. And also I collaborate with Maven and Curator. I'm participating also in some CNCF project like Pravega that is still about massaging and distributed streaming. And also contributed to RDB that is a Distributed Embeddable Java Database. Okay. Great. Thanks, Enrico. I'm really happy today to be here with Enrico because we were just working remotely, finally get to meet here in Belgium when he lives in Italy. And I'm in Chicago. So, okay. So without further ado, this is the agenda like within 20 minutes. So it's going to be a little bit quick, but we'll end up having Enrico also doing some quick demo as well. So first, let's kind of give an introduction to what is JMS, assuming you know, not everybody is familiar with that. So some introduction. And then we'll talk about Apache Pulsar and why Pulsar. And also just quickly describe the Pulsar architecture and how do you do the mapping between JMS and Pulsar. And then how do you use JMS API with Pulsar. And Enrico will show that. And then that's how we're going to be doing. So first of all, just some core concepts too, right, of JMS. And as such, right, JMS is all about also messaging, but it's very much a Java centric technology. And it's here, as you can see, right, it's also published, subscribed kind of model, making use of destinations that it supports queues and topics. So messages, producers, consumers, these are typical like pop-up producer, consumer type of pattern. As such, it's a pattern, but this has its own implementation. And basically too, it makes use of the JMS context and that will help you with the connections and sessions. Okay, so about destinations, right. So essentially too, it supports both queuing and the topic too. And so it acts as a broker in the topic case, but for queues. So each message is basically, as such, right, message queue is you drop the message there and then it gets picked up and then it's kind of done, right, by the consumer like that. It's browsable, this queue, first in, first out kind of approach. And then with topic, it allows for multiple subscriptions too. And message dispatch according to the subscription type as well. And consumer, as far as consumers styles go, you can have blocking, which is in the blocking received methods and that's all application driven. And also, yeah, okay. And then there's also making use of the message listener method, which is a JMS to driver driven in that case. And as far as producer styles go, the blocking will be send method or there's also a async send too. And that will be like with completion listener. So that's real quickly. And then as far as administrative operations go, as we know, JMS does not cover administrative operations. And how do you manage the destinations and doing, you know, connection properties, all of these things, the defining security models or resource limits, all of these things and configure all of these at JMS itself doesn't have to do it. So how do you manage it? It usually relies on your vendor. How do you, you know, we kind of do all of the management too is through some vendor way of allowing you to do that. And so basically too, there's also API also to let you work with administrative objects too. And so basically, they're, you know, supposed to be kind of also provided by the system as well. And as far as destinations go, there are queue and topic references. And connection factory basically is the, is essentially too, using connection factory is the client that allows you to connect to the system in that case. And then there's also JMS, right? The API is essentially allows you to interact with Java EE or now is Jakarta EE, but back then there's Jakarta Java EE. And in that case, you can basically make use of EJB components. There's stateful, stateless EJB. That's used in web surflets or, you know, the Jax RS, Jax WS endpoints, right? And it allows you to also do background like doing scheduling kind of way of doing things. And then there's also message driven beans. So these essentially too is basically their JMS specific kind of beans to handle messages in there. And it's basically managed by the container, the, you know, J2, JEE container. When you receive a messages from a container, then it will be essentially be, you know, activated in that case. So J, the Java EE container provides support for like all of the, you know, life cycle management pulling of these context dependency injection of these things and transaction supports of security standard API. All of these tools basically relying on the container to do that for you. And then there's also to what about external resources. So a lot of times, and that's how it relies on resource adapters. It allows you to essentially extend the Java EE container in that case. So in some key points, it basically to use it is you need to have the resource archive file. So dot RAL file that will contain the code and you have to then configure the resource adapter and everything. And it allows you to essentially create administer objects, right? That conforms to these objects will conform to the standard API and is implemented by the, by the core inside the resource adapter too. So these are the different packages like basically Java X dot JMS. In this case, it's I think in the new, new version would be Jakarta, but we're still talking about Java, the older JMS in this case, and will be connection factory queue and topic. So usually each objects to a bound to a JNDI naming and directory interface registry, right, provided by the container. And so it's specific to the container as to how you do deployment too. And that's how it usually works. Now then let's get introduced, right? So now we talk, talk about JMS stuff is a bit more legacy stuff. So what are some of the options, right? To, to kind of leverage on today's like more modern world that allows you to work in a cloud native environment. But also we want to introduce to you Apache Pulsar is an open source platform and it's cloud native and it supports distributed messaging and streaming too. And as such too, this is the link where you can kind of find out more information or this is actually more the, the GitHub repo. So wanting to highlight it because we don't have too much time, but basically it's very cloud native in nature. It's born with the cloud native DNA and various, you know, it's basically the key point of it is that why do you want pulsars? I think what, I think at least one of the key point, it separates out the compute and the storage. So basically Pulsar can focus more on working with the messages delivery, right, dealing with all the messages coming in, delivering all of these things. And then, you know, you have a whole laundry baskets of all the log messages, then what do you do with it? Rather than dealing with it, Pulsar said, let me get bookkeeper to handle it for me. So, so that way Pulsar can focus on that, you know, just the messaging part and coordinate with the bookkeepers. So that's what it does. And it also supports multi-tenancy and that's a very nice way of helping you to organize all of your messages, as well as some features that are more kind of ready for enterprise level, like, you know, geo replication is also a major thing in that. And also it has what is called like tiered offset. It's basically if your messages get code, right, and bookkeeper, you don't want it to take up too much room. Then you want to move it to, or actually, I should say, it gets kind of in the one storage and you want to move it off to cold storage. So all these, as Pulsar has built in and it knows it. So native Kubernetes support all of these things, schema, it has a Pulsar schema connectors, and you can use the basically Pulsar IO framework to build different connectors. And currently we're supporting like almost a hundred different kind of connectors, too, in there. Message processing, you can use the Pulsar functions framework, so you don't need to use anything outside to do message transformation as you are building your data pipeline. And also the nice thing, too, is that it doesn't restrict you to only using Java as your client. You can use other things like C++, Python Go, and other community contributions to such a cloud. There's also Node.js, also.NET C-Shop client, too. So that's really flexible and really functioning real well in Pulsar. So let's kind of really quickly kind of take a look. I already mentioned some of it. Essentially, too, it's a blazing performance. That's what we all want. Provides you with true like real-time type of processing. That's why we want it, right? It's basically millions of JMS messages can be handled if you have JMS leveraging on such a platform. So it's all good. Horizontal scalability. If you expand your infrastructure, adding more servers and nodes and all of these to it, Pulsar will handle that for you. You don't need to rebalance all of your topics, and you don't need to deal with offsets, right, such as in maybe like Kafka, things like that. It has its own way, so then you don't have to worry as a developer. Worrying about all of these infrastructural things. So all of these things are just listed here. I know there's a lot of, you know, works in here, but it allows you to kind of get a bit more into detail, and we can share with you this thing. So let me pass this on to, let me see. Oh, let me kind of quickly, I thought this was on. Okay, so just a really quick basic architecture. This kind of pictorially described to you what I just talked about. We only have so little time. So this is just describing to you, right? Producers, consumers can be written in, you know, many different languages, not just with Java, and it gets managing, you know, by bookkeeper that deals with all of the storage side of things, and very dynamic. As you can see, this kind of quickly summarized in picture what Pulsar can do for you. Okay, and then here, just quick summary Apache Pulsar. Again, take mixtures of a pop-up type of architecture, right, and that's what it is, and supports like multi-tenants, namespaces. Different subscription modes do that. You can also leverage on that, essentially turn Pulsar into a queuing kind of capability if you use an exclusive type of mode to do, you know, subscription. And what other thing? Yeah, so there are different modes. It's just highly flexible is what we're trying to tell you about the story. So here, we have a little bit of story about that. We can talk more about it later. Yeah, so I just want to map Pulsar concept to JMS. JMS is pretty straightforward. So the model is quite flexible because it is with a queuing, but also a pop-sub. And in Pulsar, the mapping is really natural because you can map a JMS topic to a Pulsar topic, whatever it is, Pulsar standard topic, partitioned topic, virtual topics. A JMS queue is like a Pulsar shared subscription, and the JMS is like a Pulsar message with an envelope and with the body. So in JMS, we have several consumer types. So I'm not going to enter the details, but there is a subscription type that matches the JMS requirements. One important thing is that if you want to use JMS with Pulsar, you don't need to install any additional plugin because the JMS API is built over the standard native Java client because the Pulsar features are a super set of JMS. So it's only about implementing an API. You know, in JDBC, you have an API that allows you to connect to every database. In JMS, you just have to implement the API and follow the specs. If you want, you can deploy a server-side component just to push some of the computations. So for instance, in JMS, you have filters. You can filter the messages. So if you want, you can filter them on the broker. Otherwise, you can simply filter them on the client side. I'm just showing some examples of how to use Pulsar with JMS. Maybe if you are already familiar with JMS, that's pretty simple. So in JMS, you start with a connection factory. So we have Pulsar connection factory. And this is JMS 2.0. And you can get a JMS context. You get a reference to a destination. This is create queue. Create queue is not creating a queue. It's creating a reference to a queue because JMS doesn't deal with administrative operations, as Mary said. You create a producer. You can send as many messages as you want. And if you want to consume, you create a consumer. And you can use receive or set the message listener. This is from standard Java. If you're using Jakarta or Java Enterprise, actually, yes, I've been helping a few companies to migrate from Java Enterprise to Pulsar. So I know much more cases about Java Enterprise more than Jakarta. But that's it. So for instance, if you want to write and you have an Enterprise Java bin, then you can ask to the container to inject the connection to Pulsar. And this is a standard Java Enterprise code. So this code runs with ActiveMQ, with TIBCO, with whatever you want, whatever you are running. And the container injects the connection factory and the destination. And you can, as in the standard Java code, you can get a reference to the JMS context and then you send. We will see later how the administrator, for instance, with Apache Tomy, connects all the parts. The consumer, usually in Java Enterprise, you use message driven bins to consume from destinations. So yes, this is a simple message driven bin. You configure all the relevant things that you want. For instance, usually you configure the destination that is still a logical name and a subscription type or the parallelism of the kind of things. In many containers, you can configure the things on other descriptors or descriptors on user links and files. You implement a callback on message. Every time a message is dispatched to the application, the code runs and if everything goes well, the message is acknowledged to the Pulsar broker and it won't be delivered anymore. If there is any exception that is thrown, Pulsar will deliver again the message. In Tomy, there is a very simple way to deploy the resource adapter. I'm deploying the resource adapter for Pulsar. So Pulsar RA, you configure the connection to Pulsar. Now in the demo, I'm using localhost and this is the most interesting part. I create a logical queue, so full queue. This is a queue and I bind it to a physical destination. So the container will create a Pulsar connection factory and also the Pulsar queue. The demo is on my GitHub space. So yes, you can run it by yourself. I'm going to use Apache Tomy 8, Starlight for JMS. I'll talk about that later. It is basically the JMS implementation. I create the object with the same file that we saw and Apache Pulsar to.11. So we have one application that consumes, one that produces and Pulsar will run locally. So let me switch to the console. Oh no, yes, the code. The code is really simple. This is on GitHub, so you can check it out later. So this is the producer. I'm not writing the code that instantiates or assigns some value to the factory or to the queue. I'm scheduling the execution of this method every two seconds and that's it. Very easy. On the JMS listener, these are two separate applications. Usually in a real world application, you have some application that produce the data. Then you have a pipeline that transforms your data and something else that consumes the data. This is pretty common. So here, on message, depending on the type of message, I'm printing the content and message. Here, I'm just declaring the reference to the logical queue that I want. In this case, OpenAJB that is still Tommy will resolve the binding with the physical queue via JNDI. We are running out of time. So I have a script to run all the demo. The script simply installs two instances of Tommy, Pulsar, copies the configuration file, deploys the resource archives, changes some ports because I'm running multiple services on my machine. So there will be conflicts. Copy the consumer application to Tommy one, copy the producer application to Tommy two, then start the Pulsar standalone. That is a quick way to start Pulsar locally with all the services, but only in one JVM process. Tommy one, Tommy two, and then we will see the logs. So there is some noise initially because it is installing everything. This is Pulsar. This is starting. These are the two Tommy. Actually, we don't see. Oh yes, this is good. So Tommy two is sending the messages. Tommy one is receiving the messages. So it works. It's a very straightforward setup and very common way to develop with Java Enterprise. Let's drop up. Two minutes probably. Yes, okay, good. So JMS is very useful and it allows you to switch very easily to another vendor. Usually with JMS you don't use very specific features. Usually in my experience with JMS, maybe you're using TIBCOR, you're using ActiveMQ. You configure on the container some special flags, but the code usually is pretty standard. Yes, so switching to Pulsar is usually easy. Pulsar is cloud native. It's scalable horizontally. So like Mary said, really, if you it looks like a promise, but this is real, you can add machines, add or remove machines, and the service automatically adapts. Actually, at Datastax we are running it as a service on the cloud. And so this is very powerful because you can automatically adapt the resource consumption. And also you can move the data that is not actually consumed to tier storage. And this allows you to really lower the cost. It's open source. It's a vibrant community. If you want, you can reach out to me on the community. And there are many people that are very enthusiastic. Pulsar is young. It is only five years old, something like that. But in the past two years, it grew very fast because it is really the next generation. Maybe someone working with ActiveMQ, then I did it in my previous jobs, ActiveMQ and then Kafka and then Pulsar. Now it's time for Pulsar. If you want to use Pulsar, you can use Starlight for GMS. I'm the initial author and main maintainer for Starlight for GMS. So yes, feel free to ask me any questions. It's open source. It's on GitHub. Pulsar Connection Factory, if you're using standard Java, there is a resource adapter that works well with many containers. And it's already tested and it is running on production. Okay. And these are just real quick. If you like, get this copy of the slide deck. But otherwise, there are resources in here, community info, references to all the Pulsar information on GitHub and also in our Pulsar site. And also then just additional information too with data stacks. If you're interested, we offer like the $25 credit per month for personal projects. So wanting to share with you, I know it's not true, open source in that sense, but we do have astra.datastacks.com and all of the astra streaming is our company's supporting this in our cloud. So oops, where did it go? Sorry. You tried to subscribe to us. Okay. So how do you contact us? This is the slide just containing information about Twitter handles and LinkedIn, all of these things. So please do consider staying in touch with us. We'll be very happy to answer more questions that you may have and all you want to share with us, your project idea, we'll be happy to answer. And those sound to Jay's luck. Yes. That's right. So thank you. Thank you so much. And I think that's any questions. Sure. What the Pulsar functions or Pulsar function is a lightweight processing framework that usually it's very easy to enrich the data that you have on your topics. So it's for very lightweight processing. So if you have to do more complicated processing, you usually move to something like Flink or other things. But Pulsar function is very useful when you have to really process your data. And also it is the base for Pulsar.io that is the connector framework. So basically in Pulsar, you can deploy on the Pulsar cluster your code that transforms your data on your topics. Yes. It starts from a message on Pulsar and usually it ends with another message on Pulsar. So it's really useful for transforming the data that is on Pulsar or to push your data outside of Pulsar. I don't know if this answers. We need to continue. Oh, yes. There is a question over here. If you want to have a discussion and also on Fuji Slack, you can have discussions with people, but usually at the top they are married.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.32, "text": " So, hello everyone. So, welcome to our talk and really thank you so much for staying for", "tokens": [407, 11, 7751, 1518, 13, 407, 11, 2928, 281, 527, 751, 293, 534, 1309, 291, 370, 709, 337, 7939, 337], "temperature": 0.0, "avg_logprob": -0.23315935423879913, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.5655644536018372}, {"id": 1, "seek": 0, "start": 14.32, "end": 19.12, "text": " this long. This is like the second last of the session of the day. So, really appreciate", "tokens": [341, 938, 13, 639, 307, 411, 264, 1150, 1036, 295, 264, 5481, 295, 264, 786, 13, 407, 11, 534, 4449], "temperature": 0.0, "avg_logprob": -0.23315935423879913, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.5655644536018372}, {"id": 2, "seek": 0, "start": 19.12, "end": 23.92, "text": " you being here. So, today we're going to be talking about modernizing legacy messaging", "tokens": [291, 885, 510, 13, 407, 11, 965, 321, 434, 516, 281, 312, 1417, 466, 4363, 3319, 11711, 21812], "temperature": 0.0, "avg_logprob": -0.23315935423879913, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.5655644536018372}, {"id": 3, "seek": 2392, "start": 23.92, "end": 30.0, "text": " system with Apache Pulsar. And here, you know, we have Enrico and then myself too. We're", "tokens": [1185, 365, 46597, 430, 9468, 289, 13, 400, 510, 11, 291, 458, 11, 321, 362, 2193, 23776, 293, 550, 2059, 886, 13, 492, 434], "temperature": 0.0, "avg_logprob": -0.25287737497469276, "compression_ratio": 1.435483870967742, "no_speech_prob": 8.994785457616672e-05}, {"id": 4, "seek": 2392, "start": 30.0, "end": 36.7, "text": " from Datastax. Okay. So, but before we start, if you like a copy of our, you know, slide", "tokens": [490, 9315, 525, 2797, 13, 1033, 13, 407, 11, 457, 949, 321, 722, 11, 498, 291, 411, 257, 5055, 295, 527, 11, 291, 458, 11, 4137], "temperature": 0.0, "avg_logprob": -0.25287737497469276, "compression_ratio": 1.435483870967742, "no_speech_prob": 8.994785457616672e-05}, {"id": 5, "seek": 2392, "start": 36.7, "end": 44.760000000000005, "text": " deck, here's the QR code and also the short link if you want. I'll let you take a moment.", "tokens": [9341, 11, 510, 311, 264, 32784, 3089, 293, 611, 264, 2099, 2113, 498, 291, 528, 13, 286, 603, 718, 291, 747, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.25287737497469276, "compression_ratio": 1.435483870967742, "no_speech_prob": 8.994785457616672e-05}, {"id": 6, "seek": 4476, "start": 44.76, "end": 54.44, "text": " Good. Okay. Okay. Well, even if you missed, don't worry, we'll be sharing with you our", "tokens": [2205, 13, 1033, 13, 1033, 13, 1042, 11, 754, 498, 291, 6721, 11, 500, 380, 3292, 11, 321, 603, 312, 5414, 365, 291, 527], "temperature": 0.0, "avg_logprob": -0.1744735987499507, "compression_ratio": 1.4937759336099585, "no_speech_prob": 5.138411506777629e-05}, {"id": 7, "seek": 4476, "start": 54.44, "end": 58.32, "text": " connection info. Then you can connect with us. We can always be there to answer your", "tokens": [4984, 13614, 13, 1396, 291, 393, 1745, 365, 505, 13, 492, 393, 1009, 312, 456, 281, 1867, 428], "temperature": 0.0, "avg_logprob": -0.1744735987499507, "compression_ratio": 1.4937759336099585, "no_speech_prob": 5.138411506777629e-05}, {"id": 8, "seek": 4476, "start": 58.32, "end": 63.31999999999999, "text": " questions too. So, with that, let me start. First, just a quick introduction. Who's Mary?", "tokens": [1651, 886, 13, 407, 11, 365, 300, 11, 718, 385, 722, 13, 2386, 11, 445, 257, 1702, 9339, 13, 2102, 311, 6059, 30], "temperature": 0.0, "avg_logprob": -0.1744735987499507, "compression_ratio": 1.4937759336099585, "no_speech_prob": 5.138411506777629e-05}, {"id": 9, "seek": 4476, "start": 63.31999999999999, "end": 70.28, "text": " So, I'm a streaming developer advocate at Datastax. And Datastax is a company based in California.", "tokens": [407, 11, 286, 478, 257, 11791, 10754, 14608, 412, 9315, 525, 2797, 13, 400, 9315, 525, 2797, 307, 257, 2237, 2361, 294, 5384, 13], "temperature": 0.0, "avg_logprob": -0.1744735987499507, "compression_ratio": 1.4937759336099585, "no_speech_prob": 5.138411506777629e-05}, {"id": 10, "seek": 7028, "start": 70.28, "end": 74.88, "text": " Starting in Apache Cassandra, Managed Cloud. And then now we also have the Managed Cloud", "tokens": [16217, 294, 46597, 18208, 18401, 11, 2458, 2980, 8061, 13, 400, 550, 586, 321, 611, 362, 264, 2458, 2980, 8061], "temperature": 0.0, "avg_logprob": -0.19947191144599288, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.00019372945826034993}, {"id": 11, "seek": 7028, "start": 74.88, "end": 82.2, "text": " for streaming, which is Apache Pulsar. And I was also a developer advocate before joining", "tokens": [337, 11791, 11, 597, 307, 46597, 430, 9468, 289, 13, 400, 286, 390, 611, 257, 10754, 14608, 949, 5549], "temperature": 0.0, "avg_logprob": -0.19947191144599288, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.00019372945826034993}, {"id": 12, "seek": 7028, "start": 82.2, "end": 87.68, "text": " Datastax last year. And I'm based in Chicago. I'm also the president of the Chicago Java", "tokens": [9315, 525, 2797, 1036, 1064, 13, 400, 286, 478, 2361, 294, 9525, 13, 286, 478, 611, 264, 3868, 295, 264, 9525, 10745], "temperature": 0.0, "avg_logprob": -0.19947191144599288, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.00019372945826034993}, {"id": 13, "seek": 7028, "start": 87.68, "end": 93.24000000000001, "text": " users group. And I'm also a Java champion. And before this, I was spending over 20 years", "tokens": [5022, 1594, 13, 400, 286, 478, 611, 257, 10745, 10971, 13, 400, 949, 341, 11, 286, 390, 6434, 670, 945, 924], "temperature": 0.0, "avg_logprob": -0.19947191144599288, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.00019372945826034993}, {"id": 14, "seek": 7028, "start": 93.24000000000001, "end": 99.76, "text": " or so being a developer myself too. So, that's me. And then this is Enrico. Enrico. Oh, yes.", "tokens": [420, 370, 885, 257, 10754, 2059, 886, 13, 407, 11, 300, 311, 385, 13, 400, 550, 341, 307, 2193, 23776, 13, 2193, 23776, 13, 876, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.19947191144599288, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.00019372945826034993}, {"id": 15, "seek": 9976, "start": 99.76, "end": 107.48, "text": " Sure. Sure. I'm Enrico. I work with Mary. I really enjoy working with open source communities.", "tokens": [4894, 13, 4894, 13, 286, 478, 2193, 23776, 13, 286, 589, 365, 6059, 13, 286, 534, 2103, 1364, 365, 1269, 4009, 4456, 13], "temperature": 0.0, "avg_logprob": -0.17995880176494647, "compression_ratio": 1.4111675126903553, "no_speech_prob": 0.0008169582579284906}, {"id": 16, "seek": 9976, "start": 107.48, "end": 115.92, "text": " So I'm involved in a few Apache projects like Pulsar, but all the big Datastax or ZooKeeper.", "tokens": [407, 286, 478, 3288, 294, 257, 1326, 46597, 4455, 411, 430, 9468, 289, 11, 457, 439, 264, 955, 9315, 525, 2797, 420, 34589, 41856, 260, 13], "temperature": 0.0, "avg_logprob": -0.17995880176494647, "compression_ratio": 1.4111675126903553, "no_speech_prob": 0.0008169582579284906}, {"id": 17, "seek": 9976, "start": 115.92, "end": 125.16000000000001, "text": " And also I collaborate with Maven and Curator. I'm participating also in some CNCF project", "tokens": [400, 611, 286, 18338, 365, 4042, 553, 293, 7907, 1639, 13, 286, 478, 13950, 611, 294, 512, 48714, 37, 1716], "temperature": 0.0, "avg_logprob": -0.17995880176494647, "compression_ratio": 1.4111675126903553, "no_speech_prob": 0.0008169582579284906}, {"id": 18, "seek": 12516, "start": 125.16, "end": 130.35999999999999, "text": " like Pravega that is still about massaging and distributed streaming. And also contributed", "tokens": [411, 12133, 303, 3680, 300, 307, 920, 466, 2758, 3568, 293, 12631, 11791, 13, 400, 611, 18434], "temperature": 0.0, "avg_logprob": -0.21463775634765625, "compression_ratio": 1.5407407407407407, "no_speech_prob": 0.0008828295394778252}, {"id": 19, "seek": 12516, "start": 130.35999999999999, "end": 134.64, "text": " to RDB that is a Distributed Embeddable Java Database.", "tokens": [281, 497, 27735, 300, 307, 257, 9840, 2024, 4866, 24234, 292, 67, 712, 10745, 40461, 651, 13], "temperature": 0.0, "avg_logprob": -0.21463775634765625, "compression_ratio": 1.5407407407407407, "no_speech_prob": 0.0008828295394778252}, {"id": 20, "seek": 12516, "start": 134.64, "end": 140.92, "text": " Okay. Great. Thanks, Enrico. I'm really happy today to be here with Enrico because we were", "tokens": [1033, 13, 3769, 13, 2561, 11, 2193, 23776, 13, 286, 478, 534, 2055, 965, 281, 312, 510, 365, 2193, 23776, 570, 321, 645], "temperature": 0.0, "avg_logprob": -0.21463775634765625, "compression_ratio": 1.5407407407407407, "no_speech_prob": 0.0008828295394778252}, {"id": 21, "seek": 12516, "start": 140.92, "end": 145.6, "text": " just working remotely, finally get to meet here in Belgium when he lives in Italy. And", "tokens": [445, 1364, 20824, 11, 2721, 483, 281, 1677, 510, 294, 28094, 562, 415, 2909, 294, 10705, 13, 400], "temperature": 0.0, "avg_logprob": -0.21463775634765625, "compression_ratio": 1.5407407407407407, "no_speech_prob": 0.0008828295394778252}, {"id": 22, "seek": 12516, "start": 145.6, "end": 151.24, "text": " I'm in Chicago. So, okay. So without further ado, this is the agenda like within 20 minutes.", "tokens": [286, 478, 294, 9525, 13, 407, 11, 1392, 13, 407, 1553, 3052, 22450, 11, 341, 307, 264, 9829, 411, 1951, 945, 2077, 13], "temperature": 0.0, "avg_logprob": -0.21463775634765625, "compression_ratio": 1.5407407407407407, "no_speech_prob": 0.0008828295394778252}, {"id": 23, "seek": 15124, "start": 151.24, "end": 155.64000000000001, "text": " So it's going to be a little bit quick, but we'll end up having Enrico also doing some", "tokens": [407, 309, 311, 516, 281, 312, 257, 707, 857, 1702, 11, 457, 321, 603, 917, 493, 1419, 2193, 23776, 611, 884, 512], "temperature": 0.0, "avg_logprob": -0.16199161211649576, "compression_ratio": 1.6742424242424243, "no_speech_prob": 8.453470945823938e-05}, {"id": 24, "seek": 15124, "start": 155.64000000000001, "end": 161.52, "text": " quick demo as well. So first, let's kind of give an introduction to what is JMS, assuming", "tokens": [1702, 10723, 382, 731, 13, 407, 700, 11, 718, 311, 733, 295, 976, 364, 9339, 281, 437, 307, 508, 10288, 11, 11926], "temperature": 0.0, "avg_logprob": -0.16199161211649576, "compression_ratio": 1.6742424242424243, "no_speech_prob": 8.453470945823938e-05}, {"id": 25, "seek": 15124, "start": 161.52, "end": 165.52, "text": " you know, not everybody is familiar with that. So some introduction. And then we'll talk", "tokens": [291, 458, 11, 406, 2201, 307, 4963, 365, 300, 13, 407, 512, 9339, 13, 400, 550, 321, 603, 751], "temperature": 0.0, "avg_logprob": -0.16199161211649576, "compression_ratio": 1.6742424242424243, "no_speech_prob": 8.453470945823938e-05}, {"id": 26, "seek": 15124, "start": 165.52, "end": 170.96, "text": " about Apache Pulsar and why Pulsar. And also just quickly describe the Pulsar architecture", "tokens": [466, 46597, 430, 9468, 289, 293, 983, 430, 9468, 289, 13, 400, 611, 445, 2661, 6786, 264, 430, 9468, 289, 9482], "temperature": 0.0, "avg_logprob": -0.16199161211649576, "compression_ratio": 1.6742424242424243, "no_speech_prob": 8.453470945823938e-05}, {"id": 27, "seek": 15124, "start": 170.96, "end": 176.64000000000001, "text": " and how do you do the mapping between JMS and Pulsar. And then how do you use JMS API", "tokens": [293, 577, 360, 291, 360, 264, 18350, 1296, 508, 10288, 293, 430, 9468, 289, 13, 400, 550, 577, 360, 291, 764, 508, 10288, 9362], "temperature": 0.0, "avg_logprob": -0.16199161211649576, "compression_ratio": 1.6742424242424243, "no_speech_prob": 8.453470945823938e-05}, {"id": 28, "seek": 17664, "start": 176.64, "end": 182.88, "text": " with Pulsar. And Enrico will show that. And then that's how we're going to be doing.", "tokens": [365, 430, 9468, 289, 13, 400, 2193, 23776, 486, 855, 300, 13, 400, 550, 300, 311, 577, 321, 434, 516, 281, 312, 884, 13], "temperature": 0.0, "avg_logprob": -0.16263133404301663, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.00014129278133623302}, {"id": 29, "seek": 17664, "start": 182.88, "end": 188.16, "text": " So first of all, just some core concepts too, right, of JMS. And as such, right, JMS is", "tokens": [407, 700, 295, 439, 11, 445, 512, 4965, 10392, 886, 11, 558, 11, 295, 508, 10288, 13, 400, 382, 1270, 11, 558, 11, 508, 10288, 307], "temperature": 0.0, "avg_logprob": -0.16263133404301663, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.00014129278133623302}, {"id": 30, "seek": 17664, "start": 188.16, "end": 194.76, "text": " all about also messaging, but it's very much a Java centric technology. And it's here,", "tokens": [439, 466, 611, 21812, 11, 457, 309, 311, 588, 709, 257, 10745, 1489, 1341, 2899, 13, 400, 309, 311, 510, 11], "temperature": 0.0, "avg_logprob": -0.16263133404301663, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.00014129278133623302}, {"id": 31, "seek": 17664, "start": 194.76, "end": 200.32, "text": " as you can see, right, it's also published, subscribed kind of model, making use of destinations", "tokens": [382, 291, 393, 536, 11, 558, 11, 309, 311, 611, 6572, 11, 16665, 733, 295, 2316, 11, 1455, 764, 295, 37787], "temperature": 0.0, "avg_logprob": -0.16263133404301663, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.00014129278133623302}, {"id": 32, "seek": 20032, "start": 200.32, "end": 207.28, "text": " that it supports queues and topics. So messages, producers, consumers, these are typical like", "tokens": [300, 309, 9346, 631, 1247, 293, 8378, 13, 407, 7897, 11, 16080, 11, 11883, 11, 613, 366, 7476, 411], "temperature": 0.0, "avg_logprob": -0.19990041886252918, "compression_ratio": 1.577092511013216, "no_speech_prob": 3.419037238927558e-05}, {"id": 33, "seek": 20032, "start": 207.28, "end": 211.84, "text": " pop-up producer, consumer type of pattern. As such, it's a pattern, but this has its", "tokens": [1665, 12, 1010, 12314, 11, 9711, 2010, 295, 5102, 13, 1018, 1270, 11, 309, 311, 257, 5102, 11, 457, 341, 575, 1080], "temperature": 0.0, "avg_logprob": -0.19990041886252918, "compression_ratio": 1.577092511013216, "no_speech_prob": 3.419037238927558e-05}, {"id": 34, "seek": 20032, "start": 211.84, "end": 217.12, "text": " own implementation. And basically too, it makes use of the JMS context and that will", "tokens": [1065, 11420, 13, 400, 1936, 886, 11, 309, 1669, 764, 295, 264, 508, 10288, 4319, 293, 300, 486], "temperature": 0.0, "avg_logprob": -0.19990041886252918, "compression_ratio": 1.577092511013216, "no_speech_prob": 3.419037238927558e-05}, {"id": 35, "seek": 20032, "start": 217.12, "end": 223.92, "text": " help you with the connections and sessions. Okay, so about destinations, right. So essentially", "tokens": [854, 291, 365, 264, 9271, 293, 11081, 13, 1033, 11, 370, 466, 37787, 11, 558, 13, 407, 4476], "temperature": 0.0, "avg_logprob": -0.19990041886252918, "compression_ratio": 1.577092511013216, "no_speech_prob": 3.419037238927558e-05}, {"id": 36, "seek": 22392, "start": 223.92, "end": 230.67999999999998, "text": " too, it supports both queuing and the topic too. And so it acts as a broker in the topic", "tokens": [886, 11, 309, 9346, 1293, 631, 9635, 293, 264, 4829, 886, 13, 400, 370, 309, 10672, 382, 257, 26502, 294, 264, 4829], "temperature": 0.0, "avg_logprob": -0.15856485285310665, "compression_ratio": 1.7743190661478598, "no_speech_prob": 3.809488407569006e-05}, {"id": 37, "seek": 22392, "start": 230.67999999999998, "end": 236.88, "text": " case, but for queues. So each message is basically, as such, right, message queue is you drop", "tokens": [1389, 11, 457, 337, 631, 1247, 13, 407, 1184, 3636, 307, 1936, 11, 382, 1270, 11, 558, 11, 3636, 18639, 307, 291, 3270], "temperature": 0.0, "avg_logprob": -0.15856485285310665, "compression_ratio": 1.7743190661478598, "no_speech_prob": 3.809488407569006e-05}, {"id": 38, "seek": 22392, "start": 236.88, "end": 241.56, "text": " the message there and then it gets picked up and then it's kind of done, right, by the", "tokens": [264, 3636, 456, 293, 550, 309, 2170, 6183, 493, 293, 550, 309, 311, 733, 295, 1096, 11, 558, 11, 538, 264], "temperature": 0.0, "avg_logprob": -0.15856485285310665, "compression_ratio": 1.7743190661478598, "no_speech_prob": 3.809488407569006e-05}, {"id": 39, "seek": 22392, "start": 241.56, "end": 247.23999999999998, "text": " consumer like that. It's browsable, this queue, first in, first out kind of approach. And", "tokens": [9711, 411, 300, 13, 467, 311, 8333, 712, 11, 341, 18639, 11, 700, 294, 11, 700, 484, 733, 295, 3109, 13, 400], "temperature": 0.0, "avg_logprob": -0.15856485285310665, "compression_ratio": 1.7743190661478598, "no_speech_prob": 3.809488407569006e-05}, {"id": 40, "seek": 22392, "start": 247.23999999999998, "end": 253.64, "text": " then with topic, it allows for multiple subscriptions too. And message dispatch according to the", "tokens": [550, 365, 4829, 11, 309, 4045, 337, 3866, 44951, 886, 13, 400, 3636, 36729, 4650, 281, 264], "temperature": 0.0, "avg_logprob": -0.15856485285310665, "compression_ratio": 1.7743190661478598, "no_speech_prob": 3.809488407569006e-05}, {"id": 41, "seek": 25364, "start": 253.64, "end": 259.28, "text": " subscription type as well. And consumer, as far as consumers styles go, you can have", "tokens": [17231, 2010, 382, 731, 13, 400, 9711, 11, 382, 1400, 382, 11883, 13273, 352, 11, 291, 393, 362], "temperature": 0.0, "avg_logprob": -0.16375302159508995, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.00022131011064630002}, {"id": 42, "seek": 25364, "start": 259.28, "end": 265.32, "text": " blocking, which is in the blocking received methods and that's all application driven.", "tokens": [17776, 11, 597, 307, 294, 264, 17776, 4613, 7150, 293, 300, 311, 439, 3861, 9555, 13], "temperature": 0.0, "avg_logprob": -0.16375302159508995, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.00022131011064630002}, {"id": 43, "seek": 25364, "start": 265.32, "end": 272.64, "text": " And also, yeah, okay. And then there's also making use of the message listener method,", "tokens": [400, 611, 11, 1338, 11, 1392, 13, 400, 550, 456, 311, 611, 1455, 764, 295, 264, 3636, 31569, 3170, 11], "temperature": 0.0, "avg_logprob": -0.16375302159508995, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.00022131011064630002}, {"id": 44, "seek": 25364, "start": 272.64, "end": 279.59999999999997, "text": " which is a JMS to driver driven in that case. And as far as producer styles go, the blocking", "tokens": [597, 307, 257, 508, 10288, 281, 6787, 9555, 294, 300, 1389, 13, 400, 382, 1400, 382, 12314, 13273, 352, 11, 264, 17776], "temperature": 0.0, "avg_logprob": -0.16375302159508995, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.00022131011064630002}, {"id": 45, "seek": 27960, "start": 279.6, "end": 284.44, "text": " will be send method or there's also a async send too. And that will be like with completion", "tokens": [486, 312, 2845, 3170, 420, 456, 311, 611, 257, 382, 34015, 2845, 886, 13, 400, 300, 486, 312, 411, 365, 19372], "temperature": 0.0, "avg_logprob": -0.17031599440664616, "compression_ratio": 1.8015873015873016, "no_speech_prob": 6.274264887906611e-05}, {"id": 46, "seek": 27960, "start": 284.44, "end": 290.44, "text": " listener. So that's real quickly. And then as far as administrative operations go, as", "tokens": [31569, 13, 407, 300, 311, 957, 2661, 13, 400, 550, 382, 1400, 382, 17900, 7705, 352, 11, 382], "temperature": 0.0, "avg_logprob": -0.17031599440664616, "compression_ratio": 1.8015873015873016, "no_speech_prob": 6.274264887906611e-05}, {"id": 47, "seek": 27960, "start": 290.44, "end": 297.6, "text": " we know, JMS does not cover administrative operations. And how do you manage the destinations", "tokens": [321, 458, 11, 508, 10288, 775, 406, 2060, 17900, 7705, 13, 400, 577, 360, 291, 3067, 264, 37787], "temperature": 0.0, "avg_logprob": -0.17031599440664616, "compression_ratio": 1.8015873015873016, "no_speech_prob": 6.274264887906611e-05}, {"id": 48, "seek": 27960, "start": 297.6, "end": 302.40000000000003, "text": " and doing, you know, connection properties, all of these things, the defining security", "tokens": [293, 884, 11, 291, 458, 11, 4984, 7221, 11, 439, 295, 613, 721, 11, 264, 17827, 3825], "temperature": 0.0, "avg_logprob": -0.17031599440664616, "compression_ratio": 1.8015873015873016, "no_speech_prob": 6.274264887906611e-05}, {"id": 49, "seek": 27960, "start": 302.40000000000003, "end": 307.72, "text": " models or resource limits, all of these things and configure all of these at JMS itself doesn't", "tokens": [5245, 420, 7684, 10406, 11, 439, 295, 613, 721, 293, 22162, 439, 295, 613, 412, 508, 10288, 2564, 1177, 380], "temperature": 0.0, "avg_logprob": -0.17031599440664616, "compression_ratio": 1.8015873015873016, "no_speech_prob": 6.274264887906611e-05}, {"id": 50, "seek": 30772, "start": 307.72, "end": 313.6, "text": " have to do it. So how do you manage it? It usually relies on your vendor. How do you,", "tokens": [362, 281, 360, 309, 13, 407, 577, 360, 291, 3067, 309, 30, 467, 2673, 30910, 322, 428, 24321, 13, 1012, 360, 291, 11], "temperature": 0.0, "avg_logprob": -0.17392972720566616, "compression_ratio": 1.6604651162790698, "no_speech_prob": 4.891653952654451e-05}, {"id": 51, "seek": 30772, "start": 313.6, "end": 318.88000000000005, "text": " you know, we kind of do all of the management too is through some vendor way of allowing", "tokens": [291, 458, 11, 321, 733, 295, 360, 439, 295, 264, 4592, 886, 307, 807, 512, 24321, 636, 295, 8293], "temperature": 0.0, "avg_logprob": -0.17392972720566616, "compression_ratio": 1.6604651162790698, "no_speech_prob": 4.891653952654451e-05}, {"id": 52, "seek": 30772, "start": 318.88000000000005, "end": 327.20000000000005, "text": " you to do that. And so basically too, there's also API also to let you work with administrative", "tokens": [291, 281, 360, 300, 13, 400, 370, 1936, 886, 11, 456, 311, 611, 9362, 611, 281, 718, 291, 589, 365, 17900], "temperature": 0.0, "avg_logprob": -0.17392972720566616, "compression_ratio": 1.6604651162790698, "no_speech_prob": 4.891653952654451e-05}, {"id": 53, "seek": 30772, "start": 327.20000000000005, "end": 332.40000000000003, "text": " objects too. And so basically, they're, you know, supposed to be kind of also provided", "tokens": [6565, 886, 13, 400, 370, 1936, 11, 436, 434, 11, 291, 458, 11, 3442, 281, 312, 733, 295, 611, 5649], "temperature": 0.0, "avg_logprob": -0.17392972720566616, "compression_ratio": 1.6604651162790698, "no_speech_prob": 4.891653952654451e-05}, {"id": 54, "seek": 33240, "start": 332.4, "end": 338.84, "text": " by the system as well. And as far as destinations go, there are queue and topic references.", "tokens": [538, 264, 1185, 382, 731, 13, 400, 382, 1400, 382, 37787, 352, 11, 456, 366, 18639, 293, 4829, 15400, 13], "temperature": 0.0, "avg_logprob": -0.19505562038596616, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.7431240091100335e-05}, {"id": 55, "seek": 33240, "start": 338.84, "end": 343.23999999999995, "text": " And connection factory basically is the, is essentially too, using connection factory", "tokens": [400, 4984, 9265, 1936, 307, 264, 11, 307, 4476, 886, 11, 1228, 4984, 9265], "temperature": 0.0, "avg_logprob": -0.19505562038596616, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.7431240091100335e-05}, {"id": 56, "seek": 33240, "start": 343.23999999999995, "end": 348.88, "text": " is the client that allows you to connect to the system in that case. And then there's", "tokens": [307, 264, 6423, 300, 4045, 291, 281, 1745, 281, 264, 1185, 294, 300, 1389, 13, 400, 550, 456, 311], "temperature": 0.0, "avg_logprob": -0.19505562038596616, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.7431240091100335e-05}, {"id": 57, "seek": 33240, "start": 348.88, "end": 356.0, "text": " also JMS, right? The API is essentially allows you to interact with Java EE or now is Jakarta", "tokens": [611, 508, 10288, 11, 558, 30, 440, 9362, 307, 4476, 4045, 291, 281, 4648, 365, 10745, 33685, 420, 586, 307, 15029, 19061], "temperature": 0.0, "avg_logprob": -0.19505562038596616, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.7431240091100335e-05}, {"id": 58, "seek": 33240, "start": 356.0, "end": 362.03999999999996, "text": " EE, but back then there's Jakarta Java EE. And in that case, you can basically make use", "tokens": [33685, 11, 457, 646, 550, 456, 311, 15029, 19061, 10745, 33685, 13, 400, 294, 300, 1389, 11, 291, 393, 1936, 652, 764], "temperature": 0.0, "avg_logprob": -0.19505562038596616, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.7431240091100335e-05}, {"id": 59, "seek": 36204, "start": 362.04, "end": 369.0, "text": " of EJB components. There's stateful, stateless EJB. That's used in web surflets or, you", "tokens": [295, 462, 41, 33, 6677, 13, 821, 311, 1785, 906, 11, 2219, 4272, 462, 41, 33, 13, 663, 311, 1143, 294, 3670, 9684, 12541, 420, 11, 291], "temperature": 0.0, "avg_logprob": -0.22438275814056396, "compression_ratio": 1.5301724137931034, "no_speech_prob": 4.461711796466261e-05}, {"id": 60, "seek": 36204, "start": 369.0, "end": 376.36, "text": " know, the Jax RS, Jax WS endpoints, right? And it allows you to also do background like", "tokens": [458, 11, 264, 508, 2797, 25855, 11, 508, 2797, 343, 50, 917, 20552, 11, 558, 30, 400, 309, 4045, 291, 281, 611, 360, 3678, 411], "temperature": 0.0, "avg_logprob": -0.22438275814056396, "compression_ratio": 1.5301724137931034, "no_speech_prob": 4.461711796466261e-05}, {"id": 61, "seek": 36204, "start": 376.36, "end": 381.92, "text": " doing scheduling kind of way of doing things. And then there's also message driven beans.", "tokens": [884, 29055, 733, 295, 636, 295, 884, 721, 13, 400, 550, 456, 311, 611, 3636, 9555, 12010, 13], "temperature": 0.0, "avg_logprob": -0.22438275814056396, "compression_ratio": 1.5301724137931034, "no_speech_prob": 4.461711796466261e-05}, {"id": 62, "seek": 36204, "start": 381.92, "end": 388.0, "text": " So these essentially too is basically their JMS specific kind of beans to handle messages", "tokens": [407, 613, 4476, 886, 307, 1936, 641, 508, 10288, 2685, 733, 295, 12010, 281, 4813, 7897], "temperature": 0.0, "avg_logprob": -0.22438275814056396, "compression_ratio": 1.5301724137931034, "no_speech_prob": 4.461711796466261e-05}, {"id": 63, "seek": 38800, "start": 388.0, "end": 395.64, "text": " in there. And it's basically managed by the container, the, you know, J2, JEE container.", "tokens": [294, 456, 13, 400, 309, 311, 1936, 6453, 538, 264, 10129, 11, 264, 11, 291, 458, 11, 508, 17, 11, 508, 7258, 10129, 13], "temperature": 0.0, "avg_logprob": -0.27444008575088674, "compression_ratio": 1.6650943396226414, "no_speech_prob": 4.1228337067877874e-05}, {"id": 64, "seek": 38800, "start": 395.64, "end": 400.16, "text": " When you receive a messages from a container, then it will be essentially be, you know,", "tokens": [1133, 291, 4774, 257, 7897, 490, 257, 10129, 11, 550, 309, 486, 312, 4476, 312, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.27444008575088674, "compression_ratio": 1.6650943396226414, "no_speech_prob": 4.1228337067877874e-05}, {"id": 65, "seek": 38800, "start": 400.16, "end": 406.72, "text": " activated in that case. So J, the Java EE container provides support for like all of", "tokens": [18157, 294, 300, 1389, 13, 407, 508, 11, 264, 10745, 33685, 10129, 6417, 1406, 337, 411, 439, 295], "temperature": 0.0, "avg_logprob": -0.27444008575088674, "compression_ratio": 1.6650943396226414, "no_speech_prob": 4.1228337067877874e-05}, {"id": 66, "seek": 38800, "start": 406.72, "end": 412.48, "text": " the, you know, life cycle management pulling of these context dependency injection of these", "tokens": [264, 11, 291, 458, 11, 993, 6586, 4592, 8407, 295, 613, 4319, 33621, 22873, 295, 613], "temperature": 0.0, "avg_logprob": -0.27444008575088674, "compression_ratio": 1.6650943396226414, "no_speech_prob": 4.1228337067877874e-05}, {"id": 67, "seek": 41248, "start": 412.48, "end": 418.32, "text": " things and transaction supports of security standard API. All of these tools basically", "tokens": [721, 293, 14425, 9346, 295, 3825, 3832, 9362, 13, 1057, 295, 613, 3873, 1936], "temperature": 0.0, "avg_logprob": -0.20026975257374416, "compression_ratio": 1.699248120300752, "no_speech_prob": 2.8820815714425407e-05}, {"id": 68, "seek": 41248, "start": 418.32, "end": 424.08000000000004, "text": " relying on the container to do that for you. And then there's also to what about external", "tokens": [24140, 322, 264, 10129, 281, 360, 300, 337, 291, 13, 400, 550, 456, 311, 611, 281, 437, 466, 8320], "temperature": 0.0, "avg_logprob": -0.20026975257374416, "compression_ratio": 1.699248120300752, "no_speech_prob": 2.8820815714425407e-05}, {"id": 69, "seek": 41248, "start": 424.08000000000004, "end": 429.16, "text": " resources. So a lot of times, and that's how it relies on resource adapters. It allows", "tokens": [3593, 13, 407, 257, 688, 295, 1413, 11, 293, 300, 311, 577, 309, 30910, 322, 7684, 23169, 1559, 13, 467, 4045], "temperature": 0.0, "avg_logprob": -0.20026975257374416, "compression_ratio": 1.699248120300752, "no_speech_prob": 2.8820815714425407e-05}, {"id": 70, "seek": 41248, "start": 429.16, "end": 436.28000000000003, "text": " you to essentially extend the Java EE container in that case. So in some key points, it basically", "tokens": [291, 281, 4476, 10101, 264, 10745, 33685, 10129, 294, 300, 1389, 13, 407, 294, 512, 2141, 2793, 11, 309, 1936], "temperature": 0.0, "avg_logprob": -0.20026975257374416, "compression_ratio": 1.699248120300752, "no_speech_prob": 2.8820815714425407e-05}, {"id": 71, "seek": 41248, "start": 436.28000000000003, "end": 442.20000000000005, "text": " to use it is you need to have the resource archive file. So dot RAL file that will contain", "tokens": [281, 764, 309, 307, 291, 643, 281, 362, 264, 7684, 23507, 3991, 13, 407, 5893, 497, 3427, 3991, 300, 486, 5304], "temperature": 0.0, "avg_logprob": -0.20026975257374416, "compression_ratio": 1.699248120300752, "no_speech_prob": 2.8820815714425407e-05}, {"id": 72, "seek": 44220, "start": 442.2, "end": 448.12, "text": " the code and you have to then configure the resource adapter and everything. And it allows", "tokens": [264, 3089, 293, 291, 362, 281, 550, 22162, 264, 7684, 22860, 293, 1203, 13, 400, 309, 4045], "temperature": 0.0, "avg_logprob": -0.23547262615627712, "compression_ratio": 1.6763636363636363, "no_speech_prob": 4.252494181855582e-05}, {"id": 73, "seek": 44220, "start": 448.12, "end": 453.12, "text": " you to essentially create administer objects, right? That conforms to these objects will", "tokens": [291, 281, 4476, 1884, 22096, 6565, 11, 558, 30, 663, 18975, 82, 281, 613, 6565, 486], "temperature": 0.0, "avg_logprob": -0.23547262615627712, "compression_ratio": 1.6763636363636363, "no_speech_prob": 4.252494181855582e-05}, {"id": 74, "seek": 44220, "start": 453.12, "end": 459.4, "text": " conform to the standard API and is implemented by the, by the core inside the resource adapter", "tokens": [18975, 281, 264, 3832, 9362, 293, 307, 12270, 538, 264, 11, 538, 264, 4965, 1854, 264, 7684, 22860], "temperature": 0.0, "avg_logprob": -0.23547262615627712, "compression_ratio": 1.6763636363636363, "no_speech_prob": 4.252494181855582e-05}, {"id": 75, "seek": 44220, "start": 459.4, "end": 466.0, "text": " too. So these are the different packages like basically Java X dot JMS. In this case, it's", "tokens": [886, 13, 407, 613, 366, 264, 819, 17401, 411, 1936, 10745, 1783, 5893, 508, 10288, 13, 682, 341, 1389, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.23547262615627712, "compression_ratio": 1.6763636363636363, "no_speech_prob": 4.252494181855582e-05}, {"id": 76, "seek": 44220, "start": 466.0, "end": 471.68, "text": " I think in the new, new version would be Jakarta, but we're still talking about Java, the older", "tokens": [286, 519, 294, 264, 777, 11, 777, 3037, 576, 312, 15029, 19061, 11, 457, 321, 434, 920, 1417, 466, 10745, 11, 264, 4906], "temperature": 0.0, "avg_logprob": -0.23547262615627712, "compression_ratio": 1.6763636363636363, "no_speech_prob": 4.252494181855582e-05}, {"id": 77, "seek": 47168, "start": 471.68, "end": 477.40000000000003, "text": " JMS in this case, and will be connection factory queue and topic. So usually each objects to", "tokens": [508, 10288, 294, 341, 1389, 11, 293, 486, 312, 4984, 9265, 18639, 293, 4829, 13, 407, 2673, 1184, 6565, 281], "temperature": 0.0, "avg_logprob": -0.2044486837872004, "compression_ratio": 1.6170212765957446, "no_speech_prob": 4.602575791068375e-05}, {"id": 78, "seek": 47168, "start": 477.40000000000003, "end": 484.96000000000004, "text": " a bound to a JNDI naming and directory interface registry, right, provided by the container.", "tokens": [257, 5472, 281, 257, 508, 13360, 40, 25290, 293, 21120, 9226, 36468, 11, 558, 11, 5649, 538, 264, 10129, 13], "temperature": 0.0, "avg_logprob": -0.2044486837872004, "compression_ratio": 1.6170212765957446, "no_speech_prob": 4.602575791068375e-05}, {"id": 79, "seek": 47168, "start": 484.96000000000004, "end": 489.72, "text": " And so it's specific to the container as to how you do deployment too. And that's how", "tokens": [400, 370, 309, 311, 2685, 281, 264, 10129, 382, 281, 577, 291, 360, 19317, 886, 13, 400, 300, 311, 577], "temperature": 0.0, "avg_logprob": -0.2044486837872004, "compression_ratio": 1.6170212765957446, "no_speech_prob": 4.602575791068375e-05}, {"id": 80, "seek": 47168, "start": 489.72, "end": 495.48, "text": " it usually works. Now then let's get introduced, right? So now we talk, talk about JMS stuff", "tokens": [309, 2673, 1985, 13, 823, 550, 718, 311, 483, 7268, 11, 558, 30, 407, 586, 321, 751, 11, 751, 466, 508, 10288, 1507], "temperature": 0.0, "avg_logprob": -0.2044486837872004, "compression_ratio": 1.6170212765957446, "no_speech_prob": 4.602575791068375e-05}, {"id": 81, "seek": 47168, "start": 495.48, "end": 500.08, "text": " is a bit more legacy stuff. So what are some of the options, right? To, to kind of leverage", "tokens": [307, 257, 857, 544, 11711, 1507, 13, 407, 437, 366, 512, 295, 264, 3956, 11, 558, 30, 1407, 11, 281, 733, 295, 13982], "temperature": 0.0, "avg_logprob": -0.2044486837872004, "compression_ratio": 1.6170212765957446, "no_speech_prob": 4.602575791068375e-05}, {"id": 82, "seek": 50008, "start": 500.08, "end": 505.68, "text": " on today's like more modern world that allows you to work in a cloud native environment.", "tokens": [322, 965, 311, 411, 544, 4363, 1002, 300, 4045, 291, 281, 589, 294, 257, 4588, 8470, 2823, 13], "temperature": 0.0, "avg_logprob": -0.17390140351795014, "compression_ratio": 1.619047619047619, "no_speech_prob": 7.55138389649801e-05}, {"id": 83, "seek": 50008, "start": 505.68, "end": 511.15999999999997, "text": " But also we want to introduce to you Apache Pulsar is an open source platform and it's", "tokens": [583, 611, 321, 528, 281, 5366, 281, 291, 46597, 430, 9468, 289, 307, 364, 1269, 4009, 3663, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.17390140351795014, "compression_ratio": 1.619047619047619, "no_speech_prob": 7.55138389649801e-05}, {"id": 84, "seek": 50008, "start": 511.15999999999997, "end": 517.4399999999999, "text": " cloud native and it supports distributed messaging and streaming too. And as such too, this is", "tokens": [4588, 8470, 293, 309, 9346, 12631, 21812, 293, 11791, 886, 13, 400, 382, 1270, 886, 11, 341, 307], "temperature": 0.0, "avg_logprob": -0.17390140351795014, "compression_ratio": 1.619047619047619, "no_speech_prob": 7.55138389649801e-05}, {"id": 85, "seek": 50008, "start": 517.4399999999999, "end": 521.8, "text": " the link where you can kind of find out more information or this is actually more the,", "tokens": [264, 2113, 689, 291, 393, 733, 295, 915, 484, 544, 1589, 420, 341, 307, 767, 544, 264, 11], "temperature": 0.0, "avg_logprob": -0.17390140351795014, "compression_ratio": 1.619047619047619, "no_speech_prob": 7.55138389649801e-05}, {"id": 86, "seek": 50008, "start": 521.8, "end": 526.96, "text": " the GitHub repo. So wanting to highlight it because we don't have too much time, but", "tokens": [264, 23331, 49040, 13, 407, 7935, 281, 5078, 309, 570, 321, 500, 380, 362, 886, 709, 565, 11, 457], "temperature": 0.0, "avg_logprob": -0.17390140351795014, "compression_ratio": 1.619047619047619, "no_speech_prob": 7.55138389649801e-05}, {"id": 87, "seek": 52696, "start": 526.96, "end": 534.48, "text": " basically it's very cloud native in nature. It's born with the cloud native DNA and various,", "tokens": [1936, 309, 311, 588, 4588, 8470, 294, 3687, 13, 467, 311, 4232, 365, 264, 4588, 8470, 8272, 293, 3683, 11], "temperature": 0.0, "avg_logprob": -0.1955705370221819, "compression_ratio": 1.823045267489712, "no_speech_prob": 5.788691123598255e-05}, {"id": 88, "seek": 52696, "start": 534.48, "end": 539.4000000000001, "text": " you know, it's basically the key point of it is that why do you want pulsars? I think", "tokens": [291, 458, 11, 309, 311, 1936, 264, 2141, 935, 295, 309, 307, 300, 983, 360, 291, 528, 32295, 685, 30, 286, 519], "temperature": 0.0, "avg_logprob": -0.1955705370221819, "compression_ratio": 1.823045267489712, "no_speech_prob": 5.788691123598255e-05}, {"id": 89, "seek": 52696, "start": 539.4000000000001, "end": 543.96, "text": " what, I think at least one of the key point, it separates out the compute and the storage.", "tokens": [437, 11, 286, 519, 412, 1935, 472, 295, 264, 2141, 935, 11, 309, 34149, 484, 264, 14722, 293, 264, 6725, 13], "temperature": 0.0, "avg_logprob": -0.1955705370221819, "compression_ratio": 1.823045267489712, "no_speech_prob": 5.788691123598255e-05}, {"id": 90, "seek": 52696, "start": 543.96, "end": 549.72, "text": " So basically Pulsar can focus more on working with the messages delivery, right, dealing", "tokens": [407, 1936, 430, 9468, 289, 393, 1879, 544, 322, 1364, 365, 264, 7897, 8982, 11, 558, 11, 6260], "temperature": 0.0, "avg_logprob": -0.1955705370221819, "compression_ratio": 1.823045267489712, "no_speech_prob": 5.788691123598255e-05}, {"id": 91, "seek": 52696, "start": 549.72, "end": 553.44, "text": " with all the messages coming in, delivering all of these things. And then, you know,", "tokens": [365, 439, 264, 7897, 1348, 294, 11, 14666, 439, 295, 613, 721, 13, 400, 550, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1955705370221819, "compression_ratio": 1.823045267489712, "no_speech_prob": 5.788691123598255e-05}, {"id": 92, "seek": 55344, "start": 553.44, "end": 557.5600000000001, "text": " you have a whole laundry baskets of all the log messages, then what do you do with it?", "tokens": [291, 362, 257, 1379, 19811, 42853, 295, 439, 264, 3565, 7897, 11, 550, 437, 360, 291, 360, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.13510796643685605, "compression_ratio": 1.723127035830619, "no_speech_prob": 4.969431756762788e-05}, {"id": 93, "seek": 55344, "start": 557.5600000000001, "end": 562.0, "text": " Rather than dealing with it, Pulsar said, let me get bookkeeper to handle it for me.", "tokens": [16571, 813, 6260, 365, 309, 11, 430, 9468, 289, 848, 11, 718, 385, 483, 1446, 23083, 281, 4813, 309, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.13510796643685605, "compression_ratio": 1.723127035830619, "no_speech_prob": 4.969431756762788e-05}, {"id": 94, "seek": 55344, "start": 562.0, "end": 566.7600000000001, "text": " So, so that way Pulsar can focus on that, you know, just the messaging part and coordinate", "tokens": [407, 11, 370, 300, 636, 430, 9468, 289, 393, 1879, 322, 300, 11, 291, 458, 11, 445, 264, 21812, 644, 293, 15670], "temperature": 0.0, "avg_logprob": -0.13510796643685605, "compression_ratio": 1.723127035830619, "no_speech_prob": 4.969431756762788e-05}, {"id": 95, "seek": 55344, "start": 566.7600000000001, "end": 571.0, "text": " with the bookkeepers. So that's what it does. And it also supports multi-tenancy and that's", "tokens": [365, 264, 1446, 43153, 13, 407, 300, 311, 437, 309, 775, 13, 400, 309, 611, 9346, 4825, 12, 1147, 6717, 293, 300, 311], "temperature": 0.0, "avg_logprob": -0.13510796643685605, "compression_ratio": 1.723127035830619, "no_speech_prob": 4.969431756762788e-05}, {"id": 96, "seek": 55344, "start": 571.0, "end": 575.9200000000001, "text": " a very nice way of helping you to organize all of your messages, as well as some features", "tokens": [257, 588, 1481, 636, 295, 4315, 291, 281, 13859, 439, 295, 428, 7897, 11, 382, 731, 382, 512, 4122], "temperature": 0.0, "avg_logprob": -0.13510796643685605, "compression_ratio": 1.723127035830619, "no_speech_prob": 4.969431756762788e-05}, {"id": 97, "seek": 55344, "start": 575.9200000000001, "end": 580.2, "text": " that are more kind of ready for enterprise level, like, you know, geo replication is", "tokens": [300, 366, 544, 733, 295, 1919, 337, 14132, 1496, 11, 411, 11, 291, 458, 11, 43198, 39911, 307], "temperature": 0.0, "avg_logprob": -0.13510796643685605, "compression_ratio": 1.723127035830619, "no_speech_prob": 4.969431756762788e-05}, {"id": 98, "seek": 58020, "start": 580.2, "end": 585.6800000000001, "text": " also a major thing in that. And also it has what is called like tiered offset. It's basically", "tokens": [611, 257, 2563, 551, 294, 300, 13, 400, 611, 309, 575, 437, 307, 1219, 411, 12362, 292, 18687, 13, 467, 311, 1936], "temperature": 0.0, "avg_logprob": -0.2077861059279669, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0001287508785026148}, {"id": 99, "seek": 58020, "start": 585.6800000000001, "end": 590.32, "text": " if your messages get code, right, and bookkeeper, you don't want it to take up too much room.", "tokens": [498, 428, 7897, 483, 3089, 11, 558, 11, 293, 1446, 23083, 11, 291, 500, 380, 528, 309, 281, 747, 493, 886, 709, 1808, 13], "temperature": 0.0, "avg_logprob": -0.2077861059279669, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0001287508785026148}, {"id": 100, "seek": 58020, "start": 590.32, "end": 594.6, "text": " Then you want to move it to, or actually, I should say, it gets kind of in the one storage", "tokens": [1396, 291, 528, 281, 1286, 309, 281, 11, 420, 767, 11, 286, 820, 584, 11, 309, 2170, 733, 295, 294, 264, 472, 6725], "temperature": 0.0, "avg_logprob": -0.2077861059279669, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0001287508785026148}, {"id": 101, "seek": 58020, "start": 594.6, "end": 599.36, "text": " and you want to move it off to cold storage. So all these, as Pulsar has built in and it", "tokens": [293, 291, 528, 281, 1286, 309, 766, 281, 3554, 6725, 13, 407, 439, 613, 11, 382, 430, 9468, 289, 575, 3094, 294, 293, 309], "temperature": 0.0, "avg_logprob": -0.2077861059279669, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0001287508785026148}, {"id": 102, "seek": 58020, "start": 599.36, "end": 604.76, "text": " knows it. So native Kubernetes support all of these things, schema, it has a Pulsar schema", "tokens": [3255, 309, 13, 407, 8470, 23145, 1406, 439, 295, 613, 721, 11, 34078, 11, 309, 575, 257, 430, 9468, 289, 34078], "temperature": 0.0, "avg_logprob": -0.2077861059279669, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0001287508785026148}, {"id": 103, "seek": 60476, "start": 604.76, "end": 610.92, "text": " connectors, and you can use the basically Pulsar IO framework to build different connectors.", "tokens": [31865, 11, 293, 291, 393, 764, 264, 1936, 430, 9468, 289, 39839, 8388, 281, 1322, 819, 31865, 13], "temperature": 0.0, "avg_logprob": -0.20366270235269376, "compression_ratio": 1.7294117647058824, "no_speech_prob": 4.604583591572009e-05}, {"id": 104, "seek": 60476, "start": 610.92, "end": 615.2, "text": " And currently we're supporting like almost a hundred different kind of connectors, too,", "tokens": [400, 4362, 321, 434, 7231, 411, 1920, 257, 3262, 819, 733, 295, 31865, 11, 886, 11], "temperature": 0.0, "avg_logprob": -0.20366270235269376, "compression_ratio": 1.7294117647058824, "no_speech_prob": 4.604583591572009e-05}, {"id": 105, "seek": 60476, "start": 615.2, "end": 620.16, "text": " in there. Message processing, you can use the Pulsar functions framework, so you don't", "tokens": [294, 456, 13, 45947, 9007, 11, 291, 393, 764, 264, 430, 9468, 289, 6828, 8388, 11, 370, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.20366270235269376, "compression_ratio": 1.7294117647058824, "no_speech_prob": 4.604583591572009e-05}, {"id": 106, "seek": 60476, "start": 620.16, "end": 624.96, "text": " need to use anything outside to do message transformation as you are building your data", "tokens": [643, 281, 764, 1340, 2380, 281, 360, 3636, 9887, 382, 291, 366, 2390, 428, 1412], "temperature": 0.0, "avg_logprob": -0.20366270235269376, "compression_ratio": 1.7294117647058824, "no_speech_prob": 4.604583591572009e-05}, {"id": 107, "seek": 60476, "start": 624.96, "end": 629.4, "text": " pipeline. And also the nice thing, too, is that it doesn't restrict you to only using", "tokens": [15517, 13, 400, 611, 264, 1481, 551, 11, 886, 11, 307, 300, 309, 1177, 380, 7694, 291, 281, 787, 1228], "temperature": 0.0, "avg_logprob": -0.20366270235269376, "compression_ratio": 1.7294117647058824, "no_speech_prob": 4.604583591572009e-05}, {"id": 108, "seek": 62940, "start": 629.4, "end": 635.52, "text": " Java as your client. You can use other things like C++, Python Go, and other community contributions", "tokens": [10745, 382, 428, 6423, 13, 509, 393, 764, 661, 721, 411, 383, 25472, 11, 15329, 1037, 11, 293, 661, 1768, 15725], "temperature": 0.0, "avg_logprob": -0.17240464302801317, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0001556674687890336}, {"id": 109, "seek": 62940, "start": 635.52, "end": 640.68, "text": " to such a cloud. There's also Node.js, also.NET C-Shop client, too. So that's really", "tokens": [281, 1270, 257, 4588, 13, 821, 311, 611, 38640, 13, 25530, 11, 611, 2411, 35554, 383, 12, 7774, 404, 6423, 11, 886, 13, 407, 300, 311, 534], "temperature": 0.0, "avg_logprob": -0.17240464302801317, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0001556674687890336}, {"id": 110, "seek": 62940, "start": 640.68, "end": 645.68, "text": " flexible and really functioning real well in Pulsar. So let's kind of really quickly", "tokens": [11358, 293, 534, 18483, 957, 731, 294, 430, 9468, 289, 13, 407, 718, 311, 733, 295, 534, 2661], "temperature": 0.0, "avg_logprob": -0.17240464302801317, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0001556674687890336}, {"id": 111, "seek": 62940, "start": 645.68, "end": 650.3199999999999, "text": " kind of take a look. I already mentioned some of it. Essentially, too, it's a blazing performance.", "tokens": [733, 295, 747, 257, 574, 13, 286, 1217, 2835, 512, 295, 309, 13, 23596, 11, 886, 11, 309, 311, 257, 16379, 8781, 3389, 13], "temperature": 0.0, "avg_logprob": -0.17240464302801317, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0001556674687890336}, {"id": 112, "seek": 62940, "start": 650.3199999999999, "end": 654.8, "text": " That's what we all want. Provides you with true like real-time type of processing. That's", "tokens": [663, 311, 437, 321, 439, 528, 13, 15685, 1875, 291, 365, 2074, 411, 957, 12, 3766, 2010, 295, 9007, 13, 663, 311], "temperature": 0.0, "avg_logprob": -0.17240464302801317, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0001556674687890336}, {"id": 113, "seek": 65480, "start": 654.8, "end": 660.3599999999999, "text": " why we want it, right? It's basically millions of JMS messages can be handled if you have", "tokens": [983, 321, 528, 309, 11, 558, 30, 467, 311, 1936, 6803, 295, 508, 10288, 7897, 393, 312, 18033, 498, 291, 362], "temperature": 0.0, "avg_logprob": -0.1472037474314372, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.457202784484252e-05}, {"id": 114, "seek": 65480, "start": 660.3599999999999, "end": 666.1999999999999, "text": " JMS leveraging on such a platform. So it's all good. Horizontal scalability. If you expand", "tokens": [508, 10288, 32666, 322, 1270, 257, 3663, 13, 407, 309, 311, 439, 665, 13, 42141, 896, 304, 15664, 2310, 13, 759, 291, 5268], "temperature": 0.0, "avg_logprob": -0.1472037474314372, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.457202784484252e-05}, {"id": 115, "seek": 65480, "start": 666.1999999999999, "end": 670.88, "text": " your infrastructure, adding more servers and nodes and all of these to it, Pulsar will", "tokens": [428, 6896, 11, 5127, 544, 15909, 293, 13891, 293, 439, 295, 613, 281, 309, 11, 430, 9468, 289, 486], "temperature": 0.0, "avg_logprob": -0.1472037474314372, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.457202784484252e-05}, {"id": 116, "seek": 65480, "start": 670.88, "end": 675.12, "text": " handle that for you. You don't need to rebalance all of your topics, and you don't need to", "tokens": [4813, 300, 337, 291, 13, 509, 500, 380, 643, 281, 319, 29215, 439, 295, 428, 8378, 11, 293, 291, 500, 380, 643, 281], "temperature": 0.0, "avg_logprob": -0.1472037474314372, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.457202784484252e-05}, {"id": 117, "seek": 65480, "start": 675.12, "end": 679.8399999999999, "text": " deal with offsets, right, such as in maybe like Kafka, things like that. It has its own", "tokens": [2028, 365, 39457, 1385, 11, 558, 11, 1270, 382, 294, 1310, 411, 47064, 11, 721, 411, 300, 13, 467, 575, 1080, 1065], "temperature": 0.0, "avg_logprob": -0.1472037474314372, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.457202784484252e-05}, {"id": 118, "seek": 67984, "start": 679.84, "end": 684.84, "text": " way, so then you don't have to worry as a developer. Worrying about all of these infrastructural", "tokens": [636, 11, 370, 550, 291, 500, 380, 362, 281, 3292, 382, 257, 10754, 13, 343, 2005, 278, 466, 439, 295, 613, 6534, 1757, 1807], "temperature": 0.0, "avg_logprob": -0.19006023406982422, "compression_ratio": 1.7727272727272727, "no_speech_prob": 9.891494119074196e-05}, {"id": 119, "seek": 67984, "start": 684.84, "end": 690.6, "text": " things. So all of these things are just listed here. I know there's a lot of, you know, works", "tokens": [721, 13, 407, 439, 295, 613, 721, 366, 445, 10052, 510, 13, 286, 458, 456, 311, 257, 688, 295, 11, 291, 458, 11, 1985], "temperature": 0.0, "avg_logprob": -0.19006023406982422, "compression_ratio": 1.7727272727272727, "no_speech_prob": 9.891494119074196e-05}, {"id": 120, "seek": 67984, "start": 690.6, "end": 694.2, "text": " in here, but it allows you to kind of get a bit more into detail, and we can share with", "tokens": [294, 510, 11, 457, 309, 4045, 291, 281, 733, 295, 483, 257, 857, 544, 666, 2607, 11, 293, 321, 393, 2073, 365], "temperature": 0.0, "avg_logprob": -0.19006023406982422, "compression_ratio": 1.7727272727272727, "no_speech_prob": 9.891494119074196e-05}, {"id": 121, "seek": 67984, "start": 694.2, "end": 700.32, "text": " you this thing. So let me pass this on to, let me see. Oh, let me kind of quickly, I", "tokens": [291, 341, 551, 13, 407, 718, 385, 1320, 341, 322, 281, 11, 718, 385, 536, 13, 876, 11, 718, 385, 733, 295, 2661, 11, 286], "temperature": 0.0, "avg_logprob": -0.19006023406982422, "compression_ratio": 1.7727272727272727, "no_speech_prob": 9.891494119074196e-05}, {"id": 122, "seek": 67984, "start": 700.32, "end": 705.0, "text": " thought this was on. Okay, so just a really quick basic architecture. This kind of pictorially", "tokens": [1194, 341, 390, 322, 13, 1033, 11, 370, 445, 257, 534, 1702, 3875, 9482, 13, 639, 733, 295, 2317, 284, 2270], "temperature": 0.0, "avg_logprob": -0.19006023406982422, "compression_ratio": 1.7727272727272727, "no_speech_prob": 9.891494119074196e-05}, {"id": 123, "seek": 67984, "start": 705.0, "end": 709.32, "text": " described to you what I just talked about. We only have so little time. So this is just", "tokens": [7619, 281, 291, 437, 286, 445, 2825, 466, 13, 492, 787, 362, 370, 707, 565, 13, 407, 341, 307, 445], "temperature": 0.0, "avg_logprob": -0.19006023406982422, "compression_ratio": 1.7727272727272727, "no_speech_prob": 9.891494119074196e-05}, {"id": 124, "seek": 70932, "start": 709.32, "end": 713.5600000000001, "text": " describing to you, right? Producers, consumers can be written in, you know, many different", "tokens": [16141, 281, 291, 11, 558, 30, 1705, 8117, 433, 11, 11883, 393, 312, 3720, 294, 11, 291, 458, 11, 867, 819], "temperature": 0.0, "avg_logprob": -0.17988483845686712, "compression_ratio": 1.6263736263736264, "no_speech_prob": 7.117658242350444e-05}, {"id": 125, "seek": 70932, "start": 713.5600000000001, "end": 718.5200000000001, "text": " languages, not just with Java, and it gets managing, you know, by bookkeeper that deals", "tokens": [8650, 11, 406, 445, 365, 10745, 11, 293, 309, 2170, 11642, 11, 291, 458, 11, 538, 1446, 23083, 300, 11215], "temperature": 0.0, "avg_logprob": -0.17988483845686712, "compression_ratio": 1.6263736263736264, "no_speech_prob": 7.117658242350444e-05}, {"id": 126, "seek": 70932, "start": 718.5200000000001, "end": 723.8000000000001, "text": " with all of the storage side of things, and very dynamic. As you can see, this kind of", "tokens": [365, 439, 295, 264, 6725, 1252, 295, 721, 11, 293, 588, 8546, 13, 1018, 291, 393, 536, 11, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.17988483845686712, "compression_ratio": 1.6263736263736264, "no_speech_prob": 7.117658242350444e-05}, {"id": 127, "seek": 70932, "start": 723.8000000000001, "end": 729.5600000000001, "text": " quickly summarized in picture what Pulsar can do for you. Okay, and then here, just quick", "tokens": [2661, 14611, 1602, 294, 3036, 437, 430, 9468, 289, 393, 360, 337, 291, 13, 1033, 11, 293, 550, 510, 11, 445, 1702], "temperature": 0.0, "avg_logprob": -0.17988483845686712, "compression_ratio": 1.6263736263736264, "no_speech_prob": 7.117658242350444e-05}, {"id": 128, "seek": 70932, "start": 729.5600000000001, "end": 734.96, "text": " summary Apache Pulsar. Again, take mixtures of a pop-up type of architecture, right, and", "tokens": [12691, 46597, 430, 9468, 289, 13, 3764, 11, 747, 2752, 37610, 295, 257, 1665, 12, 1010, 2010, 295, 9482, 11, 558, 11, 293], "temperature": 0.0, "avg_logprob": -0.17988483845686712, "compression_ratio": 1.6263736263736264, "no_speech_prob": 7.117658242350444e-05}, {"id": 129, "seek": 73496, "start": 734.96, "end": 740.6, "text": " that's what it is, and supports like multi-tenants, namespaces. Different subscription modes", "tokens": [300, 311, 437, 309, 307, 11, 293, 9346, 411, 4825, 12, 1147, 1719, 11, 5288, 79, 2116, 13, 20825, 17231, 14068], "temperature": 0.0, "avg_logprob": -0.19762014938613115, "compression_ratio": 1.5807560137457044, "no_speech_prob": 0.0003375412488821894}, {"id": 130, "seek": 73496, "start": 740.6, "end": 746.2, "text": " do that. You can also leverage on that, essentially turn Pulsar into a queuing kind of capability", "tokens": [360, 300, 13, 509, 393, 611, 13982, 322, 300, 11, 4476, 1261, 430, 9468, 289, 666, 257, 631, 9635, 733, 295, 13759], "temperature": 0.0, "avg_logprob": -0.19762014938613115, "compression_ratio": 1.5807560137457044, "no_speech_prob": 0.0003375412488821894}, {"id": 131, "seek": 73496, "start": 746.2, "end": 752.1600000000001, "text": " if you use an exclusive type of mode to do, you know, subscription. And what other thing?", "tokens": [498, 291, 764, 364, 13005, 2010, 295, 4391, 281, 360, 11, 291, 458, 11, 17231, 13, 400, 437, 661, 551, 30], "temperature": 0.0, "avg_logprob": -0.19762014938613115, "compression_ratio": 1.5807560137457044, "no_speech_prob": 0.0003375412488821894}, {"id": 132, "seek": 73496, "start": 752.1600000000001, "end": 755.5600000000001, "text": " Yeah, so there are different modes. It's just highly flexible is what we're trying to tell", "tokens": [865, 11, 370, 456, 366, 819, 14068, 13, 467, 311, 445, 5405, 11358, 307, 437, 321, 434, 1382, 281, 980], "temperature": 0.0, "avg_logprob": -0.19762014938613115, "compression_ratio": 1.5807560137457044, "no_speech_prob": 0.0003375412488821894}, {"id": 133, "seek": 73496, "start": 755.5600000000001, "end": 762.64, "text": " you about the story. So here, we have a little bit of story about that. We can talk more", "tokens": [291, 466, 264, 1657, 13, 407, 510, 11, 321, 362, 257, 707, 857, 295, 1657, 466, 300, 13, 492, 393, 751, 544], "temperature": 0.0, "avg_logprob": -0.19762014938613115, "compression_ratio": 1.5807560137457044, "no_speech_prob": 0.0003375412488821894}, {"id": 134, "seek": 76264, "start": 762.64, "end": 772.88, "text": " about it later. Yeah, so I just want to map Pulsar concept to JMS. JMS is pretty straightforward.", "tokens": [466, 309, 1780, 13, 865, 11, 370, 286, 445, 528, 281, 4471, 430, 9468, 289, 3410, 281, 508, 10288, 13, 508, 10288, 307, 1238, 15325, 13], "temperature": 0.0, "avg_logprob": -0.18770758310953775, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.0003342427662573755}, {"id": 135, "seek": 76264, "start": 772.88, "end": 779.68, "text": " So the model is quite flexible because it is with a queuing, but also a pop-sub. And", "tokens": [407, 264, 2316, 307, 1596, 11358, 570, 309, 307, 365, 257, 631, 9635, 11, 457, 611, 257, 1665, 12, 30131, 13, 400], "temperature": 0.0, "avg_logprob": -0.18770758310953775, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.0003342427662573755}, {"id": 136, "seek": 76264, "start": 779.68, "end": 787.84, "text": " in Pulsar, the mapping is really natural because you can map a JMS topic to a Pulsar topic,", "tokens": [294, 430, 9468, 289, 11, 264, 18350, 307, 534, 3303, 570, 291, 393, 4471, 257, 508, 10288, 4829, 281, 257, 430, 9468, 289, 4829, 11], "temperature": 0.0, "avg_logprob": -0.18770758310953775, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.0003342427662573755}, {"id": 137, "seek": 78784, "start": 787.84, "end": 795.44, "text": " whatever it is, Pulsar standard topic, partitioned topic, virtual topics. A JMS queue is like", "tokens": [2035, 309, 307, 11, 430, 9468, 289, 3832, 4829, 11, 24808, 292, 4829, 11, 6374, 8378, 13, 316, 508, 10288, 18639, 307, 411], "temperature": 0.0, "avg_logprob": -0.16933900933516652, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0001142533146776259}, {"id": 138, "seek": 78784, "start": 795.44, "end": 801.6, "text": " a Pulsar shared subscription, and the JMS is like a Pulsar message with an envelope and", "tokens": [257, 430, 9468, 289, 5507, 17231, 11, 293, 264, 508, 10288, 307, 411, 257, 430, 9468, 289, 3636, 365, 364, 19989, 293], "temperature": 0.0, "avg_logprob": -0.16933900933516652, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0001142533146776259}, {"id": 139, "seek": 78784, "start": 801.6, "end": 807.6800000000001, "text": " with the body. So in JMS, we have several consumer types. So I'm not going to enter", "tokens": [365, 264, 1772, 13, 407, 294, 508, 10288, 11, 321, 362, 2940, 9711, 3467, 13, 407, 286, 478, 406, 516, 281, 3242], "temperature": 0.0, "avg_logprob": -0.16933900933516652, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0001142533146776259}, {"id": 140, "seek": 78784, "start": 807.6800000000001, "end": 816.5600000000001, "text": " the details, but there is a subscription type that matches the JMS requirements. One important", "tokens": [264, 4365, 11, 457, 456, 307, 257, 17231, 2010, 300, 10676, 264, 508, 10288, 7728, 13, 1485, 1021], "temperature": 0.0, "avg_logprob": -0.16933900933516652, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0001142533146776259}, {"id": 141, "seek": 81656, "start": 816.56, "end": 821.1999999999999, "text": " thing is that if you want to use JMS with Pulsar, you don't need to install any additional", "tokens": [551, 307, 300, 498, 291, 528, 281, 764, 508, 10288, 365, 430, 9468, 289, 11, 291, 500, 380, 643, 281, 3625, 604, 4497], "temperature": 0.0, "avg_logprob": -0.1599541982014974, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00011816305777756497}, {"id": 142, "seek": 81656, "start": 821.1999999999999, "end": 831.8399999999999, "text": " plugin because the JMS API is built over the standard native Java client because the Pulsar", "tokens": [23407, 570, 264, 508, 10288, 9362, 307, 3094, 670, 264, 3832, 8470, 10745, 6423, 570, 264, 430, 9468, 289], "temperature": 0.0, "avg_logprob": -0.1599541982014974, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00011816305777756497}, {"id": 143, "seek": 81656, "start": 831.8399999999999, "end": 839.4399999999999, "text": " features are a super set of JMS. So it's only about implementing an API. You know, in JDBC,", "tokens": [4122, 366, 257, 1687, 992, 295, 508, 10288, 13, 407, 309, 311, 787, 466, 18114, 364, 9362, 13, 509, 458, 11, 294, 37082, 7869, 11], "temperature": 0.0, "avg_logprob": -0.1599541982014974, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00011816305777756497}, {"id": 144, "seek": 83944, "start": 839.44, "end": 846.6400000000001, "text": " you have an API that allows you to connect to every database. In JMS, you just have to implement", "tokens": [291, 362, 364, 9362, 300, 4045, 291, 281, 1745, 281, 633, 8149, 13, 682, 508, 10288, 11, 291, 445, 362, 281, 4445], "temperature": 0.0, "avg_logprob": -0.12244919935862224, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00015343695122282952}, {"id": 145, "seek": 83944, "start": 846.6400000000001, "end": 852.96, "text": " the API and follow the specs. If you want, you can deploy a server-side component just", "tokens": [264, 9362, 293, 1524, 264, 27911, 13, 759, 291, 528, 11, 291, 393, 7274, 257, 7154, 12, 1812, 6542, 445], "temperature": 0.0, "avg_logprob": -0.12244919935862224, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00015343695122282952}, {"id": 146, "seek": 83944, "start": 852.96, "end": 859.0400000000001, "text": " to push some of the computations. So for instance, in JMS, you have filters. You can filter the", "tokens": [281, 2944, 512, 295, 264, 2807, 763, 13, 407, 337, 5197, 11, 294, 508, 10288, 11, 291, 362, 15995, 13, 509, 393, 6608, 264], "temperature": 0.0, "avg_logprob": -0.12244919935862224, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00015343695122282952}, {"id": 147, "seek": 83944, "start": 859.0400000000001, "end": 864.24, "text": " messages. So if you want, you can filter them on the broker. Otherwise, you can simply", "tokens": [7897, 13, 407, 498, 291, 528, 11, 291, 393, 6608, 552, 322, 264, 26502, 13, 10328, 11, 291, 393, 2935], "temperature": 0.0, "avg_logprob": -0.12244919935862224, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00015343695122282952}, {"id": 148, "seek": 86424, "start": 864.24, "end": 875.36, "text": " filter them on the client side. I'm just showing some examples of how to use Pulsar with JMS.", "tokens": [6608, 552, 322, 264, 6423, 1252, 13, 286, 478, 445, 4099, 512, 5110, 295, 577, 281, 764, 430, 9468, 289, 365, 508, 10288, 13], "temperature": 0.0, "avg_logprob": -0.10018637150893976, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.00011996167449979112}, {"id": 149, "seek": 86424, "start": 876.08, "end": 882.8, "text": " Maybe if you are already familiar with JMS, that's pretty simple. So in JMS, you start with a", "tokens": [2704, 498, 291, 366, 1217, 4963, 365, 508, 10288, 11, 300, 311, 1238, 2199, 13, 407, 294, 508, 10288, 11, 291, 722, 365, 257], "temperature": 0.0, "avg_logprob": -0.10018637150893976, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.00011996167449979112}, {"id": 150, "seek": 86424, "start": 882.8, "end": 890.16, "text": " connection factory. So we have Pulsar connection factory. And this is JMS 2.0. And you can get", "tokens": [4984, 9265, 13, 407, 321, 362, 430, 9468, 289, 4984, 9265, 13, 400, 341, 307, 508, 10288, 568, 13, 15, 13, 400, 291, 393, 483], "temperature": 0.0, "avg_logprob": -0.10018637150893976, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.00011996167449979112}, {"id": 151, "seek": 89016, "start": 890.16, "end": 897.6, "text": " a JMS context. You get a reference to a destination. This is create queue. Create queue is not creating", "tokens": [257, 508, 10288, 4319, 13, 509, 483, 257, 6408, 281, 257, 12236, 13, 639, 307, 1884, 18639, 13, 20248, 18639, 307, 406, 4084], "temperature": 0.0, "avg_logprob": -0.09717089931170146, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00011020641977665946}, {"id": 152, "seek": 89016, "start": 897.6, "end": 902.64, "text": " a queue. It's creating a reference to a queue because JMS doesn't deal with administrative", "tokens": [257, 18639, 13, 467, 311, 4084, 257, 6408, 281, 257, 18639, 570, 508, 10288, 1177, 380, 2028, 365, 17900], "temperature": 0.0, "avg_logprob": -0.09717089931170146, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00011020641977665946}, {"id": 153, "seek": 89016, "start": 902.64, "end": 908.88, "text": " operations, as Mary said. You create a producer. You can send as many messages as you want. And", "tokens": [7705, 11, 382, 6059, 848, 13, 509, 1884, 257, 12314, 13, 509, 393, 2845, 382, 867, 7897, 382, 291, 528, 13, 400], "temperature": 0.0, "avg_logprob": -0.09717089931170146, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00011020641977665946}, {"id": 154, "seek": 89016, "start": 908.88, "end": 915.12, "text": " if you want to consume, you create a consumer. And you can use receive or set the message listener.", "tokens": [498, 291, 528, 281, 14732, 11, 291, 1884, 257, 9711, 13, 400, 291, 393, 764, 4774, 420, 992, 264, 3636, 31569, 13], "temperature": 0.0, "avg_logprob": -0.09717089931170146, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00011020641977665946}, {"id": 155, "seek": 91512, "start": 915.12, "end": 922.64, "text": " This is from standard Java. If you're using Jakarta or Java Enterprise, actually, yes,", "tokens": [639, 307, 490, 3832, 10745, 13, 759, 291, 434, 1228, 15029, 19061, 420, 10745, 26696, 11, 767, 11, 2086, 11], "temperature": 0.0, "avg_logprob": -0.21274452209472655, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0008097766549326479}, {"id": 156, "seek": 91512, "start": 922.64, "end": 932.64, "text": " I've been helping a few companies to migrate from Java Enterprise to Pulsar. So I know much", "tokens": [286, 600, 668, 4315, 257, 1326, 3431, 281, 31821, 490, 10745, 26696, 281, 430, 9468, 289, 13, 407, 286, 458, 709], "temperature": 0.0, "avg_logprob": -0.21274452209472655, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0008097766549326479}, {"id": 157, "seek": 91512, "start": 932.64, "end": 940.96, "text": " more cases about Java Enterprise more than Jakarta. But that's it. So for instance, if you", "tokens": [544, 3331, 466, 10745, 26696, 544, 813, 15029, 19061, 13, 583, 300, 311, 309, 13, 407, 337, 5197, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.21274452209472655, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0008097766549326479}, {"id": 158, "seek": 94096, "start": 940.96, "end": 948.88, "text": " want to write and you have an Enterprise Java bin, then you can ask to the container to inject the", "tokens": [528, 281, 2464, 293, 291, 362, 364, 26696, 10745, 5171, 11, 550, 291, 393, 1029, 281, 264, 10129, 281, 10711, 264], "temperature": 0.0, "avg_logprob": -0.2148975615805768, "compression_ratio": 1.8038277511961722, "no_speech_prob": 0.0002768634003587067}, {"id": 159, "seek": 94096, "start": 948.88, "end": 955.44, "text": " connection to Pulsar. And this is a standard Java Enterprise code. So this code runs with", "tokens": [4984, 281, 430, 9468, 289, 13, 400, 341, 307, 257, 3832, 10745, 26696, 3089, 13, 407, 341, 3089, 6676, 365], "temperature": 0.0, "avg_logprob": -0.2148975615805768, "compression_ratio": 1.8038277511961722, "no_speech_prob": 0.0002768634003587067}, {"id": 160, "seek": 94096, "start": 955.44, "end": 963.6800000000001, "text": " ActiveMQ, with TIBCO, with whatever you want, whatever you are running. And the container", "tokens": [26635, 44, 48, 11, 365, 28819, 7869, 46, 11, 365, 2035, 291, 528, 11, 2035, 291, 366, 2614, 13, 400, 264, 10129], "temperature": 0.0, "avg_logprob": -0.2148975615805768, "compression_ratio": 1.8038277511961722, "no_speech_prob": 0.0002768634003587067}, {"id": 161, "seek": 94096, "start": 963.6800000000001, "end": 969.6, "text": " injects the connection factory and the destination. And you can, as in the standard Java code, you", "tokens": [10711, 82, 264, 4984, 9265, 293, 264, 12236, 13, 400, 291, 393, 11, 382, 294, 264, 3832, 10745, 3089, 11, 291], "temperature": 0.0, "avg_logprob": -0.2148975615805768, "compression_ratio": 1.8038277511961722, "no_speech_prob": 0.0002768634003587067}, {"id": 162, "seek": 96960, "start": 969.6, "end": 976.72, "text": " can get a reference to the JMS context and then you send. We will see later how the administrator,", "tokens": [393, 483, 257, 6408, 281, 264, 508, 10288, 4319, 293, 550, 291, 2845, 13, 492, 486, 536, 1780, 577, 264, 25529, 11], "temperature": 0.0, "avg_logprob": -0.19496673086415167, "compression_ratio": 1.4494949494949494, "no_speech_prob": 0.00020573595247697085}, {"id": 163, "seek": 96960, "start": 976.72, "end": 985.28, "text": " for instance, with Apache Tomy, connects all the parts. The consumer, usually in Java Enterprise,", "tokens": [337, 5197, 11, 365, 46597, 5041, 88, 11, 16967, 439, 264, 3166, 13, 440, 9711, 11, 2673, 294, 10745, 26696, 11], "temperature": 0.0, "avg_logprob": -0.19496673086415167, "compression_ratio": 1.4494949494949494, "no_speech_prob": 0.00020573595247697085}, {"id": 164, "seek": 96960, "start": 985.28, "end": 992.88, "text": " you use message driven bins to consume from destinations. So yes, this is a simple message", "tokens": [291, 764, 3636, 9555, 41275, 281, 14732, 490, 37787, 13, 407, 2086, 11, 341, 307, 257, 2199, 3636], "temperature": 0.0, "avg_logprob": -0.19496673086415167, "compression_ratio": 1.4494949494949494, "no_speech_prob": 0.00020573595247697085}, {"id": 165, "seek": 99288, "start": 992.88, "end": 1002.32, "text": " driven bin. You configure all the relevant things that you want. For instance, usually you", "tokens": [9555, 5171, 13, 509, 22162, 439, 264, 7340, 721, 300, 291, 528, 13, 1171, 5197, 11, 2673, 291], "temperature": 0.0, "avg_logprob": -0.14139298261222194, "compression_ratio": 1.5843373493975903, "no_speech_prob": 0.00020465512352529913}, {"id": 166, "seek": 99288, "start": 1002.32, "end": 1008.64, "text": " configure the destination that is still a logical name and a subscription type or the", "tokens": [22162, 264, 12236, 300, 307, 920, 257, 14978, 1315, 293, 257, 17231, 2010, 420, 264], "temperature": 0.0, "avg_logprob": -0.14139298261222194, "compression_ratio": 1.5843373493975903, "no_speech_prob": 0.00020465512352529913}, {"id": 167, "seek": 99288, "start": 1008.64, "end": 1016.8, "text": " parallelism of the kind of things. In many containers, you can configure the things on", "tokens": [8952, 1434, 295, 264, 733, 295, 721, 13, 682, 867, 17089, 11, 291, 393, 22162, 264, 721, 322], "temperature": 0.0, "avg_logprob": -0.14139298261222194, "compression_ratio": 1.5843373493975903, "no_speech_prob": 0.00020465512352529913}, {"id": 168, "seek": 101680, "start": 1016.8, "end": 1024.1599999999999, "text": " other descriptors or descriptors on user links and files. You implement a callback on message.", "tokens": [661, 31280, 830, 420, 31280, 830, 322, 4195, 6123, 293, 7098, 13, 509, 4445, 257, 818, 3207, 322, 3636, 13], "temperature": 0.0, "avg_logprob": -0.1362566726152287, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.00010314927203580737}, {"id": 169, "seek": 101680, "start": 1024.1599999999999, "end": 1029.76, "text": " Every time a message is dispatched to the application, the code runs and if everything", "tokens": [2048, 565, 257, 3636, 307, 4920, 24102, 281, 264, 3861, 11, 264, 3089, 6676, 293, 498, 1203], "temperature": 0.0, "avg_logprob": -0.1362566726152287, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.00010314927203580737}, {"id": 170, "seek": 101680, "start": 1029.76, "end": 1035.28, "text": " goes well, the message is acknowledged to the Pulsar broker and it won't be delivered anymore.", "tokens": [1709, 731, 11, 264, 3636, 307, 27262, 281, 264, 430, 9468, 289, 26502, 293, 309, 1582, 380, 312, 10144, 3602, 13], "temperature": 0.0, "avg_logprob": -0.1362566726152287, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.00010314927203580737}, {"id": 171, "seek": 101680, "start": 1035.28, "end": 1041.2, "text": " If there is any exception that is thrown, Pulsar will deliver again the message.", "tokens": [759, 456, 307, 604, 11183, 300, 307, 11732, 11, 430, 9468, 289, 486, 4239, 797, 264, 3636, 13], "temperature": 0.0, "avg_logprob": -0.1362566726152287, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.00010314927203580737}, {"id": 172, "seek": 104120, "start": 1041.2, "end": 1050.0, "text": " In Tomy, there is a very simple way to deploy the resource adapter. I'm deploying the resource", "tokens": [682, 5041, 88, 11, 456, 307, 257, 588, 2199, 636, 281, 7274, 264, 7684, 22860, 13, 286, 478, 34198, 264, 7684], "temperature": 0.0, "avg_logprob": -0.17788866403940562, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.00013083273370284587}, {"id": 173, "seek": 104120, "start": 1050.0, "end": 1057.76, "text": " adapter for Pulsar. So Pulsar RA, you configure the connection to Pulsar. Now in the demo,", "tokens": [22860, 337, 430, 9468, 289, 13, 407, 430, 9468, 289, 14626, 11, 291, 22162, 264, 4984, 281, 430, 9468, 289, 13, 823, 294, 264, 10723, 11], "temperature": 0.0, "avg_logprob": -0.17788866403940562, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.00013083273370284587}, {"id": 174, "seek": 104120, "start": 1057.76, "end": 1063.76, "text": " I'm using localhost and this is the most interesting part. I create a logical queue,", "tokens": [286, 478, 1228, 2654, 6037, 293, 341, 307, 264, 881, 1880, 644, 13, 286, 1884, 257, 14978, 18639, 11], "temperature": 0.0, "avg_logprob": -0.17788866403940562, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.00013083273370284587}, {"id": 175, "seek": 106376, "start": 1063.76, "end": 1072.72, "text": " so full queue. This is a queue and I bind it to a physical destination. So the container", "tokens": [370, 1577, 18639, 13, 639, 307, 257, 18639, 293, 286, 14786, 309, 281, 257, 4001, 12236, 13, 407, 264, 10129], "temperature": 0.0, "avg_logprob": -0.15772315434047154, "compression_ratio": 1.4318181818181819, "no_speech_prob": 0.00011821369116660208}, {"id": 176, "seek": 106376, "start": 1072.72, "end": 1078.72, "text": " will create a Pulsar connection factory and also the Pulsar queue.", "tokens": [486, 1884, 257, 430, 9468, 289, 4984, 9265, 293, 611, 264, 430, 9468, 289, 18639, 13], "temperature": 0.0, "avg_logprob": -0.15772315434047154, "compression_ratio": 1.4318181818181819, "no_speech_prob": 0.00011821369116660208}, {"id": 177, "seek": 106376, "start": 1081.12, "end": 1090.0, "text": " The demo is on my GitHub space. So yes, you can run it by yourself. I'm going to use Apache Tomy", "tokens": [440, 10723, 307, 322, 452, 23331, 1901, 13, 407, 2086, 11, 291, 393, 1190, 309, 538, 1803, 13, 286, 478, 516, 281, 764, 46597, 5041, 88], "temperature": 0.0, "avg_logprob": -0.15772315434047154, "compression_ratio": 1.4318181818181819, "no_speech_prob": 0.00011821369116660208}, {"id": 178, "seek": 109000, "start": 1090.0, "end": 1098.64, "text": " 8, Starlight for JMS. I'll talk about that later. It is basically the JMS implementation.", "tokens": [1649, 11, 5705, 2764, 337, 508, 10288, 13, 286, 603, 751, 466, 300, 1780, 13, 467, 307, 1936, 264, 508, 10288, 11420, 13], "temperature": 0.0, "avg_logprob": -0.19667768478393555, "compression_ratio": 1.4350282485875707, "no_speech_prob": 0.0005680149770341814}, {"id": 179, "seek": 109000, "start": 1099.44, "end": 1105.36, "text": " I create the object with the same file that we saw and Apache Pulsar to.11.", "tokens": [286, 1884, 264, 2657, 365, 264, 912, 3991, 300, 321, 1866, 293, 46597, 430, 9468, 289, 281, 2411, 5348, 13], "temperature": 0.0, "avg_logprob": -0.19667768478393555, "compression_ratio": 1.4350282485875707, "no_speech_prob": 0.0005680149770341814}, {"id": 180, "seek": 109000, "start": 1105.36, "end": 1112.24, "text": " So we have one application that consumes, one that produces and Pulsar will run locally.", "tokens": [407, 321, 362, 472, 3861, 300, 48823, 11, 472, 300, 14725, 293, 430, 9468, 289, 486, 1190, 16143, 13], "temperature": 0.0, "avg_logprob": -0.19667768478393555, "compression_ratio": 1.4350282485875707, "no_speech_prob": 0.0005680149770341814}, {"id": 181, "seek": 111224, "start": 1112.24, "end": 1119.52, "text": " So let me switch to the console. Oh no, yes, the code. The code is really simple. This is on", "tokens": [407, 718, 385, 3679, 281, 264, 11076, 13, 876, 572, 11, 2086, 11, 264, 3089, 13, 440, 3089, 307, 534, 2199, 13, 639, 307, 322], "temperature": 0.0, "avg_logprob": -0.10905046586866503, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.00036081619327887893}, {"id": 182, "seek": 111224, "start": 1119.52, "end": 1129.28, "text": " GitHub, so you can check it out later. So this is the producer. I'm not writing the code that", "tokens": [23331, 11, 370, 291, 393, 1520, 309, 484, 1780, 13, 407, 341, 307, 264, 12314, 13, 286, 478, 406, 3579, 264, 3089, 300], "temperature": 0.0, "avg_logprob": -0.10905046586866503, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.00036081619327887893}, {"id": 183, "seek": 111224, "start": 1130.72, "end": 1137.36, "text": " instantiates or assigns some value to the factory or to the queue. I'm scheduling the execution", "tokens": [9836, 72, 1024, 420, 6269, 82, 512, 2158, 281, 264, 9265, 420, 281, 264, 18639, 13, 286, 478, 29055, 264, 15058], "temperature": 0.0, "avg_logprob": -0.10905046586866503, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.00036081619327887893}, {"id": 184, "seek": 113736, "start": 1137.36, "end": 1145.04, "text": " of this method every two seconds and that's it. Very easy. On the JMS listener, these are two", "tokens": [295, 341, 3170, 633, 732, 3949, 293, 300, 311, 309, 13, 4372, 1858, 13, 1282, 264, 508, 10288, 31569, 11, 613, 366, 732], "temperature": 0.0, "avg_logprob": -0.13093787226183662, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.00010324371396563947}, {"id": 185, "seek": 113736, "start": 1145.04, "end": 1150.8, "text": " separate applications. Usually in a real world application, you have some application that", "tokens": [4994, 5821, 13, 11419, 294, 257, 957, 1002, 3861, 11, 291, 362, 512, 3861, 300], "temperature": 0.0, "avg_logprob": -0.13093787226183662, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.00010324371396563947}, {"id": 186, "seek": 113736, "start": 1150.8, "end": 1155.76, "text": " produce the data. Then you have a pipeline that transforms your data and something else that", "tokens": [5258, 264, 1412, 13, 1396, 291, 362, 257, 15517, 300, 35592, 428, 1412, 293, 746, 1646, 300], "temperature": 0.0, "avg_logprob": -0.13093787226183662, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.00010324371396563947}, {"id": 187, "seek": 113736, "start": 1155.76, "end": 1163.52, "text": " consumes the data. This is pretty common. So here, on message, depending on the type of message,", "tokens": [48823, 264, 1412, 13, 639, 307, 1238, 2689, 13, 407, 510, 11, 322, 3636, 11, 5413, 322, 264, 2010, 295, 3636, 11], "temperature": 0.0, "avg_logprob": -0.13093787226183662, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.00010324371396563947}, {"id": 188, "seek": 116352, "start": 1163.52, "end": 1172.6399999999999, "text": " I'm printing the content and message. Here, I'm just declaring the reference to the logical queue", "tokens": [286, 478, 14699, 264, 2701, 293, 3636, 13, 1692, 11, 286, 478, 445, 40374, 264, 6408, 281, 264, 14978, 18639], "temperature": 0.0, "avg_logprob": -0.16906428337097168, "compression_ratio": 1.3448275862068966, "no_speech_prob": 0.00011990926577709615}, {"id": 189, "seek": 116352, "start": 1172.6399999999999, "end": 1182.8, "text": " that I want. In this case, OpenAJB that is still Tommy will resolve the binding with the physical", "tokens": [300, 286, 528, 13, 682, 341, 1389, 11, 7238, 36404, 33, 300, 307, 920, 19448, 486, 14151, 264, 17359, 365, 264, 4001], "temperature": 0.0, "avg_logprob": -0.16906428337097168, "compression_ratio": 1.3448275862068966, "no_speech_prob": 0.00011990926577709615}, {"id": 190, "seek": 118280, "start": 1182.8, "end": 1196.08, "text": " queue via JNDI. We are running out of time. So I have a script to run all the demo. The script", "tokens": [18639, 5766, 508, 13360, 40, 13, 492, 366, 2614, 484, 295, 565, 13, 407, 286, 362, 257, 5755, 281, 1190, 439, 264, 10723, 13, 440, 5755], "temperature": 0.0, "avg_logprob": -0.16234279360089984, "compression_ratio": 1.4300518134715026, "no_speech_prob": 0.00017758927424438298}, {"id": 191, "seek": 118280, "start": 1196.08, "end": 1204.32, "text": " simply installs two instances of Tommy, Pulsar, copies the configuration file, deploys the", "tokens": [2935, 3625, 82, 732, 14519, 295, 19448, 11, 430, 9468, 289, 11, 14341, 264, 11694, 3991, 11, 368, 49522, 264], "temperature": 0.0, "avg_logprob": -0.16234279360089984, "compression_ratio": 1.4300518134715026, "no_speech_prob": 0.00017758927424438298}, {"id": 192, "seek": 118280, "start": 1204.32, "end": 1211.2, "text": " resource archives, changes some ports because I'm running multiple services on my machine.", "tokens": [7684, 25607, 11, 2962, 512, 18160, 570, 286, 478, 2614, 3866, 3328, 322, 452, 3479, 13], "temperature": 0.0, "avg_logprob": -0.16234279360089984, "compression_ratio": 1.4300518134715026, "no_speech_prob": 0.00017758927424438298}, {"id": 193, "seek": 121120, "start": 1211.2, "end": 1217.6000000000001, "text": " So there will be conflicts. Copy the consumer application to Tommy one, copy the producer", "tokens": [407, 456, 486, 312, 19807, 13, 25653, 264, 9711, 3861, 281, 19448, 472, 11, 5055, 264, 12314], "temperature": 0.0, "avg_logprob": -0.1514357475385274, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.00019980769138783216}, {"id": 194, "seek": 121120, "start": 1217.6000000000001, "end": 1224.56, "text": " application to Tommy two, then start the Pulsar standalone. That is a quick way to start Pulsar", "tokens": [3861, 281, 19448, 732, 11, 550, 722, 264, 430, 9468, 289, 37454, 13, 663, 307, 257, 1702, 636, 281, 722, 430, 9468, 289], "temperature": 0.0, "avg_logprob": -0.1514357475385274, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.00019980769138783216}, {"id": 195, "seek": 121120, "start": 1224.56, "end": 1231.6000000000001, "text": " locally with all the services, but only in one JVM process. Tommy one, Tommy two, and then we will", "tokens": [16143, 365, 439, 264, 3328, 11, 457, 787, 294, 472, 508, 53, 44, 1399, 13, 19448, 472, 11, 19448, 732, 11, 293, 550, 321, 486], "temperature": 0.0, "avg_logprob": -0.1514357475385274, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.00019980769138783216}, {"id": 196, "seek": 123160, "start": 1231.6, "end": 1240.8, "text": " see the logs. So there is some noise initially because it is installing everything. This is", "tokens": [536, 264, 20820, 13, 407, 456, 307, 512, 5658, 9105, 570, 309, 307, 20762, 1203, 13, 639, 307], "temperature": 0.0, "avg_logprob": -0.16455536384087105, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.0005983262090012431}, {"id": 197, "seek": 123160, "start": 1240.8, "end": 1251.6799999999998, "text": " Pulsar. This is starting. These are the two Tommy. Actually, we don't see. Oh yes, this is good. So", "tokens": [430, 9468, 289, 13, 639, 307, 2891, 13, 1981, 366, 264, 732, 19448, 13, 5135, 11, 321, 500, 380, 536, 13, 876, 2086, 11, 341, 307, 665, 13, 407], "temperature": 0.0, "avg_logprob": -0.16455536384087105, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.0005983262090012431}, {"id": 198, "seek": 123160, "start": 1251.6799999999998, "end": 1258.7199999999998, "text": " Tommy two is sending the messages. Tommy one is receiving the messages. So it works. It's a very", "tokens": [19448, 732, 307, 7750, 264, 7897, 13, 19448, 472, 307, 10040, 264, 7897, 13, 407, 309, 1985, 13, 467, 311, 257, 588], "temperature": 0.0, "avg_logprob": -0.16455536384087105, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.0005983262090012431}, {"id": 199, "seek": 125872, "start": 1258.72, "end": 1268.24, "text": " straightforward setup and very common way to develop with Java Enterprise. Let's drop up.", "tokens": [15325, 8657, 293, 588, 2689, 636, 281, 1499, 365, 10745, 26696, 13, 961, 311, 3270, 493, 13], "temperature": 0.0, "avg_logprob": -0.18952435605666218, "compression_ratio": 1.4404145077720207, "no_speech_prob": 0.0001744998007779941}, {"id": 200, "seek": 125872, "start": 1269.1200000000001, "end": 1276.0, "text": " Two minutes probably. Yes, okay, good. So JMS is very useful and it allows you to switch very", "tokens": [4453, 2077, 1391, 13, 1079, 11, 1392, 11, 665, 13, 407, 508, 10288, 307, 588, 4420, 293, 309, 4045, 291, 281, 3679, 588], "temperature": 0.0, "avg_logprob": -0.18952435605666218, "compression_ratio": 1.4404145077720207, "no_speech_prob": 0.0001744998007779941}, {"id": 201, "seek": 125872, "start": 1276.0, "end": 1286.96, "text": " easily to another vendor. Usually with JMS you don't use very specific features. Usually in my", "tokens": [3612, 281, 1071, 24321, 13, 11419, 365, 508, 10288, 291, 500, 380, 764, 588, 2685, 4122, 13, 11419, 294, 452], "temperature": 0.0, "avg_logprob": -0.18952435605666218, "compression_ratio": 1.4404145077720207, "no_speech_prob": 0.0001744998007779941}, {"id": 202, "seek": 128696, "start": 1286.96, "end": 1293.04, "text": " experience with JMS, maybe you're using TIBCOR, you're using ActiveMQ. You configure on the container", "tokens": [1752, 365, 508, 10288, 11, 1310, 291, 434, 1228, 28819, 7869, 2483, 11, 291, 434, 1228, 26635, 44, 48, 13, 509, 22162, 322, 264, 10129], "temperature": 0.0, "avg_logprob": -0.2017663132910635, "compression_ratio": 1.5755102040816327, "no_speech_prob": 4.6523437049472705e-05}, {"id": 203, "seek": 128696, "start": 1293.04, "end": 1299.8400000000001, "text": " some special flags, but the code usually is pretty standard. Yes, so switching to Pulsar is usually", "tokens": [512, 2121, 23265, 11, 457, 264, 3089, 2673, 307, 1238, 3832, 13, 1079, 11, 370, 16493, 281, 430, 9468, 289, 307, 2673], "temperature": 0.0, "avg_logprob": -0.2017663132910635, "compression_ratio": 1.5755102040816327, "no_speech_prob": 4.6523437049472705e-05}, {"id": 204, "seek": 128696, "start": 1299.8400000000001, "end": 1308.88, "text": " easy. Pulsar is cloud native. It's scalable horizontally. So like Mary said, really, if you", "tokens": [1858, 13, 430, 9468, 289, 307, 4588, 8470, 13, 467, 311, 38481, 33796, 13, 407, 411, 6059, 848, 11, 534, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.2017663132910635, "compression_ratio": 1.5755102040816327, "no_speech_prob": 4.6523437049472705e-05}, {"id": 205, "seek": 128696, "start": 1309.76, "end": 1316.0, "text": " it looks like a promise, but this is real, you can add machines, add or remove machines, and", "tokens": [309, 1542, 411, 257, 6228, 11, 457, 341, 307, 957, 11, 291, 393, 909, 8379, 11, 909, 420, 4159, 8379, 11, 293], "temperature": 0.0, "avg_logprob": -0.2017663132910635, "compression_ratio": 1.5755102040816327, "no_speech_prob": 4.6523437049472705e-05}, {"id": 206, "seek": 131600, "start": 1316.0, "end": 1322.32, "text": " the service automatically adapts. Actually, at Datastax we are running it as a service on the", "tokens": [264, 2643, 6772, 23169, 1373, 13, 5135, 11, 412, 9315, 525, 2797, 321, 366, 2614, 309, 382, 257, 2643, 322, 264], "temperature": 0.0, "avg_logprob": -0.15699096208208063, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00012330745812505484}, {"id": 207, "seek": 131600, "start": 1322.32, "end": 1329.68, "text": " cloud. And so this is very powerful because you can automatically adapt the resource consumption.", "tokens": [4588, 13, 400, 370, 341, 307, 588, 4005, 570, 291, 393, 6772, 6231, 264, 7684, 12126, 13], "temperature": 0.0, "avg_logprob": -0.15699096208208063, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00012330745812505484}, {"id": 208, "seek": 131600, "start": 1330.56, "end": 1337.28, "text": " And also you can move the data that is not actually consumed to tier storage. And this", "tokens": [400, 611, 291, 393, 1286, 264, 1412, 300, 307, 406, 767, 21226, 281, 12362, 6725, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.15699096208208063, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00012330745812505484}, {"id": 209, "seek": 131600, "start": 1337.28, "end": 1345.04, "text": " allows you to really lower the cost. It's open source. It's a vibrant community. If you want,", "tokens": [4045, 291, 281, 534, 3126, 264, 2063, 13, 467, 311, 1269, 4009, 13, 467, 311, 257, 21571, 1768, 13, 759, 291, 528, 11], "temperature": 0.0, "avg_logprob": -0.15699096208208063, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00012330745812505484}, {"id": 210, "seek": 134504, "start": 1345.04, "end": 1349.68, "text": " you can reach out to me on the community. And there are many people that are very enthusiastic.", "tokens": [291, 393, 2524, 484, 281, 385, 322, 264, 1768, 13, 400, 456, 366, 867, 561, 300, 366, 588, 28574, 13], "temperature": 0.0, "avg_logprob": -0.13203672262338492, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.0002501886629033834}, {"id": 211, "seek": 134504, "start": 1349.68, "end": 1357.28, "text": " Pulsar is young. It is only five years old, something like that. But in the past two years,", "tokens": [430, 9468, 289, 307, 2037, 13, 467, 307, 787, 1732, 924, 1331, 11, 746, 411, 300, 13, 583, 294, 264, 1791, 732, 924, 11], "temperature": 0.0, "avg_logprob": -0.13203672262338492, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.0002501886629033834}, {"id": 212, "seek": 134504, "start": 1357.28, "end": 1366.32, "text": " it grew very fast because it is really the next generation. Maybe someone working with ActiveMQ,", "tokens": [309, 6109, 588, 2370, 570, 309, 307, 534, 264, 958, 5125, 13, 2704, 1580, 1364, 365, 26635, 44, 48, 11], "temperature": 0.0, "avg_logprob": -0.13203672262338492, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.0002501886629033834}, {"id": 213, "seek": 134504, "start": 1366.32, "end": 1374.1599999999999, "text": " then I did it in my previous jobs, ActiveMQ and then Kafka and then Pulsar. Now it's time for Pulsar.", "tokens": [550, 286, 630, 309, 294, 452, 3894, 4782, 11, 26635, 44, 48, 293, 550, 47064, 293, 550, 430, 9468, 289, 13, 823, 309, 311, 565, 337, 430, 9468, 289, 13], "temperature": 0.0, "avg_logprob": -0.13203672262338492, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.0002501886629033834}, {"id": 214, "seek": 137416, "start": 1374.16, "end": 1380.5600000000002, "text": " If you want to use Pulsar, you can use Starlight for GMS. I'm the initial author and main maintainer", "tokens": [759, 291, 528, 281, 764, 430, 9468, 289, 11, 291, 393, 764, 5705, 2764, 337, 460, 10288, 13, 286, 478, 264, 5883, 3793, 293, 2135, 6909, 260], "temperature": 0.0, "avg_logprob": -0.14683514196895858, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.000818160071503371}, {"id": 215, "seek": 137416, "start": 1380.5600000000002, "end": 1388.4, "text": " for Starlight for GMS. So yes, feel free to ask me any questions. It's open source. It's on GitHub.", "tokens": [337, 5705, 2764, 337, 460, 10288, 13, 407, 2086, 11, 841, 1737, 281, 1029, 385, 604, 1651, 13, 467, 311, 1269, 4009, 13, 467, 311, 322, 23331, 13], "temperature": 0.0, "avg_logprob": -0.14683514196895858, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.000818160071503371}, {"id": 216, "seek": 137416, "start": 1388.4, "end": 1393.8400000000001, "text": " Pulsar Connection Factory, if you're using standard Java, there is a resource adapter", "tokens": [430, 9468, 289, 11653, 313, 36868, 11, 498, 291, 434, 1228, 3832, 10745, 11, 456, 307, 257, 7684, 22860], "temperature": 0.0, "avg_logprob": -0.14683514196895858, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.000818160071503371}, {"id": 217, "seek": 137416, "start": 1393.8400000000001, "end": 1398.64, "text": " that works well with many containers. And it's already tested and it is running on production.", "tokens": [300, 1985, 731, 365, 867, 17089, 13, 400, 309, 311, 1217, 8246, 293, 309, 307, 2614, 322, 4265, 13], "temperature": 0.0, "avg_logprob": -0.14683514196895858, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.000818160071503371}, {"id": 218, "seek": 139864, "start": 1398.64, "end": 1406.0, "text": " Okay. And these are just real quick. If you like, get this copy of the slide deck. But otherwise,", "tokens": [1033, 13, 400, 613, 366, 445, 957, 1702, 13, 759, 291, 411, 11, 483, 341, 5055, 295, 264, 4137, 9341, 13, 583, 5911, 11], "temperature": 0.0, "avg_logprob": -0.18365486808445142, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.0004333156975917518}, {"id": 219, "seek": 139864, "start": 1406.0, "end": 1411.2, "text": " there are resources in here, community info, references to all the Pulsar information on", "tokens": [456, 366, 3593, 294, 510, 11, 1768, 13614, 11, 15400, 281, 439, 264, 430, 9468, 289, 1589, 322], "temperature": 0.0, "avg_logprob": -0.18365486808445142, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.0004333156975917518}, {"id": 220, "seek": 139864, "start": 1413.0400000000002, "end": 1418.64, "text": " GitHub and also in our Pulsar site. And also then just additional information too with data stacks.", "tokens": [23331, 293, 611, 294, 527, 430, 9468, 289, 3621, 13, 400, 611, 550, 445, 4497, 1589, 886, 365, 1412, 30792, 13], "temperature": 0.0, "avg_logprob": -0.18365486808445142, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.0004333156975917518}, {"id": 221, "seek": 139864, "start": 1418.64, "end": 1424.0, "text": " If you're interested, we offer like the $25 credit per month for personal projects. So", "tokens": [759, 291, 434, 3102, 11, 321, 2626, 411, 264, 1848, 6074, 5397, 680, 1618, 337, 2973, 4455, 13, 407], "temperature": 0.0, "avg_logprob": -0.18365486808445142, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.0004333156975917518}, {"id": 222, "seek": 142400, "start": 1424.0, "end": 1430.0, "text": " wanting to share with you, I know it's not true, open source in that sense, but we do have astra.datastacks.com", "tokens": [7935, 281, 2073, 365, 291, 11, 286, 458, 309, 311, 406, 2074, 11, 1269, 4009, 294, 300, 2020, 11, 457, 321, 360, 362, 5357, 424, 13, 20367, 525, 7424, 13, 1112], "temperature": 0.0, "avg_logprob": -0.17615214756556918, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.0001136571227107197}, {"id": 223, "seek": 142400, "start": 1430.0, "end": 1437.36, "text": " and all of the astra streaming is our company's supporting this in our cloud. So oops, where did", "tokens": [293, 439, 295, 264, 5357, 424, 11791, 307, 527, 2237, 311, 7231, 341, 294, 527, 4588, 13, 407, 34166, 11, 689, 630], "temperature": 0.0, "avg_logprob": -0.17615214756556918, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.0001136571227107197}, {"id": 224, "seek": 142400, "start": 1437.36, "end": 1445.44, "text": " it go? Sorry. You tried to subscribe to us. Okay. So how do you contact us? This is the slide", "tokens": [309, 352, 30, 4919, 13, 509, 3031, 281, 3022, 281, 505, 13, 1033, 13, 407, 577, 360, 291, 3385, 505, 30, 639, 307, 264, 4137], "temperature": 0.0, "avg_logprob": -0.17615214756556918, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.0001136571227107197}, {"id": 225, "seek": 142400, "start": 1445.44, "end": 1450.64, "text": " just containing information about Twitter handles and LinkedIn, all of these things. So please do", "tokens": [445, 19273, 1589, 466, 5794, 18722, 293, 20657, 11, 439, 295, 613, 721, 13, 407, 1767, 360], "temperature": 0.0, "avg_logprob": -0.17615214756556918, "compression_ratio": 1.556420233463035, "no_speech_prob": 0.0001136571227107197}, {"id": 226, "seek": 145064, "start": 1450.64, "end": 1455.3600000000001, "text": " consider staying in touch with us. We'll be very happy to answer more questions that you may have", "tokens": [1949, 7939, 294, 2557, 365, 505, 13, 492, 603, 312, 588, 2055, 281, 1867, 544, 1651, 300, 291, 815, 362], "temperature": 0.0, "avg_logprob": -0.23554229736328125, "compression_ratio": 1.4296296296296296, "no_speech_prob": 0.0006289116572588682}, {"id": 227, "seek": 145064, "start": 1455.3600000000001, "end": 1459.2800000000002, "text": " and all you want to share with us, your project idea, we'll be happy to answer. And those sound", "tokens": [293, 439, 291, 528, 281, 2073, 365, 505, 11, 428, 1716, 1558, 11, 321, 603, 312, 2055, 281, 1867, 13, 400, 729, 1626], "temperature": 0.0, "avg_logprob": -0.23554229736328125, "compression_ratio": 1.4296296296296296, "no_speech_prob": 0.0006289116572588682}, {"id": 228, "seek": 145928, "start": 1459.28, "end": 1482.6399999999999, "text": " to Jay's luck. Yes. That's right. So thank you. Thank you so much. And I think that's any questions.", "tokens": [281, 11146, 311, 3668, 13, 1079, 13, 663, 311, 558, 13, 407, 1309, 291, 13, 1044, 291, 370, 709, 13, 400, 286, 519, 300, 311, 604, 1651, 13], "temperature": 0.0, "avg_logprob": -0.4014749228954315, "compression_ratio": 1.1235955056179776, "no_speech_prob": 0.0017539385007694364}, {"id": 229, "seek": 148264, "start": 1482.64, "end": 1505.0400000000002, "text": " Sure. What the Pulsar functions or Pulsar function is a lightweight processing framework that", "tokens": [4894, 13, 708, 264, 430, 9468, 289, 6828, 420, 430, 9468, 289, 2445, 307, 257, 22052, 9007, 8388, 300], "temperature": 0.0, "avg_logprob": -0.2982011925090443, "compression_ratio": 1.373015873015873, "no_speech_prob": 0.0013520015636458993}, {"id": 230, "seek": 148264, "start": 1505.0400000000002, "end": 1512.48, "text": " usually it's very easy to enrich the data that you have on your topics. So it's", "tokens": [2673, 309, 311, 588, 1858, 281, 18849, 264, 1412, 300, 291, 362, 322, 428, 8378, 13, 407, 309, 311], "temperature": 0.0, "avg_logprob": -0.2982011925090443, "compression_ratio": 1.373015873015873, "no_speech_prob": 0.0013520015636458993}, {"id": 231, "seek": 151248, "start": 1512.48, "end": 1520.56, "text": " for very lightweight processing. So if you have to do more complicated processing, you usually", "tokens": [337, 588, 22052, 9007, 13, 407, 498, 291, 362, 281, 360, 544, 6179, 9007, 11, 291, 2673], "temperature": 0.0, "avg_logprob": -0.13439427652666647, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0009650528081692755}, {"id": 232, "seek": 151248, "start": 1520.56, "end": 1527.76, "text": " move to something like Flink or other things. But Pulsar function is very useful when you have to", "tokens": [1286, 281, 746, 411, 3235, 475, 420, 661, 721, 13, 583, 430, 9468, 289, 2445, 307, 588, 4420, 562, 291, 362, 281], "temperature": 0.0, "avg_logprob": -0.13439427652666647, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0009650528081692755}, {"id": 233, "seek": 151248, "start": 1527.76, "end": 1535.44, "text": " really process your data. And also it is the base for Pulsar.io that is the connector framework.", "tokens": [534, 1399, 428, 1412, 13, 400, 611, 309, 307, 264, 3096, 337, 430, 9468, 289, 13, 1004, 300, 307, 264, 19127, 8388, 13], "temperature": 0.0, "avg_logprob": -0.13439427652666647, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0009650528081692755}, {"id": 234, "seek": 151248, "start": 1535.44, "end": 1541.84, "text": " So basically in Pulsar, you can deploy on the Pulsar cluster your code that transforms your", "tokens": [407, 1936, 294, 430, 9468, 289, 11, 291, 393, 7274, 322, 264, 430, 9468, 289, 13630, 428, 3089, 300, 35592, 428], "temperature": 0.0, "avg_logprob": -0.13439427652666647, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0009650528081692755}, {"id": 235, "seek": 154184, "start": 1541.84, "end": 1551.04, "text": " data on your topics. Yes. It starts from a message on Pulsar and usually it ends with another", "tokens": [1412, 322, 428, 8378, 13, 1079, 13, 467, 3719, 490, 257, 3636, 322, 430, 9468, 289, 293, 2673, 309, 5314, 365, 1071], "temperature": 0.0, "avg_logprob": -0.1605317321004747, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.0012110708048567176}, {"id": 236, "seek": 154184, "start": 1551.04, "end": 1558.9599999999998, "text": " message on Pulsar. So it's really useful for transforming the data that is on Pulsar or", "tokens": [3636, 322, 430, 9468, 289, 13, 407, 309, 311, 534, 4420, 337, 27210, 264, 1412, 300, 307, 322, 430, 9468, 289, 420], "temperature": 0.0, "avg_logprob": -0.1605317321004747, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.0012110708048567176}, {"id": 237, "seek": 154184, "start": 1558.9599999999998, "end": 1566.0, "text": " to push your data outside of Pulsar. I don't know if this answers. We need to continue. Oh, yes.", "tokens": [281, 2944, 428, 1412, 2380, 295, 430, 9468, 289, 13, 286, 500, 380, 458, 498, 341, 6338, 13, 492, 643, 281, 2354, 13, 876, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.1605317321004747, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.0012110708048567176}, {"id": 238, "seek": 156600, "start": 1566.0, "end": 1570.72, "text": " There is a question over here. If you want to have a discussion and also on Fuji Slack,", "tokens": [821, 307, 257, 1168, 670, 510, 13, 759, 291, 528, 281, 362, 257, 5017, 293, 611, 322, 38119, 37211, 11], "temperature": 0.0, "avg_logprob": -0.39753481236899774, "compression_ratio": 1.272, "no_speech_prob": 0.005055075045675039}, {"id": 239, "seek": 157072, "start": 1570.72, "end": 1597.04, "text": " you can have discussions with people, but usually at the top they are married.", "tokens": [50364, 291, 393, 362, 11088, 365, 561, 11, 457, 2673, 412, 264, 1192, 436, 366, 5259, 13, 51680], "temperature": 0.0, "avg_logprob": -0.43347393838982834, "compression_ratio": 1.0684931506849316, "no_speech_prob": 0.004437385592609644}], "language": "en"}