{"text": " Alright, welcome. How do you like our little Duke rock stars here? So there's stickers going around somewhere so you can get some of these stickers. I think we have four different rock stars or something. Anyway, let's talk about Quarkus, obviously. Who am I? I'm a developer advocate at Red Hat. My name is Kevin Dubois. You can find me on Twitter or Macedon. So I know we've already talked in a few sessions today about, you know, traditional Java and the startup time and all that stuff, so I'll do that some more. So we'll talk about traditional Java. So traditional Java is, can I see the little hand? Traditional Java is designed for, let's say, different times, not designed for cloud-native workloads, necessarily. It's designed for running kind of long time. And what's important in traditional Java is throughput at the expense of footprint. So footprint can be quite large, right? You typically have traditional Java applications running on pretty beefy servers. And they're designed to be long running and you have dynamic loading and all that stuff with mutable systems. But in the cloud-native world, your throughput, you get that mostly through scaling. Your workloads are ephemeral, which means that, you know, like if you think of containers, when you scale up a container, when you start up a new application, those containers are going to start up and then maybe they're going to get rescheduled on a different node. And so containers kind of come and go. They're not going to be around. And if you change something in a container, that change is not going to last, right? Because that container, whatever you change inside, that's going to be gone when that container gets removed. So in that sense, we have to think of Java in a different way. We need to think about the footprint of it because we want smaller containers that we can schedule across different servers. You know, if you are familiar with Kubernetes and clusters, there's usually multiple servers on which it schedules containers. So, you know, we need to be able to handle that. And so that's where Quark has started, was kind of invented, I guess, because it's a framework that uses Java. But it's, you know, we call it supersonic because it starts up very fast. Subatomic because it's very small, like subatomic smaller than an atom. And it's still Java. So if we think, if we look at Quarkus in terms of startup time and in terms of memory usage, you can see here, this is a test that they did with a relatively small application running on a traditional cloud native stack. It took 136 megs of memory running the same application, you know, with Quarkus, you already got, you know, pretty good gain in memory, right? And that's running on the JVM. So it's the exact same application running on the JVM. And then, you know, compiled down to a native with Grail VM, you get, of course, even less memory usage. And you can see here, too, Quarkus starts up quite a bit faster than a traditional cloud native stack, which is ideal when we're talking about, you know, cloud native. We're talking about containers, talking about serverless, where we need to start up really fast so we can react quickly to, you know, changing loads. So startup time is one thing. There's also the warmup issue. I don't know if issue is the right word, but actually, when an application starts up, it takes a while with Java before you get your maximum throughput as well. So here we can see that, you know, like a traditional Java application, this is actually the point, and I think this is like 13 seconds or something, or it's actually able to be working at maximum throughput, which, you know, for this particular use case, it needed a certain amount of throughput to be able to handle load enough. And then you can see here with Quarkus, it goes quite a bit faster. Now, Quarkus isn't just about fast startup time, it's not just about memory, but it is kind of a nice feature of Quarkus. So if we think of containers and Kubernetes nodes, traditional Java applications, running on EAP or WebSphere or whatever, running on a Kubernetes node, you can see they take up quite a bit of space. Let's say that in this case, only four instances of the application can run, which isn't so ideal because if one of the pods, one of the containers goes down, that means you lose 25% of your workload, right? If you look at Quarkus, on the JVM, you already have quite a bit more density, which means that if one of these guys goes down or needs to be rescheduled or whatever, you still have, you know, what is it, maybe 70% or something, that's still up. And, you know, we can compare that to Node.js or a Go or something, where Go has quite a smaller footprint and with Quarkus native, we can actually be very comparable with Go, which is nice because that means that we can use our Java skills and not have to, you know, change languages and reinvent the wheel and still get all the benefits in the cloud native world of having fast startup and everything. So how does that work? So a traditional Java application, basically build time is when you do your packaging and then as it starts up, it loads config files and then does class pass scanning and build kind of its model of the world and everything, but this is when it starts up. So if you think of containers, again, that means that this all happens when the container starts up and that takes a while. And then, so with Quarkus, what we try to do is instead of doing all that, you know, at runtime, at startup time, we're trying to do all of this or as much as we can during build time before the application actually gets packaged, which means that during runtime, we have a lot less to do, right? So it starts up quite a bit faster. So that's kind of the cool thing about Quarkus. And then, so you can use Quarkus on JVM or you can compile it down to native, of course, just like most other frameworks. But there's some cool things about native compilation with Quarkus as well that we'll get into in just a second. So this is my favorite part about Quarkus. It's not necessarily, I mean, yes, it's nice that it starts up fast. It's nice that it has a small memory footprint. But what's really cool about Quarkus is that it has a bunch of different ways of making the experience of working with Java and Quarkus a lot more fun. So one of them is, you know, so of course, it's based on standards. So Quarkus uses, you know, your Java EE standards, the Java standards, uses, you know, Vertex and all that good stuff. So if you're used to that, hey, great. You basically already know Quarkus for 99%. What's really cool with Quarkus is that there's this dev mode. This basically, you can start Quarkus on your local machine in dev mode. It's going to start up. And it's going to just keep checking to see if you make changes in the class path. And so every time you make a change, it's going to automatically reload when you, you know, let's say go into your browser or whatever you make a new request. It's going to automatically reload your application so you don't need to recompile, redeploy every time you want to test something. Quarkus does that automatically so you can just go to your browser, hit refresh, and it's there. So make a code change, refresh, it's there. Which, you know, if you're a developer of a couple, you know, of some other language where that just happens, then that's not so cool. But in Java, that's pretty cool, right? So we've got our little guy here that says, wait, so you just save it and your code is running and it's Java? And the guy says, I know, right? Super Sonic Java. So that's, that's pretty cool. Another cool thing with Quarkus is that it has this concept of developer services. So who knows test containers? So basically it uses test containers built into Quarkus. So let's say that I'm developing an application and I'm adding an extension to use Postgres database or a Kafka, a Kafka topic or something. Actually, well, of course you have to have a Docker or Podman or something running on your local machine. But Quarkus will look and see, hey, you've got, you've got this dependency on a database. Do you have something configured on your local machine? Do you have a database running on your local machine? Is that configured in your application properties? If not, no worries, I'm just going to start up a container with that dependency, for example, a Postgres database and wire that up. So it's going to, you know, set the configuration so that it connects to that database automatically. And then you can even go and see, you know, what exactly that configuration is and then copy it down. Anyway, so that's the developer services. So Kafka or, yeah, there's a whole bunch of different developer services that you can use just out of the box, which is pretty nice because otherwise, you know, having to configure a database on your local machine or Lord forbid, a Kafka instance with all your zookeepers and all that stuff, that's not so easy. You also, you know, so you have live coding, you also have continuous testing. So kind of the same concept. So if you have unit tests, you start your continuous testing. So every time you make a code change, it knows, hey, this class is related to this unit test. So I'm going to rerun this unit test every time I make a change here or vice versa. If you're making a change in a unit test, it knows, you know, this is what I need to rerun. So it gives you quick and immediate feedback every time as you're developing, which, yeah, again, it's pretty handy. It also has a dev UI. So it has a UI in your browser where you can go and look at all these different, you know, developer services that are running, what Quarkis is doing. So again, I was talking at the start about Quarkis doing some optimization, right? So during the compilation time, so in the dev UI, you can actually see, you know, what it's doing, how it's optimizing and what it's going to remove from the class path because Quarkis does, you know, some introspection to make sure that, hey, this is used or this actually isn't used by your code. So I'm going to remove all that from the compilation. There's a Quarkis CLI, which, again, it's not super crazy, but so you can either use Quarkis with Gradle or Maven, or you can just use the Quarkis CLI, which means that you can do, like, Quarkis dev or Quarkis build or whatever. You can even use, you can say Quarkis image build or image push, and it's going to build your application. So build your application, build a container, and you can even push it automatically all, you know, from one command, which is kind of handy, right? And then one of the last, but not least, is unification of imperative and reactive programming. So Quarkis has a lot of reactive programming kind of built in underneath. Now, me, for example, I'm not a super deep expert in reactive programming, but what's nice with Quarkis, too, is that I can write imperative code, right? So just, you know, every statement gets handled one at a time and it blocks every time, whereas with reactive, you've got these event loops. But you can use both at the same time in the same, even in the same code in the same class. So for those who are familiar with reactive, usually you kind of have to decide, hey, if I'm going to build a reactive application, that means I have to decide before I start writing this code, you know, that this framework that I'm going to use is reactive and I can't combine the both. But with Quarkis, you can, which is nice. And best of all, it's still Java, right? So you get all these kind of features. And at the end of the day, if you're, you know, if you're familiar with Java, this is really not reinventing the wheel at all. So it uses micro-profile, vertex, rest easy, you know, like, and if you want to add extensions, you can interact directly with Kubernetes. So you can push your code directly to Kubernetes. You can create config maps or secrets directly from Quarkis. You can, you know, you can work really easily with Kafka and OpenShift, of course, patchy camel and all that. So in terms of native compilation, I think we've already had a few sessions about that. So I'm not going to go too deep into that other than, you know, if you can run Quarkis on the JVM and probably for 70 to 80 percent of the use cases, that's probably a good way to go. If you really want to have the fastest startup time and the smallest footprint, then you can, you know, do a native build of your Quarkis application with Quarkis, by the way, that's really easy because if you create a new Quarkis application, it already automatically has a native profile built in. So you can decide, you know, as you're doing your compilation, whether you want to do a native build or not. But yeah, so Red Hat is on the GrowlVM advisory board and then there's the mandrel project, which is a downstream distribution of GrowlVM specifically for building Java native builds. So, and that's what Quarkis uses to, for example, if I do a native build and I don't have GrowlVM installed on my local machine, Quarkis will again pull down a container, it's really good at pulling down containers to do a native build inside a container on your local machine. So again, then you don't need to have GrowlVM installed and configured on your local machine. So it really tries to make, you know, your life as easy as possible and, you know, kind of have the benefits of, you know, a lot of the things. So if you're thinking of, you know, should I do a native build or just run on the JVM? This is kind of an opinionated scoring. But, you know, if you want the maximum developer joy, the, you know, the best and easiest monitoring peak throughput and reduced max latency, then you want to run it on the JVM. If, for you, it's important to have the lowest memory footprint, a small packaging, and a very fast startup time, then a native build is probably the way to go. So what do you want to use? You know, what can you use Quarkis for? Virtually anything. So, you know, there are Quarkis-based Kubernetes operators. So there's an operator framework where you can create, you know, these automatic components in Kubernetes that manage resources in Kubernetes. You can create GitHub actions with Quarkis. You can create, you know, just regular jobs. Yes, you can build traditional Java applications, even monoliths with it. So this is, of course, the sweet spot of Quarkis is cloud-native applications, so event-driven applications, reactive systems, microservices, and serverless and functions. So that's about it for my session. So if you want to check out Quarkis more, developers.redhat.com has a ton of resources on Quarkis, on a lot of developer stuff. This dn.dev slash Quarkis tutorial is just a, you know, kind of a nice, lightweight introduction to Quarkis where you can create an application from scratch and then, you know, kind of add some components as you go. You add a database and then, you know, check out the live, the dev mode and all that stuff. And, you know, so it's a pretty nice thing. Yeah. And like I said, if you want to keep up to date, you can follow me on Twitter or Macedon. I try to post interesting stuff, but I don't know if that's really true, but we'll see. All right. And that's it for me. Thank you. Any questions? Yes. One of the first slides you compared startup time and peak performance and, like, the crowd time. I don't, yeah, I don't remember exactly the numbers on there. Yeah. So that, yeah, so the, yeah, definitely. So the peak throughput time, there was a slide about, you know, the three graphs. So, yeah, I think with the native compilation, you're not going to have necessarily more throughput than on the JVM, but you do get the startup time, you know, like the time it takes to get to the maximum throughput is faster when you're, when you're native. Yeah. Yeah. Yeah. We can look at it later. Yeah. Yes. Yeah. That's it. Yeah. Yeah. So the question was how easy is it, is it to migrate to Quarkus from, for example, spring boots? So Quarkus has spring compatibility extensions. And so that makes it relatively easy because basically you're, for the most part, you won't have to change your code. You just have to add the, you know, add the spring extensions. Of course, in your palm, you're going to need to make some changes, but it's fairly straightforward. My colleague, Eric D'Andrea, he wrote a book on spring, let's say, Quarkus for spring developers. And he does, he does talks too, but if you want on that developers.ridhat.com, you can find, you know, there's a section about books and you can find that book. But it's, yeah, overall pretty, pretty straightforward. So like I said, there are extensions so that you can keep using your spring annotations. Now, would I recommend you just migrating your application and keeping all your spring dependencies? Probably not. But it's kind of a nice way to migrate without too much work and then afterwards maybe migrate further. All right. Any more questions? Yes. So, so the question, if I understand correctly, right, so your, the question is, why, why should you use native compilation? Because on the JVM, you have all the kind of capabilities that the JVM brings, right? So in terms of, you know, garbage collection, in terms of throughput and everything, JVM is very optimized to do that. When you do a native build, the GralVM compiler is going to do kind of an opinionated approach of how to do your native build, but then that's also it. It's not going to be able to optimize afterwards like the JVM does. So, kind of depends. Yeah. I think we're out of time. But if anybody has any more questions? Any questions, you'll be up there. Yeah, yeah. Great. Thank you so much. All right. Thank you so much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.8, "text": " Alright, welcome. How do you like our little Duke rock stars here? So there's stickers", "tokens": [2798, 11, 2928, 13, 1012, 360, 291, 411, 527, 707, 17380, 3727, 6105, 510, 30, 407, 456, 311, 21019], "temperature": 0.0, "avg_logprob": -0.20691053257432096, "compression_ratio": 1.325925925925926, "no_speech_prob": 0.1393566131591797}, {"id": 1, "seek": 0, "start": 14.8, "end": 20.82, "text": " going around somewhere so you can get some of these stickers. I think we have four different", "tokens": [516, 926, 4079, 370, 291, 393, 483, 512, 295, 613, 21019, 13, 286, 519, 321, 362, 1451, 819], "temperature": 0.0, "avg_logprob": -0.20691053257432096, "compression_ratio": 1.325925925925926, "no_speech_prob": 0.1393566131591797}, {"id": 2, "seek": 2082, "start": 20.82, "end": 30.36, "text": " rock stars or something. Anyway, let's talk about Quarkus, obviously. Who am I? I'm a", "tokens": [3727, 6105, 420, 746, 13, 5684, 11, 718, 311, 751, 466, 2326, 809, 301, 11, 2745, 13, 2102, 669, 286, 30, 286, 478, 257], "temperature": 0.0, "avg_logprob": -0.26422513961791994, "compression_ratio": 1.204225352112676, "no_speech_prob": 8.604370668763295e-05}, {"id": 3, "seek": 2082, "start": 30.36, "end": 38.019999999999996, "text": " developer advocate at Red Hat. My name is Kevin Dubois. You can find me on Twitter or", "tokens": [10754, 14608, 412, 4477, 15867, 13, 1222, 1315, 307, 9954, 16488, 7376, 13, 509, 393, 915, 385, 322, 5794, 420], "temperature": 0.0, "avg_logprob": -0.26422513961791994, "compression_ratio": 1.204225352112676, "no_speech_prob": 8.604370668763295e-05}, {"id": 4, "seek": 3802, "start": 38.02, "end": 50.7, "text": " Macedon. So I know we've already talked in a few sessions today about, you know, traditional", "tokens": [45603, 266, 13, 407, 286, 458, 321, 600, 1217, 2825, 294, 257, 1326, 11081, 965, 466, 11, 291, 458, 11, 5164], "temperature": 0.0, "avg_logprob": -0.22233377184186662, "compression_ratio": 1.356060606060606, "no_speech_prob": 9.30978640099056e-05}, {"id": 5, "seek": 3802, "start": 50.7, "end": 57.0, "text": " Java and the startup time and all that stuff, so I'll do that some more. So we'll talk", "tokens": [10745, 293, 264, 18578, 565, 293, 439, 300, 1507, 11, 370, 286, 603, 360, 300, 512, 544, 13, 407, 321, 603, 751], "temperature": 0.0, "avg_logprob": -0.22233377184186662, "compression_ratio": 1.356060606060606, "no_speech_prob": 9.30978640099056e-05}, {"id": 6, "seek": 5700, "start": 57.0, "end": 68.9, "text": " about traditional Java. So traditional Java is, can I see the little hand? Traditional", "tokens": [466, 5164, 10745, 13, 407, 5164, 10745, 307, 11, 393, 286, 536, 264, 707, 1011, 30, 46738], "temperature": 0.0, "avg_logprob": -0.256849467754364, "compression_ratio": 1.6524390243902438, "no_speech_prob": 1.833270289353095e-05}, {"id": 7, "seek": 5700, "start": 68.9, "end": 74.86, "text": " Java is designed for, let's say, different times, not designed for cloud-native workloads,", "tokens": [10745, 307, 4761, 337, 11, 718, 311, 584, 11, 819, 1413, 11, 406, 4761, 337, 4588, 12, 77, 1166, 32452, 11], "temperature": 0.0, "avg_logprob": -0.256849467754364, "compression_ratio": 1.6524390243902438, "no_speech_prob": 1.833270289353095e-05}, {"id": 8, "seek": 5700, "start": 74.86, "end": 84.58, "text": " necessarily. It's designed for running kind of long time. And what's important in traditional", "tokens": [4725, 13, 467, 311, 4761, 337, 2614, 733, 295, 938, 565, 13, 400, 437, 311, 1021, 294, 5164], "temperature": 0.0, "avg_logprob": -0.256849467754364, "compression_ratio": 1.6524390243902438, "no_speech_prob": 1.833270289353095e-05}, {"id": 9, "seek": 8458, "start": 84.58, "end": 89.7, "text": " Java is throughput at the expense of footprint. So footprint can be quite large, right? You", "tokens": [10745, 307, 44629, 412, 264, 18406, 295, 24222, 13, 407, 24222, 393, 312, 1596, 2416, 11, 558, 30, 509], "temperature": 0.0, "avg_logprob": -0.1345188646431429, "compression_ratio": 1.5702127659574467, "no_speech_prob": 5.172207238501869e-06}, {"id": 10, "seek": 8458, "start": 89.7, "end": 97.66, "text": " typically have traditional Java applications running on pretty beefy servers. And they're", "tokens": [5850, 362, 5164, 10745, 5821, 2614, 322, 1238, 9256, 88, 15909, 13, 400, 436, 434], "temperature": 0.0, "avg_logprob": -0.1345188646431429, "compression_ratio": 1.5702127659574467, "no_speech_prob": 5.172207238501869e-06}, {"id": 11, "seek": 8458, "start": 97.66, "end": 105.34, "text": " designed to be long running and you have dynamic loading and all that stuff with mutable systems.", "tokens": [4761, 281, 312, 938, 2614, 293, 291, 362, 8546, 15114, 293, 439, 300, 1507, 365, 5839, 712, 3652, 13], "temperature": 0.0, "avg_logprob": -0.1345188646431429, "compression_ratio": 1.5702127659574467, "no_speech_prob": 5.172207238501869e-06}, {"id": 12, "seek": 8458, "start": 105.34, "end": 112.62, "text": " But in the cloud-native world, your throughput, you get that mostly through scaling. Your", "tokens": [583, 294, 264, 4588, 12, 77, 1166, 1002, 11, 428, 44629, 11, 291, 483, 300, 5240, 807, 21589, 13, 2260], "temperature": 0.0, "avg_logprob": -0.1345188646431429, "compression_ratio": 1.5702127659574467, "no_speech_prob": 5.172207238501869e-06}, {"id": 13, "seek": 11262, "start": 112.62, "end": 118.58, "text": " workloads are ephemeral, which means that, you know, like if you think of containers,", "tokens": [32452, 366, 308, 41245, 2790, 11, 597, 1355, 300, 11, 291, 458, 11, 411, 498, 291, 519, 295, 17089, 11], "temperature": 0.0, "avg_logprob": -0.09333778728138317, "compression_ratio": 1.9090909090909092, "no_speech_prob": 2.7527243219083175e-05}, {"id": 14, "seek": 11262, "start": 118.58, "end": 124.46000000000001, "text": " when you scale up a container, when you start up a new application, those containers are", "tokens": [562, 291, 4373, 493, 257, 10129, 11, 562, 291, 722, 493, 257, 777, 3861, 11, 729, 17089, 366], "temperature": 0.0, "avg_logprob": -0.09333778728138317, "compression_ratio": 1.9090909090909092, "no_speech_prob": 2.7527243219083175e-05}, {"id": 15, "seek": 11262, "start": 124.46000000000001, "end": 129.58, "text": " going to start up and then maybe they're going to get rescheduled on a different node. And", "tokens": [516, 281, 722, 493, 293, 550, 1310, 436, 434, 516, 281, 483, 725, 19318, 45893, 322, 257, 819, 9984, 13, 400], "temperature": 0.0, "avg_logprob": -0.09333778728138317, "compression_ratio": 1.9090909090909092, "no_speech_prob": 2.7527243219083175e-05}, {"id": 16, "seek": 11262, "start": 129.58, "end": 135.06, "text": " so containers kind of come and go. They're not going to be around. And if you change", "tokens": [370, 17089, 733, 295, 808, 293, 352, 13, 814, 434, 406, 516, 281, 312, 926, 13, 400, 498, 291, 1319], "temperature": 0.0, "avg_logprob": -0.09333778728138317, "compression_ratio": 1.9090909090909092, "no_speech_prob": 2.7527243219083175e-05}, {"id": 17, "seek": 11262, "start": 135.06, "end": 140.46, "text": " something in a container, that change is not going to last, right? Because that container,", "tokens": [746, 294, 257, 10129, 11, 300, 1319, 307, 406, 516, 281, 1036, 11, 558, 30, 1436, 300, 10129, 11], "temperature": 0.0, "avg_logprob": -0.09333778728138317, "compression_ratio": 1.9090909090909092, "no_speech_prob": 2.7527243219083175e-05}, {"id": 18, "seek": 14046, "start": 140.46, "end": 148.46, "text": " whatever you change inside, that's going to be gone when that container gets removed.", "tokens": [2035, 291, 1319, 1854, 11, 300, 311, 516, 281, 312, 2780, 562, 300, 10129, 2170, 7261, 13], "temperature": 0.0, "avg_logprob": -0.13808284571141372, "compression_ratio": 1.5633187772925765, "no_speech_prob": 1.0127479981747456e-05}, {"id": 19, "seek": 14046, "start": 148.46, "end": 156.5, "text": " So in that sense, we have to think of Java in a different way. We need to think about", "tokens": [407, 294, 300, 2020, 11, 321, 362, 281, 519, 295, 10745, 294, 257, 819, 636, 13, 492, 643, 281, 519, 466], "temperature": 0.0, "avg_logprob": -0.13808284571141372, "compression_ratio": 1.5633187772925765, "no_speech_prob": 1.0127479981747456e-05}, {"id": 20, "seek": 14046, "start": 156.5, "end": 163.26000000000002, "text": " the footprint of it because we want smaller containers that we can schedule across different", "tokens": [264, 24222, 295, 309, 570, 321, 528, 4356, 17089, 300, 321, 393, 7567, 2108, 819], "temperature": 0.0, "avg_logprob": -0.13808284571141372, "compression_ratio": 1.5633187772925765, "no_speech_prob": 1.0127479981747456e-05}, {"id": 21, "seek": 14046, "start": 163.26000000000002, "end": 169.06, "text": " servers. You know, if you are familiar with Kubernetes and clusters, there's usually multiple", "tokens": [15909, 13, 509, 458, 11, 498, 291, 366, 4963, 365, 23145, 293, 23313, 11, 456, 311, 2673, 3866], "temperature": 0.0, "avg_logprob": -0.13808284571141372, "compression_ratio": 1.5633187772925765, "no_speech_prob": 1.0127479981747456e-05}, {"id": 22, "seek": 16906, "start": 169.06, "end": 174.78, "text": " servers on which it schedules containers. So, you know, we need to be able to handle", "tokens": [15909, 322, 597, 309, 28078, 17089, 13, 407, 11, 291, 458, 11, 321, 643, 281, 312, 1075, 281, 4813], "temperature": 0.0, "avg_logprob": -0.1582291753668534, "compression_ratio": 1.6291079812206573, "no_speech_prob": 1.3417566151474603e-05}, {"id": 23, "seek": 16906, "start": 174.78, "end": 184.42000000000002, "text": " that. And so that's where Quark has started, was kind of invented, I guess, because it's", "tokens": [300, 13, 400, 370, 300, 311, 689, 2326, 809, 575, 1409, 11, 390, 733, 295, 14479, 11, 286, 2041, 11, 570, 309, 311], "temperature": 0.0, "avg_logprob": -0.1582291753668534, "compression_ratio": 1.6291079812206573, "no_speech_prob": 1.3417566151474603e-05}, {"id": 24, "seek": 16906, "start": 184.42000000000002, "end": 190.54, "text": " a framework that uses Java. But it's, you know, we call it supersonic because it starts", "tokens": [257, 8388, 300, 4960, 10745, 13, 583, 309, 311, 11, 291, 458, 11, 321, 818, 309, 9331, 44725, 570, 309, 3719], "temperature": 0.0, "avg_logprob": -0.1582291753668534, "compression_ratio": 1.6291079812206573, "no_speech_prob": 1.3417566151474603e-05}, {"id": 25, "seek": 16906, "start": 190.54, "end": 197.94, "text": " up very fast. Subatomic because it's very small, like subatomic smaller than an atom.", "tokens": [493, 588, 2370, 13, 8511, 267, 21401, 570, 309, 311, 588, 1359, 11, 411, 1422, 267, 21401, 4356, 813, 364, 12018, 13], "temperature": 0.0, "avg_logprob": -0.1582291753668534, "compression_ratio": 1.6291079812206573, "no_speech_prob": 1.3417566151474603e-05}, {"id": 26, "seek": 19794, "start": 197.94, "end": 207.06, "text": " And it's still Java. So if we think, if we look at Quarkus in terms of startup time and", "tokens": [400, 309, 311, 920, 10745, 13, 407, 498, 321, 519, 11, 498, 321, 574, 412, 2326, 809, 301, 294, 2115, 295, 18578, 565, 293], "temperature": 0.0, "avg_logprob": -0.12966192272347463, "compression_ratio": 1.4565217391304348, "no_speech_prob": 1.0449170076753944e-05}, {"id": 27, "seek": 19794, "start": 207.06, "end": 214.86, "text": " in terms of memory usage, you can see here, this is a test that they did with a relatively", "tokens": [294, 2115, 295, 4675, 14924, 11, 291, 393, 536, 510, 11, 341, 307, 257, 1500, 300, 436, 630, 365, 257, 7226], "temperature": 0.0, "avg_logprob": -0.12966192272347463, "compression_ratio": 1.4565217391304348, "no_speech_prob": 1.0449170076753944e-05}, {"id": 28, "seek": 19794, "start": 214.86, "end": 223.78, "text": " small application running on a traditional cloud native stack. It took 136 megs of memory", "tokens": [1359, 3861, 2614, 322, 257, 5164, 4588, 8470, 8630, 13, 467, 1890, 3705, 21, 10816, 82, 295, 4675], "temperature": 0.0, "avg_logprob": -0.12966192272347463, "compression_ratio": 1.4565217391304348, "no_speech_prob": 1.0449170076753944e-05}, {"id": 29, "seek": 22378, "start": 223.78, "end": 231.22, "text": " running the same application, you know, with Quarkus, you already got, you know, pretty", "tokens": [2614, 264, 912, 3861, 11, 291, 458, 11, 365, 2326, 809, 301, 11, 291, 1217, 658, 11, 291, 458, 11, 1238], "temperature": 0.0, "avg_logprob": -0.13818320487309427, "compression_ratio": 1.708133971291866, "no_speech_prob": 1.1839501894428395e-05}, {"id": 30, "seek": 22378, "start": 231.22, "end": 237.06, "text": " good gain in memory, right? And that's running on the JVM. So it's the exact same application", "tokens": [665, 6052, 294, 4675, 11, 558, 30, 400, 300, 311, 2614, 322, 264, 508, 53, 44, 13, 407, 309, 311, 264, 1900, 912, 3861], "temperature": 0.0, "avg_logprob": -0.13818320487309427, "compression_ratio": 1.708133971291866, "no_speech_prob": 1.1839501894428395e-05}, {"id": 31, "seek": 22378, "start": 237.06, "end": 243.14, "text": " running on the JVM. And then, you know, compiled down to a native with Grail VM, you get,", "tokens": [2614, 322, 264, 508, 53, 44, 13, 400, 550, 11, 291, 458, 11, 36548, 760, 281, 257, 8470, 365, 8985, 388, 18038, 11, 291, 483, 11], "temperature": 0.0, "avg_logprob": -0.13818320487309427, "compression_ratio": 1.708133971291866, "no_speech_prob": 1.1839501894428395e-05}, {"id": 32, "seek": 22378, "start": 243.14, "end": 249.38, "text": " of course, even less memory usage. And you can see here, too, Quarkus starts up quite", "tokens": [295, 1164, 11, 754, 1570, 4675, 14924, 13, 400, 291, 393, 536, 510, 11, 886, 11, 2326, 809, 301, 3719, 493, 1596], "temperature": 0.0, "avg_logprob": -0.13818320487309427, "compression_ratio": 1.708133971291866, "no_speech_prob": 1.1839501894428395e-05}, {"id": 33, "seek": 24938, "start": 249.38, "end": 254.54, "text": " a bit faster than a traditional cloud native stack, which is ideal when we're talking about,", "tokens": [257, 857, 4663, 813, 257, 5164, 4588, 8470, 8630, 11, 597, 307, 7157, 562, 321, 434, 1417, 466, 11], "temperature": 0.0, "avg_logprob": -0.11661522040206394, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.410175840050215e-06}, {"id": 34, "seek": 24938, "start": 254.54, "end": 259.38, "text": " you know, cloud native. We're talking about containers, talking about serverless, where", "tokens": [291, 458, 11, 4588, 8470, 13, 492, 434, 1417, 466, 17089, 11, 1417, 466, 7154, 1832, 11, 689], "temperature": 0.0, "avg_logprob": -0.11661522040206394, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.410175840050215e-06}, {"id": 35, "seek": 24938, "start": 259.38, "end": 267.65999999999997, "text": " we need to start up really fast so we can react quickly to, you know, changing loads.", "tokens": [321, 643, 281, 722, 493, 534, 2370, 370, 321, 393, 4515, 2661, 281, 11, 291, 458, 11, 4473, 12668, 13], "temperature": 0.0, "avg_logprob": -0.11661522040206394, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.410175840050215e-06}, {"id": 36, "seek": 24938, "start": 267.65999999999997, "end": 275.26, "text": " So startup time is one thing. There's also the warmup issue. I don't know if issue is", "tokens": [407, 18578, 565, 307, 472, 551, 13, 821, 311, 611, 264, 4561, 1010, 2734, 13, 286, 500, 380, 458, 498, 2734, 307], "temperature": 0.0, "avg_logprob": -0.11661522040206394, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.410175840050215e-06}, {"id": 37, "seek": 27526, "start": 275.26, "end": 283.26, "text": " the right word, but actually, when an application starts up, it takes a while with Java before", "tokens": [264, 558, 1349, 11, 457, 767, 11, 562, 364, 3861, 3719, 493, 11, 309, 2516, 257, 1339, 365, 10745, 949], "temperature": 0.0, "avg_logprob": -0.14214429993560349, "compression_ratio": 1.507936507936508, "no_speech_prob": 6.746265626134118e-06}, {"id": 38, "seek": 27526, "start": 283.26, "end": 292.09999999999997, "text": " you get your maximum throughput as well. So here we can see that, you know, like a traditional", "tokens": [291, 483, 428, 6674, 44629, 382, 731, 13, 407, 510, 321, 393, 536, 300, 11, 291, 458, 11, 411, 257, 5164], "temperature": 0.0, "avg_logprob": -0.14214429993560349, "compression_ratio": 1.507936507936508, "no_speech_prob": 6.746265626134118e-06}, {"id": 39, "seek": 27526, "start": 292.09999999999997, "end": 299.26, "text": " Java application, this is actually the point, and I think this is like 13 seconds or something,", "tokens": [10745, 3861, 11, 341, 307, 767, 264, 935, 11, 293, 286, 519, 341, 307, 411, 3705, 3949, 420, 746, 11], "temperature": 0.0, "avg_logprob": -0.14214429993560349, "compression_ratio": 1.507936507936508, "no_speech_prob": 6.746265626134118e-06}, {"id": 40, "seek": 29926, "start": 299.26, "end": 305.62, "text": " or it's actually able to be working at maximum throughput, which, you know, for this particular", "tokens": [420, 309, 311, 767, 1075, 281, 312, 1364, 412, 6674, 44629, 11, 597, 11, 291, 458, 11, 337, 341, 1729], "temperature": 0.0, "avg_logprob": -0.10320199137986308, "compression_ratio": 1.608695652173913, "no_speech_prob": 8.936429367167875e-06}, {"id": 41, "seek": 29926, "start": 305.62, "end": 311.9, "text": " use case, it needed a certain amount of throughput to be able to handle load enough. And then", "tokens": [764, 1389, 11, 309, 2978, 257, 1629, 2372, 295, 44629, 281, 312, 1075, 281, 4813, 3677, 1547, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.10320199137986308, "compression_ratio": 1.608695652173913, "no_speech_prob": 8.936429367167875e-06}, {"id": 42, "seek": 29926, "start": 311.9, "end": 316.94, "text": " you can see here with Quarkus, it goes quite a bit faster. Now, Quarkus isn't just about", "tokens": [291, 393, 536, 510, 365, 2326, 809, 301, 11, 309, 1709, 1596, 257, 857, 4663, 13, 823, 11, 2326, 809, 301, 1943, 380, 445, 466], "temperature": 0.0, "avg_logprob": -0.10320199137986308, "compression_ratio": 1.608695652173913, "no_speech_prob": 8.936429367167875e-06}, {"id": 43, "seek": 29926, "start": 316.94, "end": 324.18, "text": " fast startup time, it's not just about memory, but it is kind of a nice feature of Quarkus.", "tokens": [2370, 18578, 565, 11, 309, 311, 406, 445, 466, 4675, 11, 457, 309, 307, 733, 295, 257, 1481, 4111, 295, 2326, 809, 301, 13], "temperature": 0.0, "avg_logprob": -0.10320199137986308, "compression_ratio": 1.608695652173913, "no_speech_prob": 8.936429367167875e-06}, {"id": 44, "seek": 32418, "start": 324.18, "end": 331.14, "text": " So if we think of containers and Kubernetes nodes, traditional Java applications, running", "tokens": [407, 498, 321, 519, 295, 17089, 293, 23145, 13891, 11, 5164, 10745, 5821, 11, 2614], "temperature": 0.0, "avg_logprob": -0.09582319152489137, "compression_ratio": 1.6422018348623852, "no_speech_prob": 3.1866816243564244e-06}, {"id": 45, "seek": 32418, "start": 331.14, "end": 337.7, "text": " on EAP or WebSphere or whatever, running on a Kubernetes node, you can see they take", "tokens": [322, 462, 4715, 420, 9573, 50, 6605, 420, 2035, 11, 2614, 322, 257, 23145, 9984, 11, 291, 393, 536, 436, 747], "temperature": 0.0, "avg_logprob": -0.09582319152489137, "compression_ratio": 1.6422018348623852, "no_speech_prob": 3.1866816243564244e-06}, {"id": 46, "seek": 32418, "start": 337.7, "end": 344.9, "text": " up quite a bit of space. Let's say that in this case, only four instances of the application", "tokens": [493, 1596, 257, 857, 295, 1901, 13, 961, 311, 584, 300, 294, 341, 1389, 11, 787, 1451, 14519, 295, 264, 3861], "temperature": 0.0, "avg_logprob": -0.09582319152489137, "compression_ratio": 1.6422018348623852, "no_speech_prob": 3.1866816243564244e-06}, {"id": 47, "seek": 32418, "start": 344.9, "end": 353.98, "text": " can run, which isn't so ideal because if one of the pods, one of the containers goes down,", "tokens": [393, 1190, 11, 597, 1943, 380, 370, 7157, 570, 498, 472, 295, 264, 31925, 11, 472, 295, 264, 17089, 1709, 760, 11], "temperature": 0.0, "avg_logprob": -0.09582319152489137, "compression_ratio": 1.6422018348623852, "no_speech_prob": 3.1866816243564244e-06}, {"id": 48, "seek": 35398, "start": 353.98, "end": 364.66, "text": " that means you lose 25% of your workload, right? If you look at Quarkus, on the JVM,", "tokens": [300, 1355, 291, 3624, 3552, 4, 295, 428, 20139, 11, 558, 30, 759, 291, 574, 412, 2326, 809, 301, 11, 322, 264, 508, 53, 44, 11], "temperature": 0.0, "avg_logprob": -0.1364727020263672, "compression_ratio": 1.5043859649122806, "no_speech_prob": 8.011517820705194e-06}, {"id": 49, "seek": 35398, "start": 364.66, "end": 368.54, "text": " you already have quite a bit more density, which means that if one of these guys goes", "tokens": [291, 1217, 362, 1596, 257, 857, 544, 10305, 11, 597, 1355, 300, 498, 472, 295, 613, 1074, 1709], "temperature": 0.0, "avg_logprob": -0.1364727020263672, "compression_ratio": 1.5043859649122806, "no_speech_prob": 8.011517820705194e-06}, {"id": 50, "seek": 35398, "start": 368.54, "end": 375.06, "text": " down or needs to be rescheduled or whatever, you still have, you know, what is it, maybe", "tokens": [760, 420, 2203, 281, 312, 725, 19318, 45893, 420, 2035, 11, 291, 920, 362, 11, 291, 458, 11, 437, 307, 309, 11, 1310], "temperature": 0.0, "avg_logprob": -0.1364727020263672, "compression_ratio": 1.5043859649122806, "no_speech_prob": 8.011517820705194e-06}, {"id": 51, "seek": 35398, "start": 375.06, "end": 383.94, "text": " 70% or something, that's still up. And, you know, we can compare that to Node.js or", "tokens": [5285, 4, 420, 746, 11, 300, 311, 920, 493, 13, 400, 11, 291, 458, 11, 321, 393, 6794, 300, 281, 38640, 13, 25530, 420], "temperature": 0.0, "avg_logprob": -0.1364727020263672, "compression_ratio": 1.5043859649122806, "no_speech_prob": 8.011517820705194e-06}, {"id": 52, "seek": 38394, "start": 383.94, "end": 392.21999999999997, "text": " a Go or something, where Go has quite a smaller footprint and with Quarkus native, we can", "tokens": [257, 1037, 420, 746, 11, 689, 1037, 575, 1596, 257, 4356, 24222, 293, 365, 2326, 809, 301, 8470, 11, 321, 393], "temperature": 0.0, "avg_logprob": -0.12907201698027462, "compression_ratio": 1.5874439461883407, "no_speech_prob": 1.4962755813030526e-05}, {"id": 53, "seek": 38394, "start": 392.21999999999997, "end": 397.82, "text": " actually be very comparable with Go, which is nice because that means that we can use", "tokens": [767, 312, 588, 25323, 365, 1037, 11, 597, 307, 1481, 570, 300, 1355, 300, 321, 393, 764], "temperature": 0.0, "avg_logprob": -0.12907201698027462, "compression_ratio": 1.5874439461883407, "no_speech_prob": 1.4962755813030526e-05}, {"id": 54, "seek": 38394, "start": 397.82, "end": 405.78, "text": " our Java skills and not have to, you know, change languages and reinvent the wheel and", "tokens": [527, 10745, 3942, 293, 406, 362, 281, 11, 291, 458, 11, 1319, 8650, 293, 33477, 264, 5589, 293], "temperature": 0.0, "avg_logprob": -0.12907201698027462, "compression_ratio": 1.5874439461883407, "no_speech_prob": 1.4962755813030526e-05}, {"id": 55, "seek": 38394, "start": 405.78, "end": 412.22, "text": " still get all the benefits in the cloud native world of having fast startup and everything.", "tokens": [920, 483, 439, 264, 5311, 294, 264, 4588, 8470, 1002, 295, 1419, 2370, 18578, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.12907201698027462, "compression_ratio": 1.5874439461883407, "no_speech_prob": 1.4962755813030526e-05}, {"id": 56, "seek": 41222, "start": 412.22, "end": 418.22, "text": " So how does that work? So a traditional Java application, basically build time is when", "tokens": [407, 577, 775, 300, 589, 30, 407, 257, 5164, 10745, 3861, 11, 1936, 1322, 565, 307, 562], "temperature": 0.0, "avg_logprob": -0.13700578326270693, "compression_ratio": 1.6542056074766356, "no_speech_prob": 7.525824912590906e-06}, {"id": 57, "seek": 41222, "start": 418.22, "end": 423.42, "text": " you do your packaging and then as it starts up, it loads config files and then does class", "tokens": [291, 360, 428, 16836, 293, 550, 382, 309, 3719, 493, 11, 309, 12668, 6662, 7098, 293, 550, 775, 1508], "temperature": 0.0, "avg_logprob": -0.13700578326270693, "compression_ratio": 1.6542056074766356, "no_speech_prob": 7.525824912590906e-06}, {"id": 58, "seek": 41222, "start": 423.42, "end": 428.46000000000004, "text": " pass scanning and build kind of its model of the world and everything, but this is when", "tokens": [1320, 27019, 293, 1322, 733, 295, 1080, 2316, 295, 264, 1002, 293, 1203, 11, 457, 341, 307, 562], "temperature": 0.0, "avg_logprob": -0.13700578326270693, "compression_ratio": 1.6542056074766356, "no_speech_prob": 7.525824912590906e-06}, {"id": 59, "seek": 41222, "start": 428.46000000000004, "end": 433.46000000000004, "text": " it starts up. So if you think of containers, again, that means that this all happens when", "tokens": [309, 3719, 493, 13, 407, 498, 291, 519, 295, 17089, 11, 797, 11, 300, 1355, 300, 341, 439, 2314, 562], "temperature": 0.0, "avg_logprob": -0.13700578326270693, "compression_ratio": 1.6542056074766356, "no_speech_prob": 7.525824912590906e-06}, {"id": 60, "seek": 43346, "start": 433.46, "end": 443.14, "text": " the container starts up and that takes a while. And then, so with Quarkus, what we try to", "tokens": [264, 10129, 3719, 493, 293, 300, 2516, 257, 1339, 13, 400, 550, 11, 370, 365, 2326, 809, 301, 11, 437, 321, 853, 281], "temperature": 0.0, "avg_logprob": -0.10030875887189593, "compression_ratio": 1.5114942528735633, "no_speech_prob": 2.0898839920846513e-06}, {"id": 61, "seek": 43346, "start": 443.14, "end": 450.09999999999997, "text": " do is instead of doing all that, you know, at runtime, at startup time, we're trying", "tokens": [360, 307, 2602, 295, 884, 439, 300, 11, 291, 458, 11, 412, 34474, 11, 412, 18578, 565, 11, 321, 434, 1382], "temperature": 0.0, "avg_logprob": -0.10030875887189593, "compression_ratio": 1.5114942528735633, "no_speech_prob": 2.0898839920846513e-06}, {"id": 62, "seek": 43346, "start": 450.09999999999997, "end": 458.09999999999997, "text": " to do all of this or as much as we can during build time before the application actually", "tokens": [281, 360, 439, 295, 341, 420, 382, 709, 382, 321, 393, 1830, 1322, 565, 949, 264, 3861, 767], "temperature": 0.0, "avg_logprob": -0.10030875887189593, "compression_ratio": 1.5114942528735633, "no_speech_prob": 2.0898839920846513e-06}, {"id": 63, "seek": 45810, "start": 458.1, "end": 463.54, "text": " gets packaged, which means that during runtime, we have a lot less to do, right? So it starts", "tokens": [2170, 38162, 11, 597, 1355, 300, 1830, 34474, 11, 321, 362, 257, 688, 1570, 281, 360, 11, 558, 30, 407, 309, 3719], "temperature": 0.0, "avg_logprob": -0.1200332836228974, "compression_ratio": 1.5764192139737991, "no_speech_prob": 6.337530521705048e-06}, {"id": 64, "seek": 45810, "start": 463.54, "end": 471.02000000000004, "text": " up quite a bit faster. So that's kind of the cool thing about Quarkus. And then, so you", "tokens": [493, 1596, 257, 857, 4663, 13, 407, 300, 311, 733, 295, 264, 1627, 551, 466, 2326, 809, 301, 13, 400, 550, 11, 370, 291], "temperature": 0.0, "avg_logprob": -0.1200332836228974, "compression_ratio": 1.5764192139737991, "no_speech_prob": 6.337530521705048e-06}, {"id": 65, "seek": 45810, "start": 471.02000000000004, "end": 477.5, "text": " can use Quarkus on JVM or you can compile it down to native, of course, just like most", "tokens": [393, 764, 2326, 809, 301, 322, 508, 53, 44, 420, 291, 393, 31413, 309, 760, 281, 8470, 11, 295, 1164, 11, 445, 411, 881], "temperature": 0.0, "avg_logprob": -0.1200332836228974, "compression_ratio": 1.5764192139737991, "no_speech_prob": 6.337530521705048e-06}, {"id": 66, "seek": 45810, "start": 477.5, "end": 484.70000000000005, "text": " other frameworks. But there's some cool things about native compilation with Quarkus as well", "tokens": [661, 29834, 13, 583, 456, 311, 512, 1627, 721, 466, 8470, 40261, 365, 2326, 809, 301, 382, 731], "temperature": 0.0, "avg_logprob": -0.1200332836228974, "compression_ratio": 1.5764192139737991, "no_speech_prob": 6.337530521705048e-06}, {"id": 67, "seek": 48470, "start": 484.7, "end": 490.09999999999997, "text": " that we'll get into in just a second. So this is my favorite part about Quarkus. It's not", "tokens": [300, 321, 603, 483, 666, 294, 445, 257, 1150, 13, 407, 341, 307, 452, 2954, 644, 466, 2326, 809, 301, 13, 467, 311, 406], "temperature": 0.0, "avg_logprob": -0.09698894770458491, "compression_ratio": 1.617117117117117, "no_speech_prob": 2.3531942133558914e-05}, {"id": 68, "seek": 48470, "start": 490.09999999999997, "end": 494.74, "text": " necessarily, I mean, yes, it's nice that it starts up fast. It's nice that it has a small", "tokens": [4725, 11, 286, 914, 11, 2086, 11, 309, 311, 1481, 300, 309, 3719, 493, 2370, 13, 467, 311, 1481, 300, 309, 575, 257, 1359], "temperature": 0.0, "avg_logprob": -0.09698894770458491, "compression_ratio": 1.617117117117117, "no_speech_prob": 2.3531942133558914e-05}, {"id": 69, "seek": 48470, "start": 494.74, "end": 501.5, "text": " memory footprint. But what's really cool about Quarkus is that it has a bunch of different", "tokens": [4675, 24222, 13, 583, 437, 311, 534, 1627, 466, 2326, 809, 301, 307, 300, 309, 575, 257, 3840, 295, 819], "temperature": 0.0, "avg_logprob": -0.09698894770458491, "compression_ratio": 1.617117117117117, "no_speech_prob": 2.3531942133558914e-05}, {"id": 70, "seek": 48470, "start": 501.5, "end": 512.9, "text": " ways of making the experience of working with Java and Quarkus a lot more fun. So one of", "tokens": [2098, 295, 1455, 264, 1752, 295, 1364, 365, 10745, 293, 2326, 809, 301, 257, 688, 544, 1019, 13, 407, 472, 295], "temperature": 0.0, "avg_logprob": -0.09698894770458491, "compression_ratio": 1.617117117117117, "no_speech_prob": 2.3531942133558914e-05}, {"id": 71, "seek": 51290, "start": 512.9, "end": 518.78, "text": " them is, you know, so of course, it's based on standards. So Quarkus uses, you know, your", "tokens": [552, 307, 11, 291, 458, 11, 370, 295, 1164, 11, 309, 311, 2361, 322, 7787, 13, 407, 2326, 809, 301, 4960, 11, 291, 458, 11, 428], "temperature": 0.0, "avg_logprob": -0.16816207078786996, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.8336835637455806e-05}, {"id": 72, "seek": 51290, "start": 518.78, "end": 524.9399999999999, "text": " Java EE standards, the Java standards, uses, you know, Vertex and all that good stuff.", "tokens": [10745, 33685, 7787, 11, 264, 10745, 7787, 11, 4960, 11, 291, 458, 11, 21044, 3121, 293, 439, 300, 665, 1507, 13], "temperature": 0.0, "avg_logprob": -0.16816207078786996, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.8336835637455806e-05}, {"id": 73, "seek": 51290, "start": 524.9399999999999, "end": 532.8199999999999, "text": " So if you're used to that, hey, great. You basically already know Quarkus for 99%. What's", "tokens": [407, 498, 291, 434, 1143, 281, 300, 11, 4177, 11, 869, 13, 509, 1936, 1217, 458, 2326, 809, 301, 337, 11803, 6856, 708, 311], "temperature": 0.0, "avg_logprob": -0.16816207078786996, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.8336835637455806e-05}, {"id": 74, "seek": 51290, "start": 532.8199999999999, "end": 540.14, "text": " really cool with Quarkus is that there's this dev mode. This basically, you can start Quarkus", "tokens": [534, 1627, 365, 2326, 809, 301, 307, 300, 456, 311, 341, 1905, 4391, 13, 639, 1936, 11, 291, 393, 722, 2326, 809, 301], "temperature": 0.0, "avg_logprob": -0.16816207078786996, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.8336835637455806e-05}, {"id": 75, "seek": 54014, "start": 540.14, "end": 546.3, "text": " on your local machine in dev mode. It's going to start up. And it's going to just keep checking", "tokens": [322, 428, 2654, 3479, 294, 1905, 4391, 13, 467, 311, 516, 281, 722, 493, 13, 400, 309, 311, 516, 281, 445, 1066, 8568], "temperature": 0.0, "avg_logprob": -0.10561610512111498, "compression_ratio": 1.8938775510204082, "no_speech_prob": 1.0448765351611655e-05}, {"id": 76, "seek": 54014, "start": 546.3, "end": 552.5, "text": " to see if you make changes in the class path. And so every time you make a change, it's", "tokens": [281, 536, 498, 291, 652, 2962, 294, 264, 1508, 3100, 13, 400, 370, 633, 565, 291, 652, 257, 1319, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.10561610512111498, "compression_ratio": 1.8938775510204082, "no_speech_prob": 1.0448765351611655e-05}, {"id": 77, "seek": 54014, "start": 552.5, "end": 557.34, "text": " going to automatically reload when you, you know, let's say go into your browser or whatever", "tokens": [516, 281, 6772, 25628, 562, 291, 11, 291, 458, 11, 718, 311, 584, 352, 666, 428, 11185, 420, 2035], "temperature": 0.0, "avg_logprob": -0.10561610512111498, "compression_ratio": 1.8938775510204082, "no_speech_prob": 1.0448765351611655e-05}, {"id": 78, "seek": 54014, "start": 557.34, "end": 563.46, "text": " you make a new request. It's going to automatically reload your application so you don't need", "tokens": [291, 652, 257, 777, 5308, 13, 467, 311, 516, 281, 6772, 25628, 428, 3861, 370, 291, 500, 380, 643], "temperature": 0.0, "avg_logprob": -0.10561610512111498, "compression_ratio": 1.8938775510204082, "no_speech_prob": 1.0448765351611655e-05}, {"id": 79, "seek": 54014, "start": 563.46, "end": 569.62, "text": " to recompile, redeploy every time you want to test something. Quarkus does that automatically", "tokens": [281, 48000, 794, 11, 14328, 2384, 633, 565, 291, 528, 281, 1500, 746, 13, 2326, 809, 301, 775, 300, 6772], "temperature": 0.0, "avg_logprob": -0.10561610512111498, "compression_ratio": 1.8938775510204082, "no_speech_prob": 1.0448765351611655e-05}, {"id": 80, "seek": 56962, "start": 569.62, "end": 576.5, "text": " so you can just go to your browser, hit refresh, and it's there. So make a code change, refresh,", "tokens": [370, 291, 393, 445, 352, 281, 428, 11185, 11, 2045, 15134, 11, 293, 309, 311, 456, 13, 407, 652, 257, 3089, 1319, 11, 15134, 11], "temperature": 0.0, "avg_logprob": -0.1280218033563523, "compression_ratio": 1.6742081447963801, "no_speech_prob": 1.2027318916807417e-05}, {"id": 81, "seek": 56962, "start": 576.5, "end": 584.3, "text": " it's there. Which, you know, if you're a developer of a couple, you know, of some other language", "tokens": [309, 311, 456, 13, 3013, 11, 291, 458, 11, 498, 291, 434, 257, 10754, 295, 257, 1916, 11, 291, 458, 11, 295, 512, 661, 2856], "temperature": 0.0, "avg_logprob": -0.1280218033563523, "compression_ratio": 1.6742081447963801, "no_speech_prob": 1.2027318916807417e-05}, {"id": 82, "seek": 56962, "start": 584.3, "end": 589.74, "text": " where that just happens, then that's not so cool. But in Java, that's pretty cool, right?", "tokens": [689, 300, 445, 2314, 11, 550, 300, 311, 406, 370, 1627, 13, 583, 294, 10745, 11, 300, 311, 1238, 1627, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1280218033563523, "compression_ratio": 1.6742081447963801, "no_speech_prob": 1.2027318916807417e-05}, {"id": 83, "seek": 56962, "start": 589.74, "end": 593.5, "text": " So we've got our little guy here that says, wait, so you just save it and your code is", "tokens": [407, 321, 600, 658, 527, 707, 2146, 510, 300, 1619, 11, 1699, 11, 370, 291, 445, 3155, 309, 293, 428, 3089, 307], "temperature": 0.0, "avg_logprob": -0.1280218033563523, "compression_ratio": 1.6742081447963801, "no_speech_prob": 1.2027318916807417e-05}, {"id": 84, "seek": 59350, "start": 593.5, "end": 601.62, "text": " running and it's Java? And the guy says, I know, right? Super Sonic Java. So that's,", "tokens": [2614, 293, 309, 311, 10745, 30, 400, 264, 2146, 1619, 11, 286, 458, 11, 558, 30, 4548, 14290, 10745, 13, 407, 300, 311, 11], "temperature": 0.0, "avg_logprob": -0.21906248260946834, "compression_ratio": 1.497175141242938, "no_speech_prob": 8.936806807469111e-06}, {"id": 85, "seek": 59350, "start": 601.62, "end": 607.9, "text": " that's pretty cool. Another cool thing with Quarkus is that it has this concept of developer", "tokens": [300, 311, 1238, 1627, 13, 3996, 1627, 551, 365, 2326, 809, 301, 307, 300, 309, 575, 341, 3410, 295, 10754], "temperature": 0.0, "avg_logprob": -0.21906248260946834, "compression_ratio": 1.497175141242938, "no_speech_prob": 8.936806807469111e-06}, {"id": 86, "seek": 59350, "start": 607.9, "end": 615.58, "text": " services. So who knows test containers? So basically it uses test containers built into", "tokens": [3328, 13, 407, 567, 3255, 1500, 17089, 30, 407, 1936, 309, 4960, 1500, 17089, 3094, 666], "temperature": 0.0, "avg_logprob": -0.21906248260946834, "compression_ratio": 1.497175141242938, "no_speech_prob": 8.936806807469111e-06}, {"id": 87, "seek": 61558, "start": 615.58, "end": 623.86, "text": " Quarkus. So let's say that I'm developing an application and I'm adding an extension", "tokens": [2326, 809, 301, 13, 407, 718, 311, 584, 300, 286, 478, 6416, 364, 3861, 293, 286, 478, 5127, 364, 10320], "temperature": 0.0, "avg_logprob": -0.15368116923740932, "compression_ratio": 1.451086956521739, "no_speech_prob": 3.844194907287601e-06}, {"id": 88, "seek": 61558, "start": 623.86, "end": 633.98, "text": " to use Postgres database or a Kafka, a Kafka topic or something. Actually, well, of course", "tokens": [281, 764, 10223, 45189, 8149, 420, 257, 47064, 11, 257, 47064, 4829, 420, 746, 13, 5135, 11, 731, 11, 295, 1164], "temperature": 0.0, "avg_logprob": -0.15368116923740932, "compression_ratio": 1.451086956521739, "no_speech_prob": 3.844194907287601e-06}, {"id": 89, "seek": 61558, "start": 633.98, "end": 639.34, "text": " you have to have a Docker or Podman or something running on your local machine. But Quarkus", "tokens": [291, 362, 281, 362, 257, 33772, 420, 12646, 1601, 420, 746, 2614, 322, 428, 2654, 3479, 13, 583, 2326, 809, 301], "temperature": 0.0, "avg_logprob": -0.15368116923740932, "compression_ratio": 1.451086956521739, "no_speech_prob": 3.844194907287601e-06}, {"id": 90, "seek": 63934, "start": 639.34, "end": 647.14, "text": " will look and see, hey, you've got, you've got this dependency on a database. Do you", "tokens": [486, 574, 293, 536, 11, 4177, 11, 291, 600, 658, 11, 291, 600, 658, 341, 33621, 322, 257, 8149, 13, 1144, 291], "temperature": 0.0, "avg_logprob": -0.12013327938386764, "compression_ratio": 1.7355769230769231, "no_speech_prob": 6.047983788448619e-06}, {"id": 91, "seek": 63934, "start": 647.14, "end": 651.14, "text": " have something configured on your local machine? Do you have a database running on your local", "tokens": [362, 746, 30538, 322, 428, 2654, 3479, 30, 1144, 291, 362, 257, 8149, 2614, 322, 428, 2654], "temperature": 0.0, "avg_logprob": -0.12013327938386764, "compression_ratio": 1.7355769230769231, "no_speech_prob": 6.047983788448619e-06}, {"id": 92, "seek": 63934, "start": 651.14, "end": 656.14, "text": " machine? Is that configured in your application properties? If not, no worries, I'm just", "tokens": [3479, 30, 1119, 300, 30538, 294, 428, 3861, 7221, 30, 759, 406, 11, 572, 16340, 11, 286, 478, 445], "temperature": 0.0, "avg_logprob": -0.12013327938386764, "compression_ratio": 1.7355769230769231, "no_speech_prob": 6.047983788448619e-06}, {"id": 93, "seek": 63934, "start": 656.14, "end": 663.9000000000001, "text": " going to start up a container with that dependency, for example, a Postgres database and wire", "tokens": [516, 281, 722, 493, 257, 10129, 365, 300, 33621, 11, 337, 1365, 11, 257, 10223, 45189, 8149, 293, 6234], "temperature": 0.0, "avg_logprob": -0.12013327938386764, "compression_ratio": 1.7355769230769231, "no_speech_prob": 6.047983788448619e-06}, {"id": 94, "seek": 66390, "start": 663.9, "end": 671.3, "text": " that up. So it's going to, you know, set the configuration so that it connects to that", "tokens": [300, 493, 13, 407, 309, 311, 516, 281, 11, 291, 458, 11, 992, 264, 11694, 370, 300, 309, 16967, 281, 300], "temperature": 0.0, "avg_logprob": -0.10928805490558068, "compression_ratio": 1.6981132075471699, "no_speech_prob": 6.239112735784147e-06}, {"id": 95, "seek": 66390, "start": 671.3, "end": 678.74, "text": " database automatically. And then you can even go and see, you know, what exactly that configuration", "tokens": [8149, 6772, 13, 400, 550, 291, 393, 754, 352, 293, 536, 11, 291, 458, 11, 437, 2293, 300, 11694], "temperature": 0.0, "avg_logprob": -0.10928805490558068, "compression_ratio": 1.6981132075471699, "no_speech_prob": 6.239112735784147e-06}, {"id": 96, "seek": 66390, "start": 678.74, "end": 686.5, "text": " is and then copy it down. Anyway, so that's the developer services. So Kafka or, yeah,", "tokens": [307, 293, 550, 5055, 309, 760, 13, 5684, 11, 370, 300, 311, 264, 10754, 3328, 13, 407, 47064, 420, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.10928805490558068, "compression_ratio": 1.6981132075471699, "no_speech_prob": 6.239112735784147e-06}, {"id": 97, "seek": 66390, "start": 686.5, "end": 690.5799999999999, "text": " there's a whole bunch of different developer services that you can use just out of the", "tokens": [456, 311, 257, 1379, 3840, 295, 819, 10754, 3328, 300, 291, 393, 764, 445, 484, 295, 264], "temperature": 0.0, "avg_logprob": -0.10928805490558068, "compression_ratio": 1.6981132075471699, "no_speech_prob": 6.239112735784147e-06}, {"id": 98, "seek": 69058, "start": 690.58, "end": 695.86, "text": " box, which is pretty nice because otherwise, you know, having to configure a database on", "tokens": [2424, 11, 597, 307, 1238, 1481, 570, 5911, 11, 291, 458, 11, 1419, 281, 22162, 257, 8149, 322], "temperature": 0.0, "avg_logprob": -0.13704979419708252, "compression_ratio": 1.6055045871559632, "no_speech_prob": 9.221645086654462e-06}, {"id": 99, "seek": 69058, "start": 695.86, "end": 702.1, "text": " your local machine or Lord forbid, a Kafka instance with all your zookeepers and all", "tokens": [428, 2654, 3479, 420, 3257, 34117, 11, 257, 47064, 5197, 365, 439, 428, 25347, 43153, 293, 439], "temperature": 0.0, "avg_logprob": -0.13704979419708252, "compression_ratio": 1.6055045871559632, "no_speech_prob": 9.221645086654462e-06}, {"id": 100, "seek": 69058, "start": 702.1, "end": 708.38, "text": " that stuff, that's not so easy. You also, you know, so you have live coding, you also", "tokens": [300, 1507, 11, 300, 311, 406, 370, 1858, 13, 509, 611, 11, 291, 458, 11, 370, 291, 362, 1621, 17720, 11, 291, 611], "temperature": 0.0, "avg_logprob": -0.13704979419708252, "compression_ratio": 1.6055045871559632, "no_speech_prob": 9.221645086654462e-06}, {"id": 101, "seek": 69058, "start": 708.38, "end": 716.5, "text": " have continuous testing. So kind of the same concept. So if you have unit tests, you start", "tokens": [362, 10957, 4997, 13, 407, 733, 295, 264, 912, 3410, 13, 407, 498, 291, 362, 4985, 6921, 11, 291, 722], "temperature": 0.0, "avg_logprob": -0.13704979419708252, "compression_ratio": 1.6055045871559632, "no_speech_prob": 9.221645086654462e-06}, {"id": 102, "seek": 71650, "start": 716.5, "end": 724.02, "text": " your continuous testing. So every time you make a code change, it knows, hey, this class", "tokens": [428, 10957, 4997, 13, 407, 633, 565, 291, 652, 257, 3089, 1319, 11, 309, 3255, 11, 4177, 11, 341, 1508], "temperature": 0.0, "avg_logprob": -0.09685941452675677, "compression_ratio": 1.7857142857142858, "no_speech_prob": 2.7528341888682917e-05}, {"id": 103, "seek": 71650, "start": 724.02, "end": 728.5, "text": " is related to this unit test. So I'm going to rerun this unit test every time I make", "tokens": [307, 4077, 281, 341, 4985, 1500, 13, 407, 286, 478, 516, 281, 43819, 409, 341, 4985, 1500, 633, 565, 286, 652], "temperature": 0.0, "avg_logprob": -0.09685941452675677, "compression_ratio": 1.7857142857142858, "no_speech_prob": 2.7528341888682917e-05}, {"id": 104, "seek": 71650, "start": 728.5, "end": 735.94, "text": " a change here or vice versa. If you're making a change in a unit test, it knows, you know,", "tokens": [257, 1319, 510, 420, 11964, 25650, 13, 759, 291, 434, 1455, 257, 1319, 294, 257, 4985, 1500, 11, 309, 3255, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.09685941452675677, "compression_ratio": 1.7857142857142858, "no_speech_prob": 2.7528341888682917e-05}, {"id": 105, "seek": 71650, "start": 735.94, "end": 741.02, "text": " this is what I need to rerun. So it gives you quick and immediate feedback every time", "tokens": [341, 307, 437, 286, 643, 281, 43819, 409, 13, 407, 309, 2709, 291, 1702, 293, 11629, 5824, 633, 565], "temperature": 0.0, "avg_logprob": -0.09685941452675677, "compression_ratio": 1.7857142857142858, "no_speech_prob": 2.7528341888682917e-05}, {"id": 106, "seek": 74102, "start": 741.02, "end": 748.46, "text": " as you're developing, which, yeah, again, it's pretty handy. It also has a dev UI. So", "tokens": [382, 291, 434, 6416, 11, 597, 11, 1338, 11, 797, 11, 309, 311, 1238, 13239, 13, 467, 611, 575, 257, 1905, 15682, 13, 407], "temperature": 0.0, "avg_logprob": -0.17823724110921224, "compression_ratio": 1.5, "no_speech_prob": 2.045014116447419e-05}, {"id": 107, "seek": 74102, "start": 748.46, "end": 754.14, "text": " it has a UI in your browser where you can go and look at all these different, you know,", "tokens": [309, 575, 257, 15682, 294, 428, 11185, 689, 291, 393, 352, 293, 574, 412, 439, 613, 819, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.17823724110921224, "compression_ratio": 1.5, "no_speech_prob": 2.045014116447419e-05}, {"id": 108, "seek": 74102, "start": 754.14, "end": 763.38, "text": " developer services that are running, what Quarkis is doing. So again, I was talking at the start", "tokens": [10754, 3328, 300, 366, 2614, 11, 437, 2326, 809, 271, 307, 884, 13, 407, 797, 11, 286, 390, 1417, 412, 264, 722], "temperature": 0.0, "avg_logprob": -0.17823724110921224, "compression_ratio": 1.5, "no_speech_prob": 2.045014116447419e-05}, {"id": 109, "seek": 76338, "start": 763.38, "end": 773.18, "text": " about Quarkis doing some optimization, right? So during the compilation time, so in the", "tokens": [466, 2326, 809, 271, 884, 512, 19618, 11, 558, 30, 407, 1830, 264, 40261, 565, 11, 370, 294, 264], "temperature": 0.0, "avg_logprob": -0.13059576762091255, "compression_ratio": 1.6682242990654206, "no_speech_prob": 3.237125838495558e-06}, {"id": 110, "seek": 76338, "start": 773.18, "end": 780.3, "text": " dev UI, you can actually see, you know, what it's doing, how it's optimizing and what it's", "tokens": [1905, 15682, 11, 291, 393, 767, 536, 11, 291, 458, 11, 437, 309, 311, 884, 11, 577, 309, 311, 40425, 293, 437, 309, 311], "temperature": 0.0, "avg_logprob": -0.13059576762091255, "compression_ratio": 1.6682242990654206, "no_speech_prob": 3.237125838495558e-06}, {"id": 111, "seek": 76338, "start": 780.3, "end": 785.42, "text": " going to remove from the class path because Quarkis does, you know, some introspection", "tokens": [516, 281, 4159, 490, 264, 1508, 3100, 570, 2326, 809, 271, 775, 11, 291, 458, 11, 512, 560, 2635, 19997], "temperature": 0.0, "avg_logprob": -0.13059576762091255, "compression_ratio": 1.6682242990654206, "no_speech_prob": 3.237125838495558e-06}, {"id": 112, "seek": 76338, "start": 785.42, "end": 791.3, "text": " to make sure that, hey, this is used or this actually isn't used by your code. So I'm going", "tokens": [281, 652, 988, 300, 11, 4177, 11, 341, 307, 1143, 420, 341, 767, 1943, 380, 1143, 538, 428, 3089, 13, 407, 286, 478, 516], "temperature": 0.0, "avg_logprob": -0.13059576762091255, "compression_ratio": 1.6682242990654206, "no_speech_prob": 3.237125838495558e-06}, {"id": 113, "seek": 79130, "start": 791.3, "end": 800.74, "text": " to remove all that from the compilation. There's a Quarkis CLI, which, again, it's", "tokens": [281, 4159, 439, 300, 490, 264, 40261, 13, 821, 311, 257, 2326, 809, 271, 12855, 40, 11, 597, 11, 797, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.15451731505217375, "compression_ratio": 1.5421686746987953, "no_speech_prob": 2.5860908863251098e-05}, {"id": 114, "seek": 79130, "start": 800.74, "end": 809.6999999999999, "text": " not super crazy, but so you can either use Quarkis with Gradle or Maven, or you can just", "tokens": [406, 1687, 3219, 11, 457, 370, 291, 393, 2139, 764, 2326, 809, 271, 365, 16710, 306, 420, 4042, 553, 11, 420, 291, 393, 445], "temperature": 0.0, "avg_logprob": -0.15451731505217375, "compression_ratio": 1.5421686746987953, "no_speech_prob": 2.5860908863251098e-05}, {"id": 115, "seek": 79130, "start": 809.6999999999999, "end": 816.3, "text": " use the Quarkis CLI, which means that you can do, like, Quarkis dev or Quarkis build", "tokens": [764, 264, 2326, 809, 271, 12855, 40, 11, 597, 1355, 300, 291, 393, 360, 11, 411, 11, 2326, 809, 271, 1905, 420, 2326, 809, 271, 1322], "temperature": 0.0, "avg_logprob": -0.15451731505217375, "compression_ratio": 1.5421686746987953, "no_speech_prob": 2.5860908863251098e-05}, {"id": 116, "seek": 81630, "start": 816.3, "end": 825.8599999999999, "text": " or whatever. You can even use, you can say Quarkis image build or image push, and it's", "tokens": [420, 2035, 13, 509, 393, 754, 764, 11, 291, 393, 584, 2326, 809, 271, 3256, 1322, 420, 3256, 2944, 11, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.17042938400717342, "compression_ratio": 1.6211180124223603, "no_speech_prob": 9.513234545011073e-06}, {"id": 117, "seek": 81630, "start": 825.8599999999999, "end": 835.38, "text": " going to build your application. So build your application, build a container, and you can", "tokens": [516, 281, 1322, 428, 3861, 13, 407, 1322, 428, 3861, 11, 1322, 257, 10129, 11, 293, 291, 393], "temperature": 0.0, "avg_logprob": -0.17042938400717342, "compression_ratio": 1.6211180124223603, "no_speech_prob": 9.513234545011073e-06}, {"id": 118, "seek": 81630, "start": 835.38, "end": 840.38, "text": " even push it automatically all, you know, from one command, which is kind of handy,", "tokens": [754, 2944, 309, 6772, 439, 11, 291, 458, 11, 490, 472, 5622, 11, 597, 307, 733, 295, 13239, 11], "temperature": 0.0, "avg_logprob": -0.17042938400717342, "compression_ratio": 1.6211180124223603, "no_speech_prob": 9.513234545011073e-06}, {"id": 119, "seek": 84038, "start": 840.38, "end": 847.02, "text": " right? And then one of the last, but not least, is unification of imperative and reactive", "tokens": [558, 30, 400, 550, 472, 295, 264, 1036, 11, 457, 406, 1935, 11, 307, 517, 3774, 295, 32490, 293, 28897], "temperature": 0.0, "avg_logprob": -0.1618833403656448, "compression_ratio": 1.6, "no_speech_prob": 8.529295882908627e-06}, {"id": 120, "seek": 84038, "start": 847.02, "end": 859.02, "text": " programming. So Quarkis has a lot of reactive programming kind of built in underneath. Now,", "tokens": [9410, 13, 407, 2326, 809, 271, 575, 257, 688, 295, 28897, 9410, 733, 295, 3094, 294, 7223, 13, 823, 11], "temperature": 0.0, "avg_logprob": -0.1618833403656448, "compression_ratio": 1.6, "no_speech_prob": 8.529295882908627e-06}, {"id": 121, "seek": 84038, "start": 859.02, "end": 865.42, "text": " me, for example, I'm not a super deep expert in reactive programming, but what's nice with", "tokens": [385, 11, 337, 1365, 11, 286, 478, 406, 257, 1687, 2452, 5844, 294, 28897, 9410, 11, 457, 437, 311, 1481, 365], "temperature": 0.0, "avg_logprob": -0.1618833403656448, "compression_ratio": 1.6, "no_speech_prob": 8.529295882908627e-06}, {"id": 122, "seek": 86542, "start": 865.42, "end": 870.9399999999999, "text": " Quarkis, too, is that I can write imperative code, right? So just, you know, every statement", "tokens": [2326, 809, 271, 11, 886, 11, 307, 300, 286, 393, 2464, 32490, 3089, 11, 558, 30, 407, 445, 11, 291, 458, 11, 633, 5629], "temperature": 0.0, "avg_logprob": -0.11228407035439701, "compression_ratio": 1.731060606060606, "no_speech_prob": 5.4214592637436e-06}, {"id": 123, "seek": 86542, "start": 870.9399999999999, "end": 877.26, "text": " gets handled one at a time and it blocks every time, whereas with reactive, you've got these", "tokens": [2170, 18033, 472, 412, 257, 565, 293, 309, 8474, 633, 565, 11, 9735, 365, 28897, 11, 291, 600, 658, 613], "temperature": 0.0, "avg_logprob": -0.11228407035439701, "compression_ratio": 1.731060606060606, "no_speech_prob": 5.4214592637436e-06}, {"id": 124, "seek": 86542, "start": 877.26, "end": 884.2199999999999, "text": " event loops. But you can use both at the same time in the same, even in the same code in", "tokens": [2280, 16121, 13, 583, 291, 393, 764, 1293, 412, 264, 912, 565, 294, 264, 912, 11, 754, 294, 264, 912, 3089, 294], "temperature": 0.0, "avg_logprob": -0.11228407035439701, "compression_ratio": 1.731060606060606, "no_speech_prob": 5.4214592637436e-06}, {"id": 125, "seek": 86542, "start": 884.2199999999999, "end": 888.54, "text": " the same class. So for those who are familiar with reactive, usually you kind of have to", "tokens": [264, 912, 1508, 13, 407, 337, 729, 567, 366, 4963, 365, 28897, 11, 2673, 291, 733, 295, 362, 281], "temperature": 0.0, "avg_logprob": -0.11228407035439701, "compression_ratio": 1.731060606060606, "no_speech_prob": 5.4214592637436e-06}, {"id": 126, "seek": 86542, "start": 888.54, "end": 893.6999999999999, "text": " decide, hey, if I'm going to build a reactive application, that means I have to decide before", "tokens": [4536, 11, 4177, 11, 498, 286, 478, 516, 281, 1322, 257, 28897, 3861, 11, 300, 1355, 286, 362, 281, 4536, 949], "temperature": 0.0, "avg_logprob": -0.11228407035439701, "compression_ratio": 1.731060606060606, "no_speech_prob": 5.4214592637436e-06}, {"id": 127, "seek": 89370, "start": 893.7, "end": 899.5, "text": " I start writing this code, you know, that this framework that I'm going to use is reactive", "tokens": [286, 722, 3579, 341, 3089, 11, 291, 458, 11, 300, 341, 8388, 300, 286, 478, 516, 281, 764, 307, 28897], "temperature": 0.0, "avg_logprob": -0.12245770996692133, "compression_ratio": 1.6188340807174888, "no_speech_prob": 8.799963325145654e-06}, {"id": 128, "seek": 89370, "start": 899.5, "end": 906.94, "text": " and I can't combine the both. But with Quarkis, you can, which is nice. And best of all, it's", "tokens": [293, 286, 393, 380, 10432, 264, 1293, 13, 583, 365, 2326, 809, 271, 11, 291, 393, 11, 597, 307, 1481, 13, 400, 1151, 295, 439, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.12245770996692133, "compression_ratio": 1.6188340807174888, "no_speech_prob": 8.799963325145654e-06}, {"id": 129, "seek": 89370, "start": 906.94, "end": 912.7, "text": " still Java, right? So you get all these kind of features. And at the end of the day, if", "tokens": [920, 10745, 11, 558, 30, 407, 291, 483, 439, 613, 733, 295, 4122, 13, 400, 412, 264, 917, 295, 264, 786, 11, 498], "temperature": 0.0, "avg_logprob": -0.12245770996692133, "compression_ratio": 1.6188340807174888, "no_speech_prob": 8.799963325145654e-06}, {"id": 130, "seek": 89370, "start": 912.7, "end": 918.1800000000001, "text": " you're, you know, if you're familiar with Java, this is really not reinventing the wheel", "tokens": [291, 434, 11, 291, 458, 11, 498, 291, 434, 4963, 365, 10745, 11, 341, 307, 534, 406, 33477, 278, 264, 5589], "temperature": 0.0, "avg_logprob": -0.12245770996692133, "compression_ratio": 1.6188340807174888, "no_speech_prob": 8.799963325145654e-06}, {"id": 131, "seek": 91818, "start": 918.18, "end": 925.2199999999999, "text": " at all. So it uses micro-profile, vertex, rest easy, you know, like, and if you want", "tokens": [412, 439, 13, 407, 309, 4960, 4532, 12, 29175, 794, 11, 28162, 11, 1472, 1858, 11, 291, 458, 11, 411, 11, 293, 498, 291, 528], "temperature": 0.0, "avg_logprob": -0.14393899020026713, "compression_ratio": 1.572289156626506, "no_speech_prob": 1.450550371373538e-05}, {"id": 132, "seek": 91818, "start": 925.2199999999999, "end": 930.78, "text": " to add extensions, you can interact directly with Kubernetes. So you can push your code", "tokens": [281, 909, 25129, 11, 291, 393, 4648, 3838, 365, 23145, 13, 407, 291, 393, 2944, 428, 3089], "temperature": 0.0, "avg_logprob": -0.14393899020026713, "compression_ratio": 1.572289156626506, "no_speech_prob": 1.450550371373538e-05}, {"id": 133, "seek": 91818, "start": 930.78, "end": 939.3, "text": " directly to Kubernetes. You can create config maps or secrets directly from Quarkis. You", "tokens": [3838, 281, 23145, 13, 509, 393, 1884, 6662, 11317, 420, 14093, 3838, 490, 2326, 809, 271, 13, 509], "temperature": 0.0, "avg_logprob": -0.14393899020026713, "compression_ratio": 1.572289156626506, "no_speech_prob": 1.450550371373538e-05}, {"id": 134, "seek": 93930, "start": 939.3, "end": 949.18, "text": " can, you know, you can work really easily with Kafka and OpenShift, of course, patchy", "tokens": [393, 11, 291, 458, 11, 291, 393, 589, 534, 3612, 365, 47064, 293, 7238, 7774, 2008, 11, 295, 1164, 11, 9972, 88], "temperature": 0.0, "avg_logprob": -0.15534155898623997, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.9018701752647758e-06}, {"id": 135, "seek": 93930, "start": 949.18, "end": 957.8599999999999, "text": " camel and all that. So in terms of native compilation, I think we've already had a few", "tokens": [37755, 293, 439, 300, 13, 407, 294, 2115, 295, 8470, 40261, 11, 286, 519, 321, 600, 1217, 632, 257, 1326], "temperature": 0.0, "avg_logprob": -0.15534155898623997, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.9018701752647758e-06}, {"id": 136, "seek": 93930, "start": 957.8599999999999, "end": 963.02, "text": " sessions about that. So I'm not going to go too deep into that other than, you know, if", "tokens": [11081, 466, 300, 13, 407, 286, 478, 406, 516, 281, 352, 886, 2452, 666, 300, 661, 813, 11, 291, 458, 11, 498], "temperature": 0.0, "avg_logprob": -0.15534155898623997, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.9018701752647758e-06}, {"id": 137, "seek": 96302, "start": 963.02, "end": 969.46, "text": " you can run Quarkis on the JVM and probably for 70 to 80 percent of the use cases, that's", "tokens": [291, 393, 1190, 2326, 809, 271, 322, 264, 508, 53, 44, 293, 1391, 337, 5285, 281, 4688, 3043, 295, 264, 764, 3331, 11, 300, 311], "temperature": 0.0, "avg_logprob": -0.1232527732849121, "compression_ratio": 1.65625, "no_speech_prob": 4.028659986943239e-06}, {"id": 138, "seek": 96302, "start": 969.46, "end": 979.38, "text": " probably a good way to go. If you really want to have the fastest startup time and the smallest", "tokens": [1391, 257, 665, 636, 281, 352, 13, 759, 291, 534, 528, 281, 362, 264, 14573, 18578, 565, 293, 264, 16998], "temperature": 0.0, "avg_logprob": -0.1232527732849121, "compression_ratio": 1.65625, "no_speech_prob": 4.028659986943239e-06}, {"id": 139, "seek": 96302, "start": 979.38, "end": 985.42, "text": " footprint, then you can, you know, do a native build of your Quarkis application with Quarkis,", "tokens": [24222, 11, 550, 291, 393, 11, 291, 458, 11, 360, 257, 8470, 1322, 295, 428, 2326, 809, 271, 3861, 365, 2326, 809, 271, 11], "temperature": 0.0, "avg_logprob": -0.1232527732849121, "compression_ratio": 1.65625, "no_speech_prob": 4.028659986943239e-06}, {"id": 140, "seek": 96302, "start": 985.42, "end": 991.5, "text": " by the way, that's really easy because if you create a new Quarkis application, it already", "tokens": [538, 264, 636, 11, 300, 311, 534, 1858, 570, 498, 291, 1884, 257, 777, 2326, 809, 271, 3861, 11, 309, 1217], "temperature": 0.0, "avg_logprob": -0.1232527732849121, "compression_ratio": 1.65625, "no_speech_prob": 4.028659986943239e-06}, {"id": 141, "seek": 99150, "start": 991.5, "end": 998.34, "text": " automatically has a native profile built in. So you can decide, you know, as you're doing", "tokens": [6772, 575, 257, 8470, 7964, 3094, 294, 13, 407, 291, 393, 4536, 11, 291, 458, 11, 382, 291, 434, 884], "temperature": 0.0, "avg_logprob": -0.1709946496146066, "compression_ratio": 1.4432432432432432, "no_speech_prob": 2.2115675164968707e-05}, {"id": 142, "seek": 99150, "start": 998.34, "end": 1005.34, "text": " your compilation, whether you want to do a native build or not. But yeah, so Red Hat", "tokens": [428, 40261, 11, 1968, 291, 528, 281, 360, 257, 8470, 1322, 420, 406, 13, 583, 1338, 11, 370, 4477, 15867], "temperature": 0.0, "avg_logprob": -0.1709946496146066, "compression_ratio": 1.4432432432432432, "no_speech_prob": 2.2115675164968707e-05}, {"id": 143, "seek": 99150, "start": 1005.34, "end": 1011.18, "text": " is on the GrowlVM advisory board and then there's the mandrel project, which is a downstream", "tokens": [307, 322, 264, 18476, 75, 53, 44, 26289, 3150, 293, 550, 456, 311, 264, 7411, 4419, 1716, 11, 597, 307, 257, 30621], "temperature": 0.0, "avg_logprob": -0.1709946496146066, "compression_ratio": 1.4432432432432432, "no_speech_prob": 2.2115675164968707e-05}, {"id": 144, "seek": 101118, "start": 1011.18, "end": 1022.7399999999999, "text": " distribution of GrowlVM specifically for building Java native builds. So, and that's what Quarkis", "tokens": [7316, 295, 18476, 75, 53, 44, 4682, 337, 2390, 10745, 8470, 15182, 13, 407, 11, 293, 300, 311, 437, 2326, 809, 271], "temperature": 0.0, "avg_logprob": -0.15303878784179686, "compression_ratio": 1.5268817204301075, "no_speech_prob": 2.768113745332812e-06}, {"id": 145, "seek": 101118, "start": 1022.7399999999999, "end": 1029.8999999999999, "text": " uses to, for example, if I do a native build and I don't have GrowlVM installed on my local", "tokens": [4960, 281, 11, 337, 1365, 11, 498, 286, 360, 257, 8470, 1322, 293, 286, 500, 380, 362, 18476, 75, 53, 44, 8899, 322, 452, 2654], "temperature": 0.0, "avg_logprob": -0.15303878784179686, "compression_ratio": 1.5268817204301075, "no_speech_prob": 2.768113745332812e-06}, {"id": 146, "seek": 101118, "start": 1029.8999999999999, "end": 1038.3, "text": " machine, Quarkis will again pull down a container, it's really good at pulling down containers", "tokens": [3479, 11, 2326, 809, 271, 486, 797, 2235, 760, 257, 10129, 11, 309, 311, 534, 665, 412, 8407, 760, 17089], "temperature": 0.0, "avg_logprob": -0.15303878784179686, "compression_ratio": 1.5268817204301075, "no_speech_prob": 2.768113745332812e-06}, {"id": 147, "seek": 103830, "start": 1038.3, "end": 1043.6599999999999, "text": " to do a native build inside a container on your local machine. So again, then you don't", "tokens": [281, 360, 257, 8470, 1322, 1854, 257, 10129, 322, 428, 2654, 3479, 13, 407, 797, 11, 550, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.09432966684557728, "compression_ratio": 1.7673267326732673, "no_speech_prob": 8.0111622082768e-06}, {"id": 148, "seek": 103830, "start": 1043.6599999999999, "end": 1049.3799999999999, "text": " need to have GrowlVM installed and configured on your local machine. So it really tries", "tokens": [643, 281, 362, 18476, 75, 53, 44, 8899, 293, 30538, 322, 428, 2654, 3479, 13, 407, 309, 534, 9898], "temperature": 0.0, "avg_logprob": -0.09432966684557728, "compression_ratio": 1.7673267326732673, "no_speech_prob": 8.0111622082768e-06}, {"id": 149, "seek": 103830, "start": 1049.3799999999999, "end": 1057.82, "text": " to make, you know, your life as easy as possible and, you know, kind of have the benefits of,", "tokens": [281, 652, 11, 291, 458, 11, 428, 993, 382, 1858, 382, 1944, 293, 11, 291, 458, 11, 733, 295, 362, 264, 5311, 295, 11], "temperature": 0.0, "avg_logprob": -0.09432966684557728, "compression_ratio": 1.7673267326732673, "no_speech_prob": 8.0111622082768e-06}, {"id": 150, "seek": 103830, "start": 1057.82, "end": 1061.34, "text": " you know, a lot of the things. So if you're thinking of, you know, should I do a native", "tokens": [291, 458, 11, 257, 688, 295, 264, 721, 13, 407, 498, 291, 434, 1953, 295, 11, 291, 458, 11, 820, 286, 360, 257, 8470], "temperature": 0.0, "avg_logprob": -0.09432966684557728, "compression_ratio": 1.7673267326732673, "no_speech_prob": 8.0111622082768e-06}, {"id": 151, "seek": 106134, "start": 1061.34, "end": 1069.4199999999998, "text": " build or just run on the JVM? This is kind of an opinionated scoring. But, you know, if", "tokens": [1322, 420, 445, 1190, 322, 264, 508, 53, 44, 30, 639, 307, 733, 295, 364, 4800, 770, 22358, 13, 583, 11, 291, 458, 11, 498], "temperature": 0.0, "avg_logprob": -0.134749362343236, "compression_ratio": 1.5919282511210762, "no_speech_prob": 6.744590791640803e-06}, {"id": 152, "seek": 106134, "start": 1069.4199999999998, "end": 1075.1, "text": " you want the maximum developer joy, the, you know, the best and easiest monitoring peak", "tokens": [291, 528, 264, 6674, 10754, 6258, 11, 264, 11, 291, 458, 11, 264, 1151, 293, 12889, 11028, 10651], "temperature": 0.0, "avg_logprob": -0.134749362343236, "compression_ratio": 1.5919282511210762, "no_speech_prob": 6.744590791640803e-06}, {"id": 153, "seek": 106134, "start": 1075.1, "end": 1082.1799999999998, "text": " throughput and reduced max latency, then you want to run it on the JVM. If, for you, it's", "tokens": [44629, 293, 9212, 11469, 27043, 11, 550, 291, 528, 281, 1190, 309, 322, 264, 508, 53, 44, 13, 759, 11, 337, 291, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.134749362343236, "compression_ratio": 1.5919282511210762, "no_speech_prob": 6.744590791640803e-06}, {"id": 154, "seek": 106134, "start": 1082.1799999999998, "end": 1087.3799999999999, "text": " important to have the lowest memory footprint, a small packaging, and a very fast startup", "tokens": [1021, 281, 362, 264, 12437, 4675, 24222, 11, 257, 1359, 16836, 11, 293, 257, 588, 2370, 18578], "temperature": 0.0, "avg_logprob": -0.134749362343236, "compression_ratio": 1.5919282511210762, "no_speech_prob": 6.744590791640803e-06}, {"id": 155, "seek": 108738, "start": 1087.38, "end": 1093.1000000000001, "text": " time, then a native build is probably the way to go.", "tokens": [565, 11, 550, 257, 8470, 1322, 307, 1391, 264, 636, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.13926751685864996, "compression_ratio": 1.4472049689440993, "no_speech_prob": 8.663133485242724e-06}, {"id": 156, "seek": 108738, "start": 1093.1000000000001, "end": 1101.3000000000002, "text": " So what do you want to use? You know, what can you use Quarkis for? Virtually anything.", "tokens": [407, 437, 360, 291, 528, 281, 764, 30, 509, 458, 11, 437, 393, 291, 764, 2326, 809, 271, 337, 30, 19447, 671, 1340, 13], "temperature": 0.0, "avg_logprob": -0.13926751685864996, "compression_ratio": 1.4472049689440993, "no_speech_prob": 8.663133485242724e-06}, {"id": 157, "seek": 108738, "start": 1101.3000000000002, "end": 1108.66, "text": " So, you know, there are Quarkis-based Kubernetes operators. So there's an operator framework", "tokens": [407, 11, 291, 458, 11, 456, 366, 2326, 809, 271, 12, 6032, 23145, 19077, 13, 407, 456, 311, 364, 12973, 8388], "temperature": 0.0, "avg_logprob": -0.13926751685864996, "compression_ratio": 1.4472049689440993, "no_speech_prob": 8.663133485242724e-06}, {"id": 158, "seek": 110866, "start": 1108.66, "end": 1119.78, "text": " where you can create, you know, these automatic components in Kubernetes that manage resources", "tokens": [689, 291, 393, 1884, 11, 291, 458, 11, 613, 12509, 6677, 294, 23145, 300, 3067, 3593], "temperature": 0.0, "avg_logprob": -0.09993726015090942, "compression_ratio": 1.6385542168674698, "no_speech_prob": 6.437188403651817e-06}, {"id": 159, "seek": 110866, "start": 1119.78, "end": 1125.94, "text": " in Kubernetes. You can create GitHub actions with Quarkis. You can create, you know, just", "tokens": [294, 23145, 13, 509, 393, 1884, 23331, 5909, 365, 2326, 809, 271, 13, 509, 393, 1884, 11, 291, 458, 11, 445], "temperature": 0.0, "avg_logprob": -0.09993726015090942, "compression_ratio": 1.6385542168674698, "no_speech_prob": 6.437188403651817e-06}, {"id": 160, "seek": 110866, "start": 1125.94, "end": 1134.94, "text": " regular jobs. Yes, you can build traditional Java applications, even monoliths with it.", "tokens": [3890, 4782, 13, 1079, 11, 291, 393, 1322, 5164, 10745, 5821, 11, 754, 1108, 29131, 82, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.09993726015090942, "compression_ratio": 1.6385542168674698, "no_speech_prob": 6.437188403651817e-06}, {"id": 161, "seek": 113494, "start": 1134.94, "end": 1140.54, "text": " So this is, of course, the sweet spot of Quarkis is cloud-native applications, so event-driven", "tokens": [407, 341, 307, 11, 295, 1164, 11, 264, 3844, 4008, 295, 2326, 809, 271, 307, 4588, 12, 77, 1166, 5821, 11, 370, 2280, 12, 25456], "temperature": 0.0, "avg_logprob": -0.1620977528889974, "compression_ratio": 1.5568181818181819, "no_speech_prob": 4.936119694320951e-06}, {"id": 162, "seek": 113494, "start": 1140.54, "end": 1150.9, "text": " applications, reactive systems, microservices, and serverless and functions. So that's about", "tokens": [5821, 11, 28897, 3652, 11, 15547, 47480, 11, 293, 7154, 1832, 293, 6828, 13, 407, 300, 311, 466], "temperature": 0.0, "avg_logprob": -0.1620977528889974, "compression_ratio": 1.5568181818181819, "no_speech_prob": 4.936119694320951e-06}, {"id": 163, "seek": 113494, "start": 1150.9, "end": 1158.5, "text": " it for my session. So if you want to check out Quarkis more, developers.redhat.com has", "tokens": [309, 337, 452, 5481, 13, 407, 498, 291, 528, 281, 1520, 484, 2326, 809, 271, 544, 11, 8849, 13, 986, 15178, 13, 1112, 575], "temperature": 0.0, "avg_logprob": -0.1620977528889974, "compression_ratio": 1.5568181818181819, "no_speech_prob": 4.936119694320951e-06}, {"id": 164, "seek": 115850, "start": 1158.5, "end": 1166.14, "text": " a ton of resources on Quarkis, on a lot of developer stuff. This dn.dev slash Quarkis", "tokens": [257, 2952, 295, 3593, 322, 2326, 809, 271, 11, 322, 257, 688, 295, 10754, 1507, 13, 639, 274, 77, 13, 40343, 17330, 2326, 809, 271], "temperature": 0.0, "avg_logprob": -0.13652268261976644, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.165577214123914e-05}, {"id": 165, "seek": 115850, "start": 1166.14, "end": 1172.98, "text": " tutorial is just a, you know, kind of a nice, lightweight introduction to Quarkis where", "tokens": [7073, 307, 445, 257, 11, 291, 458, 11, 733, 295, 257, 1481, 11, 22052, 9339, 281, 2326, 809, 271, 689], "temperature": 0.0, "avg_logprob": -0.13652268261976644, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.165577214123914e-05}, {"id": 166, "seek": 115850, "start": 1172.98, "end": 1178.9, "text": " you can create an application from scratch and then, you know, kind of add some components", "tokens": [291, 393, 1884, 364, 3861, 490, 8459, 293, 550, 11, 291, 458, 11, 733, 295, 909, 512, 6677], "temperature": 0.0, "avg_logprob": -0.13652268261976644, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.165577214123914e-05}, {"id": 167, "seek": 117890, "start": 1178.9, "end": 1188.9, "text": " as you go. You add a database and then, you know, check out the live, the dev mode and", "tokens": [382, 291, 352, 13, 509, 909, 257, 8149, 293, 550, 11, 291, 458, 11, 1520, 484, 264, 1621, 11, 264, 1905, 4391, 293], "temperature": 0.0, "avg_logprob": -0.15176960241014711, "compression_ratio": 1.6026785714285714, "no_speech_prob": 5.591861281573074e-06}, {"id": 168, "seek": 117890, "start": 1188.9, "end": 1195.18, "text": " all that stuff. And, you know, so it's a pretty nice thing. Yeah. And like I said, if you", "tokens": [439, 300, 1507, 13, 400, 11, 291, 458, 11, 370, 309, 311, 257, 1238, 1481, 551, 13, 865, 13, 400, 411, 286, 848, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.15176960241014711, "compression_ratio": 1.6026785714285714, "no_speech_prob": 5.591861281573074e-06}, {"id": 169, "seek": 117890, "start": 1195.18, "end": 1202.5, "text": " want to keep up to date, you can follow me on Twitter or Macedon. I try to post interesting", "tokens": [528, 281, 1066, 493, 281, 4002, 11, 291, 393, 1524, 385, 322, 5794, 420, 45603, 266, 13, 286, 853, 281, 2183, 1880], "temperature": 0.0, "avg_logprob": -0.15176960241014711, "compression_ratio": 1.6026785714285714, "no_speech_prob": 5.591861281573074e-06}, {"id": 170, "seek": 117890, "start": 1202.5, "end": 1208.3000000000002, "text": " stuff, but I don't know if that's really true, but we'll see. All right. And that's it for", "tokens": [1507, 11, 457, 286, 500, 380, 458, 498, 300, 311, 534, 2074, 11, 457, 321, 603, 536, 13, 1057, 558, 13, 400, 300, 311, 309, 337], "temperature": 0.0, "avg_logprob": -0.15176960241014711, "compression_ratio": 1.6026785714285714, "no_speech_prob": 5.591861281573074e-06}, {"id": 171, "seek": 120830, "start": 1208.3, "end": 1215.3, "text": " me. Thank you. Any questions? Yes.", "tokens": [385, 13, 1044, 291, 13, 2639, 1651, 30, 1079, 13], "temperature": 0.0, "avg_logprob": -0.4210073607308524, "compression_ratio": 0.8095238095238095, "no_speech_prob": 0.00027701424551196396}, {"id": 172, "seek": 121530, "start": 1215.3, "end": 1239.1, "text": " One of the first slides you compared startup time and peak performance and, like, the crowd", "tokens": [1485, 295, 264, 700, 9788, 291, 5347, 18578, 565, 293, 10651, 3389, 293, 11, 411, 11, 264, 6919], "temperature": 0.0, "avg_logprob": -0.5440399430014871, "compression_ratio": 1.0963855421686748, "no_speech_prob": 0.0003794522781390697}, {"id": 173, "seek": 123910, "start": 1239.1, "end": 1248.6599999999999, "text": " time. I don't, yeah, I don't remember exactly the numbers on there. Yeah. So that, yeah,", "tokens": [565, 13, 286, 500, 380, 11, 1338, 11, 286, 500, 380, 1604, 2293, 264, 3547, 322, 456, 13, 865, 13, 407, 300, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.404089680424443, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.00023331475676968694}, {"id": 174, "seek": 123910, "start": 1248.6599999999999, "end": 1260.3, "text": " so the, yeah, definitely. So the peak throughput time, there was a slide about, you know, the", "tokens": [370, 264, 11, 1338, 11, 2138, 13, 407, 264, 10651, 44629, 565, 11, 456, 390, 257, 4137, 466, 11, 291, 458, 11, 264], "temperature": 0.0, "avg_logprob": -0.404089680424443, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.00023331475676968694}, {"id": 175, "seek": 126030, "start": 1260.3, "end": 1270.1, "text": " three graphs. So, yeah, I think with the native compilation, you're not going to have necessarily", "tokens": [1045, 24877, 13, 407, 11, 1338, 11, 286, 519, 365, 264, 8470, 40261, 11, 291, 434, 406, 516, 281, 362, 4725], "temperature": 0.0, "avg_logprob": -0.175346401375784, "compression_ratio": 1.5542857142857143, "no_speech_prob": 6.917870632605627e-05}, {"id": 176, "seek": 126030, "start": 1270.1, "end": 1278.62, "text": " more throughput than on the JVM, but you do get the startup time, you know, like the time", "tokens": [544, 44629, 813, 322, 264, 508, 53, 44, 11, 457, 291, 360, 483, 264, 18578, 565, 11, 291, 458, 11, 411, 264, 565], "temperature": 0.0, "avg_logprob": -0.175346401375784, "compression_ratio": 1.5542857142857143, "no_speech_prob": 6.917870632605627e-05}, {"id": 177, "seek": 126030, "start": 1278.62, "end": 1289.62, "text": " it takes to get to the maximum throughput is faster when you're, when you're native.", "tokens": [309, 2516, 281, 483, 281, 264, 6674, 44629, 307, 4663, 562, 291, 434, 11, 562, 291, 434, 8470, 13], "temperature": 0.0, "avg_logprob": -0.175346401375784, "compression_ratio": 1.5542857142857143, "no_speech_prob": 6.917870632605627e-05}, {"id": 178, "seek": 128962, "start": 1289.62, "end": 1296.62, "text": " Yeah. Yeah. Yeah. We can look at it later. Yeah. Yes.", "tokens": [865, 13, 865, 13, 865, 13, 492, 393, 574, 412, 309, 1780, 13, 865, 13, 1079, 13], "temperature": 0.0, "avg_logprob": -0.2786930175054641, "compression_ratio": 1.2325581395348837, "no_speech_prob": 0.002304116729646921}, {"id": 179, "seek": 129662, "start": 1296.62, "end": 1325.62, "text": " Yeah. That's it. Yeah.", "tokens": [865, 13, 663, 311, 309, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.2597574194272359, "compression_ratio": 0.7857142857142857, "no_speech_prob": 0.006234393455088139}, {"id": 180, "seek": 132562, "start": 1325.62, "end": 1331.86, "text": " Yeah. So the question was how easy is it, is it to migrate to Quarkus from, for example,", "tokens": [865, 13, 407, 264, 1168, 390, 577, 1858, 307, 309, 11, 307, 309, 281, 31821, 281, 2326, 809, 301, 490, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.17518832286198935, "compression_ratio": 1.6205357142857142, "no_speech_prob": 6.600985943805426e-05}, {"id": 181, "seek": 132562, "start": 1331.86, "end": 1341.9799999999998, "text": " spring boots? So Quarkus has spring compatibility extensions. And so that makes it relatively", "tokens": [5587, 15194, 30, 407, 2326, 809, 301, 575, 5587, 34237, 25129, 13, 400, 370, 300, 1669, 309, 7226], "temperature": 0.0, "avg_logprob": -0.17518832286198935, "compression_ratio": 1.6205357142857142, "no_speech_prob": 6.600985943805426e-05}, {"id": 182, "seek": 132562, "start": 1341.9799999999998, "end": 1349.5, "text": " easy because basically you're, for the most part, you won't have to change your code. You", "tokens": [1858, 570, 1936, 291, 434, 11, 337, 264, 881, 644, 11, 291, 1582, 380, 362, 281, 1319, 428, 3089, 13, 509], "temperature": 0.0, "avg_logprob": -0.17518832286198935, "compression_ratio": 1.6205357142857142, "no_speech_prob": 6.600985943805426e-05}, {"id": 183, "seek": 132562, "start": 1349.5, "end": 1354.26, "text": " just have to add the, you know, add the spring extensions. Of course, in your palm, you're", "tokens": [445, 362, 281, 909, 264, 11, 291, 458, 11, 909, 264, 5587, 25129, 13, 2720, 1164, 11, 294, 428, 17018, 11, 291, 434], "temperature": 0.0, "avg_logprob": -0.17518832286198935, "compression_ratio": 1.6205357142857142, "no_speech_prob": 6.600985943805426e-05}, {"id": 184, "seek": 135426, "start": 1354.26, "end": 1361.74, "text": " going to need to make some changes, but it's fairly straightforward. My colleague, Eric", "tokens": [516, 281, 643, 281, 652, 512, 2962, 11, 457, 309, 311, 6457, 15325, 13, 1222, 13532, 11, 9336], "temperature": 0.0, "avg_logprob": -0.20345884323120117, "compression_ratio": 1.5954545454545455, "no_speech_prob": 1.7494983694632538e-05}, {"id": 185, "seek": 135426, "start": 1361.74, "end": 1371.3799999999999, "text": " D'Andrea, he wrote a book on spring, let's say, Quarkus for spring developers. And he", "tokens": [413, 6, 5289, 12057, 11, 415, 4114, 257, 1446, 322, 5587, 11, 718, 311, 584, 11, 2326, 809, 301, 337, 5587, 8849, 13, 400, 415], "temperature": 0.0, "avg_logprob": -0.20345884323120117, "compression_ratio": 1.5954545454545455, "no_speech_prob": 1.7494983694632538e-05}, {"id": 186, "seek": 135426, "start": 1371.3799999999999, "end": 1378.58, "text": " does, he does talks too, but if you want on that developers.ridhat.com, you can find,", "tokens": [775, 11, 415, 775, 6686, 886, 11, 457, 498, 291, 528, 322, 300, 8849, 13, 8558, 15178, 13, 1112, 11, 291, 393, 915, 11], "temperature": 0.0, "avg_logprob": -0.20345884323120117, "compression_ratio": 1.5954545454545455, "no_speech_prob": 1.7494983694632538e-05}, {"id": 187, "seek": 135426, "start": 1378.58, "end": 1384.22, "text": " you know, there's a section about books and you can find that book. But it's, yeah, overall", "tokens": [291, 458, 11, 456, 311, 257, 3541, 466, 3642, 293, 291, 393, 915, 300, 1446, 13, 583, 309, 311, 11, 1338, 11, 4787], "temperature": 0.0, "avg_logprob": -0.20345884323120117, "compression_ratio": 1.5954545454545455, "no_speech_prob": 1.7494983694632538e-05}, {"id": 188, "seek": 138422, "start": 1384.22, "end": 1389.06, "text": " pretty, pretty straightforward. So like I said, there are extensions so that you can", "tokens": [1238, 11, 1238, 15325, 13, 407, 411, 286, 848, 11, 456, 366, 25129, 370, 300, 291, 393], "temperature": 0.0, "avg_logprob": -0.09763999063460553, "compression_ratio": 1.4530386740331491, "no_speech_prob": 1.1297252058284357e-05}, {"id": 189, "seek": 138422, "start": 1389.06, "end": 1399.14, "text": " keep using your spring annotations. Now, would I recommend you just migrating your application", "tokens": [1066, 1228, 428, 5587, 25339, 763, 13, 823, 11, 576, 286, 2748, 291, 445, 6186, 8754, 428, 3861], "temperature": 0.0, "avg_logprob": -0.09763999063460553, "compression_ratio": 1.4530386740331491, "no_speech_prob": 1.1297252058284357e-05}, {"id": 190, "seek": 138422, "start": 1399.14, "end": 1407.1000000000001, "text": " and keeping all your spring dependencies? Probably not. But it's kind of a nice way", "tokens": [293, 5145, 439, 428, 5587, 36606, 30, 9210, 406, 13, 583, 309, 311, 733, 295, 257, 1481, 636], "temperature": 0.0, "avg_logprob": -0.09763999063460553, "compression_ratio": 1.4530386740331491, "no_speech_prob": 1.1297252058284357e-05}, {"id": 191, "seek": 140710, "start": 1407.1, "end": 1415.6599999999999, "text": " to migrate without too much work and then afterwards maybe migrate further. All right.", "tokens": [281, 31821, 1553, 886, 709, 589, 293, 550, 10543, 1310, 31821, 3052, 13, 1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.3485768863133022, "compression_ratio": 1.1808510638297873, "no_speech_prob": 0.00014602327428292483}, {"id": 192, "seek": 140710, "start": 1415.6599999999999, "end": 1416.6599999999999, "text": " Any more questions? Yes.", "tokens": [2639, 544, 1651, 30, 1079, 13], "temperature": 0.0, "avg_logprob": -0.3485768863133022, "compression_ratio": 1.1808510638297873, "no_speech_prob": 0.00014602327428292483}, {"id": 193, "seek": 141666, "start": 1416.66, "end": 1442.78, "text": " So, so the question, if I understand correctly, right, so your, the question is, why, why", "tokens": [407, 11, 370, 264, 1168, 11, 498, 286, 1223, 8944, 11, 558, 11, 370, 428, 11, 264, 1168, 307, 11, 983, 11, 983], "temperature": 0.0, "avg_logprob": -0.307069495872215, "compression_ratio": 1.1710526315789473, "no_speech_prob": 0.0006436923868022859}, {"id": 194, "seek": 144278, "start": 1442.78, "end": 1466.78, "text": " should you use native compilation? Because on the JVM, you have all the kind of capabilities", "tokens": [820, 291, 764, 8470, 40261, 30, 1436, 322, 264, 508, 53, 44, 11, 291, 362, 439, 264, 733, 295, 10862], "temperature": 0.0, "avg_logprob": -0.192071795463562, "compression_ratio": 1.0823529411764705, "no_speech_prob": 3.940956594306044e-05}, {"id": 195, "seek": 146678, "start": 1466.78, "end": 1473.46, "text": " that the JVM brings, right? So in terms of, you know, garbage collection, in terms of", "tokens": [300, 264, 508, 53, 44, 5607, 11, 558, 30, 407, 294, 2115, 295, 11, 291, 458, 11, 14150, 5765, 11, 294, 2115, 295], "temperature": 0.0, "avg_logprob": -0.1911665926274565, "compression_ratio": 1.5964125560538116, "no_speech_prob": 4.2624240450095385e-05}, {"id": 196, "seek": 146678, "start": 1473.46, "end": 1483.3799999999999, "text": " throughput and everything, JVM is very optimized to do that. When you do a native build, the", "tokens": [44629, 293, 1203, 11, 508, 53, 44, 307, 588, 26941, 281, 360, 300, 13, 1133, 291, 360, 257, 8470, 1322, 11, 264], "temperature": 0.0, "avg_logprob": -0.1911665926274565, "compression_ratio": 1.5964125560538116, "no_speech_prob": 4.2624240450095385e-05}, {"id": 197, "seek": 146678, "start": 1483.3799999999999, "end": 1487.3799999999999, "text": " GralVM compiler is going to do kind of an opinionated approach of how to do your native", "tokens": [460, 2155, 53, 44, 31958, 307, 516, 281, 360, 733, 295, 364, 4800, 770, 3109, 295, 577, 281, 360, 428, 8470], "temperature": 0.0, "avg_logprob": -0.1911665926274565, "compression_ratio": 1.5964125560538116, "no_speech_prob": 4.2624240450095385e-05}, {"id": 198, "seek": 146678, "start": 1487.3799999999999, "end": 1492.06, "text": " build, but then that's also it. It's not going to be able to optimize afterwards like the", "tokens": [1322, 11, 457, 550, 300, 311, 611, 309, 13, 467, 311, 406, 516, 281, 312, 1075, 281, 19719, 10543, 411, 264], "temperature": 0.0, "avg_logprob": -0.1911665926274565, "compression_ratio": 1.5964125560538116, "no_speech_prob": 4.2624240450095385e-05}, {"id": 199, "seek": 149206, "start": 1492.06, "end": 1499.8999999999999, "text": " JVM does. So, kind of depends. Yeah. I think we're out of time. But if anybody has any", "tokens": [508, 53, 44, 775, 13, 407, 11, 733, 295, 5946, 13, 865, 13, 286, 519, 321, 434, 484, 295, 565, 13, 583, 498, 4472, 575, 604], "temperature": 0.0, "avg_logprob": -0.3352718940147987, "compression_ratio": 1.3191489361702127, "no_speech_prob": 3.760934851015918e-05}, {"id": 200, "seek": 149206, "start": 1499.8999999999999, "end": 1500.8999999999999, "text": " more questions?", "tokens": [544, 1651, 30], "temperature": 0.0, "avg_logprob": -0.3352718940147987, "compression_ratio": 1.3191489361702127, "no_speech_prob": 3.760934851015918e-05}, {"id": 201, "seek": 149206, "start": 1500.8999999999999, "end": 1501.8999999999999, "text": " Any questions, you'll be up there.", "tokens": [2639, 1651, 11, 291, 603, 312, 493, 456, 13], "temperature": 0.0, "avg_logprob": -0.3352718940147987, "compression_ratio": 1.3191489361702127, "no_speech_prob": 3.760934851015918e-05}, {"id": 202, "seek": 149206, "start": 1501.8999999999999, "end": 1502.8999999999999, "text": " Yeah, yeah.", "tokens": [865, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.3352718940147987, "compression_ratio": 1.3191489361702127, "no_speech_prob": 3.760934851015918e-05}, {"id": 203, "seek": 149206, "start": 1502.8999999999999, "end": 1503.8999999999999, "text": " Great. Thank you so much.", "tokens": [3769, 13, 1044, 291, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.3352718940147987, "compression_ratio": 1.3191489361702127, "no_speech_prob": 3.760934851015918e-05}, {"id": 204, "seek": 150390, "start": 1503.9, "end": 1524.14, "text": " All right. Thank you so much.", "tokens": [1057, 558, 13, 1044, 291, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.9308491547902426, "compression_ratio": 0.7837837837837838, "no_speech_prob": 0.00030829120078124106}], "language": "en"}