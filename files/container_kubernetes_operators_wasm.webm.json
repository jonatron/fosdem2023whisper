{"text": " So, hi everyone. I am Merlin and we're going to talk about lightweight Kubernetes operators with WebAssembly. So, basically, it's an attempt to lower the memory and CPU footprint of the Kubernetes control plane. So, I am Merlin. You can also say it in Dutch, Merlin. And I am a researcher at iMac and I teach at Gantt University. I'm also part of the Ubuntu Community Council. But right now, I'm here to talk about my research, which is service orchestration in the cloud and in the edge. And so, it's specifically the edge part of this research. Edge computing is becoming more and more popular. More and more people want to run their applications closer to end users on devices inside of users' homes, for example. And as a result, you have a lot of these people who are coming from a background of developing cloud applications and who now suddenly want to develop applications that run on devices, which are very low-powered. And they really like the development experience of the cloud. They like all the tools. They like the cloud-native experience with tools like Kubernetes, for example. But as most of you might know, Kubernetes isn't really a great fit for the edge. Kubernetes is incredibly resource-hungry. It really likes to gobble up RAM. It really likes to block all your CPUs. And there's a lot of components inside of the Kubernetes control plane that do this. Part of it is the kubelet that runs on every worker machine. Part of it is the container run times themselves or the API server. But what I'm going to talk about in this session, I think I have no idea why. I still have batteries, so I'm going to talk about operators specifically. Operators tend to take a lot of resources, eat up a lot of resources from your Kubernetes cluster. So first of all, operators, these are basically plugins to the Kubernetes control plane, which add additional functionality to the Kubernetes API. For example, it could add a resource to deploy and manage a MySQL cluster or it could add a resource to deploy and manage a SEF cluster, for example. And these operators, they are also really resource-hungry. And this is part of it is because they are long-running processes. So these processes, they see something change in your Kubernetes cluster. They want to do something with it and then write those changes back to the API server in order to manage the applications. But after that writing is done, these processes, they keep running because they keep listening for events from the Kubernetes API or even sometimes manually watching if some resource has changed. And so even if they're doing nothing, they're still running. A lot of them are written in Golang. And Golang really likes memory. They are running inside of containers. Most of them are running inside of separate containers. And they're basically sitting in RAM doing nothing, eating up that RAM. And so this is an issue if you want to run Kubernetes in the edge on devices which have like 512 megabytes of RAM. These operators are basically unusable in situations like that. So how could we solve this? One of the ways that you could solve this is that we think we can solve this is by using WebAssembly and the WebAssembly system interface. And so yes, really, we're trying to lower the footprint of Kubernetes by taking a web technology and putting it inside of Kubernetes. If you don't believe me, this is a tweet from one of the co-founders of Docker who basically said like if WebAssembly and the WebAssembly system interface would have existed in 2008, they wouldn't have needed to create Docker. It's a very interesting technology which we think is a very good fit to solve this issue in Kubernetes. So what is WebAssembly created originally for the browser? It's basically a binary code format. You compile your applications to WebAssembly instead of compiling them to x86 or to ARM. And then this code runs inside of a runtime. You could call it a very lightweight virtual machine. It runs in your browser, it runs in the Node.js runtime, but there's also a whole bunch of new purpose built, very lightweight runtimes such as wasm time, the one that we're using right now. And the WebAssembly system interface is basically a syscall interface. So WebAssembly is your binary, but it doesn't have access to anything. And then the system interface is a syscall interface. So that's an interface that it uses to open files, open sockets, start new threads and stuff like that. And so if you combine these two, you basically have a very lightweight, super fast sandbox. And so the result of running these operators inside of WebAssembly containers is that they use a lot less RAM. So here on this slide at the top, you see 100 operators running as Docker containers. Then you have 100 operators running as WebAssembly containers and then 100 running just on bare metal. So we're not reaching the performance of bare metal. There's still some overhead. However, we're compared to the Docker containers like we're getting a lot closer than that. As an advantage that we didn't see coming initially, but they also have a lot less latency. They run a lot quicker. This also shows the difference between Golang operators and Rust operators. So obviously, Rust will have a lot less latency and a lot less latency distribution because it's not a garbage collected language. However, we were surprised to see that running them inside of WebAssembly gave them even better, even more consistent latency. So how did we do this? We basically work with a client server model or like a parent operator and a child operator. The parent operator, it is a WebAssembly runtime with a bunch of additions to it in order to support running operators inside of that runtime. And it watches the Kubernetes resources in the name of the operators running inside of it. So the operators don't have to keep running to watch it. They can just shut down when there's nothing to do. And the parent operator will call them once there is a change to process. The child operators, those are where the actual operators run inside. And the interesting part is that they are just regular operators compiled to WebAssembly using a patched version of the Kubernetes SDK. So in the future, this will probably make it possible to just take a regular Kubernetes operator, compile it to WebAssembly, and then use it in this system. Right now, we only support Rust because Rust support for WebAssembly is very good, Golang support for WebAssembly is iffy. And we have a patched version of Kube RS, a Kubernetes SDK, to then contact the parent operator instead of contacting the Kubernetes API itself. So how does this loading and unloading work? This is the WebAssembly engine. This is basically just wasn't time, the WebAssembly runtime. And in here is your client operator, your child operator is running. Once the child operator wants to contact the Kubernetes API server, it does a syscall. We extended the WebAssembly system interface to add a few syscalls to support the scenario. And this syscall goes through to the parent operator and the parent operator is the one who actually contacts the Kubernetes API. Once these calls are finished, the parent operator, it contacts the child operator back again in order to give it the result of these calls. And if the child operator is not doing anything, the parent operator shuts down the child operator. And once there changes to process, it starts it up again. And so the results I showed you on the first slides, those results are just not unloading anything. Just running Kubernetes operators inside of WebAssembly. So these results are what you get when you have a worst case scenario for unloading operators when they're not doing anything. And so we see that in a worst case scenario, they still use 50% less RAM because they're constantly being unloaded and then reloaded again once there's changes to process. However, this is obviously at the cost of latency. Even though WebAssembly, it starts incredibly fast. It has latency that just can't be compared to Docker containers for starting applications. There is still some latency to start a WebAssembly application. And so this compounds in the worst case scenario of like 100 operators chaining themselves up to 12 seconds, which is an issue. So what are we doing now? So we have this basic proof of concept to show that this seems to be a very good approach to lower the footprint of the Kubernetes control plane. And we want to do more with this. Currently, we're improving the build tools and we're making more realistic tests. All the tests we did right now were a worst case scenario of operators constantly doing stuff. However, in the real world, most operators don't do anything most of the time. So we're creating more realistic tests to see what these operators, what the performance benefits are for real workloads. We're also working on predictive unloading so that if we know that an operator is going to have to run again in a few milliseconds, we don't unload it because it's better to just keep it running. In the future, we want to work on better support for controllers that wake periodically. So right now, we see that a lot of production controllers actually wake periodically every five seconds or every 20 seconds in order to manually check resources in the Kubernetes API because some of those resources, they can't work with callbacks. So we are trying to figure out a way to actually put that functionality into the host operator itself so that even when you're watching resources that don't support event-based APIs, the operator is still sleeping as long as there's nothing to process. And we're also really interested in upstreaming and standardizing this. We have patches for Kube RS. We have an extension for the WebAssembly system interface. It would be very interesting to see if there's people in the ecosystem who are interested in this and support for Golang, although this will probably not be work that we're doing, we'll just wait until Golang is better supported in WebAssembly. So I have to thank the developers. Francesco is somewhere here in the audience. We started from a prototype created by Francesco and Marcus, which runs Kubernetes controllers inside of WebAssembly. And we refactored it to use wasm time and we added the unloading mechanism. This was done by Tim as part of his master's thesis. And right now, student Kevin is working on it also as part of his master's thesis to improve the build system so that it's much easier to get started with it and to add predictive unloading and more realistic benchmarks to have a better idea of what is the performance for actual production controllers. So the main reason I am here today is to say like, hey, we have a really cool proof of concept, which solves an issue that we have been having. Is this solving an issue for other people in the community? And are you interested in working together on this? If you're interested in working together on this, please get in touch. If you're a student yourself and you want to do like an internship or a master's thesis working on this, we have a lot of opportunities, same for a PhD. So please contact us, send me an email to see what we can do for you and how we could collaborate. So this is the end of my presentation and there's now room for questions. I also put the link to part of our code here. I think this GitHub repo also links to the other repositories that you need. Okay, we can take a couple of questions. So why was he so fast and why it is not possible to do something similar with JVM? So definitely, JVM and WebAssembly are very similar in that regard and a lot of people, they position WebAssembly as being like a more cross-platform and a more cross-language version of the JVM. But if you're only interested in Java and Java-based languages, then the Java runtime itself is a very good alternative to this. Okay, there was another one over here, right? Yeah. So if I understood correctly, you are deploying your operators outside containers and that makes them much more efficient. But, I mean, besides the security aspects, when you deploy in containers and Kubernetes, you have many other things that you can set, like resource limits, but also things like post-topology spread constraints and notations to make sure that some processes are running on specific nodes and so on. How can you address that with WebAssembly? Because you cannot package then your operator like any other workload that you deploy in Kubernetes. Yeah, so it's a very good question. So one of the benchmarks was just running the operators on bare metal, but that's not actually what I'm proposing. It was just to see, like, what is the absolute maximum amount of performance we could get out of this. Our plan is to run each operator inside of its own container. It's just a WebAssembly plus WebAssembly system interface container instead of a Docker container. And so most of the security profile and stuff like that that you have with Docker containers is very similar with WebAssembly. Some would even argue that it's more secure in WebAssembly because it has a much smaller API footprint and it has some of the best teams working on it to make sure it's secure for the browser. Moreover, the code that is running in these WebAssembly containers in my proof of concept, this is control plane code. So this is code that the system administrator selected, like, okay, yeah, I want this specific system administration code to manage my applications. And so in that sense, there's also, like, a higher level of trust put into the code, which means that, like, things like attacks and stuff like that, there's less of a risk to it. But even then, like, it's still running inside of containers. So one of the most important scalability aspects of Kubernetes controllers is the watch-based cache, right? So without it, the API server wouldn't be able to handle all the long pulling and so on. And it's also one of the most memory-intensive aspects of Kubernetes controllers. I was wondering in your memory benchmarks if you were cutting down on this watch-based aspect, or if it is still included in the parent operator. So for example, is the parent operator caching as a proxy for the child operators? Is that the case? Yeah, that's what's happening, basically. The parent operator is where the caches are, yeah.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.24, "text": " So, hi everyone. I am Merlin and we're going to talk about lightweight Kubernetes operators", "tokens": [407, 11, 4879, 1518, 13, 286, 669, 6124, 5045, 293, 321, 434, 516, 281, 751, 466, 22052, 23145, 19077], "temperature": 0.0, "avg_logprob": -0.22248188654581705, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.47827017307281494}, {"id": 1, "seek": 0, "start": 11.24, "end": 19.52, "text": " with WebAssembly. So, basically, it's an attempt to lower the memory and CPU footprint of the", "tokens": [365, 9573, 10884, 19160, 13, 407, 11, 1936, 11, 309, 311, 364, 5217, 281, 3126, 264, 4675, 293, 13199, 24222, 295, 264], "temperature": 0.0, "avg_logprob": -0.22248188654581705, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.47827017307281494}, {"id": 2, "seek": 0, "start": 19.52, "end": 28.16, "text": " Kubernetes control plane. So, I am Merlin. You can also say it in Dutch, Merlin. And", "tokens": [23145, 1969, 5720, 13, 407, 11, 286, 669, 6124, 5045, 13, 509, 393, 611, 584, 309, 294, 15719, 11, 6124, 5045, 13, 400], "temperature": 0.0, "avg_logprob": -0.22248188654581705, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.47827017307281494}, {"id": 3, "seek": 2816, "start": 28.16, "end": 34.52, "text": " I am a researcher at iMac and I teach at Gantt University. I'm also part of the Ubuntu", "tokens": [286, 669, 257, 21751, 412, 741, 34355, 293, 286, 2924, 412, 460, 394, 83, 3535, 13, 286, 478, 611, 644, 295, 264, 30230, 45605], "temperature": 0.0, "avg_logprob": -0.14323878556155087, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.0006940682069398463}, {"id": 4, "seek": 2816, "start": 34.52, "end": 40.480000000000004, "text": " Community Council. But right now, I'm here to talk about my research, which is service", "tokens": [10421, 7076, 13, 583, 558, 586, 11, 286, 478, 510, 281, 751, 466, 452, 2132, 11, 597, 307, 2643], "temperature": 0.0, "avg_logprob": -0.14323878556155087, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.0006940682069398463}, {"id": 5, "seek": 2816, "start": 40.480000000000004, "end": 46.879999999999995, "text": " orchestration in the cloud and in the edge. And so, it's specifically the edge part of", "tokens": [14161, 2405, 294, 264, 4588, 293, 294, 264, 4691, 13, 400, 370, 11, 309, 311, 4682, 264, 4691, 644, 295], "temperature": 0.0, "avg_logprob": -0.14323878556155087, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.0006940682069398463}, {"id": 6, "seek": 2816, "start": 46.879999999999995, "end": 52.519999999999996, "text": " this research. Edge computing is becoming more and more popular. More and more people", "tokens": [341, 2132, 13, 19328, 15866, 307, 5617, 544, 293, 544, 3743, 13, 5048, 293, 544, 561], "temperature": 0.0, "avg_logprob": -0.14323878556155087, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.0006940682069398463}, {"id": 7, "seek": 5252, "start": 52.52, "end": 59.28, "text": " want to run their applications closer to end users on devices inside of users' homes,", "tokens": [528, 281, 1190, 641, 5821, 4966, 281, 917, 5022, 322, 5759, 1854, 295, 5022, 6, 7388, 11], "temperature": 0.0, "avg_logprob": -0.10631919812552537, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.0006878873100504279}, {"id": 8, "seek": 5252, "start": 59.28, "end": 65.4, "text": " for example. And as a result, you have a lot of these people who are coming from a background", "tokens": [337, 1365, 13, 400, 382, 257, 1874, 11, 291, 362, 257, 688, 295, 613, 561, 567, 366, 1348, 490, 257, 3678], "temperature": 0.0, "avg_logprob": -0.10631919812552537, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.0006878873100504279}, {"id": 9, "seek": 5252, "start": 65.4, "end": 70.32000000000001, "text": " of developing cloud applications and who now suddenly want to develop applications that", "tokens": [295, 6416, 4588, 5821, 293, 567, 586, 5800, 528, 281, 1499, 5821, 300], "temperature": 0.0, "avg_logprob": -0.10631919812552537, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.0006878873100504279}, {"id": 10, "seek": 5252, "start": 70.32000000000001, "end": 76.96000000000001, "text": " run on devices, which are very low-powered. And they really like the development experience", "tokens": [1190, 322, 5759, 11, 597, 366, 588, 2295, 12, 27178, 13, 400, 436, 534, 411, 264, 3250, 1752], "temperature": 0.0, "avg_logprob": -0.10631919812552537, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.0006878873100504279}, {"id": 11, "seek": 7696, "start": 76.96, "end": 82.44, "text": " of the cloud. They like all the tools. They like the cloud-native experience with tools", "tokens": [295, 264, 4588, 13, 814, 411, 439, 264, 3873, 13, 814, 411, 264, 4588, 12, 77, 1166, 1752, 365, 3873], "temperature": 0.0, "avg_logprob": -0.08539039486057155, "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.0003090797399636358}, {"id": 12, "seek": 7696, "start": 82.44, "end": 88.67999999999999, "text": " like Kubernetes, for example. But as most of you might know, Kubernetes isn't really", "tokens": [411, 23145, 11, 337, 1365, 13, 583, 382, 881, 295, 291, 1062, 458, 11, 23145, 1943, 380, 534], "temperature": 0.0, "avg_logprob": -0.08539039486057155, "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.0003090797399636358}, {"id": 13, "seek": 7696, "start": 88.67999999999999, "end": 96.6, "text": " a great fit for the edge. Kubernetes is incredibly resource-hungry. It really likes to gobble", "tokens": [257, 869, 3318, 337, 264, 4691, 13, 23145, 307, 6252, 7684, 12, 71, 1063, 627, 13, 467, 534, 5902, 281, 352, 10387], "temperature": 0.0, "avg_logprob": -0.08539039486057155, "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.0003090797399636358}, {"id": 14, "seek": 7696, "start": 96.6, "end": 103.75999999999999, "text": " up RAM. It really likes to block all your CPUs. And there's a lot of components inside", "tokens": [493, 14561, 13, 467, 534, 5902, 281, 3461, 439, 428, 13199, 82, 13, 400, 456, 311, 257, 688, 295, 6677, 1854], "temperature": 0.0, "avg_logprob": -0.08539039486057155, "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.0003090797399636358}, {"id": 15, "seek": 10376, "start": 103.76, "end": 110.32000000000001, "text": " of the Kubernetes control plane that do this. Part of it is the kubelet that runs on every", "tokens": [295, 264, 23145, 1969, 5720, 300, 360, 341, 13, 4100, 295, 309, 307, 264, 350, 836, 15966, 300, 6676, 322, 633], "temperature": 0.0, "avg_logprob": -0.19172293703321, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.0003563333593774587}, {"id": 16, "seek": 10376, "start": 110.32000000000001, "end": 117.08000000000001, "text": " worker machine. Part of it is the container run times themselves or the API server. But", "tokens": [11346, 3479, 13, 4100, 295, 309, 307, 264, 10129, 1190, 1413, 2969, 420, 264, 9362, 7154, 13, 583], "temperature": 0.0, "avg_logprob": -0.19172293703321, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.0003563333593774587}, {"id": 17, "seek": 10376, "start": 117.08000000000001, "end": 131.44, "text": " what I'm going to talk about in this session, I think I have no idea why. I still have batteries,", "tokens": [437, 286, 478, 516, 281, 751, 466, 294, 341, 5481, 11, 286, 519, 286, 362, 572, 1558, 983, 13, 286, 920, 362, 13070, 11], "temperature": 0.0, "avg_logprob": -0.19172293703321, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.0003563333593774587}, {"id": 18, "seek": 13144, "start": 131.44, "end": 140.04, "text": " so I'm going to talk about operators specifically. Operators tend to take a lot of resources,", "tokens": [370, 286, 478, 516, 281, 751, 466, 19077, 4682, 13, 12480, 3391, 3928, 281, 747, 257, 688, 295, 3593, 11], "temperature": 0.0, "avg_logprob": -0.143887740809743, "compression_ratio": 1.6529680365296804, "no_speech_prob": 9.372672502649948e-05}, {"id": 19, "seek": 13144, "start": 140.04, "end": 146.72, "text": " eat up a lot of resources from your Kubernetes cluster. So first of all, operators, these", "tokens": [1862, 493, 257, 688, 295, 3593, 490, 428, 23145, 13630, 13, 407, 700, 295, 439, 11, 19077, 11, 613], "temperature": 0.0, "avg_logprob": -0.143887740809743, "compression_ratio": 1.6529680365296804, "no_speech_prob": 9.372672502649948e-05}, {"id": 20, "seek": 13144, "start": 146.72, "end": 153.2, "text": " are basically plugins to the Kubernetes control plane, which add additional functionality", "tokens": [366, 1936, 33759, 281, 264, 23145, 1969, 5720, 11, 597, 909, 4497, 14980], "temperature": 0.0, "avg_logprob": -0.143887740809743, "compression_ratio": 1.6529680365296804, "no_speech_prob": 9.372672502649948e-05}, {"id": 21, "seek": 13144, "start": 153.2, "end": 159.48, "text": " to the Kubernetes API. For example, it could add a resource to deploy and manage a MySQL", "tokens": [281, 264, 23145, 9362, 13, 1171, 1365, 11, 309, 727, 909, 257, 7684, 281, 7274, 293, 3067, 257, 1222, 39934], "temperature": 0.0, "avg_logprob": -0.143887740809743, "compression_ratio": 1.6529680365296804, "no_speech_prob": 9.372672502649948e-05}, {"id": 22, "seek": 15948, "start": 159.48, "end": 168.32, "text": " cluster or it could add a resource to deploy and manage a SEF cluster, for example. And", "tokens": [13630, 420, 309, 727, 909, 257, 7684, 281, 7274, 293, 3067, 257, 10269, 37, 13630, 11, 337, 1365, 13, 400], "temperature": 0.0, "avg_logprob": -0.17096299138562432, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0001197119927383028}, {"id": 23, "seek": 15948, "start": 168.32, "end": 175.28, "text": " these operators, they are also really resource-hungry. And this is part of it is because they are", "tokens": [613, 19077, 11, 436, 366, 611, 534, 7684, 12, 71, 1063, 627, 13, 400, 341, 307, 644, 295, 309, 307, 570, 436, 366], "temperature": 0.0, "avg_logprob": -0.17096299138562432, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0001197119927383028}, {"id": 24, "seek": 15948, "start": 175.28, "end": 180.92, "text": " long-running processes. So these processes, they see something change in your Kubernetes", "tokens": [938, 12, 45482, 7555, 13, 407, 613, 7555, 11, 436, 536, 746, 1319, 294, 428, 23145], "temperature": 0.0, "avg_logprob": -0.17096299138562432, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0001197119927383028}, {"id": 25, "seek": 15948, "start": 180.92, "end": 185.2, "text": " cluster. They want to do something with it and then write those changes back to the API", "tokens": [13630, 13, 814, 528, 281, 360, 746, 365, 309, 293, 550, 2464, 729, 2962, 646, 281, 264, 9362], "temperature": 0.0, "avg_logprob": -0.17096299138562432, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0001197119927383028}, {"id": 26, "seek": 18520, "start": 185.2, "end": 190.48, "text": " server in order to manage the applications. But after that writing is done, these processes,", "tokens": [7154, 294, 1668, 281, 3067, 264, 5821, 13, 583, 934, 300, 3579, 307, 1096, 11, 613, 7555, 11], "temperature": 0.0, "avg_logprob": -0.11118489265441894, "compression_ratio": 1.7451737451737452, "no_speech_prob": 0.00013505479728337377}, {"id": 27, "seek": 18520, "start": 190.48, "end": 196.51999999999998, "text": " they keep running because they keep listening for events from the Kubernetes API or even", "tokens": [436, 1066, 2614, 570, 436, 1066, 4764, 337, 3931, 490, 264, 23145, 9362, 420, 754], "temperature": 0.0, "avg_logprob": -0.11118489265441894, "compression_ratio": 1.7451737451737452, "no_speech_prob": 0.00013505479728337377}, {"id": 28, "seek": 18520, "start": 196.51999999999998, "end": 202.48, "text": " sometimes manually watching if some resource has changed. And so even if they're doing", "tokens": [2171, 16945, 1976, 498, 512, 7684, 575, 3105, 13, 400, 370, 754, 498, 436, 434, 884], "temperature": 0.0, "avg_logprob": -0.11118489265441894, "compression_ratio": 1.7451737451737452, "no_speech_prob": 0.00013505479728337377}, {"id": 29, "seek": 18520, "start": 202.48, "end": 207.88, "text": " nothing, they're still running. A lot of them are written in Golang. And Golang really", "tokens": [1825, 11, 436, 434, 920, 2614, 13, 316, 688, 295, 552, 366, 3720, 294, 36319, 656, 13, 400, 36319, 656, 534], "temperature": 0.0, "avg_logprob": -0.11118489265441894, "compression_ratio": 1.7451737451737452, "no_speech_prob": 0.00013505479728337377}, {"id": 30, "seek": 18520, "start": 207.88, "end": 214.07999999999998, "text": " likes memory. They are running inside of containers. Most of them are running inside of separate", "tokens": [5902, 4675, 13, 814, 366, 2614, 1854, 295, 17089, 13, 4534, 295, 552, 366, 2614, 1854, 295, 4994], "temperature": 0.0, "avg_logprob": -0.11118489265441894, "compression_ratio": 1.7451737451737452, "no_speech_prob": 0.00013505479728337377}, {"id": 31, "seek": 21408, "start": 214.08, "end": 220.88000000000002, "text": " containers. And they're basically sitting in RAM doing nothing, eating up that RAM.", "tokens": [17089, 13, 400, 436, 434, 1936, 3798, 294, 14561, 884, 1825, 11, 3936, 493, 300, 14561, 13], "temperature": 0.0, "avg_logprob": -0.11127375421069917, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.00024220571503974497}, {"id": 32, "seek": 21408, "start": 220.88000000000002, "end": 225.64000000000001, "text": " And so this is an issue if you want to run Kubernetes in the edge on devices which have", "tokens": [400, 370, 341, 307, 364, 2734, 498, 291, 528, 281, 1190, 23145, 294, 264, 4691, 322, 5759, 597, 362], "temperature": 0.0, "avg_logprob": -0.11127375421069917, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.00024220571503974497}, {"id": 33, "seek": 21408, "start": 225.64000000000001, "end": 235.16000000000003, "text": " like 512 megabytes of RAM. These operators are basically unusable in situations like", "tokens": [411, 1025, 4762, 10816, 24538, 295, 14561, 13, 1981, 19077, 366, 1936, 10054, 712, 294, 6851, 411], "temperature": 0.0, "avg_logprob": -0.11127375421069917, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.00024220571503974497}, {"id": 34, "seek": 21408, "start": 235.16000000000003, "end": 242.48000000000002, "text": " that. So how could we solve this? One of the ways that you could solve this is that we", "tokens": [300, 13, 407, 577, 727, 321, 5039, 341, 30, 1485, 295, 264, 2098, 300, 291, 727, 5039, 341, 307, 300, 321], "temperature": 0.0, "avg_logprob": -0.11127375421069917, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.00024220571503974497}, {"id": 35, "seek": 24248, "start": 242.48, "end": 248.2, "text": " think we can solve this is by using WebAssembly and the WebAssembly system interface. And so", "tokens": [519, 321, 393, 5039, 341, 307, 538, 1228, 9573, 10884, 19160, 293, 264, 9573, 10884, 19160, 1185, 9226, 13, 400, 370], "temperature": 0.0, "avg_logprob": -0.10775262376536494, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00018566922517493367}, {"id": 36, "seek": 24248, "start": 248.2, "end": 254.92, "text": " yes, really, we're trying to lower the footprint of Kubernetes by taking a web technology and", "tokens": [2086, 11, 534, 11, 321, 434, 1382, 281, 3126, 264, 24222, 295, 23145, 538, 1940, 257, 3670, 2899, 293], "temperature": 0.0, "avg_logprob": -0.10775262376536494, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00018566922517493367}, {"id": 37, "seek": 24248, "start": 254.92, "end": 261.4, "text": " putting it inside of Kubernetes. If you don't believe me, this is a tweet from one of the", "tokens": [3372, 309, 1854, 295, 23145, 13, 759, 291, 500, 380, 1697, 385, 11, 341, 307, 257, 15258, 490, 472, 295, 264], "temperature": 0.0, "avg_logprob": -0.10775262376536494, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00018566922517493367}, {"id": 38, "seek": 24248, "start": 261.4, "end": 267.03999999999996, "text": " co-founders of Docker who basically said like if WebAssembly and the WebAssembly system interface", "tokens": [598, 12, 17493, 433, 295, 33772, 567, 1936, 848, 411, 498, 9573, 10884, 19160, 293, 264, 9573, 10884, 19160, 1185, 9226], "temperature": 0.0, "avg_logprob": -0.10775262376536494, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00018566922517493367}, {"id": 39, "seek": 26704, "start": 267.04, "end": 275.64000000000004, "text": " would have existed in 2008, they wouldn't have needed to create Docker. It's a very interesting", "tokens": [576, 362, 13135, 294, 10389, 11, 436, 2759, 380, 362, 2978, 281, 1884, 33772, 13, 467, 311, 257, 588, 1880], "temperature": 0.0, "avg_logprob": -0.09765670516274193, "compression_ratio": 1.4292929292929293, "no_speech_prob": 0.00010304444003850222}, {"id": 40, "seek": 26704, "start": 275.64000000000004, "end": 282.84000000000003, "text": " technology which we think is a very good fit to solve this issue in Kubernetes. So what", "tokens": [2899, 597, 321, 519, 307, 257, 588, 665, 3318, 281, 5039, 341, 2734, 294, 23145, 13, 407, 437], "temperature": 0.0, "avg_logprob": -0.09765670516274193, "compression_ratio": 1.4292929292929293, "no_speech_prob": 0.00010304444003850222}, {"id": 41, "seek": 26704, "start": 282.84000000000003, "end": 290.68, "text": " is WebAssembly created originally for the browser? It's basically a binary code format. You compile", "tokens": [307, 9573, 10884, 19160, 2942, 7993, 337, 264, 11185, 30, 467, 311, 1936, 257, 17434, 3089, 7877, 13, 509, 31413], "temperature": 0.0, "avg_logprob": -0.09765670516274193, "compression_ratio": 1.4292929292929293, "no_speech_prob": 0.00010304444003850222}, {"id": 42, "seek": 29068, "start": 290.68, "end": 297.64, "text": " your applications to WebAssembly instead of compiling them to x86 or to ARM. And then this", "tokens": [428, 5821, 281, 9573, 10884, 19160, 2602, 295, 715, 4883, 552, 281, 2031, 22193, 420, 281, 45209, 13, 400, 550, 341], "temperature": 0.0, "avg_logprob": -0.16109824933503802, "compression_ratio": 1.5948275862068966, "no_speech_prob": 7.968757563503459e-05}, {"id": 43, "seek": 29068, "start": 297.64, "end": 304.2, "text": " code runs inside of a runtime. You could call it a very lightweight virtual machine. It runs", "tokens": [3089, 6676, 1854, 295, 257, 34474, 13, 509, 727, 818, 309, 257, 588, 22052, 6374, 3479, 13, 467, 6676], "temperature": 0.0, "avg_logprob": -0.16109824933503802, "compression_ratio": 1.5948275862068966, "no_speech_prob": 7.968757563503459e-05}, {"id": 44, "seek": 29068, "start": 304.2, "end": 310.12, "text": " in your browser, it runs in the Node.js runtime, but there's also a whole bunch of new purpose", "tokens": [294, 428, 11185, 11, 309, 6676, 294, 264, 38640, 13, 25530, 34474, 11, 457, 456, 311, 611, 257, 1379, 3840, 295, 777, 4334], "temperature": 0.0, "avg_logprob": -0.16109824933503802, "compression_ratio": 1.5948275862068966, "no_speech_prob": 7.968757563503459e-05}, {"id": 45, "seek": 29068, "start": 310.12, "end": 317.76, "text": " built, very lightweight runtimes such as wasm time, the one that we're using right now. And", "tokens": [3094, 11, 588, 22052, 49435, 1532, 1270, 382, 390, 76, 565, 11, 264, 472, 300, 321, 434, 1228, 558, 586, 13, 400], "temperature": 0.0, "avg_logprob": -0.16109824933503802, "compression_ratio": 1.5948275862068966, "no_speech_prob": 7.968757563503459e-05}, {"id": 46, "seek": 31776, "start": 317.76, "end": 324.12, "text": " the WebAssembly system interface is basically a syscall interface. So WebAssembly is your binary,", "tokens": [264, 9573, 10884, 19160, 1185, 9226, 307, 1936, 257, 262, 749, 45459, 9226, 13, 407, 9573, 10884, 19160, 307, 428, 17434, 11], "temperature": 0.0, "avg_logprob": -0.13689521018494952, "compression_ratio": 1.8349514563106797, "no_speech_prob": 7.609462772961706e-05}, {"id": 47, "seek": 31776, "start": 324.12, "end": 329.68, "text": " but it doesn't have access to anything. And then the system interface is a syscall interface. So", "tokens": [457, 309, 1177, 380, 362, 2105, 281, 1340, 13, 400, 550, 264, 1185, 9226, 307, 257, 262, 749, 45459, 9226, 13, 407], "temperature": 0.0, "avg_logprob": -0.13689521018494952, "compression_ratio": 1.8349514563106797, "no_speech_prob": 7.609462772961706e-05}, {"id": 48, "seek": 31776, "start": 329.68, "end": 335.4, "text": " that's an interface that it uses to open files, open sockets, start new threads and stuff like", "tokens": [300, 311, 364, 9226, 300, 309, 4960, 281, 1269, 7098, 11, 1269, 370, 11984, 11, 722, 777, 19314, 293, 1507, 411], "temperature": 0.0, "avg_logprob": -0.13689521018494952, "compression_ratio": 1.8349514563106797, "no_speech_prob": 7.609462772961706e-05}, {"id": 49, "seek": 31776, "start": 335.4, "end": 341.2, "text": " that. And so if you combine these two, you basically have a very lightweight, super fast", "tokens": [300, 13, 400, 370, 498, 291, 10432, 613, 732, 11, 291, 1936, 362, 257, 588, 22052, 11, 1687, 2370], "temperature": 0.0, "avg_logprob": -0.13689521018494952, "compression_ratio": 1.8349514563106797, "no_speech_prob": 7.609462772961706e-05}, {"id": 50, "seek": 34120, "start": 341.2, "end": 351.08, "text": " sandbox. And so the result of running these operators inside of WebAssembly containers is", "tokens": [42115, 13, 400, 370, 264, 1874, 295, 2614, 613, 19077, 1854, 295, 9573, 10884, 19160, 17089, 307], "temperature": 0.0, "avg_logprob": -0.13318424224853515, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0001700138091109693}, {"id": 51, "seek": 34120, "start": 351.08, "end": 359.32, "text": " that they use a lot less RAM. So here on this slide at the top, you see 100 operators running as", "tokens": [300, 436, 764, 257, 688, 1570, 14561, 13, 407, 510, 322, 341, 4137, 412, 264, 1192, 11, 291, 536, 2319, 19077, 2614, 382], "temperature": 0.0, "avg_logprob": -0.13318424224853515, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0001700138091109693}, {"id": 52, "seek": 34120, "start": 359.32, "end": 366.91999999999996, "text": " Docker containers. Then you have 100 operators running as WebAssembly containers and then 100", "tokens": [33772, 17089, 13, 1396, 291, 362, 2319, 19077, 2614, 382, 9573, 10884, 19160, 17089, 293, 550, 2319], "temperature": 0.0, "avg_logprob": -0.13318424224853515, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0001700138091109693}, {"id": 53, "seek": 36692, "start": 366.92, "end": 373.56, "text": " running just on bare metal. So we're not reaching the performance of bare metal. There's still", "tokens": [2614, 445, 322, 6949, 5760, 13, 407, 321, 434, 406, 9906, 264, 3389, 295, 6949, 5760, 13, 821, 311, 920], "temperature": 0.0, "avg_logprob": -0.1198662104231588, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0001680698769632727}, {"id": 54, "seek": 36692, "start": 373.56, "end": 380.0, "text": " some overhead. However, we're compared to the Docker containers like we're getting a lot closer", "tokens": [512, 19922, 13, 2908, 11, 321, 434, 5347, 281, 264, 33772, 17089, 411, 321, 434, 1242, 257, 688, 4966], "temperature": 0.0, "avg_logprob": -0.1198662104231588, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0001680698769632727}, {"id": 55, "seek": 36692, "start": 380.0, "end": 389.48, "text": " than that. As an advantage that we didn't see coming initially, but they also have a lot less", "tokens": [813, 300, 13, 1018, 364, 5002, 300, 321, 994, 380, 536, 1348, 9105, 11, 457, 436, 611, 362, 257, 688, 1570], "temperature": 0.0, "avg_logprob": -0.1198662104231588, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0001680698769632727}, {"id": 56, "seek": 36692, "start": 389.48, "end": 396.48, "text": " latency. They run a lot quicker. This also shows the difference between Golang operators and Rust", "tokens": [27043, 13, 814, 1190, 257, 688, 16255, 13, 639, 611, 3110, 264, 2649, 1296, 36319, 656, 19077, 293, 34952], "temperature": 0.0, "avg_logprob": -0.1198662104231588, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0001680698769632727}, {"id": 57, "seek": 39648, "start": 396.48, "end": 402.44, "text": " operators. So obviously, Rust will have a lot less latency and a lot less latency distribution", "tokens": [19077, 13, 407, 2745, 11, 34952, 486, 362, 257, 688, 1570, 27043, 293, 257, 688, 1570, 27043, 7316], "temperature": 0.0, "avg_logprob": -0.09798699959941294, "compression_ratio": 1.6134453781512605, "no_speech_prob": 6.83990292600356e-05}, {"id": 58, "seek": 39648, "start": 402.44, "end": 408.04, "text": " because it's not a garbage collected language. However, we were surprised to see that running", "tokens": [570, 309, 311, 406, 257, 14150, 11087, 2856, 13, 2908, 11, 321, 645, 6100, 281, 536, 300, 2614], "temperature": 0.0, "avg_logprob": -0.09798699959941294, "compression_ratio": 1.6134453781512605, "no_speech_prob": 6.83990292600356e-05}, {"id": 59, "seek": 39648, "start": 408.04, "end": 414.96000000000004, "text": " them inside of WebAssembly gave them even better, even more consistent latency. So how did we do", "tokens": [552, 1854, 295, 9573, 10884, 19160, 2729, 552, 754, 1101, 11, 754, 544, 8398, 27043, 13, 407, 577, 630, 321, 360], "temperature": 0.0, "avg_logprob": -0.09798699959941294, "compression_ratio": 1.6134453781512605, "no_speech_prob": 6.83990292600356e-05}, {"id": 60, "seek": 39648, "start": 414.96000000000004, "end": 424.04, "text": " this? We basically work with a client server model or like a parent operator and a child operator.", "tokens": [341, 30, 492, 1936, 589, 365, 257, 6423, 7154, 2316, 420, 411, 257, 2596, 12973, 293, 257, 1440, 12973, 13], "temperature": 0.0, "avg_logprob": -0.09798699959941294, "compression_ratio": 1.6134453781512605, "no_speech_prob": 6.83990292600356e-05}, {"id": 61, "seek": 42404, "start": 424.04, "end": 430.64000000000004, "text": " The parent operator, it is a WebAssembly runtime with a bunch of additions to it in order to", "tokens": [440, 2596, 12973, 11, 309, 307, 257, 9573, 10884, 19160, 34474, 365, 257, 3840, 295, 35113, 281, 309, 294, 1668, 281], "temperature": 0.0, "avg_logprob": -0.0823424133387479, "compression_ratio": 1.7720930232558139, "no_speech_prob": 0.00022477925813291222}, {"id": 62, "seek": 42404, "start": 430.64000000000004, "end": 439.32000000000005, "text": " support running operators inside of that runtime. And it watches the Kubernetes resources in the", "tokens": [1406, 2614, 19077, 1854, 295, 300, 34474, 13, 400, 309, 17062, 264, 23145, 3593, 294, 264], "temperature": 0.0, "avg_logprob": -0.0823424133387479, "compression_ratio": 1.7720930232558139, "no_speech_prob": 0.00022477925813291222}, {"id": 63, "seek": 42404, "start": 439.32000000000005, "end": 445.52000000000004, "text": " name of the operators running inside of it. So the operators don't have to keep running to watch", "tokens": [1315, 295, 264, 19077, 2614, 1854, 295, 309, 13, 407, 264, 19077, 500, 380, 362, 281, 1066, 2614, 281, 1159], "temperature": 0.0, "avg_logprob": -0.0823424133387479, "compression_ratio": 1.7720930232558139, "no_speech_prob": 0.00022477925813291222}, {"id": 64, "seek": 42404, "start": 445.52000000000004, "end": 451.12, "text": " it. They can just shut down when there's nothing to do. And the parent operator will call them", "tokens": [309, 13, 814, 393, 445, 5309, 760, 562, 456, 311, 1825, 281, 360, 13, 400, 264, 2596, 12973, 486, 818, 552], "temperature": 0.0, "avg_logprob": -0.0823424133387479, "compression_ratio": 1.7720930232558139, "no_speech_prob": 0.00022477925813291222}, {"id": 65, "seek": 45112, "start": 451.12, "end": 457.84000000000003, "text": " once there is a change to process. The child operators, those are where the actual operators", "tokens": [1564, 456, 307, 257, 1319, 281, 1399, 13, 440, 1440, 19077, 11, 729, 366, 689, 264, 3539, 19077], "temperature": 0.0, "avg_logprob": -0.1149924560026689, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.00010225426376564428}, {"id": 66, "seek": 45112, "start": 457.84000000000003, "end": 466.32, "text": " run inside. And the interesting part is that they are just regular operators compiled to WebAssembly", "tokens": [1190, 1854, 13, 400, 264, 1880, 644, 307, 300, 436, 366, 445, 3890, 19077, 36548, 281, 9573, 10884, 19160], "temperature": 0.0, "avg_logprob": -0.1149924560026689, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.00010225426376564428}, {"id": 67, "seek": 45112, "start": 466.32, "end": 475.56, "text": " using a patched version of the Kubernetes SDK. So in the future, this will probably make it", "tokens": [1228, 257, 9972, 292, 3037, 295, 264, 23145, 37135, 13, 407, 294, 264, 2027, 11, 341, 486, 1391, 652, 309], "temperature": 0.0, "avg_logprob": -0.1149924560026689, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.00010225426376564428}, {"id": 68, "seek": 45112, "start": 475.56, "end": 480.76, "text": " possible to just take a regular Kubernetes operator, compile it to WebAssembly, and then use it in", "tokens": [1944, 281, 445, 747, 257, 3890, 23145, 12973, 11, 31413, 309, 281, 9573, 10884, 19160, 11, 293, 550, 764, 309, 294], "temperature": 0.0, "avg_logprob": -0.1149924560026689, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.00010225426376564428}, {"id": 69, "seek": 48076, "start": 480.76, "end": 488.96, "text": " this system. Right now, we only support Rust because Rust support for WebAssembly is very good,", "tokens": [341, 1185, 13, 1779, 586, 11, 321, 787, 1406, 34952, 570, 34952, 1406, 337, 9573, 10884, 19160, 307, 588, 665, 11], "temperature": 0.0, "avg_logprob": -0.20311460230085585, "compression_ratio": 1.5513513513513513, "no_speech_prob": 0.00035910436417907476}, {"id": 70, "seek": 48076, "start": 488.96, "end": 498.08, "text": " Golang support for WebAssembly is iffy. And we have a patched version of Kube RS, a Kubernetes SDK,", "tokens": [36319, 656, 1406, 337, 9573, 10884, 19160, 307, 498, 22522, 13, 400, 321, 362, 257, 9972, 292, 3037, 295, 591, 1977, 25855, 11, 257, 23145, 37135, 11], "temperature": 0.0, "avg_logprob": -0.20311460230085585, "compression_ratio": 1.5513513513513513, "no_speech_prob": 0.00035910436417907476}, {"id": 71, "seek": 48076, "start": 498.08, "end": 510.36, "text": " to then contact the parent operator instead of contacting the Kubernetes API itself. So how", "tokens": [281, 550, 3385, 264, 2596, 12973, 2602, 295, 41482, 264, 23145, 9362, 2564, 13, 407, 577], "temperature": 0.0, "avg_logprob": -0.20311460230085585, "compression_ratio": 1.5513513513513513, "no_speech_prob": 0.00035910436417907476}, {"id": 72, "seek": 51036, "start": 510.36, "end": 518.24, "text": " does this loading and unloading work? This is the WebAssembly engine. This is basically just wasn't", "tokens": [775, 341, 15114, 293, 32165, 278, 589, 30, 639, 307, 264, 9573, 10884, 19160, 2848, 13, 639, 307, 1936, 445, 2067, 380], "temperature": 0.0, "avg_logprob": -0.11481177806854248, "compression_ratio": 1.7276785714285714, "no_speech_prob": 0.00019686442101374269}, {"id": 73, "seek": 51036, "start": 518.24, "end": 525.88, "text": " time, the WebAssembly runtime. And in here is your client operator, your child operator is running.", "tokens": [565, 11, 264, 9573, 10884, 19160, 34474, 13, 400, 294, 510, 307, 428, 6423, 12973, 11, 428, 1440, 12973, 307, 2614, 13], "temperature": 0.0, "avg_logprob": -0.11481177806854248, "compression_ratio": 1.7276785714285714, "no_speech_prob": 0.00019686442101374269}, {"id": 74, "seek": 51036, "start": 525.88, "end": 532.2, "text": " Once the child operator wants to contact the Kubernetes API server, it does a syscall. We", "tokens": [3443, 264, 1440, 12973, 2738, 281, 3385, 264, 23145, 9362, 7154, 11, 309, 775, 257, 262, 749, 45459, 13, 492], "temperature": 0.0, "avg_logprob": -0.11481177806854248, "compression_ratio": 1.7276785714285714, "no_speech_prob": 0.00019686442101374269}, {"id": 75, "seek": 51036, "start": 532.2, "end": 538.88, "text": " extended the WebAssembly system interface to add a few syscalls to support the scenario. And this", "tokens": [10913, 264, 9573, 10884, 19160, 1185, 9226, 281, 909, 257, 1326, 262, 749, 66, 39655, 281, 1406, 264, 9005, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.11481177806854248, "compression_ratio": 1.7276785714285714, "no_speech_prob": 0.00019686442101374269}, {"id": 76, "seek": 53888, "start": 538.88, "end": 545.68, "text": " syscall goes through to the parent operator and the parent operator is the one who actually contacts", "tokens": [262, 749, 45459, 1709, 807, 281, 264, 2596, 12973, 293, 264, 2596, 12973, 307, 264, 472, 567, 767, 15836], "temperature": 0.0, "avg_logprob": -0.13767014671774472, "compression_ratio": 1.9846153846153847, "no_speech_prob": 0.00012115872232243419}, {"id": 77, "seek": 53888, "start": 545.68, "end": 553.04, "text": " the Kubernetes API. Once these calls are finished, the parent operator, it contacts the child", "tokens": [264, 23145, 9362, 13, 3443, 613, 5498, 366, 4335, 11, 264, 2596, 12973, 11, 309, 15836, 264, 1440], "temperature": 0.0, "avg_logprob": -0.13767014671774472, "compression_ratio": 1.9846153846153847, "no_speech_prob": 0.00012115872232243419}, {"id": 78, "seek": 53888, "start": 553.04, "end": 561.2, "text": " operator back again in order to give it the result of these calls. And if the child operator is not", "tokens": [12973, 646, 797, 294, 1668, 281, 976, 309, 264, 1874, 295, 613, 5498, 13, 400, 498, 264, 1440, 12973, 307, 406], "temperature": 0.0, "avg_logprob": -0.13767014671774472, "compression_ratio": 1.9846153846153847, "no_speech_prob": 0.00012115872232243419}, {"id": 79, "seek": 53888, "start": 561.2, "end": 566.36, "text": " doing anything, the parent operator shuts down the child operator. And once there changes to", "tokens": [884, 1340, 11, 264, 2596, 12973, 48590, 760, 264, 1440, 12973, 13, 400, 1564, 456, 2962, 281], "temperature": 0.0, "avg_logprob": -0.13767014671774472, "compression_ratio": 1.9846153846153847, "no_speech_prob": 0.00012115872232243419}, {"id": 80, "seek": 56636, "start": 566.36, "end": 573.72, "text": " process, it starts it up again. And so the results I showed you on the first slides, those results", "tokens": [1399, 11, 309, 3719, 309, 493, 797, 13, 400, 370, 264, 3542, 286, 4712, 291, 322, 264, 700, 9788, 11, 729, 3542], "temperature": 0.0, "avg_logprob": -0.10302303776596532, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.00013411483087111264}, {"id": 81, "seek": 56636, "start": 573.72, "end": 580.64, "text": " are just not unloading anything. Just running Kubernetes operators inside of WebAssembly. So", "tokens": [366, 445, 406, 32165, 278, 1340, 13, 1449, 2614, 23145, 19077, 1854, 295, 9573, 10884, 19160, 13, 407], "temperature": 0.0, "avg_logprob": -0.10302303776596532, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.00013411483087111264}, {"id": 82, "seek": 56636, "start": 580.64, "end": 590.6, "text": " these results are what you get when you have a worst case scenario for unloading operators when", "tokens": [613, 3542, 366, 437, 291, 483, 562, 291, 362, 257, 5855, 1389, 9005, 337, 32165, 278, 19077, 562], "temperature": 0.0, "avg_logprob": -0.10302303776596532, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.00013411483087111264}, {"id": 83, "seek": 59060, "start": 590.6, "end": 596.84, "text": " they're not doing anything. And so we see that in a worst case scenario, they still use 50% less", "tokens": [436, 434, 406, 884, 1340, 13, 400, 370, 321, 536, 300, 294, 257, 5855, 1389, 9005, 11, 436, 920, 764, 2625, 4, 1570], "temperature": 0.0, "avg_logprob": -0.09661609135317, "compression_ratio": 1.503968253968254, "no_speech_prob": 0.00012031978985760361}, {"id": 84, "seek": 59060, "start": 596.84, "end": 602.6800000000001, "text": " RAM because they're constantly being unloaded and then reloaded again once there's changes to", "tokens": [14561, 570, 436, 434, 6460, 885, 32165, 292, 293, 550, 25628, 292, 797, 1564, 456, 311, 2962, 281], "temperature": 0.0, "avg_logprob": -0.09661609135317, "compression_ratio": 1.503968253968254, "no_speech_prob": 0.00012031978985760361}, {"id": 85, "seek": 59060, "start": 602.6800000000001, "end": 610.84, "text": " process. However, this is obviously at the cost of latency. Even though WebAssembly, it starts", "tokens": [1399, 13, 2908, 11, 341, 307, 2745, 412, 264, 2063, 295, 27043, 13, 2754, 1673, 9573, 10884, 19160, 11, 309, 3719], "temperature": 0.0, "avg_logprob": -0.09661609135317, "compression_ratio": 1.503968253968254, "no_speech_prob": 0.00012031978985760361}, {"id": 86, "seek": 59060, "start": 610.84, "end": 620.24, "text": " incredibly fast. It has latency that just can't be compared to Docker containers for starting", "tokens": [6252, 2370, 13, 467, 575, 27043, 300, 445, 393, 380, 312, 5347, 281, 33772, 17089, 337, 2891], "temperature": 0.0, "avg_logprob": -0.09661609135317, "compression_ratio": 1.503968253968254, "no_speech_prob": 0.00012031978985760361}, {"id": 87, "seek": 62024, "start": 620.24, "end": 625.92, "text": " applications. There is still some latency to start a WebAssembly application. And so this", "tokens": [5821, 13, 821, 307, 920, 512, 27043, 281, 722, 257, 9573, 10884, 19160, 3861, 13, 400, 370, 341], "temperature": 0.0, "avg_logprob": -0.10199148514691521, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.00013988491264171898}, {"id": 88, "seek": 62024, "start": 625.92, "end": 633.92, "text": " compounds in the worst case scenario of like 100 operators chaining themselves up to 12 seconds,", "tokens": [21810, 294, 264, 5855, 1389, 9005, 295, 411, 2319, 19077, 417, 3686, 2969, 493, 281, 2272, 3949, 11], "temperature": 0.0, "avg_logprob": -0.10199148514691521, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.00013988491264171898}, {"id": 89, "seek": 62024, "start": 633.92, "end": 643.48, "text": " which is an issue. So what are we doing now? So we have this basic proof of concept to show", "tokens": [597, 307, 364, 2734, 13, 407, 437, 366, 321, 884, 586, 30, 407, 321, 362, 341, 3875, 8177, 295, 3410, 281, 855], "temperature": 0.0, "avg_logprob": -0.10199148514691521, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.00013988491264171898}, {"id": 90, "seek": 62024, "start": 643.48, "end": 649.24, "text": " that this seems to be a very good approach to lower the footprint of the Kubernetes control", "tokens": [300, 341, 2544, 281, 312, 257, 588, 665, 3109, 281, 3126, 264, 24222, 295, 264, 23145, 1969], "temperature": 0.0, "avg_logprob": -0.10199148514691521, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.00013988491264171898}, {"id": 91, "seek": 64924, "start": 649.24, "end": 656.72, "text": " plane. And we want to do more with this. Currently, we're improving the build tools and we're making", "tokens": [5720, 13, 400, 321, 528, 281, 360, 544, 365, 341, 13, 19964, 11, 321, 434, 11470, 264, 1322, 3873, 293, 321, 434, 1455], "temperature": 0.0, "avg_logprob": -0.1189725532960356, "compression_ratio": 1.71875, "no_speech_prob": 0.00020453112665563822}, {"id": 92, "seek": 64924, "start": 656.72, "end": 662.32, "text": " more realistic tests. All the tests we did right now were a worst case scenario of operators", "tokens": [544, 12465, 6921, 13, 1057, 264, 6921, 321, 630, 558, 586, 645, 257, 5855, 1389, 9005, 295, 19077], "temperature": 0.0, "avg_logprob": -0.1189725532960356, "compression_ratio": 1.71875, "no_speech_prob": 0.00020453112665563822}, {"id": 93, "seek": 64924, "start": 662.32, "end": 668.16, "text": " constantly doing stuff. However, in the real world, most operators don't do anything most of the", "tokens": [6460, 884, 1507, 13, 2908, 11, 294, 264, 957, 1002, 11, 881, 19077, 500, 380, 360, 1340, 881, 295, 264], "temperature": 0.0, "avg_logprob": -0.1189725532960356, "compression_ratio": 1.71875, "no_speech_prob": 0.00020453112665563822}, {"id": 94, "seek": 64924, "start": 668.16, "end": 674.92, "text": " time. So we're creating more realistic tests to see what these operators, what the performance", "tokens": [565, 13, 407, 321, 434, 4084, 544, 12465, 6921, 281, 536, 437, 613, 19077, 11, 437, 264, 3389], "temperature": 0.0, "avg_logprob": -0.1189725532960356, "compression_ratio": 1.71875, "no_speech_prob": 0.00020453112665563822}, {"id": 95, "seek": 67492, "start": 674.92, "end": 682.4399999999999, "text": " benefits are for real workloads. We're also working on predictive unloading so that if we know that", "tokens": [5311, 366, 337, 957, 32452, 13, 492, 434, 611, 1364, 322, 35521, 32165, 278, 370, 300, 498, 321, 458, 300], "temperature": 0.0, "avg_logprob": -0.09342379040188259, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.00013437295274343342}, {"id": 96, "seek": 67492, "start": 682.4399999999999, "end": 688.12, "text": " an operator is going to have to run again in a few milliseconds, we don't unload it because it's", "tokens": [364, 12973, 307, 516, 281, 362, 281, 1190, 797, 294, 257, 1326, 34184, 11, 321, 500, 380, 32165, 309, 570, 309, 311], "temperature": 0.0, "avg_logprob": -0.09342379040188259, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.00013437295274343342}, {"id": 97, "seek": 67492, "start": 688.12, "end": 694.64, "text": " better to just keep it running. In the future, we want to work on better support for controllers", "tokens": [1101, 281, 445, 1066, 309, 2614, 13, 682, 264, 2027, 11, 321, 528, 281, 589, 322, 1101, 1406, 337, 26903], "temperature": 0.0, "avg_logprob": -0.09342379040188259, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.00013437295274343342}, {"id": 98, "seek": 67492, "start": 694.64, "end": 701.36, "text": " that wake periodically. So right now, we see that a lot of production controllers actually wake", "tokens": [300, 6634, 38916, 13, 407, 558, 586, 11, 321, 536, 300, 257, 688, 295, 4265, 26903, 767, 6634], "temperature": 0.0, "avg_logprob": -0.09342379040188259, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.00013437295274343342}, {"id": 99, "seek": 70136, "start": 701.36, "end": 707.8000000000001, "text": " periodically every five seconds or every 20 seconds in order to manually check resources in the", "tokens": [38916, 633, 1732, 3949, 420, 633, 945, 3949, 294, 1668, 281, 16945, 1520, 3593, 294, 264], "temperature": 0.0, "avg_logprob": -0.09749939965038765, "compression_ratio": 1.6170212765957446, "no_speech_prob": 7.84407093306072e-05}, {"id": 100, "seek": 70136, "start": 707.8000000000001, "end": 715.04, "text": " Kubernetes API because some of those resources, they can't work with callbacks. So we are trying", "tokens": [23145, 9362, 570, 512, 295, 729, 3593, 11, 436, 393, 380, 589, 365, 818, 17758, 13, 407, 321, 366, 1382], "temperature": 0.0, "avg_logprob": -0.09749939965038765, "compression_ratio": 1.6170212765957446, "no_speech_prob": 7.84407093306072e-05}, {"id": 101, "seek": 70136, "start": 715.04, "end": 720.48, "text": " to figure out a way to actually put that functionality into the host operator itself so that", "tokens": [281, 2573, 484, 257, 636, 281, 767, 829, 300, 14980, 666, 264, 3975, 12973, 2564, 370, 300], "temperature": 0.0, "avg_logprob": -0.09749939965038765, "compression_ratio": 1.6170212765957446, "no_speech_prob": 7.84407093306072e-05}, {"id": 102, "seek": 70136, "start": 720.48, "end": 727.6800000000001, "text": " even when you're watching resources that don't support event-based APIs, the operator is still", "tokens": [754, 562, 291, 434, 1976, 3593, 300, 500, 380, 1406, 2280, 12, 6032, 21445, 11, 264, 12973, 307, 920], "temperature": 0.0, "avg_logprob": -0.09749939965038765, "compression_ratio": 1.6170212765957446, "no_speech_prob": 7.84407093306072e-05}, {"id": 103, "seek": 72768, "start": 727.68, "end": 733.8, "text": " sleeping as long as there's nothing to process. And we're also really interested in upstreaming", "tokens": [8296, 382, 938, 382, 456, 311, 1825, 281, 1399, 13, 400, 321, 434, 611, 534, 3102, 294, 33915, 278], "temperature": 0.0, "avg_logprob": -0.1792872083056104, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.00022705375158693641}, {"id": 104, "seek": 72768, "start": 733.8, "end": 739.2399999999999, "text": " and standardizing this. We have patches for Kube RS. We have an extension for the WebAssembly", "tokens": [293, 3832, 3319, 341, 13, 492, 362, 26531, 337, 591, 1977, 25855, 13, 492, 362, 364, 10320, 337, 264, 9573, 10884, 19160], "temperature": 0.0, "avg_logprob": -0.1792872083056104, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.00022705375158693641}, {"id": 105, "seek": 72768, "start": 739.2399999999999, "end": 745.1999999999999, "text": " system interface. It would be very interesting to see if there's people in the ecosystem who are", "tokens": [1185, 9226, 13, 467, 576, 312, 588, 1880, 281, 536, 498, 456, 311, 561, 294, 264, 11311, 567, 366], "temperature": 0.0, "avg_logprob": -0.1792872083056104, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.00022705375158693641}, {"id": 106, "seek": 72768, "start": 745.1999999999999, "end": 752.88, "text": " interested in this and support for Golang, although this will probably not be work that we're doing,", "tokens": [3102, 294, 341, 293, 1406, 337, 36319, 656, 11, 4878, 341, 486, 1391, 406, 312, 589, 300, 321, 434, 884, 11], "temperature": 0.0, "avg_logprob": -0.1792872083056104, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.00022705375158693641}, {"id": 107, "seek": 75288, "start": 752.88, "end": 760.68, "text": " we'll just wait until Golang is better supported in WebAssembly. So I have to thank the developers.", "tokens": [321, 603, 445, 1699, 1826, 36319, 656, 307, 1101, 8104, 294, 9573, 10884, 19160, 13, 407, 286, 362, 281, 1309, 264, 8849, 13], "temperature": 0.0, "avg_logprob": -0.10082191058567593, "compression_ratio": 1.4720812182741116, "no_speech_prob": 0.0003039576986338943}, {"id": 108, "seek": 75288, "start": 760.68, "end": 768.4399999999999, "text": " Francesco is somewhere here in the audience. We started from a prototype created by Francesco", "tokens": [31441, 1291, 307, 4079, 510, 294, 264, 4034, 13, 492, 1409, 490, 257, 19475, 2942, 538, 31441, 1291], "temperature": 0.0, "avg_logprob": -0.10082191058567593, "compression_ratio": 1.4720812182741116, "no_speech_prob": 0.0003039576986338943}, {"id": 109, "seek": 75288, "start": 768.4399999999999, "end": 776.0, "text": " and Marcus, which runs Kubernetes controllers inside of WebAssembly. And we refactored it to use", "tokens": [293, 26574, 11, 597, 6676, 23145, 26903, 1854, 295, 9573, 10884, 19160, 13, 400, 321, 1895, 578, 2769, 309, 281, 764], "temperature": 0.0, "avg_logprob": -0.10082191058567593, "compression_ratio": 1.4720812182741116, "no_speech_prob": 0.0003039576986338943}, {"id": 110, "seek": 77600, "start": 776.0, "end": 783.4, "text": " wasm time and we added the unloading mechanism. This was done by Tim as part of his master's thesis.", "tokens": [390, 76, 565, 293, 321, 3869, 264, 32165, 278, 7513, 13, 639, 390, 1096, 538, 7172, 382, 644, 295, 702, 4505, 311, 22288, 13], "temperature": 0.0, "avg_logprob": -0.13999031402252532, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.000533683632966131}, {"id": 111, "seek": 77600, "start": 783.4, "end": 792.16, "text": " And right now, student Kevin is working on it also as part of his master's thesis to improve the", "tokens": [400, 558, 586, 11, 3107, 9954, 307, 1364, 322, 309, 611, 382, 644, 295, 702, 4505, 311, 22288, 281, 3470, 264], "temperature": 0.0, "avg_logprob": -0.13999031402252532, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.000533683632966131}, {"id": 112, "seek": 77600, "start": 792.16, "end": 797.24, "text": " build system so that it's much easier to get started with it and to add predictive unloading", "tokens": [1322, 1185, 370, 300, 309, 311, 709, 3571, 281, 483, 1409, 365, 309, 293, 281, 909, 35521, 32165, 278], "temperature": 0.0, "avg_logprob": -0.13999031402252532, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.000533683632966131}, {"id": 113, "seek": 77600, "start": 797.24, "end": 803.8, "text": " and more realistic benchmarks to have a better idea of what is the performance for actual production", "tokens": [293, 544, 12465, 43751, 281, 362, 257, 1101, 1558, 295, 437, 307, 264, 3389, 337, 3539, 4265], "temperature": 0.0, "avg_logprob": -0.13999031402252532, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.000533683632966131}, {"id": 114, "seek": 80380, "start": 803.8, "end": 811.1999999999999, "text": " controllers. So the main reason I am here today is to say like, hey, we have a really cool proof", "tokens": [26903, 13, 407, 264, 2135, 1778, 286, 669, 510, 965, 307, 281, 584, 411, 11, 4177, 11, 321, 362, 257, 534, 1627, 8177], "temperature": 0.0, "avg_logprob": -0.08511827347126413, "compression_ratio": 1.7276785714285714, "no_speech_prob": 0.0006231642328202724}, {"id": 115, "seek": 80380, "start": 811.1999999999999, "end": 818.68, "text": " of concept, which solves an issue that we have been having. Is this solving an issue for other", "tokens": [295, 3410, 11, 597, 39890, 364, 2734, 300, 321, 362, 668, 1419, 13, 1119, 341, 12606, 364, 2734, 337, 661], "temperature": 0.0, "avg_logprob": -0.08511827347126413, "compression_ratio": 1.7276785714285714, "no_speech_prob": 0.0006231642328202724}, {"id": 116, "seek": 80380, "start": 818.68, "end": 825.1999999999999, "text": " people in the community? And are you interested in working together on this? If you're interested", "tokens": [561, 294, 264, 1768, 30, 400, 366, 291, 3102, 294, 1364, 1214, 322, 341, 30, 759, 291, 434, 3102], "temperature": 0.0, "avg_logprob": -0.08511827347126413, "compression_ratio": 1.7276785714285714, "no_speech_prob": 0.0006231642328202724}, {"id": 117, "seek": 80380, "start": 825.1999999999999, "end": 831.04, "text": " in working together on this, please get in touch. If you're a student yourself and you want to do", "tokens": [294, 1364, 1214, 322, 341, 11, 1767, 483, 294, 2557, 13, 759, 291, 434, 257, 3107, 1803, 293, 291, 528, 281, 360], "temperature": 0.0, "avg_logprob": -0.08511827347126413, "compression_ratio": 1.7276785714285714, "no_speech_prob": 0.0006231642328202724}, {"id": 118, "seek": 83104, "start": 831.04, "end": 837.16, "text": " like an internship or a master's thesis working on this, we have a lot of opportunities, same for", "tokens": [411, 364, 16861, 420, 257, 4505, 311, 22288, 1364, 322, 341, 11, 321, 362, 257, 688, 295, 4786, 11, 912, 337], "temperature": 0.0, "avg_logprob": -0.12262767070048564, "compression_ratio": 1.5078534031413613, "no_speech_prob": 0.000259584718151018}, {"id": 119, "seek": 83104, "start": 837.16, "end": 847.28, "text": " a PhD. So please contact us, send me an email to see what we can do for you and how we could", "tokens": [257, 14476, 13, 407, 1767, 3385, 505, 11, 2845, 385, 364, 3796, 281, 536, 437, 321, 393, 360, 337, 291, 293, 577, 321, 727], "temperature": 0.0, "avg_logprob": -0.12262767070048564, "compression_ratio": 1.5078534031413613, "no_speech_prob": 0.000259584718151018}, {"id": 120, "seek": 83104, "start": 847.28, "end": 856.48, "text": " collaborate. So this is the end of my presentation and there's now room for questions. I also put", "tokens": [18338, 13, 407, 341, 307, 264, 917, 295, 452, 5860, 293, 456, 311, 586, 1808, 337, 1651, 13, 286, 611, 829], "temperature": 0.0, "avg_logprob": -0.12262767070048564, "compression_ratio": 1.5078534031413613, "no_speech_prob": 0.000259584718151018}, {"id": 121, "seek": 85648, "start": 856.48, "end": 864.44, "text": " the link to part of our code here. I think this GitHub repo also links to the other repositories", "tokens": [264, 2113, 281, 644, 295, 527, 3089, 510, 13, 286, 519, 341, 23331, 49040, 611, 6123, 281, 264, 661, 22283, 2083], "temperature": 0.0, "avg_logprob": -0.15583331108093262, "compression_ratio": 1.2, "no_speech_prob": 0.0001869577681645751}, {"id": 122, "seek": 86444, "start": 864.44, "end": 894.2, "text": " that you need. Okay, we can take a couple of questions. So why was he so fast and why", "tokens": [300, 291, 643, 13, 1033, 11, 321, 393, 747, 257, 1916, 295, 1651, 13, 407, 983, 390, 415, 370, 2370, 293, 983], "temperature": 0.0, "avg_logprob": -0.2005491440112774, "compression_ratio": 1.0759493670886076, "no_speech_prob": 0.0008703129133209586}, {"id": 123, "seek": 89420, "start": 894.2, "end": 905.4000000000001, "text": " it is not possible to do something similar with JVM? So definitely, JVM and WebAssembly are very", "tokens": [309, 307, 406, 1944, 281, 360, 746, 2531, 365, 508, 53, 44, 30, 407, 2138, 11, 508, 53, 44, 293, 9573, 10884, 19160, 366, 588], "temperature": 0.0, "avg_logprob": -0.14333624779423582, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.0012676224578171968}, {"id": 124, "seek": 89420, "start": 905.4000000000001, "end": 913.96, "text": " similar in that regard and a lot of people, they position WebAssembly as being like a more", "tokens": [2531, 294, 300, 3843, 293, 257, 688, 295, 561, 11, 436, 2535, 9573, 10884, 19160, 382, 885, 411, 257, 544], "temperature": 0.0, "avg_logprob": -0.14333624779423582, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.0012676224578171968}, {"id": 125, "seek": 89420, "start": 913.96, "end": 921.32, "text": " cross-platform and a more cross-language version of the JVM. But if you're only interested in Java", "tokens": [3278, 12, 39975, 837, 293, 257, 544, 3278, 12, 25241, 20473, 3037, 295, 264, 508, 53, 44, 13, 583, 498, 291, 434, 787, 3102, 294, 10745], "temperature": 0.0, "avg_logprob": -0.14333624779423582, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.0012676224578171968}, {"id": 126, "seek": 92132, "start": 921.32, "end": 928.12, "text": " and Java-based languages, then the Java runtime itself is a very good alternative to this.", "tokens": [293, 10745, 12, 6032, 8650, 11, 550, 264, 10745, 34474, 2564, 307, 257, 588, 665, 8535, 281, 341, 13], "temperature": 0.0, "avg_logprob": -0.17613571030753, "compression_ratio": 1.4058823529411764, "no_speech_prob": 0.0002878280356526375}, {"id": 127, "seek": 92132, "start": 928.12, "end": 932.7600000000001, "text": " Okay, there was another one over here, right? Yeah.", "tokens": [1033, 11, 456, 390, 1071, 472, 670, 510, 11, 558, 30, 865, 13], "temperature": 0.0, "avg_logprob": -0.17613571030753, "compression_ratio": 1.4058823529411764, "no_speech_prob": 0.0002878280356526375}, {"id": 128, "seek": 92132, "start": 932.7600000000001, "end": 948.2800000000001, "text": " So if I understood correctly, you are deploying your operators outside containers and that makes", "tokens": [407, 498, 286, 7320, 8944, 11, 291, 366, 34198, 428, 19077, 2380, 17089, 293, 300, 1669], "temperature": 0.0, "avg_logprob": -0.17613571030753, "compression_ratio": 1.4058823529411764, "no_speech_prob": 0.0002878280356526375}, {"id": 129, "seek": 94828, "start": 948.28, "end": 958.6, "text": " them much more efficient. But, I mean, besides the security aspects, when you deploy in containers", "tokens": [552, 709, 544, 7148, 13, 583, 11, 286, 914, 11, 11868, 264, 3825, 7270, 11, 562, 291, 7274, 294, 17089], "temperature": 0.0, "avg_logprob": -0.15631586782048257, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.000671501737087965}, {"id": 130, "seek": 94828, "start": 958.6, "end": 965.4, "text": " and Kubernetes, you have many other things that you can set, like resource limits, but also things", "tokens": [293, 23145, 11, 291, 362, 867, 661, 721, 300, 291, 393, 992, 11, 411, 7684, 10406, 11, 457, 611, 721], "temperature": 0.0, "avg_logprob": -0.15631586782048257, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.000671501737087965}, {"id": 131, "seek": 94828, "start": 965.4, "end": 971.64, "text": " like post-topology spread constraints and notations to make sure that some processes are running on", "tokens": [411, 2183, 12, 19337, 1793, 3974, 18491, 293, 406, 763, 281, 652, 988, 300, 512, 7555, 366, 2614, 322], "temperature": 0.0, "avg_logprob": -0.15631586782048257, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.000671501737087965}, {"id": 132, "seek": 94828, "start": 971.64, "end": 977.4, "text": " specific nodes and so on. How can you address that with WebAssembly? Because you cannot package", "tokens": [2685, 13891, 293, 370, 322, 13, 1012, 393, 291, 2985, 300, 365, 9573, 10884, 19160, 30, 1436, 291, 2644, 7372], "temperature": 0.0, "avg_logprob": -0.15631586782048257, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.000671501737087965}, {"id": 133, "seek": 97740, "start": 977.4, "end": 982.1999999999999, "text": " then your operator like any other workload that you deploy in Kubernetes.", "tokens": [550, 428, 12973, 411, 604, 661, 20139, 300, 291, 7274, 294, 23145, 13], "temperature": 0.0, "avg_logprob": -0.09238747344619927, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.00032615032978355885}, {"id": 134, "seek": 97740, "start": 983.0, "end": 989.72, "text": " Yeah, so it's a very good question. So one of the benchmarks was just running the operators", "tokens": [865, 11, 370, 309, 311, 257, 588, 665, 1168, 13, 407, 472, 295, 264, 43751, 390, 445, 2614, 264, 19077], "temperature": 0.0, "avg_logprob": -0.09238747344619927, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.00032615032978355885}, {"id": 135, "seek": 97740, "start": 989.72, "end": 995.0799999999999, "text": " on bare metal, but that's not actually what I'm proposing. It was just to see, like, what is the", "tokens": [322, 6949, 5760, 11, 457, 300, 311, 406, 767, 437, 286, 478, 29939, 13, 467, 390, 445, 281, 536, 11, 411, 11, 437, 307, 264], "temperature": 0.0, "avg_logprob": -0.09238747344619927, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.00032615032978355885}, {"id": 136, "seek": 97740, "start": 995.0799999999999, "end": 1002.76, "text": " absolute maximum amount of performance we could get out of this. Our plan is to run each operator", "tokens": [8236, 6674, 2372, 295, 3389, 321, 727, 483, 484, 295, 341, 13, 2621, 1393, 307, 281, 1190, 1184, 12973], "temperature": 0.0, "avg_logprob": -0.09238747344619927, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.00032615032978355885}, {"id": 137, "seek": 100276, "start": 1002.76, "end": 1009.24, "text": " inside of its own container. It's just a WebAssembly plus WebAssembly system interface container", "tokens": [1854, 295, 1080, 1065, 10129, 13, 467, 311, 445, 257, 9573, 10884, 19160, 1804, 9573, 10884, 19160, 1185, 9226, 10129], "temperature": 0.0, "avg_logprob": -0.06297321533888914, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.00016304767632391304}, {"id": 138, "seek": 100276, "start": 1009.24, "end": 1018.52, "text": " instead of a Docker container. And so most of the security profile and stuff like that that", "tokens": [2602, 295, 257, 33772, 10129, 13, 400, 370, 881, 295, 264, 3825, 7964, 293, 1507, 411, 300, 300], "temperature": 0.0, "avg_logprob": -0.06297321533888914, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.00016304767632391304}, {"id": 139, "seek": 100276, "start": 1018.52, "end": 1024.68, "text": " you have with Docker containers is very similar with WebAssembly. Some would even argue that it's", "tokens": [291, 362, 365, 33772, 17089, 307, 588, 2531, 365, 9573, 10884, 19160, 13, 2188, 576, 754, 9695, 300, 309, 311], "temperature": 0.0, "avg_logprob": -0.06297321533888914, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.00016304767632391304}, {"id": 140, "seek": 100276, "start": 1024.68, "end": 1032.2, "text": " more secure in WebAssembly because it has a much smaller API footprint and it has some of the best", "tokens": [544, 7144, 294, 9573, 10884, 19160, 570, 309, 575, 257, 709, 4356, 9362, 24222, 293, 309, 575, 512, 295, 264, 1151], "temperature": 0.0, "avg_logprob": -0.06297321533888914, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.00016304767632391304}, {"id": 141, "seek": 103220, "start": 1032.2, "end": 1040.6000000000001, "text": " teams working on it to make sure it's secure for the browser. Moreover, the code that is running in", "tokens": [5491, 1364, 322, 309, 281, 652, 988, 309, 311, 7144, 337, 264, 11185, 13, 19838, 11, 264, 3089, 300, 307, 2614, 294], "temperature": 0.0, "avg_logprob": -0.09648335498312245, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.0002491724444553256}, {"id": 142, "seek": 103220, "start": 1040.6000000000001, "end": 1050.1200000000001, "text": " these WebAssembly containers in my proof of concept, this is control plane code. So this is code that", "tokens": [613, 9573, 10884, 19160, 17089, 294, 452, 8177, 295, 3410, 11, 341, 307, 1969, 5720, 3089, 13, 407, 341, 307, 3089, 300], "temperature": 0.0, "avg_logprob": -0.09648335498312245, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.0002491724444553256}, {"id": 143, "seek": 103220, "start": 1050.1200000000001, "end": 1056.6000000000001, "text": " the system administrator selected, like, okay, yeah, I want this specific system administration", "tokens": [264, 1185, 25529, 8209, 11, 411, 11, 1392, 11, 1338, 11, 286, 528, 341, 2685, 1185, 7236], "temperature": 0.0, "avg_logprob": -0.09648335498312245, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.0002491724444553256}, {"id": 144, "seek": 105660, "start": 1056.6, "end": 1064.28, "text": " code to manage my applications. And so in that sense, there's also, like, a higher level of trust", "tokens": [3089, 281, 3067, 452, 5821, 13, 400, 370, 294, 300, 2020, 11, 456, 311, 611, 11, 411, 11, 257, 2946, 1496, 295, 3361], "temperature": 0.0, "avg_logprob": -0.12843477222281444, "compression_ratio": 1.5689655172413792, "no_speech_prob": 7.752026431262493e-05}, {"id": 145, "seek": 105660, "start": 1065.0, "end": 1077.24, "text": " put into the code, which means that, like, things like attacks and stuff like that, there's less", "tokens": [829, 666, 264, 3089, 11, 597, 1355, 300, 11, 411, 11, 721, 411, 8122, 293, 1507, 411, 300, 11, 456, 311, 1570], "temperature": 0.0, "avg_logprob": -0.12843477222281444, "compression_ratio": 1.5689655172413792, "no_speech_prob": 7.752026431262493e-05}, {"id": 146, "seek": 107724, "start": 1077.24, "end": 1091.96, "text": " of a risk to it. But even then, like, it's still running inside of containers.", "tokens": [295, 257, 3148, 281, 309, 13, 583, 754, 550, 11, 411, 11, 309, 311, 920, 2614, 1854, 295, 17089, 13], "temperature": 0.0, "avg_logprob": -0.12889035088675363, "compression_ratio": 1.4175257731958764, "no_speech_prob": 5.6064145610434934e-05}, {"id": 147, "seek": 107724, "start": 1091.96, "end": 1099.72, "text": " So one of the most important scalability aspects of Kubernetes controllers is the watch-based cache,", "tokens": [407, 472, 295, 264, 881, 1021, 15664, 2310, 7270, 295, 23145, 26903, 307, 264, 1159, 12, 6032, 19459, 11], "temperature": 0.0, "avg_logprob": -0.12889035088675363, "compression_ratio": 1.4175257731958764, "no_speech_prob": 5.6064145610434934e-05}, {"id": 148, "seek": 107724, "start": 1099.72, "end": 1106.6, "text": " right? So without it, the API server wouldn't be able to handle all the long pulling and so on.", "tokens": [558, 30, 407, 1553, 309, 11, 264, 9362, 7154, 2759, 380, 312, 1075, 281, 4813, 439, 264, 938, 8407, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.12889035088675363, "compression_ratio": 1.4175257731958764, "no_speech_prob": 5.6064145610434934e-05}, {"id": 149, "seek": 110660, "start": 1106.6, "end": 1114.6799999999998, "text": " And it's also one of the most memory-intensive aspects of Kubernetes controllers. I was wondering", "tokens": [400, 309, 311, 611, 472, 295, 264, 881, 4675, 12, 686, 2953, 7270, 295, 23145, 26903, 13, 286, 390, 6359], "temperature": 0.0, "avg_logprob": -0.08781391061762328, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.0002632865507621318}, {"id": 150, "seek": 110660, "start": 1114.6799999999998, "end": 1122.28, "text": " in your memory benchmarks if you were cutting down on this watch-based aspect, or if it is still", "tokens": [294, 428, 4675, 43751, 498, 291, 645, 6492, 760, 322, 341, 1159, 12, 6032, 4171, 11, 420, 498, 309, 307, 920], "temperature": 0.0, "avg_logprob": -0.08781391061762328, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.0002632865507621318}, {"id": 151, "seek": 110660, "start": 1122.28, "end": 1129.32, "text": " included in the parent operator. So for example, is the parent operator caching as a proxy for the", "tokens": [5556, 294, 264, 2596, 12973, 13, 407, 337, 1365, 11, 307, 264, 2596, 12973, 269, 2834, 382, 257, 29690, 337, 264], "temperature": 0.0, "avg_logprob": -0.08781391061762328, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.0002632865507621318}, {"id": 152, "seek": 110660, "start": 1129.32, "end": 1135.08, "text": " child operators? Is that the case? Yeah, that's what's happening, basically. The parent operator", "tokens": [1440, 19077, 30, 1119, 300, 264, 1389, 30, 865, 11, 300, 311, 437, 311, 2737, 11, 1936, 13, 440, 2596, 12973], "temperature": 0.0, "avg_logprob": -0.08781391061762328, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.0002632865507621318}, {"id": 153, "seek": 113508, "start": 1135.08, "end": 1141.48, "text": " is where the caches are, yeah.", "tokens": [50364, 307, 689, 264, 269, 13272, 366, 11, 1338, 13, 50684], "temperature": 0.0, "avg_logprob": -0.3223665952682495, "compression_ratio": 0.7894736842105263, "no_speech_prob": 0.0006577064632438123}], "language": "en"}