{"text": " So now we have Orson, he's going to be talking about GlideSort, very beautiful opening slides, so yeah, take it away. Thank you. Can everyone hear me? All right. Good. Thanks for coming. So my name is Orson, and I'm here to present GlideSort. I did this research at the CBI Database Architecture Group, GlideSort. What is it? It's a general purpose, stable comparison sort here. Does everyone here understand what that means? No. Oh, okay. Well, good luck. So stable means that it does not reorder equal elements. They stay in the original order, so essentially it makes sorting deterministic. GlideSort is a hybrid. It's a hybrid of merge sort, quicksort, and block insertion sort, which is a variant of insertion sort, and it is robustly adaptive to pre-sorted and low cardinality inputs. Don't worry, I'll talk about what that means. I made a reference implementation in partially unsaved rust, and you can think of it if you're programming a rust as a drop-in for the slice stable sort algorithm. So you might wonder, stable quicksort. The answer is yes. A guy named Igor von Den Hoven made a very, I don't know, he did very good work on flux sort, where he showed that indeed you can do stable quicksort efficiently. Wikipedia will tell you that quicksort is in place, that it is done using element exchanges, and that it will literally tell you efficient implementations of quicksort are not a stable sort. Wikipedia tells you, no, you cannot do it. Standard stable sort uses extra memory to do its sorting, and if you tell people, hey, you can do the same with stable quicksort, they completely lose their minds. No quicksort is in place, you cannot do that. That's not true. You can, and you probably should. So earlier I mentioned adaptive sorting. What do I mean by that? To adapt is to change your behavior to deal with new information or a new situation. And there are two ways that you can be adaptive, in my opinion, major ways you can be adaptive in sorting. And they correspond to two schools of sorting. There is the bottom-up school of sorting. Those are your merge sorts, or your mergers variance, like dimsort and powersort. And they are bottom-up. They construct larger and larger sorted sequences from smaller sort of sequences. They are often presented in a schoolbook way top-down, but really fundamentally they are bottom-up. And that way they can be adaptive to pre-sorted runs. If there's already pre-sorted running your input, you can just take that as is and continue merging up. There's also the partition school of sorts. Those are your quicksort, your sample sorts, your radix sorts. They partition out or distribute data. They are fundamentally top-down. You start at the higher, and you partition to smaller, smaller, smaller. Subpartitions, and that way they can be adaptive to low cardinality inputs. So what are low cardinality inputs? Essentially you have a lot of data, and you're sorting it by a subset of the data. So you're sorting your customers, but you're sorting them by which city they live in. Or you're sorting your cars, but you're sorting by the brand of the car. And even though you might have hundreds of thousands of cars, you might only have 100 brands. So essentially duplicates, at least from the perspective of a comparison operator. So how does adaptive quicksort deal with that? The idea is that during partitioning, we can detect buckets of elements that are all equal to each other. And there's a challenge with doing that. You don't want to do extra unnecessary comparisons. And we actually want to avoid three-way comparisons. That's a bit funny, because Rust's basic ORT trait uses three-way comparisons. But that's a lie. Under the hood, we turn that back into a two-way comparison, because computers aren't very good at turner logic. They really love binary logic. They love ifs and else. So we still turn that back into two-way comparisons. And there's been a long history on adaptive quicksorts in this way, with Dijkstra and Hauer, I still don't know how to pronounce that, working on it. And already, time flies, eight years ago, I showed that in pattern defeating quicksort that you can detect this and handle this very efficiently. So how does that work? I have an entire earlier talk on PDQ sort that you can watch if you're interested in this. But essentially, we have two different partition strategies. A partition left and a partition right. The partition left puts elements equal to the pivot on the left. And the partition right puts equal elements on the right. And what you do is, when you select a pivot, you check if that pivot is equal to a pivot we used previously. And you can do this efficiently using a single extra comparison during partitioning, or at least pivot selection. And the default is that you put the equal elements on the right. But if you detect, hey, this pivot is equal to a previous pivot, you put equal elements on the left. And this way, you implicitly do a three-way partition using two-way comparisons. And you can prove that, on average, this means that your sort is o n log k, where k is the number of distinct values. If every value is distinct, that becomes o n log n, we're used to that. But if you have a lot of duplicate values, o n log k goes a lot faster than n log n. There's also adaptive merge sort. As I said earlier, these merge pre-existing runs in the input. The problem with solving this is that you want to minimize the amount of unbalanced mergers that you do. So you don't want to merge a very large array with a very small array, because that's quite inefficient. And you also want to somehow store, during your algorithm, where the runs are in memory. And if you do this in an illogical way, you have to potentially store a lot of data about where all the runs are. And Van Neumann invented merge sort very early, and Knuth described also quite early a natural merge sort that takes advantage of pre-existing runs in the input. And then, in particular, Tim Peters popularized Tim sort, which became the default sorting algorithm in Python, that really showed the first sort of clever way to keep track of your run information and minimizing unbalanced mergers. The recent work is PowerSort, which extends on Tim sort essentially, or has the same logic, but more clever logic, and actually has mathematical proofs that it creates balanced merge sequences. And in fact, Python, I believe, now uses PowerSort's logic as well. So I'm not going to go into detail on how PowerSort works. I don't have enough time for that. But essentially, the core loop of it is that you create a run, and that can either be by finding the run in the input or doing a small sorting algorithm to create a small run. You compute the power of a run. That's the heuristics I'm not going to get into. And then you keep a stack of runs, and then use this power heuristic that we computed to decide when to merge two runs. And you can prove that the stack then becomes logarithmic in size, and that your merge sequences are going to be very good. But yeah, the idea is that create a run can take advantage of existing runs in the input. So a problem merges. We want to be adaptive to low cardinality inputs, and we want to be adaptive to preexisting run in input. But one is fundamentally bottom up, and the other one is fundamentally top down. And that's why I call this GlideSort. We glide. What do I mean by that? Well, the idea is that a soaring bird only flaps its wings when necessary. GlideSort only sorts when necessary. So during this create run process, I'm sorry, before that, I changed the concept of a run to a logical run. And a logical run can be one of three things. It can be just as before. It can just be a sorted range of elements in your array, and can also be an unsorted range of elements in your array, or two sorted ranges that are right next to each other in your array. We change the create run function. We do, in fact, if there's a run in the input, detect that and return that as a sorted run. But if we don't detect a sorted run, we just return an unsorted run. We don't eagerly sort anything, and how you do that is very simple. You just scan through the array, and if you find a run that we consider big enough, we return it, and otherwise, we just skip some elements and return an unsorted run. And then you add quite a bit of code for merging two runs, but it's actually relatively simple. As long as two unsorted runs concatenate it fit in our scratch base, which is essentially this extra memory that blows people's minds, as long as it fits in that, we just concatenate our unsorted runs. And otherwise, we actively physically sort the elements using quick sort, and then create one of these two sorted concatenated run cases. If we have two sorted runs, we concatenate them. If we have an unsorted run and something else, we actually sort this unsorted run and then recurs. And finally, we have our actual physical mergers. So when we can no longer be lazy, we can no longer glide, we have to actually merge elements. So that is essentially the main loop of glide sort. So it's an extension of power sort, but you can apply the same logic to any natural stable merge sort. We don't eagerly sort small runs. We keep them as unsorted runs as long as possible. And this way, we transform the sorting problem into a sequence of quick sort calls and triple slash quad merges. And doing this, we are adaptive to pre-sorted runs and low cardinality inputs at the same time. So why triple and quad merges? And there are three main reasons. There's ping-pong merging, bidirectional merging, oh, sorry, before I want to quite clearly mention something, Glider is not the first algorithm that is adaptive to both of these categories at the same time, but to my knowledge, at least it is the first algorithm that is robustly adaptive. So it does not hard code anything, it does not use heuristics to decide when to switch to which algorithm it detects this completely naturally based on the input. So why triple slash quad merges? There are three main reasons. Ping-pong merging, bidirectional merging, and parallel merging. Ping-pong merging is not my idea, it's found in two early projects, once again by Igor van der Hove and an earlier paper, Pages is Virtue. And the idea is that in a traditional merge, you copy out part of the data someplace else and then merge back into the original array, that's an extra memcap. With a triple slash quad or a quad merge, you can merge both into your scratch space and on the way back, because essentially when you do an out of place merge, you get a mem copy for free because you're moving to some other place. So I think that's best described visually, if you have four, so in this case a quad merge, you have four mer sorted runs, you merge two into your scratch space, you merge two more into your scratch space, and you merge two back. And now we eliminated three mem copies, so don't have to do that, that's one advantage of being lazy with merging. We can also do bidirectional merging, this, to my knowledge, was first done again by Igor van der Hove in Quadsford, where he described a parity merge, where he showed a very clever technique to merge two equal length arrays without any branch checks. But then I thought by merging from both ends at the same time. But then I thought, looked really into why that was fast and how can we extend that and use that further. So the idea behind a bidirectional merge is that if your destination and your source arrays are disjoint, you can merge from both ends at the same time. And then the pointer that's going from right to left does not interfere with the pointer going from left to right. These two logics are independent, essentially. And it essentially looks like that. Why? Why do we want to do that? Well, modern processors are quite different than what maybe your traditional processor with your mental image are. They are superscaler, that means they don't execute one instruction per cycle, no, they can execute many instructions per cycle. They are out of order, the processor will internally reorder your instructions based on your assembly based on the data paths and when memory is available. And they are deeply pipelined. That means that they don't like it when the next instruction depends immediately on the result of the previous instruction because it has to go through the entire pipeline of the processor. So to study that in a bit more detail, we look at a branchless merge, which was first described in branch mispredictions don't affect merge source. This is not the code that they used in this paper. This is roughly translated from GlideSort. You don't have to get into it, how it works. The main important part is that you analyze where is the result used in the next slide. Well, you find that generally all the data that's computed is needed immediately. And the worst part of it all is that the next iteration cannot start really until the previous iteration is finished. You don't know if you're merging two arrays, you need to know, am I continuing with the left array or am I continuing with the right array? There's a lot of data dependencies. So that is my main takeaway from GlideSort and my main low level design principle is to interleave independent branchless loops. So branchless is important, so the processor isn't jumping around and constantly canceling your pipeline. And by interleaving, we can hide some of these data dependencies. The processor can execute multiple instructions at once and it can essentially reduce the impact of having to constantly wait for the previous result. You can also consider parallel merging. So in this case, we had one merge where we did it in parallel from the left and parallel from the right. But we also noticed that the first step in our quad merge has two independent merges. These are essentially parallel, but we're not using threads, but we can interleave their loops. So once I discovered that, I thought, let's create more parallelism. By doing a binary search, you can identify a split point where you can turn one merge into two smaller merges by swapping the right blocks in the middle. I won't go into the exact logic of proof about that, but you can. And in fact, if you are doing an out-of-place merge, you can do this swap implicitly by just reassigning pointers. So there's no actual physical mem copy going on. However, if you're doing an in-place merge, you can actually do the physical swap. And now you have for free a fallback for low memory merging. So even if you don't have a large buffer available to merge with, you can use this algorithm to do it in a low amount of memory. Then I also optimized the quicksort portion of it with the same principle. I came up with what I call bi-directional stable partitioning. Again, I don't have time to get into it, but the idea is that we do, again, partition like in quicksort. So one set of elements that are less than the pivot goes somewhere else. Go go here. And some that are greater or equal go somewhere else. But we do it from both the left-hand side to the right, and from the right-hand side to the left. And these two loops are independent from each other, so we can interleave them. Same principle. When you recurse, it gets a bit more involved, because now your data is in multiple different locations. I can tell you this is not fun to program, but I did it, and here it is. So I do have some experiments to show you very briefly, an experiment of the setup. So this is a lot of text that basically says a 2021 Apple MacBook. And these are the numbers you would get on an Apple 2021 MacBook. So at the top, I have two variants of GlideSort. One is the default variant that you would get if you were to download it. GlideSort 1024 is a variant that uses a fixed amount of memory, so 1024 elements of memory. Then we have the Rust stable sort, the C++ standard stable sort, an implementation of Tim sort, a PDQ sort, an older algorithm of mine, which is also the stable Rust sorting algorithm, and the whatever shipped as the standard sort in C++. You can read the slides yourself. GlideSort is quite a bit faster than the Rust stable sort right now. What isn't shown on this page are some more competitive algorithms, like Fluxort and Quadsort. So they trade blows for blows on different data sets, but those are written in C, and they don't have to deal with some of the problems that we deal with that I'll get to later in my talk on sorting in Rust. If you actually change your comparison operator, so we're only sorting by the last byte of the integer, fun fact, if you do this, stability becomes even observable for integers. GlideSort, again, speeds up even more compared to the Rust stable sorting algorithm. So now we're over an order of magnitude faster for these data sets. If you want to use it, good news, it's released. It took me a while, but it's finally out. You can just cargo add GlideSort, and you can replace your sort, call to Slidesort with GlideSort. If there are any standards library people in the audience come talk to me after the talk, I would love to see it integrated, so you don't have to call GlideSort, and it would just be done by default. But this is a Rust dev room, so some of you at least probably are interested in Rust, so I will also talk about some Rust specifics, so what it takes to implement a sorting algorithm in Rust. And first I'm just going to rant, unwinding panics, I think a Rust billion-dollar mistake. They are complete nightmare. If you are writing unsafe code and you've ever had to deal with panic, some people in the audience are laughing, they're horrible, because essentially, since you can catch them and we have to be sound and safe during a panic, they're essentially the same as C++ functions. In C++, all these functions say if you throw an exception, tough shit, like your vector is invalid now, too bad, it doesn't matter, you can't use it, you don't have the choice in Rust, you have to always be safe and sound in Rust, ensuring that is a nightmare, especially when you're dealing with generic code in unsafe code. So if you're calling foreign code, anything you do, any call, can panic, which causes an unwind. So whenever you call a foreign function, you have to make sure that you are in a sound and safe state. The problem is every single trait is foreign code. That clone call, that's foreign code. This comparison operator, that's foreign code. Lightning Glider was a complete nightmare, every time I compare two elements, that could cause a panic, that could cause an unwind, and you saw all this stuff that I'm doing with arrays all over the place, all of that has to be restored to the original location because it's a mudslice, and you cannot leave a mudslice in an unsound or you can't leave holes in it, everything has to be returned to the original array. Yeah, it's a nightmare, I really wish we would just, instead of panicking, we would just write out a stack trace and abort and be done with it. I hate it, that's my rant. Oh yeah, well, and in fact, GlideSort has an actual real performance penalty because panics are a thing. I can't just write a, like if you're writing an insertion sort, for example, in C++ or in Python, you would just have a loop with a loop variable and you would put the items in the correct place. If you're implementing a thing like this in Rust and you're leaving gaps, so you're moving the element out during the insertion sort, you have to have a drop handler that puts this element back during a panic because this ORD implementation, this foreign code, can cause a panic and cause an unwind. So even when I'm sorting something like integers, which cannot panic, if I don't want to duplicate my entire code base, I still have to pay this penalty for dealing with the potential for panics by storing all my data, instructs, and all this algorithm state. So yeah, that's a problem. But I also want to praise Rust, where it is pleasurable. I love that moves are mem copies. There's no move constructor. If you want to move a type somewhere else, you essentially just copy it and you ignore whatever, wherever it came from. This also makes optimizations possible that aren't possible in C++ because of move constructors, at least not if you don't want to use like templates metaprogramming. For example, instead of copying an element, this is an example actually from GlideSort, not written like this, but where you place an element in one of two places, and if it's going to the wrong place, it doesn't matter because it will just be ignored or overwritten in the next iteration. If it's a small type, just place it in both, don't do a branch. So essentially, this is the opposite of unwinding panics. There are no surprises. A mem copy is always what you get. This is not necessarily, it's part praise, part complaining. Split at mutt, so splitting a slice into or more. It's a one-way street. You cannot go back. Once it's split, it's split. Unless you go back to the original object, but that's not always an option. In GlideSort, when I concatenate these arrays, slices, I need actual concatenation. My options were raw pointers, but that was the option. You are storing an array with indices, but now you're storing an extra pointer everywhere and passing an extra pointer everywhere, and that's overhead that I didn't want to pay. So I came up with a thing I call branded slices. You could hold an entire talk on this, but it's essentially applying the idea of a ghost cell. Some of you might have heard from this, where you essentially brand a type with a unique lifetime that you cannot create. You can only create this lifetime once, and it's not interchangeable with any other lifetime. And with that, you can make safe concatenation. So you could just check, is the end pointer equal to the begin pointer of the other array if yes, we can concatenate? And that will work, except that could also just be happening by chance because of the local array layout on the stack, and you could create unsound behavior. But if you know that they came from the same allocation, then it's safe to concatenate them after checking and equals begin. So that's what I did with what I call mudslice, which in GlideSword, every single slice is a mudslice type, which has a brand, so you can do the safe concatenation, and it has a state, which is one of five things. It's weak on in it, maybe in it, in it, always in it. Always in it, essentially, a mutable slice, so you always have to return it to initialization state. And maybe on in it, in it are a bit more specialized than just maybe on in it, where the type doesn't really encode what it actually contains, and weak is essentially a pair of pointers. And then the code becomes a lot more readable and a lot more verifiable by explicitly encoding your assumptions about your slice type using the type, and then calling functions like upgrades to say, hey, this now becomes an exclusive mutably slice. I'm only going to access this here, or hey, I'm now going to temporarily invalidate this initialization state of this slice. That was essentially my talk. I'm leaving academia, so if you have an interesting, potentially rust job, my contact details are on the slides or come talk to me after the talk. I'm not interested in cryptocurrency, Web3 or similar endeavors. I love cryptography, but I don't know, some of this stuff gets rather sketchy, no offense. That was essentially my talk. I'm going to leave this on this slide. Are there any questions? I have a question. Did you test Glidesort on, let's say, less modern CPUs, like embedded CPUs that don't have auto-fordering execution, et cetera? Yes. Can you repeat the question, please? The question was, did you test the algorithm on any older CPUs that might not have as much instruction-level parallelism and that kind of stuff? The answer is yes, and yes, it is slower than other state-of-the-art that don't do these tricks. This is really aimed towards essentially the future of modern processors. From older CPUs, it is slower than, for example, flux sort, which doesn't do this aggressive interleaving. But if you compare it to the current Rust stable sort that's currently in the standard library, it's still completely dumps us all over that. Can you hear me? Barely. Can you speak loudly? When you take two sort of sequences and you take the bottom half of one and the top half of another and create a third sorted sequence out of that, I thought that was an interesting observation, but what do you use it for? So it's not the top half and the bottom half. That's just the simplification. You're talking about the splitting up merges into smaller merges, right? Yes. Yes. So it is not the top half and the bottom half. It involves a binary search to find the unique split point that allows you to do this swap. It could be bottom half, top half, but that's not necessarily the case. What do I use this for? It creates two independent merges. After doing the swap, this merge no longer depends on this merge at all. And by doing that, I can have two independent loops that merge these and then interleave the bodies of these loops. So it executes one instruction from this merge, one instruction from this merge, one instruction from this merge, one instruction from this merge, et cetera. And that way these instructions don't depend on each other and you can hide these data dependencies and such. On top of that, I use it as a fallback for the low memory case where you don't need, so GlideSword can use less auxiliary memory. We have a last question. Thanks for the talk. I would like to know if you have a bench. I'm sorry, I cannot hear. Can you speak a bit louder, please? Did you bench when the array is already sorted? Did I bench when the array is already sorted? Yes. Yes, it's on the slides. Is it on the slides? Yes, it's the ascending column on the slides and on this slide as well. It's the one person. Sorry? It's the one person column. No, ascending. Ascent. Okay. Okay, that means sorted in this case and descending means reverse of sorted. Okay, okay. Thank you. All right. Thanks very much. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 15.36, "text": " So now we have Orson, he's going to be talking about GlideSort, very beautiful opening slides,", "tokens": [407, 586, 321, 362, 1610, 3015, 11, 415, 311, 516, 281, 312, 1417, 466, 5209, 482, 50, 477, 11, 588, 2238, 5193, 9788, 11], "temperature": 0.0, "avg_logprob": -0.24926401319957914, "compression_ratio": 1.3988439306358382, "no_speech_prob": 0.1312180757522583}, {"id": 1, "seek": 0, "start": 15.36, "end": 17.64, "text": " so yeah, take it away.", "tokens": [370, 1338, 11, 747, 309, 1314, 13], "temperature": 0.0, "avg_logprob": -0.24926401319957914, "compression_ratio": 1.3988439306358382, "no_speech_prob": 0.1312180757522583}, {"id": 2, "seek": 0, "start": 17.64, "end": 18.64, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.24926401319957914, "compression_ratio": 1.3988439306358382, "no_speech_prob": 0.1312180757522583}, {"id": 3, "seek": 0, "start": 18.64, "end": 19.64, "text": " Can everyone hear me?", "tokens": [1664, 1518, 1568, 385, 30], "temperature": 0.0, "avg_logprob": -0.24926401319957914, "compression_ratio": 1.3988439306358382, "no_speech_prob": 0.1312180757522583}, {"id": 4, "seek": 0, "start": 19.64, "end": 20.64, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.24926401319957914, "compression_ratio": 1.3988439306358382, "no_speech_prob": 0.1312180757522583}, {"id": 5, "seek": 0, "start": 20.64, "end": 21.64, "text": " Good.", "tokens": [2205, 13], "temperature": 0.0, "avg_logprob": -0.24926401319957914, "compression_ratio": 1.3988439306358382, "no_speech_prob": 0.1312180757522583}, {"id": 6, "seek": 0, "start": 21.64, "end": 22.96, "text": " Thanks for coming.", "tokens": [2561, 337, 1348, 13], "temperature": 0.0, "avg_logprob": -0.24926401319957914, "compression_ratio": 1.3988439306358382, "no_speech_prob": 0.1312180757522583}, {"id": 7, "seek": 0, "start": 22.96, "end": 26.64, "text": " So my name is Orson, and I'm here to present GlideSort.", "tokens": [407, 452, 1315, 307, 1610, 3015, 11, 293, 286, 478, 510, 281, 1974, 5209, 482, 50, 477, 13], "temperature": 0.0, "avg_logprob": -0.24926401319957914, "compression_ratio": 1.3988439306358382, "no_speech_prob": 0.1312180757522583}, {"id": 8, "seek": 2664, "start": 26.64, "end": 31.6, "text": " I did this research at the CBI Database Architecture Group, GlideSort.", "tokens": [286, 630, 341, 2132, 412, 264, 383, 11291, 40461, 651, 43049, 10500, 11, 5209, 482, 50, 477, 13], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 9, "seek": 2664, "start": 31.6, "end": 32.6, "text": " What is it?", "tokens": [708, 307, 309, 30], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 10, "seek": 2664, "start": 32.6, "end": 35.760000000000005, "text": " It's a general purpose, stable comparison sort here.", "tokens": [467, 311, 257, 2674, 4334, 11, 8351, 9660, 1333, 510, 13], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 11, "seek": 2664, "start": 35.760000000000005, "end": 38.2, "text": " Does everyone here understand what that means?", "tokens": [4402, 1518, 510, 1223, 437, 300, 1355, 30], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 12, "seek": 2664, "start": 38.2, "end": 39.2, "text": " No.", "tokens": [883, 13], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 13, "seek": 2664, "start": 39.2, "end": 40.2, "text": " Oh, okay.", "tokens": [876, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 14, "seek": 2664, "start": 40.2, "end": 42.56, "text": " Well, good luck.", "tokens": [1042, 11, 665, 3668, 13], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 15, "seek": 2664, "start": 42.56, "end": 45.8, "text": " So stable means that it does not reorder equal elements.", "tokens": [407, 8351, 1355, 300, 309, 775, 406, 319, 4687, 2681, 4959, 13], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 16, "seek": 2664, "start": 45.8, "end": 49.88, "text": " They stay in the original order, so essentially it makes sorting deterministic.", "tokens": [814, 1754, 294, 264, 3380, 1668, 11, 370, 4476, 309, 1669, 32411, 15957, 3142, 13], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 17, "seek": 2664, "start": 49.88, "end": 52.040000000000006, "text": " GlideSort is a hybrid.", "tokens": [5209, 482, 50, 477, 307, 257, 13051, 13], "temperature": 0.0, "avg_logprob": -0.19674953845662807, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.0003158534236717969}, {"id": 18, "seek": 5204, "start": 52.04, "end": 56.8, "text": " It's a hybrid of merge sort, quicksort, and block insertion sort, which is a variant of", "tokens": [467, 311, 257, 13051, 295, 22183, 1333, 11, 1702, 82, 477, 11, 293, 3461, 8969, 313, 1333, 11, 597, 307, 257, 17501, 295], "temperature": 0.0, "avg_logprob": -0.17419800265081997, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.00010194200876867399}, {"id": 19, "seek": 5204, "start": 56.8, "end": 63.16, "text": " insertion sort, and it is robustly adaptive to pre-sorted and low cardinality inputs.", "tokens": [8969, 313, 1333, 11, 293, 309, 307, 13956, 356, 27912, 281, 659, 12, 82, 14813, 293, 2295, 2920, 259, 1860, 15743, 13], "temperature": 0.0, "avg_logprob": -0.17419800265081997, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.00010194200876867399}, {"id": 20, "seek": 5204, "start": 63.16, "end": 66.24, "text": " Don't worry, I'll talk about what that means.", "tokens": [1468, 380, 3292, 11, 286, 603, 751, 466, 437, 300, 1355, 13], "temperature": 0.0, "avg_logprob": -0.17419800265081997, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.00010194200876867399}, {"id": 21, "seek": 5204, "start": 66.24, "end": 71.52, "text": " I made a reference implementation in partially unsaved rust, and you can think of it if you're", "tokens": [286, 1027, 257, 6408, 11420, 294, 18886, 2693, 12865, 15259, 11, 293, 291, 393, 519, 295, 309, 498, 291, 434], "temperature": 0.0, "avg_logprob": -0.17419800265081997, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.00010194200876867399}, {"id": 22, "seek": 5204, "start": 71.52, "end": 76.56, "text": " programming a rust as a drop-in for the slice stable sort algorithm.", "tokens": [9410, 257, 15259, 382, 257, 3270, 12, 259, 337, 264, 13153, 8351, 1333, 9284, 13], "temperature": 0.0, "avg_logprob": -0.17419800265081997, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.00010194200876867399}, {"id": 23, "seek": 5204, "start": 76.56, "end": 79.0, "text": " So you might wonder, stable quicksort.", "tokens": [407, 291, 1062, 2441, 11, 8351, 1702, 82, 477, 13], "temperature": 0.0, "avg_logprob": -0.17419800265081997, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.00010194200876867399}, {"id": 24, "seek": 7900, "start": 79.0, "end": 82.92, "text": " The answer is yes.", "tokens": [440, 1867, 307, 2086, 13], "temperature": 0.0, "avg_logprob": -0.17900382147894967, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0001173950731754303}, {"id": 25, "seek": 7900, "start": 82.92, "end": 88.72, "text": " A guy named Igor von Den Hoven made a very, I don't know, he did very good work on flux", "tokens": [316, 2146, 4926, 40356, 2957, 6458, 3631, 553, 1027, 257, 588, 11, 286, 500, 380, 458, 11, 415, 630, 588, 665, 589, 322, 19298], "temperature": 0.0, "avg_logprob": -0.17900382147894967, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0001173950731754303}, {"id": 26, "seek": 7900, "start": 88.72, "end": 94.2, "text": " sort, where he showed that indeed you can do stable quicksort efficiently.", "tokens": [1333, 11, 689, 415, 4712, 300, 6451, 291, 393, 360, 8351, 1702, 82, 477, 19621, 13], "temperature": 0.0, "avg_logprob": -0.17900382147894967, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0001173950731754303}, {"id": 27, "seek": 7900, "start": 94.2, "end": 100.76, "text": " Wikipedia will tell you that quicksort is in place, that it is done using element exchanges,", "tokens": [28999, 486, 980, 291, 300, 1702, 82, 477, 307, 294, 1081, 11, 300, 309, 307, 1096, 1228, 4478, 27374, 11], "temperature": 0.0, "avg_logprob": -0.17900382147894967, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0001173950731754303}, {"id": 28, "seek": 7900, "start": 100.76, "end": 105.56, "text": " and that it will literally tell you efficient implementations of quicksort are not a stable", "tokens": [293, 300, 309, 486, 3736, 980, 291, 7148, 4445, 763, 295, 1702, 82, 477, 366, 406, 257, 8351], "temperature": 0.0, "avg_logprob": -0.17900382147894967, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0001173950731754303}, {"id": 29, "seek": 7900, "start": 105.56, "end": 106.56, "text": " sort.", "tokens": [1333, 13], "temperature": 0.0, "avg_logprob": -0.17900382147894967, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0001173950731754303}, {"id": 30, "seek": 10656, "start": 106.56, "end": 110.52, "text": " Wikipedia tells you, no, you cannot do it.", "tokens": [28999, 5112, 291, 11, 572, 11, 291, 2644, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.14272207532610212, "compression_ratio": 1.6283185840707965, "no_speech_prob": 7.275702228071168e-05}, {"id": 31, "seek": 10656, "start": 110.52, "end": 116.32000000000001, "text": " Standard stable sort uses extra memory to do its sorting, and if you tell people, hey,", "tokens": [21298, 8351, 1333, 4960, 2857, 4675, 281, 360, 1080, 32411, 11, 293, 498, 291, 980, 561, 11, 4177, 11], "temperature": 0.0, "avg_logprob": -0.14272207532610212, "compression_ratio": 1.6283185840707965, "no_speech_prob": 7.275702228071168e-05}, {"id": 32, "seek": 10656, "start": 116.32000000000001, "end": 120.52000000000001, "text": " you can do the same with stable quicksort, they completely lose their minds.", "tokens": [291, 393, 360, 264, 912, 365, 8351, 1702, 82, 477, 11, 436, 2584, 3624, 641, 9634, 13], "temperature": 0.0, "avg_logprob": -0.14272207532610212, "compression_ratio": 1.6283185840707965, "no_speech_prob": 7.275702228071168e-05}, {"id": 33, "seek": 10656, "start": 120.52000000000001, "end": 122.96000000000001, "text": " No quicksort is in place, you cannot do that.", "tokens": [883, 1702, 82, 477, 307, 294, 1081, 11, 291, 2644, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.14272207532610212, "compression_ratio": 1.6283185840707965, "no_speech_prob": 7.275702228071168e-05}, {"id": 34, "seek": 10656, "start": 122.96000000000001, "end": 123.96000000000001, "text": " That's not true.", "tokens": [663, 311, 406, 2074, 13], "temperature": 0.0, "avg_logprob": -0.14272207532610212, "compression_ratio": 1.6283185840707965, "no_speech_prob": 7.275702228071168e-05}, {"id": 35, "seek": 10656, "start": 123.96000000000001, "end": 127.84, "text": " You can, and you probably should.", "tokens": [509, 393, 11, 293, 291, 1391, 820, 13], "temperature": 0.0, "avg_logprob": -0.14272207532610212, "compression_ratio": 1.6283185840707965, "no_speech_prob": 7.275702228071168e-05}, {"id": 36, "seek": 10656, "start": 127.84, "end": 130.04, "text": " So earlier I mentioned adaptive sorting.", "tokens": [407, 3071, 286, 2835, 27912, 32411, 13], "temperature": 0.0, "avg_logprob": -0.14272207532610212, "compression_ratio": 1.6283185840707965, "no_speech_prob": 7.275702228071168e-05}, {"id": 37, "seek": 10656, "start": 130.04, "end": 131.76, "text": " What do I mean by that?", "tokens": [708, 360, 286, 914, 538, 300, 30], "temperature": 0.0, "avg_logprob": -0.14272207532610212, "compression_ratio": 1.6283185840707965, "no_speech_prob": 7.275702228071168e-05}, {"id": 38, "seek": 13176, "start": 131.76, "end": 138.35999999999999, "text": " To adapt is to change your behavior to deal with new information or a new situation.", "tokens": [1407, 6231, 307, 281, 1319, 428, 5223, 281, 2028, 365, 777, 1589, 420, 257, 777, 2590, 13], "temperature": 0.0, "avg_logprob": -0.2037648136175952, "compression_ratio": 1.812206572769953, "no_speech_prob": 0.00015090047963894904}, {"id": 39, "seek": 13176, "start": 138.35999999999999, "end": 145.2, "text": " And there are two ways that you can be adaptive, in my opinion, major ways you can be adaptive", "tokens": [400, 456, 366, 732, 2098, 300, 291, 393, 312, 27912, 11, 294, 452, 4800, 11, 2563, 2098, 291, 393, 312, 27912], "temperature": 0.0, "avg_logprob": -0.2037648136175952, "compression_ratio": 1.812206572769953, "no_speech_prob": 0.00015090047963894904}, {"id": 40, "seek": 13176, "start": 145.2, "end": 147.28, "text": " in sorting.", "tokens": [294, 32411, 13], "temperature": 0.0, "avg_logprob": -0.2037648136175952, "compression_ratio": 1.812206572769953, "no_speech_prob": 0.00015090047963894904}, {"id": 41, "seek": 13176, "start": 147.28, "end": 149.72, "text": " And they correspond to two schools of sorting.", "tokens": [400, 436, 6805, 281, 732, 4656, 295, 32411, 13], "temperature": 0.0, "avg_logprob": -0.2037648136175952, "compression_ratio": 1.812206572769953, "no_speech_prob": 0.00015090047963894904}, {"id": 42, "seek": 13176, "start": 149.72, "end": 152.0, "text": " There is the bottom-up school of sorting.", "tokens": [821, 307, 264, 2767, 12, 1010, 1395, 295, 32411, 13], "temperature": 0.0, "avg_logprob": -0.2037648136175952, "compression_ratio": 1.812206572769953, "no_speech_prob": 0.00015090047963894904}, {"id": 43, "seek": 13176, "start": 152.0, "end": 156.88, "text": " Those are your merge sorts, or your mergers variance, like dimsort and powersort.", "tokens": [3950, 366, 428, 22183, 7527, 11, 420, 428, 3551, 9458, 21977, 11, 411, 5013, 82, 477, 293, 8674, 477, 13], "temperature": 0.0, "avg_logprob": -0.2037648136175952, "compression_ratio": 1.812206572769953, "no_speech_prob": 0.00015090047963894904}, {"id": 44, "seek": 13176, "start": 156.88, "end": 158.2, "text": " And they are bottom-up.", "tokens": [400, 436, 366, 2767, 12, 1010, 13], "temperature": 0.0, "avg_logprob": -0.2037648136175952, "compression_ratio": 1.812206572769953, "no_speech_prob": 0.00015090047963894904}, {"id": 45, "seek": 15820, "start": 158.2, "end": 163.48, "text": " They construct larger and larger sorted sequences from smaller sort of sequences.", "tokens": [814, 7690, 4833, 293, 4833, 25462, 22978, 490, 4356, 1333, 295, 22978, 13], "temperature": 0.0, "avg_logprob": -0.1524638528898945, "compression_ratio": 1.8029739776951672, "no_speech_prob": 0.00014091840421315283}, {"id": 46, "seek": 15820, "start": 163.48, "end": 167.79999999999998, "text": " They are often presented in a schoolbook way top-down, but really fundamentally they are", "tokens": [814, 366, 2049, 8212, 294, 257, 1395, 2939, 636, 1192, 12, 5093, 11, 457, 534, 17879, 436, 366], "temperature": 0.0, "avg_logprob": -0.1524638528898945, "compression_ratio": 1.8029739776951672, "no_speech_prob": 0.00014091840421315283}, {"id": 47, "seek": 15820, "start": 167.79999999999998, "end": 168.79999999999998, "text": " bottom-up.", "tokens": [2767, 12, 1010, 13], "temperature": 0.0, "avg_logprob": -0.1524638528898945, "compression_ratio": 1.8029739776951672, "no_speech_prob": 0.00014091840421315283}, {"id": 48, "seek": 15820, "start": 168.79999999999998, "end": 171.2, "text": " And that way they can be adaptive to pre-sorted runs.", "tokens": [400, 300, 636, 436, 393, 312, 27912, 281, 659, 12, 82, 477, 292, 6676, 13], "temperature": 0.0, "avg_logprob": -0.1524638528898945, "compression_ratio": 1.8029739776951672, "no_speech_prob": 0.00014091840421315283}, {"id": 49, "seek": 15820, "start": 171.2, "end": 175.32, "text": " If there's already pre-sorted running your input, you can just take that as is and continue", "tokens": [759, 456, 311, 1217, 659, 12, 82, 477, 292, 2614, 428, 4846, 11, 291, 393, 445, 747, 300, 382, 307, 293, 2354], "temperature": 0.0, "avg_logprob": -0.1524638528898945, "compression_ratio": 1.8029739776951672, "no_speech_prob": 0.00014091840421315283}, {"id": 50, "seek": 15820, "start": 175.32, "end": 176.82, "text": " merging up.", "tokens": [44559, 493, 13], "temperature": 0.0, "avg_logprob": -0.1524638528898945, "compression_ratio": 1.8029739776951672, "no_speech_prob": 0.00014091840421315283}, {"id": 51, "seek": 15820, "start": 176.82, "end": 180.0, "text": " There's also the partition school of sorts.", "tokens": [821, 311, 611, 264, 24808, 1395, 295, 7527, 13], "temperature": 0.0, "avg_logprob": -0.1524638528898945, "compression_ratio": 1.8029739776951672, "no_speech_prob": 0.00014091840421315283}, {"id": 52, "seek": 15820, "start": 180.0, "end": 183.28, "text": " Those are your quicksort, your sample sorts, your radix sorts.", "tokens": [3950, 366, 428, 1702, 82, 477, 11, 428, 6889, 7527, 11, 428, 2843, 970, 7527, 13], "temperature": 0.0, "avg_logprob": -0.1524638528898945, "compression_ratio": 1.8029739776951672, "no_speech_prob": 0.00014091840421315283}, {"id": 53, "seek": 15820, "start": 183.28, "end": 187.07999999999998, "text": " They partition out or distribute data.", "tokens": [814, 24808, 484, 420, 20594, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1524638528898945, "compression_ratio": 1.8029739776951672, "no_speech_prob": 0.00014091840421315283}, {"id": 54, "seek": 18708, "start": 187.08, "end": 188.56, "text": " They are fundamentally top-down.", "tokens": [814, 366, 17879, 1192, 12, 5093, 13], "temperature": 0.0, "avg_logprob": -0.12497351920768006, "compression_ratio": 1.975, "no_speech_prob": 8.47813134896569e-05}, {"id": 55, "seek": 18708, "start": 188.56, "end": 192.24, "text": " You start at the higher, and you partition to smaller, smaller, smaller.", "tokens": [509, 722, 412, 264, 2946, 11, 293, 291, 24808, 281, 4356, 11, 4356, 11, 4356, 13], "temperature": 0.0, "avg_logprob": -0.12497351920768006, "compression_ratio": 1.975, "no_speech_prob": 8.47813134896569e-05}, {"id": 56, "seek": 18708, "start": 192.24, "end": 196.84, "text": " Subpartitions, and that way they can be adaptive to low cardinality inputs.", "tokens": [8511, 6971, 2451, 11, 293, 300, 636, 436, 393, 312, 27912, 281, 2295, 2920, 259, 1860, 15743, 13], "temperature": 0.0, "avg_logprob": -0.12497351920768006, "compression_ratio": 1.975, "no_speech_prob": 8.47813134896569e-05}, {"id": 57, "seek": 18708, "start": 196.84, "end": 199.72000000000003, "text": " So what are low cardinality inputs?", "tokens": [407, 437, 366, 2295, 2920, 259, 1860, 15743, 30], "temperature": 0.0, "avg_logprob": -0.12497351920768006, "compression_ratio": 1.975, "no_speech_prob": 8.47813134896569e-05}, {"id": 58, "seek": 18708, "start": 199.72000000000003, "end": 203.96, "text": " Essentially you have a lot of data, and you're sorting it by a subset of the data.", "tokens": [23596, 291, 362, 257, 688, 295, 1412, 11, 293, 291, 434, 32411, 309, 538, 257, 25993, 295, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12497351920768006, "compression_ratio": 1.975, "no_speech_prob": 8.47813134896569e-05}, {"id": 59, "seek": 18708, "start": 203.96, "end": 207.92000000000002, "text": " So you're sorting your customers, but you're sorting them by which city they live in.", "tokens": [407, 291, 434, 32411, 428, 4581, 11, 457, 291, 434, 32411, 552, 538, 597, 2307, 436, 1621, 294, 13], "temperature": 0.0, "avg_logprob": -0.12497351920768006, "compression_ratio": 1.975, "no_speech_prob": 8.47813134896569e-05}, {"id": 60, "seek": 18708, "start": 207.92000000000002, "end": 211.04000000000002, "text": " Or you're sorting your cars, but you're sorting by the brand of the car.", "tokens": [1610, 291, 434, 32411, 428, 5163, 11, 457, 291, 434, 32411, 538, 264, 3360, 295, 264, 1032, 13], "temperature": 0.0, "avg_logprob": -0.12497351920768006, "compression_ratio": 1.975, "no_speech_prob": 8.47813134896569e-05}, {"id": 61, "seek": 18708, "start": 211.04000000000002, "end": 215.4, "text": " And even though you might have hundreds of thousands of cars, you might only have 100", "tokens": [400, 754, 1673, 291, 1062, 362, 6779, 295, 5383, 295, 5163, 11, 291, 1062, 787, 362, 2319], "temperature": 0.0, "avg_logprob": -0.12497351920768006, "compression_ratio": 1.975, "no_speech_prob": 8.47813134896569e-05}, {"id": 62, "seek": 18708, "start": 215.4, "end": 216.4, "text": " brands.", "tokens": [11324, 13], "temperature": 0.0, "avg_logprob": -0.12497351920768006, "compression_ratio": 1.975, "no_speech_prob": 8.47813134896569e-05}, {"id": 63, "seek": 21640, "start": 216.4, "end": 222.28, "text": " So essentially duplicates, at least from the perspective of a comparison operator.", "tokens": [407, 4476, 17154, 1024, 11, 412, 1935, 490, 264, 4585, 295, 257, 9660, 12973, 13], "temperature": 0.0, "avg_logprob": -0.15562236055414727, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0001105927221942693}, {"id": 64, "seek": 21640, "start": 222.28, "end": 225.64000000000001, "text": " So how does adaptive quicksort deal with that?", "tokens": [407, 577, 775, 27912, 1702, 82, 477, 2028, 365, 300, 30], "temperature": 0.0, "avg_logprob": -0.15562236055414727, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0001105927221942693}, {"id": 65, "seek": 21640, "start": 225.64000000000001, "end": 230.72, "text": " The idea is that during partitioning, we can detect buckets of elements that are all equal", "tokens": [440, 1558, 307, 300, 1830, 24808, 278, 11, 321, 393, 5531, 32191, 295, 4959, 300, 366, 439, 2681], "temperature": 0.0, "avg_logprob": -0.15562236055414727, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0001105927221942693}, {"id": 66, "seek": 21640, "start": 230.72, "end": 232.44, "text": " to each other.", "tokens": [281, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.15562236055414727, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0001105927221942693}, {"id": 67, "seek": 21640, "start": 232.44, "end": 235.44, "text": " And there's a challenge with doing that.", "tokens": [400, 456, 311, 257, 3430, 365, 884, 300, 13], "temperature": 0.0, "avg_logprob": -0.15562236055414727, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0001105927221942693}, {"id": 68, "seek": 21640, "start": 235.44, "end": 239.0, "text": " You don't want to do extra unnecessary comparisons.", "tokens": [509, 500, 380, 528, 281, 360, 2857, 19350, 33157, 13], "temperature": 0.0, "avg_logprob": -0.15562236055414727, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0001105927221942693}, {"id": 69, "seek": 21640, "start": 239.0, "end": 241.12, "text": " And we actually want to avoid three-way comparisons.", "tokens": [400, 321, 767, 528, 281, 5042, 1045, 12, 676, 33157, 13], "temperature": 0.0, "avg_logprob": -0.15562236055414727, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0001105927221942693}, {"id": 70, "seek": 24112, "start": 241.12, "end": 248.04, "text": " That's a bit funny, because Rust's basic ORT trait uses three-way comparisons.", "tokens": [663, 311, 257, 857, 4074, 11, 570, 34952, 311, 3875, 19654, 51, 22538, 4960, 1045, 12, 676, 33157, 13], "temperature": 0.0, "avg_logprob": -0.2069287341573964, "compression_ratio": 1.7004219409282701, "no_speech_prob": 0.00023863124079070985}, {"id": 71, "seek": 24112, "start": 248.04, "end": 249.44, "text": " But that's a lie.", "tokens": [583, 300, 311, 257, 4544, 13], "temperature": 0.0, "avg_logprob": -0.2069287341573964, "compression_ratio": 1.7004219409282701, "no_speech_prob": 0.00023863124079070985}, {"id": 72, "seek": 24112, "start": 249.44, "end": 253.76, "text": " Under the hood, we turn that back into a two-way comparison, because computers aren't very", "tokens": [6974, 264, 13376, 11, 321, 1261, 300, 646, 666, 257, 732, 12, 676, 9660, 11, 570, 10807, 3212, 380, 588], "temperature": 0.0, "avg_logprob": -0.2069287341573964, "compression_ratio": 1.7004219409282701, "no_speech_prob": 0.00023863124079070985}, {"id": 73, "seek": 24112, "start": 253.76, "end": 255.04, "text": " good at turner logic.", "tokens": [665, 412, 1261, 260, 9952, 13], "temperature": 0.0, "avg_logprob": -0.2069287341573964, "compression_ratio": 1.7004219409282701, "no_speech_prob": 0.00023863124079070985}, {"id": 74, "seek": 24112, "start": 255.04, "end": 256.32, "text": " They really love binary logic.", "tokens": [814, 534, 959, 17434, 9952, 13], "temperature": 0.0, "avg_logprob": -0.2069287341573964, "compression_ratio": 1.7004219409282701, "no_speech_prob": 0.00023863124079070985}, {"id": 75, "seek": 24112, "start": 256.32, "end": 257.72, "text": " They love ifs and else.", "tokens": [814, 959, 498, 82, 293, 1646, 13], "temperature": 0.0, "avg_logprob": -0.2069287341573964, "compression_ratio": 1.7004219409282701, "no_speech_prob": 0.00023863124079070985}, {"id": 76, "seek": 24112, "start": 257.72, "end": 261.6, "text": " So we still turn that back into two-way comparisons.", "tokens": [407, 321, 920, 1261, 300, 646, 666, 732, 12, 676, 33157, 13], "temperature": 0.0, "avg_logprob": -0.2069287341573964, "compression_ratio": 1.7004219409282701, "no_speech_prob": 0.00023863124079070985}, {"id": 77, "seek": 24112, "start": 261.6, "end": 268.6, "text": " And there's been a long history on adaptive quicksorts in this way, with Dijkstra and", "tokens": [400, 456, 311, 668, 257, 938, 2503, 322, 27912, 1702, 82, 3299, 294, 341, 636, 11, 365, 413, 6940, 19639, 293], "temperature": 0.0, "avg_logprob": -0.2069287341573964, "compression_ratio": 1.7004219409282701, "no_speech_prob": 0.00023863124079070985}, {"id": 78, "seek": 26860, "start": 268.6, "end": 274.28000000000003, "text": " Hauer, I still don't know how to pronounce that, working on it.", "tokens": [389, 18120, 11, 286, 920, 500, 380, 458, 577, 281, 19567, 300, 11, 1364, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.179815673828125, "compression_ratio": 1.649805447470817, "no_speech_prob": 0.0002926780143752694}, {"id": 79, "seek": 26860, "start": 274.28000000000003, "end": 279.64000000000004, "text": " And already, time flies, eight years ago, I showed that in pattern defeating quicksort", "tokens": [400, 1217, 11, 565, 17414, 11, 3180, 924, 2057, 11, 286, 4712, 300, 294, 5102, 38381, 1702, 82, 477], "temperature": 0.0, "avg_logprob": -0.179815673828125, "compression_ratio": 1.649805447470817, "no_speech_prob": 0.0002926780143752694}, {"id": 80, "seek": 26860, "start": 279.64000000000004, "end": 283.52000000000004, "text": " that you can detect this and handle this very efficiently.", "tokens": [300, 291, 393, 5531, 341, 293, 4813, 341, 588, 19621, 13], "temperature": 0.0, "avg_logprob": -0.179815673828125, "compression_ratio": 1.649805447470817, "no_speech_prob": 0.0002926780143752694}, {"id": 81, "seek": 26860, "start": 283.52000000000004, "end": 284.68, "text": " So how does that work?", "tokens": [407, 577, 775, 300, 589, 30], "temperature": 0.0, "avg_logprob": -0.179815673828125, "compression_ratio": 1.649805447470817, "no_speech_prob": 0.0002926780143752694}, {"id": 82, "seek": 26860, "start": 284.68, "end": 289.48, "text": " I have an entire earlier talk on PDQ sort that you can watch if you're interested in", "tokens": [286, 362, 364, 2302, 3071, 751, 322, 10464, 48, 1333, 300, 291, 393, 1159, 498, 291, 434, 3102, 294], "temperature": 0.0, "avg_logprob": -0.179815673828125, "compression_ratio": 1.649805447470817, "no_speech_prob": 0.0002926780143752694}, {"id": 83, "seek": 26860, "start": 289.48, "end": 290.48, "text": " this.", "tokens": [341, 13], "temperature": 0.0, "avg_logprob": -0.179815673828125, "compression_ratio": 1.649805447470817, "no_speech_prob": 0.0002926780143752694}, {"id": 84, "seek": 26860, "start": 290.48, "end": 292.44, "text": " But essentially, we have two different partition strategies.", "tokens": [583, 4476, 11, 321, 362, 732, 819, 24808, 9029, 13], "temperature": 0.0, "avg_logprob": -0.179815673828125, "compression_ratio": 1.649805447470817, "no_speech_prob": 0.0002926780143752694}, {"id": 85, "seek": 26860, "start": 292.44, "end": 294.96000000000004, "text": " A partition left and a partition right.", "tokens": [316, 24808, 1411, 293, 257, 24808, 558, 13], "temperature": 0.0, "avg_logprob": -0.179815673828125, "compression_ratio": 1.649805447470817, "no_speech_prob": 0.0002926780143752694}, {"id": 86, "seek": 29496, "start": 294.96, "end": 298.56, "text": " The partition left puts elements equal to the pivot on the left.", "tokens": [440, 24808, 1411, 8137, 4959, 2681, 281, 264, 14538, 322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.10176507816758266, "compression_ratio": 2.1652542372881354, "no_speech_prob": 4.891788921668194e-05}, {"id": 87, "seek": 29496, "start": 298.56, "end": 301.96, "text": " And the partition right puts equal elements on the right.", "tokens": [400, 264, 24808, 558, 8137, 2681, 4959, 322, 264, 558, 13], "temperature": 0.0, "avg_logprob": -0.10176507816758266, "compression_ratio": 2.1652542372881354, "no_speech_prob": 4.891788921668194e-05}, {"id": 88, "seek": 29496, "start": 301.96, "end": 307.56, "text": " And what you do is, when you select a pivot, you check if that pivot is equal to a pivot", "tokens": [400, 437, 291, 360, 307, 11, 562, 291, 3048, 257, 14538, 11, 291, 1520, 498, 300, 14538, 307, 2681, 281, 257, 14538], "temperature": 0.0, "avg_logprob": -0.10176507816758266, "compression_ratio": 2.1652542372881354, "no_speech_prob": 4.891788921668194e-05}, {"id": 89, "seek": 29496, "start": 307.56, "end": 308.56, "text": " we used previously.", "tokens": [321, 1143, 8046, 13], "temperature": 0.0, "avg_logprob": -0.10176507816758266, "compression_ratio": 2.1652542372881354, "no_speech_prob": 4.891788921668194e-05}, {"id": 90, "seek": 29496, "start": 308.56, "end": 314.44, "text": " And you can do this efficiently using a single extra comparison during partitioning, or at", "tokens": [400, 291, 393, 360, 341, 19621, 1228, 257, 2167, 2857, 9660, 1830, 24808, 278, 11, 420, 412], "temperature": 0.0, "avg_logprob": -0.10176507816758266, "compression_ratio": 2.1652542372881354, "no_speech_prob": 4.891788921668194e-05}, {"id": 91, "seek": 29496, "start": 314.44, "end": 316.2, "text": " least pivot selection.", "tokens": [1935, 14538, 9450, 13], "temperature": 0.0, "avg_logprob": -0.10176507816758266, "compression_ratio": 2.1652542372881354, "no_speech_prob": 4.891788921668194e-05}, {"id": 92, "seek": 29496, "start": 316.2, "end": 319.15999999999997, "text": " And the default is that you put the equal elements on the right.", "tokens": [400, 264, 7576, 307, 300, 291, 829, 264, 2681, 4959, 322, 264, 558, 13], "temperature": 0.0, "avg_logprob": -0.10176507816758266, "compression_ratio": 2.1652542372881354, "no_speech_prob": 4.891788921668194e-05}, {"id": 93, "seek": 29496, "start": 319.15999999999997, "end": 323.03999999999996, "text": " But if you detect, hey, this pivot is equal to a previous pivot, you put equal elements", "tokens": [583, 498, 291, 5531, 11, 4177, 11, 341, 14538, 307, 2681, 281, 257, 3894, 14538, 11, 291, 829, 2681, 4959], "temperature": 0.0, "avg_logprob": -0.10176507816758266, "compression_ratio": 2.1652542372881354, "no_speech_prob": 4.891788921668194e-05}, {"id": 94, "seek": 29496, "start": 323.03999999999996, "end": 324.03999999999996, "text": " on the left.", "tokens": [322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.10176507816758266, "compression_ratio": 2.1652542372881354, "no_speech_prob": 4.891788921668194e-05}, {"id": 95, "seek": 32404, "start": 324.04, "end": 329.32, "text": " And this way, you implicitly do a three-way partition using two-way comparisons.", "tokens": [400, 341, 636, 11, 291, 26947, 356, 360, 257, 1045, 12, 676, 24808, 1228, 732, 12, 676, 33157, 13], "temperature": 0.0, "avg_logprob": -0.1436992883682251, "compression_ratio": 1.7056603773584906, "no_speech_prob": 8.647271170048043e-05}, {"id": 96, "seek": 32404, "start": 329.32, "end": 335.20000000000005, "text": " And you can prove that, on average, this means that your sort is o n log k, where k is the", "tokens": [400, 291, 393, 7081, 300, 11, 322, 4274, 11, 341, 1355, 300, 428, 1333, 307, 277, 297, 3565, 350, 11, 689, 350, 307, 264], "temperature": 0.0, "avg_logprob": -0.1436992883682251, "compression_ratio": 1.7056603773584906, "no_speech_prob": 8.647271170048043e-05}, {"id": 97, "seek": 32404, "start": 335.20000000000005, "end": 336.52000000000004, "text": " number of distinct values.", "tokens": [1230, 295, 10644, 4190, 13], "temperature": 0.0, "avg_logprob": -0.1436992883682251, "compression_ratio": 1.7056603773584906, "no_speech_prob": 8.647271170048043e-05}, {"id": 98, "seek": 32404, "start": 336.52000000000004, "end": 340.16, "text": " If every value is distinct, that becomes o n log n, we're used to that.", "tokens": [759, 633, 2158, 307, 10644, 11, 300, 3643, 277, 297, 3565, 297, 11, 321, 434, 1143, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.1436992883682251, "compression_ratio": 1.7056603773584906, "no_speech_prob": 8.647271170048043e-05}, {"id": 99, "seek": 32404, "start": 340.16, "end": 346.76, "text": " But if you have a lot of duplicate values, o n log k goes a lot faster than n log n.", "tokens": [583, 498, 291, 362, 257, 688, 295, 23976, 4190, 11, 277, 297, 3565, 350, 1709, 257, 688, 4663, 813, 297, 3565, 297, 13], "temperature": 0.0, "avg_logprob": -0.1436992883682251, "compression_ratio": 1.7056603773584906, "no_speech_prob": 8.647271170048043e-05}, {"id": 100, "seek": 32404, "start": 346.76, "end": 349.52000000000004, "text": " There's also adaptive merge sort.", "tokens": [821, 311, 611, 27912, 22183, 1333, 13], "temperature": 0.0, "avg_logprob": -0.1436992883682251, "compression_ratio": 1.7056603773584906, "no_speech_prob": 8.647271170048043e-05}, {"id": 101, "seek": 32404, "start": 349.52000000000004, "end": 353.56, "text": " As I said earlier, these merge pre-existing runs in the input.", "tokens": [1018, 286, 848, 3071, 11, 613, 22183, 659, 12, 36447, 6676, 294, 264, 4846, 13], "temperature": 0.0, "avg_logprob": -0.1436992883682251, "compression_ratio": 1.7056603773584906, "no_speech_prob": 8.647271170048043e-05}, {"id": 102, "seek": 35356, "start": 353.56, "end": 358.8, "text": " The problem with solving this is that you want to minimize the amount of unbalanced mergers", "tokens": [440, 1154, 365, 12606, 341, 307, 300, 291, 528, 281, 17522, 264, 2372, 295, 517, 40251, 3551, 9458], "temperature": 0.0, "avg_logprob": -0.0991415712568495, "compression_ratio": 1.7238493723849373, "no_speech_prob": 0.0001545719860587269}, {"id": 103, "seek": 35356, "start": 358.8, "end": 359.8, "text": " that you do.", "tokens": [300, 291, 360, 13], "temperature": 0.0, "avg_logprob": -0.0991415712568495, "compression_ratio": 1.7238493723849373, "no_speech_prob": 0.0001545719860587269}, {"id": 104, "seek": 35356, "start": 359.8, "end": 364.68, "text": " So you don't want to merge a very large array with a very small array, because that's quite", "tokens": [407, 291, 500, 380, 528, 281, 22183, 257, 588, 2416, 10225, 365, 257, 588, 1359, 10225, 11, 570, 300, 311, 1596], "temperature": 0.0, "avg_logprob": -0.0991415712568495, "compression_ratio": 1.7238493723849373, "no_speech_prob": 0.0001545719860587269}, {"id": 105, "seek": 35356, "start": 364.68, "end": 366.48, "text": " inefficient.", "tokens": [43495, 13], "temperature": 0.0, "avg_logprob": -0.0991415712568495, "compression_ratio": 1.7238493723849373, "no_speech_prob": 0.0001545719860587269}, {"id": 106, "seek": 35356, "start": 366.48, "end": 373.52, "text": " And you also want to somehow store, during your algorithm, where the runs are in memory.", "tokens": [400, 291, 611, 528, 281, 6063, 3531, 11, 1830, 428, 9284, 11, 689, 264, 6676, 366, 294, 4675, 13], "temperature": 0.0, "avg_logprob": -0.0991415712568495, "compression_ratio": 1.7238493723849373, "no_speech_prob": 0.0001545719860587269}, {"id": 107, "seek": 35356, "start": 373.52, "end": 378.52, "text": " And if you do this in an illogical way, you have to potentially store a lot of data about", "tokens": [400, 498, 291, 360, 341, 294, 364, 3171, 664, 804, 636, 11, 291, 362, 281, 7263, 3531, 257, 688, 295, 1412, 466], "temperature": 0.0, "avg_logprob": -0.0991415712568495, "compression_ratio": 1.7238493723849373, "no_speech_prob": 0.0001545719860587269}, {"id": 108, "seek": 35356, "start": 378.52, "end": 381.28, "text": " where all the runs are.", "tokens": [689, 439, 264, 6676, 366, 13], "temperature": 0.0, "avg_logprob": -0.0991415712568495, "compression_ratio": 1.7238493723849373, "no_speech_prob": 0.0001545719860587269}, {"id": 109, "seek": 38128, "start": 381.28, "end": 388.47999999999996, "text": " And Van Neumann invented merge sort very early, and Knuth described also quite early a natural", "tokens": [400, 8979, 1734, 449, 969, 14479, 22183, 1333, 588, 2440, 11, 293, 10519, 2910, 7619, 611, 1596, 2440, 257, 3303], "temperature": 0.0, "avg_logprob": -0.12946292332240514, "compression_ratio": 1.5634920634920635, "no_speech_prob": 0.0001301050651818514}, {"id": 110, "seek": 38128, "start": 388.47999999999996, "end": 391.9, "text": " merge sort that takes advantage of pre-existing runs in the input.", "tokens": [22183, 1333, 300, 2516, 5002, 295, 659, 12, 36447, 6676, 294, 264, 4846, 13], "temperature": 0.0, "avg_logprob": -0.12946292332240514, "compression_ratio": 1.5634920634920635, "no_speech_prob": 0.0001301050651818514}, {"id": 111, "seek": 38128, "start": 391.9, "end": 396.2, "text": " And then, in particular, Tim Peters popularized Tim sort, which became the default sorting", "tokens": [400, 550, 11, 294, 1729, 11, 7172, 26028, 3743, 1602, 7172, 1333, 11, 597, 3062, 264, 7576, 32411], "temperature": 0.0, "avg_logprob": -0.12946292332240514, "compression_ratio": 1.5634920634920635, "no_speech_prob": 0.0001301050651818514}, {"id": 112, "seek": 38128, "start": 396.2, "end": 403.64, "text": " algorithm in Python, that really showed the first sort of clever way to keep track of", "tokens": [9284, 294, 15329, 11, 300, 534, 4712, 264, 700, 1333, 295, 13494, 636, 281, 1066, 2837, 295], "temperature": 0.0, "avg_logprob": -0.12946292332240514, "compression_ratio": 1.5634920634920635, "no_speech_prob": 0.0001301050651818514}, {"id": 113, "seek": 38128, "start": 403.64, "end": 408.28, "text": " your run information and minimizing unbalanced mergers.", "tokens": [428, 1190, 1589, 293, 46608, 517, 40251, 3551, 9458, 13], "temperature": 0.0, "avg_logprob": -0.12946292332240514, "compression_ratio": 1.5634920634920635, "no_speech_prob": 0.0001301050651818514}, {"id": 114, "seek": 40828, "start": 408.28, "end": 415.23999999999995, "text": " The recent work is PowerSort, which extends on Tim sort essentially, or has the same logic,", "tokens": [440, 5162, 589, 307, 7086, 50, 477, 11, 597, 26448, 322, 7172, 1333, 4476, 11, 420, 575, 264, 912, 9952, 11], "temperature": 0.0, "avg_logprob": -0.14241903256147337, "compression_ratio": 1.6394052044609666, "no_speech_prob": 3.73866714653559e-05}, {"id": 115, "seek": 40828, "start": 415.23999999999995, "end": 423.59999999999997, "text": " but more clever logic, and actually has mathematical proofs that it creates balanced merge sequences.", "tokens": [457, 544, 13494, 9952, 11, 293, 767, 575, 18894, 8177, 82, 300, 309, 7829, 13902, 22183, 22978, 13], "temperature": 0.0, "avg_logprob": -0.14241903256147337, "compression_ratio": 1.6394052044609666, "no_speech_prob": 3.73866714653559e-05}, {"id": 116, "seek": 40828, "start": 423.59999999999997, "end": 428.03999999999996, "text": " And in fact, Python, I believe, now uses PowerSort's logic as well.", "tokens": [400, 294, 1186, 11, 15329, 11, 286, 1697, 11, 586, 4960, 7086, 50, 477, 311, 9952, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.14241903256147337, "compression_ratio": 1.6394052044609666, "no_speech_prob": 3.73866714653559e-05}, {"id": 117, "seek": 40828, "start": 428.03999999999996, "end": 431.08, "text": " So I'm not going to go into detail on how PowerSort works.", "tokens": [407, 286, 478, 406, 516, 281, 352, 666, 2607, 322, 577, 7086, 50, 477, 1985, 13], "temperature": 0.0, "avg_logprob": -0.14241903256147337, "compression_ratio": 1.6394052044609666, "no_speech_prob": 3.73866714653559e-05}, {"id": 118, "seek": 40828, "start": 431.08, "end": 432.91999999999996, "text": " I don't have enough time for that.", "tokens": [286, 500, 380, 362, 1547, 565, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.14241903256147337, "compression_ratio": 1.6394052044609666, "no_speech_prob": 3.73866714653559e-05}, {"id": 119, "seek": 40828, "start": 432.91999999999996, "end": 438.15999999999997, "text": " But essentially, the core loop of it is that you create a run, and that can either be", "tokens": [583, 4476, 11, 264, 4965, 6367, 295, 309, 307, 300, 291, 1884, 257, 1190, 11, 293, 300, 393, 2139, 312], "temperature": 0.0, "avg_logprob": -0.14241903256147337, "compression_ratio": 1.6394052044609666, "no_speech_prob": 3.73866714653559e-05}, {"id": 120, "seek": 43816, "start": 438.16, "end": 444.68, "text": " by finding the run in the input or doing a small sorting algorithm to create a small run.", "tokens": [538, 5006, 264, 1190, 294, 264, 4846, 420, 884, 257, 1359, 32411, 9284, 281, 1884, 257, 1359, 1190, 13], "temperature": 0.0, "avg_logprob": -0.1259677495275225, "compression_ratio": 1.7542372881355932, "no_speech_prob": 8.613101817900315e-05}, {"id": 121, "seek": 43816, "start": 444.68, "end": 446.04, "text": " You compute the power of a run.", "tokens": [509, 14722, 264, 1347, 295, 257, 1190, 13], "temperature": 0.0, "avg_logprob": -0.1259677495275225, "compression_ratio": 1.7542372881355932, "no_speech_prob": 8.613101817900315e-05}, {"id": 122, "seek": 43816, "start": 446.04, "end": 448.8, "text": " That's the heuristics I'm not going to get into.", "tokens": [663, 311, 264, 415, 374, 6006, 286, 478, 406, 516, 281, 483, 666, 13], "temperature": 0.0, "avg_logprob": -0.1259677495275225, "compression_ratio": 1.7542372881355932, "no_speech_prob": 8.613101817900315e-05}, {"id": 123, "seek": 43816, "start": 448.8, "end": 456.08000000000004, "text": " And then you keep a stack of runs, and then use this power heuristic that we computed", "tokens": [400, 550, 291, 1066, 257, 8630, 295, 6676, 11, 293, 550, 764, 341, 1347, 415, 374, 3142, 300, 321, 40610], "temperature": 0.0, "avg_logprob": -0.1259677495275225, "compression_ratio": 1.7542372881355932, "no_speech_prob": 8.613101817900315e-05}, {"id": 124, "seek": 43816, "start": 456.08000000000004, "end": 458.52000000000004, "text": " to decide when to merge two runs.", "tokens": [281, 4536, 562, 281, 22183, 732, 6676, 13], "temperature": 0.0, "avg_logprob": -0.1259677495275225, "compression_ratio": 1.7542372881355932, "no_speech_prob": 8.613101817900315e-05}, {"id": 125, "seek": 43816, "start": 458.52000000000004, "end": 464.68, "text": " And you can prove that the stack then becomes logarithmic in size, and that your merge sequences", "tokens": [400, 291, 393, 7081, 300, 264, 8630, 550, 3643, 41473, 355, 13195, 294, 2744, 11, 293, 300, 428, 22183, 22978], "temperature": 0.0, "avg_logprob": -0.1259677495275225, "compression_ratio": 1.7542372881355932, "no_speech_prob": 8.613101817900315e-05}, {"id": 126, "seek": 43816, "start": 464.68, "end": 467.92, "text": " are going to be very good.", "tokens": [366, 516, 281, 312, 588, 665, 13], "temperature": 0.0, "avg_logprob": -0.1259677495275225, "compression_ratio": 1.7542372881355932, "no_speech_prob": 8.613101817900315e-05}, {"id": 127, "seek": 46792, "start": 467.92, "end": 473.88, "text": " But yeah, the idea is that create a run can take advantage of existing runs in the input.", "tokens": [583, 1338, 11, 264, 1558, 307, 300, 1884, 257, 1190, 393, 747, 5002, 295, 6741, 6676, 294, 264, 4846, 13], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 128, "seek": 46792, "start": 473.88, "end": 475.32, "text": " So a problem merges.", "tokens": [407, 257, 1154, 3551, 2880, 13], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 129, "seek": 46792, "start": 475.32, "end": 480.08000000000004, "text": " We want to be adaptive to low cardinality inputs, and we want to be adaptive to preexisting", "tokens": [492, 528, 281, 312, 27912, 281, 2295, 2920, 259, 1860, 15743, 11, 293, 321, 528, 281, 312, 27912, 281, 659, 36447], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 130, "seek": 46792, "start": 480.08000000000004, "end": 481.28000000000003, "text": " run in input.", "tokens": [1190, 294, 4846, 13], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 131, "seek": 46792, "start": 481.28000000000003, "end": 486.56, "text": " But one is fundamentally bottom up, and the other one is fundamentally top down.", "tokens": [583, 472, 307, 17879, 2767, 493, 11, 293, 264, 661, 472, 307, 17879, 1192, 760, 13], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 132, "seek": 46792, "start": 486.56, "end": 488.52000000000004, "text": " And that's why I call this GlideSort.", "tokens": [400, 300, 311, 983, 286, 818, 341, 5209, 482, 50, 477, 13], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 133, "seek": 46792, "start": 488.52000000000004, "end": 489.52000000000004, "text": " We glide.", "tokens": [492, 41848, 13], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 134, "seek": 46792, "start": 489.52000000000004, "end": 490.76, "text": " What do I mean by that?", "tokens": [708, 360, 286, 914, 538, 300, 30], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 135, "seek": 46792, "start": 490.76, "end": 495.12, "text": " Well, the idea is that a soaring bird only flaps its wings when necessary.", "tokens": [1042, 11, 264, 1558, 307, 300, 257, 370, 1921, 5255, 787, 50065, 1080, 11405, 562, 4818, 13], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 136, "seek": 46792, "start": 495.12, "end": 497.24, "text": " GlideSort only sorts when necessary.", "tokens": [5209, 482, 50, 477, 787, 7527, 562, 4818, 13], "temperature": 0.0, "avg_logprob": -0.1640966234415987, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.685376891051419e-05}, {"id": 137, "seek": 49724, "start": 497.24, "end": 504.96000000000004, "text": " So during this create run process, I'm sorry, before that, I changed the concept of a run", "tokens": [407, 1830, 341, 1884, 1190, 1399, 11, 286, 478, 2597, 11, 949, 300, 11, 286, 3105, 264, 3410, 295, 257, 1190], "temperature": 0.0, "avg_logprob": -0.11714675834587028, "compression_ratio": 1.9142857142857144, "no_speech_prob": 2.3061818865244277e-05}, {"id": 138, "seek": 49724, "start": 504.96000000000004, "end": 506.12, "text": " to a logical run.", "tokens": [281, 257, 14978, 1190, 13], "temperature": 0.0, "avg_logprob": -0.11714675834587028, "compression_ratio": 1.9142857142857144, "no_speech_prob": 2.3061818865244277e-05}, {"id": 139, "seek": 49724, "start": 506.12, "end": 508.56, "text": " And a logical run can be one of three things.", "tokens": [400, 257, 14978, 1190, 393, 312, 472, 295, 1045, 721, 13], "temperature": 0.0, "avg_logprob": -0.11714675834587028, "compression_ratio": 1.9142857142857144, "no_speech_prob": 2.3061818865244277e-05}, {"id": 140, "seek": 49724, "start": 508.56, "end": 509.96000000000004, "text": " It can be just as before.", "tokens": [467, 393, 312, 445, 382, 949, 13], "temperature": 0.0, "avg_logprob": -0.11714675834587028, "compression_ratio": 1.9142857142857144, "no_speech_prob": 2.3061818865244277e-05}, {"id": 141, "seek": 49724, "start": 509.96000000000004, "end": 514.36, "text": " It can just be a sorted range of elements in your array, and can also be an unsorted", "tokens": [467, 393, 445, 312, 257, 25462, 3613, 295, 4959, 294, 428, 10225, 11, 293, 393, 611, 312, 364, 2693, 14813], "temperature": 0.0, "avg_logprob": -0.11714675834587028, "compression_ratio": 1.9142857142857144, "no_speech_prob": 2.3061818865244277e-05}, {"id": 142, "seek": 49724, "start": 514.36, "end": 518.84, "text": " range of elements in your array, or two sorted ranges that are right next to each other in", "tokens": [3613, 295, 4959, 294, 428, 10225, 11, 420, 732, 25462, 22526, 300, 366, 558, 958, 281, 1184, 661, 294], "temperature": 0.0, "avg_logprob": -0.11714675834587028, "compression_ratio": 1.9142857142857144, "no_speech_prob": 2.3061818865244277e-05}, {"id": 143, "seek": 49724, "start": 518.84, "end": 522.72, "text": " your array.", "tokens": [428, 10225, 13], "temperature": 0.0, "avg_logprob": -0.11714675834587028, "compression_ratio": 1.9142857142857144, "no_speech_prob": 2.3061818865244277e-05}, {"id": 144, "seek": 49724, "start": 522.72, "end": 524.88, "text": " We change the create run function.", "tokens": [492, 1319, 264, 1884, 1190, 2445, 13], "temperature": 0.0, "avg_logprob": -0.11714675834587028, "compression_ratio": 1.9142857142857144, "no_speech_prob": 2.3061818865244277e-05}, {"id": 145, "seek": 52488, "start": 524.88, "end": 531.16, "text": " We do, in fact, if there's a run in the input, detect that and return that as a sorted run.", "tokens": [492, 360, 11, 294, 1186, 11, 498, 456, 311, 257, 1190, 294, 264, 4846, 11, 5531, 300, 293, 2736, 300, 382, 257, 25462, 1190, 13], "temperature": 0.0, "avg_logprob": -0.13513587604869495, "compression_ratio": 1.8591549295774648, "no_speech_prob": 1.5159927897911984e-05}, {"id": 146, "seek": 52488, "start": 531.16, "end": 534.08, "text": " But if we don't detect a sorted run, we just return an unsorted run.", "tokens": [583, 498, 321, 500, 380, 5531, 257, 25462, 1190, 11, 321, 445, 2736, 364, 2693, 14813, 1190, 13], "temperature": 0.0, "avg_logprob": -0.13513587604869495, "compression_ratio": 1.8591549295774648, "no_speech_prob": 1.5159927897911984e-05}, {"id": 147, "seek": 52488, "start": 534.08, "end": 540.4399999999999, "text": " We don't eagerly sort anything, and how you do that is very simple.", "tokens": [492, 500, 380, 18259, 356, 1333, 1340, 11, 293, 577, 291, 360, 300, 307, 588, 2199, 13], "temperature": 0.0, "avg_logprob": -0.13513587604869495, "compression_ratio": 1.8591549295774648, "no_speech_prob": 1.5159927897911984e-05}, {"id": 148, "seek": 52488, "start": 540.4399999999999, "end": 544.68, "text": " You just scan through the array, and if you find a run that we consider big enough, we", "tokens": [509, 445, 11049, 807, 264, 10225, 11, 293, 498, 291, 915, 257, 1190, 300, 321, 1949, 955, 1547, 11, 321], "temperature": 0.0, "avg_logprob": -0.13513587604869495, "compression_ratio": 1.8591549295774648, "no_speech_prob": 1.5159927897911984e-05}, {"id": 149, "seek": 52488, "start": 544.68, "end": 552.04, "text": " return it, and otherwise, we just skip some elements and return an unsorted run.", "tokens": [2736, 309, 11, 293, 5911, 11, 321, 445, 10023, 512, 4959, 293, 2736, 364, 2693, 14813, 1190, 13], "temperature": 0.0, "avg_logprob": -0.13513587604869495, "compression_ratio": 1.8591549295774648, "no_speech_prob": 1.5159927897911984e-05}, {"id": 150, "seek": 55204, "start": 552.04, "end": 557.36, "text": " And then you add quite a bit of code for merging two runs, but it's actually relatively", "tokens": [400, 550, 291, 909, 1596, 257, 857, 295, 3089, 337, 44559, 732, 6676, 11, 457, 309, 311, 767, 7226], "temperature": 0.0, "avg_logprob": -0.14988982920743982, "compression_ratio": 1.6899563318777293, "no_speech_prob": 4.6058616135269403e-05}, {"id": 151, "seek": 55204, "start": 557.36, "end": 558.88, "text": " simple.", "tokens": [2199, 13], "temperature": 0.0, "avg_logprob": -0.14988982920743982, "compression_ratio": 1.6899563318777293, "no_speech_prob": 4.6058616135269403e-05}, {"id": 152, "seek": 55204, "start": 558.88, "end": 564.24, "text": " As long as two unsorted runs concatenate it fit in our scratch base, which is essentially", "tokens": [1018, 938, 382, 732, 2693, 14813, 6676, 1588, 7186, 473, 309, 3318, 294, 527, 8459, 3096, 11, 597, 307, 4476], "temperature": 0.0, "avg_logprob": -0.14988982920743982, "compression_ratio": 1.6899563318777293, "no_speech_prob": 4.6058616135269403e-05}, {"id": 153, "seek": 55204, "start": 564.24, "end": 570.24, "text": " this extra memory that blows people's minds, as long as it fits in that, we just concatenate", "tokens": [341, 2857, 4675, 300, 18458, 561, 311, 9634, 11, 382, 938, 382, 309, 9001, 294, 300, 11, 321, 445, 1588, 7186, 473], "temperature": 0.0, "avg_logprob": -0.14988982920743982, "compression_ratio": 1.6899563318777293, "no_speech_prob": 4.6058616135269403e-05}, {"id": 154, "seek": 55204, "start": 570.24, "end": 572.0799999999999, "text": " our unsorted runs.", "tokens": [527, 2693, 14813, 6676, 13], "temperature": 0.0, "avg_logprob": -0.14988982920743982, "compression_ratio": 1.6899563318777293, "no_speech_prob": 4.6058616135269403e-05}, {"id": 155, "seek": 55204, "start": 572.0799999999999, "end": 579.3199999999999, "text": " And otherwise, we actively physically sort the elements using quick sort, and then create", "tokens": [400, 5911, 11, 321, 13022, 9762, 1333, 264, 4959, 1228, 1702, 1333, 11, 293, 550, 1884], "temperature": 0.0, "avg_logprob": -0.14988982920743982, "compression_ratio": 1.6899563318777293, "no_speech_prob": 4.6058616135269403e-05}, {"id": 156, "seek": 57932, "start": 579.32, "end": 584.2800000000001, "text": " one of these two sorted concatenated run cases.", "tokens": [472, 295, 613, 732, 25462, 1588, 7186, 770, 1190, 3331, 13], "temperature": 0.0, "avg_logprob": -0.12063526761704597, "compression_ratio": 1.75, "no_speech_prob": 3.970337274949998e-05}, {"id": 157, "seek": 57932, "start": 584.2800000000001, "end": 589.84, "text": " If we have two sorted runs, we concatenate them.", "tokens": [759, 321, 362, 732, 25462, 6676, 11, 321, 1588, 7186, 473, 552, 13], "temperature": 0.0, "avg_logprob": -0.12063526761704597, "compression_ratio": 1.75, "no_speech_prob": 3.970337274949998e-05}, {"id": 158, "seek": 57932, "start": 589.84, "end": 599.44, "text": " If we have an unsorted run and something else, we actually sort this unsorted run and then", "tokens": [759, 321, 362, 364, 2693, 14813, 1190, 293, 746, 1646, 11, 321, 767, 1333, 341, 2693, 14813, 1190, 293, 550], "temperature": 0.0, "avg_logprob": -0.12063526761704597, "compression_ratio": 1.75, "no_speech_prob": 3.970337274949998e-05}, {"id": 159, "seek": 57932, "start": 599.44, "end": 602.08, "text": " recurs.", "tokens": [20560, 13], "temperature": 0.0, "avg_logprob": -0.12063526761704597, "compression_ratio": 1.75, "no_speech_prob": 3.970337274949998e-05}, {"id": 160, "seek": 57932, "start": 602.08, "end": 604.96, "text": " And finally, we have our actual physical mergers.", "tokens": [400, 2721, 11, 321, 362, 527, 3539, 4001, 3551, 9458, 13], "temperature": 0.0, "avg_logprob": -0.12063526761704597, "compression_ratio": 1.75, "no_speech_prob": 3.970337274949998e-05}, {"id": 161, "seek": 60496, "start": 604.96, "end": 612.88, "text": " So when we can no longer be lazy, we can no longer glide, we have to actually merge elements.", "tokens": [407, 562, 321, 393, 572, 2854, 312, 14847, 11, 321, 393, 572, 2854, 41848, 11, 321, 362, 281, 767, 22183, 4959, 13], "temperature": 0.0, "avg_logprob": -0.08090233540796972, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.9507890101522207e-05}, {"id": 162, "seek": 60496, "start": 612.88, "end": 616.8000000000001, "text": " So that is essentially the main loop of glide sort.", "tokens": [407, 300, 307, 4476, 264, 2135, 6367, 295, 41848, 1333, 13], "temperature": 0.0, "avg_logprob": -0.08090233540796972, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.9507890101522207e-05}, {"id": 163, "seek": 60496, "start": 616.8000000000001, "end": 623.12, "text": " So it's an extension of power sort, but you can apply the same logic to any natural stable", "tokens": [407, 309, 311, 364, 10320, 295, 1347, 1333, 11, 457, 291, 393, 3079, 264, 912, 9952, 281, 604, 3303, 8351], "temperature": 0.0, "avg_logprob": -0.08090233540796972, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.9507890101522207e-05}, {"id": 164, "seek": 60496, "start": 623.12, "end": 624.6800000000001, "text": " merge sort.", "tokens": [22183, 1333, 13], "temperature": 0.0, "avg_logprob": -0.08090233540796972, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.9507890101522207e-05}, {"id": 165, "seek": 60496, "start": 624.6800000000001, "end": 626.44, "text": " We don't eagerly sort small runs.", "tokens": [492, 500, 380, 18259, 356, 1333, 1359, 6676, 13], "temperature": 0.0, "avg_logprob": -0.08090233540796972, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.9507890101522207e-05}, {"id": 166, "seek": 60496, "start": 626.44, "end": 631.48, "text": " We keep them as unsorted runs as long as possible.", "tokens": [492, 1066, 552, 382, 2693, 14813, 6676, 382, 938, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.08090233540796972, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.9507890101522207e-05}, {"id": 167, "seek": 63148, "start": 631.48, "end": 637.48, "text": " And this way, we transform the sorting problem into a sequence of quick sort calls and triple", "tokens": [400, 341, 636, 11, 321, 4088, 264, 32411, 1154, 666, 257, 8310, 295, 1702, 1333, 5498, 293, 15508], "temperature": 0.0, "avg_logprob": -0.13782883634661683, "compression_ratio": 1.5869565217391304, "no_speech_prob": 9.47692315094173e-05}, {"id": 168, "seek": 63148, "start": 637.48, "end": 639.52, "text": " slash quad merges.", "tokens": [17330, 10787, 3551, 2880, 13], "temperature": 0.0, "avg_logprob": -0.13782883634661683, "compression_ratio": 1.5869565217391304, "no_speech_prob": 9.47692315094173e-05}, {"id": 169, "seek": 63148, "start": 639.52, "end": 643.52, "text": " And doing this, we are adaptive to pre-sorted runs and low cardinality inputs at the same", "tokens": [400, 884, 341, 11, 321, 366, 27912, 281, 659, 12, 82, 14813, 6676, 293, 2295, 2920, 259, 1860, 15743, 412, 264, 912], "temperature": 0.0, "avg_logprob": -0.13782883634661683, "compression_ratio": 1.5869565217391304, "no_speech_prob": 9.47692315094173e-05}, {"id": 170, "seek": 63148, "start": 643.52, "end": 646.44, "text": " time.", "tokens": [565, 13], "temperature": 0.0, "avg_logprob": -0.13782883634661683, "compression_ratio": 1.5869565217391304, "no_speech_prob": 9.47692315094173e-05}, {"id": 171, "seek": 63148, "start": 646.44, "end": 648.76, "text": " So why triple and quad merges?", "tokens": [407, 983, 15508, 293, 10787, 3551, 2880, 30], "temperature": 0.0, "avg_logprob": -0.13782883634661683, "compression_ratio": 1.5869565217391304, "no_speech_prob": 9.47692315094173e-05}, {"id": 172, "seek": 63148, "start": 648.76, "end": 651.6, "text": " And there are three main reasons.", "tokens": [400, 456, 366, 1045, 2135, 4112, 13], "temperature": 0.0, "avg_logprob": -0.13782883634661683, "compression_ratio": 1.5869565217391304, "no_speech_prob": 9.47692315094173e-05}, {"id": 173, "seek": 63148, "start": 651.6, "end": 658.24, "text": " There's ping-pong merging, bidirectional merging, oh, sorry, before I want to quite clearly", "tokens": [821, 311, 26151, 12, 79, 556, 44559, 11, 12957, 621, 41048, 44559, 11, 1954, 11, 2597, 11, 949, 286, 528, 281, 1596, 4448], "temperature": 0.0, "avg_logprob": -0.13782883634661683, "compression_ratio": 1.5869565217391304, "no_speech_prob": 9.47692315094173e-05}, {"id": 174, "seek": 65824, "start": 658.24, "end": 664.16, "text": " mention something, Glider is not the first algorithm that is adaptive to both of these", "tokens": [2152, 746, 11, 5209, 1438, 307, 406, 264, 700, 9284, 300, 307, 27912, 281, 1293, 295, 613], "temperature": 0.0, "avg_logprob": -0.134205200558617, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.00016392867837566882}, {"id": 175, "seek": 65824, "start": 664.16, "end": 669.16, "text": " categories at the same time, but to my knowledge, at least it is the first algorithm that is", "tokens": [10479, 412, 264, 912, 565, 11, 457, 281, 452, 3601, 11, 412, 1935, 309, 307, 264, 700, 9284, 300, 307], "temperature": 0.0, "avg_logprob": -0.134205200558617, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.00016392867837566882}, {"id": 176, "seek": 65824, "start": 669.16, "end": 670.32, "text": " robustly adaptive.", "tokens": [13956, 356, 27912, 13], "temperature": 0.0, "avg_logprob": -0.134205200558617, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.00016392867837566882}, {"id": 177, "seek": 65824, "start": 670.32, "end": 674.24, "text": " So it does not hard code anything, it does not use heuristics to decide when to switch", "tokens": [407, 309, 775, 406, 1152, 3089, 1340, 11, 309, 775, 406, 764, 415, 374, 6006, 281, 4536, 562, 281, 3679], "temperature": 0.0, "avg_logprob": -0.134205200558617, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.00016392867837566882}, {"id": 178, "seek": 65824, "start": 674.24, "end": 680.92, "text": " to which algorithm it detects this completely naturally based on the input.", "tokens": [281, 597, 9284, 309, 5531, 82, 341, 2584, 8195, 2361, 322, 264, 4846, 13], "temperature": 0.0, "avg_logprob": -0.134205200558617, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.00016392867837566882}, {"id": 179, "seek": 65824, "start": 680.92, "end": 683.04, "text": " So why triple slash quad merges?", "tokens": [407, 983, 15508, 17330, 10787, 3551, 2880, 30], "temperature": 0.0, "avg_logprob": -0.134205200558617, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.00016392867837566882}, {"id": 180, "seek": 65824, "start": 683.04, "end": 684.24, "text": " There are three main reasons.", "tokens": [821, 366, 1045, 2135, 4112, 13], "temperature": 0.0, "avg_logprob": -0.134205200558617, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.00016392867837566882}, {"id": 181, "seek": 68424, "start": 684.24, "end": 688.52, "text": " Ping-pong merging, bidirectional merging, and parallel merging.", "tokens": [33645, 12, 79, 556, 44559, 11, 12957, 621, 41048, 44559, 11, 293, 8952, 44559, 13], "temperature": 0.0, "avg_logprob": -0.23018596148250078, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.00030694311135448515}, {"id": 182, "seek": 68424, "start": 688.52, "end": 692.44, "text": " Ping-pong merging is not my idea, it's found in two early projects, once again by Igor", "tokens": [33645, 12, 79, 556, 44559, 307, 406, 452, 1558, 11, 309, 311, 1352, 294, 732, 2440, 4455, 11, 1564, 797, 538, 40356], "temperature": 0.0, "avg_logprob": -0.23018596148250078, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.00030694311135448515}, {"id": 183, "seek": 68424, "start": 692.44, "end": 697.04, "text": " van der Hove and an earlier paper, Pages is Virtue.", "tokens": [3161, 1163, 3631, 303, 293, 364, 3071, 3035, 11, 430, 1660, 307, 19447, 622, 13], "temperature": 0.0, "avg_logprob": -0.23018596148250078, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.00030694311135448515}, {"id": 184, "seek": 68424, "start": 697.04, "end": 702.6, "text": " And the idea is that in a traditional merge, you copy out part of the data someplace else", "tokens": [400, 264, 1558, 307, 300, 294, 257, 5164, 22183, 11, 291, 5055, 484, 644, 295, 264, 1412, 37126, 1646], "temperature": 0.0, "avg_logprob": -0.23018596148250078, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.00030694311135448515}, {"id": 185, "seek": 68424, "start": 702.6, "end": 708.4, "text": " and then merge back into the original array, that's an extra memcap.", "tokens": [293, 550, 22183, 646, 666, 264, 3380, 10225, 11, 300, 311, 364, 2857, 1334, 9485, 13], "temperature": 0.0, "avg_logprob": -0.23018596148250078, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.00030694311135448515}, {"id": 186, "seek": 70840, "start": 708.4, "end": 715.4399999999999, "text": " With a triple slash quad or a quad merge, you can merge both into your scratch space", "tokens": [2022, 257, 15508, 17330, 10787, 420, 257, 10787, 22183, 11, 291, 393, 22183, 1293, 666, 428, 8459, 1901], "temperature": 0.0, "avg_logprob": -0.15945372622237247, "compression_ratio": 1.9327731092436975, "no_speech_prob": 7.805841596564278e-05}, {"id": 187, "seek": 70840, "start": 715.4399999999999, "end": 719.1999999999999, "text": " and on the way back, because essentially when you do an out of place merge, you get a mem", "tokens": [293, 322, 264, 636, 646, 11, 570, 4476, 562, 291, 360, 364, 484, 295, 1081, 22183, 11, 291, 483, 257, 1334], "temperature": 0.0, "avg_logprob": -0.15945372622237247, "compression_ratio": 1.9327731092436975, "no_speech_prob": 7.805841596564278e-05}, {"id": 188, "seek": 70840, "start": 719.1999999999999, "end": 722.24, "text": " copy for free because you're moving to some other place.", "tokens": [5055, 337, 1737, 570, 291, 434, 2684, 281, 512, 661, 1081, 13], "temperature": 0.0, "avg_logprob": -0.15945372622237247, "compression_ratio": 1.9327731092436975, "no_speech_prob": 7.805841596564278e-05}, {"id": 189, "seek": 70840, "start": 722.24, "end": 725.92, "text": " So I think that's best described visually, if you have four, so in this case a quad merge,", "tokens": [407, 286, 519, 300, 311, 1151, 7619, 19622, 11, 498, 291, 362, 1451, 11, 370, 294, 341, 1389, 257, 10787, 22183, 11], "temperature": 0.0, "avg_logprob": -0.15945372622237247, "compression_ratio": 1.9327731092436975, "no_speech_prob": 7.805841596564278e-05}, {"id": 190, "seek": 70840, "start": 725.92, "end": 732.88, "text": " you have four mer sorted runs, you merge two into your scratch space, you merge two", "tokens": [291, 362, 1451, 3551, 25462, 6676, 11, 291, 22183, 732, 666, 428, 8459, 1901, 11, 291, 22183, 732], "temperature": 0.0, "avg_logprob": -0.15945372622237247, "compression_ratio": 1.9327731092436975, "no_speech_prob": 7.805841596564278e-05}, {"id": 191, "seek": 70840, "start": 732.88, "end": 736.64, "text": " more into your scratch space, and you merge two back.", "tokens": [544, 666, 428, 8459, 1901, 11, 293, 291, 22183, 732, 646, 13], "temperature": 0.0, "avg_logprob": -0.15945372622237247, "compression_ratio": 1.9327731092436975, "no_speech_prob": 7.805841596564278e-05}, {"id": 192, "seek": 73664, "start": 736.64, "end": 742.36, "text": " And now we eliminated three mem copies, so don't have to do that, that's one advantage", "tokens": [400, 586, 321, 20308, 1045, 1334, 14341, 11, 370, 500, 380, 362, 281, 360, 300, 11, 300, 311, 472, 5002], "temperature": 0.0, "avg_logprob": -0.16911012382917506, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.00023657595738768578}, {"id": 193, "seek": 73664, "start": 742.36, "end": 745.08, "text": " of being lazy with merging.", "tokens": [295, 885, 14847, 365, 44559, 13], "temperature": 0.0, "avg_logprob": -0.16911012382917506, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.00023657595738768578}, {"id": 194, "seek": 73664, "start": 745.08, "end": 753.24, "text": " We can also do bidirectional merging, this, to my knowledge, was first done again by Igor", "tokens": [492, 393, 611, 360, 12957, 621, 41048, 44559, 11, 341, 11, 281, 452, 3601, 11, 390, 700, 1096, 797, 538, 40356], "temperature": 0.0, "avg_logprob": -0.16911012382917506, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.00023657595738768578}, {"id": 195, "seek": 73664, "start": 753.24, "end": 757.76, "text": " van der Hove in Quadsford, where he described a parity merge, where he showed a very clever", "tokens": [3161, 1163, 3631, 303, 294, 2326, 5834, 7404, 11, 689, 415, 7619, 257, 44747, 22183, 11, 689, 415, 4712, 257, 588, 13494], "temperature": 0.0, "avg_logprob": -0.16911012382917506, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.00023657595738768578}, {"id": 196, "seek": 73664, "start": 757.76, "end": 763.64, "text": " technique to merge two equal length arrays without any branch checks.", "tokens": [6532, 281, 22183, 732, 2681, 4641, 41011, 1553, 604, 9819, 13834, 13], "temperature": 0.0, "avg_logprob": -0.16911012382917506, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.00023657595738768578}, {"id": 197, "seek": 76364, "start": 763.64, "end": 767.16, "text": " But then I thought by merging from both ends at the same time.", "tokens": [583, 550, 286, 1194, 538, 44559, 490, 1293, 5314, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.09528325457091726, "compression_ratio": 1.8553191489361702, "no_speech_prob": 0.00010253373329760507}, {"id": 198, "seek": 76364, "start": 767.16, "end": 775.08, "text": " But then I thought, looked really into why that was fast and how can we extend that", "tokens": [583, 550, 286, 1194, 11, 2956, 534, 666, 983, 300, 390, 2370, 293, 577, 393, 321, 10101, 300], "temperature": 0.0, "avg_logprob": -0.09528325457091726, "compression_ratio": 1.8553191489361702, "no_speech_prob": 0.00010253373329760507}, {"id": 199, "seek": 76364, "start": 775.08, "end": 777.68, "text": " and use that further.", "tokens": [293, 764, 300, 3052, 13], "temperature": 0.0, "avg_logprob": -0.09528325457091726, "compression_ratio": 1.8553191489361702, "no_speech_prob": 0.00010253373329760507}, {"id": 200, "seek": 76364, "start": 777.68, "end": 781.48, "text": " So the idea behind a bidirectional merge is that if your destination and your source", "tokens": [407, 264, 1558, 2261, 257, 12957, 621, 41048, 22183, 307, 300, 498, 428, 12236, 293, 428, 4009], "temperature": 0.0, "avg_logprob": -0.09528325457091726, "compression_ratio": 1.8553191489361702, "no_speech_prob": 0.00010253373329760507}, {"id": 201, "seek": 76364, "start": 781.48, "end": 786.48, "text": " arrays are disjoint, you can merge from both ends at the same time.", "tokens": [41011, 366, 717, 48613, 11, 291, 393, 22183, 490, 1293, 5314, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.09528325457091726, "compression_ratio": 1.8553191489361702, "no_speech_prob": 0.00010253373329760507}, {"id": 202, "seek": 76364, "start": 786.48, "end": 791.12, "text": " And then the pointer that's going from right to left does not interfere with the pointer", "tokens": [400, 550, 264, 23918, 300, 311, 516, 490, 558, 281, 1411, 775, 406, 23946, 365, 264, 23918], "temperature": 0.0, "avg_logprob": -0.09528325457091726, "compression_ratio": 1.8553191489361702, "no_speech_prob": 0.00010253373329760507}, {"id": 203, "seek": 76364, "start": 791.12, "end": 792.68, "text": " going from left to right.", "tokens": [516, 490, 1411, 281, 558, 13], "temperature": 0.0, "avg_logprob": -0.09528325457091726, "compression_ratio": 1.8553191489361702, "no_speech_prob": 0.00010253373329760507}, {"id": 204, "seek": 79268, "start": 792.68, "end": 795.76, "text": " These two logics are independent, essentially.", "tokens": [1981, 732, 3565, 1167, 366, 6695, 11, 4476, 13], "temperature": 0.0, "avg_logprob": -0.2447996563381619, "compression_ratio": 1.6497695852534562, "no_speech_prob": 3.149857366224751e-05}, {"id": 205, "seek": 79268, "start": 795.76, "end": 799.4399999999999, "text": " And it essentially looks like that.", "tokens": [400, 309, 4476, 1542, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2447996563381619, "compression_ratio": 1.6497695852534562, "no_speech_prob": 3.149857366224751e-05}, {"id": 206, "seek": 79268, "start": 799.4399999999999, "end": 800.9399999999999, "text": " Why?", "tokens": [1545, 30], "temperature": 0.0, "avg_logprob": -0.2447996563381619, "compression_ratio": 1.6497695852534562, "no_speech_prob": 3.149857366224751e-05}, {"id": 207, "seek": 79268, "start": 800.9399999999999, "end": 802.76, "text": " Why do we want to do that?", "tokens": [1545, 360, 321, 528, 281, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.2447996563381619, "compression_ratio": 1.6497695852534562, "no_speech_prob": 3.149857366224751e-05}, {"id": 208, "seek": 79268, "start": 802.76, "end": 810.76, "text": " Well, modern processors are quite different than what maybe your traditional processor", "tokens": [1042, 11, 4363, 27751, 366, 1596, 819, 813, 437, 1310, 428, 5164, 15321], "temperature": 0.0, "avg_logprob": -0.2447996563381619, "compression_ratio": 1.6497695852534562, "no_speech_prob": 3.149857366224751e-05}, {"id": 209, "seek": 79268, "start": 810.76, "end": 811.9599999999999, "text": " with your mental image are.", "tokens": [365, 428, 4973, 3256, 366, 13], "temperature": 0.0, "avg_logprob": -0.2447996563381619, "compression_ratio": 1.6497695852534562, "no_speech_prob": 3.149857366224751e-05}, {"id": 210, "seek": 79268, "start": 811.9599999999999, "end": 815.92, "text": " They are superscaler, that means they don't execute one instruction per cycle, no, they", "tokens": [814, 366, 37906, 9895, 260, 11, 300, 1355, 436, 500, 380, 14483, 472, 10951, 680, 6586, 11, 572, 11, 436], "temperature": 0.0, "avg_logprob": -0.2447996563381619, "compression_ratio": 1.6497695852534562, "no_speech_prob": 3.149857366224751e-05}, {"id": 211, "seek": 79268, "start": 815.92, "end": 818.8399999999999, "text": " can execute many instructions per cycle.", "tokens": [393, 14483, 867, 9415, 680, 6586, 13], "temperature": 0.0, "avg_logprob": -0.2447996563381619, "compression_ratio": 1.6497695852534562, "no_speech_prob": 3.149857366224751e-05}, {"id": 212, "seek": 81884, "start": 818.84, "end": 823.2800000000001, "text": " They are out of order, the processor will internally reorder your instructions based", "tokens": [814, 366, 484, 295, 1668, 11, 264, 15321, 486, 19501, 319, 4687, 428, 9415, 2361], "temperature": 0.0, "avg_logprob": -0.09379842546251085, "compression_ratio": 1.75, "no_speech_prob": 4.283530870452523e-05}, {"id": 213, "seek": 81884, "start": 823.2800000000001, "end": 828.12, "text": " on your assembly based on the data paths and when memory is available.", "tokens": [322, 428, 12103, 2361, 322, 264, 1412, 14518, 293, 562, 4675, 307, 2435, 13], "temperature": 0.0, "avg_logprob": -0.09379842546251085, "compression_ratio": 1.75, "no_speech_prob": 4.283530870452523e-05}, {"id": 214, "seek": 81884, "start": 828.12, "end": 829.5600000000001, "text": " And they are deeply pipelined.", "tokens": [400, 436, 366, 8760, 8489, 338, 2001, 13], "temperature": 0.0, "avg_logprob": -0.09379842546251085, "compression_ratio": 1.75, "no_speech_prob": 4.283530870452523e-05}, {"id": 215, "seek": 81884, "start": 829.5600000000001, "end": 833.9200000000001, "text": " That means that they don't like it when the next instruction depends immediately on the", "tokens": [663, 1355, 300, 436, 500, 380, 411, 309, 562, 264, 958, 10951, 5946, 4258, 322, 264], "temperature": 0.0, "avg_logprob": -0.09379842546251085, "compression_ratio": 1.75, "no_speech_prob": 4.283530870452523e-05}, {"id": 216, "seek": 81884, "start": 833.9200000000001, "end": 837.2, "text": " result of the previous instruction because it has to go through the entire pipeline of", "tokens": [1874, 295, 264, 3894, 10951, 570, 309, 575, 281, 352, 807, 264, 2302, 15517, 295], "temperature": 0.0, "avg_logprob": -0.09379842546251085, "compression_ratio": 1.75, "no_speech_prob": 4.283530870452523e-05}, {"id": 217, "seek": 81884, "start": 837.2, "end": 840.6, "text": " the processor.", "tokens": [264, 15321, 13], "temperature": 0.0, "avg_logprob": -0.09379842546251085, "compression_ratio": 1.75, "no_speech_prob": 4.283530870452523e-05}, {"id": 218, "seek": 81884, "start": 840.6, "end": 845.6800000000001, "text": " So to study that in a bit more detail, we look at a branchless merge, which was first", "tokens": [407, 281, 2979, 300, 294, 257, 857, 544, 2607, 11, 321, 574, 412, 257, 9819, 1832, 22183, 11, 597, 390, 700], "temperature": 0.0, "avg_logprob": -0.09379842546251085, "compression_ratio": 1.75, "no_speech_prob": 4.283530870452523e-05}, {"id": 219, "seek": 84568, "start": 845.68, "end": 849.64, "text": " described in branch mispredictions don't affect merge source.", "tokens": [7619, 294, 9819, 3346, 79, 986, 15607, 500, 380, 3345, 22183, 4009, 13], "temperature": 0.0, "avg_logprob": -0.16609556778617526, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.0001669539778959006}, {"id": 220, "seek": 84568, "start": 849.64, "end": 851.8, "text": " This is not the code that they used in this paper.", "tokens": [639, 307, 406, 264, 3089, 300, 436, 1143, 294, 341, 3035, 13], "temperature": 0.0, "avg_logprob": -0.16609556778617526, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.0001669539778959006}, {"id": 221, "seek": 84568, "start": 851.8, "end": 856.04, "text": " This is roughly translated from GlideSort.", "tokens": [639, 307, 9810, 16805, 490, 5209, 482, 50, 477, 13], "temperature": 0.0, "avg_logprob": -0.16609556778617526, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.0001669539778959006}, {"id": 222, "seek": 84568, "start": 856.04, "end": 858.92, "text": " You don't have to get into it, how it works.", "tokens": [509, 500, 380, 362, 281, 483, 666, 309, 11, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.16609556778617526, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.0001669539778959006}, {"id": 223, "seek": 84568, "start": 858.92, "end": 866.28, "text": " The main important part is that you analyze where is the result used in the next slide.", "tokens": [440, 2135, 1021, 644, 307, 300, 291, 12477, 689, 307, 264, 1874, 1143, 294, 264, 958, 4137, 13], "temperature": 0.0, "avg_logprob": -0.16609556778617526, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.0001669539778959006}, {"id": 224, "seek": 84568, "start": 866.28, "end": 871.3199999999999, "text": " Well, you find that generally all the data that's computed is needed immediately.", "tokens": [1042, 11, 291, 915, 300, 5101, 439, 264, 1412, 300, 311, 40610, 307, 2978, 4258, 13], "temperature": 0.0, "avg_logprob": -0.16609556778617526, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.0001669539778959006}, {"id": 225, "seek": 84568, "start": 871.3199999999999, "end": 875.52, "text": " And the worst part of it all is that the next iteration cannot start really until the", "tokens": [400, 264, 5855, 644, 295, 309, 439, 307, 300, 264, 958, 24784, 2644, 722, 534, 1826, 264], "temperature": 0.0, "avg_logprob": -0.16609556778617526, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.0001669539778959006}, {"id": 226, "seek": 87552, "start": 875.52, "end": 876.96, "text": " previous iteration is finished.", "tokens": [3894, 24784, 307, 4335, 13], "temperature": 0.0, "avg_logprob": -0.20467567443847656, "compression_ratio": 1.6806083650190113, "no_speech_prob": 4.984070255886763e-05}, {"id": 227, "seek": 87552, "start": 876.96, "end": 880.64, "text": " You don't know if you're merging two arrays, you need to know, am I continuing with the", "tokens": [509, 500, 380, 458, 498, 291, 434, 44559, 732, 41011, 11, 291, 643, 281, 458, 11, 669, 286, 9289, 365, 264], "temperature": 0.0, "avg_logprob": -0.20467567443847656, "compression_ratio": 1.6806083650190113, "no_speech_prob": 4.984070255886763e-05}, {"id": 228, "seek": 87552, "start": 880.64, "end": 882.88, "text": " left array or am I continuing with the right array?", "tokens": [1411, 10225, 420, 669, 286, 9289, 365, 264, 558, 10225, 30], "temperature": 0.0, "avg_logprob": -0.20467567443847656, "compression_ratio": 1.6806083650190113, "no_speech_prob": 4.984070255886763e-05}, {"id": 229, "seek": 87552, "start": 882.88, "end": 886.84, "text": " There's a lot of data dependencies.", "tokens": [821, 311, 257, 688, 295, 1412, 36606, 13], "temperature": 0.0, "avg_logprob": -0.20467567443847656, "compression_ratio": 1.6806083650190113, "no_speech_prob": 4.984070255886763e-05}, {"id": 230, "seek": 87552, "start": 886.84, "end": 892.4399999999999, "text": " So that is my main takeaway from GlideSort and my main low level design principle is", "tokens": [407, 300, 307, 452, 2135, 30681, 490, 5209, 482, 50, 477, 293, 452, 2135, 2295, 1496, 1715, 8665, 307], "temperature": 0.0, "avg_logprob": -0.20467567443847656, "compression_ratio": 1.6806083650190113, "no_speech_prob": 4.984070255886763e-05}, {"id": 231, "seek": 87552, "start": 892.4399999999999, "end": 895.4399999999999, "text": " to interleave independent branchless loops.", "tokens": [281, 728, 306, 946, 6695, 9819, 1832, 16121, 13], "temperature": 0.0, "avg_logprob": -0.20467567443847656, "compression_ratio": 1.6806083650190113, "no_speech_prob": 4.984070255886763e-05}, {"id": 232, "seek": 87552, "start": 895.4399999999999, "end": 899.96, "text": " So branchless is important, so the processor isn't jumping around and constantly canceling", "tokens": [407, 9819, 1832, 307, 1021, 11, 370, 264, 15321, 1943, 380, 11233, 926, 293, 6460, 10373, 278], "temperature": 0.0, "avg_logprob": -0.20467567443847656, "compression_ratio": 1.6806083650190113, "no_speech_prob": 4.984070255886763e-05}, {"id": 233, "seek": 87552, "start": 899.96, "end": 903.16, "text": " your pipeline.", "tokens": [428, 15517, 13], "temperature": 0.0, "avg_logprob": -0.20467567443847656, "compression_ratio": 1.6806083650190113, "no_speech_prob": 4.984070255886763e-05}, {"id": 234, "seek": 90316, "start": 903.16, "end": 910.1999999999999, "text": " And by interleaving, we can hide some of these data dependencies.", "tokens": [400, 538, 728, 306, 6152, 11, 321, 393, 6479, 512, 295, 613, 1412, 36606, 13], "temperature": 0.0, "avg_logprob": -0.14365589769580697, "compression_ratio": 1.619718309859155, "no_speech_prob": 6.287286669248715e-05}, {"id": 235, "seek": 90316, "start": 910.1999999999999, "end": 916.3199999999999, "text": " The processor can execute multiple instructions at once and it can essentially reduce the", "tokens": [440, 15321, 393, 14483, 3866, 9415, 412, 1564, 293, 309, 393, 4476, 5407, 264], "temperature": 0.0, "avg_logprob": -0.14365589769580697, "compression_ratio": 1.619718309859155, "no_speech_prob": 6.287286669248715e-05}, {"id": 236, "seek": 90316, "start": 916.3199999999999, "end": 924.24, "text": " impact of having to constantly wait for the previous result.", "tokens": [2712, 295, 1419, 281, 6460, 1699, 337, 264, 3894, 1874, 13], "temperature": 0.0, "avg_logprob": -0.14365589769580697, "compression_ratio": 1.619718309859155, "no_speech_prob": 6.287286669248715e-05}, {"id": 237, "seek": 90316, "start": 924.24, "end": 925.8, "text": " You can also consider parallel merging.", "tokens": [509, 393, 611, 1949, 8952, 44559, 13], "temperature": 0.0, "avg_logprob": -0.14365589769580697, "compression_ratio": 1.619718309859155, "no_speech_prob": 6.287286669248715e-05}, {"id": 238, "seek": 90316, "start": 925.8, "end": 930.72, "text": " So in this case, we had one merge where we did it in parallel from the left and parallel", "tokens": [407, 294, 341, 1389, 11, 321, 632, 472, 22183, 689, 321, 630, 309, 294, 8952, 490, 264, 1411, 293, 8952], "temperature": 0.0, "avg_logprob": -0.14365589769580697, "compression_ratio": 1.619718309859155, "no_speech_prob": 6.287286669248715e-05}, {"id": 239, "seek": 93072, "start": 930.72, "end": 933.32, "text": " from the right.", "tokens": [490, 264, 558, 13], "temperature": 0.0, "avg_logprob": -0.12355883042890947, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.911514431820251e-05}, {"id": 240, "seek": 93072, "start": 933.32, "end": 939.28, "text": " But we also noticed that the first step in our quad merge has two independent merges.", "tokens": [583, 321, 611, 5694, 300, 264, 700, 1823, 294, 527, 10787, 22183, 575, 732, 6695, 3551, 2880, 13], "temperature": 0.0, "avg_logprob": -0.12355883042890947, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.911514431820251e-05}, {"id": 241, "seek": 93072, "start": 939.28, "end": 943.76, "text": " These are essentially parallel, but we're not using threads, but we can interleave", "tokens": [1981, 366, 4476, 8952, 11, 457, 321, 434, 406, 1228, 19314, 11, 457, 321, 393, 728, 306, 946], "temperature": 0.0, "avg_logprob": -0.12355883042890947, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.911514431820251e-05}, {"id": 242, "seek": 93072, "start": 943.76, "end": 945.9200000000001, "text": " their loops.", "tokens": [641, 16121, 13], "temperature": 0.0, "avg_logprob": -0.12355883042890947, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.911514431820251e-05}, {"id": 243, "seek": 93072, "start": 945.9200000000001, "end": 951.28, "text": " So once I discovered that, I thought, let's create more parallelism.", "tokens": [407, 1564, 286, 6941, 300, 11, 286, 1194, 11, 718, 311, 1884, 544, 8952, 1434, 13], "temperature": 0.0, "avg_logprob": -0.12355883042890947, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.911514431820251e-05}, {"id": 244, "seek": 93072, "start": 951.28, "end": 957.9200000000001, "text": " By doing a binary search, you can identify a split point where you can turn one merge", "tokens": [3146, 884, 257, 17434, 3164, 11, 291, 393, 5876, 257, 7472, 935, 689, 291, 393, 1261, 472, 22183], "temperature": 0.0, "avg_logprob": -0.12355883042890947, "compression_ratio": 1.5855855855855856, "no_speech_prob": 3.911514431820251e-05}, {"id": 245, "seek": 95792, "start": 957.92, "end": 966.4, "text": " into two smaller merges by swapping the right blocks in the middle.", "tokens": [666, 732, 4356, 3551, 2880, 538, 1693, 10534, 264, 558, 8474, 294, 264, 2808, 13], "temperature": 0.0, "avg_logprob": -0.10654068892856813, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.946612120373175e-05}, {"id": 246, "seek": 95792, "start": 966.4, "end": 972.12, "text": " I won't go into the exact logic of proof about that, but you can.", "tokens": [286, 1582, 380, 352, 666, 264, 1900, 9952, 295, 8177, 466, 300, 11, 457, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.10654068892856813, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.946612120373175e-05}, {"id": 247, "seek": 95792, "start": 972.12, "end": 976.68, "text": " And in fact, if you are doing an out-of-place merge, you can do this swap implicitly by", "tokens": [400, 294, 1186, 11, 498, 291, 366, 884, 364, 484, 12, 2670, 12, 6742, 22183, 11, 291, 393, 360, 341, 18135, 26947, 356, 538], "temperature": 0.0, "avg_logprob": -0.10654068892856813, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.946612120373175e-05}, {"id": 248, "seek": 95792, "start": 976.68, "end": 979.12, "text": " just reassigning pointers.", "tokens": [445, 19486, 9676, 44548, 13], "temperature": 0.0, "avg_logprob": -0.10654068892856813, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.946612120373175e-05}, {"id": 249, "seek": 95792, "start": 979.12, "end": 981.36, "text": " So there's no actual physical mem copy going on.", "tokens": [407, 456, 311, 572, 3539, 4001, 1334, 5055, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.10654068892856813, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.946612120373175e-05}, {"id": 250, "seek": 95792, "start": 981.36, "end": 987.88, "text": " However, if you're doing an in-place merge, you can actually do the physical swap.", "tokens": [2908, 11, 498, 291, 434, 884, 364, 294, 12, 6742, 22183, 11, 291, 393, 767, 360, 264, 4001, 18135, 13], "temperature": 0.0, "avg_logprob": -0.10654068892856813, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.946612120373175e-05}, {"id": 251, "seek": 98788, "start": 987.88, "end": 992.28, "text": " And now you have for free a fallback for low memory merging.", "tokens": [400, 586, 291, 362, 337, 1737, 257, 2100, 3207, 337, 2295, 4675, 44559, 13], "temperature": 0.0, "avg_logprob": -0.12604220708211264, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.26566101750359e-05}, {"id": 252, "seek": 98788, "start": 992.28, "end": 997.96, "text": " So even if you don't have a large buffer available to merge with, you can use this algorithm", "tokens": [407, 754, 498, 291, 500, 380, 362, 257, 2416, 21762, 2435, 281, 22183, 365, 11, 291, 393, 764, 341, 9284], "temperature": 0.0, "avg_logprob": -0.12604220708211264, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.26566101750359e-05}, {"id": 253, "seek": 98788, "start": 997.96, "end": 1002.72, "text": " to do it in a low amount of memory.", "tokens": [281, 360, 309, 294, 257, 2295, 2372, 295, 4675, 13], "temperature": 0.0, "avg_logprob": -0.12604220708211264, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.26566101750359e-05}, {"id": 254, "seek": 98788, "start": 1002.72, "end": 1005.92, "text": " Then I also optimized the quicksort portion of it with the same principle.", "tokens": [1396, 286, 611, 26941, 264, 1702, 82, 477, 8044, 295, 309, 365, 264, 912, 8665, 13], "temperature": 0.0, "avg_logprob": -0.12604220708211264, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.26566101750359e-05}, {"id": 255, "seek": 98788, "start": 1005.92, "end": 1008.96, "text": " I came up with what I call bi-directional stable partitioning.", "tokens": [286, 1361, 493, 365, 437, 286, 818, 3228, 12, 18267, 41048, 8351, 24808, 278, 13], "temperature": 0.0, "avg_logprob": -0.12604220708211264, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.26566101750359e-05}, {"id": 256, "seek": 98788, "start": 1008.96, "end": 1014.92, "text": " Again, I don't have time to get into it, but the idea is that we do, again, partition", "tokens": [3764, 11, 286, 500, 380, 362, 565, 281, 483, 666, 309, 11, 457, 264, 1558, 307, 300, 321, 360, 11, 797, 11, 24808], "temperature": 0.0, "avg_logprob": -0.12604220708211264, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.26566101750359e-05}, {"id": 257, "seek": 98788, "start": 1014.92, "end": 1015.92, "text": " like in quicksort.", "tokens": [411, 294, 1702, 82, 477, 13], "temperature": 0.0, "avg_logprob": -0.12604220708211264, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.26566101750359e-05}, {"id": 258, "seek": 101592, "start": 1015.92, "end": 1020.8399999999999, "text": " So one set of elements that are less than the pivot goes somewhere else.", "tokens": [407, 472, 992, 295, 4959, 300, 366, 1570, 813, 264, 14538, 1709, 4079, 1646, 13], "temperature": 0.0, "avg_logprob": -0.16737615761636687, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.00021234859013929963}, {"id": 259, "seek": 101592, "start": 1020.8399999999999, "end": 1021.8399999999999, "text": " Go go here.", "tokens": [1037, 352, 510, 13], "temperature": 0.0, "avg_logprob": -0.16737615761636687, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.00021234859013929963}, {"id": 260, "seek": 101592, "start": 1021.8399999999999, "end": 1024.12, "text": " And some that are greater or equal go somewhere else.", "tokens": [400, 512, 300, 366, 5044, 420, 2681, 352, 4079, 1646, 13], "temperature": 0.0, "avg_logprob": -0.16737615761636687, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.00021234859013929963}, {"id": 261, "seek": 101592, "start": 1024.12, "end": 1028.3999999999999, "text": " But we do it from both the left-hand side to the right, and from the right-hand side", "tokens": [583, 321, 360, 309, 490, 1293, 264, 1411, 12, 5543, 1252, 281, 264, 558, 11, 293, 490, 264, 558, 12, 5543, 1252], "temperature": 0.0, "avg_logprob": -0.16737615761636687, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.00021234859013929963}, {"id": 262, "seek": 101592, "start": 1028.3999999999999, "end": 1029.3999999999999, "text": " to the left.", "tokens": [281, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.16737615761636687, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.00021234859013929963}, {"id": 263, "seek": 101592, "start": 1029.3999999999999, "end": 1032.6, "text": " And these two loops are independent from each other, so we can interleave them.", "tokens": [400, 613, 732, 16121, 366, 6695, 490, 1184, 661, 11, 370, 321, 393, 728, 306, 946, 552, 13], "temperature": 0.0, "avg_logprob": -0.16737615761636687, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.00021234859013929963}, {"id": 264, "seek": 101592, "start": 1032.6, "end": 1035.44, "text": " Same principle.", "tokens": [10635, 8665, 13], "temperature": 0.0, "avg_logprob": -0.16737615761636687, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.00021234859013929963}, {"id": 265, "seek": 101592, "start": 1035.44, "end": 1039.3999999999999, "text": " When you recurse, it gets a bit more involved, because now your data is in multiple different", "tokens": [1133, 291, 18680, 405, 11, 309, 2170, 257, 857, 544, 3288, 11, 570, 586, 428, 1412, 307, 294, 3866, 819], "temperature": 0.0, "avg_logprob": -0.16737615761636687, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.00021234859013929963}, {"id": 266, "seek": 101592, "start": 1039.3999999999999, "end": 1041.76, "text": " locations.", "tokens": [9253, 13], "temperature": 0.0, "avg_logprob": -0.16737615761636687, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.00021234859013929963}, {"id": 267, "seek": 104176, "start": 1041.76, "end": 1050.08, "text": " I can tell you this is not fun to program, but I did it, and here it is.", "tokens": [286, 393, 980, 291, 341, 307, 406, 1019, 281, 1461, 11, 457, 286, 630, 309, 11, 293, 510, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.1118029203170385, "compression_ratio": 1.5210526315789474, "no_speech_prob": 5.286708983476274e-05}, {"id": 268, "seek": 104176, "start": 1050.08, "end": 1057.08, "text": " So I do have some experiments to show you very briefly, an experiment of the setup.", "tokens": [407, 286, 360, 362, 512, 12050, 281, 855, 291, 588, 10515, 11, 364, 5120, 295, 264, 8657, 13], "temperature": 0.0, "avg_logprob": -0.1118029203170385, "compression_ratio": 1.5210526315789474, "no_speech_prob": 5.286708983476274e-05}, {"id": 269, "seek": 104176, "start": 1057.08, "end": 1066.44, "text": " So this is a lot of text that basically says a 2021 Apple MacBook.", "tokens": [407, 341, 307, 257, 688, 295, 2487, 300, 1936, 1619, 257, 7201, 6373, 31737, 13], "temperature": 0.0, "avg_logprob": -0.1118029203170385, "compression_ratio": 1.5210526315789474, "no_speech_prob": 5.286708983476274e-05}, {"id": 270, "seek": 104176, "start": 1066.44, "end": 1070.68, "text": " And these are the numbers you would get on an Apple 2021 MacBook.", "tokens": [400, 613, 366, 264, 3547, 291, 576, 483, 322, 364, 6373, 7201, 31737, 13], "temperature": 0.0, "avg_logprob": -0.1118029203170385, "compression_ratio": 1.5210526315789474, "no_speech_prob": 5.286708983476274e-05}, {"id": 271, "seek": 107068, "start": 1070.68, "end": 1073.8400000000001, "text": " So at the top, I have two variants of GlideSort.", "tokens": [407, 412, 264, 1192, 11, 286, 362, 732, 21669, 295, 5209, 482, 50, 477, 13], "temperature": 0.0, "avg_logprob": -0.1322789282168982, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.00014750099217053503}, {"id": 272, "seek": 107068, "start": 1073.8400000000001, "end": 1078.1200000000001, "text": " One is the default variant that you would get if you were to download it.", "tokens": [1485, 307, 264, 7576, 17501, 300, 291, 576, 483, 498, 291, 645, 281, 5484, 309, 13], "temperature": 0.0, "avg_logprob": -0.1322789282168982, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.00014750099217053503}, {"id": 273, "seek": 107068, "start": 1078.1200000000001, "end": 1085.6000000000001, "text": " GlideSort 1024 is a variant that uses a fixed amount of memory, so 1024 elements of memory.", "tokens": [5209, 482, 50, 477, 1266, 7911, 307, 257, 17501, 300, 4960, 257, 6806, 2372, 295, 4675, 11, 370, 1266, 7911, 4959, 295, 4675, 13], "temperature": 0.0, "avg_logprob": -0.1322789282168982, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.00014750099217053503}, {"id": 274, "seek": 107068, "start": 1085.6000000000001, "end": 1090.4, "text": " Then we have the Rust stable sort, the C++ standard stable sort, an implementation of", "tokens": [1396, 321, 362, 264, 34952, 8351, 1333, 11, 264, 383, 25472, 3832, 8351, 1333, 11, 364, 11420, 295], "temperature": 0.0, "avg_logprob": -0.1322789282168982, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.00014750099217053503}, {"id": 275, "seek": 107068, "start": 1090.4, "end": 1098.0, "text": " Tim sort, a PDQ sort, an older algorithm of mine, which is also the stable Rust sorting", "tokens": [7172, 1333, 11, 257, 10464, 48, 1333, 11, 364, 4906, 9284, 295, 3892, 11, 597, 307, 611, 264, 8351, 34952, 32411], "temperature": 0.0, "avg_logprob": -0.1322789282168982, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.00014750099217053503}, {"id": 276, "seek": 109800, "start": 1098.0, "end": 1105.64, "text": " algorithm, and the whatever shipped as the standard sort in C++.", "tokens": [9284, 11, 293, 264, 2035, 25312, 382, 264, 3832, 1333, 294, 383, 25472, 13], "temperature": 0.0, "avg_logprob": -0.21123034613473074, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.00010256258974550292}, {"id": 277, "seek": 109800, "start": 1105.64, "end": 1109.36, "text": " You can read the slides yourself.", "tokens": [509, 393, 1401, 264, 9788, 1803, 13], "temperature": 0.0, "avg_logprob": -0.21123034613473074, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.00010256258974550292}, {"id": 278, "seek": 109800, "start": 1109.36, "end": 1114.96, "text": " GlideSort is quite a bit faster than the Rust stable sort right now.", "tokens": [5209, 482, 50, 477, 307, 1596, 257, 857, 4663, 813, 264, 34952, 8351, 1333, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.21123034613473074, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.00010256258974550292}, {"id": 279, "seek": 109800, "start": 1114.96, "end": 1123.52, "text": " What isn't shown on this page are some more competitive algorithms, like Fluxort and Quadsort.", "tokens": [708, 1943, 380, 4898, 322, 341, 3028, 366, 512, 544, 10043, 14642, 11, 411, 3235, 2449, 477, 293, 2326, 5834, 477, 13], "temperature": 0.0, "avg_logprob": -0.21123034613473074, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.00010256258974550292}, {"id": 280, "seek": 112352, "start": 1123.52, "end": 1130.28, "text": " So they trade blows for blows on different data sets, but those are written in C, and", "tokens": [407, 436, 4923, 18458, 337, 18458, 322, 819, 1412, 6352, 11, 457, 729, 366, 3720, 294, 383, 11, 293], "temperature": 0.0, "avg_logprob": -0.14208137866148016, "compression_ratio": 1.6176470588235294, "no_speech_prob": 9.093643166124821e-05}, {"id": 281, "seek": 112352, "start": 1130.28, "end": 1136.16, "text": " they don't have to deal with some of the problems that we deal with that I'll get to later in", "tokens": [436, 500, 380, 362, 281, 2028, 365, 512, 295, 264, 2740, 300, 321, 2028, 365, 300, 286, 603, 483, 281, 1780, 294], "temperature": 0.0, "avg_logprob": -0.14208137866148016, "compression_ratio": 1.6176470588235294, "no_speech_prob": 9.093643166124821e-05}, {"id": 282, "seek": 112352, "start": 1136.16, "end": 1140.92, "text": " my talk on sorting in Rust.", "tokens": [452, 751, 322, 32411, 294, 34952, 13], "temperature": 0.0, "avg_logprob": -0.14208137866148016, "compression_ratio": 1.6176470588235294, "no_speech_prob": 9.093643166124821e-05}, {"id": 283, "seek": 112352, "start": 1140.92, "end": 1145.2, "text": " If you actually change your comparison operator, so we're only sorting by the last byte of", "tokens": [759, 291, 767, 1319, 428, 9660, 12973, 11, 370, 321, 434, 787, 32411, 538, 264, 1036, 40846, 295], "temperature": 0.0, "avg_logprob": -0.14208137866148016, "compression_ratio": 1.6176470588235294, "no_speech_prob": 9.093643166124821e-05}, {"id": 284, "seek": 112352, "start": 1145.2, "end": 1152.52, "text": " the integer, fun fact, if you do this, stability becomes even observable for integers.", "tokens": [264, 24922, 11, 1019, 1186, 11, 498, 291, 360, 341, 11, 11826, 3643, 754, 9951, 712, 337, 41674, 13], "temperature": 0.0, "avg_logprob": -0.14208137866148016, "compression_ratio": 1.6176470588235294, "no_speech_prob": 9.093643166124821e-05}, {"id": 285, "seek": 115252, "start": 1152.52, "end": 1158.12, "text": " GlideSort, again, speeds up even more compared to the Rust stable sorting algorithm.", "tokens": [5209, 482, 50, 477, 11, 797, 11, 16411, 493, 754, 544, 5347, 281, 264, 34952, 8351, 32411, 9284, 13], "temperature": 0.0, "avg_logprob": -0.1477504524530149, "compression_ratio": 1.5475113122171946, "no_speech_prob": 6.942842446733266e-05}, {"id": 286, "seek": 115252, "start": 1158.12, "end": 1166.2, "text": " So now we're over an order of magnitude faster for these data sets.", "tokens": [407, 586, 321, 434, 670, 364, 1668, 295, 15668, 4663, 337, 613, 1412, 6352, 13], "temperature": 0.0, "avg_logprob": -0.1477504524530149, "compression_ratio": 1.5475113122171946, "no_speech_prob": 6.942842446733266e-05}, {"id": 287, "seek": 115252, "start": 1166.2, "end": 1169.96, "text": " If you want to use it, good news, it's released.", "tokens": [759, 291, 528, 281, 764, 309, 11, 665, 2583, 11, 309, 311, 4736, 13], "temperature": 0.0, "avg_logprob": -0.1477504524530149, "compression_ratio": 1.5475113122171946, "no_speech_prob": 6.942842446733266e-05}, {"id": 288, "seek": 115252, "start": 1169.96, "end": 1173.0, "text": " It took me a while, but it's finally out.", "tokens": [467, 1890, 385, 257, 1339, 11, 457, 309, 311, 2721, 484, 13], "temperature": 0.0, "avg_logprob": -0.1477504524530149, "compression_ratio": 1.5475113122171946, "no_speech_prob": 6.942842446733266e-05}, {"id": 289, "seek": 115252, "start": 1173.0, "end": 1179.76, "text": " You can just cargo add GlideSort, and you can replace your sort, call to Slidesort with", "tokens": [509, 393, 445, 19449, 909, 5209, 482, 50, 477, 11, 293, 291, 393, 7406, 428, 1333, 11, 818, 281, 6187, 1875, 477, 365], "temperature": 0.0, "avg_logprob": -0.1477504524530149, "compression_ratio": 1.5475113122171946, "no_speech_prob": 6.942842446733266e-05}, {"id": 290, "seek": 115252, "start": 1179.76, "end": 1181.16, "text": " GlideSort.", "tokens": [5209, 482, 50, 477, 13], "temperature": 0.0, "avg_logprob": -0.1477504524530149, "compression_ratio": 1.5475113122171946, "no_speech_prob": 6.942842446733266e-05}, {"id": 291, "seek": 118116, "start": 1181.16, "end": 1186.3600000000001, "text": " If there are any standards library people in the audience come talk to me after the talk,", "tokens": [759, 456, 366, 604, 7787, 6405, 561, 294, 264, 4034, 808, 751, 281, 385, 934, 264, 751, 11], "temperature": 0.0, "avg_logprob": -0.1665681450112352, "compression_ratio": 1.5959183673469388, "no_speech_prob": 5.690084435627796e-05}, {"id": 292, "seek": 118116, "start": 1186.3600000000001, "end": 1190.44, "text": " I would love to see it integrated, so you don't have to call GlideSort, and it would", "tokens": [286, 576, 959, 281, 536, 309, 10919, 11, 370, 291, 500, 380, 362, 281, 818, 5209, 482, 50, 477, 11, 293, 309, 576], "temperature": 0.0, "avg_logprob": -0.1665681450112352, "compression_ratio": 1.5959183673469388, "no_speech_prob": 5.690084435627796e-05}, {"id": 293, "seek": 118116, "start": 1190.44, "end": 1194.6000000000001, "text": " just be done by default.", "tokens": [445, 312, 1096, 538, 7576, 13], "temperature": 0.0, "avg_logprob": -0.1665681450112352, "compression_ratio": 1.5959183673469388, "no_speech_prob": 5.690084435627796e-05}, {"id": 294, "seek": 118116, "start": 1194.6000000000001, "end": 1198.96, "text": " But this is a Rust dev room, so some of you at least probably are interested in Rust,", "tokens": [583, 341, 307, 257, 34952, 1905, 1808, 11, 370, 512, 295, 291, 412, 1935, 1391, 366, 3102, 294, 34952, 11], "temperature": 0.0, "avg_logprob": -0.1665681450112352, "compression_ratio": 1.5959183673469388, "no_speech_prob": 5.690084435627796e-05}, {"id": 295, "seek": 118116, "start": 1198.96, "end": 1203.76, "text": " so I will also talk about some Rust specifics, so what it takes to implement a sorting algorithm", "tokens": [370, 286, 486, 611, 751, 466, 512, 34952, 28454, 11, 370, 437, 309, 2516, 281, 4445, 257, 32411, 9284], "temperature": 0.0, "avg_logprob": -0.1665681450112352, "compression_ratio": 1.5959183673469388, "no_speech_prob": 5.690084435627796e-05}, {"id": 296, "seek": 118116, "start": 1203.76, "end": 1205.5600000000002, "text": " in Rust.", "tokens": [294, 34952, 13], "temperature": 0.0, "avg_logprob": -0.1665681450112352, "compression_ratio": 1.5959183673469388, "no_speech_prob": 5.690084435627796e-05}, {"id": 297, "seek": 120556, "start": 1205.56, "end": 1215.96, "text": " And first I'm just going to rant, unwinding panics, I think a Rust billion-dollar mistake.", "tokens": [400, 700, 286, 478, 445, 516, 281, 45332, 11, 14853, 9245, 2462, 1167, 11, 286, 519, 257, 34952, 5218, 12, 40485, 6146, 13], "temperature": 0.0, "avg_logprob": -0.15846529603004456, "compression_ratio": 1.5679012345679013, "no_speech_prob": 4.2452531488379464e-05}, {"id": 298, "seek": 120556, "start": 1215.96, "end": 1217.6, "text": " They are complete nightmare.", "tokens": [814, 366, 3566, 18724, 13], "temperature": 0.0, "avg_logprob": -0.15846529603004456, "compression_ratio": 1.5679012345679013, "no_speech_prob": 4.2452531488379464e-05}, {"id": 299, "seek": 120556, "start": 1217.6, "end": 1221.56, "text": " If you are writing unsafe code and you've ever had to deal with panic, some people in", "tokens": [759, 291, 366, 3579, 35948, 3089, 293, 291, 600, 1562, 632, 281, 2028, 365, 14783, 11, 512, 561, 294], "temperature": 0.0, "avg_logprob": -0.15846529603004456, "compression_ratio": 1.5679012345679013, "no_speech_prob": 4.2452531488379464e-05}, {"id": 300, "seek": 120556, "start": 1221.56, "end": 1227.48, "text": " the audience are laughing, they're horrible, because essentially, since you can catch them", "tokens": [264, 4034, 366, 5059, 11, 436, 434, 9263, 11, 570, 4476, 11, 1670, 291, 393, 3745, 552], "temperature": 0.0, "avg_logprob": -0.15846529603004456, "compression_ratio": 1.5679012345679013, "no_speech_prob": 4.2452531488379464e-05}, {"id": 301, "seek": 120556, "start": 1227.48, "end": 1234.56, "text": " and we have to be sound and safe during a panic, they're essentially the same as C++", "tokens": [293, 321, 362, 281, 312, 1626, 293, 3273, 1830, 257, 14783, 11, 436, 434, 4476, 264, 912, 382, 383, 25472], "temperature": 0.0, "avg_logprob": -0.15846529603004456, "compression_ratio": 1.5679012345679013, "no_speech_prob": 4.2452531488379464e-05}, {"id": 302, "seek": 123456, "start": 1234.56, "end": 1236.6799999999998, "text": " functions.", "tokens": [6828, 13], "temperature": 0.0, "avg_logprob": -0.15971941418117946, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.454294321476482e-05}, {"id": 303, "seek": 123456, "start": 1236.6799999999998, "end": 1241.8, "text": " In C++, all these functions say if you throw an exception, tough shit, like your vector", "tokens": [682, 383, 25472, 11, 439, 613, 6828, 584, 498, 291, 3507, 364, 11183, 11, 4930, 4611, 11, 411, 428, 8062], "temperature": 0.0, "avg_logprob": -0.15971941418117946, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.454294321476482e-05}, {"id": 304, "seek": 123456, "start": 1241.8, "end": 1246.6399999999999, "text": " is invalid now, too bad, it doesn't matter, you can't use it, you don't have the choice", "tokens": [307, 34702, 586, 11, 886, 1578, 11, 309, 1177, 380, 1871, 11, 291, 393, 380, 764, 309, 11, 291, 500, 380, 362, 264, 3922], "temperature": 0.0, "avg_logprob": -0.15971941418117946, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.454294321476482e-05}, {"id": 305, "seek": 123456, "start": 1246.6399999999999, "end": 1254.32, "text": " in Rust, you have to always be safe and sound in Rust, ensuring that is a nightmare, especially", "tokens": [294, 34952, 11, 291, 362, 281, 1009, 312, 3273, 293, 1626, 294, 34952, 11, 16882, 300, 307, 257, 18724, 11, 2318], "temperature": 0.0, "avg_logprob": -0.15971941418117946, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.454294321476482e-05}, {"id": 306, "seek": 123456, "start": 1254.32, "end": 1259.08, "text": " when you're dealing with generic code in unsafe code.", "tokens": [562, 291, 434, 6260, 365, 19577, 3089, 294, 35948, 3089, 13], "temperature": 0.0, "avg_logprob": -0.15971941418117946, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.454294321476482e-05}, {"id": 307, "seek": 125908, "start": 1259.08, "end": 1266.08, "text": " So if you're calling foreign code, anything you do, any call, can panic, which causes", "tokens": [407, 498, 291, 434, 5141, 5329, 3089, 11, 1340, 291, 360, 11, 604, 818, 11, 393, 14783, 11, 597, 7700], "temperature": 0.0, "avg_logprob": -0.12066990988595146, "compression_ratio": 1.7268041237113403, "no_speech_prob": 2.1668653062079102e-05}, {"id": 308, "seek": 125908, "start": 1266.08, "end": 1267.08, "text": " an unwind.", "tokens": [364, 517, 12199, 13], "temperature": 0.0, "avg_logprob": -0.12066990988595146, "compression_ratio": 1.7268041237113403, "no_speech_prob": 2.1668653062079102e-05}, {"id": 309, "seek": 125908, "start": 1267.08, "end": 1271.52, "text": " So whenever you call a foreign function, you have to make sure that you are in a sound", "tokens": [407, 5699, 291, 818, 257, 5329, 2445, 11, 291, 362, 281, 652, 988, 300, 291, 366, 294, 257, 1626], "temperature": 0.0, "avg_logprob": -0.12066990988595146, "compression_ratio": 1.7268041237113403, "no_speech_prob": 2.1668653062079102e-05}, {"id": 310, "seek": 125908, "start": 1271.52, "end": 1274.76, "text": " and safe state.", "tokens": [293, 3273, 1785, 13], "temperature": 0.0, "avg_logprob": -0.12066990988595146, "compression_ratio": 1.7268041237113403, "no_speech_prob": 2.1668653062079102e-05}, {"id": 311, "seek": 125908, "start": 1274.76, "end": 1278.36, "text": " The problem is every single trait is foreign code.", "tokens": [440, 1154, 307, 633, 2167, 22538, 307, 5329, 3089, 13], "temperature": 0.0, "avg_logprob": -0.12066990988595146, "compression_ratio": 1.7268041237113403, "no_speech_prob": 2.1668653062079102e-05}, {"id": 312, "seek": 125908, "start": 1278.36, "end": 1280.56, "text": " That clone call, that's foreign code.", "tokens": [663, 26506, 818, 11, 300, 311, 5329, 3089, 13], "temperature": 0.0, "avg_logprob": -0.12066990988595146, "compression_ratio": 1.7268041237113403, "no_speech_prob": 2.1668653062079102e-05}, {"id": 313, "seek": 125908, "start": 1280.56, "end": 1284.84, "text": " This comparison operator, that's foreign code.", "tokens": [639, 9660, 12973, 11, 300, 311, 5329, 3089, 13], "temperature": 0.0, "avg_logprob": -0.12066990988595146, "compression_ratio": 1.7268041237113403, "no_speech_prob": 2.1668653062079102e-05}, {"id": 314, "seek": 128484, "start": 1284.84, "end": 1289.12, "text": " Lightning Glider was a complete nightmare, every time I compare two elements, that could", "tokens": [28848, 5209, 1438, 390, 257, 3566, 18724, 11, 633, 565, 286, 6794, 732, 4959, 11, 300, 727], "temperature": 0.0, "avg_logprob": -0.16963805574359317, "compression_ratio": 1.8823529411764706, "no_speech_prob": 0.00037383081507869065}, {"id": 315, "seek": 128484, "start": 1289.12, "end": 1292.9199999999998, "text": " cause a panic, that could cause an unwind, and you saw all this stuff that I'm doing", "tokens": [3082, 257, 14783, 11, 300, 727, 3082, 364, 517, 12199, 11, 293, 291, 1866, 439, 341, 1507, 300, 286, 478, 884], "temperature": 0.0, "avg_logprob": -0.16963805574359317, "compression_ratio": 1.8823529411764706, "no_speech_prob": 0.00037383081507869065}, {"id": 316, "seek": 128484, "start": 1292.9199999999998, "end": 1298.12, "text": " with arrays all over the place, all of that has to be restored to the original location", "tokens": [365, 41011, 439, 670, 264, 1081, 11, 439, 295, 300, 575, 281, 312, 23143, 281, 264, 3380, 4914], "temperature": 0.0, "avg_logprob": -0.16963805574359317, "compression_ratio": 1.8823529411764706, "no_speech_prob": 0.00037383081507869065}, {"id": 317, "seek": 128484, "start": 1298.12, "end": 1302.3999999999999, "text": " because it's a mudslice, and you cannot leave a mudslice in an unsound or you can't leave", "tokens": [570, 309, 311, 257, 8933, 10418, 573, 11, 293, 291, 2644, 1856, 257, 8933, 10418, 573, 294, 364, 2693, 554, 420, 291, 393, 380, 1856], "temperature": 0.0, "avg_logprob": -0.16963805574359317, "compression_ratio": 1.8823529411764706, "no_speech_prob": 0.00037383081507869065}, {"id": 318, "seek": 128484, "start": 1302.3999999999999, "end": 1306.6799999999998, "text": " holes in it, everything has to be returned to the original array.", "tokens": [8118, 294, 309, 11, 1203, 575, 281, 312, 8752, 281, 264, 3380, 10225, 13], "temperature": 0.0, "avg_logprob": -0.16963805574359317, "compression_ratio": 1.8823529411764706, "no_speech_prob": 0.00037383081507869065}, {"id": 319, "seek": 128484, "start": 1306.6799999999998, "end": 1312.9199999999998, "text": " Yeah, it's a nightmare, I really wish we would just, instead of panicking, we would just write", "tokens": [865, 11, 309, 311, 257, 18724, 11, 286, 534, 3172, 321, 576, 445, 11, 2602, 295, 2462, 10401, 11, 321, 576, 445, 2464], "temperature": 0.0, "avg_logprob": -0.16963805574359317, "compression_ratio": 1.8823529411764706, "no_speech_prob": 0.00037383081507869065}, {"id": 320, "seek": 131292, "start": 1312.92, "end": 1316.96, "text": " out a stack trace and abort and be done with it.", "tokens": [484, 257, 8630, 13508, 293, 38117, 293, 312, 1096, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.25279056595032473, "compression_ratio": 1.4202127659574468, "no_speech_prob": 8.129352499963716e-05}, {"id": 321, "seek": 131292, "start": 1316.96, "end": 1320.64, "text": " I hate it, that's my rant.", "tokens": [286, 4700, 309, 11, 300, 311, 452, 45332, 13], "temperature": 0.0, "avg_logprob": -0.25279056595032473, "compression_ratio": 1.4202127659574468, "no_speech_prob": 8.129352499963716e-05}, {"id": 322, "seek": 131292, "start": 1320.64, "end": 1328.04, "text": " Oh yeah, well, and in fact, GlideSort has an actual real performance penalty because", "tokens": [876, 1338, 11, 731, 11, 293, 294, 1186, 11, 5209, 482, 50, 477, 575, 364, 3539, 957, 3389, 16263, 570], "temperature": 0.0, "avg_logprob": -0.25279056595032473, "compression_ratio": 1.4202127659574468, "no_speech_prob": 8.129352499963716e-05}, {"id": 323, "seek": 131292, "start": 1328.04, "end": 1331.3200000000002, "text": " panics are a thing.", "tokens": [2462, 1167, 366, 257, 551, 13], "temperature": 0.0, "avg_logprob": -0.25279056595032473, "compression_ratio": 1.4202127659574468, "no_speech_prob": 8.129352499963716e-05}, {"id": 324, "seek": 131292, "start": 1331.3200000000002, "end": 1338.3200000000002, "text": " I can't just write a, like if you're writing an insertion sort, for example, in C++ or", "tokens": [286, 393, 380, 445, 2464, 257, 11, 411, 498, 291, 434, 3579, 364, 8969, 313, 1333, 11, 337, 1365, 11, 294, 383, 25472, 420], "temperature": 0.0, "avg_logprob": -0.25279056595032473, "compression_ratio": 1.4202127659574468, "no_speech_prob": 8.129352499963716e-05}, {"id": 325, "seek": 133832, "start": 1338.32, "end": 1344.3999999999999, "text": " in Python, you would just have a loop with a loop variable and you would put the items", "tokens": [294, 15329, 11, 291, 576, 445, 362, 257, 6367, 365, 257, 6367, 7006, 293, 291, 576, 829, 264, 4754], "temperature": 0.0, "avg_logprob": -0.11317593443627451, "compression_ratio": 1.7973568281938326, "no_speech_prob": 3.438939529587515e-05}, {"id": 326, "seek": 133832, "start": 1344.3999999999999, "end": 1346.2, "text": " in the correct place.", "tokens": [294, 264, 3006, 1081, 13], "temperature": 0.0, "avg_logprob": -0.11317593443627451, "compression_ratio": 1.7973568281938326, "no_speech_prob": 3.438939529587515e-05}, {"id": 327, "seek": 133832, "start": 1346.2, "end": 1350.2, "text": " If you're implementing a thing like this in Rust and you're leaving gaps, so you're", "tokens": [759, 291, 434, 18114, 257, 551, 411, 341, 294, 34952, 293, 291, 434, 5012, 15031, 11, 370, 291, 434], "temperature": 0.0, "avg_logprob": -0.11317593443627451, "compression_ratio": 1.7973568281938326, "no_speech_prob": 3.438939529587515e-05}, {"id": 328, "seek": 133832, "start": 1350.2, "end": 1355.24, "text": " moving the element out during the insertion sort, you have to have a drop handler that", "tokens": [2684, 264, 4478, 484, 1830, 264, 8969, 313, 1333, 11, 291, 362, 281, 362, 257, 3270, 41967, 300], "temperature": 0.0, "avg_logprob": -0.11317593443627451, "compression_ratio": 1.7973568281938326, "no_speech_prob": 3.438939529587515e-05}, {"id": 329, "seek": 133832, "start": 1355.24, "end": 1360.6799999999998, "text": " puts this element back during a panic because this ORD implementation, this foreign code,", "tokens": [8137, 341, 4478, 646, 1830, 257, 14783, 570, 341, 19654, 35, 11420, 11, 341, 5329, 3089, 11], "temperature": 0.0, "avg_logprob": -0.11317593443627451, "compression_ratio": 1.7973568281938326, "no_speech_prob": 3.438939529587515e-05}, {"id": 330, "seek": 133832, "start": 1360.6799999999998, "end": 1364.12, "text": " can cause a panic and cause an unwind.", "tokens": [393, 3082, 257, 14783, 293, 3082, 364, 517, 12199, 13], "temperature": 0.0, "avg_logprob": -0.11317593443627451, "compression_ratio": 1.7973568281938326, "no_speech_prob": 3.438939529587515e-05}, {"id": 331, "seek": 136412, "start": 1364.12, "end": 1368.76, "text": " So even when I'm sorting something like integers, which cannot panic, if I don't want to duplicate", "tokens": [407, 754, 562, 286, 478, 32411, 746, 411, 41674, 11, 597, 2644, 14783, 11, 498, 286, 500, 380, 528, 281, 23976], "temperature": 0.0, "avg_logprob": -0.15798063631410952, "compression_ratio": 1.5859375, "no_speech_prob": 2.234442399640102e-05}, {"id": 332, "seek": 136412, "start": 1368.76, "end": 1374.36, "text": " my entire code base, I still have to pay this penalty for dealing with the potential for", "tokens": [452, 2302, 3089, 3096, 11, 286, 920, 362, 281, 1689, 341, 16263, 337, 6260, 365, 264, 3995, 337], "temperature": 0.0, "avg_logprob": -0.15798063631410952, "compression_ratio": 1.5859375, "no_speech_prob": 2.234442399640102e-05}, {"id": 333, "seek": 136412, "start": 1374.36, "end": 1378.8799999999999, "text": " panics by storing all my data, instructs, and all this algorithm state.", "tokens": [2462, 1167, 538, 26085, 439, 452, 1412, 11, 7232, 82, 11, 293, 439, 341, 9284, 1785, 13], "temperature": 0.0, "avg_logprob": -0.15798063631410952, "compression_ratio": 1.5859375, "no_speech_prob": 2.234442399640102e-05}, {"id": 334, "seek": 136412, "start": 1378.8799999999999, "end": 1382.6799999999998, "text": " So yeah, that's a problem.", "tokens": [407, 1338, 11, 300, 311, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.15798063631410952, "compression_ratio": 1.5859375, "no_speech_prob": 2.234442399640102e-05}, {"id": 335, "seek": 136412, "start": 1382.6799999999998, "end": 1386.8, "text": " But I also want to praise Rust, where it is pleasurable.", "tokens": [583, 286, 611, 528, 281, 13286, 34952, 11, 689, 309, 307, 35122, 25863, 13], "temperature": 0.0, "avg_logprob": -0.15798063631410952, "compression_ratio": 1.5859375, "no_speech_prob": 2.234442399640102e-05}, {"id": 336, "seek": 136412, "start": 1386.8, "end": 1388.84, "text": " I love that moves are mem copies.", "tokens": [286, 959, 300, 6067, 366, 1334, 14341, 13], "temperature": 0.0, "avg_logprob": -0.15798063631410952, "compression_ratio": 1.5859375, "no_speech_prob": 2.234442399640102e-05}, {"id": 337, "seek": 136412, "start": 1388.84, "end": 1389.9199999999998, "text": " There's no move constructor.", "tokens": [821, 311, 572, 1286, 47479, 13], "temperature": 0.0, "avg_logprob": -0.15798063631410952, "compression_ratio": 1.5859375, "no_speech_prob": 2.234442399640102e-05}, {"id": 338, "seek": 138992, "start": 1389.92, "end": 1395.2, "text": " If you want to move a type somewhere else, you essentially just copy it and you ignore", "tokens": [759, 291, 528, 281, 1286, 257, 2010, 4079, 1646, 11, 291, 4476, 445, 5055, 309, 293, 291, 11200], "temperature": 0.0, "avg_logprob": -0.1820263964064578, "compression_ratio": 1.5518672199170125, "no_speech_prob": 5.973070074105635e-05}, {"id": 339, "seek": 138992, "start": 1395.2, "end": 1397.48, "text": " whatever, wherever it came from.", "tokens": [2035, 11, 8660, 309, 1361, 490, 13], "temperature": 0.0, "avg_logprob": -0.1820263964064578, "compression_ratio": 1.5518672199170125, "no_speech_prob": 5.973070074105635e-05}, {"id": 340, "seek": 138992, "start": 1397.48, "end": 1403.16, "text": " This also makes optimizations possible that aren't possible in C++ because of move constructors,", "tokens": [639, 611, 1669, 5028, 14455, 1944, 300, 3212, 380, 1944, 294, 383, 25472, 570, 295, 1286, 7690, 830, 11], "temperature": 0.0, "avg_logprob": -0.1820263964064578, "compression_ratio": 1.5518672199170125, "no_speech_prob": 5.973070074105635e-05}, {"id": 341, "seek": 138992, "start": 1403.16, "end": 1408.52, "text": " at least not if you don't want to use like templates metaprogramming.", "tokens": [412, 1935, 406, 498, 291, 500, 380, 528, 281, 764, 411, 21165, 1131, 569, 340, 1342, 2810, 13], "temperature": 0.0, "avg_logprob": -0.1820263964064578, "compression_ratio": 1.5518672199170125, "no_speech_prob": 5.973070074105635e-05}, {"id": 342, "seek": 138992, "start": 1408.52, "end": 1414.68, "text": " For example, instead of copying an element, this is an example actually from GlideSort,", "tokens": [1171, 1365, 11, 2602, 295, 27976, 364, 4478, 11, 341, 307, 364, 1365, 767, 490, 5209, 482, 50, 477, 11], "temperature": 0.0, "avg_logprob": -0.1820263964064578, "compression_ratio": 1.5518672199170125, "no_speech_prob": 5.973070074105635e-05}, {"id": 343, "seek": 141468, "start": 1414.68, "end": 1420.48, "text": " not written like this, but where you place an element in one of two places, and if it's", "tokens": [406, 3720, 411, 341, 11, 457, 689, 291, 1081, 364, 4478, 294, 472, 295, 732, 3190, 11, 293, 498, 309, 311], "temperature": 0.0, "avg_logprob": -0.169815687375648, "compression_ratio": 1.5850622406639003, "no_speech_prob": 7.845408254070207e-05}, {"id": 344, "seek": 141468, "start": 1420.48, "end": 1424.44, "text": " going to the wrong place, it doesn't matter because it will just be ignored or overwritten", "tokens": [516, 281, 264, 2085, 1081, 11, 309, 1177, 380, 1871, 570, 309, 486, 445, 312, 19735, 420, 670, 26859], "temperature": 0.0, "avg_logprob": -0.169815687375648, "compression_ratio": 1.5850622406639003, "no_speech_prob": 7.845408254070207e-05}, {"id": 345, "seek": 141468, "start": 1424.44, "end": 1426.72, "text": " in the next iteration.", "tokens": [294, 264, 958, 24784, 13], "temperature": 0.0, "avg_logprob": -0.169815687375648, "compression_ratio": 1.5850622406639003, "no_speech_prob": 7.845408254070207e-05}, {"id": 346, "seek": 141468, "start": 1426.72, "end": 1431.16, "text": " If it's a small type, just place it in both, don't do a branch.", "tokens": [759, 309, 311, 257, 1359, 2010, 11, 445, 1081, 309, 294, 1293, 11, 500, 380, 360, 257, 9819, 13], "temperature": 0.0, "avg_logprob": -0.169815687375648, "compression_ratio": 1.5850622406639003, "no_speech_prob": 7.845408254070207e-05}, {"id": 347, "seek": 141468, "start": 1431.16, "end": 1434.48, "text": " So essentially, this is the opposite of unwinding panics.", "tokens": [407, 4476, 11, 341, 307, 264, 6182, 295, 14853, 9245, 2462, 1167, 13], "temperature": 0.0, "avg_logprob": -0.169815687375648, "compression_ratio": 1.5850622406639003, "no_speech_prob": 7.845408254070207e-05}, {"id": 348, "seek": 141468, "start": 1434.48, "end": 1435.48, "text": " There are no surprises.", "tokens": [821, 366, 572, 22655, 13], "temperature": 0.0, "avg_logprob": -0.169815687375648, "compression_ratio": 1.5850622406639003, "no_speech_prob": 7.845408254070207e-05}, {"id": 349, "seek": 141468, "start": 1435.48, "end": 1441.1200000000001, "text": " A mem copy is always what you get.", "tokens": [316, 1334, 5055, 307, 1009, 437, 291, 483, 13], "temperature": 0.0, "avg_logprob": -0.169815687375648, "compression_ratio": 1.5850622406639003, "no_speech_prob": 7.845408254070207e-05}, {"id": 350, "seek": 144112, "start": 1441.12, "end": 1445.6, "text": " This is not necessarily, it's part praise, part complaining.", "tokens": [639, 307, 406, 4725, 11, 309, 311, 644, 13286, 11, 644, 20740, 13], "temperature": 0.0, "avg_logprob": -0.19748986777612718, "compression_ratio": 1.640495867768595, "no_speech_prob": 3.050180384889245e-05}, {"id": 351, "seek": 144112, "start": 1445.6, "end": 1451.04, "text": " Split at mutt, so splitting a slice into or more.", "tokens": [45111, 412, 5839, 83, 11, 370, 30348, 257, 13153, 666, 420, 544, 13], "temperature": 0.0, "avg_logprob": -0.19748986777612718, "compression_ratio": 1.640495867768595, "no_speech_prob": 3.050180384889245e-05}, {"id": 352, "seek": 144112, "start": 1451.04, "end": 1452.04, "text": " It's a one-way street.", "tokens": [467, 311, 257, 472, 12, 676, 4838, 13], "temperature": 0.0, "avg_logprob": -0.19748986777612718, "compression_ratio": 1.640495867768595, "no_speech_prob": 3.050180384889245e-05}, {"id": 353, "seek": 144112, "start": 1452.04, "end": 1453.04, "text": " You cannot go back.", "tokens": [509, 2644, 352, 646, 13], "temperature": 0.0, "avg_logprob": -0.19748986777612718, "compression_ratio": 1.640495867768595, "no_speech_prob": 3.050180384889245e-05}, {"id": 354, "seek": 144112, "start": 1453.04, "end": 1454.04, "text": " Once it's split, it's split.", "tokens": [3443, 309, 311, 7472, 11, 309, 311, 7472, 13], "temperature": 0.0, "avg_logprob": -0.19748986777612718, "compression_ratio": 1.640495867768595, "no_speech_prob": 3.050180384889245e-05}, {"id": 355, "seek": 144112, "start": 1454.04, "end": 1458.08, "text": " Unless you go back to the original object, but that's not always an option.", "tokens": [16581, 291, 352, 646, 281, 264, 3380, 2657, 11, 457, 300, 311, 406, 1009, 364, 3614, 13], "temperature": 0.0, "avg_logprob": -0.19748986777612718, "compression_ratio": 1.640495867768595, "no_speech_prob": 3.050180384889245e-05}, {"id": 356, "seek": 144112, "start": 1458.08, "end": 1465.4399999999998, "text": " In GlideSort, when I concatenate these arrays, slices, I need actual concatenation.", "tokens": [682, 5209, 482, 50, 477, 11, 562, 286, 1588, 7186, 473, 613, 41011, 11, 19793, 11, 286, 643, 3539, 1588, 7186, 399, 13], "temperature": 0.0, "avg_logprob": -0.19748986777612718, "compression_ratio": 1.640495867768595, "no_speech_prob": 3.050180384889245e-05}, {"id": 357, "seek": 144112, "start": 1465.4399999999998, "end": 1470.0, "text": " My options were raw pointers, but that was the option.", "tokens": [1222, 3956, 645, 8936, 44548, 11, 457, 300, 390, 264, 3614, 13], "temperature": 0.0, "avg_logprob": -0.19748986777612718, "compression_ratio": 1.640495867768595, "no_speech_prob": 3.050180384889245e-05}, {"id": 358, "seek": 147000, "start": 1470.0, "end": 1474.84, "text": " You are storing an array with indices, but now you're storing an extra pointer everywhere", "tokens": [509, 366, 26085, 364, 10225, 365, 43840, 11, 457, 586, 291, 434, 26085, 364, 2857, 23918, 5315], "temperature": 0.0, "avg_logprob": -0.13382916083702676, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0001943177339853719}, {"id": 359, "seek": 147000, "start": 1474.84, "end": 1479.48, "text": " and passing an extra pointer everywhere, and that's overhead that I didn't want to pay.", "tokens": [293, 8437, 364, 2857, 23918, 5315, 11, 293, 300, 311, 19922, 300, 286, 994, 380, 528, 281, 1689, 13], "temperature": 0.0, "avg_logprob": -0.13382916083702676, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0001943177339853719}, {"id": 360, "seek": 147000, "start": 1479.48, "end": 1482.0, "text": " So I came up with a thing I call branded slices.", "tokens": [407, 286, 1361, 493, 365, 257, 551, 286, 818, 38510, 19793, 13], "temperature": 0.0, "avg_logprob": -0.13382916083702676, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0001943177339853719}, {"id": 361, "seek": 147000, "start": 1482.0, "end": 1486.84, "text": " You could hold an entire talk on this, but it's essentially applying the idea of a ghost", "tokens": [509, 727, 1797, 364, 2302, 751, 322, 341, 11, 457, 309, 311, 4476, 9275, 264, 1558, 295, 257, 8359], "temperature": 0.0, "avg_logprob": -0.13382916083702676, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0001943177339853719}, {"id": 362, "seek": 147000, "start": 1486.84, "end": 1487.84, "text": " cell.", "tokens": [2815, 13], "temperature": 0.0, "avg_logprob": -0.13382916083702676, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0001943177339853719}, {"id": 363, "seek": 147000, "start": 1487.84, "end": 1492.92, "text": " Some of you might have heard from this, where you essentially brand a type with a unique", "tokens": [2188, 295, 291, 1062, 362, 2198, 490, 341, 11, 689, 291, 4476, 3360, 257, 2010, 365, 257, 3845], "temperature": 0.0, "avg_logprob": -0.13382916083702676, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0001943177339853719}, {"id": 364, "seek": 147000, "start": 1492.92, "end": 1494.84, "text": " lifetime that you cannot create.", "tokens": [11364, 300, 291, 2644, 1884, 13], "temperature": 0.0, "avg_logprob": -0.13382916083702676, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0001943177339853719}, {"id": 365, "seek": 147000, "start": 1494.84, "end": 1499.48, "text": " You can only create this lifetime once, and it's not interchangeable with any other lifetime.", "tokens": [509, 393, 787, 1884, 341, 11364, 1564, 11, 293, 309, 311, 406, 30358, 712, 365, 604, 661, 11364, 13], "temperature": 0.0, "avg_logprob": -0.13382916083702676, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0001943177339853719}, {"id": 366, "seek": 149948, "start": 1499.48, "end": 1504.0, "text": " And with that, you can make safe concatenation.", "tokens": [400, 365, 300, 11, 291, 393, 652, 3273, 1588, 7186, 399, 13], "temperature": 0.0, "avg_logprob": -0.15089492797851561, "compression_ratio": 1.75, "no_speech_prob": 9.033937385538593e-05}, {"id": 367, "seek": 149948, "start": 1504.0, "end": 1508.08, "text": " So you could just check, is the end pointer equal to the begin pointer of the other array", "tokens": [407, 291, 727, 445, 1520, 11, 307, 264, 917, 23918, 2681, 281, 264, 1841, 23918, 295, 264, 661, 10225], "temperature": 0.0, "avg_logprob": -0.15089492797851561, "compression_ratio": 1.75, "no_speech_prob": 9.033937385538593e-05}, {"id": 368, "seek": 149948, "start": 1508.08, "end": 1509.84, "text": " if yes, we can concatenate?", "tokens": [498, 2086, 11, 321, 393, 1588, 7186, 473, 30], "temperature": 0.0, "avg_logprob": -0.15089492797851561, "compression_ratio": 1.75, "no_speech_prob": 9.033937385538593e-05}, {"id": 369, "seek": 149948, "start": 1509.84, "end": 1514.04, "text": " And that will work, except that could also just be happening by chance because of the", "tokens": [400, 300, 486, 589, 11, 3993, 300, 727, 611, 445, 312, 2737, 538, 2931, 570, 295, 264], "temperature": 0.0, "avg_logprob": -0.15089492797851561, "compression_ratio": 1.75, "no_speech_prob": 9.033937385538593e-05}, {"id": 370, "seek": 149948, "start": 1514.04, "end": 1518.08, "text": " local array layout on the stack, and you could create unsound behavior.", "tokens": [2654, 10225, 13333, 322, 264, 8630, 11, 293, 291, 727, 1884, 2693, 554, 5223, 13], "temperature": 0.0, "avg_logprob": -0.15089492797851561, "compression_ratio": 1.75, "no_speech_prob": 9.033937385538593e-05}, {"id": 371, "seek": 149948, "start": 1518.08, "end": 1524.88, "text": " But if you know that they came from the same allocation, then it's safe to concatenate", "tokens": [583, 498, 291, 458, 300, 436, 1361, 490, 264, 912, 27599, 11, 550, 309, 311, 3273, 281, 1588, 7186, 473], "temperature": 0.0, "avg_logprob": -0.15089492797851561, "compression_ratio": 1.75, "no_speech_prob": 9.033937385538593e-05}, {"id": 372, "seek": 149948, "start": 1524.88, "end": 1527.52, "text": " them after checking and equals begin.", "tokens": [552, 934, 8568, 293, 6915, 1841, 13], "temperature": 0.0, "avg_logprob": -0.15089492797851561, "compression_ratio": 1.75, "no_speech_prob": 9.033937385538593e-05}, {"id": 373, "seek": 152752, "start": 1527.52, "end": 1535.36, "text": " So that's what I did with what I call mudslice, which in GlideSword, every single slice is", "tokens": [407, 300, 311, 437, 286, 630, 365, 437, 286, 818, 8933, 10418, 573, 11, 597, 294, 5209, 482, 50, 7462, 11, 633, 2167, 13153, 307], "temperature": 0.0, "avg_logprob": -0.17763116066915946, "compression_ratio": 1.7523809523809524, "no_speech_prob": 9.396707901032642e-05}, {"id": 374, "seek": 152752, "start": 1535.36, "end": 1541.76, "text": " a mudslice type, which has a brand, so you can do the safe concatenation, and it has", "tokens": [257, 8933, 10418, 573, 2010, 11, 597, 575, 257, 3360, 11, 370, 291, 393, 360, 264, 3273, 1588, 7186, 399, 11, 293, 309, 575], "temperature": 0.0, "avg_logprob": -0.17763116066915946, "compression_ratio": 1.7523809523809524, "no_speech_prob": 9.396707901032642e-05}, {"id": 375, "seek": 152752, "start": 1541.76, "end": 1544.56, "text": " a state, which is one of five things.", "tokens": [257, 1785, 11, 597, 307, 472, 295, 1732, 721, 13], "temperature": 0.0, "avg_logprob": -0.17763116066915946, "compression_ratio": 1.7523809523809524, "no_speech_prob": 9.396707901032642e-05}, {"id": 376, "seek": 152752, "start": 1544.56, "end": 1548.08, "text": " It's weak on in it, maybe in it, in it, always in it.", "tokens": [467, 311, 5336, 322, 294, 309, 11, 1310, 294, 309, 11, 294, 309, 11, 1009, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.17763116066915946, "compression_ratio": 1.7523809523809524, "no_speech_prob": 9.396707901032642e-05}, {"id": 377, "seek": 152752, "start": 1548.08, "end": 1554.44, "text": " Always in it, essentially, a mutable slice, so you always have to return it to initialization", "tokens": [11270, 294, 309, 11, 4476, 11, 257, 5839, 712, 13153, 11, 370, 291, 1009, 362, 281, 2736, 309, 281, 5883, 2144], "temperature": 0.0, "avg_logprob": -0.17763116066915946, "compression_ratio": 1.7523809523809524, "no_speech_prob": 9.396707901032642e-05}, {"id": 378, "seek": 152752, "start": 1554.44, "end": 1555.44, "text": " state.", "tokens": [1785, 13], "temperature": 0.0, "avg_logprob": -0.17763116066915946, "compression_ratio": 1.7523809523809524, "no_speech_prob": 9.396707901032642e-05}, {"id": 379, "seek": 155544, "start": 1555.44, "end": 1561.0800000000002, "text": " And maybe on in it, in it are a bit more specialized than just maybe on in it, where the type doesn't", "tokens": [400, 1310, 322, 294, 309, 11, 294, 309, 366, 257, 857, 544, 19813, 813, 445, 1310, 322, 294, 309, 11, 689, 264, 2010, 1177, 380], "temperature": 0.0, "avg_logprob": -0.1427906821755802, "compression_ratio": 1.7611336032388665, "no_speech_prob": 6.830926577094942e-05}, {"id": 380, "seek": 155544, "start": 1561.0800000000002, "end": 1566.1200000000001, "text": " really encode what it actually contains, and weak is essentially a pair of pointers.", "tokens": [534, 2058, 1429, 437, 309, 767, 8306, 11, 293, 5336, 307, 4476, 257, 6119, 295, 44548, 13], "temperature": 0.0, "avg_logprob": -0.1427906821755802, "compression_ratio": 1.7611336032388665, "no_speech_prob": 6.830926577094942e-05}, {"id": 381, "seek": 155544, "start": 1566.1200000000001, "end": 1572.8400000000001, "text": " And then the code becomes a lot more readable and a lot more verifiable by explicitly encoding", "tokens": [400, 550, 264, 3089, 3643, 257, 688, 544, 49857, 293, 257, 688, 544, 1306, 30876, 538, 20803, 43430], "temperature": 0.0, "avg_logprob": -0.1427906821755802, "compression_ratio": 1.7611336032388665, "no_speech_prob": 6.830926577094942e-05}, {"id": 382, "seek": 155544, "start": 1572.8400000000001, "end": 1578.4, "text": " your assumptions about your slice type using the type, and then calling functions like", "tokens": [428, 17695, 466, 428, 13153, 2010, 1228, 264, 2010, 11, 293, 550, 5141, 6828, 411], "temperature": 0.0, "avg_logprob": -0.1427906821755802, "compression_ratio": 1.7611336032388665, "no_speech_prob": 6.830926577094942e-05}, {"id": 383, "seek": 155544, "start": 1578.4, "end": 1582.04, "text": " upgrades to say, hey, this now becomes an exclusive mutably slice.", "tokens": [24868, 281, 584, 11, 4177, 11, 341, 586, 3643, 364, 13005, 5839, 1188, 13153, 13], "temperature": 0.0, "avg_logprob": -0.1427906821755802, "compression_ratio": 1.7611336032388665, "no_speech_prob": 6.830926577094942e-05}, {"id": 384, "seek": 158204, "start": 1582.04, "end": 1589.2, "text": " I'm only going to access this here, or hey, I'm now going to temporarily invalidate this", "tokens": [286, 478, 787, 516, 281, 2105, 341, 510, 11, 420, 4177, 11, 286, 478, 586, 516, 281, 23750, 34702, 473, 341], "temperature": 0.0, "avg_logprob": -0.16908840032724234, "compression_ratio": 1.5595854922279793, "no_speech_prob": 0.00012544130731839687}, {"id": 385, "seek": 158204, "start": 1589.2, "end": 1593.8, "text": " initialization state of this slice.", "tokens": [5883, 2144, 1785, 295, 341, 13153, 13], "temperature": 0.0, "avg_logprob": -0.16908840032724234, "compression_ratio": 1.5595854922279793, "no_speech_prob": 0.00012544130731839687}, {"id": 386, "seek": 158204, "start": 1593.8, "end": 1595.44, "text": " That was essentially my talk.", "tokens": [663, 390, 4476, 452, 751, 13], "temperature": 0.0, "avg_logprob": -0.16908840032724234, "compression_ratio": 1.5595854922279793, "no_speech_prob": 0.00012544130731839687}, {"id": 387, "seek": 158204, "start": 1595.44, "end": 1602.68, "text": " I'm leaving academia, so if you have an interesting, potentially rust job, my contact details", "tokens": [286, 478, 5012, 28937, 11, 370, 498, 291, 362, 364, 1880, 11, 7263, 15259, 1691, 11, 452, 3385, 4365], "temperature": 0.0, "avg_logprob": -0.16908840032724234, "compression_ratio": 1.5595854922279793, "no_speech_prob": 0.00012544130731839687}, {"id": 388, "seek": 158204, "start": 1602.68, "end": 1608.12, "text": " are on the slides or come talk to me after the talk.", "tokens": [366, 322, 264, 9788, 420, 808, 751, 281, 385, 934, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.16908840032724234, "compression_ratio": 1.5595854922279793, "no_speech_prob": 0.00012544130731839687}, {"id": 389, "seek": 160812, "start": 1608.12, "end": 1618.12, "text": " I'm not interested in cryptocurrency, Web3 or similar endeavors.", "tokens": [286, 478, 406, 3102, 294, 28809, 11, 9573, 18, 420, 2531, 49608, 13], "temperature": 0.0, "avg_logprob": -0.27638287698068925, "compression_ratio": 1.382716049382716, "no_speech_prob": 0.0001469344279030338}, {"id": 390, "seek": 160812, "start": 1618.12, "end": 1630.84, "text": " I love cryptography, but I don't know, some of this stuff gets rather sketchy, no offense.", "tokens": [286, 959, 9844, 5820, 11, 457, 286, 500, 380, 458, 11, 512, 295, 341, 1507, 2170, 2831, 12325, 88, 11, 572, 17834, 13], "temperature": 0.0, "avg_logprob": -0.27638287698068925, "compression_ratio": 1.382716049382716, "no_speech_prob": 0.0001469344279030338}, {"id": 391, "seek": 160812, "start": 1630.84, "end": 1632.0, "text": " That was essentially my talk.", "tokens": [663, 390, 4476, 452, 751, 13], "temperature": 0.0, "avg_logprob": -0.27638287698068925, "compression_ratio": 1.382716049382716, "no_speech_prob": 0.0001469344279030338}, {"id": 392, "seek": 160812, "start": 1632.0, "end": 1633.8799999999999, "text": " I'm going to leave this on this slide.", "tokens": [286, 478, 516, 281, 1856, 341, 322, 341, 4137, 13], "temperature": 0.0, "avg_logprob": -0.27638287698068925, "compression_ratio": 1.382716049382716, "no_speech_prob": 0.0001469344279030338}, {"id": 393, "seek": 163388, "start": 1633.88, "end": 1650.3200000000002, "text": " Are there any questions?", "tokens": [2014, 456, 604, 1651, 30], "temperature": 0.0, "avg_logprob": -0.257958905450229, "compression_ratio": 1.2846715328467153, "no_speech_prob": 0.0007082407246343791}, {"id": 394, "seek": 163388, "start": 1650.3200000000002, "end": 1651.3200000000002, "text": " I have a question.", "tokens": [286, 362, 257, 1168, 13], "temperature": 0.0, "avg_logprob": -0.257958905450229, "compression_ratio": 1.2846715328467153, "no_speech_prob": 0.0007082407246343791}, {"id": 395, "seek": 163388, "start": 1651.3200000000002, "end": 1658.0400000000002, "text": " Did you test Glidesort on, let's say, less modern CPUs, like embedded CPUs that don't", "tokens": [2589, 291, 1500, 5209, 1875, 477, 322, 11, 718, 311, 584, 11, 1570, 4363, 13199, 82, 11, 411, 16741, 13199, 82, 300, 500, 380], "temperature": 0.0, "avg_logprob": -0.257958905450229, "compression_ratio": 1.2846715328467153, "no_speech_prob": 0.0007082407246343791}, {"id": 396, "seek": 163388, "start": 1658.0400000000002, "end": 1660.7600000000002, "text": " have auto-fordering execution, et cetera?", "tokens": [362, 8399, 12, 7404, 1794, 15058, 11, 1030, 11458, 30], "temperature": 0.0, "avg_logprob": -0.257958905450229, "compression_ratio": 1.2846715328467153, "no_speech_prob": 0.0007082407246343791}, {"id": 397, "seek": 163388, "start": 1660.7600000000002, "end": 1661.7600000000002, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.257958905450229, "compression_ratio": 1.2846715328467153, "no_speech_prob": 0.0007082407246343791}, {"id": 398, "seek": 166176, "start": 1661.76, "end": 1666.8, "text": " Can you repeat the question, please?", "tokens": [1664, 291, 7149, 264, 1168, 11, 1767, 30], "temperature": 0.0, "avg_logprob": -0.17232808859451956, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.0007179867825470865}, {"id": 399, "seek": 166176, "start": 1666.8, "end": 1677.24, "text": " The question was, did you test the algorithm on any older CPUs that might not have as much", "tokens": [440, 1168, 390, 11, 630, 291, 1500, 264, 9284, 322, 604, 4906, 13199, 82, 300, 1062, 406, 362, 382, 709], "temperature": 0.0, "avg_logprob": -0.17232808859451956, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.0007179867825470865}, {"id": 400, "seek": 166176, "start": 1677.24, "end": 1679.24, "text": " instruction-level parallelism and that kind of stuff?", "tokens": [10951, 12, 12418, 8952, 1434, 293, 300, 733, 295, 1507, 30], "temperature": 0.0, "avg_logprob": -0.17232808859451956, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.0007179867825470865}, {"id": 401, "seek": 166176, "start": 1679.24, "end": 1684.28, "text": " The answer is yes, and yes, it is slower than other state-of-the-art that don't do these", "tokens": [440, 1867, 307, 2086, 11, 293, 2086, 11, 309, 307, 14009, 813, 661, 1785, 12, 2670, 12, 3322, 12, 446, 300, 500, 380, 360, 613], "temperature": 0.0, "avg_logprob": -0.17232808859451956, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.0007179867825470865}, {"id": 402, "seek": 166176, "start": 1684.28, "end": 1686.28, "text": " tricks.", "tokens": [11733, 13], "temperature": 0.0, "avg_logprob": -0.17232808859451956, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.0007179867825470865}, {"id": 403, "seek": 166176, "start": 1686.28, "end": 1690.4, "text": " This is really aimed towards essentially the future of modern processors.", "tokens": [639, 307, 534, 20540, 3030, 4476, 264, 2027, 295, 4363, 27751, 13], "temperature": 0.0, "avg_logprob": -0.17232808859451956, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.0007179867825470865}, {"id": 404, "seek": 169040, "start": 1690.4, "end": 1695.96, "text": " From older CPUs, it is slower than, for example, flux sort, which doesn't do this aggressive", "tokens": [3358, 4906, 13199, 82, 11, 309, 307, 14009, 813, 11, 337, 1365, 11, 19298, 1333, 11, 597, 1177, 380, 360, 341, 10762], "temperature": 0.0, "avg_logprob": -0.23891666700255196, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0009287637076340616}, {"id": 405, "seek": 169040, "start": 1695.96, "end": 1699.0800000000002, "text": " interleaving.", "tokens": [728, 306, 6152, 13], "temperature": 0.0, "avg_logprob": -0.23891666700255196, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0009287637076340616}, {"id": 406, "seek": 169040, "start": 1699.0800000000002, "end": 1702.3600000000001, "text": " But if you compare it to the current Rust stable sort that's currently in the standard", "tokens": [583, 498, 291, 6794, 309, 281, 264, 2190, 34952, 8351, 1333, 300, 311, 4362, 294, 264, 3832], "temperature": 0.0, "avg_logprob": -0.23891666700255196, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0009287637076340616}, {"id": 407, "seek": 169040, "start": 1702.3600000000001, "end": 1709.24, "text": " library, it's still completely dumps us all over that.", "tokens": [6405, 11, 309, 311, 920, 2584, 11430, 82, 505, 439, 670, 300, 13], "temperature": 0.0, "avg_logprob": -0.23891666700255196, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0009287637076340616}, {"id": 408, "seek": 169040, "start": 1709.24, "end": 1711.24, "text": " Can you hear me?", "tokens": [1664, 291, 1568, 385, 30], "temperature": 0.0, "avg_logprob": -0.23891666700255196, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0009287637076340616}, {"id": 409, "seek": 169040, "start": 1711.24, "end": 1712.24, "text": " Barely.", "tokens": [43957, 356, 13], "temperature": 0.0, "avg_logprob": -0.23891666700255196, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0009287637076340616}, {"id": 410, "seek": 169040, "start": 1712.24, "end": 1714.0400000000002, "text": " Can you speak loudly?", "tokens": [1664, 291, 1710, 22958, 30], "temperature": 0.0, "avg_logprob": -0.23891666700255196, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0009287637076340616}, {"id": 411, "seek": 169040, "start": 1714.0400000000002, "end": 1719.0, "text": " When you take two sort of sequences and you take the bottom half of one and the top half", "tokens": [1133, 291, 747, 732, 1333, 295, 22978, 293, 291, 747, 264, 2767, 1922, 295, 472, 293, 264, 1192, 1922], "temperature": 0.0, "avg_logprob": -0.23891666700255196, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0009287637076340616}, {"id": 412, "seek": 171900, "start": 1719.0, "end": 1725.4, "text": " of another and create a third sorted sequence out of that, I thought that was an interesting", "tokens": [295, 1071, 293, 1884, 257, 2636, 25462, 8310, 484, 295, 300, 11, 286, 1194, 300, 390, 364, 1880], "temperature": 0.0, "avg_logprob": -0.15860177702822928, "compression_ratio": 1.732, "no_speech_prob": 0.0008283755742013454}, {"id": 413, "seek": 171900, "start": 1725.4, "end": 1730.08, "text": " observation, but what do you use it for?", "tokens": [14816, 11, 457, 437, 360, 291, 764, 309, 337, 30], "temperature": 0.0, "avg_logprob": -0.15860177702822928, "compression_ratio": 1.732, "no_speech_prob": 0.0008283755742013454}, {"id": 414, "seek": 171900, "start": 1730.08, "end": 1732.08, "text": " So it's not the top half and the bottom half.", "tokens": [407, 309, 311, 406, 264, 1192, 1922, 293, 264, 2767, 1922, 13], "temperature": 0.0, "avg_logprob": -0.15860177702822928, "compression_ratio": 1.732, "no_speech_prob": 0.0008283755742013454}, {"id": 415, "seek": 171900, "start": 1732.08, "end": 1733.08, "text": " That's just the simplification.", "tokens": [663, 311, 445, 264, 6883, 3774, 13], "temperature": 0.0, "avg_logprob": -0.15860177702822928, "compression_ratio": 1.732, "no_speech_prob": 0.0008283755742013454}, {"id": 416, "seek": 171900, "start": 1733.08, "end": 1737.84, "text": " You're talking about the splitting up merges into smaller merges, right?", "tokens": [509, 434, 1417, 466, 264, 30348, 493, 3551, 2880, 666, 4356, 3551, 2880, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.15860177702822928, "compression_ratio": 1.732, "no_speech_prob": 0.0008283755742013454}, {"id": 417, "seek": 171900, "start": 1737.84, "end": 1738.84, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.15860177702822928, "compression_ratio": 1.732, "no_speech_prob": 0.0008283755742013454}, {"id": 418, "seek": 171900, "start": 1738.84, "end": 1739.84, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.15860177702822928, "compression_ratio": 1.732, "no_speech_prob": 0.0008283755742013454}, {"id": 419, "seek": 171900, "start": 1739.84, "end": 1740.84, "text": " So it is not the top half and the bottom half.", "tokens": [407, 309, 307, 406, 264, 1192, 1922, 293, 264, 2767, 1922, 13], "temperature": 0.0, "avg_logprob": -0.15860177702822928, "compression_ratio": 1.732, "no_speech_prob": 0.0008283755742013454}, {"id": 420, "seek": 171900, "start": 1740.84, "end": 1747.24, "text": " It involves a binary search to find the unique split point that allows you to do this swap.", "tokens": [467, 11626, 257, 17434, 3164, 281, 915, 264, 3845, 7472, 935, 300, 4045, 291, 281, 360, 341, 18135, 13], "temperature": 0.0, "avg_logprob": -0.15860177702822928, "compression_ratio": 1.732, "no_speech_prob": 0.0008283755742013454}, {"id": 421, "seek": 174724, "start": 1747.24, "end": 1750.84, "text": " It could be bottom half, top half, but that's not necessarily the case.", "tokens": [467, 727, 312, 2767, 1922, 11, 1192, 1922, 11, 457, 300, 311, 406, 4725, 264, 1389, 13], "temperature": 0.0, "avg_logprob": -0.11315719059535435, "compression_ratio": 2.1444866920152093, "no_speech_prob": 0.00040906580397859216}, {"id": 422, "seek": 174724, "start": 1750.84, "end": 1751.96, "text": " What do I use this for?", "tokens": [708, 360, 286, 764, 341, 337, 30], "temperature": 0.0, "avg_logprob": -0.11315719059535435, "compression_ratio": 2.1444866920152093, "no_speech_prob": 0.00040906580397859216}, {"id": 423, "seek": 174724, "start": 1751.96, "end": 1756.0, "text": " It creates two independent merges.", "tokens": [467, 7829, 732, 6695, 3551, 2880, 13], "temperature": 0.0, "avg_logprob": -0.11315719059535435, "compression_ratio": 2.1444866920152093, "no_speech_prob": 0.00040906580397859216}, {"id": 424, "seek": 174724, "start": 1756.0, "end": 1759.4, "text": " After doing the swap, this merge no longer depends on this merge at all.", "tokens": [2381, 884, 264, 18135, 11, 341, 22183, 572, 2854, 5946, 322, 341, 22183, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.11315719059535435, "compression_ratio": 2.1444866920152093, "no_speech_prob": 0.00040906580397859216}, {"id": 425, "seek": 174724, "start": 1759.4, "end": 1765.0, "text": " And by doing that, I can have two independent loops that merge these and then interleave", "tokens": [400, 538, 884, 300, 11, 286, 393, 362, 732, 6695, 16121, 300, 22183, 613, 293, 550, 728, 306, 946], "temperature": 0.0, "avg_logprob": -0.11315719059535435, "compression_ratio": 2.1444866920152093, "no_speech_prob": 0.00040906580397859216}, {"id": 426, "seek": 174724, "start": 1765.0, "end": 1766.0, "text": " the bodies of these loops.", "tokens": [264, 7510, 295, 613, 16121, 13], "temperature": 0.0, "avg_logprob": -0.11315719059535435, "compression_ratio": 2.1444866920152093, "no_speech_prob": 0.00040906580397859216}, {"id": 427, "seek": 174724, "start": 1766.0, "end": 1769.76, "text": " So it executes one instruction from this merge, one instruction from this merge, one instruction", "tokens": [407, 309, 4454, 1819, 472, 10951, 490, 341, 22183, 11, 472, 10951, 490, 341, 22183, 11, 472, 10951], "temperature": 0.0, "avg_logprob": -0.11315719059535435, "compression_ratio": 2.1444866920152093, "no_speech_prob": 0.00040906580397859216}, {"id": 428, "seek": 174724, "start": 1769.76, "end": 1772.92, "text": " from this merge, one instruction from this merge, et cetera.", "tokens": [490, 341, 22183, 11, 472, 10951, 490, 341, 22183, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.11315719059535435, "compression_ratio": 2.1444866920152093, "no_speech_prob": 0.00040906580397859216}, {"id": 429, "seek": 174724, "start": 1772.92, "end": 1777.06, "text": " And that way these instructions don't depend on each other and you can hide these data", "tokens": [400, 300, 636, 613, 9415, 500, 380, 5672, 322, 1184, 661, 293, 291, 393, 6479, 613, 1412], "temperature": 0.0, "avg_logprob": -0.11315719059535435, "compression_ratio": 2.1444866920152093, "no_speech_prob": 0.00040906580397859216}, {"id": 430, "seek": 177706, "start": 1777.06, "end": 1778.44, "text": " dependencies and such.", "tokens": [36606, 293, 1270, 13], "temperature": 0.0, "avg_logprob": -0.30484030874151935, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0036906185559928417}, {"id": 431, "seek": 177706, "start": 1778.44, "end": 1786.12, "text": " On top of that, I use it as a fallback for the low memory case where you don't need,", "tokens": [1282, 1192, 295, 300, 11, 286, 764, 309, 382, 257, 2100, 3207, 337, 264, 2295, 4675, 1389, 689, 291, 500, 380, 643, 11], "temperature": 0.0, "avg_logprob": -0.30484030874151935, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0036906185559928417}, {"id": 432, "seek": 177706, "start": 1786.12, "end": 1788.84, "text": " so GlideSword can use less auxiliary memory.", "tokens": [370, 5209, 482, 50, 7462, 393, 764, 1570, 43741, 4675, 13], "temperature": 0.0, "avg_logprob": -0.30484030874151935, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0036906185559928417}, {"id": 433, "seek": 177706, "start": 1788.84, "end": 1793.12, "text": " We have a last question.", "tokens": [492, 362, 257, 1036, 1168, 13], "temperature": 0.0, "avg_logprob": -0.30484030874151935, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0036906185559928417}, {"id": 434, "seek": 177706, "start": 1793.12, "end": 1795.52, "text": " Thanks for the talk.", "tokens": [2561, 337, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.30484030874151935, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0036906185559928417}, {"id": 435, "seek": 177706, "start": 1795.52, "end": 1799.32, "text": " I would like to know if you have a bench.", "tokens": [286, 576, 411, 281, 458, 498, 291, 362, 257, 10638, 13], "temperature": 0.0, "avg_logprob": -0.30484030874151935, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0036906185559928417}, {"id": 436, "seek": 177706, "start": 1799.32, "end": 1800.3999999999999, "text": " I'm sorry, I cannot hear.", "tokens": [286, 478, 2597, 11, 286, 2644, 1568, 13], "temperature": 0.0, "avg_logprob": -0.30484030874151935, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0036906185559928417}, {"id": 437, "seek": 177706, "start": 1800.3999999999999, "end": 1803.8, "text": " Can you speak a bit louder, please?", "tokens": [1664, 291, 1710, 257, 857, 22717, 11, 1767, 30], "temperature": 0.0, "avg_logprob": -0.30484030874151935, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0036906185559928417}, {"id": 438, "seek": 180380, "start": 1803.8, "end": 1809.76, "text": " Did you bench when the array is already sorted?", "tokens": [2589, 291, 10638, 562, 264, 10225, 307, 1217, 25462, 30], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 439, "seek": 180380, "start": 1809.76, "end": 1812.48, "text": " Did I bench when the array is already sorted?", "tokens": [2589, 286, 10638, 562, 264, 10225, 307, 1217, 25462, 30], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 440, "seek": 180380, "start": 1812.48, "end": 1813.48, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 441, "seek": 180380, "start": 1813.48, "end": 1817.12, "text": " Yes, it's on the slides.", "tokens": [1079, 11, 309, 311, 322, 264, 9788, 13], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 442, "seek": 180380, "start": 1817.12, "end": 1818.12, "text": " Is it on the slides?", "tokens": [1119, 309, 322, 264, 9788, 30], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 443, "seek": 180380, "start": 1818.12, "end": 1823.24, "text": " Yes, it's the ascending column on the slides and on this slide as well.", "tokens": [1079, 11, 309, 311, 264, 15526, 2029, 7738, 322, 264, 9788, 293, 322, 341, 4137, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 444, "seek": 180380, "start": 1823.24, "end": 1825.28, "text": " It's the one person.", "tokens": [467, 311, 264, 472, 954, 13], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 445, "seek": 180380, "start": 1825.28, "end": 1826.28, "text": " Sorry?", "tokens": [4919, 30], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 446, "seek": 180380, "start": 1826.28, "end": 1828.28, "text": " It's the one person column.", "tokens": [467, 311, 264, 472, 954, 7738, 13], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 447, "seek": 180380, "start": 1828.28, "end": 1829.28, "text": " No, ascending.", "tokens": [883, 11, 15526, 2029, 13], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 448, "seek": 180380, "start": 1829.28, "end": 1830.28, "text": " Ascent.", "tokens": [1018, 2207, 13], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 449, "seek": 180380, "start": 1830.28, "end": 1831.28, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.32282569521949406, "compression_ratio": 1.9050632911392404, "no_speech_prob": 0.005328639410436153}, {"id": 450, "seek": 183128, "start": 1831.28, "end": 1835.48, "text": " Okay, that means sorted in this case and descending means reverse of sorted.", "tokens": [1033, 11, 300, 1355, 25462, 294, 341, 1389, 293, 40182, 1355, 9943, 295, 25462, 13], "temperature": 0.0, "avg_logprob": -0.3509737573018888, "compression_ratio": 1.2549019607843137, "no_speech_prob": 0.0013748591300100088}, {"id": 451, "seek": 183128, "start": 1835.48, "end": 1836.48, "text": " Okay, okay.", "tokens": [1033, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.3509737573018888, "compression_ratio": 1.2549019607843137, "no_speech_prob": 0.0013748591300100088}, {"id": 452, "seek": 183128, "start": 1836.48, "end": 1837.48, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.3509737573018888, "compression_ratio": 1.2549019607843137, "no_speech_prob": 0.0013748591300100088}, {"id": 453, "seek": 183128, "start": 1837.48, "end": 1838.48, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.3509737573018888, "compression_ratio": 1.2549019607843137, "no_speech_prob": 0.0013748591300100088}, {"id": 454, "seek": 183128, "start": 1838.48, "end": 1839.48, "text": " Thanks very much.", "tokens": [2561, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.3509737573018888, "compression_ratio": 1.2549019607843137, "no_speech_prob": 0.0013748591300100088}, {"id": 455, "seek": 183948, "start": 1839.48, "end": 1865.48, "text": " Thank you very much.", "tokens": [1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.8808178901672363, "compression_ratio": 0.7142857142857143, "no_speech_prob": 0.0008963453583419323}], "language": "en"}