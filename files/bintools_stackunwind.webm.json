{"text": " Welcome everyone, today we are going to talk about walking native stacks in BPF without frame pointers. So my name is Roy Shally, I work at Polar Signals as a software engineer, I mostly work on profilers and eBPF related stuff and before that I have worked in different kernel subsystems as part of my job. My name is Javier and I have been working at Polar Signals for a year, mostly working on native stack and winding, so the work that we are going to introduce today and before that I was working on web reliability, tooling for developers and performance at Facebook. Yeah, so before we dive into the topic, I wanted to go through the agenda. So first we actually want to talk about why there is a need for a dwarf based stack walker in eBPF because that is like the most asked question, then we will go into the design of our stack walker and then we will talk about how we went from the prototype to making it production ready and then a bunch of learnings so far on some future plans. So as we said, we work on the production profilers which means that generally sampling profilers collect the stack traces at particular intervals and attaches values to it. Note that the profilers generally need like the user and application level stacks as well as kernel stacks and it sort of involves iterating over all the stack frames and then collecting the written addresses. Historically, there have been a dedicated register for that called frame pointer in both x86 and 64, but in recent times because of some of the compiler optimizations, it has been mostly disabled in most of the runtimes as well as in distros. Also it becomes really hard when you don't have frame pointers and instead of involving a couple of memory accesses per frame which is like quite fast, we will need to really do more work in the stack walkers. Note that the stack walking is like also a common practice in the debuggers as you all know. So what's like the current state of the world? Well, it's not a problem for the hyperscalers because hyperscalers actually have all the applications which are already enabling frame pointers in production and this is important because when the things break and you want to really go through the inspection, it's really helpful to have all the stack when it's needed. There's also a recent discussion in the Fedora mailing list, so just feel free to go through it. TLDR of that discussion is that it's being, so FPs are going to be enabled. Since I think Fedora 38, so that's about to be released in late April, Mac or software always have binaries which has frame pointers enabled. There's also an amazing work going on by Oracle engineers to have a simple format instead of Dwarf and we hope that that work also goes through and helps the ecosystem. So that's like sort of the current status, but what we want is we want that right now and we want the support for all the distros as well as all the runtimes which is like scattered here and there, for example, only go runtime, enables FPs like since go 1.7 and in x86 and since 1.12 and 64. So now some of you might be wondering if not frame pointers, what do we have? For example, say in Rust where it has been disabled by its own, by default, but even, but when you have the panic, you still get the all mattress, so how is it happening? So well, compilers always have this information and we generally need to know the value of the stack pointer in the previous frame and it can be like from any offset if there is no frame pointer. So that way we can always like find the value of the return addresses and continue unwinding the stack. This information is generally encoded as part of.ehframe section or.debugframe section in the Dwarf and there is also another way which is like unwine tables can be also synthesized from the object file which is something being done by orc format that has been used in kernel for a while now. We will talk in detail about.ehframe in a minute, but first of all, let's see if anybody else is using.ehframe already, of course. So the profiler we have developed is not the first thing who is going to use.ehframe. Perf, the popular profiler from Linux kernel, added the Dwarf support in since like when the perf event opens, this call was added which was like in 3.4 and it can collect the registers for the profile processors as well as the copy of the stack for every sample. While this approach has been proven to work, there are a bunch of drawbacks to it. For example, one of the things which perf does is it actually collects all the stacks and copies it into the user space. The second thing is that the implications of one process having another processes data in the user space can be quite complicated and also be it's like a lot of data especially for the CPU intensive applications. So why BPF? Stack walking in BPF for our profilers actually makes a lot of sense to us because in that case we don't really have to copy the whole stack. The information, a lot of it still stays in the kernel which provides like higher safety guarantees especially in the case of like stack walking mechanism. Once it's been implemented, we can like sort of leverage the perf subsystem to get the sample CPU cycles and then instructions, altricache misses, etc. And it can then also help us to develop other tools like allocation tracers, runtime specific profilers for example for JVM or Ruby, etc. So some of you who are probably also familiar with BPF may know that there is already BPF get stack ID so why there is a need for implementing something different. Well, as it turns out, the problem with that helper is that it also requires frame pointers. So it also uses frame pointers to walk through the stacks. And for the historical reasons, fully featured DWARF unwinder is like unlikely to be part of the Linux kernel. So before we dive into how we are using EH frame with BPF, let's look at what EH frame actually has to offer. So the EH frame section contains one or more call frame informations. The main goal of the call frame information is to provide answers on like how to restore every register for the previous frame at any part of our code execution. Directly storing the table, that sort of contain each program counter and all the registered and then locations such as like whether they have been pushed to the stack or not, etc. would generate huge unwind tables. And for that reason, DWARF is actually quite compact and very space efficient in that sense. So the unwind tables encoded in the CFI format are in the form of upcodes and those upcodes needs to be evaluated. So in the case of stack walking, once it has been evaluated, we generate the table that contains for each instruction boundary like how to store the value of the register. There are two main layers to it. One is that it helps with repetitive patterns that compress well and allows for like more compact representation of some data. In some cases, there is like also a specialized opcode that consumes say 1, 2, 4 bytes rather than just 4 bytes at like all time. And the second layer, which we call the second layer is the spatial opcode. That contains like the other set of opcodes, which is like containing the arbitrary expressions. That needs to be evaluated and that's like a lot of work. The main difference between these two is that in the first one, we just need like these two values. But in the second part of it, we will actually need to evaluate like the arbitrary during complete expressions. So for that reason, we would need to have like the full blown VM to be implemented in the BPF itself, which is not quite practical. So those who don't know how like generally the BPF applications flow works. This is how it would look like in a very, yeah, very high level point of view. So like in the user space, you would have like the driver program written in go. Like that's that's our stack and we are using likely BPF go over there. We are doing like creating the maps, attaching the BPF program to a CPU cycle perf event. It reads parses and evaluates the EH frame section of the process and like all the dynamic libraries. And in the BPF program, we have using the PID, we are fetching the table. And then we have like an unwind algorithm, which processes that work information. We will go in depth for each component, but let's see how the algorithm looks like. So basically for this one, it's like a really simple one. But basically we just read like three important register. First one is instruction pointer, RIP. Next one is the stack pointer. And the third one is, of course, like frame pointer, RBP. And then when the frame count is less or equal to the maximum stack depth we have defined, we find the unwind table for the program counter. We are the instruction pointer to the stack, calculate the previous frame, frame stack pointer, then update the registers with the calculated values for the previous frame and then continue with the next frame. So there's like just a nutshell that's what the algorithm is in the BPF. But now the important part is how we store that unwind information and what we have done to make it scalable. So now Javier will talk about that. Cool. So now we have some unwind information that we're going to describe the format later, but we need to put it somewhere, right? So one possibility would be to store this unwind info in the memory space of the applications that we are trying to profile. And we could do this, for example, using a combination of ptrace, mmap, and mlock. And we could use ptrace to hijack the process execution and allocate a new memory segment. And then we will have to lock it because in BPF we need to make sure that the pages that we are accessing are never going to be swapped out. But this has a big problem, that is, that will be altering the execution flow of the program. And it's something that we never want to do. One of the reasons for this is because, first, this memory will live in the process, which means that accounting for it will be odd and developers will find a new memory segment there that appeared out of the blue. So in their metrics, there will be something that changes behind their backs, which is not great. But also because the lifecycle of managing this memory chunk is very complicated. For example, what do you do if our application, if our profiler dies before the processes that we are introspecting? How do we clean this up? It involves a lot of, that's a lot of problems and adding solutions to these problems will require like crazy engineering, which we were not planning to tackle because it will over complicated project a lot. The other problem is that sharing memories way harder and accounting for our overhead is also very hard. If you think about it, for example, Libc is probably linked in most of the applications in your machine. So why having the same information like for every single process, right? So how do we actually store this information? We use BPF maps, which are data structures that, as Shali said, they can be written and read both from kernel and user space. We use in particular hash maps, which in the case of BPF, they are basically a mapping of bytes to bytes where you can put arbitrary information. So this is always locked in memory. BPF allows you with this flag not to lock memory, but in the type of BPF program we use, it is mandatory to lock it. Otherwise, as we said before, these pages could be swapped out and from the type of BPF programs that we have, page faults are forbidden. And yeah, in the end, we could reuse these mappings because they are in this kind of global BPF map that we have control over. So we can store, for example, Libc in one particular area, and then we'll have to add metadata for where it is for every single process that has this mapping. So yeah, this is a logical representation of our information for different executable segments. So imagine this is Libc, MySQL, Zlib, SystemD, and then some tank that isn't used. So this assumes that we have this logical view has a chunk of memory that is contiguous. But in reality, we cannot allocate any arbitrary chunk of memory in BPF. We cannot say we want 200 megabytes and it needs to be contiguous. We cannot do an malloc, right? So we've been doing some experiments and in the systems that we have tested and the kernels that we want to support, we can add up to 250,000 wine entries to each value of a BPF map. So because we want to be able to fit larger wine tables, we basically use the same solution that you would use in any other data intensive application, which is partitioning or sharding. So we are splitting the wine table into different shards and depending on the memory that your machine has, we'll allocate more or less shards ahead of time. That will result in a CPU to memory trade-off because when they get full, we'll regenerate them. But we'll talk about this later. So for example, let's see SystemD some wine table and let's suppose that it's a bit bigger than 250,000 elements so it doesn't fit in a single shard. So because it doesn't, we have to chunk it up. So we store the first chunk in the first shard and then there's a little bit that it's stored in the second shard. So we have added all these layers of indirection. We need some bookkeeping to do and this metadata is also stored in BPF maps. So we have a process that can have many mappings. Each mapping can have one or more chunks and then each chunk maps to a particular shard because you might have one and wine entry or up to 250,000 in a shard. We have some other metadata to exactly tell you where that information leaves. So yeah, thanks to this way of organizing data, we're able to, as we said before, share these executable mappings and thanks to that, we skip table generation for most of the executables in your box. And thanks to this, we only use 0.9% of the CPU cycles doing the process that Vashali was talking about before, which is not the most complex process in the universe, but it consumes some CPU cycles because we need to read some information from your L file, find the section, then we need to read the section and we need to parse it and interpret the dwarf information. So now we need to do way fewer times. So in your machine, we're only going to do it once per unique executable section. So what happens if we run out of space? So basically what we have implemented is basically a bump allocator. We keep on appending information to the shards and logically you can see it as a big chunk of memory. Once it's full, at some point, we'll decide to wipe the whole thing and start again, but we do it in such a way that we give every single process a fair chance of being profiled. So yeah, let's take a look at how are we doing this. So we start with a PID of any process that you find in your machine that at that point happens to be running on CPU, and the first thing we do is to check if it has unwind information. If it does, we need to find the mapping with the current instruction pointer that we have for that frame. Then we need to find the chunk. We can find it doing linear search because we have the information of every single, like minimum and maximum program counter that is covered by that chunk. Once we get the chunk, we can have the shard information, and once we have the shard information, we have the unwind information. But the problem is the unwind information, as we said before, it's basically an array. On this array, we need to find it there, but it can be up to 250,000 items. If you have done anything on BPF, you know that you have to basically build whatever you need yourself, and you don't have, for example, some sort of binary search that is executed on kernel space for you, so you need to implement it yourself, which is not a big deal in general. Implementing binary search is not rocket science, but the problem, most of the times, it's difficult to get all the off by once, but the problem here is that in kernel space, we have a lot of limitations we're going to talk about later, and we're going to talk about how we overcame them, because this produces quite a bit of code that has to be split logically. Not only the data structures are sharded, but the code is sharded, too. So anyways, we binary search this with up to seven iterations, but let's say eight, if you're feeling pessimistic, and then we're going to get the unwind action. So what is the operation we need to do to the current registers to recover the previous registers, and add that frame to the stack trace, and continue with the next frame, as I shall explain before. If the stack is correct, and we have the luxury to know that, because when we have known one information, and RBP is zero, that is specified by the X64 API to be the end of the stack, the bottom of the stack. So if it is correct, we hash the addresses, add the hash to a map, and bump a counter. So it is reasonably cheap, and I will show you some data later on this. And then every couple seconds, I think it's every 10 seconds or so, we collect all this information from user space, and we generate the actual profiles that we send to some server. As I said before, BPF has some interesting challenges for us. I think it's the closest that I've been to coding in the 90s or 80s, because we have very little stack space. We have 512 bytes, if I am not mistaken. So in order to overcome that, we used BPF maps as some sort of heap. Then there's a problem that I mentioned before about memory locking. That memory can never be swapped out, and it is in kernel space. So we want to make sure that we allocate the minimal space you need, and we need to do it properly, because each single environment has a different C-group configuration, and as some talks explained yesterday, it's quite tricky to know the actual memory that your machine has available. For the program size, there is two main issues. One of them is that there's a limitation on the number of instructions that you can store in the kernel, but also the BPF verifier, which is this machinery that makes sure that your program is safe, and for example, your program is going to finish, you're not the reference in any null pointers, and that in general, you're not going to crash the kernel, has a limit on the amount of iterations that it does internally. This is a problem for us, because doing a full binary search already fills these limits. So we need to use some techniques like this thing called BPF tail calls that is similar to Lisp tail calls, and if you're lucky, we are not. You can use, well, we use bounded loops, but we're going to use this new helper called BPF loop that basically it's a function that you can call multiple times creating some sort of loop in BPF, but we cannot use that because we want to support older kernels. That's a pretty new feature. So let's switch to something else. We have written our application in user space in Go, and we are a profiler, so we want to make sure that the overhead we have on your machine is as little as possible. But unfortunately, many of the Go APIs aren't designed with performance in mind. I am new to Go. I didn't know this was like this, and every single time I profiled our profiler, and I found these things, I was like, how is this possible? But it has the dwarf and elf parsing library in the standard library, which is great, but they are not designed for performance sensitive environments, let's say. And also, there's two functions that are binary read and binary writes that we use all the time because we need to deal with bytes back and forth that allocate in the fast path. But anyways, we profile our profiler all the time. We have found lots of opportunities that we keep on fixing, but of course, there's more work to do. And one of the areas where we try to be pretty comprehensive, it's with testing. So we have thorough testing for, well, unit testing for most of the core functions to ensure that we don't regress, but I think that, in my opinion, has helped us the most is snapshot testing. If you're not familiar with this technique, it's very simple. You basically generate some textual representation of your data structures, write them to disk or somewhere in memory, it doesn't matter, and then you generate them again after you make some changes to your code, and then you compare them. So this is how it looks in our case. We have some Git sub repository called test data, and then we have this textual representation of the unwind tables. You don't have to understand it all, but the idea here is that this covers a full function, which program counter starts in the one over there and ends in the one over there. And then we have the information for every single program counter, and then it tells you, for example, what to do here. The first one says CFA type two that I know is for RBP. So you need to get the current RBP at eight, and that will give you the previous frame stack pointer. But anyways, the interesting thing here is that this is very easy to implement, as you can see by our very advanced setup in our make file. We just build our binary. We dump these tables to disk, and then we ask Git to give us the changes. And if there's anything that has changed, we fail. So thanks to this, we have found a lot of bugs, and it has allowed us to iterate with confidence. One of the important things in this project has been de-risking it. It's been quite complex. When I started working at this, I had no idea about dwarf unwinding. I had no idea about unwinding without frame pointers at all. So we had to make sure that all these avenues were properly covered. We had, for example, the dwarf parser properly implemented, that we had all the interactions with BPF cover, and that the BPF unwinder worked well as well. So for this, we always tried to have a plan B at every stage of the project, and we tried to go in depth as well as in breadth. But anyways, I have five minutes left apparently. So we had a lot of automated testing, and one of the things that we did was adding kernel tests, which is super important, especially for BPF programs, because the BPF sub-system changes a lot over time. And there's a lot of features that we want to make sure we don't use, because otherwise it wouldn't work in other kernels. So we have a kernel testing system where basically it runs our application in multiple kernels and reports the state. And one of the things that I want to talk about is that production, as usual, brings a lot of interesting challenges. So by deploying our profiler to production, we found a lot of things that we didn't know about. And we were able to find some of these things thanks to using continuous profiling, our own profiler on our profiler. As you know, different hardware and different configuration are the biggest sources of performance differences as well as incidents in production. So I want to show you two things that we have found recently. One of them is basically we're using almost 30% CPU time opening files in our production environments that never showed up on my NVMe. And the reason is because, turns out, cloud disks are very slow. So we have fixed this. Another very interesting thing that we fixed the other day, it's something that happened when we rolled our profiler to production and then it started crashing. If you are interested, we will upload the slides, so feel free to check the pull request because everything is open source. But basically what happened here was that, for reasons, Go has a signal-based profiler and we have it enabled for even more reasons. And this only was enabled in production. So SIGPROV was interrupting our program execution while we were trying to load the BPF program. The BPF program takes a little while to load because the verifier has to run a bunch of algorithms to start to actually ensure that everything is safe and it was getting interrupted all the time. The BPF, that is the BPF library we used to load the BPF program, was retrying this up to five times until it basically said, I tried, this didn't work, sorry, and obviously we need the BPF program to be loaded to work. So there's many other considerations in this project, like short-lived processes, which we haven't optimized for, but we are still pretty decent ads. If your program runs for one second, we're probably going to catch it, but if this is something that you care about, feel free to message us. It will be something that we optimized. And then, yeah, this is our current format, I probably have one minute left or something like that. So you don't have to understand it all, but the point is we represent every single row with 264-bit words, but since we are making it a bit smaller, and this is basically how our size compares to dwarf. We are bigger because dwarf is optimized for disk while we are optimized for disk space while we are optimized for just raw speeds. So for example, our whole table for one shard pretty much fits in L2 cache. I guess, do I have any more time, or probably not, right? Two minutes, oh, okay, sorry, maybe I sped up too much. So we need to support parsing every single dwarf CFI opcodes, and the reason for this is because otherwise we won't be able to progress, but we cannot unwind from every single program counter, which sucks. But this is not a problem in practice. The reason for this is because the most typical way to recover the previous frame stack pointer is, which is called CFA in dwarf, but doesn't matter, is that you will get given which register you need to apply some offset to, and that will give you the previous frame stack pointer. We support that, but the problem is that it could be any arbitrary register, and right now we only support either RBP or RSP offsets, which happen 99% of the time. So this is something that we're going to work on soon. The other problem, as Vishali said before, is that dwarf has a VM that you need to implement, which has to be Turing-complete, and can implement any expression. It's not Turing-complete. The second level, yeah. The dwarf? No. That's why in the infinity project they had to add this new opcode in the draft hat. Okay. It's not exactly Turing-complete, it's almost there, yeah. Okay, well. But you need to implement a VM that basically has a set of virtual registers. Yeah. But the second, well, we're going to talk about those later, because the first level, yeah, it's the stack machine 100%, but the second level is, I can show you our code, it's messed up. It's messed up. But anyways, but the thing is that we are very lucky here, and you can check more about this in this PR. So there's two dwarf expressions that account for 50% of all the expressions that we have seen in most distributions. They are the expressions used by, well, the dynamic linker needs some, basically, and they are the expressions for procedure linkage tables or PLTs. The other good news, as I said before, is that RBP and RSP offsets rarely occur, and all the other possibilities that I haven't talked about, they almost never occur. Like, we've seen them very, very, very few times. The indexes are useful. Oh, good question. So. We're playing with AR64, because the GCC has 64 backend generates CFA expressions. That's what I was talking about, yeah, yeah, yeah. So but right now we only support X64, but I'm also going to talk about this later, sorry. But anyways. We don't know. Oh. Okay. Done. Okay, well. But we have the minutes buffer for the next one, right? Five minutes. Five minutes. Okay. I have two more slides. Well, anyways, our BPR program, we tried to make it as fast as possible. So this was running on my machine with a bunch of applications that have 90 frames or more. So even the maximum time that it takes is 0.5 milliseconds, which is not terrible on my CPU, which is from late 2017. And this is in a big part because we have optimized everything for memory. So everything's aligned properly. And we try to fit as many things as possible in the CPU cache. What about high level languages? So there's a project that I happen to work on, which is called RB Perf. So this is something that we're going to be adding in the future, basically for dynamic languages. You have the knowledge of the ABI of every interpreter version. And then the Stackwalker is also implemented in BPF. But instead of getting the return addresses, because you have no return addresses there that are meaningful to you, you have to directly extract the function names and other information of the process heap. Our project is called PARCA. So there's a couple of things that we're going to be doing, like mix and why mode, that as far as we know, no one else does this in profiling, in the baggers for sure, but not in profiling, which is the idea of that different sections will be on wants using different techniques. And for example, if you have a JIT that will be used, like Node.js, that has frame pointers. So you will unwind it with frame pointers. But once you reach the actual code from your interpreter, which is compiled and has some white information, we will use Dwarf and white information. RM64 support is coming late this year. And this feature is now disabled by default, but it is stable enough that we're going to be enabling it in a month. And then we're going to add other runtime such as the JVM or Ruby. And then just to say that we are open source, user space on the Apache 2, BPF on the GPL. And yeah, all the links are here. Thanks, yeah, thank you so much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.200000000000001, "text": " Welcome everyone, today we are going to talk about walking native stacks in BPF without", "tokens": [4027, 1518, 11, 965, 321, 366, 516, 281, 751, 466, 4494, 8470, 30792, 294, 40533, 37, 1553], "temperature": 0.0, "avg_logprob": -0.29163714817592074, "compression_ratio": 1.4481132075471699, "no_speech_prob": 0.08926448971033096}, {"id": 1, "seek": 0, "start": 12.200000000000001, "end": 13.72, "text": " frame pointers.", "tokens": [3920, 44548, 13], "temperature": 0.0, "avg_logprob": -0.29163714817592074, "compression_ratio": 1.4481132075471699, "no_speech_prob": 0.08926448971033096}, {"id": 2, "seek": 0, "start": 13.72, "end": 18.96, "text": " So my name is Roy Shally, I work at Polar Signals as a software engineer, I mostly work", "tokens": [407, 452, 1315, 307, 8751, 1160, 379, 11, 286, 589, 412, 3635, 289, 13515, 1124, 382, 257, 4722, 11403, 11, 286, 5240, 589], "temperature": 0.0, "avg_logprob": -0.29163714817592074, "compression_ratio": 1.4481132075471699, "no_speech_prob": 0.08926448971033096}, {"id": 3, "seek": 0, "start": 18.96, "end": 25.36, "text": " on profilers and eBPF related stuff and before that I have worked in different kernel subsystems", "tokens": [322, 1740, 388, 433, 293, 308, 33, 47, 37, 4077, 1507, 293, 949, 300, 286, 362, 2732, 294, 819, 28256, 2090, 9321, 82], "temperature": 0.0, "avg_logprob": -0.29163714817592074, "compression_ratio": 1.4481132075471699, "no_speech_prob": 0.08926448971033096}, {"id": 4, "seek": 0, "start": 25.36, "end": 27.88, "text": " as part of my job.", "tokens": [382, 644, 295, 452, 1691, 13], "temperature": 0.0, "avg_logprob": -0.29163714817592074, "compression_ratio": 1.4481132075471699, "no_speech_prob": 0.08926448971033096}, {"id": 5, "seek": 2788, "start": 27.88, "end": 31.16, "text": " My name is Javier and I have been working at Polar Signals for a year, mostly working", "tokens": [1222, 1315, 307, 508, 25384, 293, 286, 362, 668, 1364, 412, 3635, 289, 13515, 1124, 337, 257, 1064, 11, 5240, 1364], "temperature": 0.0, "avg_logprob": -0.18512782454490662, "compression_ratio": 1.6895424836601307, "no_speech_prob": 6.173904694151133e-05}, {"id": 6, "seek": 2788, "start": 31.16, "end": 35.0, "text": " on native stack and winding, so the work that we are going to introduce today and before", "tokens": [322, 8470, 8630, 293, 29775, 11, 370, 264, 589, 300, 321, 366, 516, 281, 5366, 965, 293, 949], "temperature": 0.0, "avg_logprob": -0.18512782454490662, "compression_ratio": 1.6895424836601307, "no_speech_prob": 6.173904694151133e-05}, {"id": 7, "seek": 2788, "start": 35.0, "end": 41.0, "text": " that I was working on web reliability, tooling for developers and performance at Facebook.", "tokens": [300, 286, 390, 1364, 322, 3670, 24550, 11, 46593, 337, 8849, 293, 3389, 412, 4384, 13], "temperature": 0.0, "avg_logprob": -0.18512782454490662, "compression_ratio": 1.6895424836601307, "no_speech_prob": 6.173904694151133e-05}, {"id": 8, "seek": 2788, "start": 41.0, "end": 47.4, "text": " Yeah, so before we dive into the topic, I wanted to go through the agenda.", "tokens": [865, 11, 370, 949, 321, 9192, 666, 264, 4829, 11, 286, 1415, 281, 352, 807, 264, 9829, 13], "temperature": 0.0, "avg_logprob": -0.18512782454490662, "compression_ratio": 1.6895424836601307, "no_speech_prob": 6.173904694151133e-05}, {"id": 9, "seek": 2788, "start": 47.4, "end": 51.56, "text": " So first we actually want to talk about why there is a need for a dwarf based stack walker", "tokens": [407, 700, 321, 767, 528, 281, 751, 466, 983, 456, 307, 257, 643, 337, 257, 35527, 2361, 8630, 1792, 260], "temperature": 0.0, "avg_logprob": -0.18512782454490662, "compression_ratio": 1.6895424836601307, "no_speech_prob": 6.173904694151133e-05}, {"id": 10, "seek": 2788, "start": 51.56, "end": 56.519999999999996, "text": " in eBPF because that is like the most asked question, then we will go into the design", "tokens": [294, 308, 33, 47, 37, 570, 300, 307, 411, 264, 881, 2351, 1168, 11, 550, 321, 486, 352, 666, 264, 1715], "temperature": 0.0, "avg_logprob": -0.18512782454490662, "compression_ratio": 1.6895424836601307, "no_speech_prob": 6.173904694151133e-05}, {"id": 11, "seek": 5652, "start": 56.52, "end": 61.24, "text": " of our stack walker and then we will talk about how we went from the prototype to making", "tokens": [295, 527, 8630, 1792, 260, 293, 550, 321, 486, 751, 466, 577, 321, 1437, 490, 264, 19475, 281, 1455], "temperature": 0.0, "avg_logprob": -0.13942231072319877, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.9190098100807518e-05}, {"id": 12, "seek": 5652, "start": 61.24, "end": 68.08, "text": " it production ready and then a bunch of learnings so far on some future plans.", "tokens": [309, 4265, 1919, 293, 550, 257, 3840, 295, 2539, 82, 370, 1400, 322, 512, 2027, 5482, 13], "temperature": 0.0, "avg_logprob": -0.13942231072319877, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.9190098100807518e-05}, {"id": 13, "seek": 5652, "start": 68.08, "end": 73.24000000000001, "text": " So as we said, we work on the production profilers which means that generally sampling profilers", "tokens": [407, 382, 321, 848, 11, 321, 589, 322, 264, 4265, 1740, 388, 433, 597, 1355, 300, 5101, 21179, 1740, 388, 433], "temperature": 0.0, "avg_logprob": -0.13942231072319877, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.9190098100807518e-05}, {"id": 14, "seek": 5652, "start": 73.24000000000001, "end": 79.32000000000001, "text": " collect the stack traces at particular intervals and attaches values to it.", "tokens": [2500, 264, 8630, 26076, 412, 1729, 26651, 293, 49404, 4190, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.13942231072319877, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.9190098100807518e-05}, {"id": 15, "seek": 5652, "start": 79.32000000000001, "end": 83.76, "text": " Note that the profilers generally need like the user and application level stacks as well", "tokens": [11633, 300, 264, 1740, 388, 433, 5101, 643, 411, 264, 4195, 293, 3861, 1496, 30792, 382, 731], "temperature": 0.0, "avg_logprob": -0.13942231072319877, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.9190098100807518e-05}, {"id": 16, "seek": 8376, "start": 83.76, "end": 90.68, "text": " as kernel stacks and it sort of involves iterating over all the stack frames and then collecting", "tokens": [382, 28256, 30792, 293, 309, 1333, 295, 11626, 17138, 990, 670, 439, 264, 8630, 12083, 293, 550, 12510], "temperature": 0.0, "avg_logprob": -0.2073028929093305, "compression_ratio": 1.5233160621761659, "no_speech_prob": 3.7587724364129826e-05}, {"id": 17, "seek": 8376, "start": 90.68, "end": 92.52000000000001, "text": " the written addresses.", "tokens": [264, 3720, 16862, 13], "temperature": 0.0, "avg_logprob": -0.2073028929093305, "compression_ratio": 1.5233160621761659, "no_speech_prob": 3.7587724364129826e-05}, {"id": 18, "seek": 8376, "start": 92.52000000000001, "end": 97.96000000000001, "text": " Historically, there have been a dedicated register for that called frame pointer in both", "tokens": [25108, 984, 11, 456, 362, 668, 257, 8374, 7280, 337, 300, 1219, 3920, 23918, 294, 1293], "temperature": 0.0, "avg_logprob": -0.2073028929093305, "compression_ratio": 1.5233160621761659, "no_speech_prob": 3.7587724364129826e-05}, {"id": 19, "seek": 8376, "start": 97.96000000000001, "end": 107.16000000000001, "text": " x86 and 64, but in recent times because of some of the compiler optimizations, it has", "tokens": [2031, 22193, 293, 12145, 11, 457, 294, 5162, 1413, 570, 295, 512, 295, 264, 31958, 5028, 14455, 11, 309, 575], "temperature": 0.0, "avg_logprob": -0.2073028929093305, "compression_ratio": 1.5233160621761659, "no_speech_prob": 3.7587724364129826e-05}, {"id": 20, "seek": 10716, "start": 107.16, "end": 114.52, "text": " been mostly disabled in most of the runtimes as well as in distros.", "tokens": [668, 5240, 15191, 294, 881, 295, 264, 49435, 1532, 382, 731, 382, 294, 1483, 2635, 13], "temperature": 0.0, "avg_logprob": -0.16080007051166736, "compression_ratio": 1.6299559471365639, "no_speech_prob": 3.47554414474871e-05}, {"id": 21, "seek": 10716, "start": 114.52, "end": 121.32, "text": " Also it becomes really hard when you don't have frame pointers and instead of involving", "tokens": [2743, 309, 3643, 534, 1152, 562, 291, 500, 380, 362, 3920, 44548, 293, 2602, 295, 17030], "temperature": 0.0, "avg_logprob": -0.16080007051166736, "compression_ratio": 1.6299559471365639, "no_speech_prob": 3.47554414474871e-05}, {"id": 22, "seek": 10716, "start": 121.32, "end": 127.67999999999999, "text": " a couple of memory accesses per frame which is like quite fast, we will need to really", "tokens": [257, 1916, 295, 4675, 2105, 279, 680, 3920, 597, 307, 411, 1596, 2370, 11, 321, 486, 643, 281, 534], "temperature": 0.0, "avg_logprob": -0.16080007051166736, "compression_ratio": 1.6299559471365639, "no_speech_prob": 3.47554414474871e-05}, {"id": 23, "seek": 10716, "start": 127.67999999999999, "end": 131.16, "text": " do more work in the stack walkers.", "tokens": [360, 544, 589, 294, 264, 8630, 1792, 433, 13], "temperature": 0.0, "avg_logprob": -0.16080007051166736, "compression_ratio": 1.6299559471365639, "no_speech_prob": 3.47554414474871e-05}, {"id": 24, "seek": 10716, "start": 131.16, "end": 134.56, "text": " Note that the stack walking is like also a common practice in the debuggers as you all", "tokens": [11633, 300, 264, 8630, 4494, 307, 411, 611, 257, 2689, 3124, 294, 264, 3001, 3562, 433, 382, 291, 439], "temperature": 0.0, "avg_logprob": -0.16080007051166736, "compression_ratio": 1.6299559471365639, "no_speech_prob": 3.47554414474871e-05}, {"id": 25, "seek": 10716, "start": 134.56, "end": 135.56, "text": " know.", "tokens": [458, 13], "temperature": 0.0, "avg_logprob": -0.16080007051166736, "compression_ratio": 1.6299559471365639, "no_speech_prob": 3.47554414474871e-05}, {"id": 26, "seek": 13556, "start": 135.56, "end": 138.56, "text": " So what's like the current state of the world?", "tokens": [407, 437, 311, 411, 264, 2190, 1785, 295, 264, 1002, 30], "temperature": 0.0, "avg_logprob": -0.1786858788852034, "compression_ratio": 1.6788990825688073, "no_speech_prob": 4.60705159639474e-05}, {"id": 27, "seek": 13556, "start": 138.56, "end": 145.76, "text": " Well, it's not a problem for the hyperscalers because hyperscalers actually have all the", "tokens": [1042, 11, 309, 311, 406, 257, 1154, 337, 264, 7420, 433, 9895, 433, 570, 7420, 433, 9895, 433, 767, 362, 439, 264], "temperature": 0.0, "avg_logprob": -0.1786858788852034, "compression_ratio": 1.6788990825688073, "no_speech_prob": 4.60705159639474e-05}, {"id": 28, "seek": 13556, "start": 145.76, "end": 152.24, "text": " applications which are already enabling frame pointers in production and this is important", "tokens": [5821, 597, 366, 1217, 23148, 3920, 44548, 294, 4265, 293, 341, 307, 1021], "temperature": 0.0, "avg_logprob": -0.1786858788852034, "compression_ratio": 1.6788990825688073, "no_speech_prob": 4.60705159639474e-05}, {"id": 29, "seek": 13556, "start": 152.24, "end": 156.2, "text": " because when the things break and you want to really go through the inspection, it's", "tokens": [570, 562, 264, 721, 1821, 293, 291, 528, 281, 534, 352, 807, 264, 22085, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.1786858788852034, "compression_ratio": 1.6788990825688073, "no_speech_prob": 4.60705159639474e-05}, {"id": 30, "seek": 13556, "start": 156.2, "end": 162.08, "text": " really helpful to have all the stack when it's needed.", "tokens": [534, 4961, 281, 362, 439, 264, 8630, 562, 309, 311, 2978, 13], "temperature": 0.0, "avg_logprob": -0.1786858788852034, "compression_ratio": 1.6788990825688073, "no_speech_prob": 4.60705159639474e-05}, {"id": 31, "seek": 16208, "start": 162.08, "end": 166.68, "text": " There's also a recent discussion in the Fedora mailing list, so just feel free to go through", "tokens": [821, 311, 611, 257, 5162, 5017, 294, 264, 7772, 3252, 41612, 1329, 11, 370, 445, 841, 1737, 281, 352, 807], "temperature": 0.0, "avg_logprob": -0.2372589111328125, "compression_ratio": 1.5023923444976077, "no_speech_prob": 5.4686879593646154e-05}, {"id": 32, "seek": 16208, "start": 166.68, "end": 167.68, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.2372589111328125, "compression_ratio": 1.5023923444976077, "no_speech_prob": 5.4686879593646154e-05}, {"id": 33, "seek": 16208, "start": 167.68, "end": 175.76000000000002, "text": " TLDR of that discussion is that it's being, so FPs are going to be enabled.", "tokens": [40277, 9301, 295, 300, 5017, 307, 300, 309, 311, 885, 11, 370, 479, 23043, 366, 516, 281, 312, 15172, 13], "temperature": 0.0, "avg_logprob": -0.2372589111328125, "compression_ratio": 1.5023923444976077, "no_speech_prob": 5.4686879593646154e-05}, {"id": 34, "seek": 16208, "start": 175.76000000000002, "end": 183.60000000000002, "text": " Since I think Fedora 38, so that's about to be released in late April, Mac or software", "tokens": [4162, 286, 519, 7772, 3252, 12843, 11, 370, 300, 311, 466, 281, 312, 4736, 294, 3469, 6929, 11, 5707, 420, 4722], "temperature": 0.0, "avg_logprob": -0.2372589111328125, "compression_ratio": 1.5023923444976077, "no_speech_prob": 5.4686879593646154e-05}, {"id": 35, "seek": 16208, "start": 183.60000000000002, "end": 188.24, "text": " always have binaries which has frame pointers enabled.", "tokens": [1009, 362, 5171, 4889, 597, 575, 3920, 44548, 15172, 13], "temperature": 0.0, "avg_logprob": -0.2372589111328125, "compression_ratio": 1.5023923444976077, "no_speech_prob": 5.4686879593646154e-05}, {"id": 36, "seek": 18824, "start": 188.24, "end": 194.96, "text": " There's also an amazing work going on by Oracle engineers to have a simple format instead", "tokens": [821, 311, 611, 364, 2243, 589, 516, 322, 538, 25654, 11955, 281, 362, 257, 2199, 7877, 2602], "temperature": 0.0, "avg_logprob": -0.16539506351246552, "compression_ratio": 1.6113744075829384, "no_speech_prob": 3.4244854759890586e-05}, {"id": 37, "seek": 18824, "start": 194.96, "end": 201.84, "text": " of Dwarf and we hope that that work also goes through and helps the ecosystem.", "tokens": [295, 413, 6925, 69, 293, 321, 1454, 300, 300, 589, 611, 1709, 807, 293, 3665, 264, 11311, 13], "temperature": 0.0, "avg_logprob": -0.16539506351246552, "compression_ratio": 1.6113744075829384, "no_speech_prob": 3.4244854759890586e-05}, {"id": 38, "seek": 18824, "start": 201.84, "end": 207.8, "text": " So that's like sort of the current status, but what we want is we want that right now", "tokens": [407, 300, 311, 411, 1333, 295, 264, 2190, 6558, 11, 457, 437, 321, 528, 307, 321, 528, 300, 558, 586], "temperature": 0.0, "avg_logprob": -0.16539506351246552, "compression_ratio": 1.6113744075829384, "no_speech_prob": 3.4244854759890586e-05}, {"id": 39, "seek": 18824, "start": 207.8, "end": 212.96, "text": " and we want the support for all the distros as well as all the runtimes which is like", "tokens": [293, 321, 528, 264, 1406, 337, 439, 264, 1483, 2635, 382, 731, 382, 439, 264, 49435, 1532, 597, 307, 411], "temperature": 0.0, "avg_logprob": -0.16539506351246552, "compression_ratio": 1.6113744075829384, "no_speech_prob": 3.4244854759890586e-05}, {"id": 40, "seek": 21296, "start": 212.96, "end": 221.76000000000002, "text": " scattered here and there, for example, only go runtime, enables FPs like since go 1.7", "tokens": [21986, 510, 293, 456, 11, 337, 1365, 11, 787, 352, 34474, 11, 17077, 479, 23043, 411, 1670, 352, 502, 13, 22], "temperature": 0.0, "avg_logprob": -0.23839308851856297, "compression_ratio": 1.2960526315789473, "no_speech_prob": 8.208828512579203e-05}, {"id": 41, "seek": 21296, "start": 221.76000000000002, "end": 230.16, "text": " and in x86 and since 1.12 and 64.", "tokens": [293, 294, 2031, 22193, 293, 1670, 502, 13, 4762, 293, 12145, 13], "temperature": 0.0, "avg_logprob": -0.23839308851856297, "compression_ratio": 1.2960526315789473, "no_speech_prob": 8.208828512579203e-05}, {"id": 42, "seek": 21296, "start": 230.16, "end": 237.04000000000002, "text": " So now some of you might be wondering if not frame pointers, what do we have?", "tokens": [407, 586, 512, 295, 291, 1062, 312, 6359, 498, 406, 3920, 44548, 11, 437, 360, 321, 362, 30], "temperature": 0.0, "avg_logprob": -0.23839308851856297, "compression_ratio": 1.2960526315789473, "no_speech_prob": 8.208828512579203e-05}, {"id": 43, "seek": 23704, "start": 237.04, "end": 245.51999999999998, "text": " For example, say in Rust where it has been disabled by its own, by default, but even,", "tokens": [1171, 1365, 11, 584, 294, 34952, 689, 309, 575, 668, 15191, 538, 1080, 1065, 11, 538, 7576, 11, 457, 754, 11], "temperature": 0.0, "avg_logprob": -0.18634365974588596, "compression_ratio": 1.5982532751091703, "no_speech_prob": 1.3625926840177272e-05}, {"id": 44, "seek": 23704, "start": 245.51999999999998, "end": 251.12, "text": " but when you have the panic, you still get the all mattress, so how is it happening?", "tokens": [457, 562, 291, 362, 264, 14783, 11, 291, 920, 483, 264, 439, 20625, 11, 370, 577, 307, 309, 2737, 30], "temperature": 0.0, "avg_logprob": -0.18634365974588596, "compression_ratio": 1.5982532751091703, "no_speech_prob": 1.3625926840177272e-05}, {"id": 45, "seek": 23704, "start": 251.12, "end": 256.71999999999997, "text": " So well, compilers always have this information and we generally need to know the value of", "tokens": [407, 731, 11, 715, 388, 433, 1009, 362, 341, 1589, 293, 321, 5101, 643, 281, 458, 264, 2158, 295], "temperature": 0.0, "avg_logprob": -0.18634365974588596, "compression_ratio": 1.5982532751091703, "no_speech_prob": 1.3625926840177272e-05}, {"id": 46, "seek": 23704, "start": 256.71999999999997, "end": 261.2, "text": " the stack pointer in the previous frame and it can be like from any offset if there is", "tokens": [264, 8630, 23918, 294, 264, 3894, 3920, 293, 309, 393, 312, 411, 490, 604, 18687, 498, 456, 307], "temperature": 0.0, "avg_logprob": -0.18634365974588596, "compression_ratio": 1.5982532751091703, "no_speech_prob": 1.3625926840177272e-05}, {"id": 47, "seek": 23704, "start": 261.2, "end": 264.71999999999997, "text": " no frame pointer.", "tokens": [572, 3920, 23918, 13], "temperature": 0.0, "avg_logprob": -0.18634365974588596, "compression_ratio": 1.5982532751091703, "no_speech_prob": 1.3625926840177272e-05}, {"id": 48, "seek": 26472, "start": 264.72, "end": 268.96000000000004, "text": " So that way we can always like find the value of the return addresses and continue unwinding", "tokens": [407, 300, 636, 321, 393, 1009, 411, 915, 264, 2158, 295, 264, 2736, 16862, 293, 2354, 14853, 9245], "temperature": 0.0, "avg_logprob": -0.20482268384707872, "compression_ratio": 1.676991150442478, "no_speech_prob": 1.6955767932813615e-05}, {"id": 49, "seek": 26472, "start": 268.96000000000004, "end": 270.46000000000004, "text": " the stack.", "tokens": [264, 8630, 13], "temperature": 0.0, "avg_logprob": -0.20482268384707872, "compression_ratio": 1.676991150442478, "no_speech_prob": 1.6955767932813615e-05}, {"id": 50, "seek": 26472, "start": 270.46000000000004, "end": 278.72, "text": " This information is generally encoded as part of.ehframe section or.debugframe section", "tokens": [639, 1589, 307, 5101, 2058, 12340, 382, 644, 295, 2411, 13301, 17265, 3541, 420, 2411, 1479, 44455, 17265, 3541], "temperature": 0.0, "avg_logprob": -0.20482268384707872, "compression_ratio": 1.676991150442478, "no_speech_prob": 1.6955767932813615e-05}, {"id": 51, "seek": 26472, "start": 278.72, "end": 287.0, "text": " in the Dwarf and there is also another way which is like unwine tables can be also synthesized", "tokens": [294, 264, 413, 6925, 69, 293, 456, 307, 611, 1071, 636, 597, 307, 411, 14853, 533, 8020, 393, 312, 611, 26617, 1602], "temperature": 0.0, "avg_logprob": -0.20482268384707872, "compression_ratio": 1.676991150442478, "no_speech_prob": 1.6955767932813615e-05}, {"id": 52, "seek": 26472, "start": 287.0, "end": 294.20000000000005, "text": " from the object file which is something being done by orc format that has been used in kernel", "tokens": [490, 264, 2657, 3991, 597, 307, 746, 885, 1096, 538, 420, 66, 7877, 300, 575, 668, 1143, 294, 28256], "temperature": 0.0, "avg_logprob": -0.20482268384707872, "compression_ratio": 1.676991150442478, "no_speech_prob": 1.6955767932813615e-05}, {"id": 53, "seek": 29420, "start": 294.2, "end": 295.59999999999997, "text": " for a while now.", "tokens": [337, 257, 1339, 586, 13], "temperature": 0.0, "avg_logprob": -0.2124375070844378, "compression_ratio": 1.4746835443037976, "no_speech_prob": 6.953085539862514e-05}, {"id": 54, "seek": 29420, "start": 295.59999999999997, "end": 303.52, "text": " We will talk in detail about.ehframe in a minute, but first of all, let's see if anybody", "tokens": [492, 486, 751, 294, 2607, 466, 2411, 13301, 17265, 294, 257, 3456, 11, 457, 700, 295, 439, 11, 718, 311, 536, 498, 4472], "temperature": 0.0, "avg_logprob": -0.2124375070844378, "compression_ratio": 1.4746835443037976, "no_speech_prob": 6.953085539862514e-05}, {"id": 55, "seek": 29420, "start": 303.52, "end": 309.08, "text": " else is using.ehframe already, of course.", "tokens": [1646, 307, 1228, 2411, 13301, 17265, 1217, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.2124375070844378, "compression_ratio": 1.4746835443037976, "no_speech_prob": 6.953085539862514e-05}, {"id": 56, "seek": 29420, "start": 309.08, "end": 314.91999999999996, "text": " So the profiler we have developed is not the first thing who is going to use.ehframe.", "tokens": [407, 264, 1740, 5441, 321, 362, 4743, 307, 406, 264, 700, 551, 567, 307, 516, 281, 764, 2411, 13301, 17265, 13], "temperature": 0.0, "avg_logprob": -0.2124375070844378, "compression_ratio": 1.4746835443037976, "no_speech_prob": 6.953085539862514e-05}, {"id": 57, "seek": 31492, "start": 314.92, "end": 323.92, "text": " Perf, the popular profiler from Linux kernel, added the Dwarf support in since like when", "tokens": [3026, 69, 11, 264, 3743, 1740, 5441, 490, 18734, 28256, 11, 3869, 264, 413, 6925, 69, 1406, 294, 1670, 411, 562], "temperature": 0.0, "avg_logprob": -0.2359700853174383, "compression_ratio": 1.5656108597285068, "no_speech_prob": 7.946520781842992e-05}, {"id": 58, "seek": 31492, "start": 323.92, "end": 330.24, "text": " the perf event opens, this call was added which was like in 3.4 and it can collect the registers", "tokens": [264, 13826, 2280, 9870, 11, 341, 818, 390, 3869, 597, 390, 411, 294, 805, 13, 19, 293, 309, 393, 2500, 264, 38351], "temperature": 0.0, "avg_logprob": -0.2359700853174383, "compression_ratio": 1.5656108597285068, "no_speech_prob": 7.946520781842992e-05}, {"id": 59, "seek": 31492, "start": 330.24, "end": 336.8, "text": " for the profile processors as well as the copy of the stack for every sample.", "tokens": [337, 264, 7964, 27751, 382, 731, 382, 264, 5055, 295, 264, 8630, 337, 633, 6889, 13], "temperature": 0.0, "avg_logprob": -0.2359700853174383, "compression_ratio": 1.5656108597285068, "no_speech_prob": 7.946520781842992e-05}, {"id": 60, "seek": 31492, "start": 336.8, "end": 342.36, "text": " While this approach has been proven to work, there are a bunch of drawbacks to it.", "tokens": [3987, 341, 3109, 575, 668, 12785, 281, 589, 11, 456, 366, 257, 3840, 295, 2642, 17758, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.2359700853174383, "compression_ratio": 1.5656108597285068, "no_speech_prob": 7.946520781842992e-05}, {"id": 61, "seek": 34236, "start": 342.36, "end": 348.08000000000004, "text": " For example, one of the things which perf does is it actually collects all the stacks", "tokens": [1171, 1365, 11, 472, 295, 264, 721, 597, 13826, 775, 307, 309, 767, 39897, 439, 264, 30792], "temperature": 0.0, "avg_logprob": -0.16671456788715563, "compression_ratio": 1.6323529411764706, "no_speech_prob": 9.808750291995239e-06}, {"id": 62, "seek": 34236, "start": 348.08000000000004, "end": 351.0, "text": " and copies it into the user space.", "tokens": [293, 14341, 309, 666, 264, 4195, 1901, 13], "temperature": 0.0, "avg_logprob": -0.16671456788715563, "compression_ratio": 1.6323529411764706, "no_speech_prob": 9.808750291995239e-06}, {"id": 63, "seek": 34236, "start": 351.0, "end": 357.28000000000003, "text": " The second thing is that the implications of one process having another processes data", "tokens": [440, 1150, 551, 307, 300, 264, 16602, 295, 472, 1399, 1419, 1071, 7555, 1412], "temperature": 0.0, "avg_logprob": -0.16671456788715563, "compression_ratio": 1.6323529411764706, "no_speech_prob": 9.808750291995239e-06}, {"id": 64, "seek": 34236, "start": 357.28000000000003, "end": 363.44, "text": " in the user space can be quite complicated and also be it's like a lot of data especially", "tokens": [294, 264, 4195, 1901, 393, 312, 1596, 6179, 293, 611, 312, 309, 311, 411, 257, 688, 295, 1412, 2318], "temperature": 0.0, "avg_logprob": -0.16671456788715563, "compression_ratio": 1.6323529411764706, "no_speech_prob": 9.808750291995239e-06}, {"id": 65, "seek": 34236, "start": 363.44, "end": 369.6, "text": " for the CPU intensive applications.", "tokens": [337, 264, 13199, 18957, 5821, 13], "temperature": 0.0, "avg_logprob": -0.16671456788715563, "compression_ratio": 1.6323529411764706, "no_speech_prob": 9.808750291995239e-06}, {"id": 66, "seek": 36960, "start": 369.6, "end": 376.84000000000003, "text": " So why BPF? Stack walking in BPF for our profilers actually makes a lot of sense to us because", "tokens": [407, 983, 40533, 37, 30, 37649, 4494, 294, 40533, 37, 337, 527, 1740, 388, 433, 767, 1669, 257, 688, 295, 2020, 281, 505, 570], "temperature": 0.0, "avg_logprob": -0.17981159564146063, "compression_ratio": 1.5903614457831325, "no_speech_prob": 2.0769301045220345e-05}, {"id": 67, "seek": 36960, "start": 376.84000000000003, "end": 380.8, "text": " in that case we don't really have to copy the whole stack.", "tokens": [294, 300, 1389, 321, 500, 380, 534, 362, 281, 5055, 264, 1379, 8630, 13], "temperature": 0.0, "avg_logprob": -0.17981159564146063, "compression_ratio": 1.5903614457831325, "no_speech_prob": 2.0769301045220345e-05}, {"id": 68, "seek": 36960, "start": 380.8, "end": 386.88, "text": " The information, a lot of it still stays in the kernel which provides like higher safety", "tokens": [440, 1589, 11, 257, 688, 295, 309, 920, 10834, 294, 264, 28256, 597, 6417, 411, 2946, 4514], "temperature": 0.0, "avg_logprob": -0.17981159564146063, "compression_ratio": 1.5903614457831325, "no_speech_prob": 2.0769301045220345e-05}, {"id": 69, "seek": 36960, "start": 386.88, "end": 391.32000000000005, "text": " guarantees especially in the case of like stack walking mechanism.", "tokens": [32567, 2318, 294, 264, 1389, 295, 411, 8630, 4494, 7513, 13], "temperature": 0.0, "avg_logprob": -0.17981159564146063, "compression_ratio": 1.5903614457831325, "no_speech_prob": 2.0769301045220345e-05}, {"id": 70, "seek": 36960, "start": 391.32000000000005, "end": 397.16, "text": " Once it's been implemented, we can like sort of leverage the perf subsystem to get the", "tokens": [3443, 309, 311, 668, 12270, 11, 321, 393, 411, 1333, 295, 13982, 264, 13826, 2090, 9321, 281, 483, 264], "temperature": 0.0, "avg_logprob": -0.17981159564146063, "compression_ratio": 1.5903614457831325, "no_speech_prob": 2.0769301045220345e-05}, {"id": 71, "seek": 39716, "start": 397.16, "end": 403.84000000000003, "text": " sample CPU cycles and then instructions, altricache misses, etc.", "tokens": [6889, 13199, 17796, 293, 550, 9415, 11, 4955, 1341, 6000, 29394, 11, 5183, 13], "temperature": 0.0, "avg_logprob": -0.21441811400574523, "compression_ratio": 1.4527363184079602, "no_speech_prob": 2.2805526896263473e-05}, {"id": 72, "seek": 39716, "start": 403.84000000000003, "end": 410.0, "text": " And it can then also help us to develop other tools like allocation tracers, runtime specific", "tokens": [400, 309, 393, 550, 611, 854, 505, 281, 1499, 661, 3873, 411, 27599, 504, 326, 433, 11, 34474, 2685], "temperature": 0.0, "avg_logprob": -0.21441811400574523, "compression_ratio": 1.4527363184079602, "no_speech_prob": 2.2805526896263473e-05}, {"id": 73, "seek": 39716, "start": 410.0, "end": 416.96000000000004, "text": " profilers for example for JVM or Ruby, etc.", "tokens": [1740, 388, 433, 337, 1365, 337, 508, 53, 44, 420, 19907, 11, 5183, 13], "temperature": 0.0, "avg_logprob": -0.21441811400574523, "compression_ratio": 1.4527363184079602, "no_speech_prob": 2.2805526896263473e-05}, {"id": 74, "seek": 39716, "start": 416.96000000000004, "end": 422.8, "text": " So some of you who are probably also familiar with BPF may know that there is already BPF", "tokens": [407, 512, 295, 291, 567, 366, 1391, 611, 4963, 365, 40533, 37, 815, 458, 300, 456, 307, 1217, 40533, 37], "temperature": 0.0, "avg_logprob": -0.21441811400574523, "compression_ratio": 1.4527363184079602, "no_speech_prob": 2.2805526896263473e-05}, {"id": 75, "seek": 42280, "start": 422.8, "end": 427.92, "text": " get stack ID so why there is a need for implementing something different.", "tokens": [483, 8630, 7348, 370, 983, 456, 307, 257, 643, 337, 18114, 746, 819, 13], "temperature": 0.0, "avg_logprob": -0.20996735735637387, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.0134302758378908e-05}, {"id": 76, "seek": 42280, "start": 427.92, "end": 434.48, "text": " Well, as it turns out, the problem with that helper is that it also requires frame pointers.", "tokens": [1042, 11, 382, 309, 4523, 484, 11, 264, 1154, 365, 300, 36133, 307, 300, 309, 611, 7029, 3920, 44548, 13], "temperature": 0.0, "avg_logprob": -0.20996735735637387, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.0134302758378908e-05}, {"id": 77, "seek": 42280, "start": 434.48, "end": 437.92, "text": " So it also uses frame pointers to walk through the stacks.", "tokens": [407, 309, 611, 4960, 3920, 44548, 281, 1792, 807, 264, 30792, 13], "temperature": 0.0, "avg_logprob": -0.20996735735637387, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.0134302758378908e-05}, {"id": 78, "seek": 42280, "start": 437.92, "end": 446.0, "text": " And for the historical reasons, fully featured DWARF unwinder is like unlikely to be part", "tokens": [400, 337, 264, 8584, 4112, 11, 4498, 13822, 45318, 1899, 37, 14853, 5669, 307, 411, 17518, 281, 312, 644], "temperature": 0.0, "avg_logprob": -0.20996735735637387, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.0134302758378908e-05}, {"id": 79, "seek": 42280, "start": 446.0, "end": 449.76, "text": " of the Linux kernel.", "tokens": [295, 264, 18734, 28256, 13], "temperature": 0.0, "avg_logprob": -0.20996735735637387, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.0134302758378908e-05}, {"id": 80, "seek": 44976, "start": 449.76, "end": 459.24, "text": " So before we dive into how we are using EH frame with BPF, let's look at what EH frame", "tokens": [407, 949, 321, 9192, 666, 577, 321, 366, 1228, 39416, 3920, 365, 40533, 37, 11, 718, 311, 574, 412, 437, 39416, 3920], "temperature": 0.0, "avg_logprob": -0.11265596702917298, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.2661875593476e-05}, {"id": 81, "seek": 44976, "start": 459.24, "end": 462.08, "text": " actually has to offer.", "tokens": [767, 575, 281, 2626, 13], "temperature": 0.0, "avg_logprob": -0.11265596702917298, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.2661875593476e-05}, {"id": 82, "seek": 44976, "start": 462.08, "end": 469.36, "text": " So the EH frame section contains one or more call frame informations.", "tokens": [407, 264, 39416, 3920, 3541, 8306, 472, 420, 544, 818, 3920, 38855, 13], "temperature": 0.0, "avg_logprob": -0.11265596702917298, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.2661875593476e-05}, {"id": 83, "seek": 44976, "start": 469.36, "end": 476.03999999999996, "text": " The main goal of the call frame information is to provide answers on like how to restore", "tokens": [440, 2135, 3387, 295, 264, 818, 3920, 1589, 307, 281, 2893, 6338, 322, 411, 577, 281, 15227], "temperature": 0.0, "avg_logprob": -0.11265596702917298, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.2661875593476e-05}, {"id": 84, "seek": 47604, "start": 476.04, "end": 481.48, "text": " every register for the previous frame at any part of our code execution.", "tokens": [633, 7280, 337, 264, 3894, 3920, 412, 604, 644, 295, 527, 3089, 15058, 13], "temperature": 0.0, "avg_logprob": -0.18316371789139307, "compression_ratio": 1.5743801652892562, "no_speech_prob": 1.3402663171291351e-05}, {"id": 85, "seek": 47604, "start": 481.48, "end": 487.48, "text": " Directly storing the table, that sort of contain each program counter and all the registered", "tokens": [18308, 356, 26085, 264, 3199, 11, 300, 1333, 295, 5304, 1184, 1461, 5682, 293, 439, 264, 13968], "temperature": 0.0, "avg_logprob": -0.18316371789139307, "compression_ratio": 1.5743801652892562, "no_speech_prob": 1.3402663171291351e-05}, {"id": 86, "seek": 47604, "start": 487.48, "end": 493.64000000000004, "text": " and then locations such as like whether they have been pushed to the stack or not, etc.", "tokens": [293, 550, 9253, 1270, 382, 411, 1968, 436, 362, 668, 9152, 281, 264, 8630, 420, 406, 11, 5183, 13], "temperature": 0.0, "avg_logprob": -0.18316371789139307, "compression_ratio": 1.5743801652892562, "no_speech_prob": 1.3402663171291351e-05}, {"id": 87, "seek": 47604, "start": 493.64000000000004, "end": 497.24, "text": " would generate huge unwind tables.", "tokens": [576, 8460, 2603, 517, 12199, 8020, 13], "temperature": 0.0, "avg_logprob": -0.18316371789139307, "compression_ratio": 1.5743801652892562, "no_speech_prob": 1.3402663171291351e-05}, {"id": 88, "seek": 47604, "start": 497.24, "end": 505.96000000000004, "text": " And for that reason, DWARF is actually quite compact and very space efficient in that sense.", "tokens": [400, 337, 300, 1778, 11, 45318, 1899, 37, 307, 767, 1596, 14679, 293, 588, 1901, 7148, 294, 300, 2020, 13], "temperature": 0.0, "avg_logprob": -0.18316371789139307, "compression_ratio": 1.5743801652892562, "no_speech_prob": 1.3402663171291351e-05}, {"id": 89, "seek": 50596, "start": 505.96, "end": 513.6, "text": " So the unwind tables encoded in the CFI format are in the form of upcodes and those upcodes", "tokens": [407, 264, 517, 12199, 8020, 2058, 12340, 294, 264, 21792, 40, 7877, 366, 294, 264, 1254, 295, 493, 66, 4789, 293, 729, 493, 66, 4789], "temperature": 0.0, "avg_logprob": -0.1504512207180846, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9504488591337577e-05}, {"id": 90, "seek": 50596, "start": 513.6, "end": 515.04, "text": " needs to be evaluated.", "tokens": [2203, 281, 312, 25509, 13], "temperature": 0.0, "avg_logprob": -0.1504512207180846, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9504488591337577e-05}, {"id": 91, "seek": 50596, "start": 515.04, "end": 519.0, "text": " So in the case of stack walking, once it has been evaluated, we generate the table that", "tokens": [407, 294, 264, 1389, 295, 8630, 4494, 11, 1564, 309, 575, 668, 25509, 11, 321, 8460, 264, 3199, 300], "temperature": 0.0, "avg_logprob": -0.1504512207180846, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9504488591337577e-05}, {"id": 92, "seek": 50596, "start": 519.0, "end": 523.4, "text": " contains for each instruction boundary like how to store the value of the register.", "tokens": [8306, 337, 1184, 10951, 12866, 411, 577, 281, 3531, 264, 2158, 295, 264, 7280, 13], "temperature": 0.0, "avg_logprob": -0.1504512207180846, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9504488591337577e-05}, {"id": 93, "seek": 50596, "start": 523.4, "end": 526.4, "text": " There are two main layers to it.", "tokens": [821, 366, 732, 2135, 7914, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.1504512207180846, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9504488591337577e-05}, {"id": 94, "seek": 50596, "start": 526.4, "end": 533.16, "text": " One is that it helps with repetitive patterns that compress well and allows for like more", "tokens": [1485, 307, 300, 309, 3665, 365, 29404, 8294, 300, 14778, 731, 293, 4045, 337, 411, 544], "temperature": 0.0, "avg_logprob": -0.1504512207180846, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9504488591337577e-05}, {"id": 95, "seek": 53316, "start": 533.16, "end": 536.92, "text": " compact representation of some data.", "tokens": [14679, 10290, 295, 512, 1412, 13], "temperature": 0.0, "avg_logprob": -0.16588381021329673, "compression_ratio": 1.7412280701754386, "no_speech_prob": 1.6177697034436278e-05}, {"id": 96, "seek": 53316, "start": 536.92, "end": 544.24, "text": " In some cases, there is like also a specialized opcode that consumes say 1, 2, 4 bytes rather", "tokens": [682, 512, 3331, 11, 456, 307, 411, 611, 257, 19813, 999, 22332, 300, 48823, 584, 502, 11, 568, 11, 1017, 36088, 2831], "temperature": 0.0, "avg_logprob": -0.16588381021329673, "compression_ratio": 1.7412280701754386, "no_speech_prob": 1.6177697034436278e-05}, {"id": 97, "seek": 53316, "start": 544.24, "end": 547.3199999999999, "text": " than just 4 bytes at like all time.", "tokens": [813, 445, 1017, 36088, 412, 411, 439, 565, 13], "temperature": 0.0, "avg_logprob": -0.16588381021329673, "compression_ratio": 1.7412280701754386, "no_speech_prob": 1.6177697034436278e-05}, {"id": 98, "seek": 53316, "start": 547.3199999999999, "end": 553.4, "text": " And the second layer, which we call the second layer is the spatial opcode.", "tokens": [400, 264, 1150, 4583, 11, 597, 321, 818, 264, 1150, 4583, 307, 264, 23598, 999, 22332, 13], "temperature": 0.0, "avg_logprob": -0.16588381021329673, "compression_ratio": 1.7412280701754386, "no_speech_prob": 1.6177697034436278e-05}, {"id": 99, "seek": 53316, "start": 553.4, "end": 559.64, "text": " That contains like the other set of opcodes, which is like containing the arbitrary expressions.", "tokens": [663, 8306, 411, 264, 661, 992, 295, 999, 66, 4789, 11, 597, 307, 411, 19273, 264, 23211, 15277, 13], "temperature": 0.0, "avg_logprob": -0.16588381021329673, "compression_ratio": 1.7412280701754386, "no_speech_prob": 1.6177697034436278e-05}, {"id": 100, "seek": 53316, "start": 559.64, "end": 561.9599999999999, "text": " That needs to be evaluated and that's like a lot of work.", "tokens": [663, 2203, 281, 312, 25509, 293, 300, 311, 411, 257, 688, 295, 589, 13], "temperature": 0.0, "avg_logprob": -0.16588381021329673, "compression_ratio": 1.7412280701754386, "no_speech_prob": 1.6177697034436278e-05}, {"id": 101, "seek": 56196, "start": 561.96, "end": 566.52, "text": " The main difference between these two is that in the first one, we just need like these", "tokens": [440, 2135, 2649, 1296, 613, 732, 307, 300, 294, 264, 700, 472, 11, 321, 445, 643, 411, 613], "temperature": 0.0, "avg_logprob": -0.13094091415405273, "compression_ratio": 1.602803738317757, "no_speech_prob": 1.6955189494183287e-05}, {"id": 102, "seek": 56196, "start": 566.52, "end": 568.6800000000001, "text": " two values.", "tokens": [732, 4190, 13], "temperature": 0.0, "avg_logprob": -0.13094091415405273, "compression_ratio": 1.602803738317757, "no_speech_prob": 1.6955189494183287e-05}, {"id": 103, "seek": 56196, "start": 568.6800000000001, "end": 574.2, "text": " But in the second part of it, we will actually need to evaluate like the arbitrary during", "tokens": [583, 294, 264, 1150, 644, 295, 309, 11, 321, 486, 767, 643, 281, 13059, 411, 264, 23211, 1830], "temperature": 0.0, "avg_logprob": -0.13094091415405273, "compression_ratio": 1.602803738317757, "no_speech_prob": 1.6955189494183287e-05}, {"id": 104, "seek": 56196, "start": 574.2, "end": 576.64, "text": " complete expressions.", "tokens": [3566, 15277, 13], "temperature": 0.0, "avg_logprob": -0.13094091415405273, "compression_ratio": 1.602803738317757, "no_speech_prob": 1.6955189494183287e-05}, {"id": 105, "seek": 56196, "start": 576.64, "end": 582.08, "text": " So for that reason, we would need to have like the full blown VM to be implemented in", "tokens": [407, 337, 300, 1778, 11, 321, 576, 643, 281, 362, 411, 264, 1577, 16479, 18038, 281, 312, 12270, 294], "temperature": 0.0, "avg_logprob": -0.13094091415405273, "compression_ratio": 1.602803738317757, "no_speech_prob": 1.6955189494183287e-05}, {"id": 106, "seek": 56196, "start": 582.08, "end": 588.6, "text": " the BPF itself, which is not quite practical.", "tokens": [264, 40533, 37, 2564, 11, 597, 307, 406, 1596, 8496, 13], "temperature": 0.0, "avg_logprob": -0.13094091415405273, "compression_ratio": 1.602803738317757, "no_speech_prob": 1.6955189494183287e-05}, {"id": 107, "seek": 58860, "start": 588.6, "end": 595.0, "text": " So those who don't know how like generally the BPF applications flow works.", "tokens": [407, 729, 567, 500, 380, 458, 577, 411, 5101, 264, 40533, 37, 5821, 3095, 1985, 13], "temperature": 0.0, "avg_logprob": -0.2091518727744498, "compression_ratio": 1.527363184079602, "no_speech_prob": 1.4504784303426277e-05}, {"id": 108, "seek": 58860, "start": 595.0, "end": 601.2, "text": " This is how it would look like in a very, yeah, very high level point of view.", "tokens": [639, 307, 577, 309, 576, 574, 411, 294, 257, 588, 11, 1338, 11, 588, 1090, 1496, 935, 295, 1910, 13], "temperature": 0.0, "avg_logprob": -0.2091518727744498, "compression_ratio": 1.527363184079602, "no_speech_prob": 1.4504784303426277e-05}, {"id": 109, "seek": 58860, "start": 601.2, "end": 607.2, "text": " So like in the user space, you would have like the driver program written in go.", "tokens": [407, 411, 294, 264, 4195, 1901, 11, 291, 576, 362, 411, 264, 6787, 1461, 3720, 294, 352, 13], "temperature": 0.0, "avg_logprob": -0.2091518727744498, "compression_ratio": 1.527363184079602, "no_speech_prob": 1.4504784303426277e-05}, {"id": 110, "seek": 58860, "start": 607.2, "end": 613.5600000000001, "text": " Like that's that's our stack and we are using likely BPF go over there.", "tokens": [1743, 300, 311, 300, 311, 527, 8630, 293, 321, 366, 1228, 3700, 40533, 37, 352, 670, 456, 13], "temperature": 0.0, "avg_logprob": -0.2091518727744498, "compression_ratio": 1.527363184079602, "no_speech_prob": 1.4504784303426277e-05}, {"id": 111, "seek": 61356, "start": 613.56, "end": 620.2399999999999, "text": " We are doing like creating the maps, attaching the BPF program to a CPU cycle perf event.", "tokens": [492, 366, 884, 411, 4084, 264, 11317, 11, 39074, 264, 40533, 37, 1461, 281, 257, 13199, 6586, 13826, 2280, 13], "temperature": 0.0, "avg_logprob": -0.2737486521402995, "compression_ratio": 1.6367924528301887, "no_speech_prob": 2.5429308152524754e-05}, {"id": 112, "seek": 61356, "start": 620.2399999999999, "end": 625.88, "text": " It reads parses and evaluates the EH frame section of the process and like all the dynamic", "tokens": [467, 15700, 21156, 279, 293, 6133, 1024, 264, 39416, 3920, 3541, 295, 264, 1399, 293, 411, 439, 264, 8546], "temperature": 0.0, "avg_logprob": -0.2737486521402995, "compression_ratio": 1.6367924528301887, "no_speech_prob": 2.5429308152524754e-05}, {"id": 113, "seek": 61356, "start": 625.88, "end": 627.52, "text": " libraries.", "tokens": [15148, 13], "temperature": 0.0, "avg_logprob": -0.2737486521402995, "compression_ratio": 1.6367924528301887, "no_speech_prob": 2.5429308152524754e-05}, {"id": 114, "seek": 61356, "start": 627.52, "end": 634.8399999999999, "text": " And in the BPF program, we have using the PID, we are fetching the table.", "tokens": [400, 294, 264, 40533, 37, 1461, 11, 321, 362, 1228, 264, 430, 2777, 11, 321, 366, 23673, 278, 264, 3199, 13], "temperature": 0.0, "avg_logprob": -0.2737486521402995, "compression_ratio": 1.6367924528301887, "no_speech_prob": 2.5429308152524754e-05}, {"id": 115, "seek": 61356, "start": 634.8399999999999, "end": 640.3599999999999, "text": " And then we have like an unwind algorithm, which processes that work information.", "tokens": [400, 550, 321, 362, 411, 364, 517, 12199, 9284, 11, 597, 7555, 300, 589, 1589, 13], "temperature": 0.0, "avg_logprob": -0.2737486521402995, "compression_ratio": 1.6367924528301887, "no_speech_prob": 2.5429308152524754e-05}, {"id": 116, "seek": 64036, "start": 640.36, "end": 649.48, "text": " We will go in depth for each component, but let's see how the algorithm looks like.", "tokens": [492, 486, 352, 294, 7161, 337, 1184, 6542, 11, 457, 718, 311, 536, 577, 264, 9284, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.15914813052402454, "compression_ratio": 1.5645933014354068, "no_speech_prob": 3.217574339942075e-05}, {"id": 117, "seek": 64036, "start": 649.48, "end": 653.4, "text": " So basically for this one, it's like a really simple one.", "tokens": [407, 1936, 337, 341, 472, 11, 309, 311, 411, 257, 534, 2199, 472, 13], "temperature": 0.0, "avg_logprob": -0.15914813052402454, "compression_ratio": 1.5645933014354068, "no_speech_prob": 3.217574339942075e-05}, {"id": 118, "seek": 64036, "start": 653.4, "end": 657.32, "text": " But basically we just read like three important register.", "tokens": [583, 1936, 321, 445, 1401, 411, 1045, 1021, 7280, 13], "temperature": 0.0, "avg_logprob": -0.15914813052402454, "compression_ratio": 1.5645933014354068, "no_speech_prob": 3.217574339942075e-05}, {"id": 119, "seek": 64036, "start": 657.32, "end": 660.32, "text": " First one is instruction pointer, RIP.", "tokens": [2386, 472, 307, 10951, 23918, 11, 497, 9139, 13], "temperature": 0.0, "avg_logprob": -0.15914813052402454, "compression_ratio": 1.5645933014354068, "no_speech_prob": 3.217574339942075e-05}, {"id": 120, "seek": 64036, "start": 660.32, "end": 662.24, "text": " Next one is the stack pointer.", "tokens": [3087, 472, 307, 264, 8630, 23918, 13], "temperature": 0.0, "avg_logprob": -0.15914813052402454, "compression_ratio": 1.5645933014354068, "no_speech_prob": 3.217574339942075e-05}, {"id": 121, "seek": 64036, "start": 662.24, "end": 668.64, "text": " And the third one is, of course, like frame pointer, RBP.", "tokens": [400, 264, 2636, 472, 307, 11, 295, 1164, 11, 411, 3920, 23918, 11, 40302, 47, 13], "temperature": 0.0, "avg_logprob": -0.15914813052402454, "compression_ratio": 1.5645933014354068, "no_speech_prob": 3.217574339942075e-05}, {"id": 122, "seek": 66864, "start": 668.64, "end": 674.36, "text": " And then when the frame count is less or equal to the maximum stack depth we have defined,", "tokens": [400, 550, 562, 264, 3920, 1207, 307, 1570, 420, 2681, 281, 264, 6674, 8630, 7161, 321, 362, 7642, 11], "temperature": 0.0, "avg_logprob": -0.19831722259521484, "compression_ratio": 1.7666666666666666, "no_speech_prob": 1.5672143490519375e-05}, {"id": 123, "seek": 66864, "start": 674.36, "end": 678.56, "text": " we find the unwind table for the program counter.", "tokens": [321, 915, 264, 517, 12199, 3199, 337, 264, 1461, 5682, 13], "temperature": 0.0, "avg_logprob": -0.19831722259521484, "compression_ratio": 1.7666666666666666, "no_speech_prob": 1.5672143490519375e-05}, {"id": 124, "seek": 66864, "start": 678.56, "end": 683.16, "text": " We are the instruction pointer to the stack, calculate the previous frame, frame stack", "tokens": [492, 366, 264, 10951, 23918, 281, 264, 8630, 11, 8873, 264, 3894, 3920, 11, 3920, 8630], "temperature": 0.0, "avg_logprob": -0.19831722259521484, "compression_ratio": 1.7666666666666666, "no_speech_prob": 1.5672143490519375e-05}, {"id": 125, "seek": 66864, "start": 683.16, "end": 690.1999999999999, "text": " pointer, then update the registers with the calculated values for the previous frame and", "tokens": [23918, 11, 550, 5623, 264, 38351, 365, 264, 15598, 4190, 337, 264, 3894, 3920, 293], "temperature": 0.0, "avg_logprob": -0.19831722259521484, "compression_ratio": 1.7666666666666666, "no_speech_prob": 1.5672143490519375e-05}, {"id": 126, "seek": 66864, "start": 690.1999999999999, "end": 692.4, "text": " then continue with the next frame.", "tokens": [550, 2354, 365, 264, 958, 3920, 13], "temperature": 0.0, "avg_logprob": -0.19831722259521484, "compression_ratio": 1.7666666666666666, "no_speech_prob": 1.5672143490519375e-05}, {"id": 127, "seek": 66864, "start": 692.4, "end": 698.0, "text": " So there's like just a nutshell that's what the algorithm is in the BPF.", "tokens": [407, 456, 311, 411, 445, 257, 37711, 300, 311, 437, 264, 9284, 307, 294, 264, 40533, 37, 13], "temperature": 0.0, "avg_logprob": -0.19831722259521484, "compression_ratio": 1.7666666666666666, "no_speech_prob": 1.5672143490519375e-05}, {"id": 128, "seek": 69800, "start": 698.0, "end": 704.6, "text": " But now the important part is how we store that unwind information and what we have done", "tokens": [583, 586, 264, 1021, 644, 307, 577, 321, 3531, 300, 517, 12199, 1589, 293, 437, 321, 362, 1096], "temperature": 0.0, "avg_logprob": -0.18865885232624255, "compression_ratio": 1.5738636363636365, "no_speech_prob": 6.698031938867643e-05}, {"id": 129, "seek": 69800, "start": 704.6, "end": 706.64, "text": " to make it scalable.", "tokens": [281, 652, 309, 38481, 13], "temperature": 0.0, "avg_logprob": -0.18865885232624255, "compression_ratio": 1.5738636363636365, "no_speech_prob": 6.698031938867643e-05}, {"id": 130, "seek": 69800, "start": 706.64, "end": 712.6, "text": " So now Javier will talk about that.", "tokens": [407, 586, 508, 25384, 486, 751, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.18865885232624255, "compression_ratio": 1.5738636363636365, "no_speech_prob": 6.698031938867643e-05}, {"id": 131, "seek": 69800, "start": 712.6, "end": 717.72, "text": " Cool.", "tokens": [8561, 13], "temperature": 0.0, "avg_logprob": -0.18865885232624255, "compression_ratio": 1.5738636363636365, "no_speech_prob": 6.698031938867643e-05}, {"id": 132, "seek": 69800, "start": 717.72, "end": 722.64, "text": " So now we have some unwind information that we're going to describe the format later,", "tokens": [407, 586, 321, 362, 512, 517, 12199, 1589, 300, 321, 434, 516, 281, 6786, 264, 7877, 1780, 11], "temperature": 0.0, "avg_logprob": -0.18865885232624255, "compression_ratio": 1.5738636363636365, "no_speech_prob": 6.698031938867643e-05}, {"id": 133, "seek": 69800, "start": 722.64, "end": 725.56, "text": " but we need to put it somewhere, right?", "tokens": [457, 321, 643, 281, 829, 309, 4079, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18865885232624255, "compression_ratio": 1.5738636363636365, "no_speech_prob": 6.698031938867643e-05}, {"id": 134, "seek": 72556, "start": 725.56, "end": 730.56, "text": " So one possibility would be to store this unwind info in the memory space of the applications", "tokens": [407, 472, 7959, 576, 312, 281, 3531, 341, 517, 12199, 13614, 294, 264, 4675, 1901, 295, 264, 5821], "temperature": 0.0, "avg_logprob": -0.15099344668181047, "compression_ratio": 1.7015503875968991, "no_speech_prob": 5.5327502195723355e-05}, {"id": 135, "seek": 72556, "start": 730.56, "end": 732.64, "text": " that we are trying to profile.", "tokens": [300, 321, 366, 1382, 281, 7964, 13], "temperature": 0.0, "avg_logprob": -0.15099344668181047, "compression_ratio": 1.7015503875968991, "no_speech_prob": 5.5327502195723355e-05}, {"id": 136, "seek": 72556, "start": 732.64, "end": 737.3599999999999, "text": " And we could do this, for example, using a combination of ptrace, mmap, and mlock.", "tokens": [400, 321, 727, 360, 341, 11, 337, 1365, 11, 1228, 257, 6562, 295, 280, 6903, 617, 11, 275, 24223, 11, 293, 275, 4102, 13], "temperature": 0.0, "avg_logprob": -0.15099344668181047, "compression_ratio": 1.7015503875968991, "no_speech_prob": 5.5327502195723355e-05}, {"id": 137, "seek": 72556, "start": 737.3599999999999, "end": 745.04, "text": " And we could use ptrace to hijack the process execution and allocate a new memory segment.", "tokens": [400, 321, 727, 764, 280, 6903, 617, 281, 10625, 501, 264, 1399, 15058, 293, 35713, 257, 777, 4675, 9469, 13], "temperature": 0.0, "avg_logprob": -0.15099344668181047, "compression_ratio": 1.7015503875968991, "no_speech_prob": 5.5327502195723355e-05}, {"id": 138, "seek": 72556, "start": 745.04, "end": 749.76, "text": " And then we will have to lock it because in BPF we need to make sure that the pages that", "tokens": [400, 550, 321, 486, 362, 281, 4017, 309, 570, 294, 40533, 37, 321, 643, 281, 652, 988, 300, 264, 7183, 300], "temperature": 0.0, "avg_logprob": -0.15099344668181047, "compression_ratio": 1.7015503875968991, "no_speech_prob": 5.5327502195723355e-05}, {"id": 139, "seek": 72556, "start": 749.76, "end": 753.4799999999999, "text": " we are accessing are never going to be swapped out.", "tokens": [321, 366, 26440, 366, 1128, 516, 281, 312, 50011, 484, 13], "temperature": 0.0, "avg_logprob": -0.15099344668181047, "compression_ratio": 1.7015503875968991, "no_speech_prob": 5.5327502195723355e-05}, {"id": 140, "seek": 75348, "start": 753.48, "end": 757.48, "text": " But this has a big problem, that is, that will be altering the execution flow of the", "tokens": [583, 341, 575, 257, 955, 1154, 11, 300, 307, 11, 300, 486, 312, 11337, 278, 264, 15058, 3095, 295, 264], "temperature": 0.0, "avg_logprob": -0.15961457754819447, "compression_ratio": 1.8006756756756757, "no_speech_prob": 0.00012479498400352895}, {"id": 141, "seek": 75348, "start": 757.48, "end": 758.48, "text": " program.", "tokens": [1461, 13], "temperature": 0.0, "avg_logprob": -0.15961457754819447, "compression_ratio": 1.8006756756756757, "no_speech_prob": 0.00012479498400352895}, {"id": 142, "seek": 75348, "start": 758.48, "end": 761.04, "text": " And it's something that we never want to do.", "tokens": [400, 309, 311, 746, 300, 321, 1128, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.15961457754819447, "compression_ratio": 1.8006756756756757, "no_speech_prob": 0.00012479498400352895}, {"id": 143, "seek": 75348, "start": 761.04, "end": 764.96, "text": " One of the reasons for this is because, first, this memory will live in the process, which", "tokens": [1485, 295, 264, 4112, 337, 341, 307, 570, 11, 700, 11, 341, 4675, 486, 1621, 294, 264, 1399, 11, 597], "temperature": 0.0, "avg_logprob": -0.15961457754819447, "compression_ratio": 1.8006756756756757, "no_speech_prob": 0.00012479498400352895}, {"id": 144, "seek": 75348, "start": 764.96, "end": 769.36, "text": " means that accounting for it will be odd and developers will find a new memory segment", "tokens": [1355, 300, 19163, 337, 309, 486, 312, 7401, 293, 8849, 486, 915, 257, 777, 4675, 9469], "temperature": 0.0, "avg_logprob": -0.15961457754819447, "compression_ratio": 1.8006756756756757, "no_speech_prob": 0.00012479498400352895}, {"id": 145, "seek": 75348, "start": 769.36, "end": 770.52, "text": " there that appeared out of the blue.", "tokens": [456, 300, 8516, 484, 295, 264, 3344, 13], "temperature": 0.0, "avg_logprob": -0.15961457754819447, "compression_ratio": 1.8006756756756757, "no_speech_prob": 0.00012479498400352895}, {"id": 146, "seek": 75348, "start": 770.52, "end": 774.52, "text": " So in their metrics, there will be something that changes behind their backs, which is not", "tokens": [407, 294, 641, 16367, 11, 456, 486, 312, 746, 300, 2962, 2261, 641, 19513, 11, 597, 307, 406], "temperature": 0.0, "avg_logprob": -0.15961457754819447, "compression_ratio": 1.8006756756756757, "no_speech_prob": 0.00012479498400352895}, {"id": 147, "seek": 75348, "start": 774.52, "end": 775.52, "text": " great.", "tokens": [869, 13], "temperature": 0.0, "avg_logprob": -0.15961457754819447, "compression_ratio": 1.8006756756756757, "no_speech_prob": 0.00012479498400352895}, {"id": 148, "seek": 75348, "start": 775.52, "end": 779.24, "text": " But also because the lifecycle of managing this memory chunk is very complicated.", "tokens": [583, 611, 570, 264, 45722, 295, 11642, 341, 4675, 16635, 307, 588, 6179, 13], "temperature": 0.0, "avg_logprob": -0.15961457754819447, "compression_ratio": 1.8006756756756757, "no_speech_prob": 0.00012479498400352895}, {"id": 149, "seek": 77924, "start": 779.24, "end": 784.12, "text": " For example, what do you do if our application, if our profiler dies before the processes", "tokens": [1171, 1365, 11, 437, 360, 291, 360, 498, 527, 3861, 11, 498, 527, 1740, 5441, 2714, 949, 264, 7555], "temperature": 0.0, "avg_logprob": -0.17907173850319602, "compression_ratio": 1.6752767527675276, "no_speech_prob": 9.975237480830401e-05}, {"id": 150, "seek": 77924, "start": 784.12, "end": 785.64, "text": " that we are introspecting?", "tokens": [300, 321, 366, 560, 28713, 278, 30], "temperature": 0.0, "avg_logprob": -0.17907173850319602, "compression_ratio": 1.6752767527675276, "no_speech_prob": 9.975237480830401e-05}, {"id": 151, "seek": 77924, "start": 785.64, "end": 786.64, "text": " How do we clean this up?", "tokens": [1012, 360, 321, 2541, 341, 493, 30], "temperature": 0.0, "avg_logprob": -0.17907173850319602, "compression_ratio": 1.6752767527675276, "no_speech_prob": 9.975237480830401e-05}, {"id": 152, "seek": 77924, "start": 786.64, "end": 792.84, "text": " It involves a lot of, that's a lot of problems and adding solutions to these problems will", "tokens": [467, 11626, 257, 688, 295, 11, 300, 311, 257, 688, 295, 2740, 293, 5127, 6547, 281, 613, 2740, 486], "temperature": 0.0, "avg_logprob": -0.17907173850319602, "compression_ratio": 1.6752767527675276, "no_speech_prob": 9.975237480830401e-05}, {"id": 153, "seek": 77924, "start": 792.84, "end": 799.34, "text": " require like crazy engineering, which we were not planning to tackle because it will over", "tokens": [3651, 411, 3219, 7043, 11, 597, 321, 645, 406, 5038, 281, 14896, 570, 309, 486, 670], "temperature": 0.0, "avg_logprob": -0.17907173850319602, "compression_ratio": 1.6752767527675276, "no_speech_prob": 9.975237480830401e-05}, {"id": 154, "seek": 77924, "start": 799.34, "end": 801.08, "text": " complicated project a lot.", "tokens": [6179, 1716, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.17907173850319602, "compression_ratio": 1.6752767527675276, "no_speech_prob": 9.975237480830401e-05}, {"id": 155, "seek": 77924, "start": 801.08, "end": 806.84, "text": " The other problem is that sharing memories way harder and accounting for our overhead", "tokens": [440, 661, 1154, 307, 300, 5414, 8495, 636, 6081, 293, 19163, 337, 527, 19922], "temperature": 0.0, "avg_logprob": -0.17907173850319602, "compression_ratio": 1.6752767527675276, "no_speech_prob": 9.975237480830401e-05}, {"id": 156, "seek": 77924, "start": 806.84, "end": 807.84, "text": " is also very hard.", "tokens": [307, 611, 588, 1152, 13], "temperature": 0.0, "avg_logprob": -0.17907173850319602, "compression_ratio": 1.6752767527675276, "no_speech_prob": 9.975237480830401e-05}, {"id": 157, "seek": 80784, "start": 807.84, "end": 811.96, "text": " If you think about it, for example, Libc is probably linked in most of the applications", "tokens": [759, 291, 519, 466, 309, 11, 337, 1365, 11, 15834, 66, 307, 1391, 9408, 294, 881, 295, 264, 5821], "temperature": 0.0, "avg_logprob": -0.17068445682525635, "compression_ratio": 1.6029411764705883, "no_speech_prob": 3.414037564652972e-05}, {"id": 158, "seek": 80784, "start": 811.96, "end": 813.12, "text": " in your machine.", "tokens": [294, 428, 3479, 13], "temperature": 0.0, "avg_logprob": -0.17068445682525635, "compression_ratio": 1.6029411764705883, "no_speech_prob": 3.414037564652972e-05}, {"id": 159, "seek": 80784, "start": 813.12, "end": 818.36, "text": " So why having the same information like for every single process, right?", "tokens": [407, 983, 1419, 264, 912, 1589, 411, 337, 633, 2167, 1399, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17068445682525635, "compression_ratio": 1.6029411764705883, "no_speech_prob": 3.414037564652972e-05}, {"id": 160, "seek": 80784, "start": 818.36, "end": 820.8000000000001, "text": " So how do we actually store this information?", "tokens": [407, 577, 360, 321, 767, 3531, 341, 1589, 30], "temperature": 0.0, "avg_logprob": -0.17068445682525635, "compression_ratio": 1.6029411764705883, "no_speech_prob": 3.414037564652972e-05}, {"id": 161, "seek": 80784, "start": 820.8000000000001, "end": 826.32, "text": " We use BPF maps, which are data structures that, as Shali said, they can be written and", "tokens": [492, 764, 40533, 37, 11317, 11, 597, 366, 1412, 9227, 300, 11, 382, 1160, 5103, 848, 11, 436, 393, 312, 3720, 293], "temperature": 0.0, "avg_logprob": -0.17068445682525635, "compression_ratio": 1.6029411764705883, "no_speech_prob": 3.414037564652972e-05}, {"id": 162, "seek": 80784, "start": 826.32, "end": 829.1600000000001, "text": " read both from kernel and user space.", "tokens": [1401, 1293, 490, 28256, 293, 4195, 1901, 13], "temperature": 0.0, "avg_logprob": -0.17068445682525635, "compression_ratio": 1.6029411764705883, "no_speech_prob": 3.414037564652972e-05}, {"id": 163, "seek": 80784, "start": 829.1600000000001, "end": 833.48, "text": " We use in particular hash maps, which in the case of BPF, they are basically a mapping", "tokens": [492, 764, 294, 1729, 22019, 11317, 11, 597, 294, 264, 1389, 295, 40533, 37, 11, 436, 366, 1936, 257, 18350], "temperature": 0.0, "avg_logprob": -0.17068445682525635, "compression_ratio": 1.6029411764705883, "no_speech_prob": 3.414037564652972e-05}, {"id": 164, "seek": 83348, "start": 833.48, "end": 838.6800000000001, "text": " of bytes to bytes where you can put arbitrary information.", "tokens": [295, 36088, 281, 36088, 689, 291, 393, 829, 23211, 1589, 13], "temperature": 0.0, "avg_logprob": -0.17359930469143775, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.00014979910338297486}, {"id": 165, "seek": 83348, "start": 838.6800000000001, "end": 840.5600000000001, "text": " So this is always locked in memory.", "tokens": [407, 341, 307, 1009, 9376, 294, 4675, 13], "temperature": 0.0, "avg_logprob": -0.17359930469143775, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.00014979910338297486}, {"id": 166, "seek": 83348, "start": 840.5600000000001, "end": 845.9200000000001, "text": " BPF allows you with this flag not to lock memory, but in the type of BPF program we use,", "tokens": [40533, 37, 4045, 291, 365, 341, 7166, 406, 281, 4017, 4675, 11, 457, 294, 264, 2010, 295, 40533, 37, 1461, 321, 764, 11], "temperature": 0.0, "avg_logprob": -0.17359930469143775, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.00014979910338297486}, {"id": 167, "seek": 83348, "start": 845.9200000000001, "end": 847.72, "text": " it is mandatory to lock it.", "tokens": [309, 307, 22173, 281, 4017, 309, 13], "temperature": 0.0, "avg_logprob": -0.17359930469143775, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.00014979910338297486}, {"id": 168, "seek": 83348, "start": 847.72, "end": 853.44, "text": " Otherwise, as we said before, these pages could be swapped out and from the type of", "tokens": [10328, 11, 382, 321, 848, 949, 11, 613, 7183, 727, 312, 50011, 484, 293, 490, 264, 2010, 295], "temperature": 0.0, "avg_logprob": -0.17359930469143775, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.00014979910338297486}, {"id": 169, "seek": 83348, "start": 853.44, "end": 858.72, "text": " BPF programs that we have, page faults are forbidden.", "tokens": [40533, 37, 4268, 300, 321, 362, 11, 3028, 36090, 366, 25990, 13], "temperature": 0.0, "avg_logprob": -0.17359930469143775, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.00014979910338297486}, {"id": 170, "seek": 85872, "start": 858.72, "end": 865.0, "text": " And yeah, in the end, we could reuse these mappings because they are in this kind of", "tokens": [400, 1338, 11, 294, 264, 917, 11, 321, 727, 26225, 613, 463, 28968, 570, 436, 366, 294, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.14502803740962858, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.307409133412875e-05}, {"id": 171, "seek": 85872, "start": 865.0, "end": 868.28, "text": " global BPF map that we have control over.", "tokens": [4338, 40533, 37, 4471, 300, 321, 362, 1969, 670, 13], "temperature": 0.0, "avg_logprob": -0.14502803740962858, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.307409133412875e-05}, {"id": 172, "seek": 85872, "start": 868.28, "end": 872.0, "text": " So we can store, for example, Libc in one particular area, and then we'll have to add", "tokens": [407, 321, 393, 3531, 11, 337, 1365, 11, 15834, 66, 294, 472, 1729, 1859, 11, 293, 550, 321, 603, 362, 281, 909], "temperature": 0.0, "avg_logprob": -0.14502803740962858, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.307409133412875e-05}, {"id": 173, "seek": 85872, "start": 872.0, "end": 877.36, "text": " metadata for where it is for every single process that has this mapping.", "tokens": [26603, 337, 689, 309, 307, 337, 633, 2167, 1399, 300, 575, 341, 18350, 13], "temperature": 0.0, "avg_logprob": -0.14502803740962858, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.307409133412875e-05}, {"id": 174, "seek": 85872, "start": 877.36, "end": 882.88, "text": " So yeah, this is a logical representation of our information for different executable", "tokens": [407, 1338, 11, 341, 307, 257, 14978, 10290, 295, 527, 1589, 337, 819, 7568, 712], "temperature": 0.0, "avg_logprob": -0.14502803740962858, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.307409133412875e-05}, {"id": 175, "seek": 85872, "start": 882.88, "end": 883.88, "text": " segments.", "tokens": [19904, 13], "temperature": 0.0, "avg_logprob": -0.14502803740962858, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.307409133412875e-05}, {"id": 176, "seek": 85872, "start": 883.88, "end": 888.34, "text": " So imagine this is Libc, MySQL, Zlib, SystemD, and then some tank that isn't used.", "tokens": [407, 3811, 341, 307, 15834, 66, 11, 1222, 39934, 11, 1176, 38270, 11, 8910, 35, 11, 293, 550, 512, 5466, 300, 1943, 380, 1143, 13], "temperature": 0.0, "avg_logprob": -0.14502803740962858, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.307409133412875e-05}, {"id": 177, "seek": 88834, "start": 888.34, "end": 895.1600000000001, "text": " So this assumes that we have this logical view has a chunk of memory that is contiguous.", "tokens": [407, 341, 37808, 300, 321, 362, 341, 14978, 1910, 575, 257, 16635, 295, 4675, 300, 307, 660, 30525, 13], "temperature": 0.0, "avg_logprob": -0.177384660955061, "compression_ratio": 1.69140625, "no_speech_prob": 9.379577386425808e-05}, {"id": 178, "seek": 88834, "start": 895.1600000000001, "end": 898.48, "text": " But in reality, we cannot allocate any arbitrary chunk of memory in BPF.", "tokens": [583, 294, 4103, 11, 321, 2644, 35713, 604, 23211, 16635, 295, 4675, 294, 40533, 37, 13], "temperature": 0.0, "avg_logprob": -0.177384660955061, "compression_ratio": 1.69140625, "no_speech_prob": 9.379577386425808e-05}, {"id": 179, "seek": 88834, "start": 898.48, "end": 902.72, "text": " We cannot say we want 200 megabytes and it needs to be contiguous.", "tokens": [492, 2644, 584, 321, 528, 2331, 10816, 24538, 293, 309, 2203, 281, 312, 660, 30525, 13], "temperature": 0.0, "avg_logprob": -0.177384660955061, "compression_ratio": 1.69140625, "no_speech_prob": 9.379577386425808e-05}, {"id": 180, "seek": 88834, "start": 902.72, "end": 905.1600000000001, "text": " We cannot do an malloc, right?", "tokens": [492, 2644, 360, 364, 16026, 905, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.177384660955061, "compression_ratio": 1.69140625, "no_speech_prob": 9.379577386425808e-05}, {"id": 181, "seek": 88834, "start": 905.1600000000001, "end": 909.6800000000001, "text": " So we've been doing some experiments and in the systems that we have tested and the kernels", "tokens": [407, 321, 600, 668, 884, 512, 12050, 293, 294, 264, 3652, 300, 321, 362, 8246, 293, 264, 23434, 1625], "temperature": 0.0, "avg_logprob": -0.177384660955061, "compression_ratio": 1.69140625, "no_speech_prob": 9.379577386425808e-05}, {"id": 182, "seek": 88834, "start": 909.6800000000001, "end": 918.22, "text": " that we want to support, we can add up to 250,000 wine entries to each value of a", "tokens": [300, 321, 528, 281, 1406, 11, 321, 393, 909, 493, 281, 11650, 11, 1360, 7209, 23041, 281, 1184, 2158, 295, 257], "temperature": 0.0, "avg_logprob": -0.177384660955061, "compression_ratio": 1.69140625, "no_speech_prob": 9.379577386425808e-05}, {"id": 183, "seek": 91822, "start": 918.22, "end": 920.32, "text": " BPF map.", "tokens": [40533, 37, 4471, 13], "temperature": 0.0, "avg_logprob": -0.13053099675612015, "compression_ratio": 1.6045454545454545, "no_speech_prob": 7.190665928646922e-05}, {"id": 184, "seek": 91822, "start": 920.32, "end": 925.9200000000001, "text": " So because we want to be able to fit larger wine tables, we basically use the same solution", "tokens": [407, 570, 321, 528, 281, 312, 1075, 281, 3318, 4833, 7209, 8020, 11, 321, 1936, 764, 264, 912, 3827], "temperature": 0.0, "avg_logprob": -0.13053099675612015, "compression_ratio": 1.6045454545454545, "no_speech_prob": 7.190665928646922e-05}, {"id": 185, "seek": 91822, "start": 925.9200000000001, "end": 933.48, "text": " that you would use in any other data intensive application, which is partitioning or sharding.", "tokens": [300, 291, 576, 764, 294, 604, 661, 1412, 18957, 3861, 11, 597, 307, 24808, 278, 420, 402, 515, 278, 13], "temperature": 0.0, "avg_logprob": -0.13053099675612015, "compression_ratio": 1.6045454545454545, "no_speech_prob": 7.190665928646922e-05}, {"id": 186, "seek": 91822, "start": 933.48, "end": 940.84, "text": " So we are splitting the wine table into different shards and depending on the memory that your", "tokens": [407, 321, 366, 30348, 264, 7209, 3199, 666, 819, 402, 2287, 293, 5413, 322, 264, 4675, 300, 428], "temperature": 0.0, "avg_logprob": -0.13053099675612015, "compression_ratio": 1.6045454545454545, "no_speech_prob": 7.190665928646922e-05}, {"id": 187, "seek": 91822, "start": 940.84, "end": 945.9200000000001, "text": " machine has, we'll allocate more or less shards ahead of time.", "tokens": [3479, 575, 11, 321, 603, 35713, 544, 420, 1570, 402, 2287, 2286, 295, 565, 13], "temperature": 0.0, "avg_logprob": -0.13053099675612015, "compression_ratio": 1.6045454545454545, "no_speech_prob": 7.190665928646922e-05}, {"id": 188, "seek": 94592, "start": 945.92, "end": 951.4, "text": " That will result in a CPU to memory trade-off because when they get full, we'll regenerate", "tokens": [663, 486, 1874, 294, 257, 13199, 281, 4675, 4923, 12, 4506, 570, 562, 436, 483, 1577, 11, 321, 603, 26358, 473], "temperature": 0.0, "avg_logprob": -0.14203456044197083, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.00010771668166853487}, {"id": 189, "seek": 94592, "start": 951.4, "end": 952.4, "text": " them.", "tokens": [552, 13], "temperature": 0.0, "avg_logprob": -0.14203456044197083, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.00010771668166853487}, {"id": 190, "seek": 94592, "start": 952.4, "end": 954.28, "text": " But we'll talk about this later.", "tokens": [583, 321, 603, 751, 466, 341, 1780, 13], "temperature": 0.0, "avg_logprob": -0.14203456044197083, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.00010771668166853487}, {"id": 191, "seek": 94592, "start": 954.28, "end": 958.8, "text": " So for example, let's see SystemD some wine table and let's suppose that it's a bit bigger", "tokens": [407, 337, 1365, 11, 718, 311, 536, 8910, 35, 512, 7209, 3199, 293, 718, 311, 7297, 300, 309, 311, 257, 857, 3801], "temperature": 0.0, "avg_logprob": -0.14203456044197083, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.00010771668166853487}, {"id": 192, "seek": 94592, "start": 958.8, "end": 964.7199999999999, "text": " than 250,000 elements so it doesn't fit in a single shard.", "tokens": [813, 11650, 11, 1360, 4959, 370, 309, 1177, 380, 3318, 294, 257, 2167, 402, 515, 13], "temperature": 0.0, "avg_logprob": -0.14203456044197083, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.00010771668166853487}, {"id": 193, "seek": 94592, "start": 964.7199999999999, "end": 966.8399999999999, "text": " So because it doesn't, we have to chunk it up.", "tokens": [407, 570, 309, 1177, 380, 11, 321, 362, 281, 16635, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.14203456044197083, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.00010771668166853487}, {"id": 194, "seek": 94592, "start": 966.8399999999999, "end": 971.76, "text": " So we store the first chunk in the first shard and then there's a little bit that it's stored", "tokens": [407, 321, 3531, 264, 700, 16635, 294, 264, 700, 402, 515, 293, 550, 456, 311, 257, 707, 857, 300, 309, 311, 12187], "temperature": 0.0, "avg_logprob": -0.14203456044197083, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.00010771668166853487}, {"id": 195, "seek": 94592, "start": 971.76, "end": 974.4, "text": " in the second shard.", "tokens": [294, 264, 1150, 402, 515, 13], "temperature": 0.0, "avg_logprob": -0.14203456044197083, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.00010771668166853487}, {"id": 196, "seek": 97440, "start": 974.4, "end": 976.28, "text": " So we have added all these layers of indirection.", "tokens": [407, 321, 362, 3869, 439, 613, 7914, 295, 1016, 621, 882, 13], "temperature": 0.0, "avg_logprob": -0.1337613535451365, "compression_ratio": 1.5727699530516432, "no_speech_prob": 6.169663538457826e-05}, {"id": 197, "seek": 97440, "start": 976.28, "end": 981.6, "text": " We need some bookkeeping to do and this metadata is also stored in BPF maps.", "tokens": [492, 643, 512, 1446, 25769, 281, 360, 293, 341, 26603, 307, 611, 12187, 294, 40533, 37, 11317, 13], "temperature": 0.0, "avg_logprob": -0.1337613535451365, "compression_ratio": 1.5727699530516432, "no_speech_prob": 6.169663538457826e-05}, {"id": 198, "seek": 97440, "start": 981.6, "end": 986.04, "text": " So we have a process that can have many mappings.", "tokens": [407, 321, 362, 257, 1399, 300, 393, 362, 867, 463, 28968, 13], "temperature": 0.0, "avg_logprob": -0.1337613535451365, "compression_ratio": 1.5727699530516432, "no_speech_prob": 6.169663538457826e-05}, {"id": 199, "seek": 97440, "start": 986.04, "end": 992.4, "text": " Each mapping can have one or more chunks and then each chunk maps to a particular shard", "tokens": [6947, 18350, 393, 362, 472, 420, 544, 24004, 293, 550, 1184, 16635, 11317, 281, 257, 1729, 402, 515], "temperature": 0.0, "avg_logprob": -0.1337613535451365, "compression_ratio": 1.5727699530516432, "no_speech_prob": 6.169663538457826e-05}, {"id": 200, "seek": 97440, "start": 992.4, "end": 999.0, "text": " because you might have one and wine entry or up to 250,000 in a shard.", "tokens": [570, 291, 1062, 362, 472, 293, 7209, 8729, 420, 493, 281, 11650, 11, 1360, 294, 257, 402, 515, 13], "temperature": 0.0, "avg_logprob": -0.1337613535451365, "compression_ratio": 1.5727699530516432, "no_speech_prob": 6.169663538457826e-05}, {"id": 201, "seek": 99900, "start": 999.0, "end": 1005.4, "text": " We have some other metadata to exactly tell you where that information leaves.", "tokens": [492, 362, 512, 661, 26603, 281, 2293, 980, 291, 689, 300, 1589, 5510, 13], "temperature": 0.0, "avg_logprob": -0.17331483071310477, "compression_ratio": 1.6816479400749065, "no_speech_prob": 4.817211811314337e-05}, {"id": 202, "seek": 99900, "start": 1005.4, "end": 1010.44, "text": " So yeah, thanks to this way of organizing data, we're able to, as we said before, share", "tokens": [407, 1338, 11, 3231, 281, 341, 636, 295, 17608, 1412, 11, 321, 434, 1075, 281, 11, 382, 321, 848, 949, 11, 2073], "temperature": 0.0, "avg_logprob": -0.17331483071310477, "compression_ratio": 1.6816479400749065, "no_speech_prob": 4.817211811314337e-05}, {"id": 203, "seek": 99900, "start": 1010.44, "end": 1016.36, "text": " these executable mappings and thanks to that, we skip table generation for most of the executables", "tokens": [613, 7568, 712, 463, 28968, 293, 3231, 281, 300, 11, 321, 10023, 3199, 5125, 337, 881, 295, 264, 7568, 2965], "temperature": 0.0, "avg_logprob": -0.17331483071310477, "compression_ratio": 1.6816479400749065, "no_speech_prob": 4.817211811314337e-05}, {"id": 204, "seek": 99900, "start": 1016.36, "end": 1017.36, "text": " in your box.", "tokens": [294, 428, 2424, 13], "temperature": 0.0, "avg_logprob": -0.17331483071310477, "compression_ratio": 1.6816479400749065, "no_speech_prob": 4.817211811314337e-05}, {"id": 205, "seek": 99900, "start": 1017.36, "end": 1022.96, "text": " And thanks to this, we only use 0.9% of the CPU cycles doing the process that Vashali", "tokens": [400, 3231, 281, 341, 11, 321, 787, 764, 1958, 13, 24, 4, 295, 264, 13199, 17796, 884, 264, 1399, 300, 691, 1299, 5103], "temperature": 0.0, "avg_logprob": -0.17331483071310477, "compression_ratio": 1.6816479400749065, "no_speech_prob": 4.817211811314337e-05}, {"id": 206, "seek": 99900, "start": 1022.96, "end": 1026.4, "text": " was talking about before, which is not the most complex process in the universe, but", "tokens": [390, 1417, 466, 949, 11, 597, 307, 406, 264, 881, 3997, 1399, 294, 264, 6445, 11, 457], "temperature": 0.0, "avg_logprob": -0.17331483071310477, "compression_ratio": 1.6816479400749065, "no_speech_prob": 4.817211811314337e-05}, {"id": 207, "seek": 102640, "start": 1026.4, "end": 1031.76, "text": " it consumes some CPU cycles because we need to read some information from your L file,", "tokens": [309, 48823, 512, 13199, 17796, 570, 321, 643, 281, 1401, 512, 1589, 490, 428, 441, 3991, 11], "temperature": 0.0, "avg_logprob": -0.1366723427405724, "compression_ratio": 1.8111888111888113, "no_speech_prob": 8.855212217895314e-05}, {"id": 208, "seek": 102640, "start": 1031.76, "end": 1036.68, "text": " find the section, then we need to read the section and we need to parse it and interpret", "tokens": [915, 264, 3541, 11, 550, 321, 643, 281, 1401, 264, 3541, 293, 321, 643, 281, 48377, 309, 293, 7302], "temperature": 0.0, "avg_logprob": -0.1366723427405724, "compression_ratio": 1.8111888111888113, "no_speech_prob": 8.855212217895314e-05}, {"id": 209, "seek": 102640, "start": 1036.68, "end": 1038.48, "text": " the dwarf information.", "tokens": [264, 35527, 1589, 13], "temperature": 0.0, "avg_logprob": -0.1366723427405724, "compression_ratio": 1.8111888111888113, "no_speech_prob": 8.855212217895314e-05}, {"id": 210, "seek": 102640, "start": 1038.48, "end": 1040.3600000000001, "text": " So now we need to do way fewer times.", "tokens": [407, 586, 321, 643, 281, 360, 636, 13366, 1413, 13], "temperature": 0.0, "avg_logprob": -0.1366723427405724, "compression_ratio": 1.8111888111888113, "no_speech_prob": 8.855212217895314e-05}, {"id": 211, "seek": 102640, "start": 1040.3600000000001, "end": 1045.68, "text": " So in your machine, we're only going to do it once per unique executable section.", "tokens": [407, 294, 428, 3479, 11, 321, 434, 787, 516, 281, 360, 309, 1564, 680, 3845, 7568, 712, 3541, 13], "temperature": 0.0, "avg_logprob": -0.1366723427405724, "compression_ratio": 1.8111888111888113, "no_speech_prob": 8.855212217895314e-05}, {"id": 212, "seek": 102640, "start": 1045.68, "end": 1047.48, "text": " So what happens if we run out of space?", "tokens": [407, 437, 2314, 498, 321, 1190, 484, 295, 1901, 30], "temperature": 0.0, "avg_logprob": -0.1366723427405724, "compression_ratio": 1.8111888111888113, "no_speech_prob": 8.855212217895314e-05}, {"id": 213, "seek": 102640, "start": 1047.48, "end": 1051.4, "text": " So basically what we have implemented is basically a bump allocator.", "tokens": [407, 1936, 437, 321, 362, 12270, 307, 1936, 257, 9961, 12660, 1639, 13], "temperature": 0.0, "avg_logprob": -0.1366723427405724, "compression_ratio": 1.8111888111888113, "no_speech_prob": 8.855212217895314e-05}, {"id": 214, "seek": 102640, "start": 1051.4, "end": 1055.52, "text": " We keep on appending information to the shards and logically you can see it as a big chunk", "tokens": [492, 1066, 322, 724, 2029, 1589, 281, 264, 402, 2287, 293, 38887, 291, 393, 536, 309, 382, 257, 955, 16635], "temperature": 0.0, "avg_logprob": -0.1366723427405724, "compression_ratio": 1.8111888111888113, "no_speech_prob": 8.855212217895314e-05}, {"id": 215, "seek": 105552, "start": 1055.52, "end": 1056.52, "text": " of memory.", "tokens": [295, 4675, 13], "temperature": 0.0, "avg_logprob": -0.12834955298382303, "compression_ratio": 1.6950819672131148, "no_speech_prob": 6.179033516673371e-05}, {"id": 216, "seek": 105552, "start": 1056.52, "end": 1060.52, "text": " Once it's full, at some point, we'll decide to wipe the whole thing and start again, but", "tokens": [3443, 309, 311, 1577, 11, 412, 512, 935, 11, 321, 603, 4536, 281, 14082, 264, 1379, 551, 293, 722, 797, 11, 457], "temperature": 0.0, "avg_logprob": -0.12834955298382303, "compression_ratio": 1.6950819672131148, "no_speech_prob": 6.179033516673371e-05}, {"id": 217, "seek": 105552, "start": 1060.52, "end": 1067.24, "text": " we do it in such a way that we give every single process a fair chance of being profiled.", "tokens": [321, 360, 309, 294, 1270, 257, 636, 300, 321, 976, 633, 2167, 1399, 257, 3143, 2931, 295, 885, 1740, 7292, 13], "temperature": 0.0, "avg_logprob": -0.12834955298382303, "compression_ratio": 1.6950819672131148, "no_speech_prob": 6.179033516673371e-05}, {"id": 218, "seek": 105552, "start": 1067.24, "end": 1069.36, "text": " So yeah, let's take a look at how are we doing this.", "tokens": [407, 1338, 11, 718, 311, 747, 257, 574, 412, 577, 366, 321, 884, 341, 13], "temperature": 0.0, "avg_logprob": -0.12834955298382303, "compression_ratio": 1.6950819672131148, "no_speech_prob": 6.179033516673371e-05}, {"id": 219, "seek": 105552, "start": 1069.36, "end": 1074.0, "text": " So we start with a PID of any process that you find in your machine that at that point", "tokens": [407, 321, 722, 365, 257, 430, 2777, 295, 604, 1399, 300, 291, 915, 294, 428, 3479, 300, 412, 300, 935], "temperature": 0.0, "avg_logprob": -0.12834955298382303, "compression_ratio": 1.6950819672131148, "no_speech_prob": 6.179033516673371e-05}, {"id": 220, "seek": 105552, "start": 1074.0, "end": 1080.16, "text": " happens to be running on CPU, and the first thing we do is to check if it has unwind information.", "tokens": [2314, 281, 312, 2614, 322, 13199, 11, 293, 264, 700, 551, 321, 360, 307, 281, 1520, 498, 309, 575, 517, 12199, 1589, 13], "temperature": 0.0, "avg_logprob": -0.12834955298382303, "compression_ratio": 1.6950819672131148, "no_speech_prob": 6.179033516673371e-05}, {"id": 221, "seek": 105552, "start": 1080.16, "end": 1084.32, "text": " If it does, we need to find the mapping with the current instruction pointer that we have", "tokens": [759, 309, 775, 11, 321, 643, 281, 915, 264, 18350, 365, 264, 2190, 10951, 23918, 300, 321, 362], "temperature": 0.0, "avg_logprob": -0.12834955298382303, "compression_ratio": 1.6950819672131148, "no_speech_prob": 6.179033516673371e-05}, {"id": 222, "seek": 108432, "start": 1084.32, "end": 1086.72, "text": " for that frame.", "tokens": [337, 300, 3920, 13], "temperature": 0.0, "avg_logprob": -0.14423807981972384, "compression_ratio": 1.875, "no_speech_prob": 5.628837607218884e-05}, {"id": 223, "seek": 108432, "start": 1086.72, "end": 1088.3799999999999, "text": " Then we need to find the chunk.", "tokens": [1396, 321, 643, 281, 915, 264, 16635, 13], "temperature": 0.0, "avg_logprob": -0.14423807981972384, "compression_ratio": 1.875, "no_speech_prob": 5.628837607218884e-05}, {"id": 224, "seek": 108432, "start": 1088.3799999999999, "end": 1093.72, "text": " We can find it doing linear search because we have the information of every single, like", "tokens": [492, 393, 915, 309, 884, 8213, 3164, 570, 321, 362, 264, 1589, 295, 633, 2167, 11, 411], "temperature": 0.0, "avg_logprob": -0.14423807981972384, "compression_ratio": 1.875, "no_speech_prob": 5.628837607218884e-05}, {"id": 225, "seek": 108432, "start": 1093.72, "end": 1098.84, "text": " minimum and maximum program counter that is covered by that chunk.", "tokens": [7285, 293, 6674, 1461, 5682, 300, 307, 5343, 538, 300, 16635, 13], "temperature": 0.0, "avg_logprob": -0.14423807981972384, "compression_ratio": 1.875, "no_speech_prob": 5.628837607218884e-05}, {"id": 226, "seek": 108432, "start": 1098.84, "end": 1104.56, "text": " Once we get the chunk, we can have the shard information, and once we have the shard information,", "tokens": [3443, 321, 483, 264, 16635, 11, 321, 393, 362, 264, 402, 515, 1589, 11, 293, 1564, 321, 362, 264, 402, 515, 1589, 11], "temperature": 0.0, "avg_logprob": -0.14423807981972384, "compression_ratio": 1.875, "no_speech_prob": 5.628837607218884e-05}, {"id": 227, "seek": 108432, "start": 1104.56, "end": 1106.48, "text": " we have the unwind information.", "tokens": [321, 362, 264, 517, 12199, 1589, 13], "temperature": 0.0, "avg_logprob": -0.14423807981972384, "compression_ratio": 1.875, "no_speech_prob": 5.628837607218884e-05}, {"id": 228, "seek": 108432, "start": 1106.48, "end": 1111.2, "text": " But the problem is the unwind information, as we said before, it's basically an array.", "tokens": [583, 264, 1154, 307, 264, 517, 12199, 1589, 11, 382, 321, 848, 949, 11, 309, 311, 1936, 364, 10225, 13], "temperature": 0.0, "avg_logprob": -0.14423807981972384, "compression_ratio": 1.875, "no_speech_prob": 5.628837607218884e-05}, {"id": 229, "seek": 111120, "start": 1111.2, "end": 1115.1200000000001, "text": " On this array, we need to find it there, but it can be up to 250,000 items.", "tokens": [1282, 341, 10225, 11, 321, 643, 281, 915, 309, 456, 11, 457, 309, 393, 312, 493, 281, 11650, 11, 1360, 4754, 13], "temperature": 0.0, "avg_logprob": -0.15696182515886095, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.00011533015640452504}, {"id": 230, "seek": 111120, "start": 1115.1200000000001, "end": 1122.28, "text": " If you have done anything on BPF, you know that you have to basically build whatever", "tokens": [759, 291, 362, 1096, 1340, 322, 40533, 37, 11, 291, 458, 300, 291, 362, 281, 1936, 1322, 2035], "temperature": 0.0, "avg_logprob": -0.15696182515886095, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.00011533015640452504}, {"id": 231, "seek": 111120, "start": 1122.28, "end": 1126.68, "text": " you need yourself, and you don't have, for example, some sort of binary search that is", "tokens": [291, 643, 1803, 11, 293, 291, 500, 380, 362, 11, 337, 1365, 11, 512, 1333, 295, 17434, 3164, 300, 307], "temperature": 0.0, "avg_logprob": -0.15696182515886095, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.00011533015640452504}, {"id": 232, "seek": 111120, "start": 1126.68, "end": 1130.2, "text": " executed on kernel space for you, so you need to implement it yourself, which is not a big", "tokens": [17577, 322, 28256, 1901, 337, 291, 11, 370, 291, 643, 281, 4445, 309, 1803, 11, 597, 307, 406, 257, 955], "temperature": 0.0, "avg_logprob": -0.15696182515886095, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.00011533015640452504}, {"id": 233, "seek": 111120, "start": 1130.2, "end": 1131.2, "text": " deal in general.", "tokens": [2028, 294, 2674, 13], "temperature": 0.0, "avg_logprob": -0.15696182515886095, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.00011533015640452504}, {"id": 234, "seek": 111120, "start": 1131.2, "end": 1136.16, "text": " Implementing binary search is not rocket science, but the problem, most of the times, it's difficult", "tokens": [4331, 43704, 278, 17434, 3164, 307, 406, 13012, 3497, 11, 457, 264, 1154, 11, 881, 295, 264, 1413, 11, 309, 311, 2252], "temperature": 0.0, "avg_logprob": -0.15696182515886095, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.00011533015640452504}, {"id": 235, "seek": 111120, "start": 1136.16, "end": 1140.28, "text": " to get all the off by once, but the problem here is that in kernel space, we have a lot", "tokens": [281, 483, 439, 264, 766, 538, 1564, 11, 457, 264, 1154, 510, 307, 300, 294, 28256, 1901, 11, 321, 362, 257, 688], "temperature": 0.0, "avg_logprob": -0.15696182515886095, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.00011533015640452504}, {"id": 236, "seek": 114028, "start": 1140.28, "end": 1143.52, "text": " of limitations we're going to talk about later, and we're going to talk about how we overcame", "tokens": [295, 15705, 321, 434, 516, 281, 751, 466, 1780, 11, 293, 321, 434, 516, 281, 751, 466, 577, 321, 670, 3005], "temperature": 0.0, "avg_logprob": -0.1582909698486328, "compression_ratio": 1.7678571428571428, "no_speech_prob": 8.564947347622365e-05}, {"id": 237, "seek": 114028, "start": 1143.52, "end": 1149.52, "text": " them, because this produces quite a bit of code that has to be split logically.", "tokens": [552, 11, 570, 341, 14725, 1596, 257, 857, 295, 3089, 300, 575, 281, 312, 7472, 38887, 13], "temperature": 0.0, "avg_logprob": -0.1582909698486328, "compression_ratio": 1.7678571428571428, "no_speech_prob": 8.564947347622365e-05}, {"id": 238, "seek": 114028, "start": 1149.52, "end": 1154.6399999999999, "text": " Not only the data structures are sharded, but the code is sharded, too.", "tokens": [1726, 787, 264, 1412, 9227, 366, 402, 22803, 11, 457, 264, 3089, 307, 402, 22803, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.1582909698486328, "compression_ratio": 1.7678571428571428, "no_speech_prob": 8.564947347622365e-05}, {"id": 239, "seek": 114028, "start": 1154.6399999999999, "end": 1160.48, "text": " So anyways, we binary search this with up to seven iterations, but let's say eight, if", "tokens": [407, 13448, 11, 321, 17434, 3164, 341, 365, 493, 281, 3407, 36540, 11, 457, 718, 311, 584, 3180, 11, 498], "temperature": 0.0, "avg_logprob": -0.1582909698486328, "compression_ratio": 1.7678571428571428, "no_speech_prob": 8.564947347622365e-05}, {"id": 240, "seek": 114028, "start": 1160.48, "end": 1165.84, "text": " you're feeling pessimistic, and then we're going to get the unwind action.", "tokens": [291, 434, 2633, 37399, 3142, 11, 293, 550, 321, 434, 516, 281, 483, 264, 517, 12199, 3069, 13], "temperature": 0.0, "avg_logprob": -0.1582909698486328, "compression_ratio": 1.7678571428571428, "no_speech_prob": 8.564947347622365e-05}, {"id": 241, "seek": 114028, "start": 1165.84, "end": 1170.26, "text": " So what is the operation we need to do to the current registers to recover the previous", "tokens": [407, 437, 307, 264, 6916, 321, 643, 281, 360, 281, 264, 2190, 38351, 281, 8114, 264, 3894], "temperature": 0.0, "avg_logprob": -0.1582909698486328, "compression_ratio": 1.7678571428571428, "no_speech_prob": 8.564947347622365e-05}, {"id": 242, "seek": 117026, "start": 1170.26, "end": 1175.0, "text": " registers, and add that frame to the stack trace, and continue with the next frame, as", "tokens": [38351, 11, 293, 909, 300, 3920, 281, 264, 8630, 13508, 11, 293, 2354, 365, 264, 958, 3920, 11, 382], "temperature": 0.0, "avg_logprob": -0.15941010202680314, "compression_ratio": 1.7203389830508475, "no_speech_prob": 8.989073103293777e-05}, {"id": 243, "seek": 117026, "start": 1175.0, "end": 1177.4, "text": " I shall explain before.", "tokens": [286, 4393, 2903, 949, 13], "temperature": 0.0, "avg_logprob": -0.15941010202680314, "compression_ratio": 1.7203389830508475, "no_speech_prob": 8.989073103293777e-05}, {"id": 244, "seek": 117026, "start": 1177.4, "end": 1182.08, "text": " If the stack is correct, and we have the luxury to know that, because when we have known one", "tokens": [759, 264, 8630, 307, 3006, 11, 293, 321, 362, 264, 15558, 281, 458, 300, 11, 570, 562, 321, 362, 2570, 472], "temperature": 0.0, "avg_logprob": -0.15941010202680314, "compression_ratio": 1.7203389830508475, "no_speech_prob": 8.989073103293777e-05}, {"id": 245, "seek": 117026, "start": 1182.08, "end": 1189.48, "text": " information, and RBP is zero, that is specified by the X64 API to be the end of the stack,", "tokens": [1589, 11, 293, 40302, 47, 307, 4018, 11, 300, 307, 22206, 538, 264, 1783, 19395, 9362, 281, 312, 264, 917, 295, 264, 8630, 11], "temperature": 0.0, "avg_logprob": -0.15941010202680314, "compression_ratio": 1.7203389830508475, "no_speech_prob": 8.989073103293777e-05}, {"id": 246, "seek": 117026, "start": 1189.48, "end": 1191.76, "text": " the bottom of the stack.", "tokens": [264, 2767, 295, 264, 8630, 13], "temperature": 0.0, "avg_logprob": -0.15941010202680314, "compression_ratio": 1.7203389830508475, "no_speech_prob": 8.989073103293777e-05}, {"id": 247, "seek": 117026, "start": 1191.76, "end": 1197.4, "text": " So if it is correct, we hash the addresses, add the hash to a map, and bump a counter.", "tokens": [407, 498, 309, 307, 3006, 11, 321, 22019, 264, 16862, 11, 909, 264, 22019, 281, 257, 4471, 11, 293, 9961, 257, 5682, 13], "temperature": 0.0, "avg_logprob": -0.15941010202680314, "compression_ratio": 1.7203389830508475, "no_speech_prob": 8.989073103293777e-05}, {"id": 248, "seek": 119740, "start": 1197.4, "end": 1201.64, "text": " So it is reasonably cheap, and I will show you some data later on this.", "tokens": [407, 309, 307, 23551, 7084, 11, 293, 286, 486, 855, 291, 512, 1412, 1780, 322, 341, 13], "temperature": 0.0, "avg_logprob": -0.10804371643066406, "compression_ratio": 1.6124567474048443, "no_speech_prob": 1.8565520804258995e-05}, {"id": 249, "seek": 119740, "start": 1201.64, "end": 1204.72, "text": " And then every couple seconds, I think it's every 10 seconds or so, we collect all this", "tokens": [400, 550, 633, 1916, 3949, 11, 286, 519, 309, 311, 633, 1266, 3949, 420, 370, 11, 321, 2500, 439, 341], "temperature": 0.0, "avg_logprob": -0.10804371643066406, "compression_ratio": 1.6124567474048443, "no_speech_prob": 1.8565520804258995e-05}, {"id": 250, "seek": 119740, "start": 1204.72, "end": 1211.0, "text": " information from user space, and we generate the actual profiles that we send to some server.", "tokens": [1589, 490, 4195, 1901, 11, 293, 321, 8460, 264, 3539, 23693, 300, 321, 2845, 281, 512, 7154, 13], "temperature": 0.0, "avg_logprob": -0.10804371643066406, "compression_ratio": 1.6124567474048443, "no_speech_prob": 1.8565520804258995e-05}, {"id": 251, "seek": 119740, "start": 1211.0, "end": 1215.4, "text": " As I said before, BPF has some interesting challenges for us.", "tokens": [1018, 286, 848, 949, 11, 40533, 37, 575, 512, 1880, 4759, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.10804371643066406, "compression_ratio": 1.6124567474048443, "no_speech_prob": 1.8565520804258995e-05}, {"id": 252, "seek": 119740, "start": 1215.4, "end": 1220.0400000000002, "text": " I think it's the closest that I've been to coding in the 90s or 80s, because we have", "tokens": [286, 519, 309, 311, 264, 13699, 300, 286, 600, 668, 281, 17720, 294, 264, 4289, 82, 420, 4688, 82, 11, 570, 321, 362], "temperature": 0.0, "avg_logprob": -0.10804371643066406, "compression_ratio": 1.6124567474048443, "no_speech_prob": 1.8565520804258995e-05}, {"id": 253, "seek": 119740, "start": 1220.0400000000002, "end": 1221.0400000000002, "text": " very little stack space.", "tokens": [588, 707, 8630, 1901, 13], "temperature": 0.0, "avg_logprob": -0.10804371643066406, "compression_ratio": 1.6124567474048443, "no_speech_prob": 1.8565520804258995e-05}, {"id": 254, "seek": 119740, "start": 1221.0400000000002, "end": 1224.3600000000001, "text": " We have 512 bytes, if I am not mistaken.", "tokens": [492, 362, 1025, 4762, 36088, 11, 498, 286, 669, 406, 21333, 13], "temperature": 0.0, "avg_logprob": -0.10804371643066406, "compression_ratio": 1.6124567474048443, "no_speech_prob": 1.8565520804258995e-05}, {"id": 255, "seek": 122436, "start": 1224.36, "end": 1230.9199999999998, "text": " So in order to overcome that, we used BPF maps as some sort of heap.", "tokens": [407, 294, 1668, 281, 10473, 300, 11, 321, 1143, 40533, 37, 11317, 382, 512, 1333, 295, 33591, 13], "temperature": 0.0, "avg_logprob": -0.13300218835341193, "compression_ratio": 1.6293706293706294, "no_speech_prob": 4.241821443429217e-05}, {"id": 256, "seek": 122436, "start": 1230.9199999999998, "end": 1234.3999999999999, "text": " Then there's a problem that I mentioned before about memory locking.", "tokens": [1396, 456, 311, 257, 1154, 300, 286, 2835, 949, 466, 4675, 23954, 13], "temperature": 0.0, "avg_logprob": -0.13300218835341193, "compression_ratio": 1.6293706293706294, "no_speech_prob": 4.241821443429217e-05}, {"id": 257, "seek": 122436, "start": 1234.3999999999999, "end": 1238.24, "text": " That memory can never be swapped out, and it is in kernel space.", "tokens": [663, 4675, 393, 1128, 312, 50011, 484, 11, 293, 309, 307, 294, 28256, 1901, 13], "temperature": 0.0, "avg_logprob": -0.13300218835341193, "compression_ratio": 1.6293706293706294, "no_speech_prob": 4.241821443429217e-05}, {"id": 258, "seek": 122436, "start": 1238.24, "end": 1243.0, "text": " So we want to make sure that we allocate the minimal space you need, and we need to do it", "tokens": [407, 321, 528, 281, 652, 988, 300, 321, 35713, 264, 13206, 1901, 291, 643, 11, 293, 321, 643, 281, 360, 309], "temperature": 0.0, "avg_logprob": -0.13300218835341193, "compression_ratio": 1.6293706293706294, "no_speech_prob": 4.241821443429217e-05}, {"id": 259, "seek": 122436, "start": 1243.0, "end": 1249.32, "text": " properly, because each single environment has a different C-group configuration, and as", "tokens": [6108, 11, 570, 1184, 2167, 2823, 575, 257, 819, 383, 12, 17377, 11694, 11, 293, 382], "temperature": 0.0, "avg_logprob": -0.13300218835341193, "compression_ratio": 1.6293706293706294, "no_speech_prob": 4.241821443429217e-05}, {"id": 260, "seek": 122436, "start": 1249.32, "end": 1253.52, "text": " some talks explained yesterday, it's quite tricky to know the actual memory that your", "tokens": [512, 6686, 8825, 5186, 11, 309, 311, 1596, 12414, 281, 458, 264, 3539, 4675, 300, 428], "temperature": 0.0, "avg_logprob": -0.13300218835341193, "compression_ratio": 1.6293706293706294, "no_speech_prob": 4.241821443429217e-05}, {"id": 261, "seek": 125352, "start": 1253.52, "end": 1256.0, "text": " machine has available.", "tokens": [3479, 575, 2435, 13], "temperature": 0.0, "avg_logprob": -0.18326075871785483, "compression_ratio": 1.7581967213114753, "no_speech_prob": 6.779812247259542e-05}, {"id": 262, "seek": 125352, "start": 1256.0, "end": 1259.04, "text": " For the program size, there is two main issues.", "tokens": [1171, 264, 1461, 2744, 11, 456, 307, 732, 2135, 2663, 13], "temperature": 0.0, "avg_logprob": -0.18326075871785483, "compression_ratio": 1.7581967213114753, "no_speech_prob": 6.779812247259542e-05}, {"id": 263, "seek": 125352, "start": 1259.04, "end": 1263.8799999999999, "text": " One of them is that there's a limitation on the number of instructions that you can store", "tokens": [1485, 295, 552, 307, 300, 456, 311, 257, 27432, 322, 264, 1230, 295, 9415, 300, 291, 393, 3531], "temperature": 0.0, "avg_logprob": -0.18326075871785483, "compression_ratio": 1.7581967213114753, "no_speech_prob": 6.779812247259542e-05}, {"id": 264, "seek": 125352, "start": 1263.8799999999999, "end": 1269.6399999999999, "text": " in the kernel, but also the BPF verifier, which is this machinery that makes sure that your", "tokens": [294, 264, 28256, 11, 457, 611, 264, 40533, 37, 1306, 9902, 11, 597, 307, 341, 27302, 300, 1669, 988, 300, 428], "temperature": 0.0, "avg_logprob": -0.18326075871785483, "compression_ratio": 1.7581967213114753, "no_speech_prob": 6.779812247259542e-05}, {"id": 265, "seek": 125352, "start": 1269.6399999999999, "end": 1273.08, "text": " program is safe, and for example, your program is going to finish, you're not the reference", "tokens": [1461, 307, 3273, 11, 293, 337, 1365, 11, 428, 1461, 307, 516, 281, 2413, 11, 291, 434, 406, 264, 6408], "temperature": 0.0, "avg_logprob": -0.18326075871785483, "compression_ratio": 1.7581967213114753, "no_speech_prob": 6.779812247259542e-05}, {"id": 266, "seek": 125352, "start": 1273.08, "end": 1282.76, "text": " in any null pointers, and that in general, you're not going to crash the kernel, has", "tokens": [294, 604, 18184, 44548, 11, 293, 300, 294, 2674, 11, 291, 434, 406, 516, 281, 8252, 264, 28256, 11, 575], "temperature": 0.0, "avg_logprob": -0.18326075871785483, "compression_ratio": 1.7581967213114753, "no_speech_prob": 6.779812247259542e-05}, {"id": 267, "seek": 128276, "start": 1282.76, "end": 1287.84, "text": " a limit on the amount of iterations that it does internally.", "tokens": [257, 4948, 322, 264, 2372, 295, 36540, 300, 309, 775, 19501, 13], "temperature": 0.0, "avg_logprob": -0.17093597490762927, "compression_ratio": 1.590717299578059, "no_speech_prob": 7.929998537292704e-05}, {"id": 268, "seek": 128276, "start": 1287.84, "end": 1294.32, "text": " This is a problem for us, because doing a full binary search already fills these limits.", "tokens": [639, 307, 257, 1154, 337, 505, 11, 570, 884, 257, 1577, 17434, 3164, 1217, 22498, 613, 10406, 13], "temperature": 0.0, "avg_logprob": -0.17093597490762927, "compression_ratio": 1.590717299578059, "no_speech_prob": 7.929998537292704e-05}, {"id": 269, "seek": 128276, "start": 1294.32, "end": 1299.08, "text": " So we need to use some techniques like this thing called BPF tail calls that is similar", "tokens": [407, 321, 643, 281, 764, 512, 7512, 411, 341, 551, 1219, 40533, 37, 6838, 5498, 300, 307, 2531], "temperature": 0.0, "avg_logprob": -0.17093597490762927, "compression_ratio": 1.590717299578059, "no_speech_prob": 7.929998537292704e-05}, {"id": 270, "seek": 128276, "start": 1299.08, "end": 1303.24, "text": " to Lisp tail calls, and if you're lucky, we are not.", "tokens": [281, 441, 7631, 6838, 5498, 11, 293, 498, 291, 434, 6356, 11, 321, 366, 406, 13], "temperature": 0.0, "avg_logprob": -0.17093597490762927, "compression_ratio": 1.590717299578059, "no_speech_prob": 7.929998537292704e-05}, {"id": 271, "seek": 128276, "start": 1303.24, "end": 1308.24, "text": " You can use, well, we use bounded loops, but we're going to use this new helper called", "tokens": [509, 393, 764, 11, 731, 11, 321, 764, 37498, 16121, 11, 457, 321, 434, 516, 281, 764, 341, 777, 36133, 1219], "temperature": 0.0, "avg_logprob": -0.17093597490762927, "compression_ratio": 1.590717299578059, "no_speech_prob": 7.929998537292704e-05}, {"id": 272, "seek": 130824, "start": 1308.24, "end": 1312.88, "text": " BPF loop that basically it's a function that you can call multiple times creating some", "tokens": [40533, 37, 6367, 300, 1936, 309, 311, 257, 2445, 300, 291, 393, 818, 3866, 1413, 4084, 512], "temperature": 0.0, "avg_logprob": -0.1643685131538205, "compression_ratio": 1.6166666666666667, "no_speech_prob": 6.177926843520254e-05}, {"id": 273, "seek": 130824, "start": 1312.88, "end": 1317.44, "text": " sort of loop in BPF, but we cannot use that because we want to support older kernels.", "tokens": [1333, 295, 6367, 294, 40533, 37, 11, 457, 321, 2644, 764, 300, 570, 321, 528, 281, 1406, 4906, 23434, 1625, 13], "temperature": 0.0, "avg_logprob": -0.1643685131538205, "compression_ratio": 1.6166666666666667, "no_speech_prob": 6.177926843520254e-05}, {"id": 274, "seek": 130824, "start": 1317.44, "end": 1320.68, "text": " That's a pretty new feature.", "tokens": [663, 311, 257, 1238, 777, 4111, 13], "temperature": 0.0, "avg_logprob": -0.1643685131538205, "compression_ratio": 1.6166666666666667, "no_speech_prob": 6.177926843520254e-05}, {"id": 275, "seek": 130824, "start": 1320.68, "end": 1323.72, "text": " So let's switch to something else.", "tokens": [407, 718, 311, 3679, 281, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.1643685131538205, "compression_ratio": 1.6166666666666667, "no_speech_prob": 6.177926843520254e-05}, {"id": 276, "seek": 130824, "start": 1323.72, "end": 1329.96, "text": " We have written our application in user space in Go, and we are a profiler, so we want to", "tokens": [492, 362, 3720, 527, 3861, 294, 4195, 1901, 294, 1037, 11, 293, 321, 366, 257, 1740, 5441, 11, 370, 321, 528, 281], "temperature": 0.0, "avg_logprob": -0.1643685131538205, "compression_ratio": 1.6166666666666667, "no_speech_prob": 6.177926843520254e-05}, {"id": 277, "seek": 130824, "start": 1329.96, "end": 1333.8, "text": " make sure that the overhead we have on your machine is as little as possible.", "tokens": [652, 988, 300, 264, 19922, 321, 362, 322, 428, 3479, 307, 382, 707, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.1643685131538205, "compression_ratio": 1.6166666666666667, "no_speech_prob": 6.177926843520254e-05}, {"id": 278, "seek": 130824, "start": 1333.8, "end": 1337.24, "text": " But unfortunately, many of the Go APIs aren't designed with performance in mind.", "tokens": [583, 7015, 11, 867, 295, 264, 1037, 21445, 3212, 380, 4761, 365, 3389, 294, 1575, 13], "temperature": 0.0, "avg_logprob": -0.1643685131538205, "compression_ratio": 1.6166666666666667, "no_speech_prob": 6.177926843520254e-05}, {"id": 279, "seek": 133724, "start": 1337.24, "end": 1338.24, "text": " I am new to Go.", "tokens": [286, 669, 777, 281, 1037, 13], "temperature": 0.0, "avg_logprob": -0.24239554360648183, "compression_ratio": 1.64, "no_speech_prob": 0.00014518968237098306}, {"id": 280, "seek": 133724, "start": 1338.24, "end": 1342.0, "text": " I didn't know this was like this, and every single time I profiled our profiler, and I", "tokens": [286, 994, 380, 458, 341, 390, 411, 341, 11, 293, 633, 2167, 565, 286, 1740, 7292, 527, 1740, 5441, 11, 293, 286], "temperature": 0.0, "avg_logprob": -0.24239554360648183, "compression_ratio": 1.64, "no_speech_prob": 0.00014518968237098306}, {"id": 281, "seek": 133724, "start": 1342.0, "end": 1345.24, "text": " found these things, I was like, how is this possible?", "tokens": [1352, 613, 721, 11, 286, 390, 411, 11, 577, 307, 341, 1944, 30], "temperature": 0.0, "avg_logprob": -0.24239554360648183, "compression_ratio": 1.64, "no_speech_prob": 0.00014518968237098306}, {"id": 282, "seek": 133724, "start": 1345.24, "end": 1349.52, "text": " But it has the dwarf and elf parsing library in the standard library, which is great, but", "tokens": [583, 309, 575, 264, 35527, 293, 35565, 21156, 278, 6405, 294, 264, 3832, 6405, 11, 597, 307, 869, 11, 457], "temperature": 0.0, "avg_logprob": -0.24239554360648183, "compression_ratio": 1.64, "no_speech_prob": 0.00014518968237098306}, {"id": 283, "seek": 133724, "start": 1349.52, "end": 1355.64, "text": " they are not designed for performance sensitive environments, let's say.", "tokens": [436, 366, 406, 4761, 337, 3389, 9477, 12388, 11, 718, 311, 584, 13], "temperature": 0.0, "avg_logprob": -0.24239554360648183, "compression_ratio": 1.64, "no_speech_prob": 0.00014518968237098306}, {"id": 284, "seek": 133724, "start": 1355.64, "end": 1361.4, "text": " And also, there's two functions that are binary read and binary writes that we use all the", "tokens": [400, 611, 11, 456, 311, 732, 6828, 300, 366, 17434, 1401, 293, 17434, 13657, 300, 321, 764, 439, 264], "temperature": 0.0, "avg_logprob": -0.24239554360648183, "compression_ratio": 1.64, "no_speech_prob": 0.00014518968237098306}, {"id": 285, "seek": 136140, "start": 1361.4, "end": 1367.96, "text": " time because we need to deal with bytes back and forth that allocate in the fast path.", "tokens": [565, 570, 321, 643, 281, 2028, 365, 36088, 646, 293, 5220, 300, 35713, 294, 264, 2370, 3100, 13], "temperature": 0.0, "avg_logprob": -0.14963926852328105, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.00013017060700803995}, {"id": 286, "seek": 136140, "start": 1367.96, "end": 1370.76, "text": " But anyways, we profile our profiler all the time.", "tokens": [583, 13448, 11, 321, 7964, 527, 1740, 5441, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.14963926852328105, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.00013017060700803995}, {"id": 287, "seek": 136140, "start": 1370.76, "end": 1374.48, "text": " We have found lots of opportunities that we keep on fixing, but of course, there's more", "tokens": [492, 362, 1352, 3195, 295, 4786, 300, 321, 1066, 322, 19442, 11, 457, 295, 1164, 11, 456, 311, 544], "temperature": 0.0, "avg_logprob": -0.14963926852328105, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.00013017060700803995}, {"id": 288, "seek": 136140, "start": 1374.48, "end": 1376.64, "text": " work to do.", "tokens": [589, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.14963926852328105, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.00013017060700803995}, {"id": 289, "seek": 136140, "start": 1376.64, "end": 1383.3200000000002, "text": " And one of the areas where we try to be pretty comprehensive, it's with testing.", "tokens": [400, 472, 295, 264, 3179, 689, 321, 853, 281, 312, 1238, 13914, 11, 309, 311, 365, 4997, 13], "temperature": 0.0, "avg_logprob": -0.14963926852328105, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.00013017060700803995}, {"id": 290, "seek": 136140, "start": 1383.3200000000002, "end": 1388.4, "text": " So we have thorough testing for, well, unit testing for most of the core functions to", "tokens": [407, 321, 362, 12934, 4997, 337, 11, 731, 11, 4985, 4997, 337, 881, 295, 264, 4965, 6828, 281], "temperature": 0.0, "avg_logprob": -0.14963926852328105, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.00013017060700803995}, {"id": 291, "seek": 138840, "start": 1388.4, "end": 1392.16, "text": " ensure that we don't regress, but I think that, in my opinion, has helped us the most", "tokens": [5586, 300, 321, 500, 380, 1121, 735, 11, 457, 286, 519, 300, 11, 294, 452, 4800, 11, 575, 4254, 505, 264, 881], "temperature": 0.0, "avg_logprob": -0.12791660660547569, "compression_ratio": 1.7672955974842768, "no_speech_prob": 5.2168103138683364e-05}, {"id": 292, "seek": 138840, "start": 1392.16, "end": 1393.96, "text": " is snapshot testing.", "tokens": [307, 30163, 4997, 13], "temperature": 0.0, "avg_logprob": -0.12791660660547569, "compression_ratio": 1.7672955974842768, "no_speech_prob": 5.2168103138683364e-05}, {"id": 293, "seek": 138840, "start": 1393.96, "end": 1396.6000000000001, "text": " If you're not familiar with this technique, it's very simple.", "tokens": [759, 291, 434, 406, 4963, 365, 341, 6532, 11, 309, 311, 588, 2199, 13], "temperature": 0.0, "avg_logprob": -0.12791660660547569, "compression_ratio": 1.7672955974842768, "no_speech_prob": 5.2168103138683364e-05}, {"id": 294, "seek": 138840, "start": 1396.6000000000001, "end": 1400.68, "text": " You basically generate some textual representation of your data structures, write them to disk", "tokens": [509, 1936, 8460, 512, 2487, 901, 10290, 295, 428, 1412, 9227, 11, 2464, 552, 281, 12355], "temperature": 0.0, "avg_logprob": -0.12791660660547569, "compression_ratio": 1.7672955974842768, "no_speech_prob": 5.2168103138683364e-05}, {"id": 295, "seek": 138840, "start": 1400.68, "end": 1404.24, "text": " or somewhere in memory, it doesn't matter, and then you generate them again after you", "tokens": [420, 4079, 294, 4675, 11, 309, 1177, 380, 1871, 11, 293, 550, 291, 8460, 552, 797, 934, 291], "temperature": 0.0, "avg_logprob": -0.12791660660547569, "compression_ratio": 1.7672955974842768, "no_speech_prob": 5.2168103138683364e-05}, {"id": 296, "seek": 138840, "start": 1404.24, "end": 1407.4, "text": " make some changes to your code, and then you compare them.", "tokens": [652, 512, 2962, 281, 428, 3089, 11, 293, 550, 291, 6794, 552, 13], "temperature": 0.0, "avg_logprob": -0.12791660660547569, "compression_ratio": 1.7672955974842768, "no_speech_prob": 5.2168103138683364e-05}, {"id": 297, "seek": 138840, "start": 1407.4, "end": 1408.72, "text": " So this is how it looks in our case.", "tokens": [407, 341, 307, 577, 309, 1542, 294, 527, 1389, 13], "temperature": 0.0, "avg_logprob": -0.12791660660547569, "compression_ratio": 1.7672955974842768, "no_speech_prob": 5.2168103138683364e-05}, {"id": 298, "seek": 138840, "start": 1408.72, "end": 1413.44, "text": " We have some Git sub repository called test data, and then we have this textual representation", "tokens": [492, 362, 512, 16939, 1422, 25841, 1219, 1500, 1412, 11, 293, 550, 321, 362, 341, 2487, 901, 10290], "temperature": 0.0, "avg_logprob": -0.12791660660547569, "compression_ratio": 1.7672955974842768, "no_speech_prob": 5.2168103138683364e-05}, {"id": 299, "seek": 138840, "start": 1413.44, "end": 1414.44, "text": " of the unwind tables.", "tokens": [295, 264, 517, 12199, 8020, 13], "temperature": 0.0, "avg_logprob": -0.12791660660547569, "compression_ratio": 1.7672955974842768, "no_speech_prob": 5.2168103138683364e-05}, {"id": 300, "seek": 141444, "start": 1414.44, "end": 1419.3200000000002, "text": " You don't have to understand it all, but the idea here is that this covers a full function,", "tokens": [509, 500, 380, 362, 281, 1223, 309, 439, 11, 457, 264, 1558, 510, 307, 300, 341, 10538, 257, 1577, 2445, 11], "temperature": 0.0, "avg_logprob": -0.1250696662518618, "compression_ratio": 1.778877887788779, "no_speech_prob": 9.279145888285711e-05}, {"id": 301, "seek": 141444, "start": 1419.3200000000002, "end": 1423.64, "text": " which program counter starts in the one over there and ends in the one over there.", "tokens": [597, 1461, 5682, 3719, 294, 264, 472, 670, 456, 293, 5314, 294, 264, 472, 670, 456, 13], "temperature": 0.0, "avg_logprob": -0.1250696662518618, "compression_ratio": 1.778877887788779, "no_speech_prob": 9.279145888285711e-05}, {"id": 302, "seek": 141444, "start": 1423.64, "end": 1426.8400000000001, "text": " And then we have the information for every single program counter, and then it tells", "tokens": [400, 550, 321, 362, 264, 1589, 337, 633, 2167, 1461, 5682, 11, 293, 550, 309, 5112], "temperature": 0.0, "avg_logprob": -0.1250696662518618, "compression_ratio": 1.778877887788779, "no_speech_prob": 9.279145888285711e-05}, {"id": 303, "seek": 141444, "start": 1426.8400000000001, "end": 1428.48, "text": " you, for example, what to do here.", "tokens": [291, 11, 337, 1365, 11, 437, 281, 360, 510, 13], "temperature": 0.0, "avg_logprob": -0.1250696662518618, "compression_ratio": 1.778877887788779, "no_speech_prob": 9.279145888285711e-05}, {"id": 304, "seek": 141444, "start": 1428.48, "end": 1431.44, "text": " The first one says CFA type two that I know is for RBP.", "tokens": [440, 700, 472, 1619, 383, 19684, 2010, 732, 300, 286, 458, 307, 337, 40302, 47, 13], "temperature": 0.0, "avg_logprob": -0.1250696662518618, "compression_ratio": 1.778877887788779, "no_speech_prob": 9.279145888285711e-05}, {"id": 305, "seek": 141444, "start": 1431.44, "end": 1436.48, "text": " So you need to get the current RBP at eight, and that will give you the previous frame", "tokens": [407, 291, 643, 281, 483, 264, 2190, 40302, 47, 412, 3180, 11, 293, 300, 486, 976, 291, 264, 3894, 3920], "temperature": 0.0, "avg_logprob": -0.1250696662518618, "compression_ratio": 1.778877887788779, "no_speech_prob": 9.279145888285711e-05}, {"id": 306, "seek": 141444, "start": 1436.48, "end": 1438.16, "text": " stack pointer.", "tokens": [8630, 23918, 13], "temperature": 0.0, "avg_logprob": -0.1250696662518618, "compression_ratio": 1.778877887788779, "no_speech_prob": 9.279145888285711e-05}, {"id": 307, "seek": 141444, "start": 1438.16, "end": 1442.52, "text": " But anyways, the interesting thing here is that this is very easy to implement, as you", "tokens": [583, 13448, 11, 264, 1880, 551, 510, 307, 300, 341, 307, 588, 1858, 281, 4445, 11, 382, 291], "temperature": 0.0, "avg_logprob": -0.1250696662518618, "compression_ratio": 1.778877887788779, "no_speech_prob": 9.279145888285711e-05}, {"id": 308, "seek": 144252, "start": 1442.52, "end": 1446.52, "text": " can see by our very advanced setup in our make file.", "tokens": [393, 536, 538, 527, 588, 7339, 8657, 294, 527, 652, 3991, 13], "temperature": 0.0, "avg_logprob": -0.1402112256299268, "compression_ratio": 1.5887096774193548, "no_speech_prob": 9.998460882343352e-05}, {"id": 309, "seek": 144252, "start": 1446.52, "end": 1450.92, "text": " We just build our binary.", "tokens": [492, 445, 1322, 527, 17434, 13], "temperature": 0.0, "avg_logprob": -0.1402112256299268, "compression_ratio": 1.5887096774193548, "no_speech_prob": 9.998460882343352e-05}, {"id": 310, "seek": 144252, "start": 1450.92, "end": 1456.04, "text": " We dump these tables to disk, and then we ask Git to give us the changes.", "tokens": [492, 11430, 613, 8020, 281, 12355, 11, 293, 550, 321, 1029, 16939, 281, 976, 505, 264, 2962, 13], "temperature": 0.0, "avg_logprob": -0.1402112256299268, "compression_ratio": 1.5887096774193548, "no_speech_prob": 9.998460882343352e-05}, {"id": 311, "seek": 144252, "start": 1456.04, "end": 1459.8, "text": " And if there's anything that has changed, we fail.", "tokens": [400, 498, 456, 311, 1340, 300, 575, 3105, 11, 321, 3061, 13], "temperature": 0.0, "avg_logprob": -0.1402112256299268, "compression_ratio": 1.5887096774193548, "no_speech_prob": 9.998460882343352e-05}, {"id": 312, "seek": 144252, "start": 1459.8, "end": 1464.48, "text": " So thanks to this, we have found a lot of bugs, and it has allowed us to iterate with", "tokens": [407, 3231, 281, 341, 11, 321, 362, 1352, 257, 688, 295, 15120, 11, 293, 309, 575, 4350, 505, 281, 44497, 365], "temperature": 0.0, "avg_logprob": -0.1402112256299268, "compression_ratio": 1.5887096774193548, "no_speech_prob": 9.998460882343352e-05}, {"id": 313, "seek": 144252, "start": 1464.48, "end": 1467.44, "text": " confidence.", "tokens": [6687, 13], "temperature": 0.0, "avg_logprob": -0.1402112256299268, "compression_ratio": 1.5887096774193548, "no_speech_prob": 9.998460882343352e-05}, {"id": 314, "seek": 144252, "start": 1467.44, "end": 1470.68, "text": " One of the important things in this project has been de-risking it.", "tokens": [1485, 295, 264, 1021, 721, 294, 341, 1716, 575, 668, 368, 12, 5714, 5092, 309, 13], "temperature": 0.0, "avg_logprob": -0.1402112256299268, "compression_ratio": 1.5887096774193548, "no_speech_prob": 9.998460882343352e-05}, {"id": 315, "seek": 144252, "start": 1470.68, "end": 1472.28, "text": " It's been quite complex.", "tokens": [467, 311, 668, 1596, 3997, 13], "temperature": 0.0, "avg_logprob": -0.1402112256299268, "compression_ratio": 1.5887096774193548, "no_speech_prob": 9.998460882343352e-05}, {"id": 316, "seek": 147228, "start": 1472.28, "end": 1474.32, "text": " When I started working at this, I had no idea about dwarf unwinding.", "tokens": [1133, 286, 1409, 1364, 412, 341, 11, 286, 632, 572, 1558, 466, 35527, 14853, 9245, 13], "temperature": 0.0, "avg_logprob": -0.13439905729225213, "compression_ratio": 1.7912457912457913, "no_speech_prob": 6.670781294815242e-05}, {"id": 317, "seek": 147228, "start": 1474.32, "end": 1477.76, "text": " I had no idea about unwinding without frame pointers at all.", "tokens": [286, 632, 572, 1558, 466, 14853, 9245, 1553, 3920, 44548, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.13439905729225213, "compression_ratio": 1.7912457912457913, "no_speech_prob": 6.670781294815242e-05}, {"id": 318, "seek": 147228, "start": 1477.76, "end": 1481.24, "text": " So we had to make sure that all these avenues were properly covered.", "tokens": [407, 321, 632, 281, 652, 988, 300, 439, 613, 43039, 645, 6108, 5343, 13], "temperature": 0.0, "avg_logprob": -0.13439905729225213, "compression_ratio": 1.7912457912457913, "no_speech_prob": 6.670781294815242e-05}, {"id": 319, "seek": 147228, "start": 1481.24, "end": 1485.6399999999999, "text": " We had, for example, the dwarf parser properly implemented, that we had all the interactions", "tokens": [492, 632, 11, 337, 1365, 11, 264, 35527, 21156, 260, 6108, 12270, 11, 300, 321, 632, 439, 264, 13280], "temperature": 0.0, "avg_logprob": -0.13439905729225213, "compression_ratio": 1.7912457912457913, "no_speech_prob": 6.670781294815242e-05}, {"id": 320, "seek": 147228, "start": 1485.6399999999999, "end": 1490.24, "text": " with BPF cover, and that the BPF unwinder worked well as well.", "tokens": [365, 40533, 37, 2060, 11, 293, 300, 264, 40533, 37, 14853, 5669, 2732, 731, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.13439905729225213, "compression_ratio": 1.7912457912457913, "no_speech_prob": 6.670781294815242e-05}, {"id": 321, "seek": 147228, "start": 1490.24, "end": 1494.68, "text": " So for this, we always tried to have a plan B at every stage of the project, and we tried", "tokens": [407, 337, 341, 11, 321, 1009, 3031, 281, 362, 257, 1393, 363, 412, 633, 3233, 295, 264, 1716, 11, 293, 321, 3031], "temperature": 0.0, "avg_logprob": -0.13439905729225213, "compression_ratio": 1.7912457912457913, "no_speech_prob": 6.670781294815242e-05}, {"id": 322, "seek": 147228, "start": 1494.68, "end": 1497.8799999999999, "text": " to go in depth as well as in breadth.", "tokens": [281, 352, 294, 7161, 382, 731, 382, 294, 35862, 13], "temperature": 0.0, "avg_logprob": -0.13439905729225213, "compression_ratio": 1.7912457912457913, "no_speech_prob": 6.670781294815242e-05}, {"id": 323, "seek": 147228, "start": 1497.8799999999999, "end": 1499.6, "text": " But anyways, I have five minutes left apparently.", "tokens": [583, 13448, 11, 286, 362, 1732, 2077, 1411, 7970, 13], "temperature": 0.0, "avg_logprob": -0.13439905729225213, "compression_ratio": 1.7912457912457913, "no_speech_prob": 6.670781294815242e-05}, {"id": 324, "seek": 149960, "start": 1499.6, "end": 1503.1599999999999, "text": " So we had a lot of automated testing, and one of the things that we did was adding kernel", "tokens": [407, 321, 632, 257, 688, 295, 18473, 4997, 11, 293, 472, 295, 264, 721, 300, 321, 630, 390, 5127, 28256], "temperature": 0.0, "avg_logprob": -0.1288395181166387, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.363541175844148e-05}, {"id": 325, "seek": 149960, "start": 1503.1599999999999, "end": 1508.0, "text": " tests, which is super important, especially for BPF programs, because the BPF sub-system", "tokens": [6921, 11, 597, 307, 1687, 1021, 11, 2318, 337, 40533, 37, 4268, 11, 570, 264, 40533, 37, 1422, 12, 28215], "temperature": 0.0, "avg_logprob": -0.1288395181166387, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.363541175844148e-05}, {"id": 326, "seek": 149960, "start": 1508.0, "end": 1510.1999999999998, "text": " changes a lot over time.", "tokens": [2962, 257, 688, 670, 565, 13], "temperature": 0.0, "avg_logprob": -0.1288395181166387, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.363541175844148e-05}, {"id": 327, "seek": 149960, "start": 1510.1999999999998, "end": 1513.6399999999999, "text": " And there's a lot of features that we want to make sure we don't use, because otherwise", "tokens": [400, 456, 311, 257, 688, 295, 4122, 300, 321, 528, 281, 652, 988, 321, 500, 380, 764, 11, 570, 5911], "temperature": 0.0, "avg_logprob": -0.1288395181166387, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.363541175844148e-05}, {"id": 328, "seek": 149960, "start": 1513.6399999999999, "end": 1515.76, "text": " it wouldn't work in other kernels.", "tokens": [309, 2759, 380, 589, 294, 661, 23434, 1625, 13], "temperature": 0.0, "avg_logprob": -0.1288395181166387, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.363541175844148e-05}, {"id": 329, "seek": 149960, "start": 1515.76, "end": 1522.1999999999998, "text": " So we have a kernel testing system where basically it runs our application in multiple kernels", "tokens": [407, 321, 362, 257, 28256, 4997, 1185, 689, 1936, 309, 6676, 527, 3861, 294, 3866, 23434, 1625], "temperature": 0.0, "avg_logprob": -0.1288395181166387, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.363541175844148e-05}, {"id": 330, "seek": 149960, "start": 1522.1999999999998, "end": 1526.32, "text": " and reports the state.", "tokens": [293, 7122, 264, 1785, 13], "temperature": 0.0, "avg_logprob": -0.1288395181166387, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.363541175844148e-05}, {"id": 331, "seek": 152632, "start": 1526.32, "end": 1530.12, "text": " And one of the things that I want to talk about is that production, as usual, brings", "tokens": [400, 472, 295, 264, 721, 300, 286, 528, 281, 751, 466, 307, 300, 4265, 11, 382, 7713, 11, 5607], "temperature": 0.0, "avg_logprob": -0.12052653386042668, "compression_ratio": 1.9148936170212767, "no_speech_prob": 4.381976759759709e-05}, {"id": 332, "seek": 152632, "start": 1530.12, "end": 1531.52, "text": " a lot of interesting challenges.", "tokens": [257, 688, 295, 1880, 4759, 13], "temperature": 0.0, "avg_logprob": -0.12052653386042668, "compression_ratio": 1.9148936170212767, "no_speech_prob": 4.381976759759709e-05}, {"id": 333, "seek": 152632, "start": 1531.52, "end": 1534.96, "text": " So by deploying our profiler to production, we found a lot of things that we didn't know", "tokens": [407, 538, 34198, 527, 1740, 5441, 281, 4265, 11, 321, 1352, 257, 688, 295, 721, 300, 321, 994, 380, 458], "temperature": 0.0, "avg_logprob": -0.12052653386042668, "compression_ratio": 1.9148936170212767, "no_speech_prob": 4.381976759759709e-05}, {"id": 334, "seek": 152632, "start": 1534.96, "end": 1535.96, "text": " about.", "tokens": [466, 13], "temperature": 0.0, "avg_logprob": -0.12052653386042668, "compression_ratio": 1.9148936170212767, "no_speech_prob": 4.381976759759709e-05}, {"id": 335, "seek": 152632, "start": 1535.96, "end": 1539.8, "text": " And we were able to find some of these things thanks to using continuous profiling, our", "tokens": [400, 321, 645, 1075, 281, 915, 512, 295, 613, 721, 3231, 281, 1228, 10957, 1740, 4883, 11, 527], "temperature": 0.0, "avg_logprob": -0.12052653386042668, "compression_ratio": 1.9148936170212767, "no_speech_prob": 4.381976759759709e-05}, {"id": 336, "seek": 152632, "start": 1539.8, "end": 1542.04, "text": " own profiler on our profiler.", "tokens": [1065, 1740, 5441, 322, 527, 1740, 5441, 13], "temperature": 0.0, "avg_logprob": -0.12052653386042668, "compression_ratio": 1.9148936170212767, "no_speech_prob": 4.381976759759709e-05}, {"id": 337, "seek": 152632, "start": 1542.04, "end": 1546.4399999999998, "text": " As you know, different hardware and different configuration are the biggest sources of performance", "tokens": [1018, 291, 458, 11, 819, 8837, 293, 819, 11694, 366, 264, 3880, 7139, 295, 3389], "temperature": 0.0, "avg_logprob": -0.12052653386042668, "compression_ratio": 1.9148936170212767, "no_speech_prob": 4.381976759759709e-05}, {"id": 338, "seek": 152632, "start": 1546.4399999999998, "end": 1549.8799999999999, "text": " differences as well as incidents in production.", "tokens": [7300, 382, 731, 382, 21139, 294, 4265, 13], "temperature": 0.0, "avg_logprob": -0.12052653386042668, "compression_ratio": 1.9148936170212767, "no_speech_prob": 4.381976759759709e-05}, {"id": 339, "seek": 152632, "start": 1549.8799999999999, "end": 1552.08, "text": " So I want to show you two things that we have found recently.", "tokens": [407, 286, 528, 281, 855, 291, 732, 721, 300, 321, 362, 1352, 3938, 13], "temperature": 0.0, "avg_logprob": -0.12052653386042668, "compression_ratio": 1.9148936170212767, "no_speech_prob": 4.381976759759709e-05}, {"id": 340, "seek": 155208, "start": 1552.08, "end": 1558.4399999999998, "text": " One of them is basically we're using almost 30% CPU time opening files in our production", "tokens": [1485, 295, 552, 307, 1936, 321, 434, 1228, 1920, 2217, 4, 13199, 565, 5193, 7098, 294, 527, 4265], "temperature": 0.0, "avg_logprob": -0.15530996155320553, "compression_ratio": 1.6219931271477663, "no_speech_prob": 0.00010994628974003717}, {"id": 341, "seek": 155208, "start": 1558.4399999999998, "end": 1561.52, "text": " environments that never showed up on my NVMe.", "tokens": [12388, 300, 1128, 4712, 493, 322, 452, 46512, 12671, 13], "temperature": 0.0, "avg_logprob": -0.15530996155320553, "compression_ratio": 1.6219931271477663, "no_speech_prob": 0.00010994628974003717}, {"id": 342, "seek": 155208, "start": 1561.52, "end": 1566.1999999999998, "text": " And the reason is because, turns out, cloud disks are very slow.", "tokens": [400, 264, 1778, 307, 570, 11, 4523, 484, 11, 4588, 41617, 366, 588, 2964, 13], "temperature": 0.0, "avg_logprob": -0.15530996155320553, "compression_ratio": 1.6219931271477663, "no_speech_prob": 0.00010994628974003717}, {"id": 343, "seek": 155208, "start": 1566.1999999999998, "end": 1570.08, "text": " So we have fixed this.", "tokens": [407, 321, 362, 6806, 341, 13], "temperature": 0.0, "avg_logprob": -0.15530996155320553, "compression_ratio": 1.6219931271477663, "no_speech_prob": 0.00010994628974003717}, {"id": 344, "seek": 155208, "start": 1570.08, "end": 1573.96, "text": " Another very interesting thing that we fixed the other day, it's something that happened", "tokens": [3996, 588, 1880, 551, 300, 321, 6806, 264, 661, 786, 11, 309, 311, 746, 300, 2011], "temperature": 0.0, "avg_logprob": -0.15530996155320553, "compression_ratio": 1.6219931271477663, "no_speech_prob": 0.00010994628974003717}, {"id": 345, "seek": 155208, "start": 1573.96, "end": 1578.08, "text": " when we rolled our profiler to production and then it started crashing.", "tokens": [562, 321, 14306, 527, 1740, 5441, 281, 4265, 293, 550, 309, 1409, 26900, 13], "temperature": 0.0, "avg_logprob": -0.15530996155320553, "compression_ratio": 1.6219931271477663, "no_speech_prob": 0.00010994628974003717}, {"id": 346, "seek": 155208, "start": 1578.08, "end": 1581.32, "text": " If you are interested, we will upload the slides, so feel free to check the pull request", "tokens": [759, 291, 366, 3102, 11, 321, 486, 6580, 264, 9788, 11, 370, 841, 1737, 281, 1520, 264, 2235, 5308], "temperature": 0.0, "avg_logprob": -0.15530996155320553, "compression_ratio": 1.6219931271477663, "no_speech_prob": 0.00010994628974003717}, {"id": 347, "seek": 158132, "start": 1581.32, "end": 1582.76, "text": " because everything is open source.", "tokens": [570, 1203, 307, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.19365077722268026, "compression_ratio": 1.7123287671232876, "no_speech_prob": 9.395313827553764e-05}, {"id": 348, "seek": 158132, "start": 1582.76, "end": 1587.12, "text": " But basically what happened here was that, for reasons, Go has a signal-based profiler", "tokens": [583, 1936, 437, 2011, 510, 390, 300, 11, 337, 4112, 11, 1037, 575, 257, 6358, 12, 6032, 1740, 5441], "temperature": 0.0, "avg_logprob": -0.19365077722268026, "compression_ratio": 1.7123287671232876, "no_speech_prob": 9.395313827553764e-05}, {"id": 349, "seek": 158132, "start": 1587.12, "end": 1589.6799999999998, "text": " and we have it enabled for even more reasons.", "tokens": [293, 321, 362, 309, 15172, 337, 754, 544, 4112, 13], "temperature": 0.0, "avg_logprob": -0.19365077722268026, "compression_ratio": 1.7123287671232876, "no_speech_prob": 9.395313827553764e-05}, {"id": 350, "seek": 158132, "start": 1589.6799999999998, "end": 1592.24, "text": " And this only was enabled in production.", "tokens": [400, 341, 787, 390, 15172, 294, 4265, 13], "temperature": 0.0, "avg_logprob": -0.19365077722268026, "compression_ratio": 1.7123287671232876, "no_speech_prob": 9.395313827553764e-05}, {"id": 351, "seek": 158132, "start": 1592.24, "end": 1599.32, "text": " So SIGPROV was interrupting our program execution while we were trying to load the BPF program.", "tokens": [407, 318, 10489, 47, 7142, 53, 390, 49455, 527, 1461, 15058, 1339, 321, 645, 1382, 281, 3677, 264, 40533, 37, 1461, 13], "temperature": 0.0, "avg_logprob": -0.19365077722268026, "compression_ratio": 1.7123287671232876, "no_speech_prob": 9.395313827553764e-05}, {"id": 352, "seek": 158132, "start": 1599.32, "end": 1602.72, "text": " The BPF program takes a little while to load because the verifier has to run a bunch of", "tokens": [440, 40533, 37, 1461, 2516, 257, 707, 1339, 281, 3677, 570, 264, 1306, 9902, 575, 281, 1190, 257, 3840, 295], "temperature": 0.0, "avg_logprob": -0.19365077722268026, "compression_ratio": 1.7123287671232876, "no_speech_prob": 9.395313827553764e-05}, {"id": 353, "seek": 158132, "start": 1602.72, "end": 1608.1599999999999, "text": " algorithms to start to actually ensure that everything is safe and it was getting interrupted", "tokens": [14642, 281, 722, 281, 767, 5586, 300, 1203, 307, 3273, 293, 309, 390, 1242, 30329], "temperature": 0.0, "avg_logprob": -0.19365077722268026, "compression_ratio": 1.7123287671232876, "no_speech_prob": 9.395313827553764e-05}, {"id": 354, "seek": 158132, "start": 1608.1599999999999, "end": 1609.1599999999999, "text": " all the time.", "tokens": [439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.19365077722268026, "compression_ratio": 1.7123287671232876, "no_speech_prob": 9.395313827553764e-05}, {"id": 355, "seek": 160916, "start": 1609.16, "end": 1612.76, "text": " The BPF, that is the BPF library we used to load the BPF program, was retrying this up", "tokens": [440, 40533, 37, 11, 300, 307, 264, 40533, 37, 6405, 321, 1143, 281, 3677, 264, 40533, 37, 1461, 11, 390, 1533, 19076, 341, 493], "temperature": 0.0, "avg_logprob": -0.20590674301673625, "compression_ratio": 1.7006172839506173, "no_speech_prob": 0.00022212541080079973}, {"id": 356, "seek": 160916, "start": 1612.76, "end": 1617.96, "text": " to five times until it basically said, I tried, this didn't work, sorry, and obviously we", "tokens": [281, 1732, 1413, 1826, 309, 1936, 848, 11, 286, 3031, 11, 341, 994, 380, 589, 11, 2597, 11, 293, 2745, 321], "temperature": 0.0, "avg_logprob": -0.20590674301673625, "compression_ratio": 1.7006172839506173, "no_speech_prob": 0.00022212541080079973}, {"id": 357, "seek": 160916, "start": 1617.96, "end": 1621.44, "text": " need the BPF program to be loaded to work.", "tokens": [643, 264, 40533, 37, 1461, 281, 312, 13210, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.20590674301673625, "compression_ratio": 1.7006172839506173, "no_speech_prob": 0.00022212541080079973}, {"id": 358, "seek": 160916, "start": 1621.44, "end": 1625.5600000000002, "text": " So there's many other considerations in this project, like short-lived processes, which", "tokens": [407, 456, 311, 867, 661, 24070, 294, 341, 1716, 11, 411, 2099, 12, 46554, 7555, 11, 597], "temperature": 0.0, "avg_logprob": -0.20590674301673625, "compression_ratio": 1.7006172839506173, "no_speech_prob": 0.00022212541080079973}, {"id": 359, "seek": 160916, "start": 1625.5600000000002, "end": 1629.1200000000001, "text": " we haven't optimized for, but we are still pretty decent ads.", "tokens": [321, 2378, 380, 26941, 337, 11, 457, 321, 366, 920, 1238, 8681, 10342, 13], "temperature": 0.0, "avg_logprob": -0.20590674301673625, "compression_ratio": 1.7006172839506173, "no_speech_prob": 0.00022212541080079973}, {"id": 360, "seek": 160916, "start": 1629.1200000000001, "end": 1633.48, "text": " If your program runs for one second, we're probably going to catch it, but if this is", "tokens": [759, 428, 1461, 6676, 337, 472, 1150, 11, 321, 434, 1391, 516, 281, 3745, 309, 11, 457, 498, 341, 307], "temperature": 0.0, "avg_logprob": -0.20590674301673625, "compression_ratio": 1.7006172839506173, "no_speech_prob": 0.00022212541080079973}, {"id": 361, "seek": 160916, "start": 1633.48, "end": 1635.64, "text": " something that you care about, feel free to message us.", "tokens": [746, 300, 291, 1127, 466, 11, 841, 1737, 281, 3636, 505, 13], "temperature": 0.0, "avg_logprob": -0.20590674301673625, "compression_ratio": 1.7006172839506173, "no_speech_prob": 0.00022212541080079973}, {"id": 362, "seek": 160916, "start": 1635.64, "end": 1637.8000000000002, "text": " It will be something that we optimized.", "tokens": [467, 486, 312, 746, 300, 321, 26941, 13], "temperature": 0.0, "avg_logprob": -0.20590674301673625, "compression_ratio": 1.7006172839506173, "no_speech_prob": 0.00022212541080079973}, {"id": 363, "seek": 163780, "start": 1637.8, "end": 1642.0, "text": " And then, yeah, this is our current format, I probably have one minute left or something", "tokens": [400, 550, 11, 1338, 11, 341, 307, 527, 2190, 7877, 11, 286, 1391, 362, 472, 3456, 1411, 420, 746], "temperature": 0.0, "avg_logprob": -0.17234536951238458, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00024185267102438956}, {"id": 364, "seek": 163780, "start": 1642.0, "end": 1643.0, "text": " like that.", "tokens": [411, 300, 13], "temperature": 0.0, "avg_logprob": -0.17234536951238458, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00024185267102438956}, {"id": 365, "seek": 163780, "start": 1643.0, "end": 1646.0, "text": " So you don't have to understand it all, but the point is we represent every single row", "tokens": [407, 291, 500, 380, 362, 281, 1223, 309, 439, 11, 457, 264, 935, 307, 321, 2906, 633, 2167, 5386], "temperature": 0.0, "avg_logprob": -0.17234536951238458, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00024185267102438956}, {"id": 366, "seek": 163780, "start": 1646.0, "end": 1653.44, "text": " with 264-bit words, but since we are making it a bit smaller, and this is basically how", "tokens": [365, 7551, 19, 12, 5260, 2283, 11, 457, 1670, 321, 366, 1455, 309, 257, 857, 4356, 11, 293, 341, 307, 1936, 577], "temperature": 0.0, "avg_logprob": -0.17234536951238458, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00024185267102438956}, {"id": 367, "seek": 163780, "start": 1653.44, "end": 1655.44, "text": " our size compares to dwarf.", "tokens": [527, 2744, 38334, 281, 35527, 13], "temperature": 0.0, "avg_logprob": -0.17234536951238458, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00024185267102438956}, {"id": 368, "seek": 163780, "start": 1655.44, "end": 1660.52, "text": " We are bigger because dwarf is optimized for disk while we are optimized for disk space", "tokens": [492, 366, 3801, 570, 35527, 307, 26941, 337, 12355, 1339, 321, 366, 26941, 337, 12355, 1901], "temperature": 0.0, "avg_logprob": -0.17234536951238458, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00024185267102438956}, {"id": 369, "seek": 163780, "start": 1660.52, "end": 1662.8, "text": " while we are optimized for just raw speeds.", "tokens": [1339, 321, 366, 26941, 337, 445, 8936, 16411, 13], "temperature": 0.0, "avg_logprob": -0.17234536951238458, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.00024185267102438956}, {"id": 370, "seek": 166280, "start": 1662.8, "end": 1670.9199999999998, "text": " So for example, our whole table for one shard pretty much fits in L2 cache.", "tokens": [407, 337, 1365, 11, 527, 1379, 3199, 337, 472, 402, 515, 1238, 709, 9001, 294, 441, 17, 19459, 13], "temperature": 0.0, "avg_logprob": -0.21295402163550967, "compression_ratio": 1.5224489795918368, "no_speech_prob": 0.00026065754354931414}, {"id": 371, "seek": 166280, "start": 1670.9199999999998, "end": 1674.12, "text": " I guess, do I have any more time, or probably not, right?", "tokens": [286, 2041, 11, 360, 286, 362, 604, 544, 565, 11, 420, 1391, 406, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21295402163550967, "compression_ratio": 1.5224489795918368, "no_speech_prob": 0.00026065754354931414}, {"id": 372, "seek": 166280, "start": 1674.12, "end": 1678.08, "text": " Two minutes, oh, okay, sorry, maybe I sped up too much.", "tokens": [4453, 2077, 11, 1954, 11, 1392, 11, 2597, 11, 1310, 286, 637, 292, 493, 886, 709, 13], "temperature": 0.0, "avg_logprob": -0.21295402163550967, "compression_ratio": 1.5224489795918368, "no_speech_prob": 0.00026065754354931414}, {"id": 373, "seek": 166280, "start": 1678.08, "end": 1684.24, "text": " So we need to support parsing every single dwarf CFI opcodes, and the reason for this", "tokens": [407, 321, 643, 281, 1406, 21156, 278, 633, 2167, 35527, 383, 38568, 999, 66, 4789, 11, 293, 264, 1778, 337, 341], "temperature": 0.0, "avg_logprob": -0.21295402163550967, "compression_ratio": 1.5224489795918368, "no_speech_prob": 0.00026065754354931414}, {"id": 374, "seek": 166280, "start": 1684.24, "end": 1691.08, "text": " is because otherwise we won't be able to progress, but we cannot unwind from every single program", "tokens": [307, 570, 5911, 321, 1582, 380, 312, 1075, 281, 4205, 11, 457, 321, 2644, 517, 12199, 490, 633, 2167, 1461], "temperature": 0.0, "avg_logprob": -0.21295402163550967, "compression_ratio": 1.5224489795918368, "no_speech_prob": 0.00026065754354931414}, {"id": 375, "seek": 169108, "start": 1691.08, "end": 1693.4399999999998, "text": " counter, which sucks.", "tokens": [5682, 11, 597, 15846, 13], "temperature": 0.0, "avg_logprob": -0.11776262521743774, "compression_ratio": 1.7482758620689656, "no_speech_prob": 0.00011720493057509884}, {"id": 376, "seek": 169108, "start": 1693.4399999999998, "end": 1695.3999999999999, "text": " But this is not a problem in practice.", "tokens": [583, 341, 307, 406, 257, 1154, 294, 3124, 13], "temperature": 0.0, "avg_logprob": -0.11776262521743774, "compression_ratio": 1.7482758620689656, "no_speech_prob": 0.00011720493057509884}, {"id": 377, "seek": 169108, "start": 1695.3999999999999, "end": 1700.04, "text": " The reason for this is because the most typical way to recover the previous frame stack pointer", "tokens": [440, 1778, 337, 341, 307, 570, 264, 881, 7476, 636, 281, 8114, 264, 3894, 3920, 8630, 23918], "temperature": 0.0, "avg_logprob": -0.11776262521743774, "compression_ratio": 1.7482758620689656, "no_speech_prob": 0.00011720493057509884}, {"id": 378, "seek": 169108, "start": 1700.04, "end": 1705.8, "text": " is, which is called CFA in dwarf, but doesn't matter, is that you will get given which register", "tokens": [307, 11, 597, 307, 1219, 383, 19684, 294, 35527, 11, 457, 1177, 380, 1871, 11, 307, 300, 291, 486, 483, 2212, 597, 7280], "temperature": 0.0, "avg_logprob": -0.11776262521743774, "compression_ratio": 1.7482758620689656, "no_speech_prob": 0.00011720493057509884}, {"id": 379, "seek": 169108, "start": 1705.8, "end": 1710.9199999999998, "text": " you need to apply some offset to, and that will give you the previous frame stack pointer.", "tokens": [291, 643, 281, 3079, 512, 18687, 281, 11, 293, 300, 486, 976, 291, 264, 3894, 3920, 8630, 23918, 13], "temperature": 0.0, "avg_logprob": -0.11776262521743774, "compression_ratio": 1.7482758620689656, "no_speech_prob": 0.00011720493057509884}, {"id": 380, "seek": 169108, "start": 1710.9199999999998, "end": 1714.6399999999999, "text": " We support that, but the problem is that it could be any arbitrary register, and right", "tokens": [492, 1406, 300, 11, 457, 264, 1154, 307, 300, 309, 727, 312, 604, 23211, 7280, 11, 293, 558], "temperature": 0.0, "avg_logprob": -0.11776262521743774, "compression_ratio": 1.7482758620689656, "no_speech_prob": 0.00011720493057509884}, {"id": 381, "seek": 169108, "start": 1714.6399999999999, "end": 1719.4399999999998, "text": " now we only support either RBP or RSP offsets, which happen 99% of the time.", "tokens": [586, 321, 787, 1406, 2139, 40302, 47, 420, 25855, 47, 39457, 1385, 11, 597, 1051, 11803, 4, 295, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.11776262521743774, "compression_ratio": 1.7482758620689656, "no_speech_prob": 0.00011720493057509884}, {"id": 382, "seek": 171944, "start": 1719.44, "end": 1721.4, "text": " So this is something that we're going to work on soon.", "tokens": [407, 341, 307, 746, 300, 321, 434, 516, 281, 589, 322, 2321, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 383, "seek": 171944, "start": 1721.4, "end": 1726.1200000000001, "text": " The other problem, as Vishali said before, is that dwarf has a VM that you need to implement,", "tokens": [440, 661, 1154, 11, 382, 36752, 5103, 848, 949, 11, 307, 300, 35527, 575, 257, 18038, 300, 291, 643, 281, 4445, 11], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 384, "seek": 171944, "start": 1726.1200000000001, "end": 1730.0, "text": " which has to be Turing-complete, and can implement any expression.", "tokens": [597, 575, 281, 312, 314, 1345, 12, 1112, 17220, 11, 293, 393, 4445, 604, 6114, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 385, "seek": 171944, "start": 1730.0, "end": 1732.44, "text": " It's not Turing-complete.", "tokens": [467, 311, 406, 314, 1345, 12, 1112, 17220, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 386, "seek": 171944, "start": 1732.44, "end": 1733.44, "text": " The second level, yeah.", "tokens": [440, 1150, 1496, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 387, "seek": 171944, "start": 1733.44, "end": 1734.44, "text": " The dwarf?", "tokens": [440, 35527, 30], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 388, "seek": 171944, "start": 1734.44, "end": 1735.44, "text": " No.", "tokens": [883, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 389, "seek": 171944, "start": 1735.44, "end": 1740.44, "text": " That's why in the infinity project they had to add this new opcode in the draft hat.", "tokens": [663, 311, 983, 294, 264, 13202, 1716, 436, 632, 281, 909, 341, 777, 999, 22332, 294, 264, 11206, 2385, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 390, "seek": 171944, "start": 1740.44, "end": 1741.44, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 391, "seek": 171944, "start": 1741.44, "end": 1743.44, "text": " It's not exactly Turing-complete, it's almost there, yeah.", "tokens": [467, 311, 406, 2293, 314, 1345, 12, 1112, 17220, 11, 309, 311, 1920, 456, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 392, "seek": 171944, "start": 1743.44, "end": 1744.44, "text": " Okay, well.", "tokens": [1033, 11, 731, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 393, "seek": 171944, "start": 1744.44, "end": 1748.68, "text": " But you need to implement a VM that basically has a set of virtual registers.", "tokens": [583, 291, 643, 281, 4445, 257, 18038, 300, 1936, 575, 257, 992, 295, 6374, 38351, 13], "temperature": 0.0, "avg_logprob": -0.29264078384790665, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0007553647155873477}, {"id": 394, "seek": 174868, "start": 1748.68, "end": 1749.68, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 395, "seek": 174868, "start": 1749.68, "end": 1753.8, "text": " But the second, well, we're going to talk about those later, because the first level, yeah,", "tokens": [583, 264, 1150, 11, 731, 11, 321, 434, 516, 281, 751, 466, 729, 1780, 11, 570, 264, 700, 1496, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 396, "seek": 174868, "start": 1753.8, "end": 1757.0, "text": " it's the stack machine 100%, but the second level is, I can show you our code, it's messed", "tokens": [309, 311, 264, 8630, 3479, 2319, 8923, 457, 264, 1150, 1496, 307, 11, 286, 393, 855, 291, 527, 3089, 11, 309, 311, 16507], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 397, "seek": 174868, "start": 1757.0, "end": 1758.0, "text": " up.", "tokens": [493, 13], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 398, "seek": 174868, "start": 1758.0, "end": 1760.72, "text": " It's messed up.", "tokens": [467, 311, 16507, 493, 13], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 399, "seek": 174868, "start": 1760.72, "end": 1764.5600000000002, "text": " But anyways, but the thing is that we are very lucky here, and you can check more about", "tokens": [583, 13448, 11, 457, 264, 551, 307, 300, 321, 366, 588, 6356, 510, 11, 293, 291, 393, 1520, 544, 466], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 400, "seek": 174868, "start": 1764.5600000000002, "end": 1766.48, "text": " this in this PR.", "tokens": [341, 294, 341, 11568, 13], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 401, "seek": 174868, "start": 1766.48, "end": 1770.2, "text": " So there's two dwarf expressions that account for 50% of all the expressions that we have", "tokens": [407, 456, 311, 732, 35527, 15277, 300, 2696, 337, 2625, 4, 295, 439, 264, 15277, 300, 321, 362], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 402, "seek": 174868, "start": 1770.2, "end": 1772.28, "text": " seen in most distributions.", "tokens": [1612, 294, 881, 37870, 13], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 403, "seek": 174868, "start": 1772.28, "end": 1778.16, "text": " They are the expressions used by, well, the dynamic linker needs some, basically, and they", "tokens": [814, 366, 264, 15277, 1143, 538, 11, 731, 11, 264, 8546, 2113, 260, 2203, 512, 11, 1936, 11, 293, 436], "temperature": 0.0, "avg_logprob": -0.2146909104453193, "compression_ratio": 1.74, "no_speech_prob": 0.0001866253005573526}, {"id": 404, "seek": 177816, "start": 1778.16, "end": 1782.96, "text": " are the expressions for procedure linkage tables or PLTs.", "tokens": [366, 264, 15277, 337, 10747, 49118, 8020, 420, 6999, 33424, 13], "temperature": 0.0, "avg_logprob": -0.3152691180889423, "compression_ratio": 1.57439446366782, "no_speech_prob": 0.0006771066691726446}, {"id": 405, "seek": 177816, "start": 1782.96, "end": 1786.88, "text": " The other good news, as I said before, is that RBP and RSP offsets rarely occur, and", "tokens": [440, 661, 665, 2583, 11, 382, 286, 848, 949, 11, 307, 300, 40302, 47, 293, 25855, 47, 39457, 1385, 13752, 5160, 11, 293], "temperature": 0.0, "avg_logprob": -0.3152691180889423, "compression_ratio": 1.57439446366782, "no_speech_prob": 0.0006771066691726446}, {"id": 406, "seek": 177816, "start": 1786.88, "end": 1790.16, "text": " all the other possibilities that I haven't talked about, they almost never occur.", "tokens": [439, 264, 661, 12178, 300, 286, 2378, 380, 2825, 466, 11, 436, 1920, 1128, 5160, 13], "temperature": 0.0, "avg_logprob": -0.3152691180889423, "compression_ratio": 1.57439446366782, "no_speech_prob": 0.0006771066691726446}, {"id": 407, "seek": 177816, "start": 1790.16, "end": 1793.16, "text": " Like, we've seen them very, very, very few times.", "tokens": [1743, 11, 321, 600, 1612, 552, 588, 11, 588, 11, 588, 1326, 1413, 13], "temperature": 0.0, "avg_logprob": -0.3152691180889423, "compression_ratio": 1.57439446366782, "no_speech_prob": 0.0006771066691726446}, {"id": 408, "seek": 177816, "start": 1793.16, "end": 1794.16, "text": " The indexes are useful.", "tokens": [440, 8186, 279, 366, 4420, 13], "temperature": 0.0, "avg_logprob": -0.3152691180889423, "compression_ratio": 1.57439446366782, "no_speech_prob": 0.0006771066691726446}, {"id": 409, "seek": 177816, "start": 1794.16, "end": 1795.16, "text": " Oh, good question.", "tokens": [876, 11, 665, 1168, 13], "temperature": 0.0, "avg_logprob": -0.3152691180889423, "compression_ratio": 1.57439446366782, "no_speech_prob": 0.0006771066691726446}, {"id": 410, "seek": 177816, "start": 1795.16, "end": 1796.16, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.3152691180889423, "compression_ratio": 1.57439446366782, "no_speech_prob": 0.0006771066691726446}, {"id": 411, "seek": 177816, "start": 1796.16, "end": 1801.16, "text": " We're playing with AR64, because the GCC has 64 backend generates CFA expressions.", "tokens": [492, 434, 2433, 365, 8943, 19395, 11, 570, 264, 460, 11717, 575, 12145, 38087, 23815, 383, 19684, 15277, 13], "temperature": 0.0, "avg_logprob": -0.3152691180889423, "compression_ratio": 1.57439446366782, "no_speech_prob": 0.0006771066691726446}, {"id": 412, "seek": 177816, "start": 1801.16, "end": 1804.64, "text": " That's what I was talking about, yeah, yeah, yeah.", "tokens": [663, 311, 437, 286, 390, 1417, 466, 11, 1338, 11, 1338, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.3152691180889423, "compression_ratio": 1.57439446366782, "no_speech_prob": 0.0006771066691726446}, {"id": 413, "seek": 180464, "start": 1804.64, "end": 1809.24, "text": " So but right now we only support X64, but I'm also going to talk about this later, sorry.", "tokens": [407, 457, 558, 586, 321, 787, 1406, 1783, 19395, 11, 457, 286, 478, 611, 516, 281, 751, 466, 341, 1780, 11, 2597, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 414, "seek": 180464, "start": 1809.24, "end": 1810.24, "text": " But anyways.", "tokens": [583, 13448, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 415, "seek": 180464, "start": 1810.24, "end": 1811.24, "text": " We don't know.", "tokens": [492, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 416, "seek": 180464, "start": 1811.24, "end": 1812.24, "text": " Oh.", "tokens": [876, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 417, "seek": 180464, "start": 1812.24, "end": 1813.24, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 418, "seek": 180464, "start": 1813.24, "end": 1814.24, "text": " Done.", "tokens": [18658, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 419, "seek": 180464, "start": 1814.24, "end": 1815.24, "text": " Okay, well.", "tokens": [1033, 11, 731, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 420, "seek": 180464, "start": 1815.24, "end": 1817.24, "text": " But we have the minutes buffer for the next one, right?", "tokens": [583, 321, 362, 264, 2077, 21762, 337, 264, 958, 472, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 421, "seek": 180464, "start": 1817.24, "end": 1818.24, "text": " Five minutes.", "tokens": [9436, 2077, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 422, "seek": 180464, "start": 1818.24, "end": 1819.24, "text": " Five minutes.", "tokens": [9436, 2077, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 423, "seek": 180464, "start": 1819.24, "end": 1820.24, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 424, "seek": 180464, "start": 1820.24, "end": 1821.24, "text": " I have two more slides.", "tokens": [286, 362, 732, 544, 9788, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 425, "seek": 180464, "start": 1821.24, "end": 1824.8400000000001, "text": " Well, anyways, our BPR program, we tried to make it as fast as possible.", "tokens": [1042, 11, 13448, 11, 527, 363, 15958, 1461, 11, 321, 3031, 281, 652, 309, 382, 2370, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 426, "seek": 180464, "start": 1824.8400000000001, "end": 1829.5200000000002, "text": " So this was running on my machine with a bunch of applications that have 90 frames or more.", "tokens": [407, 341, 390, 2614, 322, 452, 3479, 365, 257, 3840, 295, 5821, 300, 362, 4289, 12083, 420, 544, 13], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 427, "seek": 180464, "start": 1829.5200000000002, "end": 1833.72, "text": " So even the maximum time that it takes is 0.5 milliseconds, which is not terrible on", "tokens": [407, 754, 264, 6674, 565, 300, 309, 2516, 307, 1958, 13, 20, 34184, 11, 597, 307, 406, 6237, 322], "temperature": 0.0, "avg_logprob": -0.22919294029284434, "compression_ratio": 1.60062893081761, "no_speech_prob": 0.00018203990475740284}, {"id": 428, "seek": 183372, "start": 1833.72, "end": 1839.28, "text": " my CPU, which is from late 2017.", "tokens": [452, 13199, 11, 597, 307, 490, 3469, 6591, 13], "temperature": 0.0, "avg_logprob": -0.16399720863059716, "compression_ratio": 1.5752895752895753, "no_speech_prob": 0.0001245359453605488}, {"id": 429, "seek": 183372, "start": 1839.28, "end": 1843.68, "text": " And this is in a big part because we have optimized everything for memory.", "tokens": [400, 341, 307, 294, 257, 955, 644, 570, 321, 362, 26941, 1203, 337, 4675, 13], "temperature": 0.0, "avg_logprob": -0.16399720863059716, "compression_ratio": 1.5752895752895753, "no_speech_prob": 0.0001245359453605488}, {"id": 430, "seek": 183372, "start": 1843.68, "end": 1847.32, "text": " So everything's aligned properly.", "tokens": [407, 1203, 311, 17962, 6108, 13], "temperature": 0.0, "avg_logprob": -0.16399720863059716, "compression_ratio": 1.5752895752895753, "no_speech_prob": 0.0001245359453605488}, {"id": 431, "seek": 183372, "start": 1847.32, "end": 1854.24, "text": " And we try to fit as many things as possible in the CPU cache.", "tokens": [400, 321, 853, 281, 3318, 382, 867, 721, 382, 1944, 294, 264, 13199, 19459, 13], "temperature": 0.0, "avg_logprob": -0.16399720863059716, "compression_ratio": 1.5752895752895753, "no_speech_prob": 0.0001245359453605488}, {"id": 432, "seek": 183372, "start": 1854.24, "end": 1855.24, "text": " What about high level languages?", "tokens": [708, 466, 1090, 1496, 8650, 30], "temperature": 0.0, "avg_logprob": -0.16399720863059716, "compression_ratio": 1.5752895752895753, "no_speech_prob": 0.0001245359453605488}, {"id": 433, "seek": 183372, "start": 1855.24, "end": 1859.0, "text": " So there's a project that I happen to work on, which is called RB Perf.", "tokens": [407, 456, 311, 257, 1716, 300, 286, 1051, 281, 589, 322, 11, 597, 307, 1219, 40302, 3026, 69, 13], "temperature": 0.0, "avg_logprob": -0.16399720863059716, "compression_ratio": 1.5752895752895753, "no_speech_prob": 0.0001245359453605488}, {"id": 434, "seek": 183372, "start": 1859.0, "end": 1862.04, "text": " So this is something that we're going to be adding in the future, basically for dynamic", "tokens": [407, 341, 307, 746, 300, 321, 434, 516, 281, 312, 5127, 294, 264, 2027, 11, 1936, 337, 8546], "temperature": 0.0, "avg_logprob": -0.16399720863059716, "compression_ratio": 1.5752895752895753, "no_speech_prob": 0.0001245359453605488}, {"id": 435, "seek": 183372, "start": 1862.04, "end": 1863.04, "text": " languages.", "tokens": [8650, 13], "temperature": 0.0, "avg_logprob": -0.16399720863059716, "compression_ratio": 1.5752895752895753, "no_speech_prob": 0.0001245359453605488}, {"id": 436, "seek": 186304, "start": 1863.04, "end": 1865.8, "text": " You have the knowledge of the ABI of every interpreter version.", "tokens": [509, 362, 264, 3601, 295, 264, 316, 11291, 295, 633, 34132, 3037, 13], "temperature": 0.0, "avg_logprob": -0.22340833602413054, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.00012114895798731595}, {"id": 437, "seek": 186304, "start": 1865.8, "end": 1867.8799999999999, "text": " And then the Stackwalker is also implemented in BPF.", "tokens": [400, 550, 264, 37649, 38980, 307, 611, 12270, 294, 40533, 37, 13], "temperature": 0.0, "avg_logprob": -0.22340833602413054, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.00012114895798731595}, {"id": 438, "seek": 186304, "start": 1867.8799999999999, "end": 1871.44, "text": " But instead of getting the return addresses, because you have no return addresses there", "tokens": [583, 2602, 295, 1242, 264, 2736, 16862, 11, 570, 291, 362, 572, 2736, 16862, 456], "temperature": 0.0, "avg_logprob": -0.22340833602413054, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.00012114895798731595}, {"id": 439, "seek": 186304, "start": 1871.44, "end": 1875.96, "text": " that are meaningful to you, you have to directly extract the function names and other information", "tokens": [300, 366, 10995, 281, 291, 11, 291, 362, 281, 3838, 8947, 264, 2445, 5288, 293, 661, 1589], "temperature": 0.0, "avg_logprob": -0.22340833602413054, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.00012114895798731595}, {"id": 440, "seek": 186304, "start": 1875.96, "end": 1880.1599999999999, "text": " of the process heap.", "tokens": [295, 264, 1399, 33591, 13], "temperature": 0.0, "avg_logprob": -0.22340833602413054, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.00012114895798731595}, {"id": 441, "seek": 186304, "start": 1880.1599999999999, "end": 1881.52, "text": " Our project is called PARCA.", "tokens": [2621, 1716, 307, 1219, 21720, 15515, 13], "temperature": 0.0, "avg_logprob": -0.22340833602413054, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.00012114895798731595}, {"id": 442, "seek": 186304, "start": 1881.52, "end": 1884.48, "text": " So there's a couple of things that we're going to be doing, like mix and why mode, that as", "tokens": [407, 456, 311, 257, 1916, 295, 721, 300, 321, 434, 516, 281, 312, 884, 11, 411, 2890, 293, 983, 4391, 11, 300, 382], "temperature": 0.0, "avg_logprob": -0.22340833602413054, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.00012114895798731595}, {"id": 443, "seek": 186304, "start": 1884.48, "end": 1889.0, "text": " far as we know, no one else does this in profiling, in the baggers for sure, but not in profiling,", "tokens": [1400, 382, 321, 458, 11, 572, 472, 1646, 775, 341, 294, 1740, 4883, 11, 294, 264, 3411, 9458, 337, 988, 11, 457, 406, 294, 1740, 4883, 11], "temperature": 0.0, "avg_logprob": -0.22340833602413054, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.00012114895798731595}, {"id": 444, "seek": 186304, "start": 1889.0, "end": 1892.44, "text": " which is the idea of that different sections will be on wants using different techniques.", "tokens": [597, 307, 264, 1558, 295, 300, 819, 10863, 486, 312, 322, 2738, 1228, 819, 7512, 13], "temperature": 0.0, "avg_logprob": -0.22340833602413054, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.00012114895798731595}, {"id": 445, "seek": 189244, "start": 1892.44, "end": 1897.0800000000002, "text": " And for example, if you have a JIT that will be used, like Node.js, that has frame pointers.", "tokens": [400, 337, 1365, 11, 498, 291, 362, 257, 508, 3927, 300, 486, 312, 1143, 11, 411, 38640, 13, 25530, 11, 300, 575, 3920, 44548, 13], "temperature": 0.0, "avg_logprob": -0.21646833419799805, "compression_ratio": 1.6979865771812082, "no_speech_prob": 0.0002586588670965284}, {"id": 446, "seek": 189244, "start": 1897.0800000000002, "end": 1899.4, "text": " So you will unwind it with frame pointers.", "tokens": [407, 291, 486, 517, 12199, 309, 365, 3920, 44548, 13], "temperature": 0.0, "avg_logprob": -0.21646833419799805, "compression_ratio": 1.6979865771812082, "no_speech_prob": 0.0002586588670965284}, {"id": 447, "seek": 189244, "start": 1899.4, "end": 1903.64, "text": " But once you reach the actual code from your interpreter, which is compiled and has some", "tokens": [583, 1564, 291, 2524, 264, 3539, 3089, 490, 428, 34132, 11, 597, 307, 36548, 293, 575, 512], "temperature": 0.0, "avg_logprob": -0.21646833419799805, "compression_ratio": 1.6979865771812082, "no_speech_prob": 0.0002586588670965284}, {"id": 448, "seek": 189244, "start": 1903.64, "end": 1906.04, "text": " white information, we will use Dwarf and white information.", "tokens": [2418, 1589, 11, 321, 486, 764, 413, 6925, 69, 293, 2418, 1589, 13], "temperature": 0.0, "avg_logprob": -0.21646833419799805, "compression_ratio": 1.6979865771812082, "no_speech_prob": 0.0002586588670965284}, {"id": 449, "seek": 189244, "start": 1906.04, "end": 1909.0800000000002, "text": " RM64 support is coming late this year.", "tokens": [23790, 19395, 1406, 307, 1348, 3469, 341, 1064, 13], "temperature": 0.0, "avg_logprob": -0.21646833419799805, "compression_ratio": 1.6979865771812082, "no_speech_prob": 0.0002586588670965284}, {"id": 450, "seek": 189244, "start": 1909.0800000000002, "end": 1912.96, "text": " And this feature is now disabled by default, but it is stable enough that we're going", "tokens": [400, 341, 4111, 307, 586, 15191, 538, 7576, 11, 457, 309, 307, 8351, 1547, 300, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.21646833419799805, "compression_ratio": 1.6979865771812082, "no_speech_prob": 0.0002586588670965284}, {"id": 451, "seek": 189244, "start": 1912.96, "end": 1915.0, "text": " to be enabling it in a month.", "tokens": [281, 312, 23148, 309, 294, 257, 1618, 13], "temperature": 0.0, "avg_logprob": -0.21646833419799805, "compression_ratio": 1.6979865771812082, "no_speech_prob": 0.0002586588670965284}, {"id": 452, "seek": 189244, "start": 1915.0, "end": 1917.72, "text": " And then we're going to add other runtime such as the JVM or Ruby.", "tokens": [400, 550, 321, 434, 516, 281, 909, 661, 34474, 1270, 382, 264, 508, 53, 44, 420, 19907, 13], "temperature": 0.0, "avg_logprob": -0.21646833419799805, "compression_ratio": 1.6979865771812082, "no_speech_prob": 0.0002586588670965284}, {"id": 453, "seek": 191772, "start": 1917.72, "end": 1922.96, "text": " And then just to say that we are open source, user space on the Apache 2, BPF on the GPL.", "tokens": [400, 550, 445, 281, 584, 300, 321, 366, 1269, 4009, 11, 4195, 1901, 322, 264, 46597, 568, 11, 40533, 37, 322, 264, 460, 21593, 13], "temperature": 0.0, "avg_logprob": -0.3007107170260682, "compression_ratio": 1.2666666666666666, "no_speech_prob": 0.0012851003557443619}, {"id": 454, "seek": 191772, "start": 1922.96, "end": 1924.96, "text": " And yeah, all the links are here.", "tokens": [400, 1338, 11, 439, 264, 6123, 366, 510, 13], "temperature": 0.0, "avg_logprob": -0.3007107170260682, "compression_ratio": 1.2666666666666666, "no_speech_prob": 0.0012851003557443619}, {"id": 455, "seek": 192496, "start": 1924.96, "end": 1950.92, "text": " Thanks, yeah, thank you so much.", "tokens": [50364, 2561, 11, 1338, 11, 1309, 291, 370, 709, 13, 51662], "temperature": 0.0, "avg_logprob": -0.7254095872243246, "compression_ratio": 0.8648648648648649, "no_speech_prob": 0.0049239713698625565}], "language": "en"}