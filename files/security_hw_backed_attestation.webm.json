{"text": " I trust that everyone here considers authentication a stable internet security and that you think that having more information about the security state of your peer when authenticating them is obviously a good thing if you want to make a good decision. So with that in mind, I want to talk to you about our work to integrate remote attestation as an authentication mechanism in TLS. So first off, who am I? I'm Jonas Mihalca. I'm a senior software engineer in ARM. I do mostly software prototyping, so doing proof of concepts for various software stacks that we think might be useful for our software ecosystems. So looking at an overview of the presentation, so we're going to start with some theory. Looking at remote attestation at TLS and how we plan to integrate the two. And then we're going to continue looking at the practice at the prototype that we're building to instantiate the theory and the draft that we're working on. So let's kick off with the theory. What exactly are we trying to improve here? So the current internet security model is mostly based around an assumption that the attacker is somewhere on the communication path between the peers. So what you usually do is you have some sort of certificate that you issue to the workloads and you have the private key associated with that certificate. And the workload can then essentially authenticate itself to its peers. But the problem is that in this trust model, you have to trust that workload is indeed running the software that you're assuming it's running. Even if, for example, your peer presumably uses some open-source software, you still have to trust them that they've deployed that and that that's where they're running. And also that they're keeping their key secure because if the software is changed or if the key is exfiltrated, then you're kind of hosed. So if you want to have more guarantees, can we actually use more emotive verifiable information within our authentication methods so that we have more information about the security states of that workload and its key? And we actually were prompted to look at this from two use cases in particular. So the first one involves IoT or edge deployment. So for example, you have in this diagram, you have an edge device that has a private identity key that was provisioned at a manufacturing time. And with this identity key, you want to create some attestation credential that you can present to a service. So presumably, you own both the device and the service, and you want to make sure that only your device is connected and can access whatever the service is doing. And sort of a mirror use case is one that involves a workload running in the cloud. So you have, again, a workload that has a private identity key provisioned, for example, in the server chip. And you want your local device to connect to the workload. And you want to get more information about software, for example, the software that booted on the server and how the key is managed. And this is where remote attestation comes in. So remote attestation is essentially a class of hardware-backed mechanisms that allows you to provide cryptographically verifiable metadata about the state of your device. So you can have more trust about, for example, what kind of firmware was running at boot time, what OS kernel you're running, and maybe even what the software in the workload is. So you do this by using that private identity key that was provisioned within the device. And the device essentially becomes certificate authority for itself, and it can issue credentials for all the workloads running on top of it. If we look at the data flow for remote attestation, this is a bit complicated, and it's useful to think of the arrows not as physical communication paths, but as logical data flows, essentially. And the components that we care mostly about here are the attestor and the relying party. So authentication happens between these two, and it's the attestor that wants to authenticate themselves using some sort of remote attestation. And as you can see from the diagram, they're not actually connected in the data flow. There's another component there called a verifier, which takes the attestation evidence, produces attestation results that the relying party can then understand and trust. And the verifier also has above in the diagram a sort of supply chain, and in particular the endorser and the reference value providers, they issue, essentially, they provision the attestor with its software, the boot time software, for example, and its identity key. And then with this information about the attestor, they can go ahead and talk to the verifier and make sure that the verifier trusts the device. So when the verifier tries to appraise the evidence, it understands it and trusts it and then can produce valid attestation results. Switching on to TLS, so the transport layer security, a pretty ubiquitous security protocol. It's used everywhere from HTTPS to lightweight M2M to secure, to provide secure channels of communication. And these secure channels essentially follow a handshake protocol where the peers authenticate each other. And what usually happens with remote attestation is that you have, you establish a security channel, the secure channel, and you do remote attestation on top of that. Whereas we're trying to integrate remote attestation directly into TLS to make it more efficient and also to limit the attack surface that an attacker might see. If we look at TLS 1.3, the handshake in particular, and how we want to integrate with it. So the handshake starts with the client sending over a client hello, a key share, and then the client hello, a bunch of extensions and other things for the server to act upon. Then the server sends, for example, any chosen Cypher suit or any other responses to the extensions that the client sent, has its own key share, and then it's authenticates itself using a certificate message and a certificate verify, and then it's with the finished. And then the client can go ahead and authenticate itself using a certificate message and a certificate verify, and it finishes the handshake with the finished message. After that, you have a secure data channel between the two peers. It's important to note for privacy reasons mostly, that from the second flight onwards, most of those messages are actually encrypted. For example, the certificate, certificate verify are encrypted using session keys. And in terms of what we care about, it's the extensions mostly, because those are used to negotiate, negotiate the type of credentials that, for example, the relying party might care about, and also to send across any freshness that is required to issue the attestation evidence. And also, we care about the certificate message, because that's obviously where we're going to carry the attestation credentials. Most of our goals, our high-level goals, obviously we want to enhance authentication in TLS to support your model attestation. We want to support as many platforms as possible, from very beefy cloud servers to small IoT devices. And we want to support the most common deployment pattern. So for example, we want to allow both client and server to authenticate, or potentially both. We want to allow existing deployments that use BKI to also use remote attestation within the same handshake just to enhance the security. So there's a whole lot of variance there. In terms of security and privacy, we're planning to formally verify the extensions that we're creating, and we're working quite meticulously to try to prevent any potential attacks, for example, relay attacks, where taking a credential form, some victim platform, and you're trying to pawn that off as your own. Then in terms of privacy, fortunately, attestation does reveal quite a lot of metadata, and this can be both privacy and security relevant. And the best we can do is to mitigate some of these by allowing the relying party to choose what kind of attestation scheme or attestation results it gets. So you can get, for example, specially crafted attestation results that have blinded or deducted some of the metadata, or schemes like direct anonymous attestation that provides some sort of privacy. Moving on to the practice. So looking at our prototype. The big picture here is that we are trying to produce an end-to-end prototype of this system, so we're trying to implement everything from the root of trust all the way to the verifier. And we're sort of limiting this because our drafts and our theoretical work is quite broad and allows a lot of deployment patterns, we're limiting this to, for example, a background check model that I'll talk about in a bit, and the TPM 2.0 as the root of trust. And obviously we're open sourcing the entire stack, and also because these components that we're using are already open source software, parts of, for example, a cloud native computing foundation or a confidential computing consortium, and it's actually under the confidential computing consortium attestation special interest group that our work is harbored. Moving back actually to the remote attestation diagram, architecture diagram, you can see here a simplified version of that, so on the bottom you can see an attestor with an existing root of trust, and the attestor wants to communicate with the relying party to authenticate it, and the relying party will then send the attestation evidence over to the verifier for verification. So this is what we call a background check model because the relying party is doing a background check on the evidence provided by the attestor, and in our case if we put a bit more flesh onto this diagram, you can see that in our case the attestor will be a client in a TLS handshake, and the relying party will be the server, and the TLS stack that we're using is MBET-TLS, and the client will essentially send attestation evidence produced by the client's root of trust, and the MBET-TLS on the client side will communicate with the root of trust not directly, but through Parsec, which is one of the projects that we've been developing, and on the server side you have MBET-TLS again communicating with the verifier, which is in our case composed using Uvaraison. So now let's have a look at all of these components independently. So Parsec. What is Parsec? Parsec is a platform abstraction for security. So if you try to write an application in Java or Python or Go, you might want to use some sort of cryptographic hardware backing, so for example a discrete EPM or some trusted services running in TrustZone, and you want to use these in a more generic way, and this is what Parsec is doing, it's presenting a high-level interface that you can use to provision, and Parsec in particular has this sort of identity key as a core use case that it works with, so it tries to allow you to create an identity for your workload and to use it, for example, to sign TLS antics. And Parsec is also quite modular, so it's really easy to implement backends for other types of hardware backends that you might want to support. Moving on to the other end, so we have Varaison, which is a set of components that can be used to build an attestation verification service. So again, Varaison is pretty abstract, it has a bunch of components, for example, for appraising different types of attestation schemes, as components for building, for example, APIs for evidence provisioning, or for endorsement provisioning for verification APIs. So in this diagram here, some factories is creating a device and then producing the endorsement data that it then feeds to Varaison, and when the device tries to connect to an application service, that application service can again go to Varaison to verify those credentials. In terms of what the work that we had to do to make this prototype work across the stack, so Parsec, as I've said, works mostly with cryptographic keys, however, at the moment, we didn't have a very generic key attestation API, and this is something that we had to build to produce those attestation tokens or attestation evidence. Parsec also needs to have configuration to allow it to essentially provision its own identity, so an attesting key that it can use to sign attestation credentials, and also ways to, for example, select the TPM PCRs that you want to include in the attestation tokens, for example, to select whether you want to send information about your firmware or about your bootloader or about your operating system kernel, and we also have a new API to produce the endorsements that are then fed to Varaison for endorsements, so Varaison can then trust the key attestation tokens. On the Varaison side, again, we have to add support for the precise attestation key scheme that we're using, and essentially, we have to build two new plugins, so one to understand the evidence that we're producing for Parsec, and one to understand the endorsements. So what essentially we're doing here is we have two components, and we're trying to make them agnostic of whatever is transporting evidence and endorsements between them, which, in our case, is actually a bad TLS. So the TLS implementation that we're using, the TLS, it's an implementation of TLS and the TLS, and the reason why, it's actually multiple reasons why we're using it, so one of them is because it offers this PSA crypto API, which Parsec hooks into, as per our design, since we created it in sync with the PSA crypto API. It also has a small code footprint, so it's more suitable for IoT and Edge use cases, like the one that I described earlier, and also we had already expertise working with Mbeth TLS, so it was easier for us to work with it. So the open source ecosystem around our projects, and this is something that has been quite important for me in the past years while I've been working on Parsec, realizing that open source is more than just some checkbox that we want to take, and that's it. It's more about the continuous involvement in the community and trying to pull the expertise and the work required to create some components that we can reuse across all of our stacks. And yeah, this is the reason why we've been seeding projects into CNCF and CCC, because we're trying to create these communities around our projects and create the ecosystems around our use cases. So if we look at the Rust ecosystem in particular, for example, because the Parsec service is written in Rust, we've released a number of crates relevant to handling routes of trust. So for example, we've released the TSA API crates that helps with interacting natively with TPMs. We've released the CryptoKey crate, which is essentially a successor to the PKS11 crate that was abandoned some time ago, and we have the PSA CryptoCrate that allows native interaction with PSA Cryptography API, and it's actually been quite a nice experience to see the communities around these projects grow and have more developers from various projects, some of which have actually presented today getting involved and helping us build this ecosystem. Yeah, the more important goal for us, at least, is not just to make these particular backends easy to use in Rust, but perhaps even to make them easy to use in an abstract way. So instead of having to integrate with TPMs or PKS11 individually, what if we could integrate with all of them via Parsec directly? On the Go ecosystem side, we also have a bunch of packages that we've released. A notable one is GoCosy, which I believe was initially developed by Mozilla and inabandant, but then our Verizon team took it over, gave it the dusting, and then released it, and now it's, I think, it's used quite widely, for example, by No3 and SixTor, and we also have a bunch of other packages relevant to remote attestation verification like SWEED or Quorum, and yeah, this brings me to my main selling point here, is that we're trying to essentially build an ecosystem where attestation can just be used as a plug-in for authentication. So whether you integrate it within the authentication step of a TLS stack, or perhaps you want to switch that to some sort of quick stack, or maybe you want to even have some sort of bespoke authentication server and workload trying to authenticate it, we're trying to make it easy to use remote attestation by making Parsec and Verizon interact so easily, so you can just plug those components in and hopefully get attestation right as it works. So just to wrap up here, we think that remote attestation is indeed a viable authentication mechanism in TLS, and perhaps in other protocols as well in the future, or design both in terms of theoretical design, so the drafts, the TLS extensions try to be as flexible as possible, but also the prototype that we're building, we're trying to make it quite flexible as well. And we want to refi all of our drafts and all of the things that we're trying to define with other people across the industry, trying to create an end-to-end prototype that represents all of this theoretical work, and yeah, we're hoping that the prototype will serve as a model for integrating remote attestation not just into specific protocols, but more widely. So yeah, questions? So any questions from the room? I see hands. Yeah, thank you. You mentioned you're working under, well, CNCF and CCCF, you also considered the open source for more foundation? Open source? No, not really. I mean, neither of these, neither of Parsec or Verizon are really firmer level components. Right. So yeah, we're essentially doing very similar stuff, but doing the full flow, like starting from the very first code running on your platform, like in the firmware. We should get in touch. Thank you. Perfect. Hey, thanks for the talk, I was kind of curious how big the impact is on round trip times in TLS if you have secure enclave or TPM involved in the initial handshake, like how does that work? Do you see any problems in practice putting that in skill at scale? We've not really gotten to the point where we can properly test end-to-end in terms of actually going to hardware and talking to hardware, so we're mostly doing with software TPMs and stuff like that, so just to integrate, we still have some integration work to do there. But yeah, we're definitely going to benchmark that and see how it impacts, but it obviously depends on the hardware because if we do that on some server, you know, some cloud server, that's going to be quite different from doing it on an IoT device that has a TPM or something like that. Yeah. Okay, do we have some other questions, anyone? If not, thank you for your talk, thanks. Thank you. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.68, "text": " I trust that everyone here considers authentication a stable internet security and that you think", "tokens": [286, 3361, 300, 1518, 510, 33095, 26643, 257, 8351, 4705, 3825, 293, 300, 291, 519], "temperature": 0.0, "avg_logprob": -0.24245216369628905, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.3147282898426056}, {"id": 1, "seek": 0, "start": 10.68, "end": 16.28, "text": " that having more information about the security state of your peer when authenticating them", "tokens": [300, 1419, 544, 1589, 466, 264, 3825, 1785, 295, 428, 15108, 562, 12466, 990, 552], "temperature": 0.0, "avg_logprob": -0.24245216369628905, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.3147282898426056}, {"id": 2, "seek": 0, "start": 16.28, "end": 21.16, "text": " is obviously a good thing if you want to make a good decision.", "tokens": [307, 2745, 257, 665, 551, 498, 291, 528, 281, 652, 257, 665, 3537, 13], "temperature": 0.0, "avg_logprob": -0.24245216369628905, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.3147282898426056}, {"id": 3, "seek": 0, "start": 21.16, "end": 26.16, "text": " So with that in mind, I want to talk to you about our work to integrate remote attestation", "tokens": [407, 365, 300, 294, 1575, 11, 286, 528, 281, 751, 281, 291, 466, 527, 589, 281, 13365, 8607, 951, 377, 399], "temperature": 0.0, "avg_logprob": -0.24245216369628905, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.3147282898426056}, {"id": 4, "seek": 2616, "start": 26.16, "end": 30.28, "text": " as an authentication mechanism in TLS.", "tokens": [382, 364, 26643, 7513, 294, 314, 19198, 13], "temperature": 0.0, "avg_logprob": -0.259556364505849, "compression_ratio": 1.5521739130434782, "no_speech_prob": 0.0002988939522765577}, {"id": 5, "seek": 2616, "start": 30.28, "end": 32.08, "text": " So first off, who am I?", "tokens": [407, 700, 766, 11, 567, 669, 286, 30], "temperature": 0.0, "avg_logprob": -0.259556364505849, "compression_ratio": 1.5521739130434782, "no_speech_prob": 0.0002988939522765577}, {"id": 6, "seek": 2616, "start": 32.08, "end": 33.08, "text": " I'm Jonas Mihalca.", "tokens": [286, 478, 34630, 48168, 304, 496, 13], "temperature": 0.0, "avg_logprob": -0.259556364505849, "compression_ratio": 1.5521739130434782, "no_speech_prob": 0.0002988939522765577}, {"id": 7, "seek": 2616, "start": 33.08, "end": 36.08, "text": " I'm a senior software engineer in ARM.", "tokens": [286, 478, 257, 7965, 4722, 11403, 294, 45209, 13], "temperature": 0.0, "avg_logprob": -0.259556364505849, "compression_ratio": 1.5521739130434782, "no_speech_prob": 0.0002988939522765577}, {"id": 8, "seek": 2616, "start": 36.08, "end": 41.92, "text": " I do mostly software prototyping, so doing proof of concepts for various software stacks", "tokens": [286, 360, 5240, 4722, 46219, 3381, 11, 370, 884, 8177, 295, 10392, 337, 3683, 4722, 30792], "temperature": 0.0, "avg_logprob": -0.259556364505849, "compression_ratio": 1.5521739130434782, "no_speech_prob": 0.0002988939522765577}, {"id": 9, "seek": 2616, "start": 41.92, "end": 46.32, "text": " that we think might be useful for our software ecosystems.", "tokens": [300, 321, 519, 1062, 312, 4420, 337, 527, 4722, 32647, 13], "temperature": 0.0, "avg_logprob": -0.259556364505849, "compression_ratio": 1.5521739130434782, "no_speech_prob": 0.0002988939522765577}, {"id": 10, "seek": 2616, "start": 46.32, "end": 52.04, "text": " So looking at an overview of the presentation, so we're going to start with some theory.", "tokens": [407, 1237, 412, 364, 12492, 295, 264, 5860, 11, 370, 321, 434, 516, 281, 722, 365, 512, 5261, 13], "temperature": 0.0, "avg_logprob": -0.259556364505849, "compression_ratio": 1.5521739130434782, "no_speech_prob": 0.0002988939522765577}, {"id": 11, "seek": 5204, "start": 52.04, "end": 58.2, "text": " Looking at remote attestation at TLS and how we plan to integrate the two.", "tokens": [11053, 412, 8607, 951, 377, 399, 412, 314, 19198, 293, 577, 321, 1393, 281, 13365, 264, 732, 13], "temperature": 0.0, "avg_logprob": -0.15768740574518839, "compression_ratio": 1.6952789699570816, "no_speech_prob": 4.795980203198269e-05}, {"id": 12, "seek": 5204, "start": 58.2, "end": 60.96, "text": " And then we're going to continue looking at the practice at the prototype that we're", "tokens": [400, 550, 321, 434, 516, 281, 2354, 1237, 412, 264, 3124, 412, 264, 19475, 300, 321, 434], "temperature": 0.0, "avg_logprob": -0.15768740574518839, "compression_ratio": 1.6952789699570816, "no_speech_prob": 4.795980203198269e-05}, {"id": 13, "seek": 5204, "start": 60.96, "end": 66.8, "text": " building to instantiate the theory and the draft that we're working on.", "tokens": [2390, 281, 9836, 13024, 264, 5261, 293, 264, 11206, 300, 321, 434, 1364, 322, 13], "temperature": 0.0, "avg_logprob": -0.15768740574518839, "compression_ratio": 1.6952789699570816, "no_speech_prob": 4.795980203198269e-05}, {"id": 14, "seek": 5204, "start": 66.8, "end": 70.48, "text": " So let's kick off with the theory.", "tokens": [407, 718, 311, 4437, 766, 365, 264, 5261, 13], "temperature": 0.0, "avg_logprob": -0.15768740574518839, "compression_ratio": 1.6952789699570816, "no_speech_prob": 4.795980203198269e-05}, {"id": 15, "seek": 5204, "start": 70.48, "end": 72.08, "text": " What exactly are we trying to improve here?", "tokens": [708, 2293, 366, 321, 1382, 281, 3470, 510, 30], "temperature": 0.0, "avg_logprob": -0.15768740574518839, "compression_ratio": 1.6952789699570816, "no_speech_prob": 4.795980203198269e-05}, {"id": 16, "seek": 5204, "start": 72.08, "end": 79.24, "text": " So the current internet security model is mostly based around an assumption that the", "tokens": [407, 264, 2190, 4705, 3825, 2316, 307, 5240, 2361, 926, 364, 15302, 300, 264], "temperature": 0.0, "avg_logprob": -0.15768740574518839, "compression_ratio": 1.6952789699570816, "no_speech_prob": 4.795980203198269e-05}, {"id": 17, "seek": 7924, "start": 79.24, "end": 83.03999999999999, "text": " attacker is somewhere on the communication path between the peers.", "tokens": [35871, 307, 4079, 322, 264, 6101, 3100, 1296, 264, 16739, 13], "temperature": 0.0, "avg_logprob": -0.11788558959960938, "compression_ratio": 1.839662447257384, "no_speech_prob": 3.530034518917091e-05}, {"id": 18, "seek": 7924, "start": 83.03999999999999, "end": 88.52, "text": " So what you usually do is you have some sort of certificate that you issue to the workloads", "tokens": [407, 437, 291, 2673, 360, 307, 291, 362, 512, 1333, 295, 15953, 300, 291, 2734, 281, 264, 32452], "temperature": 0.0, "avg_logprob": -0.11788558959960938, "compression_ratio": 1.839662447257384, "no_speech_prob": 3.530034518917091e-05}, {"id": 19, "seek": 7924, "start": 88.52, "end": 92.91999999999999, "text": " and you have the private key associated with that certificate.", "tokens": [293, 291, 362, 264, 4551, 2141, 6615, 365, 300, 15953, 13], "temperature": 0.0, "avg_logprob": -0.11788558959960938, "compression_ratio": 1.839662447257384, "no_speech_prob": 3.530034518917091e-05}, {"id": 20, "seek": 7924, "start": 92.91999999999999, "end": 98.6, "text": " And the workload can then essentially authenticate itself to its peers.", "tokens": [400, 264, 20139, 393, 550, 4476, 9214, 8700, 2564, 281, 1080, 16739, 13], "temperature": 0.0, "avg_logprob": -0.11788558959960938, "compression_ratio": 1.839662447257384, "no_speech_prob": 3.530034518917091e-05}, {"id": 21, "seek": 7924, "start": 98.6, "end": 104.16, "text": " But the problem is that in this trust model, you have to trust that workload is indeed", "tokens": [583, 264, 1154, 307, 300, 294, 341, 3361, 2316, 11, 291, 362, 281, 3361, 300, 20139, 307, 6451], "temperature": 0.0, "avg_logprob": -0.11788558959960938, "compression_ratio": 1.839662447257384, "no_speech_prob": 3.530034518917091e-05}, {"id": 22, "seek": 7924, "start": 104.16, "end": 107.75999999999999, "text": " running the software that you're assuming it's running.", "tokens": [2614, 264, 4722, 300, 291, 434, 11926, 309, 311, 2614, 13], "temperature": 0.0, "avg_logprob": -0.11788558959960938, "compression_ratio": 1.839662447257384, "no_speech_prob": 3.530034518917091e-05}, {"id": 23, "seek": 10776, "start": 107.76, "end": 116.36, "text": " Even if, for example, your peer presumably uses some open-source software, you still have", "tokens": [2754, 498, 11, 337, 1365, 11, 428, 15108, 26742, 4960, 512, 1269, 12, 41676, 4722, 11, 291, 920, 362], "temperature": 0.0, "avg_logprob": -0.16586820602416993, "compression_ratio": 1.6489795918367347, "no_speech_prob": 2.705943006731104e-05}, {"id": 24, "seek": 10776, "start": 116.36, "end": 120.2, "text": " to trust them that they've deployed that and that that's where they're running.", "tokens": [281, 3361, 552, 300, 436, 600, 17826, 300, 293, 300, 300, 311, 689, 436, 434, 2614, 13], "temperature": 0.0, "avg_logprob": -0.16586820602416993, "compression_ratio": 1.6489795918367347, "no_speech_prob": 2.705943006731104e-05}, {"id": 25, "seek": 10776, "start": 120.2, "end": 125.08000000000001, "text": " And also that they're keeping their key secure because if the software is changed or if the", "tokens": [400, 611, 300, 436, 434, 5145, 641, 2141, 7144, 570, 498, 264, 4722, 307, 3105, 420, 498, 264], "temperature": 0.0, "avg_logprob": -0.16586820602416993, "compression_ratio": 1.6489795918367347, "no_speech_prob": 2.705943006731104e-05}, {"id": 26, "seek": 10776, "start": 125.08000000000001, "end": 129.6, "text": " key is exfiltrated, then you're kind of hosed.", "tokens": [2141, 307, 454, 69, 2352, 5468, 11, 550, 291, 434, 733, 295, 276, 1744, 13], "temperature": 0.0, "avg_logprob": -0.16586820602416993, "compression_ratio": 1.6489795918367347, "no_speech_prob": 2.705943006731104e-05}, {"id": 27, "seek": 10776, "start": 129.6, "end": 135.04000000000002, "text": " So if you want to have more guarantees, can we actually use more emotive verifiable information", "tokens": [407, 498, 291, 528, 281, 362, 544, 32567, 11, 393, 321, 767, 764, 544, 3626, 488, 1306, 30876, 1589], "temperature": 0.0, "avg_logprob": -0.16586820602416993, "compression_ratio": 1.6489795918367347, "no_speech_prob": 2.705943006731104e-05}, {"id": 28, "seek": 13504, "start": 135.04, "end": 139.4, "text": " within our authentication methods so that we have more information about the security", "tokens": [1951, 527, 26643, 7150, 370, 300, 321, 362, 544, 1589, 466, 264, 3825], "temperature": 0.0, "avg_logprob": -0.11419251026251377, "compression_ratio": 1.5674418604651164, "no_speech_prob": 1.8734423065325245e-05}, {"id": 29, "seek": 13504, "start": 139.4, "end": 147.0, "text": " states of that workload and its key?", "tokens": [4368, 295, 300, 20139, 293, 1080, 2141, 30], "temperature": 0.0, "avg_logprob": -0.11419251026251377, "compression_ratio": 1.5674418604651164, "no_speech_prob": 1.8734423065325245e-05}, {"id": 30, "seek": 13504, "start": 147.0, "end": 152.48, "text": " And we actually were prompted to look at this from two use cases in particular.", "tokens": [400, 321, 767, 645, 31042, 281, 574, 412, 341, 490, 732, 764, 3331, 294, 1729, 13], "temperature": 0.0, "avg_logprob": -0.11419251026251377, "compression_ratio": 1.5674418604651164, "no_speech_prob": 1.8734423065325245e-05}, {"id": 31, "seek": 13504, "start": 152.48, "end": 157.88, "text": " So the first one involves IoT or edge deployment.", "tokens": [407, 264, 700, 472, 11626, 30112, 420, 4691, 19317, 13], "temperature": 0.0, "avg_logprob": -0.11419251026251377, "compression_ratio": 1.5674418604651164, "no_speech_prob": 1.8734423065325245e-05}, {"id": 32, "seek": 13504, "start": 157.88, "end": 163.35999999999999, "text": " So for example, you have in this diagram, you have an edge device that has a private", "tokens": [407, 337, 1365, 11, 291, 362, 294, 341, 10686, 11, 291, 362, 364, 4691, 4302, 300, 575, 257, 4551], "temperature": 0.0, "avg_logprob": -0.11419251026251377, "compression_ratio": 1.5674418604651164, "no_speech_prob": 1.8734423065325245e-05}, {"id": 33, "seek": 16336, "start": 163.36, "end": 171.24, "text": " identity key that was provisioned at a manufacturing time.", "tokens": [6575, 2141, 300, 390, 17225, 292, 412, 257, 11096, 565, 13], "temperature": 0.0, "avg_logprob": -0.16022549399846717, "compression_ratio": 1.7239583333333333, "no_speech_prob": 3.1620216759620234e-05}, {"id": 34, "seek": 16336, "start": 171.24, "end": 176.36, "text": " And with this identity key, you want to create some attestation credential that you can present", "tokens": [400, 365, 341, 6575, 2141, 11, 291, 528, 281, 1884, 512, 951, 377, 399, 22034, 300, 291, 393, 1974], "temperature": 0.0, "avg_logprob": -0.16022549399846717, "compression_ratio": 1.7239583333333333, "no_speech_prob": 3.1620216759620234e-05}, {"id": 35, "seek": 16336, "start": 176.36, "end": 177.36, "text": " to a service.", "tokens": [281, 257, 2643, 13], "temperature": 0.0, "avg_logprob": -0.16022549399846717, "compression_ratio": 1.7239583333333333, "no_speech_prob": 3.1620216759620234e-05}, {"id": 36, "seek": 16336, "start": 177.36, "end": 180.92000000000002, "text": " So presumably, you own both the device and the service, and you want to make sure that", "tokens": [407, 26742, 11, 291, 1065, 1293, 264, 4302, 293, 264, 2643, 11, 293, 291, 528, 281, 652, 988, 300], "temperature": 0.0, "avg_logprob": -0.16022549399846717, "compression_ratio": 1.7239583333333333, "no_speech_prob": 3.1620216759620234e-05}, {"id": 37, "seek": 16336, "start": 180.92000000000002, "end": 187.68, "text": " only your device is connected and can access whatever the service is doing.", "tokens": [787, 428, 4302, 307, 4582, 293, 393, 2105, 2035, 264, 2643, 307, 884, 13], "temperature": 0.0, "avg_logprob": -0.16022549399846717, "compression_ratio": 1.7239583333333333, "no_speech_prob": 3.1620216759620234e-05}, {"id": 38, "seek": 18768, "start": 187.68, "end": 194.04000000000002, "text": " And sort of a mirror use case is one that involves a workload running in the cloud.", "tokens": [400, 1333, 295, 257, 8013, 764, 1389, 307, 472, 300, 11626, 257, 20139, 2614, 294, 264, 4588, 13], "temperature": 0.0, "avg_logprob": -0.15205354788868697, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.637653991172556e-06}, {"id": 39, "seek": 18768, "start": 194.04000000000002, "end": 200.96, "text": " So you have, again, a workload that has a private identity key provisioned, for example,", "tokens": [407, 291, 362, 11, 797, 11, 257, 20139, 300, 575, 257, 4551, 6575, 2141, 17225, 292, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.15205354788868697, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.637653991172556e-06}, {"id": 40, "seek": 18768, "start": 200.96, "end": 202.84, "text": " in the server chip.", "tokens": [294, 264, 7154, 11409, 13], "temperature": 0.0, "avg_logprob": -0.15205354788868697, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.637653991172556e-06}, {"id": 41, "seek": 18768, "start": 202.84, "end": 206.52, "text": " And you want your local device to connect to the workload.", "tokens": [400, 291, 528, 428, 2654, 4302, 281, 1745, 281, 264, 20139, 13], "temperature": 0.0, "avg_logprob": -0.15205354788868697, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.637653991172556e-06}, {"id": 42, "seek": 18768, "start": 206.52, "end": 210.72, "text": " And you want to get more information about software, for example, the software that booted", "tokens": [400, 291, 528, 281, 483, 544, 1589, 466, 4722, 11, 337, 1365, 11, 264, 4722, 300, 11450, 292], "temperature": 0.0, "avg_logprob": -0.15205354788868697, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.637653991172556e-06}, {"id": 43, "seek": 18768, "start": 210.72, "end": 216.28, "text": " on the server and how the key is managed.", "tokens": [322, 264, 7154, 293, 577, 264, 2141, 307, 6453, 13], "temperature": 0.0, "avg_logprob": -0.15205354788868697, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.637653991172556e-06}, {"id": 44, "seek": 21628, "start": 216.28, "end": 218.12, "text": " And this is where remote attestation comes in.", "tokens": [400, 341, 307, 689, 8607, 951, 377, 399, 1487, 294, 13], "temperature": 0.0, "avg_logprob": -0.10869658362005175, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.539834167691879e-05}, {"id": 45, "seek": 21628, "start": 218.12, "end": 223.32, "text": " So remote attestation is essentially a class of hardware-backed mechanisms that allows", "tokens": [407, 8607, 951, 377, 399, 307, 4476, 257, 1508, 295, 8837, 12, 3207, 292, 15902, 300, 4045], "temperature": 0.0, "avg_logprob": -0.10869658362005175, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.539834167691879e-05}, {"id": 46, "seek": 21628, "start": 223.32, "end": 230.68, "text": " you to provide cryptographically verifiable metadata about the state of your device.", "tokens": [291, 281, 2893, 9844, 3108, 984, 1306, 30876, 26603, 466, 264, 1785, 295, 428, 4302, 13], "temperature": 0.0, "avg_logprob": -0.10869658362005175, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.539834167691879e-05}, {"id": 47, "seek": 21628, "start": 230.68, "end": 235.92000000000002, "text": " So you can have more trust about, for example, what kind of firmware was running at boot", "tokens": [407, 291, 393, 362, 544, 3361, 466, 11, 337, 1365, 11, 437, 733, 295, 30289, 390, 2614, 412, 11450], "temperature": 0.0, "avg_logprob": -0.10869658362005175, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.539834167691879e-05}, {"id": 48, "seek": 21628, "start": 235.92000000000002, "end": 242.36, "text": " time, what OS kernel you're running, and maybe even what the software in the workload", "tokens": [565, 11, 437, 12731, 28256, 291, 434, 2614, 11, 293, 1310, 754, 437, 264, 4722, 294, 264, 20139], "temperature": 0.0, "avg_logprob": -0.10869658362005175, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.539834167691879e-05}, {"id": 49, "seek": 21628, "start": 242.36, "end": 243.36, "text": " is.", "tokens": [307, 13], "temperature": 0.0, "avg_logprob": -0.10869658362005175, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.539834167691879e-05}, {"id": 50, "seek": 24336, "start": 243.36, "end": 250.36, "text": " So you do this by using that private identity key that was provisioned within the device.", "tokens": [407, 291, 360, 341, 538, 1228, 300, 4551, 6575, 2141, 300, 390, 17225, 292, 1951, 264, 4302, 13], "temperature": 0.0, "avg_logprob": -0.12877806864286723, "compression_ratio": 1.5673076923076923, "no_speech_prob": 2.876287544495426e-05}, {"id": 51, "seek": 24336, "start": 250.36, "end": 255.20000000000002, "text": " And the device essentially becomes certificate authority for itself, and it can issue credentials", "tokens": [400, 264, 4302, 4476, 3643, 15953, 8281, 337, 2564, 11, 293, 309, 393, 2734, 27404], "temperature": 0.0, "avg_logprob": -0.12877806864286723, "compression_ratio": 1.5673076923076923, "no_speech_prob": 2.876287544495426e-05}, {"id": 52, "seek": 24336, "start": 255.20000000000002, "end": 259.64, "text": " for all the workloads running on top of it.", "tokens": [337, 439, 264, 32452, 2614, 322, 1192, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.12877806864286723, "compression_ratio": 1.5673076923076923, "no_speech_prob": 2.876287544495426e-05}, {"id": 53, "seek": 24336, "start": 259.64, "end": 266.84000000000003, "text": " If we look at the data flow for remote attestation, this is a bit complicated, and it's useful", "tokens": [759, 321, 574, 412, 264, 1412, 3095, 337, 8607, 951, 377, 399, 11, 341, 307, 257, 857, 6179, 11, 293, 309, 311, 4420], "temperature": 0.0, "avg_logprob": -0.12877806864286723, "compression_ratio": 1.5673076923076923, "no_speech_prob": 2.876287544495426e-05}, {"id": 54, "seek": 26684, "start": 266.84, "end": 274.67999999999995, "text": " to think of the arrows not as physical communication paths, but as logical data flows, essentially.", "tokens": [281, 519, 295, 264, 19669, 406, 382, 4001, 6101, 14518, 11, 457, 382, 14978, 1412, 12867, 11, 4476, 13], "temperature": 0.0, "avg_logprob": -0.13461429245617926, "compression_ratio": 1.7458333333333333, "no_speech_prob": 2.745771053014323e-05}, {"id": 55, "seek": 26684, "start": 274.67999999999995, "end": 280.23999999999995, "text": " And the components that we care mostly about here are the attestor and the relying party.", "tokens": [400, 264, 6677, 300, 321, 1127, 5240, 466, 510, 366, 264, 951, 377, 284, 293, 264, 24140, 3595, 13], "temperature": 0.0, "avg_logprob": -0.13461429245617926, "compression_ratio": 1.7458333333333333, "no_speech_prob": 2.745771053014323e-05}, {"id": 56, "seek": 26684, "start": 280.23999999999995, "end": 284.76, "text": " So authentication happens between these two, and it's the attestor that wants to authenticate", "tokens": [407, 26643, 2314, 1296, 613, 732, 11, 293, 309, 311, 264, 951, 377, 284, 300, 2738, 281, 9214, 8700], "temperature": 0.0, "avg_logprob": -0.13461429245617926, "compression_ratio": 1.7458333333333333, "no_speech_prob": 2.745771053014323e-05}, {"id": 57, "seek": 26684, "start": 284.76, "end": 288.88, "text": " themselves using some sort of remote attestation.", "tokens": [2969, 1228, 512, 1333, 295, 8607, 951, 377, 399, 13], "temperature": 0.0, "avg_logprob": -0.13461429245617926, "compression_ratio": 1.7458333333333333, "no_speech_prob": 2.745771053014323e-05}, {"id": 58, "seek": 26684, "start": 288.88, "end": 293.84, "text": " And as you can see from the diagram, they're not actually connected in the data flow.", "tokens": [400, 382, 291, 393, 536, 490, 264, 10686, 11, 436, 434, 406, 767, 4582, 294, 264, 1412, 3095, 13], "temperature": 0.0, "avg_logprob": -0.13461429245617926, "compression_ratio": 1.7458333333333333, "no_speech_prob": 2.745771053014323e-05}, {"id": 59, "seek": 29384, "start": 293.84, "end": 299.23999999999995, "text": " There's another component there called a verifier, which takes the attestation evidence, produces", "tokens": [821, 311, 1071, 6542, 456, 1219, 257, 1306, 9902, 11, 597, 2516, 264, 951, 377, 399, 4467, 11, 14725], "temperature": 0.0, "avg_logprob": -0.16654709924625444, "compression_ratio": 1.6296296296296295, "no_speech_prob": 7.883329089963809e-05}, {"id": 60, "seek": 29384, "start": 299.23999999999995, "end": 305.71999999999997, "text": " attestation results that the relying party can then understand and trust.", "tokens": [951, 377, 399, 3542, 300, 264, 24140, 3595, 393, 550, 1223, 293, 3361, 13], "temperature": 0.0, "avg_logprob": -0.16654709924625444, "compression_ratio": 1.6296296296296295, "no_speech_prob": 7.883329089963809e-05}, {"id": 61, "seek": 29384, "start": 305.71999999999997, "end": 312.08, "text": " And the verifier also has above in the diagram a sort of supply chain, and in particular", "tokens": [400, 264, 1306, 9902, 611, 575, 3673, 294, 264, 10686, 257, 1333, 295, 5847, 5021, 11, 293, 294, 1729], "temperature": 0.0, "avg_logprob": -0.16654709924625444, "compression_ratio": 1.6296296296296295, "no_speech_prob": 7.883329089963809e-05}, {"id": 62, "seek": 29384, "start": 312.08, "end": 319.03999999999996, "text": " the endorser and the reference value providers, they issue, essentially, they provision the", "tokens": [264, 37676, 260, 293, 264, 6408, 2158, 11330, 11, 436, 2734, 11, 4476, 11, 436, 17225, 264], "temperature": 0.0, "avg_logprob": -0.16654709924625444, "compression_ratio": 1.6296296296296295, "no_speech_prob": 7.883329089963809e-05}, {"id": 63, "seek": 31904, "start": 319.04, "end": 325.36, "text": " attestor with its software, the boot time software, for example, and its identity key.", "tokens": [951, 377, 284, 365, 1080, 4722, 11, 264, 11450, 565, 4722, 11, 337, 1365, 11, 293, 1080, 6575, 2141, 13], "temperature": 0.0, "avg_logprob": -0.10995103979623445, "compression_ratio": 1.7843137254901962, "no_speech_prob": 3.840415956801735e-05}, {"id": 64, "seek": 31904, "start": 325.36, "end": 332.28000000000003, "text": " And then with this information about the attestor, they can go ahead and talk to the verifier", "tokens": [400, 550, 365, 341, 1589, 466, 264, 951, 377, 284, 11, 436, 393, 352, 2286, 293, 751, 281, 264, 1306, 9902], "temperature": 0.0, "avg_logprob": -0.10995103979623445, "compression_ratio": 1.7843137254901962, "no_speech_prob": 3.840415956801735e-05}, {"id": 65, "seek": 31904, "start": 332.28000000000003, "end": 335.04, "text": " and make sure that the verifier trusts the device.", "tokens": [293, 652, 988, 300, 264, 1306, 9902, 45358, 264, 4302, 13], "temperature": 0.0, "avg_logprob": -0.10995103979623445, "compression_ratio": 1.7843137254901962, "no_speech_prob": 3.840415956801735e-05}, {"id": 66, "seek": 31904, "start": 335.04, "end": 340.28000000000003, "text": " So when the verifier tries to appraise the evidence, it understands it and trusts it", "tokens": [407, 562, 264, 1306, 9902, 9898, 281, 724, 424, 908, 264, 4467, 11, 309, 15146, 309, 293, 45358, 309], "temperature": 0.0, "avg_logprob": -0.10995103979623445, "compression_ratio": 1.7843137254901962, "no_speech_prob": 3.840415956801735e-05}, {"id": 67, "seek": 31904, "start": 340.28000000000003, "end": 345.72, "text": " and then can produce valid attestation results.", "tokens": [293, 550, 393, 5258, 7363, 951, 377, 399, 3542, 13], "temperature": 0.0, "avg_logprob": -0.10995103979623445, "compression_ratio": 1.7843137254901962, "no_speech_prob": 3.840415956801735e-05}, {"id": 68, "seek": 34572, "start": 345.72, "end": 351.36, "text": " Switching on to TLS, so the transport layer security, a pretty ubiquitous security protocol.", "tokens": [13893, 278, 322, 281, 314, 19198, 11, 370, 264, 5495, 4583, 3825, 11, 257, 1238, 43868, 39831, 3825, 10336, 13], "temperature": 0.0, "avg_logprob": -0.2595058359125609, "compression_ratio": 1.5983935742971886, "no_speech_prob": 0.00025750318309292197}, {"id": 69, "seek": 34572, "start": 351.36, "end": 359.6, "text": " It's used everywhere from HTTPS to lightweight M2M to secure, to provide secure channels", "tokens": [467, 311, 1143, 5315, 490, 11751, 51, 6273, 281, 22052, 376, 17, 44, 281, 7144, 11, 281, 2893, 7144, 9235], "temperature": 0.0, "avg_logprob": -0.2595058359125609, "compression_ratio": 1.5983935742971886, "no_speech_prob": 0.00025750318309292197}, {"id": 70, "seek": 34572, "start": 359.6, "end": 361.12, "text": " of communication.", "tokens": [295, 6101, 13], "temperature": 0.0, "avg_logprob": -0.2595058359125609, "compression_ratio": 1.5983935742971886, "no_speech_prob": 0.00025750318309292197}, {"id": 71, "seek": 34572, "start": 361.12, "end": 365.52000000000004, "text": " And these secure channels essentially follow a handshake protocol where the peers authenticate", "tokens": [400, 613, 7144, 9235, 4476, 1524, 257, 2377, 34593, 10336, 689, 264, 16739, 9214, 8700], "temperature": 0.0, "avg_logprob": -0.2595058359125609, "compression_ratio": 1.5983935742971886, "no_speech_prob": 0.00025750318309292197}, {"id": 72, "seek": 34572, "start": 365.52000000000004, "end": 367.52000000000004, "text": " each other.", "tokens": [1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.2595058359125609, "compression_ratio": 1.5983935742971886, "no_speech_prob": 0.00025750318309292197}, {"id": 73, "seek": 34572, "start": 367.52000000000004, "end": 371.24, "text": " And what usually happens with remote attestation is that you have, you establish a security", "tokens": [400, 437, 2673, 2314, 365, 8607, 951, 377, 399, 307, 300, 291, 362, 11, 291, 8327, 257, 3825], "temperature": 0.0, "avg_logprob": -0.2595058359125609, "compression_ratio": 1.5983935742971886, "no_speech_prob": 0.00025750318309292197}, {"id": 74, "seek": 37124, "start": 371.24, "end": 376.16, "text": " channel, the secure channel, and you do remote attestation on top of that.", "tokens": [2269, 11, 264, 7144, 2269, 11, 293, 291, 360, 8607, 951, 377, 399, 322, 1192, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.15754353888681003, "compression_ratio": 1.7447698744769875, "no_speech_prob": 8.252754923887551e-05}, {"id": 75, "seek": 37124, "start": 376.16, "end": 382.08, "text": " Whereas we're trying to integrate remote attestation directly into TLS to make it more efficient", "tokens": [13813, 321, 434, 1382, 281, 13365, 8607, 951, 377, 399, 3838, 666, 314, 19198, 281, 652, 309, 544, 7148], "temperature": 0.0, "avg_logprob": -0.15754353888681003, "compression_ratio": 1.7447698744769875, "no_speech_prob": 8.252754923887551e-05}, {"id": 76, "seek": 37124, "start": 382.08, "end": 389.16, "text": " and also to limit the attack surface that an attacker might see.", "tokens": [293, 611, 281, 4948, 264, 2690, 3753, 300, 364, 35871, 1062, 536, 13], "temperature": 0.0, "avg_logprob": -0.15754353888681003, "compression_ratio": 1.7447698744769875, "no_speech_prob": 8.252754923887551e-05}, {"id": 77, "seek": 37124, "start": 389.16, "end": 394.92, "text": " If we look at TLS 1.3, the handshake in particular, and how we want to integrate with it.", "tokens": [759, 321, 574, 412, 314, 19198, 502, 13, 18, 11, 264, 2377, 34593, 294, 1729, 11, 293, 577, 321, 528, 281, 13365, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.15754353888681003, "compression_ratio": 1.7447698744769875, "no_speech_prob": 8.252754923887551e-05}, {"id": 78, "seek": 37124, "start": 394.92, "end": 400.12, "text": " So the handshake starts with the client sending over a client hello, a key share, and then", "tokens": [407, 264, 2377, 34593, 3719, 365, 264, 6423, 7750, 670, 257, 6423, 7751, 11, 257, 2141, 2073, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.15754353888681003, "compression_ratio": 1.7447698744769875, "no_speech_prob": 8.252754923887551e-05}, {"id": 79, "seek": 40012, "start": 400.12, "end": 407.8, "text": " the client hello, a bunch of extensions and other things for the server to act upon.", "tokens": [264, 6423, 7751, 11, 257, 3840, 295, 25129, 293, 661, 721, 337, 264, 7154, 281, 605, 3564, 13], "temperature": 0.0, "avg_logprob": -0.24116339002336776, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.00015854059893172234}, {"id": 80, "seek": 40012, "start": 407.8, "end": 414.96, "text": " Then the server sends, for example, any chosen Cypher suit or any other responses to the", "tokens": [1396, 264, 7154, 14790, 11, 337, 1365, 11, 604, 8614, 10295, 79, 511, 5722, 420, 604, 661, 13019, 281, 264], "temperature": 0.0, "avg_logprob": -0.24116339002336776, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.00015854059893172234}, {"id": 81, "seek": 40012, "start": 414.96, "end": 420.6, "text": " extensions that the client sent, has its own key share, and then it's authenticates itself", "tokens": [25129, 300, 264, 6423, 2279, 11, 575, 1080, 1065, 2141, 2073, 11, 293, 550, 309, 311, 12466, 1024, 2564], "temperature": 0.0, "avg_logprob": -0.24116339002336776, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.00015854059893172234}, {"id": 82, "seek": 40012, "start": 420.6, "end": 427.64, "text": " using a certificate message and a certificate verify, and then it's with the finished.", "tokens": [1228, 257, 15953, 3636, 293, 257, 15953, 16888, 11, 293, 550, 309, 311, 365, 264, 4335, 13], "temperature": 0.0, "avg_logprob": -0.24116339002336776, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.00015854059893172234}, {"id": 83, "seek": 42764, "start": 427.64, "end": 432.68, "text": " And then the client can go ahead and authenticate itself using a certificate message and a certificate", "tokens": [400, 550, 264, 6423, 393, 352, 2286, 293, 9214, 8700, 2564, 1228, 257, 15953, 3636, 293, 257, 15953], "temperature": 0.0, "avg_logprob": -0.22070131496507295, "compression_ratio": 1.76171875, "no_speech_prob": 3.925853161490522e-05}, {"id": 84, "seek": 42764, "start": 432.68, "end": 437.68, "text": " verify, and it finishes the handshake with the finished message.", "tokens": [16888, 11, 293, 309, 23615, 264, 2377, 34593, 365, 264, 4335, 3636, 13], "temperature": 0.0, "avg_logprob": -0.22070131496507295, "compression_ratio": 1.76171875, "no_speech_prob": 3.925853161490522e-05}, {"id": 85, "seek": 42764, "start": 437.68, "end": 442.15999999999997, "text": " After that, you have a secure data channel between the two peers.", "tokens": [2381, 300, 11, 291, 362, 257, 7144, 1412, 2269, 1296, 264, 732, 16739, 13], "temperature": 0.0, "avg_logprob": -0.22070131496507295, "compression_ratio": 1.76171875, "no_speech_prob": 3.925853161490522e-05}, {"id": 86, "seek": 42764, "start": 442.15999999999997, "end": 448.12, "text": " It's important to note for privacy reasons mostly, that from the second flight onwards,", "tokens": [467, 311, 1021, 281, 3637, 337, 11427, 4112, 5240, 11, 300, 490, 264, 1150, 7018, 34230, 11], "temperature": 0.0, "avg_logprob": -0.22070131496507295, "compression_ratio": 1.76171875, "no_speech_prob": 3.925853161490522e-05}, {"id": 87, "seek": 42764, "start": 448.12, "end": 449.8, "text": " most of those messages are actually encrypted.", "tokens": [881, 295, 729, 7897, 366, 767, 36663, 13], "temperature": 0.0, "avg_logprob": -0.22070131496507295, "compression_ratio": 1.76171875, "no_speech_prob": 3.925853161490522e-05}, {"id": 88, "seek": 42764, "start": 449.8, "end": 456.0, "text": " For example, the certificate, certificate verify are encrypted using session keys.", "tokens": [1171, 1365, 11, 264, 15953, 11, 15953, 16888, 366, 36663, 1228, 5481, 9317, 13], "temperature": 0.0, "avg_logprob": -0.22070131496507295, "compression_ratio": 1.76171875, "no_speech_prob": 3.925853161490522e-05}, {"id": 89, "seek": 45600, "start": 456.0, "end": 461.64, "text": " And in terms of what we care about, it's the extensions mostly, because those are used", "tokens": [400, 294, 2115, 295, 437, 321, 1127, 466, 11, 309, 311, 264, 25129, 5240, 11, 570, 729, 366, 1143], "temperature": 0.0, "avg_logprob": -0.14229631423950195, "compression_ratio": 1.793859649122807, "no_speech_prob": 5.8949008234776556e-05}, {"id": 90, "seek": 45600, "start": 461.64, "end": 467.36, "text": " to negotiate, negotiate the type of credentials that, for example, the relying party might", "tokens": [281, 21713, 11, 21713, 264, 2010, 295, 27404, 300, 11, 337, 1365, 11, 264, 24140, 3595, 1062], "temperature": 0.0, "avg_logprob": -0.14229631423950195, "compression_ratio": 1.793859649122807, "no_speech_prob": 5.8949008234776556e-05}, {"id": 91, "seek": 45600, "start": 467.36, "end": 473.88, "text": " care about, and also to send across any freshness that is required to issue the attestation", "tokens": [1127, 466, 11, 293, 611, 281, 2845, 2108, 604, 4451, 1287, 300, 307, 4739, 281, 2734, 264, 951, 377, 399], "temperature": 0.0, "avg_logprob": -0.14229631423950195, "compression_ratio": 1.793859649122807, "no_speech_prob": 5.8949008234776556e-05}, {"id": 92, "seek": 45600, "start": 473.88, "end": 476.4, "text": " evidence.", "tokens": [4467, 13], "temperature": 0.0, "avg_logprob": -0.14229631423950195, "compression_ratio": 1.793859649122807, "no_speech_prob": 5.8949008234776556e-05}, {"id": 93, "seek": 45600, "start": 476.4, "end": 479.72, "text": " And also, we care about the certificate message, because that's obviously where we're going", "tokens": [400, 611, 11, 321, 1127, 466, 264, 15953, 3636, 11, 570, 300, 311, 2745, 689, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.14229631423950195, "compression_ratio": 1.793859649122807, "no_speech_prob": 5.8949008234776556e-05}, {"id": 94, "seek": 45600, "start": 479.72, "end": 484.28, "text": " to carry the attestation credentials.", "tokens": [281, 3985, 264, 951, 377, 399, 27404, 13], "temperature": 0.0, "avg_logprob": -0.14229631423950195, "compression_ratio": 1.793859649122807, "no_speech_prob": 5.8949008234776556e-05}, {"id": 95, "seek": 48428, "start": 484.28, "end": 488.52, "text": " Most of our goals, our high-level goals, obviously we want to enhance authentication", "tokens": [4534, 295, 527, 5493, 11, 527, 1090, 12, 12418, 5493, 11, 2745, 321, 528, 281, 11985, 26643], "temperature": 0.0, "avg_logprob": -0.23663562536239624, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.00013954540190752596}, {"id": 96, "seek": 48428, "start": 488.52, "end": 491.96, "text": " in TLS to support your model attestation.", "tokens": [294, 314, 19198, 281, 1406, 428, 2316, 951, 377, 399, 13], "temperature": 0.0, "avg_logprob": -0.23663562536239624, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.00013954540190752596}, {"id": 97, "seek": 48428, "start": 491.96, "end": 500.47999999999996, "text": " We want to support as many platforms as possible, from very beefy cloud servers to small IoT", "tokens": [492, 528, 281, 1406, 382, 867, 9473, 382, 1944, 11, 490, 588, 9256, 88, 4588, 15909, 281, 1359, 30112], "temperature": 0.0, "avg_logprob": -0.23663562536239624, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.00013954540190752596}, {"id": 98, "seek": 48428, "start": 500.47999999999996, "end": 501.47999999999996, "text": " devices.", "tokens": [5759, 13], "temperature": 0.0, "avg_logprob": -0.23663562536239624, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.00013954540190752596}, {"id": 99, "seek": 48428, "start": 501.47999999999996, "end": 504.71999999999997, "text": " And we want to support the most common deployment pattern.", "tokens": [400, 321, 528, 281, 1406, 264, 881, 2689, 19317, 5102, 13], "temperature": 0.0, "avg_logprob": -0.23663562536239624, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.00013954540190752596}, {"id": 100, "seek": 48428, "start": 504.71999999999997, "end": 510.0, "text": " So for example, we want to allow both client and server to authenticate, or potentially", "tokens": [407, 337, 1365, 11, 321, 528, 281, 2089, 1293, 6423, 293, 7154, 281, 9214, 8700, 11, 420, 7263], "temperature": 0.0, "avg_logprob": -0.23663562536239624, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.00013954540190752596}, {"id": 101, "seek": 48428, "start": 510.0, "end": 511.23999999999995, "text": " both.", "tokens": [1293, 13], "temperature": 0.0, "avg_logprob": -0.23663562536239624, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.00013954540190752596}, {"id": 102, "seek": 51124, "start": 511.24, "end": 517.04, "text": " We want to allow existing deployments that use BKI to also use remote attestation within", "tokens": [492, 528, 281, 2089, 6741, 7274, 1117, 300, 764, 363, 27731, 281, 611, 764, 8607, 951, 377, 399, 1951], "temperature": 0.0, "avg_logprob": -0.14858413564747777, "compression_ratio": 1.58008658008658, "no_speech_prob": 2.083414074149914e-05}, {"id": 103, "seek": 51124, "start": 517.04, "end": 519.8, "text": " the same handshake just to enhance the security.", "tokens": [264, 912, 2377, 34593, 445, 281, 11985, 264, 3825, 13], "temperature": 0.0, "avg_logprob": -0.14858413564747777, "compression_ratio": 1.58008658008658, "no_speech_prob": 2.083414074149914e-05}, {"id": 104, "seek": 51124, "start": 519.8, "end": 524.32, "text": " So there's a whole lot of variance there.", "tokens": [407, 456, 311, 257, 1379, 688, 295, 21977, 456, 13], "temperature": 0.0, "avg_logprob": -0.14858413564747777, "compression_ratio": 1.58008658008658, "no_speech_prob": 2.083414074149914e-05}, {"id": 105, "seek": 51124, "start": 524.32, "end": 528.6800000000001, "text": " In terms of security and privacy, we're planning to formally verify the extensions that we're", "tokens": [682, 2115, 295, 3825, 293, 11427, 11, 321, 434, 5038, 281, 25983, 16888, 264, 25129, 300, 321, 434], "temperature": 0.0, "avg_logprob": -0.14858413564747777, "compression_ratio": 1.58008658008658, "no_speech_prob": 2.083414074149914e-05}, {"id": 106, "seek": 51124, "start": 528.6800000000001, "end": 535.6, "text": " creating, and we're working quite meticulously to try to prevent any potential attacks, for", "tokens": [4084, 11, 293, 321, 434, 1364, 1596, 41566, 25038, 281, 853, 281, 4871, 604, 3995, 8122, 11, 337], "temperature": 0.0, "avg_logprob": -0.14858413564747777, "compression_ratio": 1.58008658008658, "no_speech_prob": 2.083414074149914e-05}, {"id": 107, "seek": 53560, "start": 535.6, "end": 541.5600000000001, "text": " example, relay attacks, where taking a credential form, some victim platform, and you're trying", "tokens": [1365, 11, 24214, 8122, 11, 689, 1940, 257, 22034, 1254, 11, 512, 6760, 3663, 11, 293, 291, 434, 1382], "temperature": 0.0, "avg_logprob": -0.17372819989226584, "compression_ratio": 1.5765765765765767, "no_speech_prob": 8.839409565553069e-05}, {"id": 108, "seek": 53560, "start": 541.5600000000001, "end": 545.52, "text": " to pawn that off as your own.", "tokens": [281, 30905, 300, 766, 382, 428, 1065, 13], "temperature": 0.0, "avg_logprob": -0.17372819989226584, "compression_ratio": 1.5765765765765767, "no_speech_prob": 8.839409565553069e-05}, {"id": 109, "seek": 53560, "start": 545.52, "end": 553.88, "text": " Then in terms of privacy, fortunately, attestation does reveal quite a lot of metadata, and this", "tokens": [1396, 294, 2115, 295, 11427, 11, 25511, 11, 951, 377, 399, 775, 10658, 1596, 257, 688, 295, 26603, 11, 293, 341], "temperature": 0.0, "avg_logprob": -0.17372819989226584, "compression_ratio": 1.5765765765765767, "no_speech_prob": 8.839409565553069e-05}, {"id": 110, "seek": 53560, "start": 553.88, "end": 558.12, "text": " can be both privacy and security relevant.", "tokens": [393, 312, 1293, 11427, 293, 3825, 7340, 13], "temperature": 0.0, "avg_logprob": -0.17372819989226584, "compression_ratio": 1.5765765765765767, "no_speech_prob": 8.839409565553069e-05}, {"id": 111, "seek": 53560, "start": 558.12, "end": 564.6, "text": " And the best we can do is to mitigate some of these by allowing the relying party to", "tokens": [400, 264, 1151, 321, 393, 360, 307, 281, 27336, 512, 295, 613, 538, 8293, 264, 24140, 3595, 281], "temperature": 0.0, "avg_logprob": -0.17372819989226584, "compression_ratio": 1.5765765765765767, "no_speech_prob": 8.839409565553069e-05}, {"id": 112, "seek": 56460, "start": 564.6, "end": 569.08, "text": " choose what kind of attestation scheme or attestation results it gets.", "tokens": [2826, 437, 733, 295, 951, 377, 399, 12232, 420, 951, 377, 399, 3542, 309, 2170, 13], "temperature": 0.0, "avg_logprob": -0.16517135983421688, "compression_ratio": 1.738396624472574, "no_speech_prob": 4.595937571139075e-05}, {"id": 113, "seek": 56460, "start": 569.08, "end": 574.28, "text": " So you can get, for example, specially crafted attestation results that have blinded or deducted", "tokens": [407, 291, 393, 483, 11, 337, 1365, 11, 22549, 36213, 951, 377, 399, 3542, 300, 362, 6865, 292, 420, 31513, 292], "temperature": 0.0, "avg_logprob": -0.16517135983421688, "compression_ratio": 1.738396624472574, "no_speech_prob": 4.595937571139075e-05}, {"id": 114, "seek": 56460, "start": 574.28, "end": 580.72, "text": " some of the metadata, or schemes like direct anonymous attestation that provides some sort", "tokens": [512, 295, 264, 26603, 11, 420, 26954, 411, 2047, 24932, 951, 377, 399, 300, 6417, 512, 1333], "temperature": 0.0, "avg_logprob": -0.16517135983421688, "compression_ratio": 1.738396624472574, "no_speech_prob": 4.595937571139075e-05}, {"id": 115, "seek": 56460, "start": 580.72, "end": 583.72, "text": " of privacy.", "tokens": [295, 11427, 13], "temperature": 0.0, "avg_logprob": -0.16517135983421688, "compression_ratio": 1.738396624472574, "no_speech_prob": 4.595937571139075e-05}, {"id": 116, "seek": 56460, "start": 583.72, "end": 585.48, "text": " Moving on to the practice.", "tokens": [14242, 322, 281, 264, 3124, 13], "temperature": 0.0, "avg_logprob": -0.16517135983421688, "compression_ratio": 1.738396624472574, "no_speech_prob": 4.595937571139075e-05}, {"id": 117, "seek": 56460, "start": 585.48, "end": 588.2, "text": " So looking at our prototype.", "tokens": [407, 1237, 412, 527, 19475, 13], "temperature": 0.0, "avg_logprob": -0.16517135983421688, "compression_ratio": 1.738396624472574, "no_speech_prob": 4.595937571139075e-05}, {"id": 118, "seek": 56460, "start": 588.2, "end": 592.48, "text": " The big picture here is that we are trying to produce an end-to-end prototype of this", "tokens": [440, 955, 3036, 510, 307, 300, 321, 366, 1382, 281, 5258, 364, 917, 12, 1353, 12, 521, 19475, 295, 341], "temperature": 0.0, "avg_logprob": -0.16517135983421688, "compression_ratio": 1.738396624472574, "no_speech_prob": 4.595937571139075e-05}, {"id": 119, "seek": 59248, "start": 592.48, "end": 597.48, "text": " system, so we're trying to implement everything from the root of trust all the way to the", "tokens": [1185, 11, 370, 321, 434, 1382, 281, 4445, 1203, 490, 264, 5593, 295, 3361, 439, 264, 636, 281, 264], "temperature": 0.0, "avg_logprob": -0.18829476205926193, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.00010781358287204057}, {"id": 120, "seek": 59248, "start": 597.48, "end": 599.88, "text": " verifier.", "tokens": [1306, 9902, 13], "temperature": 0.0, "avg_logprob": -0.18829476205926193, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.00010781358287204057}, {"id": 121, "seek": 59248, "start": 599.88, "end": 605.72, "text": " And we're sort of limiting this because our drafts and our theoretical work is quite broad", "tokens": [400, 321, 434, 1333, 295, 22083, 341, 570, 527, 11206, 82, 293, 527, 20864, 589, 307, 1596, 4152], "temperature": 0.0, "avg_logprob": -0.18829476205926193, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.00010781358287204057}, {"id": 122, "seek": 59248, "start": 605.72, "end": 610.28, "text": " and allows a lot of deployment patterns, we're limiting this to, for example, a background", "tokens": [293, 4045, 257, 688, 295, 19317, 8294, 11, 321, 434, 22083, 341, 281, 11, 337, 1365, 11, 257, 3678], "temperature": 0.0, "avg_logprob": -0.18829476205926193, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.00010781358287204057}, {"id": 123, "seek": 59248, "start": 610.28, "end": 617.28, "text": " check model that I'll talk about in a bit, and the TPM 2.0 as the root of trust.", "tokens": [1520, 2316, 300, 286, 603, 751, 466, 294, 257, 857, 11, 293, 264, 314, 18819, 568, 13, 15, 382, 264, 5593, 295, 3361, 13], "temperature": 0.0, "avg_logprob": -0.18829476205926193, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.00010781358287204057}, {"id": 124, "seek": 61728, "start": 617.28, "end": 623.72, "text": " And obviously we're open sourcing the entire stack, and also because these components that", "tokens": [400, 2745, 321, 434, 1269, 11006, 2175, 264, 2302, 8630, 11, 293, 611, 570, 613, 6677, 300], "temperature": 0.0, "avg_logprob": -0.2534460899157402, "compression_ratio": 1.7342995169082125, "no_speech_prob": 2.010138450714294e-05}, {"id": 125, "seek": 61728, "start": 623.72, "end": 628.52, "text": " we're using are already open source software, parts of, for example, a cloud native computing", "tokens": [321, 434, 1228, 366, 1217, 1269, 4009, 4722, 11, 3166, 295, 11, 337, 1365, 11, 257, 4588, 8470, 15866], "temperature": 0.0, "avg_logprob": -0.2534460899157402, "compression_ratio": 1.7342995169082125, "no_speech_prob": 2.010138450714294e-05}, {"id": 126, "seek": 61728, "start": 628.52, "end": 633.68, "text": " foundation or a confidential computing consortium, and it's actually under the confidential computing", "tokens": [7030, 420, 257, 27054, 15866, 38343, 2197, 11, 293, 309, 311, 767, 833, 264, 27054, 15866], "temperature": 0.0, "avg_logprob": -0.2534460899157402, "compression_ratio": 1.7342995169082125, "no_speech_prob": 2.010138450714294e-05}, {"id": 127, "seek": 61728, "start": 633.68, "end": 641.0799999999999, "text": " consortium attestation special interest group that our work is harbored.", "tokens": [38343, 2197, 951, 377, 399, 2121, 1179, 1594, 300, 527, 589, 307, 2233, 65, 2769, 13], "temperature": 0.0, "avg_logprob": -0.2534460899157402, "compression_ratio": 1.7342995169082125, "no_speech_prob": 2.010138450714294e-05}, {"id": 128, "seek": 64108, "start": 641.08, "end": 647.9200000000001, "text": " Moving back actually to the remote attestation diagram, architecture diagram, you can see", "tokens": [14242, 646, 767, 281, 264, 8607, 951, 377, 399, 10686, 11, 9482, 10686, 11, 291, 393, 536], "temperature": 0.0, "avg_logprob": -0.1608101169714767, "compression_ratio": 1.857843137254902, "no_speech_prob": 1.6620735550532117e-05}, {"id": 129, "seek": 64108, "start": 647.9200000000001, "end": 654.0, "text": " here a simplified version of that, so on the bottom you can see an attestor with an existing", "tokens": [510, 257, 26335, 3037, 295, 300, 11, 370, 322, 264, 2767, 291, 393, 536, 364, 951, 377, 284, 365, 364, 6741], "temperature": 0.0, "avg_logprob": -0.1608101169714767, "compression_ratio": 1.857843137254902, "no_speech_prob": 1.6620735550532117e-05}, {"id": 130, "seek": 64108, "start": 654.0, "end": 660.24, "text": " root of trust, and the attestor wants to communicate with the relying party to authenticate it,", "tokens": [5593, 295, 3361, 11, 293, 264, 951, 377, 284, 2738, 281, 7890, 365, 264, 24140, 3595, 281, 9214, 8700, 309, 11], "temperature": 0.0, "avg_logprob": -0.1608101169714767, "compression_ratio": 1.857843137254902, "no_speech_prob": 1.6620735550532117e-05}, {"id": 131, "seek": 64108, "start": 660.24, "end": 666.9200000000001, "text": " and the relying party will then send the attestation evidence over to the verifier for verification.", "tokens": [293, 264, 24140, 3595, 486, 550, 2845, 264, 951, 377, 399, 4467, 670, 281, 264, 1306, 9902, 337, 30206, 13], "temperature": 0.0, "avg_logprob": -0.1608101169714767, "compression_ratio": 1.857843137254902, "no_speech_prob": 1.6620735550532117e-05}, {"id": 132, "seek": 66692, "start": 666.92, "end": 671.16, "text": " So this is what we call a background check model because the relying party is doing a", "tokens": [407, 341, 307, 437, 321, 818, 257, 3678, 1520, 2316, 570, 264, 24140, 3595, 307, 884, 257], "temperature": 0.0, "avg_logprob": -0.14374750985039605, "compression_ratio": 1.7783505154639174, "no_speech_prob": 9.570480324327946e-05}, {"id": 133, "seek": 66692, "start": 671.16, "end": 678.76, "text": " background check on the evidence provided by the attestor, and in our case if we put", "tokens": [3678, 1520, 322, 264, 4467, 5649, 538, 264, 951, 377, 284, 11, 293, 294, 527, 1389, 498, 321, 829], "temperature": 0.0, "avg_logprob": -0.14374750985039605, "compression_ratio": 1.7783505154639174, "no_speech_prob": 9.570480324327946e-05}, {"id": 134, "seek": 66692, "start": 678.76, "end": 684.36, "text": " a bit more flesh onto this diagram, you can see that in our case the attestor will be", "tokens": [257, 857, 544, 12497, 3911, 341, 10686, 11, 291, 393, 536, 300, 294, 527, 1389, 264, 951, 377, 284, 486, 312], "temperature": 0.0, "avg_logprob": -0.14374750985039605, "compression_ratio": 1.7783505154639174, "no_speech_prob": 9.570480324327946e-05}, {"id": 135, "seek": 66692, "start": 684.36, "end": 691.16, "text": " a client in a TLS handshake, and the relying party will be the server, and the TLS stack", "tokens": [257, 6423, 294, 257, 314, 19198, 2377, 34593, 11, 293, 264, 24140, 3595, 486, 312, 264, 7154, 11, 293, 264, 314, 19198, 8630], "temperature": 0.0, "avg_logprob": -0.14374750985039605, "compression_ratio": 1.7783505154639174, "no_speech_prob": 9.570480324327946e-05}, {"id": 136, "seek": 69116, "start": 691.16, "end": 698.0799999999999, "text": " that we're using is MBET-TLS, and the client will essentially send attestation evidence", "tokens": [300, 321, 434, 1228, 307, 28866, 4850, 12, 51, 19198, 11, 293, 264, 6423, 486, 4476, 2845, 951, 377, 399, 4467], "temperature": 0.0, "avg_logprob": -0.2237384899242504, "compression_ratio": 1.7541666666666667, "no_speech_prob": 8.060353138716891e-05}, {"id": 137, "seek": 69116, "start": 698.0799999999999, "end": 705.6, "text": " produced by the client's root of trust, and the MBET-TLS on the client side will communicate", "tokens": [7126, 538, 264, 6423, 311, 5593, 295, 3361, 11, 293, 264, 28866, 4850, 12, 51, 19198, 322, 264, 6423, 1252, 486, 7890], "temperature": 0.0, "avg_logprob": -0.2237384899242504, "compression_ratio": 1.7541666666666667, "no_speech_prob": 8.060353138716891e-05}, {"id": 138, "seek": 69116, "start": 705.6, "end": 710.0, "text": " with the root of trust not directly, but through Parsec, which is one of the projects that", "tokens": [365, 264, 5593, 295, 3361, 406, 3838, 11, 457, 807, 3457, 8159, 11, 597, 307, 472, 295, 264, 4455, 300], "temperature": 0.0, "avg_logprob": -0.2237384899242504, "compression_ratio": 1.7541666666666667, "no_speech_prob": 8.060353138716891e-05}, {"id": 139, "seek": 69116, "start": 710.0, "end": 714.3199999999999, "text": " we've been developing, and on the server side you have MBET-TLS again communicating with", "tokens": [321, 600, 668, 6416, 11, 293, 322, 264, 7154, 1252, 291, 362, 28866, 4850, 12, 51, 19198, 797, 17559, 365], "temperature": 0.0, "avg_logprob": -0.2237384899242504, "compression_ratio": 1.7541666666666667, "no_speech_prob": 8.060353138716891e-05}, {"id": 140, "seek": 69116, "start": 714.3199999999999, "end": 719.88, "text": " the verifier, which is in our case composed using Uvaraison.", "tokens": [264, 1306, 9902, 11, 597, 307, 294, 527, 1389, 18204, 1228, 624, 85, 2419, 2770, 13], "temperature": 0.0, "avg_logprob": -0.2237384899242504, "compression_ratio": 1.7541666666666667, "no_speech_prob": 8.060353138716891e-05}, {"id": 141, "seek": 71988, "start": 719.88, "end": 724.36, "text": " So now let's have a look at all of these components independently.", "tokens": [407, 586, 718, 311, 362, 257, 574, 412, 439, 295, 613, 6677, 21761, 13], "temperature": 0.0, "avg_logprob": -0.1543311716240143, "compression_ratio": 1.5517241379310345, "no_speech_prob": 3.8634443626506254e-05}, {"id": 142, "seek": 71988, "start": 724.36, "end": 725.36, "text": " So Parsec.", "tokens": [407, 3457, 8159, 13], "temperature": 0.0, "avg_logprob": -0.1543311716240143, "compression_ratio": 1.5517241379310345, "no_speech_prob": 3.8634443626506254e-05}, {"id": 143, "seek": 71988, "start": 725.36, "end": 726.36, "text": " What is Parsec?", "tokens": [708, 307, 3457, 8159, 30], "temperature": 0.0, "avg_logprob": -0.1543311716240143, "compression_ratio": 1.5517241379310345, "no_speech_prob": 3.8634443626506254e-05}, {"id": 144, "seek": 71988, "start": 726.36, "end": 729.16, "text": " Parsec is a platform abstraction for security.", "tokens": [3457, 8159, 307, 257, 3663, 37765, 337, 3825, 13], "temperature": 0.0, "avg_logprob": -0.1543311716240143, "compression_ratio": 1.5517241379310345, "no_speech_prob": 3.8634443626506254e-05}, {"id": 145, "seek": 71988, "start": 729.16, "end": 735.68, "text": " So if you try to write an application in Java or Python or Go, you might want to use some", "tokens": [407, 498, 291, 853, 281, 2464, 364, 3861, 294, 10745, 420, 15329, 420, 1037, 11, 291, 1062, 528, 281, 764, 512], "temperature": 0.0, "avg_logprob": -0.1543311716240143, "compression_ratio": 1.5517241379310345, "no_speech_prob": 3.8634443626506254e-05}, {"id": 146, "seek": 71988, "start": 735.68, "end": 740.36, "text": " sort of cryptographic hardware backing, so for example a discrete EPM or some trusted", "tokens": [1333, 295, 9844, 12295, 8837, 19373, 11, 370, 337, 1365, 257, 27706, 462, 18819, 420, 512, 16034], "temperature": 0.0, "avg_logprob": -0.1543311716240143, "compression_ratio": 1.5517241379310345, "no_speech_prob": 3.8634443626506254e-05}, {"id": 147, "seek": 71988, "start": 740.36, "end": 746.4, "text": " services running in TrustZone, and you want to use these in a more generic way, and this", "tokens": [3328, 2614, 294, 11580, 57, 546, 11, 293, 291, 528, 281, 764, 613, 294, 257, 544, 19577, 636, 11, 293, 341], "temperature": 0.0, "avg_logprob": -0.1543311716240143, "compression_ratio": 1.5517241379310345, "no_speech_prob": 3.8634443626506254e-05}, {"id": 148, "seek": 74640, "start": 746.4, "end": 753.1999999999999, "text": " is what Parsec is doing, it's presenting a high-level interface that you can use to provision,", "tokens": [307, 437, 3457, 8159, 307, 884, 11, 309, 311, 15578, 257, 1090, 12, 12418, 9226, 300, 291, 393, 764, 281, 17225, 11], "temperature": 0.0, "avg_logprob": -0.1616650562660367, "compression_ratio": 1.6329113924050633, "no_speech_prob": 3.1265008146874607e-05}, {"id": 149, "seek": 74640, "start": 753.1999999999999, "end": 761.9599999999999, "text": " and Parsec in particular has this sort of identity key as a core use case that it works", "tokens": [293, 3457, 8159, 294, 1729, 575, 341, 1333, 295, 6575, 2141, 382, 257, 4965, 764, 1389, 300, 309, 1985], "temperature": 0.0, "avg_logprob": -0.1616650562660367, "compression_ratio": 1.6329113924050633, "no_speech_prob": 3.1265008146874607e-05}, {"id": 150, "seek": 74640, "start": 761.9599999999999, "end": 767.56, "text": " with, so it tries to allow you to create an identity for your workload and to use it,", "tokens": [365, 11, 370, 309, 9898, 281, 2089, 291, 281, 1884, 364, 6575, 337, 428, 20139, 293, 281, 764, 309, 11], "temperature": 0.0, "avg_logprob": -0.1616650562660367, "compression_ratio": 1.6329113924050633, "no_speech_prob": 3.1265008146874607e-05}, {"id": 151, "seek": 74640, "start": 767.56, "end": 771.1999999999999, "text": " for example, to sign TLS antics.", "tokens": [337, 1365, 11, 281, 1465, 314, 19198, 2511, 1167, 13], "temperature": 0.0, "avg_logprob": -0.1616650562660367, "compression_ratio": 1.6329113924050633, "no_speech_prob": 3.1265008146874607e-05}, {"id": 152, "seek": 74640, "start": 771.1999999999999, "end": 775.36, "text": " And Parsec is also quite modular, so it's really easy to implement backends for other", "tokens": [400, 3457, 8159, 307, 611, 1596, 31111, 11, 370, 309, 311, 534, 1858, 281, 4445, 646, 2581, 337, 661], "temperature": 0.0, "avg_logprob": -0.1616650562660367, "compression_ratio": 1.6329113924050633, "no_speech_prob": 3.1265008146874607e-05}, {"id": 153, "seek": 77536, "start": 775.36, "end": 783.04, "text": " types of hardware backends that you might want to support.", "tokens": [3467, 295, 8837, 646, 2581, 300, 291, 1062, 528, 281, 1406, 13], "temperature": 0.0, "avg_logprob": -0.1663436496380678, "compression_ratio": 1.7058823529411764, "no_speech_prob": 7.32496555428952e-05}, {"id": 154, "seek": 77536, "start": 783.04, "end": 788.0, "text": " Moving on to the other end, so we have Varaison, which is a set of components that can be used", "tokens": [14242, 322, 281, 264, 661, 917, 11, 370, 321, 362, 691, 2419, 2770, 11, 597, 307, 257, 992, 295, 6677, 300, 393, 312, 1143], "temperature": 0.0, "avg_logprob": -0.1663436496380678, "compression_ratio": 1.7058823529411764, "no_speech_prob": 7.32496555428952e-05}, {"id": 155, "seek": 77536, "start": 788.0, "end": 791.6, "text": " to build an attestation verification service.", "tokens": [281, 1322, 364, 951, 377, 399, 30206, 2643, 13], "temperature": 0.0, "avg_logprob": -0.1663436496380678, "compression_ratio": 1.7058823529411764, "no_speech_prob": 7.32496555428952e-05}, {"id": 156, "seek": 77536, "start": 791.6, "end": 796.8000000000001, "text": " So again, Varaison is pretty abstract, it has a bunch of components, for example, for", "tokens": [407, 797, 11, 691, 2419, 2770, 307, 1238, 12649, 11, 309, 575, 257, 3840, 295, 6677, 11, 337, 1365, 11, 337], "temperature": 0.0, "avg_logprob": -0.1663436496380678, "compression_ratio": 1.7058823529411764, "no_speech_prob": 7.32496555428952e-05}, {"id": 157, "seek": 77536, "start": 796.8000000000001, "end": 801.8000000000001, "text": " appraising different types of attestation schemes, as components for building, for example,", "tokens": [724, 424, 3436, 819, 3467, 295, 951, 377, 399, 26954, 11, 382, 6677, 337, 2390, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.1663436496380678, "compression_ratio": 1.7058823529411764, "no_speech_prob": 7.32496555428952e-05}, {"id": 158, "seek": 80180, "start": 801.8, "end": 809.88, "text": " APIs for evidence provisioning, or for endorsement provisioning for verification APIs.", "tokens": [21445, 337, 4467, 17225, 278, 11, 420, 337, 29228, 518, 17225, 278, 337, 30206, 21445, 13], "temperature": 0.0, "avg_logprob": -0.1439502316136514, "compression_ratio": 1.621301775147929, "no_speech_prob": 5.518402758752927e-05}, {"id": 159, "seek": 80180, "start": 809.88, "end": 817.8, "text": " So in this diagram here, some factories is creating a device and then producing the endorsement", "tokens": [407, 294, 341, 10686, 510, 11, 512, 24813, 307, 4084, 257, 4302, 293, 550, 10501, 264, 29228, 518], "temperature": 0.0, "avg_logprob": -0.1439502316136514, "compression_ratio": 1.621301775147929, "no_speech_prob": 5.518402758752927e-05}, {"id": 160, "seek": 80180, "start": 817.8, "end": 823.8, "text": " data that it then feeds to Varaison, and when the device tries to connect to an application", "tokens": [1412, 300, 309, 550, 23712, 281, 691, 2419, 2770, 11, 293, 562, 264, 4302, 9898, 281, 1745, 281, 364, 3861], "temperature": 0.0, "avg_logprob": -0.1439502316136514, "compression_ratio": 1.621301775147929, "no_speech_prob": 5.518402758752927e-05}, {"id": 161, "seek": 82380, "start": 823.8, "end": 832.28, "text": " service, that application service can again go to Varaison to verify those credentials.", "tokens": [2643, 11, 300, 3861, 2643, 393, 797, 352, 281, 691, 2419, 2770, 281, 16888, 729, 27404, 13], "temperature": 0.0, "avg_logprob": -0.10194440417819553, "compression_ratio": 1.6, "no_speech_prob": 1.5753350453451276e-05}, {"id": 162, "seek": 82380, "start": 832.28, "end": 837.88, "text": " In terms of what the work that we had to do to make this prototype work across the stack,", "tokens": [682, 2115, 295, 437, 264, 589, 300, 321, 632, 281, 360, 281, 652, 341, 19475, 589, 2108, 264, 8630, 11], "temperature": 0.0, "avg_logprob": -0.10194440417819553, "compression_ratio": 1.6, "no_speech_prob": 1.5753350453451276e-05}, {"id": 163, "seek": 82380, "start": 837.88, "end": 846.16, "text": " so Parsec, as I've said, works mostly with cryptographic keys, however, at the moment,", "tokens": [370, 3457, 8159, 11, 382, 286, 600, 848, 11, 1985, 5240, 365, 9844, 12295, 9317, 11, 4461, 11, 412, 264, 1623, 11], "temperature": 0.0, "avg_logprob": -0.10194440417819553, "compression_ratio": 1.6, "no_speech_prob": 1.5753350453451276e-05}, {"id": 164, "seek": 82380, "start": 846.16, "end": 851.64, "text": " we didn't have a very generic key attestation API, and this is something that we had to", "tokens": [321, 994, 380, 362, 257, 588, 19577, 2141, 951, 377, 399, 9362, 11, 293, 341, 307, 746, 300, 321, 632, 281], "temperature": 0.0, "avg_logprob": -0.10194440417819553, "compression_ratio": 1.6, "no_speech_prob": 1.5753350453451276e-05}, {"id": 165, "seek": 85164, "start": 851.64, "end": 858.08, "text": " build to produce those attestation tokens or attestation evidence.", "tokens": [1322, 281, 5258, 729, 951, 377, 399, 22667, 420, 951, 377, 399, 4467, 13], "temperature": 0.0, "avg_logprob": -0.17331722529247554, "compression_ratio": 1.7956521739130435, "no_speech_prob": 4.926186738885008e-05}, {"id": 166, "seek": 85164, "start": 858.08, "end": 864.1999999999999, "text": " Parsec also needs to have configuration to allow it to essentially provision its own", "tokens": [3457, 8159, 611, 2203, 281, 362, 11694, 281, 2089, 309, 281, 4476, 17225, 1080, 1065], "temperature": 0.0, "avg_logprob": -0.17331722529247554, "compression_ratio": 1.7956521739130435, "no_speech_prob": 4.926186738885008e-05}, {"id": 167, "seek": 85164, "start": 864.1999999999999, "end": 869.92, "text": " identity, so an attesting key that it can use to sign attestation credentials, and also", "tokens": [6575, 11, 370, 364, 951, 8714, 2141, 300, 309, 393, 764, 281, 1465, 951, 377, 399, 27404, 11, 293, 611], "temperature": 0.0, "avg_logprob": -0.17331722529247554, "compression_ratio": 1.7956521739130435, "no_speech_prob": 4.926186738885008e-05}, {"id": 168, "seek": 85164, "start": 869.92, "end": 874.28, "text": " ways to, for example, select the TPM PCRs that you want to include in the attestation", "tokens": [2098, 281, 11, 337, 1365, 11, 3048, 264, 314, 18819, 44022, 82, 300, 291, 528, 281, 4090, 294, 264, 951, 377, 399], "temperature": 0.0, "avg_logprob": -0.17331722529247554, "compression_ratio": 1.7956521739130435, "no_speech_prob": 4.926186738885008e-05}, {"id": 169, "seek": 85164, "start": 874.28, "end": 880.28, "text": " tokens, for example, to select whether you want to send information about your firmware", "tokens": [22667, 11, 337, 1365, 11, 281, 3048, 1968, 291, 528, 281, 2845, 1589, 466, 428, 30289], "temperature": 0.0, "avg_logprob": -0.17331722529247554, "compression_ratio": 1.7956521739130435, "no_speech_prob": 4.926186738885008e-05}, {"id": 170, "seek": 88028, "start": 880.28, "end": 888.0, "text": " or about your bootloader or about your operating system kernel, and we also have a new API", "tokens": [420, 466, 428, 11450, 2907, 260, 420, 466, 428, 7447, 1185, 28256, 11, 293, 321, 611, 362, 257, 777, 9362], "temperature": 0.0, "avg_logprob": -0.13083439562694135, "compression_ratio": 1.6864864864864866, "no_speech_prob": 2.128892083419487e-05}, {"id": 171, "seek": 88028, "start": 888.0, "end": 895.9599999999999, "text": " to produce the endorsements that are then fed to Varaison for endorsements, so Varaison", "tokens": [281, 5258, 264, 29228, 1117, 300, 366, 550, 4636, 281, 691, 2419, 2770, 337, 29228, 1117, 11, 370, 691, 2419, 2770], "temperature": 0.0, "avg_logprob": -0.13083439562694135, "compression_ratio": 1.6864864864864866, "no_speech_prob": 2.128892083419487e-05}, {"id": 172, "seek": 88028, "start": 895.9599999999999, "end": 901.24, "text": " can then trust the key attestation tokens.", "tokens": [393, 550, 3361, 264, 2141, 951, 377, 399, 22667, 13], "temperature": 0.0, "avg_logprob": -0.13083439562694135, "compression_ratio": 1.6864864864864866, "no_speech_prob": 2.128892083419487e-05}, {"id": 173, "seek": 88028, "start": 901.24, "end": 908.04, "text": " On the Varaison side, again, we have to add support for the precise attestation key scheme", "tokens": [1282, 264, 691, 2419, 2770, 1252, 11, 797, 11, 321, 362, 281, 909, 1406, 337, 264, 13600, 951, 377, 399, 2141, 12232], "temperature": 0.0, "avg_logprob": -0.13083439562694135, "compression_ratio": 1.6864864864864866, "no_speech_prob": 2.128892083419487e-05}, {"id": 174, "seek": 90804, "start": 908.04, "end": 914.4399999999999, "text": " that we're using, and essentially, we have to build two new plugins, so one to understand", "tokens": [300, 321, 434, 1228, 11, 293, 4476, 11, 321, 362, 281, 1322, 732, 777, 33759, 11, 370, 472, 281, 1223], "temperature": 0.0, "avg_logprob": -0.16384928005257832, "compression_ratio": 1.7522522522522523, "no_speech_prob": 0.00012757489457726479}, {"id": 175, "seek": 90804, "start": 914.4399999999999, "end": 921.12, "text": " the evidence that we're producing for Parsec, and one to understand the endorsements.", "tokens": [264, 4467, 300, 321, 434, 10501, 337, 3457, 8159, 11, 293, 472, 281, 1223, 264, 29228, 1117, 13], "temperature": 0.0, "avg_logprob": -0.16384928005257832, "compression_ratio": 1.7522522522522523, "no_speech_prob": 0.00012757489457726479}, {"id": 176, "seek": 90804, "start": 921.12, "end": 924.92, "text": " So what essentially we're doing here is we have two components, and we're trying to make", "tokens": [407, 437, 4476, 321, 434, 884, 510, 307, 321, 362, 732, 6677, 11, 293, 321, 434, 1382, 281, 652], "temperature": 0.0, "avg_logprob": -0.16384928005257832, "compression_ratio": 1.7522522522522523, "no_speech_prob": 0.00012757489457726479}, {"id": 177, "seek": 90804, "start": 924.92, "end": 933.3199999999999, "text": " them agnostic of whatever is transporting evidence and endorsements between them, which,", "tokens": [552, 623, 77, 19634, 295, 2035, 307, 49302, 4467, 293, 29228, 1117, 1296, 552, 11, 597, 11], "temperature": 0.0, "avg_logprob": -0.16384928005257832, "compression_ratio": 1.7522522522522523, "no_speech_prob": 0.00012757489457726479}, {"id": 178, "seek": 90804, "start": 933.3199999999999, "end": 935.68, "text": " in our case, is actually a bad TLS.", "tokens": [294, 527, 1389, 11, 307, 767, 257, 1578, 314, 19198, 13], "temperature": 0.0, "avg_logprob": -0.16384928005257832, "compression_ratio": 1.7522522522522523, "no_speech_prob": 0.00012757489457726479}, {"id": 179, "seek": 93568, "start": 935.68, "end": 940.76, "text": " So the TLS implementation that we're using, the TLS, it's an implementation of TLS and", "tokens": [407, 264, 314, 19198, 11420, 300, 321, 434, 1228, 11, 264, 314, 19198, 11, 309, 311, 364, 11420, 295, 314, 19198, 293], "temperature": 0.0, "avg_logprob": -0.17608392238616943, "compression_ratio": 1.6916666666666667, "no_speech_prob": 9.312967449659482e-05}, {"id": 180, "seek": 93568, "start": 940.76, "end": 945.28, "text": " the TLS, and the reason why, it's actually multiple reasons why we're using it, so one", "tokens": [264, 314, 19198, 11, 293, 264, 1778, 983, 11, 309, 311, 767, 3866, 4112, 983, 321, 434, 1228, 309, 11, 370, 472], "temperature": 0.0, "avg_logprob": -0.17608392238616943, "compression_ratio": 1.6916666666666667, "no_speech_prob": 9.312967449659482e-05}, {"id": 181, "seek": 93568, "start": 945.28, "end": 953.8399999999999, "text": " of them is because it offers this PSA crypto API, which Parsec hooks into, as per our design,", "tokens": [295, 552, 307, 570, 309, 7736, 341, 8168, 32, 17240, 9362, 11, 597, 3457, 8159, 26485, 666, 11, 382, 680, 527, 1715, 11], "temperature": 0.0, "avg_logprob": -0.17608392238616943, "compression_ratio": 1.6916666666666667, "no_speech_prob": 9.312967449659482e-05}, {"id": 182, "seek": 93568, "start": 953.8399999999999, "end": 959.52, "text": " since we created it in sync with the PSA crypto API.", "tokens": [1670, 321, 2942, 309, 294, 20271, 365, 264, 8168, 32, 17240, 9362, 13], "temperature": 0.0, "avg_logprob": -0.17608392238616943, "compression_ratio": 1.6916666666666667, "no_speech_prob": 9.312967449659482e-05}, {"id": 183, "seek": 93568, "start": 959.52, "end": 964.92, "text": " It also has a small code footprint, so it's more suitable for IoT and Edge use cases,", "tokens": [467, 611, 575, 257, 1359, 3089, 24222, 11, 370, 309, 311, 544, 12873, 337, 30112, 293, 19328, 764, 3331, 11], "temperature": 0.0, "avg_logprob": -0.17608392238616943, "compression_ratio": 1.6916666666666667, "no_speech_prob": 9.312967449659482e-05}, {"id": 184, "seek": 96492, "start": 964.92, "end": 969.36, "text": " like the one that I described earlier, and also we had already expertise working with", "tokens": [411, 264, 472, 300, 286, 7619, 3071, 11, 293, 611, 321, 632, 1217, 11769, 1364, 365], "temperature": 0.0, "avg_logprob": -0.18503767013549804, "compression_ratio": 1.6122448979591837, "no_speech_prob": 6.144251528894529e-05}, {"id": 185, "seek": 96492, "start": 969.36, "end": 974.0799999999999, "text": " Mbeth TLS, so it was easier for us to work with it.", "tokens": [376, 65, 3293, 314, 19198, 11, 370, 309, 390, 3571, 337, 505, 281, 589, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.18503767013549804, "compression_ratio": 1.6122448979591837, "no_speech_prob": 6.144251528894529e-05}, {"id": 186, "seek": 96492, "start": 974.0799999999999, "end": 979.8, "text": " So the open source ecosystem around our projects, and this is something that has been quite important", "tokens": [407, 264, 1269, 4009, 11311, 926, 527, 4455, 11, 293, 341, 307, 746, 300, 575, 668, 1596, 1021], "temperature": 0.0, "avg_logprob": -0.18503767013549804, "compression_ratio": 1.6122448979591837, "no_speech_prob": 6.144251528894529e-05}, {"id": 187, "seek": 96492, "start": 979.8, "end": 986.56, "text": " for me in the past years while I've been working on Parsec, realizing that open source is more", "tokens": [337, 385, 294, 264, 1791, 924, 1339, 286, 600, 668, 1364, 322, 3457, 8159, 11, 16734, 300, 1269, 4009, 307, 544], "temperature": 0.0, "avg_logprob": -0.18503767013549804, "compression_ratio": 1.6122448979591837, "no_speech_prob": 6.144251528894529e-05}, {"id": 188, "seek": 96492, "start": 986.56, "end": 990.28, "text": " than just some checkbox that we want to take, and that's it.", "tokens": [813, 445, 512, 1520, 4995, 300, 321, 528, 281, 747, 11, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.18503767013549804, "compression_ratio": 1.6122448979591837, "no_speech_prob": 6.144251528894529e-05}, {"id": 189, "seek": 99028, "start": 990.28, "end": 997.4399999999999, "text": " It's more about the continuous involvement in the community and trying to pull the expertise", "tokens": [467, 311, 544, 466, 264, 10957, 17447, 294, 264, 1768, 293, 1382, 281, 2235, 264, 11769], "temperature": 0.0, "avg_logprob": -0.1626441776752472, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.00014910601021256298}, {"id": 190, "seek": 99028, "start": 997.4399999999999, "end": 1006.4, "text": " and the work required to create some components that we can reuse across all of our stacks.", "tokens": [293, 264, 589, 4739, 281, 1884, 512, 6677, 300, 321, 393, 26225, 2108, 439, 295, 527, 30792, 13], "temperature": 0.0, "avg_logprob": -0.1626441776752472, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.00014910601021256298}, {"id": 191, "seek": 99028, "start": 1006.4, "end": 1013.04, "text": " And yeah, this is the reason why we've been seeding projects into CNCF and CCC, because", "tokens": [400, 1338, 11, 341, 307, 264, 1778, 983, 321, 600, 668, 8871, 278, 4455, 666, 48714, 37, 293, 383, 11717, 11, 570], "temperature": 0.0, "avg_logprob": -0.1626441776752472, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.00014910601021256298}, {"id": 192, "seek": 101304, "start": 1013.04, "end": 1020.4, "text": " we're trying to create these communities around our projects and create the ecosystems around", "tokens": [321, 434, 1382, 281, 1884, 613, 4456, 926, 527, 4455, 293, 1884, 264, 32647, 926], "temperature": 0.0, "avg_logprob": -0.1417803925074888, "compression_ratio": 1.68, "no_speech_prob": 1.5088331565493718e-05}, {"id": 193, "seek": 101304, "start": 1020.4, "end": 1022.9599999999999, "text": " our use cases.", "tokens": [527, 764, 3331, 13], "temperature": 0.0, "avg_logprob": -0.1417803925074888, "compression_ratio": 1.68, "no_speech_prob": 1.5088331565493718e-05}, {"id": 194, "seek": 101304, "start": 1022.9599999999999, "end": 1028.36, "text": " So if we look at the Rust ecosystem in particular, for example, because the Parsec service is", "tokens": [407, 498, 321, 574, 412, 264, 34952, 11311, 294, 1729, 11, 337, 1365, 11, 570, 264, 3457, 8159, 2643, 307], "temperature": 0.0, "avg_logprob": -0.1417803925074888, "compression_ratio": 1.68, "no_speech_prob": 1.5088331565493718e-05}, {"id": 195, "seek": 101304, "start": 1028.36, "end": 1034.32, "text": " written in Rust, we've released a number of crates relevant to handling routes of trust.", "tokens": [3720, 294, 34952, 11, 321, 600, 4736, 257, 1230, 295, 941, 1024, 7340, 281, 13175, 18242, 295, 3361, 13], "temperature": 0.0, "avg_logprob": -0.1417803925074888, "compression_ratio": 1.68, "no_speech_prob": 1.5088331565493718e-05}, {"id": 196, "seek": 101304, "start": 1034.32, "end": 1041.68, "text": " So for example, we've released the TSA API crates that helps with interacting natively", "tokens": [407, 337, 1365, 11, 321, 600, 4736, 264, 314, 8886, 9362, 941, 1024, 300, 3665, 365, 18017, 8470, 356], "temperature": 0.0, "avg_logprob": -0.1417803925074888, "compression_ratio": 1.68, "no_speech_prob": 1.5088331565493718e-05}, {"id": 197, "seek": 104168, "start": 1041.68, "end": 1043.52, "text": " with TPMs.", "tokens": [365, 314, 18819, 82, 13], "temperature": 0.0, "avg_logprob": -0.2034545342127482, "compression_ratio": 1.5991902834008098, "no_speech_prob": 5.048669845564291e-05}, {"id": 198, "seek": 104168, "start": 1043.52, "end": 1048.88, "text": " We've released the CryptoKey crate, which is essentially a successor to the PKS11 crate", "tokens": [492, 600, 4736, 264, 34809, 78, 42, 2030, 42426, 11, 597, 307, 4476, 257, 31864, 281, 264, 430, 31558, 5348, 42426], "temperature": 0.0, "avg_logprob": -0.2034545342127482, "compression_ratio": 1.5991902834008098, "no_speech_prob": 5.048669845564291e-05}, {"id": 199, "seek": 104168, "start": 1048.88, "end": 1055.24, "text": " that was abandoned some time ago, and we have the PSA CryptoCrate that allows native interaction", "tokens": [300, 390, 13732, 512, 565, 2057, 11, 293, 321, 362, 264, 8168, 32, 34809, 78, 34, 4404, 300, 4045, 8470, 9285], "temperature": 0.0, "avg_logprob": -0.2034545342127482, "compression_ratio": 1.5991902834008098, "no_speech_prob": 5.048669845564291e-05}, {"id": 200, "seek": 104168, "start": 1055.24, "end": 1063.52, "text": " with PSA Cryptography API, and it's actually been quite a nice experience to see the communities", "tokens": [365, 8168, 32, 34809, 5820, 9362, 11, 293, 309, 311, 767, 668, 1596, 257, 1481, 1752, 281, 536, 264, 4456], "temperature": 0.0, "avg_logprob": -0.2034545342127482, "compression_ratio": 1.5991902834008098, "no_speech_prob": 5.048669845564291e-05}, {"id": 201, "seek": 104168, "start": 1063.52, "end": 1069.76, "text": " around these projects grow and have more developers from various projects, some of which have actually", "tokens": [926, 613, 4455, 1852, 293, 362, 544, 8849, 490, 3683, 4455, 11, 512, 295, 597, 362, 767], "temperature": 0.0, "avg_logprob": -0.2034545342127482, "compression_ratio": 1.5991902834008098, "no_speech_prob": 5.048669845564291e-05}, {"id": 202, "seek": 106976, "start": 1069.76, "end": 1075.12, "text": " presented today getting involved and helping us build this ecosystem.", "tokens": [8212, 965, 1242, 3288, 293, 4315, 505, 1322, 341, 11311, 13], "temperature": 0.0, "avg_logprob": -0.15999714724988823, "compression_ratio": 1.5246636771300448, "no_speech_prob": 4.3914697016589344e-05}, {"id": 203, "seek": 106976, "start": 1075.12, "end": 1081.92, "text": " Yeah, the more important goal for us, at least, is not just to make these particular backends", "tokens": [865, 11, 264, 544, 1021, 3387, 337, 505, 11, 412, 1935, 11, 307, 406, 445, 281, 652, 613, 1729, 646, 2581], "temperature": 0.0, "avg_logprob": -0.15999714724988823, "compression_ratio": 1.5246636771300448, "no_speech_prob": 4.3914697016589344e-05}, {"id": 204, "seek": 106976, "start": 1081.92, "end": 1087.68, "text": " easy to use in Rust, but perhaps even to make them easy to use in an abstract way.", "tokens": [1858, 281, 764, 294, 34952, 11, 457, 4317, 754, 281, 652, 552, 1858, 281, 764, 294, 364, 12649, 636, 13], "temperature": 0.0, "avg_logprob": -0.15999714724988823, "compression_ratio": 1.5246636771300448, "no_speech_prob": 4.3914697016589344e-05}, {"id": 205, "seek": 106976, "start": 1087.68, "end": 1094.32, "text": " So instead of having to integrate with TPMs or PKS11 individually, what if we could integrate", "tokens": [407, 2602, 295, 1419, 281, 13365, 365, 314, 18819, 82, 420, 430, 31558, 5348, 16652, 11, 437, 498, 321, 727, 13365], "temperature": 0.0, "avg_logprob": -0.15999714724988823, "compression_ratio": 1.5246636771300448, "no_speech_prob": 4.3914697016589344e-05}, {"id": 206, "seek": 109432, "start": 1094.32, "end": 1100.0, "text": " with all of them via Parsec directly?", "tokens": [365, 439, 295, 552, 5766, 3457, 8159, 3838, 30], "temperature": 0.0, "avg_logprob": -0.27102749522139385, "compression_ratio": 1.4509803921568627, "no_speech_prob": 2.914952528954018e-05}, {"id": 207, "seek": 109432, "start": 1100.0, "end": 1105.9199999999998, "text": " On the Go ecosystem side, we also have a bunch of packages that we've released.", "tokens": [1282, 264, 1037, 11311, 1252, 11, 321, 611, 362, 257, 3840, 295, 17401, 300, 321, 600, 4736, 13], "temperature": 0.0, "avg_logprob": -0.27102749522139385, "compression_ratio": 1.4509803921568627, "no_speech_prob": 2.914952528954018e-05}, {"id": 208, "seek": 109432, "start": 1105.9199999999998, "end": 1112.8799999999999, "text": " A notable one is GoCosy, which I believe was initially developed by Mozilla and inabandant,", "tokens": [316, 22556, 472, 307, 1037, 34, 329, 88, 11, 597, 286, 1697, 390, 9105, 4743, 538, 3335, 26403, 293, 294, 455, 474, 394, 11], "temperature": 0.0, "avg_logprob": -0.27102749522139385, "compression_ratio": 1.4509803921568627, "no_speech_prob": 2.914952528954018e-05}, {"id": 209, "seek": 109432, "start": 1112.8799999999999, "end": 1120.0, "text": " but then our Verizon team took it over, gave it the dusting, and then released it, and", "tokens": [457, 550, 527, 44456, 1469, 1890, 309, 670, 11, 2729, 309, 264, 8634, 278, 11, 293, 550, 4736, 309, 11, 293], "temperature": 0.0, "avg_logprob": -0.27102749522139385, "compression_ratio": 1.4509803921568627, "no_speech_prob": 2.914952528954018e-05}, {"id": 210, "seek": 112000, "start": 1120.0, "end": 1125.52, "text": " now it's, I think, it's used quite widely, for example, by No3 and SixTor, and we also", "tokens": [586, 309, 311, 11, 286, 519, 11, 309, 311, 1143, 1596, 13371, 11, 337, 1365, 11, 538, 883, 18, 293, 11678, 51, 284, 11, 293, 321, 611], "temperature": 0.0, "avg_logprob": -0.22529946160070674, "compression_ratio": 1.4897119341563787, "no_speech_prob": 3.4691165637923405e-05}, {"id": 211, "seek": 112000, "start": 1125.52, "end": 1130.08, "text": " have a bunch of other packages relevant to remote attestation verification like SWEED", "tokens": [362, 257, 3840, 295, 661, 17401, 7340, 281, 8607, 951, 377, 399, 30206, 411, 20346, 36, 4731], "temperature": 0.0, "avg_logprob": -0.22529946160070674, "compression_ratio": 1.4897119341563787, "no_speech_prob": 3.4691165637923405e-05}, {"id": 212, "seek": 112000, "start": 1130.08, "end": 1139.64, "text": " or Quorum, and yeah, this brings me to my main selling point here, is that we're trying", "tokens": [420, 2326, 36543, 11, 293, 1338, 11, 341, 5607, 385, 281, 452, 2135, 6511, 935, 510, 11, 307, 300, 321, 434, 1382], "temperature": 0.0, "avg_logprob": -0.22529946160070674, "compression_ratio": 1.4897119341563787, "no_speech_prob": 3.4691165637923405e-05}, {"id": 213, "seek": 112000, "start": 1139.64, "end": 1144.56, "text": " to essentially build an ecosystem where attestation can just be used as a plug-in for authentication.", "tokens": [281, 4476, 1322, 364, 11311, 689, 951, 377, 399, 393, 445, 312, 1143, 382, 257, 5452, 12, 259, 337, 26643, 13], "temperature": 0.0, "avg_logprob": -0.22529946160070674, "compression_ratio": 1.4897119341563787, "no_speech_prob": 3.4691165637923405e-05}, {"id": 214, "seek": 114456, "start": 1144.56, "end": 1152.32, "text": " So whether you integrate it within the authentication step of a TLS stack, or perhaps you want to", "tokens": [407, 1968, 291, 13365, 309, 1951, 264, 26643, 1823, 295, 257, 314, 19198, 8630, 11, 420, 4317, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.11194280646313196, "compression_ratio": 1.755980861244019, "no_speech_prob": 2.6633038942236453e-05}, {"id": 215, "seek": 114456, "start": 1152.32, "end": 1157.72, "text": " switch that to some sort of quick stack, or maybe you want to even have some sort of bespoke", "tokens": [3679, 300, 281, 512, 1333, 295, 1702, 8630, 11, 420, 1310, 291, 528, 281, 754, 362, 512, 1333, 295, 4097, 48776], "temperature": 0.0, "avg_logprob": -0.11194280646313196, "compression_ratio": 1.755980861244019, "no_speech_prob": 2.6633038942236453e-05}, {"id": 216, "seek": 114456, "start": 1157.72, "end": 1162.28, "text": " authentication server and workload trying to authenticate it, we're trying to make it", "tokens": [26643, 7154, 293, 20139, 1382, 281, 9214, 8700, 309, 11, 321, 434, 1382, 281, 652, 309], "temperature": 0.0, "avg_logprob": -0.11194280646313196, "compression_ratio": 1.755980861244019, "no_speech_prob": 2.6633038942236453e-05}, {"id": 217, "seek": 114456, "start": 1162.28, "end": 1169.96, "text": " easy to use remote attestation by making Parsec and Verizon interact so easily, so you can", "tokens": [1858, 281, 764, 8607, 951, 377, 399, 538, 1455, 3457, 8159, 293, 44456, 4648, 370, 3612, 11, 370, 291, 393], "temperature": 0.0, "avg_logprob": -0.11194280646313196, "compression_ratio": 1.755980861244019, "no_speech_prob": 2.6633038942236453e-05}, {"id": 218, "seek": 116996, "start": 1169.96, "end": 1177.3600000000001, "text": " just plug those components in and hopefully get attestation right as it works.", "tokens": [445, 5452, 729, 6677, 294, 293, 4696, 483, 951, 377, 399, 558, 382, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.14297132382447691, "compression_ratio": 1.6126126126126126, "no_speech_prob": 1.639616493775975e-05}, {"id": 219, "seek": 116996, "start": 1177.3600000000001, "end": 1183.92, "text": " So just to wrap up here, we think that remote attestation is indeed a viable authentication", "tokens": [407, 445, 281, 7019, 493, 510, 11, 321, 519, 300, 8607, 951, 377, 399, 307, 6451, 257, 22024, 26643], "temperature": 0.0, "avg_logprob": -0.14297132382447691, "compression_ratio": 1.6126126126126126, "no_speech_prob": 1.639616493775975e-05}, {"id": 220, "seek": 116996, "start": 1183.92, "end": 1190.56, "text": " mechanism in TLS, and perhaps in other protocols as well in the future, or design both in terms", "tokens": [7513, 294, 314, 19198, 11, 293, 4317, 294, 661, 20618, 382, 731, 294, 264, 2027, 11, 420, 1715, 1293, 294, 2115], "temperature": 0.0, "avg_logprob": -0.14297132382447691, "compression_ratio": 1.6126126126126126, "no_speech_prob": 1.639616493775975e-05}, {"id": 221, "seek": 116996, "start": 1190.56, "end": 1196.52, "text": " of theoretical design, so the drafts, the TLS extensions try to be as flexible as possible,", "tokens": [295, 20864, 1715, 11, 370, 264, 11206, 82, 11, 264, 314, 19198, 25129, 853, 281, 312, 382, 11358, 382, 1944, 11], "temperature": 0.0, "avg_logprob": -0.14297132382447691, "compression_ratio": 1.6126126126126126, "no_speech_prob": 1.639616493775975e-05}, {"id": 222, "seek": 119652, "start": 1196.52, "end": 1200.12, "text": " but also the prototype that we're building, we're trying to make it quite flexible as", "tokens": [457, 611, 264, 19475, 300, 321, 434, 2390, 11, 321, 434, 1382, 281, 652, 309, 1596, 11358, 382], "temperature": 0.0, "avg_logprob": -0.14505767822265625, "compression_ratio": 1.7913385826771653, "no_speech_prob": 4.2596206185407937e-05}, {"id": 223, "seek": 119652, "start": 1200.12, "end": 1201.12, "text": " well.", "tokens": [731, 13], "temperature": 0.0, "avg_logprob": -0.14505767822265625, "compression_ratio": 1.7913385826771653, "no_speech_prob": 4.2596206185407937e-05}, {"id": 224, "seek": 119652, "start": 1201.12, "end": 1206.52, "text": " And we want to refi all of our drafts and all of the things that we're trying to define", "tokens": [400, 321, 528, 281, 1895, 72, 439, 295, 527, 11206, 82, 293, 439, 295, 264, 721, 300, 321, 434, 1382, 281, 6964], "temperature": 0.0, "avg_logprob": -0.14505767822265625, "compression_ratio": 1.7913385826771653, "no_speech_prob": 4.2596206185407937e-05}, {"id": 225, "seek": 119652, "start": 1206.52, "end": 1212.96, "text": " with other people across the industry, trying to create an end-to-end prototype that represents", "tokens": [365, 661, 561, 2108, 264, 3518, 11, 1382, 281, 1884, 364, 917, 12, 1353, 12, 521, 19475, 300, 8855], "temperature": 0.0, "avg_logprob": -0.14505767822265625, "compression_ratio": 1.7913385826771653, "no_speech_prob": 4.2596206185407937e-05}, {"id": 226, "seek": 119652, "start": 1212.96, "end": 1218.16, "text": " all of this theoretical work, and yeah, we're hoping that the prototype will serve as a", "tokens": [439, 295, 341, 20864, 589, 11, 293, 1338, 11, 321, 434, 7159, 300, 264, 19475, 486, 4596, 382, 257], "temperature": 0.0, "avg_logprob": -0.14505767822265625, "compression_ratio": 1.7913385826771653, "no_speech_prob": 4.2596206185407937e-05}, {"id": 227, "seek": 119652, "start": 1218.16, "end": 1226.0, "text": " model for integrating remote attestation not just into specific protocols, but more widely.", "tokens": [2316, 337, 26889, 8607, 951, 377, 399, 406, 445, 666, 2685, 20618, 11, 457, 544, 13371, 13], "temperature": 0.0, "avg_logprob": -0.14505767822265625, "compression_ratio": 1.7913385826771653, "no_speech_prob": 4.2596206185407937e-05}, {"id": 228, "seek": 122600, "start": 1226.0, "end": 1236.04, "text": " So yeah, questions?", "tokens": [407, 1338, 11, 1651, 30], "temperature": 0.0, "avg_logprob": -0.418111598852909, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.001038303948007524}, {"id": 229, "seek": 122600, "start": 1236.04, "end": 1239.64, "text": " So any questions from the room?", "tokens": [407, 604, 1651, 490, 264, 1808, 30], "temperature": 0.0, "avg_logprob": -0.418111598852909, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.001038303948007524}, {"id": 230, "seek": 122600, "start": 1239.64, "end": 1243.44, "text": " I see hands.", "tokens": [286, 536, 2377, 13], "temperature": 0.0, "avg_logprob": -0.418111598852909, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.001038303948007524}, {"id": 231, "seek": 122600, "start": 1243.44, "end": 1247.08, "text": " Yeah, thank you.", "tokens": [865, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.418111598852909, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.001038303948007524}, {"id": 232, "seek": 122600, "start": 1247.08, "end": 1252.36, "text": " You mentioned you're working under, well, CNCF and CCCF, you also considered the open", "tokens": [509, 2835, 291, 434, 1364, 833, 11, 731, 11, 48714, 37, 293, 383, 11717, 37, 11, 291, 611, 4888, 264, 1269], "temperature": 0.0, "avg_logprob": -0.418111598852909, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.001038303948007524}, {"id": 233, "seek": 122600, "start": 1252.36, "end": 1254.68, "text": " source for more foundation?", "tokens": [4009, 337, 544, 7030, 30], "temperature": 0.0, "avg_logprob": -0.418111598852909, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.001038303948007524}, {"id": 234, "seek": 122600, "start": 1254.68, "end": 1255.68, "text": " Open source?", "tokens": [7238, 4009, 30], "temperature": 0.0, "avg_logprob": -0.418111598852909, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.001038303948007524}, {"id": 235, "seek": 125568, "start": 1255.68, "end": 1256.68, "text": " No, not really.", "tokens": [883, 11, 406, 534, 13], "temperature": 0.0, "avg_logprob": -0.2844978968302409, "compression_ratio": 1.5260663507109005, "no_speech_prob": 0.000643734005279839}, {"id": 236, "seek": 125568, "start": 1256.68, "end": 1265.68, "text": " I mean, neither of these, neither of Parsec or Verizon are really firmer level components.", "tokens": [286, 914, 11, 9662, 295, 613, 11, 9662, 295, 3457, 8159, 420, 44456, 366, 534, 12159, 936, 1496, 6677, 13], "temperature": 0.0, "avg_logprob": -0.2844978968302409, "compression_ratio": 1.5260663507109005, "no_speech_prob": 0.000643734005279839}, {"id": 237, "seek": 125568, "start": 1265.68, "end": 1266.68, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2844978968302409, "compression_ratio": 1.5260663507109005, "no_speech_prob": 0.000643734005279839}, {"id": 238, "seek": 125568, "start": 1266.68, "end": 1272.92, "text": " So yeah, we're essentially doing very similar stuff, but doing the full flow, like starting", "tokens": [407, 1338, 11, 321, 434, 4476, 884, 588, 2531, 1507, 11, 457, 884, 264, 1577, 3095, 11, 411, 2891], "temperature": 0.0, "avg_logprob": -0.2844978968302409, "compression_ratio": 1.5260663507109005, "no_speech_prob": 0.000643734005279839}, {"id": 239, "seek": 125568, "start": 1272.92, "end": 1276.8400000000001, "text": " from the very first code running on your platform, like in the firmware.", "tokens": [490, 264, 588, 700, 3089, 2614, 322, 428, 3663, 11, 411, 294, 264, 30289, 13], "temperature": 0.0, "avg_logprob": -0.2844978968302409, "compression_ratio": 1.5260663507109005, "no_speech_prob": 0.000643734005279839}, {"id": 240, "seek": 125568, "start": 1276.8400000000001, "end": 1277.8400000000001, "text": " We should get in touch.", "tokens": [492, 820, 483, 294, 2557, 13], "temperature": 0.0, "avg_logprob": -0.2844978968302409, "compression_ratio": 1.5260663507109005, "no_speech_prob": 0.000643734005279839}, {"id": 241, "seek": 125568, "start": 1277.8400000000001, "end": 1278.8400000000001, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.2844978968302409, "compression_ratio": 1.5260663507109005, "no_speech_prob": 0.000643734005279839}, {"id": 242, "seek": 125568, "start": 1278.8400000000001, "end": 1279.8400000000001, "text": " Perfect.", "tokens": [10246, 13], "temperature": 0.0, "avg_logprob": -0.2844978968302409, "compression_ratio": 1.5260663507109005, "no_speech_prob": 0.000643734005279839}, {"id": 243, "seek": 127984, "start": 1279.84, "end": 1288.6799999999998, "text": " Hey, thanks for the talk, I was kind of curious how big the impact is on round trip times", "tokens": [1911, 11, 3231, 337, 264, 751, 11, 286, 390, 733, 295, 6369, 577, 955, 264, 2712, 307, 322, 3098, 4931, 1413], "temperature": 0.0, "avg_logprob": -0.22194522135966532, "compression_ratio": 1.586080586080586, "no_speech_prob": 0.001083300681784749}, {"id": 244, "seek": 127984, "start": 1288.6799999999998, "end": 1294.56, "text": " in TLS if you have secure enclave or TPM involved in the initial handshake, like how does that", "tokens": [294, 314, 19198, 498, 291, 362, 7144, 2058, 27995, 420, 314, 18819, 3288, 294, 264, 5883, 2377, 34593, 11, 411, 577, 775, 300], "temperature": 0.0, "avg_logprob": -0.22194522135966532, "compression_ratio": 1.586080586080586, "no_speech_prob": 0.001083300681784749}, {"id": 245, "seek": 127984, "start": 1294.56, "end": 1295.56, "text": " work?", "tokens": [589, 30], "temperature": 0.0, "avg_logprob": -0.22194522135966532, "compression_ratio": 1.586080586080586, "no_speech_prob": 0.001083300681784749}, {"id": 246, "seek": 127984, "start": 1295.56, "end": 1300.72, "text": " Do you see any problems in practice putting that in skill at scale?", "tokens": [1144, 291, 536, 604, 2740, 294, 3124, 3372, 300, 294, 5389, 412, 4373, 30], "temperature": 0.0, "avg_logprob": -0.22194522135966532, "compression_ratio": 1.586080586080586, "no_speech_prob": 0.001083300681784749}, {"id": 247, "seek": 127984, "start": 1300.72, "end": 1305.72, "text": " We've not really gotten to the point where we can properly test end-to-end in terms of", "tokens": [492, 600, 406, 534, 5768, 281, 264, 935, 689, 321, 393, 6108, 1500, 917, 12, 1353, 12, 521, 294, 2115, 295], "temperature": 0.0, "avg_logprob": -0.22194522135966532, "compression_ratio": 1.586080586080586, "no_speech_prob": 0.001083300681784749}, {"id": 248, "seek": 127984, "start": 1305.72, "end": 1309.24, "text": " actually going to hardware and talking to hardware, so we're mostly doing with software", "tokens": [767, 516, 281, 8837, 293, 1417, 281, 8837, 11, 370, 321, 434, 5240, 884, 365, 4722], "temperature": 0.0, "avg_logprob": -0.22194522135966532, "compression_ratio": 1.586080586080586, "no_speech_prob": 0.001083300681784749}, {"id": 249, "seek": 130924, "start": 1309.24, "end": 1313.76, "text": " TPMs and stuff like that, so just to integrate, we still have some integration work to do", "tokens": [314, 18819, 82, 293, 1507, 411, 300, 11, 370, 445, 281, 13365, 11, 321, 920, 362, 512, 10980, 589, 281, 360], "temperature": 0.0, "avg_logprob": -0.20126786191239315, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00010373911936767399}, {"id": 250, "seek": 130924, "start": 1313.76, "end": 1314.76, "text": " there.", "tokens": [456, 13], "temperature": 0.0, "avg_logprob": -0.20126786191239315, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00010373911936767399}, {"id": 251, "seek": 130924, "start": 1314.76, "end": 1318.92, "text": " But yeah, we're definitely going to benchmark that and see how it impacts, but it obviously", "tokens": [583, 1338, 11, 321, 434, 2138, 516, 281, 18927, 300, 293, 536, 577, 309, 11606, 11, 457, 309, 2745], "temperature": 0.0, "avg_logprob": -0.20126786191239315, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00010373911936767399}, {"id": 252, "seek": 130924, "start": 1318.92, "end": 1323.96, "text": " depends on the hardware because if we do that on some server, you know, some cloud server,", "tokens": [5946, 322, 264, 8837, 570, 498, 321, 360, 300, 322, 512, 7154, 11, 291, 458, 11, 512, 4588, 7154, 11], "temperature": 0.0, "avg_logprob": -0.20126786191239315, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00010373911936767399}, {"id": 253, "seek": 130924, "start": 1323.96, "end": 1328.56, "text": " that's going to be quite different from doing it on an IoT device that has a TPM or something", "tokens": [300, 311, 516, 281, 312, 1596, 819, 490, 884, 309, 322, 364, 30112, 4302, 300, 575, 257, 314, 18819, 420, 746], "temperature": 0.0, "avg_logprob": -0.20126786191239315, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00010373911936767399}, {"id": 254, "seek": 130924, "start": 1328.56, "end": 1329.56, "text": " like that.", "tokens": [411, 300, 13], "temperature": 0.0, "avg_logprob": -0.20126786191239315, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00010373911936767399}, {"id": 255, "seek": 130924, "start": 1329.56, "end": 1330.56, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.20126786191239315, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00010373911936767399}, {"id": 256, "seek": 130924, "start": 1330.56, "end": 1336.6, "text": " Okay, do we have some other questions, anyone?", "tokens": [1033, 11, 360, 321, 362, 512, 661, 1651, 11, 2878, 30], "temperature": 0.0, "avg_logprob": -0.20126786191239315, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00010373911936767399}, {"id": 257, "seek": 133660, "start": 1336.6, "end": 1343.6, "text": " If not, thank you for your talk, thanks.", "tokens": [50364, 759, 406, 11, 1309, 291, 337, 428, 751, 11, 3231, 13, 50714], "temperature": 0.0, "avg_logprob": -0.4401940277644566, "compression_ratio": 1.0, "no_speech_prob": 0.0017853183671832085}, {"id": 258, "seek": 139660, "start": 1396.6, "end": 1403.6, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50714], "temperature": 0.0, "avg_logprob": -0.849927028020223, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9691035747528076}, {"id": 259, "seek": 142660, "start": 1426.6, "end": 1433.6, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50714], "temperature": 0.0, "avg_logprob": -0.7913980484008789, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9649320840835571}, {"id": 260, "seek": 145660, "start": 1456.6, "end": 1463.6, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50714], "temperature": 0.0, "avg_logprob": -0.8296061356862386, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.964474081993103}, {"id": 261, "seek": 148660, "start": 1486.6, "end": 1496.6, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50864], "temperature": 0.0, "avg_logprob": -0.825663169225057, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.7693801522254944}], "language": "en"}