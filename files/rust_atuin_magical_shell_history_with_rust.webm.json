{"text": " I'm going to talk about a project I've been building on and off for the last two years also. So to get started, who am I? My name is Ellie and I'm the lead infrastructure engineer at a company called Post Hog. When I'm not writing software for work, I try and maintain a couple of side projects in my free time and when I don't have the energy for that, I'm normally exploring outdoors, which as you can probably see is usually on a motorbike for me. So to dive into a two-in, first of all, I'm going to start with the name. Originally it was called Shink for like shell and sink, but I couldn't really say that out loud without cringing. So I looked at something new. I've been a fan of Terry Pratchett's disc world books for a really long time and for those who are unfamiliar, the sort of premise there is that the world is a disc and it rests on the shoulders of four giant elephants stood on the shell of a space turtle called the great a two-in, which I'm probably mispronouncing. I thought it would be a bit pretentious to include the words the great in my project name and putting an apostrophe in a binary is probably not a good idea. So I ended up with just the name a two-in. A little bit more specifically, a two-in was made to synchronize shell history between multiple computers. So I had the problem that I would be switching between a whole bunch of laptops. I'd be remoting into various different boxes and trying to find one command that I ran a few days previously on whichever computer it was was pretty difficult. So I wanted it all in the same place. The first thing I did was replace the normal ZSH history, bash history, or whatever fish uses, I don't really remember, with a SQLite database. And we could then have some functions to import your normal text history into the database and because databases are a little bit more flexible than flat text files, we could also include some additional context. So in the case of a two-in, this is context such as how long a command took to run, whether or not it was successful, which directory it was ran in, as well as the shell session. So the way we do this is we plug into your shell. If your shell supports it, it's via the normal shell hooks, like pre-command or pre-exact and post-command, I think they're called. But in the case of bash, which I do not have positive feelings towards, we do a really horrible pack with the prompt. So hopefully you can see the GIF on the right. On top of this database, we also built a search TUI. And this is bound by default to control R and the off arrow, which is a little bit contentious for some people, so you can remap that too. Search UI has three different search modes. By default, one of them is a fuzzy search, kind of inspired by FZF. The other is a prefix search, which is pretty self-explanatory and a substring search, which same thing. You should know what that means. We also have several different filter modes. So a TUI allows you to search your shell history for the current session, for the current directory, for the current machine, or just all of your shell history for every machine ever that you've connected anyway. It would be cool if it could have otherwise. A little bit more on that extra context. A turn has a stats command, which kind of analyzes all of your history and will show you things like the most used command, which for me is LS. I didn't realize I ran that so much. How many commands you have ran, as well as how many unique commands you've ran. We're definitely not making the most of all the data available, and there's a lot more sort of cool analysis we could do. And you can also get the stats for a specific day or week or month or whatever. A little bit more on the search. You don't have to use the search UI. We also have a command line search interface. This is kind of useful if you have like a specific command in mind. Maybe you know roughly when it was or roughly what it looks like. And it's also useful to integrate with other tools. So someone on the Discord told me that apparently they've used this to integrate directly with FZF as their search instead, which is pretty cool. So you can see here that I'm searching for all successfully ran commands after yesterday at 3 p.m. that start with git. Obviously, I did not make these slides today. The time specifier supports like a human way of expressing time, and the command search supports regular expressions. A little bit more about the sync server. It's a kind of pretty boring HTTP API that shares blobs. It has no idea what the blobs actually contain. And it was originally written in with warp, which I found to be very fun, kind of nice mental exercise, I guess. And we ended up rewriting with AXM because while warp was fun, it was difficult for contributors to figure out how to use, and it also contributed pretty massively to a high compile time. And AXM is just sort of the problems there. The ato and sync server is completely self-hostable. Anyone with it installed can just run ato and server and have a running server. We also have Docker images and Kubernetes manifests for anyone that wants to get a little bit more fancy. And a little bit more on the sync is that it's not quite real time yet. While I would love it if it was, it currently syncs an interval of 15 minutes, and you can reduce this down to zero, which basically means it will sync after every single command. If you know fancy running your own infrastructure, there's a public deployment of it in the IRAN. Currently it's got about 11 million lines of shell history on it. There's about 300 active users. And it's all running on just one dedicated Hesner box, and it handles way more requests than I thought it ever would. I'd also like to thank the GitHub sponsors I got, which I didn't really expect anyone to contribute, but they cover the server bills entirely now, which is a really nice feeling. And a little bit more about privacy. I imagine people here probably feel more strongly about that than others. Everything's fully end-to-end encrypted in the sync because I really don't want the responsibility of people's accidentally pasted into a shell API keys on my machine. We use LibSodium secret box because I'm not at all a cryptographer, and it's more difficult to mess up than most other things. Finding a reliably maintained library for that was a bit tricky. The original bindings we used were not maintained beyond security patches. We recently switched to, I think, Rust Crypto, for a member rightly. All of the encryption keys get automatically generated when you log in, and you have to keep track of them yourself. So if you lose your keys, there's nothing I can do. Your data's gone. So why Rust? This is the Rust dev room, after all. It runs twice for every shell command you run. So it runs just before and just afterwards. It lets us get the timing data and everything else. And if we had latency there for an interpreter to start up or a runtime to do whatever it does, the experience would not be great. If you added 50 to 100 milliseconds to every command you ran, people would pretty rightfully complain. So Rust fits the bill very nicely there. It also has to be reliable because if we're dropping shell history randomly, then it's not at all serving the purpose it was written for. Having a static binary to deploy is also really nice. No one has to make sure they have Rust 3.7 not pointing any languages in particular installed on the system with the right versions of various libraries installed or anything like that. And it's also safe, so you don't have to worry about any memory issues or anything like that. The other factor which I think for a side project is especially important is that Rust is fun. When I started this project, I was also considering using Go, and I was also writing Go for my day job. And I didn't really fancy the idea of getting home after work, writing Go all day, and then writing some more Go. So Rust solved that very nicely, and I think the main reason I actually got around to finishing this is because I was enjoying writing it. Additionally, the Rust community is fantastic. Every time I've asked for help, people have been really helpful. Everything I wanted has been available, and they're just generally very welcoming and accepting, especially compared to some other tech communities. So I actually have one other service, and I'm glad most of the previous talks have discussed Python, because now I don't feel as weird for mentioning it in my presentation too. I have another service called Rinsewind, a bit of a naming pattern there, if anyone's familiar with it. And what this basically does is it peeks into the database and generates graphs like this, which are heavily inspired by the GitHub commit activity chart, but for your shell history. And it's currently closed source for no real reason other than that it's a really horrible hack that I don't want to package nicely for anyone. It mostly uses NumPy and OpenCV and a few other things. It's also completely opt-in, so you don't get this by default if you don't want any proprietary code touching your data. You don't have to. It's cool. Just with one curl command, you enable this. On the open source side of things, this is the first open source project. I've released that people have actually been interested in. I made it just for myself and stuck it on my GitHub, and it ended up being quite well received by a whole bunch of people. We ended up in a lot of package repositories. I think off the top of my head it's the Arch Linux community repo, Homebrew, Alpine Linux, and some Nix. I'm not entirely sure how Nix works, but one of the Nix repositories. And there's probably a whole bunch more that I'm not aware of. And we've actually got 63 contributors at sort of as of today. Some of them are sort of returning regular contributors, which is very nice that people want to regularly give time to my project. Some of them are just sort of drive by. They found something that annoyed them or bug they wanted to fix or something like that, so they contributed, which was lovely. I'd also like to especially thank Conrad. He's much more involved in the Rust community than I am and also a very long-term friend of mine. He helps me maintain a twin, and when I was first starting and not so good at Rust, he did a great job of tidying things up a bit. In terms of the future, right now a twin has a bit of a flaw in that you can't actually delete history once it's been synced. This is mostly because the sync's pretty eventually consistent, and every machine you have is a potential writer, so ensuring that you delete something and it stays deleted is actually really difficult. I've currently got a solution to it, which works on my laptop. I just need to make sure it works on everyone else's too. I'd also like to sort out bash, because pretty much all the complaints we get about shell integrations are from people running bash, and it's very frustrating. I think I don't actually use bash, and I hate having a setup on my machine just for that. I'd also like to show some more information in the TUI, so I don't know if you saw very much on the GIF earlier, but it basically just shows what's useful for search results. I would love it if there was another tab where you could also see sort of statistics about a command that's run, maybe how often it succeeds versus fails, you could get some nice stats about make build that way, and that sort of thing. I'd like to improve the search a little bit too, because right now it's good enough, and I think it could always be improved. I've been meaning to explore some of the full-text search modules that SQLite has, or maybe something like Tantivi or one of the other search libraries in Rust. Otherwise, I'd really like to improve the sorting. Right now we sort chronologically, which is a pretty safe default. I'm not going to turn this into a horrible Twitter timeline type thing, but it would be nice if we could sort based on the context we have. Maybe every day at 9 a.m. you CD into your repo and you run GitPool. By default, it would be nice if you pressed Ctrl R, and GitPool was already there at the time that you frequently run it. We've got all the data for that, it just needs to be plugged together. In the even further future, the number of people that have spoken to me about the fact that they have development API keys in their shell history, it would be nice if we could do something to get that out of the shell history and sync that alongside the data. Being able to bookmark commands is also something I would quite like to be able to do, because there's some longer commands I run frequently in search for, frequently having some sort of hockey or alias would be really nice. Otherwise, I realized that a subset of a two-end history could also be used as a runbook if you had to begin and an end marker to it, and you could just replay some commands from your past. That's actually it. I went a bit faster than I was expecting, but if there are any questions, I'd be very happy to answer them. Can you search for things which have come after your most recent command frequently? I'm not sure what you mean, sorry. So to take what you've just typed and see what you typically do next, so actually returning the command after the one you've searched for. That's one of the things I'd love to be able to do with the smarter ordering is know that like a sequence of commands that's commonly run and predict the next one based on history, if that's, yeah. So I tried to install your tool, but I'm using Bash, and I was wondering how far are you with like fixing Bash? Bash generally works fine. It's usually the people that have a whole bunch of Bash plugins installed or have a weird Bash prompt that start to have some issues, but generally, it's okay for most people. Yeah. Sorry. Does it handle having different cells in different computers? For example, if I'm using one computer piece and another CS8, does the same work between those two? Yes. So we translate from whatever your shell uses natively into the format we use, so whichever shell you use on each machine doesn't matter. Okay. Thanks. I have a couple of questions. First, I didn't quite get how do you authenticate with the server by having a key analysis? So the sort of user authentication is just a username and password, but then your actual data is encrypted by a key that's only held locally. All right. And second question. Do you have a ZSH plugin or have you considered one? So we have a ZSH plugin. You can use normal ZSH plugin managers to install and use it. All right. Thank you. Getting some exercise in. Is it possible to disable the history for a few commands and then re-enable it? Not currently. We have spoken about the idea of like an incognito mode. If you prefix a command with a space, it won't be saved, but it's kind of annoying if you got to run a lot of them in a row. We have some questions from the matrix. So Olivier Robert says, how would it interact with something like Starship? I actually use Starship and it doesn't interact with it at all in that it works completely fine. Awesome. And yep, that was the other question. Cool. Thank you. There's one at the front, too. Two short questions. The first one is, since I'm using BESH, what's your favorite shell? I like ZSH, I think purely because I started using it maybe 10 years ago and have it so hard to break. I think if I was going to start again, I'd probably try FISH a bit more. And a question about the timestamps, are you using the client-side timestamps from the machines or server-side? So we actually store client-side, the timestamp will be whatever your client is, but we actually use two timestamps to sync to work. So we have the server-local timestamp, which is only really used for syncing, and then the actual data, it's all encrypted and hidden, so it's whatever your client stores. Because sometimes the local timestamp is important if you want to sync with a system or whatever, but sometimes also the real time, if the computers are out of sync, which that should happen. I had a bunch of issues with timestamps when I was first writing it, but we got it all sorted out in the end. Is there a limit to the length of a command, for example, imagine a huge pipeline with the SQLs and JQL queries in there? Currently it's eight megabytes of whatever it is once it's been encrypted, it's only a server-side limit, and it's pretty arbitrary. So another question, any plans for special handling for similar commands? We do fix syntax, run similar commands in a row? I hadn't really thought of that before, but it might be worth considering. Sorry, I did have a few more questions from Matrix. I think my device is not synchronizing properly, but Andy sent me a screenshot. So does it integrate with regular history mechanisms provided by the shell? For example, excluding certain commands automatically like CDNLS, skipping storing in history by prefixing with white space for sensitive commands, et cetera. So the prefixing with white space is included, the default ignoring is not, but it doesn't actually replace the text file history either. You will still write to that if you ever decide, do you want to stop using it? And where would context to where recommendations come from? So if we have a history of your shell, we know the directories you're in, we know what commands you've been running at what times, so if we're predicting the next command that you want to run, we can use your own history. So, but the question follows up with, it's end-to-end encrypted? Oh, it would all be from the client. So there's nothing, the server's just a dumb blob store, it doesn't really know much of anything. Any more questions? I think that's it. Awesome. Thank you. That was really well.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 19.68, "text": " I'm going to talk about a project I've been building on and off for the last two years", "tokens": [286, 478, 516, 281, 751, 466, 257, 1716, 286, 600, 668, 2390, 322, 293, 766, 337, 264, 1036, 732, 924], "temperature": 0.0, "avg_logprob": -0.42865064588643736, "compression_ratio": 1.3144654088050314, "no_speech_prob": 0.10954098403453827}, {"id": 1, "seek": 0, "start": 19.68, "end": 20.68, "text": " also.", "tokens": [611, 13], "temperature": 0.0, "avg_logprob": -0.42865064588643736, "compression_ratio": 1.3144654088050314, "no_speech_prob": 0.10954098403453827}, {"id": 2, "seek": 0, "start": 20.68, "end": 23.56, "text": " So to get started, who am I?", "tokens": [407, 281, 483, 1409, 11, 567, 669, 286, 30], "temperature": 0.0, "avg_logprob": -0.42865064588643736, "compression_ratio": 1.3144654088050314, "no_speech_prob": 0.10954098403453827}, {"id": 3, "seek": 0, "start": 23.56, "end": 29.080000000000002, "text": " My name is Ellie and I'm the lead infrastructure engineer at a company called Post Hog.", "tokens": [1222, 1315, 307, 27151, 293, 286, 478, 264, 1477, 6896, 11403, 412, 257, 2237, 1219, 10223, 30553, 13], "temperature": 0.0, "avg_logprob": -0.42865064588643736, "compression_ratio": 1.3144654088050314, "no_speech_prob": 0.10954098403453827}, {"id": 4, "seek": 2908, "start": 29.08, "end": 33.0, "text": " When I'm not writing software for work, I try and maintain a couple of side projects", "tokens": [1133, 286, 478, 406, 3579, 4722, 337, 589, 11, 286, 853, 293, 6909, 257, 1916, 295, 1252, 4455], "temperature": 0.0, "avg_logprob": -0.18759418302966702, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.560783054330386e-05}, {"id": 5, "seek": 2908, "start": 33.0, "end": 37.48, "text": " in my free time and when I don't have the energy for that, I'm normally exploring outdoors,", "tokens": [294, 452, 1737, 565, 293, 562, 286, 500, 380, 362, 264, 2281, 337, 300, 11, 286, 478, 5646, 12736, 20980, 11], "temperature": 0.0, "avg_logprob": -0.18759418302966702, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.560783054330386e-05}, {"id": 6, "seek": 2908, "start": 37.48, "end": 41.04, "text": " which as you can probably see is usually on a motorbike for me.", "tokens": [597, 382, 291, 393, 1391, 536, 307, 2673, 322, 257, 5932, 30283, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.18759418302966702, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.560783054330386e-05}, {"id": 7, "seek": 2908, "start": 41.04, "end": 46.64, "text": " So to dive into a two-in, first of all, I'm going to start with the name.", "tokens": [407, 281, 9192, 666, 257, 732, 12, 259, 11, 700, 295, 439, 11, 286, 478, 516, 281, 722, 365, 264, 1315, 13], "temperature": 0.0, "avg_logprob": -0.18759418302966702, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.560783054330386e-05}, {"id": 8, "seek": 2908, "start": 46.64, "end": 50.68, "text": " Originally it was called Shink for like shell and sink, but I couldn't really say that out", "tokens": [28696, 309, 390, 1219, 1160, 475, 337, 411, 8720, 293, 9500, 11, 457, 286, 2809, 380, 534, 584, 300, 484], "temperature": 0.0, "avg_logprob": -0.18759418302966702, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.560783054330386e-05}, {"id": 9, "seek": 2908, "start": 50.68, "end": 52.28, "text": " loud without cringing.", "tokens": [6588, 1553, 941, 8716, 13], "temperature": 0.0, "avg_logprob": -0.18759418302966702, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.560783054330386e-05}, {"id": 10, "seek": 2908, "start": 52.28, "end": 55.04, "text": " So I looked at something new.", "tokens": [407, 286, 2956, 412, 746, 777, 13], "temperature": 0.0, "avg_logprob": -0.18759418302966702, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.560783054330386e-05}, {"id": 11, "seek": 5504, "start": 55.04, "end": 59.92, "text": " I've been a fan of Terry Pratchett's disc world books for a really long time and for", "tokens": [286, 600, 668, 257, 3429, 295, 21983, 2114, 852, 3093, 311, 2983, 1002, 3642, 337, 257, 534, 938, 565, 293, 337], "temperature": 0.0, "avg_logprob": -0.13648333975939247, "compression_ratio": 1.674911660777385, "no_speech_prob": 3.031782944162842e-05}, {"id": 12, "seek": 5504, "start": 59.92, "end": 65.56, "text": " those who are unfamiliar, the sort of premise there is that the world is a disc and it rests", "tokens": [729, 567, 366, 29415, 11, 264, 1333, 295, 22045, 456, 307, 300, 264, 1002, 307, 257, 2983, 293, 309, 39755], "temperature": 0.0, "avg_logprob": -0.13648333975939247, "compression_ratio": 1.674911660777385, "no_speech_prob": 3.031782944162842e-05}, {"id": 13, "seek": 5504, "start": 65.56, "end": 70.44, "text": " on the shoulders of four giant elephants stood on the shell of a space turtle called the", "tokens": [322, 264, 10245, 295, 1451, 7410, 33015, 9371, 322, 264, 8720, 295, 257, 1901, 22866, 1219, 264], "temperature": 0.0, "avg_logprob": -0.13648333975939247, "compression_ratio": 1.674911660777385, "no_speech_prob": 3.031782944162842e-05}, {"id": 14, "seek": 5504, "start": 70.44, "end": 73.96000000000001, "text": " great a two-in, which I'm probably mispronouncing.", "tokens": [869, 257, 732, 12, 259, 11, 597, 286, 478, 1391, 3346, 1424, 266, 1733, 2175, 13], "temperature": 0.0, "avg_logprob": -0.13648333975939247, "compression_ratio": 1.674911660777385, "no_speech_prob": 3.031782944162842e-05}, {"id": 15, "seek": 5504, "start": 73.96000000000001, "end": 77.72, "text": " I thought it would be a bit pretentious to include the words the great in my project", "tokens": [286, 1194, 309, 576, 312, 257, 857, 1162, 317, 851, 281, 4090, 264, 2283, 264, 869, 294, 452, 1716], "temperature": 0.0, "avg_logprob": -0.13648333975939247, "compression_ratio": 1.674911660777385, "no_speech_prob": 3.031782944162842e-05}, {"id": 16, "seek": 5504, "start": 77.72, "end": 82.03999999999999, "text": " name and putting an apostrophe in a binary is probably not a good idea.", "tokens": [1315, 293, 3372, 364, 19484, 27194, 294, 257, 17434, 307, 1391, 406, 257, 665, 1558, 13], "temperature": 0.0, "avg_logprob": -0.13648333975939247, "compression_ratio": 1.674911660777385, "no_speech_prob": 3.031782944162842e-05}, {"id": 17, "seek": 8204, "start": 82.04, "end": 85.48, "text": " So I ended up with just the name a two-in.", "tokens": [407, 286, 4590, 493, 365, 445, 264, 1315, 257, 732, 12, 259, 13], "temperature": 0.0, "avg_logprob": -0.09675035653290925, "compression_ratio": 1.6090225563909775, "no_speech_prob": 3.183395165251568e-05}, {"id": 18, "seek": 8204, "start": 85.48, "end": 90.96000000000001, "text": " A little bit more specifically, a two-in was made to synchronize shell history between", "tokens": [316, 707, 857, 544, 4682, 11, 257, 732, 12, 259, 390, 1027, 281, 19331, 1125, 8720, 2503, 1296], "temperature": 0.0, "avg_logprob": -0.09675035653290925, "compression_ratio": 1.6090225563909775, "no_speech_prob": 3.183395165251568e-05}, {"id": 19, "seek": 8204, "start": 90.96000000000001, "end": 92.60000000000001, "text": " multiple computers.", "tokens": [3866, 10807, 13], "temperature": 0.0, "avg_logprob": -0.09675035653290925, "compression_ratio": 1.6090225563909775, "no_speech_prob": 3.183395165251568e-05}, {"id": 20, "seek": 8204, "start": 92.60000000000001, "end": 97.08000000000001, "text": " So I had the problem that I would be switching between a whole bunch of laptops.", "tokens": [407, 286, 632, 264, 1154, 300, 286, 576, 312, 16493, 1296, 257, 1379, 3840, 295, 27642, 13], "temperature": 0.0, "avg_logprob": -0.09675035653290925, "compression_ratio": 1.6090225563909775, "no_speech_prob": 3.183395165251568e-05}, {"id": 21, "seek": 8204, "start": 97.08000000000001, "end": 103.04, "text": " I'd be remoting into various different boxes and trying to find one command that I ran", "tokens": [286, 1116, 312, 890, 17001, 666, 3683, 819, 9002, 293, 1382, 281, 915, 472, 5622, 300, 286, 5872], "temperature": 0.0, "avg_logprob": -0.09675035653290925, "compression_ratio": 1.6090225563909775, "no_speech_prob": 3.183395165251568e-05}, {"id": 22, "seek": 8204, "start": 103.04, "end": 107.80000000000001, "text": " a few days previously on whichever computer it was was pretty difficult.", "tokens": [257, 1326, 1708, 8046, 322, 24123, 3820, 309, 390, 390, 1238, 2252, 13], "temperature": 0.0, "avg_logprob": -0.09675035653290925, "compression_ratio": 1.6090225563909775, "no_speech_prob": 3.183395165251568e-05}, {"id": 23, "seek": 8204, "start": 107.80000000000001, "end": 110.4, "text": " So I wanted it all in the same place.", "tokens": [407, 286, 1415, 309, 439, 294, 264, 912, 1081, 13], "temperature": 0.0, "avg_logprob": -0.09675035653290925, "compression_ratio": 1.6090225563909775, "no_speech_prob": 3.183395165251568e-05}, {"id": 24, "seek": 11040, "start": 110.4, "end": 116.12, "text": " The first thing I did was replace the normal ZSH history, bash history, or whatever fish", "tokens": [440, 700, 551, 286, 630, 390, 7406, 264, 2710, 1176, 17308, 2503, 11, 46183, 2503, 11, 420, 2035, 3506], "temperature": 0.0, "avg_logprob": -0.16494296012668436, "compression_ratio": 1.641025641025641, "no_speech_prob": 3.9289563574129716e-05}, {"id": 25, "seek": 11040, "start": 116.12, "end": 120.32000000000001, "text": " uses, I don't really remember, with a SQLite database.", "tokens": [4960, 11, 286, 500, 380, 534, 1604, 11, 365, 257, 19200, 642, 8149, 13], "temperature": 0.0, "avg_logprob": -0.16494296012668436, "compression_ratio": 1.641025641025641, "no_speech_prob": 3.9289563574129716e-05}, {"id": 26, "seek": 11040, "start": 120.32000000000001, "end": 126.08000000000001, "text": " And we could then have some functions to import your normal text history into the database", "tokens": [400, 321, 727, 550, 362, 512, 6828, 281, 974, 428, 2710, 2487, 2503, 666, 264, 8149], "temperature": 0.0, "avg_logprob": -0.16494296012668436, "compression_ratio": 1.641025641025641, "no_speech_prob": 3.9289563574129716e-05}, {"id": 27, "seek": 11040, "start": 126.08000000000001, "end": 131.08, "text": " and because databases are a little bit more flexible than flat text files, we could also", "tokens": [293, 570, 22380, 366, 257, 707, 857, 544, 11358, 813, 4962, 2487, 7098, 11, 321, 727, 611], "temperature": 0.0, "avg_logprob": -0.16494296012668436, "compression_ratio": 1.641025641025641, "no_speech_prob": 3.9289563574129716e-05}, {"id": 28, "seek": 11040, "start": 131.08, "end": 133.12, "text": " include some additional context.", "tokens": [4090, 512, 4497, 4319, 13], "temperature": 0.0, "avg_logprob": -0.16494296012668436, "compression_ratio": 1.641025641025641, "no_speech_prob": 3.9289563574129716e-05}, {"id": 29, "seek": 11040, "start": 133.12, "end": 139.56, "text": " So in the case of a two-in, this is context such as how long a command took to run, whether", "tokens": [407, 294, 264, 1389, 295, 257, 732, 12, 259, 11, 341, 307, 4319, 1270, 382, 577, 938, 257, 5622, 1890, 281, 1190, 11, 1968], "temperature": 0.0, "avg_logprob": -0.16494296012668436, "compression_ratio": 1.641025641025641, "no_speech_prob": 3.9289563574129716e-05}, {"id": 30, "seek": 13956, "start": 139.56, "end": 145.4, "text": " or not it was successful, which directory it was ran in, as well as the shell session.", "tokens": [420, 406, 309, 390, 4406, 11, 597, 21120, 309, 390, 5872, 294, 11, 382, 731, 382, 264, 8720, 5481, 13], "temperature": 0.0, "avg_logprob": -0.1214254886732189, "compression_ratio": 1.6218487394957983, "no_speech_prob": 8.336677274201065e-05}, {"id": 31, "seek": 13956, "start": 145.4, "end": 150.24, "text": " So the way we do this is we plug into your shell.", "tokens": [407, 264, 636, 321, 360, 341, 307, 321, 5452, 666, 428, 8720, 13], "temperature": 0.0, "avg_logprob": -0.1214254886732189, "compression_ratio": 1.6218487394957983, "no_speech_prob": 8.336677274201065e-05}, {"id": 32, "seek": 13956, "start": 150.24, "end": 154.52, "text": " If your shell supports it, it's via the normal shell hooks, like pre-command or pre-exact", "tokens": [759, 428, 8720, 9346, 309, 11, 309, 311, 5766, 264, 2710, 8720, 26485, 11, 411, 659, 12, 13278, 474, 420, 659, 12, 3121, 578], "temperature": 0.0, "avg_logprob": -0.1214254886732189, "compression_ratio": 1.6218487394957983, "no_speech_prob": 8.336677274201065e-05}, {"id": 33, "seek": 13956, "start": 154.52, "end": 156.24, "text": " and post-command, I think they're called.", "tokens": [293, 2183, 12, 13278, 474, 11, 286, 519, 436, 434, 1219, 13], "temperature": 0.0, "avg_logprob": -0.1214254886732189, "compression_ratio": 1.6218487394957983, "no_speech_prob": 8.336677274201065e-05}, {"id": 34, "seek": 13956, "start": 156.24, "end": 162.72, "text": " But in the case of bash, which I do not have positive feelings towards, we do a really", "tokens": [583, 294, 264, 1389, 295, 46183, 11, 597, 286, 360, 406, 362, 3353, 6640, 3030, 11, 321, 360, 257, 534], "temperature": 0.0, "avg_logprob": -0.1214254886732189, "compression_ratio": 1.6218487394957983, "no_speech_prob": 8.336677274201065e-05}, {"id": 35, "seek": 13956, "start": 162.72, "end": 167.8, "text": " horrible pack with the prompt.", "tokens": [9263, 2844, 365, 264, 12391, 13], "temperature": 0.0, "avg_logprob": -0.1214254886732189, "compression_ratio": 1.6218487394957983, "no_speech_prob": 8.336677274201065e-05}, {"id": 36, "seek": 16780, "start": 167.8, "end": 171.24, "text": " So hopefully you can see the GIF on the right.", "tokens": [407, 4696, 291, 393, 536, 264, 460, 12775, 322, 264, 558, 13], "temperature": 0.0, "avg_logprob": -0.188758544921875, "compression_ratio": 1.5283842794759825, "no_speech_prob": 6.475955888163298e-05}, {"id": 37, "seek": 16780, "start": 171.24, "end": 175.56, "text": " On top of this database, we also built a search TUI.", "tokens": [1282, 1192, 295, 341, 8149, 11, 321, 611, 3094, 257, 3164, 314, 46324, 13], "temperature": 0.0, "avg_logprob": -0.188758544921875, "compression_ratio": 1.5283842794759825, "no_speech_prob": 6.475955888163298e-05}, {"id": 38, "seek": 16780, "start": 175.56, "end": 180.92000000000002, "text": " And this is bound by default to control R and the off arrow, which is a little bit contentious", "tokens": [400, 341, 307, 5472, 538, 7576, 281, 1969, 497, 293, 264, 766, 11610, 11, 597, 307, 257, 707, 857, 2701, 851], "temperature": 0.0, "avg_logprob": -0.188758544921875, "compression_ratio": 1.5283842794759825, "no_speech_prob": 6.475955888163298e-05}, {"id": 39, "seek": 16780, "start": 180.92000000000002, "end": 185.52, "text": " for some people, so you can remap that too.", "tokens": [337, 512, 561, 11, 370, 291, 393, 890, 569, 300, 886, 13], "temperature": 0.0, "avg_logprob": -0.188758544921875, "compression_ratio": 1.5283842794759825, "no_speech_prob": 6.475955888163298e-05}, {"id": 40, "seek": 16780, "start": 185.52, "end": 188.32000000000002, "text": " Search UI has three different search modes.", "tokens": [17180, 15682, 575, 1045, 819, 3164, 14068, 13], "temperature": 0.0, "avg_logprob": -0.188758544921875, "compression_ratio": 1.5283842794759825, "no_speech_prob": 6.475955888163298e-05}, {"id": 41, "seek": 16780, "start": 188.32000000000002, "end": 193.24, "text": " By default, one of them is a fuzzy search, kind of inspired by FZF.", "tokens": [3146, 7576, 11, 472, 295, 552, 307, 257, 34710, 3164, 11, 733, 295, 7547, 538, 479, 57, 37, 13], "temperature": 0.0, "avg_logprob": -0.188758544921875, "compression_ratio": 1.5283842794759825, "no_speech_prob": 6.475955888163298e-05}, {"id": 42, "seek": 19324, "start": 193.24, "end": 198.96, "text": " The other is a prefix search, which is pretty self-explanatory and a substring search, which", "tokens": [440, 661, 307, 257, 46969, 3164, 11, 597, 307, 1238, 2698, 12, 3121, 16554, 4745, 293, 257, 4594, 2937, 3164, 11, 597], "temperature": 0.0, "avg_logprob": -0.20975552230584818, "compression_ratio": 1.7814814814814814, "no_speech_prob": 2.3293156118597835e-05}, {"id": 43, "seek": 19324, "start": 198.96, "end": 199.96, "text": " same thing.", "tokens": [912, 551, 13], "temperature": 0.0, "avg_logprob": -0.20975552230584818, "compression_ratio": 1.7814814814814814, "no_speech_prob": 2.3293156118597835e-05}, {"id": 44, "seek": 19324, "start": 199.96, "end": 201.96, "text": " You should know what that means.", "tokens": [509, 820, 458, 437, 300, 1355, 13], "temperature": 0.0, "avg_logprob": -0.20975552230584818, "compression_ratio": 1.7814814814814814, "no_speech_prob": 2.3293156118597835e-05}, {"id": 45, "seek": 19324, "start": 201.96, "end": 204.44, "text": " We also have several different filter modes.", "tokens": [492, 611, 362, 2940, 819, 6608, 14068, 13], "temperature": 0.0, "avg_logprob": -0.20975552230584818, "compression_ratio": 1.7814814814814814, "no_speech_prob": 2.3293156118597835e-05}, {"id": 46, "seek": 19324, "start": 204.44, "end": 210.68, "text": " So a TUI allows you to search your shell history for the current session, for the current directory,", "tokens": [407, 257, 314, 46324, 4045, 291, 281, 3164, 428, 8720, 2503, 337, 264, 2190, 5481, 11, 337, 264, 2190, 21120, 11], "temperature": 0.0, "avg_logprob": -0.20975552230584818, "compression_ratio": 1.7814814814814814, "no_speech_prob": 2.3293156118597835e-05}, {"id": 47, "seek": 19324, "start": 210.68, "end": 215.56, "text": " for the current machine, or just all of your shell history for every machine ever that", "tokens": [337, 264, 2190, 3479, 11, 420, 445, 439, 295, 428, 8720, 2503, 337, 633, 3479, 1562, 300], "temperature": 0.0, "avg_logprob": -0.20975552230584818, "compression_ratio": 1.7814814814814814, "no_speech_prob": 2.3293156118597835e-05}, {"id": 48, "seek": 19324, "start": 215.56, "end": 216.56, "text": " you've connected anyway.", "tokens": [291, 600, 4582, 4033, 13], "temperature": 0.0, "avg_logprob": -0.20975552230584818, "compression_ratio": 1.7814814814814814, "no_speech_prob": 2.3293156118597835e-05}, {"id": 49, "seek": 19324, "start": 216.56, "end": 218.56, "text": " It would be cool if it could have otherwise.", "tokens": [467, 576, 312, 1627, 498, 309, 727, 362, 5911, 13], "temperature": 0.0, "avg_logprob": -0.20975552230584818, "compression_ratio": 1.7814814814814814, "no_speech_prob": 2.3293156118597835e-05}, {"id": 50, "seek": 19324, "start": 218.56, "end": 221.56, "text": " A little bit more on that extra context.", "tokens": [316, 707, 857, 544, 322, 300, 2857, 4319, 13], "temperature": 0.0, "avg_logprob": -0.20975552230584818, "compression_ratio": 1.7814814814814814, "no_speech_prob": 2.3293156118597835e-05}, {"id": 51, "seek": 22156, "start": 221.56, "end": 226.36, "text": " A turn has a stats command, which kind of analyzes all of your history and will show", "tokens": [316, 1261, 575, 257, 18152, 5622, 11, 597, 733, 295, 6459, 12214, 439, 295, 428, 2503, 293, 486, 855], "temperature": 0.0, "avg_logprob": -0.1861281473128522, "compression_ratio": 1.673913043478261, "no_speech_prob": 7.524794636992738e-05}, {"id": 52, "seek": 22156, "start": 226.36, "end": 229.28, "text": " you things like the most used command, which for me is LS.", "tokens": [291, 721, 411, 264, 881, 1143, 5622, 11, 597, 337, 385, 307, 36657, 13], "temperature": 0.0, "avg_logprob": -0.1861281473128522, "compression_ratio": 1.673913043478261, "no_speech_prob": 7.524794636992738e-05}, {"id": 53, "seek": 22156, "start": 229.28, "end": 232.4, "text": " I didn't realize I ran that so much.", "tokens": [286, 994, 380, 4325, 286, 5872, 300, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.1861281473128522, "compression_ratio": 1.673913043478261, "no_speech_prob": 7.524794636992738e-05}, {"id": 54, "seek": 22156, "start": 232.4, "end": 237.56, "text": " How many commands you have ran, as well as how many unique commands you've ran.", "tokens": [1012, 867, 16901, 291, 362, 5872, 11, 382, 731, 382, 577, 867, 3845, 16901, 291, 600, 5872, 13], "temperature": 0.0, "avg_logprob": -0.1861281473128522, "compression_ratio": 1.673913043478261, "no_speech_prob": 7.524794636992738e-05}, {"id": 55, "seek": 22156, "start": 237.56, "end": 241.44, "text": " We're definitely not making the most of all the data available, and there's a lot more", "tokens": [492, 434, 2138, 406, 1455, 264, 881, 295, 439, 264, 1412, 2435, 11, 293, 456, 311, 257, 688, 544], "temperature": 0.0, "avg_logprob": -0.1861281473128522, "compression_ratio": 1.673913043478261, "no_speech_prob": 7.524794636992738e-05}, {"id": 56, "seek": 22156, "start": 241.44, "end": 244.4, "text": " sort of cool analysis we could do.", "tokens": [1333, 295, 1627, 5215, 321, 727, 360, 13], "temperature": 0.0, "avg_logprob": -0.1861281473128522, "compression_ratio": 1.673913043478261, "no_speech_prob": 7.524794636992738e-05}, {"id": 57, "seek": 22156, "start": 244.4, "end": 250.88, "text": " And you can also get the stats for a specific day or week or month or whatever.", "tokens": [400, 291, 393, 611, 483, 264, 18152, 337, 257, 2685, 786, 420, 1243, 420, 1618, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1861281473128522, "compression_ratio": 1.673913043478261, "no_speech_prob": 7.524794636992738e-05}, {"id": 58, "seek": 25088, "start": 250.88, "end": 252.32, "text": " A little bit more on the search.", "tokens": [316, 707, 857, 544, 322, 264, 3164, 13], "temperature": 0.0, "avg_logprob": -0.13919603098993716, "compression_ratio": 1.6804511278195489, "no_speech_prob": 6.504942575702444e-05}, {"id": 59, "seek": 25088, "start": 252.32, "end": 255.44, "text": " You don't have to use the search UI.", "tokens": [509, 500, 380, 362, 281, 764, 264, 3164, 15682, 13], "temperature": 0.0, "avg_logprob": -0.13919603098993716, "compression_ratio": 1.6804511278195489, "no_speech_prob": 6.504942575702444e-05}, {"id": 60, "seek": 25088, "start": 255.44, "end": 259.24, "text": " We also have a command line search interface.", "tokens": [492, 611, 362, 257, 5622, 1622, 3164, 9226, 13], "temperature": 0.0, "avg_logprob": -0.13919603098993716, "compression_ratio": 1.6804511278195489, "no_speech_prob": 6.504942575702444e-05}, {"id": 61, "seek": 25088, "start": 259.24, "end": 263.48, "text": " This is kind of useful if you have like a specific command in mind.", "tokens": [639, 307, 733, 295, 4420, 498, 291, 362, 411, 257, 2685, 5622, 294, 1575, 13], "temperature": 0.0, "avg_logprob": -0.13919603098993716, "compression_ratio": 1.6804511278195489, "no_speech_prob": 6.504942575702444e-05}, {"id": 62, "seek": 25088, "start": 263.48, "end": 266.92, "text": " Maybe you know roughly when it was or roughly what it looks like.", "tokens": [2704, 291, 458, 9810, 562, 309, 390, 420, 9810, 437, 309, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.13919603098993716, "compression_ratio": 1.6804511278195489, "no_speech_prob": 6.504942575702444e-05}, {"id": 63, "seek": 25088, "start": 266.92, "end": 269.12, "text": " And it's also useful to integrate with other tools.", "tokens": [400, 309, 311, 611, 4420, 281, 13365, 365, 661, 3873, 13], "temperature": 0.0, "avg_logprob": -0.13919603098993716, "compression_ratio": 1.6804511278195489, "no_speech_prob": 6.504942575702444e-05}, {"id": 64, "seek": 25088, "start": 269.12, "end": 274.52, "text": " So someone on the Discord told me that apparently they've used this to integrate directly with", "tokens": [407, 1580, 322, 264, 32623, 1907, 385, 300, 7970, 436, 600, 1143, 341, 281, 13365, 3838, 365], "temperature": 0.0, "avg_logprob": -0.13919603098993716, "compression_ratio": 1.6804511278195489, "no_speech_prob": 6.504942575702444e-05}, {"id": 65, "seek": 25088, "start": 274.52, "end": 277.48, "text": " FZF as their search instead, which is pretty cool.", "tokens": [479, 57, 37, 382, 641, 3164, 2602, 11, 597, 307, 1238, 1627, 13], "temperature": 0.0, "avg_logprob": -0.13919603098993716, "compression_ratio": 1.6804511278195489, "no_speech_prob": 6.504942575702444e-05}, {"id": 66, "seek": 27748, "start": 277.48, "end": 282.96000000000004, "text": " So you can see here that I'm searching for all successfully ran commands after yesterday", "tokens": [407, 291, 393, 536, 510, 300, 286, 478, 10808, 337, 439, 10727, 5872, 16901, 934, 5186], "temperature": 0.0, "avg_logprob": -0.24784248257860725, "compression_ratio": 1.5069767441860464, "no_speech_prob": 5.101182614453137e-05}, {"id": 67, "seek": 27748, "start": 282.96000000000004, "end": 285.48, "text": " at 3 p.m. that start with git.", "tokens": [412, 805, 280, 13, 76, 13, 300, 722, 365, 18331, 13], "temperature": 0.0, "avg_logprob": -0.24784248257860725, "compression_ratio": 1.5069767441860464, "no_speech_prob": 5.101182614453137e-05}, {"id": 68, "seek": 27748, "start": 285.48, "end": 290.32, "text": " Obviously, I did not make these slides today.", "tokens": [7580, 11, 286, 630, 406, 652, 613, 9788, 965, 13], "temperature": 0.0, "avg_logprob": -0.24784248257860725, "compression_ratio": 1.5069767441860464, "no_speech_prob": 5.101182614453137e-05}, {"id": 69, "seek": 27748, "start": 290.32, "end": 296.8, "text": " The time specifier supports like a human way of expressing time, and the command search", "tokens": [440, 565, 1608, 9902, 9346, 411, 257, 1952, 636, 295, 22171, 565, 11, 293, 264, 5622, 3164], "temperature": 0.0, "avg_logprob": -0.24784248257860725, "compression_ratio": 1.5069767441860464, "no_speech_prob": 5.101182614453137e-05}, {"id": 70, "seek": 27748, "start": 296.8, "end": 298.32, "text": " supports regular expressions.", "tokens": [9346, 3890, 15277, 13], "temperature": 0.0, "avg_logprob": -0.24784248257860725, "compression_ratio": 1.5069767441860464, "no_speech_prob": 5.101182614453137e-05}, {"id": 71, "seek": 27748, "start": 298.32, "end": 302.20000000000005, "text": " A little bit more about the sync server.", "tokens": [316, 707, 857, 544, 466, 264, 20271, 7154, 13], "temperature": 0.0, "avg_logprob": -0.24784248257860725, "compression_ratio": 1.5069767441860464, "no_speech_prob": 5.101182614453137e-05}, {"id": 72, "seek": 30220, "start": 302.2, "end": 307.88, "text": " It's a kind of pretty boring HTTP API that shares blobs.", "tokens": [467, 311, 257, 733, 295, 1238, 9989, 33283, 9362, 300, 12182, 1749, 929, 13], "temperature": 0.0, "avg_logprob": -0.18759373256138392, "compression_ratio": 1.5023923444976077, "no_speech_prob": 6.188585393829271e-05}, {"id": 73, "seek": 30220, "start": 307.88, "end": 310.96, "text": " It has no idea what the blobs actually contain.", "tokens": [467, 575, 572, 1558, 437, 264, 1749, 929, 767, 5304, 13], "temperature": 0.0, "avg_logprob": -0.18759373256138392, "compression_ratio": 1.5023923444976077, "no_speech_prob": 6.188585393829271e-05}, {"id": 74, "seek": 30220, "start": 310.96, "end": 318.0, "text": " And it was originally written in with warp, which I found to be very fun, kind of nice", "tokens": [400, 309, 390, 7993, 3720, 294, 365, 36030, 11, 597, 286, 1352, 281, 312, 588, 1019, 11, 733, 295, 1481], "temperature": 0.0, "avg_logprob": -0.18759373256138392, "compression_ratio": 1.5023923444976077, "no_speech_prob": 6.188585393829271e-05}, {"id": 75, "seek": 30220, "start": 318.0, "end": 320.12, "text": " mental exercise, I guess.", "tokens": [4973, 5380, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.18759373256138392, "compression_ratio": 1.5023923444976077, "no_speech_prob": 6.188585393829271e-05}, {"id": 76, "seek": 30220, "start": 320.12, "end": 326.44, "text": " And we ended up rewriting with AXM because while warp was fun, it was difficult for contributors", "tokens": [400, 321, 4590, 493, 319, 19868, 365, 316, 55, 44, 570, 1339, 36030, 390, 1019, 11, 309, 390, 2252, 337, 45627], "temperature": 0.0, "avg_logprob": -0.18759373256138392, "compression_ratio": 1.5023923444976077, "no_speech_prob": 6.188585393829271e-05}, {"id": 77, "seek": 32644, "start": 326.44, "end": 332.92, "text": " to figure out how to use, and it also contributed pretty massively to a high compile time.", "tokens": [281, 2573, 484, 577, 281, 764, 11, 293, 309, 611, 18434, 1238, 29379, 281, 257, 1090, 31413, 565, 13], "temperature": 0.0, "avg_logprob": -0.20650682863981829, "compression_ratio": 1.6729323308270676, "no_speech_prob": 4.3321306293364614e-05}, {"id": 78, "seek": 32644, "start": 332.92, "end": 336.28, "text": " And AXM is just sort of the problems there.", "tokens": [400, 316, 55, 44, 307, 445, 1333, 295, 264, 2740, 456, 13], "temperature": 0.0, "avg_logprob": -0.20650682863981829, "compression_ratio": 1.6729323308270676, "no_speech_prob": 4.3321306293364614e-05}, {"id": 79, "seek": 32644, "start": 336.28, "end": 339.4, "text": " The ato and sync server is completely self-hostable.", "tokens": [440, 412, 78, 293, 20271, 7154, 307, 2584, 2698, 12, 6037, 712, 13], "temperature": 0.0, "avg_logprob": -0.20650682863981829, "compression_ratio": 1.6729323308270676, "no_speech_prob": 4.3321306293364614e-05}, {"id": 80, "seek": 32644, "start": 339.4, "end": 343.64, "text": " Anyone with it installed can just run ato and server and have a running server.", "tokens": [14643, 365, 309, 8899, 393, 445, 1190, 412, 78, 293, 7154, 293, 362, 257, 2614, 7154, 13], "temperature": 0.0, "avg_logprob": -0.20650682863981829, "compression_ratio": 1.6729323308270676, "no_speech_prob": 4.3321306293364614e-05}, {"id": 81, "seek": 32644, "start": 343.64, "end": 347.68, "text": " We also have Docker images and Kubernetes manifests for anyone that wants to get a little bit", "tokens": [492, 611, 362, 33772, 5267, 293, 23145, 50252, 337, 2878, 300, 2738, 281, 483, 257, 707, 857], "temperature": 0.0, "avg_logprob": -0.20650682863981829, "compression_ratio": 1.6729323308270676, "no_speech_prob": 4.3321306293364614e-05}, {"id": 82, "seek": 32644, "start": 347.68, "end": 348.68, "text": " more fancy.", "tokens": [544, 10247, 13], "temperature": 0.0, "avg_logprob": -0.20650682863981829, "compression_ratio": 1.6729323308270676, "no_speech_prob": 4.3321306293364614e-05}, {"id": 83, "seek": 32644, "start": 348.68, "end": 354.12, "text": " And a little bit more on the sync is that it's not quite real time yet.", "tokens": [400, 257, 707, 857, 544, 322, 264, 20271, 307, 300, 309, 311, 406, 1596, 957, 565, 1939, 13], "temperature": 0.0, "avg_logprob": -0.20650682863981829, "compression_ratio": 1.6729323308270676, "no_speech_prob": 4.3321306293364614e-05}, {"id": 84, "seek": 35412, "start": 354.12, "end": 359.4, "text": " While I would love it if it was, it currently syncs an interval of 15 minutes, and you can", "tokens": [3987, 286, 576, 959, 309, 498, 309, 390, 11, 309, 4362, 5451, 14368, 364, 15035, 295, 2119, 2077, 11, 293, 291, 393], "temperature": 0.0, "avg_logprob": -0.20965471682341202, "compression_ratio": 1.533112582781457, "no_speech_prob": 0.00016662698180880398}, {"id": 85, "seek": 35412, "start": 359.4, "end": 366.4, "text": " reduce this down to zero, which basically means it will sync after every single command.", "tokens": [5407, 341, 760, 281, 4018, 11, 597, 1936, 1355, 309, 486, 20271, 934, 633, 2167, 5622, 13], "temperature": 0.0, "avg_logprob": -0.20965471682341202, "compression_ratio": 1.533112582781457, "no_speech_prob": 0.00016662698180880398}, {"id": 86, "seek": 35412, "start": 366.4, "end": 372.84000000000003, "text": " If you know fancy running your own infrastructure, there's a public deployment of it in the IRAN.", "tokens": [759, 291, 458, 10247, 2614, 428, 1065, 6896, 11, 456, 311, 257, 1908, 19317, 295, 309, 294, 264, 16486, 1770, 13], "temperature": 0.0, "avg_logprob": -0.20965471682341202, "compression_ratio": 1.533112582781457, "no_speech_prob": 0.00016662698180880398}, {"id": 87, "seek": 35412, "start": 372.84000000000003, "end": 375.76, "text": " Currently it's got about 11 million lines of shell history on it.", "tokens": [19964, 309, 311, 658, 466, 2975, 2459, 3876, 295, 8720, 2503, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.20965471682341202, "compression_ratio": 1.533112582781457, "no_speech_prob": 0.00016662698180880398}, {"id": 88, "seek": 35412, "start": 375.76, "end": 378.28000000000003, "text": " There's about 300 active users.", "tokens": [821, 311, 466, 6641, 4967, 5022, 13], "temperature": 0.0, "avg_logprob": -0.20965471682341202, "compression_ratio": 1.533112582781457, "no_speech_prob": 0.00016662698180880398}, {"id": 89, "seek": 35412, "start": 378.28000000000003, "end": 383.48, "text": " And it's all running on just one dedicated Hesner box, and it handles way more requests", "tokens": [400, 309, 311, 439, 2614, 322, 445, 472, 8374, 389, 279, 1193, 2424, 11, 293, 309, 18722, 636, 544, 12475], "temperature": 0.0, "avg_logprob": -0.20965471682341202, "compression_ratio": 1.533112582781457, "no_speech_prob": 0.00016662698180880398}, {"id": 90, "seek": 38348, "start": 383.48, "end": 384.84000000000003, "text": " than I thought it ever would.", "tokens": [813, 286, 1194, 309, 1562, 576, 13], "temperature": 0.0, "avg_logprob": -0.1603413200378418, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.00012841122224926949}, {"id": 91, "seek": 38348, "start": 384.84000000000003, "end": 389.8, "text": " I'd also like to thank the GitHub sponsors I got, which I didn't really expect anyone", "tokens": [286, 1116, 611, 411, 281, 1309, 264, 23331, 22593, 286, 658, 11, 597, 286, 994, 380, 534, 2066, 2878], "temperature": 0.0, "avg_logprob": -0.1603413200378418, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.00012841122224926949}, {"id": 92, "seek": 38348, "start": 389.8, "end": 394.84000000000003, "text": " to contribute, but they cover the server bills entirely now, which is a really nice feeling.", "tokens": [281, 10586, 11, 457, 436, 2060, 264, 7154, 12433, 7696, 586, 11, 597, 307, 257, 534, 1481, 2633, 13], "temperature": 0.0, "avg_logprob": -0.1603413200378418, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.00012841122224926949}, {"id": 93, "seek": 38348, "start": 394.84000000000003, "end": 398.44, "text": " And a little bit more about privacy.", "tokens": [400, 257, 707, 857, 544, 466, 11427, 13], "temperature": 0.0, "avg_logprob": -0.1603413200378418, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.00012841122224926949}, {"id": 94, "seek": 38348, "start": 398.44, "end": 403.44, "text": " I imagine people here probably feel more strongly about that than others.", "tokens": [286, 3811, 561, 510, 1391, 841, 544, 10613, 466, 300, 813, 2357, 13], "temperature": 0.0, "avg_logprob": -0.1603413200378418, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.00012841122224926949}, {"id": 95, "seek": 38348, "start": 403.44, "end": 407.96000000000004, "text": " Everything's fully end-to-end encrypted in the sync because I really don't want the responsibility", "tokens": [5471, 311, 4498, 917, 12, 1353, 12, 521, 36663, 294, 264, 20271, 570, 286, 534, 500, 380, 528, 264, 6357], "temperature": 0.0, "avg_logprob": -0.1603413200378418, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.00012841122224926949}, {"id": 96, "seek": 40796, "start": 407.96, "end": 414.2, "text": " of people's accidentally pasted into a shell API keys on my machine.", "tokens": [295, 561, 311, 15715, 1791, 292, 666, 257, 8720, 9362, 9317, 322, 452, 3479, 13], "temperature": 0.0, "avg_logprob": -0.13965985354255228, "compression_ratio": 1.5131086142322097, "no_speech_prob": 9.510035306448117e-05}, {"id": 97, "seek": 40796, "start": 414.2, "end": 419.56, "text": " We use LibSodium secret box because I'm not at all a cryptographer, and it's more difficult", "tokens": [492, 764, 15834, 50, 378, 2197, 4054, 2424, 570, 286, 478, 406, 412, 439, 257, 9844, 13624, 11, 293, 309, 311, 544, 2252], "temperature": 0.0, "avg_logprob": -0.13965985354255228, "compression_ratio": 1.5131086142322097, "no_speech_prob": 9.510035306448117e-05}, {"id": 98, "seek": 40796, "start": 419.56, "end": 423.35999999999996, "text": " to mess up than most other things.", "tokens": [281, 2082, 493, 813, 881, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.13965985354255228, "compression_ratio": 1.5131086142322097, "no_speech_prob": 9.510035306448117e-05}, {"id": 99, "seek": 40796, "start": 423.35999999999996, "end": 426.91999999999996, "text": " Finding a reliably maintained library for that was a bit tricky.", "tokens": [31947, 257, 49927, 17578, 6405, 337, 300, 390, 257, 857, 12414, 13], "temperature": 0.0, "avg_logprob": -0.13965985354255228, "compression_ratio": 1.5131086142322097, "no_speech_prob": 9.510035306448117e-05}, {"id": 100, "seek": 40796, "start": 426.91999999999996, "end": 433.03999999999996, "text": " The original bindings we used were not maintained beyond security patches.", "tokens": [440, 3380, 14786, 1109, 321, 1143, 645, 406, 17578, 4399, 3825, 26531, 13], "temperature": 0.0, "avg_logprob": -0.13965985354255228, "compression_ratio": 1.5131086142322097, "no_speech_prob": 9.510035306448117e-05}, {"id": 101, "seek": 40796, "start": 433.03999999999996, "end": 436.67999999999995, "text": " We recently switched to, I think, Rust Crypto, for a member rightly.", "tokens": [492, 3938, 16858, 281, 11, 286, 519, 11, 34952, 34809, 78, 11, 337, 257, 4006, 32879, 13], "temperature": 0.0, "avg_logprob": -0.13965985354255228, "compression_ratio": 1.5131086142322097, "no_speech_prob": 9.510035306448117e-05}, {"id": 102, "seek": 43668, "start": 436.68, "end": 440.6, "text": " All of the encryption keys get automatically generated when you log in, and you have to", "tokens": [1057, 295, 264, 29575, 9317, 483, 6772, 10833, 562, 291, 3565, 294, 11, 293, 291, 362, 281], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 103, "seek": 43668, "start": 440.6, "end": 441.96, "text": " keep track of them yourself.", "tokens": [1066, 2837, 295, 552, 1803, 13], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 104, "seek": 43668, "start": 441.96, "end": 444.48, "text": " So if you lose your keys, there's nothing I can do.", "tokens": [407, 498, 291, 3624, 428, 9317, 11, 456, 311, 1825, 286, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 105, "seek": 43668, "start": 444.48, "end": 447.12, "text": " Your data's gone.", "tokens": [2260, 1412, 311, 2780, 13], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 106, "seek": 43668, "start": 447.12, "end": 448.12, "text": " So why Rust?", "tokens": [407, 983, 34952, 30], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 107, "seek": 43668, "start": 448.12, "end": 451.6, "text": " This is the Rust dev room, after all.", "tokens": [639, 307, 264, 34952, 1905, 1808, 11, 934, 439, 13], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 108, "seek": 43668, "start": 451.6, "end": 454.36, "text": " It runs twice for every shell command you run.", "tokens": [467, 6676, 6091, 337, 633, 8720, 5622, 291, 1190, 13], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 109, "seek": 43668, "start": 454.36, "end": 456.52, "text": " So it runs just before and just afterwards.", "tokens": [407, 309, 6676, 445, 949, 293, 445, 10543, 13], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 110, "seek": 43668, "start": 456.52, "end": 460.12, "text": " It lets us get the timing data and everything else.", "tokens": [467, 6653, 505, 483, 264, 10822, 1412, 293, 1203, 1646, 13], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 111, "seek": 43668, "start": 460.12, "end": 465.24, "text": " And if we had latency there for an interpreter to start up or a runtime to do whatever it", "tokens": [400, 498, 321, 632, 27043, 456, 337, 364, 34132, 281, 722, 493, 420, 257, 34474, 281, 360, 2035, 309], "temperature": 0.0, "avg_logprob": -0.19662727896622786, "compression_ratio": 1.6906474820143884, "no_speech_prob": 6.150443368824199e-05}, {"id": 112, "seek": 46524, "start": 465.24, "end": 468.68, "text": " does, the experience would not be great.", "tokens": [775, 11, 264, 1752, 576, 406, 312, 869, 13], "temperature": 0.0, "avg_logprob": -0.12483704343755195, "compression_ratio": 1.5473251028806585, "no_speech_prob": 5.3804142225999385e-05}, {"id": 113, "seek": 46524, "start": 468.68, "end": 473.76, "text": " If you added 50 to 100 milliseconds to every command you ran, people would pretty rightfully", "tokens": [759, 291, 3869, 2625, 281, 2319, 34184, 281, 633, 5622, 291, 5872, 11, 561, 576, 1238, 558, 2277], "temperature": 0.0, "avg_logprob": -0.12483704343755195, "compression_ratio": 1.5473251028806585, "no_speech_prob": 5.3804142225999385e-05}, {"id": 114, "seek": 46524, "start": 473.76, "end": 474.76, "text": " complain.", "tokens": [11024, 13], "temperature": 0.0, "avg_logprob": -0.12483704343755195, "compression_ratio": 1.5473251028806585, "no_speech_prob": 5.3804142225999385e-05}, {"id": 115, "seek": 46524, "start": 474.76, "end": 478.08, "text": " So Rust fits the bill very nicely there.", "tokens": [407, 34952, 9001, 264, 2961, 588, 9594, 456, 13], "temperature": 0.0, "avg_logprob": -0.12483704343755195, "compression_ratio": 1.5473251028806585, "no_speech_prob": 5.3804142225999385e-05}, {"id": 116, "seek": 46524, "start": 478.08, "end": 484.76, "text": " It also has to be reliable because if we're dropping shell history randomly, then it's", "tokens": [467, 611, 575, 281, 312, 12924, 570, 498, 321, 434, 13601, 8720, 2503, 16979, 11, 550, 309, 311], "temperature": 0.0, "avg_logprob": -0.12483704343755195, "compression_ratio": 1.5473251028806585, "no_speech_prob": 5.3804142225999385e-05}, {"id": 117, "seek": 46524, "start": 484.76, "end": 488.52, "text": " not at all serving the purpose it was written for.", "tokens": [406, 412, 439, 8148, 264, 4334, 309, 390, 3720, 337, 13], "temperature": 0.0, "avg_logprob": -0.12483704343755195, "compression_ratio": 1.5473251028806585, "no_speech_prob": 5.3804142225999385e-05}, {"id": 118, "seek": 46524, "start": 488.52, "end": 492.0, "text": " Having a static binary to deploy is also really nice.", "tokens": [10222, 257, 13437, 17434, 281, 7274, 307, 611, 534, 1481, 13], "temperature": 0.0, "avg_logprob": -0.12483704343755195, "compression_ratio": 1.5473251028806585, "no_speech_prob": 5.3804142225999385e-05}, {"id": 119, "seek": 49200, "start": 492.0, "end": 497.44, "text": " No one has to make sure they have Rust 3.7 not pointing any languages in particular installed", "tokens": [883, 472, 575, 281, 652, 988, 436, 362, 34952, 805, 13, 22, 406, 12166, 604, 8650, 294, 1729, 8899], "temperature": 0.0, "avg_logprob": -0.12864317335524, "compression_ratio": 1.675, "no_speech_prob": 4.174435161985457e-05}, {"id": 120, "seek": 49200, "start": 497.44, "end": 503.12, "text": " on the system with the right versions of various libraries installed or anything like that.", "tokens": [322, 264, 1185, 365, 264, 558, 9606, 295, 3683, 15148, 8899, 420, 1340, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.12864317335524, "compression_ratio": 1.675, "no_speech_prob": 4.174435161985457e-05}, {"id": 121, "seek": 49200, "start": 503.12, "end": 508.0, "text": " And it's also safe, so you don't have to worry about any memory issues or anything like that.", "tokens": [400, 309, 311, 611, 3273, 11, 370, 291, 500, 380, 362, 281, 3292, 466, 604, 4675, 2663, 420, 1340, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.12864317335524, "compression_ratio": 1.675, "no_speech_prob": 4.174435161985457e-05}, {"id": 122, "seek": 49200, "start": 508.0, "end": 513.28, "text": " The other factor which I think for a side project is especially important is that Rust", "tokens": [440, 661, 5952, 597, 286, 519, 337, 257, 1252, 1716, 307, 2318, 1021, 307, 300, 34952], "temperature": 0.0, "avg_logprob": -0.12864317335524, "compression_ratio": 1.675, "no_speech_prob": 4.174435161985457e-05}, {"id": 123, "seek": 49200, "start": 513.28, "end": 515.28, "text": " is fun.", "tokens": [307, 1019, 13], "temperature": 0.0, "avg_logprob": -0.12864317335524, "compression_ratio": 1.675, "no_speech_prob": 4.174435161985457e-05}, {"id": 124, "seek": 49200, "start": 515.28, "end": 520.96, "text": " When I started this project, I was also considering using Go, and I was also writing Go for my", "tokens": [1133, 286, 1409, 341, 1716, 11, 286, 390, 611, 8079, 1228, 1037, 11, 293, 286, 390, 611, 3579, 1037, 337, 452], "temperature": 0.0, "avg_logprob": -0.12864317335524, "compression_ratio": 1.675, "no_speech_prob": 4.174435161985457e-05}, {"id": 125, "seek": 52096, "start": 520.96, "end": 521.96, "text": " day job.", "tokens": [786, 1691, 13], "temperature": 0.0, "avg_logprob": -0.1711062769736013, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00012324113049544394}, {"id": 126, "seek": 52096, "start": 521.96, "end": 526.9200000000001, "text": " And I didn't really fancy the idea of getting home after work, writing Go all day, and then", "tokens": [400, 286, 994, 380, 534, 10247, 264, 1558, 295, 1242, 1280, 934, 589, 11, 3579, 1037, 439, 786, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.1711062769736013, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00012324113049544394}, {"id": 127, "seek": 52096, "start": 526.9200000000001, "end": 529.32, "text": " writing some more Go.", "tokens": [3579, 512, 544, 1037, 13], "temperature": 0.0, "avg_logprob": -0.1711062769736013, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00012324113049544394}, {"id": 128, "seek": 52096, "start": 529.32, "end": 533.48, "text": " So Rust solved that very nicely, and I think the main reason I actually got around to finishing", "tokens": [407, 34952, 13041, 300, 588, 9594, 11, 293, 286, 519, 264, 2135, 1778, 286, 767, 658, 926, 281, 12693], "temperature": 0.0, "avg_logprob": -0.1711062769736013, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00012324113049544394}, {"id": 129, "seek": 52096, "start": 533.48, "end": 536.0, "text": " this is because I was enjoying writing it.", "tokens": [341, 307, 570, 286, 390, 9929, 3579, 309, 13], "temperature": 0.0, "avg_logprob": -0.1711062769736013, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00012324113049544394}, {"id": 130, "seek": 52096, "start": 536.0, "end": 538.9200000000001, "text": " Additionally, the Rust community is fantastic.", "tokens": [19927, 11, 264, 34952, 1768, 307, 5456, 13], "temperature": 0.0, "avg_logprob": -0.1711062769736013, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00012324113049544394}, {"id": 131, "seek": 52096, "start": 538.9200000000001, "end": 542.1600000000001, "text": " Every time I've asked for help, people have been really helpful.", "tokens": [2048, 565, 286, 600, 2351, 337, 854, 11, 561, 362, 668, 534, 4961, 13], "temperature": 0.0, "avg_logprob": -0.1711062769736013, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00012324113049544394}, {"id": 132, "seek": 52096, "start": 542.1600000000001, "end": 545.32, "text": " Everything I wanted has been available, and they're just generally very welcoming and", "tokens": [5471, 286, 1415, 575, 668, 2435, 11, 293, 436, 434, 445, 5101, 588, 17378, 293], "temperature": 0.0, "avg_logprob": -0.1711062769736013, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00012324113049544394}, {"id": 133, "seek": 52096, "start": 545.32, "end": 550.5600000000001, "text": " accepting, especially compared to some other tech communities.", "tokens": [17391, 11, 2318, 5347, 281, 512, 661, 7553, 4456, 13], "temperature": 0.0, "avg_logprob": -0.1711062769736013, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00012324113049544394}, {"id": 134, "seek": 55056, "start": 550.56, "end": 555.1199999999999, "text": " So I actually have one other service, and I'm glad most of the previous talks have discussed", "tokens": [407, 286, 767, 362, 472, 661, 2643, 11, 293, 286, 478, 5404, 881, 295, 264, 3894, 6686, 362, 7152], "temperature": 0.0, "avg_logprob": -0.14335784912109376, "compression_ratio": 1.5910652920962198, "no_speech_prob": 7.54185821278952e-05}, {"id": 135, "seek": 55056, "start": 555.1199999999999, "end": 560.1199999999999, "text": " Python, because now I don't feel as weird for mentioning it in my presentation too.", "tokens": [15329, 11, 570, 586, 286, 500, 380, 841, 382, 3657, 337, 18315, 309, 294, 452, 5860, 886, 13], "temperature": 0.0, "avg_logprob": -0.14335784912109376, "compression_ratio": 1.5910652920962198, "no_speech_prob": 7.54185821278952e-05}, {"id": 136, "seek": 55056, "start": 560.1199999999999, "end": 564.1199999999999, "text": " I have another service called Rinsewind, a bit of a naming pattern there, if anyone's", "tokens": [286, 362, 1071, 2643, 1219, 497, 22134, 12199, 11, 257, 857, 295, 257, 25290, 5102, 456, 11, 498, 2878, 311], "temperature": 0.0, "avg_logprob": -0.14335784912109376, "compression_ratio": 1.5910652920962198, "no_speech_prob": 7.54185821278952e-05}, {"id": 137, "seek": 55056, "start": 564.1199999999999, "end": 565.56, "text": " familiar with it.", "tokens": [4963, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.14335784912109376, "compression_ratio": 1.5910652920962198, "no_speech_prob": 7.54185821278952e-05}, {"id": 138, "seek": 55056, "start": 565.56, "end": 570.92, "text": " And what this basically does is it peeks into the database and generates graphs like this,", "tokens": [400, 437, 341, 1936, 775, 307, 309, 19604, 82, 666, 264, 8149, 293, 23815, 24877, 411, 341, 11], "temperature": 0.0, "avg_logprob": -0.14335784912109376, "compression_ratio": 1.5910652920962198, "no_speech_prob": 7.54185821278952e-05}, {"id": 139, "seek": 55056, "start": 570.92, "end": 576.56, "text": " which are heavily inspired by the GitHub commit activity chart, but for your shell history.", "tokens": [597, 366, 10950, 7547, 538, 264, 23331, 5599, 5191, 6927, 11, 457, 337, 428, 8720, 2503, 13], "temperature": 0.0, "avg_logprob": -0.14335784912109376, "compression_ratio": 1.5910652920962198, "no_speech_prob": 7.54185821278952e-05}, {"id": 140, "seek": 57656, "start": 576.56, "end": 581.3199999999999, "text": " And it's currently closed source for no real reason other than that it's a really horrible", "tokens": [400, 309, 311, 4362, 5395, 4009, 337, 572, 957, 1778, 661, 813, 300, 309, 311, 257, 534, 9263], "temperature": 0.0, "avg_logprob": -0.12860017923208383, "compression_ratio": 1.6931407942238268, "no_speech_prob": 6.186602695379406e-05}, {"id": 141, "seek": 57656, "start": 581.3199999999999, "end": 585.4799999999999, "text": " hack that I don't want to package nicely for anyone.", "tokens": [10339, 300, 286, 500, 380, 528, 281, 7372, 9594, 337, 2878, 13], "temperature": 0.0, "avg_logprob": -0.12860017923208383, "compression_ratio": 1.6931407942238268, "no_speech_prob": 6.186602695379406e-05}, {"id": 142, "seek": 57656, "start": 585.4799999999999, "end": 589.28, "text": " It mostly uses NumPy and OpenCV and a few other things.", "tokens": [467, 5240, 4960, 22592, 47, 88, 293, 7238, 34, 53, 293, 257, 1326, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.12860017923208383, "compression_ratio": 1.6931407942238268, "no_speech_prob": 6.186602695379406e-05}, {"id": 143, "seek": 57656, "start": 589.28, "end": 594.3599999999999, "text": " It's also completely opt-in, so you don't get this by default if you don't want any proprietary", "tokens": [467, 311, 611, 2584, 2427, 12, 259, 11, 370, 291, 500, 380, 483, 341, 538, 7576, 498, 291, 500, 380, 528, 604, 38992], "temperature": 0.0, "avg_logprob": -0.12860017923208383, "compression_ratio": 1.6931407942238268, "no_speech_prob": 6.186602695379406e-05}, {"id": 144, "seek": 57656, "start": 594.3599999999999, "end": 595.4799999999999, "text": " code touching your data.", "tokens": [3089, 11175, 428, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12860017923208383, "compression_ratio": 1.6931407942238268, "no_speech_prob": 6.186602695379406e-05}, {"id": 145, "seek": 57656, "start": 595.4799999999999, "end": 596.4799999999999, "text": " You don't have to.", "tokens": [509, 500, 380, 362, 281, 13], "temperature": 0.0, "avg_logprob": -0.12860017923208383, "compression_ratio": 1.6931407942238268, "no_speech_prob": 6.186602695379406e-05}, {"id": 146, "seek": 57656, "start": 596.4799999999999, "end": 597.4799999999999, "text": " It's cool.", "tokens": [467, 311, 1627, 13], "temperature": 0.0, "avg_logprob": -0.12860017923208383, "compression_ratio": 1.6931407942238268, "no_speech_prob": 6.186602695379406e-05}, {"id": 147, "seek": 57656, "start": 597.4799999999999, "end": 601.92, "text": " Just with one curl command, you enable this.", "tokens": [1449, 365, 472, 22591, 5622, 11, 291, 9528, 341, 13], "temperature": 0.0, "avg_logprob": -0.12860017923208383, "compression_ratio": 1.6931407942238268, "no_speech_prob": 6.186602695379406e-05}, {"id": 148, "seek": 57656, "start": 601.92, "end": 606.1999999999999, "text": " On the open source side of things, this is the first open source project.", "tokens": [1282, 264, 1269, 4009, 1252, 295, 721, 11, 341, 307, 264, 700, 1269, 4009, 1716, 13], "temperature": 0.0, "avg_logprob": -0.12860017923208383, "compression_ratio": 1.6931407942238268, "no_speech_prob": 6.186602695379406e-05}, {"id": 149, "seek": 60620, "start": 606.2, "end": 609.6, "text": " I've released that people have actually been interested in.", "tokens": [286, 600, 4736, 300, 561, 362, 767, 668, 3102, 294, 13], "temperature": 0.0, "avg_logprob": -0.13464463212107883, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.00015344287385232747}, {"id": 150, "seek": 60620, "start": 609.6, "end": 614.12, "text": " I made it just for myself and stuck it on my GitHub, and it ended up being quite well", "tokens": [286, 1027, 309, 445, 337, 2059, 293, 5541, 309, 322, 452, 23331, 11, 293, 309, 4590, 493, 885, 1596, 731], "temperature": 0.0, "avg_logprob": -0.13464463212107883, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.00015344287385232747}, {"id": 151, "seek": 60620, "start": 614.12, "end": 616.32, "text": " received by a whole bunch of people.", "tokens": [4613, 538, 257, 1379, 3840, 295, 561, 13], "temperature": 0.0, "avg_logprob": -0.13464463212107883, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.00015344287385232747}, {"id": 152, "seek": 60620, "start": 616.32, "end": 619.32, "text": " We ended up in a lot of package repositories.", "tokens": [492, 4590, 493, 294, 257, 688, 295, 7372, 22283, 2083, 13], "temperature": 0.0, "avg_logprob": -0.13464463212107883, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.00015344287385232747}, {"id": 153, "seek": 60620, "start": 619.32, "end": 625.36, "text": " I think off the top of my head it's the Arch Linux community repo, Homebrew, Alpine Linux,", "tokens": [286, 519, 766, 264, 1192, 295, 452, 1378, 309, 311, 264, 10984, 18734, 1768, 49040, 11, 8719, 65, 2236, 11, 967, 40412, 18734, 11], "temperature": 0.0, "avg_logprob": -0.13464463212107883, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.00015344287385232747}, {"id": 154, "seek": 60620, "start": 625.36, "end": 626.36, "text": " and some Nix.", "tokens": [293, 512, 426, 970, 13], "temperature": 0.0, "avg_logprob": -0.13464463212107883, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.00015344287385232747}, {"id": 155, "seek": 60620, "start": 626.36, "end": 630.08, "text": " I'm not entirely sure how Nix works, but one of the Nix repositories.", "tokens": [286, 478, 406, 7696, 988, 577, 426, 970, 1985, 11, 457, 472, 295, 264, 426, 970, 22283, 2083, 13], "temperature": 0.0, "avg_logprob": -0.13464463212107883, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.00015344287385232747}, {"id": 156, "seek": 60620, "start": 630.08, "end": 633.6, "text": " And there's probably a whole bunch more that I'm not aware of.", "tokens": [400, 456, 311, 1391, 257, 1379, 3840, 544, 300, 286, 478, 406, 3650, 295, 13], "temperature": 0.0, "avg_logprob": -0.13464463212107883, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.00015344287385232747}, {"id": 157, "seek": 63360, "start": 633.6, "end": 638.76, "text": " And we've actually got 63 contributors at sort of as of today.", "tokens": [400, 321, 600, 767, 658, 25082, 45627, 412, 1333, 295, 382, 295, 965, 13], "temperature": 0.0, "avg_logprob": -0.13736619724063423, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.00010836668661795557}, {"id": 158, "seek": 63360, "start": 638.76, "end": 642.72, "text": " Some of them are sort of returning regular contributors, which is very nice that people", "tokens": [2188, 295, 552, 366, 1333, 295, 12678, 3890, 45627, 11, 597, 307, 588, 1481, 300, 561], "temperature": 0.0, "avg_logprob": -0.13736619724063423, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.00010836668661795557}, {"id": 159, "seek": 63360, "start": 642.72, "end": 645.6, "text": " want to regularly give time to my project.", "tokens": [528, 281, 11672, 976, 565, 281, 452, 1716, 13], "temperature": 0.0, "avg_logprob": -0.13736619724063423, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.00010836668661795557}, {"id": 160, "seek": 63360, "start": 645.6, "end": 647.4, "text": " Some of them are just sort of drive by.", "tokens": [2188, 295, 552, 366, 445, 1333, 295, 3332, 538, 13], "temperature": 0.0, "avg_logprob": -0.13736619724063423, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.00010836668661795557}, {"id": 161, "seek": 63360, "start": 647.4, "end": 650.9200000000001, "text": " They found something that annoyed them or bug they wanted to fix or something like that,", "tokens": [814, 1352, 746, 300, 25921, 552, 420, 7426, 436, 1415, 281, 3191, 420, 746, 411, 300, 11], "temperature": 0.0, "avg_logprob": -0.13736619724063423, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.00010836668661795557}, {"id": 162, "seek": 63360, "start": 650.9200000000001, "end": 653.32, "text": " so they contributed, which was lovely.", "tokens": [370, 436, 18434, 11, 597, 390, 7496, 13], "temperature": 0.0, "avg_logprob": -0.13736619724063423, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.00010836668661795557}, {"id": 163, "seek": 63360, "start": 653.32, "end": 656.0, "text": " I'd also like to especially thank Conrad.", "tokens": [286, 1116, 611, 411, 281, 2318, 1309, 2656, 6206, 13], "temperature": 0.0, "avg_logprob": -0.13736619724063423, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.00010836668661795557}, {"id": 164, "seek": 63360, "start": 656.0, "end": 659.5600000000001, "text": " He's much more involved in the Rust community than I am and also a very long-term friend", "tokens": [634, 311, 709, 544, 3288, 294, 264, 34952, 1768, 813, 286, 669, 293, 611, 257, 588, 938, 12, 7039, 1277], "temperature": 0.0, "avg_logprob": -0.13736619724063423, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.00010836668661795557}, {"id": 165, "seek": 63360, "start": 659.5600000000001, "end": 660.96, "text": " of mine.", "tokens": [295, 3892, 13], "temperature": 0.0, "avg_logprob": -0.13736619724063423, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.00010836668661795557}, {"id": 166, "seek": 66096, "start": 660.96, "end": 665.64, "text": " He helps me maintain a twin, and when I was first starting and not so good at Rust, he", "tokens": [634, 3665, 385, 6909, 257, 18397, 11, 293, 562, 286, 390, 700, 2891, 293, 406, 370, 665, 412, 34952, 11, 415], "temperature": 0.0, "avg_logprob": -0.14072286671605602, "compression_ratio": 1.6875, "no_speech_prob": 0.0001342257746728137}, {"id": 167, "seek": 66096, "start": 665.64, "end": 670.64, "text": " did a great job of tidying things up a bit.", "tokens": [630, 257, 869, 1691, 295, 9422, 1840, 721, 493, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.14072286671605602, "compression_ratio": 1.6875, "no_speech_prob": 0.0001342257746728137}, {"id": 168, "seek": 66096, "start": 670.64, "end": 675.6, "text": " In terms of the future, right now a twin has a bit of a flaw in that you can't actually", "tokens": [682, 2115, 295, 264, 2027, 11, 558, 586, 257, 18397, 575, 257, 857, 295, 257, 13717, 294, 300, 291, 393, 380, 767], "temperature": 0.0, "avg_logprob": -0.14072286671605602, "compression_ratio": 1.6875, "no_speech_prob": 0.0001342257746728137}, {"id": 169, "seek": 66096, "start": 675.6, "end": 678.96, "text": " delete history once it's been synced.", "tokens": [12097, 2503, 1564, 309, 311, 668, 5451, 1232, 13], "temperature": 0.0, "avg_logprob": -0.14072286671605602, "compression_ratio": 1.6875, "no_speech_prob": 0.0001342257746728137}, {"id": 170, "seek": 66096, "start": 678.96, "end": 683.08, "text": " This is mostly because the sync's pretty eventually consistent, and every machine you have is a", "tokens": [639, 307, 5240, 570, 264, 20271, 311, 1238, 4728, 8398, 11, 293, 633, 3479, 291, 362, 307, 257], "temperature": 0.0, "avg_logprob": -0.14072286671605602, "compression_ratio": 1.6875, "no_speech_prob": 0.0001342257746728137}, {"id": 171, "seek": 66096, "start": 683.08, "end": 687.52, "text": " potential writer, so ensuring that you delete something and it stays deleted is actually", "tokens": [3995, 9936, 11, 370, 16882, 300, 291, 12097, 746, 293, 309, 10834, 22981, 307, 767], "temperature": 0.0, "avg_logprob": -0.14072286671605602, "compression_ratio": 1.6875, "no_speech_prob": 0.0001342257746728137}, {"id": 172, "seek": 66096, "start": 687.52, "end": 688.52, "text": " really difficult.", "tokens": [534, 2252, 13], "temperature": 0.0, "avg_logprob": -0.14072286671605602, "compression_ratio": 1.6875, "no_speech_prob": 0.0001342257746728137}, {"id": 173, "seek": 68852, "start": 688.52, "end": 692.76, "text": " I've currently got a solution to it, which works on my laptop.", "tokens": [286, 600, 4362, 658, 257, 3827, 281, 309, 11, 597, 1985, 322, 452, 10732, 13], "temperature": 0.0, "avg_logprob": -0.12292854845031234, "compression_ratio": 1.6900369003690037, "no_speech_prob": 9.732567559694871e-05}, {"id": 174, "seek": 68852, "start": 692.76, "end": 696.64, "text": " I just need to make sure it works on everyone else's too.", "tokens": [286, 445, 643, 281, 652, 988, 309, 1985, 322, 1518, 1646, 311, 886, 13], "temperature": 0.0, "avg_logprob": -0.12292854845031234, "compression_ratio": 1.6900369003690037, "no_speech_prob": 9.732567559694871e-05}, {"id": 175, "seek": 68852, "start": 696.64, "end": 701.72, "text": " I'd also like to sort out bash, because pretty much all the complaints we get about shell", "tokens": [286, 1116, 611, 411, 281, 1333, 484, 46183, 11, 570, 1238, 709, 439, 264, 19585, 321, 483, 466, 8720], "temperature": 0.0, "avg_logprob": -0.12292854845031234, "compression_ratio": 1.6900369003690037, "no_speech_prob": 9.732567559694871e-05}, {"id": 176, "seek": 68852, "start": 701.72, "end": 706.1999999999999, "text": " integrations are from people running bash, and it's very frustrating.", "tokens": [3572, 763, 366, 490, 561, 2614, 46183, 11, 293, 309, 311, 588, 16522, 13], "temperature": 0.0, "avg_logprob": -0.12292854845031234, "compression_ratio": 1.6900369003690037, "no_speech_prob": 9.732567559694871e-05}, {"id": 177, "seek": 68852, "start": 706.1999999999999, "end": 711.72, "text": " I think I don't actually use bash, and I hate having a setup on my machine just for that.", "tokens": [286, 519, 286, 500, 380, 767, 764, 46183, 11, 293, 286, 4700, 1419, 257, 8657, 322, 452, 3479, 445, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.12292854845031234, "compression_ratio": 1.6900369003690037, "no_speech_prob": 9.732567559694871e-05}, {"id": 178, "seek": 68852, "start": 711.72, "end": 716.68, "text": " I'd also like to show some more information in the TUI, so I don't know if you saw very", "tokens": [286, 1116, 611, 411, 281, 855, 512, 544, 1589, 294, 264, 42408, 40, 11, 370, 286, 500, 380, 458, 498, 291, 1866, 588], "temperature": 0.0, "avg_logprob": -0.12292854845031234, "compression_ratio": 1.6900369003690037, "no_speech_prob": 9.732567559694871e-05}, {"id": 179, "seek": 71668, "start": 716.68, "end": 721.0799999999999, "text": " much on the GIF earlier, but it basically just shows what's useful for search results.", "tokens": [709, 322, 264, 460, 12775, 3071, 11, 457, 309, 1936, 445, 3110, 437, 311, 4420, 337, 3164, 3542, 13], "temperature": 0.0, "avg_logprob": -0.1310031184443721, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.333470759680495e-05}, {"id": 180, "seek": 71668, "start": 721.0799999999999, "end": 725.3599999999999, "text": " I would love it if there was another tab where you could also see sort of statistics about", "tokens": [286, 576, 959, 309, 498, 456, 390, 1071, 4421, 689, 291, 727, 611, 536, 1333, 295, 12523, 466], "temperature": 0.0, "avg_logprob": -0.1310031184443721, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.333470759680495e-05}, {"id": 181, "seek": 71668, "start": 725.3599999999999, "end": 730.3599999999999, "text": " a command that's run, maybe how often it succeeds versus fails, you could get some nice stats", "tokens": [257, 5622, 300, 311, 1190, 11, 1310, 577, 2049, 309, 49263, 5717, 18199, 11, 291, 727, 483, 512, 1481, 18152], "temperature": 0.0, "avg_logprob": -0.1310031184443721, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.333470759680495e-05}, {"id": 182, "seek": 71668, "start": 730.3599999999999, "end": 733.76, "text": " about make build that way, and that sort of thing.", "tokens": [466, 652, 1322, 300, 636, 11, 293, 300, 1333, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.1310031184443721, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.333470759680495e-05}, {"id": 183, "seek": 71668, "start": 733.76, "end": 740.2399999999999, "text": " I'd like to improve the search a little bit too, because right now it's good enough, and", "tokens": [286, 1116, 411, 281, 3470, 264, 3164, 257, 707, 857, 886, 11, 570, 558, 586, 309, 311, 665, 1547, 11, 293], "temperature": 0.0, "avg_logprob": -0.1310031184443721, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.333470759680495e-05}, {"id": 184, "seek": 71668, "start": 740.2399999999999, "end": 741.7199999999999, "text": " I think it could always be improved.", "tokens": [286, 519, 309, 727, 1009, 312, 9689, 13], "temperature": 0.0, "avg_logprob": -0.1310031184443721, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.333470759680495e-05}, {"id": 185, "seek": 71668, "start": 741.7199999999999, "end": 746.4399999999999, "text": " I've been meaning to explore some of the full-text search modules that SQLite has, or maybe", "tokens": [286, 600, 668, 3620, 281, 6839, 512, 295, 264, 1577, 12, 25111, 3164, 16679, 300, 19200, 642, 575, 11, 420, 1310], "temperature": 0.0, "avg_logprob": -0.1310031184443721, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.333470759680495e-05}, {"id": 186, "seek": 74644, "start": 746.44, "end": 750.6400000000001, "text": " something like Tantivi or one of the other search libraries in Rust.", "tokens": [746, 411, 314, 394, 33448, 420, 472, 295, 264, 661, 3164, 15148, 294, 34952, 13], "temperature": 0.0, "avg_logprob": -0.19533098206039548, "compression_ratio": 1.610738255033557, "no_speech_prob": 9.147923265118152e-05}, {"id": 187, "seek": 74644, "start": 750.6400000000001, "end": 755.0400000000001, "text": " Otherwise, I'd really like to improve the sorting.", "tokens": [10328, 11, 286, 1116, 534, 411, 281, 3470, 264, 32411, 13], "temperature": 0.0, "avg_logprob": -0.19533098206039548, "compression_ratio": 1.610738255033557, "no_speech_prob": 9.147923265118152e-05}, {"id": 188, "seek": 74644, "start": 755.0400000000001, "end": 758.96, "text": " Right now we sort chronologically, which is a pretty safe default.", "tokens": [1779, 586, 321, 1333, 19393, 17157, 11, 597, 307, 257, 1238, 3273, 7576, 13], "temperature": 0.0, "avg_logprob": -0.19533098206039548, "compression_ratio": 1.610738255033557, "no_speech_prob": 9.147923265118152e-05}, {"id": 189, "seek": 74644, "start": 758.96, "end": 763.08, "text": " I'm not going to turn this into a horrible Twitter timeline type thing, but it would", "tokens": [286, 478, 406, 516, 281, 1261, 341, 666, 257, 9263, 5794, 12933, 2010, 551, 11, 457, 309, 576], "temperature": 0.0, "avg_logprob": -0.19533098206039548, "compression_ratio": 1.610738255033557, "no_speech_prob": 9.147923265118152e-05}, {"id": 190, "seek": 74644, "start": 763.08, "end": 766.6800000000001, "text": " be nice if we could sort based on the context we have.", "tokens": [312, 1481, 498, 321, 727, 1333, 2361, 322, 264, 4319, 321, 362, 13], "temperature": 0.0, "avg_logprob": -0.19533098206039548, "compression_ratio": 1.610738255033557, "no_speech_prob": 9.147923265118152e-05}, {"id": 191, "seek": 74644, "start": 766.6800000000001, "end": 770.9200000000001, "text": " Maybe every day at 9 a.m. you CD into your repo and you run GitPool.", "tokens": [2704, 633, 786, 412, 1722, 257, 13, 76, 13, 291, 6743, 666, 428, 49040, 293, 291, 1190, 16939, 47, 1092, 13], "temperature": 0.0, "avg_logprob": -0.19533098206039548, "compression_ratio": 1.610738255033557, "no_speech_prob": 9.147923265118152e-05}, {"id": 192, "seek": 74644, "start": 770.9200000000001, "end": 774.72, "text": " By default, it would be nice if you pressed Ctrl R, and GitPool was already there at", "tokens": [3146, 7576, 11, 309, 576, 312, 1481, 498, 291, 17355, 35233, 497, 11, 293, 16939, 47, 1092, 390, 1217, 456, 412], "temperature": 0.0, "avg_logprob": -0.19533098206039548, "compression_ratio": 1.610738255033557, "no_speech_prob": 9.147923265118152e-05}, {"id": 193, "seek": 77472, "start": 774.72, "end": 776.76, "text": " the time that you frequently run it.", "tokens": [264, 565, 300, 291, 10374, 1190, 309, 13], "temperature": 0.0, "avg_logprob": -0.0877853546823774, "compression_ratio": 1.711111111111111, "no_speech_prob": 9.638731717132032e-05}, {"id": 194, "seek": 77472, "start": 776.76, "end": 781.12, "text": " We've got all the data for that, it just needs to be plugged together.", "tokens": [492, 600, 658, 439, 264, 1412, 337, 300, 11, 309, 445, 2203, 281, 312, 25679, 1214, 13], "temperature": 0.0, "avg_logprob": -0.0877853546823774, "compression_ratio": 1.711111111111111, "no_speech_prob": 9.638731717132032e-05}, {"id": 195, "seek": 77472, "start": 781.12, "end": 786.88, "text": " In the even further future, the number of people that have spoken to me about the fact", "tokens": [682, 264, 754, 3052, 2027, 11, 264, 1230, 295, 561, 300, 362, 10759, 281, 385, 466, 264, 1186], "temperature": 0.0, "avg_logprob": -0.0877853546823774, "compression_ratio": 1.711111111111111, "no_speech_prob": 9.638731717132032e-05}, {"id": 196, "seek": 77472, "start": 786.88, "end": 791.84, "text": " that they have development API keys in their shell history, it would be nice if we could", "tokens": [300, 436, 362, 3250, 9362, 9317, 294, 641, 8720, 2503, 11, 309, 576, 312, 1481, 498, 321, 727], "temperature": 0.0, "avg_logprob": -0.0877853546823774, "compression_ratio": 1.711111111111111, "no_speech_prob": 9.638731717132032e-05}, {"id": 197, "seek": 77472, "start": 791.84, "end": 797.6, "text": " do something to get that out of the shell history and sync that alongside the data.", "tokens": [360, 746, 281, 483, 300, 484, 295, 264, 8720, 2503, 293, 20271, 300, 12385, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.0877853546823774, "compression_ratio": 1.711111111111111, "no_speech_prob": 9.638731717132032e-05}, {"id": 198, "seek": 77472, "start": 797.6, "end": 803.5600000000001, "text": " Being able to bookmark commands is also something I would quite like to be able to do, because", "tokens": [8891, 1075, 281, 1446, 5638, 16901, 307, 611, 746, 286, 576, 1596, 411, 281, 312, 1075, 281, 360, 11, 570], "temperature": 0.0, "avg_logprob": -0.0877853546823774, "compression_ratio": 1.711111111111111, "no_speech_prob": 9.638731717132032e-05}, {"id": 199, "seek": 80356, "start": 803.56, "end": 808.0, "text": " there's some longer commands I run frequently in search for, frequently having some sort", "tokens": [456, 311, 512, 2854, 16901, 286, 1190, 10374, 294, 3164, 337, 11, 10374, 1419, 512, 1333], "temperature": 0.0, "avg_logprob": -0.19534087181091309, "compression_ratio": 1.6098484848484849, "no_speech_prob": 7.418133463943377e-05}, {"id": 200, "seek": 80356, "start": 808.0, "end": 810.92, "text": " of hockey or alias would be really nice.", "tokens": [295, 22449, 420, 419, 4609, 576, 312, 534, 1481, 13], "temperature": 0.0, "avg_logprob": -0.19534087181091309, "compression_ratio": 1.6098484848484849, "no_speech_prob": 7.418133463943377e-05}, {"id": 201, "seek": 80356, "start": 810.92, "end": 817.52, "text": " Otherwise, I realized that a subset of a two-end history could also be used as a runbook if", "tokens": [10328, 11, 286, 5334, 300, 257, 25993, 295, 257, 732, 12, 521, 2503, 727, 611, 312, 1143, 382, 257, 1190, 2939, 498], "temperature": 0.0, "avg_logprob": -0.19534087181091309, "compression_ratio": 1.6098484848484849, "no_speech_prob": 7.418133463943377e-05}, {"id": 202, "seek": 80356, "start": 817.52, "end": 822.28, "text": " you had to begin and an end marker to it, and you could just replay some commands from", "tokens": [291, 632, 281, 1841, 293, 364, 917, 15247, 281, 309, 11, 293, 291, 727, 445, 23836, 512, 16901, 490], "temperature": 0.0, "avg_logprob": -0.19534087181091309, "compression_ratio": 1.6098484848484849, "no_speech_prob": 7.418133463943377e-05}, {"id": 203, "seek": 80356, "start": 822.28, "end": 824.28, "text": " your past.", "tokens": [428, 1791, 13], "temperature": 0.0, "avg_logprob": -0.19534087181091309, "compression_ratio": 1.6098484848484849, "no_speech_prob": 7.418133463943377e-05}, {"id": 204, "seek": 80356, "start": 824.28, "end": 826.16, "text": " That's actually it.", "tokens": [663, 311, 767, 309, 13], "temperature": 0.0, "avg_logprob": -0.19534087181091309, "compression_ratio": 1.6098484848484849, "no_speech_prob": 7.418133463943377e-05}, {"id": 205, "seek": 80356, "start": 826.16, "end": 830.4, "text": " I went a bit faster than I was expecting, but if there are any questions, I'd be very", "tokens": [286, 1437, 257, 857, 4663, 813, 286, 390, 9650, 11, 457, 498, 456, 366, 604, 1651, 11, 286, 1116, 312, 588], "temperature": 0.0, "avg_logprob": -0.19534087181091309, "compression_ratio": 1.6098484848484849, "no_speech_prob": 7.418133463943377e-05}, {"id": 206, "seek": 83040, "start": 830.4, "end": 846.56, "text": " happy to answer them.", "tokens": [2055, 281, 1867, 552, 13], "temperature": 0.0, "avg_logprob": -0.21061111708818855, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.00047545976121909916}, {"id": 207, "seek": 83040, "start": 846.56, "end": 852.52, "text": " Can you search for things which have come after your most recent command frequently?", "tokens": [1664, 291, 3164, 337, 721, 597, 362, 808, 934, 428, 881, 5162, 5622, 10374, 30], "temperature": 0.0, "avg_logprob": -0.21061111708818855, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.00047545976121909916}, {"id": 208, "seek": 83040, "start": 852.52, "end": 854.4, "text": " I'm not sure what you mean, sorry.", "tokens": [286, 478, 406, 988, 437, 291, 914, 11, 2597, 13], "temperature": 0.0, "avg_logprob": -0.21061111708818855, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.00047545976121909916}, {"id": 209, "seek": 83040, "start": 854.4, "end": 859.4399999999999, "text": " So to take what you've just typed and see what you typically do next, so actually returning", "tokens": [407, 281, 747, 437, 291, 600, 445, 33941, 293, 536, 437, 291, 5850, 360, 958, 11, 370, 767, 12678], "temperature": 0.0, "avg_logprob": -0.21061111708818855, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.00047545976121909916}, {"id": 210, "seek": 85944, "start": 859.44, "end": 861.8800000000001, "text": " the command after the one you've searched for.", "tokens": [264, 5622, 934, 264, 472, 291, 600, 22961, 337, 13], "temperature": 0.0, "avg_logprob": -0.2126840353012085, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0009080665186047554}, {"id": 211, "seek": 85944, "start": 861.8800000000001, "end": 865.96, "text": " That's one of the things I'd love to be able to do with the smarter ordering is know that", "tokens": [663, 311, 472, 295, 264, 721, 286, 1116, 959, 281, 312, 1075, 281, 360, 365, 264, 20294, 21739, 307, 458, 300], "temperature": 0.0, "avg_logprob": -0.2126840353012085, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0009080665186047554}, {"id": 212, "seek": 85944, "start": 865.96, "end": 870.5600000000001, "text": " like a sequence of commands that's commonly run and predict the next one based on history,", "tokens": [411, 257, 8310, 295, 16901, 300, 311, 12719, 1190, 293, 6069, 264, 958, 472, 2361, 322, 2503, 11], "temperature": 0.0, "avg_logprob": -0.2126840353012085, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0009080665186047554}, {"id": 213, "seek": 85944, "start": 870.5600000000001, "end": 881.7600000000001, "text": " if that's, yeah.", "tokens": [498, 300, 311, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.2126840353012085, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0009080665186047554}, {"id": 214, "seek": 85944, "start": 881.7600000000001, "end": 887.0400000000001, "text": " So I tried to install your tool, but I'm using Bash, and I was wondering how far are you with", "tokens": [407, 286, 3031, 281, 3625, 428, 2290, 11, 457, 286, 478, 1228, 43068, 11, 293, 286, 390, 6359, 577, 1400, 366, 291, 365], "temperature": 0.0, "avg_logprob": -0.2126840353012085, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0009080665186047554}, {"id": 215, "seek": 85944, "start": 887.0400000000001, "end": 888.72, "text": " like fixing Bash?", "tokens": [411, 19442, 43068, 30], "temperature": 0.0, "avg_logprob": -0.2126840353012085, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0009080665186047554}, {"id": 216, "seek": 88872, "start": 888.72, "end": 890.24, "text": " Bash generally works fine.", "tokens": [43068, 5101, 1985, 2489, 13], "temperature": 0.0, "avg_logprob": -0.22628876898023817, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00040714952046982944}, {"id": 217, "seek": 88872, "start": 890.24, "end": 895.4, "text": " It's usually the people that have a whole bunch of Bash plugins installed or have a", "tokens": [467, 311, 2673, 264, 561, 300, 362, 257, 1379, 3840, 295, 43068, 33759, 8899, 420, 362, 257], "temperature": 0.0, "avg_logprob": -0.22628876898023817, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00040714952046982944}, {"id": 218, "seek": 88872, "start": 895.4, "end": 900.52, "text": " weird Bash prompt that start to have some issues, but generally, it's okay for most", "tokens": [3657, 43068, 12391, 300, 722, 281, 362, 512, 2663, 11, 457, 5101, 11, 309, 311, 1392, 337, 881], "temperature": 0.0, "avg_logprob": -0.22628876898023817, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00040714952046982944}, {"id": 219, "seek": 88872, "start": 900.52, "end": 901.52, "text": " people.", "tokens": [561, 13], "temperature": 0.0, "avg_logprob": -0.22628876898023817, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00040714952046982944}, {"id": 220, "seek": 88872, "start": 901.52, "end": 902.52, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.22628876898023817, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00040714952046982944}, {"id": 221, "seek": 88872, "start": 902.52, "end": 903.52, "text": " Sorry.", "tokens": [4919, 13], "temperature": 0.0, "avg_logprob": -0.22628876898023817, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00040714952046982944}, {"id": 222, "seek": 88872, "start": 903.52, "end": 916.96, "text": " Does it handle having different cells in different computers?", "tokens": [4402, 309, 4813, 1419, 819, 5438, 294, 819, 10807, 30], "temperature": 0.0, "avg_logprob": -0.22628876898023817, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00040714952046982944}, {"id": 223, "seek": 91696, "start": 916.96, "end": 923.64, "text": " For example, if I'm using one computer piece and another CS8, does the same work between", "tokens": [1171, 1365, 11, 498, 286, 478, 1228, 472, 3820, 2522, 293, 1071, 9460, 23, 11, 775, 264, 912, 589, 1296], "temperature": 0.0, "avg_logprob": -0.2511638315712533, "compression_ratio": 1.3816425120772946, "no_speech_prob": 0.0031816980335861444}, {"id": 224, "seek": 91696, "start": 923.64, "end": 924.64, "text": " those two?", "tokens": [729, 732, 30], "temperature": 0.0, "avg_logprob": -0.2511638315712533, "compression_ratio": 1.3816425120772946, "no_speech_prob": 0.0031816980335861444}, {"id": 225, "seek": 91696, "start": 924.64, "end": 925.64, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.2511638315712533, "compression_ratio": 1.3816425120772946, "no_speech_prob": 0.0031816980335861444}, {"id": 226, "seek": 91696, "start": 925.64, "end": 931.12, "text": " So we translate from whatever your shell uses natively into the format we use, so whichever", "tokens": [407, 321, 13799, 490, 2035, 428, 8720, 4960, 8470, 356, 666, 264, 7877, 321, 764, 11, 370, 24123], "temperature": 0.0, "avg_logprob": -0.2511638315712533, "compression_ratio": 1.3816425120772946, "no_speech_prob": 0.0031816980335861444}, {"id": 227, "seek": 91696, "start": 931.12, "end": 933.12, "text": " shell you use on each machine doesn't matter.", "tokens": [8720, 291, 764, 322, 1184, 3479, 1177, 380, 1871, 13], "temperature": 0.0, "avg_logprob": -0.2511638315712533, "compression_ratio": 1.3816425120772946, "no_speech_prob": 0.0031816980335861444}, {"id": 228, "seek": 91696, "start": 933.12, "end": 934.12, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2511638315712533, "compression_ratio": 1.3816425120772946, "no_speech_prob": 0.0031816980335861444}, {"id": 229, "seek": 91696, "start": 934.12, "end": 935.12, "text": " Thanks.", "tokens": [2561, 13], "temperature": 0.0, "avg_logprob": -0.2511638315712533, "compression_ratio": 1.3816425120772946, "no_speech_prob": 0.0031816980335861444}, {"id": 230, "seek": 91696, "start": 935.12, "end": 940.32, "text": " I have a couple of questions.", "tokens": [286, 362, 257, 1916, 295, 1651, 13], "temperature": 0.0, "avg_logprob": -0.2511638315712533, "compression_ratio": 1.3816425120772946, "no_speech_prob": 0.0031816980335861444}, {"id": 231, "seek": 94032, "start": 940.32, "end": 947.12, "text": " First, I didn't quite get how do you authenticate with the server by having a key analysis?", "tokens": [2386, 11, 286, 994, 380, 1596, 483, 577, 360, 291, 9214, 8700, 365, 264, 7154, 538, 1419, 257, 2141, 5215, 30], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 232, "seek": 94032, "start": 947.12, "end": 951.8000000000001, "text": " So the sort of user authentication is just a username and password, but then your actual", "tokens": [407, 264, 1333, 295, 4195, 26643, 307, 445, 257, 30351, 293, 11524, 11, 457, 550, 428, 3539], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 233, "seek": 94032, "start": 951.8000000000001, "end": 955.1600000000001, "text": " data is encrypted by a key that's only held locally.", "tokens": [1412, 307, 36663, 538, 257, 2141, 300, 311, 787, 5167, 16143, 13], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 234, "seek": 94032, "start": 955.1600000000001, "end": 956.1600000000001, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 235, "seek": 94032, "start": 956.1600000000001, "end": 957.1600000000001, "text": " And second question.", "tokens": [400, 1150, 1168, 13], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 236, "seek": 94032, "start": 957.1600000000001, "end": 962.1600000000001, "text": " Do you have a ZSH plugin or have you considered one?", "tokens": [1144, 291, 362, 257, 1176, 17308, 23407, 420, 362, 291, 4888, 472, 30], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 237, "seek": 94032, "start": 962.1600000000001, "end": 963.44, "text": " So we have a ZSH plugin.", "tokens": [407, 321, 362, 257, 1176, 17308, 23407, 13], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 238, "seek": 94032, "start": 963.44, "end": 967.32, "text": " You can use normal ZSH plugin managers to install and use it.", "tokens": [509, 393, 764, 2710, 1176, 17308, 23407, 14084, 281, 3625, 293, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 239, "seek": 94032, "start": 967.32, "end": 968.32, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 240, "seek": 94032, "start": 968.32, "end": 969.32, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.20692168871561686, "compression_ratio": 1.6550387596899225, "no_speech_prob": 0.0015901882434263825}, {"id": 241, "seek": 96932, "start": 969.32, "end": 981.4000000000001, "text": " Getting some exercise in.", "tokens": [13674, 512, 5380, 294, 13], "temperature": 0.0, "avg_logprob": -0.20272443169041685, "compression_ratio": 1.4432432432432432, "no_speech_prob": 0.0004852942656725645}, {"id": 242, "seek": 96932, "start": 981.4000000000001, "end": 991.12, "text": " Is it possible to disable the history for a few commands and then re-enable it?", "tokens": [1119, 309, 1944, 281, 28362, 264, 2503, 337, 257, 1326, 16901, 293, 550, 319, 12, 268, 712, 309, 30], "temperature": 0.0, "avg_logprob": -0.20272443169041685, "compression_ratio": 1.4432432432432432, "no_speech_prob": 0.0004852942656725645}, {"id": 243, "seek": 96932, "start": 991.12, "end": 992.12, "text": " Not currently.", "tokens": [1726, 4362, 13], "temperature": 0.0, "avg_logprob": -0.20272443169041685, "compression_ratio": 1.4432432432432432, "no_speech_prob": 0.0004852942656725645}, {"id": 244, "seek": 96932, "start": 992.12, "end": 994.8800000000001, "text": " We have spoken about the idea of like an incognito mode.", "tokens": [492, 362, 10759, 466, 264, 1558, 295, 411, 364, 834, 2912, 3528, 4391, 13], "temperature": 0.0, "avg_logprob": -0.20272443169041685, "compression_ratio": 1.4432432432432432, "no_speech_prob": 0.0004852942656725645}, {"id": 245, "seek": 96932, "start": 994.8800000000001, "end": 998.8800000000001, "text": " If you prefix a command with a space, it won't be saved, but it's kind of annoying if you", "tokens": [759, 291, 46969, 257, 5622, 365, 257, 1901, 11, 309, 1582, 380, 312, 6624, 11, 457, 309, 311, 733, 295, 11304, 498, 291], "temperature": 0.0, "avg_logprob": -0.20272443169041685, "compression_ratio": 1.4432432432432432, "no_speech_prob": 0.0004852942656725645}, {"id": 246, "seek": 99888, "start": 998.88, "end": 1001.72, "text": " got to run a lot of them in a row.", "tokens": [658, 281, 1190, 257, 688, 295, 552, 294, 257, 5386, 13], "temperature": 0.0, "avg_logprob": -0.2910025879576966, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00038336520083248615}, {"id": 247, "seek": 99888, "start": 1001.72, "end": 1006.08, "text": " We have some questions from the matrix.", "tokens": [492, 362, 512, 1651, 490, 264, 8141, 13], "temperature": 0.0, "avg_logprob": -0.2910025879576966, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00038336520083248615}, {"id": 248, "seek": 99888, "start": 1006.08, "end": 1011.96, "text": " So Olivier Robert says, how would it interact with something like Starship?", "tokens": [407, 48075, 7977, 1619, 11, 577, 576, 309, 4648, 365, 746, 411, 20957, 1210, 30], "temperature": 0.0, "avg_logprob": -0.2910025879576966, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00038336520083248615}, {"id": 249, "seek": 99888, "start": 1011.96, "end": 1017.36, "text": " I actually use Starship and it doesn't interact with it at all in that it works completely", "tokens": [286, 767, 764, 20957, 1210, 293, 309, 1177, 380, 4648, 365, 309, 412, 439, 294, 300, 309, 1985, 2584], "temperature": 0.0, "avg_logprob": -0.2910025879576966, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00038336520083248615}, {"id": 250, "seek": 99888, "start": 1017.36, "end": 1018.36, "text": " fine.", "tokens": [2489, 13], "temperature": 0.0, "avg_logprob": -0.2910025879576966, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00038336520083248615}, {"id": 251, "seek": 99888, "start": 1018.36, "end": 1019.36, "text": " Awesome.", "tokens": [10391, 13], "temperature": 0.0, "avg_logprob": -0.2910025879576966, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00038336520083248615}, {"id": 252, "seek": 99888, "start": 1019.36, "end": 1024.16, "text": " And yep, that was the other question.", "tokens": [400, 18633, 11, 300, 390, 264, 661, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2910025879576966, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00038336520083248615}, {"id": 253, "seek": 99888, "start": 1024.16, "end": 1025.16, "text": " Cool.", "tokens": [8561, 13], "temperature": 0.0, "avg_logprob": -0.2910025879576966, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00038336520083248615}, {"id": 254, "seek": 99888, "start": 1025.16, "end": 1026.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.2910025879576966, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00038336520083248615}, {"id": 255, "seek": 102616, "start": 1026.16, "end": 1030.68, "text": " There's one at the front, too.", "tokens": [821, 311, 472, 412, 264, 1868, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.3464853056184538, "compression_ratio": 1.4251207729468598, "no_speech_prob": 0.0003713517216965556}, {"id": 256, "seek": 102616, "start": 1030.68, "end": 1034.5600000000002, "text": " Two short questions.", "tokens": [4453, 2099, 1651, 13], "temperature": 0.0, "avg_logprob": -0.3464853056184538, "compression_ratio": 1.4251207729468598, "no_speech_prob": 0.0003713517216965556}, {"id": 257, "seek": 102616, "start": 1034.5600000000002, "end": 1040.1200000000001, "text": " The first one is, since I'm using BESH, what's your favorite shell?", "tokens": [440, 700, 472, 307, 11, 1670, 286, 478, 1228, 363, 2358, 39, 11, 437, 311, 428, 2954, 8720, 30], "temperature": 0.0, "avg_logprob": -0.3464853056184538, "compression_ratio": 1.4251207729468598, "no_speech_prob": 0.0003713517216965556}, {"id": 258, "seek": 102616, "start": 1040.1200000000001, "end": 1045.28, "text": " I like ZSH, I think purely because I started using it maybe 10 years ago and have it so", "tokens": [286, 411, 1176, 17308, 11, 286, 519, 17491, 570, 286, 1409, 1228, 309, 1310, 1266, 924, 2057, 293, 362, 309, 370], "temperature": 0.0, "avg_logprob": -0.3464853056184538, "compression_ratio": 1.4251207729468598, "no_speech_prob": 0.0003713517216965556}, {"id": 259, "seek": 102616, "start": 1045.28, "end": 1047.0400000000002, "text": " hard to break.", "tokens": [1152, 281, 1821, 13], "temperature": 0.0, "avg_logprob": -0.3464853056184538, "compression_ratio": 1.4251207729468598, "no_speech_prob": 0.0003713517216965556}, {"id": 260, "seek": 102616, "start": 1047.0400000000002, "end": 1050.68, "text": " I think if I was going to start again, I'd probably try FISH a bit more.", "tokens": [286, 519, 498, 286, 390, 516, 281, 722, 797, 11, 286, 1116, 1391, 853, 479, 18842, 257, 857, 544, 13], "temperature": 0.0, "avg_logprob": -0.3464853056184538, "compression_ratio": 1.4251207729468598, "no_speech_prob": 0.0003713517216965556}, {"id": 261, "seek": 105068, "start": 1050.68, "end": 1056.3200000000002, "text": " And a question about the timestamps, are you using the client-side timestamps from the", "tokens": [400, 257, 1168, 466, 264, 49108, 23150, 11, 366, 291, 1228, 264, 6423, 12, 1812, 49108, 23150, 490, 264], "temperature": 0.0, "avg_logprob": -0.2371398984020903, "compression_ratio": 1.9323308270676691, "no_speech_prob": 0.0004655507218558341}, {"id": 262, "seek": 105068, "start": 1056.3200000000002, "end": 1057.3200000000002, "text": " machines or server-side?", "tokens": [8379, 420, 7154, 12, 1812, 30], "temperature": 0.0, "avg_logprob": -0.2371398984020903, "compression_ratio": 1.9323308270676691, "no_speech_prob": 0.0004655507218558341}, {"id": 263, "seek": 105068, "start": 1057.3200000000002, "end": 1062.3200000000002, "text": " So we actually store client-side, the timestamp will be whatever your client is, but we actually", "tokens": [407, 321, 767, 3531, 6423, 12, 1812, 11, 264, 49108, 1215, 486, 312, 2035, 428, 6423, 307, 11, 457, 321, 767], "temperature": 0.0, "avg_logprob": -0.2371398984020903, "compression_ratio": 1.9323308270676691, "no_speech_prob": 0.0004655507218558341}, {"id": 264, "seek": 105068, "start": 1062.3200000000002, "end": 1064.72, "text": " use two timestamps to sync to work.", "tokens": [764, 732, 49108, 23150, 281, 20271, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.2371398984020903, "compression_ratio": 1.9323308270676691, "no_speech_prob": 0.0004655507218558341}, {"id": 265, "seek": 105068, "start": 1064.72, "end": 1068.3200000000002, "text": " So we have the server-local timestamp, which is only really used for syncing, and then", "tokens": [407, 321, 362, 264, 7154, 12, 5842, 304, 49108, 1215, 11, 597, 307, 787, 534, 1143, 337, 5451, 2175, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.2371398984020903, "compression_ratio": 1.9323308270676691, "no_speech_prob": 0.0004655507218558341}, {"id": 266, "seek": 105068, "start": 1068.3200000000002, "end": 1072.72, "text": " the actual data, it's all encrypted and hidden, so it's whatever your client stores.", "tokens": [264, 3539, 1412, 11, 309, 311, 439, 36663, 293, 7633, 11, 370, 309, 311, 2035, 428, 6423, 9512, 13], "temperature": 0.0, "avg_logprob": -0.2371398984020903, "compression_ratio": 1.9323308270676691, "no_speech_prob": 0.0004655507218558341}, {"id": 267, "seek": 105068, "start": 1072.72, "end": 1078.0, "text": " Because sometimes the local timestamp is important if you want to sync with a system or whatever,", "tokens": [1436, 2171, 264, 2654, 49108, 1215, 307, 1021, 498, 291, 528, 281, 20271, 365, 257, 1185, 420, 2035, 11], "temperature": 0.0, "avg_logprob": -0.2371398984020903, "compression_ratio": 1.9323308270676691, "no_speech_prob": 0.0004655507218558341}, {"id": 268, "seek": 107800, "start": 1078.0, "end": 1083.68, "text": " but sometimes also the real time, if the computers are out of sync, which that should happen.", "tokens": [457, 2171, 611, 264, 957, 565, 11, 498, 264, 10807, 366, 484, 295, 20271, 11, 597, 300, 820, 1051, 13], "temperature": 0.0, "avg_logprob": -0.2749727231646896, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.0001870457490440458}, {"id": 269, "seek": 107800, "start": 1083.68, "end": 1086.8, "text": " I had a bunch of issues with timestamps when I was first writing it, but we got it all", "tokens": [286, 632, 257, 3840, 295, 2663, 365, 49108, 23150, 562, 286, 390, 700, 3579, 309, 11, 457, 321, 658, 309, 439], "temperature": 0.0, "avg_logprob": -0.2749727231646896, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.0001870457490440458}, {"id": 270, "seek": 107800, "start": 1086.8, "end": 1091.76, "text": " sorted out in the end.", "tokens": [25462, 484, 294, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.2749727231646896, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.0001870457490440458}, {"id": 271, "seek": 107800, "start": 1091.76, "end": 1096.2, "text": " Is there a limit to the length of a command, for example, imagine a huge pipeline with", "tokens": [1119, 456, 257, 4948, 281, 264, 4641, 295, 257, 5622, 11, 337, 1365, 11, 3811, 257, 2603, 15517, 365], "temperature": 0.0, "avg_logprob": -0.2749727231646896, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.0001870457490440458}, {"id": 272, "seek": 107800, "start": 1096.2, "end": 1099.8, "text": " the SQLs and JQL queries in there?", "tokens": [264, 19200, 82, 293, 508, 13695, 24109, 294, 456, 30], "temperature": 0.0, "avg_logprob": -0.2749727231646896, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.0001870457490440458}, {"id": 273, "seek": 107800, "start": 1099.8, "end": 1105.16, "text": " Currently it's eight megabytes of whatever it is once it's been encrypted, it's only", "tokens": [19964, 309, 311, 3180, 10816, 24538, 295, 2035, 309, 307, 1564, 309, 311, 668, 36663, 11, 309, 311, 787], "temperature": 0.0, "avg_logprob": -0.2749727231646896, "compression_ratio": 1.583011583011583, "no_speech_prob": 0.0001870457490440458}, {"id": 274, "seek": 110516, "start": 1105.16, "end": 1108.16, "text": " a server-side limit, and it's pretty arbitrary.", "tokens": [257, 7154, 12, 1812, 4948, 11, 293, 309, 311, 1238, 23211, 13], "temperature": 0.0, "avg_logprob": -0.2766933838526408, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.0003000676806550473}, {"id": 275, "seek": 110516, "start": 1108.16, "end": 1113.6000000000001, "text": " So another question, any plans for special handling for similar commands?", "tokens": [407, 1071, 1168, 11, 604, 5482, 337, 2121, 13175, 337, 2531, 16901, 30], "temperature": 0.0, "avg_logprob": -0.2766933838526408, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.0003000676806550473}, {"id": 276, "seek": 110516, "start": 1113.6000000000001, "end": 1120.0, "text": " We do fix syntax, run similar commands in a row?", "tokens": [492, 360, 3191, 28431, 11, 1190, 2531, 16901, 294, 257, 5386, 30], "temperature": 0.0, "avg_logprob": -0.2766933838526408, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.0003000676806550473}, {"id": 277, "seek": 110516, "start": 1120.0, "end": 1123.44, "text": " I hadn't really thought of that before, but it might be worth considering.", "tokens": [286, 8782, 380, 534, 1194, 295, 300, 949, 11, 457, 309, 1062, 312, 3163, 8079, 13], "temperature": 0.0, "avg_logprob": -0.2766933838526408, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.0003000676806550473}, {"id": 278, "seek": 110516, "start": 1123.44, "end": 1129.48, "text": " Sorry, I did have a few more questions from Matrix.", "tokens": [4919, 11, 286, 630, 362, 257, 1326, 544, 1651, 490, 36274, 13], "temperature": 0.0, "avg_logprob": -0.2766933838526408, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.0003000676806550473}, {"id": 279, "seek": 110516, "start": 1129.48, "end": 1133.96, "text": " I think my device is not synchronizing properly, but Andy sent me a screenshot.", "tokens": [286, 519, 452, 4302, 307, 406, 19331, 3319, 6108, 11, 457, 13285, 2279, 385, 257, 27712, 13], "temperature": 0.0, "avg_logprob": -0.2766933838526408, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.0003000676806550473}, {"id": 280, "seek": 113396, "start": 1133.96, "end": 1138.56, "text": " So does it integrate with regular history mechanisms provided by the shell?", "tokens": [407, 775, 309, 13365, 365, 3890, 2503, 15902, 5649, 538, 264, 8720, 30], "temperature": 0.0, "avg_logprob": -0.19340375264485676, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.0003548602689988911}, {"id": 281, "seek": 113396, "start": 1138.56, "end": 1145.04, "text": " For example, excluding certain commands automatically like CDNLS, skipping storing in history by", "tokens": [1171, 1365, 11, 49999, 1629, 16901, 6772, 411, 6743, 45, 19198, 11, 31533, 26085, 294, 2503, 538], "temperature": 0.0, "avg_logprob": -0.19340375264485676, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.0003548602689988911}, {"id": 282, "seek": 113396, "start": 1145.04, "end": 1148.76, "text": " prefixing with white space for sensitive commands, et cetera.", "tokens": [18417, 970, 278, 365, 2418, 1901, 337, 9477, 16901, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.19340375264485676, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.0003548602689988911}, {"id": 283, "seek": 113396, "start": 1148.76, "end": 1154.88, "text": " So the prefixing with white space is included, the default ignoring is not, but it doesn't", "tokens": [407, 264, 18417, 970, 278, 365, 2418, 1901, 307, 5556, 11, 264, 7576, 26258, 307, 406, 11, 457, 309, 1177, 380], "temperature": 0.0, "avg_logprob": -0.19340375264485676, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.0003548602689988911}, {"id": 284, "seek": 113396, "start": 1154.88, "end": 1157.92, "text": " actually replace the text file history either.", "tokens": [767, 7406, 264, 2487, 3991, 2503, 2139, 13], "temperature": 0.0, "avg_logprob": -0.19340375264485676, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.0003548602689988911}, {"id": 285, "seek": 113396, "start": 1157.92, "end": 1161.72, "text": " You will still write to that if you ever decide, do you want to stop using it?", "tokens": [509, 486, 920, 2464, 281, 300, 498, 291, 1562, 4536, 11, 360, 291, 528, 281, 1590, 1228, 309, 30], "temperature": 0.0, "avg_logprob": -0.19340375264485676, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.0003548602689988911}, {"id": 286, "seek": 116172, "start": 1161.72, "end": 1165.92, "text": " And where would context to where recommendations come from?", "tokens": [400, 689, 576, 4319, 281, 689, 10434, 808, 490, 30], "temperature": 0.0, "avg_logprob": -0.20929426819313574, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.000408822757890448}, {"id": 287, "seek": 116172, "start": 1165.92, "end": 1170.68, "text": " So if we have a history of your shell, we know the directories you're in, we know what", "tokens": [407, 498, 321, 362, 257, 2503, 295, 428, 8720, 11, 321, 458, 264, 5391, 530, 291, 434, 294, 11, 321, 458, 437], "temperature": 0.0, "avg_logprob": -0.20929426819313574, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.000408822757890448}, {"id": 288, "seek": 116172, "start": 1170.68, "end": 1174.4, "text": " commands you've been running at what times, so if we're predicting the next command that", "tokens": [16901, 291, 600, 668, 2614, 412, 437, 1413, 11, 370, 498, 321, 434, 32884, 264, 958, 5622, 300], "temperature": 0.0, "avg_logprob": -0.20929426819313574, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.000408822757890448}, {"id": 289, "seek": 116172, "start": 1174.4, "end": 1176.68, "text": " you want to run, we can use your own history.", "tokens": [291, 528, 281, 1190, 11, 321, 393, 764, 428, 1065, 2503, 13], "temperature": 0.0, "avg_logprob": -0.20929426819313574, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.000408822757890448}, {"id": 290, "seek": 116172, "start": 1176.68, "end": 1180.0, "text": " So, but the question follows up with, it's end-to-end encrypted?", "tokens": [407, 11, 457, 264, 1168, 10002, 493, 365, 11, 309, 311, 917, 12, 1353, 12, 521, 36663, 30], "temperature": 0.0, "avg_logprob": -0.20929426819313574, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.000408822757890448}, {"id": 291, "seek": 116172, "start": 1180.0, "end": 1182.08, "text": " Oh, it would all be from the client.", "tokens": [876, 11, 309, 576, 439, 312, 490, 264, 6423, 13], "temperature": 0.0, "avg_logprob": -0.20929426819313574, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.000408822757890448}, {"id": 292, "seek": 116172, "start": 1182.08, "end": 1185.64, "text": " So there's nothing, the server's just a dumb blob store, it doesn't really know much of", "tokens": [407, 456, 311, 1825, 11, 264, 7154, 311, 445, 257, 10316, 46115, 3531, 11, 309, 1177, 380, 534, 458, 709, 295], "temperature": 0.0, "avg_logprob": -0.20929426819313574, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.000408822757890448}, {"id": 293, "seek": 116172, "start": 1185.64, "end": 1186.64, "text": " anything.", "tokens": [1340, 13], "temperature": 0.0, "avg_logprob": -0.20929426819313574, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.000408822757890448}, {"id": 294, "seek": 118664, "start": 1186.64, "end": 1193.64, "text": " Any more questions?", "tokens": [2639, 544, 1651, 30], "temperature": 0.2, "avg_logprob": -0.5283731645153414, "compression_ratio": 0.9876543209876543, "no_speech_prob": 0.0012015770189464092}, {"id": 295, "seek": 118664, "start": 1193.64, "end": 1196.64, "text": " I think that's it.", "tokens": [286, 519, 300, 311, 309, 13], "temperature": 0.2, "avg_logprob": -0.5283731645153414, "compression_ratio": 0.9876543209876543, "no_speech_prob": 0.0012015770189464092}, {"id": 296, "seek": 118664, "start": 1196.64, "end": 1197.64, "text": " Awesome.", "tokens": [10391, 13], "temperature": 0.2, "avg_logprob": -0.5283731645153414, "compression_ratio": 0.9876543209876543, "no_speech_prob": 0.0012015770189464092}, {"id": 297, "seek": 118664, "start": 1197.64, "end": 1198.64, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.2, "avg_logprob": -0.5283731645153414, "compression_ratio": 0.9876543209876543, "no_speech_prob": 0.0012015770189464092}, {"id": 298, "seek": 119864, "start": 1198.64, "end": 1218.64, "text": " That was really well.", "tokens": [663, 390, 534, 731, 13], "temperature": 0.0, "avg_logprob": -0.5989502271016439, "compression_ratio": 0.7241379310344828, "no_speech_prob": 0.003661207389086485}], "language": "en"}