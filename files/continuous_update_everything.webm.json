{"text": " Yeah, I think I will start, otherwise I would know I want to have, I mean, I like to talk a lot, so I won't have enough time anyway. So thanks for coming to my presentation, and today I'm going to talk about the challenges of updating everything. So my name is working. I'm also one of the CI-CD Dev Room maintainer. I'm working for Sousa on all things related to Kubernetes, Rensho. So if there are anything you want to talk about, feel free to reach out after my presentation. But today I'm not here to talk about what I'm doing at work. And here to present a project that I started before joining Sousa, back then when I used to work on Jenkins projects, and that project is named Update CLI. So Update CLI is a common line tool that we use to automate things. So the design is to run it on your machine, on the CI environment, whatever it is. And so you specify in your manifest what's the update strategy would look like. So initially I wanted to talk about, first, Update CLI, and then all the challenges that you have when you want to automate Docker images, when you want to automate infrastructure or whatever. But I won't have the time to do that here. So for those people in Ghent, for the configuration management camp, I will have more time over there. I will just focus on what Update CLI is, what the problem is, and what I'm trying to do. So the challenge that I face is, quite often when I maintain large amounts of projects, something that used to work, to not work anymore. Like you are using Ugo, for example, to generate a website. And then at some point, you cannot deploy the website anymore because even though projects release a new Ugo version, they fail to build the published Docker image associated to that. Or you would realize yesterday I was investigating an issue where Update CLI would deploy and would roll back a version of the NGNX Ingress Controller, and then it ended up that the people maintaining that container just released, deleted the release, forgot to remove the GTIG in those situations. So you would expect something to work. You won't automate. And the thing is, when you get in those situations, you try to understand why it didn't work. I mean, it used to work for years, and then suddenly it doesn't work anymore. And then so you spend time trying to understand what's the latest version, what's the changelog, what's something failed, basically. And so when you want to automate those updates, so you don't have to pay attention to them, I mean, it obviously has benefits, right? I'm curious. Who's using, for example, Tip and Abut or Renovate about to automate things, updates? Yes, a few people. It's only the start. But once you start automating things, you know that, obviously, it gets easier to change your project infrastructure documentation, no matter what, because you get confident in the change that you want to do. And in my case, most of my projects are hosted on Git repositories. And one of the challenges when you have, when you think about those Git repositories is everything is a file. And what you try to do is you try to automate them, but most of the time you have no idea what you're trying to update, right? So for example, Dependabut will just look at a package of GZN. So if you find a package of GZN, we'll list all dependencies and try to update them one by one. But on the other side, for those people using, for example, random GZN file, there is no way to know in advance what should be updated in those files. And then you have all those middle grounds, like, for example, for those people familiar with Dockerfile, you have some instruction that you can automatically update, like the from instruction. It's pretty straightforward to know what you need to update. You don't know what you want to update. That's a different story. But the thing is you know that you want to automate the base image. On the other side, you can put pretty much every information in the run instruction, the label, the end instruction, and that's where things get difficult. So when we started working on a data line, we wanted to think, OK, we want to automate everything. So we want to define where the information is coming from, what are the conditions to automate the thing, and finally, what should be the state of your file on your Git repository. So if I go back to my ego example, the idea is the source of information is the latest ego release. That could be the Git tag, that could be the latest Docker image published, that could be the GitHub release, for example. But at some point, we have to decide what's the source of truth for that specific application. And then you have, like, a bunch of conditions that you want to apply, like, does it make sense to bump the version in production if you fail to bump the version in the dev environment? So you want to be sure that you are using the same version everywhere. And only then, you will bump all the files related to that version. And so when we come back about Update CLI, the idea is we specify a manifest, we have to write a manifest. So that's the main difference, for example, for Dependable. Because Dependable, you just enable the button, it works. But it will only detect what it can detect. But most of the time, you have no idea what you should update. With Update CLI, we went the other way. We write a manifest, so for example, this one is you have the source, the source of truth. In this case, it's a GitHub release. So it can GitHub release. And then you have the specification, where you provide all the parameters for that specific project. So in this case, I am monitoring the go-go-io git repository. This one gives me a version, let's say 100. That's the latest one. And what I want to do is I want to be sure that all my files, named natify.tom.yml, are up to date. So I look at the key. And then if I run this manifest on my machine, it will just dump the file on my machine. If I run this manifest on the CI environment, it will bump the file in the CI environment. And so the next step is, okay, that's one thing to have it working on a machine. But then you also want to be sure that your git repository is up to date and don't pay attention to them. So you can just focus on what really makes sense in your case. And so the next step is, okay, we want to specify where that file is located. So we have a bunch of other resources. In this case, it's a SCM of type git, because I want to update git repositories. And then I specify that I want the pull request approach, where I create a temporary branch and then someone can review my change. And then when you think about all those building blocks, you can really have, like, more advanced scenarios, like this one is another project that we use, where we use it, is when someone really is in a new version of Apno, we use GitHub Action there. That send a bunch of release events automatically to other git repositories. And those git repositories will trigger Update CLI. So Update CLI will retrieve all the different information. So for example, on Apno slash docs, which is obviously the website, we retrieve the latest version of Apno, and then we check that all the download links are up to date. We check that we have the version for that specific website. So we maintain one documentation per major and minor version. So we try to be sure that those files are up to date. And if it's not the case, we open a PR. And then as part of the release process of Apno, someone needs to review the PR and double check that it still contains a file that you want to have there. Another example is the way we automate Hemshot. We define, okay, we are monitoring the Apno UI, which is a front application, and we monitor the backend, the Apno. And then if for some reason there is a new version, then it will automatically bump the Hemshot, bump the metadata, and so on. And once again, we have a human validation where someone can just come, look at the PR, and decide if we want to go one step further. So really briefly here is when automated update is not a so easy challenge, as I initially thought, because so we split the project in three different categories. So the first one is declarative. So the idea is you know in advance what should be updated, and so you define in a manifest how you want to update something, because it's not something that you can define in advance. The other discovery is a bit more like for those people familiar with Dependentbot or Renovatebot, you just run the command and you ask it to automatically detect what could be updated. There are scenarios where you can find that information. For example, on a Maven project, you have the pump.xml, you fetch all the dependencies and update them. That's pretty easy. On other projects like Docker containers, it's kind of a mess over there, so it's super difficult to know what should be the next version. And then on the other side, you have all those situations where you specify a constraint, a version constraint, like you don't want to use a version bigger than the 1.0, but at some point the project upstream is like way further than you are in your project. At some point, you need to be aware that you will need to plan some work to catch up on the upstream project. And so that's another experiment, which is update monitor. So I want to do a quick demo. I don't have good internet connectivity here, so I hope it will work. So on the left side is one of the manifest, is it big enough? Oops. So on the left side, we specify a few things like, okay, in this case, we want to enable the auto merge feature of GitHub, actually, of GitHub PolarQuest. We specify labels. So we automatically open a PR, and if all the tests are passing, it will merge the PR automatically. And so I don't have to pay attention, which reduce, obviously, the noise introduced by those PR. We need to specify which projects we want to go. So in this case, that's the updated website. And finally, we specify where the information is coming from. So this one, we monitor, go, go, go, go. As I said, we could have instead of monitoring the GitHub release, at some point I could have said, okay. I just want to monitor the Docker images. But in that case, I just need to provide a different piece of information. Or you could say, for example, I want to monitor here, writing from the IDD is the easiest way. You can specify different ways of filtering version, because what's something that we notice, for example, is when I said the Docker ecosystem is a mess, is you can put whatever information you want in a tag. So there is pretty much no way, I mean, most of the time, there is no way to know what should be the next version. Then depending on the registries, they don't return you the latest version, because they don't sort the tags in the same way. So at some point, yeah, you need to enforce a specific behavior. And then the target in this case is, if there is a new version of Hugo, we want to be sure that the workflow file has the correct version and that the native file is up to date. So I don't care. And so what it looks like on the other side is just a CLI, as I said. So you can read it from my machine, Linux, Mac, wherever you want to run it. And then, voila, you get the latest version, change log, depending on the situation. And based on that, you can just combine the projects. And so we have a lot of different workflows where we automate things. The last thing, how many time do I have left? Five minutes? Okay. Where is that? It's not this one. So the thing that I was mentioning for monitoring the different versions, so this one is a different way to see the problem is you want to monitor the version that you are using at some point. And so you want to compare, okay, in this case, on one location, I say I want to monitor a version from the native file.tamiaml, so it gets me a version which is 0.1010. And on the other side, I want to compare with what's the latest code version. And so if it does not match, then I know that I need to work on that at some point. And since I have a bit of a time, I can quickly show what the discovery looks like. Yeah, the auto-discovery is a bit more difficult because you need to know in advance what you want to do, but where is that thing? Yeah, this way. As you can see, we don't have a lot of support at this time, so it's mainly around containers because I'm working on containers most of the time. But so it will pass the file, so in this case, it identifies. It's a Rancher project where we have fleets, and then based on that, it will try to fetch all the different versions specified in the fleet project, and it will suggest other versions. So that's it for my presentation. And... Voila. Is there any questions? One time, two times, yes. There is one over there. Hi there. Thanks for the presentation. You were talking about what the Panda was, but you didn't mention about renovate. I wonder how much it overlaps with renovate, if it's a bit more customizable one. So the question, I mentioned the Panda, but I didn't mention that much renovate. So if you compare the Panda, but the renovate is way better than the Panda, but because the Panda, but I didn't have the time to cover the domain. There are a lot of things that I didn't have the time to cover, but for example, one of the features that I really love in renovate, but is they allows you to group PRs which reduce the noise. Because for example, the Panda bot, especially for those people maintaining JavaScript projects, the Panda bot can just open like 10, 20, 30 PRs, and then you have to review all of them tests. And so there are different strategies to update. Renovate bot is just way better in the way that it supports more modules. On the other side, it's not really easy in the case of renovate, but to have workflows where you really want to say, okay, I'll fetch a version, I'll check a bunch of things, and then I'll update other targets, basically. So I would say renovate bot is better in the autodiscovery part, where you can detect things for you. But on the other side, it's not really easy to have like very complex updates in areas. And that's it. So Charles, the floor, thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 18.04, "text": " Yeah, I think I will start, otherwise I would know I want to have, I mean, I like to talk", "tokens": [865, 11, 286, 519, 286, 486, 722, 11, 5911, 286, 576, 458, 286, 528, 281, 362, 11, 286, 914, 11, 286, 411, 281, 751], "temperature": 0.0, "avg_logprob": -0.33166257958663137, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.2245766520500183}, {"id": 1, "seek": 0, "start": 18.04, "end": 21.080000000000002, "text": " a lot, so I won't have enough time anyway.", "tokens": [257, 688, 11, 370, 286, 1582, 380, 362, 1547, 565, 4033, 13], "temperature": 0.0, "avg_logprob": -0.33166257958663137, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.2245766520500183}, {"id": 2, "seek": 0, "start": 21.080000000000002, "end": 25.560000000000002, "text": " So thanks for coming to my presentation, and today I'm going to talk about the challenges", "tokens": [407, 3231, 337, 1348, 281, 452, 5860, 11, 293, 965, 286, 478, 516, 281, 751, 466, 264, 4759], "temperature": 0.0, "avg_logprob": -0.33166257958663137, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.2245766520500183}, {"id": 3, "seek": 0, "start": 25.560000000000002, "end": 28.04, "text": " of updating everything.", "tokens": [295, 25113, 1203, 13], "temperature": 0.0, "avg_logprob": -0.33166257958663137, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.2245766520500183}, {"id": 4, "seek": 0, "start": 28.04, "end": 29.04, "text": " So my name is working.", "tokens": [407, 452, 1315, 307, 1364, 13], "temperature": 0.0, "avg_logprob": -0.33166257958663137, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.2245766520500183}, {"id": 5, "seek": 2904, "start": 29.04, "end": 31.919999999999998, "text": " I'm also one of the CI-CD Dev Room maintainer.", "tokens": [286, 478, 611, 472, 295, 264, 37777, 12, 16508, 9096, 19190, 6909, 260, 13], "temperature": 0.0, "avg_logprob": -0.22365897849754052, "compression_ratio": 1.7, "no_speech_prob": 0.00010151066817343235}, {"id": 6, "seek": 2904, "start": 31.919999999999998, "end": 36.64, "text": " I'm working for Sousa on all things related to Kubernetes, Rensho.", "tokens": [286, 478, 1364, 337, 318, 563, 64, 322, 439, 721, 4077, 281, 23145, 11, 497, 694, 1289, 13], "temperature": 0.0, "avg_logprob": -0.22365897849754052, "compression_ratio": 1.7, "no_speech_prob": 0.00010151066817343235}, {"id": 7, "seek": 2904, "start": 36.64, "end": 40.76, "text": " So if there are anything you want to talk about, feel free to reach out after my presentation.", "tokens": [407, 498, 456, 366, 1340, 291, 528, 281, 751, 466, 11, 841, 1737, 281, 2524, 484, 934, 452, 5860, 13], "temperature": 0.0, "avg_logprob": -0.22365897849754052, "compression_ratio": 1.7, "no_speech_prob": 0.00010151066817343235}, {"id": 8, "seek": 2904, "start": 40.76, "end": 44.44, "text": " But today I'm not here to talk about what I'm doing at work.", "tokens": [583, 965, 286, 478, 406, 510, 281, 751, 466, 437, 286, 478, 884, 412, 589, 13], "temperature": 0.0, "avg_logprob": -0.22365897849754052, "compression_ratio": 1.7, "no_speech_prob": 0.00010151066817343235}, {"id": 9, "seek": 2904, "start": 44.44, "end": 48.519999999999996, "text": " And here to present a project that I started before joining Sousa, back then when I used", "tokens": [400, 510, 281, 1974, 257, 1716, 300, 286, 1409, 949, 5549, 318, 563, 64, 11, 646, 550, 562, 286, 1143], "temperature": 0.0, "avg_logprob": -0.22365897849754052, "compression_ratio": 1.7, "no_speech_prob": 0.00010151066817343235}, {"id": 10, "seek": 2904, "start": 48.519999999999996, "end": 52.16, "text": " to work on Jenkins projects, and that project is named Update CLI.", "tokens": [281, 589, 322, 41273, 4455, 11, 293, 300, 1716, 307, 4926, 28923, 12855, 40, 13], "temperature": 0.0, "avg_logprob": -0.22365897849754052, "compression_ratio": 1.7, "no_speech_prob": 0.00010151066817343235}, {"id": 11, "seek": 2904, "start": 52.16, "end": 57.28, "text": " So Update CLI is a common line tool that we use to automate things.", "tokens": [407, 28923, 12855, 40, 307, 257, 2689, 1622, 2290, 300, 321, 764, 281, 31605, 721, 13], "temperature": 0.0, "avg_logprob": -0.22365897849754052, "compression_ratio": 1.7, "no_speech_prob": 0.00010151066817343235}, {"id": 12, "seek": 5728, "start": 57.28, "end": 62.04, "text": " So the design is to run it on your machine, on the CI environment, whatever it is.", "tokens": [407, 264, 1715, 307, 281, 1190, 309, 322, 428, 3479, 11, 322, 264, 37777, 2823, 11, 2035, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.14919770608736774, "compression_ratio": 1.7216494845360826, "no_speech_prob": 2.6233092285110615e-05}, {"id": 13, "seek": 5728, "start": 62.04, "end": 67.98, "text": " And so you specify in your manifest what's the update strategy would look like.", "tokens": [400, 370, 291, 16500, 294, 428, 10067, 437, 311, 264, 5623, 5206, 576, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.14919770608736774, "compression_ratio": 1.7216494845360826, "no_speech_prob": 2.6233092285110615e-05}, {"id": 14, "seek": 5728, "start": 67.98, "end": 72.2, "text": " So initially I wanted to talk about, first, Update CLI, and then all the challenges that", "tokens": [407, 9105, 286, 1415, 281, 751, 466, 11, 700, 11, 28923, 12855, 40, 11, 293, 550, 439, 264, 4759, 300], "temperature": 0.0, "avg_logprob": -0.14919770608736774, "compression_ratio": 1.7216494845360826, "no_speech_prob": 2.6233092285110615e-05}, {"id": 15, "seek": 5728, "start": 72.2, "end": 76.04, "text": " you have when you want to automate Docker images, when you want to automate infrastructure", "tokens": [291, 362, 562, 291, 528, 281, 31605, 33772, 5267, 11, 562, 291, 528, 281, 31605, 6896], "temperature": 0.0, "avg_logprob": -0.14919770608736774, "compression_ratio": 1.7216494845360826, "no_speech_prob": 2.6233092285110615e-05}, {"id": 16, "seek": 5728, "start": 76.04, "end": 77.04, "text": " or whatever.", "tokens": [420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.14919770608736774, "compression_ratio": 1.7216494845360826, "no_speech_prob": 2.6233092285110615e-05}, {"id": 17, "seek": 5728, "start": 77.04, "end": 78.56, "text": " But I won't have the time to do that here.", "tokens": [583, 286, 1582, 380, 362, 264, 565, 281, 360, 300, 510, 13], "temperature": 0.0, "avg_logprob": -0.14919770608736774, "compression_ratio": 1.7216494845360826, "no_speech_prob": 2.6233092285110615e-05}, {"id": 18, "seek": 5728, "start": 78.56, "end": 83.0, "text": " So for those people in Ghent, for the configuration management camp, I will have more time over", "tokens": [407, 337, 729, 561, 294, 20321, 317, 11, 337, 264, 11694, 4592, 2255, 11, 286, 486, 362, 544, 565, 670], "temperature": 0.0, "avg_logprob": -0.14919770608736774, "compression_ratio": 1.7216494845360826, "no_speech_prob": 2.6233092285110615e-05}, {"id": 19, "seek": 5728, "start": 83.0, "end": 84.0, "text": " there.", "tokens": [456, 13], "temperature": 0.0, "avg_logprob": -0.14919770608736774, "compression_ratio": 1.7216494845360826, "no_speech_prob": 2.6233092285110615e-05}, {"id": 20, "seek": 8400, "start": 84.0, "end": 90.28, "text": " I will just focus on what Update CLI is, what the problem is, and what I'm trying to do.", "tokens": [286, 486, 445, 1879, 322, 437, 28923, 12855, 40, 307, 11, 437, 264, 1154, 307, 11, 293, 437, 286, 478, 1382, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.24887223529000568, "compression_ratio": 1.6319444444444444, "no_speech_prob": 3.0707258702022955e-05}, {"id": 21, "seek": 8400, "start": 90.28, "end": 95.2, "text": " So the challenge that I face is, quite often when I maintain large amounts of projects,", "tokens": [407, 264, 3430, 300, 286, 1851, 307, 11, 1596, 2049, 562, 286, 6909, 2416, 11663, 295, 4455, 11], "temperature": 0.0, "avg_logprob": -0.24887223529000568, "compression_ratio": 1.6319444444444444, "no_speech_prob": 3.0707258702022955e-05}, {"id": 22, "seek": 8400, "start": 95.2, "end": 97.32, "text": " something that used to work, to not work anymore.", "tokens": [746, 300, 1143, 281, 589, 11, 281, 406, 589, 3602, 13], "temperature": 0.0, "avg_logprob": -0.24887223529000568, "compression_ratio": 1.6319444444444444, "no_speech_prob": 3.0707258702022955e-05}, {"id": 23, "seek": 8400, "start": 97.32, "end": 101.88, "text": " Like you are using Ugo, for example, to generate a website.", "tokens": [1743, 291, 366, 1228, 624, 1571, 11, 337, 1365, 11, 281, 8460, 257, 3144, 13], "temperature": 0.0, "avg_logprob": -0.24887223529000568, "compression_ratio": 1.6319444444444444, "no_speech_prob": 3.0707258702022955e-05}, {"id": 24, "seek": 8400, "start": 101.88, "end": 106.2, "text": " And then at some point, you cannot deploy the website anymore because even though projects", "tokens": [400, 550, 412, 512, 935, 11, 291, 2644, 7274, 264, 3144, 3602, 570, 754, 1673, 4455], "temperature": 0.0, "avg_logprob": -0.24887223529000568, "compression_ratio": 1.6319444444444444, "no_speech_prob": 3.0707258702022955e-05}, {"id": 25, "seek": 8400, "start": 106.2, "end": 112.4, "text": " release a new Ugo version, they fail to build the published Docker image associated to that.", "tokens": [4374, 257, 777, 624, 1571, 3037, 11, 436, 3061, 281, 1322, 264, 6572, 33772, 3256, 6615, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.24887223529000568, "compression_ratio": 1.6319444444444444, "no_speech_prob": 3.0707258702022955e-05}, {"id": 26, "seek": 11240, "start": 112.4, "end": 117.16000000000001, "text": " Or you would realize yesterday I was investigating an issue where Update CLI would deploy and", "tokens": [1610, 291, 576, 4325, 5186, 286, 390, 22858, 364, 2734, 689, 28923, 12855, 40, 576, 7274, 293], "temperature": 0.0, "avg_logprob": -0.2503270887790766, "compression_ratio": 1.7175324675324675, "no_speech_prob": 2.5851648388197646e-05}, {"id": 27, "seek": 11240, "start": 117.16000000000001, "end": 122.52000000000001, "text": " would roll back a version of the NGNX Ingress Controller, and then it ended up that the people", "tokens": [576, 3373, 646, 257, 3037, 295, 264, 426, 38, 45, 55, 682, 3091, 44969, 11, 293, 550, 309, 4590, 493, 300, 264, 561], "temperature": 0.0, "avg_logprob": -0.2503270887790766, "compression_ratio": 1.7175324675324675, "no_speech_prob": 2.5851648388197646e-05}, {"id": 28, "seek": 11240, "start": 122.52000000000001, "end": 127.78, "text": " maintaining that container just released, deleted the release, forgot to remove the", "tokens": [14916, 300, 10129, 445, 4736, 11, 22981, 264, 4374, 11, 5298, 281, 4159, 264], "temperature": 0.0, "avg_logprob": -0.2503270887790766, "compression_ratio": 1.7175324675324675, "no_speech_prob": 2.5851648388197646e-05}, {"id": 29, "seek": 11240, "start": 127.78, "end": 129.28, "text": " GTIG in those situations.", "tokens": [460, 5422, 38, 294, 729, 6851, 13], "temperature": 0.0, "avg_logprob": -0.2503270887790766, "compression_ratio": 1.7175324675324675, "no_speech_prob": 2.5851648388197646e-05}, {"id": 30, "seek": 11240, "start": 129.28, "end": 131.08, "text": " So you would expect something to work.", "tokens": [407, 291, 576, 2066, 746, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.2503270887790766, "compression_ratio": 1.7175324675324675, "no_speech_prob": 2.5851648388197646e-05}, {"id": 31, "seek": 11240, "start": 131.08, "end": 132.08, "text": " You won't automate.", "tokens": [509, 1582, 380, 31605, 13], "temperature": 0.0, "avg_logprob": -0.2503270887790766, "compression_ratio": 1.7175324675324675, "no_speech_prob": 2.5851648388197646e-05}, {"id": 32, "seek": 11240, "start": 132.08, "end": 137.12, "text": " And the thing is, when you get in those situations, you try to understand why it didn't work.", "tokens": [400, 264, 551, 307, 11, 562, 291, 483, 294, 729, 6851, 11, 291, 853, 281, 1223, 983, 309, 994, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.2503270887790766, "compression_ratio": 1.7175324675324675, "no_speech_prob": 2.5851648388197646e-05}, {"id": 33, "seek": 11240, "start": 137.12, "end": 140.20000000000002, "text": " I mean, it used to work for years, and then suddenly it doesn't work anymore.", "tokens": [286, 914, 11, 309, 1143, 281, 589, 337, 924, 11, 293, 550, 5800, 309, 1177, 380, 589, 3602, 13], "temperature": 0.0, "avg_logprob": -0.2503270887790766, "compression_ratio": 1.7175324675324675, "no_speech_prob": 2.5851648388197646e-05}, {"id": 34, "seek": 14020, "start": 140.2, "end": 143.92, "text": " And then so you spend time trying to understand what's the latest version, what's the changelog,", "tokens": [400, 550, 370, 291, 3496, 565, 1382, 281, 1223, 437, 311, 264, 6792, 3037, 11, 437, 311, 264, 1534, 338, 664, 11], "temperature": 0.0, "avg_logprob": -0.3053910471227047, "compression_ratio": 1.697594501718213, "no_speech_prob": 1.5431660358444788e-05}, {"id": 35, "seek": 14020, "start": 143.92, "end": 146.76, "text": " what's something failed, basically.", "tokens": [437, 311, 746, 7612, 11, 1936, 13], "temperature": 0.0, "avg_logprob": -0.3053910471227047, "compression_ratio": 1.697594501718213, "no_speech_prob": 1.5431660358444788e-05}, {"id": 36, "seek": 14020, "start": 146.76, "end": 150.88, "text": " And so when you want to automate those updates, so you don't have to pay attention to them,", "tokens": [400, 370, 562, 291, 528, 281, 31605, 729, 9205, 11, 370, 291, 500, 380, 362, 281, 1689, 3202, 281, 552, 11], "temperature": 0.0, "avg_logprob": -0.3053910471227047, "compression_ratio": 1.697594501718213, "no_speech_prob": 1.5431660358444788e-05}, {"id": 37, "seek": 14020, "start": 150.88, "end": 153.32, "text": " I mean, it obviously has benefits, right?", "tokens": [286, 914, 11, 309, 2745, 575, 5311, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.3053910471227047, "compression_ratio": 1.697594501718213, "no_speech_prob": 1.5431660358444788e-05}, {"id": 38, "seek": 14020, "start": 153.32, "end": 154.32, "text": " I'm curious.", "tokens": [286, 478, 6369, 13], "temperature": 0.0, "avg_logprob": -0.3053910471227047, "compression_ratio": 1.697594501718213, "no_speech_prob": 1.5431660358444788e-05}, {"id": 39, "seek": 14020, "start": 154.32, "end": 158.72, "text": " Who's using, for example, Tip and Abut or Renovate about to automate things, updates?", "tokens": [2102, 311, 1228, 11, 337, 1365, 11, 18210, 293, 2847, 325, 420, 12883, 5179, 473, 466, 281, 31605, 721, 11, 9205, 30], "temperature": 0.0, "avg_logprob": -0.3053910471227047, "compression_ratio": 1.697594501718213, "no_speech_prob": 1.5431660358444788e-05}, {"id": 40, "seek": 14020, "start": 158.72, "end": 161.56, "text": " Yes, a few people.", "tokens": [1079, 11, 257, 1326, 561, 13], "temperature": 0.0, "avg_logprob": -0.3053910471227047, "compression_ratio": 1.697594501718213, "no_speech_prob": 1.5431660358444788e-05}, {"id": 41, "seek": 14020, "start": 161.56, "end": 163.0, "text": " It's only the start.", "tokens": [467, 311, 787, 264, 722, 13], "temperature": 0.0, "avg_logprob": -0.3053910471227047, "compression_ratio": 1.697594501718213, "no_speech_prob": 1.5431660358444788e-05}, {"id": 42, "seek": 14020, "start": 163.0, "end": 168.88, "text": " But once you start automating things, you know that, obviously, it gets easier to change", "tokens": [583, 1564, 291, 722, 3553, 990, 721, 11, 291, 458, 300, 11, 2745, 11, 309, 2170, 3571, 281, 1319], "temperature": 0.0, "avg_logprob": -0.3053910471227047, "compression_ratio": 1.697594501718213, "no_speech_prob": 1.5431660358444788e-05}, {"id": 43, "seek": 16888, "start": 168.88, "end": 174.72, "text": " your project infrastructure documentation, no matter what, because you get confident", "tokens": [428, 1716, 6896, 14333, 11, 572, 1871, 437, 11, 570, 291, 483, 6679], "temperature": 0.0, "avg_logprob": -0.2131541643955911, "compression_ratio": 1.7147887323943662, "no_speech_prob": 2.3150359993451275e-05}, {"id": 44, "seek": 16888, "start": 174.72, "end": 177.79999999999998, "text": " in the change that you want to do.", "tokens": [294, 264, 1319, 300, 291, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.2131541643955911, "compression_ratio": 1.7147887323943662, "no_speech_prob": 2.3150359993451275e-05}, {"id": 45, "seek": 16888, "start": 177.79999999999998, "end": 182.32, "text": " And in my case, most of my projects are hosted on Git repositories.", "tokens": [400, 294, 452, 1389, 11, 881, 295, 452, 4455, 366, 19204, 322, 16939, 22283, 2083, 13], "temperature": 0.0, "avg_logprob": -0.2131541643955911, "compression_ratio": 1.7147887323943662, "no_speech_prob": 2.3150359993451275e-05}, {"id": 46, "seek": 16888, "start": 182.32, "end": 185.68, "text": " And one of the challenges when you have, when you think about those Git repositories is everything", "tokens": [400, 472, 295, 264, 4759, 562, 291, 362, 11, 562, 291, 519, 466, 729, 16939, 22283, 2083, 307, 1203], "temperature": 0.0, "avg_logprob": -0.2131541643955911, "compression_ratio": 1.7147887323943662, "no_speech_prob": 2.3150359993451275e-05}, {"id": 47, "seek": 16888, "start": 185.68, "end": 186.96, "text": " is a file.", "tokens": [307, 257, 3991, 13], "temperature": 0.0, "avg_logprob": -0.2131541643955911, "compression_ratio": 1.7147887323943662, "no_speech_prob": 2.3150359993451275e-05}, {"id": 48, "seek": 16888, "start": 186.96, "end": 191.32, "text": " And what you try to do is you try to automate them, but most of the time you have no idea", "tokens": [400, 437, 291, 853, 281, 360, 307, 291, 853, 281, 31605, 552, 11, 457, 881, 295, 264, 565, 291, 362, 572, 1558], "temperature": 0.0, "avg_logprob": -0.2131541643955911, "compression_ratio": 1.7147887323943662, "no_speech_prob": 2.3150359993451275e-05}, {"id": 49, "seek": 16888, "start": 191.32, "end": 193.64, "text": " what you're trying to update, right?", "tokens": [437, 291, 434, 1382, 281, 5623, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2131541643955911, "compression_ratio": 1.7147887323943662, "no_speech_prob": 2.3150359993451275e-05}, {"id": 50, "seek": 16888, "start": 193.64, "end": 197.51999999999998, "text": " So for example, Dependabut will just look at a package of GZN.", "tokens": [407, 337, 1365, 11, 4056, 521, 455, 325, 486, 445, 574, 412, 257, 7372, 295, 460, 57, 45, 13], "temperature": 0.0, "avg_logprob": -0.2131541643955911, "compression_ratio": 1.7147887323943662, "no_speech_prob": 2.3150359993451275e-05}, {"id": 51, "seek": 19752, "start": 197.52, "end": 201.28, "text": " So if you find a package of GZN, we'll list all dependencies and try to update them one", "tokens": [407, 498, 291, 915, 257, 7372, 295, 460, 57, 45, 11, 321, 603, 1329, 439, 36606, 293, 853, 281, 5623, 552, 472], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 52, "seek": 19752, "start": 201.28, "end": 202.28, "text": " by one.", "tokens": [538, 472, 13], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 53, "seek": 19752, "start": 202.28, "end": 207.44, "text": " But on the other side, for those people using, for example, random GZN file, there is no", "tokens": [583, 322, 264, 661, 1252, 11, 337, 729, 561, 1228, 11, 337, 1365, 11, 4974, 460, 57, 45, 3991, 11, 456, 307, 572], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 54, "seek": 19752, "start": 207.44, "end": 211.56, "text": " way to know in advance what should be updated in those files.", "tokens": [636, 281, 458, 294, 7295, 437, 820, 312, 10588, 294, 729, 7098, 13], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 55, "seek": 19752, "start": 211.56, "end": 215.4, "text": " And then you have all those middle grounds, like, for example, for those people familiar", "tokens": [400, 550, 291, 362, 439, 729, 2808, 19196, 11, 411, 11, 337, 1365, 11, 337, 729, 561, 4963], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 56, "seek": 19752, "start": 215.4, "end": 219.24, "text": " with Dockerfile, you have some instruction that you can automatically update, like the", "tokens": [365, 33772, 69, 794, 11, 291, 362, 512, 10951, 300, 291, 393, 6772, 5623, 11, 411, 264], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 57, "seek": 19752, "start": 219.24, "end": 220.24, "text": " from instruction.", "tokens": [490, 10951, 13], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 58, "seek": 19752, "start": 220.24, "end": 222.8, "text": " It's pretty straightforward to know what you need to update.", "tokens": [467, 311, 1238, 15325, 281, 458, 437, 291, 643, 281, 5623, 13], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 59, "seek": 19752, "start": 222.8, "end": 225.04000000000002, "text": " You don't know what you want to update.", "tokens": [509, 500, 380, 458, 437, 291, 528, 281, 5623, 13], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 60, "seek": 19752, "start": 225.04000000000002, "end": 226.32000000000002, "text": " That's a different story.", "tokens": [663, 311, 257, 819, 1657, 13], "temperature": 0.0, "avg_logprob": -0.17627964403805316, "compression_ratio": 1.8, "no_speech_prob": 9.968426638806704e-06}, {"id": 61, "seek": 22632, "start": 226.32, "end": 229.28, "text": " But the thing is you know that you want to automate the base image.", "tokens": [583, 264, 551, 307, 291, 458, 300, 291, 528, 281, 31605, 264, 3096, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1493882745262084, "compression_ratio": 1.876865671641791, "no_speech_prob": 4.0053262637229636e-05}, {"id": 62, "seek": 22632, "start": 229.28, "end": 232.6, "text": " On the other side, you can put pretty much every information in the run instruction,", "tokens": [1282, 264, 661, 1252, 11, 291, 393, 829, 1238, 709, 633, 1589, 294, 264, 1190, 10951, 11], "temperature": 0.0, "avg_logprob": -0.1493882745262084, "compression_ratio": 1.876865671641791, "no_speech_prob": 4.0053262637229636e-05}, {"id": 63, "seek": 22632, "start": 232.6, "end": 238.64, "text": " the label, the end instruction, and that's where things get difficult.", "tokens": [264, 7645, 11, 264, 917, 10951, 11, 293, 300, 311, 689, 721, 483, 2252, 13], "temperature": 0.0, "avg_logprob": -0.1493882745262084, "compression_ratio": 1.876865671641791, "no_speech_prob": 4.0053262637229636e-05}, {"id": 64, "seek": 22632, "start": 238.64, "end": 242.56, "text": " So when we started working on a data line, we wanted to think, OK, we want to automate", "tokens": [407, 562, 321, 1409, 1364, 322, 257, 1412, 1622, 11, 321, 1415, 281, 519, 11, 2264, 11, 321, 528, 281, 31605], "temperature": 0.0, "avg_logprob": -0.1493882745262084, "compression_ratio": 1.876865671641791, "no_speech_prob": 4.0053262637229636e-05}, {"id": 65, "seek": 22632, "start": 242.56, "end": 243.56, "text": " everything.", "tokens": [1203, 13], "temperature": 0.0, "avg_logprob": -0.1493882745262084, "compression_ratio": 1.876865671641791, "no_speech_prob": 4.0053262637229636e-05}, {"id": 66, "seek": 22632, "start": 243.56, "end": 247.88, "text": " So we want to define where the information is coming from, what are the conditions to", "tokens": [407, 321, 528, 281, 6964, 689, 264, 1589, 307, 1348, 490, 11, 437, 366, 264, 4487, 281], "temperature": 0.0, "avg_logprob": -0.1493882745262084, "compression_ratio": 1.876865671641791, "no_speech_prob": 4.0053262637229636e-05}, {"id": 67, "seek": 22632, "start": 247.88, "end": 252.51999999999998, "text": " automate the thing, and finally, what should be the state of your file on your Git repository.", "tokens": [31605, 264, 551, 11, 293, 2721, 11, 437, 820, 312, 264, 1785, 295, 428, 3991, 322, 428, 16939, 25841, 13], "temperature": 0.0, "avg_logprob": -0.1493882745262084, "compression_ratio": 1.876865671641791, "no_speech_prob": 4.0053262637229636e-05}, {"id": 68, "seek": 25252, "start": 252.52, "end": 258.08, "text": " So if I go back to my ego example, the idea is the source of information is the latest", "tokens": [407, 498, 286, 352, 646, 281, 452, 14495, 1365, 11, 264, 1558, 307, 264, 4009, 295, 1589, 307, 264, 6792], "temperature": 0.0, "avg_logprob": -0.1484320847304551, "compression_ratio": 1.900662251655629, "no_speech_prob": 9.211373253492638e-06}, {"id": 69, "seek": 25252, "start": 258.08, "end": 259.08, "text": " ego release.", "tokens": [14495, 4374, 13], "temperature": 0.0, "avg_logprob": -0.1484320847304551, "compression_ratio": 1.900662251655629, "no_speech_prob": 9.211373253492638e-06}, {"id": 70, "seek": 25252, "start": 259.08, "end": 261.8, "text": " That could be the Git tag, that could be the latest Docker image published, that could", "tokens": [663, 727, 312, 264, 16939, 6162, 11, 300, 727, 312, 264, 6792, 33772, 3256, 6572, 11, 300, 727], "temperature": 0.0, "avg_logprob": -0.1484320847304551, "compression_ratio": 1.900662251655629, "no_speech_prob": 9.211373253492638e-06}, {"id": 71, "seek": 25252, "start": 261.8, "end": 263.72, "text": " be the GitHub release, for example.", "tokens": [312, 264, 23331, 4374, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1484320847304551, "compression_ratio": 1.900662251655629, "no_speech_prob": 9.211373253492638e-06}, {"id": 72, "seek": 25252, "start": 263.72, "end": 268.64, "text": " But at some point, we have to decide what's the source of truth for that specific application.", "tokens": [583, 412, 512, 935, 11, 321, 362, 281, 4536, 437, 311, 264, 4009, 295, 3494, 337, 300, 2685, 3861, 13], "temperature": 0.0, "avg_logprob": -0.1484320847304551, "compression_ratio": 1.900662251655629, "no_speech_prob": 9.211373253492638e-06}, {"id": 73, "seek": 25252, "start": 268.64, "end": 271.6, "text": " And then you have, like, a bunch of conditions that you want to apply, like, does it make", "tokens": [400, 550, 291, 362, 11, 411, 11, 257, 3840, 295, 4487, 300, 291, 528, 281, 3079, 11, 411, 11, 775, 309, 652], "temperature": 0.0, "avg_logprob": -0.1484320847304551, "compression_ratio": 1.900662251655629, "no_speech_prob": 9.211373253492638e-06}, {"id": 74, "seek": 25252, "start": 271.6, "end": 278.72, "text": " sense to bump the version in production if you fail to bump the version in the dev environment?", "tokens": [2020, 281, 9961, 264, 3037, 294, 4265, 498, 291, 3061, 281, 9961, 264, 3037, 294, 264, 1905, 2823, 30], "temperature": 0.0, "avg_logprob": -0.1484320847304551, "compression_ratio": 1.900662251655629, "no_speech_prob": 9.211373253492638e-06}, {"id": 75, "seek": 25252, "start": 278.72, "end": 281.52, "text": " So you want to be sure that you are using the same version everywhere.", "tokens": [407, 291, 528, 281, 312, 988, 300, 291, 366, 1228, 264, 912, 3037, 5315, 13], "temperature": 0.0, "avg_logprob": -0.1484320847304551, "compression_ratio": 1.900662251655629, "no_speech_prob": 9.211373253492638e-06}, {"id": 76, "seek": 28152, "start": 281.52, "end": 286.52, "text": " And only then, you will bump all the files related to that version.", "tokens": [400, 787, 550, 11, 291, 486, 9961, 439, 264, 7098, 4077, 281, 300, 3037, 13], "temperature": 0.0, "avg_logprob": -0.1977086655081135, "compression_ratio": 1.803448275862069, "no_speech_prob": 1.8889495549956337e-05}, {"id": 77, "seek": 28152, "start": 286.52, "end": 290.52, "text": " And so when we come back about Update CLI, the idea is we specify a manifest, we have", "tokens": [400, 370, 562, 321, 808, 646, 466, 28923, 12855, 40, 11, 264, 1558, 307, 321, 16500, 257, 10067, 11, 321, 362], "temperature": 0.0, "avg_logprob": -0.1977086655081135, "compression_ratio": 1.803448275862069, "no_speech_prob": 1.8889495549956337e-05}, {"id": 78, "seek": 28152, "start": 290.52, "end": 291.52, "text": " to write a manifest.", "tokens": [281, 2464, 257, 10067, 13], "temperature": 0.0, "avg_logprob": -0.1977086655081135, "compression_ratio": 1.803448275862069, "no_speech_prob": 1.8889495549956337e-05}, {"id": 79, "seek": 28152, "start": 291.52, "end": 294.47999999999996, "text": " So that's the main difference, for example, for Dependable.", "tokens": [407, 300, 311, 264, 2135, 2649, 11, 337, 1365, 11, 337, 4056, 521, 712, 13], "temperature": 0.0, "avg_logprob": -0.1977086655081135, "compression_ratio": 1.803448275862069, "no_speech_prob": 1.8889495549956337e-05}, {"id": 80, "seek": 28152, "start": 294.47999999999996, "end": 297.59999999999997, "text": " Because Dependable, you just enable the button, it works.", "tokens": [1436, 4056, 521, 712, 11, 291, 445, 9528, 264, 2960, 11, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.1977086655081135, "compression_ratio": 1.803448275862069, "no_speech_prob": 1.8889495549956337e-05}, {"id": 81, "seek": 28152, "start": 297.59999999999997, "end": 300.08, "text": " But it will only detect what it can detect.", "tokens": [583, 309, 486, 787, 5531, 437, 309, 393, 5531, 13], "temperature": 0.0, "avg_logprob": -0.1977086655081135, "compression_ratio": 1.803448275862069, "no_speech_prob": 1.8889495549956337e-05}, {"id": 82, "seek": 28152, "start": 300.08, "end": 303.24, "text": " But most of the time, you have no idea what you should update.", "tokens": [583, 881, 295, 264, 565, 11, 291, 362, 572, 1558, 437, 291, 820, 5623, 13], "temperature": 0.0, "avg_logprob": -0.1977086655081135, "compression_ratio": 1.803448275862069, "no_speech_prob": 1.8889495549956337e-05}, {"id": 83, "seek": 28152, "start": 303.24, "end": 306.12, "text": " With Update CLI, we went the other way.", "tokens": [2022, 28923, 12855, 40, 11, 321, 1437, 264, 661, 636, 13], "temperature": 0.0, "avg_logprob": -0.1977086655081135, "compression_ratio": 1.803448275862069, "no_speech_prob": 1.8889495549956337e-05}, {"id": 84, "seek": 28152, "start": 306.12, "end": 310.64, "text": " We write a manifest, so for example, this one is you have the source, the source of", "tokens": [492, 2464, 257, 10067, 11, 370, 337, 1365, 11, 341, 472, 307, 291, 362, 264, 4009, 11, 264, 4009, 295], "temperature": 0.0, "avg_logprob": -0.1977086655081135, "compression_ratio": 1.803448275862069, "no_speech_prob": 1.8889495549956337e-05}, {"id": 85, "seek": 31064, "start": 310.64, "end": 311.64, "text": " truth.", "tokens": [3494, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 86, "seek": 31064, "start": 311.64, "end": 312.64, "text": " In this case, it's a GitHub release.", "tokens": [682, 341, 1389, 11, 309, 311, 257, 23331, 4374, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 87, "seek": 31064, "start": 312.64, "end": 313.64, "text": " So it can GitHub release.", "tokens": [407, 309, 393, 23331, 4374, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 88, "seek": 31064, "start": 313.64, "end": 317.08, "text": " And then you have the specification, where you provide all the parameters for that specific", "tokens": [400, 550, 291, 362, 264, 31256, 11, 689, 291, 2893, 439, 264, 9834, 337, 300, 2685], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 89, "seek": 31064, "start": 317.08, "end": 318.08, "text": " project.", "tokens": [1716, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 90, "seek": 31064, "start": 318.08, "end": 322.96, "text": " So in this case, I am monitoring the go-go-io git repository.", "tokens": [407, 294, 341, 1389, 11, 286, 669, 11028, 264, 352, 12, 1571, 12, 1004, 18331, 25841, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 91, "seek": 31064, "start": 322.96, "end": 326.08, "text": " This one gives me a version, let's say 100.", "tokens": [639, 472, 2709, 385, 257, 3037, 11, 718, 311, 584, 2319, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 92, "seek": 31064, "start": 326.08, "end": 327.08, "text": " That's the latest one.", "tokens": [663, 311, 264, 6792, 472, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 93, "seek": 31064, "start": 327.08, "end": 333.64, "text": " And what I want to do is I want to be sure that all my files, named natify.tom.yml, are", "tokens": [400, 437, 286, 528, 281, 360, 307, 286, 528, 281, 312, 988, 300, 439, 452, 7098, 11, 4926, 2249, 2505, 13, 83, 298, 13, 4199, 75, 11, 366], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 94, "seek": 31064, "start": 333.64, "end": 334.64, "text": " up to date.", "tokens": [493, 281, 4002, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 95, "seek": 31064, "start": 334.64, "end": 335.64, "text": " So I look at the key.", "tokens": [407, 286, 574, 412, 264, 2141, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 96, "seek": 31064, "start": 335.64, "end": 340.0, "text": " And then if I run this manifest on my machine, it will just dump the file on my machine.", "tokens": [400, 550, 498, 286, 1190, 341, 10067, 322, 452, 3479, 11, 309, 486, 445, 11430, 264, 3991, 322, 452, 3479, 13], "temperature": 0.0, "avg_logprob": -0.2156293346623706, "compression_ratio": 1.7647058823529411, "no_speech_prob": 3.678050052258186e-05}, {"id": 97, "seek": 34000, "start": 340.0, "end": 345.52, "text": " If I run this manifest on the CI environment, it will bump the file in the CI environment.", "tokens": [759, 286, 1190, 341, 10067, 322, 264, 37777, 2823, 11, 309, 486, 9961, 264, 3991, 294, 264, 37777, 2823, 13], "temperature": 0.0, "avg_logprob": -0.13146850151744316, "compression_ratio": 1.7782101167315174, "no_speech_prob": 1.5607061868649907e-05}, {"id": 98, "seek": 34000, "start": 345.52, "end": 349.68, "text": " And so the next step is, okay, that's one thing to have it working on a machine.", "tokens": [400, 370, 264, 958, 1823, 307, 11, 1392, 11, 300, 311, 472, 551, 281, 362, 309, 1364, 322, 257, 3479, 13], "temperature": 0.0, "avg_logprob": -0.13146850151744316, "compression_ratio": 1.7782101167315174, "no_speech_prob": 1.5607061868649907e-05}, {"id": 99, "seek": 34000, "start": 349.68, "end": 353.4, "text": " But then you also want to be sure that your git repository is up to date and don't pay", "tokens": [583, 550, 291, 611, 528, 281, 312, 988, 300, 428, 18331, 25841, 307, 493, 281, 4002, 293, 500, 380, 1689], "temperature": 0.0, "avg_logprob": -0.13146850151744316, "compression_ratio": 1.7782101167315174, "no_speech_prob": 1.5607061868649907e-05}, {"id": 100, "seek": 34000, "start": 353.4, "end": 355.4, "text": " attention to them.", "tokens": [3202, 281, 552, 13], "temperature": 0.0, "avg_logprob": -0.13146850151744316, "compression_ratio": 1.7782101167315174, "no_speech_prob": 1.5607061868649907e-05}, {"id": 101, "seek": 34000, "start": 355.4, "end": 358.96, "text": " So you can just focus on what really makes sense in your case.", "tokens": [407, 291, 393, 445, 1879, 322, 437, 534, 1669, 2020, 294, 428, 1389, 13], "temperature": 0.0, "avg_logprob": -0.13146850151744316, "compression_ratio": 1.7782101167315174, "no_speech_prob": 1.5607061868649907e-05}, {"id": 102, "seek": 34000, "start": 358.96, "end": 363.62, "text": " And so the next step is, okay, we want to specify where that file is located.", "tokens": [400, 370, 264, 958, 1823, 307, 11, 1392, 11, 321, 528, 281, 16500, 689, 300, 3991, 307, 6870, 13], "temperature": 0.0, "avg_logprob": -0.13146850151744316, "compression_ratio": 1.7782101167315174, "no_speech_prob": 1.5607061868649907e-05}, {"id": 103, "seek": 34000, "start": 363.62, "end": 365.52, "text": " So we have a bunch of other resources.", "tokens": [407, 321, 362, 257, 3840, 295, 661, 3593, 13], "temperature": 0.0, "avg_logprob": -0.13146850151744316, "compression_ratio": 1.7782101167315174, "no_speech_prob": 1.5607061868649907e-05}, {"id": 104, "seek": 36552, "start": 365.52, "end": 371.96, "text": " In this case, it's a SCM of type git, because I want to update git repositories.", "tokens": [682, 341, 1389, 11, 309, 311, 257, 9028, 44, 295, 2010, 18331, 11, 570, 286, 528, 281, 5623, 18331, 22283, 2083, 13], "temperature": 0.0, "avg_logprob": -0.1939274092852059, "compression_ratio": 1.6654676258992807, "no_speech_prob": 2.142149787687231e-05}, {"id": 105, "seek": 36552, "start": 371.96, "end": 375.64, "text": " And then I specify that I want the pull request approach, where I create a temporary branch", "tokens": [400, 550, 286, 16500, 300, 286, 528, 264, 2235, 5308, 3109, 11, 689, 286, 1884, 257, 13413, 9819], "temperature": 0.0, "avg_logprob": -0.1939274092852059, "compression_ratio": 1.6654676258992807, "no_speech_prob": 2.142149787687231e-05}, {"id": 106, "seek": 36552, "start": 375.64, "end": 378.79999999999995, "text": " and then someone can review my change.", "tokens": [293, 550, 1580, 393, 3131, 452, 1319, 13], "temperature": 0.0, "avg_logprob": -0.1939274092852059, "compression_ratio": 1.6654676258992807, "no_speech_prob": 2.142149787687231e-05}, {"id": 107, "seek": 36552, "start": 378.79999999999995, "end": 383.91999999999996, "text": " And then when you think about all those building blocks, you can really have, like, more advanced", "tokens": [400, 550, 562, 291, 519, 466, 439, 729, 2390, 8474, 11, 291, 393, 534, 362, 11, 411, 11, 544, 7339], "temperature": 0.0, "avg_logprob": -0.1939274092852059, "compression_ratio": 1.6654676258992807, "no_speech_prob": 2.142149787687231e-05}, {"id": 108, "seek": 36552, "start": 383.91999999999996, "end": 389.15999999999997, "text": " scenarios, like this one is another project that we use, where we use it, is when someone", "tokens": [15077, 11, 411, 341, 472, 307, 1071, 1716, 300, 321, 764, 11, 689, 321, 764, 309, 11, 307, 562, 1580], "temperature": 0.0, "avg_logprob": -0.1939274092852059, "compression_ratio": 1.6654676258992807, "no_speech_prob": 2.142149787687231e-05}, {"id": 109, "seek": 36552, "start": 389.15999999999997, "end": 393.64, "text": " really is in a new version of Apno, we use GitHub Action there.", "tokens": [534, 307, 294, 257, 777, 3037, 295, 8723, 1771, 11, 321, 764, 23331, 16261, 456, 13], "temperature": 0.0, "avg_logprob": -0.1939274092852059, "compression_ratio": 1.6654676258992807, "no_speech_prob": 2.142149787687231e-05}, {"id": 110, "seek": 39364, "start": 393.64, "end": 398.2, "text": " That send a bunch of release events automatically to other git repositories.", "tokens": [663, 2845, 257, 3840, 295, 4374, 3931, 6772, 281, 661, 18331, 22283, 2083, 13], "temperature": 0.0, "avg_logprob": -0.13343752476206996, "compression_ratio": 1.7454545454545454, "no_speech_prob": 3.740410102182068e-05}, {"id": 111, "seek": 39364, "start": 398.2, "end": 401.2, "text": " And those git repositories will trigger Update CLI.", "tokens": [400, 729, 18331, 22283, 2083, 486, 7875, 28923, 12855, 40, 13], "temperature": 0.0, "avg_logprob": -0.13343752476206996, "compression_ratio": 1.7454545454545454, "no_speech_prob": 3.740410102182068e-05}, {"id": 112, "seek": 39364, "start": 401.2, "end": 403.76, "text": " So Update CLI will retrieve all the different information.", "tokens": [407, 28923, 12855, 40, 486, 30254, 439, 264, 819, 1589, 13], "temperature": 0.0, "avg_logprob": -0.13343752476206996, "compression_ratio": 1.7454545454545454, "no_speech_prob": 3.740410102182068e-05}, {"id": 113, "seek": 39364, "start": 403.76, "end": 408.71999999999997, "text": " So for example, on Apno slash docs, which is obviously the website, we retrieve the latest", "tokens": [407, 337, 1365, 11, 322, 8723, 1771, 17330, 45623, 11, 597, 307, 2745, 264, 3144, 11, 321, 30254, 264, 6792], "temperature": 0.0, "avg_logprob": -0.13343752476206996, "compression_ratio": 1.7454545454545454, "no_speech_prob": 3.740410102182068e-05}, {"id": 114, "seek": 39364, "start": 408.71999999999997, "end": 412.8, "text": " version of Apno, and then we check that all the download links are up to date.", "tokens": [3037, 295, 8723, 1771, 11, 293, 550, 321, 1520, 300, 439, 264, 5484, 6123, 366, 493, 281, 4002, 13], "temperature": 0.0, "avg_logprob": -0.13343752476206996, "compression_ratio": 1.7454545454545454, "no_speech_prob": 3.740410102182068e-05}, {"id": 115, "seek": 39364, "start": 412.8, "end": 416.08, "text": " We check that we have the version for that specific website.", "tokens": [492, 1520, 300, 321, 362, 264, 3037, 337, 300, 2685, 3144, 13], "temperature": 0.0, "avg_logprob": -0.13343752476206996, "compression_ratio": 1.7454545454545454, "no_speech_prob": 3.740410102182068e-05}, {"id": 116, "seek": 39364, "start": 416.08, "end": 421.71999999999997, "text": " So we maintain one documentation per major and minor version.", "tokens": [407, 321, 6909, 472, 14333, 680, 2563, 293, 6696, 3037, 13], "temperature": 0.0, "avg_logprob": -0.13343752476206996, "compression_ratio": 1.7454545454545454, "no_speech_prob": 3.740410102182068e-05}, {"id": 117, "seek": 42172, "start": 421.72, "end": 425.0, "text": " So we try to be sure that those files are up to date.", "tokens": [407, 321, 853, 281, 312, 988, 300, 729, 7098, 366, 493, 281, 4002, 13], "temperature": 0.0, "avg_logprob": -0.15938660002102817, "compression_ratio": 1.7098976109215016, "no_speech_prob": 1.0285184544045478e-05}, {"id": 118, "seek": 42172, "start": 425.0, "end": 427.36, "text": " And if it's not the case, we open a PR.", "tokens": [400, 498, 309, 311, 406, 264, 1389, 11, 321, 1269, 257, 11568, 13], "temperature": 0.0, "avg_logprob": -0.15938660002102817, "compression_ratio": 1.7098976109215016, "no_speech_prob": 1.0285184544045478e-05}, {"id": 119, "seek": 42172, "start": 427.36, "end": 431.48, "text": " And then as part of the release process of Apno, someone needs to review the PR and double", "tokens": [400, 550, 382, 644, 295, 264, 4374, 1399, 295, 8723, 1771, 11, 1580, 2203, 281, 3131, 264, 11568, 293, 3834], "temperature": 0.0, "avg_logprob": -0.15938660002102817, "compression_ratio": 1.7098976109215016, "no_speech_prob": 1.0285184544045478e-05}, {"id": 120, "seek": 42172, "start": 431.48, "end": 436.88000000000005, "text": " check that it still contains a file that you want to have there.", "tokens": [1520, 300, 309, 920, 8306, 257, 3991, 300, 291, 528, 281, 362, 456, 13], "temperature": 0.0, "avg_logprob": -0.15938660002102817, "compression_ratio": 1.7098976109215016, "no_speech_prob": 1.0285184544045478e-05}, {"id": 121, "seek": 42172, "start": 436.88000000000005, "end": 439.36, "text": " Another example is the way we automate Hemshot.", "tokens": [3996, 1365, 307, 264, 636, 321, 31605, 389, 9097, 12194, 13], "temperature": 0.0, "avg_logprob": -0.15938660002102817, "compression_ratio": 1.7098976109215016, "no_speech_prob": 1.0285184544045478e-05}, {"id": 122, "seek": 42172, "start": 439.36, "end": 445.0, "text": " We define, okay, we are monitoring the Apno UI, which is a front application, and we monitor", "tokens": [492, 6964, 11, 1392, 11, 321, 366, 11028, 264, 8723, 1771, 15682, 11, 597, 307, 257, 1868, 3861, 11, 293, 321, 6002], "temperature": 0.0, "avg_logprob": -0.15938660002102817, "compression_ratio": 1.7098976109215016, "no_speech_prob": 1.0285184544045478e-05}, {"id": 123, "seek": 42172, "start": 445.0, "end": 446.92, "text": " the backend, the Apno.", "tokens": [264, 38087, 11, 264, 8723, 1771, 13], "temperature": 0.0, "avg_logprob": -0.15938660002102817, "compression_ratio": 1.7098976109215016, "no_speech_prob": 1.0285184544045478e-05}, {"id": 124, "seek": 42172, "start": 446.92, "end": 450.40000000000003, "text": " And then if for some reason there is a new version, then it will automatically bump the", "tokens": [400, 550, 498, 337, 512, 1778, 456, 307, 257, 777, 3037, 11, 550, 309, 486, 6772, 9961, 264], "temperature": 0.0, "avg_logprob": -0.15938660002102817, "compression_ratio": 1.7098976109215016, "no_speech_prob": 1.0285184544045478e-05}, {"id": 125, "seek": 45040, "start": 450.4, "end": 452.4, "text": " Hemshot, bump the metadata, and so on.", "tokens": [389, 9097, 12194, 11, 9961, 264, 26603, 11, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.17957860332424358, "compression_ratio": 1.6392857142857142, "no_speech_prob": 8.12687721918337e-06}, {"id": 126, "seek": 45040, "start": 452.4, "end": 456.44, "text": " And once again, we have a human validation where someone can just come, look at the PR,", "tokens": [400, 1564, 797, 11, 321, 362, 257, 1952, 24071, 689, 1580, 393, 445, 808, 11, 574, 412, 264, 11568, 11], "temperature": 0.0, "avg_logprob": -0.17957860332424358, "compression_ratio": 1.6392857142857142, "no_speech_prob": 8.12687721918337e-06}, {"id": 127, "seek": 45040, "start": 456.44, "end": 460.35999999999996, "text": " and decide if we want to go one step further.", "tokens": [293, 4536, 498, 321, 528, 281, 352, 472, 1823, 3052, 13], "temperature": 0.0, "avg_logprob": -0.17957860332424358, "compression_ratio": 1.6392857142857142, "no_speech_prob": 8.12687721918337e-06}, {"id": 128, "seek": 45040, "start": 460.35999999999996, "end": 468.47999999999996, "text": " So really briefly here is when automated update is not a so easy challenge, as I initially", "tokens": [407, 534, 10515, 510, 307, 562, 18473, 5623, 307, 406, 257, 370, 1858, 3430, 11, 382, 286, 9105], "temperature": 0.0, "avg_logprob": -0.17957860332424358, "compression_ratio": 1.6392857142857142, "no_speech_prob": 8.12687721918337e-06}, {"id": 129, "seek": 45040, "start": 468.47999999999996, "end": 473.12, "text": " thought, because so we split the project in three different categories.", "tokens": [1194, 11, 570, 370, 321, 7472, 264, 1716, 294, 1045, 819, 10479, 13], "temperature": 0.0, "avg_logprob": -0.17957860332424358, "compression_ratio": 1.6392857142857142, "no_speech_prob": 8.12687721918337e-06}, {"id": 130, "seek": 45040, "start": 473.12, "end": 474.44, "text": " So the first one is declarative.", "tokens": [407, 264, 700, 472, 307, 16694, 1166, 13], "temperature": 0.0, "avg_logprob": -0.17957860332424358, "compression_ratio": 1.6392857142857142, "no_speech_prob": 8.12687721918337e-06}, {"id": 131, "seek": 45040, "start": 474.44, "end": 479.0, "text": " So the idea is you know in advance what should be updated, and so you define in a manifest", "tokens": [407, 264, 1558, 307, 291, 458, 294, 7295, 437, 820, 312, 10588, 11, 293, 370, 291, 6964, 294, 257, 10067], "temperature": 0.0, "avg_logprob": -0.17957860332424358, "compression_ratio": 1.6392857142857142, "no_speech_prob": 8.12687721918337e-06}, {"id": 132, "seek": 47900, "start": 479.0, "end": 483.56, "text": " how you want to update something, because it's not something that you can define in", "tokens": [577, 291, 528, 281, 5623, 746, 11, 570, 309, 311, 406, 746, 300, 291, 393, 6964, 294], "temperature": 0.0, "avg_logprob": -0.22955713272094727, "compression_ratio": 1.6392857142857142, "no_speech_prob": 3.937330984626897e-05}, {"id": 133, "seek": 47900, "start": 483.56, "end": 484.56, "text": " advance.", "tokens": [7295, 13], "temperature": 0.0, "avg_logprob": -0.22955713272094727, "compression_ratio": 1.6392857142857142, "no_speech_prob": 3.937330984626897e-05}, {"id": 134, "seek": 47900, "start": 484.56, "end": 488.2, "text": " The other discovery is a bit more like for those people familiar with Dependentbot or", "tokens": [440, 661, 12114, 307, 257, 857, 544, 411, 337, 729, 561, 4963, 365, 4056, 521, 317, 18870, 420], "temperature": 0.0, "avg_logprob": -0.22955713272094727, "compression_ratio": 1.6392857142857142, "no_speech_prob": 3.937330984626897e-05}, {"id": 135, "seek": 47900, "start": 488.2, "end": 492.04, "text": " Renovatebot, you just run the command and you ask it to automatically detect what could", "tokens": [12883, 5179, 473, 18870, 11, 291, 445, 1190, 264, 5622, 293, 291, 1029, 309, 281, 6772, 5531, 437, 727], "temperature": 0.0, "avg_logprob": -0.22955713272094727, "compression_ratio": 1.6392857142857142, "no_speech_prob": 3.937330984626897e-05}, {"id": 136, "seek": 47900, "start": 492.04, "end": 493.04, "text": " be updated.", "tokens": [312, 10588, 13], "temperature": 0.0, "avg_logprob": -0.22955713272094727, "compression_ratio": 1.6392857142857142, "no_speech_prob": 3.937330984626897e-05}, {"id": 137, "seek": 47900, "start": 493.04, "end": 496.44, "text": " There are scenarios where you can find that information.", "tokens": [821, 366, 15077, 689, 291, 393, 915, 300, 1589, 13], "temperature": 0.0, "avg_logprob": -0.22955713272094727, "compression_ratio": 1.6392857142857142, "no_speech_prob": 3.937330984626897e-05}, {"id": 138, "seek": 47900, "start": 496.44, "end": 500.64, "text": " For example, on a Maven project, you have the pump.xml, you fetch all the dependencies", "tokens": [1171, 1365, 11, 322, 257, 4042, 553, 1716, 11, 291, 362, 264, 5889, 13, 87, 15480, 11, 291, 23673, 439, 264, 36606], "temperature": 0.0, "avg_logprob": -0.22955713272094727, "compression_ratio": 1.6392857142857142, "no_speech_prob": 3.937330984626897e-05}, {"id": 139, "seek": 47900, "start": 500.64, "end": 501.64, "text": " and update them.", "tokens": [293, 5623, 552, 13], "temperature": 0.0, "avg_logprob": -0.22955713272094727, "compression_ratio": 1.6392857142857142, "no_speech_prob": 3.937330984626897e-05}, {"id": 140, "seek": 47900, "start": 501.64, "end": 504.88, "text": " That's pretty easy.", "tokens": [663, 311, 1238, 1858, 13], "temperature": 0.0, "avg_logprob": -0.22955713272094727, "compression_ratio": 1.6392857142857142, "no_speech_prob": 3.937330984626897e-05}, {"id": 141, "seek": 50488, "start": 504.88, "end": 510.0, "text": " On other projects like Docker containers, it's kind of a mess over there, so it's super", "tokens": [1282, 661, 4455, 411, 33772, 17089, 11, 309, 311, 733, 295, 257, 2082, 670, 456, 11, 370, 309, 311, 1687], "temperature": 0.0, "avg_logprob": -0.16147608114472517, "compression_ratio": 1.819935691318328, "no_speech_prob": 1.5430434359586798e-05}, {"id": 142, "seek": 50488, "start": 510.0, "end": 512.52, "text": " difficult to know what should be the next version.", "tokens": [2252, 281, 458, 437, 820, 312, 264, 958, 3037, 13], "temperature": 0.0, "avg_logprob": -0.16147608114472517, "compression_ratio": 1.819935691318328, "no_speech_prob": 1.5430434359586798e-05}, {"id": 143, "seek": 50488, "start": 512.52, "end": 516.4399999999999, "text": " And then on the other side, you have all those situations where you specify a constraint,", "tokens": [400, 550, 322, 264, 661, 1252, 11, 291, 362, 439, 729, 6851, 689, 291, 16500, 257, 25534, 11], "temperature": 0.0, "avg_logprob": -0.16147608114472517, "compression_ratio": 1.819935691318328, "no_speech_prob": 1.5430434359586798e-05}, {"id": 144, "seek": 50488, "start": 516.4399999999999, "end": 520.36, "text": " a version constraint, like you don't want to use a version bigger than the 1.0, but", "tokens": [257, 3037, 25534, 11, 411, 291, 500, 380, 528, 281, 764, 257, 3037, 3801, 813, 264, 502, 13, 15, 11, 457], "temperature": 0.0, "avg_logprob": -0.16147608114472517, "compression_ratio": 1.819935691318328, "no_speech_prob": 1.5430434359586798e-05}, {"id": 145, "seek": 50488, "start": 520.36, "end": 525.0, "text": " at some point the project upstream is like way further than you are in your project.", "tokens": [412, 512, 935, 264, 1716, 33915, 307, 411, 636, 3052, 813, 291, 366, 294, 428, 1716, 13], "temperature": 0.0, "avg_logprob": -0.16147608114472517, "compression_ratio": 1.819935691318328, "no_speech_prob": 1.5430434359586798e-05}, {"id": 146, "seek": 50488, "start": 525.0, "end": 529.6, "text": " At some point, you need to be aware that you will need to plan some work to catch up", "tokens": [1711, 512, 935, 11, 291, 643, 281, 312, 3650, 300, 291, 486, 643, 281, 1393, 512, 589, 281, 3745, 493], "temperature": 0.0, "avg_logprob": -0.16147608114472517, "compression_ratio": 1.819935691318328, "no_speech_prob": 1.5430434359586798e-05}, {"id": 147, "seek": 50488, "start": 529.6, "end": 530.88, "text": " on the upstream project.", "tokens": [322, 264, 33915, 1716, 13], "temperature": 0.0, "avg_logprob": -0.16147608114472517, "compression_ratio": 1.819935691318328, "no_speech_prob": 1.5430434359586798e-05}, {"id": 148, "seek": 50488, "start": 530.88, "end": 534.52, "text": " And so that's another experiment, which is update monitor.", "tokens": [400, 370, 300, 311, 1071, 5120, 11, 597, 307, 5623, 6002, 13], "temperature": 0.0, "avg_logprob": -0.16147608114472517, "compression_ratio": 1.819935691318328, "no_speech_prob": 1.5430434359586798e-05}, {"id": 149, "seek": 53452, "start": 534.52, "end": 536.0, "text": " So I want to do a quick demo.", "tokens": [407, 286, 528, 281, 360, 257, 1702, 10723, 13], "temperature": 0.0, "avg_logprob": -0.2817969041712144, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.962699181807693e-05}, {"id": 150, "seek": 53452, "start": 536.0, "end": 541.12, "text": " I don't have good internet connectivity here, so I hope it will work.", "tokens": [286, 500, 380, 362, 665, 4705, 21095, 510, 11, 370, 286, 1454, 309, 486, 589, 13], "temperature": 0.0, "avg_logprob": -0.2817969041712144, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.962699181807693e-05}, {"id": 151, "seek": 53452, "start": 541.12, "end": 547.96, "text": " So on the left side is one of the manifest, is it big enough?", "tokens": [407, 322, 264, 1411, 1252, 307, 472, 295, 264, 10067, 11, 307, 309, 955, 1547, 30], "temperature": 0.0, "avg_logprob": -0.2817969041712144, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.962699181807693e-05}, {"id": 152, "seek": 53452, "start": 547.96, "end": 549.36, "text": " Oops.", "tokens": [21726, 13], "temperature": 0.0, "avg_logprob": -0.2817969041712144, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.962699181807693e-05}, {"id": 153, "seek": 53452, "start": 549.36, "end": 557.1999999999999, "text": " So on the left side, we specify a few things like, okay, in this case, we want to enable", "tokens": [407, 322, 264, 1411, 1252, 11, 321, 16500, 257, 1326, 721, 411, 11, 1392, 11, 294, 341, 1389, 11, 321, 528, 281, 9528], "temperature": 0.0, "avg_logprob": -0.2817969041712144, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.962699181807693e-05}, {"id": 154, "seek": 53452, "start": 557.1999999999999, "end": 561.12, "text": " the auto merge feature of GitHub, actually, of GitHub PolarQuest.", "tokens": [264, 8399, 22183, 4111, 295, 23331, 11, 767, 11, 295, 23331, 3635, 289, 8547, 377, 13], "temperature": 0.0, "avg_logprob": -0.2817969041712144, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.962699181807693e-05}, {"id": 155, "seek": 53452, "start": 561.12, "end": 562.12, "text": " We specify labels.", "tokens": [492, 16500, 16949, 13], "temperature": 0.0, "avg_logprob": -0.2817969041712144, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.962699181807693e-05}, {"id": 156, "seek": 56212, "start": 562.12, "end": 567.52, "text": " So we automatically open a PR, and if all the tests are passing, it will merge the", "tokens": [407, 321, 6772, 1269, 257, 11568, 11, 293, 498, 439, 264, 6921, 366, 8437, 11, 309, 486, 22183, 264], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 157, "seek": 56212, "start": 567.52, "end": 568.8, "text": " PR automatically.", "tokens": [11568, 6772, 13], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 158, "seek": 56212, "start": 568.8, "end": 573.0, "text": " And so I don't have to pay attention, which reduce, obviously, the noise introduced by", "tokens": [400, 370, 286, 500, 380, 362, 281, 1689, 3202, 11, 597, 5407, 11, 2745, 11, 264, 5658, 7268, 538], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 159, "seek": 56212, "start": 573.0, "end": 574.16, "text": " those PR.", "tokens": [729, 11568, 13], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 160, "seek": 56212, "start": 574.16, "end": 577.4, "text": " We need to specify which projects we want to go.", "tokens": [492, 643, 281, 16500, 597, 4455, 321, 528, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 161, "seek": 56212, "start": 577.4, "end": 580.5600000000001, "text": " So in this case, that's the updated website.", "tokens": [407, 294, 341, 1389, 11, 300, 311, 264, 10588, 3144, 13], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 162, "seek": 56212, "start": 580.5600000000001, "end": 583.12, "text": " And finally, we specify where the information is coming from.", "tokens": [400, 2721, 11, 321, 16500, 689, 264, 1589, 307, 1348, 490, 13], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 163, "seek": 56212, "start": 583.12, "end": 585.28, "text": " So this one, we monitor, go, go, go, go.", "tokens": [407, 341, 472, 11, 321, 6002, 11, 352, 11, 352, 11, 352, 11, 352, 13], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 164, "seek": 56212, "start": 585.28, "end": 590.36, "text": " As I said, we could have instead of monitoring the GitHub release, at some point I could", "tokens": [1018, 286, 848, 11, 321, 727, 362, 2602, 295, 11028, 264, 23331, 4374, 11, 412, 512, 935, 286, 727], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 165, "seek": 56212, "start": 590.36, "end": 591.36, "text": " have said, okay.", "tokens": [362, 848, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.20024569943654452, "compression_ratio": 1.7182130584192439, "no_speech_prob": 3.367895260453224e-05}, {"id": 166, "seek": 59136, "start": 591.36, "end": 594.2, "text": " I just want to monitor the Docker images.", "tokens": [286, 445, 528, 281, 6002, 264, 33772, 5267, 13], "temperature": 0.0, "avg_logprob": -0.33293340080662776, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.9219601603690535e-05}, {"id": 167, "seek": 59136, "start": 594.2, "end": 600.32, "text": " But in that case, I just need to provide a different piece of information.", "tokens": [583, 294, 300, 1389, 11, 286, 445, 643, 281, 2893, 257, 819, 2522, 295, 1589, 13], "temperature": 0.0, "avg_logprob": -0.33293340080662776, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.9219601603690535e-05}, {"id": 168, "seek": 59136, "start": 600.32, "end": 607.76, "text": " Or you could say, for example, I want to monitor here, writing from the IDD is the easiest", "tokens": [1610, 291, 727, 584, 11, 337, 1365, 11, 286, 528, 281, 6002, 510, 11, 3579, 490, 264, 7348, 35, 307, 264, 12889], "temperature": 0.0, "avg_logprob": -0.33293340080662776, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.9219601603690535e-05}, {"id": 169, "seek": 59136, "start": 607.76, "end": 609.48, "text": " way.", "tokens": [636, 13], "temperature": 0.0, "avg_logprob": -0.33293340080662776, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.9219601603690535e-05}, {"id": 170, "seek": 59136, "start": 609.48, "end": 617.6, "text": " You can specify different ways of filtering version, because what's something that we", "tokens": [509, 393, 16500, 819, 2098, 295, 30822, 3037, 11, 570, 437, 311, 746, 300, 321], "temperature": 0.0, "avg_logprob": -0.33293340080662776, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.9219601603690535e-05}, {"id": 171, "seek": 61760, "start": 617.6, "end": 622.84, "text": " notice, for example, is when I said the Docker ecosystem is a mess, is you can put whatever", "tokens": [3449, 11, 337, 1365, 11, 307, 562, 286, 848, 264, 33772, 11311, 307, 257, 2082, 11, 307, 291, 393, 829, 2035], "temperature": 0.0, "avg_logprob": -0.13210859791985874, "compression_ratio": 1.671875, "no_speech_prob": 6.266345008043572e-05}, {"id": 172, "seek": 61760, "start": 622.84, "end": 624.36, "text": " information you want in a tag.", "tokens": [1589, 291, 528, 294, 257, 6162, 13], "temperature": 0.0, "avg_logprob": -0.13210859791985874, "compression_ratio": 1.671875, "no_speech_prob": 6.266345008043572e-05}, {"id": 173, "seek": 61760, "start": 624.36, "end": 628.0400000000001, "text": " So there is pretty much no way, I mean, most of the time, there is no way to know what", "tokens": [407, 456, 307, 1238, 709, 572, 636, 11, 286, 914, 11, 881, 295, 264, 565, 11, 456, 307, 572, 636, 281, 458, 437], "temperature": 0.0, "avg_logprob": -0.13210859791985874, "compression_ratio": 1.671875, "no_speech_prob": 6.266345008043572e-05}, {"id": 174, "seek": 61760, "start": 628.0400000000001, "end": 629.6800000000001, "text": " should be the next version.", "tokens": [820, 312, 264, 958, 3037, 13], "temperature": 0.0, "avg_logprob": -0.13210859791985874, "compression_ratio": 1.671875, "no_speech_prob": 6.266345008043572e-05}, {"id": 175, "seek": 61760, "start": 629.6800000000001, "end": 633.84, "text": " Then depending on the registries, they don't return you the latest version, because they", "tokens": [1396, 5413, 322, 264, 11376, 2244, 11, 436, 500, 380, 2736, 291, 264, 6792, 3037, 11, 570, 436], "temperature": 0.0, "avg_logprob": -0.13210859791985874, "compression_ratio": 1.671875, "no_speech_prob": 6.266345008043572e-05}, {"id": 176, "seek": 61760, "start": 633.84, "end": 636.0400000000001, "text": " don't sort the tags in the same way.", "tokens": [500, 380, 1333, 264, 18632, 294, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.13210859791985874, "compression_ratio": 1.671875, "no_speech_prob": 6.266345008043572e-05}, {"id": 177, "seek": 61760, "start": 636.0400000000001, "end": 642.4, "text": " So at some point, yeah, you need to enforce a specific behavior.", "tokens": [407, 412, 512, 935, 11, 1338, 11, 291, 643, 281, 24825, 257, 2685, 5223, 13], "temperature": 0.0, "avg_logprob": -0.13210859791985874, "compression_ratio": 1.671875, "no_speech_prob": 6.266345008043572e-05}, {"id": 178, "seek": 64240, "start": 642.4, "end": 647.84, "text": " And then the target in this case is, if there is a new version of Hugo, we want to be sure", "tokens": [400, 550, 264, 3779, 294, 341, 1389, 307, 11, 498, 456, 307, 257, 777, 3037, 295, 32504, 11, 321, 528, 281, 312, 988], "temperature": 0.0, "avg_logprob": -0.2041240460944898, "compression_ratio": 1.55, "no_speech_prob": 2.4015138478716835e-05}, {"id": 179, "seek": 64240, "start": 647.84, "end": 655.04, "text": " that the workflow file has the correct version and that the native file is up to date.", "tokens": [300, 264, 20993, 3991, 575, 264, 3006, 3037, 293, 300, 264, 8470, 3991, 307, 493, 281, 4002, 13], "temperature": 0.0, "avg_logprob": -0.2041240460944898, "compression_ratio": 1.55, "no_speech_prob": 2.4015138478716835e-05}, {"id": 180, "seek": 64240, "start": 655.04, "end": 657.0799999999999, "text": " So I don't care.", "tokens": [407, 286, 500, 380, 1127, 13], "temperature": 0.0, "avg_logprob": -0.2041240460944898, "compression_ratio": 1.55, "no_speech_prob": 2.4015138478716835e-05}, {"id": 181, "seek": 64240, "start": 657.0799999999999, "end": 661.4399999999999, "text": " And so what it looks like on the other side is just a CLI, as I said.", "tokens": [400, 370, 437, 309, 1542, 411, 322, 264, 661, 1252, 307, 445, 257, 12855, 40, 11, 382, 286, 848, 13], "temperature": 0.0, "avg_logprob": -0.2041240460944898, "compression_ratio": 1.55, "no_speech_prob": 2.4015138478716835e-05}, {"id": 182, "seek": 64240, "start": 661.4399999999999, "end": 668.04, "text": " So you can read it from my machine, Linux, Mac, wherever you want to run it.", "tokens": [407, 291, 393, 1401, 309, 490, 452, 3479, 11, 18734, 11, 5707, 11, 8660, 291, 528, 281, 1190, 309, 13], "temperature": 0.0, "avg_logprob": -0.2041240460944898, "compression_ratio": 1.55, "no_speech_prob": 2.4015138478716835e-05}, {"id": 183, "seek": 66804, "start": 668.04, "end": 673.92, "text": " And then, voila, you get the latest version, change log, depending on the situation.", "tokens": [400, 550, 11, 45565, 11, 291, 483, 264, 6792, 3037, 11, 1319, 3565, 11, 5413, 322, 264, 2590, 13], "temperature": 0.0, "avg_logprob": -0.2719323476155599, "compression_ratio": 1.4951456310679612, "no_speech_prob": 2.1990446839481592e-05}, {"id": 184, "seek": 66804, "start": 673.92, "end": 677.56, "text": " And based on that, you can just combine the projects.", "tokens": [400, 2361, 322, 300, 11, 291, 393, 445, 10432, 264, 4455, 13], "temperature": 0.0, "avg_logprob": -0.2719323476155599, "compression_ratio": 1.4951456310679612, "no_speech_prob": 2.1990446839481592e-05}, {"id": 185, "seek": 66804, "start": 677.56, "end": 684.16, "text": " And so we have a lot of different workflows where we automate things.", "tokens": [400, 370, 321, 362, 257, 688, 295, 819, 43461, 689, 321, 31605, 721, 13], "temperature": 0.0, "avg_logprob": -0.2719323476155599, "compression_ratio": 1.4951456310679612, "no_speech_prob": 2.1990446839481592e-05}, {"id": 186, "seek": 66804, "start": 684.16, "end": 687.7199999999999, "text": " The last thing, how many time do I have left?", "tokens": [440, 1036, 551, 11, 577, 867, 565, 360, 286, 362, 1411, 30], "temperature": 0.0, "avg_logprob": -0.2719323476155599, "compression_ratio": 1.4951456310679612, "no_speech_prob": 2.1990446839481592e-05}, {"id": 187, "seek": 66804, "start": 687.7199999999999, "end": 688.7199999999999, "text": " Five minutes?", "tokens": [9436, 2077, 30], "temperature": 0.0, "avg_logprob": -0.2719323476155599, "compression_ratio": 1.4951456310679612, "no_speech_prob": 2.1990446839481592e-05}, {"id": 188, "seek": 66804, "start": 688.7199999999999, "end": 689.7199999999999, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2719323476155599, "compression_ratio": 1.4951456310679612, "no_speech_prob": 2.1990446839481592e-05}, {"id": 189, "seek": 66804, "start": 689.7199999999999, "end": 690.7199999999999, "text": " Where is that?", "tokens": [2305, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.2719323476155599, "compression_ratio": 1.4951456310679612, "no_speech_prob": 2.1990446839481592e-05}, {"id": 190, "seek": 66804, "start": 690.7199999999999, "end": 691.7199999999999, "text": " It's not this one.", "tokens": [467, 311, 406, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.2719323476155599, "compression_ratio": 1.4951456310679612, "no_speech_prob": 2.1990446839481592e-05}, {"id": 191, "seek": 69172, "start": 691.72, "end": 706.72, "text": " So the thing that I was mentioning for monitoring the different versions, so this one is a different", "tokens": [407, 264, 551, 300, 286, 390, 18315, 337, 11028, 264, 819, 9606, 11, 370, 341, 472, 307, 257, 819], "temperature": 0.0, "avg_logprob": -0.21014641353062222, "compression_ratio": 1.7030303030303031, "no_speech_prob": 5.283652717480436e-05}, {"id": 192, "seek": 69172, "start": 706.72, "end": 711.88, "text": " way to see the problem is you want to monitor the version that you are using at some point.", "tokens": [636, 281, 536, 264, 1154, 307, 291, 528, 281, 6002, 264, 3037, 300, 291, 366, 1228, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.21014641353062222, "compression_ratio": 1.7030303030303031, "no_speech_prob": 5.283652717480436e-05}, {"id": 193, "seek": 69172, "start": 711.88, "end": 717.76, "text": " And so you want to compare, okay, in this case, on one location, I say I want to monitor", "tokens": [400, 370, 291, 528, 281, 6794, 11, 1392, 11, 294, 341, 1389, 11, 322, 472, 4914, 11, 286, 584, 286, 528, 281, 6002], "temperature": 0.0, "avg_logprob": -0.21014641353062222, "compression_ratio": 1.7030303030303031, "no_speech_prob": 5.283652717480436e-05}, {"id": 194, "seek": 71776, "start": 717.76, "end": 724.24, "text": " a version from the native file.tamiaml, so it gets me a version which is 0.1010.", "tokens": [257, 3037, 490, 264, 8470, 3991, 13, 83, 4526, 335, 75, 11, 370, 309, 2170, 385, 257, 3037, 597, 307, 1958, 13, 3279, 3279, 13], "temperature": 0.0, "avg_logprob": -0.2269718973260177, "compression_ratio": 1.5523809523809524, "no_speech_prob": 2.6417495973873883e-05}, {"id": 195, "seek": 71776, "start": 724.24, "end": 728.0, "text": " And on the other side, I want to compare with what's the latest code version.", "tokens": [400, 322, 264, 661, 1252, 11, 286, 528, 281, 6794, 365, 437, 311, 264, 6792, 3089, 3037, 13], "temperature": 0.0, "avg_logprob": -0.2269718973260177, "compression_ratio": 1.5523809523809524, "no_speech_prob": 2.6417495973873883e-05}, {"id": 196, "seek": 71776, "start": 728.0, "end": 734.4, "text": " And so if it does not match, then I know that I need to work on that at some point.", "tokens": [400, 370, 498, 309, 775, 406, 2995, 11, 550, 286, 458, 300, 286, 643, 281, 589, 322, 300, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.2269718973260177, "compression_ratio": 1.5523809523809524, "no_speech_prob": 2.6417495973873883e-05}, {"id": 197, "seek": 71776, "start": 734.4, "end": 746.48, "text": " And since I have a bit of a time, I can quickly show what the discovery looks like.", "tokens": [400, 1670, 286, 362, 257, 857, 295, 257, 565, 11, 286, 393, 2661, 855, 437, 264, 12114, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.2269718973260177, "compression_ratio": 1.5523809523809524, "no_speech_prob": 2.6417495973873883e-05}, {"id": 198, "seek": 74648, "start": 746.48, "end": 755.04, "text": " Yeah, the auto-discovery is a bit more difficult because you need to know in advance what you", "tokens": [865, 11, 264, 8399, 12, 67, 8610, 448, 307, 257, 857, 544, 2252, 570, 291, 643, 281, 458, 294, 7295, 437, 291], "temperature": 0.0, "avg_logprob": -0.2655585449520904, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00018109142547473311}, {"id": 199, "seek": 74648, "start": 755.04, "end": 760.32, "text": " want to do, but where is that thing?", "tokens": [528, 281, 360, 11, 457, 689, 307, 300, 551, 30], "temperature": 0.0, "avg_logprob": -0.2655585449520904, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00018109142547473311}, {"id": 200, "seek": 74648, "start": 760.32, "end": 763.16, "text": " Yeah, this way.", "tokens": [865, 11, 341, 636, 13], "temperature": 0.0, "avg_logprob": -0.2655585449520904, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00018109142547473311}, {"id": 201, "seek": 74648, "start": 763.16, "end": 767.32, "text": " As you can see, we don't have a lot of support at this time, so it's mainly around containers", "tokens": [1018, 291, 393, 536, 11, 321, 500, 380, 362, 257, 688, 295, 1406, 412, 341, 565, 11, 370, 309, 311, 8704, 926, 17089], "temperature": 0.0, "avg_logprob": -0.2655585449520904, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00018109142547473311}, {"id": 202, "seek": 74648, "start": 767.32, "end": 770.64, "text": " because I'm working on containers most of the time.", "tokens": [570, 286, 478, 1364, 322, 17089, 881, 295, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.2655585449520904, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00018109142547473311}, {"id": 203, "seek": 74648, "start": 770.64, "end": 773.32, "text": " But so it will pass the file, so in this case, it identifies.", "tokens": [583, 370, 309, 486, 1320, 264, 3991, 11, 370, 294, 341, 1389, 11, 309, 34597, 13], "temperature": 0.0, "avg_logprob": -0.2655585449520904, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00018109142547473311}, {"id": 204, "seek": 77332, "start": 773.32, "end": 778.0, "text": " It's a Rancher project where we have fleets, and then based on that, it will try to fetch", "tokens": [467, 311, 257, 37740, 260, 1716, 689, 321, 362, 7025, 1385, 11, 293, 550, 2361, 322, 300, 11, 309, 486, 853, 281, 23673], "temperature": 0.0, "avg_logprob": -0.32089966994065505, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.00016482436330989003}, {"id": 205, "seek": 77332, "start": 778.0, "end": 786.24, "text": " all the different versions specified in the fleet project, and it will suggest other versions.", "tokens": [439, 264, 819, 9606, 22206, 294, 264, 19396, 1716, 11, 293, 309, 486, 3402, 661, 9606, 13], "temperature": 0.0, "avg_logprob": -0.32089966994065505, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.00016482436330989003}, {"id": 206, "seek": 77332, "start": 786.24, "end": 790.44, "text": " So that's it for my presentation.", "tokens": [407, 300, 311, 309, 337, 452, 5860, 13], "temperature": 0.0, "avg_logprob": -0.32089966994065505, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.00016482436330989003}, {"id": 207, "seek": 77332, "start": 790.44, "end": 791.44, "text": " And...", "tokens": [400, 485], "temperature": 0.0, "avg_logprob": -0.32089966994065505, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.00016482436330989003}, {"id": 208, "seek": 77332, "start": 791.44, "end": 792.44, "text": " Voila.", "tokens": [7518, 7371, 13], "temperature": 0.0, "avg_logprob": -0.32089966994065505, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.00016482436330989003}, {"id": 209, "seek": 79244, "start": 792.44, "end": 806.48, "text": " Is there any questions?", "tokens": [1119, 456, 604, 1651, 30], "temperature": 0.0, "avg_logprob": -0.33286068803173, "compression_ratio": 1.3829787234042554, "no_speech_prob": 0.001102015608921647}, {"id": 210, "seek": 79244, "start": 806.48, "end": 807.48, "text": " One time, two times, yes.", "tokens": [1485, 565, 11, 732, 1413, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.33286068803173, "compression_ratio": 1.3829787234042554, "no_speech_prob": 0.001102015608921647}, {"id": 211, "seek": 79244, "start": 807.48, "end": 808.48, "text": " There is one over there.", "tokens": [821, 307, 472, 670, 456, 13], "temperature": 0.0, "avg_logprob": -0.33286068803173, "compression_ratio": 1.3829787234042554, "no_speech_prob": 0.001102015608921647}, {"id": 212, "seek": 79244, "start": 808.48, "end": 809.48, "text": " Hi there.", "tokens": [2421, 456, 13], "temperature": 0.0, "avg_logprob": -0.33286068803173, "compression_ratio": 1.3829787234042554, "no_speech_prob": 0.001102015608921647}, {"id": 213, "seek": 79244, "start": 809.48, "end": 810.48, "text": " Thanks for the presentation.", "tokens": [2561, 337, 264, 5860, 13], "temperature": 0.0, "avg_logprob": -0.33286068803173, "compression_ratio": 1.3829787234042554, "no_speech_prob": 0.001102015608921647}, {"id": 214, "seek": 79244, "start": 810.48, "end": 822.24, "text": " You were talking about what the Panda was, but you didn't mention about renovate.", "tokens": [509, 645, 1417, 466, 437, 264, 44207, 390, 11, 457, 291, 994, 380, 2152, 466, 18845, 473, 13], "temperature": 0.0, "avg_logprob": -0.33286068803173, "compression_ratio": 1.3829787234042554, "no_speech_prob": 0.001102015608921647}, {"id": 215, "seek": 82224, "start": 822.24, "end": 827.84, "text": " I wonder how much it overlaps with renovate, if it's a bit more customizable one.", "tokens": [286, 2441, 577, 709, 309, 15986, 2382, 365, 18845, 473, 11, 498, 309, 311, 257, 857, 544, 47922, 472, 13], "temperature": 0.0, "avg_logprob": -0.24475717544555664, "compression_ratio": 1.9015151515151516, "no_speech_prob": 0.001501579536125064}, {"id": 216, "seek": 82224, "start": 827.84, "end": 832.36, "text": " So the question, I mentioned the Panda, but I didn't mention that much renovate.", "tokens": [407, 264, 1168, 11, 286, 2835, 264, 44207, 11, 457, 286, 994, 380, 2152, 300, 709, 18845, 473, 13], "temperature": 0.0, "avg_logprob": -0.24475717544555664, "compression_ratio": 1.9015151515151516, "no_speech_prob": 0.001501579536125064}, {"id": 217, "seek": 82224, "start": 832.36, "end": 837.36, "text": " So if you compare the Panda, but the renovate is way better than the Panda, but because", "tokens": [407, 498, 291, 6794, 264, 44207, 11, 457, 264, 18845, 473, 307, 636, 1101, 813, 264, 44207, 11, 457, 570], "temperature": 0.0, "avg_logprob": -0.24475717544555664, "compression_ratio": 1.9015151515151516, "no_speech_prob": 0.001501579536125064}, {"id": 218, "seek": 82224, "start": 837.36, "end": 841.36, "text": " the Panda, but I didn't have the time to cover the domain.", "tokens": [264, 44207, 11, 457, 286, 994, 380, 362, 264, 565, 281, 2060, 264, 9274, 13], "temperature": 0.0, "avg_logprob": -0.24475717544555664, "compression_ratio": 1.9015151515151516, "no_speech_prob": 0.001501579536125064}, {"id": 219, "seek": 82224, "start": 841.36, "end": 844.6, "text": " There are a lot of things that I didn't have the time to cover, but for example, one of", "tokens": [821, 366, 257, 688, 295, 721, 300, 286, 994, 380, 362, 264, 565, 281, 2060, 11, 457, 337, 1365, 11, 472, 295], "temperature": 0.0, "avg_logprob": -0.24475717544555664, "compression_ratio": 1.9015151515151516, "no_speech_prob": 0.001501579536125064}, {"id": 220, "seek": 82224, "start": 844.6, "end": 848.4, "text": " the features that I really love in renovate, but is they allows you to group PRs which", "tokens": [264, 4122, 300, 286, 534, 959, 294, 18845, 473, 11, 457, 307, 436, 4045, 291, 281, 1594, 11568, 82, 597], "temperature": 0.0, "avg_logprob": -0.24475717544555664, "compression_ratio": 1.9015151515151516, "no_speech_prob": 0.001501579536125064}, {"id": 221, "seek": 82224, "start": 848.4, "end": 849.6, "text": " reduce the noise.", "tokens": [5407, 264, 5658, 13], "temperature": 0.0, "avg_logprob": -0.24475717544555664, "compression_ratio": 1.9015151515151516, "no_speech_prob": 0.001501579536125064}, {"id": 222, "seek": 84960, "start": 849.6, "end": 853.72, "text": " Because for example, the Panda bot, especially for those people maintaining JavaScript projects,", "tokens": [1436, 337, 1365, 11, 264, 44207, 10592, 11, 2318, 337, 729, 561, 14916, 15778, 4455, 11], "temperature": 0.0, "avg_logprob": -0.23303982638573462, "compression_ratio": 1.6357615894039734, "no_speech_prob": 0.0001622563722776249}, {"id": 223, "seek": 84960, "start": 853.72, "end": 857.72, "text": " the Panda bot can just open like 10, 20, 30 PRs, and then you have to review all of them", "tokens": [264, 44207, 10592, 393, 445, 1269, 411, 1266, 11, 945, 11, 2217, 11568, 82, 11, 293, 550, 291, 362, 281, 3131, 439, 295, 552], "temperature": 0.0, "avg_logprob": -0.23303982638573462, "compression_ratio": 1.6357615894039734, "no_speech_prob": 0.0001622563722776249}, {"id": 224, "seek": 84960, "start": 857.72, "end": 858.72, "text": " tests.", "tokens": [6921, 13], "temperature": 0.0, "avg_logprob": -0.23303982638573462, "compression_ratio": 1.6357615894039734, "no_speech_prob": 0.0001622563722776249}, {"id": 225, "seek": 84960, "start": 858.72, "end": 861.0, "text": " And so there are different strategies to update.", "tokens": [400, 370, 456, 366, 819, 9029, 281, 5623, 13], "temperature": 0.0, "avg_logprob": -0.23303982638573462, "compression_ratio": 1.6357615894039734, "no_speech_prob": 0.0001622563722776249}, {"id": 226, "seek": 84960, "start": 861.0, "end": 865.88, "text": " Renovate bot is just way better in the way that it supports more modules.", "tokens": [12883, 5179, 473, 10592, 307, 445, 636, 1101, 294, 264, 636, 300, 309, 9346, 544, 16679, 13], "temperature": 0.0, "avg_logprob": -0.23303982638573462, "compression_ratio": 1.6357615894039734, "no_speech_prob": 0.0001622563722776249}, {"id": 227, "seek": 84960, "start": 865.88, "end": 872.72, "text": " On the other side, it's not really easy in the case of renovate, but to have workflows", "tokens": [1282, 264, 661, 1252, 11, 309, 311, 406, 534, 1858, 294, 264, 1389, 295, 18845, 473, 11, 457, 281, 362, 43461], "temperature": 0.0, "avg_logprob": -0.23303982638573462, "compression_ratio": 1.6357615894039734, "no_speech_prob": 0.0001622563722776249}, {"id": 228, "seek": 84960, "start": 872.72, "end": 876.24, "text": " where you really want to say, okay, I'll fetch a version, I'll check a bunch of things, and", "tokens": [689, 291, 534, 528, 281, 584, 11, 1392, 11, 286, 603, 23673, 257, 3037, 11, 286, 603, 1520, 257, 3840, 295, 721, 11, 293], "temperature": 0.0, "avg_logprob": -0.23303982638573462, "compression_ratio": 1.6357615894039734, "no_speech_prob": 0.0001622563722776249}, {"id": 229, "seek": 87624, "start": 876.24, "end": 880.44, "text": " then I'll update other targets, basically.", "tokens": [550, 286, 603, 5623, 661, 12911, 11, 1936, 13], "temperature": 0.0, "avg_logprob": -0.3413947736713248, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.00012529057858046144}, {"id": 230, "seek": 87624, "start": 880.44, "end": 885.88, "text": " So I would say renovate bot is better in the autodiscovery part, where you can detect things", "tokens": [407, 286, 576, 584, 18845, 473, 10592, 307, 1101, 294, 264, 1476, 378, 8610, 448, 644, 11, 689, 291, 393, 5531, 721], "temperature": 0.0, "avg_logprob": -0.3413947736713248, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.00012529057858046144}, {"id": 231, "seek": 87624, "start": 885.88, "end": 886.88, "text": " for you.", "tokens": [337, 291, 13], "temperature": 0.0, "avg_logprob": -0.3413947736713248, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.00012529057858046144}, {"id": 232, "seek": 87624, "start": 886.88, "end": 896.36, "text": " But on the other side, it's not really easy to have like very complex updates in areas.", "tokens": [583, 322, 264, 661, 1252, 11, 309, 311, 406, 534, 1858, 281, 362, 411, 588, 3997, 9205, 294, 3179, 13], "temperature": 0.0, "avg_logprob": -0.3413947736713248, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.00012529057858046144}, {"id": 233, "seek": 87624, "start": 896.36, "end": 901.96, "text": " And that's it.", "tokens": [400, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.3413947736713248, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.00012529057858046144}, {"id": 234, "seek": 90196, "start": 901.96, "end": 906.52, "text": " So Charles, the floor, thank you.", "tokens": [50364, 407, 10523, 11, 264, 4123, 11, 1309, 291, 13, 50592], "temperature": 0.0, "avg_logprob": -0.7323119640350342, "compression_ratio": 0.868421052631579, "no_speech_prob": 0.0007718768902122974}], "language": "en"}