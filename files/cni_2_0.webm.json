{"text": " Awesome, thanks everybody for joining me to chat about CNI 2.0. My name's Doug. I work in a variety of areas with Kubernetes networking primarily, but to scale the conversation, I wanted to see a show of hands of who knows what CNI is. All right, that's pretty good. And for everyone else, it is the container networking interface. And really what I think most people know CNI for is it's a plug-in that you use to get your network plumbed in Kubernetes. So it's going to define how your pods are going to talk to one another. But there's kind of an underlying part of CNI that I'm not sure everybody realizes is that it is COE agnostic. Who knows what a COE is? Not as many people. Well, I have a junior engineer on my team, and he was asking me some questions about it. And I said, I can't do that, because it's COE agnostic, and he goes, what's a COE? And I said, well, it's a container orchestration engine. And he's like, well, what's a container orchestration engine? Well, I'm wondering if anyone can name one container orchestration engine. Kubernetes, yeah, totally. And really, we just kind of talk about Kubernetes, right, because who can name two of these? That's Kubernetes. Well, it's an opinionated Kubernetes, for sure. But it's still Kubernetes under the hood. So yeah, there you go. So now we know who's been around this area for a long time, because we used to have to talk about these generically, like we were going to have a bunch of them. But Kubernetes won. And CNI is container orchestration agnostic. Well, does it need to be anymore? I really, I'm not sure about that. So I wanted to bring up that we love CNI. It's great. It's really modular. It allows us to have an interface that we use to be able to do the detailed kind of work that we need to do as people who care about networking in Kubernetes. We want to get in there, and we want to have this interface to say, this is how I want to set up networking in Kubernetes. And really, something that's kind of happening because it's container orchestration agnostic is that people might not actually use it anymore. They're thinking about Kubernetes, and they don't care that it's container orchestration agnostic. And they really want to have a deeper integration, and they're ignoring this. They want to do everything with Kubernetes, and they don't want to just say, oh, well, since it's container orchestration agnostic, CNI doesn't do anything with Kubernetes. And so people are starting to ignore CNI. This is really bad for our space. It's what it's doing is it's basically people are saying, I'm going to totally bypass this API. I'm just going to do everything in Kubernetes. I'm just going to set up my networking however I want. If you're somebody that has to go and administer these systems, or you're somebody who has to develop on these systems, you're going to have to track down all of these things that somebody else did that didn't follow this standard. I think it's really bad for our ecosystem. So I'm kind of on a warpath here to let people know this is happening. I'm not going to call out any names, but there's plenty of providers that have Kubernetes as a service or as something that you buy and you install out of the box. And they're like, oh, well, you don't need to worry about this. We've taken care of it for you. And I'd love to believe that you don't have to worry about this anymore. I've been working in production systems, in operations, as a developer of these kind of things. And I realized that the world is kind of a dirtier place than that. There's always going to be stuff that you want to get in there. And when you are using this pure upstream Kubernetes, you want the detail to get in and to figure out how this stuff works. I don't want to have to take apart somebody else's science experiment. And the reason people are doing this is because they want a tighter integration with Kubernetes. So CNI plugins are binaries. They run on disk. They're called by your container runtime. And they execute these binaries on disk. So for example, junior engineer on my team, we deal with CNI plugins all day, long day and day out. And he's looking at these other teams. And they're working on Kubernetes operators, all this stuff that integrates tightly with Kubernetes. And he's like, look at all these awesome tools that they have to interactively debug their programs. And if I want to do that with a CNI plugin that's not really running in Kubernetes because it's container agnostic, well, I can see why. Some Kubernetes distributors are saying, I'll just ignore it and just do this another way because I can get a tighter Kubernetes integration if I just bypass CNI. I am a maintainer of something called Multis CNI. And what it's used for is having multiple interfaces in a pod in Kubernetes. So if you're doing something that's more of a high-powered networking kind of stuff where you want to have isolation of networks, so a classic thing would be control and media on separate networks and you want to divide traffic so that that's isolated. That's the kind of thing you would use Multis for. And Multis is Kubernetes-aware, and it's CNI-aware. And it's designed to have multiple, to give you these multiple network interfaces. But because it's Kubernetes-aware and it's CNI-aware, people are trying to use it as kind of a CNI runtime. And that's not what it is. And kind of as this, so today we have CNI 1.0, CNI 2.0 is on the horizon. And as this conversation came up, and I'm seeing more people in my community coming to me like, hey, I want Multis CNI to do this thing that's in the CNI spec. And I mean, I want to make it work as well as I can to fit everyone's use cases, but I'm really starting to realize, hey, we need to get this kind of functionality into CNI itself and to use CNI in a way that really has this Kubernetes-awareness. So I'm really trying to invite everyone to get involved and to make sure that CNI and Kubernetes are kind of like a happy family together. And I think that we've got like a strong opportunity here. I'm sure if anyone saw the previous lightning talk, which was about YAML, but kind of a weird thing between Kubernetes and CNI is that if you are specifying like workloads and resources, et cetera, your pod specs in Kubernetes, you're using YAML, which has its problems as you saw in the last talk, but CNI itself uses JSON. So when you're trying to sort of marry these two worlds together, you have this kind of problem, especially in my space with Multis where you're kind of multiplexing CNI plugins to get these multiple interfaces. So you're taking YAML that's in Kubernetes and then you're packing JSON into those specs and it's kind of dirty in its own way. So that's like one of those things I'd like to see happen better. And I think it's really awkward for when you're trying to like programmatically interact with this stuff. So sure, as a user, you specify your YAML, you pack some JSON in it, no big deal. But if you're writing an application that parses that YAML, it also has to parse the JSON inside it, which is worse. So I want everyone to have the CNI 2.0 revolution live long and strong. And so I'm trying to get everyone to get involved. And this is a space that I can invite you to that is a working group that I know and love, the Kubernetes network planning working group. We meet every other Thursday in a time that's supposed to be the most friendly for Asia, Europe and the US. And we will be discussing this until it's solved. And we're going to take these considerations up with the CNI community as well. And I'd love to see any faces join and we can keep rocking and rolling on this. So thank you. And yeah, floor is open for any questions. So the question is the given by Casey Calandrello from Red Hat, no longer at Red Hat. A couple Q-cons ago, there's about CNI 2.0. And yes, this is a related effort. And I think that what Casey was talking about at the time was so one of the problems that I mentioned was you've got these CNI plugins, they're binaries on disk, wouldn't it be better if, say, they were containerized? And that was something that Casey was talking about is that we'd like to see CNI plugins be containerized instead of binaries on disk. They're going to be more familiar to folks that work on Kubernetes applications. He was also talking about getting a GRPC interface. But I think that this is kind of a newer thought process. And I don't want to put words in Casey's mouth. So I won't. But I have a feeling that he is also on board. And for those of you who don't know, Casey Calandrello is the originator of CNI and is also an awesome guy. So yeah, so related. Go for it. OK, so in that talk, he was talking most about CNI would be more like a more complete life cycle meant for networks and all of that. And at the same time, but now there is an activity to create like a proper API for networks. So how is this to make a happy marriage? So the question is, and it's a great one. And so one thing that was talked about in that presentation was the idea of a more complete life cycle management. And there is also concurrently an effort happening now that is to define a networks object for Kubernetes, so a data representation of networks. So this is a complex two part question and I have 90 seconds for it, but I love it. So yes, also, so second part first, there is an effort that is called I call it Kubernetes native multi networking. If you join the SIG network call, you can find out all the connection or information about it. Very interesting effort. And as I mentioned, multi CNI does multi networking stuff. That's awesome. And that particular conversation is to me bringing up lots of questions about what CNI 2.0 is going to look like. And for the first part of the question, which is richer life cycle management of networking in containers is so something about CNI is that it primarily functions on container creation and container deletion. There's some exceptions to this, but primarily so CNI add is a command happens when your container is created, your CNI plug in kicks off, does its work, goes to sleep dies. And then delete when your container is deleted, it tears it down and cleans it up. However, networking can still happen between those two to 10 points, right? So things happen, things change IPv6. You could have Slack happening and auto assign routing and IPs. And that's it. So we want to fix that too. So thank you very much. Appreciate it. Thanks for the question.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.200000000000001, "text": " Awesome, thanks everybody for joining me to chat about CNI 2.0.", "tokens": [50364, 10391, 11, 3231, 2201, 337, 5549, 385, 281, 5081, 466, 14589, 40, 568, 13, 15, 13, 51074], "temperature": 0.0, "avg_logprob": -0.2118324523276471, "compression_ratio": 1.2291666666666667, "no_speech_prob": 0.09366078674793243}, {"id": 1, "seek": 0, "start": 14.200000000000001, "end": 15.200000000000001, "text": " My name's Doug.", "tokens": [51074, 1222, 1315, 311, 12742, 13, 51124], "temperature": 0.0, "avg_logprob": -0.2118324523276471, "compression_ratio": 1.2291666666666667, "no_speech_prob": 0.09366078674793243}, {"id": 2, "seek": 0, "start": 15.200000000000001, "end": 24.560000000000002, "text": " I work in a variety of areas with Kubernetes networking primarily, but to scale the conversation,", "tokens": [51124, 286, 589, 294, 257, 5673, 295, 3179, 365, 23145, 17985, 10029, 11, 457, 281, 4373, 264, 3761, 11, 51592], "temperature": 0.0, "avg_logprob": -0.2118324523276471, "compression_ratio": 1.2291666666666667, "no_speech_prob": 0.09366078674793243}, {"id": 3, "seek": 2456, "start": 24.56, "end": 29.32, "text": " I wanted to see a show of hands of who knows what CNI is.", "tokens": [50364, 286, 1415, 281, 536, 257, 855, 295, 2377, 295, 567, 3255, 437, 14589, 40, 307, 13, 50602], "temperature": 0.0, "avg_logprob": -0.19549762146382393, "compression_ratio": 1.4680851063829787, "no_speech_prob": 0.024785224348306656}, {"id": 4, "seek": 2456, "start": 29.32, "end": 32.04, "text": " All right, that's pretty good.", "tokens": [50602, 1057, 558, 11, 300, 311, 1238, 665, 13, 50738], "temperature": 0.0, "avg_logprob": -0.19549762146382393, "compression_ratio": 1.4680851063829787, "no_speech_prob": 0.024785224348306656}, {"id": 5, "seek": 2456, "start": 32.04, "end": 36.84, "text": " And for everyone else, it is the container networking interface.", "tokens": [50738, 400, 337, 1518, 1646, 11, 309, 307, 264, 10129, 17985, 9226, 13, 50978], "temperature": 0.0, "avg_logprob": -0.19549762146382393, "compression_ratio": 1.4680851063829787, "no_speech_prob": 0.024785224348306656}, {"id": 6, "seek": 2456, "start": 36.84, "end": 47.44, "text": " And really what I think most people know CNI for is it's a plug-in that you use to get", "tokens": [50978, 400, 534, 437, 286, 519, 881, 561, 458, 14589, 40, 337, 307, 309, 311, 257, 5452, 12, 259, 300, 291, 764, 281, 483, 51508], "temperature": 0.0, "avg_logprob": -0.19549762146382393, "compression_ratio": 1.4680851063829787, "no_speech_prob": 0.024785224348306656}, {"id": 7, "seek": 2456, "start": 47.44, "end": 50.08, "text": " your network plumbed in Kubernetes.", "tokens": [51508, 428, 3209, 499, 2860, 292, 294, 23145, 13, 51640], "temperature": 0.0, "avg_logprob": -0.19549762146382393, "compression_ratio": 1.4680851063829787, "no_speech_prob": 0.024785224348306656}, {"id": 8, "seek": 5008, "start": 50.08, "end": 55.0, "text": " So it's going to define how your pods are going to talk to one another.", "tokens": [50364, 407, 309, 311, 516, 281, 6964, 577, 428, 31925, 366, 516, 281, 751, 281, 472, 1071, 13, 50610], "temperature": 0.0, "avg_logprob": -0.15900375968531558, "compression_ratio": 1.4429223744292237, "no_speech_prob": 0.012817755341529846}, {"id": 9, "seek": 5008, "start": 55.0, "end": 62.44, "text": " But there's kind of an underlying part of CNI that I'm not sure everybody realizes", "tokens": [50610, 583, 456, 311, 733, 295, 364, 14217, 644, 295, 14589, 40, 300, 286, 478, 406, 988, 2201, 29316, 50982], "temperature": 0.0, "avg_logprob": -0.15900375968531558, "compression_ratio": 1.4429223744292237, "no_speech_prob": 0.012817755341529846}, {"id": 10, "seek": 5008, "start": 62.44, "end": 66.0, "text": " is that it is COE agnostic.", "tokens": [50982, 307, 300, 309, 307, 3002, 36, 623, 77, 19634, 13, 51160], "temperature": 0.0, "avg_logprob": -0.15900375968531558, "compression_ratio": 1.4429223744292237, "no_speech_prob": 0.012817755341529846}, {"id": 11, "seek": 5008, "start": 66.0, "end": 70.44, "text": " Who knows what a COE is?", "tokens": [51160, 2102, 3255, 437, 257, 3002, 36, 307, 30, 51382], "temperature": 0.0, "avg_logprob": -0.15900375968531558, "compression_ratio": 1.4429223744292237, "no_speech_prob": 0.012817755341529846}, {"id": 12, "seek": 5008, "start": 70.44, "end": 71.6, "text": " Not as many people.", "tokens": [51382, 1726, 382, 867, 561, 13, 51440], "temperature": 0.0, "avg_logprob": -0.15900375968531558, "compression_ratio": 1.4429223744292237, "no_speech_prob": 0.012817755341529846}, {"id": 13, "seek": 5008, "start": 71.6, "end": 77.12, "text": " Well, I have a junior engineer on my team, and he was asking me some questions about", "tokens": [51440, 1042, 11, 286, 362, 257, 16195, 11403, 322, 452, 1469, 11, 293, 415, 390, 3365, 385, 512, 1651, 466, 51716], "temperature": 0.0, "avg_logprob": -0.15900375968531558, "compression_ratio": 1.4429223744292237, "no_speech_prob": 0.012817755341529846}, {"id": 14, "seek": 5008, "start": 77.12, "end": 78.12, "text": " it.", "tokens": [51716, 309, 13, 51766], "temperature": 0.0, "avg_logprob": -0.15900375968531558, "compression_ratio": 1.4429223744292237, "no_speech_prob": 0.012817755341529846}, {"id": 15, "seek": 7812, "start": 78.12, "end": 83.48, "text": " And I said, I can't do that, because it's COE agnostic, and he goes, what's a COE?", "tokens": [50364, 400, 286, 848, 11, 286, 393, 380, 360, 300, 11, 570, 309, 311, 3002, 36, 623, 77, 19634, 11, 293, 415, 1709, 11, 437, 311, 257, 3002, 36, 30, 50632], "temperature": 0.0, "avg_logprob": -0.25390628346225674, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.023681728169322014}, {"id": 16, "seek": 7812, "start": 83.48, "end": 87.76, "text": " And I said, well, it's a container orchestration engine.", "tokens": [50632, 400, 286, 848, 11, 731, 11, 309, 311, 257, 10129, 14161, 2405, 2848, 13, 50846], "temperature": 0.0, "avg_logprob": -0.25390628346225674, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.023681728169322014}, {"id": 17, "seek": 7812, "start": 87.76, "end": 91.28, "text": " And he's like, well, what's a container orchestration engine?", "tokens": [50846, 400, 415, 311, 411, 11, 731, 11, 437, 311, 257, 10129, 14161, 2405, 2848, 30, 51022], "temperature": 0.0, "avg_logprob": -0.25390628346225674, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.023681728169322014}, {"id": 18, "seek": 7812, "start": 91.28, "end": 97.48, "text": " Well, I'm wondering if anyone can name one container orchestration engine.", "tokens": [51022, 1042, 11, 286, 478, 6359, 498, 2878, 393, 1315, 472, 10129, 14161, 2405, 2848, 13, 51332], "temperature": 0.0, "avg_logprob": -0.25390628346225674, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.023681728169322014}, {"id": 19, "seek": 7812, "start": 97.48, "end": 102.36000000000001, "text": " Kubernetes, yeah, totally.", "tokens": [51332, 23145, 11, 1338, 11, 3879, 13, 51576], "temperature": 0.0, "avg_logprob": -0.25390628346225674, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.023681728169322014}, {"id": 20, "seek": 7812, "start": 102.36000000000001, "end": 108.08000000000001, "text": " And really, we just kind of talk about Kubernetes, right, because who can name two of these?", "tokens": [51576, 400, 534, 11, 321, 445, 733, 295, 751, 466, 23145, 11, 558, 11, 570, 567, 393, 1315, 732, 295, 613, 30, 51862], "temperature": 0.0, "avg_logprob": -0.25390628346225674, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.023681728169322014}, {"id": 21, "seek": 10808, "start": 109.03999999999999, "end": 111.32, "text": " That's Kubernetes.", "tokens": [50412, 663, 311, 23145, 13, 50526], "temperature": 0.0, "avg_logprob": -0.24190678066677518, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.001987601863220334}, {"id": 22, "seek": 10808, "start": 111.32, "end": 115.24, "text": " Well, it's an opinionated Kubernetes, for sure.", "tokens": [50526, 1042, 11, 309, 311, 364, 4800, 770, 23145, 11, 337, 988, 13, 50722], "temperature": 0.0, "avg_logprob": -0.24190678066677518, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.001987601863220334}, {"id": 23, "seek": 10808, "start": 115.24, "end": 119.12, "text": " But it's still Kubernetes under the hood.", "tokens": [50722, 583, 309, 311, 920, 23145, 833, 264, 13376, 13, 50916], "temperature": 0.0, "avg_logprob": -0.24190678066677518, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.001987601863220334}, {"id": 24, "seek": 10808, "start": 119.12, "end": 121.16, "text": " So yeah, there you go.", "tokens": [50916, 407, 1338, 11, 456, 291, 352, 13, 51018], "temperature": 0.0, "avg_logprob": -0.24190678066677518, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.001987601863220334}, {"id": 25, "seek": 10808, "start": 121.16, "end": 126.4, "text": " So now we know who's been around this area for a long time, because we used to have to", "tokens": [51018, 407, 586, 321, 458, 567, 311, 668, 926, 341, 1859, 337, 257, 938, 565, 11, 570, 321, 1143, 281, 362, 281, 51280], "temperature": 0.0, "avg_logprob": -0.24190678066677518, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.001987601863220334}, {"id": 26, "seek": 10808, "start": 126.4, "end": 132.36, "text": " talk about these generically, like we were going to have a bunch of them.", "tokens": [51280, 751, 466, 613, 1337, 984, 11, 411, 321, 645, 516, 281, 362, 257, 3840, 295, 552, 13, 51578], "temperature": 0.0, "avg_logprob": -0.24190678066677518, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.001987601863220334}, {"id": 27, "seek": 10808, "start": 132.36, "end": 135.0, "text": " But Kubernetes won.", "tokens": [51578, 583, 23145, 1582, 13, 51710], "temperature": 0.0, "avg_logprob": -0.24190678066677518, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.001987601863220334}, {"id": 28, "seek": 13500, "start": 135.0, "end": 139.28, "text": " And CNI is container orchestration agnostic.", "tokens": [50364, 400, 14589, 40, 307, 10129, 14161, 2405, 623, 77, 19634, 13, 50578], "temperature": 0.0, "avg_logprob": -0.16460389104382744, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.00023780394985806197}, {"id": 29, "seek": 13500, "start": 139.28, "end": 142.52, "text": " Well, does it need to be anymore?", "tokens": [50578, 1042, 11, 775, 309, 643, 281, 312, 3602, 30, 50740], "temperature": 0.0, "avg_logprob": -0.16460389104382744, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.00023780394985806197}, {"id": 30, "seek": 13500, "start": 142.52, "end": 145.64, "text": " I really, I'm not sure about that.", "tokens": [50740, 286, 534, 11, 286, 478, 406, 988, 466, 300, 13, 50896], "temperature": 0.0, "avg_logprob": -0.16460389104382744, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.00023780394985806197}, {"id": 31, "seek": 13500, "start": 145.64, "end": 150.76, "text": " So I wanted to bring up that we love CNI.", "tokens": [50896, 407, 286, 1415, 281, 1565, 493, 300, 321, 959, 14589, 40, 13, 51152], "temperature": 0.0, "avg_logprob": -0.16460389104382744, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.00023780394985806197}, {"id": 32, "seek": 13500, "start": 150.76, "end": 151.76, "text": " It's great.", "tokens": [51152, 467, 311, 869, 13, 51202], "temperature": 0.0, "avg_logprob": -0.16460389104382744, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.00023780394985806197}, {"id": 33, "seek": 13500, "start": 151.76, "end": 153.2, "text": " It's really modular.", "tokens": [51202, 467, 311, 534, 31111, 13, 51274], "temperature": 0.0, "avg_logprob": -0.16460389104382744, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.00023780394985806197}, {"id": 34, "seek": 13500, "start": 153.2, "end": 160.32, "text": " It allows us to have an interface that we use to be able to do the detailed kind of work", "tokens": [51274, 467, 4045, 505, 281, 362, 364, 9226, 300, 321, 764, 281, 312, 1075, 281, 360, 264, 9942, 733, 295, 589, 51630], "temperature": 0.0, "avg_logprob": -0.16460389104382744, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.00023780394985806197}, {"id": 35, "seek": 16032, "start": 160.32, "end": 166.48, "text": " that we need to do as people who care about networking in Kubernetes.", "tokens": [50364, 300, 321, 643, 281, 360, 382, 561, 567, 1127, 466, 17985, 294, 23145, 13, 50672], "temperature": 0.0, "avg_logprob": -0.11833969975861025, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.003375984262675047}, {"id": 36, "seek": 16032, "start": 166.48, "end": 171.51999999999998, "text": " We want to get in there, and we want to have this interface to say, this is how I want", "tokens": [50672, 492, 528, 281, 483, 294, 456, 11, 293, 321, 528, 281, 362, 341, 9226, 281, 584, 11, 341, 307, 577, 286, 528, 50924], "temperature": 0.0, "avg_logprob": -0.11833969975861025, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.003375984262675047}, {"id": 37, "seek": 16032, "start": 171.51999999999998, "end": 176.64, "text": " to set up networking in Kubernetes.", "tokens": [50924, 281, 992, 493, 17985, 294, 23145, 13, 51180], "temperature": 0.0, "avg_logprob": -0.11833969975861025, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.003375984262675047}, {"id": 38, "seek": 16032, "start": 176.64, "end": 183.84, "text": " And really, something that's kind of happening because it's container orchestration agnostic", "tokens": [51180, 400, 534, 11, 746, 300, 311, 733, 295, 2737, 570, 309, 311, 10129, 14161, 2405, 623, 77, 19634, 51540], "temperature": 0.0, "avg_logprob": -0.11833969975861025, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.003375984262675047}, {"id": 39, "seek": 18384, "start": 183.84, "end": 191.76, "text": " is that people might not actually use it anymore.", "tokens": [50364, 307, 300, 561, 1062, 406, 767, 764, 309, 3602, 13, 50760], "temperature": 0.0, "avg_logprob": -0.1319989800453186, "compression_ratio": 1.6648936170212767, "no_speech_prob": 0.004754755180329084}, {"id": 40, "seek": 18384, "start": 191.76, "end": 196.44, "text": " They're thinking about Kubernetes, and they don't care that it's container orchestration", "tokens": [50760, 814, 434, 1953, 466, 23145, 11, 293, 436, 500, 380, 1127, 300, 309, 311, 10129, 14161, 2405, 50994], "temperature": 0.0, "avg_logprob": -0.1319989800453186, "compression_ratio": 1.6648936170212767, "no_speech_prob": 0.004754755180329084}, {"id": 41, "seek": 18384, "start": 196.44, "end": 198.28, "text": " agnostic.", "tokens": [50994, 623, 77, 19634, 13, 51086], "temperature": 0.0, "avg_logprob": -0.1319989800453186, "compression_ratio": 1.6648936170212767, "no_speech_prob": 0.004754755180329084}, {"id": 42, "seek": 18384, "start": 198.28, "end": 205.28, "text": " And they really want to have a deeper integration, and they're ignoring this.", "tokens": [51086, 400, 436, 534, 528, 281, 362, 257, 7731, 10980, 11, 293, 436, 434, 26258, 341, 13, 51436], "temperature": 0.0, "avg_logprob": -0.1319989800453186, "compression_ratio": 1.6648936170212767, "no_speech_prob": 0.004754755180329084}, {"id": 43, "seek": 18384, "start": 205.28, "end": 212.64000000000001, "text": " They want to do everything with Kubernetes, and they don't want to just say, oh, well,", "tokens": [51436, 814, 528, 281, 360, 1203, 365, 23145, 11, 293, 436, 500, 380, 528, 281, 445, 584, 11, 1954, 11, 731, 11, 51804], "temperature": 0.0, "avg_logprob": -0.1319989800453186, "compression_ratio": 1.6648936170212767, "no_speech_prob": 0.004754755180329084}, {"id": 44, "seek": 21264, "start": 212.64, "end": 218.76, "text": " since it's container orchestration agnostic, CNI doesn't do anything with Kubernetes.", "tokens": [50364, 1670, 309, 311, 10129, 14161, 2405, 623, 77, 19634, 11, 14589, 40, 1177, 380, 360, 1340, 365, 23145, 13, 50670], "temperature": 0.0, "avg_logprob": -0.158104116266424, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.005384138319641352}, {"id": 45, "seek": 21264, "start": 218.76, "end": 222.6, "text": " And so people are starting to ignore CNI.", "tokens": [50670, 400, 370, 561, 366, 2891, 281, 11200, 14589, 40, 13, 50862], "temperature": 0.0, "avg_logprob": -0.158104116266424, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.005384138319641352}, {"id": 46, "seek": 21264, "start": 222.6, "end": 226.79999999999998, "text": " This is really bad for our space.", "tokens": [50862, 639, 307, 534, 1578, 337, 527, 1901, 13, 51072], "temperature": 0.0, "avg_logprob": -0.158104116266424, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.005384138319641352}, {"id": 47, "seek": 21264, "start": 226.79999999999998, "end": 232.51999999999998, "text": " It's what it's doing is it's basically people are saying, I'm going to totally bypass this", "tokens": [51072, 467, 311, 437, 309, 311, 884, 307, 309, 311, 1936, 561, 366, 1566, 11, 286, 478, 516, 281, 3879, 24996, 341, 51358], "temperature": 0.0, "avg_logprob": -0.158104116266424, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.005384138319641352}, {"id": 48, "seek": 21264, "start": 232.51999999999998, "end": 233.51999999999998, "text": " API.", "tokens": [51358, 9362, 13, 51408], "temperature": 0.0, "avg_logprob": -0.158104116266424, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.005384138319641352}, {"id": 49, "seek": 21264, "start": 233.51999999999998, "end": 236.83999999999997, "text": " I'm just going to do everything in Kubernetes.", "tokens": [51408, 286, 478, 445, 516, 281, 360, 1203, 294, 23145, 13, 51574], "temperature": 0.0, "avg_logprob": -0.158104116266424, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.005384138319641352}, {"id": 50, "seek": 21264, "start": 236.83999999999997, "end": 241.0, "text": " I'm just going to set up my networking however I want.", "tokens": [51574, 286, 478, 445, 516, 281, 992, 493, 452, 17985, 4461, 286, 528, 13, 51782], "temperature": 0.0, "avg_logprob": -0.158104116266424, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.005384138319641352}, {"id": 51, "seek": 24100, "start": 241.48, "end": 245.6, "text": " If you're somebody that has to go and administer these systems, or you're somebody who has", "tokens": [50388, 759, 291, 434, 2618, 300, 575, 281, 352, 293, 22096, 613, 3652, 11, 420, 291, 434, 2618, 567, 575, 50594], "temperature": 0.0, "avg_logprob": -0.09918293085965244, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.017432384192943573}, {"id": 52, "seek": 24100, "start": 245.6, "end": 252.04, "text": " to develop on these systems, you're going to have to track down all of these things", "tokens": [50594, 281, 1499, 322, 613, 3652, 11, 291, 434, 516, 281, 362, 281, 2837, 760, 439, 295, 613, 721, 50916], "temperature": 0.0, "avg_logprob": -0.09918293085965244, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.017432384192943573}, {"id": 53, "seek": 24100, "start": 252.04, "end": 256.68, "text": " that somebody else did that didn't follow this standard.", "tokens": [50916, 300, 2618, 1646, 630, 300, 994, 380, 1524, 341, 3832, 13, 51148], "temperature": 0.0, "avg_logprob": -0.09918293085965244, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.017432384192943573}, {"id": 54, "seek": 24100, "start": 256.68, "end": 259.32, "text": " I think it's really bad for our ecosystem.", "tokens": [51148, 286, 519, 309, 311, 534, 1578, 337, 527, 11311, 13, 51280], "temperature": 0.0, "avg_logprob": -0.09918293085965244, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.017432384192943573}, {"id": 55, "seek": 24100, "start": 259.32, "end": 265.44, "text": " So I'm kind of on a warpath here to let people know this is happening.", "tokens": [51280, 407, 286, 478, 733, 295, 322, 257, 1516, 31852, 510, 281, 718, 561, 458, 341, 307, 2737, 13, 51586], "temperature": 0.0, "avg_logprob": -0.09918293085965244, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.017432384192943573}, {"id": 56, "seek": 26544, "start": 265.44, "end": 272.16, "text": " I'm not going to call out any names, but there's plenty of providers that have Kubernetes", "tokens": [50364, 286, 478, 406, 516, 281, 818, 484, 604, 5288, 11, 457, 456, 311, 7140, 295, 11330, 300, 362, 23145, 50700], "temperature": 0.0, "avg_logprob": -0.1258678332619045, "compression_ratio": 1.6116504854368932, "no_speech_prob": 0.005383969750255346}, {"id": 57, "seek": 26544, "start": 272.16, "end": 278.0, "text": " as a service or as something that you buy and you install out of the box.", "tokens": [50700, 382, 257, 2643, 420, 382, 746, 300, 291, 2256, 293, 291, 3625, 484, 295, 264, 2424, 13, 50992], "temperature": 0.0, "avg_logprob": -0.1258678332619045, "compression_ratio": 1.6116504854368932, "no_speech_prob": 0.005383969750255346}, {"id": 58, "seek": 26544, "start": 278.0, "end": 281.68, "text": " And they're like, oh, well, you don't need to worry about this.", "tokens": [50992, 400, 436, 434, 411, 11, 1954, 11, 731, 11, 291, 500, 380, 643, 281, 3292, 466, 341, 13, 51176], "temperature": 0.0, "avg_logprob": -0.1258678332619045, "compression_ratio": 1.6116504854368932, "no_speech_prob": 0.005383969750255346}, {"id": 59, "seek": 26544, "start": 281.68, "end": 284.24, "text": " We've taken care of it for you.", "tokens": [51176, 492, 600, 2726, 1127, 295, 309, 337, 291, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1258678332619045, "compression_ratio": 1.6116504854368932, "no_speech_prob": 0.005383969750255346}, {"id": 60, "seek": 26544, "start": 284.24, "end": 290.4, "text": " And I'd love to believe that you don't have to worry about this anymore.", "tokens": [51304, 400, 286, 1116, 959, 281, 1697, 300, 291, 500, 380, 362, 281, 3292, 466, 341, 3602, 13, 51612], "temperature": 0.0, "avg_logprob": -0.1258678332619045, "compression_ratio": 1.6116504854368932, "no_speech_prob": 0.005383969750255346}, {"id": 61, "seek": 29040, "start": 290.67999999999995, "end": 296.84, "text": " I've been working in production systems, in operations, as a developer of these kind", "tokens": [50378, 286, 600, 668, 1364, 294, 4265, 3652, 11, 294, 7705, 11, 382, 257, 10754, 295, 613, 733, 50686], "temperature": 0.0, "avg_logprob": -0.14612685193072308, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.009410948492586613}, {"id": 62, "seek": 29040, "start": 296.84, "end": 298.15999999999997, "text": " of things.", "tokens": [50686, 295, 721, 13, 50752], "temperature": 0.0, "avg_logprob": -0.14612685193072308, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.009410948492586613}, {"id": 63, "seek": 29040, "start": 298.15999999999997, "end": 302.52, "text": " And I realized that the world is kind of a dirtier place than that.", "tokens": [50752, 400, 286, 5334, 300, 264, 1002, 307, 733, 295, 257, 11483, 811, 1081, 813, 300, 13, 50970], "temperature": 0.0, "avg_logprob": -0.14612685193072308, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.009410948492586613}, {"id": 64, "seek": 29040, "start": 302.52, "end": 305.47999999999996, "text": " There's always going to be stuff that you want to get in there.", "tokens": [50970, 821, 311, 1009, 516, 281, 312, 1507, 300, 291, 528, 281, 483, 294, 456, 13, 51118], "temperature": 0.0, "avg_logprob": -0.14612685193072308, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.009410948492586613}, {"id": 65, "seek": 29040, "start": 305.47999999999996, "end": 312.88, "text": " And when you are using this pure upstream Kubernetes, you want the detail to get in", "tokens": [51118, 400, 562, 291, 366, 1228, 341, 6075, 33915, 23145, 11, 291, 528, 264, 2607, 281, 483, 294, 51488], "temperature": 0.0, "avg_logprob": -0.14612685193072308, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.009410948492586613}, {"id": 66, "seek": 29040, "start": 312.88, "end": 316.35999999999996, "text": " and to figure out how this stuff works.", "tokens": [51488, 293, 281, 2573, 484, 577, 341, 1507, 1985, 13, 51662], "temperature": 0.0, "avg_logprob": -0.14612685193072308, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.009410948492586613}, {"id": 67, "seek": 31636, "start": 316.36, "end": 322.28000000000003, "text": " I don't want to have to take apart somebody else's science experiment.", "tokens": [50364, 286, 500, 380, 528, 281, 362, 281, 747, 4936, 2618, 1646, 311, 3497, 5120, 13, 50660], "temperature": 0.0, "avg_logprob": -0.12333759153732146, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.003376337233930826}, {"id": 68, "seek": 31636, "start": 322.28000000000003, "end": 326.68, "text": " And the reason people are doing this is because they want a tighter integration with Kubernetes.", "tokens": [50660, 400, 264, 1778, 561, 366, 884, 341, 307, 570, 436, 528, 257, 30443, 10980, 365, 23145, 13, 50880], "temperature": 0.0, "avg_logprob": -0.12333759153732146, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.003376337233930826}, {"id": 69, "seek": 31636, "start": 326.68, "end": 330.92, "text": " So CNI plugins are binaries.", "tokens": [50880, 407, 14589, 40, 33759, 366, 5171, 4889, 13, 51092], "temperature": 0.0, "avg_logprob": -0.12333759153732146, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.003376337233930826}, {"id": 70, "seek": 31636, "start": 330.92, "end": 332.8, "text": " They run on disk.", "tokens": [51092, 814, 1190, 322, 12355, 13, 51186], "temperature": 0.0, "avg_logprob": -0.12333759153732146, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.003376337233930826}, {"id": 71, "seek": 31636, "start": 332.8, "end": 336.08000000000004, "text": " They're called by your container runtime.", "tokens": [51186, 814, 434, 1219, 538, 428, 10129, 34474, 13, 51350], "temperature": 0.0, "avg_logprob": -0.12333759153732146, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.003376337233930826}, {"id": 72, "seek": 31636, "start": 336.08000000000004, "end": 339.36, "text": " And they execute these binaries on disk.", "tokens": [51350, 400, 436, 14483, 613, 5171, 4889, 322, 12355, 13, 51514], "temperature": 0.0, "avg_logprob": -0.12333759153732146, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.003376337233930826}, {"id": 73, "seek": 31636, "start": 339.36, "end": 344.28000000000003, "text": " So for example, junior engineer on my team, we deal with CNI plugins all day, long day", "tokens": [51514, 407, 337, 1365, 11, 16195, 11403, 322, 452, 1469, 11, 321, 2028, 365, 14589, 40, 33759, 439, 786, 11, 938, 786, 51760], "temperature": 0.0, "avg_logprob": -0.12333759153732146, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.003376337233930826}, {"id": 74, "seek": 34428, "start": 344.28, "end": 346.4, "text": " and day out.", "tokens": [50364, 293, 786, 484, 13, 50470], "temperature": 0.0, "avg_logprob": -0.15504739834712103, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.00609641894698143}, {"id": 75, "seek": 34428, "start": 346.4, "end": 348.91999999999996, "text": " And he's looking at these other teams.", "tokens": [50470, 400, 415, 311, 1237, 412, 613, 661, 5491, 13, 50596], "temperature": 0.0, "avg_logprob": -0.15504739834712103, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.00609641894698143}, {"id": 76, "seek": 34428, "start": 348.91999999999996, "end": 356.67999999999995, "text": " And they're working on Kubernetes operators, all this stuff that integrates tightly with", "tokens": [50596, 400, 436, 434, 1364, 322, 23145, 19077, 11, 439, 341, 1507, 300, 3572, 1024, 21952, 365, 50984], "temperature": 0.0, "avg_logprob": -0.15504739834712103, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.00609641894698143}, {"id": 77, "seek": 34428, "start": 356.67999999999995, "end": 357.67999999999995, "text": " Kubernetes.", "tokens": [50984, 23145, 13, 51034], "temperature": 0.0, "avg_logprob": -0.15504739834712103, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.00609641894698143}, {"id": 78, "seek": 34428, "start": 357.67999999999995, "end": 362.32, "text": " And he's like, look at all these awesome tools that they have to interactively debug", "tokens": [51034, 400, 415, 311, 411, 11, 574, 412, 439, 613, 3476, 3873, 300, 436, 362, 281, 4648, 3413, 24083, 51266], "temperature": 0.0, "avg_logprob": -0.15504739834712103, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.00609641894698143}, {"id": 79, "seek": 34428, "start": 362.32, "end": 364.84, "text": " their programs.", "tokens": [51266, 641, 4268, 13, 51392], "temperature": 0.0, "avg_logprob": -0.15504739834712103, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.00609641894698143}, {"id": 80, "seek": 34428, "start": 364.84, "end": 369.47999999999996, "text": " And if I want to do that with a CNI plugin that's not really running in Kubernetes because", "tokens": [51392, 400, 498, 286, 528, 281, 360, 300, 365, 257, 14589, 40, 23407, 300, 311, 406, 534, 2614, 294, 23145, 570, 51624], "temperature": 0.0, "avg_logprob": -0.15504739834712103, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.00609641894698143}, {"id": 81, "seek": 34428, "start": 369.47999999999996, "end": 374.2, "text": " it's container agnostic, well, I can see why.", "tokens": [51624, 309, 311, 10129, 623, 77, 19634, 11, 731, 11, 286, 393, 536, 983, 13, 51860], "temperature": 0.0, "avg_logprob": -0.15504739834712103, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.00609641894698143}, {"id": 82, "seek": 37420, "start": 375.12, "end": 380.84, "text": " Some Kubernetes distributors are saying, I'll just ignore it and just do this another way", "tokens": [50410, 2188, 23145, 4400, 30751, 366, 1566, 11, 286, 603, 445, 11200, 309, 293, 445, 360, 341, 1071, 636, 50696], "temperature": 0.0, "avg_logprob": -0.15744594732920328, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0009398477268405259}, {"id": 83, "seek": 37420, "start": 380.84, "end": 388.08, "text": " because I can get a tighter Kubernetes integration if I just bypass CNI.", "tokens": [50696, 570, 286, 393, 483, 257, 30443, 23145, 10980, 498, 286, 445, 24996, 14589, 40, 13, 51058], "temperature": 0.0, "avg_logprob": -0.15744594732920328, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0009398477268405259}, {"id": 84, "seek": 37420, "start": 388.08, "end": 391.71999999999997, "text": " I am a maintainer of something called Multis CNI.", "tokens": [51058, 286, 669, 257, 6909, 260, 295, 746, 1219, 14665, 271, 14589, 40, 13, 51240], "temperature": 0.0, "avg_logprob": -0.15744594732920328, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0009398477268405259}, {"id": 85, "seek": 37420, "start": 391.71999999999997, "end": 398.28, "text": " And what it's used for is having multiple interfaces in a pod in Kubernetes.", "tokens": [51240, 400, 437, 309, 311, 1143, 337, 307, 1419, 3866, 28416, 294, 257, 2497, 294, 23145, 13, 51568], "temperature": 0.0, "avg_logprob": -0.15744594732920328, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0009398477268405259}, {"id": 86, "seek": 39828, "start": 398.28, "end": 405.11999999999995, "text": " So if you're doing something that's more of a high-powered networking kind of stuff", "tokens": [50364, 407, 498, 291, 434, 884, 746, 300, 311, 544, 295, 257, 1090, 12, 27178, 17985, 733, 295, 1507, 50706], "temperature": 0.0, "avg_logprob": -0.15838011451389478, "compression_ratio": 1.628440366972477, "no_speech_prob": 0.0001253314403584227}, {"id": 87, "seek": 39828, "start": 405.11999999999995, "end": 411.79999999999995, "text": " where you want to have isolation of networks, so a classic thing would be control and media", "tokens": [50706, 689, 291, 528, 281, 362, 16001, 295, 9590, 11, 370, 257, 7230, 551, 576, 312, 1969, 293, 3021, 51040], "temperature": 0.0, "avg_logprob": -0.15838011451389478, "compression_ratio": 1.628440366972477, "no_speech_prob": 0.0001253314403584227}, {"id": 88, "seek": 39828, "start": 411.79999999999995, "end": 417.32, "text": " on separate networks and you want to divide traffic so that that's isolated.", "tokens": [51040, 322, 4994, 9590, 293, 291, 528, 281, 9845, 6419, 370, 300, 300, 311, 14621, 13, 51316], "temperature": 0.0, "avg_logprob": -0.15838011451389478, "compression_ratio": 1.628440366972477, "no_speech_prob": 0.0001253314403584227}, {"id": 89, "seek": 39828, "start": 417.32, "end": 419.84, "text": " That's the kind of thing you would use Multis for.", "tokens": [51316, 663, 311, 264, 733, 295, 551, 291, 576, 764, 14665, 271, 337, 13, 51442], "temperature": 0.0, "avg_logprob": -0.15838011451389478, "compression_ratio": 1.628440366972477, "no_speech_prob": 0.0001253314403584227}, {"id": 90, "seek": 39828, "start": 419.84, "end": 424.96, "text": " And Multis is Kubernetes-aware, and it's CNI-aware.", "tokens": [51442, 400, 14665, 271, 307, 23145, 12, 17074, 11, 293, 309, 311, 14589, 40, 12, 17074, 13, 51698], "temperature": 0.0, "avg_logprob": -0.15838011451389478, "compression_ratio": 1.628440366972477, "no_speech_prob": 0.0001253314403584227}, {"id": 91, "seek": 42496, "start": 424.96, "end": 430.59999999999997, "text": " And it's designed to have multiple, to give you these multiple network interfaces.", "tokens": [50364, 400, 309, 311, 4761, 281, 362, 3866, 11, 281, 976, 291, 613, 3866, 3209, 28416, 13, 50646], "temperature": 0.0, "avg_logprob": -0.10577185370705344, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0005883740377612412}, {"id": 92, "seek": 42496, "start": 430.59999999999997, "end": 436.32, "text": " But because it's Kubernetes-aware and it's CNI-aware, people are trying to use it as", "tokens": [50646, 583, 570, 309, 311, 23145, 12, 17074, 293, 309, 311, 14589, 40, 12, 17074, 11, 561, 366, 1382, 281, 764, 309, 382, 50932], "temperature": 0.0, "avg_logprob": -0.10577185370705344, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0005883740377612412}, {"id": 93, "seek": 42496, "start": 436.32, "end": 439.12, "text": " kind of a CNI runtime.", "tokens": [50932, 733, 295, 257, 14589, 40, 34474, 13, 51072], "temperature": 0.0, "avg_logprob": -0.10577185370705344, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0005883740377612412}, {"id": 94, "seek": 42496, "start": 439.12, "end": 441.44, "text": " And that's not what it is.", "tokens": [51072, 400, 300, 311, 406, 437, 309, 307, 13, 51188], "temperature": 0.0, "avg_logprob": -0.10577185370705344, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0005883740377612412}, {"id": 95, "seek": 42496, "start": 441.44, "end": 449.35999999999996, "text": " And kind of as this, so today we have CNI 1.0, CNI 2.0 is on the horizon.", "tokens": [51188, 400, 733, 295, 382, 341, 11, 370, 965, 321, 362, 14589, 40, 502, 13, 15, 11, 14589, 40, 568, 13, 15, 307, 322, 264, 18046, 13, 51584], "temperature": 0.0, "avg_logprob": -0.10577185370705344, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0005883740377612412}, {"id": 96, "seek": 42496, "start": 449.35999999999996, "end": 454.35999999999996, "text": " And as this conversation came up, and I'm seeing more people in my community coming", "tokens": [51584, 400, 382, 341, 3761, 1361, 493, 11, 293, 286, 478, 2577, 544, 561, 294, 452, 1768, 1348, 51834], "temperature": 0.0, "avg_logprob": -0.10577185370705344, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0005883740377612412}, {"id": 97, "seek": 45436, "start": 454.36, "end": 459.72, "text": " to me like, hey, I want Multis CNI to do this thing that's in the CNI spec.", "tokens": [50364, 281, 385, 411, 11, 4177, 11, 286, 528, 14665, 271, 14589, 40, 281, 360, 341, 551, 300, 311, 294, 264, 14589, 40, 1608, 13, 50632], "temperature": 0.0, "avg_logprob": -0.11844863891601562, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.010009757243096828}, {"id": 98, "seek": 45436, "start": 459.72, "end": 465.68, "text": " And I mean, I want to make it work as well as I can to fit everyone's use cases, but", "tokens": [50632, 400, 286, 914, 11, 286, 528, 281, 652, 309, 589, 382, 731, 382, 286, 393, 281, 3318, 1518, 311, 764, 3331, 11, 457, 50930], "temperature": 0.0, "avg_logprob": -0.11844863891601562, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.010009757243096828}, {"id": 99, "seek": 45436, "start": 465.68, "end": 473.8, "text": " I'm really starting to realize, hey, we need to get this kind of functionality into CNI", "tokens": [50930, 286, 478, 534, 2891, 281, 4325, 11, 4177, 11, 321, 643, 281, 483, 341, 733, 295, 14980, 666, 14589, 40, 51336], "temperature": 0.0, "avg_logprob": -0.11844863891601562, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.010009757243096828}, {"id": 100, "seek": 45436, "start": 473.8, "end": 482.36, "text": " itself and to use CNI in a way that really has this Kubernetes-awareness.", "tokens": [51336, 2564, 293, 281, 764, 14589, 40, 294, 257, 636, 300, 534, 575, 341, 23145, 12, 17074, 1287, 13, 51764], "temperature": 0.0, "avg_logprob": -0.11844863891601562, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.010009757243096828}, {"id": 101, "seek": 48236, "start": 482.36, "end": 491.56, "text": " So I'm really trying to invite everyone to get involved and to make sure that CNI and", "tokens": [50364, 407, 286, 478, 534, 1382, 281, 7980, 1518, 281, 483, 3288, 293, 281, 652, 988, 300, 14589, 40, 293, 50824], "temperature": 0.0, "avg_logprob": -0.15653320260950038, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0010985221015289426}, {"id": 102, "seek": 48236, "start": 491.56, "end": 496.88, "text": " Kubernetes are kind of like a happy family together.", "tokens": [50824, 23145, 366, 733, 295, 411, 257, 2055, 1605, 1214, 13, 51090], "temperature": 0.0, "avg_logprob": -0.15653320260950038, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0010985221015289426}, {"id": 103, "seek": 48236, "start": 496.88, "end": 502.36, "text": " And I think that we've got like a strong opportunity here.", "tokens": [51090, 400, 286, 519, 300, 321, 600, 658, 411, 257, 2068, 2650, 510, 13, 51364], "temperature": 0.0, "avg_logprob": -0.15653320260950038, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0010985221015289426}, {"id": 104, "seek": 48236, "start": 502.36, "end": 507.16, "text": " I'm sure if anyone saw the previous lightning talk, which was about YAML, but kind of a", "tokens": [51364, 286, 478, 988, 498, 2878, 1866, 264, 3894, 16589, 751, 11, 597, 390, 466, 398, 2865, 43, 11, 457, 733, 295, 257, 51604], "temperature": 0.0, "avg_logprob": -0.15653320260950038, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0010985221015289426}, {"id": 105, "seek": 50716, "start": 507.16, "end": 515.24, "text": " weird thing between Kubernetes and CNI is that if you are specifying like workloads and", "tokens": [50364, 3657, 551, 1296, 23145, 293, 14589, 40, 307, 300, 498, 291, 366, 1608, 5489, 411, 32452, 293, 50768], "temperature": 0.0, "avg_logprob": -0.1676621609423534, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.09804786741733551}, {"id": 106, "seek": 50716, "start": 515.24, "end": 523.4, "text": " resources, et cetera, your pod specs in Kubernetes, you're using YAML, which has its problems", "tokens": [50768, 3593, 11, 1030, 11458, 11, 428, 2497, 27911, 294, 23145, 11, 291, 434, 1228, 398, 2865, 43, 11, 597, 575, 1080, 2740, 51176], "temperature": 0.0, "avg_logprob": -0.1676621609423534, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.09804786741733551}, {"id": 107, "seek": 50716, "start": 523.4, "end": 529.44, "text": " as you saw in the last talk, but CNI itself uses JSON.", "tokens": [51176, 382, 291, 1866, 294, 264, 1036, 751, 11, 457, 14589, 40, 2564, 4960, 31828, 13, 51478], "temperature": 0.0, "avg_logprob": -0.1676621609423534, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.09804786741733551}, {"id": 108, "seek": 50716, "start": 529.44, "end": 535.32, "text": " So when you're trying to sort of marry these two worlds together, you have this kind of", "tokens": [51478, 407, 562, 291, 434, 1382, 281, 1333, 295, 9747, 613, 732, 13401, 1214, 11, 291, 362, 341, 733, 295, 51772], "temperature": 0.0, "avg_logprob": -0.1676621609423534, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.09804786741733551}, {"id": 109, "seek": 53532, "start": 535.32, "end": 542.4000000000001, "text": " problem, especially in my space with Multis where you're kind of multiplexing CNI plugins", "tokens": [50364, 1154, 11, 2318, 294, 452, 1901, 365, 14665, 271, 689, 291, 434, 733, 295, 3311, 2021, 278, 14589, 40, 33759, 50718], "temperature": 0.0, "avg_logprob": -0.12912349700927733, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.005554442759603262}, {"id": 110, "seek": 53532, "start": 542.4000000000001, "end": 544.5200000000001, "text": " to get these multiple interfaces.", "tokens": [50718, 281, 483, 613, 3866, 28416, 13, 50824], "temperature": 0.0, "avg_logprob": -0.12912349700927733, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.005554442759603262}, {"id": 111, "seek": 53532, "start": 544.5200000000001, "end": 552.44, "text": " So you're taking YAML that's in Kubernetes and then you're packing JSON into those specs", "tokens": [50824, 407, 291, 434, 1940, 398, 2865, 43, 300, 311, 294, 23145, 293, 550, 291, 434, 20815, 31828, 666, 729, 27911, 51220], "temperature": 0.0, "avg_logprob": -0.12912349700927733, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.005554442759603262}, {"id": 112, "seek": 53532, "start": 552.44, "end": 556.2800000000001, "text": " and it's kind of dirty in its own way.", "tokens": [51220, 293, 309, 311, 733, 295, 9360, 294, 1080, 1065, 636, 13, 51412], "temperature": 0.0, "avg_logprob": -0.12912349700927733, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.005554442759603262}, {"id": 113, "seek": 53532, "start": 556.2800000000001, "end": 561.4000000000001, "text": " So that's like one of those things I'd like to see happen better.", "tokens": [51412, 407, 300, 311, 411, 472, 295, 729, 721, 286, 1116, 411, 281, 536, 1051, 1101, 13, 51668], "temperature": 0.0, "avg_logprob": -0.12912349700927733, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.005554442759603262}, {"id": 114, "seek": 56140, "start": 561.4, "end": 569.0799999999999, "text": " And I think it's really awkward for when you're trying to like programmatically interact", "tokens": [50364, 400, 286, 519, 309, 311, 534, 11411, 337, 562, 291, 434, 1382, 281, 411, 37648, 5030, 4648, 50748], "temperature": 0.0, "avg_logprob": -0.09535416789438533, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.003824229585006833}, {"id": 115, "seek": 56140, "start": 569.0799999999999, "end": 570.0799999999999, "text": " with this stuff.", "tokens": [50748, 365, 341, 1507, 13, 50798], "temperature": 0.0, "avg_logprob": -0.09535416789438533, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.003824229585006833}, {"id": 116, "seek": 56140, "start": 570.0799999999999, "end": 575.24, "text": " So sure, as a user, you specify your YAML, you pack some JSON in it, no big deal.", "tokens": [50798, 407, 988, 11, 382, 257, 4195, 11, 291, 16500, 428, 398, 2865, 43, 11, 291, 2844, 512, 31828, 294, 309, 11, 572, 955, 2028, 13, 51056], "temperature": 0.0, "avg_logprob": -0.09535416789438533, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.003824229585006833}, {"id": 117, "seek": 56140, "start": 575.24, "end": 580.88, "text": " But if you're writing an application that parses that YAML, it also has to parse the", "tokens": [51056, 583, 498, 291, 434, 3579, 364, 3861, 300, 21156, 279, 300, 398, 2865, 43, 11, 309, 611, 575, 281, 48377, 264, 51338], "temperature": 0.0, "avg_logprob": -0.09535416789438533, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.003824229585006833}, {"id": 118, "seek": 56140, "start": 580.88, "end": 586.28, "text": " JSON inside it, which is worse.", "tokens": [51338, 31828, 1854, 309, 11, 597, 307, 5324, 13, 51608], "temperature": 0.0, "avg_logprob": -0.09535416789438533, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.003824229585006833}, {"id": 119, "seek": 58628, "start": 586.28, "end": 594.92, "text": " So I want everyone to have the CNI 2.0 revolution live long and strong.", "tokens": [50364, 407, 286, 528, 1518, 281, 362, 264, 14589, 40, 568, 13, 15, 8894, 1621, 938, 293, 2068, 13, 50796], "temperature": 0.0, "avg_logprob": -0.1420658222143201, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.05497188866138458}, {"id": 120, "seek": 58628, "start": 594.92, "end": 599.8399999999999, "text": " And so I'm trying to get everyone to get involved.", "tokens": [50796, 400, 370, 286, 478, 1382, 281, 483, 1518, 281, 483, 3288, 13, 51042], "temperature": 0.0, "avg_logprob": -0.1420658222143201, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.05497188866138458}, {"id": 121, "seek": 58628, "start": 599.8399999999999, "end": 606.6, "text": " And this is a space that I can invite you to that is a working group that I know and", "tokens": [51042, 400, 341, 307, 257, 1901, 300, 286, 393, 7980, 291, 281, 300, 307, 257, 1364, 1594, 300, 286, 458, 293, 51380], "temperature": 0.0, "avg_logprob": -0.1420658222143201, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.05497188866138458}, {"id": 122, "seek": 58628, "start": 606.6, "end": 611.0, "text": " love, the Kubernetes network planning working group.", "tokens": [51380, 959, 11, 264, 23145, 3209, 5038, 1364, 1594, 13, 51600], "temperature": 0.0, "avg_logprob": -0.1420658222143201, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.05497188866138458}, {"id": 123, "seek": 61100, "start": 611.0, "end": 617.08, "text": " We meet every other Thursday in a time that's supposed to be the most friendly for Asia,", "tokens": [50364, 492, 1677, 633, 661, 10383, 294, 257, 565, 300, 311, 3442, 281, 312, 264, 881, 9208, 337, 10038, 11, 50668], "temperature": 0.0, "avg_logprob": -0.1381307773375779, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.5843910574913025}, {"id": 124, "seek": 61100, "start": 617.08, "end": 619.52, "text": " Europe and the US.", "tokens": [50668, 3315, 293, 264, 2546, 13, 50790], "temperature": 0.0, "avg_logprob": -0.1381307773375779, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.5843910574913025}, {"id": 125, "seek": 61100, "start": 619.52, "end": 624.8, "text": " And we will be discussing this until it's solved.", "tokens": [50790, 400, 321, 486, 312, 10850, 341, 1826, 309, 311, 13041, 13, 51054], "temperature": 0.0, "avg_logprob": -0.1381307773375779, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.5843910574913025}, {"id": 126, "seek": 61100, "start": 624.8, "end": 630.52, "text": " And we're going to take these considerations up with the CNI community as well.", "tokens": [51054, 400, 321, 434, 516, 281, 747, 613, 24070, 493, 365, 264, 14589, 40, 1768, 382, 731, 13, 51340], "temperature": 0.0, "avg_logprob": -0.1381307773375779, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.5843910574913025}, {"id": 127, "seek": 61100, "start": 630.52, "end": 637.44, "text": " And I'd love to see any faces join and we can keep rocking and rolling on this.", "tokens": [51340, 400, 286, 1116, 959, 281, 536, 604, 8475, 3917, 293, 321, 393, 1066, 30929, 293, 9439, 322, 341, 13, 51686], "temperature": 0.0, "avg_logprob": -0.1381307773375779, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.5843910574913025}, {"id": 128, "seek": 61100, "start": 637.44, "end": 639.64, "text": " So thank you.", "tokens": [51686, 407, 1309, 291, 13, 51796], "temperature": 0.0, "avg_logprob": -0.1381307773375779, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.5843910574913025}, {"id": 129, "seek": 63964, "start": 639.64, "end": 646.64, "text": " And yeah, floor is open for any questions.", "tokens": [50364, 400, 1338, 11, 4123, 307, 1269, 337, 604, 1651, 13, 50714], "temperature": 0.0, "avg_logprob": -0.7508135523114886, "compression_ratio": 0.875, "no_speech_prob": 0.16331475973129272}, {"id": 130, "seek": 64664, "start": 646.64, "end": 676.6, "text": " So the question is the", "tokens": [50364, 407, 264, 1168, 307, 264, 51862], "temperature": 0.2, "avg_logprob": -0.8869986004299588, "compression_ratio": 0.8148148148148148, "no_speech_prob": 0.09363076835870743}, {"id": 131, "seek": 67660, "start": 677.6, "end": 682.64, "text": " given by Casey Calandrello from Red Hat, no longer at Red Hat.", "tokens": [50414, 2212, 538, 27369, 3511, 474, 265, 1913, 490, 4477, 15867, 11, 572, 2854, 412, 4477, 15867, 13, 50666], "temperature": 0.0, "avg_logprob": -0.2594422313654534, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.784005343914032}, {"id": 132, "seek": 67660, "start": 682.64, "end": 686.88, "text": " A couple Q-cons ago, there's about CNI 2.0.", "tokens": [50666, 316, 1916, 1249, 12, 21190, 2057, 11, 456, 311, 466, 14589, 40, 568, 13, 15, 13, 50878], "temperature": 0.0, "avg_logprob": -0.2594422313654534, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.784005343914032}, {"id": 133, "seek": 67660, "start": 686.88, "end": 690.96, "text": " And yes, this is a related effort.", "tokens": [50878, 400, 2086, 11, 341, 307, 257, 4077, 4630, 13, 51082], "temperature": 0.0, "avg_logprob": -0.2594422313654534, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.784005343914032}, {"id": 134, "seek": 67660, "start": 690.96, "end": 697.0, "text": " And I think that what Casey was talking about at the time was so one of the problems that", "tokens": [51082, 400, 286, 519, 300, 437, 27369, 390, 1417, 466, 412, 264, 565, 390, 370, 472, 295, 264, 2740, 300, 51384], "temperature": 0.0, "avg_logprob": -0.2594422313654534, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.784005343914032}, {"id": 135, "seek": 67660, "start": 697.0, "end": 702.8000000000001, "text": " I mentioned was you've got these CNI plugins, they're binaries on disk, wouldn't it be better", "tokens": [51384, 286, 2835, 390, 291, 600, 658, 613, 14589, 40, 33759, 11, 436, 434, 5171, 4889, 322, 12355, 11, 2759, 380, 309, 312, 1101, 51674], "temperature": 0.0, "avg_logprob": -0.2594422313654534, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.784005343914032}, {"id": 136, "seek": 67660, "start": 702.8000000000001, "end": 706.0, "text": " if, say, they were containerized?", "tokens": [51674, 498, 11, 584, 11, 436, 645, 10129, 1602, 30, 51834], "temperature": 0.0, "avg_logprob": -0.2594422313654534, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.784005343914032}, {"id": 137, "seek": 70600, "start": 706.0, "end": 710.16, "text": " And that was something that Casey was talking about is that we'd like to see CNI plugins", "tokens": [50364, 400, 300, 390, 746, 300, 27369, 390, 1417, 466, 307, 300, 321, 1116, 411, 281, 536, 14589, 40, 33759, 50572], "temperature": 0.0, "avg_logprob": -0.1466822072079307, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.060013044625520706}, {"id": 138, "seek": 70600, "start": 710.16, "end": 713.12, "text": " be containerized instead of binaries on disk.", "tokens": [50572, 312, 10129, 1602, 2602, 295, 5171, 4889, 322, 12355, 13, 50720], "temperature": 0.0, "avg_logprob": -0.1466822072079307, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.060013044625520706}, {"id": 139, "seek": 70600, "start": 713.12, "end": 721.12, "text": " They're going to be more familiar to folks that work on Kubernetes applications.", "tokens": [50720, 814, 434, 516, 281, 312, 544, 4963, 281, 4024, 300, 589, 322, 23145, 5821, 13, 51120], "temperature": 0.0, "avg_logprob": -0.1466822072079307, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.060013044625520706}, {"id": 140, "seek": 70600, "start": 721.12, "end": 725.48, "text": " He was also talking about getting a GRPC interface.", "tokens": [51120, 634, 390, 611, 1417, 466, 1242, 257, 10903, 12986, 9226, 13, 51338], "temperature": 0.0, "avg_logprob": -0.1466822072079307, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.060013044625520706}, {"id": 141, "seek": 70600, "start": 725.48, "end": 729.32, "text": " But I think that this is kind of a newer thought process.", "tokens": [51338, 583, 286, 519, 300, 341, 307, 733, 295, 257, 17628, 1194, 1399, 13, 51530], "temperature": 0.0, "avg_logprob": -0.1466822072079307, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.060013044625520706}, {"id": 142, "seek": 70600, "start": 729.32, "end": 733.96, "text": " And I don't want to put words in Casey's mouth.", "tokens": [51530, 400, 286, 500, 380, 528, 281, 829, 2283, 294, 27369, 311, 4525, 13, 51762], "temperature": 0.0, "avg_logprob": -0.1466822072079307, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.060013044625520706}, {"id": 143, "seek": 73396, "start": 733.96, "end": 735.8000000000001, "text": " So I won't.", "tokens": [50364, 407, 286, 1582, 380, 13, 50456], "temperature": 0.0, "avg_logprob": -0.17197486332484654, "compression_ratio": 1.3288590604026846, "no_speech_prob": 0.028844987973570824}, {"id": 144, "seek": 73396, "start": 735.8000000000001, "end": 739.9200000000001, "text": " But I have a feeling that he is also on board.", "tokens": [50456, 583, 286, 362, 257, 2633, 300, 415, 307, 611, 322, 3150, 13, 50662], "temperature": 0.0, "avg_logprob": -0.17197486332484654, "compression_ratio": 1.3288590604026846, "no_speech_prob": 0.028844987973570824}, {"id": 145, "seek": 73396, "start": 739.9200000000001, "end": 746.36, "text": " And for those of you who don't know, Casey Calandrello is the originator of CNI and is", "tokens": [50662, 400, 337, 729, 295, 291, 567, 500, 380, 458, 11, 27369, 3511, 474, 265, 1913, 307, 264, 4957, 1639, 295, 14589, 40, 293, 307, 50984], "temperature": 0.0, "avg_logprob": -0.17197486332484654, "compression_ratio": 1.3288590604026846, "no_speech_prob": 0.028844987973570824}, {"id": 146, "seek": 73396, "start": 746.36, "end": 749.96, "text": " also an awesome guy.", "tokens": [50984, 611, 364, 3476, 2146, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17197486332484654, "compression_ratio": 1.3288590604026846, "no_speech_prob": 0.028844987973570824}, {"id": 147, "seek": 73396, "start": 749.96, "end": 757.48, "text": " So yeah, so related.", "tokens": [51164, 407, 1338, 11, 370, 4077, 13, 51540], "temperature": 0.0, "avg_logprob": -0.17197486332484654, "compression_ratio": 1.3288590604026846, "no_speech_prob": 0.028844987973570824}, {"id": 148, "seek": 73396, "start": 757.48, "end": 758.48, "text": " Go for it.", "tokens": [51540, 1037, 337, 309, 13, 51590], "temperature": 0.0, "avg_logprob": -0.17197486332484654, "compression_ratio": 1.3288590604026846, "no_speech_prob": 0.028844987973570824}, {"id": 149, "seek": 75848, "start": 758.48, "end": 765.16, "text": " OK, so in that talk, he was talking most about CNI would be more like a more complete life", "tokens": [50364, 2264, 11, 370, 294, 300, 751, 11, 415, 390, 1417, 881, 466, 14589, 40, 576, 312, 544, 411, 257, 544, 3566, 993, 50698], "temperature": 0.0, "avg_logprob": -0.432252706483353, "compression_ratio": 1.5098039215686274, "no_speech_prob": 0.0360242985188961}, {"id": 150, "seek": 75848, "start": 765.16, "end": 769.16, "text": " cycle meant for networks and all of that.", "tokens": [50698, 6586, 4140, 337, 9590, 293, 439, 295, 300, 13, 50898], "temperature": 0.0, "avg_logprob": -0.432252706483353, "compression_ratio": 1.5098039215686274, "no_speech_prob": 0.0360242985188961}, {"id": 151, "seek": 75848, "start": 769.16, "end": 778.16, "text": " And at the same time, but now there is an activity to create like a proper API for networks.", "tokens": [50898, 400, 412, 264, 912, 565, 11, 457, 586, 456, 307, 364, 5191, 281, 1884, 411, 257, 2296, 9362, 337, 9590, 13, 51348], "temperature": 0.0, "avg_logprob": -0.432252706483353, "compression_ratio": 1.5098039215686274, "no_speech_prob": 0.0360242985188961}, {"id": 152, "seek": 75848, "start": 778.16, "end": 782.9200000000001, "text": " So how is this to make a happy marriage?", "tokens": [51348, 407, 577, 307, 341, 281, 652, 257, 2055, 7194, 30, 51586], "temperature": 0.0, "avg_logprob": -0.432252706483353, "compression_ratio": 1.5098039215686274, "no_speech_prob": 0.0360242985188961}, {"id": 153, "seek": 75848, "start": 782.9200000000001, "end": 786.72, "text": " So the question is, and it's a great one.", "tokens": [51586, 407, 264, 1168, 307, 11, 293, 309, 311, 257, 869, 472, 13, 51776], "temperature": 0.0, "avg_logprob": -0.432252706483353, "compression_ratio": 1.5098039215686274, "no_speech_prob": 0.0360242985188961}, {"id": 154, "seek": 78672, "start": 786.72, "end": 793.9200000000001, "text": " And so one thing that was talked about in that presentation was the idea of a more complete", "tokens": [50364, 400, 370, 472, 551, 300, 390, 2825, 466, 294, 300, 5860, 390, 264, 1558, 295, 257, 544, 3566, 50724], "temperature": 0.0, "avg_logprob": -0.14675089208091177, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0008557586115784943}, {"id": 155, "seek": 78672, "start": 793.9200000000001, "end": 795.84, "text": " life cycle management.", "tokens": [50724, 993, 6586, 4592, 13, 50820], "temperature": 0.0, "avg_logprob": -0.14675089208091177, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0008557586115784943}, {"id": 156, "seek": 78672, "start": 795.84, "end": 804.6, "text": " And there is also concurrently an effort happening now that is to define a networks object for", "tokens": [50820, 400, 456, 307, 611, 37702, 356, 364, 4630, 2737, 586, 300, 307, 281, 6964, 257, 9590, 2657, 337, 51258], "temperature": 0.0, "avg_logprob": -0.14675089208091177, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0008557586115784943}, {"id": 157, "seek": 78672, "start": 804.6, "end": 808.76, "text": " Kubernetes, so a data representation of networks.", "tokens": [51258, 23145, 11, 370, 257, 1412, 10290, 295, 9590, 13, 51466], "temperature": 0.0, "avg_logprob": -0.14675089208091177, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0008557586115784943}, {"id": 158, "seek": 78672, "start": 808.76, "end": 815.96, "text": " So this is a complex two part question and I have 90 seconds for it, but I love it.", "tokens": [51466, 407, 341, 307, 257, 3997, 732, 644, 1168, 293, 286, 362, 4289, 3949, 337, 309, 11, 457, 286, 959, 309, 13, 51826], "temperature": 0.0, "avg_logprob": -0.14675089208091177, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0008557586115784943}, {"id": 159, "seek": 81596, "start": 815.96, "end": 825.8000000000001, "text": " So yes, also, so second part first, there is an effort that is called I call it Kubernetes", "tokens": [50364, 407, 2086, 11, 611, 11, 370, 1150, 644, 700, 11, 456, 307, 364, 4630, 300, 307, 1219, 286, 818, 309, 23145, 50856], "temperature": 0.0, "avg_logprob": -0.20901284734886813, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.0031719228718429804}, {"id": 160, "seek": 81596, "start": 825.8000000000001, "end": 827.96, "text": " native multi networking.", "tokens": [50856, 8470, 4825, 17985, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20901284734886813, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.0031719228718429804}, {"id": 161, "seek": 81596, "start": 827.96, "end": 833.96, "text": " If you join the SIG network call, you can find out all the connection or information", "tokens": [50964, 759, 291, 3917, 264, 318, 10489, 3209, 818, 11, 291, 393, 915, 484, 439, 264, 4984, 420, 1589, 51264], "temperature": 0.0, "avg_logprob": -0.20901284734886813, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.0031719228718429804}, {"id": 162, "seek": 81596, "start": 833.96, "end": 835.0400000000001, "text": " about it.", "tokens": [51264, 466, 309, 13, 51318], "temperature": 0.0, "avg_logprob": -0.20901284734886813, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.0031719228718429804}, {"id": 163, "seek": 81596, "start": 835.0400000000001, "end": 836.4000000000001, "text": " Very interesting effort.", "tokens": [51318, 4372, 1880, 4630, 13, 51386], "temperature": 0.0, "avg_logprob": -0.20901284734886813, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.0031719228718429804}, {"id": 164, "seek": 81596, "start": 836.4000000000001, "end": 840.2800000000001, "text": " And as I mentioned, multi CNI does multi networking stuff.", "tokens": [51386, 400, 382, 286, 2835, 11, 4825, 14589, 40, 775, 4825, 17985, 1507, 13, 51580], "temperature": 0.0, "avg_logprob": -0.20901284734886813, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.0031719228718429804}, {"id": 165, "seek": 81596, "start": 840.2800000000001, "end": 841.2800000000001, "text": " That's awesome.", "tokens": [51580, 663, 311, 3476, 13, 51630], "temperature": 0.0, "avg_logprob": -0.20901284734886813, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.0031719228718429804}, {"id": 166, "seek": 84128, "start": 841.28, "end": 851.68, "text": " And that particular conversation is to me bringing up lots of questions about what CNI 2.0 is", "tokens": [50364, 400, 300, 1729, 3761, 307, 281, 385, 5062, 493, 3195, 295, 1651, 466, 437, 14589, 40, 568, 13, 15, 307, 50884], "temperature": 0.0, "avg_logprob": -0.18981606081912392, "compression_ratio": 1.5940594059405941, "no_speech_prob": 0.0037063718773424625}, {"id": 167, "seek": 84128, "start": 851.68, "end": 853.48, "text": " going to look like.", "tokens": [50884, 516, 281, 574, 411, 13, 50974], "temperature": 0.0, "avg_logprob": -0.18981606081912392, "compression_ratio": 1.5940594059405941, "no_speech_prob": 0.0037063718773424625}, {"id": 168, "seek": 84128, "start": 853.48, "end": 859.24, "text": " And for the first part of the question, which is richer life cycle management of networking", "tokens": [50974, 400, 337, 264, 700, 644, 295, 264, 1168, 11, 597, 307, 29021, 993, 6586, 4592, 295, 17985, 51262], "temperature": 0.0, "avg_logprob": -0.18981606081912392, "compression_ratio": 1.5940594059405941, "no_speech_prob": 0.0037063718773424625}, {"id": 169, "seek": 84128, "start": 859.24, "end": 867.04, "text": " in containers is so something about CNI is that it primarily functions on container creation", "tokens": [51262, 294, 17089, 307, 370, 746, 466, 14589, 40, 307, 300, 309, 10029, 6828, 322, 10129, 8016, 51652], "temperature": 0.0, "avg_logprob": -0.18981606081912392, "compression_ratio": 1.5940594059405941, "no_speech_prob": 0.0037063718773424625}, {"id": 170, "seek": 84128, "start": 867.04, "end": 869.8, "text": " and container deletion.", "tokens": [51652, 293, 10129, 1103, 302, 313, 13, 51790], "temperature": 0.0, "avg_logprob": -0.18981606081912392, "compression_ratio": 1.5940594059405941, "no_speech_prob": 0.0037063718773424625}, {"id": 171, "seek": 86980, "start": 869.8, "end": 875.5999999999999, "text": " There's some exceptions to this, but primarily so CNI add is a command happens when your", "tokens": [50364, 821, 311, 512, 22847, 281, 341, 11, 457, 10029, 370, 14589, 40, 909, 307, 257, 5622, 2314, 562, 428, 50654], "temperature": 0.0, "avg_logprob": -0.21769164235968338, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.07581566274166107}, {"id": 172, "seek": 86980, "start": 875.5999999999999, "end": 883.12, "text": " container is created, your CNI plug in kicks off, does its work, goes to sleep dies.", "tokens": [50654, 10129, 307, 2942, 11, 428, 14589, 40, 5452, 294, 21293, 766, 11, 775, 1080, 589, 11, 1709, 281, 2817, 2714, 13, 51030], "temperature": 0.0, "avg_logprob": -0.21769164235968338, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.07581566274166107}, {"id": 173, "seek": 86980, "start": 883.12, "end": 888.16, "text": " And then delete when your container is deleted, it tears it down and cleans it up.", "tokens": [51030, 400, 550, 12097, 562, 428, 10129, 307, 22981, 11, 309, 10462, 309, 760, 293, 16912, 309, 493, 13, 51282], "temperature": 0.0, "avg_logprob": -0.21769164235968338, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.07581566274166107}, {"id": 174, "seek": 86980, "start": 888.16, "end": 892.5999999999999, "text": " However, networking can still happen between those two to 10 points, right?", "tokens": [51282, 2908, 11, 17985, 393, 920, 1051, 1296, 729, 732, 281, 1266, 2793, 11, 558, 30, 51504], "temperature": 0.0, "avg_logprob": -0.21769164235968338, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.07581566274166107}, {"id": 175, "seek": 86980, "start": 892.5999999999999, "end": 895.88, "text": " So things happen, things change IPv6.", "tokens": [51504, 407, 721, 1051, 11, 721, 1319, 8671, 85, 21, 13, 51668], "temperature": 0.0, "avg_logprob": -0.21769164235968338, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.07581566274166107}, {"id": 176, "seek": 89588, "start": 895.88, "end": 903.8, "text": " You could have Slack happening and auto assign routing and IPs.", "tokens": [50364, 509, 727, 362, 37211, 2737, 293, 8399, 6269, 32722, 293, 8671, 82, 13, 50760], "temperature": 0.0, "avg_logprob": -0.19231902428393094, "compression_ratio": 1.297709923664122, "no_speech_prob": 0.3376646935939789}, {"id": 177, "seek": 89588, "start": 903.8, "end": 904.8, "text": " And that's it.", "tokens": [50760, 400, 300, 311, 309, 13, 50810], "temperature": 0.0, "avg_logprob": -0.19231902428393094, "compression_ratio": 1.297709923664122, "no_speech_prob": 0.3376646935939789}, {"id": 178, "seek": 89588, "start": 904.8, "end": 905.8, "text": " So we want to fix that too.", "tokens": [50810, 407, 321, 528, 281, 3191, 300, 886, 13, 50860], "temperature": 0.0, "avg_logprob": -0.19231902428393094, "compression_ratio": 1.297709923664122, "no_speech_prob": 0.3376646935939789}, {"id": 179, "seek": 89588, "start": 905.8, "end": 906.8, "text": " So thank you very much.", "tokens": [50860, 407, 1309, 291, 588, 709, 13, 50910], "temperature": 0.0, "avg_logprob": -0.19231902428393094, "compression_ratio": 1.297709923664122, "no_speech_prob": 0.3376646935939789}, {"id": 180, "seek": 89588, "start": 906.8, "end": 907.8, "text": " Appreciate it.", "tokens": [50910, 37601, 309, 13, 50960], "temperature": 0.0, "avg_logprob": -0.19231902428393094, "compression_ratio": 1.297709923664122, "no_speech_prob": 0.3376646935939789}, {"id": 181, "seek": 89588, "start": 907.8, "end": 908.56, "text": " Thanks for the question.", "tokens": [50960, 2561, 337, 264, 1168, 13, 50998], "temperature": 0.0, "avg_logprob": -0.19231902428393094, "compression_ratio": 1.297709923664122, "no_speech_prob": 0.3376646935939789}], "language": "en"}