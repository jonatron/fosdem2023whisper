{"text": " I'm sorry for the wrong title, but you know, naming is hard, so I had to put something. But today, I want to talk to you about my experience with dealing with out-of-tree plug-in and tools for LLVM. Parkoach is just one example, and I will give some others. So first of all, I will try to explain to you why and for whom am I doing this talk. So you know the audience. I'm going to talk about three different things. The first one is keeping up with LLVM. So we will see some code. She makes C++ and stuff. The second point is usability, both from a developer, a tool developer point of view and a user point of view. And the final point will be dealing with packaging when you're actually targeting some system. So why am I doing this talk? First of all, it's to provide some feedback and maybe provide you with some stuff I wish I knew beforehand before coming into this. I'm doing this also because I've learned a couple of out-of-tree projects, and I've faced the same issues. So maybe you've faced them too, and it will be helpful. So it's not so much about the tool parkoach itself, it's rather about the approach. And for whom, it's basically anyone who is involved in an out-of-tree project for LLVM. This is my own point of view on this topic. If you have ideas, comments, like improvements that you think may be helpful to me, don't hesitate. I will welcome them. So parkoach is a tool for HPC application. It's basically an instrumentation, analysis and instrumentation tool for OpenMP and MPI application. It basically checks that the user is using the APIs appropriately, that there are no deadlock or data racism. The developers. This is where it gets interesting, because they are not like LLVM engineers, right? They are interns, students, PhD students, researchers. They have a whole job, which is not LLVM. The users of the tool, they are scientific application developers. So you cannot ask them to compile LLVM from the source. It's not going to work. They are not going to use your tool. And the last part, which is interesting with this project, it started a long time ago when it was LLVM 3.7, and now it's based on LLVM 15. So there has been a lot of history in the tool. And I'm working on it right now. It's my main job, so they have an LLVM engineer now, and I can do stuff. I provided the link for reference if you want to take a look. There are two other motivating projects that I can talk about. One, I'm actually not going to talk about much, because it's not free. It's a commercial compiler, which is based on LLVM, and basically the developers are LLVM engineers, so we have more flexibility when doing developments. And the users are clients who are paying for the compiler, so we need it to provide something good. And the other point is student LLVM exercises. I do courses, LLVM courses for security students, and I want them to be able to do some code transformation with LLVM. So the developer is just a friend of mine and me, and the users are students. We are expecting them to code into the project, so we need to make it easy for them to get into. And we have 16 hours to do this project, and they cannot spend two hours like installing LLVM. It's not going to work either. So in all this project, I am considered pretty much the same issues, so I'm going to talk about them now, and the first one is keeping up with LLVM. So I'm not sure if it was intentional in the schedule, but having a talk with you about CMake and stuff, it's quite helpful because I don't have to go too deep in the details. You already know them. So let's go back maybe eight years ago. You wanted to do some LLVM tools, there was no CMake integration. The first approach that you had as a developer was either do stuff manually, maybe using LLVM config to get the flags and the libraries and so on. But basically, you had no easy way to integrate with LLVM. It was quite manual. Then came CMake, and you could use the standard ad library, target link libraries, but you had to know what to feed these macros with. And some stuff I've encountered in this project is some kind of people who were developing this project were not comfortable with CMake, and they would perform some changes where they would actually do CMake integration, but with R-coded passes in the CMake, so it would be awkward. So basically now it's, I think, at least from the examples we have, it's way better. So using the LLVM CMake integration simplifies a lot of stuff. You just have basically to know which component of LLVM you want to use, how you want to build your library, like is it static or shared basically. And you have dedicated macros to just construct whatever stuff you want to construct for LLVM. So let's take an example code. So you don't have to understand everything, just to give an example of how it works. You basically say, okay, I want to find LLVM, provide a version, sometimes, include the LLVM CMake helper, and include some definition, and then this is the interesting part. Because you can say, okay, I want these components in my tool. Call the CMake helper with your plug-in source, and that's it. I mean, the CMake helper will take care of saying, okay, depending on how LLVM is installed, like is it just the big dialy, but are there like individual libraries? It will set up the target link libraries appropriately, and you don't have to think about it. It's just automatic. If you want to like do some tools or pass plug-in, there are macros to do these two. So basically, you just have to figure out which kind of build you want, and CMake LLVM will configure everything for you. There are some useful examples. For pass plug-ins, there is the buy example, which is basically a new pass plug-in, very simple. It's a kind of a hello world. And LLVM tutor has some out-of-three passes to get you started with, and it's actually quite helpful if you are looking into this. No, let's talk about some code. So let's say you're new to LLVM, pretty new to C++, your student, for instance, and you want to perform some LLVM transformation. So you go on your search engine, and you look for how do I iterate over instructions of LLVM function? And pretty much all the resources like Stack Overflow or even some presentations, they will give you the code on the left. So it's fine. It works. I mean, you are iterating over all the iteration instruction of the function. But if you know a bit better C++, you know that you can put range instead of row iterators. And if you know the instruction iterators from LLVM, you know that you can use instruction of F to just get all the instruction of F. All the code works, but arguably the codes on the right are easier to read, and in the end easier to maintain, especially if you consider that there are a lot of examples like this in the code. It adds up, and so simplifying stuff is nice sometimes. So it's not a problem of Stack Overflow or anything. It's just that the answer in Stack Overflow or in the slides are old, like from 2015. Like if you would update the answer, it would just be the option on the right. Another thing I want to talk about, and that I've seen a lot in ParCoach, is iterating over something, but putting a predicate. Like I want to iterate through this stuff, but only if this stuff is true for some predicate. So you can do stuff like that, early, continuous, or nested if. But if you know the STL extra from LLVM, you know that you can create filtered range for any range, actually. So you pass a range, you pass a predicate, and inside the loop, you just get the object you're looking for. Again, it's a simple predicate, so it doesn't matter much as is, but if you add some more stuff, it starts like growing up, and maintenance became a bit harder, readability is impacted too. So this is something to consider. Now, something more like critical is advanced data types. There are a lot of data types in LLVM, and if you are not familiar with LLVM, and I've seen a lot of code like this, you will just use whatever data types is available in the STL, and you will get a map, for instance, use some helper. And the actual issue starts when input, the map of instruction, you want to map an instruction to something. If you go through the input and change an instruction, like if you delete it, or if you replace all the uses with some other value, what happens to the instruction in the map? So with raw map from the STL, like there is no mechanism, so nothing happens, and you end up iterating or trying to find something which is not valid anymore, whereas if you are aware of the data types from LLVM, you are able to use some kind of value map which has specific handle to remove the value or update the value if it is changed during the life of the value. So some other helper that are quite nice, I mean, it's not a big deal, but for instance, instead of using std-finif, you can use LLVM-finif and just put a range, instead of just like the individual iterator, in this case, it's not a big deal, but it's actually quite nice. But basically, every stuff like that, I've encountered this for a lot of kind of code where you would be able to replace most of the occurrences with any vector from the LLVM array advanced data types, or like a array or string array, like there are a lot of stuff in LLVM that you may not be aware of and that makes your code quite nicer if you use them. So yeah, dealing with it, so you may think, okay, this guy is just being picky with people who are writing the code. It may be true. I will argue that it depends on actually who makes the contribution, because you cannot expect the same level of contribution from a student or from a LLVM engineer, and like especially when you're a PhD student, you have, I don't know, a deadline, you just want a tool who does something, like you're not going to spend times and times on how you do stuff as long as it works, at least that's my experience dealing with that. But in my opinion, the accumulation of small details matters, and it was very explicit in the case of Barcoach, because I came after like maybe five, six years where the accumulation of researchers and PhD students like led to a lot of technical depths, and if there was some advice that were given to the PhD students or the researcher, it would have been a way nicer code to read or to maintain. And so obviously, it's quite obvious, but doing code reviews helps a lot. Sometimes you cannot do them if there is no one able to actually provide some useful feedback on this, like in the case when people don't know LLVM, you cannot expect them to review code and provide some, a lot of feedback. But what I do know is I redirect every time to the LLVM programmers manual, it's not like the first thing you usually just go to a search engine and search for what you want. But I will argue that actually reading the program manual is more helpful in that, in this specific case. And something that I know people don't want to do when they are starting LLVM is just read the code from the passes in LLVM, there are a lot of good stuff in there. Obviously, if you're not familiar with C++ and LLVM, it's not the easiest, but I think it's still worth it. So the next topic is updating the LLVM versions. So far, when I've developed out of three tools, I've always set the version to one specific number, right? And like let's say LLVM 9. And then when LLVM 10 comes out, you rebase your plug-in and check if any API broke, if there was like some changes in the IR. Most recently, I am thinking about Opak pointers, it was quite a big change when updating the LLVM version. And something to consider when doing this is that it may be time-consuming, like a lot of time can be spent in, it may be like just a day if there were no changes in the API, but it could also be very time-consuming for instance if you have to change all your passes because it's been three years that the new pass manager was out and you still didn't do the migration and now suddenly it's deprecating and it's going to be removed, so you need to migrate your passes, so you have to do it. And in my experience, it's quite obvious too, but skipping versions makes it worse. And some things that I've seen, and I know sometimes it cannot be avoided, but in that case it was avoidable, but basically trying to support multiple LLVM versions at once, like say support from LLVM 9 through 12, it's actually what was done, and yeah, don't do it. Just pick a version and stay like this, because otherwise it's just multiple if-deaf and everyone in the code and it's unmaintainable, I think. So now let's talk about passes. If you look for a hello world pass on the internet, you will get a hello world pass, which is a transformation pass. So in LLVM, you have two kind of passes, the first kind is analysis, and basically they don't touch the IR, you just look at the IR and maybe provide some result, which is a result of the analysis and that can be used by transformation passes or other analysis. And there are the transformation passes, which may or may not change the IR. And obviously, when you get your hello world pass, you want to do everything in it. Like, I mean, I'm not talking about LLVM developers, I'm talking about students and researchers that have the pass and they put everything in it. And so it's fine when it's just like one shot or something like that, but in the time, at some point, both the analysis and the transformation are semantically different, and LLVM has some mechanism to make it easy for you to have the analysis run only when it's needed, right? There is a caching mechanism, you can say, okay, I want this analysis for this object and if it exists, it will give it back to you. And also, it avoids passing structure around because when you are in a transformation pass, you can request any analysis from basically anywhere as long as you have the analysis manager. And so this is something that has costed me quite some time, like just untangling the analysis code from the transformation code, and overall, it improved the performances because some analyses were requested more than once for the same object. And yes, it leads me to investigating performance issues because it was something too. So what happens when you don't know LLVM and you want to debug your code? You put LLVM errors everywhere and you command them out when your code is ready, okay? So it's a nightmare, I mean, it works, but you're not supposed to do it like this. So specifically for like printf like debug stuff, you have some LLVM helper, it's actually quite handy. You just put a debug type somewhere and you dot CPP, you wrap everything in LLVM debug because it does all the things for you if you don't include debug information, it doesn't even appear in the binary. And when you're running your pass without, you can say, okay, I want to show debug information for this kind of pass and it basically provides the same feature and you don't have to command out LLVM errors. The other thing is timing your code, being able to tell, okay, this part of the transformation is costing me time. And so what I've seen was some manual attempt to do timers and basically declare all the timers, you start them manually and it starts being a mess really quick. Hopefully, thankfully, now we have a time trace scope. It was, I think it's what's used when you use a F time trace when starting clung. And so basically it's just one line, you put one variable and when it's constricted, it starts a scope and it starts a timer and when it's destructed, it stops the timer. And LLVM has a whole system for this and it emits a JSON and you get, if you put this in this JSON speed scope, you get something like that. And you can see basically everything in your code without having to do anything. You get the entry point, you get the analysis and here it was quite obvious for us was the changes, what the changes were because this analysis, for instance, was called multiple times but it was for the same object. So like for instance, it would appear here too but because of the caching mechanism and the untangling, it basically just, it was just called once. So this is something nice that you get basically for free. So now let's, okay, some conclusion on the tool development, so it's a fairly basic conclusion. Try to invest in maintenance. I know it's not always possible, especially in a scientific project but it's worth it. Don't remember the wheel. If you want to do something in LLVM, it likely has already something in LLVM for this. And keep the this minimal. One of the main weakness of Parkour right now is that we use some passes which exist already in LLVM. I'm thinking about memory SSA for instance, we use some copies of this and from a maintenance point of view, it's not quite nice so we need to migrate this away. And if your passes can be useful to others, just try to upstream them, I mean if you don't use them, you don't have to pay for them. Then let's talk a bit about usability because it's quite a big deal for a tool because you want it to be usable. So first, from a developer point of view, if your developers are going to be non-LLVM folks, you don't want them to go into the LLVM install and stuff so I've had good experience with using Docker and basically provide a Docker image with the LLVM compiled installed somewhere or just installed using the APT repositories and have some clear CI, like how to build your tool, like just looking at the CI should be enough to know how to build your tool from a developer point of view. And the other great thing is when you use LLVM, you get LLVM tools with it. So you get a lead and five check and so instead of going through some manual testing and stuff, you can just use them and it's actually quite nice. And yes, of course, I could talk about coding standards but basically since you're making a plugin or a tool for LLVM, it makes sense to follow the same standard and you have already clonk format and clonk tidy configuration for this. Now, as a user, you obviously don't want a scientific application developer to compile your code from source, you want them to just have the plugin and use it or have the tool and use it. If you look at Hello World passes, you see a lot of times that you have to first get the IR. So in our case, it's either from clonk or from clonk and you have to call out, load the path manually and call the path manually. So I would argue this is not nice enough for researchers and students and since Spark Coach is a verification tool, we cannot expect users to call it on every single file. So we actually had to do some more tooling to create some wrapper which takes the original compiler invocation, runs the original compiler invocation, generates temporary IR and then runs the tool over it. It makes it much more easy for the users to just integrate with auto tools or CMake. So that makes the tool more user friendly than I would say unusual. And the other part is how do you get the tool? So again, I've had good experience with Docker especially for students because it's easy for them. And sometimes obviously we also provide some package for major distributions but you actually have to worry about how is LLVM packaged on the target system because depending on what is available, how is it shared libraries, Dalib and stuff, it's not the same thing. And yeah, Docker, it's not something you can quite use on shared HPC clusters, you're more looking at stuff like geeks for instance when targeting such platforms. So for this, you need some packaging. And packaging is my last point. So obviously we used to use do-it-yourself approach, basically just create a shared library and hope for the best, it doesn't work. Because you depend on how opt is installed and compiled because you're loading dynamically a library into opt. So if you have not used the same like C++ libraries, you're going to run into issues. You don't know for sure which pass manager is enabled by default in opt. So there is also this. So we've moved to doing some proper packages for APT.deb and for geeks and for Red Hat 2 because we have some users using some custom version of Red Hat. And for this, we actually have quite an interesting issue because we are sure that the LL version in their image is not available. So we made the choice of shipping just one single static tool. And for this, it was actually quite easy because as I said, when I talked about CMake, you just say, OK, I want this to be linked statically or as a shared library and CMake, LLVM CMake handles it for you. And it was quite a nice experience for us to package for so many distribution without having to worry too much about CMake option and stuff. So some takeaways for the whole talk. In my opinion, the LLVM integration has evolved a lot and in a good direction. It's way easier to integrate with LLVM now than it was 10 years ago. It's nice, but it's nice to say it because when nice stuff happens, you have to say it too. Be prepared for maintenance. If you want to create a not-off-tree tool, you have to invest in maintenance both for LLVM rebases and basically reviews and make sure that your contributors, if you are able to provide some LLVM guidance to your contributors, do it and it's worth it. Investing in CI is worth it, obviously. And LLVM documentation, I would definitely, every day, recommend going to the LLVM documentation rather than Google for understanding what is available in LLVM. And I want to encourage my students to read LLVM source code, but it's sometimes a bit hard. So if you have questions or comments, feel free and I will be happy to answer them. Yeah. So the question is for the wrapper we created, what do we use to create this wrapper, right? So basically, it's a very, very small LLVM tool, maybe you are familiar with not in LLVM. There is a very small utility in LLVM which just does not on the return of a program. And it's a very small LLVM tool based on LLVM. And we use a similar approach. Basically we say, okay, I created basically an empty main where I just use the LLVM support library to get the benefit from like argument parsing and the data types and so on. And I just parse the command line and call successively clang the original compiler line. And then I just generate the intermediate representation for it by adding the appropriate flag and filtering out the other object generation flags. And then I just run the tool over it. Yes, yes, because you can just, for instance, with CMake, you can use the CMake C launcher basically just like Ccache work for LLVM, you just change the launcher and you can use the tool to launch the compiler. And for other tools, you can actually, actually in our project we use MPICC but we are able to change if compiler used for MPICC and say, okay, use instead of GCC for instance. So the question is when you ship your tool, do you link statically or dynamically? So actually both. When shipping for Red Hat because we don't have a control over what package are in their custom image, we ship statically because we are not sure about which LLVM we are going to have. So we just, the binary is 100 megabyte but we don't have much choice. And when shipping for system like Ubuntu or Debian, we just ship the dependence on the shared libraries. So the question is, when we're basing the tool from one LL version to the next one, do you use the changelog developers put their love into and if yes, is it helpful? Unfortunately the answer is no. But that's because I look at the LLVM weeklies so I kind of know what happens. This is just my way of doing stuff, yeah, so no, but if I would look into the changelog, I would find helpful information I'm sure. So the question is, am I trying to rebase as LLVM progresses or am I just rebasing every version when it's released and it's only when a release came out, comes out, I do the rebase. It's easier because otherwise, you know, depending on what kind of target you ship for, it's hard and it's just simpler to say, okay, we know and then, we know we need to rebase the version and it's fine. I think we're out of time now, thank you Philippe.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 29.92, "text": " I'm sorry for the wrong title, but you know, naming is hard, so I had to put something.", "tokens": [286, 478, 2597, 337, 264, 2085, 4876, 11, 457, 291, 458, 11, 25290, 307, 1152, 11, 370, 286, 632, 281, 829, 746, 13], "temperature": 0.0, "avg_logprob": -0.5761645634969076, "compression_ratio": 1.0740740740740742, "no_speech_prob": 0.4310189485549927}, {"id": 1, "seek": 2992, "start": 29.92, "end": 35.46, "text": " But today, I want to talk to you about my experience with dealing with out-of-tree", "tokens": [583, 965, 11, 286, 528, 281, 751, 281, 291, 466, 452, 1752, 365, 6260, 365, 484, 12, 2670, 12, 83, 701], "temperature": 0.0, "avg_logprob": -0.29066997265997735, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.0011786880204454064}, {"id": 2, "seek": 2992, "start": 35.46, "end": 37.36, "text": " plug-in and tools for LLVM.", "tokens": [5452, 12, 259, 293, 3873, 337, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.29066997265997735, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.0011786880204454064}, {"id": 3, "seek": 2992, "start": 37.36, "end": 42.2, "text": " Parkoach is just one example, and I will give some others.", "tokens": [4964, 78, 608, 307, 445, 472, 1365, 11, 293, 286, 486, 976, 512, 2357, 13], "temperature": 0.0, "avg_logprob": -0.29066997265997735, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.0011786880204454064}, {"id": 4, "seek": 2992, "start": 42.2, "end": 47.8, "text": " So first of all, I will try to explain to you why and for whom am I doing this talk.", "tokens": [407, 700, 295, 439, 11, 286, 486, 853, 281, 2903, 281, 291, 983, 293, 337, 7101, 669, 286, 884, 341, 751, 13], "temperature": 0.0, "avg_logprob": -0.29066997265997735, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.0011786880204454064}, {"id": 5, "seek": 2992, "start": 47.8, "end": 49.92, "text": " So you know the audience.", "tokens": [407, 291, 458, 264, 4034, 13], "temperature": 0.0, "avg_logprob": -0.29066997265997735, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.0011786880204454064}, {"id": 6, "seek": 2992, "start": 49.92, "end": 52.24, "text": " I'm going to talk about three different things.", "tokens": [286, 478, 516, 281, 751, 466, 1045, 819, 721, 13], "temperature": 0.0, "avg_logprob": -0.29066997265997735, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.0011786880204454064}, {"id": 7, "seek": 2992, "start": 52.24, "end": 54.2, "text": " The first one is keeping up with LLVM.", "tokens": [440, 700, 472, 307, 5145, 493, 365, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.29066997265997735, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.0011786880204454064}, {"id": 8, "seek": 2992, "start": 54.2, "end": 55.56, "text": " So we will see some code.", "tokens": [407, 321, 486, 536, 512, 3089, 13], "temperature": 0.0, "avg_logprob": -0.29066997265997735, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.0011786880204454064}, {"id": 9, "seek": 2992, "start": 55.56, "end": 58.24, "text": " She makes C++ and stuff.", "tokens": [1240, 1669, 383, 25472, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.29066997265997735, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.0011786880204454064}, {"id": 10, "seek": 5824, "start": 58.24, "end": 62.68, "text": " The second point is usability, both from a developer, a tool developer point of view", "tokens": [440, 1150, 935, 307, 46878, 11, 1293, 490, 257, 10754, 11, 257, 2290, 10754, 935, 295, 1910], "temperature": 0.0, "avg_logprob": -0.1656135982937283, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.00010669617768144235}, {"id": 11, "seek": 5824, "start": 62.68, "end": 65.04, "text": " and a user point of view.", "tokens": [293, 257, 4195, 935, 295, 1910, 13], "temperature": 0.0, "avg_logprob": -0.1656135982937283, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.00010669617768144235}, {"id": 12, "seek": 5824, "start": 65.04, "end": 72.72, "text": " And the final point will be dealing with packaging when you're actually targeting some system.", "tokens": [400, 264, 2572, 935, 486, 312, 6260, 365, 16836, 562, 291, 434, 767, 17918, 512, 1185, 13], "temperature": 0.0, "avg_logprob": -0.1656135982937283, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.00010669617768144235}, {"id": 13, "seek": 5824, "start": 72.72, "end": 74.96000000000001, "text": " So why am I doing this talk?", "tokens": [407, 983, 669, 286, 884, 341, 751, 30], "temperature": 0.0, "avg_logprob": -0.1656135982937283, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.00010669617768144235}, {"id": 14, "seek": 5824, "start": 74.96000000000001, "end": 81.8, "text": " First of all, it's to provide some feedback and maybe provide you with some stuff I wish", "tokens": [2386, 295, 439, 11, 309, 311, 281, 2893, 512, 5824, 293, 1310, 2893, 291, 365, 512, 1507, 286, 3172], "temperature": 0.0, "avg_logprob": -0.1656135982937283, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.00010669617768144235}, {"id": 15, "seek": 5824, "start": 81.8, "end": 88.0, "text": " I knew beforehand before coming into this.", "tokens": [286, 2586, 22893, 949, 1348, 666, 341, 13], "temperature": 0.0, "avg_logprob": -0.1656135982937283, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.00010669617768144235}, {"id": 16, "seek": 8800, "start": 88.0, "end": 91.96, "text": " I'm doing this also because I've learned a couple of out-of-tree projects, and I've", "tokens": [286, 478, 884, 341, 611, 570, 286, 600, 3264, 257, 1916, 295, 484, 12, 2670, 12, 83, 701, 4455, 11, 293, 286, 600], "temperature": 0.0, "avg_logprob": -0.18757241232353344, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0004341663443483412}, {"id": 17, "seek": 8800, "start": 91.96, "end": 93.92, "text": " faced the same issues.", "tokens": [11446, 264, 912, 2663, 13], "temperature": 0.0, "avg_logprob": -0.18757241232353344, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0004341663443483412}, {"id": 18, "seek": 8800, "start": 93.92, "end": 97.44, "text": " So maybe you've faced them too, and it will be helpful.", "tokens": [407, 1310, 291, 600, 11446, 552, 886, 11, 293, 309, 486, 312, 4961, 13], "temperature": 0.0, "avg_logprob": -0.18757241232353344, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0004341663443483412}, {"id": 19, "seek": 8800, "start": 97.44, "end": 103.68, "text": " So it's not so much about the tool parkoach itself, it's rather about the approach.", "tokens": [407, 309, 311, 406, 370, 709, 466, 264, 2290, 3884, 78, 608, 2564, 11, 309, 311, 2831, 466, 264, 3109, 13], "temperature": 0.0, "avg_logprob": -0.18757241232353344, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0004341663443483412}, {"id": 20, "seek": 8800, "start": 103.68, "end": 109.72, "text": " And for whom, it's basically anyone who is involved in an out-of-tree project for LLVM.", "tokens": [400, 337, 7101, 11, 309, 311, 1936, 2878, 567, 307, 3288, 294, 364, 484, 12, 2670, 12, 83, 701, 1716, 337, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.18757241232353344, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0004341663443483412}, {"id": 21, "seek": 8800, "start": 109.72, "end": 113.96000000000001, "text": " This is my own point of view on this topic.", "tokens": [639, 307, 452, 1065, 935, 295, 1910, 322, 341, 4829, 13], "temperature": 0.0, "avg_logprob": -0.18757241232353344, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0004341663443483412}, {"id": 22, "seek": 11396, "start": 113.96, "end": 119.91999999999999, "text": " If you have ideas, comments, like improvements that you think may be helpful to me, don't", "tokens": [759, 291, 362, 3487, 11, 3053, 11, 411, 13797, 300, 291, 519, 815, 312, 4961, 281, 385, 11, 500, 380], "temperature": 0.0, "avg_logprob": -0.2347551859342135, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.0001352430845145136}, {"id": 23, "seek": 11396, "start": 119.91999999999999, "end": 120.91999999999999, "text": " hesitate.", "tokens": [20842, 13], "temperature": 0.0, "avg_logprob": -0.2347551859342135, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.0001352430845145136}, {"id": 24, "seek": 11396, "start": 120.91999999999999, "end": 122.63999999999999, "text": " I will welcome them.", "tokens": [286, 486, 2928, 552, 13], "temperature": 0.0, "avg_logprob": -0.2347551859342135, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.0001352430845145136}, {"id": 25, "seek": 11396, "start": 122.63999999999999, "end": 126.63999999999999, "text": " So parkoach is a tool for HPC application.", "tokens": [407, 3884, 78, 608, 307, 257, 2290, 337, 12557, 34, 3861, 13], "temperature": 0.0, "avg_logprob": -0.2347551859342135, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.0001352430845145136}, {"id": 26, "seek": 11396, "start": 126.63999999999999, "end": 132.56, "text": " It's basically an instrumentation, analysis and instrumentation tool for OpenMP and MPI", "tokens": [467, 311, 1936, 364, 7198, 399, 11, 5215, 293, 7198, 399, 2290, 337, 7238, 12224, 293, 14146, 40], "temperature": 0.0, "avg_logprob": -0.2347551859342135, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.0001352430845145136}, {"id": 27, "seek": 11396, "start": 132.56, "end": 133.56, "text": " application.", "tokens": [3861, 13], "temperature": 0.0, "avg_logprob": -0.2347551859342135, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.0001352430845145136}, {"id": 28, "seek": 11396, "start": 133.56, "end": 138.76, "text": " It basically checks that the user is using the APIs appropriately, that there are no", "tokens": [467, 1936, 13834, 300, 264, 4195, 307, 1228, 264, 21445, 23505, 11, 300, 456, 366, 572], "temperature": 0.0, "avg_logprob": -0.2347551859342135, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.0001352430845145136}, {"id": 29, "seek": 11396, "start": 138.76, "end": 141.72, "text": " deadlock or data racism.", "tokens": [3116, 4102, 420, 1412, 12664, 13], "temperature": 0.0, "avg_logprob": -0.2347551859342135, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.0001352430845145136}, {"id": 30, "seek": 11396, "start": 141.72, "end": 142.72, "text": " The developers.", "tokens": [440, 8849, 13], "temperature": 0.0, "avg_logprob": -0.2347551859342135, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.0001352430845145136}, {"id": 31, "seek": 14272, "start": 142.72, "end": 146.0, "text": " This is where it gets interesting, because they are not like LLVM engineers, right?", "tokens": [639, 307, 689, 309, 2170, 1880, 11, 570, 436, 366, 406, 411, 441, 43, 53, 44, 11955, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19475489807128907, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00016521700308658183}, {"id": 32, "seek": 14272, "start": 146.0, "end": 150.76, "text": " They are interns, students, PhD students, researchers.", "tokens": [814, 366, 46145, 11, 1731, 11, 14476, 1731, 11, 10309, 13], "temperature": 0.0, "avg_logprob": -0.19475489807128907, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00016521700308658183}, {"id": 33, "seek": 14272, "start": 150.76, "end": 155.88, "text": " They have a whole job, which is not LLVM.", "tokens": [814, 362, 257, 1379, 1691, 11, 597, 307, 406, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.19475489807128907, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00016521700308658183}, {"id": 34, "seek": 14272, "start": 155.88, "end": 159.07999999999998, "text": " The users of the tool, they are scientific application developers.", "tokens": [440, 5022, 295, 264, 2290, 11, 436, 366, 8134, 3861, 8849, 13], "temperature": 0.0, "avg_logprob": -0.19475489807128907, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00016521700308658183}, {"id": 35, "seek": 14272, "start": 159.07999999999998, "end": 162.44, "text": " So you cannot ask them to compile LLVM from the source.", "tokens": [407, 291, 2644, 1029, 552, 281, 31413, 441, 43, 53, 44, 490, 264, 4009, 13], "temperature": 0.0, "avg_logprob": -0.19475489807128907, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00016521700308658183}, {"id": 36, "seek": 14272, "start": 162.44, "end": 163.44, "text": " It's not going to work.", "tokens": [467, 311, 406, 516, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.19475489807128907, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00016521700308658183}, {"id": 37, "seek": 14272, "start": 163.44, "end": 167.16, "text": " They are not going to use your tool.", "tokens": [814, 366, 406, 516, 281, 764, 428, 2290, 13], "temperature": 0.0, "avg_logprob": -0.19475489807128907, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00016521700308658183}, {"id": 38, "seek": 14272, "start": 167.16, "end": 171.76, "text": " And the last part, which is interesting with this project, it started a long time ago when", "tokens": [400, 264, 1036, 644, 11, 597, 307, 1880, 365, 341, 1716, 11, 309, 1409, 257, 938, 565, 2057, 562], "temperature": 0.0, "avg_logprob": -0.19475489807128907, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00016521700308658183}, {"id": 39, "seek": 17176, "start": 171.76, "end": 176.2, "text": " it was LLVM 3.7, and now it's based on LLVM 15.", "tokens": [309, 390, 441, 43, 53, 44, 805, 13, 22, 11, 293, 586, 309, 311, 2361, 322, 441, 43, 53, 44, 2119, 13], "temperature": 0.0, "avg_logprob": -0.18011026533823166, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0001911623403429985}, {"id": 40, "seek": 17176, "start": 176.2, "end": 179.51999999999998, "text": " So there has been a lot of history in the tool.", "tokens": [407, 456, 575, 668, 257, 688, 295, 2503, 294, 264, 2290, 13], "temperature": 0.0, "avg_logprob": -0.18011026533823166, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0001911623403429985}, {"id": 41, "seek": 17176, "start": 179.51999999999998, "end": 180.92, "text": " And I'm working on it right now.", "tokens": [400, 286, 478, 1364, 322, 309, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.18011026533823166, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0001911623403429985}, {"id": 42, "seek": 17176, "start": 180.92, "end": 185.84, "text": " It's my main job, so they have an LLVM engineer now, and I can do stuff.", "tokens": [467, 311, 452, 2135, 1691, 11, 370, 436, 362, 364, 441, 43, 53, 44, 11403, 586, 11, 293, 286, 393, 360, 1507, 13], "temperature": 0.0, "avg_logprob": -0.18011026533823166, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0001911623403429985}, {"id": 43, "seek": 17176, "start": 185.84, "end": 188.79999999999998, "text": " I provided the link for reference if you want to take a look.", "tokens": [286, 5649, 264, 2113, 337, 6408, 498, 291, 528, 281, 747, 257, 574, 13], "temperature": 0.0, "avg_logprob": -0.18011026533823166, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0001911623403429985}, {"id": 44, "seek": 17176, "start": 188.79999999999998, "end": 192.6, "text": " There are two other motivating projects that I can talk about.", "tokens": [821, 366, 732, 661, 41066, 4455, 300, 286, 393, 751, 466, 13], "temperature": 0.0, "avg_logprob": -0.18011026533823166, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0001911623403429985}, {"id": 45, "seek": 17176, "start": 192.6, "end": 196.28, "text": " One, I'm actually not going to talk about much, because it's not free.", "tokens": [1485, 11, 286, 478, 767, 406, 516, 281, 751, 466, 709, 11, 570, 309, 311, 406, 1737, 13], "temperature": 0.0, "avg_logprob": -0.18011026533823166, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0001911623403429985}, {"id": 46, "seek": 19628, "start": 196.28, "end": 202.16, "text": " It's a commercial compiler, which is based on LLVM, and basically the developers are", "tokens": [467, 311, 257, 6841, 31958, 11, 597, 307, 2361, 322, 441, 43, 53, 44, 11, 293, 1936, 264, 8849, 366], "temperature": 0.0, "avg_logprob": -0.1485600471496582, "compression_ratio": 1.6866952789699572, "no_speech_prob": 6.569691322511062e-05}, {"id": 47, "seek": 19628, "start": 202.16, "end": 207.36, "text": " LLVM engineers, so we have more flexibility when doing developments.", "tokens": [441, 43, 53, 44, 11955, 11, 370, 321, 362, 544, 12635, 562, 884, 20862, 13], "temperature": 0.0, "avg_logprob": -0.1485600471496582, "compression_ratio": 1.6866952789699572, "no_speech_prob": 6.569691322511062e-05}, {"id": 48, "seek": 19628, "start": 207.36, "end": 212.6, "text": " And the users are clients who are paying for the compiler, so we need it to provide something", "tokens": [400, 264, 5022, 366, 6982, 567, 366, 6229, 337, 264, 31958, 11, 370, 321, 643, 309, 281, 2893, 746], "temperature": 0.0, "avg_logprob": -0.1485600471496582, "compression_ratio": 1.6866952789699572, "no_speech_prob": 6.569691322511062e-05}, {"id": 49, "seek": 19628, "start": 212.6, "end": 215.72, "text": " good.", "tokens": [665, 13], "temperature": 0.0, "avg_logprob": -0.1485600471496582, "compression_ratio": 1.6866952789699572, "no_speech_prob": 6.569691322511062e-05}, {"id": 50, "seek": 19628, "start": 215.72, "end": 218.56, "text": " And the other point is student LLVM exercises.", "tokens": [400, 264, 661, 935, 307, 3107, 441, 43, 53, 44, 11900, 13], "temperature": 0.0, "avg_logprob": -0.1485600471496582, "compression_ratio": 1.6866952789699572, "no_speech_prob": 6.569691322511062e-05}, {"id": 51, "seek": 19628, "start": 218.56, "end": 225.36, "text": " I do courses, LLVM courses for security students, and I want them to be able to do some code", "tokens": [286, 360, 7712, 11, 441, 43, 53, 44, 7712, 337, 3825, 1731, 11, 293, 286, 528, 552, 281, 312, 1075, 281, 360, 512, 3089], "temperature": 0.0, "avg_logprob": -0.1485600471496582, "compression_ratio": 1.6866952789699572, "no_speech_prob": 6.569691322511062e-05}, {"id": 52, "seek": 22536, "start": 225.36, "end": 227.76000000000002, "text": " transformation with LLVM.", "tokens": [9887, 365, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.16725073022357487, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0001462336804252118}, {"id": 53, "seek": 22536, "start": 227.76000000000002, "end": 232.68, "text": " So the developer is just a friend of mine and me, and the users are students.", "tokens": [407, 264, 10754, 307, 445, 257, 1277, 295, 3892, 293, 385, 11, 293, 264, 5022, 366, 1731, 13], "temperature": 0.0, "avg_logprob": -0.16725073022357487, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0001462336804252118}, {"id": 54, "seek": 22536, "start": 232.68, "end": 238.20000000000002, "text": " We are expecting them to code into the project, so we need to make it easy for them to get", "tokens": [492, 366, 9650, 552, 281, 3089, 666, 264, 1716, 11, 370, 321, 643, 281, 652, 309, 1858, 337, 552, 281, 483], "temperature": 0.0, "avg_logprob": -0.16725073022357487, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0001462336804252118}, {"id": 55, "seek": 22536, "start": 238.20000000000002, "end": 239.20000000000002, "text": " into.", "tokens": [666, 13], "temperature": 0.0, "avg_logprob": -0.16725073022357487, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0001462336804252118}, {"id": 56, "seek": 22536, "start": 239.20000000000002, "end": 246.44000000000003, "text": " And we have 16 hours to do this project, and they cannot spend two hours like installing", "tokens": [400, 321, 362, 3165, 2496, 281, 360, 341, 1716, 11, 293, 436, 2644, 3496, 732, 2496, 411, 20762], "temperature": 0.0, "avg_logprob": -0.16725073022357487, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0001462336804252118}, {"id": 57, "seek": 22536, "start": 246.44000000000003, "end": 247.44000000000003, "text": " LLVM.", "tokens": [441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.16725073022357487, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0001462336804252118}, {"id": 58, "seek": 22536, "start": 247.44000000000003, "end": 250.20000000000002, "text": " It's not going to work either.", "tokens": [467, 311, 406, 516, 281, 589, 2139, 13], "temperature": 0.0, "avg_logprob": -0.16725073022357487, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0001462336804252118}, {"id": 59, "seek": 22536, "start": 250.20000000000002, "end": 254.0, "text": " So in all this project, I am considered pretty much the same issues, so I'm going to talk", "tokens": [407, 294, 439, 341, 1716, 11, 286, 669, 4888, 1238, 709, 264, 912, 2663, 11, 370, 286, 478, 516, 281, 751], "temperature": 0.0, "avg_logprob": -0.16725073022357487, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0001462336804252118}, {"id": 60, "seek": 25400, "start": 254.0, "end": 257.76, "text": " about them now, and the first one is keeping up with LLVM.", "tokens": [466, 552, 586, 11, 293, 264, 700, 472, 307, 5145, 493, 365, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.18299108181359633, "compression_ratio": 1.5381355932203389, "no_speech_prob": 0.000291796081000939}, {"id": 61, "seek": 25400, "start": 257.76, "end": 261.88, "text": " So I'm not sure if it was intentional in the schedule, but having a talk with you about", "tokens": [407, 286, 478, 406, 988, 498, 309, 390, 21935, 294, 264, 7567, 11, 457, 1419, 257, 751, 365, 291, 466], "temperature": 0.0, "avg_logprob": -0.18299108181359633, "compression_ratio": 1.5381355932203389, "no_speech_prob": 0.000291796081000939}, {"id": 62, "seek": 25400, "start": 261.88, "end": 266.32, "text": " CMake and stuff, it's quite helpful because I don't have to go too deep in the details.", "tokens": [20424, 619, 293, 1507, 11, 309, 311, 1596, 4961, 570, 286, 500, 380, 362, 281, 352, 886, 2452, 294, 264, 4365, 13], "temperature": 0.0, "avg_logprob": -0.18299108181359633, "compression_ratio": 1.5381355932203389, "no_speech_prob": 0.000291796081000939}, {"id": 63, "seek": 25400, "start": 266.32, "end": 268.4, "text": " You already know them.", "tokens": [509, 1217, 458, 552, 13], "temperature": 0.0, "avg_logprob": -0.18299108181359633, "compression_ratio": 1.5381355932203389, "no_speech_prob": 0.000291796081000939}, {"id": 64, "seek": 25400, "start": 268.4, "end": 274.6, "text": " So let's go back maybe eight years ago.", "tokens": [407, 718, 311, 352, 646, 1310, 3180, 924, 2057, 13], "temperature": 0.0, "avg_logprob": -0.18299108181359633, "compression_ratio": 1.5381355932203389, "no_speech_prob": 0.000291796081000939}, {"id": 65, "seek": 25400, "start": 274.6, "end": 278.56, "text": " You wanted to do some LLVM tools, there was no CMake integration.", "tokens": [509, 1415, 281, 360, 512, 441, 43, 53, 44, 3873, 11, 456, 390, 572, 20424, 619, 10980, 13], "temperature": 0.0, "avg_logprob": -0.18299108181359633, "compression_ratio": 1.5381355932203389, "no_speech_prob": 0.000291796081000939}, {"id": 66, "seek": 27856, "start": 278.56, "end": 284.76, "text": " The first approach that you had as a developer was either do stuff manually, maybe using", "tokens": [440, 700, 3109, 300, 291, 632, 382, 257, 10754, 390, 2139, 360, 1507, 16945, 11, 1310, 1228], "temperature": 0.0, "avg_logprob": -0.16633274579288984, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.00015753810293972492}, {"id": 67, "seek": 27856, "start": 284.76, "end": 288.84, "text": " LLVM config to get the flags and the libraries and so on.", "tokens": [441, 43, 53, 44, 6662, 281, 483, 264, 23265, 293, 264, 15148, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.16633274579288984, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.00015753810293972492}, {"id": 68, "seek": 27856, "start": 288.84, "end": 291.28000000000003, "text": " But basically, you had no easy way to integrate with LLVM.", "tokens": [583, 1936, 11, 291, 632, 572, 1858, 636, 281, 13365, 365, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.16633274579288984, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.00015753810293972492}, {"id": 69, "seek": 27856, "start": 291.28000000000003, "end": 293.28000000000003, "text": " It was quite manual.", "tokens": [467, 390, 1596, 9688, 13], "temperature": 0.0, "avg_logprob": -0.16633274579288984, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.00015753810293972492}, {"id": 70, "seek": 27856, "start": 293.28000000000003, "end": 299.76, "text": " Then came CMake, and you could use the standard ad library, target link libraries, but you", "tokens": [1396, 1361, 20424, 619, 11, 293, 291, 727, 764, 264, 3832, 614, 6405, 11, 3779, 2113, 15148, 11, 457, 291], "temperature": 0.0, "avg_logprob": -0.16633274579288984, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.00015753810293972492}, {"id": 71, "seek": 27856, "start": 299.76, "end": 305.8, "text": " had to know what to feed these macros with.", "tokens": [632, 281, 458, 437, 281, 3154, 613, 7912, 2635, 365, 13], "temperature": 0.0, "avg_logprob": -0.16633274579288984, "compression_ratio": 1.5973451327433628, "no_speech_prob": 0.00015753810293972492}, {"id": 72, "seek": 30580, "start": 305.8, "end": 313.0, "text": " And some stuff I've encountered in this project is some kind of people who were developing", "tokens": [400, 512, 1507, 286, 600, 20381, 294, 341, 1716, 307, 512, 733, 295, 561, 567, 645, 6416], "temperature": 0.0, "avg_logprob": -0.24061088151829216, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.00016012937703635544}, {"id": 73, "seek": 30580, "start": 313.0, "end": 319.16, "text": " this project were not comfortable with CMake, and they would perform some changes where", "tokens": [341, 1716, 645, 406, 4619, 365, 20424, 619, 11, 293, 436, 576, 2042, 512, 2962, 689], "temperature": 0.0, "avg_logprob": -0.24061088151829216, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.00016012937703635544}, {"id": 74, "seek": 30580, "start": 319.16, "end": 324.08000000000004, "text": " they would actually do CMake integration, but with R-coded passes in the CMake, so it", "tokens": [436, 576, 767, 360, 20424, 619, 10980, 11, 457, 365, 497, 12, 66, 12340, 11335, 294, 264, 20424, 619, 11, 370, 309], "temperature": 0.0, "avg_logprob": -0.24061088151829216, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.00016012937703635544}, {"id": 75, "seek": 30580, "start": 324.08000000000004, "end": 325.64, "text": " would be awkward.", "tokens": [576, 312, 11411, 13], "temperature": 0.0, "avg_logprob": -0.24061088151829216, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.00016012937703635544}, {"id": 76, "seek": 30580, "start": 325.64, "end": 334.92, "text": " So basically now it's, I think, at least from the examples we have, it's way better.", "tokens": [407, 1936, 586, 309, 311, 11, 286, 519, 11, 412, 1935, 490, 264, 5110, 321, 362, 11, 309, 311, 636, 1101, 13], "temperature": 0.0, "avg_logprob": -0.24061088151829216, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.00016012937703635544}, {"id": 77, "seek": 33492, "start": 334.92, "end": 338.88, "text": " So using the LLVM CMake integration simplifies a lot of stuff.", "tokens": [407, 1228, 264, 441, 43, 53, 44, 20424, 619, 10980, 6883, 11221, 257, 688, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.11094542309246232, "compression_ratio": 1.6706349206349207, "no_speech_prob": 9.645180398365483e-05}, {"id": 78, "seek": 33492, "start": 338.88, "end": 345.08000000000004, "text": " You just have basically to know which component of LLVM you want to use, how you want to build", "tokens": [509, 445, 362, 1936, 281, 458, 597, 6542, 295, 441, 43, 53, 44, 291, 528, 281, 764, 11, 577, 291, 528, 281, 1322], "temperature": 0.0, "avg_logprob": -0.11094542309246232, "compression_ratio": 1.6706349206349207, "no_speech_prob": 9.645180398365483e-05}, {"id": 79, "seek": 33492, "start": 345.08000000000004, "end": 348.36, "text": " your library, like is it static or shared basically.", "tokens": [428, 6405, 11, 411, 307, 309, 13437, 420, 5507, 1936, 13], "temperature": 0.0, "avg_logprob": -0.11094542309246232, "compression_ratio": 1.6706349206349207, "no_speech_prob": 9.645180398365483e-05}, {"id": 80, "seek": 33492, "start": 348.36, "end": 355.40000000000003, "text": " And you have dedicated macros to just construct whatever stuff you want to construct for LLVM.", "tokens": [400, 291, 362, 8374, 7912, 2635, 281, 445, 7690, 2035, 1507, 291, 528, 281, 7690, 337, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.11094542309246232, "compression_ratio": 1.6706349206349207, "no_speech_prob": 9.645180398365483e-05}, {"id": 81, "seek": 33492, "start": 355.40000000000003, "end": 357.8, "text": " So let's take an example code.", "tokens": [407, 718, 311, 747, 364, 1365, 3089, 13], "temperature": 0.0, "avg_logprob": -0.11094542309246232, "compression_ratio": 1.6706349206349207, "no_speech_prob": 9.645180398365483e-05}, {"id": 82, "seek": 33492, "start": 357.8, "end": 363.0, "text": " So you don't have to understand everything, just to give an example of how it works.", "tokens": [407, 291, 500, 380, 362, 281, 1223, 1203, 11, 445, 281, 976, 364, 1365, 295, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.11094542309246232, "compression_ratio": 1.6706349206349207, "no_speech_prob": 9.645180398365483e-05}, {"id": 83, "seek": 36300, "start": 363.0, "end": 369.96, "text": " You basically say, okay, I want to find LLVM, provide a version, sometimes, include the", "tokens": [509, 1936, 584, 11, 1392, 11, 286, 528, 281, 915, 441, 43, 53, 44, 11, 2893, 257, 3037, 11, 2171, 11, 4090, 264], "temperature": 0.0, "avg_logprob": -0.2132742903953375, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.00012083437468390912}, {"id": 84, "seek": 36300, "start": 369.96, "end": 376.28, "text": " LLVM CMake helper, and include some definition, and then this is the interesting part.", "tokens": [441, 43, 53, 44, 20424, 619, 36133, 11, 293, 4090, 512, 7123, 11, 293, 550, 341, 307, 264, 1880, 644, 13], "temperature": 0.0, "avg_logprob": -0.2132742903953375, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.00012083437468390912}, {"id": 85, "seek": 36300, "start": 376.28, "end": 380.6, "text": " Because you can say, okay, I want these components in my tool.", "tokens": [1436, 291, 393, 584, 11, 1392, 11, 286, 528, 613, 6677, 294, 452, 2290, 13], "temperature": 0.0, "avg_logprob": -0.2132742903953375, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.00012083437468390912}, {"id": 86, "seek": 36300, "start": 380.6, "end": 386.44, "text": " Call the CMake helper with your plug-in source, and that's it.", "tokens": [7807, 264, 20424, 619, 36133, 365, 428, 5452, 12, 259, 4009, 11, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.2132742903953375, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.00012083437468390912}, {"id": 87, "seek": 38644, "start": 386.44, "end": 393.56, "text": " I mean, the CMake helper will take care of saying, okay, depending on how LLVM is installed,", "tokens": [286, 914, 11, 264, 20424, 619, 36133, 486, 747, 1127, 295, 1566, 11, 1392, 11, 5413, 322, 577, 441, 43, 53, 44, 307, 8899, 11], "temperature": 0.0, "avg_logprob": -0.21324410769018795, "compression_ratio": 1.5555555555555556, "no_speech_prob": 7.214846846181899e-05}, {"id": 88, "seek": 38644, "start": 393.56, "end": 398.92, "text": " like is it just the big dialy, but are there like individual libraries?", "tokens": [411, 307, 309, 445, 264, 955, 5502, 88, 11, 457, 366, 456, 411, 2609, 15148, 30], "temperature": 0.0, "avg_logprob": -0.21324410769018795, "compression_ratio": 1.5555555555555556, "no_speech_prob": 7.214846846181899e-05}, {"id": 89, "seek": 38644, "start": 398.92, "end": 403.44, "text": " It will set up the target link libraries appropriately, and you don't have to think about it.", "tokens": [467, 486, 992, 493, 264, 3779, 2113, 15148, 23505, 11, 293, 291, 500, 380, 362, 281, 519, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.21324410769018795, "compression_ratio": 1.5555555555555556, "no_speech_prob": 7.214846846181899e-05}, {"id": 90, "seek": 38644, "start": 403.44, "end": 406.28, "text": " It's just automatic.", "tokens": [467, 311, 445, 12509, 13], "temperature": 0.0, "avg_logprob": -0.21324410769018795, "compression_ratio": 1.5555555555555556, "no_speech_prob": 7.214846846181899e-05}, {"id": 91, "seek": 38644, "start": 406.28, "end": 411.88, "text": " If you want to like do some tools or pass plug-in, there are macros to do these two.", "tokens": [759, 291, 528, 281, 411, 360, 512, 3873, 420, 1320, 5452, 12, 259, 11, 456, 366, 7912, 2635, 281, 360, 613, 732, 13], "temperature": 0.0, "avg_logprob": -0.21324410769018795, "compression_ratio": 1.5555555555555556, "no_speech_prob": 7.214846846181899e-05}, {"id": 92, "seek": 41188, "start": 411.88, "end": 417.88, "text": " So basically, you just have to figure out which kind of build you want, and CMake LLVM", "tokens": [407, 1936, 11, 291, 445, 362, 281, 2573, 484, 597, 733, 295, 1322, 291, 528, 11, 293, 20424, 619, 441, 43, 53, 44], "temperature": 0.0, "avg_logprob": -0.23234373728434246, "compression_ratio": 1.5930232558139534, "no_speech_prob": 5.8761463151313365e-05}, {"id": 93, "seek": 41188, "start": 417.88, "end": 420.28, "text": " will configure everything for you.", "tokens": [486, 22162, 1203, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.23234373728434246, "compression_ratio": 1.5930232558139534, "no_speech_prob": 5.8761463151313365e-05}, {"id": 94, "seek": 41188, "start": 420.28, "end": 422.84, "text": " There are some useful examples.", "tokens": [821, 366, 512, 4420, 5110, 13], "temperature": 0.0, "avg_logprob": -0.23234373728434246, "compression_ratio": 1.5930232558139534, "no_speech_prob": 5.8761463151313365e-05}, {"id": 95, "seek": 41188, "start": 422.84, "end": 427.64, "text": " For pass plug-ins, there is the buy example, which is basically a new pass plug-in, very", "tokens": [1171, 1320, 5452, 12, 1292, 11, 456, 307, 264, 2256, 1365, 11, 597, 307, 1936, 257, 777, 1320, 5452, 12, 259, 11, 588], "temperature": 0.0, "avg_logprob": -0.23234373728434246, "compression_ratio": 1.5930232558139534, "no_speech_prob": 5.8761463151313365e-05}, {"id": 96, "seek": 41188, "start": 427.64, "end": 428.64, "text": " simple.", "tokens": [2199, 13], "temperature": 0.0, "avg_logprob": -0.23234373728434246, "compression_ratio": 1.5930232558139534, "no_speech_prob": 5.8761463151313365e-05}, {"id": 97, "seek": 41188, "start": 428.64, "end": 430.0, "text": " It's a kind of a hello world.", "tokens": [467, 311, 257, 733, 295, 257, 7751, 1002, 13], "temperature": 0.0, "avg_logprob": -0.23234373728434246, "compression_ratio": 1.5930232558139534, "no_speech_prob": 5.8761463151313365e-05}, {"id": 98, "seek": 41188, "start": 430.0, "end": 435.56, "text": " And LLVM tutor has some out-of-three passes to get you started with, and it's actually", "tokens": [400, 441, 43, 53, 44, 35613, 575, 512, 484, 12, 2670, 12, 27583, 11335, 281, 483, 291, 1409, 365, 11, 293, 309, 311, 767], "temperature": 0.0, "avg_logprob": -0.23234373728434246, "compression_ratio": 1.5930232558139534, "no_speech_prob": 5.8761463151313365e-05}, {"id": 99, "seek": 41188, "start": 435.56, "end": 438.56, "text": " quite helpful if you are looking into this.", "tokens": [1596, 4961, 498, 291, 366, 1237, 666, 341, 13], "temperature": 0.0, "avg_logprob": -0.23234373728434246, "compression_ratio": 1.5930232558139534, "no_speech_prob": 5.8761463151313365e-05}, {"id": 100, "seek": 43856, "start": 438.56, "end": 446.28000000000003, "text": " No, let's talk about some code.", "tokens": [883, 11, 718, 311, 751, 466, 512, 3089, 13], "temperature": 0.0, "avg_logprob": -0.18340748476694865, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00032633563387207687}, {"id": 101, "seek": 43856, "start": 446.28000000000003, "end": 453.92, "text": " So let's say you're new to LLVM, pretty new to C++, your student, for instance, and you", "tokens": [407, 718, 311, 584, 291, 434, 777, 281, 441, 43, 53, 44, 11, 1238, 777, 281, 383, 25472, 11, 428, 3107, 11, 337, 5197, 11, 293, 291], "temperature": 0.0, "avg_logprob": -0.18340748476694865, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00032633563387207687}, {"id": 102, "seek": 43856, "start": 453.92, "end": 456.6, "text": " want to perform some LLVM transformation.", "tokens": [528, 281, 2042, 512, 441, 43, 53, 44, 9887, 13], "temperature": 0.0, "avg_logprob": -0.18340748476694865, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00032633563387207687}, {"id": 103, "seek": 43856, "start": 456.6, "end": 464.76, "text": " So you go on your search engine, and you look for how do I iterate over instructions of", "tokens": [407, 291, 352, 322, 428, 3164, 2848, 11, 293, 291, 574, 337, 577, 360, 286, 44497, 670, 9415, 295], "temperature": 0.0, "avg_logprob": -0.18340748476694865, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00032633563387207687}, {"id": 104, "seek": 43856, "start": 464.76, "end": 467.68, "text": " LLVM function?", "tokens": [441, 43, 53, 44, 2445, 30], "temperature": 0.0, "avg_logprob": -0.18340748476694865, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00032633563387207687}, {"id": 105, "seek": 46768, "start": 467.68, "end": 471.84000000000003, "text": " And pretty much all the resources like Stack Overflow or even some presentations, they will", "tokens": [400, 1238, 709, 439, 264, 3593, 411, 37649, 4886, 10565, 420, 754, 512, 18964, 11, 436, 486], "temperature": 0.0, "avg_logprob": -0.1599035732081679, "compression_ratio": 1.8218623481781377, "no_speech_prob": 9.979314199881628e-05}, {"id": 106, "seek": 46768, "start": 471.84000000000003, "end": 474.44, "text": " give you the code on the left.", "tokens": [976, 291, 264, 3089, 322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.1599035732081679, "compression_ratio": 1.8218623481781377, "no_speech_prob": 9.979314199881628e-05}, {"id": 107, "seek": 46768, "start": 474.44, "end": 475.44, "text": " So it's fine.", "tokens": [407, 309, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.1599035732081679, "compression_ratio": 1.8218623481781377, "no_speech_prob": 9.979314199881628e-05}, {"id": 108, "seek": 46768, "start": 475.44, "end": 476.44, "text": " It works.", "tokens": [467, 1985, 13], "temperature": 0.0, "avg_logprob": -0.1599035732081679, "compression_ratio": 1.8218623481781377, "no_speech_prob": 9.979314199881628e-05}, {"id": 109, "seek": 46768, "start": 476.44, "end": 479.68, "text": " I mean, you are iterating over all the iteration instruction of the function.", "tokens": [286, 914, 11, 291, 366, 17138, 990, 670, 439, 264, 24784, 10951, 295, 264, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1599035732081679, "compression_ratio": 1.8218623481781377, "no_speech_prob": 9.979314199881628e-05}, {"id": 110, "seek": 46768, "start": 479.68, "end": 484.64, "text": " But if you know a bit better C++, you know that you can put range instead of row iterators.", "tokens": [583, 498, 291, 458, 257, 857, 1101, 383, 25472, 11, 291, 458, 300, 291, 393, 829, 3613, 2602, 295, 5386, 17138, 3391, 13], "temperature": 0.0, "avg_logprob": -0.1599035732081679, "compression_ratio": 1.8218623481781377, "no_speech_prob": 9.979314199881628e-05}, {"id": 111, "seek": 46768, "start": 484.64, "end": 489.64, "text": " And if you know the instruction iterators from LLVM, you know that you can use instruction", "tokens": [400, 498, 291, 458, 264, 10951, 17138, 3391, 490, 441, 43, 53, 44, 11, 291, 458, 300, 291, 393, 764, 10951], "temperature": 0.0, "avg_logprob": -0.1599035732081679, "compression_ratio": 1.8218623481781377, "no_speech_prob": 9.979314199881628e-05}, {"id": 112, "seek": 46768, "start": 489.64, "end": 493.4, "text": " of F to just get all the instruction of F.", "tokens": [295, 479, 281, 445, 483, 439, 264, 10951, 295, 479, 13], "temperature": 0.0, "avg_logprob": -0.1599035732081679, "compression_ratio": 1.8218623481781377, "no_speech_prob": 9.979314199881628e-05}, {"id": 113, "seek": 49340, "start": 493.4, "end": 499.88, "text": " All the code works, but arguably the codes on the right are easier to read, and in the", "tokens": [1057, 264, 3089, 1985, 11, 457, 26771, 264, 14211, 322, 264, 558, 366, 3571, 281, 1401, 11, 293, 294, 264], "temperature": 0.0, "avg_logprob": -0.21229495817017788, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00019229408644605428}, {"id": 114, "seek": 49340, "start": 499.88, "end": 503.64, "text": " end easier to maintain, especially if you consider that there are a lot of examples like this", "tokens": [917, 3571, 281, 6909, 11, 2318, 498, 291, 1949, 300, 456, 366, 257, 688, 295, 5110, 411, 341], "temperature": 0.0, "avg_logprob": -0.21229495817017788, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00019229408644605428}, {"id": 115, "seek": 49340, "start": 503.64, "end": 504.64, "text": " in the code.", "tokens": [294, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.21229495817017788, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00019229408644605428}, {"id": 116, "seek": 49340, "start": 504.64, "end": 510.88, "text": " It adds up, and so simplifying stuff is nice sometimes.", "tokens": [467, 10860, 493, 11, 293, 370, 6883, 5489, 1507, 307, 1481, 2171, 13], "temperature": 0.0, "avg_logprob": -0.21229495817017788, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00019229408644605428}, {"id": 117, "seek": 49340, "start": 510.88, "end": 514.68, "text": " So it's not a problem of Stack Overflow or anything.", "tokens": [407, 309, 311, 406, 257, 1154, 295, 37649, 4886, 10565, 420, 1340, 13], "temperature": 0.0, "avg_logprob": -0.21229495817017788, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00019229408644605428}, {"id": 118, "seek": 49340, "start": 514.68, "end": 520.92, "text": " It's just that the answer in Stack Overflow or in the slides are old, like from 2015.", "tokens": [467, 311, 445, 300, 264, 1867, 294, 37649, 4886, 10565, 420, 294, 264, 9788, 366, 1331, 11, 411, 490, 7546, 13], "temperature": 0.0, "avg_logprob": -0.21229495817017788, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00019229408644605428}, {"id": 119, "seek": 52092, "start": 520.92, "end": 529.16, "text": " Like if you would update the answer, it would just be the option on the right.", "tokens": [1743, 498, 291, 576, 5623, 264, 1867, 11, 309, 576, 445, 312, 264, 3614, 322, 264, 558, 13], "temperature": 0.0, "avg_logprob": -0.18342248916625978, "compression_ratio": 1.625, "no_speech_prob": 0.0002181728050345555}, {"id": 120, "seek": 52092, "start": 529.16, "end": 535.88, "text": " Another thing I want to talk about, and that I've seen a lot in ParCoach, is iterating", "tokens": [3996, 551, 286, 528, 281, 751, 466, 11, 293, 300, 286, 600, 1612, 257, 688, 294, 3457, 21141, 608, 11, 307, 17138, 990], "temperature": 0.0, "avg_logprob": -0.18342248916625978, "compression_ratio": 1.625, "no_speech_prob": 0.0002181728050345555}, {"id": 121, "seek": 52092, "start": 535.88, "end": 538.1999999999999, "text": " over something, but putting a predicate.", "tokens": [670, 746, 11, 457, 3372, 257, 3852, 8700, 13], "temperature": 0.0, "avg_logprob": -0.18342248916625978, "compression_ratio": 1.625, "no_speech_prob": 0.0002181728050345555}, {"id": 122, "seek": 52092, "start": 538.1999999999999, "end": 543.88, "text": " Like I want to iterate through this stuff, but only if this stuff is true for some predicate.", "tokens": [1743, 286, 528, 281, 44497, 807, 341, 1507, 11, 457, 787, 498, 341, 1507, 307, 2074, 337, 512, 3852, 8700, 13], "temperature": 0.0, "avg_logprob": -0.18342248916625978, "compression_ratio": 1.625, "no_speech_prob": 0.0002181728050345555}, {"id": 123, "seek": 52092, "start": 543.88, "end": 549.0, "text": " So you can do stuff like that, early, continuous, or nested if.", "tokens": [407, 291, 393, 360, 1507, 411, 300, 11, 2440, 11, 10957, 11, 420, 15646, 292, 498, 13], "temperature": 0.0, "avg_logprob": -0.18342248916625978, "compression_ratio": 1.625, "no_speech_prob": 0.0002181728050345555}, {"id": 124, "seek": 54900, "start": 549.0, "end": 556.36, "text": " But if you know the STL extra from LLVM, you know that you can create filtered range for", "tokens": [583, 498, 291, 458, 264, 4904, 43, 2857, 490, 441, 43, 53, 44, 11, 291, 458, 300, 291, 393, 1884, 37111, 3613, 337], "temperature": 0.0, "avg_logprob": -0.19710108329509868, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.00012385760783217847}, {"id": 125, "seek": 54900, "start": 556.36, "end": 557.36, "text": " any range, actually.", "tokens": [604, 3613, 11, 767, 13], "temperature": 0.0, "avg_logprob": -0.19710108329509868, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.00012385760783217847}, {"id": 126, "seek": 54900, "start": 557.36, "end": 563.64, "text": " So you pass a range, you pass a predicate, and inside the loop, you just get the object", "tokens": [407, 291, 1320, 257, 3613, 11, 291, 1320, 257, 3852, 8700, 11, 293, 1854, 264, 6367, 11, 291, 445, 483, 264, 2657], "temperature": 0.0, "avg_logprob": -0.19710108329509868, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.00012385760783217847}, {"id": 127, "seek": 54900, "start": 563.64, "end": 565.28, "text": " you're looking for.", "tokens": [291, 434, 1237, 337, 13], "temperature": 0.0, "avg_logprob": -0.19710108329509868, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.00012385760783217847}, {"id": 128, "seek": 54900, "start": 565.28, "end": 571.08, "text": " Again, it's a simple predicate, so it doesn't matter much as is, but if you add some more", "tokens": [3764, 11, 309, 311, 257, 2199, 3852, 8700, 11, 370, 309, 1177, 380, 1871, 709, 382, 307, 11, 457, 498, 291, 909, 512, 544], "temperature": 0.0, "avg_logprob": -0.19710108329509868, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.00012385760783217847}, {"id": 129, "seek": 54900, "start": 571.08, "end": 576.88, "text": " stuff, it starts like growing up, and maintenance became a bit harder, readability is impacted", "tokens": [1507, 11, 309, 3719, 411, 4194, 493, 11, 293, 11258, 3062, 257, 857, 6081, 11, 1401, 2310, 307, 15653], "temperature": 0.0, "avg_logprob": -0.19710108329509868, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.00012385760783217847}, {"id": 130, "seek": 54900, "start": 576.88, "end": 577.88, "text": " too.", "tokens": [886, 13], "temperature": 0.0, "avg_logprob": -0.19710108329509868, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.00012385760783217847}, {"id": 131, "seek": 57788, "start": 577.88, "end": 580.12, "text": " So this is something to consider.", "tokens": [407, 341, 307, 746, 281, 1949, 13], "temperature": 0.0, "avg_logprob": -0.1859508514404297, "compression_ratio": 1.7325102880658436, "no_speech_prob": 0.0001417613384546712}, {"id": 132, "seek": 57788, "start": 580.12, "end": 585.6, "text": " Now, something more like critical is advanced data types.", "tokens": [823, 11, 746, 544, 411, 4924, 307, 7339, 1412, 3467, 13], "temperature": 0.0, "avg_logprob": -0.1859508514404297, "compression_ratio": 1.7325102880658436, "no_speech_prob": 0.0001417613384546712}, {"id": 133, "seek": 57788, "start": 585.6, "end": 590.76, "text": " There are a lot of data types in LLVM, and if you are not familiar with LLVM, and I've", "tokens": [821, 366, 257, 688, 295, 1412, 3467, 294, 441, 43, 53, 44, 11, 293, 498, 291, 366, 406, 4963, 365, 441, 43, 53, 44, 11, 293, 286, 600], "temperature": 0.0, "avg_logprob": -0.1859508514404297, "compression_ratio": 1.7325102880658436, "no_speech_prob": 0.0001417613384546712}, {"id": 134, "seek": 57788, "start": 590.76, "end": 597.24, "text": " seen a lot of code like this, you will just use whatever data types is available in the", "tokens": [1612, 257, 688, 295, 3089, 411, 341, 11, 291, 486, 445, 764, 2035, 1412, 3467, 307, 2435, 294, 264], "temperature": 0.0, "avg_logprob": -0.1859508514404297, "compression_ratio": 1.7325102880658436, "no_speech_prob": 0.0001417613384546712}, {"id": 135, "seek": 57788, "start": 597.24, "end": 601.72, "text": " STL, and you will get a map, for instance, use some helper.", "tokens": [4904, 43, 11, 293, 291, 486, 483, 257, 4471, 11, 337, 5197, 11, 764, 512, 36133, 13], "temperature": 0.0, "avg_logprob": -0.1859508514404297, "compression_ratio": 1.7325102880658436, "no_speech_prob": 0.0001417613384546712}, {"id": 136, "seek": 57788, "start": 601.72, "end": 607.76, "text": " And the actual issue starts when input, the map of instruction, you want to map an instruction", "tokens": [400, 264, 3539, 2734, 3719, 562, 4846, 11, 264, 4471, 295, 10951, 11, 291, 528, 281, 4471, 364, 10951], "temperature": 0.0, "avg_logprob": -0.1859508514404297, "compression_ratio": 1.7325102880658436, "no_speech_prob": 0.0001417613384546712}, {"id": 137, "seek": 60776, "start": 607.76, "end": 609.68, "text": " to something.", "tokens": [281, 746, 13], "temperature": 0.0, "avg_logprob": -0.1585987028868302, "compression_ratio": 1.6962616822429906, "no_speech_prob": 9.480588778387755e-05}, {"id": 138, "seek": 60776, "start": 609.68, "end": 616.48, "text": " If you go through the input and change an instruction, like if you delete it, or if", "tokens": [759, 291, 352, 807, 264, 4846, 293, 1319, 364, 10951, 11, 411, 498, 291, 12097, 309, 11, 420, 498], "temperature": 0.0, "avg_logprob": -0.1585987028868302, "compression_ratio": 1.6962616822429906, "no_speech_prob": 9.480588778387755e-05}, {"id": 139, "seek": 60776, "start": 616.48, "end": 622.28, "text": " you replace all the uses with some other value, what happens to the instruction in the map?", "tokens": [291, 7406, 439, 264, 4960, 365, 512, 661, 2158, 11, 437, 2314, 281, 264, 10951, 294, 264, 4471, 30], "temperature": 0.0, "avg_logprob": -0.1585987028868302, "compression_ratio": 1.6962616822429906, "no_speech_prob": 9.480588778387755e-05}, {"id": 140, "seek": 60776, "start": 622.28, "end": 629.6, "text": " So with raw map from the STL, like there is no mechanism, so nothing happens, and you", "tokens": [407, 365, 8936, 4471, 490, 264, 4904, 43, 11, 411, 456, 307, 572, 7513, 11, 370, 1825, 2314, 11, 293, 291], "temperature": 0.0, "avg_logprob": -0.1585987028868302, "compression_ratio": 1.6962616822429906, "no_speech_prob": 9.480588778387755e-05}, {"id": 141, "seek": 60776, "start": 629.6, "end": 635.04, "text": " end up iterating or trying to find something which is not valid anymore, whereas if you", "tokens": [917, 493, 17138, 990, 420, 1382, 281, 915, 746, 597, 307, 406, 7363, 3602, 11, 9735, 498, 291], "temperature": 0.0, "avg_logprob": -0.1585987028868302, "compression_ratio": 1.6962616822429906, "no_speech_prob": 9.480588778387755e-05}, {"id": 142, "seek": 63504, "start": 635.04, "end": 641.1999999999999, "text": " are aware of the data types from LLVM, you are able to use some kind of value map which", "tokens": [366, 3650, 295, 264, 1412, 3467, 490, 441, 43, 53, 44, 11, 291, 366, 1075, 281, 764, 512, 733, 295, 2158, 4471, 597], "temperature": 0.0, "avg_logprob": -0.20542129026640446, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.00014823616947978735}, {"id": 143, "seek": 63504, "start": 641.1999999999999, "end": 648.56, "text": " has specific handle to remove the value or update the value if it is changed during the", "tokens": [575, 2685, 4813, 281, 4159, 264, 2158, 420, 5623, 264, 2158, 498, 309, 307, 3105, 1830, 264], "temperature": 0.0, "avg_logprob": -0.20542129026640446, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.00014823616947978735}, {"id": 144, "seek": 63504, "start": 648.56, "end": 650.3199999999999, "text": " life of the value.", "tokens": [993, 295, 264, 2158, 13], "temperature": 0.0, "avg_logprob": -0.20542129026640446, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.00014823616947978735}, {"id": 145, "seek": 63504, "start": 650.3199999999999, "end": 658.24, "text": " So some other helper that are quite nice, I mean, it's not a big deal, but for instance,", "tokens": [407, 512, 661, 36133, 300, 366, 1596, 1481, 11, 286, 914, 11, 309, 311, 406, 257, 955, 2028, 11, 457, 337, 5197, 11], "temperature": 0.0, "avg_logprob": -0.20542129026640446, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.00014823616947978735}, {"id": 146, "seek": 63504, "start": 658.24, "end": 663.16, "text": " instead of using std-finif, you can use LLVM-finif and just put a range, instead of just like", "tokens": [2602, 295, 1228, 342, 67, 12, 5194, 351, 11, 291, 393, 764, 441, 43, 53, 44, 12, 5194, 351, 293, 445, 829, 257, 3613, 11, 2602, 295, 445, 411], "temperature": 0.0, "avg_logprob": -0.20542129026640446, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.00014823616947978735}, {"id": 147, "seek": 66316, "start": 663.16, "end": 669.3199999999999, "text": " the individual iterator, in this case, it's not a big deal, but it's actually quite nice.", "tokens": [264, 2609, 17138, 1639, 11, 294, 341, 1389, 11, 309, 311, 406, 257, 955, 2028, 11, 457, 309, 311, 767, 1596, 1481, 13], "temperature": 0.0, "avg_logprob": -0.23106402735556325, "compression_ratio": 1.5733333333333333, "no_speech_prob": 7.182870467659086e-05}, {"id": 148, "seek": 66316, "start": 669.3199999999999, "end": 675.3199999999999, "text": " But basically, every stuff like that, I've encountered this for a lot of kind of code", "tokens": [583, 1936, 11, 633, 1507, 411, 300, 11, 286, 600, 20381, 341, 337, 257, 688, 295, 733, 295, 3089], "temperature": 0.0, "avg_logprob": -0.23106402735556325, "compression_ratio": 1.5733333333333333, "no_speech_prob": 7.182870467659086e-05}, {"id": 149, "seek": 66316, "start": 675.3199999999999, "end": 684.68, "text": " where you would be able to replace most of the occurrences with any vector from the LLVM", "tokens": [689, 291, 576, 312, 1075, 281, 7406, 881, 295, 264, 5160, 38983, 365, 604, 8062, 490, 264, 441, 43, 53, 44], "temperature": 0.0, "avg_logprob": -0.23106402735556325, "compression_ratio": 1.5733333333333333, "no_speech_prob": 7.182870467659086e-05}, {"id": 150, "seek": 66316, "start": 684.68, "end": 689.4399999999999, "text": " array advanced data types, or like a array or string array, like there are a lot of stuff", "tokens": [10225, 7339, 1412, 3467, 11, 420, 411, 257, 10225, 420, 6798, 10225, 11, 411, 456, 366, 257, 688, 295, 1507], "temperature": 0.0, "avg_logprob": -0.23106402735556325, "compression_ratio": 1.5733333333333333, "no_speech_prob": 7.182870467659086e-05}, {"id": 151, "seek": 68944, "start": 689.44, "end": 700.36, "text": " in LLVM that you may not be aware of and that makes your code quite nicer if you use them.", "tokens": [294, 441, 43, 53, 44, 300, 291, 815, 406, 312, 3650, 295, 293, 300, 1669, 428, 3089, 1596, 22842, 498, 291, 764, 552, 13], "temperature": 0.0, "avg_logprob": -0.1710804199503961, "compression_ratio": 1.6514522821576763, "no_speech_prob": 7.445165829267353e-05}, {"id": 152, "seek": 68944, "start": 700.36, "end": 705.0400000000001, "text": " So yeah, dealing with it, so you may think, okay, this guy is just being picky with people", "tokens": [407, 1338, 11, 6260, 365, 309, 11, 370, 291, 815, 519, 11, 1392, 11, 341, 2146, 307, 445, 885, 41099, 365, 561], "temperature": 0.0, "avg_logprob": -0.1710804199503961, "compression_ratio": 1.6514522821576763, "no_speech_prob": 7.445165829267353e-05}, {"id": 153, "seek": 68944, "start": 705.0400000000001, "end": 706.9200000000001, "text": " who are writing the code.", "tokens": [567, 366, 3579, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1710804199503961, "compression_ratio": 1.6514522821576763, "no_speech_prob": 7.445165829267353e-05}, {"id": 154, "seek": 68944, "start": 706.9200000000001, "end": 707.9200000000001, "text": " It may be true.", "tokens": [467, 815, 312, 2074, 13], "temperature": 0.0, "avg_logprob": -0.1710804199503961, "compression_ratio": 1.6514522821576763, "no_speech_prob": 7.445165829267353e-05}, {"id": 155, "seek": 68944, "start": 707.9200000000001, "end": 711.6, "text": " I will argue that it depends on actually who makes the contribution, because you cannot", "tokens": [286, 486, 9695, 300, 309, 5946, 322, 767, 567, 1669, 264, 13150, 11, 570, 291, 2644], "temperature": 0.0, "avg_logprob": -0.1710804199503961, "compression_ratio": 1.6514522821576763, "no_speech_prob": 7.445165829267353e-05}, {"id": 156, "seek": 68944, "start": 711.6, "end": 717.6400000000001, "text": " expect the same level of contribution from a student or from a LLVM engineer, and like", "tokens": [2066, 264, 912, 1496, 295, 13150, 490, 257, 3107, 420, 490, 257, 441, 43, 53, 44, 11403, 11, 293, 411], "temperature": 0.0, "avg_logprob": -0.1710804199503961, "compression_ratio": 1.6514522821576763, "no_speech_prob": 7.445165829267353e-05}, {"id": 157, "seek": 71764, "start": 717.64, "end": 720.92, "text": " especially when you're a PhD student, you have, I don't know, a deadline, you just want", "tokens": [2318, 562, 291, 434, 257, 14476, 3107, 11, 291, 362, 11, 286, 500, 380, 458, 11, 257, 20615, 11, 291, 445, 528], "temperature": 0.0, "avg_logprob": -0.183359198613998, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.0001834389695432037}, {"id": 158, "seek": 71764, "start": 720.92, "end": 727.3199999999999, "text": " a tool who does something, like you're not going to spend times and times on how you", "tokens": [257, 2290, 567, 775, 746, 11, 411, 291, 434, 406, 516, 281, 3496, 1413, 293, 1413, 322, 577, 291], "temperature": 0.0, "avg_logprob": -0.183359198613998, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.0001834389695432037}, {"id": 159, "seek": 71764, "start": 727.3199999999999, "end": 734.24, "text": " do stuff as long as it works, at least that's my experience dealing with that.", "tokens": [360, 1507, 382, 938, 382, 309, 1985, 11, 412, 1935, 300, 311, 452, 1752, 6260, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.183359198613998, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.0001834389695432037}, {"id": 160, "seek": 71764, "start": 734.24, "end": 740.28, "text": " But in my opinion, the accumulation of small details matters, and it was very explicit in", "tokens": [583, 294, 452, 4800, 11, 264, 35647, 295, 1359, 4365, 7001, 11, 293, 309, 390, 588, 13691, 294], "temperature": 0.0, "avg_logprob": -0.183359198613998, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.0001834389695432037}, {"id": 161, "seek": 71764, "start": 740.28, "end": 746.36, "text": " the case of Barcoach, because I came after like maybe five, six years where the accumulation", "tokens": [264, 1389, 295, 4156, 1291, 608, 11, 570, 286, 1361, 934, 411, 1310, 1732, 11, 2309, 924, 689, 264, 35647], "temperature": 0.0, "avg_logprob": -0.183359198613998, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.0001834389695432037}, {"id": 162, "seek": 74636, "start": 746.36, "end": 756.72, "text": " of researchers and PhD students like led to a lot of technical depths, and if there was", "tokens": [295, 10309, 293, 14476, 1731, 411, 4684, 281, 257, 688, 295, 6191, 28439, 11, 293, 498, 456, 390], "temperature": 0.0, "avg_logprob": -0.16641019450293648, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.00018636425375007093}, {"id": 163, "seek": 74636, "start": 756.72, "end": 765.04, "text": " some advice that were given to the PhD students or the researcher, it would have been a way", "tokens": [512, 5192, 300, 645, 2212, 281, 264, 14476, 1731, 420, 264, 21751, 11, 309, 576, 362, 668, 257, 636], "temperature": 0.0, "avg_logprob": -0.16641019450293648, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.00018636425375007093}, {"id": 164, "seek": 74636, "start": 765.04, "end": 767.48, "text": " nicer code to read or to maintain.", "tokens": [22842, 3089, 281, 1401, 420, 281, 6909, 13], "temperature": 0.0, "avg_logprob": -0.16641019450293648, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.00018636425375007093}, {"id": 165, "seek": 74636, "start": 767.48, "end": 774.04, "text": " And so obviously, it's quite obvious, but doing code reviews helps a lot.", "tokens": [400, 370, 2745, 11, 309, 311, 1596, 6322, 11, 457, 884, 3089, 10229, 3665, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.16641019450293648, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.00018636425375007093}, {"id": 166, "seek": 77404, "start": 774.04, "end": 779.12, "text": " Sometimes you cannot do them if there is no one able to actually provide some useful feedback", "tokens": [4803, 291, 2644, 360, 552, 498, 456, 307, 572, 472, 1075, 281, 767, 2893, 512, 4420, 5824], "temperature": 0.0, "avg_logprob": -0.17585332276391202, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0002506982709746808}, {"id": 167, "seek": 77404, "start": 779.12, "end": 784.76, "text": " on this, like in the case when people don't know LLVM, you cannot expect them to review", "tokens": [322, 341, 11, 411, 294, 264, 1389, 562, 561, 500, 380, 458, 441, 43, 53, 44, 11, 291, 2644, 2066, 552, 281, 3131], "temperature": 0.0, "avg_logprob": -0.17585332276391202, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0002506982709746808}, {"id": 168, "seek": 77404, "start": 784.76, "end": 788.8, "text": " code and provide some, a lot of feedback.", "tokens": [3089, 293, 2893, 512, 11, 257, 688, 295, 5824, 13], "temperature": 0.0, "avg_logprob": -0.17585332276391202, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0002506982709746808}, {"id": 169, "seek": 77404, "start": 788.8, "end": 795.52, "text": " But what I do know is I redirect every time to the LLVM programmers manual, it's not like", "tokens": [583, 437, 286, 360, 458, 307, 286, 29066, 633, 565, 281, 264, 441, 43, 53, 44, 41504, 9688, 11, 309, 311, 406, 411], "temperature": 0.0, "avg_logprob": -0.17585332276391202, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0002506982709746808}, {"id": 170, "seek": 77404, "start": 795.52, "end": 800.04, "text": " the first thing you usually just go to a search engine and search for what you want.", "tokens": [264, 700, 551, 291, 2673, 445, 352, 281, 257, 3164, 2848, 293, 3164, 337, 437, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.17585332276391202, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0002506982709746808}, {"id": 171, "seek": 77404, "start": 800.04, "end": 803.56, "text": " But I will argue that actually reading the program manual is more helpful in that, in", "tokens": [583, 286, 486, 9695, 300, 767, 3760, 264, 1461, 9688, 307, 544, 4961, 294, 300, 11, 294], "temperature": 0.0, "avg_logprob": -0.17585332276391202, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0002506982709746808}, {"id": 172, "seek": 80356, "start": 803.56, "end": 805.8, "text": " this specific case.", "tokens": [341, 2685, 1389, 13], "temperature": 0.0, "avg_logprob": -0.18752317882719494, "compression_ratio": 1.508849557522124, "no_speech_prob": 0.00010434459545649588}, {"id": 173, "seek": 80356, "start": 805.8, "end": 809.76, "text": " And something that I know people don't want to do when they are starting LLVM is just", "tokens": [400, 746, 300, 286, 458, 561, 500, 380, 528, 281, 360, 562, 436, 366, 2891, 441, 43, 53, 44, 307, 445], "temperature": 0.0, "avg_logprob": -0.18752317882719494, "compression_ratio": 1.508849557522124, "no_speech_prob": 0.00010434459545649588}, {"id": 174, "seek": 80356, "start": 809.76, "end": 813.68, "text": " read the code from the passes in LLVM, there are a lot of good stuff in there.", "tokens": [1401, 264, 3089, 490, 264, 11335, 294, 441, 43, 53, 44, 11, 456, 366, 257, 688, 295, 665, 1507, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.18752317882719494, "compression_ratio": 1.508849557522124, "no_speech_prob": 0.00010434459545649588}, {"id": 175, "seek": 80356, "start": 813.68, "end": 819.92, "text": " Obviously, if you're not familiar with C++ and LLVM, it's not the easiest, but I think", "tokens": [7580, 11, 498, 291, 434, 406, 4963, 365, 383, 25472, 293, 441, 43, 53, 44, 11, 309, 311, 406, 264, 12889, 11, 457, 286, 519], "temperature": 0.0, "avg_logprob": -0.18752317882719494, "compression_ratio": 1.508849557522124, "no_speech_prob": 0.00010434459545649588}, {"id": 176, "seek": 80356, "start": 819.92, "end": 823.92, "text": " it's still worth it.", "tokens": [309, 311, 920, 3163, 309, 13], "temperature": 0.0, "avg_logprob": -0.18752317882719494, "compression_ratio": 1.508849557522124, "no_speech_prob": 0.00010434459545649588}, {"id": 177, "seek": 80356, "start": 823.92, "end": 829.64, "text": " So the next topic is updating the LLVM versions.", "tokens": [407, 264, 958, 4829, 307, 25113, 264, 441, 43, 53, 44, 9606, 13], "temperature": 0.0, "avg_logprob": -0.18752317882719494, "compression_ratio": 1.508849557522124, "no_speech_prob": 0.00010434459545649588}, {"id": 178, "seek": 82964, "start": 829.64, "end": 834.96, "text": " So far, when I've developed out of three tools, I've always set the version to one", "tokens": [407, 1400, 11, 562, 286, 600, 4743, 484, 295, 1045, 3873, 11, 286, 600, 1009, 992, 264, 3037, 281, 472], "temperature": 0.0, "avg_logprob": -0.26882887308576464, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001650326157687232}, {"id": 179, "seek": 82964, "start": 834.96, "end": 836.84, "text": " specific number, right?", "tokens": [2685, 1230, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.26882887308576464, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001650326157687232}, {"id": 180, "seek": 82964, "start": 836.84, "end": 838.84, "text": " And like let's say LLVM 9.", "tokens": [400, 411, 718, 311, 584, 441, 43, 53, 44, 1722, 13], "temperature": 0.0, "avg_logprob": -0.26882887308576464, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001650326157687232}, {"id": 181, "seek": 82964, "start": 838.84, "end": 847.0, "text": " And then when LLVM 10 comes out, you rebase your plug-in and check if any API broke, if", "tokens": [400, 550, 562, 441, 43, 53, 44, 1266, 1487, 484, 11, 291, 12970, 651, 428, 5452, 12, 259, 293, 1520, 498, 604, 9362, 6902, 11, 498], "temperature": 0.0, "avg_logprob": -0.26882887308576464, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001650326157687232}, {"id": 182, "seek": 82964, "start": 847.0, "end": 849.72, "text": " there was like some changes in the IR.", "tokens": [456, 390, 411, 512, 2962, 294, 264, 16486, 13], "temperature": 0.0, "avg_logprob": -0.26882887308576464, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001650326157687232}, {"id": 183, "seek": 82964, "start": 849.72, "end": 856.3199999999999, "text": " Most recently, I am thinking about Opak pointers, it was quite a big change when updating the", "tokens": [4534, 3938, 11, 286, 669, 1953, 466, 12011, 514, 44548, 11, 309, 390, 1596, 257, 955, 1319, 562, 25113, 264], "temperature": 0.0, "avg_logprob": -0.26882887308576464, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001650326157687232}, {"id": 184, "seek": 82964, "start": 856.3199999999999, "end": 858.48, "text": " LLVM version.", "tokens": [441, 43, 53, 44, 3037, 13], "temperature": 0.0, "avg_logprob": -0.26882887308576464, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001650326157687232}, {"id": 185, "seek": 85848, "start": 858.48, "end": 862.4, "text": " And something to consider when doing this is that it may be time-consuming, like a lot", "tokens": [400, 746, 281, 1949, 562, 884, 341, 307, 300, 309, 815, 312, 565, 12, 21190, 24919, 11, 411, 257, 688], "temperature": 0.0, "avg_logprob": -0.1780796346738357, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00010201585973845795}, {"id": 186, "seek": 85848, "start": 862.4, "end": 869.52, "text": " of time can be spent in, it may be like just a day if there were no changes in the API,", "tokens": [295, 565, 393, 312, 4418, 294, 11, 309, 815, 312, 411, 445, 257, 786, 498, 456, 645, 572, 2962, 294, 264, 9362, 11], "temperature": 0.0, "avg_logprob": -0.1780796346738357, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00010201585973845795}, {"id": 187, "seek": 85848, "start": 869.52, "end": 873.28, "text": " but it could also be very time-consuming for instance if you have to change all your passes", "tokens": [457, 309, 727, 611, 312, 588, 565, 12, 21190, 24919, 337, 5197, 498, 291, 362, 281, 1319, 439, 428, 11335], "temperature": 0.0, "avg_logprob": -0.1780796346738357, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00010201585973845795}, {"id": 188, "seek": 85848, "start": 873.28, "end": 877.12, "text": " because it's been three years that the new pass manager was out and you still didn't", "tokens": [570, 309, 311, 668, 1045, 924, 300, 264, 777, 1320, 6598, 390, 484, 293, 291, 920, 994, 380], "temperature": 0.0, "avg_logprob": -0.1780796346738357, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00010201585973845795}, {"id": 189, "seek": 85848, "start": 877.12, "end": 881.12, "text": " do the migration and now suddenly it's deprecating and it's going to be removed, so you need", "tokens": [360, 264, 17011, 293, 586, 5800, 309, 311, 1367, 13867, 990, 293, 309, 311, 516, 281, 312, 7261, 11, 370, 291, 643], "temperature": 0.0, "avg_logprob": -0.1780796346738357, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00010201585973845795}, {"id": 190, "seek": 85848, "start": 881.12, "end": 885.08, "text": " to migrate your passes, so you have to do it.", "tokens": [281, 31821, 428, 11335, 11, 370, 291, 362, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.1780796346738357, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00010201585973845795}, {"id": 191, "seek": 88508, "start": 885.08, "end": 892.96, "text": " And in my experience, it's quite obvious too, but skipping versions makes it worse.", "tokens": [400, 294, 452, 1752, 11, 309, 311, 1596, 6322, 886, 11, 457, 31533, 9606, 1669, 309, 5324, 13], "temperature": 0.0, "avg_logprob": -0.22033130999692938, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00014764865045435727}, {"id": 192, "seek": 88508, "start": 892.96, "end": 897.76, "text": " And some things that I've seen, and I know sometimes it cannot be avoided, but in that", "tokens": [400, 512, 721, 300, 286, 600, 1612, 11, 293, 286, 458, 2171, 309, 2644, 312, 24890, 11, 457, 294, 300], "temperature": 0.0, "avg_logprob": -0.22033130999692938, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00014764865045435727}, {"id": 193, "seek": 88508, "start": 897.76, "end": 905.4000000000001, "text": " case it was avoidable, but basically trying to support multiple LLVM versions at once,", "tokens": [1389, 309, 390, 5042, 712, 11, 457, 1936, 1382, 281, 1406, 3866, 441, 43, 53, 44, 9606, 412, 1564, 11], "temperature": 0.0, "avg_logprob": -0.22033130999692938, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00014764865045435727}, {"id": 194, "seek": 88508, "start": 905.4000000000001, "end": 911.2, "text": " like say support from LLVM 9 through 12, it's actually what was done, and yeah, don't", "tokens": [411, 584, 1406, 490, 441, 43, 53, 44, 1722, 807, 2272, 11, 309, 311, 767, 437, 390, 1096, 11, 293, 1338, 11, 500, 380], "temperature": 0.0, "avg_logprob": -0.22033130999692938, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00014764865045435727}, {"id": 195, "seek": 88508, "start": 911.2, "end": 912.2, "text": " do it.", "tokens": [360, 309, 13], "temperature": 0.0, "avg_logprob": -0.22033130999692938, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.00014764865045435727}, {"id": 196, "seek": 91220, "start": 912.2, "end": 918.84, "text": " Just pick a version and stay like this, because otherwise it's just multiple if-deaf and everyone", "tokens": [1449, 1888, 257, 3037, 293, 1754, 411, 341, 11, 570, 5911, 309, 311, 445, 3866, 498, 12, 1479, 2792, 293, 1518], "temperature": 0.0, "avg_logprob": -0.2772079043918186, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.00022538183839060366}, {"id": 197, "seek": 91220, "start": 918.84, "end": 924.96, "text": " in the code and it's unmaintainable, I think.", "tokens": [294, 264, 3089, 293, 309, 311, 19334, 5114, 491, 712, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.2772079043918186, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.00022538183839060366}, {"id": 198, "seek": 91220, "start": 924.96, "end": 928.4000000000001, "text": " So now let's talk about passes.", "tokens": [407, 586, 718, 311, 751, 466, 11335, 13], "temperature": 0.0, "avg_logprob": -0.2772079043918186, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.00022538183839060366}, {"id": 199, "seek": 91220, "start": 928.4000000000001, "end": 934.84, "text": " If you look for a hello world pass on the internet, you will get a hello world pass,", "tokens": [759, 291, 574, 337, 257, 7751, 1002, 1320, 322, 264, 4705, 11, 291, 486, 483, 257, 7751, 1002, 1320, 11], "temperature": 0.0, "avg_logprob": -0.2772079043918186, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.00022538183839060366}, {"id": 200, "seek": 91220, "start": 934.84, "end": 937.32, "text": " which is a transformation pass.", "tokens": [597, 307, 257, 9887, 1320, 13], "temperature": 0.0, "avg_logprob": -0.2772079043918186, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.00022538183839060366}, {"id": 201, "seek": 93732, "start": 937.32, "end": 944.2, "text": " So in LLVM, you have two kind of passes, the first kind is analysis, and basically they", "tokens": [407, 294, 441, 43, 53, 44, 11, 291, 362, 732, 733, 295, 11335, 11, 264, 700, 733, 307, 5215, 11, 293, 1936, 436], "temperature": 0.0, "avg_logprob": -0.20183741489303447, "compression_ratio": 1.7224489795918367, "no_speech_prob": 6.359448889270425e-05}, {"id": 202, "seek": 93732, "start": 944.2, "end": 949.5600000000001, "text": " don't touch the IR, you just look at the IR and maybe provide some result, which is", "tokens": [500, 380, 2557, 264, 16486, 11, 291, 445, 574, 412, 264, 16486, 293, 1310, 2893, 512, 1874, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.20183741489303447, "compression_ratio": 1.7224489795918367, "no_speech_prob": 6.359448889270425e-05}, {"id": 203, "seek": 93732, "start": 949.5600000000001, "end": 955.32, "text": " a result of the analysis and that can be used by transformation passes or other analysis.", "tokens": [257, 1874, 295, 264, 5215, 293, 300, 393, 312, 1143, 538, 9887, 11335, 420, 661, 5215, 13], "temperature": 0.0, "avg_logprob": -0.20183741489303447, "compression_ratio": 1.7224489795918367, "no_speech_prob": 6.359448889270425e-05}, {"id": 204, "seek": 93732, "start": 955.32, "end": 961.2, "text": " And there are the transformation passes, which may or may not change the IR.", "tokens": [400, 456, 366, 264, 9887, 11335, 11, 597, 815, 420, 815, 406, 1319, 264, 16486, 13], "temperature": 0.0, "avg_logprob": -0.20183741489303447, "compression_ratio": 1.7224489795918367, "no_speech_prob": 6.359448889270425e-05}, {"id": 205, "seek": 93732, "start": 961.2, "end": 964.8800000000001, "text": " And obviously, when you get your hello world pass, you want to do everything in it.", "tokens": [400, 2745, 11, 562, 291, 483, 428, 7751, 1002, 1320, 11, 291, 528, 281, 360, 1203, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.20183741489303447, "compression_ratio": 1.7224489795918367, "no_speech_prob": 6.359448889270425e-05}, {"id": 206, "seek": 96488, "start": 964.88, "end": 970.28, "text": " Like, I mean, I'm not talking about LLVM developers, I'm talking about students and", "tokens": [1743, 11, 286, 914, 11, 286, 478, 406, 1417, 466, 441, 43, 53, 44, 8849, 11, 286, 478, 1417, 466, 1731, 293], "temperature": 0.0, "avg_logprob": -0.17054073627178484, "compression_ratio": 1.6791666666666667, "no_speech_prob": 6.628713163081557e-05}, {"id": 207, "seek": 96488, "start": 970.28, "end": 974.64, "text": " researchers that have the pass and they put everything in it.", "tokens": [10309, 300, 362, 264, 1320, 293, 436, 829, 1203, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.17054073627178484, "compression_ratio": 1.6791666666666667, "no_speech_prob": 6.628713163081557e-05}, {"id": 208, "seek": 96488, "start": 974.64, "end": 981.6, "text": " And so it's fine when it's just like one shot or something like that, but in the time,", "tokens": [400, 370, 309, 311, 2489, 562, 309, 311, 445, 411, 472, 3347, 420, 746, 411, 300, 11, 457, 294, 264, 565, 11], "temperature": 0.0, "avg_logprob": -0.17054073627178484, "compression_ratio": 1.6791666666666667, "no_speech_prob": 6.628713163081557e-05}, {"id": 209, "seek": 96488, "start": 981.6, "end": 987.12, "text": " at some point, both the analysis and the transformation are semantically different,", "tokens": [412, 512, 935, 11, 1293, 264, 5215, 293, 264, 9887, 366, 4361, 49505, 819, 11], "temperature": 0.0, "avg_logprob": -0.17054073627178484, "compression_ratio": 1.6791666666666667, "no_speech_prob": 6.628713163081557e-05}, {"id": 210, "seek": 96488, "start": 987.12, "end": 993.92, "text": " and LLVM has some mechanism to make it easy for you to have the analysis run only when", "tokens": [293, 441, 43, 53, 44, 575, 512, 7513, 281, 652, 309, 1858, 337, 291, 281, 362, 264, 5215, 1190, 787, 562], "temperature": 0.0, "avg_logprob": -0.17054073627178484, "compression_ratio": 1.6791666666666667, "no_speech_prob": 6.628713163081557e-05}, {"id": 211, "seek": 99392, "start": 993.92, "end": 994.92, "text": " it's needed, right?", "tokens": [309, 311, 2978, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1817077530754937, "compression_ratio": 1.6536964980544746, "no_speech_prob": 6.398937694029883e-05}, {"id": 212, "seek": 99392, "start": 994.92, "end": 999.76, "text": " There is a caching mechanism, you can say, okay, I want this analysis for this object", "tokens": [821, 307, 257, 269, 2834, 7513, 11, 291, 393, 584, 11, 1392, 11, 286, 528, 341, 5215, 337, 341, 2657], "temperature": 0.0, "avg_logprob": -0.1817077530754937, "compression_ratio": 1.6536964980544746, "no_speech_prob": 6.398937694029883e-05}, {"id": 213, "seek": 99392, "start": 999.76, "end": 1004.4399999999999, "text": " and if it exists, it will give it back to you.", "tokens": [293, 498, 309, 8198, 11, 309, 486, 976, 309, 646, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.1817077530754937, "compression_ratio": 1.6536964980544746, "no_speech_prob": 6.398937694029883e-05}, {"id": 214, "seek": 99392, "start": 1004.4399999999999, "end": 1009.9599999999999, "text": " And also, it avoids passing structure around because when you are in a transformation pass,", "tokens": [400, 611, 11, 309, 3641, 3742, 8437, 3877, 926, 570, 562, 291, 366, 294, 257, 9887, 1320, 11], "temperature": 0.0, "avg_logprob": -0.1817077530754937, "compression_ratio": 1.6536964980544746, "no_speech_prob": 6.398937694029883e-05}, {"id": 215, "seek": 99392, "start": 1009.9599999999999, "end": 1015.16, "text": " you can request any analysis from basically anywhere as long as you have the analysis manager.", "tokens": [291, 393, 5308, 604, 5215, 490, 1936, 4992, 382, 938, 382, 291, 362, 264, 5215, 6598, 13], "temperature": 0.0, "avg_logprob": -0.1817077530754937, "compression_ratio": 1.6536964980544746, "no_speech_prob": 6.398937694029883e-05}, {"id": 216, "seek": 99392, "start": 1015.16, "end": 1023.0, "text": " And so this is something that has costed me quite some time, like just untangling the", "tokens": [400, 370, 341, 307, 746, 300, 575, 2063, 292, 385, 1596, 512, 565, 11, 411, 445, 1701, 656, 1688, 264], "temperature": 0.0, "avg_logprob": -0.1817077530754937, "compression_ratio": 1.6536964980544746, "no_speech_prob": 6.398937694029883e-05}, {"id": 217, "seek": 102300, "start": 1023.0, "end": 1028.96, "text": " analysis code from the transformation code, and overall, it improved the performances", "tokens": [5215, 3089, 490, 264, 9887, 3089, 11, 293, 4787, 11, 309, 9689, 264, 16087], "temperature": 0.0, "avg_logprob": -0.1659293240063811, "compression_ratio": 1.5637254901960784, "no_speech_prob": 7.81950366217643e-05}, {"id": 218, "seek": 102300, "start": 1028.96, "end": 1035.88, "text": " because some analyses were requested more than once for the same object.", "tokens": [570, 512, 37560, 645, 16436, 544, 813, 1564, 337, 264, 912, 2657, 13], "temperature": 0.0, "avg_logprob": -0.1659293240063811, "compression_ratio": 1.5637254901960784, "no_speech_prob": 7.81950366217643e-05}, {"id": 219, "seek": 102300, "start": 1035.88, "end": 1045.64, "text": " And yes, it leads me to investigating performance issues because it was something too.", "tokens": [400, 2086, 11, 309, 6689, 385, 281, 22858, 3389, 2663, 570, 309, 390, 746, 886, 13], "temperature": 0.0, "avg_logprob": -0.1659293240063811, "compression_ratio": 1.5637254901960784, "no_speech_prob": 7.81950366217643e-05}, {"id": 220, "seek": 102300, "start": 1045.64, "end": 1049.08, "text": " So what happens when you don't know LLVM and you want to debug your code?", "tokens": [407, 437, 2314, 562, 291, 500, 380, 458, 441, 43, 53, 44, 293, 291, 528, 281, 24083, 428, 3089, 30], "temperature": 0.0, "avg_logprob": -0.1659293240063811, "compression_ratio": 1.5637254901960784, "no_speech_prob": 7.81950366217643e-05}, {"id": 221, "seek": 104908, "start": 1049.08, "end": 1054.4399999999998, "text": " You put LLVM errors everywhere and you command them out when your code is ready, okay?", "tokens": [509, 829, 441, 43, 53, 44, 13603, 5315, 293, 291, 5622, 552, 484, 562, 428, 3089, 307, 1919, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.1856936297370392, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0002870810276363045}, {"id": 222, "seek": 104908, "start": 1054.4399999999998, "end": 1062.9199999999998, "text": " So it's a nightmare, I mean, it works, but you're not supposed to do it like this.", "tokens": [407, 309, 311, 257, 18724, 11, 286, 914, 11, 309, 1985, 11, 457, 291, 434, 406, 3442, 281, 360, 309, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1856936297370392, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0002870810276363045}, {"id": 223, "seek": 104908, "start": 1062.9199999999998, "end": 1070.96, "text": " So specifically for like printf like debug stuff, you have some LLVM helper, it's actually", "tokens": [407, 4682, 337, 411, 4482, 69, 411, 24083, 1507, 11, 291, 362, 512, 441, 43, 53, 44, 36133, 11, 309, 311, 767], "temperature": 0.0, "avg_logprob": -0.1856936297370392, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0002870810276363045}, {"id": 224, "seek": 104908, "start": 1070.96, "end": 1071.96, "text": " quite handy.", "tokens": [1596, 13239, 13], "temperature": 0.0, "avg_logprob": -0.1856936297370392, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0002870810276363045}, {"id": 225, "seek": 104908, "start": 1071.96, "end": 1077.1599999999999, "text": " You just put a debug type somewhere and you dot CPP, you wrap everything in LLVM debug", "tokens": [509, 445, 829, 257, 24083, 2010, 4079, 293, 291, 5893, 383, 17755, 11, 291, 7019, 1203, 294, 441, 43, 53, 44, 24083], "temperature": 0.0, "avg_logprob": -0.1856936297370392, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0002870810276363045}, {"id": 226, "seek": 107716, "start": 1077.16, "end": 1083.0, "text": " because it does all the things for you if you don't include debug information, it doesn't", "tokens": [570, 309, 775, 439, 264, 721, 337, 291, 498, 291, 500, 380, 4090, 24083, 1589, 11, 309, 1177, 380], "temperature": 0.0, "avg_logprob": -0.17658071697882885, "compression_ratio": 1.678714859437751, "no_speech_prob": 5.9059479099232703e-05}, {"id": 227, "seek": 107716, "start": 1083.0, "end": 1085.24, "text": " even appear in the binary.", "tokens": [754, 4204, 294, 264, 17434, 13], "temperature": 0.0, "avg_logprob": -0.17658071697882885, "compression_ratio": 1.678714859437751, "no_speech_prob": 5.9059479099232703e-05}, {"id": 228, "seek": 107716, "start": 1085.24, "end": 1090.48, "text": " And when you're running your pass without, you can say, okay, I want to show debug information", "tokens": [400, 562, 291, 434, 2614, 428, 1320, 1553, 11, 291, 393, 584, 11, 1392, 11, 286, 528, 281, 855, 24083, 1589], "temperature": 0.0, "avg_logprob": -0.17658071697882885, "compression_ratio": 1.678714859437751, "no_speech_prob": 5.9059479099232703e-05}, {"id": 229, "seek": 107716, "start": 1090.48, "end": 1094.88, "text": " for this kind of pass and it basically provides the same feature and you don't have to command", "tokens": [337, 341, 733, 295, 1320, 293, 309, 1936, 6417, 264, 912, 4111, 293, 291, 500, 380, 362, 281, 5622], "temperature": 0.0, "avg_logprob": -0.17658071697882885, "compression_ratio": 1.678714859437751, "no_speech_prob": 5.9059479099232703e-05}, {"id": 230, "seek": 107716, "start": 1094.88, "end": 1098.48, "text": " out LLVM errors.", "tokens": [484, 441, 43, 53, 44, 13603, 13], "temperature": 0.0, "avg_logprob": -0.17658071697882885, "compression_ratio": 1.678714859437751, "no_speech_prob": 5.9059479099232703e-05}, {"id": 231, "seek": 107716, "start": 1098.48, "end": 1104.3200000000002, "text": " The other thing is timing your code, being able to tell, okay, this part of the transformation", "tokens": [440, 661, 551, 307, 10822, 428, 3089, 11, 885, 1075, 281, 980, 11, 1392, 11, 341, 644, 295, 264, 9887], "temperature": 0.0, "avg_logprob": -0.17658071697882885, "compression_ratio": 1.678714859437751, "no_speech_prob": 5.9059479099232703e-05}, {"id": 232, "seek": 110432, "start": 1104.32, "end": 1107.12, "text": " is costing me time.", "tokens": [307, 37917, 385, 565, 13], "temperature": 0.0, "avg_logprob": -0.2690065557306463, "compression_ratio": 1.7203389830508475, "no_speech_prob": 4.782862379215658e-05}, {"id": 233, "seek": 110432, "start": 1107.12, "end": 1112.6799999999998, "text": " And so what I've seen was some manual attempt to do timers and basically declare all the", "tokens": [400, 370, 437, 286, 600, 1612, 390, 512, 9688, 5217, 281, 360, 524, 433, 293, 1936, 19710, 439, 264], "temperature": 0.0, "avg_logprob": -0.2690065557306463, "compression_ratio": 1.7203389830508475, "no_speech_prob": 4.782862379215658e-05}, {"id": 234, "seek": 110432, "start": 1112.6799999999998, "end": 1117.32, "text": " timers, you start them manually and it starts being a mess really quick.", "tokens": [524, 433, 11, 291, 722, 552, 16945, 293, 309, 3719, 885, 257, 2082, 534, 1702, 13], "temperature": 0.0, "avg_logprob": -0.2690065557306463, "compression_ratio": 1.7203389830508475, "no_speech_prob": 4.782862379215658e-05}, {"id": 235, "seek": 110432, "start": 1117.32, "end": 1120.72, "text": " Hopefully, thankfully, now we have a time trace scope.", "tokens": [10429, 11, 27352, 11, 586, 321, 362, 257, 565, 13508, 11923, 13], "temperature": 0.0, "avg_logprob": -0.2690065557306463, "compression_ratio": 1.7203389830508475, "no_speech_prob": 4.782862379215658e-05}, {"id": 236, "seek": 110432, "start": 1120.72, "end": 1126.8799999999999, "text": " It was, I think it's what's used when you use a F time trace when starting clung.", "tokens": [467, 390, 11, 286, 519, 309, 311, 437, 311, 1143, 562, 291, 764, 257, 479, 565, 13508, 562, 2891, 596, 1063, 13], "temperature": 0.0, "avg_logprob": -0.2690065557306463, "compression_ratio": 1.7203389830508475, "no_speech_prob": 4.782862379215658e-05}, {"id": 237, "seek": 110432, "start": 1126.8799999999999, "end": 1132.04, "text": " And so basically it's just one line, you put one variable and when it's constricted, it", "tokens": [400, 370, 1936, 309, 311, 445, 472, 1622, 11, 291, 829, 472, 7006, 293, 562, 309, 311, 1817, 3740, 292, 11, 309], "temperature": 0.0, "avg_logprob": -0.2690065557306463, "compression_ratio": 1.7203389830508475, "no_speech_prob": 4.782862379215658e-05}, {"id": 238, "seek": 113204, "start": 1132.04, "end": 1138.12, "text": " starts a scope and it starts a timer and when it's destructed, it stops the timer.", "tokens": [3719, 257, 11923, 293, 309, 3719, 257, 19247, 293, 562, 309, 311, 2677, 1757, 292, 11, 309, 10094, 264, 19247, 13], "temperature": 0.0, "avg_logprob": -0.19646664574032738, "compression_ratio": 1.6808510638297873, "no_speech_prob": 3.709158772835508e-05}, {"id": 239, "seek": 113204, "start": 1138.12, "end": 1145.76, "text": " And LLVM has a whole system for this and it emits a JSON and you get, if you put this", "tokens": [400, 441, 43, 53, 44, 575, 257, 1379, 1185, 337, 341, 293, 309, 846, 1208, 257, 31828, 293, 291, 483, 11, 498, 291, 829, 341], "temperature": 0.0, "avg_logprob": -0.19646664574032738, "compression_ratio": 1.6808510638297873, "no_speech_prob": 3.709158772835508e-05}, {"id": 240, "seek": 113204, "start": 1145.76, "end": 1149.52, "text": " in this JSON speed scope, you get something like that.", "tokens": [294, 341, 31828, 3073, 11923, 11, 291, 483, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.19646664574032738, "compression_ratio": 1.6808510638297873, "no_speech_prob": 3.709158772835508e-05}, {"id": 241, "seek": 113204, "start": 1149.52, "end": 1155.04, "text": " And you can see basically everything in your code without having to do anything.", "tokens": [400, 291, 393, 536, 1936, 1203, 294, 428, 3089, 1553, 1419, 281, 360, 1340, 13], "temperature": 0.0, "avg_logprob": -0.19646664574032738, "compression_ratio": 1.6808510638297873, "no_speech_prob": 3.709158772835508e-05}, {"id": 242, "seek": 113204, "start": 1155.04, "end": 1161.84, "text": " You get the entry point, you get the analysis and here it was quite obvious for us was the", "tokens": [509, 483, 264, 8729, 935, 11, 291, 483, 264, 5215, 293, 510, 309, 390, 1596, 6322, 337, 505, 390, 264], "temperature": 0.0, "avg_logprob": -0.19646664574032738, "compression_ratio": 1.6808510638297873, "no_speech_prob": 3.709158772835508e-05}, {"id": 243, "seek": 116184, "start": 1161.84, "end": 1167.08, "text": " changes, what the changes were because this analysis, for instance, was called multiple", "tokens": [2962, 11, 437, 264, 2962, 645, 570, 341, 5215, 11, 337, 5197, 11, 390, 1219, 3866], "temperature": 0.0, "avg_logprob": -0.19823095933446344, "compression_ratio": 1.7833333333333334, "no_speech_prob": 7.326193008339033e-05}, {"id": 244, "seek": 116184, "start": 1167.08, "end": 1169.6399999999999, "text": " times but it was for the same object.", "tokens": [1413, 457, 309, 390, 337, 264, 912, 2657, 13], "temperature": 0.0, "avg_logprob": -0.19823095933446344, "compression_ratio": 1.7833333333333334, "no_speech_prob": 7.326193008339033e-05}, {"id": 245, "seek": 116184, "start": 1169.6399999999999, "end": 1173.9199999999998, "text": " So like for instance, it would appear here too but because of the caching mechanism and", "tokens": [407, 411, 337, 5197, 11, 309, 576, 4204, 510, 886, 457, 570, 295, 264, 269, 2834, 7513, 293], "temperature": 0.0, "avg_logprob": -0.19823095933446344, "compression_ratio": 1.7833333333333334, "no_speech_prob": 7.326193008339033e-05}, {"id": 246, "seek": 116184, "start": 1173.9199999999998, "end": 1178.28, "text": " the untangling, it basically just, it was just called once.", "tokens": [264, 1701, 656, 1688, 11, 309, 1936, 445, 11, 309, 390, 445, 1219, 1564, 13], "temperature": 0.0, "avg_logprob": -0.19823095933446344, "compression_ratio": 1.7833333333333334, "no_speech_prob": 7.326193008339033e-05}, {"id": 247, "seek": 116184, "start": 1178.28, "end": 1182.8, "text": " So this is something nice that you get basically for free.", "tokens": [407, 341, 307, 746, 1481, 300, 291, 483, 1936, 337, 1737, 13], "temperature": 0.0, "avg_logprob": -0.19823095933446344, "compression_ratio": 1.7833333333333334, "no_speech_prob": 7.326193008339033e-05}, {"id": 248, "seek": 116184, "start": 1182.8, "end": 1191.1599999999999, "text": " So now let's, okay, some conclusion on the tool development, so it's a fairly basic conclusion.", "tokens": [407, 586, 718, 311, 11, 1392, 11, 512, 10063, 322, 264, 2290, 3250, 11, 370, 309, 311, 257, 6457, 3875, 10063, 13], "temperature": 0.0, "avg_logprob": -0.19823095933446344, "compression_ratio": 1.7833333333333334, "no_speech_prob": 7.326193008339033e-05}, {"id": 249, "seek": 119116, "start": 1191.16, "end": 1192.16, "text": " Try to invest in maintenance.", "tokens": [6526, 281, 1963, 294, 11258, 13], "temperature": 0.0, "avg_logprob": -0.21349814331647263, "compression_ratio": 1.536480686695279, "no_speech_prob": 0.00015941557649057359}, {"id": 250, "seek": 119116, "start": 1192.16, "end": 1201.16, "text": " I know it's not always possible, especially in a scientific project but it's worth it.", "tokens": [286, 458, 309, 311, 406, 1009, 1944, 11, 2318, 294, 257, 8134, 1716, 457, 309, 311, 3163, 309, 13], "temperature": 0.0, "avg_logprob": -0.21349814331647263, "compression_ratio": 1.536480686695279, "no_speech_prob": 0.00015941557649057359}, {"id": 251, "seek": 119116, "start": 1201.16, "end": 1202.16, "text": " Don't remember the wheel.", "tokens": [1468, 380, 1604, 264, 5589, 13], "temperature": 0.0, "avg_logprob": -0.21349814331647263, "compression_ratio": 1.536480686695279, "no_speech_prob": 0.00015941557649057359}, {"id": 252, "seek": 119116, "start": 1202.16, "end": 1208.4, "text": " If you want to do something in LLVM, it likely has already something in LLVM for this.", "tokens": [759, 291, 528, 281, 360, 746, 294, 441, 43, 53, 44, 11, 309, 3700, 575, 1217, 746, 294, 441, 43, 53, 44, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.21349814331647263, "compression_ratio": 1.536480686695279, "no_speech_prob": 0.00015941557649057359}, {"id": 253, "seek": 119116, "start": 1208.4, "end": 1209.72, "text": " And keep the this minimal.", "tokens": [400, 1066, 264, 341, 13206, 13], "temperature": 0.0, "avg_logprob": -0.21349814331647263, "compression_ratio": 1.536480686695279, "no_speech_prob": 0.00015941557649057359}, {"id": 254, "seek": 119116, "start": 1209.72, "end": 1214.8400000000001, "text": " One of the main weakness of Parkour right now is that we use some passes which exist", "tokens": [1485, 295, 264, 2135, 12772, 295, 4964, 396, 558, 586, 307, 300, 321, 764, 512, 11335, 597, 2514], "temperature": 0.0, "avg_logprob": -0.21349814331647263, "compression_ratio": 1.536480686695279, "no_speech_prob": 0.00015941557649057359}, {"id": 255, "seek": 119116, "start": 1214.8400000000001, "end": 1216.6000000000001, "text": " already in LLVM.", "tokens": [1217, 294, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.21349814331647263, "compression_ratio": 1.536480686695279, "no_speech_prob": 0.00015941557649057359}, {"id": 256, "seek": 121660, "start": 1216.6, "end": 1222.28, "text": " I'm thinking about memory SSA for instance, we use some copies of this and from a maintenance", "tokens": [286, 478, 1953, 466, 4675, 318, 8886, 337, 5197, 11, 321, 764, 512, 14341, 295, 341, 293, 490, 257, 11258], "temperature": 0.0, "avg_logprob": -0.19059377103238492, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.00010812440450536087}, {"id": 257, "seek": 121660, "start": 1222.28, "end": 1226.56, "text": " point of view, it's not quite nice so we need to migrate this away.", "tokens": [935, 295, 1910, 11, 309, 311, 406, 1596, 1481, 370, 321, 643, 281, 31821, 341, 1314, 13], "temperature": 0.0, "avg_logprob": -0.19059377103238492, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.00010812440450536087}, {"id": 258, "seek": 121660, "start": 1226.56, "end": 1231.52, "text": " And if your passes can be useful to others, just try to upstream them, I mean if you don't", "tokens": [400, 498, 428, 11335, 393, 312, 4420, 281, 2357, 11, 445, 853, 281, 33915, 552, 11, 286, 914, 498, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.19059377103238492, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.00010812440450536087}, {"id": 259, "seek": 121660, "start": 1231.52, "end": 1235.6, "text": " use them, you don't have to pay for them.", "tokens": [764, 552, 11, 291, 500, 380, 362, 281, 1689, 337, 552, 13], "temperature": 0.0, "avg_logprob": -0.19059377103238492, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.00010812440450536087}, {"id": 260, "seek": 121660, "start": 1235.6, "end": 1240.3999999999999, "text": " Then let's talk a bit about usability because it's quite a big deal for a tool because you", "tokens": [1396, 718, 311, 751, 257, 857, 466, 46878, 570, 309, 311, 1596, 257, 955, 2028, 337, 257, 2290, 570, 291], "temperature": 0.0, "avg_logprob": -0.19059377103238492, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.00010812440450536087}, {"id": 261, "seek": 121660, "start": 1240.3999999999999, "end": 1242.3999999999999, "text": " want it to be usable.", "tokens": [528, 309, 281, 312, 29975, 13], "temperature": 0.0, "avg_logprob": -0.19059377103238492, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.00010812440450536087}, {"id": 262, "seek": 124240, "start": 1242.4, "end": 1249.3200000000002, "text": " So first, from a developer point of view, if your developers are going to be non-LLVM", "tokens": [407, 700, 11, 490, 257, 10754, 935, 295, 1910, 11, 498, 428, 8849, 366, 516, 281, 312, 2107, 12, 43, 43, 53, 44], "temperature": 0.0, "avg_logprob": -0.19219650634347576, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001591034233570099}, {"id": 263, "seek": 124240, "start": 1249.3200000000002, "end": 1256.64, "text": " folks, you don't want them to go into the LLVM install and stuff so I've had good experience", "tokens": [4024, 11, 291, 500, 380, 528, 552, 281, 352, 666, 264, 441, 43, 53, 44, 3625, 293, 1507, 370, 286, 600, 632, 665, 1752], "temperature": 0.0, "avg_logprob": -0.19219650634347576, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001591034233570099}, {"id": 264, "seek": 124240, "start": 1256.64, "end": 1264.0400000000002, "text": " with using Docker and basically provide a Docker image with the LLVM compiled installed somewhere", "tokens": [365, 1228, 33772, 293, 1936, 2893, 257, 33772, 3256, 365, 264, 441, 43, 53, 44, 36548, 8899, 4079], "temperature": 0.0, "avg_logprob": -0.19219650634347576, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0001591034233570099}, {"id": 265, "seek": 126404, "start": 1264.04, "end": 1272.76, "text": " or just installed using the APT repositories and have some clear CI, like how to build", "tokens": [420, 445, 8899, 1228, 264, 5372, 51, 22283, 2083, 293, 362, 512, 1850, 37777, 11, 411, 577, 281, 1322], "temperature": 0.0, "avg_logprob": -0.18348049881434678, "compression_ratio": 1.632034632034632, "no_speech_prob": 9.87526000244543e-05}, {"id": 266, "seek": 126404, "start": 1272.76, "end": 1277.36, "text": " your tool, like just looking at the CI should be enough to know how to build your tool from", "tokens": [428, 2290, 11, 411, 445, 1237, 412, 264, 37777, 820, 312, 1547, 281, 458, 577, 281, 1322, 428, 2290, 490], "temperature": 0.0, "avg_logprob": -0.18348049881434678, "compression_ratio": 1.632034632034632, "no_speech_prob": 9.87526000244543e-05}, {"id": 267, "seek": 126404, "start": 1277.36, "end": 1279.56, "text": " a developer point of view.", "tokens": [257, 10754, 935, 295, 1910, 13], "temperature": 0.0, "avg_logprob": -0.18348049881434678, "compression_ratio": 1.632034632034632, "no_speech_prob": 9.87526000244543e-05}, {"id": 268, "seek": 126404, "start": 1279.56, "end": 1284.56, "text": " And the other great thing is when you use LLVM, you get LLVM tools with it.", "tokens": [400, 264, 661, 869, 551, 307, 562, 291, 764, 441, 43, 53, 44, 11, 291, 483, 441, 43, 53, 44, 3873, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.18348049881434678, "compression_ratio": 1.632034632034632, "no_speech_prob": 9.87526000244543e-05}, {"id": 269, "seek": 126404, "start": 1284.56, "end": 1290.08, "text": " So you get a lead and five check and so instead of going through some manual testing and stuff,", "tokens": [407, 291, 483, 257, 1477, 293, 1732, 1520, 293, 370, 2602, 295, 516, 807, 512, 9688, 4997, 293, 1507, 11], "temperature": 0.0, "avg_logprob": -0.18348049881434678, "compression_ratio": 1.632034632034632, "no_speech_prob": 9.87526000244543e-05}, {"id": 270, "seek": 129008, "start": 1290.08, "end": 1294.32, "text": " you can just use them and it's actually quite nice.", "tokens": [291, 393, 445, 764, 552, 293, 309, 311, 767, 1596, 1481, 13], "temperature": 0.0, "avg_logprob": -0.20739954898231908, "compression_ratio": 1.5349794238683128, "no_speech_prob": 0.00023034522018861026}, {"id": 271, "seek": 129008, "start": 1294.32, "end": 1298.6799999999998, "text": " And yes, of course, I could talk about coding standards but basically since you're making", "tokens": [400, 2086, 11, 295, 1164, 11, 286, 727, 751, 466, 17720, 7787, 457, 1936, 1670, 291, 434, 1455], "temperature": 0.0, "avg_logprob": -0.20739954898231908, "compression_ratio": 1.5349794238683128, "no_speech_prob": 0.00023034522018861026}, {"id": 272, "seek": 129008, "start": 1298.6799999999998, "end": 1302.96, "text": " a plugin or a tool for LLVM, it makes sense to follow the same standard and you have already", "tokens": [257, 23407, 420, 257, 2290, 337, 441, 43, 53, 44, 11, 309, 1669, 2020, 281, 1524, 264, 912, 3832, 293, 291, 362, 1217], "temperature": 0.0, "avg_logprob": -0.20739954898231908, "compression_ratio": 1.5349794238683128, "no_speech_prob": 0.00023034522018861026}, {"id": 273, "seek": 129008, "start": 1302.96, "end": 1306.76, "text": " clonk format and clonk tidy configuration for this.", "tokens": [596, 266, 74, 7877, 293, 596, 266, 74, 34646, 11694, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.20739954898231908, "compression_ratio": 1.5349794238683128, "no_speech_prob": 0.00023034522018861026}, {"id": 274, "seek": 129008, "start": 1306.76, "end": 1314.8, "text": " Now, as a user, you obviously don't want a scientific application developer to compile", "tokens": [823, 11, 382, 257, 4195, 11, 291, 2745, 500, 380, 528, 257, 8134, 3861, 10754, 281, 31413], "temperature": 0.0, "avg_logprob": -0.20739954898231908, "compression_ratio": 1.5349794238683128, "no_speech_prob": 0.00023034522018861026}, {"id": 275, "seek": 131480, "start": 1314.8, "end": 1320.3999999999999, "text": " your code from source, you want them to just have the plugin and use it or have the tool", "tokens": [428, 3089, 490, 4009, 11, 291, 528, 552, 281, 445, 362, 264, 23407, 293, 764, 309, 420, 362, 264, 2290], "temperature": 0.0, "avg_logprob": -0.18370393451891448, "compression_ratio": 1.7459459459459459, "no_speech_prob": 5.358626367524266e-05}, {"id": 276, "seek": 131480, "start": 1320.3999999999999, "end": 1322.44, "text": " and use it.", "tokens": [293, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.18370393451891448, "compression_ratio": 1.7459459459459459, "no_speech_prob": 5.358626367524266e-05}, {"id": 277, "seek": 131480, "start": 1322.44, "end": 1327.76, "text": " If you look at Hello World passes, you see a lot of times that you have to first get the", "tokens": [759, 291, 574, 412, 2425, 3937, 11335, 11, 291, 536, 257, 688, 295, 1413, 300, 291, 362, 281, 700, 483, 264], "temperature": 0.0, "avg_logprob": -0.18370393451891448, "compression_ratio": 1.7459459459459459, "no_speech_prob": 5.358626367524266e-05}, {"id": 278, "seek": 131480, "start": 1327.76, "end": 1328.76, "text": " IR.", "tokens": [16486, 13], "temperature": 0.0, "avg_logprob": -0.18370393451891448, "compression_ratio": 1.7459459459459459, "no_speech_prob": 5.358626367524266e-05}, {"id": 279, "seek": 131480, "start": 1328.76, "end": 1335.3999999999999, "text": " So in our case, it's either from clonk or from clonk and you have to call out, load the", "tokens": [407, 294, 527, 1389, 11, 309, 311, 2139, 490, 596, 266, 74, 420, 490, 596, 266, 74, 293, 291, 362, 281, 818, 484, 11, 3677, 264], "temperature": 0.0, "avg_logprob": -0.18370393451891448, "compression_ratio": 1.7459459459459459, "no_speech_prob": 5.358626367524266e-05}, {"id": 280, "seek": 131480, "start": 1335.3999999999999, "end": 1339.1599999999999, "text": " path manually and call the path manually.", "tokens": [3100, 16945, 293, 818, 264, 3100, 16945, 13], "temperature": 0.0, "avg_logprob": -0.18370393451891448, "compression_ratio": 1.7459459459459459, "no_speech_prob": 5.358626367524266e-05}, {"id": 281, "seek": 133916, "start": 1339.16, "end": 1348.0800000000002, "text": " So I would argue this is not nice enough for researchers and students and since Spark", "tokens": [407, 286, 576, 9695, 341, 307, 406, 1481, 1547, 337, 10309, 293, 1731, 293, 1670, 23424], "temperature": 0.0, "avg_logprob": -0.151872139472466, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.0001136492210207507}, {"id": 282, "seek": 133916, "start": 1348.0800000000002, "end": 1355.8400000000001, "text": " Coach is a verification tool, we cannot expect users to call it on every single file.", "tokens": [17369, 307, 257, 30206, 2290, 11, 321, 2644, 2066, 5022, 281, 818, 309, 322, 633, 2167, 3991, 13], "temperature": 0.0, "avg_logprob": -0.151872139472466, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.0001136492210207507}, {"id": 283, "seek": 133916, "start": 1355.8400000000001, "end": 1362.68, "text": " So we actually had to do some more tooling to create some wrapper which takes the original", "tokens": [407, 321, 767, 632, 281, 360, 512, 544, 46593, 281, 1884, 512, 46906, 597, 2516, 264, 3380], "temperature": 0.0, "avg_logprob": -0.151872139472466, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.0001136492210207507}, {"id": 284, "seek": 133916, "start": 1362.68, "end": 1369.0800000000002, "text": " compiler invocation, runs the original compiler invocation, generates temporary IR and then", "tokens": [31958, 1048, 27943, 11, 6676, 264, 3380, 31958, 1048, 27943, 11, 23815, 13413, 16486, 293, 550], "temperature": 0.0, "avg_logprob": -0.151872139472466, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.0001136492210207507}, {"id": 285, "seek": 136908, "start": 1369.08, "end": 1370.1999999999998, "text": " runs the tool over it.", "tokens": [6676, 264, 2290, 670, 309, 13], "temperature": 0.0, "avg_logprob": -0.20245242399327895, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00022846442880108953}, {"id": 286, "seek": 136908, "start": 1370.1999999999998, "end": 1378.72, "text": " It makes it much more easy for the users to just integrate with auto tools or CMake.", "tokens": [467, 1669, 309, 709, 544, 1858, 337, 264, 5022, 281, 445, 13365, 365, 8399, 3873, 420, 20424, 619, 13], "temperature": 0.0, "avg_logprob": -0.20245242399327895, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00022846442880108953}, {"id": 287, "seek": 136908, "start": 1378.72, "end": 1384.08, "text": " So that makes the tool more user friendly than I would say unusual.", "tokens": [407, 300, 1669, 264, 2290, 544, 4195, 9208, 813, 286, 576, 584, 10901, 13], "temperature": 0.0, "avg_logprob": -0.20245242399327895, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00022846442880108953}, {"id": 288, "seek": 136908, "start": 1384.08, "end": 1387.28, "text": " And the other part is how do you get the tool?", "tokens": [400, 264, 661, 644, 307, 577, 360, 291, 483, 264, 2290, 30], "temperature": 0.0, "avg_logprob": -0.20245242399327895, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00022846442880108953}, {"id": 289, "seek": 136908, "start": 1387.28, "end": 1395.6799999999998, "text": " So again, I've had good experience with Docker especially for students because it's easy", "tokens": [407, 797, 11, 286, 600, 632, 665, 1752, 365, 33772, 2318, 337, 1731, 570, 309, 311, 1858], "temperature": 0.0, "avg_logprob": -0.20245242399327895, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00022846442880108953}, {"id": 290, "seek": 136908, "start": 1395.6799999999998, "end": 1398.48, "text": " for them.", "tokens": [337, 552, 13], "temperature": 0.0, "avg_logprob": -0.20245242399327895, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00022846442880108953}, {"id": 291, "seek": 139848, "start": 1398.48, "end": 1405.04, "text": " And sometimes obviously we also provide some package for major distributions but you actually", "tokens": [400, 2171, 2745, 321, 611, 2893, 512, 7372, 337, 2563, 37870, 457, 291, 767], "temperature": 0.0, "avg_logprob": -0.22298795123432957, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0002401593083050102}, {"id": 292, "seek": 139848, "start": 1405.04, "end": 1410.4, "text": " have to worry about how is LLVM packaged on the target system because depending on what", "tokens": [362, 281, 3292, 466, 577, 307, 441, 43, 53, 44, 38162, 322, 264, 3779, 1185, 570, 5413, 322, 437], "temperature": 0.0, "avg_logprob": -0.22298795123432957, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0002401593083050102}, {"id": 293, "seek": 139848, "start": 1410.4, "end": 1418.56, "text": " is available, how is it shared libraries, Dalib and stuff, it's not the same thing.", "tokens": [307, 2435, 11, 577, 307, 309, 5507, 15148, 11, 17357, 897, 293, 1507, 11, 309, 311, 406, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.22298795123432957, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0002401593083050102}, {"id": 294, "seek": 139848, "start": 1418.56, "end": 1423.44, "text": " And yeah, Docker, it's not something you can quite use on shared HPC clusters, you're more", "tokens": [400, 1338, 11, 33772, 11, 309, 311, 406, 746, 291, 393, 1596, 764, 322, 5507, 12557, 34, 23313, 11, 291, 434, 544], "temperature": 0.0, "avg_logprob": -0.22298795123432957, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0002401593083050102}, {"id": 295, "seek": 142344, "start": 1423.44, "end": 1430.04, "text": " looking at stuff like geeks for instance when targeting such platforms.", "tokens": [1237, 412, 1507, 411, 1519, 24785, 337, 5197, 562, 17918, 1270, 9473, 13], "temperature": 0.0, "avg_logprob": -0.1988846328523424, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.00014386385737452656}, {"id": 296, "seek": 142344, "start": 1430.04, "end": 1433.56, "text": " So for this, you need some packaging.", "tokens": [407, 337, 341, 11, 291, 643, 512, 16836, 13], "temperature": 0.0, "avg_logprob": -0.1988846328523424, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.00014386385737452656}, {"id": 297, "seek": 142344, "start": 1433.56, "end": 1437.0, "text": " And packaging is my last point.", "tokens": [400, 16836, 307, 452, 1036, 935, 13], "temperature": 0.0, "avg_logprob": -0.1988846328523424, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.00014386385737452656}, {"id": 298, "seek": 142344, "start": 1437.0, "end": 1444.72, "text": " So obviously we used to use do-it-yourself approach, basically just create a shared library", "tokens": [407, 2745, 321, 1143, 281, 764, 360, 12, 270, 12, 23093, 927, 3109, 11, 1936, 445, 1884, 257, 5507, 6405], "temperature": 0.0, "avg_logprob": -0.1988846328523424, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.00014386385737452656}, {"id": 299, "seek": 142344, "start": 1444.72, "end": 1448.48, "text": " and hope for the best, it doesn't work.", "tokens": [293, 1454, 337, 264, 1151, 11, 309, 1177, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.1988846328523424, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.00014386385737452656}, {"id": 300, "seek": 144848, "start": 1448.48, "end": 1453.4, "text": " Because you depend on how opt is installed and compiled because you're loading dynamically", "tokens": [1436, 291, 5672, 322, 577, 2427, 307, 8899, 293, 36548, 570, 291, 434, 15114, 43492], "temperature": 0.0, "avg_logprob": -0.218619431599532, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.0002646699722390622}, {"id": 301, "seek": 144848, "start": 1453.4, "end": 1454.52, "text": " a library into opt.", "tokens": [257, 6405, 666, 2427, 13], "temperature": 0.0, "avg_logprob": -0.218619431599532, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.0002646699722390622}, {"id": 302, "seek": 144848, "start": 1454.52, "end": 1459.6, "text": " So if you have not used the same like C++ libraries, you're going to run into issues.", "tokens": [407, 498, 291, 362, 406, 1143, 264, 912, 411, 383, 25472, 15148, 11, 291, 434, 516, 281, 1190, 666, 2663, 13], "temperature": 0.0, "avg_logprob": -0.218619431599532, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.0002646699722390622}, {"id": 303, "seek": 144848, "start": 1459.6, "end": 1463.32, "text": " You don't know for sure which pass manager is enabled by default in opt.", "tokens": [509, 500, 380, 458, 337, 988, 597, 1320, 6598, 307, 15172, 538, 7576, 294, 2427, 13], "temperature": 0.0, "avg_logprob": -0.218619431599532, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.0002646699722390622}, {"id": 304, "seek": 144848, "start": 1463.32, "end": 1466.32, "text": " So there is also this.", "tokens": [407, 456, 307, 611, 341, 13], "temperature": 0.0, "avg_logprob": -0.218619431599532, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.0002646699722390622}, {"id": 305, "seek": 144848, "start": 1466.32, "end": 1476.3600000000001, "text": " So we've moved to doing some proper packages for APT.deb and for geeks and for Red Hat 2", "tokens": [407, 321, 600, 4259, 281, 884, 512, 2296, 17401, 337, 5372, 51, 13, 1479, 65, 293, 337, 1519, 24785, 293, 337, 4477, 15867, 568], "temperature": 0.0, "avg_logprob": -0.218619431599532, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.0002646699722390622}, {"id": 306, "seek": 147636, "start": 1476.36, "end": 1482.0, "text": " because we have some users using some custom version of Red Hat.", "tokens": [570, 321, 362, 512, 5022, 1228, 512, 2375, 3037, 295, 4477, 15867, 13], "temperature": 0.0, "avg_logprob": -0.16537160983030824, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.0002030905452556908}, {"id": 307, "seek": 147636, "start": 1482.0, "end": 1490.0, "text": " And for this, we actually have quite an interesting issue because we are sure that the LL version", "tokens": [400, 337, 341, 11, 321, 767, 362, 1596, 364, 1880, 2734, 570, 321, 366, 988, 300, 264, 441, 43, 3037], "temperature": 0.0, "avg_logprob": -0.16537160983030824, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.0002030905452556908}, {"id": 308, "seek": 147636, "start": 1490.0, "end": 1492.08, "text": " in their image is not available.", "tokens": [294, 641, 3256, 307, 406, 2435, 13], "temperature": 0.0, "avg_logprob": -0.16537160983030824, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.0002030905452556908}, {"id": 309, "seek": 147636, "start": 1492.08, "end": 1498.76, "text": " So we made the choice of shipping just one single static tool.", "tokens": [407, 321, 1027, 264, 3922, 295, 14122, 445, 472, 2167, 13437, 2290, 13], "temperature": 0.0, "avg_logprob": -0.16537160983030824, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.0002030905452556908}, {"id": 310, "seek": 147636, "start": 1498.76, "end": 1504.3999999999999, "text": " And for this, it was actually quite easy because as I said, when I talked about CMake, you", "tokens": [400, 337, 341, 11, 309, 390, 767, 1596, 1858, 570, 382, 286, 848, 11, 562, 286, 2825, 466, 20424, 619, 11, 291], "temperature": 0.0, "avg_logprob": -0.16537160983030824, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.0002030905452556908}, {"id": 311, "seek": 150440, "start": 1504.4, "end": 1512.48, "text": " just say, OK, I want this to be linked statically or as a shared library and CMake, LLVM CMake", "tokens": [445, 584, 11, 2264, 11, 286, 528, 341, 281, 312, 9408, 2219, 984, 420, 382, 257, 5507, 6405, 293, 20424, 619, 11, 441, 43, 53, 44, 20424, 619], "temperature": 0.0, "avg_logprob": -0.1782944688519228, "compression_ratio": 1.537190082644628, "no_speech_prob": 9.191466961055994e-05}, {"id": 312, "seek": 150440, "start": 1512.48, "end": 1514.2800000000002, "text": " handles it for you.", "tokens": [18722, 309, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.1782944688519228, "compression_ratio": 1.537190082644628, "no_speech_prob": 9.191466961055994e-05}, {"id": 313, "seek": 150440, "start": 1514.2800000000002, "end": 1519.5600000000002, "text": " And it was quite a nice experience for us to package for so many distribution without", "tokens": [400, 309, 390, 1596, 257, 1481, 1752, 337, 505, 281, 7372, 337, 370, 867, 7316, 1553], "temperature": 0.0, "avg_logprob": -0.1782944688519228, "compression_ratio": 1.537190082644628, "no_speech_prob": 9.191466961055994e-05}, {"id": 314, "seek": 150440, "start": 1519.5600000000002, "end": 1524.1200000000001, "text": " having to worry too much about CMake option and stuff.", "tokens": [1419, 281, 3292, 886, 709, 466, 20424, 619, 3614, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.1782944688519228, "compression_ratio": 1.537190082644628, "no_speech_prob": 9.191466961055994e-05}, {"id": 315, "seek": 150440, "start": 1524.1200000000001, "end": 1526.76, "text": " So some takeaways for the whole talk.", "tokens": [407, 512, 45584, 337, 264, 1379, 751, 13], "temperature": 0.0, "avg_logprob": -0.1782944688519228, "compression_ratio": 1.537190082644628, "no_speech_prob": 9.191466961055994e-05}, {"id": 316, "seek": 150440, "start": 1526.76, "end": 1531.68, "text": " In my opinion, the LLVM integration has evolved a lot and in a good direction.", "tokens": [682, 452, 4800, 11, 264, 441, 43, 53, 44, 10980, 575, 14178, 257, 688, 293, 294, 257, 665, 3513, 13], "temperature": 0.0, "avg_logprob": -0.1782944688519228, "compression_ratio": 1.537190082644628, "no_speech_prob": 9.191466961055994e-05}, {"id": 317, "seek": 153168, "start": 1531.68, "end": 1535.88, "text": " It's way easier to integrate with LLVM now than it was 10 years ago.", "tokens": [467, 311, 636, 3571, 281, 13365, 365, 441, 43, 53, 44, 586, 813, 309, 390, 1266, 924, 2057, 13], "temperature": 0.0, "avg_logprob": -0.22106266021728516, "compression_ratio": 1.6177777777777778, "no_speech_prob": 6.74473776598461e-05}, {"id": 318, "seek": 153168, "start": 1535.88, "end": 1542.16, "text": " It's nice, but it's nice to say it because when nice stuff happens, you have to say it", "tokens": [467, 311, 1481, 11, 457, 309, 311, 1481, 281, 584, 309, 570, 562, 1481, 1507, 2314, 11, 291, 362, 281, 584, 309], "temperature": 0.0, "avg_logprob": -0.22106266021728516, "compression_ratio": 1.6177777777777778, "no_speech_prob": 6.74473776598461e-05}, {"id": 319, "seek": 153168, "start": 1542.16, "end": 1543.16, "text": " too.", "tokens": [886, 13], "temperature": 0.0, "avg_logprob": -0.22106266021728516, "compression_ratio": 1.6177777777777778, "no_speech_prob": 6.74473776598461e-05}, {"id": 320, "seek": 153168, "start": 1543.16, "end": 1544.92, "text": " Be prepared for maintenance.", "tokens": [879, 4927, 337, 11258, 13], "temperature": 0.0, "avg_logprob": -0.22106266021728516, "compression_ratio": 1.6177777777777778, "no_speech_prob": 6.74473776598461e-05}, {"id": 321, "seek": 153168, "start": 1544.92, "end": 1549.2, "text": " If you want to create a not-off-tree tool, you have to invest in maintenance both for", "tokens": [759, 291, 528, 281, 1884, 257, 406, 12, 4506, 12, 83, 701, 2290, 11, 291, 362, 281, 1963, 294, 11258, 1293, 337], "temperature": 0.0, "avg_logprob": -0.22106266021728516, "compression_ratio": 1.6177777777777778, "no_speech_prob": 6.74473776598461e-05}, {"id": 322, "seek": 153168, "start": 1549.2, "end": 1557.3200000000002, "text": " LLVM rebases and basically reviews and make sure that your contributors, if you are able", "tokens": [441, 43, 53, 44, 12970, 1957, 293, 1936, 10229, 293, 652, 988, 300, 428, 45627, 11, 498, 291, 366, 1075], "temperature": 0.0, "avg_logprob": -0.22106266021728516, "compression_ratio": 1.6177777777777778, "no_speech_prob": 6.74473776598461e-05}, {"id": 323, "seek": 155732, "start": 1557.32, "end": 1564.08, "text": " to provide some LLVM guidance to your contributors, do it and it's worth it.", "tokens": [281, 2893, 512, 441, 43, 53, 44, 10056, 281, 428, 45627, 11, 360, 309, 293, 309, 311, 3163, 309, 13], "temperature": 0.0, "avg_logprob": -0.17565472095043627, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.000141085620271042}, {"id": 324, "seek": 155732, "start": 1564.08, "end": 1566.2, "text": " Investing in CI is worth it, obviously.", "tokens": [14008, 278, 294, 37777, 307, 3163, 309, 11, 2745, 13], "temperature": 0.0, "avg_logprob": -0.17565472095043627, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.000141085620271042}, {"id": 325, "seek": 155732, "start": 1566.2, "end": 1574.08, "text": " And LLVM documentation, I would definitely, every day, recommend going to the LLVM documentation", "tokens": [400, 441, 43, 53, 44, 14333, 11, 286, 576, 2138, 11, 633, 786, 11, 2748, 516, 281, 264, 441, 43, 53, 44, 14333], "temperature": 0.0, "avg_logprob": -0.17565472095043627, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.000141085620271042}, {"id": 326, "seek": 155732, "start": 1574.08, "end": 1580.9199999999998, "text": " rather than Google for understanding what is available in LLVM.", "tokens": [2831, 813, 3329, 337, 3701, 437, 307, 2435, 294, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.17565472095043627, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.000141085620271042}, {"id": 327, "seek": 158092, "start": 1580.92, "end": 1588.2, "text": " And I want to encourage my students to read LLVM source code, but it's sometimes a bit", "tokens": [400, 286, 528, 281, 5373, 452, 1731, 281, 1401, 441, 43, 53, 44, 4009, 3089, 11, 457, 309, 311, 2171, 257, 857], "temperature": 0.0, "avg_logprob": -0.2813329870050604, "compression_ratio": 1.2907801418439717, "no_speech_prob": 0.00015543840709142387}, {"id": 328, "seek": 158092, "start": 1588.2, "end": 1589.2, "text": " hard.", "tokens": [1152, 13], "temperature": 0.0, "avg_logprob": -0.2813329870050604, "compression_ratio": 1.2907801418439717, "no_speech_prob": 0.00015543840709142387}, {"id": 329, "seek": 158092, "start": 1589.2, "end": 1595.52, "text": " So if you have questions or comments, feel free and I will be happy to answer them.", "tokens": [407, 498, 291, 362, 1651, 420, 3053, 11, 841, 1737, 293, 286, 486, 312, 2055, 281, 1867, 552, 13], "temperature": 0.0, "avg_logprob": -0.2813329870050604, "compression_ratio": 1.2907801418439717, "no_speech_prob": 0.00015543840709142387}, {"id": 330, "seek": 158092, "start": 1595.52, "end": 1596.52, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2813329870050604, "compression_ratio": 1.2907801418439717, "no_speech_prob": 0.00015543840709142387}, {"id": 331, "seek": 159652, "start": 1596.52, "end": 1619.52, "text": " So the question is for the wrapper we created, what do we use to create this wrapper, right?", "tokens": [407, 264, 1168, 307, 337, 264, 46906, 321, 2942, 11, 437, 360, 321, 764, 281, 1884, 341, 46906, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.23877578735351562, "compression_ratio": 1.1794871794871795, "no_speech_prob": 0.00046499870950356126}, {"id": 332, "seek": 161952, "start": 1619.52, "end": 1627.52, "text": " So basically, it's a very, very small LLVM tool, maybe you are familiar with not in LLVM.", "tokens": [407, 1936, 11, 309, 311, 257, 588, 11, 588, 1359, 441, 43, 53, 44, 2290, 11, 1310, 291, 366, 4963, 365, 406, 294, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.19858276297193056, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.00010024276707554236}, {"id": 333, "seek": 161952, "start": 1627.52, "end": 1634.28, "text": " There is a very small utility in LLVM which just does not on the return of a program.", "tokens": [821, 307, 257, 588, 1359, 14877, 294, 441, 43, 53, 44, 597, 445, 775, 406, 322, 264, 2736, 295, 257, 1461, 13], "temperature": 0.0, "avg_logprob": -0.19858276297193056, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.00010024276707554236}, {"id": 334, "seek": 161952, "start": 1634.28, "end": 1637.48, "text": " And it's a very small LLVM tool based on LLVM.", "tokens": [400, 309, 311, 257, 588, 1359, 441, 43, 53, 44, 2290, 2361, 322, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.19858276297193056, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.00010024276707554236}, {"id": 335, "seek": 161952, "start": 1637.48, "end": 1640.84, "text": " And we use a similar approach.", "tokens": [400, 321, 764, 257, 2531, 3109, 13], "temperature": 0.0, "avg_logprob": -0.19858276297193056, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.00010024276707554236}, {"id": 336, "seek": 161952, "start": 1640.84, "end": 1647.48, "text": " Basically we say, okay, I created basically an empty main where I just use the LLVM support", "tokens": [8537, 321, 584, 11, 1392, 11, 286, 2942, 1936, 364, 6707, 2135, 689, 286, 445, 764, 264, 441, 43, 53, 44, 1406], "temperature": 0.0, "avg_logprob": -0.19858276297193056, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.00010024276707554236}, {"id": 337, "seek": 164748, "start": 1647.48, "end": 1653.32, "text": " library to get the benefit from like argument parsing and the data types and so on.", "tokens": [6405, 281, 483, 264, 5121, 490, 411, 6770, 21156, 278, 293, 264, 1412, 3467, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.1853322982788086, "compression_ratio": 1.6546391752577319, "no_speech_prob": 9.999107714975253e-05}, {"id": 338, "seek": 164748, "start": 1653.32, "end": 1662.4, "text": " And I just parse the command line and call successively clang the original compiler line.", "tokens": [400, 286, 445, 48377, 264, 5622, 1622, 293, 818, 2245, 3413, 596, 656, 264, 3380, 31958, 1622, 13], "temperature": 0.0, "avg_logprob": -0.1853322982788086, "compression_ratio": 1.6546391752577319, "no_speech_prob": 9.999107714975253e-05}, {"id": 339, "seek": 164748, "start": 1662.4, "end": 1670.68, "text": " And then I just generate the intermediate representation for it by adding the appropriate", "tokens": [400, 550, 286, 445, 8460, 264, 19376, 10290, 337, 309, 538, 5127, 264, 6854], "temperature": 0.0, "avg_logprob": -0.1853322982788086, "compression_ratio": 1.6546391752577319, "no_speech_prob": 9.999107714975253e-05}, {"id": 340, "seek": 164748, "start": 1670.68, "end": 1675.44, "text": " flag and filtering out the other object generation flags.", "tokens": [7166, 293, 30822, 484, 264, 661, 2657, 5125, 23265, 13], "temperature": 0.0, "avg_logprob": -0.1853322982788086, "compression_ratio": 1.6546391752577319, "no_speech_prob": 9.999107714975253e-05}, {"id": 341, "seek": 167544, "start": 1675.44, "end": 1678.72, "text": " And then I just run the tool over it.", "tokens": [400, 550, 286, 445, 1190, 264, 2290, 670, 309, 13], "temperature": 0.0, "avg_logprob": -0.2999505111851643, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00014904113777447492}, {"id": 342, "seek": 167544, "start": 1678.72, "end": 1687.04, "text": " Yes, yes, because you can just, for instance, with CMake, you can use the CMake C launcher", "tokens": [1079, 11, 2086, 11, 570, 291, 393, 445, 11, 337, 5197, 11, 365, 20424, 619, 11, 291, 393, 764, 264, 20424, 619, 383, 36805], "temperature": 0.0, "avg_logprob": -0.2999505111851643, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00014904113777447492}, {"id": 343, "seek": 167544, "start": 1687.04, "end": 1691.56, "text": " basically just like Ccache work for LLVM, you just change the launcher and you can use", "tokens": [1936, 445, 411, 383, 66, 6000, 589, 337, 441, 43, 53, 44, 11, 291, 445, 1319, 264, 36805, 293, 291, 393, 764], "temperature": 0.0, "avg_logprob": -0.2999505111851643, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00014904113777447492}, {"id": 344, "seek": 167544, "start": 1691.56, "end": 1693.68, "text": " the tool to launch the compiler.", "tokens": [264, 2290, 281, 4025, 264, 31958, 13], "temperature": 0.0, "avg_logprob": -0.2999505111851643, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00014904113777447492}, {"id": 345, "seek": 167544, "start": 1693.68, "end": 1699.64, "text": " And for other tools, you can actually, actually in our project we use MPICC but we are able", "tokens": [400, 337, 661, 3873, 11, 291, 393, 767, 11, 767, 294, 527, 1716, 321, 764, 14146, 2532, 34, 457, 321, 366, 1075], "temperature": 0.0, "avg_logprob": -0.2999505111851643, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00014904113777447492}, {"id": 346, "seek": 169964, "start": 1699.64, "end": 1721.8000000000002, "text": " to change if compiler used for MPICC and say, okay, use instead of GCC for instance.", "tokens": [281, 1319, 498, 31958, 1143, 337, 14146, 2532, 34, 293, 584, 11, 1392, 11, 764, 2602, 295, 460, 11717, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.2474447540614916, "compression_ratio": 1.2846153846153847, "no_speech_prob": 0.0001298299612244591}, {"id": 347, "seek": 169964, "start": 1721.8000000000002, "end": 1727.24, "text": " So the question is when you ship your tool, do you link statically or dynamically?", "tokens": [407, 264, 1168, 307, 562, 291, 5374, 428, 2290, 11, 360, 291, 2113, 2219, 984, 420, 43492, 30], "temperature": 0.0, "avg_logprob": -0.2474447540614916, "compression_ratio": 1.2846153846153847, "no_speech_prob": 0.0001298299612244591}, {"id": 348, "seek": 172724, "start": 1727.24, "end": 1730.36, "text": " So actually both.", "tokens": [407, 767, 1293, 13], "temperature": 0.0, "avg_logprob": -0.2647823819927141, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00024044713063631207}, {"id": 349, "seek": 172724, "start": 1730.36, "end": 1735.96, "text": " When shipping for Red Hat because we don't have a control over what package are in their", "tokens": [1133, 14122, 337, 4477, 15867, 570, 321, 500, 380, 362, 257, 1969, 670, 437, 7372, 366, 294, 641], "temperature": 0.0, "avg_logprob": -0.2647823819927141, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00024044713063631207}, {"id": 350, "seek": 172724, "start": 1735.96, "end": 1740.32, "text": " custom image, we ship statically because we are not sure about which LLVM we are going", "tokens": [2375, 3256, 11, 321, 5374, 2219, 984, 570, 321, 366, 406, 988, 466, 597, 441, 43, 53, 44, 321, 366, 516], "temperature": 0.0, "avg_logprob": -0.2647823819927141, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00024044713063631207}, {"id": 351, "seek": 172724, "start": 1740.32, "end": 1741.32, "text": " to have.", "tokens": [281, 362, 13], "temperature": 0.0, "avg_logprob": -0.2647823819927141, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00024044713063631207}, {"id": 352, "seek": 172724, "start": 1741.32, "end": 1746.16, "text": " So we just, the binary is 100 megabyte but we don't have much choice.", "tokens": [407, 321, 445, 11, 264, 17434, 307, 2319, 10816, 34529, 457, 321, 500, 380, 362, 709, 3922, 13], "temperature": 0.0, "avg_logprob": -0.2647823819927141, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00024044713063631207}, {"id": 353, "seek": 172724, "start": 1746.16, "end": 1752.88, "text": " And when shipping for system like Ubuntu or Debian, we just ship the dependence on the", "tokens": [400, 562, 14122, 337, 1185, 411, 30230, 45605, 420, 1346, 20196, 11, 321, 445, 5374, 264, 31704, 322, 264], "temperature": 0.0, "avg_logprob": -0.2647823819927141, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00024044713063631207}, {"id": 354, "seek": 172724, "start": 1752.88, "end": 1754.88, "text": " shared libraries.", "tokens": [5507, 15148, 13], "temperature": 0.0, "avg_logprob": -0.2647823819927141, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00024044713063631207}, {"id": 355, "seek": 175488, "start": 1754.88, "end": 1783.0800000000002, "text": " So the question is, when we're basing the tool from one LL version to the next one,", "tokens": [407, 264, 1168, 307, 11, 562, 321, 434, 987, 278, 264, 2290, 490, 472, 441, 43, 3037, 281, 264, 958, 472, 11], "temperature": 0.0, "avg_logprob": -0.3087833844698392, "compression_ratio": 1.0921052631578947, "no_speech_prob": 0.00042584550101310015}, {"id": 356, "seek": 178308, "start": 1783.08, "end": 1793.08, "text": " do you use the changelog developers put their love into and if yes, is it helpful?", "tokens": [360, 291, 764, 264, 1534, 338, 664, 8849, 829, 641, 959, 666, 293, 498, 2086, 11, 307, 309, 4961, 30], "temperature": 0.0, "avg_logprob": -0.3107341858277838, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0007559242658317089}, {"id": 357, "seek": 178308, "start": 1793.08, "end": 1797.9199999999998, "text": " Unfortunately the answer is no.", "tokens": [8590, 264, 1867, 307, 572, 13], "temperature": 0.0, "avg_logprob": -0.3107341858277838, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0007559242658317089}, {"id": 358, "seek": 178308, "start": 1797.9199999999998, "end": 1802.72, "text": " But that's because I look at the LLVM weeklies so I kind of know what happens.", "tokens": [583, 300, 311, 570, 286, 574, 412, 264, 441, 43, 53, 44, 1243, 24119, 370, 286, 733, 295, 458, 437, 2314, 13], "temperature": 0.0, "avg_logprob": -0.3107341858277838, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0007559242658317089}, {"id": 359, "seek": 178308, "start": 1802.72, "end": 1811.76, "text": " This is just my way of doing stuff, yeah, so no, but if I would look into the changelog,", "tokens": [639, 307, 445, 452, 636, 295, 884, 1507, 11, 1338, 11, 370, 572, 11, 457, 498, 286, 576, 574, 666, 264, 1534, 338, 664, 11], "temperature": 0.0, "avg_logprob": -0.3107341858277838, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0007559242658317089}, {"id": 360, "seek": 181176, "start": 1811.76, "end": 1825.2, "text": " I would find helpful information I'm sure.", "tokens": [286, 576, 915, 4961, 1589, 286, 478, 988, 13], "temperature": 0.0, "avg_logprob": -0.21790770017183744, "compression_ratio": 1.4423076923076923, "no_speech_prob": 0.00018069527868647128}, {"id": 361, "seek": 181176, "start": 1825.2, "end": 1833.44, "text": " So the question is, am I trying to rebase as LLVM progresses or am I just rebasing every", "tokens": [407, 264, 1168, 307, 11, 669, 286, 1382, 281, 12970, 651, 382, 441, 43, 53, 44, 41929, 420, 669, 286, 445, 12970, 3349, 633], "temperature": 0.0, "avg_logprob": -0.21790770017183744, "compression_ratio": 1.4423076923076923, "no_speech_prob": 0.00018069527868647128}, {"id": 362, "seek": 181176, "start": 1833.44, "end": 1840.84, "text": " version when it's released and it's only when a release came out, comes out, I do the rebase.", "tokens": [3037, 562, 309, 311, 4736, 293, 309, 311, 787, 562, 257, 4374, 1361, 484, 11, 1487, 484, 11, 286, 360, 264, 12970, 651, 13], "temperature": 0.0, "avg_logprob": -0.21790770017183744, "compression_ratio": 1.4423076923076923, "no_speech_prob": 0.00018069527868647128}, {"id": 363, "seek": 184084, "start": 1840.84, "end": 1850.0, "text": " It's easier because otherwise, you know, depending on what kind of target you ship for, it's", "tokens": [467, 311, 3571, 570, 5911, 11, 291, 458, 11, 5413, 322, 437, 733, 295, 3779, 291, 5374, 337, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.33686169123245496, "compression_ratio": 1.457142857142857, "no_speech_prob": 0.0010936944745481014}, {"id": 364, "seek": 184084, "start": 1850.0, "end": 1855.08, "text": " hard and it's just simpler to say, okay, we know and then, we know we need to rebase", "tokens": [1152, 293, 309, 311, 445, 18587, 281, 584, 11, 1392, 11, 321, 458, 293, 550, 11, 321, 458, 321, 643, 281, 12970, 651], "temperature": 0.0, "avg_logprob": -0.33686169123245496, "compression_ratio": 1.457142857142857, "no_speech_prob": 0.0010936944745481014}, {"id": 365, "seek": 184084, "start": 1855.08, "end": 1857.08, "text": " the version and it's fine.", "tokens": [264, 3037, 293, 309, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.33686169123245496, "compression_ratio": 1.457142857142857, "no_speech_prob": 0.0010936944745481014}, {"id": 366, "seek": 185708, "start": 1857.08, "end": 1872.32, "text": " I think we're out of time now, thank you Philippe.", "tokens": [50364, 286, 519, 321, 434, 484, 295, 565, 586, 11, 1309, 291, 13694, 68, 13, 51126], "temperature": 0.0, "avg_logprob": -0.7169044158037972, "compression_ratio": 0.9090909090909091, "no_speech_prob": 0.003256570314988494}], "language": "en"}