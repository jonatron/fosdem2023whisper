{"text": " Hello everyone, I'm Mehdi Bessa, CTO of Metrual Security, and today I'm going to present you Bastion Lab, a secure data privacy-friendly framework written in Rust. Is it working? Yeah. It's better this way. So when making this project, we came across one big problem. Let's say, for example, you are one hospital and you want to share critical data, such as ECG data, Earth rate, respiration rate, and so on, what, for example, a startup that is working on data as a deep learning algorithm to detect anomalies in those data. The most usual way today is to use a Jupyter Notebook that you can isolate from network and all, but unfortunately, this is not the appropriate way because Jupyter Notebooks allow arbitrary code execution, and with some way, you can extract the data without even the data owner seeing that you did that, which is a big problem, mostly with sensitive data. Our solution, try to fix this issue. For example, you will not have direct access to data. You will only have limited operations allowed, so really what you need to, for example, aggregate the data, only extract what you need, only do, for example, some average and calculation on the microcept of data, but most importantly, you can only have sanitize and authorize output allowed, meaning, for example, if I don't want the startup or any other actor that work on my dataset to see the name of my patients or some critical data such as if they have hypertension or so on, I can just set up in the policy, and they will not be able to access that unless I explicitly authorize it, and yet, nothing's forced me to accept it. I'm going to present to you very quickly our API. Don't get mad with me. It's the API is in Python because the API is in Python by the server in Rust, so don't get mad yet. Okay. It doesn't look as bad as I thought, actually it doesn't. Yeah. Sorry about that. Is that working? No, I think the resolution is not there. That's okay. That's okay. I will go on with just explanation. Okay. That was fun. No, that's fun. Ah, thanks. Sorry about that, so no Pytons, so good for you in a way! Thanks. All experiments at Rust in Berlin Bastion lab, we had seven reasons to choose Bastion to make our projects, which is the biggest reason, memory safety. I think you know all very well what I'm talking about here. The very paranoid way Rust has to handling multi-trading, no mutable static unless you use lazy static and any other technique. That was a pain to bypass, but we did manage. And the minimum call-based size, thanks to what, thanks to Rust being a low-level programming language. It's ideal for trusted execution environments as we are working with, such as for example AMD, ACV, IntelliJX, and so on. The less call-based, the less big the cost-based, the easier it is to audit. Now for the performance reason, as I said, Rust is a low-level programming language, very close to seeing term of execution speed, but the biggest reason is polar because our APR easily relies on it, except that we implemented a network stack to never allow anyone to access to the data directly. Polar as well offers one of the best performance in working with datasets and so on, join aggregation and so on. It was the easiest way to do it, plus it's in for Rust. There is no binding and so on. Thanks for that. So you can see here the performance, the benchmark we made. We use Panda as a reference, that is, as you can see here, more than terrible compared to Polars. We compared to Polars, lazy, all solution that is lazy by default. Lazy means I'm only executing a query when I strictly need it. Learn about Panda that is eager and we do it all the time. That makes a big difference, plus I'm working on only the data that I need and not the world dataset if I don't need to. That's another benchmark on a bigger set. You can see that Panda is still off the roof and never compared to the other one. Now though, how did we do that? We thought to use the best crates that are available for doing that. We wanted to use Tonic and Tokyo because Tonic offers GRPC which will allow us to make clowns that are not in Python if we need to, thanks to the protobuf that is implemented in many languages and the GRPC protocol as well. Polar, as I mentioned it already, rings because in addition of setting up a policy, for example, if I don't want people to access a specific two names or whatever, there's that. But rings, we always ring implementation directly to verify a piece and I need to provide my public key to access to the server. We use ring implementation to do that directly and to check if the key matches and if the key is real. And Tokyo because we are using heavily like MAD, the multi-trading, the asynchronous move and so on. For example, when you need to accept a dataset, we spawn a new thread that will send a request to the data owner saying, do you want to accept this request that is about to leak sensitive data? It's not right in this way, but it is this and can come with now. Instead of blocking the whole process, I will have a thread that will time out after a while if I don't access it, I reject it. But I can say yes or no and other requests such as a simple one or not, sensitive one will be accepted. And so move plus tonic to Tokyo that makes very well together and allow many connections as we want. This is the best we could dream of. As I was about to show, that was supposed to be in the Gullo collab, but it's an easier representation here. We have for simplicity reason, sorry, Python code, but only a few lines. The data in all part that uploads the dataset set up a policy and for example, I can reject my dataset, but I can allow sensitive request, but I want it to log it. Oh, shit. Thanks, everyone. Thank you. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.4, "text": " Hello everyone, I'm Mehdi Bessa, CTO of Metrual Security, and today I'm going to present", "tokens": [50364, 2425, 1518, 11, 286, 478, 29337, 4504, 363, 8391, 11, 383, 15427, 295, 6377, 894, 304, 11164, 11, 293, 965, 286, 478, 516, 281, 1974, 50934], "temperature": 0.0, "avg_logprob": -0.35629208087921144, "compression_ratio": 1.3417085427135678, "no_speech_prob": 0.0988897904753685}, {"id": 1, "seek": 0, "start": 11.4, "end": 19.2, "text": " you Bastion Lab, a secure data privacy-friendly framework written in Rust.", "tokens": [50934, 291, 31915, 313, 10137, 11, 257, 7144, 1412, 11427, 12, 22864, 8388, 3720, 294, 34952, 13, 51324], "temperature": 0.0, "avg_logprob": -0.35629208087921144, "compression_ratio": 1.3417085427135678, "no_speech_prob": 0.0988897904753685}, {"id": 2, "seek": 0, "start": 19.2, "end": 21.32, "text": " Is it working?", "tokens": [51324, 1119, 309, 1364, 30, 51430], "temperature": 0.0, "avg_logprob": -0.35629208087921144, "compression_ratio": 1.3417085427135678, "no_speech_prob": 0.0988897904753685}, {"id": 3, "seek": 0, "start": 21.32, "end": 22.32, "text": " Yeah.", "tokens": [51430, 865, 13, 51480], "temperature": 0.0, "avg_logprob": -0.35629208087921144, "compression_ratio": 1.3417085427135678, "no_speech_prob": 0.0988897904753685}, {"id": 4, "seek": 0, "start": 22.32, "end": 24.52, "text": " It's better this way.", "tokens": [51480, 467, 311, 1101, 341, 636, 13, 51590], "temperature": 0.0, "avg_logprob": -0.35629208087921144, "compression_ratio": 1.3417085427135678, "no_speech_prob": 0.0988897904753685}, {"id": 5, "seek": 0, "start": 24.52, "end": 28.8, "text": " So when making this project, we came across one big problem.", "tokens": [51590, 407, 562, 1455, 341, 1716, 11, 321, 1361, 2108, 472, 955, 1154, 13, 51804], "temperature": 0.0, "avg_logprob": -0.35629208087921144, "compression_ratio": 1.3417085427135678, "no_speech_prob": 0.0988897904753685}, {"id": 6, "seek": 2880, "start": 28.8, "end": 33.0, "text": " Let's say, for example, you are one hospital and you want to share critical data, such", "tokens": [50364, 961, 311, 584, 11, 337, 1365, 11, 291, 366, 472, 4530, 293, 291, 528, 281, 2073, 4924, 1412, 11, 1270, 50574], "temperature": 0.0, "avg_logprob": -0.23971459672257706, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.11688964068889618}, {"id": 7, "seek": 2880, "start": 33.0, "end": 38.52, "text": " as ECG data, Earth rate, respiration rate, and so on, what, for example, a startup that", "tokens": [50574, 382, 19081, 38, 1412, 11, 4755, 3314, 11, 1597, 7611, 3314, 11, 293, 370, 322, 11, 437, 11, 337, 1365, 11, 257, 18578, 300, 50850], "temperature": 0.0, "avg_logprob": -0.23971459672257706, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.11688964068889618}, {"id": 8, "seek": 2880, "start": 38.52, "end": 46.32, "text": " is working on data as a deep learning algorithm to detect anomalies in those data.", "tokens": [50850, 307, 1364, 322, 1412, 382, 257, 2452, 2539, 9284, 281, 5531, 24769, 48872, 294, 729, 1412, 13, 51240], "temperature": 0.0, "avg_logprob": -0.23971459672257706, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.11688964068889618}, {"id": 9, "seek": 2880, "start": 46.32, "end": 52.16, "text": " The most usual way today is to use a Jupyter Notebook that you can isolate from network", "tokens": [51240, 440, 881, 7713, 636, 965, 307, 281, 764, 257, 22125, 88, 391, 11633, 2939, 300, 291, 393, 25660, 490, 3209, 51532], "temperature": 0.0, "avg_logprob": -0.23971459672257706, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.11688964068889618}, {"id": 10, "seek": 2880, "start": 52.16, "end": 58.56, "text": " and all, but unfortunately, this is not the appropriate way because Jupyter Notebooks", "tokens": [51532, 293, 439, 11, 457, 7015, 11, 341, 307, 406, 264, 6854, 636, 570, 22125, 88, 391, 11633, 15170, 51852], "temperature": 0.0, "avg_logprob": -0.23971459672257706, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.11688964068889618}, {"id": 11, "seek": 5856, "start": 58.56, "end": 65.52, "text": " allow arbitrary code execution, and with some way, you can extract the data without", "tokens": [50364, 2089, 23211, 3089, 15058, 11, 293, 365, 512, 636, 11, 291, 393, 8947, 264, 1412, 1553, 50712], "temperature": 0.0, "avg_logprob": -0.19010116241790437, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.008890285156667233}, {"id": 12, "seek": 5856, "start": 65.52, "end": 71.16, "text": " even the data owner seeing that you did that, which is a big problem, mostly with sensitive", "tokens": [50712, 754, 264, 1412, 7289, 2577, 300, 291, 630, 300, 11, 597, 307, 257, 955, 1154, 11, 5240, 365, 9477, 50994], "temperature": 0.0, "avg_logprob": -0.19010116241790437, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.008890285156667233}, {"id": 13, "seek": 5856, "start": 71.16, "end": 72.16, "text": " data.", "tokens": [50994, 1412, 13, 51044], "temperature": 0.0, "avg_logprob": -0.19010116241790437, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.008890285156667233}, {"id": 14, "seek": 5856, "start": 72.16, "end": 76.88, "text": " Our solution, try to fix this issue.", "tokens": [51044, 2621, 3827, 11, 853, 281, 3191, 341, 2734, 13, 51280], "temperature": 0.0, "avg_logprob": -0.19010116241790437, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.008890285156667233}, {"id": 15, "seek": 5856, "start": 76.88, "end": 80.08, "text": " For example, you will not have direct access to data.", "tokens": [51280, 1171, 1365, 11, 291, 486, 406, 362, 2047, 2105, 281, 1412, 13, 51440], "temperature": 0.0, "avg_logprob": -0.19010116241790437, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.008890285156667233}, {"id": 16, "seek": 5856, "start": 80.08, "end": 87.6, "text": " You will only have limited operations allowed, so really what you need to, for example, aggregate", "tokens": [51440, 509, 486, 787, 362, 5567, 7705, 4350, 11, 370, 534, 437, 291, 643, 281, 11, 337, 1365, 11, 26118, 51816], "temperature": 0.0, "avg_logprob": -0.19010116241790437, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.008890285156667233}, {"id": 17, "seek": 8760, "start": 87.6, "end": 94.55999999999999, "text": " the data, only extract what you need, only do, for example, some average and calculation", "tokens": [50364, 264, 1412, 11, 787, 8947, 437, 291, 643, 11, 787, 360, 11, 337, 1365, 11, 512, 4274, 293, 17108, 50712], "temperature": 0.0, "avg_logprob": -0.22051853357359422, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.08014637231826782}, {"id": 18, "seek": 8760, "start": 94.55999999999999, "end": 99.67999999999999, "text": " on the microcept of data, but most importantly, you can only have sanitize and authorize", "tokens": [50712, 322, 264, 4532, 1336, 295, 1412, 11, 457, 881, 8906, 11, 291, 393, 787, 362, 24533, 1125, 293, 3793, 1125, 50968], "temperature": 0.0, "avg_logprob": -0.22051853357359422, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.08014637231826782}, {"id": 19, "seek": 8760, "start": 99.67999999999999, "end": 107.44, "text": " output allowed, meaning, for example, if I don't want the startup or any other actor", "tokens": [50968, 5598, 4350, 11, 3620, 11, 337, 1365, 11, 498, 286, 500, 380, 528, 264, 18578, 420, 604, 661, 8747, 51356], "temperature": 0.0, "avg_logprob": -0.22051853357359422, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.08014637231826782}, {"id": 20, "seek": 8760, "start": 107.44, "end": 113.11999999999999, "text": " that work on my dataset to see the name of my patients or some critical data such as", "tokens": [51356, 300, 589, 322, 452, 28872, 281, 536, 264, 1315, 295, 452, 4209, 420, 512, 4924, 1412, 1270, 382, 51640], "temperature": 0.0, "avg_logprob": -0.22051853357359422, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.08014637231826782}, {"id": 21, "seek": 11312, "start": 113.12, "end": 120.56, "text": " if they have hypertension or so on, I can just set up in the policy, and they will not", "tokens": [50364, 498, 436, 362, 46172, 420, 370, 322, 11, 286, 393, 445, 992, 493, 294, 264, 3897, 11, 293, 436, 486, 406, 50736], "temperature": 0.0, "avg_logprob": -0.22785288878161497, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.2087058573961258}, {"id": 22, "seek": 11312, "start": 120.56, "end": 126.24000000000001, "text": " be able to access that unless I explicitly authorize it, and yet, nothing's forced me", "tokens": [50736, 312, 1075, 281, 2105, 300, 5969, 286, 20803, 3793, 1125, 309, 11, 293, 1939, 11, 1825, 311, 7579, 385, 51020], "temperature": 0.0, "avg_logprob": -0.22785288878161497, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.2087058573961258}, {"id": 23, "seek": 11312, "start": 126.24000000000001, "end": 128.32, "text": " to accept it.", "tokens": [51020, 281, 3241, 309, 13, 51124], "temperature": 0.0, "avg_logprob": -0.22785288878161497, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.2087058573961258}, {"id": 24, "seek": 11312, "start": 128.32, "end": 132.36, "text": " I'm going to present to you very quickly our API.", "tokens": [51124, 286, 478, 516, 281, 1974, 281, 291, 588, 2661, 527, 9362, 13, 51326], "temperature": 0.0, "avg_logprob": -0.22785288878161497, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.2087058573961258}, {"id": 25, "seek": 11312, "start": 132.36, "end": 133.36, "text": " Don't get mad with me.", "tokens": [51326, 1468, 380, 483, 5244, 365, 385, 13, 51376], "temperature": 0.0, "avg_logprob": -0.22785288878161497, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.2087058573961258}, {"id": 26, "seek": 11312, "start": 133.36, "end": 139.72, "text": " It's the API is in Python because the API is in Python by the server in Rust, so don't", "tokens": [51376, 467, 311, 264, 9362, 307, 294, 15329, 570, 264, 9362, 307, 294, 15329, 538, 264, 7154, 294, 34952, 11, 370, 500, 380, 51694], "temperature": 0.0, "avg_logprob": -0.22785288878161497, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.2087058573961258}, {"id": 27, "seek": 13972, "start": 139.72, "end": 143.24, "text": " get mad yet.", "tokens": [50364, 483, 5244, 1939, 13, 50540], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 28, "seek": 13972, "start": 143.24, "end": 144.24, "text": " Okay.", "tokens": [50540, 1033, 13, 50590], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 29, "seek": 13972, "start": 144.24, "end": 150.12, "text": " It doesn't look as bad as I thought, actually it doesn't.", "tokens": [50590, 467, 1177, 380, 574, 382, 1578, 382, 286, 1194, 11, 767, 309, 1177, 380, 13, 50884], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 30, "seek": 13972, "start": 150.12, "end": 151.12, "text": " Yeah.", "tokens": [50884, 865, 13, 50934], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 31, "seek": 13972, "start": 151.12, "end": 152.12, "text": " Sorry about that.", "tokens": [50934, 4919, 466, 300, 13, 50984], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 32, "seek": 13972, "start": 152.12, "end": 153.12, "text": " Is that working?", "tokens": [50984, 1119, 300, 1364, 30, 51034], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 33, "seek": 13972, "start": 153.12, "end": 164.12, "text": " No, I think the resolution is not there.", "tokens": [51034, 883, 11, 286, 519, 264, 8669, 307, 406, 456, 13, 51584], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 34, "seek": 13972, "start": 164.12, "end": 165.12, "text": " That's okay.", "tokens": [51584, 663, 311, 1392, 13, 51634], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 35, "seek": 13972, "start": 165.12, "end": 166.12, "text": " That's okay.", "tokens": [51634, 663, 311, 1392, 13, 51684], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 36, "seek": 13972, "start": 166.12, "end": 168.12, "text": " I will go on with just explanation.", "tokens": [51684, 286, 486, 352, 322, 365, 445, 10835, 13, 51784], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 37, "seek": 13972, "start": 168.12, "end": 169.12, "text": " Okay.", "tokens": [51784, 1033, 13, 51834], "temperature": 0.0, "avg_logprob": -0.4577837564859046, "compression_ratio": 1.421383647798742, "no_speech_prob": 0.14887696504592896}, {"id": 38, "seek": 16912, "start": 169.24, "end": 171.28, "text": " That was fun.", "tokens": [50370, 663, 390, 1019, 13, 50472], "temperature": 1.0, "avg_logprob": -0.9090419862328506, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.004261455032974482}, {"id": 39, "seek": 16912, "start": 171.28, "end": 175.36, "text": " No, that's fun.", "tokens": [50472, 883, 11, 300, 311, 1019, 13, 50676], "temperature": 1.0, "avg_logprob": -0.9090419862328506, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.004261455032974482}, {"id": 40, "seek": 16912, "start": 175.36, "end": 176.88, "text": " Ah, thanks.", "tokens": [50676, 2438, 11, 3231, 13, 50752], "temperature": 1.0, "avg_logprob": -0.9090419862328506, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.004261455032974482}, {"id": 41, "seek": 16912, "start": 176.88, "end": 184.22, "text": " Sorry about that, so no Pytons, so good for you in a way!", "tokens": [50752, 4919, 466, 300, 11, 370, 572, 430, 4328, 892, 11, 370, 665, 337, 291, 294, 257, 636, 0, 51119], "temperature": 1.0, "avg_logprob": -0.9090419862328506, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.004261455032974482}, {"id": 42, "seek": 16912, "start": 184.22, "end": 186.8, "text": " Thanks.", "tokens": [51119, 2561, 13, 51248], "temperature": 1.0, "avg_logprob": -0.9090419862328506, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.004261455032974482}, {"id": 43, "seek": 16912, "start": 186.8, "end": 193.88, "text": " All experiments at Rust in Berlin Bastion lab, we had seven reasons to choose Bastion", "tokens": [51248, 1057, 12050, 412, 34952, 294, 13848, 31915, 313, 2715, 11, 321, 632, 3407, 4112, 281, 2826, 31915, 313, 51602], "temperature": 1.0, "avg_logprob": -0.9090419862328506, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.004261455032974482}, {"id": 44, "seek": 16912, "start": 193.88, "end": 197.76, "text": " to make our projects, which is the biggest reason, memory safety.", "tokens": [51602, 281, 652, 527, 4455, 11, 597, 307, 264, 3880, 1778, 11, 4675, 4514, 13, 51796], "temperature": 1.0, "avg_logprob": -0.9090419862328506, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.004261455032974482}, {"id": 45, "seek": 19776, "start": 198.76, "end": 203.16, "text": " I think you know all very well what I'm talking about here.", "tokens": [50414, 286, 519, 291, 458, 439, 588, 731, 437, 286, 478, 1417, 466, 510, 13, 50634], "temperature": 0.0, "avg_logprob": -0.32369853125678166, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07683512568473816}, {"id": 46, "seek": 19776, "start": 203.16, "end": 213.39999999999998, "text": " The very paranoid way Rust has to handling multi-trading, no mutable static unless you", "tokens": [50634, 440, 588, 43948, 636, 34952, 575, 281, 13175, 4825, 12, 43831, 278, 11, 572, 5839, 712, 13437, 5969, 291, 51146], "temperature": 0.0, "avg_logprob": -0.32369853125678166, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07683512568473816}, {"id": 47, "seek": 19776, "start": 213.39999999999998, "end": 217.6, "text": " use lazy static and any other technique.", "tokens": [51146, 764, 14847, 13437, 293, 604, 661, 6532, 13, 51356], "temperature": 0.0, "avg_logprob": -0.32369853125678166, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07683512568473816}, {"id": 48, "seek": 19776, "start": 217.6, "end": 221.28, "text": " That was a pain to bypass, but we did manage.", "tokens": [51356, 663, 390, 257, 1822, 281, 24996, 11, 457, 321, 630, 3067, 13, 51540], "temperature": 0.0, "avg_logprob": -0.32369853125678166, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07683512568473816}, {"id": 49, "seek": 19776, "start": 221.28, "end": 226.72, "text": " And the minimum call-based size, thanks to what, thanks to Rust being a low-level programming", "tokens": [51540, 400, 264, 7285, 818, 12, 6032, 2744, 11, 3231, 281, 437, 11, 3231, 281, 34952, 885, 257, 2295, 12, 12418, 9410, 51812], "temperature": 0.0, "avg_logprob": -0.32369853125678166, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07683512568473816}, {"id": 50, "seek": 19776, "start": 226.72, "end": 227.72, "text": " language.", "tokens": [51812, 2856, 13, 51862], "temperature": 0.0, "avg_logprob": -0.32369853125678166, "compression_ratio": 1.5248868778280542, "no_speech_prob": 0.07683512568473816}, {"id": 51, "seek": 22772, "start": 227.72, "end": 232.44, "text": " It's ideal for trusted execution environments as we are working with, such as for example", "tokens": [50364, 467, 311, 7157, 337, 16034, 15058, 12388, 382, 321, 366, 1364, 365, 11, 1270, 382, 337, 1365, 50600], "temperature": 0.0, "avg_logprob": -0.29966163635253906, "compression_ratio": 1.528688524590164, "no_speech_prob": 0.02939600683748722}, {"id": 52, "seek": 22772, "start": 232.44, "end": 236.0, "text": " AMD, ACV, IntelliJX, and so on.", "tokens": [50600, 34808, 11, 8157, 53, 11, 18762, 72, 41, 55, 11, 293, 370, 322, 13, 50778], "temperature": 0.0, "avg_logprob": -0.29966163635253906, "compression_ratio": 1.528688524590164, "no_speech_prob": 0.02939600683748722}, {"id": 53, "seek": 22772, "start": 236.0, "end": 241.24, "text": " The less call-based, the less big the cost-based, the easier it is to audit.", "tokens": [50778, 440, 1570, 818, 12, 6032, 11, 264, 1570, 955, 264, 2063, 12, 6032, 11, 264, 3571, 309, 307, 281, 17748, 13, 51040], "temperature": 0.0, "avg_logprob": -0.29966163635253906, "compression_ratio": 1.528688524590164, "no_speech_prob": 0.02939600683748722}, {"id": 54, "seek": 22772, "start": 241.24, "end": 248.4, "text": " Now for the performance reason, as I said, Rust is a low-level programming language,", "tokens": [51040, 823, 337, 264, 3389, 1778, 11, 382, 286, 848, 11, 34952, 307, 257, 2295, 12, 12418, 9410, 2856, 11, 51398], "temperature": 0.0, "avg_logprob": -0.29966163635253906, "compression_ratio": 1.528688524590164, "no_speech_prob": 0.02939600683748722}, {"id": 55, "seek": 22772, "start": 248.4, "end": 254.68, "text": " very close to seeing term of execution speed, but the biggest reason is polar because our", "tokens": [51398, 588, 1998, 281, 2577, 1433, 295, 15058, 3073, 11, 457, 264, 3880, 1778, 307, 12367, 570, 527, 51712], "temperature": 0.0, "avg_logprob": -0.29966163635253906, "compression_ratio": 1.528688524590164, "no_speech_prob": 0.02939600683748722}, {"id": 56, "seek": 25468, "start": 254.68, "end": 265.44, "text": " APR easily relies on it, except that we implemented a network stack to never allow anyone to access", "tokens": [50364, 5372, 49, 3612, 30910, 322, 309, 11, 3993, 300, 321, 12270, 257, 3209, 8630, 281, 1128, 2089, 2878, 281, 2105, 50902], "temperature": 0.0, "avg_logprob": -0.22659563510975939, "compression_ratio": 1.5363636363636364, "no_speech_prob": 0.00706882681697607}, {"id": 57, "seek": 25468, "start": 265.44, "end": 267.04, "text": " to the data directly.", "tokens": [50902, 281, 264, 1412, 3838, 13, 50982], "temperature": 0.0, "avg_logprob": -0.22659563510975939, "compression_ratio": 1.5363636363636364, "no_speech_prob": 0.00706882681697607}, {"id": 58, "seek": 25468, "start": 267.04, "end": 274.6, "text": " Polar as well offers one of the best performance in working with datasets and so on, join aggregation", "tokens": [50982, 3635, 289, 382, 731, 7736, 472, 295, 264, 1151, 3389, 294, 1364, 365, 42856, 293, 370, 322, 11, 3917, 16743, 399, 51360], "temperature": 0.0, "avg_logprob": -0.22659563510975939, "compression_ratio": 1.5363636363636364, "no_speech_prob": 0.00706882681697607}, {"id": 59, "seek": 25468, "start": 274.6, "end": 275.6, "text": " and so on.", "tokens": [51360, 293, 370, 322, 13, 51410], "temperature": 0.0, "avg_logprob": -0.22659563510975939, "compression_ratio": 1.5363636363636364, "no_speech_prob": 0.00706882681697607}, {"id": 60, "seek": 25468, "start": 275.6, "end": 278.2, "text": " It was the easiest way to do it, plus it's in for Rust.", "tokens": [51410, 467, 390, 264, 12889, 636, 281, 360, 309, 11, 1804, 309, 311, 294, 337, 34952, 13, 51540], "temperature": 0.0, "avg_logprob": -0.22659563510975939, "compression_ratio": 1.5363636363636364, "no_speech_prob": 0.00706882681697607}, {"id": 61, "seek": 25468, "start": 278.2, "end": 280.64, "text": " There is no binding and so on.", "tokens": [51540, 821, 307, 572, 17359, 293, 370, 322, 13, 51662], "temperature": 0.0, "avg_logprob": -0.22659563510975939, "compression_ratio": 1.5363636363636364, "no_speech_prob": 0.00706882681697607}, {"id": 62, "seek": 25468, "start": 280.64, "end": 282.6, "text": " Thanks for that.", "tokens": [51662, 2561, 337, 300, 13, 51760], "temperature": 0.0, "avg_logprob": -0.22659563510975939, "compression_ratio": 1.5363636363636364, "no_speech_prob": 0.00706882681697607}, {"id": 63, "seek": 28260, "start": 282.6, "end": 286.48, "text": " So you can see here the performance, the benchmark we made.", "tokens": [50364, 407, 291, 393, 536, 510, 264, 3389, 11, 264, 18927, 321, 1027, 13, 50558], "temperature": 0.0, "avg_logprob": -0.29508546988169354, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.4927133321762085}, {"id": 64, "seek": 28260, "start": 286.48, "end": 291.8, "text": " We use Panda as a reference, that is, as you can see here, more than terrible compared", "tokens": [50558, 492, 764, 44207, 382, 257, 6408, 11, 300, 307, 11, 382, 291, 393, 536, 510, 11, 544, 813, 6237, 5347, 50824], "temperature": 0.0, "avg_logprob": -0.29508546988169354, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.4927133321762085}, {"id": 65, "seek": 28260, "start": 291.8, "end": 293.3, "text": " to Polars.", "tokens": [50824, 281, 3635, 685, 13, 50899], "temperature": 0.0, "avg_logprob": -0.29508546988169354, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.4927133321762085}, {"id": 66, "seek": 28260, "start": 293.3, "end": 298.52000000000004, "text": " We compared to Polars, lazy, all solution that is lazy by default.", "tokens": [50899, 492, 5347, 281, 3635, 685, 11, 14847, 11, 439, 3827, 300, 307, 14847, 538, 7576, 13, 51160], "temperature": 0.0, "avg_logprob": -0.29508546988169354, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.4927133321762085}, {"id": 67, "seek": 28260, "start": 298.52000000000004, "end": 304.32000000000005, "text": " Lazy means I'm only executing a query when I strictly need it.", "tokens": [51160, 441, 33235, 1355, 286, 478, 787, 32368, 257, 14581, 562, 286, 20792, 643, 309, 13, 51450], "temperature": 0.0, "avg_logprob": -0.29508546988169354, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.4927133321762085}, {"id": 68, "seek": 28260, "start": 304.32000000000005, "end": 308.32000000000005, "text": " Learn about Panda that is eager and we do it all the time.", "tokens": [51450, 17216, 466, 44207, 300, 307, 18259, 293, 321, 360, 309, 439, 264, 565, 13, 51650], "temperature": 0.0, "avg_logprob": -0.29508546988169354, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.4927133321762085}, {"id": 69, "seek": 30832, "start": 308.32, "end": 313.04, "text": " That makes a big difference, plus I'm working on only the data that I need and not the world", "tokens": [50364, 663, 1669, 257, 955, 2649, 11, 1804, 286, 478, 1364, 322, 787, 264, 1412, 300, 286, 643, 293, 406, 264, 1002, 50600], "temperature": 0.0, "avg_logprob": -0.20648169010243517, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.480371356010437}, {"id": 70, "seek": 30832, "start": 313.04, "end": 315.59999999999997, "text": " dataset if I don't need to.", "tokens": [50600, 28872, 498, 286, 500, 380, 643, 281, 13, 50728], "temperature": 0.0, "avg_logprob": -0.20648169010243517, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.480371356010437}, {"id": 71, "seek": 30832, "start": 315.59999999999997, "end": 317.56, "text": " That's another benchmark on a bigger set.", "tokens": [50728, 663, 311, 1071, 18927, 322, 257, 3801, 992, 13, 50826], "temperature": 0.0, "avg_logprob": -0.20648169010243517, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.480371356010437}, {"id": 72, "seek": 30832, "start": 317.56, "end": 324.28, "text": " You can see that Panda is still off the roof and never compared to the other one.", "tokens": [50826, 509, 393, 536, 300, 44207, 307, 920, 766, 264, 8418, 293, 1128, 5347, 281, 264, 661, 472, 13, 51162], "temperature": 0.0, "avg_logprob": -0.20648169010243517, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.480371356010437}, {"id": 73, "seek": 30832, "start": 324.28, "end": 329.71999999999997, "text": " Now though, how did we do that?", "tokens": [51162, 823, 1673, 11, 577, 630, 321, 360, 300, 30, 51434], "temperature": 0.0, "avg_logprob": -0.20648169010243517, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.480371356010437}, {"id": 74, "seek": 30832, "start": 329.71999999999997, "end": 333.15999999999997, "text": " We thought to use the best crates that are available for doing that.", "tokens": [51434, 492, 1194, 281, 764, 264, 1151, 941, 1024, 300, 366, 2435, 337, 884, 300, 13, 51606], "temperature": 0.0, "avg_logprob": -0.20648169010243517, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.480371356010437}, {"id": 75, "seek": 33316, "start": 333.16, "end": 342.76000000000005, "text": " We wanted to use Tonic and Tokyo because Tonic offers GRPC which will allow us to make", "tokens": [50364, 492, 1415, 281, 764, 11385, 299, 293, 15147, 570, 11385, 299, 7736, 10903, 12986, 597, 486, 2089, 505, 281, 652, 50844], "temperature": 0.0, "avg_logprob": -0.26170969009399414, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.6173266172409058}, {"id": 76, "seek": 33316, "start": 342.76000000000005, "end": 348.48, "text": " clowns that are not in Python if we need to, thanks to the protobuf that is implemented", "tokens": [50844, 22209, 82, 300, 366, 406, 294, 15329, 498, 321, 643, 281, 11, 3231, 281, 264, 1742, 996, 2947, 300, 307, 12270, 51130], "temperature": 0.0, "avg_logprob": -0.26170969009399414, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.6173266172409058}, {"id": 77, "seek": 33316, "start": 348.48, "end": 352.8, "text": " in many languages and the GRPC protocol as well.", "tokens": [51130, 294, 867, 8650, 293, 264, 10903, 12986, 10336, 382, 731, 13, 51346], "temperature": 0.0, "avg_logprob": -0.26170969009399414, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.6173266172409058}, {"id": 78, "seek": 33316, "start": 352.8, "end": 359.68, "text": " Polar, as I mentioned it already, rings because in addition of setting up a policy, for example,", "tokens": [51346, 3635, 289, 11, 382, 286, 2835, 309, 1217, 11, 11136, 570, 294, 4500, 295, 3287, 493, 257, 3897, 11, 337, 1365, 11, 51690], "temperature": 0.0, "avg_logprob": -0.26170969009399414, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.6173266172409058}, {"id": 79, "seek": 35968, "start": 359.72, "end": 364.88, "text": " if I don't want people to access a specific two names or whatever, there's that.", "tokens": [50366, 498, 286, 500, 380, 528, 561, 281, 2105, 257, 2685, 732, 5288, 420, 2035, 11, 456, 311, 300, 13, 50624], "temperature": 0.0, "avg_logprob": -0.30062106836622005, "compression_ratio": 1.652, "no_speech_prob": 0.42613548040390015}, {"id": 80, "seek": 35968, "start": 364.88, "end": 370.76, "text": " But rings, we always ring implementation directly to verify a piece and I need to provide my", "tokens": [50624, 583, 11136, 11, 321, 1009, 4875, 11420, 3838, 281, 16888, 257, 2522, 293, 286, 643, 281, 2893, 452, 50918], "temperature": 0.0, "avg_logprob": -0.30062106836622005, "compression_ratio": 1.652, "no_speech_prob": 0.42613548040390015}, {"id": 81, "seek": 35968, "start": 370.76, "end": 374.44, "text": " public key to access to the server.", "tokens": [50918, 1908, 2141, 281, 2105, 281, 264, 7154, 13, 51102], "temperature": 0.0, "avg_logprob": -0.30062106836622005, "compression_ratio": 1.652, "no_speech_prob": 0.42613548040390015}, {"id": 82, "seek": 35968, "start": 374.44, "end": 381.0, "text": " We use ring implementation to do that directly and to check if the key matches and if the", "tokens": [51102, 492, 764, 4875, 11420, 281, 360, 300, 3838, 293, 281, 1520, 498, 264, 2141, 10676, 293, 498, 264, 51430], "temperature": 0.0, "avg_logprob": -0.30062106836622005, "compression_ratio": 1.652, "no_speech_prob": 0.42613548040390015}, {"id": 83, "seek": 35968, "start": 381.0, "end": 382.0, "text": " key is real.", "tokens": [51430, 2141, 307, 957, 13, 51480], "temperature": 0.0, "avg_logprob": -0.30062106836622005, "compression_ratio": 1.652, "no_speech_prob": 0.42613548040390015}, {"id": 84, "seek": 35968, "start": 382.0, "end": 387.44, "text": " And Tokyo because we are using heavily like MAD, the multi-trading, the asynchronous move", "tokens": [51480, 400, 15147, 570, 321, 366, 1228, 10950, 411, 376, 6112, 11, 264, 4825, 12, 43831, 278, 11, 264, 49174, 1286, 51752], "temperature": 0.0, "avg_logprob": -0.30062106836622005, "compression_ratio": 1.652, "no_speech_prob": 0.42613548040390015}, {"id": 85, "seek": 35968, "start": 387.44, "end": 389.48, "text": " and so on.", "tokens": [51752, 293, 370, 322, 13, 51854], "temperature": 0.0, "avg_logprob": -0.30062106836622005, "compression_ratio": 1.652, "no_speech_prob": 0.42613548040390015}, {"id": 86, "seek": 38948, "start": 389.48, "end": 398.48, "text": " For example, when you need to accept a dataset, we spawn a new thread that will send a request", "tokens": [50364, 1171, 1365, 11, 562, 291, 643, 281, 3241, 257, 28872, 11, 321, 17088, 257, 777, 7207, 300, 486, 2845, 257, 5308, 50814], "temperature": 0.0, "avg_logprob": -0.22646407242659683, "compression_ratio": 1.6525821596244132, "no_speech_prob": 0.028409749269485474}, {"id": 87, "seek": 38948, "start": 398.48, "end": 405.20000000000005, "text": " to the data owner saying, do you want to accept this request that is about to leak sensitive", "tokens": [50814, 281, 264, 1412, 7289, 1566, 11, 360, 291, 528, 281, 3241, 341, 5308, 300, 307, 466, 281, 17143, 9477, 51150], "temperature": 0.0, "avg_logprob": -0.22646407242659683, "compression_ratio": 1.6525821596244132, "no_speech_prob": 0.028409749269485474}, {"id": 88, "seek": 38948, "start": 405.20000000000005, "end": 406.20000000000005, "text": " data?", "tokens": [51150, 1412, 30, 51200], "temperature": 0.0, "avg_logprob": -0.22646407242659683, "compression_ratio": 1.6525821596244132, "no_speech_prob": 0.028409749269485474}, {"id": 89, "seek": 38948, "start": 406.20000000000005, "end": 411.76, "text": " It's not right in this way, but it is this and can come with now.", "tokens": [51200, 467, 311, 406, 558, 294, 341, 636, 11, 457, 309, 307, 341, 293, 393, 808, 365, 586, 13, 51478], "temperature": 0.0, "avg_logprob": -0.22646407242659683, "compression_ratio": 1.6525821596244132, "no_speech_prob": 0.028409749269485474}, {"id": 90, "seek": 38948, "start": 411.76, "end": 415.72, "text": " Instead of blocking the whole process, I will have a thread that will time out after a while", "tokens": [51478, 7156, 295, 17776, 264, 1379, 1399, 11, 286, 486, 362, 257, 7207, 300, 486, 565, 484, 934, 257, 1339, 51676], "temperature": 0.0, "avg_logprob": -0.22646407242659683, "compression_ratio": 1.6525821596244132, "no_speech_prob": 0.028409749269485474}, {"id": 91, "seek": 41572, "start": 415.72, "end": 418.40000000000003, "text": " if I don't access it, I reject it.", "tokens": [50364, 498, 286, 500, 380, 2105, 309, 11, 286, 8248, 309, 13, 50498], "temperature": 0.0, "avg_logprob": -0.34458507191051135, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.05442499741911888}, {"id": 92, "seek": 41572, "start": 418.40000000000003, "end": 425.20000000000005, "text": " But I can say yes or no and other requests such as a simple one or not, sensitive one", "tokens": [50498, 583, 286, 393, 584, 2086, 420, 572, 293, 661, 12475, 1270, 382, 257, 2199, 472, 420, 406, 11, 9477, 472, 50838], "temperature": 0.0, "avg_logprob": -0.34458507191051135, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.05442499741911888}, {"id": 93, "seek": 41572, "start": 425.20000000000005, "end": 426.20000000000005, "text": " will be accepted.", "tokens": [50838, 486, 312, 9035, 13, 50888], "temperature": 0.0, "avg_logprob": -0.34458507191051135, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.05442499741911888}, {"id": 94, "seek": 41572, "start": 426.20000000000005, "end": 432.44000000000005, "text": " And so move plus tonic to Tokyo that makes very well together and allow many connections", "tokens": [50888, 400, 370, 1286, 1804, 2952, 299, 281, 15147, 300, 1669, 588, 731, 1214, 293, 2089, 867, 9271, 51200], "temperature": 0.0, "avg_logprob": -0.34458507191051135, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.05442499741911888}, {"id": 95, "seek": 41572, "start": 432.44000000000005, "end": 433.44000000000005, "text": " as we want.", "tokens": [51200, 382, 321, 528, 13, 51250], "temperature": 0.0, "avg_logprob": -0.34458507191051135, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.05442499741911888}, {"id": 96, "seek": 41572, "start": 433.44000000000005, "end": 437.28000000000003, "text": " This is the best we could dream of.", "tokens": [51250, 639, 307, 264, 1151, 321, 727, 3055, 295, 13, 51442], "temperature": 0.0, "avg_logprob": -0.34458507191051135, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.05442499741911888}, {"id": 97, "seek": 41572, "start": 437.28000000000003, "end": 441.16, "text": " As I was about to show, that was supposed to be in the Gullo collab, but it's an easier", "tokens": [51442, 1018, 286, 390, 466, 281, 855, 11, 300, 390, 3442, 281, 312, 294, 264, 460, 858, 78, 44228, 11, 457, 309, 311, 364, 3571, 51636], "temperature": 0.0, "avg_logprob": -0.34458507191051135, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.05442499741911888}, {"id": 98, "seek": 41572, "start": 441.16, "end": 443.36, "text": " representation here.", "tokens": [51636, 10290, 510, 13, 51746], "temperature": 0.0, "avg_logprob": -0.34458507191051135, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.05442499741911888}, {"id": 99, "seek": 44336, "start": 443.36, "end": 449.08000000000004, "text": " We have for simplicity reason, sorry, Python code, but only a few lines.", "tokens": [50364, 492, 362, 337, 25632, 1778, 11, 2597, 11, 15329, 3089, 11, 457, 787, 257, 1326, 3876, 13, 50650], "temperature": 0.0, "avg_logprob": -0.3177099024995844, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.14479437470436096}, {"id": 100, "seek": 44336, "start": 449.08000000000004, "end": 455.64, "text": " The data in all part that uploads the dataset set up a policy and for example, I can reject", "tokens": [50650, 440, 1412, 294, 439, 644, 300, 48611, 264, 28872, 992, 493, 257, 3897, 293, 337, 1365, 11, 286, 393, 8248, 50978], "temperature": 0.0, "avg_logprob": -0.3177099024995844, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.14479437470436096}, {"id": 101, "seek": 44336, "start": 455.64, "end": 461.2, "text": " my dataset, but I can allow sensitive request, but I want it to log it.", "tokens": [50978, 452, 28872, 11, 457, 286, 393, 2089, 9477, 5308, 11, 457, 286, 528, 309, 281, 3565, 309, 13, 51256], "temperature": 0.0, "avg_logprob": -0.3177099024995844, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.14479437470436096}, {"id": 102, "seek": 44336, "start": 461.2, "end": 462.2, "text": " Oh, shit.", "tokens": [51256, 876, 11, 4611, 13, 51306], "temperature": 0.0, "avg_logprob": -0.3177099024995844, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.14479437470436096}, {"id": 103, "seek": 44336, "start": 462.2, "end": 463.2, "text": " Thanks, everyone.", "tokens": [51306, 2561, 11, 1518, 13, 51356], "temperature": 0.0, "avg_logprob": -0.3177099024995844, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.14479437470436096}, {"id": 104, "seek": 44336, "start": 463.2, "end": 464.2, "text": " Thank you.", "tokens": [51356, 1044, 291, 13, 51406], "temperature": 0.0, "avg_logprob": -0.3177099024995844, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.14479437470436096}, {"id": 105, "seek": 44336, "start": 464.2, "end": 465.2, "text": " Thank you.", "tokens": [51406, 1044, 291, 13, 51456], "temperature": 0.0, "avg_logprob": -0.3177099024995844, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.14479437470436096}, {"id": 106, "seek": 44336, "start": 465.2, "end": 466.2, "text": " Thank you.", "tokens": [51456, 1044, 291, 13, 51506], "temperature": 0.0, "avg_logprob": -0.3177099024995844, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.14479437470436096}, {"id": 107, "seek": 44336, "start": 466.2, "end": 466.2, "text": "", "tokens": [], "temperature": 0.0, "avg_logprob": -0.3177099024995844, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.14479437470436096, "words": []}, {"id": 108, "seek": 47336, "start": 473.36, "end": 474.36, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.6674781279130415, "compression_ratio": 1.0, "no_speech_prob": 0.9952979683876038}, {"id": 109, "seek": 47336, "start": 474.36, "end": 474.36, "text": "", "tokens": [], "temperature": 0.0, "avg_logprob": -0.6674781279130415, "compression_ratio": 1.0, "no_speech_prob": 0.9952979683876038, "words": []}], "language": "en"}