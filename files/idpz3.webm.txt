[00:00.000 --> 00:08.560]  All right, good.
[00:08.560 --> 00:13.600]  So thank you for joining me this afternoon for this presentation.
[00:13.600 --> 00:20.200]  I'm a researcher at KU Leuven, and I'll be talking about our work on a reasoning engine
[00:20.200 --> 00:23.960]  for FODOT.
[00:23.960 --> 00:32.000]  So this morning, I connected to Chad GPT, and I asked him, or it, I don't know, what's
[00:32.000 --> 00:38.080]  the, I'm twice the age of my son, who is 15 years younger than me, or old MI.
[00:38.080 --> 00:43.320]  And it started pretty well by saying that let's give it, let's give a variable a name,
[00:43.320 --> 00:45.760]  and then let's write the formula.
[00:45.760 --> 00:51.560]  But then when it tried to solve the equation, somehow he got lost, and he was not able to
[00:51.560 --> 00:54.120]  find the correct answer.
[00:54.120 --> 01:00.800]  And that shows that Chad GPT is very capable at understanding English, but not so much
[01:00.800 --> 01:09.400]  about reasoning, about, it does not have the cognitive skills to solve the equation.
[01:09.400 --> 01:14.920]  And so if we ever will be able to create a machine that can pass the Turing test, of
[01:14.920 --> 01:21.240]  course it needs to be able to handle natural language, but it also has to have the cognitive
[01:21.240 --> 01:26.320]  skills that we human have, like those listed here, we should be able, it should be able
[01:26.320 --> 01:30.600]  to learn from others through symbolic communication.
[01:30.600 --> 01:35.160]  It should be able to apply knowledge in new ways to perform new tasks, like the capacity
[01:35.160 --> 01:41.600]  to solve an equation, that's a knowledge that you can apply in many different settings.
[01:41.600 --> 01:47.520]  And it should have other cognitive skills, like the capability to ask relevant questions,
[01:47.520 --> 01:49.920]  and to explain its reasoning.
[01:49.920 --> 01:56.760]  In all these types of skills, we try to implement them, and the field of study at the university
[01:56.760 --> 02:02.840]  is called knowledge representation and reasoning, and that's what we are working on.
[02:02.840 --> 02:09.800]  Now one way to have a computer solve a riddle, like on the edge that I gave earlier, is to
[02:09.800 --> 02:13.400]  program the system, to program the computer.
[02:13.400 --> 02:18.960]  But there's a big difference between a statement in a program and a statement of knowledge.
[02:18.960 --> 02:27.440]  If, for example, I write in a program that F is equal to M multiplied by A, that's a
[02:27.440 --> 02:33.800]  statement in a procedure, you can compute F if you know M and A. But that's quite different
[02:33.800 --> 02:40.080]  from what you would see in a physics book, where the second law of motion would really
[02:40.080 --> 02:46.240]  mean that given any two of those quantities, you can compute the third one.
[02:46.240 --> 02:51.360]  And so you can really reason in multiple directions, unlike in a procedural statement.
[02:51.360 --> 02:55.880]  So that's a big difference between a program and knowledge.
[02:55.880 --> 03:00.320]  And you might think that a prologue, because it's a so-called declarative language, does
[03:00.320 --> 03:04.000]  not have that problem, but in fact it does.
[03:04.000 --> 03:10.760]  If you have a prologue program, like you can vote if you are more than 18, it can only
[03:10.760 --> 03:15.560]  compute vote from the fact that you are more than 18 or not.
[03:15.560 --> 03:17.640]  It cannot go the other way around.
[03:17.640 --> 03:22.360]  And that's quite unlike what you would write in a logic statement, that you can vote if
[03:22.360 --> 03:27.160]  and only if your age is larger than 18.
[03:27.160 --> 03:31.800]  And with that kind of statement, you should be able to say, to infer your age or at least
[03:31.800 --> 03:37.280]  a minimum value of your age from your right to vote.
[03:37.280 --> 03:39.200]  So really, a prologue is a programming language.
[03:39.200 --> 03:43.320]  It's not a knowledge representation language.
[03:43.320 --> 03:47.520]  Now, what is programming?
[03:47.520 --> 03:53.200]  It's actually the process of translating the knowledge that we have of a problem into a
[03:53.200 --> 03:58.240]  program that can then give a problem, solve it.
[03:58.240 --> 04:01.720]  And then if you have another problem, you have to apply that knowledge and convert it
[04:01.720 --> 04:04.680]  into another program, possibly, to solve it.
[04:04.680 --> 04:10.640]  And so depending on what kind of information you get as input and what kind of information
[04:10.640 --> 04:14.840]  you want as output, you will have to write different programs.
[04:14.840 --> 04:20.160]  And sometimes these programs will be quite different, which is a pity because the knowledge
[04:20.160 --> 04:22.120]  that is implicit in the program is the same.
[04:22.120 --> 04:26.680]  So why do we have to write so many different programs?
[04:26.680 --> 04:33.040]  This process, the industry of converting knowledge into a program is, of course, a big industry.
[04:33.040 --> 04:34.600]  It's the acting industry.
[04:34.600 --> 04:37.800]  That's what makes us live.
[04:37.800 --> 04:42.680]  But still, there's possibly a better way to do it, and that's what we are working on.
[04:42.680 --> 04:51.240]  If we can represent the knowledge into a knowledge base and then develop some generic inferences
[04:51.240 --> 04:57.920]  depending on the type of problem that you have, then you don't have to rewrite the program
[04:57.920 --> 04:58.920]  every time.
[04:58.920 --> 05:03.480]  You can use a generic inference, give it the knowledge base that you have, the input of
[05:03.480 --> 05:06.320]  your problem, and it will give you the answer.
[05:06.320 --> 05:11.880]  So for example, for the age riddle that I had in the beginning, the generic inference
[05:11.880 --> 05:14.360]  is what we call model search.
[05:14.360 --> 05:20.280]  So we search for a model of the equation, and that's a very generic skill that can be
[05:20.280 --> 05:27.280]  implemented once and then applied in many different ways.
[05:27.280 --> 05:30.800]  So what is knowledge then?
[05:30.800 --> 05:36.520]  Knowledge is a statement of knowledge, it's a statement that is true in all possible worlds,
[05:36.520 --> 05:39.120]  like for example, the second law of motion.
[05:39.120 --> 05:44.040]  It's true in all possible worlds that you can imagine.
[05:44.040 --> 05:48.320]  You can also say that a statement of knowledge is true in all acceptable worlds.
[05:48.320 --> 05:55.760]  That's what the law says, like the regulations, what is acceptable as a behavior.
[05:55.760 --> 06:00.840]  Sometimes a statement of knowledge can be about what you desire the world to be.
[06:00.840 --> 06:07.040]  So it's an expectation, or it can be about a particular situation that you face, and
[06:07.040 --> 06:10.240]  all these are different propositional attitudes.
[06:10.240 --> 06:14.280]  If you are interested in philosophy, you can go and look at Wittgenstein and his book,
[06:14.280 --> 06:20.240]  but that's the idea behind this.
[06:20.240 --> 06:25.440]  And so we have been thinking about what would be a good knowledge representation language,
[06:25.440 --> 06:31.880]  what could be its good attributes, and it should be, it should use symbols that have
[06:31.880 --> 06:43.440]  very simple semantics, like the age of a person, like very simple predicates and functions.
[06:43.440 --> 06:47.400]  It should have statements that are close to natural language, so it should be very easy
[06:47.400 --> 06:52.280]  to express a statement in natural language into a statement in knowledge representation,
[06:52.280 --> 06:56.160]  and vice versa, when you have a representation of knowledge, you should be able to read it
[06:56.160 --> 07:00.080]  very easily into a natural language.
[07:00.080 --> 07:01.320]  And it should be expressive.
[07:01.320 --> 07:06.800]  It should be able to express complex forms of knowledge.
[07:06.800 --> 07:14.440]  So first order logic is a nice candidate for expressing knowledge.
[07:14.440 --> 07:20.920]  That's why it's one of the basic language to express scientific knowledge, for example.
[07:20.920 --> 07:25.840]  We do use it in school for a good purpose.
[07:25.840 --> 07:30.920]  It has indeed some symbols with simple semantics.
[07:30.920 --> 07:36.160]  The statements are close to natural language, but still it is not as expressive as we would
[07:36.160 --> 07:37.920]  like it to be.
[07:37.920 --> 07:42.040]  So it has a construct like quantification.
[07:42.040 --> 07:47.520]  You can say for every x something is true, or there is an x such that something is true,
[07:47.520 --> 07:49.520]  but it doesn't have aggregates.
[07:49.520 --> 07:55.320]  It doesn't have inductive definitions, which are complex ways of explaining how you would
[07:55.320 --> 08:00.920]  compute the value of some elements.
[08:00.920 --> 08:09.840]  And so we introduce a language called fo dot, the dot being representing a list of extensions.
[08:09.840 --> 08:18.280]  And so it's first order logic extended with types, or so-called sorts in the literature,
[08:18.280 --> 08:24.880]  with definitions or inductive definitions, with arithmetic so that you can do some computations.
[08:24.880 --> 08:30.200]  It's still this point limited to linear arithmetic, so you cannot do transcendental functions
[08:30.200 --> 08:33.920]  like sine and cosine.
[08:33.920 --> 08:41.160]  It supports aggregates, like counting the cardinality of elements that satisfy some conditions,
[08:41.160 --> 08:46.640]  as well as the minimal or maximum, et cetera, and it has some more advanced functions like
[08:46.640 --> 08:51.040]  you're dealing with partial functions, functions that are undefined for some values of their
[08:51.040 --> 08:54.720]  arguments and intentional objects.
[08:54.720 --> 08:59.280]  You can look at the documentation if you want to have more details.
[08:59.280 --> 09:03.520]  Maybe I can give you some examples of statements.
[09:03.520 --> 09:12.240]  The first one would be for regulation about COVID, and you could read it like this.
[09:12.240 --> 09:18.960]  So if you want to do an activity of outdoor sports, then you have to finish it before
[09:18.960 --> 09:26.640]  8 p.m. in the evening, and then either you have a mask or you have a COVID-safe ticket.
[09:26.640 --> 09:37.360]  So the hat is a symbol, is a logic symbol for and, and the V is a logic symbol for all.
[09:37.360 --> 09:42.960]  The second statement would be like for an organization of an event like this one, or
[09:42.960 --> 09:46.160]  for a course, planning of a course.
[09:46.160 --> 09:53.680]  For every course provided by the university, the number of students that attend the course
[09:53.680 --> 09:57.800]  should be less than the capacity of the room of the course.
[09:57.800 --> 10:02.640]  That's really a very simple statement that can then be used into, for the search of a
[10:02.640 --> 10:06.240]  correct planning.
[10:06.240 --> 10:14.600]  The bottom example is an example of a definition where you have rules that can be applied.
[10:14.600 --> 10:20.840]  And the first, so it looks a little bit like a prologue statement that can then be used
[10:20.840 --> 10:29.840]  to define the tax rate of, for, for, for, for selling a house, for example.
[10:29.840 --> 10:36.520]  And so at KU Leuven, we have developed, we are developing these technologies.
[10:36.520 --> 10:40.240]  I mentioned FODOT, which is one of the two knowledge representation language.
[10:40.240 --> 10:41.840]  This is the more powerful one.
[10:41.840 --> 10:48.840]  CDMN is a table-like way to, to introduce decision tables.
[10:48.840 --> 10:54.360]  And it can be used by business, by, by business analysts, I would say, in a, and it's a little
[10:54.360 --> 10:57.440]  bit simpler than, than FODOT.
[10:57.440 --> 11:02.680]  Then IDPZ3 is your reasoning engine that can use that knowledge base, as well as some
[11:02.680 --> 11:08.160]  inputs to compute, to, to, to perform some reasoning tasks.
[11:08.160 --> 11:12.520]  And on top of that, we have developed the IC, the Interactive Concertant, as we call
[11:12.520 --> 11:13.520]  it.
[11:13.520 --> 11:19.840]  So it's a little bit like a machine that can pass a Turing test, but we vote the knowledge,
[11:19.840 --> 11:24.800]  the natural language capabilities, but it can reason like a Turing test machine would,
[11:24.800 --> 11:27.960]  would need to do.
[11:27.960 --> 11:30.520]  And these parts are really generic.
[11:30.520 --> 11:36.760]  So once it is developed, then it can be reused very, very easily.
[11:36.760 --> 11:41.600]  So the IDPZ3 is the reasoning engine that has these capabilities.
[11:41.600 --> 11:46.960]  It can ask questions like, is it possible, according to the knowledge base of the possible
[11:46.960 --> 11:49.440]  words that we give him.
[11:49.440 --> 11:51.320]  That's called model checking.
[11:51.320 --> 11:57.800]  It can ask, you can ask him what would be a possible word, again, according to the knowledge,
[11:57.800 --> 11:59.480]  the knowledge base.
[11:59.480 --> 12:03.520]  That's model generation or model search, model expansion.
[12:03.520 --> 12:04.600]  What is relevant?
[12:04.600 --> 12:11.160]  What would, what should I get for, as information to check, to, to be able to construct a model
[12:11.160 --> 12:17.280]  of the, of the, of the, of the knowledge base?
[12:17.280 --> 12:22.520]  What are the consequences of some partial information that I have about a situation?
[12:22.520 --> 12:25.560]  I have some information about the situation that I face.
[12:25.560 --> 12:28.080]  What are the consequences of that?
[12:28.080 --> 12:32.320]  It can then give you some explanations about those consequences.
[12:32.320 --> 12:33.560]  Why this is a consequence?
[12:33.560 --> 12:36.560]  So it can explain its own reasoning.
[12:36.560 --> 12:39.640]  And it can also do some kind of optimization.
[12:39.640 --> 12:46.280]  Again, you can look at the website to have some more information there.
[12:46.280 --> 12:50.000]  So the reasoning engine is hosted in a Python program.
[12:50.000 --> 12:56.880]  So it's a Python program that will tell which inference to, to, to, to perform.
[12:56.880 --> 13:04.240]  And so it's easily downloadable from the, the Python package index.
[13:04.240 --> 13:08.400]  And so let me talk about the interactive consultants.
[13:08.400 --> 13:17.720]  Let's say that you have some challenge to engineer a design that meets some customer requirements.
[13:17.720 --> 13:23.720]  Well, to address that challenge, we develop a novel class of applets that can perform
[13:23.720 --> 13:26.680]  various forms of reasoning in, in the domain of expertise.
[13:26.680 --> 13:33.480]  And that will help the engineer finds proper design.
[13:33.480 --> 13:36.240]  So how does that work?
[13:36.240 --> 13:42.400]  So you have the requirements that come from, from the outside, from the environment, from,
[13:42.400 --> 13:43.600]  from, from the customer.
[13:43.600 --> 13:45.560]  So you have a set of requirements.
[13:45.560 --> 13:51.560]  The engineer will then interact with the application to enter the requirements that he knows.
[13:51.560 --> 13:58.000]  As well as some tentative decisions that he thinks would be proper design.
[13:58.000 --> 14:02.560]  And then in return, the system will ask him some additional question.
[14:02.560 --> 14:08.400]  And really, you, you, you should know exactly what is the property of this material or what
[14:08.400 --> 14:11.920]  is the expected operating temperature of the, of the system.
[14:11.920 --> 14:16.040]  So it's, it's starting to have a conversation with the engineer.
[14:16.040 --> 14:20.480]  It will tell him what are the prerequisites of his tentative decisions.
[14:20.480 --> 14:24.920]  So if he says, oh, I'd like to use steel, well, the system says, okay, but then you
[14:24.920 --> 14:28.960]  need to have, I don't know, some kind of pressure that is not higher than, than something
[14:28.960 --> 14:31.920]  else, whatever.
[14:31.920 --> 14:35.840]  It will tell him the consequences of his, of his decisions.
[14:35.840 --> 14:41.960]  It will be able to give some explanations and then some do some optimization of the design.
[14:41.960 --> 14:48.200]  So it's really a consultant that will help the engineer come to a solution.
[14:48.200 --> 14:53.880]  And all that with some proprietary expertise of the domain of, of, of interest that will
[14:53.880 --> 14:57.680]  be used to do the, the reasoning.
[14:57.680 --> 15:03.880]  If I have time, I'll give you a quick demo, maybe I'll go through the slides first.
[15:03.880 --> 15:08.080]  So we are developing that in partnership with some industrial partners.
[15:08.080 --> 15:12.480]  It is a big multinational that prefers to keep privates.
[15:12.480 --> 15:13.640]  I have five minutes left.
[15:13.640 --> 15:14.640]  Thank you.
[15:14.640 --> 15:20.680]  But we are also working with Siemens with Flandersmake, which is a research lab for
[15:20.680 --> 15:24.440]  the industry in, in, in, in Flanders.
[15:24.440 --> 15:30.720]  We entirely select in the, the banking sector, heads up with notaries.
[15:30.720 --> 15:37.000]  And the idea is to reduce the decision time of, of some experts.
[15:37.000 --> 15:44.480]  For example, in the Flandersmake, it was to reduce the time to select a glue, to glue
[15:44.480 --> 15:46.880]  two materials together.
[15:46.880 --> 15:52.080]  And typically they had to go through data sheets and to find the proper glue.
[15:52.080 --> 15:55.040]  And with the tool, they cannot do it in less than five minutes.
[15:55.040 --> 16:01.440]  And with the development cause, that was quite, quite low.
[16:01.440 --> 16:06.240]  This is an example with the big multinational company.
[16:06.240 --> 16:10.200]  They had to design custom industrial components.
[16:10.200 --> 16:15.720]  The expertise of doing that was in the head of the experienced engineers.
[16:15.720 --> 16:18.000]  But they wanted to empower the younger engineers.
[16:18.000 --> 16:22.800]  And so we formalized the knowledge of the experts into the system.
[16:22.800 --> 16:26.480]  And then with the interactive consultant, the younger engineers can play around with
[16:26.480 --> 16:32.280]  the different options and find a proper design that is right the first time.
[16:32.280 --> 16:37.280]  And the fact of formalizing the knowledge in, in the system really makes that knowledge
[16:37.280 --> 16:42.120]  an asset of the company that can then be managed as an over asset.
[16:42.120 --> 16:46.960]  And the organization becomes a learning organization.
[16:46.960 --> 16:49.240]  So why do we do this now?
[16:49.240 --> 16:52.200]  Why, why is it possible now and not before?
[16:52.200 --> 16:58.920]  That's because there are new solvers that are capable of making those types of reasoning.
[16:58.920 --> 17:04.760]  It's a big progress in the artificial intelligence world, but it's a little bit less well known
[17:04.760 --> 17:06.720]  than neural networks and so on.
[17:06.720 --> 17:09.560]  But it is quite, quite a nice progress.
[17:09.560 --> 17:13.880]  And we try to put that into, into practice.
[17:13.880 --> 17:17.760]  And also, we are getting a new understanding of what is knowledge and how to use it.
[17:17.760 --> 17:23.400]  And that's why this is, this is an interesting area.
[17:23.400 --> 17:27.880]  Let me go back to, to the demo.
[17:27.880 --> 17:34.960]  So you can go to the IDPZ3, ooh, I don't have internet.
[17:34.960 --> 17:37.960]  I did have it before.
[17:37.960 --> 17:42.000]  Yeah, sorry about that.
[17:42.000 --> 17:45.640]  So I won't be able to show it, but that's, that's the end of my presentation.
[17:45.640 --> 17:48.920]  If there are any questions, I'll be happy to answer.
[17:48.920 --> 17:49.920]  Thank you.
[17:49.920 --> 17:50.920]  Yes.
[17:50.920 --> 18:05.920]  Can you explain how this, how you approach differences from the classical expert systems?
[18:05.920 --> 18:08.920]  What's the next step?
[18:08.920 --> 18:14.200]  So, so yeah, the, the question is how is this, if I understand well, how is this different
[18:14.200 --> 18:15.800]  from expert systems, right?
[18:15.800 --> 18:19.760]  Because expert systems were quite popular back in the 80s and 90s.
[18:19.760 --> 18:21.760]  And this looks very much the same.
[18:21.760 --> 18:24.960]  But the thing is that expert systems were very much like prologue.
[18:24.960 --> 18:30.520]  And so they could make inferences in one direction, but, but they could not reason with, with,
[18:30.520 --> 18:32.080]  in, in any other direction.
[18:32.080 --> 18:35.040]  So it could not reason with partial information, for example.
[18:35.040 --> 18:40.120]  Well, here, even with partial information, it's capable of doing some, some, some, to,
[18:40.120 --> 18:43.160]  to come up with, with some conclusions.
[18:43.160 --> 18:48.160]  So it's very different from, from programming from, from knowledge.
[18:48.160 --> 18:49.160]  Yeah.
[18:49.160 --> 18:50.160]  Yeah.
[18:50.160 --> 18:57.160]  So in the use case you presented, you said that you took the expert note.
[18:57.160 --> 19:02.160]  How can you formalize it in order to be used by the original engine?
[19:02.160 --> 19:03.160]  Yeah.
[19:03.160 --> 19:06.160]  So the representation of the data is on FODAR.
[19:06.160 --> 19:07.160]  Yes.
[19:07.160 --> 19:09.160]  The representation of the knowledge is in FODAR.
[19:09.160 --> 19:10.160]  Yes.
[19:10.160 --> 19:11.160]  Okay.
[19:11.160 --> 19:14.160]  How, what's the process of transferring the data?
[19:14.160 --> 19:16.160]  We're just discussing with experts.
[19:16.160 --> 19:17.160]  Right.
[19:17.160 --> 19:18.160]  Yeah.
[19:18.160 --> 19:21.440]  So for the moment it's done by a knowledge engineer, as we call it, who talks with the
[19:21.440 --> 19:25.160]  experts and who looks in the data sheets and then that formalize it.
[19:25.160 --> 19:28.080]  It's like a programmer if you want, but for knowledge.
[19:28.080 --> 19:32.160]  So he has to, to, to formalize the knowledge into the, the, the formal language.
[19:32.160 --> 19:33.160]  Okay.
[19:33.160 --> 19:34.160]  And one more follow-up.
[19:34.160 --> 19:39.160]  So data representation is something like a decision tree or something?
[19:39.160 --> 19:43.160]  The, the representation is what I showed earlier.
[19:43.160 --> 19:50.160]  These are statements in logic, like the one I showed.
[19:50.160 --> 19:56.160]  Like this, this one's here.
[19:56.160 --> 20:00.160]  Let's, let's go ahead and show.
[20:00.160 --> 20:07.160]  So it would be statements like these that look very much like statement in English, but
[20:07.160 --> 20:09.160]  they would use some kind of formal.
[20:09.160 --> 20:12.160]  So the knowledge base is really just a text file.
[20:12.160 --> 20:13.160]  Okay.
[20:13.160 --> 20:14.160]  Steven?
[20:14.160 --> 20:15.160]  Yeah.
[20:15.160 --> 20:16.160]  Maybe one more.
[20:16.160 --> 20:18.160]  You mentioned humor.
[20:18.160 --> 20:20.160]  You mentioned humor.
[20:20.160 --> 20:21.160]  Yes.
[20:21.160 --> 20:25.160]  It's not capable of that yet, but we are working on it.
[20:25.160 --> 20:26.160]  All right.
[20:26.160 --> 20:27.160]  All right.
[20:27.160 --> 20:28.160]  Yeah.
[20:28.160 --> 20:30.160]  One more.
[20:30.160 --> 20:31.160]  Yeah.
[20:31.160 --> 20:38.160]  Was it a lot of work to customize Z3 to work with this?
[20:38.160 --> 20:39.160]  To work with this?
[20:39.160 --> 20:40.160]  Yeah.
[20:40.160 --> 20:41.160]  It was some, some work.
[20:41.160 --> 20:42.160]  Yes.
[20:42.160 --> 20:47.160]  So the question is, we use Z3 as a back end for the reasoning engine.
[20:47.160 --> 20:52.160]  How much work did it require to build to the reasoning engine, engine that we, we have?
[20:52.160 --> 20:55.160]  Of course, Z3 is already quite capable.
[20:55.160 --> 20:57.160]  So it's very, very useful.
[20:57.160 --> 21:02.160]  On top of that, we have new language constructs like aggregates that Z3 does not have.
[21:02.160 --> 21:03.160]  Natively.
[21:03.160 --> 21:09.160]  And we have also some additional inference or reasoning capabilities on top of it.
[21:09.160 --> 21:14.160]  Like the term, determination of what is the relevant question in the particular case.
[21:14.160 --> 21:16.160]  So, yeah.
[21:16.160 --> 21:21.160]  The system capable of recognizing or even pointing out some coherent specifications in the knowledge
[21:21.160 --> 21:22.160]  base.
[21:22.160 --> 21:23.160]  Could you speak a bit louder?
[21:23.160 --> 21:24.160]  I don't hear you.
[21:24.160 --> 21:29.160]  Yes, indeed.
[21:29.160 --> 21:30.160]  Right.
[21:30.160 --> 21:31.160]  Yeah.
[21:31.160 --> 21:32.160]  Yeah.
[21:32.160 --> 21:37.160]  So the question is, what happens is the knowledge base have conflicting statements in it, because
[21:37.160 --> 21:40.160]  then it cannot reason correctly.
[21:40.160 --> 21:47.160]  And actually, we have an inference that will try to extract the minimum set of instances
[21:47.160 --> 21:48.160]  of statements in it.
[21:48.160 --> 21:55.160]  That will make the, that makes the knowledge base inconsistent.
[21:55.160 --> 22:01.160]  And then from that inconsistent set of statements, we can try, the knowledge engineer can try
[22:01.160 --> 22:02.160]  to resolve it.
[22:02.160 --> 22:04.160]  Has that been used in practice?
[22:04.160 --> 22:06.160]  It is used, yes, indeed.
[22:06.160 --> 22:09.160]  Has that helped the specific case?
[22:09.160 --> 22:12.160]  In that specific case, I don't remember exactly.
[22:12.160 --> 22:15.160]  I couldn't say, but it could be.
[22:15.160 --> 22:18.160]  I don't know if.
[22:18.160 --> 22:21.160]  Yeah, this should come in.
[22:21.160 --> 22:26.160]  No, no, come on.
[22:26.160 --> 22:29.160]  And your picture is a big form.
[22:29.160 --> 22:36.160]  I thought you were expecting the general picture.
[22:36.160 --> 22:38.160]  There's still one question.
[22:38.160 --> 22:40.160]  If you could stay quiet, please.
[22:40.160 --> 23:02.160]  So the question is whether this could have applications in the medical field, where you
[23:02.160 --> 23:06.160]  have some, I need to reason with some probabilities.
[23:06.160 --> 23:13.160]  If there is this set of symptoms, there's a probability of such that this could happen.
[23:13.160 --> 23:17.160]  At this point, we are not focusing on this type of reasoning with probabilities.
[23:17.160 --> 23:23.160]  There's another group at KU11 that has developed the logic called probabilistic logic, which
[23:23.160 --> 23:28.160]  is an evolution of prologue, which goes in that direction.
[23:28.160 --> 23:33.160]  But this one does not do it.
[23:33.160 --> 23:36.160]  All right, thank you very much.
