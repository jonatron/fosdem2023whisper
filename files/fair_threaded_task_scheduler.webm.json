{"text": " Hello, my name is Vlad, I am a CEO and C++ developer with roughly eight years of experience. Right now I work at a game dev company called Ubisoft, which some of you probably heard about, with mostly low level networking and some bits of system programming. And in Ubisoft, while doing a complete rewrite of our networking stack in one of game engines, I managed to design, I hope, a cool algorithm for doing so-called task scheduling. And today I share this algorithm in the form of this talk and an open source C++ implementation of it. Although, if you don't like C++, it doesn't have to be, today we focus just on the algorithms and they can be implemented in some other language too, like in Rust, I'm sure it can be done in Java, in C-sharp maybe. So there will be a lot of content, so we will be going relatively quick and I ask you to concentrate. Talk will follow the plan firstly, what is task scheduling exactly, because many things can be understood as it, then I explain how it's normally done, what are typical problems with it. I'm actually, at least, known to me and how worked an old task scheduler in my game engine and how works the new one. And then I will briefly show you the benchmarks, how it's verified and what are the future plans for it. So what is task scheduling exactly? Today, in this talk, I mean, as task scheduling, any kind of execution of code, such as code exec functions or something similar, and we just call it task, a generic term. And so to give you a few examples, tasks can be callbacks in a thread pool, or tasks can be watchers in an event loop like in LibF in C, we can have watchers as timers or wrapping sockets and they also have callbacks, or we can also call tasks routines in some routine engine like C++ routines or fibers in Toronto database. So here is a very, very simple trivial scheduler implemented in C++ like pseudo code for simplicity, which demonstrates this example. So it's just a single thread. It has a mutex locked queue for callbacks, and what it does is just executes those callbacks one by one. This is a very simple scheduler. Now let's see if such a basic scheduler can solve a real task, which I had at Ubisoft. Here, tasks execute requests coming to a server, and they handle save games, save game blobs. And there might be tens of thousands of those requests per second, and they are also CPU intensive. So every task might take milliseconds of pure CPU time, and also they consist of multiple steps like, I have to, in each task, lock user profile in some database, then I have to download the save game blob from another database, then I have to do some pre-processing of this blob, some stuff with some manipulations, then I have to upload it back and unlock the user profile. As you can guess, most of the time the task is not doing anything at all. It just sleeps waiting for network input from the databases. So literally more than 90% of times there is nothing happening in this task. The trivial scheduler, which we just saw with single triad, it will not work here, it simply will not scale. Firstly, single triad is not enough to handle so many requests, so being so CPU intensive, it will just choke on CPU. Secondly, we can postpone blocked tasks and do other tasks while the first ones are waiting for some events like network input. So this means we need routines so that tasks could yield, so they could give up their time to some other tasks in the same thread. The game engine I'm working with had a good enough scheduler, which could do the job for some years good enough. This was just a thread pool where each thread had a list of own tasks, and when new tasks were appearing, they were distributed to those threads in around Robin Manor one by one, and they were pinned to those threads forever. They could not migrate between threads. And then what each worker thread does is updates all its tasks with some fixed hard-coded period like once per 100 milliseconds or once per second. Each task, after being updated, it can return false eventually, and it consider it done, and it is deleted. So this is some polling, basically, and we will call this scheduler updater because there isn't much scheduling, really, it just updates those tasks without looking at their state or anything, so we call it updater. This updater thing had some typical problems, like schedulers of this type sometimes do. Firstly, it was unfair, meaning that tasks were pinned to threads, they could not migrate. This leads to a problem that your CPU usage will be unbalanced because some worker threads will get heavy tasks, and a lot of them will stay in the queues, and other threads will get light tasks and will be in idling most of the time. This will happen even if you do perfect round robin, and all your tasks are the same because actually tasks are never the same. Like in my case, all the tasks do the same several steps, but save game blobs, they can vary in size from kilobytes to megabytes, their processing, their downloading, obviously takes not the same time, so some threads will be unfairly loaded, and they will perform worse, at least in terms of latency, because they will have bigger queues, tasks will wait longer in them, and that is not the only problem. The other problem is polling, which in this case means the tasks, each task is updated unconditionally with some fixed period regardless of task state, so every task is updated even if it doesn't have work to do yet, so it's still waiting for network input. What it means is that if you select too big polling interval, then you will have too high latency, more than you could have. For instance, imagine like we have a task with just three steps, each taking five milliseconds, and in between it waits for some network input, and we will update it once per hundred milliseconds. Then your task will always at least take 215 milliseconds. The thing is, you don't always need so much time. Most of the time, like almost always, the network response will arrive earlier than 100 milliseconds expire, and you have events to process, but you are not doing it because it's not yet time to update the task, so we have higher latency than we could have. If you try to fight it, try to set lower polling interval, then you will burn CPU without need, because you will have spurious wakeups, so unnecessary wakeups. You will sometimes wake up tasks before they have stuff to do. Then it sounds too bad, like how expensive can it be, really, and imagine like spurious update of a task would cost us just 10 microseconds. To check a deadline or check an atomic flag, lock and lock, and you text and that's it. It's not much, but if you have 10,000 tasks per second doing those unnecessary wakeups, you just burned 10% of one CPU core, which already sounds worse, and this problem aggravates if you have more threads than CPU cores. Because then you didn't just burn the CPU time. You stole it from other threads, which could spend it on something useful. This problem was actually real, and during low tests, some servers were spending more CPU time on spurious wakeups than on doing actual work, because they were just burning so much for the green data clusters. What we need on the summary from a really performance schedule, firstly, it should be fair. We are not allowed to pin tasks to threads. It doesn't scale. Secondly, we need routines, so that tasks could give up their time, so they could yield and let the worker thread do some other work, other tasks. And also, we have zero tolerance against polling, no polling at all, everything should be event based. And these goals are achieved in a new scheduler, which I do to lack of fantasy, just called the task scheduler. Although the name is a pretty self-explanatory, what it does, the plan is that we will go firstly, we'll look at the big picture of the entire scheduler, and then we will look at individual parts of the scheduler, when you will already know what they do. Imagine like we have a process, this server running, it's a process. It has multiple threads, and they produce tasks. And we have a global object of type task scheduler in the process, like it can be C++ task scheduler, Java task scheduler, whatever language you implemented it in, it is a global object in the process. And those threads, they produce tasks, so they receive some requests from clients and post the, wrap them into tasks and post into the task scheduler in form of some callbacks of some sort. In the scheduler, they will gather in a so-called front queue. Then the scheduler will periodically pick up, take all the tasks from the front queue, and inspect them one by one. It will see that some tasks are ready to be executed right now, the red ones on the slide. They want to be executed at SAP, and some other tasks they do not want to be executed right now, they just yielded. We have routines, so there will be tasks which don't want to be executed now. They are waiting for something. For a deadline or for an explicit wake up for some event, they are moved into the wait queue, where they will wait for their events. So from the wait queue, we extract some older tasks which were already sleeping there for some time, and now their deadline is up, or they were woken up explicitly, either way we extract them from the queue, and all those red tasks go to the ready queue. And from here, they are extracted by the worker threads, which take them from the ready queue one by one and execute. And this is basically the entire pipeline, it's not too complicated, although some of you could already have a question, who does this part? We have external threads posting tasks. We have worker threads doing tasks, but who does the scheduling itself, managing management of the queues? The thing is, there is no dedicated thread doing just the scheduling. Instead, the worker threads compete for doing the scheduling, depending on who of them is idle. Imagine, like this big rectangle with queues, it's a room with a single key to it. And the worker threads, sometimes, depending on who of them is idle, again, will try to pick out the key. Whoever does it first, enters the room, does the scheduling, this queue management stuff, leaves the room, and starts doing tasks. So all the threads are the same. There is no threads having goals of some sort, like a naive implementation could do. And it's a bit like dining philosophers' problem, except that we have just one fork here. And this big rectangle, in this case, is just a plate of spaghetti, but not on code, code is clean. To improve understanding, there is a short visual example I prepared. Imagine, like, we have five tasks. They are posted onto the front queue, and one of the worker threads has the scheduling key right now. It will extract the tasks from the queue. We'll see that a couple of them yielded. They go to the wait queue, waiting for something, and the others are moved into the ready queue. From here, they are picked up by the worker threads. Nobody is doing the scheduling right now. All the threads are doing some actual work. A couple of tasks are done, and suddenly, those waiting tasks are woken up, or their deadline is up. They want to be executed now. So one of the worker threads will eventually pick up the scheduling key. We'll notice this. We'll move the tasks into the ready queue, and in parallel, some other thread finished and older tasks. Now, those two tasks are picked up by a couple of random threads. They are done, and some other thread will pick up the scheduling key, and the process repeats all the time when new tasks arrive. This is it. What we need to implement all this cool stuff, the language and the libraries, which we will be using, need to provide us with the following stuff, at least. We need mutexes, containers like race, lists, condition variables, and not important for the algorithm, but for the implementation, for the performance, it's extremely important. We will also need log-free atomic operations. Just in case not all of you know what they are, here is a short pseudo code explaining what these log-free atomics are, we will need three of them. Firstly, it's atomic load, which is basically reading a variable, but with respect to so-called memory models, which, again, Google afterwards, it's too complicated topic to dive in right now. We will also need atomic compare exchange, which is conditional assignment. So we set a new value to some variable if it was equal to something else which we wanted to check. And we will also need atomic exchange. So it sets a new value and returns the old value. The cool stuff about those log-free atomics is that they are not only atomic, but they are log-free. There is no mutexes. On the contrary, mutexes use this stuff inside. And how they are implemented, they are special instructions right on the CPU. So doing those operations doesn't even involve the kernel. It's quite cheap if you use it efficiently. And those three operations are basis for some very cool and extremely performant algorithms, as we will see. Not just here. There are a lot of those algorithms based on those log-free atomic operations. They are also called log-free algorithms. And we will follow the task pipeline, looking at the scheduler parts, and we will start from the front queue, just like the tasks. We know that this queue has multiple producers, and it has a single consumer. So it means this queue is multi-producer, single-consumer. This is a common notation for naming queues. We say multi-produce, multi- or single-producer, multi- or single-consumer, and we get four combinations of queue types. This is multi-producer, single-consumer. We also know about this queue that it will experience high contention, because I want my scheduler to be functional. When I have tens of threads and millions of tasks per second, this means extreme contention on the front queue. This in turn means I should avoid mutexes, because mutexes most likely will choke here. What you would do in a normal queue, not thread safe or anything, you would have to remember two positions, head and tail, and maintain those positions. If you try to turn this algorithm into a log-free thread safe implementation, it would be nightmare, because the more variables you have to update in a log-free way, the more complicated the algorithm gets, and queue, like with two variables, it's extremely hard to implement in a log-free way. We should try to avoid this if possible, and the idea is let's make it a stack instead of queue. So we will maintain just one position, the top item, and that's it. We don't need two variables here, and then the algorithm becomes quite simple. Pushing is, well, we try to link new item with the old top, set it, atomic compare exchange will fail, if some other threads does it faster than we are in this push, and we don't retry it. It's pretty simple. The more complicated part, although it looks shorter, is popping the items. The thing is that how pop is implemented, we just replace top item with null, effectively taking all the items at once. We cannot pop them one by one. And also, we have to reverse the list before we return it, because when we are pushing items in FIFO order, pushing them on the stack, they are returned in LIFO order, and we want to maintain the order, so we have to reverse it again. These are two downsides that we can't pop one by one, and we have to reverse the result before returning it. On the other hand, what we get, it is completely lock free, thread safe, and it's weight free. Who will win those drawbacks for being lock free and weight free? We will see in the end in the benchmark section. Next part of the task journey is weight queue. As we know, it stores yielded tasks, so they are waiting for something, like in 99 percent of cases, they are waiting for a deadline. Since we are using tasks for requests, requests usually have a timeout, meaning that they have a deadline. So what we need is to be able to quickly pop all tasks with expired deadline, simply because we have to do everything here quickly, there is a lot of tasks. And we also know that this queue is always accessed by one third at a time. The current scheduler worker who owns the scheduling key, so there is no concurrency on this queue. And that gives us quite a lot of freedom about what data structures we can use. That basically means we can use binary heap. It's ideal for such a job when you have to quickly pop something sorted by a thing like deadline. What happens is that we sort the tasks by deadlines here, basically. So the task with the closest deadline will be on top and we will be able, for constant time, tell immediately if any task has expired by just looking at the top. And in case not all of you know what binary heap is, there is a brief explanation. It's a perfectly balanced binary tree where each node value is less than values of its child nodes. We call this minimal heap. If we reverse the order, it will be called maximal heap. And this heap, it has quite good complexity. Quite good complexity. So for logarithmic time, we can pop any items even from the middle. We can push new items also for logarithmic time, which is very nice, very fast. From the weight queue, the tasks migrate to the ready queue, which as we know is populated by one thread, current scheduler worker, and it is consumed by multiple threads, worker threads. So it means this is a multi-consumer single producer queue. We also know that it will as well experience high contention because task scheduler should be perfectly functional with like 10 worker threads. Why not? And with millions of tasks per second, we will have high contention. We have to deal with it somehow. Although unfortunately, I don't know a nice simple algorithm for doing unbounded and lock free queue of this type. For the reason why you can Google ABA problem, after the talk, it's also quite complicated. We will not have time to dive into this, but just know that it is much more complicated than multi-producer single consumer version. Although I know a couple of other queues, unbounded log-based and bounded lock free. I want my final queue to be exactly unbounded, meaning not limited in size. So I don't want any limits inside the scheduler. You can add them on top, but I don't want them to be inside the scheduler. I don't want it to be limited by anything like queue size. So let's see what we can do with those two queues. The bounded lock free version, bounded lock free queue is simple. It's just a cyclic rate, except that the read and write index will make atomic variables. So in pushing, the only thing changes compared to normal cyclic buffer is that you increment the write index atomic increment and that's it. The popping is just a little bit more complicated. We have to retry it sometimes because there will be multiple consumers. They will compete for the same element sometimes. So atomic compare exchange will eventually fail and we will have to retry, but it's still quite simple. And the unbounded lock queue is just trivial. So it's a mutex and it's a list and we take mutex on every operation. Then it becomes lock based, but it's unbounded. So what we can do with the ready queue, what I had was the craziest idea. The thing is, our enemy is not the mutex itself, it's the contention on the mutex. So we could try to reduce the contention instead of deleting the mutex. We could skip it, but somehow maybe not lock it so often. Let's combine those two approaches together. Let's take the bounded lock free queue and make unbounded lock based queue of those lock free sub-queues. So it will be like a stdq, but the blocks are lock free and the big queue of those blocks is lock based. And how producer works, it will push new items to the latest block in a lock free way. When the block becomes full, it takes mutex, appends a new block, fills it in a lock free way and so on. And the consumers, they do their other thing vice versa, so they consume the first block in a lock free way. When it becomes empty, they take mutex, switch to the next block, consume it in a lock free way and so on. To see the benefit, imagine like sub-queue size, this block size, there's not four like on the slide, but it's 10,000. What happens then is we will take mutex lock not on IV operation, but once per 10,000 operations. Mutex is still here, but it's locked so rarely that its cost is neglectable. You will not see this mutex lock in any flame graphs anymore. The only problem with this is that the consumers will need an explicit state, because if consumer doesn't know which is the first block, in this queue of blocks, it will have to locate it. The queue of blocks, it's protected by a mutex, so if consumers don't have a state, if they don't reference the first block having items, then on every pop, they would have to find it, keeping the mutex, and that would mean mutex lock on every pop, if this is exactly what we wanted to avoid. Consumers need to register themselves, and then they can do the popping. This is not a problem for a task scheduler itself, because it has fixed set of worker threads which you specify at creation. They can register themselves as consumers at start and leave just fine with it, so it's just a problem for generic usage of this type of queue, but for task scheduler, it is just fine. Let's examine the visual example again. Imagine like we have this queue, it's empty, just single block, one producer, two consumers. Producer adds three items in a lock-free way. Everything is lock-free so far, one consumer consumes one item, lock-free. Now producer adds another item, lock-free. It sees that the block became full, so we need to append a new block, we take mutex, switch to the next, append a new block, switch to the next block, release the mutex, and add three more items in a lock-free way. Our consumers will work, they will finish consumption of the first block, consumer A will see that the block is empty, so it takes mutex, switches to next block, releases the mutex, and continues consumption in a lock-free way. So we take mutex only when we switch from block to block. And the other consumer, when we will try to consume something from it, it will see immediately that its current block is empty, because those blocks, they are, as you remember, lock-free bounded queues, there are read and write index, if we see that the read index of this block equals its size, it means it's empty, so we don't even need to full scan it. Anyway, consumer B will then lock mutex, switch to next block, release the mutex, and continue the consumption. And the old blocks, the completely consumed ones, can be discarded. You can free them, you can reuse them, like have a pool of those blocks, and append them to beginning again, if you want to, like, it's not cheap to allocate blocks having 10,000 items in them, so you might want to pull them, to have a pool of them. About the benchmarks, we will see in the end, again, as I said, with everything combined. And our progress so far is that we saw test-calular parts, those queues, and now we can have a glimpse of the routines. Unfortunately, we don't have enough time to dive deep into the implementation, but I can show you some usage examples, show the features they have, and for the implementation, you can look at the source code and ask me questions after the talk. To see why do we need coroutines again, and what features we need from the coroutines, let's inspect the simplified version of this save games example. This time, we have just two steps. Start download of a save game block, and then handle the result. This is in just two steps. What we know is that while the task is waiting for response from the network, it shouldn't block other tasks, so it should be able to yield. It should be able to step away. But we also know that we can't, this task, it can't sleep infinitely. There should be some sort of timeout. Requests can't be executing infinitely, so we need some deadline after which the task would be woken up and will cancel the request. So if the response arrives in time, before the deadline, we have to wake up the task before the deadline. There should be some sort of explicit wake up for the task which is right now sleeping in the wait queue, so it's not executing. How exactly do we wake it up from there? So we need an explicit wake up. We need yield, deadlines, and wake ups, three main features of those coroutines. Let's see an example. It's almost exactly like it looks in real code. Once there will be simplified version of C++, but it's very similar how it looks in reality. We have a global task scheduler in the process and some HTTP client. And imagine like a request from the client arrives, so we wrap it into a task and give it a callback called download. And we post it into the scheduler, so it will go into this front queue. The scheduler will execute our callback in one of the worker threads. This download callback, so what we do here is firstly set what will be the next step. The next step will be handling the result. Then we do the asynchronous HTTP request. Assume that our HTTP client is able to do this. So we start an asynchronous HTTP request and give it a future callback to execute when the request is done, which we'll call wake up on our task. While this will be explicit wake up when the request is done. And then we start waiting. So we post ourselves back into the scheduler with five seconds deadline. Either the task will wake up in five seconds or it will be woken up explicitly when the request is complete. This goes into the scheduler, sleeps in the wait queue for some time and eventually our callback handle result is executed. We have to check what happened. It could be two reasons. It could be that the task is expired. So five seconds passed and we were woken up by the deadline. And we just literally check if it's expired. If it is sold and we cancel the request and we start waiting for the cancellation to be complete to properly free all the resources and to go back into the scheduler. But now we wait for the cancellation. Otherwise, if it's not expired, it means the request is finally complete with some result. It could be success. It could be an HTTP error code or it could be our own consolation done on a previous wake up a few lines above. Either way, we just handle it and delete the task. This is literally, this is almost exactly how it looks in the source code. There is no spurious wake ups at all, no sleeps and the request has clear state machine with every state expressed at the callback. And what is better, these entire routine stuff, all those wake ups, post deadlines, this is all completely lock free. There is no single mutics used to implement this all. So this is to get you further interested into looking at the source code and asking questions afterwards. This is quite complicated stuff, as you can imagine, especially the implementation. How do we verify such stuff? Of course, there are unit tests, like literally hundreds and thousands of lines of unit tests. But with multi-tried algorithms, the thing is, even if you have 100% code coverage, it doesn't tell you anything. It's better than, I think, not having 100% coverage, but it's still, there might be bugs which can stay hidden for literally years. And you will not find them except when this thing explodes in production. There should be a way to at least verify the algorithm, maybe. We can't verify the source code, but we can improve our confidence about the algorithm itself. And the solution is TLA+, TLA+, stands for temporal logic of actions, and it is a combination of mathematics and temporal logic. And it's also a language and runtime of this language. This language allows you to verify literally any algorithms or systems, like you can verify an algorithm of a queue, like I did, or how your microservices interact, or you can verify how you go to a grocery store. If you can algorithmize it, then you can verify it. TLA+. It's suitable for anything like this. So in this TLA+, language, you write a specification and run the verification, and it will run and it will split your system, your algorithm, into a set of all the possible states in which this algorithm can be. And verify your own invariance in every reachable state of your system. So firstly, you define the algorithm, then you define what means validness for your algorithm, the invariance, and TLA+, we'll verify all them. Let's see an example, like I assume you have implemented a queue in any language, and we want to verify the algorithm of this queue. First you have to define what objects exist in your system, what agents you have there. In my queue, I have just pipe for items, so some sort of storage, and a couple of counters and limits. Then you have to define actions. In TLA+, every action is a set of mathematical conditions combined with some mathematical operators, like you have operators and or operator, or list or set operator, or complex operators like all items in the set comply with the condition operator, and many more other operators which can use in your actions. And the first action is always initialization, where you give initial values to your variables. Here I say that storage pipe is an empty list, and my counters of sent and received items are zero. Then I start defining some actual actions doing stuff, like send or push or insert or whatever. And there are ways how to do it. I'm not aware of any standard ways how to do it properly, so I invented my own. Firstly, I split my actions into two groups. And first group of conditions I define when the action is possible. So here I say send is possible when queue is not full, and when I still have items to send, so not everything pushed yet. In the second group, I tell what changes should be done when the first group is true, so when the condition is true. Here I say if the first part is true, then I add a new item to the pipe storage, as items I use numbers, and I increment the number of sent items, of pushed items. The problem is, as you could see, probably there is no really distinction between those two groups. It's imaginary, and the only distinction is this small single code sign. It means next value of the variable. The problem is, since here it passes basically math, in math there is no assignment. There is no action like assign new value to some variable. There is only, the closest thing we have is equal operator in math, but there is no assignment. But you can emulate it saying like next value of your variable equals old value and something done with it. So here I say literally last sent next equals last sent old plus one, which effectively results into assignment and programming languages, but here you have to simulate it like this. In theory plus there is no separation into groups, it's just several mathematical conditions, but I do separate it for making the specification easier to read. I do the same for the receive action. It's possible when I have items to receive, and the changes are to receive. And then you have to define what means validness for your system, so the invariance, which will be validated in every Ritual state. Here as they say that my queue is valid when all the items in the queue are ordered, like I pushed them. The queue never overflows, and then the items are received in the same order as sent. And then with some technical steps, simple ones, I run the validation, and it will give me a result like n states are found, like hundreds of thousands of millions of states that are found, and they are valid, or it will say that I found an invalid state. And here is how you get into the state from the initial one following this sequence of actions. And then you can turn those failure traces into unit tests in your actual code. Now this actually works, and they call it a bug in the scheduler, thanks to this thing. Here by links you can find the specifications for tax scheduler on the whole, and for the multi-consumer queue, which was not trivial enough, so as I would try to validate it as well. Two specifications, they are quite big, but most of the lines are comments explaining the algorithm. So the specification, the code part of them is not too complicated. You can read it like easily. And also there are instructions how to install TLA+, in the source code repository, how to run validation on those models, how to install TLA+, into the command line. It's not trivial, surprisingly. And there are also great course of lectures from the author of TLA+, Leslie Lampert. Lectures are quite fun, if you are not even planning to use TLA+, they are still worth watching, very entertaining. All of this can be found on the source code repository, and now about the benchmarks. How I did them, the benchmarks are comparative. So I'm not just running the benchmarks against themselves in vacuum against some random stuff. I compare the improved versions of those, my algorithms against trivial versions, naive versions using mutexes, to see if stuff actually improved. Like all the same benchmarks run on my algorithms and don't trivial implementations. For example, the smart queues I benchmark against their mutex locked versions, or the task scheduler I benchmark against thread pool, without coroutines, single queues, single mutex and nothing else. I run this on five different configurations of software and hardware with tens of scenarios and all the reports, while the performance are available on GitHub, in human readable markdown format. And you can also run them on your system with just a single line of Python script. It will generate the report for your case, and you can read it and see what's up. And so there are quite a lot of results, I can show just a few of them on the slides. I will use Debian Linux with eight cores running in Google Cloud, and I will show just some average results, no shocking like 100 times faster, although there are extreme cases when algorithms are almost the same, or when it's extremely faster, but I will show just some average results which you can actually get in real production. We start from the front queue again. The benchmark uses five producer threads and one consumer thread, doing busy loop pushes and pops all the time to get the worst case contention. It's just for one and a half times faster, and this is all considering the two drawbacks which you can remember, so we store items as stack in the front queue, we have to reverse them, we can pop them one by one, and still it is one and a half times faster. If we make it 10 producer threads, so we have more threads than CPU cores, worst case for mutics contention, it becomes 2.6 times faster. The ready queue, another benchmark, five consumer threads, one producer threads, one producer thread, again busy loop pushes and pops, it becomes 2.6 times faster, already and you can see that the mutics, the log contention is multiple orders slower than in a trivial implementation. This is thanks to us taking mutics log, not on every operation, but once per multiple thousand operations, and this is the result. Mutics is still here, but it almost doesn't affect the results at all. When we make it 10, consumer threads, it becomes already four and a half times faster. The naive queue degrades quite quick in this case. And now everything combined, the task scheduler on the whole. In this benchmark, tasks are empty, so they are just empty C++ functions. Not doing anything, worst case for contention again. And now we start from single worker thread, which will do both the scheduling and tasks, it becomes right away 2.2 times faster. Then a trivial thread pool without routine support, it becomes already 2.2 times faster. And zero log contention, so log wasn't contended even once between the worker and producer. When we make it five worker threads, it becomes three times faster, so it scales better than naive implementation, but we make it 10 worker threads, it becomes seven and half times faster. And these are not the best results, it can be even better. I'm just not showing extreme cases here, but I saw like 15 times speed up as well. It's just not something you will most likely get in production if you start using this, but those benchmarks are also available. And now about the real usage, not some random benchmarks in the vacuum, how it affects the actual code. Apply to this save games case from the beginning. We reported one of the microservices from updater scheduler to task scheduler, and we immediately without any further optimizations got 10 times speed up. We went from 100s RPS to bigger than 10,000 RPS, and latency dropped five times like right out of the box before we started doing some other optimizations. And the algorithm is extendable. Now, as you remember, there is this big rectangle where only one thread at a time can work. It means this is thread safe space. We can replace the binary heap with weighting task with something more complicated. For instance, we can put LibF inside, or EPUL or IO completion ports from Windows inside, and we get multi-threaded event loop, like multi-threaded LibF, we can store sockets in tasks, and we get circuits with deadlines, with yields, and this is, in fact, what we do have in Ubisoft, it's a fork of task scheduler where we just replaced weight queue with EPUL on Linux and IO completion ports on Windows. And we get more than millions, more than million messages per second with just several threads on sockets. With this thing, it's not too complicated to extend scheduler, it's just maybe next time about this multi-threaded event loop. What are the future plans for it? Firstly, we could try to run it on ARM. Maybe it already runs, but I just haven't tried. Maybe it works, maybe not, I have no idea. That's why it's open source. You can try it, send a pull request if something's not working. Also, it's currently implemented only in C++, and it's not even STL, although some people might consider it good, like me. I don't like STL, but it could use a port to STL as well, or to some other language. And also, there could be optimizations done like the front queue. Maybe there is a way not to store it as a stack, not to reverse the list of items before returning it. I just haven't found a simple way to do it, which would be worth trying, and this is the end. Thanks for your attention. And here are the links to the source code, and to this talk. It will be available, the animated versions with all the slides and my notes online by this link and my other talks. And also, there are bonus sections which some of you might ask as questions, and we will quickly go for them, or you can click on them yourself after the talk if you're interested. Okay, so time for questions, so show of hands, and we'll give you a mic. So, for the front queue, you can use some of Dmitry Vyukov's NPSC queue, very fast, much faster than the tribal stack, which is the thing you're using. The other thing is for the wait queue, well, you answer this with IOCP, KQ, Epo, that would be much more in line with something that uses timer or for networking. And you said that we cannot have single produce, no, multi-multi-consumer single production. Yes, you can, actually, you can use one of the chase left DQ, there's a paper for 2013 with formally verified primitives, including ARM, and those will work for you, use case. I know that there exist implementations of such queues, I just couldn't find the simple enough one. The thing is, in Ubisoft, internally, above all, sometimes, in Harm to performance, can value code simplicity, so it's not an option to use something extremely complicated, like hazard pointers or stuff like this, or, for example, I saw implementations of such queues, which are not wait-free, so they can be lock-free, let's say, but not wait-free, that also wasn't an option, because that's basically a spin-lock. There's 100 levels.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.0, "text": " Hello, my name is Vlad, I am a CEO and C++ developer with roughly eight years of experience.", "tokens": [2425, 11, 452, 1315, 307, 21958, 11, 286, 669, 257, 9282, 293, 383, 25472, 10754, 365, 9810, 3180, 924, 295, 1752, 13], "temperature": 0.0, "avg_logprob": -0.2501144257802812, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.47135430574417114}, {"id": 1, "seek": 0, "start": 14.0, "end": 18.44, "text": " Right now I work at a game dev company called Ubisoft, which some of you probably heard", "tokens": [1779, 586, 286, 589, 412, 257, 1216, 1905, 2237, 1219, 30230, 47929, 11, 597, 512, 295, 291, 1391, 2198], "temperature": 0.0, "avg_logprob": -0.2501144257802812, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.47135430574417114}, {"id": 2, "seek": 0, "start": 18.44, "end": 25.2, "text": " about, with mostly low level networking and some bits of system programming.", "tokens": [466, 11, 365, 5240, 2295, 1496, 17985, 293, 512, 9239, 295, 1185, 9410, 13], "temperature": 0.0, "avg_logprob": -0.2501144257802812, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.47135430574417114}, {"id": 3, "seek": 2520, "start": 25.2, "end": 31.64, "text": " And in Ubisoft, while doing a complete rewrite of our networking stack in one of game engines,", "tokens": [400, 294, 30230, 47929, 11, 1339, 884, 257, 3566, 28132, 295, 527, 17985, 8630, 294, 472, 295, 1216, 12982, 11], "temperature": 0.0, "avg_logprob": -0.2277220499884222, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0028209818992763758}, {"id": 4, "seek": 2520, "start": 31.64, "end": 37.92, "text": " I managed to design, I hope, a cool algorithm for doing so-called task scheduling.", "tokens": [286, 6453, 281, 1715, 11, 286, 1454, 11, 257, 1627, 9284, 337, 884, 370, 12, 11880, 5633, 29055, 13], "temperature": 0.0, "avg_logprob": -0.2277220499884222, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0028209818992763758}, {"id": 5, "seek": 2520, "start": 37.92, "end": 44.84, "text": " And today I share this algorithm in the form of this talk and an open source C++ implementation", "tokens": [400, 965, 286, 2073, 341, 9284, 294, 264, 1254, 295, 341, 751, 293, 364, 1269, 4009, 383, 25472, 11420], "temperature": 0.0, "avg_logprob": -0.2277220499884222, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0028209818992763758}, {"id": 6, "seek": 2520, "start": 44.84, "end": 45.84, "text": " of it.", "tokens": [295, 309, 13], "temperature": 0.0, "avg_logprob": -0.2277220499884222, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0028209818992763758}, {"id": 7, "seek": 2520, "start": 45.84, "end": 53.120000000000005, "text": " Although, if you don't like C++, it doesn't have to be, today we focus just on the algorithms", "tokens": [5780, 11, 498, 291, 500, 380, 411, 383, 25472, 11, 309, 1177, 380, 362, 281, 312, 11, 965, 321, 1879, 445, 322, 264, 14642], "temperature": 0.0, "avg_logprob": -0.2277220499884222, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0028209818992763758}, {"id": 8, "seek": 5312, "start": 53.12, "end": 57.919999999999995, "text": " and they can be implemented in some other language too, like in Rust, I'm sure it can", "tokens": [293, 436, 393, 312, 12270, 294, 512, 661, 2856, 886, 11, 411, 294, 34952, 11, 286, 478, 988, 309, 393], "temperature": 0.0, "avg_logprob": -0.2245817621913525, "compression_ratio": 1.5670498084291187, "no_speech_prob": 0.002019248204305768}, {"id": 9, "seek": 5312, "start": 57.919999999999995, "end": 61.64, "text": " be done in Java, in C-sharp maybe.", "tokens": [312, 1096, 294, 10745, 11, 294, 383, 12, 2716, 6529, 1310, 13], "temperature": 0.0, "avg_logprob": -0.2245817621913525, "compression_ratio": 1.5670498084291187, "no_speech_prob": 0.002019248204305768}, {"id": 10, "seek": 5312, "start": 61.64, "end": 69.44, "text": " So there will be a lot of content, so we will be going relatively quick and I ask you to", "tokens": [407, 456, 486, 312, 257, 688, 295, 2701, 11, 370, 321, 486, 312, 516, 7226, 1702, 293, 286, 1029, 291, 281], "temperature": 0.0, "avg_logprob": -0.2245817621913525, "compression_ratio": 1.5670498084291187, "no_speech_prob": 0.002019248204305768}, {"id": 11, "seek": 5312, "start": 69.44, "end": 70.44, "text": " concentrate.", "tokens": [18089, 13], "temperature": 0.0, "avg_logprob": -0.2245817621913525, "compression_ratio": 1.5670498084291187, "no_speech_prob": 0.002019248204305768}, {"id": 12, "seek": 5312, "start": 70.44, "end": 76.0, "text": " Talk will follow the plan firstly, what is task scheduling exactly, because many things", "tokens": [8780, 486, 1524, 264, 1393, 27376, 11, 437, 307, 5633, 29055, 2293, 11, 570, 867, 721], "temperature": 0.0, "avg_logprob": -0.2245817621913525, "compression_ratio": 1.5670498084291187, "no_speech_prob": 0.002019248204305768}, {"id": 13, "seek": 5312, "start": 76.0, "end": 81.84, "text": " can be understood as it, then I explain how it's normally done, what are typical problems", "tokens": [393, 312, 7320, 382, 309, 11, 550, 286, 2903, 577, 309, 311, 5646, 1096, 11, 437, 366, 7476, 2740], "temperature": 0.0, "avg_logprob": -0.2245817621913525, "compression_ratio": 1.5670498084291187, "no_speech_prob": 0.002019248204305768}, {"id": 14, "seek": 5312, "start": 81.84, "end": 82.84, "text": " with it.", "tokens": [365, 309, 13], "temperature": 0.0, "avg_logprob": -0.2245817621913525, "compression_ratio": 1.5670498084291187, "no_speech_prob": 0.002019248204305768}, {"id": 15, "seek": 8284, "start": 82.84, "end": 88.48, "text": " I'm actually, at least, known to me and how worked an old task scheduler in my game engine", "tokens": [286, 478, 767, 11, 412, 1935, 11, 2570, 281, 385, 293, 577, 2732, 364, 1331, 5633, 12000, 260, 294, 452, 1216, 2848], "temperature": 0.0, "avg_logprob": -0.27987996737162274, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.0032489963341504335}, {"id": 16, "seek": 8284, "start": 88.48, "end": 90.2, "text": " and how works the new one.", "tokens": [293, 577, 1985, 264, 777, 472, 13], "temperature": 0.0, "avg_logprob": -0.27987996737162274, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.0032489963341504335}, {"id": 17, "seek": 8284, "start": 90.2, "end": 95.76, "text": " And then I will briefly show you the benchmarks, how it's verified and what are the future", "tokens": [400, 550, 286, 486, 10515, 855, 291, 264, 43751, 11, 577, 309, 311, 31197, 293, 437, 366, 264, 2027], "temperature": 0.0, "avg_logprob": -0.27987996737162274, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.0032489963341504335}, {"id": 18, "seek": 8284, "start": 95.76, "end": 97.44, "text": " plans for it.", "tokens": [5482, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.27987996737162274, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.0032489963341504335}, {"id": 19, "seek": 8284, "start": 97.44, "end": 100.16, "text": " So what is task scheduling exactly?", "tokens": [407, 437, 307, 5633, 29055, 2293, 30], "temperature": 0.0, "avg_logprob": -0.27987996737162274, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.0032489963341504335}, {"id": 20, "seek": 8284, "start": 100.16, "end": 107.4, "text": " Today, in this talk, I mean, as task scheduling, any kind of execution of code, such as code", "tokens": [2692, 11, 294, 341, 751, 11, 286, 914, 11, 382, 5633, 29055, 11, 604, 733, 295, 15058, 295, 3089, 11, 1270, 382, 3089], "temperature": 0.0, "avg_logprob": -0.27987996737162274, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.0032489963341504335}, {"id": 21, "seek": 10740, "start": 107.4, "end": 114.28, "text": " exec functions or something similar, and we just call it task, a generic term.", "tokens": [4454, 6828, 420, 746, 2531, 11, 293, 321, 445, 818, 309, 5633, 11, 257, 19577, 1433, 13], "temperature": 0.0, "avg_logprob": -0.25313271646914276, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.0013707199832424521}, {"id": 22, "seek": 10740, "start": 114.28, "end": 120.56, "text": " And so to give you a few examples, tasks can be callbacks in a thread pool, or tasks can", "tokens": [400, 370, 281, 976, 291, 257, 1326, 5110, 11, 9608, 393, 312, 818, 17758, 294, 257, 7207, 7005, 11, 420, 9608, 393], "temperature": 0.0, "avg_logprob": -0.25313271646914276, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.0013707199832424521}, {"id": 23, "seek": 10740, "start": 120.56, "end": 128.36, "text": " be watchers in an event loop like in LibF in C, we can have watchers as timers or wrapping", "tokens": [312, 1159, 433, 294, 364, 2280, 6367, 411, 294, 15834, 37, 294, 383, 11, 321, 393, 362, 1159, 433, 382, 524, 433, 420, 21993], "temperature": 0.0, "avg_logprob": -0.25313271646914276, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.0013707199832424521}, {"id": 24, "seek": 10740, "start": 128.36, "end": 134.6, "text": " sockets and they also have callbacks, or we can also call tasks routines in some routine", "tokens": [370, 11984, 293, 436, 611, 362, 818, 17758, 11, 420, 321, 393, 611, 818, 9608, 33827, 294, 512, 9927], "temperature": 0.0, "avg_logprob": -0.25313271646914276, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.0013707199832424521}, {"id": 25, "seek": 13460, "start": 134.6, "end": 141.79999999999998, "text": " engine like C++ routines or fibers in Toronto database.", "tokens": [2848, 411, 383, 25472, 33827, 420, 25252, 294, 14140, 8149, 13], "temperature": 0.0, "avg_logprob": -0.18510467127749794, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0004510999715421349}, {"id": 26, "seek": 13460, "start": 141.79999999999998, "end": 149.51999999999998, "text": " So here is a very, very simple trivial scheduler implemented in C++ like pseudo code for simplicity,", "tokens": [407, 510, 307, 257, 588, 11, 588, 2199, 26703, 12000, 260, 12270, 294, 383, 25472, 411, 35899, 3089, 337, 25632, 11], "temperature": 0.0, "avg_logprob": -0.18510467127749794, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0004510999715421349}, {"id": 27, "seek": 13460, "start": 149.51999999999998, "end": 152.0, "text": " which demonstrates this example.", "tokens": [597, 31034, 341, 1365, 13], "temperature": 0.0, "avg_logprob": -0.18510467127749794, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0004510999715421349}, {"id": 28, "seek": 13460, "start": 152.0, "end": 154.32, "text": " So it's just a single thread.", "tokens": [407, 309, 311, 445, 257, 2167, 7207, 13], "temperature": 0.0, "avg_logprob": -0.18510467127749794, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0004510999715421349}, {"id": 29, "seek": 13460, "start": 154.32, "end": 160.72, "text": " It has a mutex locked queue for callbacks, and what it does is just executes those callbacks", "tokens": [467, 575, 257, 24523, 87, 9376, 18639, 337, 818, 17758, 11, 293, 437, 309, 775, 307, 445, 4454, 1819, 729, 818, 17758], "temperature": 0.0, "avg_logprob": -0.18510467127749794, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0004510999715421349}, {"id": 30, "seek": 13460, "start": 160.72, "end": 161.72, "text": " one by one.", "tokens": [472, 538, 472, 13], "temperature": 0.0, "avg_logprob": -0.18510467127749794, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0004510999715421349}, {"id": 31, "seek": 13460, "start": 161.72, "end": 164.07999999999998, "text": " This is a very simple scheduler.", "tokens": [639, 307, 257, 588, 2199, 12000, 260, 13], "temperature": 0.0, "avg_logprob": -0.18510467127749794, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0004510999715421349}, {"id": 32, "seek": 16408, "start": 164.08, "end": 170.52, "text": " Now let's see if such a basic scheduler can solve a real task, which I had at Ubisoft.", "tokens": [823, 718, 311, 536, 498, 1270, 257, 3875, 12000, 260, 393, 5039, 257, 957, 5633, 11, 597, 286, 632, 412, 30230, 47929, 13], "temperature": 0.0, "avg_logprob": -0.18054178709624916, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.00132044090423733}, {"id": 33, "seek": 16408, "start": 170.52, "end": 178.04000000000002, "text": " Here, tasks execute requests coming to a server, and they handle save games, save game blobs.", "tokens": [1692, 11, 9608, 14483, 12475, 1348, 281, 257, 7154, 11, 293, 436, 4813, 3155, 2813, 11, 3155, 1216, 1749, 929, 13], "temperature": 0.0, "avg_logprob": -0.18054178709624916, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.00132044090423733}, {"id": 34, "seek": 16408, "start": 178.04000000000002, "end": 182.8, "text": " And there might be tens of thousands of those requests per second, and they are also CPU", "tokens": [400, 456, 1062, 312, 10688, 295, 5383, 295, 729, 12475, 680, 1150, 11, 293, 436, 366, 611, 13199], "temperature": 0.0, "avg_logprob": -0.18054178709624916, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.00132044090423733}, {"id": 35, "seek": 16408, "start": 182.8, "end": 183.8, "text": " intensive.", "tokens": [18957, 13], "temperature": 0.0, "avg_logprob": -0.18054178709624916, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.00132044090423733}, {"id": 36, "seek": 16408, "start": 183.8, "end": 189.96, "text": " So every task might take milliseconds of pure CPU time, and also they consist of multiple", "tokens": [407, 633, 5633, 1062, 747, 34184, 295, 6075, 13199, 565, 11, 293, 611, 436, 4603, 295, 3866], "temperature": 0.0, "avg_logprob": -0.18054178709624916, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.00132044090423733}, {"id": 37, "seek": 18996, "start": 189.96, "end": 196.96, "text": " steps like, I have to, in each task, lock user profile in some database, then I have", "tokens": [4439, 411, 11, 286, 362, 281, 11, 294, 1184, 5633, 11, 4017, 4195, 7964, 294, 512, 8149, 11, 550, 286, 362], "temperature": 0.0, "avg_logprob": -0.17135444987903942, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.0005546578904613853}, {"id": 38, "seek": 18996, "start": 196.96, "end": 201.68, "text": " to download the save game blob from another database, then I have to do some pre-processing", "tokens": [281, 5484, 264, 3155, 1216, 1749, 65, 490, 1071, 8149, 11, 550, 286, 362, 281, 360, 512, 659, 12, 41075, 278], "temperature": 0.0, "avg_logprob": -0.17135444987903942, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.0005546578904613853}, {"id": 39, "seek": 18996, "start": 201.68, "end": 207.72, "text": " of this blob, some stuff with some manipulations, then I have to upload it back and unlock the", "tokens": [295, 341, 1749, 65, 11, 512, 1507, 365, 512, 9258, 4136, 11, 550, 286, 362, 281, 6580, 309, 646, 293, 11634, 264], "temperature": 0.0, "avg_logprob": -0.17135444987903942, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.0005546578904613853}, {"id": 40, "seek": 18996, "start": 207.72, "end": 209.72, "text": " user profile.", "tokens": [4195, 7964, 13], "temperature": 0.0, "avg_logprob": -0.17135444987903942, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.0005546578904613853}, {"id": 41, "seek": 18996, "start": 209.72, "end": 213.8, "text": " As you can guess, most of the time the task is not doing anything at all.", "tokens": [1018, 291, 393, 2041, 11, 881, 295, 264, 565, 264, 5633, 307, 406, 884, 1340, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.17135444987903942, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.0005546578904613853}, {"id": 42, "seek": 18996, "start": 213.8, "end": 218.88, "text": " It just sleeps waiting for network input from the databases.", "tokens": [467, 445, 37991, 3806, 337, 3209, 4846, 490, 264, 22380, 13], "temperature": 0.0, "avg_logprob": -0.17135444987903942, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.0005546578904613853}, {"id": 43, "seek": 21888, "start": 218.88, "end": 225.56, "text": " So literally more than 90% of times there is nothing happening in this task.", "tokens": [407, 3736, 544, 813, 4289, 4, 295, 1413, 456, 307, 1825, 2737, 294, 341, 5633, 13], "temperature": 0.0, "avg_logprob": -0.19615073251252127, "compression_ratio": 1.5863453815261044, "no_speech_prob": 0.00251392531208694}, {"id": 44, "seek": 21888, "start": 225.56, "end": 230.44, "text": " The trivial scheduler, which we just saw with single triad, it will not work here, it simply", "tokens": [440, 26703, 12000, 260, 11, 597, 321, 445, 1866, 365, 2167, 1376, 345, 11, 309, 486, 406, 589, 510, 11, 309, 2935], "temperature": 0.0, "avg_logprob": -0.19615073251252127, "compression_ratio": 1.5863453815261044, "no_speech_prob": 0.00251392531208694}, {"id": 45, "seek": 21888, "start": 230.44, "end": 231.64, "text": " will not scale.", "tokens": [486, 406, 4373, 13], "temperature": 0.0, "avg_logprob": -0.19615073251252127, "compression_ratio": 1.5863453815261044, "no_speech_prob": 0.00251392531208694}, {"id": 46, "seek": 21888, "start": 231.64, "end": 239.28, "text": " Firstly, single triad is not enough to handle so many requests, so being so CPU intensive,", "tokens": [20042, 11, 2167, 1376, 345, 307, 406, 1547, 281, 4813, 370, 867, 12475, 11, 370, 885, 370, 13199, 18957, 11], "temperature": 0.0, "avg_logprob": -0.19615073251252127, "compression_ratio": 1.5863453815261044, "no_speech_prob": 0.00251392531208694}, {"id": 47, "seek": 21888, "start": 239.28, "end": 241.28, "text": " it will just choke on CPU.", "tokens": [309, 486, 445, 34427, 322, 13199, 13], "temperature": 0.0, "avg_logprob": -0.19615073251252127, "compression_ratio": 1.5863453815261044, "no_speech_prob": 0.00251392531208694}, {"id": 48, "seek": 21888, "start": 241.28, "end": 247.12, "text": " Secondly, we can postpone blocked tasks and do other tasks while the first ones are waiting", "tokens": [19483, 11, 321, 393, 28973, 546, 15470, 9608, 293, 360, 661, 9608, 1339, 264, 700, 2306, 366, 3806], "temperature": 0.0, "avg_logprob": -0.19615073251252127, "compression_ratio": 1.5863453815261044, "no_speech_prob": 0.00251392531208694}, {"id": 49, "seek": 24712, "start": 247.12, "end": 249.84, "text": " for some events like network input.", "tokens": [337, 512, 3931, 411, 3209, 4846, 13], "temperature": 0.0, "avg_logprob": -0.17957378955597572, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.001310292980633676}, {"id": 50, "seek": 24712, "start": 249.84, "end": 256.28000000000003, "text": " So this means we need routines so that tasks could yield, so they could give up their time", "tokens": [407, 341, 1355, 321, 643, 33827, 370, 300, 9608, 727, 11257, 11, 370, 436, 727, 976, 493, 641, 565], "temperature": 0.0, "avg_logprob": -0.17957378955597572, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.001310292980633676}, {"id": 51, "seek": 24712, "start": 256.28000000000003, "end": 260.36, "text": " to some other tasks in the same thread.", "tokens": [281, 512, 661, 9608, 294, 264, 912, 7207, 13], "temperature": 0.0, "avg_logprob": -0.17957378955597572, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.001310292980633676}, {"id": 52, "seek": 24712, "start": 260.36, "end": 266.16, "text": " The game engine I'm working with had a good enough scheduler, which could do the job for", "tokens": [440, 1216, 2848, 286, 478, 1364, 365, 632, 257, 665, 1547, 12000, 260, 11, 597, 727, 360, 264, 1691, 337], "temperature": 0.0, "avg_logprob": -0.17957378955597572, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.001310292980633676}, {"id": 53, "seek": 24712, "start": 266.16, "end": 269.24, "text": " some years good enough.", "tokens": [512, 924, 665, 1547, 13], "temperature": 0.0, "avg_logprob": -0.17957378955597572, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.001310292980633676}, {"id": 54, "seek": 24712, "start": 269.24, "end": 276.24, "text": " This was just a thread pool where each thread had a list of own tasks, and when new tasks", "tokens": [639, 390, 445, 257, 7207, 7005, 689, 1184, 7207, 632, 257, 1329, 295, 1065, 9608, 11, 293, 562, 777, 9608], "temperature": 0.0, "avg_logprob": -0.17957378955597572, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.001310292980633676}, {"id": 55, "seek": 27624, "start": 276.24, "end": 281.84000000000003, "text": " were appearing, they were distributed to those threads in around Robin Manor one by one,", "tokens": [645, 19870, 11, 436, 645, 12631, 281, 729, 19314, 294, 926, 16533, 2458, 284, 472, 538, 472, 11], "temperature": 0.0, "avg_logprob": -0.2286818761091966, "compression_ratio": 1.6770428015564203, "no_speech_prob": 0.0010055617894977331}, {"id": 56, "seek": 27624, "start": 281.84000000000003, "end": 285.28000000000003, "text": " and they were pinned to those threads forever.", "tokens": [293, 436, 645, 33802, 281, 729, 19314, 5680, 13], "temperature": 0.0, "avg_logprob": -0.2286818761091966, "compression_ratio": 1.6770428015564203, "no_speech_prob": 0.0010055617894977331}, {"id": 57, "seek": 27624, "start": 285.28000000000003, "end": 287.76, "text": " They could not migrate between threads.", "tokens": [814, 727, 406, 31821, 1296, 19314, 13], "temperature": 0.0, "avg_logprob": -0.2286818761091966, "compression_ratio": 1.6770428015564203, "no_speech_prob": 0.0010055617894977331}, {"id": 58, "seek": 27624, "start": 287.76, "end": 293.64, "text": " And then what each worker thread does is updates all its tasks with some fixed hard-coded period", "tokens": [400, 550, 437, 1184, 11346, 7207, 775, 307, 9205, 439, 1080, 9608, 365, 512, 6806, 1152, 12, 66, 12340, 2896], "temperature": 0.0, "avg_logprob": -0.2286818761091966, "compression_ratio": 1.6770428015564203, "no_speech_prob": 0.0010055617894977331}, {"id": 59, "seek": 27624, "start": 293.64, "end": 297.52, "text": " like once per 100 milliseconds or once per second.", "tokens": [411, 1564, 680, 2319, 34184, 420, 1564, 680, 1150, 13], "temperature": 0.0, "avg_logprob": -0.2286818761091966, "compression_ratio": 1.6770428015564203, "no_speech_prob": 0.0010055617894977331}, {"id": 60, "seek": 27624, "start": 297.52, "end": 303.76, "text": " Each task, after being updated, it can return false eventually, and it consider it done,", "tokens": [6947, 5633, 11, 934, 885, 10588, 11, 309, 393, 2736, 7908, 4728, 11, 293, 309, 1949, 309, 1096, 11], "temperature": 0.0, "avg_logprob": -0.2286818761091966, "compression_ratio": 1.6770428015564203, "no_speech_prob": 0.0010055617894977331}, {"id": 61, "seek": 27624, "start": 303.76, "end": 304.92, "text": " and it is deleted.", "tokens": [293, 309, 307, 22981, 13], "temperature": 0.0, "avg_logprob": -0.2286818761091966, "compression_ratio": 1.6770428015564203, "no_speech_prob": 0.0010055617894977331}, {"id": 62, "seek": 30492, "start": 304.92, "end": 311.44, "text": " So this is some polling, basically, and we will call this scheduler updater because", "tokens": [407, 341, 307, 512, 29518, 11, 1936, 11, 293, 321, 486, 818, 341, 12000, 260, 3460, 771, 570], "temperature": 0.0, "avg_logprob": -0.2247613404926501, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0014447291614487767}, {"id": 63, "seek": 30492, "start": 311.44, "end": 317.96000000000004, "text": " there isn't much scheduling, really, it just updates those tasks without looking at their", "tokens": [456, 1943, 380, 709, 29055, 11, 534, 11, 309, 445, 9205, 729, 9608, 1553, 1237, 412, 641], "temperature": 0.0, "avg_logprob": -0.2247613404926501, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0014447291614487767}, {"id": 64, "seek": 30492, "start": 317.96000000000004, "end": 321.72, "text": " state or anything, so we call it updater.", "tokens": [1785, 420, 1340, 11, 370, 321, 818, 309, 3460, 771, 13], "temperature": 0.0, "avg_logprob": -0.2247613404926501, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0014447291614487767}, {"id": 65, "seek": 30492, "start": 321.72, "end": 327.88, "text": " This updater thing had some typical problems, like schedulers of this type sometimes do.", "tokens": [639, 3460, 771, 551, 632, 512, 7476, 2740, 11, 411, 12000, 433, 295, 341, 2010, 2171, 360, 13], "temperature": 0.0, "avg_logprob": -0.2247613404926501, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0014447291614487767}, {"id": 66, "seek": 30492, "start": 327.88, "end": 333.96000000000004, "text": " Firstly, it was unfair, meaning that tasks were pinned to threads, they could not migrate.", "tokens": [20042, 11, 309, 390, 17019, 11, 3620, 300, 9608, 645, 33802, 281, 19314, 11, 436, 727, 406, 31821, 13], "temperature": 0.0, "avg_logprob": -0.2247613404926501, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0014447291614487767}, {"id": 67, "seek": 33396, "start": 333.96, "end": 340.2, "text": " This leads to a problem that your CPU usage will be unbalanced because some worker threads", "tokens": [639, 6689, 281, 257, 1154, 300, 428, 13199, 14924, 486, 312, 517, 40251, 570, 512, 11346, 19314], "temperature": 0.0, "avg_logprob": -0.1685748781476702, "compression_ratio": 1.723809523809524, "no_speech_prob": 0.002927035093307495}, {"id": 68, "seek": 33396, "start": 340.2, "end": 346.47999999999996, "text": " will get heavy tasks, and a lot of them will stay in the queues, and other threads will", "tokens": [486, 483, 4676, 9608, 11, 293, 257, 688, 295, 552, 486, 1754, 294, 264, 631, 1247, 11, 293, 661, 19314, 486], "temperature": 0.0, "avg_logprob": -0.1685748781476702, "compression_ratio": 1.723809523809524, "no_speech_prob": 0.002927035093307495}, {"id": 69, "seek": 33396, "start": 346.47999999999996, "end": 352.0, "text": " get light tasks and will be in idling most of the time.", "tokens": [483, 1442, 9608, 293, 486, 312, 294, 4496, 1688, 881, 295, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.1685748781476702, "compression_ratio": 1.723809523809524, "no_speech_prob": 0.002927035093307495}, {"id": 70, "seek": 33396, "start": 352.0, "end": 357.67999999999995, "text": " This will happen even if you do perfect round robin, and all your tasks are the same because", "tokens": [639, 486, 1051, 754, 498, 291, 360, 2176, 3098, 3870, 259, 11, 293, 439, 428, 9608, 366, 264, 912, 570], "temperature": 0.0, "avg_logprob": -0.1685748781476702, "compression_ratio": 1.723809523809524, "no_speech_prob": 0.002927035093307495}, {"id": 71, "seek": 33396, "start": 357.67999999999995, "end": 360.24, "text": " actually tasks are never the same.", "tokens": [767, 9608, 366, 1128, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.1685748781476702, "compression_ratio": 1.723809523809524, "no_speech_prob": 0.002927035093307495}, {"id": 72, "seek": 36024, "start": 360.24, "end": 366.04, "text": " Like in my case, all the tasks do the same several steps, but save game blobs, they can", "tokens": [1743, 294, 452, 1389, 11, 439, 264, 9608, 360, 264, 912, 2940, 4439, 11, 457, 3155, 1216, 1749, 929, 11, 436, 393], "temperature": 0.0, "avg_logprob": -0.1569289235235418, "compression_ratio": 1.7016806722689075, "no_speech_prob": 0.0013387600192800164}, {"id": 73, "seek": 36024, "start": 366.04, "end": 371.40000000000003, "text": " vary in size from kilobytes to megabytes, their processing, their downloading, obviously", "tokens": [10559, 294, 2744, 490, 5128, 996, 43673, 281, 10816, 24538, 11, 641, 9007, 11, 641, 32529, 11, 2745], "temperature": 0.0, "avg_logprob": -0.1569289235235418, "compression_ratio": 1.7016806722689075, "no_speech_prob": 0.0013387600192800164}, {"id": 74, "seek": 36024, "start": 371.40000000000003, "end": 376.64, "text": " takes not the same time, so some threads will be unfairly loaded, and they will perform", "tokens": [2516, 406, 264, 912, 565, 11, 370, 512, 19314, 486, 312, 17019, 356, 13210, 11, 293, 436, 486, 2042], "temperature": 0.0, "avg_logprob": -0.1569289235235418, "compression_ratio": 1.7016806722689075, "no_speech_prob": 0.0013387600192800164}, {"id": 75, "seek": 36024, "start": 376.64, "end": 382.16, "text": " worse, at least in terms of latency, because they will have bigger queues, tasks will wait", "tokens": [5324, 11, 412, 1935, 294, 2115, 295, 27043, 11, 570, 436, 486, 362, 3801, 631, 1247, 11, 9608, 486, 1699], "temperature": 0.0, "avg_logprob": -0.1569289235235418, "compression_ratio": 1.7016806722689075, "no_speech_prob": 0.0013387600192800164}, {"id": 76, "seek": 36024, "start": 382.16, "end": 386.48, "text": " longer in them, and that is not the only problem.", "tokens": [2854, 294, 552, 11, 293, 300, 307, 406, 264, 787, 1154, 13], "temperature": 0.0, "avg_logprob": -0.1569289235235418, "compression_ratio": 1.7016806722689075, "no_speech_prob": 0.0013387600192800164}, {"id": 77, "seek": 38648, "start": 386.48, "end": 391.88, "text": " The other problem is polling, which in this case means the tasks, each task is updated", "tokens": [440, 661, 1154, 307, 29518, 11, 597, 294, 341, 1389, 1355, 264, 9608, 11, 1184, 5633, 307, 10588], "temperature": 0.0, "avg_logprob": -0.13157704055950206, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.0007872033165767789}, {"id": 78, "seek": 38648, "start": 391.88, "end": 398.20000000000005, "text": " unconditionally with some fixed period regardless of task state, so every task is updated even", "tokens": [34959, 15899, 365, 512, 6806, 2896, 10060, 295, 5633, 1785, 11, 370, 633, 5633, 307, 10588, 754], "temperature": 0.0, "avg_logprob": -0.13157704055950206, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.0007872033165767789}, {"id": 79, "seek": 38648, "start": 398.20000000000005, "end": 404.12, "text": " if it doesn't have work to do yet, so it's still waiting for network input.", "tokens": [498, 309, 1177, 380, 362, 589, 281, 360, 1939, 11, 370, 309, 311, 920, 3806, 337, 3209, 4846, 13], "temperature": 0.0, "avg_logprob": -0.13157704055950206, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.0007872033165767789}, {"id": 80, "seek": 38648, "start": 404.12, "end": 409.0, "text": " What it means is that if you select too big polling interval, then you will have too high", "tokens": [708, 309, 1355, 307, 300, 498, 291, 3048, 886, 955, 29518, 15035, 11, 550, 291, 486, 362, 886, 1090], "temperature": 0.0, "avg_logprob": -0.13157704055950206, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.0007872033165767789}, {"id": 81, "seek": 38648, "start": 409.0, "end": 411.8, "text": " latency, more than you could have.", "tokens": [27043, 11, 544, 813, 291, 727, 362, 13], "temperature": 0.0, "avg_logprob": -0.13157704055950206, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.0007872033165767789}, {"id": 82, "seek": 41180, "start": 411.8, "end": 417.36, "text": " For instance, imagine like we have a task with just three steps, each taking five milliseconds,", "tokens": [1171, 5197, 11, 3811, 411, 321, 362, 257, 5633, 365, 445, 1045, 4439, 11, 1184, 1940, 1732, 34184, 11], "temperature": 0.0, "avg_logprob": -0.1261885995450227, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.0008718040189705789}, {"id": 83, "seek": 41180, "start": 417.36, "end": 423.84000000000003, "text": " and in between it waits for some network input, and we will update it once per hundred milliseconds.", "tokens": [293, 294, 1296, 309, 40597, 337, 512, 3209, 4846, 11, 293, 321, 486, 5623, 309, 1564, 680, 3262, 34184, 13], "temperature": 0.0, "avg_logprob": -0.1261885995450227, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.0008718040189705789}, {"id": 84, "seek": 41180, "start": 423.84000000000003, "end": 429.44, "text": " Then your task will always at least take 215 milliseconds.", "tokens": [1396, 428, 5633, 486, 1009, 412, 1935, 747, 5080, 20, 34184, 13], "temperature": 0.0, "avg_logprob": -0.1261885995450227, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.0008718040189705789}, {"id": 85, "seek": 41180, "start": 429.44, "end": 433.96000000000004, "text": " The thing is, you don't always need so much time.", "tokens": [440, 551, 307, 11, 291, 500, 380, 1009, 643, 370, 709, 565, 13], "temperature": 0.0, "avg_logprob": -0.1261885995450227, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.0008718040189705789}, {"id": 86, "seek": 41180, "start": 433.96000000000004, "end": 438.12, "text": " Most of the time, like almost always, the network response will arrive earlier than", "tokens": [4534, 295, 264, 565, 11, 411, 1920, 1009, 11, 264, 3209, 4134, 486, 8881, 3071, 813], "temperature": 0.0, "avg_logprob": -0.1261885995450227, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.0008718040189705789}, {"id": 87, "seek": 43812, "start": 438.12, "end": 443.72, "text": " 100 milliseconds expire, and you have events to process, but you are not doing it because", "tokens": [2319, 34184, 45447, 11, 293, 291, 362, 3931, 281, 1399, 11, 457, 291, 366, 406, 884, 309, 570], "temperature": 0.0, "avg_logprob": -0.19415963298142558, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0024424190632998943}, {"id": 88, "seek": 43812, "start": 443.72, "end": 448.76, "text": " it's not yet time to update the task, so we have higher latency than we could have.", "tokens": [309, 311, 406, 1939, 565, 281, 5623, 264, 5633, 11, 370, 321, 362, 2946, 27043, 813, 321, 727, 362, 13], "temperature": 0.0, "avg_logprob": -0.19415963298142558, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0024424190632998943}, {"id": 89, "seek": 43812, "start": 448.76, "end": 457.64, "text": " If you try to fight it, try to set lower polling interval, then you will burn CPU without need,", "tokens": [759, 291, 853, 281, 2092, 309, 11, 853, 281, 992, 3126, 29518, 15035, 11, 550, 291, 486, 5064, 13199, 1553, 643, 11], "temperature": 0.0, "avg_logprob": -0.19415963298142558, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0024424190632998943}, {"id": 90, "seek": 43812, "start": 457.64, "end": 461.16, "text": " because you will have spurious wakeups, so unnecessary wakeups.", "tokens": [570, 291, 486, 362, 637, 24274, 6634, 7528, 11, 370, 19350, 6634, 7528, 13], "temperature": 0.0, "avg_logprob": -0.19415963298142558, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0024424190632998943}, {"id": 91, "seek": 43812, "start": 461.16, "end": 466.76, "text": " You will sometimes wake up tasks before they have stuff to do.", "tokens": [509, 486, 2171, 6634, 493, 9608, 949, 436, 362, 1507, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.19415963298142558, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0024424190632998943}, {"id": 92, "seek": 46676, "start": 466.76, "end": 472.2, "text": " Then it sounds too bad, like how expensive can it be, really, and imagine like spurious", "tokens": [1396, 309, 3263, 886, 1578, 11, 411, 577, 5124, 393, 309, 312, 11, 534, 11, 293, 3811, 411, 637, 24274], "temperature": 0.0, "avg_logprob": -0.20900601298869156, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0008533290238119662}, {"id": 93, "seek": 46676, "start": 472.2, "end": 476.2, "text": " update of a task would cost us just 10 microseconds.", "tokens": [5623, 295, 257, 5633, 576, 2063, 505, 445, 1266, 3123, 37841, 28750, 13], "temperature": 0.0, "avg_logprob": -0.20900601298869156, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0008533290238119662}, {"id": 94, "seek": 46676, "start": 476.2, "end": 481.08, "text": " To check a deadline or check an atomic flag, lock and lock, and you text and that's it.", "tokens": [1407, 1520, 257, 20615, 420, 1520, 364, 22275, 7166, 11, 4017, 293, 4017, 11, 293, 291, 2487, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.20900601298869156, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0008533290238119662}, {"id": 95, "seek": 46676, "start": 481.08, "end": 485.84, "text": " It's not much, but if you have 10,000 tasks per second doing those unnecessary wakeups,", "tokens": [467, 311, 406, 709, 11, 457, 498, 291, 362, 1266, 11, 1360, 9608, 680, 1150, 884, 729, 19350, 6634, 7528, 11], "temperature": 0.0, "avg_logprob": -0.20900601298869156, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0008533290238119662}, {"id": 96, "seek": 46676, "start": 485.84, "end": 493.12, "text": " you just burned 10% of one CPU core, which already sounds worse, and this problem aggravates", "tokens": [291, 445, 13490, 1266, 4, 295, 472, 13199, 4965, 11, 597, 1217, 3263, 5324, 11, 293, 341, 1154, 47339, 1024], "temperature": 0.0, "avg_logprob": -0.20900601298869156, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0008533290238119662}, {"id": 97, "seek": 46676, "start": 493.12, "end": 496.15999999999997, "text": " if you have more threads than CPU cores.", "tokens": [498, 291, 362, 544, 19314, 813, 13199, 24826, 13], "temperature": 0.0, "avg_logprob": -0.20900601298869156, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0008533290238119662}, {"id": 98, "seek": 49616, "start": 496.16, "end": 499.44, "text": " Because then you didn't just burn the CPU time.", "tokens": [1436, 550, 291, 994, 380, 445, 5064, 264, 13199, 565, 13], "temperature": 0.0, "avg_logprob": -0.19727041721343994, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.002678848337382078}, {"id": 99, "seek": 49616, "start": 499.44, "end": 504.48, "text": " You stole it from other threads, which could spend it on something useful.", "tokens": [509, 16326, 309, 490, 661, 19314, 11, 597, 727, 3496, 309, 322, 746, 4420, 13], "temperature": 0.0, "avg_logprob": -0.19727041721343994, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.002678848337382078}, {"id": 100, "seek": 49616, "start": 504.48, "end": 510.08000000000004, "text": " This problem was actually real, and during low tests, some servers were spending more", "tokens": [639, 1154, 390, 767, 957, 11, 293, 1830, 2295, 6921, 11, 512, 15909, 645, 6434, 544], "temperature": 0.0, "avg_logprob": -0.19727041721343994, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.002678848337382078}, {"id": 101, "seek": 49616, "start": 510.08000000000004, "end": 518.32, "text": " CPU time on spurious wakeups than on doing actual work, because they were just burning", "tokens": [13199, 565, 322, 637, 24274, 6634, 7528, 813, 322, 884, 3539, 589, 11, 570, 436, 645, 445, 9488], "temperature": 0.0, "avg_logprob": -0.19727041721343994, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.002678848337382078}, {"id": 102, "seek": 49616, "start": 518.32, "end": 523.4, "text": " so much for the green data clusters.", "tokens": [370, 709, 337, 264, 3092, 1412, 23313, 13], "temperature": 0.0, "avg_logprob": -0.19727041721343994, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.002678848337382078}, {"id": 103, "seek": 52340, "start": 523.4, "end": 528.88, "text": " What we need on the summary from a really performance schedule, firstly, it should be", "tokens": [708, 321, 643, 322, 264, 12691, 490, 257, 534, 3389, 7567, 11, 27376, 11, 309, 820, 312], "temperature": 0.0, "avg_logprob": -0.2674074445452009, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.004025198519229889}, {"id": 104, "seek": 52340, "start": 528.88, "end": 529.88, "text": " fair.", "tokens": [3143, 13], "temperature": 0.0, "avg_logprob": -0.2674074445452009, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.004025198519229889}, {"id": 105, "seek": 52340, "start": 529.88, "end": 533.0, "text": " We are not allowed to pin tasks to threads.", "tokens": [492, 366, 406, 4350, 281, 5447, 9608, 281, 19314, 13], "temperature": 0.0, "avg_logprob": -0.2674074445452009, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.004025198519229889}, {"id": 106, "seek": 52340, "start": 533.0, "end": 534.0, "text": " It doesn't scale.", "tokens": [467, 1177, 380, 4373, 13], "temperature": 0.0, "avg_logprob": -0.2674074445452009, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.004025198519229889}, {"id": 107, "seek": 52340, "start": 534.0, "end": 539.9599999999999, "text": " Secondly, we need routines, so that tasks could give up their time, so they could yield", "tokens": [19483, 11, 321, 643, 33827, 11, 370, 300, 9608, 727, 976, 493, 641, 565, 11, 370, 436, 727, 11257], "temperature": 0.0, "avg_logprob": -0.2674074445452009, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.004025198519229889}, {"id": 108, "seek": 52340, "start": 539.9599999999999, "end": 544.3199999999999, "text": " and let the worker thread do some other work, other tasks.", "tokens": [293, 718, 264, 11346, 7207, 360, 512, 661, 589, 11, 661, 9608, 13], "temperature": 0.0, "avg_logprob": -0.2674074445452009, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.004025198519229889}, {"id": 109, "seek": 52340, "start": 544.3199999999999, "end": 550.92, "text": " And also, we have zero tolerance against polling, no polling at all, everything should be event", "tokens": [400, 611, 11, 321, 362, 4018, 23368, 1970, 29518, 11, 572, 29518, 412, 439, 11, 1203, 820, 312, 2280], "temperature": 0.0, "avg_logprob": -0.2674074445452009, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.004025198519229889}, {"id": 110, "seek": 52340, "start": 550.92, "end": 551.92, "text": " based.", "tokens": [2361, 13], "temperature": 0.0, "avg_logprob": -0.2674074445452009, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.004025198519229889}, {"id": 111, "seek": 55192, "start": 551.92, "end": 557.8, "text": " And these goals are achieved in a new scheduler, which I do to lack of fantasy, just called", "tokens": [400, 613, 5493, 366, 11042, 294, 257, 777, 12000, 260, 11, 597, 286, 360, 281, 5011, 295, 13861, 11, 445, 1219], "temperature": 0.0, "avg_logprob": -0.23089819941027412, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.0014152898220345378}, {"id": 112, "seek": 55192, "start": 557.8, "end": 559.28, "text": " the task scheduler.", "tokens": [264, 5633, 12000, 260, 13], "temperature": 0.0, "avg_logprob": -0.23089819941027412, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.0014152898220345378}, {"id": 113, "seek": 55192, "start": 559.28, "end": 565.9599999999999, "text": " Although the name is a pretty self-explanatory, what it does, the plan is that we will go", "tokens": [5780, 264, 1315, 307, 257, 1238, 2698, 12, 3121, 16554, 4745, 11, 437, 309, 775, 11, 264, 1393, 307, 300, 321, 486, 352], "temperature": 0.0, "avg_logprob": -0.23089819941027412, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.0014152898220345378}, {"id": 114, "seek": 55192, "start": 565.9599999999999, "end": 571.56, "text": " firstly, we'll look at the big picture of the entire scheduler, and then we will look", "tokens": [27376, 11, 321, 603, 574, 412, 264, 955, 3036, 295, 264, 2302, 12000, 260, 11, 293, 550, 321, 486, 574], "temperature": 0.0, "avg_logprob": -0.23089819941027412, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.0014152898220345378}, {"id": 115, "seek": 55192, "start": 571.56, "end": 576.52, "text": " at individual parts of the scheduler, when you will already know what they do.", "tokens": [412, 2609, 3166, 295, 264, 12000, 260, 11, 562, 291, 486, 1217, 458, 437, 436, 360, 13], "temperature": 0.0, "avg_logprob": -0.23089819941027412, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.0014152898220345378}, {"id": 116, "seek": 55192, "start": 576.52, "end": 580.4, "text": " Imagine like we have a process, this server running, it's a process.", "tokens": [11739, 411, 321, 362, 257, 1399, 11, 341, 7154, 2614, 11, 309, 311, 257, 1399, 13], "temperature": 0.0, "avg_logprob": -0.23089819941027412, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.0014152898220345378}, {"id": 117, "seek": 58040, "start": 580.4, "end": 586.8, "text": " It has multiple threads, and they produce tasks.", "tokens": [467, 575, 3866, 19314, 11, 293, 436, 5258, 9608, 13], "temperature": 0.0, "avg_logprob": -0.20319259734380812, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0017462411196902394}, {"id": 118, "seek": 58040, "start": 586.8, "end": 593.16, "text": " And we have a global object of type task scheduler in the process, like it can be C++ task scheduler,", "tokens": [400, 321, 362, 257, 4338, 2657, 295, 2010, 5633, 12000, 260, 294, 264, 1399, 11, 411, 309, 393, 312, 383, 25472, 5633, 12000, 260, 11], "temperature": 0.0, "avg_logprob": -0.20319259734380812, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0017462411196902394}, {"id": 119, "seek": 58040, "start": 593.16, "end": 598.24, "text": " Java task scheduler, whatever language you implemented it in, it is a global object in", "tokens": [10745, 5633, 12000, 260, 11, 2035, 2856, 291, 12270, 309, 294, 11, 309, 307, 257, 4338, 2657, 294], "temperature": 0.0, "avg_logprob": -0.20319259734380812, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0017462411196902394}, {"id": 120, "seek": 58040, "start": 598.24, "end": 599.24, "text": " the process.", "tokens": [264, 1399, 13], "temperature": 0.0, "avg_logprob": -0.20319259734380812, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0017462411196902394}, {"id": 121, "seek": 58040, "start": 599.24, "end": 604.4399999999999, "text": " And those threads, they produce tasks, so they receive some requests from clients and", "tokens": [400, 729, 19314, 11, 436, 5258, 9608, 11, 370, 436, 4774, 512, 12475, 490, 6982, 293], "temperature": 0.0, "avg_logprob": -0.20319259734380812, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0017462411196902394}, {"id": 122, "seek": 60444, "start": 604.44, "end": 611.5600000000001, "text": " post the, wrap them into tasks and post into the task scheduler in form of some callbacks", "tokens": [2183, 264, 11, 7019, 552, 666, 9608, 293, 2183, 666, 264, 5633, 12000, 260, 294, 1254, 295, 512, 818, 17758], "temperature": 0.0, "avg_logprob": -0.15309519767761232, "compression_ratio": 1.759433962264151, "no_speech_prob": 0.0006119258468970656}, {"id": 123, "seek": 60444, "start": 611.5600000000001, "end": 613.2800000000001, "text": " of some sort.", "tokens": [295, 512, 1333, 13], "temperature": 0.0, "avg_logprob": -0.15309519767761232, "compression_ratio": 1.759433962264151, "no_speech_prob": 0.0006119258468970656}, {"id": 124, "seek": 60444, "start": 613.2800000000001, "end": 618.6, "text": " In the scheduler, they will gather in a so-called front queue.", "tokens": [682, 264, 12000, 260, 11, 436, 486, 5448, 294, 257, 370, 12, 11880, 1868, 18639, 13], "temperature": 0.0, "avg_logprob": -0.15309519767761232, "compression_ratio": 1.759433962264151, "no_speech_prob": 0.0006119258468970656}, {"id": 125, "seek": 60444, "start": 618.6, "end": 625.1600000000001, "text": " Then the scheduler will periodically pick up, take all the tasks from the front queue,", "tokens": [1396, 264, 12000, 260, 486, 38916, 1888, 493, 11, 747, 439, 264, 9608, 490, 264, 1868, 18639, 11], "temperature": 0.0, "avg_logprob": -0.15309519767761232, "compression_ratio": 1.759433962264151, "no_speech_prob": 0.0006119258468970656}, {"id": 126, "seek": 60444, "start": 625.1600000000001, "end": 626.9200000000001, "text": " and inspect them one by one.", "tokens": [293, 15018, 552, 472, 538, 472, 13], "temperature": 0.0, "avg_logprob": -0.15309519767761232, "compression_ratio": 1.759433962264151, "no_speech_prob": 0.0006119258468970656}, {"id": 127, "seek": 60444, "start": 626.9200000000001, "end": 632.5200000000001, "text": " It will see that some tasks are ready to be executed right now, the red ones on the slide.", "tokens": [467, 486, 536, 300, 512, 9608, 366, 1919, 281, 312, 17577, 558, 586, 11, 264, 2182, 2306, 322, 264, 4137, 13], "temperature": 0.0, "avg_logprob": -0.15309519767761232, "compression_ratio": 1.759433962264151, "no_speech_prob": 0.0006119258468970656}, {"id": 128, "seek": 63252, "start": 632.52, "end": 638.68, "text": " They want to be executed at SAP, and some other tasks they do not want to be executed", "tokens": [814, 528, 281, 312, 17577, 412, 27743, 11, 293, 512, 661, 9608, 436, 360, 406, 528, 281, 312, 17577], "temperature": 0.0, "avg_logprob": -0.20866594923303483, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0033273666631430387}, {"id": 129, "seek": 63252, "start": 638.68, "end": 640.96, "text": " right now, they just yielded.", "tokens": [558, 586, 11, 436, 445, 11257, 292, 13], "temperature": 0.0, "avg_logprob": -0.20866594923303483, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0033273666631430387}, {"id": 130, "seek": 63252, "start": 640.96, "end": 644.68, "text": " We have routines, so there will be tasks which don't want to be executed now.", "tokens": [492, 362, 33827, 11, 370, 456, 486, 312, 9608, 597, 500, 380, 528, 281, 312, 17577, 586, 13], "temperature": 0.0, "avg_logprob": -0.20866594923303483, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0033273666631430387}, {"id": 131, "seek": 63252, "start": 644.68, "end": 646.72, "text": " They are waiting for something.", "tokens": [814, 366, 3806, 337, 746, 13], "temperature": 0.0, "avg_logprob": -0.20866594923303483, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0033273666631430387}, {"id": 132, "seek": 63252, "start": 646.72, "end": 653.16, "text": " For a deadline or for an explicit wake up for some event, they are moved into the wait", "tokens": [1171, 257, 20615, 420, 337, 364, 13691, 6634, 493, 337, 512, 2280, 11, 436, 366, 4259, 666, 264, 1699], "temperature": 0.0, "avg_logprob": -0.20866594923303483, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0033273666631430387}, {"id": 133, "seek": 63252, "start": 653.16, "end": 657.84, "text": " queue, where they will wait for their events.", "tokens": [18639, 11, 689, 436, 486, 1699, 337, 641, 3931, 13], "temperature": 0.0, "avg_logprob": -0.20866594923303483, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0033273666631430387}, {"id": 134, "seek": 65784, "start": 657.84, "end": 663.36, "text": " So from the wait queue, we extract some older tasks which were already sleeping there for", "tokens": [407, 490, 264, 1699, 18639, 11, 321, 8947, 512, 4906, 9608, 597, 645, 1217, 8296, 456, 337], "temperature": 0.0, "avg_logprob": -0.19488479780114215, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0021094565745443106}, {"id": 135, "seek": 65784, "start": 663.36, "end": 670.64, "text": " some time, and now their deadline is up, or they were woken up explicitly, either way", "tokens": [512, 565, 11, 293, 586, 641, 20615, 307, 493, 11, 420, 436, 645, 261, 8406, 493, 20803, 11, 2139, 636], "temperature": 0.0, "avg_logprob": -0.19488479780114215, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0021094565745443106}, {"id": 136, "seek": 65784, "start": 670.64, "end": 676.44, "text": " we extract them from the queue, and all those red tasks go to the ready queue.", "tokens": [321, 8947, 552, 490, 264, 18639, 11, 293, 439, 729, 2182, 9608, 352, 281, 264, 1919, 18639, 13], "temperature": 0.0, "avg_logprob": -0.19488479780114215, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0021094565745443106}, {"id": 137, "seek": 65784, "start": 676.44, "end": 682.84, "text": " And from here, they are extracted by the worker threads, which take them from the ready queue", "tokens": [400, 490, 510, 11, 436, 366, 34086, 538, 264, 11346, 19314, 11, 597, 747, 552, 490, 264, 1919, 18639], "temperature": 0.0, "avg_logprob": -0.19488479780114215, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0021094565745443106}, {"id": 138, "seek": 65784, "start": 682.84, "end": 686.08, "text": " one by one and execute.", "tokens": [472, 538, 472, 293, 14483, 13], "temperature": 0.0, "avg_logprob": -0.19488479780114215, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0021094565745443106}, {"id": 139, "seek": 68608, "start": 686.08, "end": 691.1600000000001, "text": " And this is basically the entire pipeline, it's not too complicated, although some of", "tokens": [400, 341, 307, 1936, 264, 2302, 15517, 11, 309, 311, 406, 886, 6179, 11, 4878, 512, 295], "temperature": 0.0, "avg_logprob": -0.18313395535504376, "compression_ratio": 1.8047808764940239, "no_speech_prob": 0.0014211524976417422}, {"id": 140, "seek": 68608, "start": 691.1600000000001, "end": 694.72, "text": " you could already have a question, who does this part?", "tokens": [291, 727, 1217, 362, 257, 1168, 11, 567, 775, 341, 644, 30], "temperature": 0.0, "avg_logprob": -0.18313395535504376, "compression_ratio": 1.8047808764940239, "no_speech_prob": 0.0014211524976417422}, {"id": 141, "seek": 68608, "start": 694.72, "end": 697.48, "text": " We have external threads posting tasks.", "tokens": [492, 362, 8320, 19314, 15978, 9608, 13], "temperature": 0.0, "avg_logprob": -0.18313395535504376, "compression_ratio": 1.8047808764940239, "no_speech_prob": 0.0014211524976417422}, {"id": 142, "seek": 68608, "start": 697.48, "end": 702.4000000000001, "text": " We have worker threads doing tasks, but who does the scheduling itself, managing management", "tokens": [492, 362, 11346, 19314, 884, 9608, 11, 457, 567, 775, 264, 29055, 2564, 11, 11642, 4592], "temperature": 0.0, "avg_logprob": -0.18313395535504376, "compression_ratio": 1.8047808764940239, "no_speech_prob": 0.0014211524976417422}, {"id": 143, "seek": 68608, "start": 702.4000000000001, "end": 704.1600000000001, "text": " of the queues?", "tokens": [295, 264, 631, 1247, 30], "temperature": 0.0, "avg_logprob": -0.18313395535504376, "compression_ratio": 1.8047808764940239, "no_speech_prob": 0.0014211524976417422}, {"id": 144, "seek": 68608, "start": 704.1600000000001, "end": 707.96, "text": " The thing is, there is no dedicated thread doing just the scheduling.", "tokens": [440, 551, 307, 11, 456, 307, 572, 8374, 7207, 884, 445, 264, 29055, 13], "temperature": 0.0, "avg_logprob": -0.18313395535504376, "compression_ratio": 1.8047808764940239, "no_speech_prob": 0.0014211524976417422}, {"id": 145, "seek": 68608, "start": 707.96, "end": 714.08, "text": " Instead, the worker threads compete for doing the scheduling, depending on who of them is", "tokens": [7156, 11, 264, 11346, 19314, 11831, 337, 884, 264, 29055, 11, 5413, 322, 567, 295, 552, 307], "temperature": 0.0, "avg_logprob": -0.18313395535504376, "compression_ratio": 1.8047808764940239, "no_speech_prob": 0.0014211524976417422}, {"id": 146, "seek": 68608, "start": 714.08, "end": 715.08, "text": " idle.", "tokens": [30650, 13], "temperature": 0.0, "avg_logprob": -0.18313395535504376, "compression_ratio": 1.8047808764940239, "no_speech_prob": 0.0014211524976417422}, {"id": 147, "seek": 71508, "start": 715.08, "end": 721.1600000000001, "text": " Imagine, like this big rectangle with queues, it's a room with a single key to it.", "tokens": [11739, 11, 411, 341, 955, 21930, 365, 631, 1247, 11, 309, 311, 257, 1808, 365, 257, 2167, 2141, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.232804582830061, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0024216491729021072}, {"id": 148, "seek": 71508, "start": 721.1600000000001, "end": 725.96, "text": " And the worker threads, sometimes, depending on who of them is idle, again, will try to", "tokens": [400, 264, 11346, 19314, 11, 2171, 11, 5413, 322, 567, 295, 552, 307, 30650, 11, 797, 11, 486, 853, 281], "temperature": 0.0, "avg_logprob": -0.232804582830061, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0024216491729021072}, {"id": 149, "seek": 71508, "start": 725.96, "end": 726.96, "text": " pick out the key.", "tokens": [1888, 484, 264, 2141, 13], "temperature": 0.0, "avg_logprob": -0.232804582830061, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0024216491729021072}, {"id": 150, "seek": 71508, "start": 726.96, "end": 732.76, "text": " Whoever does it first, enters the room, does the scheduling, this queue management stuff,", "tokens": [24743, 775, 309, 700, 11, 18780, 264, 1808, 11, 775, 264, 29055, 11, 341, 18639, 4592, 1507, 11], "temperature": 0.0, "avg_logprob": -0.232804582830061, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0024216491729021072}, {"id": 151, "seek": 71508, "start": 732.76, "end": 734.72, "text": " leaves the room, and starts doing tasks.", "tokens": [5510, 264, 1808, 11, 293, 3719, 884, 9608, 13], "temperature": 0.0, "avg_logprob": -0.232804582830061, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0024216491729021072}, {"id": 152, "seek": 71508, "start": 734.72, "end": 736.72, "text": " So all the threads are the same.", "tokens": [407, 439, 264, 19314, 366, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.232804582830061, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0024216491729021072}, {"id": 153, "seek": 71508, "start": 736.72, "end": 742.84, "text": " There is no threads having goals of some sort, like a naive implementation could do.", "tokens": [821, 307, 572, 19314, 1419, 5493, 295, 512, 1333, 11, 411, 257, 29052, 11420, 727, 360, 13], "temperature": 0.0, "avg_logprob": -0.232804582830061, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0024216491729021072}, {"id": 154, "seek": 74284, "start": 742.84, "end": 748.6, "text": " And it's a bit like dining philosophers' problem, except that we have just one fork here.", "tokens": [400, 309, 311, 257, 857, 411, 17874, 36839, 6, 1154, 11, 3993, 300, 321, 362, 445, 472, 17716, 510, 13], "temperature": 0.0, "avg_logprob": -0.2634977377378024, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0021578227169811726}, {"id": 155, "seek": 74284, "start": 748.6, "end": 754.0, "text": " And this big rectangle, in this case, is just a plate of spaghetti, but not on code, code", "tokens": [400, 341, 955, 21930, 11, 294, 341, 1389, 11, 307, 445, 257, 5924, 295, 28556, 11, 457, 406, 322, 3089, 11, 3089], "temperature": 0.0, "avg_logprob": -0.2634977377378024, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0021578227169811726}, {"id": 156, "seek": 74284, "start": 754.0, "end": 756.52, "text": " is clean.", "tokens": [307, 2541, 13], "temperature": 0.0, "avg_logprob": -0.2634977377378024, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0021578227169811726}, {"id": 157, "seek": 74284, "start": 756.52, "end": 762.24, "text": " To improve understanding, there is a short visual example I prepared.", "tokens": [1407, 3470, 3701, 11, 456, 307, 257, 2099, 5056, 1365, 286, 4927, 13], "temperature": 0.0, "avg_logprob": -0.2634977377378024, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0021578227169811726}, {"id": 158, "seek": 74284, "start": 762.24, "end": 764.2, "text": " Imagine, like, we have five tasks.", "tokens": [11739, 11, 411, 11, 321, 362, 1732, 9608, 13], "temperature": 0.0, "avg_logprob": -0.2634977377378024, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0021578227169811726}, {"id": 159, "seek": 74284, "start": 764.2, "end": 769.2800000000001, "text": " They are posted onto the front queue, and one of the worker threads has the scheduling", "tokens": [814, 366, 9437, 3911, 264, 1868, 18639, 11, 293, 472, 295, 264, 11346, 19314, 575, 264, 29055], "temperature": 0.0, "avg_logprob": -0.2634977377378024, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0021578227169811726}, {"id": 160, "seek": 74284, "start": 769.2800000000001, "end": 771.48, "text": " key right now.", "tokens": [2141, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.2634977377378024, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0021578227169811726}, {"id": 161, "seek": 77148, "start": 771.48, "end": 774.36, "text": " It will extract the tasks from the queue.", "tokens": [467, 486, 8947, 264, 9608, 490, 264, 18639, 13], "temperature": 0.0, "avg_logprob": -0.1731209715535818, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0014370493590831757}, {"id": 162, "seek": 77148, "start": 774.36, "end": 776.5600000000001, "text": " We'll see that a couple of them yielded.", "tokens": [492, 603, 536, 300, 257, 1916, 295, 552, 11257, 292, 13], "temperature": 0.0, "avg_logprob": -0.1731209715535818, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0014370493590831757}, {"id": 163, "seek": 77148, "start": 776.5600000000001, "end": 782.96, "text": " They go to the wait queue, waiting for something, and the others are moved into the ready queue.", "tokens": [814, 352, 281, 264, 1699, 18639, 11, 3806, 337, 746, 11, 293, 264, 2357, 366, 4259, 666, 264, 1919, 18639, 13], "temperature": 0.0, "avg_logprob": -0.1731209715535818, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0014370493590831757}, {"id": 164, "seek": 77148, "start": 782.96, "end": 786.24, "text": " From here, they are picked up by the worker threads.", "tokens": [3358, 510, 11, 436, 366, 6183, 493, 538, 264, 11346, 19314, 13], "temperature": 0.0, "avg_logprob": -0.1731209715535818, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0014370493590831757}, {"id": 165, "seek": 77148, "start": 786.24, "end": 787.76, "text": " Nobody is doing the scheduling right now.", "tokens": [9297, 307, 884, 264, 29055, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.1731209715535818, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0014370493590831757}, {"id": 166, "seek": 77148, "start": 787.76, "end": 790.84, "text": " All the threads are doing some actual work.", "tokens": [1057, 264, 19314, 366, 884, 512, 3539, 589, 13], "temperature": 0.0, "avg_logprob": -0.1731209715535818, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0014370493590831757}, {"id": 167, "seek": 77148, "start": 790.84, "end": 796.72, "text": " A couple of tasks are done, and suddenly, those waiting tasks are woken up, or their", "tokens": [316, 1916, 295, 9608, 366, 1096, 11, 293, 5800, 11, 729, 3806, 9608, 366, 261, 8406, 493, 11, 420, 641], "temperature": 0.0, "avg_logprob": -0.1731209715535818, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0014370493590831757}, {"id": 168, "seek": 77148, "start": 796.72, "end": 798.36, "text": " deadline is up.", "tokens": [20615, 307, 493, 13], "temperature": 0.0, "avg_logprob": -0.1731209715535818, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0014370493590831757}, {"id": 169, "seek": 77148, "start": 798.36, "end": 799.9200000000001, "text": " They want to be executed now.", "tokens": [814, 528, 281, 312, 17577, 586, 13], "temperature": 0.0, "avg_logprob": -0.1731209715535818, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0014370493590831757}, {"id": 170, "seek": 79992, "start": 799.92, "end": 803.24, "text": " So one of the worker threads will eventually pick up the scheduling key.", "tokens": [407, 472, 295, 264, 11346, 19314, 486, 4728, 1888, 493, 264, 29055, 2141, 13], "temperature": 0.0, "avg_logprob": -0.18340846470424108, "compression_ratio": 1.8102189781021898, "no_speech_prob": 0.0022984924726188183}, {"id": 171, "seek": 79992, "start": 803.24, "end": 804.24, "text": " We'll notice this.", "tokens": [492, 603, 3449, 341, 13], "temperature": 0.0, "avg_logprob": -0.18340846470424108, "compression_ratio": 1.8102189781021898, "no_speech_prob": 0.0022984924726188183}, {"id": 172, "seek": 79992, "start": 804.24, "end": 808.68, "text": " We'll move the tasks into the ready queue, and in parallel, some other thread finished", "tokens": [492, 603, 1286, 264, 9608, 666, 264, 1919, 18639, 11, 293, 294, 8952, 11, 512, 661, 7207, 4335], "temperature": 0.0, "avg_logprob": -0.18340846470424108, "compression_ratio": 1.8102189781021898, "no_speech_prob": 0.0022984924726188183}, {"id": 173, "seek": 79992, "start": 808.68, "end": 810.1999999999999, "text": " and older tasks.", "tokens": [293, 4906, 9608, 13], "temperature": 0.0, "avg_logprob": -0.18340846470424108, "compression_ratio": 1.8102189781021898, "no_speech_prob": 0.0022984924726188183}, {"id": 174, "seek": 79992, "start": 810.1999999999999, "end": 815.24, "text": " Now, those two tasks are picked up by a couple of random threads.", "tokens": [823, 11, 729, 732, 9608, 366, 6183, 493, 538, 257, 1916, 295, 4974, 19314, 13], "temperature": 0.0, "avg_logprob": -0.18340846470424108, "compression_ratio": 1.8102189781021898, "no_speech_prob": 0.0022984924726188183}, {"id": 175, "seek": 79992, "start": 815.24, "end": 819.92, "text": " They are done, and some other thread will pick up the scheduling key, and the process", "tokens": [814, 366, 1096, 11, 293, 512, 661, 7207, 486, 1888, 493, 264, 29055, 2141, 11, 293, 264, 1399], "temperature": 0.0, "avg_logprob": -0.18340846470424108, "compression_ratio": 1.8102189781021898, "no_speech_prob": 0.0022984924726188183}, {"id": 176, "seek": 79992, "start": 819.92, "end": 822.28, "text": " repeats all the time when new tasks arrive.", "tokens": [35038, 439, 264, 565, 562, 777, 9608, 8881, 13], "temperature": 0.0, "avg_logprob": -0.18340846470424108, "compression_ratio": 1.8102189781021898, "no_speech_prob": 0.0022984924726188183}, {"id": 177, "seek": 79992, "start": 822.28, "end": 823.28, "text": " This is it.", "tokens": [639, 307, 309, 13], "temperature": 0.0, "avg_logprob": -0.18340846470424108, "compression_ratio": 1.8102189781021898, "no_speech_prob": 0.0022984924726188183}, {"id": 178, "seek": 79992, "start": 823.28, "end": 829.88, "text": " What we need to implement all this cool stuff, the language and the libraries, which we will", "tokens": [708, 321, 643, 281, 4445, 439, 341, 1627, 1507, 11, 264, 2856, 293, 264, 15148, 11, 597, 321, 486], "temperature": 0.0, "avg_logprob": -0.18340846470424108, "compression_ratio": 1.8102189781021898, "no_speech_prob": 0.0022984924726188183}, {"id": 179, "seek": 82988, "start": 829.88, "end": 835.0, "text": " be using, need to provide us with the following stuff, at least.", "tokens": [312, 1228, 11, 643, 281, 2893, 505, 365, 264, 3480, 1507, 11, 412, 1935, 13], "temperature": 0.0, "avg_logprob": -0.23037768722674168, "compression_ratio": 1.70703125, "no_speech_prob": 0.00182053551543504}, {"id": 180, "seek": 82988, "start": 835.0, "end": 841.2, "text": " We need mutexes, containers like race, lists, condition variables, and not important for", "tokens": [492, 643, 24523, 47047, 11, 17089, 411, 4569, 11, 14511, 11, 4188, 9102, 11, 293, 406, 1021, 337], "temperature": 0.0, "avg_logprob": -0.23037768722674168, "compression_ratio": 1.70703125, "no_speech_prob": 0.00182053551543504}, {"id": 181, "seek": 82988, "start": 841.2, "end": 847.0, "text": " the algorithm, but for the implementation, for the performance, it's extremely important.", "tokens": [264, 9284, 11, 457, 337, 264, 11420, 11, 337, 264, 3389, 11, 309, 311, 4664, 1021, 13], "temperature": 0.0, "avg_logprob": -0.23037768722674168, "compression_ratio": 1.70703125, "no_speech_prob": 0.00182053551543504}, {"id": 182, "seek": 82988, "start": 847.0, "end": 850.76, "text": " We will also need log-free atomic operations.", "tokens": [492, 486, 611, 643, 3565, 12, 10792, 22275, 7705, 13], "temperature": 0.0, "avg_logprob": -0.23037768722674168, "compression_ratio": 1.70703125, "no_speech_prob": 0.00182053551543504}, {"id": 183, "seek": 82988, "start": 850.76, "end": 855.72, "text": " Just in case not all of you know what they are, here is a short pseudo code explaining", "tokens": [1449, 294, 1389, 406, 439, 295, 291, 458, 437, 436, 366, 11, 510, 307, 257, 2099, 35899, 3089, 13468], "temperature": 0.0, "avg_logprob": -0.23037768722674168, "compression_ratio": 1.70703125, "no_speech_prob": 0.00182053551543504}, {"id": 184, "seek": 82988, "start": 855.72, "end": 859.76, "text": " what these log-free atomics are, we will need three of them.", "tokens": [437, 613, 3565, 12, 10792, 12018, 1167, 366, 11, 321, 486, 643, 1045, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.23037768722674168, "compression_ratio": 1.70703125, "no_speech_prob": 0.00182053551543504}, {"id": 185, "seek": 85976, "start": 859.76, "end": 867.6, "text": " Firstly, it's atomic load, which is basically reading a variable, but with respect to so-called", "tokens": [20042, 11, 309, 311, 22275, 3677, 11, 597, 307, 1936, 3760, 257, 7006, 11, 457, 365, 3104, 281, 370, 12, 11880], "temperature": 0.0, "avg_logprob": -0.21745872497558594, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.001232445822097361}, {"id": 186, "seek": 85976, "start": 867.6, "end": 873.4, "text": " memory models, which, again, Google afterwards, it's too complicated topic to dive in right", "tokens": [4675, 5245, 11, 597, 11, 797, 11, 3329, 10543, 11, 309, 311, 886, 6179, 4829, 281, 9192, 294, 558], "temperature": 0.0, "avg_logprob": -0.21745872497558594, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.001232445822097361}, {"id": 187, "seek": 85976, "start": 873.4, "end": 874.4, "text": " now.", "tokens": [586, 13], "temperature": 0.0, "avg_logprob": -0.21745872497558594, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.001232445822097361}, {"id": 188, "seek": 85976, "start": 874.4, "end": 879.08, "text": " We will also need atomic compare exchange, which is conditional assignment.", "tokens": [492, 486, 611, 643, 22275, 6794, 7742, 11, 597, 307, 27708, 15187, 13], "temperature": 0.0, "avg_logprob": -0.21745872497558594, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.001232445822097361}, {"id": 189, "seek": 85976, "start": 879.08, "end": 885.36, "text": " So we set a new value to some variable if it was equal to something else which we wanted", "tokens": [407, 321, 992, 257, 777, 2158, 281, 512, 7006, 498, 309, 390, 2681, 281, 746, 1646, 597, 321, 1415], "temperature": 0.0, "avg_logprob": -0.21745872497558594, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.001232445822097361}, {"id": 190, "seek": 85976, "start": 885.36, "end": 886.36, "text": " to check.", "tokens": [281, 1520, 13], "temperature": 0.0, "avg_logprob": -0.21745872497558594, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.001232445822097361}, {"id": 191, "seek": 85976, "start": 886.36, "end": 888.4399999999999, "text": " And we will also need atomic exchange.", "tokens": [400, 321, 486, 611, 643, 22275, 7742, 13], "temperature": 0.0, "avg_logprob": -0.21745872497558594, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.001232445822097361}, {"id": 192, "seek": 88844, "start": 888.44, "end": 892.2, "text": " So it sets a new value and returns the old value.", "tokens": [407, 309, 6352, 257, 777, 2158, 293, 11247, 264, 1331, 2158, 13], "temperature": 0.0, "avg_logprob": -0.17078880027488427, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.0019204940181225538}, {"id": 193, "seek": 88844, "start": 892.2, "end": 898.32, "text": " The cool stuff about those log-free atomics is that they are not only atomic, but they", "tokens": [440, 1627, 1507, 466, 729, 3565, 12, 10792, 12018, 1167, 307, 300, 436, 366, 406, 787, 22275, 11, 457, 436], "temperature": 0.0, "avg_logprob": -0.17078880027488427, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.0019204940181225538}, {"id": 194, "seek": 88844, "start": 898.32, "end": 899.8000000000001, "text": " are log-free.", "tokens": [366, 3565, 12, 10792, 13], "temperature": 0.0, "avg_logprob": -0.17078880027488427, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.0019204940181225538}, {"id": 195, "seek": 88844, "start": 899.8000000000001, "end": 901.8800000000001, "text": " There is no mutexes.", "tokens": [821, 307, 572, 24523, 47047, 13], "temperature": 0.0, "avg_logprob": -0.17078880027488427, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.0019204940181225538}, {"id": 196, "seek": 88844, "start": 901.8800000000001, "end": 906.2, "text": " On the contrary, mutexes use this stuff inside.", "tokens": [1282, 264, 19506, 11, 24523, 47047, 764, 341, 1507, 1854, 13], "temperature": 0.0, "avg_logprob": -0.17078880027488427, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.0019204940181225538}, {"id": 197, "seek": 88844, "start": 906.2, "end": 910.32, "text": " And how they are implemented, they are special instructions right on the CPU.", "tokens": [400, 577, 436, 366, 12270, 11, 436, 366, 2121, 9415, 558, 322, 264, 13199, 13], "temperature": 0.0, "avg_logprob": -0.17078880027488427, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.0019204940181225538}, {"id": 198, "seek": 88844, "start": 910.32, "end": 914.36, "text": " So doing those operations doesn't even involve the kernel.", "tokens": [407, 884, 729, 7705, 1177, 380, 754, 9494, 264, 28256, 13], "temperature": 0.0, "avg_logprob": -0.17078880027488427, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.0019204940181225538}, {"id": 199, "seek": 88844, "start": 914.36, "end": 917.12, "text": " It's quite cheap if you use it efficiently.", "tokens": [467, 311, 1596, 7084, 498, 291, 764, 309, 19621, 13], "temperature": 0.0, "avg_logprob": -0.17078880027488427, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.0019204940181225538}, {"id": 200, "seek": 91712, "start": 917.12, "end": 923.08, "text": " And those three operations are basis for some very cool and extremely performant algorithms,", "tokens": [400, 729, 1045, 7705, 366, 5143, 337, 512, 588, 1627, 293, 4664, 2042, 394, 14642, 11], "temperature": 0.0, "avg_logprob": -0.2196630176744963, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.003125044284388423}, {"id": 201, "seek": 91712, "start": 923.08, "end": 924.08, "text": " as we will see.", "tokens": [382, 321, 486, 536, 13], "temperature": 0.0, "avg_logprob": -0.2196630176744963, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.003125044284388423}, {"id": 202, "seek": 91712, "start": 924.08, "end": 925.08, "text": " Not just here.", "tokens": [1726, 445, 510, 13], "temperature": 0.0, "avg_logprob": -0.2196630176744963, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.003125044284388423}, {"id": 203, "seek": 91712, "start": 925.08, "end": 929.96, "text": " There are a lot of those algorithms based on those log-free atomic operations.", "tokens": [821, 366, 257, 688, 295, 729, 14642, 2361, 322, 729, 3565, 12, 10792, 22275, 7705, 13], "temperature": 0.0, "avg_logprob": -0.2196630176744963, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.003125044284388423}, {"id": 204, "seek": 91712, "start": 929.96, "end": 933.4, "text": " They are also called log-free algorithms.", "tokens": [814, 366, 611, 1219, 3565, 12, 10792, 14642, 13], "temperature": 0.0, "avg_logprob": -0.2196630176744963, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.003125044284388423}, {"id": 205, "seek": 91712, "start": 933.4, "end": 940.28, "text": " And we will follow the task pipeline, looking at the scheduler parts, and we will start", "tokens": [400, 321, 486, 1524, 264, 5633, 15517, 11, 1237, 412, 264, 12000, 260, 3166, 11, 293, 321, 486, 722], "temperature": 0.0, "avg_logprob": -0.2196630176744963, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.003125044284388423}, {"id": 206, "seek": 91712, "start": 940.28, "end": 943.8, "text": " from the front queue, just like the tasks.", "tokens": [490, 264, 1868, 18639, 11, 445, 411, 264, 9608, 13], "temperature": 0.0, "avg_logprob": -0.2196630176744963, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.003125044284388423}, {"id": 207, "seek": 94380, "start": 943.8, "end": 949.88, "text": " We know that this queue has multiple producers, and it has a single consumer.", "tokens": [492, 458, 300, 341, 18639, 575, 3866, 16080, 11, 293, 309, 575, 257, 2167, 9711, 13], "temperature": 0.0, "avg_logprob": -0.1621765489337825, "compression_ratio": 1.9953488372093022, "no_speech_prob": 0.0031069207470864058}, {"id": 208, "seek": 94380, "start": 949.88, "end": 954.88, "text": " So it means this queue is multi-producer, single-consumer.", "tokens": [407, 309, 1355, 341, 18639, 307, 4825, 12, 14314, 1776, 11, 2167, 12, 21190, 15583, 13], "temperature": 0.0, "avg_logprob": -0.1621765489337825, "compression_ratio": 1.9953488372093022, "no_speech_prob": 0.0031069207470864058}, {"id": 209, "seek": 94380, "start": 954.88, "end": 957.68, "text": " This is a common notation for naming queues.", "tokens": [639, 307, 257, 2689, 24657, 337, 25290, 631, 1247, 13], "temperature": 0.0, "avg_logprob": -0.1621765489337825, "compression_ratio": 1.9953488372093022, "no_speech_prob": 0.0031069207470864058}, {"id": 210, "seek": 94380, "start": 957.68, "end": 963.0, "text": " We say multi-produce, multi- or single-producer, multi- or single-consumer, and we get four", "tokens": [492, 584, 4825, 12, 14314, 384, 11, 4825, 12, 420, 2167, 12, 14314, 1776, 11, 4825, 12, 420, 2167, 12, 21190, 15583, 11, 293, 321, 483, 1451], "temperature": 0.0, "avg_logprob": -0.1621765489337825, "compression_ratio": 1.9953488372093022, "no_speech_prob": 0.0031069207470864058}, {"id": 211, "seek": 94380, "start": 963.0, "end": 964.76, "text": " combinations of queue types.", "tokens": [21267, 295, 18639, 3467, 13], "temperature": 0.0, "avg_logprob": -0.1621765489337825, "compression_ratio": 1.9953488372093022, "no_speech_prob": 0.0031069207470864058}, {"id": 212, "seek": 94380, "start": 964.76, "end": 968.0799999999999, "text": " This is multi-producer, single-consumer.", "tokens": [639, 307, 4825, 12, 14314, 1776, 11, 2167, 12, 21190, 15583, 13], "temperature": 0.0, "avg_logprob": -0.1621765489337825, "compression_ratio": 1.9953488372093022, "no_speech_prob": 0.0031069207470864058}, {"id": 213, "seek": 94380, "start": 968.0799999999999, "end": 972.5999999999999, "text": " We also know about this queue that it will experience high contention, because I want", "tokens": [492, 611, 458, 466, 341, 18639, 300, 309, 486, 1752, 1090, 660, 1251, 11, 570, 286, 528], "temperature": 0.0, "avg_logprob": -0.1621765489337825, "compression_ratio": 1.9953488372093022, "no_speech_prob": 0.0031069207470864058}, {"id": 214, "seek": 97260, "start": 972.6, "end": 975.12, "text": " my scheduler to be functional.", "tokens": [452, 12000, 260, 281, 312, 11745, 13], "temperature": 0.0, "avg_logprob": -0.20528913281627537, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0016567036509513855}, {"id": 215, "seek": 97260, "start": 975.12, "end": 981.1800000000001, "text": " When I have tens of threads and millions of tasks per second, this means extreme contention", "tokens": [1133, 286, 362, 10688, 295, 19314, 293, 6803, 295, 9608, 680, 1150, 11, 341, 1355, 8084, 660, 1251], "temperature": 0.0, "avg_logprob": -0.20528913281627537, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0016567036509513855}, {"id": 216, "seek": 97260, "start": 981.1800000000001, "end": 982.6800000000001, "text": " on the front queue.", "tokens": [322, 264, 1868, 18639, 13], "temperature": 0.0, "avg_logprob": -0.20528913281627537, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0016567036509513855}, {"id": 217, "seek": 97260, "start": 982.6800000000001, "end": 987.8000000000001, "text": " This in turn means I should avoid mutexes, because mutexes most likely will choke here.", "tokens": [639, 294, 1261, 1355, 286, 820, 5042, 24523, 87, 279, 11, 570, 24523, 87, 279, 881, 3700, 486, 34427, 510, 13], "temperature": 0.0, "avg_logprob": -0.20528913281627537, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0016567036509513855}, {"id": 218, "seek": 97260, "start": 987.8000000000001, "end": 994.12, "text": " What you would do in a normal queue, not thread safe or anything, you would have to remember", "tokens": [708, 291, 576, 360, 294, 257, 2710, 18639, 11, 406, 7207, 3273, 420, 1340, 11, 291, 576, 362, 281, 1604], "temperature": 0.0, "avg_logprob": -0.20528913281627537, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0016567036509513855}, {"id": 219, "seek": 97260, "start": 994.12, "end": 998.52, "text": " two positions, head and tail, and maintain those positions.", "tokens": [732, 8432, 11, 1378, 293, 6838, 11, 293, 6909, 729, 8432, 13], "temperature": 0.0, "avg_logprob": -0.20528913281627537, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0016567036509513855}, {"id": 220, "seek": 99852, "start": 998.52, "end": 1004.84, "text": " If you try to turn this algorithm into a log-free thread safe implementation, it would be nightmare,", "tokens": [759, 291, 853, 281, 1261, 341, 9284, 666, 257, 3565, 12, 10792, 7207, 3273, 11420, 11, 309, 576, 312, 18724, 11], "temperature": 0.0, "avg_logprob": -0.16964589487207998, "compression_ratio": 1.7300884955752212, "no_speech_prob": 0.002477639354765415}, {"id": 221, "seek": 99852, "start": 1004.84, "end": 1011.52, "text": " because the more variables you have to update in a log-free way, the more complicated the", "tokens": [570, 264, 544, 9102, 291, 362, 281, 5623, 294, 257, 3565, 12, 10792, 636, 11, 264, 544, 6179, 264], "temperature": 0.0, "avg_logprob": -0.16964589487207998, "compression_ratio": 1.7300884955752212, "no_speech_prob": 0.002477639354765415}, {"id": 222, "seek": 99852, "start": 1011.52, "end": 1018.36, "text": " algorithm gets, and queue, like with two variables, it's extremely hard to implement in a log-free", "tokens": [9284, 2170, 11, 293, 18639, 11, 411, 365, 732, 9102, 11, 309, 311, 4664, 1152, 281, 4445, 294, 257, 3565, 12, 10792], "temperature": 0.0, "avg_logprob": -0.16964589487207998, "compression_ratio": 1.7300884955752212, "no_speech_prob": 0.002477639354765415}, {"id": 223, "seek": 99852, "start": 1018.36, "end": 1019.36, "text": " way.", "tokens": [636, 13], "temperature": 0.0, "avg_logprob": -0.16964589487207998, "compression_ratio": 1.7300884955752212, "no_speech_prob": 0.002477639354765415}, {"id": 224, "seek": 99852, "start": 1019.36, "end": 1024.68, "text": " We should try to avoid this if possible, and the idea is let's make it a stack instead", "tokens": [492, 820, 853, 281, 5042, 341, 498, 1944, 11, 293, 264, 1558, 307, 718, 311, 652, 309, 257, 8630, 2602], "temperature": 0.0, "avg_logprob": -0.16964589487207998, "compression_ratio": 1.7300884955752212, "no_speech_prob": 0.002477639354765415}, {"id": 225, "seek": 99852, "start": 1024.68, "end": 1026.2, "text": " of queue.", "tokens": [295, 18639, 13], "temperature": 0.0, "avg_logprob": -0.16964589487207998, "compression_ratio": 1.7300884955752212, "no_speech_prob": 0.002477639354765415}, {"id": 226, "seek": 102620, "start": 1026.2, "end": 1029.88, "text": " So we will maintain just one position, the top item, and that's it.", "tokens": [407, 321, 486, 6909, 445, 472, 2535, 11, 264, 1192, 3174, 11, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.16372488298986712, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0017553644720464945}, {"id": 227, "seek": 102620, "start": 1029.88, "end": 1034.8, "text": " We don't need two variables here, and then the algorithm becomes quite simple.", "tokens": [492, 500, 380, 643, 732, 9102, 510, 11, 293, 550, 264, 9284, 3643, 1596, 2199, 13], "temperature": 0.0, "avg_logprob": -0.16372488298986712, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0017553644720464945}, {"id": 228, "seek": 102620, "start": 1034.8, "end": 1042.0, "text": " Pushing is, well, we try to link new item with the old top, set it, atomic compare exchange", "tokens": [430, 5371, 307, 11, 731, 11, 321, 853, 281, 2113, 777, 3174, 365, 264, 1331, 1192, 11, 992, 309, 11, 22275, 6794, 7742], "temperature": 0.0, "avg_logprob": -0.16372488298986712, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0017553644720464945}, {"id": 229, "seek": 102620, "start": 1042.0, "end": 1048.1200000000001, "text": " will fail, if some other threads does it faster than we are in this push, and we don't retry", "tokens": [486, 3061, 11, 498, 512, 661, 19314, 775, 309, 4663, 813, 321, 366, 294, 341, 2944, 11, 293, 321, 500, 380, 1533, 627], "temperature": 0.0, "avg_logprob": -0.16372488298986712, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0017553644720464945}, {"id": 230, "seek": 102620, "start": 1048.1200000000001, "end": 1049.1200000000001, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.16372488298986712, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0017553644720464945}, {"id": 231, "seek": 102620, "start": 1049.1200000000001, "end": 1050.1200000000001, "text": " It's pretty simple.", "tokens": [467, 311, 1238, 2199, 13], "temperature": 0.0, "avg_logprob": -0.16372488298986712, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0017553644720464945}, {"id": 232, "seek": 102620, "start": 1050.1200000000001, "end": 1055.2, "text": " The more complicated part, although it looks shorter, is popping the items.", "tokens": [440, 544, 6179, 644, 11, 4878, 309, 1542, 11639, 11, 307, 18374, 264, 4754, 13], "temperature": 0.0, "avg_logprob": -0.16372488298986712, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0017553644720464945}, {"id": 233, "seek": 105520, "start": 1055.2, "end": 1061.6000000000001, "text": " The thing is that how pop is implemented, we just replace top item with null, effectively", "tokens": [440, 551, 307, 300, 577, 1665, 307, 12270, 11, 321, 445, 7406, 1192, 3174, 365, 18184, 11, 8659], "temperature": 0.0, "avg_logprob": -0.18034542417063296, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0015723503893241286}, {"id": 234, "seek": 105520, "start": 1061.6000000000001, "end": 1063.72, "text": " taking all the items at once.", "tokens": [1940, 439, 264, 4754, 412, 1564, 13], "temperature": 0.0, "avg_logprob": -0.18034542417063296, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0015723503893241286}, {"id": 235, "seek": 105520, "start": 1063.72, "end": 1066.32, "text": " We cannot pop them one by one.", "tokens": [492, 2644, 1665, 552, 472, 538, 472, 13], "temperature": 0.0, "avg_logprob": -0.18034542417063296, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0015723503893241286}, {"id": 236, "seek": 105520, "start": 1066.32, "end": 1071.0, "text": " And also, we have to reverse the list before we return it, because when we are pushing", "tokens": [400, 611, 11, 321, 362, 281, 9943, 264, 1329, 949, 321, 2736, 309, 11, 570, 562, 321, 366, 7380], "temperature": 0.0, "avg_logprob": -0.18034542417063296, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0015723503893241286}, {"id": 237, "seek": 105520, "start": 1071.0, "end": 1078.44, "text": " items in FIFO order, pushing them on the stack, they are returned in LIFO order, and we want", "tokens": [4754, 294, 479, 12775, 46, 1668, 11, 7380, 552, 322, 264, 8630, 11, 436, 366, 8752, 294, 7169, 18067, 1668, 11, 293, 321, 528], "temperature": 0.0, "avg_logprob": -0.18034542417063296, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0015723503893241286}, {"id": 238, "seek": 105520, "start": 1078.44, "end": 1081.64, "text": " to maintain the order, so we have to reverse it again.", "tokens": [281, 6909, 264, 1668, 11, 370, 321, 362, 281, 9943, 309, 797, 13], "temperature": 0.0, "avg_logprob": -0.18034542417063296, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0015723503893241286}, {"id": 239, "seek": 108164, "start": 1081.64, "end": 1087.2, "text": " These are two downsides that we can't pop one by one, and we have to reverse the result", "tokens": [1981, 366, 732, 21554, 1875, 300, 321, 393, 380, 1665, 472, 538, 472, 11, 293, 321, 362, 281, 9943, 264, 1874], "temperature": 0.0, "avg_logprob": -0.18331480999382174, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.003011788707226515}, {"id": 240, "seek": 108164, "start": 1087.2, "end": 1088.5200000000002, "text": " before returning it.", "tokens": [949, 12678, 309, 13], "temperature": 0.0, "avg_logprob": -0.18331480999382174, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.003011788707226515}, {"id": 241, "seek": 108164, "start": 1088.5200000000002, "end": 1095.3200000000002, "text": " On the other hand, what we get, it is completely lock free, thread safe, and it's weight free.", "tokens": [1282, 264, 661, 1011, 11, 437, 321, 483, 11, 309, 307, 2584, 4017, 1737, 11, 7207, 3273, 11, 293, 309, 311, 3364, 1737, 13], "temperature": 0.0, "avg_logprob": -0.18331480999382174, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.003011788707226515}, {"id": 242, "seek": 108164, "start": 1095.3200000000002, "end": 1100.3600000000001, "text": " Who will win those drawbacks for being lock free and weight free?", "tokens": [2102, 486, 1942, 729, 2642, 17758, 337, 885, 4017, 1737, 293, 3364, 1737, 30], "temperature": 0.0, "avg_logprob": -0.18331480999382174, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.003011788707226515}, {"id": 243, "seek": 108164, "start": 1100.3600000000001, "end": 1104.0400000000002, "text": " We will see in the end in the benchmark section.", "tokens": [492, 486, 536, 294, 264, 917, 294, 264, 18927, 3541, 13], "temperature": 0.0, "avg_logprob": -0.18331480999382174, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.003011788707226515}, {"id": 244, "seek": 108164, "start": 1104.0400000000002, "end": 1107.0800000000002, "text": " Next part of the task journey is weight queue.", "tokens": [3087, 644, 295, 264, 5633, 4671, 307, 3364, 18639, 13], "temperature": 0.0, "avg_logprob": -0.18331480999382174, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.003011788707226515}, {"id": 245, "seek": 110708, "start": 1107.08, "end": 1113.28, "text": " As we know, it stores yielded tasks, so they are waiting for something, like in 99 percent", "tokens": [1018, 321, 458, 11, 309, 9512, 11257, 292, 9608, 11, 370, 436, 366, 3806, 337, 746, 11, 411, 294, 11803, 3043], "temperature": 0.0, "avg_logprob": -0.1639024526766031, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0036652248818427324}, {"id": 246, "seek": 110708, "start": 1113.28, "end": 1116.08, "text": " of cases, they are waiting for a deadline.", "tokens": [295, 3331, 11, 436, 366, 3806, 337, 257, 20615, 13], "temperature": 0.0, "avg_logprob": -0.1639024526766031, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0036652248818427324}, {"id": 247, "seek": 110708, "start": 1116.08, "end": 1120.3999999999999, "text": " Since we are using tasks for requests, requests usually have a timeout, meaning that they", "tokens": [4162, 321, 366, 1228, 9608, 337, 12475, 11, 12475, 2673, 362, 257, 565, 346, 11, 3620, 300, 436], "temperature": 0.0, "avg_logprob": -0.1639024526766031, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0036652248818427324}, {"id": 248, "seek": 110708, "start": 1120.3999999999999, "end": 1122.12, "text": " have a deadline.", "tokens": [362, 257, 20615, 13], "temperature": 0.0, "avg_logprob": -0.1639024526766031, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0036652248818427324}, {"id": 249, "seek": 110708, "start": 1122.12, "end": 1128.52, "text": " So what we need is to be able to quickly pop all tasks with expired deadline, simply because", "tokens": [407, 437, 321, 643, 307, 281, 312, 1075, 281, 2661, 1665, 439, 9608, 365, 36587, 20615, 11, 2935, 570], "temperature": 0.0, "avg_logprob": -0.1639024526766031, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0036652248818427324}, {"id": 250, "seek": 110708, "start": 1128.52, "end": 1133.72, "text": " we have to do everything here quickly, there is a lot of tasks.", "tokens": [321, 362, 281, 360, 1203, 510, 2661, 11, 456, 307, 257, 688, 295, 9608, 13], "temperature": 0.0, "avg_logprob": -0.1639024526766031, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0036652248818427324}, {"id": 251, "seek": 113372, "start": 1133.72, "end": 1139.48, "text": " And we also know that this queue is always accessed by one third at a time.", "tokens": [400, 321, 611, 458, 300, 341, 18639, 307, 1009, 34211, 538, 472, 2636, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.20681672049040842, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0018555769929662347}, {"id": 252, "seek": 113372, "start": 1139.48, "end": 1143.48, "text": " The current scheduler worker who owns the scheduling key, so there is no concurrency", "tokens": [440, 2190, 12000, 260, 11346, 567, 19143, 264, 29055, 2141, 11, 370, 456, 307, 572, 23702, 10457], "temperature": 0.0, "avg_logprob": -0.20681672049040842, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0018555769929662347}, {"id": 253, "seek": 113372, "start": 1143.48, "end": 1144.8, "text": " on this queue.", "tokens": [322, 341, 18639, 13], "temperature": 0.0, "avg_logprob": -0.20681672049040842, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0018555769929662347}, {"id": 254, "seek": 113372, "start": 1144.8, "end": 1151.0, "text": " And that gives us quite a lot of freedom about what data structures we can use.", "tokens": [400, 300, 2709, 505, 1596, 257, 688, 295, 5645, 466, 437, 1412, 9227, 321, 393, 764, 13], "temperature": 0.0, "avg_logprob": -0.20681672049040842, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0018555769929662347}, {"id": 255, "seek": 113372, "start": 1151.0, "end": 1153.92, "text": " That basically means we can use binary heap.", "tokens": [663, 1936, 1355, 321, 393, 764, 17434, 33591, 13], "temperature": 0.0, "avg_logprob": -0.20681672049040842, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0018555769929662347}, {"id": 256, "seek": 113372, "start": 1153.92, "end": 1159.96, "text": " It's ideal for such a job when you have to quickly pop something sorted by a thing like", "tokens": [467, 311, 7157, 337, 1270, 257, 1691, 562, 291, 362, 281, 2661, 1665, 746, 25462, 538, 257, 551, 411], "temperature": 0.0, "avg_logprob": -0.20681672049040842, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0018555769929662347}, {"id": 257, "seek": 113372, "start": 1159.96, "end": 1161.76, "text": " deadline.", "tokens": [20615, 13], "temperature": 0.0, "avg_logprob": -0.20681672049040842, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0018555769929662347}, {"id": 258, "seek": 116176, "start": 1161.76, "end": 1166.52, "text": " What happens is that we sort the tasks by deadlines here, basically.", "tokens": [708, 2314, 307, 300, 321, 1333, 264, 9608, 538, 37548, 510, 11, 1936, 13], "temperature": 0.0, "avg_logprob": -0.13433272568220944, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0016956732142716646}, {"id": 259, "seek": 116176, "start": 1166.52, "end": 1172.0, "text": " So the task with the closest deadline will be on top and we will be able, for constant", "tokens": [407, 264, 5633, 365, 264, 13699, 20615, 486, 312, 322, 1192, 293, 321, 486, 312, 1075, 11, 337, 5754], "temperature": 0.0, "avg_logprob": -0.13433272568220944, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0016956732142716646}, {"id": 260, "seek": 116176, "start": 1172.0, "end": 1178.04, "text": " time, tell immediately if any task has expired by just looking at the top.", "tokens": [565, 11, 980, 4258, 498, 604, 5633, 575, 36587, 538, 445, 1237, 412, 264, 1192, 13], "temperature": 0.0, "avg_logprob": -0.13433272568220944, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0016956732142716646}, {"id": 261, "seek": 116176, "start": 1178.04, "end": 1184.96, "text": " And in case not all of you know what binary heap is, there is a brief explanation.", "tokens": [400, 294, 1389, 406, 439, 295, 291, 458, 437, 17434, 33591, 307, 11, 456, 307, 257, 5353, 10835, 13], "temperature": 0.0, "avg_logprob": -0.13433272568220944, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0016956732142716646}, {"id": 262, "seek": 116176, "start": 1184.96, "end": 1191.72, "text": " It's a perfectly balanced binary tree where each node value is less than values of its", "tokens": [467, 311, 257, 6239, 13902, 17434, 4230, 689, 1184, 9984, 2158, 307, 1570, 813, 4190, 295, 1080], "temperature": 0.0, "avg_logprob": -0.13433272568220944, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0016956732142716646}, {"id": 263, "seek": 119172, "start": 1191.72, "end": 1192.72, "text": " child nodes.", "tokens": [1440, 13891, 13], "temperature": 0.0, "avg_logprob": -0.21732587492867803, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.001453314907848835}, {"id": 264, "seek": 119172, "start": 1192.72, "end": 1194.48, "text": " We call this minimal heap.", "tokens": [492, 818, 341, 13206, 33591, 13], "temperature": 0.0, "avg_logprob": -0.21732587492867803, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.001453314907848835}, {"id": 265, "seek": 119172, "start": 1194.48, "end": 1198.6000000000001, "text": " If we reverse the order, it will be called maximal heap.", "tokens": [759, 321, 9943, 264, 1668, 11, 309, 486, 312, 1219, 49336, 33591, 13], "temperature": 0.0, "avg_logprob": -0.21732587492867803, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.001453314907848835}, {"id": 266, "seek": 119172, "start": 1198.6000000000001, "end": 1204.84, "text": " And this heap, it has quite good complexity.", "tokens": [400, 341, 33591, 11, 309, 575, 1596, 665, 14024, 13], "temperature": 0.0, "avg_logprob": -0.21732587492867803, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.001453314907848835}, {"id": 267, "seek": 119172, "start": 1204.84, "end": 1205.84, "text": " Quite good complexity.", "tokens": [20464, 665, 14024, 13], "temperature": 0.0, "avg_logprob": -0.21732587492867803, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.001453314907848835}, {"id": 268, "seek": 119172, "start": 1205.84, "end": 1210.72, "text": " So for logarithmic time, we can pop any items even from the middle.", "tokens": [407, 337, 41473, 355, 13195, 565, 11, 321, 393, 1665, 604, 4754, 754, 490, 264, 2808, 13], "temperature": 0.0, "avg_logprob": -0.21732587492867803, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.001453314907848835}, {"id": 269, "seek": 119172, "start": 1210.72, "end": 1216.56, "text": " We can push new items also for logarithmic time, which is very nice, very fast.", "tokens": [492, 393, 2944, 777, 4754, 611, 337, 41473, 355, 13195, 565, 11, 597, 307, 588, 1481, 11, 588, 2370, 13], "temperature": 0.0, "avg_logprob": -0.21732587492867803, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.001453314907848835}, {"id": 270, "seek": 121656, "start": 1216.56, "end": 1226.6, "text": " From the weight queue, the tasks migrate to the ready queue, which as we know is populated", "tokens": [3358, 264, 3364, 18639, 11, 264, 9608, 31821, 281, 264, 1919, 18639, 11, 597, 382, 321, 458, 307, 32998], "temperature": 0.0, "avg_logprob": -0.17696080556729946, "compression_ratio": 1.648780487804878, "no_speech_prob": 0.0018953172257170081}, {"id": 271, "seek": 121656, "start": 1226.6, "end": 1233.0, "text": " by one thread, current scheduler worker, and it is consumed by multiple threads, worker", "tokens": [538, 472, 7207, 11, 2190, 12000, 260, 11346, 11, 293, 309, 307, 21226, 538, 3866, 19314, 11, 11346], "temperature": 0.0, "avg_logprob": -0.17696080556729946, "compression_ratio": 1.648780487804878, "no_speech_prob": 0.0018953172257170081}, {"id": 272, "seek": 121656, "start": 1233.0, "end": 1234.84, "text": " threads.", "tokens": [19314, 13], "temperature": 0.0, "avg_logprob": -0.17696080556729946, "compression_ratio": 1.648780487804878, "no_speech_prob": 0.0018953172257170081}, {"id": 273, "seek": 121656, "start": 1234.84, "end": 1239.6799999999998, "text": " So it means this is a multi-consumer single producer queue.", "tokens": [407, 309, 1355, 341, 307, 257, 4825, 12, 21190, 15583, 2167, 12314, 18639, 13], "temperature": 0.0, "avg_logprob": -0.17696080556729946, "compression_ratio": 1.648780487804878, "no_speech_prob": 0.0018953172257170081}, {"id": 274, "seek": 121656, "start": 1239.6799999999998, "end": 1244.72, "text": " We also know that it will as well experience high contention because task scheduler should", "tokens": [492, 611, 458, 300, 309, 486, 382, 731, 1752, 1090, 660, 1251, 570, 5633, 12000, 260, 820], "temperature": 0.0, "avg_logprob": -0.17696080556729946, "compression_ratio": 1.648780487804878, "no_speech_prob": 0.0018953172257170081}, {"id": 275, "seek": 124472, "start": 1244.72, "end": 1247.92, "text": " be perfectly functional with like 10 worker threads.", "tokens": [312, 6239, 11745, 365, 411, 1266, 11346, 19314, 13], "temperature": 0.0, "avg_logprob": -0.20974638064702353, "compression_ratio": 1.4919354838709677, "no_speech_prob": 0.0034514565486460924}, {"id": 276, "seek": 124472, "start": 1247.92, "end": 1248.92, "text": " Why not?", "tokens": [1545, 406, 30], "temperature": 0.0, "avg_logprob": -0.20974638064702353, "compression_ratio": 1.4919354838709677, "no_speech_prob": 0.0034514565486460924}, {"id": 277, "seek": 124472, "start": 1248.92, "end": 1252.1200000000001, "text": " And with millions of tasks per second, we will have high contention.", "tokens": [400, 365, 6803, 295, 9608, 680, 1150, 11, 321, 486, 362, 1090, 660, 1251, 13], "temperature": 0.0, "avg_logprob": -0.20974638064702353, "compression_ratio": 1.4919354838709677, "no_speech_prob": 0.0034514565486460924}, {"id": 278, "seek": 124472, "start": 1252.1200000000001, "end": 1254.4, "text": " We have to deal with it somehow.", "tokens": [492, 362, 281, 2028, 365, 309, 6063, 13], "temperature": 0.0, "avg_logprob": -0.20974638064702353, "compression_ratio": 1.4919354838709677, "no_speech_prob": 0.0034514565486460924}, {"id": 279, "seek": 124472, "start": 1254.4, "end": 1261.3600000000001, "text": " Although unfortunately, I don't know a nice simple algorithm for doing unbounded and lock", "tokens": [5780, 7015, 11, 286, 500, 380, 458, 257, 1481, 2199, 9284, 337, 884, 517, 18767, 292, 293, 4017], "temperature": 0.0, "avg_logprob": -0.20974638064702353, "compression_ratio": 1.4919354838709677, "no_speech_prob": 0.0034514565486460924}, {"id": 280, "seek": 124472, "start": 1261.3600000000001, "end": 1263.6000000000001, "text": " free queue of this type.", "tokens": [1737, 18639, 295, 341, 2010, 13], "temperature": 0.0, "avg_logprob": -0.20974638064702353, "compression_ratio": 1.4919354838709677, "no_speech_prob": 0.0034514565486460924}, {"id": 281, "seek": 124472, "start": 1263.6000000000001, "end": 1269.3600000000001, "text": " For the reason why you can Google ABA problem, after the talk, it's also quite complicated.", "tokens": [1171, 264, 1778, 983, 291, 393, 3329, 316, 9295, 1154, 11, 934, 264, 751, 11, 309, 311, 611, 1596, 6179, 13], "temperature": 0.0, "avg_logprob": -0.20974638064702353, "compression_ratio": 1.4919354838709677, "no_speech_prob": 0.0034514565486460924}, {"id": 282, "seek": 126936, "start": 1269.36, "end": 1276.1999999999998, "text": " We will not have time to dive into this, but just know that it is much more complicated", "tokens": [492, 486, 406, 362, 565, 281, 9192, 666, 341, 11, 457, 445, 458, 300, 309, 307, 709, 544, 6179], "temperature": 0.0, "avg_logprob": -0.14140606770473244, "compression_ratio": 1.668, "no_speech_prob": 0.0025590064469724894}, {"id": 283, "seek": 126936, "start": 1276.1999999999998, "end": 1279.84, "text": " than multi-producer single consumer version.", "tokens": [813, 4825, 12, 14314, 1776, 2167, 9711, 3037, 13], "temperature": 0.0, "avg_logprob": -0.14140606770473244, "compression_ratio": 1.668, "no_speech_prob": 0.0025590064469724894}, {"id": 284, "seek": 126936, "start": 1279.84, "end": 1288.08, "text": " Although I know a couple of other queues, unbounded log-based and bounded lock free.", "tokens": [5780, 286, 458, 257, 1916, 295, 661, 631, 1247, 11, 517, 18767, 292, 3565, 12, 6032, 293, 37498, 4017, 1737, 13], "temperature": 0.0, "avg_logprob": -0.14140606770473244, "compression_ratio": 1.668, "no_speech_prob": 0.0025590064469724894}, {"id": 285, "seek": 126936, "start": 1288.08, "end": 1292.4399999999998, "text": " I want my final queue to be exactly unbounded, meaning not limited in size.", "tokens": [286, 528, 452, 2572, 18639, 281, 312, 2293, 517, 18767, 292, 11, 3620, 406, 5567, 294, 2744, 13], "temperature": 0.0, "avg_logprob": -0.14140606770473244, "compression_ratio": 1.668, "no_speech_prob": 0.0025590064469724894}, {"id": 286, "seek": 126936, "start": 1292.4399999999998, "end": 1295.32, "text": " So I don't want any limits inside the scheduler.", "tokens": [407, 286, 500, 380, 528, 604, 10406, 1854, 264, 12000, 260, 13], "temperature": 0.0, "avg_logprob": -0.14140606770473244, "compression_ratio": 1.668, "no_speech_prob": 0.0025590064469724894}, {"id": 287, "seek": 126936, "start": 1295.32, "end": 1298.76, "text": " You can add them on top, but I don't want them to be inside the scheduler.", "tokens": [509, 393, 909, 552, 322, 1192, 11, 457, 286, 500, 380, 528, 552, 281, 312, 1854, 264, 12000, 260, 13], "temperature": 0.0, "avg_logprob": -0.14140606770473244, "compression_ratio": 1.668, "no_speech_prob": 0.0025590064469724894}, {"id": 288, "seek": 129876, "start": 1298.76, "end": 1307.32, "text": " I don't want it to be limited by anything like queue size.", "tokens": [286, 500, 380, 528, 309, 281, 312, 5567, 538, 1340, 411, 18639, 2744, 13], "temperature": 0.0, "avg_logprob": -0.18328890957675137, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.0008498732349835336}, {"id": 289, "seek": 129876, "start": 1307.32, "end": 1310.2, "text": " So let's see what we can do with those two queues.", "tokens": [407, 718, 311, 536, 437, 321, 393, 360, 365, 729, 732, 631, 1247, 13], "temperature": 0.0, "avg_logprob": -0.18328890957675137, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.0008498732349835336}, {"id": 290, "seek": 129876, "start": 1310.2, "end": 1315.16, "text": " The bounded lock free version, bounded lock free queue is simple.", "tokens": [440, 37498, 4017, 1737, 3037, 11, 37498, 4017, 1737, 18639, 307, 2199, 13], "temperature": 0.0, "avg_logprob": -0.18328890957675137, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.0008498732349835336}, {"id": 291, "seek": 129876, "start": 1315.16, "end": 1321.36, "text": " It's just a cyclic rate, except that the read and write index will make atomic variables.", "tokens": [467, 311, 445, 257, 38154, 1050, 3314, 11, 3993, 300, 264, 1401, 293, 2464, 8186, 486, 652, 22275, 9102, 13], "temperature": 0.0, "avg_logprob": -0.18328890957675137, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.0008498732349835336}, {"id": 292, "seek": 129876, "start": 1321.36, "end": 1327.0, "text": " So in pushing, the only thing changes compared to normal cyclic buffer is that you increment", "tokens": [407, 294, 7380, 11, 264, 787, 551, 2962, 5347, 281, 2710, 38154, 1050, 21762, 307, 300, 291, 26200], "temperature": 0.0, "avg_logprob": -0.18328890957675137, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.0008498732349835336}, {"id": 293, "seek": 132700, "start": 1327.0, "end": 1331.72, "text": " the write index atomic increment and that's it.", "tokens": [264, 2464, 8186, 22275, 26200, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.22135046254033627, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010310676880180836}, {"id": 294, "seek": 132700, "start": 1331.72, "end": 1335.12, "text": " The popping is just a little bit more complicated.", "tokens": [440, 18374, 307, 445, 257, 707, 857, 544, 6179, 13], "temperature": 0.0, "avg_logprob": -0.22135046254033627, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010310676880180836}, {"id": 295, "seek": 132700, "start": 1335.12, "end": 1339.16, "text": " We have to retry it sometimes because there will be multiple consumers.", "tokens": [492, 362, 281, 1533, 627, 309, 2171, 570, 456, 486, 312, 3866, 11883, 13], "temperature": 0.0, "avg_logprob": -0.22135046254033627, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010310676880180836}, {"id": 296, "seek": 132700, "start": 1339.16, "end": 1342.16, "text": " They will compete for the same element sometimes.", "tokens": [814, 486, 11831, 337, 264, 912, 4478, 2171, 13], "temperature": 0.0, "avg_logprob": -0.22135046254033627, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010310676880180836}, {"id": 297, "seek": 132700, "start": 1342.16, "end": 1347.04, "text": " So atomic compare exchange will eventually fail and we will have to retry, but it's still", "tokens": [407, 22275, 6794, 7742, 486, 4728, 3061, 293, 321, 486, 362, 281, 1533, 627, 11, 457, 309, 311, 920], "temperature": 0.0, "avg_logprob": -0.22135046254033627, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010310676880180836}, {"id": 298, "seek": 132700, "start": 1347.04, "end": 1349.44, "text": " quite simple.", "tokens": [1596, 2199, 13], "temperature": 0.0, "avg_logprob": -0.22135046254033627, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010310676880180836}, {"id": 299, "seek": 132700, "start": 1349.44, "end": 1354.12, "text": " And the unbounded lock queue is just trivial.", "tokens": [400, 264, 517, 18767, 292, 4017, 18639, 307, 445, 26703, 13], "temperature": 0.0, "avg_logprob": -0.22135046254033627, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010310676880180836}, {"id": 300, "seek": 135412, "start": 1354.12, "end": 1359.3999999999999, "text": " So it's a mutex and it's a list and we take mutex on every operation.", "tokens": [407, 309, 311, 257, 24523, 87, 293, 309, 311, 257, 1329, 293, 321, 747, 24523, 87, 322, 633, 6916, 13], "temperature": 0.0, "avg_logprob": -0.15033397487565583, "compression_ratio": 1.696078431372549, "no_speech_prob": 0.0022758422419428825}, {"id": 301, "seek": 135412, "start": 1359.3999999999999, "end": 1363.76, "text": " Then it becomes lock based, but it's unbounded.", "tokens": [1396, 309, 3643, 4017, 2361, 11, 457, 309, 311, 517, 18767, 292, 13], "temperature": 0.0, "avg_logprob": -0.15033397487565583, "compression_ratio": 1.696078431372549, "no_speech_prob": 0.0022758422419428825}, {"id": 302, "seek": 135412, "start": 1363.76, "end": 1368.9599999999998, "text": " So what we can do with the ready queue, what I had was the craziest idea.", "tokens": [407, 437, 321, 393, 360, 365, 264, 1919, 18639, 11, 437, 286, 632, 390, 264, 46339, 1558, 13], "temperature": 0.0, "avg_logprob": -0.15033397487565583, "compression_ratio": 1.696078431372549, "no_speech_prob": 0.0022758422419428825}, {"id": 303, "seek": 135412, "start": 1368.9599999999998, "end": 1376.3999999999999, "text": " The thing is, our enemy is not the mutex itself, it's the contention on the mutex.", "tokens": [440, 551, 307, 11, 527, 5945, 307, 406, 264, 24523, 87, 2564, 11, 309, 311, 264, 660, 1251, 322, 264, 24523, 87, 13], "temperature": 0.0, "avg_logprob": -0.15033397487565583, "compression_ratio": 1.696078431372549, "no_speech_prob": 0.0022758422419428825}, {"id": 304, "seek": 135412, "start": 1376.3999999999999, "end": 1381.12, "text": " So we could try to reduce the contention instead of deleting the mutex.", "tokens": [407, 321, 727, 853, 281, 5407, 264, 660, 1251, 2602, 295, 48946, 264, 24523, 87, 13], "temperature": 0.0, "avg_logprob": -0.15033397487565583, "compression_ratio": 1.696078431372549, "no_speech_prob": 0.0022758422419428825}, {"id": 305, "seek": 138112, "start": 1381.12, "end": 1386.76, "text": " We could skip it, but somehow maybe not lock it so often.", "tokens": [492, 727, 10023, 309, 11, 457, 6063, 1310, 406, 4017, 309, 370, 2049, 13], "temperature": 0.0, "avg_logprob": -0.17461555654352362, "compression_ratio": 1.7584269662921348, "no_speech_prob": 0.001623774180188775}, {"id": 306, "seek": 138112, "start": 1386.76, "end": 1391.32, "text": " Let's combine those two approaches together.", "tokens": [961, 311, 10432, 729, 732, 11587, 1214, 13], "temperature": 0.0, "avg_logprob": -0.17461555654352362, "compression_ratio": 1.7584269662921348, "no_speech_prob": 0.001623774180188775}, {"id": 307, "seek": 138112, "start": 1391.32, "end": 1399.1599999999999, "text": " Let's take the bounded lock free queue and make unbounded lock based queue of those lock", "tokens": [961, 311, 747, 264, 37498, 4017, 1737, 18639, 293, 652, 517, 18767, 292, 4017, 2361, 18639, 295, 729, 4017], "temperature": 0.0, "avg_logprob": -0.17461555654352362, "compression_ratio": 1.7584269662921348, "no_speech_prob": 0.001623774180188775}, {"id": 308, "seek": 138112, "start": 1399.1599999999999, "end": 1401.1599999999999, "text": " free sub-queues.", "tokens": [1737, 1422, 12, 1077, 1247, 13], "temperature": 0.0, "avg_logprob": -0.17461555654352362, "compression_ratio": 1.7584269662921348, "no_speech_prob": 0.001623774180188775}, {"id": 309, "seek": 138112, "start": 1401.1599999999999, "end": 1407.76, "text": " So it will be like a stdq, but the blocks are lock free and the big queue of those blocks", "tokens": [407, 309, 486, 312, 411, 257, 342, 67, 80, 11, 457, 264, 8474, 366, 4017, 1737, 293, 264, 955, 18639, 295, 729, 8474], "temperature": 0.0, "avg_logprob": -0.17461555654352362, "compression_ratio": 1.7584269662921348, "no_speech_prob": 0.001623774180188775}, {"id": 310, "seek": 138112, "start": 1407.76, "end": 1409.9599999999998, "text": " is lock based.", "tokens": [307, 4017, 2361, 13], "temperature": 0.0, "avg_logprob": -0.17461555654352362, "compression_ratio": 1.7584269662921348, "no_speech_prob": 0.001623774180188775}, {"id": 311, "seek": 140996, "start": 1409.96, "end": 1417.76, "text": " And how producer works, it will push new items to the latest block in a lock free way.", "tokens": [400, 577, 12314, 1985, 11, 309, 486, 2944, 777, 4754, 281, 264, 6792, 3461, 294, 257, 4017, 1737, 636, 13], "temperature": 0.0, "avg_logprob": -0.1652342423148777, "compression_ratio": 2.014851485148515, "no_speech_prob": 0.0022991946898400784}, {"id": 312, "seek": 140996, "start": 1417.76, "end": 1422.56, "text": " When the block becomes full, it takes mutex, appends a new block, fills it in a lock free", "tokens": [1133, 264, 3461, 3643, 1577, 11, 309, 2516, 24523, 87, 11, 724, 2581, 257, 777, 3461, 11, 22498, 309, 294, 257, 4017, 1737], "temperature": 0.0, "avg_logprob": -0.1652342423148777, "compression_ratio": 2.014851485148515, "no_speech_prob": 0.0022991946898400784}, {"id": 313, "seek": 140996, "start": 1422.56, "end": 1424.24, "text": " way and so on.", "tokens": [636, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.1652342423148777, "compression_ratio": 2.014851485148515, "no_speech_prob": 0.0022991946898400784}, {"id": 314, "seek": 140996, "start": 1424.24, "end": 1429.3600000000001, "text": " And the consumers, they do their other thing vice versa, so they consume the first block", "tokens": [400, 264, 11883, 11, 436, 360, 641, 661, 551, 11964, 25650, 11, 370, 436, 14732, 264, 700, 3461], "temperature": 0.0, "avg_logprob": -0.1652342423148777, "compression_ratio": 2.014851485148515, "no_speech_prob": 0.0022991946898400784}, {"id": 315, "seek": 140996, "start": 1429.3600000000001, "end": 1431.08, "text": " in a lock free way.", "tokens": [294, 257, 4017, 1737, 636, 13], "temperature": 0.0, "avg_logprob": -0.1652342423148777, "compression_ratio": 2.014851485148515, "no_speech_prob": 0.0022991946898400784}, {"id": 316, "seek": 140996, "start": 1431.08, "end": 1435.3600000000001, "text": " When it becomes empty, they take mutex, switch to the next block, consume it in a lock free", "tokens": [1133, 309, 3643, 6707, 11, 436, 747, 24523, 87, 11, 3679, 281, 264, 958, 3461, 11, 14732, 309, 294, 257, 4017, 1737], "temperature": 0.0, "avg_logprob": -0.1652342423148777, "compression_ratio": 2.014851485148515, "no_speech_prob": 0.0022991946898400784}, {"id": 317, "seek": 140996, "start": 1435.3600000000001, "end": 1437.44, "text": " way and so on.", "tokens": [636, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.1652342423148777, "compression_ratio": 2.014851485148515, "no_speech_prob": 0.0022991946898400784}, {"id": 318, "seek": 143744, "start": 1437.44, "end": 1442.92, "text": " To see the benefit, imagine like sub-queue size, this block size, there's not four like", "tokens": [1407, 536, 264, 5121, 11, 3811, 411, 1422, 12, 1077, 622, 2744, 11, 341, 3461, 2744, 11, 456, 311, 406, 1451, 411], "temperature": 0.0, "avg_logprob": -0.1803909750545726, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.0012209664564579725}, {"id": 319, "seek": 143744, "start": 1442.92, "end": 1445.64, "text": " on the slide, but it's 10,000.", "tokens": [322, 264, 4137, 11, 457, 309, 311, 1266, 11, 1360, 13], "temperature": 0.0, "avg_logprob": -0.1803909750545726, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.0012209664564579725}, {"id": 320, "seek": 143744, "start": 1445.64, "end": 1454.3200000000002, "text": " What happens then is we will take mutex lock not on IV operation, but once per 10,000 operations.", "tokens": [708, 2314, 550, 307, 321, 486, 747, 24523, 87, 4017, 406, 322, 15967, 6916, 11, 457, 1564, 680, 1266, 11, 1360, 7705, 13], "temperature": 0.0, "avg_logprob": -0.1803909750545726, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.0012209664564579725}, {"id": 321, "seek": 143744, "start": 1454.3200000000002, "end": 1459.4, "text": " Mutex is still here, but it's locked so rarely that its cost is neglectable.", "tokens": [376, 1169, 87, 307, 920, 510, 11, 457, 309, 311, 9376, 370, 13752, 300, 1080, 2063, 307, 17745, 712, 13], "temperature": 0.0, "avg_logprob": -0.1803909750545726, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.0012209664564579725}, {"id": 322, "seek": 143744, "start": 1459.4, "end": 1464.8400000000001, "text": " You will not see this mutex lock in any flame graphs anymore.", "tokens": [509, 486, 406, 536, 341, 24523, 87, 4017, 294, 604, 13287, 24877, 3602, 13], "temperature": 0.0, "avg_logprob": -0.1803909750545726, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.0012209664564579725}, {"id": 323, "seek": 146484, "start": 1464.84, "end": 1471.8799999999999, "text": " The only problem with this is that the consumers will need an explicit state, because if consumer", "tokens": [440, 787, 1154, 365, 341, 307, 300, 264, 11883, 486, 643, 364, 13691, 1785, 11, 570, 498, 9711], "temperature": 0.0, "avg_logprob": -0.13889392884839483, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.002780372742563486}, {"id": 324, "seek": 146484, "start": 1471.8799999999999, "end": 1477.12, "text": " doesn't know which is the first block, in this queue of blocks, it will have to locate", "tokens": [1177, 380, 458, 597, 307, 264, 700, 3461, 11, 294, 341, 18639, 295, 8474, 11, 309, 486, 362, 281, 22370], "temperature": 0.0, "avg_logprob": -0.13889392884839483, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.002780372742563486}, {"id": 325, "seek": 146484, "start": 1477.12, "end": 1478.12, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.13889392884839483, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.002780372742563486}, {"id": 326, "seek": 146484, "start": 1478.12, "end": 1484.76, "text": " The queue of blocks, it's protected by a mutex, so if consumers don't have a state, if they", "tokens": [440, 18639, 295, 8474, 11, 309, 311, 10594, 538, 257, 24523, 87, 11, 370, 498, 11883, 500, 380, 362, 257, 1785, 11, 498, 436], "temperature": 0.0, "avg_logprob": -0.13889392884839483, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.002780372742563486}, {"id": 327, "seek": 146484, "start": 1484.76, "end": 1490.52, "text": " don't reference the first block having items, then on every pop, they would have to find", "tokens": [500, 380, 6408, 264, 700, 3461, 1419, 4754, 11, 550, 322, 633, 1665, 11, 436, 576, 362, 281, 915], "temperature": 0.0, "avg_logprob": -0.13889392884839483, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.002780372742563486}, {"id": 328, "seek": 146484, "start": 1490.52, "end": 1494.52, "text": " it, keeping the mutex, and that would mean mutex lock on every pop, if this is exactly", "tokens": [309, 11, 5145, 264, 24523, 87, 11, 293, 300, 576, 914, 24523, 87, 4017, 322, 633, 1665, 11, 498, 341, 307, 2293], "temperature": 0.0, "avg_logprob": -0.13889392884839483, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.002780372742563486}, {"id": 329, "seek": 149452, "start": 1494.52, "end": 1497.4, "text": " what we wanted to avoid.", "tokens": [437, 321, 1415, 281, 5042, 13], "temperature": 0.0, "avg_logprob": -0.21203731355212985, "compression_ratio": 1.7172995780590716, "no_speech_prob": 0.0003781383275054395}, {"id": 330, "seek": 149452, "start": 1497.4, "end": 1502.04, "text": " Consumers need to register themselves, and then they can do the popping.", "tokens": [6923, 449, 433, 643, 281, 7280, 2969, 11, 293, 550, 436, 393, 360, 264, 18374, 13], "temperature": 0.0, "avg_logprob": -0.21203731355212985, "compression_ratio": 1.7172995780590716, "no_speech_prob": 0.0003781383275054395}, {"id": 331, "seek": 149452, "start": 1502.04, "end": 1507.24, "text": " This is not a problem for a task scheduler itself, because it has fixed set of worker", "tokens": [639, 307, 406, 257, 1154, 337, 257, 5633, 12000, 260, 2564, 11, 570, 309, 575, 6806, 992, 295, 11346], "temperature": 0.0, "avg_logprob": -0.21203731355212985, "compression_ratio": 1.7172995780590716, "no_speech_prob": 0.0003781383275054395}, {"id": 332, "seek": 149452, "start": 1507.24, "end": 1510.24, "text": " threads which you specify at creation.", "tokens": [19314, 597, 291, 16500, 412, 8016, 13], "temperature": 0.0, "avg_logprob": -0.21203731355212985, "compression_ratio": 1.7172995780590716, "no_speech_prob": 0.0003781383275054395}, {"id": 333, "seek": 149452, "start": 1510.24, "end": 1514.28, "text": " They can register themselves as consumers at start and leave just fine with it, so it's", "tokens": [814, 393, 7280, 2969, 382, 11883, 412, 722, 293, 1856, 445, 2489, 365, 309, 11, 370, 309, 311], "temperature": 0.0, "avg_logprob": -0.21203731355212985, "compression_ratio": 1.7172995780590716, "no_speech_prob": 0.0003781383275054395}, {"id": 334, "seek": 149452, "start": 1514.28, "end": 1520.12, "text": " just a problem for generic usage of this type of queue, but for task scheduler, it is just", "tokens": [445, 257, 1154, 337, 19577, 14924, 295, 341, 2010, 295, 18639, 11, 457, 337, 5633, 12000, 260, 11, 309, 307, 445], "temperature": 0.0, "avg_logprob": -0.21203731355212985, "compression_ratio": 1.7172995780590716, "no_speech_prob": 0.0003781383275054395}, {"id": 335, "seek": 149452, "start": 1520.12, "end": 1522.24, "text": " fine.", "tokens": [2489, 13], "temperature": 0.0, "avg_logprob": -0.21203731355212985, "compression_ratio": 1.7172995780590716, "no_speech_prob": 0.0003781383275054395}, {"id": 336, "seek": 152224, "start": 1522.24, "end": 1527.72, "text": " Let's examine the visual example again.", "tokens": [961, 311, 17496, 264, 5056, 1365, 797, 13], "temperature": 0.0, "avg_logprob": -0.22665672302246093, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.0013353163376450539}, {"id": 337, "seek": 152224, "start": 1527.72, "end": 1534.6, "text": " Imagine like we have this queue, it's empty, just single block, one producer, two consumers.", "tokens": [11739, 411, 321, 362, 341, 18639, 11, 309, 311, 6707, 11, 445, 2167, 3461, 11, 472, 12314, 11, 732, 11883, 13], "temperature": 0.0, "avg_logprob": -0.22665672302246093, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.0013353163376450539}, {"id": 338, "seek": 152224, "start": 1534.6, "end": 1539.04, "text": " Producer adds three items in a lock-free way.", "tokens": [33034, 10860, 1045, 4754, 294, 257, 4017, 12, 10792, 636, 13], "temperature": 0.0, "avg_logprob": -0.22665672302246093, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.0013353163376450539}, {"id": 339, "seek": 152224, "start": 1539.04, "end": 1544.32, "text": " Everything is lock-free so far, one consumer consumes one item, lock-free.", "tokens": [5471, 307, 4017, 12, 10792, 370, 1400, 11, 472, 9711, 48823, 472, 3174, 11, 4017, 12, 10792, 13], "temperature": 0.0, "avg_logprob": -0.22665672302246093, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.0013353163376450539}, {"id": 340, "seek": 152224, "start": 1544.32, "end": 1548.1200000000001, "text": " Now producer adds another item, lock-free.", "tokens": [823, 12314, 10860, 1071, 3174, 11, 4017, 12, 10792, 13], "temperature": 0.0, "avg_logprob": -0.22665672302246093, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.0013353163376450539}, {"id": 341, "seek": 154812, "start": 1548.12, "end": 1554.6399999999999, "text": " It sees that the block became full, so we need to append a new block, we take mutex,", "tokens": [467, 8194, 300, 264, 3461, 3062, 1577, 11, 370, 321, 643, 281, 34116, 257, 777, 3461, 11, 321, 747, 24523, 87, 11], "temperature": 0.0, "avg_logprob": -0.1374586700299464, "compression_ratio": 1.9902912621359223, "no_speech_prob": 0.0034501473419368267}, {"id": 342, "seek": 154812, "start": 1554.6399999999999, "end": 1561.1999999999998, "text": " switch to the next, append a new block, switch to the next block, release the mutex, and", "tokens": [3679, 281, 264, 958, 11, 34116, 257, 777, 3461, 11, 3679, 281, 264, 958, 3461, 11, 4374, 264, 24523, 87, 11, 293], "temperature": 0.0, "avg_logprob": -0.1374586700299464, "compression_ratio": 1.9902912621359223, "no_speech_prob": 0.0034501473419368267}, {"id": 343, "seek": 154812, "start": 1561.1999999999998, "end": 1564.56, "text": " add three more items in a lock-free way.", "tokens": [909, 1045, 544, 4754, 294, 257, 4017, 12, 10792, 636, 13], "temperature": 0.0, "avg_logprob": -0.1374586700299464, "compression_ratio": 1.9902912621359223, "no_speech_prob": 0.0034501473419368267}, {"id": 344, "seek": 154812, "start": 1564.56, "end": 1570.9599999999998, "text": " Our consumers will work, they will finish consumption of the first block, consumer A will see that", "tokens": [2621, 11883, 486, 589, 11, 436, 486, 2413, 12126, 295, 264, 700, 3461, 11, 9711, 316, 486, 536, 300], "temperature": 0.0, "avg_logprob": -0.1374586700299464, "compression_ratio": 1.9902912621359223, "no_speech_prob": 0.0034501473419368267}, {"id": 345, "seek": 154812, "start": 1570.9599999999998, "end": 1577.84, "text": " the block is empty, so it takes mutex, switches to next block, releases the mutex, and continues", "tokens": [264, 3461, 307, 6707, 11, 370, 309, 2516, 24523, 87, 11, 19458, 281, 958, 3461, 11, 16952, 264, 24523, 87, 11, 293, 6515], "temperature": 0.0, "avg_logprob": -0.1374586700299464, "compression_ratio": 1.9902912621359223, "no_speech_prob": 0.0034501473419368267}, {"id": 346, "seek": 157784, "start": 1577.84, "end": 1580.0, "text": " consumption in a lock-free way.", "tokens": [12126, 294, 257, 4017, 12, 10792, 636, 13], "temperature": 0.0, "avg_logprob": -0.16254856626866226, "compression_ratio": 1.7049808429118773, "no_speech_prob": 0.0013959568459540606}, {"id": 347, "seek": 157784, "start": 1580.0, "end": 1584.1999999999998, "text": " So we take mutex only when we switch from block to block.", "tokens": [407, 321, 747, 24523, 87, 787, 562, 321, 3679, 490, 3461, 281, 3461, 13], "temperature": 0.0, "avg_logprob": -0.16254856626866226, "compression_ratio": 1.7049808429118773, "no_speech_prob": 0.0013959568459540606}, {"id": 348, "seek": 157784, "start": 1584.1999999999998, "end": 1589.32, "text": " And the other consumer, when we will try to consume something from it, it will see immediately", "tokens": [400, 264, 661, 9711, 11, 562, 321, 486, 853, 281, 14732, 746, 490, 309, 11, 309, 486, 536, 4258], "temperature": 0.0, "avg_logprob": -0.16254856626866226, "compression_ratio": 1.7049808429118773, "no_speech_prob": 0.0013959568459540606}, {"id": 349, "seek": 157784, "start": 1589.32, "end": 1594.12, "text": " that its current block is empty, because those blocks, they are, as you remember, lock-free", "tokens": [300, 1080, 2190, 3461, 307, 6707, 11, 570, 729, 8474, 11, 436, 366, 11, 382, 291, 1604, 11, 4017, 12, 10792], "temperature": 0.0, "avg_logprob": -0.16254856626866226, "compression_ratio": 1.7049808429118773, "no_speech_prob": 0.0013959568459540606}, {"id": 350, "seek": 157784, "start": 1594.12, "end": 1600.04, "text": " bounded queues, there are read and write index, if we see that the read index of this block", "tokens": [37498, 631, 1247, 11, 456, 366, 1401, 293, 2464, 8186, 11, 498, 321, 536, 300, 264, 1401, 8186, 295, 341, 3461], "temperature": 0.0, "avg_logprob": -0.16254856626866226, "compression_ratio": 1.7049808429118773, "no_speech_prob": 0.0013959568459540606}, {"id": 351, "seek": 157784, "start": 1600.04, "end": 1604.6799999999998, "text": " equals its size, it means it's empty, so we don't even need to full scan it.", "tokens": [6915, 1080, 2744, 11, 309, 1355, 309, 311, 6707, 11, 370, 321, 500, 380, 754, 643, 281, 1577, 11049, 309, 13], "temperature": 0.0, "avg_logprob": -0.16254856626866226, "compression_ratio": 1.7049808429118773, "no_speech_prob": 0.0013959568459540606}, {"id": 352, "seek": 160468, "start": 1604.68, "end": 1611.92, "text": " Anyway, consumer B will then lock mutex, switch to next block, release the mutex, and continue", "tokens": [5684, 11, 9711, 363, 486, 550, 4017, 24523, 87, 11, 3679, 281, 958, 3461, 11, 4374, 264, 24523, 87, 11, 293, 2354], "temperature": 0.0, "avg_logprob": -0.15619088233785428, "compression_ratio": 1.6886792452830188, "no_speech_prob": 0.0028405352495610714}, {"id": 353, "seek": 160468, "start": 1611.92, "end": 1614.0, "text": " the consumption.", "tokens": [264, 12126, 13], "temperature": 0.0, "avg_logprob": -0.15619088233785428, "compression_ratio": 1.6886792452830188, "no_speech_prob": 0.0028405352495610714}, {"id": 354, "seek": 160468, "start": 1614.0, "end": 1618.5600000000002, "text": " And the old blocks, the completely consumed ones, can be discarded.", "tokens": [400, 264, 1331, 8474, 11, 264, 2584, 21226, 2306, 11, 393, 312, 45469, 13], "temperature": 0.0, "avg_logprob": -0.15619088233785428, "compression_ratio": 1.6886792452830188, "no_speech_prob": 0.0028405352495610714}, {"id": 355, "seek": 160468, "start": 1618.5600000000002, "end": 1623.5600000000002, "text": " You can free them, you can reuse them, like have a pool of those blocks, and append them", "tokens": [509, 393, 1737, 552, 11, 291, 393, 26225, 552, 11, 411, 362, 257, 7005, 295, 729, 8474, 11, 293, 34116, 552], "temperature": 0.0, "avg_logprob": -0.15619088233785428, "compression_ratio": 1.6886792452830188, "no_speech_prob": 0.0028405352495610714}, {"id": 356, "seek": 160468, "start": 1623.5600000000002, "end": 1629.6000000000001, "text": " to beginning again, if you want to, like, it's not cheap to allocate blocks having 10,000", "tokens": [281, 2863, 797, 11, 498, 291, 528, 281, 11, 411, 11, 309, 311, 406, 7084, 281, 35713, 8474, 1419, 1266, 11, 1360], "temperature": 0.0, "avg_logprob": -0.15619088233785428, "compression_ratio": 1.6886792452830188, "no_speech_prob": 0.0028405352495610714}, {"id": 357, "seek": 162960, "start": 1629.6, "end": 1634.9199999999998, "text": " items in them, so you might want to pull them, to have a pool of them.", "tokens": [4754, 294, 552, 11, 370, 291, 1062, 528, 281, 2235, 552, 11, 281, 362, 257, 7005, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.2521296310424805, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0020515196956694126}, {"id": 358, "seek": 162960, "start": 1634.9199999999998, "end": 1640.08, "text": " About the benchmarks, we will see in the end, again, as I said, with everything combined.", "tokens": [7769, 264, 43751, 11, 321, 486, 536, 294, 264, 917, 11, 797, 11, 382, 286, 848, 11, 365, 1203, 9354, 13], "temperature": 0.0, "avg_logprob": -0.2521296310424805, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0020515196956694126}, {"id": 359, "seek": 162960, "start": 1640.08, "end": 1646.56, "text": " And our progress so far is that we saw test-calular parts, those queues, and now we can have a", "tokens": [400, 527, 4205, 370, 1400, 307, 300, 321, 1866, 1500, 12, 9895, 1040, 3166, 11, 729, 631, 1247, 11, 293, 586, 321, 393, 362, 257], "temperature": 0.0, "avg_logprob": -0.2521296310424805, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0020515196956694126}, {"id": 360, "seek": 162960, "start": 1646.56, "end": 1648.24, "text": " glimpse of the routines.", "tokens": [25838, 295, 264, 33827, 13], "temperature": 0.0, "avg_logprob": -0.2521296310424805, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0020515196956694126}, {"id": 361, "seek": 162960, "start": 1648.24, "end": 1655.6399999999999, "text": " Unfortunately, we don't have enough time to dive deep into the implementation, but I can", "tokens": [8590, 11, 321, 500, 380, 362, 1547, 565, 281, 9192, 2452, 666, 264, 11420, 11, 457, 286, 393], "temperature": 0.0, "avg_logprob": -0.2521296310424805, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0020515196956694126}, {"id": 362, "seek": 165564, "start": 1655.64, "end": 1660.8000000000002, "text": " show you some usage examples, show the features they have, and for the implementation, you", "tokens": [855, 291, 512, 14924, 5110, 11, 855, 264, 4122, 436, 362, 11, 293, 337, 264, 11420, 11, 291], "temperature": 0.0, "avg_logprob": -0.18157551969800675, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.00035463785752654076}, {"id": 363, "seek": 165564, "start": 1660.8000000000002, "end": 1666.0400000000002, "text": " can look at the source code and ask me questions after the talk.", "tokens": [393, 574, 412, 264, 4009, 3089, 293, 1029, 385, 1651, 934, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.18157551969800675, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.00035463785752654076}, {"id": 364, "seek": 165564, "start": 1666.0400000000002, "end": 1671.2, "text": " To see why do we need coroutines again, and what features we need from the coroutines,", "tokens": [1407, 536, 983, 360, 321, 643, 1181, 346, 1652, 797, 11, 293, 437, 4122, 321, 643, 490, 264, 1181, 346, 1652, 11], "temperature": 0.0, "avg_logprob": -0.18157551969800675, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.00035463785752654076}, {"id": 365, "seek": 165564, "start": 1671.2, "end": 1675.1200000000001, "text": " let's inspect the simplified version of this save games example.", "tokens": [718, 311, 15018, 264, 26335, 3037, 295, 341, 3155, 2813, 1365, 13], "temperature": 0.0, "avg_logprob": -0.18157551969800675, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.00035463785752654076}, {"id": 366, "seek": 165564, "start": 1675.1200000000001, "end": 1677.8000000000002, "text": " This time, we have just two steps.", "tokens": [639, 565, 11, 321, 362, 445, 732, 4439, 13], "temperature": 0.0, "avg_logprob": -0.18157551969800675, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.00035463785752654076}, {"id": 367, "seek": 165564, "start": 1677.8000000000002, "end": 1681.0400000000002, "text": " Start download of a save game block, and then handle the result.", "tokens": [6481, 5484, 295, 257, 3155, 1216, 3461, 11, 293, 550, 4813, 264, 1874, 13], "temperature": 0.0, "avg_logprob": -0.18157551969800675, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.00035463785752654076}, {"id": 368, "seek": 165564, "start": 1681.0400000000002, "end": 1683.68, "text": " This is in just two steps.", "tokens": [639, 307, 294, 445, 732, 4439, 13], "temperature": 0.0, "avg_logprob": -0.18157551969800675, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.00035463785752654076}, {"id": 369, "seek": 168368, "start": 1683.68, "end": 1689.96, "text": " What we know is that while the task is waiting for response from the network, it shouldn't", "tokens": [708, 321, 458, 307, 300, 1339, 264, 5633, 307, 3806, 337, 4134, 490, 264, 3209, 11, 309, 4659, 380], "temperature": 0.0, "avg_logprob": -0.18221092224121094, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.001495199161581695}, {"id": 370, "seek": 168368, "start": 1689.96, "end": 1694.0, "text": " block other tasks, so it should be able to yield.", "tokens": [3461, 661, 9608, 11, 370, 309, 820, 312, 1075, 281, 11257, 13], "temperature": 0.0, "avg_logprob": -0.18221092224121094, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.001495199161581695}, {"id": 371, "seek": 168368, "start": 1694.0, "end": 1696.8400000000001, "text": " It should be able to step away.", "tokens": [467, 820, 312, 1075, 281, 1823, 1314, 13], "temperature": 0.0, "avg_logprob": -0.18221092224121094, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.001495199161581695}, {"id": 372, "seek": 168368, "start": 1696.8400000000001, "end": 1702.3200000000002, "text": " But we also know that we can't, this task, it can't sleep infinitely.", "tokens": [583, 321, 611, 458, 300, 321, 393, 380, 11, 341, 5633, 11, 309, 393, 380, 2817, 36227, 13], "temperature": 0.0, "avg_logprob": -0.18221092224121094, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.001495199161581695}, {"id": 373, "seek": 168368, "start": 1702.3200000000002, "end": 1704.3600000000001, "text": " There should be some sort of timeout.", "tokens": [821, 820, 312, 512, 1333, 295, 565, 346, 13], "temperature": 0.0, "avg_logprob": -0.18221092224121094, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.001495199161581695}, {"id": 374, "seek": 168368, "start": 1704.3600000000001, "end": 1709.2, "text": " Requests can't be executing infinitely, so we need some deadline after which the task", "tokens": [42029, 4409, 393, 380, 312, 32368, 36227, 11, 370, 321, 643, 512, 20615, 934, 597, 264, 5633], "temperature": 0.0, "avg_logprob": -0.18221092224121094, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.001495199161581695}, {"id": 375, "seek": 168368, "start": 1709.2, "end": 1713.04, "text": " would be woken up and will cancel the request.", "tokens": [576, 312, 261, 8406, 493, 293, 486, 10373, 264, 5308, 13], "temperature": 0.0, "avg_logprob": -0.18221092224121094, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.001495199161581695}, {"id": 376, "seek": 171304, "start": 1713.04, "end": 1718.48, "text": " So if the response arrives in time, before the deadline, we have to wake up the task", "tokens": [407, 498, 264, 4134, 20116, 294, 565, 11, 949, 264, 20615, 11, 321, 362, 281, 6634, 493, 264, 5633], "temperature": 0.0, "avg_logprob": -0.1588712615966797, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.0005920546827837825}, {"id": 377, "seek": 171304, "start": 1718.48, "end": 1720.24, "text": " before the deadline.", "tokens": [949, 264, 20615, 13], "temperature": 0.0, "avg_logprob": -0.1588712615966797, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.0005920546827837825}, {"id": 378, "seek": 171304, "start": 1720.24, "end": 1724.44, "text": " There should be some sort of explicit wake up for the task which is right now sleeping", "tokens": [821, 820, 312, 512, 1333, 295, 13691, 6634, 493, 337, 264, 5633, 597, 307, 558, 586, 8296], "temperature": 0.0, "avg_logprob": -0.1588712615966797, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.0005920546827837825}, {"id": 379, "seek": 171304, "start": 1724.44, "end": 1726.52, "text": " in the wait queue, so it's not executing.", "tokens": [294, 264, 1699, 18639, 11, 370, 309, 311, 406, 32368, 13], "temperature": 0.0, "avg_logprob": -0.1588712615966797, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.0005920546827837825}, {"id": 380, "seek": 171304, "start": 1726.52, "end": 1729.56, "text": " How exactly do we wake it up from there?", "tokens": [1012, 2293, 360, 321, 6634, 309, 493, 490, 456, 30], "temperature": 0.0, "avg_logprob": -0.1588712615966797, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.0005920546827837825}, {"id": 381, "seek": 171304, "start": 1729.56, "end": 1730.96, "text": " So we need an explicit wake up.", "tokens": [407, 321, 643, 364, 13691, 6634, 493, 13], "temperature": 0.0, "avg_logprob": -0.1588712615966797, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.0005920546827837825}, {"id": 382, "seek": 171304, "start": 1730.96, "end": 1737.8, "text": " We need yield, deadlines, and wake ups, three main features of those coroutines.", "tokens": [492, 643, 11257, 11, 37548, 11, 293, 6634, 15497, 11, 1045, 2135, 4122, 295, 729, 1181, 346, 1652, 13], "temperature": 0.0, "avg_logprob": -0.1588712615966797, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.0005920546827837825}, {"id": 383, "seek": 171304, "start": 1737.8, "end": 1740.08, "text": " Let's see an example.", "tokens": [961, 311, 536, 364, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1588712615966797, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.0005920546827837825}, {"id": 384, "seek": 171304, "start": 1740.08, "end": 1742.96, "text": " It's almost exactly like it looks in real code.", "tokens": [467, 311, 1920, 2293, 411, 309, 1542, 294, 957, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1588712615966797, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.0005920546827837825}, {"id": 385, "seek": 174296, "start": 1742.96, "end": 1750.04, "text": " Once there will be simplified version of C++, but it's very similar how it looks in reality.", "tokens": [3443, 456, 486, 312, 26335, 3037, 295, 383, 25472, 11, 457, 309, 311, 588, 2531, 577, 309, 1542, 294, 4103, 13], "temperature": 0.0, "avg_logprob": -0.171838553055473, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.0009938778821378946}, {"id": 386, "seek": 174296, "start": 1750.04, "end": 1754.8, "text": " We have a global task scheduler in the process and some HTTP client.", "tokens": [492, 362, 257, 4338, 5633, 12000, 260, 294, 264, 1399, 293, 512, 33283, 6423, 13], "temperature": 0.0, "avg_logprob": -0.171838553055473, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.0009938778821378946}, {"id": 387, "seek": 174296, "start": 1754.8, "end": 1760.52, "text": " And imagine like a request from the client arrives, so we wrap it into a task and give", "tokens": [400, 3811, 411, 257, 5308, 490, 264, 6423, 20116, 11, 370, 321, 7019, 309, 666, 257, 5633, 293, 976], "temperature": 0.0, "avg_logprob": -0.171838553055473, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.0009938778821378946}, {"id": 388, "seek": 174296, "start": 1760.52, "end": 1762.76, "text": " it a callback called download.", "tokens": [309, 257, 818, 3207, 1219, 5484, 13], "temperature": 0.0, "avg_logprob": -0.171838553055473, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.0009938778821378946}, {"id": 389, "seek": 174296, "start": 1762.76, "end": 1768.2, "text": " And we post it into the scheduler, so it will go into this front queue.", "tokens": [400, 321, 2183, 309, 666, 264, 12000, 260, 11, 370, 309, 486, 352, 666, 341, 1868, 18639, 13], "temperature": 0.0, "avg_logprob": -0.171838553055473, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.0009938778821378946}, {"id": 390, "seek": 176820, "start": 1768.2, "end": 1773.68, "text": " The scheduler will execute our callback in one of the worker threads.", "tokens": [440, 12000, 260, 486, 14483, 527, 818, 3207, 294, 472, 295, 264, 11346, 19314, 13], "temperature": 0.0, "avg_logprob": -0.16350695065089635, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006104331696406007}, {"id": 391, "seek": 176820, "start": 1773.68, "end": 1779.2, "text": " This download callback, so what we do here is firstly set what will be the next step.", "tokens": [639, 5484, 818, 3207, 11, 370, 437, 321, 360, 510, 307, 27376, 992, 437, 486, 312, 264, 958, 1823, 13], "temperature": 0.0, "avg_logprob": -0.16350695065089635, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006104331696406007}, {"id": 392, "seek": 176820, "start": 1779.2, "end": 1782.8, "text": " The next step will be handling the result.", "tokens": [440, 958, 1823, 486, 312, 13175, 264, 1874, 13], "temperature": 0.0, "avg_logprob": -0.16350695065089635, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006104331696406007}, {"id": 393, "seek": 176820, "start": 1782.8, "end": 1785.3600000000001, "text": " Then we do the asynchronous HTTP request.", "tokens": [1396, 321, 360, 264, 49174, 33283, 5308, 13], "temperature": 0.0, "avg_logprob": -0.16350695065089635, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006104331696406007}, {"id": 394, "seek": 176820, "start": 1785.3600000000001, "end": 1788.68, "text": " Assume that our HTTP client is able to do this.", "tokens": [6281, 2540, 300, 527, 33283, 6423, 307, 1075, 281, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.16350695065089635, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006104331696406007}, {"id": 395, "seek": 176820, "start": 1788.68, "end": 1793.48, "text": " So we start an asynchronous HTTP request and give it a future callback to execute when", "tokens": [407, 321, 722, 364, 49174, 33283, 5308, 293, 976, 309, 257, 2027, 818, 3207, 281, 14483, 562], "temperature": 0.0, "avg_logprob": -0.16350695065089635, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006104331696406007}, {"id": 396, "seek": 176820, "start": 1793.48, "end": 1798.1200000000001, "text": " the request is done, which we'll call wake up on our task.", "tokens": [264, 5308, 307, 1096, 11, 597, 321, 603, 818, 6634, 493, 322, 527, 5633, 13], "temperature": 0.0, "avg_logprob": -0.16350695065089635, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006104331696406007}, {"id": 397, "seek": 179812, "start": 1798.12, "end": 1801.76, "text": " While this will be explicit wake up when the request is done.", "tokens": [3987, 341, 486, 312, 13691, 6634, 493, 562, 264, 5308, 307, 1096, 13], "temperature": 0.0, "avg_logprob": -0.2348106451201857, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.0006922772154211998}, {"id": 398, "seek": 179812, "start": 1801.76, "end": 1803.08, "text": " And then we start waiting.", "tokens": [400, 550, 321, 722, 3806, 13], "temperature": 0.0, "avg_logprob": -0.2348106451201857, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.0006922772154211998}, {"id": 399, "seek": 179812, "start": 1803.08, "end": 1808.12, "text": " So we post ourselves back into the scheduler with five seconds deadline.", "tokens": [407, 321, 2183, 4175, 646, 666, 264, 12000, 260, 365, 1732, 3949, 20615, 13], "temperature": 0.0, "avg_logprob": -0.2348106451201857, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.0006922772154211998}, {"id": 400, "seek": 179812, "start": 1808.12, "end": 1813.36, "text": " Either the task will wake up in five seconds or it will be woken up explicitly when the", "tokens": [13746, 264, 5633, 486, 6634, 493, 294, 1732, 3949, 420, 309, 486, 312, 261, 8406, 493, 20803, 562, 264], "temperature": 0.0, "avg_logprob": -0.2348106451201857, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.0006922772154211998}, {"id": 401, "seek": 179812, "start": 1813.36, "end": 1814.6799999999998, "text": " request is complete.", "tokens": [5308, 307, 3566, 13], "temperature": 0.0, "avg_logprob": -0.2348106451201857, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.0006922772154211998}, {"id": 402, "seek": 179812, "start": 1814.6799999999998, "end": 1820.12, "text": " This goes into the scheduler, sleeps in the wait queue for some time and eventually our", "tokens": [639, 1709, 666, 264, 12000, 260, 11, 37991, 294, 264, 1699, 18639, 337, 512, 565, 293, 4728, 527], "temperature": 0.0, "avg_logprob": -0.2348106451201857, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.0006922772154211998}, {"id": 403, "seek": 179812, "start": 1820.12, "end": 1823.2399999999998, "text": " callback handle result is executed.", "tokens": [818, 3207, 4813, 1874, 307, 17577, 13], "temperature": 0.0, "avg_logprob": -0.2348106451201857, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.0006922772154211998}, {"id": 404, "seek": 179812, "start": 1823.2399999999998, "end": 1824.6, "text": " We have to check what happened.", "tokens": [492, 362, 281, 1520, 437, 2011, 13], "temperature": 0.0, "avg_logprob": -0.2348106451201857, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.0006922772154211998}, {"id": 405, "seek": 179812, "start": 1824.6, "end": 1826.6, "text": " It could be two reasons.", "tokens": [467, 727, 312, 732, 4112, 13], "temperature": 0.0, "avg_logprob": -0.2348106451201857, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.0006922772154211998}, {"id": 406, "seek": 182660, "start": 1826.6, "end": 1828.4399999999998, "text": " It could be that the task is expired.", "tokens": [467, 727, 312, 300, 264, 5633, 307, 36587, 13], "temperature": 0.0, "avg_logprob": -0.21780084137223724, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0010682501597329974}, {"id": 407, "seek": 182660, "start": 1828.4399999999998, "end": 1832.12, "text": " So five seconds passed and we were woken up by the deadline.", "tokens": [407, 1732, 3949, 4678, 293, 321, 645, 261, 8406, 493, 538, 264, 20615, 13], "temperature": 0.0, "avg_logprob": -0.21780084137223724, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0010682501597329974}, {"id": 408, "seek": 182660, "start": 1832.12, "end": 1835.24, "text": " And we just literally check if it's expired.", "tokens": [400, 321, 445, 3736, 1520, 498, 309, 311, 36587, 13], "temperature": 0.0, "avg_logprob": -0.21780084137223724, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0010682501597329974}, {"id": 409, "seek": 182660, "start": 1835.24, "end": 1840.1999999999998, "text": " If it is sold and we cancel the request and we start waiting for the cancellation to be", "tokens": [759, 309, 307, 3718, 293, 321, 10373, 264, 5308, 293, 321, 722, 3806, 337, 264, 45867, 281, 312], "temperature": 0.0, "avg_logprob": -0.21780084137223724, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0010682501597329974}, {"id": 410, "seek": 182660, "start": 1840.1999999999998, "end": 1845.48, "text": " complete to properly free all the resources and to go back into the scheduler.", "tokens": [3566, 281, 6108, 1737, 439, 264, 3593, 293, 281, 352, 646, 666, 264, 12000, 260, 13], "temperature": 0.0, "avg_logprob": -0.21780084137223724, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0010682501597329974}, {"id": 411, "seek": 182660, "start": 1845.48, "end": 1848.32, "text": " But now we wait for the cancellation.", "tokens": [583, 586, 321, 1699, 337, 264, 45867, 13], "temperature": 0.0, "avg_logprob": -0.21780084137223724, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0010682501597329974}, {"id": 412, "seek": 182660, "start": 1848.32, "end": 1853.6799999999998, "text": " Otherwise, if it's not expired, it means the request is finally complete with some result.", "tokens": [10328, 11, 498, 309, 311, 406, 36587, 11, 309, 1355, 264, 5308, 307, 2721, 3566, 365, 512, 1874, 13], "temperature": 0.0, "avg_logprob": -0.21780084137223724, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0010682501597329974}, {"id": 413, "seek": 182660, "start": 1853.6799999999998, "end": 1855.1599999999999, "text": " It could be success.", "tokens": [467, 727, 312, 2245, 13], "temperature": 0.0, "avg_logprob": -0.21780084137223724, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0010682501597329974}, {"id": 414, "seek": 185516, "start": 1855.16, "end": 1860.3200000000002, "text": " It could be an HTTP error code or it could be our own consolation done on a previous", "tokens": [467, 727, 312, 364, 33283, 6713, 3089, 420, 309, 727, 312, 527, 1065, 16054, 399, 1096, 322, 257, 3894], "temperature": 0.0, "avg_logprob": -0.19674456119537354, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.0023844754323363304}, {"id": 415, "seek": 185516, "start": 1860.3200000000002, "end": 1862.0, "text": " wake up a few lines above.", "tokens": [6634, 493, 257, 1326, 3876, 3673, 13], "temperature": 0.0, "avg_logprob": -0.19674456119537354, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.0023844754323363304}, {"id": 416, "seek": 185516, "start": 1862.0, "end": 1865.5600000000002, "text": " Either way, we just handle it and delete the task.", "tokens": [13746, 636, 11, 321, 445, 4813, 309, 293, 12097, 264, 5633, 13], "temperature": 0.0, "avg_logprob": -0.19674456119537354, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.0023844754323363304}, {"id": 417, "seek": 185516, "start": 1865.5600000000002, "end": 1870.24, "text": " This is literally, this is almost exactly how it looks in the source code.", "tokens": [639, 307, 3736, 11, 341, 307, 1920, 2293, 577, 309, 1542, 294, 264, 4009, 3089, 13], "temperature": 0.0, "avg_logprob": -0.19674456119537354, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.0023844754323363304}, {"id": 418, "seek": 185516, "start": 1870.24, "end": 1876.3200000000002, "text": " There is no spurious wake ups at all, no sleeps and the request has clear state machine with", "tokens": [821, 307, 572, 637, 24274, 6634, 15497, 412, 439, 11, 572, 37991, 293, 264, 5308, 575, 1850, 1785, 3479, 365], "temperature": 0.0, "avg_logprob": -0.19674456119537354, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.0023844754323363304}, {"id": 419, "seek": 185516, "start": 1876.3200000000002, "end": 1879.8400000000001, "text": " every state expressed at the callback.", "tokens": [633, 1785, 12675, 412, 264, 818, 3207, 13], "temperature": 0.0, "avg_logprob": -0.19674456119537354, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.0023844754323363304}, {"id": 420, "seek": 187984, "start": 1879.84, "end": 1886.52, "text": " And what is better, these entire routine stuff, all those wake ups, post deadlines, this is", "tokens": [400, 437, 307, 1101, 11, 613, 2302, 9927, 1507, 11, 439, 729, 6634, 15497, 11, 2183, 37548, 11, 341, 307], "temperature": 0.0, "avg_logprob": -0.20755142861224235, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0025803230237215757}, {"id": 421, "seek": 187984, "start": 1886.52, "end": 1887.76, "text": " all completely lock free.", "tokens": [439, 2584, 4017, 1737, 13], "temperature": 0.0, "avg_logprob": -0.20755142861224235, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0025803230237215757}, {"id": 422, "seek": 187984, "start": 1887.76, "end": 1892.84, "text": " There is no single mutics used to implement this all.", "tokens": [821, 307, 572, 2167, 5839, 1167, 1143, 281, 4445, 341, 439, 13], "temperature": 0.0, "avg_logprob": -0.20755142861224235, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0025803230237215757}, {"id": 423, "seek": 187984, "start": 1892.84, "end": 1897.8, "text": " So this is to get you further interested into looking at the source code and asking questions", "tokens": [407, 341, 307, 281, 483, 291, 3052, 3102, 666, 1237, 412, 264, 4009, 3089, 293, 3365, 1651], "temperature": 0.0, "avg_logprob": -0.20755142861224235, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0025803230237215757}, {"id": 424, "seek": 187984, "start": 1897.8, "end": 1900.56, "text": " afterwards.", "tokens": [10543, 13], "temperature": 0.0, "avg_logprob": -0.20755142861224235, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0025803230237215757}, {"id": 425, "seek": 187984, "start": 1900.56, "end": 1905.56, "text": " This is quite complicated stuff, as you can imagine, especially the implementation.", "tokens": [639, 307, 1596, 6179, 1507, 11, 382, 291, 393, 3811, 11, 2318, 264, 11420, 13], "temperature": 0.0, "avg_logprob": -0.20755142861224235, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0025803230237215757}, {"id": 426, "seek": 187984, "start": 1905.56, "end": 1908.52, "text": " How do we verify such stuff?", "tokens": [1012, 360, 321, 16888, 1270, 1507, 30], "temperature": 0.0, "avg_logprob": -0.20755142861224235, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0025803230237215757}, {"id": 427, "seek": 190852, "start": 1908.52, "end": 1914.4, "text": " Of course, there are unit tests, like literally hundreds and thousands of lines of unit tests.", "tokens": [2720, 1164, 11, 456, 366, 4985, 6921, 11, 411, 3736, 6779, 293, 5383, 295, 3876, 295, 4985, 6921, 13], "temperature": 0.0, "avg_logprob": -0.23106054989796765, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.0011092612985521555}, {"id": 428, "seek": 190852, "start": 1914.4, "end": 1919.84, "text": " But with multi-tried algorithms, the thing is, even if you have 100% code coverage, it", "tokens": [583, 365, 4825, 12, 83, 2428, 14642, 11, 264, 551, 307, 11, 754, 498, 291, 362, 2319, 4, 3089, 9645, 11, 309], "temperature": 0.0, "avg_logprob": -0.23106054989796765, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.0011092612985521555}, {"id": 429, "seek": 190852, "start": 1919.84, "end": 1922.36, "text": " doesn't tell you anything.", "tokens": [1177, 380, 980, 291, 1340, 13], "temperature": 0.0, "avg_logprob": -0.23106054989796765, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.0011092612985521555}, {"id": 430, "seek": 190852, "start": 1922.36, "end": 1928.56, "text": " It's better than, I think, not having 100% coverage, but it's still, there might be bugs", "tokens": [467, 311, 1101, 813, 11, 286, 519, 11, 406, 1419, 2319, 4, 9645, 11, 457, 309, 311, 920, 11, 456, 1062, 312, 15120], "temperature": 0.0, "avg_logprob": -0.23106054989796765, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.0011092612985521555}, {"id": 431, "seek": 190852, "start": 1928.56, "end": 1931.52, "text": " which can stay hidden for literally years.", "tokens": [597, 393, 1754, 7633, 337, 3736, 924, 13], "temperature": 0.0, "avg_logprob": -0.23106054989796765, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.0011092612985521555}, {"id": 432, "seek": 190852, "start": 1931.52, "end": 1936.2, "text": " And you will not find them except when this thing explodes in production.", "tokens": [400, 291, 486, 406, 915, 552, 3993, 562, 341, 551, 42610, 294, 4265, 13], "temperature": 0.0, "avg_logprob": -0.23106054989796765, "compression_ratio": 1.6108949416342413, "no_speech_prob": 0.0011092612985521555}, {"id": 433, "seek": 193620, "start": 1936.2, "end": 1940.0, "text": " There should be a way to at least verify the algorithm, maybe.", "tokens": [821, 820, 312, 257, 636, 281, 412, 1935, 16888, 264, 9284, 11, 1310, 13], "temperature": 0.0, "avg_logprob": -0.2015465265032889, "compression_ratio": 1.6634146341463414, "no_speech_prob": 0.002581698587164283}, {"id": 434, "seek": 193620, "start": 1940.0, "end": 1946.6000000000001, "text": " We can't verify the source code, but we can improve our confidence about the algorithm", "tokens": [492, 393, 380, 16888, 264, 4009, 3089, 11, 457, 321, 393, 3470, 527, 6687, 466, 264, 9284], "temperature": 0.0, "avg_logprob": -0.2015465265032889, "compression_ratio": 1.6634146341463414, "no_speech_prob": 0.002581698587164283}, {"id": 435, "seek": 193620, "start": 1946.6000000000001, "end": 1947.76, "text": " itself.", "tokens": [2564, 13], "temperature": 0.0, "avg_logprob": -0.2015465265032889, "compression_ratio": 1.6634146341463414, "no_speech_prob": 0.002581698587164283}, {"id": 436, "seek": 193620, "start": 1947.76, "end": 1955.32, "text": " And the solution is TLA+, TLA+, stands for temporal logic of actions, and it is a combination", "tokens": [400, 264, 3827, 307, 314, 11435, 46797, 314, 11435, 46797, 7382, 337, 30881, 9952, 295, 5909, 11, 293, 309, 307, 257, 6562], "temperature": 0.0, "avg_logprob": -0.2015465265032889, "compression_ratio": 1.6634146341463414, "no_speech_prob": 0.002581698587164283}, {"id": 437, "seek": 193620, "start": 1955.32, "end": 1958.3600000000001, "text": " of mathematics and temporal logic.", "tokens": [295, 18666, 293, 30881, 9952, 13], "temperature": 0.0, "avg_logprob": -0.2015465265032889, "compression_ratio": 1.6634146341463414, "no_speech_prob": 0.002581698587164283}, {"id": 438, "seek": 193620, "start": 1958.3600000000001, "end": 1962.96, "text": " And it's also a language and runtime of this language.", "tokens": [400, 309, 311, 611, 257, 2856, 293, 34474, 295, 341, 2856, 13], "temperature": 0.0, "avg_logprob": -0.2015465265032889, "compression_ratio": 1.6634146341463414, "no_speech_prob": 0.002581698587164283}, {"id": 439, "seek": 196296, "start": 1962.96, "end": 1968.68, "text": " This language allows you to verify literally any algorithms or systems, like you can verify", "tokens": [639, 2856, 4045, 291, 281, 16888, 3736, 604, 14642, 420, 3652, 11, 411, 291, 393, 16888], "temperature": 0.0, "avg_logprob": -0.23886209164025649, "compression_ratio": 1.7565217391304349, "no_speech_prob": 0.0010172827169299126}, {"id": 440, "seek": 196296, "start": 1968.68, "end": 1977.56, "text": " an algorithm of a queue, like I did, or how your microservices interact, or you can verify", "tokens": [364, 9284, 295, 257, 18639, 11, 411, 286, 630, 11, 420, 577, 428, 15547, 47480, 4648, 11, 420, 291, 393, 16888], "temperature": 0.0, "avg_logprob": -0.23886209164025649, "compression_ratio": 1.7565217391304349, "no_speech_prob": 0.0010172827169299126}, {"id": 441, "seek": 196296, "start": 1977.56, "end": 1979.2, "text": " how you go to a grocery store.", "tokens": [577, 291, 352, 281, 257, 14410, 3531, 13], "temperature": 0.0, "avg_logprob": -0.23886209164025649, "compression_ratio": 1.7565217391304349, "no_speech_prob": 0.0010172827169299126}, {"id": 442, "seek": 196296, "start": 1979.2, "end": 1981.76, "text": " If you can algorithmize it, then you can verify it.", "tokens": [759, 291, 393, 9284, 1125, 309, 11, 550, 291, 393, 16888, 309, 13], "temperature": 0.0, "avg_logprob": -0.23886209164025649, "compression_ratio": 1.7565217391304349, "no_speech_prob": 0.0010172827169299126}, {"id": 443, "seek": 196296, "start": 1981.76, "end": 1982.76, "text": " TLA+.", "tokens": [314, 11435, 45585], "temperature": 0.0, "avg_logprob": -0.23886209164025649, "compression_ratio": 1.7565217391304349, "no_speech_prob": 0.0010172827169299126}, {"id": 444, "seek": 196296, "start": 1982.76, "end": 1986.44, "text": " It's suitable for anything like this.", "tokens": [467, 311, 12873, 337, 1340, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.23886209164025649, "compression_ratio": 1.7565217391304349, "no_speech_prob": 0.0010172827169299126}, {"id": 445, "seek": 196296, "start": 1986.44, "end": 1992.92, "text": " So in this TLA+, language, you write a specification and run the verification, and it will run", "tokens": [407, 294, 341, 314, 11435, 46797, 2856, 11, 291, 2464, 257, 31256, 293, 1190, 264, 30206, 11, 293, 309, 486, 1190], "temperature": 0.0, "avg_logprob": -0.23886209164025649, "compression_ratio": 1.7565217391304349, "no_speech_prob": 0.0010172827169299126}, {"id": 446, "seek": 199292, "start": 1992.92, "end": 1999.4, "text": " and it will split your system, your algorithm, into a set of all the possible states in which", "tokens": [293, 309, 486, 7472, 428, 1185, 11, 428, 9284, 11, 666, 257, 992, 295, 439, 264, 1944, 4368, 294, 597], "temperature": 0.0, "avg_logprob": -0.19504639120662914, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.002897635567933321}, {"id": 447, "seek": 199292, "start": 1999.4, "end": 2001.8400000000001, "text": " this algorithm can be.", "tokens": [341, 9284, 393, 312, 13], "temperature": 0.0, "avg_logprob": -0.19504639120662914, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.002897635567933321}, {"id": 448, "seek": 199292, "start": 2001.8400000000001, "end": 2007.72, "text": " And verify your own invariance in every reachable state of your system.", "tokens": [400, 16888, 428, 1065, 33270, 719, 294, 633, 2524, 712, 1785, 295, 428, 1185, 13], "temperature": 0.0, "avg_logprob": -0.19504639120662914, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.002897635567933321}, {"id": 449, "seek": 199292, "start": 2007.72, "end": 2014.52, "text": " So firstly, you define the algorithm, then you define what means validness for your algorithm,", "tokens": [407, 27376, 11, 291, 6964, 264, 9284, 11, 550, 291, 6964, 437, 1355, 7363, 1287, 337, 428, 9284, 11], "temperature": 0.0, "avg_logprob": -0.19504639120662914, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.002897635567933321}, {"id": 450, "seek": 199292, "start": 2014.52, "end": 2018.0800000000002, "text": " the invariance, and TLA+, we'll verify all them.", "tokens": [264, 33270, 719, 11, 293, 314, 11435, 46797, 321, 603, 16888, 439, 552, 13], "temperature": 0.0, "avg_logprob": -0.19504639120662914, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.002897635567933321}, {"id": 451, "seek": 201808, "start": 2018.08, "end": 2023.4399999999998, "text": " Let's see an example, like I assume you have implemented a queue in any language, and we", "tokens": [961, 311, 536, 364, 1365, 11, 411, 286, 6552, 291, 362, 12270, 257, 18639, 294, 604, 2856, 11, 293, 321], "temperature": 0.0, "avg_logprob": -0.18643639677314347, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0006889200303703547}, {"id": 452, "seek": 201808, "start": 2023.4399999999998, "end": 2026.04, "text": " want to verify the algorithm of this queue.", "tokens": [528, 281, 16888, 264, 9284, 295, 341, 18639, 13], "temperature": 0.0, "avg_logprob": -0.18643639677314347, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0006889200303703547}, {"id": 453, "seek": 201808, "start": 2026.04, "end": 2033.6, "text": " First you have to define what objects exist in your system, what agents you have there.", "tokens": [2386, 291, 362, 281, 6964, 437, 6565, 2514, 294, 428, 1185, 11, 437, 12554, 291, 362, 456, 13], "temperature": 0.0, "avg_logprob": -0.18643639677314347, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0006889200303703547}, {"id": 454, "seek": 201808, "start": 2033.6, "end": 2039.1599999999999, "text": " In my queue, I have just pipe for items, so some sort of storage, and a couple of counters", "tokens": [682, 452, 18639, 11, 286, 362, 445, 11240, 337, 4754, 11, 370, 512, 1333, 295, 6725, 11, 293, 257, 1916, 295, 39338], "temperature": 0.0, "avg_logprob": -0.18643639677314347, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0006889200303703547}, {"id": 455, "seek": 201808, "start": 2039.1599999999999, "end": 2040.6399999999999, "text": " and limits.", "tokens": [293, 10406, 13], "temperature": 0.0, "avg_logprob": -0.18643639677314347, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0006889200303703547}, {"id": 456, "seek": 201808, "start": 2040.6399999999999, "end": 2043.32, "text": " Then you have to define actions.", "tokens": [1396, 291, 362, 281, 6964, 5909, 13], "temperature": 0.0, "avg_logprob": -0.18643639677314347, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0006889200303703547}, {"id": 457, "seek": 204332, "start": 2043.32, "end": 2048.52, "text": " In TLA+, every action is a set of mathematical conditions combined with some mathematical", "tokens": [682, 314, 11435, 46797, 633, 3069, 307, 257, 992, 295, 18894, 4487, 9354, 365, 512, 18894], "temperature": 0.0, "avg_logprob": -0.19910675220275192, "compression_ratio": 1.8623853211009174, "no_speech_prob": 0.0007185389986261725}, {"id": 458, "seek": 204332, "start": 2048.52, "end": 2058.52, "text": " operators, like you have operators and or operator, or list or set operator, or complex", "tokens": [19077, 11, 411, 291, 362, 19077, 293, 420, 12973, 11, 420, 1329, 420, 992, 12973, 11, 420, 3997], "temperature": 0.0, "avg_logprob": -0.19910675220275192, "compression_ratio": 1.8623853211009174, "no_speech_prob": 0.0007185389986261725}, {"id": 459, "seek": 204332, "start": 2058.52, "end": 2063.92, "text": " operators like all items in the set comply with the condition operator, and many more", "tokens": [19077, 411, 439, 4754, 294, 264, 992, 27956, 365, 264, 4188, 12973, 11, 293, 867, 544], "temperature": 0.0, "avg_logprob": -0.19910675220275192, "compression_ratio": 1.8623853211009174, "no_speech_prob": 0.0007185389986261725}, {"id": 460, "seek": 204332, "start": 2063.92, "end": 2066.84, "text": " other operators which can use in your actions.", "tokens": [661, 19077, 597, 393, 764, 294, 428, 5909, 13], "temperature": 0.0, "avg_logprob": -0.19910675220275192, "compression_ratio": 1.8623853211009174, "no_speech_prob": 0.0007185389986261725}, {"id": 461, "seek": 204332, "start": 2066.84, "end": 2072.68, "text": " And the first action is always initialization, where you give initial values to your variables.", "tokens": [400, 264, 700, 3069, 307, 1009, 5883, 2144, 11, 689, 291, 976, 5883, 4190, 281, 428, 9102, 13], "temperature": 0.0, "avg_logprob": -0.19910675220275192, "compression_ratio": 1.8623853211009174, "no_speech_prob": 0.0007185389986261725}, {"id": 462, "seek": 207268, "start": 2072.68, "end": 2077.68, "text": " Here I say that storage pipe is an empty list, and my counters of sent and received items", "tokens": [1692, 286, 584, 300, 6725, 11240, 307, 364, 6707, 1329, 11, 293, 452, 39338, 295, 2279, 293, 4613, 4754], "temperature": 0.0, "avg_logprob": -0.21709348758061728, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.0007707893382757902}, {"id": 463, "seek": 207268, "start": 2077.68, "end": 2079.2, "text": " are zero.", "tokens": [366, 4018, 13], "temperature": 0.0, "avg_logprob": -0.21709348758061728, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.0007707893382757902}, {"id": 464, "seek": 207268, "start": 2079.2, "end": 2087.08, "text": " Then I start defining some actual actions doing stuff, like send or push or insert or", "tokens": [1396, 286, 722, 17827, 512, 3539, 5909, 884, 1507, 11, 411, 2845, 420, 2944, 420, 8969, 420], "temperature": 0.0, "avg_logprob": -0.21709348758061728, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.0007707893382757902}, {"id": 465, "seek": 207268, "start": 2087.08, "end": 2088.08, "text": " whatever.", "tokens": [2035, 13], "temperature": 0.0, "avg_logprob": -0.21709348758061728, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.0007707893382757902}, {"id": 466, "seek": 207268, "start": 2088.08, "end": 2090.08, "text": " And there are ways how to do it.", "tokens": [400, 456, 366, 2098, 577, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.21709348758061728, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.0007707893382757902}, {"id": 467, "seek": 207268, "start": 2090.08, "end": 2095.68, "text": " I'm not aware of any standard ways how to do it properly, so I invented my own.", "tokens": [286, 478, 406, 3650, 295, 604, 3832, 2098, 577, 281, 360, 309, 6108, 11, 370, 286, 14479, 452, 1065, 13], "temperature": 0.0, "avg_logprob": -0.21709348758061728, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.0007707893382757902}, {"id": 468, "seek": 207268, "start": 2095.68, "end": 2099.48, "text": " Firstly, I split my actions into two groups.", "tokens": [20042, 11, 286, 7472, 452, 5909, 666, 732, 3935, 13], "temperature": 0.0, "avg_logprob": -0.21709348758061728, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.0007707893382757902}, {"id": 469, "seek": 209948, "start": 2099.48, "end": 2104.64, "text": " And first group of conditions I define when the action is possible.", "tokens": [400, 700, 1594, 295, 4487, 286, 6964, 562, 264, 3069, 307, 1944, 13], "temperature": 0.0, "avg_logprob": -0.12395880772517277, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002014881232753396}, {"id": 470, "seek": 209948, "start": 2104.64, "end": 2111.6, "text": " So here I say send is possible when queue is not full, and when I still have items to", "tokens": [407, 510, 286, 584, 2845, 307, 1944, 562, 18639, 307, 406, 1577, 11, 293, 562, 286, 920, 362, 4754, 281], "temperature": 0.0, "avg_logprob": -0.12395880772517277, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002014881232753396}, {"id": 471, "seek": 209948, "start": 2111.6, "end": 2114.28, "text": " send, so not everything pushed yet.", "tokens": [2845, 11, 370, 406, 1203, 9152, 1939, 13], "temperature": 0.0, "avg_logprob": -0.12395880772517277, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002014881232753396}, {"id": 472, "seek": 209948, "start": 2114.28, "end": 2120.68, "text": " In the second group, I tell what changes should be done when the first group is true, so when", "tokens": [682, 264, 1150, 1594, 11, 286, 980, 437, 2962, 820, 312, 1096, 562, 264, 700, 1594, 307, 2074, 11, 370, 562], "temperature": 0.0, "avg_logprob": -0.12395880772517277, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002014881232753396}, {"id": 473, "seek": 209948, "start": 2120.68, "end": 2121.8, "text": " the condition is true.", "tokens": [264, 4188, 307, 2074, 13], "temperature": 0.0, "avg_logprob": -0.12395880772517277, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002014881232753396}, {"id": 474, "seek": 209948, "start": 2121.8, "end": 2128.16, "text": " Here I say if the first part is true, then I add a new item to the pipe storage, as items", "tokens": [1692, 286, 584, 498, 264, 700, 644, 307, 2074, 11, 550, 286, 909, 257, 777, 3174, 281, 264, 11240, 6725, 11, 382, 4754], "temperature": 0.0, "avg_logprob": -0.12395880772517277, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002014881232753396}, {"id": 475, "seek": 212816, "start": 2128.16, "end": 2133.3599999999997, "text": " I use numbers, and I increment the number of sent items, of pushed items.", "tokens": [286, 764, 3547, 11, 293, 286, 26200, 264, 1230, 295, 2279, 4754, 11, 295, 9152, 4754, 13], "temperature": 0.0, "avg_logprob": -0.18141672746190485, "compression_ratio": 1.8093220338983051, "no_speech_prob": 0.001110098441131413}, {"id": 476, "seek": 212816, "start": 2133.3599999999997, "end": 2137.64, "text": " The problem is, as you could see, probably there is no really distinction between those", "tokens": [440, 1154, 307, 11, 382, 291, 727, 536, 11, 1391, 456, 307, 572, 534, 16844, 1296, 729], "temperature": 0.0, "avg_logprob": -0.18141672746190485, "compression_ratio": 1.8093220338983051, "no_speech_prob": 0.001110098441131413}, {"id": 477, "seek": 212816, "start": 2137.64, "end": 2138.64, "text": " two groups.", "tokens": [732, 3935, 13], "temperature": 0.0, "avg_logprob": -0.18141672746190485, "compression_ratio": 1.8093220338983051, "no_speech_prob": 0.001110098441131413}, {"id": 478, "seek": 212816, "start": 2138.64, "end": 2145.2, "text": " It's imaginary, and the only distinction is this small single code sign.", "tokens": [467, 311, 26164, 11, 293, 264, 787, 16844, 307, 341, 1359, 2167, 3089, 1465, 13], "temperature": 0.0, "avg_logprob": -0.18141672746190485, "compression_ratio": 1.8093220338983051, "no_speech_prob": 0.001110098441131413}, {"id": 479, "seek": 212816, "start": 2145.2, "end": 2147.3199999999997, "text": " It means next value of the variable.", "tokens": [467, 1355, 958, 2158, 295, 264, 7006, 13], "temperature": 0.0, "avg_logprob": -0.18141672746190485, "compression_ratio": 1.8093220338983051, "no_speech_prob": 0.001110098441131413}, {"id": 480, "seek": 212816, "start": 2147.3199999999997, "end": 2153.2, "text": " The problem is, since here it passes basically math, in math there is no assignment.", "tokens": [440, 1154, 307, 11, 1670, 510, 309, 11335, 1936, 5221, 11, 294, 5221, 456, 307, 572, 15187, 13], "temperature": 0.0, "avg_logprob": -0.18141672746190485, "compression_ratio": 1.8093220338983051, "no_speech_prob": 0.001110098441131413}, {"id": 481, "seek": 212816, "start": 2153.2, "end": 2156.8799999999997, "text": " There is no action like assign new value to some variable.", "tokens": [821, 307, 572, 3069, 411, 6269, 777, 2158, 281, 512, 7006, 13], "temperature": 0.0, "avg_logprob": -0.18141672746190485, "compression_ratio": 1.8093220338983051, "no_speech_prob": 0.001110098441131413}, {"id": 482, "seek": 215688, "start": 2156.88, "end": 2163.44, "text": " There is only, the closest thing we have is equal operator in math, but there is no assignment.", "tokens": [821, 307, 787, 11, 264, 13699, 551, 321, 362, 307, 2681, 12973, 294, 5221, 11, 457, 456, 307, 572, 15187, 13], "temperature": 0.0, "avg_logprob": -0.17159411040219394, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.0006637130863964558}, {"id": 483, "seek": 215688, "start": 2163.44, "end": 2169.8, "text": " But you can emulate it saying like next value of your variable equals old value and something", "tokens": [583, 291, 393, 45497, 309, 1566, 411, 958, 2158, 295, 428, 7006, 6915, 1331, 2158, 293, 746], "temperature": 0.0, "avg_logprob": -0.17159411040219394, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.0006637130863964558}, {"id": 484, "seek": 215688, "start": 2169.8, "end": 2170.8, "text": " done with it.", "tokens": [1096, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.17159411040219394, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.0006637130863964558}, {"id": 485, "seek": 215688, "start": 2170.8, "end": 2178.88, "text": " So here I say literally last sent next equals last sent old plus one, which effectively results", "tokens": [407, 510, 286, 584, 3736, 1036, 2279, 958, 6915, 1036, 2279, 1331, 1804, 472, 11, 597, 8659, 3542], "temperature": 0.0, "avg_logprob": -0.17159411040219394, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.0006637130863964558}, {"id": 486, "seek": 215688, "start": 2178.88, "end": 2183.36, "text": " into assignment and programming languages, but here you have to simulate it like this.", "tokens": [666, 15187, 293, 9410, 8650, 11, 457, 510, 291, 362, 281, 27817, 309, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.17159411040219394, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.0006637130863964558}, {"id": 487, "seek": 218336, "start": 2183.36, "end": 2189.8, "text": " In theory plus there is no separation into groups, it's just several mathematical conditions,", "tokens": [682, 5261, 1804, 456, 307, 572, 14634, 666, 3935, 11, 309, 311, 445, 2940, 18894, 4487, 11], "temperature": 0.0, "avg_logprob": -0.25225746154785156, "compression_ratio": 1.6735537190082646, "no_speech_prob": 0.0010939493076875806}, {"id": 488, "seek": 218336, "start": 2189.8, "end": 2194.6400000000003, "text": " but I do separate it for making the specification easier to read.", "tokens": [457, 286, 360, 4994, 309, 337, 1455, 264, 31256, 3571, 281, 1401, 13], "temperature": 0.0, "avg_logprob": -0.25225746154785156, "compression_ratio": 1.6735537190082646, "no_speech_prob": 0.0010939493076875806}, {"id": 489, "seek": 218336, "start": 2194.6400000000003, "end": 2196.8, "text": " I do the same for the receive action.", "tokens": [286, 360, 264, 912, 337, 264, 4774, 3069, 13], "temperature": 0.0, "avg_logprob": -0.25225746154785156, "compression_ratio": 1.6735537190082646, "no_speech_prob": 0.0010939493076875806}, {"id": 490, "seek": 218336, "start": 2196.8, "end": 2203.8, "text": " It's possible when I have items to receive, and the changes are to receive.", "tokens": [467, 311, 1944, 562, 286, 362, 4754, 281, 4774, 11, 293, 264, 2962, 366, 281, 4774, 13], "temperature": 0.0, "avg_logprob": -0.25225746154785156, "compression_ratio": 1.6735537190082646, "no_speech_prob": 0.0010939493076875806}, {"id": 491, "seek": 218336, "start": 2203.8, "end": 2210.2000000000003, "text": " And then you have to define what means validness for your system, so the invariance, which", "tokens": [400, 550, 291, 362, 281, 6964, 437, 1355, 7363, 1287, 337, 428, 1185, 11, 370, 264, 33270, 719, 11, 597], "temperature": 0.0, "avg_logprob": -0.25225746154785156, "compression_ratio": 1.6735537190082646, "no_speech_prob": 0.0010939493076875806}, {"id": 492, "seek": 218336, "start": 2210.2000000000003, "end": 2212.48, "text": " will be validated in every Ritual state.", "tokens": [486, 312, 40693, 294, 633, 497, 270, 901, 1785, 13], "temperature": 0.0, "avg_logprob": -0.25225746154785156, "compression_ratio": 1.6735537190082646, "no_speech_prob": 0.0010939493076875806}, {"id": 493, "seek": 221248, "start": 2212.48, "end": 2217.0, "text": " Here as they say that my queue is valid when all the items in the queue are ordered, like", "tokens": [1692, 382, 436, 584, 300, 452, 18639, 307, 7363, 562, 439, 264, 4754, 294, 264, 18639, 366, 8866, 11, 411], "temperature": 0.0, "avg_logprob": -0.2188461429470188, "compression_ratio": 1.7251184834123223, "no_speech_prob": 0.0029872716404497623}, {"id": 494, "seek": 221248, "start": 2217.0, "end": 2219.0, "text": " I pushed them.", "tokens": [286, 9152, 552, 13], "temperature": 0.0, "avg_logprob": -0.2188461429470188, "compression_ratio": 1.7251184834123223, "no_speech_prob": 0.0029872716404497623}, {"id": 495, "seek": 221248, "start": 2219.0, "end": 2225.6, "text": " The queue never overflows, and then the items are received in the same order as sent.", "tokens": [440, 18639, 1128, 670, 33229, 11, 293, 550, 264, 4754, 366, 4613, 294, 264, 912, 1668, 382, 2279, 13], "temperature": 0.0, "avg_logprob": -0.2188461429470188, "compression_ratio": 1.7251184834123223, "no_speech_prob": 0.0029872716404497623}, {"id": 496, "seek": 221248, "start": 2225.6, "end": 2232.16, "text": " And then with some technical steps, simple ones, I run the validation, and it will give", "tokens": [400, 550, 365, 512, 6191, 4439, 11, 2199, 2306, 11, 286, 1190, 264, 24071, 11, 293, 309, 486, 976], "temperature": 0.0, "avg_logprob": -0.2188461429470188, "compression_ratio": 1.7251184834123223, "no_speech_prob": 0.0029872716404497623}, {"id": 497, "seek": 221248, "start": 2232.16, "end": 2236.76, "text": " me a result like n states are found, like hundreds of thousands of millions of states", "tokens": [385, 257, 1874, 411, 297, 4368, 366, 1352, 11, 411, 6779, 295, 5383, 295, 6803, 295, 4368], "temperature": 0.0, "avg_logprob": -0.2188461429470188, "compression_ratio": 1.7251184834123223, "no_speech_prob": 0.0029872716404497623}, {"id": 498, "seek": 223676, "start": 2236.76, "end": 2243.2400000000002, "text": " that are found, and they are valid, or it will say that I found an invalid state.", "tokens": [300, 366, 1352, 11, 293, 436, 366, 7363, 11, 420, 309, 486, 584, 300, 286, 1352, 364, 34702, 1785, 13], "temperature": 0.0, "avg_logprob": -0.2629285292191939, "compression_ratio": 1.6586538461538463, "no_speech_prob": 0.0011552652576938272}, {"id": 499, "seek": 223676, "start": 2243.2400000000002, "end": 2247.96, "text": " And here is how you get into the state from the initial one following this sequence of", "tokens": [400, 510, 307, 577, 291, 483, 666, 264, 1785, 490, 264, 5883, 472, 3480, 341, 8310, 295], "temperature": 0.0, "avg_logprob": -0.2629285292191939, "compression_ratio": 1.6586538461538463, "no_speech_prob": 0.0011552652576938272}, {"id": 500, "seek": 223676, "start": 2247.96, "end": 2249.7200000000003, "text": " actions.", "tokens": [5909, 13], "temperature": 0.0, "avg_logprob": -0.2629285292191939, "compression_ratio": 1.6586538461538463, "no_speech_prob": 0.0011552652576938272}, {"id": 501, "seek": 223676, "start": 2249.7200000000003, "end": 2254.28, "text": " And then you can turn those failure traces into unit tests in your actual code.", "tokens": [400, 550, 291, 393, 1261, 729, 7763, 26076, 666, 4985, 6921, 294, 428, 3539, 3089, 13], "temperature": 0.0, "avg_logprob": -0.2629285292191939, "compression_ratio": 1.6586538461538463, "no_speech_prob": 0.0011552652576938272}, {"id": 502, "seek": 223676, "start": 2254.28, "end": 2261.5200000000004, "text": " Now this actually works, and they call it a bug in the scheduler, thanks to this thing.", "tokens": [823, 341, 767, 1985, 11, 293, 436, 818, 309, 257, 7426, 294, 264, 12000, 260, 11, 3231, 281, 341, 551, 13], "temperature": 0.0, "avg_logprob": -0.2629285292191939, "compression_ratio": 1.6586538461538463, "no_speech_prob": 0.0011552652576938272}, {"id": 503, "seek": 226152, "start": 2261.52, "end": 2268.84, "text": " Here by links you can find the specifications for tax scheduler on the whole, and for the", "tokens": [1692, 538, 6123, 291, 393, 915, 264, 29448, 337, 3366, 12000, 260, 322, 264, 1379, 11, 293, 337, 264], "temperature": 0.0, "avg_logprob": -0.2191797567873585, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0032364523503929377}, {"id": 504, "seek": 226152, "start": 2268.84, "end": 2274.12, "text": " multi-consumer queue, which was not trivial enough, so as I would try to validate it as", "tokens": [4825, 12, 21190, 15583, 18639, 11, 597, 390, 406, 26703, 1547, 11, 370, 382, 286, 576, 853, 281, 29562, 309, 382], "temperature": 0.0, "avg_logprob": -0.2191797567873585, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0032364523503929377}, {"id": 505, "seek": 226152, "start": 2274.12, "end": 2275.12, "text": " well.", "tokens": [731, 13], "temperature": 0.0, "avg_logprob": -0.2191797567873585, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0032364523503929377}, {"id": 506, "seek": 226152, "start": 2275.12, "end": 2279.24, "text": " Two specifications, they are quite big, but most of the lines are comments explaining", "tokens": [4453, 29448, 11, 436, 366, 1596, 955, 11, 457, 881, 295, 264, 3876, 366, 3053, 13468], "temperature": 0.0, "avg_logprob": -0.2191797567873585, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0032364523503929377}, {"id": 507, "seek": 226152, "start": 2279.24, "end": 2280.24, "text": " the algorithm.", "tokens": [264, 9284, 13], "temperature": 0.0, "avg_logprob": -0.2191797567873585, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0032364523503929377}, {"id": 508, "seek": 226152, "start": 2280.24, "end": 2286.4, "text": " So the specification, the code part of them is not too complicated.", "tokens": [407, 264, 31256, 11, 264, 3089, 644, 295, 552, 307, 406, 886, 6179, 13], "temperature": 0.0, "avg_logprob": -0.2191797567873585, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0032364523503929377}, {"id": 509, "seek": 226152, "start": 2286.4, "end": 2291.5, "text": " You can read it like easily.", "tokens": [509, 393, 1401, 309, 411, 3612, 13], "temperature": 0.0, "avg_logprob": -0.2191797567873585, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0032364523503929377}, {"id": 510, "seek": 229150, "start": 2291.5, "end": 2297.28, "text": " And also there are instructions how to install TLA+, in the source code repository, how to", "tokens": [400, 611, 456, 366, 9415, 577, 281, 3625, 314, 11435, 46797, 294, 264, 4009, 3089, 25841, 11, 577, 281], "temperature": 0.0, "avg_logprob": -0.22324176587556538, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0016400626627728343}, {"id": 511, "seek": 229150, "start": 2297.28, "end": 2302.08, "text": " run validation on those models, how to install TLA+, into the command line.", "tokens": [1190, 24071, 322, 729, 5245, 11, 577, 281, 3625, 314, 11435, 46797, 666, 264, 5622, 1622, 13], "temperature": 0.0, "avg_logprob": -0.22324176587556538, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0016400626627728343}, {"id": 512, "seek": 229150, "start": 2302.08, "end": 2304.96, "text": " It's not trivial, surprisingly.", "tokens": [467, 311, 406, 26703, 11, 17600, 13], "temperature": 0.0, "avg_logprob": -0.22324176587556538, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0016400626627728343}, {"id": 513, "seek": 229150, "start": 2304.96, "end": 2311.6, "text": " And there are also great course of lectures from the author of TLA+, Leslie Lampert.", "tokens": [400, 456, 366, 611, 869, 1164, 295, 16564, 490, 264, 3793, 295, 314, 11435, 46797, 28140, 18825, 15346, 13], "temperature": 0.0, "avg_logprob": -0.22324176587556538, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0016400626627728343}, {"id": 514, "seek": 229150, "start": 2311.6, "end": 2316.8, "text": " Lectures are quite fun, if you are not even planning to use TLA+, they are still worth", "tokens": [37196, 1303, 366, 1596, 1019, 11, 498, 291, 366, 406, 754, 5038, 281, 764, 314, 11435, 46797, 436, 366, 920, 3163], "temperature": 0.0, "avg_logprob": -0.22324176587556538, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0016400626627728343}, {"id": 515, "seek": 231680, "start": 2316.8, "end": 2321.8, "text": " watching, very entertaining.", "tokens": [1976, 11, 588, 20402, 13], "temperature": 0.0, "avg_logprob": -0.21004642139781604, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.0013630917528644204}, {"id": 516, "seek": 231680, "start": 2321.8, "end": 2326.84, "text": " All of this can be found on the source code repository, and now about the benchmarks.", "tokens": [1057, 295, 341, 393, 312, 1352, 322, 264, 4009, 3089, 25841, 11, 293, 586, 466, 264, 43751, 13], "temperature": 0.0, "avg_logprob": -0.21004642139781604, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.0013630917528644204}, {"id": 517, "seek": 231680, "start": 2326.84, "end": 2330.1200000000003, "text": " How I did them, the benchmarks are comparative.", "tokens": [1012, 286, 630, 552, 11, 264, 43751, 366, 39292, 13], "temperature": 0.0, "avg_logprob": -0.21004642139781604, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.0013630917528644204}, {"id": 518, "seek": 231680, "start": 2330.1200000000003, "end": 2336.4, "text": " So I'm not just running the benchmarks against themselves in vacuum against some random stuff.", "tokens": [407, 286, 478, 406, 445, 2614, 264, 43751, 1970, 2969, 294, 14224, 1970, 512, 4974, 1507, 13], "temperature": 0.0, "avg_logprob": -0.21004642139781604, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.0013630917528644204}, {"id": 519, "seek": 231680, "start": 2336.4, "end": 2342.8, "text": " I compare the improved versions of those, my algorithms against trivial versions, naive", "tokens": [286, 6794, 264, 9689, 9606, 295, 729, 11, 452, 14642, 1970, 26703, 9606, 11, 29052], "temperature": 0.0, "avg_logprob": -0.21004642139781604, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.0013630917528644204}, {"id": 520, "seek": 234280, "start": 2342.8, "end": 2349.2000000000003, "text": " versions using mutexes, to see if stuff actually improved.", "tokens": [9606, 1228, 24523, 47047, 11, 281, 536, 498, 1507, 767, 9689, 13], "temperature": 0.0, "avg_logprob": -0.26189184188842773, "compression_ratio": 1.7125984251968505, "no_speech_prob": 0.0018893368542194366}, {"id": 521, "seek": 234280, "start": 2349.2000000000003, "end": 2354.44, "text": " Like all the same benchmarks run on my algorithms and don't trivial implementations.", "tokens": [1743, 439, 264, 912, 43751, 1190, 322, 452, 14642, 293, 500, 380, 26703, 4445, 763, 13], "temperature": 0.0, "avg_logprob": -0.26189184188842773, "compression_ratio": 1.7125984251968505, "no_speech_prob": 0.0018893368542194366}, {"id": 522, "seek": 234280, "start": 2354.44, "end": 2359.1200000000003, "text": " For example, the smart queues I benchmark against their mutex locked versions, or the", "tokens": [1171, 1365, 11, 264, 4069, 631, 1247, 286, 18927, 1970, 641, 24523, 87, 9376, 9606, 11, 420, 264], "temperature": 0.0, "avg_logprob": -0.26189184188842773, "compression_ratio": 1.7125984251968505, "no_speech_prob": 0.0018893368542194366}, {"id": 523, "seek": 234280, "start": 2359.1200000000003, "end": 2364.28, "text": " task scheduler I benchmark against thread pool, without coroutines, single queues, single", "tokens": [5633, 12000, 260, 286, 18927, 1970, 7207, 7005, 11, 1553, 1181, 346, 1652, 11, 2167, 631, 1247, 11, 2167], "temperature": 0.0, "avg_logprob": -0.26189184188842773, "compression_ratio": 1.7125984251968505, "no_speech_prob": 0.0018893368542194366}, {"id": 524, "seek": 234280, "start": 2364.28, "end": 2366.6000000000004, "text": " mutex and nothing else.", "tokens": [24523, 87, 293, 1825, 1646, 13], "temperature": 0.0, "avg_logprob": -0.26189184188842773, "compression_ratio": 1.7125984251968505, "no_speech_prob": 0.0018893368542194366}, {"id": 525, "seek": 234280, "start": 2366.6000000000004, "end": 2372.48, "text": " I run this on five different configurations of software and hardware with tens of scenarios", "tokens": [286, 1190, 341, 322, 1732, 819, 31493, 295, 4722, 293, 8837, 365, 10688, 295, 15077], "temperature": 0.0, "avg_logprob": -0.26189184188842773, "compression_ratio": 1.7125984251968505, "no_speech_prob": 0.0018893368542194366}, {"id": 526, "seek": 237248, "start": 2372.48, "end": 2378.6, "text": " and all the reports, while the performance are available on GitHub, in human readable", "tokens": [293, 439, 264, 7122, 11, 1339, 264, 3389, 366, 2435, 322, 23331, 11, 294, 1952, 49857], "temperature": 0.0, "avg_logprob": -0.19262637262759003, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.002665217500180006}, {"id": 527, "seek": 237248, "start": 2378.6, "end": 2380.2, "text": " markdown format.", "tokens": [1491, 5093, 7877, 13], "temperature": 0.0, "avg_logprob": -0.19262637262759003, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.002665217500180006}, {"id": 528, "seek": 237248, "start": 2380.2, "end": 2384.88, "text": " And you can also run them on your system with just a single line of Python script.", "tokens": [400, 291, 393, 611, 1190, 552, 322, 428, 1185, 365, 445, 257, 2167, 1622, 295, 15329, 5755, 13], "temperature": 0.0, "avg_logprob": -0.19262637262759003, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.002665217500180006}, {"id": 529, "seek": 237248, "start": 2384.88, "end": 2391.48, "text": " It will generate the report for your case, and you can read it and see what's up.", "tokens": [467, 486, 8460, 264, 2275, 337, 428, 1389, 11, 293, 291, 393, 1401, 309, 293, 536, 437, 311, 493, 13], "temperature": 0.0, "avg_logprob": -0.19262637262759003, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.002665217500180006}, {"id": 530, "seek": 237248, "start": 2391.48, "end": 2396.0, "text": " And so there are quite a lot of results, I can show just a few of them on the slides.", "tokens": [400, 370, 456, 366, 1596, 257, 688, 295, 3542, 11, 286, 393, 855, 445, 257, 1326, 295, 552, 322, 264, 9788, 13], "temperature": 0.0, "avg_logprob": -0.19262637262759003, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.002665217500180006}, {"id": 531, "seek": 239600, "start": 2396.0, "end": 2403.12, "text": " I will use Debian Linux with eight cores running in Google Cloud, and I will show just some", "tokens": [286, 486, 764, 1346, 20196, 18734, 365, 3180, 24826, 2614, 294, 3329, 8061, 11, 293, 286, 486, 855, 445, 512], "temperature": 0.0, "avg_logprob": -0.23368753388870595, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0016977052437141538}, {"id": 532, "seek": 239600, "start": 2403.12, "end": 2409.92, "text": " average results, no shocking like 100 times faster, although there are extreme cases when", "tokens": [4274, 3542, 11, 572, 18776, 411, 2319, 1413, 4663, 11, 4878, 456, 366, 8084, 3331, 562], "temperature": 0.0, "avg_logprob": -0.23368753388870595, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0016977052437141538}, {"id": 533, "seek": 239600, "start": 2409.92, "end": 2415.12, "text": " algorithms are almost the same, or when it's extremely faster, but I will show just some", "tokens": [14642, 366, 1920, 264, 912, 11, 420, 562, 309, 311, 4664, 4663, 11, 457, 286, 486, 855, 445, 512], "temperature": 0.0, "avg_logprob": -0.23368753388870595, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0016977052437141538}, {"id": 534, "seek": 239600, "start": 2415.12, "end": 2421.12, "text": " average results which you can actually get in real production.", "tokens": [4274, 3542, 597, 291, 393, 767, 483, 294, 957, 4265, 13], "temperature": 0.0, "avg_logprob": -0.23368753388870595, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0016977052437141538}, {"id": 535, "seek": 239600, "start": 2421.12, "end": 2424.28, "text": " We start from the front queue again.", "tokens": [492, 722, 490, 264, 1868, 18639, 797, 13], "temperature": 0.0, "avg_logprob": -0.23368753388870595, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0016977052437141538}, {"id": 536, "seek": 242428, "start": 2424.28, "end": 2429.88, "text": " The benchmark uses five producer threads and one consumer thread, doing busy loop pushes", "tokens": [440, 18927, 4960, 1732, 12314, 19314, 293, 472, 9711, 7207, 11, 884, 5856, 6367, 21020], "temperature": 0.0, "avg_logprob": -0.1909887672650932, "compression_ratio": 1.7253218884120172, "no_speech_prob": 0.002588281873613596}, {"id": 537, "seek": 242428, "start": 2429.88, "end": 2435.1600000000003, "text": " and pops all the time to get the worst case contention.", "tokens": [293, 16795, 439, 264, 565, 281, 483, 264, 5855, 1389, 660, 1251, 13], "temperature": 0.0, "avg_logprob": -0.1909887672650932, "compression_ratio": 1.7253218884120172, "no_speech_prob": 0.002588281873613596}, {"id": 538, "seek": 242428, "start": 2435.1600000000003, "end": 2439.5600000000004, "text": " It's just for one and a half times faster, and this is all considering the two drawbacks", "tokens": [467, 311, 445, 337, 472, 293, 257, 1922, 1413, 4663, 11, 293, 341, 307, 439, 8079, 264, 732, 2642, 17758], "temperature": 0.0, "avg_logprob": -0.1909887672650932, "compression_ratio": 1.7253218884120172, "no_speech_prob": 0.002588281873613596}, {"id": 539, "seek": 242428, "start": 2439.5600000000004, "end": 2445.1600000000003, "text": " which you can remember, so we store items as stack in the front queue, we have to reverse", "tokens": [597, 291, 393, 1604, 11, 370, 321, 3531, 4754, 382, 8630, 294, 264, 1868, 18639, 11, 321, 362, 281, 9943], "temperature": 0.0, "avg_logprob": -0.1909887672650932, "compression_ratio": 1.7253218884120172, "no_speech_prob": 0.002588281873613596}, {"id": 540, "seek": 242428, "start": 2445.1600000000003, "end": 2450.0, "text": " them, we can pop them one by one, and still it is one and a half times faster.", "tokens": [552, 11, 321, 393, 1665, 552, 472, 538, 472, 11, 293, 920, 309, 307, 472, 293, 257, 1922, 1413, 4663, 13], "temperature": 0.0, "avg_logprob": -0.1909887672650932, "compression_ratio": 1.7253218884120172, "no_speech_prob": 0.002588281873613596}, {"id": 541, "seek": 245000, "start": 2450.0, "end": 2455.52, "text": " If we make it 10 producer threads, so we have more threads than CPU cores, worst case for", "tokens": [759, 321, 652, 309, 1266, 12314, 19314, 11, 370, 321, 362, 544, 19314, 813, 13199, 24826, 11, 5855, 1389, 337], "temperature": 0.0, "avg_logprob": -0.2582258224487305, "compression_ratio": 1.6861702127659575, "no_speech_prob": 0.0021015177480876446}, {"id": 542, "seek": 245000, "start": 2455.52, "end": 2460.12, "text": " mutics contention, it becomes 2.6 times faster.", "tokens": [5839, 1167, 660, 1251, 11, 309, 3643, 568, 13, 21, 1413, 4663, 13], "temperature": 0.0, "avg_logprob": -0.2582258224487305, "compression_ratio": 1.6861702127659575, "no_speech_prob": 0.0021015177480876446}, {"id": 543, "seek": 245000, "start": 2460.12, "end": 2466.88, "text": " The ready queue, another benchmark, five consumer threads, one producer threads, one producer", "tokens": [440, 1919, 18639, 11, 1071, 18927, 11, 1732, 9711, 19314, 11, 472, 12314, 19314, 11, 472, 12314], "temperature": 0.0, "avg_logprob": -0.2582258224487305, "compression_ratio": 1.6861702127659575, "no_speech_prob": 0.0021015177480876446}, {"id": 544, "seek": 245000, "start": 2466.88, "end": 2473.28, "text": " thread, again busy loop pushes and pops, it becomes 2.6 times faster, already and you", "tokens": [7207, 11, 797, 5856, 6367, 21020, 293, 16795, 11, 309, 3643, 568, 13, 21, 1413, 4663, 11, 1217, 293, 291], "temperature": 0.0, "avg_logprob": -0.2582258224487305, "compression_ratio": 1.6861702127659575, "no_speech_prob": 0.0021015177480876446}, {"id": 545, "seek": 247328, "start": 2473.28, "end": 2479.96, "text": " can see that the mutics, the log contention is multiple orders slower than in a trivial", "tokens": [393, 536, 300, 264, 5839, 1167, 11, 264, 3565, 660, 1251, 307, 3866, 9470, 14009, 813, 294, 257, 26703], "temperature": 0.0, "avg_logprob": -0.19235639861135773, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0008563092560507357}, {"id": 546, "seek": 247328, "start": 2479.96, "end": 2481.96, "text": " implementation.", "tokens": [11420, 13], "temperature": 0.0, "avg_logprob": -0.19235639861135773, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0008563092560507357}, {"id": 547, "seek": 247328, "start": 2481.96, "end": 2487.4, "text": " This is thanks to us taking mutics log, not on every operation, but once per multiple", "tokens": [639, 307, 3231, 281, 505, 1940, 5839, 1167, 3565, 11, 406, 322, 633, 6916, 11, 457, 1564, 680, 3866], "temperature": 0.0, "avg_logprob": -0.19235639861135773, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0008563092560507357}, {"id": 548, "seek": 247328, "start": 2487.4, "end": 2490.6400000000003, "text": " thousand operations, and this is the result.", "tokens": [4714, 7705, 11, 293, 341, 307, 264, 1874, 13], "temperature": 0.0, "avg_logprob": -0.19235639861135773, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0008563092560507357}, {"id": 549, "seek": 247328, "start": 2490.6400000000003, "end": 2495.88, "text": " Mutics is still here, but it almost doesn't affect the results at all.", "tokens": [18517, 1167, 307, 920, 510, 11, 457, 309, 1920, 1177, 380, 3345, 264, 3542, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.19235639861135773, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0008563092560507357}, {"id": 550, "seek": 247328, "start": 2495.88, "end": 2501.28, "text": " When we make it 10, consumer threads, it becomes already four and a half times faster.", "tokens": [1133, 321, 652, 309, 1266, 11, 9711, 19314, 11, 309, 3643, 1217, 1451, 293, 257, 1922, 1413, 4663, 13], "temperature": 0.0, "avg_logprob": -0.19235639861135773, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0008563092560507357}, {"id": 551, "seek": 250128, "start": 2501.28, "end": 2506.2400000000002, "text": " The naive queue degrades quite quick in this case.", "tokens": [440, 29052, 18639, 368, 22626, 1596, 1702, 294, 341, 1389, 13], "temperature": 0.0, "avg_logprob": -0.21844275454257397, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002534874016419053}, {"id": 552, "seek": 250128, "start": 2506.2400000000002, "end": 2509.84, "text": " And now everything combined, the task scheduler on the whole.", "tokens": [400, 586, 1203, 9354, 11, 264, 5633, 12000, 260, 322, 264, 1379, 13], "temperature": 0.0, "avg_logprob": -0.21844275454257397, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002534874016419053}, {"id": 553, "seek": 250128, "start": 2509.84, "end": 2516.6400000000003, "text": " In this benchmark, tasks are empty, so they are just empty C++ functions.", "tokens": [682, 341, 18927, 11, 9608, 366, 6707, 11, 370, 436, 366, 445, 6707, 383, 25472, 6828, 13], "temperature": 0.0, "avg_logprob": -0.21844275454257397, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002534874016419053}, {"id": 554, "seek": 250128, "start": 2516.6400000000003, "end": 2521.5600000000004, "text": " Not doing anything, worst case for contention again.", "tokens": [1726, 884, 1340, 11, 5855, 1389, 337, 660, 1251, 797, 13], "temperature": 0.0, "avg_logprob": -0.21844275454257397, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002534874016419053}, {"id": 555, "seek": 250128, "start": 2521.5600000000004, "end": 2525.88, "text": " And now we start from single worker thread, which will do both the scheduling and tasks,", "tokens": [400, 586, 321, 722, 490, 2167, 11346, 7207, 11, 597, 486, 360, 1293, 264, 29055, 293, 9608, 11], "temperature": 0.0, "avg_logprob": -0.21844275454257397, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002534874016419053}, {"id": 556, "seek": 250128, "start": 2525.88, "end": 2529.0800000000004, "text": " it becomes right away 2.2 times faster.", "tokens": [309, 3643, 558, 1314, 568, 13, 17, 1413, 4663, 13], "temperature": 0.0, "avg_logprob": -0.21844275454257397, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002534874016419053}, {"id": 557, "seek": 252908, "start": 2529.08, "end": 2535.2799999999997, "text": " Then a trivial thread pool without routine support, it becomes already 2.2 times faster.", "tokens": [1396, 257, 26703, 7207, 7005, 1553, 9927, 1406, 11, 309, 3643, 1217, 568, 13, 17, 1413, 4663, 13], "temperature": 0.0, "avg_logprob": -0.18548492356842639, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.0007465279777534306}, {"id": 558, "seek": 252908, "start": 2535.2799999999997, "end": 2541.56, "text": " And zero log contention, so log wasn't contended even once between the worker and producer.", "tokens": [400, 4018, 3565, 660, 1251, 11, 370, 3565, 2067, 380, 660, 3502, 754, 1564, 1296, 264, 11346, 293, 12314, 13], "temperature": 0.0, "avg_logprob": -0.18548492356842639, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.0007465279777534306}, {"id": 559, "seek": 252908, "start": 2541.56, "end": 2546.2799999999997, "text": " When we make it five worker threads, it becomes three times faster, so it scales better than", "tokens": [1133, 321, 652, 309, 1732, 11346, 19314, 11, 309, 3643, 1045, 1413, 4663, 11, 370, 309, 17408, 1101, 813], "temperature": 0.0, "avg_logprob": -0.18548492356842639, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.0007465279777534306}, {"id": 560, "seek": 252908, "start": 2546.2799999999997, "end": 2552.68, "text": " naive implementation, but we make it 10 worker threads, it becomes seven and half times faster.", "tokens": [29052, 11420, 11, 457, 321, 652, 309, 1266, 11346, 19314, 11, 309, 3643, 3407, 293, 1922, 1413, 4663, 13], "temperature": 0.0, "avg_logprob": -0.18548492356842639, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.0007465279777534306}, {"id": 561, "seek": 252908, "start": 2552.68, "end": 2556.84, "text": " And these are not the best results, it can be even better.", "tokens": [400, 613, 366, 406, 264, 1151, 3542, 11, 309, 393, 312, 754, 1101, 13], "temperature": 0.0, "avg_logprob": -0.18548492356842639, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.0007465279777534306}, {"id": 562, "seek": 255684, "start": 2556.84, "end": 2564.1600000000003, "text": " I'm just not showing extreme cases here, but I saw like 15 times speed up as well.", "tokens": [286, 478, 445, 406, 4099, 8084, 3331, 510, 11, 457, 286, 1866, 411, 2119, 1413, 3073, 493, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17837847196138823, "compression_ratio": 1.5732758620689655, "no_speech_prob": 0.0016914441948756576}, {"id": 563, "seek": 255684, "start": 2564.1600000000003, "end": 2568.36, "text": " It's just not something you will most likely get in production if you start using this,", "tokens": [467, 311, 445, 406, 746, 291, 486, 881, 3700, 483, 294, 4265, 498, 291, 722, 1228, 341, 11], "temperature": 0.0, "avg_logprob": -0.17837847196138823, "compression_ratio": 1.5732758620689655, "no_speech_prob": 0.0016914441948756576}, {"id": 564, "seek": 255684, "start": 2568.36, "end": 2570.7200000000003, "text": " but those benchmarks are also available.", "tokens": [457, 729, 43751, 366, 611, 2435, 13], "temperature": 0.0, "avg_logprob": -0.17837847196138823, "compression_ratio": 1.5732758620689655, "no_speech_prob": 0.0016914441948756576}, {"id": 565, "seek": 255684, "start": 2570.7200000000003, "end": 2576.2400000000002, "text": " And now about the real usage, not some random benchmarks in the vacuum, how it affects the", "tokens": [400, 586, 466, 264, 957, 14924, 11, 406, 512, 4974, 43751, 294, 264, 14224, 11, 577, 309, 11807, 264], "temperature": 0.0, "avg_logprob": -0.17837847196138823, "compression_ratio": 1.5732758620689655, "no_speech_prob": 0.0016914441948756576}, {"id": 566, "seek": 255684, "start": 2576.2400000000002, "end": 2577.2400000000002, "text": " actual code.", "tokens": [3539, 3089, 13], "temperature": 0.0, "avg_logprob": -0.17837847196138823, "compression_ratio": 1.5732758620689655, "no_speech_prob": 0.0016914441948756576}, {"id": 567, "seek": 255684, "start": 2577.2400000000002, "end": 2582.52, "text": " Apply to this save games case from the beginning.", "tokens": [25264, 281, 341, 3155, 2813, 1389, 490, 264, 2863, 13], "temperature": 0.0, "avg_logprob": -0.17837847196138823, "compression_ratio": 1.5732758620689655, "no_speech_prob": 0.0016914441948756576}, {"id": 568, "seek": 258252, "start": 2582.52, "end": 2589.2, "text": " We reported one of the microservices from updater scheduler to task scheduler, and we immediately", "tokens": [492, 7055, 472, 295, 264, 15547, 47480, 490, 3460, 771, 12000, 260, 281, 5633, 12000, 260, 11, 293, 321, 4258], "temperature": 0.0, "avg_logprob": -0.23484544975813046, "compression_ratio": 1.5381165919282511, "no_speech_prob": 0.0027780048549175262}, {"id": 569, "seek": 258252, "start": 2589.2, "end": 2594.4, "text": " without any further optimizations got 10 times speed up.", "tokens": [1553, 604, 3052, 5028, 14455, 658, 1266, 1413, 3073, 493, 13], "temperature": 0.0, "avg_logprob": -0.23484544975813046, "compression_ratio": 1.5381165919282511, "no_speech_prob": 0.0027780048549175262}, {"id": 570, "seek": 258252, "start": 2594.4, "end": 2603.7599999999998, "text": " We went from 100s RPS to bigger than 10,000 RPS, and latency dropped five times like right", "tokens": [492, 1437, 490, 2319, 82, 497, 6273, 281, 3801, 813, 1266, 11, 1360, 497, 6273, 11, 293, 27043, 8119, 1732, 1413, 411, 558], "temperature": 0.0, "avg_logprob": -0.23484544975813046, "compression_ratio": 1.5381165919282511, "no_speech_prob": 0.0027780048549175262}, {"id": 571, "seek": 258252, "start": 2603.7599999999998, "end": 2608.72, "text": " out of the box before we started doing some other optimizations.", "tokens": [484, 295, 264, 2424, 949, 321, 1409, 884, 512, 661, 5028, 14455, 13], "temperature": 0.0, "avg_logprob": -0.23484544975813046, "compression_ratio": 1.5381165919282511, "no_speech_prob": 0.0027780048549175262}, {"id": 572, "seek": 258252, "start": 2608.72, "end": 2610.64, "text": " And the algorithm is extendable.", "tokens": [400, 264, 9284, 307, 10101, 712, 13], "temperature": 0.0, "avg_logprob": -0.23484544975813046, "compression_ratio": 1.5381165919282511, "no_speech_prob": 0.0027780048549175262}, {"id": 573, "seek": 261064, "start": 2610.64, "end": 2616.92, "text": " Now, as you remember, there is this big rectangle where only one thread at a time can work.", "tokens": [823, 11, 382, 291, 1604, 11, 456, 307, 341, 955, 21930, 689, 787, 472, 7207, 412, 257, 565, 393, 589, 13], "temperature": 0.0, "avg_logprob": -0.2513556434112845, "compression_ratio": 1.6150627615062763, "no_speech_prob": 0.0029814729932695627}, {"id": 574, "seek": 261064, "start": 2616.92, "end": 2620.64, "text": " It means this is thread safe space.", "tokens": [467, 1355, 341, 307, 7207, 3273, 1901, 13], "temperature": 0.0, "avg_logprob": -0.2513556434112845, "compression_ratio": 1.6150627615062763, "no_speech_prob": 0.0029814729932695627}, {"id": 575, "seek": 261064, "start": 2620.64, "end": 2624.64, "text": " We can replace the binary heap with weighting task with something more complicated.", "tokens": [492, 393, 7406, 264, 17434, 33591, 365, 3364, 278, 5633, 365, 746, 544, 6179, 13], "temperature": 0.0, "avg_logprob": -0.2513556434112845, "compression_ratio": 1.6150627615062763, "no_speech_prob": 0.0029814729932695627}, {"id": 576, "seek": 261064, "start": 2624.64, "end": 2631.0, "text": " For instance, we can put LibF inside, or EPUL or IO completion ports from Windows inside,", "tokens": [1171, 5197, 11, 321, 393, 829, 15834, 37, 1854, 11, 420, 462, 8115, 43, 420, 39839, 19372, 18160, 490, 8591, 1854, 11], "temperature": 0.0, "avg_logprob": -0.2513556434112845, "compression_ratio": 1.6150627615062763, "no_speech_prob": 0.0029814729932695627}, {"id": 577, "seek": 261064, "start": 2631.0, "end": 2637.16, "text": " and we get multi-threaded event loop, like multi-threaded LibF, we can store sockets", "tokens": [293, 321, 483, 4825, 12, 392, 2538, 292, 2280, 6367, 11, 411, 4825, 12, 392, 2538, 292, 15834, 37, 11, 321, 393, 3531, 370, 11984], "temperature": 0.0, "avg_logprob": -0.2513556434112845, "compression_ratio": 1.6150627615062763, "no_speech_prob": 0.0029814729932695627}, {"id": 578, "seek": 263716, "start": 2637.16, "end": 2643.24, "text": " in tasks, and we get circuits with deadlines, with yields, and this is, in fact, what we", "tokens": [294, 9608, 11, 293, 321, 483, 26354, 365, 37548, 11, 365, 32168, 11, 293, 341, 307, 11, 294, 1186, 11, 437, 321], "temperature": 0.0, "avg_logprob": -0.2074891886579881, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.0014916550135239959}, {"id": 579, "seek": 263716, "start": 2643.24, "end": 2650.0, "text": " do have in Ubisoft, it's a fork of task scheduler where we just replaced weight queue with EPUL", "tokens": [360, 362, 294, 30230, 47929, 11, 309, 311, 257, 17716, 295, 5633, 12000, 260, 689, 321, 445, 10772, 3364, 18639, 365, 462, 8115, 43], "temperature": 0.0, "avg_logprob": -0.2074891886579881, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.0014916550135239959}, {"id": 580, "seek": 263716, "start": 2650.0, "end": 2652.92, "text": " on Linux and IO completion ports on Windows.", "tokens": [322, 18734, 293, 39839, 19372, 18160, 322, 8591, 13], "temperature": 0.0, "avg_logprob": -0.2074891886579881, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.0014916550135239959}, {"id": 581, "seek": 263716, "start": 2652.92, "end": 2658.04, "text": " And we get more than millions, more than million messages per second with just several threads", "tokens": [400, 321, 483, 544, 813, 6803, 11, 544, 813, 2459, 7897, 680, 1150, 365, 445, 2940, 19314], "temperature": 0.0, "avg_logprob": -0.2074891886579881, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.0014916550135239959}, {"id": 582, "seek": 263716, "start": 2658.04, "end": 2659.04, "text": " on sockets.", "tokens": [322, 370, 11984, 13], "temperature": 0.0, "avg_logprob": -0.2074891886579881, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.0014916550135239959}, {"id": 583, "seek": 263716, "start": 2659.04, "end": 2665.72, "text": " With this thing, it's not too complicated to extend scheduler, it's just maybe next", "tokens": [2022, 341, 551, 11, 309, 311, 406, 886, 6179, 281, 10101, 12000, 260, 11, 309, 311, 445, 1310, 958], "temperature": 0.0, "avg_logprob": -0.2074891886579881, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.0014916550135239959}, {"id": 584, "seek": 266572, "start": 2665.72, "end": 2669.3999999999996, "text": " time about this multi-threaded event loop.", "tokens": [565, 466, 341, 4825, 12, 392, 2538, 292, 2280, 6367, 13], "temperature": 0.0, "avg_logprob": -0.20148558128537156, "compression_ratio": 1.5197132616487454, "no_speech_prob": 0.003603546414524317}, {"id": 585, "seek": 266572, "start": 2669.3999999999996, "end": 2671.3999999999996, "text": " What are the future plans for it?", "tokens": [708, 366, 264, 2027, 5482, 337, 309, 30], "temperature": 0.0, "avg_logprob": -0.20148558128537156, "compression_ratio": 1.5197132616487454, "no_speech_prob": 0.003603546414524317}, {"id": 586, "seek": 266572, "start": 2671.3999999999996, "end": 2674.2, "text": " Firstly, we could try to run it on ARM.", "tokens": [20042, 11, 321, 727, 853, 281, 1190, 309, 322, 45209, 13], "temperature": 0.0, "avg_logprob": -0.20148558128537156, "compression_ratio": 1.5197132616487454, "no_speech_prob": 0.003603546414524317}, {"id": 587, "seek": 266572, "start": 2674.2, "end": 2677.2, "text": " Maybe it already runs, but I just haven't tried.", "tokens": [2704, 309, 1217, 6676, 11, 457, 286, 445, 2378, 380, 3031, 13], "temperature": 0.0, "avg_logprob": -0.20148558128537156, "compression_ratio": 1.5197132616487454, "no_speech_prob": 0.003603546414524317}, {"id": 588, "seek": 266572, "start": 2677.2, "end": 2680.0, "text": " Maybe it works, maybe not, I have no idea.", "tokens": [2704, 309, 1985, 11, 1310, 406, 11, 286, 362, 572, 1558, 13], "temperature": 0.0, "avg_logprob": -0.20148558128537156, "compression_ratio": 1.5197132616487454, "no_speech_prob": 0.003603546414524317}, {"id": 589, "seek": 266572, "start": 2680.0, "end": 2681.2, "text": " That's why it's open source.", "tokens": [663, 311, 983, 309, 311, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.20148558128537156, "compression_ratio": 1.5197132616487454, "no_speech_prob": 0.003603546414524317}, {"id": 590, "seek": 266572, "start": 2681.2, "end": 2685.12, "text": " You can try it, send a pull request if something's not working.", "tokens": [509, 393, 853, 309, 11, 2845, 257, 2235, 5308, 498, 746, 311, 406, 1364, 13], "temperature": 0.0, "avg_logprob": -0.20148558128537156, "compression_ratio": 1.5197132616487454, "no_speech_prob": 0.003603546414524317}, {"id": 591, "seek": 266572, "start": 2685.12, "end": 2691.52, "text": " Also, it's currently implemented only in C++, and it's not even STL, although some people", "tokens": [2743, 11, 309, 311, 4362, 12270, 787, 294, 383, 25472, 11, 293, 309, 311, 406, 754, 4904, 43, 11, 4878, 512, 561], "temperature": 0.0, "avg_logprob": -0.20148558128537156, "compression_ratio": 1.5197132616487454, "no_speech_prob": 0.003603546414524317}, {"id": 592, "seek": 266572, "start": 2691.52, "end": 2694.04, "text": " might consider it good, like me.", "tokens": [1062, 1949, 309, 665, 11, 411, 385, 13], "temperature": 0.0, "avg_logprob": -0.20148558128537156, "compression_ratio": 1.5197132616487454, "no_speech_prob": 0.003603546414524317}, {"id": 593, "seek": 269404, "start": 2694.04, "end": 2700.12, "text": " I don't like STL, but it could use a port to STL as well, or to some other language.", "tokens": [286, 500, 380, 411, 4904, 43, 11, 457, 309, 727, 764, 257, 2436, 281, 4904, 43, 382, 731, 11, 420, 281, 512, 661, 2856, 13], "temperature": 0.0, "avg_logprob": -0.13760615278173377, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.002973817987367511}, {"id": 594, "seek": 269404, "start": 2700.12, "end": 2705.32, "text": " And also, there could be optimizations done like the front queue.", "tokens": [400, 611, 11, 456, 727, 312, 5028, 14455, 1096, 411, 264, 1868, 18639, 13], "temperature": 0.0, "avg_logprob": -0.13760615278173377, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.002973817987367511}, {"id": 595, "seek": 269404, "start": 2705.32, "end": 2710.12, "text": " Maybe there is a way not to store it as a stack, not to reverse the list of items before", "tokens": [2704, 456, 307, 257, 636, 406, 281, 3531, 309, 382, 257, 8630, 11, 406, 281, 9943, 264, 1329, 295, 4754, 949], "temperature": 0.0, "avg_logprob": -0.13760615278173377, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.002973817987367511}, {"id": 596, "seek": 269404, "start": 2710.12, "end": 2711.12, "text": " returning it.", "tokens": [12678, 309, 13], "temperature": 0.0, "avg_logprob": -0.13760615278173377, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.002973817987367511}, {"id": 597, "seek": 269404, "start": 2711.12, "end": 2716.32, "text": " I just haven't found a simple way to do it, which would be worth trying, and this is the", "tokens": [286, 445, 2378, 380, 1352, 257, 2199, 636, 281, 360, 309, 11, 597, 576, 312, 3163, 1382, 11, 293, 341, 307, 264], "temperature": 0.0, "avg_logprob": -0.13760615278173377, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.002973817987367511}, {"id": 598, "seek": 269404, "start": 2716.32, "end": 2717.32, "text": " end.", "tokens": [917, 13], "temperature": 0.0, "avg_logprob": -0.13760615278173377, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.002973817987367511}, {"id": 599, "seek": 269404, "start": 2717.32, "end": 2718.32, "text": " Thanks for your attention.", "tokens": [2561, 337, 428, 3202, 13], "temperature": 0.0, "avg_logprob": -0.13760615278173377, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.002973817987367511}, {"id": 600, "seek": 271832, "start": 2718.32, "end": 2726.84, "text": " And here are the links to the source code, and to this talk.", "tokens": [400, 510, 366, 264, 6123, 281, 264, 4009, 3089, 11, 293, 281, 341, 751, 13], "temperature": 0.0, "avg_logprob": -0.2127229690551758, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.003845718689262867}, {"id": 601, "seek": 271832, "start": 2726.84, "end": 2731.04, "text": " It will be available, the animated versions with all the slides and my notes online by", "tokens": [467, 486, 312, 2435, 11, 264, 18947, 9606, 365, 439, 264, 9788, 293, 452, 5570, 2950, 538], "temperature": 0.0, "avg_logprob": -0.2127229690551758, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.003845718689262867}, {"id": 602, "seek": 271832, "start": 2731.04, "end": 2733.48, "text": " this link and my other talks.", "tokens": [341, 2113, 293, 452, 661, 6686, 13], "temperature": 0.0, "avg_logprob": -0.2127229690551758, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.003845718689262867}, {"id": 603, "seek": 271832, "start": 2733.48, "end": 2738.1200000000003, "text": " And also, there are bonus sections which some of you might ask as questions, and we will", "tokens": [400, 611, 11, 456, 366, 10882, 10863, 597, 512, 295, 291, 1062, 1029, 382, 1651, 11, 293, 321, 486], "temperature": 0.0, "avg_logprob": -0.2127229690551758, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.003845718689262867}, {"id": 604, "seek": 271832, "start": 2738.1200000000003, "end": 2744.36, "text": " quickly go for them, or you can click on them yourself after the talk if you're interested.", "tokens": [2661, 352, 337, 552, 11, 420, 291, 393, 2052, 322, 552, 1803, 934, 264, 751, 498, 291, 434, 3102, 13], "temperature": 0.0, "avg_logprob": -0.2127229690551758, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.003845718689262867}, {"id": 605, "seek": 274436, "start": 2744.36, "end": 2767.56, "text": " Okay, so time for questions, so show of hands, and we'll give you a mic.", "tokens": [1033, 11, 370, 565, 337, 1651, 11, 370, 855, 295, 2377, 11, 293, 321, 603, 976, 291, 257, 3123, 13], "temperature": 0.0, "avg_logprob": -0.4604979356129964, "compression_ratio": 0.9863013698630136, "no_speech_prob": 0.0021785518620163202}, {"id": 606, "seek": 276756, "start": 2767.56, "end": 2793.04, "text": " So, for the front queue, you can use some of Dmitry Vyukov's NPSC queue, very fast, much", "tokens": [407, 11, 337, 264, 1868, 18639, 11, 291, 393, 764, 512, 295, 413, 3508, 627, 691, 88, 2034, 5179, 311, 426, 6273, 34, 18639, 11, 588, 2370, 11, 709], "temperature": 0.0, "avg_logprob": -0.4017020716811671, "compression_ratio": 1.0476190476190477, "no_speech_prob": 0.004644713830202818}, {"id": 607, "seek": 279304, "start": 2793.04, "end": 2797.88, "text": " faster than the tribal stack, which is the thing you're using.", "tokens": [4663, 813, 264, 20958, 8630, 11, 597, 307, 264, 551, 291, 434, 1228, 13], "temperature": 0.0, "avg_logprob": -0.367526574568315, "compression_ratio": 1.536231884057971, "no_speech_prob": 0.006592971738427877}, {"id": 608, "seek": 279304, "start": 2797.88, "end": 2803.72, "text": " The other thing is for the wait queue, well, you answer this with IOCP, KQ, Epo, that would", "tokens": [440, 661, 551, 307, 337, 264, 1699, 18639, 11, 731, 11, 291, 1867, 341, 365, 286, 30087, 47, 11, 591, 48, 11, 462, 2259, 11, 300, 576], "temperature": 0.0, "avg_logprob": -0.367526574568315, "compression_ratio": 1.536231884057971, "no_speech_prob": 0.006592971738427877}, {"id": 609, "seek": 279304, "start": 2803.72, "end": 2810.7599999999998, "text": " be much more in line with something that uses timer or for networking.", "tokens": [312, 709, 544, 294, 1622, 365, 746, 300, 4960, 19247, 420, 337, 17985, 13], "temperature": 0.0, "avg_logprob": -0.367526574568315, "compression_ratio": 1.536231884057971, "no_speech_prob": 0.006592971738427877}, {"id": 610, "seek": 279304, "start": 2810.7599999999998, "end": 2821.32, "text": " And you said that we cannot have single produce, no, multi-multi-consumer single production.", "tokens": [400, 291, 848, 300, 321, 2644, 362, 2167, 5258, 11, 572, 11, 4825, 12, 76, 723, 72, 12, 21190, 15583, 2167, 4265, 13], "temperature": 0.0, "avg_logprob": -0.367526574568315, "compression_ratio": 1.536231884057971, "no_speech_prob": 0.006592971738427877}, {"id": 611, "seek": 282132, "start": 2821.32, "end": 2828.6400000000003, "text": " Yes, you can, actually, you can use one of the chase left DQ, there's a paper for 2013", "tokens": [1079, 11, 291, 393, 11, 767, 11, 291, 393, 764, 472, 295, 264, 15359, 1411, 413, 48, 11, 456, 311, 257, 3035, 337, 9012], "temperature": 0.0, "avg_logprob": -0.2783407483782087, "compression_ratio": 1.4816326530612245, "no_speech_prob": 0.007938031107187271}, {"id": 612, "seek": 282132, "start": 2828.6400000000003, "end": 2835.04, "text": " with formally verified primitives, including ARM, and those will work for you, use case.", "tokens": [365, 25983, 31197, 2886, 38970, 11, 3009, 45209, 11, 293, 729, 486, 589, 337, 291, 11, 764, 1389, 13], "temperature": 0.0, "avg_logprob": -0.2783407483782087, "compression_ratio": 1.4816326530612245, "no_speech_prob": 0.007938031107187271}, {"id": 613, "seek": 282132, "start": 2835.04, "end": 2839.6400000000003, "text": " I know that there exist implementations of such queues, I just couldn't find the simple", "tokens": [286, 458, 300, 456, 2514, 4445, 763, 295, 1270, 631, 1247, 11, 286, 445, 2809, 380, 915, 264, 2199], "temperature": 0.0, "avg_logprob": -0.2783407483782087, "compression_ratio": 1.4816326530612245, "no_speech_prob": 0.007938031107187271}, {"id": 614, "seek": 282132, "start": 2839.6400000000003, "end": 2840.88, "text": " enough one.", "tokens": [1547, 472, 13], "temperature": 0.0, "avg_logprob": -0.2783407483782087, "compression_ratio": 1.4816326530612245, "no_speech_prob": 0.007938031107187271}, {"id": 615, "seek": 282132, "start": 2840.88, "end": 2848.1200000000003, "text": " The thing is, in Ubisoft, internally, above all, sometimes, in Harm to performance, can", "tokens": [440, 551, 307, 11, 294, 30230, 47929, 11, 19501, 11, 3673, 439, 11, 2171, 11, 294, 43523, 281, 3389, 11, 393], "temperature": 0.0, "avg_logprob": -0.2783407483782087, "compression_ratio": 1.4816326530612245, "no_speech_prob": 0.007938031107187271}, {"id": 616, "seek": 284812, "start": 2848.12, "end": 2854.44, "text": " value code simplicity, so it's not an option to use something extremely complicated, like", "tokens": [2158, 3089, 25632, 11, 370, 309, 311, 406, 364, 3614, 281, 764, 746, 4664, 6179, 11, 411], "temperature": 0.0, "avg_logprob": -0.23883628845214844, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.007457011379301548}, {"id": 617, "seek": 284812, "start": 2854.44, "end": 2860.7999999999997, "text": " hazard pointers or stuff like this, or, for example, I saw implementations of such queues,", "tokens": [20790, 44548, 420, 1507, 411, 341, 11, 420, 11, 337, 1365, 11, 286, 1866, 4445, 763, 295, 1270, 631, 1247, 11], "temperature": 0.0, "avg_logprob": -0.23883628845214844, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.007457011379301548}, {"id": 618, "seek": 284812, "start": 2860.7999999999997, "end": 2866.04, "text": " which are not wait-free, so they can be lock-free, let's say, but not wait-free, that also wasn't", "tokens": [597, 366, 406, 1699, 12, 10792, 11, 370, 436, 393, 312, 4017, 12, 10792, 11, 718, 311, 584, 11, 457, 406, 1699, 12, 10792, 11, 300, 611, 2067, 380], "temperature": 0.0, "avg_logprob": -0.23883628845214844, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.007457011379301548}, {"id": 619, "seek": 284812, "start": 2866.04, "end": 2869.0, "text": " an option, because that's basically a spin-lock.", "tokens": [364, 3614, 11, 570, 300, 311, 1936, 257, 6060, 12, 4102, 13], "temperature": 0.0, "avg_logprob": -0.23883628845214844, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.007457011379301548}, {"id": 620, "seek": 286900, "start": 2869.0, "end": 2882.52, "text": " There's 100 levels.", "tokens": [821, 311, 2319, 4358, 13], "temperature": 1.0, "avg_logprob": -1.7546535068088107, "compression_ratio": 0.7037037037037037, "no_speech_prob": 0.002880127402022481}], "language": "en"}