{"text": " So we have Guillaume. He's going to talk about the merging process for the Rust compiler. Okay. Yeah, you can hear me. Perfect. So, hi, everyone. So, I will be talking as he mentioned about the merge process in the Rust compiler. So, who I am first, Rust language reviewer and contributor. I'm a member of a few teams. So, I'm in the Rust doc team. Not to be confused with the former documentation team. Also, Docs.Rust team and DevTools team. So, very documentation oriented. And I'm working at Huawei currently. So, we will start by taking a scenario. Hold on. So, when you have made a pull request, you open it. And the first thing that will happen on the pull request will be that the bot will assign you a reviewer. So, in this case, myself. So, very likely pull request on a Rust doc tool. And after that, you will have some tags. So, it's waiting on review and it's concerning the Rust doc team, which helps us to find the right people in case the reviewer assigned isn't available in a week, if I remember correctly. So, explanation a bit about how the bot is picking the people. So, we have a repository with the list of all teams and its members, formers and everything. And the bot basically pick someone from this repository. And this website, the governance page on the Rust long.org website is generated from it. So, if you need to contact someone from one of the teams, whatever reason, that's where you go. So, now the approval itself. So, let's say that the pull request is implemented with no request from the reviewer or anything. If it has no performance impact for this to have this information, if we have a depth, we have tools automated that allow us to actually check its actually the case. So, if needed, we just say, hey, Rust bot, can you run a perfect check on this? We come back to this later and we have a very nice page with some metrics and a lot of steps. So, another important thing is checking that there is no breaking change. So, of course, if you are changing something in the STD, for example, or changing how projection works on anything, then it becomes a lot more complex and the process becomes a lot longer. Same, we will come back to this later. So, if it adds a new feature, it's very likely that we will need to be sure at 100% that it's not something that we'll need to change or deprecate or literally just remove at some point because it happened a few times and it's not great. And obviously, the CI must pass. So, that's a lot of small conditions. So, now about the CI. So, there are two levels of CI. The one that you will see directly when you open the pull request. It's a lot of tests, almost all of them. But it's only on Linux X64 because, as you may know, we support quite a lot of targets, not as much as GCC yet, but at some point, maybe. And this checks, for example, if the call is wait-formatted, if you have all the tests passing, and by all the tests, I mean literally all the tests, so you have all the rest of the tool suite, tool test suite, the compiler error output, the compiler checks if the code is giving the right result, the assembly, pretty much everything, and it includes the tools. So, if you made a change in the compiler that breaks a tool, like REST doc, Clippy, or REST FMT, then we need to be aware of it right away. Otherwise, we are going to have quite a bite time. And all that is done directly on the pull request. So, at the current time, it takes around one hour to run this small subset. And when the pull request has been approved, we make the full run of all these tests and for all platforms. And this time, it's run, I think if I remember correctly, it's like on 40 targets or something like that, and it takes roughly around three hours. We have our own infra for this. We have dedicated the team for that too, the infra team. And I think it's currently done on AWS to be confirmed. But in short, nothing can be merged if the CI doesn't pass. We enforced this, I think it was three or four years ago. A few things that were merged and were expected to be fixed in very soon coming fixes were quite bad experiences, and we decided to have a zero-tolerance policy. It's working quite nice, so currently we keep it. So now it's a build queue. When we approve the command with the pull request with the command AddBulls R+, you might have seen it or not. We have a build queue, and that's where you can see pretty much everything that is happening. So in the current case, you see the pull request, the first one which is pending. So it allows you to see what is being tested and eventually how long it remains. And you can see also everything that is approved and everything. And it's sorted by priority first, which you can see because I had to make a small screenshot. And the second thing is how old the pull request is. We generally have around 20 pull requests at the same time in this build queue. So to make things faster, we have what we call a roll-up process. We group a full pull request that we are sure have no performance impact or anything. And we say, okay, make a roll-up of five pull requests. You can see the button, create a roll-up. So we pick a few pull requests and we click on the button, and it generates a pull request for us with our account. And after that, we give it quite a high priority and like that, we can have a big bunch of pull requests to merge at once. Very useful. And that is for the build queue. So what I explained a bit before, what is tested. So we have the compile test. So if your code is supposed to compile or not, because, for example, we want to ensure certain cases in very weird cases that don't compile or in other cases compile. And that's how you can discover things like you can't implement directly on projections. And if that doesn't speak much to you, it's a good sign. We have all the unit tests. Unit tests are mostly for the tools. But we have a few tests with, like I mentioned, just below the error output. It's quite important. So we ensure that the Rust doc and the Rusty errors are looking exactly as you might expect. If you ever used, and I think a lot of you used already Rust, you might have appreciated the errors and the output. Yes, because they are very, very strongly tested. Currently, just for the UI test, we have around 20,000 tests. So it's quite monstrous. And running it takes quite some time. I think it's, well, at least 10 minutes, something like that. It's quite heavy. Maybe you don't know it, but the documentation example are tested, all of them. You can just test them manually in your code by running cargo test. The cargo tool will take all the unit tests in your code. The test folder will run on everything. And it includes, of course, everything that is in the documentation. So that allows us to reduce the maintenance burden by being sure that we don't give examples that are not compiling anymore or completely broken, quite useful. Once again, it reduces the burden. And, of course, we have all the tools. So cargo, RustDoc, Clippy, RustFMT. So as I mentioned, when you change something on the compiler, sorry, when you change something in the compiler, since these tools are using directly the compiler, they are actually compiler extensions except cargo. Cargo is just tested to ensure that not a new option is breaking something. So for the others, they are extensions of the compiler and we need to ensure that no changes is breaking anything because that would be problematic. We generate a lot of documentation and we have to ensure that we have no deadlinks. And, in fact, we do have some of them and we ignore them on purpose. So sorry for that. We can't fix them because, funnily enough, in the STD, we re-export stuff that is in the core and they share the same documentation. So if you are looking at the documentation in the STD pages, all the links are working in the core create. They're not. So try to use STD as much as possible. And it's just very basic, but we have quite a lot more. We mentioned in the previous talk, the inline assembly, it's part of the things. Something we realized when working on the GCC backend this time is that GCC doesn't allow to specify a syntax that's thanks to this test suite. So currently, we can't implement all features and it's going to take quite a long time, but hopefully at some point, someone motivated will do it. Don't know. So on which OS and architectures are tested, everything. We have target tier policy. You can go check it on the page just linked below. But basically tier one, the platforms are the platforms that are fully tested, implemented, and everything. So macOS, Linux, and Windows. And they must pass all the tests and we build them and we ensure that what we have built and has to be able to be uncomplaced and working on the target and everything. So strict, very strict restriction. On the tier two platforms, it's a lot more relaxed. We just need it to build. If it works, well, it's good. If it doesn't, well, too bad. And for the tier three platforms, it exists. Yeah, that's good. So for example, if you want to build on the Nintendo 3DS, you can. We don't know if it would work, but you can. And you can see the list of the platforms each tier on the page just below. Like I mentioned, we have quite a lot and we hope to be able to expand it a bit more by adding at least the GCC backend at some point. A lot of work remaining. So what about releases now? Because as you might know, we make a release every six weeks. So it's very fast release cycle. So when this happens, the build queue is frozen. We don't allow anything below like a priority of 10,000 to be merged. It's a completely random number, but generally if you go higher than 10, it's quite important. So in this case, we freeze everything. And the only things allowed to be merged are the patches to make actually the stable and beta branches update. An important thing that isn't noted here is that we don't have the need to freeze for the nightly. We just say at a given time of every day, okay, this will be the nightly version for today. Yay, and that's it. So back to this, the third point. All relevant information is updated and reared. And by that, I mean the websites, the documentation, the book, I think, too. Pretty much everything. We generate the binaries. So that's what I mentioned. That's the things that need to be working for at least tier one polyform. And of course, we make a blog post. Generally, the blog post is written not for the current stable release, but we write it at the beta version. And then depending if we need the backports, for example, we realize that in the current beta version, something is completely broken and we don't want that. And it's an easy enough fix. Either we backport a patch that was merged on the nightly directly onto the beta branch. Or we say, okay, too bad. We revert that and we'll do it the next time. It happened quite a lot. And it's not uncommon. Let's just say it's better if it doesn't happen. It allows us to not have the dot one version coming up like a three days later because we realize that we broke something. And the blog post is released. So now a performance. What I mentioned is that we need to check sometimes the performance. So we have to speed it now. So for the performance, we have a lot of benchmarks you can see on the left. It's generally for the number of instructions that have been written. It's what we consider the most important metric and most, let's say, stable. So when you have all green numbers and quite high, oh, yeah, 8%, yeah, that's quite right. So when you have all green numbers, it's green and everyone is parting. And if you have all red numbers, either you have a very good reason or it's not going to be merged until you can make them at least black. And we have, like I said, a lot of metrics like cycles, memory usage, disk usage, because we started to worry about the binary size. We realized that all the doc attributes were generated in the binaries, which is not great. So we are going to fix that at some point. And you can see on the right that, yeah, maybe you can see. Anyway, just to believe what I say, the results are showed in the nice comment directly on the pull request. So other cases, when you add a new feature or introduce a breaking change, there are three possibilities. The mostly non-one is the RFC, request for comments. It has its own repository. It takes a lot of time and effort and comments. It can go really fast, like two days, or it can take indefinite amount of time. Some examples, some RFCs have been open and still are commented on before the 1.0, so that gives you an idea. We have the MCP, major compiler changes. So not too big changes in the compiler. We find it not to greet how the query system is working. So let's try this solution, and they discuss mostly design and very technical points. Interesting, but if you don't know this area, well, it's not very understandable. And the last one is common to all teams. So the FCP, the final comment period, it's something that we want. And we just want to be sure that everyone is on board. So we ask for an FCP, and once more than half of the members of the team are okay with it, then we approve it, and here we go. So we, of course, for every poll request that is merged, we check for potential examples. No, that's before, sorry. When we make a new feature that potentially changes current behavior, we look for potential regressions in all the crates ecosystem. So we make what we call a crater run. And with this version of your code, we run on all crates, and we generate a nice report. You can see on the left. And if you only have flaky stuff, we say, okay, no impact. So it's good. We don't care, and that's pretty much it. And same as for the performance, we have a nice comment explaining everything in short, which is much more easy to read that the thing on the left, which is actually not good. And now a little part I like to do every time, tips for potential new contributors. We have a lot of classified tagged issues with ELZ or E-Monitor or both issues. Take a look at them. We try to be as helpful as possible to newcomers. It's important for us to have new blood. We have always good surprises with newcomers. We wrote a receipt of guide, which is not up-to-date at all. So at least you have a vague idea of what's going on, because I think not many people have an idea. And you can try also to write compiler plugins or eventually contribute to ClipIt to see how the compiler higher internal levels work. About ClipIt, it's really simple to contribute to it, like they have a full guide or anything. So if you want a big, nice first step, take a look at ClipIt and how it works, and it gives a very, very nice introduction. And I am making publicity for myself. I wrote a small receipt towards Crate, which makes a few things simpler to write plugins and extensions to the compiler. If you want to write, go ahead. It's made to be usable as much as possible. And thank you for listening. Thank you so much for watching.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.0, "text": " So we have Guillaume. He's going to talk about the merging process for the Rust compiler.", "tokens": [407, 321, 362, 2694, 5291, 2540, 13, 634, 311, 516, 281, 751, 466, 264, 44559, 1399, 337, 264, 34952, 31958, 13], "temperature": 0.0, "avg_logprob": -0.4112719049993551, "compression_ratio": 1.3071428571428572, "no_speech_prob": 0.2673301100730896}, {"id": 1, "seek": 0, "start": 11.0, "end": 20.0, "text": " Okay. Yeah, you can hear me. Perfect. So, hi, everyone. So, I will be talking as he mentioned", "tokens": [1033, 13, 865, 11, 291, 393, 1568, 385, 13, 10246, 13, 407, 11, 4879, 11, 1518, 13, 407, 11, 286, 486, 312, 1417, 382, 415, 2835], "temperature": 0.0, "avg_logprob": -0.4112719049993551, "compression_ratio": 1.3071428571428572, "no_speech_prob": 0.2673301100730896}, {"id": 2, "seek": 2000, "start": 20.0, "end": 29.0, "text": " about the merge process in the Rust compiler. So, who I am first, Rust language reviewer and contributor.", "tokens": [466, 264, 22183, 1399, 294, 264, 34952, 31958, 13, 407, 11, 567, 286, 669, 700, 11, 34952, 2856, 3131, 260, 293, 42859, 13], "temperature": 0.0, "avg_logprob": -0.24736341563138095, "compression_ratio": 1.5741626794258374, "no_speech_prob": 0.0011578473495319486}, {"id": 3, "seek": 2000, "start": 29.0, "end": 37.0, "text": " I'm a member of a few teams. So, I'm in the Rust doc team. Not to be confused with the former documentation team.", "tokens": [286, 478, 257, 4006, 295, 257, 1326, 5491, 13, 407, 11, 286, 478, 294, 264, 34952, 3211, 1469, 13, 1726, 281, 312, 9019, 365, 264, 5819, 14333, 1469, 13], "temperature": 0.0, "avg_logprob": -0.24736341563138095, "compression_ratio": 1.5741626794258374, "no_speech_prob": 0.0011578473495319486}, {"id": 4, "seek": 2000, "start": 37.0, "end": 48.0, "text": " Also, Docs.Rust team and DevTools team. So, very documentation oriented. And I'm working at Huawei currently.", "tokens": [2743, 11, 16024, 82, 13, 49, 381, 1469, 293, 9096, 51, 29298, 1469, 13, 407, 11, 588, 14333, 21841, 13, 400, 286, 478, 1364, 412, 28542, 4362, 13], "temperature": 0.0, "avg_logprob": -0.24736341563138095, "compression_ratio": 1.5741626794258374, "no_speech_prob": 0.0011578473495319486}, {"id": 5, "seek": 4800, "start": 48.0, "end": 57.0, "text": " So, we will start by taking a scenario. Hold on.", "tokens": [407, 11, 321, 486, 722, 538, 1940, 257, 9005, 13, 6962, 322, 13], "temperature": 0.0, "avg_logprob": -0.13482118264222756, "compression_ratio": 1.6242774566473988, "no_speech_prob": 0.0012079165317118168}, {"id": 6, "seek": 4800, "start": 57.0, "end": 66.0, "text": " So, when you have made a pull request, you open it. And the first thing that will happen on the pull request will be that", "tokens": [407, 11, 562, 291, 362, 1027, 257, 2235, 5308, 11, 291, 1269, 309, 13, 400, 264, 700, 551, 300, 486, 1051, 322, 264, 2235, 5308, 486, 312, 300], "temperature": 0.0, "avg_logprob": -0.13482118264222756, "compression_ratio": 1.6242774566473988, "no_speech_prob": 0.0012079165317118168}, {"id": 7, "seek": 4800, "start": 66.0, "end": 76.0, "text": " the bot will assign you a reviewer. So, in this case, myself. So, very likely pull request on a Rust doc tool.", "tokens": [264, 10592, 486, 6269, 291, 257, 3131, 260, 13, 407, 11, 294, 341, 1389, 11, 2059, 13, 407, 11, 588, 3700, 2235, 5308, 322, 257, 34952, 3211, 2290, 13], "temperature": 0.0, "avg_logprob": -0.13482118264222756, "compression_ratio": 1.6242774566473988, "no_speech_prob": 0.0012079165317118168}, {"id": 8, "seek": 7600, "start": 76.0, "end": 83.0, "text": " And after that, you will have some tags. So, it's waiting on review and it's concerning the Rust doc team,", "tokens": [400, 934, 300, 11, 291, 486, 362, 512, 18632, 13, 407, 11, 309, 311, 3806, 322, 3131, 293, 309, 311, 18087, 264, 34952, 3211, 1469, 11], "temperature": 0.0, "avg_logprob": -0.09490012478184055, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.0004926449037156999}, {"id": 9, "seek": 7600, "start": 83.0, "end": 95.0, "text": " which helps us to find the right people in case the reviewer assigned isn't available in a week, if I remember correctly.", "tokens": [597, 3665, 505, 281, 915, 264, 558, 561, 294, 1389, 264, 3131, 260, 13279, 1943, 380, 2435, 294, 257, 1243, 11, 498, 286, 1604, 8944, 13], "temperature": 0.0, "avg_logprob": -0.09490012478184055, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.0004926449037156999}, {"id": 10, "seek": 7600, "start": 95.0, "end": 101.0, "text": " So, explanation a bit about how the bot is picking the people.", "tokens": [407, 11, 10835, 257, 857, 466, 577, 264, 10592, 307, 8867, 264, 561, 13], "temperature": 0.0, "avg_logprob": -0.09490012478184055, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.0004926449037156999}, {"id": 11, "seek": 10100, "start": 101.0, "end": 110.0, "text": " So, we have a repository with the list of all teams and its members, formers and everything.", "tokens": [407, 11, 321, 362, 257, 25841, 365, 264, 1329, 295, 439, 5491, 293, 1080, 2679, 11, 1254, 433, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.19258000932890793, "compression_ratio": 1.5063291139240507, "no_speech_prob": 0.0016986018745228648}, {"id": 12, "seek": 10100, "start": 110.0, "end": 116.0, "text": " And the bot basically pick someone from this repository.", "tokens": [400, 264, 10592, 1936, 1888, 1580, 490, 341, 25841, 13], "temperature": 0.0, "avg_logprob": -0.19258000932890793, "compression_ratio": 1.5063291139240507, "no_speech_prob": 0.0016986018745228648}, {"id": 13, "seek": 10100, "start": 116.0, "end": 124.0, "text": " And this website, the governance page on the Rust long.org website is generated from it.", "tokens": [400, 341, 3144, 11, 264, 17449, 3028, 322, 264, 34952, 938, 13, 4646, 3144, 307, 10833, 490, 309, 13], "temperature": 0.0, "avg_logprob": -0.19258000932890793, "compression_ratio": 1.5063291139240507, "no_speech_prob": 0.0016986018745228648}, {"id": 14, "seek": 12400, "start": 124.0, "end": 134.0, "text": " So, if you need to contact someone from one of the teams, whatever reason, that's where you go.", "tokens": [407, 11, 498, 291, 643, 281, 3385, 1580, 490, 472, 295, 264, 5491, 11, 2035, 1778, 11, 300, 311, 689, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.095870294068989, "compression_ratio": 1.48, "no_speech_prob": 0.0002474954817444086}, {"id": 15, "seek": 12400, "start": 134.0, "end": 144.0, "text": " So, now the approval itself. So, let's say that the pull request is implemented with no request from the reviewer or anything.", "tokens": [407, 11, 586, 264, 13317, 2564, 13, 407, 11, 718, 311, 584, 300, 264, 2235, 5308, 307, 12270, 365, 572, 5308, 490, 264, 3131, 260, 420, 1340, 13], "temperature": 0.0, "avg_logprob": -0.095870294068989, "compression_ratio": 1.48, "no_speech_prob": 0.0002474954817444086}, {"id": 16, "seek": 14400, "start": 144.0, "end": 160.0, "text": " If it has no performance impact for this to have this information, if we have a depth, we have tools automated that allow us to actually check its actually the case.", "tokens": [759, 309, 575, 572, 3389, 2712, 337, 341, 281, 362, 341, 1589, 11, 498, 321, 362, 257, 7161, 11, 321, 362, 3873, 18473, 300, 2089, 505, 281, 767, 1520, 1080, 767, 264, 1389, 13], "temperature": 0.0, "avg_logprob": -0.21634483337402344, "compression_ratio": 1.5408805031446542, "no_speech_prob": 0.0010627422016113997}, {"id": 17, "seek": 14400, "start": 160.0, "end": 168.0, "text": " So, if needed, we just say, hey, Rust bot, can you run a perfect check on this?", "tokens": [407, 11, 498, 2978, 11, 321, 445, 584, 11, 4177, 11, 34952, 10592, 11, 393, 291, 1190, 257, 2176, 1520, 322, 341, 30], "temperature": 0.0, "avg_logprob": -0.21634483337402344, "compression_ratio": 1.5408805031446542, "no_speech_prob": 0.0010627422016113997}, {"id": 18, "seek": 16800, "start": 168.0, "end": 175.0, "text": " We come back to this later and we have a very nice page with some metrics and a lot of steps.", "tokens": [492, 808, 646, 281, 341, 1780, 293, 321, 362, 257, 588, 1481, 3028, 365, 512, 16367, 293, 257, 688, 295, 4439, 13], "temperature": 0.0, "avg_logprob": -0.10722954104645084, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0005717647145502269}, {"id": 19, "seek": 16800, "start": 175.0, "end": 181.0, "text": " So, another important thing is checking that there is no breaking change.", "tokens": [407, 11, 1071, 1021, 551, 307, 8568, 300, 456, 307, 572, 7697, 1319, 13], "temperature": 0.0, "avg_logprob": -0.10722954104645084, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0005717647145502269}, {"id": 20, "seek": 16800, "start": 181.0, "end": 189.0, "text": " So, of course, if you are changing something in the STD, for example, or changing how projection works on anything,", "tokens": [407, 11, 295, 1164, 11, 498, 291, 366, 4473, 746, 294, 264, 4904, 35, 11, 337, 1365, 11, 420, 4473, 577, 22743, 1985, 322, 1340, 11], "temperature": 0.0, "avg_logprob": -0.10722954104645084, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0005717647145502269}, {"id": 21, "seek": 16800, "start": 189.0, "end": 194.0, "text": " then it becomes a lot more complex and the process becomes a lot longer.", "tokens": [550, 309, 3643, 257, 688, 544, 3997, 293, 264, 1399, 3643, 257, 688, 2854, 13], "temperature": 0.0, "avg_logprob": -0.10722954104645084, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0005717647145502269}, {"id": 22, "seek": 16800, "start": 194.0, "end": 197.0, "text": " Same, we will come back to this later.", "tokens": [10635, 11, 321, 486, 808, 646, 281, 341, 1780, 13], "temperature": 0.0, "avg_logprob": -0.10722954104645084, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0005717647145502269}, {"id": 23, "seek": 19700, "start": 197.0, "end": 212.0, "text": " So, if it adds a new feature, it's very likely that we will need to be sure at 100% that it's not something that we'll need to change or deprecate or literally just remove at some point", "tokens": [407, 11, 498, 309, 10860, 257, 777, 4111, 11, 309, 311, 588, 3700, 300, 321, 486, 643, 281, 312, 988, 412, 2319, 4, 300, 309, 311, 406, 746, 300, 321, 603, 643, 281, 1319, 420, 1367, 13867, 473, 420, 3736, 445, 4159, 412, 512, 935], "temperature": 0.0, "avg_logprob": -0.14283570682301241, "compression_ratio": 1.502439024390244, "no_speech_prob": 0.000597173348069191}, {"id": 24, "seek": 19700, "start": 212.0, "end": 216.0, "text": " because it happened a few times and it's not great.", "tokens": [570, 309, 2011, 257, 1326, 1413, 293, 309, 311, 406, 869, 13], "temperature": 0.0, "avg_logprob": -0.14283570682301241, "compression_ratio": 1.502439024390244, "no_speech_prob": 0.000597173348069191}, {"id": 25, "seek": 19700, "start": 216.0, "end": 219.0, "text": " And obviously, the CI must pass.", "tokens": [400, 2745, 11, 264, 37777, 1633, 1320, 13], "temperature": 0.0, "avg_logprob": -0.14283570682301241, "compression_ratio": 1.502439024390244, "no_speech_prob": 0.000597173348069191}, {"id": 26, "seek": 19700, "start": 219.0, "end": 225.0, "text": " So, that's a lot of small conditions.", "tokens": [407, 11, 300, 311, 257, 688, 295, 1359, 4487, 13], "temperature": 0.0, "avg_logprob": -0.14283570682301241, "compression_ratio": 1.502439024390244, "no_speech_prob": 0.000597173348069191}, {"id": 27, "seek": 22500, "start": 225.0, "end": 227.0, "text": " So, now about the CI.", "tokens": [407, 11, 586, 466, 264, 37777, 13], "temperature": 0.0, "avg_logprob": -0.12101270841515582, "compression_ratio": 1.4514563106796117, "no_speech_prob": 0.0005784428212791681}, {"id": 28, "seek": 22500, "start": 227.0, "end": 230.0, "text": " So, there are two levels of CI.", "tokens": [407, 11, 456, 366, 732, 4358, 295, 37777, 13], "temperature": 0.0, "avg_logprob": -0.12101270841515582, "compression_ratio": 1.4514563106796117, "no_speech_prob": 0.0005784428212791681}, {"id": 29, "seek": 22500, "start": 230.0, "end": 234.0, "text": " The one that you will see directly when you open the pull request.", "tokens": [440, 472, 300, 291, 486, 536, 3838, 562, 291, 1269, 264, 2235, 5308, 13], "temperature": 0.0, "avg_logprob": -0.12101270841515582, "compression_ratio": 1.4514563106796117, "no_speech_prob": 0.0005784428212791681}, {"id": 30, "seek": 22500, "start": 234.0, "end": 238.0, "text": " It's a lot of tests, almost all of them.", "tokens": [467, 311, 257, 688, 295, 6921, 11, 1920, 439, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.12101270841515582, "compression_ratio": 1.4514563106796117, "no_speech_prob": 0.0005784428212791681}, {"id": 31, "seek": 22500, "start": 238.0, "end": 251.0, "text": " But it's only on Linux X64 because, as you may know, we support quite a lot of targets, not as much as GCC yet, but at some point, maybe.", "tokens": [583, 309, 311, 787, 322, 18734, 1783, 19395, 570, 11, 382, 291, 815, 458, 11, 321, 1406, 1596, 257, 688, 295, 12911, 11, 406, 382, 709, 382, 460, 11717, 1939, 11, 457, 412, 512, 935, 11, 1310, 13], "temperature": 0.0, "avg_logprob": -0.12101270841515582, "compression_ratio": 1.4514563106796117, "no_speech_prob": 0.0005784428212791681}, {"id": 32, "seek": 25100, "start": 251.0, "end": 263.0, "text": " And this checks, for example, if the call is wait-formatted, if you have all the tests passing, and by all the tests, I mean literally all the tests,", "tokens": [400, 341, 13834, 11, 337, 1365, 11, 498, 264, 818, 307, 1699, 12, 837, 32509, 11, 498, 291, 362, 439, 264, 6921, 8437, 11, 293, 538, 439, 264, 6921, 11, 286, 914, 3736, 439, 264, 6921, 11], "temperature": 0.0, "avg_logprob": -0.26225773493448895, "compression_ratio": 1.830601092896175, "no_speech_prob": 0.0003001030709128827}, {"id": 33, "seek": 25100, "start": 263.0, "end": 270.0, "text": " so you have all the rest of the tool suite, tool test suite, the compiler error output,", "tokens": [370, 291, 362, 439, 264, 1472, 295, 264, 2290, 14205, 11, 2290, 1500, 14205, 11, 264, 31958, 6713, 5598, 11], "temperature": 0.0, "avg_logprob": -0.26225773493448895, "compression_ratio": 1.830601092896175, "no_speech_prob": 0.0003001030709128827}, {"id": 34, "seek": 25100, "start": 270.0, "end": 278.0, "text": " the compiler checks if the code is giving the right result, the assembly, pretty much everything,", "tokens": [264, 31958, 13834, 498, 264, 3089, 307, 2902, 264, 558, 1874, 11, 264, 12103, 11, 1238, 709, 1203, 11], "temperature": 0.0, "avg_logprob": -0.26225773493448895, "compression_ratio": 1.830601092896175, "no_speech_prob": 0.0003001030709128827}, {"id": 35, "seek": 27800, "start": 278.0, "end": 287.0, "text": " and it includes the tools. So, if you made a change in the compiler that breaks a tool, like REST doc, Clippy, or REST FMT,", "tokens": [293, 309, 5974, 264, 3873, 13, 407, 11, 498, 291, 1027, 257, 1319, 294, 264, 31958, 300, 9857, 257, 2290, 11, 411, 497, 14497, 3211, 11, 2033, 48363, 11, 420, 497, 14497, 29614, 51, 11], "temperature": 0.0, "avg_logprob": -0.153493476636482, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.00016934493032749742}, {"id": 36, "seek": 27800, "start": 287.0, "end": 290.0, "text": " then we need to be aware of it right away.", "tokens": [550, 321, 643, 281, 312, 3650, 295, 309, 558, 1314, 13], "temperature": 0.0, "avg_logprob": -0.153493476636482, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.00016934493032749742}, {"id": 37, "seek": 27800, "start": 290.0, "end": 294.0, "text": " Otherwise, we are going to have quite a bite time.", "tokens": [10328, 11, 321, 366, 516, 281, 362, 1596, 257, 7988, 565, 13], "temperature": 0.0, "avg_logprob": -0.153493476636482, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.00016934493032749742}, {"id": 38, "seek": 27800, "start": 294.0, "end": 298.0, "text": " And all that is done directly on the pull request.", "tokens": [400, 439, 300, 307, 1096, 3838, 322, 264, 2235, 5308, 13], "temperature": 0.0, "avg_logprob": -0.153493476636482, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.00016934493032749742}, {"id": 39, "seek": 27800, "start": 298.0, "end": 306.0, "text": " So, at the current time, it takes around one hour to run this small subset.", "tokens": [407, 11, 412, 264, 2190, 565, 11, 309, 2516, 926, 472, 1773, 281, 1190, 341, 1359, 25993, 13], "temperature": 0.0, "avg_logprob": -0.153493476636482, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.00016934493032749742}, {"id": 40, "seek": 30600, "start": 306.0, "end": 317.0, "text": " And when the pull request has been approved, we make the full run of all these tests and for all platforms.", "tokens": [400, 562, 264, 2235, 5308, 575, 668, 10826, 11, 321, 652, 264, 1577, 1190, 295, 439, 613, 6921, 293, 337, 439, 9473, 13], "temperature": 0.0, "avg_logprob": -0.14685220567006912, "compression_ratio": 1.4853801169590644, "no_speech_prob": 0.00026057884679175913}, {"id": 41, "seek": 30600, "start": 317.0, "end": 329.0, "text": " And this time, it's run, I think if I remember correctly, it's like on 40 targets or something like that, and it takes roughly around three hours.", "tokens": [400, 341, 565, 11, 309, 311, 1190, 11, 286, 519, 498, 286, 1604, 8944, 11, 309, 311, 411, 322, 3356, 12911, 420, 746, 411, 300, 11, 293, 309, 2516, 9810, 926, 1045, 2496, 13], "temperature": 0.0, "avg_logprob": -0.14685220567006912, "compression_ratio": 1.4853801169590644, "no_speech_prob": 0.00026057884679175913}, {"id": 42, "seek": 32900, "start": 329.0, "end": 336.0, "text": " We have our own infra for this. We have dedicated the team for that too, the infra team.", "tokens": [492, 362, 527, 1065, 23654, 337, 341, 13, 492, 362, 8374, 264, 1469, 337, 300, 886, 11, 264, 23654, 1469, 13], "temperature": 0.0, "avg_logprob": -0.13215149918647662, "compression_ratio": 1.5057471264367817, "no_speech_prob": 0.00035549866151995957}, {"id": 43, "seek": 32900, "start": 336.0, "end": 341.0, "text": " And I think it's currently done on AWS to be confirmed.", "tokens": [400, 286, 519, 309, 311, 4362, 1096, 322, 17650, 281, 312, 11341, 13], "temperature": 0.0, "avg_logprob": -0.13215149918647662, "compression_ratio": 1.5057471264367817, "no_speech_prob": 0.00035549866151995957}, {"id": 44, "seek": 32900, "start": 341.0, "end": 346.0, "text": " But in short, nothing can be merged if the CI doesn't pass.", "tokens": [583, 294, 2099, 11, 1825, 393, 312, 36427, 498, 264, 37777, 1177, 380, 1320, 13], "temperature": 0.0, "avg_logprob": -0.13215149918647662, "compression_ratio": 1.5057471264367817, "no_speech_prob": 0.00035549866151995957}, {"id": 45, "seek": 32900, "start": 346.0, "end": 351.0, "text": " We enforced this, I think it was three or four years ago.", "tokens": [492, 40953, 341, 11, 286, 519, 309, 390, 1045, 420, 1451, 924, 2057, 13], "temperature": 0.0, "avg_logprob": -0.13215149918647662, "compression_ratio": 1.5057471264367817, "no_speech_prob": 0.00035549866151995957}, {"id": 46, "seek": 35100, "start": 351.0, "end": 360.0, "text": " A few things that were merged and were expected to be fixed in very soon coming fixes were quite bad experiences,", "tokens": [316, 1326, 721, 300, 645, 36427, 293, 645, 5176, 281, 312, 6806, 294, 588, 2321, 1348, 32539, 645, 1596, 1578, 5235, 11], "temperature": 0.0, "avg_logprob": -0.17818977649395282, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.0005405207048170269}, {"id": 47, "seek": 35100, "start": 360.0, "end": 364.0, "text": " and we decided to have a zero-tolerance policy.", "tokens": [293, 321, 3047, 281, 362, 257, 4018, 12, 83, 27035, 719, 3897, 13], "temperature": 0.0, "avg_logprob": -0.17818977649395282, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.0005405207048170269}, {"id": 48, "seek": 35100, "start": 364.0, "end": 369.0, "text": " It's working quite nice, so currently we keep it.", "tokens": [467, 311, 1364, 1596, 1481, 11, 370, 4362, 321, 1066, 309, 13], "temperature": 0.0, "avg_logprob": -0.17818977649395282, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.0005405207048170269}, {"id": 49, "seek": 35100, "start": 369.0, "end": 371.0, "text": " So now it's a build queue.", "tokens": [407, 586, 309, 311, 257, 1322, 18639, 13], "temperature": 0.0, "avg_logprob": -0.17818977649395282, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.0005405207048170269}, {"id": 50, "seek": 37100, "start": 371.0, "end": 381.0, "text": " When we approve the command with the pull request with the command AddBulls R+, you might have seen it or not.", "tokens": [1133, 321, 18827, 264, 5622, 365, 264, 2235, 5308, 365, 264, 5622, 5349, 33, 858, 82, 497, 46797, 291, 1062, 362, 1612, 309, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.19108965085900348, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.000337196426698938}, {"id": 51, "seek": 37100, "start": 381.0, "end": 388.0, "text": " We have a build queue, and that's where you can see pretty much everything that is happening.", "tokens": [492, 362, 257, 1322, 18639, 11, 293, 300, 311, 689, 291, 393, 536, 1238, 709, 1203, 300, 307, 2737, 13], "temperature": 0.0, "avg_logprob": -0.19108965085900348, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.000337196426698938}, {"id": 52, "seek": 37100, "start": 388.0, "end": 393.0, "text": " So in the current case, you see the pull request, the first one which is pending.", "tokens": [407, 294, 264, 2190, 1389, 11, 291, 536, 264, 2235, 5308, 11, 264, 700, 472, 597, 307, 32110, 13], "temperature": 0.0, "avg_logprob": -0.19108965085900348, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.000337196426698938}, {"id": 53, "seek": 37100, "start": 393.0, "end": 400.0, "text": " So it allows you to see what is being tested and eventually how long it remains.", "tokens": [407, 309, 4045, 291, 281, 536, 437, 307, 885, 8246, 293, 4728, 577, 938, 309, 7023, 13], "temperature": 0.0, "avg_logprob": -0.19108965085900348, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.000337196426698938}, {"id": 54, "seek": 40000, "start": 400.0, "end": 404.0, "text": " And you can see also everything that is approved and everything.", "tokens": [400, 291, 393, 536, 611, 1203, 300, 307, 10826, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.08326833348878672, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.0003717888321261853}, {"id": 55, "seek": 40000, "start": 404.0, "end": 411.0, "text": " And it's sorted by priority first, which you can see because I had to make a small screenshot.", "tokens": [400, 309, 311, 25462, 538, 9365, 700, 11, 597, 291, 393, 536, 570, 286, 632, 281, 652, 257, 1359, 27712, 13], "temperature": 0.0, "avg_logprob": -0.08326833348878672, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.0003717888321261853}, {"id": 56, "seek": 40000, "start": 411.0, "end": 417.0, "text": " And the second thing is how old the pull request is.", "tokens": [400, 264, 1150, 551, 307, 577, 1331, 264, 2235, 5308, 307, 13], "temperature": 0.0, "avg_logprob": -0.08326833348878672, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.0003717888321261853}, {"id": 57, "seek": 40000, "start": 417.0, "end": 425.0, "text": " We generally have around 20 pull requests at the same time in this build queue.", "tokens": [492, 5101, 362, 926, 945, 2235, 12475, 412, 264, 912, 565, 294, 341, 1322, 18639, 13], "temperature": 0.0, "avg_logprob": -0.08326833348878672, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.0003717888321261853}, {"id": 58, "seek": 42500, "start": 425.0, "end": 430.0, "text": " So to make things faster, we have what we call a roll-up process.", "tokens": [407, 281, 652, 721, 4663, 11, 321, 362, 437, 321, 818, 257, 3373, 12, 1010, 1399, 13], "temperature": 0.0, "avg_logprob": -0.11499740563186944, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00018849404295906425}, {"id": 59, "seek": 42500, "start": 430.0, "end": 436.0, "text": " We group a full pull request that we are sure have no performance impact or anything.", "tokens": [492, 1594, 257, 1577, 2235, 5308, 300, 321, 366, 988, 362, 572, 3389, 2712, 420, 1340, 13], "temperature": 0.0, "avg_logprob": -0.11499740563186944, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00018849404295906425}, {"id": 60, "seek": 42500, "start": 436.0, "end": 440.0, "text": " And we say, okay, make a roll-up of five pull requests.", "tokens": [400, 321, 584, 11, 1392, 11, 652, 257, 3373, 12, 1010, 295, 1732, 2235, 12475, 13], "temperature": 0.0, "avg_logprob": -0.11499740563186944, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00018849404295906425}, {"id": 61, "seek": 42500, "start": 440.0, "end": 443.0, "text": " You can see the button, create a roll-up.", "tokens": [509, 393, 536, 264, 2960, 11, 1884, 257, 3373, 12, 1010, 13], "temperature": 0.0, "avg_logprob": -0.11499740563186944, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00018849404295906425}, {"id": 62, "seek": 42500, "start": 443.0, "end": 447.0, "text": " So we pick a few pull requests and we click on the button,", "tokens": [407, 321, 1888, 257, 1326, 2235, 12475, 293, 321, 2052, 322, 264, 2960, 11], "temperature": 0.0, "avg_logprob": -0.11499740563186944, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00018849404295906425}, {"id": 63, "seek": 42500, "start": 447.0, "end": 451.0, "text": " and it generates a pull request for us with our account.", "tokens": [293, 309, 23815, 257, 2235, 5308, 337, 505, 365, 527, 2696, 13], "temperature": 0.0, "avg_logprob": -0.11499740563186944, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00018849404295906425}, {"id": 64, "seek": 45100, "start": 451.0, "end": 455.0, "text": " And after that, we give it quite a high priority and like that,", "tokens": [400, 934, 300, 11, 321, 976, 309, 1596, 257, 1090, 9365, 293, 411, 300, 11], "temperature": 0.0, "avg_logprob": -0.10512262166932572, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00017069770547095686}, {"id": 65, "seek": 45100, "start": 455.0, "end": 459.0, "text": " we can have a big bunch of pull requests to merge at once.", "tokens": [321, 393, 362, 257, 955, 3840, 295, 2235, 12475, 281, 22183, 412, 1564, 13], "temperature": 0.0, "avg_logprob": -0.10512262166932572, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00017069770547095686}, {"id": 66, "seek": 45100, "start": 459.0, "end": 461.0, "text": " Very useful.", "tokens": [4372, 4420, 13], "temperature": 0.0, "avg_logprob": -0.10512262166932572, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00017069770547095686}, {"id": 67, "seek": 45100, "start": 461.0, "end": 464.0, "text": " And that is for the build queue.", "tokens": [400, 300, 307, 337, 264, 1322, 18639, 13], "temperature": 0.0, "avg_logprob": -0.10512262166932572, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00017069770547095686}, {"id": 68, "seek": 45100, "start": 464.0, "end": 468.0, "text": " So what I explained a bit before, what is tested.", "tokens": [407, 437, 286, 8825, 257, 857, 949, 11, 437, 307, 8246, 13], "temperature": 0.0, "avg_logprob": -0.10512262166932572, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00017069770547095686}, {"id": 69, "seek": 45100, "start": 468.0, "end": 470.0, "text": " So we have the compile test.", "tokens": [407, 321, 362, 264, 31413, 1500, 13], "temperature": 0.0, "avg_logprob": -0.10512262166932572, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00017069770547095686}, {"id": 70, "seek": 45100, "start": 470.0, "end": 474.0, "text": " So if your code is supposed to compile or not,", "tokens": [407, 498, 428, 3089, 307, 3442, 281, 31413, 420, 406, 11], "temperature": 0.0, "avg_logprob": -0.10512262166932572, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00017069770547095686}, {"id": 71, "seek": 47400, "start": 474.0, "end": 481.0, "text": " because, for example, we want to ensure certain cases in very weird cases that don't compile", "tokens": [570, 11, 337, 1365, 11, 321, 528, 281, 5586, 1629, 3331, 294, 588, 3657, 3331, 300, 500, 380, 31413], "temperature": 0.0, "avg_logprob": -0.11133486649085736, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.0004889669944532216}, {"id": 72, "seek": 47400, "start": 481.0, "end": 484.0, "text": " or in other cases compile.", "tokens": [420, 294, 661, 3331, 31413, 13], "temperature": 0.0, "avg_logprob": -0.11133486649085736, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.0004889669944532216}, {"id": 73, "seek": 47400, "start": 484.0, "end": 489.0, "text": " And that's how you can discover things like you can't implement directly on projections.", "tokens": [400, 300, 311, 577, 291, 393, 4411, 721, 411, 291, 393, 380, 4445, 3838, 322, 32371, 13], "temperature": 0.0, "avg_logprob": -0.11133486649085736, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.0004889669944532216}, {"id": 74, "seek": 47400, "start": 489.0, "end": 493.0, "text": " And if that doesn't speak much to you, it's a good sign.", "tokens": [400, 498, 300, 1177, 380, 1710, 709, 281, 291, 11, 309, 311, 257, 665, 1465, 13], "temperature": 0.0, "avg_logprob": -0.11133486649085736, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.0004889669944532216}, {"id": 75, "seek": 47400, "start": 493.0, "end": 496.0, "text": " We have all the unit tests.", "tokens": [492, 362, 439, 264, 4985, 6921, 13], "temperature": 0.0, "avg_logprob": -0.11133486649085736, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.0004889669944532216}, {"id": 76, "seek": 47400, "start": 496.0, "end": 499.0, "text": " Unit tests are mostly for the tools.", "tokens": [27894, 6921, 366, 5240, 337, 264, 3873, 13], "temperature": 0.0, "avg_logprob": -0.11133486649085736, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.0004889669944532216}, {"id": 77, "seek": 49900, "start": 499.0, "end": 508.0, "text": " But we have a few tests with, like I mentioned, just below the error output.", "tokens": [583, 321, 362, 257, 1326, 6921, 365, 11, 411, 286, 2835, 11, 445, 2507, 264, 6713, 5598, 13], "temperature": 0.0, "avg_logprob": -0.19407962281026958, "compression_ratio": 1.5989583333333333, "no_speech_prob": 0.0004240615526214242}, {"id": 78, "seek": 49900, "start": 508.0, "end": 510.0, "text": " It's quite important.", "tokens": [467, 311, 1596, 1021, 13], "temperature": 0.0, "avg_logprob": -0.19407962281026958, "compression_ratio": 1.5989583333333333, "no_speech_prob": 0.0004240615526214242}, {"id": 79, "seek": 49900, "start": 510.0, "end": 517.0, "text": " So we ensure that the Rust doc and the Rusty errors are looking exactly as you might expect.", "tokens": [407, 321, 5586, 300, 264, 34952, 3211, 293, 264, 34952, 88, 13603, 366, 1237, 2293, 382, 291, 1062, 2066, 13], "temperature": 0.0, "avg_logprob": -0.19407962281026958, "compression_ratio": 1.5989583333333333, "no_speech_prob": 0.0004240615526214242}, {"id": 80, "seek": 49900, "start": 517.0, "end": 522.0, "text": " If you ever used, and I think a lot of you used already Rust,", "tokens": [759, 291, 1562, 1143, 11, 293, 286, 519, 257, 688, 295, 291, 1143, 1217, 34952, 11], "temperature": 0.0, "avg_logprob": -0.19407962281026958, "compression_ratio": 1.5989583333333333, "no_speech_prob": 0.0004240615526214242}, {"id": 81, "seek": 49900, "start": 522.0, "end": 528.0, "text": " you might have appreciated the errors and the output.", "tokens": [291, 1062, 362, 17169, 264, 13603, 293, 264, 5598, 13], "temperature": 0.0, "avg_logprob": -0.19407962281026958, "compression_ratio": 1.5989583333333333, "no_speech_prob": 0.0004240615526214242}, {"id": 82, "seek": 52800, "start": 528.0, "end": 531.0, "text": " Yes, because they are very, very strongly tested.", "tokens": [1079, 11, 570, 436, 366, 588, 11, 588, 10613, 8246, 13], "temperature": 0.0, "avg_logprob": -0.09269113456253457, "compression_ratio": 1.5703125, "no_speech_prob": 0.00019334722310304642}, {"id": 83, "seek": 52800, "start": 531.0, "end": 536.0, "text": " Currently, just for the UI test, we have around 20,000 tests.", "tokens": [19964, 11, 445, 337, 264, 15682, 1500, 11, 321, 362, 926, 945, 11, 1360, 6921, 13], "temperature": 0.0, "avg_logprob": -0.09269113456253457, "compression_ratio": 1.5703125, "no_speech_prob": 0.00019334722310304642}, {"id": 84, "seek": 52800, "start": 536.0, "end": 538.0, "text": " So it's quite monstrous.", "tokens": [407, 309, 311, 1596, 47137, 563, 13], "temperature": 0.0, "avg_logprob": -0.09269113456253457, "compression_ratio": 1.5703125, "no_speech_prob": 0.00019334722310304642}, {"id": 85, "seek": 52800, "start": 538.0, "end": 541.0, "text": " And running it takes quite some time.", "tokens": [400, 2614, 309, 2516, 1596, 512, 565, 13], "temperature": 0.0, "avg_logprob": -0.09269113456253457, "compression_ratio": 1.5703125, "no_speech_prob": 0.00019334722310304642}, {"id": 86, "seek": 52800, "start": 541.0, "end": 544.0, "text": " I think it's, well, at least 10 minutes, something like that.", "tokens": [286, 519, 309, 311, 11, 731, 11, 412, 1935, 1266, 2077, 11, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.09269113456253457, "compression_ratio": 1.5703125, "no_speech_prob": 0.00019334722310304642}, {"id": 87, "seek": 52800, "start": 544.0, "end": 546.0, "text": " It's quite heavy.", "tokens": [467, 311, 1596, 4676, 13], "temperature": 0.0, "avg_logprob": -0.09269113456253457, "compression_ratio": 1.5703125, "no_speech_prob": 0.00019334722310304642}, {"id": 88, "seek": 52800, "start": 546.0, "end": 552.0, "text": " Maybe you don't know it, but the documentation example are tested, all of them.", "tokens": [2704, 291, 500, 380, 458, 309, 11, 457, 264, 14333, 1365, 366, 8246, 11, 439, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.09269113456253457, "compression_ratio": 1.5703125, "no_speech_prob": 0.00019334722310304642}, {"id": 89, "seek": 52800, "start": 552.0, "end": 557.0, "text": " You can just test them manually in your code by running cargo test.", "tokens": [509, 393, 445, 1500, 552, 16945, 294, 428, 3089, 538, 2614, 19449, 1500, 13], "temperature": 0.0, "avg_logprob": -0.09269113456253457, "compression_ratio": 1.5703125, "no_speech_prob": 0.00019334722310304642}, {"id": 90, "seek": 55700, "start": 557.0, "end": 561.0, "text": " The cargo tool will take all the unit tests in your code.", "tokens": [440, 19449, 2290, 486, 747, 439, 264, 4985, 6921, 294, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.12502305074171585, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.0005812629824504256}, {"id": 91, "seek": 55700, "start": 561.0, "end": 564.0, "text": " The test folder will run on everything.", "tokens": [440, 1500, 10820, 486, 1190, 322, 1203, 13], "temperature": 0.0, "avg_logprob": -0.12502305074171585, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.0005812629824504256}, {"id": 92, "seek": 55700, "start": 564.0, "end": 568.0, "text": " And it includes, of course, everything that is in the documentation.", "tokens": [400, 309, 5974, 11, 295, 1164, 11, 1203, 300, 307, 294, 264, 14333, 13], "temperature": 0.0, "avg_logprob": -0.12502305074171585, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.0005812629824504256}, {"id": 93, "seek": 55700, "start": 568.0, "end": 579.0, "text": " So that allows us to reduce the maintenance burden by being sure that we don't give examples that are not compiling anymore", "tokens": [407, 300, 4045, 505, 281, 5407, 264, 11258, 12578, 538, 885, 988, 300, 321, 500, 380, 976, 5110, 300, 366, 406, 715, 4883, 3602], "temperature": 0.0, "avg_logprob": -0.12502305074171585, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.0005812629824504256}, {"id": 94, "seek": 55700, "start": 579.0, "end": 582.0, "text": " or completely broken, quite useful.", "tokens": [420, 2584, 5463, 11, 1596, 4420, 13], "temperature": 0.0, "avg_logprob": -0.12502305074171585, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.0005812629824504256}, {"id": 95, "seek": 55700, "start": 582.0, "end": 584.0, "text": " Once again, it reduces the burden.", "tokens": [3443, 797, 11, 309, 18081, 264, 12578, 13], "temperature": 0.0, "avg_logprob": -0.12502305074171585, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.0005812629824504256}, {"id": 96, "seek": 58400, "start": 584.0, "end": 587.0, "text": " And, of course, we have all the tools.", "tokens": [400, 11, 295, 1164, 11, 321, 362, 439, 264, 3873, 13], "temperature": 0.0, "avg_logprob": -0.18758483808867785, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00039674306754022837}, {"id": 97, "seek": 58400, "start": 587.0, "end": 590.0, "text": " So cargo, RustDoc, Clippy, RustFMT.", "tokens": [407, 19449, 11, 34952, 35, 905, 11, 2033, 48363, 11, 34952, 37, 44, 51, 13], "temperature": 0.0, "avg_logprob": -0.18758483808867785, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00039674306754022837}, {"id": 98, "seek": 58400, "start": 590.0, "end": 594.0, "text": " So as I mentioned, when you change something on the compiler, sorry,", "tokens": [407, 382, 286, 2835, 11, 562, 291, 1319, 746, 322, 264, 31958, 11, 2597, 11], "temperature": 0.0, "avg_logprob": -0.18758483808867785, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00039674306754022837}, {"id": 99, "seek": 58400, "start": 594.0, "end": 597.0, "text": " when you change something in the compiler,", "tokens": [562, 291, 1319, 746, 294, 264, 31958, 11], "temperature": 0.0, "avg_logprob": -0.18758483808867785, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00039674306754022837}, {"id": 100, "seek": 58400, "start": 597.0, "end": 601.0, "text": " since these tools are using directly the compiler,", "tokens": [1670, 613, 3873, 366, 1228, 3838, 264, 31958, 11], "temperature": 0.0, "avg_logprob": -0.18758483808867785, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00039674306754022837}, {"id": 101, "seek": 58400, "start": 601.0, "end": 604.0, "text": " they are actually compiler extensions except cargo.", "tokens": [436, 366, 767, 31958, 25129, 3993, 19449, 13], "temperature": 0.0, "avg_logprob": -0.18758483808867785, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00039674306754022837}, {"id": 102, "seek": 58400, "start": 604.0, "end": 609.0, "text": " Cargo is just tested to ensure that not a new option is breaking something.", "tokens": [2741, 1571, 307, 445, 8246, 281, 5586, 300, 406, 257, 777, 3614, 307, 7697, 746, 13], "temperature": 0.0, "avg_logprob": -0.18758483808867785, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00039674306754022837}, {"id": 103, "seek": 60900, "start": 609.0, "end": 616.0, "text": " So for the others, they are extensions of the compiler and we need to ensure that no changes is breaking anything", "tokens": [407, 337, 264, 2357, 11, 436, 366, 25129, 295, 264, 31958, 293, 321, 643, 281, 5586, 300, 572, 2962, 307, 7697, 1340], "temperature": 0.0, "avg_logprob": -0.10702526569366455, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0002699424512684345}, {"id": 104, "seek": 60900, "start": 616.0, "end": 619.0, "text": " because that would be problematic.", "tokens": [570, 300, 576, 312, 19011, 13], "temperature": 0.0, "avg_logprob": -0.10702526569366455, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0002699424512684345}, {"id": 105, "seek": 60900, "start": 619.0, "end": 626.0, "text": " We generate a lot of documentation and we have to ensure that we have no deadlinks.", "tokens": [492, 8460, 257, 688, 295, 14333, 293, 321, 362, 281, 5586, 300, 321, 362, 572, 3116, 75, 16431, 13], "temperature": 0.0, "avg_logprob": -0.10702526569366455, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0002699424512684345}, {"id": 106, "seek": 60900, "start": 626.0, "end": 631.0, "text": " And, in fact, we do have some of them and we ignore them on purpose.", "tokens": [400, 11, 294, 1186, 11, 321, 360, 362, 512, 295, 552, 293, 321, 11200, 552, 322, 4334, 13], "temperature": 0.0, "avg_logprob": -0.10702526569366455, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0002699424512684345}, {"id": 107, "seek": 60900, "start": 631.0, "end": 632.0, "text": " So sorry for that.", "tokens": [407, 2597, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.10702526569366455, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0002699424512684345}, {"id": 108, "seek": 60900, "start": 632.0, "end": 638.0, "text": " We can't fix them because, funnily enough, in the STD, we re-export stuff that is in the core", "tokens": [492, 393, 380, 3191, 552, 570, 11, 1019, 77, 953, 1547, 11, 294, 264, 4904, 35, 11, 321, 319, 12, 3121, 2707, 1507, 300, 307, 294, 264, 4965], "temperature": 0.0, "avg_logprob": -0.10702526569366455, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0002699424512684345}, {"id": 109, "seek": 63800, "start": 638.0, "end": 640.0, "text": " and they share the same documentation.", "tokens": [293, 436, 2073, 264, 912, 14333, 13], "temperature": 0.0, "avg_logprob": -0.13403911391894022, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00024776096688583493}, {"id": 110, "seek": 63800, "start": 640.0, "end": 645.0, "text": " So if you are looking at the documentation in the STD pages,", "tokens": [407, 498, 291, 366, 1237, 412, 264, 14333, 294, 264, 4904, 35, 7183, 11], "temperature": 0.0, "avg_logprob": -0.13403911391894022, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00024776096688583493}, {"id": 111, "seek": 63800, "start": 645.0, "end": 649.0, "text": " all the links are working in the core create.", "tokens": [439, 264, 6123, 366, 1364, 294, 264, 4965, 1884, 13], "temperature": 0.0, "avg_logprob": -0.13403911391894022, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00024776096688583493}, {"id": 112, "seek": 63800, "start": 649.0, "end": 650.0, "text": " They're not.", "tokens": [814, 434, 406, 13], "temperature": 0.0, "avg_logprob": -0.13403911391894022, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00024776096688583493}, {"id": 113, "seek": 63800, "start": 650.0, "end": 653.0, "text": " So try to use STD as much as possible.", "tokens": [407, 853, 281, 764, 4904, 35, 382, 709, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.13403911391894022, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00024776096688583493}, {"id": 114, "seek": 63800, "start": 653.0, "end": 657.0, "text": " And it's just very basic, but we have quite a lot more.", "tokens": [400, 309, 311, 445, 588, 3875, 11, 457, 321, 362, 1596, 257, 688, 544, 13], "temperature": 0.0, "avg_logprob": -0.13403911391894022, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00024776096688583493}, {"id": 115, "seek": 63800, "start": 657.0, "end": 662.0, "text": " We mentioned in the previous talk, the inline assembly, it's part of the things.", "tokens": [492, 2835, 294, 264, 3894, 751, 11, 264, 294, 1889, 12103, 11, 309, 311, 644, 295, 264, 721, 13], "temperature": 0.0, "avg_logprob": -0.13403911391894022, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00024776096688583493}, {"id": 116, "seek": 66200, "start": 662.0, "end": 671.0, "text": " Something we realized when working on the GCC backend this time is that GCC doesn't allow to specify a syntax", "tokens": [6595, 321, 5334, 562, 1364, 322, 264, 460, 11717, 38087, 341, 565, 307, 300, 460, 11717, 1177, 380, 2089, 281, 16500, 257, 28431], "temperature": 0.0, "avg_logprob": -0.134120120797106, "compression_ratio": 1.5407725321888412, "no_speech_prob": 8.806744153844193e-05}, {"id": 117, "seek": 66200, "start": 671.0, "end": 674.0, "text": " that's thanks to this test suite.", "tokens": [300, 311, 3231, 281, 341, 1500, 14205, 13], "temperature": 0.0, "avg_logprob": -0.134120120797106, "compression_ratio": 1.5407725321888412, "no_speech_prob": 8.806744153844193e-05}, {"id": 118, "seek": 66200, "start": 674.0, "end": 679.0, "text": " So currently, we can't implement all features and it's going to take quite a long time,", "tokens": [407, 4362, 11, 321, 393, 380, 4445, 439, 4122, 293, 309, 311, 516, 281, 747, 1596, 257, 938, 565, 11], "temperature": 0.0, "avg_logprob": -0.134120120797106, "compression_ratio": 1.5407725321888412, "no_speech_prob": 8.806744153844193e-05}, {"id": 119, "seek": 66200, "start": 679.0, "end": 683.0, "text": " but hopefully at some point, someone motivated will do it.", "tokens": [457, 4696, 412, 512, 935, 11, 1580, 14515, 486, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.134120120797106, "compression_ratio": 1.5407725321888412, "no_speech_prob": 8.806744153844193e-05}, {"id": 120, "seek": 66200, "start": 683.0, "end": 685.0, "text": " Don't know.", "tokens": [1468, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.134120120797106, "compression_ratio": 1.5407725321888412, "no_speech_prob": 8.806744153844193e-05}, {"id": 121, "seek": 66200, "start": 685.0, "end": 690.0, "text": " So on which OS and architectures are tested, everything.", "tokens": [407, 322, 597, 12731, 293, 6331, 1303, 366, 8246, 11, 1203, 13], "temperature": 0.0, "avg_logprob": -0.134120120797106, "compression_ratio": 1.5407725321888412, "no_speech_prob": 8.806744153844193e-05}, {"id": 122, "seek": 69000, "start": 690.0, "end": 694.0, "text": " We have target tier policy.", "tokens": [492, 362, 3779, 12362, 3897, 13], "temperature": 0.0, "avg_logprob": -0.15358694791793823, "compression_ratio": 1.5561224489795917, "no_speech_prob": 0.0003946041688323021}, {"id": 123, "seek": 69000, "start": 694.0, "end": 698.0, "text": " You can go check it on the page just linked below.", "tokens": [509, 393, 352, 1520, 309, 322, 264, 3028, 445, 9408, 2507, 13], "temperature": 0.0, "avg_logprob": -0.15358694791793823, "compression_ratio": 1.5561224489795917, "no_speech_prob": 0.0003946041688323021}, {"id": 124, "seek": 69000, "start": 698.0, "end": 703.0, "text": " But basically tier one, the platforms are the platforms that are fully tested,", "tokens": [583, 1936, 12362, 472, 11, 264, 9473, 366, 264, 9473, 300, 366, 4498, 8246, 11], "temperature": 0.0, "avg_logprob": -0.15358694791793823, "compression_ratio": 1.5561224489795917, "no_speech_prob": 0.0003946041688323021}, {"id": 125, "seek": 69000, "start": 703.0, "end": 705.0, "text": " implemented, and everything.", "tokens": [12270, 11, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.15358694791793823, "compression_ratio": 1.5561224489795917, "no_speech_prob": 0.0003946041688323021}, {"id": 126, "seek": 69000, "start": 705.0, "end": 708.0, "text": " So macOS, Linux, and Windows.", "tokens": [407, 7912, 4367, 11, 18734, 11, 293, 8591, 13], "temperature": 0.0, "avg_logprob": -0.15358694791793823, "compression_ratio": 1.5561224489795917, "no_speech_prob": 0.0003946041688323021}, {"id": 127, "seek": 69000, "start": 708.0, "end": 715.0, "text": " And they must pass all the tests and we build them and we ensure that what we have built", "tokens": [400, 436, 1633, 1320, 439, 264, 6921, 293, 321, 1322, 552, 293, 321, 5586, 300, 437, 321, 362, 3094], "temperature": 0.0, "avg_logprob": -0.15358694791793823, "compression_ratio": 1.5561224489795917, "no_speech_prob": 0.0003946041688323021}, {"id": 128, "seek": 71500, "start": 715.0, "end": 721.0, "text": " and has to be able to be uncomplaced and working on the target and everything.", "tokens": [293, 575, 281, 312, 1075, 281, 312, 8585, 564, 3839, 293, 1364, 322, 264, 3779, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.08918653353296145, "compression_ratio": 1.6544502617801047, "no_speech_prob": 0.00013325666077435017}, {"id": 129, "seek": 71500, "start": 721.0, "end": 724.0, "text": " So strict, very strict restriction.", "tokens": [407, 10910, 11, 588, 10910, 29529, 13], "temperature": 0.0, "avg_logprob": -0.08918653353296145, "compression_ratio": 1.6544502617801047, "no_speech_prob": 0.00013325666077435017}, {"id": 130, "seek": 71500, "start": 724.0, "end": 728.0, "text": " On the tier two platforms, it's a lot more relaxed.", "tokens": [1282, 264, 12362, 732, 9473, 11, 309, 311, 257, 688, 544, 14628, 13], "temperature": 0.0, "avg_logprob": -0.08918653353296145, "compression_ratio": 1.6544502617801047, "no_speech_prob": 0.00013325666077435017}, {"id": 131, "seek": 71500, "start": 728.0, "end": 730.0, "text": " We just need it to build.", "tokens": [492, 445, 643, 309, 281, 1322, 13], "temperature": 0.0, "avg_logprob": -0.08918653353296145, "compression_ratio": 1.6544502617801047, "no_speech_prob": 0.00013325666077435017}, {"id": 132, "seek": 71500, "start": 730.0, "end": 732.0, "text": " If it works, well, it's good.", "tokens": [759, 309, 1985, 11, 731, 11, 309, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.08918653353296145, "compression_ratio": 1.6544502617801047, "no_speech_prob": 0.00013325666077435017}, {"id": 133, "seek": 71500, "start": 732.0, "end": 735.0, "text": " If it doesn't, well, too bad.", "tokens": [759, 309, 1177, 380, 11, 731, 11, 886, 1578, 13], "temperature": 0.0, "avg_logprob": -0.08918653353296145, "compression_ratio": 1.6544502617801047, "no_speech_prob": 0.00013325666077435017}, {"id": 134, "seek": 71500, "start": 735.0, "end": 739.0, "text": " And for the tier three platforms, it exists.", "tokens": [400, 337, 264, 12362, 1045, 9473, 11, 309, 8198, 13], "temperature": 0.0, "avg_logprob": -0.08918653353296145, "compression_ratio": 1.6544502617801047, "no_speech_prob": 0.00013325666077435017}, {"id": 135, "seek": 71500, "start": 739.0, "end": 741.0, "text": " Yeah, that's good.", "tokens": [865, 11, 300, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.08918653353296145, "compression_ratio": 1.6544502617801047, "no_speech_prob": 0.00013325666077435017}, {"id": 136, "seek": 74100, "start": 741.0, "end": 747.0, "text": " So for example, if you want to build on the Nintendo 3DS, you can.", "tokens": [407, 337, 1365, 11, 498, 291, 528, 281, 1322, 322, 264, 11578, 805, 11844, 11, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.10131211800150353, "compression_ratio": 1.508695652173913, "no_speech_prob": 0.00017418261268176138}, {"id": 137, "seek": 74100, "start": 747.0, "end": 750.0, "text": " We don't know if it would work, but you can.", "tokens": [492, 500, 380, 458, 498, 309, 576, 589, 11, 457, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.10131211800150353, "compression_ratio": 1.508695652173913, "no_speech_prob": 0.00017418261268176138}, {"id": 138, "seek": 74100, "start": 750.0, "end": 756.0, "text": " And you can see the list of the platforms each tier on the page just below.", "tokens": [400, 291, 393, 536, 264, 1329, 295, 264, 9473, 1184, 12362, 322, 264, 3028, 445, 2507, 13], "temperature": 0.0, "avg_logprob": -0.10131211800150353, "compression_ratio": 1.508695652173913, "no_speech_prob": 0.00017418261268176138}, {"id": 139, "seek": 74100, "start": 756.0, "end": 762.0, "text": " Like I mentioned, we have quite a lot and we hope to be able to expand it a bit more", "tokens": [1743, 286, 2835, 11, 321, 362, 1596, 257, 688, 293, 321, 1454, 281, 312, 1075, 281, 5268, 309, 257, 857, 544], "temperature": 0.0, "avg_logprob": -0.10131211800150353, "compression_ratio": 1.508695652173913, "no_speech_prob": 0.00017418261268176138}, {"id": 140, "seek": 74100, "start": 762.0, "end": 767.0, "text": " by adding at least the GCC backend at some point.", "tokens": [538, 5127, 412, 1935, 264, 460, 11717, 38087, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.10131211800150353, "compression_ratio": 1.508695652173913, "no_speech_prob": 0.00017418261268176138}, {"id": 141, "seek": 74100, "start": 767.0, "end": 770.0, "text": " A lot of work remaining.", "tokens": [316, 688, 295, 589, 8877, 13], "temperature": 0.0, "avg_logprob": -0.10131211800150353, "compression_ratio": 1.508695652173913, "no_speech_prob": 0.00017418261268176138}, {"id": 142, "seek": 77000, "start": 770.0, "end": 772.0, "text": " So what about releases now?", "tokens": [407, 437, 466, 16952, 586, 30], "temperature": 0.0, "avg_logprob": -0.11381909426520853, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.00042476155795156956}, {"id": 143, "seek": 77000, "start": 772.0, "end": 776.0, "text": " Because as you might know, we make a release every six weeks.", "tokens": [1436, 382, 291, 1062, 458, 11, 321, 652, 257, 4374, 633, 2309, 3259, 13], "temperature": 0.0, "avg_logprob": -0.11381909426520853, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.00042476155795156956}, {"id": 144, "seek": 77000, "start": 776.0, "end": 780.0, "text": " So it's very fast release cycle.", "tokens": [407, 309, 311, 588, 2370, 4374, 6586, 13], "temperature": 0.0, "avg_logprob": -0.11381909426520853, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.00042476155795156956}, {"id": 145, "seek": 77000, "start": 780.0, "end": 784.0, "text": " So when this happens, the build queue is frozen.", "tokens": [407, 562, 341, 2314, 11, 264, 1322, 18639, 307, 12496, 13], "temperature": 0.0, "avg_logprob": -0.11381909426520853, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.00042476155795156956}, {"id": 146, "seek": 77000, "start": 784.0, "end": 789.0, "text": " We don't allow anything below like a priority of 10,000 to be merged.", "tokens": [492, 500, 380, 2089, 1340, 2507, 411, 257, 9365, 295, 1266, 11, 1360, 281, 312, 36427, 13], "temperature": 0.0, "avg_logprob": -0.11381909426520853, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.00042476155795156956}, {"id": 147, "seek": 77000, "start": 789.0, "end": 795.0, "text": " It's a completely random number, but generally if you go higher than 10, it's quite important.", "tokens": [467, 311, 257, 2584, 4974, 1230, 11, 457, 5101, 498, 291, 352, 2946, 813, 1266, 11, 309, 311, 1596, 1021, 13], "temperature": 0.0, "avg_logprob": -0.11381909426520853, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.00042476155795156956}, {"id": 148, "seek": 77000, "start": 795.0, "end": 798.0, "text": " So in this case, we freeze everything.", "tokens": [407, 294, 341, 1389, 11, 321, 15959, 1203, 13], "temperature": 0.0, "avg_logprob": -0.11381909426520853, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.00042476155795156956}, {"id": 149, "seek": 79800, "start": 798.0, "end": 807.0, "text": " And the only things allowed to be merged are the patches to make actually the stable and beta branches update.", "tokens": [400, 264, 787, 721, 4350, 281, 312, 36427, 366, 264, 26531, 281, 652, 767, 264, 8351, 293, 9861, 14770, 5623, 13], "temperature": 0.0, "avg_logprob": -0.1439994970957438, "compression_ratio": 1.5891089108910892, "no_speech_prob": 0.00019474729197099805}, {"id": 150, "seek": 79800, "start": 807.0, "end": 815.0, "text": " An important thing that isn't noted here is that we don't have the need to freeze for the nightly.", "tokens": [1107, 1021, 551, 300, 1943, 380, 12964, 510, 307, 300, 321, 500, 380, 362, 264, 643, 281, 15959, 337, 264, 1818, 356, 13], "temperature": 0.0, "avg_logprob": -0.1439994970957438, "compression_ratio": 1.5891089108910892, "no_speech_prob": 0.00019474729197099805}, {"id": 151, "seek": 79800, "start": 815.0, "end": 821.0, "text": " We just say at a given time of every day, okay, this will be the nightly version for today.", "tokens": [492, 445, 584, 412, 257, 2212, 565, 295, 633, 786, 11, 1392, 11, 341, 486, 312, 264, 1818, 356, 3037, 337, 965, 13], "temperature": 0.0, "avg_logprob": -0.1439994970957438, "compression_ratio": 1.5891089108910892, "no_speech_prob": 0.00019474729197099805}, {"id": 152, "seek": 79800, "start": 821.0, "end": 824.0, "text": " Yay, and that's it.", "tokens": [13268, 11, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.1439994970957438, "compression_ratio": 1.5891089108910892, "no_speech_prob": 0.00019474729197099805}, {"id": 153, "seek": 82400, "start": 824.0, "end": 828.0, "text": " So back to this, the third point.", "tokens": [407, 646, 281, 341, 11, 264, 2636, 935, 13], "temperature": 0.0, "avg_logprob": -0.1958827322179621, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00018029134662356228}, {"id": 154, "seek": 82400, "start": 828.0, "end": 832.0, "text": " All relevant information is updated and reared.", "tokens": [1057, 7340, 1589, 307, 10588, 293, 319, 1642, 13], "temperature": 0.0, "avg_logprob": -0.1958827322179621, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00018029134662356228}, {"id": 155, "seek": 82400, "start": 832.0, "end": 839.0, "text": " And by that, I mean the websites, the documentation, the book, I think, too.", "tokens": [400, 538, 300, 11, 286, 914, 264, 12891, 11, 264, 14333, 11, 264, 1446, 11, 286, 519, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.1958827322179621, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00018029134662356228}, {"id": 156, "seek": 82400, "start": 839.0, "end": 840.0, "text": " Pretty much everything.", "tokens": [10693, 709, 1203, 13], "temperature": 0.0, "avg_logprob": -0.1958827322179621, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00018029134662356228}, {"id": 157, "seek": 82400, "start": 840.0, "end": 842.0, "text": " We generate the binaries.", "tokens": [492, 8460, 264, 5171, 4889, 13], "temperature": 0.0, "avg_logprob": -0.1958827322179621, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00018029134662356228}, {"id": 158, "seek": 82400, "start": 842.0, "end": 844.0, "text": " So that's what I mentioned.", "tokens": [407, 300, 311, 437, 286, 2835, 13], "temperature": 0.0, "avg_logprob": -0.1958827322179621, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00018029134662356228}, {"id": 159, "seek": 82400, "start": 844.0, "end": 851.0, "text": " That's the things that need to be working for at least tier one polyform.", "tokens": [663, 311, 264, 721, 300, 643, 281, 312, 1364, 337, 412, 1935, 12362, 472, 6754, 837, 13], "temperature": 0.0, "avg_logprob": -0.1958827322179621, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00018029134662356228}, {"id": 160, "seek": 85100, "start": 851.0, "end": 854.0, "text": " And of course, we make a blog post.", "tokens": [400, 295, 1164, 11, 321, 652, 257, 6968, 2183, 13], "temperature": 0.0, "avg_logprob": -0.16192119066105332, "compression_ratio": 1.6386138613861385, "no_speech_prob": 0.00035920896334573627}, {"id": 161, "seek": 85100, "start": 854.0, "end": 861.0, "text": " Generally, the blog post is written not for the current stable release, but we write it at the beta version.", "tokens": [21082, 11, 264, 6968, 2183, 307, 3720, 406, 337, 264, 2190, 8351, 4374, 11, 457, 321, 2464, 309, 412, 264, 9861, 3037, 13], "temperature": 0.0, "avg_logprob": -0.16192119066105332, "compression_ratio": 1.6386138613861385, "no_speech_prob": 0.00035920896334573627}, {"id": 162, "seek": 85100, "start": 861.0, "end": 869.0, "text": " And then depending if we need the backports, for example, we realize that in the current beta version,", "tokens": [400, 550, 5413, 498, 321, 643, 264, 646, 17845, 11, 337, 1365, 11, 321, 4325, 300, 294, 264, 2190, 9861, 3037, 11], "temperature": 0.0, "avg_logprob": -0.16192119066105332, "compression_ratio": 1.6386138613861385, "no_speech_prob": 0.00035920896334573627}, {"id": 163, "seek": 85100, "start": 869.0, "end": 872.0, "text": " something is completely broken and we don't want that.", "tokens": [746, 307, 2584, 5463, 293, 321, 500, 380, 528, 300, 13], "temperature": 0.0, "avg_logprob": -0.16192119066105332, "compression_ratio": 1.6386138613861385, "no_speech_prob": 0.00035920896334573627}, {"id": 164, "seek": 85100, "start": 872.0, "end": 874.0, "text": " And it's an easy enough fix.", "tokens": [400, 309, 311, 364, 1858, 1547, 3191, 13], "temperature": 0.0, "avg_logprob": -0.16192119066105332, "compression_ratio": 1.6386138613861385, "no_speech_prob": 0.00035920896334573627}, {"id": 165, "seek": 87400, "start": 874.0, "end": 881.0, "text": " Either we backport a patch that was merged on the nightly directly onto the beta branch.", "tokens": [13746, 321, 646, 2707, 257, 9972, 300, 390, 36427, 322, 264, 1818, 356, 3838, 3911, 264, 9861, 9819, 13], "temperature": 0.0, "avg_logprob": -0.12424137436340903, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0003020792792085558}, {"id": 166, "seek": 87400, "start": 881.0, "end": 883.0, "text": " Or we say, okay, too bad.", "tokens": [1610, 321, 584, 11, 1392, 11, 886, 1578, 13], "temperature": 0.0, "avg_logprob": -0.12424137436340903, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0003020792792085558}, {"id": 167, "seek": 87400, "start": 883.0, "end": 887.0, "text": " We revert that and we'll do it the next time.", "tokens": [492, 319, 3281, 300, 293, 321, 603, 360, 309, 264, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.12424137436340903, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0003020792792085558}, {"id": 168, "seek": 87400, "start": 887.0, "end": 889.0, "text": " It happened quite a lot.", "tokens": [467, 2011, 1596, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.12424137436340903, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0003020792792085558}, {"id": 169, "seek": 87400, "start": 889.0, "end": 892.0, "text": " And it's not uncommon.", "tokens": [400, 309, 311, 406, 29289, 13], "temperature": 0.0, "avg_logprob": -0.12424137436340903, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0003020792792085558}, {"id": 170, "seek": 87400, "start": 892.0, "end": 894.0, "text": " Let's just say it's better if it doesn't happen.", "tokens": [961, 311, 445, 584, 309, 311, 1101, 498, 309, 1177, 380, 1051, 13], "temperature": 0.0, "avg_logprob": -0.12424137436340903, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0003020792792085558}, {"id": 171, "seek": 87400, "start": 894.0, "end": 902.0, "text": " It allows us to not have the dot one version coming up like a three days later because we realize that we broke something.", "tokens": [467, 4045, 505, 281, 406, 362, 264, 5893, 472, 3037, 1348, 493, 411, 257, 1045, 1708, 1780, 570, 321, 4325, 300, 321, 6902, 746, 13], "temperature": 0.0, "avg_logprob": -0.12424137436340903, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0003020792792085558}, {"id": 172, "seek": 90200, "start": 902.0, "end": 906.0, "text": " And the blog post is released.", "tokens": [400, 264, 6968, 2183, 307, 4736, 13], "temperature": 0.0, "avg_logprob": -0.10200863006787422, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.00041398644680157304}, {"id": 173, "seek": 90200, "start": 906.0, "end": 908.0, "text": " So now a performance.", "tokens": [407, 586, 257, 3389, 13], "temperature": 0.0, "avg_logprob": -0.10200863006787422, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.00041398644680157304}, {"id": 174, "seek": 90200, "start": 908.0, "end": 913.0, "text": " What I mentioned is that we need to check sometimes the performance.", "tokens": [708, 286, 2835, 307, 300, 321, 643, 281, 1520, 2171, 264, 3389, 13], "temperature": 0.0, "avg_logprob": -0.10200863006787422, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.00041398644680157304}, {"id": 175, "seek": 90200, "start": 913.0, "end": 915.0, "text": " So we have to speed it now.", "tokens": [407, 321, 362, 281, 3073, 309, 586, 13], "temperature": 0.0, "avg_logprob": -0.10200863006787422, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.00041398644680157304}, {"id": 176, "seek": 90200, "start": 915.0, "end": 921.0, "text": " So for the performance, we have a lot of benchmarks you can see on the left.", "tokens": [407, 337, 264, 3389, 11, 321, 362, 257, 688, 295, 43751, 291, 393, 536, 322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.10200863006787422, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.00041398644680157304}, {"id": 177, "seek": 90200, "start": 921.0, "end": 925.0, "text": " It's generally for the number of instructions that have been written.", "tokens": [467, 311, 5101, 337, 264, 1230, 295, 9415, 300, 362, 668, 3720, 13], "temperature": 0.0, "avg_logprob": -0.10200863006787422, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.00041398644680157304}, {"id": 178, "seek": 92500, "start": 925.0, "end": 933.0, "text": " It's what we consider the most important metric and most, let's say, stable.", "tokens": [467, 311, 437, 321, 1949, 264, 881, 1021, 20678, 293, 881, 11, 718, 311, 584, 11, 8351, 13], "temperature": 0.0, "avg_logprob": -0.1333609390258789, "compression_ratio": 1.75, "no_speech_prob": 0.00033207889646291733}, {"id": 179, "seek": 92500, "start": 933.0, "end": 941.0, "text": " So when you have all green numbers and quite high, oh, yeah, 8%, yeah, that's quite right.", "tokens": [407, 562, 291, 362, 439, 3092, 3547, 293, 1596, 1090, 11, 1954, 11, 1338, 11, 1649, 8923, 1338, 11, 300, 311, 1596, 558, 13], "temperature": 0.0, "avg_logprob": -0.1333609390258789, "compression_ratio": 1.75, "no_speech_prob": 0.00033207889646291733}, {"id": 180, "seek": 92500, "start": 941.0, "end": 945.0, "text": " So when you have all green numbers, it's green and everyone is parting.", "tokens": [407, 562, 291, 362, 439, 3092, 3547, 11, 309, 311, 3092, 293, 1518, 307, 46607, 13], "temperature": 0.0, "avg_logprob": -0.1333609390258789, "compression_ratio": 1.75, "no_speech_prob": 0.00033207889646291733}, {"id": 181, "seek": 92500, "start": 945.0, "end": 954.0, "text": " And if you have all red numbers, either you have a very good reason or it's not going to be merged until you can make them at least black.", "tokens": [400, 498, 291, 362, 439, 2182, 3547, 11, 2139, 291, 362, 257, 588, 665, 1778, 420, 309, 311, 406, 516, 281, 312, 36427, 1826, 291, 393, 652, 552, 412, 1935, 2211, 13], "temperature": 0.0, "avg_logprob": -0.1333609390258789, "compression_ratio": 1.75, "no_speech_prob": 0.00033207889646291733}, {"id": 182, "seek": 95400, "start": 954.0, "end": 965.0, "text": " And we have, like I said, a lot of metrics like cycles, memory usage, disk usage, because we started to worry about the binary size.", "tokens": [400, 321, 362, 11, 411, 286, 848, 11, 257, 688, 295, 16367, 411, 17796, 11, 4675, 14924, 11, 12355, 14924, 11, 570, 321, 1409, 281, 3292, 466, 264, 17434, 2744, 13], "temperature": 0.0, "avg_logprob": -0.1169991438416229, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.0001820388570195064}, {"id": 183, "seek": 95400, "start": 965.0, "end": 972.0, "text": " We realized that all the doc attributes were generated in the binaries, which is not great.", "tokens": [492, 5334, 300, 439, 264, 3211, 17212, 645, 10833, 294, 264, 5171, 4889, 11, 597, 307, 406, 869, 13], "temperature": 0.0, "avg_logprob": -0.1169991438416229, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.0001820388570195064}, {"id": 184, "seek": 95400, "start": 972.0, "end": 974.0, "text": " So we are going to fix that at some point.", "tokens": [407, 321, 366, 516, 281, 3191, 300, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.1169991438416229, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.0001820388570195064}, {"id": 185, "seek": 95400, "start": 974.0, "end": 978.0, "text": " And you can see on the right that, yeah, maybe you can see.", "tokens": [400, 291, 393, 536, 322, 264, 558, 300, 11, 1338, 11, 1310, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.1169991438416229, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.0001820388570195064}, {"id": 186, "seek": 97800, "start": 978.0, "end": 986.0, "text": " Anyway, just to believe what I say, the results are showed in the nice comment directly on the pull request.", "tokens": [5684, 11, 445, 281, 1697, 437, 286, 584, 11, 264, 3542, 366, 4712, 294, 264, 1481, 2871, 3838, 322, 264, 2235, 5308, 13], "temperature": 0.0, "avg_logprob": -0.15698314535206762, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0003160244959872216}, {"id": 187, "seek": 97800, "start": 986.0, "end": 994.0, "text": " So other cases, when you add a new feature or introduce a breaking change, there are three possibilities.", "tokens": [407, 661, 3331, 11, 562, 291, 909, 257, 777, 4111, 420, 5366, 257, 7697, 1319, 11, 456, 366, 1045, 12178, 13], "temperature": 0.0, "avg_logprob": -0.15698314535206762, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0003160244959872216}, {"id": 188, "seek": 97800, "start": 994.0, "end": 998.0, "text": " The mostly non-one is the RFC, request for comments.", "tokens": [440, 5240, 2107, 12, 546, 307, 264, 497, 18671, 11, 5308, 337, 3053, 13], "temperature": 0.0, "avg_logprob": -0.15698314535206762, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0003160244959872216}, {"id": 189, "seek": 97800, "start": 998.0, "end": 1000.0, "text": " It has its own repository.", "tokens": [467, 575, 1080, 1065, 25841, 13], "temperature": 0.0, "avg_logprob": -0.15698314535206762, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0003160244959872216}, {"id": 190, "seek": 97800, "start": 1000.0, "end": 1003.0, "text": " It takes a lot of time and effort and comments.", "tokens": [467, 2516, 257, 688, 295, 565, 293, 4630, 293, 3053, 13], "temperature": 0.0, "avg_logprob": -0.15698314535206762, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0003160244959872216}, {"id": 191, "seek": 100300, "start": 1003.0, "end": 1010.0, "text": " It can go really fast, like two days, or it can take indefinite amount of time.", "tokens": [467, 393, 352, 534, 2370, 11, 411, 732, 1708, 11, 420, 309, 393, 747, 24162, 5194, 642, 2372, 295, 565, 13], "temperature": 0.0, "avg_logprob": -0.1754151621172505, "compression_ratio": 1.5, "no_speech_prob": 0.00012393947690725327}, {"id": 192, "seek": 100300, "start": 1010.0, "end": 1020.0, "text": " Some examples, some RFCs have been open and still are commented on before the 1.0, so that gives you an idea.", "tokens": [2188, 5110, 11, 512, 497, 18671, 82, 362, 668, 1269, 293, 920, 366, 26940, 322, 949, 264, 502, 13, 15, 11, 370, 300, 2709, 291, 364, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1754151621172505, "compression_ratio": 1.5, "no_speech_prob": 0.00012393947690725327}, {"id": 193, "seek": 100300, "start": 1020.0, "end": 1023.0, "text": " We have the MCP, major compiler changes.", "tokens": [492, 362, 264, 8797, 47, 11, 2563, 31958, 2962, 13], "temperature": 0.0, "avg_logprob": -0.1754151621172505, "compression_ratio": 1.5, "no_speech_prob": 0.00012393947690725327}, {"id": 194, "seek": 100300, "start": 1023.0, "end": 1025.0, "text": " So not too big changes in the compiler.", "tokens": [407, 406, 886, 955, 2962, 294, 264, 31958, 13], "temperature": 0.0, "avg_logprob": -0.1754151621172505, "compression_ratio": 1.5, "no_speech_prob": 0.00012393947690725327}, {"id": 195, "seek": 100300, "start": 1025.0, "end": 1028.0, "text": " We find it not to greet how the query system is working.", "tokens": [492, 915, 309, 406, 281, 12044, 577, 264, 14581, 1185, 307, 1364, 13], "temperature": 0.0, "avg_logprob": -0.1754151621172505, "compression_ratio": 1.5, "no_speech_prob": 0.00012393947690725327}, {"id": 196, "seek": 102800, "start": 1028.0, "end": 1034.0, "text": " So let's try this solution, and they discuss mostly design and very technical points.", "tokens": [407, 718, 311, 853, 341, 3827, 11, 293, 436, 2248, 5240, 1715, 293, 588, 6191, 2793, 13], "temperature": 0.0, "avg_logprob": -0.10040472854267467, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.0003236019692849368}, {"id": 197, "seek": 102800, "start": 1034.0, "end": 1039.0, "text": " Interesting, but if you don't know this area, well, it's not very understandable.", "tokens": [14711, 11, 457, 498, 291, 500, 380, 458, 341, 1859, 11, 731, 11, 309, 311, 406, 588, 25648, 13], "temperature": 0.0, "avg_logprob": -0.10040472854267467, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.0003236019692849368}, {"id": 198, "seek": 102800, "start": 1039.0, "end": 1042.0, "text": " And the last one is common to all teams.", "tokens": [400, 264, 1036, 472, 307, 2689, 281, 439, 5491, 13], "temperature": 0.0, "avg_logprob": -0.10040472854267467, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.0003236019692849368}, {"id": 199, "seek": 102800, "start": 1042.0, "end": 1046.0, "text": " So the FCP, the final comment period, it's something that we want.", "tokens": [407, 264, 479, 20049, 11, 264, 2572, 2871, 2896, 11, 309, 311, 746, 300, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.10040472854267467, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.0003236019692849368}, {"id": 200, "seek": 102800, "start": 1046.0, "end": 1049.0, "text": " And we just want to be sure that everyone is on board.", "tokens": [400, 321, 445, 528, 281, 312, 988, 300, 1518, 307, 322, 3150, 13], "temperature": 0.0, "avg_logprob": -0.10040472854267467, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.0003236019692849368}, {"id": 201, "seek": 104900, "start": 1049.0, "end": 1060.0, "text": " So we ask for an FCP, and once more than half of the members of the team are okay with it, then we approve it, and here we go.", "tokens": [407, 321, 1029, 337, 364, 479, 20049, 11, 293, 1564, 544, 813, 1922, 295, 264, 2679, 295, 264, 1469, 366, 1392, 365, 309, 11, 550, 321, 18827, 309, 11, 293, 510, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.13283084687732516, "compression_ratio": 1.5145631067961165, "no_speech_prob": 0.0002064439031528309}, {"id": 202, "seek": 104900, "start": 1060.0, "end": 1068.0, "text": " So we, of course, for every poll request that is merged, we check for potential examples.", "tokens": [407, 321, 11, 295, 1164, 11, 337, 633, 6418, 5308, 300, 307, 36427, 11, 321, 1520, 337, 3995, 5110, 13], "temperature": 0.0, "avg_logprob": -0.13283084687732516, "compression_ratio": 1.5145631067961165, "no_speech_prob": 0.0002064439031528309}, {"id": 203, "seek": 104900, "start": 1068.0, "end": 1070.0, "text": " No, that's before, sorry.", "tokens": [883, 11, 300, 311, 949, 11, 2597, 13], "temperature": 0.0, "avg_logprob": -0.13283084687732516, "compression_ratio": 1.5145631067961165, "no_speech_prob": 0.0002064439031528309}, {"id": 204, "seek": 104900, "start": 1070.0, "end": 1077.0, "text": " When we make a new feature that potentially changes current behavior,", "tokens": [1133, 321, 652, 257, 777, 4111, 300, 7263, 2962, 2190, 5223, 11], "temperature": 0.0, "avg_logprob": -0.13283084687732516, "compression_ratio": 1.5145631067961165, "no_speech_prob": 0.0002064439031528309}, {"id": 205, "seek": 107700, "start": 1077.0, "end": 1082.0, "text": " we look for potential regressions in all the crates ecosystem.", "tokens": [321, 574, 337, 3995, 1121, 735, 626, 294, 439, 264, 941, 1024, 11311, 13], "temperature": 0.0, "avg_logprob": -0.13924637207618126, "compression_ratio": 1.5592417061611374, "no_speech_prob": 0.00025661606923677027}, {"id": 206, "seek": 107700, "start": 1082.0, "end": 1085.0, "text": " So we make what we call a crater run.", "tokens": [407, 321, 652, 437, 321, 818, 257, 941, 771, 1190, 13], "temperature": 0.0, "avg_logprob": -0.13924637207618126, "compression_ratio": 1.5592417061611374, "no_speech_prob": 0.00025661606923677027}, {"id": 207, "seek": 107700, "start": 1085.0, "end": 1093.0, "text": " And with this version of your code, we run on all crates, and we generate a nice report.", "tokens": [400, 365, 341, 3037, 295, 428, 3089, 11, 321, 1190, 322, 439, 941, 1024, 11, 293, 321, 8460, 257, 1481, 2275, 13], "temperature": 0.0, "avg_logprob": -0.13924637207618126, "compression_ratio": 1.5592417061611374, "no_speech_prob": 0.00025661606923677027}, {"id": 208, "seek": 107700, "start": 1093.0, "end": 1095.0, "text": " You can see on the left.", "tokens": [509, 393, 536, 322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.13924637207618126, "compression_ratio": 1.5592417061611374, "no_speech_prob": 0.00025661606923677027}, {"id": 209, "seek": 107700, "start": 1095.0, "end": 1099.0, "text": " And if you only have flaky stuff, we say, okay, no impact.", "tokens": [400, 498, 291, 787, 362, 932, 15681, 1507, 11, 321, 584, 11, 1392, 11, 572, 2712, 13], "temperature": 0.0, "avg_logprob": -0.13924637207618126, "compression_ratio": 1.5592417061611374, "no_speech_prob": 0.00025661606923677027}, {"id": 210, "seek": 107700, "start": 1099.0, "end": 1100.0, "text": " So it's good.", "tokens": [407, 309, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.13924637207618126, "compression_ratio": 1.5592417061611374, "no_speech_prob": 0.00025661606923677027}, {"id": 211, "seek": 107700, "start": 1100.0, "end": 1103.0, "text": " We don't care, and that's pretty much it.", "tokens": [492, 500, 380, 1127, 11, 293, 300, 311, 1238, 709, 309, 13], "temperature": 0.0, "avg_logprob": -0.13924637207618126, "compression_ratio": 1.5592417061611374, "no_speech_prob": 0.00025661606923677027}, {"id": 212, "seek": 110300, "start": 1103.0, "end": 1111.0, "text": " And same as for the performance, we have a nice comment explaining everything in short,", "tokens": [400, 912, 382, 337, 264, 3389, 11, 321, 362, 257, 1481, 2871, 13468, 1203, 294, 2099, 11], "temperature": 0.0, "avg_logprob": -0.12526823225475492, "compression_ratio": 1.5146198830409356, "no_speech_prob": 0.0008838767535053194}, {"id": 213, "seek": 110300, "start": 1111.0, "end": 1116.0, "text": " which is much more easy to read that the thing on the left, which is actually not good.", "tokens": [597, 307, 709, 544, 1858, 281, 1401, 300, 264, 551, 322, 264, 1411, 11, 597, 307, 767, 406, 665, 13], "temperature": 0.0, "avg_logprob": -0.12526823225475492, "compression_ratio": 1.5146198830409356, "no_speech_prob": 0.0008838767535053194}, {"id": 214, "seek": 110300, "start": 1116.0, "end": 1124.0, "text": " And now a little part I like to do every time, tips for potential new contributors.", "tokens": [400, 586, 257, 707, 644, 286, 411, 281, 360, 633, 565, 11, 6082, 337, 3995, 777, 45627, 13], "temperature": 0.0, "avg_logprob": -0.12526823225475492, "compression_ratio": 1.5146198830409356, "no_speech_prob": 0.0008838767535053194}, {"id": 215, "seek": 112400, "start": 1124.0, "end": 1134.0, "text": " We have a lot of classified tagged issues with ELZ or E-Monitor or both issues.", "tokens": [492, 362, 257, 688, 295, 20627, 40239, 2663, 365, 14426, 57, 420, 462, 12, 32498, 3029, 420, 1293, 2663, 13], "temperature": 0.0, "avg_logprob": -0.14800234808438067, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.0005078123067505658}, {"id": 216, "seek": 112400, "start": 1134.0, "end": 1137.0, "text": " Take a look at them.", "tokens": [3664, 257, 574, 412, 552, 13], "temperature": 0.0, "avg_logprob": -0.14800234808438067, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.0005078123067505658}, {"id": 217, "seek": 112400, "start": 1137.0, "end": 1141.0, "text": " We try to be as helpful as possible to newcomers.", "tokens": [492, 853, 281, 312, 382, 4961, 382, 1944, 281, 40014, 433, 13], "temperature": 0.0, "avg_logprob": -0.14800234808438067, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.0005078123067505658}, {"id": 218, "seek": 112400, "start": 1141.0, "end": 1144.0, "text": " It's important for us to have new blood.", "tokens": [467, 311, 1021, 337, 505, 281, 362, 777, 3390, 13], "temperature": 0.0, "avg_logprob": -0.14800234808438067, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.0005078123067505658}, {"id": 219, "seek": 112400, "start": 1144.0, "end": 1148.0, "text": " We have always good surprises with newcomers.", "tokens": [492, 362, 1009, 665, 22655, 365, 40014, 433, 13], "temperature": 0.0, "avg_logprob": -0.14800234808438067, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.0005078123067505658}, {"id": 220, "seek": 114800, "start": 1148.0, "end": 1154.0, "text": " We wrote a receipt of guide, which is not up-to-date at all.", "tokens": [492, 4114, 257, 33882, 295, 5934, 11, 597, 307, 406, 493, 12, 1353, 12, 17393, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.18657333422929812, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.00048738683108240366}, {"id": 221, "seek": 114800, "start": 1154.0, "end": 1161.0, "text": " So at least you have a vague idea of what's going on, because I think not many people have an idea.", "tokens": [407, 412, 1935, 291, 362, 257, 24247, 1558, 295, 437, 311, 516, 322, 11, 570, 286, 519, 406, 867, 561, 362, 364, 1558, 13], "temperature": 0.0, "avg_logprob": -0.18657333422929812, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.00048738683108240366}, {"id": 222, "seek": 114800, "start": 1161.0, "end": 1168.0, "text": " And you can try also to write compiler plugins or eventually contribute to ClipIt", "tokens": [400, 291, 393, 853, 611, 281, 2464, 31958, 33759, 420, 4728, 10586, 281, 2033, 647, 3522], "temperature": 0.0, "avg_logprob": -0.18657333422929812, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.00048738683108240366}, {"id": 223, "seek": 114800, "start": 1168.0, "end": 1172.0, "text": " to see how the compiler higher internal levels work.", "tokens": [281, 536, 577, 264, 31958, 2946, 6920, 4358, 589, 13], "temperature": 0.0, "avg_logprob": -0.18657333422929812, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.00048738683108240366}, {"id": 224, "seek": 117200, "start": 1172.0, "end": 1178.0, "text": " About ClipIt, it's really simple to contribute to it, like they have a full guide or anything.", "tokens": [7769, 2033, 647, 3522, 11, 309, 311, 534, 2199, 281, 10586, 281, 309, 11, 411, 436, 362, 257, 1577, 5934, 420, 1340, 13], "temperature": 0.0, "avg_logprob": -0.1556585216522217, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0006394472438842058}, {"id": 225, "seek": 117200, "start": 1178.0, "end": 1183.0, "text": " So if you want a big, nice first step, take a look at ClipIt and how it works,", "tokens": [407, 498, 291, 528, 257, 955, 11, 1481, 700, 1823, 11, 747, 257, 574, 412, 2033, 647, 3522, 293, 577, 309, 1985, 11], "temperature": 0.0, "avg_logprob": -0.1556585216522217, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0006394472438842058}, {"id": 226, "seek": 117200, "start": 1183.0, "end": 1187.0, "text": " and it gives a very, very nice introduction.", "tokens": [293, 309, 2709, 257, 588, 11, 588, 1481, 9339, 13], "temperature": 0.0, "avg_logprob": -0.1556585216522217, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0006394472438842058}, {"id": 227, "seek": 117200, "start": 1187.0, "end": 1192.0, "text": " And I am making publicity for myself.", "tokens": [400, 286, 669, 1455, 37264, 337, 2059, 13], "temperature": 0.0, "avg_logprob": -0.1556585216522217, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0006394472438842058}, {"id": 228, "seek": 117200, "start": 1192.0, "end": 1200.0, "text": " I wrote a small receipt towards Crate, which makes a few things simpler to write plugins and extensions to the compiler.", "tokens": [286, 4114, 257, 1359, 33882, 3030, 383, 4404, 11, 597, 1669, 257, 1326, 721, 18587, 281, 2464, 33759, 293, 25129, 281, 264, 31958, 13], "temperature": 0.0, "avg_logprob": -0.1556585216522217, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0006394472438842058}, {"id": 229, "seek": 120000, "start": 1200.0, "end": 1203.0, "text": " If you want to write, go ahead.", "tokens": [759, 291, 528, 281, 2464, 11, 352, 2286, 13], "temperature": 0.0, "avg_logprob": -0.22813309070675872, "compression_ratio": 1.2100840336134453, "no_speech_prob": 0.0005973158986307681}, {"id": 230, "seek": 120000, "start": 1203.0, "end": 1206.0, "text": " It's made to be usable as much as possible.", "tokens": [467, 311, 1027, 281, 312, 29975, 382, 709, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.22813309070675872, "compression_ratio": 1.2100840336134453, "no_speech_prob": 0.0005973158986307681}, {"id": 231, "seek": 120000, "start": 1206.0, "end": 1208.0, "text": " And thank you for listening.", "tokens": [400, 1309, 291, 337, 4764, 13], "temperature": 0.0, "avg_logprob": -0.22813309070675872, "compression_ratio": 1.2100840336134453, "no_speech_prob": 0.0005973158986307681}, {"id": 232, "seek": 120800, "start": 1208.0, "end": 1231.0, "text": " Thank you so much for watching.", "tokens": [50364, 1044, 291, 370, 709, 337, 1976, 13, 51514], "temperature": 0.0, "avg_logprob": -0.7699416637420654, "compression_ratio": 0.7948717948717948, "no_speech_prob": 0.0012281759409233928}], "language": "en"}