{"text": " So, now we have Harry Berstow with an instruction to Gleam, which is another language running on Erlang VM, so give it up for him. Hi, everyone, my name is Harry, and I'm, as was said, an instruction to Gleam. You might ask, why is Gleam? Gleam is a programming language for building type-safe systems that scale, it's powered primarily by the beam, but can also be run on JavaScript targets too. I thought I'd go first into the three key points which make Gleam what it is. First it's safety. Gleam has powerful compile-time type checking built into its core. This helps you write fast code that's integrated with Erlang and Elixir while giving you the safety of a statically typed language. Secondly it's performance, as was just discussed before, building on the success of Discord, WhatsApp, Ericsson, and more with the beam. Gleam adds no overhead, so you get the same great type-safety and performance with an enjoyable syntax. And finally it's friendliness, both the community and the syntax of Gleam are friendly. The community is more than happy to help with any problem or just friendly chit-chat, they even help write some of this talk. And when you get something wrong, the compiler provides insightful help so that you can hunt down the issues and stop them. The syntax of Gleam is similar to that of Rust, but if you're not from one of those backgrounds, don't worry, there are several guides to get started if you're used to a syntax from Python, Elm, Erlang, or even Elixir. Here's an example of the start of the Gleam project. All Gleam projects have an exported main function in the project name.gleam file, which is within your source folder. If you need I.O., you can import the standard libraries I.O. module as shown there. And the standard library contains several modules to help you with everything you can think of, from regex to options, iterators, and more. If you need target-specific standard library features, look at the Gleam, Erlang, and Gleam JavaScript packages, which are both available on Hex and GitHub. Let's explore some Gleam examples to get a better understanding of the language. And once we've done that, you can go away and look at the docs yourself for more examples, and we'll go on to building some stuff with Shimmer. Variables in Gleam are created using the let keyword. They are assigned to a name and a value. The name can be reused later by other let bindings, but the values contained within are immutable, meaning the values themselves cannot be changed. Here's an example of blocks. Every block in Gleam is an expression. All expressions in the block are executed, and then the result of the last expression is returned. So as you can see here, the response will be false, even though hello and 42 plus 12 are evaluated. This can be used to build more advanced expressions where the order of operations is important. Here's an example of using the blocks to convert from Fahrenheit to Celsius, meaning sure to remove the 32 before multiplying and dividing. In Gleam, lists are all homogenous. This means that elements in a list must all be of the same type. If you try and construct a list of multiple types, this will result in a compiler presenting you with a type error and showing you where you try to use the multiple different types, so you can find it and correct it. Planning to a list in Gleam is very fast, and this is the way that Gleam's documentation recommends that you should add new values to a list. In the standard library, there is a list module, which allows you to do more advanced operations and also add to lists that way. The above example uses two constant lists, well, a constant and a constant list, but the same principles apply whether you have one dynamic and the other constant or vice versa. If you need multiple types in one place, you can use two pools using the hash and bracket syntax there. They can have multiple types and can be pattern matched against. We'll look at pattern matching in a few slides, but if you want to access the values on a two-pool, there's always the dot syntax, which I'll show you on the next slide, which is similar to that that you'd be used to in object-oriented for custom types and objects. Here's an example of a two-pool, which has two elements, and they're selected using the dot syntax and assigned to their own variables. It's not particularly useful here because they're constants, but with runtime variables, it's easy to access. Gleam supports custom types, and custom types in Gleam are a collection of keys and their values, and you can see them as objects. There's just one caveat though, types in Gleam don't have methods. Similar to two-pools, you can use the dot syntax to access properties within them, but instead of dot and position, you use dot and the name. In Gleam, custom types can have multiple constructors, similar to in the Rust ecosystem for enums. This does bring another caveat though, which is that the dot syntax now only works for keys that are shared across all elements. In this case, the only key you would be able to use the dot syntax with is name, otherwise you would have to pattern match against them to make sure that type safety stays. Case statements can match anything. In this first example, we use basic integers, but there's more advanced pattern matching over the next couple slides. You can see we match the first three numbers and produce a value, and otherwise we just consume as a variable and say we can either use or discard that variable. Some pattern match against two-pools here and even extract values from within. In this example, we're checking for two specific paths where one is no and the other is yes. The unique thing about the yes path is that we're discarding the integer in the middle, but we could again take that as a variable and do further checks against it. If you remember the custom type from earlier, this pattern matches against that, so we can extract the values into certain variables here, like talks and mic, and the rest can be thrown away with the two dots. You can also use the two dots and assign that to a variable so that then you can reconstruct the type afterwards to pass it back on somewhere else. There's lots more about Gleam syntax that I don't have time to cover today, such as external functions, generics, the use keyword, and more, and stuff's always being added to the syntax. All of it's documented in the language tour, so feel free to have a look over there and get a better understanding of what else is available within Gleam. Now let's get on to building some bots to put our Gleam skills into practice. Shimmer is a library which I've doubled in and out of over the last 13 months. I started as a project to learn Gleam and get into the Beam ecosystem, but in the process I've done much more. I'm doing this talk now, I've started contributing to the Gleam compiler and the wider ecosystem, and I use Elixir and Erlang more day-to-day now. At this point in Shimmer's development, we've moved away from using Erlang foreign functions and now a majority of it is in Gleam. Some key features of Shimmer, first, is compatibility. While Shimmer is built in Gleam, it can be used in Elixir, Erlang, and any other Beam language, it's published on Hex and the source code is available online. I've been working on some examples for Erlang and Elixir, which I'll publish into the GitHub repository once I've got them to a stable point. Secondly, it's actor-based. As we discussed before with its resilience, Shimmer is built on top of actors, and when we're running in single shard mode, you only have one actor, multiple shards, that's not a problem. We use a supervisor tree so that all the shards stay alive, and it's built on top of Erlang's OTP using the Gleam OTP package. And finally, it's type safety. As well as Beam Core to Gleam is a useful feature for Shimmer. While building your Discord bot in Gleam, we leverage all of Gleam's type functionality to ensure that the code you write for the Beam is type safe. You only get the full type safety when you write all of your code in Gleam, but you can always trust that the core of the library will be type safe. It's a little fun fact, moving more and more of Shimmer to Gleam. We're currently at 97% Gleam, and the rest is just Erlang foreign functions for small parts of networking, which are yet to have libraries implemented in Gleam. For some of you, this might now be the most interesting part of the talk, and for some of you, it might not. But I'm just going to quickly touch on how Discord's gateway works so that you have a better understanding of why we use actors and how that's useful to us in Gleam and with the OTP package. Discord Bot is powered by Discord's real-time gateway, which uses WebSockets to send and receive messages. For Shimmer, we use Erlang's gun library from 9.9 to receive them, and we use a typed wrapper on top of that, which is based upon Lewis, the creator of Gleam's Nerf library. The diagram here shows what happens when Shimmer opens a connection to the gateway. We use ETF encoding and hand the frames off to actors to pass, manage them, and send them to the event loop, and eventually either trigger handlers or discard them. Inside of that, Shimmer has a powerful event loop built on top of actors and messages, which manages multiple messages as well as its own state, both internally and externally accepts messages so that you can send updates to Discord, or internally, we can manage the updates. The next slide shows a state diagram, which roughly shows how it works. The state diagram shows what happens at different stages, depending on the initial message. For example, here, if you have a WebSocket frame, it's then passed. We then check whether it's what it's asking us to do. We then either respond, discard it, stop the bot, and then terminate. This diagram isn't complete at all, but it just shows you how complicated it can be very quickly, and how Gleam and the beam can easily handle it. Now that we know some Gleam and understand how Shimmer works under the hood, let's actually get our bot written. Above the boilerplate we're going to use, and as a side note, the final code for all of this is in the GitHub repository, which there's a link to at the end. Shimmer uses a handler-based system, which allows for one function to be registered for each event. For the purpose of this bot, we're only registering two events, but you can always register more as and when they're implemented in Shimmer. But before we have a look at that, let's understand how this code uses what we learned earlier and what it actually does. Here we create a new Shimmer client. Here we use a function that wraps around a custom type. The custom type holds both internal data as well as token, intents, and other data you pass in. So we create a function to wrap it. That way you don't have to manage all of that state yourself. And then we pipe that into the connect function, where it takes the client, passes that as the first parameter, and then passes your handlers in as the second. Normally the token should be an environment variable, but for the purpose of this, we're just using a string. Finally, we'll tell Erlang to sleep forever so that our actor and supervisor can run in the background, accepting messages from the gateway, and passing them to the event loop. Now that we know what it all vaguely does, let's revisit the handlers. First we're going to add a handler for the on-ready event. All handlers are passed in their event, as well as the client. That way you can use the client to call other methods, such as updating the bot's presence or sending messages yourself across the gateway. On the client, there's no private accesses, so you can access all the internal stuff as well if you want to add your own custom functionality. The client has its gun connection and all that other stuff in there as well, so you can adapt that as you please. Let's quickly zoom into the handler and explore that. Here, you can see the event in this case is an on-ready event, which provides us crucial information. As I said before, there's the client that we have just spoken about. The Gleams accesses syntax we learned about earlier makes it easy to access fields within the types, even when they're two levels deep. As you can see here, we're accessing the user's ID, which is in the user field of the event, and then we're printing it to the console using the standard libraries IO. We can then make this into a function, and then we can pass that into our on-ready handler. That way we could have the functions in multiple different files and import them from across the project to keep everything tidy. Let's move on to actually receiving some messages and sending some responses. When we receive a message, we get the on-message payload as our event. This contains information about the message itself, as well as the Guild ID mentions the message content and other variables. For now, we're going to assign the content to a variable for ease, but we can always collapse that into the case statement we use later on if that isn't something you need. Let's have a look how we're going to use our pattern matching to match against the content. Using Gleams' powerful pattern matching, we can check it as a desired prefix, and then we can extract the part to the right of the prefix into a separate variable. If not, we can take the message out itself, and we can just print that for easier debugging for now. Let's say we want a specific command, though. We could either add another case statement onto that, or we could just edit it so it's exclamation mark on what we want as the string of pattern matching against. Let's say, for example, you wanted some arguments, though. You could put the two together, and you could have your prefix with the command and take all of the arguments out separately to then pass and manage them. Now we'll match against a specific command, and in the response, we'll use the message send function to reply to the user by sending another message. As before, we can use the Handler's Builder to add this in as a function, and the bot should be done. Now you have a basic ping pong where you can send and receive messages using basically everything you learned from the introduction earlier. This before code, as I said earlier, was available on the GitHub as well, if you want to have a look and take a deeper dive there. Just to recap, at the start of the talk, we went over some Gleam syntax before we get ready on our exploration of Shimmer. We found out how the Discord's gateway worked on a high level and how to leverage Gleam OTP, and how Gleam OTP is leveraged within Shimmer for Actors. Thank you very much for listening, and if there's some QR codes to the Gleam website as well as the Gleam Discord, if you want to talk there, and if there's any questions, I'm happy to take them if I have time. So there's time for questions. You showed the tuple access syntax, which was tuple dot zero, tuple dot one. Does that mean that if you use a record, or if it's called, can you still use zero as a key? Or is that not? If you use a custom type, no. When you use custom types, you have to use the keys you define in the custom type to access them, the index syntax is only available for tuples. Question there. I have a question about the handlers on the library, and about Gleam, I guess. When I'm writing the handler, do I know what type of the event is, and the client, by the time of writing? Yes, so when a Gleam project is put onto Hex, we produce Hex docs, and they're all documented there as well. So the types on Hex docs you can look at, and also Gleam has an LSP built into it, which gives you the information, which is going to give you the information in your editor. Okay. Hello. If you're used to LX0, what are the things that you would miss in Gleam, or is there a big overlap? There's a fairly, it has most of the features you're used to, along with your type safety. The only, I guess, difference would be in Elixir, you can define multiple modules in one file, whereas in Gleam, that's not really something. Modules are files themselves. I guess that's the only thing I could think of off the top of my head. Right. Thank you. No worries. Is there a microse as well? No, we don't have macros right now, but there has been several discussions about how we want to do them and what they're going to be like, so there's potential for that in the future. Any more questions? Okay. Yeah. I'm sorry. Thank you for your talk. It was very nice. I have one question. I think currently it's version 0.25 of Gleam, or 0.26. 0.26, yeah. I'm sorry. This week. Are there any big hurdles before plans for 1.0, for example? I believe Lewis wants to get LSP features more properly implemented, but you can always join the Discord and talk there. I think Lewis is probably better, but I think we also have a GitHub milestone on the GitHub repository, which says what we want before V1. Any more questions? Okay. Thank you, Aria, again.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.6, "text": " So, now we have Harry Berstow with an instruction to Gleam, which is another language running", "tokens": [407, 11, 586, 321, 362, 9378, 5637, 372, 305, 365, 364, 10951, 281, 460, 306, 335, 11, 597, 307, 1071, 2856, 2614], "temperature": 0.0, "avg_logprob": -0.3766945569943159, "compression_ratio": 1.4424242424242424, "no_speech_prob": 0.13538014888763428}, {"id": 1, "seek": 0, "start": 13.6, "end": 17.400000000000002, "text": " on Erlang VM, so give it up for him.", "tokens": [322, 3300, 25241, 18038, 11, 370, 976, 309, 493, 337, 796, 13], "temperature": 0.0, "avg_logprob": -0.3766945569943159, "compression_ratio": 1.4424242424242424, "no_speech_prob": 0.13538014888763428}, {"id": 2, "seek": 0, "start": 17.400000000000002, "end": 27.12, "text": " Hi, everyone, my name is Harry, and I'm, as was said, an instruction to Gleam.", "tokens": [2421, 11, 1518, 11, 452, 1315, 307, 9378, 11, 293, 286, 478, 11, 382, 390, 848, 11, 364, 10951, 281, 460, 306, 335, 13], "temperature": 0.0, "avg_logprob": -0.3766945569943159, "compression_ratio": 1.4424242424242424, "no_speech_prob": 0.13538014888763428}, {"id": 3, "seek": 0, "start": 27.12, "end": 28.12, "text": " You might ask, why is Gleam?", "tokens": [509, 1062, 1029, 11, 983, 307, 460, 306, 335, 30], "temperature": 0.0, "avg_logprob": -0.3766945569943159, "compression_ratio": 1.4424242424242424, "no_speech_prob": 0.13538014888763428}, {"id": 4, "seek": 2812, "start": 28.12, "end": 32.04, "text": " Gleam is a programming language for building type-safe systems that scale, it's powered", "tokens": [460, 306, 335, 307, 257, 9410, 2856, 337, 2390, 2010, 12, 5790, 2106, 3652, 300, 4373, 11, 309, 311, 17786], "temperature": 0.0, "avg_logprob": -0.2019057651217893, "compression_ratio": 1.6298507462686567, "no_speech_prob": 0.000384215876692906}, {"id": 5, "seek": 2812, "start": 32.04, "end": 35.72, "text": " primarily by the beam, but can also be run on JavaScript targets too.", "tokens": [10029, 538, 264, 14269, 11, 457, 393, 611, 312, 1190, 322, 15778, 12911, 886, 13], "temperature": 0.0, "avg_logprob": -0.2019057651217893, "compression_ratio": 1.6298507462686567, "no_speech_prob": 0.000384215876692906}, {"id": 6, "seek": 2812, "start": 35.72, "end": 40.24, "text": " I thought I'd go first into the three key points which make Gleam what it is.", "tokens": [286, 1194, 286, 1116, 352, 700, 666, 264, 1045, 2141, 2793, 597, 652, 460, 306, 335, 437, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.2019057651217893, "compression_ratio": 1.6298507462686567, "no_speech_prob": 0.000384215876692906}, {"id": 7, "seek": 2812, "start": 40.24, "end": 41.24, "text": " First it's safety.", "tokens": [2386, 309, 311, 4514, 13], "temperature": 0.0, "avg_logprob": -0.2019057651217893, "compression_ratio": 1.6298507462686567, "no_speech_prob": 0.000384215876692906}, {"id": 8, "seek": 2812, "start": 41.24, "end": 45.08, "text": " Gleam has powerful compile-time type checking built into its core.", "tokens": [460, 306, 335, 575, 4005, 31413, 12, 3766, 2010, 8568, 3094, 666, 1080, 4965, 13], "temperature": 0.0, "avg_logprob": -0.2019057651217893, "compression_ratio": 1.6298507462686567, "no_speech_prob": 0.000384215876692906}, {"id": 9, "seek": 2812, "start": 45.08, "end": 49.120000000000005, "text": " This helps you write fast code that's integrated with Erlang and Elixir while giving you the", "tokens": [639, 3665, 291, 2464, 2370, 3089, 300, 311, 10919, 365, 3300, 25241, 293, 2699, 970, 347, 1339, 2902, 291, 264], "temperature": 0.0, "avg_logprob": -0.2019057651217893, "compression_ratio": 1.6298507462686567, "no_speech_prob": 0.000384215876692906}, {"id": 10, "seek": 2812, "start": 49.120000000000005, "end": 52.56, "text": " safety of a statically typed language.", "tokens": [4514, 295, 257, 2219, 984, 33941, 2856, 13], "temperature": 0.0, "avg_logprob": -0.2019057651217893, "compression_ratio": 1.6298507462686567, "no_speech_prob": 0.000384215876692906}, {"id": 11, "seek": 2812, "start": 52.56, "end": 56.400000000000006, "text": " Secondly it's performance, as was just discussed before, building on the success of Discord,", "tokens": [19483, 309, 311, 3389, 11, 382, 390, 445, 7152, 949, 11, 2390, 322, 264, 2245, 295, 32623, 11], "temperature": 0.0, "avg_logprob": -0.2019057651217893, "compression_ratio": 1.6298507462686567, "no_speech_prob": 0.000384215876692906}, {"id": 12, "seek": 5640, "start": 56.4, "end": 58.96, "text": " WhatsApp, Ericsson, and more with the beam.", "tokens": [30513, 11, 3300, 1167, 3015, 11, 293, 544, 365, 264, 14269, 13], "temperature": 0.0, "avg_logprob": -0.15934013215121845, "compression_ratio": 1.7670807453416149, "no_speech_prob": 6.73072281642817e-05}, {"id": 13, "seek": 5640, "start": 58.96, "end": 62.76, "text": " Gleam adds no overhead, so you get the same great type-safety and performance with an", "tokens": [460, 306, 335, 10860, 572, 19922, 11, 370, 291, 483, 264, 912, 869, 2010, 12, 82, 2792, 2210, 293, 3389, 365, 364], "temperature": 0.0, "avg_logprob": -0.15934013215121845, "compression_ratio": 1.7670807453416149, "no_speech_prob": 6.73072281642817e-05}, {"id": 14, "seek": 5640, "start": 62.76, "end": 64.8, "text": " enjoyable syntax.", "tokens": [20305, 28431, 13], "temperature": 0.0, "avg_logprob": -0.15934013215121845, "compression_ratio": 1.7670807453416149, "no_speech_prob": 6.73072281642817e-05}, {"id": 15, "seek": 5640, "start": 64.8, "end": 68.64, "text": " And finally it's friendliness, both the community and the syntax of Gleam are friendly.", "tokens": [400, 2721, 309, 311, 1277, 32268, 11, 1293, 264, 1768, 293, 264, 28431, 295, 460, 306, 335, 366, 9208, 13], "temperature": 0.0, "avg_logprob": -0.15934013215121845, "compression_ratio": 1.7670807453416149, "no_speech_prob": 6.73072281642817e-05}, {"id": 16, "seek": 5640, "start": 68.64, "end": 72.16, "text": " The community is more than happy to help with any problem or just friendly chit-chat, they", "tokens": [440, 1768, 307, 544, 813, 2055, 281, 854, 365, 604, 1154, 420, 445, 9208, 417, 270, 12, 20057, 11, 436], "temperature": 0.0, "avg_logprob": -0.15934013215121845, "compression_ratio": 1.7670807453416149, "no_speech_prob": 6.73072281642817e-05}, {"id": 17, "seek": 5640, "start": 72.16, "end": 74.52, "text": " even help write some of this talk.", "tokens": [754, 854, 2464, 512, 295, 341, 751, 13], "temperature": 0.0, "avg_logprob": -0.15934013215121845, "compression_ratio": 1.7670807453416149, "no_speech_prob": 6.73072281642817e-05}, {"id": 18, "seek": 5640, "start": 74.52, "end": 78.64, "text": " And when you get something wrong, the compiler provides insightful help so that you can hunt", "tokens": [400, 562, 291, 483, 746, 2085, 11, 264, 31958, 6417, 46401, 854, 370, 300, 291, 393, 12454], "temperature": 0.0, "avg_logprob": -0.15934013215121845, "compression_ratio": 1.7670807453416149, "no_speech_prob": 6.73072281642817e-05}, {"id": 19, "seek": 5640, "start": 78.64, "end": 80.56, "text": " down the issues and stop them.", "tokens": [760, 264, 2663, 293, 1590, 552, 13], "temperature": 0.0, "avg_logprob": -0.15934013215121845, "compression_ratio": 1.7670807453416149, "no_speech_prob": 6.73072281642817e-05}, {"id": 20, "seek": 5640, "start": 80.56, "end": 83.44, "text": " The syntax of Gleam is similar to that of Rust, but if you're not from one of those", "tokens": [440, 28431, 295, 460, 306, 335, 307, 2531, 281, 300, 295, 34952, 11, 457, 498, 291, 434, 406, 490, 472, 295, 729], "temperature": 0.0, "avg_logprob": -0.15934013215121845, "compression_ratio": 1.7670807453416149, "no_speech_prob": 6.73072281642817e-05}, {"id": 21, "seek": 8344, "start": 83.44, "end": 87.28, "text": " backgrounds, don't worry, there are several guides to get started if you're used to a", "tokens": [17336, 11, 500, 380, 3292, 11, 456, 366, 2940, 17007, 281, 483, 1409, 498, 291, 434, 1143, 281, 257], "temperature": 0.0, "avg_logprob": -0.17390257691683836, "compression_ratio": 1.7175324675324675, "no_speech_prob": 6.376864621415734e-05}, {"id": 22, "seek": 8344, "start": 87.28, "end": 90.92, "text": " syntax from Python, Elm, Erlang, or even Elixir.", "tokens": [28431, 490, 15329, 11, 2699, 76, 11, 3300, 25241, 11, 420, 754, 2699, 970, 347, 13], "temperature": 0.0, "avg_logprob": -0.17390257691683836, "compression_ratio": 1.7175324675324675, "no_speech_prob": 6.376864621415734e-05}, {"id": 23, "seek": 8344, "start": 90.92, "end": 95.64, "text": " Here's an example of the start of the Gleam project.", "tokens": [1692, 311, 364, 1365, 295, 264, 722, 295, 264, 460, 306, 335, 1716, 13], "temperature": 0.0, "avg_logprob": -0.17390257691683836, "compression_ratio": 1.7175324675324675, "no_speech_prob": 6.376864621415734e-05}, {"id": 24, "seek": 8344, "start": 95.64, "end": 100.52, "text": " All Gleam projects have an exported main function in the project name.gleam file, which is within", "tokens": [1057, 460, 306, 335, 4455, 362, 364, 42055, 2135, 2445, 294, 264, 1716, 1315, 13, 70, 306, 335, 3991, 11, 597, 307, 1951], "temperature": 0.0, "avg_logprob": -0.17390257691683836, "compression_ratio": 1.7175324675324675, "no_speech_prob": 6.376864621415734e-05}, {"id": 25, "seek": 8344, "start": 100.52, "end": 101.52, "text": " your source folder.", "tokens": [428, 4009, 10820, 13], "temperature": 0.0, "avg_logprob": -0.17390257691683836, "compression_ratio": 1.7175324675324675, "no_speech_prob": 6.376864621415734e-05}, {"id": 26, "seek": 8344, "start": 101.52, "end": 106.92, "text": " If you need I.O., you can import the standard libraries I.O. module as shown there.", "tokens": [759, 291, 643, 286, 13, 46, 7933, 291, 393, 974, 264, 3832, 15148, 286, 13, 46, 13, 10088, 382, 4898, 456, 13], "temperature": 0.0, "avg_logprob": -0.17390257691683836, "compression_ratio": 1.7175324675324675, "no_speech_prob": 6.376864621415734e-05}, {"id": 27, "seek": 8344, "start": 106.92, "end": 109.56, "text": " And the standard library contains several modules to help you with everything you can", "tokens": [400, 264, 3832, 6405, 8306, 2940, 16679, 281, 854, 291, 365, 1203, 291, 393], "temperature": 0.0, "avg_logprob": -0.17390257691683836, "compression_ratio": 1.7175324675324675, "no_speech_prob": 6.376864621415734e-05}, {"id": 28, "seek": 8344, "start": 109.56, "end": 112.8, "text": " think of, from regex to options, iterators, and more.", "tokens": [519, 295, 11, 490, 319, 432, 87, 281, 3956, 11, 17138, 3391, 11, 293, 544, 13], "temperature": 0.0, "avg_logprob": -0.17390257691683836, "compression_ratio": 1.7175324675324675, "no_speech_prob": 6.376864621415734e-05}, {"id": 29, "seek": 11280, "start": 112.8, "end": 117.67999999999999, "text": " If you need target-specific standard library features, look at the Gleam, Erlang, and Gleam", "tokens": [759, 291, 643, 3779, 12, 29258, 3832, 6405, 4122, 11, 574, 412, 264, 460, 306, 335, 11, 3300, 25241, 11, 293, 460, 306, 335], "temperature": 0.0, "avg_logprob": -0.13902501984844057, "compression_ratio": 1.5973154362416107, "no_speech_prob": 2.0281477191019803e-05}, {"id": 30, "seek": 11280, "start": 117.67999999999999, "end": 123.75999999999999, "text": " JavaScript packages, which are both available on Hex and GitHub.", "tokens": [15778, 17401, 11, 597, 366, 1293, 2435, 322, 634, 87, 293, 23331, 13], "temperature": 0.0, "avg_logprob": -0.13902501984844057, "compression_ratio": 1.5973154362416107, "no_speech_prob": 2.0281477191019803e-05}, {"id": 31, "seek": 11280, "start": 123.75999999999999, "end": 127.08, "text": " Let's explore some Gleam examples to get a better understanding of the language.", "tokens": [961, 311, 6839, 512, 460, 306, 335, 5110, 281, 483, 257, 1101, 3701, 295, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.13902501984844057, "compression_ratio": 1.5973154362416107, "no_speech_prob": 2.0281477191019803e-05}, {"id": 32, "seek": 11280, "start": 127.08, "end": 130.84, "text": " And once we've done that, you can go away and look at the docs yourself for more examples,", "tokens": [400, 1564, 321, 600, 1096, 300, 11, 291, 393, 352, 1314, 293, 574, 412, 264, 45623, 1803, 337, 544, 5110, 11], "temperature": 0.0, "avg_logprob": -0.13902501984844057, "compression_ratio": 1.5973154362416107, "no_speech_prob": 2.0281477191019803e-05}, {"id": 33, "seek": 11280, "start": 130.84, "end": 135.56, "text": " and we'll go on to building some stuff with Shimmer.", "tokens": [293, 321, 603, 352, 322, 281, 2390, 512, 1507, 365, 1160, 14477, 13], "temperature": 0.0, "avg_logprob": -0.13902501984844057, "compression_ratio": 1.5973154362416107, "no_speech_prob": 2.0281477191019803e-05}, {"id": 34, "seek": 11280, "start": 135.56, "end": 138.07999999999998, "text": " Variables in Gleam are created using the let keyword.", "tokens": [32511, 2965, 294, 460, 306, 335, 366, 2942, 1228, 264, 718, 20428, 13], "temperature": 0.0, "avg_logprob": -0.13902501984844057, "compression_ratio": 1.5973154362416107, "no_speech_prob": 2.0281477191019803e-05}, {"id": 35, "seek": 11280, "start": 138.07999999999998, "end": 140.24, "text": " They are assigned to a name and a value.", "tokens": [814, 366, 13279, 281, 257, 1315, 293, 257, 2158, 13], "temperature": 0.0, "avg_logprob": -0.13902501984844057, "compression_ratio": 1.5973154362416107, "no_speech_prob": 2.0281477191019803e-05}, {"id": 36, "seek": 14024, "start": 140.24, "end": 143.8, "text": " The name can be reused later by other let bindings, but the values contained within", "tokens": [440, 1315, 393, 312, 319, 4717, 1780, 538, 661, 718, 14786, 1109, 11, 457, 264, 4190, 16212, 1951], "temperature": 0.0, "avg_logprob": -0.13757486192006912, "compression_ratio": 1.7114093959731544, "no_speech_prob": 1.4052562619326636e-05}, {"id": 37, "seek": 14024, "start": 143.8, "end": 147.96, "text": " are immutable, meaning the values themselves cannot be changed.", "tokens": [366, 3397, 32148, 11, 3620, 264, 4190, 2969, 2644, 312, 3105, 13], "temperature": 0.0, "avg_logprob": -0.13757486192006912, "compression_ratio": 1.7114093959731544, "no_speech_prob": 1.4052562619326636e-05}, {"id": 38, "seek": 14024, "start": 147.96, "end": 151.24, "text": " Here's an example of blocks.", "tokens": [1692, 311, 364, 1365, 295, 8474, 13], "temperature": 0.0, "avg_logprob": -0.13757486192006912, "compression_ratio": 1.7114093959731544, "no_speech_prob": 1.4052562619326636e-05}, {"id": 39, "seek": 14024, "start": 151.24, "end": 154.08, "text": " Every block in Gleam is an expression.", "tokens": [2048, 3461, 294, 460, 306, 335, 307, 364, 6114, 13], "temperature": 0.0, "avg_logprob": -0.13757486192006912, "compression_ratio": 1.7114093959731544, "no_speech_prob": 1.4052562619326636e-05}, {"id": 40, "seek": 14024, "start": 154.08, "end": 157.20000000000002, "text": " All expressions in the block are executed, and then the result of the last expression", "tokens": [1057, 15277, 294, 264, 3461, 366, 17577, 11, 293, 550, 264, 1874, 295, 264, 1036, 6114], "temperature": 0.0, "avg_logprob": -0.13757486192006912, "compression_ratio": 1.7114093959731544, "no_speech_prob": 1.4052562619326636e-05}, {"id": 41, "seek": 14024, "start": 157.20000000000002, "end": 158.20000000000002, "text": " is returned.", "tokens": [307, 8752, 13], "temperature": 0.0, "avg_logprob": -0.13757486192006912, "compression_ratio": 1.7114093959731544, "no_speech_prob": 1.4052562619326636e-05}, {"id": 42, "seek": 14024, "start": 158.20000000000002, "end": 162.52, "text": " So as you can see here, the response will be false, even though hello and 42 plus 12", "tokens": [407, 382, 291, 393, 536, 510, 11, 264, 4134, 486, 312, 7908, 11, 754, 1673, 7751, 293, 14034, 1804, 2272], "temperature": 0.0, "avg_logprob": -0.13757486192006912, "compression_ratio": 1.7114093959731544, "no_speech_prob": 1.4052562619326636e-05}, {"id": 43, "seek": 14024, "start": 162.52, "end": 164.04000000000002, "text": " are evaluated.", "tokens": [366, 25509, 13], "temperature": 0.0, "avg_logprob": -0.13757486192006912, "compression_ratio": 1.7114093959731544, "no_speech_prob": 1.4052562619326636e-05}, {"id": 44, "seek": 14024, "start": 164.04000000000002, "end": 169.28, "text": " This can be used to build more advanced expressions where the order of operations is important.", "tokens": [639, 393, 312, 1143, 281, 1322, 544, 7339, 15277, 689, 264, 1668, 295, 7705, 307, 1021, 13], "temperature": 0.0, "avg_logprob": -0.13757486192006912, "compression_ratio": 1.7114093959731544, "no_speech_prob": 1.4052562619326636e-05}, {"id": 45, "seek": 16928, "start": 169.28, "end": 172.36, "text": " Here's an example of using the blocks to convert from Fahrenheit to Celsius, meaning", "tokens": [1692, 311, 364, 1365, 295, 1228, 264, 8474, 281, 7620, 490, 31199, 281, 22658, 11, 3620], "temperature": 0.0, "avg_logprob": -0.15994573272435011, "compression_ratio": 1.673992673992674, "no_speech_prob": 2.4039647541940212e-05}, {"id": 46, "seek": 16928, "start": 172.36, "end": 178.2, "text": " sure to remove the 32 before multiplying and dividing.", "tokens": [988, 281, 4159, 264, 8858, 949, 30955, 293, 26764, 13], "temperature": 0.0, "avg_logprob": -0.15994573272435011, "compression_ratio": 1.673992673992674, "no_speech_prob": 2.4039647541940212e-05}, {"id": 47, "seek": 16928, "start": 178.2, "end": 180.32, "text": " In Gleam, lists are all homogenous.", "tokens": [682, 460, 306, 335, 11, 14511, 366, 439, 3655, 45519, 13], "temperature": 0.0, "avg_logprob": -0.15994573272435011, "compression_ratio": 1.673992673992674, "no_speech_prob": 2.4039647541940212e-05}, {"id": 48, "seek": 16928, "start": 180.32, "end": 183.76, "text": " This means that elements in a list must all be of the same type.", "tokens": [639, 1355, 300, 4959, 294, 257, 1329, 1633, 439, 312, 295, 264, 912, 2010, 13], "temperature": 0.0, "avg_logprob": -0.15994573272435011, "compression_ratio": 1.673992673992674, "no_speech_prob": 2.4039647541940212e-05}, {"id": 49, "seek": 16928, "start": 183.76, "end": 188.32, "text": " If you try and construct a list of multiple types, this will result in a compiler presenting", "tokens": [759, 291, 853, 293, 7690, 257, 1329, 295, 3866, 3467, 11, 341, 486, 1874, 294, 257, 31958, 15578], "temperature": 0.0, "avg_logprob": -0.15994573272435011, "compression_ratio": 1.673992673992674, "no_speech_prob": 2.4039647541940212e-05}, {"id": 50, "seek": 16928, "start": 188.32, "end": 193.2, "text": " you with a type error and showing you where you try to use the multiple different types,", "tokens": [291, 365, 257, 2010, 6713, 293, 4099, 291, 689, 291, 853, 281, 764, 264, 3866, 819, 3467, 11], "temperature": 0.0, "avg_logprob": -0.15994573272435011, "compression_ratio": 1.673992673992674, "no_speech_prob": 2.4039647541940212e-05}, {"id": 51, "seek": 16928, "start": 193.2, "end": 197.48, "text": " so you can find it and correct it.", "tokens": [370, 291, 393, 915, 309, 293, 3006, 309, 13], "temperature": 0.0, "avg_logprob": -0.15994573272435011, "compression_ratio": 1.673992673992674, "no_speech_prob": 2.4039647541940212e-05}, {"id": 52, "seek": 19748, "start": 197.48, "end": 200.92, "text": " Planning to a list in Gleam is very fast, and this is the way that Gleam's documentation", "tokens": [29308, 281, 257, 1329, 294, 460, 306, 335, 307, 588, 2370, 11, 293, 341, 307, 264, 636, 300, 460, 306, 335, 311, 14333], "temperature": 0.0, "avg_logprob": -0.14537082758164943, "compression_ratio": 1.769736842105263, "no_speech_prob": 2.847247560566757e-05}, {"id": 53, "seek": 19748, "start": 200.92, "end": 203.67999999999998, "text": " recommends that you should add new values to a list.", "tokens": [34556, 300, 291, 820, 909, 777, 4190, 281, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.14537082758164943, "compression_ratio": 1.769736842105263, "no_speech_prob": 2.847247560566757e-05}, {"id": 54, "seek": 19748, "start": 203.67999999999998, "end": 207.83999999999997, "text": " In the standard library, there is a list module, which allows you to do more advanced operations", "tokens": [682, 264, 3832, 6405, 11, 456, 307, 257, 1329, 10088, 11, 597, 4045, 291, 281, 360, 544, 7339, 7705], "temperature": 0.0, "avg_logprob": -0.14537082758164943, "compression_ratio": 1.769736842105263, "no_speech_prob": 2.847247560566757e-05}, {"id": 55, "seek": 19748, "start": 207.83999999999997, "end": 210.2, "text": " and also add to lists that way.", "tokens": [293, 611, 909, 281, 14511, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.14537082758164943, "compression_ratio": 1.769736842105263, "no_speech_prob": 2.847247560566757e-05}, {"id": 56, "seek": 19748, "start": 210.2, "end": 214.6, "text": " The above example uses two constant lists, well, a constant and a constant list, but", "tokens": [440, 3673, 1365, 4960, 732, 5754, 14511, 11, 731, 11, 257, 5754, 293, 257, 5754, 1329, 11, 457], "temperature": 0.0, "avg_logprob": -0.14537082758164943, "compression_ratio": 1.769736842105263, "no_speech_prob": 2.847247560566757e-05}, {"id": 57, "seek": 19748, "start": 214.6, "end": 218.51999999999998, "text": " the same principles apply whether you have one dynamic and the other constant or vice", "tokens": [264, 912, 9156, 3079, 1968, 291, 362, 472, 8546, 293, 264, 661, 5754, 420, 11964], "temperature": 0.0, "avg_logprob": -0.14537082758164943, "compression_ratio": 1.769736842105263, "no_speech_prob": 2.847247560566757e-05}, {"id": 58, "seek": 19748, "start": 218.51999999999998, "end": 221.92, "text": " versa.", "tokens": [25650, 13], "temperature": 0.0, "avg_logprob": -0.14537082758164943, "compression_ratio": 1.769736842105263, "no_speech_prob": 2.847247560566757e-05}, {"id": 59, "seek": 19748, "start": 221.92, "end": 227.44, "text": " If you need multiple types in one place, you can use two pools using the hash and bracket", "tokens": [759, 291, 643, 3866, 3467, 294, 472, 1081, 11, 291, 393, 764, 732, 28688, 1228, 264, 22019, 293, 16904], "temperature": 0.0, "avg_logprob": -0.14537082758164943, "compression_ratio": 1.769736842105263, "no_speech_prob": 2.847247560566757e-05}, {"id": 60, "seek": 22744, "start": 227.44, "end": 228.44, "text": " syntax there.", "tokens": [28431, 456, 13], "temperature": 0.0, "avg_logprob": -0.17179755089988172, "compression_ratio": 1.778125, "no_speech_prob": 4.152635301579721e-05}, {"id": 61, "seek": 22744, "start": 228.44, "end": 231.92, "text": " They can have multiple types and can be pattern matched against.", "tokens": [814, 393, 362, 3866, 3467, 293, 393, 312, 5102, 21447, 1970, 13], "temperature": 0.0, "avg_logprob": -0.17179755089988172, "compression_ratio": 1.778125, "no_speech_prob": 4.152635301579721e-05}, {"id": 62, "seek": 22744, "start": 231.92, "end": 235.52, "text": " We'll look at pattern matching in a few slides, but if you want to access the values on a", "tokens": [492, 603, 574, 412, 5102, 14324, 294, 257, 1326, 9788, 11, 457, 498, 291, 528, 281, 2105, 264, 4190, 322, 257], "temperature": 0.0, "avg_logprob": -0.17179755089988172, "compression_ratio": 1.778125, "no_speech_prob": 4.152635301579721e-05}, {"id": 63, "seek": 22744, "start": 235.52, "end": 239.8, "text": " two-pool, there's always the dot syntax, which I'll show you on the next slide, which is", "tokens": [732, 12, 17374, 11, 456, 311, 1009, 264, 5893, 28431, 11, 597, 286, 603, 855, 291, 322, 264, 958, 4137, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.17179755089988172, "compression_ratio": 1.778125, "no_speech_prob": 4.152635301579721e-05}, {"id": 64, "seek": 22744, "start": 239.8, "end": 243.84, "text": " similar to that that you'd be used to in object-oriented for custom types and objects.", "tokens": [2531, 281, 300, 300, 291, 1116, 312, 1143, 281, 294, 2657, 12, 27414, 337, 2375, 3467, 293, 6565, 13], "temperature": 0.0, "avg_logprob": -0.17179755089988172, "compression_ratio": 1.778125, "no_speech_prob": 4.152635301579721e-05}, {"id": 65, "seek": 22744, "start": 243.84, "end": 248.32, "text": " Here's an example of a two-pool, which has two elements, and they're selected using", "tokens": [1692, 311, 364, 1365, 295, 257, 732, 12, 17374, 11, 597, 575, 732, 4959, 11, 293, 436, 434, 8209, 1228], "temperature": 0.0, "avg_logprob": -0.17179755089988172, "compression_ratio": 1.778125, "no_speech_prob": 4.152635301579721e-05}, {"id": 66, "seek": 22744, "start": 248.32, "end": 251.52, "text": " the dot syntax and assigned to their own variables.", "tokens": [264, 5893, 28431, 293, 13279, 281, 641, 1065, 9102, 13], "temperature": 0.0, "avg_logprob": -0.17179755089988172, "compression_ratio": 1.778125, "no_speech_prob": 4.152635301579721e-05}, {"id": 67, "seek": 22744, "start": 251.52, "end": 254.76, "text": " It's not particularly useful here because they're constants, but with runtime variables,", "tokens": [467, 311, 406, 4098, 4420, 510, 570, 436, 434, 35870, 11, 457, 365, 34474, 9102, 11], "temperature": 0.0, "avg_logprob": -0.17179755089988172, "compression_ratio": 1.778125, "no_speech_prob": 4.152635301579721e-05}, {"id": 68, "seek": 25476, "start": 254.76, "end": 259.32, "text": " it's easy to access.", "tokens": [309, 311, 1858, 281, 2105, 13], "temperature": 0.0, "avg_logprob": -0.1556275722592376, "compression_ratio": 1.622340425531915, "no_speech_prob": 1.2444275853340514e-05}, {"id": 69, "seek": 25476, "start": 259.32, "end": 262.71999999999997, "text": " Gleam supports custom types, and custom types in Gleam are a collection of keys and their", "tokens": [460, 306, 335, 9346, 2375, 3467, 11, 293, 2375, 3467, 294, 460, 306, 335, 366, 257, 5765, 295, 9317, 293, 641], "temperature": 0.0, "avg_logprob": -0.1556275722592376, "compression_ratio": 1.622340425531915, "no_speech_prob": 1.2444275853340514e-05}, {"id": 70, "seek": 25476, "start": 262.71999999999997, "end": 266.36, "text": " values, and you can see them as objects.", "tokens": [4190, 11, 293, 291, 393, 536, 552, 382, 6565, 13], "temperature": 0.0, "avg_logprob": -0.1556275722592376, "compression_ratio": 1.622340425531915, "no_speech_prob": 1.2444275853340514e-05}, {"id": 71, "seek": 25476, "start": 266.36, "end": 272.2, "text": " There's just one caveat though, types in Gleam don't have methods.", "tokens": [821, 311, 445, 472, 43012, 1673, 11, 3467, 294, 460, 306, 335, 500, 380, 362, 7150, 13], "temperature": 0.0, "avg_logprob": -0.1556275722592376, "compression_ratio": 1.622340425531915, "no_speech_prob": 1.2444275853340514e-05}, {"id": 72, "seek": 25476, "start": 272.2, "end": 278.2, "text": " Similar to two-pools, you can use the dot syntax to access properties within them, but", "tokens": [10905, 281, 732, 12, 17374, 82, 11, 291, 393, 764, 264, 5893, 28431, 281, 2105, 7221, 1951, 552, 11, 457], "temperature": 0.0, "avg_logprob": -0.1556275722592376, "compression_ratio": 1.622340425531915, "no_speech_prob": 1.2444275853340514e-05}, {"id": 73, "seek": 27820, "start": 278.2, "end": 286.36, "text": " instead of dot and position, you use dot and the name.", "tokens": [2602, 295, 5893, 293, 2535, 11, 291, 764, 5893, 293, 264, 1315, 13], "temperature": 0.0, "avg_logprob": -0.14840340614318848, "compression_ratio": 1.6077586206896552, "no_speech_prob": 9.623609912523534e-06}, {"id": 74, "seek": 27820, "start": 286.36, "end": 290.4, "text": " In Gleam, custom types can have multiple constructors, similar to in the Rust ecosystem", "tokens": [682, 460, 306, 335, 11, 2375, 3467, 393, 362, 3866, 7690, 830, 11, 2531, 281, 294, 264, 34952, 11311], "temperature": 0.0, "avg_logprob": -0.14840340614318848, "compression_ratio": 1.6077586206896552, "no_speech_prob": 9.623609912523534e-06}, {"id": 75, "seek": 27820, "start": 290.4, "end": 292.0, "text": " for enums.", "tokens": [337, 465, 8099, 13], "temperature": 0.0, "avg_logprob": -0.14840340614318848, "compression_ratio": 1.6077586206896552, "no_speech_prob": 9.623609912523534e-06}, {"id": 76, "seek": 27820, "start": 292.0, "end": 296.64, "text": " This does bring another caveat though, which is that the dot syntax now only works for", "tokens": [639, 775, 1565, 1071, 43012, 1673, 11, 597, 307, 300, 264, 5893, 28431, 586, 787, 1985, 337], "temperature": 0.0, "avg_logprob": -0.14840340614318848, "compression_ratio": 1.6077586206896552, "no_speech_prob": 9.623609912523534e-06}, {"id": 77, "seek": 27820, "start": 296.64, "end": 299.12, "text": " keys that are shared across all elements.", "tokens": [9317, 300, 366, 5507, 2108, 439, 4959, 13], "temperature": 0.0, "avg_logprob": -0.14840340614318848, "compression_ratio": 1.6077586206896552, "no_speech_prob": 9.623609912523534e-06}, {"id": 78, "seek": 27820, "start": 299.12, "end": 303.28, "text": " In this case, the only key you would be able to use the dot syntax with is name, otherwise", "tokens": [682, 341, 1389, 11, 264, 787, 2141, 291, 576, 312, 1075, 281, 764, 264, 5893, 28431, 365, 307, 1315, 11, 5911], "temperature": 0.0, "avg_logprob": -0.14840340614318848, "compression_ratio": 1.6077586206896552, "no_speech_prob": 9.623609912523534e-06}, {"id": 79, "seek": 30328, "start": 303.28, "end": 311.47999999999996, "text": " you would have to pattern match against them to make sure that type safety stays.", "tokens": [291, 576, 362, 281, 5102, 2995, 1970, 552, 281, 652, 988, 300, 2010, 4514, 10834, 13], "temperature": 0.0, "avg_logprob": -0.13691332029259723, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.3657512681675144e-05}, {"id": 80, "seek": 30328, "start": 311.47999999999996, "end": 313.15999999999997, "text": " Case statements can match anything.", "tokens": [17791, 12363, 393, 2995, 1340, 13], "temperature": 0.0, "avg_logprob": -0.13691332029259723, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.3657512681675144e-05}, {"id": 81, "seek": 30328, "start": 313.15999999999997, "end": 317.32, "text": " In this first example, we use basic integers, but there's more advanced pattern matching", "tokens": [682, 341, 700, 1365, 11, 321, 764, 3875, 41674, 11, 457, 456, 311, 544, 7339, 5102, 14324], "temperature": 0.0, "avg_logprob": -0.13691332029259723, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.3657512681675144e-05}, {"id": 82, "seek": 30328, "start": 317.32, "end": 319.55999999999995, "text": " over the next couple slides.", "tokens": [670, 264, 958, 1916, 9788, 13], "temperature": 0.0, "avg_logprob": -0.13691332029259723, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.3657512681675144e-05}, {"id": 83, "seek": 30328, "start": 319.55999999999995, "end": 323.4, "text": " You can see we match the first three numbers and produce a value, and otherwise we just", "tokens": [509, 393, 536, 321, 2995, 264, 700, 1045, 3547, 293, 5258, 257, 2158, 11, 293, 5911, 321, 445], "temperature": 0.0, "avg_logprob": -0.13691332029259723, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.3657512681675144e-05}, {"id": 84, "seek": 30328, "start": 323.4, "end": 331.03999999999996, "text": " consume as a variable and say we can either use or discard that variable.", "tokens": [14732, 382, 257, 7006, 293, 584, 321, 393, 2139, 764, 420, 31597, 300, 7006, 13], "temperature": 0.0, "avg_logprob": -0.13691332029259723, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.3657512681675144e-05}, {"id": 85, "seek": 33104, "start": 331.04, "end": 334.6, "text": " Some pattern match against two-pools here and even extract values from within.", "tokens": [2188, 5102, 2995, 1970, 732, 12, 17374, 82, 510, 293, 754, 8947, 4190, 490, 1951, 13], "temperature": 0.0, "avg_logprob": -0.14543924144670076, "compression_ratio": 1.6944444444444444, "no_speech_prob": 1.3896757081965916e-05}, {"id": 86, "seek": 33104, "start": 334.6, "end": 338.68, "text": " In this example, we're checking for two specific paths where one is no and the other is yes.", "tokens": [682, 341, 1365, 11, 321, 434, 8568, 337, 732, 2685, 14518, 689, 472, 307, 572, 293, 264, 661, 307, 2086, 13], "temperature": 0.0, "avg_logprob": -0.14543924144670076, "compression_ratio": 1.6944444444444444, "no_speech_prob": 1.3896757081965916e-05}, {"id": 87, "seek": 33104, "start": 338.68, "end": 342.96000000000004, "text": " The unique thing about the yes path is that we're discarding the integer in the middle,", "tokens": [440, 3845, 551, 466, 264, 2086, 3100, 307, 300, 321, 434, 31597, 278, 264, 24922, 294, 264, 2808, 11], "temperature": 0.0, "avg_logprob": -0.14543924144670076, "compression_ratio": 1.6944444444444444, "no_speech_prob": 1.3896757081965916e-05}, {"id": 88, "seek": 33104, "start": 342.96000000000004, "end": 352.08000000000004, "text": " but we could again take that as a variable and do further checks against it.", "tokens": [457, 321, 727, 797, 747, 300, 382, 257, 7006, 293, 360, 3052, 13834, 1970, 309, 13], "temperature": 0.0, "avg_logprob": -0.14543924144670076, "compression_ratio": 1.6944444444444444, "no_speech_prob": 1.3896757081965916e-05}, {"id": 89, "seek": 33104, "start": 352.08000000000004, "end": 355.32000000000005, "text": " If you remember the custom type from earlier, this pattern matches against that, so we can", "tokens": [759, 291, 1604, 264, 2375, 2010, 490, 3071, 11, 341, 5102, 10676, 1970, 300, 11, 370, 321, 393], "temperature": 0.0, "avg_logprob": -0.14543924144670076, "compression_ratio": 1.6944444444444444, "no_speech_prob": 1.3896757081965916e-05}, {"id": 90, "seek": 35532, "start": 355.32, "end": 361.84, "text": " extract the values into certain variables here, like talks and mic, and the rest can", "tokens": [8947, 264, 4190, 666, 1629, 9102, 510, 11, 411, 6686, 293, 3123, 11, 293, 264, 1472, 393], "temperature": 0.0, "avg_logprob": -0.1401169486667799, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.057150075212121e-05}, {"id": 91, "seek": 35532, "start": 361.84, "end": 364.44, "text": " be thrown away with the two dots.", "tokens": [312, 11732, 1314, 365, 264, 732, 15026, 13], "temperature": 0.0, "avg_logprob": -0.1401169486667799, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.057150075212121e-05}, {"id": 92, "seek": 35532, "start": 364.44, "end": 368.32, "text": " You can also use the two dots and assign that to a variable so that then you can reconstruct", "tokens": [509, 393, 611, 764, 264, 732, 15026, 293, 6269, 300, 281, 257, 7006, 370, 300, 550, 291, 393, 31499], "temperature": 0.0, "avg_logprob": -0.1401169486667799, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.057150075212121e-05}, {"id": 93, "seek": 35532, "start": 368.32, "end": 373.64, "text": " the type afterwards to pass it back on somewhere else.", "tokens": [264, 2010, 10543, 281, 1320, 309, 646, 322, 4079, 1646, 13], "temperature": 0.0, "avg_logprob": -0.1401169486667799, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.057150075212121e-05}, {"id": 94, "seek": 35532, "start": 373.64, "end": 376.8, "text": " There's lots more about Gleam syntax that I don't have time to cover today, such as", "tokens": [821, 311, 3195, 544, 466, 460, 306, 335, 28431, 300, 286, 500, 380, 362, 565, 281, 2060, 965, 11, 1270, 382], "temperature": 0.0, "avg_logprob": -0.1401169486667799, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.057150075212121e-05}, {"id": 95, "seek": 35532, "start": 376.8, "end": 381.03999999999996, "text": " external functions, generics, the use keyword, and more, and stuff's always being added", "tokens": [8320, 6828, 11, 1337, 1167, 11, 264, 764, 20428, 11, 293, 544, 11, 293, 1507, 311, 1009, 885, 3869], "temperature": 0.0, "avg_logprob": -0.1401169486667799, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.057150075212121e-05}, {"id": 96, "seek": 35532, "start": 381.03999999999996, "end": 382.48, "text": " to the syntax.", "tokens": [281, 264, 28431, 13], "temperature": 0.0, "avg_logprob": -0.1401169486667799, "compression_ratio": 1.6654411764705883, "no_speech_prob": 1.057150075212121e-05}, {"id": 97, "seek": 38248, "start": 382.48, "end": 386.28000000000003, "text": " All of it's documented in the language tour, so feel free to have a look over there and", "tokens": [1057, 295, 309, 311, 23007, 294, 264, 2856, 3512, 11, 370, 841, 1737, 281, 362, 257, 574, 670, 456, 293], "temperature": 0.0, "avg_logprob": -0.13324703790445244, "compression_ratio": 1.6106870229007633, "no_speech_prob": 2.7471343855722807e-05}, {"id": 98, "seek": 38248, "start": 386.28000000000003, "end": 390.64000000000004, "text": " get a better understanding of what else is available within Gleam.", "tokens": [483, 257, 1101, 3701, 295, 437, 1646, 307, 2435, 1951, 460, 306, 335, 13], "temperature": 0.0, "avg_logprob": -0.13324703790445244, "compression_ratio": 1.6106870229007633, "no_speech_prob": 2.7471343855722807e-05}, {"id": 99, "seek": 38248, "start": 390.64000000000004, "end": 399.28000000000003, "text": " Now let's get on to building some bots to put our Gleam skills into practice.", "tokens": [823, 718, 311, 483, 322, 281, 2390, 512, 35410, 281, 829, 527, 460, 306, 335, 3942, 666, 3124, 13], "temperature": 0.0, "avg_logprob": -0.13324703790445244, "compression_ratio": 1.6106870229007633, "no_speech_prob": 2.7471343855722807e-05}, {"id": 100, "seek": 38248, "start": 399.28000000000003, "end": 402.68, "text": " Shimmer is a library which I've doubled in and out of over the last 13 months.", "tokens": [1160, 14477, 307, 257, 6405, 597, 286, 600, 24405, 294, 293, 484, 295, 670, 264, 1036, 3705, 2493, 13], "temperature": 0.0, "avg_logprob": -0.13324703790445244, "compression_ratio": 1.6106870229007633, "no_speech_prob": 2.7471343855722807e-05}, {"id": 101, "seek": 38248, "start": 402.68, "end": 408.24, "text": " I started as a project to learn Gleam and get into the Beam ecosystem, but in the process", "tokens": [286, 1409, 382, 257, 1716, 281, 1466, 460, 306, 335, 293, 483, 666, 264, 40916, 11311, 11, 457, 294, 264, 1399], "temperature": 0.0, "avg_logprob": -0.13324703790445244, "compression_ratio": 1.6106870229007633, "no_speech_prob": 2.7471343855722807e-05}, {"id": 102, "seek": 38248, "start": 408.24, "end": 409.6, "text": " I've done much more.", "tokens": [286, 600, 1096, 709, 544, 13], "temperature": 0.0, "avg_logprob": -0.13324703790445244, "compression_ratio": 1.6106870229007633, "no_speech_prob": 2.7471343855722807e-05}, {"id": 103, "seek": 40960, "start": 409.6, "end": 414.76000000000005, "text": " I'm doing this talk now, I've started contributing to the Gleam compiler and the wider ecosystem,", "tokens": [286, 478, 884, 341, 751, 586, 11, 286, 600, 1409, 19270, 281, 264, 460, 306, 335, 31958, 293, 264, 11842, 11311, 11], "temperature": 0.0, "avg_logprob": -0.1387911780935819, "compression_ratio": 1.6015325670498084, "no_speech_prob": 2.0763432985404506e-05}, {"id": 104, "seek": 40960, "start": 414.76000000000005, "end": 418.36, "text": " and I use Elixir and Erlang more day-to-day now.", "tokens": [293, 286, 764, 2699, 970, 347, 293, 3300, 25241, 544, 786, 12, 1353, 12, 810, 586, 13], "temperature": 0.0, "avg_logprob": -0.1387911780935819, "compression_ratio": 1.6015325670498084, "no_speech_prob": 2.0763432985404506e-05}, {"id": 105, "seek": 40960, "start": 418.36, "end": 424.56, "text": " At this point in Shimmer's development, we've moved away from using Erlang foreign functions", "tokens": [1711, 341, 935, 294, 1160, 14477, 311, 3250, 11, 321, 600, 4259, 1314, 490, 1228, 3300, 25241, 5329, 6828], "temperature": 0.0, "avg_logprob": -0.1387911780935819, "compression_ratio": 1.6015325670498084, "no_speech_prob": 2.0763432985404506e-05}, {"id": 106, "seek": 40960, "start": 424.56, "end": 428.8, "text": " and now a majority of it is in Gleam.", "tokens": [293, 586, 257, 6286, 295, 309, 307, 294, 460, 306, 335, 13], "temperature": 0.0, "avg_logprob": -0.1387911780935819, "compression_ratio": 1.6015325670498084, "no_speech_prob": 2.0763432985404506e-05}, {"id": 107, "seek": 40960, "start": 428.8, "end": 431.92, "text": " Some key features of Shimmer, first, is compatibility.", "tokens": [2188, 2141, 4122, 295, 1160, 14477, 11, 700, 11, 307, 34237, 13], "temperature": 0.0, "avg_logprob": -0.1387911780935819, "compression_ratio": 1.6015325670498084, "no_speech_prob": 2.0763432985404506e-05}, {"id": 108, "seek": 40960, "start": 431.92, "end": 436.04, "text": " While Shimmer is built in Gleam, it can be used in Elixir, Erlang, and any other Beam", "tokens": [3987, 1160, 14477, 307, 3094, 294, 460, 306, 335, 11, 309, 393, 312, 1143, 294, 2699, 970, 347, 11, 3300, 25241, 11, 293, 604, 661, 40916], "temperature": 0.0, "avg_logprob": -0.1387911780935819, "compression_ratio": 1.6015325670498084, "no_speech_prob": 2.0763432985404506e-05}, {"id": 109, "seek": 43604, "start": 436.04, "end": 440.64000000000004, "text": " language, it's published on Hex and the source code is available online.", "tokens": [2856, 11, 309, 311, 6572, 322, 634, 87, 293, 264, 4009, 3089, 307, 2435, 2950, 13], "temperature": 0.0, "avg_logprob": -0.17036223244833779, "compression_ratio": 1.6582278481012658, "no_speech_prob": 7.008348620729521e-05}, {"id": 110, "seek": 43604, "start": 440.64000000000004, "end": 446.52000000000004, "text": " I've been working on some examples for Erlang and Elixir, which I'll publish into the GitHub", "tokens": [286, 600, 668, 1364, 322, 512, 5110, 337, 3300, 25241, 293, 2699, 970, 347, 11, 597, 286, 603, 11374, 666, 264, 23331], "temperature": 0.0, "avg_logprob": -0.17036223244833779, "compression_ratio": 1.6582278481012658, "no_speech_prob": 7.008348620729521e-05}, {"id": 111, "seek": 43604, "start": 446.52000000000004, "end": 449.12, "text": " repository once I've got them to a stable point.", "tokens": [25841, 1564, 286, 600, 658, 552, 281, 257, 8351, 935, 13], "temperature": 0.0, "avg_logprob": -0.17036223244833779, "compression_ratio": 1.6582278481012658, "no_speech_prob": 7.008348620729521e-05}, {"id": 112, "seek": 43604, "start": 449.12, "end": 451.6, "text": " Secondly, it's actor-based.", "tokens": [19483, 11, 309, 311, 8747, 12, 6032, 13], "temperature": 0.0, "avg_logprob": -0.17036223244833779, "compression_ratio": 1.6582278481012658, "no_speech_prob": 7.008348620729521e-05}, {"id": 113, "seek": 43604, "start": 451.6, "end": 455.76, "text": " As we discussed before with its resilience, Shimmer is built on top of actors, and when", "tokens": [1018, 321, 7152, 949, 365, 1080, 19980, 11, 1160, 14477, 307, 3094, 322, 1192, 295, 10037, 11, 293, 562], "temperature": 0.0, "avg_logprob": -0.17036223244833779, "compression_ratio": 1.6582278481012658, "no_speech_prob": 7.008348620729521e-05}, {"id": 114, "seek": 43604, "start": 455.76, "end": 460.16, "text": " we're running in single shard mode, you only have one actor, multiple shards, that's not", "tokens": [321, 434, 2614, 294, 2167, 402, 515, 4391, 11, 291, 787, 362, 472, 8747, 11, 3866, 402, 2287, 11, 300, 311, 406], "temperature": 0.0, "avg_logprob": -0.17036223244833779, "compression_ratio": 1.6582278481012658, "no_speech_prob": 7.008348620729521e-05}, {"id": 115, "seek": 43604, "start": 460.16, "end": 461.16, "text": " a problem.", "tokens": [257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.17036223244833779, "compression_ratio": 1.6582278481012658, "no_speech_prob": 7.008348620729521e-05}, {"id": 116, "seek": 43604, "start": 461.16, "end": 465.16, "text": " We use a supervisor tree so that all the shards stay alive, and it's built on top of Erlang's", "tokens": [492, 764, 257, 24610, 4230, 370, 300, 439, 264, 402, 2287, 1754, 5465, 11, 293, 309, 311, 3094, 322, 1192, 295, 3300, 25241, 311], "temperature": 0.0, "avg_logprob": -0.17036223244833779, "compression_ratio": 1.6582278481012658, "no_speech_prob": 7.008348620729521e-05}, {"id": 117, "seek": 46516, "start": 465.16, "end": 467.8, "text": " OTP using the Gleam OTP package.", "tokens": [422, 16804, 1228, 264, 460, 306, 335, 422, 16804, 7372, 13], "temperature": 0.0, "avg_logprob": -0.1432792368069501, "compression_ratio": 1.7753623188405796, "no_speech_prob": 2.3085947759682313e-05}, {"id": 118, "seek": 46516, "start": 467.8, "end": 470.72, "text": " And finally, it's type safety.", "tokens": [400, 2721, 11, 309, 311, 2010, 4514, 13], "temperature": 0.0, "avg_logprob": -0.1432792368069501, "compression_ratio": 1.7753623188405796, "no_speech_prob": 2.3085947759682313e-05}, {"id": 119, "seek": 46516, "start": 470.72, "end": 473.96000000000004, "text": " As well as Beam Core to Gleam is a useful feature for Shimmer.", "tokens": [1018, 731, 382, 40916, 14798, 281, 460, 306, 335, 307, 257, 4420, 4111, 337, 1160, 14477, 13], "temperature": 0.0, "avg_logprob": -0.1432792368069501, "compression_ratio": 1.7753623188405796, "no_speech_prob": 2.3085947759682313e-05}, {"id": 120, "seek": 46516, "start": 473.96000000000004, "end": 478.16, "text": " While building your Discord bot in Gleam, we leverage all of Gleam's type functionality", "tokens": [3987, 2390, 428, 32623, 10592, 294, 460, 306, 335, 11, 321, 13982, 439, 295, 460, 306, 335, 311, 2010, 14980], "temperature": 0.0, "avg_logprob": -0.1432792368069501, "compression_ratio": 1.7753623188405796, "no_speech_prob": 2.3085947759682313e-05}, {"id": 121, "seek": 46516, "start": 478.16, "end": 481.40000000000003, "text": " to ensure that the code you write for the Beam is type safe.", "tokens": [281, 5586, 300, 264, 3089, 291, 2464, 337, 264, 40916, 307, 2010, 3273, 13], "temperature": 0.0, "avg_logprob": -0.1432792368069501, "compression_ratio": 1.7753623188405796, "no_speech_prob": 2.3085947759682313e-05}, {"id": 122, "seek": 46516, "start": 481.40000000000003, "end": 484.92, "text": " You only get the full type safety when you write all of your code in Gleam, but you can", "tokens": [509, 787, 483, 264, 1577, 2010, 4514, 562, 291, 2464, 439, 295, 428, 3089, 294, 460, 306, 335, 11, 457, 291, 393], "temperature": 0.0, "avg_logprob": -0.1432792368069501, "compression_ratio": 1.7753623188405796, "no_speech_prob": 2.3085947759682313e-05}, {"id": 123, "seek": 46516, "start": 484.92, "end": 488.40000000000003, "text": " always trust that the core of the library will be type safe.", "tokens": [1009, 3361, 300, 264, 4965, 295, 264, 6405, 486, 312, 2010, 3273, 13], "temperature": 0.0, "avg_logprob": -0.1432792368069501, "compression_ratio": 1.7753623188405796, "no_speech_prob": 2.3085947759682313e-05}, {"id": 124, "seek": 46516, "start": 488.40000000000003, "end": 494.36, "text": " It's a little fun fact, moving more and more of Shimmer to Gleam.", "tokens": [467, 311, 257, 707, 1019, 1186, 11, 2684, 544, 293, 544, 295, 1160, 14477, 281, 460, 306, 335, 13], "temperature": 0.0, "avg_logprob": -0.1432792368069501, "compression_ratio": 1.7753623188405796, "no_speech_prob": 2.3085947759682313e-05}, {"id": 125, "seek": 49436, "start": 494.36, "end": 497.96000000000004, "text": " We're currently at 97% Gleam, and the rest is just Erlang foreign functions for small", "tokens": [492, 434, 4362, 412, 23399, 4, 460, 306, 335, 11, 293, 264, 1472, 307, 445, 3300, 25241, 5329, 6828, 337, 1359], "temperature": 0.0, "avg_logprob": -0.11566740466702369, "compression_ratio": 1.6083916083916083, "no_speech_prob": 3.755295620067045e-05}, {"id": 126, "seek": 49436, "start": 497.96000000000004, "end": 505.68, "text": " parts of networking, which are yet to have libraries implemented in Gleam.", "tokens": [3166, 295, 17985, 11, 597, 366, 1939, 281, 362, 15148, 12270, 294, 460, 306, 335, 13], "temperature": 0.0, "avg_logprob": -0.11566740466702369, "compression_ratio": 1.6083916083916083, "no_speech_prob": 3.755295620067045e-05}, {"id": 127, "seek": 49436, "start": 505.68, "end": 509.56, "text": " For some of you, this might now be the most interesting part of the talk, and for some", "tokens": [1171, 512, 295, 291, 11, 341, 1062, 586, 312, 264, 881, 1880, 644, 295, 264, 751, 11, 293, 337, 512], "temperature": 0.0, "avg_logprob": -0.11566740466702369, "compression_ratio": 1.6083916083916083, "no_speech_prob": 3.755295620067045e-05}, {"id": 128, "seek": 49436, "start": 509.56, "end": 510.56, "text": " of you, it might not.", "tokens": [295, 291, 11, 309, 1062, 406, 13], "temperature": 0.0, "avg_logprob": -0.11566740466702369, "compression_ratio": 1.6083916083916083, "no_speech_prob": 3.755295620067045e-05}, {"id": 129, "seek": 49436, "start": 510.56, "end": 514.16, "text": " But I'm just going to quickly touch on how Discord's gateway works so that you have a", "tokens": [583, 286, 478, 445, 516, 281, 2661, 2557, 322, 577, 32623, 311, 28532, 1985, 370, 300, 291, 362, 257], "temperature": 0.0, "avg_logprob": -0.11566740466702369, "compression_ratio": 1.6083916083916083, "no_speech_prob": 3.755295620067045e-05}, {"id": 130, "seek": 49436, "start": 514.16, "end": 520.4, "text": " better understanding of why we use actors and how that's useful to us in Gleam and", "tokens": [1101, 3701, 295, 983, 321, 764, 10037, 293, 577, 300, 311, 4420, 281, 505, 294, 460, 306, 335, 293], "temperature": 0.0, "avg_logprob": -0.11566740466702369, "compression_ratio": 1.6083916083916083, "no_speech_prob": 3.755295620067045e-05}, {"id": 131, "seek": 49436, "start": 520.4, "end": 524.12, "text": " with the OTP package.", "tokens": [365, 264, 422, 16804, 7372, 13], "temperature": 0.0, "avg_logprob": -0.11566740466702369, "compression_ratio": 1.6083916083916083, "no_speech_prob": 3.755295620067045e-05}, {"id": 132, "seek": 52412, "start": 524.12, "end": 527.96, "text": " Discord Bot is powered by Discord's real-time gateway, which uses WebSockets to send and", "tokens": [32623, 25486, 307, 17786, 538, 32623, 311, 957, 12, 3766, 28532, 11, 597, 4960, 9573, 50, 1560, 1385, 281, 2845, 293], "temperature": 0.0, "avg_logprob": -0.135744473165717, "compression_ratio": 1.6330935251798562, "no_speech_prob": 8.864852134138346e-05}, {"id": 133, "seek": 52412, "start": 527.96, "end": 529.46, "text": " receive messages.", "tokens": [4774, 7897, 13], "temperature": 0.0, "avg_logprob": -0.135744473165717, "compression_ratio": 1.6330935251798562, "no_speech_prob": 8.864852134138346e-05}, {"id": 134, "seek": 52412, "start": 529.46, "end": 535.96, "text": " For Shimmer, we use Erlang's gun library from 9.9 to receive them, and we use a typed wrapper", "tokens": [1171, 1160, 14477, 11, 321, 764, 3300, 25241, 311, 3874, 6405, 490, 1722, 13, 24, 281, 4774, 552, 11, 293, 321, 764, 257, 33941, 46906], "temperature": 0.0, "avg_logprob": -0.135744473165717, "compression_ratio": 1.6330935251798562, "no_speech_prob": 8.864852134138346e-05}, {"id": 135, "seek": 52412, "start": 535.96, "end": 543.16, "text": " on top of that, which is based upon Lewis, the creator of Gleam's Nerf library.", "tokens": [322, 1192, 295, 300, 11, 597, 307, 2361, 3564, 17412, 11, 264, 14181, 295, 460, 306, 335, 311, 36536, 69, 6405, 13], "temperature": 0.0, "avg_logprob": -0.135744473165717, "compression_ratio": 1.6330935251798562, "no_speech_prob": 8.864852134138346e-05}, {"id": 136, "seek": 52412, "start": 543.16, "end": 546.76, "text": " The diagram here shows what happens when Shimmer opens a connection to the gateway.", "tokens": [440, 10686, 510, 3110, 437, 2314, 562, 1160, 14477, 9870, 257, 4984, 281, 264, 28532, 13], "temperature": 0.0, "avg_logprob": -0.135744473165717, "compression_ratio": 1.6330935251798562, "no_speech_prob": 8.864852134138346e-05}, {"id": 137, "seek": 52412, "start": 546.76, "end": 553.72, "text": " We use ETF encoding and hand the frames off to actors to pass, manage them, and send them", "tokens": [492, 764, 37436, 43430, 293, 1011, 264, 12083, 766, 281, 10037, 281, 1320, 11, 3067, 552, 11, 293, 2845, 552], "temperature": 0.0, "avg_logprob": -0.135744473165717, "compression_ratio": 1.6330935251798562, "no_speech_prob": 8.864852134138346e-05}, {"id": 138, "seek": 55372, "start": 553.72, "end": 561.8000000000001, "text": " to the event loop, and eventually either trigger handlers or discard them.", "tokens": [281, 264, 2280, 6367, 11, 293, 4728, 2139, 7875, 1011, 11977, 420, 31597, 552, 13], "temperature": 0.0, "avg_logprob": -0.15881241584310726, "compression_ratio": 1.743801652892562, "no_speech_prob": 2.301871427334845e-05}, {"id": 139, "seek": 55372, "start": 561.8000000000001, "end": 566.24, "text": " Inside of that, Shimmer has a powerful event loop built on top of actors and messages,", "tokens": [15123, 295, 300, 11, 1160, 14477, 575, 257, 4005, 2280, 6367, 3094, 322, 1192, 295, 10037, 293, 7897, 11], "temperature": 0.0, "avg_logprob": -0.15881241584310726, "compression_ratio": 1.743801652892562, "no_speech_prob": 2.301871427334845e-05}, {"id": 140, "seek": 55372, "start": 566.24, "end": 570.12, "text": " which manages multiple messages as well as its own state, both internally and externally", "tokens": [597, 22489, 3866, 7897, 382, 731, 382, 1080, 1065, 1785, 11, 1293, 19501, 293, 40899], "temperature": 0.0, "avg_logprob": -0.15881241584310726, "compression_ratio": 1.743801652892562, "no_speech_prob": 2.301871427334845e-05}, {"id": 141, "seek": 55372, "start": 570.12, "end": 575.32, "text": " accepts messages so that you can send updates to Discord, or internally, we can manage the", "tokens": [33538, 7897, 370, 300, 291, 393, 2845, 9205, 281, 32623, 11, 420, 19501, 11, 321, 393, 3067, 264], "temperature": 0.0, "avg_logprob": -0.15881241584310726, "compression_ratio": 1.743801652892562, "no_speech_prob": 2.301871427334845e-05}, {"id": 142, "seek": 55372, "start": 575.32, "end": 577.0, "text": " updates.", "tokens": [9205, 13], "temperature": 0.0, "avg_logprob": -0.15881241584310726, "compression_ratio": 1.743801652892562, "no_speech_prob": 2.301871427334845e-05}, {"id": 143, "seek": 55372, "start": 577.0, "end": 580.88, "text": " The next slide shows a state diagram, which roughly shows how it works.", "tokens": [440, 958, 4137, 3110, 257, 1785, 10686, 11, 597, 9810, 3110, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.15881241584310726, "compression_ratio": 1.743801652892562, "no_speech_prob": 2.301871427334845e-05}, {"id": 144, "seek": 58088, "start": 580.88, "end": 586.04, "text": " The state diagram shows what happens at different stages, depending on the initial message.", "tokens": [440, 1785, 10686, 3110, 437, 2314, 412, 819, 10232, 11, 5413, 322, 264, 5883, 3636, 13], "temperature": 0.0, "avg_logprob": -0.1348969536106082, "compression_ratio": 1.700325732899023, "no_speech_prob": 2.0991357814637013e-05}, {"id": 145, "seek": 58088, "start": 586.04, "end": 589.68, "text": " For example, here, if you have a WebSocket frame, it's then passed.", "tokens": [1171, 1365, 11, 510, 11, 498, 291, 362, 257, 9573, 50, 31380, 3920, 11, 309, 311, 550, 4678, 13], "temperature": 0.0, "avg_logprob": -0.1348969536106082, "compression_ratio": 1.700325732899023, "no_speech_prob": 2.0991357814637013e-05}, {"id": 146, "seek": 58088, "start": 589.68, "end": 592.64, "text": " We then check whether it's what it's asking us to do.", "tokens": [492, 550, 1520, 1968, 309, 311, 437, 309, 311, 3365, 505, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.1348969536106082, "compression_ratio": 1.700325732899023, "no_speech_prob": 2.0991357814637013e-05}, {"id": 147, "seek": 58088, "start": 592.64, "end": 597.8, "text": " We then either respond, discard it, stop the bot, and then terminate.", "tokens": [492, 550, 2139, 4196, 11, 31597, 309, 11, 1590, 264, 10592, 11, 293, 550, 10761, 473, 13], "temperature": 0.0, "avg_logprob": -0.1348969536106082, "compression_ratio": 1.700325732899023, "no_speech_prob": 2.0991357814637013e-05}, {"id": 148, "seek": 58088, "start": 597.8, "end": 600.84, "text": " This diagram isn't complete at all, but it just shows you how complicated it can be", "tokens": [639, 10686, 1943, 380, 3566, 412, 439, 11, 457, 309, 445, 3110, 291, 577, 6179, 309, 393, 312], "temperature": 0.0, "avg_logprob": -0.1348969536106082, "compression_ratio": 1.700325732899023, "no_speech_prob": 2.0991357814637013e-05}, {"id": 149, "seek": 58088, "start": 600.84, "end": 607.12, "text": " very quickly, and how Gleam and the beam can easily handle it.", "tokens": [588, 2661, 11, 293, 577, 460, 306, 335, 293, 264, 14269, 393, 3612, 4813, 309, 13], "temperature": 0.0, "avg_logprob": -0.1348969536106082, "compression_ratio": 1.700325732899023, "no_speech_prob": 2.0991357814637013e-05}, {"id": 150, "seek": 58088, "start": 607.12, "end": 610.4, "text": " Now that we know some Gleam and understand how Shimmer works under the hood, let's actually", "tokens": [823, 300, 321, 458, 512, 460, 306, 335, 293, 1223, 577, 1160, 14477, 1985, 833, 264, 13376, 11, 718, 311, 767], "temperature": 0.0, "avg_logprob": -0.1348969536106082, "compression_ratio": 1.700325732899023, "no_speech_prob": 2.0991357814637013e-05}, {"id": 151, "seek": 61040, "start": 610.4, "end": 612.0, "text": " get our bot written.", "tokens": [483, 527, 10592, 3720, 13], "temperature": 0.0, "avg_logprob": -0.10600534596837553, "compression_ratio": 1.6907894736842106, "no_speech_prob": 5.091790808364749e-05}, {"id": 152, "seek": 61040, "start": 612.0, "end": 615.68, "text": " Above the boilerplate we're going to use, and as a side note, the final code for all", "tokens": [32691, 264, 39228, 37008, 321, 434, 516, 281, 764, 11, 293, 382, 257, 1252, 3637, 11, 264, 2572, 3089, 337, 439], "temperature": 0.0, "avg_logprob": -0.10600534596837553, "compression_ratio": 1.6907894736842106, "no_speech_prob": 5.091790808364749e-05}, {"id": 153, "seek": 61040, "start": 615.68, "end": 621.72, "text": " of this is in the GitHub repository, which there's a link to at the end.", "tokens": [295, 341, 307, 294, 264, 23331, 25841, 11, 597, 456, 311, 257, 2113, 281, 412, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.10600534596837553, "compression_ratio": 1.6907894736842106, "no_speech_prob": 5.091790808364749e-05}, {"id": 154, "seek": 61040, "start": 621.72, "end": 625.24, "text": " Shimmer uses a handler-based system, which allows for one function to be registered for", "tokens": [1160, 14477, 4960, 257, 41967, 12, 6032, 1185, 11, 597, 4045, 337, 472, 2445, 281, 312, 13968, 337], "temperature": 0.0, "avg_logprob": -0.10600534596837553, "compression_ratio": 1.6907894736842106, "no_speech_prob": 5.091790808364749e-05}, {"id": 155, "seek": 61040, "start": 625.24, "end": 626.24, "text": " each event.", "tokens": [1184, 2280, 13], "temperature": 0.0, "avg_logprob": -0.10600534596837553, "compression_ratio": 1.6907894736842106, "no_speech_prob": 5.091790808364749e-05}, {"id": 156, "seek": 61040, "start": 626.24, "end": 630.3199999999999, "text": " For the purpose of this bot, we're only registering two events, but you can always register more", "tokens": [1171, 264, 4334, 295, 341, 10592, 11, 321, 434, 787, 47329, 732, 3931, 11, 457, 291, 393, 1009, 7280, 544], "temperature": 0.0, "avg_logprob": -0.10600534596837553, "compression_ratio": 1.6907894736842106, "no_speech_prob": 5.091790808364749e-05}, {"id": 157, "seek": 61040, "start": 630.3199999999999, "end": 632.64, "text": " as and when they're implemented in Shimmer.", "tokens": [382, 293, 562, 436, 434, 12270, 294, 1160, 14477, 13], "temperature": 0.0, "avg_logprob": -0.10600534596837553, "compression_ratio": 1.6907894736842106, "no_speech_prob": 5.091790808364749e-05}, {"id": 158, "seek": 61040, "start": 632.64, "end": 637.92, "text": " But before we have a look at that, let's understand how this code uses what we learned earlier", "tokens": [583, 949, 321, 362, 257, 574, 412, 300, 11, 718, 311, 1223, 577, 341, 3089, 4960, 437, 321, 3264, 3071], "temperature": 0.0, "avg_logprob": -0.10600534596837553, "compression_ratio": 1.6907894736842106, "no_speech_prob": 5.091790808364749e-05}, {"id": 159, "seek": 63792, "start": 637.92, "end": 641.9599999999999, "text": " and what it actually does.", "tokens": [293, 437, 309, 767, 775, 13], "temperature": 0.0, "avg_logprob": -0.1646171359840883, "compression_ratio": 1.7191489361702128, "no_speech_prob": 3.4193180908914655e-05}, {"id": 160, "seek": 63792, "start": 641.9599999999999, "end": 643.8399999999999, "text": " Here we create a new Shimmer client.", "tokens": [1692, 321, 1884, 257, 777, 1160, 14477, 6423, 13], "temperature": 0.0, "avg_logprob": -0.1646171359840883, "compression_ratio": 1.7191489361702128, "no_speech_prob": 3.4193180908914655e-05}, {"id": 161, "seek": 63792, "start": 643.8399999999999, "end": 648.3199999999999, "text": " Here we use a function that wraps around a custom type.", "tokens": [1692, 321, 764, 257, 2445, 300, 25831, 926, 257, 2375, 2010, 13], "temperature": 0.0, "avg_logprob": -0.1646171359840883, "compression_ratio": 1.7191489361702128, "no_speech_prob": 3.4193180908914655e-05}, {"id": 162, "seek": 63792, "start": 648.3199999999999, "end": 653.12, "text": " The custom type holds both internal data as well as token, intents, and other data you", "tokens": [440, 2375, 2010, 9190, 1293, 6920, 1412, 382, 731, 382, 14862, 11, 560, 791, 11, 293, 661, 1412, 291], "temperature": 0.0, "avg_logprob": -0.1646171359840883, "compression_ratio": 1.7191489361702128, "no_speech_prob": 3.4193180908914655e-05}, {"id": 163, "seek": 63792, "start": 653.12, "end": 654.12, "text": " pass in.", "tokens": [1320, 294, 13], "temperature": 0.0, "avg_logprob": -0.1646171359840883, "compression_ratio": 1.7191489361702128, "no_speech_prob": 3.4193180908914655e-05}, {"id": 164, "seek": 63792, "start": 654.12, "end": 656.04, "text": " So we create a function to wrap it.", "tokens": [407, 321, 1884, 257, 2445, 281, 7019, 309, 13], "temperature": 0.0, "avg_logprob": -0.1646171359840883, "compression_ratio": 1.7191489361702128, "no_speech_prob": 3.4193180908914655e-05}, {"id": 165, "seek": 63792, "start": 656.04, "end": 659.52, "text": " That way you don't have to manage all of that state yourself.", "tokens": [663, 636, 291, 500, 380, 362, 281, 3067, 439, 295, 300, 1785, 1803, 13], "temperature": 0.0, "avg_logprob": -0.1646171359840883, "compression_ratio": 1.7191489361702128, "no_speech_prob": 3.4193180908914655e-05}, {"id": 166, "seek": 63792, "start": 659.52, "end": 664.88, "text": " And then we pipe that into the connect function, where it takes the client, passes that as", "tokens": [400, 550, 321, 11240, 300, 666, 264, 1745, 2445, 11, 689, 309, 2516, 264, 6423, 11, 11335, 300, 382], "temperature": 0.0, "avg_logprob": -0.1646171359840883, "compression_ratio": 1.7191489361702128, "no_speech_prob": 3.4193180908914655e-05}, {"id": 167, "seek": 66488, "start": 664.88, "end": 669.76, "text": " the first parameter, and then passes your handlers in as the second.", "tokens": [264, 700, 13075, 11, 293, 550, 11335, 428, 1011, 11977, 294, 382, 264, 1150, 13], "temperature": 0.0, "avg_logprob": -0.18714954407234502, "compression_ratio": 1.6724137931034482, "no_speech_prob": 1.0046731404145248e-05}, {"id": 168, "seek": 66488, "start": 669.76, "end": 672.6, "text": " Normally the token should be an environment variable, but for the purpose of this, we're", "tokens": [17424, 264, 14862, 820, 312, 364, 2823, 7006, 11, 457, 337, 264, 4334, 295, 341, 11, 321, 434], "temperature": 0.0, "avg_logprob": -0.18714954407234502, "compression_ratio": 1.6724137931034482, "no_speech_prob": 1.0046731404145248e-05}, {"id": 169, "seek": 66488, "start": 672.6, "end": 674.16, "text": " just using a string.", "tokens": [445, 1228, 257, 6798, 13], "temperature": 0.0, "avg_logprob": -0.18714954407234502, "compression_ratio": 1.6724137931034482, "no_speech_prob": 1.0046731404145248e-05}, {"id": 170, "seek": 66488, "start": 674.16, "end": 678.52, "text": " Finally, we'll tell Erlang to sleep forever so that our actor and supervisor can run in", "tokens": [6288, 11, 321, 603, 980, 3300, 25241, 281, 2817, 5680, 370, 300, 527, 8747, 293, 24610, 393, 1190, 294], "temperature": 0.0, "avg_logprob": -0.18714954407234502, "compression_ratio": 1.6724137931034482, "no_speech_prob": 1.0046731404145248e-05}, {"id": 171, "seek": 66488, "start": 678.52, "end": 685.96, "text": " the background, accepting messages from the gateway, and passing them to the event loop.", "tokens": [264, 3678, 11, 17391, 7897, 490, 264, 28532, 11, 293, 8437, 552, 281, 264, 2280, 6367, 13], "temperature": 0.0, "avg_logprob": -0.18714954407234502, "compression_ratio": 1.6724137931034482, "no_speech_prob": 1.0046731404145248e-05}, {"id": 172, "seek": 66488, "start": 685.96, "end": 691.16, "text": " Now that we know what it all vaguely does, let's revisit the handlers.", "tokens": [823, 300, 321, 458, 437, 309, 439, 13501, 48863, 775, 11, 718, 311, 32676, 264, 1011, 11977, 13], "temperature": 0.0, "avg_logprob": -0.18714954407234502, "compression_ratio": 1.6724137931034482, "no_speech_prob": 1.0046731404145248e-05}, {"id": 173, "seek": 66488, "start": 691.16, "end": 693.44, "text": " First we're going to add a handler for the on-ready event.", "tokens": [2386, 321, 434, 516, 281, 909, 257, 41967, 337, 264, 322, 12, 1201, 2280, 13], "temperature": 0.0, "avg_logprob": -0.18714954407234502, "compression_ratio": 1.6724137931034482, "no_speech_prob": 1.0046731404145248e-05}, {"id": 174, "seek": 69344, "start": 693.44, "end": 696.8800000000001, "text": " All handlers are passed in their event, as well as the client.", "tokens": [1057, 1011, 11977, 366, 4678, 294, 641, 2280, 11, 382, 731, 382, 264, 6423, 13], "temperature": 0.0, "avg_logprob": -0.14146294510155394, "compression_ratio": 1.8070866141732282, "no_speech_prob": 2.9512346372939646e-05}, {"id": 175, "seek": 69344, "start": 696.8800000000001, "end": 701.36, "text": " That way you can use the client to call other methods, such as updating the bot's presence", "tokens": [663, 636, 291, 393, 764, 264, 6423, 281, 818, 661, 7150, 11, 1270, 382, 25113, 264, 10592, 311, 6814], "temperature": 0.0, "avg_logprob": -0.14146294510155394, "compression_ratio": 1.8070866141732282, "no_speech_prob": 2.9512346372939646e-05}, {"id": 176, "seek": 69344, "start": 701.36, "end": 704.08, "text": " or sending messages yourself across the gateway.", "tokens": [420, 7750, 7897, 1803, 2108, 264, 28532, 13], "temperature": 0.0, "avg_logprob": -0.14146294510155394, "compression_ratio": 1.8070866141732282, "no_speech_prob": 2.9512346372939646e-05}, {"id": 177, "seek": 69344, "start": 704.08, "end": 709.8000000000001, "text": " On the client, there's no private accesses, so you can access all the internal stuff as", "tokens": [1282, 264, 6423, 11, 456, 311, 572, 4551, 2105, 279, 11, 370, 291, 393, 2105, 439, 264, 6920, 1507, 382], "temperature": 0.0, "avg_logprob": -0.14146294510155394, "compression_ratio": 1.8070866141732282, "no_speech_prob": 2.9512346372939646e-05}, {"id": 178, "seek": 69344, "start": 709.8000000000001, "end": 712.8000000000001, "text": " well if you want to add your own custom functionality.", "tokens": [731, 498, 291, 528, 281, 909, 428, 1065, 2375, 14980, 13], "temperature": 0.0, "avg_logprob": -0.14146294510155394, "compression_ratio": 1.8070866141732282, "no_speech_prob": 2.9512346372939646e-05}, {"id": 179, "seek": 69344, "start": 712.8000000000001, "end": 717.0, "text": " The client has its gun connection and all that other stuff in there as well, so you", "tokens": [440, 6423, 575, 1080, 3874, 4984, 293, 439, 300, 661, 1507, 294, 456, 382, 731, 11, 370, 291], "temperature": 0.0, "avg_logprob": -0.14146294510155394, "compression_ratio": 1.8070866141732282, "no_speech_prob": 2.9512346372939646e-05}, {"id": 180, "seek": 69344, "start": 717.0, "end": 721.4000000000001, "text": " can adapt that as you please.", "tokens": [393, 6231, 300, 382, 291, 1767, 13], "temperature": 0.0, "avg_logprob": -0.14146294510155394, "compression_ratio": 1.8070866141732282, "no_speech_prob": 2.9512346372939646e-05}, {"id": 181, "seek": 72140, "start": 721.4, "end": 724.9599999999999, "text": " Let's quickly zoom into the handler and explore that.", "tokens": [961, 311, 2661, 8863, 666, 264, 41967, 293, 6839, 300, 13], "temperature": 0.0, "avg_logprob": -0.17053769215816209, "compression_ratio": 1.6593406593406594, "no_speech_prob": 1.87470704986481e-05}, {"id": 182, "seek": 72140, "start": 724.9599999999999, "end": 729.8, "text": " Here, you can see the event in this case is an on-ready event, which provides us crucial", "tokens": [1692, 11, 291, 393, 536, 264, 2280, 294, 341, 1389, 307, 364, 322, 12, 1201, 2280, 11, 597, 6417, 505, 11462], "temperature": 0.0, "avg_logprob": -0.17053769215816209, "compression_ratio": 1.6593406593406594, "no_speech_prob": 1.87470704986481e-05}, {"id": 183, "seek": 72140, "start": 729.8, "end": 730.8, "text": " information.", "tokens": [1589, 13], "temperature": 0.0, "avg_logprob": -0.17053769215816209, "compression_ratio": 1.6593406593406594, "no_speech_prob": 1.87470704986481e-05}, {"id": 184, "seek": 72140, "start": 730.8, "end": 737.04, "text": " As I said before, there's the client that we have just spoken about.", "tokens": [1018, 286, 848, 949, 11, 456, 311, 264, 6423, 300, 321, 362, 445, 10759, 466, 13], "temperature": 0.0, "avg_logprob": -0.17053769215816209, "compression_ratio": 1.6593406593406594, "no_speech_prob": 1.87470704986481e-05}, {"id": 185, "seek": 72140, "start": 737.04, "end": 741.8, "text": " The Gleams accesses syntax we learned about earlier makes it easy to access fields within", "tokens": [440, 460, 306, 4070, 2105, 279, 28431, 321, 3264, 466, 3071, 1669, 309, 1858, 281, 2105, 7909, 1951], "temperature": 0.0, "avg_logprob": -0.17053769215816209, "compression_ratio": 1.6593406593406594, "no_speech_prob": 1.87470704986481e-05}, {"id": 186, "seek": 72140, "start": 741.8, "end": 744.0, "text": " the types, even when they're two levels deep.", "tokens": [264, 3467, 11, 754, 562, 436, 434, 732, 4358, 2452, 13], "temperature": 0.0, "avg_logprob": -0.17053769215816209, "compression_ratio": 1.6593406593406594, "no_speech_prob": 1.87470704986481e-05}, {"id": 187, "seek": 72140, "start": 744.0, "end": 750.3199999999999, "text": " As you can see here, we're accessing the user's ID, which is in the user field of the event,", "tokens": [1018, 291, 393, 536, 510, 11, 321, 434, 26440, 264, 4195, 311, 7348, 11, 597, 307, 294, 264, 4195, 2519, 295, 264, 2280, 11], "temperature": 0.0, "avg_logprob": -0.17053769215816209, "compression_ratio": 1.6593406593406594, "no_speech_prob": 1.87470704986481e-05}, {"id": 188, "seek": 75032, "start": 750.32, "end": 755.44, "text": " and then we're printing it to the console using the standard libraries IO.", "tokens": [293, 550, 321, 434, 14699, 309, 281, 264, 11076, 1228, 264, 3832, 15148, 39839, 13], "temperature": 0.0, "avg_logprob": -0.11464555686879381, "compression_ratio": 1.6984732824427482, "no_speech_prob": 8.327568139065988e-06}, {"id": 189, "seek": 75032, "start": 755.44, "end": 760.44, "text": " We can then make this into a function, and then we can pass that into our on-ready handler.", "tokens": [492, 393, 550, 652, 341, 666, 257, 2445, 11, 293, 550, 321, 393, 1320, 300, 666, 527, 322, 12, 1201, 41967, 13], "temperature": 0.0, "avg_logprob": -0.11464555686879381, "compression_ratio": 1.6984732824427482, "no_speech_prob": 8.327568139065988e-06}, {"id": 190, "seek": 75032, "start": 760.44, "end": 763.84, "text": " That way we could have the functions in multiple different files and import them from across", "tokens": [663, 636, 321, 727, 362, 264, 6828, 294, 3866, 819, 7098, 293, 974, 552, 490, 2108], "temperature": 0.0, "avg_logprob": -0.11464555686879381, "compression_ratio": 1.6984732824427482, "no_speech_prob": 8.327568139065988e-06}, {"id": 191, "seek": 75032, "start": 763.84, "end": 768.0, "text": " the project to keep everything tidy.", "tokens": [264, 1716, 281, 1066, 1203, 34646, 13], "temperature": 0.0, "avg_logprob": -0.11464555686879381, "compression_ratio": 1.6984732824427482, "no_speech_prob": 8.327568139065988e-06}, {"id": 192, "seek": 75032, "start": 768.0, "end": 773.36, "text": " Let's move on to actually receiving some messages and sending some responses.", "tokens": [961, 311, 1286, 322, 281, 767, 10040, 512, 7897, 293, 7750, 512, 13019, 13], "temperature": 0.0, "avg_logprob": -0.11464555686879381, "compression_ratio": 1.6984732824427482, "no_speech_prob": 8.327568139065988e-06}, {"id": 193, "seek": 75032, "start": 773.36, "end": 779.1600000000001, "text": " When we receive a message, we get the on-message payload as our event.", "tokens": [1133, 321, 4774, 257, 3636, 11, 321, 483, 264, 322, 12, 76, 442, 609, 30918, 382, 527, 2280, 13], "temperature": 0.0, "avg_logprob": -0.11464555686879381, "compression_ratio": 1.6984732824427482, "no_speech_prob": 8.327568139065988e-06}, {"id": 194, "seek": 77916, "start": 779.16, "end": 783.4399999999999, "text": " This contains information about the message itself, as well as the Guild ID mentions the", "tokens": [639, 8306, 1589, 466, 264, 3636, 2564, 11, 382, 731, 382, 264, 38968, 7348, 23844, 264], "temperature": 0.0, "avg_logprob": -0.12848336236518726, "compression_ratio": 1.7472527472527473, "no_speech_prob": 6.807201771152904e-06}, {"id": 195, "seek": 77916, "start": 783.4399999999999, "end": 786.64, "text": " message content and other variables.", "tokens": [3636, 2701, 293, 661, 9102, 13], "temperature": 0.0, "avg_logprob": -0.12848336236518726, "compression_ratio": 1.7472527472527473, "no_speech_prob": 6.807201771152904e-06}, {"id": 196, "seek": 77916, "start": 786.64, "end": 789.92, "text": " For now, we're going to assign the content to a variable for ease, but we can always", "tokens": [1171, 586, 11, 321, 434, 516, 281, 6269, 264, 2701, 281, 257, 7006, 337, 12708, 11, 457, 321, 393, 1009], "temperature": 0.0, "avg_logprob": -0.12848336236518726, "compression_ratio": 1.7472527472527473, "no_speech_prob": 6.807201771152904e-06}, {"id": 197, "seek": 77916, "start": 789.92, "end": 795.52, "text": " collapse that into the case statement we use later on if that isn't something you need.", "tokens": [15584, 300, 666, 264, 1389, 5629, 321, 764, 1780, 322, 498, 300, 1943, 380, 746, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.12848336236518726, "compression_ratio": 1.7472527472527473, "no_speech_prob": 6.807201771152904e-06}, {"id": 198, "seek": 77916, "start": 795.52, "end": 801.0799999999999, "text": " Let's have a look how we're going to use our pattern matching to match against the content.", "tokens": [961, 311, 362, 257, 574, 577, 321, 434, 516, 281, 764, 527, 5102, 14324, 281, 2995, 1970, 264, 2701, 13], "temperature": 0.0, "avg_logprob": -0.12848336236518726, "compression_ratio": 1.7472527472527473, "no_speech_prob": 6.807201771152904e-06}, {"id": 199, "seek": 77916, "start": 801.0799999999999, "end": 804.56, "text": " Using Gleams' powerful pattern matching, we can check it as a desired prefix, and then", "tokens": [11142, 460, 306, 4070, 6, 4005, 5102, 14324, 11, 321, 393, 1520, 309, 382, 257, 14721, 46969, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.12848336236518726, "compression_ratio": 1.7472527472527473, "no_speech_prob": 6.807201771152904e-06}, {"id": 200, "seek": 80456, "start": 804.56, "end": 809.3199999999999, "text": " we can extract the part to the right of the prefix into a separate variable.", "tokens": [321, 393, 8947, 264, 644, 281, 264, 558, 295, 264, 46969, 666, 257, 4994, 7006, 13], "temperature": 0.0, "avg_logprob": -0.12322078534026644, "compression_ratio": 1.7740863787375416, "no_speech_prob": 9.149423021881375e-06}, {"id": 201, "seek": 80456, "start": 809.3199999999999, "end": 813.4399999999999, "text": " If not, we can take the message out itself, and we can just print that for easier debugging", "tokens": [759, 406, 11, 321, 393, 747, 264, 3636, 484, 2564, 11, 293, 321, 393, 445, 4482, 300, 337, 3571, 45592], "temperature": 0.0, "avg_logprob": -0.12322078534026644, "compression_ratio": 1.7740863787375416, "no_speech_prob": 9.149423021881375e-06}, {"id": 202, "seek": 80456, "start": 813.4399999999999, "end": 814.4399999999999, "text": " for now.", "tokens": [337, 586, 13], "temperature": 0.0, "avg_logprob": -0.12322078534026644, "compression_ratio": 1.7740863787375416, "no_speech_prob": 9.149423021881375e-06}, {"id": 203, "seek": 80456, "start": 814.4399999999999, "end": 816.7199999999999, "text": " Let's say we want a specific command, though.", "tokens": [961, 311, 584, 321, 528, 257, 2685, 5622, 11, 1673, 13], "temperature": 0.0, "avg_logprob": -0.12322078534026644, "compression_ratio": 1.7740863787375416, "no_speech_prob": 9.149423021881375e-06}, {"id": 204, "seek": 80456, "start": 816.7199999999999, "end": 821.64, "text": " We could either add another case statement onto that, or we could just edit it so it's", "tokens": [492, 727, 2139, 909, 1071, 1389, 5629, 3911, 300, 11, 420, 321, 727, 445, 8129, 309, 370, 309, 311], "temperature": 0.0, "avg_logprob": -0.12322078534026644, "compression_ratio": 1.7740863787375416, "no_speech_prob": 9.149423021881375e-06}, {"id": 205, "seek": 80456, "start": 821.64, "end": 825.52, "text": " exclamation mark on what we want as the string of pattern matching against.", "tokens": [1624, 43233, 1491, 322, 437, 321, 528, 382, 264, 6798, 295, 5102, 14324, 1970, 13], "temperature": 0.0, "avg_logprob": -0.12322078534026644, "compression_ratio": 1.7740863787375416, "no_speech_prob": 9.149423021881375e-06}, {"id": 206, "seek": 80456, "start": 825.52, "end": 827.5999999999999, "text": " Let's say, for example, you wanted some arguments, though.", "tokens": [961, 311, 584, 11, 337, 1365, 11, 291, 1415, 512, 12869, 11, 1673, 13], "temperature": 0.0, "avg_logprob": -0.12322078534026644, "compression_ratio": 1.7740863787375416, "no_speech_prob": 9.149423021881375e-06}, {"id": 207, "seek": 80456, "start": 827.5999999999999, "end": 830.8, "text": " You could put the two together, and you could have your prefix with the command and take", "tokens": [509, 727, 829, 264, 732, 1214, 11, 293, 291, 727, 362, 428, 46969, 365, 264, 5622, 293, 747], "temperature": 0.0, "avg_logprob": -0.12322078534026644, "compression_ratio": 1.7740863787375416, "no_speech_prob": 9.149423021881375e-06}, {"id": 208, "seek": 83080, "start": 830.8, "end": 837.16, "text": " all of the arguments out separately to then pass and manage them.", "tokens": [439, 295, 264, 12869, 484, 14759, 281, 550, 1320, 293, 3067, 552, 13], "temperature": 0.0, "avg_logprob": -0.13476390649776648, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.4273759916250128e-05}, {"id": 209, "seek": 83080, "start": 837.16, "end": 841.76, "text": " Now we'll match against a specific command, and in the response, we'll use the message", "tokens": [823, 321, 603, 2995, 1970, 257, 2685, 5622, 11, 293, 294, 264, 4134, 11, 321, 603, 764, 264, 3636], "temperature": 0.0, "avg_logprob": -0.13476390649776648, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.4273759916250128e-05}, {"id": 210, "seek": 83080, "start": 841.76, "end": 848.4399999999999, "text": " send function to reply to the user by sending another message.", "tokens": [2845, 2445, 281, 16972, 281, 264, 4195, 538, 7750, 1071, 3636, 13], "temperature": 0.0, "avg_logprob": -0.13476390649776648, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.4273759916250128e-05}, {"id": 211, "seek": 83080, "start": 848.4399999999999, "end": 854.52, "text": " As before, we can use the Handler's Builder to add this in as a function, and the bot", "tokens": [1018, 949, 11, 321, 393, 764, 264, 8854, 1918, 311, 11875, 260, 281, 909, 341, 294, 382, 257, 2445, 11, 293, 264, 10592], "temperature": 0.0, "avg_logprob": -0.13476390649776648, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.4273759916250128e-05}, {"id": 212, "seek": 83080, "start": 854.52, "end": 855.52, "text": " should be done.", "tokens": [820, 312, 1096, 13], "temperature": 0.0, "avg_logprob": -0.13476390649776648, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.4273759916250128e-05}, {"id": 213, "seek": 83080, "start": 855.52, "end": 859.68, "text": " Now you have a basic ping pong where you can send and receive messages using basically", "tokens": [823, 291, 362, 257, 3875, 26151, 36164, 689, 291, 393, 2845, 293, 4774, 7897, 1228, 1936], "temperature": 0.0, "avg_logprob": -0.13476390649776648, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.4273759916250128e-05}, {"id": 214, "seek": 85968, "start": 859.68, "end": 864.0799999999999, "text": " everything you learned from the introduction earlier.", "tokens": [1203, 291, 3264, 490, 264, 9339, 3071, 13], "temperature": 0.0, "avg_logprob": -0.19630832116580704, "compression_ratio": 1.58, "no_speech_prob": 5.922707714489661e-05}, {"id": 215, "seek": 85968, "start": 864.0799999999999, "end": 866.8399999999999, "text": " This before code, as I said earlier, was available on the GitHub as well, if you want", "tokens": [639, 949, 3089, 11, 382, 286, 848, 3071, 11, 390, 2435, 322, 264, 23331, 382, 731, 11, 498, 291, 528], "temperature": 0.0, "avg_logprob": -0.19630832116580704, "compression_ratio": 1.58, "no_speech_prob": 5.922707714489661e-05}, {"id": 216, "seek": 85968, "start": 866.8399999999999, "end": 870.5999999999999, "text": " to have a look and take a deeper dive there.", "tokens": [281, 362, 257, 574, 293, 747, 257, 7731, 9192, 456, 13], "temperature": 0.0, "avg_logprob": -0.19630832116580704, "compression_ratio": 1.58, "no_speech_prob": 5.922707714489661e-05}, {"id": 217, "seek": 85968, "start": 870.5999999999999, "end": 874.3199999999999, "text": " Just to recap, at the start of the talk, we went over some Gleam syntax before we get", "tokens": [1449, 281, 20928, 11, 412, 264, 722, 295, 264, 751, 11, 321, 1437, 670, 512, 460, 306, 335, 28431, 949, 321, 483], "temperature": 0.0, "avg_logprob": -0.19630832116580704, "compression_ratio": 1.58, "no_speech_prob": 5.922707714489661e-05}, {"id": 218, "seek": 85968, "start": 874.3199999999999, "end": 875.76, "text": " ready on our exploration of Shimmer.", "tokens": [1919, 322, 527, 16197, 295, 1160, 14477, 13], "temperature": 0.0, "avg_logprob": -0.19630832116580704, "compression_ratio": 1.58, "no_speech_prob": 5.922707714489661e-05}, {"id": 219, "seek": 85968, "start": 875.76, "end": 880.4, "text": " We found out how the Discord's gateway worked on a high level and how to leverage Gleam", "tokens": [492, 1352, 484, 577, 264, 32623, 311, 28532, 2732, 322, 257, 1090, 1496, 293, 577, 281, 13982, 460, 306, 335], "temperature": 0.0, "avg_logprob": -0.19630832116580704, "compression_ratio": 1.58, "no_speech_prob": 5.922707714489661e-05}, {"id": 220, "seek": 88040, "start": 880.4, "end": 890.04, "text": " OTP, and how Gleam OTP is leveraged within Shimmer for Actors.", "tokens": [422, 16804, 11, 293, 577, 460, 306, 335, 422, 16804, 307, 12451, 2980, 1951, 1160, 14477, 337, 3251, 830, 13], "temperature": 0.0, "avg_logprob": -0.16722307886396134, "compression_ratio": 1.5, "no_speech_prob": 4.539206929621287e-05}, {"id": 221, "seek": 88040, "start": 890.04, "end": 893.92, "text": " Thank you very much for listening, and if there's some QR codes to the Gleam website", "tokens": [1044, 291, 588, 709, 337, 4764, 11, 293, 498, 456, 311, 512, 32784, 14211, 281, 264, 460, 306, 335, 3144], "temperature": 0.0, "avg_logprob": -0.16722307886396134, "compression_ratio": 1.5, "no_speech_prob": 4.539206929621287e-05}, {"id": 222, "seek": 88040, "start": 893.92, "end": 896.88, "text": " as well as the Gleam Discord, if you want to talk there, and if there's any questions,", "tokens": [382, 731, 382, 264, 460, 306, 335, 32623, 11, 498, 291, 528, 281, 751, 456, 11, 293, 498, 456, 311, 604, 1651, 11], "temperature": 0.0, "avg_logprob": -0.16722307886396134, "compression_ratio": 1.5, "no_speech_prob": 4.539206929621287e-05}, {"id": 223, "seek": 88040, "start": 896.88, "end": 906.16, "text": " I'm happy to take them if I have time.", "tokens": [286, 478, 2055, 281, 747, 552, 498, 286, 362, 565, 13], "temperature": 0.0, "avg_logprob": -0.16722307886396134, "compression_ratio": 1.5, "no_speech_prob": 4.539206929621287e-05}, {"id": 224, "seek": 90616, "start": 906.16, "end": 912.4, "text": " So there's time for questions.", "tokens": [407, 456, 311, 565, 337, 1651, 13], "temperature": 0.0, "avg_logprob": -0.2307937168838954, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00046431642840616405}, {"id": 225, "seek": 90616, "start": 912.4, "end": 919.36, "text": " You showed the tuple access syntax, which was tuple dot zero, tuple dot one.", "tokens": [509, 4712, 264, 2604, 781, 2105, 28431, 11, 597, 390, 2604, 781, 5893, 4018, 11, 2604, 781, 5893, 472, 13], "temperature": 0.0, "avg_logprob": -0.2307937168838954, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00046431642840616405}, {"id": 226, "seek": 90616, "start": 919.36, "end": 926.28, "text": " Does that mean that if you use a record, or if it's called, can you still use zero as", "tokens": [4402, 300, 914, 300, 498, 291, 764, 257, 2136, 11, 420, 498, 309, 311, 1219, 11, 393, 291, 920, 764, 4018, 382], "temperature": 0.0, "avg_logprob": -0.2307937168838954, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00046431642840616405}, {"id": 227, "seek": 90616, "start": 926.28, "end": 927.28, "text": " a key?", "tokens": [257, 2141, 30], "temperature": 0.0, "avg_logprob": -0.2307937168838954, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00046431642840616405}, {"id": 228, "seek": 90616, "start": 927.28, "end": 928.28, "text": " Or is that not?", "tokens": [1610, 307, 300, 406, 30], "temperature": 0.0, "avg_logprob": -0.2307937168838954, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00046431642840616405}, {"id": 229, "seek": 90616, "start": 928.28, "end": 931.24, "text": " If you use a custom type, no.", "tokens": [759, 291, 764, 257, 2375, 2010, 11, 572, 13], "temperature": 0.0, "avg_logprob": -0.2307937168838954, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00046431642840616405}, {"id": 230, "seek": 90616, "start": 931.24, "end": 934.04, "text": " When you use custom types, you have to use the keys you define in the custom type to", "tokens": [1133, 291, 764, 2375, 3467, 11, 291, 362, 281, 764, 264, 9317, 291, 6964, 294, 264, 2375, 2010, 281], "temperature": 0.0, "avg_logprob": -0.2307937168838954, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00046431642840616405}, {"id": 231, "seek": 93404, "start": 934.04, "end": 941.92, "text": " access them, the index syntax is only available for tuples.", "tokens": [2105, 552, 11, 264, 8186, 28431, 307, 787, 2435, 337, 2604, 2622, 13], "temperature": 0.0, "avg_logprob": -0.23475970719989978, "compression_ratio": 1.5, "no_speech_prob": 0.0006040013395249844}, {"id": 232, "seek": 93404, "start": 941.92, "end": 943.0799999999999, "text": " Question there.", "tokens": [14464, 456, 13], "temperature": 0.0, "avg_logprob": -0.23475970719989978, "compression_ratio": 1.5, "no_speech_prob": 0.0006040013395249844}, {"id": 233, "seek": 93404, "start": 943.0799999999999, "end": 952.36, "text": " I have a question about the handlers on the library, and about Gleam, I guess.", "tokens": [286, 362, 257, 1168, 466, 264, 1011, 11977, 322, 264, 6405, 11, 293, 466, 460, 306, 335, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.23475970719989978, "compression_ratio": 1.5, "no_speech_prob": 0.0006040013395249844}, {"id": 234, "seek": 93404, "start": 952.36, "end": 959.04, "text": " When I'm writing the handler, do I know what type of the event is, and the client, by the", "tokens": [1133, 286, 478, 3579, 264, 41967, 11, 360, 286, 458, 437, 2010, 295, 264, 2280, 307, 11, 293, 264, 6423, 11, 538, 264], "temperature": 0.0, "avg_logprob": -0.23475970719989978, "compression_ratio": 1.5, "no_speech_prob": 0.0006040013395249844}, {"id": 235, "seek": 93404, "start": 959.04, "end": 960.04, "text": " time of writing?", "tokens": [565, 295, 3579, 30], "temperature": 0.0, "avg_logprob": -0.23475970719989978, "compression_ratio": 1.5, "no_speech_prob": 0.0006040013395249844}, {"id": 236, "seek": 96004, "start": 960.04, "end": 966.4399999999999, "text": " Yes, so when a Gleam project is put onto Hex, we produce Hex docs, and they're all documented", "tokens": [1079, 11, 370, 562, 257, 460, 306, 335, 1716, 307, 829, 3911, 634, 87, 11, 321, 5258, 634, 87, 45623, 11, 293, 436, 434, 439, 23007], "temperature": 0.0, "avg_logprob": -0.2469053508854714, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.00034265435533598065}, {"id": 237, "seek": 96004, "start": 966.4399999999999, "end": 967.4399999999999, "text": " there as well.", "tokens": [456, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.2469053508854714, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.00034265435533598065}, {"id": 238, "seek": 96004, "start": 967.4399999999999, "end": 973.4, "text": " So the types on Hex docs you can look at, and also Gleam has an LSP built into it, which", "tokens": [407, 264, 3467, 322, 634, 87, 45623, 291, 393, 574, 412, 11, 293, 611, 460, 306, 335, 575, 364, 441, 27921, 3094, 666, 309, 11, 597], "temperature": 0.0, "avg_logprob": -0.2469053508854714, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.00034265435533598065}, {"id": 239, "seek": 96004, "start": 973.4, "end": 980.0, "text": " gives you the information, which is going to give you the information in your editor.", "tokens": [2709, 291, 264, 1589, 11, 597, 307, 516, 281, 976, 291, 264, 1589, 294, 428, 9839, 13], "temperature": 0.0, "avg_logprob": -0.2469053508854714, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.00034265435533598065}, {"id": 240, "seek": 96004, "start": 980.0, "end": 981.48, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2469053508854714, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.00034265435533598065}, {"id": 241, "seek": 96004, "start": 981.48, "end": 983.7199999999999, "text": " Hello.", "tokens": [2425, 13], "temperature": 0.0, "avg_logprob": -0.2469053508854714, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.00034265435533598065}, {"id": 242, "seek": 96004, "start": 983.7199999999999, "end": 989.4399999999999, "text": " If you're used to LX0, what are the things that you would miss in Gleam, or is there a", "tokens": [759, 291, 434, 1143, 281, 441, 55, 15, 11, 437, 366, 264, 721, 300, 291, 576, 1713, 294, 460, 306, 335, 11, 420, 307, 456, 257], "temperature": 0.0, "avg_logprob": -0.2469053508854714, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.00034265435533598065}, {"id": 243, "seek": 98944, "start": 989.44, "end": 991.6800000000001, "text": " big overlap?", "tokens": [955, 19959, 30], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 244, "seek": 98944, "start": 991.6800000000001, "end": 996.6400000000001, "text": " There's a fairly, it has most of the features you're used to, along with your type safety.", "tokens": [821, 311, 257, 6457, 11, 309, 575, 881, 295, 264, 4122, 291, 434, 1143, 281, 11, 2051, 365, 428, 2010, 4514, 13], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 245, "seek": 98944, "start": 996.6400000000001, "end": 1000.24, "text": " The only, I guess, difference would be in Elixir, you can define multiple modules in", "tokens": [440, 787, 11, 286, 2041, 11, 2649, 576, 312, 294, 2699, 970, 347, 11, 291, 393, 6964, 3866, 16679, 294], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 246, "seek": 98944, "start": 1000.24, "end": 1004.32, "text": " one file, whereas in Gleam, that's not really something.", "tokens": [472, 3991, 11, 9735, 294, 460, 306, 335, 11, 300, 311, 406, 534, 746, 13], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 247, "seek": 98944, "start": 1004.32, "end": 1005.8000000000001, "text": " Modules are files themselves.", "tokens": [6583, 3473, 366, 7098, 2969, 13], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 248, "seek": 98944, "start": 1005.8000000000001, "end": 1008.2800000000001, "text": " I guess that's the only thing I could think of off the top of my head.", "tokens": [286, 2041, 300, 311, 264, 787, 551, 286, 727, 519, 295, 766, 264, 1192, 295, 452, 1378, 13], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 249, "seek": 98944, "start": 1008.2800000000001, "end": 1009.2800000000001, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 250, "seek": 98944, "start": 1009.2800000000001, "end": 1010.2800000000001, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 251, "seek": 98944, "start": 1010.2800000000001, "end": 1011.2800000000001, "text": " No worries.", "tokens": [883, 16340, 13], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 252, "seek": 98944, "start": 1011.2800000000001, "end": 1013.1600000000001, "text": " Is there a microse as well?", "tokens": [1119, 456, 257, 3123, 37841, 382, 731, 30], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 253, "seek": 98944, "start": 1013.1600000000001, "end": 1017.72, "text": " No, we don't have macros right now, but there has been several discussions about how we", "tokens": [883, 11, 321, 500, 380, 362, 7912, 2635, 558, 586, 11, 457, 456, 575, 668, 2940, 11088, 466, 577, 321], "temperature": 0.0, "avg_logprob": -0.1959349446826511, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00025197427021339536}, {"id": 254, "seek": 101772, "start": 1017.72, "end": 1021.44, "text": " want to do them and what they're going to be like, so there's potential for that in the", "tokens": [528, 281, 360, 552, 293, 437, 436, 434, 516, 281, 312, 411, 11, 370, 456, 311, 3995, 337, 300, 294, 264], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 255, "seek": 101772, "start": 1021.44, "end": 1025.3600000000001, "text": " future.", "tokens": [2027, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 256, "seek": 101772, "start": 1025.3600000000001, "end": 1027.3600000000001, "text": " Any more questions?", "tokens": [2639, 544, 1651, 30], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 257, "seek": 101772, "start": 1027.3600000000001, "end": 1028.3600000000001, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 258, "seek": 101772, "start": 1028.3600000000001, "end": 1029.3600000000001, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 259, "seek": 101772, "start": 1029.3600000000001, "end": 1030.3600000000001, "text": " I'm sorry.", "tokens": [286, 478, 2597, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 260, "seek": 101772, "start": 1030.3600000000001, "end": 1031.3600000000001, "text": " Thank you for your talk.", "tokens": [1044, 291, 337, 428, 751, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 261, "seek": 101772, "start": 1031.3600000000001, "end": 1032.3600000000001, "text": " It was very nice.", "tokens": [467, 390, 588, 1481, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 262, "seek": 101772, "start": 1032.3600000000001, "end": 1033.3600000000001, "text": " I have one question.", "tokens": [286, 362, 472, 1168, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 263, "seek": 101772, "start": 1033.3600000000001, "end": 1034.3600000000001, "text": " I think currently it's version 0.25 of Gleam, or 0.26.", "tokens": [286, 519, 4362, 309, 311, 3037, 1958, 13, 6074, 295, 460, 306, 335, 11, 420, 1958, 13, 10880, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 264, "seek": 101772, "start": 1034.3600000000001, "end": 1035.3600000000001, "text": " 0.26, yeah.", "tokens": [1958, 13, 10880, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 265, "seek": 101772, "start": 1035.3600000000001, "end": 1036.3600000000001, "text": " I'm sorry.", "tokens": [286, 478, 2597, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 266, "seek": 101772, "start": 1036.3600000000001, "end": 1037.3600000000001, "text": " This week.", "tokens": [639, 1243, 13], "temperature": 0.0, "avg_logprob": -0.28844018884607264, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0006848335615359247}, {"id": 267, "seek": 103736, "start": 1037.36, "end": 1051.0, "text": " Are there any big hurdles before plans for 1.0, for example?", "tokens": [2014, 456, 604, 955, 48387, 949, 5482, 337, 502, 13, 15, 11, 337, 1365, 30], "temperature": 0.0, "avg_logprob": -0.1749118636636173, "compression_ratio": 1.421875, "no_speech_prob": 0.00042650921386666596}, {"id": 268, "seek": 103736, "start": 1051.0, "end": 1057.32, "text": " I believe Lewis wants to get LSP features more properly implemented, but you can always", "tokens": [286, 1697, 17412, 2738, 281, 483, 441, 27921, 4122, 544, 6108, 12270, 11, 457, 291, 393, 1009], "temperature": 0.0, "avg_logprob": -0.1749118636636173, "compression_ratio": 1.421875, "no_speech_prob": 0.00042650921386666596}, {"id": 269, "seek": 103736, "start": 1057.32, "end": 1059.52, "text": " join the Discord and talk there.", "tokens": [3917, 264, 32623, 293, 751, 456, 13], "temperature": 0.0, "avg_logprob": -0.1749118636636173, "compression_ratio": 1.421875, "no_speech_prob": 0.00042650921386666596}, {"id": 270, "seek": 103736, "start": 1059.52, "end": 1064.3999999999999, "text": " I think Lewis is probably better, but I think we also have a GitHub milestone on the GitHub", "tokens": [286, 519, 17412, 307, 1391, 1101, 11, 457, 286, 519, 321, 611, 362, 257, 23331, 28048, 322, 264, 23331], "temperature": 0.0, "avg_logprob": -0.1749118636636173, "compression_ratio": 1.421875, "no_speech_prob": 0.00042650921386666596}, {"id": 271, "seek": 106440, "start": 1064.4, "end": 1071.16, "text": " repository, which says what we want before V1.", "tokens": [25841, 11, 597, 1619, 437, 321, 528, 949, 691, 16, 13], "temperature": 0.0, "avg_logprob": -0.467992233507561, "compression_ratio": 1.0326086956521738, "no_speech_prob": 8.517091191606596e-05}, {"id": 272, "seek": 106440, "start": 1071.16, "end": 1072.88, "text": " Any more questions?", "tokens": [2639, 544, 1651, 30], "temperature": 0.0, "avg_logprob": -0.467992233507561, "compression_ratio": 1.0326086956521738, "no_speech_prob": 8.517091191606596e-05}, {"id": 273, "seek": 106440, "start": 1072.88, "end": 1074.3600000000001, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.467992233507561, "compression_ratio": 1.0326086956521738, "no_speech_prob": 8.517091191606596e-05}, {"id": 274, "seek": 107436, "start": 1074.36, "end": 1095.8799999999999, "text": " Thank you, Aria, again.", "tokens": [50364, 1044, 291, 11, 316, 4668, 11, 797, 13, 51440], "temperature": 0.0, "avg_logprob": -0.7388609972867098, "compression_ratio": 0.7419354838709677, "no_speech_prob": 0.00011351626017130911}], "language": "en"}