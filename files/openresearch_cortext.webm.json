{"text": " So, thank you Paul, welcome everybody. So we will today present to you the Cortex platform, which is an open platform for research in social sciences. And it's a collective presentation where all the team is here, but we have three of us will be presenting today out of the team that you see on the picture. So what is the Cortex? It's an online platform built on top of an architecture and its main goal is to help the social scientists with a research question to actually find the benefit of a computational method to fit a specific question. So it has been founded in 2009 and it's driven by social science research and is supported by several French national institutes at the beginning, in particular INRA, and then later on some funding, some research funding and some European project called RIS, European project of infrastructure. We are now at our second version of this online platform called Cortex Manager. So this is the part that you can actually go online. It has been designed from the very beginning, as I said, for the social scientists. So we took the point of departure was that the social scientist doesn't have any IT capabilities, doesn't have any, on average, doesn't have any resource on the computer, especially 15 years ago. So one of the main benefits of the platform would have to be empowering him with the power of computing and of methods. It's a collaborative platform, so a lot of projects can be shared between scientists. And there is, as a web interface connected to a workspace online, you don't have to, of course, have it on your computer, which was, again, quite new at the time. And it's very important to note that it's very permissive. So it's a bunch of methods that you can apply on all kinds of data that we will detail later. And this was one of the main foundation of our platform in the beginning, that all the methods are runnable on all the viable that you have at your disposal. So how is it going from ten, ten, ten, twelve years after that? So we have over 250 peer-reviewed publications that we are counting from now. And of them, 75 documents in 2022. So it's growing, and it's growing quite fast the last few years. So 50,000 analysis, so 50,000 jobs have been done on the platform by scientists last year, by over 1,000 active users, 400 institutions, and in 50 countries. So it's pretty worldwide issue-wide. The team we have now in 2223 is consisted of eight technical persons, so engineers mainly, two researchers, one trainee, and two close collaborators in companies, or independent. Very important is located at University Gustave Eiffel in Paris, near, in the greater Paris, so near Marne-la-Vall\u00e9e. So you have Disneyland not far away. And this infrastructure is composed as a classic web-oriented application and infrastructure. So obviously we have the web interface that you can go to as a user, regular user, that encloses a lot of web services, so the main interface, but also an API that you can go and act upon from outside. So this allows us to open all our better-than-services to external applications, and specifically external projects that we are part on. We are built on an infrastructure of servers that are hosted at Marne-la-Vall\u00e9e, so in our university. So everything is local. We don't have anything hosted online, which is 300 CPU, 3.5 terabytes of RAM, and 40 terabytes of storage, which is big and not big at the same time nowadays, but it's enough for our needs. We have two main services that we are providing. First is the storage of big database that we are collecting and curating, like for example the patents, the European patents. We have several other databases that we are putting inside some projects, so we can help specific projects with this data that we have stored in the infrastructure. And the second part is the processing that we offer, so the method, the scientist method that I will talk about later, that are run inside of projects on the platform directly by the researchers. So the researchers are actually actioning those methods directly from the web interface with the parameters and their data. And we of course have this monitoring of the whole infrastructure, so it stays online. So once you have an infrastructure, it has to do something for scientists, and that's the goal of the platform. So how does it do, and what does it do for science? First what? So this is the right part of the previous diagram. So we have a bunch of heterogeneous methods. So from science to metrics, the biometrics, the study of basically publications, scientific publications and tracks, natural language processing, so terms of traction, name-intensive recognition and stuff like that, social network analysis, so the study of all the interactions inside publications and texts in between actors, keywords, et cetera. Stochastic block models, then I will end the table somewhere in the room. We'll talk to you about later. Knowledge dynamics, so through time, the study of the knowledge through time, and the special analysis, which is a big part of our infrastructure now, because we have geocoding, geolocating inside publications, and geo-mapping framework. Okay, next we'll be, I will give, join you the mic to talk to you about how to cite cortex, because this is one of the big, I will try to note. Then as cortex is a research software being used mainly by researchers, then suppose the to be cited, besides the fact that there is no yet strong culture of citing software properly inside academic works, it's expected to be done. Then according to that, in 2022, we documented how cortex must be cited inside academic works, and here we have just an example, for example, if I am writing a paper, and if I cite cortex, this is how cortex will be handed at the end of the paper in the reference section, for example, and with this, we can give, for example, the credit to the developers, like, for example, Philip, Ale, and many others, who is contributing with this software for a long time, and must be recognized by this work academically speaking, then this is important, then that's what we did, and nowadays, we are lucky because a few years ago, we are missing the infrastructure to how to define, how to document, and how to cite software, and now we have, for example, the citation.cff, that it's a citation file format, that it's been adopted a lot, and I think it will be the standard way to do it, and on top of it, we have many tools. Here is one example, CFF convert tool, where we can convert the CFF file format, for example, to big tech, to bibliotech, or to APA format, and many other formats, then we can keep the automated data about the software important for citation in one single file, and from this file, we can derivate to many others, and it's really an easy way to do it. And then in Cortex, it's a solved problem, but we still have an issue about how to identify permanently this object. I say object as a digital object, okay, it's a software, but it's a digital object from the point of view of science, and how we can identify it permanently, for example, for papers, we have a DOI, that it's very well known, and so it's very well for papers, PDF, but for software, we have a problem to, we can need to cite software in many different levels of granularity, for example. We can cite the software, just the software name, or a specific version of the software, or a specific line of a specific file inside the source code of the software. Again, this is still an open question, because, for example, we have a proposition from the community to solve it, but there is no one single kind of permanent ID that covers all the levels of granularity, for example. We have the proposition from the Software Heritage Project, that it's the suite, the Software Heritage ID, that we can use it to cite software in the very specific code fragment to the snapshot of the full source code, but, for example, we can't use Software ID to cite software in a high level, like the software version of this, only this project name. For that, we should use another kind of ID, that's it. And it's an open question that we should work this year or next year, and that's it. Now it's the time for you, Juan. You? I don't know. So one question we've been asking ourselves is how to open the platform fully. What did we do to do that until now, and what to do in the future? So there is no platform, web platform, without free open source software today, and we are using a lot already, and I just put some of them on this page. You can see here, from any layer of the infrastructure, from the virtual machine, the containers, the scripts, the operating systems, et cetera, et cetera, until the actual methods and interface that you produce to the user. We are using free open source software, or at least open source software, because I don't want to start a debate here, but that's the general idea. Now this is not Cortex producing that. The Cortex is wrapping around this open source software, and it's open access for now. So it's free and open to everybody to use as an interface, but the code is not entirely free. We've been trying to do that a little bit more than the last few years, and hopefully in the next few years, even more. And Ale will talk to you about how to do that, and what are the challenges to actually produce a good open source software and methods. Hello, everybody, I'm Ale. I work with the guys and go in Cortex. So this is not really a talk about Cortex, I'm not going to do a demo or something. Because we thought of this talk as a moment to discuss what's going on with us, what is going on in the platform, because up to now, like Philippe just explained, everybody can come and use, but most of the software in Cortex has been developed without, well, with open source in mind, but not in practice, for practical reasons. So are we missing one slide? No, yeah, so everything from the methods, the interfaces, the back ends, everything has, so even our documentation is on Wordpress or Q&A also. So everything is based on open source, but up to now, we didn't have real open source practices. So how are we managing this transition from a project that is very aligned with open source community, but that doesn't manage to do open source, to start doing open source? So there was really a big part was just getting even more open source into the project. So we're starting to use project management tools that we were using, like some of them, but not as much, not as systematically. So this is a real common problem with research software, where researchers, they don't always have the reflex to go into GitLab or GitHub or whatever and use issues and use dashboards and project management, sometimes not even a thing in their head. And that's kind of the background that we were facing, like years and years of research and developing stuff, using open source software, but using version control because, well, it was still the infrastructure guys really needed that to work with, but it was really like the bare minimum. So how do you start to get people more involved? So we just, the first step was really pushing everybody to start using the usual tools, and sometimes first moving some projects and moving the discussion into issues on GitLab and all that. And then, okay, so, and then, and also adopting for our discussions more open source software, like Matrix, so it's like, I don't know if anybody knows Matrix here, maybe today everybody already knows Matrix, it wasn't really a given last year. And then, once we had like adopted the general workflow, the projects were still, most of the projects were still private, but they had the workflow of an open source project, so it helped get people into a better mindset and the people who would arrive and start working with us would like more easily recognize the pattern of working with open source. Then because we had this system that runs the jobs and everything, and usually in the old scripts, they would just use the structure that was in the system directly, and it was pretty hard to adapt and evolve them. So then we developed some kind of intermediate libraries so that it gets easier to, so making it easier to develop new methods in the platform. So we had to develop this intermediate, I won't have time to go into show the details, but just getting the idea that we have to get people into the workflow, develop libraries and interfaces and intermediate layers that help and automate some of the processes, give people more freedom to work, actually we also started integrating containers in the job manager and everything so that we could end with this intermediate layer so that people could have more freedom to make it easier for them to keep doing their non-standard, non-advisable, non-best practices stuff, but that works for them because their researchers are not coders, they're not always coders. And finally, and even for the people in the team that are more skilled programmers, of course, they want to have the possibility to do all this stuff. And finally, one thing is very important is at the management level, because this is like a kind of already intermediate kind of big-ish thing where we have hundreds of users everywhere, so we had to discuss this in the strategic planning so that our institutional partners could get it. So basically, just get it everywhere as soon as possible and then start, once you can show some of the benefits, also work at the institutional level. So these are some of the challenges. Most part of the team didn't have the know-how, part of the researchers we work with. People have limited resources, they have priorities, and I'm just reading out of there, but that's it. It's not very surprising. There's this learning curve of open source and everything. And there's always doubts about where is this going to lead us. There's licensing doubts, so there's part of, like, next thing I'm going to quickly show is that we're starting to open up stuff, and there's lots of stuff that hasn't been open yet simply because somewhere, we know that somewhere in some file, somebody used an extract from a software library that is not clearly documented, where it has been used, and we need to find it and check if the license is compatible. So we're always like, okay, where are we going? But getting things to as close as possible on every dimension is what's keeping us moving. It's keeping the feeling that something is moving, even if we're not seeing everything. But then we, well, through this effort, eventually, we managed to open source already a good part of specifically the science part, so the infrastructure, the dashboard, the interfaces, the front-end of the web application, and the job-managing part, or this part is not necessarily, it's taking longer because it's also another part of the infrastructure. But the main, most important, short-term part is to let the scientific part of it be available. So here's just some examples, I'm not going to, but yeah, so there's two parsers, an importer for a big database of scientific publications, a kind of generic parser that we use for, we're in a sociology of science lab, so even though the tools are more like general humanities and social sciences, we have a lot of interesting things that come from PubMed, data that comes from PubMed, and similar databases, so this is like also a parser for that, and here's one example of a project that's in progress because even though we reworked the project, parts of it still use some libraries that we're not sure, so we have to check, take the time to check if we need to change anything or replace. Just quickly show what some one of these things look like, well, this is just the repository for one of the projects, you have the source code, some documentation, it makes pretty graphs, and you have to use it like this, like this. So just getting things into what we all know about, what you know as an open source format, how do I go back to the presentation, F, no, no, there you go. What else there's to say, that's it, so thank you, I think, I mean, if you, if you, if you have any of you work in a similar institution where open source is not an evidence but it's something that you have to struggle with, we're very happy to exchange after, during or after the conference, did you skip the, no, no, you have no more time, thank you. Thank you. Any questions? Yeah, thank you a lot, I like your time because there is a lot of nice to choose, and you just wanted to share with us, and I'm very happy to hear that you are bringing up the gauging. Yeah, so the question was, what was preventing us to opening it from the beginning, and to make open source software from the beginning. So as Ale was saying, the first thing I think is just the lack of know-how, especially 15 years ago when we started, the second thing I would say is that we, we basically didn't have a precise idea of what we were building, we just went basically script by script project by project, and this, this is how we built slowly the, the platform, then it became a platform, a proper platform, I mean, with the, with the resources and everything, and then, then it was already used, and, and we trained people on those methods already, so the problem of opening, of doing open source software is you have to think about it from the beginning, or at least refactor enough the, the code, so it's big, it's, it has no problem of, of license, and stuff like that, so this is, this is just a, you know, an ongoing streak. Yeah, speak loud, sorry, I can't, I can't hear you. Yeah, it's about, yeah, some, some people upload software to Zenodo or upload a documentation or, that's, that creates one kind of identifier, which you could also make a, some people just make a publication related to the software, so people can cite a DOI, Zenodo is going to give a DOI, so it's the same, pretty much the same thing. The problem is that, I think like Jenner was explaining is that sometimes you want to cite a specific version of the software or a specific file in a specific version, or you want to cite the software without mentioning a specific version, and, and you don't want to upload one version to Zenodo for every possible thing. Yeah, yeah, yeah, I, I don't know exactly deep what Zenodo offers, but I know that Zenodo offers a way to manage many different kind of digital objects, data, images, software, etc., and not only Zenodo. In our case, what is missing is to study all the options to see which fits better in, in, in our case, you know, is more to, to understand, because in, in fact, inside the, the, the software engineering community discussing this topic is still an open question, exactly how to do it. And when we, we search about this topic, it's quite difficult to find tutorials or someone teaching you how to, what kind of permanent indentifier you should use. For example, software heritage ID, for example, here is an example of the type of persistent indentifier that name it as intrinsic persistent indentifier. What means it doesn't, doesn't depend on, on, on a service registry where you need to ask a new ID to, to use it. It's like a hash, a hash ID of a commit is this kind of a intrinsic persistent indentifier that we can generate by the source code itself. Another option is to use maybe Zenodo or maybe any other thing to generate a DOI. Then for that, we are, we are going to ask to the registry, the DOI server to generate a DOI for us. And we have many options, we don't know yet deep and maybe Zenodo could be really interesting. I would be happy to, to learn with you, your experience because it's a lot of things to, to learn. Sorry. Okay, thanks for coming back to stop here.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.5, "text": " So, thank you Paul, welcome everybody.", "tokens": [407, 11, 1309, 291, 4552, 11, 2928, 2201, 13], "temperature": 0.0, "avg_logprob": -0.24946825621558016, "compression_ratio": 1.427710843373494, "no_speech_prob": 0.21211247146129608}, {"id": 1, "seek": 0, "start": 9.5, "end": 17.96, "text": " So we will today present to you the Cortex platform, which is an open platform for research", "tokens": [407, 321, 486, 965, 1974, 281, 291, 264, 28522, 3121, 3663, 11, 597, 307, 364, 1269, 3663, 337, 2132], "temperature": 0.0, "avg_logprob": -0.24946825621558016, "compression_ratio": 1.427710843373494, "no_speech_prob": 0.21211247146129608}, {"id": 2, "seek": 0, "start": 17.96, "end": 20.2, "text": " in social sciences.", "tokens": [294, 2093, 17677, 13], "temperature": 0.0, "avg_logprob": -0.24946825621558016, "compression_ratio": 1.427710843373494, "no_speech_prob": 0.21211247146129608}, {"id": 3, "seek": 0, "start": 20.2, "end": 26.28, "text": " And it's a collective presentation where all the team is here, but we have three of us", "tokens": [400, 309, 311, 257, 12590, 5860, 689, 439, 264, 1469, 307, 510, 11, 457, 321, 362, 1045, 295, 505], "temperature": 0.0, "avg_logprob": -0.24946825621558016, "compression_ratio": 1.427710843373494, "no_speech_prob": 0.21211247146129608}, {"id": 4, "seek": 2628, "start": 26.28, "end": 31.240000000000002, "text": " will be presenting today out of the team that you see on the picture.", "tokens": [486, 312, 15578, 965, 484, 295, 264, 1469, 300, 291, 536, 322, 264, 3036, 13], "temperature": 0.0, "avg_logprob": -0.18837997075673696, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.0012284412514418364}, {"id": 5, "seek": 2628, "start": 31.240000000000002, "end": 33.68, "text": " So what is the Cortex?", "tokens": [407, 437, 307, 264, 28522, 3121, 30], "temperature": 0.0, "avg_logprob": -0.18837997075673696, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.0012284412514418364}, {"id": 6, "seek": 2628, "start": 33.68, "end": 42.28, "text": " It's an online platform built on top of an architecture and its main goal is to help", "tokens": [467, 311, 364, 2950, 3663, 3094, 322, 1192, 295, 364, 9482, 293, 1080, 2135, 3387, 307, 281, 854], "temperature": 0.0, "avg_logprob": -0.18837997075673696, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.0012284412514418364}, {"id": 7, "seek": 2628, "start": 42.28, "end": 49.36, "text": " the social scientists with a research question to actually find the benefit of a computational", "tokens": [264, 2093, 7708, 365, 257, 2132, 1168, 281, 767, 915, 264, 5121, 295, 257, 28270], "temperature": 0.0, "avg_logprob": -0.18837997075673696, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.0012284412514418364}, {"id": 8, "seek": 2628, "start": 49.36, "end": 55.24, "text": " method to fit a specific question.", "tokens": [3170, 281, 3318, 257, 2685, 1168, 13], "temperature": 0.0, "avg_logprob": -0.18837997075673696, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.0012284412514418364}, {"id": 9, "seek": 5524, "start": 55.24, "end": 64.36, "text": " So it has been founded in 2009 and it's driven by social science research and is supported", "tokens": [407, 309, 575, 668, 13234, 294, 11453, 293, 309, 311, 9555, 538, 2093, 3497, 2132, 293, 307, 8104], "temperature": 0.0, "avg_logprob": -0.24477565649783972, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.0002681892947293818}, {"id": 10, "seek": 5524, "start": 64.36, "end": 72.28, "text": " by several French national institutes at the beginning, in particular INRA, and then later", "tokens": [538, 2940, 5522, 4048, 4348, 1819, 412, 264, 2863, 11, 294, 1729, 6892, 3750, 11, 293, 550, 1780], "temperature": 0.0, "avg_logprob": -0.24477565649783972, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.0002681892947293818}, {"id": 11, "seek": 5524, "start": 72.28, "end": 78.52000000000001, "text": " on some funding, some research funding and some European project called RIS, European", "tokens": [322, 512, 6137, 11, 512, 2132, 6137, 293, 512, 6473, 1716, 1219, 497, 2343, 11, 6473], "temperature": 0.0, "avg_logprob": -0.24477565649783972, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.0002681892947293818}, {"id": 12, "seek": 5524, "start": 78.52000000000001, "end": 82.88, "text": " project of infrastructure.", "tokens": [1716, 295, 6896, 13], "temperature": 0.0, "avg_logprob": -0.24477565649783972, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.0002681892947293818}, {"id": 13, "seek": 8288, "start": 82.88, "end": 87.6, "text": " We are now at our second version of this online platform called Cortex Manager.", "tokens": [492, 366, 586, 412, 527, 1150, 3037, 295, 341, 2950, 3663, 1219, 28522, 3121, 13821, 13], "temperature": 0.0, "avg_logprob": -0.2013613764444987, "compression_ratio": 1.5467980295566504, "no_speech_prob": 0.0001375798456138}, {"id": 14, "seek": 8288, "start": 87.6, "end": 91.75999999999999, "text": " So this is the part that you can actually go online.", "tokens": [407, 341, 307, 264, 644, 300, 291, 393, 767, 352, 2950, 13], "temperature": 0.0, "avg_logprob": -0.2013613764444987, "compression_ratio": 1.5467980295566504, "no_speech_prob": 0.0001375798456138}, {"id": 15, "seek": 8288, "start": 91.75999999999999, "end": 96.92, "text": " It has been designed from the very beginning, as I said, for the social scientists.", "tokens": [467, 575, 668, 4761, 490, 264, 588, 2863, 11, 382, 286, 848, 11, 337, 264, 2093, 7708, 13], "temperature": 0.0, "avg_logprob": -0.2013613764444987, "compression_ratio": 1.5467980295566504, "no_speech_prob": 0.0001375798456138}, {"id": 16, "seek": 8288, "start": 96.92, "end": 108.8, "text": " So we took the point of departure was that the social scientist doesn't have any IT capabilities,", "tokens": [407, 321, 1890, 264, 935, 295, 25866, 390, 300, 264, 2093, 12662, 1177, 380, 362, 604, 6783, 10862, 11], "temperature": 0.0, "avg_logprob": -0.2013613764444987, "compression_ratio": 1.5467980295566504, "no_speech_prob": 0.0001375798456138}, {"id": 17, "seek": 10880, "start": 108.8, "end": 117.16, "text": " doesn't have any, on average, doesn't have any resource on the computer, especially 15", "tokens": [1177, 380, 362, 604, 11, 322, 4274, 11, 1177, 380, 362, 604, 7684, 322, 264, 3820, 11, 2318, 2119], "temperature": 0.0, "avg_logprob": -0.20867908477783204, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.000248402648139745}, {"id": 18, "seek": 10880, "start": 117.16, "end": 118.16, "text": " years ago.", "tokens": [924, 2057, 13], "temperature": 0.0, "avg_logprob": -0.20867908477783204, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.000248402648139745}, {"id": 19, "seek": 10880, "start": 118.16, "end": 126.12, "text": " So one of the main benefits of the platform would have to be empowering him with the power", "tokens": [407, 472, 295, 264, 2135, 5311, 295, 264, 3663, 576, 362, 281, 312, 28261, 796, 365, 264, 1347], "temperature": 0.0, "avg_logprob": -0.20867908477783204, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.000248402648139745}, {"id": 20, "seek": 10880, "start": 126.12, "end": 130.48, "text": " of computing and of methods.", "tokens": [295, 15866, 293, 295, 7150, 13], "temperature": 0.0, "avg_logprob": -0.20867908477783204, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.000248402648139745}, {"id": 21, "seek": 10880, "start": 130.48, "end": 137.84, "text": " It's a collaborative platform, so a lot of projects can be shared between scientists.", "tokens": [467, 311, 257, 16555, 3663, 11, 370, 257, 688, 295, 4455, 393, 312, 5507, 1296, 7708, 13], "temperature": 0.0, "avg_logprob": -0.20867908477783204, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.000248402648139745}, {"id": 22, "seek": 13784, "start": 137.84, "end": 143.68, "text": " And there is, as a web interface connected to a workspace online, you don't have to,", "tokens": [400, 456, 307, 11, 382, 257, 3670, 9226, 4582, 281, 257, 32706, 2950, 11, 291, 500, 380, 362, 281, 11], "temperature": 0.0, "avg_logprob": -0.10699664320901175, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004373514384496957}, {"id": 23, "seek": 13784, "start": 143.68, "end": 150.16, "text": " of course, have it on your computer, which was, again, quite new at the time.", "tokens": [295, 1164, 11, 362, 309, 322, 428, 3820, 11, 597, 390, 11, 797, 11, 1596, 777, 412, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.10699664320901175, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004373514384496957}, {"id": 24, "seek": 13784, "start": 150.16, "end": 153.52, "text": " And it's very important to note that it's very permissive.", "tokens": [400, 309, 311, 588, 1021, 281, 3637, 300, 309, 311, 588, 4784, 891, 488, 13], "temperature": 0.0, "avg_logprob": -0.10699664320901175, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004373514384496957}, {"id": 25, "seek": 13784, "start": 153.52, "end": 159.72, "text": " So it's a bunch of methods that you can apply on all kinds of data that we will detail later.", "tokens": [407, 309, 311, 257, 3840, 295, 7150, 300, 291, 393, 3079, 322, 439, 3685, 295, 1412, 300, 321, 486, 2607, 1780, 13], "temperature": 0.0, "avg_logprob": -0.10699664320901175, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004373514384496957}, {"id": 26, "seek": 13784, "start": 159.72, "end": 166.08, "text": " And this was one of the main foundation of our platform in the beginning, that all the", "tokens": [400, 341, 390, 472, 295, 264, 2135, 7030, 295, 527, 3663, 294, 264, 2863, 11, 300, 439, 264], "temperature": 0.0, "avg_logprob": -0.10699664320901175, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004373514384496957}, {"id": 27, "seek": 16608, "start": 166.08, "end": 173.88000000000002, "text": " methods are runnable on all the viable that you have at your disposal.", "tokens": [7150, 366, 1190, 77, 712, 322, 439, 264, 22024, 300, 291, 362, 412, 428, 26400, 13], "temperature": 0.0, "avg_logprob": -0.19889322194186124, "compression_ratio": 1.5445544554455446, "no_speech_prob": 0.00014511781046167016}, {"id": 28, "seek": 16608, "start": 173.88000000000002, "end": 179.12, "text": " So how is it going from ten, ten, ten, twelve years after that?", "tokens": [407, 577, 307, 309, 516, 490, 2064, 11, 2064, 11, 2064, 11, 14390, 924, 934, 300, 30], "temperature": 0.0, "avg_logprob": -0.19889322194186124, "compression_ratio": 1.5445544554455446, "no_speech_prob": 0.00014511781046167016}, {"id": 29, "seek": 16608, "start": 179.12, "end": 186.84, "text": " So we have over 250 peer-reviewed publications that we are counting from now.", "tokens": [407, 321, 362, 670, 11650, 15108, 12, 265, 1759, 292, 25618, 300, 321, 366, 13251, 490, 586, 13], "temperature": 0.0, "avg_logprob": -0.19889322194186124, "compression_ratio": 1.5445544554455446, "no_speech_prob": 0.00014511781046167016}, {"id": 30, "seek": 16608, "start": 186.84, "end": 190.64000000000001, "text": " And of them, 75 documents in 2022.", "tokens": [400, 295, 552, 11, 9562, 8512, 294, 20229, 13], "temperature": 0.0, "avg_logprob": -0.19889322194186124, "compression_ratio": 1.5445544554455446, "no_speech_prob": 0.00014511781046167016}, {"id": 31, "seek": 16608, "start": 190.64000000000001, "end": 195.88000000000002, "text": " So it's growing, and it's growing quite fast the last few years.", "tokens": [407, 309, 311, 4194, 11, 293, 309, 311, 4194, 1596, 2370, 264, 1036, 1326, 924, 13], "temperature": 0.0, "avg_logprob": -0.19889322194186124, "compression_ratio": 1.5445544554455446, "no_speech_prob": 0.00014511781046167016}, {"id": 32, "seek": 19588, "start": 195.88, "end": 204.2, "text": " So 50,000 analysis, so 50,000 jobs have been done on the platform by scientists last year,", "tokens": [407, 2625, 11, 1360, 5215, 11, 370, 2625, 11, 1360, 4782, 362, 668, 1096, 322, 264, 3663, 538, 7708, 1036, 1064, 11], "temperature": 0.0, "avg_logprob": -0.26788008840460525, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0002597974962554872}, {"id": 33, "seek": 19588, "start": 204.2, "end": 208.79999999999998, "text": " by over 1,000 active users, 400 institutions, and in 50 countries.", "tokens": [538, 670, 502, 11, 1360, 4967, 5022, 11, 8423, 8142, 11, 293, 294, 2625, 3517, 13], "temperature": 0.0, "avg_logprob": -0.26788008840460525, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0002597974962554872}, {"id": 34, "seek": 19588, "start": 208.79999999999998, "end": 216.84, "text": " So it's pretty worldwide issue-wide.", "tokens": [407, 309, 311, 1238, 13485, 2734, 12, 7990, 13], "temperature": 0.0, "avg_logprob": -0.26788008840460525, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0002597974962554872}, {"id": 35, "seek": 19588, "start": 216.84, "end": 223.68, "text": " The team we have now in 2223 is consisted of eight technical persons, so engineers mainly,", "tokens": [440, 1469, 321, 362, 586, 294, 5853, 9356, 307, 38227, 295, 3180, 6191, 14453, 11, 370, 11955, 8704, 11], "temperature": 0.0, "avg_logprob": -0.26788008840460525, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0002597974962554872}, {"id": 36, "seek": 22368, "start": 223.68, "end": 230.36, "text": " two researchers, one trainee, and two close collaborators in companies, or independent.", "tokens": [732, 10309, 11, 472, 40350, 11, 293, 732, 1998, 39789, 294, 3431, 11, 420, 6695, 13], "temperature": 0.0, "avg_logprob": -0.28839426155549935, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.0004786621720995754}, {"id": 37, "seek": 22368, "start": 230.36, "end": 235.76000000000002, "text": " Very important is located at University Gustave Eiffel in Paris, near, in the greater Paris,", "tokens": [4372, 1021, 307, 6870, 412, 3535, 32337, 946, 462, 3661, 338, 294, 8380, 11, 2651, 11, 294, 264, 5044, 8380, 11], "temperature": 0.0, "avg_logprob": -0.28839426155549935, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.0004786621720995754}, {"id": 38, "seek": 22368, "start": 235.76000000000002, "end": 236.76000000000002, "text": " so near Marne-la-Vall\u00e9e.", "tokens": [370, 2651, 2039, 716, 12, 875, 12, 53, 336, 3856, 13], "temperature": 0.0, "avg_logprob": -0.28839426155549935, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.0004786621720995754}, {"id": 39, "seek": 22368, "start": 236.76000000000002, "end": 241.56, "text": " So you have Disneyland not far away.", "tokens": [407, 291, 362, 34797, 406, 1400, 1314, 13], "temperature": 0.0, "avg_logprob": -0.28839426155549935, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.0004786621720995754}, {"id": 40, "seek": 22368, "start": 241.56, "end": 250.36, "text": " And this infrastructure is composed as a classic web-oriented application and infrastructure.", "tokens": [400, 341, 6896, 307, 18204, 382, 257, 7230, 3670, 12, 27414, 3861, 293, 6896, 13], "temperature": 0.0, "avg_logprob": -0.28839426155549935, "compression_ratio": 1.4780701754385965, "no_speech_prob": 0.0004786621720995754}, {"id": 41, "seek": 25036, "start": 250.36, "end": 256.96000000000004, "text": " So obviously we have the web interface that you can go to as a user, regular user, that", "tokens": [407, 2745, 321, 362, 264, 3670, 9226, 300, 291, 393, 352, 281, 382, 257, 4195, 11, 3890, 4195, 11, 300], "temperature": 0.0, "avg_logprob": -0.14482228509311018, "compression_ratio": 1.625, "no_speech_prob": 0.0003173999139107764}, {"id": 42, "seek": 25036, "start": 256.96000000000004, "end": 265.68, "text": " encloses a lot of web services, so the main interface, but also an API that you can go", "tokens": [20987, 4201, 257, 688, 295, 3670, 3328, 11, 370, 264, 2135, 9226, 11, 457, 611, 364, 9362, 300, 291, 393, 352], "temperature": 0.0, "avg_logprob": -0.14482228509311018, "compression_ratio": 1.625, "no_speech_prob": 0.0003173999139107764}, {"id": 43, "seek": 25036, "start": 265.68, "end": 268.8, "text": " and act upon from outside.", "tokens": [293, 605, 3564, 490, 2380, 13], "temperature": 0.0, "avg_logprob": -0.14482228509311018, "compression_ratio": 1.625, "no_speech_prob": 0.0003173999139107764}, {"id": 44, "seek": 25036, "start": 268.8, "end": 276.12, "text": " So this allows us to open all our better-than-services to external applications, and specifically", "tokens": [407, 341, 4045, 505, 281, 1269, 439, 527, 1101, 12, 24852, 12, 82, 47480, 281, 8320, 5821, 11, 293, 4682], "temperature": 0.0, "avg_logprob": -0.14482228509311018, "compression_ratio": 1.625, "no_speech_prob": 0.0003173999139107764}, {"id": 45, "seek": 25036, "start": 276.12, "end": 279.84000000000003, "text": " external projects that we are part on.", "tokens": [8320, 4455, 300, 321, 366, 644, 322, 13], "temperature": 0.0, "avg_logprob": -0.14482228509311018, "compression_ratio": 1.625, "no_speech_prob": 0.0003173999139107764}, {"id": 46, "seek": 27984, "start": 279.84, "end": 286.52, "text": " We are built on an infrastructure of servers that are hosted at Marne-la-Vall\u00e9e, so in", "tokens": [492, 366, 3094, 322, 364, 6896, 295, 15909, 300, 366, 19204, 412, 2039, 716, 12, 875, 12, 53, 336, 3856, 11, 370, 294], "temperature": 0.0, "avg_logprob": -0.1475777574764785, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00026599850389175117}, {"id": 47, "seek": 27984, "start": 286.52, "end": 288.32, "text": " our university.", "tokens": [527, 5454, 13], "temperature": 0.0, "avg_logprob": -0.1475777574764785, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00026599850389175117}, {"id": 48, "seek": 27984, "start": 288.32, "end": 289.96, "text": " So everything is local.", "tokens": [407, 1203, 307, 2654, 13], "temperature": 0.0, "avg_logprob": -0.1475777574764785, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00026599850389175117}, {"id": 49, "seek": 27984, "start": 289.96, "end": 297.79999999999995, "text": " We don't have anything hosted online, which is 300 CPU, 3.5 terabytes of RAM, and 40 terabytes", "tokens": [492, 500, 380, 362, 1340, 19204, 2950, 11, 597, 307, 6641, 13199, 11, 805, 13, 20, 1796, 24538, 295, 14561, 11, 293, 3356, 1796, 24538], "temperature": 0.0, "avg_logprob": -0.1475777574764785, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00026599850389175117}, {"id": 50, "seek": 27984, "start": 297.79999999999995, "end": 303.35999999999996, "text": " of storage, which is big and not big at the same time nowadays, but it's enough for our", "tokens": [295, 6725, 11, 597, 307, 955, 293, 406, 955, 412, 264, 912, 565, 13434, 11, 457, 309, 311, 1547, 337, 527], "temperature": 0.0, "avg_logprob": -0.1475777574764785, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00026599850389175117}, {"id": 51, "seek": 27984, "start": 303.35999999999996, "end": 305.44, "text": " needs.", "tokens": [2203, 13], "temperature": 0.0, "avg_logprob": -0.1475777574764785, "compression_ratio": 1.4541284403669725, "no_speech_prob": 0.00026599850389175117}, {"id": 52, "seek": 30544, "start": 305.44, "end": 310.6, "text": " We have two main services that we are providing.", "tokens": [492, 362, 732, 2135, 3328, 300, 321, 366, 6530, 13], "temperature": 0.0, "avg_logprob": -0.1625387284063524, "compression_ratio": 1.6134969325153374, "no_speech_prob": 0.00014723805361427367}, {"id": 53, "seek": 30544, "start": 310.6, "end": 319.48, "text": " First is the storage of big database that we are collecting and curating, like for example", "tokens": [2386, 307, 264, 6725, 295, 955, 8149, 300, 321, 366, 12510, 293, 1262, 990, 11, 411, 337, 1365], "temperature": 0.0, "avg_logprob": -0.1625387284063524, "compression_ratio": 1.6134969325153374, "no_speech_prob": 0.00014723805361427367}, {"id": 54, "seek": 30544, "start": 319.48, "end": 322.64, "text": " the patents, the European patents.", "tokens": [264, 38142, 11, 264, 6473, 38142, 13], "temperature": 0.0, "avg_logprob": -0.1625387284063524, "compression_ratio": 1.6134969325153374, "no_speech_prob": 0.00014723805361427367}, {"id": 55, "seek": 30544, "start": 322.64, "end": 333.2, "text": " We have several other databases that we are putting inside some projects, so we can help", "tokens": [492, 362, 2940, 661, 22380, 300, 321, 366, 3372, 1854, 512, 4455, 11, 370, 321, 393, 854], "temperature": 0.0, "avg_logprob": -0.1625387284063524, "compression_ratio": 1.6134969325153374, "no_speech_prob": 0.00014723805361427367}, {"id": 56, "seek": 33320, "start": 333.2, "end": 340.08, "text": " specific projects with this data that we have stored in the infrastructure.", "tokens": [2685, 4455, 365, 341, 1412, 300, 321, 362, 12187, 294, 264, 6896, 13], "temperature": 0.0, "avg_logprob": -0.1668816346388597, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00010117562487721443}, {"id": 57, "seek": 33320, "start": 340.08, "end": 347.28, "text": " And the second part is the processing that we offer, so the method, the scientist method", "tokens": [400, 264, 1150, 644, 307, 264, 9007, 300, 321, 2626, 11, 370, 264, 3170, 11, 264, 12662, 3170], "temperature": 0.0, "avg_logprob": -0.1668816346388597, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00010117562487721443}, {"id": 58, "seek": 33320, "start": 347.28, "end": 355.59999999999997, "text": " that I will talk about later, that are run inside of projects on the platform directly", "tokens": [300, 286, 486, 751, 466, 1780, 11, 300, 366, 1190, 1854, 295, 4455, 322, 264, 3663, 3838], "temperature": 0.0, "avg_logprob": -0.1668816346388597, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00010117562487721443}, {"id": 59, "seek": 33320, "start": 355.59999999999997, "end": 356.59999999999997, "text": " by the researchers.", "tokens": [538, 264, 10309, 13], "temperature": 0.0, "avg_logprob": -0.1668816346388597, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00010117562487721443}, {"id": 60, "seek": 33320, "start": 356.59999999999997, "end": 362.03999999999996, "text": " So the researchers are actually actioning those methods directly from the web interface", "tokens": [407, 264, 10309, 366, 767, 3069, 278, 729, 7150, 3838, 490, 264, 3670, 9226], "temperature": 0.0, "avg_logprob": -0.1668816346388597, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00010117562487721443}, {"id": 61, "seek": 36204, "start": 362.04, "end": 368.48, "text": " with the parameters and their data.", "tokens": [365, 264, 9834, 293, 641, 1412, 13], "temperature": 0.0, "avg_logprob": -0.18651356904403024, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0001191213887068443}, {"id": 62, "seek": 36204, "start": 368.48, "end": 375.28000000000003, "text": " And we of course have this monitoring of the whole infrastructure, so it stays online.", "tokens": [400, 321, 295, 1164, 362, 341, 11028, 295, 264, 1379, 6896, 11, 370, 309, 10834, 2950, 13], "temperature": 0.0, "avg_logprob": -0.18651356904403024, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0001191213887068443}, {"id": 63, "seek": 36204, "start": 375.28000000000003, "end": 379.56, "text": " So once you have an infrastructure, it has to do something for scientists, and that's", "tokens": [407, 1564, 291, 362, 364, 6896, 11, 309, 575, 281, 360, 746, 337, 7708, 11, 293, 300, 311], "temperature": 0.0, "avg_logprob": -0.18651356904403024, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0001191213887068443}, {"id": 64, "seek": 36204, "start": 379.56, "end": 382.16, "text": " the goal of the platform.", "tokens": [264, 3387, 295, 264, 3663, 13], "temperature": 0.0, "avg_logprob": -0.18651356904403024, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0001191213887068443}, {"id": 65, "seek": 36204, "start": 382.16, "end": 384.68, "text": " So how does it do, and what does it do for science?", "tokens": [407, 577, 775, 309, 360, 11, 293, 437, 775, 309, 360, 337, 3497, 30], "temperature": 0.0, "avg_logprob": -0.18651356904403024, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0001191213887068443}, {"id": 66, "seek": 36204, "start": 384.68, "end": 386.84000000000003, "text": " First what?", "tokens": [2386, 437, 30], "temperature": 0.0, "avg_logprob": -0.18651356904403024, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0001191213887068443}, {"id": 67, "seek": 36204, "start": 386.84000000000003, "end": 390.8, "text": " So this is the right part of the previous diagram.", "tokens": [407, 341, 307, 264, 558, 644, 295, 264, 3894, 10686, 13], "temperature": 0.0, "avg_logprob": -0.18651356904403024, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0001191213887068443}, {"id": 68, "seek": 39080, "start": 390.8, "end": 395.24, "text": " So we have a bunch of heterogeneous methods.", "tokens": [407, 321, 362, 257, 3840, 295, 20789, 31112, 7150, 13], "temperature": 0.0, "avg_logprob": -0.30089060465494794, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.0003331716579850763}, {"id": 69, "seek": 39080, "start": 395.24, "end": 399.56, "text": " So from science to metrics, the biometrics, the study of basically publications, scientific", "tokens": [407, 490, 3497, 281, 16367, 11, 264, 3228, 649, 10716, 11, 264, 2979, 295, 1936, 25618, 11, 8134], "temperature": 0.0, "avg_logprob": -0.30089060465494794, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.0003331716579850763}, {"id": 70, "seek": 39080, "start": 399.56, "end": 407.08000000000004, "text": " publications and tracks, natural language processing, so terms of traction, name-intensive", "tokens": [25618, 293, 10218, 11, 3303, 2856, 9007, 11, 370, 2115, 295, 23558, 11, 1315, 12, 686, 2953], "temperature": 0.0, "avg_logprob": -0.30089060465494794, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.0003331716579850763}, {"id": 71, "seek": 39080, "start": 407.08000000000004, "end": 416.56, "text": " recognition and stuff like that, social network analysis, so the study of all the interactions", "tokens": [11150, 293, 1507, 411, 300, 11, 2093, 3209, 5215, 11, 370, 264, 2979, 295, 439, 264, 13280], "temperature": 0.0, "avg_logprob": -0.30089060465494794, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.0003331716579850763}, {"id": 72, "seek": 41656, "start": 416.56, "end": 423.84, "text": " inside publications and texts in between actors, keywords, et cetera.", "tokens": [1854, 25618, 293, 15765, 294, 1296, 10037, 11, 21009, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.22863599756261804, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00040388782508671284}, {"id": 73, "seek": 41656, "start": 423.84, "end": 430.52, "text": " Stochastic block models, then I will end the table somewhere in the room.", "tokens": [745, 8997, 2750, 3461, 5245, 11, 550, 286, 486, 917, 264, 3199, 4079, 294, 264, 1808, 13], "temperature": 0.0, "avg_logprob": -0.22863599756261804, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00040388782508671284}, {"id": 74, "seek": 41656, "start": 430.52, "end": 432.24, "text": " We'll talk to you about later.", "tokens": [492, 603, 751, 281, 291, 466, 1780, 13], "temperature": 0.0, "avg_logprob": -0.22863599756261804, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00040388782508671284}, {"id": 75, "seek": 41656, "start": 432.24, "end": 439.72, "text": " Knowledge dynamics, so through time, the study of the knowledge through time, and the special", "tokens": [32906, 15679, 11, 370, 807, 565, 11, 264, 2979, 295, 264, 3601, 807, 565, 11, 293, 264, 2121], "temperature": 0.0, "avg_logprob": -0.22863599756261804, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00040388782508671284}, {"id": 76, "seek": 41656, "start": 439.72, "end": 444.96, "text": " analysis, which is a big part of our infrastructure now, because we have geocoding, geolocating", "tokens": [5215, 11, 597, 307, 257, 955, 644, 295, 527, 6896, 586, 11, 570, 321, 362, 1519, 905, 8616, 11, 1519, 401, 905, 990], "temperature": 0.0, "avg_logprob": -0.22863599756261804, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00040388782508671284}, {"id": 77, "seek": 44496, "start": 444.96, "end": 452.96, "text": " inside publications, and geo-mapping framework.", "tokens": [1854, 25618, 11, 293, 43198, 12, 1696, 3759, 8388, 13], "temperature": 0.0, "avg_logprob": -0.4818860567533053, "compression_ratio": 1.212962962962963, "no_speech_prob": 0.003498299280181527}, {"id": 78, "seek": 44496, "start": 452.96, "end": 461.91999999999996, "text": " Okay, next we'll be, I will give, join you the mic to talk to you about how to cite", "tokens": [1033, 11, 958, 321, 603, 312, 11, 286, 486, 976, 11, 3917, 291, 264, 3123, 281, 751, 281, 291, 466, 577, 281, 37771], "temperature": 0.0, "avg_logprob": -0.4818860567533053, "compression_ratio": 1.212962962962963, "no_speech_prob": 0.003498299280181527}, {"id": 79, "seek": 46192, "start": 461.92, "end": 480.44, "text": " cortex, because this is one of the big, I will try to note.", "tokens": [33312, 11, 570, 341, 307, 472, 295, 264, 955, 11, 286, 486, 853, 281, 3637, 13], "temperature": 0.0, "avg_logprob": -0.257609718724301, "compression_ratio": 1.2869565217391303, "no_speech_prob": 0.001799965393729508}, {"id": 80, "seek": 46192, "start": 480.44, "end": 491.8, "text": " Then as cortex is a research software being used mainly by researchers, then suppose the", "tokens": [1396, 382, 33312, 307, 257, 2132, 4722, 885, 1143, 8704, 538, 10309, 11, 550, 7297, 264], "temperature": 0.0, "avg_logprob": -0.257609718724301, "compression_ratio": 1.2869565217391303, "no_speech_prob": 0.001799965393729508}, {"id": 81, "seek": 49180, "start": 491.8, "end": 502.40000000000003, "text": " to be cited, besides the fact that there is no yet strong culture of citing software properly", "tokens": [281, 312, 30134, 11, 11868, 264, 1186, 300, 456, 307, 572, 1939, 2068, 3713, 295, 48749, 4722, 6108], "temperature": 0.0, "avg_logprob": -0.20235581057412283, "compression_ratio": 1.5389610389610389, "no_speech_prob": 0.0014852186432108283}, {"id": 82, "seek": 49180, "start": 502.40000000000003, "end": 506.84000000000003, "text": " inside academic works, it's expected to be done.", "tokens": [1854, 7778, 1985, 11, 309, 311, 5176, 281, 312, 1096, 13], "temperature": 0.0, "avg_logprob": -0.20235581057412283, "compression_ratio": 1.5389610389610389, "no_speech_prob": 0.0014852186432108283}, {"id": 83, "seek": 49180, "start": 506.84000000000003, "end": 517.12, "text": " Then according to that, in 2022, we documented how cortex must be cited inside academic works,", "tokens": [1396, 4650, 281, 300, 11, 294, 20229, 11, 321, 23007, 577, 33312, 1633, 312, 30134, 1854, 7778, 1985, 11], "temperature": 0.0, "avg_logprob": -0.20235581057412283, "compression_ratio": 1.5389610389610389, "no_speech_prob": 0.0014852186432108283}, {"id": 84, "seek": 51712, "start": 517.12, "end": 523.28, "text": " and here we have just an example, for example, if I am writing a paper, and if I cite cortex,", "tokens": [293, 510, 321, 362, 445, 364, 1365, 11, 337, 1365, 11, 498, 286, 669, 3579, 257, 3035, 11, 293, 498, 286, 37771, 33312, 11], "temperature": 0.0, "avg_logprob": -0.20261597146793286, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.0013098453637212515}, {"id": 85, "seek": 51712, "start": 523.28, "end": 530.24, "text": " this is how cortex will be handed at the end of the paper in the reference section, for", "tokens": [341, 307, 577, 33312, 486, 312, 16013, 412, 264, 917, 295, 264, 3035, 294, 264, 6408, 3541, 11, 337], "temperature": 0.0, "avg_logprob": -0.20261597146793286, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.0013098453637212515}, {"id": 86, "seek": 51712, "start": 530.24, "end": 537.5600000000001, "text": " example, and with this, we can give, for example, the credit to the developers, like, for example,", "tokens": [1365, 11, 293, 365, 341, 11, 321, 393, 976, 11, 337, 1365, 11, 264, 5397, 281, 264, 8849, 11, 411, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.20261597146793286, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.0013098453637212515}, {"id": 87, "seek": 51712, "start": 537.5600000000001, "end": 544.4, "text": " Philip, Ale, and many others, who is contributing with this software for a long time, and must", "tokens": [21144, 11, 9366, 11, 293, 867, 2357, 11, 567, 307, 19270, 365, 341, 4722, 337, 257, 938, 565, 11, 293, 1633], "temperature": 0.0, "avg_logprob": -0.20261597146793286, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.0013098453637212515}, {"id": 88, "seek": 54440, "start": 544.4, "end": 551.4, "text": " be recognized by this work academically speaking, then this is important, then that's what", "tokens": [312, 9823, 538, 341, 589, 48944, 4124, 11, 550, 341, 307, 1021, 11, 550, 300, 311, 437], "temperature": 0.0, "avg_logprob": -0.18660614069770365, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.0004557661304716021}, {"id": 89, "seek": 54440, "start": 551.4, "end": 563.0, "text": " we did, and nowadays, we are lucky because a few years ago, we are missing the infrastructure", "tokens": [321, 630, 11, 293, 13434, 11, 321, 366, 6356, 570, 257, 1326, 924, 2057, 11, 321, 366, 5361, 264, 6896], "temperature": 0.0, "avg_logprob": -0.18660614069770365, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.0004557661304716021}, {"id": 90, "seek": 54440, "start": 563.0, "end": 572.68, "text": " to how to define, how to document, and how to cite software, and now we have, for example,", "tokens": [281, 577, 281, 6964, 11, 577, 281, 4166, 11, 293, 577, 281, 37771, 4722, 11, 293, 586, 321, 362, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.18660614069770365, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.0004557661304716021}, {"id": 91, "seek": 57268, "start": 572.68, "end": 582.8, "text": " the citation.cff, that it's a citation file format, that it's been adopted a lot, and", "tokens": [264, 45590, 13, 66, 602, 11, 300, 309, 311, 257, 45590, 3991, 7877, 11, 300, 309, 311, 668, 12175, 257, 688, 11, 293], "temperature": 0.0, "avg_logprob": -0.19758177422857903, "compression_ratio": 1.64375, "no_speech_prob": 0.0015132216503843665}, {"id": 92, "seek": 57268, "start": 582.8, "end": 591.8399999999999, "text": " I think it will be the standard way to do it, and on top of it, we have many tools.", "tokens": [286, 519, 309, 486, 312, 264, 3832, 636, 281, 360, 309, 11, 293, 322, 1192, 295, 309, 11, 321, 362, 867, 3873, 13], "temperature": 0.0, "avg_logprob": -0.19758177422857903, "compression_ratio": 1.64375, "no_speech_prob": 0.0015132216503843665}, {"id": 93, "seek": 57268, "start": 591.8399999999999, "end": 598.64, "text": " Here is one example, CFF convert tool, where we can convert the CFF file format, for example,", "tokens": [1692, 307, 472, 1365, 11, 383, 6345, 7620, 2290, 11, 689, 321, 393, 7620, 264, 383, 6345, 3991, 7877, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.19758177422857903, "compression_ratio": 1.64375, "no_speech_prob": 0.0015132216503843665}, {"id": 94, "seek": 59864, "start": 598.64, "end": 605.76, "text": " to big tech, to bibliotech, or to APA format, and many other formats, then we can keep the", "tokens": [281, 955, 7553, 11, 281, 34344, 1370, 339, 11, 420, 281, 5372, 32, 7877, 11, 293, 867, 661, 25879, 11, 550, 321, 393, 1066, 264], "temperature": 0.0, "avg_logprob": -0.2552279881068638, "compression_ratio": 1.5962732919254659, "no_speech_prob": 0.0006395900272764266}, {"id": 95, "seek": 59864, "start": 605.76, "end": 610.84, "text": " automated data about the software important for citation in one single file, and from", "tokens": [18473, 1412, 466, 264, 4722, 1021, 337, 45590, 294, 472, 2167, 3991, 11, 293, 490], "temperature": 0.0, "avg_logprob": -0.2552279881068638, "compression_ratio": 1.5962732919254659, "no_speech_prob": 0.0006395900272764266}, {"id": 96, "seek": 59864, "start": 610.84, "end": 622.04, "text": " this file, we can derivate to many others, and it's really an easy way to do it.", "tokens": [341, 3991, 11, 321, 393, 10151, 473, 281, 867, 2357, 11, 293, 309, 311, 534, 364, 1858, 636, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.2552279881068638, "compression_ratio": 1.5962732919254659, "no_speech_prob": 0.0006395900272764266}, {"id": 97, "seek": 62204, "start": 622.04, "end": 631.52, "text": " And then in Cortex, it's a solved problem, but we still have an issue about how to identify", "tokens": [400, 550, 294, 28522, 3121, 11, 309, 311, 257, 13041, 1154, 11, 457, 321, 920, 362, 364, 2734, 466, 577, 281, 5876], "temperature": 0.0, "avg_logprob": -0.17679247071471396, "compression_ratio": 1.625, "no_speech_prob": 0.0005416581407189369}, {"id": 98, "seek": 62204, "start": 631.52, "end": 635.64, "text": " permanently this object.", "tokens": [24042, 341, 2657, 13], "temperature": 0.0, "avg_logprob": -0.17679247071471396, "compression_ratio": 1.625, "no_speech_prob": 0.0005416581407189369}, {"id": 99, "seek": 62204, "start": 635.64, "end": 641.28, "text": " I say object as a digital object, okay, it's a software, but it's a digital object from", "tokens": [286, 584, 2657, 382, 257, 4562, 2657, 11, 1392, 11, 309, 311, 257, 4722, 11, 457, 309, 311, 257, 4562, 2657, 490], "temperature": 0.0, "avg_logprob": -0.17679247071471396, "compression_ratio": 1.625, "no_speech_prob": 0.0005416581407189369}, {"id": 100, "seek": 62204, "start": 641.28, "end": 646.9599999999999, "text": " the point of view of science, and how we can identify it permanently, for example, for papers,", "tokens": [264, 935, 295, 1910, 295, 3497, 11, 293, 577, 321, 393, 5876, 309, 24042, 11, 337, 1365, 11, 337, 10577, 11], "temperature": 0.0, "avg_logprob": -0.17679247071471396, "compression_ratio": 1.625, "no_speech_prob": 0.0005416581407189369}, {"id": 101, "seek": 64696, "start": 646.96, "end": 653.4000000000001, "text": " we have a DOI, that it's very well known, and so it's very well for papers, PDF, but", "tokens": [321, 362, 257, 10699, 40, 11, 300, 309, 311, 588, 731, 2570, 11, 293, 370, 309, 311, 588, 731, 337, 10577, 11, 17752, 11, 457], "temperature": 0.0, "avg_logprob": -0.17402829929273955, "compression_ratio": 1.8316831683168318, "no_speech_prob": 0.0004008325922768563}, {"id": 102, "seek": 64696, "start": 653.4000000000001, "end": 661.72, "text": " for software, we have a problem to, we can need to cite software in many different levels", "tokens": [337, 4722, 11, 321, 362, 257, 1154, 281, 11, 321, 393, 643, 281, 37771, 4722, 294, 867, 819, 4358], "temperature": 0.0, "avg_logprob": -0.17402829929273955, "compression_ratio": 1.8316831683168318, "no_speech_prob": 0.0004008325922768563}, {"id": 103, "seek": 64696, "start": 661.72, "end": 664.6, "text": " of granularity, for example.", "tokens": [295, 39962, 507, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.17402829929273955, "compression_ratio": 1.8316831683168318, "no_speech_prob": 0.0004008325922768563}, {"id": 104, "seek": 64696, "start": 664.6, "end": 669.48, "text": " We can cite the software, just the software name, or a specific version of the software,", "tokens": [492, 393, 37771, 264, 4722, 11, 445, 264, 4722, 1315, 11, 420, 257, 2685, 3037, 295, 264, 4722, 11], "temperature": 0.0, "avg_logprob": -0.17402829929273955, "compression_ratio": 1.8316831683168318, "no_speech_prob": 0.0004008325922768563}, {"id": 105, "seek": 64696, "start": 669.48, "end": 675.0, "text": " or a specific line of a specific file inside the source code of the software.", "tokens": [420, 257, 2685, 1622, 295, 257, 2685, 3991, 1854, 264, 4009, 3089, 295, 264, 4722, 13], "temperature": 0.0, "avg_logprob": -0.17402829929273955, "compression_ratio": 1.8316831683168318, "no_speech_prob": 0.0004008325922768563}, {"id": 106, "seek": 67500, "start": 675.0, "end": 680.48, "text": " Again, this is still an open question, because, for example, we have a proposition from the", "tokens": [3764, 11, 341, 307, 920, 364, 1269, 1168, 11, 570, 11, 337, 1365, 11, 321, 362, 257, 24830, 490, 264], "temperature": 0.0, "avg_logprob": -0.19749240617494326, "compression_ratio": 1.5618556701030928, "no_speech_prob": 0.0006044442416168749}, {"id": 107, "seek": 67500, "start": 680.48, "end": 690.44, "text": " community to solve it, but there is no one single kind of permanent ID that covers all", "tokens": [1768, 281, 5039, 309, 11, 457, 456, 307, 572, 472, 2167, 733, 295, 10996, 7348, 300, 10538, 439], "temperature": 0.0, "avg_logprob": -0.19749240617494326, "compression_ratio": 1.5618556701030928, "no_speech_prob": 0.0006044442416168749}, {"id": 108, "seek": 67500, "start": 690.44, "end": 693.56, "text": " the levels of granularity, for example.", "tokens": [264, 4358, 295, 39962, 507, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.19749240617494326, "compression_ratio": 1.5618556701030928, "no_speech_prob": 0.0006044442416168749}, {"id": 109, "seek": 67500, "start": 693.56, "end": 698.4, "text": " We have the proposition from the Software Heritage Project, that it's the suite, the", "tokens": [492, 362, 264, 24830, 490, 264, 27428, 27406, 9849, 11, 300, 309, 311, 264, 14205, 11, 264], "temperature": 0.0, "avg_logprob": -0.19749240617494326, "compression_ratio": 1.5618556701030928, "no_speech_prob": 0.0006044442416168749}, {"id": 110, "seek": 69840, "start": 698.4, "end": 705.12, "text": " Software Heritage ID, that we can use it to cite software in the very specific code fragment", "tokens": [27428, 27406, 7348, 11, 300, 321, 393, 764, 309, 281, 37771, 4722, 294, 264, 588, 2685, 3089, 26424], "temperature": 0.0, "avg_logprob": -0.19502709946542415, "compression_ratio": 1.7257383966244726, "no_speech_prob": 0.00032660330180078745}, {"id": 111, "seek": 69840, "start": 705.12, "end": 712.0799999999999, "text": " to the snapshot of the full source code, but, for example, we can't use Software ID to cite", "tokens": [281, 264, 30163, 295, 264, 1577, 4009, 3089, 11, 457, 11, 337, 1365, 11, 321, 393, 380, 764, 27428, 7348, 281, 37771], "temperature": 0.0, "avg_logprob": -0.19502709946542415, "compression_ratio": 1.7257383966244726, "no_speech_prob": 0.00032660330180078745}, {"id": 112, "seek": 69840, "start": 712.0799999999999, "end": 717.52, "text": " software in a high level, like the software version of this, only this project name.", "tokens": [4722, 294, 257, 1090, 1496, 11, 411, 264, 4722, 3037, 295, 341, 11, 787, 341, 1716, 1315, 13], "temperature": 0.0, "avg_logprob": -0.19502709946542415, "compression_ratio": 1.7257383966244726, "no_speech_prob": 0.00032660330180078745}, {"id": 113, "seek": 69840, "start": 717.52, "end": 720.72, "text": " For that, we should use another kind of ID, that's it.", "tokens": [1171, 300, 11, 321, 820, 764, 1071, 733, 295, 7348, 11, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.19502709946542415, "compression_ratio": 1.7257383966244726, "no_speech_prob": 0.00032660330180078745}, {"id": 114, "seek": 69840, "start": 720.72, "end": 727.56, "text": " And it's an open question that we should work this year or next year, and that's it.", "tokens": [400, 309, 311, 364, 1269, 1168, 300, 321, 820, 589, 341, 1064, 420, 958, 1064, 11, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.19502709946542415, "compression_ratio": 1.7257383966244726, "no_speech_prob": 0.00032660330180078745}, {"id": 115, "seek": 72756, "start": 727.56, "end": 730.56, "text": " Now it's the time for you, Juan.", "tokens": [823, 309, 311, 264, 565, 337, 291, 11, 17064, 13], "temperature": 0.0, "avg_logprob": -0.26347099031720844, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.0018718893406912684}, {"id": 116, "seek": 72756, "start": 730.56, "end": 731.56, "text": " You?", "tokens": [509, 30], "temperature": 0.0, "avg_logprob": -0.26347099031720844, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.0018718893406912684}, {"id": 117, "seek": 72756, "start": 731.56, "end": 734.56, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.26347099031720844, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.0018718893406912684}, {"id": 118, "seek": 72756, "start": 734.56, "end": 745.2399999999999, "text": " So one question we've been asking ourselves is how to open the platform fully.", "tokens": [407, 472, 1168, 321, 600, 668, 3365, 4175, 307, 577, 281, 1269, 264, 3663, 4498, 13], "temperature": 0.0, "avg_logprob": -0.26347099031720844, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.0018718893406912684}, {"id": 119, "seek": 72756, "start": 745.2399999999999, "end": 750.9599999999999, "text": " What did we do to do that until now, and what to do in the future?", "tokens": [708, 630, 321, 360, 281, 360, 300, 1826, 586, 11, 293, 437, 281, 360, 294, 264, 2027, 30], "temperature": 0.0, "avg_logprob": -0.26347099031720844, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.0018718893406912684}, {"id": 120, "seek": 72756, "start": 750.9599999999999, "end": 756.4799999999999, "text": " So there is no platform, web platform, without free open source software today, and we are", "tokens": [407, 456, 307, 572, 3663, 11, 3670, 3663, 11, 1553, 1737, 1269, 4009, 4722, 965, 11, 293, 321, 366], "temperature": 0.0, "avg_logprob": -0.26347099031720844, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.0018718893406912684}, {"id": 121, "seek": 75648, "start": 756.48, "end": 763.6, "text": " using a lot already, and I just put some of them on this page.", "tokens": [1228, 257, 688, 1217, 11, 293, 286, 445, 829, 512, 295, 552, 322, 341, 3028, 13], "temperature": 0.0, "avg_logprob": -0.17314753267500135, "compression_ratio": 1.6214689265536724, "no_speech_prob": 0.0009519843733869493}, {"id": 122, "seek": 75648, "start": 763.6, "end": 772.9200000000001, "text": " You can see here, from any layer of the infrastructure, from the virtual machine, the containers,", "tokens": [509, 393, 536, 510, 11, 490, 604, 4583, 295, 264, 6896, 11, 490, 264, 6374, 3479, 11, 264, 17089, 11], "temperature": 0.0, "avg_logprob": -0.17314753267500135, "compression_ratio": 1.6214689265536724, "no_speech_prob": 0.0009519843733869493}, {"id": 123, "seek": 75648, "start": 772.9200000000001, "end": 782.0, "text": " the scripts, the operating systems, et cetera, et cetera, until the actual methods and interface", "tokens": [264, 23294, 11, 264, 7447, 3652, 11, 1030, 11458, 11, 1030, 11458, 11, 1826, 264, 3539, 7150, 293, 9226], "temperature": 0.0, "avg_logprob": -0.17314753267500135, "compression_ratio": 1.6214689265536724, "no_speech_prob": 0.0009519843733869493}, {"id": 124, "seek": 75648, "start": 782.0, "end": 784.6800000000001, "text": " that you produce to the user.", "tokens": [300, 291, 5258, 281, 264, 4195, 13], "temperature": 0.0, "avg_logprob": -0.17314753267500135, "compression_ratio": 1.6214689265536724, "no_speech_prob": 0.0009519843733869493}, {"id": 125, "seek": 78468, "start": 784.68, "end": 789.12, "text": " We are using free open source software, or at least open source software, because I don't", "tokens": [492, 366, 1228, 1737, 1269, 4009, 4722, 11, 420, 412, 1935, 1269, 4009, 4722, 11, 570, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.1502637216600321, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0005120017449371517}, {"id": 126, "seek": 78468, "start": 789.12, "end": 793.12, "text": " want to start a debate here, but that's the general idea.", "tokens": [528, 281, 722, 257, 7958, 510, 11, 457, 300, 311, 264, 2674, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1502637216600321, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0005120017449371517}, {"id": 127, "seek": 78468, "start": 793.12, "end": 794.92, "text": " Now this is not Cortex producing that.", "tokens": [823, 341, 307, 406, 28522, 3121, 10501, 300, 13], "temperature": 0.0, "avg_logprob": -0.1502637216600321, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0005120017449371517}, {"id": 128, "seek": 78468, "start": 794.92, "end": 802.4799999999999, "text": " The Cortex is wrapping around this open source software, and it's open access for now.", "tokens": [440, 28522, 3121, 307, 21993, 926, 341, 1269, 4009, 4722, 11, 293, 309, 311, 1269, 2105, 337, 586, 13], "temperature": 0.0, "avg_logprob": -0.1502637216600321, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0005120017449371517}, {"id": 129, "seek": 78468, "start": 802.4799999999999, "end": 807.9599999999999, "text": " So it's free and open to everybody to use as an interface, but the code is not entirely", "tokens": [407, 309, 311, 1737, 293, 1269, 281, 2201, 281, 764, 382, 364, 9226, 11, 457, 264, 3089, 307, 406, 7696], "temperature": 0.0, "avg_logprob": -0.1502637216600321, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0005120017449371517}, {"id": 130, "seek": 78468, "start": 807.9599999999999, "end": 808.9599999999999, "text": " free.", "tokens": [1737, 13], "temperature": 0.0, "avg_logprob": -0.1502637216600321, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0005120017449371517}, {"id": 131, "seek": 78468, "start": 808.9599999999999, "end": 814.16, "text": " We've been trying to do that a little bit more than the last few years, and hopefully", "tokens": [492, 600, 668, 1382, 281, 360, 300, 257, 707, 857, 544, 813, 264, 1036, 1326, 924, 11, 293, 4696], "temperature": 0.0, "avg_logprob": -0.1502637216600321, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0005120017449371517}, {"id": 132, "seek": 81416, "start": 814.16, "end": 816.68, "text": " in the next few years, even more.", "tokens": [294, 264, 958, 1326, 924, 11, 754, 544, 13], "temperature": 0.0, "avg_logprob": -0.24656722856604535, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.001152317738160491}, {"id": 133, "seek": 81416, "start": 816.68, "end": 822.68, "text": " And Ale will talk to you about how to do that, and what are the challenges to actually produce", "tokens": [400, 9366, 486, 751, 281, 291, 466, 577, 281, 360, 300, 11, 293, 437, 366, 264, 4759, 281, 767, 5258], "temperature": 0.0, "avg_logprob": -0.24656722856604535, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.001152317738160491}, {"id": 134, "seek": 81416, "start": 822.68, "end": 826.68, "text": " a good open source software and methods.", "tokens": [257, 665, 1269, 4009, 4722, 293, 7150, 13], "temperature": 0.0, "avg_logprob": -0.24656722856604535, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.001152317738160491}, {"id": 135, "seek": 81416, "start": 826.68, "end": 832.52, "text": " Hello, everybody, I'm Ale.", "tokens": [2425, 11, 2201, 11, 286, 478, 9366, 13], "temperature": 0.0, "avg_logprob": -0.24656722856604535, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.001152317738160491}, {"id": 136, "seek": 81416, "start": 832.52, "end": 837.12, "text": " I work with the guys and go in Cortex.", "tokens": [286, 589, 365, 264, 1074, 293, 352, 294, 28522, 3121, 13], "temperature": 0.0, "avg_logprob": -0.24656722856604535, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.001152317738160491}, {"id": 137, "seek": 81416, "start": 837.12, "end": 842.1999999999999, "text": " So this is not really a talk about Cortex, I'm not going to do a demo or something.", "tokens": [407, 341, 307, 406, 534, 257, 751, 466, 28522, 3121, 11, 286, 478, 406, 516, 281, 360, 257, 10723, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.24656722856604535, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.001152317738160491}, {"id": 138, "seek": 84220, "start": 842.2, "end": 847.8000000000001, "text": " Because we thought of this talk as a moment to discuss what's going on with us, what is", "tokens": [1436, 321, 1194, 295, 341, 751, 382, 257, 1623, 281, 2248, 437, 311, 516, 322, 365, 505, 11, 437, 307], "temperature": 0.0, "avg_logprob": -0.20792552699213443, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.00040435881237499416}, {"id": 139, "seek": 84220, "start": 847.8000000000001, "end": 852.88, "text": " going on in the platform, because up to now, like Philippe just explained, everybody can", "tokens": [516, 322, 294, 264, 3663, 11, 570, 493, 281, 586, 11, 411, 13694, 68, 445, 8825, 11, 2201, 393], "temperature": 0.0, "avg_logprob": -0.20792552699213443, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.00040435881237499416}, {"id": 140, "seek": 84220, "start": 852.88, "end": 859.0, "text": " come and use, but most of the software in Cortex has been developed without, well, with", "tokens": [808, 293, 764, 11, 457, 881, 295, 264, 4722, 294, 28522, 3121, 575, 668, 4743, 1553, 11, 731, 11, 365], "temperature": 0.0, "avg_logprob": -0.20792552699213443, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.00040435881237499416}, {"id": 141, "seek": 84220, "start": 859.0, "end": 863.8000000000001, "text": " open source in mind, but not in practice, for practical reasons.", "tokens": [1269, 4009, 294, 1575, 11, 457, 406, 294, 3124, 11, 337, 8496, 4112, 13], "temperature": 0.0, "avg_logprob": -0.20792552699213443, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.00040435881237499416}, {"id": 142, "seek": 84220, "start": 863.8000000000001, "end": 868.72, "text": " So are we missing one slide?", "tokens": [407, 366, 321, 5361, 472, 4137, 30], "temperature": 0.0, "avg_logprob": -0.20792552699213443, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.00040435881237499416}, {"id": 143, "seek": 86872, "start": 868.72, "end": 873.6800000000001, "text": " No, yeah, so everything from the methods, the interfaces, the back ends, everything", "tokens": [883, 11, 1338, 11, 370, 1203, 490, 264, 7150, 11, 264, 28416, 11, 264, 646, 5314, 11, 1203], "temperature": 0.0, "avg_logprob": -0.2079220045180548, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00047585112042725086}, {"id": 144, "seek": 86872, "start": 873.6800000000001, "end": 878.52, "text": " has, so even our documentation is on Wordpress or Q&A also.", "tokens": [575, 11, 370, 754, 527, 14333, 307, 322, 8725, 11637, 420, 1249, 5, 32, 611, 13], "temperature": 0.0, "avg_logprob": -0.2079220045180548, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00047585112042725086}, {"id": 145, "seek": 86872, "start": 878.52, "end": 885.1600000000001, "text": " So everything is based on open source, but up to now, we didn't have real open source", "tokens": [407, 1203, 307, 2361, 322, 1269, 4009, 11, 457, 493, 281, 586, 11, 321, 994, 380, 362, 957, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.2079220045180548, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00047585112042725086}, {"id": 146, "seek": 86872, "start": 885.1600000000001, "end": 886.1600000000001, "text": " practices.", "tokens": [7525, 13], "temperature": 0.0, "avg_logprob": -0.2079220045180548, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00047585112042725086}, {"id": 147, "seek": 86872, "start": 886.1600000000001, "end": 897.0, "text": " So how are we managing this transition from a project that is very aligned with open", "tokens": [407, 577, 366, 321, 11642, 341, 6034, 490, 257, 1716, 300, 307, 588, 17962, 365, 1269], "temperature": 0.0, "avg_logprob": -0.2079220045180548, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.00047585112042725086}, {"id": 148, "seek": 89700, "start": 897.0, "end": 902.2, "text": " source community, but that doesn't manage to do open source, to start doing open source?", "tokens": [4009, 1768, 11, 457, 300, 1177, 380, 3067, 281, 360, 1269, 4009, 11, 281, 722, 884, 1269, 4009, 30], "temperature": 0.0, "avg_logprob": -0.21989864550138774, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.0004044769739266485}, {"id": 149, "seek": 89700, "start": 902.2, "end": 908.84, "text": " So there was really a big part was just getting even more open source into the project.", "tokens": [407, 456, 390, 534, 257, 955, 644, 390, 445, 1242, 754, 544, 1269, 4009, 666, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.21989864550138774, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.0004044769739266485}, {"id": 150, "seek": 89700, "start": 908.84, "end": 917.12, "text": " So we're starting to use project management tools that we were using, like some of them,", "tokens": [407, 321, 434, 2891, 281, 764, 1716, 4592, 3873, 300, 321, 645, 1228, 11, 411, 512, 295, 552, 11], "temperature": 0.0, "avg_logprob": -0.21989864550138774, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.0004044769739266485}, {"id": 151, "seek": 89700, "start": 917.12, "end": 919.84, "text": " but not as much, not as systematically.", "tokens": [457, 406, 382, 709, 11, 406, 382, 39531, 13], "temperature": 0.0, "avg_logprob": -0.21989864550138774, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.0004044769739266485}, {"id": 152, "seek": 89700, "start": 919.84, "end": 925.0, "text": " So this is a real common problem with research software, where researchers, they don't always", "tokens": [407, 341, 307, 257, 957, 2689, 1154, 365, 2132, 4722, 11, 689, 10309, 11, 436, 500, 380, 1009], "temperature": 0.0, "avg_logprob": -0.21989864550138774, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.0004044769739266485}, {"id": 153, "seek": 92500, "start": 925.0, "end": 935.32, "text": " have the reflex to go into GitLab or GitHub or whatever and use issues and use dashboards", "tokens": [362, 264, 23802, 281, 352, 666, 16939, 37880, 420, 23331, 420, 2035, 293, 764, 2663, 293, 764, 8240, 17228], "temperature": 0.0, "avg_logprob": -0.18203950750416723, "compression_ratio": 1.4727272727272727, "no_speech_prob": 8.668797818245366e-05}, {"id": 154, "seek": 92500, "start": 935.32, "end": 941.04, "text": " and project management, sometimes not even a thing in their head.", "tokens": [293, 1716, 4592, 11, 2171, 406, 754, 257, 551, 294, 641, 1378, 13], "temperature": 0.0, "avg_logprob": -0.18203950750416723, "compression_ratio": 1.4727272727272727, "no_speech_prob": 8.668797818245366e-05}, {"id": 155, "seek": 92500, "start": 941.04, "end": 946.36, "text": " And that's kind of the background that we were facing, like years and years of research", "tokens": [400, 300, 311, 733, 295, 264, 3678, 300, 321, 645, 7170, 11, 411, 924, 293, 924, 295, 2132], "temperature": 0.0, "avg_logprob": -0.18203950750416723, "compression_ratio": 1.4727272727272727, "no_speech_prob": 8.668797818245366e-05}, {"id": 156, "seek": 94636, "start": 946.36, "end": 956.12, "text": " and developing stuff, using open source software, but using version control because, well, it", "tokens": [293, 6416, 1507, 11, 1228, 1269, 4009, 4722, 11, 457, 1228, 3037, 1969, 570, 11, 731, 11, 309], "temperature": 0.0, "avg_logprob": -0.24028279781341552, "compression_ratio": 1.5943396226415094, "no_speech_prob": 0.0001732643140712753}, {"id": 157, "seek": 94636, "start": 956.12, "end": 961.4, "text": " was still the infrastructure guys really needed that to work with, but it was really like", "tokens": [390, 920, 264, 6896, 1074, 534, 2978, 300, 281, 589, 365, 11, 457, 309, 390, 534, 411], "temperature": 0.0, "avg_logprob": -0.24028279781341552, "compression_ratio": 1.5943396226415094, "no_speech_prob": 0.0001732643140712753}, {"id": 158, "seek": 94636, "start": 961.4, "end": 962.7, "text": " the bare minimum.", "tokens": [264, 6949, 7285, 13], "temperature": 0.0, "avg_logprob": -0.24028279781341552, "compression_ratio": 1.5943396226415094, "no_speech_prob": 0.0001732643140712753}, {"id": 159, "seek": 94636, "start": 962.7, "end": 966.24, "text": " So how do you start to get people more involved?", "tokens": [407, 577, 360, 291, 722, 281, 483, 561, 544, 3288, 30], "temperature": 0.0, "avg_logprob": -0.24028279781341552, "compression_ratio": 1.5943396226415094, "no_speech_prob": 0.0001732643140712753}, {"id": 160, "seek": 94636, "start": 966.24, "end": 974.4, "text": " So we just, the first step was really pushing everybody to start using the usual tools,", "tokens": [407, 321, 445, 11, 264, 700, 1823, 390, 534, 7380, 2201, 281, 722, 1228, 264, 7713, 3873, 11], "temperature": 0.0, "avg_logprob": -0.24028279781341552, "compression_ratio": 1.5943396226415094, "no_speech_prob": 0.0001732643140712753}, {"id": 161, "seek": 97440, "start": 974.4, "end": 981.04, "text": " and sometimes first moving some projects and moving the discussion into issues on GitLab", "tokens": [293, 2171, 700, 2684, 512, 4455, 293, 2684, 264, 5017, 666, 2663, 322, 16939, 37880], "temperature": 0.0, "avg_logprob": -0.2266073226928711, "compression_ratio": 1.613953488372093, "no_speech_prob": 0.00016964779933914542}, {"id": 162, "seek": 97440, "start": 981.04, "end": 982.16, "text": " and all that.", "tokens": [293, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.2266073226928711, "compression_ratio": 1.613953488372093, "no_speech_prob": 0.00016964779933914542}, {"id": 163, "seek": 97440, "start": 982.16, "end": 989.04, "text": " And then, okay, so, and then, and also adopting for our discussions more open source software,", "tokens": [400, 550, 11, 1392, 11, 370, 11, 293, 550, 11, 293, 611, 32328, 337, 527, 11088, 544, 1269, 4009, 4722, 11], "temperature": 0.0, "avg_logprob": -0.2266073226928711, "compression_ratio": 1.613953488372093, "no_speech_prob": 0.00016964779933914542}, {"id": 164, "seek": 97440, "start": 989.04, "end": 996.48, "text": " like Matrix, so it's like, I don't know if anybody knows Matrix here, maybe today everybody", "tokens": [411, 36274, 11, 370, 309, 311, 411, 11, 286, 500, 380, 458, 498, 4472, 3255, 36274, 510, 11, 1310, 965, 2201], "temperature": 0.0, "avg_logprob": -0.2266073226928711, "compression_ratio": 1.613953488372093, "no_speech_prob": 0.00016964779933914542}, {"id": 165, "seek": 97440, "start": 996.48, "end": 1000.92, "text": " already knows Matrix, it wasn't really a given last year.", "tokens": [1217, 3255, 36274, 11, 309, 2067, 380, 534, 257, 2212, 1036, 1064, 13], "temperature": 0.0, "avg_logprob": -0.2266073226928711, "compression_ratio": 1.613953488372093, "no_speech_prob": 0.00016964779933914542}, {"id": 166, "seek": 100092, "start": 1000.92, "end": 1011.68, "text": " And then, once we had like adopted the general workflow, the projects were still, most of", "tokens": [400, 550, 11, 1564, 321, 632, 411, 12175, 264, 2674, 20993, 11, 264, 4455, 645, 920, 11, 881, 295], "temperature": 0.0, "avg_logprob": -0.17937944781395695, "compression_ratio": 1.7151898734177216, "no_speech_prob": 7.063717202981934e-05}, {"id": 167, "seek": 100092, "start": 1011.68, "end": 1017.16, "text": " the projects were still private, but they had the workflow of an open source project,", "tokens": [264, 4455, 645, 920, 4551, 11, 457, 436, 632, 264, 20993, 295, 364, 1269, 4009, 1716, 11], "temperature": 0.0, "avg_logprob": -0.17937944781395695, "compression_ratio": 1.7151898734177216, "no_speech_prob": 7.063717202981934e-05}, {"id": 168, "seek": 100092, "start": 1017.16, "end": 1023.4399999999999, "text": " so it helped get people into a better mindset and the people who would arrive and start working", "tokens": [370, 309, 4254, 483, 561, 666, 257, 1101, 12543, 293, 264, 561, 567, 576, 8881, 293, 722, 1364], "temperature": 0.0, "avg_logprob": -0.17937944781395695, "compression_ratio": 1.7151898734177216, "no_speech_prob": 7.063717202981934e-05}, {"id": 169, "seek": 102344, "start": 1023.44, "end": 1032.04, "text": " with us would like more easily recognize the pattern of working with open source.", "tokens": [365, 505, 576, 411, 544, 3612, 5521, 264, 5102, 295, 1364, 365, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.2111576190893201, "compression_ratio": 1.5913978494623655, "no_speech_prob": 5.5123568017734215e-05}, {"id": 170, "seek": 102344, "start": 1032.04, "end": 1039.28, "text": " Then because we had this system that runs the jobs and everything, and usually in the", "tokens": [1396, 570, 321, 632, 341, 1185, 300, 6676, 264, 4782, 293, 1203, 11, 293, 2673, 294, 264], "temperature": 0.0, "avg_logprob": -0.2111576190893201, "compression_ratio": 1.5913978494623655, "no_speech_prob": 5.5123568017734215e-05}, {"id": 171, "seek": 102344, "start": 1039.28, "end": 1045.3600000000001, "text": " old scripts, they would just use the structure that was in the system directly, and it was", "tokens": [1331, 23294, 11, 436, 576, 445, 764, 264, 3877, 300, 390, 294, 264, 1185, 3838, 11, 293, 309, 390], "temperature": 0.0, "avg_logprob": -0.2111576190893201, "compression_ratio": 1.5913978494623655, "no_speech_prob": 5.5123568017734215e-05}, {"id": 172, "seek": 102344, "start": 1045.3600000000001, "end": 1047.96, "text": " pretty hard to adapt and evolve them.", "tokens": [1238, 1152, 281, 6231, 293, 16693, 552, 13], "temperature": 0.0, "avg_logprob": -0.2111576190893201, "compression_ratio": 1.5913978494623655, "no_speech_prob": 5.5123568017734215e-05}, {"id": 173, "seek": 104796, "start": 1047.96, "end": 1054.56, "text": " So then we developed some kind of intermediate libraries so that it gets easier to, so making", "tokens": [407, 550, 321, 4743, 512, 733, 295, 19376, 15148, 370, 300, 309, 2170, 3571, 281, 11, 370, 1455], "temperature": 0.0, "avg_logprob": -0.224473876953125, "compression_ratio": 1.7204301075268817, "no_speech_prob": 3.870265936711803e-05}, {"id": 174, "seek": 104796, "start": 1054.56, "end": 1060.88, "text": " it easier to develop new methods in the platform.", "tokens": [309, 3571, 281, 1499, 777, 7150, 294, 264, 3663, 13], "temperature": 0.0, "avg_logprob": -0.224473876953125, "compression_ratio": 1.7204301075268817, "no_speech_prob": 3.870265936711803e-05}, {"id": 175, "seek": 104796, "start": 1060.88, "end": 1064.96, "text": " So we had to develop this intermediate, I won't have time to go into show the details,", "tokens": [407, 321, 632, 281, 1499, 341, 19376, 11, 286, 1582, 380, 362, 565, 281, 352, 666, 855, 264, 4365, 11], "temperature": 0.0, "avg_logprob": -0.224473876953125, "compression_ratio": 1.7204301075268817, "no_speech_prob": 3.870265936711803e-05}, {"id": 176, "seek": 104796, "start": 1064.96, "end": 1071.8, "text": " but just getting the idea that we have to get people into the workflow, develop libraries", "tokens": [457, 445, 1242, 264, 1558, 300, 321, 362, 281, 483, 561, 666, 264, 20993, 11, 1499, 15148], "temperature": 0.0, "avg_logprob": -0.224473876953125, "compression_ratio": 1.7204301075268817, "no_speech_prob": 3.870265936711803e-05}, {"id": 177, "seek": 107180, "start": 1071.8, "end": 1079.8, "text": " and interfaces and intermediate layers that help and automate some of the processes, give", "tokens": [293, 28416, 293, 19376, 7914, 300, 854, 293, 31605, 512, 295, 264, 7555, 11, 976], "temperature": 0.0, "avg_logprob": -0.21803004786653338, "compression_ratio": 1.65625, "no_speech_prob": 0.00020939146634191275}, {"id": 178, "seek": 107180, "start": 1079.8, "end": 1086.04, "text": " people more freedom to work, actually we also started integrating containers in the job", "tokens": [561, 544, 5645, 281, 589, 11, 767, 321, 611, 1409, 26889, 17089, 294, 264, 1691], "temperature": 0.0, "avg_logprob": -0.21803004786653338, "compression_ratio": 1.65625, "no_speech_prob": 0.00020939146634191275}, {"id": 179, "seek": 107180, "start": 1086.04, "end": 1090.84, "text": " manager and everything so that we could end with this intermediate layer so that people", "tokens": [6598, 293, 1203, 370, 300, 321, 727, 917, 365, 341, 19376, 4583, 370, 300, 561], "temperature": 0.0, "avg_logprob": -0.21803004786653338, "compression_ratio": 1.65625, "no_speech_prob": 0.00020939146634191275}, {"id": 180, "seek": 109084, "start": 1090.84, "end": 1101.84, "text": " could have more freedom to make it easier for them to keep doing their non-standard,", "tokens": [727, 362, 544, 5645, 281, 652, 309, 3571, 337, 552, 281, 1066, 884, 641, 2107, 12, 1115, 515, 11], "temperature": 0.0, "avg_logprob": -0.17843667766715907, "compression_ratio": 1.5968586387434556, "no_speech_prob": 0.00013991029118187726}, {"id": 181, "seek": 109084, "start": 1101.84, "end": 1107.72, "text": " non-advisable, non-best practices stuff, but that works for them because their researchers", "tokens": [2107, 12, 345, 4938, 712, 11, 2107, 12, 25331, 7525, 1507, 11, 457, 300, 1985, 337, 552, 570, 641, 10309], "temperature": 0.0, "avg_logprob": -0.17843667766715907, "compression_ratio": 1.5968586387434556, "no_speech_prob": 0.00013991029118187726}, {"id": 182, "seek": 109084, "start": 1107.72, "end": 1113.84, "text": " are not coders, they're not always coders.", "tokens": [366, 406, 17656, 433, 11, 436, 434, 406, 1009, 17656, 433, 13], "temperature": 0.0, "avg_logprob": -0.17843667766715907, "compression_ratio": 1.5968586387434556, "no_speech_prob": 0.00013991029118187726}, {"id": 183, "seek": 109084, "start": 1113.84, "end": 1120.36, "text": " And finally, and even for the people in the team that are more skilled programmers, of", "tokens": [400, 2721, 11, 293, 754, 337, 264, 561, 294, 264, 1469, 300, 366, 544, 19690, 41504, 11, 295], "temperature": 0.0, "avg_logprob": -0.17843667766715907, "compression_ratio": 1.5968586387434556, "no_speech_prob": 0.00013991029118187726}, {"id": 184, "seek": 112036, "start": 1120.36, "end": 1124.9199999999998, "text": " course, they want to have the possibility to do all this stuff.", "tokens": [1164, 11, 436, 528, 281, 362, 264, 7959, 281, 360, 439, 341, 1507, 13], "temperature": 0.0, "avg_logprob": -0.23472997618884575, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.00029116260702721775}, {"id": 185, "seek": 112036, "start": 1124.9199999999998, "end": 1130.36, "text": " And finally, one thing is very important is at the management level, because this is", "tokens": [400, 2721, 11, 472, 551, 307, 588, 1021, 307, 412, 264, 4592, 1496, 11, 570, 341, 307], "temperature": 0.0, "avg_logprob": -0.23472997618884575, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.00029116260702721775}, {"id": 186, "seek": 112036, "start": 1130.36, "end": 1136.6, "text": " like a kind of already intermediate kind of big-ish thing where we have hundreds of users", "tokens": [411, 257, 733, 295, 1217, 19376, 733, 295, 955, 12, 742, 551, 689, 321, 362, 6779, 295, 5022], "temperature": 0.0, "avg_logprob": -0.23472997618884575, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.00029116260702721775}, {"id": 187, "seek": 112036, "start": 1136.6, "end": 1143.4399999999998, "text": " everywhere, so we had to discuss this in the strategic planning so that our institutional", "tokens": [5315, 11, 370, 321, 632, 281, 2248, 341, 294, 264, 10924, 5038, 370, 300, 527, 18391], "temperature": 0.0, "avg_logprob": -0.23472997618884575, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.00029116260702721775}, {"id": 188, "seek": 112036, "start": 1143.4399999999998, "end": 1145.8, "text": " partners could get it.", "tokens": [4462, 727, 483, 309, 13], "temperature": 0.0, "avg_logprob": -0.23472997618884575, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.00029116260702721775}, {"id": 189, "seek": 114580, "start": 1145.8, "end": 1153.2, "text": " So basically, just get it everywhere as soon as possible and then start, once you can show", "tokens": [407, 1936, 11, 445, 483, 309, 5315, 382, 2321, 382, 1944, 293, 550, 722, 11, 1564, 291, 393, 855], "temperature": 0.0, "avg_logprob": -0.22319553920200894, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0001381460315315053}, {"id": 190, "seek": 114580, "start": 1153.2, "end": 1162.52, "text": " some of the benefits, also work at the institutional level.", "tokens": [512, 295, 264, 5311, 11, 611, 589, 412, 264, 18391, 1496, 13], "temperature": 0.0, "avg_logprob": -0.22319553920200894, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0001381460315315053}, {"id": 191, "seek": 114580, "start": 1162.52, "end": 1167.6, "text": " So these are some of the challenges.", "tokens": [407, 613, 366, 512, 295, 264, 4759, 13], "temperature": 0.0, "avg_logprob": -0.22319553920200894, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0001381460315315053}, {"id": 192, "seek": 114580, "start": 1167.6, "end": 1172.3999999999999, "text": " Most part of the team didn't have the know-how, part of the researchers we work with.", "tokens": [4534, 644, 295, 264, 1469, 994, 380, 362, 264, 458, 12, 4286, 11, 644, 295, 264, 10309, 321, 589, 365, 13], "temperature": 0.0, "avg_logprob": -0.22319553920200894, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0001381460315315053}, {"id": 193, "seek": 117240, "start": 1172.4, "end": 1178.8400000000001, "text": " People have limited resources, they have priorities, and I'm just reading out of there, but that's", "tokens": [3432, 362, 5567, 3593, 11, 436, 362, 15503, 11, 293, 286, 478, 445, 3760, 484, 295, 456, 11, 457, 300, 311], "temperature": 0.0, "avg_logprob": -0.207344617162432, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.0005744678783230484}, {"id": 194, "seek": 117240, "start": 1178.8400000000001, "end": 1179.8400000000001, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.207344617162432, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.0005744678783230484}, {"id": 195, "seek": 117240, "start": 1179.8400000000001, "end": 1181.3400000000001, "text": " It's not very surprising.", "tokens": [467, 311, 406, 588, 8830, 13], "temperature": 0.0, "avg_logprob": -0.207344617162432, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.0005744678783230484}, {"id": 196, "seek": 117240, "start": 1181.3400000000001, "end": 1185.8400000000001, "text": " There's this learning curve of open source and everything.", "tokens": [821, 311, 341, 2539, 7605, 295, 1269, 4009, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.207344617162432, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.0005744678783230484}, {"id": 197, "seek": 117240, "start": 1185.8400000000001, "end": 1190.3200000000002, "text": " And there's always doubts about where is this going to lead us.", "tokens": [400, 456, 311, 1009, 22618, 466, 689, 307, 341, 516, 281, 1477, 505, 13], "temperature": 0.0, "avg_logprob": -0.207344617162432, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.0005744678783230484}, {"id": 198, "seek": 117240, "start": 1190.3200000000002, "end": 1195.0400000000002, "text": " There's licensing doubts, so there's part of, like, next thing I'm going to quickly show", "tokens": [821, 311, 29759, 22618, 11, 370, 456, 311, 644, 295, 11, 411, 11, 958, 551, 286, 478, 516, 281, 2661, 855], "temperature": 0.0, "avg_logprob": -0.207344617162432, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.0005744678783230484}, {"id": 199, "seek": 117240, "start": 1195.0400000000002, "end": 1200.16, "text": " is that we're starting to open up stuff, and there's lots of stuff that hasn't been open", "tokens": [307, 300, 321, 434, 2891, 281, 1269, 493, 1507, 11, 293, 456, 311, 3195, 295, 1507, 300, 6132, 380, 668, 1269], "temperature": 0.0, "avg_logprob": -0.207344617162432, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.0005744678783230484}, {"id": 200, "seek": 120016, "start": 1200.16, "end": 1206.92, "text": " yet simply because somewhere, we know that somewhere in some file, somebody used an extract", "tokens": [1939, 2935, 570, 4079, 11, 321, 458, 300, 4079, 294, 512, 3991, 11, 2618, 1143, 364, 8947], "temperature": 0.0, "avg_logprob": -0.18417218526204426, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.00022175550111569464}, {"id": 201, "seek": 120016, "start": 1206.92, "end": 1212.64, "text": " from a software library that is not clearly documented, where it has been used, and we", "tokens": [490, 257, 4722, 6405, 300, 307, 406, 4448, 23007, 11, 689, 309, 575, 668, 1143, 11, 293, 321], "temperature": 0.0, "avg_logprob": -0.18417218526204426, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.00022175550111569464}, {"id": 202, "seek": 120016, "start": 1212.64, "end": 1219.3600000000001, "text": " need to find it and check if the license is compatible.", "tokens": [643, 281, 915, 309, 293, 1520, 498, 264, 10476, 307, 18218, 13], "temperature": 0.0, "avg_logprob": -0.18417218526204426, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.00022175550111569464}, {"id": 203, "seek": 120016, "start": 1219.3600000000001, "end": 1222.24, "text": " So we're always like, okay, where are we going?", "tokens": [407, 321, 434, 1009, 411, 11, 1392, 11, 689, 366, 321, 516, 30], "temperature": 0.0, "avg_logprob": -0.18417218526204426, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.00022175550111569464}, {"id": 204, "seek": 120016, "start": 1222.24, "end": 1229.8400000000001, "text": " But getting things to as close as possible on every dimension is what's keeping us moving.", "tokens": [583, 1242, 721, 281, 382, 1998, 382, 1944, 322, 633, 10139, 307, 437, 311, 5145, 505, 2684, 13], "temperature": 0.0, "avg_logprob": -0.18417218526204426, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.00022175550111569464}, {"id": 205, "seek": 122984, "start": 1229.84, "end": 1235.28, "text": " It's keeping the feeling that something is moving, even if we're not seeing everything.", "tokens": [467, 311, 5145, 264, 2633, 300, 746, 307, 2684, 11, 754, 498, 321, 434, 406, 2577, 1203, 13], "temperature": 0.0, "avg_logprob": -0.2178583249940977, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.000287773204036057}, {"id": 206, "seek": 122984, "start": 1235.28, "end": 1241.1999999999998, "text": " But then we, well, through this effort, eventually, we managed to open source already a good part", "tokens": [583, 550, 321, 11, 731, 11, 807, 341, 4630, 11, 4728, 11, 321, 6453, 281, 1269, 4009, 1217, 257, 665, 644], "temperature": 0.0, "avg_logprob": -0.2178583249940977, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.000287773204036057}, {"id": 207, "seek": 122984, "start": 1241.1999999999998, "end": 1252.1999999999998, "text": " of specifically the science part, so the infrastructure, the dashboard, the interfaces, the front-end", "tokens": [295, 4682, 264, 3497, 644, 11, 370, 264, 6896, 11, 264, 18342, 11, 264, 28416, 11, 264, 1868, 12, 521], "temperature": 0.0, "avg_logprob": -0.2178583249940977, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.000287773204036057}, {"id": 208, "seek": 122984, "start": 1252.1999999999998, "end": 1258.1599999999999, "text": " of the web application, and the job-managing part, or this part is not necessarily, it's", "tokens": [295, 264, 3670, 3861, 11, 293, 264, 1691, 12, 1601, 3568, 644, 11, 420, 341, 644, 307, 406, 4725, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.2178583249940977, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.000287773204036057}, {"id": 209, "seek": 125816, "start": 1258.16, "end": 1265.52, "text": " taking longer because it's also another part of the infrastructure.", "tokens": [1940, 2854, 570, 309, 311, 611, 1071, 644, 295, 264, 6896, 13], "temperature": 0.0, "avg_logprob": -0.1860638242779356, "compression_ratio": 1.4502923976608186, "no_speech_prob": 0.00018588796956464648}, {"id": 210, "seek": 125816, "start": 1265.52, "end": 1273.4, "text": " But the main, most important, short-term part is to let the scientific part of it be available.", "tokens": [583, 264, 2135, 11, 881, 1021, 11, 2099, 12, 7039, 644, 307, 281, 718, 264, 8134, 644, 295, 309, 312, 2435, 13], "temperature": 0.0, "avg_logprob": -0.1860638242779356, "compression_ratio": 1.4502923976608186, "no_speech_prob": 0.00018588796956464648}, {"id": 211, "seek": 125816, "start": 1273.4, "end": 1280.48, "text": " So here's just some examples, I'm not going to, but yeah, so there's two parsers, an", "tokens": [407, 510, 311, 445, 512, 5110, 11, 286, 478, 406, 516, 281, 11, 457, 1338, 11, 370, 456, 311, 732, 21156, 433, 11, 364], "temperature": 0.0, "avg_logprob": -0.1860638242779356, "compression_ratio": 1.4502923976608186, "no_speech_prob": 0.00018588796956464648}, {"id": 212, "seek": 128048, "start": 1280.48, "end": 1289.84, "text": " importer for a big database of scientific publications, a kind of generic parser that", "tokens": [704, 6122, 337, 257, 955, 8149, 295, 8134, 25618, 11, 257, 733, 295, 19577, 21156, 260, 300], "temperature": 0.0, "avg_logprob": -0.16260278081319418, "compression_ratio": 1.674757281553398, "no_speech_prob": 3.977934829890728e-05}, {"id": 213, "seek": 128048, "start": 1289.84, "end": 1297.96, "text": " we use for, we're in a sociology of science lab, so even though the tools are more like", "tokens": [321, 764, 337, 11, 321, 434, 294, 257, 41744, 295, 3497, 2715, 11, 370, 754, 1673, 264, 3873, 366, 544, 411], "temperature": 0.0, "avg_logprob": -0.16260278081319418, "compression_ratio": 1.674757281553398, "no_speech_prob": 3.977934829890728e-05}, {"id": 214, "seek": 128048, "start": 1297.96, "end": 1301.56, "text": " general humanities and social sciences, we have a lot of interesting things that come", "tokens": [2674, 36140, 293, 2093, 17677, 11, 321, 362, 257, 688, 295, 1880, 721, 300, 808], "temperature": 0.0, "avg_logprob": -0.16260278081319418, "compression_ratio": 1.674757281553398, "no_speech_prob": 3.977934829890728e-05}, {"id": 215, "seek": 128048, "start": 1301.56, "end": 1307.6, "text": " from PubMed, data that comes from PubMed, and similar databases, so this is like also", "tokens": [490, 21808, 42954, 11, 1412, 300, 1487, 490, 21808, 42954, 11, 293, 2531, 22380, 11, 370, 341, 307, 411, 611], "temperature": 0.0, "avg_logprob": -0.16260278081319418, "compression_ratio": 1.674757281553398, "no_speech_prob": 3.977934829890728e-05}, {"id": 216, "seek": 130760, "start": 1307.6, "end": 1314.6799999999998, "text": " a parser for that, and here's one example of a project that's in progress because even", "tokens": [257, 21156, 260, 337, 300, 11, 293, 510, 311, 472, 1365, 295, 257, 1716, 300, 311, 294, 4205, 570, 754], "temperature": 0.0, "avg_logprob": -0.18053187681048105, "compression_ratio": 1.6063348416289593, "no_speech_prob": 7.070523133734241e-05}, {"id": 217, "seek": 130760, "start": 1314.6799999999998, "end": 1320.4399999999998, "text": " though we reworked the project, parts of it still use some libraries that we're not sure,", "tokens": [1673, 321, 48376, 292, 264, 1716, 11, 3166, 295, 309, 920, 764, 512, 15148, 300, 321, 434, 406, 988, 11], "temperature": 0.0, "avg_logprob": -0.18053187681048105, "compression_ratio": 1.6063348416289593, "no_speech_prob": 7.070523133734241e-05}, {"id": 218, "seek": 130760, "start": 1320.4399999999998, "end": 1328.6, "text": " so we have to check, take the time to check if we need to change anything or replace.", "tokens": [370, 321, 362, 281, 1520, 11, 747, 264, 565, 281, 1520, 498, 321, 643, 281, 1319, 1340, 420, 7406, 13], "temperature": 0.0, "avg_logprob": -0.18053187681048105, "compression_ratio": 1.6063348416289593, "no_speech_prob": 7.070523133734241e-05}, {"id": 219, "seek": 130760, "start": 1328.6, "end": 1334.9599999999998, "text": " Just quickly show what some one of these things look like, well, this is just the repository", "tokens": [1449, 2661, 855, 437, 512, 472, 295, 613, 721, 574, 411, 11, 731, 11, 341, 307, 445, 264, 25841], "temperature": 0.0, "avg_logprob": -0.18053187681048105, "compression_ratio": 1.6063348416289593, "no_speech_prob": 7.070523133734241e-05}, {"id": 220, "seek": 133496, "start": 1334.96, "end": 1344.76, "text": " for one of the projects, you have the source code, some documentation, it makes pretty", "tokens": [337, 472, 295, 264, 4455, 11, 291, 362, 264, 4009, 3089, 11, 512, 14333, 11, 309, 1669, 1238], "temperature": 0.0, "avg_logprob": -0.24334108034769694, "compression_ratio": 1.5298013245033113, "no_speech_prob": 0.0001624456635909155}, {"id": 221, "seek": 133496, "start": 1344.76, "end": 1350.6000000000001, "text": " graphs, and you have to use it like this, like this.", "tokens": [24877, 11, 293, 291, 362, 281, 764, 309, 411, 341, 11, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.24334108034769694, "compression_ratio": 1.5298013245033113, "no_speech_prob": 0.0001624456635909155}, {"id": 222, "seek": 133496, "start": 1350.6000000000001, "end": 1357.1200000000001, "text": " So just getting things into what we all know about, what you know as an open source format,", "tokens": [407, 445, 1242, 721, 666, 437, 321, 439, 458, 466, 11, 437, 291, 458, 382, 364, 1269, 4009, 7877, 11], "temperature": 0.0, "avg_logprob": -0.24334108034769694, "compression_ratio": 1.5298013245033113, "no_speech_prob": 0.0001624456635909155}, {"id": 223, "seek": 135712, "start": 1357.12, "end": 1373.52, "text": " how do I go back to the presentation, F, no, no, there you go.", "tokens": [577, 360, 286, 352, 646, 281, 264, 5860, 11, 479, 11, 572, 11, 572, 11, 456, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.3285950907954463, "compression_ratio": 1.3660714285714286, "no_speech_prob": 0.0010008137905970216}, {"id": 224, "seek": 135712, "start": 1373.52, "end": 1382.56, "text": " What else there's to say, that's it, so thank you, I think, I mean, if you, if you, if you", "tokens": [708, 1646, 456, 311, 281, 584, 11, 300, 311, 309, 11, 370, 1309, 291, 11, 286, 519, 11, 286, 914, 11, 498, 291, 11, 498, 291, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.3285950907954463, "compression_ratio": 1.3660714285714286, "no_speech_prob": 0.0010008137905970216}, {"id": 225, "seek": 138256, "start": 1382.56, "end": 1390.48, "text": " have any of you work in a similar institution where open source is not an evidence but it's", "tokens": [362, 604, 295, 291, 589, 294, 257, 2531, 7818, 689, 1269, 4009, 307, 406, 364, 4467, 457, 309, 311], "temperature": 0.0, "avg_logprob": -0.32165535884117014, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0012688077986240387}, {"id": 226, "seek": 138256, "start": 1390.48, "end": 1397.0, "text": " something that you have to struggle with, we're very happy to exchange after, during", "tokens": [746, 300, 291, 362, 281, 7799, 365, 11, 321, 434, 588, 2055, 281, 7742, 934, 11, 1830], "temperature": 0.0, "avg_logprob": -0.32165535884117014, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0012688077986240387}, {"id": 227, "seek": 138256, "start": 1397.0, "end": 1409.8799999999999, "text": " or after the conference, did you skip the, no, no, you have no more time, thank you.", "tokens": [420, 934, 264, 7586, 11, 630, 291, 10023, 264, 11, 572, 11, 572, 11, 291, 362, 572, 544, 565, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.32165535884117014, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0012688077986240387}, {"id": 228, "seek": 140988, "start": 1409.88, "end": 1416.88, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.2, "avg_logprob": -0.9910422960917155, "compression_ratio": 0.7575757575757576, "no_speech_prob": 0.003984966780990362}, {"id": 229, "seek": 140988, "start": 1416.88, "end": 1419.88, "text": " Any questions?", "tokens": [2639, 1651, 30], "temperature": 0.2, "avg_logprob": -0.9910422960917155, "compression_ratio": 0.7575757575757576, "no_speech_prob": 0.003984966780990362}, {"id": 230, "seek": 141988, "start": 1419.88, "end": 1441.88, "text": " Yeah, thank you a lot, I like your time because there is a lot of nice to choose, and you just", "tokens": [865, 11, 1309, 291, 257, 688, 11, 286, 411, 428, 565, 570, 456, 307, 257, 688, 295, 1481, 281, 2826, 11, 293, 291, 445], "temperature": 0.0, "avg_logprob": -0.6253644398280552, "compression_ratio": 1.1325301204819278, "no_speech_prob": 0.017088981345295906}, {"id": 231, "seek": 144188, "start": 1441.88, "end": 1455.2, "text": " wanted to share with us, and I'm very happy to hear that you are bringing up the gauging.", "tokens": [1415, 281, 2073, 365, 505, 11, 293, 286, 478, 588, 2055, 281, 1568, 300, 291, 366, 5062, 493, 264, 5959, 697, 278, 13], "temperature": 0.0, "avg_logprob": -0.5016558084143213, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00403196644037962}, {"id": 232, "seek": 144188, "start": 1455.2, "end": 1462.16, "text": " Yeah, so the question was, what was preventing us to opening it from the beginning, and to", "tokens": [865, 11, 370, 264, 1168, 390, 11, 437, 390, 19965, 505, 281, 5193, 309, 490, 264, 2863, 11, 293, 281], "temperature": 0.0, "avg_logprob": -0.5016558084143213, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00403196644037962}, {"id": 233, "seek": 144188, "start": 1462.16, "end": 1464.2800000000002, "text": " make open source software from the beginning.", "tokens": [652, 1269, 4009, 4722, 490, 264, 2863, 13], "temperature": 0.0, "avg_logprob": -0.5016558084143213, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00403196644037962}, {"id": 234, "seek": 144188, "start": 1464.2800000000002, "end": 1470.2800000000002, "text": " So as Ale was saying, the first thing I think is just the lack of know-how, especially 15", "tokens": [407, 382, 9366, 390, 1566, 11, 264, 700, 551, 286, 519, 307, 445, 264, 5011, 295, 458, 12, 4286, 11, 2318, 2119], "temperature": 0.0, "avg_logprob": -0.5016558084143213, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00403196644037962}, {"id": 235, "seek": 147028, "start": 1470.28, "end": 1476.72, "text": " years ago when we started, the second thing I would say is that we, we basically didn't", "tokens": [924, 2057, 562, 321, 1409, 11, 264, 1150, 551, 286, 576, 584, 307, 300, 321, 11, 321, 1936, 994, 380], "temperature": 0.0, "avg_logprob": -0.16089252156948824, "compression_ratio": 1.8326359832635983, "no_speech_prob": 0.0024291053414344788}, {"id": 236, "seek": 147028, "start": 1476.72, "end": 1484.48, "text": " have a precise idea of what we were building, we just went basically script by script project", "tokens": [362, 257, 13600, 1558, 295, 437, 321, 645, 2390, 11, 321, 445, 1437, 1936, 5755, 538, 5755, 1716], "temperature": 0.0, "avg_logprob": -0.16089252156948824, "compression_ratio": 1.8326359832635983, "no_speech_prob": 0.0024291053414344788}, {"id": 237, "seek": 147028, "start": 1484.48, "end": 1489.16, "text": " by project, and this, this is how we built slowly the, the platform, then it became a", "tokens": [538, 1716, 11, 293, 341, 11, 341, 307, 577, 321, 3094, 5692, 264, 11, 264, 3663, 11, 550, 309, 3062, 257], "temperature": 0.0, "avg_logprob": -0.16089252156948824, "compression_ratio": 1.8326359832635983, "no_speech_prob": 0.0024291053414344788}, {"id": 238, "seek": 147028, "start": 1489.16, "end": 1493.24, "text": " platform, a proper platform, I mean, with the, with the resources and everything, and", "tokens": [3663, 11, 257, 2296, 3663, 11, 286, 914, 11, 365, 264, 11, 365, 264, 3593, 293, 1203, 11, 293], "temperature": 0.0, "avg_logprob": -0.16089252156948824, "compression_ratio": 1.8326359832635983, "no_speech_prob": 0.0024291053414344788}, {"id": 239, "seek": 147028, "start": 1493.24, "end": 1498.48, "text": " then, then it was already used, and, and we trained people on those methods already,", "tokens": [550, 11, 550, 309, 390, 1217, 1143, 11, 293, 11, 293, 321, 8895, 561, 322, 729, 7150, 1217, 11], "temperature": 0.0, "avg_logprob": -0.16089252156948824, "compression_ratio": 1.8326359832635983, "no_speech_prob": 0.0024291053414344788}, {"id": 240, "seek": 149848, "start": 1498.48, "end": 1504.3600000000001, "text": " so the problem of opening, of doing open source software is you have to think about it from", "tokens": [370, 264, 1154, 295, 5193, 11, 295, 884, 1269, 4009, 4722, 307, 291, 362, 281, 519, 466, 309, 490], "temperature": 0.0, "avg_logprob": -0.21721846969039352, "compression_ratio": 1.6184971098265897, "no_speech_prob": 0.0019429513486102223}, {"id": 241, "seek": 149848, "start": 1504.3600000000001, "end": 1509.48, "text": " the beginning, or at least refactor enough the, the code, so it's big, it's, it has no", "tokens": [264, 2863, 11, 420, 412, 1935, 1895, 15104, 1547, 264, 11, 264, 3089, 11, 370, 309, 311, 955, 11, 309, 311, 11, 309, 575, 572], "temperature": 0.0, "avg_logprob": -0.21721846969039352, "compression_ratio": 1.6184971098265897, "no_speech_prob": 0.0019429513486102223}, {"id": 242, "seek": 149848, "start": 1509.48, "end": 1514.88, "text": " problem of, of license, and stuff like that, so this is, this is just a, you know, an ongoing", "tokens": [1154, 295, 11, 295, 10476, 11, 293, 1507, 411, 300, 11, 370, 341, 307, 11, 341, 307, 445, 257, 11, 291, 458, 11, 364, 10452], "temperature": 0.0, "avg_logprob": -0.21721846969039352, "compression_ratio": 1.6184971098265897, "no_speech_prob": 0.0019429513486102223}, {"id": 243, "seek": 149848, "start": 1514.88, "end": 1515.88, "text": " streak.", "tokens": [35634, 13], "temperature": 0.0, "avg_logprob": -0.21721846969039352, "compression_ratio": 1.6184971098265897, "no_speech_prob": 0.0019429513486102223}, {"id": 244, "seek": 151588, "start": 1515.88, "end": 1532.88, "text": " Yeah, speak loud, sorry, I can't, I can't hear you.", "tokens": [865, 11, 1710, 6588, 11, 2597, 11, 286, 393, 380, 11, 286, 393, 380, 1568, 291, 13], "temperature": 0.0, "avg_logprob": -0.501746586390904, "compression_ratio": 1.02, "no_speech_prob": 0.005241598468273878}, {"id": 245, "seek": 153288, "start": 1532.88, "end": 1552.4, "text": " Yeah, it's about, yeah, some, some people upload software to Zenodo or upload a documentation", "tokens": [865, 11, 309, 311, 466, 11, 1338, 11, 512, 11, 512, 561, 6580, 4722, 281, 22387, 17423, 420, 6580, 257, 14333], "temperature": 0.0, "avg_logprob": -0.20513692194101762, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.003308790735900402}, {"id": 246, "seek": 153288, "start": 1552.4, "end": 1558.7600000000002, "text": " or, that's, that creates one kind of identifier, which you could also make a, some people just", "tokens": [420, 11, 300, 311, 11, 300, 7829, 472, 733, 295, 45690, 11, 597, 291, 727, 611, 652, 257, 11, 512, 561, 445], "temperature": 0.0, "avg_logprob": -0.20513692194101762, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.003308790735900402}, {"id": 247, "seek": 155876, "start": 1558.76, "end": 1563.04, "text": " make a publication related to the software, so people can cite a DOI, Zenodo is going", "tokens": [652, 257, 19953, 4077, 281, 264, 4722, 11, 370, 561, 393, 37771, 257, 10699, 40, 11, 22387, 17423, 307, 516], "temperature": 0.0, "avg_logprob": -0.19634666082993993, "compression_ratio": 1.8584070796460177, "no_speech_prob": 0.0005617319839075208}, {"id": 248, "seek": 155876, "start": 1563.04, "end": 1565.96, "text": " to give a DOI, so it's the same, pretty much the same thing.", "tokens": [281, 976, 257, 10699, 40, 11, 370, 309, 311, 264, 912, 11, 1238, 709, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.19634666082993993, "compression_ratio": 1.8584070796460177, "no_speech_prob": 0.0005617319839075208}, {"id": 249, "seek": 155876, "start": 1565.96, "end": 1570.48, "text": " The problem is that, I think like Jenner was explaining is that sometimes you want to cite", "tokens": [440, 1154, 307, 300, 11, 286, 519, 411, 9228, 1193, 390, 13468, 307, 300, 2171, 291, 528, 281, 37771], "temperature": 0.0, "avg_logprob": -0.19634666082993993, "compression_ratio": 1.8584070796460177, "no_speech_prob": 0.0005617319839075208}, {"id": 250, "seek": 155876, "start": 1570.48, "end": 1575.68, "text": " a specific version of the software or a specific file in a specific version, or you want to", "tokens": [257, 2685, 3037, 295, 264, 4722, 420, 257, 2685, 3991, 294, 257, 2685, 3037, 11, 420, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.19634666082993993, "compression_ratio": 1.8584070796460177, "no_speech_prob": 0.0005617319839075208}, {"id": 251, "seek": 155876, "start": 1575.68, "end": 1581.36, "text": " cite the software without mentioning a specific version, and, and you don't want to upload", "tokens": [37771, 264, 4722, 1553, 18315, 257, 2685, 3037, 11, 293, 11, 293, 291, 500, 380, 528, 281, 6580], "temperature": 0.0, "avg_logprob": -0.19634666082993993, "compression_ratio": 1.8584070796460177, "no_speech_prob": 0.0005617319839075208}, {"id": 252, "seek": 158136, "start": 1581.36, "end": 1594.6799999999998, "text": " one version to Zenodo for every possible thing.", "tokens": [472, 3037, 281, 22387, 17423, 337, 633, 1944, 551, 13], "temperature": 0.0, "avg_logprob": -0.2621232798842133, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.0023913977202028036}, {"id": 253, "seek": 158136, "start": 1594.6799999999998, "end": 1603.3999999999999, "text": " Yeah, yeah, yeah, I, I don't know exactly deep what Zenodo offers, but I know that Zenodo", "tokens": [865, 11, 1338, 11, 1338, 11, 286, 11, 286, 500, 380, 458, 2293, 2452, 437, 22387, 17423, 7736, 11, 457, 286, 458, 300, 22387, 17423], "temperature": 0.0, "avg_logprob": -0.2621232798842133, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.0023913977202028036}, {"id": 254, "seek": 158136, "start": 1603.3999999999999, "end": 1610.08, "text": " offers a way to manage many different kind of digital objects, data, images, software,", "tokens": [7736, 257, 636, 281, 3067, 867, 819, 733, 295, 4562, 6565, 11, 1412, 11, 5267, 11, 4722, 11], "temperature": 0.0, "avg_logprob": -0.2621232798842133, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.0023913977202028036}, {"id": 255, "seek": 161008, "start": 1610.08, "end": 1613.0, "text": " etc., and not only Zenodo.", "tokens": [5183, 7933, 293, 406, 787, 22387, 17423, 13], "temperature": 0.0, "avg_logprob": -0.17378074432087837, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.0009089830564334989}, {"id": 256, "seek": 161008, "start": 1613.0, "end": 1618.3999999999999, "text": " In our case, what is missing is to study all the options to see which fits better in, in,", "tokens": [682, 527, 1389, 11, 437, 307, 5361, 307, 281, 2979, 439, 264, 3956, 281, 536, 597, 9001, 1101, 294, 11, 294, 11], "temperature": 0.0, "avg_logprob": -0.17378074432087837, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.0009089830564334989}, {"id": 257, "seek": 161008, "start": 1618.3999999999999, "end": 1626.52, "text": " in our case, you know, is more to, to understand, because in, in fact, inside the, the, the software", "tokens": [294, 527, 1389, 11, 291, 458, 11, 307, 544, 281, 11, 281, 1223, 11, 570, 294, 11, 294, 1186, 11, 1854, 264, 11, 264, 11, 264, 4722], "temperature": 0.0, "avg_logprob": -0.17378074432087837, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.0009089830564334989}, {"id": 258, "seek": 161008, "start": 1626.52, "end": 1632.04, "text": " engineering community discussing this topic is still an open question, exactly how to", "tokens": [7043, 1768, 10850, 341, 4829, 307, 920, 364, 1269, 1168, 11, 2293, 577, 281], "temperature": 0.0, "avg_logprob": -0.17378074432087837, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.0009089830564334989}, {"id": 259, "seek": 161008, "start": 1632.04, "end": 1633.04, "text": " do it.", "tokens": [360, 309, 13], "temperature": 0.0, "avg_logprob": -0.17378074432087837, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.0009089830564334989}, {"id": 260, "seek": 161008, "start": 1633.04, "end": 1637.8799999999999, "text": " And when we, we search about this topic, it's quite difficult to find tutorials or someone", "tokens": [400, 562, 321, 11, 321, 3164, 466, 341, 4829, 11, 309, 311, 1596, 2252, 281, 915, 17616, 420, 1580], "temperature": 0.0, "avg_logprob": -0.17378074432087837, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.0009089830564334989}, {"id": 261, "seek": 163788, "start": 1637.88, "end": 1643.7600000000002, "text": " teaching you how to, what kind of permanent indentifier you should use.", "tokens": [4571, 291, 577, 281, 11, 437, 733, 295, 10996, 44494, 9902, 291, 820, 764, 13], "temperature": 0.0, "avg_logprob": -0.22529103539206766, "compression_ratio": 1.7, "no_speech_prob": 0.001595790614373982}, {"id": 262, "seek": 163788, "start": 1643.7600000000002, "end": 1650.3200000000002, "text": " For example, software heritage ID, for example, here is an example of the type of persistent", "tokens": [1171, 1365, 11, 4722, 16040, 7348, 11, 337, 1365, 11, 510, 307, 364, 1365, 295, 264, 2010, 295, 24315], "temperature": 0.0, "avg_logprob": -0.22529103539206766, "compression_ratio": 1.7, "no_speech_prob": 0.001595790614373982}, {"id": 263, "seek": 163788, "start": 1650.3200000000002, "end": 1656.0400000000002, "text": " indentifier that name it as intrinsic persistent indentifier.", "tokens": [44494, 9902, 300, 1315, 309, 382, 35698, 24315, 44494, 9902, 13], "temperature": 0.0, "avg_logprob": -0.22529103539206766, "compression_ratio": 1.7, "no_speech_prob": 0.001595790614373982}, {"id": 264, "seek": 163788, "start": 1656.0400000000002, "end": 1662.5600000000002, "text": " What means it doesn't, doesn't depend on, on, on a service registry where you need to", "tokens": [708, 1355, 309, 1177, 380, 11, 1177, 380, 5672, 322, 11, 322, 11, 322, 257, 2643, 36468, 689, 291, 643, 281], "temperature": 0.0, "avg_logprob": -0.22529103539206766, "compression_ratio": 1.7, "no_speech_prob": 0.001595790614373982}, {"id": 265, "seek": 163788, "start": 1662.5600000000002, "end": 1665.5200000000002, "text": " ask a new ID to, to use it.", "tokens": [1029, 257, 777, 7348, 281, 11, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.22529103539206766, "compression_ratio": 1.7, "no_speech_prob": 0.001595790614373982}, {"id": 266, "seek": 166552, "start": 1665.52, "end": 1673.52, "text": " It's like a hash, a hash ID of a commit is this kind of a intrinsic persistent indentifier", "tokens": [467, 311, 411, 257, 22019, 11, 257, 22019, 7348, 295, 257, 5599, 307, 341, 733, 295, 257, 35698, 24315, 44494, 9902], "temperature": 0.0, "avg_logprob": -0.18187457190619574, "compression_ratio": 1.6377551020408163, "no_speech_prob": 0.0013506143586710095}, {"id": 267, "seek": 166552, "start": 1673.52, "end": 1677.44, "text": " that we can generate by the source code itself.", "tokens": [300, 321, 393, 8460, 538, 264, 4009, 3089, 2564, 13], "temperature": 0.0, "avg_logprob": -0.18187457190619574, "compression_ratio": 1.6377551020408163, "no_speech_prob": 0.0013506143586710095}, {"id": 268, "seek": 166552, "start": 1677.44, "end": 1683.24, "text": " Another option is to use maybe Zenodo or maybe any other thing to generate a DOI.", "tokens": [3996, 3614, 307, 281, 764, 1310, 22387, 17423, 420, 1310, 604, 661, 551, 281, 8460, 257, 10699, 40, 13], "temperature": 0.0, "avg_logprob": -0.18187457190619574, "compression_ratio": 1.6377551020408163, "no_speech_prob": 0.0013506143586710095}, {"id": 269, "seek": 166552, "start": 1683.24, "end": 1688.76, "text": " Then for that, we are, we are going to ask to the registry, the DOI server to generate", "tokens": [1396, 337, 300, 11, 321, 366, 11, 321, 366, 516, 281, 1029, 281, 264, 36468, 11, 264, 10699, 40, 7154, 281, 8460], "temperature": 0.0, "avg_logprob": -0.18187457190619574, "compression_ratio": 1.6377551020408163, "no_speech_prob": 0.0013506143586710095}, {"id": 270, "seek": 166552, "start": 1688.76, "end": 1690.44, "text": " a DOI for us.", "tokens": [257, 10699, 40, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.18187457190619574, "compression_ratio": 1.6377551020408163, "no_speech_prob": 0.0013506143586710095}, {"id": 271, "seek": 169044, "start": 1690.44, "end": 1698.72, "text": " And we have many options, we don't know yet deep and maybe Zenodo could be really interesting.", "tokens": [400, 321, 362, 867, 3956, 11, 321, 500, 380, 458, 1939, 2452, 293, 1310, 22387, 17423, 727, 312, 534, 1880, 13], "temperature": 0.0, "avg_logprob": -0.25065397394114525, "compression_ratio": 1.3986013986013985, "no_speech_prob": 0.002455997047945857}, {"id": 272, "seek": 169044, "start": 1698.72, "end": 1706.0, "text": " I would be happy to, to learn with you, your experience because it's a lot of things to,", "tokens": [286, 576, 312, 2055, 281, 11, 281, 1466, 365, 291, 11, 428, 1752, 570, 309, 311, 257, 688, 295, 721, 281, 11], "temperature": 0.0, "avg_logprob": -0.25065397394114525, "compression_ratio": 1.3986013986013985, "no_speech_prob": 0.002455997047945857}, {"id": 273, "seek": 169044, "start": 1706.0, "end": 1707.0, "text": " to learn.", "tokens": [281, 1466, 13], "temperature": 0.0, "avg_logprob": -0.25065397394114525, "compression_ratio": 1.3986013986013985, "no_speech_prob": 0.002455997047945857}, {"id": 274, "seek": 169044, "start": 1707.0, "end": 1708.0, "text": " Sorry.", "tokens": [4919, 13], "temperature": 0.0, "avg_logprob": -0.25065397394114525, "compression_ratio": 1.3986013986013985, "no_speech_prob": 0.002455997047945857}, {"id": 275, "seek": 170800, "start": 1708.0, "end": 1721.2, "text": " Okay, thanks for coming back to stop here.", "tokens": [1033, 11, 3231, 337, 1348, 646, 281, 1590, 510, 13], "temperature": 0.0, "avg_logprob": -0.9159677369253976, "compression_ratio": 0.84, "no_speech_prob": 0.012588603422045708}], "language": "en"}