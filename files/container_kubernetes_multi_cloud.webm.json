{"text": " Okay. Okay. I am Marco Mancini. I am a social architect in Open Nebula System. Open Nebula System is, okay. Open Nebula System is the company behind Open Nebula, the open source software. So today, I will talk about how you can easily deploy Kubernetes clusters on hybrid and multi-cloud environments by using our open source solution. So let me introduce Open Nebula. Open Nebula was born around 14 years ago as a solution for private cloud computing, you know, for on-premises. And evolved during the last years, and now we provide a solution that allows you to manage different types of workloads. So going from virtual machines to application containers to Kubernetes clusters along what we call today, you know, the data-sender cloud edge continuum. So you can have resources on on-premises, you can have resources on public or on far edge and so on. So what we would like to do with this open source solution, no? Open Nebula is to provide you with a simple way in order to manage different type of workloads along the, let's say, this cloud edge continuum. And so you can minimize the complexity, you know, to manage these workloads. You reduce no consumption of resources because you can manage different types across different kind of resources and so on. So mainly what we, at the core of Open Nebula, we use different virtualization technologies. So we go from supporting using VMware, KVM for virtual machine workloads, to LXC for system containers, to Firecracker, where you can manage micro-VMs and deploy container-based applications. And we manage these technologies by using clearly advanced features, no? You can have multi-tenancy, self-service, no? You can provide resources on these different virtualization technologies and so on. We have a graphical user interface where you can manage all your resources across the, as I said, this continuum and also we have integrated different third-party tools, no? Going from Terraform to Ansible to Kubernetes and so on. So our vision about the multi-cloud is that we can, no, we would like to provide an easy way for automatic provisioning of resources, no? Across multiple cloud providers. That's the moment. So what we have built is a tool that is called the One Provision. So you can see in the bottom, so we have also a graphical user interface, but it's also a command line interface. So you can create resources on different providers. At the moment, we support providers that has bare-metal servers like AWS and Equinix. But, yeah, we can support other providers. We just need to write some drivers, no? That allow us to provide resources also across different providers. Behind the One Provision tool, we use open-source tools like Terraform and Ansible. So with this tool, with this One Provision tool, we can build so different what we call edge clusters. So an edge cluster for Openable is an abstraction where you have computing, you have storage and networking. So once you provide this edge cluster, every cluster, whenever it's provisioning, can be managed by our uniform, just from one managing place that is our Sunstone graphical user interface or with our command line interface. And so from one just panel, you can manage all your clusters across different, for example, providers or your premise resources. And then at the end, what we have is the concept of marketplace. So whether you can have appliances or you can have, we have also integrated Docker app. So you can have also Docker images that you can deploy. So you can deploy virtual machine, multi-virtual machine, containers, and Kubernetes clusters across these different resources that we have provisioned. So this is how we manage, let's say, multi-cloud environment. So by using this One Provision tool and then our graphical user interface and the marketplace. So let me introduce also how we have built Kubernetes, how Kubernetes is integrated in Open Nebula. So for us, Kubernetes is just a service. So we have built an appliance. I will talk soon about how we have built this appliance. So as I said, you can manage Kubernetes by using our tool for managing any application, right? And then you can deploy on different edge clusters, right? So you can exploit all the features that we have. So since we have a multi-tenants environment, you can deploy Kubernetes clusters for all your tenant within Open Nebula. So you want to deploy Kubernetes clusters on the same physical resources that are shared. They will be deployed in a secure way because you can deploy by using our visualization technologies and so on. And also you are not looking to any vendor because you can just deploy your Kubernetes clusters on any, let's say, cloud edge or premise or far edge provider that you would like to integrate within your infrastructure and the price infrastructure. So how we have built Kubernetes, integrated Kubernetes in Open Nebula is we have defined an appliance. It's called one key. This is just a complete Kubernetes deployment. So it's based on RQ2 and we use the version 1.24 of Kubernetes. So we provide all the features. So when you deploy this appliance, you have all the features included. So you don't have to deal with managing deployment of a storage solution or ingress controllers or load balancing. At the moment, we have used these technologies on our roadmap. There are some features that we would like to include, especially a better integration with some of the features that has Open Nebula. But at the moment, yeah, we have this kind of solution that is based on, as I said, on RQ2. The one key appliance, these are the components. It's based on one flow. One flow is a component in Open Nebula that allow you to define multi VMs applications. So in a one flow service, you can have different roles. And each role, for example, in this case, for the Kubernetes appliance, we have defined different roles. For example, we use the VNF role. This is the load balancer for the control plane. But it also does NAT and routing because we have two networks within our appliance. One is the public network and another is the private network between the different components. So this VNF also allows for the different VMs within the private network to communicate outside to the public. Then we have the master role. His role is to manage the control plane, the ATC database, the API, and so on. Then we have the worker nodes that you can use for any workloads that you want to deploy on your Kubernetes cluster. And then finally, we have the storage nodes. These are dedicated so they will not be used for when you have to deploy some workloads, but they are used just for your storage needs. And we use Longcore for persistent volumes within other Kubernetes, within the one case service. As I said, the VNF, this virtual network function service provides a load balancer. So you can have multiple VNF, so in an availability mode. Taking into account that OpenNebula offers you the abstraction of virtual machine groups. So usually for having an availability solution, if you have a virtual machine, you would like to deploy your virtual machine on different hosts in order to have an available solution. So you can use OpenNebula VM groups and then using some affinity rules, your VMs will be deployed for example on different hosts so you can have an available solution. And this is valid for any role that you have seen before. So for any role, you can use these VM groups in order to have also available solution. So one key by default, just create one VM for each role, but you can modify and scale the solution. So having multiple VMs for each role. So this is the VM. As I said, for the persistent volumes, we have this storage nodes where we deploy a Longcore, we use Longcore. So you can have replicas of your volumes on different VMs related to the storage nodes. Then we have, in order to access your services, we need that you deploy within your Kubernetes clusters. You can have the ingress controller you can use. We deploy an ingress controller based on traffic. So this can be used for HTTP and HTTPS protocol. And then you can access the service by just defining an ingress controller for your service. And then we have integrated also Metal LB, instead for the load balancer service. So in this case, you can use this for other kind of protocols that are not HTTP or HTTP based. Yeah, I would like to go because, yeah, it's almost, I have five minutes now, more or less. I will prepare just a demo to show you how you can use Open Nebula. So I will show you how to use one provision in order to provide resources on AWS and Equinix. And then we can deploy a Kubernetes cluster on both edge clusters that on this two public cloud provider. And then we just, you can just access one of the Kubernetes clusters and just deploy an application. Let's me go on the demo. Okay, so this is the Sunstone Graphica user interface that you can see here. If we go to clusters, we have just the default cluster. But there are no host, no data, there are only data store, there are no host. So in this moment, we have just our front end without any resources. Now what's it go is to go to the one provision. We have defined already two providers, one for Equinix and one for AWS. And once you define these providers, you can create clusters on the two providers. So we are going to create a cluster, for example, in AWS. In this case, we have defined a provider for AWS in London, the zone. And this will now create an edge cluster on AWS. As I said, we use Terraform and Ansible to create resources and to compute in such a way that you create an edge cluster for OpenEbula. And then here I'm going to create another cluster instead of on Equinix. Clearly, you have some parameters. You can define the number of hosts, you can define the number of public IP that you would like to access, and so on. Okay? By the way, you can define two type of clusters with one provision. One is an edge cluster, it's a base, or you can also create a safe cluster, an hyperconverged cluster. As you can see here, once you use one provision in a Sunstone, graphical user interface, you will see the hosts that are going to be proficient. And while it will take around five, ten minutes, this depends on the cloud provider how much time it needs to create resources. But once you have created the resources, you can see here the two clusters. What you have to do is to instantiate a couple of, to use Kubernetes appliance, we have to define a couple of private networks, one for Equinix and one for the other AWS clusters. And in order to do this, it's simplified because we create a template, then you just instantiate the template, and then you can create also the private networks, both for AWS and Equinix. Because we need the private for the internal VMs, the roles like node, master, storage, and the worker nodes, and then we need the public network instead for the VNF, that is our main endpoint where to access the Kubernetes clusters. Now what we are going to do is to import the one key appliance for our marketplace within our open Nebula. You can do this just once. So we are going to import the appliance. And once you import the appliance, what will be imported are templates for the VMs that are for each role, and the template for the service. This service is based on one floor, and also the images that are related to the different roles. So in order to create a new Kubernetes cluster, what we have to do is to just instantiate a service by selecting the appropriate networks, for example. So in this case, you can see now I'm creating a cluster on AWS. So I select for the public network, the AWS cluster public for the private, the AWS private, and then I just have to put a couple of IPs internal. These are for the internal networks, for the virtual IP, for the VNF, and for the gateway. And we can do the same for Equinix. So by just selecting the public networks of Equinix and then the private networks that we have defined. Also in this case, I've used the same network for both clusters. And here you see that now we are deploying the two Kubernetes clusters on the two different edge clusters that are on AWS London and Equinix. As you see, the first role that is deployed is VNF. Once the VNF is ready running, in one floor, you can define dependencies. And once the VNF is ready, one floor is going to deploy the other roles, master, the worker, and the storage node. In order to access the Kubernetes clusters, you have to use the public IP of the VNF. And you can use SSH agent forwarding by using, you know, first connecting to the VNF and then connecting to the master by using the private IP. Okay. Here we can see the nodes. So we can have, as I said, by default, you have one node for each master clear. This is not for production environment. If you want to have for production environment, you need to scale each node, for example. So here, I just create an image and I prepared also a YAML file, a manifest file for exposing the service through the ingress controller. And then you can use the public IP of the VNF to access the service. Okay. Clearly OpenEBOLA is not, doesn't have any tools for managing the deployment of application on Kubernetes. So we manage the infrastructure and the deployment of Kubernetes cluster. Then you can use kubectl, you can use Ranger, you can use other open source tooling, you know, that maybe in the future we can add also. As you can see here, by using the public IP of the VNF, I have access to the engine mix. Another thing, you can scale the roles once you deploy, for example. In this case, I can scale, for example, the worker. You just put the number here. We use the one flow, one flow allows us to scale the cluster for each role. Okay. And now you can see another worker is going to be deployed. Yeah, this was the demo and I think that's the conclusion. Okay. Thank you. Thank you all. Okay.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.68, "text": " Okay. Okay. I am Marco Mancini. I am a social architect in Open Nebula System. Open Nebula", "tokens": [1033, 13, 1033, 13, 286, 669, 26535, 2458, 66, 3812, 13, 286, 669, 257, 2093, 6331, 294, 7238, 1734, 37775, 8910, 13, 7238, 1734, 37775], "temperature": 0.0, "avg_logprob": -0.32499932551729505, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.41669607162475586}, {"id": 1, "seek": 0, "start": 12.68, "end": 19.72, "text": " System is, okay. Open Nebula System is the company behind Open Nebula, the open source", "tokens": [8910, 307, 11, 1392, 13, 7238, 1734, 37775, 8910, 307, 264, 2237, 2261, 7238, 1734, 37775, 11, 264, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.32499932551729505, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.41669607162475586}, {"id": 2, "seek": 0, "start": 19.72, "end": 27.64, "text": " software. So today, I will talk about how you can easily deploy Kubernetes clusters", "tokens": [4722, 13, 407, 965, 11, 286, 486, 751, 466, 577, 291, 393, 3612, 7274, 23145, 23313], "temperature": 0.0, "avg_logprob": -0.32499932551729505, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.41669607162475586}, {"id": 3, "seek": 2764, "start": 27.64, "end": 35.4, "text": " on hybrid and multi-cloud environments by using our open source solution. So let me", "tokens": [322, 13051, 293, 4825, 12, 44495, 12388, 538, 1228, 527, 1269, 4009, 3827, 13, 407, 718, 385], "temperature": 0.0, "avg_logprob": -0.20493303026471818, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0002043923595920205}, {"id": 4, "seek": 2764, "start": 35.4, "end": 42.88, "text": " introduce Open Nebula. Open Nebula was born around 14 years ago as a solution for private", "tokens": [5366, 7238, 1734, 37775, 13, 7238, 1734, 37775, 390, 4232, 926, 3499, 924, 2057, 382, 257, 3827, 337, 4551], "temperature": 0.0, "avg_logprob": -0.20493303026471818, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0002043923595920205}, {"id": 5, "seek": 2764, "start": 42.88, "end": 48.760000000000005, "text": " cloud computing, you know, for on-premises. And evolved during the last years, and now", "tokens": [4588, 15866, 11, 291, 458, 11, 337, 322, 12, 29403, 3598, 13, 400, 14178, 1830, 264, 1036, 924, 11, 293, 586], "temperature": 0.0, "avg_logprob": -0.20493303026471818, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0002043923595920205}, {"id": 6, "seek": 2764, "start": 48.760000000000005, "end": 57.480000000000004, "text": " we provide a solution that allows you to manage different types of workloads. So going from", "tokens": [321, 2893, 257, 3827, 300, 4045, 291, 281, 3067, 819, 3467, 295, 32452, 13, 407, 516, 490], "temperature": 0.0, "avg_logprob": -0.20493303026471818, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0002043923595920205}, {"id": 7, "seek": 5748, "start": 57.48, "end": 62.519999999999996, "text": " virtual machines to application containers to Kubernetes clusters along what we call", "tokens": [6374, 8379, 281, 3861, 17089, 281, 23145, 23313, 2051, 437, 321, 818], "temperature": 0.0, "avg_logprob": -0.2077219673756803, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0011765954550355673}, {"id": 8, "seek": 5748, "start": 62.519999999999996, "end": 68.92, "text": " today, you know, the data-sender cloud edge continuum. So you can have resources on on-premises,", "tokens": [965, 11, 291, 458, 11, 264, 1412, 12, 82, 3216, 4588, 4691, 36120, 13, 407, 291, 393, 362, 3593, 322, 322, 12, 29403, 3598, 11], "temperature": 0.0, "avg_logprob": -0.2077219673756803, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0011765954550355673}, {"id": 9, "seek": 5748, "start": 68.92, "end": 75.96, "text": " you can have resources on public or on far edge and so on. So what we would like to do", "tokens": [291, 393, 362, 3593, 322, 1908, 420, 322, 1400, 4691, 293, 370, 322, 13, 407, 437, 321, 576, 411, 281, 360], "temperature": 0.0, "avg_logprob": -0.2077219673756803, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0011765954550355673}, {"id": 10, "seek": 5748, "start": 75.96, "end": 83.12, "text": " with this open source solution, no? Open Nebula is to provide you with a simple way in order", "tokens": [365, 341, 1269, 4009, 3827, 11, 572, 30, 7238, 1734, 37775, 307, 281, 2893, 291, 365, 257, 2199, 636, 294, 1668], "temperature": 0.0, "avg_logprob": -0.2077219673756803, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0011765954550355673}, {"id": 11, "seek": 8312, "start": 83.12, "end": 90.08, "text": " to manage different type of workloads along the, let's say, this cloud edge continuum.", "tokens": [281, 3067, 819, 2010, 295, 32452, 2051, 264, 11, 718, 311, 584, 11, 341, 4588, 4691, 36120, 13], "temperature": 0.0, "avg_logprob": -0.16924798047101056, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.0012322048423811793}, {"id": 12, "seek": 8312, "start": 90.08, "end": 96.60000000000001, "text": " And so you can minimize the complexity, you know, to manage these workloads. You reduce", "tokens": [400, 370, 291, 393, 17522, 264, 14024, 11, 291, 458, 11, 281, 3067, 613, 32452, 13, 509, 5407], "temperature": 0.0, "avg_logprob": -0.16924798047101056, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.0012322048423811793}, {"id": 13, "seek": 8312, "start": 96.60000000000001, "end": 102.44, "text": " no consumption of resources because you can manage different types across different kind", "tokens": [572, 12126, 295, 3593, 570, 291, 393, 3067, 819, 3467, 2108, 819, 733], "temperature": 0.0, "avg_logprob": -0.16924798047101056, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.0012322048423811793}, {"id": 14, "seek": 8312, "start": 102.44, "end": 111.68, "text": " of resources and so on. So mainly what we, at the core of Open Nebula, we use different", "tokens": [295, 3593, 293, 370, 322, 13, 407, 8704, 437, 321, 11, 412, 264, 4965, 295, 7238, 1734, 37775, 11, 321, 764, 819], "temperature": 0.0, "avg_logprob": -0.16924798047101056, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.0012322048423811793}, {"id": 15, "seek": 11168, "start": 111.68, "end": 120.12, "text": " virtualization technologies. So we go from supporting using VMware, KVM for virtual machine", "tokens": [6374, 2144, 7943, 13, 407, 321, 352, 490, 7231, 1228, 40146, 11, 591, 53, 44, 337, 6374, 3479], "temperature": 0.0, "avg_logprob": -0.1928500384092331, "compression_ratio": 1.4361702127659575, "no_speech_prob": 0.00030953550594858825}, {"id": 16, "seek": 11168, "start": 120.12, "end": 129.20000000000002, "text": " workloads, to LXC for system containers, to Firecracker, where you can manage micro-VMs", "tokens": [32452, 11, 281, 441, 55, 34, 337, 1185, 17089, 11, 281, 7652, 10757, 23599, 11, 689, 291, 393, 3067, 4532, 12, 53, 26386], "temperature": 0.0, "avg_logprob": -0.1928500384092331, "compression_ratio": 1.4361702127659575, "no_speech_prob": 0.00030953550594858825}, {"id": 17, "seek": 11168, "start": 129.20000000000002, "end": 139.0, "text": " and deploy container-based applications. And we manage these technologies by using clearly", "tokens": [293, 7274, 10129, 12, 6032, 5821, 13, 400, 321, 3067, 613, 7943, 538, 1228, 4448], "temperature": 0.0, "avg_logprob": -0.1928500384092331, "compression_ratio": 1.4361702127659575, "no_speech_prob": 0.00030953550594858825}, {"id": 18, "seek": 13900, "start": 139.0, "end": 145.48, "text": " advanced features, no? You can have multi-tenancy, self-service, no? You can provide resources", "tokens": [7339, 4122, 11, 572, 30, 509, 393, 362, 4825, 12, 1147, 6717, 11, 2698, 12, 39279, 11, 572, 30, 509, 393, 2893, 3593], "temperature": 0.0, "avg_logprob": -0.18813258203966865, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0002652490802574903}, {"id": 19, "seek": 13900, "start": 145.48, "end": 153.64, "text": " on these different virtualization technologies and so on. We have a graphical user interface", "tokens": [322, 613, 819, 6374, 2144, 7943, 293, 370, 322, 13, 492, 362, 257, 35942, 4195, 9226], "temperature": 0.0, "avg_logprob": -0.18813258203966865, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0002652490802574903}, {"id": 20, "seek": 13900, "start": 153.64, "end": 161.48, "text": " where you can manage all your resources across the, as I said, this continuum and also we", "tokens": [689, 291, 393, 3067, 439, 428, 3593, 2108, 264, 11, 382, 286, 848, 11, 341, 36120, 293, 611, 321], "temperature": 0.0, "avg_logprob": -0.18813258203966865, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0002652490802574903}, {"id": 21, "seek": 13900, "start": 161.48, "end": 168.04, "text": " have integrated different third-party tools, no? Going from Terraform to Ansible to Kubernetes", "tokens": [362, 10919, 819, 2636, 12, 23409, 3873, 11, 572, 30, 10963, 490, 25366, 837, 281, 14590, 964, 281, 23145], "temperature": 0.0, "avg_logprob": -0.18813258203966865, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0002652490802574903}, {"id": 22, "seek": 16804, "start": 168.04, "end": 179.6, "text": " and so on. So our vision about the multi-cloud is that we can, no, we would like to provide", "tokens": [293, 370, 322, 13, 407, 527, 5201, 466, 264, 4825, 12, 44495, 307, 300, 321, 393, 11, 572, 11, 321, 576, 411, 281, 2893], "temperature": 0.0, "avg_logprob": -0.15634644416070753, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00040932773845270276}, {"id": 23, "seek": 16804, "start": 179.6, "end": 186.88, "text": " an easy way for automatic provisioning of resources, no? Across multiple cloud providers.", "tokens": [364, 1858, 636, 337, 12509, 17225, 278, 295, 3593, 11, 572, 30, 34527, 3866, 4588, 11330, 13], "temperature": 0.0, "avg_logprob": -0.15634644416070753, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00040932773845270276}, {"id": 24, "seek": 16804, "start": 186.88, "end": 192.64, "text": " That's the moment. So what we have built is a tool that is called the One Provision.", "tokens": [663, 311, 264, 1623, 13, 407, 437, 321, 362, 3094, 307, 257, 2290, 300, 307, 1219, 264, 1485, 1705, 6763, 13], "temperature": 0.0, "avg_logprob": -0.15634644416070753, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00040932773845270276}, {"id": 25, "seek": 16804, "start": 192.64, "end": 197.32, "text": " So you can see in the bottom, so we have also a graphical user interface, but it's also", "tokens": [407, 291, 393, 536, 294, 264, 2767, 11, 370, 321, 362, 611, 257, 35942, 4195, 9226, 11, 457, 309, 311, 611], "temperature": 0.0, "avg_logprob": -0.15634644416070753, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00040932773845270276}, {"id": 26, "seek": 19732, "start": 197.32, "end": 202.79999999999998, "text": " a command line interface. So you can create resources on different providers. At the moment,", "tokens": [257, 5622, 1622, 9226, 13, 407, 291, 393, 1884, 3593, 322, 819, 11330, 13, 1711, 264, 1623, 11], "temperature": 0.0, "avg_logprob": -0.17411251629100127, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.0004327051865402609}, {"id": 27, "seek": 19732, "start": 202.79999999999998, "end": 213.79999999999998, "text": " we support providers that has bare-metal servers like AWS and Equinix. But, yeah, we can support", "tokens": [321, 1406, 11330, 300, 575, 6949, 12, 39857, 15909, 411, 17650, 293, 15624, 259, 970, 13, 583, 11, 1338, 11, 321, 393, 1406], "temperature": 0.0, "avg_logprob": -0.17411251629100127, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.0004327051865402609}, {"id": 28, "seek": 19732, "start": 213.79999999999998, "end": 220.92, "text": " other providers. We just need to write some drivers, no? That allow us to provide resources", "tokens": [661, 11330, 13, 492, 445, 643, 281, 2464, 512, 11590, 11, 572, 30, 663, 2089, 505, 281, 2893, 3593], "temperature": 0.0, "avg_logprob": -0.17411251629100127, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.0004327051865402609}, {"id": 29, "seek": 22092, "start": 220.92, "end": 227.35999999999999, "text": " also across different providers. Behind the One Provision tool, we use open-source tools", "tokens": [611, 2108, 819, 11330, 13, 20475, 264, 1485, 1705, 6763, 2290, 11, 321, 764, 1269, 12, 41676, 3873], "temperature": 0.0, "avg_logprob": -0.19502345814424402, "compression_ratio": 1.7047619047619047, "no_speech_prob": 0.00019828714721370488}, {"id": 30, "seek": 22092, "start": 227.35999999999999, "end": 234.39999999999998, "text": " like Terraform and Ansible. So with this tool, with this One Provision tool, we can build", "tokens": [411, 25366, 837, 293, 14590, 964, 13, 407, 365, 341, 2290, 11, 365, 341, 1485, 1705, 6763, 2290, 11, 321, 393, 1322], "temperature": 0.0, "avg_logprob": -0.19502345814424402, "compression_ratio": 1.7047619047619047, "no_speech_prob": 0.00019828714721370488}, {"id": 31, "seek": 22092, "start": 234.39999999999998, "end": 240.64, "text": " so different what we call edge clusters. So an edge cluster for Openable is an abstraction", "tokens": [370, 819, 437, 321, 818, 4691, 23313, 13, 407, 364, 4691, 13630, 337, 7238, 712, 307, 364, 37765], "temperature": 0.0, "avg_logprob": -0.19502345814424402, "compression_ratio": 1.7047619047619047, "no_speech_prob": 0.00019828714721370488}, {"id": 32, "seek": 22092, "start": 240.64, "end": 247.56, "text": " where you have computing, you have storage and networking. So once you provide this edge", "tokens": [689, 291, 362, 15866, 11, 291, 362, 6725, 293, 17985, 13, 407, 1564, 291, 2893, 341, 4691], "temperature": 0.0, "avg_logprob": -0.19502345814424402, "compression_ratio": 1.7047619047619047, "no_speech_prob": 0.00019828714721370488}, {"id": 33, "seek": 24756, "start": 247.56, "end": 258.48, "text": " cluster, every cluster, whenever it's provisioning, can be managed by our uniform, just from one", "tokens": [13630, 11, 633, 13630, 11, 5699, 309, 311, 17225, 278, 11, 393, 312, 6453, 538, 527, 9452, 11, 445, 490, 472], "temperature": 0.0, "avg_logprob": -0.24097188802865835, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.0004701878351625055}, {"id": 34, "seek": 24756, "start": 258.48, "end": 266.64, "text": " managing place that is our Sunstone graphical user interface or with our command line interface.", "tokens": [11642, 1081, 300, 307, 527, 6163, 11243, 35942, 4195, 9226, 420, 365, 527, 5622, 1622, 9226, 13], "temperature": 0.0, "avg_logprob": -0.24097188802865835, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.0004701878351625055}, {"id": 35, "seek": 24756, "start": 266.64, "end": 273.2, "text": " And so from one just panel, you can manage all your clusters across different, for example,", "tokens": [400, 370, 490, 472, 445, 4831, 11, 291, 393, 3067, 439, 428, 23313, 2108, 819, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.24097188802865835, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.0004701878351625055}, {"id": 36, "seek": 27320, "start": 273.2, "end": 280.92, "text": " providers or your premise resources. And then at the end, what we have is the concept", "tokens": [11330, 420, 428, 22045, 3593, 13, 400, 550, 412, 264, 917, 11, 437, 321, 362, 307, 264, 3410], "temperature": 0.0, "avg_logprob": -0.2461315522710961, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.00042499543633311987}, {"id": 37, "seek": 27320, "start": 280.92, "end": 288.15999999999997, "text": " of marketplace. So whether you can have appliances or you can have, we have also integrated Docker", "tokens": [295, 19455, 13, 407, 1968, 291, 393, 362, 35480, 420, 291, 393, 362, 11, 321, 362, 611, 10919, 33772], "temperature": 0.0, "avg_logprob": -0.2461315522710961, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.00042499543633311987}, {"id": 38, "seek": 27320, "start": 288.15999999999997, "end": 295.24, "text": " app. So you can have also Docker images that you can deploy. So you can deploy virtual", "tokens": [724, 13, 407, 291, 393, 362, 611, 33772, 5267, 300, 291, 393, 7274, 13, 407, 291, 393, 7274, 6374], "temperature": 0.0, "avg_logprob": -0.2461315522710961, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.00042499543633311987}, {"id": 39, "seek": 27320, "start": 295.24, "end": 302.68, "text": " machine, multi-virtual machine, containers, and Kubernetes clusters across these different", "tokens": [3479, 11, 4825, 12, 85, 2498, 901, 3479, 11, 17089, 11, 293, 23145, 23313, 2108, 613, 819], "temperature": 0.0, "avg_logprob": -0.2461315522710961, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.00042499543633311987}, {"id": 40, "seek": 30268, "start": 302.68, "end": 313.2, "text": " resources that we have provisioned. So this is how we manage, let's say, multi-cloud", "tokens": [3593, 300, 321, 362, 17225, 292, 13, 407, 341, 307, 577, 321, 3067, 11, 718, 311, 584, 11, 4825, 12, 44495], "temperature": 0.0, "avg_logprob": -0.18782563363352128, "compression_ratio": 1.5144508670520231, "no_speech_prob": 0.0004775834095198661}, {"id": 41, "seek": 30268, "start": 313.2, "end": 320.0, "text": " environment. So by using this One Provision tool and then our graphical user interface", "tokens": [2823, 13, 407, 538, 1228, 341, 1485, 1705, 6763, 2290, 293, 550, 527, 35942, 4195, 9226], "temperature": 0.0, "avg_logprob": -0.18782563363352128, "compression_ratio": 1.5144508670520231, "no_speech_prob": 0.0004775834095198661}, {"id": 42, "seek": 30268, "start": 320.0, "end": 328.24, "text": " and the marketplace. So let me introduce also how we have built Kubernetes, how Kubernetes", "tokens": [293, 264, 19455, 13, 407, 718, 385, 5366, 611, 577, 321, 362, 3094, 23145, 11, 577, 23145], "temperature": 0.0, "avg_logprob": -0.18782563363352128, "compression_ratio": 1.5144508670520231, "no_speech_prob": 0.0004775834095198661}, {"id": 43, "seek": 32824, "start": 328.24, "end": 337.04, "text": " is integrated in Open Nebula. So for us, Kubernetes is just a service. So we have built an appliance.", "tokens": [307, 10919, 294, 7238, 1734, 37775, 13, 407, 337, 505, 11, 23145, 307, 445, 257, 2643, 13, 407, 321, 362, 3094, 364, 45646, 13], "temperature": 0.0, "avg_logprob": -0.190585754287075, "compression_ratio": 1.5425531914893618, "no_speech_prob": 0.00014851581363473088}, {"id": 44, "seek": 32824, "start": 337.04, "end": 345.96000000000004, "text": " I will talk soon about how we have built this appliance. So as I said, you can manage Kubernetes", "tokens": [286, 486, 751, 2321, 466, 577, 321, 362, 3094, 341, 45646, 13, 407, 382, 286, 848, 11, 291, 393, 3067, 23145], "temperature": 0.0, "avg_logprob": -0.190585754287075, "compression_ratio": 1.5425531914893618, "no_speech_prob": 0.00014851581363473088}, {"id": 45, "seek": 32824, "start": 345.96000000000004, "end": 354.96000000000004, "text": " by using our tool for managing any application, right? And then you can deploy on different", "tokens": [538, 1228, 527, 2290, 337, 11642, 604, 3861, 11, 558, 30, 400, 550, 291, 393, 7274, 322, 819], "temperature": 0.0, "avg_logprob": -0.190585754287075, "compression_ratio": 1.5425531914893618, "no_speech_prob": 0.00014851581363473088}, {"id": 46, "seek": 35496, "start": 354.96, "end": 361.91999999999996, "text": " edge clusters, right? So you can exploit all the features that we have. So since we have", "tokens": [4691, 23313, 11, 558, 30, 407, 291, 393, 25924, 439, 264, 4122, 300, 321, 362, 13, 407, 1670, 321, 362], "temperature": 0.0, "avg_logprob": -0.1724405403596809, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.00041333812987431884}, {"id": 47, "seek": 35496, "start": 361.91999999999996, "end": 368.71999999999997, "text": " a multi-tenants environment, you can deploy Kubernetes clusters for all your tenant within", "tokens": [257, 4825, 12, 1147, 1719, 2823, 11, 291, 393, 7274, 23145, 23313, 337, 439, 428, 31000, 1951], "temperature": 0.0, "avg_logprob": -0.1724405403596809, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.00041333812987431884}, {"id": 48, "seek": 35496, "start": 368.71999999999997, "end": 375.08, "text": " Open Nebula. So you want to deploy Kubernetes clusters on the same physical resources that", "tokens": [7238, 1734, 37775, 13, 407, 291, 528, 281, 7274, 23145, 23313, 322, 264, 912, 4001, 3593, 300], "temperature": 0.0, "avg_logprob": -0.1724405403596809, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.00041333812987431884}, {"id": 49, "seek": 35496, "start": 375.08, "end": 383.88, "text": " are shared. They will be deployed in a secure way because you can deploy by using our visualization", "tokens": [366, 5507, 13, 814, 486, 312, 17826, 294, 257, 7144, 636, 570, 291, 393, 7274, 538, 1228, 527, 25801], "temperature": 0.0, "avg_logprob": -0.1724405403596809, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.00041333812987431884}, {"id": 50, "seek": 38388, "start": 383.88, "end": 391.2, "text": " technologies and so on. And also you are not looking to any vendor because you can just", "tokens": [7943, 293, 370, 322, 13, 400, 611, 291, 366, 406, 1237, 281, 604, 24321, 570, 291, 393, 445], "temperature": 0.0, "avg_logprob": -0.1775078406700721, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.00010879291221499443}, {"id": 51, "seek": 38388, "start": 391.2, "end": 400.0, "text": " deploy your Kubernetes clusters on any, let's say, cloud edge or premise or far edge provider", "tokens": [7274, 428, 23145, 23313, 322, 604, 11, 718, 311, 584, 11, 4588, 4691, 420, 22045, 420, 1400, 4691, 12398], "temperature": 0.0, "avg_logprob": -0.1775078406700721, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.00010879291221499443}, {"id": 52, "seek": 38388, "start": 400.0, "end": 405.76, "text": " that you would like to integrate within your infrastructure and the price infrastructure.", "tokens": [300, 291, 576, 411, 281, 13365, 1951, 428, 6896, 293, 264, 3218, 6896, 13], "temperature": 0.0, "avg_logprob": -0.1775078406700721, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.00010879291221499443}, {"id": 53, "seek": 38388, "start": 405.76, "end": 412.24, "text": " So how we have built Kubernetes, integrated Kubernetes in Open Nebula is we have defined", "tokens": [407, 577, 321, 362, 3094, 23145, 11, 10919, 23145, 294, 7238, 1734, 37775, 307, 321, 362, 7642], "temperature": 0.0, "avg_logprob": -0.1775078406700721, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.00010879291221499443}, {"id": 54, "seek": 41224, "start": 412.24, "end": 420.52, "text": " an appliance. It's called one key. This is just a complete Kubernetes deployment. So", "tokens": [364, 45646, 13, 467, 311, 1219, 472, 2141, 13, 639, 307, 445, 257, 3566, 23145, 19317, 13, 407], "temperature": 0.0, "avg_logprob": -0.19654340744018556, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00016216524818446487}, {"id": 55, "seek": 41224, "start": 420.52, "end": 429.96000000000004, "text": " it's based on RQ2 and we use the version 1.24 of Kubernetes. So we provide all the features.", "tokens": [309, 311, 2361, 322, 497, 48, 17, 293, 321, 764, 264, 3037, 502, 13, 7911, 295, 23145, 13, 407, 321, 2893, 439, 264, 4122, 13], "temperature": 0.0, "avg_logprob": -0.19654340744018556, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00016216524818446487}, {"id": 56, "seek": 41224, "start": 429.96000000000004, "end": 436.16, "text": " So when you deploy this appliance, you have all the features included. So you don't have", "tokens": [407, 562, 291, 7274, 341, 45646, 11, 291, 362, 439, 264, 4122, 5556, 13, 407, 291, 500, 380, 362], "temperature": 0.0, "avg_logprob": -0.19654340744018556, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00016216524818446487}, {"id": 57, "seek": 43616, "start": 436.16, "end": 444.8, "text": " to deal with managing deployment of a storage solution or ingress controllers or load balancing.", "tokens": [281, 2028, 365, 11642, 19317, 295, 257, 6725, 3827, 420, 3957, 735, 26903, 420, 3677, 22495, 13], "temperature": 0.0, "avg_logprob": -0.1507548122871213, "compression_ratio": 1.65, "no_speech_prob": 0.0006118656019680202}, {"id": 58, "seek": 43616, "start": 444.8, "end": 451.56, "text": " At the moment, we have used these technologies on our roadmap. There are some features that", "tokens": [1711, 264, 1623, 11, 321, 362, 1143, 613, 7943, 322, 527, 35738, 13, 821, 366, 512, 4122, 300], "temperature": 0.0, "avg_logprob": -0.1507548122871213, "compression_ratio": 1.65, "no_speech_prob": 0.0006118656019680202}, {"id": 59, "seek": 43616, "start": 451.56, "end": 456.28000000000003, "text": " we would like to include, especially a better integration with some of the features that", "tokens": [321, 576, 411, 281, 4090, 11, 2318, 257, 1101, 10980, 365, 512, 295, 264, 4122, 300], "temperature": 0.0, "avg_logprob": -0.1507548122871213, "compression_ratio": 1.65, "no_speech_prob": 0.0006118656019680202}, {"id": 60, "seek": 43616, "start": 456.28000000000003, "end": 462.64000000000004, "text": " has Open Nebula. But at the moment, yeah, we have this kind of solution that is based", "tokens": [575, 7238, 1734, 37775, 13, 583, 412, 264, 1623, 11, 1338, 11, 321, 362, 341, 733, 295, 3827, 300, 307, 2361], "temperature": 0.0, "avg_logprob": -0.1507548122871213, "compression_ratio": 1.65, "no_speech_prob": 0.0006118656019680202}, {"id": 61, "seek": 46264, "start": 462.64, "end": 472.36, "text": " on, as I said, on RQ2. The one key appliance, these are the components. It's based on one", "tokens": [322, 11, 382, 286, 848, 11, 322, 497, 48, 17, 13, 440, 472, 2141, 45646, 11, 613, 366, 264, 6677, 13, 467, 311, 2361, 322, 472], "temperature": 0.0, "avg_logprob": -0.16909445725478134, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.00026015721959993243}, {"id": 62, "seek": 46264, "start": 472.36, "end": 480.03999999999996, "text": " flow. One flow is a component in Open Nebula that allow you to define multi VMs applications.", "tokens": [3095, 13, 1485, 3095, 307, 257, 6542, 294, 7238, 1734, 37775, 300, 2089, 291, 281, 6964, 4825, 18038, 82, 5821, 13], "temperature": 0.0, "avg_logprob": -0.16909445725478134, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.00026015721959993243}, {"id": 63, "seek": 46264, "start": 480.03999999999996, "end": 486.88, "text": " So in a one flow service, you can have different roles. And each role, for example, in this", "tokens": [407, 294, 257, 472, 3095, 2643, 11, 291, 393, 362, 819, 9604, 13, 400, 1184, 3090, 11, 337, 1365, 11, 294, 341], "temperature": 0.0, "avg_logprob": -0.16909445725478134, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.00026015721959993243}, {"id": 64, "seek": 48688, "start": 486.88, "end": 493.36, "text": " case, for the Kubernetes appliance, we have defined different roles. For example, we use", "tokens": [1389, 11, 337, 264, 23145, 45646, 11, 321, 362, 7642, 819, 9604, 13, 1171, 1365, 11, 321, 764], "temperature": 0.0, "avg_logprob": -0.19111711433134884, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.0003970533434767276}, {"id": 65, "seek": 48688, "start": 493.36, "end": 500.08, "text": " the VNF role. This is the load balancer for the control plane. But it also does NAT and", "tokens": [264, 691, 45, 37, 3090, 13, 639, 307, 264, 3677, 3119, 28347, 337, 264, 1969, 5720, 13, 583, 309, 611, 775, 14500, 293], "temperature": 0.0, "avg_logprob": -0.19111711433134884, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.0003970533434767276}, {"id": 66, "seek": 48688, "start": 500.08, "end": 505.92, "text": " routing because we have two networks within our appliance. One is the public network", "tokens": [32722, 570, 321, 362, 732, 9590, 1951, 527, 45646, 13, 1485, 307, 264, 1908, 3209], "temperature": 0.0, "avg_logprob": -0.19111711433134884, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.0003970533434767276}, {"id": 67, "seek": 48688, "start": 505.92, "end": 513.48, "text": " and another is the private network between the different components. So this VNF also", "tokens": [293, 1071, 307, 264, 4551, 3209, 1296, 264, 819, 6677, 13, 407, 341, 691, 45, 37, 611], "temperature": 0.0, "avg_logprob": -0.19111711433134884, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.0003970533434767276}, {"id": 68, "seek": 51348, "start": 513.48, "end": 522.4, "text": " allows for the different VMs within the private network to communicate outside to the public.", "tokens": [4045, 337, 264, 819, 18038, 82, 1951, 264, 4551, 3209, 281, 7890, 2380, 281, 264, 1908, 13], "temperature": 0.0, "avg_logprob": -0.1977284132544674, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0004984377883374691}, {"id": 69, "seek": 51348, "start": 522.4, "end": 532.28, "text": " Then we have the master role. His role is to manage the control plane, the ATC database,", "tokens": [1396, 321, 362, 264, 4505, 3090, 13, 2812, 3090, 307, 281, 3067, 264, 1969, 5720, 11, 264, 8872, 34, 8149, 11], "temperature": 0.0, "avg_logprob": -0.1977284132544674, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0004984377883374691}, {"id": 70, "seek": 51348, "start": 532.28, "end": 540.76, "text": " the API, and so on. Then we have the worker nodes that you can use for any workloads that", "tokens": [264, 9362, 11, 293, 370, 322, 13, 1396, 321, 362, 264, 11346, 13891, 300, 291, 393, 764, 337, 604, 32452, 300], "temperature": 0.0, "avg_logprob": -0.1977284132544674, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0004984377883374691}, {"id": 71, "seek": 54076, "start": 540.76, "end": 545.92, "text": " you want to deploy on your Kubernetes cluster. And then finally, we have the storage nodes.", "tokens": [291, 528, 281, 7274, 322, 428, 23145, 13630, 13, 400, 550, 2721, 11, 321, 362, 264, 6725, 13891, 13], "temperature": 0.0, "avg_logprob": -0.19827427974967068, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.00026088219601660967}, {"id": 72, "seek": 54076, "start": 545.92, "end": 550.52, "text": " These are dedicated so they will not be used for when you have to deploy some workloads,", "tokens": [1981, 366, 8374, 370, 436, 486, 406, 312, 1143, 337, 562, 291, 362, 281, 7274, 512, 32452, 11], "temperature": 0.0, "avg_logprob": -0.19827427974967068, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.00026088219601660967}, {"id": 73, "seek": 54076, "start": 550.52, "end": 559.24, "text": " but they are used just for your storage needs. And we use Longcore for persistent volumes", "tokens": [457, 436, 366, 1143, 445, 337, 428, 6725, 2203, 13, 400, 321, 764, 8282, 12352, 337, 24315, 22219], "temperature": 0.0, "avg_logprob": -0.19827427974967068, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.00026088219601660967}, {"id": 74, "seek": 54076, "start": 559.24, "end": 567.52, "text": " within other Kubernetes, within the one case service. As I said, the VNF, this virtual", "tokens": [1951, 661, 23145, 11, 1951, 264, 472, 1389, 2643, 13, 1018, 286, 848, 11, 264, 691, 45, 37, 11, 341, 6374], "temperature": 0.0, "avg_logprob": -0.19827427974967068, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.00026088219601660967}, {"id": 75, "seek": 56752, "start": 567.52, "end": 575.48, "text": " network function service provides a load balancer. So you can have multiple VNF, so in an availability", "tokens": [3209, 2445, 2643, 6417, 257, 3677, 3119, 28347, 13, 407, 291, 393, 362, 3866, 691, 45, 37, 11, 370, 294, 364, 17945], "temperature": 0.0, "avg_logprob": -0.25719220297677176, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.00028349587228149176}, {"id": 76, "seek": 56752, "start": 575.48, "end": 584.0, "text": " mode. Taking into account that OpenNebula offers you the abstraction of virtual machine groups.", "tokens": [4391, 13, 17837, 666, 2696, 300, 7238, 15496, 37775, 7736, 291, 264, 37765, 295, 6374, 3479, 3935, 13], "temperature": 0.0, "avg_logprob": -0.25719220297677176, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.00028349587228149176}, {"id": 77, "seek": 56752, "start": 584.0, "end": 591.28, "text": " So usually for having an availability solution, if you have a virtual machine, you would like", "tokens": [407, 2673, 337, 1419, 364, 17945, 3827, 11, 498, 291, 362, 257, 6374, 3479, 11, 291, 576, 411], "temperature": 0.0, "avg_logprob": -0.25719220297677176, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.00028349587228149176}, {"id": 78, "seek": 56752, "start": 591.28, "end": 596.88, "text": " to deploy your virtual machine on different hosts in order to have an available solution.", "tokens": [281, 7274, 428, 6374, 3479, 322, 819, 21573, 294, 1668, 281, 362, 364, 2435, 3827, 13], "temperature": 0.0, "avg_logprob": -0.25719220297677176, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.00028349587228149176}, {"id": 79, "seek": 59688, "start": 596.88, "end": 604.16, "text": " So you can use OpenNebula VM groups and then using some affinity rules, your VMs will be", "tokens": [407, 291, 393, 764, 7238, 15496, 37775, 18038, 3935, 293, 550, 1228, 512, 39703, 4474, 11, 428, 18038, 82, 486, 312], "temperature": 0.0, "avg_logprob": -0.19199791821566495, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.00020193375530652702}, {"id": 80, "seek": 59688, "start": 604.16, "end": 609.0, "text": " deployed for example on different hosts so you can have an available solution. And this", "tokens": [17826, 337, 1365, 322, 819, 21573, 370, 291, 393, 362, 364, 2435, 3827, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.19199791821566495, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.00020193375530652702}, {"id": 81, "seek": 59688, "start": 609.0, "end": 616.68, "text": " is valid for any role that you have seen before. So for any role, you can use these VM groups", "tokens": [307, 7363, 337, 604, 3090, 300, 291, 362, 1612, 949, 13, 407, 337, 604, 3090, 11, 291, 393, 764, 613, 18038, 3935], "temperature": 0.0, "avg_logprob": -0.19199791821566495, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.00020193375530652702}, {"id": 82, "seek": 59688, "start": 616.68, "end": 624.84, "text": " in order to have also available solution. So one key by default, just create one VM for", "tokens": [294, 1668, 281, 362, 611, 2435, 3827, 13, 407, 472, 2141, 538, 7576, 11, 445, 1884, 472, 18038, 337], "temperature": 0.0, "avg_logprob": -0.19199791821566495, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.00020193375530652702}, {"id": 83, "seek": 62484, "start": 624.84, "end": 632.48, "text": " each role, but you can modify and scale the solution. So having multiple VMs for each", "tokens": [1184, 3090, 11, 457, 291, 393, 16927, 293, 4373, 264, 3827, 13, 407, 1419, 3866, 18038, 82, 337, 1184], "temperature": 0.0, "avg_logprob": -0.19244371333592375, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.00013370491797104478}, {"id": 84, "seek": 62484, "start": 632.48, "end": 642.72, "text": " role. So this is the VM. As I said, for the persistent volumes, we have this storage nodes", "tokens": [3090, 13, 407, 341, 307, 264, 18038, 13, 1018, 286, 848, 11, 337, 264, 24315, 22219, 11, 321, 362, 341, 6725, 13891], "temperature": 0.0, "avg_logprob": -0.19244371333592375, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.00013370491797104478}, {"id": 85, "seek": 62484, "start": 642.72, "end": 652.2, "text": " where we deploy a Longcore, we use Longcore. So you can have replicas of your volumes on", "tokens": [689, 321, 7274, 257, 8282, 12352, 11, 321, 764, 8282, 12352, 13, 407, 291, 393, 362, 3248, 9150, 295, 428, 22219, 322], "temperature": 0.0, "avg_logprob": -0.19244371333592375, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.00013370491797104478}, {"id": 86, "seek": 65220, "start": 652.2, "end": 661.5200000000001, "text": " different VMs related to the storage nodes. Then we have, in order to access your services,", "tokens": [819, 18038, 82, 4077, 281, 264, 6725, 13891, 13, 1396, 321, 362, 11, 294, 1668, 281, 2105, 428, 3328, 11], "temperature": 0.0, "avg_logprob": -0.16801660910420035, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.00020948206656612456}, {"id": 87, "seek": 65220, "start": 661.5200000000001, "end": 667.8000000000001, "text": " we need that you deploy within your Kubernetes clusters. You can have the ingress controller", "tokens": [321, 643, 300, 291, 7274, 1951, 428, 23145, 23313, 13, 509, 393, 362, 264, 3957, 735, 10561], "temperature": 0.0, "avg_logprob": -0.16801660910420035, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.00020948206656612456}, {"id": 88, "seek": 65220, "start": 667.8000000000001, "end": 674.0400000000001, "text": " you can use. We deploy an ingress controller based on traffic. So this can be used for", "tokens": [291, 393, 764, 13, 492, 7274, 364, 3957, 735, 10561, 2361, 322, 6419, 13, 407, 341, 393, 312, 1143, 337], "temperature": 0.0, "avg_logprob": -0.16801660910420035, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.00020948206656612456}, {"id": 89, "seek": 65220, "start": 674.0400000000001, "end": 681.88, "text": " HTTP and HTTPS protocol. And then you can access the service by just defining an ingress", "tokens": [33283, 293, 11751, 51, 6273, 10336, 13, 400, 550, 291, 393, 2105, 264, 2643, 538, 445, 17827, 364, 3957, 735], "temperature": 0.0, "avg_logprob": -0.16801660910420035, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.00020948206656612456}, {"id": 90, "seek": 68188, "start": 681.88, "end": 687.92, "text": " controller for your service. And then we have integrated also Metal LB, instead for the", "tokens": [10561, 337, 428, 2643, 13, 400, 550, 321, 362, 10919, 611, 23488, 441, 33, 11, 2602, 337, 264], "temperature": 0.0, "avg_logprob": -0.23417085759779988, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.0009181316709145904}, {"id": 91, "seek": 68188, "start": 687.92, "end": 695.48, "text": " load balancer service. So in this case, you can use this for other kind of protocols", "tokens": [3677, 3119, 28347, 2643, 13, 407, 294, 341, 1389, 11, 291, 393, 764, 341, 337, 661, 733, 295, 20618], "temperature": 0.0, "avg_logprob": -0.23417085759779988, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.0009181316709145904}, {"id": 92, "seek": 68188, "start": 695.48, "end": 703.28, "text": " that are not HTTP or HTTP based. Yeah, I would like to go because, yeah, it's almost,", "tokens": [300, 366, 406, 33283, 420, 33283, 2361, 13, 865, 11, 286, 576, 411, 281, 352, 570, 11, 1338, 11, 309, 311, 1920, 11], "temperature": 0.0, "avg_logprob": -0.23417085759779988, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.0009181316709145904}, {"id": 93, "seek": 70328, "start": 703.28, "end": 713.64, "text": " I have five minutes now, more or less. I will prepare just a demo to show you how you can", "tokens": [286, 362, 1732, 2077, 586, 11, 544, 420, 1570, 13, 286, 486, 5940, 445, 257, 10723, 281, 855, 291, 577, 291, 393], "temperature": 0.0, "avg_logprob": -0.20273204471753992, "compression_ratio": 1.4696132596685083, "no_speech_prob": 0.0002572321391198784}, {"id": 94, "seek": 70328, "start": 713.64, "end": 722.0799999999999, "text": " use Open Nebula. So I will show you how to use one provision in order to provide resources", "tokens": [764, 7238, 1734, 37775, 13, 407, 286, 486, 855, 291, 577, 281, 764, 472, 17225, 294, 1668, 281, 2893, 3593], "temperature": 0.0, "avg_logprob": -0.20273204471753992, "compression_ratio": 1.4696132596685083, "no_speech_prob": 0.0002572321391198784}, {"id": 95, "seek": 70328, "start": 722.0799999999999, "end": 728.56, "text": " on AWS and Equinix. And then we can deploy a Kubernetes cluster on both edge clusters", "tokens": [322, 17650, 293, 15624, 259, 970, 13, 400, 550, 321, 393, 7274, 257, 23145, 13630, 322, 1293, 4691, 23313], "temperature": 0.0, "avg_logprob": -0.20273204471753992, "compression_ratio": 1.4696132596685083, "no_speech_prob": 0.0002572321391198784}, {"id": 96, "seek": 72856, "start": 728.56, "end": 737.0, "text": " that on this two public cloud provider. And then we just, you can just access one of the", "tokens": [300, 322, 341, 732, 1908, 4588, 12398, 13, 400, 550, 321, 445, 11, 291, 393, 445, 2105, 472, 295, 264], "temperature": 0.0, "avg_logprob": -0.27976946208788, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.00027365965070202947}, {"id": 97, "seek": 72856, "start": 737.0, "end": 748.1199999999999, "text": " Kubernetes clusters and just deploy an application. Let's me go on the demo. Okay, so this is", "tokens": [23145, 23313, 293, 445, 7274, 364, 3861, 13, 961, 311, 385, 352, 322, 264, 10723, 13, 1033, 11, 370, 341, 307], "temperature": 0.0, "avg_logprob": -0.27976946208788, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.00027365965070202947}, {"id": 98, "seek": 72856, "start": 748.1199999999999, "end": 752.52, "text": " the Sunstone Graphica user interface that you can see here. If we go to clusters, we", "tokens": [264, 6163, 11243, 21884, 2262, 4195, 9226, 300, 291, 393, 536, 510, 13, 759, 321, 352, 281, 23313, 11, 321], "temperature": 0.0, "avg_logprob": -0.27976946208788, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.00027365965070202947}, {"id": 99, "seek": 72856, "start": 752.52, "end": 758.1199999999999, "text": " have just the default cluster. But there are no host, no data, there are only data store,", "tokens": [362, 445, 264, 7576, 13630, 13, 583, 456, 366, 572, 3975, 11, 572, 1412, 11, 456, 366, 787, 1412, 3531, 11], "temperature": 0.0, "avg_logprob": -0.27976946208788, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.00027365965070202947}, {"id": 100, "seek": 75812, "start": 758.12, "end": 763.6, "text": " there are no host. So in this moment, we have just our front end without any resources.", "tokens": [456, 366, 572, 3975, 13, 407, 294, 341, 1623, 11, 321, 362, 445, 527, 1868, 917, 1553, 604, 3593, 13], "temperature": 0.0, "avg_logprob": -0.15105574758429277, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.00029114747303538024}, {"id": 101, "seek": 75812, "start": 763.6, "end": 768.96, "text": " Now what's it go is to go to the one provision. We have defined already two providers, one", "tokens": [823, 437, 311, 309, 352, 307, 281, 352, 281, 264, 472, 17225, 13, 492, 362, 7642, 1217, 732, 11330, 11, 472], "temperature": 0.0, "avg_logprob": -0.15105574758429277, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.00029114747303538024}, {"id": 102, "seek": 75812, "start": 768.96, "end": 778.52, "text": " for Equinix and one for AWS. And once you define these providers, you can create clusters", "tokens": [337, 15624, 259, 970, 293, 472, 337, 17650, 13, 400, 1564, 291, 6964, 613, 11330, 11, 291, 393, 1884, 23313], "temperature": 0.0, "avg_logprob": -0.15105574758429277, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.00029114747303538024}, {"id": 103, "seek": 75812, "start": 778.52, "end": 784.6, "text": " on the two providers. So we are going to create a cluster, for example, in AWS. In this case,", "tokens": [322, 264, 732, 11330, 13, 407, 321, 366, 516, 281, 1884, 257, 13630, 11, 337, 1365, 11, 294, 17650, 13, 682, 341, 1389, 11], "temperature": 0.0, "avg_logprob": -0.15105574758429277, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.00029114747303538024}, {"id": 104, "seek": 78460, "start": 784.6, "end": 792.2, "text": " we have defined a provider for AWS in London, the zone. And this will now create an edge", "tokens": [321, 362, 7642, 257, 12398, 337, 17650, 294, 7042, 11, 264, 6668, 13, 400, 341, 486, 586, 1884, 364, 4691], "temperature": 0.0, "avg_logprob": -0.19086835717642178, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.00033428240567445755}, {"id": 105, "seek": 78460, "start": 792.2, "end": 798.52, "text": " cluster on AWS. As I said, we use Terraform and Ansible to create resources and to compute", "tokens": [13630, 322, 17650, 13, 1018, 286, 848, 11, 321, 764, 25366, 837, 293, 14590, 964, 281, 1884, 3593, 293, 281, 14722], "temperature": 0.0, "avg_logprob": -0.19086835717642178, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.00033428240567445755}, {"id": 106, "seek": 78460, "start": 798.52, "end": 804.52, "text": " in such a way that you create an edge cluster for OpenEbula. And then here I'm going to", "tokens": [294, 1270, 257, 636, 300, 291, 1884, 364, 4691, 13630, 337, 7238, 36, 65, 3780, 13, 400, 550, 510, 286, 478, 516, 281], "temperature": 0.0, "avg_logprob": -0.19086835717642178, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.00033428240567445755}, {"id": 107, "seek": 78460, "start": 804.52, "end": 810.2, "text": " create another cluster instead of on Equinix. Clearly, you have some parameters. You can", "tokens": [1884, 1071, 13630, 2602, 295, 322, 15624, 259, 970, 13, 24120, 11, 291, 362, 512, 9834, 13, 509, 393], "temperature": 0.0, "avg_logprob": -0.19086835717642178, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.00033428240567445755}, {"id": 108, "seek": 81020, "start": 810.2, "end": 814.9200000000001, "text": " define the number of hosts, you can define the number of public IP that you would like", "tokens": [6964, 264, 1230, 295, 21573, 11, 291, 393, 6964, 264, 1230, 295, 1908, 8671, 300, 291, 576, 411], "temperature": 0.0, "avg_logprob": -0.2500772476196289, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.0006321301916614175}, {"id": 109, "seek": 81020, "start": 814.9200000000001, "end": 822.0, "text": " to access, and so on. Okay? By the way, you can define two type of clusters with one provision.", "tokens": [281, 2105, 11, 293, 370, 322, 13, 1033, 30, 3146, 264, 636, 11, 291, 393, 6964, 732, 2010, 295, 23313, 365, 472, 17225, 13], "temperature": 0.0, "avg_logprob": -0.2500772476196289, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.0006321301916614175}, {"id": 110, "seek": 81020, "start": 822.0, "end": 828.12, "text": " One is an edge cluster, it's a base, or you can also create a safe cluster, an hyperconverged", "tokens": [1485, 307, 364, 4691, 13630, 11, 309, 311, 257, 3096, 11, 420, 291, 393, 611, 1884, 257, 3273, 13630, 11, 364, 9848, 1671, 331, 3004], "temperature": 0.0, "avg_logprob": -0.2500772476196289, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.0006321301916614175}, {"id": 111, "seek": 81020, "start": 828.12, "end": 832.88, "text": " cluster. As you can see here, once you use one provision in a Sunstone, graphical user", "tokens": [13630, 13, 1018, 291, 393, 536, 510, 11, 1564, 291, 764, 472, 17225, 294, 257, 6163, 11243, 11, 35942, 4195], "temperature": 0.0, "avg_logprob": -0.2500772476196289, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.0006321301916614175}, {"id": 112, "seek": 81020, "start": 832.88, "end": 837.96, "text": " interface, you will see the hosts that are going to be proficient. And while it will", "tokens": [9226, 11, 291, 486, 536, 264, 21573, 300, 366, 516, 281, 312, 1740, 24549, 13, 400, 1339, 309, 486], "temperature": 0.0, "avg_logprob": -0.2500772476196289, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.0006321301916614175}, {"id": 113, "seek": 83796, "start": 837.96, "end": 844.6800000000001, "text": " take around five, ten minutes, this depends on the cloud provider how much time it needs", "tokens": [747, 926, 1732, 11, 2064, 2077, 11, 341, 5946, 322, 264, 4588, 12398, 577, 709, 565, 309, 2203], "temperature": 0.0, "avg_logprob": -0.19654128256808506, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.001003442914225161}, {"id": 114, "seek": 83796, "start": 844.6800000000001, "end": 852.08, "text": " to create resources. But once you have created the resources, you can see here the two clusters.", "tokens": [281, 1884, 3593, 13, 583, 1564, 291, 362, 2942, 264, 3593, 11, 291, 393, 536, 510, 264, 732, 23313, 13], "temperature": 0.0, "avg_logprob": -0.19654128256808506, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.001003442914225161}, {"id": 115, "seek": 83796, "start": 852.08, "end": 858.2800000000001, "text": " What you have to do is to instantiate a couple of, to use Kubernetes appliance, we have to", "tokens": [708, 291, 362, 281, 360, 307, 281, 9836, 13024, 257, 1916, 295, 11, 281, 764, 23145, 45646, 11, 321, 362, 281], "temperature": 0.0, "avg_logprob": -0.19654128256808506, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.001003442914225161}, {"id": 116, "seek": 83796, "start": 858.2800000000001, "end": 867.48, "text": " define a couple of private networks, one for Equinix and one for the other AWS clusters.", "tokens": [6964, 257, 1916, 295, 4551, 9590, 11, 472, 337, 15624, 259, 970, 293, 472, 337, 264, 661, 17650, 23313, 13], "temperature": 0.0, "avg_logprob": -0.19654128256808506, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.001003442914225161}, {"id": 117, "seek": 86748, "start": 867.48, "end": 873.48, "text": " And in order to do this, it's simplified because we create a template, then you just instantiate", "tokens": [400, 294, 1668, 281, 360, 341, 11, 309, 311, 26335, 570, 321, 1884, 257, 12379, 11, 550, 291, 445, 9836, 13024], "temperature": 0.0, "avg_logprob": -0.1716383041874055, "compression_ratio": 1.7403846153846154, "no_speech_prob": 0.0008596974657848477}, {"id": 118, "seek": 86748, "start": 873.48, "end": 879.76, "text": " the template, and then you can create also the private networks, both for AWS and Equinix.", "tokens": [264, 12379, 11, 293, 550, 291, 393, 1884, 611, 264, 4551, 9590, 11, 1293, 337, 17650, 293, 15624, 259, 970, 13], "temperature": 0.0, "avg_logprob": -0.1716383041874055, "compression_ratio": 1.7403846153846154, "no_speech_prob": 0.0008596974657848477}, {"id": 119, "seek": 86748, "start": 879.76, "end": 887.16, "text": " Because we need the private for the internal VMs, the roles like node, master, storage,", "tokens": [1436, 321, 643, 264, 4551, 337, 264, 6920, 18038, 82, 11, 264, 9604, 411, 9984, 11, 4505, 11, 6725, 11], "temperature": 0.0, "avg_logprob": -0.1716383041874055, "compression_ratio": 1.7403846153846154, "no_speech_prob": 0.0008596974657848477}, {"id": 120, "seek": 86748, "start": 887.16, "end": 892.48, "text": " and the worker nodes, and then we need the public network instead for the VNF, that is", "tokens": [293, 264, 11346, 13891, 11, 293, 550, 321, 643, 264, 1908, 3209, 2602, 337, 264, 691, 45, 37, 11, 300, 307], "temperature": 0.0, "avg_logprob": -0.1716383041874055, "compression_ratio": 1.7403846153846154, "no_speech_prob": 0.0008596974657848477}, {"id": 121, "seek": 89248, "start": 892.48, "end": 901.96, "text": " our main endpoint where to access the Kubernetes clusters. Now what we are going to do is to", "tokens": [527, 2135, 35795, 689, 281, 2105, 264, 23145, 23313, 13, 823, 437, 321, 366, 516, 281, 360, 307, 281], "temperature": 0.0, "avg_logprob": -0.21704087112889145, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.0003525560605339706}, {"id": 122, "seek": 89248, "start": 901.96, "end": 909.9200000000001, "text": " import the one key appliance for our marketplace within our open Nebula. You can do this just", "tokens": [974, 264, 472, 2141, 45646, 337, 527, 19455, 1951, 527, 1269, 1734, 37775, 13, 509, 393, 360, 341, 445], "temperature": 0.0, "avg_logprob": -0.21704087112889145, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.0003525560605339706}, {"id": 123, "seek": 89248, "start": 909.9200000000001, "end": 917.52, "text": " once. So we are going to import the appliance. And once you import the appliance, what will", "tokens": [1564, 13, 407, 321, 366, 516, 281, 974, 264, 45646, 13, 400, 1564, 291, 974, 264, 45646, 11, 437, 486], "temperature": 0.0, "avg_logprob": -0.21704087112889145, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.0003525560605339706}, {"id": 124, "seek": 91752, "start": 917.52, "end": 923.64, "text": " be imported are templates for the VMs that are for each role, and the template for the", "tokens": [312, 25524, 366, 21165, 337, 264, 18038, 82, 300, 366, 337, 1184, 3090, 11, 293, 264, 12379, 337, 264], "temperature": 0.0, "avg_logprob": -0.2009896887354104, "compression_ratio": 1.6844660194174756, "no_speech_prob": 0.0002956594980787486}, {"id": 125, "seek": 91752, "start": 923.64, "end": 931.36, "text": " service. This service is based on one floor, and also the images that are related to the", "tokens": [2643, 13, 639, 2643, 307, 2361, 322, 472, 4123, 11, 293, 611, 264, 5267, 300, 366, 4077, 281, 264], "temperature": 0.0, "avg_logprob": -0.2009896887354104, "compression_ratio": 1.6844660194174756, "no_speech_prob": 0.0002956594980787486}, {"id": 126, "seek": 91752, "start": 931.36, "end": 936.8, "text": " different roles. So in order to create a new Kubernetes cluster, what we have to do is", "tokens": [819, 9604, 13, 407, 294, 1668, 281, 1884, 257, 777, 23145, 13630, 11, 437, 321, 362, 281, 360, 307], "temperature": 0.0, "avg_logprob": -0.2009896887354104, "compression_ratio": 1.6844660194174756, "no_speech_prob": 0.0002956594980787486}, {"id": 127, "seek": 91752, "start": 936.8, "end": 943.24, "text": " to just instantiate a service by selecting the appropriate networks, for example. So", "tokens": [281, 445, 9836, 13024, 257, 2643, 538, 18182, 264, 6854, 9590, 11, 337, 1365, 13, 407], "temperature": 0.0, "avg_logprob": -0.2009896887354104, "compression_ratio": 1.6844660194174756, "no_speech_prob": 0.0002956594980787486}, {"id": 128, "seek": 94324, "start": 943.24, "end": 948.36, "text": " in this case, you can see now I'm creating a cluster on AWS. So I select for the public", "tokens": [294, 341, 1389, 11, 291, 393, 536, 586, 286, 478, 4084, 257, 13630, 322, 17650, 13, 407, 286, 3048, 337, 264, 1908], "temperature": 0.0, "avg_logprob": -0.14532350034129862, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.0009126798831857741}, {"id": 129, "seek": 94324, "start": 948.36, "end": 955.16, "text": " network, the AWS cluster public for the private, the AWS private, and then I just have to put", "tokens": [3209, 11, 264, 17650, 13630, 1908, 337, 264, 4551, 11, 264, 17650, 4551, 11, 293, 550, 286, 445, 362, 281, 829], "temperature": 0.0, "avg_logprob": -0.14532350034129862, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.0009126798831857741}, {"id": 130, "seek": 94324, "start": 955.16, "end": 962.24, "text": " a couple of IPs internal. These are for the internal networks, for the virtual IP, for", "tokens": [257, 1916, 295, 8671, 82, 6920, 13, 1981, 366, 337, 264, 6920, 9590, 11, 337, 264, 6374, 8671, 11, 337], "temperature": 0.0, "avg_logprob": -0.14532350034129862, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.0009126798831857741}, {"id": 131, "seek": 94324, "start": 962.24, "end": 970.92, "text": " the VNF, and for the gateway. And we can do the same for Equinix. So by just selecting", "tokens": [264, 691, 45, 37, 11, 293, 337, 264, 28532, 13, 400, 321, 393, 360, 264, 912, 337, 15624, 259, 970, 13, 407, 538, 445, 18182], "temperature": 0.0, "avg_logprob": -0.14532350034129862, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.0009126798831857741}, {"id": 132, "seek": 97092, "start": 970.92, "end": 977.36, "text": " the public networks of Equinix and then the private networks that we have defined. Also", "tokens": [264, 1908, 9590, 295, 15624, 259, 970, 293, 550, 264, 4551, 9590, 300, 321, 362, 7642, 13, 2743], "temperature": 0.0, "avg_logprob": -0.15540010421002498, "compression_ratio": 1.5688622754491017, "no_speech_prob": 0.0006534080021083355}, {"id": 133, "seek": 97092, "start": 977.36, "end": 988.88, "text": " in this case, I've used the same network for both clusters. And here you see that now we", "tokens": [294, 341, 1389, 11, 286, 600, 1143, 264, 912, 3209, 337, 1293, 23313, 13, 400, 510, 291, 536, 300, 586, 321], "temperature": 0.0, "avg_logprob": -0.15540010421002498, "compression_ratio": 1.5688622754491017, "no_speech_prob": 0.0006534080021083355}, {"id": 134, "seek": 97092, "start": 988.88, "end": 994.64, "text": " are deploying the two Kubernetes clusters on the two different edge clusters that are", "tokens": [366, 34198, 264, 732, 23145, 23313, 322, 264, 732, 819, 4691, 23313, 300, 366], "temperature": 0.0, "avg_logprob": -0.15540010421002498, "compression_ratio": 1.5688622754491017, "no_speech_prob": 0.0006534080021083355}, {"id": 135, "seek": 99464, "start": 994.64, "end": 1003.48, "text": " on AWS London and Equinix. As you see, the first role that is deployed is VNF. Once the", "tokens": [322, 17650, 7042, 293, 15624, 259, 970, 13, 1018, 291, 536, 11, 264, 700, 3090, 300, 307, 17826, 307, 691, 45, 37, 13, 3443, 264], "temperature": 0.0, "avg_logprob": -0.20488675017105906, "compression_ratio": 1.544378698224852, "no_speech_prob": 0.0003018205752596259}, {"id": 136, "seek": 99464, "start": 1003.48, "end": 1011.96, "text": " VNF is ready running, in one floor, you can define dependencies. And once the VNF is", "tokens": [691, 45, 37, 307, 1919, 2614, 11, 294, 472, 4123, 11, 291, 393, 6964, 36606, 13, 400, 1564, 264, 691, 45, 37, 307], "temperature": 0.0, "avg_logprob": -0.20488675017105906, "compression_ratio": 1.544378698224852, "no_speech_prob": 0.0003018205752596259}, {"id": 137, "seek": 99464, "start": 1011.96, "end": 1019.56, "text": " ready, one floor is going to deploy the other roles, master, the worker, and the storage", "tokens": [1919, 11, 472, 4123, 307, 516, 281, 7274, 264, 661, 9604, 11, 4505, 11, 264, 11346, 11, 293, 264, 6725], "temperature": 0.0, "avg_logprob": -0.20488675017105906, "compression_ratio": 1.544378698224852, "no_speech_prob": 0.0003018205752596259}, {"id": 138, "seek": 101956, "start": 1019.56, "end": 1029.72, "text": " node. In order to access the Kubernetes clusters, you have to use the public IP of the VNF.", "tokens": [9984, 13, 682, 1668, 281, 2105, 264, 23145, 23313, 11, 291, 362, 281, 764, 264, 1908, 8671, 295, 264, 691, 45, 37, 13], "temperature": 0.0, "avg_logprob": -0.1514580571973646, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0005450953613035381}, {"id": 139, "seek": 101956, "start": 1029.72, "end": 1037.96, "text": " And you can use SSH agent forwarding by using, you know, first connecting to the VNF and", "tokens": [400, 291, 393, 764, 12238, 39, 9461, 2128, 278, 538, 1228, 11, 291, 458, 11, 700, 11015, 281, 264, 691, 45, 37, 293], "temperature": 0.0, "avg_logprob": -0.1514580571973646, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0005450953613035381}, {"id": 140, "seek": 101956, "start": 1037.96, "end": 1044.24, "text": " then connecting to the master by using the private IP. Okay. Here we can see the nodes.", "tokens": [550, 11015, 281, 264, 4505, 538, 1228, 264, 4551, 8671, 13, 1033, 13, 1692, 321, 393, 536, 264, 13891, 13], "temperature": 0.0, "avg_logprob": -0.1514580571973646, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0005450953613035381}, {"id": 141, "seek": 104424, "start": 1044.24, "end": 1049.88, "text": " So we can have, as I said, by default, you have one node for each master clear. This", "tokens": [407, 321, 393, 362, 11, 382, 286, 848, 11, 538, 7576, 11, 291, 362, 472, 9984, 337, 1184, 4505, 1850, 13, 639], "temperature": 0.0, "avg_logprob": -0.2333211682059548, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0011729425750672817}, {"id": 142, "seek": 104424, "start": 1049.88, "end": 1056.92, "text": " is not for production environment. If you want to have for production environment, you", "tokens": [307, 406, 337, 4265, 2823, 13, 759, 291, 528, 281, 362, 337, 4265, 2823, 11, 291], "temperature": 0.0, "avg_logprob": -0.2333211682059548, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0011729425750672817}, {"id": 143, "seek": 104424, "start": 1056.92, "end": 1063.48, "text": " need to scale each node, for example. So here, I just create an image and I prepared also", "tokens": [643, 281, 4373, 1184, 9984, 11, 337, 1365, 13, 407, 510, 11, 286, 445, 1884, 364, 3256, 293, 286, 4927, 611], "temperature": 0.0, "avg_logprob": -0.2333211682059548, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0011729425750672817}, {"id": 144, "seek": 104424, "start": 1063.48, "end": 1070.52, "text": " a YAML file, a manifest file for exposing the service through the ingress controller.", "tokens": [257, 398, 2865, 43, 3991, 11, 257, 10067, 3991, 337, 33178, 264, 2643, 807, 264, 3957, 735, 10561, 13], "temperature": 0.0, "avg_logprob": -0.2333211682059548, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0011729425750672817}, {"id": 145, "seek": 107052, "start": 1070.52, "end": 1079.52, "text": " And then you can use the public IP of the VNF to access the service. Okay. Clearly OpenEBOLA", "tokens": [400, 550, 291, 393, 764, 264, 1908, 8671, 295, 264, 691, 45, 37, 281, 2105, 264, 2643, 13, 1033, 13, 24120, 7238, 36, 33, 5046, 32], "temperature": 0.0, "avg_logprob": -0.20335921976301405, "compression_ratio": 1.4946808510638299, "no_speech_prob": 0.0002819708315655589}, {"id": 146, "seek": 107052, "start": 1079.52, "end": 1088.32, "text": " is not, doesn't have any tools for managing the deployment of application on Kubernetes.", "tokens": [307, 406, 11, 1177, 380, 362, 604, 3873, 337, 11642, 264, 19317, 295, 3861, 322, 23145, 13], "temperature": 0.0, "avg_logprob": -0.20335921976301405, "compression_ratio": 1.4946808510638299, "no_speech_prob": 0.0002819708315655589}, {"id": 147, "seek": 107052, "start": 1088.32, "end": 1094.4, "text": " So we manage the infrastructure and the deployment of Kubernetes cluster. Then you can use kubectl,", "tokens": [407, 321, 3067, 264, 6896, 293, 264, 19317, 295, 23145, 13630, 13, 1396, 291, 393, 764, 350, 836, 557, 75, 11], "temperature": 0.0, "avg_logprob": -0.20335921976301405, "compression_ratio": 1.4946808510638299, "no_speech_prob": 0.0002819708315655589}, {"id": 148, "seek": 109440, "start": 1094.4, "end": 1101.76, "text": " you can use Ranger, you can use other open source tooling, you know, that maybe in the", "tokens": [291, 393, 764, 34222, 11, 291, 393, 764, 661, 1269, 4009, 46593, 11, 291, 458, 11, 300, 1310, 294, 264], "temperature": 0.0, "avg_logprob": -0.241422075213808, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0005148726631887257}, {"id": 149, "seek": 109440, "start": 1101.76, "end": 1106.68, "text": " future we can add also. As you can see here, by using the public IP of the VNF, I have", "tokens": [2027, 321, 393, 909, 611, 13, 1018, 291, 393, 536, 510, 11, 538, 1228, 264, 1908, 8671, 295, 264, 691, 45, 37, 11, 286, 362], "temperature": 0.0, "avg_logprob": -0.241422075213808, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0005148726631887257}, {"id": 150, "seek": 109440, "start": 1106.68, "end": 1113.8400000000001, "text": " access to the engine mix. Another thing, you can scale the roles once you deploy, for example.", "tokens": [2105, 281, 264, 2848, 2890, 13, 3996, 551, 11, 291, 393, 4373, 264, 9604, 1564, 291, 7274, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.241422075213808, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0005148726631887257}, {"id": 151, "seek": 109440, "start": 1113.8400000000001, "end": 1119.44, "text": " In this case, I can scale, for example, the worker. You just put the number here. We use", "tokens": [682, 341, 1389, 11, 286, 393, 4373, 11, 337, 1365, 11, 264, 11346, 13, 509, 445, 829, 264, 1230, 510, 13, 492, 764], "temperature": 0.0, "avg_logprob": -0.241422075213808, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0005148726631887257}, {"id": 152, "seek": 111944, "start": 1119.44, "end": 1127.8, "text": " the one flow, one flow allows us to scale the cluster for each role. Okay. And now you", "tokens": [264, 472, 3095, 11, 472, 3095, 4045, 505, 281, 4373, 264, 13630, 337, 1184, 3090, 13, 1033, 13, 400, 586, 291], "temperature": 0.0, "avg_logprob": -0.2377010224357484, "compression_ratio": 1.4903225806451612, "no_speech_prob": 0.00013332878006622195}, {"id": 153, "seek": 111944, "start": 1127.8, "end": 1137.72, "text": " can see another worker is going to be deployed. Yeah, this was the demo and I think that's", "tokens": [393, 536, 1071, 11346, 307, 516, 281, 312, 17826, 13, 865, 11, 341, 390, 264, 10723, 293, 286, 519, 300, 311], "temperature": 0.0, "avg_logprob": -0.2377010224357484, "compression_ratio": 1.4903225806451612, "no_speech_prob": 0.00013332878006622195}, {"id": 154, "seek": 113772, "start": 1137.72, "end": 1151.76, "text": " the conclusion. Okay. Thank you. Thank you all. Okay.", "tokens": [50364, 264, 10063, 13, 1033, 13, 1044, 291, 13, 1044, 291, 439, 13, 1033, 13, 51066], "temperature": 0.0, "avg_logprob": -0.396941858179429, "compression_ratio": 1.1521739130434783, "no_speech_prob": 0.0030220700427889824}], "language": "en"}