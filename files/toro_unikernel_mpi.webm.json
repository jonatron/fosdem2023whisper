{"text": " All right, we'll get started. We have another talk on MPI, but I think a very different one, running MPI applications on the Toro Unicolon. Exactly. Yeah. So, hello, everyone. I'm Matthias. Here, I'm going to talk about running MPI applications on Toro Unicolonial. Usually speaking, a Unicolonial is a way to deploy a user application in a way that is closer to the hardware by trying to reuse the operating system interference. So, in the overall, it should perform better than just deploying a user application by using a, during our proposed operating system. First, I would like to introduce myself while I am passionate about operating system development and mutualization technologies. I had worked at Citrix, to take Huawei, and I'm currently a Baptist, and here I have my email and my GitHub profile, if you want to know more about why I'm doing it. So, I'm going to start to present what is exactly a Unicolonial, and then I'm going to go to the details of what makes Toro special, and then I will show current implementation of the MPI standard on top of Toro, and I will finish with a benchmark that I'm trying to do to see if the current implementation is working as expected, or if there are things that could be improved. So, maybe you are already familiar with this picture. This is more or less how a user application is deployed, either using a built-in machine or bare metal. So, what we have is the operating system, the user application, and the two different modes, the RIN 3.0, which is the different modes in the X86 processor. So, in general, what we have is that when a user application requires one to open a file, send a packet, or whatever, it's going to trigger a Cisco, and then it's going to be a switch in which the processor is running from, which is user space to kernel space, so it's going to be processed here, kernel space, and come back, right? In general, when we see what we have inside the kernel is, well, we have different components, right, that, for example, have the scheduler, the file system, different drivers, and so on. So, in particular, when we have a scheduler, a scheduler is going to choose what is the next process that's going to be executed. One of these processes, or several of them, is going to be your MPI application, for example. So, if you deploy your MPI application in a, by using a general proposal, but as a system, your application is going to compete with other processes in the system for sure. And also, what you have in the scheduler is some policy, which is going to decide which is the next process to be deployed. Also, we have components like the file system, and since we have a general proposal processing system, we're going to have several drivers for different file systems, and different drivers, and so on. So, what some people observed was that there were too much generality in using a general proposal processing system for a single proposed application, like, can be an MPI. So, some people come up with a new architecture, they propose what they call Unicolonial. You have some projects there, like OSV, Mirage OS, Unicrash, or Nano VMs. What they do is just take the user application and compile it within the kernel itself. So, at the end, what you have is a single binary that is going to be deployed, either by using a virtual machine or a bare metal, right? So, instead of, for example, having syscalls that we have in the case that we have a general proposal processing system and different modes of execution, in the case of a Unicolonial, we have simply calls, which are cheaper than using syscalls, for example. In general, the projects, the projects that I presented before all come forward to the epoxy standard, so it means that if you have any application written in C that come forward epoxy, you can theoretically compile with the Unicolonial without any modification of the user application. In reality, this does not happen, and most of the time, the epoxy that the Unicolonial implement is not complete, so you have to do some work to just, you cannot just take your application and compile it and generate something, it doesn't work out of the box in most of the cases, right? So, in this context, what is total is also a Unicolonial, it's an application-oriented Unicolonial, and the idea of total is to offer an API which is dedicated, I mean, to efficiently deploy parallel application. In the case of total, it is, it's not a epoxy complaint, it means that even if the nail of the functions like this opens in close and so on, it's more or less the same nail, the semantic of this function is slightly different, so I will not say that it's a epoxy complaint in that sense, and I will explain that later. So, let's say that the three building blocks of the total Unicolonial are the memory per core, cooperative scheduler, and core-to-core communication based on built IEA. Here I'm talking about the architect of the Unicolonial, I'm not talking about yet the application of how we're going to build an application to compile tutorial, right? And I'm going to explain these three points. So, first, what happened in the total Unicolonial is that we have memory dedicated per core, so at the beginning what we do is just allocate memory, I mean, to split the whole memory in rations and we assign these rations per core, and for the moment the size of these rations is just proportional to the number of cores that we have. That makes that, for example, the memory allocator is quite simple, it doesn't require any communication because we have chunks of data, I mean, yeah, the allocator is, we have one allocator per core which means that we don't require any synchronization in the kernel to allocate for one core. It's quite, we call it per CPU data, let's say, yeah. So, for example, if you have a thread in a core one and we want to locate memory, we're going always to get it from the same rations and that happens also if you're on the core two, we're going to use the rations, from rations two. And the idea is that by doing this, we can then leverage technologies like hypertransport or interquit path interconnect in which we can say, well, this core is going to access this rations of memory and if you access all the rations, it's going to get a penalty to do it, right? So, talking about the scheduler, what happened in total is that we only have thread, so we don't have process means that we, all threads share the view of the memory and we have mainly one API to create thread, it's called a begin thread and it's the parameter that have to say in which core each thread is going to run. The scheduler scoperity, which means that it is the thread that's going to call the scheduler to then choose another thread and this is by relying on the API call assist thread switch and most of the time, this is just in bucket because we are going to be idle for a while, so we just call the scheduler or we, for example, we're going to do some IO. So the scheduler is also very simple, we have, again, first CPU data, so we have one cube per core and the scheduler is simple going to choose the next thread that is ready and then the scheduler and this means that also we don't require any synchronization at the level of the kernel to schedule a thread, so it's like each core run independently one for another. Fine I am going to talk a bit about how we communicate cores and basically what we have is one dedicated reception cube per core for any other core in the system, so we have one to one communication. This basically relies on two primitives which is send and resist front and it's just by using the destination core and from where we want to get a packet, for example. These two primitives are the ingridients to then build more complicated APIs like MPI gutter, MPI because and MPI scatter, so these are the building blocks for those API, for example. So to implement this core-to-core communication, I was using butaio, so I was just following the specification, I will talk a little bit about this, I don't want to go too much into detail so as to understand roughly how communication between core is done. As I said before, we have one reception cube for each core, for any other core in the system, so means that, for example, if core one want to get packets from core two, we have a reception cube and also if core one want to send a packet to core two, it's going to have a transmission cube and the number of queues is going to be for sure different if you have three cores, for example, because the build queues are dedicated. So basically how a build queue works is made of three RINs buffers. So the first RIN buffer is the buffer which only contains descriptors to chunks of memory. The second buffer is the aviable RIN and the third buffer is the user RIN. Basically what happens is the aviable RIN is the buffers that the core one are exposing to core two. So if the core two want to send a packet to core one, it's going to get a buffer from aviable RIN, put the data and then put it again in the user RIN. This is basically how build.io works, just that if you are familiar with build.io, in this case, for example, the consumer of aviable RIN is the core two, but if, for example, if you are in a hypervisor and you're implementing some build.io device, the consumer is not going to be the core two, but it's going to be the device model, QMU, for example, and if you are familiar with that. But it's the same scheme. This allows that, for example, since we have one producer and one consumer, we can access to the build queue without any synchronization, I mean, at least if we have only one consumer. So you don't require any luck, for example, to access to the build queue. So yeah, I already talked too much, I don't know how much time I have left, but I wanted to show some examples about the implementation, maybe it's more fun that all the flyers should show. So what happened, how we, how we deploy an application by using Toiletware. We have the MPI application, this is a C application for the moment, and you compile it with a unit that's going just to link the application with some functions that are the implementation of the MPI, the MPI, for example, MPI Bicass, Gatter, and so on, it's implemented in this level in the MPI interface. And this unit is going to use some MPI from the unique kernel. So at the end, what you're going to get is an ELF and binary that could be used to deploy your application, either as a built-in machine or a bare metal. So you don't have any operating system intermediate there, you have only your application, the threads and so on, but you don't have nothing else. So if you want to see how it is deployed, if you get the MPI application that doesn't see what is going to happen, we're going to get the main and then instantiate it to one for every core in the system, as a thread. So to benchmark the current implementation, I'm not very familiar with the MPI where I was just coming from another domain, so I am not really familiar with how I had to benchmark such implementation, and so I choose the also microbenchmarks, maybe you know them, maybe not, and I just pick up one of them, like for example, MPI barrier, and I try to implement, which is quite simple, the benchmark itself is quite simple, so I decided to implement it. I could not take the benchmark as it is, I have to do some rework to make it work, and then my idea was to see how this behave when I was deploying this as a single VM, which many cores. The hardware that I use is this one, since I'm not familiar with the high performance computing work, I'm not really sure if this is a hardware that you often use, it's quite a new Intel, you can get it in Equinex, the price is four euros per hour. So I launched the test and I tried to measure things, so I was just measuring the latency of this, and I was taking into account the max latency through, I mean, over four, eight, sixteen, or thirty-two cores. I am getting values in the order of the microseconds, and then I found this paper, which was also using this benchmark to measure their platform, and I was saying, well, in this paper, they were reporting around 20 nanoseconds and 13 nanoseconds, sorry, this is nanoseconds, this is microseconds, not nanoseconds, sorry, in this platform. In any case, I will be very cautious about this graph, because I was getting a lot of variation in the numbers, most of the time, for example, I was trying in a machine with thirty-two cores, and the VM has already thirty-two BCPUs, so you should not test in that sort of machine, because one of the threads is going to compete with the others, with the main one of the hosts, so you should always test with less cores, less BCPU cores, physical cores. And, yeah, the idea is to continue doing this, I mean, improving the way I am measuring this, and also try maybe in different hardware, and at the same time, I found a lot of packs in the unicroner by doing this, so for example, at the beginning, I only support more or less four cores, so I went from four to thirty-two, well, it was a number in a constant, but anyway, I found many packs when I was doing this, so it is all, this is just a proof-of-concept and a work in progress, so you don't take it too serious, I am trying to say, I don't want to jump into any conclusion from this, and, yeah, it was fun to do, anyway. So that's all, I don't know if you have any questions. So you said this runs on bare metal. Sorry? The unicroner runs on bare metal. Yeah, they are some. How do you even install it? I mean, operating systems are kind of complicated, right? Sorry? How do you even install it on bare metal? Can you say that again? How do you install it on bare metal? How do you install it? Yeah, like if I had this, how would I install it on bare metal? Is there an installer or...? Installer, you mean? Yeah. Now, you can just use some device to boot from, for example. So it's bootable? Yeah, that's it. Yeah. Okay. Yeah. Well, yeah. There are many ways to do that, for example, you don't have to install it, for example. You can use from a device that is removable, for example, you don't need to install it. Any questions? Thanks. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.0, "text": " All right, we'll get started.", "tokens": [1057, 558, 11, 321, 603, 483, 1409, 13], "temperature": 0.0, "avg_logprob": -0.32354579653058735, "compression_ratio": 1.6, "no_speech_prob": 0.3796703517436981}, {"id": 1, "seek": 0, "start": 8.0, "end": 12.92, "text": " We have another talk on MPI, but I think a very different one, running MPI applications", "tokens": [492, 362, 1071, 751, 322, 14146, 40, 11, 457, 286, 519, 257, 588, 819, 472, 11, 2614, 14146, 40, 5821], "temperature": 0.0, "avg_logprob": -0.32354579653058735, "compression_ratio": 1.6, "no_speech_prob": 0.3796703517436981}, {"id": 2, "seek": 0, "start": 12.92, "end": 14.52, "text": " on the Toro Unicolon.", "tokens": [322, 264, 7160, 78, 1156, 299, 38780, 13], "temperature": 0.0, "avg_logprob": -0.32354579653058735, "compression_ratio": 1.6, "no_speech_prob": 0.3796703517436981}, {"id": 3, "seek": 0, "start": 14.52, "end": 15.52, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.32354579653058735, "compression_ratio": 1.6, "no_speech_prob": 0.3796703517436981}, {"id": 4, "seek": 0, "start": 15.52, "end": 16.52, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.32354579653058735, "compression_ratio": 1.6, "no_speech_prob": 0.3796703517436981}, {"id": 5, "seek": 0, "start": 16.52, "end": 17.52, "text": " So, hello, everyone.", "tokens": [407, 11, 7751, 11, 1518, 13], "temperature": 0.0, "avg_logprob": -0.32354579653058735, "compression_ratio": 1.6, "no_speech_prob": 0.3796703517436981}, {"id": 6, "seek": 0, "start": 17.52, "end": 18.52, "text": " I'm Matthias.", "tokens": [286, 478, 11327, 4609, 13], "temperature": 0.0, "avg_logprob": -0.32354579653058735, "compression_ratio": 1.6, "no_speech_prob": 0.3796703517436981}, {"id": 7, "seek": 0, "start": 18.52, "end": 22.84, "text": " Here, I'm going to talk about running MPI applications on Toro Unicolonial.", "tokens": [1692, 11, 286, 478, 516, 281, 751, 466, 2614, 14146, 40, 5821, 322, 7160, 78, 1156, 299, 38780, 831, 13], "temperature": 0.0, "avg_logprob": -0.32354579653058735, "compression_ratio": 1.6, "no_speech_prob": 0.3796703517436981}, {"id": 8, "seek": 0, "start": 22.84, "end": 28.32, "text": " Usually speaking, a Unicolonial is a way to deploy a user application in a way that is", "tokens": [11419, 4124, 11, 257, 1156, 299, 38780, 831, 307, 257, 636, 281, 7274, 257, 4195, 3861, 294, 257, 636, 300, 307], "temperature": 0.0, "avg_logprob": -0.32354579653058735, "compression_ratio": 1.6, "no_speech_prob": 0.3796703517436981}, {"id": 9, "seek": 2832, "start": 28.32, "end": 34.28, "text": " closer to the hardware by trying to reuse the operating system interference.", "tokens": [4966, 281, 264, 8837, 538, 1382, 281, 26225, 264, 7447, 1185, 24497, 13], "temperature": 0.0, "avg_logprob": -0.3374272375991664, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00013660705008078367}, {"id": 10, "seek": 2832, "start": 34.28, "end": 38.96, "text": " So, in the overall, it should perform better than just deploying a user application by", "tokens": [407, 11, 294, 264, 4787, 11, 309, 820, 2042, 1101, 813, 445, 34198, 257, 4195, 3861, 538], "temperature": 0.0, "avg_logprob": -0.3374272375991664, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00013660705008078367}, {"id": 11, "seek": 2832, "start": 38.96, "end": 41.96, "text": " using a, during our proposed operating system.", "tokens": [1228, 257, 11, 1830, 527, 10348, 7447, 1185, 13], "temperature": 0.0, "avg_logprob": -0.3374272375991664, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00013660705008078367}, {"id": 12, "seek": 2832, "start": 41.96, "end": 48.64, "text": " First, I would like to introduce myself while I am passionate about operating system development", "tokens": [2386, 11, 286, 576, 411, 281, 5366, 2059, 1339, 286, 669, 11410, 466, 7447, 1185, 3250], "temperature": 0.0, "avg_logprob": -0.3374272375991664, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00013660705008078367}, {"id": 13, "seek": 2832, "start": 48.64, "end": 50.68, "text": " and mutualization technologies.", "tokens": [293, 16917, 2144, 7943, 13], "temperature": 0.0, "avg_logprob": -0.3374272375991664, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00013660705008078367}, {"id": 14, "seek": 2832, "start": 50.68, "end": 56.04, "text": " I had worked at Citrix, to take Huawei, and I'm currently a Baptist, and here I have my", "tokens": [286, 632, 2732, 412, 18435, 6579, 11, 281, 747, 28542, 11, 293, 286, 478, 4362, 257, 32410, 11, 293, 510, 286, 362, 452], "temperature": 0.0, "avg_logprob": -0.3374272375991664, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00013660705008078367}, {"id": 15, "seek": 5604, "start": 56.04, "end": 63.16, "text": " email and my GitHub profile, if you want to know more about why I'm doing it.", "tokens": [3796, 293, 452, 23331, 7964, 11, 498, 291, 528, 281, 458, 544, 466, 983, 286, 478, 884, 309, 13], "temperature": 0.0, "avg_logprob": -0.177513184085969, "compression_ratio": 1.5934579439252337, "no_speech_prob": 2.2934389562578872e-05}, {"id": 16, "seek": 5604, "start": 63.16, "end": 67.92, "text": " So, I'm going to start to present what is exactly a Unicolonial, and then I'm going", "tokens": [407, 11, 286, 478, 516, 281, 722, 281, 1974, 437, 307, 2293, 257, 1156, 299, 38780, 831, 11, 293, 550, 286, 478, 516], "temperature": 0.0, "avg_logprob": -0.177513184085969, "compression_ratio": 1.5934579439252337, "no_speech_prob": 2.2934389562578872e-05}, {"id": 17, "seek": 5604, "start": 67.92, "end": 75.36, "text": " to go to the details of what makes Toro special, and then I will show current implementation", "tokens": [281, 352, 281, 264, 4365, 295, 437, 1669, 7160, 78, 2121, 11, 293, 550, 286, 486, 855, 2190, 11420], "temperature": 0.0, "avg_logprob": -0.177513184085969, "compression_ratio": 1.5934579439252337, "no_speech_prob": 2.2934389562578872e-05}, {"id": 18, "seek": 5604, "start": 75.36, "end": 82.64, "text": " of the MPI standard on top of Toro, and I will finish with a benchmark that I'm trying", "tokens": [295, 264, 14146, 40, 3832, 322, 1192, 295, 7160, 78, 11, 293, 286, 486, 2413, 365, 257, 18927, 300, 286, 478, 1382], "temperature": 0.0, "avg_logprob": -0.177513184085969, "compression_ratio": 1.5934579439252337, "no_speech_prob": 2.2934389562578872e-05}, {"id": 19, "seek": 8264, "start": 82.64, "end": 87.4, "text": " to do to see if the current implementation is working as expected, or if there are things", "tokens": [281, 360, 281, 536, 498, 264, 2190, 11420, 307, 1364, 382, 5176, 11, 420, 498, 456, 366, 721], "temperature": 0.0, "avg_logprob": -0.2958725594185494, "compression_ratio": 1.6525096525096525, "no_speech_prob": 8.650166819279548e-06}, {"id": 20, "seek": 8264, "start": 87.4, "end": 90.68, "text": " that could be improved.", "tokens": [300, 727, 312, 9689, 13], "temperature": 0.0, "avg_logprob": -0.2958725594185494, "compression_ratio": 1.6525096525096525, "no_speech_prob": 8.650166819279548e-06}, {"id": 21, "seek": 8264, "start": 90.68, "end": 94.6, "text": " So, maybe you are already familiar with this picture.", "tokens": [407, 11, 1310, 291, 366, 1217, 4963, 365, 341, 3036, 13], "temperature": 0.0, "avg_logprob": -0.2958725594185494, "compression_ratio": 1.6525096525096525, "no_speech_prob": 8.650166819279548e-06}, {"id": 22, "seek": 8264, "start": 94.6, "end": 99.12, "text": " This is more or less how a user application is deployed, either using a built-in machine", "tokens": [639, 307, 544, 420, 1570, 577, 257, 4195, 3861, 307, 17826, 11, 2139, 1228, 257, 3094, 12, 259, 3479], "temperature": 0.0, "avg_logprob": -0.2958725594185494, "compression_ratio": 1.6525096525096525, "no_speech_prob": 8.650166819279548e-06}, {"id": 23, "seek": 8264, "start": 99.12, "end": 100.12, "text": " or bare metal.", "tokens": [420, 6949, 5760, 13], "temperature": 0.0, "avg_logprob": -0.2958725594185494, "compression_ratio": 1.6525096525096525, "no_speech_prob": 8.650166819279548e-06}, {"id": 24, "seek": 8264, "start": 100.12, "end": 104.08, "text": " So, what we have is the operating system, the user application, and the two different", "tokens": [407, 11, 437, 321, 362, 307, 264, 7447, 1185, 11, 264, 4195, 3861, 11, 293, 264, 732, 819], "temperature": 0.0, "avg_logprob": -0.2958725594185494, "compression_ratio": 1.6525096525096525, "no_speech_prob": 8.650166819279548e-06}, {"id": 25, "seek": 8264, "start": 104.08, "end": 109.12, "text": " modes, the RIN 3.0, which is the different modes in the X86 processor.", "tokens": [14068, 11, 264, 497, 1464, 805, 13, 15, 11, 597, 307, 264, 819, 14068, 294, 264, 1783, 22193, 15321, 13], "temperature": 0.0, "avg_logprob": -0.2958725594185494, "compression_ratio": 1.6525096525096525, "no_speech_prob": 8.650166819279548e-06}, {"id": 26, "seek": 10912, "start": 109.12, "end": 115.92, "text": " So, in general, what we have is that when a user application requires one to open a", "tokens": [407, 11, 294, 2674, 11, 437, 321, 362, 307, 300, 562, 257, 4195, 3861, 7029, 472, 281, 1269, 257], "temperature": 0.0, "avg_logprob": -0.24006221975599015, "compression_ratio": 1.8484848484848484, "no_speech_prob": 5.949564183538314e-06}, {"id": 27, "seek": 10912, "start": 115.92, "end": 119.92, "text": " file, send a packet, or whatever, it's going to trigger a Cisco, and then it's going to", "tokens": [3991, 11, 2845, 257, 20300, 11, 420, 2035, 11, 309, 311, 516, 281, 7875, 257, 38528, 11, 293, 550, 309, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.24006221975599015, "compression_ratio": 1.8484848484848484, "no_speech_prob": 5.949564183538314e-06}, {"id": 28, "seek": 10912, "start": 119.92, "end": 127.80000000000001, "text": " be a switch in which the processor is running from, which is user space to kernel space,", "tokens": [312, 257, 3679, 294, 597, 264, 15321, 307, 2614, 490, 11, 597, 307, 4195, 1901, 281, 28256, 1901, 11], "temperature": 0.0, "avg_logprob": -0.24006221975599015, "compression_ratio": 1.8484848484848484, "no_speech_prob": 5.949564183538314e-06}, {"id": 29, "seek": 10912, "start": 127.80000000000001, "end": 133.6, "text": " so it's going to be processed here, kernel space, and come back, right?", "tokens": [370, 309, 311, 516, 281, 312, 18846, 510, 11, 28256, 1901, 11, 293, 808, 646, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.24006221975599015, "compression_ratio": 1.8484848484848484, "no_speech_prob": 5.949564183538314e-06}, {"id": 30, "seek": 10912, "start": 133.6, "end": 138.36, "text": " In general, when we see what we have inside the kernel is, well, we have different components,", "tokens": [682, 2674, 11, 562, 321, 536, 437, 321, 362, 1854, 264, 28256, 307, 11, 731, 11, 321, 362, 819, 6677, 11], "temperature": 0.0, "avg_logprob": -0.24006221975599015, "compression_ratio": 1.8484848484848484, "no_speech_prob": 5.949564183538314e-06}, {"id": 31, "seek": 13836, "start": 138.36, "end": 142.48000000000002, "text": " right, that, for example, have the scheduler, the file system, different drivers, and so", "tokens": [558, 11, 300, 11, 337, 1365, 11, 362, 264, 12000, 260, 11, 264, 3991, 1185, 11, 819, 11590, 11, 293, 370], "temperature": 0.0, "avg_logprob": -0.26268577575683594, "compression_ratio": 1.888030888030888, "no_speech_prob": 2.1202752122917445e-06}, {"id": 32, "seek": 13836, "start": 142.48000000000002, "end": 143.48000000000002, "text": " on.", "tokens": [322, 13], "temperature": 0.0, "avg_logprob": -0.26268577575683594, "compression_ratio": 1.888030888030888, "no_speech_prob": 2.1202752122917445e-06}, {"id": 33, "seek": 13836, "start": 143.48000000000002, "end": 148.44000000000003, "text": " So, in particular, when we have a scheduler, a scheduler is going to choose what is the", "tokens": [407, 11, 294, 1729, 11, 562, 321, 362, 257, 12000, 260, 11, 257, 12000, 260, 307, 516, 281, 2826, 437, 307, 264], "temperature": 0.0, "avg_logprob": -0.26268577575683594, "compression_ratio": 1.888030888030888, "no_speech_prob": 2.1202752122917445e-06}, {"id": 34, "seek": 13836, "start": 148.44000000000003, "end": 151.16000000000003, "text": " next process that's going to be executed.", "tokens": [958, 1399, 300, 311, 516, 281, 312, 17577, 13], "temperature": 0.0, "avg_logprob": -0.26268577575683594, "compression_ratio": 1.888030888030888, "no_speech_prob": 2.1202752122917445e-06}, {"id": 35, "seek": 13836, "start": 151.16000000000003, "end": 155.48000000000002, "text": " One of these processes, or several of them, is going to be your MPI application, for example.", "tokens": [1485, 295, 613, 7555, 11, 420, 2940, 295, 552, 11, 307, 516, 281, 312, 428, 14146, 40, 3861, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.26268577575683594, "compression_ratio": 1.888030888030888, "no_speech_prob": 2.1202752122917445e-06}, {"id": 36, "seek": 13836, "start": 155.48000000000002, "end": 162.92000000000002, "text": " So, if you deploy your MPI application in a, by using a general proposal, but as a system,", "tokens": [407, 11, 498, 291, 7274, 428, 14146, 40, 3861, 294, 257, 11, 538, 1228, 257, 2674, 11494, 11, 457, 382, 257, 1185, 11], "temperature": 0.0, "avg_logprob": -0.26268577575683594, "compression_ratio": 1.888030888030888, "no_speech_prob": 2.1202752122917445e-06}, {"id": 37, "seek": 13836, "start": 162.92000000000002, "end": 166.4, "text": " your application is going to compete with other processes in the system for sure.", "tokens": [428, 3861, 307, 516, 281, 11831, 365, 661, 7555, 294, 264, 1185, 337, 988, 13], "temperature": 0.0, "avg_logprob": -0.26268577575683594, "compression_ratio": 1.888030888030888, "no_speech_prob": 2.1202752122917445e-06}, {"id": 38, "seek": 16640, "start": 166.4, "end": 170.76000000000002, "text": " And also, what you have in the scheduler is some policy, which is going to decide which", "tokens": [400, 611, 11, 437, 291, 362, 294, 264, 12000, 260, 307, 512, 3897, 11, 597, 307, 516, 281, 4536, 597], "temperature": 0.0, "avg_logprob": -0.20104137420654297, "compression_ratio": 1.8193832599118942, "no_speech_prob": 1.5645068742742296e-06}, {"id": 39, "seek": 16640, "start": 170.76000000000002, "end": 175.08, "text": " is the next process to be deployed.", "tokens": [307, 264, 958, 1399, 281, 312, 17826, 13], "temperature": 0.0, "avg_logprob": -0.20104137420654297, "compression_ratio": 1.8193832599118942, "no_speech_prob": 1.5645068742742296e-06}, {"id": 40, "seek": 16640, "start": 175.08, "end": 180.84, "text": " Also, we have components like the file system, and since we have a general proposal processing", "tokens": [2743, 11, 321, 362, 6677, 411, 264, 3991, 1185, 11, 293, 1670, 321, 362, 257, 2674, 11494, 9007], "temperature": 0.0, "avg_logprob": -0.20104137420654297, "compression_ratio": 1.8193832599118942, "no_speech_prob": 1.5645068742742296e-06}, {"id": 41, "seek": 16640, "start": 180.84, "end": 185.44, "text": " system, we're going to have several drivers for different file systems, and different", "tokens": [1185, 11, 321, 434, 516, 281, 362, 2940, 11590, 337, 819, 3991, 3652, 11, 293, 819], "temperature": 0.0, "avg_logprob": -0.20104137420654297, "compression_ratio": 1.8193832599118942, "no_speech_prob": 1.5645068742742296e-06}, {"id": 42, "seek": 16640, "start": 185.44, "end": 187.6, "text": " drivers, and so on.", "tokens": [11590, 11, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.20104137420654297, "compression_ratio": 1.8193832599118942, "no_speech_prob": 1.5645068742742296e-06}, {"id": 43, "seek": 16640, "start": 187.6, "end": 194.6, "text": " So, what some people observed was that there were too much generality in using a general", "tokens": [407, 11, 437, 512, 561, 13095, 390, 300, 456, 645, 886, 709, 1337, 1860, 294, 1228, 257, 2674], "temperature": 0.0, "avg_logprob": -0.20104137420654297, "compression_ratio": 1.8193832599118942, "no_speech_prob": 1.5645068742742296e-06}, {"id": 44, "seek": 19460, "start": 194.6, "end": 201.12, "text": " proposal processing system for a single proposed application, like, can be an MPI.", "tokens": [11494, 9007, 1185, 337, 257, 2167, 10348, 3861, 11, 411, 11, 393, 312, 364, 14146, 40, 13], "temperature": 0.0, "avg_logprob": -0.24708092212677002, "compression_ratio": 1.640625, "no_speech_prob": 2.2578205971512944e-06}, {"id": 45, "seek": 19460, "start": 201.12, "end": 208.24, "text": " So, some people come up with a new architecture, they propose what they call Unicolonial.", "tokens": [407, 11, 512, 561, 808, 493, 365, 257, 777, 9482, 11, 436, 17421, 437, 436, 818, 1156, 299, 38780, 831, 13], "temperature": 0.0, "avg_logprob": -0.24708092212677002, "compression_ratio": 1.640625, "no_speech_prob": 2.2578205971512944e-06}, {"id": 46, "seek": 19460, "start": 208.24, "end": 213.4, "text": " You have some projects there, like OSV, Mirage OS, Unicrash, or Nano VMs.", "tokens": [509, 362, 512, 4455, 456, 11, 411, 12731, 53, 11, 9421, 609, 12731, 11, 1156, 299, 81, 1299, 11, 420, 43511, 18038, 82, 13], "temperature": 0.0, "avg_logprob": -0.24708092212677002, "compression_ratio": 1.640625, "no_speech_prob": 2.2578205971512944e-06}, {"id": 47, "seek": 19460, "start": 213.4, "end": 218.51999999999998, "text": " What they do is just take the user application and compile it within the kernel itself.", "tokens": [708, 436, 360, 307, 445, 747, 264, 4195, 3861, 293, 31413, 309, 1951, 264, 28256, 2564, 13], "temperature": 0.0, "avg_logprob": -0.24708092212677002, "compression_ratio": 1.640625, "no_speech_prob": 2.2578205971512944e-06}, {"id": 48, "seek": 19460, "start": 218.51999999999998, "end": 224.2, "text": " So, at the end, what you have is a single binary that is going to be deployed, either", "tokens": [407, 11, 412, 264, 917, 11, 437, 291, 362, 307, 257, 2167, 17434, 300, 307, 516, 281, 312, 17826, 11, 2139], "temperature": 0.0, "avg_logprob": -0.24708092212677002, "compression_ratio": 1.640625, "no_speech_prob": 2.2578205971512944e-06}, {"id": 49, "seek": 22420, "start": 224.2, "end": 228.48, "text": " by using a virtual machine or a bare metal, right?", "tokens": [538, 1228, 257, 6374, 3479, 420, 257, 6949, 5760, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.27366122077493105, "compression_ratio": 1.7633928571428572, "no_speech_prob": 1.3584274256572826e-06}, {"id": 50, "seek": 22420, "start": 228.48, "end": 234.07999999999998, "text": " So, instead of, for example, having syscalls that we have in the case that we have a general", "tokens": [407, 11, 2602, 295, 11, 337, 1365, 11, 1419, 262, 749, 66, 39655, 300, 321, 362, 294, 264, 1389, 300, 321, 362, 257, 2674], "temperature": 0.0, "avg_logprob": -0.27366122077493105, "compression_ratio": 1.7633928571428572, "no_speech_prob": 1.3584274256572826e-06}, {"id": 51, "seek": 22420, "start": 234.07999999999998, "end": 238.88, "text": " proposal processing system and different modes of execution, in the case of a Unicolonial,", "tokens": [11494, 9007, 1185, 293, 819, 14068, 295, 15058, 11, 294, 264, 1389, 295, 257, 1156, 299, 38780, 831, 11], "temperature": 0.0, "avg_logprob": -0.27366122077493105, "compression_ratio": 1.7633928571428572, "no_speech_prob": 1.3584274256572826e-06}, {"id": 52, "seek": 22420, "start": 238.88, "end": 248.48, "text": " we have simply calls, which are cheaper than using syscalls, for example.", "tokens": [321, 362, 2935, 5498, 11, 597, 366, 12284, 813, 1228, 262, 749, 66, 39655, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.27366122077493105, "compression_ratio": 1.7633928571428572, "no_speech_prob": 1.3584274256572826e-06}, {"id": 53, "seek": 22420, "start": 248.48, "end": 252.28, "text": " In general, the projects, the projects that I presented before all come forward to the", "tokens": [682, 2674, 11, 264, 4455, 11, 264, 4455, 300, 286, 8212, 949, 439, 808, 2128, 281, 264], "temperature": 0.0, "avg_logprob": -0.27366122077493105, "compression_ratio": 1.7633928571428572, "no_speech_prob": 1.3584274256572826e-06}, {"id": 54, "seek": 25228, "start": 252.28, "end": 257.68, "text": " epoxy standard, so it means that if you have any application written in C that come forward", "tokens": [45397, 3832, 11, 370, 309, 1355, 300, 498, 291, 362, 604, 3861, 3720, 294, 383, 300, 808, 2128], "temperature": 0.0, "avg_logprob": -0.2401452671397816, "compression_ratio": 1.854251012145749, "no_speech_prob": 1.4629548786615487e-05}, {"id": 55, "seek": 25228, "start": 257.68, "end": 264.4, "text": " epoxy, you can theoretically compile with the Unicolonial without any modification of", "tokens": [45397, 11, 291, 393, 29400, 31413, 365, 264, 1156, 299, 38780, 831, 1553, 604, 26747, 295], "temperature": 0.0, "avg_logprob": -0.2401452671397816, "compression_ratio": 1.854251012145749, "no_speech_prob": 1.4629548786615487e-05}, {"id": 56, "seek": 25228, "start": 264.4, "end": 265.88, "text": " the user application.", "tokens": [264, 4195, 3861, 13], "temperature": 0.0, "avg_logprob": -0.2401452671397816, "compression_ratio": 1.854251012145749, "no_speech_prob": 1.4629548786615487e-05}, {"id": 57, "seek": 25228, "start": 265.88, "end": 270.08, "text": " In reality, this does not happen, and most of the time, the epoxy that the Unicolonial", "tokens": [682, 4103, 11, 341, 775, 406, 1051, 11, 293, 881, 295, 264, 565, 11, 264, 45397, 300, 264, 1156, 299, 38780, 831], "temperature": 0.0, "avg_logprob": -0.2401452671397816, "compression_ratio": 1.854251012145749, "no_speech_prob": 1.4629548786615487e-05}, {"id": 58, "seek": 25228, "start": 270.08, "end": 275.4, "text": " implement is not complete, so you have to do some work to just, you cannot just take", "tokens": [4445, 307, 406, 3566, 11, 370, 291, 362, 281, 360, 512, 589, 281, 445, 11, 291, 2644, 445, 747], "temperature": 0.0, "avg_logprob": -0.2401452671397816, "compression_ratio": 1.854251012145749, "no_speech_prob": 1.4629548786615487e-05}, {"id": 59, "seek": 25228, "start": 275.4, "end": 279.36, "text": " your application and compile it and generate something, it doesn't work out of the box", "tokens": [428, 3861, 293, 31413, 309, 293, 8460, 746, 11, 309, 1177, 380, 589, 484, 295, 264, 2424], "temperature": 0.0, "avg_logprob": -0.2401452671397816, "compression_ratio": 1.854251012145749, "no_speech_prob": 1.4629548786615487e-05}, {"id": 60, "seek": 27936, "start": 279.36, "end": 282.44, "text": " in most of the cases, right?", "tokens": [294, 881, 295, 264, 3331, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.22423926905581826, "compression_ratio": 1.6274509803921569, "no_speech_prob": 2.7210610369365895e-06}, {"id": 61, "seek": 27936, "start": 282.44, "end": 288.36, "text": " So, in this context, what is total is also a Unicolonial, it's an application-oriented", "tokens": [407, 11, 294, 341, 4319, 11, 437, 307, 3217, 307, 611, 257, 1156, 299, 38780, 831, 11, 309, 311, 364, 3861, 12, 27414], "temperature": 0.0, "avg_logprob": -0.22423926905581826, "compression_ratio": 1.6274509803921569, "no_speech_prob": 2.7210610369365895e-06}, {"id": 62, "seek": 27936, "start": 288.36, "end": 295.6, "text": " Unicolonial, and the idea of total is to offer an API which is dedicated, I mean, to efficiently", "tokens": [1156, 299, 38780, 831, 11, 293, 264, 1558, 295, 3217, 307, 281, 2626, 364, 9362, 597, 307, 8374, 11, 286, 914, 11, 281, 19621], "temperature": 0.0, "avg_logprob": -0.22423926905581826, "compression_ratio": 1.6274509803921569, "no_speech_prob": 2.7210610369365895e-06}, {"id": 63, "seek": 27936, "start": 295.6, "end": 299.04, "text": " deploy parallel application.", "tokens": [7274, 8952, 3861, 13], "temperature": 0.0, "avg_logprob": -0.22423926905581826, "compression_ratio": 1.6274509803921569, "no_speech_prob": 2.7210610369365895e-06}, {"id": 64, "seek": 27936, "start": 299.04, "end": 304.36, "text": " In the case of total, it is, it's not a epoxy complaint, it means that even if the nail of", "tokens": [682, 264, 1389, 295, 3217, 11, 309, 307, 11, 309, 311, 406, 257, 45397, 20100, 11, 309, 1355, 300, 754, 498, 264, 10173, 295], "temperature": 0.0, "avg_logprob": -0.22423926905581826, "compression_ratio": 1.6274509803921569, "no_speech_prob": 2.7210610369365895e-06}, {"id": 65, "seek": 30436, "start": 304.36, "end": 309.40000000000003, "text": " the functions like this opens in close and so on, it's more or less the same nail, the", "tokens": [264, 6828, 411, 341, 9870, 294, 1998, 293, 370, 322, 11, 309, 311, 544, 420, 1570, 264, 912, 10173, 11, 264], "temperature": 0.0, "avg_logprob": -0.2742715615492601, "compression_ratio": 1.6363636363636365, "no_speech_prob": 4.511785391514422e-06}, {"id": 66, "seek": 30436, "start": 309.40000000000003, "end": 314.24, "text": " semantic of this function is slightly different, so I will not say that it's a epoxy complaint", "tokens": [47982, 295, 341, 2445, 307, 4748, 819, 11, 370, 286, 486, 406, 584, 300, 309, 311, 257, 45397, 20100], "temperature": 0.0, "avg_logprob": -0.2742715615492601, "compression_ratio": 1.6363636363636365, "no_speech_prob": 4.511785391514422e-06}, {"id": 67, "seek": 30436, "start": 314.24, "end": 318.44, "text": " in that sense, and I will explain that later.", "tokens": [294, 300, 2020, 11, 293, 286, 486, 2903, 300, 1780, 13], "temperature": 0.0, "avg_logprob": -0.2742715615492601, "compression_ratio": 1.6363636363636365, "no_speech_prob": 4.511785391514422e-06}, {"id": 68, "seek": 30436, "start": 318.44, "end": 325.44, "text": " So, let's say that the three building blocks of the total Unicolonial are the memory per", "tokens": [407, 11, 718, 311, 584, 300, 264, 1045, 2390, 8474, 295, 264, 3217, 1156, 299, 38780, 831, 366, 264, 4675, 680], "temperature": 0.0, "avg_logprob": -0.2742715615492601, "compression_ratio": 1.6363636363636365, "no_speech_prob": 4.511785391514422e-06}, {"id": 69, "seek": 30436, "start": 325.44, "end": 331.08000000000004, "text": " core, cooperative scheduler, and core-to-core communication based on built IEA.", "tokens": [4965, 11, 31772, 12000, 260, 11, 293, 4965, 12, 1353, 12, 12352, 6101, 2361, 322, 3094, 286, 36, 32, 13], "temperature": 0.0, "avg_logprob": -0.2742715615492601, "compression_ratio": 1.6363636363636365, "no_speech_prob": 4.511785391514422e-06}, {"id": 70, "seek": 33108, "start": 331.08, "end": 335.56, "text": " Here I'm talking about the architect of the Unicolonial, I'm not talking about yet the", "tokens": [1692, 286, 478, 1417, 466, 264, 6331, 295, 264, 1156, 299, 38780, 831, 11, 286, 478, 406, 1417, 466, 1939, 264], "temperature": 0.0, "avg_logprob": -0.2404197618073108, "compression_ratio": 1.7167381974248928, "no_speech_prob": 5.415126906882506e-06}, {"id": 71, "seek": 33108, "start": 335.56, "end": 339.76, "text": " application of how we're going to build an application to compile tutorial, right?", "tokens": [3861, 295, 577, 321, 434, 516, 281, 1322, 364, 3861, 281, 31413, 7073, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2404197618073108, "compression_ratio": 1.7167381974248928, "no_speech_prob": 5.415126906882506e-06}, {"id": 72, "seek": 33108, "start": 339.76, "end": 342.76, "text": " And I'm going to explain these three points.", "tokens": [400, 286, 478, 516, 281, 2903, 613, 1045, 2793, 13], "temperature": 0.0, "avg_logprob": -0.2404197618073108, "compression_ratio": 1.7167381974248928, "no_speech_prob": 5.415126906882506e-06}, {"id": 73, "seek": 33108, "start": 342.76, "end": 348.36, "text": " So, first, what happened in the total Unicolonial is that we have memory dedicated per core,", "tokens": [407, 11, 700, 11, 437, 2011, 294, 264, 3217, 1156, 299, 38780, 831, 307, 300, 321, 362, 4675, 8374, 680, 4965, 11], "temperature": 0.0, "avg_logprob": -0.2404197618073108, "compression_ratio": 1.7167381974248928, "no_speech_prob": 5.415126906882506e-06}, {"id": 74, "seek": 33108, "start": 348.36, "end": 354.15999999999997, "text": " so at the beginning what we do is just allocate memory, I mean, to split the whole memory in", "tokens": [370, 412, 264, 2863, 437, 321, 360, 307, 445, 35713, 4675, 11, 286, 914, 11, 281, 7472, 264, 1379, 4675, 294], "temperature": 0.0, "avg_logprob": -0.2404197618073108, "compression_ratio": 1.7167381974248928, "no_speech_prob": 5.415126906882506e-06}, {"id": 75, "seek": 35416, "start": 354.16, "end": 361.56, "text": " rations and we assign these rations per core, and for the moment the size of these rations", "tokens": [367, 763, 293, 321, 6269, 613, 367, 763, 680, 4965, 11, 293, 337, 264, 1623, 264, 2744, 295, 613, 367, 763], "temperature": 0.0, "avg_logprob": -0.2130995913668796, "compression_ratio": 1.8808510638297873, "no_speech_prob": 1.0095228390127886e-05}, {"id": 76, "seek": 35416, "start": 361.56, "end": 366.48, "text": " is just proportional to the number of cores that we have.", "tokens": [307, 445, 24969, 281, 264, 1230, 295, 24826, 300, 321, 362, 13], "temperature": 0.0, "avg_logprob": -0.2130995913668796, "compression_ratio": 1.8808510638297873, "no_speech_prob": 1.0095228390127886e-05}, {"id": 77, "seek": 35416, "start": 366.48, "end": 371.88, "text": " That makes that, for example, the memory allocator is quite simple, it doesn't require any communication", "tokens": [663, 1669, 300, 11, 337, 1365, 11, 264, 4675, 12660, 1639, 307, 1596, 2199, 11, 309, 1177, 380, 3651, 604, 6101], "temperature": 0.0, "avg_logprob": -0.2130995913668796, "compression_ratio": 1.8808510638297873, "no_speech_prob": 1.0095228390127886e-05}, {"id": 78, "seek": 35416, "start": 371.88, "end": 378.48, "text": " because we have chunks of data, I mean, yeah, the allocator is, we have one allocator per", "tokens": [570, 321, 362, 24004, 295, 1412, 11, 286, 914, 11, 1338, 11, 264, 12660, 1639, 307, 11, 321, 362, 472, 12660, 1639, 680], "temperature": 0.0, "avg_logprob": -0.2130995913668796, "compression_ratio": 1.8808510638297873, "no_speech_prob": 1.0095228390127886e-05}, {"id": 79, "seek": 35416, "start": 378.48, "end": 382.16, "text": " core which means that we don't require any synchronization in the kernel to allocate", "tokens": [4965, 597, 1355, 300, 321, 500, 380, 3651, 604, 19331, 2144, 294, 264, 28256, 281, 35713], "temperature": 0.0, "avg_logprob": -0.2130995913668796, "compression_ratio": 1.8808510638297873, "no_speech_prob": 1.0095228390127886e-05}, {"id": 80, "seek": 35416, "start": 382.16, "end": 383.16, "text": " for one core.", "tokens": [337, 472, 4965, 13], "temperature": 0.0, "avg_logprob": -0.2130995913668796, "compression_ratio": 1.8808510638297873, "no_speech_prob": 1.0095228390127886e-05}, {"id": 81, "seek": 38316, "start": 383.16, "end": 388.44, "text": " It's quite, we call it per CPU data, let's say, yeah.", "tokens": [467, 311, 1596, 11, 321, 818, 309, 680, 13199, 1412, 11, 718, 311, 584, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.27868738770484924, "compression_ratio": 1.7047970479704797, "no_speech_prob": 4.925056146021234e-06}, {"id": 82, "seek": 38316, "start": 388.44, "end": 393.64000000000004, "text": " So, for example, if you have a thread in a core one and we want to locate memory, we're", "tokens": [407, 11, 337, 1365, 11, 498, 291, 362, 257, 7207, 294, 257, 4965, 472, 293, 321, 528, 281, 22370, 4675, 11, 321, 434], "temperature": 0.0, "avg_logprob": -0.27868738770484924, "compression_ratio": 1.7047970479704797, "no_speech_prob": 4.925056146021234e-06}, {"id": 83, "seek": 38316, "start": 393.64000000000004, "end": 397.44000000000005, "text": " going always to get it from the same rations and that happens also if you're on the core", "tokens": [516, 1009, 281, 483, 309, 490, 264, 912, 367, 763, 293, 300, 2314, 611, 498, 291, 434, 322, 264, 4965], "temperature": 0.0, "avg_logprob": -0.27868738770484924, "compression_ratio": 1.7047970479704797, "no_speech_prob": 4.925056146021234e-06}, {"id": 84, "seek": 38316, "start": 397.44000000000005, "end": 400.76000000000005, "text": " two, we're going to use the rations, from rations two.", "tokens": [732, 11, 321, 434, 516, 281, 764, 264, 367, 763, 11, 490, 367, 763, 732, 13], "temperature": 0.0, "avg_logprob": -0.27868738770484924, "compression_ratio": 1.7047970479704797, "no_speech_prob": 4.925056146021234e-06}, {"id": 85, "seek": 38316, "start": 400.76000000000005, "end": 405.16, "text": " And the idea is that by doing this, we can then leverage technologies like hypertransport", "tokens": [400, 264, 1558, 307, 300, 538, 884, 341, 11, 321, 393, 550, 13982, 7943, 411, 9848, 24999, 2707], "temperature": 0.0, "avg_logprob": -0.27868738770484924, "compression_ratio": 1.7047970479704797, "no_speech_prob": 4.925056146021234e-06}, {"id": 86, "seek": 38316, "start": 405.16, "end": 409.92, "text": " or interquit path interconnect in which we can say, well, this core is going to access", "tokens": [420, 728, 358, 270, 3100, 26253, 294, 597, 321, 393, 584, 11, 731, 11, 341, 4965, 307, 516, 281, 2105], "temperature": 0.0, "avg_logprob": -0.27868738770484924, "compression_ratio": 1.7047970479704797, "no_speech_prob": 4.925056146021234e-06}, {"id": 87, "seek": 40992, "start": 409.92, "end": 414.2, "text": " this rations of memory and if you access all the rations, it's going to get a penalty", "tokens": [341, 367, 763, 295, 4675, 293, 498, 291, 2105, 439, 264, 367, 763, 11, 309, 311, 516, 281, 483, 257, 16263], "temperature": 0.0, "avg_logprob": -0.28131832122802736, "compression_ratio": 1.6936936936936937, "no_speech_prob": 2.767201067399583e-06}, {"id": 88, "seek": 40992, "start": 414.2, "end": 416.16, "text": " to do it, right?", "tokens": [281, 360, 309, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.28131832122802736, "compression_ratio": 1.6936936936936937, "no_speech_prob": 2.767201067399583e-06}, {"id": 89, "seek": 40992, "start": 416.16, "end": 422.72, "text": " So, talking about the scheduler, what happened in total is that we only have thread, so we", "tokens": [407, 11, 1417, 466, 264, 12000, 260, 11, 437, 2011, 294, 3217, 307, 300, 321, 787, 362, 7207, 11, 370, 321], "temperature": 0.0, "avg_logprob": -0.28131832122802736, "compression_ratio": 1.6936936936936937, "no_speech_prob": 2.767201067399583e-06}, {"id": 90, "seek": 40992, "start": 422.72, "end": 429.72, "text": " don't have process means that we, all threads share the view of the memory and we have mainly", "tokens": [500, 380, 362, 1399, 1355, 300, 321, 11, 439, 19314, 2073, 264, 1910, 295, 264, 4675, 293, 321, 362, 8704], "temperature": 0.0, "avg_logprob": -0.28131832122802736, "compression_ratio": 1.6936936936936937, "no_speech_prob": 2.767201067399583e-06}, {"id": 91, "seek": 40992, "start": 429.72, "end": 434.92, "text": " one API to create thread, it's called a begin thread and it's the parameter that have to", "tokens": [472, 9362, 281, 1884, 7207, 11, 309, 311, 1219, 257, 1841, 7207, 293, 309, 311, 264, 13075, 300, 362, 281], "temperature": 0.0, "avg_logprob": -0.28131832122802736, "compression_ratio": 1.6936936936936937, "no_speech_prob": 2.767201067399583e-06}, {"id": 92, "seek": 43492, "start": 434.92, "end": 441.84000000000003, "text": " say in which core each thread is going to run.", "tokens": [584, 294, 597, 4965, 1184, 7207, 307, 516, 281, 1190, 13], "temperature": 0.0, "avg_logprob": -0.22329397108948346, "compression_ratio": 1.7863636363636364, "no_speech_prob": 4.278582309780177e-06}, {"id": 93, "seek": 43492, "start": 441.84000000000003, "end": 446.36, "text": " The scheduler scoperity, which means that it is the thread that's going to call the", "tokens": [440, 12000, 260, 795, 7192, 507, 11, 597, 1355, 300, 309, 307, 264, 7207, 300, 311, 516, 281, 818, 264], "temperature": 0.0, "avg_logprob": -0.22329397108948346, "compression_ratio": 1.7863636363636364, "no_speech_prob": 4.278582309780177e-06}, {"id": 94, "seek": 43492, "start": 446.36, "end": 452.36, "text": " scheduler to then choose another thread and this is by relying on the API call assist", "tokens": [12000, 260, 281, 550, 2826, 1071, 7207, 293, 341, 307, 538, 24140, 322, 264, 9362, 818, 4255], "temperature": 0.0, "avg_logprob": -0.22329397108948346, "compression_ratio": 1.7863636363636364, "no_speech_prob": 4.278582309780177e-06}, {"id": 95, "seek": 43492, "start": 452.36, "end": 457.6, "text": " thread switch and most of the time, this is just in bucket because we are going to be", "tokens": [7207, 3679, 293, 881, 295, 264, 565, 11, 341, 307, 445, 294, 13058, 570, 321, 366, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.22329397108948346, "compression_ratio": 1.7863636363636364, "no_speech_prob": 4.278582309780177e-06}, {"id": 96, "seek": 43492, "start": 457.6, "end": 462.08000000000004, "text": " idle for a while, so we just call the scheduler or we, for example, we're going to do some", "tokens": [30650, 337, 257, 1339, 11, 370, 321, 445, 818, 264, 12000, 260, 420, 321, 11, 337, 1365, 11, 321, 434, 516, 281, 360, 512], "temperature": 0.0, "avg_logprob": -0.22329397108948346, "compression_ratio": 1.7863636363636364, "no_speech_prob": 4.278582309780177e-06}, {"id": 97, "seek": 46208, "start": 462.08, "end": 465.47999999999996, "text": " IO.", "tokens": [39839, 13], "temperature": 0.0, "avg_logprob": -0.2104652828640408, "compression_ratio": 1.6956521739130435, "no_speech_prob": 4.351614279585192e-06}, {"id": 98, "seek": 46208, "start": 465.47999999999996, "end": 471.56, "text": " So the scheduler is also very simple, we have, again, first CPU data, so we have one", "tokens": [407, 264, 12000, 260, 307, 611, 588, 2199, 11, 321, 362, 11, 797, 11, 700, 13199, 1412, 11, 370, 321, 362, 472], "temperature": 0.0, "avg_logprob": -0.2104652828640408, "compression_ratio": 1.6956521739130435, "no_speech_prob": 4.351614279585192e-06}, {"id": 99, "seek": 46208, "start": 471.56, "end": 478.2, "text": " cube per core and the scheduler is simple going to choose the next thread that is ready", "tokens": [13728, 680, 4965, 293, 264, 12000, 260, 307, 2199, 516, 281, 2826, 264, 958, 7207, 300, 307, 1919], "temperature": 0.0, "avg_logprob": -0.2104652828640408, "compression_ratio": 1.6956521739130435, "no_speech_prob": 4.351614279585192e-06}, {"id": 100, "seek": 46208, "start": 478.2, "end": 483.52, "text": " and then the scheduler and this means that also we don't require any synchronization", "tokens": [293, 550, 264, 12000, 260, 293, 341, 1355, 300, 611, 321, 500, 380, 3651, 604, 19331, 2144], "temperature": 0.0, "avg_logprob": -0.2104652828640408, "compression_ratio": 1.6956521739130435, "no_speech_prob": 4.351614279585192e-06}, {"id": 101, "seek": 46208, "start": 483.52, "end": 488.59999999999997, "text": " at the level of the kernel to schedule a thread, so it's like each core run independently", "tokens": [412, 264, 1496, 295, 264, 28256, 281, 7567, 257, 7207, 11, 370, 309, 311, 411, 1184, 4965, 1190, 21761], "temperature": 0.0, "avg_logprob": -0.2104652828640408, "compression_ratio": 1.6956521739130435, "no_speech_prob": 4.351614279585192e-06}, {"id": 102, "seek": 48860, "start": 488.6, "end": 495.28000000000003, "text": " one for another.", "tokens": [472, 337, 1071, 13], "temperature": 0.0, "avg_logprob": -0.27322222969748755, "compression_ratio": 1.5104895104895104, "no_speech_prob": 6.634631972701754e-06}, {"id": 103, "seek": 48860, "start": 495.28000000000003, "end": 500.8, "text": " Fine I am going to talk a bit about how we communicate cores and basically what we have", "tokens": [12024, 286, 669, 516, 281, 751, 257, 857, 466, 577, 321, 7890, 24826, 293, 1936, 437, 321, 362], "temperature": 0.0, "avg_logprob": -0.27322222969748755, "compression_ratio": 1.5104895104895104, "no_speech_prob": 6.634631972701754e-06}, {"id": 104, "seek": 48860, "start": 500.8, "end": 509.28000000000003, "text": " is one dedicated reception cube per core for any other core in the system, so we have one", "tokens": [307, 472, 8374, 21682, 13728, 680, 4965, 337, 604, 661, 4965, 294, 264, 1185, 11, 370, 321, 362, 472], "temperature": 0.0, "avg_logprob": -0.27322222969748755, "compression_ratio": 1.5104895104895104, "no_speech_prob": 6.634631972701754e-06}, {"id": 105, "seek": 48860, "start": 509.28000000000003, "end": 512.84, "text": " to one communication.", "tokens": [281, 472, 6101, 13], "temperature": 0.0, "avg_logprob": -0.27322222969748755, "compression_ratio": 1.5104895104895104, "no_speech_prob": 6.634631972701754e-06}, {"id": 106, "seek": 51284, "start": 512.84, "end": 518.6800000000001, "text": " This basically relies on two primitives which is send and resist front and it's just by", "tokens": [639, 1936, 30910, 322, 732, 2886, 38970, 597, 307, 2845, 293, 4597, 1868, 293, 309, 311, 445, 538], "temperature": 0.0, "avg_logprob": -0.3475772557633646, "compression_ratio": 1.610091743119266, "no_speech_prob": 9.199409760185517e-06}, {"id": 107, "seek": 51284, "start": 518.6800000000001, "end": 527.08, "text": " using the destination core and from where we want to get a packet, for example.", "tokens": [1228, 264, 12236, 4965, 293, 490, 689, 321, 528, 281, 483, 257, 20300, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.3475772557633646, "compression_ratio": 1.610091743119266, "no_speech_prob": 9.199409760185517e-06}, {"id": 108, "seek": 51284, "start": 527.08, "end": 533.9200000000001, "text": " These two primitives are the ingridients to then build more complicated APIs like MPI", "tokens": [1981, 732, 2886, 38970, 366, 264, 3957, 8558, 2448, 281, 550, 1322, 544, 6179, 21445, 411, 14146, 40], "temperature": 0.0, "avg_logprob": -0.3475772557633646, "compression_ratio": 1.610091743119266, "no_speech_prob": 9.199409760185517e-06}, {"id": 109, "seek": 51284, "start": 533.9200000000001, "end": 539.1600000000001, "text": " gutter, MPI because and MPI scatter, so these are the building blocks for those API, for", "tokens": [5228, 391, 11, 14146, 40, 570, 293, 14146, 40, 34951, 11, 370, 613, 366, 264, 2390, 8474, 337, 729, 9362, 11, 337], "temperature": 0.0, "avg_logprob": -0.3475772557633646, "compression_ratio": 1.610091743119266, "no_speech_prob": 9.199409760185517e-06}, {"id": 110, "seek": 51284, "start": 539.1600000000001, "end": 541.96, "text": " example.", "tokens": [1365, 13], "temperature": 0.0, "avg_logprob": -0.3475772557633646, "compression_ratio": 1.610091743119266, "no_speech_prob": 9.199409760185517e-06}, {"id": 111, "seek": 54196, "start": 541.96, "end": 546.8000000000001, "text": " So to implement this core-to-core communication, I was using butaio, so I was just following", "tokens": [407, 281, 4445, 341, 4965, 12, 1353, 12, 12352, 6101, 11, 286, 390, 1228, 457, 64, 1004, 11, 370, 286, 390, 445, 3480], "temperature": 0.0, "avg_logprob": -0.25183508369360075, "compression_ratio": 1.6203703703703705, "no_speech_prob": 2.593537101347465e-05}, {"id": 112, "seek": 54196, "start": 546.8000000000001, "end": 553.32, "text": " the specification, I will talk a little bit about this, I don't want to go too much into", "tokens": [264, 31256, 11, 286, 486, 751, 257, 707, 857, 466, 341, 11, 286, 500, 380, 528, 281, 352, 886, 709, 666], "temperature": 0.0, "avg_logprob": -0.25183508369360075, "compression_ratio": 1.6203703703703705, "no_speech_prob": 2.593537101347465e-05}, {"id": 113, "seek": 54196, "start": 553.32, "end": 559.08, "text": " detail so as to understand roughly how communication between core is done.", "tokens": [2607, 370, 382, 281, 1223, 9810, 577, 6101, 1296, 4965, 307, 1096, 13], "temperature": 0.0, "avg_logprob": -0.25183508369360075, "compression_ratio": 1.6203703703703705, "no_speech_prob": 2.593537101347465e-05}, {"id": 114, "seek": 54196, "start": 559.08, "end": 566.08, "text": " As I said before, we have one reception cube for each core, for any other core in the system,", "tokens": [1018, 286, 848, 949, 11, 321, 362, 472, 21682, 13728, 337, 1184, 4965, 11, 337, 604, 661, 4965, 294, 264, 1185, 11], "temperature": 0.0, "avg_logprob": -0.25183508369360075, "compression_ratio": 1.6203703703703705, "no_speech_prob": 2.593537101347465e-05}, {"id": 115, "seek": 56608, "start": 566.08, "end": 573.2800000000001, "text": " so means that, for example, if core one want to get packets from core two, we have a reception", "tokens": [370, 1355, 300, 11, 337, 1365, 11, 498, 4965, 472, 528, 281, 483, 30364, 490, 4965, 732, 11, 321, 362, 257, 21682], "temperature": 0.0, "avg_logprob": -0.2062045602237477, "compression_ratio": 1.8186813186813187, "no_speech_prob": 4.766489382745931e-06}, {"id": 116, "seek": 56608, "start": 573.2800000000001, "end": 579.5200000000001, "text": " cube and also if core one want to send a packet to core two, it's going to have a transmission", "tokens": [13728, 293, 611, 498, 4965, 472, 528, 281, 2845, 257, 20300, 281, 4965, 732, 11, 309, 311, 516, 281, 362, 257, 11574], "temperature": 0.0, "avg_logprob": -0.2062045602237477, "compression_ratio": 1.8186813186813187, "no_speech_prob": 4.766489382745931e-06}, {"id": 117, "seek": 56608, "start": 579.5200000000001, "end": 584.2800000000001, "text": " cube and the number of queues is going to be for sure different if you have three cores,", "tokens": [13728, 293, 264, 1230, 295, 631, 1247, 307, 516, 281, 312, 337, 988, 819, 498, 291, 362, 1045, 24826, 11], "temperature": 0.0, "avg_logprob": -0.2062045602237477, "compression_ratio": 1.8186813186813187, "no_speech_prob": 4.766489382745931e-06}, {"id": 118, "seek": 56608, "start": 584.2800000000001, "end": 590.9200000000001, "text": " for example, because the build queues are dedicated.", "tokens": [337, 1365, 11, 570, 264, 1322, 631, 1247, 366, 8374, 13], "temperature": 0.0, "avg_logprob": -0.2062045602237477, "compression_ratio": 1.8186813186813187, "no_speech_prob": 4.766489382745931e-06}, {"id": 119, "seek": 59092, "start": 590.92, "end": 596.12, "text": " So basically how a build queue works is made of three RINs buffers.", "tokens": [407, 1936, 577, 257, 1322, 18639, 1985, 307, 1027, 295, 1045, 497, 1464, 82, 9204, 433, 13], "temperature": 0.0, "avg_logprob": -0.21267005671625552, "compression_ratio": 1.7216494845360826, "no_speech_prob": 1.0322312846255954e-05}, {"id": 120, "seek": 59092, "start": 596.12, "end": 603.3199999999999, "text": " So the first RIN buffer is the buffer which only contains descriptors to chunks of memory.", "tokens": [407, 264, 700, 497, 1464, 21762, 307, 264, 21762, 597, 787, 8306, 31280, 830, 281, 24004, 295, 4675, 13], "temperature": 0.0, "avg_logprob": -0.21267005671625552, "compression_ratio": 1.7216494845360826, "no_speech_prob": 1.0322312846255954e-05}, {"id": 121, "seek": 59092, "start": 603.3199999999999, "end": 608.3199999999999, "text": " The second buffer is the aviable RIN and the third buffer is the user RIN.", "tokens": [440, 1150, 21762, 307, 264, 1305, 72, 712, 497, 1464, 293, 264, 2636, 21762, 307, 264, 4195, 497, 1464, 13], "temperature": 0.0, "avg_logprob": -0.21267005671625552, "compression_ratio": 1.7216494845360826, "no_speech_prob": 1.0322312846255954e-05}, {"id": 122, "seek": 59092, "start": 608.3199999999999, "end": 614.9599999999999, "text": " Basically what happens is the aviable RIN is the buffers that the core one are exposing", "tokens": [8537, 437, 2314, 307, 264, 1305, 72, 712, 497, 1464, 307, 264, 9204, 433, 300, 264, 4965, 472, 366, 33178], "temperature": 0.0, "avg_logprob": -0.21267005671625552, "compression_ratio": 1.7216494845360826, "no_speech_prob": 1.0322312846255954e-05}, {"id": 123, "seek": 59092, "start": 614.9599999999999, "end": 616.64, "text": " to core two.", "tokens": [281, 4965, 732, 13], "temperature": 0.0, "avg_logprob": -0.21267005671625552, "compression_ratio": 1.7216494845360826, "no_speech_prob": 1.0322312846255954e-05}, {"id": 124, "seek": 61664, "start": 616.64, "end": 622.3199999999999, "text": " So if the core two want to send a packet to core one, it's going to get a buffer from", "tokens": [407, 498, 264, 4965, 732, 528, 281, 2845, 257, 20300, 281, 4965, 472, 11, 309, 311, 516, 281, 483, 257, 21762, 490], "temperature": 0.0, "avg_logprob": -0.1649017649248612, "compression_ratio": 1.7679324894514767, "no_speech_prob": 1.4170004760671873e-05}, {"id": 125, "seek": 61664, "start": 622.3199999999999, "end": 626.56, "text": " aviable RIN, put the data and then put it again in the user RIN.", "tokens": [1305, 72, 712, 497, 1464, 11, 829, 264, 1412, 293, 550, 829, 309, 797, 294, 264, 4195, 497, 1464, 13], "temperature": 0.0, "avg_logprob": -0.1649017649248612, "compression_ratio": 1.7679324894514767, "no_speech_prob": 1.4170004760671873e-05}, {"id": 126, "seek": 61664, "start": 626.56, "end": 633.48, "text": " This is basically how build.io works, just that if you are familiar with build.io, in", "tokens": [639, 307, 1936, 577, 1322, 13, 1004, 1985, 11, 445, 300, 498, 291, 366, 4963, 365, 1322, 13, 1004, 11, 294], "temperature": 0.0, "avg_logprob": -0.1649017649248612, "compression_ratio": 1.7679324894514767, "no_speech_prob": 1.4170004760671873e-05}, {"id": 127, "seek": 61664, "start": 633.48, "end": 639.56, "text": " this case, for example, the consumer of aviable RIN is the core two, but if, for example,", "tokens": [341, 1389, 11, 337, 1365, 11, 264, 9711, 295, 1305, 72, 712, 497, 1464, 307, 264, 4965, 732, 11, 457, 498, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.1649017649248612, "compression_ratio": 1.7679324894514767, "no_speech_prob": 1.4170004760671873e-05}, {"id": 128, "seek": 61664, "start": 639.56, "end": 645.04, "text": " if you are in a hypervisor and you're implementing some build.io device, the consumer is not", "tokens": [498, 291, 366, 294, 257, 9848, 16457, 293, 291, 434, 18114, 512, 1322, 13, 1004, 4302, 11, 264, 9711, 307, 406], "temperature": 0.0, "avg_logprob": -0.1649017649248612, "compression_ratio": 1.7679324894514767, "no_speech_prob": 1.4170004760671873e-05}, {"id": 129, "seek": 64504, "start": 645.04, "end": 649.48, "text": " going to be the core two, but it's going to be the device model, QMU, for example, and", "tokens": [516, 281, 312, 264, 4965, 732, 11, 457, 309, 311, 516, 281, 312, 264, 4302, 2316, 11, 1249, 44, 52, 11, 337, 1365, 11, 293], "temperature": 0.0, "avg_logprob": -0.22962008295832453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 5.541474365600152e-06}, {"id": 130, "seek": 64504, "start": 649.48, "end": 650.8399999999999, "text": " if you are familiar with that.", "tokens": [498, 291, 366, 4963, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.22962008295832453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 5.541474365600152e-06}, {"id": 131, "seek": 64504, "start": 650.8399999999999, "end": 654.88, "text": " But it's the same scheme.", "tokens": [583, 309, 311, 264, 912, 12232, 13], "temperature": 0.0, "avg_logprob": -0.22962008295832453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 5.541474365600152e-06}, {"id": 132, "seek": 64504, "start": 654.88, "end": 660.9599999999999, "text": " This allows that, for example, since we have one producer and one consumer, we can access", "tokens": [639, 4045, 300, 11, 337, 1365, 11, 1670, 321, 362, 472, 12314, 293, 472, 9711, 11, 321, 393, 2105], "temperature": 0.0, "avg_logprob": -0.22962008295832453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 5.541474365600152e-06}, {"id": 133, "seek": 64504, "start": 660.9599999999999, "end": 668.28, "text": " to the build queue without any synchronization, I mean, at least if we have only one consumer.", "tokens": [281, 264, 1322, 18639, 1553, 604, 19331, 2144, 11, 286, 914, 11, 412, 1935, 498, 321, 362, 787, 472, 9711, 13], "temperature": 0.0, "avg_logprob": -0.22962008295832453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 5.541474365600152e-06}, {"id": 134, "seek": 64504, "start": 668.28, "end": 673.8399999999999, "text": " So you don't require any luck, for example, to access to the build queue.", "tokens": [407, 291, 500, 380, 3651, 604, 3668, 11, 337, 1365, 11, 281, 2105, 281, 264, 1322, 18639, 13], "temperature": 0.0, "avg_logprob": -0.22962008295832453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 5.541474365600152e-06}, {"id": 135, "seek": 67384, "start": 673.84, "end": 678.88, "text": " So yeah, I already talked too much, I don't know how much time I have left, but I wanted", "tokens": [407, 1338, 11, 286, 1217, 2825, 886, 709, 11, 286, 500, 380, 458, 577, 709, 565, 286, 362, 1411, 11, 457, 286, 1415], "temperature": 0.0, "avg_logprob": -0.30588804815233367, "compression_ratio": 1.6, "no_speech_prob": 4.5181983296060935e-05}, {"id": 136, "seek": 67384, "start": 678.88, "end": 685.32, "text": " to show some examples about the implementation, maybe it's more fun that all the flyers should", "tokens": [281, 855, 512, 5110, 466, 264, 11420, 11, 1310, 309, 311, 544, 1019, 300, 439, 264, 3603, 433, 820], "temperature": 0.0, "avg_logprob": -0.30588804815233367, "compression_ratio": 1.6, "no_speech_prob": 4.5181983296060935e-05}, {"id": 137, "seek": 67384, "start": 685.32, "end": 686.32, "text": " show.", "tokens": [855, 13], "temperature": 0.0, "avg_logprob": -0.30588804815233367, "compression_ratio": 1.6, "no_speech_prob": 4.5181983296060935e-05}, {"id": 138, "seek": 67384, "start": 686.32, "end": 692.96, "text": " So what happened, how we, how we deploy an application by using Toiletware.", "tokens": [407, 437, 2011, 11, 577, 321, 11, 577, 321, 7274, 364, 3861, 538, 1228, 1407, 388, 302, 3039, 13], "temperature": 0.0, "avg_logprob": -0.30588804815233367, "compression_ratio": 1.6, "no_speech_prob": 4.5181983296060935e-05}, {"id": 139, "seek": 67384, "start": 692.96, "end": 698.36, "text": " We have the MPI application, this is a C application for the moment, and you compile it with a", "tokens": [492, 362, 264, 14146, 40, 3861, 11, 341, 307, 257, 383, 3861, 337, 264, 1623, 11, 293, 291, 31413, 309, 365, 257], "temperature": 0.0, "avg_logprob": -0.30588804815233367, "compression_ratio": 1.6, "no_speech_prob": 4.5181983296060935e-05}, {"id": 140, "seek": 69836, "start": 698.36, "end": 706.08, "text": " unit that's going just to link the application with some functions that are the implementation", "tokens": [4985, 300, 311, 516, 445, 281, 2113, 264, 3861, 365, 512, 6828, 300, 366, 264, 11420], "temperature": 0.0, "avg_logprob": -0.2514431407150713, "compression_ratio": 1.6294642857142858, "no_speech_prob": 5.629821680486202e-05}, {"id": 141, "seek": 69836, "start": 706.08, "end": 713.04, "text": " of the MPI, the MPI, for example, MPI Bicass, Gatter, and so on, it's implemented in this", "tokens": [295, 264, 14146, 40, 11, 264, 14146, 40, 11, 337, 1365, 11, 14146, 40, 363, 299, 640, 11, 460, 1161, 11, 293, 370, 322, 11, 309, 311, 12270, 294, 341], "temperature": 0.0, "avg_logprob": -0.2514431407150713, "compression_ratio": 1.6294642857142858, "no_speech_prob": 5.629821680486202e-05}, {"id": 142, "seek": 69836, "start": 713.04, "end": 715.44, "text": " level in the MPI interface.", "tokens": [1496, 294, 264, 14146, 40, 9226, 13], "temperature": 0.0, "avg_logprob": -0.2514431407150713, "compression_ratio": 1.6294642857142858, "no_speech_prob": 5.629821680486202e-05}, {"id": 143, "seek": 69836, "start": 715.44, "end": 719.6800000000001, "text": " And this unit is going to use some MPI from the unique kernel.", "tokens": [400, 341, 4985, 307, 516, 281, 764, 512, 14146, 40, 490, 264, 3845, 28256, 13], "temperature": 0.0, "avg_logprob": -0.2514431407150713, "compression_ratio": 1.6294642857142858, "no_speech_prob": 5.629821680486202e-05}, {"id": 144, "seek": 69836, "start": 719.6800000000001, "end": 724.28, "text": " So at the end, what you're going to get is an ELF and binary that could be used to deploy", "tokens": [407, 412, 264, 917, 11, 437, 291, 434, 516, 281, 483, 307, 364, 14426, 37, 293, 17434, 300, 727, 312, 1143, 281, 7274], "temperature": 0.0, "avg_logprob": -0.2514431407150713, "compression_ratio": 1.6294642857142858, "no_speech_prob": 5.629821680486202e-05}, {"id": 145, "seek": 72428, "start": 724.28, "end": 729.1999999999999, "text": " your application, either as a built-in machine or a bare metal.", "tokens": [428, 3861, 11, 2139, 382, 257, 3094, 12, 259, 3479, 420, 257, 6949, 5760, 13], "temperature": 0.0, "avg_logprob": -0.267111759185791, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.2473974392341916e-06}, {"id": 146, "seek": 72428, "start": 729.1999999999999, "end": 735.76, "text": " So you don't have any operating system intermediate there, you have only your application, the", "tokens": [407, 291, 500, 380, 362, 604, 7447, 1185, 19376, 456, 11, 291, 362, 787, 428, 3861, 11, 264], "temperature": 0.0, "avg_logprob": -0.267111759185791, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.2473974392341916e-06}, {"id": 147, "seek": 72428, "start": 735.76, "end": 740.88, "text": " threads and so on, but you don't have nothing else.", "tokens": [19314, 293, 370, 322, 11, 457, 291, 500, 380, 362, 1825, 1646, 13], "temperature": 0.0, "avg_logprob": -0.267111759185791, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.2473974392341916e-06}, {"id": 148, "seek": 72428, "start": 740.88, "end": 745.3199999999999, "text": " So if you want to see how it is deployed, if you get the MPI application that doesn't", "tokens": [407, 498, 291, 528, 281, 536, 577, 309, 307, 17826, 11, 498, 291, 483, 264, 14146, 40, 3861, 300, 1177, 380], "temperature": 0.0, "avg_logprob": -0.267111759185791, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.2473974392341916e-06}, {"id": 149, "seek": 72428, "start": 745.3199999999999, "end": 750.92, "text": " see what is going to happen, we're going to get the main and then instantiate it to one", "tokens": [536, 437, 307, 516, 281, 1051, 11, 321, 434, 516, 281, 483, 264, 2135, 293, 550, 9836, 13024, 309, 281, 472], "temperature": 0.0, "avg_logprob": -0.267111759185791, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.2473974392341916e-06}, {"id": 150, "seek": 75092, "start": 750.92, "end": 761.5999999999999, "text": " for every core in the system, as a thread.", "tokens": [337, 633, 4965, 294, 264, 1185, 11, 382, 257, 7207, 13], "temperature": 0.0, "avg_logprob": -0.28824892911044037, "compression_ratio": 1.6684491978609626, "no_speech_prob": 1.8295304471394047e-05}, {"id": 151, "seek": 75092, "start": 761.5999999999999, "end": 766.64, "text": " So to benchmark the current implementation, I'm not very familiar with the MPI where I", "tokens": [407, 281, 18927, 264, 2190, 11420, 11, 286, 478, 406, 588, 4963, 365, 264, 14146, 40, 689, 286], "temperature": 0.0, "avg_logprob": -0.28824892911044037, "compression_ratio": 1.6684491978609626, "no_speech_prob": 1.8295304471394047e-05}, {"id": 152, "seek": 75092, "start": 766.64, "end": 771.16, "text": " was just coming from another domain, so I am not really familiar with how I had to benchmark", "tokens": [390, 445, 1348, 490, 1071, 9274, 11, 370, 286, 669, 406, 534, 4963, 365, 577, 286, 632, 281, 18927], "temperature": 0.0, "avg_logprob": -0.28824892911044037, "compression_ratio": 1.6684491978609626, "no_speech_prob": 1.8295304471394047e-05}, {"id": 153, "seek": 75092, "start": 771.16, "end": 778.24, "text": " such implementation, and so I choose the also microbenchmarks, maybe you know them, maybe", "tokens": [1270, 11420, 11, 293, 370, 286, 2826, 264, 611, 4532, 47244, 37307, 11, 1310, 291, 458, 552, 11, 1310], "temperature": 0.0, "avg_logprob": -0.28824892911044037, "compression_ratio": 1.6684491978609626, "no_speech_prob": 1.8295304471394047e-05}, {"id": 154, "seek": 77824, "start": 778.24, "end": 786.6, "text": " not, and I just pick up one of them, like for example, MPI barrier, and I try to implement,", "tokens": [406, 11, 293, 286, 445, 1888, 493, 472, 295, 552, 11, 411, 337, 1365, 11, 14146, 40, 13357, 11, 293, 286, 853, 281, 4445, 11], "temperature": 0.0, "avg_logprob": -0.20328282336799466, "compression_ratio": 1.6919431279620853, "no_speech_prob": 2.563297857705038e-05}, {"id": 155, "seek": 77824, "start": 786.6, "end": 790.92, "text": " which is quite simple, the benchmark itself is quite simple, so I decided to implement", "tokens": [597, 307, 1596, 2199, 11, 264, 18927, 2564, 307, 1596, 2199, 11, 370, 286, 3047, 281, 4445], "temperature": 0.0, "avg_logprob": -0.20328282336799466, "compression_ratio": 1.6919431279620853, "no_speech_prob": 2.563297857705038e-05}, {"id": 156, "seek": 77824, "start": 790.92, "end": 791.92, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.20328282336799466, "compression_ratio": 1.6919431279620853, "no_speech_prob": 2.563297857705038e-05}, {"id": 157, "seek": 77824, "start": 791.92, "end": 800.08, "text": " I could not take the benchmark as it is, I have to do some rework to make it work, and", "tokens": [286, 727, 406, 747, 264, 18927, 382, 309, 307, 11, 286, 362, 281, 360, 512, 48376, 281, 652, 309, 589, 11, 293], "temperature": 0.0, "avg_logprob": -0.20328282336799466, "compression_ratio": 1.6919431279620853, "no_speech_prob": 2.563297857705038e-05}, {"id": 158, "seek": 77824, "start": 800.08, "end": 805.72, "text": " then my idea was to see how this behave when I was deploying this as a single VM, which", "tokens": [550, 452, 1558, 390, 281, 536, 577, 341, 15158, 562, 286, 390, 34198, 341, 382, 257, 2167, 18038, 11, 597], "temperature": 0.0, "avg_logprob": -0.20328282336799466, "compression_ratio": 1.6919431279620853, "no_speech_prob": 2.563297857705038e-05}, {"id": 159, "seek": 80572, "start": 805.72, "end": 809.0400000000001, "text": " many cores.", "tokens": [867, 24826, 13], "temperature": 0.0, "avg_logprob": -0.2582453636273946, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.696236697374843e-05}, {"id": 160, "seek": 80572, "start": 809.0400000000001, "end": 816.2, "text": " The hardware that I use is this one, since I'm not familiar with the high performance", "tokens": [440, 8837, 300, 286, 764, 307, 341, 472, 11, 1670, 286, 478, 406, 4963, 365, 264, 1090, 3389], "temperature": 0.0, "avg_logprob": -0.2582453636273946, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.696236697374843e-05}, {"id": 161, "seek": 80572, "start": 816.2, "end": 822.12, "text": " computing work, I'm not really sure if this is a hardware that you often use, it's quite", "tokens": [15866, 589, 11, 286, 478, 406, 534, 988, 498, 341, 307, 257, 8837, 300, 291, 2049, 764, 11, 309, 311, 1596], "temperature": 0.0, "avg_logprob": -0.2582453636273946, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.696236697374843e-05}, {"id": 162, "seek": 80572, "start": 822.12, "end": 834.52, "text": " a new Intel, you can get it in Equinex, the price is four euros per hour.", "tokens": [257, 777, 19762, 11, 291, 393, 483, 309, 294, 15624, 533, 87, 11, 264, 3218, 307, 1451, 14160, 680, 1773, 13], "temperature": 0.0, "avg_logprob": -0.2582453636273946, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.696236697374843e-05}, {"id": 163, "seek": 83452, "start": 834.52, "end": 839.4, "text": " So I launched the test and I tried to measure things, so I was just measuring the latency", "tokens": [407, 286, 8730, 264, 1500, 293, 286, 3031, 281, 3481, 721, 11, 370, 286, 390, 445, 13389, 264, 27043], "temperature": 0.0, "avg_logprob": -0.217739314567752, "compression_ratio": 1.6073298429319371, "no_speech_prob": 7.878503674874082e-05}, {"id": 164, "seek": 83452, "start": 839.4, "end": 847.28, "text": " of this, and I was taking into account the max latency through, I mean, over four, eight,", "tokens": [295, 341, 11, 293, 286, 390, 1940, 666, 2696, 264, 11469, 27043, 807, 11, 286, 914, 11, 670, 1451, 11, 3180, 11], "temperature": 0.0, "avg_logprob": -0.217739314567752, "compression_ratio": 1.6073298429319371, "no_speech_prob": 7.878503674874082e-05}, {"id": 165, "seek": 83452, "start": 847.28, "end": 851.12, "text": " sixteen, or thirty-two cores.", "tokens": [27847, 11, 420, 11790, 12, 20534, 24826, 13], "temperature": 0.0, "avg_logprob": -0.217739314567752, "compression_ratio": 1.6073298429319371, "no_speech_prob": 7.878503674874082e-05}, {"id": 166, "seek": 83452, "start": 851.12, "end": 859.76, "text": " I am getting values in the order of the microseconds, and then I found this paper, which was also", "tokens": [286, 669, 1242, 4190, 294, 264, 1668, 295, 264, 3123, 37841, 28750, 11, 293, 550, 286, 1352, 341, 3035, 11, 597, 390, 611], "temperature": 0.0, "avg_logprob": -0.217739314567752, "compression_ratio": 1.6073298429319371, "no_speech_prob": 7.878503674874082e-05}, {"id": 167, "seek": 85976, "start": 859.76, "end": 869.0, "text": " using this benchmark to measure their platform, and I was saying, well, in this paper, they", "tokens": [1228, 341, 18927, 281, 3481, 641, 3663, 11, 293, 286, 390, 1566, 11, 731, 11, 294, 341, 3035, 11, 436], "temperature": 0.0, "avg_logprob": -0.2808681545835553, "compression_ratio": 1.702127659574468, "no_speech_prob": 1.9786339180427603e-05}, {"id": 168, "seek": 85976, "start": 869.0, "end": 879.16, "text": " were reporting around 20 nanoseconds and 13 nanoseconds, sorry, this is nanoseconds,", "tokens": [645, 10031, 926, 945, 14067, 541, 28750, 293, 3705, 14067, 541, 28750, 11, 2597, 11, 341, 307, 14067, 541, 28750, 11], "temperature": 0.0, "avg_logprob": -0.2808681545835553, "compression_ratio": 1.702127659574468, "no_speech_prob": 1.9786339180427603e-05}, {"id": 169, "seek": 85976, "start": 879.16, "end": 886.68, "text": " this is microseconds, not nanoseconds, sorry, in this platform.", "tokens": [341, 307, 3123, 37841, 28750, 11, 406, 14067, 541, 28750, 11, 2597, 11, 294, 341, 3663, 13], "temperature": 0.0, "avg_logprob": -0.2808681545835553, "compression_ratio": 1.702127659574468, "no_speech_prob": 1.9786339180427603e-05}, {"id": 170, "seek": 88668, "start": 886.68, "end": 896.1999999999999, "text": " In any case, I will be very cautious about this graph, because I was getting a lot of", "tokens": [682, 604, 1389, 11, 286, 486, 312, 588, 25278, 466, 341, 4295, 11, 570, 286, 390, 1242, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.19083163502452138, "compression_ratio": 1.6150234741784038, "no_speech_prob": 2.6554576834314503e-05}, {"id": 171, "seek": 88668, "start": 896.1999999999999, "end": 902.12, "text": " variation in the numbers, most of the time, for example, I was trying in a machine with", "tokens": [12990, 294, 264, 3547, 11, 881, 295, 264, 565, 11, 337, 1365, 11, 286, 390, 1382, 294, 257, 3479, 365], "temperature": 0.0, "avg_logprob": -0.19083163502452138, "compression_ratio": 1.6150234741784038, "no_speech_prob": 2.6554576834314503e-05}, {"id": 172, "seek": 88668, "start": 902.12, "end": 909.1999999999999, "text": " thirty-two cores, and the VM has already thirty-two BCPUs, so you should not test in", "tokens": [11790, 12, 20534, 24826, 11, 293, 264, 18038, 575, 1217, 11790, 12, 20534, 14359, 8115, 82, 11, 370, 291, 820, 406, 1500, 294], "temperature": 0.0, "avg_logprob": -0.19083163502452138, "compression_ratio": 1.6150234741784038, "no_speech_prob": 2.6554576834314503e-05}, {"id": 173, "seek": 88668, "start": 909.1999999999999, "end": 913.0799999999999, "text": " that sort of machine, because one of the threads is going to compete with the others,", "tokens": [300, 1333, 295, 3479, 11, 570, 472, 295, 264, 19314, 307, 516, 281, 11831, 365, 264, 2357, 11], "temperature": 0.0, "avg_logprob": -0.19083163502452138, "compression_ratio": 1.6150234741784038, "no_speech_prob": 2.6554576834314503e-05}, {"id": 174, "seek": 91308, "start": 913.08, "end": 918.9200000000001, "text": " with the main one of the hosts, so you should always test with less cores, less BCPU cores,", "tokens": [365, 264, 2135, 472, 295, 264, 21573, 11, 370, 291, 820, 1009, 1500, 365, 1570, 24826, 11, 1570, 14359, 8115, 24826, 11], "temperature": 0.0, "avg_logprob": -0.2872632055571585, "compression_ratio": 1.6890459363957597, "no_speech_prob": 3.452436067163944e-05}, {"id": 175, "seek": 91308, "start": 918.9200000000001, "end": 919.9200000000001, "text": " physical cores.", "tokens": [4001, 24826, 13], "temperature": 0.0, "avg_logprob": -0.2872632055571585, "compression_ratio": 1.6890459363957597, "no_speech_prob": 3.452436067163944e-05}, {"id": 176, "seek": 91308, "start": 919.9200000000001, "end": 927.0400000000001, "text": " And, yeah, the idea is to continue doing this, I mean, improving the way I am measuring", "tokens": [400, 11, 1338, 11, 264, 1558, 307, 281, 2354, 884, 341, 11, 286, 914, 11, 11470, 264, 636, 286, 669, 13389], "temperature": 0.0, "avg_logprob": -0.2872632055571585, "compression_ratio": 1.6890459363957597, "no_speech_prob": 3.452436067163944e-05}, {"id": 177, "seek": 91308, "start": 927.0400000000001, "end": 932.44, "text": " this, and also try maybe in different hardware, and at the same time, I found a lot of packs", "tokens": [341, 11, 293, 611, 853, 1310, 294, 819, 8837, 11, 293, 412, 264, 912, 565, 11, 286, 1352, 257, 688, 295, 19403], "temperature": 0.0, "avg_logprob": -0.2872632055571585, "compression_ratio": 1.6890459363957597, "no_speech_prob": 3.452436067163944e-05}, {"id": 178, "seek": 91308, "start": 932.44, "end": 936.32, "text": " in the unicroner by doing this, so for example, at the beginning, I only support more or less", "tokens": [294, 264, 517, 299, 2044, 260, 538, 884, 341, 11, 370, 337, 1365, 11, 412, 264, 2863, 11, 286, 787, 1406, 544, 420, 1570], "temperature": 0.0, "avg_logprob": -0.2872632055571585, "compression_ratio": 1.6890459363957597, "no_speech_prob": 3.452436067163944e-05}, {"id": 179, "seek": 91308, "start": 936.32, "end": 942.1600000000001, "text": " four cores, so I went from four to thirty-two, well, it was a number in a constant, but anyway,", "tokens": [1451, 24826, 11, 370, 286, 1437, 490, 1451, 281, 11790, 12, 20534, 11, 731, 11, 309, 390, 257, 1230, 294, 257, 5754, 11, 457, 4033, 11], "temperature": 0.0, "avg_logprob": -0.2872632055571585, "compression_ratio": 1.6890459363957597, "no_speech_prob": 3.452436067163944e-05}, {"id": 180, "seek": 94216, "start": 942.16, "end": 948.6, "text": " I found many packs when I was doing this, so it is all, this is just a proof-of-concept", "tokens": [286, 1352, 867, 19403, 562, 286, 390, 884, 341, 11, 370, 309, 307, 439, 11, 341, 307, 445, 257, 8177, 12, 2670, 12, 1671, 1336], "temperature": 0.0, "avg_logprob": -0.3499593001145583, "compression_ratio": 1.5119047619047619, "no_speech_prob": 3.59479890903458e-05}, {"id": 181, "seek": 94216, "start": 948.6, "end": 952.8, "text": " and a work in progress, so you don't take it too serious, I am trying to say, I don't", "tokens": [293, 257, 589, 294, 4205, 11, 370, 291, 500, 380, 747, 309, 886, 3156, 11, 286, 669, 1382, 281, 584, 11, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.3499593001145583, "compression_ratio": 1.5119047619047619, "no_speech_prob": 3.59479890903458e-05}, {"id": 182, "seek": 94216, "start": 952.8, "end": 961.8399999999999, "text": " want to jump into any conclusion from this, and, yeah, it was fun to do, anyway.", "tokens": [528, 281, 3012, 666, 604, 10063, 490, 341, 11, 293, 11, 1338, 11, 309, 390, 1019, 281, 360, 11, 4033, 13], "temperature": 0.0, "avg_logprob": -0.3499593001145583, "compression_ratio": 1.5119047619047619, "no_speech_prob": 3.59479890903458e-05}, {"id": 183, "seek": 96184, "start": 961.84, "end": 977.72, "text": " So that's all, I don't know if you have any questions.", "tokens": [407, 300, 311, 439, 11, 286, 500, 380, 458, 498, 291, 362, 604, 1651, 13], "temperature": 0.0, "avg_logprob": -0.30691902725784864, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.00018020802235696465}, {"id": 184, "seek": 96184, "start": 977.72, "end": 979.5600000000001, "text": " So you said this runs on bare metal.", "tokens": [407, 291, 848, 341, 6676, 322, 6949, 5760, 13], "temperature": 0.0, "avg_logprob": -0.30691902725784864, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.00018020802235696465}, {"id": 185, "seek": 96184, "start": 979.5600000000001, "end": 980.5600000000001, "text": " Sorry?", "tokens": [4919, 30], "temperature": 0.0, "avg_logprob": -0.30691902725784864, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.00018020802235696465}, {"id": 186, "seek": 96184, "start": 980.5600000000001, "end": 982.76, "text": " The unicroner runs on bare metal.", "tokens": [440, 517, 299, 2044, 260, 6676, 322, 6949, 5760, 13], "temperature": 0.0, "avg_logprob": -0.30691902725784864, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.00018020802235696465}, {"id": 187, "seek": 96184, "start": 982.76, "end": 983.76, "text": " Yeah, they are some.", "tokens": [865, 11, 436, 366, 512, 13], "temperature": 0.0, "avg_logprob": -0.30691902725784864, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.00018020802235696465}, {"id": 188, "seek": 96184, "start": 983.76, "end": 984.76, "text": " How do you even install it?", "tokens": [1012, 360, 291, 754, 3625, 309, 30], "temperature": 0.0, "avg_logprob": -0.30691902725784864, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.00018020802235696465}, {"id": 189, "seek": 96184, "start": 984.76, "end": 987.32, "text": " I mean, operating systems are kind of complicated, right?", "tokens": [286, 914, 11, 7447, 3652, 366, 733, 295, 6179, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.30691902725784864, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.00018020802235696465}, {"id": 190, "seek": 96184, "start": 987.32, "end": 988.32, "text": " Sorry?", "tokens": [4919, 30], "temperature": 0.0, "avg_logprob": -0.30691902725784864, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.00018020802235696465}, {"id": 191, "seek": 98832, "start": 988.32, "end": 992.0, "text": " How do you even install it on bare metal?", "tokens": [1012, 360, 291, 754, 3625, 309, 322, 6949, 5760, 30], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 192, "seek": 98832, "start": 992.0, "end": 993.5, "text": " Can you say that again?", "tokens": [1664, 291, 584, 300, 797, 30], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 193, "seek": 98832, "start": 993.5, "end": 995.96, "text": " How do you install it on bare metal?", "tokens": [1012, 360, 291, 3625, 309, 322, 6949, 5760, 30], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 194, "seek": 98832, "start": 995.96, "end": 997.96, "text": " How do you install it?", "tokens": [1012, 360, 291, 3625, 309, 30], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 195, "seek": 98832, "start": 997.96, "end": 1001.5600000000001, "text": " Yeah, like if I had this, how would I install it on bare metal?", "tokens": [865, 11, 411, 498, 286, 632, 341, 11, 577, 576, 286, 3625, 309, 322, 6949, 5760, 30], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 196, "seek": 98832, "start": 1001.5600000000001, "end": 1003.84, "text": " Is there an installer or...?", "tokens": [1119, 456, 364, 46620, 420, 8964], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 197, "seek": 98832, "start": 1003.84, "end": 1004.84, "text": " Installer, you mean?", "tokens": [2730, 22414, 11, 291, 914, 30], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 198, "seek": 98832, "start": 1004.84, "end": 1005.84, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 199, "seek": 98832, "start": 1005.84, "end": 1010.5600000000001, "text": " Now, you can just use some device to boot from, for example.", "tokens": [823, 11, 291, 393, 445, 764, 512, 4302, 281, 11450, 490, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 200, "seek": 98832, "start": 1010.5600000000001, "end": 1011.5600000000001, "text": " So it's bootable?", "tokens": [407, 309, 311, 11450, 712, 30], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 201, "seek": 98832, "start": 1011.5600000000001, "end": 1012.5600000000001, "text": " Yeah, that's it.", "tokens": [865, 11, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 202, "seek": 98832, "start": 1012.5600000000001, "end": 1013.5600000000001, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 203, "seek": 98832, "start": 1013.5600000000001, "end": 1014.5600000000001, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 204, "seek": 98832, "start": 1014.5600000000001, "end": 1015.5600000000001, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 205, "seek": 98832, "start": 1015.5600000000001, "end": 1016.5600000000001, "text": " Well, yeah.", "tokens": [1042, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.319449563062828, "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.000179020018549636}, {"id": 206, "seek": 101656, "start": 1016.56, "end": 1019.64, "text": " There are many ways to do that, for example, you don't have to install it, for example.", "tokens": [821, 366, 867, 2098, 281, 360, 300, 11, 337, 1365, 11, 291, 500, 380, 362, 281, 3625, 309, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.33662017734571437, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.0008185426122508943}, {"id": 207, "seek": 101656, "start": 1019.64, "end": 1029.44, "text": " You can use from a device that is removable, for example, you don't need to install it.", "tokens": [509, 393, 764, 490, 257, 4302, 300, 307, 44060, 11, 337, 1365, 11, 291, 500, 380, 643, 281, 3625, 309, 13], "temperature": 0.0, "avg_logprob": -0.33662017734571437, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.0008185426122508943}, {"id": 208, "seek": 101656, "start": 1029.44, "end": 1030.44, "text": " Any questions?", "tokens": [2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.33662017734571437, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.0008185426122508943}, {"id": 209, "seek": 101656, "start": 1030.44, "end": 1031.44, "text": " Thanks.", "tokens": [2561, 13], "temperature": 0.0, "avg_logprob": -0.33662017734571437, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.0008185426122508943}, {"id": 210, "seek": 101656, "start": 1031.44, "end": 1032.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.33662017734571437, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.0008185426122508943}, {"id": 211, "seek": 101656, "start": 1032.44, "end": 1033.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.33662017734571437, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.0008185426122508943}, {"id": 212, "seek": 101656, "start": 1033.44, "end": 1034.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.33662017734571437, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.0008185426122508943}, {"id": 213, "seek": 101656, "start": 1034.44, "end": 1035.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.33662017734571437, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.0008185426122508943}, {"id": 214, "seek": 101656, "start": 1035.44, "end": 1036.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.33662017734571437, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.0008185426122508943}, {"id": 215, "seek": 103644, "start": 1036.44, "end": 1051.06, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 1.0, "avg_logprob": -1.4925647463117326, "compression_ratio": 0.96875, "no_speech_prob": 0.002305785659700632}, {"id": 216, "seek": 103644, "start": 1051.06, "end": 1063.02, "text": " Thank you very much.", "tokens": [1044, 291, 588, 709, 13], "temperature": 1.0, "avg_logprob": -1.4925647463117326, "compression_ratio": 0.96875, "no_speech_prob": 0.002305785659700632}], "language": "en"}