{"text": " Well, all right. I'll get going since we're here. My name is Saul and today I'd like to talk to you about our little project P10K or how to get 10,000 participants into a GC meeting. No, it doesn't go on the loudspeakers, it's just for the recording. It is what it is. Sorry, I lost my voice. I'll try. I suppose most of you know what it is, but for those who don't, it's a way about to see compatible video conferencing application. I like to say that I can think of it in three ways. A set of open source projects that allow you to either deploy it or, you know, piecemeal it and build something with it. It's also a set of APIs and mobile SDK so you can embed it into your existing application and fully open source Apache to license and we have a pretty vibrant community that helps us build some stuff. So I've talked about scaling GC meets a couple of years ago here at FOSDOM with what we did during the pandemic. Also at Comcom about how we reached 500 participants. Then of course somebody will ask, yeah, how do you do more, right? So that's what I'm about to go on today. A quick TLDR on what the trick is to scale up is mostly to cheat because it turns out that you never see 10,000 participants at the same time. So you need to paginate and not show all of them at the same time, not load them at the same time. Also on the back end, you don't want to be, you know, taking care of 10,000 things at once. You want to be really careful avoiding re-renders on the react side of things. So on your front end, you definitely don't want to have 10,000 things. And very importantly, reducing signaling. And this is kind of the crux of the thing. So with all of those things, we ended up getting 500 participants in a single meeting. All of them are fully functional, bidirectional audio video participants. They will never all have video on. So that's sort of fine. I'm going to go a quick run through our architecture. So when we dive into XMPP, we know what we're talking about. XMPP is our course signal protocol. You heard it from Matt for chat. So all the participants join an XMPP mock, so a group chat. And then our focus, you call for negotiates a session with each participant. And then they all end up mixed in the JVB, which is where we allocate the media. So this is like a back of an app design level, but it's pretty accurate. Prosody is our XMPP server of choice. And you call for is the one that will allocate sessions here and then establish sessions with the users. So they all end up, you know, having this connection. Now, how do you go about solving 10,000 participants? Well, first of all, we do some research. And what we knew is that presence is stanza. So XMPP presence was our Achilles heel. So we needed to sort that out. And intuitively, when you need to support many of something, you think of, well, I'll partition it in smaller chunks. And maybe that's how I do it. So there is federated mark for that. So we thought maybe that's where it goes. And turns out the military had sort of researched this problem as well. And there is this cool white paper called federated multi-user chat for military deployments. And one of the things they got there is how to avoid these presence flooding. And they do that with the visitor role. And that's where we got the idea from. So the idea is that we're going to have two types of users, the active users and like passive users. So we don't need to know about all these passive users, like all these audience, we just need to know the number. We don't need to draw a tile for them. They don't need to be as apparently they're participating in the meeting. They're just viewers, right? And this is what the visitor role in XMPP Mach-Lingo means. So a passive participant can then become an active participant by switching the role. Because we're not building live streaming. So what we want to build is a way to actually actively be able to participate. Anybody of those 10,000 participants should be able to take the mic anytime. Scenarios for this, earnings calls on public to traded companies. Just because we can, you name it. So step two, how do we test it? Because if we build it, we need to be able to know we have a complete store goal. And in order to test 10,000 participants, you need, well, 10,000 participants. So we use a big ass linear grid and we created some lightweight clients so that we could have a lot of chunks that join the call. They've got no UI. We spawn multiple browser windows with multiple tabs, with multiple of these clients. And a recent trick is we use insertable streams to drop all media. One thing you can do is modify. Another thing you can do is drop it. So it's nothing. And then there are a lot more lightweight in our Selenium grid. Otherwise, it would take millions just to test what you're doing is right. There's a PR by Philip Hankey actually to do something like Chrome would said, Black Franks, very tiny ones. So maybe that's where we go in the future as well. And we also delay track creation so that we don't create tracks. If you join muted, we don't need to do the whole create a video track that is useless and things like this. The next thing is we scale the signaling. And the way we do it is we ended up having multiple processes servers. This is one node, but it could be spread to multiple nodes. So we have a main process server, which is where the active participants join the meeting. And then we have up to five extra nodes, which we call visitor nodes, where people join in this visitor role. So the presence is not broadcasted. Jigofa will decide which one you join, usually depending on the capacity. And the trick to actually become an active participant is to just join this one, join the main one afterwards. And we can do that very fast because you don't need to recreate the XMPP connection. So now, in order to establish this sort of mesh, we ended up using Federation, even though it's like within a single server, but still. So there's server to server bidirectional connections to avoid having duplicated connections. So custom modules that's where process shines because it allows us to do all these customizations to mirror like chat messages that have been typed in a visitor node to the main node and back. So to kind of fake it that they are in separate instances, actually. And as I said, becoming active is fast because you don't need to recreate the XMPP connection. You just need to join a different mock. Our step number four is to have an improved topology for media routing. Currently, we have Octo, which allows us to spread the load across multiple bridges. But this doesn't work very well for such a large load. You need a tree-style topology where some people are just receiving and a full mesh for those who are actively participating. So both loads can be spread. And last, we need to fix up the UI, let's say. So we don't need to render the visitors. We just need to know that there is 100 people and then 9,000 visitors. And that's it. So we want to refine the UI a little bit. We're thinking of using the raised-hand functionality to become an active participant. So you raise your hand, you are approved and then you become active. That's how we're thinking about it. Now, some of it is in the present, some of it is in the future. So how is it going? We got there with 51 bridges. We got 10,009 participants. So it worked out. There's still some work to do. So the UI is not yet final. We're polishing up a little bit. And we're still going to add some more modules to mirror all the data we want, like the polls and other stuff. And we're thinking that maybe we don't really need to support 500 active participants because that's a weird conference, really. So that number could actually be lower or pretty much configurable. So you can say, I want these very many active participants and the rest, it will be visitors. And that's that. And of course, we need to make it easy to deploy for everyone. Right now, this is a bit held together with that tip. Before I go, I'd like to give a shout out to the heroes that worked on the guts of this. You may know their names from our community, Boy is Domenico and Jonathan, incredible characters. And I'm relaying the message. I know they knew words, but they did the work. And I like to share the love we have for Prosody. We wouldn't have been able to do it, I think, without such a flexible piece of software. They help us. We help them. It's a very nice relationship we have with the project. We love Matt and team. So shout out to them. And since that's all I got, you can follow the progress there. We have documentation actually how to deploy the existing way of doing things. Again, early stages, but it's there. And if you have any questions, well, I'm around here. Or find me online. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.64, "text": " Well, all right. I'll get going since we're here. My name is Saul and today I'd like to", "tokens": [1042, 11, 439, 558, 13, 286, 603, 483, 516, 1670, 321, 434, 510, 13, 1222, 1315, 307, 35661, 293, 965, 286, 1116, 411, 281], "temperature": 0.0, "avg_logprob": -0.2918832360244379, "compression_ratio": 1.3743589743589744, "no_speech_prob": 0.6099976897239685}, {"id": 1, "seek": 0, "start": 14.64, "end": 19.12, "text": " talk to you about our little project P10K or how to get 10,000 participants into a", "tokens": [751, 281, 291, 466, 527, 707, 1716, 430, 3279, 42, 420, 577, 281, 483, 1266, 11, 1360, 10503, 666, 257], "temperature": 0.0, "avg_logprob": -0.2918832360244379, "compression_ratio": 1.3743589743589744, "no_speech_prob": 0.6099976897239685}, {"id": 2, "seek": 0, "start": 19.12, "end": 21.12, "text": " GC meeting.", "tokens": [29435, 3440, 13], "temperature": 0.0, "avg_logprob": -0.2918832360244379, "compression_ratio": 1.3743589743589744, "no_speech_prob": 0.6099976897239685}, {"id": 3, "seek": 0, "start": 21.12, "end": 28.400000000000002, "text": " No, it doesn't go on the loudspeakers, it's just for the recording. It is what it is.", "tokens": [883, 11, 309, 1177, 380, 352, 322, 264, 6588, 7053, 19552, 11, 309, 311, 445, 337, 264, 6613, 13, 467, 307, 437, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.2918832360244379, "compression_ratio": 1.3743589743589744, "no_speech_prob": 0.6099976897239685}, {"id": 4, "seek": 2840, "start": 28.4, "end": 35.32, "text": " Sorry, I lost my voice. I'll try. I suppose most of you know what it is, but for those", "tokens": [4919, 11, 286, 2731, 452, 3177, 13, 286, 603, 853, 13, 286, 7297, 881, 295, 291, 458, 437, 309, 307, 11, 457, 337, 729], "temperature": 0.0, "avg_logprob": -0.20414397198220957, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.00035746622597798705}, {"id": 5, "seek": 2840, "start": 35.32, "end": 41.519999999999996, "text": " who don't, it's a way about to see compatible video conferencing application. I like to", "tokens": [567, 500, 380, 11, 309, 311, 257, 636, 466, 281, 536, 18218, 960, 13765, 13644, 3861, 13, 286, 411, 281], "temperature": 0.0, "avg_logprob": -0.20414397198220957, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.00035746622597798705}, {"id": 6, "seek": 2840, "start": 41.519999999999996, "end": 46.519999999999996, "text": " say that I can think of it in three ways. A set of open source projects that allow you", "tokens": [584, 300, 286, 393, 519, 295, 309, 294, 1045, 2098, 13, 316, 992, 295, 1269, 4009, 4455, 300, 2089, 291], "temperature": 0.0, "avg_logprob": -0.20414397198220957, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.00035746622597798705}, {"id": 7, "seek": 2840, "start": 46.519999999999996, "end": 51.64, "text": " to either deploy it or, you know, piecemeal it and build something with it. It's also", "tokens": [281, 2139, 7274, 309, 420, 11, 291, 458, 11, 2522, 32914, 309, 293, 1322, 746, 365, 309, 13, 467, 311, 611], "temperature": 0.0, "avg_logprob": -0.20414397198220957, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.00035746622597798705}, {"id": 8, "seek": 2840, "start": 51.64, "end": 57.9, "text": " a set of APIs and mobile SDK so you can embed it into your existing application and fully", "tokens": [257, 992, 295, 21445, 293, 6013, 37135, 370, 291, 393, 12240, 309, 666, 428, 6741, 3861, 293, 4498], "temperature": 0.0, "avg_logprob": -0.20414397198220957, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.00035746622597798705}, {"id": 9, "seek": 5790, "start": 57.9, "end": 63.08, "text": " open source Apache to license and we have a pretty vibrant community that helps us build", "tokens": [1269, 4009, 46597, 281, 10476, 293, 321, 362, 257, 1238, 21571, 1768, 300, 3665, 505, 1322], "temperature": 0.0, "avg_logprob": -0.21554248187006736, "compression_ratio": 1.4534883720930232, "no_speech_prob": 0.00014110935444477946}, {"id": 10, "seek": 5790, "start": 63.08, "end": 64.6, "text": " some stuff.", "tokens": [512, 1507, 13], "temperature": 0.0, "avg_logprob": -0.21554248187006736, "compression_ratio": 1.4534883720930232, "no_speech_prob": 0.00014110935444477946}, {"id": 11, "seek": 5790, "start": 64.6, "end": 71.84, "text": " So I've talked about scaling GC meets a couple of years ago here at FOSDOM with what we did", "tokens": [407, 286, 600, 2825, 466, 21589, 29435, 13961, 257, 1916, 295, 924, 2057, 510, 412, 479, 4367, 35, 5251, 365, 437, 321, 630], "temperature": 0.0, "avg_logprob": -0.21554248187006736, "compression_ratio": 1.4534883720930232, "no_speech_prob": 0.00014110935444477946}, {"id": 12, "seek": 5790, "start": 71.84, "end": 78.96, "text": " during the pandemic. Also at Comcom about how we reached 500 participants. Then of course", "tokens": [1830, 264, 5388, 13, 2743, 412, 2432, 1112, 466, 577, 321, 6488, 5923, 10503, 13, 1396, 295, 1164], "temperature": 0.0, "avg_logprob": -0.21554248187006736, "compression_ratio": 1.4534883720930232, "no_speech_prob": 0.00014110935444477946}, {"id": 13, "seek": 5790, "start": 78.96, "end": 86.36, "text": " somebody will ask, yeah, how do you do more, right? So that's what I'm about to go on today.", "tokens": [2618, 486, 1029, 11, 1338, 11, 577, 360, 291, 360, 544, 11, 558, 30, 407, 300, 311, 437, 286, 478, 466, 281, 352, 322, 965, 13], "temperature": 0.0, "avg_logprob": -0.21554248187006736, "compression_ratio": 1.4534883720930232, "no_speech_prob": 0.00014110935444477946}, {"id": 14, "seek": 8636, "start": 86.36, "end": 93.12, "text": " A quick TLDR on what the trick is to scale up is mostly to cheat because it turns out", "tokens": [316, 1702, 40277, 9301, 322, 437, 264, 4282, 307, 281, 4373, 493, 307, 5240, 281, 17470, 570, 309, 4523, 484], "temperature": 0.0, "avg_logprob": -0.1319543202718099, "compression_ratio": 1.736, "no_speech_prob": 0.00010878657485591248}, {"id": 15, "seek": 8636, "start": 93.12, "end": 99.72, "text": " that you never see 10,000 participants at the same time. So you need to paginate and", "tokens": [300, 291, 1128, 536, 1266, 11, 1360, 10503, 412, 264, 912, 565, 13, 407, 291, 643, 281, 11812, 13923, 293], "temperature": 0.0, "avg_logprob": -0.1319543202718099, "compression_ratio": 1.736, "no_speech_prob": 0.00010878657485591248}, {"id": 16, "seek": 8636, "start": 99.72, "end": 104.16, "text": " not show all of them at the same time, not load them at the same time. Also on the back", "tokens": [406, 855, 439, 295, 552, 412, 264, 912, 565, 11, 406, 3677, 552, 412, 264, 912, 565, 13, 2743, 322, 264, 646], "temperature": 0.0, "avg_logprob": -0.1319543202718099, "compression_ratio": 1.736, "no_speech_prob": 0.00010878657485591248}, {"id": 17, "seek": 8636, "start": 104.16, "end": 110.28, "text": " end, you don't want to be, you know, taking care of 10,000 things at once. You want to", "tokens": [917, 11, 291, 500, 380, 528, 281, 312, 11, 291, 458, 11, 1940, 1127, 295, 1266, 11, 1360, 721, 412, 1564, 13, 509, 528, 281], "temperature": 0.0, "avg_logprob": -0.1319543202718099, "compression_ratio": 1.736, "no_speech_prob": 0.00010878657485591248}, {"id": 18, "seek": 8636, "start": 110.28, "end": 115.0, "text": " be really careful avoiding re-renders on the react side of things. So on your front end,", "tokens": [312, 534, 5026, 20220, 319, 12, 4542, 433, 322, 264, 4515, 1252, 295, 721, 13, 407, 322, 428, 1868, 917, 11], "temperature": 0.0, "avg_logprob": -0.1319543202718099, "compression_ratio": 1.736, "no_speech_prob": 0.00010878657485591248}, {"id": 19, "seek": 11500, "start": 115.0, "end": 121.88, "text": " you definitely don't want to have 10,000 things. And very importantly, reducing signaling.", "tokens": [291, 2138, 500, 380, 528, 281, 362, 1266, 11, 1360, 721, 13, 400, 588, 8906, 11, 12245, 38639, 13], "temperature": 0.0, "avg_logprob": -0.19576932047749615, "compression_ratio": 1.5782608695652174, "no_speech_prob": 3.021934571734164e-05}, {"id": 20, "seek": 11500, "start": 121.88, "end": 128.16, "text": " And this is kind of the crux of the thing. So with all of those things, we ended up getting", "tokens": [400, 341, 307, 733, 295, 264, 5140, 87, 295, 264, 551, 13, 407, 365, 439, 295, 729, 721, 11, 321, 4590, 493, 1242], "temperature": 0.0, "avg_logprob": -0.19576932047749615, "compression_ratio": 1.5782608695652174, "no_speech_prob": 3.021934571734164e-05}, {"id": 21, "seek": 11500, "start": 128.16, "end": 134.0, "text": " 500 participants in a single meeting. All of them are fully functional, bidirectional audio", "tokens": [5923, 10503, 294, 257, 2167, 3440, 13, 1057, 295, 552, 366, 4498, 11745, 11, 12957, 621, 41048, 6278], "temperature": 0.0, "avg_logprob": -0.19576932047749615, "compression_ratio": 1.5782608695652174, "no_speech_prob": 3.021934571734164e-05}, {"id": 22, "seek": 11500, "start": 134.0, "end": 139.68, "text": " video participants. They will never all have video on. So that's sort of fine. I'm going", "tokens": [960, 10503, 13, 814, 486, 1128, 439, 362, 960, 322, 13, 407, 300, 311, 1333, 295, 2489, 13, 286, 478, 516], "temperature": 0.0, "avg_logprob": -0.19576932047749615, "compression_ratio": 1.5782608695652174, "no_speech_prob": 3.021934571734164e-05}, {"id": 23, "seek": 13968, "start": 139.68, "end": 145.20000000000002, "text": " to go a quick run through our architecture. So when we dive into XMPP, we know what we're", "tokens": [281, 352, 257, 1702, 1190, 807, 527, 9482, 13, 407, 562, 321, 9192, 666, 1783, 12224, 47, 11, 321, 458, 437, 321, 434], "temperature": 0.0, "avg_logprob": -0.19994698801348287, "compression_ratio": 1.5874125874125875, "no_speech_prob": 7.244380685733631e-05}, {"id": 24, "seek": 13968, "start": 145.20000000000002, "end": 151.24, "text": " talking about. XMPP is our course signal protocol. You heard it from Matt for chat. So all the", "tokens": [1417, 466, 13, 1783, 12224, 47, 307, 527, 1164, 6358, 10336, 13, 509, 2198, 309, 490, 7397, 337, 5081, 13, 407, 439, 264], "temperature": 0.0, "avg_logprob": -0.19994698801348287, "compression_ratio": 1.5874125874125875, "no_speech_prob": 7.244380685733631e-05}, {"id": 25, "seek": 13968, "start": 151.24, "end": 156.72, "text": " participants join an XMPP mock, so a group chat. And then our focus, you call for negotiates", "tokens": [10503, 3917, 364, 1783, 12224, 47, 17362, 11, 370, 257, 1594, 5081, 13, 400, 550, 527, 1879, 11, 291, 818, 337, 9542, 1024], "temperature": 0.0, "avg_logprob": -0.19994698801348287, "compression_ratio": 1.5874125874125875, "no_speech_prob": 7.244380685733631e-05}, {"id": 26, "seek": 13968, "start": 156.72, "end": 162.84, "text": " a session with each participant. And then they all end up mixed in the JVB, which is", "tokens": [257, 5481, 365, 1184, 24950, 13, 400, 550, 436, 439, 917, 493, 7467, 294, 264, 508, 53, 33, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.19994698801348287, "compression_ratio": 1.5874125874125875, "no_speech_prob": 7.244380685733631e-05}, {"id": 27, "seek": 13968, "start": 162.84, "end": 169.44, "text": " where we allocate the media. So this is like a back of an app design level, but it's pretty", "tokens": [689, 321, 35713, 264, 3021, 13, 407, 341, 307, 411, 257, 646, 295, 364, 724, 1715, 1496, 11, 457, 309, 311, 1238], "temperature": 0.0, "avg_logprob": -0.19994698801348287, "compression_ratio": 1.5874125874125875, "no_speech_prob": 7.244380685733631e-05}, {"id": 28, "seek": 16944, "start": 169.44, "end": 177.6, "text": " accurate. Prosody is our XMPP server of choice. And you call for is the one that will allocate", "tokens": [8559, 13, 26024, 843, 307, 527, 1783, 12224, 47, 7154, 295, 3922, 13, 400, 291, 818, 337, 307, 264, 472, 300, 486, 35713], "temperature": 0.0, "avg_logprob": -0.18491093317667642, "compression_ratio": 1.55793991416309, "no_speech_prob": 4.129507578909397e-05}, {"id": 29, "seek": 16944, "start": 177.6, "end": 183.12, "text": " sessions here and then establish sessions with the users. So they all end up, you know,", "tokens": [11081, 510, 293, 550, 8327, 11081, 365, 264, 5022, 13, 407, 436, 439, 917, 493, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.18491093317667642, "compression_ratio": 1.55793991416309, "no_speech_prob": 4.129507578909397e-05}, {"id": 30, "seek": 16944, "start": 183.12, "end": 189.72, "text": " having this connection. Now, how do you go about solving 10,000 participants? Well, first", "tokens": [1419, 341, 4984, 13, 823, 11, 577, 360, 291, 352, 466, 12606, 1266, 11, 1360, 10503, 30, 1042, 11, 700], "temperature": 0.0, "avg_logprob": -0.18491093317667642, "compression_ratio": 1.55793991416309, "no_speech_prob": 4.129507578909397e-05}, {"id": 31, "seek": 16944, "start": 189.72, "end": 196.28, "text": " of all, we do some research. And what we knew is that presence is stanza. So XMPP presence", "tokens": [295, 439, 11, 321, 360, 512, 2132, 13, 400, 437, 321, 2586, 307, 300, 6814, 307, 342, 20030, 13, 407, 1783, 12224, 47, 6814], "temperature": 0.0, "avg_logprob": -0.18491093317667642, "compression_ratio": 1.55793991416309, "no_speech_prob": 4.129507578909397e-05}, {"id": 32, "seek": 19628, "start": 196.28, "end": 203.88, "text": " was our Achilles heel. So we needed to sort that out. And intuitively, when you need to", "tokens": [390, 527, 15847, 14835, 9430, 13, 407, 321, 2978, 281, 1333, 300, 484, 13, 400, 46506, 11, 562, 291, 643, 281], "temperature": 0.0, "avg_logprob": -0.14463379108800298, "compression_ratio": 1.7286821705426356, "no_speech_prob": 8.603824971942231e-05}, {"id": 33, "seek": 19628, "start": 203.88, "end": 208.48, "text": " support many of something, you think of, well, I'll partition it in smaller chunks. And maybe", "tokens": [1406, 867, 295, 746, 11, 291, 519, 295, 11, 731, 11, 286, 603, 24808, 309, 294, 4356, 24004, 13, 400, 1310], "temperature": 0.0, "avg_logprob": -0.14463379108800298, "compression_ratio": 1.7286821705426356, "no_speech_prob": 8.603824971942231e-05}, {"id": 34, "seek": 19628, "start": 208.48, "end": 212.96, "text": " that's how I do it. So there is federated mark for that. So we thought maybe that's where", "tokens": [300, 311, 577, 286, 360, 309, 13, 407, 456, 307, 38024, 770, 1491, 337, 300, 13, 407, 321, 1194, 1310, 300, 311, 689], "temperature": 0.0, "avg_logprob": -0.14463379108800298, "compression_ratio": 1.7286821705426356, "no_speech_prob": 8.603824971942231e-05}, {"id": 35, "seek": 19628, "start": 212.96, "end": 218.04, "text": " it goes. And turns out the military had sort of researched this problem as well. And there", "tokens": [309, 1709, 13, 400, 4523, 484, 264, 4632, 632, 1333, 295, 37098, 341, 1154, 382, 731, 13, 400, 456], "temperature": 0.0, "avg_logprob": -0.14463379108800298, "compression_ratio": 1.7286821705426356, "no_speech_prob": 8.603824971942231e-05}, {"id": 36, "seek": 19628, "start": 218.04, "end": 224.2, "text": " is this cool white paper called federated multi-user chat for military deployments.", "tokens": [307, 341, 1627, 2418, 3035, 1219, 38024, 770, 4825, 12, 18088, 5081, 337, 4632, 7274, 1117, 13], "temperature": 0.0, "avg_logprob": -0.14463379108800298, "compression_ratio": 1.7286821705426356, "no_speech_prob": 8.603824971942231e-05}, {"id": 37, "seek": 22420, "start": 224.2, "end": 230.64, "text": " And one of the things they got there is how to avoid these presence flooding. And they", "tokens": [400, 472, 295, 264, 721, 436, 658, 456, 307, 577, 281, 5042, 613, 6814, 24132, 13, 400, 436], "temperature": 0.0, "avg_logprob": -0.14254096516391687, "compression_ratio": 1.851063829787234, "no_speech_prob": 9.598536416888237e-05}, {"id": 38, "seek": 22420, "start": 230.64, "end": 235.72, "text": " do that with the visitor role. And that's where we got the idea from. So the idea is", "tokens": [360, 300, 365, 264, 28222, 3090, 13, 400, 300, 311, 689, 321, 658, 264, 1558, 490, 13, 407, 264, 1558, 307], "temperature": 0.0, "avg_logprob": -0.14254096516391687, "compression_ratio": 1.851063829787234, "no_speech_prob": 9.598536416888237e-05}, {"id": 39, "seek": 22420, "start": 235.72, "end": 241.95999999999998, "text": " that we're going to have two types of users, the active users and like passive users. So", "tokens": [300, 321, 434, 516, 281, 362, 732, 3467, 295, 5022, 11, 264, 4967, 5022, 293, 411, 14975, 5022, 13, 407], "temperature": 0.0, "avg_logprob": -0.14254096516391687, "compression_ratio": 1.851063829787234, "no_speech_prob": 9.598536416888237e-05}, {"id": 40, "seek": 22420, "start": 241.95999999999998, "end": 246.76, "text": " we don't need to know about all these passive users, like all these audience, we just need", "tokens": [321, 500, 380, 643, 281, 458, 466, 439, 613, 14975, 5022, 11, 411, 439, 613, 4034, 11, 321, 445, 643], "temperature": 0.0, "avg_logprob": -0.14254096516391687, "compression_ratio": 1.851063829787234, "no_speech_prob": 9.598536416888237e-05}, {"id": 41, "seek": 22420, "start": 246.76, "end": 252.04, "text": " to know the number. We don't need to draw a tile for them. They don't need to be as", "tokens": [281, 458, 264, 1230, 13, 492, 500, 380, 643, 281, 2642, 257, 20590, 337, 552, 13, 814, 500, 380, 643, 281, 312, 382], "temperature": 0.0, "avg_logprob": -0.14254096516391687, "compression_ratio": 1.851063829787234, "no_speech_prob": 9.598536416888237e-05}, {"id": 42, "seek": 25204, "start": 252.04, "end": 255.88, "text": " apparently they're participating in the meeting. They're just viewers, right? And this is what", "tokens": [7970, 436, 434, 13950, 294, 264, 3440, 13, 814, 434, 445, 8499, 11, 558, 30, 400, 341, 307, 437], "temperature": 0.0, "avg_logprob": -0.1943724830195589, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.0001329388323938474}, {"id": 43, "seek": 25204, "start": 255.88, "end": 261.96, "text": " the visitor role in XMPP Mach-Lingo means. So a passive participant can then become an", "tokens": [264, 28222, 3090, 294, 1783, 12224, 47, 12089, 12, 43, 18459, 1355, 13, 407, 257, 14975, 24950, 393, 550, 1813, 364], "temperature": 0.0, "avg_logprob": -0.1943724830195589, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.0001329388323938474}, {"id": 44, "seek": 25204, "start": 261.96, "end": 266.88, "text": " active participant by switching the role. Because we're not building live streaming.", "tokens": [4967, 24950, 538, 16493, 264, 3090, 13, 1436, 321, 434, 406, 2390, 1621, 11791, 13], "temperature": 0.0, "avg_logprob": -0.1943724830195589, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.0001329388323938474}, {"id": 45, "seek": 25204, "start": 266.88, "end": 271.2, "text": " So what we want to build is a way to actually actively be able to participate. Anybody of", "tokens": [407, 437, 321, 528, 281, 1322, 307, 257, 636, 281, 767, 13022, 312, 1075, 281, 8197, 13, 19082, 295], "temperature": 0.0, "avg_logprob": -0.1943724830195589, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.0001329388323938474}, {"id": 46, "seek": 25204, "start": 271.2, "end": 278.64, "text": " those 10,000 participants should be able to take the mic anytime. Scenarios for this,", "tokens": [729, 1266, 11, 1360, 10503, 820, 312, 1075, 281, 747, 264, 3123, 13038, 13, 2747, 268, 9720, 337, 341, 11], "temperature": 0.0, "avg_logprob": -0.1943724830195589, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.0001329388323938474}, {"id": 47, "seek": 27864, "start": 278.64, "end": 285.84, "text": " earnings calls on public to traded companies. Just because we can, you name it.", "tokens": [20548, 5498, 322, 1908, 281, 27157, 3431, 13, 1449, 570, 321, 393, 11, 291, 1315, 309, 13], "temperature": 0.0, "avg_logprob": -0.2182452160379161, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.00046460263547487557}, {"id": 48, "seek": 27864, "start": 285.84, "end": 291.12, "text": " So step two, how do we test it? Because if we build it, we need to be able to know we", "tokens": [407, 1823, 732, 11, 577, 360, 321, 1500, 309, 30, 1436, 498, 321, 1322, 309, 11, 321, 643, 281, 312, 1075, 281, 458, 321], "temperature": 0.0, "avg_logprob": -0.2182452160379161, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.00046460263547487557}, {"id": 49, "seek": 27864, "start": 291.12, "end": 295.52, "text": " have a complete store goal. And in order to test 10,000 participants, you need, well,", "tokens": [362, 257, 3566, 3531, 3387, 13, 400, 294, 1668, 281, 1500, 1266, 11, 1360, 10503, 11, 291, 643, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.2182452160379161, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.00046460263547487557}, {"id": 50, "seek": 27864, "start": 295.52, "end": 302.88, "text": " 10,000 participants. So we use a big ass linear grid and we created some lightweight clients", "tokens": [1266, 11, 1360, 10503, 13, 407, 321, 764, 257, 955, 1256, 8213, 10748, 293, 321, 2942, 512, 22052, 6982], "temperature": 0.0, "avg_logprob": -0.2182452160379161, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.00046460263547487557}, {"id": 51, "seek": 27864, "start": 302.88, "end": 308.12, "text": " so that we could have a lot of chunks that join the call. They've got no UI. We spawn", "tokens": [370, 300, 321, 727, 362, 257, 688, 295, 24004, 300, 3917, 264, 818, 13, 814, 600, 658, 572, 15682, 13, 492, 17088], "temperature": 0.0, "avg_logprob": -0.2182452160379161, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.00046460263547487557}, {"id": 52, "seek": 30812, "start": 308.12, "end": 313.92, "text": " multiple browser windows with multiple tabs, with multiple of these clients. And a recent", "tokens": [3866, 11185, 9309, 365, 3866, 20743, 11, 365, 3866, 295, 613, 6982, 13, 400, 257, 5162], "temperature": 0.0, "avg_logprob": -0.22603923350841076, "compression_ratio": 1.6593406593406594, "no_speech_prob": 0.00032361672492697835}, {"id": 53, "seek": 30812, "start": 313.92, "end": 319.08, "text": " trick is we use insertable streams to drop all media. One thing you can do is modify.", "tokens": [4282, 307, 321, 764, 8969, 712, 15842, 281, 3270, 439, 3021, 13, 1485, 551, 291, 393, 360, 307, 16927, 13], "temperature": 0.0, "avg_logprob": -0.22603923350841076, "compression_ratio": 1.6593406593406594, "no_speech_prob": 0.00032361672492697835}, {"id": 54, "seek": 30812, "start": 319.08, "end": 323.6, "text": " Another thing you can do is drop it. So it's nothing. And then there are a lot more lightweight", "tokens": [3996, 551, 291, 393, 360, 307, 3270, 309, 13, 407, 309, 311, 1825, 13, 400, 550, 456, 366, 257, 688, 544, 22052], "temperature": 0.0, "avg_logprob": -0.22603923350841076, "compression_ratio": 1.6593406593406594, "no_speech_prob": 0.00032361672492697835}, {"id": 55, "seek": 30812, "start": 323.6, "end": 327.24, "text": " in our Selenium grid. Otherwise, it would take millions just to test what you're doing", "tokens": [294, 527, 10736, 268, 2197, 10748, 13, 10328, 11, 309, 576, 747, 6803, 445, 281, 1500, 437, 291, 434, 884], "temperature": 0.0, "avg_logprob": -0.22603923350841076, "compression_ratio": 1.6593406593406594, "no_speech_prob": 0.00032361672492697835}, {"id": 56, "seek": 30812, "start": 327.24, "end": 334.16, "text": " is right. There's a PR by Philip Hankey actually to do something like Chrome would said, Black", "tokens": [307, 558, 13, 821, 311, 257, 11568, 538, 21144, 7820, 4119, 767, 281, 360, 746, 411, 15327, 576, 848, 11, 4076], "temperature": 0.0, "avg_logprob": -0.22603923350841076, "compression_ratio": 1.6593406593406594, "no_speech_prob": 0.00032361672492697835}, {"id": 57, "seek": 33416, "start": 334.16, "end": 341.20000000000005, "text": " Franks, very tiny ones. So maybe that's where we go in the future as well. And we also delay", "tokens": [6823, 82, 11, 588, 5870, 2306, 13, 407, 1310, 300, 311, 689, 321, 352, 294, 264, 2027, 382, 731, 13, 400, 321, 611, 8577], "temperature": 0.0, "avg_logprob": -0.1593554260533884, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010534901230130345}, {"id": 58, "seek": 33416, "start": 341.20000000000005, "end": 346.04, "text": " track creation so that we don't create tracks. If you join muted, we don't need to do the", "tokens": [2837, 8016, 370, 300, 321, 500, 380, 1884, 10218, 13, 759, 291, 3917, 32808, 11, 321, 500, 380, 643, 281, 360, 264], "temperature": 0.0, "avg_logprob": -0.1593554260533884, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010534901230130345}, {"id": 59, "seek": 33416, "start": 346.04, "end": 351.08000000000004, "text": " whole create a video track that is useless and things like this.", "tokens": [1379, 1884, 257, 960, 2837, 300, 307, 14115, 293, 721, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1593554260533884, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010534901230130345}, {"id": 60, "seek": 33416, "start": 351.08000000000004, "end": 356.48, "text": " The next thing is we scale the signaling. And the way we do it is we ended up having", "tokens": [440, 958, 551, 307, 321, 4373, 264, 38639, 13, 400, 264, 636, 321, 360, 309, 307, 321, 4590, 493, 1419], "temperature": 0.0, "avg_logprob": -0.1593554260533884, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010534901230130345}, {"id": 61, "seek": 33416, "start": 356.48, "end": 362.0, "text": " multiple processes servers. This is one node, but it could be spread to multiple nodes.", "tokens": [3866, 7555, 15909, 13, 639, 307, 472, 9984, 11, 457, 309, 727, 312, 3974, 281, 3866, 13891, 13], "temperature": 0.0, "avg_logprob": -0.1593554260533884, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010534901230130345}, {"id": 62, "seek": 36200, "start": 362.0, "end": 367.68, "text": " So we have a main process server, which is where the active participants join the meeting.", "tokens": [407, 321, 362, 257, 2135, 1399, 7154, 11, 597, 307, 689, 264, 4967, 10503, 3917, 264, 3440, 13], "temperature": 0.0, "avg_logprob": -0.16525615836089513, "compression_ratio": 1.7741935483870968, "no_speech_prob": 2.0439581930986606e-05}, {"id": 63, "seek": 36200, "start": 367.68, "end": 374.72, "text": " And then we have up to five extra nodes, which we call visitor nodes, where people join in", "tokens": [400, 550, 321, 362, 493, 281, 1732, 2857, 13891, 11, 597, 321, 818, 28222, 13891, 11, 689, 561, 3917, 294], "temperature": 0.0, "avg_logprob": -0.16525615836089513, "compression_ratio": 1.7741935483870968, "no_speech_prob": 2.0439581930986606e-05}, {"id": 64, "seek": 36200, "start": 374.72, "end": 380.28, "text": " this visitor role. So the presence is not broadcasted. Jigofa will decide which one", "tokens": [341, 28222, 3090, 13, 407, 264, 6814, 307, 406, 9975, 292, 13, 508, 328, 2670, 64, 486, 4536, 597, 472], "temperature": 0.0, "avg_logprob": -0.16525615836089513, "compression_ratio": 1.7741935483870968, "no_speech_prob": 2.0439581930986606e-05}, {"id": 65, "seek": 36200, "start": 380.28, "end": 385.72, "text": " you join, usually depending on the capacity. And the trick to actually become an active", "tokens": [291, 3917, 11, 2673, 5413, 322, 264, 6042, 13, 400, 264, 4282, 281, 767, 1813, 364, 4967], "temperature": 0.0, "avg_logprob": -0.16525615836089513, "compression_ratio": 1.7741935483870968, "no_speech_prob": 2.0439581930986606e-05}, {"id": 66, "seek": 36200, "start": 385.72, "end": 391.52, "text": " participant is to just join this one, join the main one afterwards. And we can do that", "tokens": [24950, 307, 281, 445, 3917, 341, 472, 11, 3917, 264, 2135, 472, 10543, 13, 400, 321, 393, 360, 300], "temperature": 0.0, "avg_logprob": -0.16525615836089513, "compression_ratio": 1.7741935483870968, "no_speech_prob": 2.0439581930986606e-05}, {"id": 67, "seek": 39152, "start": 391.52, "end": 397.44, "text": " very fast because you don't need to recreate the XMPP connection.", "tokens": [588, 2370, 570, 291, 500, 380, 643, 281, 25833, 264, 1783, 12224, 47, 4984, 13], "temperature": 0.0, "avg_logprob": -0.19623404858159085, "compression_ratio": 1.6872586872586872, "no_speech_prob": 8.205473568523303e-05}, {"id": 68, "seek": 39152, "start": 397.44, "end": 404.52, "text": " So now, in order to establish this sort of mesh, we ended up using Federation, even though", "tokens": [407, 586, 11, 294, 1668, 281, 8327, 341, 1333, 295, 17407, 11, 321, 4590, 493, 1228, 27237, 11, 754, 1673], "temperature": 0.0, "avg_logprob": -0.19623404858159085, "compression_ratio": 1.6872586872586872, "no_speech_prob": 8.205473568523303e-05}, {"id": 69, "seek": 39152, "start": 404.52, "end": 408.84, "text": " it's like within a single server, but still. So there's server to server bidirectional", "tokens": [309, 311, 411, 1951, 257, 2167, 7154, 11, 457, 920, 13, 407, 456, 311, 7154, 281, 7154, 12957, 621, 41048], "temperature": 0.0, "avg_logprob": -0.19623404858159085, "compression_ratio": 1.6872586872586872, "no_speech_prob": 8.205473568523303e-05}, {"id": 70, "seek": 39152, "start": 408.84, "end": 414.79999999999995, "text": " connections to avoid having duplicated connections. So custom modules that's where process shines", "tokens": [9271, 281, 5042, 1419, 1581, 564, 3587, 9271, 13, 407, 2375, 16679, 300, 311, 689, 1399, 28056], "temperature": 0.0, "avg_logprob": -0.19623404858159085, "compression_ratio": 1.6872586872586872, "no_speech_prob": 8.205473568523303e-05}, {"id": 71, "seek": 39152, "start": 414.79999999999995, "end": 419.68, "text": " because it allows us to do all these customizations to mirror like chat messages that have been", "tokens": [570, 309, 4045, 505, 281, 360, 439, 613, 2375, 14455, 281, 8013, 411, 5081, 7897, 300, 362, 668], "temperature": 0.0, "avg_logprob": -0.19623404858159085, "compression_ratio": 1.6872586872586872, "no_speech_prob": 8.205473568523303e-05}, {"id": 72, "seek": 41968, "start": 419.68, "end": 425.92, "text": " typed in a visitor node to the main node and back. So to kind of fake it that they are", "tokens": [33941, 294, 257, 28222, 9984, 281, 264, 2135, 9984, 293, 646, 13, 407, 281, 733, 295, 7592, 309, 300, 436, 366], "temperature": 0.0, "avg_logprob": -0.1638204242111346, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.00016777339624240994}, {"id": 73, "seek": 41968, "start": 425.92, "end": 432.08, "text": " in separate instances, actually. And as I said, becoming active is fast because you", "tokens": [294, 4994, 14519, 11, 767, 13, 400, 382, 286, 848, 11, 5617, 4967, 307, 2370, 570, 291], "temperature": 0.0, "avg_logprob": -0.1638204242111346, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.00016777339624240994}, {"id": 74, "seek": 41968, "start": 432.08, "end": 436.84000000000003, "text": " don't need to recreate the XMPP connection. You just need to join a different mock.", "tokens": [500, 380, 643, 281, 25833, 264, 1783, 12224, 47, 4984, 13, 509, 445, 643, 281, 3917, 257, 819, 17362, 13], "temperature": 0.0, "avg_logprob": -0.1638204242111346, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.00016777339624240994}, {"id": 75, "seek": 41968, "start": 436.84000000000003, "end": 443.0, "text": " Our step number four is to have an improved topology for media routing. Currently, we have", "tokens": [2621, 1823, 1230, 1451, 307, 281, 362, 364, 9689, 1192, 1793, 337, 3021, 32722, 13, 19964, 11, 321, 362], "temperature": 0.0, "avg_logprob": -0.1638204242111346, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.00016777339624240994}, {"id": 76, "seek": 41968, "start": 443.0, "end": 448.12, "text": " Octo, which allows us to spread the load across multiple bridges. But this doesn't work very", "tokens": [6788, 78, 11, 597, 4045, 505, 281, 3974, 264, 3677, 2108, 3866, 21114, 13, 583, 341, 1177, 380, 589, 588], "temperature": 0.0, "avg_logprob": -0.1638204242111346, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.00016777339624240994}, {"id": 77, "seek": 44812, "start": 448.12, "end": 453.72, "text": " well for such a large load. You need a tree-style topology where some people are just receiving", "tokens": [731, 337, 1270, 257, 2416, 3677, 13, 509, 643, 257, 4230, 12, 15014, 1192, 1793, 689, 512, 561, 366, 445, 10040], "temperature": 0.0, "avg_logprob": -0.14013238297295325, "compression_ratio": 1.5745614035087718, "no_speech_prob": 4.262521906639449e-05}, {"id": 78, "seek": 44812, "start": 453.72, "end": 461.2, "text": " and a full mesh for those who are actively participating. So both loads can be spread.", "tokens": [293, 257, 1577, 17407, 337, 729, 567, 366, 13022, 13950, 13, 407, 1293, 12668, 393, 312, 3974, 13], "temperature": 0.0, "avg_logprob": -0.14013238297295325, "compression_ratio": 1.5745614035087718, "no_speech_prob": 4.262521906639449e-05}, {"id": 79, "seek": 44812, "start": 461.2, "end": 467.92, "text": " And last, we need to fix up the UI, let's say. So we don't need to render the visitors.", "tokens": [400, 1036, 11, 321, 643, 281, 3191, 493, 264, 15682, 11, 718, 311, 584, 13, 407, 321, 500, 380, 643, 281, 15529, 264, 14315, 13], "temperature": 0.0, "avg_logprob": -0.14013238297295325, "compression_ratio": 1.5745614035087718, "no_speech_prob": 4.262521906639449e-05}, {"id": 80, "seek": 44812, "start": 467.92, "end": 475.0, "text": " We just need to know that there is 100 people and then 9,000 visitors. And that's it. So", "tokens": [492, 445, 643, 281, 458, 300, 456, 307, 2319, 561, 293, 550, 1722, 11, 1360, 14315, 13, 400, 300, 311, 309, 13, 407], "temperature": 0.0, "avg_logprob": -0.14013238297295325, "compression_ratio": 1.5745614035087718, "no_speech_prob": 4.262521906639449e-05}, {"id": 81, "seek": 47500, "start": 475.0, "end": 479.92, "text": " we want to refine the UI a little bit. We're thinking of using the raised-hand functionality", "tokens": [321, 528, 281, 33906, 264, 15682, 257, 707, 857, 13, 492, 434, 1953, 295, 1228, 264, 6005, 12, 5543, 14980], "temperature": 0.0, "avg_logprob": -0.1688651841940339, "compression_ratio": 1.634703196347032, "no_speech_prob": 3.881635711877607e-05}, {"id": 82, "seek": 47500, "start": 479.92, "end": 483.76, "text": " to become an active participant. So you raise your hand, you are approved and then you become", "tokens": [281, 1813, 364, 4967, 24950, 13, 407, 291, 5300, 428, 1011, 11, 291, 366, 10826, 293, 550, 291, 1813], "temperature": 0.0, "avg_logprob": -0.1688651841940339, "compression_ratio": 1.634703196347032, "no_speech_prob": 3.881635711877607e-05}, {"id": 83, "seek": 47500, "start": 483.76, "end": 490.56, "text": " active. That's how we're thinking about it. Now, some of it is in the present, some of", "tokens": [4967, 13, 663, 311, 577, 321, 434, 1953, 466, 309, 13, 823, 11, 512, 295, 309, 307, 294, 264, 1974, 11, 512, 295], "temperature": 0.0, "avg_logprob": -0.1688651841940339, "compression_ratio": 1.634703196347032, "no_speech_prob": 3.881635711877607e-05}, {"id": 84, "seek": 47500, "start": 490.56, "end": 498.6, "text": " it is in the future. So how is it going? We got there with 51 bridges. We got 10,009", "tokens": [309, 307, 294, 264, 2027, 13, 407, 577, 307, 309, 516, 30, 492, 658, 456, 365, 18485, 21114, 13, 492, 658, 1266, 11, 628, 24], "temperature": 0.0, "avg_logprob": -0.1688651841940339, "compression_ratio": 1.634703196347032, "no_speech_prob": 3.881635711877607e-05}, {"id": 85, "seek": 49860, "start": 498.6, "end": 507.64000000000004, "text": " participants. So it worked out. There's still some work to do. So the UI is not yet final.", "tokens": [10503, 13, 407, 309, 2732, 484, 13, 821, 311, 920, 512, 589, 281, 360, 13, 407, 264, 15682, 307, 406, 1939, 2572, 13], "temperature": 0.0, "avg_logprob": -0.13596301026396698, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00012489069194998592}, {"id": 86, "seek": 49860, "start": 507.64000000000004, "end": 513.52, "text": " We're polishing up a little bit. And we're still going to add some more modules to mirror", "tokens": [492, 434, 47258, 493, 257, 707, 857, 13, 400, 321, 434, 920, 516, 281, 909, 512, 544, 16679, 281, 8013], "temperature": 0.0, "avg_logprob": -0.13596301026396698, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00012489069194998592}, {"id": 87, "seek": 49860, "start": 513.52, "end": 518.4, "text": " all the data we want, like the polls and other stuff. And we're thinking that maybe we don't", "tokens": [439, 264, 1412, 321, 528, 11, 411, 264, 24264, 293, 661, 1507, 13, 400, 321, 434, 1953, 300, 1310, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.13596301026396698, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00012489069194998592}, {"id": 88, "seek": 49860, "start": 518.4, "end": 524.4, "text": " really need to support 500 active participants because that's a weird conference, really.", "tokens": [534, 643, 281, 1406, 5923, 4967, 10503, 570, 300, 311, 257, 3657, 7586, 11, 534, 13], "temperature": 0.0, "avg_logprob": -0.13596301026396698, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00012489069194998592}, {"id": 89, "seek": 52440, "start": 524.4, "end": 528.9599999999999, "text": " So that number could actually be lower or pretty much configurable. So you can say,", "tokens": [407, 300, 1230, 727, 767, 312, 3126, 420, 1238, 709, 22192, 712, 13, 407, 291, 393, 584, 11], "temperature": 0.0, "avg_logprob": -0.16815340518951416, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.0003262002719566226}, {"id": 90, "seek": 52440, "start": 528.9599999999999, "end": 533.8, "text": " I want these very many active participants and the rest, it will be visitors. And that's", "tokens": [286, 528, 613, 588, 867, 4967, 10503, 293, 264, 1472, 11, 309, 486, 312, 14315, 13, 400, 300, 311], "temperature": 0.0, "avg_logprob": -0.16815340518951416, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.0003262002719566226}, {"id": 91, "seek": 52440, "start": 533.8, "end": 537.88, "text": " that. And of course, we need to make it easy to deploy for everyone. Right now, this is", "tokens": [300, 13, 400, 295, 1164, 11, 321, 643, 281, 652, 309, 1858, 281, 7274, 337, 1518, 13, 1779, 586, 11, 341, 307], "temperature": 0.0, "avg_logprob": -0.16815340518951416, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.0003262002719566226}, {"id": 92, "seek": 52440, "start": 537.88, "end": 543.1999999999999, "text": " a bit held together with that tip. Before I go, I'd like to give a shout out to the", "tokens": [257, 857, 5167, 1214, 365, 300, 4125, 13, 4546, 286, 352, 11, 286, 1116, 411, 281, 976, 257, 8043, 484, 281, 264], "temperature": 0.0, "avg_logprob": -0.16815340518951416, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.0003262002719566226}, {"id": 93, "seek": 52440, "start": 543.1999999999999, "end": 549.6, "text": " heroes that worked on the guts of this. You may know their names from our community, Boy", "tokens": [12332, 300, 2732, 322, 264, 28560, 295, 341, 13, 509, 815, 458, 641, 5288, 490, 527, 1768, 11, 9486], "temperature": 0.0, "avg_logprob": -0.16815340518951416, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.0003262002719566226}, {"id": 94, "seek": 54960, "start": 549.6, "end": 555.9200000000001, "text": " is Domenico and Jonathan, incredible characters. And I'm relaying the message. I know they", "tokens": [307, 413, 4726, 2789, 293, 15471, 11, 4651, 4342, 13, 400, 286, 478, 24214, 278, 264, 3636, 13, 286, 458, 436], "temperature": 0.0, "avg_logprob": -0.25845104016755754, "compression_ratio": 1.5260869565217392, "no_speech_prob": 0.0004149609594605863}, {"id": 95, "seek": 54960, "start": 555.9200000000001, "end": 563.2, "text": " knew words, but they did the work. And I like to share the love we have for Prosody. We", "tokens": [2586, 2283, 11, 457, 436, 630, 264, 589, 13, 400, 286, 411, 281, 2073, 264, 959, 321, 362, 337, 26024, 843, 13, 492], "temperature": 0.0, "avg_logprob": -0.25845104016755754, "compression_ratio": 1.5260869565217392, "no_speech_prob": 0.0004149609594605863}, {"id": 96, "seek": 54960, "start": 563.2, "end": 568.9200000000001, "text": " wouldn't have been able to do it, I think, without such a flexible piece of software.", "tokens": [2759, 380, 362, 668, 1075, 281, 360, 309, 11, 286, 519, 11, 1553, 1270, 257, 11358, 2522, 295, 4722, 13], "temperature": 0.0, "avg_logprob": -0.25845104016755754, "compression_ratio": 1.5260869565217392, "no_speech_prob": 0.0004149609594605863}, {"id": 97, "seek": 54960, "start": 568.9200000000001, "end": 572.96, "text": " They help us. We help them. It's a very nice relationship we have with the project. We", "tokens": [814, 854, 505, 13, 492, 854, 552, 13, 467, 311, 257, 588, 1481, 2480, 321, 362, 365, 264, 1716, 13, 492], "temperature": 0.0, "avg_logprob": -0.25845104016755754, "compression_ratio": 1.5260869565217392, "no_speech_prob": 0.0004149609594605863}, {"id": 98, "seek": 57296, "start": 572.96, "end": 580.6, "text": " love Matt and team. So shout out to them. And since that's all I got, you can follow", "tokens": [959, 7397, 293, 1469, 13, 407, 8043, 484, 281, 552, 13, 400, 1670, 300, 311, 439, 286, 658, 11, 291, 393, 1524], "temperature": 0.0, "avg_logprob": -0.18093522772731552, "compression_ratio": 1.4811320754716981, "no_speech_prob": 0.0002080344274872914}, {"id": 99, "seek": 57296, "start": 580.6, "end": 585.48, "text": " the progress there. We have documentation actually how to deploy the existing way of", "tokens": [264, 4205, 456, 13, 492, 362, 14333, 767, 577, 281, 7274, 264, 6741, 636, 295], "temperature": 0.0, "avg_logprob": -0.18093522772731552, "compression_ratio": 1.4811320754716981, "no_speech_prob": 0.0002080344274872914}, {"id": 100, "seek": 57296, "start": 585.48, "end": 591.76, "text": " doing things. Again, early stages, but it's there. And if you have any questions, well,", "tokens": [884, 721, 13, 3764, 11, 2440, 10232, 11, 457, 309, 311, 456, 13, 400, 498, 291, 362, 604, 1651, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.18093522772731552, "compression_ratio": 1.4811320754716981, "no_speech_prob": 0.0002080344274872914}, {"id": 101, "seek": 59176, "start": 591.76, "end": 602.4, "text": " I'm around here. Or find me online. Thank you very much.", "tokens": [50364, 286, 478, 926, 510, 13, 1610, 915, 385, 2950, 13, 1044, 291, 588, 709, 13, 50896], "temperature": 0.0, "avg_logprob": -0.23181218571133083, "compression_ratio": 0.9180327868852459, "no_speech_prob": 0.0003447258786763996}], "language": "en"}