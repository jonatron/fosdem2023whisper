{"text": " So, it's nice to see a nice crowd after two years of pandemic. You're beautiful. So today we're going to talk about similarity detection and how we use it in integrity. As a way to ensure that the website is a safe place, that people just maintain an integrity of place. The outline of the presentation is as follows. We're going to outline the problem, then how we use automation and similarity detection in order to achieve what we want. The current technology that we use for images, which is the vector search, then we are going to discuss in depth what is the actual technology, the vector embedding that makes possible to transform a picture into an element of search. The current platform offering that met up with this proposal to allow other people to crowd source all of their findings into a centralized place. And last but not least, what we have of open and free that you can install in your own, you can deploy in your own site to benefit all these technological findings. So the problem is that any big platform bears the responsibility to ensure it's a safe place to serve. No matter what also the law says, that you have to make sure whatever the user posts, you are ultimately responsible to make sure that everybody is just not exposed to things that will violate your community guidelines. Meta has almost three billion users, it's likely less than a world population. And although the vast majority of our users follow rules, some fringe bad actors will always be present. And at that scale, fringe means tens of millions of bad person creating a lot of problems. And when I mean issues, problems, I mean child exploitation, imageries, non-consensual, intimate imagery, which is a way to say revenge porn, adult sexual exploitation, people forced to perform sexual acts in front of camera against their will, terrorism, violence, whatever. And just to give you a couple of numbers, Meta publishes a transparency report quarterly about what we do to ensure the platform stays safe. And on the second quarter of 2022, we removed the 38 million of adult sexual exploitation pieces of content taken down. And it's just for this category, child exploitation is not so huge, thank God, but also there are other like violence, terrorism and stuff. That accounted for the 0.04% of view content worldwide. And in case you were asking, 97% of this content was proactively taken off, even before people could even see it. The remaining 2.8% is user reports, like I found this. And we take that down also, and we also add to the data banks just to make sure that we are not forgetting about that. Sometimes there are false positives because it's just unavoidable. And half million was restored upon user appeal. And we restore accounts and mostly accounts and the pictures that we're banned for. It goes by itself to the sheer volume of content, the huge scale, the problem we are facing, requires both automation and also human review to ensure either accuracy, both accuracy and also consistency. So there will be a problem if we had the 1 million people clicking and making decisions and what is violating for one is not for the other and vice versa. And so, and we cannot just also just employ automation, because otherwise we will have this very powerful site, decapitating everybody, also innocent users. So the role of automation and similarity detection, the thing is that a lot of things that happen online are things that are being repeated. So are things that are already occurred in the past. Like people posting a picture of some shooting, some mass shooting, for example, like the buffalo or the Christ church, gets taken down and the 10 more accounts spawn and post the same things. So it's much, it's very efficient to reason in terms of let's just redo the things that we already found out that worked. We employ automation to scale, of course, handle the scale of the problem and to consistently repeat a decision that a human reviewer has already vetted in the past. So we tie a content to a decision, a violating content to a decision, let's act upon this. And we take, we act, we tie the decision to the actions. Let's just repeat this action every time we meet a piece of content that triggered this same decision. We do that for videos, for pictures, and also for text. Today we'll be mostly talking about images because the techniques for video and pictures are somewhat very similar, text has a completely different array of techniques that we'll not be presenting today. So a way to, if you want to achieve similarity detection, you have to come up with a way to achieve similarity first. So how do we compare to pictures? Of course, we are not, we are not be doing pixel by pixel comparison. We want to be much faster. Our way to do that is just, okay, let's just MD5 hash all the pictures or SHA1 all the pictures and then we store them somewhere in an indexing system. And whenever a new picture comes in, we just recreate the hash and if it matches, we just ban, right? Well, that doesn't work very well because the cryptographic hashes are not resistant to resizing, rotation, one pixel alteration, all the hash changes all together. Instead, we can really benefit from local hashing because it allows for similarity measurement. Like you change slightly one piece, one portion of the image, and the hash changes a little, but not completely. Then you can reason in terms of distance between two hashes. So you have to turn, you have to find a way to turn an image into a vector and then you perform a vector search. Whenever two vectors are very, very close beyond a certain threshold, then it's probably a match. And just in case if you're asking, these are based as the architecture. You have more or less all the architectures share these four stages, observation, an image has been generated, usually push event like user uploaded something. Then you have the representation phase in which you hash the image to a compact representation. If you're indexing, you store that into your index and instead if you are at inference time like an event someone uploaded something, you search the index they have built with representation. In case you have a match, you action upon what you decide what to do with the match you got. Usually the idea is that this is very close to an image that I already see in the past that was banned and also the account was taken down. Do the same to this user. So first three pieces of content, Facebook has released a library which is FICE, the Facebook similarity search library is a library to do similarity search over a vector of dense vectors or vector floats or integers, for example. You can think about it like a C++ version of Lucene so you index stuff, puts that in a very big space and you can search in this space very fast. It supports CUDA so you can use your GPUs to search. It's basically index on steroids and it's C++ but it has Python bindings available and it scales almost nearly. You can really index 100 millions of pieces on a single machine and it just handles them really, doesn't need to saturate all the memory so it has a very good optimization properties that makes it a very good tool and you can go and download that on GitHub. Today we are also mostly referring to with the perceptual ashing. This means that we are reasoning in terms of colors, colors and images, shapes. We are not reasoning about what's happening inside the image. That's the semantic ashing which we are not going to talk about this today. Perceptual ashing just captures visual similarities and it's very nice for use case because it exactly does its job. So you might think that we are all talking about machine learning systems that come up with very clever representations about our pictures and I'm asking do we really need a convnet for that? Do we really need to employ GPUs? You already said that it's on CUDA so perhaps that's a nice hint but absolutely not. Most of this technology is like a ashing technology so they just computer represent a mathematical transformation over the image and it's really fast and it's really cheap and it can be executed almost everywhere. So a little bit of history, the first very notable example, it comes from a source that nobody would have thought about, it's Microsoft in 2009. Microsoft invents photo DNA. Photo DNA is the first algorithm employed in fight against exploitive images of children. So it transforms a picture into an ash of 144 unsigned integers on 8-bit representation. It's proprietary. So Microsoft licenses this to any non-profit or any organization that wants to fight exploitive images of children. It gives you a license, you can use for that and nothing else. But I cannot disclose the details of how that works. It can be used only for that but Microsoft donated the photo DNA to the National Center for the Missing and Exploited Children, the NACMAC. It's this American non-profit that basically acts as a coordination center in global fight against this phenomenon and shares this library with anyone that wants to integrate. This I cannot talk about how this works, this is the only moment in which I will say something like that. But we can talk about an open source counterpart that almost 10 years later Facebook releases PDQ. PDQ stands for Perceptual Algorithm Using Discrete Cousin Transform and gives a quality metric. It's a very, very bad acronym but we need a three-letter acronym so it's that. It creates a 256-bit hash, uses hamming distance to compute the distance. It's really fast. The compute overhead is negligible compared to discrete. Can tolerate some level of adversality. This means that you change the image because you want to fool the systems in that this image is not something which is well-known, PDQ can resist a little to this manipulation but not all of them. It's used in stopncii.org. It's a website where people, in case you have a fight with your ex-fianc\u00e9 and he's threatening to publish your intimate imagery, you go to stopncii.org, you upload your intimate imageries, fingerprints get taken, original images get deleted right away of course, and these fingerprints are shared with partners that, okay, if I am going to see these fingerprints in my website, my platform, I'm going to take them down. So it's a crowd source effort and uses PDQ for images. How does that work? So PDQ hashing is, optionally scale down to a square image, okay. Then you compute the luminance. Luminance is the idea that you take the pixel that contributes most in the RGB channel. Instead of putting black and white, you use the luminance. It's just another procedure and the idea is that the luminance gives you better information about what was the channel that was contributing most to the color, to the light in that place. Then you down sample to 64 times 64 using a blur filter and the idea of the blur filter or tent filter is that it gets the most significant value in that region because if you keep convoluting a pixel with your neighborhood, what you will have in the end will be the highest value. So you obtain a representation which is compact and retains the most significant information. Then you divide the images in 16 times 16 boxes, each one by 4 pixels, and you calculate a discrete cosine transform of each box. The discrete cosine transform, so the box is at the 4 bar color there. You see that the grid with a lot of wobbly images, that is a discrete cosine transform. The idea is that any image, any signal can be represented as a sum of cosine signals. You only take the signal, the most significant one, so it's a form of compression actually, and you take the most significant coefficient for the biggest cosine you have. And then you calculate if the median is above a certain value, then it's one, otherwise it's zero. So you get this 256 in an array of 010101 in case this pixel were a high luminance or a low luminance. The DCT provides a spectral hashing property, identifies what is the point in the images, that contributes more or less. You have an hashing space, which is 2 to the power of 1 to 28, because it's half the ashes, because half is always 0, half is always 1. To search, you just do a vector search again, what you've just created. In case we want, we can use partially the same technology to do video hashing, and this is another, it comes in almost the same paper. The TMK is a temporary matching kernel, is a way to use the PDQ creation to do a video similarity detection algorithm. It produces a fixed length video hashes, so your hash stays at the same length, which is like 256 kilobytes, if I'm not wrong, even if your video lasts for 3 hours or 30 seconds. It just produces a fixed length, so it's really nice. What you do is that you resample a video to 15 frames, then you compute the PDQ without the 01 quantization, so you keep the float numbers. That's why it's called PDQF, PDQ float, and then you compute the average of the old descriptors that you have within various periods of the cousin and scene. Why we add the cousin curves? Because a cousin or a scene adds this wobbly movement that tells you whether a frame is before or later in the near surroundings, the near neighborhood of the frames. In case you have 10 pictures, you add this cousin signal, you know this picture is before this one because you see the cousin curve which is going up and going down, and it's a nice uniqueness fingerprinting time signature algorithm to add a cousin. You compute the average of all the frames, the PDQF for all the frames, with various periods, various scene and cousin, and then you pack them all together, and you have these five or six averages, and that's your PDQF embedding. Exampling is just you compare first the vector zero, which is the average of all the frames and doesn't retain a temporal signature, then if there is a match, you compare also all the other vectors at different periods, which are the level two action as the time signature, and so you can be really be sure that the videos are really the same, because if you find the same averages with the same periods, it must be the same video. It's nice that it's resistant to resampling, because you always resample. So in some way, if you vary the frame rate, the video will change, and MD5 hash will change, but this one is not full load. Ashing is really slow, because you have to do a transcoding of all the videos first, and then you have to read all the frames and compute the PDQ for every frame. But search is actually very fast. Another nice hashing technique that we have is the video MD5. I said that we will not be using a crypto-ashes highlight. We use crypto-ashes, but just for videos. This because if you take a MD5 of video and find exact copies, it's really cheap in this way. A lot of actors just repost unmodified content. They are not going really through the hassle of doing a encoding just to try to fool the systems. They just try to repost again. So the MD5 actually works, and it can be done with vector search if we use the bytes for the MD5 algorithm. And it's used widely in stopncii.org also. In 2022, Facebook has released the video PDQ, which is a different algorithm from the former one. Hashing is that we hash every frame to a PDQ hash, and we just pack the list. It's much bigger. It's not slower than the other one, but it has a nice property that we just have to search for individual frames. So we treat the problem as a back-of-word approach. So we just put all these frames inside an index library. Then we search, and we take all the candidates, and we do a pairwise comparison. If the pairwise comparison is successful beyond a certain threshold, then it's a match. And also this you get for free, and it's released along with the PDQ, along with the TMK, PDQF. All this is available inside the Facebook Research GitHub repository. What do you do once you have all these hashes? Your platform is computing the hashes, but it's the first time that you see this content, but perhaps all other actors have already seen this content, too. While you upload them to the threat exchange platform, Necmac shares the PDNA hashes, I told you, with all companies that are asking for them. So can you please tell me where this picture that someone uploaded is a match in Necmac? So I already know that this is something I should call the law enforcement. Data does the equivalent, but for the PDQ, because it has much less friction to adopt the PDQ compared to the PDNA. There's a team, the Internet Safety Engineering that builds and operates all these services where anyone can upload fingerprints, and so you can crowdsource a big graph of matches. There's REST API to access and post new data, has multi-language clients, uses PDQ, and users can also download the data. You are not forced to stay online, stay connected. You can just request for a dump of the database and you can search it. And you find all the data and all the APIs at the GitHub page. In 2020, Facebook also has released its most advanced algorithm to spot similar images, the SimSearchNet++. This is an error network, and it is capable of facing adversarial manipulation that the other embeddings just are not able to. Unfortunately, SimSearchNet is proprietary, so I cannot really talk about that, but we have a cousin product, SSCD, the SimSearch Copy Detection, which is open source and free. So I can really talk about that. They are somewhat related in some technological principles, so I can really talk about this. So this is a PyTorch-based model. So the problem that this, which is a state-of-the-art product, is trying to solve is what happens if I take a picture and I put a caption on it, alterating so many pixels everywhere. A PDQ or a PDNA-ASH would be altered dramatically, but is there anything we can do to teach a computer to just ignore all the captions, all the rotations, all the jitters, all the cropping of the image? Yes, there is. A person is able to do that, so we can teach a computer to do that, too. So models and code are available. What is now available is the training data that we use to create a model, of course. For those which are into the deep learning, it's a ResNet 50 convolutive neural network. And the novelty of the approach is that it's based on our MAC vocabularies. Our regional MAC, for those, how many of you know how a convolutive network work? Raise your hand. Okay, fine. Very good. So it's a network for the others that looks at the image, looks at portions of the image. Each neuron looks at a different portion, and then they pass what they have understood to a higher level series of neurons, the higher and the higher and the higher, until the last layer of the neurons has a very wide overview of the whole picture. In this case, we are using the maximum activation of all the channels that we have. So we take note which are the regions of our Carnaut maps for every different channel, which across all channels have the maximum activation. If you have 10 channels, and that region across all the different channels, all of them you have a maximum activation, that means that that area is an area of interest. So we use these areas of interest as a word in a vocabulary. So exactly when you do the Cosine similarity search for documents, you take all the words, you index all the words, you say these documents as these words, so it's like a vector of words, and then we try to see which are the vectors that have the most words in common and put in the same place. We do the same things, but for portions of the image. So we use the rmax. The idea is that it's a self-supervised system also. So it means that it's trained to recognize augmented input, and it's trained to match an input to its augmented version. So what we do is that we take the training set, we repeat a lot of augmentation, we add the captions, the randomity, we rotate, we flip, we alter the colors. For example, if you do a one degree of whitening, you make the image brighter, which is you add plus one to all the pixels in the image, you are altering all the pixels. But in this case, a PDQ hash is capable of understanding the difference. There's a very weak form of adversarial attack, because the PDQ just computes the difference between regions, so it's not going to be fooled. But you can be much more violent and put just a spot color somewhere, and PDQ is going to be fooled by that. Then you do through the CNN, you do a thing called gem pool, which means you do a generative mean pooling, a generalization of the average pooling, in case you were wondering. Then you go, and at the end you use an entropy-oriented loss function. This means that we want to encourage the network to spread the representation of training data along all different places, because we want to maximize the distance between all the training examples in the training set. So you get a nice uniform search space. At the inference time, you do the same with the CNN, and then you obtain a vector, which is a representation of an image. And the idea is that there is a distance that you can compute between the data set of the reference images. Of course, you can subtract a background data set that was used generally to augment the images, but in this case, what you obtain in the end is that the score of the augmented image is almost the same of the non-augmented version, because it just learns to ignore the places which are not organic in the image. And SSCD is freely available. You can download that and start playing. You find both code and models, as I already said, but not the training data. And by the way, Facebook has also announced an image similarity challenge. You have to determine whether a query image is a modified copy of any image in a reference corpus of one million. This is very similar to the Netflix recommendation challenge, when you had to recommend the movies and you had to beat Netflix's algorithm. And this is the image similarity challenge, and also the meta-IE video similarity challenge, which is two tracks. Generate a useful vector representation for a video, and also try to find a reference video into this very big corpus, and you don't have to only find a video. You have to find a clip, so a sub-portion of a video, into a very big corpus. And last but not least, since the last part of a donor is the tastier one, we have your turnkey open-source solution that you can install in your own premise. The hushier matcher actioner. HMA is an open-source turnkey safety solution. So you just download it, install it, and it starts working right away. What it does is that it scans the images that you want to push towards it. It has an index that is updated with all the hashes coming from thread exchange, but also from yours, and is able to, say, to bind banks' verticals of violations. You might have a non-severe violation or very severe violation, and you might decide that for non-severe violation, you just delete the content and send a warning, or for high-severity violation, you just immediately delete the content, shut down the account of the poster, and you also signal it to the law enforcement. You can do that. And you can configure actions in a backend that are tied to the content that you want to bank into your HMA platform. You can pull violating seeds from Facebook thread exchange API, and works on AWS only, because we wanted to make a very easy-to-use thing, and also something that doesn't really mix your bill higher. So we built it on AWS Lambda. So it doesn't cost anything until it runs, then it runs, spawns a Lambda instance, and then goes down, and you only pay for the seconds that it actually runs. But it's very fast. And there's a Terraform module available thanks to the lovely folks of the Internet Safety Engineering. This is how you deploy that. Your infra, you collocate HMA to your platform. For example, you might own a platform where people have a chat or people post pictures. Whenever new content comes, the web server asks the Azure, have you seen this? And the Azure goes to Matcher. Matcher goes to the index and says, do I know this? And in case there's a match, the actioner module will just tell your, you have to define a callback API in your own platform, like whenever the actioner calls, you are killing this content in your own backend. And, of course, you can fetch from external API new content from the fact exchange platform. So wrapping up, automation is necessary to be effective. But you will lose precision, of course, because automation doesn't really think. It just does whatever you have configured blindly. Human support is always needed for appeals and also to establish the ground through. So what is actually violating, what is not? Do expect false positive, because they will happen. You should put in place an appeal process to allow your users to restore the content. PDQ, video PDQ, MT5 and SSCD will provide you with a way to obtain compact representation of high dimensionality content like pictures and videos. HMA provides you with a turnkey solution that you can install on premise, on your premise, and search and enforce your integrity policies at your platform. And thread exchange provides you with a platform for exchanging representation with other big actors like, maybe, itself, for example. That was all from me. Thank you very much for listening. Any questions? You mentioned it for the challenge, I think? Oh, louder. So you mentioned it for the challenge, finding a clip of a video. Can PDQ do that, actually? You can't hear me. So can PDQ find clips of videos? That's my question, actually. So you should, you say, perhaps I heard about YouTube, what is something that already does. Like if the challenge is to find the clips of videos. Yeah, in general, it's possible, of course, and the video PDQ algorithms will ask every frame. So in case you send a very small sub portion of a video, you will have, like, 100 frames, for example, then these 100 frames will be treated as a bag of words. You search the index, you find the video that contained all of these words. So you have a match of all your query frames inside the index at the very long video that has it. And so it's a match. That's how we do. Of course, there are more clever ways to do that. Thanks. Hello. Not a technical question, but let's see. I was thinking that if you're using such a system to try to prevent digital crimes and such things like that, from an ethical perspective, I was just wondering that you, I suppose you have such images to compare them. And how do you process those, how do you make the decisions? So I repeat the question. From the ethical perspective, the idea is that, of course, we have to see the images in order to be able to know what's happening, right? Yeah, see and, of course, you have to save them and, I don't know, process them and how do you handle this? So this is not the kind of question that I really can answer because it is related to internal procedures. Now, if we have to compute the fingerprint of an image, there must be a one second in which the image is on our surface. It is, since the agency is like NECMAC, they share ashes. So you might have an ash for which you don't have a picture. And you have to trust that this ash is coming from a trusted source that has already vetted whether this ash is nasty stuff or not. That's how we actually avoid sanctioning heavily innocent people. So there is a collaboration with the trusted entities for this. When you receive those from an external agent, if those images are on your platform, you already know what you've seen. Thank you. Can you hear me despite the mask? Can you hear me? Thank you. So I have a question, but first I have a thanks because I have worked in this kind of thing and NECMAC doesn't share any useful data, IWF doesn't share any useful data, Farros doesn't share any useful data. So I will definitely take a look at the threat exchange platform and hope that it's much more useful. And thanks for that. No, I have a question anyway. If I was an attacker, I could download data from the threat exchange platform and try and run as many filters automatically until I find something that is not matched by PDQ, video PDQ, et cetera. What's the way to counter that? Oh, you're asking whether adversarial attacks are possible on PDQ? Yeah, of course. PDQ is a very naive algorithm that just detects the patches of colors. It is actually possible to create adversarial attacks. Just if you think that you alter many pixels in the image and perceptually for us doesn't change anything, but you might end up changing the most relevant pictures for the DCT algorithm. I will create a completely different ashing in the end. Also someone has demonstrated an attack, a reverse engineering attack on photo DNA. Like from the project, it's called ribosome. And it's a neural network that from a hash reconstructs a very blurry picture. So it is actually possible to do that, but PDQ is a very simple and fast algorithm. If you really want to combat seriously adversarial engineering, the things that you need neural networks like SSCD because it contains so many relations to different parts of the images and it's much harder to fool. I'm not saying it's not impossible because, of course, it's possible. In general, later someone will find a way, but it's the usual arms race between attackers and defenders. And it's no exception. Thank you for your question. Hello. Hi. First, thank you for the presentation. I think it's a very interesting topic. I wanted to link it because it's been a bit of a buzz the past few weeks, the generative AI, especially chat GPT, was wondering when you use that kind of algorithm and you scan an image, detect something, is there a level of confidence attached to the result and can you detect when an image is potentially a fake or? There is a lot of time because there's an echo, so I cannot really, can you do it louder please? It's hard to understand from here. Hello. Okay. Is it better? Okay. Yeah, so I said thank you, but I wanted to link to generative AI and I was asking so when you run that kind of algorithm to detect violence or child abuse or anything else, can you also attach a level of confidence in the response to explain whether it's, well, to define whether it's a potentially fake picture or is there an extension to the algorithm where you can link with the generative AI? I'm not sure about the answer. Sorry, we can go for a beer and I can explain more details and let's see. Yeah, you have a question. Hi. Thank you for the talk. It was very interesting. One more question also. Do you run SSCD in production as well? The deep learning network? If we're using SSCD in production, can't I reply to this question? We use simsearch net plus plus. We use this other one because we have written a blog post about this, so I can confirm that we use simsearch net plus plus. I cannot nor confirm or deny about SSCD, but those are related technologies, so I could talk about that. What does the production stack for simsearch net plus plus look like? How do you serve it? It must be pretty hard to deal with the GPUs. This is not a question that I'm sorry. I cannot talk about the production setups. I'm sorry. Okay, any question nearby? Thank you. Of course, you can imagine that we do not operate in the vacuum, so if you can think about how we serve results from a neural network, it is something perhaps similar to what would you do if you would have to put behind an API a model? So I kind of have two questions. The first question is, to what extent do... I think there are potentially two problems. Intentional mismatches and unintentional mismatches. So situations where perhaps an image has been recompressed or has been cropped, or is perhaps another image of the same situation, versus situations where people have deliberately deformed the image to try and get around these kind of systems. Do you have any idea of how performant it is against the two scenarios of either accidental or unintentional mismatches versus intentionally trying to avoid it? So it is, of course, possible to have unintentional mismatches, and I've seen images that were adversarial engineered to give the same embedding. Those are absolutely possible, again, in PDQ, PDNA, and all the perceptual hashing, which is just a mathematical transformation. You just have to find a way where the input seems the same to the algorithm. For the neural network things, it depends. You can study the code, you can study how it's done, if you can, it is absolutely possible sooner or later, because the adversarial attacker on combinets are a reality, so it's absolutely possible. I've seen some mismatches, but usually two perceptual hashes. Usually the more refined the technique, the harder it is to attack, of course, otherwise we just will stay with MD5, because it will be enough. Crops. PDQ is resistant to crops, SSCD is very resistant to crops. If you have rotations, I believe also PDQ is resistant to rotations, like flips, but you cannot ask much more than that. Other questions? Yeah. Do you have any information about the speed difference between SSCD and PDQ? So the question is whether I have some speed benchmarks for the difference of performance between PDQ and SSCD at inference time. PDQ is faster than your time to read the image from disk. So it's negligible. It will just compute. It's a mathematical transformation on the pixel. The neural network requires a dedicated hardware, if you do that on CPU it will take seconds, also because the model I think is big enough. It's not as big as GPT, but it's a 50 level CNET. So it's of course lower and requires dedicated hardware, but it's more precise. It just finds, SSCD finds anything that PDQ is able to find and much more. So in case, if you are very curious about, sorry, if you are very conscious about, I have to scan this stuff just to make sure they don't come from a ill source. You might want to set up an async process that will take more, but will just batch process all your stuff. If you need a super fast thing, PDQ will not really wait over your server. Thank you. Any other question? Hi. First of all, great question from my former colleague David, I think, down there. Not even looking this way. But what happens if you get a false positive match? How do you disregard that in the future without potentially disregarding a real match? So if we get a false positive match, how do we do to restore? Yeah. How do you restore? You mean or in MEDA all the day? Just anywhere. Like as a concept. So in MEDA, I cannot really say. With the Asher Matcher Actioner, you have the, you should provide a capability to your own platform for which you are soft deleting the image because you have to provide away an API in your platform that HMA will call on, where you say, soft delete this picture. So make it unavailable, but do not really delete it in case you want to appeal. So you need to provide like, undelete and unsoft delete and soft delete. This is the simplest way and most effective way to deal with false positive in case, whoops, I did a mistake, I want to restore the content. Sure. But if you have an image that someone wants to upload, say it's a popular image that a lot of people are going to upload, but it matches a pattern of another bad image, can you auto, is there a good way to make a more precise hash and exclude that and say this one is a false positive? It doesn't match what you think it does. So you don't have to keep undoing the. Okay. So partly if the image is popular, so we have many examples and we have many examples of an image which is not bad and then comes a bad image, whether we can use the fact that it's very widespread to augment our position. Is this the question? Okay. Well, really, there's nothing in this presentation that says these because once you train the network is trained and you start serving and the network will give you the same answers to the same question, to the same query. PDQ or other mathematical algorithm, perceptual algorithm is just a mathematical function so will not change. There's nothing to train. So to change a deficiency of your model, you have to retrain. You can do a better retraining and sometimes model are retrained as anything which is still under maintenance. For example, we get new data, for example, and we might want to retrain as any other model also for the spam filters is the same. Do we have more room for questions? I think it's done. Thank you so much. You'll be a wonderful audience. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.84, "text": " So, it's nice to see a nice crowd after two years of pandemic.", "tokens": [407, 11, 309, 311, 1481, 281, 536, 257, 1481, 6919, 934, 732, 924, 295, 5388, 13], "temperature": 0.0, "avg_logprob": -0.26647360428519873, "compression_ratio": 1.302325581395349, "no_speech_prob": 0.2748907804489136}, {"id": 1, "seek": 0, "start": 10.84, "end": 12.56, "text": " You're beautiful.", "tokens": [509, 434, 2238, 13], "temperature": 0.0, "avg_logprob": -0.26647360428519873, "compression_ratio": 1.302325581395349, "no_speech_prob": 0.2748907804489136}, {"id": 2, "seek": 0, "start": 12.56, "end": 20.72, "text": " So today we're going to talk about similarity detection and how we use it in integrity.", "tokens": [407, 965, 321, 434, 516, 281, 751, 466, 32194, 17784, 293, 577, 321, 764, 309, 294, 16000, 13], "temperature": 0.0, "avg_logprob": -0.26647360428519873, "compression_ratio": 1.302325581395349, "no_speech_prob": 0.2748907804489136}, {"id": 3, "seek": 2072, "start": 20.72, "end": 31.439999999999998, "text": " As a way to ensure that the website is a safe place, that people just maintain an integrity", "tokens": [1018, 257, 636, 281, 5586, 300, 264, 3144, 307, 257, 3273, 1081, 11, 300, 561, 445, 6909, 364, 16000], "temperature": 0.0, "avg_logprob": -0.16145285693081943, "compression_ratio": 1.65, "no_speech_prob": 0.0009682251838967204}, {"id": 4, "seek": 2072, "start": 31.439999999999998, "end": 33.84, "text": " of place.", "tokens": [295, 1081, 13], "temperature": 0.0, "avg_logprob": -0.16145285693081943, "compression_ratio": 1.65, "no_speech_prob": 0.0009682251838967204}, {"id": 5, "seek": 2072, "start": 33.84, "end": 36.12, "text": " The outline of the presentation is as follows.", "tokens": [440, 16387, 295, 264, 5860, 307, 382, 10002, 13], "temperature": 0.0, "avg_logprob": -0.16145285693081943, "compression_ratio": 1.65, "no_speech_prob": 0.0009682251838967204}, {"id": 6, "seek": 2072, "start": 36.12, "end": 41.64, "text": " We're going to outline the problem, then how we use automation and similarity detection", "tokens": [492, 434, 516, 281, 16387, 264, 1154, 11, 550, 577, 321, 764, 17769, 293, 32194, 17784], "temperature": 0.0, "avg_logprob": -0.16145285693081943, "compression_ratio": 1.65, "no_speech_prob": 0.0009682251838967204}, {"id": 7, "seek": 2072, "start": 41.64, "end": 45.120000000000005, "text": " in order to achieve what we want.", "tokens": [294, 1668, 281, 4584, 437, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.16145285693081943, "compression_ratio": 1.65, "no_speech_prob": 0.0009682251838967204}, {"id": 8, "seek": 2072, "start": 45.120000000000005, "end": 50.120000000000005, "text": " The current technology that we use for images, which is the vector search, then we are going", "tokens": [440, 2190, 2899, 300, 321, 764, 337, 5267, 11, 597, 307, 264, 8062, 3164, 11, 550, 321, 366, 516], "temperature": 0.0, "avg_logprob": -0.16145285693081943, "compression_ratio": 1.65, "no_speech_prob": 0.0009682251838967204}, {"id": 9, "seek": 5012, "start": 50.12, "end": 57.599999999999994, "text": " to discuss in depth what is the actual technology, the vector embedding that makes possible to", "tokens": [281, 2248, 294, 7161, 437, 307, 264, 3539, 2899, 11, 264, 8062, 12240, 3584, 300, 1669, 1944, 281], "temperature": 0.0, "avg_logprob": -0.1900245977002521, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0010753244860097766}, {"id": 10, "seek": 5012, "start": 57.599999999999994, "end": 61.36, "text": " transform a picture into an element of search.", "tokens": [4088, 257, 3036, 666, 364, 4478, 295, 3164, 13], "temperature": 0.0, "avg_logprob": -0.1900245977002521, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0010753244860097766}, {"id": 11, "seek": 5012, "start": 61.36, "end": 66.75999999999999, "text": " The current platform offering that met up with this proposal to allow other people to", "tokens": [440, 2190, 3663, 8745, 300, 1131, 493, 365, 341, 11494, 281, 2089, 661, 561, 281], "temperature": 0.0, "avg_logprob": -0.1900245977002521, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0010753244860097766}, {"id": 12, "seek": 5012, "start": 66.75999999999999, "end": 72.84, "text": " crowd source all of their findings into a centralized place.", "tokens": [6919, 4009, 439, 295, 641, 16483, 666, 257, 32395, 1081, 13], "temperature": 0.0, "avg_logprob": -0.1900245977002521, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0010753244860097766}, {"id": 13, "seek": 5012, "start": 72.84, "end": 79.0, "text": " And last but not least, what we have of open and free that you can install in your own,", "tokens": [400, 1036, 457, 406, 1935, 11, 437, 321, 362, 295, 1269, 293, 1737, 300, 291, 393, 3625, 294, 428, 1065, 11], "temperature": 0.0, "avg_logprob": -0.1900245977002521, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0010753244860097766}, {"id": 14, "seek": 7900, "start": 79.0, "end": 87.56, "text": " you can deploy in your own site to benefit all these technological findings.", "tokens": [291, 393, 7274, 294, 428, 1065, 3621, 281, 5121, 439, 613, 18439, 16483, 13], "temperature": 0.0, "avg_logprob": -0.14049486466396002, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0005043279961682856}, {"id": 15, "seek": 7900, "start": 87.56, "end": 94.28, "text": " So the problem is that any big platform bears the responsibility to ensure it's a safe place", "tokens": [407, 264, 1154, 307, 300, 604, 955, 3663, 17276, 264, 6357, 281, 5586, 309, 311, 257, 3273, 1081], "temperature": 0.0, "avg_logprob": -0.14049486466396002, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0005043279961682856}, {"id": 16, "seek": 7900, "start": 94.28, "end": 95.28, "text": " to serve.", "tokens": [281, 4596, 13], "temperature": 0.0, "avg_logprob": -0.14049486466396002, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0005043279961682856}, {"id": 17, "seek": 7900, "start": 95.28, "end": 100.68, "text": " No matter what also the law says, that you have to make sure whatever the user posts,", "tokens": [883, 1871, 437, 611, 264, 2101, 1619, 11, 300, 291, 362, 281, 652, 988, 2035, 264, 4195, 12300, 11], "temperature": 0.0, "avg_logprob": -0.14049486466396002, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0005043279961682856}, {"id": 18, "seek": 7900, "start": 100.68, "end": 107.32, "text": " you are ultimately responsible to make sure that everybody is just not exposed to things", "tokens": [291, 366, 6284, 6250, 281, 652, 988, 300, 2201, 307, 445, 406, 9495, 281, 721], "temperature": 0.0, "avg_logprob": -0.14049486466396002, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0005043279961682856}, {"id": 19, "seek": 10732, "start": 107.32, "end": 112.08, "text": " that will violate your community guidelines.", "tokens": [300, 486, 37478, 428, 1768, 12470, 13], "temperature": 0.0, "avg_logprob": -0.19826946258544922, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0011574341915547848}, {"id": 20, "seek": 10732, "start": 112.08, "end": 117.52, "text": " Meta has almost three billion users, it's likely less than a world population.", "tokens": [6377, 64, 575, 1920, 1045, 5218, 5022, 11, 309, 311, 3700, 1570, 813, 257, 1002, 4415, 13], "temperature": 0.0, "avg_logprob": -0.19826946258544922, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0011574341915547848}, {"id": 21, "seek": 10732, "start": 117.52, "end": 123.24, "text": " And although the vast majority of our users follow rules, some fringe bad actors will", "tokens": [400, 4878, 264, 8369, 6286, 295, 527, 5022, 1524, 4474, 11, 512, 38764, 1578, 10037, 486], "temperature": 0.0, "avg_logprob": -0.19826946258544922, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0011574341915547848}, {"id": 22, "seek": 10732, "start": 123.24, "end": 124.52, "text": " always be present.", "tokens": [1009, 312, 1974, 13], "temperature": 0.0, "avg_logprob": -0.19826946258544922, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0011574341915547848}, {"id": 23, "seek": 10732, "start": 124.52, "end": 133.79999999999998, "text": " And at that scale, fringe means tens of millions of bad person creating a lot of problems.", "tokens": [400, 412, 300, 4373, 11, 38764, 1355, 10688, 295, 6803, 295, 1578, 954, 4084, 257, 688, 295, 2740, 13], "temperature": 0.0, "avg_logprob": -0.19826946258544922, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0011574341915547848}, {"id": 24, "seek": 13380, "start": 133.8, "end": 141.8, "text": " And when I mean issues, problems, I mean child exploitation, imageries, non-consensual, intimate", "tokens": [400, 562, 286, 914, 2663, 11, 2740, 11, 286, 914, 1440, 33122, 11, 2576, 21659, 11, 2107, 12, 21190, 694, 901, 11, 20215], "temperature": 0.0, "avg_logprob": -0.17097017376921897, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001558454823680222}, {"id": 25, "seek": 13380, "start": 141.8, "end": 147.44, "text": " imagery, which is a way to say revenge porn, adult sexual exploitation, people forced to", "tokens": [24340, 11, 597, 307, 257, 636, 281, 584, 16711, 19444, 11, 5075, 6701, 33122, 11, 561, 7579, 281], "temperature": 0.0, "avg_logprob": -0.17097017376921897, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001558454823680222}, {"id": 26, "seek": 13380, "start": 147.44, "end": 156.36, "text": " perform sexual acts in front of camera against their will, terrorism, violence, whatever.", "tokens": [2042, 6701, 10672, 294, 1868, 295, 2799, 1970, 641, 486, 11, 23917, 11, 6270, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.17097017376921897, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001558454823680222}, {"id": 27, "seek": 13380, "start": 156.36, "end": 163.20000000000002, "text": " And just to give you a couple of numbers, Meta publishes a transparency report quarterly", "tokens": [400, 445, 281, 976, 291, 257, 1916, 295, 3547, 11, 6377, 64, 11374, 279, 257, 17131, 2275, 38633], "temperature": 0.0, "avg_logprob": -0.17097017376921897, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001558454823680222}, {"id": 28, "seek": 16320, "start": 163.2, "end": 168.83999999999997, "text": " about what we do to ensure the platform stays safe.", "tokens": [466, 437, 321, 360, 281, 5586, 264, 3663, 10834, 3273, 13], "temperature": 0.0, "avg_logprob": -0.17469058194003262, "compression_ratio": 1.4979591836734694, "no_speech_prob": 0.0020674094557762146}, {"id": 29, "seek": 16320, "start": 168.83999999999997, "end": 177.35999999999999, "text": " And on the second quarter of 2022, we removed the 38 million of adult sexual exploitation", "tokens": [400, 322, 264, 1150, 6555, 295, 20229, 11, 321, 7261, 264, 12843, 2459, 295, 5075, 6701, 33122], "temperature": 0.0, "avg_logprob": -0.17469058194003262, "compression_ratio": 1.4979591836734694, "no_speech_prob": 0.0020674094557762146}, {"id": 30, "seek": 16320, "start": 177.35999999999999, "end": 179.28, "text": " pieces of content taken down.", "tokens": [3755, 295, 2701, 2726, 760, 13], "temperature": 0.0, "avg_logprob": -0.17469058194003262, "compression_ratio": 1.4979591836734694, "no_speech_prob": 0.0020674094557762146}, {"id": 31, "seek": 16320, "start": 179.28, "end": 183.76, "text": " And it's just for this category, child exploitation is not so huge, thank God, but also there", "tokens": [400, 309, 311, 445, 337, 341, 7719, 11, 1440, 33122, 307, 406, 370, 2603, 11, 1309, 1265, 11, 457, 611, 456], "temperature": 0.0, "avg_logprob": -0.17469058194003262, "compression_ratio": 1.4979591836734694, "no_speech_prob": 0.0020674094557762146}, {"id": 32, "seek": 16320, "start": 183.76, "end": 187.2, "text": " are other like violence, terrorism and stuff.", "tokens": [366, 661, 411, 6270, 11, 23917, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.17469058194003262, "compression_ratio": 1.4979591836734694, "no_speech_prob": 0.0020674094557762146}, {"id": 33, "seek": 16320, "start": 187.2, "end": 192.67999999999998, "text": " That accounted for the 0.04% of view content worldwide.", "tokens": [663, 43138, 337, 264, 1958, 13, 14565, 4, 295, 1910, 2701, 13485, 13], "temperature": 0.0, "avg_logprob": -0.17469058194003262, "compression_ratio": 1.4979591836734694, "no_speech_prob": 0.0020674094557762146}, {"id": 34, "seek": 19268, "start": 192.68, "end": 200.64000000000001, "text": " And in case you were asking, 97% of this content was proactively taken off, even before people", "tokens": [400, 294, 1389, 291, 645, 3365, 11, 23399, 4, 295, 341, 2701, 390, 447, 45679, 2726, 766, 11, 754, 949, 561], "temperature": 0.0, "avg_logprob": -0.1403403131585372, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.003865474136546254}, {"id": 35, "seek": 19268, "start": 200.64000000000001, "end": 203.84, "text": " could even see it.", "tokens": [727, 754, 536, 309, 13], "temperature": 0.0, "avg_logprob": -0.1403403131585372, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.003865474136546254}, {"id": 36, "seek": 19268, "start": 203.84, "end": 209.32, "text": " The remaining 2.8% is user reports, like I found this.", "tokens": [440, 8877, 568, 13, 23, 4, 307, 4195, 7122, 11, 411, 286, 1352, 341, 13], "temperature": 0.0, "avg_logprob": -0.1403403131585372, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.003865474136546254}, {"id": 37, "seek": 19268, "start": 209.32, "end": 214.44, "text": " And we take that down also, and we also add to the data banks just to make sure that we", "tokens": [400, 321, 747, 300, 760, 611, 11, 293, 321, 611, 909, 281, 264, 1412, 10237, 445, 281, 652, 988, 300, 321], "temperature": 0.0, "avg_logprob": -0.1403403131585372, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.003865474136546254}, {"id": 38, "seek": 19268, "start": 214.44, "end": 216.84, "text": " are not forgetting about that.", "tokens": [366, 406, 25428, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.1403403131585372, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.003865474136546254}, {"id": 39, "seek": 19268, "start": 216.84, "end": 220.28, "text": " Sometimes there are false positives because it's just unavoidable.", "tokens": [4803, 456, 366, 7908, 35127, 570, 309, 311, 445, 36541, 17079, 712, 13], "temperature": 0.0, "avg_logprob": -0.1403403131585372, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.003865474136546254}, {"id": 40, "seek": 22028, "start": 220.28, "end": 224.0, "text": " And half million was restored upon user appeal.", "tokens": [400, 1922, 2459, 390, 23143, 3564, 4195, 13668, 13], "temperature": 0.0, "avg_logprob": -0.20669397554899516, "compression_ratio": 1.6057692307692308, "no_speech_prob": 0.0010215241927653551}, {"id": 41, "seek": 22028, "start": 224.0, "end": 231.08, "text": " And we restore accounts and mostly accounts and the pictures that we're banned for.", "tokens": [400, 321, 15227, 9402, 293, 5240, 9402, 293, 264, 5242, 300, 321, 434, 19564, 337, 13], "temperature": 0.0, "avg_logprob": -0.20669397554899516, "compression_ratio": 1.6057692307692308, "no_speech_prob": 0.0010215241927653551}, {"id": 42, "seek": 22028, "start": 231.08, "end": 238.0, "text": " It goes by itself to the sheer volume of content, the huge scale, the problem we are facing,", "tokens": [467, 1709, 538, 2564, 281, 264, 23061, 5523, 295, 2701, 11, 264, 2603, 4373, 11, 264, 1154, 321, 366, 7170, 11], "temperature": 0.0, "avg_logprob": -0.20669397554899516, "compression_ratio": 1.6057692307692308, "no_speech_prob": 0.0010215241927653551}, {"id": 43, "seek": 22028, "start": 238.0, "end": 245.04, "text": " requires both automation and also human review to ensure either accuracy, both accuracy and", "tokens": [7029, 1293, 17769, 293, 611, 1952, 3131, 281, 5586, 2139, 14170, 11, 1293, 14170, 293], "temperature": 0.0, "avg_logprob": -0.20669397554899516, "compression_ratio": 1.6057692307692308, "no_speech_prob": 0.0010215241927653551}, {"id": 44, "seek": 22028, "start": 245.04, "end": 246.54, "text": " also consistency.", "tokens": [611, 14416, 13], "temperature": 0.0, "avg_logprob": -0.20669397554899516, "compression_ratio": 1.6057692307692308, "no_speech_prob": 0.0010215241927653551}, {"id": 45, "seek": 24654, "start": 246.54, "end": 251.51999999999998, "text": " So there will be a problem if we had the 1 million people clicking and making decisions", "tokens": [407, 456, 486, 312, 257, 1154, 498, 321, 632, 264, 502, 2459, 561, 9697, 293, 1455, 5327], "temperature": 0.0, "avg_logprob": -0.24775736382667055, "compression_ratio": 1.7041666666666666, "no_speech_prob": 0.002409970387816429}, {"id": 46, "seek": 24654, "start": 251.51999999999998, "end": 256.44, "text": " and what is violating for one is not for the other and vice versa.", "tokens": [293, 437, 307, 42201, 337, 472, 307, 406, 337, 264, 661, 293, 11964, 25650, 13], "temperature": 0.0, "avg_logprob": -0.24775736382667055, "compression_ratio": 1.7041666666666666, "no_speech_prob": 0.002409970387816429}, {"id": 47, "seek": 24654, "start": 256.44, "end": 261.48, "text": " And so, and we cannot just also just employ automation, because otherwise we will have", "tokens": [400, 370, 11, 293, 321, 2644, 445, 611, 445, 3188, 17769, 11, 570, 5911, 321, 486, 362], "temperature": 0.0, "avg_logprob": -0.24775736382667055, "compression_ratio": 1.7041666666666666, "no_speech_prob": 0.002409970387816429}, {"id": 48, "seek": 24654, "start": 261.48, "end": 267.84, "text": " this very powerful site, decapitating everybody, also innocent users.", "tokens": [341, 588, 4005, 3621, 11, 368, 9485, 16350, 2201, 11, 611, 13171, 5022, 13], "temperature": 0.0, "avg_logprob": -0.24775736382667055, "compression_ratio": 1.7041666666666666, "no_speech_prob": 0.002409970387816429}, {"id": 49, "seek": 24654, "start": 267.84, "end": 274.6, "text": " So the role of automation and similarity detection, the thing is that a lot of things that happen", "tokens": [407, 264, 3090, 295, 17769, 293, 32194, 17784, 11, 264, 551, 307, 300, 257, 688, 295, 721, 300, 1051], "temperature": 0.0, "avg_logprob": -0.24775736382667055, "compression_ratio": 1.7041666666666666, "no_speech_prob": 0.002409970387816429}, {"id": 50, "seek": 27460, "start": 274.6, "end": 278.36, "text": " online are things that are being repeated.", "tokens": [2950, 366, 721, 300, 366, 885, 10477, 13], "temperature": 0.0, "avg_logprob": -0.18038083148258988, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0023084557615220547}, {"id": 51, "seek": 27460, "start": 278.36, "end": 280.56, "text": " So are things that are already occurred in the past.", "tokens": [407, 366, 721, 300, 366, 1217, 11068, 294, 264, 1791, 13], "temperature": 0.0, "avg_logprob": -0.18038083148258988, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0023084557615220547}, {"id": 52, "seek": 27460, "start": 280.56, "end": 287.56, "text": " Like people posting a picture of some shooting, some mass shooting, for example, like the", "tokens": [1743, 561, 15978, 257, 3036, 295, 512, 5942, 11, 512, 2758, 5942, 11, 337, 1365, 11, 411, 264], "temperature": 0.0, "avg_logprob": -0.18038083148258988, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0023084557615220547}, {"id": 53, "seek": 27460, "start": 287.56, "end": 293.8, "text": " buffalo or the Christ church, gets taken down and the 10 more accounts spawn and post the", "tokens": [39681, 420, 264, 2040, 4128, 11, 2170, 2726, 760, 293, 264, 1266, 544, 9402, 17088, 293, 2183, 264], "temperature": 0.0, "avg_logprob": -0.18038083148258988, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0023084557615220547}, {"id": 54, "seek": 27460, "start": 293.8, "end": 294.8, "text": " same things.", "tokens": [912, 721, 13], "temperature": 0.0, "avg_logprob": -0.18038083148258988, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0023084557615220547}, {"id": 55, "seek": 27460, "start": 294.8, "end": 303.76000000000005, "text": " So it's much, it's very efficient to reason in terms of let's just redo the things that", "tokens": [407, 309, 311, 709, 11, 309, 311, 588, 7148, 281, 1778, 294, 2115, 295, 718, 311, 445, 29956, 264, 721, 300], "temperature": 0.0, "avg_logprob": -0.18038083148258988, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0023084557615220547}, {"id": 56, "seek": 30376, "start": 303.76, "end": 306.59999999999997, "text": " we already found out that worked.", "tokens": [321, 1217, 1352, 484, 300, 2732, 13], "temperature": 0.0, "avg_logprob": -0.1330594666507266, "compression_ratio": 1.8049792531120332, "no_speech_prob": 0.0009469392825849354}, {"id": 57, "seek": 30376, "start": 306.59999999999997, "end": 311.68, "text": " We employ automation to scale, of course, handle the scale of the problem and to consistently", "tokens": [492, 3188, 17769, 281, 4373, 11, 295, 1164, 11, 4813, 264, 4373, 295, 264, 1154, 293, 281, 14961], "temperature": 0.0, "avg_logprob": -0.1330594666507266, "compression_ratio": 1.8049792531120332, "no_speech_prob": 0.0009469392825849354}, {"id": 58, "seek": 30376, "start": 311.68, "end": 317.28, "text": " repeat a decision that a human reviewer has already vetted in the past.", "tokens": [7149, 257, 3537, 300, 257, 1952, 3131, 260, 575, 1217, 371, 46508, 294, 264, 1791, 13], "temperature": 0.0, "avg_logprob": -0.1330594666507266, "compression_ratio": 1.8049792531120332, "no_speech_prob": 0.0009469392825849354}, {"id": 59, "seek": 30376, "start": 317.28, "end": 324.08, "text": " So we tie a content to a decision, a violating content to a decision, let's act upon this.", "tokens": [407, 321, 7582, 257, 2701, 281, 257, 3537, 11, 257, 42201, 2701, 281, 257, 3537, 11, 718, 311, 605, 3564, 341, 13], "temperature": 0.0, "avg_logprob": -0.1330594666507266, "compression_ratio": 1.8049792531120332, "no_speech_prob": 0.0009469392825849354}, {"id": 60, "seek": 30376, "start": 324.08, "end": 327.84, "text": " And we take, we act, we tie the decision to the actions.", "tokens": [400, 321, 747, 11, 321, 605, 11, 321, 7582, 264, 3537, 281, 264, 5909, 13], "temperature": 0.0, "avg_logprob": -0.1330594666507266, "compression_ratio": 1.8049792531120332, "no_speech_prob": 0.0009469392825849354}, {"id": 61, "seek": 30376, "start": 327.84, "end": 333.15999999999997, "text": " Let's just repeat this action every time we meet a piece of content that triggered this", "tokens": [961, 311, 445, 7149, 341, 3069, 633, 565, 321, 1677, 257, 2522, 295, 2701, 300, 21710, 341], "temperature": 0.0, "avg_logprob": -0.1330594666507266, "compression_ratio": 1.8049792531120332, "no_speech_prob": 0.0009469392825849354}, {"id": 62, "seek": 33316, "start": 333.16, "end": 334.64000000000004, "text": " same decision.", "tokens": [912, 3537, 13], "temperature": 0.0, "avg_logprob": -0.1303574612266139, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0007457113242708147}, {"id": 63, "seek": 33316, "start": 334.64000000000004, "end": 338.68, "text": " We do that for videos, for pictures, and also for text.", "tokens": [492, 360, 300, 337, 2145, 11, 337, 5242, 11, 293, 611, 337, 2487, 13], "temperature": 0.0, "avg_logprob": -0.1303574612266139, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0007457113242708147}, {"id": 64, "seek": 33316, "start": 338.68, "end": 344.36, "text": " Today we'll be mostly talking about images because the techniques for video and pictures", "tokens": [2692, 321, 603, 312, 5240, 1417, 466, 5267, 570, 264, 7512, 337, 960, 293, 5242], "temperature": 0.0, "avg_logprob": -0.1303574612266139, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0007457113242708147}, {"id": 65, "seek": 33316, "start": 344.36, "end": 350.20000000000005, "text": " are somewhat very similar, text has a completely different array of techniques that we'll not", "tokens": [366, 8344, 588, 2531, 11, 2487, 575, 257, 2584, 819, 10225, 295, 7512, 300, 321, 603, 406], "temperature": 0.0, "avg_logprob": -0.1303574612266139, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0007457113242708147}, {"id": 66, "seek": 33316, "start": 350.20000000000005, "end": 353.28000000000003, "text": " be presenting today.", "tokens": [312, 15578, 965, 13], "temperature": 0.0, "avg_logprob": -0.1303574612266139, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0007457113242708147}, {"id": 67, "seek": 33316, "start": 353.28000000000003, "end": 359.44000000000005, "text": " So a way to, if you want to achieve similarity detection, you have to come up with a way", "tokens": [407, 257, 636, 281, 11, 498, 291, 528, 281, 4584, 32194, 17784, 11, 291, 362, 281, 808, 493, 365, 257, 636], "temperature": 0.0, "avg_logprob": -0.1303574612266139, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0007457113242708147}, {"id": 68, "seek": 33316, "start": 359.44000000000005, "end": 362.04, "text": " to achieve similarity first.", "tokens": [281, 4584, 32194, 700, 13], "temperature": 0.0, "avg_logprob": -0.1303574612266139, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0007457113242708147}, {"id": 69, "seek": 36204, "start": 362.04, "end": 365.24, "text": " So how do we compare to pictures?", "tokens": [407, 577, 360, 321, 6794, 281, 5242, 30], "temperature": 0.0, "avg_logprob": -0.19083252303097226, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0013629357563331723}, {"id": 70, "seek": 36204, "start": 365.24, "end": 369.40000000000003, "text": " Of course, we are not, we are not be doing pixel by pixel comparison.", "tokens": [2720, 1164, 11, 321, 366, 406, 11, 321, 366, 406, 312, 884, 19261, 538, 19261, 9660, 13], "temperature": 0.0, "avg_logprob": -0.19083252303097226, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0013629357563331723}, {"id": 71, "seek": 36204, "start": 369.40000000000003, "end": 371.24, "text": " We want to be much faster.", "tokens": [492, 528, 281, 312, 709, 4663, 13], "temperature": 0.0, "avg_logprob": -0.19083252303097226, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0013629357563331723}, {"id": 72, "seek": 36204, "start": 371.24, "end": 376.96000000000004, "text": " Our way to do that is just, okay, let's just MD5 hash all the pictures or SHA1 all the", "tokens": [2621, 636, 281, 360, 300, 307, 445, 11, 1392, 11, 718, 311, 445, 22521, 20, 22019, 439, 264, 5242, 420, 38820, 16, 439, 264], "temperature": 0.0, "avg_logprob": -0.19083252303097226, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0013629357563331723}, {"id": 73, "seek": 36204, "start": 376.96000000000004, "end": 382.44, "text": " pictures and then we store them somewhere in an indexing system.", "tokens": [5242, 293, 550, 321, 3531, 552, 4079, 294, 364, 8186, 278, 1185, 13], "temperature": 0.0, "avg_logprob": -0.19083252303097226, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0013629357563331723}, {"id": 74, "seek": 36204, "start": 382.44, "end": 389.56, "text": " And whenever a new picture comes in, we just recreate the hash and if it matches, we just", "tokens": [400, 5699, 257, 777, 3036, 1487, 294, 11, 321, 445, 25833, 264, 22019, 293, 498, 309, 10676, 11, 321, 445], "temperature": 0.0, "avg_logprob": -0.19083252303097226, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0013629357563331723}, {"id": 75, "seek": 36204, "start": 389.56, "end": 391.08000000000004, "text": " ban, right?", "tokens": [5643, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19083252303097226, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0013629357563331723}, {"id": 76, "seek": 39108, "start": 391.08, "end": 396.35999999999996, "text": " Well, that doesn't work very well because the cryptographic hashes are not resistant", "tokens": [1042, 11, 300, 1177, 380, 589, 588, 731, 570, 264, 9844, 12295, 575, 8076, 366, 406, 20383], "temperature": 0.0, "avg_logprob": -0.17146617716008966, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.000666641746647656}, {"id": 77, "seek": 39108, "start": 396.35999999999996, "end": 403.71999999999997, "text": " to resizing, rotation, one pixel alteration, all the hash changes all together.", "tokens": [281, 725, 3319, 11, 12447, 11, 472, 19261, 11337, 399, 11, 439, 264, 22019, 2962, 439, 1214, 13], "temperature": 0.0, "avg_logprob": -0.17146617716008966, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.000666641746647656}, {"id": 78, "seek": 39108, "start": 403.71999999999997, "end": 411.68, "text": " Instead, we can really benefit from local hashing because it allows for similarity measurement.", "tokens": [7156, 11, 321, 393, 534, 5121, 490, 2654, 575, 571, 570, 309, 4045, 337, 32194, 13160, 13], "temperature": 0.0, "avg_logprob": -0.17146617716008966, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.000666641746647656}, {"id": 79, "seek": 39108, "start": 411.68, "end": 418.96, "text": " Like you change slightly one piece, one portion of the image, and the hash changes a little,", "tokens": [1743, 291, 1319, 4748, 472, 2522, 11, 472, 8044, 295, 264, 3256, 11, 293, 264, 22019, 2962, 257, 707, 11], "temperature": 0.0, "avg_logprob": -0.17146617716008966, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.000666641746647656}, {"id": 80, "seek": 39108, "start": 418.96, "end": 419.96, "text": " but not completely.", "tokens": [457, 406, 2584, 13], "temperature": 0.0, "avg_logprob": -0.17146617716008966, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.000666641746647656}, {"id": 81, "seek": 41996, "start": 419.96, "end": 426.2, "text": " Then you can reason in terms of distance between two hashes.", "tokens": [1396, 291, 393, 1778, 294, 2115, 295, 4560, 1296, 732, 575, 8076, 13], "temperature": 0.0, "avg_logprob": -0.1605783568488227, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0008777934708632529}, {"id": 82, "seek": 41996, "start": 426.2, "end": 430.35999999999996, "text": " So you have to turn, you have to find a way to turn an image into a vector and then you", "tokens": [407, 291, 362, 281, 1261, 11, 291, 362, 281, 915, 257, 636, 281, 1261, 364, 3256, 666, 257, 8062, 293, 550, 291], "temperature": 0.0, "avg_logprob": -0.1605783568488227, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0008777934708632529}, {"id": 83, "seek": 41996, "start": 430.35999999999996, "end": 432.03999999999996, "text": " perform a vector search.", "tokens": [2042, 257, 8062, 3164, 13], "temperature": 0.0, "avg_logprob": -0.1605783568488227, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0008777934708632529}, {"id": 84, "seek": 41996, "start": 432.03999999999996, "end": 438.35999999999996, "text": " Whenever two vectors are very, very close beyond a certain threshold, then it's probably", "tokens": [14159, 732, 18875, 366, 588, 11, 588, 1998, 4399, 257, 1629, 14678, 11, 550, 309, 311, 1391], "temperature": 0.0, "avg_logprob": -0.1605783568488227, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0008777934708632529}, {"id": 85, "seek": 41996, "start": 438.35999999999996, "end": 439.71999999999997, "text": " a match.", "tokens": [257, 2995, 13], "temperature": 0.0, "avg_logprob": -0.1605783568488227, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0008777934708632529}, {"id": 86, "seek": 41996, "start": 439.71999999999997, "end": 444.0, "text": " And just in case if you're asking, these are based as the architecture.", "tokens": [400, 445, 294, 1389, 498, 291, 434, 3365, 11, 613, 366, 2361, 382, 264, 9482, 13], "temperature": 0.0, "avg_logprob": -0.1605783568488227, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0008777934708632529}, {"id": 87, "seek": 44400, "start": 444.0, "end": 450.24, "text": " You have more or less all the architectures share these four stages, observation, an image", "tokens": [509, 362, 544, 420, 1570, 439, 264, 6331, 1303, 2073, 613, 1451, 10232, 11, 14816, 11, 364, 3256], "temperature": 0.0, "avg_logprob": -0.23917391393091772, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.0004819012829102576}, {"id": 88, "seek": 44400, "start": 450.24, "end": 455.44, "text": " has been generated, usually push event like user uploaded something.", "tokens": [575, 668, 10833, 11, 2673, 2944, 2280, 411, 4195, 17135, 746, 13], "temperature": 0.0, "avg_logprob": -0.23917391393091772, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.0004819012829102576}, {"id": 89, "seek": 44400, "start": 455.44, "end": 462.36, "text": " Then you have the representation phase in which you hash the image to a compact representation.", "tokens": [1396, 291, 362, 264, 10290, 5574, 294, 597, 291, 22019, 264, 3256, 281, 257, 14679, 10290, 13], "temperature": 0.0, "avg_logprob": -0.23917391393091772, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.0004819012829102576}, {"id": 90, "seek": 44400, "start": 462.36, "end": 468.0, "text": " If you're indexing, you store that into your index and instead if you are at inference time", "tokens": [759, 291, 434, 8186, 278, 11, 291, 3531, 300, 666, 428, 8186, 293, 2602, 498, 291, 366, 412, 38253, 565], "temperature": 0.0, "avg_logprob": -0.23917391393091772, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.0004819012829102576}, {"id": 91, "seek": 46800, "start": 468.0, "end": 475.2, "text": " like an event someone uploaded something, you search the index they have built with representation.", "tokens": [411, 364, 2280, 1580, 17135, 746, 11, 291, 3164, 264, 8186, 436, 362, 3094, 365, 10290, 13], "temperature": 0.0, "avg_logprob": -0.22291627797213467, "compression_ratio": 1.6651162790697673, "no_speech_prob": 0.0005828706780448556}, {"id": 92, "seek": 46800, "start": 475.2, "end": 483.16, "text": " In case you have a match, you action upon what you decide what to do with the match you got.", "tokens": [682, 1389, 291, 362, 257, 2995, 11, 291, 3069, 3564, 437, 291, 4536, 437, 281, 360, 365, 264, 2995, 291, 658, 13], "temperature": 0.0, "avg_logprob": -0.22291627797213467, "compression_ratio": 1.6651162790697673, "no_speech_prob": 0.0005828706780448556}, {"id": 93, "seek": 46800, "start": 483.16, "end": 487.12, "text": " Usually the idea is that this is very close to an image that I already see in the past", "tokens": [11419, 264, 1558, 307, 300, 341, 307, 588, 1998, 281, 364, 3256, 300, 286, 1217, 536, 294, 264, 1791], "temperature": 0.0, "avg_logprob": -0.22291627797213467, "compression_ratio": 1.6651162790697673, "no_speech_prob": 0.0005828706780448556}, {"id": 94, "seek": 46800, "start": 487.12, "end": 490.2, "text": " that was banned and also the account was taken down.", "tokens": [300, 390, 19564, 293, 611, 264, 2696, 390, 2726, 760, 13], "temperature": 0.0, "avg_logprob": -0.22291627797213467, "compression_ratio": 1.6651162790697673, "no_speech_prob": 0.0005828706780448556}, {"id": 95, "seek": 46800, "start": 490.2, "end": 494.48, "text": " Do the same to this user.", "tokens": [1144, 264, 912, 281, 341, 4195, 13], "temperature": 0.0, "avg_logprob": -0.22291627797213467, "compression_ratio": 1.6651162790697673, "no_speech_prob": 0.0005828706780448556}, {"id": 96, "seek": 49448, "start": 494.48, "end": 504.48, "text": " So first three pieces of content, Facebook has released a library which is FICE, the", "tokens": [407, 700, 1045, 3755, 295, 2701, 11, 4384, 575, 4736, 257, 6405, 597, 307, 479, 13663, 11, 264], "temperature": 0.0, "avg_logprob": -0.26117668151855467, "compression_ratio": 1.5829145728643217, "no_speech_prob": 0.0004638126993086189}, {"id": 97, "seek": 49448, "start": 504.48, "end": 512.32, "text": " Facebook similarity search library is a library to do similarity search over a vector of dense", "tokens": [4384, 32194, 3164, 6405, 307, 257, 6405, 281, 360, 32194, 3164, 670, 257, 8062, 295, 18011], "temperature": 0.0, "avg_logprob": -0.26117668151855467, "compression_ratio": 1.5829145728643217, "no_speech_prob": 0.0004638126993086189}, {"id": 98, "seek": 49448, "start": 512.32, "end": 516.4, "text": " vectors or vector floats or integers, for example.", "tokens": [18875, 420, 8062, 37878, 420, 41674, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.26117668151855467, "compression_ratio": 1.5829145728643217, "no_speech_prob": 0.0004638126993086189}, {"id": 99, "seek": 49448, "start": 516.4, "end": 522.6, "text": " You can think about it like a C++ version of Lucene so you index stuff, puts that in", "tokens": [509, 393, 519, 466, 309, 411, 257, 383, 25472, 3037, 295, 9593, 1450, 370, 291, 8186, 1507, 11, 8137, 300, 294], "temperature": 0.0, "avg_logprob": -0.26117668151855467, "compression_ratio": 1.5829145728643217, "no_speech_prob": 0.0004638126993086189}, {"id": 100, "seek": 52260, "start": 522.6, "end": 526.4, "text": " a very big space and you can search in this space very fast.", "tokens": [257, 588, 955, 1901, 293, 291, 393, 3164, 294, 341, 1901, 588, 2370, 13], "temperature": 0.0, "avg_logprob": -0.24901446589717158, "compression_ratio": 1.5392156862745099, "no_speech_prob": 0.0014724885113537312}, {"id": 101, "seek": 52260, "start": 526.4, "end": 531.72, "text": " It supports CUDA so you can use your GPUs to search.", "tokens": [467, 9346, 29777, 7509, 370, 291, 393, 764, 428, 18407, 82, 281, 3164, 13], "temperature": 0.0, "avg_logprob": -0.24901446589717158, "compression_ratio": 1.5392156862745099, "no_speech_prob": 0.0014724885113537312}, {"id": 102, "seek": 52260, "start": 531.72, "end": 538.0, "text": " It's basically index on steroids and it's C++ but it has Python bindings available and", "tokens": [467, 311, 1936, 8186, 322, 45717, 293, 309, 311, 383, 25472, 457, 309, 575, 15329, 14786, 1109, 2435, 293], "temperature": 0.0, "avg_logprob": -0.24901446589717158, "compression_ratio": 1.5392156862745099, "no_speech_prob": 0.0014724885113537312}, {"id": 103, "seek": 52260, "start": 538.0, "end": 540.12, "text": " it scales almost nearly.", "tokens": [309, 17408, 1920, 6217, 13], "temperature": 0.0, "avg_logprob": -0.24901446589717158, "compression_ratio": 1.5392156862745099, "no_speech_prob": 0.0014724885113537312}, {"id": 104, "seek": 52260, "start": 540.12, "end": 547.4, "text": " You can really index 100 millions of pieces on a single machine and it just handles them", "tokens": [509, 393, 534, 8186, 2319, 6803, 295, 3755, 322, 257, 2167, 3479, 293, 309, 445, 18722, 552], "temperature": 0.0, "avg_logprob": -0.24901446589717158, "compression_ratio": 1.5392156862745099, "no_speech_prob": 0.0014724885113537312}, {"id": 105, "seek": 54740, "start": 547.4, "end": 554.56, "text": " really, doesn't need to saturate all the memory so it has a very good optimization properties", "tokens": [534, 11, 1177, 380, 643, 281, 21160, 473, 439, 264, 4675, 370, 309, 575, 257, 588, 665, 19618, 7221], "temperature": 0.0, "avg_logprob": -0.22176847353086368, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0004168747691437602}, {"id": 106, "seek": 54740, "start": 554.56, "end": 561.48, "text": " that makes it a very good tool and you can go and download that on GitHub.", "tokens": [300, 1669, 309, 257, 588, 665, 2290, 293, 291, 393, 352, 293, 5484, 300, 322, 23331, 13], "temperature": 0.0, "avg_logprob": -0.22176847353086368, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0004168747691437602}, {"id": 107, "seek": 54740, "start": 561.48, "end": 567.92, "text": " Today we are also mostly referring to with the perceptual ashing.", "tokens": [2692, 321, 366, 611, 5240, 13761, 281, 365, 264, 43276, 901, 382, 571, 13], "temperature": 0.0, "avg_logprob": -0.22176847353086368, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0004168747691437602}, {"id": 108, "seek": 54740, "start": 567.92, "end": 573.24, "text": " This means that we are reasoning in terms of colors, colors and images, shapes.", "tokens": [639, 1355, 300, 321, 366, 21577, 294, 2115, 295, 4577, 11, 4577, 293, 5267, 11, 10854, 13], "temperature": 0.0, "avg_logprob": -0.22176847353086368, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0004168747691437602}, {"id": 109, "seek": 54740, "start": 573.24, "end": 576.68, "text": " We are not reasoning about what's happening inside the image.", "tokens": [492, 366, 406, 21577, 466, 437, 311, 2737, 1854, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.22176847353086368, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0004168747691437602}, {"id": 110, "seek": 57668, "start": 576.68, "end": 583.1999999999999, "text": " That's the semantic ashing which we are not going to talk about this today.", "tokens": [663, 311, 264, 47982, 382, 571, 597, 321, 366, 406, 516, 281, 751, 466, 341, 965, 13], "temperature": 0.0, "avg_logprob": -0.19646905717395602, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.00043282032129354775}, {"id": 111, "seek": 57668, "start": 583.1999999999999, "end": 589.0, "text": " Perceptual ashing just captures visual similarities and it's very nice for use case because it", "tokens": [3026, 1336, 901, 382, 571, 445, 27986, 5056, 24197, 293, 309, 311, 588, 1481, 337, 764, 1389, 570, 309], "temperature": 0.0, "avg_logprob": -0.19646905717395602, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.00043282032129354775}, {"id": 112, "seek": 57668, "start": 589.0, "end": 592.12, "text": " exactly does its job.", "tokens": [2293, 775, 1080, 1691, 13], "temperature": 0.0, "avg_logprob": -0.19646905717395602, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.00043282032129354775}, {"id": 113, "seek": 57668, "start": 592.12, "end": 598.9599999999999, "text": " So you might think that we are all talking about machine learning systems that come up", "tokens": [407, 291, 1062, 519, 300, 321, 366, 439, 1417, 466, 3479, 2539, 3652, 300, 808, 493], "temperature": 0.0, "avg_logprob": -0.19646905717395602, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.00043282032129354775}, {"id": 114, "seek": 57668, "start": 598.9599999999999, "end": 604.88, "text": " with very clever representations about our pictures and I'm asking do we really need", "tokens": [365, 588, 13494, 33358, 466, 527, 5242, 293, 286, 478, 3365, 360, 321, 534, 643], "temperature": 0.0, "avg_logprob": -0.19646905717395602, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.00043282032129354775}, {"id": 115, "seek": 60488, "start": 604.88, "end": 606.8, "text": " a convnet for that?", "tokens": [257, 3754, 7129, 337, 300, 30], "temperature": 0.0, "avg_logprob": -0.2579258138483221, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0009021874284371734}, {"id": 116, "seek": 60488, "start": 606.8, "end": 609.48, "text": " Do we really need to employ GPUs?", "tokens": [1144, 321, 534, 643, 281, 3188, 18407, 82, 30], "temperature": 0.0, "avg_logprob": -0.2579258138483221, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0009021874284371734}, {"id": 117, "seek": 60488, "start": 609.48, "end": 615.12, "text": " You already said that it's on CUDA so perhaps that's a nice hint but absolutely not.", "tokens": [509, 1217, 848, 300, 309, 311, 322, 29777, 7509, 370, 4317, 300, 311, 257, 1481, 12075, 457, 3122, 406, 13], "temperature": 0.0, "avg_logprob": -0.2579258138483221, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0009021874284371734}, {"id": 118, "seek": 60488, "start": 615.12, "end": 621.24, "text": " Most of this technology is like a ashing technology so they just computer represent a mathematical", "tokens": [4534, 295, 341, 2899, 307, 411, 257, 382, 571, 2899, 370, 436, 445, 3820, 2906, 257, 18894], "temperature": 0.0, "avg_logprob": -0.2579258138483221, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0009021874284371734}, {"id": 119, "seek": 60488, "start": 621.24, "end": 626.76, "text": " transformation over the image and it's really fast and it's really cheap and it can be executed", "tokens": [9887, 670, 264, 3256, 293, 309, 311, 534, 2370, 293, 309, 311, 534, 7084, 293, 309, 393, 312, 17577], "temperature": 0.0, "avg_logprob": -0.2579258138483221, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0009021874284371734}, {"id": 120, "seek": 60488, "start": 626.76, "end": 629.08, "text": " almost everywhere.", "tokens": [1920, 5315, 13], "temperature": 0.0, "avg_logprob": -0.2579258138483221, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.0009021874284371734}, {"id": 121, "seek": 62908, "start": 629.08, "end": 637.5200000000001, "text": " So a little bit of history, the first very notable example, it comes from a source that", "tokens": [407, 257, 707, 857, 295, 2503, 11, 264, 700, 588, 22556, 1365, 11, 309, 1487, 490, 257, 4009, 300], "temperature": 0.0, "avg_logprob": -0.2391376495361328, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.0002674286370165646}, {"id": 122, "seek": 62908, "start": 637.5200000000001, "end": 642.4000000000001, "text": " nobody would have thought about, it's Microsoft in 2009.", "tokens": [5079, 576, 362, 1194, 466, 11, 309, 311, 8116, 294, 11453, 13], "temperature": 0.0, "avg_logprob": -0.2391376495361328, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.0002674286370165646}, {"id": 123, "seek": 62908, "start": 642.4000000000001, "end": 644.4000000000001, "text": " Microsoft invents photo DNA.", "tokens": [8116, 1048, 791, 5052, 8272, 13], "temperature": 0.0, "avg_logprob": -0.2391376495361328, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.0002674286370165646}, {"id": 124, "seek": 62908, "start": 644.4000000000001, "end": 650.64, "text": " Photo DNA is the first algorithm employed in fight against exploitive images of children.", "tokens": [39175, 8272, 307, 264, 700, 9284, 20115, 294, 2092, 1970, 12382, 2187, 5267, 295, 2227, 13], "temperature": 0.0, "avg_logprob": -0.2391376495361328, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.0002674286370165646}, {"id": 125, "seek": 65064, "start": 650.64, "end": 664.08, "text": " So it transforms a picture into an ash of 144 unsigned integers on 8-bit representation.", "tokens": [407, 309, 35592, 257, 3036, 666, 364, 12588, 295, 45218, 2693, 16690, 41674, 322, 1649, 12, 5260, 10290, 13], "temperature": 0.0, "avg_logprob": -0.22198814815945095, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0011730099795386195}, {"id": 126, "seek": 65064, "start": 664.08, "end": 665.72, "text": " It's proprietary.", "tokens": [467, 311, 38992, 13], "temperature": 0.0, "avg_logprob": -0.22198814815945095, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0011730099795386195}, {"id": 127, "seek": 65064, "start": 665.72, "end": 675.8, "text": " So Microsoft licenses this to any non-profit or any organization that wants to fight exploitive", "tokens": [407, 8116, 32821, 341, 281, 604, 2107, 12, 14583, 420, 604, 4475, 300, 2738, 281, 2092, 12382, 2187], "temperature": 0.0, "avg_logprob": -0.22198814815945095, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0011730099795386195}, {"id": 128, "seek": 65064, "start": 675.8, "end": 676.8, "text": " images of children.", "tokens": [5267, 295, 2227, 13], "temperature": 0.0, "avg_logprob": -0.22198814815945095, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0011730099795386195}, {"id": 129, "seek": 65064, "start": 676.8, "end": 679.56, "text": " It gives you a license, you can use for that and nothing else.", "tokens": [467, 2709, 291, 257, 10476, 11, 291, 393, 764, 337, 300, 293, 1825, 1646, 13], "temperature": 0.0, "avg_logprob": -0.22198814815945095, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0011730099795386195}, {"id": 130, "seek": 67956, "start": 679.56, "end": 683.0799999999999, "text": " But I cannot disclose the details of how that works.", "tokens": [583, 286, 2644, 36146, 264, 4365, 295, 577, 300, 1985, 13], "temperature": 0.0, "avg_logprob": -0.18730803741805854, "compression_ratio": 1.5527426160337552, "no_speech_prob": 0.0016130332369357347}, {"id": 131, "seek": 67956, "start": 683.0799999999999, "end": 689.04, "text": " It can be used only for that but Microsoft donated the photo DNA to the National Center", "tokens": [467, 393, 312, 1143, 787, 337, 300, 457, 8116, 23723, 264, 5052, 8272, 281, 264, 4862, 5169], "temperature": 0.0, "avg_logprob": -0.18730803741805854, "compression_ratio": 1.5527426160337552, "no_speech_prob": 0.0016130332369357347}, {"id": 132, "seek": 67956, "start": 689.04, "end": 692.0799999999999, "text": " for the Missing and Exploited Children, the NACMAC.", "tokens": [337, 264, 5275, 278, 293, 12514, 78, 1226, 13354, 11, 264, 426, 4378, 44, 4378, 13], "temperature": 0.0, "avg_logprob": -0.18730803741805854, "compression_ratio": 1.5527426160337552, "no_speech_prob": 0.0016130332369357347}, {"id": 133, "seek": 67956, "start": 692.0799999999999, "end": 699.7199999999999, "text": " It's this American non-profit that basically acts as a coordination center in global fight", "tokens": [467, 311, 341, 2665, 2107, 12, 14583, 300, 1936, 10672, 382, 257, 21252, 3056, 294, 4338, 2092], "temperature": 0.0, "avg_logprob": -0.18730803741805854, "compression_ratio": 1.5527426160337552, "no_speech_prob": 0.0016130332369357347}, {"id": 134, "seek": 67956, "start": 699.7199999999999, "end": 707.88, "text": " against this phenomenon and shares this library with anyone that wants to integrate.", "tokens": [1970, 341, 14029, 293, 12182, 341, 6405, 365, 2878, 300, 2738, 281, 13365, 13], "temperature": 0.0, "avg_logprob": -0.18730803741805854, "compression_ratio": 1.5527426160337552, "no_speech_prob": 0.0016130332369357347}, {"id": 135, "seek": 70788, "start": 707.88, "end": 713.56, "text": " This I cannot talk about how this works, this is the only moment in which I will say something", "tokens": [639, 286, 2644, 751, 466, 577, 341, 1985, 11, 341, 307, 264, 787, 1623, 294, 597, 286, 486, 584, 746], "temperature": 0.0, "avg_logprob": -0.2464756498149797, "compression_ratio": 1.5220883534136547, "no_speech_prob": 0.0018456886755302548}, {"id": 136, "seek": 70788, "start": 713.56, "end": 714.56, "text": " like that.", "tokens": [411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2464756498149797, "compression_ratio": 1.5220883534136547, "no_speech_prob": 0.0018456886755302548}, {"id": 137, "seek": 70788, "start": 714.56, "end": 720.36, "text": " But we can talk about an open source counterpart that almost 10 years later Facebook releases", "tokens": [583, 321, 393, 751, 466, 364, 1269, 4009, 22335, 300, 1920, 1266, 924, 1780, 4384, 16952], "temperature": 0.0, "avg_logprob": -0.2464756498149797, "compression_ratio": 1.5220883534136547, "no_speech_prob": 0.0018456886755302548}, {"id": 138, "seek": 70788, "start": 720.36, "end": 721.36, "text": " PDQ.", "tokens": [10464, 48, 13], "temperature": 0.0, "avg_logprob": -0.2464756498149797, "compression_ratio": 1.5220883534136547, "no_speech_prob": 0.0018456886755302548}, {"id": 139, "seek": 70788, "start": 721.36, "end": 728.2, "text": " PDQ stands for Perceptual Algorithm Using Discrete Cousin Transform and gives a quality", "tokens": [10464, 48, 7382, 337, 3026, 1336, 901, 35014, 6819, 76, 11142, 19839, 7600, 383, 563, 259, 27938, 293, 2709, 257, 3125], "temperature": 0.0, "avg_logprob": -0.2464756498149797, "compression_ratio": 1.5220883534136547, "no_speech_prob": 0.0018456886755302548}, {"id": 140, "seek": 70788, "start": 728.2, "end": 729.2, "text": " metric.", "tokens": [20678, 13], "temperature": 0.0, "avg_logprob": -0.2464756498149797, "compression_ratio": 1.5220883534136547, "no_speech_prob": 0.0018456886755302548}, {"id": 141, "seek": 70788, "start": 729.2, "end": 733.56, "text": " It's a very, very bad acronym but we need a three-letter acronym so it's that.", "tokens": [467, 311, 257, 588, 11, 588, 1578, 39195, 457, 321, 643, 257, 1045, 12, 21248, 39195, 370, 309, 311, 300, 13], "temperature": 0.0, "avg_logprob": -0.2464756498149797, "compression_ratio": 1.5220883534136547, "no_speech_prob": 0.0018456886755302548}, {"id": 142, "seek": 73356, "start": 733.56, "end": 740.64, "text": " It creates a 256-bit hash, uses hamming distance to compute the distance.", "tokens": [467, 7829, 257, 38882, 12, 5260, 22019, 11, 4960, 36600, 278, 4560, 281, 14722, 264, 4560, 13], "temperature": 0.0, "avg_logprob": -0.18457310994466145, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0023355779703706503}, {"id": 143, "seek": 73356, "start": 740.64, "end": 741.9399999999999, "text": " It's really fast.", "tokens": [467, 311, 534, 2370, 13], "temperature": 0.0, "avg_logprob": -0.18457310994466145, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0023355779703706503}, {"id": 144, "seek": 73356, "start": 741.9399999999999, "end": 747.64, "text": " The compute overhead is negligible compared to discrete.", "tokens": [440, 14722, 19922, 307, 32570, 964, 5347, 281, 27706, 13], "temperature": 0.0, "avg_logprob": -0.18457310994466145, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0023355779703706503}, {"id": 145, "seek": 73356, "start": 747.64, "end": 750.92, "text": " Can tolerate some level of adversality.", "tokens": [1664, 25773, 512, 1496, 295, 17641, 1860, 13], "temperature": 0.0, "avg_logprob": -0.18457310994466145, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0023355779703706503}, {"id": 146, "seek": 73356, "start": 750.92, "end": 755.8, "text": " This means that you change the image because you want to fool the systems in that this", "tokens": [639, 1355, 300, 291, 1319, 264, 3256, 570, 291, 528, 281, 7979, 264, 3652, 294, 300, 341], "temperature": 0.0, "avg_logprob": -0.18457310994466145, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0023355779703706503}, {"id": 147, "seek": 73356, "start": 755.8, "end": 761.8399999999999, "text": " image is not something which is well-known, PDQ can resist a little to this manipulation", "tokens": [3256, 307, 406, 746, 597, 307, 731, 12, 6861, 11, 10464, 48, 393, 4597, 257, 707, 281, 341, 26475], "temperature": 0.0, "avg_logprob": -0.18457310994466145, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0023355779703706503}, {"id": 148, "seek": 76184, "start": 761.84, "end": 763.88, "text": " but not all of them.", "tokens": [457, 406, 439, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.238839750704558, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.0036319498904049397}, {"id": 149, "seek": 76184, "start": 763.88, "end": 767.2, "text": " It's used in stopncii.org.", "tokens": [467, 311, 1143, 294, 1590, 77, 537, 72, 13, 4646, 13], "temperature": 0.0, "avg_logprob": -0.238839750704558, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.0036319498904049397}, {"id": 150, "seek": 76184, "start": 767.2, "end": 774.12, "text": " It's a website where people, in case you have a fight with your ex-fianc\u00e9 and he's threatening", "tokens": [467, 311, 257, 3144, 689, 561, 11, 294, 1389, 291, 362, 257, 2092, 365, 428, 454, 12, 69, 952, 13523, 293, 415, 311, 20768], "temperature": 0.0, "avg_logprob": -0.238839750704558, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.0036319498904049397}, {"id": 151, "seek": 76184, "start": 774.12, "end": 782.32, "text": " to publish your intimate imagery, you go to stopncii.org, you upload your intimate imageries,", "tokens": [281, 11374, 428, 20215, 24340, 11, 291, 352, 281, 1590, 77, 537, 72, 13, 4646, 11, 291, 6580, 428, 20215, 2576, 21659, 11], "temperature": 0.0, "avg_logprob": -0.238839750704558, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.0036319498904049397}, {"id": 152, "seek": 76184, "start": 782.32, "end": 790.0, "text": " fingerprints get taken, original images get deleted right away of course, and these fingerprints", "tokens": [42170, 483, 2726, 11, 3380, 5267, 483, 22981, 558, 1314, 295, 1164, 11, 293, 613, 42170], "temperature": 0.0, "avg_logprob": -0.238839750704558, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.0036319498904049397}, {"id": 153, "seek": 79000, "start": 790.0, "end": 797.36, "text": " are shared with partners that, okay, if I am going to see these fingerprints in my website,", "tokens": [366, 5507, 365, 4462, 300, 11, 1392, 11, 498, 286, 669, 516, 281, 536, 613, 42170, 294, 452, 3144, 11], "temperature": 0.0, "avg_logprob": -0.2409088049042091, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001524773659184575}, {"id": 154, "seek": 79000, "start": 797.36, "end": 799.6, "text": " my platform, I'm going to take them down.", "tokens": [452, 3663, 11, 286, 478, 516, 281, 747, 552, 760, 13], "temperature": 0.0, "avg_logprob": -0.2409088049042091, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001524773659184575}, {"id": 155, "seek": 79000, "start": 799.6, "end": 804.64, "text": " So it's a crowd source effort and uses PDQ for images.", "tokens": [407, 309, 311, 257, 6919, 4009, 4630, 293, 4960, 10464, 48, 337, 5267, 13], "temperature": 0.0, "avg_logprob": -0.2409088049042091, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001524773659184575}, {"id": 156, "seek": 79000, "start": 804.64, "end": 806.4, "text": " How does that work?", "tokens": [1012, 775, 300, 589, 30], "temperature": 0.0, "avg_logprob": -0.2409088049042091, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001524773659184575}, {"id": 157, "seek": 79000, "start": 806.4, "end": 813.76, "text": " So PDQ hashing is, optionally scale down to a square image, okay.", "tokens": [407, 10464, 48, 575, 571, 307, 11, 3614, 379, 4373, 760, 281, 257, 3732, 3256, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.2409088049042091, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001524773659184575}, {"id": 158, "seek": 79000, "start": 813.76, "end": 815.88, "text": " Then you compute the luminance.", "tokens": [1396, 291, 14722, 264, 32476, 719, 13], "temperature": 0.0, "avg_logprob": -0.2409088049042091, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001524773659184575}, {"id": 159, "seek": 81588, "start": 815.88, "end": 822.08, "text": " Luminance is the idea that you take the pixel that contributes most in the RGB channel.", "tokens": [441, 7112, 719, 307, 264, 1558, 300, 291, 747, 264, 19261, 300, 32035, 881, 294, 264, 31231, 2269, 13], "temperature": 0.0, "avg_logprob": -0.19783933639526366, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.0014298399910330772}, {"id": 160, "seek": 81588, "start": 822.08, "end": 825.08, "text": " Instead of putting black and white, you use the luminance.", "tokens": [7156, 295, 3372, 2211, 293, 2418, 11, 291, 764, 264, 32476, 719, 13], "temperature": 0.0, "avg_logprob": -0.19783933639526366, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.0014298399910330772}, {"id": 161, "seek": 81588, "start": 825.08, "end": 830.04, "text": " It's just another procedure and the idea is that the luminance gives you better information", "tokens": [467, 311, 445, 1071, 10747, 293, 264, 1558, 307, 300, 264, 32476, 719, 2709, 291, 1101, 1589], "temperature": 0.0, "avg_logprob": -0.19783933639526366, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.0014298399910330772}, {"id": 162, "seek": 81588, "start": 830.04, "end": 838.24, "text": " about what was the channel that was contributing most to the color, to the light in that place.", "tokens": [466, 437, 390, 264, 2269, 300, 390, 19270, 881, 281, 264, 2017, 11, 281, 264, 1442, 294, 300, 1081, 13], "temperature": 0.0, "avg_logprob": -0.19783933639526366, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.0014298399910330772}, {"id": 163, "seek": 81588, "start": 838.24, "end": 845.68, "text": " Then you down sample to 64 times 64 using a blur filter and the idea of the blur filter", "tokens": [1396, 291, 760, 6889, 281, 12145, 1413, 12145, 1228, 257, 14257, 6608, 293, 264, 1558, 295, 264, 14257, 6608], "temperature": 0.0, "avg_logprob": -0.19783933639526366, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.0014298399910330772}, {"id": 164, "seek": 84568, "start": 845.68, "end": 853.64, "text": " or tent filter is that it gets the most significant value in that region because if you keep convoluting", "tokens": [420, 7054, 6608, 307, 300, 309, 2170, 264, 881, 4776, 2158, 294, 300, 4458, 570, 498, 291, 1066, 3754, 2308, 278], "temperature": 0.0, "avg_logprob": -0.16490542888641357, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.0004234441730659455}, {"id": 165, "seek": 84568, "start": 853.64, "end": 859.9599999999999, "text": " a pixel with your neighborhood, what you will have in the end will be the highest value.", "tokens": [257, 19261, 365, 428, 7630, 11, 437, 291, 486, 362, 294, 264, 917, 486, 312, 264, 6343, 2158, 13], "temperature": 0.0, "avg_logprob": -0.16490542888641357, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.0004234441730659455}, {"id": 166, "seek": 84568, "start": 859.9599999999999, "end": 866.5999999999999, "text": " So you obtain a representation which is compact and retains the most significant information.", "tokens": [407, 291, 12701, 257, 10290, 597, 307, 14679, 293, 1533, 2315, 264, 881, 4776, 1589, 13], "temperature": 0.0, "avg_logprob": -0.16490542888641357, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.0004234441730659455}, {"id": 167, "seek": 84568, "start": 866.5999999999999, "end": 872.12, "text": " Then you divide the images in 16 times 16 boxes, each one by 4 pixels, and you calculate", "tokens": [1396, 291, 9845, 264, 5267, 294, 3165, 1413, 3165, 9002, 11, 1184, 472, 538, 1017, 18668, 11, 293, 291, 8873], "temperature": 0.0, "avg_logprob": -0.16490542888641357, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.0004234441730659455}, {"id": 168, "seek": 84568, "start": 872.12, "end": 875.1999999999999, "text": " a discrete cosine transform of each box.", "tokens": [257, 27706, 23565, 4088, 295, 1184, 2424, 13], "temperature": 0.0, "avg_logprob": -0.16490542888641357, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.0004234441730659455}, {"id": 169, "seek": 87520, "start": 875.2, "end": 880.76, "text": " The discrete cosine transform, so the box is at the 4 bar color there.", "tokens": [440, 27706, 23565, 4088, 11, 370, 264, 2424, 307, 412, 264, 1017, 2159, 2017, 456, 13], "temperature": 0.0, "avg_logprob": -0.12478532230152803, "compression_ratio": 1.75, "no_speech_prob": 0.0008026535506360233}, {"id": 170, "seek": 87520, "start": 880.76, "end": 887.1600000000001, "text": " You see that the grid with a lot of wobbly images, that is a discrete cosine transform.", "tokens": [509, 536, 300, 264, 10748, 365, 257, 688, 295, 33775, 25021, 5267, 11, 300, 307, 257, 27706, 23565, 4088, 13], "temperature": 0.0, "avg_logprob": -0.12478532230152803, "compression_ratio": 1.75, "no_speech_prob": 0.0008026535506360233}, {"id": 171, "seek": 87520, "start": 887.1600000000001, "end": 894.6800000000001, "text": " The idea is that any image, any signal can be represented as a sum of cosine signals.", "tokens": [440, 1558, 307, 300, 604, 3256, 11, 604, 6358, 393, 312, 10379, 382, 257, 2408, 295, 23565, 12354, 13], "temperature": 0.0, "avg_logprob": -0.12478532230152803, "compression_ratio": 1.75, "no_speech_prob": 0.0008026535506360233}, {"id": 172, "seek": 87520, "start": 894.6800000000001, "end": 899.96, "text": " You only take the signal, the most significant one, so it's a form of compression actually,", "tokens": [509, 787, 747, 264, 6358, 11, 264, 881, 4776, 472, 11, 370, 309, 311, 257, 1254, 295, 19355, 767, 11], "temperature": 0.0, "avg_logprob": -0.12478532230152803, "compression_ratio": 1.75, "no_speech_prob": 0.0008026535506360233}, {"id": 173, "seek": 89996, "start": 899.96, "end": 909.12, "text": " and you take the most significant coefficient for the biggest cosine you have.", "tokens": [293, 291, 747, 264, 881, 4776, 17619, 337, 264, 3880, 23565, 291, 362, 13], "temperature": 0.0, "avg_logprob": -0.1809124265398298, "compression_ratio": 1.5352697095435686, "no_speech_prob": 0.00035400688648223877}, {"id": 174, "seek": 89996, "start": 909.12, "end": 913.2800000000001, "text": " And then you calculate if the median is above a certain value, then it's one, otherwise", "tokens": [400, 550, 291, 8873, 498, 264, 26779, 307, 3673, 257, 1629, 2158, 11, 550, 309, 311, 472, 11, 5911], "temperature": 0.0, "avg_logprob": -0.1809124265398298, "compression_ratio": 1.5352697095435686, "no_speech_prob": 0.00035400688648223877}, {"id": 175, "seek": 89996, "start": 913.2800000000001, "end": 914.2800000000001, "text": " it's zero.", "tokens": [309, 311, 4018, 13], "temperature": 0.0, "avg_logprob": -0.1809124265398298, "compression_ratio": 1.5352697095435686, "no_speech_prob": 0.00035400688648223877}, {"id": 176, "seek": 89996, "start": 914.2800000000001, "end": 920.84, "text": " So you get this 256 in an array of 010101 in case this pixel were a high luminance or", "tokens": [407, 291, 483, 341, 38882, 294, 364, 10225, 295, 1958, 3279, 3279, 16, 294, 1389, 341, 19261, 645, 257, 1090, 32476, 719, 420], "temperature": 0.0, "avg_logprob": -0.1809124265398298, "compression_ratio": 1.5352697095435686, "no_speech_prob": 0.00035400688648223877}, {"id": 177, "seek": 89996, "start": 920.84, "end": 923.24, "text": " a low luminance.", "tokens": [257, 2295, 32476, 719, 13], "temperature": 0.0, "avg_logprob": -0.1809124265398298, "compression_ratio": 1.5352697095435686, "no_speech_prob": 0.00035400688648223877}, {"id": 178, "seek": 89996, "start": 923.24, "end": 929.48, "text": " The DCT provides a spectral hashing property, identifies what is the point in the images,", "tokens": [440, 9114, 51, 6417, 257, 42761, 575, 571, 4707, 11, 34597, 437, 307, 264, 935, 294, 264, 5267, 11], "temperature": 0.0, "avg_logprob": -0.1809124265398298, "compression_ratio": 1.5352697095435686, "no_speech_prob": 0.00035400688648223877}, {"id": 179, "seek": 92948, "start": 929.48, "end": 931.72, "text": " that contributes more or less.", "tokens": [300, 32035, 544, 420, 1570, 13], "temperature": 0.0, "avg_logprob": -0.20276768390948957, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001363118295557797}, {"id": 180, "seek": 92948, "start": 931.72, "end": 936.36, "text": " You have an hashing space, which is 2 to the power of 1 to 28, because it's half the", "tokens": [509, 362, 364, 575, 571, 1901, 11, 597, 307, 568, 281, 264, 1347, 295, 502, 281, 7562, 11, 570, 309, 311, 1922, 264], "temperature": 0.0, "avg_logprob": -0.20276768390948957, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001363118295557797}, {"id": 181, "seek": 92948, "start": 936.36, "end": 941.24, "text": " ashes, because half is always 0, half is always 1.", "tokens": [32942, 11, 570, 1922, 307, 1009, 1958, 11, 1922, 307, 1009, 502, 13], "temperature": 0.0, "avg_logprob": -0.20276768390948957, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001363118295557797}, {"id": 182, "seek": 92948, "start": 941.24, "end": 947.84, "text": " To search, you just do a vector search again, what you've just created.", "tokens": [1407, 3164, 11, 291, 445, 360, 257, 8062, 3164, 797, 11, 437, 291, 600, 445, 2942, 13], "temperature": 0.0, "avg_logprob": -0.20276768390948957, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001363118295557797}, {"id": 183, "seek": 92948, "start": 947.84, "end": 953.96, "text": " In case we want, we can use partially the same technology to do video hashing, and this", "tokens": [682, 1389, 321, 528, 11, 321, 393, 764, 18886, 264, 912, 2899, 281, 360, 960, 575, 571, 11, 293, 341], "temperature": 0.0, "avg_logprob": -0.20276768390948957, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001363118295557797}, {"id": 184, "seek": 92948, "start": 953.96, "end": 957.9200000000001, "text": " is another, it comes in almost the same paper.", "tokens": [307, 1071, 11, 309, 1487, 294, 1920, 264, 912, 3035, 13], "temperature": 0.0, "avg_logprob": -0.20276768390948957, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001363118295557797}, {"id": 185, "seek": 95792, "start": 957.92, "end": 967.8, "text": " The TMK is a temporary matching kernel, is a way to use the PDQ creation to do a video", "tokens": [440, 33550, 42, 307, 257, 13413, 14324, 28256, 11, 307, 257, 636, 281, 764, 264, 10464, 48, 8016, 281, 360, 257, 960], "temperature": 0.0, "avg_logprob": -0.18877443012438322, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.00046855895197950304}, {"id": 186, "seek": 95792, "start": 967.8, "end": 970.64, "text": " similarity detection algorithm.", "tokens": [32194, 17784, 9284, 13], "temperature": 0.0, "avg_logprob": -0.18877443012438322, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.00046855895197950304}, {"id": 187, "seek": 95792, "start": 970.64, "end": 976.56, "text": " It produces a fixed length video hashes, so your hash stays at the same length, which", "tokens": [467, 14725, 257, 6806, 4641, 960, 575, 8076, 11, 370, 428, 22019, 10834, 412, 264, 912, 4641, 11, 597], "temperature": 0.0, "avg_logprob": -0.18877443012438322, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.00046855895197950304}, {"id": 188, "seek": 95792, "start": 976.56, "end": 984.4399999999999, "text": " is like 256 kilobytes, if I'm not wrong, even if your video lasts for 3 hours or 30 seconds.", "tokens": [307, 411, 38882, 5128, 996, 43673, 11, 498, 286, 478, 406, 2085, 11, 754, 498, 428, 960, 20669, 337, 805, 2496, 420, 2217, 3949, 13], "temperature": 0.0, "avg_logprob": -0.18877443012438322, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.00046855895197950304}, {"id": 189, "seek": 95792, "start": 984.4399999999999, "end": 987.5999999999999, "text": " It just produces a fixed length, so it's really nice.", "tokens": [467, 445, 14725, 257, 6806, 4641, 11, 370, 309, 311, 534, 1481, 13], "temperature": 0.0, "avg_logprob": -0.18877443012438322, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.00046855895197950304}, {"id": 190, "seek": 98760, "start": 987.6, "end": 993.44, "text": " What you do is that you resample a video to 15 frames, then you compute the PDQ without", "tokens": [708, 291, 360, 307, 300, 291, 725, 335, 781, 257, 960, 281, 2119, 12083, 11, 550, 291, 14722, 264, 10464, 48, 1553], "temperature": 0.0, "avg_logprob": -0.1881246778700087, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.0020110795740038157}, {"id": 191, "seek": 98760, "start": 993.44, "end": 996.88, "text": " the 01 quantization, so you keep the float numbers.", "tokens": [264, 23185, 4426, 2144, 11, 370, 291, 1066, 264, 15706, 3547, 13], "temperature": 0.0, "avg_logprob": -0.1881246778700087, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.0020110795740038157}, {"id": 192, "seek": 98760, "start": 996.88, "end": 1004.48, "text": " That's why it's called PDQF, PDQ float, and then you compute the average of the old descriptors", "tokens": [663, 311, 983, 309, 311, 1219, 10464, 48, 37, 11, 10464, 48, 15706, 11, 293, 550, 291, 14722, 264, 4274, 295, 264, 1331, 31280, 830], "temperature": 0.0, "avg_logprob": -0.1881246778700087, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.0020110795740038157}, {"id": 193, "seek": 98760, "start": 1004.48, "end": 1009.6, "text": " that you have within various periods of the cousin and scene.", "tokens": [300, 291, 362, 1951, 3683, 13804, 295, 264, 16207, 293, 4145, 13], "temperature": 0.0, "avg_logprob": -0.1881246778700087, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.0020110795740038157}, {"id": 194, "seek": 98760, "start": 1009.6, "end": 1012.4, "text": " Why we add the cousin curves?", "tokens": [1545, 321, 909, 264, 16207, 19490, 30], "temperature": 0.0, "avg_logprob": -0.1881246778700087, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.0020110795740038157}, {"id": 195, "seek": 101240, "start": 1012.4, "end": 1020.0799999999999, "text": " Because a cousin or a scene adds this wobbly movement that tells you whether a frame is", "tokens": [1436, 257, 16207, 420, 257, 4145, 10860, 341, 33775, 25021, 3963, 300, 5112, 291, 1968, 257, 3920, 307], "temperature": 0.0, "avg_logprob": -0.185305948610659, "compression_ratio": 1.6798029556650247, "no_speech_prob": 0.0010082273511216044}, {"id": 196, "seek": 101240, "start": 1020.0799999999999, "end": 1026.6, "text": " before or later in the near surroundings, the near neighborhood of the frames.", "tokens": [949, 420, 1780, 294, 264, 2651, 25314, 11, 264, 2651, 7630, 295, 264, 12083, 13], "temperature": 0.0, "avg_logprob": -0.185305948610659, "compression_ratio": 1.6798029556650247, "no_speech_prob": 0.0010082273511216044}, {"id": 197, "seek": 101240, "start": 1026.6, "end": 1032.68, "text": " In case you have 10 pictures, you add this cousin signal, you know this picture is before", "tokens": [682, 1389, 291, 362, 1266, 5242, 11, 291, 909, 341, 16207, 6358, 11, 291, 458, 341, 3036, 307, 949], "temperature": 0.0, "avg_logprob": -0.185305948610659, "compression_ratio": 1.6798029556650247, "no_speech_prob": 0.0010082273511216044}, {"id": 198, "seek": 101240, "start": 1032.68, "end": 1038.48, "text": " this one because you see the cousin curve which is going up and going down, and it's", "tokens": [341, 472, 570, 291, 536, 264, 16207, 7605, 597, 307, 516, 493, 293, 516, 760, 11, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.185305948610659, "compression_ratio": 1.6798029556650247, "no_speech_prob": 0.0010082273511216044}, {"id": 199, "seek": 103848, "start": 1038.48, "end": 1045.48, "text": " a nice uniqueness fingerprinting time signature algorithm to add a cousin.", "tokens": [257, 1481, 48294, 30715, 278, 565, 13397, 9284, 281, 909, 257, 16207, 13], "temperature": 0.0, "avg_logprob": -0.1640501393900289, "compression_ratio": 1.625668449197861, "no_speech_prob": 0.0008507929160259664}, {"id": 200, "seek": 103848, "start": 1045.48, "end": 1051.1200000000001, "text": " You compute the average of all the frames, the PDQF for all the frames, with various", "tokens": [509, 14722, 264, 4274, 295, 439, 264, 12083, 11, 264, 10464, 48, 37, 337, 439, 264, 12083, 11, 365, 3683], "temperature": 0.0, "avg_logprob": -0.1640501393900289, "compression_ratio": 1.625668449197861, "no_speech_prob": 0.0008507929160259664}, {"id": 201, "seek": 103848, "start": 1051.1200000000001, "end": 1056.32, "text": " periods, various scene and cousin, and then you pack them all together, and you have these", "tokens": [13804, 11, 3683, 4145, 293, 16207, 11, 293, 550, 291, 2844, 552, 439, 1214, 11, 293, 291, 362, 613], "temperature": 0.0, "avg_logprob": -0.1640501393900289, "compression_ratio": 1.625668449197861, "no_speech_prob": 0.0008507929160259664}, {"id": 202, "seek": 103848, "start": 1056.32, "end": 1062.84, "text": " five or six averages, and that's your PDQF embedding.", "tokens": [1732, 420, 2309, 42257, 11, 293, 300, 311, 428, 10464, 48, 37, 12240, 3584, 13], "temperature": 0.0, "avg_logprob": -0.1640501393900289, "compression_ratio": 1.625668449197861, "no_speech_prob": 0.0008507929160259664}, {"id": 203, "seek": 106284, "start": 1062.84, "end": 1068.76, "text": " Exampling is just you compare first the vector zero, which is the average of all the frames", "tokens": [24755, 11970, 307, 445, 291, 6794, 700, 264, 8062, 4018, 11, 597, 307, 264, 4274, 295, 439, 264, 12083], "temperature": 0.0, "avg_logprob": -0.1849814109431887, "compression_ratio": 1.8340425531914895, "no_speech_prob": 0.0005770298885181546}, {"id": 204, "seek": 106284, "start": 1068.76, "end": 1075.08, "text": " and doesn't retain a temporal signature, then if there is a match, you compare also all", "tokens": [293, 1177, 380, 18340, 257, 30881, 13397, 11, 550, 498, 456, 307, 257, 2995, 11, 291, 6794, 611, 439], "temperature": 0.0, "avg_logprob": -0.1849814109431887, "compression_ratio": 1.8340425531914895, "no_speech_prob": 0.0005770298885181546}, {"id": 205, "seek": 106284, "start": 1075.08, "end": 1081.1999999999998, "text": " the other vectors at different periods, which are the level two action as the time signature,", "tokens": [264, 661, 18875, 412, 819, 13804, 11, 597, 366, 264, 1496, 732, 3069, 382, 264, 565, 13397, 11], "temperature": 0.0, "avg_logprob": -0.1849814109431887, "compression_ratio": 1.8340425531914895, "no_speech_prob": 0.0005770298885181546}, {"id": 206, "seek": 106284, "start": 1081.1999999999998, "end": 1084.84, "text": " and so you can be really be sure that the videos are really the same, because if you", "tokens": [293, 370, 291, 393, 312, 534, 312, 988, 300, 264, 2145, 366, 534, 264, 912, 11, 570, 498, 291], "temperature": 0.0, "avg_logprob": -0.1849814109431887, "compression_ratio": 1.8340425531914895, "no_speech_prob": 0.0005770298885181546}, {"id": 207, "seek": 106284, "start": 1084.84, "end": 1089.6399999999999, "text": " find the same averages with the same periods, it must be the same video.", "tokens": [915, 264, 912, 42257, 365, 264, 912, 13804, 11, 309, 1633, 312, 264, 912, 960, 13], "temperature": 0.0, "avg_logprob": -0.1849814109431887, "compression_ratio": 1.8340425531914895, "no_speech_prob": 0.0005770298885181546}, {"id": 208, "seek": 108964, "start": 1089.64, "end": 1093.76, "text": " It's nice that it's resistant to resampling, because you always resample.", "tokens": [467, 311, 1481, 300, 309, 311, 20383, 281, 725, 335, 11970, 11, 570, 291, 1009, 725, 335, 781, 13], "temperature": 0.0, "avg_logprob": -0.17925704609264026, "compression_ratio": 1.6982758620689655, "no_speech_prob": 0.0007692615617997944}, {"id": 209, "seek": 108964, "start": 1093.76, "end": 1099.8000000000002, "text": " So in some way, if you vary the frame rate, the video will change, and MD5 hash will change,", "tokens": [407, 294, 512, 636, 11, 498, 291, 10559, 264, 3920, 3314, 11, 264, 960, 486, 1319, 11, 293, 22521, 20, 22019, 486, 1319, 11], "temperature": 0.0, "avg_logprob": -0.17925704609264026, "compression_ratio": 1.6982758620689655, "no_speech_prob": 0.0007692615617997944}, {"id": 210, "seek": 108964, "start": 1099.8000000000002, "end": 1102.16, "text": " but this one is not full load.", "tokens": [457, 341, 472, 307, 406, 1577, 3677, 13], "temperature": 0.0, "avg_logprob": -0.17925704609264026, "compression_ratio": 1.6982758620689655, "no_speech_prob": 0.0007692615617997944}, {"id": 211, "seek": 108964, "start": 1102.16, "end": 1108.72, "text": " Ashing is really slow, because you have to do a transcoding of all the videos first,", "tokens": [1018, 571, 307, 534, 2964, 11, 570, 291, 362, 281, 360, 257, 43800, 8616, 295, 439, 264, 2145, 700, 11], "temperature": 0.0, "avg_logprob": -0.17925704609264026, "compression_ratio": 1.6982758620689655, "no_speech_prob": 0.0007692615617997944}, {"id": 212, "seek": 108964, "start": 1108.72, "end": 1113.48, "text": " and then you have to read all the frames and compute the PDQ for every frame.", "tokens": [293, 550, 291, 362, 281, 1401, 439, 264, 12083, 293, 14722, 264, 10464, 48, 337, 633, 3920, 13], "temperature": 0.0, "avg_logprob": -0.17925704609264026, "compression_ratio": 1.6982758620689655, "no_speech_prob": 0.0007692615617997944}, {"id": 213, "seek": 108964, "start": 1113.48, "end": 1116.68, "text": " But search is actually very fast.", "tokens": [583, 3164, 307, 767, 588, 2370, 13], "temperature": 0.0, "avg_logprob": -0.17925704609264026, "compression_ratio": 1.6982758620689655, "no_speech_prob": 0.0007692615617997944}, {"id": 214, "seek": 111668, "start": 1116.68, "end": 1119.92, "text": " Another nice hashing technique that we have is the video MD5.", "tokens": [3996, 1481, 575, 571, 6532, 300, 321, 362, 307, 264, 960, 22521, 20, 13], "temperature": 0.0, "avg_logprob": -0.2135446782697711, "compression_ratio": 1.5889328063241106, "no_speech_prob": 0.0020360134076327085}, {"id": 215, "seek": 111668, "start": 1119.92, "end": 1123.6000000000001, "text": " I said that we will not be using a crypto-ashes highlight.", "tokens": [286, 848, 300, 321, 486, 406, 312, 1228, 257, 17240, 12, 296, 8076, 5078, 13], "temperature": 0.0, "avg_logprob": -0.2135446782697711, "compression_ratio": 1.5889328063241106, "no_speech_prob": 0.0020360134076327085}, {"id": 216, "seek": 111668, "start": 1123.6000000000001, "end": 1126.44, "text": " We use crypto-ashes, but just for videos.", "tokens": [492, 764, 17240, 12, 296, 8076, 11, 457, 445, 337, 2145, 13], "temperature": 0.0, "avg_logprob": -0.2135446782697711, "compression_ratio": 1.5889328063241106, "no_speech_prob": 0.0020360134076327085}, {"id": 217, "seek": 111668, "start": 1126.44, "end": 1131.0, "text": " This because if you take a MD5 of video and find exact copies, it's really cheap in this", "tokens": [639, 570, 498, 291, 747, 257, 22521, 20, 295, 960, 293, 915, 1900, 14341, 11, 309, 311, 534, 7084, 294, 341], "temperature": 0.0, "avg_logprob": -0.2135446782697711, "compression_ratio": 1.5889328063241106, "no_speech_prob": 0.0020360134076327085}, {"id": 218, "seek": 111668, "start": 1131.0, "end": 1132.0, "text": " way.", "tokens": [636, 13], "temperature": 0.0, "avg_logprob": -0.2135446782697711, "compression_ratio": 1.5889328063241106, "no_speech_prob": 0.0020360134076327085}, {"id": 219, "seek": 111668, "start": 1132.0, "end": 1138.3200000000002, "text": " A lot of actors just repost unmodified content.", "tokens": [316, 688, 295, 10037, 445, 1085, 555, 517, 8014, 2587, 2701, 13], "temperature": 0.0, "avg_logprob": -0.2135446782697711, "compression_ratio": 1.5889328063241106, "no_speech_prob": 0.0020360134076327085}, {"id": 220, "seek": 111668, "start": 1138.3200000000002, "end": 1144.3200000000002, "text": " They are not going really through the hassle of doing a encoding just to try to fool the", "tokens": [814, 366, 406, 516, 534, 807, 264, 39526, 295, 884, 257, 43430, 445, 281, 853, 281, 7979, 264], "temperature": 0.0, "avg_logprob": -0.2135446782697711, "compression_ratio": 1.5889328063241106, "no_speech_prob": 0.0020360134076327085}, {"id": 221, "seek": 111668, "start": 1144.3200000000002, "end": 1145.3200000000002, "text": " systems.", "tokens": [3652, 13], "temperature": 0.0, "avg_logprob": -0.2135446782697711, "compression_ratio": 1.5889328063241106, "no_speech_prob": 0.0020360134076327085}, {"id": 222, "seek": 114532, "start": 1145.32, "end": 1147.28, "text": " They just try to repost again.", "tokens": [814, 445, 853, 281, 1085, 555, 797, 13], "temperature": 0.0, "avg_logprob": -0.20312692534248783, "compression_ratio": 1.4875, "no_speech_prob": 0.0007477642502635717}, {"id": 223, "seek": 114532, "start": 1147.28, "end": 1152.76, "text": " So the MD5 actually works, and it can be done with vector search if we use the bytes for", "tokens": [407, 264, 22521, 20, 767, 1985, 11, 293, 309, 393, 312, 1096, 365, 8062, 3164, 498, 321, 764, 264, 36088, 337], "temperature": 0.0, "avg_logprob": -0.20312692534248783, "compression_ratio": 1.4875, "no_speech_prob": 0.0007477642502635717}, {"id": 224, "seek": 114532, "start": 1152.76, "end": 1154.6, "text": " the MD5 algorithm.", "tokens": [264, 22521, 20, 9284, 13], "temperature": 0.0, "avg_logprob": -0.20312692534248783, "compression_ratio": 1.4875, "no_speech_prob": 0.0007477642502635717}, {"id": 225, "seek": 114532, "start": 1154.6, "end": 1160.8799999999999, "text": " And it's used widely in stopncii.org also.", "tokens": [400, 309, 311, 1143, 13371, 294, 1590, 77, 537, 72, 13, 4646, 611, 13], "temperature": 0.0, "avg_logprob": -0.20312692534248783, "compression_ratio": 1.4875, "no_speech_prob": 0.0007477642502635717}, {"id": 226, "seek": 114532, "start": 1160.8799999999999, "end": 1167.3999999999999, "text": " In 2022, Facebook has released the video PDQ, which is a different algorithm from the former", "tokens": [682, 20229, 11, 4384, 575, 4736, 264, 960, 10464, 48, 11, 597, 307, 257, 819, 9284, 490, 264, 5819], "temperature": 0.0, "avg_logprob": -0.20312692534248783, "compression_ratio": 1.4875, "no_speech_prob": 0.0007477642502635717}, {"id": 227, "seek": 114532, "start": 1167.3999999999999, "end": 1168.8799999999999, "text": " one.", "tokens": [472, 13], "temperature": 0.0, "avg_logprob": -0.20312692534248783, "compression_ratio": 1.4875, "no_speech_prob": 0.0007477642502635717}, {"id": 228, "seek": 114532, "start": 1168.8799999999999, "end": 1173.8799999999999, "text": " Hashing is that we hash every frame to a PDQ hash, and we just pack the list.", "tokens": [8646, 571, 307, 300, 321, 22019, 633, 3920, 281, 257, 10464, 48, 22019, 11, 293, 321, 445, 2844, 264, 1329, 13], "temperature": 0.0, "avg_logprob": -0.20312692534248783, "compression_ratio": 1.4875, "no_speech_prob": 0.0007477642502635717}, {"id": 229, "seek": 117388, "start": 1173.88, "end": 1176.1200000000001, "text": " It's much bigger.", "tokens": [467, 311, 709, 3801, 13], "temperature": 0.0, "avg_logprob": -0.16433020388142447, "compression_ratio": 1.5735294117647058, "no_speech_prob": 0.0011403380194678903}, {"id": 230, "seek": 117388, "start": 1176.1200000000001, "end": 1184.24, "text": " It's not slower than the other one, but it has a nice property that we just have to search", "tokens": [467, 311, 406, 14009, 813, 264, 661, 472, 11, 457, 309, 575, 257, 1481, 4707, 300, 321, 445, 362, 281, 3164], "temperature": 0.0, "avg_logprob": -0.16433020388142447, "compression_ratio": 1.5735294117647058, "no_speech_prob": 0.0011403380194678903}, {"id": 231, "seek": 117388, "start": 1184.24, "end": 1186.16, "text": " for individual frames.", "tokens": [337, 2609, 12083, 13], "temperature": 0.0, "avg_logprob": -0.16433020388142447, "compression_ratio": 1.5735294117647058, "no_speech_prob": 0.0011403380194678903}, {"id": 232, "seek": 117388, "start": 1186.16, "end": 1190.1200000000001, "text": " So we treat the problem as a back-of-word approach.", "tokens": [407, 321, 2387, 264, 1154, 382, 257, 646, 12, 2670, 12, 7462, 3109, 13], "temperature": 0.0, "avg_logprob": -0.16433020388142447, "compression_ratio": 1.5735294117647058, "no_speech_prob": 0.0011403380194678903}, {"id": 233, "seek": 117388, "start": 1190.1200000000001, "end": 1195.3200000000002, "text": " So we just put all these frames inside an index library.", "tokens": [407, 321, 445, 829, 439, 613, 12083, 1854, 364, 8186, 6405, 13], "temperature": 0.0, "avg_logprob": -0.16433020388142447, "compression_ratio": 1.5735294117647058, "no_speech_prob": 0.0011403380194678903}, {"id": 234, "seek": 117388, "start": 1195.3200000000002, "end": 1200.3600000000001, "text": " Then we search, and we take all the candidates, and we do a pairwise comparison.", "tokens": [1396, 321, 3164, 11, 293, 321, 747, 439, 264, 11255, 11, 293, 321, 360, 257, 6119, 3711, 9660, 13], "temperature": 0.0, "avg_logprob": -0.16433020388142447, "compression_ratio": 1.5735294117647058, "no_speech_prob": 0.0011403380194678903}, {"id": 235, "seek": 120036, "start": 1200.36, "end": 1205.4799999999998, "text": " If the pairwise comparison is successful beyond a certain threshold, then it's a match.", "tokens": [759, 264, 6119, 3711, 9660, 307, 4406, 4399, 257, 1629, 14678, 11, 550, 309, 311, 257, 2995, 13], "temperature": 0.0, "avg_logprob": -0.17572261319302096, "compression_ratio": 1.56, "no_speech_prob": 0.00034504171344451606}, {"id": 236, "seek": 120036, "start": 1205.4799999999998, "end": 1212.08, "text": " And also this you get for free, and it's released along with the PDQ, along with the TMK, PDQF.", "tokens": [400, 611, 341, 291, 483, 337, 1737, 11, 293, 309, 311, 4736, 2051, 365, 264, 10464, 48, 11, 2051, 365, 264, 33550, 42, 11, 10464, 48, 37, 13], "temperature": 0.0, "avg_logprob": -0.17572261319302096, "compression_ratio": 1.56, "no_speech_prob": 0.00034504171344451606}, {"id": 237, "seek": 120036, "start": 1212.08, "end": 1220.08, "text": " All this is available inside the Facebook Research GitHub repository.", "tokens": [1057, 341, 307, 2435, 1854, 264, 4384, 10303, 23331, 25841, 13], "temperature": 0.0, "avg_logprob": -0.17572261319302096, "compression_ratio": 1.56, "no_speech_prob": 0.00034504171344451606}, {"id": 238, "seek": 120036, "start": 1220.08, "end": 1222.9199999999998, "text": " What do you do once you have all these hashes?", "tokens": [708, 360, 291, 360, 1564, 291, 362, 439, 613, 575, 8076, 30], "temperature": 0.0, "avg_logprob": -0.17572261319302096, "compression_ratio": 1.56, "no_speech_prob": 0.00034504171344451606}, {"id": 239, "seek": 120036, "start": 1222.9199999999998, "end": 1228.1999999999998, "text": " Your platform is computing the hashes, but it's the first time that you see this content,", "tokens": [2260, 3663, 307, 15866, 264, 575, 8076, 11, 457, 309, 311, 264, 700, 565, 300, 291, 536, 341, 2701, 11], "temperature": 0.0, "avg_logprob": -0.17572261319302096, "compression_ratio": 1.56, "no_speech_prob": 0.00034504171344451606}, {"id": 240, "seek": 122820, "start": 1228.2, "end": 1232.64, "text": " but perhaps all other actors have already seen this content, too.", "tokens": [457, 4317, 439, 661, 10037, 362, 1217, 1612, 341, 2701, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.22940547491914481, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0012093380792066455}, {"id": 241, "seek": 122820, "start": 1232.64, "end": 1239.92, "text": " While you upload them to the threat exchange platform, Necmac shares the PDNA hashes, I", "tokens": [3987, 291, 6580, 552, 281, 264, 4734, 7742, 3663, 11, 1734, 15210, 326, 12182, 264, 10464, 5321, 575, 8076, 11, 286], "temperature": 0.0, "avg_logprob": -0.22940547491914481, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0012093380792066455}, {"id": 242, "seek": 122820, "start": 1239.92, "end": 1242.4, "text": " told you, with all companies that are asking for them.", "tokens": [1907, 291, 11, 365, 439, 3431, 300, 366, 3365, 337, 552, 13], "temperature": 0.0, "avg_logprob": -0.22940547491914481, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0012093380792066455}, {"id": 243, "seek": 122820, "start": 1242.4, "end": 1248.16, "text": " So can you please tell me where this picture that someone uploaded is a match in Necmac?", "tokens": [407, 393, 291, 1767, 980, 385, 689, 341, 3036, 300, 1580, 17135, 307, 257, 2995, 294, 1734, 15210, 326, 30], "temperature": 0.0, "avg_logprob": -0.22940547491914481, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0012093380792066455}, {"id": 244, "seek": 122820, "start": 1248.16, "end": 1252.4, "text": " So I already know that this is something I should call the law enforcement.", "tokens": [407, 286, 1217, 458, 300, 341, 307, 746, 286, 820, 818, 264, 2101, 11475, 13], "temperature": 0.0, "avg_logprob": -0.22940547491914481, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0012093380792066455}, {"id": 245, "seek": 125240, "start": 1252.4, "end": 1259.3600000000001, "text": " Data does the equivalent, but for the PDQ, because it has much less friction to adopt", "tokens": [11888, 775, 264, 10344, 11, 457, 337, 264, 10464, 48, 11, 570, 309, 575, 709, 1570, 17710, 281, 6878], "temperature": 0.0, "avg_logprob": -0.23015893830193412, "compression_ratio": 1.4509803921568627, "no_speech_prob": 0.002245471114292741}, {"id": 246, "seek": 125240, "start": 1259.3600000000001, "end": 1262.6000000000001, "text": " the PDQ compared to the PDNA.", "tokens": [264, 10464, 48, 5347, 281, 264, 10464, 5321, 13], "temperature": 0.0, "avg_logprob": -0.23015893830193412, "compression_ratio": 1.4509803921568627, "no_speech_prob": 0.002245471114292741}, {"id": 247, "seek": 125240, "start": 1262.6000000000001, "end": 1266.24, "text": " There's a team, the Internet Safety Engineering that builds and operates all these services", "tokens": [821, 311, 257, 1469, 11, 264, 7703, 21340, 16215, 300, 15182, 293, 22577, 439, 613, 3328], "temperature": 0.0, "avg_logprob": -0.23015893830193412, "compression_ratio": 1.4509803921568627, "no_speech_prob": 0.002245471114292741}, {"id": 248, "seek": 125240, "start": 1266.24, "end": 1275.96, "text": " where anyone can upload fingerprints, and so you can crowdsource a big graph of matches.", "tokens": [689, 2878, 393, 6580, 42170, 11, 293, 370, 291, 393, 26070, 2948, 257, 955, 4295, 295, 10676, 13], "temperature": 0.0, "avg_logprob": -0.23015893830193412, "compression_ratio": 1.4509803921568627, "no_speech_prob": 0.002245471114292741}, {"id": 249, "seek": 127596, "start": 1275.96, "end": 1283.6000000000001, "text": " There's REST API to access and post new data, has multi-language clients, uses PDQ, and", "tokens": [821, 311, 497, 14497, 9362, 281, 2105, 293, 2183, 777, 1412, 11, 575, 4825, 12, 25241, 20473, 6982, 11, 4960, 10464, 48, 11, 293], "temperature": 0.0, "avg_logprob": -0.20341339111328124, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.0012489130022004247}, {"id": 250, "seek": 127596, "start": 1283.6000000000001, "end": 1285.0, "text": " users can also download the data.", "tokens": [5022, 393, 611, 5484, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.20341339111328124, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.0012489130022004247}, {"id": 251, "seek": 127596, "start": 1285.0, "end": 1287.8, "text": " You are not forced to stay online, stay connected.", "tokens": [509, 366, 406, 7579, 281, 1754, 2950, 11, 1754, 4582, 13], "temperature": 0.0, "avg_logprob": -0.20341339111328124, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.0012489130022004247}, {"id": 252, "seek": 127596, "start": 1287.8, "end": 1293.08, "text": " You can just request for a dump of the database and you can search it.", "tokens": [509, 393, 445, 5308, 337, 257, 11430, 295, 264, 8149, 293, 291, 393, 3164, 309, 13], "temperature": 0.0, "avg_logprob": -0.20341339111328124, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.0012489130022004247}, {"id": 253, "seek": 127596, "start": 1293.08, "end": 1300.04, "text": " And you find all the data and all the APIs at the GitHub page.", "tokens": [400, 291, 915, 439, 264, 1412, 293, 439, 264, 21445, 412, 264, 23331, 3028, 13], "temperature": 0.0, "avg_logprob": -0.20341339111328124, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.0012489130022004247}, {"id": 254, "seek": 130004, "start": 1300.04, "end": 1309.72, "text": " In 2020, Facebook also has released its most advanced algorithm to spot similar images,", "tokens": [682, 4808, 11, 4384, 611, 575, 4736, 1080, 881, 7339, 9284, 281, 4008, 2531, 5267, 11], "temperature": 0.0, "avg_logprob": -0.24697192240569552, "compression_ratio": 1.3604651162790697, "no_speech_prob": 0.0014184009050950408}, {"id": 255, "seek": 130004, "start": 1309.72, "end": 1312.72, "text": " the SimSearchNet++.", "tokens": [264, 3998, 10637, 1178, 31890, 25472, 13], "temperature": 0.0, "avg_logprob": -0.24697192240569552, "compression_ratio": 1.3604651162790697, "no_speech_prob": 0.0014184009050950408}, {"id": 256, "seek": 130004, "start": 1312.72, "end": 1321.92, "text": " This is an error network, and it is capable of facing adversarial manipulation that the", "tokens": [639, 307, 364, 6713, 3209, 11, 293, 309, 307, 8189, 295, 7170, 17641, 44745, 26475, 300, 264], "temperature": 0.0, "avg_logprob": -0.24697192240569552, "compression_ratio": 1.3604651162790697, "no_speech_prob": 0.0014184009050950408}, {"id": 257, "seek": 130004, "start": 1321.92, "end": 1326.04, "text": " other embeddings just are not able to.", "tokens": [661, 12240, 29432, 445, 366, 406, 1075, 281, 13], "temperature": 0.0, "avg_logprob": -0.24697192240569552, "compression_ratio": 1.3604651162790697, "no_speech_prob": 0.0014184009050950408}, {"id": 258, "seek": 132604, "start": 1326.04, "end": 1333.24, "text": " Unfortunately, SimSearchNet is proprietary, so I cannot really talk about that, but we", "tokens": [8590, 11, 3998, 10637, 1178, 31890, 307, 38992, 11, 370, 286, 2644, 534, 751, 466, 300, 11, 457, 321], "temperature": 0.0, "avg_logprob": -0.21439849556266488, "compression_ratio": 1.6149732620320856, "no_speech_prob": 0.0030658177565783262}, {"id": 259, "seek": 132604, "start": 1333.24, "end": 1345.68, "text": " have a cousin product, SSCD, the SimSearch Copy Detection, which is open source and free.", "tokens": [362, 257, 16207, 1674, 11, 12238, 16508, 11, 264, 3998, 10637, 1178, 25653, 4237, 10183, 11, 597, 307, 1269, 4009, 293, 1737, 13], "temperature": 0.0, "avg_logprob": -0.21439849556266488, "compression_ratio": 1.6149732620320856, "no_speech_prob": 0.0030658177565783262}, {"id": 260, "seek": 132604, "start": 1345.68, "end": 1347.56, "text": " So I can really talk about that.", "tokens": [407, 286, 393, 534, 751, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.21439849556266488, "compression_ratio": 1.6149732620320856, "no_speech_prob": 0.0030658177565783262}, {"id": 261, "seek": 132604, "start": 1347.56, "end": 1354.6399999999999, "text": " They are somewhat related in some technological principles, so I can really talk about this.", "tokens": [814, 366, 8344, 4077, 294, 512, 18439, 9156, 11, 370, 286, 393, 534, 751, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.21439849556266488, "compression_ratio": 1.6149732620320856, "no_speech_prob": 0.0030658177565783262}, {"id": 262, "seek": 135464, "start": 1354.64, "end": 1359.48, "text": " So this is a PyTorch-based model.", "tokens": [407, 341, 307, 257, 9953, 51, 284, 339, 12, 6032, 2316, 13], "temperature": 0.0, "avg_logprob": -0.1997184329562717, "compression_ratio": 1.4325581395348836, "no_speech_prob": 0.0012153959833085537}, {"id": 263, "seek": 135464, "start": 1359.48, "end": 1366.2, "text": " So the problem that this, which is a state-of-the-art product, is trying to solve is what happens", "tokens": [407, 264, 1154, 300, 341, 11, 597, 307, 257, 1785, 12, 2670, 12, 3322, 12, 446, 1674, 11, 307, 1382, 281, 5039, 307, 437, 2314], "temperature": 0.0, "avg_logprob": -0.1997184329562717, "compression_ratio": 1.4325581395348836, "no_speech_prob": 0.0012153959833085537}, {"id": 264, "seek": 135464, "start": 1366.2, "end": 1374.8400000000001, "text": " if I take a picture and I put a caption on it, alterating so many pixels everywhere.", "tokens": [498, 286, 747, 257, 3036, 293, 286, 829, 257, 31974, 322, 309, 11, 11337, 990, 370, 867, 18668, 5315, 13], "temperature": 0.0, "avg_logprob": -0.1997184329562717, "compression_ratio": 1.4325581395348836, "no_speech_prob": 0.0012153959833085537}, {"id": 265, "seek": 135464, "start": 1374.8400000000001, "end": 1383.1200000000001, "text": " A PDQ or a PDNA-ASH would be altered dramatically, but is there anything we can do to teach", "tokens": [316, 10464, 48, 420, 257, 10464, 5321, 12, 24036, 576, 312, 28783, 17548, 11, 457, 307, 456, 1340, 321, 393, 360, 281, 2924], "temperature": 0.0, "avg_logprob": -0.1997184329562717, "compression_ratio": 1.4325581395348836, "no_speech_prob": 0.0012153959833085537}, {"id": 266, "seek": 138312, "start": 1383.12, "end": 1390.08, "text": " a computer to just ignore all the captions, all the rotations, all the jitters, all the", "tokens": [257, 3820, 281, 445, 11200, 439, 264, 44832, 11, 439, 264, 44796, 11, 439, 264, 361, 38873, 11, 439, 264], "temperature": 0.0, "avg_logprob": -0.14367473334596867, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0006630220450460911}, {"id": 267, "seek": 138312, "start": 1390.08, "end": 1391.6, "text": " cropping of the image?", "tokens": [4848, 3759, 295, 264, 3256, 30], "temperature": 0.0, "avg_logprob": -0.14367473334596867, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0006630220450460911}, {"id": 268, "seek": 138312, "start": 1391.6, "end": 1392.6799999999998, "text": " Yes, there is.", "tokens": [1079, 11, 456, 307, 13], "temperature": 0.0, "avg_logprob": -0.14367473334596867, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0006630220450460911}, {"id": 269, "seek": 138312, "start": 1392.6799999999998, "end": 1397.28, "text": " A person is able to do that, so we can teach a computer to do that, too.", "tokens": [316, 954, 307, 1075, 281, 360, 300, 11, 370, 321, 393, 2924, 257, 3820, 281, 360, 300, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.14367473334596867, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0006630220450460911}, {"id": 270, "seek": 138312, "start": 1397.28, "end": 1399.1999999999998, "text": " So models and code are available.", "tokens": [407, 5245, 293, 3089, 366, 2435, 13], "temperature": 0.0, "avg_logprob": -0.14367473334596867, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0006630220450460911}, {"id": 271, "seek": 138312, "start": 1399.1999999999998, "end": 1404.04, "text": " What is now available is the training data that we use to create a model, of course.", "tokens": [708, 307, 586, 2435, 307, 264, 3097, 1412, 300, 321, 764, 281, 1884, 257, 2316, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.14367473334596867, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0006630220450460911}, {"id": 272, "seek": 138312, "start": 1404.04, "end": 1411.7199999999998, "text": " For those which are into the deep learning, it's a ResNet 50 convolutive neural network.", "tokens": [1171, 729, 597, 366, 666, 264, 2452, 2539, 11, 309, 311, 257, 5015, 31890, 2625, 3754, 2308, 488, 18161, 3209, 13], "temperature": 0.0, "avg_logprob": -0.14367473334596867, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0006630220450460911}, {"id": 273, "seek": 141172, "start": 1411.72, "end": 1417.32, "text": " And the novelty of the approach is that it's based on our MAC vocabularies.", "tokens": [400, 264, 44805, 295, 264, 3109, 307, 300, 309, 311, 2361, 322, 527, 27716, 2329, 455, 1040, 530, 13], "temperature": 0.0, "avg_logprob": -0.1659573860538816, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0008864808478392661}, {"id": 274, "seek": 141172, "start": 1417.32, "end": 1423.96, "text": " Our regional MAC, for those, how many of you know how a convolutive network work?", "tokens": [2621, 10964, 27716, 11, 337, 729, 11, 577, 867, 295, 291, 458, 577, 257, 3754, 2308, 488, 3209, 589, 30], "temperature": 0.0, "avg_logprob": -0.1659573860538816, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0008864808478392661}, {"id": 275, "seek": 141172, "start": 1423.96, "end": 1424.96, "text": " Raise your hand.", "tokens": [30062, 428, 1011, 13], "temperature": 0.0, "avg_logprob": -0.1659573860538816, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0008864808478392661}, {"id": 276, "seek": 141172, "start": 1424.96, "end": 1425.96, "text": " Okay, fine.", "tokens": [1033, 11, 2489, 13], "temperature": 0.0, "avg_logprob": -0.1659573860538816, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0008864808478392661}, {"id": 277, "seek": 141172, "start": 1425.96, "end": 1426.96, "text": " Very good.", "tokens": [4372, 665, 13], "temperature": 0.0, "avg_logprob": -0.1659573860538816, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0008864808478392661}, {"id": 278, "seek": 141172, "start": 1426.96, "end": 1433.8, "text": " So it's a network for the others that looks at the image, looks at portions of the image.", "tokens": [407, 309, 311, 257, 3209, 337, 264, 2357, 300, 1542, 412, 264, 3256, 11, 1542, 412, 25070, 295, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1659573860538816, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0008864808478392661}, {"id": 279, "seek": 141172, "start": 1433.8, "end": 1439.68, "text": " Each neuron looks at a different portion, and then they pass what they have understood", "tokens": [6947, 34090, 1542, 412, 257, 819, 8044, 11, 293, 550, 436, 1320, 437, 436, 362, 7320], "temperature": 0.0, "avg_logprob": -0.1659573860538816, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0008864808478392661}, {"id": 280, "seek": 143968, "start": 1439.68, "end": 1444.8400000000001, "text": " to a higher level series of neurons, the higher and the higher and the higher, until the last", "tokens": [281, 257, 2946, 1496, 2638, 295, 22027, 11, 264, 2946, 293, 264, 2946, 293, 264, 2946, 11, 1826, 264, 1036], "temperature": 0.0, "avg_logprob": -0.11298428000984612, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.002195306122303009}, {"id": 281, "seek": 143968, "start": 1444.8400000000001, "end": 1450.64, "text": " layer of the neurons has a very wide overview of the whole picture.", "tokens": [4583, 295, 264, 22027, 575, 257, 588, 4874, 12492, 295, 264, 1379, 3036, 13], "temperature": 0.0, "avg_logprob": -0.11298428000984612, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.002195306122303009}, {"id": 282, "seek": 143968, "start": 1450.64, "end": 1457.24, "text": " In this case, we are using the maximum activation of all the channels that we have.", "tokens": [682, 341, 1389, 11, 321, 366, 1228, 264, 6674, 24433, 295, 439, 264, 9235, 300, 321, 362, 13], "temperature": 0.0, "avg_logprob": -0.11298428000984612, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.002195306122303009}, {"id": 283, "seek": 143968, "start": 1457.24, "end": 1464.96, "text": " So we take note which are the regions of our Carnaut maps for every different channel,", "tokens": [407, 321, 747, 3637, 597, 366, 264, 10682, 295, 527, 32254, 1375, 11317, 337, 633, 819, 2269, 11], "temperature": 0.0, "avg_logprob": -0.11298428000984612, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.002195306122303009}, {"id": 284, "seek": 143968, "start": 1464.96, "end": 1468.8400000000001, "text": " which across all channels have the maximum activation.", "tokens": [597, 2108, 439, 9235, 362, 264, 6674, 24433, 13], "temperature": 0.0, "avg_logprob": -0.11298428000984612, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.002195306122303009}, {"id": 285, "seek": 146884, "start": 1468.84, "end": 1474.76, "text": " If you have 10 channels, and that region across all the different channels, all of them you", "tokens": [759, 291, 362, 1266, 9235, 11, 293, 300, 4458, 2108, 439, 264, 819, 9235, 11, 439, 295, 552, 291], "temperature": 0.0, "avg_logprob": -0.12835293371700546, "compression_ratio": 1.8209606986899562, "no_speech_prob": 0.0004140777455177158}, {"id": 286, "seek": 146884, "start": 1474.76, "end": 1479.32, "text": " have a maximum activation, that means that that area is an area of interest.", "tokens": [362, 257, 6674, 24433, 11, 300, 1355, 300, 300, 1859, 307, 364, 1859, 295, 1179, 13], "temperature": 0.0, "avg_logprob": -0.12835293371700546, "compression_ratio": 1.8209606986899562, "no_speech_prob": 0.0004140777455177158}, {"id": 287, "seek": 146884, "start": 1479.32, "end": 1485.6599999999999, "text": " So we use these areas of interest as a word in a vocabulary.", "tokens": [407, 321, 764, 613, 3179, 295, 1179, 382, 257, 1349, 294, 257, 19864, 13], "temperature": 0.0, "avg_logprob": -0.12835293371700546, "compression_ratio": 1.8209606986899562, "no_speech_prob": 0.0004140777455177158}, {"id": 288, "seek": 146884, "start": 1485.6599999999999, "end": 1492.1999999999998, "text": " So exactly when you do the Cosine similarity search for documents, you take all the words,", "tokens": [407, 2293, 562, 291, 360, 264, 15855, 533, 32194, 3164, 337, 8512, 11, 291, 747, 439, 264, 2283, 11], "temperature": 0.0, "avg_logprob": -0.12835293371700546, "compression_ratio": 1.8209606986899562, "no_speech_prob": 0.0004140777455177158}, {"id": 289, "seek": 146884, "start": 1492.1999999999998, "end": 1497.76, "text": " you index all the words, you say these documents as these words, so it's like a vector of words,", "tokens": [291, 8186, 439, 264, 2283, 11, 291, 584, 613, 8512, 382, 613, 2283, 11, 370, 309, 311, 411, 257, 8062, 295, 2283, 11], "temperature": 0.0, "avg_logprob": -0.12835293371700546, "compression_ratio": 1.8209606986899562, "no_speech_prob": 0.0004140777455177158}, {"id": 290, "seek": 149776, "start": 1497.76, "end": 1505.08, "text": " and then we try to see which are the vectors that have the most words in common and put", "tokens": [293, 550, 321, 853, 281, 536, 597, 366, 264, 18875, 300, 362, 264, 881, 2283, 294, 2689, 293, 829], "temperature": 0.0, "avg_logprob": -0.16069635815090602, "compression_ratio": 1.619289340101523, "no_speech_prob": 0.0007050171261653304}, {"id": 291, "seek": 149776, "start": 1505.08, "end": 1507.16, "text": " in the same place.", "tokens": [294, 264, 912, 1081, 13], "temperature": 0.0, "avg_logprob": -0.16069635815090602, "compression_ratio": 1.619289340101523, "no_speech_prob": 0.0007050171261653304}, {"id": 292, "seek": 149776, "start": 1507.16, "end": 1510.68, "text": " We do the same things, but for portions of the image.", "tokens": [492, 360, 264, 912, 721, 11, 457, 337, 25070, 295, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.16069635815090602, "compression_ratio": 1.619289340101523, "no_speech_prob": 0.0007050171261653304}, {"id": 293, "seek": 149776, "start": 1510.68, "end": 1513.12, "text": " So we use the rmax.", "tokens": [407, 321, 764, 264, 367, 41167, 13], "temperature": 0.0, "avg_logprob": -0.16069635815090602, "compression_ratio": 1.619289340101523, "no_speech_prob": 0.0007050171261653304}, {"id": 294, "seek": 149776, "start": 1513.12, "end": 1517.28, "text": " The idea is that it's a self-supervised system also.", "tokens": [440, 1558, 307, 300, 309, 311, 257, 2698, 12, 48172, 24420, 1185, 611, 13], "temperature": 0.0, "avg_logprob": -0.16069635815090602, "compression_ratio": 1.619289340101523, "no_speech_prob": 0.0007050171261653304}, {"id": 295, "seek": 149776, "start": 1517.28, "end": 1525.24, "text": " So it means that it's trained to recognize augmented input, and it's trained to match", "tokens": [407, 309, 1355, 300, 309, 311, 8895, 281, 5521, 36155, 4846, 11, 293, 309, 311, 8895, 281, 2995], "temperature": 0.0, "avg_logprob": -0.16069635815090602, "compression_ratio": 1.619289340101523, "no_speech_prob": 0.0007050171261653304}, {"id": 296, "seek": 152524, "start": 1525.24, "end": 1528.32, "text": " an input to its augmented version.", "tokens": [364, 4846, 281, 1080, 36155, 3037, 13], "temperature": 0.0, "avg_logprob": -0.15479286193847655, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.001317628426477313}, {"id": 297, "seek": 152524, "start": 1528.32, "end": 1532.44, "text": " So what we do is that we take the training set, we repeat a lot of augmentation, we add", "tokens": [407, 437, 321, 360, 307, 300, 321, 747, 264, 3097, 992, 11, 321, 7149, 257, 688, 295, 14501, 19631, 11, 321, 909], "temperature": 0.0, "avg_logprob": -0.15479286193847655, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.001317628426477313}, {"id": 298, "seek": 152524, "start": 1532.44, "end": 1537.88, "text": " the captions, the randomity, we rotate, we flip, we alter the colors.", "tokens": [264, 44832, 11, 264, 4974, 507, 11, 321, 13121, 11, 321, 7929, 11, 321, 11337, 264, 4577, 13], "temperature": 0.0, "avg_logprob": -0.15479286193847655, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.001317628426477313}, {"id": 299, "seek": 152524, "start": 1537.88, "end": 1546.6, "text": " For example, if you do a one degree of whitening, you make the image brighter, which is you", "tokens": [1171, 1365, 11, 498, 291, 360, 257, 472, 4314, 295, 47548, 4559, 11, 291, 652, 264, 3256, 19764, 11, 597, 307, 291], "temperature": 0.0, "avg_logprob": -0.15479286193847655, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.001317628426477313}, {"id": 300, "seek": 152524, "start": 1546.6, "end": 1551.56, "text": " add plus one to all the pixels in the image, you are altering all the pixels.", "tokens": [909, 1804, 472, 281, 439, 264, 18668, 294, 264, 3256, 11, 291, 366, 11337, 278, 439, 264, 18668, 13], "temperature": 0.0, "avg_logprob": -0.15479286193847655, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.001317628426477313}, {"id": 301, "seek": 155156, "start": 1551.56, "end": 1556.76, "text": " But in this case, a PDQ hash is capable of understanding the difference.", "tokens": [583, 294, 341, 1389, 11, 257, 10464, 48, 22019, 307, 8189, 295, 3701, 264, 2649, 13], "temperature": 0.0, "avg_logprob": -0.2005663438276811, "compression_ratio": 1.657370517928287, "no_speech_prob": 0.00130433717276901}, {"id": 302, "seek": 155156, "start": 1556.76, "end": 1561.28, "text": " There's a very weak form of adversarial attack, because the PDQ just computes the difference", "tokens": [821, 311, 257, 588, 5336, 1254, 295, 17641, 44745, 2690, 11, 570, 264, 10464, 48, 445, 715, 1819, 264, 2649], "temperature": 0.0, "avg_logprob": -0.2005663438276811, "compression_ratio": 1.657370517928287, "no_speech_prob": 0.00130433717276901}, {"id": 303, "seek": 155156, "start": 1561.28, "end": 1563.8, "text": " between regions, so it's not going to be fooled.", "tokens": [1296, 10682, 11, 370, 309, 311, 406, 516, 281, 312, 33372, 13], "temperature": 0.0, "avg_logprob": -0.2005663438276811, "compression_ratio": 1.657370517928287, "no_speech_prob": 0.00130433717276901}, {"id": 304, "seek": 155156, "start": 1563.8, "end": 1569.28, "text": " But you can be much more violent and put just a spot color somewhere, and PDQ is going to", "tokens": [583, 291, 393, 312, 709, 544, 11867, 293, 829, 445, 257, 4008, 2017, 4079, 11, 293, 10464, 48, 307, 516, 281], "temperature": 0.0, "avg_logprob": -0.2005663438276811, "compression_ratio": 1.657370517928287, "no_speech_prob": 0.00130433717276901}, {"id": 305, "seek": 155156, "start": 1569.28, "end": 1570.28, "text": " be fooled by that.", "tokens": [312, 33372, 538, 300, 13], "temperature": 0.0, "avg_logprob": -0.2005663438276811, "compression_ratio": 1.657370517928287, "no_speech_prob": 0.00130433717276901}, {"id": 306, "seek": 155156, "start": 1570.28, "end": 1575.76, "text": " Then you do through the CNN, you do a thing called gem pool, which means you do a generative", "tokens": [1396, 291, 360, 807, 264, 24859, 11, 291, 360, 257, 551, 1219, 7173, 7005, 11, 597, 1355, 291, 360, 257, 1337, 1166], "temperature": 0.0, "avg_logprob": -0.2005663438276811, "compression_ratio": 1.657370517928287, "no_speech_prob": 0.00130433717276901}, {"id": 307, "seek": 157576, "start": 1575.76, "end": 1582.84, "text": " mean pooling, a generalization of the average pooling, in case you were wondering.", "tokens": [914, 7005, 278, 11, 257, 2674, 2144, 295, 264, 4274, 7005, 278, 11, 294, 1389, 291, 645, 6359, 13], "temperature": 0.0, "avg_logprob": -0.13958473694630158, "compression_ratio": 1.6682926829268292, "no_speech_prob": 0.0005941426497884095}, {"id": 308, "seek": 157576, "start": 1582.84, "end": 1590.4, "text": " Then you go, and at the end you use an entropy-oriented loss function.", "tokens": [1396, 291, 352, 11, 293, 412, 264, 917, 291, 764, 364, 30867, 12, 27414, 4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.13958473694630158, "compression_ratio": 1.6682926829268292, "no_speech_prob": 0.0005941426497884095}, {"id": 309, "seek": 157576, "start": 1590.4, "end": 1599.36, "text": " This means that we want to encourage the network to spread the representation of training data", "tokens": [639, 1355, 300, 321, 528, 281, 5373, 264, 3209, 281, 3974, 264, 10290, 295, 3097, 1412], "temperature": 0.0, "avg_logprob": -0.13958473694630158, "compression_ratio": 1.6682926829268292, "no_speech_prob": 0.0005941426497884095}, {"id": 310, "seek": 157576, "start": 1599.36, "end": 1605.72, "text": " along all different places, because we want to maximize the distance between all the training", "tokens": [2051, 439, 819, 3190, 11, 570, 321, 528, 281, 19874, 264, 4560, 1296, 439, 264, 3097], "temperature": 0.0, "avg_logprob": -0.13958473694630158, "compression_ratio": 1.6682926829268292, "no_speech_prob": 0.0005941426497884095}, {"id": 311, "seek": 160572, "start": 1605.72, "end": 1608.16, "text": " examples in the training set.", "tokens": [5110, 294, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.19015107695589362, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00041406555101275444}, {"id": 312, "seek": 160572, "start": 1608.16, "end": 1611.2, "text": " So you get a nice uniform search space.", "tokens": [407, 291, 483, 257, 1481, 9452, 3164, 1901, 13], "temperature": 0.0, "avg_logprob": -0.19015107695589362, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00041406555101275444}, {"id": 313, "seek": 160572, "start": 1611.2, "end": 1617.52, "text": " At the inference time, you do the same with the CNN, and then you obtain a vector, which", "tokens": [1711, 264, 38253, 565, 11, 291, 360, 264, 912, 365, 264, 24859, 11, 293, 550, 291, 12701, 257, 8062, 11, 597], "temperature": 0.0, "avg_logprob": -0.19015107695589362, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00041406555101275444}, {"id": 314, "seek": 160572, "start": 1617.52, "end": 1619.76, "text": " is a representation of an image.", "tokens": [307, 257, 10290, 295, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.19015107695589362, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00041406555101275444}, {"id": 315, "seek": 160572, "start": 1619.76, "end": 1626.68, "text": " And the idea is that there is a distance that you can compute between the data set of the", "tokens": [400, 264, 1558, 307, 300, 456, 307, 257, 4560, 300, 291, 393, 14722, 1296, 264, 1412, 992, 295, 264], "temperature": 0.0, "avg_logprob": -0.19015107695589362, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00041406555101275444}, {"id": 316, "seek": 160572, "start": 1626.68, "end": 1628.44, "text": " reference images.", "tokens": [6408, 5267, 13], "temperature": 0.0, "avg_logprob": -0.19015107695589362, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00041406555101275444}, {"id": 317, "seek": 160572, "start": 1628.44, "end": 1634.64, "text": " Of course, you can subtract a background data set that was used generally to augment", "tokens": [2720, 1164, 11, 291, 393, 16390, 257, 3678, 1412, 992, 300, 390, 1143, 5101, 281, 29919], "temperature": 0.0, "avg_logprob": -0.19015107695589362, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00041406555101275444}, {"id": 318, "seek": 163464, "start": 1634.64, "end": 1640.24, "text": " the images, but in this case, what you obtain in the end is that the score of the augmented", "tokens": [264, 5267, 11, 457, 294, 341, 1389, 11, 437, 291, 12701, 294, 264, 917, 307, 300, 264, 6175, 295, 264, 36155], "temperature": 0.0, "avg_logprob": -0.1267311843400149, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012436864199116826}, {"id": 319, "seek": 163464, "start": 1640.24, "end": 1646.48, "text": " image is almost the same of the non-augmented version, because it just learns to ignore", "tokens": [3256, 307, 1920, 264, 912, 295, 264, 2107, 12, 20056, 14684, 3037, 11, 570, 309, 445, 27152, 281, 11200], "temperature": 0.0, "avg_logprob": -0.1267311843400149, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012436864199116826}, {"id": 320, "seek": 163464, "start": 1646.48, "end": 1650.44, "text": " the places which are not organic in the image.", "tokens": [264, 3190, 597, 366, 406, 10220, 294, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1267311843400149, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012436864199116826}, {"id": 321, "seek": 163464, "start": 1650.44, "end": 1654.4, "text": " And SSCD is freely available.", "tokens": [400, 12238, 16508, 307, 16433, 2435, 13], "temperature": 0.0, "avg_logprob": -0.1267311843400149, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012436864199116826}, {"id": 322, "seek": 163464, "start": 1654.4, "end": 1657.0800000000002, "text": " You can download that and start playing.", "tokens": [509, 393, 5484, 300, 293, 722, 2433, 13], "temperature": 0.0, "avg_logprob": -0.1267311843400149, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012436864199116826}, {"id": 323, "seek": 163464, "start": 1657.0800000000002, "end": 1662.6000000000001, "text": " You find both code and models, as I already said, but not the training data.", "tokens": [509, 915, 1293, 3089, 293, 5245, 11, 382, 286, 1217, 848, 11, 457, 406, 264, 3097, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1267311843400149, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012436864199116826}, {"id": 324, "seek": 166260, "start": 1662.6, "end": 1667.1599999999999, "text": " And by the way, Facebook has also announced an image similarity challenge.", "tokens": [400, 538, 264, 636, 11, 4384, 575, 611, 7548, 364, 3256, 32194, 3430, 13], "temperature": 0.0, "avg_logprob": -0.17700791358947754, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.001285943784750998}, {"id": 325, "seek": 166260, "start": 1667.1599999999999, "end": 1672.32, "text": " You have to determine whether a query image is a modified copy of any image in a reference", "tokens": [509, 362, 281, 6997, 1968, 257, 14581, 3256, 307, 257, 15873, 5055, 295, 604, 3256, 294, 257, 6408], "temperature": 0.0, "avg_logprob": -0.17700791358947754, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.001285943784750998}, {"id": 326, "seek": 166260, "start": 1672.32, "end": 1673.9199999999998, "text": " corpus of one million.", "tokens": [1181, 31624, 295, 472, 2459, 13], "temperature": 0.0, "avg_logprob": -0.17700791358947754, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.001285943784750998}, {"id": 327, "seek": 166260, "start": 1673.9199999999998, "end": 1681.9599999999998, "text": " This is very similar to the Netflix recommendation challenge, when you had to recommend the movies", "tokens": [639, 307, 588, 2531, 281, 264, 12778, 11879, 3430, 11, 562, 291, 632, 281, 2748, 264, 6233], "temperature": 0.0, "avg_logprob": -0.17700791358947754, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.001285943784750998}, {"id": 328, "seek": 166260, "start": 1681.9599999999998, "end": 1685.52, "text": " and you had to beat Netflix's algorithm.", "tokens": [293, 291, 632, 281, 4224, 12778, 311, 9284, 13], "temperature": 0.0, "avg_logprob": -0.17700791358947754, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.001285943784750998}, {"id": 329, "seek": 166260, "start": 1685.52, "end": 1690.6, "text": " And this is the image similarity challenge, and also the meta-IE video similarity challenge,", "tokens": [400, 341, 307, 264, 3256, 32194, 3430, 11, 293, 611, 264, 19616, 12, 6550, 960, 32194, 3430, 11], "temperature": 0.0, "avg_logprob": -0.17700791358947754, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.001285943784750998}, {"id": 330, "seek": 169060, "start": 1690.6, "end": 1694.52, "text": " which is two tracks.", "tokens": [597, 307, 732, 10218, 13], "temperature": 0.0, "avg_logprob": -0.1379177220662435, "compression_ratio": 1.6024844720496894, "no_speech_prob": 0.0032253440003842115}, {"id": 331, "seek": 169060, "start": 1694.52, "end": 1700.9199999999998, "text": " Generate a useful vector representation for a video, and also try to find a reference", "tokens": [15409, 473, 257, 4420, 8062, 10290, 337, 257, 960, 11, 293, 611, 853, 281, 915, 257, 6408], "temperature": 0.0, "avg_logprob": -0.1379177220662435, "compression_ratio": 1.6024844720496894, "no_speech_prob": 0.0032253440003842115}, {"id": 332, "seek": 169060, "start": 1700.9199999999998, "end": 1706.4399999999998, "text": " video into this very big corpus, and you don't have to only find a video.", "tokens": [960, 666, 341, 588, 955, 1181, 31624, 11, 293, 291, 500, 380, 362, 281, 787, 915, 257, 960, 13], "temperature": 0.0, "avg_logprob": -0.1379177220662435, "compression_ratio": 1.6024844720496894, "no_speech_prob": 0.0032253440003842115}, {"id": 333, "seek": 169060, "start": 1706.4399999999998, "end": 1716.1999999999998, "text": " You have to find a clip, so a sub-portion of a video, into a very big corpus.", "tokens": [509, 362, 281, 915, 257, 7353, 11, 370, 257, 1422, 12, 2707, 313, 295, 257, 960, 11, 666, 257, 588, 955, 1181, 31624, 13], "temperature": 0.0, "avg_logprob": -0.1379177220662435, "compression_ratio": 1.6024844720496894, "no_speech_prob": 0.0032253440003842115}, {"id": 334, "seek": 171620, "start": 1716.2, "end": 1723.44, "text": " And last but not least, since the last part of a donor is the tastier one, we have your", "tokens": [400, 1036, 457, 406, 1935, 11, 1670, 264, 1036, 644, 295, 257, 25493, 307, 264, 2700, 811, 472, 11, 321, 362, 428], "temperature": 0.0, "avg_logprob": -0.19323091728742733, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.003008082276210189}, {"id": 335, "seek": 171620, "start": 1723.44, "end": 1729.48, "text": " turnkey open-source solution that you can install in your own premise.", "tokens": [1261, 4119, 1269, 12, 41676, 3827, 300, 291, 393, 3625, 294, 428, 1065, 22045, 13], "temperature": 0.0, "avg_logprob": -0.19323091728742733, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.003008082276210189}, {"id": 336, "seek": 171620, "start": 1729.48, "end": 1731.64, "text": " The hushier matcher actioner.", "tokens": [440, 276, 1498, 811, 2995, 260, 3069, 260, 13], "temperature": 0.0, "avg_logprob": -0.19323091728742733, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.003008082276210189}, {"id": 337, "seek": 171620, "start": 1731.64, "end": 1737.68, "text": " HMA is an open-source turnkey safety solution.", "tokens": [389, 9998, 307, 364, 1269, 12, 41676, 1261, 4119, 4514, 3827, 13], "temperature": 0.0, "avg_logprob": -0.19323091728742733, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.003008082276210189}, {"id": 338, "seek": 171620, "start": 1737.68, "end": 1743.48, "text": " So you just download it, install it, and it starts working right away.", "tokens": [407, 291, 445, 5484, 309, 11, 3625, 309, 11, 293, 309, 3719, 1364, 558, 1314, 13], "temperature": 0.0, "avg_logprob": -0.19323091728742733, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.003008082276210189}, {"id": 339, "seek": 174348, "start": 1743.48, "end": 1749.88, "text": " What it does is that it scans the images that you want to push towards it.", "tokens": [708, 309, 775, 307, 300, 309, 35116, 264, 5267, 300, 291, 528, 281, 2944, 3030, 309, 13], "temperature": 0.0, "avg_logprob": -0.1512878735860189, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0030474658124148846}, {"id": 340, "seek": 174348, "start": 1749.88, "end": 1756.32, "text": " It has an index that is updated with all the hashes coming from thread exchange, but also", "tokens": [467, 575, 364, 8186, 300, 307, 10588, 365, 439, 264, 575, 8076, 1348, 490, 7207, 7742, 11, 457, 611], "temperature": 0.0, "avg_logprob": -0.1512878735860189, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0030474658124148846}, {"id": 341, "seek": 174348, "start": 1756.32, "end": 1766.16, "text": " from yours, and is able to, say, to bind banks' verticals of violations.", "tokens": [490, 6342, 11, 293, 307, 1075, 281, 11, 584, 11, 281, 14786, 10237, 6, 9429, 82, 295, 30405, 13], "temperature": 0.0, "avg_logprob": -0.1512878735860189, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0030474658124148846}, {"id": 342, "seek": 174348, "start": 1766.16, "end": 1770.32, "text": " You might have a non-severe violation or very severe violation, and you might decide that", "tokens": [509, 1062, 362, 257, 2107, 12, 405, 5887, 22840, 420, 588, 8922, 22840, 11, 293, 291, 1062, 4536, 300], "temperature": 0.0, "avg_logprob": -0.1512878735860189, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0030474658124148846}, {"id": 343, "seek": 177032, "start": 1770.32, "end": 1775.9199999999998, "text": " for non-severe violation, you just delete the content and send a warning, or for high-severity", "tokens": [337, 2107, 12, 405, 5887, 22840, 11, 291, 445, 12097, 264, 2701, 293, 2845, 257, 9164, 11, 420, 337, 1090, 12, 405, 331, 507], "temperature": 0.0, "avg_logprob": -0.17716598510742188, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.002254311228170991}, {"id": 344, "seek": 177032, "start": 1775.9199999999998, "end": 1782.4399999999998, "text": " violation, you just immediately delete the content, shut down the account of the poster,", "tokens": [22840, 11, 291, 445, 4258, 12097, 264, 2701, 11, 5309, 760, 264, 2696, 295, 264, 17171, 11], "temperature": 0.0, "avg_logprob": -0.17716598510742188, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.002254311228170991}, {"id": 345, "seek": 177032, "start": 1782.4399999999998, "end": 1785.9199999999998, "text": " and you also signal it to the law enforcement.", "tokens": [293, 291, 611, 6358, 309, 281, 264, 2101, 11475, 13], "temperature": 0.0, "avg_logprob": -0.17716598510742188, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.002254311228170991}, {"id": 346, "seek": 177032, "start": 1785.9199999999998, "end": 1787.9199999999998, "text": " You can do that.", "tokens": [509, 393, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.17716598510742188, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.002254311228170991}, {"id": 347, "seek": 177032, "start": 1787.9199999999998, "end": 1793.6399999999999, "text": " And you can configure actions in a backend that are tied to the content that you want", "tokens": [400, 291, 393, 22162, 5909, 294, 257, 38087, 300, 366, 9601, 281, 264, 2701, 300, 291, 528], "temperature": 0.0, "avg_logprob": -0.17716598510742188, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.002254311228170991}, {"id": 348, "seek": 177032, "start": 1793.6399999999999, "end": 1798.3999999999999, "text": " to bank into your HMA platform.", "tokens": [281, 3765, 666, 428, 389, 9998, 3663, 13], "temperature": 0.0, "avg_logprob": -0.17716598510742188, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.002254311228170991}, {"id": 349, "seek": 179840, "start": 1798.4, "end": 1803.44, "text": " You can pull violating seeds from Facebook thread exchange API, and works on AWS only,", "tokens": [509, 393, 2235, 42201, 9203, 490, 4384, 7207, 7742, 9362, 11, 293, 1985, 322, 17650, 787, 11], "temperature": 0.0, "avg_logprob": -0.23141352335611978, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.0019908116664737463}, {"id": 350, "seek": 179840, "start": 1803.44, "end": 1812.24, "text": " because we wanted to make a very easy-to-use thing, and also something that doesn't really", "tokens": [570, 321, 1415, 281, 652, 257, 588, 1858, 12, 1353, 12, 438, 551, 11, 293, 611, 746, 300, 1177, 380, 534], "temperature": 0.0, "avg_logprob": -0.23141352335611978, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.0019908116664737463}, {"id": 351, "seek": 179840, "start": 1812.24, "end": 1813.76, "text": " mix your bill higher.", "tokens": [2890, 428, 2961, 2946, 13], "temperature": 0.0, "avg_logprob": -0.23141352335611978, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.0019908116664737463}, {"id": 352, "seek": 179840, "start": 1813.76, "end": 1817.6000000000001, "text": " So we built it on AWS Lambda.", "tokens": [407, 321, 3094, 309, 322, 17650, 45691, 13], "temperature": 0.0, "avg_logprob": -0.23141352335611978, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.0019908116664737463}, {"id": 353, "seek": 179840, "start": 1817.6000000000001, "end": 1822.16, "text": " So it doesn't cost anything until it runs, then it runs, spawns a Lambda instance, and", "tokens": [407, 309, 1177, 380, 2063, 1340, 1826, 309, 6676, 11, 550, 309, 6676, 11, 17088, 82, 257, 45691, 5197, 11, 293], "temperature": 0.0, "avg_logprob": -0.23141352335611978, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.0019908116664737463}, {"id": 354, "seek": 179840, "start": 1822.16, "end": 1827.2, "text": " then goes down, and you only pay for the seconds that it actually runs.", "tokens": [550, 1709, 760, 11, 293, 291, 787, 1689, 337, 264, 3949, 300, 309, 767, 6676, 13], "temperature": 0.0, "avg_logprob": -0.23141352335611978, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.0019908116664737463}, {"id": 355, "seek": 182720, "start": 1827.2, "end": 1828.72, "text": " But it's very fast.", "tokens": [583, 309, 311, 588, 2370, 13], "temperature": 0.0, "avg_logprob": -0.17746861106471012, "compression_ratio": 1.491869918699187, "no_speech_prob": 0.000318337872158736}, {"id": 356, "seek": 182720, "start": 1828.72, "end": 1833.48, "text": " And there's a Terraform module available thanks to the lovely folks of the Internet Safety", "tokens": [400, 456, 311, 257, 25366, 837, 10088, 2435, 3231, 281, 264, 7496, 4024, 295, 264, 7703, 21340], "temperature": 0.0, "avg_logprob": -0.17746861106471012, "compression_ratio": 1.491869918699187, "no_speech_prob": 0.000318337872158736}, {"id": 357, "seek": 182720, "start": 1833.48, "end": 1834.48, "text": " Engineering.", "tokens": [16215, 13], "temperature": 0.0, "avg_logprob": -0.17746861106471012, "compression_ratio": 1.491869918699187, "no_speech_prob": 0.000318337872158736}, {"id": 358, "seek": 182720, "start": 1834.48, "end": 1837.52, "text": " This is how you deploy that.", "tokens": [639, 307, 577, 291, 7274, 300, 13], "temperature": 0.0, "avg_logprob": -0.17746861106471012, "compression_ratio": 1.491869918699187, "no_speech_prob": 0.000318337872158736}, {"id": 359, "seek": 182720, "start": 1837.52, "end": 1843.32, "text": " Your infra, you collocate HMA to your platform.", "tokens": [2260, 23654, 11, 291, 1263, 42869, 389, 9998, 281, 428, 3663, 13], "temperature": 0.0, "avg_logprob": -0.17746861106471012, "compression_ratio": 1.491869918699187, "no_speech_prob": 0.000318337872158736}, {"id": 360, "seek": 182720, "start": 1843.32, "end": 1849.24, "text": " For example, you might own a platform where people have a chat or people post pictures.", "tokens": [1171, 1365, 11, 291, 1062, 1065, 257, 3663, 689, 561, 362, 257, 5081, 420, 561, 2183, 5242, 13], "temperature": 0.0, "avg_logprob": -0.17746861106471012, "compression_ratio": 1.491869918699187, "no_speech_prob": 0.000318337872158736}, {"id": 361, "seek": 182720, "start": 1849.24, "end": 1855.16, "text": " Whenever new content comes, the web server asks the Azure, have you seen this?", "tokens": [14159, 777, 2701, 1487, 11, 264, 3670, 7154, 8962, 264, 11969, 11, 362, 291, 1612, 341, 30], "temperature": 0.0, "avg_logprob": -0.17746861106471012, "compression_ratio": 1.491869918699187, "no_speech_prob": 0.000318337872158736}, {"id": 362, "seek": 185516, "start": 1855.16, "end": 1857.44, "text": " And the Azure goes to Matcher.", "tokens": [400, 264, 11969, 1709, 281, 26178, 260, 13], "temperature": 0.0, "avg_logprob": -0.20873052933636835, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000233848812058568}, {"id": 363, "seek": 185516, "start": 1857.44, "end": 1861.0, "text": " Matcher goes to the index and says, do I know this?", "tokens": [26178, 260, 1709, 281, 264, 8186, 293, 1619, 11, 360, 286, 458, 341, 30], "temperature": 0.0, "avg_logprob": -0.20873052933636835, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000233848812058568}, {"id": 364, "seek": 185516, "start": 1861.0, "end": 1869.2, "text": " And in case there's a match, the actioner module will just tell your, you have to define", "tokens": [400, 294, 1389, 456, 311, 257, 2995, 11, 264, 3069, 260, 10088, 486, 445, 980, 428, 11, 291, 362, 281, 6964], "temperature": 0.0, "avg_logprob": -0.20873052933636835, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000233848812058568}, {"id": 365, "seek": 185516, "start": 1869.2, "end": 1874.88, "text": " a callback API in your own platform, like whenever the actioner calls, you are killing", "tokens": [257, 818, 3207, 9362, 294, 428, 1065, 3663, 11, 411, 5699, 264, 3069, 260, 5498, 11, 291, 366, 8011], "temperature": 0.0, "avg_logprob": -0.20873052933636835, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000233848812058568}, {"id": 366, "seek": 185516, "start": 1874.88, "end": 1877.16, "text": " this content in your own backend.", "tokens": [341, 2701, 294, 428, 1065, 38087, 13], "temperature": 0.0, "avg_logprob": -0.20873052933636835, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000233848812058568}, {"id": 367, "seek": 185516, "start": 1877.16, "end": 1884.3600000000001, "text": " And, of course, you can fetch from external API new content from the fact exchange platform.", "tokens": [400, 11, 295, 1164, 11, 291, 393, 23673, 490, 8320, 9362, 777, 2701, 490, 264, 1186, 7742, 3663, 13], "temperature": 0.0, "avg_logprob": -0.20873052933636835, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000233848812058568}, {"id": 368, "seek": 188436, "start": 1884.36, "end": 1890.1599999999999, "text": " So wrapping up, automation is necessary to be effective.", "tokens": [407, 21993, 493, 11, 17769, 307, 4818, 281, 312, 4942, 13], "temperature": 0.0, "avg_logprob": -0.14741148107192095, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.0016379946609959006}, {"id": 369, "seek": 188436, "start": 1890.1599999999999, "end": 1895.3999999999999, "text": " But you will lose precision, of course, because automation doesn't really think.", "tokens": [583, 291, 486, 3624, 18356, 11, 295, 1164, 11, 570, 17769, 1177, 380, 534, 519, 13], "temperature": 0.0, "avg_logprob": -0.14741148107192095, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.0016379946609959006}, {"id": 370, "seek": 188436, "start": 1895.3999999999999, "end": 1898.9199999999998, "text": " It just does whatever you have configured blindly.", "tokens": [467, 445, 775, 2035, 291, 362, 30538, 47744, 13], "temperature": 0.0, "avg_logprob": -0.14741148107192095, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.0016379946609959006}, {"id": 371, "seek": 188436, "start": 1898.9199999999998, "end": 1904.3999999999999, "text": " Human support is always needed for appeals and also to establish the ground through.", "tokens": [10294, 1406, 307, 1009, 2978, 337, 32603, 293, 611, 281, 8327, 264, 2727, 807, 13], "temperature": 0.0, "avg_logprob": -0.14741148107192095, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.0016379946609959006}, {"id": 372, "seek": 188436, "start": 1904.3999999999999, "end": 1907.52, "text": " So what is actually violating, what is not?", "tokens": [407, 437, 307, 767, 42201, 11, 437, 307, 406, 30], "temperature": 0.0, "avg_logprob": -0.14741148107192095, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.0016379946609959006}, {"id": 373, "seek": 188436, "start": 1907.52, "end": 1912.36, "text": " Do expect false positive, because they will happen.", "tokens": [1144, 2066, 7908, 3353, 11, 570, 436, 486, 1051, 13], "temperature": 0.0, "avg_logprob": -0.14741148107192095, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.0016379946609959006}, {"id": 374, "seek": 191236, "start": 1912.36, "end": 1918.9199999999998, "text": " You should put in place an appeal process to allow your users to restore the content.", "tokens": [509, 820, 829, 294, 1081, 364, 13668, 1399, 281, 2089, 428, 5022, 281, 15227, 264, 2701, 13], "temperature": 0.0, "avg_logprob": -0.22813736637936363, "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.0013598413206636906}, {"id": 375, "seek": 191236, "start": 1918.9199999999998, "end": 1926.4799999999998, "text": " PDQ, video PDQ, MT5 and SSCD will provide you with a way to obtain compact representation", "tokens": [10464, 48, 11, 960, 10464, 48, 11, 37333, 20, 293, 12238, 16508, 486, 2893, 291, 365, 257, 636, 281, 12701, 14679, 10290], "temperature": 0.0, "avg_logprob": -0.22813736637936363, "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.0013598413206636906}, {"id": 376, "seek": 191236, "start": 1926.4799999999998, "end": 1931.4399999999998, "text": " of high dimensionality content like pictures and videos.", "tokens": [295, 1090, 10139, 1860, 2701, 411, 5242, 293, 2145, 13], "temperature": 0.0, "avg_logprob": -0.22813736637936363, "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.0013598413206636906}, {"id": 377, "seek": 191236, "start": 1931.4399999999998, "end": 1937.6399999999999, "text": " HMA provides you with a turnkey solution that you can install on premise, on your premise,", "tokens": [389, 9998, 6417, 291, 365, 257, 1261, 4119, 3827, 300, 291, 393, 3625, 322, 22045, 11, 322, 428, 22045, 11], "temperature": 0.0, "avg_logprob": -0.22813736637936363, "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.0013598413206636906}, {"id": 378, "seek": 193764, "start": 1937.64, "end": 1944.2800000000002, "text": " and search and enforce your integrity policies at your platform.", "tokens": [293, 3164, 293, 24825, 428, 16000, 7657, 412, 428, 3663, 13], "temperature": 0.0, "avg_logprob": -0.2719535514956615, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0002531487261876464}, {"id": 379, "seek": 193764, "start": 1944.2800000000002, "end": 1949.48, "text": " And thread exchange provides you with a platform for exchanging representation with other big", "tokens": [400, 7207, 7742, 6417, 291, 365, 257, 3663, 337, 6210, 9741, 10290, 365, 661, 955], "temperature": 0.0, "avg_logprob": -0.2719535514956615, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0002531487261876464}, {"id": 380, "seek": 193764, "start": 1949.48, "end": 1954.72, "text": " actors like, maybe, itself, for example.", "tokens": [10037, 411, 11, 1310, 11, 2564, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.2719535514956615, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0002531487261876464}, {"id": 381, "seek": 193764, "start": 1954.72, "end": 1955.72, "text": " That was all from me.", "tokens": [663, 390, 439, 490, 385, 13], "temperature": 0.0, "avg_logprob": -0.2719535514956615, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0002531487261876464}, {"id": 382, "seek": 193764, "start": 1955.72, "end": 1966.16, "text": " Thank you very much for listening.", "tokens": [1044, 291, 588, 709, 337, 4764, 13], "temperature": 0.0, "avg_logprob": -0.2719535514956615, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0002531487261876464}, {"id": 383, "seek": 196616, "start": 1966.16, "end": 1975.1200000000001, "text": " Any questions?", "tokens": [2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.34890502293904624, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.011347710154950619}, {"id": 384, "seek": 196616, "start": 1975.1200000000001, "end": 1978.16, "text": " You mentioned it for the challenge, I think?", "tokens": [509, 2835, 309, 337, 264, 3430, 11, 286, 519, 30], "temperature": 0.0, "avg_logprob": -0.34890502293904624, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.011347710154950619}, {"id": 385, "seek": 196616, "start": 1978.16, "end": 1980.4, "text": " Oh, louder.", "tokens": [876, 11, 22717, 13], "temperature": 0.0, "avg_logprob": -0.34890502293904624, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.011347710154950619}, {"id": 386, "seek": 196616, "start": 1980.4, "end": 1985.28, "text": " So you mentioned it for the challenge, finding a clip of a video.", "tokens": [407, 291, 2835, 309, 337, 264, 3430, 11, 5006, 257, 7353, 295, 257, 960, 13], "temperature": 0.0, "avg_logprob": -0.34890502293904624, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.011347710154950619}, {"id": 387, "seek": 196616, "start": 1985.28, "end": 1988.64, "text": " Can PDQ do that, actually?", "tokens": [1664, 10464, 48, 360, 300, 11, 767, 30], "temperature": 0.0, "avg_logprob": -0.34890502293904624, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.011347710154950619}, {"id": 388, "seek": 196616, "start": 1988.64, "end": 1991.2, "text": " You can't hear me.", "tokens": [509, 393, 380, 1568, 385, 13], "temperature": 0.0, "avg_logprob": -0.34890502293904624, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.011347710154950619}, {"id": 389, "seek": 199120, "start": 1991.2, "end": 1999.24, "text": " So can PDQ find clips of videos?", "tokens": [407, 393, 10464, 48, 915, 13117, 295, 2145, 30], "temperature": 0.0, "avg_logprob": -0.32223467991269866, "compression_ratio": 1.3419354838709678, "no_speech_prob": 0.009141569957137108}, {"id": 390, "seek": 199120, "start": 1999.24, "end": 2000.8400000000001, "text": " That's my question, actually.", "tokens": [663, 311, 452, 1168, 11, 767, 13], "temperature": 0.0, "avg_logprob": -0.32223467991269866, "compression_ratio": 1.3419354838709678, "no_speech_prob": 0.009141569957137108}, {"id": 391, "seek": 199120, "start": 2000.8400000000001, "end": 2009.44, "text": " So you should, you say, perhaps I heard about YouTube, what is something that already does.", "tokens": [407, 291, 820, 11, 291, 584, 11, 4317, 286, 2198, 466, 3088, 11, 437, 307, 746, 300, 1217, 775, 13], "temperature": 0.0, "avg_logprob": -0.32223467991269866, "compression_ratio": 1.3419354838709678, "no_speech_prob": 0.009141569957137108}, {"id": 392, "seek": 199120, "start": 2009.44, "end": 2015.3600000000001, "text": " Like if the challenge is to find the clips of videos.", "tokens": [1743, 498, 264, 3430, 307, 281, 915, 264, 13117, 295, 2145, 13], "temperature": 0.0, "avg_logprob": -0.32223467991269866, "compression_ratio": 1.3419354838709678, "no_speech_prob": 0.009141569957137108}, {"id": 393, "seek": 201536, "start": 2015.36, "end": 2026.04, "text": " Yeah, in general, it's possible, of course, and the video PDQ algorithms will ask every", "tokens": [865, 11, 294, 2674, 11, 309, 311, 1944, 11, 295, 1164, 11, 293, 264, 960, 10464, 48, 14642, 486, 1029, 633], "temperature": 0.0, "avg_logprob": -0.17920587327745224, "compression_ratio": 1.5865384615384615, "no_speech_prob": 0.0053111482411623}, {"id": 394, "seek": 201536, "start": 2026.04, "end": 2027.04, "text": " frame.", "tokens": [3920, 13], "temperature": 0.0, "avg_logprob": -0.17920587327745224, "compression_ratio": 1.5865384615384615, "no_speech_prob": 0.0053111482411623}, {"id": 395, "seek": 201536, "start": 2027.04, "end": 2034.52, "text": " So in case you send a very small sub portion of a video, you will have, like, 100 frames,", "tokens": [407, 294, 1389, 291, 2845, 257, 588, 1359, 1422, 8044, 295, 257, 960, 11, 291, 486, 362, 11, 411, 11, 2319, 12083, 11], "temperature": 0.0, "avg_logprob": -0.17920587327745224, "compression_ratio": 1.5865384615384615, "no_speech_prob": 0.0053111482411623}, {"id": 396, "seek": 201536, "start": 2034.52, "end": 2038.56, "text": " for example, then these 100 frames will be treated as a bag of words.", "tokens": [337, 1365, 11, 550, 613, 2319, 12083, 486, 312, 8668, 382, 257, 3411, 295, 2283, 13], "temperature": 0.0, "avg_logprob": -0.17920587327745224, "compression_ratio": 1.5865384615384615, "no_speech_prob": 0.0053111482411623}, {"id": 397, "seek": 201536, "start": 2038.56, "end": 2043.8799999999999, "text": " You search the index, you find the video that contained all of these words.", "tokens": [509, 3164, 264, 8186, 11, 291, 915, 264, 960, 300, 16212, 439, 295, 613, 2283, 13], "temperature": 0.0, "avg_logprob": -0.17920587327745224, "compression_ratio": 1.5865384615384615, "no_speech_prob": 0.0053111482411623}, {"id": 398, "seek": 204388, "start": 2043.88, "end": 2050.84, "text": " So you have a match of all your query frames inside the index at the very long video that", "tokens": [407, 291, 362, 257, 2995, 295, 439, 428, 14581, 12083, 1854, 264, 8186, 412, 264, 588, 938, 960, 300], "temperature": 0.0, "avg_logprob": -0.21778891358194472, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.0036502957809716463}, {"id": 399, "seek": 204388, "start": 2050.84, "end": 2051.84, "text": " has it.", "tokens": [575, 309, 13], "temperature": 0.0, "avg_logprob": -0.21778891358194472, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.0036502957809716463}, {"id": 400, "seek": 204388, "start": 2051.84, "end": 2053.7200000000003, "text": " And so it's a match.", "tokens": [400, 370, 309, 311, 257, 2995, 13], "temperature": 0.0, "avg_logprob": -0.21778891358194472, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.0036502957809716463}, {"id": 401, "seek": 204388, "start": 2053.7200000000003, "end": 2054.7200000000003, "text": " That's how we do.", "tokens": [663, 311, 577, 321, 360, 13], "temperature": 0.0, "avg_logprob": -0.21778891358194472, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.0036502957809716463}, {"id": 402, "seek": 204388, "start": 2054.7200000000003, "end": 2058.7200000000003, "text": " Of course, there are more clever ways to do that.", "tokens": [2720, 1164, 11, 456, 366, 544, 13494, 2098, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.21778891358194472, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.0036502957809716463}, {"id": 403, "seek": 204388, "start": 2058.7200000000003, "end": 2059.7200000000003, "text": " Thanks.", "tokens": [2561, 13], "temperature": 0.0, "avg_logprob": -0.21778891358194472, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.0036502957809716463}, {"id": 404, "seek": 204388, "start": 2059.7200000000003, "end": 2060.7200000000003, "text": " Hello.", "tokens": [2425, 13], "temperature": 0.0, "avg_logprob": -0.21778891358194472, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.0036502957809716463}, {"id": 405, "seek": 204388, "start": 2060.7200000000003, "end": 2068.12, "text": " Not a technical question, but let's see.", "tokens": [1726, 257, 6191, 1168, 11, 457, 718, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.21778891358194472, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.0036502957809716463}, {"id": 406, "seek": 206812, "start": 2068.12, "end": 2075.68, "text": " I was thinking that if you're using such a system to try to prevent digital crimes and", "tokens": [286, 390, 1953, 300, 498, 291, 434, 1228, 1270, 257, 1185, 281, 853, 281, 4871, 4562, 13916, 293], "temperature": 0.0, "avg_logprob": -0.1722686073996804, "compression_ratio": 1.5431472081218274, "no_speech_prob": 0.01218660082668066}, {"id": 407, "seek": 206812, "start": 2075.68, "end": 2083.64, "text": " such things like that, from an ethical perspective, I was just wondering that you, I suppose you", "tokens": [1270, 721, 411, 300, 11, 490, 364, 18890, 4585, 11, 286, 390, 445, 6359, 300, 291, 11, 286, 7297, 291], "temperature": 0.0, "avg_logprob": -0.1722686073996804, "compression_ratio": 1.5431472081218274, "no_speech_prob": 0.01218660082668066}, {"id": 408, "seek": 206812, "start": 2083.64, "end": 2087.64, "text": " have such images to compare them.", "tokens": [362, 1270, 5267, 281, 6794, 552, 13], "temperature": 0.0, "avg_logprob": -0.1722686073996804, "compression_ratio": 1.5431472081218274, "no_speech_prob": 0.01218660082668066}, {"id": 409, "seek": 206812, "start": 2087.64, "end": 2093.12, "text": " And how do you process those, how do you make the decisions?", "tokens": [400, 577, 360, 291, 1399, 729, 11, 577, 360, 291, 652, 264, 5327, 30], "temperature": 0.0, "avg_logprob": -0.1722686073996804, "compression_ratio": 1.5431472081218274, "no_speech_prob": 0.01218660082668066}, {"id": 410, "seek": 206812, "start": 2093.12, "end": 2097.48, "text": " So I repeat the question.", "tokens": [407, 286, 7149, 264, 1168, 13], "temperature": 0.0, "avg_logprob": -0.1722686073996804, "compression_ratio": 1.5431472081218274, "no_speech_prob": 0.01218660082668066}, {"id": 411, "seek": 209748, "start": 2097.48, "end": 2102.36, "text": " From the ethical perspective, the idea is that, of course, we have to see the images", "tokens": [3358, 264, 18890, 4585, 11, 264, 1558, 307, 300, 11, 295, 1164, 11, 321, 362, 281, 536, 264, 5267], "temperature": 0.0, "avg_logprob": -0.16204012433687845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004269662778824568}, {"id": 412, "seek": 209748, "start": 2102.36, "end": 2106.0, "text": " in order to be able to know what's happening, right?", "tokens": [294, 1668, 281, 312, 1075, 281, 458, 437, 311, 2737, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.16204012433687845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004269662778824568}, {"id": 413, "seek": 209748, "start": 2106.0, "end": 2112.4, "text": " Yeah, see and, of course, you have to save them and, I don't know, process them and how", "tokens": [865, 11, 536, 293, 11, 295, 1164, 11, 291, 362, 281, 3155, 552, 293, 11, 286, 500, 380, 458, 11, 1399, 552, 293, 577], "temperature": 0.0, "avg_logprob": -0.16204012433687845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004269662778824568}, {"id": 414, "seek": 209748, "start": 2112.4, "end": 2114.56, "text": " do you handle this?", "tokens": [360, 291, 4813, 341, 30], "temperature": 0.0, "avg_logprob": -0.16204012433687845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004269662778824568}, {"id": 415, "seek": 209748, "start": 2114.56, "end": 2120.0, "text": " So this is not the kind of question that I really can answer because it is related to", "tokens": [407, 341, 307, 406, 264, 733, 295, 1168, 300, 286, 534, 393, 1867, 570, 309, 307, 4077, 281], "temperature": 0.0, "avg_logprob": -0.16204012433687845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004269662778824568}, {"id": 416, "seek": 209748, "start": 2120.0, "end": 2122.48, "text": " internal procedures.", "tokens": [6920, 13846, 13], "temperature": 0.0, "avg_logprob": -0.16204012433687845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004269662778824568}, {"id": 417, "seek": 212248, "start": 2122.48, "end": 2130.12, "text": " Now, if we have to compute the fingerprint of an image, there must be a one second in", "tokens": [823, 11, 498, 321, 362, 281, 14722, 264, 30715, 295, 364, 3256, 11, 456, 1633, 312, 257, 472, 1150, 294], "temperature": 0.0, "avg_logprob": -0.19442646320049578, "compression_ratio": 1.5467289719626167, "no_speech_prob": 0.001436891034245491}, {"id": 418, "seek": 212248, "start": 2130.12, "end": 2134.28, "text": " which the image is on our surface.", "tokens": [597, 264, 3256, 307, 322, 527, 3753, 13], "temperature": 0.0, "avg_logprob": -0.19442646320049578, "compression_ratio": 1.5467289719626167, "no_speech_prob": 0.001436891034245491}, {"id": 419, "seek": 212248, "start": 2134.28, "end": 2141.68, "text": " It is, since the agency is like NECMAC, they share ashes.", "tokens": [467, 307, 11, 1670, 264, 7934, 307, 411, 426, 8140, 44, 4378, 11, 436, 2073, 32942, 13], "temperature": 0.0, "avg_logprob": -0.19442646320049578, "compression_ratio": 1.5467289719626167, "no_speech_prob": 0.001436891034245491}, {"id": 420, "seek": 212248, "start": 2141.68, "end": 2145.44, "text": " So you might have an ash for which you don't have a picture.", "tokens": [407, 291, 1062, 362, 364, 12588, 337, 597, 291, 500, 380, 362, 257, 3036, 13], "temperature": 0.0, "avg_logprob": -0.19442646320049578, "compression_ratio": 1.5467289719626167, "no_speech_prob": 0.001436891034245491}, {"id": 421, "seek": 212248, "start": 2145.44, "end": 2150.8, "text": " And you have to trust that this ash is coming from a trusted source that has already vetted", "tokens": [400, 291, 362, 281, 3361, 300, 341, 12588, 307, 1348, 490, 257, 16034, 4009, 300, 575, 1217, 371, 46508], "temperature": 0.0, "avg_logprob": -0.19442646320049578, "compression_ratio": 1.5467289719626167, "no_speech_prob": 0.001436891034245491}, {"id": 422, "seek": 215080, "start": 2150.8, "end": 2154.5600000000004, "text": " whether this ash is nasty stuff or not.", "tokens": [1968, 341, 12588, 307, 17923, 1507, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.12731119860773502, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0017134187510237098}, {"id": 423, "seek": 215080, "start": 2154.5600000000004, "end": 2161.4, "text": " That's how we actually avoid sanctioning heavily innocent people.", "tokens": [663, 311, 577, 321, 767, 5042, 39830, 278, 10950, 13171, 561, 13], "temperature": 0.0, "avg_logprob": -0.12731119860773502, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0017134187510237098}, {"id": 424, "seek": 215080, "start": 2161.4, "end": 2165.6000000000004, "text": " So there is a collaboration with the trusted entities for this.", "tokens": [407, 456, 307, 257, 9363, 365, 264, 16034, 16667, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.12731119860773502, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0017134187510237098}, {"id": 425, "seek": 215080, "start": 2165.6000000000004, "end": 2170.6000000000004, "text": " When you receive those from an external agent, if those images are on your platform, you", "tokens": [1133, 291, 4774, 729, 490, 364, 8320, 9461, 11, 498, 729, 5267, 366, 322, 428, 3663, 11, 291], "temperature": 0.0, "avg_logprob": -0.12731119860773502, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0017134187510237098}, {"id": 426, "seek": 215080, "start": 2170.6000000000004, "end": 2174.5600000000004, "text": " already know what you've seen.", "tokens": [1217, 458, 437, 291, 600, 1612, 13], "temperature": 0.0, "avg_logprob": -0.12731119860773502, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0017134187510237098}, {"id": 427, "seek": 215080, "start": 2174.5600000000004, "end": 2176.2000000000003, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.12731119860773502, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0017134187510237098}, {"id": 428, "seek": 215080, "start": 2176.2000000000003, "end": 2179.1200000000003, "text": " Can you hear me despite the mask?", "tokens": [1664, 291, 1568, 385, 7228, 264, 6094, 30], "temperature": 0.0, "avg_logprob": -0.12731119860773502, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0017134187510237098}, {"id": 429, "seek": 215080, "start": 2179.1200000000003, "end": 2180.1200000000003, "text": " Can you hear me?", "tokens": [1664, 291, 1568, 385, 30], "temperature": 0.0, "avg_logprob": -0.12731119860773502, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0017134187510237098}, {"id": 430, "seek": 218012, "start": 2180.12, "end": 2182.24, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.17635679244995117, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0011460694950073957}, {"id": 431, "seek": 218012, "start": 2182.24, "end": 2186.92, "text": " So I have a question, but first I have a thanks because I have worked in this kind of thing", "tokens": [407, 286, 362, 257, 1168, 11, 457, 700, 286, 362, 257, 3231, 570, 286, 362, 2732, 294, 341, 733, 295, 551], "temperature": 0.0, "avg_logprob": -0.17635679244995117, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0011460694950073957}, {"id": 432, "seek": 218012, "start": 2186.92, "end": 2196.96, "text": " and NECMAC doesn't share any useful data, IWF doesn't share any useful data, Farros doesn't", "tokens": [293, 426, 8140, 44, 4378, 1177, 380, 2073, 604, 4420, 1412, 11, 286, 54, 37, 1177, 380, 2073, 604, 4420, 1412, 11, 479, 2284, 329, 1177, 380], "temperature": 0.0, "avg_logprob": -0.17635679244995117, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0011460694950073957}, {"id": 433, "seek": 218012, "start": 2196.96, "end": 2198.96, "text": " share any useful data.", "tokens": [2073, 604, 4420, 1412, 13], "temperature": 0.0, "avg_logprob": -0.17635679244995117, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0011460694950073957}, {"id": 434, "seek": 218012, "start": 2198.96, "end": 2202.92, "text": " So I will definitely take a look at the threat exchange platform and hope that it's much", "tokens": [407, 286, 486, 2138, 747, 257, 574, 412, 264, 4734, 7742, 3663, 293, 1454, 300, 309, 311, 709], "temperature": 0.0, "avg_logprob": -0.17635679244995117, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0011460694950073957}, {"id": 435, "seek": 218012, "start": 2202.92, "end": 2204.2799999999997, "text": " more useful.", "tokens": [544, 4420, 13], "temperature": 0.0, "avg_logprob": -0.17635679244995117, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0011460694950073957}, {"id": 436, "seek": 218012, "start": 2204.2799999999997, "end": 2205.44, "text": " And thanks for that.", "tokens": [400, 3231, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.17635679244995117, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0011460694950073957}, {"id": 437, "seek": 218012, "start": 2205.44, "end": 2209.48, "text": " No, I have a question anyway.", "tokens": [883, 11, 286, 362, 257, 1168, 4033, 13], "temperature": 0.0, "avg_logprob": -0.17635679244995117, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0011460694950073957}, {"id": 438, "seek": 220948, "start": 2209.48, "end": 2216.6, "text": " If I was an attacker, I could download data from the threat exchange platform and try", "tokens": [759, 286, 390, 364, 35871, 11, 286, 727, 5484, 1412, 490, 264, 4734, 7742, 3663, 293, 853], "temperature": 0.0, "avg_logprob": -0.22291717075166248, "compression_ratio": 1.4511627906976745, "no_speech_prob": 0.004281485453248024}, {"id": 439, "seek": 220948, "start": 2216.6, "end": 2223.4, "text": " and run as many filters automatically until I find something that is not matched by PDQ,", "tokens": [293, 1190, 382, 867, 15995, 6772, 1826, 286, 915, 746, 300, 307, 406, 21447, 538, 10464, 48, 11], "temperature": 0.0, "avg_logprob": -0.22291717075166248, "compression_ratio": 1.4511627906976745, "no_speech_prob": 0.004281485453248024}, {"id": 440, "seek": 220948, "start": 2223.4, "end": 2226.04, "text": " video PDQ, et cetera.", "tokens": [960, 10464, 48, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.22291717075166248, "compression_ratio": 1.4511627906976745, "no_speech_prob": 0.004281485453248024}, {"id": 441, "seek": 220948, "start": 2226.04, "end": 2227.48, "text": " What's the way to counter that?", "tokens": [708, 311, 264, 636, 281, 5682, 300, 30], "temperature": 0.0, "avg_logprob": -0.22291717075166248, "compression_ratio": 1.4511627906976745, "no_speech_prob": 0.004281485453248024}, {"id": 442, "seek": 220948, "start": 2227.48, "end": 2233.08, "text": " Oh, you're asking whether adversarial attacks are possible on PDQ?", "tokens": [876, 11, 291, 434, 3365, 1968, 17641, 44745, 8122, 366, 1944, 322, 10464, 48, 30], "temperature": 0.0, "avg_logprob": -0.22291717075166248, "compression_ratio": 1.4511627906976745, "no_speech_prob": 0.004281485453248024}, {"id": 443, "seek": 220948, "start": 2233.08, "end": 2234.76, "text": " Yeah, of course.", "tokens": [865, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.22291717075166248, "compression_ratio": 1.4511627906976745, "no_speech_prob": 0.004281485453248024}, {"id": 444, "seek": 223476, "start": 2234.76, "end": 2239.5200000000004, "text": " PDQ is a very naive algorithm that just detects the patches of colors.", "tokens": [10464, 48, 307, 257, 588, 29052, 9284, 300, 445, 5531, 82, 264, 26531, 295, 4577, 13], "temperature": 0.0, "avg_logprob": -0.11277692382400101, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.0027292403392493725}, {"id": 445, "seek": 223476, "start": 2239.5200000000004, "end": 2244.44, "text": " It is actually possible to create adversarial attacks.", "tokens": [467, 307, 767, 1944, 281, 1884, 17641, 44745, 8122, 13], "temperature": 0.0, "avg_logprob": -0.11277692382400101, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.0027292403392493725}, {"id": 446, "seek": 223476, "start": 2244.44, "end": 2254.4, "text": " Just if you think that you alter many pixels in the image and perceptually for us doesn't", "tokens": [1449, 498, 291, 519, 300, 291, 11337, 867, 18668, 294, 264, 3256, 293, 43276, 671, 337, 505, 1177, 380], "temperature": 0.0, "avg_logprob": -0.11277692382400101, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.0027292403392493725}, {"id": 447, "seek": 223476, "start": 2254.4, "end": 2263.5600000000004, "text": " change anything, but you might end up changing the most relevant pictures for the DCT algorithm.", "tokens": [1319, 1340, 11, 457, 291, 1062, 917, 493, 4473, 264, 881, 7340, 5242, 337, 264, 9114, 51, 9284, 13], "temperature": 0.0, "avg_logprob": -0.11277692382400101, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.0027292403392493725}, {"id": 448, "seek": 226356, "start": 2263.56, "end": 2271.2, "text": " I will create a completely different ashing in the end.", "tokens": [286, 486, 1884, 257, 2584, 819, 382, 571, 294, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.2044045419404001, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.0004008290998172015}, {"id": 449, "seek": 226356, "start": 2271.2, "end": 2278.24, "text": " Also someone has demonstrated an attack, a reverse engineering attack on photo DNA.", "tokens": [2743, 1580, 575, 18772, 364, 2690, 11, 257, 9943, 7043, 2690, 322, 5052, 8272, 13], "temperature": 0.0, "avg_logprob": -0.2044045419404001, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.0004008290998172015}, {"id": 450, "seek": 226356, "start": 2278.24, "end": 2285.08, "text": " Like from the project, it's called ribosome.", "tokens": [1743, 490, 264, 1716, 11, 309, 311, 1219, 9162, 329, 423, 13], "temperature": 0.0, "avg_logprob": -0.2044045419404001, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.0004008290998172015}, {"id": 451, "seek": 226356, "start": 2285.08, "end": 2293.04, "text": " And it's a neural network that from a hash reconstructs a very blurry picture.", "tokens": [400, 309, 311, 257, 18161, 3209, 300, 490, 257, 22019, 31499, 82, 257, 588, 37644, 3036, 13], "temperature": 0.0, "avg_logprob": -0.2044045419404001, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.0004008290998172015}, {"id": 452, "seek": 229304, "start": 2293.04, "end": 2301.56, "text": " So it is actually possible to do that, but PDQ is a very simple and fast algorithm.", "tokens": [407, 309, 307, 767, 1944, 281, 360, 300, 11, 457, 10464, 48, 307, 257, 588, 2199, 293, 2370, 9284, 13], "temperature": 0.0, "avg_logprob": -0.16955864164564344, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0010020543122664094}, {"id": 453, "seek": 229304, "start": 2301.56, "end": 2309.52, "text": " If you really want to combat seriously adversarial engineering, the things that you need neural", "tokens": [759, 291, 534, 528, 281, 8361, 6638, 17641, 44745, 7043, 11, 264, 721, 300, 291, 643, 18161], "temperature": 0.0, "avg_logprob": -0.16955864164564344, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0010020543122664094}, {"id": 454, "seek": 229304, "start": 2309.52, "end": 2315.92, "text": " networks like SSCD because it contains so many relations to different parts of the images", "tokens": [9590, 411, 12238, 16508, 570, 309, 8306, 370, 867, 2299, 281, 819, 3166, 295, 264, 5267], "temperature": 0.0, "avg_logprob": -0.16955864164564344, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0010020543122664094}, {"id": 455, "seek": 229304, "start": 2315.92, "end": 2318.08, "text": " and it's much harder to fool.", "tokens": [293, 309, 311, 709, 6081, 281, 7979, 13], "temperature": 0.0, "avg_logprob": -0.16955864164564344, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0010020543122664094}, {"id": 456, "seek": 229304, "start": 2318.08, "end": 2321.56, "text": " I'm not saying it's not impossible because, of course, it's possible.", "tokens": [286, 478, 406, 1566, 309, 311, 406, 6243, 570, 11, 295, 1164, 11, 309, 311, 1944, 13], "temperature": 0.0, "avg_logprob": -0.16955864164564344, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0010020543122664094}, {"id": 457, "seek": 232156, "start": 2321.56, "end": 2327.7999999999997, "text": " In general, later someone will find a way, but it's the usual arms race between attackers", "tokens": [682, 2674, 11, 1780, 1580, 486, 915, 257, 636, 11, 457, 309, 311, 264, 7713, 5812, 4569, 1296, 45129], "temperature": 0.0, "avg_logprob": -0.32505711820936695, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.01440258789807558}, {"id": 458, "seek": 232156, "start": 2327.7999999999997, "end": 2328.7999999999997, "text": " and defenders.", "tokens": [293, 36063, 13], "temperature": 0.0, "avg_logprob": -0.32505711820936695, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.01440258789807558}, {"id": 459, "seek": 232156, "start": 2328.7999999999997, "end": 2331.0, "text": " And it's no exception.", "tokens": [400, 309, 311, 572, 11183, 13], "temperature": 0.0, "avg_logprob": -0.32505711820936695, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.01440258789807558}, {"id": 460, "seek": 232156, "start": 2331.0, "end": 2333.0, "text": " Thank you for your question.", "tokens": [1044, 291, 337, 428, 1168, 13], "temperature": 0.0, "avg_logprob": -0.32505711820936695, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.01440258789807558}, {"id": 461, "seek": 232156, "start": 2333.0, "end": 2334.0, "text": " Hello.", "tokens": [2425, 13], "temperature": 0.0, "avg_logprob": -0.32505711820936695, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.01440258789807558}, {"id": 462, "seek": 232156, "start": 2334.0, "end": 2335.0, "text": " Hi.", "tokens": [2421, 13], "temperature": 0.0, "avg_logprob": -0.32505711820936695, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.01440258789807558}, {"id": 463, "seek": 232156, "start": 2335.0, "end": 2337.92, "text": " First, thank you for the presentation.", "tokens": [2386, 11, 1309, 291, 337, 264, 5860, 13], "temperature": 0.0, "avg_logprob": -0.32505711820936695, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.01440258789807558}, {"id": 464, "seek": 232156, "start": 2337.92, "end": 2340.08, "text": " I think it's a very interesting topic.", "tokens": [286, 519, 309, 311, 257, 588, 1880, 4829, 13], "temperature": 0.0, "avg_logprob": -0.32505711820936695, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.01440258789807558}, {"id": 465, "seek": 232156, "start": 2340.08, "end": 2347.64, "text": " I wanted to link it because it's been a bit of a buzz the past few weeks, the generative", "tokens": [286, 1415, 281, 2113, 309, 570, 309, 311, 668, 257, 857, 295, 257, 13036, 264, 1791, 1326, 3259, 11, 264, 1337, 1166], "temperature": 0.0, "avg_logprob": -0.32505711820936695, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.01440258789807558}, {"id": 466, "seek": 234764, "start": 2347.64, "end": 2353.24, "text": " AI, especially chat GPT, was wondering when you use that kind of algorithm and you scan", "tokens": [7318, 11, 2318, 5081, 26039, 51, 11, 390, 6359, 562, 291, 764, 300, 733, 295, 9284, 293, 291, 11049], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 467, "seek": 234764, "start": 2353.24, "end": 2358.44, "text": " an image, detect something, is there a level of confidence attached to the result and can", "tokens": [364, 3256, 11, 5531, 746, 11, 307, 456, 257, 1496, 295, 6687, 8570, 281, 264, 1874, 293, 393], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 468, "seek": 234764, "start": 2358.44, "end": 2361.72, "text": " you detect when an image is potentially a fake or?", "tokens": [291, 5531, 562, 364, 3256, 307, 7263, 257, 7592, 420, 30], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 469, "seek": 234764, "start": 2361.72, "end": 2368.52, "text": " There is a lot of time because there's an echo, so I cannot really, can you do it louder", "tokens": [821, 307, 257, 688, 295, 565, 570, 456, 311, 364, 14300, 11, 370, 286, 2644, 534, 11, 393, 291, 360, 309, 22717], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 470, "seek": 234764, "start": 2368.52, "end": 2369.52, "text": " please?", "tokens": [1767, 30], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 471, "seek": 234764, "start": 2369.52, "end": 2371.92, "text": " It's hard to understand from here.", "tokens": [467, 311, 1152, 281, 1223, 490, 510, 13], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 472, "seek": 234764, "start": 2371.92, "end": 2372.92, "text": " Hello.", "tokens": [2425, 13], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 473, "seek": 234764, "start": 2372.92, "end": 2373.92, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 474, "seek": 234764, "start": 2373.92, "end": 2374.92, "text": " Is it better?", "tokens": [1119, 309, 1101, 30], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 475, "seek": 234764, "start": 2374.92, "end": 2375.92, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.32585133825029644, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.006807760335505009}, {"id": 476, "seek": 237592, "start": 2375.92, "end": 2382.64, "text": " Yeah, so I said thank you, but I wanted to link to generative AI and I was asking so when", "tokens": [865, 11, 370, 286, 848, 1309, 291, 11, 457, 286, 1415, 281, 2113, 281, 1337, 1166, 7318, 293, 286, 390, 3365, 370, 562], "temperature": 0.0, "avg_logprob": -0.18537572487113402, "compression_ratio": 1.6851063829787234, "no_speech_prob": 0.006714957300573587}, {"id": 477, "seek": 237592, "start": 2382.64, "end": 2389.88, "text": " you run that kind of algorithm to detect violence or child abuse or anything else, can you also", "tokens": [291, 1190, 300, 733, 295, 9284, 281, 5531, 6270, 420, 1440, 9852, 420, 1340, 1646, 11, 393, 291, 611], "temperature": 0.0, "avg_logprob": -0.18537572487113402, "compression_ratio": 1.6851063829787234, "no_speech_prob": 0.006714957300573587}, {"id": 478, "seek": 237592, "start": 2389.88, "end": 2395.48, "text": " attach a level of confidence in the response to explain whether it's, well, to define whether", "tokens": [5085, 257, 1496, 295, 6687, 294, 264, 4134, 281, 2903, 1968, 309, 311, 11, 731, 11, 281, 6964, 1968], "temperature": 0.0, "avg_logprob": -0.18537572487113402, "compression_ratio": 1.6851063829787234, "no_speech_prob": 0.006714957300573587}, {"id": 479, "seek": 237592, "start": 2395.48, "end": 2400.56, "text": " it's a potentially fake picture or is there an extension to the algorithm where you can", "tokens": [309, 311, 257, 7263, 7592, 3036, 420, 307, 456, 364, 10320, 281, 264, 9284, 689, 291, 393], "temperature": 0.0, "avg_logprob": -0.18537572487113402, "compression_ratio": 1.6851063829787234, "no_speech_prob": 0.006714957300573587}, {"id": 480, "seek": 237592, "start": 2400.56, "end": 2403.44, "text": " link with the generative AI?", "tokens": [2113, 365, 264, 1337, 1166, 7318, 30], "temperature": 0.0, "avg_logprob": -0.18537572487113402, "compression_ratio": 1.6851063829787234, "no_speech_prob": 0.006714957300573587}, {"id": 481, "seek": 240344, "start": 2403.44, "end": 2408.44, "text": " I'm not sure about the answer.", "tokens": [286, 478, 406, 988, 466, 264, 1867, 13], "temperature": 0.0, "avg_logprob": -0.3043940533166644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.004826799966394901}, {"id": 482, "seek": 240344, "start": 2408.44, "end": 2416.76, "text": " Sorry, we can go for a beer and I can explain more details and let's see.", "tokens": [4919, 11, 321, 393, 352, 337, 257, 8795, 293, 286, 393, 2903, 544, 4365, 293, 718, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.3043940533166644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.004826799966394901}, {"id": 483, "seek": 240344, "start": 2416.76, "end": 2420.2000000000003, "text": " Yeah, you have a question.", "tokens": [865, 11, 291, 362, 257, 1168, 13], "temperature": 0.0, "avg_logprob": -0.3043940533166644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.004826799966394901}, {"id": 484, "seek": 240344, "start": 2420.2000000000003, "end": 2421.2000000000003, "text": " Hi.", "tokens": [2421, 13], "temperature": 0.0, "avg_logprob": -0.3043940533166644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.004826799966394901}, {"id": 485, "seek": 240344, "start": 2421.2000000000003, "end": 2422.48, "text": " Thank you for the talk.", "tokens": [1044, 291, 337, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.3043940533166644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.004826799966394901}, {"id": 486, "seek": 240344, "start": 2422.48, "end": 2424.48, "text": " It was very interesting.", "tokens": [467, 390, 588, 1880, 13], "temperature": 0.0, "avg_logprob": -0.3043940533166644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.004826799966394901}, {"id": 487, "seek": 240344, "start": 2424.48, "end": 2425.6, "text": " One more question also.", "tokens": [1485, 544, 1168, 611, 13], "temperature": 0.0, "avg_logprob": -0.3043940533166644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.004826799966394901}, {"id": 488, "seek": 240344, "start": 2425.6, "end": 2428.92, "text": " Do you run SSCD in production as well?", "tokens": [1144, 291, 1190, 12238, 16508, 294, 4265, 382, 731, 30], "temperature": 0.0, "avg_logprob": -0.3043940533166644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.004826799966394901}, {"id": 489, "seek": 240344, "start": 2428.92, "end": 2431.28, "text": " The deep learning network?", "tokens": [440, 2452, 2539, 3209, 30], "temperature": 0.0, "avg_logprob": -0.3043940533166644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.004826799966394901}, {"id": 490, "seek": 243128, "start": 2431.28, "end": 2438.1200000000003, "text": " If we're using SSCD in production, can't I reply to this question?", "tokens": [759, 321, 434, 1228, 12238, 16508, 294, 4265, 11, 393, 380, 286, 16972, 281, 341, 1168, 30], "temperature": 0.0, "avg_logprob": -0.258591133615245, "compression_ratio": 1.676923076923077, "no_speech_prob": 0.0027989335358142853}, {"id": 491, "seek": 243128, "start": 2438.1200000000003, "end": 2442.1600000000003, "text": " We use simsearch net plus plus.", "tokens": [492, 764, 1034, 405, 1178, 2533, 1804, 1804, 13], "temperature": 0.0, "avg_logprob": -0.258591133615245, "compression_ratio": 1.676923076923077, "no_speech_prob": 0.0027989335358142853}, {"id": 492, "seek": 243128, "start": 2442.1600000000003, "end": 2447.6400000000003, "text": " We use this other one because we have written a blog post about this, so I can confirm that", "tokens": [492, 764, 341, 661, 472, 570, 321, 362, 3720, 257, 6968, 2183, 466, 341, 11, 370, 286, 393, 9064, 300], "temperature": 0.0, "avg_logprob": -0.258591133615245, "compression_ratio": 1.676923076923077, "no_speech_prob": 0.0027989335358142853}, {"id": 493, "seek": 243128, "start": 2447.6400000000003, "end": 2449.7200000000003, "text": " we use simsearch net plus plus.", "tokens": [321, 764, 1034, 405, 1178, 2533, 1804, 1804, 13], "temperature": 0.0, "avg_logprob": -0.258591133615245, "compression_ratio": 1.676923076923077, "no_speech_prob": 0.0027989335358142853}, {"id": 494, "seek": 243128, "start": 2449.7200000000003, "end": 2457.32, "text": " I cannot nor confirm or deny about SSCD, but those are related technologies, so I could", "tokens": [286, 2644, 6051, 9064, 420, 15744, 466, 12238, 16508, 11, 457, 729, 366, 4077, 7943, 11, 370, 286, 727], "temperature": 0.0, "avg_logprob": -0.258591133615245, "compression_ratio": 1.676923076923077, "no_speech_prob": 0.0027989335358142853}, {"id": 495, "seek": 243128, "start": 2457.32, "end": 2458.32, "text": " talk about that.", "tokens": [751, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.258591133615245, "compression_ratio": 1.676923076923077, "no_speech_prob": 0.0027989335358142853}, {"id": 496, "seek": 245832, "start": 2458.32, "end": 2462.2400000000002, "text": " What does the production stack for simsearch net plus plus look like?", "tokens": [708, 775, 264, 4265, 8630, 337, 1034, 405, 1178, 2533, 1804, 1804, 574, 411, 30], "temperature": 0.0, "avg_logprob": -0.27684987508333647, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.0008904621354304254}, {"id": 497, "seek": 245832, "start": 2462.2400000000002, "end": 2463.2400000000002, "text": " How do you serve it?", "tokens": [1012, 360, 291, 4596, 309, 30], "temperature": 0.0, "avg_logprob": -0.27684987508333647, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.0008904621354304254}, {"id": 498, "seek": 245832, "start": 2463.2400000000002, "end": 2466.1600000000003, "text": " It must be pretty hard to deal with the GPUs.", "tokens": [467, 1633, 312, 1238, 1152, 281, 2028, 365, 264, 18407, 82, 13], "temperature": 0.0, "avg_logprob": -0.27684987508333647, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.0008904621354304254}, {"id": 499, "seek": 245832, "start": 2466.1600000000003, "end": 2468.2400000000002, "text": " This is not a question that I'm sorry.", "tokens": [639, 307, 406, 257, 1168, 300, 286, 478, 2597, 13], "temperature": 0.0, "avg_logprob": -0.27684987508333647, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.0008904621354304254}, {"id": 500, "seek": 245832, "start": 2468.2400000000002, "end": 2470.52, "text": " I cannot talk about the production setups.", "tokens": [286, 2644, 751, 466, 264, 4265, 46832, 13], "temperature": 0.0, "avg_logprob": -0.27684987508333647, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.0008904621354304254}, {"id": 501, "seek": 245832, "start": 2470.52, "end": 2472.04, "text": " I'm sorry.", "tokens": [286, 478, 2597, 13], "temperature": 0.0, "avg_logprob": -0.27684987508333647, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.0008904621354304254}, {"id": 502, "seek": 245832, "start": 2472.04, "end": 2475.88, "text": " Okay, any question nearby?", "tokens": [1033, 11, 604, 1168, 11184, 30], "temperature": 0.0, "avg_logprob": -0.27684987508333647, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.0008904621354304254}, {"id": 503, "seek": 245832, "start": 2475.88, "end": 2476.88, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.27684987508333647, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.0008904621354304254}, {"id": 504, "seek": 245832, "start": 2476.88, "end": 2483.1200000000003, "text": " Of course, you can imagine that we do not operate in the vacuum, so if you can think", "tokens": [2720, 1164, 11, 291, 393, 3811, 300, 321, 360, 406, 9651, 294, 264, 14224, 11, 370, 498, 291, 393, 519], "temperature": 0.0, "avg_logprob": -0.27684987508333647, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.0008904621354304254}, {"id": 505, "seek": 248312, "start": 2483.12, "end": 2491.8399999999997, "text": " about how we serve results from a neural network, it is something perhaps similar to what would", "tokens": [466, 577, 321, 4596, 3542, 490, 257, 18161, 3209, 11, 309, 307, 746, 4317, 2531, 281, 437, 576], "temperature": 0.0, "avg_logprob": -0.2645154840805951, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.000921520171687007}, {"id": 506, "seek": 248312, "start": 2491.8399999999997, "end": 2502.4, "text": " you do if you would have to put behind an API a model?", "tokens": [291, 360, 498, 291, 576, 362, 281, 829, 2261, 364, 9362, 257, 2316, 30], "temperature": 0.0, "avg_logprob": -0.2645154840805951, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.000921520171687007}, {"id": 507, "seek": 248312, "start": 2502.4, "end": 2504.68, "text": " So I kind of have two questions.", "tokens": [407, 286, 733, 295, 362, 732, 1651, 13], "temperature": 0.0, "avg_logprob": -0.2645154840805951, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.000921520171687007}, {"id": 508, "seek": 248312, "start": 2504.68, "end": 2512.7999999999997, "text": " The first question is, to what extent do... I think there are potentially two problems.", "tokens": [440, 700, 1168, 307, 11, 281, 437, 8396, 360, 1097, 286, 519, 456, 366, 7263, 732, 2740, 13], "temperature": 0.0, "avg_logprob": -0.2645154840805951, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.000921520171687007}, {"id": 509, "seek": 251280, "start": 2512.8, "end": 2519.52, "text": " Intentional mismatches and unintentional mismatches.", "tokens": [5681, 1251, 304, 23220, 852, 279, 293, 45514, 304, 23220, 852, 279, 13], "temperature": 0.0, "avg_logprob": -0.1742657543568129, "compression_ratio": 1.7880184331797235, "no_speech_prob": 0.0013604179257526994}, {"id": 510, "seek": 251280, "start": 2519.52, "end": 2525.32, "text": " So situations where perhaps an image has been recompressed or has been cropped, or is perhaps", "tokens": [407, 6851, 689, 4317, 364, 3256, 575, 668, 48000, 3805, 420, 575, 668, 4848, 3320, 11, 420, 307, 4317], "temperature": 0.0, "avg_logprob": -0.1742657543568129, "compression_ratio": 1.7880184331797235, "no_speech_prob": 0.0013604179257526994}, {"id": 511, "seek": 251280, "start": 2525.32, "end": 2530.7200000000003, "text": " another image of the same situation, versus situations where people have deliberately", "tokens": [1071, 3256, 295, 264, 912, 2590, 11, 5717, 6851, 689, 561, 362, 23506], "temperature": 0.0, "avg_logprob": -0.1742657543568129, "compression_ratio": 1.7880184331797235, "no_speech_prob": 0.0013604179257526994}, {"id": 512, "seek": 251280, "start": 2530.7200000000003, "end": 2534.76, "text": " deformed the image to try and get around these kind of systems.", "tokens": [368, 22892, 264, 3256, 281, 853, 293, 483, 926, 613, 733, 295, 3652, 13], "temperature": 0.0, "avg_logprob": -0.1742657543568129, "compression_ratio": 1.7880184331797235, "no_speech_prob": 0.0013604179257526994}, {"id": 513, "seek": 251280, "start": 2534.76, "end": 2541.42, "text": " Do you have any idea of how performant it is against the two scenarios of either accidental", "tokens": [1144, 291, 362, 604, 1558, 295, 577, 2042, 394, 309, 307, 1970, 264, 732, 15077, 295, 2139, 38094], "temperature": 0.0, "avg_logprob": -0.1742657543568129, "compression_ratio": 1.7880184331797235, "no_speech_prob": 0.0013604179257526994}, {"id": 514, "seek": 254142, "start": 2541.42, "end": 2546.08, "text": " or unintentional mismatches versus intentionally trying to avoid it?", "tokens": [420, 45514, 304, 23220, 852, 279, 5717, 22062, 1382, 281, 5042, 309, 30], "temperature": 0.0, "avg_logprob": -0.1363227778467639, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0022316877730190754}, {"id": 515, "seek": 254142, "start": 2546.08, "end": 2556.52, "text": " So it is, of course, possible to have unintentional mismatches, and I've seen images that were", "tokens": [407, 309, 307, 11, 295, 1164, 11, 1944, 281, 362, 45514, 304, 23220, 852, 279, 11, 293, 286, 600, 1612, 5267, 300, 645], "temperature": 0.0, "avg_logprob": -0.1363227778467639, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0022316877730190754}, {"id": 516, "seek": 254142, "start": 2556.52, "end": 2562.48, "text": " adversarial engineered to give the same embedding.", "tokens": [17641, 44745, 38648, 281, 976, 264, 912, 12240, 3584, 13], "temperature": 0.0, "avg_logprob": -0.1363227778467639, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0022316877730190754}, {"id": 517, "seek": 254142, "start": 2562.48, "end": 2568.56, "text": " Those are absolutely possible, again, in PDQ, PDNA, and all the perceptual hashing, which", "tokens": [3950, 366, 3122, 1944, 11, 797, 11, 294, 10464, 48, 11, 10464, 5321, 11, 293, 439, 264, 43276, 901, 575, 571, 11, 597], "temperature": 0.0, "avg_logprob": -0.1363227778467639, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0022316877730190754}, {"id": 518, "seek": 254142, "start": 2568.56, "end": 2570.88, "text": " is just a mathematical transformation.", "tokens": [307, 445, 257, 18894, 9887, 13], "temperature": 0.0, "avg_logprob": -0.1363227778467639, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0022316877730190754}, {"id": 519, "seek": 257088, "start": 2570.88, "end": 2577.32, "text": " You just have to find a way where the input seems the same to the algorithm.", "tokens": [509, 445, 362, 281, 915, 257, 636, 689, 264, 4846, 2544, 264, 912, 281, 264, 9284, 13], "temperature": 0.0, "avg_logprob": -0.184896606996835, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.0016864356584846973}, {"id": 520, "seek": 257088, "start": 2577.32, "end": 2582.56, "text": " For the neural network things, it depends.", "tokens": [1171, 264, 18161, 3209, 721, 11, 309, 5946, 13], "temperature": 0.0, "avg_logprob": -0.184896606996835, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.0016864356584846973}, {"id": 521, "seek": 257088, "start": 2582.56, "end": 2589.56, "text": " You can study the code, you can study how it's done, if you can, it is absolutely possible", "tokens": [509, 393, 2979, 264, 3089, 11, 291, 393, 2979, 577, 309, 311, 1096, 11, 498, 291, 393, 11, 309, 307, 3122, 1944], "temperature": 0.0, "avg_logprob": -0.184896606996835, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.0016864356584846973}, {"id": 522, "seek": 257088, "start": 2589.56, "end": 2597.44, "text": " sooner or later, because the adversarial attacker on combinets are a reality, so it's absolutely", "tokens": [15324, 420, 1780, 11, 570, 264, 17641, 44745, 35871, 322, 2512, 259, 1385, 366, 257, 4103, 11, 370, 309, 311, 3122], "temperature": 0.0, "avg_logprob": -0.184896606996835, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.0016864356584846973}, {"id": 523, "seek": 257088, "start": 2597.44, "end": 2598.44, "text": " possible.", "tokens": [1944, 13], "temperature": 0.0, "avg_logprob": -0.184896606996835, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.0016864356584846973}, {"id": 524, "seek": 259844, "start": 2598.44, "end": 2606.36, "text": " I've seen some mismatches, but usually two perceptual hashes.", "tokens": [286, 600, 1612, 512, 23220, 852, 279, 11, 457, 2673, 732, 43276, 901, 575, 8076, 13], "temperature": 0.0, "avg_logprob": -0.2611519006582407, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.0011102984426543117}, {"id": 525, "seek": 259844, "start": 2606.36, "end": 2612.08, "text": " Usually the more refined the technique, the harder it is to attack, of course, otherwise", "tokens": [11419, 264, 544, 26201, 264, 6532, 11, 264, 6081, 309, 307, 281, 2690, 11, 295, 1164, 11, 5911], "temperature": 0.0, "avg_logprob": -0.2611519006582407, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.0011102984426543117}, {"id": 526, "seek": 259844, "start": 2612.08, "end": 2616.52, "text": " we just will stay with MD5, because it will be enough.", "tokens": [321, 445, 486, 1754, 365, 22521, 20, 11, 570, 309, 486, 312, 1547, 13], "temperature": 0.0, "avg_logprob": -0.2611519006582407, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.0011102984426543117}, {"id": 527, "seek": 259844, "start": 2616.52, "end": 2617.52, "text": " Crops.", "tokens": [383, 49715, 13], "temperature": 0.0, "avg_logprob": -0.2611519006582407, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.0011102984426543117}, {"id": 528, "seek": 259844, "start": 2617.52, "end": 2626.2400000000002, "text": " PDQ is resistant to crops, SSCD is very resistant to crops.", "tokens": [10464, 48, 307, 20383, 281, 16829, 11, 12238, 16508, 307, 588, 20383, 281, 16829, 13], "temperature": 0.0, "avg_logprob": -0.2611519006582407, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.0011102984426543117}, {"id": 529, "seek": 262624, "start": 2626.24, "end": 2632.68, "text": " If you have rotations, I believe also PDQ is resistant to rotations, like flips, but", "tokens": [759, 291, 362, 44796, 11, 286, 1697, 611, 10464, 48, 307, 20383, 281, 44796, 11, 411, 40249, 11, 457], "temperature": 0.0, "avg_logprob": -0.2265343189239502, "compression_ratio": 1.3836477987421383, "no_speech_prob": 0.0024429720360785723}, {"id": 530, "seek": 262624, "start": 2632.68, "end": 2638.2799999999997, "text": " you cannot ask much more than that.", "tokens": [291, 2644, 1029, 709, 544, 813, 300, 13], "temperature": 0.0, "avg_logprob": -0.2265343189239502, "compression_ratio": 1.3836477987421383, "no_speech_prob": 0.0024429720360785723}, {"id": 531, "seek": 262624, "start": 2638.2799999999997, "end": 2639.2799999999997, "text": " Other questions?", "tokens": [5358, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2265343189239502, "compression_ratio": 1.3836477987421383, "no_speech_prob": 0.0024429720360785723}, {"id": 532, "seek": 262624, "start": 2639.2799999999997, "end": 2640.2799999999997, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2265343189239502, "compression_ratio": 1.3836477987421383, "no_speech_prob": 0.0024429720360785723}, {"id": 533, "seek": 262624, "start": 2640.2799999999997, "end": 2648.72, "text": " Do you have any information about the speed difference between SSCD and PDQ?", "tokens": [1144, 291, 362, 604, 1589, 466, 264, 3073, 2649, 1296, 12238, 16508, 293, 10464, 48, 30], "temperature": 0.0, "avg_logprob": -0.2265343189239502, "compression_ratio": 1.3836477987421383, "no_speech_prob": 0.0024429720360785723}, {"id": 534, "seek": 264872, "start": 2648.72, "end": 2656.9199999999996, "text": " So the question is whether I have some speed benchmarks for the difference of performance", "tokens": [407, 264, 1168, 307, 1968, 286, 362, 512, 3073, 43751, 337, 264, 2649, 295, 3389], "temperature": 0.0, "avg_logprob": -0.184339118330446, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.001212548348121345}, {"id": 535, "seek": 264872, "start": 2656.9199999999996, "end": 2662.04, "text": " between PDQ and SSCD at inference time.", "tokens": [1296, 10464, 48, 293, 12238, 16508, 412, 38253, 565, 13], "temperature": 0.0, "avg_logprob": -0.184339118330446, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.001212548348121345}, {"id": 536, "seek": 264872, "start": 2662.04, "end": 2668.68, "text": " PDQ is faster than your time to read the image from disk.", "tokens": [10464, 48, 307, 4663, 813, 428, 565, 281, 1401, 264, 3256, 490, 12355, 13], "temperature": 0.0, "avg_logprob": -0.184339118330446, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.001212548348121345}, {"id": 537, "seek": 264872, "start": 2668.68, "end": 2670.56, "text": " So it's negligible.", "tokens": [407, 309, 311, 32570, 964, 13], "temperature": 0.0, "avg_logprob": -0.184339118330446, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.001212548348121345}, {"id": 538, "seek": 264872, "start": 2670.56, "end": 2671.56, "text": " It will just compute.", "tokens": [467, 486, 445, 14722, 13], "temperature": 0.0, "avg_logprob": -0.184339118330446, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.001212548348121345}, {"id": 539, "seek": 264872, "start": 2671.56, "end": 2673.9599999999996, "text": " It's a mathematical transformation on the pixel.", "tokens": [467, 311, 257, 18894, 9887, 322, 264, 19261, 13], "temperature": 0.0, "avg_logprob": -0.184339118330446, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.001212548348121345}, {"id": 540, "seek": 267396, "start": 2673.96, "end": 2681.12, "text": " The neural network requires a dedicated hardware, if you do that on CPU it will take seconds,", "tokens": [440, 18161, 3209, 7029, 257, 8374, 8837, 11, 498, 291, 360, 300, 322, 13199, 309, 486, 747, 3949, 11], "temperature": 0.0, "avg_logprob": -0.198090944792095, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.0018385715084150434}, {"id": 541, "seek": 267396, "start": 2681.12, "end": 2683.96, "text": " also because the model I think is big enough.", "tokens": [611, 570, 264, 2316, 286, 519, 307, 955, 1547, 13], "temperature": 0.0, "avg_logprob": -0.198090944792095, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.0018385715084150434}, {"id": 542, "seek": 267396, "start": 2683.96, "end": 2689.76, "text": " It's not as big as GPT, but it's a 50 level CNET.", "tokens": [467, 311, 406, 382, 955, 382, 26039, 51, 11, 457, 309, 311, 257, 2625, 1496, 14589, 4850, 13], "temperature": 0.0, "avg_logprob": -0.198090944792095, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.0018385715084150434}, {"id": 543, "seek": 267396, "start": 2689.76, "end": 2696.52, "text": " So it's of course lower and requires dedicated hardware, but it's more precise.", "tokens": [407, 309, 311, 295, 1164, 3126, 293, 7029, 8374, 8837, 11, 457, 309, 311, 544, 13600, 13], "temperature": 0.0, "avg_logprob": -0.198090944792095, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.0018385715084150434}, {"id": 544, "seek": 267396, "start": 2696.52, "end": 2702.8, "text": " It just finds, SSCD finds anything that PDQ is able to find and much more.", "tokens": [467, 445, 10704, 11, 12238, 16508, 10704, 1340, 300, 10464, 48, 307, 1075, 281, 915, 293, 709, 544, 13], "temperature": 0.0, "avg_logprob": -0.198090944792095, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.0018385715084150434}, {"id": 545, "seek": 270280, "start": 2702.8, "end": 2711.6400000000003, "text": " So in case, if you are very curious about, sorry, if you are very conscious about, I", "tokens": [407, 294, 1389, 11, 498, 291, 366, 588, 6369, 466, 11, 2597, 11, 498, 291, 366, 588, 6648, 466, 11, 286], "temperature": 0.0, "avg_logprob": -0.19161117717783938, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0015913665993139148}, {"id": 546, "seek": 270280, "start": 2711.6400000000003, "end": 2717.1600000000003, "text": " have to scan this stuff just to make sure they don't come from a ill source.", "tokens": [362, 281, 11049, 341, 1507, 445, 281, 652, 988, 436, 500, 380, 808, 490, 257, 3171, 4009, 13], "temperature": 0.0, "avg_logprob": -0.19161117717783938, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0015913665993139148}, {"id": 547, "seek": 270280, "start": 2717.1600000000003, "end": 2721.88, "text": " You might want to set up an async process that will take more, but will just batch process", "tokens": [509, 1062, 528, 281, 992, 493, 364, 382, 34015, 1399, 300, 486, 747, 544, 11, 457, 486, 445, 15245, 1399], "temperature": 0.0, "avg_logprob": -0.19161117717783938, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0015913665993139148}, {"id": 548, "seek": 270280, "start": 2721.88, "end": 2722.88, "text": " all your stuff.", "tokens": [439, 428, 1507, 13], "temperature": 0.0, "avg_logprob": -0.19161117717783938, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0015913665993139148}, {"id": 549, "seek": 270280, "start": 2722.88, "end": 2730.28, "text": " If you need a super fast thing, PDQ will not really wait over your server.", "tokens": [759, 291, 643, 257, 1687, 2370, 551, 11, 10464, 48, 486, 406, 534, 1699, 670, 428, 7154, 13], "temperature": 0.0, "avg_logprob": -0.19161117717783938, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0015913665993139148}, {"id": 550, "seek": 273028, "start": 2730.28, "end": 2733.76, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.23572926772268196, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0024163818452507257}, {"id": 551, "seek": 273028, "start": 2733.76, "end": 2734.76, "text": " Any other question?", "tokens": [2639, 661, 1168, 30], "temperature": 0.0, "avg_logprob": -0.23572926772268196, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0024163818452507257}, {"id": 552, "seek": 273028, "start": 2734.76, "end": 2735.76, "text": " Hi.", "tokens": [2421, 13], "temperature": 0.0, "avg_logprob": -0.23572926772268196, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0024163818452507257}, {"id": 553, "seek": 273028, "start": 2735.76, "end": 2744.92, "text": " First of all, great question from my former colleague David, I think, down there.", "tokens": [2386, 295, 439, 11, 869, 1168, 490, 452, 5819, 13532, 4389, 11, 286, 519, 11, 760, 456, 13], "temperature": 0.0, "avg_logprob": -0.23572926772268196, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0024163818452507257}, {"id": 554, "seek": 273028, "start": 2744.92, "end": 2747.28, "text": " Not even looking this way.", "tokens": [1726, 754, 1237, 341, 636, 13], "temperature": 0.0, "avg_logprob": -0.23572926772268196, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0024163818452507257}, {"id": 555, "seek": 273028, "start": 2747.28, "end": 2753.0800000000004, "text": " But what happens if you get a false positive match?", "tokens": [583, 437, 2314, 498, 291, 483, 257, 7908, 3353, 2995, 30], "temperature": 0.0, "avg_logprob": -0.23572926772268196, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0024163818452507257}, {"id": 556, "seek": 273028, "start": 2753.0800000000004, "end": 2758.6800000000003, "text": " How do you disregard that in the future without potentially disregarding a real match?", "tokens": [1012, 360, 291, 44493, 300, 294, 264, 2027, 1553, 7263, 44493, 278, 257, 957, 2995, 30], "temperature": 0.0, "avg_logprob": -0.23572926772268196, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0024163818452507257}, {"id": 557, "seek": 275868, "start": 2758.68, "end": 2763.96, "text": " So if we get a false positive match, how do we do to restore?", "tokens": [407, 498, 321, 483, 257, 7908, 3353, 2995, 11, 577, 360, 321, 360, 281, 15227, 30], "temperature": 0.0, "avg_logprob": -0.3204934006437249, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0017692731926217675}, {"id": 558, "seek": 275868, "start": 2763.96, "end": 2764.96, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3204934006437249, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0017692731926217675}, {"id": 559, "seek": 275868, "start": 2764.96, "end": 2765.96, "text": " How do you restore?", "tokens": [1012, 360, 291, 15227, 30], "temperature": 0.0, "avg_logprob": -0.3204934006437249, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0017692731926217675}, {"id": 560, "seek": 275868, "start": 2765.96, "end": 2770.0, "text": " You mean or in MEDA all the day?", "tokens": [509, 914, 420, 294, 376, 4731, 32, 439, 264, 786, 30], "temperature": 0.0, "avg_logprob": -0.3204934006437249, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0017692731926217675}, {"id": 561, "seek": 275868, "start": 2770.0, "end": 2771.0, "text": " Just anywhere.", "tokens": [1449, 4992, 13], "temperature": 0.0, "avg_logprob": -0.3204934006437249, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0017692731926217675}, {"id": 562, "seek": 275868, "start": 2771.0, "end": 2772.0, "text": " Like as a concept.", "tokens": [1743, 382, 257, 3410, 13], "temperature": 0.0, "avg_logprob": -0.3204934006437249, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0017692731926217675}, {"id": 563, "seek": 275868, "start": 2772.0, "end": 2774.3599999999997, "text": " So in MEDA, I cannot really say.", "tokens": [407, 294, 376, 4731, 32, 11, 286, 2644, 534, 584, 13], "temperature": 0.0, "avg_logprob": -0.3204934006437249, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0017692731926217675}, {"id": 564, "seek": 275868, "start": 2774.3599999999997, "end": 2781.2, "text": " With the Asher Matcher Actioner, you have the, you should provide a capability to your", "tokens": [2022, 264, 1018, 511, 26178, 260, 16261, 260, 11, 291, 362, 264, 11, 291, 820, 2893, 257, 13759, 281, 428], "temperature": 0.0, "avg_logprob": -0.3204934006437249, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0017692731926217675}, {"id": 565, "seek": 275868, "start": 2781.2, "end": 2787.3599999999997, "text": " own platform for which you are soft deleting the image because you have to provide away", "tokens": [1065, 3663, 337, 597, 291, 366, 2787, 48946, 264, 3256, 570, 291, 362, 281, 2893, 1314], "temperature": 0.0, "avg_logprob": -0.3204934006437249, "compression_ratio": 1.5404255319148936, "no_speech_prob": 0.0017692731926217675}, {"id": 566, "seek": 278736, "start": 2787.36, "end": 2794.56, "text": " an API in your platform that HMA will call on, where you say, soft delete this picture.", "tokens": [364, 9362, 294, 428, 3663, 300, 389, 9998, 486, 818, 322, 11, 689, 291, 584, 11, 2787, 12097, 341, 3036, 13], "temperature": 0.0, "avg_logprob": -0.263460484418002, "compression_ratio": 1.5933014354066986, "no_speech_prob": 0.0041512087918818}, {"id": 567, "seek": 278736, "start": 2794.56, "end": 2799.56, "text": " So make it unavailable, but do not really delete it in case you want to appeal.", "tokens": [407, 652, 309, 36541, 32699, 11, 457, 360, 406, 534, 12097, 309, 294, 1389, 291, 528, 281, 13668, 13], "temperature": 0.0, "avg_logprob": -0.263460484418002, "compression_ratio": 1.5933014354066986, "no_speech_prob": 0.0041512087918818}, {"id": 568, "seek": 278736, "start": 2799.56, "end": 2806.7200000000003, "text": " So you need to provide like, undelete and unsoft delete and soft delete.", "tokens": [407, 291, 643, 281, 2893, 411, 11, 674, 338, 3498, 293, 2693, 6750, 12097, 293, 2787, 12097, 13], "temperature": 0.0, "avg_logprob": -0.263460484418002, "compression_ratio": 1.5933014354066986, "no_speech_prob": 0.0041512087918818}, {"id": 569, "seek": 278736, "start": 2806.7200000000003, "end": 2814.56, "text": " This is the simplest way and most effective way to deal with false positive in case, whoops,", "tokens": [639, 307, 264, 22811, 636, 293, 881, 4942, 636, 281, 2028, 365, 7908, 3353, 294, 1389, 11, 567, 3370, 11], "temperature": 0.0, "avg_logprob": -0.263460484418002, "compression_ratio": 1.5933014354066986, "no_speech_prob": 0.0041512087918818}, {"id": 570, "seek": 281456, "start": 2814.56, "end": 2817.56, "text": " I did a mistake, I want to restore the content.", "tokens": [286, 630, 257, 6146, 11, 286, 528, 281, 15227, 264, 2701, 13], "temperature": 0.0, "avg_logprob": -0.2016923779346904, "compression_ratio": 1.66015625, "no_speech_prob": 0.007363973651081324}, {"id": 571, "seek": 281456, "start": 2817.56, "end": 2818.56, "text": " Sure.", "tokens": [4894, 13], "temperature": 0.0, "avg_logprob": -0.2016923779346904, "compression_ratio": 1.66015625, "no_speech_prob": 0.007363973651081324}, {"id": 572, "seek": 281456, "start": 2818.56, "end": 2823.32, "text": " But if you have an image that someone wants to upload, say it's a popular image that a", "tokens": [583, 498, 291, 362, 364, 3256, 300, 1580, 2738, 281, 6580, 11, 584, 309, 311, 257, 3743, 3256, 300, 257], "temperature": 0.0, "avg_logprob": -0.2016923779346904, "compression_ratio": 1.66015625, "no_speech_prob": 0.007363973651081324}, {"id": 573, "seek": 281456, "start": 2823.32, "end": 2829.24, "text": " lot of people are going to upload, but it matches a pattern of another bad image, can", "tokens": [688, 295, 561, 366, 516, 281, 6580, 11, 457, 309, 10676, 257, 5102, 295, 1071, 1578, 3256, 11, 393], "temperature": 0.0, "avg_logprob": -0.2016923779346904, "compression_ratio": 1.66015625, "no_speech_prob": 0.007363973651081324}, {"id": 574, "seek": 281456, "start": 2829.24, "end": 2835.7999999999997, "text": " you auto, is there a good way to make a more precise hash and exclude that and say this", "tokens": [291, 8399, 11, 307, 456, 257, 665, 636, 281, 652, 257, 544, 13600, 22019, 293, 33536, 300, 293, 584, 341], "temperature": 0.0, "avg_logprob": -0.2016923779346904, "compression_ratio": 1.66015625, "no_speech_prob": 0.007363973651081324}, {"id": 575, "seek": 281456, "start": 2835.7999999999997, "end": 2837.2, "text": " one is a false positive?", "tokens": [472, 307, 257, 7908, 3353, 30], "temperature": 0.0, "avg_logprob": -0.2016923779346904, "compression_ratio": 1.66015625, "no_speech_prob": 0.007363973651081324}, {"id": 576, "seek": 281456, "start": 2837.2, "end": 2839.0, "text": " It doesn't match what you think it does.", "tokens": [467, 1177, 380, 2995, 437, 291, 519, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.2016923779346904, "compression_ratio": 1.66015625, "no_speech_prob": 0.007363973651081324}, {"id": 577, "seek": 281456, "start": 2839.0, "end": 2841.04, "text": " So you don't have to keep undoing the.", "tokens": [407, 291, 500, 380, 362, 281, 1066, 23779, 278, 264, 13], "temperature": 0.0, "avg_logprob": -0.2016923779346904, "compression_ratio": 1.66015625, "no_speech_prob": 0.007363973651081324}, {"id": 578, "seek": 281456, "start": 2841.04, "end": 2842.04, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2016923779346904, "compression_ratio": 1.66015625, "no_speech_prob": 0.007363973651081324}, {"id": 579, "seek": 284204, "start": 2842.04, "end": 2848.24, "text": " So partly if the image is popular, so we have many examples and we have many examples of", "tokens": [407, 17031, 498, 264, 3256, 307, 3743, 11, 370, 321, 362, 867, 5110, 293, 321, 362, 867, 5110, 295], "temperature": 0.0, "avg_logprob": -0.23976479453602056, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.0022204106207937002}, {"id": 580, "seek": 284204, "start": 2848.24, "end": 2853.36, "text": " an image which is not bad and then comes a bad image, whether we can use the fact that", "tokens": [364, 3256, 597, 307, 406, 1578, 293, 550, 1487, 257, 1578, 3256, 11, 1968, 321, 393, 764, 264, 1186, 300], "temperature": 0.0, "avg_logprob": -0.23976479453602056, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.0022204106207937002}, {"id": 581, "seek": 284204, "start": 2853.36, "end": 2855.96, "text": " it's very widespread to augment our position.", "tokens": [309, 311, 588, 22679, 281, 29919, 527, 2535, 13], "temperature": 0.0, "avg_logprob": -0.23976479453602056, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.0022204106207937002}, {"id": 582, "seek": 284204, "start": 2855.96, "end": 2857.96, "text": " Is this the question?", "tokens": [1119, 341, 264, 1168, 30], "temperature": 0.0, "avg_logprob": -0.23976479453602056, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.0022204106207937002}, {"id": 583, "seek": 284204, "start": 2857.96, "end": 2858.96, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.23976479453602056, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.0022204106207937002}, {"id": 584, "seek": 284204, "start": 2858.96, "end": 2868.0, "text": " Well, really, there's nothing in this presentation that says these because once you train the", "tokens": [1042, 11, 534, 11, 456, 311, 1825, 294, 341, 5860, 300, 1619, 613, 570, 1564, 291, 3847, 264], "temperature": 0.0, "avg_logprob": -0.23976479453602056, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.0022204106207937002}, {"id": 585, "seek": 286800, "start": 2868.0, "end": 2873.56, "text": " network is trained and you start serving and the network will give you the same answers", "tokens": [3209, 307, 8895, 293, 291, 722, 8148, 293, 264, 3209, 486, 976, 291, 264, 912, 6338], "temperature": 0.0, "avg_logprob": -0.22226797504189574, "compression_ratio": 1.663265306122449, "no_speech_prob": 0.0006411351496353745}, {"id": 586, "seek": 286800, "start": 2873.56, "end": 2876.04, "text": " to the same question, to the same query.", "tokens": [281, 264, 912, 1168, 11, 281, 264, 912, 14581, 13], "temperature": 0.0, "avg_logprob": -0.22226797504189574, "compression_ratio": 1.663265306122449, "no_speech_prob": 0.0006411351496353745}, {"id": 587, "seek": 286800, "start": 2876.04, "end": 2882.32, "text": " PDQ or other mathematical algorithm, perceptual algorithm is just a mathematical function so", "tokens": [10464, 48, 420, 661, 18894, 9284, 11, 43276, 901, 9284, 307, 445, 257, 18894, 2445, 370], "temperature": 0.0, "avg_logprob": -0.22226797504189574, "compression_ratio": 1.663265306122449, "no_speech_prob": 0.0006411351496353745}, {"id": 588, "seek": 286800, "start": 2882.32, "end": 2883.32, "text": " will not change.", "tokens": [486, 406, 1319, 13], "temperature": 0.0, "avg_logprob": -0.22226797504189574, "compression_ratio": 1.663265306122449, "no_speech_prob": 0.0006411351496353745}, {"id": 589, "seek": 286800, "start": 2883.32, "end": 2885.0, "text": " There's nothing to train.", "tokens": [821, 311, 1825, 281, 3847, 13], "temperature": 0.0, "avg_logprob": -0.22226797504189574, "compression_ratio": 1.663265306122449, "no_speech_prob": 0.0006411351496353745}, {"id": 590, "seek": 286800, "start": 2885.0, "end": 2892.92, "text": " So to change a deficiency of your model, you have to retrain.", "tokens": [407, 281, 1319, 257, 37500, 295, 428, 2316, 11, 291, 362, 281, 1533, 7146, 13], "temperature": 0.0, "avg_logprob": -0.22226797504189574, "compression_ratio": 1.663265306122449, "no_speech_prob": 0.0006411351496353745}, {"id": 591, "seek": 289292, "start": 2892.92, "end": 2899.0, "text": " You can do a better retraining and sometimes model are retrained as anything which is still", "tokens": [509, 393, 360, 257, 1101, 49356, 1760, 293, 2171, 2316, 366, 1533, 31774, 382, 1340, 597, 307, 920], "temperature": 0.0, "avg_logprob": -0.2126802603403727, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.0009840771090239286}, {"id": 592, "seek": 289292, "start": 2899.0, "end": 2900.0, "text": " under maintenance.", "tokens": [833, 11258, 13], "temperature": 0.0, "avg_logprob": -0.2126802603403727, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.0009840771090239286}, {"id": 593, "seek": 289292, "start": 2900.0, "end": 2905.56, "text": " For example, we get new data, for example, and we might want to retrain as any other", "tokens": [1171, 1365, 11, 321, 483, 777, 1412, 11, 337, 1365, 11, 293, 321, 1062, 528, 281, 1533, 7146, 382, 604, 661], "temperature": 0.0, "avg_logprob": -0.2126802603403727, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.0009840771090239286}, {"id": 594, "seek": 289292, "start": 2905.56, "end": 2911.4, "text": " model also for the spam filters is the same.", "tokens": [2316, 611, 337, 264, 24028, 15995, 307, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.2126802603403727, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.0009840771090239286}, {"id": 595, "seek": 289292, "start": 2911.4, "end": 2916.92, "text": " Do we have more room for questions?", "tokens": [1144, 321, 362, 544, 1808, 337, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2126802603403727, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.0009840771090239286}, {"id": 596, "seek": 289292, "start": 2916.92, "end": 2917.92, "text": " I think it's done.", "tokens": [286, 519, 309, 311, 1096, 13], "temperature": 0.0, "avg_logprob": -0.2126802603403727, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.0009840771090239286}, {"id": 597, "seek": 289292, "start": 2917.92, "end": 2918.92, "text": " Thank you so much.", "tokens": [1044, 291, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.2126802603403727, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.0009840771090239286}, {"id": 598, "seek": 289292, "start": 2918.92, "end": 2919.92, "text": " You'll be a wonderful audience.", "tokens": [509, 603, 312, 257, 3715, 4034, 13], "temperature": 0.0, "avg_logprob": -0.2126802603403727, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.0009840771090239286}, {"id": 599, "seek": 291992, "start": 2919.92, "end": 2925.92, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50664], "temperature": 0.0, "avg_logprob": -0.7432421843210856, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.0034738765098154545}], "language": "en"}