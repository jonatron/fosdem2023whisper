{"text": " So, hello, everyone. Thanks for joining us today to the Postgres Dayroom. Our next speaker is Chris Trevers, who flew all the way from Indonesia. Thank you. And he's going to talk about why database teams need human factor training. Thank you. Thank you very much for coming to this talk. I think it's certainly one of the topics I'm most excited about when it comes to database-related topics, actually, even though I'm very, very much into Postgres. This topic really excites me. So, just introducing myself a bit for those who don't know me. I have a bit over 24 years of experience in Postgres, so almost 25 years. I've built accounting software on it. I have worked as a database administrator on very large databases, built database teams, managed infrastructure, a lot of that sort of thing. So, I have a wide range of experience. I have submitted several patches in for Postgres, so which one has been accepted, and I'll probably be submitting more patches at some point in the future. So, I absolutely love Postgres for its extensibility. And with that, of course, comes some complexity, some difficulties in kind of maintaining our mental models about how things are actually working. And especially if you're working at things in scale, it's really easy for your mental model not to match what's actually happening, and then sometimes we make mistakes and things happen. So, this talk is basically going to be about two things. The first thing is something our industry doesn't do very well. And that is how we look at human error, and how we can possibly do that better. I kind of want to talk a little bit about how we can improve, and what the benefits are that we can expect from some of the early steps that we can take as an industry. So, this is very much a talk about database people. It's a talk about us. It's much less a talk about like a specific technology. But a lot of the same technical approaches apply. So, I want to give a few thanks, first of all, timescale for paying me to come and do this. Wouldn't really be feasible for me to fly from an issue without them. But I also really want to thank two of my prior employers. I want to thank Adjust, where we were actually able to bring in aviation training on these human factors. So, we brought in a company that did training for pilots, as well as doctors. And a lot of the training was really eye-opening, and it allowed us to do some things that we couldn't do before. This was really a grand experiment, and it had a number of really big, tangible benefits. And then, of course, I also want to thank Delivery Hero, who I worked after that, where I was able to kind of work with people and evaluate both the successes and the shortcomings of what we had done at Adjust, and further develop some of these ideas. So, these are important areas, and I would also say that I'm involved in trying to help implement some of these things also at timescale. So, introduction. So, just as a, this is a completely rhetorical question. You don't have to raise your hand if you don't feel comfortable doing so. But how many of us have been on a team where somebody has been working on a production database while they're drunk? Yes, I see. I mean, as we go through our career, almost every single one of us will probably have that experience. And yet, how many times does it cause a major problem? Almost never. At least, I've never seen it cause a major problem. Now, part of that may be the context in which it happens, like, you know, the subject matter experts spent out partying was not expecting to, was not really on call and has now been called in an escalation. Somebody else may be handling a lot of the sort of wider incident strategy stuff where maybe alcohol might be a bigger problem. But at least in these contexts, alcohol doesn't seem to be a big factor in the further disruption of things once stuff's going on. But let me ask another question. How many people here have seen a case where a major incident or outage happened because somebody made a mistake because that person was tired? See? So, we valorize the thing that causes us problems. Well, we demonize something that probably does cause some problems, no doubt. And maybe the demonization helps prevent more problems, but we valorize something that causes a lot more problems. Okay? Why isn't we do that? How is it that we should stop doing that and actually we think our priorities? Now, on one side, this is a good example of human error, right? We can talk about all the factors that go into that prioritization. But on the other side, it's also partly because we don't understand human error in our field, right? When we do a post-mortem, if somebody made a mistake, we just say, oh, human error, and that's it. I'm going to come back to that point in a few minutes. So, drunkenness versus fatigue. Now, if one person drinks, say, a bottle of wine, and another person, one group of people drinks each a bottle of wine, and the other group of the people has, say, their sleep disrupted, so they're only sleeping four hours, and then get up, and a few hours later, they're in the other group. Give both of them complex tasks to perform. Who's going to perform worse? Sleep deprivation causes heavier cognitive deficiencies. Four hours of sleep, missing sleep, is worse than four drinks. Now, obviously, there are some tasks where that's not the case, like driving a car or something, because you also have coordination problems induced by the alcohol. From a peer information processing standpoint, having four hours of sleep only is worse than drinking a bottle of wine, and it's going to last at least the next day. So, totally, totally worth thinking about that. So, now that I've talked about, like, one aspect of human error, one thing that can induce a lot of human error, I want to talk about a brief history of why this field became really big in aviation. So, back in the 1950s, 1960s, 80% of the aircraft accidents or incidents were blamed on pilot error. Notice I didn't say human error, I said pilot error. I'm going to come back to that distinction in a moment. In fact, I think the number might have been closer than 90%. Today, our incident and accident rates in airlines are well over 100 times lower than they were at that point. So, if you think about it, improvements in the technology in men and of the airplanes could only account for maybe 10% of that improvement. All of the rest of this is due to much better understanding of the question of human error. There's been a shift from focusing on pilot error to focusing on human error. When the aviation industry talks about human error, they don't mean somebody made a mistake, and that's where they leave it. They have a rich taxonomy of understanding kinds of human error, causes of each of these particular types of errors, and sort of practices to try to mitigate them. The way I would actually describe this difference is that if you're debugging software and it's connecting to the database, and every time, let's say you have an error in your query or something the database can't fulfill your request, it just says something went wrong. You're not going to be able to debug that software at all, and you're probably going to have a lot of trouble. That's kind of what we do currently when we say human error. We just simply say the person made a mistake, and that's as far usually as we look. The aircraft industry has actually come up with something with a much richer understanding of this topic and sort of richer system of almost like error codes that they use when they talk about these issues. The reason is it's a very unforgiving environment. If you make a mistake, you might or might not be able to recover, so you have a lot of training on this, and now the chance of a massive disaster is down probably one error disaster per billion takeoffs, which is really impressive. We'd love to have that. So they've made this shift. They've also made a shift that we've already made, and it's worth pointing this out, and that's that they've made a shift from individual responsibility to collective responsibility. In our terms, we call that blameless culture. Somebody makes a mistake. We don't blame them. We don't go, hey, stop making mistakes. We try to find some way to keep that mistake from happening, but because we don't have a clear understanding of this topic, we try to solve this in ways that maybe aren't as effective as they could be. I want to give one really good example of sort of a watershed moment. Actually, before I talk about that, let me just discuss David Beatty's contribution quickly. Beatty was a cognitive psychologist and pilot in the U.K., and in 1969, he wrote a seminal book called The Human Factor in Aircraft Accidents, where he basically looked at the kinds of mistakes that happen and the kinds of circumstances that lead to those mistakes. There are newer versions of that book out now. It's actually worth reading, but probably not best to read if you're a nervous flyer. As a good description of how we break down error, it was the industry starting point. Ten years after that, there was I think the watershed moment in how this became really big within aviation, and that was the Tenerife disaster. Tenerife disaster was the most deadly aircraft accident still in history. It happened on the ground in Tenerife due to a variety of factors. I'm not sure how much detail I should go into in this talk, but the end result was basically that 1-747 tried to take off down a runway with limited visibility without a proper takeoff clearance, and they hit another 747 on the ground. Clear case of human error, and the Spanish report on this more or less blamed it on pilot error. This guy tried to take off. He didn't have the clearance. It was his fault. The Dutch report, which is often criticized in some documentaries that I've seen on this, was very, very different. What they actually did was they asked, why did he try to take off without clearance? What was going through, how did that mistake happen? The thing was, he was an extremely experienced pilot. He was their chief pilot. He actually didn't fly airplanes that much. He was mostly sitting on simulators. The thing was, at that time, when you were the senior pilot in the simulator, you were giving the clearances. A stressful situation, visibility is slow, there's pressure to take off, stressful situation. He goes back to what he's used to doing, which is assuming he has the clearance because he's used to giving them to himself. Airlines don't do that anymore in their simulators, for obvious reasons. The Dutch report actually became the basis for how the aviation industry has started to look at human error ever since. As a result, what we've seen is we've seen this massive, massive improvement in safety. Every pilot in every airline gets this sort of training, and it has made our flights much, much, much, much safer. The question is, can we benefit from the same thing? The answer is yes. We actually can get a lot more benefits from it than just reducing incidents and recovering from them. In fact, if you look at the standard definition that people give of crew resource management, it's the use of all available resources to ensure the safe and efficient operation of the aircraft. If we can use all of our resources to improve both safety and efficiency, that's going to make our jobs better, we're going to be more productive, we're going to be happier. This is actually a really, really important field that I think that we need to improve on. Now I'm going to talk about how we look at human error in the industry. Human error typically in the DevOps and SRE systems, we have one answer to human error. What that is, automation. If somebody made a mistake, we're going to automate that away. We're just going to add more automation. We're going to add more automation. It seems like a great idea. Computers are infallible, we're fallible, so we're just going to use the computers to prevent the mistake. The problem with this, the IEEE has done a bunch of research on something they call the automation paradox. The automation paradox is that the more reliable the automation is, the less opportunities humans have to contribute to the overall success of that. I think I'm going to take a little bit of time here to talk about why that is the case, and then I'll get reinforced in the next section when we talk about why we make mistakes. But to start with a basic summary, obviously we need automation because there are certain kinds of tasks that we're actually very bad at following, and there are certain kinds of requirements where automation can really save us a lot of safety considerations. So steps that have to be done together really should be automated so that they happen together. But automation is just done reflexively, at least according to a lot of the research that's come out of the IEEE as well as many of the aviation study groups on this, is that simply throwing automation at a problem can actually make human error more common and can make human error more severe, and then when things are out of whack, you have no possibility at all of saving, of preventing a major incident. Part of the reason here is that we process all of what we see through a mental model, and so when we add more complexity, when we add more automation around a lot of this, we make it really, really, really, really, really hard for us to keep that mental model reasonably in sync with reality. And then when something goes wrong, we can spend a lot of time and effort struggling to understand what's going on, or we may reflexively react in ways which actually make the problem worse. So automation isn't the answer, it is part of an answer. And reflexive automation, oh, we had a problem that's automated away, is not the answer. Now, I mentioned just a moment ago this issue of mental models. We humans, we operate in a world that's very different from the way computers operate. Computers are basically systems that mathematically process inputs and produce outputs, right? And therefore, computing programs basically operate in a closed world. We humans don't operate in closed worlds, right? We all operate in open worlds. We have the situation where we know we don't know everything. We know we don't know some things. We know, well, and then we don't know other things that we don't know we don't know, right? Some cases we know we don't know what we don't know, right? But in order to function, we have to maintain these mental models, and those mental models are necessarily a simplification of reality. And so when something's going wrong, we have to dig into how we think the system works and we have to kind of go through that. And the more complexity we throw into our automation, the harder that process becomes, right? So automation, as I say, is an important tool. I'm going to talk in a few moments about good automation versus bad automation, but it's something that we can't rely on to solve the human error problem. So I mentioned that I talked about good automation versus bad automation. I think this is really, really, really important here. So oftentimes what I've seen happen is that you end up with large automated systems, whether they're something like Ansible or Rax or Kubernetes or whatever. And oftentimes there isn't a clear understanding of how these things work underneath. Now, if people do understand all of that, and they've built in a lot of these things, then a lot of that's going to be a lot easier, right? So good automation is basically going to be a deliberate and engineered process, right? Rather than something that's thrown together in the course of the messy world of operations, it is a deliberate process which is designed around two factors and three factors, actually. The first factor is the system, right? The second factor is the people, and we usually forget that one. And then the last one is that we actually need to be thinking about the human machine interaction, right? So good automation takes the people into account. Good automation is something which has built in decision points where the person can actually sit there and say, hmm, this isn't going right. We're not going to proceed, right? And good automation is sort of then a well-understood process, right? So the other thing that is really important as we look at automation is this issue of feedback, right? Because the more we automate, typically the more we insulate the individual from the feedback of the individual steps that would be right, right? So it's really super important to sit down and think about what's the person going to see? What's the human going to see? How's the human going to be able to interpret this? How much feedback do we want to send? Do we want to send everything that we got? Do we want to send some summary of it? And those are going to be decisions that have to be made deliberately based upon the context of what we're doing, as well as a clear understanding of what the failure cases of the automation are. And then of course people actually need to be trained on what the automation is actually doing under the hood so that they understand it, rather than just simply saying, oh, push button, okay, everything good. So the way I always look at it is a lot of people think automation basically, a lot of people think checklists are a step towards automation. I think that automation should be a step towards a checklist, okay? The relationship should actually be something around on the other side so that you're thinking about how do I want the human to interact with this? How do I want the human to perform these? Where do I want the human to be able to say this isn't going while we are stopping? And those are the sorts of questions and designs that we have to think about when we're dealing with especially these sorts of critical systems like the databases, where if the database is down, you know, the business maybe now. So now I want to talk a little bit about why we make mistakes. Now, I'm mentioned before, computers operate in a closed world, right? They get inputs from us. They do processing. They give us outputs, right? We live in an open world. We have, we experience things, we perceive things. What we perceive is not a complete model of, or it's not even complete aspect of what our mental models are. We make inferences based on incomplete data, okay? And in order to function in this world, we have had to adapt and develop certain kinds of cognitive biases, okay? And a lot of times people look at this and they go, oh, it's not good to be biased. Bias is a bad word. We don't like biases. But the fact of the matter is that if you could get rid of all of your cognitive biases, you would be unable to function, okay? Confirmation bias, of course, is one thing that we tend to be aware of. But here's another one, continuation bias. Continuation bias is the tendency to continue to follow a plan you've put in motion, even when you're starting to get good indications that that's not a good idea, okay? If you didn't have continuation bias, you might have to sit down and rethink your plan continuously over and over and over again, right? That wouldn't be very helpful. So continuation bias, just like confirmation bias, actually helps us function in the real world. Problem is, it can also lead us into situations where we do the wrong thing. And so understanding these biases, understanding their implications is very clear, is a very important step to being able to notice when they're causing problems and start to trap those sorts of problems. So rather than trying to eliminate our biases, which is, I think, a way in which I see people typically trying to do this, is better to think about what kinds of problems the biases can cause and how we can detect and trap those problems, right? And there are a large number of these biases, right? Expectation bias. Expectation bias is also related to confirmation bias. It's the tendency to filter out perceptions that don't match your expectations, right? This happens today in a lot of environments. It happens in our industry. It obviously still happens in aviation, fortunately, usually not with serious problems. The most common problem it causes there is that the plane comes up to the gate, the pilot says disarmed doors and cross check. Somebody misses the door that's going to be opened. The other person cross checks and expectation bias kicks in and they don't notice that the door is still armed. Go to open the door and guess what happens. Emergency slide deploys. It doesn't harm anybody on the airplane, but it's going to make a bunch of people unhappy because the next leg on the airplane's flight is going to get canceled. And that's usually the worst that happens. But these are important things and we have to recognize that these sorts of biases are going to happen and that our ability to maintain a situation awareness in the course of these biases is very much tied to, very much tied to how aware we are of the kinds of problems that they can cause, right? Because, you know, we form this mental model. We're going to interpret things according to that mental model. We're going to continue our existing plans and things like that. And when somebody says, hey, wait, maybe this isn't right, then that's suddenly an opportunity to go, hey, my bias is maybe leading me astray. Let's sit down and figure out what's going on and verify. And human factors training actually tends to include exercises or training specifically aimed at doing that. So, second major issue is reversion to prior behavior under stress. Something that happens to all of us when we're under stress, our focus narrows, right? We start filtering things out and we start resorting to habit. What this also means is that in a database team, when there's an outage, if we're not careful, we will resort to the things that we're used to doing, even if we have decided that they're not maybe the best ways forward. And, you know, I've watched cases where, you know, incidents happen and, you know, if a company has been really trying to move towards a more collaborative approach to incidents, that suddenly when the incident happens, people are getting stressed out and they're going back to this like hyper-individualistic cowboy incident response. And a lot of that is just simply due to stress. It's a very well-documented part of the stress response. One thing that we got at a just with the human factors training was a strong understanding of that problem as well as good understandings of how to measure the stress so that we could actually kind of keep an eye on it. Another major point that causes problems, and I've alluded to this before, is fatigue. How often do we see people who have a rough on call night, who come back in the next day and start working on stuff? How often are we willing to say to that person, no, go home, get some rest, I don't want you working on this stuff right now? Right? How often have we seen people who are on call for an extended time period and a rough shift make mistakes after several days of continuous sleep interruptions? You know, do we start to think about the question of maybe when this happens, we should be switching these people out more frequently. In the airlines, before any flight happens, the flight crew get together and they check out how each other are doing, right? And there is an expectation that there is a standby flight crew so that if you're not feeling your best, you can say, hey, I didn't sleep well last night, I don't want to fly. And that's another thing which has really helped the increase of the safety, something we should probably think about doing. You're getting tired from the on call, time to switch you out. Do we? I have never worked anywhere the day. So a final major point on how and why we make mistakes has to do with a term in human factors, Lingo, called workload. Now, I don't like this term in this context because when we say workload in here, everybody is thinking, oh, I have so many things I need to get done this month. But in the human factor side, workload doesn't mean over the next month or over the next week, although planning that can be helpful. What it really means is how many tasks are you having to pay attention to right now? How many people here can actually listen to and understand two conversations at the same time? Nobody? Maybe it's possible for some people to train that. But a brain can't, there are certain kinds of things that our brains can't parallelize very well. Understanding where those boundaries are. Switching and flipping between tasks. How much can we reduce that workload? That's actually really important because one of the things I've seen happen is you have your standard runbook and the way most people write their runbooks is you have step, explanation, discussion of output, next step. What happens at three in the morning if you've never done this particular process is step. Okay? Yes, it did what I expected to. Where's the next step? It becomes really, really, really easy to miss the next step in your checklist or to miss critical details that are kind of obscured in the fact that now you're having to read through paragraphs at three in the morning while troubleshooting a broken system. One of the things that I did while it was at adjust is I started writing some of our, I guess I would call them unusual procedure checklists. A non-normal procedure checklist. So things that happen when, things that you do when something goes wrong. Things that you might have to do at three in the morning without doing them for any of the previous three months. And what I ended up doing in this case, and it was actually, this is a good opportunity to talk about some of the main benefits of this sort of training, is that we talked about, we talked about basically what we did was we did the following format. It's a bullet point. Here's what you can ideally copy and paste into the terminal. Expected output, warning signs, all in bullet points and then back, unindented again, the next bullet point. So they're hierarchical, it's easy to scan, but then your main points are all really, really, really short. And then all of the major description that would be in those paragraphs would be moved into foot notes. And those would all be hyperlinked. So you run a test, you know, you run a step. Something doesn't look quite right, you want to see the longer description, you click that hyperlink, you come down to the footnote, you read the whole thing, decide if you want to proceed or not, and then decide. And what this allowed us to do was to take, like the standard platform team people who are on call and actually have them do error spike maintenance at three in the morning on, as I say, the super critical high-speed database system. And before that, every time there was an error spike issue, it was an automatic escalation. And it was automatic escalation because we didn't trust that they would be able to do it or make proper decisions around it. But since we formalized it into checklists and we offered some training on them, and we tried to make sure that people kind of understood the overall considerations of the processes, then they could do some basic stuff and then call us if there were questions that weren't obviously answered by the documentation. Every very, very good tangible benefit meant that instead of several people waking up in the middle of the night, they could be done by the on-call engineer. So that's a really good example of the benefits that come out of paying attention to that workload issue and the sensory overload that happens that's much more serious at three in the morning than at three in the afternoon. So at this point, it's really important to recognize that at this point, we're no longer really talking about human error being somebody made a mistake. Instead, we're talking about the need to be able to debug the person and why they made the mistake. And this is something which very often times we don't even try to do in our industry, but we should. This requires that we have a really good taxonomy of types of mistakes. That we can say, okay, situation awareness laps because of sensory overload from too many monitoring alerts going off. A very common one that happens in our industry. It's also something that's caused airplane issues. So if we understand that, we know, they lost their situation awareness. They couldn't understand where the problem was. This happened because they had too many alerts they were trying to focus on. Now the question is, are we actually throwing too many alerts? Do we need to think about maybe prioritizing things differently? Do we need to rethink how we do alerting? And suddenly, we have a dimension for looking at these problems that we currently don't have. Instead, currently, what happens most places I've worked is, okay, something went wrong. We didn't spot it. Therefore, let's add another alert over this. But when I was at the delivery here, we actually had a major incident where somebody, again, missed a problem relating to a database, relating to a Postgres instance, I believe, if I remember right. Despite the fact that it was well alerted. I was talking to somebody afterwards and he says, do you know what the false positivity rate of our alerts are? And I'm like, no, it's like 99.8%. How do you expect somebody to spot the problem when almost all the time our alerts don't mean there's a real problem? Okay. Now what he meant by false positivity isn't what I would mean by it. I mean, there were problems that the alerts were alerting about, but they weren't like customer facing problems, right? So the second thing is we need a really good understanding of our cognitive biases and the functions that they provide to us and also the problems that they can lead us into, right? So one of the good examples is, hey, look, you know, I know you're about to do this. I'm not sure that's what the problem is. Can we think about this first, right? And as soon as somebody says that, that means that they're saying, my mental model is not the same as your mental model. One of us is wrong. We should probably figure that out before we proceed. Figuring out how to do that's really, really important, especially when we talk about social factors involved, right? It's one thing to do that with your peer when you're on an incident call and there are two of you there. Something very different to do when the person typing the words is very senior and you're very junior and there's somebody C-level popping into the call to ask for an update. I've been there. I've done that and yes, no, I have not raised the issue and I should have, right? You know, figuring out how to make these sorts of interventions and how to understand the intervention and how to respond to it, those are things that we actually need training on, right? We also need training on the social factors. We need to understand how power distance affects these. What happens when there's, you know, the C-level person in the call? How does that change your social interactions? How does that change your interactions in terms of debugging, right? Those are important things and that's one thing that we can get some really big improvements on relating to this. Finally, it's really important for us to be able to get to the point where we can contextualize the person. In other words, since we operate as humans in a relatively heuristic manner, right? We need to understand what the situation the human was in when the mistake happened and that's another thing that these sorts of trainings can help with. So, I've talked a little bit about social factors here. Power distance is what it sounds like, you know, how big the difference is between the most powerful person in the interaction and the least powerful person in the interaction, where we want it to be kind of, you know, not quite equal but much closer instead of like this, maybe more like this and, you know, figuring out how to structure things so that power distance doesn't cause a problem. That also means giving people good training on how to intervene when they see somebody much more senior about to make a mistake, you know, and you want to intervene in a way which is not threatening and in the event where there's somebody even higher in the call isn't going to be perceived as humiliating, right? Having good training on this and how to communicate in those cases is really, really important. And a lot of this ends up playing out into trying to create a work relationship between the people on the team which is very heavily mutually supportive and also kind of helps prevent or checks and traps the kinds of mistakes that each of us can make. So let's talk a little bit about the ideal role of humans in database operations. Now, we kind of need to understand this well. Okay, ten? Okay. Who's checking? Five? Okay, perfect. We kind of need to understand this. Humans need to be in control. We need to be the decision makers. We need to be the people who can say, this is what I think is going on. Let's go ahead and try this process. And halfway through that process goes, this is not going well. Let's back off, rethink, and make another decision, right? Partly because we're also operating heuristically, we can do things that computers can't, right? We need to maintain really good situation awareness. This means we need to have transparency in our complex automation. We need the automation to be built around helping us, not replacing us. And to do this, we need to be well rested. We need to be a clear peak capability ideally when we're in the middle of an incident. Now, we may not be able to completely manage that last part, but if we can take steps towards it and we can try to improve, we can do better, right? So a lot of this training is, at least what I've gotten out of it, is really important. What I think is really important about this, I'll just talk quickly about how to go about doing it, is that if we can get the organizational leverage behind the training, then we can actually turn the promise of the training into the reality. Sometimes you can't just teach people something and then have the punishment abandoned them. That doesn't work. So as an industry, we treat human error the way pilot error was treated in the 1950s. We have a whole lot to learn from aviation. Those lessons are already being played out in medicine and many other fields today. We need to do what we can to learn from it also. And it's really important to recognize that we can get really good improvements in reliability, efficiency, speed of development, all these sorts of things if we can better work with the human side of things. And I'm not talking about human managers rating performance. I'm talking about people on the team understanding performance for themselves and others. I just want to say that the three pieces of this are trying to get trainers in who have experience. Also, an organizational commitment to make it happen and then internally building your own programs and your own recurring trainings and your own training for new people. So that internally you have a big culture around it and you have experts who can think about it when it comes to be a post-mortem. So that's what I have. Any questions? Thank you. That was an amazing talk. Do you have any recommendations for further reading if you can't bring in experts? So this is a field which an aviation has a massive textbook industry. I think probably the best, sort of the most accessible book I would recommend starting with is the more recent versions of David Beatty's human factors and aircraft accidents. I think the most recent version is called the naked pilot of human factors and aircraft accidents. It's just referring to exposing the inner workings of the human piece of the aircraft. But again, if you're a nervous flyer, probably look for a crew resource management textbook instead because it may be less nerve wracking, it may be less intimidating, but it will have information there too. Do you have any recommendations for testing or drilling your processes like those checklists? Yes, I do. One thing that I think we really should figure out how to do is an industry and I completely believe in this. Obviously, like the chaos monkey idea and Netflix could be exploited to do this if you can also build war games around it. But the thing is it's really important to have drills, which means oftentimes you've actually got to probably simulate or create some sort of a potential incident that you have to come together and resolve. Now, ideally, you need to figure out how to do this without threatening your customer-oriented services. In some cases, maybe the cloud's a really good opportunity for that. But having those sorts of drills, maybe once a quarter or twice a year or something, can really give you an opportunity to spot problems, figure out improvements and actually go figure out what to do about those. Just kind of building on that last point is how do you justify the expense in time or money? Given that if this is successful, then nothing goes wrong. So it can sometimes be the outcome of success is that you're spending a lot of effort on apparently doing nothing. I don't believe that, but that's a reasonable thing that gets asked. How do you go about justifying the time or the money on this after it's successful? What I've usually done in the past is I make my points about, yes, we're going to improve our incident response. This will reduce our time recovery. It'll improve our reliability, et cetera. Maybe it'll improve our throughput organizationally. But then usually, people don't listen. And then usually, there are more incidents. And then you can come in and say, you know, these are specific problems that we had here where this training would help. And I usually find that after two or three of those, people start listening and go, oh, really? Maybe there is something to this. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.24, "text": " So, hello, everyone. Thanks for joining us today to the Postgres Dayroom. Our next speaker", "tokens": [407, 11, 7751, 11, 1518, 13, 2561, 337, 5549, 505, 965, 281, 264, 10223, 45189, 5226, 2861, 13, 2621, 958, 8145], "temperature": 0.0, "avg_logprob": -0.34509725419301834, "compression_ratio": 1.396551724137931, "no_speech_prob": 0.44200557470321655}, {"id": 1, "seek": 0, "start": 12.24, "end": 17.8, "text": " is Chris Trevers, who flew all the way from Indonesia. Thank you. And he's going to talk", "tokens": [307, 6688, 8648, 840, 11, 567, 15728, 439, 264, 636, 490, 16879, 13, 1044, 291, 13, 400, 415, 311, 516, 281, 751], "temperature": 0.0, "avg_logprob": -0.34509725419301834, "compression_ratio": 1.396551724137931, "no_speech_prob": 0.44200557470321655}, {"id": 2, "seek": 0, "start": 17.8, "end": 23.68, "text": " about why database teams need human factor training. Thank you.", "tokens": [466, 983, 8149, 5491, 643, 1952, 5952, 3097, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.34509725419301834, "compression_ratio": 1.396551724137931, "no_speech_prob": 0.44200557470321655}, {"id": 3, "seek": 2368, "start": 23.68, "end": 34.36, "text": " Thank you very much for coming to this talk. I think it's certainly one of the topics I'm", "tokens": [1044, 291, 588, 709, 337, 1348, 281, 341, 751, 13, 286, 519, 309, 311, 3297, 472, 295, 264, 8378, 286, 478], "temperature": 0.0, "avg_logprob": -0.1323429652622768, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.00011580781574593857}, {"id": 4, "seek": 2368, "start": 34.36, "end": 41.36, "text": " most excited about when it comes to database-related topics, actually, even though I'm very, very", "tokens": [881, 2919, 466, 562, 309, 1487, 281, 8149, 12, 12004, 8378, 11, 767, 11, 754, 1673, 286, 478, 588, 11, 588], "temperature": 0.0, "avg_logprob": -0.1323429652622768, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.00011580781574593857}, {"id": 5, "seek": 2368, "start": 41.36, "end": 48.2, "text": " much into Postgres. This topic really excites me. So, just introducing myself a bit for", "tokens": [709, 666, 10223, 45189, 13, 639, 4829, 534, 1624, 3324, 385, 13, 407, 11, 445, 15424, 2059, 257, 857, 337], "temperature": 0.0, "avg_logprob": -0.1323429652622768, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.00011580781574593857}, {"id": 6, "seek": 4820, "start": 48.2, "end": 54.0, "text": " those who don't know me. I have a bit over 24 years of experience in Postgres, so almost", "tokens": [729, 567, 500, 380, 458, 385, 13, 286, 362, 257, 857, 670, 4022, 924, 295, 1752, 294, 10223, 45189, 11, 370, 1920], "temperature": 0.0, "avg_logprob": -0.13114632500542533, "compression_ratio": 1.6383928571428572, "no_speech_prob": 7.001505582593381e-05}, {"id": 7, "seek": 4820, "start": 54.0, "end": 60.24, "text": " 25 years. I've built accounting software on it. I have worked as a database administrator", "tokens": [3552, 924, 13, 286, 600, 3094, 19163, 4722, 322, 309, 13, 286, 362, 2732, 382, 257, 8149, 25529], "temperature": 0.0, "avg_logprob": -0.13114632500542533, "compression_ratio": 1.6383928571428572, "no_speech_prob": 7.001505582593381e-05}, {"id": 8, "seek": 4820, "start": 60.24, "end": 67.44, "text": " on very large databases, built database teams, managed infrastructure, a lot of that sort", "tokens": [322, 588, 2416, 22380, 11, 3094, 8149, 5491, 11, 6453, 6896, 11, 257, 688, 295, 300, 1333], "temperature": 0.0, "avg_logprob": -0.13114632500542533, "compression_ratio": 1.6383928571428572, "no_speech_prob": 7.001505582593381e-05}, {"id": 9, "seek": 4820, "start": 67.44, "end": 72.32000000000001, "text": " of thing. So, I have a wide range of experience. I have submitted several patches in for Postgres,", "tokens": [295, 551, 13, 407, 11, 286, 362, 257, 4874, 3613, 295, 1752, 13, 286, 362, 14405, 2940, 26531, 294, 337, 10223, 45189, 11], "temperature": 0.0, "avg_logprob": -0.13114632500542533, "compression_ratio": 1.6383928571428572, "no_speech_prob": 7.001505582593381e-05}, {"id": 10, "seek": 7232, "start": 72.32, "end": 78.11999999999999, "text": " so which one has been accepted, and I'll probably be submitting more patches at some point in", "tokens": [370, 597, 472, 575, 668, 9035, 11, 293, 286, 603, 1391, 312, 31836, 544, 26531, 412, 512, 935, 294], "temperature": 0.0, "avg_logprob": -0.16282428292667164, "compression_ratio": 1.5423728813559323, "no_speech_prob": 9.343456440547016e-06}, {"id": 11, "seek": 7232, "start": 78.11999999999999, "end": 86.08, "text": " the future. So, I absolutely love Postgres for its extensibility. And with that, of course,", "tokens": [264, 2027, 13, 407, 11, 286, 3122, 959, 10223, 45189, 337, 1080, 1279, 694, 2841, 13, 400, 365, 300, 11, 295, 1164, 11], "temperature": 0.0, "avg_logprob": -0.16282428292667164, "compression_ratio": 1.5423728813559323, "no_speech_prob": 9.343456440547016e-06}, {"id": 12, "seek": 7232, "start": 86.08, "end": 91.16, "text": " comes some complexity, some difficulties in kind of maintaining our mental models about", "tokens": [1487, 512, 14024, 11, 512, 14399, 294, 733, 295, 14916, 527, 4973, 5245, 466], "temperature": 0.0, "avg_logprob": -0.16282428292667164, "compression_ratio": 1.5423728813559323, "no_speech_prob": 9.343456440547016e-06}, {"id": 13, "seek": 7232, "start": 91.16, "end": 98.44, "text": " how things are actually working. And especially if you're working at things in scale, it's", "tokens": [577, 721, 366, 767, 1364, 13, 400, 2318, 498, 291, 434, 1364, 412, 721, 294, 4373, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.16282428292667164, "compression_ratio": 1.5423728813559323, "no_speech_prob": 9.343456440547016e-06}, {"id": 14, "seek": 9844, "start": 98.44, "end": 103.36, "text": " really easy for your mental model not to match what's actually happening, and then sometimes", "tokens": [534, 1858, 337, 428, 4973, 2316, 406, 281, 2995, 437, 311, 767, 2737, 11, 293, 550, 2171], "temperature": 0.0, "avg_logprob": -0.11003632256478975, "compression_ratio": 1.5494505494505495, "no_speech_prob": 7.515344350395026e-06}, {"id": 15, "seek": 9844, "start": 103.36, "end": 113.32, "text": " we make mistakes and things happen. So, this talk is basically going to be about two things.", "tokens": [321, 652, 8038, 293, 721, 1051, 13, 407, 11, 341, 751, 307, 1936, 516, 281, 312, 466, 732, 721, 13], "temperature": 0.0, "avg_logprob": -0.11003632256478975, "compression_ratio": 1.5494505494505495, "no_speech_prob": 7.515344350395026e-06}, {"id": 16, "seek": 9844, "start": 113.32, "end": 122.6, "text": " The first thing is something our industry doesn't do very well. And that is how we look at human", "tokens": [440, 700, 551, 307, 746, 527, 3518, 1177, 380, 360, 588, 731, 13, 400, 300, 307, 577, 321, 574, 412, 1952], "temperature": 0.0, "avg_logprob": -0.11003632256478975, "compression_ratio": 1.5494505494505495, "no_speech_prob": 7.515344350395026e-06}, {"id": 17, "seek": 12260, "start": 122.6, "end": 131.28, "text": " error, and how we can possibly do that better. I kind of want to talk a little bit about", "tokens": [6713, 11, 293, 577, 321, 393, 6264, 360, 300, 1101, 13, 286, 733, 295, 528, 281, 751, 257, 707, 857, 466], "temperature": 0.0, "avg_logprob": -0.10994397440264302, "compression_ratio": 1.6904761904761905, "no_speech_prob": 6.129522716946667e-06}, {"id": 18, "seek": 12260, "start": 131.28, "end": 137.79999999999998, "text": " how we can improve, and what the benefits are that we can expect from some of the early", "tokens": [577, 321, 393, 3470, 11, 293, 437, 264, 5311, 366, 300, 321, 393, 2066, 490, 512, 295, 264, 2440], "temperature": 0.0, "avg_logprob": -0.10994397440264302, "compression_ratio": 1.6904761904761905, "no_speech_prob": 6.129522716946667e-06}, {"id": 19, "seek": 12260, "start": 137.79999999999998, "end": 144.88, "text": " steps that we can take as an industry. So, this is very much a talk about database people.", "tokens": [4439, 300, 321, 393, 747, 382, 364, 3518, 13, 407, 11, 341, 307, 588, 709, 257, 751, 466, 8149, 561, 13], "temperature": 0.0, "avg_logprob": -0.10994397440264302, "compression_ratio": 1.6904761904761905, "no_speech_prob": 6.129522716946667e-06}, {"id": 20, "seek": 12260, "start": 144.88, "end": 151.76, "text": " It's a talk about us. It's much less a talk about like a specific technology. But a lot", "tokens": [467, 311, 257, 751, 466, 505, 13, 467, 311, 709, 1570, 257, 751, 466, 411, 257, 2685, 2899, 13, 583, 257, 688], "temperature": 0.0, "avg_logprob": -0.10994397440264302, "compression_ratio": 1.6904761904761905, "no_speech_prob": 6.129522716946667e-06}, {"id": 21, "seek": 15176, "start": 151.76, "end": 158.67999999999998, "text": " of the same technical approaches apply. So, I want to give a few thanks, first of all,", "tokens": [295, 264, 912, 6191, 11587, 3079, 13, 407, 11, 286, 528, 281, 976, 257, 1326, 3231, 11, 700, 295, 439, 11], "temperature": 0.0, "avg_logprob": -0.16114528612657028, "compression_ratio": 1.5739910313901346, "no_speech_prob": 1.746521593304351e-05}, {"id": 22, "seek": 15176, "start": 158.67999999999998, "end": 165.2, "text": " timescale for paying me to come and do this. Wouldn't really be feasible for me to fly", "tokens": [1413, 37088, 337, 6229, 385, 281, 808, 293, 360, 341, 13, 26291, 380, 534, 312, 26648, 337, 385, 281, 3603], "temperature": 0.0, "avg_logprob": -0.16114528612657028, "compression_ratio": 1.5739910313901346, "no_speech_prob": 1.746521593304351e-05}, {"id": 23, "seek": 15176, "start": 165.2, "end": 171.0, "text": " from an issue without them. But I also really want to thank two of my prior employers. I", "tokens": [490, 364, 2734, 1553, 552, 13, 583, 286, 611, 534, 528, 281, 1309, 732, 295, 452, 4059, 16744, 13, 286], "temperature": 0.0, "avg_logprob": -0.16114528612657028, "compression_ratio": 1.5739910313901346, "no_speech_prob": 1.746521593304351e-05}, {"id": 24, "seek": 15176, "start": 171.0, "end": 177.35999999999999, "text": " want to thank Adjust, where we were actually able to bring in aviation training on these", "tokens": [528, 281, 1309, 34049, 11, 689, 321, 645, 767, 1075, 281, 1565, 294, 28831, 3097, 322, 613], "temperature": 0.0, "avg_logprob": -0.16114528612657028, "compression_ratio": 1.5739910313901346, "no_speech_prob": 1.746521593304351e-05}, {"id": 25, "seek": 17736, "start": 177.36, "end": 185.4, "text": " human factors. So, we brought in a company that did training for pilots, as well as doctors.", "tokens": [1952, 6771, 13, 407, 11, 321, 3038, 294, 257, 2237, 300, 630, 3097, 337, 21506, 11, 382, 731, 382, 8778, 13], "temperature": 0.0, "avg_logprob": -0.15654761974628156, "compression_ratio": 1.5844748858447488, "no_speech_prob": 2.70483797066845e-05}, {"id": 26, "seek": 17736, "start": 185.4, "end": 189.48000000000002, "text": " And a lot of the training was really eye-opening, and it allowed us to do some things that we", "tokens": [400, 257, 688, 295, 264, 3097, 390, 534, 3313, 12, 404, 4559, 11, 293, 309, 4350, 505, 281, 360, 512, 721, 300, 321], "temperature": 0.0, "avg_logprob": -0.15654761974628156, "compression_ratio": 1.5844748858447488, "no_speech_prob": 2.70483797066845e-05}, {"id": 27, "seek": 17736, "start": 189.48000000000002, "end": 196.44000000000003, "text": " couldn't do before. This was really a grand experiment, and it had a number of really", "tokens": [2809, 380, 360, 949, 13, 639, 390, 534, 257, 2697, 5120, 11, 293, 309, 632, 257, 1230, 295, 534], "temperature": 0.0, "avg_logprob": -0.15654761974628156, "compression_ratio": 1.5844748858447488, "no_speech_prob": 2.70483797066845e-05}, {"id": 28, "seek": 17736, "start": 196.44000000000003, "end": 202.02, "text": " big, tangible benefits. And then, of course, I also want to thank Delivery", "tokens": [955, 11, 27094, 5311, 13, 400, 550, 11, 295, 1164, 11, 286, 611, 528, 281, 1309, 5831, 8549], "temperature": 0.0, "avg_logprob": -0.15654761974628156, "compression_ratio": 1.5844748858447488, "no_speech_prob": 2.70483797066845e-05}, {"id": 29, "seek": 20202, "start": 202.02, "end": 208.24, "text": " Hero, who I worked after that, where I was able to kind of work with people and evaluate", "tokens": [14731, 11, 567, 286, 2732, 934, 300, 11, 689, 286, 390, 1075, 281, 733, 295, 589, 365, 561, 293, 13059], "temperature": 0.0, "avg_logprob": -0.12420951786325939, "compression_ratio": 1.5, "no_speech_prob": 1.944579344126396e-05}, {"id": 30, "seek": 20202, "start": 208.24, "end": 213.32000000000002, "text": " both the successes and the shortcomings of what we had done at Adjust, and further develop", "tokens": [1293, 264, 26101, 293, 264, 2099, 49886, 295, 437, 321, 632, 1096, 412, 34049, 11, 293, 3052, 1499], "temperature": 0.0, "avg_logprob": -0.12420951786325939, "compression_ratio": 1.5, "no_speech_prob": 1.944579344126396e-05}, {"id": 31, "seek": 20202, "start": 213.32000000000002, "end": 223.32000000000002, "text": " some of these ideas. So, these are important areas, and I would also say that I'm involved", "tokens": [512, 295, 613, 3487, 13, 407, 11, 613, 366, 1021, 3179, 11, 293, 286, 576, 611, 584, 300, 286, 478, 3288], "temperature": 0.0, "avg_logprob": -0.12420951786325939, "compression_ratio": 1.5, "no_speech_prob": 1.944579344126396e-05}, {"id": 32, "seek": 22332, "start": 223.32, "end": 234.07999999999998, "text": " in trying to help implement some of these things also at timescale. So, introduction.", "tokens": [294, 1382, 281, 854, 4445, 512, 295, 613, 721, 611, 412, 1413, 37088, 13, 407, 11, 9339, 13], "temperature": 0.0, "avg_logprob": -0.1660116740635463, "compression_ratio": 1.5416666666666667, "no_speech_prob": 8.792141670710407e-06}, {"id": 33, "seek": 22332, "start": 234.07999999999998, "end": 240.48, "text": " So, just as a, this is a completely rhetorical question. You don't have to raise your hand", "tokens": [407, 11, 445, 382, 257, 11, 341, 307, 257, 2584, 24182, 284, 804, 1168, 13, 509, 500, 380, 362, 281, 5300, 428, 1011], "temperature": 0.0, "avg_logprob": -0.1660116740635463, "compression_ratio": 1.5416666666666667, "no_speech_prob": 8.792141670710407e-06}, {"id": 34, "seek": 22332, "start": 240.48, "end": 245.88, "text": " if you don't feel comfortable doing so. But how many of us have been on a team where somebody", "tokens": [498, 291, 500, 380, 841, 4619, 884, 370, 13, 583, 577, 867, 295, 505, 362, 668, 322, 257, 1469, 689, 2618], "temperature": 0.0, "avg_logprob": -0.1660116740635463, "compression_ratio": 1.5416666666666667, "no_speech_prob": 8.792141670710407e-06}, {"id": 35, "seek": 22332, "start": 245.88, "end": 249.84, "text": " has been working on a production database while they're drunk?", "tokens": [575, 668, 1364, 322, 257, 4265, 8149, 1339, 436, 434, 11192, 30], "temperature": 0.0, "avg_logprob": -0.1660116740635463, "compression_ratio": 1.5416666666666667, "no_speech_prob": 8.792141670710407e-06}, {"id": 36, "seek": 24984, "start": 249.84, "end": 256.84000000000003, "text": " Yes, I see. I mean, as we go through our career, almost every single one of us will probably", "tokens": [1079, 11, 286, 536, 13, 286, 914, 11, 382, 321, 352, 807, 527, 3988, 11, 1920, 633, 2167, 472, 295, 505, 486, 1391], "temperature": 0.0, "avg_logprob": -0.17979326750102795, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.352848787268158e-05}, {"id": 37, "seek": 24984, "start": 256.84000000000003, "end": 267.84000000000003, "text": " have that experience. And yet, how many times does it cause a major problem? Almost never.", "tokens": [362, 300, 1752, 13, 400, 1939, 11, 577, 867, 1413, 775, 309, 3082, 257, 2563, 1154, 30, 12627, 1128, 13], "temperature": 0.0, "avg_logprob": -0.17979326750102795, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.352848787268158e-05}, {"id": 38, "seek": 24984, "start": 267.84000000000003, "end": 273.48, "text": " At least, I've never seen it cause a major problem. Now, part of that may be the context", "tokens": [1711, 1935, 11, 286, 600, 1128, 1612, 309, 3082, 257, 2563, 1154, 13, 823, 11, 644, 295, 300, 815, 312, 264, 4319], "temperature": 0.0, "avg_logprob": -0.17979326750102795, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.352848787268158e-05}, {"id": 39, "seek": 24984, "start": 273.48, "end": 278.04, "text": " in which it happens, like, you know, the subject matter experts spent out partying was not", "tokens": [294, 597, 309, 2314, 11, 411, 11, 291, 458, 11, 264, 3983, 1871, 8572, 4418, 484, 644, 1840, 390, 406], "temperature": 0.0, "avg_logprob": -0.17979326750102795, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.352848787268158e-05}, {"id": 40, "seek": 27804, "start": 278.04, "end": 283.20000000000005, "text": " expecting to, was not really on call and has now been called in an escalation. Somebody", "tokens": [9650, 281, 11, 390, 406, 534, 322, 818, 293, 575, 586, 668, 1219, 294, 364, 17871, 399, 13, 13463], "temperature": 0.0, "avg_logprob": -0.14001637194530073, "compression_ratio": 1.6036866359447004, "no_speech_prob": 1.721479566185735e-05}, {"id": 41, "seek": 27804, "start": 283.20000000000005, "end": 288.8, "text": " else may be handling a lot of the sort of wider incident strategy stuff where maybe", "tokens": [1646, 815, 312, 13175, 257, 688, 295, 264, 1333, 295, 11842, 9348, 5206, 1507, 689, 1310], "temperature": 0.0, "avg_logprob": -0.14001637194530073, "compression_ratio": 1.6036866359447004, "no_speech_prob": 1.721479566185735e-05}, {"id": 42, "seek": 27804, "start": 288.8, "end": 297.20000000000005, "text": " alcohol might be a bigger problem. But at least in these contexts, alcohol doesn't seem", "tokens": [7658, 1062, 312, 257, 3801, 1154, 13, 583, 412, 1935, 294, 613, 30628, 11, 7658, 1177, 380, 1643], "temperature": 0.0, "avg_logprob": -0.14001637194530073, "compression_ratio": 1.6036866359447004, "no_speech_prob": 1.721479566185735e-05}, {"id": 43, "seek": 27804, "start": 297.20000000000005, "end": 306.24, "text": " to be a big factor in the further disruption of things once stuff's going on. But let me", "tokens": [281, 312, 257, 955, 5952, 294, 264, 3052, 28751, 295, 721, 1564, 1507, 311, 516, 322, 13, 583, 718, 385], "temperature": 0.0, "avg_logprob": -0.14001637194530073, "compression_ratio": 1.6036866359447004, "no_speech_prob": 1.721479566185735e-05}, {"id": 44, "seek": 30624, "start": 306.24, "end": 313.16, "text": " ask another question. How many people here have seen a case where a major incident or", "tokens": [1029, 1071, 1168, 13, 1012, 867, 561, 510, 362, 1612, 257, 1389, 689, 257, 2563, 9348, 420], "temperature": 0.0, "avg_logprob": -0.12869134361361279, "compression_ratio": 1.6542056074766356, "no_speech_prob": 2.5042339984793216e-05}, {"id": 45, "seek": 30624, "start": 313.16, "end": 324.16, "text": " outage happened because somebody made a mistake because that person was tired? See? So, we", "tokens": [484, 609, 2011, 570, 2618, 1027, 257, 6146, 570, 300, 954, 390, 5868, 30, 3008, 30, 407, 11, 321], "temperature": 0.0, "avg_logprob": -0.12869134361361279, "compression_ratio": 1.6542056074766356, "no_speech_prob": 2.5042339984793216e-05}, {"id": 46, "seek": 30624, "start": 324.16, "end": 329.96000000000004, "text": " valorize the thing that causes us problems. Well, we demonize something that probably", "tokens": [15367, 1125, 264, 551, 300, 7700, 505, 2740, 13, 1042, 11, 321, 14283, 1125, 746, 300, 1391], "temperature": 0.0, "avg_logprob": -0.12869134361361279, "compression_ratio": 1.6542056074766356, "no_speech_prob": 2.5042339984793216e-05}, {"id": 47, "seek": 30624, "start": 329.96000000000004, "end": 335.88, "text": " does cause some problems, no doubt. And maybe the demonization helps prevent more problems,", "tokens": [775, 3082, 512, 2740, 11, 572, 6385, 13, 400, 1310, 264, 14283, 2144, 3665, 4871, 544, 2740, 11], "temperature": 0.0, "avg_logprob": -0.12869134361361279, "compression_ratio": 1.6542056074766356, "no_speech_prob": 2.5042339984793216e-05}, {"id": 48, "seek": 33588, "start": 335.88, "end": 343.2, "text": " but we valorize something that causes a lot more problems. Okay? Why isn't we do that?", "tokens": [457, 321, 15367, 1125, 746, 300, 7700, 257, 688, 544, 2740, 13, 1033, 30, 1545, 1943, 380, 321, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.146411190862241, "compression_ratio": 1.4216216216216215, "no_speech_prob": 7.52432379158563e-06}, {"id": 49, "seek": 33588, "start": 343.2, "end": 349.15999999999997, "text": " How is it that we should stop doing that and actually we think our priorities? Now, on", "tokens": [1012, 307, 309, 300, 321, 820, 1590, 884, 300, 293, 767, 321, 519, 527, 15503, 30, 823, 11, 322], "temperature": 0.0, "avg_logprob": -0.146411190862241, "compression_ratio": 1.4216216216216215, "no_speech_prob": 7.52432379158563e-06}, {"id": 50, "seek": 33588, "start": 349.15999999999997, "end": 357.92, "text": " one side, this is a good example of human error, right? We can talk about all the factors", "tokens": [472, 1252, 11, 341, 307, 257, 665, 1365, 295, 1952, 6713, 11, 558, 30, 492, 393, 751, 466, 439, 264, 6771], "temperature": 0.0, "avg_logprob": -0.146411190862241, "compression_ratio": 1.4216216216216215, "no_speech_prob": 7.52432379158563e-06}, {"id": 51, "seek": 35792, "start": 357.92, "end": 366.56, "text": " that go into that prioritization. But on the other side, it's also partly because we don't", "tokens": [300, 352, 666, 300, 14846, 2144, 13, 583, 322, 264, 661, 1252, 11, 309, 311, 611, 17031, 570, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.12390910951714766, "compression_ratio": 1.427027027027027, "no_speech_prob": 3.4453619264240842e-06}, {"id": 52, "seek": 35792, "start": 366.56, "end": 374.76, "text": " understand human error in our field, right? When we do a post-mortem, if somebody made", "tokens": [1223, 1952, 6713, 294, 527, 2519, 11, 558, 30, 1133, 321, 360, 257, 2183, 12, 76, 477, 443, 11, 498, 2618, 1027], "temperature": 0.0, "avg_logprob": -0.12390910951714766, "compression_ratio": 1.427027027027027, "no_speech_prob": 3.4453619264240842e-06}, {"id": 53, "seek": 35792, "start": 374.76, "end": 378.84000000000003, "text": " a mistake, we just say, oh, human error, and that's it. I'm going to come back to that", "tokens": [257, 6146, 11, 321, 445, 584, 11, 1954, 11, 1952, 6713, 11, 293, 300, 311, 309, 13, 286, 478, 516, 281, 808, 646, 281, 300], "temperature": 0.0, "avg_logprob": -0.12390910951714766, "compression_ratio": 1.427027027027027, "no_speech_prob": 3.4453619264240842e-06}, {"id": 54, "seek": 37884, "start": 378.84, "end": 388.08, "text": " point in a few minutes. So, drunkenness versus fatigue. Now, if one person drinks, say, a", "tokens": [935, 294, 257, 1326, 2077, 13, 407, 11, 1224, 39071, 1287, 5717, 20574, 13, 823, 11, 498, 472, 954, 12142, 11, 584, 11, 257], "temperature": 0.0, "avg_logprob": -0.16093432903289795, "compression_ratio": 1.7673267326732673, "no_speech_prob": 1.9505907403072342e-05}, {"id": 55, "seek": 37884, "start": 388.08, "end": 393.71999999999997, "text": " bottle of wine, and another person, one group of people drinks each a bottle of wine, and", "tokens": [7817, 295, 7209, 11, 293, 1071, 954, 11, 472, 1594, 295, 561, 12142, 1184, 257, 7817, 295, 7209, 11, 293], "temperature": 0.0, "avg_logprob": -0.16093432903289795, "compression_ratio": 1.7673267326732673, "no_speech_prob": 1.9505907403072342e-05}, {"id": 56, "seek": 37884, "start": 393.71999999999997, "end": 398.23999999999995, "text": " the other group of the people has, say, their sleep disrupted, so they're only sleeping", "tokens": [264, 661, 1594, 295, 264, 561, 575, 11, 584, 11, 641, 2817, 42271, 11, 370, 436, 434, 787, 8296], "temperature": 0.0, "avg_logprob": -0.16093432903289795, "compression_ratio": 1.7673267326732673, "no_speech_prob": 1.9505907403072342e-05}, {"id": 57, "seek": 37884, "start": 398.23999999999995, "end": 405.08, "text": " four hours, and then get up, and a few hours later, they're in the other group. Give both", "tokens": [1451, 2496, 11, 293, 550, 483, 493, 11, 293, 257, 1326, 2496, 1780, 11, 436, 434, 294, 264, 661, 1594, 13, 5303, 1293], "temperature": 0.0, "avg_logprob": -0.16093432903289795, "compression_ratio": 1.7673267326732673, "no_speech_prob": 1.9505907403072342e-05}, {"id": 58, "seek": 40508, "start": 405.08, "end": 415.32, "text": " of them complex tasks to perform. Who's going to perform worse? Sleep deprivation causes", "tokens": [295, 552, 3997, 9608, 281, 2042, 13, 2102, 311, 516, 281, 2042, 5324, 30, 19383, 27095, 11116, 7700], "temperature": 0.0, "avg_logprob": -0.13224916923336866, "compression_ratio": 1.3461538461538463, "no_speech_prob": 1.299440918955952e-05}, {"id": 59, "seek": 40508, "start": 415.32, "end": 423.0, "text": " heavier cognitive deficiencies. Four hours of sleep, missing sleep, is worse than four", "tokens": [18279, 15605, 19248, 31294, 13, 7451, 2496, 295, 2817, 11, 5361, 2817, 11, 307, 5324, 813, 1451], "temperature": 0.0, "avg_logprob": -0.13224916923336866, "compression_ratio": 1.3461538461538463, "no_speech_prob": 1.299440918955952e-05}, {"id": 60, "seek": 42300, "start": 423.0, "end": 435.52, "text": " drinks. Now, obviously, there are some tasks where that's not the case, like driving a", "tokens": [12142, 13, 823, 11, 2745, 11, 456, 366, 512, 9608, 689, 300, 311, 406, 264, 1389, 11, 411, 4840, 257], "temperature": 0.0, "avg_logprob": -0.13359978993733723, "compression_ratio": 1.481081081081081, "no_speech_prob": 5.76687079956173e-06}, {"id": 61, "seek": 42300, "start": 435.52, "end": 441.12, "text": " car or something, because you also have coordination problems induced by the alcohol. From a peer", "tokens": [1032, 420, 746, 11, 570, 291, 611, 362, 21252, 2740, 33991, 538, 264, 7658, 13, 3358, 257, 15108], "temperature": 0.0, "avg_logprob": -0.13359978993733723, "compression_ratio": 1.481081081081081, "no_speech_prob": 5.76687079956173e-06}, {"id": 62, "seek": 42300, "start": 441.12, "end": 451.32, "text": " information processing standpoint, having four hours of sleep only is worse than drinking", "tokens": [1589, 9007, 15827, 11, 1419, 1451, 2496, 295, 2817, 787, 307, 5324, 813, 7583], "temperature": 0.0, "avg_logprob": -0.13359978993733723, "compression_ratio": 1.481081081081081, "no_speech_prob": 5.76687079956173e-06}, {"id": 63, "seek": 45132, "start": 451.32, "end": 463.88, "text": " a bottle of wine, and it's going to last at least the next day. So, totally, totally worth", "tokens": [257, 7817, 295, 7209, 11, 293, 309, 311, 516, 281, 1036, 412, 1935, 264, 958, 786, 13, 407, 11, 3879, 11, 3879, 3163], "temperature": 0.0, "avg_logprob": -0.11970071923242856, "compression_ratio": 1.6144578313253013, "no_speech_prob": 4.215175522404024e-06}, {"id": 64, "seek": 45132, "start": 463.88, "end": 475.56, "text": " thinking about that. So, now that I've talked about, like, one aspect of human error, one", "tokens": [1953, 466, 300, 13, 407, 11, 586, 300, 286, 600, 2825, 466, 11, 411, 11, 472, 4171, 295, 1952, 6713, 11, 472], "temperature": 0.0, "avg_logprob": -0.11970071923242856, "compression_ratio": 1.6144578313253013, "no_speech_prob": 4.215175522404024e-06}, {"id": 65, "seek": 45132, "start": 475.56, "end": 480.64, "text": " thing that can induce a lot of human error, I want to talk about a brief history of why", "tokens": [551, 300, 393, 41263, 257, 688, 295, 1952, 6713, 11, 286, 528, 281, 751, 466, 257, 5353, 2503, 295, 983], "temperature": 0.0, "avg_logprob": -0.11970071923242856, "compression_ratio": 1.6144578313253013, "no_speech_prob": 4.215175522404024e-06}, {"id": 66, "seek": 48064, "start": 480.64, "end": 491.71999999999997, "text": " this field became really big in aviation. So, back in the 1950s, 1960s, 80% of the aircraft", "tokens": [341, 2519, 3062, 534, 955, 294, 28831, 13, 407, 11, 646, 294, 264, 18141, 82, 11, 16157, 82, 11, 4688, 4, 295, 264, 9465], "temperature": 0.0, "avg_logprob": -0.1323618623945448, "compression_ratio": 1.4408602150537635, "no_speech_prob": 8.006349162315018e-06}, {"id": 67, "seek": 48064, "start": 491.71999999999997, "end": 496.76, "text": " accidents or incidents were blamed on pilot error. Notice I didn't say human error, I", "tokens": [23875, 420, 21139, 645, 32027, 322, 9691, 6713, 13, 13428, 286, 994, 380, 584, 1952, 6713, 11, 286], "temperature": 0.0, "avg_logprob": -0.1323618623945448, "compression_ratio": 1.4408602150537635, "no_speech_prob": 8.006349162315018e-06}, {"id": 68, "seek": 48064, "start": 496.76, "end": 502.71999999999997, "text": " said pilot error. I'm going to come back to that distinction in a moment. In fact, I think", "tokens": [848, 9691, 6713, 13, 286, 478, 516, 281, 808, 646, 281, 300, 16844, 294, 257, 1623, 13, 682, 1186, 11, 286, 519], "temperature": 0.0, "avg_logprob": -0.1323618623945448, "compression_ratio": 1.4408602150537635, "no_speech_prob": 8.006349162315018e-06}, {"id": 69, "seek": 50272, "start": 502.72, "end": 511.16, "text": " the number might have been closer than 90%. Today, our incident and accident rates in", "tokens": [264, 1230, 1062, 362, 668, 4966, 813, 4289, 6856, 2692, 11, 527, 9348, 293, 6398, 6846, 294], "temperature": 0.0, "avg_logprob": -0.12368768598975205, "compression_ratio": 1.5594713656387664, "no_speech_prob": 4.634022843674757e-06}, {"id": 70, "seek": 50272, "start": 511.16, "end": 518.72, "text": " airlines are well over 100 times lower than they were at that point. So, if you think", "tokens": [37147, 366, 731, 670, 2319, 1413, 3126, 813, 436, 645, 412, 300, 935, 13, 407, 11, 498, 291, 519], "temperature": 0.0, "avg_logprob": -0.12368768598975205, "compression_ratio": 1.5594713656387664, "no_speech_prob": 4.634022843674757e-06}, {"id": 71, "seek": 50272, "start": 518.72, "end": 524.4, "text": " about it, improvements in the technology in men and of the airplanes could only account", "tokens": [466, 309, 11, 13797, 294, 264, 2899, 294, 1706, 293, 295, 264, 32947, 727, 787, 2696], "temperature": 0.0, "avg_logprob": -0.12368768598975205, "compression_ratio": 1.5594713656387664, "no_speech_prob": 4.634022843674757e-06}, {"id": 72, "seek": 50272, "start": 524.4, "end": 532.24, "text": " for maybe 10% of that improvement. All of the rest of this is due to much better understanding", "tokens": [337, 1310, 1266, 4, 295, 300, 10444, 13, 1057, 295, 264, 1472, 295, 341, 307, 3462, 281, 709, 1101, 3701], "temperature": 0.0, "avg_logprob": -0.12368768598975205, "compression_ratio": 1.5594713656387664, "no_speech_prob": 4.634022843674757e-06}, {"id": 73, "seek": 53224, "start": 532.24, "end": 539.32, "text": " of the question of human error. There's been a shift from focusing on pilot error to focusing", "tokens": [295, 264, 1168, 295, 1952, 6713, 13, 821, 311, 668, 257, 5513, 490, 8416, 322, 9691, 6713, 281, 8416], "temperature": 0.0, "avg_logprob": -0.10877040375110715, "compression_ratio": 1.7348837209302326, "no_speech_prob": 2.5810351871768944e-05}, {"id": 74, "seek": 53224, "start": 539.32, "end": 544.72, "text": " on human error. When the aviation industry talks about human error, they don't mean somebody", "tokens": [322, 1952, 6713, 13, 1133, 264, 28831, 3518, 6686, 466, 1952, 6713, 11, 436, 500, 380, 914, 2618], "temperature": 0.0, "avg_logprob": -0.10877040375110715, "compression_ratio": 1.7348837209302326, "no_speech_prob": 2.5810351871768944e-05}, {"id": 75, "seek": 53224, "start": 544.72, "end": 551.04, "text": " made a mistake, and that's where they leave it. They have a rich taxonomy of understanding", "tokens": [1027, 257, 6146, 11, 293, 300, 311, 689, 436, 1856, 309, 13, 814, 362, 257, 4593, 3366, 23423, 295, 3701], "temperature": 0.0, "avg_logprob": -0.10877040375110715, "compression_ratio": 1.7348837209302326, "no_speech_prob": 2.5810351871768944e-05}, {"id": 76, "seek": 53224, "start": 551.04, "end": 561.08, "text": " kinds of human error, causes of each of these particular types of errors, and sort of practices", "tokens": [3685, 295, 1952, 6713, 11, 7700, 295, 1184, 295, 613, 1729, 3467, 295, 13603, 11, 293, 1333, 295, 7525], "temperature": 0.0, "avg_logprob": -0.10877040375110715, "compression_ratio": 1.7348837209302326, "no_speech_prob": 2.5810351871768944e-05}, {"id": 77, "seek": 56108, "start": 561.08, "end": 567.2800000000001, "text": " to try to mitigate them. The way I would actually describe this difference is that if you're", "tokens": [281, 853, 281, 27336, 552, 13, 440, 636, 286, 576, 767, 6786, 341, 2649, 307, 300, 498, 291, 434], "temperature": 0.0, "avg_logprob": -0.17388995188587117, "compression_ratio": 1.7198443579766538, "no_speech_prob": 1.4723117601533886e-05}, {"id": 78, "seek": 56108, "start": 567.2800000000001, "end": 571.4000000000001, "text": " debugging software and it's connecting to the database, and every time, let's say you", "tokens": [45592, 4722, 293, 309, 311, 11015, 281, 264, 8149, 11, 293, 633, 565, 11, 718, 311, 584, 291], "temperature": 0.0, "avg_logprob": -0.17388995188587117, "compression_ratio": 1.7198443579766538, "no_speech_prob": 1.4723117601533886e-05}, {"id": 79, "seek": 56108, "start": 571.4000000000001, "end": 575.88, "text": " have an error in your query or something the database can't fulfill your request, it just", "tokens": [362, 364, 6713, 294, 428, 14581, 420, 746, 264, 8149, 393, 380, 13875, 428, 5308, 11, 309, 445], "temperature": 0.0, "avg_logprob": -0.17388995188587117, "compression_ratio": 1.7198443579766538, "no_speech_prob": 1.4723117601533886e-05}, {"id": 80, "seek": 56108, "start": 575.88, "end": 581.4000000000001, "text": " says something went wrong. You're not going to be able to debug that software at all,", "tokens": [1619, 746, 1437, 2085, 13, 509, 434, 406, 516, 281, 312, 1075, 281, 24083, 300, 4722, 412, 439, 11], "temperature": 0.0, "avg_logprob": -0.17388995188587117, "compression_ratio": 1.7198443579766538, "no_speech_prob": 1.4723117601533886e-05}, {"id": 81, "seek": 56108, "start": 581.4000000000001, "end": 588.6, "text": " and you're probably going to have a lot of trouble. That's kind of what we do currently", "tokens": [293, 291, 434, 1391, 516, 281, 362, 257, 688, 295, 5253, 13, 663, 311, 733, 295, 437, 321, 360, 4362], "temperature": 0.0, "avg_logprob": -0.17388995188587117, "compression_ratio": 1.7198443579766538, "no_speech_prob": 1.4723117601533886e-05}, {"id": 82, "seek": 58860, "start": 588.6, "end": 593.0400000000001, "text": " when we say human error. We just simply say the person made a mistake, and that's as far", "tokens": [562, 321, 584, 1952, 6713, 13, 492, 445, 2935, 584, 264, 954, 1027, 257, 6146, 11, 293, 300, 311, 382, 1400], "temperature": 0.0, "avg_logprob": -0.13913740430559432, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.4713663404108956e-05}, {"id": 83, "seek": 58860, "start": 593.0400000000001, "end": 599.32, "text": " usually as we look. The aircraft industry has actually come up with something with a much", "tokens": [2673, 382, 321, 574, 13, 440, 9465, 3518, 575, 767, 808, 493, 365, 746, 365, 257, 709], "temperature": 0.0, "avg_logprob": -0.13913740430559432, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.4713663404108956e-05}, {"id": 84, "seek": 58860, "start": 599.32, "end": 606.84, "text": " richer understanding of this topic and sort of richer system of almost like error codes", "tokens": [29021, 3701, 295, 341, 4829, 293, 1333, 295, 29021, 1185, 295, 1920, 411, 6713, 14211], "temperature": 0.0, "avg_logprob": -0.13913740430559432, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.4713663404108956e-05}, {"id": 85, "seek": 58860, "start": 606.84, "end": 614.1600000000001, "text": " that they use when they talk about these issues. The reason is it's a very unforgiving environment.", "tokens": [300, 436, 764, 562, 436, 751, 466, 613, 2663, 13, 440, 1778, 307, 309, 311, 257, 588, 31411, 15441, 2823, 13], "temperature": 0.0, "avg_logprob": -0.13913740430559432, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.4713663404108956e-05}, {"id": 86, "seek": 61416, "start": 614.16, "end": 620.28, "text": " If you make a mistake, you might or might not be able to recover, so you have a lot", "tokens": [759, 291, 652, 257, 6146, 11, 291, 1062, 420, 1062, 406, 312, 1075, 281, 8114, 11, 370, 291, 362, 257, 688], "temperature": 0.0, "avg_logprob": -0.14579561673677885, "compression_ratio": 1.5, "no_speech_prob": 4.416183855937561e-06}, {"id": 87, "seek": 61416, "start": 620.28, "end": 631.0, "text": " of training on this, and now the chance of a massive disaster is down probably one error", "tokens": [295, 3097, 322, 341, 11, 293, 586, 264, 2931, 295, 257, 5994, 11293, 307, 760, 1391, 472, 6713], "temperature": 0.0, "avg_logprob": -0.14579561673677885, "compression_ratio": 1.5, "no_speech_prob": 4.416183855937561e-06}, {"id": 88, "seek": 61416, "start": 631.0, "end": 643.4, "text": " disaster per billion takeoffs, which is really impressive. We'd love to have that.", "tokens": [11293, 680, 5218, 747, 19231, 11, 597, 307, 534, 8992, 13, 492, 1116, 959, 281, 362, 300, 13], "temperature": 0.0, "avg_logprob": -0.14579561673677885, "compression_ratio": 1.5, "no_speech_prob": 4.416183855937561e-06}, {"id": 89, "seek": 64340, "start": 643.4, "end": 647.64, "text": " So they've made this shift. They've also made a shift that we've already made, and it's", "tokens": [407, 436, 600, 1027, 341, 5513, 13, 814, 600, 611, 1027, 257, 5513, 300, 321, 600, 1217, 1027, 11, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.11510827519872167, "compression_ratio": 1.800796812749004, "no_speech_prob": 4.15234217143734e-06}, {"id": 90, "seek": 64340, "start": 647.64, "end": 652.56, "text": " worth pointing this out, and that's that they've made a shift from individual responsibility", "tokens": [3163, 12166, 341, 484, 11, 293, 300, 311, 300, 436, 600, 1027, 257, 5513, 490, 2609, 6357], "temperature": 0.0, "avg_logprob": -0.11510827519872167, "compression_ratio": 1.800796812749004, "no_speech_prob": 4.15234217143734e-06}, {"id": 91, "seek": 64340, "start": 652.56, "end": 658.4399999999999, "text": " to collective responsibility. In our terms, we call that blameless culture. Somebody makes", "tokens": [281, 12590, 6357, 13, 682, 527, 2115, 11, 321, 818, 300, 888, 335, 4272, 3713, 13, 13463, 1669], "temperature": 0.0, "avg_logprob": -0.11510827519872167, "compression_ratio": 1.800796812749004, "no_speech_prob": 4.15234217143734e-06}, {"id": 92, "seek": 64340, "start": 658.4399999999999, "end": 663.0, "text": " a mistake. We don't blame them. We don't go, hey, stop making mistakes. We try to find", "tokens": [257, 6146, 13, 492, 500, 380, 10127, 552, 13, 492, 500, 380, 352, 11, 4177, 11, 1590, 1455, 8038, 13, 492, 853, 281, 915], "temperature": 0.0, "avg_logprob": -0.11510827519872167, "compression_ratio": 1.800796812749004, "no_speech_prob": 4.15234217143734e-06}, {"id": 93, "seek": 64340, "start": 663.0, "end": 667.24, "text": " some way to keep that mistake from happening, but because we don't have a clear understanding", "tokens": [512, 636, 281, 1066, 300, 6146, 490, 2737, 11, 457, 570, 321, 500, 380, 362, 257, 1850, 3701], "temperature": 0.0, "avg_logprob": -0.11510827519872167, "compression_ratio": 1.800796812749004, "no_speech_prob": 4.15234217143734e-06}, {"id": 94, "seek": 66724, "start": 667.24, "end": 673.6800000000001, "text": " of this topic, we try to solve this in ways that maybe aren't as effective as they could", "tokens": [295, 341, 4829, 11, 321, 853, 281, 5039, 341, 294, 2098, 300, 1310, 3212, 380, 382, 4942, 382, 436, 727], "temperature": 0.0, "avg_logprob": -0.12977970971001518, "compression_ratio": 1.4625, "no_speech_prob": 8.389333743252791e-06}, {"id": 95, "seek": 66724, "start": 673.6800000000001, "end": 680.48, "text": " be. I want to give one really good example of sort of a watershed moment. Actually, before", "tokens": [312, 13, 286, 528, 281, 976, 472, 534, 665, 1365, 295, 1333, 295, 257, 49728, 1623, 13, 5135, 11, 949], "temperature": 0.0, "avg_logprob": -0.12977970971001518, "compression_ratio": 1.4625, "no_speech_prob": 8.389333743252791e-06}, {"id": 96, "seek": 66724, "start": 680.48, "end": 687.96, "text": " I talk about that, let me just discuss David Beatty's contribution quickly. Beatty was", "tokens": [286, 751, 466, 300, 11, 718, 385, 445, 2248, 4389, 16031, 874, 311, 13150, 2661, 13, 16031, 874, 390], "temperature": 0.0, "avg_logprob": -0.12977970971001518, "compression_ratio": 1.4625, "no_speech_prob": 8.389333743252791e-06}, {"id": 97, "seek": 66724, "start": 687.96, "end": 696.0, "text": " a cognitive psychologist and pilot in the U.K., and in 1969, he wrote a seminal book", "tokens": [257, 15605, 29514, 293, 9691, 294, 264, 624, 13, 42, 7933, 293, 294, 32090, 11, 415, 4114, 257, 4361, 2071, 1446], "temperature": 0.0, "avg_logprob": -0.12977970971001518, "compression_ratio": 1.4625, "no_speech_prob": 8.389333743252791e-06}, {"id": 98, "seek": 69600, "start": 696.0, "end": 701.48, "text": " called The Human Factor in Aircraft Accidents, where he basically looked at the kinds of", "tokens": [1219, 440, 10294, 479, 15104, 294, 5774, 5611, 5725, 6026, 11, 689, 415, 1936, 2956, 412, 264, 3685, 295], "temperature": 0.0, "avg_logprob": -0.09279870230054098, "compression_ratio": 1.5027322404371584, "no_speech_prob": 1.3620986464957241e-05}, {"id": 99, "seek": 69600, "start": 701.48, "end": 707.56, "text": " mistakes that happen and the kinds of circumstances that lead to those mistakes. There are newer", "tokens": [8038, 300, 1051, 293, 264, 3685, 295, 9121, 300, 1477, 281, 729, 8038, 13, 821, 366, 17628], "temperature": 0.0, "avg_logprob": -0.09279870230054098, "compression_ratio": 1.5027322404371584, "no_speech_prob": 1.3620986464957241e-05}, {"id": 100, "seek": 69600, "start": 707.56, "end": 714.36, "text": " versions of that book out now. It's actually worth reading, but probably not best to read", "tokens": [9606, 295, 300, 1446, 484, 586, 13, 467, 311, 767, 3163, 3760, 11, 457, 1391, 406, 1151, 281, 1401], "temperature": 0.0, "avg_logprob": -0.09279870230054098, "compression_ratio": 1.5027322404371584, "no_speech_prob": 1.3620986464957241e-05}, {"id": 101, "seek": 71436, "start": 714.36, "end": 727.0, "text": " if you're a nervous flyer. As a good description of how we break down error, it was the industry", "tokens": [498, 291, 434, 257, 6296, 3603, 260, 13, 1018, 257, 665, 3855, 295, 577, 321, 1821, 760, 6713, 11, 309, 390, 264, 3518], "temperature": 0.0, "avg_logprob": -0.12241109679726993, "compression_ratio": 1.5222222222222221, "no_speech_prob": 1.0767911589937285e-05}, {"id": 102, "seek": 71436, "start": 727.0, "end": 733.6, "text": " starting point. Ten years after that, there was I think the watershed moment in how this", "tokens": [2891, 935, 13, 9380, 924, 934, 300, 11, 456, 390, 286, 519, 264, 49728, 1623, 294, 577, 341], "temperature": 0.0, "avg_logprob": -0.12241109679726993, "compression_ratio": 1.5222222222222221, "no_speech_prob": 1.0767911589937285e-05}, {"id": 103, "seek": 71436, "start": 733.6, "end": 739.12, "text": " became really big within aviation, and that was the Tenerife disaster. Tenerife disaster", "tokens": [3062, 534, 955, 1951, 28831, 11, 293, 300, 390, 264, 314, 7971, 863, 11293, 13, 314, 7971, 863, 11293], "temperature": 0.0, "avg_logprob": -0.12241109679726993, "compression_ratio": 1.5222222222222221, "no_speech_prob": 1.0767911589937285e-05}, {"id": 104, "seek": 73912, "start": 739.12, "end": 748.44, "text": " was the most deadly aircraft accident still in history. It happened on the ground in Tenerife", "tokens": [390, 264, 881, 18232, 9465, 6398, 920, 294, 2503, 13, 467, 2011, 322, 264, 2727, 294, 314, 7971, 863], "temperature": 0.0, "avg_logprob": -0.12343387327332428, "compression_ratio": 1.4114583333333333, "no_speech_prob": 6.848898010503035e-06}, {"id": 105, "seek": 73912, "start": 748.44, "end": 754.5600000000001, "text": " due to a variety of factors. I'm not sure how much detail I should go into in this talk,", "tokens": [3462, 281, 257, 5673, 295, 6771, 13, 286, 478, 406, 988, 577, 709, 2607, 286, 820, 352, 666, 294, 341, 751, 11], "temperature": 0.0, "avg_logprob": -0.12343387327332428, "compression_ratio": 1.4114583333333333, "no_speech_prob": 6.848898010503035e-06}, {"id": 106, "seek": 73912, "start": 754.5600000000001, "end": 760.68, "text": " but the end result was basically that 1-747 tried to take off down a runway with limited", "tokens": [457, 264, 917, 1874, 390, 1936, 300, 502, 12, 22, 14060, 3031, 281, 747, 766, 760, 257, 26642, 365, 5567], "temperature": 0.0, "avg_logprob": -0.12343387327332428, "compression_ratio": 1.4114583333333333, "no_speech_prob": 6.848898010503035e-06}, {"id": 107, "seek": 76068, "start": 760.68, "end": 769.0, "text": " visibility without a proper takeoff clearance, and they hit another 747 on the ground. Clear", "tokens": [19883, 1553, 257, 2296, 747, 4506, 27218, 11, 293, 436, 2045, 1071, 1614, 14060, 322, 264, 2727, 13, 14993], "temperature": 0.0, "avg_logprob": -0.1472631622763241, "compression_ratio": 1.454054054054054, "no_speech_prob": 7.406770237139426e-06}, {"id": 108, "seek": 76068, "start": 769.0, "end": 775.8, "text": " case of human error, and the Spanish report on this more or less blamed it on pilot error.", "tokens": [1389, 295, 1952, 6713, 11, 293, 264, 8058, 2275, 322, 341, 544, 420, 1570, 32027, 309, 322, 9691, 6713, 13], "temperature": 0.0, "avg_logprob": -0.1472631622763241, "compression_ratio": 1.454054054054054, "no_speech_prob": 7.406770237139426e-06}, {"id": 109, "seek": 76068, "start": 775.8, "end": 782.16, "text": " This guy tried to take off. He didn't have the clearance. It was his fault. The Dutch", "tokens": [639, 2146, 3031, 281, 747, 766, 13, 634, 994, 380, 362, 264, 27218, 13, 467, 390, 702, 7441, 13, 440, 15719], "temperature": 0.0, "avg_logprob": -0.1472631622763241, "compression_ratio": 1.454054054054054, "no_speech_prob": 7.406770237139426e-06}, {"id": 110, "seek": 78216, "start": 782.16, "end": 792.24, "text": " report, which is often criticized in some documentaries that I've seen on this, was", "tokens": [2275, 11, 597, 307, 2049, 28011, 294, 512, 41630, 300, 286, 600, 1612, 322, 341, 11, 390], "temperature": 0.0, "avg_logprob": -0.12734832533870835, "compression_ratio": 1.6018518518518519, "no_speech_prob": 1.3407155165623408e-05}, {"id": 111, "seek": 78216, "start": 792.24, "end": 795.8399999999999, "text": " very, very different. What they actually did was they asked, why did he try to take off", "tokens": [588, 11, 588, 819, 13, 708, 436, 767, 630, 390, 436, 2351, 11, 983, 630, 415, 853, 281, 747, 766], "temperature": 0.0, "avg_logprob": -0.12734832533870835, "compression_ratio": 1.6018518518518519, "no_speech_prob": 1.3407155165623408e-05}, {"id": 112, "seek": 78216, "start": 795.8399999999999, "end": 802.16, "text": " without clearance? What was going through, how did that mistake happen? The thing was,", "tokens": [1553, 27218, 30, 708, 390, 516, 807, 11, 577, 630, 300, 6146, 1051, 30, 440, 551, 390, 11], "temperature": 0.0, "avg_logprob": -0.12734832533870835, "compression_ratio": 1.6018518518518519, "no_speech_prob": 1.3407155165623408e-05}, {"id": 113, "seek": 78216, "start": 802.16, "end": 808.0799999999999, "text": " he was an extremely experienced pilot. He was their chief pilot. He actually didn't fly", "tokens": [415, 390, 364, 4664, 6751, 9691, 13, 634, 390, 641, 9588, 9691, 13, 634, 767, 994, 380, 3603], "temperature": 0.0, "avg_logprob": -0.12734832533870835, "compression_ratio": 1.6018518518518519, "no_speech_prob": 1.3407155165623408e-05}, {"id": 114, "seek": 80808, "start": 808.08, "end": 813.5200000000001, "text": " airplanes that much. He was mostly sitting on simulators. The thing was, at that time,", "tokens": [32947, 300, 709, 13, 634, 390, 5240, 3798, 322, 1034, 39265, 13, 440, 551, 390, 11, 412, 300, 565, 11], "temperature": 0.0, "avg_logprob": -0.1456222977749137, "compression_ratio": 1.669811320754717, "no_speech_prob": 1.519339275546372e-05}, {"id": 115, "seek": 80808, "start": 813.5200000000001, "end": 820.4000000000001, "text": " when you were the senior pilot in the simulator, you were giving the clearances. A stressful", "tokens": [562, 291, 645, 264, 7965, 9691, 294, 264, 32974, 11, 291, 645, 2902, 264, 1850, 2676, 13, 316, 19108], "temperature": 0.0, "avg_logprob": -0.1456222977749137, "compression_ratio": 1.669811320754717, "no_speech_prob": 1.519339275546372e-05}, {"id": 116, "seek": 80808, "start": 820.4000000000001, "end": 829.8000000000001, "text": " situation, visibility is slow, there's pressure to take off, stressful situation. He goes", "tokens": [2590, 11, 19883, 307, 2964, 11, 456, 311, 3321, 281, 747, 766, 11, 19108, 2590, 13, 634, 1709], "temperature": 0.0, "avg_logprob": -0.1456222977749137, "compression_ratio": 1.669811320754717, "no_speech_prob": 1.519339275546372e-05}, {"id": 117, "seek": 80808, "start": 829.8000000000001, "end": 834.2, "text": " back to what he's used to doing, which is assuming he has the clearance because he's", "tokens": [646, 281, 437, 415, 311, 1143, 281, 884, 11, 597, 307, 11926, 415, 575, 264, 27218, 570, 415, 311], "temperature": 0.0, "avg_logprob": -0.1456222977749137, "compression_ratio": 1.669811320754717, "no_speech_prob": 1.519339275546372e-05}, {"id": 118, "seek": 83420, "start": 834.2, "end": 840.84, "text": " used to giving them to himself. Airlines don't do that anymore in their simulators,", "tokens": [1143, 281, 2902, 552, 281, 3647, 13, 38788, 500, 380, 360, 300, 3602, 294, 641, 1034, 39265, 11], "temperature": 0.0, "avg_logprob": -0.11770069308397246, "compression_ratio": 1.5822222222222222, "no_speech_prob": 1.8318767615710385e-05}, {"id": 119, "seek": 83420, "start": 840.84, "end": 850.32, "text": " for obvious reasons. The Dutch report actually became the basis for how the aviation industry", "tokens": [337, 6322, 4112, 13, 440, 15719, 2275, 767, 3062, 264, 5143, 337, 577, 264, 28831, 3518], "temperature": 0.0, "avg_logprob": -0.11770069308397246, "compression_ratio": 1.5822222222222222, "no_speech_prob": 1.8318767615710385e-05}, {"id": 120, "seek": 83420, "start": 850.32, "end": 856.08, "text": " has started to look at human error ever since. As a result, what we've seen is we've seen", "tokens": [575, 1409, 281, 574, 412, 1952, 6713, 1562, 1670, 13, 1018, 257, 1874, 11, 437, 321, 600, 1612, 307, 321, 600, 1612], "temperature": 0.0, "avg_logprob": -0.11770069308397246, "compression_ratio": 1.5822222222222222, "no_speech_prob": 1.8318767615710385e-05}, {"id": 121, "seek": 83420, "start": 856.08, "end": 863.72, "text": " this massive, massive improvement in safety. Every pilot in every airline gets this sort", "tokens": [341, 5994, 11, 5994, 10444, 294, 4514, 13, 2048, 9691, 294, 633, 29528, 2170, 341, 1333], "temperature": 0.0, "avg_logprob": -0.11770069308397246, "compression_ratio": 1.5822222222222222, "no_speech_prob": 1.8318767615710385e-05}, {"id": 122, "seek": 86372, "start": 863.72, "end": 871.9200000000001, "text": " of training, and it has made our flights much, much, much, much safer.", "tokens": [295, 3097, 11, 293, 309, 575, 1027, 527, 21089, 709, 11, 709, 11, 709, 11, 709, 15856, 13], "temperature": 0.0, "avg_logprob": -0.16776713870820545, "compression_ratio": 1.5636363636363637, "no_speech_prob": 3.059187292819843e-05}, {"id": 123, "seek": 86372, "start": 871.9200000000001, "end": 876.88, "text": " The question is, can we benefit from the same thing? The answer is yes. We actually can get", "tokens": [440, 1168, 307, 11, 393, 321, 5121, 490, 264, 912, 551, 30, 440, 1867, 307, 2086, 13, 492, 767, 393, 483], "temperature": 0.0, "avg_logprob": -0.16776713870820545, "compression_ratio": 1.5636363636363637, "no_speech_prob": 3.059187292819843e-05}, {"id": 124, "seek": 86372, "start": 876.88, "end": 885.8000000000001, "text": " a lot more benefits from it than just reducing incidents and recovering from them. In fact,", "tokens": [257, 688, 544, 5311, 490, 309, 813, 445, 12245, 21139, 293, 29180, 490, 552, 13, 682, 1186, 11], "temperature": 0.0, "avg_logprob": -0.16776713870820545, "compression_ratio": 1.5636363636363637, "no_speech_prob": 3.059187292819843e-05}, {"id": 125, "seek": 86372, "start": 885.8000000000001, "end": 891.36, "text": " if you look at the standard definition that people give of crew resource management, it's", "tokens": [498, 291, 574, 412, 264, 3832, 7123, 300, 561, 976, 295, 7260, 7684, 4592, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.16776713870820545, "compression_ratio": 1.5636363636363637, "no_speech_prob": 3.059187292819843e-05}, {"id": 126, "seek": 89136, "start": 891.36, "end": 897.84, "text": " the use of all available resources to ensure the safe and efficient operation of the aircraft.", "tokens": [264, 764, 295, 439, 2435, 3593, 281, 5586, 264, 3273, 293, 7148, 6916, 295, 264, 9465, 13], "temperature": 0.0, "avg_logprob": -0.10481180627662015, "compression_ratio": 1.714975845410628, "no_speech_prob": 2.3486409190809354e-05}, {"id": 127, "seek": 89136, "start": 897.84, "end": 905.0, "text": " If we can use all of our resources to improve both safety and efficiency, that's going", "tokens": [759, 321, 393, 764, 439, 295, 527, 3593, 281, 3470, 1293, 4514, 293, 10493, 11, 300, 311, 516], "temperature": 0.0, "avg_logprob": -0.10481180627662015, "compression_ratio": 1.714975845410628, "no_speech_prob": 2.3486409190809354e-05}, {"id": 128, "seek": 89136, "start": 905.0, "end": 911.72, "text": " to make our jobs better, we're going to be more productive, we're going to be happier.", "tokens": [281, 652, 527, 4782, 1101, 11, 321, 434, 516, 281, 312, 544, 13304, 11, 321, 434, 516, 281, 312, 20423, 13], "temperature": 0.0, "avg_logprob": -0.10481180627662015, "compression_ratio": 1.714975845410628, "no_speech_prob": 2.3486409190809354e-05}, {"id": 129, "seek": 89136, "start": 911.72, "end": 917.36, "text": " This is actually a really, really important field that I think that we need to improve", "tokens": [639, 307, 767, 257, 534, 11, 534, 1021, 2519, 300, 286, 519, 300, 321, 643, 281, 3470], "temperature": 0.0, "avg_logprob": -0.10481180627662015, "compression_ratio": 1.714975845410628, "no_speech_prob": 2.3486409190809354e-05}, {"id": 130, "seek": 91736, "start": 917.36, "end": 922.0, "text": " on. Now I'm going to talk about how we look at", "tokens": [322, 13, 823, 286, 478, 516, 281, 751, 466, 577, 321, 574, 412], "temperature": 0.0, "avg_logprob": -0.2193915647618911, "compression_ratio": 1.7225130890052356, "no_speech_prob": 1.6167075955308974e-05}, {"id": 131, "seek": 91736, "start": 922.0, "end": 933.0, "text": " human error in the industry. Human error typically in the DevOps and SRE systems, we have one", "tokens": [1952, 6713, 294, 264, 3518, 13, 10294, 6713, 5850, 294, 264, 43051, 293, 318, 3850, 3652, 11, 321, 362, 472], "temperature": 0.0, "avg_logprob": -0.2193915647618911, "compression_ratio": 1.7225130890052356, "no_speech_prob": 1.6167075955308974e-05}, {"id": 132, "seek": 91736, "start": 933.0, "end": 938.92, "text": " answer to human error. What that is, automation. If somebody made a mistake, we're going to", "tokens": [1867, 281, 1952, 6713, 13, 708, 300, 307, 11, 17769, 13, 759, 2618, 1027, 257, 6146, 11, 321, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.2193915647618911, "compression_ratio": 1.7225130890052356, "no_speech_prob": 1.6167075955308974e-05}, {"id": 133, "seek": 91736, "start": 938.92, "end": 945.12, "text": " automate that away. We're just going to add more automation. We're going to add more automation.", "tokens": [31605, 300, 1314, 13, 492, 434, 445, 516, 281, 909, 544, 17769, 13, 492, 434, 516, 281, 909, 544, 17769, 13], "temperature": 0.0, "avg_logprob": -0.2193915647618911, "compression_ratio": 1.7225130890052356, "no_speech_prob": 1.6167075955308974e-05}, {"id": 134, "seek": 94512, "start": 945.12, "end": 951.36, "text": " It seems like a great idea. Computers are infallible, we're fallible, so we're just", "tokens": [467, 2544, 411, 257, 869, 1558, 13, 37804, 433, 366, 1536, 336, 964, 11, 321, 434, 2100, 964, 11, 370, 321, 434, 445], "temperature": 0.0, "avg_logprob": -0.2430313861731327, "compression_ratio": 1.5207100591715976, "no_speech_prob": 8.932120181270875e-06}, {"id": 135, "seek": 94512, "start": 951.36, "end": 958.52, "text": " going to use the computers to prevent the mistake. The problem with this, the IEEE", "tokens": [516, 281, 764, 264, 10807, 281, 4871, 264, 6146, 13, 440, 1154, 365, 341, 11, 264, 286, 7258, 36], "temperature": 0.0, "avg_logprob": -0.2430313861731327, "compression_ratio": 1.5207100591715976, "no_speech_prob": 8.932120181270875e-06}, {"id": 136, "seek": 94512, "start": 958.52, "end": 966.08, "text": " has done a bunch of research on something they call the automation paradox. The automation", "tokens": [575, 1096, 257, 3840, 295, 2132, 322, 746, 436, 818, 264, 17769, 26221, 13, 440, 17769], "temperature": 0.0, "avg_logprob": -0.2430313861731327, "compression_ratio": 1.5207100591715976, "no_speech_prob": 8.932120181270875e-06}, {"id": 137, "seek": 96608, "start": 966.08, "end": 979.6, "text": " paradox is that the more reliable the automation is, the less opportunities humans have to", "tokens": [26221, 307, 300, 264, 544, 12924, 264, 17769, 307, 11, 264, 1570, 4786, 6255, 362, 281], "temperature": 0.0, "avg_logprob": -0.1267751157283783, "compression_ratio": 1.5517241379310345, "no_speech_prob": 5.161605258763302e-06}, {"id": 138, "seek": 96608, "start": 979.6, "end": 985.44, "text": " contribute to the overall success of that. I think I'm going to take a little bit of", "tokens": [10586, 281, 264, 4787, 2245, 295, 300, 13, 286, 519, 286, 478, 516, 281, 747, 257, 707, 857, 295], "temperature": 0.0, "avg_logprob": -0.1267751157283783, "compression_ratio": 1.5517241379310345, "no_speech_prob": 5.161605258763302e-06}, {"id": 139, "seek": 96608, "start": 985.44, "end": 991.08, "text": " time here to talk about why that is the case, and then I'll get reinforced in the next section", "tokens": [565, 510, 281, 751, 466, 983, 300, 307, 264, 1389, 11, 293, 550, 286, 603, 483, 31365, 294, 264, 958, 3541], "temperature": 0.0, "avg_logprob": -0.1267751157283783, "compression_ratio": 1.5517241379310345, "no_speech_prob": 5.161605258763302e-06}, {"id": 140, "seek": 99108, "start": 991.08, "end": 1001.44, "text": " when we talk about why we make mistakes. But to start with a basic summary, obviously", "tokens": [562, 321, 751, 466, 983, 321, 652, 8038, 13, 583, 281, 722, 365, 257, 3875, 12691, 11, 2745], "temperature": 0.0, "avg_logprob": -0.13396261850992838, "compression_ratio": 1.6634615384615385, "no_speech_prob": 7.397223271254916e-06}, {"id": 141, "seek": 99108, "start": 1001.44, "end": 1006.44, "text": " we need automation because there are certain kinds of tasks that we're actually very bad", "tokens": [321, 643, 17769, 570, 456, 366, 1629, 3685, 295, 9608, 300, 321, 434, 767, 588, 1578], "temperature": 0.0, "avg_logprob": -0.13396261850992838, "compression_ratio": 1.6634615384615385, "no_speech_prob": 7.397223271254916e-06}, {"id": 142, "seek": 99108, "start": 1006.44, "end": 1013.2, "text": " at following, and there are certain kinds of requirements where automation can really", "tokens": [412, 3480, 11, 293, 456, 366, 1629, 3685, 295, 7728, 689, 17769, 393, 534], "temperature": 0.0, "avg_logprob": -0.13396261850992838, "compression_ratio": 1.6634615384615385, "no_speech_prob": 7.397223271254916e-06}, {"id": 143, "seek": 99108, "start": 1013.2, "end": 1020.48, "text": " save us a lot of safety considerations. So steps that have to be done together really", "tokens": [3155, 505, 257, 688, 295, 4514, 24070, 13, 407, 4439, 300, 362, 281, 312, 1096, 1214, 534], "temperature": 0.0, "avg_logprob": -0.13396261850992838, "compression_ratio": 1.6634615384615385, "no_speech_prob": 7.397223271254916e-06}, {"id": 144, "seek": 102048, "start": 1020.48, "end": 1028.64, "text": " should be automated so that they happen together. But automation is just done reflexively, at", "tokens": [820, 312, 18473, 370, 300, 436, 1051, 1214, 13, 583, 17769, 307, 445, 1096, 23802, 3413, 11, 412], "temperature": 0.0, "avg_logprob": -0.14490731557210287, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.291333076864248e-06}, {"id": 145, "seek": 102048, "start": 1028.64, "end": 1035.04, "text": " least according to a lot of the research that's come out of the IEEE as well as many of the", "tokens": [1935, 4650, 281, 257, 688, 295, 264, 2132, 300, 311, 808, 484, 295, 264, 286, 7258, 36, 382, 731, 382, 867, 295, 264], "temperature": 0.0, "avg_logprob": -0.14490731557210287, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.291333076864248e-06}, {"id": 146, "seek": 102048, "start": 1035.04, "end": 1042.56, "text": " aviation study groups on this, is that simply throwing automation at a problem can actually", "tokens": [28831, 2979, 3935, 322, 341, 11, 307, 300, 2935, 10238, 17769, 412, 257, 1154, 393, 767], "temperature": 0.0, "avg_logprob": -0.14490731557210287, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.291333076864248e-06}, {"id": 147, "seek": 102048, "start": 1042.56, "end": 1047.28, "text": " make human error more common and can make human error more severe, and then when things", "tokens": [652, 1952, 6713, 544, 2689, 293, 393, 652, 1952, 6713, 544, 8922, 11, 293, 550, 562, 721], "temperature": 0.0, "avg_logprob": -0.14490731557210287, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.291333076864248e-06}, {"id": 148, "seek": 104728, "start": 1047.28, "end": 1061.24, "text": " are out of whack, you have no possibility at all of saving, of preventing a major incident.", "tokens": [366, 484, 295, 42877, 11, 291, 362, 572, 7959, 412, 439, 295, 6816, 11, 295, 19965, 257, 2563, 9348, 13], "temperature": 0.0, "avg_logprob": -0.1255075570308801, "compression_ratio": 1.593939393939394, "no_speech_prob": 1.0769472282845527e-05}, {"id": 149, "seek": 104728, "start": 1061.24, "end": 1066.92, "text": " Part of the reason here is that we process all of what we see through a mental model,", "tokens": [4100, 295, 264, 1778, 510, 307, 300, 321, 1399, 439, 295, 437, 321, 536, 807, 257, 4973, 2316, 11], "temperature": 0.0, "avg_logprob": -0.1255075570308801, "compression_ratio": 1.593939393939394, "no_speech_prob": 1.0769472282845527e-05}, {"id": 150, "seek": 104728, "start": 1066.92, "end": 1076.08, "text": " and so when we add more complexity, when we add more automation around a lot of this,", "tokens": [293, 370, 562, 321, 909, 544, 14024, 11, 562, 321, 909, 544, 17769, 926, 257, 688, 295, 341, 11], "temperature": 0.0, "avg_logprob": -0.1255075570308801, "compression_ratio": 1.593939393939394, "no_speech_prob": 1.0769472282845527e-05}, {"id": 151, "seek": 107608, "start": 1076.08, "end": 1082.3999999999999, "text": " we make it really, really, really, really, really hard for us to keep that mental model", "tokens": [321, 652, 309, 534, 11, 534, 11, 534, 11, 534, 11, 534, 1152, 337, 505, 281, 1066, 300, 4973, 2316], "temperature": 0.0, "avg_logprob": -0.08529338836669922, "compression_ratio": 1.631336405529954, "no_speech_prob": 5.767104994447436e-06}, {"id": 152, "seek": 107608, "start": 1082.3999999999999, "end": 1087.8799999999999, "text": " reasonably in sync with reality. And then when something goes wrong, we can spend a", "tokens": [23551, 294, 20271, 365, 4103, 13, 400, 550, 562, 746, 1709, 2085, 11, 321, 393, 3496, 257], "temperature": 0.0, "avg_logprob": -0.08529338836669922, "compression_ratio": 1.631336405529954, "no_speech_prob": 5.767104994447436e-06}, {"id": 153, "seek": 107608, "start": 1087.8799999999999, "end": 1093.9199999999998, "text": " lot of time and effort struggling to understand what's going on, or we may reflexively react", "tokens": [688, 295, 565, 293, 4630, 9314, 281, 1223, 437, 311, 516, 322, 11, 420, 321, 815, 23802, 3413, 4515], "temperature": 0.0, "avg_logprob": -0.08529338836669922, "compression_ratio": 1.631336405529954, "no_speech_prob": 5.767104994447436e-06}, {"id": 154, "seek": 107608, "start": 1093.9199999999998, "end": 1104.32, "text": " in ways which actually make the problem worse. So automation isn't the answer, it is part", "tokens": [294, 2098, 597, 767, 652, 264, 1154, 5324, 13, 407, 17769, 1943, 380, 264, 1867, 11, 309, 307, 644], "temperature": 0.0, "avg_logprob": -0.08529338836669922, "compression_ratio": 1.631336405529954, "no_speech_prob": 5.767104994447436e-06}, {"id": 155, "seek": 110432, "start": 1104.32, "end": 1111.32, "text": " of an answer. And reflexive automation, oh, we had a problem that's automated away, is", "tokens": [295, 364, 1867, 13, 400, 23802, 488, 17769, 11, 1954, 11, 321, 632, 257, 1154, 300, 311, 18473, 1314, 11, 307], "temperature": 0.0, "avg_logprob": -0.1312875035983413, "compression_ratio": 1.5290697674418605, "no_speech_prob": 7.76142769609578e-06}, {"id": 156, "seek": 110432, "start": 1111.32, "end": 1126.24, "text": " not the answer. Now, I mentioned just a moment ago this issue of mental models. We humans,", "tokens": [406, 264, 1867, 13, 823, 11, 286, 2835, 445, 257, 1623, 2057, 341, 2734, 295, 4973, 5245, 13, 492, 6255, 11], "temperature": 0.0, "avg_logprob": -0.1312875035983413, "compression_ratio": 1.5290697674418605, "no_speech_prob": 7.76142769609578e-06}, {"id": 157, "seek": 110432, "start": 1126.24, "end": 1130.6399999999999, "text": " we operate in a world that's very different from the way computers operate. Computers", "tokens": [321, 9651, 294, 257, 1002, 300, 311, 588, 819, 490, 264, 636, 10807, 9651, 13, 37804, 433], "temperature": 0.0, "avg_logprob": -0.1312875035983413, "compression_ratio": 1.5290697674418605, "no_speech_prob": 7.76142769609578e-06}, {"id": 158, "seek": 113064, "start": 1130.64, "end": 1140.2, "text": " are basically systems that mathematically process inputs and produce outputs, right?", "tokens": [366, 1936, 3652, 300, 44003, 1399, 15743, 293, 5258, 23930, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1323975682258606, "compression_ratio": 1.8072916666666667, "no_speech_prob": 2.043065796897281e-05}, {"id": 159, "seek": 113064, "start": 1140.2, "end": 1146.48, "text": " And therefore, computing programs basically operate in a closed world. We humans don't", "tokens": [400, 4412, 11, 15866, 4268, 1936, 9651, 294, 257, 5395, 1002, 13, 492, 6255, 500, 380], "temperature": 0.0, "avg_logprob": -0.1323975682258606, "compression_ratio": 1.8072916666666667, "no_speech_prob": 2.043065796897281e-05}, {"id": 160, "seek": 113064, "start": 1146.48, "end": 1152.48, "text": " operate in closed worlds, right? We all operate in open worlds. We have the situation where", "tokens": [9651, 294, 5395, 13401, 11, 558, 30, 492, 439, 9651, 294, 1269, 13401, 13, 492, 362, 264, 2590, 689], "temperature": 0.0, "avg_logprob": -0.1323975682258606, "compression_ratio": 1.8072916666666667, "no_speech_prob": 2.043065796897281e-05}, {"id": 161, "seek": 113064, "start": 1152.48, "end": 1159.72, "text": " we know we don't know everything. We know we don't know some things. We know, well,", "tokens": [321, 458, 321, 500, 380, 458, 1203, 13, 492, 458, 321, 500, 380, 458, 512, 721, 13, 492, 458, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.1323975682258606, "compression_ratio": 1.8072916666666667, "no_speech_prob": 2.043065796897281e-05}, {"id": 162, "seek": 115972, "start": 1159.72, "end": 1164.2, "text": " and then we don't know other things that we don't know we don't know, right? Some cases", "tokens": [293, 550, 321, 500, 380, 458, 661, 721, 300, 321, 500, 380, 458, 321, 500, 380, 458, 11, 558, 30, 2188, 3331], "temperature": 0.0, "avg_logprob": -0.12531922314618085, "compression_ratio": 1.8927038626609443, "no_speech_prob": 7.756166269246023e-06}, {"id": 163, "seek": 115972, "start": 1164.2, "end": 1172.4, "text": " we know we don't know what we don't know, right? But in order to function, we have to", "tokens": [321, 458, 321, 500, 380, 458, 437, 321, 500, 380, 458, 11, 558, 30, 583, 294, 1668, 281, 2445, 11, 321, 362, 281], "temperature": 0.0, "avg_logprob": -0.12531922314618085, "compression_ratio": 1.8927038626609443, "no_speech_prob": 7.756166269246023e-06}, {"id": 164, "seek": 115972, "start": 1172.4, "end": 1176.32, "text": " maintain these mental models, and those mental models are necessarily a simplification of", "tokens": [6909, 613, 4973, 5245, 11, 293, 729, 4973, 5245, 366, 4725, 257, 6883, 3774, 295], "temperature": 0.0, "avg_logprob": -0.12531922314618085, "compression_ratio": 1.8927038626609443, "no_speech_prob": 7.756166269246023e-06}, {"id": 165, "seek": 115972, "start": 1176.32, "end": 1182.16, "text": " reality. And so when something's going wrong, we have to dig into how we think the system", "tokens": [4103, 13, 400, 370, 562, 746, 311, 516, 2085, 11, 321, 362, 281, 2528, 666, 577, 321, 519, 264, 1185], "temperature": 0.0, "avg_logprob": -0.12531922314618085, "compression_ratio": 1.8927038626609443, "no_speech_prob": 7.756166269246023e-06}, {"id": 166, "seek": 115972, "start": 1182.16, "end": 1189.2, "text": " works and we have to kind of go through that. And the more complexity we throw into our", "tokens": [1985, 293, 321, 362, 281, 733, 295, 352, 807, 300, 13, 400, 264, 544, 14024, 321, 3507, 666, 527], "temperature": 0.0, "avg_logprob": -0.12531922314618085, "compression_ratio": 1.8927038626609443, "no_speech_prob": 7.756166269246023e-06}, {"id": 167, "seek": 118920, "start": 1189.2, "end": 1195.92, "text": " automation, the harder that process becomes, right?", "tokens": [17769, 11, 264, 6081, 300, 1399, 3643, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.12724907774674266, "compression_ratio": 1.7119565217391304, "no_speech_prob": 1.2584813703142572e-05}, {"id": 168, "seek": 118920, "start": 1195.92, "end": 1203.6000000000001, "text": " So automation, as I say, is an important tool. I'm going to talk in a few moments about", "tokens": [407, 17769, 11, 382, 286, 584, 11, 307, 364, 1021, 2290, 13, 286, 478, 516, 281, 751, 294, 257, 1326, 6065, 466], "temperature": 0.0, "avg_logprob": -0.12724907774674266, "compression_ratio": 1.7119565217391304, "no_speech_prob": 1.2584813703142572e-05}, {"id": 169, "seek": 118920, "start": 1203.6000000000001, "end": 1208.8400000000001, "text": " good automation versus bad automation, but it's something that we can't rely on to solve", "tokens": [665, 17769, 5717, 1578, 17769, 11, 457, 309, 311, 746, 300, 321, 393, 380, 10687, 322, 281, 5039], "temperature": 0.0, "avg_logprob": -0.12724907774674266, "compression_ratio": 1.7119565217391304, "no_speech_prob": 1.2584813703142572e-05}, {"id": 170, "seek": 118920, "start": 1208.8400000000001, "end": 1215.72, "text": " the human error problem. So I mentioned that I talked about good automation versus bad", "tokens": [264, 1952, 6713, 1154, 13, 407, 286, 2835, 300, 286, 2825, 466, 665, 17769, 5717, 1578], "temperature": 0.0, "avg_logprob": -0.12724907774674266, "compression_ratio": 1.7119565217391304, "no_speech_prob": 1.2584813703142572e-05}, {"id": 171, "seek": 121572, "start": 1215.72, "end": 1222.08, "text": " automation. I think this is really, really, really important here. So oftentimes what", "tokens": [17769, 13, 286, 519, 341, 307, 534, 11, 534, 11, 534, 1021, 510, 13, 407, 18349, 437], "temperature": 0.0, "avg_logprob": -0.12410898362436602, "compression_ratio": 1.5, "no_speech_prob": 2.075576594506856e-05}, {"id": 172, "seek": 121572, "start": 1222.08, "end": 1228.56, "text": " I've seen happen is that you end up with large automated systems, whether they're something", "tokens": [286, 600, 1612, 1051, 307, 300, 291, 917, 493, 365, 2416, 18473, 3652, 11, 1968, 436, 434, 746], "temperature": 0.0, "avg_logprob": -0.12410898362436602, "compression_ratio": 1.5, "no_speech_prob": 2.075576594506856e-05}, {"id": 173, "seek": 121572, "start": 1228.56, "end": 1239.84, "text": " like Ansible or Rax or Kubernetes or whatever. And oftentimes there isn't a clear understanding", "tokens": [411, 14590, 964, 420, 497, 2797, 420, 23145, 420, 2035, 13, 400, 18349, 456, 1943, 380, 257, 1850, 3701], "temperature": 0.0, "avg_logprob": -0.12410898362436602, "compression_ratio": 1.5, "no_speech_prob": 2.075576594506856e-05}, {"id": 174, "seek": 123984, "start": 1239.84, "end": 1248.9599999999998, "text": " of how these things work underneath. Now, if people do understand all of that, and they've", "tokens": [295, 577, 613, 721, 589, 7223, 13, 823, 11, 498, 561, 360, 1223, 439, 295, 300, 11, 293, 436, 600], "temperature": 0.0, "avg_logprob": -0.1596143966497377, "compression_ratio": 1.6839622641509433, "no_speech_prob": 6.7427549765852746e-06}, {"id": 175, "seek": 123984, "start": 1248.9599999999998, "end": 1254.8, "text": " built in a lot of these things, then a lot of that's going to be a lot easier, right?", "tokens": [3094, 294, 257, 688, 295, 613, 721, 11, 550, 257, 688, 295, 300, 311, 516, 281, 312, 257, 688, 3571, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1596143966497377, "compression_ratio": 1.6839622641509433, "no_speech_prob": 6.7427549765852746e-06}, {"id": 176, "seek": 123984, "start": 1254.8, "end": 1261.36, "text": " So good automation is basically going to be a deliberate and engineered process, right?", "tokens": [407, 665, 17769, 307, 1936, 516, 281, 312, 257, 30515, 293, 38648, 1399, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1596143966497377, "compression_ratio": 1.6839622641509433, "no_speech_prob": 6.7427549765852746e-06}, {"id": 177, "seek": 123984, "start": 1261.36, "end": 1266.24, "text": " Rather than something that's thrown together in the course of the messy world of operations,", "tokens": [16571, 813, 746, 300, 311, 11732, 1214, 294, 264, 1164, 295, 264, 16191, 1002, 295, 7705, 11], "temperature": 0.0, "avg_logprob": -0.1596143966497377, "compression_ratio": 1.6839622641509433, "no_speech_prob": 6.7427549765852746e-06}, {"id": 178, "seek": 126624, "start": 1266.24, "end": 1272.1200000000001, "text": " it is a deliberate process which is designed around two factors and three factors, actually.", "tokens": [309, 307, 257, 30515, 1399, 597, 307, 4761, 926, 732, 6771, 293, 1045, 6771, 11, 767, 13], "temperature": 0.0, "avg_logprob": -0.12059329748153687, "compression_ratio": 1.7004830917874396, "no_speech_prob": 1.1288349924143404e-05}, {"id": 179, "seek": 126624, "start": 1272.1200000000001, "end": 1277.28, "text": " The first factor is the system, right? The second factor is the people, and we usually", "tokens": [440, 700, 5952, 307, 264, 1185, 11, 558, 30, 440, 1150, 5952, 307, 264, 561, 11, 293, 321, 2673], "temperature": 0.0, "avg_logprob": -0.12059329748153687, "compression_ratio": 1.7004830917874396, "no_speech_prob": 1.1288349924143404e-05}, {"id": 180, "seek": 126624, "start": 1277.28, "end": 1283.28, "text": " forget that one. And then the last one is that we actually need to be thinking about", "tokens": [2870, 300, 472, 13, 400, 550, 264, 1036, 472, 307, 300, 321, 767, 643, 281, 312, 1953, 466], "temperature": 0.0, "avg_logprob": -0.12059329748153687, "compression_ratio": 1.7004830917874396, "no_speech_prob": 1.1288349924143404e-05}, {"id": 181, "seek": 126624, "start": 1283.28, "end": 1294.08, "text": " the human machine interaction, right? So good automation takes the people into account.", "tokens": [264, 1952, 3479, 9285, 11, 558, 30, 407, 665, 17769, 2516, 264, 561, 666, 2696, 13], "temperature": 0.0, "avg_logprob": -0.12059329748153687, "compression_ratio": 1.7004830917874396, "no_speech_prob": 1.1288349924143404e-05}, {"id": 182, "seek": 129408, "start": 1294.08, "end": 1302.0, "text": " Good automation is something which has built in decision points where the person can actually", "tokens": [2205, 17769, 307, 746, 597, 575, 3094, 294, 3537, 2793, 689, 264, 954, 393, 767], "temperature": 0.0, "avg_logprob": -0.12147726482815213, "compression_ratio": 1.3503649635036497, "no_speech_prob": 1.0603650480334181e-05}, {"id": 183, "seek": 129408, "start": 1302.0, "end": 1311.1999999999998, "text": " sit there and say, hmm, this isn't going right. We're not going to proceed, right? And good", "tokens": [1394, 456, 293, 584, 11, 16478, 11, 341, 1943, 380, 516, 558, 13, 492, 434, 406, 516, 281, 8991, 11, 558, 30, 400, 665], "temperature": 0.0, "avg_logprob": -0.12147726482815213, "compression_ratio": 1.3503649635036497, "no_speech_prob": 1.0603650480334181e-05}, {"id": 184, "seek": 131120, "start": 1311.2, "end": 1330.1200000000001, "text": " automation is sort of then a well-understood process, right? So the other thing that is", "tokens": [17769, 307, 1333, 295, 550, 257, 731, 12, 6617, 6431, 1399, 11, 558, 30, 407, 264, 661, 551, 300, 307], "temperature": 0.0, "avg_logprob": -0.0946919804527646, "compression_ratio": 1.6768292682926829, "no_speech_prob": 3.4414099445712054e-06}, {"id": 185, "seek": 131120, "start": 1330.1200000000001, "end": 1334.56, "text": " really important as we look at automation is this issue of feedback, right? Because the", "tokens": [534, 1021, 382, 321, 574, 412, 17769, 307, 341, 2734, 295, 5824, 11, 558, 30, 1436, 264], "temperature": 0.0, "avg_logprob": -0.0946919804527646, "compression_ratio": 1.6768292682926829, "no_speech_prob": 3.4414099445712054e-06}, {"id": 186, "seek": 131120, "start": 1334.56, "end": 1339.8, "text": " more we automate, typically the more we insulate the individual from the feedback of the individual", "tokens": [544, 321, 31605, 11, 5850, 264, 544, 321, 1028, 5256, 264, 2609, 490, 264, 5824, 295, 264, 2609], "temperature": 0.0, "avg_logprob": -0.0946919804527646, "compression_ratio": 1.6768292682926829, "no_speech_prob": 3.4414099445712054e-06}, {"id": 187, "seek": 133980, "start": 1339.8, "end": 1347.1599999999999, "text": " steps that would be right, right? So it's really super important to sit down and think", "tokens": [4439, 300, 576, 312, 558, 11, 558, 30, 407, 309, 311, 534, 1687, 1021, 281, 1394, 760, 293, 519], "temperature": 0.0, "avg_logprob": -0.09335266275608793, "compression_ratio": 1.8059701492537314, "no_speech_prob": 3.800614649662748e-05}, {"id": 188, "seek": 133980, "start": 1347.1599999999999, "end": 1354.36, "text": " about what's the person going to see? What's the human going to see? How's the human going", "tokens": [466, 437, 311, 264, 954, 516, 281, 536, 30, 708, 311, 264, 1952, 516, 281, 536, 30, 1012, 311, 264, 1952, 516], "temperature": 0.0, "avg_logprob": -0.09335266275608793, "compression_ratio": 1.8059701492537314, "no_speech_prob": 3.800614649662748e-05}, {"id": 189, "seek": 133980, "start": 1354.36, "end": 1360.3999999999999, "text": " to be able to interpret this? How much feedback do we want to send? Do we want to send everything", "tokens": [281, 312, 1075, 281, 7302, 341, 30, 1012, 709, 5824, 360, 321, 528, 281, 2845, 30, 1144, 321, 528, 281, 2845, 1203], "temperature": 0.0, "avg_logprob": -0.09335266275608793, "compression_ratio": 1.8059701492537314, "no_speech_prob": 3.800614649662748e-05}, {"id": 190, "seek": 133980, "start": 1360.3999999999999, "end": 1366.52, "text": " that we got? Do we want to send some summary of it? And those are going to be decisions", "tokens": [300, 321, 658, 30, 1144, 321, 528, 281, 2845, 512, 12691, 295, 309, 30, 400, 729, 366, 516, 281, 312, 5327], "temperature": 0.0, "avg_logprob": -0.09335266275608793, "compression_ratio": 1.8059701492537314, "no_speech_prob": 3.800614649662748e-05}, {"id": 191, "seek": 136652, "start": 1366.52, "end": 1371.8799999999999, "text": " that have to be made deliberately based upon the context of what we're doing, as well as", "tokens": [300, 362, 281, 312, 1027, 23506, 2361, 3564, 264, 4319, 295, 437, 321, 434, 884, 11, 382, 731, 382], "temperature": 0.0, "avg_logprob": -0.1647494665466913, "compression_ratio": 1.7580645161290323, "no_speech_prob": 1.424956826667767e-05}, {"id": 192, "seek": 136652, "start": 1371.8799999999999, "end": 1376.6, "text": " a clear understanding of what the failure cases of the automation are. And then of course", "tokens": [257, 1850, 3701, 295, 437, 264, 7763, 3331, 295, 264, 17769, 366, 13, 400, 550, 295, 1164], "temperature": 0.0, "avg_logprob": -0.1647494665466913, "compression_ratio": 1.7580645161290323, "no_speech_prob": 1.424956826667767e-05}, {"id": 193, "seek": 136652, "start": 1376.6, "end": 1379.76, "text": " people actually need to be trained on what the automation is actually doing under the", "tokens": [561, 767, 643, 281, 312, 8895, 322, 437, 264, 17769, 307, 767, 884, 833, 264], "temperature": 0.0, "avg_logprob": -0.1647494665466913, "compression_ratio": 1.7580645161290323, "no_speech_prob": 1.424956826667767e-05}, {"id": 194, "seek": 136652, "start": 1379.76, "end": 1385.56, "text": " hood so that they understand it, rather than just simply saying, oh, push button, okay,", "tokens": [13376, 370, 300, 436, 1223, 309, 11, 2831, 813, 445, 2935, 1566, 11, 1954, 11, 2944, 2960, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.1647494665466913, "compression_ratio": 1.7580645161290323, "no_speech_prob": 1.424956826667767e-05}, {"id": 195, "seek": 136652, "start": 1385.56, "end": 1396.28, "text": " everything good. So the way I always look at it is a lot of people think automation", "tokens": [1203, 665, 13, 407, 264, 636, 286, 1009, 574, 412, 309, 307, 257, 688, 295, 561, 519, 17769], "temperature": 0.0, "avg_logprob": -0.1647494665466913, "compression_ratio": 1.7580645161290323, "no_speech_prob": 1.424956826667767e-05}, {"id": 196, "seek": 139628, "start": 1396.28, "end": 1403.24, "text": " basically, a lot of people think checklists are a step towards automation. I think that", "tokens": [1936, 11, 257, 688, 295, 561, 519, 1520, 36693, 366, 257, 1823, 3030, 17769, 13, 286, 519, 300], "temperature": 0.0, "avg_logprob": -0.1139990248770084, "compression_ratio": 1.8414634146341464, "no_speech_prob": 1.4038717381481547e-05}, {"id": 197, "seek": 139628, "start": 1403.24, "end": 1410.6, "text": " automation should be a step towards a checklist, okay? The relationship should actually be", "tokens": [17769, 820, 312, 257, 1823, 3030, 257, 30357, 11, 1392, 30, 440, 2480, 820, 767, 312], "temperature": 0.0, "avg_logprob": -0.1139990248770084, "compression_ratio": 1.8414634146341464, "no_speech_prob": 1.4038717381481547e-05}, {"id": 198, "seek": 139628, "start": 1410.6, "end": 1415.6, "text": " something around on the other side so that you're thinking about how do I want the human", "tokens": [746, 926, 322, 264, 661, 1252, 370, 300, 291, 434, 1953, 466, 577, 360, 286, 528, 264, 1952], "temperature": 0.0, "avg_logprob": -0.1139990248770084, "compression_ratio": 1.8414634146341464, "no_speech_prob": 1.4038717381481547e-05}, {"id": 199, "seek": 139628, "start": 1415.6, "end": 1420.12, "text": " to interact with this? How do I want the human to perform these? Where do I want the human", "tokens": [281, 4648, 365, 341, 30, 1012, 360, 286, 528, 264, 1952, 281, 2042, 613, 30, 2305, 360, 286, 528, 264, 1952], "temperature": 0.0, "avg_logprob": -0.1139990248770084, "compression_ratio": 1.8414634146341464, "no_speech_prob": 1.4038717381481547e-05}, {"id": 200, "seek": 139628, "start": 1420.12, "end": 1426.08, "text": " to be able to say this isn't going while we are stopping? And those are the sorts of questions", "tokens": [281, 312, 1075, 281, 584, 341, 1943, 380, 516, 1339, 321, 366, 12767, 30, 400, 729, 366, 264, 7527, 295, 1651], "temperature": 0.0, "avg_logprob": -0.1139990248770084, "compression_ratio": 1.8414634146341464, "no_speech_prob": 1.4038717381481547e-05}, {"id": 201, "seek": 142608, "start": 1426.08, "end": 1430.32, "text": " and designs that we have to think about when we're dealing with especially these sorts", "tokens": [293, 11347, 300, 321, 362, 281, 519, 466, 562, 321, 434, 6260, 365, 2318, 613, 7527], "temperature": 0.0, "avg_logprob": -0.19172803438626804, "compression_ratio": 1.502857142857143, "no_speech_prob": 2.388658504060004e-05}, {"id": 202, "seek": 142608, "start": 1430.32, "end": 1435.76, "text": " of critical systems like the databases, where if the database is down, you know, the business", "tokens": [295, 4924, 3652, 411, 264, 22380, 11, 689, 498, 264, 8149, 307, 760, 11, 291, 458, 11, 264, 1606], "temperature": 0.0, "avg_logprob": -0.19172803438626804, "compression_ratio": 1.502857142857143, "no_speech_prob": 2.388658504060004e-05}, {"id": 203, "seek": 142608, "start": 1435.76, "end": 1456.0, "text": " maybe now. So now I want to talk a little bit about why we make mistakes. Now, I'm", "tokens": [1310, 586, 13, 407, 586, 286, 528, 281, 751, 257, 707, 857, 466, 983, 321, 652, 8038, 13, 823, 11, 286, 478], "temperature": 0.0, "avg_logprob": -0.19172803438626804, "compression_ratio": 1.502857142857143, "no_speech_prob": 2.388658504060004e-05}, {"id": 204, "seek": 145600, "start": 1456.0, "end": 1462.96, "text": " mentioned before, computers operate in a closed world, right? They get inputs from us. They", "tokens": [2835, 949, 11, 10807, 9651, 294, 257, 5395, 1002, 11, 558, 30, 814, 483, 15743, 490, 505, 13, 814], "temperature": 0.0, "avg_logprob": -0.16604446683611188, "compression_ratio": 1.611764705882353, "no_speech_prob": 5.500420684256824e-06}, {"id": 205, "seek": 145600, "start": 1462.96, "end": 1474.72, "text": " do processing. They give us outputs, right? We live in an open world. We have, we experience", "tokens": [360, 9007, 13, 814, 976, 505, 23930, 11, 558, 30, 492, 1621, 294, 364, 1269, 1002, 13, 492, 362, 11, 321, 1752], "temperature": 0.0, "avg_logprob": -0.16604446683611188, "compression_ratio": 1.611764705882353, "no_speech_prob": 5.500420684256824e-06}, {"id": 206, "seek": 145600, "start": 1474.72, "end": 1481.12, "text": " things, we perceive things. What we perceive is not a complete model of, or it's not even", "tokens": [721, 11, 321, 20281, 721, 13, 708, 321, 20281, 307, 406, 257, 3566, 2316, 295, 11, 420, 309, 311, 406, 754], "temperature": 0.0, "avg_logprob": -0.16604446683611188, "compression_ratio": 1.611764705882353, "no_speech_prob": 5.500420684256824e-06}, {"id": 207, "seek": 148112, "start": 1481.12, "end": 1488.7199999999998, "text": " complete aspect of what our mental models are. We make inferences based on incomplete", "tokens": [3566, 4171, 295, 437, 527, 4973, 5245, 366, 13, 492, 652, 13596, 2667, 2361, 322, 31709], "temperature": 0.0, "avg_logprob": -0.11333146659276819, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.1295122021692805e-05}, {"id": 208, "seek": 148112, "start": 1488.7199999999998, "end": 1497.4399999999998, "text": " data, okay? And in order to function in this world, we have had to adapt and develop certain", "tokens": [1412, 11, 1392, 30, 400, 294, 1668, 281, 2445, 294, 341, 1002, 11, 321, 362, 632, 281, 6231, 293, 1499, 1629], "temperature": 0.0, "avg_logprob": -0.11333146659276819, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.1295122021692805e-05}, {"id": 209, "seek": 148112, "start": 1497.4399999999998, "end": 1503.76, "text": " kinds of cognitive biases, okay? And a lot of times people look at this and they go,", "tokens": [3685, 295, 15605, 32152, 11, 1392, 30, 400, 257, 688, 295, 1413, 561, 574, 412, 341, 293, 436, 352, 11], "temperature": 0.0, "avg_logprob": -0.11333146659276819, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.1295122021692805e-05}, {"id": 210, "seek": 148112, "start": 1503.76, "end": 1509.4799999999998, "text": " oh, it's not good to be biased. Bias is a bad word. We don't like biases. But the fact", "tokens": [1954, 11, 309, 311, 406, 665, 281, 312, 28035, 13, 363, 4609, 307, 257, 1578, 1349, 13, 492, 500, 380, 411, 32152, 13, 583, 264, 1186], "temperature": 0.0, "avg_logprob": -0.11333146659276819, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.1295122021692805e-05}, {"id": 211, "seek": 150948, "start": 1509.48, "end": 1513.24, "text": " of the matter is that if you could get rid of all of your cognitive biases, you would", "tokens": [295, 264, 1871, 307, 300, 498, 291, 727, 483, 3973, 295, 439, 295, 428, 15605, 32152, 11, 291, 576], "temperature": 0.0, "avg_logprob": -0.10699119148673591, "compression_ratio": 1.6851851851851851, "no_speech_prob": 7.763735084154177e-06}, {"id": 212, "seek": 150948, "start": 1513.24, "end": 1520.52, "text": " be unable to function, okay? Confirmation bias, of course, is one thing that we tend", "tokens": [312, 11299, 281, 2445, 11, 1392, 30, 11701, 3692, 399, 12577, 11, 295, 1164, 11, 307, 472, 551, 300, 321, 3928], "temperature": 0.0, "avg_logprob": -0.10699119148673591, "compression_ratio": 1.6851851851851851, "no_speech_prob": 7.763735084154177e-06}, {"id": 213, "seek": 150948, "start": 1520.52, "end": 1527.6, "text": " to be aware of. But here's another one, continuation bias. Continuation bias is the tendency to", "tokens": [281, 312, 3650, 295, 13, 583, 510, 311, 1071, 472, 11, 29357, 12577, 13, 14674, 16073, 12577, 307, 264, 18187, 281], "temperature": 0.0, "avg_logprob": -0.10699119148673591, "compression_ratio": 1.6851851851851851, "no_speech_prob": 7.763735084154177e-06}, {"id": 214, "seek": 150948, "start": 1527.6, "end": 1534.96, "text": " continue to follow a plan you've put in motion, even when you're starting to get good indications", "tokens": [2354, 281, 1524, 257, 1393, 291, 600, 829, 294, 5394, 11, 754, 562, 291, 434, 2891, 281, 483, 665, 44450], "temperature": 0.0, "avg_logprob": -0.10699119148673591, "compression_ratio": 1.6851851851851851, "no_speech_prob": 7.763735084154177e-06}, {"id": 215, "seek": 153496, "start": 1534.96, "end": 1541.1200000000001, "text": " that that's not a good idea, okay? If you didn't have continuation bias, you might have", "tokens": [300, 300, 311, 406, 257, 665, 1558, 11, 1392, 30, 759, 291, 994, 380, 362, 29357, 12577, 11, 291, 1062, 362], "temperature": 0.0, "avg_logprob": -0.09188776924496606, "compression_ratio": 1.6495327102803738, "no_speech_prob": 6.637275873799808e-06}, {"id": 216, "seek": 153496, "start": 1541.1200000000001, "end": 1549.48, "text": " to sit down and rethink your plan continuously over and over and over again, right? That", "tokens": [281, 1394, 760, 293, 34595, 428, 1393, 15684, 670, 293, 670, 293, 670, 797, 11, 558, 30, 663], "temperature": 0.0, "avg_logprob": -0.09188776924496606, "compression_ratio": 1.6495327102803738, "no_speech_prob": 6.637275873799808e-06}, {"id": 217, "seek": 153496, "start": 1549.48, "end": 1555.2, "text": " wouldn't be very helpful. So continuation bias, just like confirmation bias, actually", "tokens": [2759, 380, 312, 588, 4961, 13, 407, 29357, 12577, 11, 445, 411, 21871, 12577, 11, 767], "temperature": 0.0, "avg_logprob": -0.09188776924496606, "compression_ratio": 1.6495327102803738, "no_speech_prob": 6.637275873799808e-06}, {"id": 218, "seek": 153496, "start": 1555.2, "end": 1560.76, "text": " helps us function in the real world. Problem is, it can also lead us into situations where", "tokens": [3665, 505, 2445, 294, 264, 957, 1002, 13, 11676, 307, 11, 309, 393, 611, 1477, 505, 666, 6851, 689], "temperature": 0.0, "avg_logprob": -0.09188776924496606, "compression_ratio": 1.6495327102803738, "no_speech_prob": 6.637275873799808e-06}, {"id": 219, "seek": 156076, "start": 1560.76, "end": 1565.84, "text": " we do the wrong thing. And so understanding these biases, understanding their implications", "tokens": [321, 360, 264, 2085, 551, 13, 400, 370, 3701, 613, 32152, 11, 3701, 641, 16602], "temperature": 0.0, "avg_logprob": -0.12079819337821301, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.8610895494930446e-05}, {"id": 220, "seek": 156076, "start": 1565.84, "end": 1574.4, "text": " is very clear, is a very important step to being able to notice when they're causing", "tokens": [307, 588, 1850, 11, 307, 257, 588, 1021, 1823, 281, 885, 1075, 281, 3449, 562, 436, 434, 9853], "temperature": 0.0, "avg_logprob": -0.12079819337821301, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.8610895494930446e-05}, {"id": 221, "seek": 156076, "start": 1574.4, "end": 1581.12, "text": " problems and start to trap those sorts of problems. So rather than trying to eliminate", "tokens": [2740, 293, 722, 281, 11487, 729, 7527, 295, 2740, 13, 407, 2831, 813, 1382, 281, 13819], "temperature": 0.0, "avg_logprob": -0.12079819337821301, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.8610895494930446e-05}, {"id": 222, "seek": 156076, "start": 1581.12, "end": 1589.0, "text": " our biases, which is, I think, a way in which I see people typically trying to do this,", "tokens": [527, 32152, 11, 597, 307, 11, 286, 519, 11, 257, 636, 294, 597, 286, 536, 561, 5850, 1382, 281, 360, 341, 11], "temperature": 0.0, "avg_logprob": -0.12079819337821301, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.8610895494930446e-05}, {"id": 223, "seek": 158900, "start": 1589.0, "end": 1594.36, "text": " is better to think about what kinds of problems the biases can cause and how we can detect", "tokens": [307, 1101, 281, 519, 466, 437, 3685, 295, 2740, 264, 32152, 393, 3082, 293, 577, 321, 393, 5531], "temperature": 0.0, "avg_logprob": -0.10946997889765987, "compression_ratio": 1.69377990430622, "no_speech_prob": 2.1760055460617878e-05}, {"id": 224, "seek": 158900, "start": 1594.36, "end": 1602.52, "text": " and trap those problems, right? And there are a large number of these biases, right?", "tokens": [293, 11487, 729, 2740, 11, 558, 30, 400, 456, 366, 257, 2416, 1230, 295, 613, 32152, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.10946997889765987, "compression_ratio": 1.69377990430622, "no_speech_prob": 2.1760055460617878e-05}, {"id": 225, "seek": 158900, "start": 1602.52, "end": 1607.84, "text": " Expectation bias. Expectation bias is also related to confirmation bias. It's the tendency", "tokens": [46318, 399, 12577, 13, 46318, 399, 12577, 307, 611, 4077, 281, 21871, 12577, 13, 467, 311, 264, 18187], "temperature": 0.0, "avg_logprob": -0.10946997889765987, "compression_ratio": 1.69377990430622, "no_speech_prob": 2.1760055460617878e-05}, {"id": 226, "seek": 158900, "start": 1607.84, "end": 1616.96, "text": " to filter out perceptions that don't match your expectations, right? This happens today", "tokens": [281, 6608, 484, 35258, 300, 500, 380, 2995, 428, 9843, 11, 558, 30, 639, 2314, 965], "temperature": 0.0, "avg_logprob": -0.10946997889765987, "compression_ratio": 1.69377990430622, "no_speech_prob": 2.1760055460617878e-05}, {"id": 227, "seek": 161696, "start": 1616.96, "end": 1622.72, "text": " in a lot of environments. It happens in our industry. It obviously still happens in aviation,", "tokens": [294, 257, 688, 295, 12388, 13, 467, 2314, 294, 527, 3518, 13, 467, 2745, 920, 2314, 294, 28831, 11], "temperature": 0.0, "avg_logprob": -0.14853868030366443, "compression_ratio": 1.7471264367816093, "no_speech_prob": 3.5859469790011644e-05}, {"id": 228, "seek": 161696, "start": 1622.72, "end": 1628.16, "text": " fortunately, usually not with serious problems. The most common problem it causes there is", "tokens": [25511, 11, 2673, 406, 365, 3156, 2740, 13, 440, 881, 2689, 1154, 309, 7700, 456, 307], "temperature": 0.0, "avg_logprob": -0.14853868030366443, "compression_ratio": 1.7471264367816093, "no_speech_prob": 3.5859469790011644e-05}, {"id": 229, "seek": 161696, "start": 1628.16, "end": 1633.48, "text": " that the plane comes up to the gate, the pilot says disarmed doors and cross check. Somebody", "tokens": [300, 264, 5720, 1487, 493, 281, 264, 8539, 11, 264, 9691, 1619, 717, 38375, 8077, 293, 3278, 1520, 13, 13463], "temperature": 0.0, "avg_logprob": -0.14853868030366443, "compression_ratio": 1.7471264367816093, "no_speech_prob": 3.5859469790011644e-05}, {"id": 230, "seek": 161696, "start": 1633.48, "end": 1637.76, "text": " misses the door that's going to be opened. The other person cross checks and expectation", "tokens": [29394, 264, 2853, 300, 311, 516, 281, 312, 5625, 13, 440, 661, 954, 3278, 13834, 293, 14334], "temperature": 0.0, "avg_logprob": -0.14853868030366443, "compression_ratio": 1.7471264367816093, "no_speech_prob": 3.5859469790011644e-05}, {"id": 231, "seek": 161696, "start": 1637.76, "end": 1643.0, "text": " bias kicks in and they don't notice that the door is still armed. Go to open the door and", "tokens": [12577, 21293, 294, 293, 436, 500, 380, 3449, 300, 264, 2853, 307, 920, 16297, 13, 1037, 281, 1269, 264, 2853, 293], "temperature": 0.0, "avg_logprob": -0.14853868030366443, "compression_ratio": 1.7471264367816093, "no_speech_prob": 3.5859469790011644e-05}, {"id": 232, "seek": 164300, "start": 1643.0, "end": 1647.6, "text": " guess what happens. Emergency slide deploys. It doesn't harm anybody on the airplane, but", "tokens": [2041, 437, 2314, 13, 30524, 4137, 368, 49522, 13, 467, 1177, 380, 6491, 4472, 322, 264, 17130, 11, 457], "temperature": 0.0, "avg_logprob": -0.17376399945609178, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.1833445569209289e-05}, {"id": 233, "seek": 164300, "start": 1647.6, "end": 1654.28, "text": " it's going to make a bunch of people unhappy because the next leg on the airplane's flight", "tokens": [309, 311, 516, 281, 652, 257, 3840, 295, 561, 22172, 570, 264, 958, 1676, 322, 264, 17130, 311, 7018], "temperature": 0.0, "avg_logprob": -0.17376399945609178, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.1833445569209289e-05}, {"id": 234, "seek": 164300, "start": 1654.28, "end": 1659.8, "text": " is going to get canceled. And that's usually the worst that happens.", "tokens": [307, 516, 281, 483, 24839, 13, 400, 300, 311, 2673, 264, 5855, 300, 2314, 13], "temperature": 0.0, "avg_logprob": -0.17376399945609178, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.1833445569209289e-05}, {"id": 235, "seek": 164300, "start": 1659.8, "end": 1666.72, "text": " But these are important things and we have to recognize that these sorts of biases are", "tokens": [583, 613, 366, 1021, 721, 293, 321, 362, 281, 5521, 300, 613, 7527, 295, 32152, 366], "temperature": 0.0, "avg_logprob": -0.17376399945609178, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.1833445569209289e-05}, {"id": 236, "seek": 166672, "start": 1666.72, "end": 1675.2, "text": " going to happen and that our ability to maintain a situation awareness in the course of these", "tokens": [516, 281, 1051, 293, 300, 527, 3485, 281, 6909, 257, 2590, 8888, 294, 264, 1164, 295, 613], "temperature": 0.0, "avg_logprob": -0.15702922308622902, "compression_ratio": 1.5755813953488371, "no_speech_prob": 9.363155186292715e-06}, {"id": 237, "seek": 166672, "start": 1675.2, "end": 1687.76, "text": " biases is very much tied to, very much tied to how aware we are of the kinds of problems", "tokens": [32152, 307, 588, 709, 9601, 281, 11, 588, 709, 9601, 281, 577, 3650, 321, 366, 295, 264, 3685, 295, 2740], "temperature": 0.0, "avg_logprob": -0.15702922308622902, "compression_ratio": 1.5755813953488371, "no_speech_prob": 9.363155186292715e-06}, {"id": 238, "seek": 166672, "start": 1687.76, "end": 1693.6000000000001, "text": " that they can cause, right? Because, you know, we form this mental model. We're going to", "tokens": [300, 436, 393, 3082, 11, 558, 30, 1436, 11, 291, 458, 11, 321, 1254, 341, 4973, 2316, 13, 492, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.15702922308622902, "compression_ratio": 1.5755813953488371, "no_speech_prob": 9.363155186292715e-06}, {"id": 239, "seek": 169360, "start": 1693.6, "end": 1698.1999999999998, "text": " interpret things according to that mental model. We're going to continue our existing", "tokens": [7302, 721, 4650, 281, 300, 4973, 2316, 13, 492, 434, 516, 281, 2354, 527, 6741], "temperature": 0.0, "avg_logprob": -0.13302515922708713, "compression_ratio": 1.6475409836065573, "no_speech_prob": 1.1649653970380314e-05}, {"id": 240, "seek": 169360, "start": 1698.1999999999998, "end": 1703.9599999999998, "text": " plans and things like that. And when somebody says, hey, wait, maybe this isn't right, then", "tokens": [5482, 293, 721, 411, 300, 13, 400, 562, 2618, 1619, 11, 4177, 11, 1699, 11, 1310, 341, 1943, 380, 558, 11, 550], "temperature": 0.0, "avg_logprob": -0.13302515922708713, "compression_ratio": 1.6475409836065573, "no_speech_prob": 1.1649653970380314e-05}, {"id": 241, "seek": 169360, "start": 1703.9599999999998, "end": 1709.0, "text": " that's suddenly an opportunity to go, hey, my bias is maybe leading me astray. Let's", "tokens": [300, 311, 5800, 364, 2650, 281, 352, 11, 4177, 11, 452, 12577, 307, 1310, 5775, 385, 5357, 3458, 13, 961, 311], "temperature": 0.0, "avg_logprob": -0.13302515922708713, "compression_ratio": 1.6475409836065573, "no_speech_prob": 1.1649653970380314e-05}, {"id": 242, "seek": 169360, "start": 1709.0, "end": 1713.6, "text": " sit down and figure out what's going on and verify.", "tokens": [1394, 760, 293, 2573, 484, 437, 311, 516, 322, 293, 16888, 13], "temperature": 0.0, "avg_logprob": -0.13302515922708713, "compression_ratio": 1.6475409836065573, "no_speech_prob": 1.1649653970380314e-05}, {"id": 243, "seek": 169360, "start": 1713.6, "end": 1719.1999999999998, "text": " And human factors training actually tends to include exercises or training specifically", "tokens": [400, 1952, 6771, 3097, 767, 12258, 281, 4090, 11900, 420, 3097, 4682], "temperature": 0.0, "avg_logprob": -0.13302515922708713, "compression_ratio": 1.6475409836065573, "no_speech_prob": 1.1649653970380314e-05}, {"id": 244, "seek": 171920, "start": 1719.2, "end": 1735.68, "text": " aimed at doing that. So, second major issue is reversion to prior behavior under stress.", "tokens": [20540, 412, 884, 300, 13, 407, 11, 1150, 2563, 2734, 307, 14582, 313, 281, 4059, 5223, 833, 4244, 13], "temperature": 0.0, "avg_logprob": -0.12995928128560383, "compression_ratio": 1.5063291139240507, "no_speech_prob": 2.1735380869358778e-05}, {"id": 245, "seek": 171920, "start": 1735.68, "end": 1742.52, "text": " Something that happens to all of us when we're under stress, our focus narrows, right? We", "tokens": [6595, 300, 2314, 281, 439, 295, 505, 562, 321, 434, 833, 4244, 11, 527, 1879, 6397, 1509, 11, 558, 30, 492], "temperature": 0.0, "avg_logprob": -0.12995928128560383, "compression_ratio": 1.5063291139240507, "no_speech_prob": 2.1735380869358778e-05}, {"id": 246, "seek": 171920, "start": 1742.52, "end": 1747.52, "text": " start filtering things out and we start resorting to habit.", "tokens": [722, 30822, 721, 484, 293, 321, 722, 19606, 278, 281, 7164, 13], "temperature": 0.0, "avg_logprob": -0.12995928128560383, "compression_ratio": 1.5063291139240507, "no_speech_prob": 2.1735380869358778e-05}, {"id": 247, "seek": 174752, "start": 1747.52, "end": 1753.08, "text": " What this also means is that in a database team, when there's an outage, if we're not", "tokens": [708, 341, 611, 1355, 307, 300, 294, 257, 8149, 1469, 11, 562, 456, 311, 364, 484, 609, 11, 498, 321, 434, 406], "temperature": 0.0, "avg_logprob": -0.11845054626464843, "compression_ratio": 1.7421875, "no_speech_prob": 8.254727617895696e-06}, {"id": 248, "seek": 174752, "start": 1753.08, "end": 1758.96, "text": " careful, we will resort to the things that we're used to doing, even if we have decided", "tokens": [5026, 11, 321, 486, 19606, 281, 264, 721, 300, 321, 434, 1143, 281, 884, 11, 754, 498, 321, 362, 3047], "temperature": 0.0, "avg_logprob": -0.11845054626464843, "compression_ratio": 1.7421875, "no_speech_prob": 8.254727617895696e-06}, {"id": 249, "seek": 174752, "start": 1758.96, "end": 1763.8799999999999, "text": " that they're not maybe the best ways forward. And, you know, I've watched cases where, you", "tokens": [300, 436, 434, 406, 1310, 264, 1151, 2098, 2128, 13, 400, 11, 291, 458, 11, 286, 600, 6337, 3331, 689, 11, 291], "temperature": 0.0, "avg_logprob": -0.11845054626464843, "compression_ratio": 1.7421875, "no_speech_prob": 8.254727617895696e-06}, {"id": 250, "seek": 174752, "start": 1763.8799999999999, "end": 1768.96, "text": " know, incidents happen and, you know, if a company has been really trying to move towards", "tokens": [458, 11, 21139, 1051, 293, 11, 291, 458, 11, 498, 257, 2237, 575, 668, 534, 1382, 281, 1286, 3030], "temperature": 0.0, "avg_logprob": -0.11845054626464843, "compression_ratio": 1.7421875, "no_speech_prob": 8.254727617895696e-06}, {"id": 251, "seek": 174752, "start": 1768.96, "end": 1774.44, "text": " a more collaborative approach to incidents, that suddenly when the incident happens, people", "tokens": [257, 544, 16555, 3109, 281, 21139, 11, 300, 5800, 562, 264, 9348, 2314, 11, 561], "temperature": 0.0, "avg_logprob": -0.11845054626464843, "compression_ratio": 1.7421875, "no_speech_prob": 8.254727617895696e-06}, {"id": 252, "seek": 177444, "start": 1774.44, "end": 1779.1200000000001, "text": " are getting stressed out and they're going back to this like hyper-individualistic cowboy", "tokens": [366, 1242, 14471, 484, 293, 436, 434, 516, 646, 281, 341, 411, 9848, 12, 471, 33323, 3142, 39174], "temperature": 0.0, "avg_logprob": -0.1527914836488921, "compression_ratio": 1.6255506607929515, "no_speech_prob": 1.1836761586891953e-05}, {"id": 253, "seek": 177444, "start": 1779.1200000000001, "end": 1785.76, "text": " incident response. And a lot of that is just simply due to stress. It's a very well-documented", "tokens": [9348, 4134, 13, 400, 257, 688, 295, 300, 307, 445, 2935, 3462, 281, 4244, 13, 467, 311, 257, 588, 731, 12, 67, 35739], "temperature": 0.0, "avg_logprob": -0.1527914836488921, "compression_ratio": 1.6255506607929515, "no_speech_prob": 1.1836761586891953e-05}, {"id": 254, "seek": 177444, "start": 1785.76, "end": 1792.0800000000002, "text": " part of the stress response. One thing that we got at a just with the human factors training", "tokens": [644, 295, 264, 4244, 4134, 13, 1485, 551, 300, 321, 658, 412, 257, 445, 365, 264, 1952, 6771, 3097], "temperature": 0.0, "avg_logprob": -0.1527914836488921, "compression_ratio": 1.6255506607929515, "no_speech_prob": 1.1836761586891953e-05}, {"id": 255, "seek": 177444, "start": 1792.0800000000002, "end": 1800.48, "text": " was a strong understanding of that problem as well as good understandings of how to measure", "tokens": [390, 257, 2068, 3701, 295, 300, 1154, 382, 731, 382, 665, 1223, 1109, 295, 577, 281, 3481], "temperature": 0.0, "avg_logprob": -0.1527914836488921, "compression_ratio": 1.6255506607929515, "no_speech_prob": 1.1836761586891953e-05}, {"id": 256, "seek": 180048, "start": 1800.48, "end": 1806.8, "text": " the stress so that we could actually kind of keep an eye on it.", "tokens": [264, 4244, 370, 300, 321, 727, 767, 733, 295, 1066, 364, 3313, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.16743005708206532, "compression_ratio": 1.5185185185185186, "no_speech_prob": 7.0640135163557716e-06}, {"id": 257, "seek": 180048, "start": 1806.8, "end": 1813.3600000000001, "text": " Another major point that causes problems, and I've alluded to this before, is fatigue.", "tokens": [3996, 2563, 935, 300, 7700, 2740, 11, 293, 286, 600, 33919, 281, 341, 949, 11, 307, 20574, 13], "temperature": 0.0, "avg_logprob": -0.16743005708206532, "compression_ratio": 1.5185185185185186, "no_speech_prob": 7.0640135163557716e-06}, {"id": 258, "seek": 180048, "start": 1813.3600000000001, "end": 1818.4, "text": " How often do we see people who have a rough on call night, who come back in the next day", "tokens": [1012, 2049, 360, 321, 536, 561, 567, 362, 257, 5903, 322, 818, 1818, 11, 567, 808, 646, 294, 264, 958, 786], "temperature": 0.0, "avg_logprob": -0.16743005708206532, "compression_ratio": 1.5185185185185186, "no_speech_prob": 7.0640135163557716e-06}, {"id": 259, "seek": 180048, "start": 1818.4, "end": 1825.0, "text": " and start working on stuff? How often are we willing to say to that person, no, go home,", "tokens": [293, 722, 1364, 322, 1507, 30, 1012, 2049, 366, 321, 4950, 281, 584, 281, 300, 954, 11, 572, 11, 352, 1280, 11], "temperature": 0.0, "avg_logprob": -0.16743005708206532, "compression_ratio": 1.5185185185185186, "no_speech_prob": 7.0640135163557716e-06}, {"id": 260, "seek": 182500, "start": 1825.0, "end": 1835.28, "text": " get some rest, I don't want you working on this stuff right now? Right? How often have", "tokens": [483, 512, 1472, 11, 286, 500, 380, 528, 291, 1364, 322, 341, 1507, 558, 586, 30, 1779, 30, 1012, 2049, 362], "temperature": 0.0, "avg_logprob": -0.11331558227539062, "compression_ratio": 1.441025641025641, "no_speech_prob": 1.0934206329693552e-05}, {"id": 261, "seek": 182500, "start": 1835.28, "end": 1842.56, "text": " we seen people who are on call for an extended time period and a rough shift make mistakes", "tokens": [321, 1612, 561, 567, 366, 322, 818, 337, 364, 10913, 565, 2896, 293, 257, 5903, 5513, 652, 8038], "temperature": 0.0, "avg_logprob": -0.11331558227539062, "compression_ratio": 1.441025641025641, "no_speech_prob": 1.0934206329693552e-05}, {"id": 262, "seek": 182500, "start": 1842.56, "end": 1850.72, "text": " after several days of continuous sleep interruptions? You know, do we start to think about the question", "tokens": [934, 2940, 1708, 295, 10957, 2817, 12729, 626, 30, 509, 458, 11, 360, 321, 722, 281, 519, 466, 264, 1168], "temperature": 0.0, "avg_logprob": -0.11331558227539062, "compression_ratio": 1.441025641025641, "no_speech_prob": 1.0934206329693552e-05}, {"id": 263, "seek": 185072, "start": 1850.72, "end": 1857.44, "text": " of maybe when this happens, we should be switching these people out more frequently.", "tokens": [295, 1310, 562, 341, 2314, 11, 321, 820, 312, 16493, 613, 561, 484, 544, 10374, 13], "temperature": 0.0, "avg_logprob": -0.12696869032723562, "compression_ratio": 1.6291079812206573, "no_speech_prob": 3.64057304977905e-05}, {"id": 264, "seek": 185072, "start": 1857.44, "end": 1864.44, "text": " In the airlines, before any flight happens, the flight crew get together and they check", "tokens": [682, 264, 37147, 11, 949, 604, 7018, 2314, 11, 264, 7018, 7260, 483, 1214, 293, 436, 1520], "temperature": 0.0, "avg_logprob": -0.12696869032723562, "compression_ratio": 1.6291079812206573, "no_speech_prob": 3.64057304977905e-05}, {"id": 265, "seek": 185072, "start": 1864.44, "end": 1870.28, "text": " out how each other are doing, right? And there is an expectation that there is a standby", "tokens": [484, 577, 1184, 661, 366, 884, 11, 558, 30, 400, 456, 307, 364, 14334, 300, 456, 307, 257, 50170], "temperature": 0.0, "avg_logprob": -0.12696869032723562, "compression_ratio": 1.6291079812206573, "no_speech_prob": 3.64057304977905e-05}, {"id": 266, "seek": 185072, "start": 1870.28, "end": 1875.28, "text": " flight crew so that if you're not feeling your best, you can say, hey, I didn't sleep", "tokens": [7018, 7260, 370, 300, 498, 291, 434, 406, 2633, 428, 1151, 11, 291, 393, 584, 11, 4177, 11, 286, 994, 380, 2817], "temperature": 0.0, "avg_logprob": -0.12696869032723562, "compression_ratio": 1.6291079812206573, "no_speech_prob": 3.64057304977905e-05}, {"id": 267, "seek": 187528, "start": 1875.28, "end": 1883.52, "text": " well last night, I don't want to fly. And that's another thing which has really helped", "tokens": [731, 1036, 1818, 11, 286, 500, 380, 528, 281, 3603, 13, 400, 300, 311, 1071, 551, 597, 575, 534, 4254], "temperature": 0.0, "avg_logprob": -0.14853307283841646, "compression_ratio": 1.4262295081967213, "no_speech_prob": 1.8572010958450846e-05}, {"id": 268, "seek": 187528, "start": 1883.52, "end": 1889.44, "text": " the increase of the safety, something we should probably think about doing. You're getting", "tokens": [264, 3488, 295, 264, 4514, 11, 746, 321, 820, 1391, 519, 466, 884, 13, 509, 434, 1242], "temperature": 0.0, "avg_logprob": -0.14853307283841646, "compression_ratio": 1.4262295081967213, "no_speech_prob": 1.8572010958450846e-05}, {"id": 269, "seek": 187528, "start": 1889.44, "end": 1898.44, "text": " tired from the on call, time to switch you out. Do we? I have never worked anywhere", "tokens": [5868, 490, 264, 322, 818, 11, 565, 281, 3679, 291, 484, 13, 1144, 321, 30, 286, 362, 1128, 2732, 4992], "temperature": 0.0, "avg_logprob": -0.14853307283841646, "compression_ratio": 1.4262295081967213, "no_speech_prob": 1.8572010958450846e-05}, {"id": 270, "seek": 189844, "start": 1898.44, "end": 1913.8, "text": " the day. So a final major point on how and why we make mistakes has to do with a term", "tokens": [264, 786, 13, 407, 257, 2572, 2563, 935, 322, 577, 293, 983, 321, 652, 8038, 575, 281, 360, 365, 257, 1433], "temperature": 0.0, "avg_logprob": -0.16540599876726178, "compression_ratio": 1.4640883977900552, "no_speech_prob": 1.1820680811069906e-05}, {"id": 271, "seek": 189844, "start": 1913.8, "end": 1920.3200000000002, "text": " in human factors, Lingo, called workload. Now, I don't like this term in this context", "tokens": [294, 1952, 6771, 11, 441, 18459, 11, 1219, 20139, 13, 823, 11, 286, 500, 380, 411, 341, 1433, 294, 341, 4319], "temperature": 0.0, "avg_logprob": -0.16540599876726178, "compression_ratio": 1.4640883977900552, "no_speech_prob": 1.1820680811069906e-05}, {"id": 272, "seek": 189844, "start": 1920.3200000000002, "end": 1925.52, "text": " because when we say workload in here, everybody is thinking, oh, I have so many things I need", "tokens": [570, 562, 321, 584, 20139, 294, 510, 11, 2201, 307, 1953, 11, 1954, 11, 286, 362, 370, 867, 721, 286, 643], "temperature": 0.0, "avg_logprob": -0.16540599876726178, "compression_ratio": 1.4640883977900552, "no_speech_prob": 1.1820680811069906e-05}, {"id": 273, "seek": 192552, "start": 1925.52, "end": 1932.0, "text": " to get done this month. But in the human factor side, workload doesn't mean over the next", "tokens": [281, 483, 1096, 341, 1618, 13, 583, 294, 264, 1952, 5952, 1252, 11, 20139, 1177, 380, 914, 670, 264, 958], "temperature": 0.0, "avg_logprob": -0.10833589890423943, "compression_ratio": 1.5598290598290598, "no_speech_prob": 8.135227290040348e-06}, {"id": 274, "seek": 192552, "start": 1932.0, "end": 1937.56, "text": " month or over the next week, although planning that can be helpful. What it really means", "tokens": [1618, 420, 670, 264, 958, 1243, 11, 4878, 5038, 300, 393, 312, 4961, 13, 708, 309, 534, 1355], "temperature": 0.0, "avg_logprob": -0.10833589890423943, "compression_ratio": 1.5598290598290598, "no_speech_prob": 8.135227290040348e-06}, {"id": 275, "seek": 192552, "start": 1937.56, "end": 1946.76, "text": " is how many tasks are you having to pay attention to right now? How many people here can actually", "tokens": [307, 577, 867, 9608, 366, 291, 1419, 281, 1689, 3202, 281, 558, 586, 30, 1012, 867, 561, 510, 393, 767], "temperature": 0.0, "avg_logprob": -0.10833589890423943, "compression_ratio": 1.5598290598290598, "no_speech_prob": 8.135227290040348e-06}, {"id": 276, "seek": 192552, "start": 1946.76, "end": 1953.72, "text": " listen to and understand two conversations at the same time? Nobody? Maybe it's possible", "tokens": [2140, 281, 293, 1223, 732, 7315, 412, 264, 912, 565, 30, 9297, 30, 2704, 309, 311, 1944], "temperature": 0.0, "avg_logprob": -0.10833589890423943, "compression_ratio": 1.5598290598290598, "no_speech_prob": 8.135227290040348e-06}, {"id": 277, "seek": 195372, "start": 1953.72, "end": 1961.44, "text": " for some people to train that. But a brain can't, there are certain kinds of things", "tokens": [337, 512, 561, 281, 3847, 300, 13, 583, 257, 3567, 393, 380, 11, 456, 366, 1629, 3685, 295, 721], "temperature": 0.0, "avg_logprob": -0.18877517120747628, "compression_ratio": 1.5535714285714286, "no_speech_prob": 2.315755955351051e-05}, {"id": 278, "seek": 195372, "start": 1961.44, "end": 1969.92, "text": " that our brains can't parallelize very well. Understanding where those boundaries are.", "tokens": [300, 527, 15442, 393, 380, 8952, 1125, 588, 731, 13, 36858, 689, 729, 13180, 366, 13], "temperature": 0.0, "avg_logprob": -0.18877517120747628, "compression_ratio": 1.5535714285714286, "no_speech_prob": 2.315755955351051e-05}, {"id": 279, "seek": 195372, "start": 1969.92, "end": 1977.76, "text": " Switching and flipping between tasks. How much can we reduce that workload? That's actually", "tokens": [13893, 278, 293, 26886, 1296, 9608, 13, 1012, 709, 393, 321, 5407, 300, 20139, 30, 663, 311, 767], "temperature": 0.0, "avg_logprob": -0.18877517120747628, "compression_ratio": 1.5535714285714286, "no_speech_prob": 2.315755955351051e-05}, {"id": 280, "seek": 195372, "start": 1977.76, "end": 1981.64, "text": " really important because one of the things I've seen happen is you have your standard", "tokens": [534, 1021, 570, 472, 295, 264, 721, 286, 600, 1612, 1051, 307, 291, 362, 428, 3832], "temperature": 0.0, "avg_logprob": -0.18877517120747628, "compression_ratio": 1.5535714285714286, "no_speech_prob": 2.315755955351051e-05}, {"id": 281, "seek": 198164, "start": 1981.64, "end": 1986.76, "text": " runbook and the way most people write their runbooks is you have step, explanation, discussion", "tokens": [1190, 2939, 293, 264, 636, 881, 561, 2464, 641, 1190, 15170, 307, 291, 362, 1823, 11, 10835, 11, 5017], "temperature": 0.0, "avg_logprob": -0.20080152239118304, "compression_ratio": 1.4761904761904763, "no_speech_prob": 3.115597792202607e-05}, {"id": 282, "seek": 198164, "start": 1986.76, "end": 1992.68, "text": " of output, next step. What happens at three in the morning if you've never done this particular", "tokens": [295, 5598, 11, 958, 1823, 13, 708, 2314, 412, 1045, 294, 264, 2446, 498, 291, 600, 1128, 1096, 341, 1729], "temperature": 0.0, "avg_logprob": -0.20080152239118304, "compression_ratio": 1.4761904761904763, "no_speech_prob": 3.115597792202607e-05}, {"id": 283, "seek": 198164, "start": 1992.68, "end": 2002.16, "text": " process is step. Okay? Yes, it did what I expected to. Where's the next step? It becomes", "tokens": [1399, 307, 1823, 13, 1033, 30, 1079, 11, 309, 630, 437, 286, 5176, 281, 13, 2305, 311, 264, 958, 1823, 30, 467, 3643], "temperature": 0.0, "avg_logprob": -0.20080152239118304, "compression_ratio": 1.4761904761904763, "no_speech_prob": 3.115597792202607e-05}, {"id": 284, "seek": 200216, "start": 2002.16, "end": 2011.92, "text": " really, really, really easy to miss the next step in your checklist or to miss critical", "tokens": [534, 11, 534, 11, 534, 1858, 281, 1713, 264, 958, 1823, 294, 428, 30357, 420, 281, 1713, 4924], "temperature": 0.0, "avg_logprob": -0.11317508939712767, "compression_ratio": 1.5574712643678161, "no_speech_prob": 8.929433533921838e-06}, {"id": 285, "seek": 200216, "start": 2011.92, "end": 2018.2, "text": " details that are kind of obscured in the fact that now you're having to read through paragraphs", "tokens": [4365, 300, 366, 733, 295, 22082, 3831, 294, 264, 1186, 300, 586, 291, 434, 1419, 281, 1401, 807, 48910], "temperature": 0.0, "avg_logprob": -0.11317508939712767, "compression_ratio": 1.5574712643678161, "no_speech_prob": 8.929433533921838e-06}, {"id": 286, "seek": 200216, "start": 2018.2, "end": 2023.76, "text": " at three in the morning while troubleshooting a broken system. One of the things that I", "tokens": [412, 1045, 294, 264, 2446, 1339, 15379, 47011, 257, 5463, 1185, 13, 1485, 295, 264, 721, 300, 286], "temperature": 0.0, "avg_logprob": -0.11317508939712767, "compression_ratio": 1.5574712643678161, "no_speech_prob": 8.929433533921838e-06}, {"id": 287, "seek": 202376, "start": 2023.76, "end": 2034.76, "text": " did while it was at adjust is I started writing some of our, I guess I would call them unusual", "tokens": [630, 1339, 309, 390, 412, 4369, 307, 286, 1409, 3579, 512, 295, 527, 11, 286, 2041, 286, 576, 818, 552, 10901], "temperature": 0.0, "avg_logprob": -0.14820505030014935, "compression_ratio": 1.6728971962616823, "no_speech_prob": 3.4440884064679267e-06}, {"id": 288, "seek": 202376, "start": 2034.76, "end": 2042.0, "text": " procedure checklists. A non-normal procedure checklist. So things that happen when, things", "tokens": [10747, 1520, 36693, 13, 316, 2107, 12, 23157, 10747, 30357, 13, 407, 721, 300, 1051, 562, 11, 721], "temperature": 0.0, "avg_logprob": -0.14820505030014935, "compression_ratio": 1.6728971962616823, "no_speech_prob": 3.4440884064679267e-06}, {"id": 289, "seek": 202376, "start": 2042.0, "end": 2046.04, "text": " that you do when something goes wrong. Things that you might have to do at three in the", "tokens": [300, 291, 360, 562, 746, 1709, 2085, 13, 9514, 300, 291, 1062, 362, 281, 360, 412, 1045, 294, 264], "temperature": 0.0, "avg_logprob": -0.14820505030014935, "compression_ratio": 1.6728971962616823, "no_speech_prob": 3.4440884064679267e-06}, {"id": 290, "seek": 202376, "start": 2046.04, "end": 2051.8, "text": " morning without doing them for any of the previous three months. And what I ended up", "tokens": [2446, 1553, 884, 552, 337, 604, 295, 264, 3894, 1045, 2493, 13, 400, 437, 286, 4590, 493], "temperature": 0.0, "avg_logprob": -0.14820505030014935, "compression_ratio": 1.6728971962616823, "no_speech_prob": 3.4440884064679267e-06}, {"id": 291, "seek": 205180, "start": 2051.8, "end": 2055.8, "text": " doing in this case, and it was actually, this is a good opportunity to talk about some of", "tokens": [884, 294, 341, 1389, 11, 293, 309, 390, 767, 11, 341, 307, 257, 665, 2650, 281, 751, 466, 512, 295], "temperature": 0.0, "avg_logprob": -0.13185716711956522, "compression_ratio": 1.606936416184971, "no_speech_prob": 1.3158555702830199e-05}, {"id": 292, "seek": 205180, "start": 2055.8, "end": 2070.28, "text": " the main benefits of this sort of training, is that we talked about, we talked about basically", "tokens": [264, 2135, 5311, 295, 341, 1333, 295, 3097, 11, 307, 300, 321, 2825, 466, 11, 321, 2825, 466, 1936], "temperature": 0.0, "avg_logprob": -0.13185716711956522, "compression_ratio": 1.606936416184971, "no_speech_prob": 1.3158555702830199e-05}, {"id": 293, "seek": 205180, "start": 2070.28, "end": 2077.44, "text": " what we did was we did the following format. It's a bullet point. Here's what you can ideally", "tokens": [437, 321, 630, 390, 321, 630, 264, 3480, 7877, 13, 467, 311, 257, 11632, 935, 13, 1692, 311, 437, 291, 393, 22915], "temperature": 0.0, "avg_logprob": -0.13185716711956522, "compression_ratio": 1.606936416184971, "no_speech_prob": 1.3158555702830199e-05}, {"id": 294, "seek": 207744, "start": 2077.44, "end": 2085.08, "text": " copy and paste into the terminal. Expected output, warning signs, all in bullet points", "tokens": [5055, 293, 9163, 666, 264, 14709, 13, 2111, 10729, 5598, 11, 9164, 7880, 11, 439, 294, 11632, 2793], "temperature": 0.0, "avg_logprob": -0.15327173055604446, "compression_ratio": 1.613953488372093, "no_speech_prob": 1.8597966118250042e-05}, {"id": 295, "seek": 207744, "start": 2085.08, "end": 2093.28, "text": " and then back, unindented again, the next bullet point. So they're hierarchical, it's", "tokens": [293, 550, 646, 11, 517, 471, 6003, 797, 11, 264, 958, 11632, 935, 13, 407, 436, 434, 35250, 804, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.15327173055604446, "compression_ratio": 1.613953488372093, "no_speech_prob": 1.8597966118250042e-05}, {"id": 296, "seek": 207744, "start": 2093.28, "end": 2098.04, "text": " easy to scan, but then your main points are all really, really, really short. And then", "tokens": [1858, 281, 11049, 11, 457, 550, 428, 2135, 2793, 366, 439, 534, 11, 534, 11, 534, 2099, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.15327173055604446, "compression_ratio": 1.613953488372093, "no_speech_prob": 1.8597966118250042e-05}, {"id": 297, "seek": 207744, "start": 2098.04, "end": 2101.84, "text": " all of the major description that would be in those paragraphs would be moved into foot", "tokens": [439, 295, 264, 2563, 3855, 300, 576, 312, 294, 729, 48910, 576, 312, 4259, 666, 2671], "temperature": 0.0, "avg_logprob": -0.15327173055604446, "compression_ratio": 1.613953488372093, "no_speech_prob": 1.8597966118250042e-05}, {"id": 298, "seek": 210184, "start": 2101.84, "end": 2109.36, "text": " notes. And those would all be hyperlinked. So you run a test, you know, you run a step.", "tokens": [5570, 13, 400, 729, 576, 439, 312, 9848, 22473, 292, 13, 407, 291, 1190, 257, 1500, 11, 291, 458, 11, 291, 1190, 257, 1823, 13], "temperature": 0.0, "avg_logprob": -0.13643976052602133, "compression_ratio": 1.7019230769230769, "no_speech_prob": 4.676887328969315e-05}, {"id": 299, "seek": 210184, "start": 2109.36, "end": 2112.44, "text": " Something doesn't look quite right, you want to see the longer description, you click that", "tokens": [6595, 1177, 380, 574, 1596, 558, 11, 291, 528, 281, 536, 264, 2854, 3855, 11, 291, 2052, 300], "temperature": 0.0, "avg_logprob": -0.13643976052602133, "compression_ratio": 1.7019230769230769, "no_speech_prob": 4.676887328969315e-05}, {"id": 300, "seek": 210184, "start": 2112.44, "end": 2118.6000000000004, "text": " hyperlink, you come down to the footnote, you read the whole thing, decide if you want", "tokens": [9848, 22473, 11, 291, 808, 760, 281, 264, 2671, 22178, 11, 291, 1401, 264, 1379, 551, 11, 4536, 498, 291, 528], "temperature": 0.0, "avg_logprob": -0.13643976052602133, "compression_ratio": 1.7019230769230769, "no_speech_prob": 4.676887328969315e-05}, {"id": 301, "seek": 210184, "start": 2118.6000000000004, "end": 2128.76, "text": " to proceed or not, and then decide. And what this allowed us to do was to take, like the", "tokens": [281, 8991, 420, 406, 11, 293, 550, 4536, 13, 400, 437, 341, 4350, 505, 281, 360, 390, 281, 747, 11, 411, 264], "temperature": 0.0, "avg_logprob": -0.13643976052602133, "compression_ratio": 1.7019230769230769, "no_speech_prob": 4.676887328969315e-05}, {"id": 302, "seek": 212876, "start": 2128.76, "end": 2136.84, "text": " standard platform team people who are on call and actually have them do error spike maintenance", "tokens": [3832, 3663, 1469, 561, 567, 366, 322, 818, 293, 767, 362, 552, 360, 6713, 21053, 11258], "temperature": 0.0, "avg_logprob": -0.19124010631016322, "compression_ratio": 1.6497695852534562, "no_speech_prob": 5.052721462561749e-05}, {"id": 303, "seek": 212876, "start": 2136.84, "end": 2144.28, "text": " at three in the morning on, as I say, the super critical high-speed database system.", "tokens": [412, 1045, 294, 264, 2446, 322, 11, 382, 286, 584, 11, 264, 1687, 4924, 1090, 12, 22746, 8149, 1185, 13], "temperature": 0.0, "avg_logprob": -0.19124010631016322, "compression_ratio": 1.6497695852534562, "no_speech_prob": 5.052721462561749e-05}, {"id": 304, "seek": 212876, "start": 2144.28, "end": 2151.36, "text": " And before that, every time there was an error spike issue, it was an automatic escalation.", "tokens": [400, 949, 300, 11, 633, 565, 456, 390, 364, 6713, 21053, 2734, 11, 309, 390, 364, 12509, 17871, 399, 13], "temperature": 0.0, "avg_logprob": -0.19124010631016322, "compression_ratio": 1.6497695852534562, "no_speech_prob": 5.052721462561749e-05}, {"id": 305, "seek": 212876, "start": 2151.36, "end": 2154.44, "text": " And it was automatic escalation because we didn't trust that they would be able to do", "tokens": [400, 309, 390, 12509, 17871, 399, 570, 321, 994, 380, 3361, 300, 436, 576, 312, 1075, 281, 360], "temperature": 0.0, "avg_logprob": -0.19124010631016322, "compression_ratio": 1.6497695852534562, "no_speech_prob": 5.052721462561749e-05}, {"id": 306, "seek": 215444, "start": 2154.44, "end": 2159.16, "text": " it or make proper decisions around it. But since we formalized it into checklists and", "tokens": [309, 420, 652, 2296, 5327, 926, 309, 13, 583, 1670, 321, 9860, 1602, 309, 666, 1520, 36693, 293], "temperature": 0.0, "avg_logprob": -0.1224771227155413, "compression_ratio": 1.6221198156682028, "no_speech_prob": 2.2717340470990166e-05}, {"id": 307, "seek": 215444, "start": 2159.16, "end": 2163.8, "text": " we offered some training on them, and we tried to make sure that people kind of understood", "tokens": [321, 8059, 512, 3097, 322, 552, 11, 293, 321, 3031, 281, 652, 988, 300, 561, 733, 295, 7320], "temperature": 0.0, "avg_logprob": -0.1224771227155413, "compression_ratio": 1.6221198156682028, "no_speech_prob": 2.2717340470990166e-05}, {"id": 308, "seek": 215444, "start": 2163.8, "end": 2170.04, "text": " the overall considerations of the processes, then they could do some basic stuff and then", "tokens": [264, 4787, 24070, 295, 264, 7555, 11, 550, 436, 727, 360, 512, 3875, 1507, 293, 550], "temperature": 0.0, "avg_logprob": -0.1224771227155413, "compression_ratio": 1.6221198156682028, "no_speech_prob": 2.2717340470990166e-05}, {"id": 309, "seek": 215444, "start": 2170.04, "end": 2180.84, "text": " call us if there were questions that weren't obviously answered by the documentation.", "tokens": [818, 505, 498, 456, 645, 1651, 300, 4999, 380, 2745, 10103, 538, 264, 14333, 13], "temperature": 0.0, "avg_logprob": -0.1224771227155413, "compression_ratio": 1.6221198156682028, "no_speech_prob": 2.2717340470990166e-05}, {"id": 310, "seek": 218084, "start": 2180.84, "end": 2186.08, "text": " Every very, very good tangible benefit meant that instead of several people waking up in", "tokens": [2048, 588, 11, 588, 665, 27094, 5121, 4140, 300, 2602, 295, 2940, 561, 20447, 493, 294], "temperature": 0.0, "avg_logprob": -0.11350607872009277, "compression_ratio": 1.6135265700483092, "no_speech_prob": 6.040732841938734e-06}, {"id": 311, "seek": 218084, "start": 2186.08, "end": 2192.52, "text": " the middle of the night, they could be done by the on-call engineer.", "tokens": [264, 2808, 295, 264, 1818, 11, 436, 727, 312, 1096, 538, 264, 322, 12, 45459, 11403, 13], "temperature": 0.0, "avg_logprob": -0.11350607872009277, "compression_ratio": 1.6135265700483092, "no_speech_prob": 6.040732841938734e-06}, {"id": 312, "seek": 218084, "start": 2192.52, "end": 2198.88, "text": " So that's a really good example of the benefits that come out of paying attention to that", "tokens": [407, 300, 311, 257, 534, 665, 1365, 295, 264, 5311, 300, 808, 484, 295, 6229, 3202, 281, 300], "temperature": 0.0, "avg_logprob": -0.11350607872009277, "compression_ratio": 1.6135265700483092, "no_speech_prob": 6.040732841938734e-06}, {"id": 313, "seek": 218084, "start": 2198.88, "end": 2203.6400000000003, "text": " workload issue and the sensory overload that happens that's much more serious at three", "tokens": [20139, 2734, 293, 264, 27233, 28777, 300, 2314, 300, 311, 709, 544, 3156, 412, 1045], "temperature": 0.0, "avg_logprob": -0.11350607872009277, "compression_ratio": 1.6135265700483092, "no_speech_prob": 6.040732841938734e-06}, {"id": 314, "seek": 220364, "start": 2203.64, "end": 2213.24, "text": " in the morning than at three in the afternoon. So at this point, it's really important to", "tokens": [294, 264, 2446, 813, 412, 1045, 294, 264, 6499, 13, 407, 412, 341, 935, 11, 309, 311, 534, 1021, 281], "temperature": 0.0, "avg_logprob": -0.10715505159818209, "compression_ratio": 1.6385542168674698, "no_speech_prob": 5.951453658781247e-06}, {"id": 315, "seek": 220364, "start": 2213.24, "end": 2219.96, "text": " recognize that at this point, we're no longer really talking about human error being somebody", "tokens": [5521, 300, 412, 341, 935, 11, 321, 434, 572, 2854, 534, 1417, 466, 1952, 6713, 885, 2618], "temperature": 0.0, "avg_logprob": -0.10715505159818209, "compression_ratio": 1.6385542168674698, "no_speech_prob": 5.951453658781247e-06}, {"id": 316, "seek": 220364, "start": 2219.96, "end": 2226.96, "text": " made a mistake. Instead, we're talking about the need to be able to debug the person and", "tokens": [1027, 257, 6146, 13, 7156, 11, 321, 434, 1417, 466, 264, 643, 281, 312, 1075, 281, 24083, 264, 954, 293], "temperature": 0.0, "avg_logprob": -0.10715505159818209, "compression_ratio": 1.6385542168674698, "no_speech_prob": 5.951453658781247e-06}, {"id": 317, "seek": 222696, "start": 2226.96, "end": 2237.56, "text": " why they made the mistake. And this is something which very often times we don't even try to", "tokens": [983, 436, 1027, 264, 6146, 13, 400, 341, 307, 746, 597, 588, 2049, 1413, 321, 500, 380, 754, 853, 281], "temperature": 0.0, "avg_logprob": -0.11442159084563559, "compression_ratio": 1.3478260869565217, "no_speech_prob": 9.2155087259016e-06}, {"id": 318, "seek": 222696, "start": 2237.56, "end": 2247.56, "text": " do in our industry, but we should. This requires that we have a really good taxonomy of types", "tokens": [360, 294, 527, 3518, 11, 457, 321, 820, 13, 639, 7029, 300, 321, 362, 257, 534, 665, 3366, 23423, 295, 3467], "temperature": 0.0, "avg_logprob": -0.11442159084563559, "compression_ratio": 1.3478260869565217, "no_speech_prob": 9.2155087259016e-06}, {"id": 319, "seek": 224756, "start": 2247.56, "end": 2258.32, "text": " of mistakes. That we can say, okay, situation awareness laps because of sensory overload", "tokens": [295, 8038, 13, 663, 321, 393, 584, 11, 1392, 11, 2590, 8888, 24971, 570, 295, 27233, 28777], "temperature": 0.0, "avg_logprob": -0.24858463964154642, "compression_ratio": 1.4480874316939891, "no_speech_prob": 2.2079555492382497e-05}, {"id": 320, "seek": 224756, "start": 2258.32, "end": 2264.04, "text": " from too many monitoring alerts going off. A very common one that happens in our industry.", "tokens": [490, 886, 867, 11028, 28061, 516, 766, 13, 316, 588, 2689, 472, 300, 2314, 294, 527, 3518, 13], "temperature": 0.0, "avg_logprob": -0.24858463964154642, "compression_ratio": 1.4480874316939891, "no_speech_prob": 2.2079555492382497e-05}, {"id": 321, "seek": 224756, "start": 2264.04, "end": 2275.64, "text": " It's also something that's caused airplane issues. So if we understand that, we know,", "tokens": [467, 311, 611, 746, 300, 311, 7008, 17130, 2663, 13, 407, 498, 321, 1223, 300, 11, 321, 458, 11], "temperature": 0.0, "avg_logprob": -0.24858463964154642, "compression_ratio": 1.4480874316939891, "no_speech_prob": 2.2079555492382497e-05}, {"id": 322, "seek": 227564, "start": 2275.64, "end": 2281.7999999999997, "text": " they lost their situation awareness. They couldn't understand where the problem was. This happened", "tokens": [436, 2731, 641, 2590, 8888, 13, 814, 2809, 380, 1223, 689, 264, 1154, 390, 13, 639, 2011], "temperature": 0.0, "avg_logprob": -0.13710080304192107, "compression_ratio": 1.728301886792453, "no_speech_prob": 1.4720213584951125e-05}, {"id": 323, "seek": 227564, "start": 2281.7999999999997, "end": 2286.8399999999997, "text": " because they had too many alerts they were trying to focus on. Now the question is, are", "tokens": [570, 436, 632, 886, 867, 28061, 436, 645, 1382, 281, 1879, 322, 13, 823, 264, 1168, 307, 11, 366], "temperature": 0.0, "avg_logprob": -0.13710080304192107, "compression_ratio": 1.728301886792453, "no_speech_prob": 1.4720213584951125e-05}, {"id": 324, "seek": 227564, "start": 2286.8399999999997, "end": 2291.16, "text": " we actually throwing too many alerts? Do we need to think about maybe prioritizing things", "tokens": [321, 767, 10238, 886, 867, 28061, 30, 1144, 321, 643, 281, 519, 466, 1310, 14846, 3319, 721], "temperature": 0.0, "avg_logprob": -0.13710080304192107, "compression_ratio": 1.728301886792453, "no_speech_prob": 1.4720213584951125e-05}, {"id": 325, "seek": 227564, "start": 2291.16, "end": 2297.7999999999997, "text": " differently? Do we need to rethink how we do alerting? And suddenly, we have a dimension", "tokens": [7614, 30, 1144, 321, 643, 281, 34595, 577, 321, 360, 419, 27187, 30, 400, 5800, 11, 321, 362, 257, 10139], "temperature": 0.0, "avg_logprob": -0.13710080304192107, "compression_ratio": 1.728301886792453, "no_speech_prob": 1.4720213584951125e-05}, {"id": 326, "seek": 227564, "start": 2297.7999999999997, "end": 2303.8399999999997, "text": " for looking at these problems that we currently don't have. Instead, currently, what happens", "tokens": [337, 1237, 412, 613, 2740, 300, 321, 4362, 500, 380, 362, 13, 7156, 11, 4362, 11, 437, 2314], "temperature": 0.0, "avg_logprob": -0.13710080304192107, "compression_ratio": 1.728301886792453, "no_speech_prob": 1.4720213584951125e-05}, {"id": 327, "seek": 230384, "start": 2303.84, "end": 2308.36, "text": " most places I've worked is, okay, something went wrong. We didn't spot it. Therefore,", "tokens": [881, 3190, 286, 600, 2732, 307, 11, 1392, 11, 746, 1437, 2085, 13, 492, 994, 380, 4008, 309, 13, 7504, 11], "temperature": 0.0, "avg_logprob": -0.23590636521242977, "compression_ratio": 1.521551724137931, "no_speech_prob": 2.5060007828869857e-05}, {"id": 328, "seek": 230384, "start": 2308.36, "end": 2313.48, "text": " let's add another alert over this. But when I was at the delivery here, we actually had", "tokens": [718, 311, 909, 1071, 9615, 670, 341, 13, 583, 562, 286, 390, 412, 264, 8982, 510, 11, 321, 767, 632], "temperature": 0.0, "avg_logprob": -0.23590636521242977, "compression_ratio": 1.521551724137931, "no_speech_prob": 2.5060007828869857e-05}, {"id": 329, "seek": 230384, "start": 2313.48, "end": 2323.6800000000003, "text": " a major incident where somebody, again, missed a problem relating to a database, relating", "tokens": [257, 2563, 9348, 689, 2618, 11, 797, 11, 6721, 257, 1154, 23968, 281, 257, 8149, 11, 23968], "temperature": 0.0, "avg_logprob": -0.23590636521242977, "compression_ratio": 1.521551724137931, "no_speech_prob": 2.5060007828869857e-05}, {"id": 330, "seek": 230384, "start": 2323.6800000000003, "end": 2329.8, "text": " to a Postgres instance, I believe, if I remember right. Despite the fact that it was well", "tokens": [281, 257, 10223, 45189, 5197, 11, 286, 1697, 11, 498, 286, 1604, 558, 13, 11334, 264, 1186, 300, 309, 390, 731], "temperature": 0.0, "avg_logprob": -0.23590636521242977, "compression_ratio": 1.521551724137931, "no_speech_prob": 2.5060007828869857e-05}, {"id": 331, "seek": 232980, "start": 2329.8, "end": 2334.6800000000003, "text": " alerted. I was talking to somebody afterwards and he says, do you know what the false positivity", "tokens": [9615, 292, 13, 286, 390, 1417, 281, 2618, 10543, 293, 415, 1619, 11, 360, 291, 458, 437, 264, 7908, 35198], "temperature": 0.0, "avg_logprob": -0.14070302042467842, "compression_ratio": 1.7346153846153847, "no_speech_prob": 1.3619377568829805e-05}, {"id": 332, "seek": 232980, "start": 2334.6800000000003, "end": 2340.04, "text": " rate of our alerts are? And I'm like, no, it's like 99.8%. How do you expect somebody", "tokens": [3314, 295, 527, 28061, 366, 30, 400, 286, 478, 411, 11, 572, 11, 309, 311, 411, 11803, 13, 23, 6856, 1012, 360, 291, 2066, 2618], "temperature": 0.0, "avg_logprob": -0.14070302042467842, "compression_ratio": 1.7346153846153847, "no_speech_prob": 1.3619377568829805e-05}, {"id": 333, "seek": 232980, "start": 2340.04, "end": 2348.04, "text": " to spot the problem when almost all the time our alerts don't mean there's a real problem?", "tokens": [281, 4008, 264, 1154, 562, 1920, 439, 264, 565, 527, 28061, 500, 380, 914, 456, 311, 257, 957, 1154, 30], "temperature": 0.0, "avg_logprob": -0.14070302042467842, "compression_ratio": 1.7346153846153847, "no_speech_prob": 1.3619377568829805e-05}, {"id": 334, "seek": 232980, "start": 2348.04, "end": 2353.2400000000002, "text": " Okay. Now what he meant by false positivity isn't what I would mean by it. I mean, there", "tokens": [1033, 13, 823, 437, 415, 4140, 538, 7908, 35198, 1943, 380, 437, 286, 576, 914, 538, 309, 13, 286, 914, 11, 456], "temperature": 0.0, "avg_logprob": -0.14070302042467842, "compression_ratio": 1.7346153846153847, "no_speech_prob": 1.3619377568829805e-05}, {"id": 335, "seek": 232980, "start": 2353.2400000000002, "end": 2358.1200000000003, "text": " were problems that the alerts were alerting about, but they weren't like customer facing", "tokens": [645, 2740, 300, 264, 28061, 645, 419, 27187, 466, 11, 457, 436, 4999, 380, 411, 5474, 7170], "temperature": 0.0, "avg_logprob": -0.14070302042467842, "compression_ratio": 1.7346153846153847, "no_speech_prob": 1.3619377568829805e-05}, {"id": 336, "seek": 235812, "start": 2358.12, "end": 2371.04, "text": " problems, right? So the second thing is we need a really good understanding of our cognitive", "tokens": [2740, 11, 558, 30, 407, 264, 1150, 551, 307, 321, 643, 257, 534, 665, 3701, 295, 527, 15605], "temperature": 0.0, "avg_logprob": -0.15455187068266027, "compression_ratio": 1.5574712643678161, "no_speech_prob": 1.449387491447851e-05}, {"id": 337, "seek": 235812, "start": 2371.04, "end": 2374.7999999999997, "text": " biases and the functions that they provide to us and also the problems that they can", "tokens": [32152, 293, 264, 6828, 300, 436, 2893, 281, 505, 293, 611, 264, 2740, 300, 436, 393], "temperature": 0.0, "avg_logprob": -0.15455187068266027, "compression_ratio": 1.5574712643678161, "no_speech_prob": 1.449387491447851e-05}, {"id": 338, "seek": 235812, "start": 2374.7999999999997, "end": 2383.96, "text": " lead us into, right? So one of the good examples is, hey, look, you know, I know you're about", "tokens": [1477, 505, 666, 11, 558, 30, 407, 472, 295, 264, 665, 5110, 307, 11, 4177, 11, 574, 11, 291, 458, 11, 286, 458, 291, 434, 466], "temperature": 0.0, "avg_logprob": -0.15455187068266027, "compression_ratio": 1.5574712643678161, "no_speech_prob": 1.449387491447851e-05}, {"id": 339, "seek": 238396, "start": 2383.96, "end": 2389.2400000000002, "text": " to do this. I'm not sure that's what the problem is. Can we think about this first, right?", "tokens": [281, 360, 341, 13, 286, 478, 406, 988, 300, 311, 437, 264, 1154, 307, 13, 1664, 321, 519, 466, 341, 700, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1321356493727605, "compression_ratio": 1.7532894736842106, "no_speech_prob": 1.2019388123007957e-05}, {"id": 340, "seek": 238396, "start": 2389.2400000000002, "end": 2392.4, "text": " And as soon as somebody says that, that means that they're saying, my mental model is not", "tokens": [400, 382, 2321, 382, 2618, 1619, 300, 11, 300, 1355, 300, 436, 434, 1566, 11, 452, 4973, 2316, 307, 406], "temperature": 0.0, "avg_logprob": -0.1321356493727605, "compression_ratio": 1.7532894736842106, "no_speech_prob": 1.2019388123007957e-05}, {"id": 341, "seek": 238396, "start": 2392.4, "end": 2395.76, "text": " the same as your mental model. One of us is wrong. We should probably figure that out", "tokens": [264, 912, 382, 428, 4973, 2316, 13, 1485, 295, 505, 307, 2085, 13, 492, 820, 1391, 2573, 300, 484], "temperature": 0.0, "avg_logprob": -0.1321356493727605, "compression_ratio": 1.7532894736842106, "no_speech_prob": 1.2019388123007957e-05}, {"id": 342, "seek": 238396, "start": 2395.76, "end": 2402.52, "text": " before we proceed. Figuring out how to do that's really, really important, especially", "tokens": [949, 321, 8991, 13, 22443, 1345, 484, 577, 281, 360, 300, 311, 534, 11, 534, 1021, 11, 2318], "temperature": 0.0, "avg_logprob": -0.1321356493727605, "compression_ratio": 1.7532894736842106, "no_speech_prob": 1.2019388123007957e-05}, {"id": 343, "seek": 238396, "start": 2402.52, "end": 2406.2, "text": " when we talk about social factors involved, right? It's one thing to do that with your", "tokens": [562, 321, 751, 466, 2093, 6771, 3288, 11, 558, 30, 467, 311, 472, 551, 281, 360, 300, 365, 428], "temperature": 0.0, "avg_logprob": -0.1321356493727605, "compression_ratio": 1.7532894736842106, "no_speech_prob": 1.2019388123007957e-05}, {"id": 344, "seek": 238396, "start": 2406.2, "end": 2410.44, "text": " peer when you're on an incident call and there are two of you there. Something very different", "tokens": [15108, 562, 291, 434, 322, 364, 9348, 818, 293, 456, 366, 732, 295, 291, 456, 13, 6595, 588, 819], "temperature": 0.0, "avg_logprob": -0.1321356493727605, "compression_ratio": 1.7532894736842106, "no_speech_prob": 1.2019388123007957e-05}, {"id": 345, "seek": 241044, "start": 2410.44, "end": 2415.56, "text": " to do when the person typing the words is very senior and you're very junior and there's", "tokens": [281, 360, 562, 264, 954, 18444, 264, 2283, 307, 588, 7965, 293, 291, 434, 588, 16195, 293, 456, 311], "temperature": 0.0, "avg_logprob": -0.12754353512538952, "compression_ratio": 1.6359447004608294, "no_speech_prob": 9.351742846774869e-06}, {"id": 346, "seek": 241044, "start": 2415.56, "end": 2421.76, "text": " somebody C-level popping into the call to ask for an update. I've been there. I've done", "tokens": [2618, 383, 12, 12418, 18374, 666, 264, 818, 281, 1029, 337, 364, 5623, 13, 286, 600, 668, 456, 13, 286, 600, 1096], "temperature": 0.0, "avg_logprob": -0.12754353512538952, "compression_ratio": 1.6359447004608294, "no_speech_prob": 9.351742846774869e-06}, {"id": 347, "seek": 241044, "start": 2421.76, "end": 2430.96, "text": " that and yes, no, I have not raised the issue and I should have, right? You know, figuring", "tokens": [300, 293, 2086, 11, 572, 11, 286, 362, 406, 6005, 264, 2734, 293, 286, 820, 362, 11, 558, 30, 509, 458, 11, 15213], "temperature": 0.0, "avg_logprob": -0.12754353512538952, "compression_ratio": 1.6359447004608294, "no_speech_prob": 9.351742846774869e-06}, {"id": 348, "seek": 241044, "start": 2430.96, "end": 2437.7200000000003, "text": " out how to make these sorts of interventions and how to understand the intervention and", "tokens": [484, 577, 281, 652, 613, 7527, 295, 20924, 293, 577, 281, 1223, 264, 13176, 293], "temperature": 0.0, "avg_logprob": -0.12754353512538952, "compression_ratio": 1.6359447004608294, "no_speech_prob": 9.351742846774869e-06}, {"id": 349, "seek": 243772, "start": 2437.72, "end": 2443.24, "text": " how to respond to it, those are things that we actually need training on, right? We also", "tokens": [577, 281, 4196, 281, 309, 11, 729, 366, 721, 300, 321, 767, 643, 3097, 322, 11, 558, 30, 492, 611], "temperature": 0.0, "avg_logprob": -0.10319620768229167, "compression_ratio": 1.79296875, "no_speech_prob": 1.2970969692105427e-05}, {"id": 350, "seek": 243772, "start": 2443.24, "end": 2448.24, "text": " need training on the social factors. We need to understand how power distance affects these.", "tokens": [643, 3097, 322, 264, 2093, 6771, 13, 492, 643, 281, 1223, 577, 1347, 4560, 11807, 613, 13], "temperature": 0.0, "avg_logprob": -0.10319620768229167, "compression_ratio": 1.79296875, "no_speech_prob": 1.2970969692105427e-05}, {"id": 351, "seek": 243772, "start": 2448.24, "end": 2451.8399999999997, "text": " What happens when there's, you know, the C-level person in the call? How does that change your", "tokens": [708, 2314, 562, 456, 311, 11, 291, 458, 11, 264, 383, 12, 12418, 954, 294, 264, 818, 30, 1012, 775, 300, 1319, 428], "temperature": 0.0, "avg_logprob": -0.10319620768229167, "compression_ratio": 1.79296875, "no_speech_prob": 1.2970969692105427e-05}, {"id": 352, "seek": 243772, "start": 2451.8399999999997, "end": 2458.8799999999997, "text": " social interactions? How does that change your interactions in terms of debugging, right?", "tokens": [2093, 13280, 30, 1012, 775, 300, 1319, 428, 13280, 294, 2115, 295, 45592, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.10319620768229167, "compression_ratio": 1.79296875, "no_speech_prob": 1.2970969692105427e-05}, {"id": 353, "seek": 243772, "start": 2458.8799999999997, "end": 2465.48, "text": " Those are important things and that's one thing that we can get some really big improvements", "tokens": [3950, 366, 1021, 721, 293, 300, 311, 472, 551, 300, 321, 393, 483, 512, 534, 955, 13797], "temperature": 0.0, "avg_logprob": -0.10319620768229167, "compression_ratio": 1.79296875, "no_speech_prob": 1.2970969692105427e-05}, {"id": 354, "seek": 246548, "start": 2465.48, "end": 2474.0, "text": " on relating to this. Finally, it's really important for us to be able to get to the", "tokens": [322, 23968, 281, 341, 13, 6288, 11, 309, 311, 534, 1021, 337, 505, 281, 312, 1075, 281, 483, 281, 264], "temperature": 0.0, "avg_logprob": -0.10215906350009413, "compression_ratio": 1.6027397260273972, "no_speech_prob": 1.275482281926088e-05}, {"id": 355, "seek": 246548, "start": 2474.0, "end": 2480.4, "text": " point where we can contextualize the person. In other words, since we operate as humans", "tokens": [935, 689, 321, 393, 35526, 1125, 264, 954, 13, 682, 661, 2283, 11, 1670, 321, 9651, 382, 6255], "temperature": 0.0, "avg_logprob": -0.10215906350009413, "compression_ratio": 1.6027397260273972, "no_speech_prob": 1.275482281926088e-05}, {"id": 356, "seek": 246548, "start": 2480.4, "end": 2486.8, "text": " in a relatively heuristic manner, right? We need to understand what the situation the", "tokens": [294, 257, 7226, 415, 374, 3142, 9060, 11, 558, 30, 492, 643, 281, 1223, 437, 264, 2590, 264], "temperature": 0.0, "avg_logprob": -0.10215906350009413, "compression_ratio": 1.6027397260273972, "no_speech_prob": 1.275482281926088e-05}, {"id": 357, "seek": 246548, "start": 2486.8, "end": 2494.64, "text": " human was in when the mistake happened and that's another thing that these sorts of trainings", "tokens": [1952, 390, 294, 562, 264, 6146, 2011, 293, 300, 311, 1071, 551, 300, 613, 7527, 295, 33856], "temperature": 0.0, "avg_logprob": -0.10215906350009413, "compression_ratio": 1.6027397260273972, "no_speech_prob": 1.275482281926088e-05}, {"id": 358, "seek": 249464, "start": 2494.64, "end": 2505.16, "text": " can help with. So, I've talked a little bit about social factors here. Power distance", "tokens": [393, 854, 365, 13, 407, 11, 286, 600, 2825, 257, 707, 857, 466, 2093, 6771, 510, 13, 7086, 4560], "temperature": 0.0, "avg_logprob": -0.11681130353142233, "compression_ratio": 1.669811320754717, "no_speech_prob": 2.2078429537941702e-05}, {"id": 359, "seek": 249464, "start": 2505.16, "end": 2510.2799999999997, "text": " is what it sounds like, you know, how big the difference is between the most powerful", "tokens": [307, 437, 309, 3263, 411, 11, 291, 458, 11, 577, 955, 264, 2649, 307, 1296, 264, 881, 4005], "temperature": 0.0, "avg_logprob": -0.11681130353142233, "compression_ratio": 1.669811320754717, "no_speech_prob": 2.2078429537941702e-05}, {"id": 360, "seek": 249464, "start": 2510.2799999999997, "end": 2514.7599999999998, "text": " person in the interaction and the least powerful person in the interaction, where we want it", "tokens": [954, 294, 264, 9285, 293, 264, 1935, 4005, 954, 294, 264, 9285, 11, 689, 321, 528, 309], "temperature": 0.0, "avg_logprob": -0.11681130353142233, "compression_ratio": 1.669811320754717, "no_speech_prob": 2.2078429537941702e-05}, {"id": 361, "seek": 249464, "start": 2514.7599999999998, "end": 2520.44, "text": " to be kind of, you know, not quite equal but much closer instead of like this, maybe more", "tokens": [281, 312, 733, 295, 11, 291, 458, 11, 406, 1596, 2681, 457, 709, 4966, 2602, 295, 411, 341, 11, 1310, 544], "temperature": 0.0, "avg_logprob": -0.11681130353142233, "compression_ratio": 1.669811320754717, "no_speech_prob": 2.2078429537941702e-05}, {"id": 362, "seek": 252044, "start": 2520.44, "end": 2529.12, "text": " like this and, you know, figuring out how to structure things so that power distance", "tokens": [411, 341, 293, 11, 291, 458, 11, 15213, 484, 577, 281, 3877, 721, 370, 300, 1347, 4560], "temperature": 0.0, "avg_logprob": -0.11524275791497877, "compression_ratio": 1.6650943396226414, "no_speech_prob": 8.92097523319535e-06}, {"id": 363, "seek": 252044, "start": 2529.12, "end": 2536.92, "text": " doesn't cause a problem. That also means giving people good training on how to intervene when", "tokens": [1177, 380, 3082, 257, 1154, 13, 663, 611, 1355, 2902, 561, 665, 3097, 322, 577, 281, 30407, 562], "temperature": 0.0, "avg_logprob": -0.11524275791497877, "compression_ratio": 1.6650943396226414, "no_speech_prob": 8.92097523319535e-06}, {"id": 364, "seek": 252044, "start": 2536.92, "end": 2542.52, "text": " they see somebody much more senior about to make a mistake, you know, and you want to", "tokens": [436, 536, 2618, 709, 544, 7965, 466, 281, 652, 257, 6146, 11, 291, 458, 11, 293, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.11524275791497877, "compression_ratio": 1.6650943396226414, "no_speech_prob": 8.92097523319535e-06}, {"id": 365, "seek": 252044, "start": 2542.52, "end": 2547.48, "text": " intervene in a way which is not threatening and in the event where there's somebody even", "tokens": [30407, 294, 257, 636, 597, 307, 406, 20768, 293, 294, 264, 2280, 689, 456, 311, 2618, 754], "temperature": 0.0, "avg_logprob": -0.11524275791497877, "compression_ratio": 1.6650943396226414, "no_speech_prob": 8.92097523319535e-06}, {"id": 366, "seek": 254748, "start": 2547.48, "end": 2552.96, "text": " higher in the call isn't going to be perceived as humiliating, right? Having good training", "tokens": [2946, 294, 264, 818, 1943, 380, 516, 281, 312, 19049, 382, 29981, 990, 11, 558, 30, 10222, 665, 3097], "temperature": 0.0, "avg_logprob": -0.11317123174667358, "compression_ratio": 1.5884955752212389, "no_speech_prob": 2.3459804651793092e-05}, {"id": 367, "seek": 254748, "start": 2552.96, "end": 2559.2400000000002, "text": " on this and how to communicate in those cases is really, really important. And a lot of", "tokens": [322, 341, 293, 577, 281, 7890, 294, 729, 3331, 307, 534, 11, 534, 1021, 13, 400, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.11317123174667358, "compression_ratio": 1.5884955752212389, "no_speech_prob": 2.3459804651793092e-05}, {"id": 368, "seek": 254748, "start": 2559.2400000000002, "end": 2565.68, "text": " this ends up playing out into trying to create a work relationship between the people on", "tokens": [341, 5314, 493, 2433, 484, 666, 1382, 281, 1884, 257, 589, 2480, 1296, 264, 561, 322], "temperature": 0.0, "avg_logprob": -0.11317123174667358, "compression_ratio": 1.5884955752212389, "no_speech_prob": 2.3459804651793092e-05}, {"id": 369, "seek": 254748, "start": 2565.68, "end": 2577.32, "text": " the team which is very heavily mutually supportive and also kind of helps prevent or checks", "tokens": [264, 1469, 597, 307, 588, 10950, 39144, 14435, 293, 611, 733, 295, 3665, 4871, 420, 13834], "temperature": 0.0, "avg_logprob": -0.11317123174667358, "compression_ratio": 1.5884955752212389, "no_speech_prob": 2.3459804651793092e-05}, {"id": 370, "seek": 257732, "start": 2577.32, "end": 2588.7200000000003, "text": " and traps the kinds of mistakes that each of us can make. So let's talk a little bit", "tokens": [293, 24173, 264, 3685, 295, 8038, 300, 1184, 295, 505, 393, 652, 13, 407, 718, 311, 751, 257, 707, 857], "temperature": 0.0, "avg_logprob": -0.14652990211140027, "compression_ratio": 1.359375, "no_speech_prob": 1.845967381086666e-05}, {"id": 371, "seek": 257732, "start": 2588.7200000000003, "end": 2604.4, "text": " about the ideal role of humans in database operations. Now, we kind of need to understand", "tokens": [466, 264, 7157, 3090, 295, 6255, 294, 8149, 7705, 13, 823, 11, 321, 733, 295, 643, 281, 1223], "temperature": 0.0, "avg_logprob": -0.14652990211140027, "compression_ratio": 1.359375, "no_speech_prob": 1.845967381086666e-05}, {"id": 372, "seek": 260440, "start": 2604.4, "end": 2616.52, "text": " this well. Okay, ten? Okay. Who's checking? Five? Okay, perfect. We kind of need to understand", "tokens": [341, 731, 13, 1033, 11, 2064, 30, 1033, 13, 2102, 311, 8568, 30, 9436, 30, 1033, 11, 2176, 13, 492, 733, 295, 643, 281, 1223], "temperature": 0.0, "avg_logprob": -0.1625241499680739, "compression_ratio": 1.583815028901734, "no_speech_prob": 2.208262412750628e-05}, {"id": 373, "seek": 260440, "start": 2616.52, "end": 2622.64, "text": " this. Humans need to be in control. We need to be the decision makers. We need to be the", "tokens": [341, 13, 35809, 643, 281, 312, 294, 1969, 13, 492, 643, 281, 312, 264, 3537, 19323, 13, 492, 643, 281, 312, 264], "temperature": 0.0, "avg_logprob": -0.1625241499680739, "compression_ratio": 1.583815028901734, "no_speech_prob": 2.208262412750628e-05}, {"id": 374, "seek": 260440, "start": 2622.64, "end": 2629.48, "text": " people who can say, this is what I think is going on. Let's go ahead and try this process.", "tokens": [561, 567, 393, 584, 11, 341, 307, 437, 286, 519, 307, 516, 322, 13, 961, 311, 352, 2286, 293, 853, 341, 1399, 13], "temperature": 0.0, "avg_logprob": -0.1625241499680739, "compression_ratio": 1.583815028901734, "no_speech_prob": 2.208262412750628e-05}, {"id": 375, "seek": 262948, "start": 2629.48, "end": 2634.64, "text": " And halfway through that process goes, this is not going well. Let's back off, rethink,", "tokens": [400, 15461, 807, 300, 1399, 1709, 11, 341, 307, 406, 516, 731, 13, 961, 311, 646, 766, 11, 34595, 11], "temperature": 0.0, "avg_logprob": -0.1353315852937244, "compression_ratio": 1.5560344827586208, "no_speech_prob": 7.404148618661566e-06}, {"id": 376, "seek": 262948, "start": 2634.64, "end": 2641.08, "text": " and make another decision, right? Partly because we're also operating heuristically, we can", "tokens": [293, 652, 1071, 3537, 11, 558, 30, 4100, 356, 570, 321, 434, 611, 7447, 415, 374, 20458, 11, 321, 393], "temperature": 0.0, "avg_logprob": -0.1353315852937244, "compression_ratio": 1.5560344827586208, "no_speech_prob": 7.404148618661566e-06}, {"id": 377, "seek": 262948, "start": 2641.08, "end": 2648.64, "text": " do things that computers can't, right? We need to maintain really good situation awareness.", "tokens": [360, 721, 300, 10807, 393, 380, 11, 558, 30, 492, 643, 281, 6909, 534, 665, 2590, 8888, 13], "temperature": 0.0, "avg_logprob": -0.1353315852937244, "compression_ratio": 1.5560344827586208, "no_speech_prob": 7.404148618661566e-06}, {"id": 378, "seek": 262948, "start": 2648.64, "end": 2652.92, "text": " This means we need to have transparency in our complex automation. We need the automation", "tokens": [639, 1355, 321, 643, 281, 362, 17131, 294, 527, 3997, 17769, 13, 492, 643, 264, 17769], "temperature": 0.0, "avg_logprob": -0.1353315852937244, "compression_ratio": 1.5560344827586208, "no_speech_prob": 7.404148618661566e-06}, {"id": 379, "seek": 265292, "start": 2652.92, "end": 2666.04, "text": " to be built around helping us, not replacing us. And to do this, we need to be well rested.", "tokens": [281, 312, 3094, 926, 4315, 505, 11, 406, 19139, 505, 13, 400, 281, 360, 341, 11, 321, 643, 281, 312, 731, 43090, 13], "temperature": 0.0, "avg_logprob": -0.14365493075948366, "compression_ratio": 1.5027624309392265, "no_speech_prob": 1.2589449397637509e-05}, {"id": 380, "seek": 265292, "start": 2666.04, "end": 2672.2000000000003, "text": " We need to be a clear peak capability ideally when we're in the middle of an incident. Now,", "tokens": [492, 643, 281, 312, 257, 1850, 10651, 13759, 22915, 562, 321, 434, 294, 264, 2808, 295, 364, 9348, 13, 823, 11], "temperature": 0.0, "avg_logprob": -0.14365493075948366, "compression_ratio": 1.5027624309392265, "no_speech_prob": 1.2589449397637509e-05}, {"id": 381, "seek": 265292, "start": 2672.2000000000003, "end": 2677.88, "text": " we may not be able to completely manage that last part, but if we can take steps towards", "tokens": [321, 815, 406, 312, 1075, 281, 2584, 3067, 300, 1036, 644, 11, 457, 498, 321, 393, 747, 4439, 3030], "temperature": 0.0, "avg_logprob": -0.14365493075948366, "compression_ratio": 1.5027624309392265, "no_speech_prob": 1.2589449397637509e-05}, {"id": 382, "seek": 267788, "start": 2677.88, "end": 2688.04, "text": " it and we can try to improve, we can do better, right? So a lot of this training is, at least", "tokens": [309, 293, 321, 393, 853, 281, 3470, 11, 321, 393, 360, 1101, 11, 558, 30, 407, 257, 688, 295, 341, 3097, 307, 11, 412, 1935], "temperature": 0.0, "avg_logprob": -0.12689966740815536, "compression_ratio": 1.7230046948356808, "no_speech_prob": 1.0930877579085063e-05}, {"id": 383, "seek": 267788, "start": 2688.04, "end": 2694.76, "text": " what I've gotten out of it, is really important. What I think is really important about this,", "tokens": [437, 286, 600, 5768, 484, 295, 309, 11, 307, 534, 1021, 13, 708, 286, 519, 307, 534, 1021, 466, 341, 11], "temperature": 0.0, "avg_logprob": -0.12689966740815536, "compression_ratio": 1.7230046948356808, "no_speech_prob": 1.0930877579085063e-05}, {"id": 384, "seek": 267788, "start": 2694.76, "end": 2700.96, "text": " I'll just talk quickly about how to go about doing it, is that if we can get the organizational", "tokens": [286, 603, 445, 751, 2661, 466, 577, 281, 352, 466, 884, 309, 11, 307, 300, 498, 321, 393, 483, 264, 24730], "temperature": 0.0, "avg_logprob": -0.12689966740815536, "compression_ratio": 1.7230046948356808, "no_speech_prob": 1.0930877579085063e-05}, {"id": 385, "seek": 267788, "start": 2700.96, "end": 2706.6800000000003, "text": " leverage behind the training, then we can actually turn the promise of the training", "tokens": [13982, 2261, 264, 3097, 11, 550, 321, 393, 767, 1261, 264, 6228, 295, 264, 3097], "temperature": 0.0, "avg_logprob": -0.12689966740815536, "compression_ratio": 1.7230046948356808, "no_speech_prob": 1.0930877579085063e-05}, {"id": 386, "seek": 270668, "start": 2706.68, "end": 2710.9199999999996, "text": " into the reality. Sometimes you can't just teach people something and then have the", "tokens": [666, 264, 4103, 13, 4803, 291, 393, 380, 445, 2924, 561, 746, 293, 550, 362, 264], "temperature": 0.0, "avg_logprob": -0.1779972863575769, "compression_ratio": 1.446927374301676, "no_speech_prob": 2.4651293642818928e-05}, {"id": 387, "seek": 270668, "start": 2710.9199999999996, "end": 2718.68, "text": " punishment abandoned them. That doesn't work. So as an industry, we treat human error the", "tokens": [14133, 13732, 552, 13, 663, 1177, 380, 589, 13, 407, 382, 364, 3518, 11, 321, 2387, 1952, 6713, 264], "temperature": 0.0, "avg_logprob": -0.1779972863575769, "compression_ratio": 1.446927374301676, "no_speech_prob": 2.4651293642818928e-05}, {"id": 388, "seek": 270668, "start": 2718.68, "end": 2736.3999999999996, "text": " way pilot error was treated in the 1950s. We have a whole lot to learn from aviation.", "tokens": [636, 9691, 6713, 390, 8668, 294, 264, 18141, 82, 13, 492, 362, 257, 1379, 688, 281, 1466, 490, 28831, 13], "temperature": 0.0, "avg_logprob": -0.1779972863575769, "compression_ratio": 1.446927374301676, "no_speech_prob": 2.4651293642818928e-05}, {"id": 389, "seek": 273640, "start": 2736.4, "end": 2742.12, "text": " Those lessons are already being played out in medicine and many other fields today. We", "tokens": [3950, 8820, 366, 1217, 885, 3737, 484, 294, 7195, 293, 867, 661, 7909, 965, 13, 492], "temperature": 0.0, "avg_logprob": -0.11163043975830078, "compression_ratio": 1.5695652173913044, "no_speech_prob": 2.31461144721834e-05}, {"id": 390, "seek": 273640, "start": 2742.12, "end": 2748.2400000000002, "text": " need to do what we can to learn from it also. And it's really important to recognize that", "tokens": [643, 281, 360, 437, 321, 393, 281, 1466, 490, 309, 611, 13, 400, 309, 311, 534, 1021, 281, 5521, 300], "temperature": 0.0, "avg_logprob": -0.11163043975830078, "compression_ratio": 1.5695652173913044, "no_speech_prob": 2.31461144721834e-05}, {"id": 391, "seek": 273640, "start": 2748.2400000000002, "end": 2754.28, "text": " we can get really good improvements in reliability, efficiency, speed of development, all these", "tokens": [321, 393, 483, 534, 665, 13797, 294, 24550, 11, 10493, 11, 3073, 295, 3250, 11, 439, 613], "temperature": 0.0, "avg_logprob": -0.11163043975830078, "compression_ratio": 1.5695652173913044, "no_speech_prob": 2.31461144721834e-05}, {"id": 392, "seek": 273640, "start": 2754.28, "end": 2761.6800000000003, "text": " sorts of things if we can better work with the human side of things. And I'm not talking", "tokens": [7527, 295, 721, 498, 321, 393, 1101, 589, 365, 264, 1952, 1252, 295, 721, 13, 400, 286, 478, 406, 1417], "temperature": 0.0, "avg_logprob": -0.11163043975830078, "compression_ratio": 1.5695652173913044, "no_speech_prob": 2.31461144721834e-05}, {"id": 393, "seek": 276168, "start": 2761.68, "end": 2769.24, "text": " about human managers rating performance. I'm talking about people on the team understanding", "tokens": [466, 1952, 14084, 10990, 3389, 13, 286, 478, 1417, 466, 561, 322, 264, 1469, 3701], "temperature": 0.0, "avg_logprob": -0.14059129479813248, "compression_ratio": 1.6205357142857142, "no_speech_prob": 1.746255838952493e-05}, {"id": 394, "seek": 276168, "start": 2769.24, "end": 2775.8399999999997, "text": " performance for themselves and others. I just want to say that the three pieces of this", "tokens": [3389, 337, 2969, 293, 2357, 13, 286, 445, 528, 281, 584, 300, 264, 1045, 3755, 295, 341], "temperature": 0.0, "avg_logprob": -0.14059129479813248, "compression_ratio": 1.6205357142857142, "no_speech_prob": 1.746255838952493e-05}, {"id": 395, "seek": 276168, "start": 2775.8399999999997, "end": 2786.68, "text": " are trying to get trainers in who have experience. Also, an organizational commitment to make", "tokens": [366, 1382, 281, 483, 35393, 294, 567, 362, 1752, 13, 2743, 11, 364, 24730, 8371, 281, 652], "temperature": 0.0, "avg_logprob": -0.14059129479813248, "compression_ratio": 1.6205357142857142, "no_speech_prob": 1.746255838952493e-05}, {"id": 396, "seek": 276168, "start": 2786.68, "end": 2791.2799999999997, "text": " it happen and then internally building your own programs and your own recurring trainings", "tokens": [309, 1051, 293, 550, 19501, 2390, 428, 1065, 4268, 293, 428, 1065, 32279, 33856], "temperature": 0.0, "avg_logprob": -0.14059129479813248, "compression_ratio": 1.6205357142857142, "no_speech_prob": 1.746255838952493e-05}, {"id": 397, "seek": 279128, "start": 2791.28, "end": 2796.76, "text": " and your own training for new people. So that internally you have a big culture around it", "tokens": [293, 428, 1065, 3097, 337, 777, 561, 13, 407, 300, 19501, 291, 362, 257, 955, 3713, 926, 309], "temperature": 0.0, "avg_logprob": -0.2944413235313014, "compression_ratio": 1.3825503355704698, "no_speech_prob": 0.00034554084413684905}, {"id": 398, "seek": 279128, "start": 2796.76, "end": 2801.4, "text": " and you have experts who can think about it when it comes to be a post-mortem. So that's", "tokens": [293, 291, 362, 8572, 567, 393, 519, 466, 309, 562, 309, 1487, 281, 312, 257, 2183, 12, 76, 477, 443, 13, 407, 300, 311], "temperature": 0.0, "avg_logprob": -0.2944413235313014, "compression_ratio": 1.3825503355704698, "no_speech_prob": 0.00034554084413684905}, {"id": 399, "seek": 279128, "start": 2801.4, "end": 2807.76, "text": " what I have. Any questions?", "tokens": [437, 286, 362, 13, 2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2944413235313014, "compression_ratio": 1.3825503355704698, "no_speech_prob": 0.00034554084413684905}, {"id": 400, "seek": 280776, "start": 2807.76, "end": 2824.5200000000004, "text": " Thank you. That was an amazing talk. Do you have any recommendations for further reading", "tokens": [1044, 291, 13, 663, 390, 364, 2243, 751, 13, 1144, 291, 362, 604, 10434, 337, 3052, 3760], "temperature": 0.0, "avg_logprob": -0.21942286337575606, "compression_ratio": 1.1782178217821782, "no_speech_prob": 0.0005860853125341237}, {"id": 401, "seek": 280776, "start": 2824.5200000000004, "end": 2827.84, "text": " if you can't bring in experts?", "tokens": [498, 291, 393, 380, 1565, 294, 8572, 30], "temperature": 0.0, "avg_logprob": -0.21942286337575606, "compression_ratio": 1.1782178217821782, "no_speech_prob": 0.0005860853125341237}, {"id": 402, "seek": 282784, "start": 2827.84, "end": 2839.36, "text": " So this is a field which an aviation has a massive textbook industry. I think probably", "tokens": [407, 341, 307, 257, 2519, 597, 364, 28831, 575, 257, 5994, 25591, 3518, 13, 286, 519, 1391], "temperature": 0.0, "avg_logprob": -0.1683215850438827, "compression_ratio": 1.710144927536232, "no_speech_prob": 4.978076322004199e-05}, {"id": 403, "seek": 282784, "start": 2839.36, "end": 2844.88, "text": " the best, sort of the most accessible book I would recommend starting with is the more", "tokens": [264, 1151, 11, 1333, 295, 264, 881, 9515, 1446, 286, 576, 2748, 2891, 365, 307, 264, 544], "temperature": 0.0, "avg_logprob": -0.1683215850438827, "compression_ratio": 1.710144927536232, "no_speech_prob": 4.978076322004199e-05}, {"id": 404, "seek": 282784, "start": 2844.88, "end": 2850.1600000000003, "text": " recent versions of David Beatty's human factors and aircraft accidents. I think the most recent", "tokens": [5162, 9606, 295, 4389, 16031, 874, 311, 1952, 6771, 293, 9465, 23875, 13, 286, 519, 264, 881, 5162], "temperature": 0.0, "avg_logprob": -0.1683215850438827, "compression_ratio": 1.710144927536232, "no_speech_prob": 4.978076322004199e-05}, {"id": 405, "seek": 282784, "start": 2850.1600000000003, "end": 2854.2400000000002, "text": " version is called the naked pilot of human factors and aircraft accidents. It's just", "tokens": [3037, 307, 1219, 264, 15791, 9691, 295, 1952, 6771, 293, 9465, 23875, 13, 467, 311, 445], "temperature": 0.0, "avg_logprob": -0.1683215850438827, "compression_ratio": 1.710144927536232, "no_speech_prob": 4.978076322004199e-05}, {"id": 406, "seek": 285424, "start": 2854.24, "end": 2865.7599999999998, "text": " referring to exposing the inner workings of the human piece of the aircraft. But again,", "tokens": [13761, 281, 33178, 264, 7284, 589, 1109, 295, 264, 1952, 2522, 295, 264, 9465, 13, 583, 797, 11], "temperature": 0.0, "avg_logprob": -0.20730377012683499, "compression_ratio": 1.5263157894736843, "no_speech_prob": 6.9042929681018e-05}, {"id": 407, "seek": 285424, "start": 2865.7599999999998, "end": 2871.68, "text": " if you're a nervous flyer, probably look for a crew resource management textbook instead", "tokens": [498, 291, 434, 257, 6296, 3603, 260, 11, 1391, 574, 337, 257, 7260, 7684, 4592, 25591, 2602], "temperature": 0.0, "avg_logprob": -0.20730377012683499, "compression_ratio": 1.5263157894736843, "no_speech_prob": 6.9042929681018e-05}, {"id": 408, "seek": 285424, "start": 2871.68, "end": 2879.3199999999997, "text": " because it may be less nerve wracking, it may be less intimidating, but it will have", "tokens": [570, 309, 815, 312, 1570, 16355, 928, 14134, 11, 309, 815, 312, 1570, 29714, 11, 457, 309, 486, 362], "temperature": 0.0, "avg_logprob": -0.20730377012683499, "compression_ratio": 1.5263157894736843, "no_speech_prob": 6.9042929681018e-05}, {"id": 409, "seek": 287932, "start": 2879.32, "end": 2889.0800000000004, "text": " information there too.", "tokens": [1589, 456, 886, 13], "temperature": 0.0, "avg_logprob": -0.22536646618562586, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.0001018888724502176}, {"id": 410, "seek": 287932, "start": 2889.0800000000004, "end": 2893.88, "text": " Do you have any recommendations for testing or drilling your processes like those checklists?", "tokens": [1144, 291, 362, 604, 10434, 337, 4997, 420, 26290, 428, 7555, 411, 729, 1520, 36693, 30], "temperature": 0.0, "avg_logprob": -0.22536646618562586, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.0001018888724502176}, {"id": 411, "seek": 287932, "start": 2893.88, "end": 2900.52, "text": " Yes, I do. One thing that I think we really should figure out how to do is an industry", "tokens": [1079, 11, 286, 360, 13, 1485, 551, 300, 286, 519, 321, 534, 820, 2573, 484, 577, 281, 360, 307, 364, 3518], "temperature": 0.0, "avg_logprob": -0.22536646618562586, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.0001018888724502176}, {"id": 412, "seek": 287932, "start": 2900.52, "end": 2907.92, "text": " and I completely believe in this. Obviously, like the chaos monkey idea and Netflix could", "tokens": [293, 286, 2584, 1697, 294, 341, 13, 7580, 11, 411, 264, 14158, 17847, 1558, 293, 12778, 727], "temperature": 0.0, "avg_logprob": -0.22536646618562586, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.0001018888724502176}, {"id": 413, "seek": 290792, "start": 2907.92, "end": 2914.28, "text": " be exploited to do this if you can also build war games around it. But the thing is it's", "tokens": [312, 40918, 281, 360, 341, 498, 291, 393, 611, 1322, 1516, 2813, 926, 309, 13, 583, 264, 551, 307, 309, 311], "temperature": 0.0, "avg_logprob": -0.17452318981440382, "compression_ratio": 1.6305970149253732, "no_speech_prob": 4.900351996184327e-05}, {"id": 414, "seek": 290792, "start": 2914.28, "end": 2919.04, "text": " really important to have drills, which means oftentimes you've actually got to probably", "tokens": [534, 1021, 281, 362, 36126, 11, 597, 1355, 18349, 291, 600, 767, 658, 281, 1391], "temperature": 0.0, "avg_logprob": -0.17452318981440382, "compression_ratio": 1.6305970149253732, "no_speech_prob": 4.900351996184327e-05}, {"id": 415, "seek": 290792, "start": 2919.04, "end": 2925.6800000000003, "text": " simulate or create some sort of a potential incident that you have to come together and", "tokens": [27817, 420, 1884, 512, 1333, 295, 257, 3995, 9348, 300, 291, 362, 281, 808, 1214, 293], "temperature": 0.0, "avg_logprob": -0.17452318981440382, "compression_ratio": 1.6305970149253732, "no_speech_prob": 4.900351996184327e-05}, {"id": 416, "seek": 290792, "start": 2925.6800000000003, "end": 2931.36, "text": " resolve. Now, ideally, you need to figure out how to do this without threatening your", "tokens": [14151, 13, 823, 11, 22915, 11, 291, 643, 281, 2573, 484, 577, 281, 360, 341, 1553, 20768, 428], "temperature": 0.0, "avg_logprob": -0.17452318981440382, "compression_ratio": 1.6305970149253732, "no_speech_prob": 4.900351996184327e-05}, {"id": 417, "seek": 290792, "start": 2931.36, "end": 2936.12, "text": " customer-oriented services. In some cases, maybe the cloud's a really good opportunity", "tokens": [5474, 12, 27414, 3328, 13, 682, 512, 3331, 11, 1310, 264, 4588, 311, 257, 534, 665, 2650], "temperature": 0.0, "avg_logprob": -0.17452318981440382, "compression_ratio": 1.6305970149253732, "no_speech_prob": 4.900351996184327e-05}, {"id": 418, "seek": 293612, "start": 2936.12, "end": 2944.72, "text": " for that. But having those sorts of drills, maybe once a quarter or twice a year or something,", "tokens": [337, 300, 13, 583, 1419, 729, 7527, 295, 36126, 11, 1310, 1564, 257, 6555, 420, 6091, 257, 1064, 420, 746, 11], "temperature": 0.0, "avg_logprob": -0.14678503062627088, "compression_ratio": 1.54, "no_speech_prob": 0.0002638128644321114}, {"id": 419, "seek": 293612, "start": 2944.72, "end": 2949.8399999999997, "text": " can really give you an opportunity to spot problems, figure out improvements and actually", "tokens": [393, 534, 976, 291, 364, 2650, 281, 4008, 2740, 11, 2573, 484, 13797, 293, 767], "temperature": 0.0, "avg_logprob": -0.14678503062627088, "compression_ratio": 1.54, "no_speech_prob": 0.0002638128644321114}, {"id": 420, "seek": 293612, "start": 2949.8399999999997, "end": 2957.56, "text": " go figure out what to do about those.", "tokens": [352, 2573, 484, 437, 281, 360, 466, 729, 13], "temperature": 0.0, "avg_logprob": -0.14678503062627088, "compression_ratio": 1.54, "no_speech_prob": 0.0002638128644321114}, {"id": 421, "seek": 293612, "start": 2957.56, "end": 2962.2799999999997, "text": " Just kind of building on that last point is how do you justify the expense in time or", "tokens": [1449, 733, 295, 2390, 322, 300, 1036, 935, 307, 577, 360, 291, 20833, 264, 18406, 294, 565, 420], "temperature": 0.0, "avg_logprob": -0.14678503062627088, "compression_ratio": 1.54, "no_speech_prob": 0.0002638128644321114}, {"id": 422, "seek": 296228, "start": 2962.28, "end": 2967.88, "text": " money? Given that if this is successful, then nothing goes wrong. So it can sometimes be", "tokens": [1460, 30, 18600, 300, 498, 341, 307, 4406, 11, 550, 1825, 1709, 2085, 13, 407, 309, 393, 2171, 312], "temperature": 0.0, "avg_logprob": -0.1438840650162607, "compression_ratio": 1.6332046332046333, "no_speech_prob": 0.0002615208213683218}, {"id": 423, "seek": 296228, "start": 2967.88, "end": 2973.1200000000003, "text": " the outcome of success is that you're spending a lot of effort on apparently doing nothing.", "tokens": [264, 9700, 295, 2245, 307, 300, 291, 434, 6434, 257, 688, 295, 4630, 322, 7970, 884, 1825, 13], "temperature": 0.0, "avg_logprob": -0.1438840650162607, "compression_ratio": 1.6332046332046333, "no_speech_prob": 0.0002615208213683218}, {"id": 424, "seek": 296228, "start": 2973.1200000000003, "end": 2977.0400000000004, "text": " I don't believe that, but that's a reasonable thing that gets asked. How do you go about", "tokens": [286, 500, 380, 1697, 300, 11, 457, 300, 311, 257, 10585, 551, 300, 2170, 2351, 13, 1012, 360, 291, 352, 466], "temperature": 0.0, "avg_logprob": -0.1438840650162607, "compression_ratio": 1.6332046332046333, "no_speech_prob": 0.0002615208213683218}, {"id": 425, "seek": 296228, "start": 2977.0400000000004, "end": 2983.52, "text": " justifying the time or the money on this after it's successful?", "tokens": [445, 5489, 264, 565, 420, 264, 1460, 322, 341, 934, 309, 311, 4406, 30], "temperature": 0.0, "avg_logprob": -0.1438840650162607, "compression_ratio": 1.6332046332046333, "no_speech_prob": 0.0002615208213683218}, {"id": 426, "seek": 296228, "start": 2983.52, "end": 2989.6000000000004, "text": " What I've usually done in the past is I make my points about, yes, we're going to improve", "tokens": [708, 286, 600, 2673, 1096, 294, 264, 1791, 307, 286, 652, 452, 2793, 466, 11, 2086, 11, 321, 434, 516, 281, 3470], "temperature": 0.0, "avg_logprob": -0.1438840650162607, "compression_ratio": 1.6332046332046333, "no_speech_prob": 0.0002615208213683218}, {"id": 427, "seek": 298960, "start": 2989.6, "end": 2996.2799999999997, "text": " our incident response. This will reduce our time recovery. It'll improve our reliability,", "tokens": [527, 9348, 4134, 13, 639, 486, 5407, 527, 565, 8597, 13, 467, 603, 3470, 527, 24550, 11], "temperature": 0.0, "avg_logprob": -0.2133985213291498, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.3170325221144594e-05}, {"id": 428, "seek": 298960, "start": 2996.2799999999997, "end": 3003.16, "text": " et cetera. Maybe it'll improve our throughput organizationally. But then usually, people", "tokens": [1030, 11458, 13, 2704, 309, 603, 3470, 527, 44629, 4475, 379, 13, 583, 550, 2673, 11, 561], "temperature": 0.0, "avg_logprob": -0.2133985213291498, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.3170325221144594e-05}, {"id": 429, "seek": 298960, "start": 3003.16, "end": 3008.2799999999997, "text": " don't listen. And then usually, there are more incidents. And then you can come in and", "tokens": [500, 380, 2140, 13, 400, 550, 2673, 11, 456, 366, 544, 21139, 13, 400, 550, 291, 393, 808, 294, 293], "temperature": 0.0, "avg_logprob": -0.2133985213291498, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.3170325221144594e-05}, {"id": 430, "seek": 298960, "start": 3008.2799999999997, "end": 3013.48, "text": " say, you know, these are specific problems that we had here where this training would", "tokens": [584, 11, 291, 458, 11, 613, 366, 2685, 2740, 300, 321, 632, 510, 689, 341, 3097, 576], "temperature": 0.0, "avg_logprob": -0.2133985213291498, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.3170325221144594e-05}, {"id": 431, "seek": 301348, "start": 3013.48, "end": 3019.68, "text": " help. And I usually find that after two or three of those, people start listening and", "tokens": [854, 13, 400, 286, 2673, 915, 300, 934, 732, 420, 1045, 295, 729, 11, 561, 722, 4764, 293], "temperature": 0.0, "avg_logprob": -0.2963651098856112, "compression_ratio": 1.2372881355932204, "no_speech_prob": 3.362027200637385e-05}, {"id": 432, "seek": 301348, "start": 3019.68, "end": 3022.68, "text": " go, oh, really? Maybe there is something to this.", "tokens": [352, 11, 1954, 11, 534, 30, 2704, 456, 307, 746, 281, 341, 13], "temperature": 0.0, "avg_logprob": -0.2963651098856112, "compression_ratio": 1.2372881355932204, "no_speech_prob": 3.362027200637385e-05}, {"id": 433, "seek": 302268, "start": 3022.68, "end": 3044.8799999999997, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 51474], "temperature": 0.0, "avg_logprob": -0.683243195215861, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.00034104453516192734}], "language": "en"}