{"text": " I am Gabor Sarnas and I'm here with David Proha. We work at CWI Amsterdam and we're here to present you the LDBC social network benchmark. What is the LDBC? The abbreviation stands for Linked Data Benchmark Council. It is a non-profit company founded in 2012 and its mission is to accelerate the progress in the field of graph data management. And to this end, it designs and governs the use of graph benchmarks and everything we do is open source under the Apache version 2 license. From an organizational perspective, LDBC consists of more than 20 members who all have some vested interest in graph data management. We have financial service providers like the End Group, database vendors like Oracle, Neo4j and Tigrograph, cloud vendors like AWS and hardware vendors like Intel. Also we have individual contributors like David and me who contribute to the benchmarks. So to put things into context, the last two decades has seen a rise in the use of modern graph database management systems. Typically, the data model used in these systems is called a property graph, which is a labelled graph where both the nodes and the edges can have an arbitrary number of properties. For example, this is a small social network consisting of five person nodes and a single city node, which is the city of SPA. And the properties can be on the nodes. For example, here the nodes have names and the edges have attributes like the date when the friendship was established. We can see that Bob and Carl met in 2015. And if you want to run a query on this system, we can use a graph query where we look for matches of a given graph. So here the query says we want to start from Bob. We want to use an arbitrary number of edges to reach some person who lives in SPA and we want to do an aggregation to return the number of those people. If you want to evaluate this, we then start from the person Bob, push to all the people transitively, which are known by Bob directly or via multiple edges. This means all four people here. We shrink it down to the people who actually live in SPA, then add up the results and get the result too. So graph databases use something called a visual graph syntax, also known as the sqr graph syntax, which is similar to the popular cipher language of Neo4j. And here this query is actually really similar to the graph pattern that I have shown. So there are similarities in how the nodes are formulated, how the edges are captured in this text, and also how the transitive closure of the little asterisk is captured in the query language. So this is a very intuitive and concise way of formulating the queries. If we deconstruct this query, we can see three main components. The one is relational operators. Obviously, we still need relational operators. We want to be able to identify people by filtering. So we filter for Bob, we filter for SPA, and also we want to sometimes aggregate. So the count aggregation is part of this query. The pathfinding is really elegant in this formulation because we have nodes asterisk which captures that we can use an arbitrary number of edges. And the pattern matching which connects the person to SPA is also very concise and readable. So what is interesting from a future work perspective on graph databases? Obviously, relational operators are quite well known at this point, and there are endless papers and techniques on how to implement these. But we believe that pathfinding and pattern matching is really good in graph databases compared to traditional relational systems because they provide a more concise syntax and better algorithms and implementations. Interestingly enough, even in the last 15 years, there have been lots of papers on better BFS algorithms, better factorization representations for graph patterns, multi-wavers, case optimal joins, and so on. So we believe that these should be adopted by more and more systems. And to this end, we designed benchmarks that try to push the state of the art and the four systems to adopt better and better techniques. David will talk about these benchmarks. Yeah, hi. So I will give an overview about the social network benchmark. And so first, we'll go through three steps of this benchmark, so the data sets, two example queries, and the update operations done in this benchmark. So here we see a small example of the data sets where on the left side, we see persons with friendships, forms, and network, and these persons post messages on the social network and can reply to each other forming a tree-shaped data structure. And now we will do one query on this very small data set example. So with query nine, we want to retrieve messages posted by a given person, friend, and friends of friends before a given date. And the dates are here shortened for simplicity. So if we would start with BOP, we will traverse to their friends and friends of friends, retrieve the messages, and then filter out the ones that are actually before Saturday. And then we touch upon 10 nodes in this data. Suppose we would start from another person, so for example Finn, and we traverse again to their friends and friends of friends. Here we see that we touch upon five different nodes. So half of the one of BOP. And this difference can actually be troublesome since runtimes for the same queries are different and therefore doesn't help in understanding what's happening. So for this benchmark, we actually want to select parameters that have similar runtimes and also to actually stress the technical difficulties in these systems. So we select the parameters more carefully. So here we see an example of when we do not select the parameters carefully, just a uniform random. And we can see here a trial model, distribution by model, and one with many outliers. And we don't want that. So in the data sets, there are also statistics provided in this example for each person, the number of friends and friends of friends. Then we want to select persons with similar number to get more predictable runtimes. And so if we do that, then we can see here an example that we have unimodal distributions with very tight runtimes. And that improves also in understanding these, like the behavior of the queries. So now we're going to the updates. And for example, if Eve and Gia wants to be friends, we insert a nose edge. And this is then formed into the network. Suppose that the next operation is inserting a comment. So Gia comments replies on a message posted by Eve. And both messages are posted on the same date. Then we have another problem. Because when we are executing these operations concurrently, it can happen that the reply is earlier than the message in such a network, posting an error. And to mitigate this, we introduce dependency tracking. So for each operation, and also includes the edges, but just for simplicity, the notes are here with the dependent dates. We include for each operation a creation date and dependent date. The creation date is when it's scheduled to be executed, and the dependent date is the one that's, like in this case, for M6, is the creation date of M3. And here we can see, actually, that each operation is dependent on each other, forming a whole chain in the social network. Suppose now that Eve wants to leave the social network and removes her account. And so we start with deleting the notes of Eve, and this will trigger a cascading effect by, since we then need to remove the edges connected to Eve, the messages posted, and also the replies to those messages. We can actually see, like, this huge cascading effect, and that can actually have a large impact on the data distribution, and also therefore the executability of these operations. And furthermore, it also influences for selecting the parameters, which we have shown before. And we want to include this delete because it prohibits append only data structures in databases and also stress the garbage collector of these systems. Now we are going to give another example to also stress the temporal aspect of this benchmark. So suppose we want to find a path between two persons. So we have a start person and a destination person, and, for example, Finn and Gia. Then we can see here that we have a four-hole path between these persons. But at one point in the benchmark, it can happen that a node's edge is removed, and then there is no path anymore. It can also happen that there's another edge inserted between Carl and Gia, and then we have a path again. And so for the same parameters, we can actually have three different outcomes. And to mitigate this, we do temporal parameter selection. So each parameter is assigned in a time bucket to actually ensure that we have similar results and therefore also similar run times. Now going through the benchmark workflow. So we start by the data gen, and the data gen provides us with a temporal graph spanning over social media activity for three years, and it is simulated closely to the, similar to the Facebook social network. It's a spark-based data generator that can generate data up to 30 terabytes, and it contains the, you know, skewed data sets, for example, with the nodes and person data in this data. And so the output is a data set suitable for loading into the system on a test, updates which are then executed during the benchmark, and statistics where we can select the parameters. And the selection of the parameters is done in the parameter generator. This ensures the stable query run times and assigns parameters into a temporal bucket. So a parameter can, it may include parameters that once are inserted into the data sets or before they are removed from the network. So and then we have a benchmark driver who schedules these operations and ensures that they can be executed with using the dependency tracking. And this is especially important when executing the operations concurrently. And lastly, we have the system on the test where we have, for example, graph databases, triple stores or relational databases. And now Gabor will go further into the workloads. Okay, so graph workloads are actually quite diverse in terms of what they are trying to achieve, and our benchmark reflects that by having multiple workloads. We have the social network benchmark interactive workload, which is transactional in nature, so it has loads of concurrent operations. The queries here are relatively simple, so they always start in one or two person nodes, the same as David presented before. And here the systems are striving to achieve a high throughput, so the competition is getting as many operations per second as possible. We are happy to report that we have official results from the last three years, where systems started with slightly above 5,000 operations per second and have sped up exponentially, now being close to 17,000 operations per second on a 100 gigabyte dataset. The other workload of the social network benchmark is called business intelligence. This is an analytical workload where the queries touch on large portions of the data. For example, this query in this slide shows a case where we start from a given country and then find all triangles of friendships in that country. It's easy to see that this is a very heavy hitting operation. It may touch on billions of edges in the graph, and it also has to do a complex computation to find those people. So here system can use either a bulk update or a concurrent update method, and they should also strive to get both a high throughput and low query run times. This benchmark is relatively new. It was released at the end of last year, so we only have a single result, which was done by a collaboration of Tiger Graph and AMD. We're happy to report that there are more audits under way, so we are going to release more results in 2023. So probably you can see from this presentation that these benchmarks can get fairly complex and implementing them is not trivial. So we did our best to provide everything our users need. For each of the workloads that we have presented, we have a specification, we have detailed academic papers who motivate the design choices and the architecture of these benchmarks. We released a data generator as well as pre-generated datasets, and we have benchmark drivers and at least two reference implementations for each of the workloads. Moreover, we have guidelines on how to execute these benchmarks correctly, how to validate the results of a given system, and how to ensure that the system will lose your data or mingle up the transactions. So we have asset compliance tests and recovery tests. This leads us to our auditing process. Similarly to the TPC, the Transaction Processing Performance Council, we have a rigorous auditing process where vendors can commission an independent third party who will rerun the benchmark in an executable and reproducible manner, and they will write up it as a full disclosure report so that the benchmark is understandable by whoever wants to see that result. This is important because LDBC is trademarked worldwide, and we only allow official audited results to use the term LDBC benchmark result. This is not to say that we don't allow people to use this benchmark. Researchers, practitioners, and developers are welcome to use the benchmark. They can run it. They can report the results if it is accompanied by the appropriate disclaimer that this is not an official LDBC benchmark result. I would like to talk a bit about standard GraphQL languages. This is an important topic because this has been a pain point for GraphSystems for many years. There is a bit of a tower of Babel out there with many languages, both of them using some sort of visual graph syntax, but always with slightly different semantics and a slightly different syntax, which makes it difficult for users to adopt these techniques and may put them in a position of being locked in by their vendors. In the next couple of years, there are going to be new standard queer languages. These focus on pathfinding and pattern matching. The first one is called SQL PGQ. This is an extension to the SQL language and PGQ stands for property graph queries. This is going to be released next summer, and GQL, the standalone GraphQL language, is going to come out in 2024. We are happy to report that even though we have two new languages, the pattern matching core of them, the visual graph syntax that we all know and love, is going to be the same, so users can port at least those bits of their queries. To give you a taste of how this will look like, here is query 9 that David presented in the social network benchmark interactive workload. This query can be formulated in SQL. It's not too difficult, but the new variants, SQL PGQ and GQL, can represent it as terms of a graph pattern, and this is a much more concise formulation. The difference is even more pronounced for query 13 with the path queries. Here we can see that in SQL PGQ, the pattern is really similar to the visual representation. It just has a source, a target, and an arbitrary amount of nose edges denoted by nose asterisk in between. In SQL, this is a lot less readable, hard to maintain, and it's even less sufficient because it just implements a unidirectional search algorithm instead of doing a bidirectional search which has a better algorithmic complexity. The way LDBC is involved in these new query languages is manifold. First, it had the G-core design language released in 2018 which influenced these benchmarks. Then LDBC has the formal semantics working group which formalized the pattern matching core of these new languages, and LDBC is doing further research to advance the state of the art on graph schemas. We have an industry-driven and a theory-driven group, and what they do will end up in the new versions of these languages. The outlook is the LDBC Graphalytics benchmark. This is a more wide benchmark because it can target analytical libraries like NetworkX, distributed systems like Apache Giraffe, or the GraphBlast API. This is everything that has to do with analyzing large graphs. Here the graph is an untyped, unattributed graph, so there are no properties or no labels. We do use the LDBC social network benchmark dataset, but it is stripped down to the person-nose-person core graph. Additionally, we have included a number of well-known datasets like Graph500, Twitter, and so on. The algorithms that we run are mostly well-known graph algorithms. There is the BFS, which starts from a given node and assigns the number of steps that need to be taken to all of the other nodes to reach them. We have the famous PageRank centrality algorithm, which highlights the most important nodes in the network, and we have the local clustering coefficient, community detection using label propagation, weakly connected components, and shortest paths. This benchmark is a bit simpler than the social network benchmark. It does not have a rigorous auditing process. We trust people that they can run this benchmark efficiently and correctly on their own infrastructure, and they can report results. If they do so, they will be able to participate in the Graphalytics competition, which has a leaderboard for the best implementations. Wrapping up, you should consider joining the IDBC because members can participate in the benchmark design. They have a say in where we are going in terms of including new features. They can commission audits if they are vendors, and members can gain access to these ISO standard drafts that I mentioned, SQL, PGQ, and GQR. Otherwise, these are not available to general public. Being wise, this is free for individuals, and there is a yearly fee for companies. To sum up, we have presented three benchmarks, the social network benchmark's interactive workload, its business intelligence workload, and the Graphalytics graph algorithms workload. We have more benchmarks. There is semantic publishing benchmark, which is targeting RDF systems set in the media and publishing industry. There is the financial benchmark, which is going to be released this year, which targets distributed systems, and it uses the financial fraud detection domain as its area, and it imposes strict latency bounds on queries. This is quite a different workload from the previous ones. Of course, graphs are ubiquitous, and they have loads of use cases, so there are many future benchmark ideas, including graph neural network mining and streaming. Thank you very much, and we're open to any questions. Yes. So, in this one overview that was the graph data set, and the updates were kind of separated. Is there a possibility to create a graph data set where the updates are included in the data set, so that the nodes and vertices get time stamps when they were deleted or when they were added? Yes. So, is it possible to create something like a temporal graph with the time stamps of when the specific node is created and deleted, and this is actually very easy, because this is the first step that the data gen creates. So, when David said that it creates a social network of three years, that has everything that was ever created or deleted during those three years, and then we have attributes like creation date and deletion date, and then we turn it into something that's loadable to the database, we hide deletion dates, because the database, of course, shouldn't be aware of this, but this is something that the data gen supports out of the box. Okay, but then it's also too able to get this data set with the deletion date, because you already said that it's hideable. It's hideable, but we have one which is called the row temporal data set, and that is available, and we even published that, so that's something that, yeah, it has a lot of chance to be influential in the streaming community, I believe. All right, more questions? Yeah, Michael? Yeah, Michael? So the question is, can we extend to other domains? And we usually emphasize that social networks is not really the domain that is the actual primary use case for graphs, we just use this because this is really easy to understand, we don't have to explain person-nose-person, and you can put in all sorts of interesting technological challenges to a graph domain like this. It would make sense, and sometimes we are approached by our members saying, we want to do a new benchmark in the domain X, and we then send them the process that is required to get one of these benchmarks completed, and that's usually the end of the conversation, but we are definitely open to have more interesting benchmarks, and of course, a good data generator is worth gold to all the researchers and the vendors in this community, so that's usually the hard point, and I would be definitely interested in having a retail graph generator. Carlo? Hi. The question is specifically, what do you see the impact of this will be on the industry or it's more uneductive of evidence if it's, if the system would have improved, or if the system would get more robust as in that you detect stuff that is doing things and stuff get fixed, or what's the, yeah. So the question? Yeah, the question is about the potential impact. What could all this achieve? And we believe that it will help accelerate the field in the sense that systems will get more mature, because if you want to get an audited result, you have to pass all the asset tests, you have to be able to recover after a crash, and ideally you would have to be fast, so that is hopefully one of the other things that systems will take away. They will have better optimizers, improved storage, better query execution engines, and we have seen this in the aftermath of the TPC benchmarks, so those resulted in quite a big speedup. So that's one area, and of course there is pricing, we would like that users can get more transactions per dollar, and the third that we are personally quite interested in is the new accelerators that come out. So there are, especially in the field of machine learning, there are cards that do fast sparse matrix multiplications, those could be harnessed specifically for the analytical benchmarks that we have, and that would be interesting to see how big of a hassle it is to implement and how big of a speedup they give, cool, all right, okay, thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.28, "text": " I am Gabor Sarnas and I'm here with David Proha.", "tokens": [286, 669, 460, 3816, 318, 1083, 296, 293, 286, 478, 510, 365, 4389, 1705, 1641, 13], "temperature": 0.0, "avg_logprob": -0.2339135822496916, "compression_ratio": 1.4533898305084745, "no_speech_prob": 0.21854065358638763}, {"id": 1, "seek": 0, "start": 8.28, "end": 14.32, "text": " We work at CWI Amsterdam and we're here to present you the LDBC social network benchmark.", "tokens": [492, 589, 412, 383, 54, 40, 28291, 293, 321, 434, 510, 281, 1974, 291, 264, 33936, 7869, 2093, 3209, 18927, 13], "temperature": 0.0, "avg_logprob": -0.2339135822496916, "compression_ratio": 1.4533898305084745, "no_speech_prob": 0.21854065358638763}, {"id": 2, "seek": 0, "start": 14.32, "end": 15.6, "text": " What is the LDBC?", "tokens": [708, 307, 264, 33936, 7869, 30], "temperature": 0.0, "avg_logprob": -0.2339135822496916, "compression_ratio": 1.4533898305084745, "no_speech_prob": 0.21854065358638763}, {"id": 3, "seek": 0, "start": 15.6, "end": 18.56, "text": " The abbreviation stands for Linked Data Benchmark Council.", "tokens": [440, 35839, 399, 7382, 337, 19322, 11888, 3964, 339, 5638, 7076, 13], "temperature": 0.0, "avg_logprob": -0.2339135822496916, "compression_ratio": 1.4533898305084745, "no_speech_prob": 0.21854065358638763}, {"id": 4, "seek": 0, "start": 18.56, "end": 23.32, "text": " It is a non-profit company founded in 2012 and its mission is to accelerate the progress", "tokens": [467, 307, 257, 2107, 12, 14583, 2237, 13234, 294, 9125, 293, 1080, 4447, 307, 281, 21341, 264, 4205], "temperature": 0.0, "avg_logprob": -0.2339135822496916, "compression_ratio": 1.4533898305084745, "no_speech_prob": 0.21854065358638763}, {"id": 5, "seek": 0, "start": 23.32, "end": 25.64, "text": " in the field of graph data management.", "tokens": [294, 264, 2519, 295, 4295, 1412, 4592, 13], "temperature": 0.0, "avg_logprob": -0.2339135822496916, "compression_ratio": 1.4533898305084745, "no_speech_prob": 0.21854065358638763}, {"id": 6, "seek": 2564, "start": 25.64, "end": 30.8, "text": " And to this end, it designs and governs the use of graph benchmarks and everything we", "tokens": [400, 281, 341, 917, 11, 309, 11347, 293, 1980, 82, 264, 764, 295, 4295, 43751, 293, 1203, 321], "temperature": 0.0, "avg_logprob": -0.1837259292602539, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0002050076291197911}, {"id": 7, "seek": 2564, "start": 30.8, "end": 34.96, "text": " do is open source under the Apache version 2 license.", "tokens": [360, 307, 1269, 4009, 833, 264, 46597, 3037, 568, 10476, 13], "temperature": 0.0, "avg_logprob": -0.1837259292602539, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0002050076291197911}, {"id": 8, "seek": 2564, "start": 34.96, "end": 40.36, "text": " From an organizational perspective, LDBC consists of more than 20 members who all have some", "tokens": [3358, 364, 24730, 4585, 11, 33936, 7869, 14689, 295, 544, 813, 945, 2679, 567, 439, 362, 512], "temperature": 0.0, "avg_logprob": -0.1837259292602539, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0002050076291197911}, {"id": 9, "seek": 2564, "start": 40.36, "end": 42.36, "text": " vested interest in graph data management.", "tokens": [49317, 1179, 294, 4295, 1412, 4592, 13], "temperature": 0.0, "avg_logprob": -0.1837259292602539, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0002050076291197911}, {"id": 10, "seek": 2564, "start": 42.36, "end": 46.760000000000005, "text": " We have financial service providers like the End Group, database vendors like Oracle,", "tokens": [492, 362, 4669, 2643, 11330, 411, 264, 6967, 10500, 11, 8149, 22056, 411, 25654, 11], "temperature": 0.0, "avg_logprob": -0.1837259292602539, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0002050076291197911}, {"id": 11, "seek": 2564, "start": 46.760000000000005, "end": 53.120000000000005, "text": " Neo4j and Tigrograph, cloud vendors like AWS and hardware vendors like Intel.", "tokens": [24458, 19, 73, 293, 44550, 6675, 2662, 11, 4588, 22056, 411, 17650, 293, 8837, 22056, 411, 19762, 13], "temperature": 0.0, "avg_logprob": -0.1837259292602539, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0002050076291197911}, {"id": 12, "seek": 5312, "start": 53.12, "end": 58.839999999999996, "text": " Also we have individual contributors like David and me who contribute to the benchmarks.", "tokens": [2743, 321, 362, 2609, 45627, 411, 4389, 293, 385, 567, 10586, 281, 264, 43751, 13], "temperature": 0.0, "avg_logprob": -0.12024424009233992, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.00014780668425373733}, {"id": 13, "seek": 5312, "start": 58.839999999999996, "end": 64.0, "text": " So to put things into context, the last two decades has seen a rise in the use of modern", "tokens": [407, 281, 829, 721, 666, 4319, 11, 264, 1036, 732, 7878, 575, 1612, 257, 6272, 294, 264, 764, 295, 4363], "temperature": 0.0, "avg_logprob": -0.12024424009233992, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.00014780668425373733}, {"id": 14, "seek": 5312, "start": 64.0, "end": 66.44, "text": " graph database management systems.", "tokens": [4295, 8149, 4592, 3652, 13], "temperature": 0.0, "avg_logprob": -0.12024424009233992, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.00014780668425373733}, {"id": 15, "seek": 5312, "start": 66.44, "end": 70.88, "text": " Typically, the data model used in these systems is called a property graph, which is a labelled", "tokens": [23129, 11, 264, 1412, 2316, 1143, 294, 613, 3652, 307, 1219, 257, 4707, 4295, 11, 597, 307, 257, 2715, 41307], "temperature": 0.0, "avg_logprob": -0.12024424009233992, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.00014780668425373733}, {"id": 16, "seek": 5312, "start": 70.88, "end": 75.52, "text": " graph where both the nodes and the edges can have an arbitrary number of properties.", "tokens": [4295, 689, 1293, 264, 13891, 293, 264, 8819, 393, 362, 364, 23211, 1230, 295, 7221, 13], "temperature": 0.0, "avg_logprob": -0.12024424009233992, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.00014780668425373733}, {"id": 17, "seek": 5312, "start": 75.52, "end": 80.32, "text": " For example, this is a small social network consisting of five person nodes and a single", "tokens": [1171, 1365, 11, 341, 307, 257, 1359, 2093, 3209, 33921, 295, 1732, 954, 13891, 293, 257, 2167], "temperature": 0.0, "avg_logprob": -0.12024424009233992, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.00014780668425373733}, {"id": 18, "seek": 8032, "start": 80.32, "end": 83.0, "text": " city node, which is the city of SPA.", "tokens": [2307, 9984, 11, 597, 307, 264, 2307, 295, 8420, 32, 13], "temperature": 0.0, "avg_logprob": -0.1386793325613211, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.0006973213749006391}, {"id": 19, "seek": 8032, "start": 83.0, "end": 85.03999999999999, "text": " And the properties can be on the nodes.", "tokens": [400, 264, 7221, 393, 312, 322, 264, 13891, 13], "temperature": 0.0, "avg_logprob": -0.1386793325613211, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.0006973213749006391}, {"id": 20, "seek": 8032, "start": 85.03999999999999, "end": 90.03999999999999, "text": " For example, here the nodes have names and the edges have attributes like the date when", "tokens": [1171, 1365, 11, 510, 264, 13891, 362, 5288, 293, 264, 8819, 362, 17212, 411, 264, 4002, 562], "temperature": 0.0, "avg_logprob": -0.1386793325613211, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.0006973213749006391}, {"id": 21, "seek": 8032, "start": 90.03999999999999, "end": 91.55999999999999, "text": " the friendship was established.", "tokens": [264, 13216, 390, 7545, 13], "temperature": 0.0, "avg_logprob": -0.1386793325613211, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.0006973213749006391}, {"id": 22, "seek": 8032, "start": 91.55999999999999, "end": 95.75999999999999, "text": " We can see that Bob and Carl met in 2015.", "tokens": [492, 393, 536, 300, 6085, 293, 14256, 1131, 294, 7546, 13], "temperature": 0.0, "avg_logprob": -0.1386793325613211, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.0006973213749006391}, {"id": 23, "seek": 8032, "start": 95.75999999999999, "end": 100.91999999999999, "text": " And if you want to run a query on this system, we can use a graph query where we look for", "tokens": [400, 498, 291, 528, 281, 1190, 257, 14581, 322, 341, 1185, 11, 321, 393, 764, 257, 4295, 14581, 689, 321, 574, 337], "temperature": 0.0, "avg_logprob": -0.1386793325613211, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.0006973213749006391}, {"id": 24, "seek": 8032, "start": 100.91999999999999, "end": 102.91999999999999, "text": " matches of a given graph.", "tokens": [10676, 295, 257, 2212, 4295, 13], "temperature": 0.0, "avg_logprob": -0.1386793325613211, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.0006973213749006391}, {"id": 25, "seek": 8032, "start": 102.91999999999999, "end": 106.28, "text": " So here the query says we want to start from Bob.", "tokens": [407, 510, 264, 14581, 1619, 321, 528, 281, 722, 490, 6085, 13], "temperature": 0.0, "avg_logprob": -0.1386793325613211, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.0006973213749006391}, {"id": 26, "seek": 10628, "start": 106.28, "end": 111.24, "text": " We want to use an arbitrary number of edges to reach some person who lives in SPA and", "tokens": [492, 528, 281, 764, 364, 23211, 1230, 295, 8819, 281, 2524, 512, 954, 567, 2909, 294, 8420, 32, 293], "temperature": 0.0, "avg_logprob": -0.09154449660202553, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00040809682104736567}, {"id": 27, "seek": 10628, "start": 111.24, "end": 115.68, "text": " we want to do an aggregation to return the number of those people.", "tokens": [321, 528, 281, 360, 364, 16743, 399, 281, 2736, 264, 1230, 295, 729, 561, 13], "temperature": 0.0, "avg_logprob": -0.09154449660202553, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00040809682104736567}, {"id": 28, "seek": 10628, "start": 115.68, "end": 121.8, "text": " If you want to evaluate this, we then start from the person Bob, push to all the people", "tokens": [759, 291, 528, 281, 13059, 341, 11, 321, 550, 722, 490, 264, 954, 6085, 11, 2944, 281, 439, 264, 561], "temperature": 0.0, "avg_logprob": -0.09154449660202553, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00040809682104736567}, {"id": 29, "seek": 10628, "start": 121.8, "end": 126.52000000000001, "text": " transitively, which are known by Bob directly or via multiple edges.", "tokens": [17976, 3413, 11, 597, 366, 2570, 538, 6085, 3838, 420, 5766, 3866, 8819, 13], "temperature": 0.0, "avg_logprob": -0.09154449660202553, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00040809682104736567}, {"id": 30, "seek": 10628, "start": 126.52000000000001, "end": 128.68, "text": " This means all four people here.", "tokens": [639, 1355, 439, 1451, 561, 510, 13], "temperature": 0.0, "avg_logprob": -0.09154449660202553, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00040809682104736567}, {"id": 31, "seek": 10628, "start": 128.68, "end": 133.24, "text": " We shrink it down to the people who actually live in SPA, then add up the results and get", "tokens": [492, 23060, 309, 760, 281, 264, 561, 567, 767, 1621, 294, 8420, 32, 11, 550, 909, 493, 264, 3542, 293, 483], "temperature": 0.0, "avg_logprob": -0.09154449660202553, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00040809682104736567}, {"id": 32, "seek": 10628, "start": 133.24, "end": 134.96, "text": " the result too.", "tokens": [264, 1874, 886, 13], "temperature": 0.0, "avg_logprob": -0.09154449660202553, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00040809682104736567}, {"id": 33, "seek": 13496, "start": 134.96, "end": 141.28, "text": " So graph databases use something called a visual graph syntax, also known as the sqr graph", "tokens": [407, 4295, 22380, 764, 746, 1219, 257, 5056, 4295, 28431, 11, 611, 2570, 382, 264, 262, 80, 81, 4295], "temperature": 0.0, "avg_logprob": -0.11927955555465986, "compression_ratio": 1.748, "no_speech_prob": 3.499113881844096e-05}, {"id": 34, "seek": 13496, "start": 141.28, "end": 147.92000000000002, "text": " syntax, which is similar to the popular cipher language of Neo4j.", "tokens": [28431, 11, 597, 307, 2531, 281, 264, 3743, 269, 21240, 2856, 295, 24458, 19, 73, 13], "temperature": 0.0, "avg_logprob": -0.11927955555465986, "compression_ratio": 1.748, "no_speech_prob": 3.499113881844096e-05}, {"id": 35, "seek": 13496, "start": 147.92000000000002, "end": 152.08, "text": " And here this query is actually really similar to the graph pattern that I have shown.", "tokens": [400, 510, 341, 14581, 307, 767, 534, 2531, 281, 264, 4295, 5102, 300, 286, 362, 4898, 13], "temperature": 0.0, "avg_logprob": -0.11927955555465986, "compression_ratio": 1.748, "no_speech_prob": 3.499113881844096e-05}, {"id": 36, "seek": 13496, "start": 152.08, "end": 156.36, "text": " So there are similarities in how the nodes are formulated, how the edges are captured", "tokens": [407, 456, 366, 24197, 294, 577, 264, 13891, 366, 48936, 11, 577, 264, 8819, 366, 11828], "temperature": 0.0, "avg_logprob": -0.11927955555465986, "compression_ratio": 1.748, "no_speech_prob": 3.499113881844096e-05}, {"id": 37, "seek": 13496, "start": 156.36, "end": 161.08, "text": " in this text, and also how the transitive closure of the little asterisk is captured", "tokens": [294, 341, 2487, 11, 293, 611, 577, 264, 1145, 2187, 24653, 295, 264, 707, 257, 3120, 7797, 307, 11828], "temperature": 0.0, "avg_logprob": -0.11927955555465986, "compression_ratio": 1.748, "no_speech_prob": 3.499113881844096e-05}, {"id": 38, "seek": 13496, "start": 161.08, "end": 162.44, "text": " in the query language.", "tokens": [294, 264, 14581, 2856, 13], "temperature": 0.0, "avg_logprob": -0.11927955555465986, "compression_ratio": 1.748, "no_speech_prob": 3.499113881844096e-05}, {"id": 39, "seek": 16244, "start": 162.44, "end": 166.96, "text": " So this is a very intuitive and concise way of formulating the queries.", "tokens": [407, 341, 307, 257, 588, 21769, 293, 44882, 636, 295, 1254, 12162, 264, 24109, 13], "temperature": 0.0, "avg_logprob": -0.1027116854985555, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00020403281087055802}, {"id": 40, "seek": 16244, "start": 166.96, "end": 171.24, "text": " If we deconstruct this query, we can see three main components.", "tokens": [759, 321, 49473, 1757, 341, 14581, 11, 321, 393, 536, 1045, 2135, 6677, 13], "temperature": 0.0, "avg_logprob": -0.1027116854985555, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00020403281087055802}, {"id": 41, "seek": 16244, "start": 171.24, "end": 172.64, "text": " The one is relational operators.", "tokens": [440, 472, 307, 38444, 19077, 13], "temperature": 0.0, "avg_logprob": -0.1027116854985555, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00020403281087055802}, {"id": 42, "seek": 16244, "start": 172.64, "end": 175.4, "text": " Obviously, we still need relational operators.", "tokens": [7580, 11, 321, 920, 643, 38444, 19077, 13], "temperature": 0.0, "avg_logprob": -0.1027116854985555, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00020403281087055802}, {"id": 43, "seek": 16244, "start": 175.4, "end": 178.68, "text": " We want to be able to identify people by filtering.", "tokens": [492, 528, 281, 312, 1075, 281, 5876, 561, 538, 30822, 13], "temperature": 0.0, "avg_logprob": -0.1027116854985555, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00020403281087055802}, {"id": 44, "seek": 16244, "start": 178.68, "end": 183.0, "text": " So we filter for Bob, we filter for SPA, and also we want to sometimes aggregate.", "tokens": [407, 321, 6608, 337, 6085, 11, 321, 6608, 337, 8420, 32, 11, 293, 611, 321, 528, 281, 2171, 26118, 13], "temperature": 0.0, "avg_logprob": -0.1027116854985555, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00020403281087055802}, {"id": 45, "seek": 16244, "start": 183.0, "end": 186.36, "text": " So the count aggregation is part of this query.", "tokens": [407, 264, 1207, 16743, 399, 307, 644, 295, 341, 14581, 13], "temperature": 0.0, "avg_logprob": -0.1027116854985555, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00020403281087055802}, {"id": 46, "seek": 16244, "start": 186.36, "end": 190.56, "text": " The pathfinding is really elegant in this formulation because we have nodes asterisk", "tokens": [440, 3100, 69, 9245, 307, 534, 21117, 294, 341, 37642, 570, 321, 362, 13891, 257, 3120, 7797], "temperature": 0.0, "avg_logprob": -0.1027116854985555, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00020403281087055802}, {"id": 47, "seek": 19056, "start": 190.56, "end": 193.92000000000002, "text": " which captures that we can use an arbitrary number of edges.", "tokens": [597, 27986, 300, 321, 393, 764, 364, 23211, 1230, 295, 8819, 13], "temperature": 0.0, "avg_logprob": -0.11216219104066187, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.0001257829717360437}, {"id": 48, "seek": 19056, "start": 193.92000000000002, "end": 200.6, "text": " And the pattern matching which connects the person to SPA is also very concise and readable.", "tokens": [400, 264, 5102, 14324, 597, 16967, 264, 954, 281, 8420, 32, 307, 611, 588, 44882, 293, 49857, 13], "temperature": 0.0, "avg_logprob": -0.11216219104066187, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.0001257829717360437}, {"id": 49, "seek": 19056, "start": 200.6, "end": 206.24, "text": " So what is interesting from a future work perspective on graph databases?", "tokens": [407, 437, 307, 1880, 490, 257, 2027, 589, 4585, 322, 4295, 22380, 30], "temperature": 0.0, "avg_logprob": -0.11216219104066187, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.0001257829717360437}, {"id": 50, "seek": 19056, "start": 206.24, "end": 210.2, "text": " Obviously, relational operators are quite well known at this point, and there are endless", "tokens": [7580, 11, 38444, 19077, 366, 1596, 731, 2570, 412, 341, 935, 11, 293, 456, 366, 16144], "temperature": 0.0, "avg_logprob": -0.11216219104066187, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.0001257829717360437}, {"id": 51, "seek": 19056, "start": 210.2, "end": 212.96, "text": " papers and techniques on how to implement these.", "tokens": [10577, 293, 7512, 322, 577, 281, 4445, 613, 13], "temperature": 0.0, "avg_logprob": -0.11216219104066187, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.0001257829717360437}, {"id": 52, "seek": 19056, "start": 212.96, "end": 217.72, "text": " But we believe that pathfinding and pattern matching is really good in graph databases", "tokens": [583, 321, 1697, 300, 3100, 69, 9245, 293, 5102, 14324, 307, 534, 665, 294, 4295, 22380], "temperature": 0.0, "avg_logprob": -0.11216219104066187, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.0001257829717360437}, {"id": 53, "seek": 21772, "start": 217.72, "end": 222.2, "text": " compared to traditional relational systems because they provide a more concise syntax", "tokens": [5347, 281, 5164, 38444, 3652, 570, 436, 2893, 257, 544, 44882, 28431], "temperature": 0.0, "avg_logprob": -0.17552106721060617, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.00043967145029455423}, {"id": 54, "seek": 21772, "start": 222.2, "end": 224.8, "text": " and better algorithms and implementations.", "tokens": [293, 1101, 14642, 293, 4445, 763, 13], "temperature": 0.0, "avg_logprob": -0.17552106721060617, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.00043967145029455423}, {"id": 55, "seek": 21772, "start": 224.8, "end": 229.52, "text": " Interestingly enough, even in the last 15 years, there have been lots of papers on better", "tokens": [30564, 1547, 11, 754, 294, 264, 1036, 2119, 924, 11, 456, 362, 668, 3195, 295, 10577, 322, 1101], "temperature": 0.0, "avg_logprob": -0.17552106721060617, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.00043967145029455423}, {"id": 56, "seek": 21772, "start": 229.52, "end": 236.16, "text": " BFS algorithms, better factorization representations for graph patterns, multi-wavers, case optimal", "tokens": [363, 29318, 14642, 11, 1101, 5952, 2144, 33358, 337, 4295, 8294, 11, 4825, 12, 4151, 840, 11, 1389, 16252], "temperature": 0.0, "avg_logprob": -0.17552106721060617, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.00043967145029455423}, {"id": 57, "seek": 21772, "start": 236.16, "end": 237.72, "text": " joins, and so on.", "tokens": [24397, 11, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.17552106721060617, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.00043967145029455423}, {"id": 58, "seek": 21772, "start": 237.72, "end": 241.0, "text": " So we believe that these should be adopted by more and more systems.", "tokens": [407, 321, 1697, 300, 613, 820, 312, 12175, 538, 544, 293, 544, 3652, 13], "temperature": 0.0, "avg_logprob": -0.17552106721060617, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.00043967145029455423}, {"id": 59, "seek": 21772, "start": 241.0, "end": 245.4, "text": " And to this end, we designed benchmarks that try to push the state of the art and the four", "tokens": [400, 281, 341, 917, 11, 321, 4761, 43751, 300, 853, 281, 2944, 264, 1785, 295, 264, 1523, 293, 264, 1451], "temperature": 0.0, "avg_logprob": -0.17552106721060617, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.00043967145029455423}, {"id": 60, "seek": 24540, "start": 245.4, "end": 248.0, "text": " systems to adopt better and better techniques.", "tokens": [3652, 281, 6878, 1101, 293, 1101, 7512, 13], "temperature": 0.0, "avg_logprob": -0.2178136844827671, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.0006157255847938359}, {"id": 61, "seek": 24540, "start": 248.0, "end": 250.16, "text": " David will talk about these benchmarks.", "tokens": [4389, 486, 751, 466, 613, 43751, 13], "temperature": 0.0, "avg_logprob": -0.2178136844827671, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.0006157255847938359}, {"id": 62, "seek": 24540, "start": 250.16, "end": 251.52, "text": " Yeah, hi.", "tokens": [865, 11, 4879, 13], "temperature": 0.0, "avg_logprob": -0.2178136844827671, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.0006157255847938359}, {"id": 63, "seek": 24540, "start": 251.52, "end": 254.8, "text": " So I will give an overview about the social network benchmark.", "tokens": [407, 286, 486, 976, 364, 12492, 466, 264, 2093, 3209, 18927, 13], "temperature": 0.0, "avg_logprob": -0.2178136844827671, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.0006157255847938359}, {"id": 64, "seek": 24540, "start": 254.8, "end": 261.52, "text": " And so first, we'll go through three steps of this benchmark, so the data sets, two example", "tokens": [400, 370, 700, 11, 321, 603, 352, 807, 1045, 4439, 295, 341, 18927, 11, 370, 264, 1412, 6352, 11, 732, 1365], "temperature": 0.0, "avg_logprob": -0.2178136844827671, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.0006157255847938359}, {"id": 65, "seek": 24540, "start": 261.52, "end": 265.36, "text": " queries, and the update operations done in this benchmark.", "tokens": [24109, 11, 293, 264, 5623, 7705, 1096, 294, 341, 18927, 13], "temperature": 0.0, "avg_logprob": -0.2178136844827671, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.0006157255847938359}, {"id": 66, "seek": 24540, "start": 265.36, "end": 271.36, "text": " So here we see a small example of the data sets where on the left side, we see persons", "tokens": [407, 510, 321, 536, 257, 1359, 1365, 295, 264, 1412, 6352, 689, 322, 264, 1411, 1252, 11, 321, 536, 14453], "temperature": 0.0, "avg_logprob": -0.2178136844827671, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.0006157255847938359}, {"id": 67, "seek": 27136, "start": 271.36, "end": 277.44, "text": " with friendships, forms, and network, and these persons post messages on the social network", "tokens": [365, 30003, 11, 6422, 11, 293, 3209, 11, 293, 613, 14453, 2183, 7897, 322, 264, 2093, 3209], "temperature": 0.0, "avg_logprob": -0.13843019803365073, "compression_ratio": 1.7272727272727273, "no_speech_prob": 8.913255442166701e-05}, {"id": 68, "seek": 27136, "start": 277.44, "end": 282.88, "text": " and can reply to each other forming a tree-shaped data structure.", "tokens": [293, 393, 16972, 281, 1184, 661, 15745, 257, 4230, 12, 23103, 1412, 3877, 13], "temperature": 0.0, "avg_logprob": -0.13843019803365073, "compression_ratio": 1.7272727272727273, "no_speech_prob": 8.913255442166701e-05}, {"id": 69, "seek": 27136, "start": 282.88, "end": 288.64, "text": " And now we will do one query on this very small data set example.", "tokens": [400, 586, 321, 486, 360, 472, 14581, 322, 341, 588, 1359, 1412, 992, 1365, 13], "temperature": 0.0, "avg_logprob": -0.13843019803365073, "compression_ratio": 1.7272727272727273, "no_speech_prob": 8.913255442166701e-05}, {"id": 70, "seek": 27136, "start": 288.64, "end": 294.72, "text": " So with query nine, we want to retrieve messages posted by a given person, friend, and friends", "tokens": [407, 365, 14581, 4949, 11, 321, 528, 281, 30254, 7897, 9437, 538, 257, 2212, 954, 11, 1277, 11, 293, 1855], "temperature": 0.0, "avg_logprob": -0.13843019803365073, "compression_ratio": 1.7272727272727273, "no_speech_prob": 8.913255442166701e-05}, {"id": 71, "seek": 27136, "start": 294.72, "end": 298.28000000000003, "text": " of friends before a given date.", "tokens": [295, 1855, 949, 257, 2212, 4002, 13], "temperature": 0.0, "avg_logprob": -0.13843019803365073, "compression_ratio": 1.7272727272727273, "no_speech_prob": 8.913255442166701e-05}, {"id": 72, "seek": 27136, "start": 298.28000000000003, "end": 300.64, "text": " And the dates are here shortened for simplicity.", "tokens": [400, 264, 11691, 366, 510, 45183, 337, 25632, 13], "temperature": 0.0, "avg_logprob": -0.13843019803365073, "compression_ratio": 1.7272727272727273, "no_speech_prob": 8.913255442166701e-05}, {"id": 73, "seek": 30064, "start": 300.64, "end": 306.24, "text": " So if we would start with BOP, we will traverse to their friends and friends of friends, retrieve", "tokens": [407, 498, 321, 576, 722, 365, 363, 12059, 11, 321, 486, 45674, 281, 641, 1855, 293, 1855, 295, 1855, 11, 30254], "temperature": 0.0, "avg_logprob": -0.17477336372296834, "compression_ratio": 1.7946428571428572, "no_speech_prob": 0.00019509971025399864}, {"id": 74, "seek": 30064, "start": 306.24, "end": 312.12, "text": " the messages, and then filter out the ones that are actually before Saturday.", "tokens": [264, 7897, 11, 293, 550, 6608, 484, 264, 2306, 300, 366, 767, 949, 8803, 13], "temperature": 0.0, "avg_logprob": -0.17477336372296834, "compression_ratio": 1.7946428571428572, "no_speech_prob": 0.00019509971025399864}, {"id": 75, "seek": 30064, "start": 312.12, "end": 315.52, "text": " And then we touch upon 10 nodes in this data.", "tokens": [400, 550, 321, 2557, 3564, 1266, 13891, 294, 341, 1412, 13], "temperature": 0.0, "avg_logprob": -0.17477336372296834, "compression_ratio": 1.7946428571428572, "no_speech_prob": 0.00019509971025399864}, {"id": 76, "seek": 30064, "start": 315.52, "end": 321.24, "text": " Suppose we would start from another person, so for example Finn, and we traverse again", "tokens": [21360, 321, 576, 722, 490, 1071, 954, 11, 370, 337, 1365, 21066, 11, 293, 321, 45674, 797], "temperature": 0.0, "avg_logprob": -0.17477336372296834, "compression_ratio": 1.7946428571428572, "no_speech_prob": 0.00019509971025399864}, {"id": 77, "seek": 30064, "start": 321.24, "end": 324.64, "text": " to their friends and friends of friends.", "tokens": [281, 641, 1855, 293, 1855, 295, 1855, 13], "temperature": 0.0, "avg_logprob": -0.17477336372296834, "compression_ratio": 1.7946428571428572, "no_speech_prob": 0.00019509971025399864}, {"id": 78, "seek": 30064, "start": 324.64, "end": 330.24, "text": " Here we see that we touch upon five different nodes.", "tokens": [1692, 321, 536, 300, 321, 2557, 3564, 1732, 819, 13891, 13], "temperature": 0.0, "avg_logprob": -0.17477336372296834, "compression_ratio": 1.7946428571428572, "no_speech_prob": 0.00019509971025399864}, {"id": 79, "seek": 33024, "start": 330.24, "end": 333.2, "text": " So half of the one of BOP.", "tokens": [407, 1922, 295, 264, 472, 295, 363, 12059, 13], "temperature": 0.0, "avg_logprob": -0.11317281973989386, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.00038134862552396953}, {"id": 80, "seek": 33024, "start": 333.2, "end": 340.68, "text": " And this difference can actually be troublesome since runtimes for the same queries are different", "tokens": [400, 341, 2649, 393, 767, 312, 46838, 1670, 49435, 1532, 337, 264, 912, 24109, 366, 819], "temperature": 0.0, "avg_logprob": -0.11317281973989386, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.00038134862552396953}, {"id": 81, "seek": 33024, "start": 340.68, "end": 345.24, "text": " and therefore doesn't help in understanding what's happening.", "tokens": [293, 4412, 1177, 380, 854, 294, 3701, 437, 311, 2737, 13], "temperature": 0.0, "avg_logprob": -0.11317281973989386, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.00038134862552396953}, {"id": 82, "seek": 33024, "start": 345.24, "end": 351.64, "text": " So for this benchmark, we actually want to select parameters that have similar runtimes", "tokens": [407, 337, 341, 18927, 11, 321, 767, 528, 281, 3048, 9834, 300, 362, 2531, 49435, 1532], "temperature": 0.0, "avg_logprob": -0.11317281973989386, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.00038134862552396953}, {"id": 83, "seek": 33024, "start": 351.64, "end": 356.2, "text": " and also to actually stress the technical difficulties in these systems.", "tokens": [293, 611, 281, 767, 4244, 264, 6191, 14399, 294, 613, 3652, 13], "temperature": 0.0, "avg_logprob": -0.11317281973989386, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.00038134862552396953}, {"id": 84, "seek": 35620, "start": 356.2, "end": 360.32, "text": " So we select the parameters more carefully.", "tokens": [407, 321, 3048, 264, 9834, 544, 7500, 13], "temperature": 0.0, "avg_logprob": -0.1614482378718829, "compression_ratio": 1.755656108597285, "no_speech_prob": 5.140539724379778e-05}, {"id": 85, "seek": 35620, "start": 360.32, "end": 365.52, "text": " So here we see an example of when we do not select the parameters carefully, just a uniform", "tokens": [407, 510, 321, 536, 364, 1365, 295, 562, 321, 360, 406, 3048, 264, 9834, 7500, 11, 445, 257, 9452], "temperature": 0.0, "avg_logprob": -0.1614482378718829, "compression_ratio": 1.755656108597285, "no_speech_prob": 5.140539724379778e-05}, {"id": 86, "seek": 35620, "start": 365.52, "end": 366.52, "text": " random.", "tokens": [4974, 13], "temperature": 0.0, "avg_logprob": -0.1614482378718829, "compression_ratio": 1.755656108597285, "no_speech_prob": 5.140539724379778e-05}, {"id": 87, "seek": 35620, "start": 366.52, "end": 372.4, "text": " And we can see here a trial model, distribution by model, and one with many outliers.", "tokens": [400, 321, 393, 536, 510, 257, 7308, 2316, 11, 7316, 538, 2316, 11, 293, 472, 365, 867, 484, 23646, 13], "temperature": 0.0, "avg_logprob": -0.1614482378718829, "compression_ratio": 1.755656108597285, "no_speech_prob": 5.140539724379778e-05}, {"id": 88, "seek": 35620, "start": 372.4, "end": 374.52, "text": " And we don't want that.", "tokens": [400, 321, 500, 380, 528, 300, 13], "temperature": 0.0, "avg_logprob": -0.1614482378718829, "compression_ratio": 1.755656108597285, "no_speech_prob": 5.140539724379778e-05}, {"id": 89, "seek": 35620, "start": 374.52, "end": 382.4, "text": " So in the data sets, there are also statistics provided in this example for each person,", "tokens": [407, 294, 264, 1412, 6352, 11, 456, 366, 611, 12523, 5649, 294, 341, 1365, 337, 1184, 954, 11], "temperature": 0.0, "avg_logprob": -0.1614482378718829, "compression_ratio": 1.755656108597285, "no_speech_prob": 5.140539724379778e-05}, {"id": 90, "seek": 35620, "start": 382.4, "end": 385.24, "text": " the number of friends and friends of friends.", "tokens": [264, 1230, 295, 1855, 293, 1855, 295, 1855, 13], "temperature": 0.0, "avg_logprob": -0.1614482378718829, "compression_ratio": 1.755656108597285, "no_speech_prob": 5.140539724379778e-05}, {"id": 91, "seek": 38524, "start": 385.24, "end": 392.24, "text": " Then we want to select persons with similar number to get more predictable runtimes.", "tokens": [1396, 321, 528, 281, 3048, 14453, 365, 2531, 1230, 281, 483, 544, 27737, 49435, 1532, 13], "temperature": 0.0, "avg_logprob": -0.14572151899337768, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.00014924092101864517}, {"id": 92, "seek": 38524, "start": 392.24, "end": 397.96000000000004, "text": " And so if we do that, then we can see here an example that we have unimodal distributions", "tokens": [400, 370, 498, 321, 360, 300, 11, 550, 321, 393, 536, 510, 364, 1365, 300, 321, 362, 517, 332, 378, 304, 37870], "temperature": 0.0, "avg_logprob": -0.14572151899337768, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.00014924092101864517}, {"id": 93, "seek": 38524, "start": 397.96000000000004, "end": 400.88, "text": " with very tight runtimes.", "tokens": [365, 588, 4524, 49435, 1532, 13], "temperature": 0.0, "avg_logprob": -0.14572151899337768, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.00014924092101864517}, {"id": 94, "seek": 38524, "start": 400.88, "end": 407.8, "text": " And that improves also in understanding these, like the behavior of the queries.", "tokens": [400, 300, 24771, 611, 294, 3701, 613, 11, 411, 264, 5223, 295, 264, 24109, 13], "temperature": 0.0, "avg_logprob": -0.14572151899337768, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.00014924092101864517}, {"id": 95, "seek": 38524, "start": 407.8, "end": 410.6, "text": " So now we're going to the updates.", "tokens": [407, 586, 321, 434, 516, 281, 264, 9205, 13], "temperature": 0.0, "avg_logprob": -0.14572151899337768, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.00014924092101864517}, {"id": 96, "seek": 41060, "start": 410.6, "end": 417.28000000000003, "text": " And for example, if Eve and Gia wants to be friends, we insert a nose edge.", "tokens": [400, 337, 1365, 11, 498, 15544, 293, 460, 654, 2738, 281, 312, 1855, 11, 321, 8969, 257, 6690, 4691, 13], "temperature": 0.0, "avg_logprob": -0.15697329935401377, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.0002108932676492259}, {"id": 97, "seek": 41060, "start": 417.28000000000003, "end": 421.12, "text": " And this is then formed into the network.", "tokens": [400, 341, 307, 550, 8693, 666, 264, 3209, 13], "temperature": 0.0, "avg_logprob": -0.15697329935401377, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.0002108932676492259}, {"id": 98, "seek": 41060, "start": 421.12, "end": 424.08000000000004, "text": " Suppose that the next operation is inserting a comment.", "tokens": [21360, 300, 264, 958, 6916, 307, 46567, 257, 2871, 13], "temperature": 0.0, "avg_logprob": -0.15697329935401377, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.0002108932676492259}, {"id": 99, "seek": 41060, "start": 424.08000000000004, "end": 429.12, "text": " So Gia comments replies on a message posted by Eve.", "tokens": [407, 460, 654, 3053, 42289, 322, 257, 3636, 9437, 538, 15544, 13], "temperature": 0.0, "avg_logprob": -0.15697329935401377, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.0002108932676492259}, {"id": 100, "seek": 41060, "start": 429.12, "end": 432.88, "text": " And both messages are posted on the same date.", "tokens": [400, 1293, 7897, 366, 9437, 322, 264, 912, 4002, 13], "temperature": 0.0, "avg_logprob": -0.15697329935401377, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.0002108932676492259}, {"id": 101, "seek": 41060, "start": 432.88, "end": 435.28000000000003, "text": " Then we have another problem.", "tokens": [1396, 321, 362, 1071, 1154, 13], "temperature": 0.0, "avg_logprob": -0.15697329935401377, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.0002108932676492259}, {"id": 102, "seek": 41060, "start": 435.28000000000003, "end": 440.36, "text": " Because when we are executing these operations concurrently, it can happen that the reply", "tokens": [1436, 562, 321, 366, 32368, 613, 7705, 37702, 356, 11, 309, 393, 1051, 300, 264, 16972], "temperature": 0.0, "avg_logprob": -0.15697329935401377, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.0002108932676492259}, {"id": 103, "seek": 44036, "start": 440.36, "end": 446.72, "text": " is earlier than the message in such a network, posting an error.", "tokens": [307, 3071, 813, 264, 3636, 294, 1270, 257, 3209, 11, 15978, 364, 6713, 13], "temperature": 0.0, "avg_logprob": -0.14924365527009312, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0002945214801002294}, {"id": 104, "seek": 44036, "start": 446.72, "end": 451.32, "text": " And to mitigate this, we introduce dependency tracking.", "tokens": [400, 281, 27336, 341, 11, 321, 5366, 33621, 11603, 13], "temperature": 0.0, "avg_logprob": -0.14924365527009312, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0002945214801002294}, {"id": 105, "seek": 44036, "start": 451.32, "end": 456.88, "text": " So for each operation, and also includes the edges, but just for simplicity, the notes", "tokens": [407, 337, 1184, 6916, 11, 293, 611, 5974, 264, 8819, 11, 457, 445, 337, 25632, 11, 264, 5570], "temperature": 0.0, "avg_logprob": -0.14924365527009312, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0002945214801002294}, {"id": 106, "seek": 44036, "start": 456.88, "end": 460.96000000000004, "text": " are here with the dependent dates.", "tokens": [366, 510, 365, 264, 12334, 11691, 13], "temperature": 0.0, "avg_logprob": -0.14924365527009312, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0002945214801002294}, {"id": 107, "seek": 44036, "start": 460.96000000000004, "end": 465.36, "text": " We include for each operation a creation date and dependent date.", "tokens": [492, 4090, 337, 1184, 6916, 257, 8016, 4002, 293, 12334, 4002, 13], "temperature": 0.0, "avg_logprob": -0.14924365527009312, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0002945214801002294}, {"id": 108, "seek": 46536, "start": 465.36, "end": 470.36, "text": " The creation date is when it's scheduled to be executed, and the dependent date is the", "tokens": [440, 8016, 4002, 307, 562, 309, 311, 15678, 281, 312, 17577, 11, 293, 264, 12334, 4002, 307, 264], "temperature": 0.0, "avg_logprob": -0.1568060128585152, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00010443075007060543}, {"id": 109, "seek": 46536, "start": 470.36, "end": 478.04, "text": " one that's, like in this case, for M6, is the creation date of M3.", "tokens": [472, 300, 311, 11, 411, 294, 341, 1389, 11, 337, 376, 21, 11, 307, 264, 8016, 4002, 295, 376, 18, 13], "temperature": 0.0, "avg_logprob": -0.1568060128585152, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00010443075007060543}, {"id": 110, "seek": 46536, "start": 478.04, "end": 482.76, "text": " And here we can see, actually, that each operation is dependent on each other, forming", "tokens": [400, 510, 321, 393, 536, 11, 767, 11, 300, 1184, 6916, 307, 12334, 322, 1184, 661, 11, 15745], "temperature": 0.0, "avg_logprob": -0.1568060128585152, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00010443075007060543}, {"id": 111, "seek": 46536, "start": 482.76, "end": 486.36, "text": " a whole chain in the social network.", "tokens": [257, 1379, 5021, 294, 264, 2093, 3209, 13], "temperature": 0.0, "avg_logprob": -0.1568060128585152, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00010443075007060543}, {"id": 112, "seek": 46536, "start": 486.36, "end": 490.88, "text": " Suppose now that Eve wants to leave the social network and removes her account.", "tokens": [21360, 586, 300, 15544, 2738, 281, 1856, 264, 2093, 3209, 293, 30445, 720, 2696, 13], "temperature": 0.0, "avg_logprob": -0.1568060128585152, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00010443075007060543}, {"id": 113, "seek": 49088, "start": 490.88, "end": 495.92, "text": " And so we start with deleting the notes of Eve, and this will trigger a cascading effect", "tokens": [400, 370, 321, 722, 365, 48946, 264, 5570, 295, 15544, 11, 293, 341, 486, 7875, 257, 3058, 66, 8166, 1802], "temperature": 0.0, "avg_logprob": -0.17064969916092723, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.00030318828066810966}, {"id": 114, "seek": 49088, "start": 495.92, "end": 502.52, "text": " by, since we then need to remove the edges connected to Eve, the messages posted, and", "tokens": [538, 11, 1670, 321, 550, 643, 281, 4159, 264, 8819, 4582, 281, 15544, 11, 264, 7897, 9437, 11, 293], "temperature": 0.0, "avg_logprob": -0.17064969916092723, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.00030318828066810966}, {"id": 115, "seek": 49088, "start": 502.52, "end": 505.44, "text": " also the replies to those messages.", "tokens": [611, 264, 42289, 281, 729, 7897, 13], "temperature": 0.0, "avg_logprob": -0.17064969916092723, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.00030318828066810966}, {"id": 116, "seek": 49088, "start": 505.44, "end": 511.2, "text": " We can actually see, like, this huge cascading effect, and that can actually have a large", "tokens": [492, 393, 767, 536, 11, 411, 11, 341, 2603, 3058, 66, 8166, 1802, 11, 293, 300, 393, 767, 362, 257, 2416], "temperature": 0.0, "avg_logprob": -0.17064969916092723, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.00030318828066810966}, {"id": 117, "seek": 49088, "start": 511.2, "end": 518.44, "text": " impact on the data distribution, and also therefore the executability of these operations.", "tokens": [2712, 322, 264, 1412, 7316, 11, 293, 611, 4412, 264, 7568, 2310, 295, 613, 7705, 13], "temperature": 0.0, "avg_logprob": -0.17064969916092723, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.00030318828066810966}, {"id": 118, "seek": 51844, "start": 518.44, "end": 525.32, "text": " And furthermore, it also influences for selecting the parameters, which we have shown before.", "tokens": [400, 3052, 3138, 11, 309, 611, 21222, 337, 18182, 264, 9834, 11, 597, 321, 362, 4898, 949, 13], "temperature": 0.0, "avg_logprob": -0.1590755396875842, "compression_ratio": 1.616326530612245, "no_speech_prob": 0.000147680621012114}, {"id": 119, "seek": 51844, "start": 525.32, "end": 529.6400000000001, "text": " And we want to include this delete because it prohibits append only data structures in", "tokens": [400, 321, 528, 281, 4090, 341, 12097, 570, 309, 16015, 1208, 34116, 787, 1412, 9227, 294], "temperature": 0.0, "avg_logprob": -0.1590755396875842, "compression_ratio": 1.616326530612245, "no_speech_prob": 0.000147680621012114}, {"id": 120, "seek": 51844, "start": 529.6400000000001, "end": 534.12, "text": " databases and also stress the garbage collector of these systems.", "tokens": [22380, 293, 611, 4244, 264, 14150, 23960, 295, 613, 3652, 13], "temperature": 0.0, "avg_logprob": -0.1590755396875842, "compression_ratio": 1.616326530612245, "no_speech_prob": 0.000147680621012114}, {"id": 121, "seek": 51844, "start": 534.12, "end": 540.36, "text": " Now we are going to give another example to also stress the temporal aspect of this benchmark.", "tokens": [823, 321, 366, 516, 281, 976, 1071, 1365, 281, 611, 4244, 264, 30881, 4171, 295, 341, 18927, 13], "temperature": 0.0, "avg_logprob": -0.1590755396875842, "compression_ratio": 1.616326530612245, "no_speech_prob": 0.000147680621012114}, {"id": 122, "seek": 51844, "start": 540.36, "end": 544.6800000000001, "text": " So suppose we want to find a path between two persons.", "tokens": [407, 7297, 321, 528, 281, 915, 257, 3100, 1296, 732, 14453, 13], "temperature": 0.0, "avg_logprob": -0.1590755396875842, "compression_ratio": 1.616326530612245, "no_speech_prob": 0.000147680621012114}, {"id": 123, "seek": 54468, "start": 544.68, "end": 551.0799999999999, "text": " So we have a start person and a destination person, and, for example, Finn and Gia.", "tokens": [407, 321, 362, 257, 722, 954, 293, 257, 12236, 954, 11, 293, 11, 337, 1365, 11, 21066, 293, 460, 654, 13], "temperature": 0.0, "avg_logprob": -0.15288131676831293, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.00017006468260660768}, {"id": 124, "seek": 54468, "start": 551.0799999999999, "end": 556.04, "text": " Then we can see here that we have a four-hole path between these persons.", "tokens": [1396, 321, 393, 536, 510, 300, 321, 362, 257, 1451, 12, 14094, 3100, 1296, 613, 14453, 13], "temperature": 0.0, "avg_logprob": -0.15288131676831293, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.00017006468260660768}, {"id": 125, "seek": 54468, "start": 556.04, "end": 562.12, "text": " But at one point in the benchmark, it can happen that a node's edge is removed, and", "tokens": [583, 412, 472, 935, 294, 264, 18927, 11, 309, 393, 1051, 300, 257, 9984, 311, 4691, 307, 7261, 11, 293], "temperature": 0.0, "avg_logprob": -0.15288131676831293, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.00017006468260660768}, {"id": 126, "seek": 54468, "start": 562.12, "end": 565.16, "text": " then there is no path anymore.", "tokens": [550, 456, 307, 572, 3100, 3602, 13], "temperature": 0.0, "avg_logprob": -0.15288131676831293, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.00017006468260660768}, {"id": 127, "seek": 54468, "start": 565.16, "end": 569.56, "text": " It can also happen that there's another edge inserted between Carl and Gia, and then we", "tokens": [467, 393, 611, 1051, 300, 456, 311, 1071, 4691, 27992, 1296, 14256, 293, 460, 654, 11, 293, 550, 321], "temperature": 0.0, "avg_logprob": -0.15288131676831293, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.00017006468260660768}, {"id": 128, "seek": 54468, "start": 569.56, "end": 571.8399999999999, "text": " have a path again.", "tokens": [362, 257, 3100, 797, 13], "temperature": 0.0, "avg_logprob": -0.15288131676831293, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.00017006468260660768}, {"id": 129, "seek": 57184, "start": 571.84, "end": 576.64, "text": " And so for the same parameters, we can actually have three different outcomes.", "tokens": [400, 370, 337, 264, 912, 9834, 11, 321, 393, 767, 362, 1045, 819, 10070, 13], "temperature": 0.0, "avg_logprob": -0.09026932186550564, "compression_ratio": 1.680672268907563, "no_speech_prob": 3.593189103412442e-05}, {"id": 130, "seek": 57184, "start": 576.64, "end": 579.48, "text": " And to mitigate this, we do temporal parameter selection.", "tokens": [400, 281, 27336, 341, 11, 321, 360, 30881, 13075, 9450, 13], "temperature": 0.0, "avg_logprob": -0.09026932186550564, "compression_ratio": 1.680672268907563, "no_speech_prob": 3.593189103412442e-05}, {"id": 131, "seek": 57184, "start": 579.48, "end": 586.24, "text": " So each parameter is assigned in a time bucket to actually ensure that we have similar results", "tokens": [407, 1184, 13075, 307, 13279, 294, 257, 565, 13058, 281, 767, 5586, 300, 321, 362, 2531, 3542], "temperature": 0.0, "avg_logprob": -0.09026932186550564, "compression_ratio": 1.680672268907563, "no_speech_prob": 3.593189103412442e-05}, {"id": 132, "seek": 57184, "start": 586.24, "end": 589.32, "text": " and therefore also similar run times.", "tokens": [293, 4412, 611, 2531, 1190, 1413, 13], "temperature": 0.0, "avg_logprob": -0.09026932186550564, "compression_ratio": 1.680672268907563, "no_speech_prob": 3.593189103412442e-05}, {"id": 133, "seek": 57184, "start": 589.32, "end": 592.6800000000001, "text": " Now going through the benchmark workflow.", "tokens": [823, 516, 807, 264, 18927, 20993, 13], "temperature": 0.0, "avg_logprob": -0.09026932186550564, "compression_ratio": 1.680672268907563, "no_speech_prob": 3.593189103412442e-05}, {"id": 134, "seek": 57184, "start": 592.6800000000001, "end": 599.6, "text": " So we start by the data gen, and the data gen provides us with a temporal graph spanning", "tokens": [407, 321, 722, 538, 264, 1412, 1049, 11, 293, 264, 1412, 1049, 6417, 505, 365, 257, 30881, 4295, 47626], "temperature": 0.0, "avg_logprob": -0.09026932186550564, "compression_ratio": 1.680672268907563, "no_speech_prob": 3.593189103412442e-05}, {"id": 135, "seek": 59960, "start": 599.6, "end": 605.4, "text": " over social media activity for three years, and it is simulated closely to the, similar", "tokens": [670, 2093, 3021, 5191, 337, 1045, 924, 11, 293, 309, 307, 41713, 8185, 281, 264, 11, 2531], "temperature": 0.0, "avg_logprob": -0.1736981404292119, "compression_ratio": 1.578125, "no_speech_prob": 0.00012231123400852084}, {"id": 136, "seek": 59960, "start": 605.4, "end": 608.5600000000001, "text": " to the Facebook social network.", "tokens": [281, 264, 4384, 2093, 3209, 13], "temperature": 0.0, "avg_logprob": -0.1736981404292119, "compression_ratio": 1.578125, "no_speech_prob": 0.00012231123400852084}, {"id": 137, "seek": 59960, "start": 608.5600000000001, "end": 615.48, "text": " It's a spark-based data generator that can generate data up to 30 terabytes, and it contains", "tokens": [467, 311, 257, 9908, 12, 6032, 1412, 19265, 300, 393, 8460, 1412, 493, 281, 2217, 1796, 24538, 11, 293, 309, 8306], "temperature": 0.0, "avg_logprob": -0.1736981404292119, "compression_ratio": 1.578125, "no_speech_prob": 0.00012231123400852084}, {"id": 138, "seek": 59960, "start": 615.48, "end": 624.72, "text": " the, you know, skewed data sets, for example, with the nodes and person data in this data.", "tokens": [264, 11, 291, 458, 11, 8756, 26896, 1412, 6352, 11, 337, 1365, 11, 365, 264, 13891, 293, 954, 1412, 294, 341, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1736981404292119, "compression_ratio": 1.578125, "no_speech_prob": 0.00012231123400852084}, {"id": 139, "seek": 62472, "start": 624.72, "end": 631.1600000000001, "text": " And so the output is a data set suitable for loading into the system on a test, updates", "tokens": [400, 370, 264, 5598, 307, 257, 1412, 992, 12873, 337, 15114, 666, 264, 1185, 322, 257, 1500, 11, 9205], "temperature": 0.0, "avg_logprob": -0.16282725016276042, "compression_ratio": 1.698019801980198, "no_speech_prob": 6.344237044686452e-05}, {"id": 140, "seek": 62472, "start": 631.1600000000001, "end": 638.28, "text": " which are then executed during the benchmark, and statistics where we can select the parameters.", "tokens": [597, 366, 550, 17577, 1830, 264, 18927, 11, 293, 12523, 689, 321, 393, 3048, 264, 9834, 13], "temperature": 0.0, "avg_logprob": -0.16282725016276042, "compression_ratio": 1.698019801980198, "no_speech_prob": 6.344237044686452e-05}, {"id": 141, "seek": 62472, "start": 638.28, "end": 642.36, "text": " And the selection of the parameters is done in the parameter generator.", "tokens": [400, 264, 9450, 295, 264, 9834, 307, 1096, 294, 264, 13075, 19265, 13], "temperature": 0.0, "avg_logprob": -0.16282725016276042, "compression_ratio": 1.698019801980198, "no_speech_prob": 6.344237044686452e-05}, {"id": 142, "seek": 62472, "start": 642.36, "end": 648.24, "text": " This ensures the stable query run times and assigns parameters into a temporal bucket.", "tokens": [639, 28111, 264, 8351, 14581, 1190, 1413, 293, 6269, 82, 9834, 666, 257, 30881, 13058, 13], "temperature": 0.0, "avg_logprob": -0.16282725016276042, "compression_ratio": 1.698019801980198, "no_speech_prob": 6.344237044686452e-05}, {"id": 143, "seek": 64824, "start": 648.24, "end": 655.92, "text": " So a parameter can, it may include parameters that once are inserted into the data sets", "tokens": [407, 257, 13075, 393, 11, 309, 815, 4090, 9834, 300, 1564, 366, 27992, 666, 264, 1412, 6352], "temperature": 0.0, "avg_logprob": -0.1554689915974935, "compression_ratio": 1.6192660550458715, "no_speech_prob": 2.798013338178862e-05}, {"id": 144, "seek": 64824, "start": 655.92, "end": 660.6, "text": " or before they are removed from the network.", "tokens": [420, 949, 436, 366, 7261, 490, 264, 3209, 13], "temperature": 0.0, "avg_logprob": -0.1554689915974935, "compression_ratio": 1.6192660550458715, "no_speech_prob": 2.798013338178862e-05}, {"id": 145, "seek": 64824, "start": 660.6, "end": 666.76, "text": " So and then we have a benchmark driver who schedules these operations and ensures that", "tokens": [407, 293, 550, 321, 362, 257, 18927, 6787, 567, 28078, 613, 7705, 293, 28111, 300], "temperature": 0.0, "avg_logprob": -0.1554689915974935, "compression_ratio": 1.6192660550458715, "no_speech_prob": 2.798013338178862e-05}, {"id": 146, "seek": 64824, "start": 666.76, "end": 671.12, "text": " they can be executed with using the dependency tracking.", "tokens": [436, 393, 312, 17577, 365, 1228, 264, 33621, 11603, 13], "temperature": 0.0, "avg_logprob": -0.1554689915974935, "compression_ratio": 1.6192660550458715, "no_speech_prob": 2.798013338178862e-05}, {"id": 147, "seek": 64824, "start": 671.12, "end": 676.92, "text": " And this is especially important when executing the operations concurrently.", "tokens": [400, 341, 307, 2318, 1021, 562, 32368, 264, 7705, 37702, 356, 13], "temperature": 0.0, "avg_logprob": -0.1554689915974935, "compression_ratio": 1.6192660550458715, "no_speech_prob": 2.798013338178862e-05}, {"id": 148, "seek": 67692, "start": 676.92, "end": 681.64, "text": " And lastly, we have the system on the test where we have, for example, graph databases,", "tokens": [400, 16386, 11, 321, 362, 264, 1185, 322, 264, 1500, 689, 321, 362, 11, 337, 1365, 11, 4295, 22380, 11], "temperature": 0.0, "avg_logprob": -0.2021108865737915, "compression_ratio": 1.705179282868526, "no_speech_prob": 5.18191845912952e-05}, {"id": 149, "seek": 67692, "start": 681.64, "end": 684.12, "text": " triple stores or relational databases.", "tokens": [15508, 9512, 420, 38444, 22380, 13], "temperature": 0.0, "avg_logprob": -0.2021108865737915, "compression_ratio": 1.705179282868526, "no_speech_prob": 5.18191845912952e-05}, {"id": 150, "seek": 67692, "start": 684.12, "end": 687.92, "text": " And now Gabor will go further into the workloads.", "tokens": [400, 586, 460, 3816, 486, 352, 3052, 666, 264, 32452, 13], "temperature": 0.0, "avg_logprob": -0.2021108865737915, "compression_ratio": 1.705179282868526, "no_speech_prob": 5.18191845912952e-05}, {"id": 151, "seek": 67692, "start": 687.92, "end": 696.52, "text": " Okay, so graph workloads are actually quite diverse in terms of what they are trying to", "tokens": [1033, 11, 370, 4295, 32452, 366, 767, 1596, 9521, 294, 2115, 295, 437, 436, 366, 1382, 281], "temperature": 0.0, "avg_logprob": -0.2021108865737915, "compression_ratio": 1.705179282868526, "no_speech_prob": 5.18191845912952e-05}, {"id": 152, "seek": 67692, "start": 696.52, "end": 700.68, "text": " achieve, and our benchmark reflects that by having multiple workloads.", "tokens": [4584, 11, 293, 527, 18927, 18926, 300, 538, 1419, 3866, 32452, 13], "temperature": 0.0, "avg_logprob": -0.2021108865737915, "compression_ratio": 1.705179282868526, "no_speech_prob": 5.18191845912952e-05}, {"id": 153, "seek": 67692, "start": 700.68, "end": 705.5799999999999, "text": " We have the social network benchmark interactive workload, which is transactional in nature,", "tokens": [492, 362, 264, 2093, 3209, 18927, 15141, 20139, 11, 597, 307, 46688, 1966, 294, 3687, 11], "temperature": 0.0, "avg_logprob": -0.2021108865737915, "compression_ratio": 1.705179282868526, "no_speech_prob": 5.18191845912952e-05}, {"id": 154, "seek": 70558, "start": 705.58, "end": 707.72, "text": " so it has loads of concurrent operations.", "tokens": [370, 309, 575, 12668, 295, 37702, 7705, 13], "temperature": 0.0, "avg_logprob": -0.11093145772951458, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.0004123553226236254}, {"id": 155, "seek": 70558, "start": 707.72, "end": 712.9200000000001, "text": " The queries here are relatively simple, so they always start in one or two person nodes,", "tokens": [440, 24109, 510, 366, 7226, 2199, 11, 370, 436, 1009, 722, 294, 472, 420, 732, 954, 13891, 11], "temperature": 0.0, "avg_logprob": -0.11093145772951458, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.0004123553226236254}, {"id": 156, "seek": 70558, "start": 712.9200000000001, "end": 715.8000000000001, "text": " the same as David presented before.", "tokens": [264, 912, 382, 4389, 8212, 949, 13], "temperature": 0.0, "avg_logprob": -0.11093145772951458, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.0004123553226236254}, {"id": 157, "seek": 70558, "start": 715.8000000000001, "end": 720.0, "text": " And here the systems are striving to achieve a high throughput, so the competition is getting", "tokens": [400, 510, 264, 3652, 366, 36582, 281, 4584, 257, 1090, 44629, 11, 370, 264, 6211, 307, 1242], "temperature": 0.0, "avg_logprob": -0.11093145772951458, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.0004123553226236254}, {"id": 158, "seek": 70558, "start": 720.0, "end": 723.36, "text": " as many operations per second as possible.", "tokens": [382, 867, 7705, 680, 1150, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.11093145772951458, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.0004123553226236254}, {"id": 159, "seek": 70558, "start": 723.36, "end": 728.4000000000001, "text": " We are happy to report that we have official results from the last three years, where systems", "tokens": [492, 366, 2055, 281, 2275, 300, 321, 362, 4783, 3542, 490, 264, 1036, 1045, 924, 11, 689, 3652], "temperature": 0.0, "avg_logprob": -0.11093145772951458, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.0004123553226236254}, {"id": 160, "seek": 70558, "start": 728.4000000000001, "end": 733.5600000000001, "text": " started with slightly above 5,000 operations per second and have sped up exponentially,", "tokens": [1409, 365, 4748, 3673, 1025, 11, 1360, 7705, 680, 1150, 293, 362, 637, 292, 493, 37330, 11], "temperature": 0.0, "avg_logprob": -0.11093145772951458, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.0004123553226236254}, {"id": 161, "seek": 73356, "start": 733.56, "end": 739.5999999999999, "text": " now being close to 17,000 operations per second on a 100 gigabyte dataset.", "tokens": [586, 885, 1998, 281, 3282, 11, 1360, 7705, 680, 1150, 322, 257, 2319, 8741, 34529, 28872, 13], "temperature": 0.0, "avg_logprob": -0.09638016895183081, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0002365186664974317}, {"id": 162, "seek": 73356, "start": 739.5999999999999, "end": 743.28, "text": " The other workload of the social network benchmark is called business intelligence.", "tokens": [440, 661, 20139, 295, 264, 2093, 3209, 18927, 307, 1219, 1606, 7599, 13], "temperature": 0.0, "avg_logprob": -0.09638016895183081, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0002365186664974317}, {"id": 163, "seek": 73356, "start": 743.28, "end": 747.8, "text": " This is an analytical workload where the queries touch on large portions of the data.", "tokens": [639, 307, 364, 29579, 20139, 689, 264, 24109, 2557, 322, 2416, 25070, 295, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.09638016895183081, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0002365186664974317}, {"id": 164, "seek": 73356, "start": 747.8, "end": 753.4, "text": " For example, this query in this slide shows a case where we start from a given country", "tokens": [1171, 1365, 11, 341, 14581, 294, 341, 4137, 3110, 257, 1389, 689, 321, 722, 490, 257, 2212, 1941], "temperature": 0.0, "avg_logprob": -0.09638016895183081, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0002365186664974317}, {"id": 165, "seek": 73356, "start": 753.4, "end": 757.7199999999999, "text": " and then find all triangles of friendships in that country.", "tokens": [293, 550, 915, 439, 29896, 295, 30003, 294, 300, 1941, 13], "temperature": 0.0, "avg_logprob": -0.09638016895183081, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0002365186664974317}, {"id": 166, "seek": 73356, "start": 757.7199999999999, "end": 760.4, "text": " It's easy to see that this is a very heavy hitting operation.", "tokens": [467, 311, 1858, 281, 536, 300, 341, 307, 257, 588, 4676, 8850, 6916, 13], "temperature": 0.0, "avg_logprob": -0.09638016895183081, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0002365186664974317}, {"id": 167, "seek": 76040, "start": 760.4, "end": 765.36, "text": " It may touch on billions of edges in the graph, and it also has to do a complex computation", "tokens": [467, 815, 2557, 322, 17375, 295, 8819, 294, 264, 4295, 11, 293, 309, 611, 575, 281, 360, 257, 3997, 24903], "temperature": 0.0, "avg_logprob": -0.129789468896298, "compression_ratio": 1.6222910216718267, "no_speech_prob": 0.00022977583284955472}, {"id": 168, "seek": 76040, "start": 765.36, "end": 766.88, "text": " to find those people.", "tokens": [281, 915, 729, 561, 13], "temperature": 0.0, "avg_logprob": -0.129789468896298, "compression_ratio": 1.6222910216718267, "no_speech_prob": 0.00022977583284955472}, {"id": 169, "seek": 76040, "start": 766.88, "end": 772.24, "text": " So here system can use either a bulk update or a concurrent update method, and they should", "tokens": [407, 510, 1185, 393, 764, 2139, 257, 16139, 5623, 420, 257, 37702, 5623, 3170, 11, 293, 436, 820], "temperature": 0.0, "avg_logprob": -0.129789468896298, "compression_ratio": 1.6222910216718267, "no_speech_prob": 0.00022977583284955472}, {"id": 170, "seek": 76040, "start": 772.24, "end": 777.4, "text": " also strive to get both a high throughput and low query run times.", "tokens": [611, 23829, 281, 483, 1293, 257, 1090, 44629, 293, 2295, 14581, 1190, 1413, 13], "temperature": 0.0, "avg_logprob": -0.129789468896298, "compression_ratio": 1.6222910216718267, "no_speech_prob": 0.00022977583284955472}, {"id": 171, "seek": 76040, "start": 777.4, "end": 778.9599999999999, "text": " This benchmark is relatively new.", "tokens": [639, 18927, 307, 7226, 777, 13], "temperature": 0.0, "avg_logprob": -0.129789468896298, "compression_ratio": 1.6222910216718267, "no_speech_prob": 0.00022977583284955472}, {"id": 172, "seek": 76040, "start": 778.9599999999999, "end": 782.56, "text": " It was released at the end of last year, so we only have a single result, which was done", "tokens": [467, 390, 4736, 412, 264, 917, 295, 1036, 1064, 11, 370, 321, 787, 362, 257, 2167, 1874, 11, 597, 390, 1096], "temperature": 0.0, "avg_logprob": -0.129789468896298, "compression_ratio": 1.6222910216718267, "no_speech_prob": 0.00022977583284955472}, {"id": 173, "seek": 76040, "start": 782.56, "end": 785.04, "text": " by a collaboration of Tiger Graph and AMD.", "tokens": [538, 257, 9363, 295, 22025, 21884, 293, 34808, 13], "temperature": 0.0, "avg_logprob": -0.129789468896298, "compression_ratio": 1.6222910216718267, "no_speech_prob": 0.00022977583284955472}, {"id": 174, "seek": 76040, "start": 785.04, "end": 790.0799999999999, "text": " We're happy to report that there are more audits under way, so we are going to release", "tokens": [492, 434, 2055, 281, 2275, 300, 456, 366, 544, 2379, 1208, 833, 636, 11, 370, 321, 366, 516, 281, 4374], "temperature": 0.0, "avg_logprob": -0.129789468896298, "compression_ratio": 1.6222910216718267, "no_speech_prob": 0.00022977583284955472}, {"id": 175, "seek": 79008, "start": 790.08, "end": 793.6, "text": " more results in 2023.", "tokens": [544, 3542, 294, 44377, 13], "temperature": 0.0, "avg_logprob": -0.09529985445682133, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.00017227113130502403}, {"id": 176, "seek": 79008, "start": 793.6, "end": 798.08, "text": " So probably you can see from this presentation that these benchmarks can get fairly complex", "tokens": [407, 1391, 291, 393, 536, 490, 341, 5860, 300, 613, 43751, 393, 483, 6457, 3997], "temperature": 0.0, "avg_logprob": -0.09529985445682133, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.00017227113130502403}, {"id": 177, "seek": 79008, "start": 798.08, "end": 800.24, "text": " and implementing them is not trivial.", "tokens": [293, 18114, 552, 307, 406, 26703, 13], "temperature": 0.0, "avg_logprob": -0.09529985445682133, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.00017227113130502403}, {"id": 178, "seek": 79008, "start": 800.24, "end": 803.96, "text": " So we did our best to provide everything our users need.", "tokens": [407, 321, 630, 527, 1151, 281, 2893, 1203, 527, 5022, 643, 13], "temperature": 0.0, "avg_logprob": -0.09529985445682133, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.00017227113130502403}, {"id": 179, "seek": 79008, "start": 803.96, "end": 807.6800000000001, "text": " For each of the workloads that we have presented, we have a specification, we have detailed", "tokens": [1171, 1184, 295, 264, 32452, 300, 321, 362, 8212, 11, 321, 362, 257, 31256, 11, 321, 362, 9942], "temperature": 0.0, "avg_logprob": -0.09529985445682133, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.00017227113130502403}, {"id": 180, "seek": 79008, "start": 807.6800000000001, "end": 813.6800000000001, "text": " academic papers who motivate the design choices and the architecture of these benchmarks.", "tokens": [7778, 10577, 567, 28497, 264, 1715, 7994, 293, 264, 9482, 295, 613, 43751, 13], "temperature": 0.0, "avg_logprob": -0.09529985445682133, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.00017227113130502403}, {"id": 181, "seek": 79008, "start": 813.6800000000001, "end": 819.1600000000001, "text": " We released a data generator as well as pre-generated datasets, and we have benchmark drivers and", "tokens": [492, 4736, 257, 1412, 19265, 382, 731, 382, 659, 12, 21848, 770, 42856, 11, 293, 321, 362, 18927, 11590, 293], "temperature": 0.0, "avg_logprob": -0.09529985445682133, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.00017227113130502403}, {"id": 182, "seek": 81916, "start": 819.16, "end": 822.16, "text": " at least two reference implementations for each of the workloads.", "tokens": [412, 1935, 732, 6408, 4445, 763, 337, 1184, 295, 264, 32452, 13], "temperature": 0.0, "avg_logprob": -0.11942295674924497, "compression_ratio": 1.7148148148148148, "no_speech_prob": 6.2632403569296e-05}, {"id": 183, "seek": 81916, "start": 822.16, "end": 826.6, "text": " Moreover, we have guidelines on how to execute these benchmarks correctly, how to validate", "tokens": [19838, 11, 321, 362, 12470, 322, 577, 281, 14483, 613, 43751, 8944, 11, 577, 281, 29562], "temperature": 0.0, "avg_logprob": -0.11942295674924497, "compression_ratio": 1.7148148148148148, "no_speech_prob": 6.2632403569296e-05}, {"id": 184, "seek": 81916, "start": 826.6, "end": 831.3199999999999, "text": " the results of a given system, and how to ensure that the system will lose your data", "tokens": [264, 3542, 295, 257, 2212, 1185, 11, 293, 577, 281, 5586, 300, 264, 1185, 486, 3624, 428, 1412], "temperature": 0.0, "avg_logprob": -0.11942295674924497, "compression_ratio": 1.7148148148148148, "no_speech_prob": 6.2632403569296e-05}, {"id": 185, "seek": 81916, "start": 831.3199999999999, "end": 834.24, "text": " or mingle up the transactions.", "tokens": [420, 275, 26209, 493, 264, 16856, 13], "temperature": 0.0, "avg_logprob": -0.11942295674924497, "compression_ratio": 1.7148148148148148, "no_speech_prob": 6.2632403569296e-05}, {"id": 186, "seek": 81916, "start": 834.24, "end": 838.68, "text": " So we have asset compliance tests and recovery tests.", "tokens": [407, 321, 362, 11999, 15882, 6921, 293, 8597, 6921, 13], "temperature": 0.0, "avg_logprob": -0.11942295674924497, "compression_ratio": 1.7148148148148148, "no_speech_prob": 6.2632403569296e-05}, {"id": 187, "seek": 81916, "start": 838.68, "end": 840.92, "text": " This leads us to our auditing process.", "tokens": [639, 6689, 505, 281, 527, 2379, 1748, 1399, 13], "temperature": 0.0, "avg_logprob": -0.11942295674924497, "compression_ratio": 1.7148148148148148, "no_speech_prob": 6.2632403569296e-05}, {"id": 188, "seek": 81916, "start": 840.92, "end": 845.76, "text": " Similarly to the TPC, the Transaction Processing Performance Council, we have a rigorous auditing", "tokens": [13157, 281, 264, 314, 12986, 11, 264, 6531, 2894, 31093, 278, 25047, 7076, 11, 321, 362, 257, 29882, 2379, 1748], "temperature": 0.0, "avg_logprob": -0.11942295674924497, "compression_ratio": 1.7148148148148148, "no_speech_prob": 6.2632403569296e-05}, {"id": 189, "seek": 84576, "start": 845.76, "end": 851.84, "text": " process where vendors can commission an independent third party who will rerun the benchmark in", "tokens": [1399, 689, 22056, 393, 9221, 364, 6695, 2636, 3595, 567, 486, 43819, 409, 264, 18927, 294], "temperature": 0.0, "avg_logprob": -0.08392680628915851, "compression_ratio": 1.6833333333333333, "no_speech_prob": 0.00030207150848582387}, {"id": 190, "seek": 84576, "start": 851.84, "end": 857.68, "text": " an executable and reproducible manner, and they will write up it as a full disclosure", "tokens": [364, 7568, 712, 293, 11408, 32128, 9060, 11, 293, 436, 486, 2464, 493, 309, 382, 257, 1577, 30392], "temperature": 0.0, "avg_logprob": -0.08392680628915851, "compression_ratio": 1.6833333333333333, "no_speech_prob": 0.00030207150848582387}, {"id": 191, "seek": 84576, "start": 857.68, "end": 863.56, "text": " report so that the benchmark is understandable by whoever wants to see that result.", "tokens": [2275, 370, 300, 264, 18927, 307, 25648, 538, 11387, 2738, 281, 536, 300, 1874, 13], "temperature": 0.0, "avg_logprob": -0.08392680628915851, "compression_ratio": 1.6833333333333333, "no_speech_prob": 0.00030207150848582387}, {"id": 192, "seek": 84576, "start": 863.56, "end": 869.0, "text": " This is important because LDBC is trademarked worldwide, and we only allow official audited", "tokens": [639, 307, 1021, 570, 33936, 7869, 307, 31361, 292, 13485, 11, 293, 321, 787, 2089, 4783, 2379, 1226], "temperature": 0.0, "avg_logprob": -0.08392680628915851, "compression_ratio": 1.6833333333333333, "no_speech_prob": 0.00030207150848582387}, {"id": 193, "seek": 84576, "start": 869.0, "end": 872.4399999999999, "text": " results to use the term LDBC benchmark result.", "tokens": [3542, 281, 764, 264, 1433, 33936, 7869, 18927, 1874, 13], "temperature": 0.0, "avg_logprob": -0.08392680628915851, "compression_ratio": 1.6833333333333333, "no_speech_prob": 0.00030207150848582387}, {"id": 194, "seek": 87244, "start": 872.44, "end": 875.96, "text": " This is not to say that we don't allow people to use this benchmark.", "tokens": [639, 307, 406, 281, 584, 300, 321, 500, 380, 2089, 561, 281, 764, 341, 18927, 13], "temperature": 0.0, "avg_logprob": -0.12414005452936346, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.00010992247553076595}, {"id": 195, "seek": 87244, "start": 875.96, "end": 880.44, "text": " Researchers, practitioners, and developers are welcome to use the benchmark.", "tokens": [43555, 11, 25742, 11, 293, 8849, 366, 2928, 281, 764, 264, 18927, 13], "temperature": 0.0, "avg_logprob": -0.12414005452936346, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.00010992247553076595}, {"id": 196, "seek": 87244, "start": 880.44, "end": 881.44, "text": " They can run it.", "tokens": [814, 393, 1190, 309, 13], "temperature": 0.0, "avg_logprob": -0.12414005452936346, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.00010992247553076595}, {"id": 197, "seek": 87244, "start": 881.44, "end": 885.6400000000001, "text": " They can report the results if it is accompanied by the appropriate disclaimer that this is", "tokens": [814, 393, 2275, 264, 3542, 498, 309, 307, 24202, 538, 264, 6854, 40896, 300, 341, 307], "temperature": 0.0, "avg_logprob": -0.12414005452936346, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.00010992247553076595}, {"id": 198, "seek": 87244, "start": 885.6400000000001, "end": 889.8000000000001, "text": " not an official LDBC benchmark result.", "tokens": [406, 364, 4783, 33936, 7869, 18927, 1874, 13], "temperature": 0.0, "avg_logprob": -0.12414005452936346, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.00010992247553076595}, {"id": 199, "seek": 87244, "start": 889.8000000000001, "end": 893.48, "text": " I would like to talk a bit about standard GraphQL languages.", "tokens": [286, 576, 411, 281, 751, 257, 857, 466, 3832, 21884, 13695, 8650, 13], "temperature": 0.0, "avg_logprob": -0.12414005452936346, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.00010992247553076595}, {"id": 200, "seek": 87244, "start": 893.48, "end": 897.5600000000001, "text": " This is an important topic because this has been a pain point for GraphSystems for many", "tokens": [639, 307, 364, 1021, 4829, 570, 341, 575, 668, 257, 1822, 935, 337, 21884, 50, 9321, 82, 337, 867], "temperature": 0.0, "avg_logprob": -0.12414005452936346, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.00010992247553076595}, {"id": 201, "seek": 87244, "start": 897.5600000000001, "end": 898.5600000000001, "text": " years.", "tokens": [924, 13], "temperature": 0.0, "avg_logprob": -0.12414005452936346, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.00010992247553076595}, {"id": 202, "seek": 89856, "start": 898.56, "end": 903.0799999999999, "text": " There is a bit of a tower of Babel out there with many languages, both of them using some", "tokens": [821, 307, 257, 857, 295, 257, 10567, 295, 15820, 338, 484, 456, 365, 867, 8650, 11, 1293, 295, 552, 1228, 512], "temperature": 0.0, "avg_logprob": -0.15462969918536323, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0001899639901239425}, {"id": 203, "seek": 89856, "start": 903.0799999999999, "end": 907.2399999999999, "text": " sort of visual graph syntax, but always with slightly different semantics and a slightly", "tokens": [1333, 295, 5056, 4295, 28431, 11, 457, 1009, 365, 4748, 819, 4361, 45298, 293, 257, 4748], "temperature": 0.0, "avg_logprob": -0.15462969918536323, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0001899639901239425}, {"id": 204, "seek": 89856, "start": 907.2399999999999, "end": 912.5999999999999, "text": " different syntax, which makes it difficult for users to adopt these techniques and may", "tokens": [819, 28431, 11, 597, 1669, 309, 2252, 337, 5022, 281, 6878, 613, 7512, 293, 815], "temperature": 0.0, "avg_logprob": -0.15462969918536323, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0001899639901239425}, {"id": 205, "seek": 89856, "start": 912.5999999999999, "end": 916.8399999999999, "text": " put them in a position of being locked in by their vendors.", "tokens": [829, 552, 294, 257, 2535, 295, 885, 9376, 294, 538, 641, 22056, 13], "temperature": 0.0, "avg_logprob": -0.15462969918536323, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0001899639901239425}, {"id": 206, "seek": 89856, "start": 916.8399999999999, "end": 921.4799999999999, "text": " In the next couple of years, there are going to be new standard queer languages.", "tokens": [682, 264, 958, 1916, 295, 924, 11, 456, 366, 516, 281, 312, 777, 3832, 20323, 8650, 13], "temperature": 0.0, "avg_logprob": -0.15462969918536323, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0001899639901239425}, {"id": 207, "seek": 89856, "start": 921.4799999999999, "end": 924.92, "text": " These focus on pathfinding and pattern matching.", "tokens": [1981, 1879, 322, 3100, 69, 9245, 293, 5102, 14324, 13], "temperature": 0.0, "avg_logprob": -0.15462969918536323, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0001899639901239425}, {"id": 208, "seek": 89856, "start": 924.92, "end": 926.8399999999999, "text": " The first one is called SQL PGQ.", "tokens": [440, 700, 472, 307, 1219, 19200, 40975, 48, 13], "temperature": 0.0, "avg_logprob": -0.15462969918536323, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0001899639901239425}, {"id": 209, "seek": 92684, "start": 926.84, "end": 931.44, "text": " This is an extension to the SQL language and PGQ stands for property graph queries.", "tokens": [639, 307, 364, 10320, 281, 264, 19200, 2856, 293, 40975, 48, 7382, 337, 4707, 4295, 24109, 13], "temperature": 0.0, "avg_logprob": -0.12686836172681337, "compression_ratio": 1.68359375, "no_speech_prob": 0.00014364381786435843}, {"id": 210, "seek": 92684, "start": 931.44, "end": 936.6, "text": " This is going to be released next summer, and GQL, the standalone GraphQL language,", "tokens": [639, 307, 516, 281, 312, 4736, 958, 4266, 11, 293, 460, 13695, 11, 264, 37454, 21884, 13695, 2856, 11], "temperature": 0.0, "avg_logprob": -0.12686836172681337, "compression_ratio": 1.68359375, "no_speech_prob": 0.00014364381786435843}, {"id": 211, "seek": 92684, "start": 936.6, "end": 939.36, "text": " is going to come out in 2024.", "tokens": [307, 516, 281, 808, 484, 294, 45237, 13], "temperature": 0.0, "avg_logprob": -0.12686836172681337, "compression_ratio": 1.68359375, "no_speech_prob": 0.00014364381786435843}, {"id": 212, "seek": 92684, "start": 939.36, "end": 943.6800000000001, "text": " We are happy to report that even though we have two new languages, the pattern matching", "tokens": [492, 366, 2055, 281, 2275, 300, 754, 1673, 321, 362, 732, 777, 8650, 11, 264, 5102, 14324], "temperature": 0.0, "avg_logprob": -0.12686836172681337, "compression_ratio": 1.68359375, "no_speech_prob": 0.00014364381786435843}, {"id": 213, "seek": 92684, "start": 943.6800000000001, "end": 948.9200000000001, "text": " core of them, the visual graph syntax that we all know and love, is going to be the same,", "tokens": [4965, 295, 552, 11, 264, 5056, 4295, 28431, 300, 321, 439, 458, 293, 959, 11, 307, 516, 281, 312, 264, 912, 11], "temperature": 0.0, "avg_logprob": -0.12686836172681337, "compression_ratio": 1.68359375, "no_speech_prob": 0.00014364381786435843}, {"id": 214, "seek": 92684, "start": 948.9200000000001, "end": 952.84, "text": " so users can port at least those bits of their queries.", "tokens": [370, 5022, 393, 2436, 412, 1935, 729, 9239, 295, 641, 24109, 13], "temperature": 0.0, "avg_logprob": -0.12686836172681337, "compression_ratio": 1.68359375, "no_speech_prob": 0.00014364381786435843}, {"id": 215, "seek": 95284, "start": 952.84, "end": 957.24, "text": " To give you a taste of how this will look like, here is query 9 that David presented", "tokens": [1407, 976, 291, 257, 3939, 295, 577, 341, 486, 574, 411, 11, 510, 307, 14581, 1722, 300, 4389, 8212], "temperature": 0.0, "avg_logprob": -0.1247283591598761, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.00011041674588341266}, {"id": 216, "seek": 95284, "start": 957.24, "end": 960.5600000000001, "text": " in the social network benchmark interactive workload.", "tokens": [294, 264, 2093, 3209, 18927, 15141, 20139, 13], "temperature": 0.0, "avg_logprob": -0.1247283591598761, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.00011041674588341266}, {"id": 217, "seek": 95284, "start": 960.5600000000001, "end": 962.52, "text": " This query can be formulated in SQL.", "tokens": [639, 14581, 393, 312, 48936, 294, 19200, 13], "temperature": 0.0, "avg_logprob": -0.1247283591598761, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.00011041674588341266}, {"id": 218, "seek": 95284, "start": 962.52, "end": 968.2800000000001, "text": " It's not too difficult, but the new variants, SQL PGQ and GQL, can represent it as terms", "tokens": [467, 311, 406, 886, 2252, 11, 457, 264, 777, 21669, 11, 19200, 40975, 48, 293, 460, 13695, 11, 393, 2906, 309, 382, 2115], "temperature": 0.0, "avg_logprob": -0.1247283591598761, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.00011041674588341266}, {"id": 219, "seek": 95284, "start": 968.2800000000001, "end": 972.9200000000001, "text": " of a graph pattern, and this is a much more concise formulation.", "tokens": [295, 257, 4295, 5102, 11, 293, 341, 307, 257, 709, 544, 44882, 37642, 13], "temperature": 0.0, "avg_logprob": -0.1247283591598761, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.00011041674588341266}, {"id": 220, "seek": 95284, "start": 972.9200000000001, "end": 976.9200000000001, "text": " The difference is even more pronounced for query 13 with the path queries.", "tokens": [440, 2649, 307, 754, 544, 23155, 337, 14581, 3705, 365, 264, 3100, 24109, 13], "temperature": 0.0, "avg_logprob": -0.1247283591598761, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.00011041674588341266}, {"id": 221, "seek": 95284, "start": 976.9200000000001, "end": 982.24, "text": " Here we can see that in SQL PGQ, the pattern is really similar to the visual representation.", "tokens": [1692, 321, 393, 536, 300, 294, 19200, 40975, 48, 11, 264, 5102, 307, 534, 2531, 281, 264, 5056, 10290, 13], "temperature": 0.0, "avg_logprob": -0.1247283591598761, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.00011041674588341266}, {"id": 222, "seek": 98224, "start": 982.24, "end": 988.64, "text": " It just has a source, a target, and an arbitrary amount of nose edges denoted by nose asterisk", "tokens": [467, 445, 575, 257, 4009, 11, 257, 3779, 11, 293, 364, 23211, 2372, 295, 6690, 8819, 1441, 23325, 538, 6690, 257, 3120, 7797], "temperature": 0.0, "avg_logprob": -0.1335584584949086, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00016566897102165967}, {"id": 223, "seek": 98224, "start": 988.64, "end": 989.84, "text": " in between.", "tokens": [294, 1296, 13], "temperature": 0.0, "avg_logprob": -0.1335584584949086, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00016566897102165967}, {"id": 224, "seek": 98224, "start": 989.84, "end": 995.04, "text": " In SQL, this is a lot less readable, hard to maintain, and it's even less sufficient", "tokens": [682, 19200, 11, 341, 307, 257, 688, 1570, 49857, 11, 1152, 281, 6909, 11, 293, 309, 311, 754, 1570, 11563], "temperature": 0.0, "avg_logprob": -0.1335584584949086, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00016566897102165967}, {"id": 225, "seek": 98224, "start": 995.04, "end": 999.4, "text": " because it just implements a unidirectional search algorithm instead of doing a bidirectional", "tokens": [570, 309, 445, 704, 17988, 257, 517, 327, 621, 41048, 3164, 9284, 2602, 295, 884, 257, 12957, 621, 41048], "temperature": 0.0, "avg_logprob": -0.1335584584949086, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00016566897102165967}, {"id": 226, "seek": 98224, "start": 999.4, "end": 1002.84, "text": " search which has a better algorithmic complexity.", "tokens": [3164, 597, 575, 257, 1101, 9284, 299, 14024, 13], "temperature": 0.0, "avg_logprob": -0.1335584584949086, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00016566897102165967}, {"id": 227, "seek": 98224, "start": 1002.84, "end": 1006.44, "text": " The way LDBC is involved in these new query languages is manifold.", "tokens": [440, 636, 441, 35, 7869, 307, 3288, 294, 613, 777, 14581, 8650, 307, 47138, 13], "temperature": 0.0, "avg_logprob": -0.1335584584949086, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00016566897102165967}, {"id": 228, "seek": 100644, "start": 1006.44, "end": 1012.6400000000001, "text": " First, it had the G-core design language released in 2018 which influenced these benchmarks.", "tokens": [2386, 11, 309, 632, 264, 460, 12, 12352, 1715, 2856, 4736, 294, 6096, 597, 15269, 613, 43751, 13], "temperature": 0.0, "avg_logprob": -0.12913950207163988, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.00014975585509091616}, {"id": 229, "seek": 100644, "start": 1012.6400000000001, "end": 1016.6800000000001, "text": " Then LDBC has the formal semantics working group which formalized the pattern matching", "tokens": [1396, 441, 35, 7869, 575, 264, 9860, 4361, 45298, 1364, 1594, 597, 9860, 1602, 264, 5102, 14324], "temperature": 0.0, "avg_logprob": -0.12913950207163988, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.00014975585509091616}, {"id": 230, "seek": 100644, "start": 1016.6800000000001, "end": 1024.0, "text": " core of these new languages, and LDBC is doing further research to advance the state", "tokens": [4965, 295, 613, 777, 8650, 11, 293, 441, 35, 7869, 307, 884, 3052, 2132, 281, 7295, 264, 1785], "temperature": 0.0, "avg_logprob": -0.12913950207163988, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.00014975585509091616}, {"id": 231, "seek": 100644, "start": 1024.0, "end": 1025.72, "text": " of the art on graph schemas.", "tokens": [295, 264, 1523, 322, 4295, 22627, 296, 13], "temperature": 0.0, "avg_logprob": -0.12913950207163988, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.00014975585509091616}, {"id": 232, "seek": 100644, "start": 1025.72, "end": 1030.56, "text": " We have an industry-driven and a theory-driven group, and what they do will end up in the", "tokens": [492, 362, 364, 3518, 12, 25456, 293, 257, 5261, 12, 25456, 1594, 11, 293, 437, 436, 360, 486, 917, 493, 294, 264], "temperature": 0.0, "avg_logprob": -0.12913950207163988, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.00014975585509091616}, {"id": 233, "seek": 100644, "start": 1030.56, "end": 1033.6000000000001, "text": " new versions of these languages.", "tokens": [777, 9606, 295, 613, 8650, 13], "temperature": 0.0, "avg_logprob": -0.12913950207163988, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.00014975585509091616}, {"id": 234, "seek": 103360, "start": 1033.6, "end": 1036.6, "text": " The outlook is the LDBC Graphalytics benchmark.", "tokens": [440, 26650, 307, 264, 441, 35, 7869, 21884, 304, 4328, 1167, 18927, 13], "temperature": 0.0, "avg_logprob": -0.1960564441368228, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.00021500910224858671}, {"id": 235, "seek": 103360, "start": 1036.6, "end": 1043.6399999999999, "text": " This is a more wide benchmark because it can target analytical libraries like NetworkX,", "tokens": [639, 307, 257, 544, 4874, 18927, 570, 309, 393, 3779, 29579, 15148, 411, 12640, 55, 11], "temperature": 0.0, "avg_logprob": -0.1960564441368228, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.00021500910224858671}, {"id": 236, "seek": 103360, "start": 1043.6399999999999, "end": 1047.28, "text": " distributed systems like Apache Giraffe, or the GraphBlast API.", "tokens": [12631, 3652, 411, 46597, 36306, 23629, 11, 420, 264, 21884, 14520, 525, 9362, 13], "temperature": 0.0, "avg_logprob": -0.1960564441368228, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.00021500910224858671}, {"id": 237, "seek": 103360, "start": 1047.28, "end": 1051.12, "text": " This is everything that has to do with analyzing large graphs.", "tokens": [639, 307, 1203, 300, 575, 281, 360, 365, 23663, 2416, 24877, 13], "temperature": 0.0, "avg_logprob": -0.1960564441368228, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.00021500910224858671}, {"id": 238, "seek": 103360, "start": 1051.12, "end": 1056.56, "text": " Here the graph is an untyped, unattributed graph, so there are no properties or no labels.", "tokens": [1692, 264, 4295, 307, 364, 517, 874, 3452, 11, 47316, 2024, 4866, 4295, 11, 370, 456, 366, 572, 7221, 420, 572, 16949, 13], "temperature": 0.0, "avg_logprob": -0.1960564441368228, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.00021500910224858671}, {"id": 239, "seek": 103360, "start": 1056.56, "end": 1062.04, "text": " We do use the LDBC social network benchmark dataset, but it is stripped down to the person-nose-person", "tokens": [492, 360, 764, 264, 441, 35, 7869, 2093, 3209, 18927, 28872, 11, 457, 309, 307, 33221, 760, 281, 264, 954, 12, 77, 541, 12, 10813], "temperature": 0.0, "avg_logprob": -0.1960564441368228, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.00021500910224858671}, {"id": 240, "seek": 103360, "start": 1062.04, "end": 1063.04, "text": " core graph.", "tokens": [4965, 4295, 13], "temperature": 0.0, "avg_logprob": -0.1960564441368228, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.00021500910224858671}, {"id": 241, "seek": 106304, "start": 1063.04, "end": 1068.68, "text": " Additionally, we have included a number of well-known datasets like Graph500, Twitter,", "tokens": [19927, 11, 321, 362, 5556, 257, 1230, 295, 731, 12, 6861, 42856, 411, 21884, 7526, 11, 5794, 11], "temperature": 0.0, "avg_logprob": -0.12154124987007368, "compression_ratio": 1.651639344262295, "no_speech_prob": 0.00019227387383580208}, {"id": 242, "seek": 106304, "start": 1068.68, "end": 1069.68, "text": " and so on.", "tokens": [293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.12154124987007368, "compression_ratio": 1.651639344262295, "no_speech_prob": 0.00019227387383580208}, {"id": 243, "seek": 106304, "start": 1069.68, "end": 1073.28, "text": " The algorithms that we run are mostly well-known graph algorithms.", "tokens": [440, 14642, 300, 321, 1190, 366, 5240, 731, 12, 6861, 4295, 14642, 13], "temperature": 0.0, "avg_logprob": -0.12154124987007368, "compression_ratio": 1.651639344262295, "no_speech_prob": 0.00019227387383580208}, {"id": 244, "seek": 106304, "start": 1073.28, "end": 1078.96, "text": " There is the BFS, which starts from a given node and assigns the number of steps that", "tokens": [821, 307, 264, 363, 29318, 11, 597, 3719, 490, 257, 2212, 9984, 293, 6269, 82, 264, 1230, 295, 4439, 300], "temperature": 0.0, "avg_logprob": -0.12154124987007368, "compression_ratio": 1.651639344262295, "no_speech_prob": 0.00019227387383580208}, {"id": 245, "seek": 106304, "start": 1078.96, "end": 1082.32, "text": " need to be taken to all of the other nodes to reach them.", "tokens": [643, 281, 312, 2726, 281, 439, 295, 264, 661, 13891, 281, 2524, 552, 13], "temperature": 0.0, "avg_logprob": -0.12154124987007368, "compression_ratio": 1.651639344262295, "no_speech_prob": 0.00019227387383580208}, {"id": 246, "seek": 106304, "start": 1082.32, "end": 1086.8, "text": " We have the famous PageRank centrality algorithm, which highlights the most important nodes in", "tokens": [492, 362, 264, 4618, 21217, 49, 657, 32199, 1860, 9284, 11, 597, 14254, 264, 881, 1021, 13891, 294], "temperature": 0.0, "avg_logprob": -0.12154124987007368, "compression_ratio": 1.651639344262295, "no_speech_prob": 0.00019227387383580208}, {"id": 247, "seek": 108680, "start": 1086.8, "end": 1093.48, "text": " the network, and we have the local clustering coefficient, community detection using label", "tokens": [264, 3209, 11, 293, 321, 362, 264, 2654, 596, 48673, 17619, 11, 1768, 17784, 1228, 7645], "temperature": 0.0, "avg_logprob": -0.12229359478031823, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.00015282700769603252}, {"id": 248, "seek": 108680, "start": 1093.48, "end": 1097.72, "text": " propagation, weakly connected components, and shortest paths.", "tokens": [38377, 11, 5336, 356, 4582, 6677, 11, 293, 31875, 14518, 13], "temperature": 0.0, "avg_logprob": -0.12229359478031823, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.00015282700769603252}, {"id": 249, "seek": 108680, "start": 1097.72, "end": 1100.8, "text": " This benchmark is a bit simpler than the social network benchmark.", "tokens": [639, 18927, 307, 257, 857, 18587, 813, 264, 2093, 3209, 18927, 13], "temperature": 0.0, "avg_logprob": -0.12229359478031823, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.00015282700769603252}, {"id": 250, "seek": 108680, "start": 1100.8, "end": 1103.6, "text": " It does not have a rigorous auditing process.", "tokens": [467, 775, 406, 362, 257, 29882, 2379, 1748, 1399, 13], "temperature": 0.0, "avg_logprob": -0.12229359478031823, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.00015282700769603252}, {"id": 251, "seek": 108680, "start": 1103.6, "end": 1109.04, "text": " We trust people that they can run this benchmark efficiently and correctly on their own infrastructure,", "tokens": [492, 3361, 561, 300, 436, 393, 1190, 341, 18927, 19621, 293, 8944, 322, 641, 1065, 6896, 11], "temperature": 0.0, "avg_logprob": -0.12229359478031823, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.00015282700769603252}, {"id": 252, "seek": 108680, "start": 1109.04, "end": 1110.8, "text": " and they can report results.", "tokens": [293, 436, 393, 2275, 3542, 13], "temperature": 0.0, "avg_logprob": -0.12229359478031823, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.00015282700769603252}, {"id": 253, "seek": 108680, "start": 1110.8, "end": 1115.04, "text": " If they do so, they will be able to participate in the Graphalytics competition, which has", "tokens": [759, 436, 360, 370, 11, 436, 486, 312, 1075, 281, 8197, 294, 264, 21884, 304, 4328, 1167, 6211, 11, 597, 575], "temperature": 0.0, "avg_logprob": -0.12229359478031823, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.00015282700769603252}, {"id": 254, "seek": 111504, "start": 1115.04, "end": 1118.84, "text": " a leaderboard for the best implementations.", "tokens": [257, 5263, 3787, 337, 264, 1151, 4445, 763, 13], "temperature": 0.0, "avg_logprob": -0.15707249507725796, "compression_ratio": 1.5441176470588236, "no_speech_prob": 7.734197424724698e-05}, {"id": 255, "seek": 111504, "start": 1118.84, "end": 1124.1599999999999, "text": " Wrapping up, you should consider joining the IDBC because members can participate in the", "tokens": [343, 424, 3759, 493, 11, 291, 820, 1949, 5549, 264, 7348, 7869, 570, 2679, 393, 8197, 294, 264], "temperature": 0.0, "avg_logprob": -0.15707249507725796, "compression_ratio": 1.5441176470588236, "no_speech_prob": 7.734197424724698e-05}, {"id": 256, "seek": 111504, "start": 1124.1599999999999, "end": 1125.1599999999999, "text": " benchmark design.", "tokens": [18927, 1715, 13], "temperature": 0.0, "avg_logprob": -0.15707249507725796, "compression_ratio": 1.5441176470588236, "no_speech_prob": 7.734197424724698e-05}, {"id": 257, "seek": 111504, "start": 1125.1599999999999, "end": 1129.08, "text": " They have a say in where we are going in terms of including new features.", "tokens": [814, 362, 257, 584, 294, 689, 321, 366, 516, 294, 2115, 295, 3009, 777, 4122, 13], "temperature": 0.0, "avg_logprob": -0.15707249507725796, "compression_ratio": 1.5441176470588236, "no_speech_prob": 7.734197424724698e-05}, {"id": 258, "seek": 111504, "start": 1129.08, "end": 1135.04, "text": " They can commission audits if they are vendors, and members can gain access to these ISO standard", "tokens": [814, 393, 9221, 2379, 1208, 498, 436, 366, 22056, 11, 293, 2679, 393, 6052, 2105, 281, 613, 25042, 3832], "temperature": 0.0, "avg_logprob": -0.15707249507725796, "compression_ratio": 1.5441176470588236, "no_speech_prob": 7.734197424724698e-05}, {"id": 259, "seek": 111504, "start": 1135.04, "end": 1138.0, "text": " drafts that I mentioned, SQL, PGQ, and GQR.", "tokens": [11206, 82, 300, 286, 2835, 11, 19200, 11, 40975, 48, 11, 293, 460, 48, 49, 13], "temperature": 0.0, "avg_logprob": -0.15707249507725796, "compression_ratio": 1.5441176470588236, "no_speech_prob": 7.734197424724698e-05}, {"id": 260, "seek": 111504, "start": 1138.0, "end": 1141.56, "text": " Otherwise, these are not available to general public.", "tokens": [10328, 11, 613, 366, 406, 2435, 281, 2674, 1908, 13], "temperature": 0.0, "avg_logprob": -0.15707249507725796, "compression_ratio": 1.5441176470588236, "no_speech_prob": 7.734197424724698e-05}, {"id": 261, "seek": 114156, "start": 1141.56, "end": 1146.44, "text": " Being wise, this is free for individuals, and there is a yearly fee for companies.", "tokens": [8891, 10829, 11, 341, 307, 1737, 337, 5346, 11, 293, 456, 307, 257, 39102, 12054, 337, 3431, 13], "temperature": 0.0, "avg_logprob": -0.14942704646959218, "compression_ratio": 1.8395522388059702, "no_speech_prob": 0.0001831964182201773}, {"id": 262, "seek": 114156, "start": 1146.44, "end": 1150.52, "text": " To sum up, we have presented three benchmarks, the social network benchmark's interactive", "tokens": [1407, 2408, 493, 11, 321, 362, 8212, 1045, 43751, 11, 264, 2093, 3209, 18927, 311, 15141], "temperature": 0.0, "avg_logprob": -0.14942704646959218, "compression_ratio": 1.8395522388059702, "no_speech_prob": 0.0001831964182201773}, {"id": 263, "seek": 114156, "start": 1150.52, "end": 1155.76, "text": " workload, its business intelligence workload, and the Graphalytics graph algorithms workload.", "tokens": [20139, 11, 1080, 1606, 7599, 20139, 11, 293, 264, 21884, 304, 4328, 1167, 4295, 14642, 20139, 13], "temperature": 0.0, "avg_logprob": -0.14942704646959218, "compression_ratio": 1.8395522388059702, "no_speech_prob": 0.0001831964182201773}, {"id": 264, "seek": 114156, "start": 1155.76, "end": 1156.76, "text": " We have more benchmarks.", "tokens": [492, 362, 544, 43751, 13], "temperature": 0.0, "avg_logprob": -0.14942704646959218, "compression_ratio": 1.8395522388059702, "no_speech_prob": 0.0001831964182201773}, {"id": 265, "seek": 114156, "start": 1156.76, "end": 1162.72, "text": " There is semantic publishing benchmark, which is targeting RDF systems set in the media", "tokens": [821, 307, 47982, 17832, 18927, 11, 597, 307, 17918, 49488, 37, 3652, 992, 294, 264, 3021], "temperature": 0.0, "avg_logprob": -0.14942704646959218, "compression_ratio": 1.8395522388059702, "no_speech_prob": 0.0001831964182201773}, {"id": 266, "seek": 114156, "start": 1162.72, "end": 1164.48, "text": " and publishing industry.", "tokens": [293, 17832, 3518, 13], "temperature": 0.0, "avg_logprob": -0.14942704646959218, "compression_ratio": 1.8395522388059702, "no_speech_prob": 0.0001831964182201773}, {"id": 267, "seek": 114156, "start": 1164.48, "end": 1167.8799999999999, "text": " There is the financial benchmark, which is going to be released this year, which targets", "tokens": [821, 307, 264, 4669, 18927, 11, 597, 307, 516, 281, 312, 4736, 341, 1064, 11, 597, 12911], "temperature": 0.0, "avg_logprob": -0.14942704646959218, "compression_ratio": 1.8395522388059702, "no_speech_prob": 0.0001831964182201773}, {"id": 268, "seek": 116788, "start": 1167.88, "end": 1174.16, "text": " distributed systems, and it uses the financial fraud detection domain as its area, and it", "tokens": [12631, 3652, 11, 293, 309, 4960, 264, 4669, 14560, 17784, 9274, 382, 1080, 1859, 11, 293, 309], "temperature": 0.0, "avg_logprob": -0.1700748042056435, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00023742771008983254}, {"id": 269, "seek": 116788, "start": 1174.16, "end": 1176.8000000000002, "text": " imposes strict latency bounds on queries.", "tokens": [704, 4201, 10910, 27043, 29905, 322, 24109, 13], "temperature": 0.0, "avg_logprob": -0.1700748042056435, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00023742771008983254}, {"id": 270, "seek": 116788, "start": 1176.8000000000002, "end": 1179.88, "text": " This is quite a different workload from the previous ones.", "tokens": [639, 307, 1596, 257, 819, 20139, 490, 264, 3894, 2306, 13], "temperature": 0.0, "avg_logprob": -0.1700748042056435, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00023742771008983254}, {"id": 271, "seek": 116788, "start": 1179.88, "end": 1184.44, "text": " Of course, graphs are ubiquitous, and they have loads of use cases, so there are many", "tokens": [2720, 1164, 11, 24877, 366, 43868, 39831, 11, 293, 436, 362, 12668, 295, 764, 3331, 11, 370, 456, 366, 867], "temperature": 0.0, "avg_logprob": -0.1700748042056435, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00023742771008983254}, {"id": 272, "seek": 116788, "start": 1184.44, "end": 1189.0400000000002, "text": " future benchmark ideas, including graph neural network mining and streaming.", "tokens": [2027, 18927, 3487, 11, 3009, 4295, 18161, 3209, 15512, 293, 11791, 13], "temperature": 0.0, "avg_logprob": -0.1700748042056435, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00023742771008983254}, {"id": 273, "seek": 116788, "start": 1189.0400000000002, "end": 1191.0800000000002, "text": " Thank you very much, and we're open to any questions.", "tokens": [1044, 291, 588, 709, 11, 293, 321, 434, 1269, 281, 604, 1651, 13], "temperature": 0.0, "avg_logprob": -0.1700748042056435, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00023742771008983254}, {"id": 274, "seek": 119108, "start": 1191.08, "end": 1198.08, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.3666613163092198, "compression_ratio": 1.7109826589595376, "no_speech_prob": 9.734809282235801e-05}, {"id": 275, "seek": 119108, "start": 1198.08, "end": 1204.56, "text": " So, in this one overview that was the graph data set, and the updates were kind of separated.", "tokens": [407, 11, 294, 341, 472, 12492, 300, 390, 264, 4295, 1412, 992, 11, 293, 264, 9205, 645, 733, 295, 12005, 13], "temperature": 0.0, "avg_logprob": -0.3666613163092198, "compression_ratio": 1.7109826589595376, "no_speech_prob": 9.734809282235801e-05}, {"id": 276, "seek": 119108, "start": 1204.56, "end": 1209.96, "text": " Is there a possibility to create a graph data set where the updates are included in the", "tokens": [1119, 456, 257, 7959, 281, 1884, 257, 4295, 1412, 992, 689, 264, 9205, 366, 5556, 294, 264], "temperature": 0.0, "avg_logprob": -0.3666613163092198, "compression_ratio": 1.7109826589595376, "no_speech_prob": 9.734809282235801e-05}, {"id": 277, "seek": 119108, "start": 1209.96, "end": 1214.56, "text": " data set, so that the nodes and vertices get time stamps when they were deleted or when", "tokens": [1412, 992, 11, 370, 300, 264, 13891, 293, 32053, 483, 565, 30800, 562, 436, 645, 22981, 420, 562], "temperature": 0.0, "avg_logprob": -0.3666613163092198, "compression_ratio": 1.7109826589595376, "no_speech_prob": 9.734809282235801e-05}, {"id": 278, "seek": 119108, "start": 1214.56, "end": 1215.56, "text": " they were added?", "tokens": [436, 645, 3869, 30], "temperature": 0.0, "avg_logprob": -0.3666613163092198, "compression_ratio": 1.7109826589595376, "no_speech_prob": 9.734809282235801e-05}, {"id": 279, "seek": 119108, "start": 1215.56, "end": 1216.56, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.3666613163092198, "compression_ratio": 1.7109826589595376, "no_speech_prob": 9.734809282235801e-05}, {"id": 280, "seek": 121656, "start": 1216.56, "end": 1222.6799999999998, "text": " So, is it possible to create something like a temporal graph with the time stamps of when", "tokens": [407, 11, 307, 309, 1944, 281, 1884, 746, 411, 257, 30881, 4295, 365, 264, 565, 30800, 295, 562], "temperature": 0.0, "avg_logprob": -0.16239539289896468, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.00021232664585113525}, {"id": 281, "seek": 121656, "start": 1222.6799999999998, "end": 1227.8799999999999, "text": " the specific node is created and deleted, and this is actually very easy, because this", "tokens": [264, 2685, 9984, 307, 2942, 293, 22981, 11, 293, 341, 307, 767, 588, 1858, 11, 570, 341], "temperature": 0.0, "avg_logprob": -0.16239539289896468, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.00021232664585113525}, {"id": 282, "seek": 121656, "start": 1227.8799999999999, "end": 1230.9199999999998, "text": " is the first step that the data gen creates.", "tokens": [307, 264, 700, 1823, 300, 264, 1412, 1049, 7829, 13], "temperature": 0.0, "avg_logprob": -0.16239539289896468, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.00021232664585113525}, {"id": 283, "seek": 121656, "start": 1230.9199999999998, "end": 1236.1599999999999, "text": " So, when David said that it creates a social network of three years, that has everything", "tokens": [407, 11, 562, 4389, 848, 300, 309, 7829, 257, 2093, 3209, 295, 1045, 924, 11, 300, 575, 1203], "temperature": 0.0, "avg_logprob": -0.16239539289896468, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.00021232664585113525}, {"id": 284, "seek": 121656, "start": 1236.1599999999999, "end": 1240.56, "text": " that was ever created or deleted during those three years, and then we have attributes like", "tokens": [300, 390, 1562, 2942, 420, 22981, 1830, 729, 1045, 924, 11, 293, 550, 321, 362, 17212, 411], "temperature": 0.0, "avg_logprob": -0.16239539289896468, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.00021232664585113525}, {"id": 285, "seek": 121656, "start": 1240.56, "end": 1244.48, "text": " creation date and deletion date, and then we turn it into something that's loadable", "tokens": [8016, 4002, 293, 1103, 302, 313, 4002, 11, 293, 550, 321, 1261, 309, 666, 746, 300, 311, 3677, 712], "temperature": 0.0, "avg_logprob": -0.16239539289896468, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.00021232664585113525}, {"id": 286, "seek": 124448, "start": 1244.48, "end": 1249.64, "text": " to the database, we hide deletion dates, because the database, of course, shouldn't be aware", "tokens": [281, 264, 8149, 11, 321, 6479, 1103, 302, 313, 11691, 11, 570, 264, 8149, 11, 295, 1164, 11, 4659, 380, 312, 3650], "temperature": 0.0, "avg_logprob": -0.24997533162434896, "compression_ratio": 1.8, "no_speech_prob": 0.00030329852597787976}, {"id": 287, "seek": 124448, "start": 1249.64, "end": 1254.8, "text": " of this, but this is something that the data gen supports out of the box.", "tokens": [295, 341, 11, 457, 341, 307, 746, 300, 264, 1412, 1049, 9346, 484, 295, 264, 2424, 13], "temperature": 0.0, "avg_logprob": -0.24997533162434896, "compression_ratio": 1.8, "no_speech_prob": 0.00030329852597787976}, {"id": 288, "seek": 124448, "start": 1254.8, "end": 1260.04, "text": " Okay, but then it's also too able to get this data set with the deletion date, because you", "tokens": [1033, 11, 457, 550, 309, 311, 611, 886, 1075, 281, 483, 341, 1412, 992, 365, 264, 1103, 302, 313, 4002, 11, 570, 291], "temperature": 0.0, "avg_logprob": -0.24997533162434896, "compression_ratio": 1.8, "no_speech_prob": 0.00030329852597787976}, {"id": 289, "seek": 124448, "start": 1260.04, "end": 1262.08, "text": " already said that it's hideable.", "tokens": [1217, 848, 300, 309, 311, 6479, 712, 13], "temperature": 0.0, "avg_logprob": -0.24997533162434896, "compression_ratio": 1.8, "no_speech_prob": 0.00030329852597787976}, {"id": 290, "seek": 124448, "start": 1262.08, "end": 1267.72, "text": " It's hideable, but we have one which is called the row temporal data set, and that is available,", "tokens": [467, 311, 6479, 712, 11, 457, 321, 362, 472, 597, 307, 1219, 264, 5386, 30881, 1412, 992, 11, 293, 300, 307, 2435, 11], "temperature": 0.0, "avg_logprob": -0.24997533162434896, "compression_ratio": 1.8, "no_speech_prob": 0.00030329852597787976}, {"id": 291, "seek": 126772, "start": 1267.72, "end": 1274.68, "text": " and we even published that, so that's something that, yeah, it has a lot of chance to be influential", "tokens": [293, 321, 754, 6572, 300, 11, 370, 300, 311, 746, 300, 11, 1338, 11, 309, 575, 257, 688, 295, 2931, 281, 312, 22215], "temperature": 0.0, "avg_logprob": -0.37159089481129365, "compression_ratio": 1.3115942028985508, "no_speech_prob": 0.00016851554391905665}, {"id": 292, "seek": 126772, "start": 1274.68, "end": 1276.52, "text": " in the streaming community, I believe.", "tokens": [294, 264, 11791, 1768, 11, 286, 1697, 13], "temperature": 0.0, "avg_logprob": -0.37159089481129365, "compression_ratio": 1.3115942028985508, "no_speech_prob": 0.00016851554391905665}, {"id": 293, "seek": 126772, "start": 1276.52, "end": 1278.92, "text": " All right, more questions?", "tokens": [1057, 558, 11, 544, 1651, 30], "temperature": 0.0, "avg_logprob": -0.37159089481129365, "compression_ratio": 1.3115942028985508, "no_speech_prob": 0.00016851554391905665}, {"id": 294, "seek": 126772, "start": 1278.92, "end": 1279.92, "text": " Yeah, Michael?", "tokens": [865, 11, 5116, 30], "temperature": 0.0, "avg_logprob": -0.37159089481129365, "compression_ratio": 1.3115942028985508, "no_speech_prob": 0.00016851554391905665}, {"id": 295, "seek": 127992, "start": 1279.92, "end": 1308.1200000000001, "text": " Yeah, Michael?", "tokens": [865, 11, 5116, 30], "temperature": 0.0, "avg_logprob": -0.4071081280708313, "compression_ratio": 0.6363636363636364, "no_speech_prob": 0.0008513623033650219}, {"id": 296, "seek": 130812, "start": 1308.12, "end": 1310.84, "text": " So the question is, can we extend to other domains?", "tokens": [407, 264, 1168, 307, 11, 393, 321, 10101, 281, 661, 25514, 30], "temperature": 0.0, "avg_logprob": -0.11406483473601164, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.0004896429018117487}, {"id": 297, "seek": 130812, "start": 1310.84, "end": 1317.36, "text": " And we usually emphasize that social networks is not really the domain that is the actual", "tokens": [400, 321, 2673, 16078, 300, 2093, 9590, 307, 406, 534, 264, 9274, 300, 307, 264, 3539], "temperature": 0.0, "avg_logprob": -0.11406483473601164, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.0004896429018117487}, {"id": 298, "seek": 130812, "start": 1317.36, "end": 1321.36, "text": " primary use case for graphs, we just use this because this is really easy to understand,", "tokens": [6194, 764, 1389, 337, 24877, 11, 321, 445, 764, 341, 570, 341, 307, 534, 1858, 281, 1223, 11], "temperature": 0.0, "avg_logprob": -0.11406483473601164, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.0004896429018117487}, {"id": 299, "seek": 130812, "start": 1321.36, "end": 1325.6399999999999, "text": " we don't have to explain person-nose-person, and you can put in all sorts of interesting", "tokens": [321, 500, 380, 362, 281, 2903, 954, 12, 77, 541, 12, 10813, 11, 293, 291, 393, 829, 294, 439, 7527, 295, 1880], "temperature": 0.0, "avg_logprob": -0.11406483473601164, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.0004896429018117487}, {"id": 300, "seek": 130812, "start": 1325.6399999999999, "end": 1329.4399999999998, "text": " technological challenges to a graph domain like this.", "tokens": [18439, 4759, 281, 257, 4295, 9274, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.11406483473601164, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.0004896429018117487}, {"id": 301, "seek": 130812, "start": 1329.4399999999998, "end": 1334.84, "text": " It would make sense, and sometimes we are approached by our members saying, we want", "tokens": [467, 576, 652, 2020, 11, 293, 2171, 321, 366, 17247, 538, 527, 2679, 1566, 11, 321, 528], "temperature": 0.0, "avg_logprob": -0.11406483473601164, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.0004896429018117487}, {"id": 302, "seek": 133484, "start": 1334.84, "end": 1342.32, "text": " to do a new benchmark in the domain X, and we then send them the process that is required", "tokens": [281, 360, 257, 777, 18927, 294, 264, 9274, 1783, 11, 293, 321, 550, 2845, 552, 264, 1399, 300, 307, 4739], "temperature": 0.0, "avg_logprob": -0.09238806331858915, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.00043404943426139653}, {"id": 303, "seek": 133484, "start": 1342.32, "end": 1347.1599999999999, "text": " to get one of these benchmarks completed, and that's usually the end of the conversation,", "tokens": [281, 483, 472, 295, 613, 43751, 7365, 11, 293, 300, 311, 2673, 264, 917, 295, 264, 3761, 11], "temperature": 0.0, "avg_logprob": -0.09238806331858915, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.00043404943426139653}, {"id": 304, "seek": 133484, "start": 1347.1599999999999, "end": 1353.6399999999999, "text": " but we are definitely open to have more interesting benchmarks, and of course, a good data generator", "tokens": [457, 321, 366, 2138, 1269, 281, 362, 544, 1880, 43751, 11, 293, 295, 1164, 11, 257, 665, 1412, 19265], "temperature": 0.0, "avg_logprob": -0.09238806331858915, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.00043404943426139653}, {"id": 305, "seek": 133484, "start": 1353.6399999999999, "end": 1360.12, "text": " is worth gold to all the researchers and the vendors in this community, so that's usually", "tokens": [307, 3163, 3821, 281, 439, 264, 10309, 293, 264, 22056, 294, 341, 1768, 11, 370, 300, 311, 2673], "temperature": 0.0, "avg_logprob": -0.09238806331858915, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.00043404943426139653}, {"id": 306, "seek": 136012, "start": 1360.12, "end": 1365.56, "text": " the hard point, and I would be definitely interested in having a retail graph generator.", "tokens": [264, 1152, 935, 11, 293, 286, 576, 312, 2138, 3102, 294, 1419, 257, 10800, 4295, 19265, 13], "temperature": 0.0, "avg_logprob": -0.41512500996492346, "compression_ratio": 1.3055555555555556, "no_speech_prob": 0.0017717896262183785}, {"id": 307, "seek": 136012, "start": 1365.56, "end": 1366.56, "text": " Carlo?", "tokens": [45112, 30], "temperature": 0.0, "avg_logprob": -0.41512500996492346, "compression_ratio": 1.3055555555555556, "no_speech_prob": 0.0017717896262183785}, {"id": 308, "seek": 136012, "start": 1366.56, "end": 1367.56, "text": " Hi.", "tokens": [2421, 13], "temperature": 0.0, "avg_logprob": -0.41512500996492346, "compression_ratio": 1.3055555555555556, "no_speech_prob": 0.0017717896262183785}, {"id": 309, "seek": 136012, "start": 1367.56, "end": 1377.56, "text": " The question is specifically, what do you see the impact of this will be on the industry", "tokens": [440, 1168, 307, 4682, 11, 437, 360, 291, 536, 264, 2712, 295, 341, 486, 312, 322, 264, 3518], "temperature": 0.0, "avg_logprob": -0.41512500996492346, "compression_ratio": 1.3055555555555556, "no_speech_prob": 0.0017717896262183785}, {"id": 310, "seek": 137756, "start": 1377.56, "end": 1394.32, "text": " or it's more uneductive of evidence if it's, if the system would have improved, or if the", "tokens": [420, 309, 311, 544, 517, 292, 11130, 488, 295, 4467, 498, 309, 311, 11, 498, 264, 1185, 576, 362, 9689, 11, 420, 498, 264], "temperature": 0.0, "avg_logprob": -0.38926586737999547, "compression_ratio": 1.7056277056277056, "no_speech_prob": 0.0011959824478253722}, {"id": 311, "seek": 137756, "start": 1394.32, "end": 1395.32, "text": " system would get more robust as in that you detect stuff that is doing things and stuff", "tokens": [1185, 576, 483, 544, 13956, 382, 294, 300, 291, 5531, 1507, 300, 307, 884, 721, 293, 1507], "temperature": 0.0, "avg_logprob": -0.38926586737999547, "compression_ratio": 1.7056277056277056, "no_speech_prob": 0.0011959824478253722}, {"id": 312, "seek": 137756, "start": 1395.32, "end": 1396.32, "text": " get fixed, or what's the, yeah.", "tokens": [483, 6806, 11, 420, 437, 311, 264, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.38926586737999547, "compression_ratio": 1.7056277056277056, "no_speech_prob": 0.0011959824478253722}, {"id": 313, "seek": 137756, "start": 1396.32, "end": 1397.32, "text": " So the question?", "tokens": [407, 264, 1168, 30], "temperature": 0.0, "avg_logprob": -0.38926586737999547, "compression_ratio": 1.7056277056277056, "no_speech_prob": 0.0011959824478253722}, {"id": 314, "seek": 137756, "start": 1397.32, "end": 1398.32, "text": " Yeah, the question is about the potential impact.", "tokens": [865, 11, 264, 1168, 307, 466, 264, 3995, 2712, 13], "temperature": 0.0, "avg_logprob": -0.38926586737999547, "compression_ratio": 1.7056277056277056, "no_speech_prob": 0.0011959824478253722}, {"id": 315, "seek": 137756, "start": 1398.32, "end": 1399.96, "text": " What could all this achieve?", "tokens": [708, 727, 439, 341, 4584, 30], "temperature": 0.0, "avg_logprob": -0.38926586737999547, "compression_ratio": 1.7056277056277056, "no_speech_prob": 0.0011959824478253722}, {"id": 316, "seek": 137756, "start": 1399.96, "end": 1406.6, "text": " And we believe that it will help accelerate the field in the sense that systems will get", "tokens": [400, 321, 1697, 300, 309, 486, 854, 21341, 264, 2519, 294, 264, 2020, 300, 3652, 486, 483], "temperature": 0.0, "avg_logprob": -0.38926586737999547, "compression_ratio": 1.7056277056277056, "no_speech_prob": 0.0011959824478253722}, {"id": 317, "seek": 140660, "start": 1406.6, "end": 1411.28, "text": " more mature, because if you want to get an audited result, you have to pass all the asset", "tokens": [544, 14442, 11, 570, 498, 291, 528, 281, 483, 364, 2379, 1226, 1874, 11, 291, 362, 281, 1320, 439, 264, 11999], "temperature": 0.0, "avg_logprob": -0.1373439307685371, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.001213590381667018}, {"id": 318, "seek": 140660, "start": 1411.28, "end": 1416.8799999999999, "text": " tests, you have to be able to recover after a crash, and ideally you would have to be", "tokens": [6921, 11, 291, 362, 281, 312, 1075, 281, 8114, 934, 257, 8252, 11, 293, 22915, 291, 576, 362, 281, 312], "temperature": 0.0, "avg_logprob": -0.1373439307685371, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.001213590381667018}, {"id": 319, "seek": 140660, "start": 1416.8799999999999, "end": 1421.48, "text": " fast, so that is hopefully one of the other things that systems will take away.", "tokens": [2370, 11, 370, 300, 307, 4696, 472, 295, 264, 661, 721, 300, 3652, 486, 747, 1314, 13], "temperature": 0.0, "avg_logprob": -0.1373439307685371, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.001213590381667018}, {"id": 320, "seek": 140660, "start": 1421.48, "end": 1428.12, "text": " They will have better optimizers, improved storage, better query execution engines,", "tokens": [814, 486, 362, 1101, 5028, 22525, 11, 9689, 6725, 11, 1101, 14581, 15058, 12982, 11], "temperature": 0.0, "avg_logprob": -0.1373439307685371, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.001213590381667018}, {"id": 321, "seek": 140660, "start": 1428.12, "end": 1434.9599999999998, "text": " and we have seen this in the aftermath of the TPC benchmarks, so those resulted in quite", "tokens": [293, 321, 362, 1612, 341, 294, 264, 34095, 295, 264, 314, 12986, 43751, 11, 370, 729, 18753, 294, 1596], "temperature": 0.0, "avg_logprob": -0.1373439307685371, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.001213590381667018}, {"id": 322, "seek": 140660, "start": 1434.9599999999998, "end": 1436.32, "text": " a big speedup.", "tokens": [257, 955, 3073, 1010, 13], "temperature": 0.0, "avg_logprob": -0.1373439307685371, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.001213590381667018}, {"id": 323, "seek": 143632, "start": 1436.32, "end": 1442.1599999999999, "text": " So that's one area, and of course there is pricing, we would like that users can get", "tokens": [407, 300, 311, 472, 1859, 11, 293, 295, 1164, 456, 307, 17621, 11, 321, 576, 411, 300, 5022, 393, 483], "temperature": 0.0, "avg_logprob": -0.10863353931798345, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.0003008766798302531}, {"id": 324, "seek": 143632, "start": 1442.1599999999999, "end": 1447.24, "text": " more transactions per dollar, and the third that we are personally quite interested in", "tokens": [544, 16856, 680, 7241, 11, 293, 264, 2636, 300, 321, 366, 5665, 1596, 3102, 294], "temperature": 0.0, "avg_logprob": -0.10863353931798345, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.0003008766798302531}, {"id": 325, "seek": 143632, "start": 1447.24, "end": 1449.2, "text": " is the new accelerators that come out.", "tokens": [307, 264, 777, 10172, 3391, 300, 808, 484, 13], "temperature": 0.0, "avg_logprob": -0.10863353931798345, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.0003008766798302531}, {"id": 326, "seek": 143632, "start": 1449.2, "end": 1454.56, "text": " So there are, especially in the field of machine learning, there are cards that do fast sparse", "tokens": [407, 456, 366, 11, 2318, 294, 264, 2519, 295, 3479, 2539, 11, 456, 366, 5632, 300, 360, 2370, 637, 11668], "temperature": 0.0, "avg_logprob": -0.10863353931798345, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.0003008766798302531}, {"id": 327, "seek": 143632, "start": 1454.56, "end": 1459.84, "text": " matrix multiplications, those could be harnessed specifically for the analytical benchmarks", "tokens": [8141, 17596, 763, 11, 729, 727, 312, 276, 1083, 10830, 4682, 337, 264, 29579, 43751], "temperature": 0.0, "avg_logprob": -0.10863353931798345, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.0003008766798302531}, {"id": 328, "seek": 143632, "start": 1459.84, "end": 1464.96, "text": " that we have, and that would be interesting to see how big of a hassle it is to implement", "tokens": [300, 321, 362, 11, 293, 300, 576, 312, 1880, 281, 536, 577, 955, 295, 257, 39526, 309, 307, 281, 4445], "temperature": 0.0, "avg_logprob": -0.10863353931798345, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.0003008766798302531}, {"id": 329, "seek": 146496, "start": 1464.96, "end": 1475.04, "text": " and how big of a speedup they give, cool, all right, okay, thank you very much.", "tokens": [50364, 293, 577, 955, 295, 257, 3073, 1010, 436, 976, 11, 1627, 11, 439, 558, 11, 1392, 11, 1309, 291, 588, 709, 13, 50868], "temperature": 0.0, "avg_logprob": -0.3490685272216797, "compression_ratio": 1.0533333333333332, "no_speech_prob": 0.0007183635607361794}], "language": "en"}