{"text": " Okay, so the aim is to control the source of variation and from a scientific point of view when you are publishing a paper, an independent observer should observe the same results and have the same conclusion and this observation must be a sustainable so it doesn't depend where, when you observe it and maybe not where neither. So it's also collective. So all the question in this scientific framework is how can we redo later and elsewhere so I'm doing something on my laptop and another person will try to redo something like two years later the same thing. So how can we redo later and elsewhere what I've done here and today and this is a big question and the challenge in reproducible research and in science and I think Geeks answer to this question. So what does it mean a computational environment? So for example Alice says using this data you need that C file and GCC 11 to run my analysis. Okay, but what is the source code of GCC 11 and GCC 11 requires some tools for building and these tools, there is also tools require a runtime and this is recursive. So answering all this question is controlling the source of variations so you are controlling your computational environment. So this question is not new in computing, I mean in computing, it's not new. We have solutions. The solutions are package manager and so on. So we have package manager like APTU but there are some issues for example it's difficult to have several versions, difficult to have rollback. We have environment manager like Conda, PIP, module files but there is a kind of issue with transparency, who know what is inside a PIP installed torch. There is module files but how they maintain on your, I mean how they maintain, do you use on your laptop and on another machine? There is a docker file but the docker and docker files are based on previous solutions so also drawback apply also. Geeks in fact is all this solution plugged together and in fact it fix all the annoyance of each. This is what Geeks is. So Geeks is a package manager like APTU, etc. is a transactional and decorative and it produce showable packs like docker images. You can produce virtual machines and you can deploy that. For example you like unseemble or parker and you can build a whole Linux distribution and it's also a scheme library. Geeks is really awesome. Okay we have 20 minutes so I don't speak about that because it's too much. I'll just explain you how Geeks is helping me in my daily job. Geeks you can run Geeks on the top of any Linux distribution so it's really easy to try. If you haven't you should. So Geeks is just another package manager. So yeah you can install, remove without any privilege. This is more than APT from Debian for example. You have the direct creative management so declarative management means that you can have a configuration file and so on transactional so you don't have broken state you can rollback and so on and you have binary substitutes so you are not compiling everything from scratch every time. Okay this is some kind of classical package manager but you have more. You have isolated environment on the fly so you can create an isolated environment with Linux namespace on the fly and this is really helpful to check the dependency of your scientific analysis and you also can use Geeks to produce images like Docker images but without using the Docker file machinery. So you are saying okay nice but the issue with science is about reproducibility so you have a package manager that have all these features but why is reproducible? So the answer is about version. So for example Alice says I use GCC Adversion 11 so you have GCC to change but you need a linker like LD you need binitils and GCC is a compiler but the compiler need NPC and also need the NPC need NPFR and the big question is is the same GCC if we replace this NPF 4.1 by NPF 4 NPFR 4.0 is the same GCC or not and this is the issue that we can have when we are using when we are running analysis we are not controlling within us detail this graph and maybe the difference in the version of this package have a big influence of GCC at the end we cannot know and okay so Geeks in fact the version of Geeks it's fixed by I mean the state of Geeks is provided by Geeks described and this fix the graph this graph it fix the complete collection of packages and Geeks itself so in fact each node specify a receipt and each node specify code source the upstream source but also all the tools that you need to build the package so the compiler the build automation CMake make etc the configuration flags and so on and the dependency that you need to do that so you have a kind of recursive graph and this graph can be really really used for example for skypie it's more than 1000 nodes so it's it's not manageable by end and Geeks provide you a fine control about this graph so collaboration in action is this is what Geeks is helping me concretely every day so I write a manifest manifest it's just a file where I describe my tools for example python skype skipy nimpy or or and so on and I create my environment with Geeks shell so this is nice then I can I can pin this graph and I apply Geeks describe and I pin the graph so now I have another file state-alice which pins this graph but collaboration is about sharing the computational environment so somewhere is sharing one specific graph so in fact if I share these two files the manifest which describe the list of the tools and state-alice which describe the state of the graph okay Blake my collaborator can spawn exactly the same computational environment using the Geeks time machine so you think that Blake and Alice are running exactly the same computational environment and if Carol also knows these two files Carol can run the exact same environment as Blake and Alice so here we have some things that it's really easy so on my laptop I write my I specify the tools that I need python or etc and I specify the state I'm running on my on the laptop then I deploy on the cluster I use just transfer the two files and I run this Geeks time machine command and on the cluster I have the exact same environment that I have on my laptop so there is no question about what can be wrong between my laptop and the cluster because it's exactly the same computational environment and this is a game changer when you are running analysis on different machines where your colleagues are running in different places so Geeks this time machine provides a way to jump in different states temporarily so you can be I mean if you imagine you have the time and and and Alice and Blake or Carol are not on the same state compared to the time but they can jump artificially and temporarily to the same point in time to have the exact same computational environment and this is not possible with any other maybe next and so this is kind of game-changing for me so to have that working very well you need to preserve all the source code and for that you need software heritage which is I took just after and you need to have a backward compatibility of the Linux Linux kernel so and you also need to have some compatibility of hardware for example in five year we can if the hardware are not x86 yeah maybe we cannot jump it back in time but if you have compatibility of that where we have this that work and the question is what we have this size where these three conditions are satisfied so now we have for example this condition and what is the size of this window and from my point of view Geeks is running a quasi unique experiment at I mean real-world experiment a large since 2019 so we will see that this size maybe in five years we will try to to redo something from now and we will fail because something that we but we have this mechanism able to jump in different point in time so software heritage is a long-term source code archive so you collect and preserve all the source code of the world I mean open source code of the world so all github githlab debian and so on and geeks is able to to save the code of the geek package definition so for example the source code of DCC you can geeks use the source code of DCC coming from internet but you can save this directly to to software heritage and the package definition itself and what is really nice is that geeks is able to to fall back if the source disappears so for example you have a product if tomorrow github is down for whatever reason all the paper published with with the line my script is on github and the package is on on github and github is down like githulite I don't remember the name there is many popular platforms that are down and all all break and with this mechanism it is doesn't break so I have five minutes right okay so just geeks is able to so geeks is able to pack everything so you can produce a docker image with geeks so using the manifest you use geeks pack and geeks pack generate the docker image and then if Blake doesn't run geeks she can run the docker and the binary inside the docker are exactly the same than the binary inside the computational environment of Alice and because of the time machine this is reproducible over the time and this is also a kind of game changing in science and in fact a container it's just a format of the archive and geeks is an austic about this container format so you can generate torbol docker singularity there is an experimental debian binary package and yesterday evening there is a patch about supporting rpm package so this is just flexible to every context the key point is to to fully control the binary going inside the container and geeks does this job so this way it's a factory for creating images so geeks is helping me because there is three commands and two files so this is really easy to explain to for example medical doctor and and so on and it's a packing factory when I can deploy on infrastructure where geeks is not running for sharing computational environment and for me this is a two key for two keys for for for open science research and so on and if you want more information there is a this group geeks hpc but it's like many things in geeks the name is not good because it's more like geeks for science than not specific to geeks hpcs geeks for scientific and okay and it's running production so don't be afraid to install geeks I mean it's a there is all this cluster running already geeks more all the laptops and desktop so it's now it's in production so yeah this is uh I mean why the picture geeks and and and science that I would like to have in in the future so thanks so uh yeah but yeah yeah if you're the first one scientists but for example the scientists uh we are trying to reuse uh they can use for example different uh kind different cpu or different architecture how much some kind of uh optimizations for particular cpu can have a impact on having different results can it just like ruin a whole idea they can can they really like if you have idea like how much impact so I have to repeat the question so the question is the so in hpc context you have you have performance that depends on the architecture and you can have micro optimization for specific architecture so how geeks deal with that for the first question and how will we do that for reproducibility is the second question I think from my understanding is the two question I don't know the difference of the performances about the the micro optimization this is a job of the researcher in the field to say this micro optimization provides this performance improvement what I can say what geeks does to manage this micro optimization so Ludo is is is giving a talk in hpc dev room about the the the tune package transformation that I can ask when we are speaking about reproducibility we can ask if this micro micro optimization or I mean our fit the reproducible and the scientific method so I don't have the answer but at some at some point I think is it worth to have a micro optimization for I mean having something like a couple of percent of improvement but we lose all the reproducibility we lose the way to check that the computation is correct so I don't know if it's I mean this is a question for a collective question for the researcher in general so there is a question so the question is is it enough or not to have all this machinery to have reproducible science so the answer is I don't know because I mean if to have the answer is that everybody should run this to be be sure that he's in case or not so I don't know and the I don't remember what I want to say about that I mean I don't show here but there is a paper published with this method and yeah there is more reproducibility than than the other but at some point the the the the software is just one part of the big picture of the reproducibility issue in in in science and in fact is a is a is a is a collective practice in fact because you for example I'm trying to reproduce the paper from August this August and some data are missing the script are missing the the package that's been used are missing so so I cannot reproduce and this is not geeks it's just because publisher didn't good job thanks everybody", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 26.240000000000002, "text": " Okay, so the aim is to control the source of variation and from a scientific point of", "tokens": [50364, 1033, 11, 370, 264, 5939, 307, 281, 1969, 264, 4009, 295, 12990, 293, 490, 257, 8134, 935, 295, 51676], "temperature": 0.0, "avg_logprob": -0.39162037589333276, "compression_ratio": 1.118421052631579, "no_speech_prob": 0.0844556987285614}, {"id": 1, "seek": 2624, "start": 26.24, "end": 32.32, "text": " view when you are publishing a paper, an independent observer should observe the same", "tokens": [50364, 1910, 562, 291, 366, 17832, 257, 3035, 11, 364, 6695, 27878, 820, 11441, 264, 912, 50668], "temperature": 0.0, "avg_logprob": -0.28588421280319626, "compression_ratio": 1.642156862745098, "no_speech_prob": 0.27877411246299744}, {"id": 2, "seek": 2624, "start": 32.32, "end": 40.519999999999996, "text": " results and have the same conclusion and this observation must be a sustainable so it", "tokens": [50668, 3542, 293, 362, 264, 912, 10063, 293, 341, 14816, 1633, 312, 257, 11235, 370, 309, 51078], "temperature": 0.0, "avg_logprob": -0.28588421280319626, "compression_ratio": 1.642156862745098, "no_speech_prob": 0.27877411246299744}, {"id": 3, "seek": 2624, "start": 40.519999999999996, "end": 45.92, "text": " doesn't depend where, when you observe it and maybe not where neither. So it's also", "tokens": [51078, 1177, 380, 5672, 689, 11, 562, 291, 11441, 309, 293, 1310, 406, 689, 9662, 13, 407, 309, 311, 611, 51348], "temperature": 0.0, "avg_logprob": -0.28588421280319626, "compression_ratio": 1.642156862745098, "no_speech_prob": 0.27877411246299744}, {"id": 4, "seek": 2624, "start": 45.92, "end": 54.12, "text": " collective. So all the question in this scientific framework is how can we redo", "tokens": [51348, 12590, 13, 407, 439, 264, 1168, 294, 341, 8134, 8388, 307, 577, 393, 321, 29956, 51758], "temperature": 0.0, "avg_logprob": -0.28588421280319626, "compression_ratio": 1.642156862745098, "no_speech_prob": 0.27877411246299744}, {"id": 5, "seek": 5412, "start": 54.12, "end": 61.879999999999995, "text": " later and elsewhere so I'm doing something on my laptop and another person will try to", "tokens": [50364, 1780, 293, 14517, 370, 286, 478, 884, 746, 322, 452, 10732, 293, 1071, 954, 486, 853, 281, 50752], "temperature": 0.0, "avg_logprob": -0.27654244822840535, "compression_ratio": 1.6144578313253013, "no_speech_prob": 0.11958527565002441}, {"id": 6, "seek": 5412, "start": 61.879999999999995, "end": 70.28, "text": " redo something like two years later the same thing. So how can we redo later and elsewhere", "tokens": [50752, 29956, 746, 411, 732, 924, 1780, 264, 912, 551, 13, 407, 577, 393, 321, 29956, 1780, 293, 14517, 51172], "temperature": 0.0, "avg_logprob": -0.27654244822840535, "compression_ratio": 1.6144578313253013, "no_speech_prob": 0.11958527565002441}, {"id": 7, "seek": 5412, "start": 70.28, "end": 77.72, "text": " what I've done here and today and this is a big question and the challenge in reproducible", "tokens": [51172, 437, 286, 600, 1096, 510, 293, 965, 293, 341, 307, 257, 955, 1168, 293, 264, 3430, 294, 11408, 32128, 51544], "temperature": 0.0, "avg_logprob": -0.27654244822840535, "compression_ratio": 1.6144578313253013, "no_speech_prob": 0.11958527565002441}, {"id": 8, "seek": 7772, "start": 77.72, "end": 85.52, "text": " research and in science and I think Geeks answer to this question. So what does it mean", "tokens": [50364, 2132, 293, 294, 3497, 293, 286, 519, 2876, 24785, 1867, 281, 341, 1168, 13, 407, 437, 775, 309, 914, 50754], "temperature": 0.0, "avg_logprob": -0.29954185485839846, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.08139420300722122}, {"id": 9, "seek": 7772, "start": 85.52, "end": 91.88, "text": " a computational environment? So for example Alice says using this data you need that", "tokens": [50754, 257, 28270, 2823, 30, 407, 337, 1365, 16004, 1619, 1228, 341, 1412, 291, 643, 300, 51072], "temperature": 0.0, "avg_logprob": -0.29954185485839846, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.08139420300722122}, {"id": 10, "seek": 7772, "start": 91.88, "end": 100.84, "text": " C file and GCC 11 to run my analysis. Okay, but what is the source code of GCC 11 and", "tokens": [51072, 383, 3991, 293, 460, 11717, 2975, 281, 1190, 452, 5215, 13, 1033, 11, 457, 437, 307, 264, 4009, 3089, 295, 460, 11717, 2975, 293, 51520], "temperature": 0.0, "avg_logprob": -0.29954185485839846, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.08139420300722122}, {"id": 11, "seek": 7772, "start": 100.84, "end": 106.2, "text": " GCC 11 requires some tools for building and these tools, there is also tools require", "tokens": [51520, 460, 11717, 2975, 7029, 512, 3873, 337, 2390, 293, 613, 3873, 11, 456, 307, 611, 3873, 3651, 51788], "temperature": 0.0, "avg_logprob": -0.29954185485839846, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.08139420300722122}, {"id": 12, "seek": 10620, "start": 106.2, "end": 114.96000000000001, "text": " a runtime and this is recursive. So answering all this question is controlling the source", "tokens": [50364, 257, 34474, 293, 341, 307, 20560, 488, 13, 407, 13430, 439, 341, 1168, 307, 14905, 264, 4009, 50802], "temperature": 0.0, "avg_logprob": -0.2727323857749381, "compression_ratio": 1.7661691542288558, "no_speech_prob": 0.07369516044855118}, {"id": 13, "seek": 10620, "start": 114.96000000000001, "end": 119.68, "text": " of variations so you are controlling your computational environment. So this question", "tokens": [50802, 295, 17840, 370, 291, 366, 14905, 428, 28270, 2823, 13, 407, 341, 1168, 51038], "temperature": 0.0, "avg_logprob": -0.2727323857749381, "compression_ratio": 1.7661691542288558, "no_speech_prob": 0.07369516044855118}, {"id": 14, "seek": 10620, "start": 119.68, "end": 125.60000000000001, "text": " is not new in computing, I mean in computing, it's not new. We have solutions. The solutions", "tokens": [51038, 307, 406, 777, 294, 15866, 11, 286, 914, 294, 15866, 11, 309, 311, 406, 777, 13, 492, 362, 6547, 13, 440, 6547, 51334], "temperature": 0.0, "avg_logprob": -0.2727323857749381, "compression_ratio": 1.7661691542288558, "no_speech_prob": 0.07369516044855118}, {"id": 15, "seek": 10620, "start": 125.60000000000001, "end": 133.6, "text": " are package manager and so on. So we have package manager like APTU but there are some", "tokens": [51334, 366, 7372, 6598, 293, 370, 322, 13, 407, 321, 362, 7372, 6598, 411, 5372, 51, 52, 457, 456, 366, 512, 51734], "temperature": 0.0, "avg_logprob": -0.2727323857749381, "compression_ratio": 1.7661691542288558, "no_speech_prob": 0.07369516044855118}, {"id": 16, "seek": 13360, "start": 133.6, "end": 137.88, "text": " issues for example it's difficult to have several versions, difficult to have rollback.", "tokens": [50364, 2663, 337, 1365, 309, 311, 2252, 281, 362, 2940, 9606, 11, 2252, 281, 362, 3373, 3207, 13, 50578], "temperature": 0.0, "avg_logprob": -0.3073831670424517, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.01606132462620735}, {"id": 17, "seek": 13360, "start": 137.88, "end": 143.44, "text": " We have environment manager like Conda, PIP, module files but there is a kind of issue", "tokens": [50578, 492, 362, 2823, 6598, 411, 383, 12233, 11, 430, 9139, 11, 10088, 7098, 457, 456, 307, 257, 733, 295, 2734, 50856], "temperature": 0.0, "avg_logprob": -0.3073831670424517, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.01606132462620735}, {"id": 18, "seek": 13360, "start": 143.44, "end": 150.88, "text": " with transparency, who know what is inside a PIP installed torch. There is module files", "tokens": [50856, 365, 17131, 11, 567, 458, 437, 307, 1854, 257, 430, 9139, 8899, 27822, 13, 821, 307, 10088, 7098, 51228], "temperature": 0.0, "avg_logprob": -0.3073831670424517, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.01606132462620735}, {"id": 19, "seek": 13360, "start": 150.88, "end": 157.07999999999998, "text": " but how they maintain on your, I mean how they maintain, do you use on your laptop and", "tokens": [51228, 457, 577, 436, 6909, 322, 428, 11, 286, 914, 577, 436, 6909, 11, 360, 291, 764, 322, 428, 10732, 293, 51538], "temperature": 0.0, "avg_logprob": -0.3073831670424517, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.01606132462620735}, {"id": 20, "seek": 15708, "start": 157.08, "end": 164.0, "text": " on another machine? There is a docker file but the docker and docker files are based", "tokens": [50364, 322, 1071, 3479, 30, 821, 307, 257, 360, 9178, 3991, 457, 264, 360, 9178, 293, 360, 9178, 7098, 366, 2361, 50710], "temperature": 0.0, "avg_logprob": -0.23271969002737125, "compression_ratio": 1.6242424242424243, "no_speech_prob": 0.24154289066791534}, {"id": 21, "seek": 15708, "start": 164.0, "end": 175.28, "text": " on previous solutions so also drawback apply also. Geeks in fact is all this solution plugged", "tokens": [50710, 322, 3894, 6547, 370, 611, 2642, 3207, 3079, 611, 13, 2876, 24785, 294, 1186, 307, 439, 341, 3827, 25679, 51274], "temperature": 0.0, "avg_logprob": -0.23271969002737125, "compression_ratio": 1.6242424242424243, "no_speech_prob": 0.24154289066791534}, {"id": 22, "seek": 15708, "start": 175.28, "end": 183.44, "text": " together and in fact it fix all the annoyance of each. This is what Geeks is. So Geeks is", "tokens": [51274, 1214, 293, 294, 1186, 309, 3191, 439, 264, 8759, 719, 295, 1184, 13, 639, 307, 437, 2876, 24785, 307, 13, 407, 2876, 24785, 307, 51682], "temperature": 0.0, "avg_logprob": -0.23271969002737125, "compression_ratio": 1.6242424242424243, "no_speech_prob": 0.24154289066791534}, {"id": 23, "seek": 18344, "start": 183.44, "end": 191.32, "text": " a package manager like APTU, etc. is a transactional and decorative and it produce showable packs", "tokens": [50364, 257, 7372, 6598, 411, 5372, 51, 52, 11, 5183, 13, 307, 257, 46688, 1966, 293, 35185, 293, 309, 5258, 855, 712, 19403, 50758], "temperature": 0.0, "avg_logprob": -0.3257469994681222, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.20647235214710236}, {"id": 24, "seek": 18344, "start": 191.32, "end": 197.28, "text": " like docker images. You can produce virtual machines and you can deploy that. For example", "tokens": [50758, 411, 360, 9178, 5267, 13, 509, 393, 5258, 6374, 8379, 293, 291, 393, 7274, 300, 13, 1171, 1365, 51056], "temperature": 0.0, "avg_logprob": -0.3257469994681222, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.20647235214710236}, {"id": 25, "seek": 18344, "start": 197.28, "end": 204.24, "text": " you like unseemble or parker and you can build a whole Linux distribution and it's also a", "tokens": [51056, 291, 411, 517, 405, 443, 638, 420, 3884, 260, 293, 291, 393, 1322, 257, 1379, 18734, 7316, 293, 309, 311, 611, 257, 51404], "temperature": 0.0, "avg_logprob": -0.3257469994681222, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.20647235214710236}, {"id": 26, "seek": 20424, "start": 204.32000000000002, "end": 212.52, "text": " scheme library. Geeks is really awesome. Okay we have 20 minutes so I don't speak about", "tokens": [50368, 12232, 6405, 13, 2876, 24785, 307, 534, 3476, 13, 1033, 321, 362, 945, 2077, 370, 286, 500, 380, 1710, 466, 50778], "temperature": 0.0, "avg_logprob": -0.2444319080662083, "compression_ratio": 1.4438502673796791, "no_speech_prob": 0.6052213311195374}, {"id": 27, "seek": 20424, "start": 212.52, "end": 219.96, "text": " that because it's too much. I'll just explain you how Geeks is helping me in my daily job.", "tokens": [50778, 300, 570, 309, 311, 886, 709, 13, 286, 603, 445, 2903, 291, 577, 2876, 24785, 307, 4315, 385, 294, 452, 5212, 1691, 13, 51150], "temperature": 0.0, "avg_logprob": -0.2444319080662083, "compression_ratio": 1.4438502673796791, "no_speech_prob": 0.6052213311195374}, {"id": 28, "seek": 20424, "start": 219.96, "end": 227.76000000000002, "text": " Geeks you can run Geeks on the top of any Linux distribution so it's really easy to try. If", "tokens": [51150, 2876, 24785, 291, 393, 1190, 2876, 24785, 322, 264, 1192, 295, 604, 18734, 7316, 370, 309, 311, 534, 1858, 281, 853, 13, 759, 51540], "temperature": 0.0, "avg_logprob": -0.2444319080662083, "compression_ratio": 1.4438502673796791, "no_speech_prob": 0.6052213311195374}, {"id": 29, "seek": 22776, "start": 227.84, "end": 237.84, "text": " you haven't you should. So Geeks is just another package manager. So yeah you can install, remove", "tokens": [50368, 291, 2378, 380, 291, 820, 13, 407, 2876, 24785, 307, 445, 1071, 7372, 6598, 13, 407, 1338, 291, 393, 3625, 11, 4159, 50868], "temperature": 0.0, "avg_logprob": -0.23004975429801053, "compression_ratio": 1.625, "no_speech_prob": 0.010702725499868393}, {"id": 30, "seek": 22776, "start": 237.84, "end": 244.07999999999998, "text": " without any privilege. This is more than APT from Debian for example. You have the direct", "tokens": [50868, 1553, 604, 12122, 13, 639, 307, 544, 813, 5372, 51, 490, 1346, 20196, 337, 1365, 13, 509, 362, 264, 2047, 51180], "temperature": 0.0, "avg_logprob": -0.23004975429801053, "compression_ratio": 1.625, "no_speech_prob": 0.010702725499868393}, {"id": 31, "seek": 22776, "start": 244.07999999999998, "end": 249.64, "text": " creative management so declarative management means that you can have a configuration file", "tokens": [51180, 5880, 4592, 370, 16694, 1166, 4592, 1355, 300, 291, 393, 362, 257, 11694, 3991, 51458], "temperature": 0.0, "avg_logprob": -0.23004975429801053, "compression_ratio": 1.625, "no_speech_prob": 0.010702725499868393}, {"id": 32, "seek": 22776, "start": 249.64, "end": 254.44, "text": " and so on transactional so you don't have broken state you can rollback and so on and", "tokens": [51458, 293, 370, 322, 46688, 1966, 370, 291, 500, 380, 362, 5463, 1785, 291, 393, 3373, 3207, 293, 370, 322, 293, 51698], "temperature": 0.0, "avg_logprob": -0.23004975429801053, "compression_ratio": 1.625, "no_speech_prob": 0.010702725499868393}, {"id": 33, "seek": 25444, "start": 254.48, "end": 259.08, "text": " you have binary substitutes so you are not compiling everything from scratch every time.", "tokens": [50366, 291, 362, 17434, 26441, 1819, 370, 291, 366, 406, 715, 4883, 1203, 490, 8459, 633, 565, 13, 50596], "temperature": 0.0, "avg_logprob": -0.2008360206306755, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.027111534029245377}, {"id": 34, "seek": 25444, "start": 259.08, "end": 265.24, "text": " Okay this is some kind of classical package manager but you have more. You have isolated", "tokens": [50596, 1033, 341, 307, 512, 733, 295, 13735, 7372, 6598, 457, 291, 362, 544, 13, 509, 362, 14621, 50904], "temperature": 0.0, "avg_logprob": -0.2008360206306755, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.027111534029245377}, {"id": 35, "seek": 25444, "start": 265.24, "end": 273.0, "text": " environment on the fly so you can create an isolated environment with Linux namespace on", "tokens": [50904, 2823, 322, 264, 3603, 370, 291, 393, 1884, 364, 14621, 2823, 365, 18734, 5288, 17940, 322, 51292], "temperature": 0.0, "avg_logprob": -0.2008360206306755, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.027111534029245377}, {"id": 36, "seek": 25444, "start": 273.0, "end": 279.44, "text": " the fly and this is really helpful to check the dependency of your scientific analysis and you", "tokens": [51292, 264, 3603, 293, 341, 307, 534, 4961, 281, 1520, 264, 33621, 295, 428, 8134, 5215, 293, 291, 51614], "temperature": 0.0, "avg_logprob": -0.2008360206306755, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.027111534029245377}, {"id": 37, "seek": 27944, "start": 279.44, "end": 287.16, "text": " also can use Geeks to produce images like Docker images but without using the Docker file machinery.", "tokens": [50364, 611, 393, 764, 2876, 24785, 281, 5258, 5267, 411, 33772, 5267, 457, 1553, 1228, 264, 33772, 3991, 27302, 13, 50750], "temperature": 0.0, "avg_logprob": -0.21277707906869742, "compression_ratio": 1.6214689265536724, "no_speech_prob": 0.0075162360444664955}, {"id": 38, "seek": 27944, "start": 287.16, "end": 297.32, "text": " So you are saying okay nice but the issue with science is about reproducibility so you have a", "tokens": [50750, 407, 291, 366, 1566, 1392, 1481, 457, 264, 2734, 365, 3497, 307, 466, 11408, 537, 39802, 370, 291, 362, 257, 51258], "temperature": 0.0, "avg_logprob": -0.21277707906869742, "compression_ratio": 1.6214689265536724, "no_speech_prob": 0.0075162360444664955}, {"id": 39, "seek": 27944, "start": 297.32, "end": 303.12, "text": " package manager that have all these features but why is reproducible? So the answer is about", "tokens": [51258, 7372, 6598, 300, 362, 439, 613, 4122, 457, 983, 307, 11408, 32128, 30, 407, 264, 1867, 307, 466, 51548], "temperature": 0.0, "avg_logprob": -0.21277707906869742, "compression_ratio": 1.6214689265536724, "no_speech_prob": 0.0075162360444664955}, {"id": 40, "seek": 30312, "start": 303.2, "end": 311.24, "text": " version. So for example Alice says I use GCC Adversion 11 so you have GCC to change but you", "tokens": [50368, 3037, 13, 407, 337, 1365, 16004, 1619, 286, 764, 460, 11717, 1999, 29153, 2975, 370, 291, 362, 460, 11717, 281, 1319, 457, 291, 50770], "temperature": 0.0, "avg_logprob": -0.2815897199842665, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.036935269832611084}, {"id": 41, "seek": 30312, "start": 311.24, "end": 318.24, "text": " need a linker like LD you need binitils and GCC is a compiler but the compiler need NPC and also", "tokens": [50770, 643, 257, 2113, 260, 411, 33936, 291, 643, 5171, 270, 4174, 293, 460, 11717, 307, 257, 31958, 457, 264, 31958, 643, 28787, 293, 611, 51120], "temperature": 0.0, "avg_logprob": -0.2815897199842665, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.036935269832611084}, {"id": 42, "seek": 30312, "start": 318.24, "end": 329.48, "text": " need the NPC need NPFR and the big question is is the same GCC if we replace this NPF 4.1 by", "tokens": [51120, 643, 264, 28787, 643, 38611, 34658, 293, 264, 955, 1168, 307, 307, 264, 912, 460, 11717, 498, 321, 7406, 341, 38611, 37, 1017, 13, 16, 538, 51682], "temperature": 0.0, "avg_logprob": -0.2815897199842665, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.036935269832611084}, {"id": 43, "seek": 32948, "start": 329.52000000000004, "end": 338.8, "text": " NPF 4 NPFR 4.0 is the same GCC or not and this is the issue that we can have when we are", "tokens": [50366, 38611, 37, 1017, 38611, 34658, 1017, 13, 15, 307, 264, 912, 460, 11717, 420, 406, 293, 341, 307, 264, 2734, 300, 321, 393, 362, 562, 321, 366, 50830], "temperature": 0.0, "avg_logprob": -0.22268854060643156, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.007497041951864958}, {"id": 44, "seek": 32948, "start": 338.8, "end": 346.0, "text": " using when we are running analysis we are not controlling within us detail this graph and", "tokens": [50830, 1228, 562, 321, 366, 2614, 5215, 321, 366, 406, 14905, 1951, 505, 2607, 341, 4295, 293, 51190], "temperature": 0.0, "avg_logprob": -0.22268854060643156, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.007497041951864958}, {"id": 45, "seek": 32948, "start": 346.0, "end": 352.20000000000005, "text": " maybe the difference in the version of this package have a big influence of GCC at the end we", "tokens": [51190, 1310, 264, 2649, 294, 264, 3037, 295, 341, 7372, 362, 257, 955, 6503, 295, 460, 11717, 412, 264, 917, 321, 51500], "temperature": 0.0, "avg_logprob": -0.22268854060643156, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.007497041951864958}, {"id": 46, "seek": 35220, "start": 352.44, "end": 363.76, "text": " cannot know and okay so Geeks in fact the version of Geeks it's fixed by I mean the state of Geeks is", "tokens": [50376, 2644, 458, 293, 1392, 370, 2876, 24785, 294, 1186, 264, 3037, 295, 2876, 24785, 309, 311, 6806, 538, 286, 914, 264, 1785, 295, 2876, 24785, 307, 50942], "temperature": 0.0, "avg_logprob": -0.27441362380981443, "compression_ratio": 1.576, "no_speech_prob": 0.028062382712960243}, {"id": 47, "seek": 35220, "start": 363.76, "end": 370.84, "text": " provided by Geeks described and this fix the graph this graph it fix the complete collection of", "tokens": [50942, 5649, 538, 2876, 24785, 7619, 293, 341, 3191, 264, 4295, 341, 4295, 309, 3191, 264, 3566, 5765, 295, 51296], "temperature": 0.0, "avg_logprob": -0.27441362380981443, "compression_ratio": 1.576, "no_speech_prob": 0.028062382712960243}, {"id": 48, "seek": 37084, "start": 370.88, "end": 383.0, "text": " packages and Geeks itself so in fact each node specify a receipt and each node specify code", "tokens": [50366, 17401, 293, 2876, 24785, 2564, 370, 294, 1186, 1184, 9984, 16500, 257, 33882, 293, 1184, 9984, 16500, 3089, 50972], "temperature": 0.0, "avg_logprob": -0.22111743688583374, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.019901536405086517}, {"id": 49, "seek": 37084, "start": 383.0, "end": 391.08, "text": " source the upstream source but also all the tools that you need to build the package so the compiler", "tokens": [50972, 4009, 264, 33915, 4009, 457, 611, 439, 264, 3873, 300, 291, 643, 281, 1322, 264, 7372, 370, 264, 31958, 51376], "temperature": 0.0, "avg_logprob": -0.22111743688583374, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.019901536405086517}, {"id": 50, "seek": 37084, "start": 391.08, "end": 399.08, "text": " the build automation CMake make etc the configuration flags and so on and the dependency that you need", "tokens": [51376, 264, 1322, 17769, 20424, 619, 652, 5183, 264, 11694, 23265, 293, 370, 322, 293, 264, 33621, 300, 291, 643, 51776], "temperature": 0.0, "avg_logprob": -0.22111743688583374, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.019901536405086517}, {"id": 51, "seek": 39908, "start": 399.32, "end": 404.47999999999996, "text": " to do that so you have a kind of recursive graph and this graph can be really really used for", "tokens": [50376, 281, 360, 300, 370, 291, 362, 257, 733, 295, 20560, 488, 4295, 293, 341, 4295, 393, 312, 534, 534, 1143, 337, 50634], "temperature": 0.0, "avg_logprob": -0.2271946801079644, "compression_ratio": 1.5846994535519126, "no_speech_prob": 0.0084579112008214}, {"id": 52, "seek": 39908, "start": 404.47999999999996, "end": 412.76, "text": " example for skypie it's more than 1000 nodes so it's it's not manageable by end and Geeks provide", "tokens": [50634, 1365, 337, 5443, 9144, 309, 311, 544, 813, 9714, 13891, 370, 309, 311, 309, 311, 406, 38798, 538, 917, 293, 2876, 24785, 2893, 51048], "temperature": 0.0, "avg_logprob": -0.2271946801079644, "compression_ratio": 1.5846994535519126, "no_speech_prob": 0.0084579112008214}, {"id": 53, "seek": 39908, "start": 412.76, "end": 424.71999999999997, "text": " you a fine control about this graph so collaboration in action is this is what Geeks is helping me", "tokens": [51048, 291, 257, 2489, 1969, 466, 341, 4295, 370, 9363, 294, 3069, 307, 341, 307, 437, 2876, 24785, 307, 4315, 385, 51646], "temperature": 0.0, "avg_logprob": -0.2271946801079644, "compression_ratio": 1.5846994535519126, "no_speech_prob": 0.0084579112008214}, {"id": 54, "seek": 42472, "start": 424.96000000000004, "end": 432.16, "text": " concretely every day so I write a manifest manifest it's just a file where I describe my tools for", "tokens": [50376, 39481, 736, 633, 786, 370, 286, 2464, 257, 10067, 10067, 309, 311, 445, 257, 3991, 689, 286, 6786, 452, 3873, 337, 50736], "temperature": 0.0, "avg_logprob": -0.29679667485224737, "compression_ratio": 1.6424581005586592, "no_speech_prob": 0.04903389513492584}, {"id": 55, "seek": 42472, "start": 432.16, "end": 440.96000000000004, "text": " example python skype skipy nimpy or or and so on and I create my environment with Geeks shell so", "tokens": [50736, 1365, 38797, 5443, 494, 10023, 88, 297, 8814, 88, 420, 420, 293, 370, 322, 293, 286, 1884, 452, 2823, 365, 2876, 24785, 8720, 370, 51176], "temperature": 0.0, "avg_logprob": -0.29679667485224737, "compression_ratio": 1.6424581005586592, "no_speech_prob": 0.04903389513492584}, {"id": 56, "seek": 42472, "start": 440.96000000000004, "end": 450.6, "text": " this is nice then I can I can pin this graph and I apply Geeks describe and I pin the graph so now", "tokens": [51176, 341, 307, 1481, 550, 286, 393, 286, 393, 5447, 341, 4295, 293, 286, 3079, 2876, 24785, 6786, 293, 286, 5447, 264, 4295, 370, 586, 51658], "temperature": 0.0, "avg_logprob": -0.29679667485224737, "compression_ratio": 1.6424581005586592, "no_speech_prob": 0.04903389513492584}, {"id": 57, "seek": 45060, "start": 450.6, "end": 458.88, "text": " I have another file state-alice which pins this graph but collaboration is about sharing the", "tokens": [50364, 286, 362, 1071, 3991, 1785, 12, 304, 573, 597, 16392, 341, 4295, 457, 9363, 307, 466, 5414, 264, 50778], "temperature": 0.0, "avg_logprob": -0.21205478418068807, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.011679177172482014}, {"id": 58, "seek": 45060, "start": 458.88, "end": 465.92, "text": " computational environment so somewhere is sharing one specific graph so in fact if I share these", "tokens": [50778, 28270, 2823, 370, 4079, 307, 5414, 472, 2685, 4295, 370, 294, 1186, 498, 286, 2073, 613, 51130], "temperature": 0.0, "avg_logprob": -0.21205478418068807, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.011679177172482014}, {"id": 59, "seek": 45060, "start": 465.92, "end": 473.6, "text": " two files the manifest which describe the list of the tools and state-alice which describe the", "tokens": [51130, 732, 7098, 264, 10067, 597, 6786, 264, 1329, 295, 264, 3873, 293, 1785, 12, 304, 573, 597, 6786, 264, 51514], "temperature": 0.0, "avg_logprob": -0.21205478418068807, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.011679177172482014}, {"id": 60, "seek": 47360, "start": 473.6, "end": 486.36, "text": " state of the graph okay Blake my collaborator can spawn exactly the same computational environment", "tokens": [50364, 1785, 295, 264, 4295, 1392, 23451, 452, 5091, 1639, 393, 17088, 2293, 264, 912, 28270, 2823, 51002], "temperature": 0.0, "avg_logprob": -0.20424776077270507, "compression_ratio": 1.450381679389313, "no_speech_prob": 0.031646065413951874}, {"id": 61, "seek": 47360, "start": 486.36, "end": 494.32000000000005, "text": " using the Geeks time machine so you think that Blake and Alice are running exactly the same", "tokens": [51002, 1228, 264, 2876, 24785, 565, 3479, 370, 291, 519, 300, 23451, 293, 16004, 366, 2614, 2293, 264, 912, 51400], "temperature": 0.0, "avg_logprob": -0.20424776077270507, "compression_ratio": 1.450381679389313, "no_speech_prob": 0.031646065413951874}, {"id": 62, "seek": 49432, "start": 494.36, "end": 503.12, "text": " computational environment and if Carol also knows these two files Carol can run the exact", "tokens": [50366, 28270, 2823, 293, 498, 7925, 611, 3255, 613, 732, 7098, 7925, 393, 1190, 264, 1900, 50804], "temperature": 0.0, "avg_logprob": -0.21016491949558258, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.08452988415956497}, {"id": 63, "seek": 49432, "start": 503.12, "end": 510.64, "text": " same environment as Blake and Alice so here we have some things that it's really easy so on", "tokens": [50804, 912, 2823, 382, 23451, 293, 16004, 370, 510, 321, 362, 512, 721, 300, 309, 311, 534, 1858, 370, 322, 51180], "temperature": 0.0, "avg_logprob": -0.21016491949558258, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.08452988415956497}, {"id": 64, "seek": 49432, "start": 510.64, "end": 519.96, "text": " my laptop I write my I specify the tools that I need python or etc and I specify the state I'm", "tokens": [51180, 452, 10732, 286, 2464, 452, 286, 16500, 264, 3873, 300, 286, 643, 38797, 420, 5183, 293, 286, 16500, 264, 1785, 286, 478, 51646], "temperature": 0.0, "avg_logprob": -0.21016491949558258, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.08452988415956497}, {"id": 65, "seek": 51996, "start": 520.0, "end": 525.96, "text": " running on my on the laptop then I deploy on the cluster I use just transfer the two files and I run", "tokens": [50366, 2614, 322, 452, 322, 264, 10732, 550, 286, 7274, 322, 264, 13630, 286, 764, 445, 5003, 264, 732, 7098, 293, 286, 1190, 50664], "temperature": 0.0, "avg_logprob": -0.15409601818431506, "compression_ratio": 1.81651376146789, "no_speech_prob": 0.04176633059978485}, {"id": 66, "seek": 51996, "start": 525.96, "end": 532.0400000000001, "text": " this Geeks time machine command and on the cluster I have the exact same environment that I have on", "tokens": [50664, 341, 2876, 24785, 565, 3479, 5622, 293, 322, 264, 13630, 286, 362, 264, 1900, 912, 2823, 300, 286, 362, 322, 50968], "temperature": 0.0, "avg_logprob": -0.15409601818431506, "compression_ratio": 1.81651376146789, "no_speech_prob": 0.04176633059978485}, {"id": 67, "seek": 51996, "start": 532.0400000000001, "end": 536.64, "text": " my laptop so there is no question about what can be wrong between my laptop and the cluster because", "tokens": [50968, 452, 10732, 370, 456, 307, 572, 1168, 466, 437, 393, 312, 2085, 1296, 452, 10732, 293, 264, 13630, 570, 51198], "temperature": 0.0, "avg_logprob": -0.15409601818431506, "compression_ratio": 1.81651376146789, "no_speech_prob": 0.04176633059978485}, {"id": 68, "seek": 51996, "start": 536.64, "end": 543.4000000000001, "text": " it's exactly the same computational environment and this is a game changer when you are running", "tokens": [51198, 309, 311, 2293, 264, 912, 28270, 2823, 293, 341, 307, 257, 1216, 22822, 562, 291, 366, 2614, 51536], "temperature": 0.0, "avg_logprob": -0.15409601818431506, "compression_ratio": 1.81651376146789, "no_speech_prob": 0.04176633059978485}, {"id": 69, "seek": 54340, "start": 543.4, "end": 547.9599999999999, "text": " analysis on different machines where your colleagues are running in different places", "tokens": [50364, 5215, 322, 819, 8379, 689, 428, 7734, 366, 2614, 294, 819, 3190, 50592], "temperature": 0.0, "avg_logprob": -0.19764723316315683, "compression_ratio": 1.6171428571428572, "no_speech_prob": 0.02890932373702526}, {"id": 70, "seek": 54340, "start": 547.9599999999999, "end": 559.72, "text": " so Geeks this time machine provides a way to jump in different states temporarily so you can be I", "tokens": [50592, 370, 2876, 24785, 341, 565, 3479, 6417, 257, 636, 281, 3012, 294, 819, 4368, 23750, 370, 291, 393, 312, 286, 51180], "temperature": 0.0, "avg_logprob": -0.19764723316315683, "compression_ratio": 1.6171428571428572, "no_speech_prob": 0.02890932373702526}, {"id": 71, "seek": 54340, "start": 559.72, "end": 567.36, "text": " mean if you imagine you have the time and and and Alice and Blake or Carol are not on the same state", "tokens": [51180, 914, 498, 291, 3811, 291, 362, 264, 565, 293, 293, 293, 16004, 293, 23451, 420, 7925, 366, 406, 322, 264, 912, 1785, 51562], "temperature": 0.0, "avg_logprob": -0.19764723316315683, "compression_ratio": 1.6171428571428572, "no_speech_prob": 0.02890932373702526}, {"id": 72, "seek": 56736, "start": 568.2, "end": 575.48, "text": " compared to the time but they can jump artificially and temporarily to the same point in time to have", "tokens": [50406, 5347, 281, 264, 565, 457, 436, 393, 3012, 39905, 2270, 293, 23750, 281, 264, 912, 935, 294, 565, 281, 362, 50770], "temperature": 0.0, "avg_logprob": -0.18296886212898023, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.033119916915893555}, {"id": 73, "seek": 56736, "start": 575.48, "end": 585.52, "text": " the exact same computational environment and this is not possible with any other maybe next and so", "tokens": [50770, 264, 1900, 912, 28270, 2823, 293, 341, 307, 406, 1944, 365, 604, 661, 1310, 958, 293, 370, 51272], "temperature": 0.0, "avg_logprob": -0.18296886212898023, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.033119916915893555}, {"id": 74, "seek": 56736, "start": 585.52, "end": 592.04, "text": " this is kind of game-changing for me so to have that working very well you need to preserve all", "tokens": [51272, 341, 307, 733, 295, 1216, 12, 27123, 337, 385, 370, 281, 362, 300, 1364, 588, 731, 291, 643, 281, 15665, 439, 51598], "temperature": 0.0, "avg_logprob": -0.18296886212898023, "compression_ratio": 1.6353591160220995, "no_speech_prob": 0.033119916915893555}, {"id": 75, "seek": 59204, "start": 592.04, "end": 597.92, "text": " the source code and for that you need software heritage which is I took just after and you need", "tokens": [50364, 264, 4009, 3089, 293, 337, 300, 291, 643, 4722, 16040, 597, 307, 286, 1890, 445, 934, 293, 291, 643, 50658], "temperature": 0.0, "avg_logprob": -0.1812712725471048, "compression_ratio": 1.8086124401913874, "no_speech_prob": 0.02755521982908249}, {"id": 76, "seek": 59204, "start": 597.92, "end": 606.16, "text": " to have a backward compatibility of the Linux Linux kernel so and you also need to have some", "tokens": [50658, 281, 362, 257, 23897, 34237, 295, 264, 18734, 18734, 28256, 370, 293, 291, 611, 643, 281, 362, 512, 51070], "temperature": 0.0, "avg_logprob": -0.1812712725471048, "compression_ratio": 1.8086124401913874, "no_speech_prob": 0.02755521982908249}, {"id": 77, "seek": 59204, "start": 606.16, "end": 613.28, "text": " compatibility of hardware for example in five year we can if the hardware are not x86 yeah maybe", "tokens": [51070, 34237, 295, 8837, 337, 1365, 294, 1732, 1064, 321, 393, 498, 264, 8837, 366, 406, 2031, 22193, 1338, 1310, 51426], "temperature": 0.0, "avg_logprob": -0.1812712725471048, "compression_ratio": 1.8086124401913874, "no_speech_prob": 0.02755521982908249}, {"id": 78, "seek": 59204, "start": 613.28, "end": 617.68, "text": " we cannot jump it back in time but if you have compatibility of that where we have this that", "tokens": [51426, 321, 2644, 3012, 309, 646, 294, 565, 457, 498, 291, 362, 34237, 295, 300, 689, 321, 362, 341, 300, 51646], "temperature": 0.0, "avg_logprob": -0.1812712725471048, "compression_ratio": 1.8086124401913874, "no_speech_prob": 0.02755521982908249}, {"id": 79, "seek": 61768, "start": 617.7199999999999, "end": 625.8399999999999, "text": " work and the question is what we have this size where these three conditions are satisfied so now", "tokens": [50366, 589, 293, 264, 1168, 307, 437, 321, 362, 341, 2744, 689, 613, 1045, 4487, 366, 11239, 370, 586, 50772], "temperature": 0.0, "avg_logprob": -0.22546097726532907, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.046675246208906174}, {"id": 80, "seek": 61768, "start": 625.8399999999999, "end": 632.16, "text": " we have for example this condition and what is the size of this window and from my point of view", "tokens": [50772, 321, 362, 337, 1365, 341, 4188, 293, 437, 307, 264, 2744, 295, 341, 4910, 293, 490, 452, 935, 295, 1910, 51088], "temperature": 0.0, "avg_logprob": -0.22546097726532907, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.046675246208906174}, {"id": 81, "seek": 61768, "start": 632.16, "end": 644.28, "text": " Geeks is running a quasi unique experiment at I mean real-world experiment a large since 2019 so", "tokens": [51088, 2876, 24785, 307, 2614, 257, 20954, 3845, 5120, 412, 286, 914, 957, 12, 13217, 5120, 257, 2416, 1670, 6071, 370, 51694], "temperature": 0.0, "avg_logprob": -0.22546097726532907, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.046675246208906174}, {"id": 82, "seek": 64428, "start": 644.3199999999999, "end": 650.28, "text": " we will see that this size maybe in five years we will try to to redo something from now and we", "tokens": [50366, 321, 486, 536, 300, 341, 2744, 1310, 294, 1732, 924, 321, 486, 853, 281, 281, 29956, 746, 490, 586, 293, 321, 50664], "temperature": 0.0, "avg_logprob": -0.20205810222219914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 0.0048089041374623775}, {"id": 83, "seek": 64428, "start": 650.28, "end": 656.52, "text": " will fail because something that we but we have this mechanism able to jump in different point in", "tokens": [50664, 486, 3061, 570, 746, 300, 321, 457, 321, 362, 341, 7513, 1075, 281, 3012, 294, 819, 935, 294, 50976], "temperature": 0.0, "avg_logprob": -0.20205810222219914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 0.0048089041374623775}, {"id": 84, "seek": 64428, "start": 656.52, "end": 666.28, "text": " time so software heritage is a long-term source code archive so you collect and preserve all the", "tokens": [50976, 565, 370, 4722, 16040, 307, 257, 938, 12, 7039, 4009, 3089, 23507, 370, 291, 2500, 293, 15665, 439, 264, 51464], "temperature": 0.0, "avg_logprob": -0.20205810222219914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 0.0048089041374623775}, {"id": 85, "seek": 64428, "start": 666.28, "end": 673.64, "text": " source code of the world I mean open source code of the world so all github githlab debian and so on", "tokens": [51464, 4009, 3089, 295, 264, 1002, 286, 914, 1269, 4009, 3089, 295, 264, 1002, 370, 439, 290, 355, 836, 290, 355, 44990, 3001, 952, 293, 370, 322, 51832], "temperature": 0.0, "avg_logprob": -0.20205810222219914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 0.0048089041374623775}, {"id": 86, "seek": 67364, "start": 674.36, "end": 680.08, "text": " and geeks is able to to save the code of the geek package definition so for example the source", "tokens": [50400, 293, 1519, 24785, 307, 1075, 281, 281, 3155, 264, 3089, 295, 264, 36162, 7372, 7123, 370, 337, 1365, 264, 4009, 50686], "temperature": 0.0, "avg_logprob": -0.19017680307452597, "compression_ratio": 1.96875, "no_speech_prob": 0.009312492795288563}, {"id": 87, "seek": 67364, "start": 680.08, "end": 688.8, "text": " code of DCC you can geeks use the source code of DCC coming from internet but you can save this", "tokens": [50686, 3089, 295, 9114, 34, 291, 393, 1519, 24785, 764, 264, 4009, 3089, 295, 9114, 34, 1348, 490, 4705, 457, 291, 393, 3155, 341, 51122], "temperature": 0.0, "avg_logprob": -0.19017680307452597, "compression_ratio": 1.96875, "no_speech_prob": 0.009312492795288563}, {"id": 88, "seek": 67364, "start": 688.8, "end": 694.48, "text": " directly to to software heritage and the package definition itself and what is really nice is", "tokens": [51122, 3838, 281, 281, 4722, 16040, 293, 264, 7372, 7123, 2564, 293, 437, 307, 534, 1481, 307, 51406], "temperature": 0.0, "avg_logprob": -0.19017680307452597, "compression_ratio": 1.96875, "no_speech_prob": 0.009312492795288563}, {"id": 89, "seek": 67364, "start": 694.48, "end": 700.36, "text": " that geeks is able to to fall back if the source disappears so for example you have a product", "tokens": [51406, 300, 1519, 24785, 307, 1075, 281, 281, 2100, 646, 498, 264, 4009, 25527, 370, 337, 1365, 291, 362, 257, 1674, 51700], "temperature": 0.0, "avg_logprob": -0.19017680307452597, "compression_ratio": 1.96875, "no_speech_prob": 0.009312492795288563}, {"id": 90, "seek": 70036, "start": 700.92, "end": 709.4, "text": " if tomorrow github is down for whatever reason all the paper published with with the line my script", "tokens": [50392, 498, 4153, 290, 355, 836, 307, 760, 337, 2035, 1778, 439, 264, 3035, 6572, 365, 365, 264, 1622, 452, 5755, 50816], "temperature": 0.0, "avg_logprob": -0.2195411173502604, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.041090186685323715}, {"id": 91, "seek": 70036, "start": 709.4, "end": 719.16, "text": " is on github and the package is on on github and github is down like githulite I don't remember", "tokens": [50816, 307, 322, 290, 355, 836, 293, 264, 7372, 307, 322, 322, 290, 355, 836, 293, 290, 355, 836, 307, 760, 411, 290, 355, 425, 642, 286, 500, 380, 1604, 51304], "temperature": 0.0, "avg_logprob": -0.2195411173502604, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.041090186685323715}, {"id": 92, "seek": 70036, "start": 719.16, "end": 727.4, "text": " the name there is many popular platforms that are down and all all break and with this mechanism", "tokens": [51304, 264, 1315, 456, 307, 867, 3743, 9473, 300, 366, 760, 293, 439, 439, 1821, 293, 365, 341, 7513, 51716], "temperature": 0.0, "avg_logprob": -0.2195411173502604, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.041090186685323715}, {"id": 93, "seek": 72740, "start": 728.1999999999999, "end": 746.04, "text": " it is doesn't break so I have five minutes right okay so just geeks is able to so geeks", "tokens": [50404, 309, 307, 1177, 380, 1821, 370, 286, 362, 1732, 2077, 558, 1392, 370, 445, 1519, 24785, 307, 1075, 281, 370, 1519, 24785, 51296], "temperature": 0.0, "avg_logprob": -0.15334323048591614, "compression_ratio": 1.4365079365079365, "no_speech_prob": 0.010028563439846039}, {"id": 94, "seek": 72740, "start": 746.04, "end": 753.72, "text": " is able to pack everything so you can produce a docker image with geeks so using the manifest", "tokens": [51296, 307, 1075, 281, 2844, 1203, 370, 291, 393, 5258, 257, 360, 9178, 3256, 365, 1519, 24785, 370, 1228, 264, 10067, 51680], "temperature": 0.0, "avg_logprob": -0.15334323048591614, "compression_ratio": 1.4365079365079365, "no_speech_prob": 0.010028563439846039}, {"id": 95, "seek": 75372, "start": 753.8000000000001, "end": 759.88, "text": " you use geeks pack and geeks pack generate the docker image and then if Blake doesn't run geeks", "tokens": [50368, 291, 764, 1519, 24785, 2844, 293, 1519, 24785, 2844, 8460, 264, 360, 9178, 3256, 293, 550, 498, 23451, 1177, 380, 1190, 1519, 24785, 50672], "temperature": 0.0, "avg_logprob": -0.10295578638712564, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.033885810524225235}, {"id": 96, "seek": 75372, "start": 761.08, "end": 767.08, "text": " she can run the docker and the binary inside the docker are exactly the same than the binary", "tokens": [50732, 750, 393, 1190, 264, 360, 9178, 293, 264, 17434, 1854, 264, 360, 9178, 366, 2293, 264, 912, 813, 264, 17434, 51032], "temperature": 0.0, "avg_logprob": -0.10295578638712564, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.033885810524225235}, {"id": 97, "seek": 75372, "start": 767.08, "end": 772.6800000000001, "text": " inside the computational environment of Alice and because of the time machine this is reproducible", "tokens": [51032, 1854, 264, 28270, 2823, 295, 16004, 293, 570, 295, 264, 565, 3479, 341, 307, 11408, 32128, 51312], "temperature": 0.0, "avg_logprob": -0.10295578638712564, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.033885810524225235}, {"id": 98, "seek": 75372, "start": 772.6800000000001, "end": 781.8000000000001, "text": " over the time and this is also a kind of game changing in science and in fact a container it's", "tokens": [51312, 670, 264, 565, 293, 341, 307, 611, 257, 733, 295, 1216, 4473, 294, 3497, 293, 294, 1186, 257, 10129, 309, 311, 51768], "temperature": 0.0, "avg_logprob": -0.10295578638712564, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.033885810524225235}, {"id": 99, "seek": 78180, "start": 781.8, "end": 788.8399999999999, "text": " just a format of the archive and geeks is an austic about this container format so you can", "tokens": [50364, 445, 257, 7877, 295, 264, 23507, 293, 1519, 24785, 307, 364, 34916, 299, 466, 341, 10129, 7877, 370, 291, 393, 50716], "temperature": 0.0, "avg_logprob": -0.16925248867127954, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.008170942775905132}, {"id": 100, "seek": 78180, "start": 788.8399999999999, "end": 795.4, "text": " generate torbol docker singularity there is an experimental debian binary package and yesterday", "tokens": [50716, 8460, 3930, 17460, 360, 9178, 20010, 507, 456, 307, 364, 17069, 3001, 952, 17434, 7372, 293, 5186, 51044], "temperature": 0.0, "avg_logprob": -0.16925248867127954, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.008170942775905132}, {"id": 101, "seek": 78180, "start": 795.4, "end": 803.0, "text": " evening there is a patch about supporting rpm package so this is just flexible to every", "tokens": [51044, 5634, 456, 307, 257, 9972, 466, 7231, 367, 14395, 7372, 370, 341, 307, 445, 11358, 281, 633, 51424], "temperature": 0.0, "avg_logprob": -0.16925248867127954, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.008170942775905132}, {"id": 102, "seek": 78180, "start": 803.7199999999999, "end": 810.04, "text": " context the key point is to to fully control the binary going inside the container and geeks", "tokens": [51460, 4319, 264, 2141, 935, 307, 281, 281, 4498, 1969, 264, 17434, 516, 1854, 264, 10129, 293, 1519, 24785, 51776], "temperature": 0.0, "avg_logprob": -0.16925248867127954, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.008170942775905132}, {"id": 103, "seek": 81004, "start": 810.04, "end": 813.48, "text": " does this job so this way it's a factory for creating images", "tokens": [50364, 775, 341, 1691, 370, 341, 636, 309, 311, 257, 9265, 337, 4084, 5267, 50536], "temperature": 0.0, "avg_logprob": -0.0867584747604177, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.0033385648857802153}, {"id": 104, "seek": 81004, "start": 815.7199999999999, "end": 821.64, "text": " so geeks is helping me because there is three commands and two files so this is really easy", "tokens": [50648, 370, 1519, 24785, 307, 4315, 385, 570, 456, 307, 1045, 16901, 293, 732, 7098, 370, 341, 307, 534, 1858, 50944], "temperature": 0.0, "avg_logprob": -0.0867584747604177, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.0033385648857802153}, {"id": 105, "seek": 81004, "start": 821.64, "end": 829.16, "text": " to explain to for example medical doctor and and so on and it's a packing factory when I can deploy", "tokens": [50944, 281, 2903, 281, 337, 1365, 4625, 4631, 293, 293, 370, 322, 293, 309, 311, 257, 20815, 9265, 562, 286, 393, 7274, 51320], "temperature": 0.0, "avg_logprob": -0.0867584747604177, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.0033385648857802153}, {"id": 106, "seek": 81004, "start": 829.16, "end": 833.8, "text": " on infrastructure where geeks is not running for sharing computational environment and for me this", "tokens": [51320, 322, 6896, 689, 1519, 24785, 307, 406, 2614, 337, 5414, 28270, 2823, 293, 337, 385, 341, 51552], "temperature": 0.0, "avg_logprob": -0.0867584747604177, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.0033385648857802153}, {"id": 107, "seek": 83380, "start": 833.8, "end": 844.04, "text": " is a two key for two keys for for for open science research and so on and if you want more", "tokens": [50364, 307, 257, 732, 2141, 337, 732, 9317, 337, 337, 337, 1269, 3497, 2132, 293, 370, 322, 293, 498, 291, 528, 544, 50876], "temperature": 0.0, "avg_logprob": -0.12469763369173617, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.012327916920185089}, {"id": 108, "seek": 83380, "start": 845.88, "end": 852.12, "text": " information there is a this group geeks hpc but it's like many things in geeks the name is not", "tokens": [50968, 1589, 456, 307, 257, 341, 1594, 1519, 24785, 34064, 66, 457, 309, 311, 411, 867, 721, 294, 1519, 24785, 264, 1315, 307, 406, 51280], "temperature": 0.0, "avg_logprob": -0.12469763369173617, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.012327916920185089}, {"id": 109, "seek": 83380, "start": 852.12, "end": 857.4799999999999, "text": " good because it's more like geeks for science than not specific to geeks hpcs geeks for scientific", "tokens": [51280, 665, 570, 309, 311, 544, 411, 1519, 24785, 337, 3497, 813, 406, 2685, 281, 1519, 24785, 34064, 14368, 1519, 24785, 337, 8134, 51548], "temperature": 0.0, "avg_logprob": -0.12469763369173617, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.012327916920185089}, {"id": 110, "seek": 85748, "start": 857.8000000000001, "end": 867.24, "text": " and okay and it's running production so don't be afraid to install geeks I mean it's a there is", "tokens": [50380, 293, 1392, 293, 309, 311, 2614, 4265, 370, 500, 380, 312, 4638, 281, 3625, 1519, 24785, 286, 914, 309, 311, 257, 456, 307, 50852], "temperature": 0.0, "avg_logprob": -0.18834784189860027, "compression_ratio": 1.6954022988505748, "no_speech_prob": 0.007943054661154747}, {"id": 111, "seek": 85748, "start": 867.24, "end": 873.88, "text": " all this cluster running already geeks more all the laptops and desktop so it's now it's in production", "tokens": [50852, 439, 341, 13630, 2614, 1217, 1519, 24785, 544, 439, 264, 27642, 293, 14502, 370, 309, 311, 586, 309, 311, 294, 4265, 51184], "temperature": 0.0, "avg_logprob": -0.18834784189860027, "compression_ratio": 1.6954022988505748, "no_speech_prob": 0.007943054661154747}, {"id": 112, "seek": 85748, "start": 875.72, "end": 884.76, "text": " so yeah this is uh I mean why the picture geeks and and and science that I would like to have in", "tokens": [51276, 370, 1338, 341, 307, 2232, 286, 914, 983, 264, 3036, 1519, 24785, 293, 293, 293, 3497, 300, 286, 576, 411, 281, 362, 294, 51728], "temperature": 0.0, "avg_logprob": -0.18834784189860027, "compression_ratio": 1.6954022988505748, "no_speech_prob": 0.007943054661154747}, {"id": 113, "seek": 88476, "start": 884.84, "end": 887.56, "text": " in the future so thanks", "tokens": [50368, 294, 264, 2027, 370, 3231, 50504], "temperature": 0.0, "avg_logprob": -0.45546718077226117, "compression_ratio": 1.1076923076923078, "no_speech_prob": 0.007756842765957117}, {"id": 114, "seek": 88476, "start": 901.3199999999999, "end": 906.2, "text": " so uh yeah but yeah yeah if you're the first one", "tokens": [51192, 370, 2232, 1338, 457, 1338, 1338, 498, 291, 434, 264, 700, 472, 51436], "temperature": 0.0, "avg_logprob": -0.45546718077226117, "compression_ratio": 1.1076923076923078, "no_speech_prob": 0.007756842765957117}, {"id": 115, "seek": 91476, "start": 915.0, "end": 921.96, "text": " scientists but for example the scientists uh we are trying to reuse uh they can use for example", "tokens": [50376, 7708, 457, 337, 1365, 264, 7708, 2232, 321, 366, 1382, 281, 26225, 2232, 436, 393, 764, 337, 1365, 50724], "temperature": 0.0, "avg_logprob": -0.2603675066414526, "compression_ratio": 1.7341772151898733, "no_speech_prob": 0.22037702798843384}, {"id": 116, "seek": 91476, "start": 921.96, "end": 931.16, "text": " different uh kind different cpu or different architecture how much some kind of uh optimizations", "tokens": [50724, 819, 2232, 733, 819, 269, 34859, 420, 819, 9482, 577, 709, 512, 733, 295, 2232, 5028, 14455, 51184], "temperature": 0.0, "avg_logprob": -0.2603675066414526, "compression_ratio": 1.7341772151898733, "no_speech_prob": 0.22037702798843384}, {"id": 117, "seek": 91476, "start": 931.16, "end": 937.88, "text": " for particular cpu can have a impact on having different results can it just like", "tokens": [51184, 337, 1729, 269, 34859, 393, 362, 257, 2712, 322, 1419, 819, 3542, 393, 309, 445, 411, 51520], "temperature": 0.0, "avg_logprob": -0.2603675066414526, "compression_ratio": 1.7341772151898733, "no_speech_prob": 0.22037702798843384}, {"id": 118, "seek": 93788, "start": 938.68, "end": 945.64, "text": " ruin a whole idea they can can they really like if you have idea like how much impact", "tokens": [50404, 15514, 257, 1379, 1558, 436, 393, 393, 436, 534, 411, 498, 291, 362, 1558, 411, 577, 709, 2712, 50752], "temperature": 0.0, "avg_logprob": -0.17726524805618546, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.006132906768471003}, {"id": 119, "seek": 93788, "start": 947.16, "end": 958.12, "text": " so I have to repeat the question so the question is the so in hpc context you have", "tokens": [50828, 370, 286, 362, 281, 7149, 264, 1168, 370, 264, 1168, 307, 264, 370, 294, 34064, 66, 4319, 291, 362, 51376], "temperature": 0.0, "avg_logprob": -0.17726524805618546, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.006132906768471003}, {"id": 120, "seek": 93788, "start": 961.08, "end": 965.16, "text": " you have performance that depends on the architecture and you can have micro optimization", "tokens": [51524, 291, 362, 3389, 300, 5946, 322, 264, 9482, 293, 291, 393, 362, 4532, 19618, 51728], "temperature": 0.0, "avg_logprob": -0.17726524805618546, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.006132906768471003}, {"id": 121, "seek": 96516, "start": 965.16, "end": 970.68, "text": " for specific architecture so how geeks deal with that for the first question and how will", "tokens": [50364, 337, 2685, 9482, 370, 577, 1519, 24785, 2028, 365, 300, 337, 264, 700, 1168, 293, 577, 486, 50640], "temperature": 0.0, "avg_logprob": -0.20168375357603416, "compression_ratio": 1.75, "no_speech_prob": 0.03293833136558533}, {"id": 122, "seek": 96516, "start": 970.68, "end": 975.0, "text": " we do that for reproducibility is the second question I think from my understanding is the two", "tokens": [50640, 321, 360, 300, 337, 11408, 537, 39802, 307, 264, 1150, 1168, 286, 519, 490, 452, 3701, 307, 264, 732, 50856], "temperature": 0.0, "avg_logprob": -0.20168375357603416, "compression_ratio": 1.75, "no_speech_prob": 0.03293833136558533}, {"id": 123, "seek": 96516, "start": 975.0, "end": 987.8, "text": " question I don't know the difference of the performances about the the micro optimization", "tokens": [50856, 1168, 286, 500, 380, 458, 264, 2649, 295, 264, 16087, 466, 264, 264, 4532, 19618, 51496], "temperature": 0.0, "avg_logprob": -0.20168375357603416, "compression_ratio": 1.75, "no_speech_prob": 0.03293833136558533}, {"id": 124, "seek": 96516, "start": 987.8, "end": 994.36, "text": " this is a job of the researcher in the field to say this micro optimization provides this", "tokens": [51496, 341, 307, 257, 1691, 295, 264, 21751, 294, 264, 2519, 281, 584, 341, 4532, 19618, 6417, 341, 51824], "temperature": 0.0, "avg_logprob": -0.20168375357603416, "compression_ratio": 1.75, "no_speech_prob": 0.03293833136558533}, {"id": 125, "seek": 99436, "start": 994.36, "end": 1001.48, "text": " performance improvement what I can say what geeks does to manage this micro optimization so", "tokens": [50364, 3389, 10444, 437, 286, 393, 584, 437, 1519, 24785, 775, 281, 3067, 341, 4532, 19618, 370, 50720], "temperature": 0.0, "avg_logprob": -0.21137210934661155, "compression_ratio": 1.453125, "no_speech_prob": 0.016358524560928345}, {"id": 126, "seek": 99436, "start": 1002.12, "end": 1010.36, "text": " Ludo is is is giving a talk in hpc dev room about the the the tune package transformation that", "tokens": [50752, 441, 6207, 307, 307, 307, 2902, 257, 751, 294, 34064, 66, 1905, 1808, 466, 264, 264, 264, 10864, 7372, 9887, 300, 51164], "temperature": 0.0, "avg_logprob": -0.21137210934661155, "compression_ratio": 1.453125, "no_speech_prob": 0.016358524560928345}, {"id": 127, "seek": 101036, "start": 1010.36, "end": 1026.68, "text": " I can ask when we are speaking about reproducibility we can ask if this micro", "tokens": [50364, 286, 393, 1029, 562, 321, 366, 4124, 466, 11408, 537, 39802, 321, 393, 1029, 498, 341, 4532, 51180], "temperature": 0.0, "avg_logprob": -0.22993965502138491, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.010142483748495579}, {"id": 128, "seek": 101036, "start": 1026.68, "end": 1033.16, "text": " micro optimization or I mean our fit the reproducible and the scientific method", "tokens": [51180, 4532, 19618, 420, 286, 914, 527, 3318, 264, 11408, 32128, 293, 264, 8134, 3170, 51504], "temperature": 0.0, "avg_logprob": -0.22993965502138491, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.010142483748495579}, {"id": 129, "seek": 101036, "start": 1033.16, "end": 1036.44, "text": " so I don't have the answer but at some at some point I think", "tokens": [51504, 370, 286, 500, 380, 362, 264, 1867, 457, 412, 512, 412, 512, 935, 286, 519, 51668], "temperature": 0.0, "avg_logprob": -0.22993965502138491, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.010142483748495579}, {"id": 130, "seek": 103644, "start": 1037.3200000000002, "end": 1043.72, "text": " is it worth to have a micro optimization for I mean having something like a couple of percent", "tokens": [50408, 307, 309, 3163, 281, 362, 257, 4532, 19618, 337, 286, 914, 1419, 746, 411, 257, 1916, 295, 3043, 50728], "temperature": 0.0, "avg_logprob": -0.09661449603180387, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.017628230154514313}, {"id": 131, "seek": 103644, "start": 1043.72, "end": 1049.96, "text": " of improvement but we lose all the reproducibility we lose the way to check that the computation is", "tokens": [50728, 295, 10444, 457, 321, 3624, 439, 264, 11408, 537, 39802, 321, 3624, 264, 636, 281, 1520, 300, 264, 24903, 307, 51040], "temperature": 0.0, "avg_logprob": -0.09661449603180387, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.017628230154514313}, {"id": 132, "seek": 103644, "start": 1049.96, "end": 1054.6000000000001, "text": " correct so I don't know if it's I mean this is a question for a collective question for the", "tokens": [51040, 3006, 370, 286, 500, 380, 458, 498, 309, 311, 286, 914, 341, 307, 257, 1168, 337, 257, 12590, 1168, 337, 264, 51272], "temperature": 0.0, "avg_logprob": -0.09661449603180387, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.017628230154514313}, {"id": 133, "seek": 105460, "start": 1054.6, "end": 1058.76, "text": " researcher in general so there is a question", "tokens": [50364, 21751, 294, 2674, 370, 456, 307, 257, 1168, 50572], "temperature": 0.0, "avg_logprob": -0.1243686242537065, "compression_ratio": 1.4329896907216495, "no_speech_prob": 0.054035767912864685}, {"id": 134, "seek": 105460, "start": 1077.8, "end": 1083.1599999999999, "text": " so the question is is it enough or not to have all this machinery to have reproducible science", "tokens": [51524, 370, 264, 1168, 307, 307, 309, 1547, 420, 406, 281, 362, 439, 341, 27302, 281, 362, 11408, 32128, 3497, 51792], "temperature": 0.0, "avg_logprob": -0.1243686242537065, "compression_ratio": 1.4329896907216495, "no_speech_prob": 0.054035767912864685}, {"id": 135, "seek": 108316, "start": 1083.88, "end": 1091.5600000000002, "text": " so the answer is I don't know because I mean if to have the answer is that everybody should", "tokens": [50400, 370, 264, 1867, 307, 286, 500, 380, 458, 570, 286, 914, 498, 281, 362, 264, 1867, 307, 300, 2201, 820, 50784], "temperature": 0.0, "avg_logprob": -0.19276704626568295, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.017465051263570786}, {"id": 136, "seek": 108316, "start": 1091.5600000000002, "end": 1100.2, "text": " run this to be be sure that he's in case or not so I don't know and the I don't remember what I want", "tokens": [50784, 1190, 341, 281, 312, 312, 988, 300, 415, 311, 294, 1389, 420, 406, 370, 286, 500, 380, 458, 293, 264, 286, 500, 380, 1604, 437, 286, 528, 51216], "temperature": 0.0, "avg_logprob": -0.19276704626568295, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.017465051263570786}, {"id": 137, "seek": 108316, "start": 1100.2, "end": 1101.48, "text": " to say about that", "tokens": [51216, 281, 584, 466, 300, 51280], "temperature": 0.0, "avg_logprob": -0.19276704626568295, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.017465051263570786}, {"id": 138, "seek": 110148, "start": 1102.04, "end": 1120.6, "text": " I mean I don't show here but there is a paper published with this method and yeah there is more", "tokens": [50392, 286, 914, 286, 500, 380, 855, 510, 457, 456, 307, 257, 3035, 6572, 365, 341, 3170, 293, 1338, 456, 307, 544, 51320], "temperature": 0.0, "avg_logprob": -0.2963400292903819, "compression_ratio": 1.528, "no_speech_prob": 0.05150533467531204}, {"id": 139, "seek": 110148, "start": 1120.6, "end": 1129.32, "text": " reproducibility than than the other but at some point the the the the software is just one part", "tokens": [51320, 11408, 537, 39802, 813, 813, 264, 661, 457, 412, 512, 935, 264, 264, 264, 264, 4722, 307, 445, 472, 644, 51756], "temperature": 0.0, "avg_logprob": -0.2963400292903819, "compression_ratio": 1.528, "no_speech_prob": 0.05150533467531204}, {"id": 140, "seek": 112932, "start": 1129.32, "end": 1135.8, "text": " of the big picture of the reproducibility issue in in in science and in fact is a is a is a is a", "tokens": [50364, 295, 264, 955, 3036, 295, 264, 11408, 537, 39802, 2734, 294, 294, 294, 3497, 293, 294, 1186, 307, 257, 307, 257, 307, 257, 307, 257, 50688], "temperature": 0.0, "avg_logprob": -0.1703351153883823, "compression_ratio": 1.8341708542713568, "no_speech_prob": 0.05891019105911255}, {"id": 141, "seek": 112932, "start": 1135.8, "end": 1144.36, "text": " collective practice in fact because you for example I'm trying to reproduce the paper from", "tokens": [50688, 12590, 3124, 294, 1186, 570, 291, 337, 1365, 286, 478, 1382, 281, 29501, 264, 3035, 490, 51116], "temperature": 0.0, "avg_logprob": -0.1703351153883823, "compression_ratio": 1.8341708542713568, "no_speech_prob": 0.05891019105911255}, {"id": 142, "seek": 112932, "start": 1144.36, "end": 1151.48, "text": " August this August and some data are missing the script are missing the the package that's", "tokens": [51116, 6897, 341, 6897, 293, 512, 1412, 366, 5361, 264, 5755, 366, 5361, 264, 264, 7372, 300, 311, 51472], "temperature": 0.0, "avg_logprob": -0.1703351153883823, "compression_ratio": 1.8341708542713568, "no_speech_prob": 0.05891019105911255}, {"id": 143, "seek": 112932, "start": 1151.48, "end": 1158.84, "text": " been used are missing so so I cannot reproduce and this is not geeks it's just because", "tokens": [51472, 668, 1143, 366, 5361, 370, 370, 286, 2644, 29501, 293, 341, 307, 406, 1519, 24785, 309, 311, 445, 570, 51840], "temperature": 0.0, "avg_logprob": -0.1703351153883823, "compression_ratio": 1.8341708542713568, "no_speech_prob": 0.05891019105911255}, {"id": 144, "seek": 115932, "start": 1159.32, "end": 1163.32, "text": " publisher didn't good job thanks everybody", "tokens": [50384, 25088, 994, 380, 665, 1691, 3231, 2201, 50564], "temperature": 0.0, "avg_logprob": -0.3390537977218628, "compression_ratio": 0.84, "no_speech_prob": 0.01211455650627613}], "language": "en"}