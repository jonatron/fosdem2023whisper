{"text": " Hi everybody, welcome to my presentation about Kaitai struct. I am Peter Pucil and I have a question. How many of you have any experience with Kaitai? Okay, there are a few of you. What is Kaitai struct? It's a tool for dealing with binary formats, especially parsing. It is based on a declarative language, Kaitai struct YAML, that can be used to specify arbitrary binary formats. It works as a parse generator and it currently supports 11 target programming languages. Parsing means to convert the binary data you see above to the structure data and object tree so that you can work with it later. Today I will also introduce a new functionality, which is serialization. I've been working on it for the last six months and it currently works in Java. Serialization means, I didn't mention that, that basically the inverse process. You want to create a binary file from an object tree. Something about this story. So the author of Kaitai struct is Michael Action and the project started in 2014. In 2016, Michael decided to release the project as open source and at that time the only supported languages were Java and TrueWe. In 2017, Michael presented Kaitai struct at FOSDEM and by then it already supported eight languages and had over 400 stars on GitHub. Michael also wanted to come today but unfortunately he couldn't. But if there is some chat or something, I think he should be there so you can ask him some questions or whatever. And how is it today? So we have 11 target languages and over 3,000 stars on GitHub and Kaitai is used in more than 500 GitHub projects. So let me share how I discovered Kaitai struct. This was in 2019 and I was playing electronic keyboard with a band and I wanted to create a MIDI editor so that I could record the songs on the keyboard and edit them on the computer. And I wanted the user to be able to upload a sound bank in the sound font to binary format so that they could control how the song could sound. And I wanted a web-based MIDI editor so I searched for a JavaScript parsing library of the.sf2 format but I couldn't find one that would work for me. So I started writing my own parser but it was really hard and a lot of debugging had to be done and it was just not fun. And when I finished I came across Kaitai struct and I found that my two months of work I spent on this could be done in just one day with Kaitai. So Kaitai impressed me with its concept, simplicity and versatility and I started contributing a lot. And Kaitai also helped me my personal development because until then I'd only programmed in JavaScript, PHP and a little bit of Python and within a few months I was able to work in 14 programming languages that were used in Kaitai. And in 2020 I accepted an offer from Michael to become an administrator of the project. So in my story I showed what options there are to get a parser. So the most convenient way that you are probably familiar with is to use a dedicated format library in the given language. So it will probably have a user-friendly API and can be optimized for a format. But sometimes it may be of poor quality and incomplete and it may be difficult to debug and fix it. And also for the most common formats like JPEG, L for zip, you can find even several libraries and you can choose, but for less common formats, some obscure ones, there will simply be no library in your language. So we need to look into other options and another option is to simply write your own parser. But in my experience this is the worst option because it takes a lot of time and you need to do a lot of debugging using some debug brains and dumps and it's just not fun. But it's what most people do, often because they just don't know any better. So that's why I'm here today. And well, the problem is that if you have already written a parser for your format in Python, for example, and then after some time you are asked to create a Java parser for the same format, you basically need to start again. So a bit better way is to use a parser combinator, which means that you are essentially still writing your own parser, but you are using some building blocks from a library. And a parser combinator typically allows you to declaratively define some sub structures, but still in the code and like in CU can define structs for the fixed size pieces of the format and then you can directly interpret some block of bytes with that struct. And there are many parser combinators, perhaps dozens in popular languages, but as with the two previous options, you have still the disadvantage that the parser you get this way is still bound to the particular language. And it may be even bound to an application. For example, if it was developed for a graphical editor, so it may be difficult to separate just a parser from that application to use it somewhere else. And the fourth option is to use a parser generator, which means that you are not writing the parsing code directly in the programming language, but instead you describe it in a domain, describe the format structure in a domain-specific language, and this description can be then automatically translated into a parser. So, KeitaStruck falls into this category and it is the KeitaStruck language is designed so that it's independent of both the application and the programming language. Here I'll show you how to work with Keita. The first stage is compilation. So you take this KeitaStruck specification of the format and in this case, this is a format that has one byte because this U1 type means unsigned integer of one byte. And you take this KeitaStruck specification and you compile it using the KeitaStruck compiler, which is a command line tool. And as output, you get the source code of the parser, in this case in Python. The main stage is parsing. You take, you give the input binary file to the generated parser. You get in the first step and you give the input binary file to the parser as input and you get parsed data as output, so an object tree. And in case of KeitaStruck, the generated parser works with the runtime library so you need to include it also into your application. Why use Keita? What are the advantages? So as I already mentioned, the advantage is that you write the KSY specification once and you can use it everywhere. It standardizes the way we describe binary formats and there are already many formats described in the Keita format gallery and any described format can be visualized automatically in a Gravis diagram and the KeitaStruck language is simple, you will see. There are also several visualization and dumping tool available in KeitaStruck. So the write once use everywhere feature means that you get parses in 11 programming languages for free from a single KSY specification. So in this case, I've had the compiler generate Java, Python and Ruby parsers from a simple KSY specification you see on the left. When you look for specifications of binary formats, you will find that each one looks different and there is no single standard to how to document formats and Keita is used or intended primarily for creating parses but some people write KSY specification just to document a format in an easy to understand way because you don't even have to be a programmer to understand a KSY specification and it's often easier than to read these long PDF documents. And the Keita project includes an extensive gallery of described formats. At the moment, there are 181 formats described by 76 contributors and there are also several hundreds more format specifications in various Keita projects. And so the Keita format gallery contains formats of various kinds, for example, as you see archive files, for example, executables, file systems, game data files, multimedia files and network protocols, you can go to this page and I took it from there. And this suggests the wide applicability of Keita. And it offers an idea to create an international database of formats where various obscure and historical formats would be documented in a uniform way for future preservation. And this would guarantee that we could basically, we could read the binary files we write now in like 100 or 200 years from now. The fact that the Keita extract language is declarative makes it possible to automatically visualize it, visualize the described format in a Gravis diagram. The Keita extract language is simple but powerful. You can describe pretty much any binary format with it. And a case one specification starts with the meta section and this sets the little end in byte order as default. The SEQ section is a sequence of attributes. The attribute name is in the ID key. The type U4 means that in this case num underscore files will be an unsigned for byte integer. You can define your own types in the type section. A field can also be repeated. So in this case the files attribute will be a list or an array of base type file. In the instances section you can define attributes that start at an arbitrary byte position. You can also use a powerful expression language in many places. And there is another built-in type is a character string in a certain encoding. And if you omit the type and only specify the size, the result is a byte array. There are several visualization and dumping tools available for inspecting files. And this can be useful for, for example, for finding errors, forensic analysis, or debugging. And the visualizers allow us to view the structured data parts from the input file based on a kitesh track specification, so something like this. And you can use the console visualizer or also the command line to case dump is available, which can give you the same structured data as you can see in JSON format. And this can be useful for automation. But the most popular visualization tool is the Web IDE. You can check it out on this URL. And at the top right is a hex-dump of the input binary file. So in this case I selected this.png file in the file tree on the left. And at the top left is the kitesh track specification editor, so a KSY spec editor. And according to the kitesh track specification, the input file is parsed and the result is the structured data that you see in the object tree at the bottom, bottom left. And when you edit the kitesh track specification, the input file is automatically parsed again and the object tree is updated. Serialization is a new feature in kitesh track and it's being developed thanks to the financial support of the NLNET Foundation. While parsing allows you to read binary data to an object, serialization is all about the inverse process. So we want to write an object to binary data. And currently in kitesh track, the serialization for support for Java is fully working and C-sharp and Python are in development. There are basically two use cases of serialization. You can edit an existing file or you can create a new file from scratch. And the support for serialization greatly extends the use of all written format specifications because now you can use them not only for parsing but also for serialization. And this has many uses, for example, you can convert one format into another or it can be used for fuzzing or video games modding and so on. This serialization process in kitesh track can be divided into four phases. First you need to create a ks object and then you fill it with data. So you set its individual fields or attributes using setters. Then you should call the underscore check method to check the consistency of the data with the format constraints. Finally, we can call underscore write and pass the stream where to write. And you can actually check out more details of how to use serialization in Java on this page. Currently, the serialization support in kitesh track is designed for the general case so that it works for every conceivable format specification. While a simple solution would work for perhaps most specifications, well, the solution that works for all of them was chosen. Even at the cost of delegating some task to the user. In the future, I would like to automate these tasks that need to be done manually at the moment so that it's more convenient for the user. The basic idea is that the user sets everything, including lengths of sets, magic signatures and kitesh track checks for consistency. Also, only fixed length streams are considered. So once you create a stream, you cannot resize it. Finally, I would like to talk about the plans for the future. Design for C-sharp and Python is in development and they should be ready in two months. There is also interest in adding Rust, C and Julia as target languages. And I would also like to see Wireshark desectors as a target because the concept of kitesh is not limited to programming languages. A target can be anything, for example, we already have a target for construct, which is a Python library for parsing and serialization of binary data. Thanks for listening. Now it's time for our questions. Yes, there is a dock key for which you can use on attributes and types in many places and you can write some documentation of the specific element and in some languages, but it doesn't work like 100% of the time, but the idea is that these documentation should translate to the generated parser as dock blocks and then the IDs and tools for development should autocomplete usually this documentation. Do you support in DNS when generating source code, depending on the target machine? Yes, there is a feature for calculated NDNS, it is called and you can switch the NDNS or the default NDNS based on the value of an arbitrary expression basically, so this can... But do you support host NDNS and target NDNS? Well, not really, but it's not that of a limitation because you can, for example, you can use parameters, for example, to pass it from your application basically because I don't know if I can... I don't know if it's a good idea, but another feature of KiteStruck is that you can define that types can have parameters and even the top level... Yeah, I should probably at least... Never mind, yeah, and you can define parameters and you can easily pass a parameter from your application that will somehow change the behavior of the specification over, yeah, so it's possible. With KSI, you seem to aim to define specification for certain languages or formats, but for languages and formats that already have a specification, how can you ensure that these two specs are actually the same and that you're not passing differently than other parts of it? I don't... Well, you mean that there is already an implementation of some... For example, someone's passing ZIP files out there, how do you guarantee that KiteStruck will pass ZIP files the same way? You don't basically, but from this point of view, it's just another implementation... Well, if you compare it to other parsers, for example, so there is, for example, a ZIP parser in every language, yeah, so ZIP parser library and this KiteStruck specification, it's just another implementation, so, well, it needs to be developed carefully so that it works well or... Yeah. I guess you would need a way to translate from a written specification to the KataI structure or the other way around to validate that what you wrote as the script actually corresponds to the actual specification, for example, if a specification is already matched in machine written, which is readable, I mean, it's not here, we should have a tool to convert from one to the other, so that would ensure that the passing is correct. But it doesn't help, because the implementation is done by humans, it's impossible, it's impossible. It's just an introduction. You have to run all those things. Why? I'm wondering if it would be possible to add some functionality to that, not only parsing but some very common functionality, do you think you can add that in the highest form? Common functionalities, so... Like, for example, there's a binary format and there's very common functionality everybody uses on that, let's say, like, I don't know, cutting a part of it or getting, calculating some, I don't know, value, magic value or hash value, could you add some extra functionality other than parsing in there? Well, so the question was that if you can, if we can add some common functionality in addition to the format specification, and the answer is that, well, you can do this to a certain extent, because there are, I didn't mention them or talk about them, but there are value instances, and you can prepare some, you can, this is like a calculated attribute, so you can write an arbitrary expression to it, and this can calculate, for example, some, like, I wrote a, I wrote a BMP specification or I extended it, and I used this, for example, to, well, in the BMP format, there are like color masks in different places, depending on the head version, and I used a value instance to get it from, so, depending on the version, so either get it from here on here, or if it's a fixed, fixed, I don't know if it's fixed core palette, or what is it called, so, yeah, we can do this to a certain extent, but some common functionality, like, I don't know some, well, if it would require, like, a programming language or something like that, so this would be infeasible, basically, because then, then we should, we would have, we would have to some, some programming languages, something language that translates to all targets, which is basically impossible, I think, yeah. There is some different type of learning, like service, you know, testing, you are this tool set to write a comprehensive diff tools that explains the differences between two binaries and that can leverage the existing descriptions to explain what the difference became to find. Yes, so I think you can compute some diff. Basically, I would do it, I showed the ksdump tool here. So I think you could generate the gson dumps of the two files and compare them, but when I did this, it was usually very, very massive, but you can probably improve that somehow, I don't know. But it's, yeah, okay, so thanks and...", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.96, "text": " Hi everybody, welcome to my presentation about Kaitai struct.", "tokens": [2421, 2201, 11, 2928, 281, 452, 5860, 466, 45791, 1301, 6594, 13], "temperature": 0.0, "avg_logprob": -0.3122153811984592, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.18087568879127502}, {"id": 1, "seek": 0, "start": 12.96, "end": 17.52, "text": " I am Peter Pucil and I have a question.", "tokens": [286, 669, 6508, 430, 1311, 388, 293, 286, 362, 257, 1168, 13], "temperature": 0.0, "avg_logprob": -0.3122153811984592, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.18087568879127502}, {"id": 2, "seek": 0, "start": 17.52, "end": 21.84, "text": " How many of you have any experience with Kaitai?", "tokens": [1012, 867, 295, 291, 362, 604, 1752, 365, 45791, 1301, 30], "temperature": 0.0, "avg_logprob": -0.3122153811984592, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.18087568879127502}, {"id": 3, "seek": 0, "start": 21.84, "end": 27.8, "text": " Okay, there are a few of you.", "tokens": [1033, 11, 456, 366, 257, 1326, 295, 291, 13], "temperature": 0.0, "avg_logprob": -0.3122153811984592, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.18087568879127502}, {"id": 4, "seek": 2780, "start": 27.8, "end": 32.6, "text": " What is Kaitai struct?", "tokens": [708, 307, 45791, 1301, 6594, 30], "temperature": 0.0, "avg_logprob": -0.18162638800484793, "compression_ratio": 1.4184397163120568, "no_speech_prob": 0.0004976496566087008}, {"id": 5, "seek": 2780, "start": 32.6, "end": 41.04, "text": " It's a tool for dealing with binary formats, especially parsing.", "tokens": [467, 311, 257, 2290, 337, 6260, 365, 17434, 25879, 11, 2318, 21156, 278, 13], "temperature": 0.0, "avg_logprob": -0.18162638800484793, "compression_ratio": 1.4184397163120568, "no_speech_prob": 0.0004976496566087008}, {"id": 6, "seek": 2780, "start": 41.04, "end": 49.24, "text": " It is based on a declarative language, Kaitai struct YAML, that can be used to specify arbitrary", "tokens": [467, 307, 2361, 322, 257, 16694, 1166, 2856, 11, 45791, 1301, 6594, 398, 2865, 43, 11, 300, 393, 312, 1143, 281, 16500, 23211], "temperature": 0.0, "avg_logprob": -0.18162638800484793, "compression_ratio": 1.4184397163120568, "no_speech_prob": 0.0004976496566087008}, {"id": 7, "seek": 2780, "start": 49.24, "end": 51.480000000000004, "text": " binary formats.", "tokens": [17434, 25879, 13], "temperature": 0.0, "avg_logprob": -0.18162638800484793, "compression_ratio": 1.4184397163120568, "no_speech_prob": 0.0004976496566087008}, {"id": 8, "seek": 5148, "start": 51.48, "end": 63.68, "text": " It works as a parse generator and it currently supports 11 target programming languages.", "tokens": [467, 1985, 382, 257, 48377, 19265, 293, 309, 4362, 9346, 2975, 3779, 9410, 8650, 13], "temperature": 0.0, "avg_logprob": -0.18346637725830078, "compression_ratio": 1.4276315789473684, "no_speech_prob": 0.001214346382766962}, {"id": 9, "seek": 5148, "start": 63.68, "end": 72.44, "text": " Parsing means to convert the binary data you see above to the structure data and object", "tokens": [49691, 278, 1355, 281, 7620, 264, 17434, 1412, 291, 536, 3673, 281, 264, 3877, 1412, 293, 2657], "temperature": 0.0, "avg_logprob": -0.18346637725830078, "compression_ratio": 1.4276315789473684, "no_speech_prob": 0.001214346382766962}, {"id": 10, "seek": 5148, "start": 72.44, "end": 78.44, "text": " tree so that you can work with it later.", "tokens": [4230, 370, 300, 291, 393, 589, 365, 309, 1780, 13], "temperature": 0.0, "avg_logprob": -0.18346637725830078, "compression_ratio": 1.4276315789473684, "no_speech_prob": 0.001214346382766962}, {"id": 11, "seek": 7844, "start": 78.44, "end": 85.24, "text": " Today I will also introduce a new functionality, which is serialization.", "tokens": [2692, 286, 486, 611, 5366, 257, 777, 14980, 11, 597, 307, 17436, 2144, 13], "temperature": 0.0, "avg_logprob": -0.18033842454876817, "compression_ratio": 1.4320987654320987, "no_speech_prob": 0.00044353402336128056}, {"id": 12, "seek": 7844, "start": 85.24, "end": 98.92, "text": " I've been working on it for the last six months and it currently works in Java.", "tokens": [286, 600, 668, 1364, 322, 309, 337, 264, 1036, 2309, 2493, 293, 309, 4362, 1985, 294, 10745, 13], "temperature": 0.0, "avg_logprob": -0.18033842454876817, "compression_ratio": 1.4320987654320987, "no_speech_prob": 0.00044353402336128056}, {"id": 13, "seek": 7844, "start": 98.92, "end": 105.32, "text": " Serialization means, I didn't mention that, that basically the inverse process.", "tokens": [4210, 831, 2144, 1355, 11, 286, 994, 380, 2152, 300, 11, 300, 1936, 264, 17340, 1399, 13], "temperature": 0.0, "avg_logprob": -0.18033842454876817, "compression_ratio": 1.4320987654320987, "no_speech_prob": 0.00044353402336128056}, {"id": 14, "seek": 10532, "start": 105.32, "end": 111.91999999999999, "text": " You want to create a binary file from an object tree.", "tokens": [509, 528, 281, 1884, 257, 17434, 3991, 490, 364, 2657, 4230, 13], "temperature": 0.0, "avg_logprob": -0.2124908765157064, "compression_ratio": 1.2635658914728682, "no_speech_prob": 0.0005139323184266686}, {"id": 15, "seek": 10532, "start": 111.91999999999999, "end": 116.8, "text": " Something about this story.", "tokens": [6595, 466, 341, 1657, 13], "temperature": 0.0, "avg_logprob": -0.2124908765157064, "compression_ratio": 1.2635658914728682, "no_speech_prob": 0.0005139323184266686}, {"id": 16, "seek": 10532, "start": 116.8, "end": 127.24, "text": " So the author of Kaitai struct is Michael Action and the project started in 2014.", "tokens": [407, 264, 3793, 295, 45791, 1301, 6594, 307, 5116, 16261, 293, 264, 1716, 1409, 294, 8227, 13], "temperature": 0.0, "avg_logprob": -0.2124908765157064, "compression_ratio": 1.2635658914728682, "no_speech_prob": 0.0005139323184266686}, {"id": 17, "seek": 12724, "start": 127.24, "end": 136.51999999999998, "text": " In 2016, Michael decided to release the project as open source and at that time the only supported", "tokens": [682, 6549, 11, 5116, 3047, 281, 4374, 264, 1716, 382, 1269, 4009, 293, 412, 300, 565, 264, 787, 8104], "temperature": 0.0, "avg_logprob": -0.24991666353665865, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.0012942866887897253}, {"id": 18, "seek": 12724, "start": 136.51999999999998, "end": 140.6, "text": " languages were Java and TrueWe.", "tokens": [8650, 645, 10745, 293, 13587, 4360, 13], "temperature": 0.0, "avg_logprob": -0.24991666353665865, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.0012942866887897253}, {"id": 19, "seek": 12724, "start": 140.6, "end": 149.48, "text": " In 2017, Michael presented Kaitai struct at FOSDEM and by then it already supported eight", "tokens": [682, 6591, 11, 5116, 8212, 45791, 1301, 6594, 412, 479, 4367, 35, 6683, 293, 538, 550, 309, 1217, 8104, 3180], "temperature": 0.0, "avg_logprob": -0.24991666353665865, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.0012942866887897253}, {"id": 20, "seek": 12724, "start": 149.48, "end": 156.72, "text": " languages and had over 400 stars on GitHub.", "tokens": [8650, 293, 632, 670, 8423, 6105, 322, 23331, 13], "temperature": 0.0, "avg_logprob": -0.24991666353665865, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.0012942866887897253}, {"id": 21, "seek": 15672, "start": 156.72, "end": 161.0, "text": " Michael also wanted to come today but unfortunately he couldn't.", "tokens": [5116, 611, 1415, 281, 808, 965, 457, 7015, 415, 2809, 380, 13], "temperature": 0.0, "avg_logprob": -0.16954705589695981, "compression_ratio": 1.4328358208955223, "no_speech_prob": 0.0008920631953515112}, {"id": 22, "seek": 15672, "start": 161.0, "end": 166.8, "text": " But if there is some chat or something, I think he should be there so you can ask him", "tokens": [583, 498, 456, 307, 512, 5081, 420, 746, 11, 286, 519, 415, 820, 312, 456, 370, 291, 393, 1029, 796], "temperature": 0.0, "avg_logprob": -0.16954705589695981, "compression_ratio": 1.4328358208955223, "no_speech_prob": 0.0008920631953515112}, {"id": 23, "seek": 15672, "start": 166.8, "end": 169.6, "text": " some questions or whatever.", "tokens": [512, 1651, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.16954705589695981, "compression_ratio": 1.4328358208955223, "no_speech_prob": 0.0008920631953515112}, {"id": 24, "seek": 15672, "start": 169.6, "end": 171.2, "text": " And how is it today?", "tokens": [400, 577, 307, 309, 965, 30], "temperature": 0.0, "avg_logprob": -0.16954705589695981, "compression_ratio": 1.4328358208955223, "no_speech_prob": 0.0008920631953515112}, {"id": 25, "seek": 15672, "start": 171.2, "end": 181.68, "text": " So we have 11 target languages and over 3,000 stars on GitHub and Kaitai is used in more", "tokens": [407, 321, 362, 2975, 3779, 8650, 293, 670, 805, 11, 1360, 6105, 322, 23331, 293, 45791, 1301, 307, 1143, 294, 544], "temperature": 0.0, "avg_logprob": -0.16954705589695981, "compression_ratio": 1.4328358208955223, "no_speech_prob": 0.0008920631953515112}, {"id": 26, "seek": 18168, "start": 181.68, "end": 188.4, "text": " than 500 GitHub projects.", "tokens": [813, 5923, 23331, 4455, 13], "temperature": 0.0, "avg_logprob": -0.10562196232023693, "compression_ratio": 1.2348484848484849, "no_speech_prob": 0.00018009818450082093}, {"id": 27, "seek": 18168, "start": 188.4, "end": 194.32, "text": " So let me share how I discovered Kaitai struct.", "tokens": [407, 718, 385, 2073, 577, 286, 6941, 45791, 1301, 6594, 13], "temperature": 0.0, "avg_logprob": -0.10562196232023693, "compression_ratio": 1.2348484848484849, "no_speech_prob": 0.00018009818450082093}, {"id": 28, "seek": 18168, "start": 194.32, "end": 203.24, "text": " This was in 2019 and I was playing electronic keyboard with a band and I wanted to create", "tokens": [639, 390, 294, 6071, 293, 286, 390, 2433, 10092, 10186, 365, 257, 4116, 293, 286, 1415, 281, 1884], "temperature": 0.0, "avg_logprob": -0.10562196232023693, "compression_ratio": 1.2348484848484849, "no_speech_prob": 0.00018009818450082093}, {"id": 29, "seek": 20324, "start": 203.24, "end": 212.44, "text": " a MIDI editor so that I could record the songs on the keyboard and edit them on the computer.", "tokens": [257, 41474, 9839, 370, 300, 286, 727, 2136, 264, 5781, 322, 264, 10186, 293, 8129, 552, 322, 264, 3820, 13], "temperature": 0.0, "avg_logprob": -0.14741983252056576, "compression_ratio": 1.58, "no_speech_prob": 0.005386910866945982}, {"id": 30, "seek": 20324, "start": 212.44, "end": 221.08, "text": " And I wanted the user to be able to upload a sound bank in the sound font to binary format", "tokens": [400, 286, 1415, 264, 4195, 281, 312, 1075, 281, 6580, 257, 1626, 3765, 294, 264, 1626, 10703, 281, 17434, 7877], "temperature": 0.0, "avg_logprob": -0.14741983252056576, "compression_ratio": 1.58, "no_speech_prob": 0.005386910866945982}, {"id": 31, "seek": 20324, "start": 221.08, "end": 226.36, "text": " so that they could control how the song could sound.", "tokens": [370, 300, 436, 727, 1969, 577, 264, 2153, 727, 1626, 13], "temperature": 0.0, "avg_logprob": -0.14741983252056576, "compression_ratio": 1.58, "no_speech_prob": 0.005386910866945982}, {"id": 32, "seek": 22636, "start": 226.36, "end": 234.12, "text": " And I wanted a web-based MIDI editor so I searched for a JavaScript parsing library", "tokens": [400, 286, 1415, 257, 3670, 12, 6032, 41474, 9839, 370, 286, 22961, 337, 257, 15778, 21156, 278, 6405], "temperature": 0.0, "avg_logprob": -0.10588594486838893, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.003249902045354247}, {"id": 33, "seek": 22636, "start": 234.12, "end": 241.36, "text": " of the.sf2 format but I couldn't find one that would work for me.", "tokens": [295, 264, 2411, 82, 69, 17, 7877, 457, 286, 2809, 380, 915, 472, 300, 576, 589, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.10588594486838893, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.003249902045354247}, {"id": 34, "seek": 22636, "start": 241.36, "end": 249.60000000000002, "text": " So I started writing my own parser but it was really hard and a lot of debugging had", "tokens": [407, 286, 1409, 3579, 452, 1065, 21156, 260, 457, 309, 390, 534, 1152, 293, 257, 688, 295, 45592, 632], "temperature": 0.0, "avg_logprob": -0.10588594486838893, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.003249902045354247}, {"id": 35, "seek": 22636, "start": 249.60000000000002, "end": 253.32000000000002, "text": " to be done and it was just not fun.", "tokens": [281, 312, 1096, 293, 309, 390, 445, 406, 1019, 13], "temperature": 0.0, "avg_logprob": -0.10588594486838893, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.003249902045354247}, {"id": 36, "seek": 25332, "start": 253.32, "end": 264.71999999999997, "text": " And when I finished I came across Kaitai struct and I found that my two months of work I spent", "tokens": [400, 562, 286, 4335, 286, 1361, 2108, 45791, 1301, 6594, 293, 286, 1352, 300, 452, 732, 2493, 295, 589, 286, 4418], "temperature": 0.0, "avg_logprob": -0.1207091212272644, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0069989999756217}, {"id": 37, "seek": 25332, "start": 264.71999999999997, "end": 269.15999999999997, "text": " on this could be done in just one day with Kaitai.", "tokens": [322, 341, 727, 312, 1096, 294, 445, 472, 786, 365, 45791, 1301, 13], "temperature": 0.0, "avg_logprob": -0.1207091212272644, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0069989999756217}, {"id": 38, "seek": 25332, "start": 269.15999999999997, "end": 278.48, "text": " So Kaitai impressed me with its concept, simplicity and versatility and I started contributing", "tokens": [407, 45791, 1301, 11679, 385, 365, 1080, 3410, 11, 25632, 293, 1774, 20758, 293, 286, 1409, 19270], "temperature": 0.0, "avg_logprob": -0.1207091212272644, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0069989999756217}, {"id": 39, "seek": 25332, "start": 278.48, "end": 280.12, "text": " a lot.", "tokens": [257, 688, 13], "temperature": 0.0, "avg_logprob": -0.1207091212272644, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0069989999756217}, {"id": 40, "seek": 28012, "start": 280.12, "end": 287.72, "text": " And Kaitai also helped me my personal development because until then I'd only programmed in", "tokens": [400, 45791, 1301, 611, 4254, 385, 452, 2973, 3250, 570, 1826, 550, 286, 1116, 787, 31092, 294], "temperature": 0.0, "avg_logprob": -0.1438081914728338, "compression_ratio": 1.3508771929824561, "no_speech_prob": 0.001327131176367402}, {"id": 41, "seek": 28012, "start": 287.72, "end": 294.44, "text": " JavaScript, PHP and a little bit of Python and within a few months I was able to work", "tokens": [15778, 11, 47298, 293, 257, 707, 857, 295, 15329, 293, 1951, 257, 1326, 2493, 286, 390, 1075, 281, 589], "temperature": 0.0, "avg_logprob": -0.1438081914728338, "compression_ratio": 1.3508771929824561, "no_speech_prob": 0.001327131176367402}, {"id": 42, "seek": 28012, "start": 294.44, "end": 299.12, "text": " in 14 programming languages that were used in Kaitai.", "tokens": [294, 3499, 9410, 8650, 300, 645, 1143, 294, 45791, 1301, 13], "temperature": 0.0, "avg_logprob": -0.1438081914728338, "compression_ratio": 1.3508771929824561, "no_speech_prob": 0.001327131176367402}, {"id": 43, "seek": 29912, "start": 299.12, "end": 310.52, "text": " And in 2020 I accepted an offer from Michael to become an administrator of the project.", "tokens": [400, 294, 4808, 286, 9035, 364, 2626, 490, 5116, 281, 1813, 364, 25529, 295, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.06063827601346103, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.0005972905782982707}, {"id": 44, "seek": 29912, "start": 310.52, "end": 317.76, "text": " So in my story I showed what options there are to get a parser.", "tokens": [407, 294, 452, 1657, 286, 4712, 437, 3956, 456, 366, 281, 483, 257, 21156, 260, 13], "temperature": 0.0, "avg_logprob": -0.06063827601346103, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.0005972905782982707}, {"id": 45, "seek": 29912, "start": 317.76, "end": 324.8, "text": " So the most convenient way that you are probably familiar with is to use a dedicated format", "tokens": [407, 264, 881, 10851, 636, 300, 291, 366, 1391, 4963, 365, 307, 281, 764, 257, 8374, 7877], "temperature": 0.0, "avg_logprob": -0.06063827601346103, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.0005972905782982707}, {"id": 46, "seek": 29912, "start": 324.8, "end": 328.52, "text": " library in the given language.", "tokens": [6405, 294, 264, 2212, 2856, 13], "temperature": 0.0, "avg_logprob": -0.06063827601346103, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.0005972905782982707}, {"id": 47, "seek": 32852, "start": 328.52, "end": 336.24, "text": " So it will probably have a user-friendly API and can be optimized for a format.", "tokens": [407, 309, 486, 1391, 362, 257, 4195, 12, 22864, 9362, 293, 393, 312, 26941, 337, 257, 7877, 13], "temperature": 0.0, "avg_logprob": -0.16322732652936664, "compression_ratio": 1.427027027027027, "no_speech_prob": 0.002357529941946268}, {"id": 48, "seek": 32852, "start": 336.24, "end": 344.28, "text": " But sometimes it may be of poor quality and incomplete and it may be difficult to debug", "tokens": [583, 2171, 309, 815, 312, 295, 4716, 3125, 293, 31709, 293, 309, 815, 312, 2252, 281, 24083], "temperature": 0.0, "avg_logprob": -0.16322732652936664, "compression_ratio": 1.427027027027027, "no_speech_prob": 0.002357529941946268}, {"id": 49, "seek": 32852, "start": 344.28, "end": 346.56, "text": " and fix it.", "tokens": [293, 3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.16322732652936664, "compression_ratio": 1.427027027027027, "no_speech_prob": 0.002357529941946268}, {"id": 50, "seek": 32852, "start": 346.56, "end": 355.12, "text": " And also for the most common formats like JPEG, L for zip, you can find even several", "tokens": [400, 611, 337, 264, 881, 2689, 25879, 411, 508, 5208, 38, 11, 441, 337, 20730, 11, 291, 393, 915, 754, 2940], "temperature": 0.0, "avg_logprob": -0.16322732652936664, "compression_ratio": 1.427027027027027, "no_speech_prob": 0.002357529941946268}, {"id": 51, "seek": 35512, "start": 355.12, "end": 363.08, "text": " libraries and you can choose, but for less common formats, some obscure ones, there will", "tokens": [15148, 293, 291, 393, 2826, 11, 457, 337, 1570, 2689, 25879, 11, 512, 34443, 2306, 11, 456, 486], "temperature": 0.0, "avg_logprob": -0.15844076020377024, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0005882043042220175}, {"id": 52, "seek": 35512, "start": 363.08, "end": 366.44, "text": " simply be no library in your language.", "tokens": [2935, 312, 572, 6405, 294, 428, 2856, 13], "temperature": 0.0, "avg_logprob": -0.15844076020377024, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0005882043042220175}, {"id": 53, "seek": 35512, "start": 366.44, "end": 374.68, "text": " So we need to look into other options and another option is to simply write your own", "tokens": [407, 321, 643, 281, 574, 666, 661, 3956, 293, 1071, 3614, 307, 281, 2935, 2464, 428, 1065], "temperature": 0.0, "avg_logprob": -0.15844076020377024, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0005882043042220175}, {"id": 54, "seek": 35512, "start": 374.68, "end": 375.68, "text": " parser.", "tokens": [21156, 260, 13], "temperature": 0.0, "avg_logprob": -0.15844076020377024, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0005882043042220175}, {"id": 55, "seek": 37568, "start": 375.68, "end": 386.6, "text": " But in my experience this is the worst option because it takes a lot of time and you need", "tokens": [583, 294, 452, 1752, 341, 307, 264, 5855, 3614, 570, 309, 2516, 257, 688, 295, 565, 293, 291, 643], "temperature": 0.0, "avg_logprob": -0.14932858316521896, "compression_ratio": 1.5444444444444445, "no_speech_prob": 0.005042540840804577}, {"id": 56, "seek": 37568, "start": 386.6, "end": 394.84000000000003, "text": " to do a lot of debugging using some debug brains and dumps and it's just not fun.", "tokens": [281, 360, 257, 688, 295, 45592, 1228, 512, 24083, 15442, 293, 11430, 82, 293, 309, 311, 445, 406, 1019, 13], "temperature": 0.0, "avg_logprob": -0.14932858316521896, "compression_ratio": 1.5444444444444445, "no_speech_prob": 0.005042540840804577}, {"id": 57, "seek": 37568, "start": 394.84000000000003, "end": 400.64, "text": " But it's what most people do, often because they just don't know any better.", "tokens": [583, 309, 311, 437, 881, 561, 360, 11, 2049, 570, 436, 445, 500, 380, 458, 604, 1101, 13], "temperature": 0.0, "avg_logprob": -0.14932858316521896, "compression_ratio": 1.5444444444444445, "no_speech_prob": 0.005042540840804577}, {"id": 58, "seek": 37568, "start": 400.64, "end": 404.08, "text": " So that's why I'm here today.", "tokens": [407, 300, 311, 983, 286, 478, 510, 965, 13], "temperature": 0.0, "avg_logprob": -0.14932858316521896, "compression_ratio": 1.5444444444444445, "no_speech_prob": 0.005042540840804577}, {"id": 59, "seek": 40408, "start": 404.08, "end": 412.47999999999996, "text": " And well, the problem is that if you have already written a parser for your format in", "tokens": [400, 731, 11, 264, 1154, 307, 300, 498, 291, 362, 1217, 3720, 257, 21156, 260, 337, 428, 7877, 294], "temperature": 0.0, "avg_logprob": -0.10303700381311877, "compression_ratio": 1.490066225165563, "no_speech_prob": 0.0017223377944901586}, {"id": 60, "seek": 40408, "start": 412.47999999999996, "end": 418.64, "text": " Python, for example, and then after some time you are asked to create a Java parser for the", "tokens": [15329, 11, 337, 1365, 11, 293, 550, 934, 512, 565, 291, 366, 2351, 281, 1884, 257, 10745, 21156, 260, 337, 264], "temperature": 0.0, "avg_logprob": -0.10303700381311877, "compression_ratio": 1.490066225165563, "no_speech_prob": 0.0017223377944901586}, {"id": 61, "seek": 40408, "start": 418.64, "end": 426.76, "text": " same format, you basically need to start again.", "tokens": [912, 7877, 11, 291, 1936, 643, 281, 722, 797, 13], "temperature": 0.0, "avg_logprob": -0.10303700381311877, "compression_ratio": 1.490066225165563, "no_speech_prob": 0.0017223377944901586}, {"id": 62, "seek": 42676, "start": 426.76, "end": 433.92, "text": " So a bit better way is to use a parser combinator, which means that you are essentially still", "tokens": [407, 257, 857, 1101, 636, 307, 281, 764, 257, 21156, 260, 2512, 31927, 11, 597, 1355, 300, 291, 366, 4476, 920], "temperature": 0.0, "avg_logprob": -0.1489072527204241, "compression_ratio": 1.5470588235294118, "no_speech_prob": 0.0008755462476983666}, {"id": 63, "seek": 42676, "start": 433.92, "end": 441.03999999999996, "text": " writing your own parser, but you are using some building blocks from a library.", "tokens": [3579, 428, 1065, 21156, 260, 11, 457, 291, 366, 1228, 512, 2390, 8474, 490, 257, 6405, 13], "temperature": 0.0, "avg_logprob": -0.1489072527204241, "compression_ratio": 1.5470588235294118, "no_speech_prob": 0.0008755462476983666}, {"id": 64, "seek": 42676, "start": 441.03999999999996, "end": 448.88, "text": " And a parser combinator typically allows you to declaratively define some sub structures,", "tokens": [400, 257, 21156, 260, 2512, 31927, 5850, 4045, 291, 281, 16694, 19020, 6964, 512, 1422, 9227, 11], "temperature": 0.0, "avg_logprob": -0.1489072527204241, "compression_ratio": 1.5470588235294118, "no_speech_prob": 0.0008755462476983666}, {"id": 65, "seek": 44888, "start": 448.88, "end": 458.88, "text": " but still in the code and like in CU can define structs for the fixed size pieces of the format", "tokens": [457, 920, 294, 264, 3089, 293, 411, 294, 29777, 393, 6964, 6594, 82, 337, 264, 6806, 2744, 3755, 295, 264, 7877], "temperature": 0.0, "avg_logprob": -0.1632898699852728, "compression_ratio": 1.4745762711864407, "no_speech_prob": 0.0019538786727935076}, {"id": 66, "seek": 44888, "start": 458.88, "end": 466.0, "text": " and then you can directly interpret some block of bytes with that struct.", "tokens": [293, 550, 291, 393, 3838, 7302, 512, 3461, 295, 36088, 365, 300, 6594, 13], "temperature": 0.0, "avg_logprob": -0.1632898699852728, "compression_ratio": 1.4745762711864407, "no_speech_prob": 0.0019538786727935076}, {"id": 67, "seek": 44888, "start": 466.0, "end": 477.32, "text": " And there are many parser combinators, perhaps dozens in popular languages, but as with the", "tokens": [400, 456, 366, 867, 21156, 260, 38514, 3391, 11, 4317, 18431, 294, 3743, 8650, 11, 457, 382, 365, 264], "temperature": 0.0, "avg_logprob": -0.1632898699852728, "compression_ratio": 1.4745762711864407, "no_speech_prob": 0.0019538786727935076}, {"id": 68, "seek": 47732, "start": 477.32, "end": 488.15999999999997, "text": " two previous options, you have still the disadvantage that the parser you get this way is still", "tokens": [732, 3894, 3956, 11, 291, 362, 920, 264, 24292, 300, 264, 21156, 260, 291, 483, 341, 636, 307, 920], "temperature": 0.0, "avg_logprob": -0.16958455741405487, "compression_ratio": 1.5497076023391814, "no_speech_prob": 0.0016799195436760783}, {"id": 69, "seek": 47732, "start": 488.15999999999997, "end": 491.24, "text": " bound to the particular language.", "tokens": [5472, 281, 264, 1729, 2856, 13], "temperature": 0.0, "avg_logprob": -0.16958455741405487, "compression_ratio": 1.5497076023391814, "no_speech_prob": 0.0016799195436760783}, {"id": 70, "seek": 47732, "start": 491.24, "end": 495.15999999999997, "text": " And it may be even bound to an application.", "tokens": [400, 309, 815, 312, 754, 5472, 281, 364, 3861, 13], "temperature": 0.0, "avg_logprob": -0.16958455741405487, "compression_ratio": 1.5497076023391814, "no_speech_prob": 0.0016799195436760783}, {"id": 71, "seek": 47732, "start": 495.15999999999997, "end": 503.12, "text": " For example, if it was developed for a graphical editor, so it may be difficult to separate", "tokens": [1171, 1365, 11, 498, 309, 390, 4743, 337, 257, 35942, 9839, 11, 370, 309, 815, 312, 2252, 281, 4994], "temperature": 0.0, "avg_logprob": -0.16958455741405487, "compression_ratio": 1.5497076023391814, "no_speech_prob": 0.0016799195436760783}, {"id": 72, "seek": 50312, "start": 503.12, "end": 510.12, "text": " just a parser from that application to use it somewhere else.", "tokens": [445, 257, 21156, 260, 490, 300, 3861, 281, 764, 309, 4079, 1646, 13], "temperature": 0.0, "avg_logprob": -0.13851925532023113, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0002630115777719766}, {"id": 73, "seek": 50312, "start": 510.12, "end": 519.52, "text": " And the fourth option is to use a parser generator, which means that you are not writing the parsing", "tokens": [400, 264, 6409, 3614, 307, 281, 764, 257, 21156, 260, 19265, 11, 597, 1355, 300, 291, 366, 406, 3579, 264, 21156, 278], "temperature": 0.0, "avg_logprob": -0.13851925532023113, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0002630115777719766}, {"id": 74, "seek": 50312, "start": 519.52, "end": 526.88, "text": " code directly in the programming language, but instead you describe it in a domain, describe", "tokens": [3089, 3838, 294, 264, 9410, 2856, 11, 457, 2602, 291, 6786, 309, 294, 257, 9274, 11, 6786], "temperature": 0.0, "avg_logprob": -0.13851925532023113, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0002630115777719766}, {"id": 75, "seek": 52688, "start": 526.88, "end": 534.52, "text": " the format structure in a domain-specific language, and this description can be then", "tokens": [264, 7877, 3877, 294, 257, 9274, 12, 29258, 2856, 11, 293, 341, 3855, 393, 312, 550], "temperature": 0.0, "avg_logprob": -0.3182243200448843, "compression_ratio": 1.4825174825174825, "no_speech_prob": 0.0007406093645840883}, {"id": 76, "seek": 52688, "start": 534.52, "end": 538.96, "text": " automatically translated into a parser.", "tokens": [6772, 16805, 666, 257, 21156, 260, 13], "temperature": 0.0, "avg_logprob": -0.3182243200448843, "compression_ratio": 1.4825174825174825, "no_speech_prob": 0.0007406093645840883}, {"id": 77, "seek": 52688, "start": 538.96, "end": 548.4, "text": " So, KeitaStruck falls into this category and it is the KeitaStruck language is designed", "tokens": [407, 11, 3189, 2786, 4520, 8161, 8804, 666, 341, 7719, 293, 309, 307, 264, 3189, 2786, 4520, 8161, 2856, 307, 4761], "temperature": 0.0, "avg_logprob": -0.3182243200448843, "compression_ratio": 1.4825174825174825, "no_speech_prob": 0.0007406093645840883}, {"id": 78, "seek": 54840, "start": 548.4, "end": 558.1999999999999, "text": " so that it's independent of both the application and the programming language.", "tokens": [370, 300, 309, 311, 6695, 295, 1293, 264, 3861, 293, 264, 9410, 2856, 13], "temperature": 0.0, "avg_logprob": -0.1417956276545449, "compression_ratio": 1.4759036144578312, "no_speech_prob": 0.001104672090150416}, {"id": 79, "seek": 54840, "start": 558.1999999999999, "end": 562.6, "text": " Here I'll show you how to work with Keita.", "tokens": [1692, 286, 603, 855, 291, 577, 281, 589, 365, 3189, 2786, 13], "temperature": 0.0, "avg_logprob": -0.1417956276545449, "compression_ratio": 1.4759036144578312, "no_speech_prob": 0.001104672090150416}, {"id": 80, "seek": 54840, "start": 562.6, "end": 566.28, "text": " The first stage is compilation.", "tokens": [440, 700, 3233, 307, 40261, 13], "temperature": 0.0, "avg_logprob": -0.1417956276545449, "compression_ratio": 1.4759036144578312, "no_speech_prob": 0.001104672090150416}, {"id": 81, "seek": 54840, "start": 566.28, "end": 576.0799999999999, "text": " So you take this KeitaStruck specification of the format and in this case, this is a format", "tokens": [407, 291, 747, 341, 3189, 2786, 4520, 8161, 31256, 295, 264, 7877, 293, 294, 341, 1389, 11, 341, 307, 257, 7877], "temperature": 0.0, "avg_logprob": -0.1417956276545449, "compression_ratio": 1.4759036144578312, "no_speech_prob": 0.001104672090150416}, {"id": 82, "seek": 57608, "start": 576.08, "end": 585.84, "text": " that has one byte because this U1 type means unsigned integer of one byte.", "tokens": [300, 575, 472, 40846, 570, 341, 624, 16, 2010, 1355, 2693, 16690, 24922, 295, 472, 40846, 13], "temperature": 0.0, "avg_logprob": -0.14264665459686854, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.003977734129875898}, {"id": 83, "seek": 57608, "start": 585.84, "end": 593.5600000000001, "text": " And you take this KeitaStruck specification and you compile it using the KeitaStruck compiler,", "tokens": [400, 291, 747, 341, 3189, 2786, 4520, 8161, 31256, 293, 291, 31413, 309, 1228, 264, 3189, 2786, 4520, 8161, 31958, 11], "temperature": 0.0, "avg_logprob": -0.14264665459686854, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.003977734129875898}, {"id": 84, "seek": 57608, "start": 593.5600000000001, "end": 595.5600000000001, "text": " which is a command line tool.", "tokens": [597, 307, 257, 5622, 1622, 2290, 13], "temperature": 0.0, "avg_logprob": -0.14264665459686854, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.003977734129875898}, {"id": 85, "seek": 59556, "start": 595.56, "end": 606.3599999999999, "text": " And as output, you get the source code of the parser, in this case in Python.", "tokens": [400, 382, 5598, 11, 291, 483, 264, 4009, 3089, 295, 264, 21156, 260, 11, 294, 341, 1389, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.12459216117858887, "compression_ratio": 1.36, "no_speech_prob": 0.003008617088198662}, {"id": 86, "seek": 59556, "start": 606.3599999999999, "end": 611.1999999999999, "text": " The main stage is parsing.", "tokens": [440, 2135, 3233, 307, 21156, 278, 13], "temperature": 0.0, "avg_logprob": -0.12459216117858887, "compression_ratio": 1.36, "no_speech_prob": 0.003008617088198662}, {"id": 87, "seek": 59556, "start": 611.1999999999999, "end": 618.8, "text": " You take, you give the input binary file to the generated parser.", "tokens": [509, 747, 11, 291, 976, 264, 4846, 17434, 3991, 281, 264, 10833, 21156, 260, 13], "temperature": 0.0, "avg_logprob": -0.12459216117858887, "compression_ratio": 1.36, "no_speech_prob": 0.003008617088198662}, {"id": 88, "seek": 61880, "start": 618.8, "end": 628.3199999999999, "text": " You get in the first step and you give the input binary file to the parser as input and", "tokens": [509, 483, 294, 264, 700, 1823, 293, 291, 976, 264, 4846, 17434, 3991, 281, 264, 21156, 260, 382, 4846, 293], "temperature": 0.0, "avg_logprob": -0.1409179187211834, "compression_ratio": 1.4933333333333334, "no_speech_prob": 0.0009592279675416648}, {"id": 89, "seek": 61880, "start": 628.3199999999999, "end": 635.04, "text": " you get parsed data as output, so an object tree.", "tokens": [291, 483, 21156, 292, 1412, 382, 5598, 11, 370, 364, 2657, 4230, 13], "temperature": 0.0, "avg_logprob": -0.1409179187211834, "compression_ratio": 1.4933333333333334, "no_speech_prob": 0.0009592279675416648}, {"id": 90, "seek": 61880, "start": 635.04, "end": 643.4799999999999, "text": " And in case of KeitaStruck, the generated parser works with the runtime library so you", "tokens": [400, 294, 1389, 295, 3189, 2786, 4520, 8161, 11, 264, 10833, 21156, 260, 1985, 365, 264, 34474, 6405, 370, 291], "temperature": 0.0, "avg_logprob": -0.1409179187211834, "compression_ratio": 1.4933333333333334, "no_speech_prob": 0.0009592279675416648}, {"id": 91, "seek": 64348, "start": 643.48, "end": 650.6, "text": " need to include it also into your application.", "tokens": [643, 281, 4090, 309, 611, 666, 428, 3861, 13], "temperature": 0.0, "avg_logprob": -0.14694687298366002, "compression_ratio": 1.4195804195804196, "no_speech_prob": 0.0006364990258589387}, {"id": 92, "seek": 64348, "start": 650.6, "end": 651.6800000000001, "text": " Why use Keita?", "tokens": [1545, 764, 3189, 2786, 30], "temperature": 0.0, "avg_logprob": -0.14694687298366002, "compression_ratio": 1.4195804195804196, "no_speech_prob": 0.0006364990258589387}, {"id": 93, "seek": 64348, "start": 651.6800000000001, "end": 656.36, "text": " What are the advantages?", "tokens": [708, 366, 264, 14906, 30], "temperature": 0.0, "avg_logprob": -0.14694687298366002, "compression_ratio": 1.4195804195804196, "no_speech_prob": 0.0006364990258589387}, {"id": 94, "seek": 64348, "start": 656.36, "end": 666.6800000000001, "text": " So as I already mentioned, the advantage is that you write the KSY specification once", "tokens": [407, 382, 286, 1217, 2835, 11, 264, 5002, 307, 300, 291, 2464, 264, 591, 50, 56, 31256, 1564], "temperature": 0.0, "avg_logprob": -0.14694687298366002, "compression_ratio": 1.4195804195804196, "no_speech_prob": 0.0006364990258589387}, {"id": 95, "seek": 64348, "start": 666.6800000000001, "end": 669.32, "text": " and you can use it everywhere.", "tokens": [293, 291, 393, 764, 309, 5315, 13], "temperature": 0.0, "avg_logprob": -0.14694687298366002, "compression_ratio": 1.4195804195804196, "no_speech_prob": 0.0006364990258589387}, {"id": 96, "seek": 66932, "start": 669.32, "end": 676.32, "text": " It standardizes the way we describe binary formats and there are already many formats", "tokens": [467, 3832, 5660, 264, 636, 321, 6786, 17434, 25879, 293, 456, 366, 1217, 867, 25879], "temperature": 0.0, "avg_logprob": -0.1726830581138874, "compression_ratio": 1.5974842767295598, "no_speech_prob": 0.00017236701387446374}, {"id": 97, "seek": 66932, "start": 676.32, "end": 685.6400000000001, "text": " described in the Keita format gallery and any described format can be visualized automatically", "tokens": [7619, 294, 264, 3189, 2786, 7877, 18378, 293, 604, 7619, 7877, 393, 312, 5056, 1602, 6772], "temperature": 0.0, "avg_logprob": -0.1726830581138874, "compression_ratio": 1.5974842767295598, "no_speech_prob": 0.00017236701387446374}, {"id": 98, "seek": 66932, "start": 685.6400000000001, "end": 693.0400000000001, "text": " in a Gravis diagram and the KeitaStruck language is simple, you will see.", "tokens": [294, 257, 8985, 4938, 10686, 293, 264, 3189, 2786, 4520, 8161, 2856, 307, 2199, 11, 291, 486, 536, 13], "temperature": 0.0, "avg_logprob": -0.1726830581138874, "compression_ratio": 1.5974842767295598, "no_speech_prob": 0.00017236701387446374}, {"id": 99, "seek": 69304, "start": 693.04, "end": 701.36, "text": " There are also several visualization and dumping tool available in KeitaStruck.", "tokens": [821, 366, 611, 2940, 25801, 293, 42224, 2290, 2435, 294, 3189, 2786, 4520, 8161, 13], "temperature": 0.0, "avg_logprob": -0.17186262130737304, "compression_ratio": 1.35, "no_speech_prob": 0.00025416960124857724}, {"id": 100, "seek": 69304, "start": 701.36, "end": 713.36, "text": " So the write once use everywhere feature means that you get parses in 11 programming languages", "tokens": [407, 264, 2464, 1564, 764, 5315, 4111, 1355, 300, 291, 483, 21156, 279, 294, 2975, 9410, 8650], "temperature": 0.0, "avg_logprob": -0.17186262130737304, "compression_ratio": 1.35, "no_speech_prob": 0.00025416960124857724}, {"id": 101, "seek": 69304, "start": 713.36, "end": 717.92, "text": " for free from a single KSY specification.", "tokens": [337, 1737, 490, 257, 2167, 591, 50, 56, 31256, 13], "temperature": 0.0, "avg_logprob": -0.17186262130737304, "compression_ratio": 1.35, "no_speech_prob": 0.00025416960124857724}, {"id": 102, "seek": 71792, "start": 717.92, "end": 727.4399999999999, "text": " So in this case, I've had the compiler generate Java, Python and Ruby parsers from a simple", "tokens": [407, 294, 341, 1389, 11, 286, 600, 632, 264, 31958, 8460, 10745, 11, 15329, 293, 19907, 21156, 433, 490, 257, 2199], "temperature": 0.0, "avg_logprob": -0.1504606940529563, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0011902486439794302}, {"id": 103, "seek": 71792, "start": 727.4399999999999, "end": 734.12, "text": " KSY specification you see on the left.", "tokens": [591, 50, 56, 31256, 291, 536, 322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.1504606940529563, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0011902486439794302}, {"id": 104, "seek": 71792, "start": 734.12, "end": 740.76, "text": " When you look for specifications of binary formats, you will find that each one looks", "tokens": [1133, 291, 574, 337, 29448, 295, 17434, 25879, 11, 291, 486, 915, 300, 1184, 472, 1542], "temperature": 0.0, "avg_logprob": -0.1504606940529563, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0011902486439794302}, {"id": 105, "seek": 74076, "start": 740.76, "end": 752.64, "text": " different and there is no single standard to how to document formats and Keita is used", "tokens": [819, 293, 456, 307, 572, 2167, 3832, 281, 577, 281, 4166, 25879, 293, 3189, 2786, 307, 1143], "temperature": 0.0, "avg_logprob": -0.14546361516733639, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.0009248456335626543}, {"id": 106, "seek": 74076, "start": 752.64, "end": 761.2, "text": " or intended primarily for creating parses but some people write KSY specification just", "tokens": [420, 10226, 10029, 337, 4084, 21156, 279, 457, 512, 561, 2464, 591, 50, 56, 31256, 445], "temperature": 0.0, "avg_logprob": -0.14546361516733639, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.0009248456335626543}, {"id": 107, "seek": 74076, "start": 761.2, "end": 768.4399999999999, "text": " to document a format in an easy to understand way because you don't even have to be a programmer", "tokens": [281, 4166, 257, 7877, 294, 364, 1858, 281, 1223, 636, 570, 291, 500, 380, 754, 362, 281, 312, 257, 32116], "temperature": 0.0, "avg_logprob": -0.14546361516733639, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.0009248456335626543}, {"id": 108, "seek": 76844, "start": 768.44, "end": 780.32, "text": " to understand a KSY specification and it's often easier than to read these long PDF documents.", "tokens": [281, 1223, 257, 591, 50, 56, 31256, 293, 309, 311, 2049, 3571, 813, 281, 1401, 613, 938, 17752, 8512, 13], "temperature": 0.0, "avg_logprob": -0.17731237411499023, "compression_ratio": 1.263157894736842, "no_speech_prob": 0.0003787850437220186}, {"id": 109, "seek": 76844, "start": 780.32, "end": 788.08, "text": " And the Keita project includes an extensive gallery of described formats.", "tokens": [400, 264, 3189, 2786, 1716, 5974, 364, 13246, 18378, 295, 7619, 25879, 13], "temperature": 0.0, "avg_logprob": -0.17731237411499023, "compression_ratio": 1.263157894736842, "no_speech_prob": 0.0003787850437220186}, {"id": 110, "seek": 78808, "start": 788.08, "end": 808.48, "text": " At the moment, there are 181 formats described by 76 contributors and there are also several", "tokens": [1711, 264, 1623, 11, 456, 366, 2443, 16, 25879, 7619, 538, 24733, 45627, 293, 456, 366, 611, 2940], "temperature": 0.0, "avg_logprob": -0.2526861639583812, "compression_ratio": 1.2704918032786885, "no_speech_prob": 0.001339038135483861}, {"id": 111, "seek": 78808, "start": 808.48, "end": 816.72, "text": " hundreds more format specifications in various Keita projects.", "tokens": [6779, 544, 7877, 29448, 294, 3683, 3189, 2786, 4455, 13], "temperature": 0.0, "avg_logprob": -0.2526861639583812, "compression_ratio": 1.2704918032786885, "no_speech_prob": 0.001339038135483861}, {"id": 112, "seek": 81672, "start": 816.72, "end": 826.4, "text": " And so the Keita format gallery contains formats of various kinds, for example, as you see", "tokens": [400, 370, 264, 3189, 2786, 7877, 18378, 8306, 25879, 295, 3683, 3685, 11, 337, 1365, 11, 382, 291, 536], "temperature": 0.0, "avg_logprob": -0.18206470243392453, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.00041986783617176116}, {"id": 113, "seek": 81672, "start": 826.4, "end": 835.1600000000001, "text": " archive files, for example, executables, file systems, game data files, multimedia files", "tokens": [23507, 7098, 11, 337, 1365, 11, 7568, 2965, 11, 3991, 3652, 11, 1216, 1412, 7098, 11, 49202, 7098], "temperature": 0.0, "avg_logprob": -0.18206470243392453, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.00041986783617176116}, {"id": 114, "seek": 81672, "start": 835.1600000000001, "end": 844.5600000000001, "text": " and network protocols, you can go to this page and I took it from there.", "tokens": [293, 3209, 20618, 11, 291, 393, 352, 281, 341, 3028, 293, 286, 1890, 309, 490, 456, 13], "temperature": 0.0, "avg_logprob": -0.18206470243392453, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.00041986783617176116}, {"id": 115, "seek": 84456, "start": 844.56, "end": 850.68, "text": " And this suggests the wide applicability of Keita.", "tokens": [400, 341, 13409, 264, 4874, 2580, 2310, 295, 3189, 2786, 13], "temperature": 0.0, "avg_logprob": -0.1599991818269094, "compression_ratio": 1.477124183006536, "no_speech_prob": 0.00323398201726377}, {"id": 116, "seek": 84456, "start": 850.68, "end": 859.3199999999999, "text": " And it offers an idea to create an international database of formats where various obscure", "tokens": [400, 309, 7736, 364, 1558, 281, 1884, 364, 5058, 8149, 295, 25879, 689, 3683, 34443], "temperature": 0.0, "avg_logprob": -0.1599991818269094, "compression_ratio": 1.477124183006536, "no_speech_prob": 0.00323398201726377}, {"id": 117, "seek": 84456, "start": 859.3199999999999, "end": 866.76, "text": " and historical formats would be documented in a uniform way for future preservation.", "tokens": [293, 8584, 25879, 576, 312, 23007, 294, 257, 9452, 636, 337, 2027, 27257, 13], "temperature": 0.0, "avg_logprob": -0.1599991818269094, "compression_ratio": 1.477124183006536, "no_speech_prob": 0.00323398201726377}, {"id": 118, "seek": 86676, "start": 866.76, "end": 876.3199999999999, "text": " And this would guarantee that we could basically, we could read the binary files we write now", "tokens": [400, 341, 576, 10815, 300, 321, 727, 1936, 11, 321, 727, 1401, 264, 17434, 7098, 321, 2464, 586], "temperature": 0.0, "avg_logprob": -0.17459631901161343, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.0010293921222910285}, {"id": 119, "seek": 86676, "start": 876.3199999999999, "end": 883.8, "text": " in like 100 or 200 years from now.", "tokens": [294, 411, 2319, 420, 2331, 924, 490, 586, 13], "temperature": 0.0, "avg_logprob": -0.17459631901161343, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.0010293921222910285}, {"id": 120, "seek": 86676, "start": 883.8, "end": 889.96, "text": " The fact that the Keita extract language is declarative makes it possible to automatically", "tokens": [440, 1186, 300, 264, 3189, 2786, 8947, 2856, 307, 16694, 1166, 1669, 309, 1944, 281, 6772], "temperature": 0.0, "avg_logprob": -0.17459631901161343, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.0010293921222910285}, {"id": 121, "seek": 88996, "start": 889.96, "end": 901.6, "text": " visualize it, visualize the described format in a Gravis diagram.", "tokens": [23273, 309, 11, 23273, 264, 7619, 7877, 294, 257, 8985, 4938, 10686, 13], "temperature": 0.0, "avg_logprob": -0.1966446081797282, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.00113385240547359}, {"id": 122, "seek": 88996, "start": 901.6, "end": 905.2, "text": " The Keita extract language is simple but powerful.", "tokens": [440, 3189, 2786, 8947, 2856, 307, 2199, 457, 4005, 13], "temperature": 0.0, "avg_logprob": -0.1966446081797282, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.00113385240547359}, {"id": 123, "seek": 88996, "start": 905.2, "end": 910.52, "text": " You can describe pretty much any binary format with it.", "tokens": [509, 393, 6786, 1238, 709, 604, 17434, 7877, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.1966446081797282, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.00113385240547359}, {"id": 124, "seek": 88996, "start": 910.52, "end": 918.84, "text": " And a case one specification starts with the meta section and this sets the little end", "tokens": [400, 257, 1389, 472, 31256, 3719, 365, 264, 19616, 3541, 293, 341, 6352, 264, 707, 917], "temperature": 0.0, "avg_logprob": -0.1966446081797282, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.00113385240547359}, {"id": 125, "seek": 91884, "start": 918.84, "end": 922.76, "text": " in byte order as default.", "tokens": [294, 40846, 1668, 382, 7576, 13], "temperature": 0.0, "avg_logprob": -0.17480131558009557, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.0006368725444190204}, {"id": 126, "seek": 91884, "start": 922.76, "end": 928.6800000000001, "text": " The SEQ section is a sequence of attributes.", "tokens": [440, 10269, 48, 3541, 307, 257, 8310, 295, 17212, 13], "temperature": 0.0, "avg_logprob": -0.17480131558009557, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.0006368725444190204}, {"id": 127, "seek": 91884, "start": 928.6800000000001, "end": 934.1600000000001, "text": " The attribute name is in the ID key.", "tokens": [440, 19667, 1315, 307, 294, 264, 7348, 2141, 13], "temperature": 0.0, "avg_logprob": -0.17480131558009557, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.0006368725444190204}, {"id": 128, "seek": 91884, "start": 934.1600000000001, "end": 945.0, "text": " The type U4 means that in this case num underscore files will be an unsigned for byte integer.", "tokens": [440, 2010, 624, 19, 1355, 300, 294, 341, 1389, 1031, 37556, 7098, 486, 312, 364, 2693, 16690, 337, 40846, 24922, 13], "temperature": 0.0, "avg_logprob": -0.17480131558009557, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.0006368725444190204}, {"id": 129, "seek": 94500, "start": 945.0, "end": 950.28, "text": " You can define your own types in the type section.", "tokens": [509, 393, 6964, 428, 1065, 3467, 294, 264, 2010, 3541, 13], "temperature": 0.0, "avg_logprob": -0.11714168578859359, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.00042511106585152447}, {"id": 130, "seek": 94500, "start": 950.28, "end": 953.0, "text": " A field can also be repeated.", "tokens": [316, 2519, 393, 611, 312, 10477, 13], "temperature": 0.0, "avg_logprob": -0.11714168578859359, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.00042511106585152447}, {"id": 131, "seek": 94500, "start": 953.0, "end": 964.0, "text": " So in this case the files attribute will be a list or an array of base type file.", "tokens": [407, 294, 341, 1389, 264, 7098, 19667, 486, 312, 257, 1329, 420, 364, 10225, 295, 3096, 2010, 3991, 13], "temperature": 0.0, "avg_logprob": -0.11714168578859359, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.00042511106585152447}, {"id": 132, "seek": 94500, "start": 964.0, "end": 973.32, "text": " In the instances section you can define attributes that start at an arbitrary byte position.", "tokens": [682, 264, 14519, 3541, 291, 393, 6964, 17212, 300, 722, 412, 364, 23211, 40846, 2535, 13], "temperature": 0.0, "avg_logprob": -0.11714168578859359, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.00042511106585152447}, {"id": 133, "seek": 97332, "start": 973.32, "end": 980.2, "text": " You can also use a powerful expression language in many places.", "tokens": [509, 393, 611, 764, 257, 4005, 6114, 2856, 294, 867, 3190, 13], "temperature": 0.0, "avg_logprob": -0.17409575612921463, "compression_ratio": 1.4671052631578947, "no_speech_prob": 0.0003282314573880285}, {"id": 134, "seek": 97332, "start": 980.2, "end": 987.8000000000001, "text": " And there is another built-in type is a character string in a certain encoding.", "tokens": [400, 456, 307, 1071, 3094, 12, 259, 2010, 307, 257, 2517, 6798, 294, 257, 1629, 43430, 13], "temperature": 0.0, "avg_logprob": -0.17409575612921463, "compression_ratio": 1.4671052631578947, "no_speech_prob": 0.0003282314573880285}, {"id": 135, "seek": 97332, "start": 987.8000000000001, "end": 998.0400000000001, "text": " And if you omit the type and only specify the size, the result is a byte array.", "tokens": [400, 498, 291, 3406, 270, 264, 2010, 293, 787, 16500, 264, 2744, 11, 264, 1874, 307, 257, 40846, 10225, 13], "temperature": 0.0, "avg_logprob": -0.17409575612921463, "compression_ratio": 1.4671052631578947, "no_speech_prob": 0.0003282314573880285}, {"id": 136, "seek": 99804, "start": 998.04, "end": 1004.68, "text": " There are several visualization and dumping tools available for inspecting files.", "tokens": [821, 366, 2940, 25801, 293, 42224, 3873, 2435, 337, 15018, 278, 7098, 13], "temperature": 0.0, "avg_logprob": -0.17311930656433105, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0001383349735988304}, {"id": 137, "seek": 99804, "start": 1004.68, "end": 1013.56, "text": " And this can be useful for, for example, for finding errors, forensic analysis, or debugging.", "tokens": [400, 341, 393, 312, 4420, 337, 11, 337, 1365, 11, 337, 5006, 13603, 11, 39084, 5215, 11, 420, 45592, 13], "temperature": 0.0, "avg_logprob": -0.17311930656433105, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0001383349735988304}, {"id": 138, "seek": 99804, "start": 1013.56, "end": 1024.8799999999999, "text": " And the visualizers allow us to view the structured data parts from the input file based on a", "tokens": [400, 264, 5056, 22525, 2089, 505, 281, 1910, 264, 18519, 1412, 3166, 490, 264, 4846, 3991, 2361, 322, 257], "temperature": 0.0, "avg_logprob": -0.17311930656433105, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0001383349735988304}, {"id": 139, "seek": 102488, "start": 1024.88, "end": 1029.8000000000002, "text": " kitesh track specification, so something like this.", "tokens": [350, 3324, 71, 2837, 31256, 11, 370, 746, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.21646809577941895, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.00047886077663861215}, {"id": 140, "seek": 102488, "start": 1029.8000000000002, "end": 1039.0800000000002, "text": " And you can use the console visualizer or also the command line to case dump is available,", "tokens": [400, 291, 393, 764, 264, 11076, 5056, 6545, 420, 611, 264, 5622, 1622, 281, 1389, 11430, 307, 2435, 11], "temperature": 0.0, "avg_logprob": -0.21646809577941895, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.00047886077663861215}, {"id": 141, "seek": 102488, "start": 1039.0800000000002, "end": 1044.72, "text": " which can give you the same structured data as you can see in JSON format.", "tokens": [597, 393, 976, 291, 264, 912, 18519, 1412, 382, 291, 393, 536, 294, 31828, 7877, 13], "temperature": 0.0, "avg_logprob": -0.21646809577941895, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.00047886077663861215}, {"id": 142, "seek": 102488, "start": 1044.72, "end": 1050.64, "text": " And this can be useful for automation.", "tokens": [400, 341, 393, 312, 4420, 337, 17769, 13], "temperature": 0.0, "avg_logprob": -0.21646809577941895, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.00047886077663861215}, {"id": 143, "seek": 105064, "start": 1050.64, "end": 1055.6000000000001, "text": " But the most popular visualization tool is the Web IDE.", "tokens": [583, 264, 881, 3743, 25801, 2290, 307, 264, 9573, 40930, 13], "temperature": 0.0, "avg_logprob": -0.16473167592828925, "compression_ratio": 1.4076433121019107, "no_speech_prob": 0.00022905944206286222}, {"id": 144, "seek": 105064, "start": 1055.6000000000001, "end": 1059.88, "text": " You can check it out on this URL.", "tokens": [509, 393, 1520, 309, 484, 322, 341, 12905, 13], "temperature": 0.0, "avg_logprob": -0.16473167592828925, "compression_ratio": 1.4076433121019107, "no_speech_prob": 0.00022905944206286222}, {"id": 145, "seek": 105064, "start": 1059.88, "end": 1068.16, "text": " And at the top right is a hex-dump of the input binary file.", "tokens": [400, 412, 264, 1192, 558, 307, 257, 23291, 12, 67, 1420, 295, 264, 4846, 17434, 3991, 13], "temperature": 0.0, "avg_logprob": -0.16473167592828925, "compression_ratio": 1.4076433121019107, "no_speech_prob": 0.00022905944206286222}, {"id": 146, "seek": 105064, "start": 1068.16, "end": 1077.2800000000002, "text": " So in this case I selected this.png file in the file tree on the left.", "tokens": [407, 294, 341, 1389, 286, 8209, 341, 2411, 79, 872, 3991, 294, 264, 3991, 4230, 322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.16473167592828925, "compression_ratio": 1.4076433121019107, "no_speech_prob": 0.00022905944206286222}, {"id": 147, "seek": 107728, "start": 1077.28, "end": 1086.48, "text": " And at the top left is the kitesh track specification editor, so a KSY spec editor.", "tokens": [400, 412, 264, 1192, 1411, 307, 264, 350, 3324, 71, 2837, 31256, 9839, 11, 370, 257, 591, 50, 56, 1608, 9839, 13], "temperature": 0.0, "avg_logprob": -0.10630958730524237, "compression_ratio": 1.9774011299435028, "no_speech_prob": 0.0016356242122128606}, {"id": 148, "seek": 107728, "start": 1086.48, "end": 1093.8, "text": " And according to the kitesh track specification, the input file is parsed and the result is", "tokens": [400, 4650, 281, 264, 350, 3324, 71, 2837, 31256, 11, 264, 4846, 3991, 307, 21156, 292, 293, 264, 1874, 307], "temperature": 0.0, "avg_logprob": -0.10630958730524237, "compression_ratio": 1.9774011299435028, "no_speech_prob": 0.0016356242122128606}, {"id": 149, "seek": 107728, "start": 1093.8, "end": 1100.0, "text": " the structured data that you see in the object tree at the bottom, bottom left.", "tokens": [264, 18519, 1412, 300, 291, 536, 294, 264, 2657, 4230, 412, 264, 2767, 11, 2767, 1411, 13], "temperature": 0.0, "avg_logprob": -0.10630958730524237, "compression_ratio": 1.9774011299435028, "no_speech_prob": 0.0016356242122128606}, {"id": 150, "seek": 107728, "start": 1100.0, "end": 1106.12, "text": " And when you edit the kitesh track specification, the input file is automatically parsed again", "tokens": [400, 562, 291, 8129, 264, 350, 3324, 71, 2837, 31256, 11, 264, 4846, 3991, 307, 6772, 21156, 292, 797], "temperature": 0.0, "avg_logprob": -0.10630958730524237, "compression_ratio": 1.9774011299435028, "no_speech_prob": 0.0016356242122128606}, {"id": 151, "seek": 110612, "start": 1106.12, "end": 1113.52, "text": " and the object tree is updated.", "tokens": [293, 264, 2657, 4230, 307, 10588, 13], "temperature": 0.0, "avg_logprob": -0.20127838850021362, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.0001515939657110721}, {"id": 152, "seek": 110612, "start": 1113.52, "end": 1122.1999999999998, "text": " Serialization is a new feature in kitesh track and it's being developed thanks to the financial", "tokens": [4210, 831, 2144, 307, 257, 777, 4111, 294, 350, 3324, 71, 2837, 293, 309, 311, 885, 4743, 3231, 281, 264, 4669], "temperature": 0.0, "avg_logprob": -0.20127838850021362, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.0001515939657110721}, {"id": 153, "seek": 110612, "start": 1122.1999999999998, "end": 1127.8, "text": " support of the NLNET Foundation.", "tokens": [1406, 295, 264, 426, 43, 35554, 10335, 13], "temperature": 0.0, "avg_logprob": -0.20127838850021362, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.0001515939657110721}, {"id": 154, "seek": 110612, "start": 1127.8, "end": 1136.08, "text": " While parsing allows you to read binary data to an object, serialization is all about", "tokens": [3987, 21156, 278, 4045, 291, 281, 1401, 17434, 1412, 281, 364, 2657, 11, 17436, 2144, 307, 439, 466], "temperature": 0.0, "avg_logprob": -0.20127838850021362, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.0001515939657110721}, {"id": 155, "seek": 113608, "start": 1136.08, "end": 1138.08, "text": " the inverse process.", "tokens": [264, 17340, 1399, 13], "temperature": 0.0, "avg_logprob": -0.23147510599206994, "compression_ratio": 1.3154362416107384, "no_speech_prob": 0.0002405179402558133}, {"id": 156, "seek": 113608, "start": 1138.08, "end": 1144.24, "text": " So we want to write an object to binary data.", "tokens": [407, 321, 528, 281, 2464, 364, 2657, 281, 17434, 1412, 13], "temperature": 0.0, "avg_logprob": -0.23147510599206994, "compression_ratio": 1.3154362416107384, "no_speech_prob": 0.0002405179402558133}, {"id": 157, "seek": 113608, "start": 1144.24, "end": 1156.8, "text": " And currently in kitesh track, the serialization for support for Java is fully working and", "tokens": [400, 4362, 294, 350, 3324, 71, 2837, 11, 264, 17436, 2144, 337, 1406, 337, 10745, 307, 4498, 1364, 293], "temperature": 0.0, "avg_logprob": -0.23147510599206994, "compression_ratio": 1.3154362416107384, "no_speech_prob": 0.0002405179402558133}, {"id": 158, "seek": 113608, "start": 1156.8, "end": 1163.1599999999999, "text": " C-sharp and Python are in development.", "tokens": [383, 12, 2716, 6529, 293, 15329, 366, 294, 3250, 13], "temperature": 0.0, "avg_logprob": -0.23147510599206994, "compression_ratio": 1.3154362416107384, "no_speech_prob": 0.0002405179402558133}, {"id": 159, "seek": 116316, "start": 1163.16, "end": 1167.24, "text": " There are basically two use cases of serialization.", "tokens": [821, 366, 1936, 732, 764, 3331, 295, 17436, 2144, 13], "temperature": 0.0, "avg_logprob": -0.08211312574498794, "compression_ratio": 1.6141304347826086, "no_speech_prob": 0.0009987636003643274}, {"id": 160, "seek": 116316, "start": 1167.24, "end": 1174.96, "text": " You can edit an existing file or you can create a new file from scratch.", "tokens": [509, 393, 8129, 364, 6741, 3991, 420, 291, 393, 1884, 257, 777, 3991, 490, 8459, 13], "temperature": 0.0, "avg_logprob": -0.08211312574498794, "compression_ratio": 1.6141304347826086, "no_speech_prob": 0.0009987636003643274}, {"id": 161, "seek": 116316, "start": 1174.96, "end": 1183.24, "text": " And the support for serialization greatly extends the use of all written format specifications", "tokens": [400, 264, 1406, 337, 17436, 2144, 14147, 26448, 264, 764, 295, 439, 3720, 7877, 29448], "temperature": 0.0, "avg_logprob": -0.08211312574498794, "compression_ratio": 1.6141304347826086, "no_speech_prob": 0.0009987636003643274}, {"id": 162, "seek": 116316, "start": 1183.24, "end": 1189.16, "text": " because now you can use them not only for parsing but also for serialization.", "tokens": [570, 586, 291, 393, 764, 552, 406, 787, 337, 21156, 278, 457, 611, 337, 17436, 2144, 13], "temperature": 0.0, "avg_logprob": -0.08211312574498794, "compression_ratio": 1.6141304347826086, "no_speech_prob": 0.0009987636003643274}, {"id": 163, "seek": 118916, "start": 1189.16, "end": 1197.48, "text": " And this has many uses, for example, you can convert one format into another or it can", "tokens": [400, 341, 575, 867, 4960, 11, 337, 1365, 11, 291, 393, 7620, 472, 7877, 666, 1071, 420, 309, 393], "temperature": 0.0, "avg_logprob": -0.17373242871514682, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0009022125159390271}, {"id": 164, "seek": 118916, "start": 1197.48, "end": 1206.78, "text": " be used for fuzzing or video games modding and so on.", "tokens": [312, 1143, 337, 283, 3334, 8781, 420, 960, 2813, 1072, 3584, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.17373242871514682, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0009022125159390271}, {"id": 165, "seek": 118916, "start": 1206.78, "end": 1212.96, "text": " This serialization process in kitesh track can be divided into four phases.", "tokens": [639, 17436, 2144, 1399, 294, 350, 3324, 71, 2837, 393, 312, 6666, 666, 1451, 18764, 13], "temperature": 0.0, "avg_logprob": -0.17373242871514682, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0009022125159390271}, {"id": 166, "seek": 121296, "start": 1212.96, "end": 1220.72, "text": " First you need to create a ks object and then you fill it with data.", "tokens": [2386, 291, 643, 281, 1884, 257, 350, 82, 2657, 293, 550, 291, 2836, 309, 365, 1412, 13], "temperature": 0.0, "avg_logprob": -0.2010211459660934, "compression_ratio": 1.53125, "no_speech_prob": 3.2350930268876255e-05}, {"id": 167, "seek": 121296, "start": 1220.72, "end": 1227.88, "text": " So you set its individual fields or attributes using setters.", "tokens": [407, 291, 992, 1080, 2609, 7909, 420, 17212, 1228, 992, 1559, 13], "temperature": 0.0, "avg_logprob": -0.2010211459660934, "compression_ratio": 1.53125, "no_speech_prob": 3.2350930268876255e-05}, {"id": 168, "seek": 121296, "start": 1227.88, "end": 1233.56, "text": " Then you should call the underscore check method to check the consistency of the data", "tokens": [1396, 291, 820, 818, 264, 37556, 1520, 3170, 281, 1520, 264, 14416, 295, 264, 1412], "temperature": 0.0, "avg_logprob": -0.2010211459660934, "compression_ratio": 1.53125, "no_speech_prob": 3.2350930268876255e-05}, {"id": 169, "seek": 121296, "start": 1233.56, "end": 1237.4, "text": " with the format constraints.", "tokens": [365, 264, 7877, 18491, 13], "temperature": 0.0, "avg_logprob": -0.2010211459660934, "compression_ratio": 1.53125, "no_speech_prob": 3.2350930268876255e-05}, {"id": 170, "seek": 123740, "start": 1237.4, "end": 1250.72, "text": " Finally, we can call underscore write and pass the stream where to write.", "tokens": [6288, 11, 321, 393, 818, 37556, 2464, 293, 1320, 264, 4309, 689, 281, 2464, 13], "temperature": 0.0, "avg_logprob": -0.24269840329192405, "compression_ratio": 1.2945736434108528, "no_speech_prob": 0.00036556916893459857}, {"id": 171, "seek": 123740, "start": 1250.72, "end": 1258.92, "text": " And you can actually check out more details of how to use serialization in Java on this", "tokens": [400, 291, 393, 767, 1520, 484, 544, 4365, 295, 577, 281, 764, 17436, 2144, 294, 10745, 322, 341], "temperature": 0.0, "avg_logprob": -0.24269840329192405, "compression_ratio": 1.2945736434108528, "no_speech_prob": 0.00036556916893459857}, {"id": 172, "seek": 123740, "start": 1258.92, "end": 1261.2800000000002, "text": " page.", "tokens": [3028, 13], "temperature": 0.0, "avg_logprob": -0.24269840329192405, "compression_ratio": 1.2945736434108528, "no_speech_prob": 0.00036556916893459857}, {"id": 173, "seek": 126128, "start": 1261.28, "end": 1272.32, "text": " Currently, the serialization support in kitesh track is designed for the general case so", "tokens": [19964, 11, 264, 17436, 2144, 1406, 294, 350, 3324, 71, 2837, 307, 4761, 337, 264, 2674, 1389, 370], "temperature": 0.0, "avg_logprob": -0.22094434307467553, "compression_ratio": 1.6, "no_speech_prob": 0.0017483873525634408}, {"id": 174, "seek": 126128, "start": 1272.32, "end": 1276.76, "text": " that it works for every conceivable format specification.", "tokens": [300, 309, 1985, 337, 633, 10413, 34376, 7877, 31256, 13], "temperature": 0.0, "avg_logprob": -0.22094434307467553, "compression_ratio": 1.6, "no_speech_prob": 0.0017483873525634408}, {"id": 175, "seek": 126128, "start": 1276.76, "end": 1285.24, "text": " While a simple solution would work for perhaps most specifications, well, the solution that", "tokens": [3987, 257, 2199, 3827, 576, 589, 337, 4317, 881, 29448, 11, 731, 11, 264, 3827, 300], "temperature": 0.0, "avg_logprob": -0.22094434307467553, "compression_ratio": 1.6, "no_speech_prob": 0.0017483873525634408}, {"id": 176, "seek": 126128, "start": 1285.24, "end": 1289.6, "text": " works for all of them was chosen.", "tokens": [1985, 337, 439, 295, 552, 390, 8614, 13], "temperature": 0.0, "avg_logprob": -0.22094434307467553, "compression_ratio": 1.6, "no_speech_prob": 0.0017483873525634408}, {"id": 177, "seek": 128960, "start": 1289.6, "end": 1293.7199999999998, "text": " Even at the cost of delegating some task to the user.", "tokens": [2754, 412, 264, 2063, 295, 15824, 990, 512, 5633, 281, 264, 4195, 13], "temperature": 0.0, "avg_logprob": -0.1504770415169852, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.0009285601554438472}, {"id": 178, "seek": 128960, "start": 1293.7199999999998, "end": 1300.9599999999998, "text": " In the future, I would like to automate these tasks that need to be done manually at the", "tokens": [682, 264, 2027, 11, 286, 576, 411, 281, 31605, 613, 9608, 300, 643, 281, 312, 1096, 16945, 412, 264], "temperature": 0.0, "avg_logprob": -0.1504770415169852, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.0009285601554438472}, {"id": 179, "seek": 128960, "start": 1300.9599999999998, "end": 1307.56, "text": " moment so that it's more convenient for the user.", "tokens": [1623, 370, 300, 309, 311, 544, 10851, 337, 264, 4195, 13], "temperature": 0.0, "avg_logprob": -0.1504770415169852, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.0009285601554438472}, {"id": 180, "seek": 128960, "start": 1307.56, "end": 1316.84, "text": " The basic idea is that the user sets everything, including lengths of sets, magic signatures", "tokens": [440, 3875, 1558, 307, 300, 264, 4195, 6352, 1203, 11, 3009, 26329, 295, 6352, 11, 5585, 32322], "temperature": 0.0, "avg_logprob": -0.1504770415169852, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.0009285601554438472}, {"id": 181, "seek": 131684, "start": 1316.84, "end": 1320.9599999999998, "text": " and kitesh track checks for consistency.", "tokens": [293, 350, 3324, 71, 2837, 13834, 337, 14416, 13], "temperature": 0.0, "avg_logprob": -0.20298419175324617, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0010961422231048346}, {"id": 182, "seek": 131684, "start": 1320.9599999999998, "end": 1326.0, "text": " Also, only fixed length streams are considered.", "tokens": [2743, 11, 787, 6806, 4641, 15842, 366, 4888, 13], "temperature": 0.0, "avg_logprob": -0.20298419175324617, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0010961422231048346}, {"id": 183, "seek": 131684, "start": 1326.0, "end": 1331.8, "text": " So once you create a stream, you cannot resize it.", "tokens": [407, 1564, 291, 1884, 257, 4309, 11, 291, 2644, 50069, 309, 13], "temperature": 0.0, "avg_logprob": -0.20298419175324617, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0010961422231048346}, {"id": 184, "seek": 131684, "start": 1331.8, "end": 1340.6399999999999, "text": " Finally, I would like to talk about the plans for the future.", "tokens": [6288, 11, 286, 576, 411, 281, 751, 466, 264, 5482, 337, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.20298419175324617, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0010961422231048346}, {"id": 185, "seek": 134064, "start": 1340.64, "end": 1350.8000000000002, "text": " Design for C-sharp and Python is in development and they should be ready in two months.", "tokens": [12748, 337, 383, 12, 2716, 6529, 293, 15329, 307, 294, 3250, 293, 436, 820, 312, 1919, 294, 732, 2493, 13], "temperature": 0.0, "avg_logprob": -0.2930852488467568, "compression_ratio": 1.4846938775510203, "no_speech_prob": 0.004506546538323164}, {"id": 186, "seek": 134064, "start": 1350.8000000000002, "end": 1357.64, "text": " There is also interest in adding Rust, C and Julia as target languages.", "tokens": [821, 307, 611, 1179, 294, 5127, 34952, 11, 383, 293, 18551, 382, 3779, 8650, 13], "temperature": 0.0, "avg_logprob": -0.2930852488467568, "compression_ratio": 1.4846938775510203, "no_speech_prob": 0.004506546538323164}, {"id": 187, "seek": 134064, "start": 1357.64, "end": 1365.24, "text": " And I would also like to see Wireshark desectors as a target because the concept of kitesh", "tokens": [400, 286, 576, 611, 411, 281, 536, 343, 3145, 71, 809, 730, 557, 830, 382, 257, 3779, 570, 264, 3410, 295, 350, 3324, 71], "temperature": 0.0, "avg_logprob": -0.2930852488467568, "compression_ratio": 1.4846938775510203, "no_speech_prob": 0.004506546538323164}, {"id": 188, "seek": 134064, "start": 1365.24, "end": 1368.44, "text": " is not limited to programming languages.", "tokens": [307, 406, 5567, 281, 9410, 8650, 13], "temperature": 0.0, "avg_logprob": -0.2930852488467568, "compression_ratio": 1.4846938775510203, "no_speech_prob": 0.004506546538323164}, {"id": 189, "seek": 136844, "start": 1368.44, "end": 1376.2, "text": " A target can be anything, for example, we already have a target for construct, which", "tokens": [316, 3779, 393, 312, 1340, 11, 337, 1365, 11, 321, 1217, 362, 257, 3779, 337, 7690, 11, 597], "temperature": 0.0, "avg_logprob": -0.2514676180752841, "compression_ratio": 1.3129770992366412, "no_speech_prob": 0.0019177544163540006}, {"id": 190, "seek": 136844, "start": 1376.2, "end": 1384.64, "text": " is a Python library for parsing and serialization of binary data.", "tokens": [307, 257, 15329, 6405, 337, 21156, 278, 293, 17436, 2144, 295, 17434, 1412, 13], "temperature": 0.0, "avg_logprob": -0.2514676180752841, "compression_ratio": 1.3129770992366412, "no_speech_prob": 0.0019177544163540006}, {"id": 191, "seek": 136844, "start": 1384.64, "end": 1385.64, "text": " Thanks for listening.", "tokens": [2561, 337, 4764, 13], "temperature": 0.0, "avg_logprob": -0.2514676180752841, "compression_ratio": 1.3129770992366412, "no_speech_prob": 0.0019177544163540006}, {"id": 192, "seek": 138564, "start": 1385.64, "end": 1413.2, "text": " Now it's time for our questions.", "tokens": [823, 309, 311, 565, 337, 527, 1651, 13], "temperature": 0.0, "avg_logprob": -0.49563145637512207, "compression_ratio": 0.8, "no_speech_prob": 0.0018465013708919287}, {"id": 193, "seek": 141320, "start": 1413.2, "end": 1427.8400000000001, "text": " Yes, there is a dock key for which you can use on attributes and types in many places", "tokens": [1079, 11, 456, 307, 257, 20929, 2141, 337, 597, 291, 393, 764, 322, 17212, 293, 3467, 294, 867, 3190], "temperature": 0.0, "avg_logprob": -0.25095632599621287, "compression_ratio": 1.4065040650406504, "no_speech_prob": 0.0268310084939003}, {"id": 194, "seek": 141320, "start": 1427.8400000000001, "end": 1440.64, "text": " and you can write some documentation of the specific element and in some languages, but", "tokens": [293, 291, 393, 2464, 512, 14333, 295, 264, 2685, 4478, 293, 294, 512, 8650, 11, 457], "temperature": 0.0, "avg_logprob": -0.25095632599621287, "compression_ratio": 1.4065040650406504, "no_speech_prob": 0.0268310084939003}, {"id": 195, "seek": 144064, "start": 1440.64, "end": 1454.88, "text": " it doesn't work like 100% of the time, but the idea is that these documentation should", "tokens": [309, 1177, 380, 589, 411, 2319, 4, 295, 264, 565, 11, 457, 264, 1558, 307, 300, 613, 14333, 820], "temperature": 0.0, "avg_logprob": -0.28727206729707266, "compression_ratio": 1.3692307692307693, "no_speech_prob": 0.0030197796877473593}, {"id": 196, "seek": 144064, "start": 1454.88, "end": 1467.0, "text": " translate to the generated parser as dock blocks and then the IDs and tools for development", "tokens": [13799, 281, 264, 10833, 21156, 260, 382, 20929, 8474, 293, 550, 264, 48212, 293, 3873, 337, 3250], "temperature": 0.0, "avg_logprob": -0.28727206729707266, "compression_ratio": 1.3692307692307693, "no_speech_prob": 0.0030197796877473593}, {"id": 197, "seek": 146700, "start": 1467.0, "end": 1472.28, "text": " should autocomplete usually this documentation.", "tokens": [820, 45833, 298, 17220, 2673, 341, 14333, 13], "temperature": 0.0, "avg_logprob": -0.4053565774645124, "compression_ratio": 1.3924050632911393, "no_speech_prob": 9.200276690535247e-05}, {"id": 198, "seek": 146700, "start": 1472.28, "end": 1483.28, "text": " Do you support in DNS when generating source code, depending on the target machine?", "tokens": [1144, 291, 1406, 294, 35153, 562, 17746, 4009, 3089, 11, 5413, 322, 264, 3779, 3479, 30], "temperature": 0.0, "avg_logprob": -0.4053565774645124, "compression_ratio": 1.3924050632911393, "no_speech_prob": 9.200276690535247e-05}, {"id": 199, "seek": 146700, "start": 1483.28, "end": 1496.08, "text": " Yes, there is a feature for calculated NDNS, it is called and you can switch the NDNS or", "tokens": [1079, 11, 456, 307, 257, 4111, 337, 15598, 426, 35, 42003, 11, 309, 307, 1219, 293, 291, 393, 3679, 264, 426, 35, 42003, 420], "temperature": 0.0, "avg_logprob": -0.4053565774645124, "compression_ratio": 1.3924050632911393, "no_speech_prob": 9.200276690535247e-05}, {"id": 200, "seek": 149608, "start": 1496.08, "end": 1505.72, "text": " the default NDNS based on the value of an arbitrary expression basically, so this can", "tokens": [264, 7576, 426, 35, 42003, 2361, 322, 264, 2158, 295, 364, 23211, 6114, 1936, 11, 370, 341, 393], "temperature": 0.0, "avg_logprob": -0.27938675157951587, "compression_ratio": 1.425, "no_speech_prob": 0.003937183879315853}, {"id": 201, "seek": 149608, "start": 1505.72, "end": 1506.72, "text": "...", "tokens": [1097], "temperature": 0.0, "avg_logprob": -0.27938675157951587, "compression_ratio": 1.425, "no_speech_prob": 0.003937183879315853}, {"id": 202, "seek": 149608, "start": 1506.72, "end": 1512.1999999999998, "text": " But do you support host NDNS and target NDNS?", "tokens": [583, 360, 291, 1406, 3975, 426, 35, 42003, 293, 3779, 426, 35, 42003, 30], "temperature": 0.0, "avg_logprob": -0.27938675157951587, "compression_ratio": 1.425, "no_speech_prob": 0.003937183879315853}, {"id": 203, "seek": 149608, "start": 1512.1999999999998, "end": 1523.56, "text": " Well, not really, but it's not that of a limitation because you can, for example, you can use", "tokens": [1042, 11, 406, 534, 11, 457, 309, 311, 406, 300, 295, 257, 27432, 570, 291, 393, 11, 337, 1365, 11, 291, 393, 764], "temperature": 0.0, "avg_logprob": -0.27938675157951587, "compression_ratio": 1.425, "no_speech_prob": 0.003937183879315853}, {"id": 204, "seek": 152356, "start": 1523.56, "end": 1531.3999999999999, "text": " parameters, for example, to pass it from your application basically because I don't", "tokens": [9834, 11, 337, 1365, 11, 281, 1320, 309, 490, 428, 3861, 1936, 570, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.26659303722959576, "compression_ratio": 1.4597701149425288, "no_speech_prob": 0.0021931116934865713}, {"id": 205, "seek": 152356, "start": 1531.3999999999999, "end": 1540.36, "text": " know if I can... I don't know if it's a good idea, but another feature of KiteStruck", "tokens": [458, 498, 286, 393, 1097, 286, 500, 380, 458, 498, 309, 311, 257, 665, 1558, 11, 457, 1071, 4111, 295, 591, 642, 4520, 8161], "temperature": 0.0, "avg_logprob": -0.26659303722959576, "compression_ratio": 1.4597701149425288, "no_speech_prob": 0.0021931116934865713}, {"id": 206, "seek": 152356, "start": 1540.36, "end": 1548.8799999999999, "text": " is that you can define that types can have parameters and even the top level... Yeah,", "tokens": [307, 300, 291, 393, 6964, 300, 3467, 393, 362, 9834, 293, 754, 264, 1192, 1496, 1097, 865, 11], "temperature": 0.0, "avg_logprob": -0.26659303722959576, "compression_ratio": 1.4597701149425288, "no_speech_prob": 0.0021931116934865713}, {"id": 207, "seek": 154888, "start": 1548.88, "end": 1557.8400000000001, "text": " I should probably at least... Never mind, yeah, and you can define parameters and you", "tokens": [286, 820, 1391, 412, 1935, 1097, 7344, 1575, 11, 1338, 11, 293, 291, 393, 6964, 9834, 293, 291], "temperature": 0.0, "avg_logprob": -0.31740683775681716, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.0016431352123618126}, {"id": 208, "seek": 154888, "start": 1557.8400000000001, "end": 1569.0, "text": " can easily pass a parameter from your application that will somehow change the behavior of the", "tokens": [393, 3612, 1320, 257, 13075, 490, 428, 3861, 300, 486, 6063, 1319, 264, 5223, 295, 264], "temperature": 0.0, "avg_logprob": -0.31740683775681716, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.0016431352123618126}, {"id": 209, "seek": 154888, "start": 1569.0, "end": 1573.2, "text": " specification over, yeah, so it's possible.", "tokens": [31256, 670, 11, 1338, 11, 370, 309, 311, 1944, 13], "temperature": 0.0, "avg_logprob": -0.31740683775681716, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.0016431352123618126}, {"id": 210, "seek": 157320, "start": 1573.2, "end": 1584.4, "text": " With KSI, you seem to aim to define specification for certain languages or formats, but for", "tokens": [2022, 591, 20262, 11, 291, 1643, 281, 5939, 281, 6964, 31256, 337, 1629, 8650, 420, 25879, 11, 457, 337], "temperature": 0.0, "avg_logprob": -0.3367555649554143, "compression_ratio": 1.5747126436781609, "no_speech_prob": 0.013396497815847397}, {"id": 211, "seek": 157320, "start": 1584.4, "end": 1590.4, "text": " languages and formats that already have a specification, how can you ensure that these two specs are", "tokens": [8650, 293, 25879, 300, 1217, 362, 257, 31256, 11, 577, 393, 291, 5586, 300, 613, 732, 27911, 366], "temperature": 0.0, "avg_logprob": -0.3367555649554143, "compression_ratio": 1.5747126436781609, "no_speech_prob": 0.013396497815847397}, {"id": 212, "seek": 157320, "start": 1590.4, "end": 1598.4, "text": " actually the same and that you're not passing differently than other parts of it?", "tokens": [767, 264, 912, 293, 300, 291, 434, 406, 8437, 7614, 813, 661, 3166, 295, 309, 30], "temperature": 0.0, "avg_logprob": -0.3367555649554143, "compression_ratio": 1.5747126436781609, "no_speech_prob": 0.013396497815847397}, {"id": 213, "seek": 159840, "start": 1598.4, "end": 1604.8000000000002, "text": " I don't... Well, you mean that there is already an implementation of some...", "tokens": [286, 500, 380, 1097, 1042, 11, 291, 914, 300, 456, 307, 1217, 364, 11420, 295, 512, 1097], "temperature": 0.0, "avg_logprob": -0.36428687355735084, "compression_ratio": 1.3355704697986577, "no_speech_prob": 0.005614432506263256}, {"id": 214, "seek": 159840, "start": 1604.8000000000002, "end": 1613.8000000000002, "text": " For example, someone's passing ZIP files out there, how do you guarantee that KiteStruck", "tokens": [1171, 1365, 11, 1580, 311, 8437, 1176, 9139, 7098, 484, 456, 11, 577, 360, 291, 10815, 300, 591, 642, 4520, 8161], "temperature": 0.0, "avg_logprob": -0.36428687355735084, "compression_ratio": 1.3355704697986577, "no_speech_prob": 0.005614432506263256}, {"id": 215, "seek": 159840, "start": 1613.8000000000002, "end": 1619.4, "text": " will pass ZIP files the same way?", "tokens": [486, 1320, 1176, 9139, 7098, 264, 912, 636, 30], "temperature": 0.0, "avg_logprob": -0.36428687355735084, "compression_ratio": 1.3355704697986577, "no_speech_prob": 0.005614432506263256}, {"id": 216, "seek": 161940, "start": 1619.4, "end": 1633.0, "text": " You don't basically, but from this point of view, it's just another implementation... Well,", "tokens": [509, 500, 380, 1936, 11, 457, 490, 341, 935, 295, 1910, 11, 309, 311, 445, 1071, 11420, 1097, 1042, 11], "temperature": 0.0, "avg_logprob": -0.21725130716959634, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.0005789975402876735}, {"id": 217, "seek": 161940, "start": 1633.0, "end": 1640.3200000000002, "text": " if you compare it to other parsers, for example, so there is, for example, a ZIP parser in", "tokens": [498, 291, 6794, 309, 281, 661, 21156, 433, 11, 337, 1365, 11, 370, 456, 307, 11, 337, 1365, 11, 257, 1176, 9139, 21156, 260, 294], "temperature": 0.0, "avg_logprob": -0.21725130716959634, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.0005789975402876735}, {"id": 218, "seek": 161940, "start": 1640.3200000000002, "end": 1647.24, "text": " every language, yeah, so ZIP parser library and this KiteStruck specification, it's just", "tokens": [633, 2856, 11, 1338, 11, 370, 1176, 9139, 21156, 260, 6405, 293, 341, 591, 642, 4520, 8161, 31256, 11, 309, 311, 445], "temperature": 0.0, "avg_logprob": -0.21725130716959634, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.0005789975402876735}, {"id": 219, "seek": 164724, "start": 1647.24, "end": 1654.8, "text": " another implementation, so, well, it needs to be developed carefully so that it works", "tokens": [1071, 11420, 11, 370, 11, 731, 11, 309, 2203, 281, 312, 4743, 7500, 370, 300, 309, 1985], "temperature": 0.0, "avg_logprob": -0.3879803825827206, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0036588571965694427}, {"id": 220, "seek": 164724, "start": 1654.8, "end": 1655.8, "text": " well or... Yeah.", "tokens": [731, 420, 1097, 865, 13], "temperature": 0.0, "avg_logprob": -0.3879803825827206, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0036588571965694427}, {"id": 221, "seek": 164724, "start": 1655.8, "end": 1664.8, "text": " I guess you would need a way to translate from a written specification to the KataI structure", "tokens": [286, 2041, 291, 576, 643, 257, 636, 281, 13799, 490, 257, 3720, 31256, 281, 264, 591, 3274, 40, 3877], "temperature": 0.0, "avg_logprob": -0.3879803825827206, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0036588571965694427}, {"id": 222, "seek": 164724, "start": 1664.8, "end": 1671.28, "text": " or the other way around to validate that what you wrote as the script actually corresponds", "tokens": [420, 264, 661, 636, 926, 281, 29562, 300, 437, 291, 4114, 382, 264, 5755, 767, 23249], "temperature": 0.0, "avg_logprob": -0.3879803825827206, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0036588571965694427}, {"id": 223, "seek": 164724, "start": 1671.28, "end": 1677.04, "text": " to the actual specification, for example, if a specification is already matched in machine", "tokens": [281, 264, 3539, 31256, 11, 337, 1365, 11, 498, 257, 31256, 307, 1217, 21447, 294, 3479], "temperature": 0.0, "avg_logprob": -0.3879803825827206, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0036588571965694427}, {"id": 224, "seek": 167704, "start": 1677.04, "end": 1684.2, "text": " written, which is readable, I mean, it's not here, we should have a tool to convert from", "tokens": [3720, 11, 597, 307, 49857, 11, 286, 914, 11, 309, 311, 406, 510, 11, 321, 820, 362, 257, 2290, 281, 7620, 490], "temperature": 0.0, "avg_logprob": -0.4762296571836367, "compression_ratio": 1.5679611650485437, "no_speech_prob": 0.027202164754271507}, {"id": 225, "seek": 167704, "start": 1684.2, "end": 1688.36, "text": " one to the other, so that would ensure that the passing is correct.", "tokens": [472, 281, 264, 661, 11, 370, 300, 576, 5586, 300, 264, 8437, 307, 3006, 13], "temperature": 0.0, "avg_logprob": -0.4762296571836367, "compression_ratio": 1.5679611650485437, "no_speech_prob": 0.027202164754271507}, {"id": 226, "seek": 167704, "start": 1688.36, "end": 1694.3999999999999, "text": " But it doesn't help, because the implementation is done by humans, it's impossible, it's", "tokens": [583, 309, 1177, 380, 854, 11, 570, 264, 11420, 307, 1096, 538, 6255, 11, 309, 311, 6243, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.4762296571836367, "compression_ratio": 1.5679611650485437, "no_speech_prob": 0.027202164754271507}, {"id": 227, "seek": 167704, "start": 1694.3999999999999, "end": 1695.3999999999999, "text": " impossible.", "tokens": [6243, 13], "temperature": 0.0, "avg_logprob": -0.4762296571836367, "compression_ratio": 1.5679611650485437, "no_speech_prob": 0.027202164754271507}, {"id": 228, "seek": 167704, "start": 1695.3999999999999, "end": 1696.3999999999999, "text": " It's just an introduction.", "tokens": [467, 311, 445, 364, 9339, 13], "temperature": 0.0, "avg_logprob": -0.4762296571836367, "compression_ratio": 1.5679611650485437, "no_speech_prob": 0.027202164754271507}, {"id": 229, "seek": 167704, "start": 1696.3999999999999, "end": 1697.3999999999999, "text": " You have to run all those things.", "tokens": [509, 362, 281, 1190, 439, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.4762296571836367, "compression_ratio": 1.5679611650485437, "no_speech_prob": 0.027202164754271507}, {"id": 230, "seek": 167704, "start": 1697.3999999999999, "end": 1698.3999999999999, "text": " Why?", "tokens": [1545, 30], "temperature": 0.0, "avg_logprob": -0.4762296571836367, "compression_ratio": 1.5679611650485437, "no_speech_prob": 0.027202164754271507}, {"id": 231, "seek": 169840, "start": 1698.4, "end": 1725.92, "text": " I'm wondering if it would be possible to add some functionality to that, not only parsing", "tokens": [286, 478, 6359, 498, 309, 576, 312, 1944, 281, 909, 512, 14980, 281, 300, 11, 406, 787, 21156, 278], "temperature": 0.0, "avg_logprob": -0.4653931493344514, "compression_ratio": 1.072289156626506, "no_speech_prob": 0.027782198041677475}, {"id": 232, "seek": 172592, "start": 1725.92, "end": 1732.48, "text": " but some very common functionality, do you think you can add that in the highest form?", "tokens": [457, 512, 588, 2689, 14980, 11, 360, 291, 519, 291, 393, 909, 300, 294, 264, 6343, 1254, 30], "temperature": 0.0, "avg_logprob": -0.3512246873643663, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.006407352164387703}, {"id": 233, "seek": 172592, "start": 1732.48, "end": 1737.76, "text": " Common functionalities, so... Like, for example, there's a binary format and there's", "tokens": [18235, 11745, 1088, 11, 370, 1097, 1743, 11, 337, 1365, 11, 456, 311, 257, 17434, 7877, 293, 456, 311], "temperature": 0.0, "avg_logprob": -0.3512246873643663, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.006407352164387703}, {"id": 234, "seek": 172592, "start": 1737.76, "end": 1744.3200000000002, "text": " very common functionality everybody uses on that, let's say, like, I don't know, cutting", "tokens": [588, 2689, 14980, 2201, 4960, 322, 300, 11, 718, 311, 584, 11, 411, 11, 286, 500, 380, 458, 11, 6492], "temperature": 0.0, "avg_logprob": -0.3512246873643663, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.006407352164387703}, {"id": 235, "seek": 172592, "start": 1744.3200000000002, "end": 1751.96, "text": " a part of it or getting, calculating some, I don't know, value, magic value or hash value,", "tokens": [257, 644, 295, 309, 420, 1242, 11, 28258, 512, 11, 286, 500, 380, 458, 11, 2158, 11, 5585, 2158, 420, 22019, 2158, 11], "temperature": 0.0, "avg_logprob": -0.3512246873643663, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.006407352164387703}, {"id": 236, "seek": 175196, "start": 1751.96, "end": 1759.04, "text": " could you add some extra functionality other than parsing in there?", "tokens": [727, 291, 909, 512, 2857, 14980, 661, 813, 21156, 278, 294, 456, 30], "temperature": 0.0, "avg_logprob": -0.23467350006103516, "compression_ratio": 1.6122448979591837, "no_speech_prob": 0.0075025479309260845}, {"id": 237, "seek": 175196, "start": 1759.04, "end": 1767.28, "text": " Well, so the question was that if you can, if we can add some common functionality in", "tokens": [1042, 11, 370, 264, 1168, 390, 300, 498, 291, 393, 11, 498, 321, 393, 909, 512, 2689, 14980, 294], "temperature": 0.0, "avg_logprob": -0.23467350006103516, "compression_ratio": 1.6122448979591837, "no_speech_prob": 0.0075025479309260845}, {"id": 238, "seek": 175196, "start": 1767.28, "end": 1777.1200000000001, "text": " addition to the format specification, and the answer is that, well, you can do this", "tokens": [4500, 281, 264, 7877, 31256, 11, 293, 264, 1867, 307, 300, 11, 731, 11, 291, 393, 360, 341], "temperature": 0.0, "avg_logprob": -0.23467350006103516, "compression_ratio": 1.6122448979591837, "no_speech_prob": 0.0075025479309260845}, {"id": 239, "seek": 177712, "start": 1777.12, "end": 1786.0, "text": " to a certain extent, because there are, I didn't mention them or talk about them, but", "tokens": [281, 257, 1629, 8396, 11, 570, 456, 366, 11, 286, 994, 380, 2152, 552, 420, 751, 466, 552, 11, 457], "temperature": 0.0, "avg_logprob": -0.22048118932923275, "compression_ratio": 1.6107784431137724, "no_speech_prob": 0.003610587678849697}, {"id": 240, "seek": 177712, "start": 1786.0, "end": 1797.9599999999998, "text": " there are value instances, and you can prepare some, you can, this is like a calculated attribute,", "tokens": [456, 366, 2158, 14519, 11, 293, 291, 393, 5940, 512, 11, 291, 393, 11, 341, 307, 411, 257, 15598, 19667, 11], "temperature": 0.0, "avg_logprob": -0.22048118932923275, "compression_ratio": 1.6107784431137724, "no_speech_prob": 0.003610587678849697}, {"id": 241, "seek": 177712, "start": 1797.9599999999998, "end": 1803.52, "text": " so you can write an arbitrary expression to it, and this can calculate, for example,", "tokens": [370, 291, 393, 2464, 364, 23211, 6114, 281, 309, 11, 293, 341, 393, 8873, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.22048118932923275, "compression_ratio": 1.6107784431137724, "no_speech_prob": 0.003610587678849697}, {"id": 242, "seek": 180352, "start": 1803.52, "end": 1814.52, "text": " some, like, I wrote a, I wrote a BMP specification or I extended it, and I used this, for example,", "tokens": [512, 11, 411, 11, 286, 4114, 257, 11, 286, 4114, 257, 363, 12224, 31256, 420, 286, 10913, 309, 11, 293, 286, 1143, 341, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.22941759745279947, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.001055966829881072}, {"id": 243, "seek": 180352, "start": 1814.52, "end": 1823.0, "text": " to, well, in the BMP format, there are like color masks in different places, depending", "tokens": [281, 11, 731, 11, 294, 264, 363, 12224, 7877, 11, 456, 366, 411, 2017, 11830, 294, 819, 3190, 11, 5413], "temperature": 0.0, "avg_logprob": -0.22941759745279947, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.001055966829881072}, {"id": 244, "seek": 180352, "start": 1823.0, "end": 1833.48, "text": " on the head version, and I used a value instance to get it from, so, depending on", "tokens": [322, 264, 1378, 3037, 11, 293, 286, 1143, 257, 2158, 5197, 281, 483, 309, 490, 11, 370, 11, 5413, 322], "temperature": 0.0, "avg_logprob": -0.22941759745279947, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.001055966829881072}, {"id": 245, "seek": 183348, "start": 1833.48, "end": 1844.0, "text": " the version, so either get it from here on here, or if it's a fixed, fixed, I don't", "tokens": [264, 3037, 11, 370, 2139, 483, 309, 490, 510, 322, 510, 11, 420, 498, 309, 311, 257, 6806, 11, 6806, 11, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.2512128260228541, "compression_ratio": 1.6024844720496894, "no_speech_prob": 0.0011512958444654942}, {"id": 246, "seek": 183348, "start": 1844.0, "end": 1850.72, "text": " know if it's fixed core palette, or what is it called, so, yeah, we can do this to", "tokens": [458, 498, 309, 311, 6806, 4965, 15851, 11, 420, 437, 307, 309, 1219, 11, 370, 11, 1338, 11, 321, 393, 360, 341, 281], "temperature": 0.0, "avg_logprob": -0.2512128260228541, "compression_ratio": 1.6024844720496894, "no_speech_prob": 0.0011512958444654942}, {"id": 247, "seek": 183348, "start": 1850.72, "end": 1860.8, "text": " a certain extent, but some common functionality, like, I don't know some, well, if it would", "tokens": [257, 1629, 8396, 11, 457, 512, 2689, 14980, 11, 411, 11, 286, 500, 380, 458, 512, 11, 731, 11, 498, 309, 576], "temperature": 0.0, "avg_logprob": -0.2512128260228541, "compression_ratio": 1.6024844720496894, "no_speech_prob": 0.0011512958444654942}, {"id": 248, "seek": 186080, "start": 1860.8, "end": 1869.32, "text": " require, like, a programming language or something like that, so this would be infeasible, basically,", "tokens": [3651, 11, 411, 11, 257, 9410, 2856, 420, 746, 411, 300, 11, 370, 341, 576, 312, 1536, 68, 296, 964, 11, 1936, 11], "temperature": 0.0, "avg_logprob": -0.21028175354003906, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0013953824527561665}, {"id": 249, "seek": 186080, "start": 1869.32, "end": 1882.2, "text": " because then, then we should, we would have, we would have to some, some programming languages,", "tokens": [570, 550, 11, 550, 321, 820, 11, 321, 576, 362, 11, 321, 576, 362, 281, 512, 11, 512, 9410, 8650, 11], "temperature": 0.0, "avg_logprob": -0.21028175354003906, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0013953824527561665}, {"id": 250, "seek": 188220, "start": 1882.2, "end": 1891.24, "text": " something language that translates to all targets, which is basically impossible, I", "tokens": [746, 2856, 300, 28468, 281, 439, 12911, 11, 597, 307, 1936, 6243, 11, 286], "temperature": 0.0, "avg_logprob": -0.39553829034169513, "compression_ratio": 1.1294117647058823, "no_speech_prob": 0.004004908725619316}, {"id": 251, "seek": 188220, "start": 1891.24, "end": 1892.24, "text": " think, yeah.", "tokens": [519, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.39553829034169513, "compression_ratio": 1.1294117647058823, "no_speech_prob": 0.004004908725619316}, {"id": 252, "seek": 189224, "start": 1892.24, "end": 1912.76, "text": " There is some different type of learning, like service, you know, testing, you are", "tokens": [821, 307, 512, 819, 2010, 295, 2539, 11, 411, 2643, 11, 291, 458, 11, 4997, 11, 291, 366], "temperature": 1.0, "avg_logprob": -2.936227625066584, "compression_ratio": 1.0649350649350648, "no_speech_prob": 0.02156701683998108}, {"id": 253, "seek": 191276, "start": 1912.76, "end": 1917.76, "text": " this tool set to write a comprehensive diff tools", "tokens": [341, 2290, 992, 281, 2464, 257, 13914, 7593, 3873], "temperature": 0.0, "avg_logprob": -0.4639333997453962, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.34392642974853516}, {"id": 254, "seek": 191276, "start": 1918.32, "end": 1921.08, "text": " that explains the differences between two binaries", "tokens": [300, 13948, 264, 7300, 1296, 732, 5171, 4889], "temperature": 0.0, "avg_logprob": -0.4639333997453962, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.34392642974853516}, {"id": 255, "seek": 191276, "start": 1921.08, "end": 1926.08, "text": " and that can leverage the existing descriptions", "tokens": [293, 300, 393, 13982, 264, 6741, 24406], "temperature": 0.0, "avg_logprob": -0.4639333997453962, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.34392642974853516}, {"id": 256, "seek": 191276, "start": 1927.8799999999999, "end": 1931.8799999999999, "text": " to explain what the difference became to find.", "tokens": [281, 2903, 437, 264, 2649, 3062, 281, 915, 13], "temperature": 0.0, "avg_logprob": -0.4639333997453962, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.34392642974853516}, {"id": 257, "seek": 191276, "start": 1933.24, "end": 1938.24, "text": " Yes, so I think you can compute some diff.", "tokens": [1079, 11, 370, 286, 519, 291, 393, 14722, 512, 7593, 13], "temperature": 0.0, "avg_logprob": -0.4639333997453962, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.34392642974853516}, {"id": 258, "seek": 193824, "start": 1938.24, "end": 1943.24, "text": " Basically, I would do it, I showed the ksdump tool here.", "tokens": [8537, 11, 286, 576, 360, 309, 11, 286, 4712, 264, 350, 82, 67, 1420, 2290, 510, 13], "temperature": 0.0, "avg_logprob": -0.3463748434315557, "compression_ratio": 1.4506172839506173, "no_speech_prob": 0.01643475890159607}, {"id": 259, "seek": 193824, "start": 1944.92, "end": 1949.92, "text": " So I think you could generate the gson dumps of the two files", "tokens": [407, 286, 519, 291, 727, 8460, 264, 290, 3015, 11430, 82, 295, 264, 732, 7098], "temperature": 0.0, "avg_logprob": -0.3463748434315557, "compression_ratio": 1.4506172839506173, "no_speech_prob": 0.01643475890159607}, {"id": 260, "seek": 193824, "start": 1951.84, "end": 1956.84, "text": " and compare them, but when I did this,", "tokens": [293, 6794, 552, 11, 457, 562, 286, 630, 341, 11], "temperature": 0.0, "avg_logprob": -0.3463748434315557, "compression_ratio": 1.4506172839506173, "no_speech_prob": 0.01643475890159607}, {"id": 261, "seek": 193824, "start": 1957.24, "end": 1960.24, "text": " it was usually very, very massive,", "tokens": [309, 390, 2673, 588, 11, 588, 5994, 11], "temperature": 0.0, "avg_logprob": -0.3463748434315557, "compression_ratio": 1.4506172839506173, "no_speech_prob": 0.01643475890159607}, {"id": 262, "seek": 196024, "start": 1960.24, "end": 1969.24, "text": " but you can probably improve that somehow, I don't know.", "tokens": [457, 291, 393, 1391, 3470, 300, 6063, 11, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.4201594670613607, "compression_ratio": 1.0674157303370786, "no_speech_prob": 0.01875920593738556}, {"id": 263, "seek": 196924, "start": 1969.24, "end": 1982.24, "text": " But it's, yeah, okay, so thanks and...", "tokens": [50364, 583, 309, 311, 11, 1338, 11, 1392, 11, 370, 3231, 293, 485, 51014], "temperature": 0.0, "avg_logprob": -0.561077626546224, "compression_ratio": 0.8260869565217391, "no_speech_prob": 0.04539521411061287}], "language": "en"}