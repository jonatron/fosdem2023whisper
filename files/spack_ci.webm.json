{"text": " So next speaker is Todd Gamblin and as I think a lot of people here know I'm very much involved in the EasyBuild project which was actually the excuse we used to start the HPC Dev Room but we're also very open to other projects which are very similar to what we work on every day so in some sense back as our mortal enemy but we do allow them to give talks in the Dev Room as well. Yeah, with that, thanks. Okay, who's heard of SPAC? Okay, cool. People have heard of SPAC. We don't need to do too many introductions for this talk. This is less of a talk about SPAC and more of a talk about the CI that we've started doing since introducing binary packages in SPAC. I don't think I need to tell people why they need SPAC for HPC. I think lots of folks have talked about that already today. Harman said that, so I'm supposed to talk about a little bit about deployment. To deploy SPAC, if you want to try it on a new system, just clone it from the Git repo and run it. Like all you need is Python and a few other tools on your system to do that. So you can just run it straight out of the repo if you want to play around with it and build stuff right there. SPAC is designed to install lots of different versions of things like others have said. This is sort of a snapshot of the syntax. Some of the things that you can add, you can install HDF5 at lots of different versions, you can inject flags in the build, you can pick a compiler, you can do all that on a fly and it will build you sort of a custom version of that software and let you use it. You can get it into your environment a lot of different ways. What we're trying to do with SPAC is provide the ease of use of mainstream tools that people are used to, but with the flexibility for HPC, whether we fully accomplish that is a whole other question because there's a lot of complexity still in this because it is intended for HPC. Originally it was designed to build from source because it was trying to automate people's common workflow. The Fermi lab and CERN folks added a first implementation of binary packaging to SPAC and I talked about some of that in a past FOSDM. Since then we've actually started relying on the build caches a lot more. SPAC has relocatable build caches that you can build in either a build farm or you can make one right out of your SPAC build. You may not want to do one yourself that way because then you won't have padding on the path. Like you said, the patch off relocation is dangerous. Generally if we build binaries for wide use, we pad the paths pretty extensively so that we can just poke values in instead of having to do all the patch off stuff. Anyway, you can install SPAC binaries from a build cache in S3 to your home directory. You can make a common build cache in the file system. You can use a build cache to accelerate CI. It's very handy because it eliminates the need to rebuild lots of stuff all the time. If you look at the SPAC project as a whole, I think people know most of this. There's a community. We maintain the core tool. There's package recipes but the part that you don't see is all the infrastructure behind the scenes that keeps the thing working. Originally, we did not have CI for SPAC or at least not for the package builds. We've always had CI for the tool itself and we've done unit tests and checked a bunch of things about concretization and so on, but we weren't building all the packages. We're still not building all the packages, but we're building quite a few of them. With the infrastructure that we have, we have a system where essentially you can build lots of software stacks on top of SPAC. You can write an ML description of what you want in the software stack. You can have E4S, AWS stack, Livermore's, Math stack. There's a Viz SDK within the Exascale Computing Project. Every application is its own software stack these days. Our production codes have upwards of 100 dependencies that they are using for multi-physics. Each of them is essentially maintaining their own little private software distribution in some sense or another. We'd like to be able to build all of this stuff and ensure that these things keep working. That's hard to do given that the GitHub for SPAC is a pretty busy place. There's almost 7,000 packages in SPAC now. Over the whole life of the project, there's been over 1,100 contributors. You can see down there, this month, there's been 122 people active on the GitHub repo. Over 400 commits and 300 to 500 PRs per month that we have to merge. Ensuring that everything stays working without many changes is pretty hard and you'd be nuts to do it without CI. One of the problems that we have, though, is that CI for HPC is hard. If you want to test in the HPC environments that you actually care about, you can't just take an HPC node and hook it up to random pull requests on GitHub. They don't like that when the machine might have export-controlled software on it because you're effectively allowing some random person in a pull request to run software on your HPC machine. This is the model for SPAC. We have a bunch of external contributors on GitHub constantly contributing to this develop branch. We have stable release branches where we freeze the packages to reduce the churn that some people rely on. Most users are actually on develop, at least according to our surveys, which is a little surprising to me, but that's where we are. Then off of the release branches, there is a software distribution within the XSCL project in the U.S. called E4S. There's a few others that sort of freeze a commit from SPAC and do their own integration after that. That's really supposed to be the deployment mechanism for the 100 or so packages, and it's like 600 with dependencies, that are in ECP. What happens with this is that that gets deployed to the facilities, and the E4S team goes and ensures that everything works, but we're not able to run on these systems on pull requests in CI, and it's very frustrating. Essentially, this is a bunch of downstream work that we would really like to get rid of. Moreover, the applications are also doing downstream integration. They may have their own CI, which may be good. They're essentially pulling from all these places. They may pull a facility deployment. They may pull from develop. They may pull from a release. They're essentially integrating from all these places, and so there's a lot of downstream porting there. What we would ultimately like to do in SPAC is take all of that work that's going on downstream and move it upstream so that we're actually doing CI testing on develop along with everything else. This is progress towards that, but we're not doing that yet. Essentially, the main obstacle for us to build stuff that looks like the HPC environments right now is a licensing issue, which is that we can't take the CrayPE container and run it in the cloud, because that's just not something you can do with HPC's license. We are pushing them real hard on this and trying to get an exception for us to build things, in which case we would be able to do work upstream and, ideally, deploy at the facilities from the binary cache, which I think would be way more stable and less error-prone than what we do right now. We set out to make this CI system to enable this with a bunch of different goals. One of the goals is that we want to be sustainable. We don't want to change the maintainer workflow, and we already have few enough maintainers for the amount of work that there is that we don't want to change what they have to do. They're used to going out on GitHub and approving PRs, getting them merged, checking if they build and so on. We don't want them to have to do something different, so we don't want them to both have to maintain PRs and think about how the integration branch is doing, like some distros do. We'd like that to just happen. In that vein, we want a rolling release where, on develop, we're constantly building binaries for the develop branch, and that we basically snapshot develop for every release that we do and say, okay, it's stable. Everything built. We are ready to do the release. We'll just cut one, and then we will backport bug fixes to this back tool on that release if we need to. We want it to eventually support all 6,900 packages. It's not something we're doing now, and we want source builds to still work with these binaries effectively once it's done. We want to make sure that the recipes are still versatile enough to do all those combinations of builds that I showed on the first slide. Then finally, and this is a big one, we wanted to ensure that the binaries that we have in SPAC are just as trustworthy as the sources. If you feel like you can trust our maintainers and rely on the sources that are in SPAC packages with checksums, that you feel just as comfortable with the binaries that we're putting in the build cache for you. If you think about how this works, if you look at traditional package managers, like say APT or YUM, you have a recipe per package configuration that's getting thrown into a build farm. For each of those package configurations, think like easy configs if easy build had binaries. Throw that into a build farm and then you get these portable unoptimized binaries for theoretical binary having easy build, where there's one of those per package configuration or per spec file or whatever. This is more like an APT or whatever. You're managing one software stack that's meant to be upgraded over time, and there's a consistent ABI across the distribution so that you can swap one package in for another. The solver in those distributions really operates on the binaries. In SPAC, you have parameterized package recipes that we are designing to be portable, and we want the maintainers to work on them together so that they remain portable, so you can use them in different environments. Throw those into the build farm and effectively test the parameterized package recipe in lots of different configurations and spit out different stacks. Lots of different stacks optimized for different environments from the same portable recipes for different systems, OSs, compilers and MPIs and so on. We also want, at any time, for you to be able to choose to build something from source along with that if you want to customize some aspect of the pipeline. To enable that, we came up with this architecture. We have a bunch of AWS resources, because AWS has been nice enough to donate some cycles to the project. They are interested in using SPAC in their parallel cluster product, and so that's the motivation for them is they want binaries ready to go if someone spins up a cluster in the cloud. They don't want to spin up a cluster and have it sit there and build software for hours and then run after having charged a bunch of money, which is nice to them, because they would make a lot of money. But then no one would use their service. They want binaries. In there, we use S3 and CloudFront to distribute the binaries around the world. EC2 is really the main build resource, and RDS is in there, but it's not that important. We've got a Kubernetes cluster in there that we have autoscaling runners in, and so we're building mostly in containers inside of Kube, and there's a GitLab instance in there, too. We have a high-availability GitLab instance. We chose GitLab because the HPC centers actually have GitLab CI themselves. The same CI logic that we run in the cloud, you could take that and run it internally and have these pipelines generated for you at your own site, too. You could slap another back end on this and have it generate build grass for some other system, but that's the one that we're using. We're using runner pools with something called Carpenter to basically get just-in-time instances and allocate the containers on them efficiently, and then we have some bare-metal runners at the University of Oregon with some fairly exotic architectures on them. So if we need to build or if we need to specifically run on something that has an AMD GPU or A64FX and so on, we can do that. And we could add more runners to this eventually. And there's a bot that coordinates all this work. So it's a lot of stuff. Every time I look at this, I am amazed at how complicated CI is and how it's one of those things that seems like it should just work, but there is a lot to maintaining a reliable service for doing this many builds. And I suspect other distro maintainers have realized that, too, and I'm just late to the game. The way that contributing a stack in SPAC works is we have this directory in the repo that has all of the cloud pipelines in it. And so you can see some of them are for AWS. Some of them are different variations on E4S. Each of those directories contains just a SPAC.yml that defines the stuff that is to be built. And so if you look inside of there, it's basically just, it's a list of packages. So here's the ML CUDA one that has the build of, I think, PyTorch and TensorFlow, Keras, Jax and friends for CUDA. It's just a list of packages plus there's a target up there, a target setting for all the packages. You could have a matrix of targets if you wanted. And then there's disable, rock them and enable CUDA on everything except for LLVM because there's that bug that's linked there. And I'm not entirely sure about the specifics of that. But the configuration part is up here and it's fairly minimal for the stack. There's currently, if you look at these, a bunch of other boilerplate stuff for things like mapping runners. I'll get to that in a minute. But this is, there's a PR that's going to go in where this is basically all that's going to be in your stack. And you might include some stuff from elsewhere. But this is essentially a stack definition. And we take that and, you know, this makes it very easy to change low-level parameters in the stack. So we had a working E4S stack with something like 6 or 700 packages building. We wanted to get better testing for one API because that's what they're going to use on Aurora. And so we wanted to use the one API compilers. We added some compiler config and we said everything should use one API. And then, you know, at the very least we got a pipeline generated with some errors for one API. And it made it really easy to iterate on this with Intel where we would basically say, okay, this package is broken. Here's the bug. Go fix it. And then it would come back with another version of one API and we would iterate with them until it was done. I think this is probably more open-source than anyone has recently run through a vendor compiler. And so just being able to do this, I think, is big because it might make those compilers like actually viable things to use for real programs that have lots of dependencies. At the moment, you know, you have to sort of piece your program together and build parts of it with like, I don't know, PGI was the infamous one that broke on everything. But, you know, I think this could help with the vendor compiler being a viable second option and, you know, maybe instill some competition among the vendors because they can do this frequently and show, you know, benchmarks against these packages. So this was, I think, a win. Yeah, thank you. Each of those stacks gets concretized. And so people know, in SPAC, you take that abstract description of the things that you want to install, which is basically the requirements. You run it through our dependency solver. You get, essentially, a concrete description of what you're going to build, which is the whole concrete graph. And then we generate a GitLab CI YAML from that that describes the jobs that need to be run to build the whole thing. This is the part that we could swap out for something else. So, like, we've looked at, like, Tecton pipelines. We've looked at other options. I don't know, some people use Jenkins. There's all sorts of things out there that you could potentially map the jobs to. And I think we could generate a description like that from the representation that we have. For mapping those jobs, we have a section in the CI YAML right now, or in the SPAC.YAML, that basically tells you how to generate the GitLab piece. And so you see this mapping section here. There's a match section. If you match any of those specs there, and the first three are just a couple, just some names, then we have special tags that we put on the runners that say, you know, get me a special resource for these things. And so that first block is basically so that I don't run out of memory building LLVM TensorFlow or Torch, get me something with a lot of memory and a big CPU to build that one. It has to run on a big instance, because those are sort of the long poles in our tent in CI. And then down at the bottom, there's just a mapping from everything else gets something that supports X8664, V4, and it's a little smaller than the other one for builds. And you could do this for lots of different architecture combinations and so on. And you can ask for images and things like that. I said that we needed to ensure that the source is, or that the binaries are as reliable as the source. And so we sat down and we asked ourselves, you know, what is it that people trust about the SPAC project? And it's really the maintainers. If you use any open source project, you're trusting the maintainers, or you really shouldn't be using that open source project. And so I don't see where we can do better than that. And so what we've done is we've said the place where bad things could get into a build, at least from SPAC, is in the build environment. And so if you give people control of the PR environment where they're submitting things there, they could push a commit that puts something in a binary that gets cached. And then, you know, somehow, I don't know, they could do bad things and end up caching a binary. And if we took that binary and stuck it out there for anyone to use, you know, there could be bad things in it. And so we have this separate set of untrusted S3 buckets where we only build PR things. Each PR gets its own build cache. That enables the maintainers to see if things work. And then they come along and review the code. And then once things are actually merged to develop, we don't trust any of the binaries that we built on PRs. And we go and rebuild everything in sign, specifically from the, you know, the sources that got approved, just, you know, so that we know that we didn't cache anything from that environment. So that's where the development and release caches are coming from, where they're entirely separate from the PR environment. And the signature here is, you know, it's ephemeral. They have, like, a signing key locked up somewhere in a secret server. And we generate, you know, we have subkeys and then we generate ephemeral keys for the signing in the pipelines. So whatever it is that you got signed with doesn't actually exist anymore by the time the user consumes the binary. We could look at sick store for this. It wasn't quite ready for arbitrary binary signing when we did this. But that's an option to reduce some of the custom GPG stuff we had to do here. So the pull request integration, I think, makes it easy for at least for most of the contributors. They get status updates on PRs. And it's fairly easy for users because they can just add one of these binary mirrors and then start using the build cache. And I'm not going to get into the details here, but in SPAC, for a very long time, it was easy to get a lot of cache misses, like we would just look up hashes. And I have another presentation about our reusing Concretizer. The summary is, if you add one of these build caches and you have those binaries available, SPAC will prefer to use them. And so before it tries to rebuild something. And so with the reusing Concretizer, this is actually quite powerful. And so, yeah, what could go wrong? Well, there is a burden to doing this. And a build cache distribution like SPACnix or Geeks is different from an RPM distribution because every node has a hash. And the deployment model is really that you have to deploy with what you built with. And so you can't just swap in a new version of Zlib in a stack. If something has a particular hash, that implies all of its dependencies' hashes. And so you need to deploy the build cache with everything that it was built with. So if, for example, you modify XZ, right? Yep. And then you're going to need to rebuild all of these things, too. And you're going to need to do that all the way up to the roots of your environment every once in a while so that there's a consistent build cache for people to deploy. And that can be bad if your stack is this big. This is E4S, right? And someone comes in and submits a PR, which you can do, by the way, that, you know, modifies package comp. And then all of a sudden, you know, this is what happens to your CI system, right? Your whole graph is rebuilding again. And it can take a long time for develop to catch up with a change like this. And right now we are rebuilding all that stuff on PRs. So your pipelines can get long. You dig in there and you see that, like, visit is still building. And you're like, this is the fifth time I've built visit today. I think Harman once commented that he was worried that SPAC would eventually cause the heat death of the universe because of pair of view builds. Or no, the pair of view builds would eventually bring on climate change in the U.S. So we worry about that. We don't want to do that all the time. The other thing that can happen is there's a delicate balance between redundant builds and, you know, holding back PRs. I didn't think about this before we really got into CI. But it matters what commit you pick to merge with when you're doing a build-cache build. And so if you have a pipeline like this where you've built B and develop has now picked up on D and that one's building up there. And you get a PR like this. So PR1 comes in. You can merge that with B and get a lot of reuse there and get a pretty good testing on PR1. If instead you get a PR up here that is based beyond your last developed build and you try to merge that with D or even C, I guess it's already based on C, so you can't really merge with C. But if you merge that with D, you're going to be duplicating the work that's already being done on develop. And so if you get a bunch of PRs like this at the same time, you can get a whole bunch of builds at the same time that are effectively already being done on develop. And so this is a difficulty of navigating these PR-based CI systems. If you had a server that had shared that one patch was built all the time once, then you could get around this. So you have to be picky about this, hold up PR2 until the next thing is built and then merge with that commit and send it to GitLab to be merged or to be built. And this can annoy contributors because they have to wait for that to happen for their PR in order to keep the CI system sane. We actually did bring down GitLab once with a bunch of PRs like this. Essentially something got broken in develop, develop, got held up, people started submitting a bunch of PRs, they were all doing redundant builds and GitLab fell over. So that was fun. CI does keep things stable. And so we have had, at least anecdotally, that our package maintainers at the lab are much more happy with how reliable their builds are for packages on the machines since we've had CI. But like I said, the committers get frustrated. And the other thing that happens here if you're doing so many builds on PRs is that if your CI system has occasional system errors, if you're building a thousand things on a PR pipeline, it's very likely that you're going to get a system error on there. And so what ends up happening is that you end up having to babysit PRs a bit. And that can be painful. The other thing that happens is it's hard to stay correct. So testing on PRs doesn't really ensure that you have a working develop branch. If you have a setup like this with an initial package state, you get a pull request at update B. You get another pull request in there that updates C. You test both of those configurations on your PRs and they work. And you merge them. The thing that you now have in develop is actually updated B and updated C. And you never tested that. And so keeping that state consistent is rather difficult. And we're thinking we're going to, we didn't, you know, before we had CI, I think we just didn't see these kinds of issues. They would just get manifested on users, which is not great. But now we run into them in CI because we can see that things are broken undeveloped. So we're looking into using merge queues, which actually solved this problem and a couple others that we have pretty effectively. So you can do faster iteration on PRs with merge queues because you're merging in sequence, testing in parallel. I'll describe what that looks like in a minute. It's a good balance of CI versus responsiveness because you can do sort of sparse tests on the PRs and queue them and then do the heavy tests. And it actually does preserve the security model because anything queued in a merge queue is actually approved by containers, by maintainers, and you can take the builds and move them straight into develop. And so what that looks like is this, where you might have the same initial packet state, you get two pull requests, you do some small testing on the pull request, and then you set up this merge queue where effectively you're doing heavy testing on things that are basically staged exactly as they will be merged if they are successful. Okay. So that gets committed, that gets committed, and now you've tested the final configuration on develop and you're not in an inconsistent state. So we're going to stage the work that we do in CI. On PRs, we're probably going to build just the package or just the package and its dependence, which is similar to what Nix does. On most merge queue pipelines, we may build a bit more than that, and then every once in a while we'll build everything on develop, and we'll see how it goes. We can probe, you know, what the balance is here. So that's where we're at. Thanks. Okay, I think we have time for one or two questions. Any questions for Todd? And off the wall question, we have, for example, software bill of materials, dev room. You mentioned export controlled software and also being able to trust binaries. I work with classified customers who have isolated networks, probably Shopify, MI6, if I told you who they were. But could SPAC help with providing, they're now asking for what software is running on these systems. I mean, what does that question mean, really? Can you help with producing a report on exactly what software is? Yeah, we have a PR right now for so that every SPAC build would produce an SBOM in some standard format. There's a whole dev room on SBOMs today, which gets into that. And so I think, yeah, I mean, we know everything in the graph, and so do Nixon Geeks and the other systems that do this. We don't expose it in a standard format that auditing systems can scan right now, but that's what we'd like to do. So very briefly, Debbie and I, a while ago, did something on reproducible builds, which were much more difficult. So if you haven't worked with her a bit, that might be interesting for you. Yeah, so we would like to have fully reproducible builds. It's a lot of upstream patching, right? And even Debian isn't fully reproducible right now. I think that that would be like something we could consider after we get down to, like, libc even, because at the moment, because we have to run on things like craze where there's so much dependent on, like, the module environment, we have to include the external environment to get some of these builds done. But yeah, I would like to have a much more isolated build environment with that. It's a good practice. Okay, one more question here, and then need to switch. Hi, so you were talking about padding your header files for rallies of pathing. Given that you don't have a static path or a pre-defined destination as in FHS-type locations, are you in serious danger of running out of space in that header? Well, we're not building in a static path. We might be building in a home directory, right? And so you can put padding in your install tree prefix, it's like the next store, and you can say build with 256 long paths. And you wouldn't want to have a user actually deploy in a path like that, but you can build that way, create the binary, and then redeploy in a short path. You've got potentially a space where there's, where you can have an arbitrary length path as you're running. A lot of stuff doesn't build with overly long paths. So if you get to 5.12, auto-tools starts breaking down and not supporting that length of a path, and the packages actually don't support it. And so the sweet spot seems to be like 256. Okay, thanks.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.88, "text": " So next speaker is Todd Gamblin and as I think a lot of people here know I'm very much involved", "tokens": [407, 958, 8145, 307, 21488, 44643, 5045, 293, 382, 286, 519, 257, 688, 295, 561, 510, 458, 286, 478, 588, 709, 3288], "temperature": 0.0, "avg_logprob": -0.23553829193115233, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.5836099982261658}, {"id": 1, "seek": 0, "start": 12.88, "end": 18.8, "text": " in the EasyBuild project which was actually the excuse we used to start the HPC Dev Room", "tokens": [294, 264, 16002, 28110, 793, 1716, 597, 390, 767, 264, 8960, 321, 1143, 281, 722, 264, 12557, 34, 9096, 19190], "temperature": 0.0, "avg_logprob": -0.23553829193115233, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.5836099982261658}, {"id": 2, "seek": 0, "start": 18.8, "end": 23.16, "text": " but we're also very open to other projects which are very similar to what we work on", "tokens": [457, 321, 434, 611, 588, 1269, 281, 661, 4455, 597, 366, 588, 2531, 281, 437, 321, 589, 322], "temperature": 0.0, "avg_logprob": -0.23553829193115233, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.5836099982261658}, {"id": 3, "seek": 0, "start": 23.16, "end": 28.48, "text": " every day so in some sense back as our mortal enemy but we do allow them to give talks in", "tokens": [633, 786, 370, 294, 512, 2020, 646, 382, 527, 27624, 5945, 457, 321, 360, 2089, 552, 281, 976, 6686, 294], "temperature": 0.0, "avg_logprob": -0.23553829193115233, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.5836099982261658}, {"id": 4, "seek": 2848, "start": 28.48, "end": 36.72, "text": " the Dev Room as well. Yeah, with that, thanks. Okay, who's heard of SPAC? Okay, cool. People", "tokens": [264, 9096, 19190, 382, 731, 13, 865, 11, 365, 300, 11, 3231, 13, 1033, 11, 567, 311, 2198, 295, 8420, 4378, 30, 1033, 11, 1627, 13, 3432], "temperature": 0.0, "avg_logprob": -0.14900949966808982, "compression_ratio": 1.6793893129770991, "no_speech_prob": 2.7941605367232114e-05}, {"id": 5, "seek": 2848, "start": 36.72, "end": 42.68, "text": " have heard of SPAC. We don't need to do too many introductions for this talk. This is", "tokens": [362, 2198, 295, 8420, 4378, 13, 492, 500, 380, 643, 281, 360, 886, 867, 48032, 337, 341, 751, 13, 639, 307], "temperature": 0.0, "avg_logprob": -0.14900949966808982, "compression_ratio": 1.6793893129770991, "no_speech_prob": 2.7941605367232114e-05}, {"id": 6, "seek": 2848, "start": 42.68, "end": 47.56, "text": " less of a talk about SPAC and more of a talk about the CI that we've started doing since", "tokens": [1570, 295, 257, 751, 466, 8420, 4378, 293, 544, 295, 257, 751, 466, 264, 37777, 300, 321, 600, 1409, 884, 1670], "temperature": 0.0, "avg_logprob": -0.14900949966808982, "compression_ratio": 1.6793893129770991, "no_speech_prob": 2.7941605367232114e-05}, {"id": 7, "seek": 2848, "start": 47.56, "end": 52.32, "text": " introducing binary packages in SPAC. I don't think I need to tell people why they need", "tokens": [15424, 17434, 17401, 294, 8420, 4378, 13, 286, 500, 380, 519, 286, 643, 281, 980, 561, 983, 436, 643], "temperature": 0.0, "avg_logprob": -0.14900949966808982, "compression_ratio": 1.6793893129770991, "no_speech_prob": 2.7941605367232114e-05}, {"id": 8, "seek": 2848, "start": 52.32, "end": 58.36, "text": " SPAC for HPC. I think lots of folks have talked about that already today. Harman said", "tokens": [8420, 4378, 337, 12557, 34, 13, 286, 519, 3195, 295, 4024, 362, 2825, 466, 300, 1217, 965, 13, 3653, 1601, 848], "temperature": 0.0, "avg_logprob": -0.14900949966808982, "compression_ratio": 1.6793893129770991, "no_speech_prob": 2.7941605367232114e-05}, {"id": 9, "seek": 5836, "start": 58.36, "end": 62.32, "text": " that, so I'm supposed to talk about a little bit about deployment. To deploy SPAC, if you", "tokens": [300, 11, 370, 286, 478, 3442, 281, 751, 466, 257, 707, 857, 466, 19317, 13, 1407, 7274, 8420, 4378, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.13791248297235767, "compression_ratio": 1.8149253731343284, "no_speech_prob": 8.137869372148998e-06}, {"id": 10, "seek": 5836, "start": 62.32, "end": 65.44, "text": " want to try it on a new system, just clone it from the Git repo and run it. Like all", "tokens": [528, 281, 853, 309, 322, 257, 777, 1185, 11, 445, 26506, 309, 490, 264, 16939, 49040, 293, 1190, 309, 13, 1743, 439], "temperature": 0.0, "avg_logprob": -0.13791248297235767, "compression_ratio": 1.8149253731343284, "no_speech_prob": 8.137869372148998e-06}, {"id": 11, "seek": 5836, "start": 65.44, "end": 70.03999999999999, "text": " you need is Python and a few other tools on your system to do that. So you can just run", "tokens": [291, 643, 307, 15329, 293, 257, 1326, 661, 3873, 322, 428, 1185, 281, 360, 300, 13, 407, 291, 393, 445, 1190], "temperature": 0.0, "avg_logprob": -0.13791248297235767, "compression_ratio": 1.8149253731343284, "no_speech_prob": 8.137869372148998e-06}, {"id": 12, "seek": 5836, "start": 70.03999999999999, "end": 73.08, "text": " it straight out of the repo if you want to play around with it and build stuff right", "tokens": [309, 2997, 484, 295, 264, 49040, 498, 291, 528, 281, 862, 926, 365, 309, 293, 1322, 1507, 558], "temperature": 0.0, "avg_logprob": -0.13791248297235767, "compression_ratio": 1.8149253731343284, "no_speech_prob": 8.137869372148998e-06}, {"id": 13, "seek": 5836, "start": 73.08, "end": 78.88, "text": " there. SPAC is designed to install lots of different versions of things like others", "tokens": [456, 13, 8420, 4378, 307, 4761, 281, 3625, 3195, 295, 819, 9606, 295, 721, 411, 2357], "temperature": 0.0, "avg_logprob": -0.13791248297235767, "compression_ratio": 1.8149253731343284, "no_speech_prob": 8.137869372148998e-06}, {"id": 14, "seek": 5836, "start": 78.88, "end": 83.4, "text": " have said. This is sort of a snapshot of the syntax. Some of the things that you can add,", "tokens": [362, 848, 13, 639, 307, 1333, 295, 257, 30163, 295, 264, 28431, 13, 2188, 295, 264, 721, 300, 291, 393, 909, 11], "temperature": 0.0, "avg_logprob": -0.13791248297235767, "compression_ratio": 1.8149253731343284, "no_speech_prob": 8.137869372148998e-06}, {"id": 15, "seek": 5836, "start": 83.4, "end": 87.2, "text": " you can install HDF5 at lots of different versions, you can inject flags in the build,", "tokens": [291, 393, 3625, 12149, 37, 20, 412, 3195, 295, 819, 9606, 11, 291, 393, 10711, 23265, 294, 264, 1322, 11], "temperature": 0.0, "avg_logprob": -0.13791248297235767, "compression_ratio": 1.8149253731343284, "no_speech_prob": 8.137869372148998e-06}, {"id": 16, "seek": 8720, "start": 87.2, "end": 90.72, "text": " you can pick a compiler, you can do all that on a fly and it will build you sort of a custom", "tokens": [291, 393, 1888, 257, 31958, 11, 291, 393, 360, 439, 300, 322, 257, 3603, 293, 309, 486, 1322, 291, 1333, 295, 257, 2375], "temperature": 0.0, "avg_logprob": -0.13068857926588792, "compression_ratio": 1.711111111111111, "no_speech_prob": 3.5000812204089016e-06}, {"id": 17, "seek": 8720, "start": 90.72, "end": 94.88, "text": " version of that software and let you use it. You can get it into your environment a lot", "tokens": [3037, 295, 300, 4722, 293, 718, 291, 764, 309, 13, 509, 393, 483, 309, 666, 428, 2823, 257, 688], "temperature": 0.0, "avg_logprob": -0.13068857926588792, "compression_ratio": 1.711111111111111, "no_speech_prob": 3.5000812204089016e-06}, {"id": 18, "seek": 8720, "start": 94.88, "end": 100.24000000000001, "text": " of different ways. What we're trying to do with SPAC is provide the ease of use of mainstream", "tokens": [295, 819, 2098, 13, 708, 321, 434, 1382, 281, 360, 365, 8420, 4378, 307, 2893, 264, 12708, 295, 764, 295, 15960], "temperature": 0.0, "avg_logprob": -0.13068857926588792, "compression_ratio": 1.711111111111111, "no_speech_prob": 3.5000812204089016e-06}, {"id": 19, "seek": 8720, "start": 100.24000000000001, "end": 104.96000000000001, "text": " tools that people are used to, but with the flexibility for HPC, whether we fully accomplish", "tokens": [3873, 300, 561, 366, 1143, 281, 11, 457, 365, 264, 12635, 337, 12557, 34, 11, 1968, 321, 4498, 9021], "temperature": 0.0, "avg_logprob": -0.13068857926588792, "compression_ratio": 1.711111111111111, "no_speech_prob": 3.5000812204089016e-06}, {"id": 20, "seek": 8720, "start": 104.96000000000001, "end": 109.2, "text": " that is a whole other question because there's a lot of complexity still in this because", "tokens": [300, 307, 257, 1379, 661, 1168, 570, 456, 311, 257, 688, 295, 14024, 920, 294, 341, 570], "temperature": 0.0, "avg_logprob": -0.13068857926588792, "compression_ratio": 1.711111111111111, "no_speech_prob": 3.5000812204089016e-06}, {"id": 21, "seek": 8720, "start": 109.2, "end": 115.08, "text": " it is intended for HPC. Originally it was designed to build from source because it", "tokens": [309, 307, 10226, 337, 12557, 34, 13, 28696, 309, 390, 4761, 281, 1322, 490, 4009, 570, 309], "temperature": 0.0, "avg_logprob": -0.13068857926588792, "compression_ratio": 1.711111111111111, "no_speech_prob": 3.5000812204089016e-06}, {"id": 22, "seek": 11508, "start": 115.08, "end": 123.92, "text": " was trying to automate people's common workflow. The Fermi lab and CERN folks added a first", "tokens": [390, 1382, 281, 31605, 561, 311, 2689, 20993, 13, 440, 43261, 72, 2715, 293, 383, 1598, 45, 4024, 3869, 257, 700], "temperature": 0.0, "avg_logprob": -0.186976073890604, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.0449766705278307e-05}, {"id": 23, "seek": 11508, "start": 123.92, "end": 128.72, "text": " implementation of binary packaging to SPAC and I talked about some of that in a past", "tokens": [11420, 295, 17434, 16836, 281, 8420, 4378, 293, 286, 2825, 466, 512, 295, 300, 294, 257, 1791], "temperature": 0.0, "avg_logprob": -0.186976073890604, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.0449766705278307e-05}, {"id": 24, "seek": 11508, "start": 128.72, "end": 137.16, "text": " FOSDM. Since then we've actually started relying on the build caches a lot more. SPAC has relocatable", "tokens": [479, 4367, 35, 44, 13, 4162, 550, 321, 600, 767, 1409, 24140, 322, 264, 1322, 269, 13272, 257, 688, 544, 13, 8420, 4378, 575, 26981, 31415], "temperature": 0.0, "avg_logprob": -0.186976073890604, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.0449766705278307e-05}, {"id": 25, "seek": 11508, "start": 137.16, "end": 142.12, "text": " build caches that you can build in either a build farm or you can make one right out", "tokens": [1322, 269, 13272, 300, 291, 393, 1322, 294, 2139, 257, 1322, 5421, 420, 291, 393, 652, 472, 558, 484], "temperature": 0.0, "avg_logprob": -0.186976073890604, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.0449766705278307e-05}, {"id": 26, "seek": 14212, "start": 142.12, "end": 148.28, "text": " of your SPAC build. You may not want to do one yourself that way because then you won't", "tokens": [295, 428, 8420, 4378, 1322, 13, 509, 815, 406, 528, 281, 360, 472, 1803, 300, 636, 570, 550, 291, 1582, 380], "temperature": 0.0, "avg_logprob": -0.12256285122462682, "compression_ratio": 1.6394052044609666, "no_speech_prob": 1.722314118524082e-05}, {"id": 27, "seek": 14212, "start": 148.28, "end": 153.32, "text": " have padding on the path. Like you said, the patch off relocation is dangerous. Generally", "tokens": [362, 39562, 322, 264, 3100, 13, 1743, 291, 848, 11, 264, 9972, 766, 26981, 399, 307, 5795, 13, 21082], "temperature": 0.0, "avg_logprob": -0.12256285122462682, "compression_ratio": 1.6394052044609666, "no_speech_prob": 1.722314118524082e-05}, {"id": 28, "seek": 14212, "start": 153.32, "end": 159.56, "text": " if we build binaries for wide use, we pad the paths pretty extensively so that we can just", "tokens": [498, 321, 1322, 5171, 4889, 337, 4874, 764, 11, 321, 6887, 264, 14518, 1238, 32636, 370, 300, 321, 393, 445], "temperature": 0.0, "avg_logprob": -0.12256285122462682, "compression_ratio": 1.6394052044609666, "no_speech_prob": 1.722314118524082e-05}, {"id": 29, "seek": 14212, "start": 159.56, "end": 164.24, "text": " poke values in instead of having to do all the patch off stuff. Anyway, you can install", "tokens": [19712, 4190, 294, 2602, 295, 1419, 281, 360, 439, 264, 9972, 766, 1507, 13, 5684, 11, 291, 393, 3625], "temperature": 0.0, "avg_logprob": -0.12256285122462682, "compression_ratio": 1.6394052044609666, "no_speech_prob": 1.722314118524082e-05}, {"id": 30, "seek": 14212, "start": 164.24, "end": 169.08, "text": " SPAC binaries from a build cache in S3 to your home directory. You can make a common", "tokens": [8420, 4378, 5171, 4889, 490, 257, 1322, 19459, 294, 318, 18, 281, 428, 1280, 21120, 13, 509, 393, 652, 257, 2689], "temperature": 0.0, "avg_logprob": -0.12256285122462682, "compression_ratio": 1.6394052044609666, "no_speech_prob": 1.722314118524082e-05}, {"id": 31, "seek": 16908, "start": 169.08, "end": 174.88000000000002, "text": " build cache in the file system. You can use a build cache to accelerate CI. It's very", "tokens": [1322, 19459, 294, 264, 3991, 1185, 13, 509, 393, 764, 257, 1322, 19459, 281, 21341, 37777, 13, 467, 311, 588], "temperature": 0.0, "avg_logprob": -0.13708790579994956, "compression_ratio": 1.5391304347826087, "no_speech_prob": 1.2406972928147297e-05}, {"id": 32, "seek": 16908, "start": 174.88000000000002, "end": 184.76000000000002, "text": " handy because it eliminates the need to rebuild lots of stuff all the time. If you look at", "tokens": [13239, 570, 309, 49893, 264, 643, 281, 16877, 3195, 295, 1507, 439, 264, 565, 13, 759, 291, 574, 412], "temperature": 0.0, "avg_logprob": -0.13708790579994956, "compression_ratio": 1.5391304347826087, "no_speech_prob": 1.2406972928147297e-05}, {"id": 33, "seek": 16908, "start": 184.76000000000002, "end": 190.88000000000002, "text": " the SPAC project as a whole, I think people know most of this. There's a community. We", "tokens": [264, 8420, 4378, 1716, 382, 257, 1379, 11, 286, 519, 561, 458, 881, 295, 341, 13, 821, 311, 257, 1768, 13, 492], "temperature": 0.0, "avg_logprob": -0.13708790579994956, "compression_ratio": 1.5391304347826087, "no_speech_prob": 1.2406972928147297e-05}, {"id": 34, "seek": 16908, "start": 190.88000000000002, "end": 195.20000000000002, "text": " maintain the core tool. There's package recipes but the part that you don't see is all the", "tokens": [6909, 264, 4965, 2290, 13, 821, 311, 7372, 13035, 457, 264, 644, 300, 291, 500, 380, 536, 307, 439, 264], "temperature": 0.0, "avg_logprob": -0.13708790579994956, "compression_ratio": 1.5391304347826087, "no_speech_prob": 1.2406972928147297e-05}, {"id": 35, "seek": 19520, "start": 195.2, "end": 200.56, "text": " infrastructure behind the scenes that keeps the thing working. Originally, we did not", "tokens": [6896, 2261, 264, 8026, 300, 5965, 264, 551, 1364, 13, 28696, 11, 321, 630, 406], "temperature": 0.0, "avg_logprob": -0.11478432332436869, "compression_ratio": 1.7905405405405406, "no_speech_prob": 1.0449967703607399e-05}, {"id": 36, "seek": 19520, "start": 200.56, "end": 206.95999999999998, "text": " have CI for SPAC or at least not for the package builds. We've always had CI for the tool itself", "tokens": [362, 37777, 337, 8420, 4378, 420, 412, 1935, 406, 337, 264, 7372, 15182, 13, 492, 600, 1009, 632, 37777, 337, 264, 2290, 2564], "temperature": 0.0, "avg_logprob": -0.11478432332436869, "compression_ratio": 1.7905405405405406, "no_speech_prob": 1.0449967703607399e-05}, {"id": 37, "seek": 19520, "start": 206.95999999999998, "end": 211.64, "text": " and we've done unit tests and checked a bunch of things about concretization and so on,", "tokens": [293, 321, 600, 1096, 4985, 6921, 293, 10033, 257, 3840, 295, 721, 466, 39481, 2144, 293, 370, 322, 11], "temperature": 0.0, "avg_logprob": -0.11478432332436869, "compression_ratio": 1.7905405405405406, "no_speech_prob": 1.0449967703607399e-05}, {"id": 38, "seek": 19520, "start": 211.64, "end": 215.44, "text": " but we weren't building all the packages. We're still not building all the packages,", "tokens": [457, 321, 4999, 380, 2390, 439, 264, 17401, 13, 492, 434, 920, 406, 2390, 439, 264, 17401, 11], "temperature": 0.0, "avg_logprob": -0.11478432332436869, "compression_ratio": 1.7905405405405406, "no_speech_prob": 1.0449967703607399e-05}, {"id": 39, "seek": 19520, "start": 215.44, "end": 219.67999999999998, "text": " but we're building quite a few of them. With the infrastructure that we have, we have a", "tokens": [457, 321, 434, 2390, 1596, 257, 1326, 295, 552, 13, 2022, 264, 6896, 300, 321, 362, 11, 321, 362, 257], "temperature": 0.0, "avg_logprob": -0.11478432332436869, "compression_ratio": 1.7905405405405406, "no_speech_prob": 1.0449967703607399e-05}, {"id": 40, "seek": 19520, "start": 219.67999999999998, "end": 223.32, "text": " system where essentially you can build lots of software stacks on top of SPAC. You can", "tokens": [1185, 689, 4476, 291, 393, 1322, 3195, 295, 4722, 30792, 322, 1192, 295, 8420, 4378, 13, 509, 393], "temperature": 0.0, "avg_logprob": -0.11478432332436869, "compression_ratio": 1.7905405405405406, "no_speech_prob": 1.0449967703607399e-05}, {"id": 41, "seek": 22332, "start": 223.32, "end": 227.84, "text": " write an ML description of what you want in the software stack. You can have E4S, AWS", "tokens": [2464, 364, 376, 43, 3855, 295, 437, 291, 528, 294, 264, 4722, 8630, 13, 509, 393, 362, 462, 19, 50, 11, 17650], "temperature": 0.0, "avg_logprob": -0.23979728626755048, "compression_ratio": 1.5419580419580419, "no_speech_prob": 1.4965831724111922e-05}, {"id": 42, "seek": 22332, "start": 227.84, "end": 235.07999999999998, "text": " stack, Livermore's, Math stack. There's a Viz SDK within the Exascale Computing Project.", "tokens": [8630, 11, 28010, 3138, 311, 11, 15776, 8630, 13, 821, 311, 257, 691, 590, 37135, 1951, 264, 2111, 4806, 1220, 37804, 278, 9849, 13], "temperature": 0.0, "avg_logprob": -0.23979728626755048, "compression_ratio": 1.5419580419580419, "no_speech_prob": 1.4965831724111922e-05}, {"id": 43, "seek": 22332, "start": 235.07999999999998, "end": 239.84, "text": " Every application is its own software stack these days. Our production codes have upwards", "tokens": [2048, 3861, 307, 1080, 1065, 4722, 8630, 613, 1708, 13, 2621, 4265, 14211, 362, 22167], "temperature": 0.0, "avg_logprob": -0.23979728626755048, "compression_ratio": 1.5419580419580419, "no_speech_prob": 1.4965831724111922e-05}, {"id": 44, "seek": 22332, "start": 239.84, "end": 245.51999999999998, "text": " of 100 dependencies that they are using for multi-physics. Each of them is essentially", "tokens": [295, 2319, 36606, 300, 436, 366, 1228, 337, 4825, 12, 950, 41732, 13, 6947, 295, 552, 307, 4476], "temperature": 0.0, "avg_logprob": -0.23979728626755048, "compression_ratio": 1.5419580419580419, "no_speech_prob": 1.4965831724111922e-05}, {"id": 45, "seek": 22332, "start": 245.51999999999998, "end": 251.56, "text": " maintaining their own little private software distribution in some sense or another. We'd", "tokens": [14916, 641, 1065, 707, 4551, 4722, 7316, 294, 512, 2020, 420, 1071, 13, 492, 1116], "temperature": 0.0, "avg_logprob": -0.23979728626755048, "compression_ratio": 1.5419580419580419, "no_speech_prob": 1.4965831724111922e-05}, {"id": 46, "seek": 25156, "start": 251.56, "end": 256.64, "text": " like to be able to build all of this stuff and ensure that these things keep working.", "tokens": [411, 281, 312, 1075, 281, 1322, 439, 295, 341, 1507, 293, 5586, 300, 613, 721, 1066, 1364, 13], "temperature": 0.0, "avg_logprob": -0.1581540765433476, "compression_ratio": 1.5963636363636364, "no_speech_prob": 1.8336302673560567e-05}, {"id": 47, "seek": 25156, "start": 256.64, "end": 261.88, "text": " That's hard to do given that the GitHub for SPAC is a pretty busy place. There's almost", "tokens": [663, 311, 1152, 281, 360, 2212, 300, 264, 23331, 337, 8420, 4378, 307, 257, 1238, 5856, 1081, 13, 821, 311, 1920], "temperature": 0.0, "avg_logprob": -0.1581540765433476, "compression_ratio": 1.5963636363636364, "no_speech_prob": 1.8336302673560567e-05}, {"id": 48, "seek": 25156, "start": 261.88, "end": 267.84000000000003, "text": " 7,000 packages in SPAC now. Over the whole life of the project, there's been over 1,100", "tokens": [1614, 11, 1360, 17401, 294, 8420, 4378, 586, 13, 4886, 264, 1379, 993, 295, 264, 1716, 11, 456, 311, 668, 670, 502, 11, 6879], "temperature": 0.0, "avg_logprob": -0.1581540765433476, "compression_ratio": 1.5963636363636364, "no_speech_prob": 1.8336302673560567e-05}, {"id": 49, "seek": 25156, "start": 267.84000000000003, "end": 274.28, "text": " contributors. You can see down there, this month, there's been 122 people active on the", "tokens": [45627, 13, 509, 393, 536, 760, 456, 11, 341, 1618, 11, 456, 311, 668, 2272, 17, 561, 4967, 322, 264], "temperature": 0.0, "avg_logprob": -0.1581540765433476, "compression_ratio": 1.5963636363636364, "no_speech_prob": 1.8336302673560567e-05}, {"id": 50, "seek": 27428, "start": 274.28, "end": 283.44, "text": " GitHub repo. Over 400 commits and 300 to 500 PRs per month that we have to merge. Ensuring", "tokens": [23331, 49040, 13, 4886, 8423, 48311, 293, 6641, 281, 5923, 11568, 82, 680, 1618, 300, 321, 362, 281, 22183, 13, 25979, 1345], "temperature": 0.0, "avg_logprob": -0.12150537449380626, "compression_ratio": 1.51931330472103, "no_speech_prob": 1.2802791388821788e-05}, {"id": 51, "seek": 27428, "start": 283.44, "end": 288.32, "text": " that everything stays working without many changes is pretty hard and you'd be nuts", "tokens": [300, 1203, 10834, 1364, 1553, 867, 2962, 307, 1238, 1152, 293, 291, 1116, 312, 10483], "temperature": 0.0, "avg_logprob": -0.12150537449380626, "compression_ratio": 1.51931330472103, "no_speech_prob": 1.2802791388821788e-05}, {"id": 52, "seek": 27428, "start": 288.32, "end": 296.4, "text": " to do it without CI. One of the problems that we have, though, is that CI for HPC is hard.", "tokens": [281, 360, 309, 1553, 37777, 13, 1485, 295, 264, 2740, 300, 321, 362, 11, 1673, 11, 307, 300, 37777, 337, 12557, 34, 307, 1152, 13], "temperature": 0.0, "avg_logprob": -0.12150537449380626, "compression_ratio": 1.51931330472103, "no_speech_prob": 1.2802791388821788e-05}, {"id": 53, "seek": 27428, "start": 296.4, "end": 302.03999999999996, "text": " If you want to test in the HPC environments that you actually care about, you can't just", "tokens": [759, 291, 528, 281, 1500, 294, 264, 12557, 34, 12388, 300, 291, 767, 1127, 466, 11, 291, 393, 380, 445], "temperature": 0.0, "avg_logprob": -0.12150537449380626, "compression_ratio": 1.51931330472103, "no_speech_prob": 1.2802791388821788e-05}, {"id": 54, "seek": 30204, "start": 302.04, "end": 307.32, "text": " take an HPC node and hook it up to random pull requests on GitHub. They don't like that", "tokens": [747, 364, 12557, 34, 9984, 293, 6328, 309, 493, 281, 4974, 2235, 12475, 322, 23331, 13, 814, 500, 380, 411, 300], "temperature": 0.0, "avg_logprob": -0.10855569644850127, "compression_ratio": 1.66793893129771, "no_speech_prob": 5.172740202397108e-06}, {"id": 55, "seek": 30204, "start": 307.32, "end": 310.52000000000004, "text": " when the machine might have export-controlled software on it because you're effectively", "tokens": [562, 264, 3479, 1062, 362, 10725, 12, 49344, 4722, 322, 309, 570, 291, 434, 8659], "temperature": 0.0, "avg_logprob": -0.10855569644850127, "compression_ratio": 1.66793893129771, "no_speech_prob": 5.172740202397108e-06}, {"id": 56, "seek": 30204, "start": 310.52000000000004, "end": 319.40000000000003, "text": " allowing some random person in a pull request to run software on your HPC machine. This", "tokens": [8293, 512, 4974, 954, 294, 257, 2235, 5308, 281, 1190, 4722, 322, 428, 12557, 34, 3479, 13, 639], "temperature": 0.0, "avg_logprob": -0.10855569644850127, "compression_ratio": 1.66793893129771, "no_speech_prob": 5.172740202397108e-06}, {"id": 57, "seek": 30204, "start": 319.40000000000003, "end": 322.72, "text": " is the model for SPAC. We have a bunch of external contributors on GitHub constantly", "tokens": [307, 264, 2316, 337, 8420, 4378, 13, 492, 362, 257, 3840, 295, 8320, 45627, 322, 23331, 6460], "temperature": 0.0, "avg_logprob": -0.10855569644850127, "compression_ratio": 1.66793893129771, "no_speech_prob": 5.172740202397108e-06}, {"id": 58, "seek": 30204, "start": 322.72, "end": 328.88, "text": " contributing to this develop branch. We have stable release branches where we freeze the", "tokens": [19270, 281, 341, 1499, 9819, 13, 492, 362, 8351, 4374, 14770, 689, 321, 15959, 264], "temperature": 0.0, "avg_logprob": -0.10855569644850127, "compression_ratio": 1.66793893129771, "no_speech_prob": 5.172740202397108e-06}, {"id": 59, "seek": 32888, "start": 328.88, "end": 334.8, "text": " packages to reduce the churn that some people rely on. Most users are actually on develop,", "tokens": [17401, 281, 5407, 264, 417, 925, 300, 512, 561, 10687, 322, 13, 4534, 5022, 366, 767, 322, 1499, 11], "temperature": 0.0, "avg_logprob": -0.13891412486200747, "compression_ratio": 1.5670103092783505, "no_speech_prob": 2.7520116418600082e-05}, {"id": 60, "seek": 32888, "start": 334.8, "end": 338.92, "text": " at least according to our surveys, which is a little surprising to me, but that's where", "tokens": [412, 1935, 4650, 281, 527, 22711, 11, 597, 307, 257, 707, 8830, 281, 385, 11, 457, 300, 311, 689], "temperature": 0.0, "avg_logprob": -0.13891412486200747, "compression_ratio": 1.5670103092783505, "no_speech_prob": 2.7520116418600082e-05}, {"id": 61, "seek": 32888, "start": 338.92, "end": 340.6, "text": " we are.", "tokens": [321, 366, 13], "temperature": 0.0, "avg_logprob": -0.13891412486200747, "compression_ratio": 1.5670103092783505, "no_speech_prob": 2.7520116418600082e-05}, {"id": 62, "seek": 32888, "start": 340.6, "end": 345.15999999999997, "text": " Then off of the release branches, there is a software distribution within the XSCL project", "tokens": [1396, 766, 295, 264, 4374, 14770, 11, 456, 307, 257, 4722, 7316, 1951, 264, 1783, 20839, 43, 1716], "temperature": 0.0, "avg_logprob": -0.13891412486200747, "compression_ratio": 1.5670103092783505, "no_speech_prob": 2.7520116418600082e-05}, {"id": 63, "seek": 32888, "start": 345.15999999999997, "end": 349.88, "text": " in the U.S. called E4S. There's a few others that sort of freeze a commit from SPAC and", "tokens": [294, 264, 624, 13, 50, 13, 1219, 462, 19, 50, 13, 821, 311, 257, 1326, 2357, 300, 1333, 295, 15959, 257, 5599, 490, 8420, 4378, 293], "temperature": 0.0, "avg_logprob": -0.13891412486200747, "compression_ratio": 1.5670103092783505, "no_speech_prob": 2.7520116418600082e-05}, {"id": 64, "seek": 32888, "start": 349.88, "end": 354.56, "text": " do their own integration after that. That's really supposed to be the deployment mechanism", "tokens": [360, 641, 1065, 10980, 934, 300, 13, 663, 311, 534, 3442, 281, 312, 264, 19317, 7513], "temperature": 0.0, "avg_logprob": -0.13891412486200747, "compression_ratio": 1.5670103092783505, "no_speech_prob": 2.7520116418600082e-05}, {"id": 65, "seek": 35456, "start": 354.56, "end": 360.56, "text": " for the 100 or so packages, and it's like 600 with dependencies, that are in ECP. What", "tokens": [337, 264, 2319, 420, 370, 17401, 11, 293, 309, 311, 411, 11849, 365, 36606, 11, 300, 366, 294, 19081, 47, 13, 708], "temperature": 0.0, "avg_logprob": -0.13471342899181224, "compression_ratio": 1.6109090909090908, "no_speech_prob": 1.9520499336067587e-05}, {"id": 66, "seek": 35456, "start": 360.56, "end": 367.68, "text": " happens with this is that that gets deployed to the facilities, and the E4S team goes and", "tokens": [2314, 365, 341, 307, 300, 300, 2170, 17826, 281, 264, 9406, 11, 293, 264, 462, 19, 50, 1469, 1709, 293], "temperature": 0.0, "avg_logprob": -0.13471342899181224, "compression_ratio": 1.6109090909090908, "no_speech_prob": 1.9520499336067587e-05}, {"id": 67, "seek": 35456, "start": 367.68, "end": 373.16, "text": " ensures that everything works, but we're not able to run on these systems on pull requests", "tokens": [28111, 300, 1203, 1985, 11, 457, 321, 434, 406, 1075, 281, 1190, 322, 613, 3652, 322, 2235, 12475], "temperature": 0.0, "avg_logprob": -0.13471342899181224, "compression_ratio": 1.6109090909090908, "no_speech_prob": 1.9520499336067587e-05}, {"id": 68, "seek": 35456, "start": 373.16, "end": 378.12, "text": " in CI, and it's very frustrating. Essentially, this is a bunch of downstream work that we", "tokens": [294, 37777, 11, 293, 309, 311, 588, 16522, 13, 23596, 11, 341, 307, 257, 3840, 295, 30621, 589, 300, 321], "temperature": 0.0, "avg_logprob": -0.13471342899181224, "compression_ratio": 1.6109090909090908, "no_speech_prob": 1.9520499336067587e-05}, {"id": 69, "seek": 35456, "start": 378.12, "end": 383.16, "text": " would really like to get rid of. Moreover, the applications are also doing downstream", "tokens": [576, 534, 411, 281, 483, 3973, 295, 13, 19838, 11, 264, 5821, 366, 611, 884, 30621], "temperature": 0.0, "avg_logprob": -0.13471342899181224, "compression_ratio": 1.6109090909090908, "no_speech_prob": 1.9520499336067587e-05}, {"id": 70, "seek": 38316, "start": 383.16, "end": 387.28000000000003, "text": " integration. They may have their own CI, which may be good. They're essentially pulling", "tokens": [10980, 13, 814, 815, 362, 641, 1065, 37777, 11, 597, 815, 312, 665, 13, 814, 434, 4476, 8407], "temperature": 0.0, "avg_logprob": -0.09291268086087877, "compression_ratio": 1.9311475409836065, "no_speech_prob": 1.5202018403215334e-05}, {"id": 71, "seek": 38316, "start": 387.28000000000003, "end": 391.0, "text": " from all these places. They may pull a facility deployment. They may pull from develop. They", "tokens": [490, 439, 613, 3190, 13, 814, 815, 2235, 257, 8973, 19317, 13, 814, 815, 2235, 490, 1499, 13, 814], "temperature": 0.0, "avg_logprob": -0.09291268086087877, "compression_ratio": 1.9311475409836065, "no_speech_prob": 1.5202018403215334e-05}, {"id": 72, "seek": 38316, "start": 391.0, "end": 394.28000000000003, "text": " may pull from a release. They're essentially integrating from all these places, and so", "tokens": [815, 2235, 490, 257, 4374, 13, 814, 434, 4476, 26889, 490, 439, 613, 3190, 11, 293, 370], "temperature": 0.0, "avg_logprob": -0.09291268086087877, "compression_ratio": 1.9311475409836065, "no_speech_prob": 1.5202018403215334e-05}, {"id": 73, "seek": 38316, "start": 394.28000000000003, "end": 396.40000000000003, "text": " there's a lot of downstream porting there.", "tokens": [456, 311, 257, 688, 295, 30621, 2436, 278, 456, 13], "temperature": 0.0, "avg_logprob": -0.09291268086087877, "compression_ratio": 1.9311475409836065, "no_speech_prob": 1.5202018403215334e-05}, {"id": 74, "seek": 38316, "start": 396.40000000000003, "end": 401.16, "text": " What we would ultimately like to do in SPAC is take all of that work that's going on downstream", "tokens": [708, 321, 576, 6284, 411, 281, 360, 294, 8420, 4378, 307, 747, 439, 295, 300, 589, 300, 311, 516, 322, 30621], "temperature": 0.0, "avg_logprob": -0.09291268086087877, "compression_ratio": 1.9311475409836065, "no_speech_prob": 1.5202018403215334e-05}, {"id": 75, "seek": 38316, "start": 401.16, "end": 406.8, "text": " and move it upstream so that we're actually doing CI testing on develop along with everything", "tokens": [293, 1286, 309, 33915, 370, 300, 321, 434, 767, 884, 37777, 4997, 322, 1499, 2051, 365, 1203], "temperature": 0.0, "avg_logprob": -0.09291268086087877, "compression_ratio": 1.9311475409836065, "no_speech_prob": 1.5202018403215334e-05}, {"id": 76, "seek": 38316, "start": 406.8, "end": 410.44000000000005, "text": " else. This is progress towards that, but we're not doing that yet. Essentially, the main", "tokens": [1646, 13, 639, 307, 4205, 3030, 300, 11, 457, 321, 434, 406, 884, 300, 1939, 13, 23596, 11, 264, 2135], "temperature": 0.0, "avg_logprob": -0.09291268086087877, "compression_ratio": 1.9311475409836065, "no_speech_prob": 1.5202018403215334e-05}, {"id": 77, "seek": 41044, "start": 410.44, "end": 416.84, "text": " obstacle for us to build stuff that looks like the HPC environments right now is a", "tokens": [23112, 337, 505, 281, 1322, 1507, 300, 1542, 411, 264, 12557, 34, 12388, 558, 586, 307, 257], "temperature": 0.0, "avg_logprob": -0.13217215971513227, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.355652436061064e-06}, {"id": 78, "seek": 41044, "start": 416.84, "end": 422.76, "text": " licensing issue, which is that we can't take the CrayPE container and run it in the cloud,", "tokens": [29759, 2734, 11, 597, 307, 300, 321, 393, 380, 747, 264, 383, 3458, 5208, 10129, 293, 1190, 309, 294, 264, 4588, 11], "temperature": 0.0, "avg_logprob": -0.13217215971513227, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.355652436061064e-06}, {"id": 79, "seek": 41044, "start": 422.76, "end": 426.8, "text": " because that's just not something you can do with HPC's license. We are pushing them", "tokens": [570, 300, 311, 445, 406, 746, 291, 393, 360, 365, 12557, 34, 311, 10476, 13, 492, 366, 7380, 552], "temperature": 0.0, "avg_logprob": -0.13217215971513227, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.355652436061064e-06}, {"id": 80, "seek": 41044, "start": 426.8, "end": 431.56, "text": " real hard on this and trying to get an exception for us to build things, in which case we would", "tokens": [957, 1152, 322, 341, 293, 1382, 281, 483, 364, 11183, 337, 505, 281, 1322, 721, 11, 294, 597, 1389, 321, 576], "temperature": 0.0, "avg_logprob": -0.13217215971513227, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.355652436061064e-06}, {"id": 81, "seek": 41044, "start": 431.56, "end": 437.04, "text": " be able to do work upstream and, ideally, deploy at the facilities from the binary cache,", "tokens": [312, 1075, 281, 360, 589, 33915, 293, 11, 22915, 11, 7274, 412, 264, 9406, 490, 264, 17434, 19459, 11], "temperature": 0.0, "avg_logprob": -0.13217215971513227, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.355652436061064e-06}, {"id": 82, "seek": 43704, "start": 437.04, "end": 443.72, "text": " which I think would be way more stable and less error-prone than what we do right now.", "tokens": [597, 286, 519, 576, 312, 636, 544, 8351, 293, 1570, 6713, 12, 1424, 546, 813, 437, 321, 360, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.12338634899684361, "compression_ratio": 1.7322834645669292, "no_speech_prob": 2.1108156943228096e-05}, {"id": 83, "seek": 43704, "start": 443.72, "end": 450.20000000000005, "text": " We set out to make this CI system to enable this with a bunch of different goals. One", "tokens": [492, 992, 484, 281, 652, 341, 37777, 1185, 281, 9528, 341, 365, 257, 3840, 295, 819, 5493, 13, 1485], "temperature": 0.0, "avg_logprob": -0.12338634899684361, "compression_ratio": 1.7322834645669292, "no_speech_prob": 2.1108156943228096e-05}, {"id": 84, "seek": 43704, "start": 450.20000000000005, "end": 454.84000000000003, "text": " of the goals is that we want to be sustainable. We don't want to change the maintainer workflow,", "tokens": [295, 264, 5493, 307, 300, 321, 528, 281, 312, 11235, 13, 492, 500, 380, 528, 281, 1319, 264, 6909, 260, 20993, 11], "temperature": 0.0, "avg_logprob": -0.12338634899684361, "compression_ratio": 1.7322834645669292, "no_speech_prob": 2.1108156943228096e-05}, {"id": 85, "seek": 43704, "start": 454.84000000000003, "end": 459.84000000000003, "text": " and we already have few enough maintainers for the amount of work that there is that", "tokens": [293, 321, 1217, 362, 1326, 1547, 6909, 433, 337, 264, 2372, 295, 589, 300, 456, 307, 300], "temperature": 0.0, "avg_logprob": -0.12338634899684361, "compression_ratio": 1.7322834645669292, "no_speech_prob": 2.1108156943228096e-05}, {"id": 86, "seek": 43704, "start": 459.84000000000003, "end": 463.92, "text": " we don't want to change what they have to do. They're used to going out on GitHub and", "tokens": [321, 500, 380, 528, 281, 1319, 437, 436, 362, 281, 360, 13, 814, 434, 1143, 281, 516, 484, 322, 23331, 293], "temperature": 0.0, "avg_logprob": -0.12338634899684361, "compression_ratio": 1.7322834645669292, "no_speech_prob": 2.1108156943228096e-05}, {"id": 87, "seek": 46392, "start": 463.92, "end": 469.92, "text": " approving PRs, getting them merged, checking if they build and so on. We don't want them", "tokens": [2075, 798, 11568, 82, 11, 1242, 552, 36427, 11, 8568, 498, 436, 1322, 293, 370, 322, 13, 492, 500, 380, 528, 552], "temperature": 0.0, "avg_logprob": -0.12028042355874427, "compression_ratio": 1.7898305084745763, "no_speech_prob": 1.6697034880053252e-05}, {"id": 88, "seek": 46392, "start": 469.92, "end": 473.56, "text": " to have to do something different, so we don't want them to both have to maintain PRs and", "tokens": [281, 362, 281, 360, 746, 819, 11, 370, 321, 500, 380, 528, 552, 281, 1293, 362, 281, 6909, 11568, 82, 293], "temperature": 0.0, "avg_logprob": -0.12028042355874427, "compression_ratio": 1.7898305084745763, "no_speech_prob": 1.6697034880053252e-05}, {"id": 89, "seek": 46392, "start": 473.56, "end": 477.96000000000004, "text": " think about how the integration branch is doing, like some distros do. We'd like that", "tokens": [519, 466, 577, 264, 10980, 9819, 307, 884, 11, 411, 512, 1483, 2635, 360, 13, 492, 1116, 411, 300], "temperature": 0.0, "avg_logprob": -0.12028042355874427, "compression_ratio": 1.7898305084745763, "no_speech_prob": 1.6697034880053252e-05}, {"id": 90, "seek": 46392, "start": 477.96000000000004, "end": 483.12, "text": " to just happen. In that vein, we want a rolling release where, on develop, we're constantly", "tokens": [281, 445, 1051, 13, 682, 300, 30669, 11, 321, 528, 257, 9439, 4374, 689, 11, 322, 1499, 11, 321, 434, 6460], "temperature": 0.0, "avg_logprob": -0.12028042355874427, "compression_ratio": 1.7898305084745763, "no_speech_prob": 1.6697034880053252e-05}, {"id": 91, "seek": 46392, "start": 483.12, "end": 489.20000000000005, "text": " building binaries for the develop branch, and that we basically snapshot develop for", "tokens": [2390, 5171, 4889, 337, 264, 1499, 9819, 11, 293, 300, 321, 1936, 30163, 1499, 337], "temperature": 0.0, "avg_logprob": -0.12028042355874427, "compression_ratio": 1.7898305084745763, "no_speech_prob": 1.6697034880053252e-05}, {"id": 92, "seek": 46392, "start": 489.20000000000005, "end": 492.76, "text": " every release that we do and say, okay, it's stable. Everything built. We are ready to", "tokens": [633, 4374, 300, 321, 360, 293, 584, 11, 1392, 11, 309, 311, 8351, 13, 5471, 3094, 13, 492, 366, 1919, 281], "temperature": 0.0, "avg_logprob": -0.12028042355874427, "compression_ratio": 1.7898305084745763, "no_speech_prob": 1.6697034880053252e-05}, {"id": 93, "seek": 49276, "start": 492.76, "end": 497.0, "text": " do the release. We'll just cut one, and then we will backport bug fixes to this back tool", "tokens": [360, 264, 4374, 13, 492, 603, 445, 1723, 472, 11, 293, 550, 321, 486, 646, 2707, 7426, 32539, 281, 341, 646, 2290], "temperature": 0.0, "avg_logprob": -0.13436944556958746, "compression_ratio": 1.7475083056478404, "no_speech_prob": 9.365247024106793e-06}, {"id": 94, "seek": 49276, "start": 497.0, "end": 501.71999999999997, "text": " on that release if we need to. We want it to eventually support all 6,900 packages.", "tokens": [322, 300, 4374, 498, 321, 643, 281, 13, 492, 528, 309, 281, 4728, 1406, 439, 1386, 11, 23943, 17401, 13], "temperature": 0.0, "avg_logprob": -0.13436944556958746, "compression_ratio": 1.7475083056478404, "no_speech_prob": 9.365247024106793e-06}, {"id": 95, "seek": 49276, "start": 501.71999999999997, "end": 505.36, "text": " It's not something we're doing now, and we want source builds to still work with these", "tokens": [467, 311, 406, 746, 321, 434, 884, 586, 11, 293, 321, 528, 4009, 15182, 281, 920, 589, 365, 613], "temperature": 0.0, "avg_logprob": -0.13436944556958746, "compression_ratio": 1.7475083056478404, "no_speech_prob": 9.365247024106793e-06}, {"id": 96, "seek": 49276, "start": 505.36, "end": 510.0, "text": " binaries effectively once it's done. We want to make sure that the recipes are still versatile", "tokens": [5171, 4889, 8659, 1564, 309, 311, 1096, 13, 492, 528, 281, 652, 988, 300, 264, 13035, 366, 920, 25057], "temperature": 0.0, "avg_logprob": -0.13436944556958746, "compression_ratio": 1.7475083056478404, "no_speech_prob": 9.365247024106793e-06}, {"id": 97, "seek": 49276, "start": 510.0, "end": 514.4, "text": " enough to do all those combinations of builds that I showed on the first slide.", "tokens": [1547, 281, 360, 439, 729, 21267, 295, 15182, 300, 286, 4712, 322, 264, 700, 4137, 13], "temperature": 0.0, "avg_logprob": -0.13436944556958746, "compression_ratio": 1.7475083056478404, "no_speech_prob": 9.365247024106793e-06}, {"id": 98, "seek": 49276, "start": 514.4, "end": 519.16, "text": " Then finally, and this is a big one, we wanted to ensure that the binaries that we have in", "tokens": [1396, 2721, 11, 293, 341, 307, 257, 955, 472, 11, 321, 1415, 281, 5586, 300, 264, 5171, 4889, 300, 321, 362, 294], "temperature": 0.0, "avg_logprob": -0.13436944556958746, "compression_ratio": 1.7475083056478404, "no_speech_prob": 9.365247024106793e-06}, {"id": 99, "seek": 51916, "start": 519.16, "end": 523.48, "text": " SPAC are just as trustworthy as the sources. If you feel like you can trust our maintainers", "tokens": [8420, 4378, 366, 445, 382, 39714, 382, 264, 7139, 13, 759, 291, 841, 411, 291, 393, 3361, 527, 6909, 433], "temperature": 0.0, "avg_logprob": -0.15686377267988902, "compression_ratio": 1.8013698630136987, "no_speech_prob": 1.9219101886847056e-05}, {"id": 100, "seek": 51916, "start": 523.48, "end": 527.88, "text": " and rely on the sources that are in SPAC packages with checksums, that you feel just as comfortable", "tokens": [293, 10687, 322, 264, 7139, 300, 366, 294, 8420, 4378, 17401, 365, 13834, 8099, 11, 300, 291, 841, 445, 382, 4619], "temperature": 0.0, "avg_logprob": -0.15686377267988902, "compression_ratio": 1.8013698630136987, "no_speech_prob": 1.9219101886847056e-05}, {"id": 101, "seek": 51916, "start": 527.88, "end": 532.9599999999999, "text": " with the binaries that we're putting in the build cache for you.", "tokens": [365, 264, 5171, 4889, 300, 321, 434, 3372, 294, 264, 1322, 19459, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.15686377267988902, "compression_ratio": 1.8013698630136987, "no_speech_prob": 1.9219101886847056e-05}, {"id": 102, "seek": 51916, "start": 532.9599999999999, "end": 537.7199999999999, "text": " If you think about how this works, if you look at traditional package managers, like", "tokens": [759, 291, 519, 466, 577, 341, 1985, 11, 498, 291, 574, 412, 5164, 7372, 14084, 11, 411], "temperature": 0.0, "avg_logprob": -0.15686377267988902, "compression_ratio": 1.8013698630136987, "no_speech_prob": 1.9219101886847056e-05}, {"id": 103, "seek": 51916, "start": 537.7199999999999, "end": 543.0799999999999, "text": " say APT or YUM, you have a recipe per package configuration that's getting thrown into a", "tokens": [584, 5372, 51, 420, 398, 14340, 11, 291, 362, 257, 6782, 680, 7372, 11694, 300, 311, 1242, 11732, 666, 257], "temperature": 0.0, "avg_logprob": -0.15686377267988902, "compression_ratio": 1.8013698630136987, "no_speech_prob": 1.9219101886847056e-05}, {"id": 104, "seek": 51916, "start": 543.0799999999999, "end": 548.12, "text": " build farm. For each of those package configurations, think like easy configs if easy build had", "tokens": [1322, 5421, 13, 1171, 1184, 295, 729, 7372, 31493, 11, 519, 411, 1858, 6662, 82, 498, 1858, 1322, 632], "temperature": 0.0, "avg_logprob": -0.15686377267988902, "compression_ratio": 1.8013698630136987, "no_speech_prob": 1.9219101886847056e-05}, {"id": 105, "seek": 54812, "start": 548.12, "end": 554.92, "text": " binaries. Throw that into a build farm and then you get these portable unoptimized binaries", "tokens": [5171, 4889, 13, 22228, 300, 666, 257, 1322, 5421, 293, 550, 291, 483, 613, 21800, 517, 5747, 332, 1602, 5171, 4889], "temperature": 0.0, "avg_logprob": -0.145420457715186, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.4736726370756514e-05}, {"id": 106, "seek": 54812, "start": 554.92, "end": 559.16, "text": " for theoretical binary having easy build, where there's one of those per package configuration", "tokens": [337, 20864, 17434, 1419, 1858, 1322, 11, 689, 456, 311, 472, 295, 729, 680, 7372, 11694], "temperature": 0.0, "avg_logprob": -0.145420457715186, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.4736726370756514e-05}, {"id": 107, "seek": 54812, "start": 559.16, "end": 565.12, "text": " or per spec file or whatever. This is more like an APT or whatever. You're managing one", "tokens": [420, 680, 1608, 3991, 420, 2035, 13, 639, 307, 544, 411, 364, 5372, 51, 420, 2035, 13, 509, 434, 11642, 472], "temperature": 0.0, "avg_logprob": -0.145420457715186, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.4736726370756514e-05}, {"id": 108, "seek": 54812, "start": 565.12, "end": 568.76, "text": " software stack that's meant to be upgraded over time, and there's a consistent ABI across", "tokens": [4722, 8630, 300, 311, 4140, 281, 312, 24133, 670, 565, 11, 293, 456, 311, 257, 8398, 316, 11291, 2108], "temperature": 0.0, "avg_logprob": -0.145420457715186, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.4736726370756514e-05}, {"id": 109, "seek": 54812, "start": 568.76, "end": 573.28, "text": " the distribution so that you can swap one package in for another. The solver in those", "tokens": [264, 7316, 370, 300, 291, 393, 18135, 472, 7372, 294, 337, 1071, 13, 440, 1404, 331, 294, 729], "temperature": 0.0, "avg_logprob": -0.145420457715186, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.4736726370756514e-05}, {"id": 110, "seek": 57328, "start": 573.28, "end": 578.64, "text": " distributions really operates on the binaries. In SPAC, you have parameterized package recipes", "tokens": [37870, 534, 22577, 322, 264, 5171, 4889, 13, 682, 8420, 4378, 11, 291, 362, 13075, 1602, 7372, 13035], "temperature": 0.0, "avg_logprob": -0.12183749986731487, "compression_ratio": 1.9031141868512111, "no_speech_prob": 1.1476654435682576e-05}, {"id": 111, "seek": 57328, "start": 578.64, "end": 582.1999999999999, "text": " that we are designing to be portable, and we want the maintainers to work on them together", "tokens": [300, 321, 366, 14685, 281, 312, 21800, 11, 293, 321, 528, 264, 6909, 433, 281, 589, 322, 552, 1214], "temperature": 0.0, "avg_logprob": -0.12183749986731487, "compression_ratio": 1.9031141868512111, "no_speech_prob": 1.1476654435682576e-05}, {"id": 112, "seek": 57328, "start": 582.1999999999999, "end": 585.8399999999999, "text": " so that they remain portable, so you can use them in different environments. Throw those", "tokens": [370, 300, 436, 6222, 21800, 11, 370, 291, 393, 764, 552, 294, 819, 12388, 13, 22228, 729], "temperature": 0.0, "avg_logprob": -0.12183749986731487, "compression_ratio": 1.9031141868512111, "no_speech_prob": 1.1476654435682576e-05}, {"id": 113, "seek": 57328, "start": 585.8399999999999, "end": 589.64, "text": " into the build farm and effectively test the parameterized package recipe in lots of different", "tokens": [666, 264, 1322, 5421, 293, 8659, 1500, 264, 13075, 1602, 7372, 6782, 294, 3195, 295, 819], "temperature": 0.0, "avg_logprob": -0.12183749986731487, "compression_ratio": 1.9031141868512111, "no_speech_prob": 1.1476654435682576e-05}, {"id": 114, "seek": 57328, "start": 589.64, "end": 594.28, "text": " configurations and spit out different stacks. Lots of different stacks optimized for different", "tokens": [31493, 293, 22127, 484, 819, 30792, 13, 15908, 295, 819, 30792, 26941, 337, 819], "temperature": 0.0, "avg_logprob": -0.12183749986731487, "compression_ratio": 1.9031141868512111, "no_speech_prob": 1.1476654435682576e-05}, {"id": 115, "seek": 57328, "start": 594.28, "end": 598.76, "text": " environments from the same portable recipes for different systems, OSs, compilers and", "tokens": [12388, 490, 264, 912, 21800, 13035, 337, 819, 3652, 11, 12731, 82, 11, 715, 388, 433, 293], "temperature": 0.0, "avg_logprob": -0.12183749986731487, "compression_ratio": 1.9031141868512111, "no_speech_prob": 1.1476654435682576e-05}, {"id": 116, "seek": 59876, "start": 598.76, "end": 603.84, "text": " MPIs and so on. We also want, at any time, for you to be able to choose to build something", "tokens": [14146, 6802, 293, 370, 322, 13, 492, 611, 528, 11, 412, 604, 565, 11, 337, 291, 281, 312, 1075, 281, 2826, 281, 1322, 746], "temperature": 0.0, "avg_logprob": -0.16992856838085033, "compression_ratio": 1.6109090909090908, "no_speech_prob": 6.8531217038980685e-06}, {"id": 117, "seek": 59876, "start": 603.84, "end": 609.88, "text": " from source along with that if you want to customize some aspect of the pipeline. To", "tokens": [490, 4009, 2051, 365, 300, 498, 291, 528, 281, 19734, 512, 4171, 295, 264, 15517, 13, 1407], "temperature": 0.0, "avg_logprob": -0.16992856838085033, "compression_ratio": 1.6109090909090908, "no_speech_prob": 6.8531217038980685e-06}, {"id": 118, "seek": 59876, "start": 609.88, "end": 616.2, "text": " enable that, we came up with this architecture. We have a bunch of AWS resources, because", "tokens": [9528, 300, 11, 321, 1361, 493, 365, 341, 9482, 13, 492, 362, 257, 3840, 295, 17650, 3593, 11, 570], "temperature": 0.0, "avg_logprob": -0.16992856838085033, "compression_ratio": 1.6109090909090908, "no_speech_prob": 6.8531217038980685e-06}, {"id": 119, "seek": 59876, "start": 616.2, "end": 623.08, "text": " AWS has been nice enough to donate some cycles to the project. They are interested in using", "tokens": [17650, 575, 668, 1481, 1547, 281, 17751, 512, 17796, 281, 264, 1716, 13, 814, 366, 3102, 294, 1228], "temperature": 0.0, "avg_logprob": -0.16992856838085033, "compression_ratio": 1.6109090909090908, "no_speech_prob": 6.8531217038980685e-06}, {"id": 120, "seek": 59876, "start": 623.08, "end": 626.8, "text": " SPAC in their parallel cluster product, and so that's the motivation for them is they", "tokens": [8420, 4378, 294, 641, 8952, 13630, 1674, 11, 293, 370, 300, 311, 264, 12335, 337, 552, 307, 436], "temperature": 0.0, "avg_logprob": -0.16992856838085033, "compression_ratio": 1.6109090909090908, "no_speech_prob": 6.8531217038980685e-06}, {"id": 121, "seek": 62680, "start": 626.8, "end": 630.24, "text": " want binaries ready to go if someone spins up a cluster in the cloud. They don't want", "tokens": [528, 5171, 4889, 1919, 281, 352, 498, 1580, 31587, 493, 257, 13630, 294, 264, 4588, 13, 814, 500, 380, 528], "temperature": 0.0, "avg_logprob": -0.15091540847999463, "compression_ratio": 1.7193548387096773, "no_speech_prob": 1.6184185369638726e-05}, {"id": 122, "seek": 62680, "start": 630.24, "end": 634.24, "text": " to spin up a cluster and have it sit there and build software for hours and then run", "tokens": [281, 6060, 493, 257, 13630, 293, 362, 309, 1394, 456, 293, 1322, 4722, 337, 2496, 293, 550, 1190], "temperature": 0.0, "avg_logprob": -0.15091540847999463, "compression_ratio": 1.7193548387096773, "no_speech_prob": 1.6184185369638726e-05}, {"id": 123, "seek": 62680, "start": 634.24, "end": 637.64, "text": " after having charged a bunch of money, which is nice to them, because they would make a", "tokens": [934, 1419, 11109, 257, 3840, 295, 1460, 11, 597, 307, 1481, 281, 552, 11, 570, 436, 576, 652, 257], "temperature": 0.0, "avg_logprob": -0.15091540847999463, "compression_ratio": 1.7193548387096773, "no_speech_prob": 1.6184185369638726e-05}, {"id": 124, "seek": 62680, "start": 637.64, "end": 645.52, "text": " lot of money. But then no one would use their service. They want binaries. In there, we", "tokens": [688, 295, 1460, 13, 583, 550, 572, 472, 576, 764, 641, 2643, 13, 814, 528, 5171, 4889, 13, 682, 456, 11, 321], "temperature": 0.0, "avg_logprob": -0.15091540847999463, "compression_ratio": 1.7193548387096773, "no_speech_prob": 1.6184185369638726e-05}, {"id": 125, "seek": 62680, "start": 645.52, "end": 650.92, "text": " use S3 and CloudFront to distribute the binaries around the world. EC2 is really the main build", "tokens": [764, 318, 18, 293, 8061, 37, 10001, 281, 20594, 264, 5171, 4889, 926, 264, 1002, 13, 19081, 17, 307, 534, 264, 2135, 1322], "temperature": 0.0, "avg_logprob": -0.15091540847999463, "compression_ratio": 1.7193548387096773, "no_speech_prob": 1.6184185369638726e-05}, {"id": 126, "seek": 62680, "start": 650.92, "end": 656.0799999999999, "text": " resource, and RDS is in there, but it's not that important. We've got a Kubernetes cluster", "tokens": [7684, 11, 293, 497, 11844, 307, 294, 456, 11, 457, 309, 311, 406, 300, 1021, 13, 492, 600, 658, 257, 23145, 13630], "temperature": 0.0, "avg_logprob": -0.15091540847999463, "compression_ratio": 1.7193548387096773, "no_speech_prob": 1.6184185369638726e-05}, {"id": 127, "seek": 65608, "start": 656.08, "end": 660.2800000000001, "text": " in there that we have autoscaling runners in, and so we're building mostly in containers", "tokens": [294, 456, 300, 321, 362, 1476, 10466, 4270, 33892, 294, 11, 293, 370, 321, 434, 2390, 5240, 294, 17089], "temperature": 0.0, "avg_logprob": -0.14726650609379321, "compression_ratio": 1.7115384615384615, "no_speech_prob": 1.1123311196570285e-05}, {"id": 128, "seek": 65608, "start": 660.2800000000001, "end": 664.48, "text": " inside of Kube, and there's a GitLab instance in there, too. We have a high-availability", "tokens": [1854, 295, 591, 1977, 11, 293, 456, 311, 257, 16939, 37880, 5197, 294, 456, 11, 886, 13, 492, 362, 257, 1090, 12, 706, 864, 2310], "temperature": 0.0, "avg_logprob": -0.14726650609379321, "compression_ratio": 1.7115384615384615, "no_speech_prob": 1.1123311196570285e-05}, {"id": 129, "seek": 65608, "start": 664.48, "end": 671.5600000000001, "text": " GitLab instance. We chose GitLab because the HPC centers actually have GitLab CI themselves.", "tokens": [16939, 37880, 5197, 13, 492, 5111, 16939, 37880, 570, 264, 12557, 34, 10898, 767, 362, 16939, 37880, 37777, 2969, 13], "temperature": 0.0, "avg_logprob": -0.14726650609379321, "compression_ratio": 1.7115384615384615, "no_speech_prob": 1.1123311196570285e-05}, {"id": 130, "seek": 65608, "start": 671.5600000000001, "end": 677.24, "text": " The same CI logic that we run in the cloud, you could take that and run it internally", "tokens": [440, 912, 37777, 9952, 300, 321, 1190, 294, 264, 4588, 11, 291, 727, 747, 300, 293, 1190, 309, 19501], "temperature": 0.0, "avg_logprob": -0.14726650609379321, "compression_ratio": 1.7115384615384615, "no_speech_prob": 1.1123311196570285e-05}, {"id": 131, "seek": 65608, "start": 677.24, "end": 682.08, "text": " and have these pipelines generated for you at your own site, too. You could slap another", "tokens": [293, 362, 613, 40168, 10833, 337, 291, 412, 428, 1065, 3621, 11, 886, 13, 509, 727, 21075, 1071], "temperature": 0.0, "avg_logprob": -0.14726650609379321, "compression_ratio": 1.7115384615384615, "no_speech_prob": 1.1123311196570285e-05}, {"id": 132, "seek": 68208, "start": 682.08, "end": 686.2800000000001, "text": " back end on this and have it generate build grass for some other system, but that's the", "tokens": [646, 917, 322, 341, 293, 362, 309, 8460, 1322, 8054, 337, 512, 661, 1185, 11, 457, 300, 311, 264], "temperature": 0.0, "avg_logprob": -0.13535257975260417, "compression_ratio": 1.717557251908397, "no_speech_prob": 1.184048960567452e-05}, {"id": 133, "seek": 68208, "start": 686.2800000000001, "end": 691.08, "text": " one that we're using. We're using runner pools with something called Carpenter to basically", "tokens": [472, 300, 321, 434, 1228, 13, 492, 434, 1228, 24376, 28688, 365, 746, 1219, 2741, 79, 14278, 281, 1936], "temperature": 0.0, "avg_logprob": -0.13535257975260417, "compression_ratio": 1.717557251908397, "no_speech_prob": 1.184048960567452e-05}, {"id": 134, "seek": 68208, "start": 691.08, "end": 696.64, "text": " get just-in-time instances and allocate the containers on them efficiently, and then we", "tokens": [483, 445, 12, 259, 12, 3766, 14519, 293, 35713, 264, 17089, 322, 552, 19621, 11, 293, 550, 321], "temperature": 0.0, "avg_logprob": -0.13535257975260417, "compression_ratio": 1.717557251908397, "no_speech_prob": 1.184048960567452e-05}, {"id": 135, "seek": 68208, "start": 696.64, "end": 700.4000000000001, "text": " have some bare-metal runners at the University of Oregon with some fairly exotic architectures", "tokens": [362, 512, 6949, 12, 39857, 33892, 412, 264, 3535, 295, 18664, 365, 512, 6457, 27063, 6331, 1303], "temperature": 0.0, "avg_logprob": -0.13535257975260417, "compression_ratio": 1.717557251908397, "no_speech_prob": 1.184048960567452e-05}, {"id": 136, "seek": 68208, "start": 700.4000000000001, "end": 705.4000000000001, "text": " on them. So if we need to build or if we need to specifically run on something that has", "tokens": [322, 552, 13, 407, 498, 321, 643, 281, 1322, 420, 498, 321, 643, 281, 4682, 1190, 322, 746, 300, 575], "temperature": 0.0, "avg_logprob": -0.13535257975260417, "compression_ratio": 1.717557251908397, "no_speech_prob": 1.184048960567452e-05}, {"id": 137, "seek": 70540, "start": 705.4, "end": 712.28, "text": " an AMD GPU or A64FX and so on, we can do that. And we could add more runners to this eventually.", "tokens": [364, 34808, 18407, 420, 316, 19395, 36092, 293, 370, 322, 11, 321, 393, 360, 300, 13, 400, 321, 727, 909, 544, 33892, 281, 341, 4728, 13], "temperature": 0.0, "avg_logprob": -0.16409660207814183, "compression_ratio": 1.5857142857142856, "no_speech_prob": 6.961644885450369e-06}, {"id": 138, "seek": 70540, "start": 712.28, "end": 717.92, "text": " And there's a bot that coordinates all this work. So it's a lot of stuff. Every time I", "tokens": [400, 456, 311, 257, 10592, 300, 21056, 439, 341, 589, 13, 407, 309, 311, 257, 688, 295, 1507, 13, 2048, 565, 286], "temperature": 0.0, "avg_logprob": -0.16409660207814183, "compression_ratio": 1.5857142857142856, "no_speech_prob": 6.961644885450369e-06}, {"id": 139, "seek": 70540, "start": 717.92, "end": 724.88, "text": " look at this, I am amazed at how complicated CI is and how it's one of those things that", "tokens": [574, 412, 341, 11, 286, 669, 20507, 412, 577, 6179, 37777, 307, 293, 577, 309, 311, 472, 295, 729, 721, 300], "temperature": 0.0, "avg_logprob": -0.16409660207814183, "compression_ratio": 1.5857142857142856, "no_speech_prob": 6.961644885450369e-06}, {"id": 140, "seek": 70540, "start": 724.88, "end": 729.68, "text": " seems like it should just work, but there is a lot to maintaining a reliable service", "tokens": [2544, 411, 309, 820, 445, 589, 11, 457, 456, 307, 257, 688, 281, 14916, 257, 12924, 2643], "temperature": 0.0, "avg_logprob": -0.16409660207814183, "compression_ratio": 1.5857142857142856, "no_speech_prob": 6.961644885450369e-06}, {"id": 141, "seek": 70540, "start": 729.68, "end": 734.0799999999999, "text": " for doing this many builds. And I suspect other distro maintainers have realized that,", "tokens": [337, 884, 341, 867, 15182, 13, 400, 286, 9091, 661, 1483, 340, 6909, 433, 362, 5334, 300, 11], "temperature": 0.0, "avg_logprob": -0.16409660207814183, "compression_ratio": 1.5857142857142856, "no_speech_prob": 6.961644885450369e-06}, {"id": 142, "seek": 73408, "start": 734.08, "end": 737.64, "text": " too, and I'm just late to the game.", "tokens": [886, 11, 293, 286, 478, 445, 3469, 281, 264, 1216, 13], "temperature": 0.0, "avg_logprob": -0.1378471446487139, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.282521927554626e-05}, {"id": 143, "seek": 73408, "start": 737.64, "end": 743.0400000000001, "text": " The way that contributing a stack in SPAC works is we have this directory in the repo", "tokens": [440, 636, 300, 19270, 257, 8630, 294, 8420, 4378, 1985, 307, 321, 362, 341, 21120, 294, 264, 49040], "temperature": 0.0, "avg_logprob": -0.1378471446487139, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.282521927554626e-05}, {"id": 144, "seek": 73408, "start": 743.0400000000001, "end": 748.08, "text": " that has all of the cloud pipelines in it. And so you can see some of them are for AWS.", "tokens": [300, 575, 439, 295, 264, 4588, 40168, 294, 309, 13, 400, 370, 291, 393, 536, 512, 295, 552, 366, 337, 17650, 13], "temperature": 0.0, "avg_logprob": -0.1378471446487139, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.282521927554626e-05}, {"id": 145, "seek": 73408, "start": 748.08, "end": 751.88, "text": " Some of them are different variations on E4S. Each of those directories contains just a", "tokens": [2188, 295, 552, 366, 819, 17840, 322, 462, 19, 50, 13, 6947, 295, 729, 5391, 530, 8306, 445, 257], "temperature": 0.0, "avg_logprob": -0.1378471446487139, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.282521927554626e-05}, {"id": 146, "seek": 73408, "start": 751.88, "end": 758.76, "text": " SPAC.yml that defines the stuff that is to be built. And so if you look inside of there,", "tokens": [8420, 4378, 13, 4199, 75, 300, 23122, 264, 1507, 300, 307, 281, 312, 3094, 13, 400, 370, 498, 291, 574, 1854, 295, 456, 11], "temperature": 0.0, "avg_logprob": -0.1378471446487139, "compression_ratio": 1.6016597510373445, "no_speech_prob": 2.282521927554626e-05}, {"id": 147, "seek": 75876, "start": 758.76, "end": 764.8, "text": " it's basically just, it's a list of packages. So here's the ML CUDA one that has the build", "tokens": [309, 311, 1936, 445, 11, 309, 311, 257, 1329, 295, 17401, 13, 407, 510, 311, 264, 21601, 29777, 7509, 472, 300, 575, 264, 1322], "temperature": 0.0, "avg_logprob": -0.20067196507607737, "compression_ratio": 1.6679245283018869, "no_speech_prob": 1.4282105439633597e-05}, {"id": 148, "seek": 75876, "start": 764.8, "end": 772.4, "text": " of, I think, PyTorch and TensorFlow, Keras, Jax and friends for CUDA. It's just a list", "tokens": [295, 11, 286, 519, 11, 9953, 51, 284, 339, 293, 37624, 11, 591, 6985, 11, 508, 2797, 293, 1855, 337, 29777, 7509, 13, 467, 311, 445, 257, 1329], "temperature": 0.0, "avg_logprob": -0.20067196507607737, "compression_ratio": 1.6679245283018869, "no_speech_prob": 1.4282105439633597e-05}, {"id": 149, "seek": 75876, "start": 772.4, "end": 776.24, "text": " of packages plus there's a target up there, a target setting for all the packages. You", "tokens": [295, 17401, 1804, 456, 311, 257, 3779, 493, 456, 11, 257, 3779, 3287, 337, 439, 264, 17401, 13, 509], "temperature": 0.0, "avg_logprob": -0.20067196507607737, "compression_ratio": 1.6679245283018869, "no_speech_prob": 1.4282105439633597e-05}, {"id": 150, "seek": 75876, "start": 776.24, "end": 781.24, "text": " could have a matrix of targets if you wanted. And then there's disable, rock them and enable", "tokens": [727, 362, 257, 8141, 295, 12911, 498, 291, 1415, 13, 400, 550, 456, 311, 28362, 11, 3727, 552, 293, 9528], "temperature": 0.0, "avg_logprob": -0.20067196507607737, "compression_ratio": 1.6679245283018869, "no_speech_prob": 1.4282105439633597e-05}, {"id": 151, "seek": 75876, "start": 781.24, "end": 785.12, "text": " CUDA on everything except for LLVM because there's that bug that's linked there. And", "tokens": [29777, 7509, 322, 1203, 3993, 337, 441, 43, 53, 44, 570, 456, 311, 300, 7426, 300, 311, 9408, 456, 13, 400], "temperature": 0.0, "avg_logprob": -0.20067196507607737, "compression_ratio": 1.6679245283018869, "no_speech_prob": 1.4282105439633597e-05}, {"id": 152, "seek": 78512, "start": 785.12, "end": 790.88, "text": " I'm not entirely sure about the specifics of that. But the configuration part is up here", "tokens": [286, 478, 406, 7696, 988, 466, 264, 28454, 295, 300, 13, 583, 264, 11694, 644, 307, 493, 510], "temperature": 0.0, "avg_logprob": -0.13347714287894114, "compression_ratio": 1.7072243346007605, "no_speech_prob": 2.1107171050971374e-05}, {"id": 153, "seek": 78512, "start": 790.88, "end": 795.5600000000001, "text": " and it's fairly minimal for the stack. There's currently, if you look at these, a bunch of", "tokens": [293, 309, 311, 6457, 13206, 337, 264, 8630, 13, 821, 311, 4362, 11, 498, 291, 574, 412, 613, 11, 257, 3840, 295], "temperature": 0.0, "avg_logprob": -0.13347714287894114, "compression_ratio": 1.7072243346007605, "no_speech_prob": 2.1107171050971374e-05}, {"id": 154, "seek": 78512, "start": 795.5600000000001, "end": 800.28, "text": " other boilerplate stuff for things like mapping runners. I'll get to that in a minute. But", "tokens": [661, 39228, 37008, 1507, 337, 721, 411, 18350, 33892, 13, 286, 603, 483, 281, 300, 294, 257, 3456, 13, 583], "temperature": 0.0, "avg_logprob": -0.13347714287894114, "compression_ratio": 1.7072243346007605, "no_speech_prob": 2.1107171050971374e-05}, {"id": 155, "seek": 78512, "start": 800.28, "end": 803.92, "text": " this is, there's a PR that's going to go in where this is basically all that's going", "tokens": [341, 307, 11, 456, 311, 257, 11568, 300, 311, 516, 281, 352, 294, 689, 341, 307, 1936, 439, 300, 311, 516], "temperature": 0.0, "avg_logprob": -0.13347714287894114, "compression_ratio": 1.7072243346007605, "no_speech_prob": 2.1107171050971374e-05}, {"id": 156, "seek": 78512, "start": 803.92, "end": 808.6, "text": " to be in your stack. And you might include some stuff from elsewhere. But this is essentially", "tokens": [281, 312, 294, 428, 8630, 13, 400, 291, 1062, 4090, 512, 1507, 490, 14517, 13, 583, 341, 307, 4476], "temperature": 0.0, "avg_logprob": -0.13347714287894114, "compression_ratio": 1.7072243346007605, "no_speech_prob": 2.1107171050971374e-05}, {"id": 157, "seek": 80860, "start": 808.6, "end": 816.4, "text": " a stack definition. And we take that and, you know, this makes it very easy to change", "tokens": [257, 8630, 7123, 13, 400, 321, 747, 300, 293, 11, 291, 458, 11, 341, 1669, 309, 588, 1858, 281, 1319], "temperature": 0.0, "avg_logprob": -0.15767738882419283, "compression_ratio": 1.649056603773585, "no_speech_prob": 2.7963715183432214e-05}, {"id": 158, "seek": 80860, "start": 816.4, "end": 821.2, "text": " low-level parameters in the stack. So we had a working E4S stack with something like", "tokens": [2295, 12, 12418, 9834, 294, 264, 8630, 13, 407, 321, 632, 257, 1364, 462, 19, 50, 8630, 365, 746, 411], "temperature": 0.0, "avg_logprob": -0.15767738882419283, "compression_ratio": 1.649056603773585, "no_speech_prob": 2.7963715183432214e-05}, {"id": 159, "seek": 80860, "start": 821.2, "end": 829.6, "text": " 6 or 700 packages building. We wanted to get better testing for one API because that's", "tokens": [1386, 420, 15204, 17401, 2390, 13, 492, 1415, 281, 483, 1101, 4997, 337, 472, 9362, 570, 300, 311], "temperature": 0.0, "avg_logprob": -0.15767738882419283, "compression_ratio": 1.649056603773585, "no_speech_prob": 2.7963715183432214e-05}, {"id": 160, "seek": 80860, "start": 829.6, "end": 833.96, "text": " what they're going to use on Aurora. And so we wanted to use the one API compilers.", "tokens": [437, 436, 434, 516, 281, 764, 322, 40663, 13, 400, 370, 321, 1415, 281, 764, 264, 472, 9362, 715, 388, 433, 13], "temperature": 0.0, "avg_logprob": -0.15767738882419283, "compression_ratio": 1.649056603773585, "no_speech_prob": 2.7963715183432214e-05}, {"id": 161, "seek": 80860, "start": 833.96, "end": 837.76, "text": " We added some compiler config and we said everything should use one API. And then, you know, at", "tokens": [492, 3869, 512, 31958, 6662, 293, 321, 848, 1203, 820, 764, 472, 9362, 13, 400, 550, 11, 291, 458, 11, 412], "temperature": 0.0, "avg_logprob": -0.15767738882419283, "compression_ratio": 1.649056603773585, "no_speech_prob": 2.7963715183432214e-05}, {"id": 162, "seek": 83776, "start": 837.76, "end": 842.92, "text": " the very least we got a pipeline generated with some errors for one API. And it made", "tokens": [264, 588, 1935, 321, 658, 257, 15517, 10833, 365, 512, 13603, 337, 472, 9362, 13, 400, 309, 1027], "temperature": 0.0, "avg_logprob": -0.12189894456129807, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.218615529476665e-05}, {"id": 163, "seek": 83776, "start": 842.92, "end": 847.24, "text": " it really easy to iterate on this with Intel where we would basically say, okay, this package", "tokens": [309, 534, 1858, 281, 44497, 322, 341, 365, 19762, 689, 321, 576, 1936, 584, 11, 1392, 11, 341, 7372], "temperature": 0.0, "avg_logprob": -0.12189894456129807, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.218615529476665e-05}, {"id": 164, "seek": 83776, "start": 847.24, "end": 850.68, "text": " is broken. Here's the bug. Go fix it. And then it would come back with another version", "tokens": [307, 5463, 13, 1692, 311, 264, 7426, 13, 1037, 3191, 309, 13, 400, 550, 309, 576, 808, 646, 365, 1071, 3037], "temperature": 0.0, "avg_logprob": -0.12189894456129807, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.218615529476665e-05}, {"id": 165, "seek": 83776, "start": 850.68, "end": 855.48, "text": " of one API and we would iterate with them until it was done. I think this is probably", "tokens": [295, 472, 9362, 293, 321, 576, 44497, 365, 552, 1826, 309, 390, 1096, 13, 286, 519, 341, 307, 1391], "temperature": 0.0, "avg_logprob": -0.12189894456129807, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.218615529476665e-05}, {"id": 166, "seek": 83776, "start": 855.48, "end": 861.64, "text": " more open-source than anyone has recently run through a vendor compiler. And so just being", "tokens": [544, 1269, 12, 41676, 813, 2878, 575, 3938, 1190, 807, 257, 24321, 31958, 13, 400, 370, 445, 885], "temperature": 0.0, "avg_logprob": -0.12189894456129807, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.218615529476665e-05}, {"id": 167, "seek": 83776, "start": 861.64, "end": 866.24, "text": " able to do this, I think, is big because it might make those compilers like actually viable", "tokens": [1075, 281, 360, 341, 11, 286, 519, 11, 307, 955, 570, 309, 1062, 652, 729, 715, 388, 433, 411, 767, 22024], "temperature": 0.0, "avg_logprob": -0.12189894456129807, "compression_ratio": 1.7115384615384615, "no_speech_prob": 3.218615529476665e-05}, {"id": 168, "seek": 86624, "start": 866.24, "end": 871.0, "text": " things to use for real programs that have lots of dependencies. At the moment, you", "tokens": [721, 281, 764, 337, 957, 4268, 300, 362, 3195, 295, 36606, 13, 1711, 264, 1623, 11, 291], "temperature": 0.0, "avg_logprob": -0.17088721348689154, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.6181065802811645e-05}, {"id": 169, "seek": 86624, "start": 871.0, "end": 874.04, "text": " know, you have to sort of piece your program together and build parts of it with like,", "tokens": [458, 11, 291, 362, 281, 1333, 295, 2522, 428, 1461, 1214, 293, 1322, 3166, 295, 309, 365, 411, 11], "temperature": 0.0, "avg_logprob": -0.17088721348689154, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.6181065802811645e-05}, {"id": 170, "seek": 86624, "start": 874.04, "end": 878.88, "text": " I don't know, PGI was the infamous one that broke on everything. But, you know, I think", "tokens": [286, 500, 380, 458, 11, 430, 26252, 390, 264, 30769, 472, 300, 6902, 322, 1203, 13, 583, 11, 291, 458, 11, 286, 519], "temperature": 0.0, "avg_logprob": -0.17088721348689154, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.6181065802811645e-05}, {"id": 171, "seek": 86624, "start": 878.88, "end": 883.12, "text": " this could help with the vendor compiler being a viable second option and, you know, maybe", "tokens": [341, 727, 854, 365, 264, 24321, 31958, 885, 257, 22024, 1150, 3614, 293, 11, 291, 458, 11, 1310], "temperature": 0.0, "avg_logprob": -0.17088721348689154, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.6181065802811645e-05}, {"id": 172, "seek": 86624, "start": 883.12, "end": 886.88, "text": " instill some competition among the vendors because they can do this frequently and show,", "tokens": [1058, 373, 512, 6211, 3654, 264, 22056, 570, 436, 393, 360, 341, 10374, 293, 855, 11], "temperature": 0.0, "avg_logprob": -0.17088721348689154, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.6181065802811645e-05}, {"id": 173, "seek": 86624, "start": 886.88, "end": 894.08, "text": " you know, benchmarks against these packages. So this was, I think, a win. Yeah, thank you.", "tokens": [291, 458, 11, 43751, 1970, 613, 17401, 13, 407, 341, 390, 11, 286, 519, 11, 257, 1942, 13, 865, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.17088721348689154, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.6181065802811645e-05}, {"id": 174, "seek": 89408, "start": 894.08, "end": 899.2, "text": " Each of those stacks gets concretized. And so people know, in SPAC, you take that abstract", "tokens": [6947, 295, 729, 30792, 2170, 39481, 1602, 13, 400, 370, 561, 458, 11, 294, 8420, 4378, 11, 291, 747, 300, 12649], "temperature": 0.0, "avg_logprob": -0.11648404781634991, "compression_ratio": 1.7022653721682848, "no_speech_prob": 2.5861589165288024e-05}, {"id": 175, "seek": 89408, "start": 899.2, "end": 902.76, "text": " description of the things that you want to install, which is basically the requirements.", "tokens": [3855, 295, 264, 721, 300, 291, 528, 281, 3625, 11, 597, 307, 1936, 264, 7728, 13], "temperature": 0.0, "avg_logprob": -0.11648404781634991, "compression_ratio": 1.7022653721682848, "no_speech_prob": 2.5861589165288024e-05}, {"id": 176, "seek": 89408, "start": 902.76, "end": 907.0400000000001, "text": " You run it through our dependency solver. You get, essentially, a concrete description", "tokens": [509, 1190, 309, 807, 527, 33621, 1404, 331, 13, 509, 483, 11, 4476, 11, 257, 9859, 3855], "temperature": 0.0, "avg_logprob": -0.11648404781634991, "compression_ratio": 1.7022653721682848, "no_speech_prob": 2.5861589165288024e-05}, {"id": 177, "seek": 89408, "start": 907.0400000000001, "end": 912.5200000000001, "text": " of what you're going to build, which is the whole concrete graph. And then we generate", "tokens": [295, 437, 291, 434, 516, 281, 1322, 11, 597, 307, 264, 1379, 9859, 4295, 13, 400, 550, 321, 8460], "temperature": 0.0, "avg_logprob": -0.11648404781634991, "compression_ratio": 1.7022653721682848, "no_speech_prob": 2.5861589165288024e-05}, {"id": 178, "seek": 89408, "start": 912.5200000000001, "end": 917.0, "text": " a GitLab CI YAML from that that describes the jobs that need to be run to build the", "tokens": [257, 16939, 37880, 37777, 398, 2865, 43, 490, 300, 300, 15626, 264, 4782, 300, 643, 281, 312, 1190, 281, 1322, 264], "temperature": 0.0, "avg_logprob": -0.11648404781634991, "compression_ratio": 1.7022653721682848, "no_speech_prob": 2.5861589165288024e-05}, {"id": 179, "seek": 89408, "start": 917.0, "end": 920.84, "text": " whole thing. This is the part that we could swap out for something else. So, like, we've", "tokens": [1379, 551, 13, 639, 307, 264, 644, 300, 321, 727, 18135, 484, 337, 746, 1646, 13, 407, 11, 411, 11, 321, 600], "temperature": 0.0, "avg_logprob": -0.11648404781634991, "compression_ratio": 1.7022653721682848, "no_speech_prob": 2.5861589165288024e-05}, {"id": 180, "seek": 92084, "start": 920.84, "end": 924.96, "text": " looked at, like, Tecton pipelines. We've looked at other options. I don't know, some", "tokens": [2956, 412, 11, 411, 11, 314, 557, 266, 40168, 13, 492, 600, 2956, 412, 661, 3956, 13, 286, 500, 380, 458, 11, 512], "temperature": 0.0, "avg_logprob": -0.13757806810839424, "compression_ratio": 1.6185185185185185, "no_speech_prob": 1.496890308771981e-05}, {"id": 181, "seek": 92084, "start": 924.96, "end": 929.0400000000001, "text": " people use Jenkins. There's all sorts of things out there that you could potentially map the", "tokens": [561, 764, 41273, 13, 821, 311, 439, 7527, 295, 721, 484, 456, 300, 291, 727, 7263, 4471, 264], "temperature": 0.0, "avg_logprob": -0.13757806810839424, "compression_ratio": 1.6185185185185185, "no_speech_prob": 1.496890308771981e-05}, {"id": 182, "seek": 92084, "start": 929.0400000000001, "end": 933.9200000000001, "text": " jobs to. And I think we could generate a description like that from the representation", "tokens": [4782, 281, 13, 400, 286, 519, 321, 727, 8460, 257, 3855, 411, 300, 490, 264, 10290], "temperature": 0.0, "avg_logprob": -0.13757806810839424, "compression_ratio": 1.6185185185185185, "no_speech_prob": 1.496890308771981e-05}, {"id": 183, "seek": 92084, "start": 933.9200000000001, "end": 943.0400000000001, "text": " that we have. For mapping those jobs, we have a section in the CI YAML right now, or in", "tokens": [300, 321, 362, 13, 1171, 18350, 729, 4782, 11, 321, 362, 257, 3541, 294, 264, 37777, 398, 2865, 43, 558, 586, 11, 420, 294], "temperature": 0.0, "avg_logprob": -0.13757806810839424, "compression_ratio": 1.6185185185185185, "no_speech_prob": 1.496890308771981e-05}, {"id": 184, "seek": 92084, "start": 943.0400000000001, "end": 950.2800000000001, "text": " the SPAC.YAML, that basically tells you how to generate the GitLab piece. And so you", "tokens": [264, 8420, 4378, 13, 56, 2865, 43, 11, 300, 1936, 5112, 291, 577, 281, 8460, 264, 16939, 37880, 2522, 13, 400, 370, 291], "temperature": 0.0, "avg_logprob": -0.13757806810839424, "compression_ratio": 1.6185185185185185, "no_speech_prob": 1.496890308771981e-05}, {"id": 185, "seek": 95028, "start": 950.28, "end": 956.3199999999999, "text": " see this mapping section here. There's a match section. If you match any of those specs there,", "tokens": [536, 341, 18350, 3541, 510, 13, 821, 311, 257, 2995, 3541, 13, 759, 291, 2995, 604, 295, 729, 27911, 456, 11], "temperature": 0.0, "avg_logprob": -0.15177031694832493, "compression_ratio": 1.6691176470588236, "no_speech_prob": 7.068024842737941e-06}, {"id": 186, "seek": 95028, "start": 956.3199999999999, "end": 961.0, "text": " and the first three are just a couple, just some names, then we have special tags that", "tokens": [293, 264, 700, 1045, 366, 445, 257, 1916, 11, 445, 512, 5288, 11, 550, 321, 362, 2121, 18632, 300], "temperature": 0.0, "avg_logprob": -0.15177031694832493, "compression_ratio": 1.6691176470588236, "no_speech_prob": 7.068024842737941e-06}, {"id": 187, "seek": 95028, "start": 961.0, "end": 964.8399999999999, "text": " we put on the runners that say, you know, get me a special resource for these things.", "tokens": [321, 829, 322, 264, 33892, 300, 584, 11, 291, 458, 11, 483, 385, 257, 2121, 7684, 337, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.15177031694832493, "compression_ratio": 1.6691176470588236, "no_speech_prob": 7.068024842737941e-06}, {"id": 188, "seek": 95028, "start": 964.8399999999999, "end": 970.48, "text": " And so that first block is basically so that I don't run out of memory building LLVM TensorFlow", "tokens": [400, 370, 300, 700, 3461, 307, 1936, 370, 300, 286, 500, 380, 1190, 484, 295, 4675, 2390, 441, 43, 53, 44, 37624], "temperature": 0.0, "avg_logprob": -0.15177031694832493, "compression_ratio": 1.6691176470588236, "no_speech_prob": 7.068024842737941e-06}, {"id": 189, "seek": 95028, "start": 970.48, "end": 976.04, "text": " or Torch, get me something with a lot of memory and a big CPU to build that one. It has to", "tokens": [420, 7160, 339, 11, 483, 385, 746, 365, 257, 688, 295, 4675, 293, 257, 955, 13199, 281, 1322, 300, 472, 13, 467, 575, 281], "temperature": 0.0, "avg_logprob": -0.15177031694832493, "compression_ratio": 1.6691176470588236, "no_speech_prob": 7.068024842737941e-06}, {"id": 190, "seek": 97604, "start": 976.04, "end": 981.4399999999999, "text": " run on a big instance, because those are sort of the long poles in our tent in CI. And then", "tokens": [1190, 322, 257, 955, 5197, 11, 570, 729, 366, 1333, 295, 264, 938, 24760, 294, 527, 7054, 294, 37777, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.19276451278518844, "compression_ratio": 1.5358649789029535, "no_speech_prob": 9.366672202304471e-06}, {"id": 191, "seek": 97604, "start": 981.4399999999999, "end": 985.9599999999999, "text": " down at the bottom, there's just a mapping from everything else gets something that supports", "tokens": [760, 412, 264, 2767, 11, 456, 311, 445, 257, 18350, 490, 1203, 1646, 2170, 746, 300, 9346], "temperature": 0.0, "avg_logprob": -0.19276451278518844, "compression_ratio": 1.5358649789029535, "no_speech_prob": 9.366672202304471e-06}, {"id": 192, "seek": 97604, "start": 985.9599999999999, "end": 993.5999999999999, "text": " X8664, V4, and it's a little smaller than the other one for builds. And you could do", "tokens": [1783, 22193, 19395, 11, 691, 19, 11, 293, 309, 311, 257, 707, 4356, 813, 264, 661, 472, 337, 15182, 13, 400, 291, 727, 360], "temperature": 0.0, "avg_logprob": -0.19276451278518844, "compression_ratio": 1.5358649789029535, "no_speech_prob": 9.366672202304471e-06}, {"id": 193, "seek": 97604, "start": 993.5999999999999, "end": 998.56, "text": " this for lots of different architecture combinations and so on. And you can ask for images and", "tokens": [341, 337, 3195, 295, 819, 9482, 21267, 293, 370, 322, 13, 400, 291, 393, 1029, 337, 5267, 293], "temperature": 0.0, "avg_logprob": -0.19276451278518844, "compression_ratio": 1.5358649789029535, "no_speech_prob": 9.366672202304471e-06}, {"id": 194, "seek": 99856, "start": 998.56, "end": 1007.1199999999999, "text": " things like that. I said that we needed to ensure that the source is, or that the binaries", "tokens": [721, 411, 300, 13, 286, 848, 300, 321, 2978, 281, 5586, 300, 264, 4009, 307, 11, 420, 300, 264, 5171, 4889], "temperature": 0.0, "avg_logprob": -0.10291206327259031, "compression_ratio": 1.812, "no_speech_prob": 6.746454801032087e-06}, {"id": 195, "seek": 99856, "start": 1007.1199999999999, "end": 1011.3599999999999, "text": " are as reliable as the source. And so we sat down and we asked ourselves, you know, what", "tokens": [366, 382, 12924, 382, 264, 4009, 13, 400, 370, 321, 3227, 760, 293, 321, 2351, 4175, 11, 291, 458, 11, 437], "temperature": 0.0, "avg_logprob": -0.10291206327259031, "compression_ratio": 1.812, "no_speech_prob": 6.746454801032087e-06}, {"id": 196, "seek": 99856, "start": 1011.3599999999999, "end": 1016.1999999999999, "text": " is it that people trust about the SPAC project? And it's really the maintainers. If you use", "tokens": [307, 309, 300, 561, 3361, 466, 264, 8420, 4378, 1716, 30, 400, 309, 311, 534, 264, 6909, 433, 13, 759, 291, 764], "temperature": 0.0, "avg_logprob": -0.10291206327259031, "compression_ratio": 1.812, "no_speech_prob": 6.746454801032087e-06}, {"id": 197, "seek": 99856, "start": 1016.1999999999999, "end": 1020.64, "text": " any open source project, you're trusting the maintainers, or you really shouldn't be using", "tokens": [604, 1269, 4009, 1716, 11, 291, 434, 28235, 264, 6909, 433, 11, 420, 291, 534, 4659, 380, 312, 1228], "temperature": 0.0, "avg_logprob": -0.10291206327259031, "compression_ratio": 1.812, "no_speech_prob": 6.746454801032087e-06}, {"id": 198, "seek": 99856, "start": 1020.64, "end": 1025.48, "text": " that open source project. And so I don't see where we can do better than that. And so what", "tokens": [300, 1269, 4009, 1716, 13, 400, 370, 286, 500, 380, 536, 689, 321, 393, 360, 1101, 813, 300, 13, 400, 370, 437], "temperature": 0.0, "avg_logprob": -0.10291206327259031, "compression_ratio": 1.812, "no_speech_prob": 6.746454801032087e-06}, {"id": 199, "seek": 102548, "start": 1025.48, "end": 1031.84, "text": " we've done is we've said the place where bad things could get into a build, at least from", "tokens": [321, 600, 1096, 307, 321, 600, 848, 264, 1081, 689, 1578, 721, 727, 483, 666, 257, 1322, 11, 412, 1935, 490], "temperature": 0.0, "avg_logprob": -0.12557436072308084, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.611222382460255e-06}, {"id": 200, "seek": 102548, "start": 1031.84, "end": 1037.32, "text": " SPAC, is in the build environment. And so if you give people control of the PR environment", "tokens": [8420, 4378, 11, 307, 294, 264, 1322, 2823, 13, 400, 370, 498, 291, 976, 561, 1969, 295, 264, 11568, 2823], "temperature": 0.0, "avg_logprob": -0.12557436072308084, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.611222382460255e-06}, {"id": 201, "seek": 102548, "start": 1037.32, "end": 1041.64, "text": " where they're submitting things there, they could push a commit that puts something in", "tokens": [689, 436, 434, 31836, 721, 456, 11, 436, 727, 2944, 257, 5599, 300, 8137, 746, 294], "temperature": 0.0, "avg_logprob": -0.12557436072308084, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.611222382460255e-06}, {"id": 202, "seek": 102548, "start": 1041.64, "end": 1047.0, "text": " a binary that gets cached. And then, you know, somehow, I don't know, they could do bad things", "tokens": [257, 17434, 300, 2170, 269, 15095, 13, 400, 550, 11, 291, 458, 11, 6063, 11, 286, 500, 380, 458, 11, 436, 727, 360, 1578, 721], "temperature": 0.0, "avg_logprob": -0.12557436072308084, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.611222382460255e-06}, {"id": 203, "seek": 102548, "start": 1047.0, "end": 1050.96, "text": " and end up caching a binary. And if we took that binary and stuck it out there for anyone", "tokens": [293, 917, 493, 269, 2834, 257, 17434, 13, 400, 498, 321, 1890, 300, 17434, 293, 5541, 309, 484, 456, 337, 2878], "temperature": 0.0, "avg_logprob": -0.12557436072308084, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.611222382460255e-06}, {"id": 204, "seek": 105096, "start": 1050.96, "end": 1057.16, "text": " to use, you know, there could be bad things in it. And so we have this separate set of", "tokens": [281, 764, 11, 291, 458, 11, 456, 727, 312, 1578, 721, 294, 309, 13, 400, 370, 321, 362, 341, 4994, 992, 295], "temperature": 0.0, "avg_logprob": -0.1181592515536717, "compression_ratio": 1.6539923954372624, "no_speech_prob": 1.7775442756828852e-05}, {"id": 205, "seek": 105096, "start": 1057.16, "end": 1063.52, "text": " untrusted S3 buckets where we only build PR things. Each PR gets its own build cache.", "tokens": [1701, 81, 6589, 318, 18, 32191, 689, 321, 787, 1322, 11568, 721, 13, 6947, 11568, 2170, 1080, 1065, 1322, 19459, 13], "temperature": 0.0, "avg_logprob": -0.1181592515536717, "compression_ratio": 1.6539923954372624, "no_speech_prob": 1.7775442756828852e-05}, {"id": 206, "seek": 105096, "start": 1063.52, "end": 1067.16, "text": " That enables the maintainers to see if things work. And then they come along and review", "tokens": [663, 17077, 264, 6909, 433, 281, 536, 498, 721, 589, 13, 400, 550, 436, 808, 2051, 293, 3131], "temperature": 0.0, "avg_logprob": -0.1181592515536717, "compression_ratio": 1.6539923954372624, "no_speech_prob": 1.7775442756828852e-05}, {"id": 207, "seek": 105096, "start": 1067.16, "end": 1071.8400000000001, "text": " the code. And then once things are actually merged to develop, we don't trust any of the", "tokens": [264, 3089, 13, 400, 550, 1564, 721, 366, 767, 36427, 281, 1499, 11, 321, 500, 380, 3361, 604, 295, 264], "temperature": 0.0, "avg_logprob": -0.1181592515536717, "compression_ratio": 1.6539923954372624, "no_speech_prob": 1.7775442756828852e-05}, {"id": 208, "seek": 105096, "start": 1071.8400000000001, "end": 1076.04, "text": " binaries that we built on PRs. And we go and rebuild everything in sign, specifically", "tokens": [5171, 4889, 300, 321, 3094, 322, 11568, 82, 13, 400, 321, 352, 293, 16877, 1203, 294, 1465, 11, 4682], "temperature": 0.0, "avg_logprob": -0.1181592515536717, "compression_ratio": 1.6539923954372624, "no_speech_prob": 1.7775442756828852e-05}, {"id": 209, "seek": 107604, "start": 1076.04, "end": 1082.04, "text": " from the, you know, the sources that got approved, just, you know, so that we know that we didn't", "tokens": [490, 264, 11, 291, 458, 11, 264, 7139, 300, 658, 10826, 11, 445, 11, 291, 458, 11, 370, 300, 321, 458, 300, 321, 994, 380], "temperature": 0.0, "avg_logprob": -0.1571009141685319, "compression_ratio": 1.9027777777777777, "no_speech_prob": 3.6678745800600154e-06}, {"id": 210, "seek": 107604, "start": 1082.04, "end": 1085.48, "text": " cache anything from that environment. So that's where the development and release caches are", "tokens": [19459, 1340, 490, 300, 2823, 13, 407, 300, 311, 689, 264, 3250, 293, 4374, 269, 13272, 366], "temperature": 0.0, "avg_logprob": -0.1571009141685319, "compression_ratio": 1.9027777777777777, "no_speech_prob": 3.6678745800600154e-06}, {"id": 211, "seek": 107604, "start": 1085.48, "end": 1091.24, "text": " coming from, where they're entirely separate from the PR environment. And the signature", "tokens": [1348, 490, 11, 689, 436, 434, 7696, 4994, 490, 264, 11568, 2823, 13, 400, 264, 13397], "temperature": 0.0, "avg_logprob": -0.1571009141685319, "compression_ratio": 1.9027777777777777, "no_speech_prob": 3.6678745800600154e-06}, {"id": 212, "seek": 107604, "start": 1091.24, "end": 1094.92, "text": " here is, you know, it's ephemeral. They have, like, a signing key locked up somewhere in", "tokens": [510, 307, 11, 291, 458, 11, 309, 311, 308, 41245, 2790, 13, 814, 362, 11, 411, 11, 257, 13393, 2141, 9376, 493, 4079, 294], "temperature": 0.0, "avg_logprob": -0.1571009141685319, "compression_ratio": 1.9027777777777777, "no_speech_prob": 3.6678745800600154e-06}, {"id": 213, "seek": 107604, "start": 1094.92, "end": 1099.3999999999999, "text": " a secret server. And we generate, you know, we have subkeys and then we generate ephemeral", "tokens": [257, 4054, 7154, 13, 400, 321, 8460, 11, 291, 458, 11, 321, 362, 1422, 18847, 293, 550, 321, 8460, 308, 41245, 2790], "temperature": 0.0, "avg_logprob": -0.1571009141685319, "compression_ratio": 1.9027777777777777, "no_speech_prob": 3.6678745800600154e-06}, {"id": 214, "seek": 107604, "start": 1099.3999999999999, "end": 1104.76, "text": " keys for the signing in the pipelines. So whatever it is that you got signed with doesn't", "tokens": [9317, 337, 264, 13393, 294, 264, 40168, 13, 407, 2035, 309, 307, 300, 291, 658, 8175, 365, 1177, 380], "temperature": 0.0, "avg_logprob": -0.1571009141685319, "compression_ratio": 1.9027777777777777, "no_speech_prob": 3.6678745800600154e-06}, {"id": 215, "seek": 110476, "start": 1104.76, "end": 1108.8, "text": " actually exist anymore by the time the user consumes the binary. We could look at sick", "tokens": [767, 2514, 3602, 538, 264, 565, 264, 4195, 48823, 264, 17434, 13, 492, 727, 574, 412, 4998], "temperature": 0.0, "avg_logprob": -0.13053558069631593, "compression_ratio": 1.5842293906810037, "no_speech_prob": 2.668335218913853e-05}, {"id": 216, "seek": 110476, "start": 1108.8, "end": 1112.64, "text": " store for this. It wasn't quite ready for arbitrary binary signing when we did this.", "tokens": [3531, 337, 341, 13, 467, 2067, 380, 1596, 1919, 337, 23211, 17434, 13393, 562, 321, 630, 341, 13], "temperature": 0.0, "avg_logprob": -0.13053558069631593, "compression_ratio": 1.5842293906810037, "no_speech_prob": 2.668335218913853e-05}, {"id": 217, "seek": 110476, "start": 1112.64, "end": 1119.92, "text": " But that's an option to reduce some of the custom GPG stuff we had to do here. So the", "tokens": [583, 300, 311, 364, 3614, 281, 5407, 512, 295, 264, 2375, 26039, 38, 1507, 321, 632, 281, 360, 510, 13, 407, 264], "temperature": 0.0, "avg_logprob": -0.13053558069631593, "compression_ratio": 1.5842293906810037, "no_speech_prob": 2.668335218913853e-05}, {"id": 218, "seek": 110476, "start": 1119.92, "end": 1125.36, "text": " pull request integration, I think, makes it easy for at least for most of the contributors.", "tokens": [2235, 5308, 10980, 11, 286, 519, 11, 1669, 309, 1858, 337, 412, 1935, 337, 881, 295, 264, 45627, 13], "temperature": 0.0, "avg_logprob": -0.13053558069631593, "compression_ratio": 1.5842293906810037, "no_speech_prob": 2.668335218913853e-05}, {"id": 219, "seek": 110476, "start": 1125.36, "end": 1130.56, "text": " They get status updates on PRs. And it's fairly easy for users because they can just add one", "tokens": [814, 483, 6558, 9205, 322, 11568, 82, 13, 400, 309, 311, 6457, 1858, 337, 5022, 570, 436, 393, 445, 909, 472], "temperature": 0.0, "avg_logprob": -0.13053558069631593, "compression_ratio": 1.5842293906810037, "no_speech_prob": 2.668335218913853e-05}, {"id": 220, "seek": 113056, "start": 1130.56, "end": 1134.6799999999998, "text": " of these binary mirrors and then start using the build cache. And I'm not going to get", "tokens": [295, 613, 17434, 24238, 293, 550, 722, 1228, 264, 1322, 19459, 13, 400, 286, 478, 406, 516, 281, 483], "temperature": 0.0, "avg_logprob": -0.1468358533135776, "compression_ratio": 1.647940074906367, "no_speech_prob": 1.6438960301456973e-05}, {"id": 221, "seek": 113056, "start": 1134.6799999999998, "end": 1141.3999999999999, "text": " into the details here, but in SPAC, for a very long time, it was easy to get a lot of", "tokens": [666, 264, 4365, 510, 11, 457, 294, 8420, 4378, 11, 337, 257, 588, 938, 565, 11, 309, 390, 1858, 281, 483, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.1468358533135776, "compression_ratio": 1.647940074906367, "no_speech_prob": 1.6438960301456973e-05}, {"id": 222, "seek": 113056, "start": 1141.3999999999999, "end": 1145.6, "text": " cache misses, like we would just look up hashes. And I have another presentation about our", "tokens": [19459, 29394, 11, 411, 321, 576, 445, 574, 493, 575, 8076, 13, 400, 286, 362, 1071, 5860, 466, 527], "temperature": 0.0, "avg_logprob": -0.1468358533135776, "compression_ratio": 1.647940074906367, "no_speech_prob": 1.6438960301456973e-05}, {"id": 223, "seek": 113056, "start": 1145.6, "end": 1150.1599999999999, "text": " reusing Concretizer. The summary is, if you add one of these build caches and you have", "tokens": [319, 7981, 18200, 1505, 6545, 13, 440, 12691, 307, 11, 498, 291, 909, 472, 295, 613, 1322, 269, 13272, 293, 291, 362], "temperature": 0.0, "avg_logprob": -0.1468358533135776, "compression_ratio": 1.647940074906367, "no_speech_prob": 1.6438960301456973e-05}, {"id": 224, "seek": 113056, "start": 1150.1599999999999, "end": 1155.2, "text": " those binaries available, SPAC will prefer to use them. And so before it tries to rebuild", "tokens": [729, 5171, 4889, 2435, 11, 8420, 4378, 486, 4382, 281, 764, 552, 13, 400, 370, 949, 309, 9898, 281, 16877], "temperature": 0.0, "avg_logprob": -0.1468358533135776, "compression_ratio": 1.647940074906367, "no_speech_prob": 1.6438960301456973e-05}, {"id": 225, "seek": 115520, "start": 1155.2, "end": 1161.68, "text": " something. And so with the reusing Concretizer, this is actually quite powerful. And so, yeah,", "tokens": [746, 13, 400, 370, 365, 264, 319, 7981, 18200, 1505, 6545, 11, 341, 307, 767, 1596, 4005, 13, 400, 370, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.1486527626974541, "compression_ratio": 1.6014492753623188, "no_speech_prob": 8.66324444359634e-06}, {"id": 226, "seek": 115520, "start": 1161.68, "end": 1169.3600000000001, "text": " what could go wrong? Well, there is a burden to doing this. And a build cache distribution", "tokens": [437, 727, 352, 2085, 30, 1042, 11, 456, 307, 257, 12578, 281, 884, 341, 13, 400, 257, 1322, 19459, 7316], "temperature": 0.0, "avg_logprob": -0.1486527626974541, "compression_ratio": 1.6014492753623188, "no_speech_prob": 8.66324444359634e-06}, {"id": 227, "seek": 115520, "start": 1169.3600000000001, "end": 1174.72, "text": " like SPACnix or Geeks is different from an RPM distribution because every node has a", "tokens": [411, 8420, 4378, 77, 970, 420, 2876, 24785, 307, 819, 490, 364, 37389, 7316, 570, 633, 9984, 575, 257], "temperature": 0.0, "avg_logprob": -0.1486527626974541, "compression_ratio": 1.6014492753623188, "no_speech_prob": 8.66324444359634e-06}, {"id": 228, "seek": 115520, "start": 1174.72, "end": 1178.28, "text": " hash. And the deployment model is really that you have to deploy with what you built", "tokens": [22019, 13, 400, 264, 19317, 2316, 307, 534, 300, 291, 362, 281, 7274, 365, 437, 291, 3094], "temperature": 0.0, "avg_logprob": -0.1486527626974541, "compression_ratio": 1.6014492753623188, "no_speech_prob": 8.66324444359634e-06}, {"id": 229, "seek": 115520, "start": 1178.28, "end": 1183.48, "text": " with. And so you can't just swap in a new version of Zlib in a stack. If something has", "tokens": [365, 13, 400, 370, 291, 393, 380, 445, 18135, 294, 257, 777, 3037, 295, 1176, 38270, 294, 257, 8630, 13, 759, 746, 575], "temperature": 0.0, "avg_logprob": -0.1486527626974541, "compression_ratio": 1.6014492753623188, "no_speech_prob": 8.66324444359634e-06}, {"id": 230, "seek": 118348, "start": 1183.48, "end": 1186.8, "text": " a particular hash, that implies all of its dependencies' hashes. And so you need to", "tokens": [257, 1729, 22019, 11, 300, 18779, 439, 295, 1080, 36606, 6, 575, 8076, 13, 400, 370, 291, 643, 281], "temperature": 0.0, "avg_logprob": -0.1405449458530971, "compression_ratio": 1.7751677852348993, "no_speech_prob": 5.14179773745127e-05}, {"id": 231, "seek": 118348, "start": 1186.8, "end": 1192.2, "text": " deploy the build cache with everything that it was built with. So if, for example, you", "tokens": [7274, 264, 1322, 19459, 365, 1203, 300, 309, 390, 3094, 365, 13, 407, 498, 11, 337, 1365, 11, 291], "temperature": 0.0, "avg_logprob": -0.1405449458530971, "compression_ratio": 1.7751677852348993, "no_speech_prob": 5.14179773745127e-05}, {"id": 232, "seek": 118348, "start": 1192.2, "end": 1199.16, "text": " modify XZ, right? Yep. And then you're going to need to rebuild all of these things, too.", "tokens": [16927, 1783, 57, 11, 558, 30, 7010, 13, 400, 550, 291, 434, 516, 281, 643, 281, 16877, 439, 295, 613, 721, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.1405449458530971, "compression_ratio": 1.7751677852348993, "no_speech_prob": 5.14179773745127e-05}, {"id": 233, "seek": 118348, "start": 1199.16, "end": 1202.2, "text": " And you're going to need to do that all the way up to the roots of your environment every", "tokens": [400, 291, 434, 516, 281, 643, 281, 360, 300, 439, 264, 636, 493, 281, 264, 10669, 295, 428, 2823, 633], "temperature": 0.0, "avg_logprob": -0.1405449458530971, "compression_ratio": 1.7751677852348993, "no_speech_prob": 5.14179773745127e-05}, {"id": 234, "seek": 118348, "start": 1202.2, "end": 1207.16, "text": " once in a while so that there's a consistent build cache for people to deploy. And that", "tokens": [1564, 294, 257, 1339, 370, 300, 456, 311, 257, 8398, 1322, 19459, 337, 561, 281, 7274, 13, 400, 300], "temperature": 0.0, "avg_logprob": -0.1405449458530971, "compression_ratio": 1.7751677852348993, "no_speech_prob": 5.14179773745127e-05}, {"id": 235, "seek": 118348, "start": 1207.16, "end": 1211.72, "text": " can be bad if your stack is this big. This is E4S, right? And someone comes in and submits", "tokens": [393, 312, 1578, 498, 428, 8630, 307, 341, 955, 13, 639, 307, 462, 19, 50, 11, 558, 30, 400, 1580, 1487, 294, 293, 8286, 1208], "temperature": 0.0, "avg_logprob": -0.1405449458530971, "compression_ratio": 1.7751677852348993, "no_speech_prob": 5.14179773745127e-05}, {"id": 236, "seek": 121172, "start": 1211.72, "end": 1217.56, "text": " a PR, which you can do, by the way, that, you know, modifies package comp. And then", "tokens": [257, 11568, 11, 597, 291, 393, 360, 11, 538, 264, 636, 11, 300, 11, 291, 458, 11, 1072, 11221, 7372, 715, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.14350467708939357, "compression_ratio": 1.7012987012987013, "no_speech_prob": 4.8312263970728964e-05}, {"id": 237, "seek": 121172, "start": 1217.56, "end": 1222.08, "text": " all of a sudden, you know, this is what happens to your CI system, right? Your whole graph", "tokens": [439, 295, 257, 3990, 11, 291, 458, 11, 341, 307, 437, 2314, 281, 428, 37777, 1185, 11, 558, 30, 2260, 1379, 4295], "temperature": 0.0, "avg_logprob": -0.14350467708939357, "compression_ratio": 1.7012987012987013, "no_speech_prob": 4.8312263970728964e-05}, {"id": 238, "seek": 121172, "start": 1222.08, "end": 1226.64, "text": " is rebuilding again. And it can take a long time for develop to catch up with a change", "tokens": [307, 36717, 797, 13, 400, 309, 393, 747, 257, 938, 565, 337, 1499, 281, 3745, 493, 365, 257, 1319], "temperature": 0.0, "avg_logprob": -0.14350467708939357, "compression_ratio": 1.7012987012987013, "no_speech_prob": 4.8312263970728964e-05}, {"id": 239, "seek": 121172, "start": 1226.64, "end": 1232.24, "text": " like this. And right now we are rebuilding all that stuff on PRs. So your pipelines can", "tokens": [411, 341, 13, 400, 558, 586, 321, 366, 36717, 439, 300, 1507, 322, 11568, 82, 13, 407, 428, 40168, 393], "temperature": 0.0, "avg_logprob": -0.14350467708939357, "compression_ratio": 1.7012987012987013, "no_speech_prob": 4.8312263970728964e-05}, {"id": 240, "seek": 121172, "start": 1232.24, "end": 1236.16, "text": " get long. You dig in there and you see that, like, visit is still building. And you're", "tokens": [483, 938, 13, 509, 2528, 294, 456, 293, 291, 536, 300, 11, 411, 11, 3441, 307, 920, 2390, 13, 400, 291, 434], "temperature": 0.0, "avg_logprob": -0.14350467708939357, "compression_ratio": 1.7012987012987013, "no_speech_prob": 4.8312263970728964e-05}, {"id": 241, "seek": 121172, "start": 1236.16, "end": 1240.76, "text": " like, this is the fifth time I've built visit today. I think Harman once commented that", "tokens": [411, 11, 341, 307, 264, 9266, 565, 286, 600, 3094, 3441, 965, 13, 286, 519, 3653, 1601, 1564, 26940, 300], "temperature": 0.0, "avg_logprob": -0.14350467708939357, "compression_ratio": 1.7012987012987013, "no_speech_prob": 4.8312263970728964e-05}, {"id": 242, "seek": 124076, "start": 1240.76, "end": 1245.6, "text": " he was worried that SPAC would eventually cause the heat death of the universe because", "tokens": [415, 390, 5804, 300, 8420, 4378, 576, 4728, 3082, 264, 3738, 2966, 295, 264, 6445, 570], "temperature": 0.0, "avg_logprob": -0.15838703262471707, "compression_ratio": 1.6692607003891051, "no_speech_prob": 2.7962065360043198e-05}, {"id": 243, "seek": 124076, "start": 1245.6, "end": 1249.52, "text": " of pair of view builds. Or no, the pair of view builds would eventually bring on climate", "tokens": [295, 6119, 295, 1910, 15182, 13, 1610, 572, 11, 264, 6119, 295, 1910, 15182, 576, 4728, 1565, 322, 5659], "temperature": 0.0, "avg_logprob": -0.15838703262471707, "compression_ratio": 1.6692607003891051, "no_speech_prob": 2.7962065360043198e-05}, {"id": 244, "seek": 124076, "start": 1249.52, "end": 1257.44, "text": " change in the U.S. So we worry about that. We don't want to do that all the time.", "tokens": [1319, 294, 264, 624, 13, 50, 13, 407, 321, 3292, 466, 300, 13, 492, 500, 380, 528, 281, 360, 300, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.15838703262471707, "compression_ratio": 1.6692607003891051, "no_speech_prob": 2.7962065360043198e-05}, {"id": 245, "seek": 124076, "start": 1257.44, "end": 1265.0, "text": " The other thing that can happen is there's a delicate balance between redundant builds", "tokens": [440, 661, 551, 300, 393, 1051, 307, 456, 311, 257, 21417, 4772, 1296, 40997, 15182], "temperature": 0.0, "avg_logprob": -0.15838703262471707, "compression_ratio": 1.6692607003891051, "no_speech_prob": 2.7962065360043198e-05}, {"id": 246, "seek": 124076, "start": 1265.0, "end": 1269.84, "text": " and, you know, holding back PRs. I didn't think about this before we really got into", "tokens": [293, 11, 291, 458, 11, 5061, 646, 11568, 82, 13, 286, 994, 380, 519, 466, 341, 949, 321, 534, 658, 666], "temperature": 0.0, "avg_logprob": -0.15838703262471707, "compression_ratio": 1.6692607003891051, "no_speech_prob": 2.7962065360043198e-05}, {"id": 247, "seek": 126984, "start": 1269.84, "end": 1275.4399999999998, "text": " CI. But it matters what commit you pick to merge with when you're doing a build-cache", "tokens": [37777, 13, 583, 309, 7001, 437, 5599, 291, 1888, 281, 22183, 365, 562, 291, 434, 884, 257, 1322, 12, 66, 6000], "temperature": 0.0, "avg_logprob": -0.17559673911646792, "compression_ratio": 1.6074766355140186, "no_speech_prob": 5.063867865828797e-05}, {"id": 248, "seek": 126984, "start": 1275.4399999999998, "end": 1281.0, "text": " build. And so if you have a pipeline like this where you've built B and develop has", "tokens": [1322, 13, 400, 370, 498, 291, 362, 257, 15517, 411, 341, 689, 291, 600, 3094, 363, 293, 1499, 575], "temperature": 0.0, "avg_logprob": -0.17559673911646792, "compression_ratio": 1.6074766355140186, "no_speech_prob": 5.063867865828797e-05}, {"id": 249, "seek": 126984, "start": 1281.0, "end": 1287.4399999999998, "text": " now picked up on D and that one's building up there. And you get a PR like this. So PR1", "tokens": [586, 6183, 493, 322, 413, 293, 300, 472, 311, 2390, 493, 456, 13, 400, 291, 483, 257, 11568, 411, 341, 13, 407, 11568, 16], "temperature": 0.0, "avg_logprob": -0.17559673911646792, "compression_ratio": 1.6074766355140186, "no_speech_prob": 5.063867865828797e-05}, {"id": 250, "seek": 126984, "start": 1287.4399999999998, "end": 1292.8, "text": " comes in. You can merge that with B and get a lot of reuse there and get a pretty good", "tokens": [1487, 294, 13, 509, 393, 22183, 300, 365, 363, 293, 483, 257, 688, 295, 26225, 456, 293, 483, 257, 1238, 665], "temperature": 0.0, "avg_logprob": -0.17559673911646792, "compression_ratio": 1.6074766355140186, "no_speech_prob": 5.063867865828797e-05}, {"id": 251, "seek": 129280, "start": 1292.8, "end": 1300.84, "text": " testing on PR1. If instead you get a PR up here that is based beyond your last developed", "tokens": [4997, 322, 11568, 16, 13, 759, 2602, 291, 483, 257, 11568, 493, 510, 300, 307, 2361, 4399, 428, 1036, 4743], "temperature": 0.0, "avg_logprob": -0.09155300458272299, "compression_ratio": 1.792, "no_speech_prob": 9.514837984170299e-06}, {"id": 252, "seek": 129280, "start": 1300.84, "end": 1306.32, "text": " build and you try to merge that with D or even C, I guess it's already based on C, so", "tokens": [1322, 293, 291, 853, 281, 22183, 300, 365, 413, 420, 754, 383, 11, 286, 2041, 309, 311, 1217, 2361, 322, 383, 11, 370], "temperature": 0.0, "avg_logprob": -0.09155300458272299, "compression_ratio": 1.792, "no_speech_prob": 9.514837984170299e-06}, {"id": 253, "seek": 129280, "start": 1306.32, "end": 1309.72, "text": " you can't really merge with C. But if you merge that with D, you're going to be duplicating", "tokens": [291, 393, 380, 534, 22183, 365, 383, 13, 583, 498, 291, 22183, 300, 365, 413, 11, 291, 434, 516, 281, 312, 17154, 990], "temperature": 0.0, "avg_logprob": -0.09155300458272299, "compression_ratio": 1.792, "no_speech_prob": 9.514837984170299e-06}, {"id": 254, "seek": 129280, "start": 1309.72, "end": 1313.72, "text": " the work that's already being done on develop. And so if you get a bunch of PRs like this", "tokens": [264, 589, 300, 311, 1217, 885, 1096, 322, 1499, 13, 400, 370, 498, 291, 483, 257, 3840, 295, 11568, 82, 411, 341], "temperature": 0.0, "avg_logprob": -0.09155300458272299, "compression_ratio": 1.792, "no_speech_prob": 9.514837984170299e-06}, {"id": 255, "seek": 129280, "start": 1313.72, "end": 1319.2, "text": " at the same time, you can get a whole bunch of builds at the same time that are effectively", "tokens": [412, 264, 912, 565, 11, 291, 393, 483, 257, 1379, 3840, 295, 15182, 412, 264, 912, 565, 300, 366, 8659], "temperature": 0.0, "avg_logprob": -0.09155300458272299, "compression_ratio": 1.792, "no_speech_prob": 9.514837984170299e-06}, {"id": 256, "seek": 131920, "start": 1319.2, "end": 1324.0, "text": " already being done on develop. And so this is a difficulty of navigating these PR-based", "tokens": [1217, 885, 1096, 322, 1499, 13, 400, 370, 341, 307, 257, 10360, 295, 32054, 613, 11568, 12, 6032], "temperature": 0.0, "avg_logprob": -0.17466780516478392, "compression_ratio": 1.6568265682656826, "no_speech_prob": 9.514118573861197e-06}, {"id": 257, "seek": 131920, "start": 1324.0, "end": 1329.44, "text": " CI systems. If you had a server that had shared that one patch was built all the time once,", "tokens": [37777, 3652, 13, 759, 291, 632, 257, 7154, 300, 632, 5507, 300, 472, 9972, 390, 3094, 439, 264, 565, 1564, 11], "temperature": 0.0, "avg_logprob": -0.17466780516478392, "compression_ratio": 1.6568265682656826, "no_speech_prob": 9.514118573861197e-06}, {"id": 258, "seek": 131920, "start": 1329.44, "end": 1334.2, "text": " then you could get around this. So you have to be picky about this, hold up PR2 until", "tokens": [550, 291, 727, 483, 926, 341, 13, 407, 291, 362, 281, 312, 41099, 466, 341, 11, 1797, 493, 11568, 17, 1826], "temperature": 0.0, "avg_logprob": -0.17466780516478392, "compression_ratio": 1.6568265682656826, "no_speech_prob": 9.514118573861197e-06}, {"id": 259, "seek": 131920, "start": 1334.2, "end": 1339.8400000000001, "text": " the next thing is built and then merge with that commit and send it to GitLab to be merged", "tokens": [264, 958, 551, 307, 3094, 293, 550, 22183, 365, 300, 5599, 293, 2845, 309, 281, 16939, 37880, 281, 312, 36427], "temperature": 0.0, "avg_logprob": -0.17466780516478392, "compression_ratio": 1.6568265682656826, "no_speech_prob": 9.514118573861197e-06}, {"id": 260, "seek": 131920, "start": 1339.8400000000001, "end": 1345.2, "text": " or to be built. And this can annoy contributors because they have to wait for that to happen", "tokens": [420, 281, 312, 3094, 13, 400, 341, 393, 8759, 45627, 570, 436, 362, 281, 1699, 337, 300, 281, 1051], "temperature": 0.0, "avg_logprob": -0.17466780516478392, "compression_ratio": 1.6568265682656826, "no_speech_prob": 9.514118573861197e-06}, {"id": 261, "seek": 134520, "start": 1345.2, "end": 1349.88, "text": " for their PR in order to keep the CI system sane.", "tokens": [337, 641, 11568, 294, 1668, 281, 1066, 264, 37777, 1185, 45610, 13], "temperature": 0.0, "avg_logprob": -0.16136059902682162, "compression_ratio": 1.564, "no_speech_prob": 9.222055268764962e-06}, {"id": 262, "seek": 134520, "start": 1349.88, "end": 1355.56, "text": " We actually did bring down GitLab once with a bunch of PRs like this. Essentially something", "tokens": [492, 767, 630, 1565, 760, 16939, 37880, 1564, 365, 257, 3840, 295, 11568, 82, 411, 341, 13, 23596, 746], "temperature": 0.0, "avg_logprob": -0.16136059902682162, "compression_ratio": 1.564, "no_speech_prob": 9.222055268764962e-06}, {"id": 263, "seek": 134520, "start": 1355.56, "end": 1359.0800000000002, "text": " got broken in develop, develop, got held up, people started submitting a bunch of PRs,", "tokens": [658, 5463, 294, 1499, 11, 1499, 11, 658, 5167, 493, 11, 561, 1409, 31836, 257, 3840, 295, 11568, 82, 11], "temperature": 0.0, "avg_logprob": -0.16136059902682162, "compression_ratio": 1.564, "no_speech_prob": 9.222055268764962e-06}, {"id": 264, "seek": 134520, "start": 1359.0800000000002, "end": 1365.3600000000001, "text": " they were all doing redundant builds and GitLab fell over. So that was fun.", "tokens": [436, 645, 439, 884, 40997, 15182, 293, 16939, 37880, 5696, 670, 13, 407, 300, 390, 1019, 13], "temperature": 0.0, "avg_logprob": -0.16136059902682162, "compression_ratio": 1.564, "no_speech_prob": 9.222055268764962e-06}, {"id": 265, "seek": 134520, "start": 1365.3600000000001, "end": 1370.5800000000002, "text": " CI does keep things stable. And so we have had, at least anecdotally, that our package", "tokens": [37777, 775, 1066, 721, 8351, 13, 400, 370, 321, 362, 632, 11, 412, 1935, 26652, 310, 379, 11, 300, 527, 7372], "temperature": 0.0, "avg_logprob": -0.16136059902682162, "compression_ratio": 1.564, "no_speech_prob": 9.222055268764962e-06}, {"id": 266, "seek": 137058, "start": 1370.58, "end": 1376.08, "text": " maintainers at the lab are much more happy with how reliable their builds are for packages", "tokens": [6909, 433, 412, 264, 2715, 366, 709, 544, 2055, 365, 577, 12924, 641, 15182, 366, 337, 17401], "temperature": 0.0, "avg_logprob": -0.123281715452209, "compression_ratio": 1.8006993006993006, "no_speech_prob": 1.3207927622715943e-05}, {"id": 267, "seek": 137058, "start": 1376.08, "end": 1382.48, "text": " on the machines since we've had CI. But like I said, the committers get frustrated. And", "tokens": [322, 264, 8379, 1670, 321, 600, 632, 37777, 13, 583, 411, 286, 848, 11, 264, 5599, 1559, 483, 15751, 13, 400], "temperature": 0.0, "avg_logprob": -0.123281715452209, "compression_ratio": 1.8006993006993006, "no_speech_prob": 1.3207927622715943e-05}, {"id": 268, "seek": 137058, "start": 1382.48, "end": 1385.48, "text": " the other thing that happens here if you're doing so many builds on PRs is that if your", "tokens": [264, 661, 551, 300, 2314, 510, 498, 291, 434, 884, 370, 867, 15182, 322, 11568, 82, 307, 300, 498, 428], "temperature": 0.0, "avg_logprob": -0.123281715452209, "compression_ratio": 1.8006993006993006, "no_speech_prob": 1.3207927622715943e-05}, {"id": 269, "seek": 137058, "start": 1385.48, "end": 1390.6, "text": " CI system has occasional system errors, if you're building a thousand things on a PR", "tokens": [37777, 1185, 575, 31644, 1185, 13603, 11, 498, 291, 434, 2390, 257, 4714, 721, 322, 257, 11568], "temperature": 0.0, "avg_logprob": -0.123281715452209, "compression_ratio": 1.8006993006993006, "no_speech_prob": 1.3207927622715943e-05}, {"id": 270, "seek": 137058, "start": 1390.6, "end": 1393.52, "text": " pipeline, it's very likely that you're going to get a system error on there.", "tokens": [15517, 11, 309, 311, 588, 3700, 300, 291, 434, 516, 281, 483, 257, 1185, 6713, 322, 456, 13], "temperature": 0.0, "avg_logprob": -0.123281715452209, "compression_ratio": 1.8006993006993006, "no_speech_prob": 1.3207927622715943e-05}, {"id": 271, "seek": 137058, "start": 1393.52, "end": 1398.4399999999998, "text": " And so what ends up happening is that you end up having to babysit PRs a bit. And that", "tokens": [400, 370, 437, 5314, 493, 2737, 307, 300, 291, 917, 493, 1419, 281, 39764, 270, 11568, 82, 257, 857, 13, 400, 300], "temperature": 0.0, "avg_logprob": -0.123281715452209, "compression_ratio": 1.8006993006993006, "no_speech_prob": 1.3207927622715943e-05}, {"id": 272, "seek": 139844, "start": 1398.44, "end": 1404.88, "text": " can be painful. The other thing that happens is it's hard to stay correct. So testing on", "tokens": [393, 312, 11697, 13, 440, 661, 551, 300, 2314, 307, 309, 311, 1152, 281, 1754, 3006, 13, 407, 4997, 322], "temperature": 0.0, "avg_logprob": -0.13848963571250986, "compression_ratio": 1.6943396226415095, "no_speech_prob": 3.94297567254398e-05}, {"id": 273, "seek": 139844, "start": 1404.88, "end": 1408.64, "text": " PRs doesn't really ensure that you have a working develop branch. If you have a setup", "tokens": [11568, 82, 1177, 380, 534, 5586, 300, 291, 362, 257, 1364, 1499, 9819, 13, 759, 291, 362, 257, 8657], "temperature": 0.0, "avg_logprob": -0.13848963571250986, "compression_ratio": 1.6943396226415095, "no_speech_prob": 3.94297567254398e-05}, {"id": 274, "seek": 139844, "start": 1408.64, "end": 1415.3200000000002, "text": " like this with an initial package state, you get a pull request at update B. You get another", "tokens": [411, 341, 365, 364, 5883, 7372, 1785, 11, 291, 483, 257, 2235, 5308, 412, 5623, 363, 13, 509, 483, 1071], "temperature": 0.0, "avg_logprob": -0.13848963571250986, "compression_ratio": 1.6943396226415095, "no_speech_prob": 3.94297567254398e-05}, {"id": 275, "seek": 139844, "start": 1415.3200000000002, "end": 1419.92, "text": " pull request in there that updates C. You test both of those configurations on your PRs", "tokens": [2235, 5308, 294, 456, 300, 9205, 383, 13, 509, 1500, 1293, 295, 729, 31493, 322, 428, 11568, 82], "temperature": 0.0, "avg_logprob": -0.13848963571250986, "compression_ratio": 1.6943396226415095, "no_speech_prob": 3.94297567254398e-05}, {"id": 276, "seek": 139844, "start": 1419.92, "end": 1425.4, "text": " and they work. And you merge them. The thing that you now have in develop is actually updated", "tokens": [293, 436, 589, 13, 400, 291, 22183, 552, 13, 440, 551, 300, 291, 586, 362, 294, 1499, 307, 767, 10588], "temperature": 0.0, "avg_logprob": -0.13848963571250986, "compression_ratio": 1.6943396226415095, "no_speech_prob": 3.94297567254398e-05}, {"id": 277, "seek": 142540, "start": 1425.4, "end": 1431.88, "text": " B and updated C. And you never tested that. And so keeping that state consistent is rather", "tokens": [363, 293, 10588, 383, 13, 400, 291, 1128, 8246, 300, 13, 400, 370, 5145, 300, 1785, 8398, 307, 2831], "temperature": 0.0, "avg_logprob": -0.13569692072977546, "compression_ratio": 1.703583061889251, "no_speech_prob": 1.3842678526998498e-05}, {"id": 278, "seek": 142540, "start": 1431.88, "end": 1436.52, "text": " difficult. And we're thinking we're going to, we didn't, you know, before we had CI,", "tokens": [2252, 13, 400, 321, 434, 1953, 321, 434, 516, 281, 11, 321, 994, 380, 11, 291, 458, 11, 949, 321, 632, 37777, 11], "temperature": 0.0, "avg_logprob": -0.13569692072977546, "compression_ratio": 1.703583061889251, "no_speech_prob": 1.3842678526998498e-05}, {"id": 279, "seek": 142540, "start": 1436.52, "end": 1440.16, "text": " I think we just didn't see these kinds of issues. They would just get manifested on", "tokens": [286, 519, 321, 445, 994, 380, 536, 613, 3685, 295, 2663, 13, 814, 576, 445, 483, 42775, 322], "temperature": 0.0, "avg_logprob": -0.13569692072977546, "compression_ratio": 1.703583061889251, "no_speech_prob": 1.3842678526998498e-05}, {"id": 280, "seek": 142540, "start": 1440.16, "end": 1445.0, "text": " users, which is not great. But now we run into them in CI because we can see that things", "tokens": [5022, 11, 597, 307, 406, 869, 13, 583, 586, 321, 1190, 666, 552, 294, 37777, 570, 321, 393, 536, 300, 721], "temperature": 0.0, "avg_logprob": -0.13569692072977546, "compression_ratio": 1.703583061889251, "no_speech_prob": 1.3842678526998498e-05}, {"id": 281, "seek": 142540, "start": 1445.0, "end": 1448.16, "text": " are broken undeveloped. So we're looking into using merge queues, which actually solved", "tokens": [366, 5463, 40981, 1388, 292, 13, 407, 321, 434, 1237, 666, 1228, 22183, 631, 1247, 11, 597, 767, 13041], "temperature": 0.0, "avg_logprob": -0.13569692072977546, "compression_ratio": 1.703583061889251, "no_speech_prob": 1.3842678526998498e-05}, {"id": 282, "seek": 142540, "start": 1448.16, "end": 1452.26, "text": " this problem and a couple others that we have pretty effectively. So you can do faster", "tokens": [341, 1154, 293, 257, 1916, 2357, 300, 321, 362, 1238, 8659, 13, 407, 291, 393, 360, 4663], "temperature": 0.0, "avg_logprob": -0.13569692072977546, "compression_ratio": 1.703583061889251, "no_speech_prob": 1.3842678526998498e-05}, {"id": 283, "seek": 145226, "start": 1452.26, "end": 1456.04, "text": " iteration on PRs with merge queues because you're merging in sequence, testing in parallel.", "tokens": [24784, 322, 11568, 82, 365, 22183, 631, 1247, 570, 291, 434, 44559, 294, 8310, 11, 4997, 294, 8952, 13], "temperature": 0.0, "avg_logprob": -0.1493375301361084, "compression_ratio": 1.8127090301003344, "no_speech_prob": 1.3418485650618095e-05}, {"id": 284, "seek": 145226, "start": 1456.04, "end": 1460.52, "text": " I'll describe what that looks like in a minute. It's a good balance of CI versus responsiveness", "tokens": [286, 603, 6786, 437, 300, 1542, 411, 294, 257, 3456, 13, 467, 311, 257, 665, 4772, 295, 37777, 5717, 2914, 8477], "temperature": 0.0, "avg_logprob": -0.1493375301361084, "compression_ratio": 1.8127090301003344, "no_speech_prob": 1.3418485650618095e-05}, {"id": 285, "seek": 145226, "start": 1460.52, "end": 1464.72, "text": " because you can do sort of sparse tests on the PRs and queue them and then do the heavy", "tokens": [570, 291, 393, 360, 1333, 295, 637, 11668, 6921, 322, 264, 11568, 82, 293, 18639, 552, 293, 550, 360, 264, 4676], "temperature": 0.0, "avg_logprob": -0.1493375301361084, "compression_ratio": 1.8127090301003344, "no_speech_prob": 1.3418485650618095e-05}, {"id": 286, "seek": 145226, "start": 1464.72, "end": 1469.14, "text": " tests. And it actually does preserve the security model because anything queued in a merge", "tokens": [6921, 13, 400, 309, 767, 775, 15665, 264, 3825, 2316, 570, 1340, 631, 5827, 294, 257, 22183], "temperature": 0.0, "avg_logprob": -0.1493375301361084, "compression_ratio": 1.8127090301003344, "no_speech_prob": 1.3418485650618095e-05}, {"id": 287, "seek": 145226, "start": 1469.14, "end": 1472.48, "text": " queue is actually approved by containers, by maintainers, and you can take the builds", "tokens": [18639, 307, 767, 10826, 538, 17089, 11, 538, 6909, 433, 11, 293, 291, 393, 747, 264, 15182], "temperature": 0.0, "avg_logprob": -0.1493375301361084, "compression_ratio": 1.8127090301003344, "no_speech_prob": 1.3418485650618095e-05}, {"id": 288, "seek": 145226, "start": 1472.48, "end": 1477.72, "text": " and move them straight into develop. And so what that looks like is this, where you might", "tokens": [293, 1286, 552, 2997, 666, 1499, 13, 400, 370, 437, 300, 1542, 411, 307, 341, 11, 689, 291, 1062], "temperature": 0.0, "avg_logprob": -0.1493375301361084, "compression_ratio": 1.8127090301003344, "no_speech_prob": 1.3418485650618095e-05}, {"id": 289, "seek": 147772, "start": 1477.72, "end": 1482.66, "text": " have the same initial packet state, you get two pull requests, you do some small testing", "tokens": [362, 264, 912, 5883, 20300, 1785, 11, 291, 483, 732, 2235, 12475, 11, 291, 360, 512, 1359, 4997], "temperature": 0.0, "avg_logprob": -0.14236786341903232, "compression_ratio": 1.7559055118110236, "no_speech_prob": 7.886224011599552e-06}, {"id": 290, "seek": 147772, "start": 1482.66, "end": 1487.2, "text": " on the pull request, and then you set up this merge queue where effectively you're doing", "tokens": [322, 264, 2235, 5308, 11, 293, 550, 291, 992, 493, 341, 22183, 18639, 689, 8659, 291, 434, 884], "temperature": 0.0, "avg_logprob": -0.14236786341903232, "compression_ratio": 1.7559055118110236, "no_speech_prob": 7.886224011599552e-06}, {"id": 291, "seek": 147772, "start": 1487.2, "end": 1491.88, "text": " heavy testing on things that are basically staged exactly as they will be merged if they", "tokens": [4676, 4997, 322, 721, 300, 366, 1936, 45178, 2293, 382, 436, 486, 312, 36427, 498, 436], "temperature": 0.0, "avg_logprob": -0.14236786341903232, "compression_ratio": 1.7559055118110236, "no_speech_prob": 7.886224011599552e-06}, {"id": 292, "seek": 147772, "start": 1491.88, "end": 1497.04, "text": " are successful. Okay. So that gets committed, that gets committed, and now you've tested", "tokens": [366, 4406, 13, 1033, 13, 407, 300, 2170, 7784, 11, 300, 2170, 7784, 11, 293, 586, 291, 600, 8246], "temperature": 0.0, "avg_logprob": -0.14236786341903232, "compression_ratio": 1.7559055118110236, "no_speech_prob": 7.886224011599552e-06}, {"id": 293, "seek": 147772, "start": 1497.04, "end": 1502.3600000000001, "text": " the final configuration on develop and you're not in an inconsistent state. So we're going", "tokens": [264, 2572, 11694, 322, 1499, 293, 291, 434, 406, 294, 364, 36891, 1785, 13, 407, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.14236786341903232, "compression_ratio": 1.7559055118110236, "no_speech_prob": 7.886224011599552e-06}, {"id": 294, "seek": 150236, "start": 1502.36, "end": 1508.6399999999999, "text": " to stage the work that we do in CI. On PRs, we're probably going to build just the package", "tokens": [281, 3233, 264, 589, 300, 321, 360, 294, 37777, 13, 1282, 11568, 82, 11, 321, 434, 1391, 516, 281, 1322, 445, 264, 7372], "temperature": 0.0, "avg_logprob": -0.17629475252968924, "compression_ratio": 1.6451612903225807, "no_speech_prob": 6.472732638940215e-05}, {"id": 295, "seek": 150236, "start": 1508.6399999999999, "end": 1513.04, "text": " or just the package and its dependence, which is similar to what Nix does. On most merge", "tokens": [420, 445, 264, 7372, 293, 1080, 31704, 11, 597, 307, 2531, 281, 437, 426, 970, 775, 13, 1282, 881, 22183], "temperature": 0.0, "avg_logprob": -0.17629475252968924, "compression_ratio": 1.6451612903225807, "no_speech_prob": 6.472732638940215e-05}, {"id": 296, "seek": 150236, "start": 1513.04, "end": 1516.08, "text": " queue pipelines, we may build a bit more than that, and then every once in a while we'll", "tokens": [18639, 40168, 11, 321, 815, 1322, 257, 857, 544, 813, 300, 11, 293, 550, 633, 1564, 294, 257, 1339, 321, 603], "temperature": 0.0, "avg_logprob": -0.17629475252968924, "compression_ratio": 1.6451612903225807, "no_speech_prob": 6.472732638940215e-05}, {"id": 297, "seek": 150236, "start": 1516.08, "end": 1519.9599999999998, "text": " build everything on develop, and we'll see how it goes. We can probe, you know, what", "tokens": [1322, 1203, 322, 1499, 11, 293, 321, 603, 536, 577, 309, 1709, 13, 492, 393, 22715, 11, 291, 458, 11, 437], "temperature": 0.0, "avg_logprob": -0.17629475252968924, "compression_ratio": 1.6451612903225807, "no_speech_prob": 6.472732638940215e-05}, {"id": 298, "seek": 150236, "start": 1519.9599999999998, "end": 1523.6799999999998, "text": " the balance is here. So that's where we're at. Thanks.", "tokens": [264, 4772, 307, 510, 13, 407, 300, 311, 689, 321, 434, 412, 13, 2561, 13], "temperature": 0.0, "avg_logprob": -0.17629475252968924, "compression_ratio": 1.6451612903225807, "no_speech_prob": 6.472732638940215e-05}, {"id": 299, "seek": 152368, "start": 1523.68, "end": 1534.6000000000001, "text": " Okay, I think we have time for one or two questions. Any questions for Todd?", "tokens": [1033, 11, 286, 519, 321, 362, 565, 337, 472, 420, 732, 1651, 13, 2639, 1651, 337, 21488, 30], "temperature": 0.0, "avg_logprob": -0.37272083948528956, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.0005503135616891086}, {"id": 300, "seek": 152368, "start": 1534.6000000000001, "end": 1544.4, "text": " And off the wall question, we have, for example, software bill of materials, dev room. You", "tokens": [400, 766, 264, 2929, 1168, 11, 321, 362, 11, 337, 1365, 11, 4722, 2961, 295, 5319, 11, 1905, 1808, 13, 509], "temperature": 0.0, "avg_logprob": -0.37272083948528956, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.0005503135616891086}, {"id": 301, "seek": 152368, "start": 1544.4, "end": 1549.48, "text": " mentioned export controlled software and also being able to trust binaries. I work with", "tokens": [2835, 10725, 10164, 4722, 293, 611, 885, 1075, 281, 3361, 5171, 4889, 13, 286, 589, 365], "temperature": 0.0, "avg_logprob": -0.37272083948528956, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.0005503135616891086}, {"id": 302, "seek": 154948, "start": 1549.48, "end": 1555.0, "text": " classified customers who have isolated networks, probably Shopify, MI6, if I told you who", "tokens": [20627, 4581, 567, 362, 14621, 9590, 11, 1391, 43991, 11, 13696, 21, 11, 498, 286, 1907, 291, 567], "temperature": 0.0, "avg_logprob": -0.2200386435897262, "compression_ratio": 1.5905797101449275, "no_speech_prob": 0.0006117131561040878}, {"id": 303, "seek": 154948, "start": 1555.0, "end": 1561.44, "text": " they were. But could SPAC help with providing, they're now asking for what software is running", "tokens": [436, 645, 13, 583, 727, 8420, 4378, 854, 365, 6530, 11, 436, 434, 586, 3365, 337, 437, 4722, 307, 2614], "temperature": 0.0, "avg_logprob": -0.2200386435897262, "compression_ratio": 1.5905797101449275, "no_speech_prob": 0.0006117131561040878}, {"id": 304, "seek": 154948, "start": 1561.44, "end": 1566.68, "text": " on these systems. I mean, what does that question mean, really? Can you help with producing", "tokens": [322, 613, 3652, 13, 286, 914, 11, 437, 775, 300, 1168, 914, 11, 534, 30, 1664, 291, 854, 365, 10501], "temperature": 0.0, "avg_logprob": -0.2200386435897262, "compression_ratio": 1.5905797101449275, "no_speech_prob": 0.0006117131561040878}, {"id": 305, "seek": 154948, "start": 1566.68, "end": 1572.32, "text": " a report on exactly what software is? Yeah, we have a PR right now for so that", "tokens": [257, 2275, 322, 2293, 437, 4722, 307, 30, 865, 11, 321, 362, 257, 11568, 558, 586, 337, 370, 300], "temperature": 0.0, "avg_logprob": -0.2200386435897262, "compression_ratio": 1.5905797101449275, "no_speech_prob": 0.0006117131561040878}, {"id": 306, "seek": 154948, "start": 1572.32, "end": 1577.76, "text": " every SPAC build would produce an SBOM in some standard format. There's a whole dev", "tokens": [633, 8420, 4378, 1322, 576, 5258, 364, 26944, 5251, 294, 512, 3832, 7877, 13, 821, 311, 257, 1379, 1905], "temperature": 0.0, "avg_logprob": -0.2200386435897262, "compression_ratio": 1.5905797101449275, "no_speech_prob": 0.0006117131561040878}, {"id": 307, "seek": 157776, "start": 1577.76, "end": 1582.84, "text": " room on SBOMs today, which gets into that. And so I think, yeah, I mean, we know everything", "tokens": [1808, 322, 26944, 5251, 82, 965, 11, 597, 2170, 666, 300, 13, 400, 370, 286, 519, 11, 1338, 11, 286, 914, 11, 321, 458, 1203], "temperature": 0.0, "avg_logprob": -0.18978151679039001, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001327726786257699}, {"id": 308, "seek": 157776, "start": 1582.84, "end": 1587.52, "text": " in the graph, and so do Nixon Geeks and the other systems that do this. We don't expose", "tokens": [294, 264, 4295, 11, 293, 370, 360, 31130, 2876, 24785, 293, 264, 661, 3652, 300, 360, 341, 13, 492, 500, 380, 19219], "temperature": 0.0, "avg_logprob": -0.18978151679039001, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001327726786257699}, {"id": 309, "seek": 157776, "start": 1587.52, "end": 1591.12, "text": " it in a standard format that auditing systems can scan right now, but that's what we'd like", "tokens": [309, 294, 257, 3832, 7877, 300, 2379, 1748, 3652, 393, 11049, 558, 586, 11, 457, 300, 311, 437, 321, 1116, 411], "temperature": 0.0, "avg_logprob": -0.18978151679039001, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001327726786257699}, {"id": 310, "seek": 157776, "start": 1591.12, "end": 1596.44, "text": " to do. So very briefly, Debbie and I, a while ago,", "tokens": [281, 360, 13, 407, 588, 10515, 11, 35834, 293, 286, 11, 257, 1339, 2057, 11], "temperature": 0.0, "avg_logprob": -0.18978151679039001, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001327726786257699}, {"id": 311, "seek": 157776, "start": 1596.44, "end": 1600.2, "text": " did something on reproducible builds, which were much more difficult. So if you haven't", "tokens": [630, 746, 322, 11408, 32128, 15182, 11, 597, 645, 709, 544, 2252, 13, 407, 498, 291, 2378, 380], "temperature": 0.0, "avg_logprob": -0.18978151679039001, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001327726786257699}, {"id": 312, "seek": 157776, "start": 1600.2, "end": 1603.96, "text": " worked with her a bit, that might be interesting for you.", "tokens": [2732, 365, 720, 257, 857, 11, 300, 1062, 312, 1880, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.18978151679039001, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001327726786257699}, {"id": 313, "seek": 160396, "start": 1603.96, "end": 1611.16, "text": " Yeah, so we would like to have fully reproducible builds. It's a lot of upstream patching, right?", "tokens": [865, 11, 370, 321, 576, 411, 281, 362, 4498, 11408, 32128, 15182, 13, 467, 311, 257, 688, 295, 33915, 9972, 278, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.16527676789656928, "compression_ratio": 1.7653846153846153, "no_speech_prob": 2.4292172383866273e-05}, {"id": 314, "seek": 160396, "start": 1611.16, "end": 1616.88, "text": " And even Debian isn't fully reproducible right now. I think that that would be like something", "tokens": [400, 754, 1346, 20196, 1943, 380, 4498, 11408, 32128, 558, 586, 13, 286, 519, 300, 300, 576, 312, 411, 746], "temperature": 0.0, "avg_logprob": -0.16527676789656928, "compression_ratio": 1.7653846153846153, "no_speech_prob": 2.4292172383866273e-05}, {"id": 315, "seek": 160396, "start": 1616.88, "end": 1622.08, "text": " we could consider after we get down to, like, libc even, because at the moment, because", "tokens": [321, 727, 1949, 934, 321, 483, 760, 281, 11, 411, 11, 22854, 66, 754, 11, 570, 412, 264, 1623, 11, 570], "temperature": 0.0, "avg_logprob": -0.16527676789656928, "compression_ratio": 1.7653846153846153, "no_speech_prob": 2.4292172383866273e-05}, {"id": 316, "seek": 160396, "start": 1622.08, "end": 1625.3600000000001, "text": " we have to run on things like craze where there's so much dependent on, like, the module", "tokens": [321, 362, 281, 1190, 322, 721, 411, 2094, 1381, 689, 456, 311, 370, 709, 12334, 322, 11, 411, 11, 264, 10088], "temperature": 0.0, "avg_logprob": -0.16527676789656928, "compression_ratio": 1.7653846153846153, "no_speech_prob": 2.4292172383866273e-05}, {"id": 317, "seek": 160396, "start": 1625.3600000000001, "end": 1630.8, "text": " environment, we have to include the external environment to get some of these builds done.", "tokens": [2823, 11, 321, 362, 281, 4090, 264, 8320, 2823, 281, 483, 512, 295, 613, 15182, 1096, 13], "temperature": 0.0, "avg_logprob": -0.16527676789656928, "compression_ratio": 1.7653846153846153, "no_speech_prob": 2.4292172383866273e-05}, {"id": 318, "seek": 163080, "start": 1630.8, "end": 1635.0, "text": " But yeah, I would like to have a much more isolated build environment with that. It's", "tokens": [583, 1338, 11, 286, 576, 411, 281, 362, 257, 709, 544, 14621, 1322, 2823, 365, 300, 13, 467, 311], "temperature": 0.0, "avg_logprob": -0.24412047344705332, "compression_ratio": 1.5863309352517985, "no_speech_prob": 0.00019036194134969264}, {"id": 319, "seek": 163080, "start": 1635.0, "end": 1639.76, "text": " a good practice. Okay, one more question here, and then need", "tokens": [257, 665, 3124, 13, 1033, 11, 472, 544, 1168, 510, 11, 293, 550, 643], "temperature": 0.0, "avg_logprob": -0.24412047344705332, "compression_ratio": 1.5863309352517985, "no_speech_prob": 0.00019036194134969264}, {"id": 320, "seek": 163080, "start": 1639.76, "end": 1644.32, "text": " to switch. Hi, so you were talking about padding your", "tokens": [281, 3679, 13, 2421, 11, 370, 291, 645, 1417, 466, 39562, 428], "temperature": 0.0, "avg_logprob": -0.24412047344705332, "compression_ratio": 1.5863309352517985, "no_speech_prob": 0.00019036194134969264}, {"id": 321, "seek": 163080, "start": 1644.32, "end": 1650.3999999999999, "text": " header files for rallies of pathing. Given that you don't have a static path or a pre-defined", "tokens": [23117, 7098, 337, 48169, 295, 1947, 571, 13, 18600, 300, 291, 500, 380, 362, 257, 13437, 3100, 420, 257, 659, 12, 37716], "temperature": 0.0, "avg_logprob": -0.24412047344705332, "compression_ratio": 1.5863309352517985, "no_speech_prob": 0.00019036194134969264}, {"id": 322, "seek": 163080, "start": 1650.3999999999999, "end": 1656.28, "text": " destination as in FHS-type locations, are you in serious danger of running out of space", "tokens": [12236, 382, 294, 479, 12527, 12, 20467, 9253, 11, 366, 291, 294, 3156, 4330, 295, 2614, 484, 295, 1901], "temperature": 0.0, "avg_logprob": -0.24412047344705332, "compression_ratio": 1.5863309352517985, "no_speech_prob": 0.00019036194134969264}, {"id": 323, "seek": 163080, "start": 1656.28, "end": 1660.04, "text": " in that header? Well, we're not building in a static path.", "tokens": [294, 300, 23117, 30, 1042, 11, 321, 434, 406, 2390, 294, 257, 13437, 3100, 13], "temperature": 0.0, "avg_logprob": -0.24412047344705332, "compression_ratio": 1.5863309352517985, "no_speech_prob": 0.00019036194134969264}, {"id": 324, "seek": 166004, "start": 1660.04, "end": 1665.08, "text": " We might be building in a home directory, right? And so you can put padding in your", "tokens": [492, 1062, 312, 2390, 294, 257, 1280, 21120, 11, 558, 30, 400, 370, 291, 393, 829, 39562, 294, 428], "temperature": 0.0, "avg_logprob": -0.208955532167016, "compression_ratio": 1.723021582733813, "no_speech_prob": 9.14853299036622e-05}, {"id": 325, "seek": 166004, "start": 1665.08, "end": 1671.12, "text": " install tree prefix, it's like the next store, and you can say build with 256 long paths.", "tokens": [3625, 4230, 46969, 11, 309, 311, 411, 264, 958, 3531, 11, 293, 291, 393, 584, 1322, 365, 38882, 938, 14518, 13], "temperature": 0.0, "avg_logprob": -0.208955532167016, "compression_ratio": 1.723021582733813, "no_speech_prob": 9.14853299036622e-05}, {"id": 326, "seek": 166004, "start": 1671.12, "end": 1675.36, "text": " And you wouldn't want to have a user actually deploy in a path like that, but you can build", "tokens": [400, 291, 2759, 380, 528, 281, 362, 257, 4195, 767, 7274, 294, 257, 3100, 411, 300, 11, 457, 291, 393, 1322], "temperature": 0.0, "avg_logprob": -0.208955532167016, "compression_ratio": 1.723021582733813, "no_speech_prob": 9.14853299036622e-05}, {"id": 327, "seek": 166004, "start": 1675.36, "end": 1678.32, "text": " that way, create the binary, and then redeploy in a short path.", "tokens": [300, 636, 11, 1884, 264, 17434, 11, 293, 550, 14328, 2384, 294, 257, 2099, 3100, 13], "temperature": 0.0, "avg_logprob": -0.208955532167016, "compression_ratio": 1.723021582733813, "no_speech_prob": 9.14853299036622e-05}, {"id": 328, "seek": 166004, "start": 1678.32, "end": 1683.8799999999999, "text": " You've got potentially a space where there's, where you can have an arbitrary length path", "tokens": [509, 600, 658, 7263, 257, 1901, 689, 456, 311, 11, 689, 291, 393, 362, 364, 23211, 4641, 3100], "temperature": 0.0, "avg_logprob": -0.208955532167016, "compression_ratio": 1.723021582733813, "no_speech_prob": 9.14853299036622e-05}, {"id": 329, "seek": 166004, "start": 1683.8799999999999, "end": 1687.12, "text": " as you're running. A lot of stuff doesn't build with overly", "tokens": [382, 291, 434, 2614, 13, 316, 688, 295, 1507, 1177, 380, 1322, 365, 24324], "temperature": 0.0, "avg_logprob": -0.208955532167016, "compression_ratio": 1.723021582733813, "no_speech_prob": 9.14853299036622e-05}, {"id": 330, "seek": 168712, "start": 1687.12, "end": 1691.8, "text": " long paths. So if you get to 5.12, auto-tools starts breaking down and not supporting that", "tokens": [938, 14518, 13, 407, 498, 291, 483, 281, 1025, 13, 4762, 11, 8399, 12, 83, 29298, 3719, 7697, 760, 293, 406, 7231, 300], "temperature": 0.0, "avg_logprob": -0.2557515501976013, "compression_ratio": 1.3987730061349692, "no_speech_prob": 0.0001289328356506303}, {"id": 331, "seek": 168712, "start": 1691.8, "end": 1696.4399999999998, "text": " length of a path, and the packages actually don't support it. And so the sweet spot seems", "tokens": [4641, 295, 257, 3100, 11, 293, 264, 17401, 767, 500, 380, 1406, 309, 13, 400, 370, 264, 3844, 4008, 2544], "temperature": 0.0, "avg_logprob": -0.2557515501976013, "compression_ratio": 1.3987730061349692, "no_speech_prob": 0.0001289328356506303}, {"id": 332, "seek": 169644, "start": 1696.44, "end": 1718.2, "text": " to be like 256. Okay, thanks.", "tokens": [50364, 281, 312, 411, 38882, 13, 1033, 11, 3231, 13, 51452], "temperature": 0.0, "avg_logprob": -0.47347553571065265, "compression_ratio": 0.7837837837837838, "no_speech_prob": 0.00026786292437464}], "language": "en"}