{"text": " Okay, so yeah, thank you, everyone, for coming. The streaming data, the last one of the day, after that, you're free to use, you know, go elsewhere. For the last one, we have a super cool talk with Alex, he is the CEO of the house. Yes, he's going to tell us how to build real-time application with the house. Yeah, thank you. So, the title of my talk is very similar to the previous. So, let's see what will be the difference. I will try to build a small, simple analytical application, just about right now. And how to build an analytical application? We have to figure out what to do, where to collect our data, how to prepare and clean our data, how to load it, and how to visualize it. And I will use the following technologies. Apache Flink, Apache Boom, Apache Kafka, Apache Pulsar, Apache Spark, Apache Plane, Stringlet, the Bezier, Apache Iceberg, Apache Superset. Every time I notice Apache once again, I'm looking more and more stupid. So, maybe I don't actually have to use all of these technologies, because if I do, at least I will have to be able to tell apart what is the difference between Apache Kafka and Apache Pulsar. If you cannot, don't even try to use these technologies. And what I want to do? Actually, I want just analyze data. What power data? Give me some data. I want to analyze it. I have no idea what I will get in the result. I want some interesting data set with logs, metrics, time series data. I want clicks, whatever. So, where to find this data? If you want some demos, there are plenty of sources of fairly available public updatable data sets, like Internet Archive or Zmodo.org, whatever does it mean, or Common Core, GitHub Archive, Wikipedia, blockchain data from public blockchains, whatever scans. Sometimes you can do metrics scan by yourself and get away with it, but there are plenty of downloads. So, maybe you will be surprised by my choice, but I selected the data from Wikipedia. Exactly, almost exactly as from previous talk. The data is available on dumps.wikimedia.org. It is public demoing. You can do whatever you want with it. It contains data dumps, edit history, and page view statistics. And I will analyze page view statistics. It is updated every hour and represented by about 70,000 gzip files, 3.5 terabytes. What to do is 3.5 terabytes, download it. So, the data looks like this. It looks kind of low, and I like it. And how to download it? With this shell script, it looks kind of raw, and I like it. So, what it is doing? It writes by years, it writes by month, collects on the list of links, and then simply downloading by parallel with WGET and XRX. It is rate-limited to three concurrent requests, apparently. Actually, WGET has recursive mode, but it does not have parallelism, so I decided to simply parallelize with XRX. And after about three days, data is downloaded. Let's preview it. If you decompress just one file, it looks like this. It is kind of a strange format. It is not CSV, not TSV, not JSON. It does not look like ProtoBuff. It is the white space separated file. It was just a few fields. Title, project, subproject, the number of page views, and also zero, for whatever, always zero field. How to load this data? And I like shell scripts, but I don't want to use set, oak, and parallel. Even despite I am on this open source conference, I will not use set, oak, and parallel. Instead, I will use ClickHouse local. What is ClickHouse local? It is a small tool for analytical data processing on local files or remote files without a server. You don't have to install ClickHouse to use ClickHouse local. And it can process every data format. It can process external data from external data sources, data lakes, object storages, everything. And actually, ClickHouse local is not a unique tool. There are many tools for command line data processing. Here is a list. I will not pronounce this list because I like ClickHouse local. I don't like all these tools. Installing ClickHouse local is easy. Google.sh. It is also safe because, keep in mind, it is pipe.sh, not pipe.sudo.sh. Writing it is also easy. And let's preview this data. It has interactive mode. Let's run ClickHouse local. And we can select directly from URL. What format to use? CSV does not work. CSV does not work. But there is a format, pretty simple, named line as string. What is this format? It interprets a file as a table with a single column, named line with type string. So just a single column with all our data. We can use it for just filtering. We can also select from multiple files. As in this example, we can select a file name. We can filter by something. OK. Now we have some idea what our data looks like. Now we have to clean up, prepare, structure our data, maybe convert it into another format. And I will do it with this select query. What it is doing? It is selecting from files all our 3 terabyte jzip files with line as a string. It will split the string by white space to some values, represent it as array, select elements of this array as project, sub-project, and path. Path can be URL encoded with percent encoding. I will use a function decode URL component. I will also extract the date from the file name with a function path date time best effort. And it looks like this. It is not Russian Wikipedia. It is AB Wikipedia, whatever it means. And what is AA Wikipedia? I don't know. It will be pretty interesting. Also, what I did with this 3.5 terabyte of files, I uploaded to my S3 bucket. And I just made this S3 bucket public. So until we have money, you will be able to download something. But please be kind. And you can select directly from this S3 bucket as well from all of these files. Yes, in the same way. Okay, so we just previewed our data. Now let's proceed to real data loading. Let's install a real ClickHouse server instead of ClickHouse local. But actually, there is no difference between ClickHouse local and ClickHouse client and ClickHouse server. Well, everything in a single binary. You just rename it to ClickHouse server and it automatically becomes a server. You can create a sim link. You can take this binary and install it. And it will install into user bin, user and etc. You can run it without installation. So let's start it and let's create a table. So here is a table structure. Five fields, date time, because it is time-serious, project, sub-project, page title, name it path, the number of page views, name it hits. I also enabled stronger compression with ZSTD, the standard and low cardinality data types. And this standard is just a compression codec. I will also index it by path and time. So I will be able to quickly select for specific pages. And how to load data into this table? Let's use Kafka or Pulsar and automate with Airflow and do ETL with Airbite or DBT. Actually, I don't know why DBT even exists, because I can do everything without DBT. I will do it with just insert select. Insert into Wikistat my select query from S3. And I will wait while it finishes. Let's take a look. You don't see anything. Let's make a font slightly larger. I will make a font slightly larger. Okay. Now it started to load the data. 0%, 57 CPU consumed, 2 gigabytes per second and 50 million rows per second. 50 million. I did not watch one of the previous talk. It was named loading more than a million records per second on a single server. So we are loading more than a million records per second on a single server. Okay. Let's take a look what is happening, because just loading data is not enough. It will take a while. And what to do while it is loading? I will run Distat. Distat will show me the system usage, and I see that it is bounded by IO, 500 megabytes per second, Britain. It is compressor data. IO weighed 68%. CPU weighed almost non-existing. I can also run top to see what is happening. CPU 16 cores, and it works, and IO weighed 70%. But for me, it is not enough. For me, it is not enough, because I also run this tool per top, because I always profile my code. So what my code is doing? It is doing compression, sorting, nothing. Okay. And after eight hours, my data is loaded. The table size on disk is just 700 gigabytes. Original was 3.5 terabytes, so it compressed like five times. It was in Gzip, now it is in Clickhouse, with all the column-oriented compression. The speed was 50 million rows per second, but actually, it was not true, because after eight hours, it degraded to just 14 million rows per second. Still not bad. It degraded because data has to be merged on disk, and it takes write amplification, it takes additional IO. So what is the size? 380 billion records, 0.3 trillion. The total page views on Wikipedia is just 1 trillion, 300 billion page views. Nothing surprising, Wikipedia is quite popular. And about my table. So every record took just 2.0 bytes compressed. All this title, like Wikipedia main page, it was like 50 bytes, now it is compressed to just two bytes. And if you look at compression ratio, actually path is compressed to 170 times because we sorted by path. Okay, but so what? What to do with my data? I have loaded. It took, it was 3.5 terabytes, and I can't be proud that I wasted eight hours loading this data, and it compressed so well. But what to do with this data? We need some actionable insights from this data. Let's make real-time dashboards. How to do real-time dashboard? We can use Grafana, SuperSet, Netbase, Tableau, Observable, or even Streamlit. I don't want to use Streamlit, it looks too complex, too complicated in the previous talk. And actually there is no problem, I can use Grafana, SuperSet, Netbase with Clickhouse, it works perfectly, but I am an engineer. And why to use Grafana if I can write my own Grafana in a day? Let's do it just now. Let's decide what JavaScript framework to use. I can use React, View, Swelte, I don't know what is Swelte, but it is popular. You know, if Rust were JavaScript framework, I will use Rust. Maybe I should use not JavaScript, but TypeScript. But no, I will use modern JavaScript. What is modern JavaScript? Modern JavaScript, it is when you simply open HTML file in Notepad or VI or whatever, and writing a code without frameworks, without build systems, without dependencies. Actually, I need one dependency, some charting library. And I just picked a random charting library from GitHub. Name it Uplot from Lyonya. The description Uplot is a fast memory-efficient library. Okay, solved. I will use it. Another question, how to query my database? Should I write a backend in Python in Go? No, I will query my database directly from JavaScript, from modern JavaScript with Rust API. I will use Async, await, fetch API, and post my query to the database, and it will return the data in format JSON. Okay, enough modern JavaScript. So, Clickhouse has Rust API embedded into the server. It has authentication, access control, rate limiting, quotas, query complexity limiting, parameterized queries, custom handlers, so you don't have to write a select query, you can just define a handler like slash my report, or slash insert my data. And you can actually open Clickhouse to the Internet and get away with that. I did that, it still works. Okay, here is a query for Wikipedia trends that we will use for a dashboard. It will simply select this time series rounded to some time frame, to some page. And here is a parameterized query. It looks slightly different, it's not like question mark here. It is actually a strictly typed substitution. Okay, and how long this query will take? Let me ask you, how long this query will take? What do you think? Eight days. Eight days, why eight days? It should work on a table with 0.3 trillion records. How long this query will take? Twenty milliseconds. Okay, let's experiment nine milliseconds. So, you are wrong. You are also wrong. I was scrolling back and forth. So, maybe Clickhouse is fast. What if I do my SQL, 29 milliseconds? Okay, closer. MariaDB, 20 milliseconds. What if I will replace equality comparison to like and add percent? The same, because prefix also using index. But what if I will add percent on the front? Okay, now it started to do a full scan. And this full scan was quite fast, over 1 billion records per second, but still not fast enough for real time. But all the queries with exact matching was real time. Okay, let me show you this dashboard. It looks like this modern dashboard. It looks actually gorgeous. It has dark seam. And you can see it compares trends on Wikipedia for Clickhouse. Clickhouse is growing. Spark is not growing. Green Plum is not growing. What was there? Snowflake is quite okay. Let's check it. Let's see what is inside. Every chart is defined with parameterized query. You write select. Actually, it's not even parameterized. Okay, what about MongoDB? Here I define a new chart and here is Mongo. Okay, I did one mistake. It was filtered by outliers for Snowflake. Let's move. Okay, Mongo... No, Mongo is not doing great. Clickhouse is doing great. By the way, what if you will just open a dashboard by default? It will present you observability dashboard for Clickhouse. So you can see what the system is doing. It is actually the same code, the same dashboard, but different queries. You can use parameterized queries for these parameters, change parameters, change the time frame. It's not like Grafana, it does not have features, but it is nice. And you can see, yes, it is a single HTML page and here is a proof. Okay. So what do we have? We have created real-time dashboard with Clickhouse. We have loaded 0.3 trillion records of data from a public data set. It works, it works fast, it looks great. And if you want to build... Actually, I don't insist you to use modern JavaScript. I don't insist you to query Clickhouse directly from a user browser. You can use Grafana superset meta-base. Streamlit, maybe, I'm not sure. But you can also build these small applications. And I have built quite a few. There is Clickhouse Playground where you can explore some data sets. There is a web page for Clickhouse testing infrastructure. Name it R, test green, yet you can try and check what it is. And the source code, dashboard HTML, is located in our repository. And just to note, this service is not original. I have found multiple similar services, for example, WikiShark, for the same trends on Wikipedia. But on WikiShark, there is a description that the author... I did not remember, maybe he made a PhD implementing a data structure, custom data structure for this. But he can simply load the data into Clickhouse. The experience of working with Clickhouse worth multiple PhDs. Okay. Thank you, that's it. Thank you. We do have time for multiple questions. More than JavaScript, for example. Why is this super fast? Very easy. Why this dashboard is fast? Because it's processing very fast. Why it is inserting fast? Why it is selecting fast? Because I always profile it. You have seen, I always look at what is happening inside the code. What can be optimized? If I see that, like some percent of time, spent doing nothing for mem copy, I'm thinking maybe I should optimize mem copy. Maybe I should remove mem copy. But actually a very long list about everything. But still we are talking about one machine. If one machine can process all the data. Yeah. I just created a machine on AWS with GP2 EBS, just in case. Data was in S3. I have uploaded. By the way, maybe we have time for some demos. But the resolution, the screen resolution is not. And Wi-Fi stopped to work. So probably no demos. But okay, next questions. Okay. Hello, thanks for the talk. You mentioned compression. Does that slow down select? Not quite. Actually compression can even improve select queries. It is kind of paradoxical, but let me explain. First, because less amount of data will be read from disk. Second, because data read from disk is also cached in memory, in the page cache. And the page cache will contain compressed data. And when you process this data, you will decompress this data into CPU cache without using main memory. So even... Yeah. LZ4 from multiple threads can be faster than memory bandwidth. ZSTD not always. But on servers like AMD Epic with 128 cores, if you run ZSTD decompression in every core, it has a chance to be faster than memory. Thank you. So what is your total AWS bill for this project? I prepared it yesterday and used also S3, prepared before that. So let's calculate S3 cost. I am storing the original data, three and a half terabytes. And it should be like 23. But 23 is the least price per month for terabytes. So it will be like $70 per month if you don't have AWS discounts. But I do. And for the server, the server was about $4 per hour for a server. And something for GP2. So maybe something like $5 per hour. And it is still running. I started up it yesterday when I prepared the talk. And so 24 hours will be how many? Something like maybe $50. Okay, I spent $50 for this talk. Is your S3 back in public? Yeah, it is public. So keep in mind, if you will abuse it, we will simply turn it off. Maybe another question about S3. What type of connectors do you have to S3? Is it just for uploading? Or can you also use S3 for indexing and storing data? Yes, you can. And in multiple different ways. First, just a bunch of files on S3. Process them as is. Parquet, protobufs, Avro. Avro does not matter. Everything works. Second, you can process files in Apache Delta Lake or Apache Hoodie. Asperk will be supported maybe in the next release. So you can prepare data in your data bricks or Spark. And process with Clickhouse because Clickhouse is better than Spark. Third option. You can also plug in S3 as a virtual file system for merge three tables. And it will be used not only for selects but also for inserts. And you can have your servers almost stateless. And the data will be in the object storage. Yeah, plenty of options. One more question. Yeah, for sure. You can use it in a cluster. You can set up an insert in a distributed table and it will scale linearly. And these queries will also scale. The queries that take already like 9 milliseconds, 10 milliseconds will take not less. Maybe they will take even more, like 15 milliseconds. But the queries that took seconds, minutes, they will scale linearly. Theoretically, no. But in practice, some companies are using Clickhouse on over 1,000 of nodes. Many companies are using Clickhouse on several hundreds of nodes. When you have to deal with clusters with hundreds and thousands of nodes, especially if it is geographically distributed, you will definitely have troubles. But with Clickhouse, it is totally possible to have these clusters and it will work. Another question. Interesting question because maybe you are asking about what are the data structures inside. Maybe you are asking, is Clickhouse based on some readily available data structures? The data format, Clickhouse Merge 3, is original. You can think that maybe it is somehow similar to Apache Iceberg, maybe. But actually not. The column format in memory and the network transfer format is also original, but it is very similar to Apache Arrow. That's slightly different. The algorithms, actually, we took every good algorithm from everywhere. If someone writes a blog post on the Internet like about, I have implemented the best hash table. Instantly, someone from my team will try and test it inside Clickhouse. Okay, looks like no more questions. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.0, "text": " Okay, so yeah, thank you, everyone, for coming.", "tokens": [1033, 11, 370, 1338, 11, 1309, 291, 11, 1518, 11, 337, 1348, 13], "temperature": 0.0, "avg_logprob": -0.5393689611683721, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.6292328834533691}, {"id": 1, "seek": 0, "start": 11.0, "end": 16.0, "text": " The streaming data, the last one of the day, after that, you're free to use, you know,", "tokens": [440, 11791, 1412, 11, 264, 1036, 472, 295, 264, 786, 11, 934, 300, 11, 291, 434, 1737, 281, 764, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.5393689611683721, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.6292328834533691}, {"id": 2, "seek": 0, "start": 16.0, "end": 17.0, "text": " go elsewhere.", "tokens": [352, 14517, 13], "temperature": 0.0, "avg_logprob": -0.5393689611683721, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.6292328834533691}, {"id": 3, "seek": 0, "start": 17.0, "end": 24.0, "text": " For the last one, we have a super cool talk with Alex, he is the CEO of the house.", "tokens": [1171, 264, 1036, 472, 11, 321, 362, 257, 1687, 1627, 751, 365, 5202, 11, 415, 307, 264, 9282, 295, 264, 1782, 13], "temperature": 0.0, "avg_logprob": -0.5393689611683721, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.6292328834533691}, {"id": 4, "seek": 0, "start": 24.0, "end": 29.0, "text": " Yes, he's going to tell us how to build real-time application with the house.", "tokens": [1079, 11, 415, 311, 516, 281, 980, 505, 577, 281, 1322, 957, 12, 3766, 3861, 365, 264, 1782, 13], "temperature": 0.0, "avg_logprob": -0.5393689611683721, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.6292328834533691}, {"id": 5, "seek": 2900, "start": 29.0, "end": 36.0, "text": " Yeah, thank you.", "tokens": [865, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.14816138993448286, "compression_ratio": 1.5093167701863355, "no_speech_prob": 0.0014766674721613526}, {"id": 6, "seek": 2900, "start": 36.0, "end": 40.0, "text": " So, the title of my talk is very similar to the previous.", "tokens": [407, 11, 264, 4876, 295, 452, 751, 307, 588, 2531, 281, 264, 3894, 13], "temperature": 0.0, "avg_logprob": -0.14816138993448286, "compression_ratio": 1.5093167701863355, "no_speech_prob": 0.0014766674721613526}, {"id": 7, "seek": 2900, "start": 40.0, "end": 45.0, "text": " So, let's see what will be the difference.", "tokens": [407, 11, 718, 311, 536, 437, 486, 312, 264, 2649, 13], "temperature": 0.0, "avg_logprob": -0.14816138993448286, "compression_ratio": 1.5093167701863355, "no_speech_prob": 0.0014766674721613526}, {"id": 8, "seek": 2900, "start": 45.0, "end": 52.0, "text": " I will try to build a small, simple analytical application, just about right now.", "tokens": [286, 486, 853, 281, 1322, 257, 1359, 11, 2199, 29579, 3861, 11, 445, 466, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.14816138993448286, "compression_ratio": 1.5093167701863355, "no_speech_prob": 0.0014766674721613526}, {"id": 9, "seek": 2900, "start": 52.0, "end": 55.0, "text": " And how to build an analytical application?", "tokens": [400, 577, 281, 1322, 364, 29579, 3861, 30], "temperature": 0.0, "avg_logprob": -0.14816138993448286, "compression_ratio": 1.5093167701863355, "no_speech_prob": 0.0014766674721613526}, {"id": 10, "seek": 5500, "start": 55.0, "end": 60.0, "text": " We have to figure out what to do, where to collect our data, how to prepare and clean our data,", "tokens": [492, 362, 281, 2573, 484, 437, 281, 360, 11, 689, 281, 2500, 527, 1412, 11, 577, 281, 5940, 293, 2541, 527, 1412, 11], "temperature": 0.0, "avg_logprob": -0.214229712615142, "compression_ratio": 1.603658536585366, "no_speech_prob": 0.0028126256074756384}, {"id": 11, "seek": 5500, "start": 60.0, "end": 64.0, "text": " how to load it, and how to visualize it.", "tokens": [577, 281, 3677, 309, 11, 293, 577, 281, 23273, 309, 13], "temperature": 0.0, "avg_logprob": -0.214229712615142, "compression_ratio": 1.603658536585366, "no_speech_prob": 0.0028126256074756384}, {"id": 12, "seek": 5500, "start": 64.0, "end": 72.0, "text": " And I will use the following technologies.", "tokens": [400, 286, 486, 764, 264, 3480, 7943, 13], "temperature": 0.0, "avg_logprob": -0.214229712615142, "compression_ratio": 1.603658536585366, "no_speech_prob": 0.0028126256074756384}, {"id": 13, "seek": 5500, "start": 72.0, "end": 79.0, "text": " Apache Flink, Apache Boom, Apache Kafka, Apache Pulsar, Apache Spark, Apache Plane,", "tokens": [46597, 3235, 475, 11, 46597, 15523, 11, 46597, 47064, 11, 46597, 430, 9468, 289, 11, 46597, 23424, 11, 46597, 2149, 1929, 11], "temperature": 0.0, "avg_logprob": -0.214229712615142, "compression_ratio": 1.603658536585366, "no_speech_prob": 0.0028126256074756384}, {"id": 14, "seek": 7900, "start": 79.0, "end": 85.0, "text": " Stringlet, the Bezier, Apache Iceberg, Apache Superset.", "tokens": [745, 2937, 2631, 11, 264, 879, 33352, 11, 46597, 15332, 6873, 11, 46597, 9141, 433, 302, 13], "temperature": 0.0, "avg_logprob": -0.24912332684806224, "compression_ratio": 1.5311004784688995, "no_speech_prob": 0.0019409415544942021}, {"id": 15, "seek": 7900, "start": 85.0, "end": 92.0, "text": " Every time I notice Apache once again, I'm looking more and more stupid.", "tokens": [2048, 565, 286, 3449, 46597, 1564, 797, 11, 286, 478, 1237, 544, 293, 544, 6631, 13], "temperature": 0.0, "avg_logprob": -0.24912332684806224, "compression_ratio": 1.5311004784688995, "no_speech_prob": 0.0019409415544942021}, {"id": 16, "seek": 7900, "start": 92.0, "end": 98.0, "text": " So, maybe I don't actually have to use all of these technologies, because if I do,", "tokens": [407, 11, 1310, 286, 500, 380, 767, 362, 281, 764, 439, 295, 613, 7943, 11, 570, 498, 286, 360, 11], "temperature": 0.0, "avg_logprob": -0.24912332684806224, "compression_ratio": 1.5311004784688995, "no_speech_prob": 0.0019409415544942021}, {"id": 17, "seek": 7900, "start": 98.0, "end": 105.0, "text": " at least I will have to be able to tell apart what is the difference between Apache Kafka", "tokens": [412, 1935, 286, 486, 362, 281, 312, 1075, 281, 980, 4936, 437, 307, 264, 2649, 1296, 46597, 47064], "temperature": 0.0, "avg_logprob": -0.24912332684806224, "compression_ratio": 1.5311004784688995, "no_speech_prob": 0.0019409415544942021}, {"id": 18, "seek": 7900, "start": 105.0, "end": 107.0, "text": " and Apache Pulsar.", "tokens": [293, 46597, 430, 9468, 289, 13], "temperature": 0.0, "avg_logprob": -0.24912332684806224, "compression_ratio": 1.5311004784688995, "no_speech_prob": 0.0019409415544942021}, {"id": 19, "seek": 10700, "start": 107.0, "end": 115.0, "text": " If you cannot, don't even try to use these technologies.", "tokens": [759, 291, 2644, 11, 500, 380, 754, 853, 281, 764, 613, 7943, 13], "temperature": 0.0, "avg_logprob": -0.12835218740064044, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0006644462700933218}, {"id": 20, "seek": 10700, "start": 115.0, "end": 117.0, "text": " And what I want to do?", "tokens": [400, 437, 286, 528, 281, 360, 30], "temperature": 0.0, "avg_logprob": -0.12835218740064044, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0006644462700933218}, {"id": 21, "seek": 10700, "start": 117.0, "end": 120.0, "text": " Actually, I want just analyze data.", "tokens": [5135, 11, 286, 528, 445, 12477, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12835218740064044, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0006644462700933218}, {"id": 22, "seek": 10700, "start": 120.0, "end": 123.0, "text": " What power data? Give me some data.", "tokens": [708, 1347, 1412, 30, 5303, 385, 512, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12835218740064044, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0006644462700933218}, {"id": 23, "seek": 10700, "start": 123.0, "end": 124.0, "text": " I want to analyze it.", "tokens": [286, 528, 281, 12477, 309, 13], "temperature": 0.0, "avg_logprob": -0.12835218740064044, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0006644462700933218}, {"id": 24, "seek": 10700, "start": 124.0, "end": 128.0, "text": " I have no idea what I will get in the result.", "tokens": [286, 362, 572, 1558, 437, 286, 486, 483, 294, 264, 1874, 13], "temperature": 0.0, "avg_logprob": -0.12835218740064044, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0006644462700933218}, {"id": 25, "seek": 10700, "start": 128.0, "end": 134.0, "text": " I want some interesting data set with logs, metrics, time series data.", "tokens": [286, 528, 512, 1880, 1412, 992, 365, 20820, 11, 16367, 11, 565, 2638, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12835218740064044, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0006644462700933218}, {"id": 26, "seek": 13400, "start": 134.0, "end": 139.0, "text": " I want clicks, whatever.", "tokens": [286, 528, 18521, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.31336407661437987, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.0019748948980122805}, {"id": 27, "seek": 13400, "start": 139.0, "end": 141.0, "text": " So, where to find this data?", "tokens": [407, 11, 689, 281, 915, 341, 1412, 30], "temperature": 0.0, "avg_logprob": -0.31336407661437987, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.0019748948980122805}, {"id": 28, "seek": 13400, "start": 141.0, "end": 147.0, "text": " If you want some demos, there are plenty of sources of fairly available public", "tokens": [759, 291, 528, 512, 33788, 11, 456, 366, 7140, 295, 7139, 295, 6457, 2435, 1908], "temperature": 0.0, "avg_logprob": -0.31336407661437987, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.0019748948980122805}, {"id": 29, "seek": 13400, "start": 147.0, "end": 155.0, "text": " updatable data sets, like Internet Archive or Zmodo.org, whatever does it mean,", "tokens": [3460, 31415, 1412, 6352, 11, 411, 7703, 10984, 488, 420, 1176, 8014, 78, 13, 4646, 11, 2035, 775, 309, 914, 11], "temperature": 0.0, "avg_logprob": -0.31336407661437987, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.0019748948980122805}, {"id": 30, "seek": 13400, "start": 155.0, "end": 162.0, "text": " or Common Core, GitHub Archive, Wikipedia, blockchain data from public blockchains,", "tokens": [420, 18235, 14798, 11, 23331, 10984, 488, 11, 28999, 11, 17176, 1412, 490, 1908, 3461, 339, 2315, 11], "temperature": 0.0, "avg_logprob": -0.31336407661437987, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.0019748948980122805}, {"id": 31, "seek": 16200, "start": 162.0, "end": 164.0, "text": " whatever scans.", "tokens": [2035, 35116, 13], "temperature": 0.0, "avg_logprob": -0.20544977486133575, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.0010936493054032326}, {"id": 32, "seek": 16200, "start": 164.0, "end": 171.0, "text": " Sometimes you can do metrics scan by yourself and get away with it, but there are", "tokens": [4803, 291, 393, 360, 16367, 11049, 538, 1803, 293, 483, 1314, 365, 309, 11, 457, 456, 366], "temperature": 0.0, "avg_logprob": -0.20544977486133575, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.0010936493054032326}, {"id": 33, "seek": 16200, "start": 171.0, "end": 173.0, "text": " plenty of downloads.", "tokens": [7140, 295, 36553, 13], "temperature": 0.0, "avg_logprob": -0.20544977486133575, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.0010936493054032326}, {"id": 34, "seek": 16200, "start": 173.0, "end": 181.0, "text": " So, maybe you will be surprised by my choice, but I selected the data from Wikipedia.", "tokens": [407, 11, 1310, 291, 486, 312, 6100, 538, 452, 3922, 11, 457, 286, 8209, 264, 1412, 490, 28999, 13], "temperature": 0.0, "avg_logprob": -0.20544977486133575, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.0010936493054032326}, {"id": 35, "seek": 16200, "start": 181.0, "end": 185.0, "text": " Exactly, almost exactly as from previous talk.", "tokens": [7587, 11, 1920, 2293, 382, 490, 3894, 751, 13], "temperature": 0.0, "avg_logprob": -0.20544977486133575, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.0010936493054032326}, {"id": 36, "seek": 18500, "start": 185.0, "end": 192.0, "text": " The data is available on dumps.wikimedia.org.", "tokens": [440, 1412, 307, 2435, 322, 11430, 82, 13, 86, 1035, 332, 14212, 13, 4646, 13], "temperature": 0.0, "avg_logprob": -0.18144257366657257, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.0031523408833891153}, {"id": 37, "seek": 18500, "start": 192.0, "end": 194.0, "text": " It is public demoing.", "tokens": [467, 307, 1908, 10723, 278, 13], "temperature": 0.0, "avg_logprob": -0.18144257366657257, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.0031523408833891153}, {"id": 38, "seek": 18500, "start": 194.0, "end": 196.0, "text": " You can do whatever you want with it.", "tokens": [509, 393, 360, 2035, 291, 528, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.18144257366657257, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.0031523408833891153}, {"id": 39, "seek": 18500, "start": 196.0, "end": 201.0, "text": " It contains data dumps, edit history, and page view statistics.", "tokens": [467, 8306, 1412, 11430, 82, 11, 8129, 2503, 11, 293, 3028, 1910, 12523, 13], "temperature": 0.0, "avg_logprob": -0.18144257366657257, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.0031523408833891153}, {"id": 40, "seek": 18500, "start": 201.0, "end": 207.0, "text": " And I will analyze page view statistics.", "tokens": [400, 286, 486, 12477, 3028, 1910, 12523, 13], "temperature": 0.0, "avg_logprob": -0.18144257366657257, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.0031523408833891153}, {"id": 41, "seek": 20700, "start": 207.0, "end": 215.0, "text": " It is updated every hour and represented by about 70,000 gzip files,", "tokens": [467, 307, 10588, 633, 1773, 293, 10379, 538, 466, 5285, 11, 1360, 290, 27268, 7098, 11], "temperature": 0.0, "avg_logprob": -0.16471022528571053, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.0014214424882084131}, {"id": 42, "seek": 20700, "start": 215.0, "end": 217.0, "text": " 3.5 terabytes.", "tokens": [805, 13, 20, 1796, 24538, 13], "temperature": 0.0, "avg_logprob": -0.16471022528571053, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.0014214424882084131}, {"id": 43, "seek": 20700, "start": 217.0, "end": 226.0, "text": " What to do is 3.5 terabytes, download it.", "tokens": [708, 281, 360, 307, 805, 13, 20, 1796, 24538, 11, 5484, 309, 13], "temperature": 0.0, "avg_logprob": -0.16471022528571053, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.0014214424882084131}, {"id": 44, "seek": 20700, "start": 226.0, "end": 229.0, "text": " So, the data looks like this.", "tokens": [407, 11, 264, 1412, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.16471022528571053, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.0014214424882084131}, {"id": 45, "seek": 20700, "start": 229.0, "end": 234.0, "text": " It looks kind of low, and I like it.", "tokens": [467, 1542, 733, 295, 2295, 11, 293, 286, 411, 309, 13], "temperature": 0.0, "avg_logprob": -0.16471022528571053, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.0014214424882084131}, {"id": 46, "seek": 20700, "start": 234.0, "end": 236.0, "text": " And how to download it?", "tokens": [400, 577, 281, 5484, 309, 30], "temperature": 0.0, "avg_logprob": -0.16471022528571053, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.0014214424882084131}, {"id": 47, "seek": 23600, "start": 236.0, "end": 243.0, "text": " With this shell script, it looks kind of raw, and I like it.", "tokens": [2022, 341, 8720, 5755, 11, 309, 1542, 733, 295, 8936, 11, 293, 286, 411, 309, 13], "temperature": 0.0, "avg_logprob": -0.21002522982083835, "compression_ratio": 1.358974358974359, "no_speech_prob": 0.0014165708562359214}, {"id": 48, "seek": 23600, "start": 243.0, "end": 246.0, "text": " So, what it is doing?", "tokens": [407, 11, 437, 309, 307, 884, 30], "temperature": 0.0, "avg_logprob": -0.21002522982083835, "compression_ratio": 1.358974358974359, "no_speech_prob": 0.0014165708562359214}, {"id": 49, "seek": 23600, "start": 246.0, "end": 254.0, "text": " It writes by years, it writes by month, collects on the list of links,", "tokens": [467, 13657, 538, 924, 11, 309, 13657, 538, 1618, 11, 39897, 322, 264, 1329, 295, 6123, 11], "temperature": 0.0, "avg_logprob": -0.21002522982083835, "compression_ratio": 1.358974358974359, "no_speech_prob": 0.0014165708562359214}, {"id": 50, "seek": 23600, "start": 254.0, "end": 260.0, "text": " and then simply downloading by parallel with WGET and XRX.", "tokens": [293, 550, 2935, 32529, 538, 8952, 365, 343, 38, 4850, 293, 1783, 49, 55, 13], "temperature": 0.0, "avg_logprob": -0.21002522982083835, "compression_ratio": 1.358974358974359, "no_speech_prob": 0.0014165708562359214}, {"id": 51, "seek": 26000, "start": 260.0, "end": 266.0, "text": " It is rate-limited to three concurrent requests, apparently.", "tokens": [467, 307, 3314, 12, 18692, 281, 1045, 37702, 12475, 11, 7970, 13], "temperature": 0.0, "avg_logprob": -0.0961675713027733, "compression_ratio": 1.348314606741573, "no_speech_prob": 0.000670224369969219}, {"id": 52, "seek": 26000, "start": 266.0, "end": 272.0, "text": " Actually, WGET has recursive mode, but it does not have parallelism,", "tokens": [5135, 11, 343, 38, 4850, 575, 20560, 488, 4391, 11, 457, 309, 775, 406, 362, 8952, 1434, 11], "temperature": 0.0, "avg_logprob": -0.0961675713027733, "compression_ratio": 1.348314606741573, "no_speech_prob": 0.000670224369969219}, {"id": 53, "seek": 26000, "start": 272.0, "end": 278.0, "text": " so I decided to simply parallelize with XRX.", "tokens": [370, 286, 3047, 281, 2935, 8952, 1125, 365, 1783, 49, 55, 13], "temperature": 0.0, "avg_logprob": -0.0961675713027733, "compression_ratio": 1.348314606741573, "no_speech_prob": 0.000670224369969219}, {"id": 54, "seek": 26000, "start": 278.0, "end": 285.0, "text": " And after about three days, data is downloaded.", "tokens": [400, 934, 466, 1045, 1708, 11, 1412, 307, 21748, 13], "temperature": 0.0, "avg_logprob": -0.0961675713027733, "compression_ratio": 1.348314606741573, "no_speech_prob": 0.000670224369969219}, {"id": 55, "seek": 26000, "start": 285.0, "end": 288.0, "text": " Let's preview it.", "tokens": [961, 311, 14281, 309, 13], "temperature": 0.0, "avg_logprob": -0.0961675713027733, "compression_ratio": 1.348314606741573, "no_speech_prob": 0.000670224369969219}, {"id": 56, "seek": 28800, "start": 288.0, "end": 292.0, "text": " If you decompress just one file, it looks like this.", "tokens": [759, 291, 22867, 735, 445, 472, 3991, 11, 309, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1194664228080523, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0009602489299140871}, {"id": 57, "seek": 28800, "start": 292.0, "end": 294.0, "text": " It is kind of a strange format.", "tokens": [467, 307, 733, 295, 257, 5861, 7877, 13], "temperature": 0.0, "avg_logprob": -0.1194664228080523, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0009602489299140871}, {"id": 58, "seek": 28800, "start": 294.0, "end": 300.0, "text": " It is not CSV, not TSV, not JSON.", "tokens": [467, 307, 406, 48814, 11, 406, 37645, 53, 11, 406, 31828, 13], "temperature": 0.0, "avg_logprob": -0.1194664228080523, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0009602489299140871}, {"id": 59, "seek": 28800, "start": 300.0, "end": 302.0, "text": " It does not look like ProtoBuff.", "tokens": [467, 775, 406, 574, 411, 2114, 6738, 33, 1245, 13], "temperature": 0.0, "avg_logprob": -0.1194664228080523, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0009602489299140871}, {"id": 60, "seek": 28800, "start": 302.0, "end": 306.0, "text": " It is the white space separated file.", "tokens": [467, 307, 264, 2418, 1901, 12005, 3991, 13], "temperature": 0.0, "avg_logprob": -0.1194664228080523, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0009602489299140871}, {"id": 61, "seek": 28800, "start": 306.0, "end": 308.0, "text": " It was just a few fields.", "tokens": [467, 390, 445, 257, 1326, 7909, 13], "temperature": 0.0, "avg_logprob": -0.1194664228080523, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0009602489299140871}, {"id": 62, "seek": 28800, "start": 308.0, "end": 312.0, "text": " Title, project, subproject, the number of page views,", "tokens": [26768, 11, 1716, 11, 1422, 4318, 1020, 11, 264, 1230, 295, 3028, 6809, 11], "temperature": 0.0, "avg_logprob": -0.1194664228080523, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0009602489299140871}, {"id": 63, "seek": 28800, "start": 312.0, "end": 317.0, "text": " and also zero, for whatever, always zero field.", "tokens": [293, 611, 4018, 11, 337, 2035, 11, 1009, 4018, 2519, 13], "temperature": 0.0, "avg_logprob": -0.1194664228080523, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0009602489299140871}, {"id": 64, "seek": 31700, "start": 317.0, "end": 319.0, "text": " How to load this data?", "tokens": [1012, 281, 3677, 341, 1412, 30], "temperature": 0.0, "avg_logprob": -0.13960222179970044, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.0010249405167996883}, {"id": 65, "seek": 31700, "start": 319.0, "end": 325.0, "text": " And I like shell scripts, but I don't want to use set, oak, and parallel.", "tokens": [400, 286, 411, 8720, 23294, 11, 457, 286, 500, 380, 528, 281, 764, 992, 11, 31322, 11, 293, 8952, 13], "temperature": 0.0, "avg_logprob": -0.13960222179970044, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.0010249405167996883}, {"id": 66, "seek": 31700, "start": 325.0, "end": 329.0, "text": " Even despite I am on this open source conference,", "tokens": [2754, 7228, 286, 669, 322, 341, 1269, 4009, 7586, 11], "temperature": 0.0, "avg_logprob": -0.13960222179970044, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.0010249405167996883}, {"id": 67, "seek": 31700, "start": 329.0, "end": 333.0, "text": " I will not use set, oak, and parallel.", "tokens": [286, 486, 406, 764, 992, 11, 31322, 11, 293, 8952, 13], "temperature": 0.0, "avg_logprob": -0.13960222179970044, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.0010249405167996883}, {"id": 68, "seek": 31700, "start": 333.0, "end": 337.0, "text": " Instead, I will use ClickHouse local.", "tokens": [7156, 11, 286, 486, 764, 8230, 39, 1316, 2654, 13], "temperature": 0.0, "avg_logprob": -0.13960222179970044, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.0010249405167996883}, {"id": 69, "seek": 31700, "start": 337.0, "end": 339.0, "text": " What is ClickHouse local?", "tokens": [708, 307, 8230, 39, 1316, 2654, 30], "temperature": 0.0, "avg_logprob": -0.13960222179970044, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.0010249405167996883}, {"id": 70, "seek": 31700, "start": 339.0, "end": 344.0, "text": " It is a small tool for analytical data processing", "tokens": [467, 307, 257, 1359, 2290, 337, 29579, 1412, 9007], "temperature": 0.0, "avg_logprob": -0.13960222179970044, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.0010249405167996883}, {"id": 71, "seek": 34400, "start": 344.0, "end": 349.0, "text": " on local files or remote files without a server.", "tokens": [322, 2654, 7098, 420, 8607, 7098, 1553, 257, 7154, 13], "temperature": 0.0, "avg_logprob": -0.07272158861160279, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.0003755807410925627}, {"id": 72, "seek": 34400, "start": 349.0, "end": 353.0, "text": " You don't have to install ClickHouse to use ClickHouse local.", "tokens": [509, 500, 380, 362, 281, 3625, 8230, 39, 1316, 281, 764, 8230, 39, 1316, 2654, 13], "temperature": 0.0, "avg_logprob": -0.07272158861160279, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.0003755807410925627}, {"id": 73, "seek": 34400, "start": 353.0, "end": 358.0, "text": " And it can process every data format.", "tokens": [400, 309, 393, 1399, 633, 1412, 7877, 13], "temperature": 0.0, "avg_logprob": -0.07272158861160279, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.0003755807410925627}, {"id": 74, "seek": 34400, "start": 358.0, "end": 361.0, "text": " It can process external data from external data sources,", "tokens": [467, 393, 1399, 8320, 1412, 490, 8320, 1412, 7139, 11], "temperature": 0.0, "avg_logprob": -0.07272158861160279, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.0003755807410925627}, {"id": 75, "seek": 34400, "start": 361.0, "end": 367.0, "text": " data lakes, object storages, everything.", "tokens": [1412, 25595, 11, 2657, 5967, 1660, 11, 1203, 13], "temperature": 0.0, "avg_logprob": -0.07272158861160279, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.0003755807410925627}, {"id": 76, "seek": 34400, "start": 367.0, "end": 371.0, "text": " And actually, ClickHouse local is not a unique tool.", "tokens": [400, 767, 11, 8230, 39, 1316, 2654, 307, 406, 257, 3845, 2290, 13], "temperature": 0.0, "avg_logprob": -0.07272158861160279, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.0003755807410925627}, {"id": 77, "seek": 37100, "start": 371.0, "end": 374.0, "text": " There are many tools for command line data processing.", "tokens": [821, 366, 867, 3873, 337, 5622, 1622, 1412, 9007, 13], "temperature": 0.0, "avg_logprob": -0.1334659949592922, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.00039833845221437514}, {"id": 78, "seek": 37100, "start": 374.0, "end": 376.0, "text": " Here is a list.", "tokens": [1692, 307, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.1334659949592922, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.00039833845221437514}, {"id": 79, "seek": 37100, "start": 376.0, "end": 381.0, "text": " I will not pronounce this list because I like ClickHouse local.", "tokens": [286, 486, 406, 19567, 341, 1329, 570, 286, 411, 8230, 39, 1316, 2654, 13], "temperature": 0.0, "avg_logprob": -0.1334659949592922, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.00039833845221437514}, {"id": 80, "seek": 37100, "start": 381.0, "end": 385.0, "text": " I don't like all these tools.", "tokens": [286, 500, 380, 411, 439, 613, 3873, 13], "temperature": 0.0, "avg_logprob": -0.1334659949592922, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.00039833845221437514}, {"id": 81, "seek": 37100, "start": 385.0, "end": 388.0, "text": " Installing ClickHouse local is easy.", "tokens": [2730, 24021, 8230, 39, 1316, 2654, 307, 1858, 13], "temperature": 0.0, "avg_logprob": -0.1334659949592922, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.00039833845221437514}, {"id": 82, "seek": 37100, "start": 388.0, "end": 389.0, "text": " Google.sh.", "tokens": [3329, 13, 2716, 13], "temperature": 0.0, "avg_logprob": -0.1334659949592922, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.00039833845221437514}, {"id": 83, "seek": 37100, "start": 389.0, "end": 393.0, "text": " It is also safe because, keep in mind, it is pipe.sh,", "tokens": [467, 307, 611, 3273, 570, 11, 1066, 294, 1575, 11, 309, 307, 11240, 13, 2716, 11], "temperature": 0.0, "avg_logprob": -0.1334659949592922, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.00039833845221437514}, {"id": 84, "seek": 37100, "start": 393.0, "end": 398.0, "text": " not pipe.sudo.sh.", "tokens": [406, 11240, 13, 82, 6207, 13, 2716, 13], "temperature": 0.0, "avg_logprob": -0.1334659949592922, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.00039833845221437514}, {"id": 85, "seek": 39800, "start": 398.0, "end": 402.0, "text": " Writing it is also easy.", "tokens": [32774, 309, 307, 611, 1858, 13], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 86, "seek": 39800, "start": 402.0, "end": 404.0, "text": " And let's preview this data.", "tokens": [400, 718, 311, 14281, 341, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 87, "seek": 39800, "start": 404.0, "end": 406.0, "text": " It has interactive mode.", "tokens": [467, 575, 15141, 4391, 13], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 88, "seek": 39800, "start": 406.0, "end": 408.0, "text": " Let's run ClickHouse local.", "tokens": [961, 311, 1190, 8230, 39, 1316, 2654, 13], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 89, "seek": 39800, "start": 408.0, "end": 412.0, "text": " And we can select directly from URL.", "tokens": [400, 321, 393, 3048, 3838, 490, 12905, 13], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 90, "seek": 39800, "start": 412.0, "end": 414.0, "text": " What format to use?", "tokens": [708, 7877, 281, 764, 30], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 91, "seek": 39800, "start": 414.0, "end": 415.0, "text": " CSV does not work.", "tokens": [48814, 775, 406, 589, 13], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 92, "seek": 39800, "start": 415.0, "end": 417.0, "text": " CSV does not work.", "tokens": [48814, 775, 406, 589, 13], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 93, "seek": 39800, "start": 417.0, "end": 421.0, "text": " But there is a format, pretty simple, named line as string.", "tokens": [583, 456, 307, 257, 7877, 11, 1238, 2199, 11, 4926, 1622, 382, 6798, 13], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 94, "seek": 39800, "start": 421.0, "end": 423.0, "text": " What is this format?", "tokens": [708, 307, 341, 7877, 30], "temperature": 0.0, "avg_logprob": -0.12407525380452473, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.0014171232469379902}, {"id": 95, "seek": 42300, "start": 423.0, "end": 429.0, "text": " It interprets a file as a table with a single column,", "tokens": [467, 17489, 1373, 257, 3991, 382, 257, 3199, 365, 257, 2167, 7738, 11], "temperature": 0.0, "avg_logprob": -0.09620108785508555, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.0007814608397893608}, {"id": 96, "seek": 42300, "start": 429.0, "end": 433.0, "text": " named line with type string.", "tokens": [4926, 1622, 365, 2010, 6798, 13], "temperature": 0.0, "avg_logprob": -0.09620108785508555, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.0007814608397893608}, {"id": 97, "seek": 42300, "start": 433.0, "end": 436.0, "text": " So just a single column with all our data.", "tokens": [407, 445, 257, 2167, 7738, 365, 439, 527, 1412, 13], "temperature": 0.0, "avg_logprob": -0.09620108785508555, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.0007814608397893608}, {"id": 98, "seek": 42300, "start": 436.0, "end": 440.0, "text": " We can use it for just filtering.", "tokens": [492, 393, 764, 309, 337, 445, 30822, 13], "temperature": 0.0, "avg_logprob": -0.09620108785508555, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.0007814608397893608}, {"id": 99, "seek": 42300, "start": 440.0, "end": 443.0, "text": " We can also select from multiple files.", "tokens": [492, 393, 611, 3048, 490, 3866, 7098, 13], "temperature": 0.0, "avg_logprob": -0.09620108785508555, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.0007814608397893608}, {"id": 100, "seek": 42300, "start": 443.0, "end": 448.0, "text": " As in this example, we can select a file name.", "tokens": [1018, 294, 341, 1365, 11, 321, 393, 3048, 257, 3991, 1315, 13], "temperature": 0.0, "avg_logprob": -0.09620108785508555, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.0007814608397893608}, {"id": 101, "seek": 42300, "start": 448.0, "end": 452.0, "text": " We can filter by something.", "tokens": [492, 393, 6608, 538, 746, 13], "temperature": 0.0, "avg_logprob": -0.09620108785508555, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.0007814608397893608}, {"id": 102, "seek": 45200, "start": 452.0, "end": 453.0, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.13526925479664523, "compression_ratio": 1.46875, "no_speech_prob": 0.00040453800465911627}, {"id": 103, "seek": 45200, "start": 453.0, "end": 458.0, "text": " Now we have some idea what our data looks like.", "tokens": [823, 321, 362, 512, 1558, 437, 527, 1412, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.13526925479664523, "compression_ratio": 1.46875, "no_speech_prob": 0.00040453800465911627}, {"id": 104, "seek": 45200, "start": 458.0, "end": 461.0, "text": " Now we have to clean up, prepare,", "tokens": [823, 321, 362, 281, 2541, 493, 11, 5940, 11], "temperature": 0.0, "avg_logprob": -0.13526925479664523, "compression_ratio": 1.46875, "no_speech_prob": 0.00040453800465911627}, {"id": 105, "seek": 45200, "start": 461.0, "end": 466.0, "text": " structure our data, maybe convert it into another format.", "tokens": [3877, 527, 1412, 11, 1310, 7620, 309, 666, 1071, 7877, 13], "temperature": 0.0, "avg_logprob": -0.13526925479664523, "compression_ratio": 1.46875, "no_speech_prob": 0.00040453800465911627}, {"id": 106, "seek": 45200, "start": 466.0, "end": 471.0, "text": " And I will do it with this select query.", "tokens": [400, 286, 486, 360, 309, 365, 341, 3048, 14581, 13], "temperature": 0.0, "avg_logprob": -0.13526925479664523, "compression_ratio": 1.46875, "no_speech_prob": 0.00040453800465911627}, {"id": 107, "seek": 45200, "start": 471.0, "end": 473.0, "text": " What it is doing?", "tokens": [708, 309, 307, 884, 30], "temperature": 0.0, "avg_logprob": -0.13526925479664523, "compression_ratio": 1.46875, "no_speech_prob": 0.00040453800465911627}, {"id": 108, "seek": 45200, "start": 473.0, "end": 479.0, "text": " It is selecting from files all our 3 terabyte jzip files", "tokens": [467, 307, 18182, 490, 7098, 439, 527, 805, 1796, 34529, 361, 27268, 7098], "temperature": 0.0, "avg_logprob": -0.13526925479664523, "compression_ratio": 1.46875, "no_speech_prob": 0.00040453800465911627}, {"id": 109, "seek": 45200, "start": 479.0, "end": 481.0, "text": " with line as a string.", "tokens": [365, 1622, 382, 257, 6798, 13], "temperature": 0.0, "avg_logprob": -0.13526925479664523, "compression_ratio": 1.46875, "no_speech_prob": 0.00040453800465911627}, {"id": 110, "seek": 48100, "start": 481.0, "end": 487.0, "text": " It will split the string by white space to some values,", "tokens": [467, 486, 7472, 264, 6798, 538, 2418, 1901, 281, 512, 4190, 11], "temperature": 0.0, "avg_logprob": -0.12191179201200411, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0007532465388067067}, {"id": 111, "seek": 48100, "start": 487.0, "end": 491.0, "text": " represent it as array, select elements of this array", "tokens": [2906, 309, 382, 10225, 11, 3048, 4959, 295, 341, 10225], "temperature": 0.0, "avg_logprob": -0.12191179201200411, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0007532465388067067}, {"id": 112, "seek": 48100, "start": 491.0, "end": 495.0, "text": " as project, sub-project, and path.", "tokens": [382, 1716, 11, 1422, 12, 4318, 1020, 11, 293, 3100, 13], "temperature": 0.0, "avg_logprob": -0.12191179201200411, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0007532465388067067}, {"id": 113, "seek": 48100, "start": 495.0, "end": 499.0, "text": " Path can be URL encoded with percent encoding.", "tokens": [21914, 393, 312, 12905, 2058, 12340, 365, 3043, 43430, 13], "temperature": 0.0, "avg_logprob": -0.12191179201200411, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0007532465388067067}, {"id": 114, "seek": 48100, "start": 499.0, "end": 503.0, "text": " I will use a function decode URL component.", "tokens": [286, 486, 764, 257, 2445, 979, 1429, 12905, 6542, 13], "temperature": 0.0, "avg_logprob": -0.12191179201200411, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0007532465388067067}, {"id": 115, "seek": 48100, "start": 503.0, "end": 507.0, "text": " I will also extract the date from the file name", "tokens": [286, 486, 611, 8947, 264, 4002, 490, 264, 3991, 1315], "temperature": 0.0, "avg_logprob": -0.12191179201200411, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0007532465388067067}, {"id": 116, "seek": 50700, "start": 507.0, "end": 511.0, "text": " with a function path date time best effort.", "tokens": [365, 257, 2445, 3100, 4002, 565, 1151, 4630, 13], "temperature": 0.0, "avg_logprob": -0.14010583162307738, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0002676484000403434}, {"id": 117, "seek": 50700, "start": 511.0, "end": 514.0, "text": " And it looks like this.", "tokens": [400, 309, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.14010583162307738, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0002676484000403434}, {"id": 118, "seek": 50700, "start": 514.0, "end": 516.0, "text": " It is not Russian Wikipedia.", "tokens": [467, 307, 406, 7220, 28999, 13], "temperature": 0.0, "avg_logprob": -0.14010583162307738, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0002676484000403434}, {"id": 119, "seek": 50700, "start": 516.0, "end": 524.0, "text": " It is AB Wikipedia, whatever it means.", "tokens": [467, 307, 13838, 28999, 11, 2035, 309, 1355, 13], "temperature": 0.0, "avg_logprob": -0.14010583162307738, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0002676484000403434}, {"id": 120, "seek": 50700, "start": 524.0, "end": 526.0, "text": " And what is AA Wikipedia?", "tokens": [400, 437, 307, 30680, 28999, 30], "temperature": 0.0, "avg_logprob": -0.14010583162307738, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0002676484000403434}, {"id": 121, "seek": 50700, "start": 526.0, "end": 528.0, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.14010583162307738, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0002676484000403434}, {"id": 122, "seek": 50700, "start": 528.0, "end": 530.0, "text": " It will be pretty interesting.", "tokens": [467, 486, 312, 1238, 1880, 13], "temperature": 0.0, "avg_logprob": -0.14010583162307738, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0002676484000403434}, {"id": 123, "seek": 50700, "start": 530.0, "end": 534.0, "text": " Also, what I did with this 3.5 terabyte of files,", "tokens": [2743, 11, 437, 286, 630, 365, 341, 805, 13, 20, 1796, 34529, 295, 7098, 11], "temperature": 0.0, "avg_logprob": -0.14010583162307738, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0002676484000403434}, {"id": 124, "seek": 53400, "start": 534.0, "end": 537.0, "text": " I uploaded to my S3 bucket.", "tokens": [286, 17135, 281, 452, 318, 18, 13058, 13], "temperature": 0.0, "avg_logprob": -0.11268543851548347, "compression_ratio": 1.4528301886792452, "no_speech_prob": 0.0009279216174036264}, {"id": 125, "seek": 53400, "start": 537.0, "end": 540.0, "text": " And I just made this S3 bucket public.", "tokens": [400, 286, 445, 1027, 341, 318, 18, 13058, 1908, 13], "temperature": 0.0, "avg_logprob": -0.11268543851548347, "compression_ratio": 1.4528301886792452, "no_speech_prob": 0.0009279216174036264}, {"id": 126, "seek": 53400, "start": 540.0, "end": 549.0, "text": " So until we have money, you will be able to download something.", "tokens": [407, 1826, 321, 362, 1460, 11, 291, 486, 312, 1075, 281, 5484, 746, 13], "temperature": 0.0, "avg_logprob": -0.11268543851548347, "compression_ratio": 1.4528301886792452, "no_speech_prob": 0.0009279216174036264}, {"id": 127, "seek": 53400, "start": 549.0, "end": 552.0, "text": " But please be kind.", "tokens": [583, 1767, 312, 733, 13], "temperature": 0.0, "avg_logprob": -0.11268543851548347, "compression_ratio": 1.4528301886792452, "no_speech_prob": 0.0009279216174036264}, {"id": 128, "seek": 53400, "start": 552.0, "end": 557.0, "text": " And you can select directly from this S3 bucket as well", "tokens": [400, 291, 393, 3048, 3838, 490, 341, 318, 18, 13058, 382, 731], "temperature": 0.0, "avg_logprob": -0.11268543851548347, "compression_ratio": 1.4528301886792452, "no_speech_prob": 0.0009279216174036264}, {"id": 129, "seek": 53400, "start": 557.0, "end": 559.0, "text": " from all of these files.", "tokens": [490, 439, 295, 613, 7098, 13], "temperature": 0.0, "avg_logprob": -0.11268543851548347, "compression_ratio": 1.4528301886792452, "no_speech_prob": 0.0009279216174036264}, {"id": 130, "seek": 55900, "start": 559.0, "end": 564.0, "text": " Yes, in the same way.", "tokens": [1079, 11, 294, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.10897743271057864, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00035296601708978415}, {"id": 131, "seek": 55900, "start": 564.0, "end": 570.0, "text": " Okay, so we just previewed our data.", "tokens": [1033, 11, 370, 321, 445, 14281, 292, 527, 1412, 13], "temperature": 0.0, "avg_logprob": -0.10897743271057864, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00035296601708978415}, {"id": 132, "seek": 55900, "start": 570.0, "end": 574.0, "text": " Now let's proceed to real data loading.", "tokens": [823, 718, 311, 8991, 281, 957, 1412, 15114, 13], "temperature": 0.0, "avg_logprob": -0.10897743271057864, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00035296601708978415}, {"id": 133, "seek": 55900, "start": 574.0, "end": 577.0, "text": " Let's install a real ClickHouse server", "tokens": [961, 311, 3625, 257, 957, 8230, 39, 1316, 7154], "temperature": 0.0, "avg_logprob": -0.10897743271057864, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00035296601708978415}, {"id": 134, "seek": 55900, "start": 577.0, "end": 579.0, "text": " instead of ClickHouse local.", "tokens": [2602, 295, 8230, 39, 1316, 2654, 13], "temperature": 0.0, "avg_logprob": -0.10897743271057864, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00035296601708978415}, {"id": 135, "seek": 55900, "start": 579.0, "end": 582.0, "text": " But actually, there is no difference", "tokens": [583, 767, 11, 456, 307, 572, 2649], "temperature": 0.0, "avg_logprob": -0.10897743271057864, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00035296601708978415}, {"id": 136, "seek": 55900, "start": 582.0, "end": 585.0, "text": " between ClickHouse local and ClickHouse client", "tokens": [1296, 8230, 39, 1316, 2654, 293, 8230, 39, 1316, 6423], "temperature": 0.0, "avg_logprob": -0.10897743271057864, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00035296601708978415}, {"id": 137, "seek": 55900, "start": 585.0, "end": 587.0, "text": " and ClickHouse server.", "tokens": [293, 8230, 39, 1316, 7154, 13], "temperature": 0.0, "avg_logprob": -0.10897743271057864, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00035296601708978415}, {"id": 138, "seek": 58700, "start": 587.0, "end": 591.0, "text": " Well, everything in a single binary.", "tokens": [1042, 11, 1203, 294, 257, 2167, 17434, 13], "temperature": 0.0, "avg_logprob": -0.1099264653523763, "compression_ratio": 1.6303030303030304, "no_speech_prob": 0.0013166574062779546}, {"id": 139, "seek": 58700, "start": 591.0, "end": 593.0, "text": " You just rename it to ClickHouse server", "tokens": [509, 445, 36741, 309, 281, 8230, 39, 1316, 7154], "temperature": 0.0, "avg_logprob": -0.1099264653523763, "compression_ratio": 1.6303030303030304, "no_speech_prob": 0.0013166574062779546}, {"id": 140, "seek": 58700, "start": 593.0, "end": 597.0, "text": " and it automatically becomes a server.", "tokens": [293, 309, 6772, 3643, 257, 7154, 13], "temperature": 0.0, "avg_logprob": -0.1099264653523763, "compression_ratio": 1.6303030303030304, "no_speech_prob": 0.0013166574062779546}, {"id": 141, "seek": 58700, "start": 597.0, "end": 600.0, "text": " You can create a sim link.", "tokens": [509, 393, 1884, 257, 1034, 2113, 13], "temperature": 0.0, "avg_logprob": -0.1099264653523763, "compression_ratio": 1.6303030303030304, "no_speech_prob": 0.0013166574062779546}, {"id": 142, "seek": 58700, "start": 600.0, "end": 603.0, "text": " You can take this binary and install it.", "tokens": [509, 393, 747, 341, 17434, 293, 3625, 309, 13], "temperature": 0.0, "avg_logprob": -0.1099264653523763, "compression_ratio": 1.6303030303030304, "no_speech_prob": 0.0013166574062779546}, {"id": 143, "seek": 58700, "start": 603.0, "end": 610.0, "text": " And it will install into user bin, user and etc.", "tokens": [400, 309, 486, 3625, 666, 4195, 5171, 11, 4195, 293, 5183, 13], "temperature": 0.0, "avg_logprob": -0.1099264653523763, "compression_ratio": 1.6303030303030304, "no_speech_prob": 0.0013166574062779546}, {"id": 144, "seek": 58700, "start": 610.0, "end": 613.0, "text": " You can run it without installation.", "tokens": [509, 393, 1190, 309, 1553, 13260, 13], "temperature": 0.0, "avg_logprob": -0.1099264653523763, "compression_ratio": 1.6303030303030304, "no_speech_prob": 0.0013166574062779546}, {"id": 145, "seek": 61300, "start": 613.0, "end": 619.0, "text": " So let's start it and let's create a table.", "tokens": [407, 718, 311, 722, 309, 293, 718, 311, 1884, 257, 3199, 13], "temperature": 0.0, "avg_logprob": -0.15646066783386983, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.0006609460106119514}, {"id": 146, "seek": 61300, "start": 619.0, "end": 622.0, "text": " So here is a table structure.", "tokens": [407, 510, 307, 257, 3199, 3877, 13], "temperature": 0.0, "avg_logprob": -0.15646066783386983, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.0006609460106119514}, {"id": 147, "seek": 61300, "start": 622.0, "end": 626.0, "text": " Five fields, date time, because it is time-serious,", "tokens": [9436, 7909, 11, 4002, 565, 11, 570, 309, 307, 565, 12, 12484, 851, 11], "temperature": 0.0, "avg_logprob": -0.15646066783386983, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.0006609460106119514}, {"id": 148, "seek": 61300, "start": 626.0, "end": 629.0, "text": " project, sub-project, page title,", "tokens": [1716, 11, 1422, 12, 4318, 1020, 11, 3028, 4876, 11], "temperature": 0.0, "avg_logprob": -0.15646066783386983, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.0006609460106119514}, {"id": 149, "seek": 61300, "start": 629.0, "end": 634.0, "text": " name it path, the number of page views, name it hits.", "tokens": [1315, 309, 3100, 11, 264, 1230, 295, 3028, 6809, 11, 1315, 309, 8664, 13], "temperature": 0.0, "avg_logprob": -0.15646066783386983, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.0006609460106119514}, {"id": 150, "seek": 61300, "start": 634.0, "end": 638.0, "text": " I also enabled stronger compression with ZSTD,", "tokens": [286, 611, 15172, 7249, 19355, 365, 1176, 6840, 35, 11], "temperature": 0.0, "avg_logprob": -0.15646066783386983, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.0006609460106119514}, {"id": 151, "seek": 63800, "start": 638.0, "end": 643.0, "text": " the standard and low cardinality data types.", "tokens": [264, 3832, 293, 2295, 2920, 259, 1860, 1412, 3467, 13], "temperature": 0.0, "avg_logprob": -0.125554816363609, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0004821122856810689}, {"id": 152, "seek": 63800, "start": 643.0, "end": 646.0, "text": " And this standard is just a compression codec.", "tokens": [400, 341, 3832, 307, 445, 257, 19355, 3089, 66, 13], "temperature": 0.0, "avg_logprob": -0.125554816363609, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0004821122856810689}, {"id": 153, "seek": 63800, "start": 646.0, "end": 650.0, "text": " I will also index it by path and time.", "tokens": [286, 486, 611, 8186, 309, 538, 3100, 293, 565, 13], "temperature": 0.0, "avg_logprob": -0.125554816363609, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0004821122856810689}, {"id": 154, "seek": 63800, "start": 650.0, "end": 655.0, "text": " So I will be able to quickly select for specific pages.", "tokens": [407, 286, 486, 312, 1075, 281, 2661, 3048, 337, 2685, 7183, 13], "temperature": 0.0, "avg_logprob": -0.125554816363609, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0004821122856810689}, {"id": 155, "seek": 63800, "start": 655.0, "end": 659.0, "text": " And how to load data into this table?", "tokens": [400, 577, 281, 3677, 1412, 666, 341, 3199, 30], "temperature": 0.0, "avg_logprob": -0.125554816363609, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0004821122856810689}, {"id": 156, "seek": 63800, "start": 659.0, "end": 664.0, "text": " Let's use Kafka or Pulsar", "tokens": [961, 311, 764, 47064, 420, 430, 9468, 289], "temperature": 0.0, "avg_logprob": -0.125554816363609, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0004821122856810689}, {"id": 157, "seek": 66400, "start": 664.0, "end": 671.0, "text": " and automate with Airflow and do ETL with Airbite or DBT.", "tokens": [293, 31605, 365, 5774, 10565, 293, 360, 36953, 43, 365, 5774, 65, 642, 420, 26754, 51, 13], "temperature": 0.0, "avg_logprob": -0.16139015150658878, "compression_ratio": 1.441988950276243, "no_speech_prob": 0.0014089328469708562}, {"id": 158, "seek": 66400, "start": 671.0, "end": 674.0, "text": " Actually, I don't know why DBT even exists,", "tokens": [5135, 11, 286, 500, 380, 458, 983, 26754, 51, 754, 8198, 11], "temperature": 0.0, "avg_logprob": -0.16139015150658878, "compression_ratio": 1.441988950276243, "no_speech_prob": 0.0014089328469708562}, {"id": 159, "seek": 66400, "start": 674.0, "end": 680.0, "text": " because I can do everything without DBT.", "tokens": [570, 286, 393, 360, 1203, 1553, 26754, 51, 13], "temperature": 0.0, "avg_logprob": -0.16139015150658878, "compression_ratio": 1.441988950276243, "no_speech_prob": 0.0014089328469708562}, {"id": 160, "seek": 66400, "start": 680.0, "end": 683.0, "text": " I will do it with just insert select.", "tokens": [286, 486, 360, 309, 365, 445, 8969, 3048, 13], "temperature": 0.0, "avg_logprob": -0.16139015150658878, "compression_ratio": 1.441988950276243, "no_speech_prob": 0.0014089328469708562}, {"id": 161, "seek": 66400, "start": 683.0, "end": 687.0, "text": " Insert into Wikistat my select query from S3.", "tokens": [36487, 666, 23377, 468, 267, 452, 3048, 14581, 490, 318, 18, 13], "temperature": 0.0, "avg_logprob": -0.16139015150658878, "compression_ratio": 1.441988950276243, "no_speech_prob": 0.0014089328469708562}, {"id": 162, "seek": 66400, "start": 687.0, "end": 691.0, "text": " And I will wait while it finishes.", "tokens": [400, 286, 486, 1699, 1339, 309, 23615, 13], "temperature": 0.0, "avg_logprob": -0.16139015150658878, "compression_ratio": 1.441988950276243, "no_speech_prob": 0.0014089328469708562}, {"id": 163, "seek": 69100, "start": 691.0, "end": 694.0, "text": " Let's take a look. You don't see anything.", "tokens": [961, 311, 747, 257, 574, 13, 509, 500, 380, 536, 1340, 13], "temperature": 0.0, "avg_logprob": -0.15316546802789394, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.001250861445441842}, {"id": 164, "seek": 69100, "start": 694.0, "end": 698.0, "text": " Let's make a font slightly larger.", "tokens": [961, 311, 652, 257, 10703, 4748, 4833, 13], "temperature": 0.0, "avg_logprob": -0.15316546802789394, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.001250861445441842}, {"id": 165, "seek": 69100, "start": 698.0, "end": 702.0, "text": " I will make a font slightly larger.", "tokens": [286, 486, 652, 257, 10703, 4748, 4833, 13], "temperature": 0.0, "avg_logprob": -0.15316546802789394, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.001250861445441842}, {"id": 166, "seek": 69100, "start": 702.0, "end": 704.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.15316546802789394, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.001250861445441842}, {"id": 167, "seek": 69100, "start": 704.0, "end": 707.0, "text": " Now it started to load the data.", "tokens": [823, 309, 1409, 281, 3677, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.15316546802789394, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.001250861445441842}, {"id": 168, "seek": 69100, "start": 707.0, "end": 712.0, "text": " 0%, 57 CPU consumed,", "tokens": [1958, 8923, 21423, 13199, 21226, 11], "temperature": 0.0, "avg_logprob": -0.15316546802789394, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.001250861445441842}, {"id": 169, "seek": 69100, "start": 712.0, "end": 718.0, "text": " 2 gigabytes per second and 50 million rows per second.", "tokens": [568, 42741, 680, 1150, 293, 2625, 2459, 13241, 680, 1150, 13], "temperature": 0.0, "avg_logprob": -0.15316546802789394, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.001250861445441842}, {"id": 170, "seek": 71800, "start": 718.0, "end": 721.0, "text": " 50 million.", "tokens": [2625, 2459, 13], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 171, "seek": 71800, "start": 721.0, "end": 723.0, "text": " I did not watch one of the previous talk.", "tokens": [286, 630, 406, 1159, 472, 295, 264, 3894, 751, 13], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 172, "seek": 71800, "start": 723.0, "end": 727.0, "text": " It was named loading more than a million records per second", "tokens": [467, 390, 4926, 15114, 544, 813, 257, 2459, 7724, 680, 1150], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 173, "seek": 71800, "start": 727.0, "end": 729.0, "text": " on a single server.", "tokens": [322, 257, 2167, 7154, 13], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 174, "seek": 71800, "start": 729.0, "end": 735.0, "text": " So we are loading more than a million records per second", "tokens": [407, 321, 366, 15114, 544, 813, 257, 2459, 7724, 680, 1150], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 175, "seek": 71800, "start": 735.0, "end": 737.0, "text": " on a single server.", "tokens": [322, 257, 2167, 7154, 13], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 176, "seek": 71800, "start": 737.0, "end": 739.0, "text": " Okay. Let's take a look what is happening,", "tokens": [1033, 13, 961, 311, 747, 257, 574, 437, 307, 2737, 11], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 177, "seek": 71800, "start": 739.0, "end": 742.0, "text": " because just loading data is not enough.", "tokens": [570, 445, 15114, 1412, 307, 406, 1547, 13], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 178, "seek": 71800, "start": 742.0, "end": 744.0, "text": " It will take a while.", "tokens": [467, 486, 747, 257, 1339, 13], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 179, "seek": 71800, "start": 744.0, "end": 746.0, "text": " And what to do while it is loading?", "tokens": [400, 437, 281, 360, 1339, 309, 307, 15114, 30], "temperature": 0.0, "avg_logprob": -0.08178577800788502, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.0009426004835404456}, {"id": 180, "seek": 74600, "start": 746.0, "end": 749.0, "text": " I will run Distat.", "tokens": [286, 486, 1190, 9840, 267, 13], "temperature": 0.0, "avg_logprob": -0.19027123084435096, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.001363039598800242}, {"id": 181, "seek": 74600, "start": 749.0, "end": 752.0, "text": " Distat will show me the system usage,", "tokens": [9840, 267, 486, 855, 385, 264, 1185, 14924, 11], "temperature": 0.0, "avg_logprob": -0.19027123084435096, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.001363039598800242}, {"id": 182, "seek": 74600, "start": 752.0, "end": 756.0, "text": " and I see that it is bounded by IO,", "tokens": [293, 286, 536, 300, 309, 307, 37498, 538, 39839, 11], "temperature": 0.0, "avg_logprob": -0.19027123084435096, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.001363039598800242}, {"id": 183, "seek": 74600, "start": 756.0, "end": 760.0, "text": " 500 megabytes per second, Britain.", "tokens": [5923, 10816, 24538, 680, 1150, 11, 12960, 13], "temperature": 0.0, "avg_logprob": -0.19027123084435096, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.001363039598800242}, {"id": 184, "seek": 74600, "start": 760.0, "end": 762.0, "text": " It is compressor data.", "tokens": [467, 307, 28765, 1412, 13], "temperature": 0.0, "avg_logprob": -0.19027123084435096, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.001363039598800242}, {"id": 185, "seek": 74600, "start": 762.0, "end": 764.0, "text": " IO weighed 68%.", "tokens": [39839, 32844, 23317, 6856], "temperature": 0.0, "avg_logprob": -0.19027123084435096, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.001363039598800242}, {"id": 186, "seek": 74600, "start": 764.0, "end": 767.0, "text": " CPU weighed almost non-existing.", "tokens": [13199, 32844, 1920, 2107, 12, 36447, 13], "temperature": 0.0, "avg_logprob": -0.19027123084435096, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.001363039598800242}, {"id": 187, "seek": 74600, "start": 767.0, "end": 771.0, "text": " I can also run top to see what is happening.", "tokens": [286, 393, 611, 1190, 1192, 281, 536, 437, 307, 2737, 13], "temperature": 0.0, "avg_logprob": -0.19027123084435096, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.001363039598800242}, {"id": 188, "seek": 77100, "start": 771.0, "end": 778.0, "text": " CPU 16 cores, and it works, and IO weighed 70%.", "tokens": [13199, 3165, 24826, 11, 293, 309, 1985, 11, 293, 39839, 32844, 5285, 6856], "temperature": 0.0, "avg_logprob": -0.1325674179272774, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0015511051751673222}, {"id": 189, "seek": 77100, "start": 778.0, "end": 781.0, "text": " But for me, it is not enough.", "tokens": [583, 337, 385, 11, 309, 307, 406, 1547, 13], "temperature": 0.0, "avg_logprob": -0.1325674179272774, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0015511051751673222}, {"id": 190, "seek": 77100, "start": 781.0, "end": 783.0, "text": " For me, it is not enough,", "tokens": [1171, 385, 11, 309, 307, 406, 1547, 11], "temperature": 0.0, "avg_logprob": -0.1325674179272774, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0015511051751673222}, {"id": 191, "seek": 77100, "start": 783.0, "end": 787.0, "text": " because I also run this tool per top,", "tokens": [570, 286, 611, 1190, 341, 2290, 680, 1192, 11], "temperature": 0.0, "avg_logprob": -0.1325674179272774, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0015511051751673222}, {"id": 192, "seek": 77100, "start": 787.0, "end": 790.0, "text": " because I always profile my code.", "tokens": [570, 286, 1009, 7964, 452, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1325674179272774, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0015511051751673222}, {"id": 193, "seek": 77100, "start": 790.0, "end": 792.0, "text": " So what my code is doing?", "tokens": [407, 437, 452, 3089, 307, 884, 30], "temperature": 0.0, "avg_logprob": -0.1325674179272774, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0015511051751673222}, {"id": 194, "seek": 77100, "start": 792.0, "end": 796.0, "text": " It is doing compression, sorting, nothing.", "tokens": [467, 307, 884, 19355, 11, 32411, 11, 1825, 13], "temperature": 0.0, "avg_logprob": -0.1325674179272774, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0015511051751673222}, {"id": 195, "seek": 79600, "start": 796.0, "end": 805.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.16653219858805338, "compression_ratio": 1.2109375, "no_speech_prob": 0.0013175568310543895}, {"id": 196, "seek": 79600, "start": 805.0, "end": 808.0, "text": " And after eight hours,", "tokens": [400, 934, 3180, 2496, 11], "temperature": 0.0, "avg_logprob": -0.16653219858805338, "compression_ratio": 1.2109375, "no_speech_prob": 0.0013175568310543895}, {"id": 197, "seek": 79600, "start": 808.0, "end": 811.0, "text": " my data is loaded.", "tokens": [452, 1412, 307, 13210, 13], "temperature": 0.0, "avg_logprob": -0.16653219858805338, "compression_ratio": 1.2109375, "no_speech_prob": 0.0013175568310543895}, {"id": 198, "seek": 79600, "start": 811.0, "end": 816.0, "text": " The table size on disk is just 700 gigabytes.", "tokens": [440, 3199, 2744, 322, 12355, 307, 445, 15204, 42741, 13], "temperature": 0.0, "avg_logprob": -0.16653219858805338, "compression_ratio": 1.2109375, "no_speech_prob": 0.0013175568310543895}, {"id": 199, "seek": 79600, "start": 816.0, "end": 819.0, "text": " Original was 3.5 terabytes,", "tokens": [30022, 390, 805, 13, 20, 1796, 24538, 11], "temperature": 0.0, "avg_logprob": -0.16653219858805338, "compression_ratio": 1.2109375, "no_speech_prob": 0.0013175568310543895}, {"id": 200, "seek": 79600, "start": 819.0, "end": 822.0, "text": " so it compressed like five times.", "tokens": [370, 309, 30353, 411, 1732, 1413, 13], "temperature": 0.0, "avg_logprob": -0.16653219858805338, "compression_ratio": 1.2109375, "no_speech_prob": 0.0013175568310543895}, {"id": 201, "seek": 82200, "start": 822.0, "end": 826.0, "text": " It was in Gzip, now it is in Clickhouse,", "tokens": [467, 390, 294, 460, 27268, 11, 586, 309, 307, 294, 8230, 6410, 11], "temperature": 0.0, "avg_logprob": -0.1232048598202792, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.00039568691863678396}, {"id": 202, "seek": 82200, "start": 826.0, "end": 829.0, "text": " with all the column-oriented compression.", "tokens": [365, 439, 264, 7738, 12, 27414, 19355, 13], "temperature": 0.0, "avg_logprob": -0.1232048598202792, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.00039568691863678396}, {"id": 203, "seek": 82200, "start": 829.0, "end": 834.0, "text": " The speed was 50 million rows per second,", "tokens": [440, 3073, 390, 2625, 2459, 13241, 680, 1150, 11], "temperature": 0.0, "avg_logprob": -0.1232048598202792, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.00039568691863678396}, {"id": 204, "seek": 82200, "start": 834.0, "end": 839.0, "text": " but actually, it was not true,", "tokens": [457, 767, 11, 309, 390, 406, 2074, 11], "temperature": 0.0, "avg_logprob": -0.1232048598202792, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.00039568691863678396}, {"id": 205, "seek": 82200, "start": 839.0, "end": 842.0, "text": " because after eight hours, it degraded", "tokens": [570, 934, 3180, 2496, 11, 309, 24740, 292], "temperature": 0.0, "avg_logprob": -0.1232048598202792, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.00039568691863678396}, {"id": 206, "seek": 82200, "start": 842.0, "end": 846.0, "text": " to just 14 million rows per second.", "tokens": [281, 445, 3499, 2459, 13241, 680, 1150, 13], "temperature": 0.0, "avg_logprob": -0.1232048598202792, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.00039568691863678396}, {"id": 207, "seek": 82200, "start": 846.0, "end": 848.0, "text": " Still not bad.", "tokens": [8291, 406, 1578, 13], "temperature": 0.0, "avg_logprob": -0.1232048598202792, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.00039568691863678396}, {"id": 208, "seek": 82200, "start": 848.0, "end": 851.0, "text": " It degraded because data has to be merged on disk,", "tokens": [467, 24740, 292, 570, 1412, 575, 281, 312, 36427, 322, 12355, 11], "temperature": 0.0, "avg_logprob": -0.1232048598202792, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.00039568691863678396}, {"id": 209, "seek": 85100, "start": 851.0, "end": 854.0, "text": " and it takes write amplification,", "tokens": [293, 309, 2516, 2464, 9731, 3774, 11], "temperature": 0.0, "avg_logprob": -0.15506144227652713, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0007780970190651715}, {"id": 210, "seek": 85100, "start": 854.0, "end": 856.0, "text": " it takes additional IO.", "tokens": [309, 2516, 4497, 39839, 13], "temperature": 0.0, "avg_logprob": -0.15506144227652713, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0007780970190651715}, {"id": 211, "seek": 85100, "start": 856.0, "end": 859.0, "text": " So what is the size?", "tokens": [407, 437, 307, 264, 2744, 30], "temperature": 0.0, "avg_logprob": -0.15506144227652713, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0007780970190651715}, {"id": 212, "seek": 85100, "start": 859.0, "end": 869.0, "text": " 380 billion records, 0.3 trillion.", "tokens": [805, 4702, 5218, 7724, 11, 1958, 13, 18, 18723, 13], "temperature": 0.0, "avg_logprob": -0.15506144227652713, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0007780970190651715}, {"id": 213, "seek": 85100, "start": 869.0, "end": 872.0, "text": " The total page views on Wikipedia", "tokens": [440, 3217, 3028, 6809, 322, 28999], "temperature": 0.0, "avg_logprob": -0.15506144227652713, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0007780970190651715}, {"id": 214, "seek": 85100, "start": 872.0, "end": 879.0, "text": " is just 1 trillion, 300 billion page views.", "tokens": [307, 445, 502, 18723, 11, 6641, 5218, 3028, 6809, 13], "temperature": 0.0, "avg_logprob": -0.15506144227652713, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0007780970190651715}, {"id": 215, "seek": 87900, "start": 879.0, "end": 885.0, "text": " Nothing surprising, Wikipedia is quite popular.", "tokens": [6693, 8830, 11, 28999, 307, 1596, 3743, 13], "temperature": 0.0, "avg_logprob": -0.1492813479515814, "compression_ratio": 1.4313725490196079, "no_speech_prob": 0.0015041966689750552}, {"id": 216, "seek": 87900, "start": 885.0, "end": 888.0, "text": " And about my table.", "tokens": [400, 466, 452, 3199, 13], "temperature": 0.0, "avg_logprob": -0.1492813479515814, "compression_ratio": 1.4313725490196079, "no_speech_prob": 0.0015041966689750552}, {"id": 217, "seek": 87900, "start": 888.0, "end": 895.0, "text": " So every record took just 2.0 bytes compressed.", "tokens": [407, 633, 2136, 1890, 445, 568, 13, 15, 36088, 30353, 13], "temperature": 0.0, "avg_logprob": -0.1492813479515814, "compression_ratio": 1.4313725490196079, "no_speech_prob": 0.0015041966689750552}, {"id": 218, "seek": 87900, "start": 895.0, "end": 901.0, "text": " All this title, like Wikipedia main page,", "tokens": [1057, 341, 4876, 11, 411, 28999, 2135, 3028, 11], "temperature": 0.0, "avg_logprob": -0.1492813479515814, "compression_ratio": 1.4313725490196079, "no_speech_prob": 0.0015041966689750552}, {"id": 219, "seek": 87900, "start": 901.0, "end": 903.0, "text": " it was like 50 bytes,", "tokens": [309, 390, 411, 2625, 36088, 11], "temperature": 0.0, "avg_logprob": -0.1492813479515814, "compression_ratio": 1.4313725490196079, "no_speech_prob": 0.0015041966689750552}, {"id": 220, "seek": 87900, "start": 903.0, "end": 906.0, "text": " now it is compressed to just two bytes.", "tokens": [586, 309, 307, 30353, 281, 445, 732, 36088, 13], "temperature": 0.0, "avg_logprob": -0.1492813479515814, "compression_ratio": 1.4313725490196079, "no_speech_prob": 0.0015041966689750552}, {"id": 221, "seek": 90600, "start": 906.0, "end": 909.0, "text": " And if you look at compression ratio,", "tokens": [400, 498, 291, 574, 412, 19355, 8509, 11], "temperature": 0.0, "avg_logprob": -0.16420297133616912, "compression_ratio": 1.3595505617977528, "no_speech_prob": 0.0009575325530022383}, {"id": 222, "seek": 90600, "start": 909.0, "end": 915.0, "text": " actually path is compressed to 170 times", "tokens": [767, 3100, 307, 30353, 281, 27228, 1413], "temperature": 0.0, "avg_logprob": -0.16420297133616912, "compression_ratio": 1.3595505617977528, "no_speech_prob": 0.0009575325530022383}, {"id": 223, "seek": 90600, "start": 915.0, "end": 919.0, "text": " because we sorted by path.", "tokens": [570, 321, 25462, 538, 3100, 13], "temperature": 0.0, "avg_logprob": -0.16420297133616912, "compression_ratio": 1.3595505617977528, "no_speech_prob": 0.0009575325530022383}, {"id": 224, "seek": 90600, "start": 919.0, "end": 923.0, "text": " Okay, but so what?", "tokens": [1033, 11, 457, 370, 437, 30], "temperature": 0.0, "avg_logprob": -0.16420297133616912, "compression_ratio": 1.3595505617977528, "no_speech_prob": 0.0009575325530022383}, {"id": 225, "seek": 90600, "start": 923.0, "end": 926.0, "text": " What to do with my data?", "tokens": [708, 281, 360, 365, 452, 1412, 30], "temperature": 0.0, "avg_logprob": -0.16420297133616912, "compression_ratio": 1.3595505617977528, "no_speech_prob": 0.0009575325530022383}, {"id": 226, "seek": 90600, "start": 926.0, "end": 927.0, "text": " I have loaded.", "tokens": [286, 362, 13210, 13], "temperature": 0.0, "avg_logprob": -0.16420297133616912, "compression_ratio": 1.3595505617977528, "no_speech_prob": 0.0009575325530022383}, {"id": 227, "seek": 90600, "start": 927.0, "end": 930.0, "text": " It took, it was 3.5 terabytes,", "tokens": [467, 1890, 11, 309, 390, 805, 13, 20, 1796, 24538, 11], "temperature": 0.0, "avg_logprob": -0.16420297133616912, "compression_ratio": 1.3595505617977528, "no_speech_prob": 0.0009575325530022383}, {"id": 228, "seek": 90600, "start": 930.0, "end": 934.0, "text": " and I can't be proud that I wasted eight hours", "tokens": [293, 286, 393, 380, 312, 4570, 300, 286, 19496, 3180, 2496], "temperature": 0.0, "avg_logprob": -0.16420297133616912, "compression_ratio": 1.3595505617977528, "no_speech_prob": 0.0009575325530022383}, {"id": 229, "seek": 93400, "start": 934.0, "end": 937.0, "text": " loading this data, and it compressed so well.", "tokens": [15114, 341, 1412, 11, 293, 309, 30353, 370, 731, 13], "temperature": 0.0, "avg_logprob": -0.15343448093959264, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.001854010159149766}, {"id": 230, "seek": 93400, "start": 937.0, "end": 940.0, "text": " But what to do with this data?", "tokens": [583, 437, 281, 360, 365, 341, 1412, 30], "temperature": 0.0, "avg_logprob": -0.15343448093959264, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.001854010159149766}, {"id": 231, "seek": 93400, "start": 940.0, "end": 946.0, "text": " We need some actionable insights from this data.", "tokens": [492, 643, 512, 45098, 14310, 490, 341, 1412, 13], "temperature": 0.0, "avg_logprob": -0.15343448093959264, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.001854010159149766}, {"id": 232, "seek": 93400, "start": 946.0, "end": 951.0, "text": " Let's make real-time dashboards.", "tokens": [961, 311, 652, 957, 12, 3766, 8240, 17228, 13], "temperature": 0.0, "avg_logprob": -0.15343448093959264, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.001854010159149766}, {"id": 233, "seek": 93400, "start": 951.0, "end": 953.0, "text": " How to do real-time dashboard?", "tokens": [1012, 281, 360, 957, 12, 3766, 18342, 30], "temperature": 0.0, "avg_logprob": -0.15343448093959264, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.001854010159149766}, {"id": 234, "seek": 93400, "start": 953.0, "end": 956.0, "text": " We can use Grafana, SuperSet,", "tokens": [492, 393, 764, 8985, 69, 2095, 11, 4548, 42718, 11], "temperature": 0.0, "avg_logprob": -0.15343448093959264, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.001854010159149766}, {"id": 235, "seek": 93400, "start": 956.0, "end": 961.0, "text": " Netbase, Tableau, Observable, or even Streamlit.", "tokens": [6188, 17429, 11, 25535, 1459, 11, 42547, 712, 11, 420, 754, 24904, 23062, 13], "temperature": 0.0, "avg_logprob": -0.15343448093959264, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.001854010159149766}, {"id": 236, "seek": 96100, "start": 961.0, "end": 964.0, "text": " I don't want to use Streamlit,", "tokens": [286, 500, 380, 528, 281, 764, 24904, 23062, 11], "temperature": 0.0, "avg_logprob": -0.13766745461357965, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0019164379918947816}, {"id": 237, "seek": 96100, "start": 964.0, "end": 970.0, "text": " it looks too complex, too complicated in the previous talk.", "tokens": [309, 1542, 886, 3997, 11, 886, 6179, 294, 264, 3894, 751, 13], "temperature": 0.0, "avg_logprob": -0.13766745461357965, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0019164379918947816}, {"id": 238, "seek": 96100, "start": 970.0, "end": 973.0, "text": " And actually there is no problem,", "tokens": [400, 767, 456, 307, 572, 1154, 11], "temperature": 0.0, "avg_logprob": -0.13766745461357965, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0019164379918947816}, {"id": 239, "seek": 96100, "start": 973.0, "end": 975.0, "text": " I can use Grafana, SuperSet,", "tokens": [286, 393, 764, 8985, 69, 2095, 11, 4548, 42718, 11], "temperature": 0.0, "avg_logprob": -0.13766745461357965, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0019164379918947816}, {"id": 240, "seek": 96100, "start": 975.0, "end": 978.0, "text": " Netbase with Clickhouse, it works perfectly,", "tokens": [6188, 17429, 365, 8230, 6410, 11, 309, 1985, 6239, 11], "temperature": 0.0, "avg_logprob": -0.13766745461357965, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0019164379918947816}, {"id": 241, "seek": 96100, "start": 978.0, "end": 981.0, "text": " but I am an engineer.", "tokens": [457, 286, 669, 364, 11403, 13], "temperature": 0.0, "avg_logprob": -0.13766745461357965, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0019164379918947816}, {"id": 242, "seek": 96100, "start": 981.0, "end": 990.0, "text": " And why to use Grafana if I can write my own Grafana in a day?", "tokens": [400, 983, 281, 764, 8985, 69, 2095, 498, 286, 393, 2464, 452, 1065, 8985, 69, 2095, 294, 257, 786, 30], "temperature": 0.0, "avg_logprob": -0.13766745461357965, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0019164379918947816}, {"id": 243, "seek": 99000, "start": 990.0, "end": 992.0, "text": " Let's do it just now.", "tokens": [961, 311, 360, 309, 445, 586, 13], "temperature": 0.0, "avg_logprob": -0.13253885292145143, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0011700777104124427}, {"id": 244, "seek": 99000, "start": 992.0, "end": 996.0, "text": " Let's decide what JavaScript framework to use.", "tokens": [961, 311, 4536, 437, 15778, 8388, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.13253885292145143, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0011700777104124427}, {"id": 245, "seek": 99000, "start": 996.0, "end": 999.0, "text": " I can use React, View, Swelte,", "tokens": [286, 393, 764, 30644, 11, 13909, 11, 3926, 338, 975, 11], "temperature": 0.0, "avg_logprob": -0.13253885292145143, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0011700777104124427}, {"id": 246, "seek": 99000, "start": 999.0, "end": 1003.0, "text": " I don't know what is Swelte, but it is popular.", "tokens": [286, 500, 380, 458, 437, 307, 3926, 338, 975, 11, 457, 309, 307, 3743, 13], "temperature": 0.0, "avg_logprob": -0.13253885292145143, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0011700777104124427}, {"id": 247, "seek": 99000, "start": 1003.0, "end": 1007.0, "text": " You know, if Rust were JavaScript framework,", "tokens": [509, 458, 11, 498, 34952, 645, 15778, 8388, 11], "temperature": 0.0, "avg_logprob": -0.13253885292145143, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0011700777104124427}, {"id": 248, "seek": 99000, "start": 1007.0, "end": 1011.0, "text": " I will use Rust.", "tokens": [286, 486, 764, 34952, 13], "temperature": 0.0, "avg_logprob": -0.13253885292145143, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0011700777104124427}, {"id": 249, "seek": 99000, "start": 1011.0, "end": 1017.0, "text": " Maybe I should use not JavaScript, but TypeScript.", "tokens": [2704, 286, 820, 764, 406, 15778, 11, 457, 15576, 14237, 13], "temperature": 0.0, "avg_logprob": -0.13253885292145143, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0011700777104124427}, {"id": 250, "seek": 101700, "start": 1017.0, "end": 1022.0, "text": " But no, I will use modern JavaScript.", "tokens": [583, 572, 11, 286, 486, 764, 4363, 15778, 13], "temperature": 0.0, "avg_logprob": -0.17397527874640697, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.0016313623636960983}, {"id": 251, "seek": 101700, "start": 1022.0, "end": 1027.0, "text": " What is modern JavaScript?", "tokens": [708, 307, 4363, 15778, 30], "temperature": 0.0, "avg_logprob": -0.17397527874640697, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.0016313623636960983}, {"id": 252, "seek": 101700, "start": 1027.0, "end": 1036.0, "text": " Modern JavaScript, it is when you simply open HTML file", "tokens": [19814, 15778, 11, 309, 307, 562, 291, 2935, 1269, 17995, 3991], "temperature": 0.0, "avg_logprob": -0.17397527874640697, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.0016313623636960983}, {"id": 253, "seek": 101700, "start": 1036.0, "end": 1040.0, "text": " in Notepad or VI or whatever,", "tokens": [294, 1726, 595, 345, 420, 27619, 420, 2035, 11], "temperature": 0.0, "avg_logprob": -0.17397527874640697, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.0016313623636960983}, {"id": 254, "seek": 101700, "start": 1040.0, "end": 1043.0, "text": " and writing a code without frameworks,", "tokens": [293, 3579, 257, 3089, 1553, 29834, 11], "temperature": 0.0, "avg_logprob": -0.17397527874640697, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.0016313623636960983}, {"id": 255, "seek": 104300, "start": 1043.0, "end": 1047.0, "text": " without build systems, without dependencies.", "tokens": [1553, 1322, 3652, 11, 1553, 36606, 13], "temperature": 0.0, "avg_logprob": -0.2040301091743238, "compression_ratio": 1.475609756097561, "no_speech_prob": 0.0009317565709352493}, {"id": 256, "seek": 104300, "start": 1047.0, "end": 1053.0, "text": " Actually, I need one dependency, some charting library.", "tokens": [5135, 11, 286, 643, 472, 33621, 11, 512, 6927, 278, 6405, 13], "temperature": 0.0, "avg_logprob": -0.2040301091743238, "compression_ratio": 1.475609756097561, "no_speech_prob": 0.0009317565709352493}, {"id": 257, "seek": 104300, "start": 1053.0, "end": 1058.0, "text": " And I just picked a random charting library from GitHub.", "tokens": [400, 286, 445, 6183, 257, 4974, 6927, 278, 6405, 490, 23331, 13], "temperature": 0.0, "avg_logprob": -0.2040301091743238, "compression_ratio": 1.475609756097561, "no_speech_prob": 0.0009317565709352493}, {"id": 258, "seek": 104300, "start": 1058.0, "end": 1062.0, "text": " Name it Uplot from Lyonya.", "tokens": [13866, 309, 624, 564, 310, 490, 12687, 44727, 13], "temperature": 0.0, "avg_logprob": -0.2040301091743238, "compression_ratio": 1.475609756097561, "no_speech_prob": 0.0009317565709352493}, {"id": 259, "seek": 104300, "start": 1062.0, "end": 1068.0, "text": " The description Uplot is a fast memory-efficient library.", "tokens": [440, 3855, 624, 564, 310, 307, 257, 2370, 4675, 12, 68, 7816, 6405, 13], "temperature": 0.0, "avg_logprob": -0.2040301091743238, "compression_ratio": 1.475609756097561, "no_speech_prob": 0.0009317565709352493}, {"id": 260, "seek": 106800, "start": 1068.0, "end": 1074.0, "text": " Okay, solved. I will use it.", "tokens": [1033, 11, 13041, 13, 286, 486, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.175149522978684, "compression_ratio": 1.389261744966443, "no_speech_prob": 0.0011835440527647734}, {"id": 261, "seek": 106800, "start": 1074.0, "end": 1078.0, "text": " Another question, how to query my database?", "tokens": [3996, 1168, 11, 577, 281, 14581, 452, 8149, 30], "temperature": 0.0, "avg_logprob": -0.175149522978684, "compression_ratio": 1.389261744966443, "no_speech_prob": 0.0011835440527647734}, {"id": 262, "seek": 106800, "start": 1078.0, "end": 1084.0, "text": " Should I write a backend in Python in Go?", "tokens": [6454, 286, 2464, 257, 38087, 294, 15329, 294, 1037, 30], "temperature": 0.0, "avg_logprob": -0.175149522978684, "compression_ratio": 1.389261744966443, "no_speech_prob": 0.0011835440527647734}, {"id": 263, "seek": 106800, "start": 1084.0, "end": 1089.0, "text": " No, I will query my database directly from JavaScript,", "tokens": [883, 11, 286, 486, 14581, 452, 8149, 3838, 490, 15778, 11], "temperature": 0.0, "avg_logprob": -0.175149522978684, "compression_ratio": 1.389261744966443, "no_speech_prob": 0.0011835440527647734}, {"id": 264, "seek": 106800, "start": 1089.0, "end": 1093.0, "text": " from modern JavaScript with Rust API.", "tokens": [490, 4363, 15778, 365, 34952, 9362, 13], "temperature": 0.0, "avg_logprob": -0.175149522978684, "compression_ratio": 1.389261744966443, "no_speech_prob": 0.0011835440527647734}, {"id": 265, "seek": 109300, "start": 1093.0, "end": 1099.0, "text": " I will use Async, await, fetch API, and post my query", "tokens": [286, 486, 764, 1018, 34015, 11, 19670, 11, 23673, 9362, 11, 293, 2183, 452, 14581], "temperature": 0.0, "avg_logprob": -0.15886963277623273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.0006103187333792448}, {"id": 266, "seek": 109300, "start": 1099.0, "end": 1105.0, "text": " to the database, and it will return the data in format JSON.", "tokens": [281, 264, 8149, 11, 293, 309, 486, 2736, 264, 1412, 294, 7877, 31828, 13], "temperature": 0.0, "avg_logprob": -0.15886963277623273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.0006103187333792448}, {"id": 267, "seek": 109300, "start": 1105.0, "end": 1110.0, "text": " Okay, enough modern JavaScript.", "tokens": [1033, 11, 1547, 4363, 15778, 13], "temperature": 0.0, "avg_logprob": -0.15886963277623273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.0006103187333792448}, {"id": 268, "seek": 109300, "start": 1110.0, "end": 1115.0, "text": " So, Clickhouse has Rust API embedded into the server.", "tokens": [407, 11, 8230, 6410, 575, 34952, 9362, 16741, 666, 264, 7154, 13], "temperature": 0.0, "avg_logprob": -0.15886963277623273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.0006103187333792448}, {"id": 269, "seek": 109300, "start": 1115.0, "end": 1119.0, "text": " It has authentication, access control, rate limiting,", "tokens": [467, 575, 26643, 11, 2105, 1969, 11, 3314, 22083, 11], "temperature": 0.0, "avg_logprob": -0.15886963277623273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.0006103187333792448}, {"id": 270, "seek": 111900, "start": 1119.0, "end": 1124.0, "text": " quotas, query complexity limiting, parameterized queries,", "tokens": [9641, 296, 11, 14581, 14024, 22083, 11, 13075, 1602, 24109, 11], "temperature": 0.0, "avg_logprob": -0.14042198494689107, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0008439286611974239}, {"id": 271, "seek": 111900, "start": 1124.0, "end": 1128.0, "text": " custom handlers, so you don't have to write a select query,", "tokens": [2375, 1011, 11977, 11, 370, 291, 500, 380, 362, 281, 2464, 257, 3048, 14581, 11], "temperature": 0.0, "avg_logprob": -0.14042198494689107, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0008439286611974239}, {"id": 272, "seek": 111900, "start": 1128.0, "end": 1131.0, "text": " you can just define a handler like", "tokens": [291, 393, 445, 6964, 257, 41967, 411], "temperature": 0.0, "avg_logprob": -0.14042198494689107, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0008439286611974239}, {"id": 273, "seek": 111900, "start": 1131.0, "end": 1138.0, "text": " slash my report, or slash insert my data.", "tokens": [17330, 452, 2275, 11, 420, 17330, 8969, 452, 1412, 13], "temperature": 0.0, "avg_logprob": -0.14042198494689107, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0008439286611974239}, {"id": 274, "seek": 111900, "start": 1138.0, "end": 1142.0, "text": " And you can actually open Clickhouse to the Internet", "tokens": [400, 291, 393, 767, 1269, 8230, 6410, 281, 264, 7703], "temperature": 0.0, "avg_logprob": -0.14042198494689107, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0008439286611974239}, {"id": 275, "seek": 111900, "start": 1142.0, "end": 1144.0, "text": " and get away with that.", "tokens": [293, 483, 1314, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.14042198494689107, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0008439286611974239}, {"id": 276, "seek": 114400, "start": 1144.0, "end": 1150.0, "text": " I did that, it still works.", "tokens": [286, 630, 300, 11, 309, 920, 1985, 13], "temperature": 0.0, "avg_logprob": -0.11774913966655731, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0009217243059538305}, {"id": 277, "seek": 114400, "start": 1150.0, "end": 1154.0, "text": " Okay, here is a query for Wikipedia trends", "tokens": [1033, 11, 510, 307, 257, 14581, 337, 28999, 13892], "temperature": 0.0, "avg_logprob": -0.11774913966655731, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0009217243059538305}, {"id": 278, "seek": 114400, "start": 1154.0, "end": 1157.0, "text": " that we will use for a dashboard.", "tokens": [300, 321, 486, 764, 337, 257, 18342, 13], "temperature": 0.0, "avg_logprob": -0.11774913966655731, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0009217243059538305}, {"id": 279, "seek": 114400, "start": 1157.0, "end": 1161.0, "text": " It will simply select this time series", "tokens": [467, 486, 2935, 3048, 341, 565, 2638], "temperature": 0.0, "avg_logprob": -0.11774913966655731, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0009217243059538305}, {"id": 280, "seek": 114400, "start": 1161.0, "end": 1167.0, "text": " rounded to some time frame, to some page.", "tokens": [23382, 281, 512, 565, 3920, 11, 281, 512, 3028, 13], "temperature": 0.0, "avg_logprob": -0.11774913966655731, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0009217243059538305}, {"id": 281, "seek": 114400, "start": 1167.0, "end": 1170.0, "text": " And here is a parameterized query.", "tokens": [400, 510, 307, 257, 13075, 1602, 14581, 13], "temperature": 0.0, "avg_logprob": -0.11774913966655731, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0009217243059538305}, {"id": 282, "seek": 117000, "start": 1170.0, "end": 1175.0, "text": " It looks slightly different, it's not like question mark here.", "tokens": [467, 1542, 4748, 819, 11, 309, 311, 406, 411, 1168, 1491, 510, 13], "temperature": 0.0, "avg_logprob": -0.12996654252748233, "compression_ratio": 1.5548780487804879, "no_speech_prob": 0.0004567907890304923}, {"id": 283, "seek": 117000, "start": 1175.0, "end": 1181.0, "text": " It is actually a strictly typed substitution.", "tokens": [467, 307, 767, 257, 20792, 33941, 35827, 13], "temperature": 0.0, "avg_logprob": -0.12996654252748233, "compression_ratio": 1.5548780487804879, "no_speech_prob": 0.0004567907890304923}, {"id": 284, "seek": 117000, "start": 1181.0, "end": 1187.0, "text": " Okay, and how long this query will take?", "tokens": [1033, 11, 293, 577, 938, 341, 14581, 486, 747, 30], "temperature": 0.0, "avg_logprob": -0.12996654252748233, "compression_ratio": 1.5548780487804879, "no_speech_prob": 0.0004567907890304923}, {"id": 285, "seek": 117000, "start": 1187.0, "end": 1190.0, "text": " Let me ask you, how long this query will take?", "tokens": [961, 385, 1029, 291, 11, 577, 938, 341, 14581, 486, 747, 30], "temperature": 0.0, "avg_logprob": -0.12996654252748233, "compression_ratio": 1.5548780487804879, "no_speech_prob": 0.0004567907890304923}, {"id": 286, "seek": 117000, "start": 1190.0, "end": 1193.0, "text": " What do you think?", "tokens": [708, 360, 291, 519, 30], "temperature": 0.0, "avg_logprob": -0.12996654252748233, "compression_ratio": 1.5548780487804879, "no_speech_prob": 0.0004567907890304923}, {"id": 287, "seek": 117000, "start": 1193.0, "end": 1194.0, "text": " Eight days.", "tokens": [17708, 1708, 13], "temperature": 0.0, "avg_logprob": -0.12996654252748233, "compression_ratio": 1.5548780487804879, "no_speech_prob": 0.0004567907890304923}, {"id": 288, "seek": 117000, "start": 1194.0, "end": 1196.0, "text": " Eight days, why eight days?", "tokens": [17708, 1708, 11, 983, 3180, 1708, 30], "temperature": 0.0, "avg_logprob": -0.12996654252748233, "compression_ratio": 1.5548780487804879, "no_speech_prob": 0.0004567907890304923}, {"id": 289, "seek": 119600, "start": 1196.0, "end": 1203.0, "text": " It should work on a table with 0.3 trillion records.", "tokens": [467, 820, 589, 322, 257, 3199, 365, 1958, 13, 18, 18723, 7724, 13], "temperature": 0.0, "avg_logprob": -0.15334127630506242, "compression_ratio": 1.330935251798561, "no_speech_prob": 0.002855042926967144}, {"id": 290, "seek": 119600, "start": 1203.0, "end": 1206.0, "text": " How long this query will take?", "tokens": [1012, 938, 341, 14581, 486, 747, 30], "temperature": 0.0, "avg_logprob": -0.15334127630506242, "compression_ratio": 1.330935251798561, "no_speech_prob": 0.002855042926967144}, {"id": 291, "seek": 119600, "start": 1206.0, "end": 1211.0, "text": " Twenty milliseconds.", "tokens": [28789, 34184, 13], "temperature": 0.0, "avg_logprob": -0.15334127630506242, "compression_ratio": 1.330935251798561, "no_speech_prob": 0.002855042926967144}, {"id": 292, "seek": 119600, "start": 1211.0, "end": 1216.0, "text": " Okay, let's experiment nine milliseconds.", "tokens": [1033, 11, 718, 311, 5120, 4949, 34184, 13], "temperature": 0.0, "avg_logprob": -0.15334127630506242, "compression_ratio": 1.330935251798561, "no_speech_prob": 0.002855042926967144}, {"id": 293, "seek": 119600, "start": 1216.0, "end": 1218.0, "text": " So, you are wrong.", "tokens": [407, 11, 291, 366, 2085, 13], "temperature": 0.0, "avg_logprob": -0.15334127630506242, "compression_ratio": 1.330935251798561, "no_speech_prob": 0.002855042926967144}, {"id": 294, "seek": 119600, "start": 1218.0, "end": 1224.0, "text": " You are also wrong.", "tokens": [509, 366, 611, 2085, 13], "temperature": 0.0, "avg_logprob": -0.15334127630506242, "compression_ratio": 1.330935251798561, "no_speech_prob": 0.002855042926967144}, {"id": 295, "seek": 122400, "start": 1224.0, "end": 1226.0, "text": " I was scrolling back and forth.", "tokens": [286, 390, 29053, 646, 293, 5220, 13], "temperature": 0.0, "avg_logprob": -0.17833204702897507, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0017811565194278955}, {"id": 296, "seek": 122400, "start": 1226.0, "end": 1228.0, "text": " So, maybe Clickhouse is fast.", "tokens": [407, 11, 1310, 8230, 6410, 307, 2370, 13], "temperature": 0.0, "avg_logprob": -0.17833204702897507, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0017811565194278955}, {"id": 297, "seek": 122400, "start": 1228.0, "end": 1232.0, "text": " What if I do my SQL, 29 milliseconds?", "tokens": [708, 498, 286, 360, 452, 19200, 11, 9413, 34184, 30], "temperature": 0.0, "avg_logprob": -0.17833204702897507, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0017811565194278955}, {"id": 298, "seek": 122400, "start": 1232.0, "end": 1234.0, "text": " Okay, closer.", "tokens": [1033, 11, 4966, 13], "temperature": 0.0, "avg_logprob": -0.17833204702897507, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0017811565194278955}, {"id": 299, "seek": 122400, "start": 1234.0, "end": 1239.0, "text": " MariaDB, 20 milliseconds.", "tokens": [12734, 27735, 11, 945, 34184, 13], "temperature": 0.0, "avg_logprob": -0.17833204702897507, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0017811565194278955}, {"id": 300, "seek": 122400, "start": 1239.0, "end": 1243.0, "text": " What if I will replace equality comparison to like", "tokens": [708, 498, 286, 486, 7406, 14949, 9660, 281, 411], "temperature": 0.0, "avg_logprob": -0.17833204702897507, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0017811565194278955}, {"id": 301, "seek": 122400, "start": 1243.0, "end": 1245.0, "text": " and add percent?", "tokens": [293, 909, 3043, 30], "temperature": 0.0, "avg_logprob": -0.17833204702897507, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0017811565194278955}, {"id": 302, "seek": 122400, "start": 1245.0, "end": 1248.0, "text": " The same, because prefix also using index.", "tokens": [440, 912, 11, 570, 46969, 611, 1228, 8186, 13], "temperature": 0.0, "avg_logprob": -0.17833204702897507, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0017811565194278955}, {"id": 303, "seek": 122400, "start": 1248.0, "end": 1251.0, "text": " But what if I will add percent on the front?", "tokens": [583, 437, 498, 286, 486, 909, 3043, 322, 264, 1868, 30], "temperature": 0.0, "avg_logprob": -0.17833204702897507, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.0017811565194278955}, {"id": 304, "seek": 125100, "start": 1251.0, "end": 1256.0, "text": " Okay, now it started to do a full scan.", "tokens": [1033, 11, 586, 309, 1409, 281, 360, 257, 1577, 11049, 13], "temperature": 0.0, "avg_logprob": -0.10057534342226775, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.001608733320608735}, {"id": 305, "seek": 125100, "start": 1256.0, "end": 1259.0, "text": " And this full scan was quite fast,", "tokens": [400, 341, 1577, 11049, 390, 1596, 2370, 11], "temperature": 0.0, "avg_logprob": -0.10057534342226775, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.001608733320608735}, {"id": 306, "seek": 125100, "start": 1259.0, "end": 1262.0, "text": " over 1 billion records per second,", "tokens": [670, 502, 5218, 7724, 680, 1150, 11], "temperature": 0.0, "avg_logprob": -0.10057534342226775, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.001608733320608735}, {"id": 307, "seek": 125100, "start": 1262.0, "end": 1265.0, "text": " but still not fast enough for real time.", "tokens": [457, 920, 406, 2370, 1547, 337, 957, 565, 13], "temperature": 0.0, "avg_logprob": -0.10057534342226775, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.001608733320608735}, {"id": 308, "seek": 125100, "start": 1265.0, "end": 1270.0, "text": " But all the queries with exact matching was real time.", "tokens": [583, 439, 264, 24109, 365, 1900, 14324, 390, 957, 565, 13], "temperature": 0.0, "avg_logprob": -0.10057534342226775, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.001608733320608735}, {"id": 309, "seek": 125100, "start": 1270.0, "end": 1277.0, "text": " Okay, let me show you this dashboard.", "tokens": [1033, 11, 718, 385, 855, 291, 341, 18342, 13], "temperature": 0.0, "avg_logprob": -0.10057534342226775, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.001608733320608735}, {"id": 310, "seek": 127700, "start": 1277.0, "end": 1282.0, "text": " It looks like this modern dashboard.", "tokens": [467, 1542, 411, 341, 4363, 18342, 13], "temperature": 0.0, "avg_logprob": -0.16222016016642252, "compression_ratio": 1.48, "no_speech_prob": 0.0014768186956644058}, {"id": 311, "seek": 127700, "start": 1282.0, "end": 1284.0, "text": " It looks actually gorgeous.", "tokens": [467, 1542, 767, 12291, 13], "temperature": 0.0, "avg_logprob": -0.16222016016642252, "compression_ratio": 1.48, "no_speech_prob": 0.0014768186956644058}, {"id": 312, "seek": 127700, "start": 1284.0, "end": 1287.0, "text": " It has dark seam.", "tokens": [467, 575, 2877, 12337, 13], "temperature": 0.0, "avg_logprob": -0.16222016016642252, "compression_ratio": 1.48, "no_speech_prob": 0.0014768186956644058}, {"id": 313, "seek": 127700, "start": 1287.0, "end": 1293.0, "text": " And you can see it compares trends on Wikipedia for Clickhouse.", "tokens": [400, 291, 393, 536, 309, 38334, 13892, 322, 28999, 337, 8230, 6410, 13], "temperature": 0.0, "avg_logprob": -0.16222016016642252, "compression_ratio": 1.48, "no_speech_prob": 0.0014768186956644058}, {"id": 314, "seek": 127700, "start": 1293.0, "end": 1295.0, "text": " Clickhouse is growing.", "tokens": [8230, 6410, 307, 4194, 13], "temperature": 0.0, "avg_logprob": -0.16222016016642252, "compression_ratio": 1.48, "no_speech_prob": 0.0014768186956644058}, {"id": 315, "seek": 127700, "start": 1295.0, "end": 1299.0, "text": " Spark is not growing.", "tokens": [23424, 307, 406, 4194, 13], "temperature": 0.0, "avg_logprob": -0.16222016016642252, "compression_ratio": 1.48, "no_speech_prob": 0.0014768186956644058}, {"id": 316, "seek": 127700, "start": 1299.0, "end": 1301.0, "text": " Green Plum is not growing.", "tokens": [6969, 2149, 449, 307, 406, 4194, 13], "temperature": 0.0, "avg_logprob": -0.16222016016642252, "compression_ratio": 1.48, "no_speech_prob": 0.0014768186956644058}, {"id": 317, "seek": 127700, "start": 1301.0, "end": 1303.0, "text": " What was there?", "tokens": [708, 390, 456, 30], "temperature": 0.0, "avg_logprob": -0.16222016016642252, "compression_ratio": 1.48, "no_speech_prob": 0.0014768186956644058}, {"id": 318, "seek": 127700, "start": 1303.0, "end": 1305.0, "text": " Snowflake is quite okay.", "tokens": [14827, 3423, 619, 307, 1596, 1392, 13], "temperature": 0.0, "avg_logprob": -0.16222016016642252, "compression_ratio": 1.48, "no_speech_prob": 0.0014768186956644058}, {"id": 319, "seek": 130500, "start": 1305.0, "end": 1307.0, "text": " Let's check it.", "tokens": [961, 311, 1520, 309, 13], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 320, "seek": 130500, "start": 1307.0, "end": 1311.0, "text": " Let's see what is inside.", "tokens": [961, 311, 536, 437, 307, 1854, 13], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 321, "seek": 130500, "start": 1311.0, "end": 1314.0, "text": " Every chart is defined with parameterized query.", "tokens": [2048, 6927, 307, 7642, 365, 13075, 1602, 14581, 13], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 322, "seek": 130500, "start": 1314.0, "end": 1316.0, "text": " You write select.", "tokens": [509, 2464, 3048, 13], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 323, "seek": 130500, "start": 1316.0, "end": 1318.0, "text": " Actually, it's not even parameterized.", "tokens": [5135, 11, 309, 311, 406, 754, 13075, 1602, 13], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 324, "seek": 130500, "start": 1318.0, "end": 1320.0, "text": " Okay, what about MongoDB?", "tokens": [1033, 11, 437, 466, 48380, 27735, 30], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 325, "seek": 130500, "start": 1320.0, "end": 1323.0, "text": " Here I define a new chart and here is Mongo.", "tokens": [1692, 286, 6964, 257, 777, 6927, 293, 510, 307, 48380, 13], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 326, "seek": 130500, "start": 1323.0, "end": 1325.0, "text": " Okay, I did one mistake.", "tokens": [1033, 11, 286, 630, 472, 6146, 13], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 327, "seek": 130500, "start": 1325.0, "end": 1331.0, "text": " It was filtered by outliers for Snowflake.", "tokens": [467, 390, 37111, 538, 484, 23646, 337, 14827, 3423, 619, 13], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 328, "seek": 130500, "start": 1331.0, "end": 1333.0, "text": " Let's move.", "tokens": [961, 311, 1286, 13], "temperature": 0.0, "avg_logprob": -0.13806265592575073, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.00121984479483217}, {"id": 329, "seek": 133300, "start": 1333.0, "end": 1335.0, "text": " Okay, Mongo...", "tokens": [1033, 11, 48380, 485], "temperature": 0.0, "avg_logprob": -0.08800074066778626, "compression_ratio": 1.7009345794392523, "no_speech_prob": 0.0012090777745470405}, {"id": 330, "seek": 133300, "start": 1335.0, "end": 1337.0, "text": " No, Mongo is not doing great.", "tokens": [883, 11, 48380, 307, 406, 884, 869, 13], "temperature": 0.0, "avg_logprob": -0.08800074066778626, "compression_ratio": 1.7009345794392523, "no_speech_prob": 0.0012090777745470405}, {"id": 331, "seek": 133300, "start": 1337.0, "end": 1339.0, "text": " Clickhouse is doing great.", "tokens": [8230, 6410, 307, 884, 869, 13], "temperature": 0.0, "avg_logprob": -0.08800074066778626, "compression_ratio": 1.7009345794392523, "no_speech_prob": 0.0012090777745470405}, {"id": 332, "seek": 133300, "start": 1339.0, "end": 1343.0, "text": " By the way, what if you will just open a dashboard by default?", "tokens": [3146, 264, 636, 11, 437, 498, 291, 486, 445, 1269, 257, 18342, 538, 7576, 30], "temperature": 0.0, "avg_logprob": -0.08800074066778626, "compression_ratio": 1.7009345794392523, "no_speech_prob": 0.0012090777745470405}, {"id": 333, "seek": 133300, "start": 1343.0, "end": 1348.0, "text": " It will present you observability dashboard for Clickhouse.", "tokens": [467, 486, 1974, 291, 9951, 2310, 18342, 337, 8230, 6410, 13], "temperature": 0.0, "avg_logprob": -0.08800074066778626, "compression_ratio": 1.7009345794392523, "no_speech_prob": 0.0012090777745470405}, {"id": 334, "seek": 133300, "start": 1348.0, "end": 1351.0, "text": " So you can see what the system is doing.", "tokens": [407, 291, 393, 536, 437, 264, 1185, 307, 884, 13], "temperature": 0.0, "avg_logprob": -0.08800074066778626, "compression_ratio": 1.7009345794392523, "no_speech_prob": 0.0012090777745470405}, {"id": 335, "seek": 133300, "start": 1351.0, "end": 1354.0, "text": " It is actually the same code, the same dashboard,", "tokens": [467, 307, 767, 264, 912, 3089, 11, 264, 912, 18342, 11], "temperature": 0.0, "avg_logprob": -0.08800074066778626, "compression_ratio": 1.7009345794392523, "no_speech_prob": 0.0012090777745470405}, {"id": 336, "seek": 133300, "start": 1354.0, "end": 1358.0, "text": " but different queries.", "tokens": [457, 819, 24109, 13], "temperature": 0.0, "avg_logprob": -0.08800074066778626, "compression_ratio": 1.7009345794392523, "no_speech_prob": 0.0012090777745470405}, {"id": 337, "seek": 133300, "start": 1358.0, "end": 1361.0, "text": " You can use parameterized queries for these parameters,", "tokens": [509, 393, 764, 13075, 1602, 24109, 337, 613, 9834, 11], "temperature": 0.0, "avg_logprob": -0.08800074066778626, "compression_ratio": 1.7009345794392523, "no_speech_prob": 0.0012090777745470405}, {"id": 338, "seek": 136100, "start": 1361.0, "end": 1364.0, "text": " change parameters, change the time frame.", "tokens": [1319, 9834, 11, 1319, 264, 565, 3920, 13], "temperature": 0.0, "avg_logprob": -0.16106297629220145, "compression_ratio": 1.348993288590604, "no_speech_prob": 0.000458554713986814}, {"id": 339, "seek": 136100, "start": 1364.0, "end": 1369.0, "text": " It's not like Grafana, it does not have features,", "tokens": [467, 311, 406, 411, 8985, 69, 2095, 11, 309, 775, 406, 362, 4122, 11], "temperature": 0.0, "avg_logprob": -0.16106297629220145, "compression_ratio": 1.348993288590604, "no_speech_prob": 0.000458554713986814}, {"id": 340, "seek": 136100, "start": 1369.0, "end": 1374.0, "text": " but it is nice.", "tokens": [457, 309, 307, 1481, 13], "temperature": 0.0, "avg_logprob": -0.16106297629220145, "compression_ratio": 1.348993288590604, "no_speech_prob": 0.000458554713986814}, {"id": 341, "seek": 136100, "start": 1374.0, "end": 1377.0, "text": " And you can see, yes, it is a single HTML page", "tokens": [400, 291, 393, 536, 11, 2086, 11, 309, 307, 257, 2167, 17995, 3028], "temperature": 0.0, "avg_logprob": -0.16106297629220145, "compression_ratio": 1.348993288590604, "no_speech_prob": 0.000458554713986814}, {"id": 342, "seek": 136100, "start": 1377.0, "end": 1382.0, "text": " and here is a proof.", "tokens": [293, 510, 307, 257, 8177, 13], "temperature": 0.0, "avg_logprob": -0.16106297629220145, "compression_ratio": 1.348993288590604, "no_speech_prob": 0.000458554713986814}, {"id": 343, "seek": 136100, "start": 1382.0, "end": 1386.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.16106297629220145, "compression_ratio": 1.348993288590604, "no_speech_prob": 0.000458554713986814}, {"id": 344, "seek": 136100, "start": 1386.0, "end": 1389.0, "text": " So what do we have?", "tokens": [407, 437, 360, 321, 362, 30], "temperature": 0.0, "avg_logprob": -0.16106297629220145, "compression_ratio": 1.348993288590604, "no_speech_prob": 0.000458554713986814}, {"id": 345, "seek": 138900, "start": 1389.0, "end": 1393.0, "text": " We have created real-time dashboard with Clickhouse.", "tokens": [492, 362, 2942, 957, 12, 3766, 18342, 365, 8230, 6410, 13], "temperature": 0.0, "avg_logprob": -0.11458345901134402, "compression_ratio": 1.541871921182266, "no_speech_prob": 0.0028404404874891043}, {"id": 346, "seek": 138900, "start": 1393.0, "end": 1400.0, "text": " We have loaded 0.3 trillion records of data from a public data set.", "tokens": [492, 362, 13210, 1958, 13, 18, 18723, 7724, 295, 1412, 490, 257, 1908, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.11458345901134402, "compression_ratio": 1.541871921182266, "no_speech_prob": 0.0028404404874891043}, {"id": 347, "seek": 138900, "start": 1400.0, "end": 1404.0, "text": " It works, it works fast, it looks great.", "tokens": [467, 1985, 11, 309, 1985, 2370, 11, 309, 1542, 869, 13], "temperature": 0.0, "avg_logprob": -0.11458345901134402, "compression_ratio": 1.541871921182266, "no_speech_prob": 0.0028404404874891043}, {"id": 348, "seek": 138900, "start": 1404.0, "end": 1406.0, "text": " And if you want to build...", "tokens": [400, 498, 291, 528, 281, 1322, 485], "temperature": 0.0, "avg_logprob": -0.11458345901134402, "compression_ratio": 1.541871921182266, "no_speech_prob": 0.0028404404874891043}, {"id": 349, "seek": 138900, "start": 1406.0, "end": 1410.0, "text": " Actually, I don't insist you to use modern JavaScript.", "tokens": [5135, 11, 286, 500, 380, 13466, 291, 281, 764, 4363, 15778, 13], "temperature": 0.0, "avg_logprob": -0.11458345901134402, "compression_ratio": 1.541871921182266, "no_speech_prob": 0.0028404404874891043}, {"id": 350, "seek": 138900, "start": 1410.0, "end": 1417.0, "text": " I don't insist you to query Clickhouse directly from a user browser.", "tokens": [286, 500, 380, 13466, 291, 281, 14581, 8230, 6410, 3838, 490, 257, 4195, 11185, 13], "temperature": 0.0, "avg_logprob": -0.11458345901134402, "compression_ratio": 1.541871921182266, "no_speech_prob": 0.0028404404874891043}, {"id": 351, "seek": 141700, "start": 1417.0, "end": 1421.0, "text": " You can use Grafana superset meta-base.", "tokens": [509, 393, 764, 8985, 69, 2095, 37906, 302, 19616, 12, 17429, 13], "temperature": 0.0, "avg_logprob": -0.17048074781280204, "compression_ratio": 1.527027027027027, "no_speech_prob": 0.0009325808496214449}, {"id": 352, "seek": 141700, "start": 1421.0, "end": 1423.0, "text": " Streamlit, maybe, I'm not sure.", "tokens": [24904, 23062, 11, 1310, 11, 286, 478, 406, 988, 13], "temperature": 0.0, "avg_logprob": -0.17048074781280204, "compression_ratio": 1.527027027027027, "no_speech_prob": 0.0009325808496214449}, {"id": 353, "seek": 141700, "start": 1423.0, "end": 1426.0, "text": " But you can also build these small applications.", "tokens": [583, 291, 393, 611, 1322, 613, 1359, 5821, 13], "temperature": 0.0, "avg_logprob": -0.17048074781280204, "compression_ratio": 1.527027027027027, "no_speech_prob": 0.0009325808496214449}, {"id": 354, "seek": 141700, "start": 1426.0, "end": 1428.0, "text": " And I have built quite a few.", "tokens": [400, 286, 362, 3094, 1596, 257, 1326, 13], "temperature": 0.0, "avg_logprob": -0.17048074781280204, "compression_ratio": 1.527027027027027, "no_speech_prob": 0.0009325808496214449}, {"id": 355, "seek": 141700, "start": 1428.0, "end": 1434.0, "text": " There is Clickhouse Playground where you can explore some data sets.", "tokens": [821, 307, 8230, 6410, 5506, 2921, 689, 291, 393, 6839, 512, 1412, 6352, 13], "temperature": 0.0, "avg_logprob": -0.17048074781280204, "compression_ratio": 1.527027027027027, "no_speech_prob": 0.0009325808496214449}, {"id": 356, "seek": 141700, "start": 1434.0, "end": 1438.0, "text": " There is a web page for Clickhouse testing infrastructure.", "tokens": [821, 307, 257, 3670, 3028, 337, 8230, 6410, 4997, 6896, 13], "temperature": 0.0, "avg_logprob": -0.17048074781280204, "compression_ratio": 1.527027027027027, "no_speech_prob": 0.0009325808496214449}, {"id": 357, "seek": 141700, "start": 1438.0, "end": 1443.0, "text": " Name it R, test green, yet you can try and check what it is.", "tokens": [13866, 309, 497, 11, 1500, 3092, 11, 1939, 291, 393, 853, 293, 1520, 437, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.17048074781280204, "compression_ratio": 1.527027027027027, "no_speech_prob": 0.0009325808496214449}, {"id": 358, "seek": 144300, "start": 1443.0, "end": 1448.0, "text": " And the source code, dashboard HTML, is located in our repository.", "tokens": [400, 264, 4009, 3089, 11, 18342, 17995, 11, 307, 6870, 294, 527, 25841, 13], "temperature": 0.0, "avg_logprob": -0.1259763108359443, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001504378393292427}, {"id": 359, "seek": 144300, "start": 1448.0, "end": 1454.0, "text": " And just to note, this service is not original.", "tokens": [400, 445, 281, 3637, 11, 341, 2643, 307, 406, 3380, 13], "temperature": 0.0, "avg_logprob": -0.1259763108359443, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001504378393292427}, {"id": 360, "seek": 144300, "start": 1454.0, "end": 1459.0, "text": " I have found multiple similar services, for example, WikiShark,", "tokens": [286, 362, 1352, 3866, 2531, 3328, 11, 337, 1365, 11, 35892, 7774, 809, 11], "temperature": 0.0, "avg_logprob": -0.1259763108359443, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001504378393292427}, {"id": 361, "seek": 144300, "start": 1459.0, "end": 1462.0, "text": " for the same trends on Wikipedia.", "tokens": [337, 264, 912, 13892, 322, 28999, 13], "temperature": 0.0, "avg_logprob": -0.1259763108359443, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001504378393292427}, {"id": 362, "seek": 144300, "start": 1462.0, "end": 1469.0, "text": " But on WikiShark, there is a description that the author...", "tokens": [583, 322, 35892, 7774, 809, 11, 456, 307, 257, 3855, 300, 264, 3793, 485], "temperature": 0.0, "avg_logprob": -0.1259763108359443, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.001504378393292427}, {"id": 363, "seek": 146900, "start": 1469.0, "end": 1475.0, "text": " I did not remember, maybe he made a PhD implementing a data structure,", "tokens": [286, 630, 406, 1604, 11, 1310, 415, 1027, 257, 14476, 18114, 257, 1412, 3877, 11], "temperature": 0.0, "avg_logprob": -0.16401418999059877, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.0012004583841189742}, {"id": 364, "seek": 146900, "start": 1475.0, "end": 1477.0, "text": " custom data structure for this.", "tokens": [2375, 1412, 3877, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.16401418999059877, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.0012004583841189742}, {"id": 365, "seek": 146900, "start": 1477.0, "end": 1481.0, "text": " But he can simply load the data into Clickhouse.", "tokens": [583, 415, 393, 2935, 3677, 264, 1412, 666, 8230, 6410, 13], "temperature": 0.0, "avg_logprob": -0.16401418999059877, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.0012004583841189742}, {"id": 366, "seek": 146900, "start": 1481.0, "end": 1488.0, "text": " The experience of working with Clickhouse worth multiple PhDs.", "tokens": [440, 1752, 295, 1364, 365, 8230, 6410, 3163, 3866, 14476, 82, 13], "temperature": 0.0, "avg_logprob": -0.16401418999059877, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.0012004583841189742}, {"id": 367, "seek": 146900, "start": 1488.0, "end": 1490.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.16401418999059877, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.0012004583841189742}, {"id": 368, "seek": 146900, "start": 1490.0, "end": 1493.0, "text": " Thank you, that's it.", "tokens": [1044, 291, 11, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.16401418999059877, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.0012004583841189742}, {"id": 369, "seek": 149300, "start": 1493.0, "end": 1500.0, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.29146539404037153, "compression_ratio": 1.2333333333333334, "no_speech_prob": 0.006553261540830135}, {"id": 370, "seek": 149300, "start": 1500.0, "end": 1505.0, "text": " We do have time for multiple questions.", "tokens": [492, 360, 362, 565, 337, 3866, 1651, 13], "temperature": 0.0, "avg_logprob": -0.29146539404037153, "compression_ratio": 1.2333333333333334, "no_speech_prob": 0.006553261540830135}, {"id": 371, "seek": 149300, "start": 1505.0, "end": 1509.0, "text": " More than JavaScript, for example.", "tokens": [5048, 813, 15778, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.29146539404037153, "compression_ratio": 1.2333333333333334, "no_speech_prob": 0.006553261540830135}, {"id": 372, "seek": 149300, "start": 1509.0, "end": 1514.0, "text": " Why is this super fast?", "tokens": [1545, 307, 341, 1687, 2370, 30], "temperature": 0.0, "avg_logprob": -0.29146539404037153, "compression_ratio": 1.2333333333333334, "no_speech_prob": 0.006553261540830135}, {"id": 373, "seek": 149300, "start": 1514.0, "end": 1516.0, "text": " Very easy.", "tokens": [4372, 1858, 13], "temperature": 0.0, "avg_logprob": -0.29146539404037153, "compression_ratio": 1.2333333333333334, "no_speech_prob": 0.006553261540830135}, {"id": 374, "seek": 149300, "start": 1516.0, "end": 1520.0, "text": " Why this dashboard is fast?", "tokens": [1545, 341, 18342, 307, 2370, 30], "temperature": 0.0, "avg_logprob": -0.29146539404037153, "compression_ratio": 1.2333333333333334, "no_speech_prob": 0.006553261540830135}, {"id": 375, "seek": 152000, "start": 1520.0, "end": 1524.0, "text": " Because it's processing very fast.", "tokens": [1436, 309, 311, 9007, 588, 2370, 13], "temperature": 0.0, "avg_logprob": -0.16220678308958647, "compression_ratio": 1.6157635467980296, "no_speech_prob": 0.0023795203305780888}, {"id": 376, "seek": 152000, "start": 1524.0, "end": 1526.0, "text": " Why it is inserting fast?", "tokens": [1545, 309, 307, 46567, 2370, 30], "temperature": 0.0, "avg_logprob": -0.16220678308958647, "compression_ratio": 1.6157635467980296, "no_speech_prob": 0.0023795203305780888}, {"id": 377, "seek": 152000, "start": 1526.0, "end": 1528.0, "text": " Why it is selecting fast?", "tokens": [1545, 309, 307, 18182, 2370, 30], "temperature": 0.0, "avg_logprob": -0.16220678308958647, "compression_ratio": 1.6157635467980296, "no_speech_prob": 0.0023795203305780888}, {"id": 378, "seek": 152000, "start": 1528.0, "end": 1530.0, "text": " Because I always profile it.", "tokens": [1436, 286, 1009, 7964, 309, 13], "temperature": 0.0, "avg_logprob": -0.16220678308958647, "compression_ratio": 1.6157635467980296, "no_speech_prob": 0.0023795203305780888}, {"id": 379, "seek": 152000, "start": 1530.0, "end": 1535.0, "text": " You have seen, I always look at what is happening inside the code.", "tokens": [509, 362, 1612, 11, 286, 1009, 574, 412, 437, 307, 2737, 1854, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.16220678308958647, "compression_ratio": 1.6157635467980296, "no_speech_prob": 0.0023795203305780888}, {"id": 380, "seek": 152000, "start": 1535.0, "end": 1537.0, "text": " What can be optimized?", "tokens": [708, 393, 312, 26941, 30], "temperature": 0.0, "avg_logprob": -0.16220678308958647, "compression_ratio": 1.6157635467980296, "no_speech_prob": 0.0023795203305780888}, {"id": 381, "seek": 152000, "start": 1537.0, "end": 1540.0, "text": " If I see that, like some percent of time,", "tokens": [759, 286, 536, 300, 11, 411, 512, 3043, 295, 565, 11], "temperature": 0.0, "avg_logprob": -0.16220678308958647, "compression_ratio": 1.6157635467980296, "no_speech_prob": 0.0023795203305780888}, {"id": 382, "seek": 152000, "start": 1540.0, "end": 1543.0, "text": " spent doing nothing for mem copy,", "tokens": [4418, 884, 1825, 337, 1334, 5055, 11], "temperature": 0.0, "avg_logprob": -0.16220678308958647, "compression_ratio": 1.6157635467980296, "no_speech_prob": 0.0023795203305780888}, {"id": 383, "seek": 152000, "start": 1543.0, "end": 1547.0, "text": " I'm thinking maybe I should optimize mem copy.", "tokens": [286, 478, 1953, 1310, 286, 820, 19719, 1334, 5055, 13], "temperature": 0.0, "avg_logprob": -0.16220678308958647, "compression_ratio": 1.6157635467980296, "no_speech_prob": 0.0023795203305780888}, {"id": 384, "seek": 154700, "start": 1547.0, "end": 1554.0, "text": " Maybe I should remove mem copy.", "tokens": [2704, 286, 820, 4159, 1334, 5055, 13], "temperature": 0.0, "avg_logprob": -0.1742739753117637, "compression_ratio": 1.35, "no_speech_prob": 0.0011157469125464559}, {"id": 385, "seek": 154700, "start": 1554.0, "end": 1559.0, "text": " But actually a very long list about everything.", "tokens": [583, 767, 257, 588, 938, 1329, 466, 1203, 13], "temperature": 0.0, "avg_logprob": -0.1742739753117637, "compression_ratio": 1.35, "no_speech_prob": 0.0011157469125464559}, {"id": 386, "seek": 154700, "start": 1559.0, "end": 1563.0, "text": " But still we are talking about one machine.", "tokens": [583, 920, 321, 366, 1417, 466, 472, 3479, 13], "temperature": 0.0, "avg_logprob": -0.1742739753117637, "compression_ratio": 1.35, "no_speech_prob": 0.0011157469125464559}, {"id": 387, "seek": 154700, "start": 1563.0, "end": 1566.0, "text": " If one machine can process all the data.", "tokens": [759, 472, 3479, 393, 1399, 439, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1742739753117637, "compression_ratio": 1.35, "no_speech_prob": 0.0011157469125464559}, {"id": 388, "seek": 154700, "start": 1566.0, "end": 1568.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.1742739753117637, "compression_ratio": 1.35, "no_speech_prob": 0.0011157469125464559}, {"id": 389, "seek": 154700, "start": 1568.0, "end": 1574.0, "text": " I just created a machine on AWS with GP2 EBS,", "tokens": [286, 445, 2942, 257, 3479, 322, 17650, 365, 26039, 17, 462, 8176, 11], "temperature": 0.0, "avg_logprob": -0.1742739753117637, "compression_ratio": 1.35, "no_speech_prob": 0.0011157469125464559}, {"id": 390, "seek": 157400, "start": 1574.0, "end": 1577.0, "text": " just in case.", "tokens": [445, 294, 1389, 13], "temperature": 0.0, "avg_logprob": -0.17503124475479126, "compression_ratio": 1.2654867256637168, "no_speech_prob": 0.0010355882113799453}, {"id": 391, "seek": 157400, "start": 1577.0, "end": 1579.0, "text": " Data was in S3.", "tokens": [11888, 390, 294, 318, 18, 13], "temperature": 0.0, "avg_logprob": -0.17503124475479126, "compression_ratio": 1.2654867256637168, "no_speech_prob": 0.0010355882113799453}, {"id": 392, "seek": 157400, "start": 1579.0, "end": 1580.0, "text": " I have uploaded.", "tokens": [286, 362, 17135, 13], "temperature": 0.0, "avg_logprob": -0.17503124475479126, "compression_ratio": 1.2654867256637168, "no_speech_prob": 0.0010355882113799453}, {"id": 393, "seek": 157400, "start": 1580.0, "end": 1589.0, "text": " By the way, maybe we have time for some demos.", "tokens": [3146, 264, 636, 11, 1310, 321, 362, 565, 337, 512, 33788, 13], "temperature": 0.0, "avg_logprob": -0.17503124475479126, "compression_ratio": 1.2654867256637168, "no_speech_prob": 0.0010355882113799453}, {"id": 394, "seek": 157400, "start": 1589.0, "end": 1601.0, "text": " But the resolution, the screen resolution is not.", "tokens": [583, 264, 8669, 11, 264, 2568, 8669, 307, 406, 13], "temperature": 0.0, "avg_logprob": -0.17503124475479126, "compression_ratio": 1.2654867256637168, "no_speech_prob": 0.0010355882113799453}, {"id": 395, "seek": 160100, "start": 1601.0, "end": 1605.0, "text": " And Wi-Fi stopped to work.", "tokens": [400, 14035, 12, 13229, 5936, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 396, "seek": 160100, "start": 1605.0, "end": 1610.0, "text": " So probably no demos.", "tokens": [407, 1391, 572, 33788, 13], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 397, "seek": 160100, "start": 1610.0, "end": 1612.0, "text": " But okay, next questions.", "tokens": [583, 1392, 11, 958, 1651, 13], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 398, "seek": 160100, "start": 1612.0, "end": 1614.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 399, "seek": 160100, "start": 1614.0, "end": 1615.0, "text": " Hello, thanks for the talk.", "tokens": [2425, 11, 3231, 337, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 400, "seek": 160100, "start": 1615.0, "end": 1617.0, "text": " You mentioned compression.", "tokens": [509, 2835, 19355, 13], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 401, "seek": 160100, "start": 1617.0, "end": 1620.0, "text": " Does that slow down select?", "tokens": [4402, 300, 2964, 760, 3048, 30], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 402, "seek": 160100, "start": 1620.0, "end": 1621.0, "text": " Not quite.", "tokens": [1726, 1596, 13], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 403, "seek": 160100, "start": 1621.0, "end": 1624.0, "text": " Actually compression can even improve select queries.", "tokens": [5135, 19355, 393, 754, 3470, 3048, 24109, 13], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 404, "seek": 160100, "start": 1624.0, "end": 1627.0, "text": " It is kind of paradoxical, but let me explain.", "tokens": [467, 307, 733, 295, 26221, 804, 11, 457, 718, 385, 2903, 13], "temperature": 0.0, "avg_logprob": -0.16063529324818807, "compression_ratio": 1.3819095477386936, "no_speech_prob": 0.000686946848873049}, {"id": 405, "seek": 162700, "start": 1627.0, "end": 1631.0, "text": " First, because less amount of data will be read from disk.", "tokens": [2386, 11, 570, 1570, 2372, 295, 1412, 486, 312, 1401, 490, 12355, 13], "temperature": 0.0, "avg_logprob": -0.10103264221778283, "compression_ratio": 1.7076023391812865, "no_speech_prob": 0.0019371758680790663}, {"id": 406, "seek": 162700, "start": 1631.0, "end": 1637.0, "text": " Second, because data read from disk is also cached in memory,", "tokens": [5736, 11, 570, 1412, 1401, 490, 12355, 307, 611, 269, 15095, 294, 4675, 11], "temperature": 0.0, "avg_logprob": -0.10103264221778283, "compression_ratio": 1.7076023391812865, "no_speech_prob": 0.0019371758680790663}, {"id": 407, "seek": 162700, "start": 1637.0, "end": 1639.0, "text": " in the page cache.", "tokens": [294, 264, 3028, 19459, 13], "temperature": 0.0, "avg_logprob": -0.10103264221778283, "compression_ratio": 1.7076023391812865, "no_speech_prob": 0.0019371758680790663}, {"id": 408, "seek": 162700, "start": 1639.0, "end": 1642.0, "text": " And the page cache will contain compressed data.", "tokens": [400, 264, 3028, 19459, 486, 5304, 30353, 1412, 13], "temperature": 0.0, "avg_logprob": -0.10103264221778283, "compression_ratio": 1.7076023391812865, "no_speech_prob": 0.0019371758680790663}, {"id": 409, "seek": 162700, "start": 1642.0, "end": 1645.0, "text": " And when you process this data,", "tokens": [400, 562, 291, 1399, 341, 1412, 11], "temperature": 0.0, "avg_logprob": -0.10103264221778283, "compression_ratio": 1.7076023391812865, "no_speech_prob": 0.0019371758680790663}, {"id": 410, "seek": 162700, "start": 1645.0, "end": 1649.0, "text": " you will decompress this data into CPU cache", "tokens": [291, 486, 22867, 735, 341, 1412, 666, 13199, 19459], "temperature": 0.0, "avg_logprob": -0.10103264221778283, "compression_ratio": 1.7076023391812865, "no_speech_prob": 0.0019371758680790663}, {"id": 411, "seek": 162700, "start": 1649.0, "end": 1652.0, "text": " without using main memory.", "tokens": [1553, 1228, 2135, 4675, 13], "temperature": 0.0, "avg_logprob": -0.10103264221778283, "compression_ratio": 1.7076023391812865, "no_speech_prob": 0.0019371758680790663}, {"id": 412, "seek": 165200, "start": 1652.0, "end": 1657.0, "text": " So even...", "tokens": [407, 754, 485], "temperature": 0.0, "avg_logprob": -0.15636899736192492, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.0008615026017650962}, {"id": 413, "seek": 165200, "start": 1657.0, "end": 1658.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.15636899736192492, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.0008615026017650962}, {"id": 414, "seek": 165200, "start": 1658.0, "end": 1663.0, "text": " LZ4 from multiple threads can be faster than memory bandwidth.", "tokens": [441, 57, 19, 490, 3866, 19314, 393, 312, 4663, 813, 4675, 23647, 13], "temperature": 0.0, "avg_logprob": -0.15636899736192492, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.0008615026017650962}, {"id": 415, "seek": 165200, "start": 1663.0, "end": 1665.0, "text": " ZSTD not always.", "tokens": [1176, 6840, 35, 406, 1009, 13], "temperature": 0.0, "avg_logprob": -0.15636899736192492, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.0008615026017650962}, {"id": 416, "seek": 165200, "start": 1665.0, "end": 1671.0, "text": " But on servers like AMD Epic with 128 cores,", "tokens": [583, 322, 15909, 411, 34808, 26785, 365, 29810, 24826, 11], "temperature": 0.0, "avg_logprob": -0.15636899736192492, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.0008615026017650962}, {"id": 417, "seek": 165200, "start": 1671.0, "end": 1675.0, "text": " if you run ZSTD decompression in every core,", "tokens": [498, 291, 1190, 1176, 6840, 35, 22867, 2775, 294, 633, 4965, 11], "temperature": 0.0, "avg_logprob": -0.15636899736192492, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.0008615026017650962}, {"id": 418, "seek": 165200, "start": 1675.0, "end": 1681.0, "text": " it has a chance to be faster than memory.", "tokens": [309, 575, 257, 2931, 281, 312, 4663, 813, 4675, 13], "temperature": 0.0, "avg_logprob": -0.15636899736192492, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.0008615026017650962}, {"id": 419, "seek": 168100, "start": 1681.0, "end": 1683.0, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.1488121894940938, "compression_ratio": 1.3941176470588235, "no_speech_prob": 0.001267281943000853}, {"id": 420, "seek": 168100, "start": 1683.0, "end": 1688.0, "text": " So what is your total AWS bill for this project?", "tokens": [407, 437, 307, 428, 3217, 17650, 2961, 337, 341, 1716, 30], "temperature": 0.0, "avg_logprob": -0.1488121894940938, "compression_ratio": 1.3941176470588235, "no_speech_prob": 0.001267281943000853}, {"id": 421, "seek": 168100, "start": 1688.0, "end": 1693.0, "text": " I prepared it yesterday and used also S3,", "tokens": [286, 4927, 309, 5186, 293, 1143, 611, 318, 18, 11], "temperature": 0.0, "avg_logprob": -0.1488121894940938, "compression_ratio": 1.3941176470588235, "no_speech_prob": 0.001267281943000853}, {"id": 422, "seek": 168100, "start": 1693.0, "end": 1696.0, "text": " prepared before that.", "tokens": [4927, 949, 300, 13], "temperature": 0.0, "avg_logprob": -0.1488121894940938, "compression_ratio": 1.3941176470588235, "no_speech_prob": 0.001267281943000853}, {"id": 423, "seek": 168100, "start": 1696.0, "end": 1700.0, "text": " So let's calculate S3 cost.", "tokens": [407, 718, 311, 8873, 318, 18, 2063, 13], "temperature": 0.0, "avg_logprob": -0.1488121894940938, "compression_ratio": 1.3941176470588235, "no_speech_prob": 0.001267281943000853}, {"id": 424, "seek": 168100, "start": 1700.0, "end": 1704.0, "text": " I am storing the original data, three and a half terabytes.", "tokens": [286, 669, 26085, 264, 3380, 1412, 11, 1045, 293, 257, 1922, 1796, 24538, 13], "temperature": 0.0, "avg_logprob": -0.1488121894940938, "compression_ratio": 1.3941176470588235, "no_speech_prob": 0.001267281943000853}, {"id": 425, "seek": 168100, "start": 1704.0, "end": 1707.0, "text": " And it should be like 23.", "tokens": [400, 309, 820, 312, 411, 6673, 13], "temperature": 0.0, "avg_logprob": -0.1488121894940938, "compression_ratio": 1.3941176470588235, "no_speech_prob": 0.001267281943000853}, {"id": 426, "seek": 170700, "start": 1707.0, "end": 1712.0, "text": " But 23 is the least price per month for terabytes.", "tokens": [583, 6673, 307, 264, 1935, 3218, 680, 1618, 337, 1796, 24538, 13], "temperature": 0.0, "avg_logprob": -0.11510079354047775, "compression_ratio": 1.3496503496503496, "no_speech_prob": 0.00046017038403078914}, {"id": 427, "seek": 170700, "start": 1712.0, "end": 1720.0, "text": " So it will be like $70 per month", "tokens": [407, 309, 486, 312, 411, 1848, 5867, 680, 1618], "temperature": 0.0, "avg_logprob": -0.11510079354047775, "compression_ratio": 1.3496503496503496, "no_speech_prob": 0.00046017038403078914}, {"id": 428, "seek": 170700, "start": 1720.0, "end": 1722.0, "text": " if you don't have AWS discounts.", "tokens": [498, 291, 500, 380, 362, 17650, 37930, 13], "temperature": 0.0, "avg_logprob": -0.11510079354047775, "compression_ratio": 1.3496503496503496, "no_speech_prob": 0.00046017038403078914}, {"id": 429, "seek": 170700, "start": 1722.0, "end": 1727.0, "text": " But I do.", "tokens": [583, 286, 360, 13], "temperature": 0.0, "avg_logprob": -0.11510079354047775, "compression_ratio": 1.3496503496503496, "no_speech_prob": 0.00046017038403078914}, {"id": 430, "seek": 170700, "start": 1727.0, "end": 1729.0, "text": " And for the server,", "tokens": [400, 337, 264, 7154, 11], "temperature": 0.0, "avg_logprob": -0.11510079354047775, "compression_ratio": 1.3496503496503496, "no_speech_prob": 0.00046017038403078914}, {"id": 431, "seek": 170700, "start": 1729.0, "end": 1736.0, "text": " the server was about $4 per hour for a server.", "tokens": [264, 7154, 390, 466, 1848, 19, 680, 1773, 337, 257, 7154, 13], "temperature": 0.0, "avg_logprob": -0.11510079354047775, "compression_ratio": 1.3496503496503496, "no_speech_prob": 0.00046017038403078914}, {"id": 432, "seek": 173600, "start": 1736.0, "end": 1738.0, "text": " And something for GP2.", "tokens": [400, 746, 337, 26039, 17, 13], "temperature": 0.0, "avg_logprob": -0.09972740852669494, "compression_ratio": 1.4223602484472049, "no_speech_prob": 0.0013097873888909817}, {"id": 433, "seek": 173600, "start": 1738.0, "end": 1741.0, "text": " So maybe something like $5 per hour.", "tokens": [407, 1310, 746, 411, 1848, 20, 680, 1773, 13], "temperature": 0.0, "avg_logprob": -0.09972740852669494, "compression_ratio": 1.4223602484472049, "no_speech_prob": 0.0013097873888909817}, {"id": 434, "seek": 173600, "start": 1741.0, "end": 1743.0, "text": " And it is still running.", "tokens": [400, 309, 307, 920, 2614, 13], "temperature": 0.0, "avg_logprob": -0.09972740852669494, "compression_ratio": 1.4223602484472049, "no_speech_prob": 0.0013097873888909817}, {"id": 435, "seek": 173600, "start": 1743.0, "end": 1746.0, "text": " I started up it yesterday when I prepared the talk.", "tokens": [286, 1409, 493, 309, 5186, 562, 286, 4927, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.09972740852669494, "compression_ratio": 1.4223602484472049, "no_speech_prob": 0.0013097873888909817}, {"id": 436, "seek": 173600, "start": 1746.0, "end": 1754.0, "text": " And so 24 hours will be how many?", "tokens": [400, 370, 4022, 2496, 486, 312, 577, 867, 30], "temperature": 0.0, "avg_logprob": -0.09972740852669494, "compression_ratio": 1.4223602484472049, "no_speech_prob": 0.0013097873888909817}, {"id": 437, "seek": 173600, "start": 1754.0, "end": 1758.0, "text": " Something like maybe $50.", "tokens": [6595, 411, 1310, 1848, 2803, 13], "temperature": 0.0, "avg_logprob": -0.09972740852669494, "compression_ratio": 1.4223602484472049, "no_speech_prob": 0.0013097873888909817}, {"id": 438, "seek": 173600, "start": 1758.0, "end": 1762.0, "text": " Okay, I spent $50 for this talk.", "tokens": [1033, 11, 286, 4418, 1848, 2803, 337, 341, 751, 13], "temperature": 0.0, "avg_logprob": -0.09972740852669494, "compression_ratio": 1.4223602484472049, "no_speech_prob": 0.0013097873888909817}, {"id": 439, "seek": 176200, "start": 1762.0, "end": 1768.0, "text": " Is your S3 back in public?", "tokens": [1119, 428, 318, 18, 646, 294, 1908, 30], "temperature": 0.0, "avg_logprob": -0.21381662108681418, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.004112062975764275}, {"id": 440, "seek": 176200, "start": 1768.0, "end": 1770.0, "text": " Yeah, it is public.", "tokens": [865, 11, 309, 307, 1908, 13], "temperature": 0.0, "avg_logprob": -0.21381662108681418, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.004112062975764275}, {"id": 441, "seek": 176200, "start": 1770.0, "end": 1773.0, "text": " So keep in mind, if you will abuse it,", "tokens": [407, 1066, 294, 1575, 11, 498, 291, 486, 9852, 309, 11], "temperature": 0.0, "avg_logprob": -0.21381662108681418, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.004112062975764275}, {"id": 442, "seek": 176200, "start": 1773.0, "end": 1781.0, "text": " we will simply turn it off.", "tokens": [321, 486, 2935, 1261, 309, 766, 13], "temperature": 0.0, "avg_logprob": -0.21381662108681418, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.004112062975764275}, {"id": 443, "seek": 176200, "start": 1781.0, "end": 1783.0, "text": " Maybe another question about S3.", "tokens": [2704, 1071, 1168, 466, 318, 18, 13], "temperature": 0.0, "avg_logprob": -0.21381662108681418, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.004112062975764275}, {"id": 444, "seek": 176200, "start": 1783.0, "end": 1785.0, "text": " What type of connectors do you have to S3?", "tokens": [708, 2010, 295, 31865, 360, 291, 362, 281, 318, 18, 30], "temperature": 0.0, "avg_logprob": -0.21381662108681418, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.004112062975764275}, {"id": 445, "seek": 176200, "start": 1785.0, "end": 1787.0, "text": " Is it just for uploading?", "tokens": [1119, 309, 445, 337, 27301, 30], "temperature": 0.0, "avg_logprob": -0.21381662108681418, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.004112062975764275}, {"id": 446, "seek": 176200, "start": 1787.0, "end": 1791.0, "text": " Or can you also use S3 for indexing and storing data?", "tokens": [1610, 393, 291, 611, 764, 318, 18, 337, 8186, 278, 293, 26085, 1412, 30], "temperature": 0.0, "avg_logprob": -0.21381662108681418, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.004112062975764275}, {"id": 447, "seek": 179100, "start": 1791.0, "end": 1793.0, "text": " Yes, you can.", "tokens": [1079, 11, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.15348062282655298, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0031121058855205774}, {"id": 448, "seek": 179100, "start": 1793.0, "end": 1795.0, "text": " And in multiple different ways.", "tokens": [400, 294, 3866, 819, 2098, 13], "temperature": 0.0, "avg_logprob": -0.15348062282655298, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0031121058855205774}, {"id": 449, "seek": 179100, "start": 1795.0, "end": 1799.0, "text": " First, just a bunch of files on S3.", "tokens": [2386, 11, 445, 257, 3840, 295, 7098, 322, 318, 18, 13], "temperature": 0.0, "avg_logprob": -0.15348062282655298, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0031121058855205774}, {"id": 450, "seek": 179100, "start": 1799.0, "end": 1801.0, "text": " Process them as is.", "tokens": [31093, 552, 382, 307, 13], "temperature": 0.0, "avg_logprob": -0.15348062282655298, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0031121058855205774}, {"id": 451, "seek": 179100, "start": 1801.0, "end": 1806.0, "text": " Parquet, protobufs, Avro.", "tokens": [3457, 19343, 11, 1742, 996, 2947, 82, 11, 11667, 340, 13], "temperature": 0.0, "avg_logprob": -0.15348062282655298, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0031121058855205774}, {"id": 452, "seek": 179100, "start": 1806.0, "end": 1807.0, "text": " Avro does not matter.", "tokens": [11667, 340, 775, 406, 1871, 13], "temperature": 0.0, "avg_logprob": -0.15348062282655298, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0031121058855205774}, {"id": 453, "seek": 179100, "start": 1807.0, "end": 1809.0, "text": " Everything works.", "tokens": [5471, 1985, 13], "temperature": 0.0, "avg_logprob": -0.15348062282655298, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0031121058855205774}, {"id": 454, "seek": 179100, "start": 1809.0, "end": 1817.0, "text": " Second, you can process files in Apache Delta Lake", "tokens": [5736, 11, 291, 393, 1399, 7098, 294, 46597, 18183, 10582], "temperature": 0.0, "avg_logprob": -0.15348062282655298, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0031121058855205774}, {"id": 455, "seek": 179100, "start": 1817.0, "end": 1819.0, "text": " or Apache Hoodie.", "tokens": [420, 46597, 33213, 414, 13], "temperature": 0.0, "avg_logprob": -0.15348062282655298, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0031121058855205774}, {"id": 456, "seek": 181900, "start": 1819.0, "end": 1823.0, "text": " Asperk will be supported maybe in the next release.", "tokens": [1018, 610, 74, 486, 312, 8104, 1310, 294, 264, 958, 4374, 13], "temperature": 0.0, "avg_logprob": -0.25165422439575197, "compression_ratio": 1.3925925925925926, "no_speech_prob": 0.0005362430238164961}, {"id": 457, "seek": 181900, "start": 1823.0, "end": 1831.0, "text": " So you can prepare data in your data bricks or Spark.", "tokens": [407, 291, 393, 5940, 1412, 294, 428, 1412, 25497, 420, 23424, 13], "temperature": 0.0, "avg_logprob": -0.25165422439575197, "compression_ratio": 1.3925925925925926, "no_speech_prob": 0.0005362430238164961}, {"id": 458, "seek": 181900, "start": 1831.0, "end": 1837.0, "text": " And process with Clickhouse because Clickhouse is better than Spark.", "tokens": [400, 1399, 365, 8230, 6410, 570, 8230, 6410, 307, 1101, 813, 23424, 13], "temperature": 0.0, "avg_logprob": -0.25165422439575197, "compression_ratio": 1.3925925925925926, "no_speech_prob": 0.0005362430238164961}, {"id": 459, "seek": 181900, "start": 1837.0, "end": 1839.0, "text": " Third option.", "tokens": [12548, 3614, 13], "temperature": 0.0, "avg_logprob": -0.25165422439575197, "compression_ratio": 1.3925925925925926, "no_speech_prob": 0.0005362430238164961}, {"id": 460, "seek": 183900, "start": 1839.0, "end": 1849.0, "text": " You can also plug in S3 as a virtual file system for merge three tables.", "tokens": [509, 393, 611, 5452, 294, 318, 18, 382, 257, 6374, 3991, 1185, 337, 22183, 1045, 8020, 13], "temperature": 0.0, "avg_logprob": -0.08399730343972484, "compression_ratio": 1.474025974025974, "no_speech_prob": 0.0007937675109133124}, {"id": 461, "seek": 183900, "start": 1849.0, "end": 1855.0, "text": " And it will be used not only for selects but also for inserts.", "tokens": [400, 309, 486, 312, 1143, 406, 787, 337, 3048, 82, 457, 611, 337, 49163, 13], "temperature": 0.0, "avg_logprob": -0.08399730343972484, "compression_ratio": 1.474025974025974, "no_speech_prob": 0.0007937675109133124}, {"id": 462, "seek": 183900, "start": 1855.0, "end": 1858.0, "text": " And you can have your servers almost stateless.", "tokens": [400, 291, 393, 362, 428, 15909, 1920, 2219, 4272, 13], "temperature": 0.0, "avg_logprob": -0.08399730343972484, "compression_ratio": 1.474025974025974, "no_speech_prob": 0.0007937675109133124}, {"id": 463, "seek": 183900, "start": 1858.0, "end": 1866.0, "text": " And the data will be in the object storage.", "tokens": [400, 264, 1412, 486, 312, 294, 264, 2657, 6725, 13], "temperature": 0.0, "avg_logprob": -0.08399730343972484, "compression_ratio": 1.474025974025974, "no_speech_prob": 0.0007937675109133124}, {"id": 464, "seek": 186600, "start": 1866.0, "end": 1879.0, "text": " Yeah, plenty of options.", "tokens": [865, 11, 7140, 295, 3956, 13], "temperature": 0.0, "avg_logprob": -0.17532917947480173, "compression_ratio": 1.0864197530864197, "no_speech_prob": 0.001705401693470776}, {"id": 465, "seek": 186600, "start": 1879.0, "end": 1888.0, "text": " One more question.", "tokens": [1485, 544, 1168, 13], "temperature": 0.0, "avg_logprob": -0.17532917947480173, "compression_ratio": 1.0864197530864197, "no_speech_prob": 0.001705401693470776}, {"id": 466, "seek": 186600, "start": 1888.0, "end": 1889.0, "text": " Yeah, for sure.", "tokens": [865, 11, 337, 988, 13], "temperature": 0.0, "avg_logprob": -0.17532917947480173, "compression_ratio": 1.0864197530864197, "no_speech_prob": 0.001705401693470776}, {"id": 467, "seek": 186600, "start": 1889.0, "end": 1891.0, "text": " You can use it in a cluster.", "tokens": [509, 393, 764, 309, 294, 257, 13630, 13], "temperature": 0.0, "avg_logprob": -0.17532917947480173, "compression_ratio": 1.0864197530864197, "no_speech_prob": 0.001705401693470776}, {"id": 468, "seek": 189100, "start": 1891.0, "end": 1897.0, "text": " You can set up an insert in a distributed table and it will scale linearly.", "tokens": [509, 393, 992, 493, 364, 8969, 294, 257, 12631, 3199, 293, 309, 486, 4373, 43586, 13], "temperature": 0.0, "avg_logprob": -0.13853095372517904, "compression_ratio": 1.5886075949367089, "no_speech_prob": 0.001632083673030138}, {"id": 469, "seek": 189100, "start": 1897.0, "end": 1900.0, "text": " And these queries will also scale.", "tokens": [400, 613, 24109, 486, 611, 4373, 13], "temperature": 0.0, "avg_logprob": -0.13853095372517904, "compression_ratio": 1.5886075949367089, "no_speech_prob": 0.001632083673030138}, {"id": 470, "seek": 189100, "start": 1900.0, "end": 1907.0, "text": " The queries that take already like 9 milliseconds, 10 milliseconds will take not less.", "tokens": [440, 24109, 300, 747, 1217, 411, 1722, 34184, 11, 1266, 34184, 486, 747, 406, 1570, 13], "temperature": 0.0, "avg_logprob": -0.13853095372517904, "compression_ratio": 1.5886075949367089, "no_speech_prob": 0.001632083673030138}, {"id": 471, "seek": 189100, "start": 1907.0, "end": 1911.0, "text": " Maybe they will take even more, like 15 milliseconds.", "tokens": [2704, 436, 486, 747, 754, 544, 11, 411, 2119, 34184, 13], "temperature": 0.0, "avg_logprob": -0.13853095372517904, "compression_ratio": 1.5886075949367089, "no_speech_prob": 0.001632083673030138}, {"id": 472, "seek": 191100, "start": 1911.0, "end": 1925.0, "text": " But the queries that took seconds, minutes, they will scale linearly.", "tokens": [583, 264, 24109, 300, 1890, 3949, 11, 2077, 11, 436, 486, 4373, 43586, 13], "temperature": 0.0, "avg_logprob": -0.12851916188779083, "compression_ratio": 1.2692307692307692, "no_speech_prob": 0.00045811664313077927}, {"id": 473, "seek": 191100, "start": 1925.0, "end": 1927.0, "text": " Theoretically, no.", "tokens": [440, 26262, 984, 11, 572, 13], "temperature": 0.0, "avg_logprob": -0.12851916188779083, "compression_ratio": 1.2692307692307692, "no_speech_prob": 0.00045811664313077927}, {"id": 474, "seek": 191100, "start": 1927.0, "end": 1935.0, "text": " But in practice, some companies are using Clickhouse on over 1,000 of nodes.", "tokens": [583, 294, 3124, 11, 512, 3431, 366, 1228, 8230, 6410, 322, 670, 502, 11, 1360, 295, 13891, 13], "temperature": 0.0, "avg_logprob": -0.12851916188779083, "compression_ratio": 1.2692307692307692, "no_speech_prob": 0.00045811664313077927}, {"id": 475, "seek": 193500, "start": 1935.0, "end": 1941.0, "text": " Many companies are using Clickhouse on several hundreds of nodes.", "tokens": [5126, 3431, 366, 1228, 8230, 6410, 322, 2940, 6779, 295, 13891, 13], "temperature": 0.0, "avg_logprob": -0.04619284967581431, "compression_ratio": 1.4605263157894737, "no_speech_prob": 0.0006031437078490853}, {"id": 476, "seek": 193500, "start": 1941.0, "end": 1946.0, "text": " When you have to deal with clusters with hundreds and thousands of nodes,", "tokens": [1133, 291, 362, 281, 2028, 365, 23313, 365, 6779, 293, 5383, 295, 13891, 11], "temperature": 0.0, "avg_logprob": -0.04619284967581431, "compression_ratio": 1.4605263157894737, "no_speech_prob": 0.0006031437078490853}, {"id": 477, "seek": 193500, "start": 1946.0, "end": 1956.0, "text": " especially if it is geographically distributed, you will definitely have troubles.", "tokens": [2318, 498, 309, 307, 25435, 984, 12631, 11, 291, 486, 2138, 362, 15379, 13], "temperature": 0.0, "avg_logprob": -0.04619284967581431, "compression_ratio": 1.4605263157894737, "no_speech_prob": 0.0006031437078490853}, {"id": 478, "seek": 195600, "start": 1956.0, "end": 1982.0, "text": " But with Clickhouse, it is totally possible to have these clusters and it will work.", "tokens": [583, 365, 8230, 6410, 11, 309, 307, 3879, 1944, 281, 362, 613, 23313, 293, 309, 486, 589, 13], "temperature": 0.0, "avg_logprob": -0.08570454879240556, "compression_ratio": 1.05, "no_speech_prob": 0.0012237122282385826}, {"id": 479, "seek": 198200, "start": 1982.0, "end": 1990.0, "text": " Another question.", "tokens": [3996, 1168, 13], "temperature": 0.0, "avg_logprob": -0.1995397032352916, "compression_ratio": 1.5705128205128205, "no_speech_prob": 0.00024926807964220643}, {"id": 480, "seek": 198200, "start": 1990.0, "end": 1998.0, "text": " Interesting question because maybe you are asking about what are the data structures inside.", "tokens": [14711, 1168, 570, 1310, 291, 366, 3365, 466, 437, 366, 264, 1412, 9227, 1854, 13], "temperature": 0.0, "avg_logprob": -0.1995397032352916, "compression_ratio": 1.5705128205128205, "no_speech_prob": 0.00024926807964220643}, {"id": 481, "seek": 198200, "start": 1998.0, "end": 2005.0, "text": " Maybe you are asking, is Clickhouse based on some readily available data structures?", "tokens": [2704, 291, 366, 3365, 11, 307, 8230, 6410, 2361, 322, 512, 26336, 2435, 1412, 9227, 30], "temperature": 0.0, "avg_logprob": -0.1995397032352916, "compression_ratio": 1.5705128205128205, "no_speech_prob": 0.00024926807964220643}, {"id": 482, "seek": 198200, "start": 2005.0, "end": 2009.0, "text": " The data format, Clickhouse Merge 3, is original.", "tokens": [440, 1412, 7877, 11, 8230, 6410, 6124, 432, 805, 11, 307, 3380, 13], "temperature": 0.0, "avg_logprob": -0.1995397032352916, "compression_ratio": 1.5705128205128205, "no_speech_prob": 0.00024926807964220643}, {"id": 483, "seek": 200900, "start": 2009.0, "end": 2016.0, "text": " You can think that maybe it is somehow similar to Apache Iceberg, maybe.", "tokens": [509, 393, 519, 300, 1310, 309, 307, 6063, 2531, 281, 46597, 15332, 6873, 11, 1310, 13], "temperature": 0.0, "avg_logprob": -0.11721181074778239, "compression_ratio": 1.46875, "no_speech_prob": 0.001144237583503127}, {"id": 484, "seek": 200900, "start": 2016.0, "end": 2018.0, "text": " But actually not.", "tokens": [583, 767, 406, 13], "temperature": 0.0, "avg_logprob": -0.11721181074778239, "compression_ratio": 1.46875, "no_speech_prob": 0.001144237583503127}, {"id": 485, "seek": 200900, "start": 2018.0, "end": 2026.0, "text": " The column format in memory and the network transfer format is also original,", "tokens": [440, 7738, 7877, 294, 4675, 293, 264, 3209, 5003, 7877, 307, 611, 3380, 11], "temperature": 0.0, "avg_logprob": -0.11721181074778239, "compression_ratio": 1.46875, "no_speech_prob": 0.001144237583503127}, {"id": 486, "seek": 200900, "start": 2026.0, "end": 2029.0, "text": " but it is very similar to Apache Arrow.", "tokens": [457, 309, 307, 588, 2531, 281, 46597, 40269, 13], "temperature": 0.0, "avg_logprob": -0.11721181074778239, "compression_ratio": 1.46875, "no_speech_prob": 0.001144237583503127}, {"id": 487, "seek": 200900, "start": 2029.0, "end": 2033.0, "text": " That's slightly different.", "tokens": [663, 311, 4748, 819, 13], "temperature": 0.0, "avg_logprob": -0.11721181074778239, "compression_ratio": 1.46875, "no_speech_prob": 0.001144237583503127}, {"id": 488, "seek": 203300, "start": 2033.0, "end": 2039.0, "text": " The algorithms, actually, we took every good algorithm from everywhere.", "tokens": [440, 14642, 11, 767, 11, 321, 1890, 633, 665, 9284, 490, 5315, 13], "temperature": 0.0, "avg_logprob": -0.17498121423236393, "compression_ratio": 1.4606060606060607, "no_speech_prob": 0.003076341701671481}, {"id": 489, "seek": 203300, "start": 2039.0, "end": 2046.0, "text": " If someone writes a blog post on the Internet like about,", "tokens": [759, 1580, 13657, 257, 6968, 2183, 322, 264, 7703, 411, 466, 11], "temperature": 0.0, "avg_logprob": -0.17498121423236393, "compression_ratio": 1.4606060606060607, "no_speech_prob": 0.003076341701671481}, {"id": 490, "seek": 203300, "start": 2046.0, "end": 2049.0, "text": " I have implemented the best hash table.", "tokens": [286, 362, 12270, 264, 1151, 22019, 3199, 13], "temperature": 0.0, "avg_logprob": -0.17498121423236393, "compression_ratio": 1.4606060606060607, "no_speech_prob": 0.003076341701671481}, {"id": 491, "seek": 203300, "start": 2049.0, "end": 2062.0, "text": " Instantly, someone from my team will try and test it inside Clickhouse.", "tokens": [2730, 3627, 11, 1580, 490, 452, 1469, 486, 853, 293, 1500, 309, 1854, 8230, 6410, 13], "temperature": 0.0, "avg_logprob": -0.17498121423236393, "compression_ratio": 1.4606060606060607, "no_speech_prob": 0.003076341701671481}, {"id": 492, "seek": 206200, "start": 2062.0, "end": 2065.0, "text": " Okay, looks like no more questions.", "tokens": [1033, 11, 1542, 411, 572, 544, 1651, 13], "temperature": 0.0, "avg_logprob": -0.22100898623466492, "compression_ratio": 0.8518518518518519, "no_speech_prob": 0.0008577514090575278}, {"id": 493, "seek": 206500, "start": 2065.0, "end": 2094.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13718915979067484, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.0006250151782296598}], "language": "en"}