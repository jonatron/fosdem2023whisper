{"text": " Alright, good morning everyone. My name is Jan Simon Muller. I work on the Automotive Great Linux project and today I want to talk about how we produce our S-bombs or what we evaluated, what we did, what we learned and yeah, some lessons learned. If you want to reach me just find my email or find the AGL ISC channel or what not, there you can contact me. Okay, in a nutshell, AGL is an open source platform for different users in the car. We started with infotainment. We have also an instrument cluster profile, telematics profile and we are also working on software divine vehicle. There is a virtualization expert group and all of that. Code first so you can go to our website, you can download pre-built releases, you can clone the stuff, rebuild it, everything is there. And we built with the Yocto project, so we are essentially a collection of layers. Yocto plus some automotive software and tooling. So for S-bombs, things started around like three years ago when one of the member companies looked into how to generate S-bombs kind of early and they were looking for an in-house solution and they were basically developing that within AGL, presenting and doing stuff. We encouraged them to do that upstream, have a repo within AGL and out of that, we then told them, you know, that should actually go more upstream. So that ended up on git.yachtoproject.org and that's META SPDX scanner. So initially there was just one tool supported in there and that was upload to phosology. So they were looking into a combination of phosology and SW360. That's what they were evaluating and that basically gives you Yocto build, upload to phosology. Phosology will do the scanning and then later on you move the data into SW360. That was their plan. In principle, that's a post-mortem, that's a post-build approach. You take the sources that were exported from the build, the patched sources and then do analysis on it. All of that predates the now available Create SPDX in Yocto. So that was before that time. To make that work, you need to set up a phosology server. You need to upload the sources. It will then run, I think, five different scanners on it and then essentially you get the results for manual review and correction and whatnot. So you really need to sit down, inspect the result, make decisions on where the scanners are unsure and make a final verdict and then you can output the data, put it into other tooling. Meanwhile, there are at least three different tools supported in that layer. One is for Solotree, the other is CanCode and the third is an uploader for commercial tool. After that, later Joshua Hulthog right after me added support for exporting SPDX files right during the build from Yocto. So the difference is that this happens right at the build stage with all the data, metadata we know there and it does not require an external server. It uses the available metadata we have. So it's faster for us. It runs during the build and basically it's close to no additional resources consumed. We now have that enabled. So for our releases and the stuff, you'll find the SPDX files right next to the artifacts. Okay, great. What did we learn essentially? It depends now from an open source project versus in-house product and so on. For us, the Solotree approach or the approach with the scanner, I don't want to pick on one here, it required way more CPU resources. You need to shuffle all the source tower balls up and down. It requires manual review and that was for kind of for the open source project side. That was just too much, right? And actually we lost information once we went from the build to the external scanner. Basically, what does this belong to? Which build is this? Yes, you can partially solve that by folder naming and help out on that but you'll lose a connection here. On the other side, it depends on your requirements. If your legal department in the end says we have to scan, right? Because even if we get most of the artifacts from, let's say, supplier, we still add something, right? Or we need to know for sure, then you have to scan, period. And that's what actually happens for us. Our members, essentially, they have to scan because they add stuff on their own. So in the end, they have to scan their final stuff anyway, right? So for us, we took then the route to take the faster way. We take the analysis during the build and use that. And there is one basically thing that we have to solve at a more global level. The data we have and we provide, which we basically can say, okay, this is our sources that you consume. Does the legal department accept that and trust it? Or will they go ahead and say, we have inspected everything again? So that's a crucial point. Yeah, so right now, we are basically at the stage, all right, we can create the SPDX files. But how can I consume it? How can I present it? Basically, the S-bombs, it's relatively new in the end. So the tooling is still evolving. So the tooling is new. And for us, we are looking for how can we present this in a way that makes it easily consumable. Essentially, let's say for our CI purpose, we would like to know is there anything that was added that changed? So the diff is interesting. Yeah, that's an essential next step for us. All right, questions? So, Josh will detail that. Yes, so what information goes into the SPDX files here? Yeah, what that will come in the next talk. Yeah, so I don't want to steal Josh, the funder from Josh. He has it in his slides, I know. So I think your slide probably answers this. You're producing S-bombs, but you're not doing anything with them. So it's just basically, have I created a file? Yes. Yeah, right now, we are at the stage, okay, check, S-bombs created. Actually, I failed now a decision to say the build's not long. I've got to go back and change the build. Yeah, no, no, okay, no, no. So what are you doing differently to what you were doing before three years ago? We just do generating release notes. Yeah, yeah, so you're not so okay. Yeah, yeah. So, I mean, we are using the report tool. So we can basically ease and the diopto recipes. So we can easily say that's the diff in the recipes. So we changed this and this and this and that. But back then, no. Yeah. No, not yet. So there's two questions. How much of this code was used from the double open original project that was in the app too? This is the one that created the whole spdx generation on the app too. This is, I think this is the original code. Do you know? That's the question for Josh. Next talk. Why do you need the presentation visualization tool? Why are you reinventing the use if you already have a couple of tools already doing that? For presentation and presentation. Why are you working now? It would be the next step for us. So I'm not saying we develop this. Basically, we are looking now, start using what exists. I'm not saying we are reinventing the wheel. I'm going step by step. So I'm an, I'm an adopter. Yeah. So that's why I'll sit in and listen. As to the problem you mentioned before about the choice between using phosology review, we face the same problem in our project. And the way we solved it is to decouple the two processes. So you provide input for phosology with one more pipeline. Yeah. And then leave it, the only thing work. And then when the data is ready, you can import them in subsequently. Yeah. So the only way, because in this way you can provide input to the audit team so they can work timely before the release. Yes. And then you basically feed that back into, I mean, if you have a release build, right? For release builds, we have, we can. No, but we do that also from the time. Okay. Okay. Thank you very much. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.72, "text": " Alright, good morning everyone. My name is Jan Simon Muller. I work on the Automotive", "tokens": [50364, 2798, 11, 665, 2446, 1518, 13, 1222, 1315, 307, 4956, 13193, 41621, 260, 13, 286, 589, 322, 264, 24619, 22459, 51100], "temperature": 0.0, "avg_logprob": -0.3376777569452922, "compression_ratio": 1.2608695652173914, "no_speech_prob": 0.17009486258029938}, {"id": 1, "seek": 0, "start": 14.72, "end": 25.52, "text": " Great Linux project and today I want to talk about how we produce our S-bombs or what we", "tokens": [51100, 3769, 18734, 1716, 293, 965, 286, 528, 281, 751, 466, 577, 321, 5258, 527, 318, 12, 65, 298, 929, 420, 437, 321, 51640], "temperature": 0.0, "avg_logprob": -0.3376777569452922, "compression_ratio": 1.2608695652173914, "no_speech_prob": 0.17009486258029938}, {"id": 2, "seek": 2552, "start": 25.52, "end": 37.56, "text": " evaluated, what we did, what we learned and yeah, some lessons learned. If you want to", "tokens": [50364, 25509, 11, 437, 321, 630, 11, 437, 321, 3264, 293, 1338, 11, 512, 8820, 3264, 13, 759, 291, 528, 281, 50966], "temperature": 0.0, "avg_logprob": -0.30635776519775393, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.10014467686414719}, {"id": 3, "seek": 2552, "start": 37.56, "end": 45.120000000000005, "text": " reach me just find my email or find the AGL ISC channel or what not, there you can contact me.", "tokens": [50966, 2524, 385, 445, 915, 452, 3796, 420, 915, 264, 316, 19440, 6205, 34, 2269, 420, 437, 406, 11, 456, 291, 393, 3385, 385, 13, 51344], "temperature": 0.0, "avg_logprob": -0.30635776519775393, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.10014467686414719}, {"id": 4, "seek": 4512, "start": 45.559999999999995, "end": 57.519999999999996, "text": " Okay, in a nutshell, AGL is an open source platform for different users in the car. We", "tokens": [50386, 1033, 11, 294, 257, 37711, 11, 316, 19440, 307, 364, 1269, 4009, 3663, 337, 819, 5022, 294, 264, 1032, 13, 492, 50984], "temperature": 0.0, "avg_logprob": -0.259006353525015, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.05718526616692543}, {"id": 5, "seek": 4512, "start": 57.519999999999996, "end": 64.67999999999999, "text": " started with infotainment. We have also an instrument cluster profile, telematics profile", "tokens": [50984, 1409, 365, 1536, 310, 491, 518, 13, 492, 362, 611, 364, 7198, 13630, 7964, 11, 4304, 15677, 1167, 7964, 51342], "temperature": 0.0, "avg_logprob": -0.259006353525015, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.05718526616692543}, {"id": 6, "seek": 4512, "start": 64.67999999999999, "end": 73.88, "text": " and we are also working on software divine vehicle. There is a virtualization expert group", "tokens": [51342, 293, 321, 366, 611, 1364, 322, 4722, 13678, 5864, 13, 821, 307, 257, 6374, 2144, 5844, 1594, 51802], "temperature": 0.0, "avg_logprob": -0.259006353525015, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.05718526616692543}, {"id": 7, "seek": 7388, "start": 73.88, "end": 80.6, "text": " and all of that. Code first so you can go to our website, you can download pre-built releases,", "tokens": [50364, 293, 439, 295, 300, 13, 15549, 700, 370, 291, 393, 352, 281, 527, 3144, 11, 291, 393, 5484, 659, 12, 23018, 16952, 11, 50700], "temperature": 0.0, "avg_logprob": -0.18643409258698765, "compression_ratio": 1.5351351351351352, "no_speech_prob": 0.02084510028362274}, {"id": 8, "seek": 7388, "start": 80.6, "end": 89.36, "text": " you can clone the stuff, rebuild it, everything is there. And we built with the Yocto project,", "tokens": [50700, 291, 393, 26506, 264, 1507, 11, 16877, 309, 11, 1203, 307, 456, 13, 400, 321, 3094, 365, 264, 7616, 349, 78, 1716, 11, 51138], "temperature": 0.0, "avg_logprob": -0.18643409258698765, "compression_ratio": 1.5351351351351352, "no_speech_prob": 0.02084510028362274}, {"id": 9, "seek": 7388, "start": 89.36, "end": 97.75999999999999, "text": " so we are essentially a collection of layers. Yocto plus some automotive software and tooling.", "tokens": [51138, 370, 321, 366, 4476, 257, 5765, 295, 7914, 13, 7616, 349, 78, 1804, 512, 32866, 4722, 293, 46593, 13, 51558], "temperature": 0.0, "avg_logprob": -0.18643409258698765, "compression_ratio": 1.5351351351351352, "no_speech_prob": 0.02084510028362274}, {"id": 10, "seek": 9776, "start": 97.76, "end": 112.28, "text": " So for S-bombs, things started around like three years ago when one of the member companies", "tokens": [50364, 407, 337, 318, 12, 65, 298, 929, 11, 721, 1409, 926, 411, 1045, 924, 2057, 562, 472, 295, 264, 4006, 3431, 51090], "temperature": 0.0, "avg_logprob": -0.1715398710601184, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.003529811045154929}, {"id": 11, "seek": 9776, "start": 112.28, "end": 122.60000000000001, "text": " looked into how to generate S-bombs kind of early and they were looking for an in-house", "tokens": [51090, 2956, 666, 577, 281, 8460, 318, 12, 65, 298, 929, 733, 295, 2440, 293, 436, 645, 1237, 337, 364, 294, 12, 6410, 51606], "temperature": 0.0, "avg_logprob": -0.1715398710601184, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.003529811045154929}, {"id": 12, "seek": 12260, "start": 122.64, "end": 130.32, "text": " solution and they were basically developing that within AGL, presenting and doing stuff.", "tokens": [50366, 3827, 293, 436, 645, 1936, 6416, 300, 1951, 316, 19440, 11, 15578, 293, 884, 1507, 13, 50750], "temperature": 0.0, "avg_logprob": -0.19824348934113034, "compression_ratio": 1.5058823529411764, "no_speech_prob": 0.00829943735152483}, {"id": 13, "seek": 12260, "start": 130.32, "end": 139.12, "text": " We encouraged them to do that upstream, have a repo within AGL and out of that,", "tokens": [50750, 492, 14658, 552, 281, 360, 300, 33915, 11, 362, 257, 49040, 1951, 316, 19440, 293, 484, 295, 300, 11, 51190], "temperature": 0.0, "avg_logprob": -0.19824348934113034, "compression_ratio": 1.5058823529411764, "no_speech_prob": 0.00829943735152483}, {"id": 14, "seek": 12260, "start": 139.12, "end": 148.32, "text": " we then told them, you know, that should actually go more upstream. So that ended up on", "tokens": [51190, 321, 550, 1907, 552, 11, 291, 458, 11, 300, 820, 767, 352, 544, 33915, 13, 407, 300, 4590, 493, 322, 51650], "temperature": 0.0, "avg_logprob": -0.19824348934113034, "compression_ratio": 1.5058823529411764, "no_speech_prob": 0.00829943735152483}, {"id": 15, "seek": 14832, "start": 148.56, "end": 160.79999999999998, "text": " git.yachtoproject.org and that's META SPDX scanner. So initially there was just one tool", "tokens": [50376, 18331, 13, 88, 3589, 404, 340, 1020, 13, 4646, 293, 300, 311, 376, 4850, 32, 19572, 55, 30211, 13, 407, 9105, 456, 390, 445, 472, 2290, 50988], "temperature": 0.0, "avg_logprob": -0.37908297318678635, "compression_ratio": 1.3237410071942446, "no_speech_prob": 0.013595026917755604}, {"id": 16, "seek": 14832, "start": 160.79999999999998, "end": 173.92, "text": " supported in there and that was upload to phosology. So they were looking into a combination of", "tokens": [50988, 8104, 294, 456, 293, 300, 390, 6580, 281, 903, 329, 1793, 13, 407, 436, 645, 1237, 666, 257, 6562, 295, 51644], "temperature": 0.0, "avg_logprob": -0.37908297318678635, "compression_ratio": 1.3237410071942446, "no_speech_prob": 0.013595026917755604}, {"id": 17, "seek": 17392, "start": 174.88, "end": 185.11999999999998, "text": " phosology and SW360. That's what they were evaluating and that basically gives you", "tokens": [50412, 903, 329, 1793, 293, 20346, 34099, 13, 663, 311, 437, 436, 645, 27479, 293, 300, 1936, 2709, 291, 50924], "temperature": 0.0, "avg_logprob": -0.18868773034278383, "compression_ratio": 1.3203125, "no_speech_prob": 0.004603283479809761}, {"id": 18, "seek": 17392, "start": 185.11999999999998, "end": 195.04, "text": " Yocto build, upload to phosology. Phosology will do the scanning and then later on you", "tokens": [50924, 7616, 349, 78, 1322, 11, 6580, 281, 903, 329, 1793, 13, 2623, 329, 1793, 486, 360, 264, 27019, 293, 550, 1780, 322, 291, 51420], "temperature": 0.0, "avg_logprob": -0.18868773034278383, "compression_ratio": 1.3203125, "no_speech_prob": 0.004603283479809761}, {"id": 19, "seek": 19504, "start": 195.04, "end": 209.35999999999999, "text": " move the data into SW360. That was their plan. In principle, that's a post-mortem,", "tokens": [50364, 1286, 264, 1412, 666, 20346, 34099, 13, 663, 390, 641, 1393, 13, 682, 8665, 11, 300, 311, 257, 2183, 12, 76, 477, 443, 11, 51080], "temperature": 0.0, "avg_logprob": -0.1607682656268684, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.011496540158987045}, {"id": 20, "seek": 19504, "start": 209.35999999999999, "end": 219.04, "text": " that's a post-build approach. You take the sources that were exported from the build,", "tokens": [51080, 300, 311, 257, 2183, 12, 11516, 3109, 13, 509, 747, 264, 7139, 300, 645, 42055, 490, 264, 1322, 11, 51564], "temperature": 0.0, "avg_logprob": -0.1607682656268684, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.011496540158987045}, {"id": 21, "seek": 21904, "start": 219.04, "end": 231.35999999999999, "text": " the patched sources and then do analysis on it. All of that predates the now available", "tokens": [50364, 264, 9972, 292, 7139, 293, 550, 360, 5215, 322, 309, 13, 1057, 295, 300, 3852, 1024, 264, 586, 2435, 50980], "temperature": 0.0, "avg_logprob": -0.1848282051086426, "compression_ratio": 1.2941176470588236, "no_speech_prob": 0.002146063605323434}, {"id": 22, "seek": 21904, "start": 231.35999999999999, "end": 247.0, "text": " Create SPDX in Yocto. So that was before that time. To make that work, you need to set up", "tokens": [50980, 20248, 19572, 55, 294, 7616, 349, 78, 13, 407, 300, 390, 949, 300, 565, 13, 1407, 652, 300, 589, 11, 291, 643, 281, 992, 493, 51762], "temperature": 0.0, "avg_logprob": -0.1848282051086426, "compression_ratio": 1.2941176470588236, "no_speech_prob": 0.002146063605323434}, {"id": 23, "seek": 24700, "start": 247.0, "end": 255.24, "text": " a phosology server. You need to upload the sources. It will then run, I think, five different", "tokens": [50364, 257, 903, 329, 1793, 7154, 13, 509, 643, 281, 6580, 264, 7139, 13, 467, 486, 550, 1190, 11, 286, 519, 11, 1732, 819, 50776], "temperature": 0.0, "avg_logprob": -0.16103461294463187, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.011677367612719536}, {"id": 24, "seek": 24700, "start": 255.24, "end": 265.44, "text": " scanners on it and then essentially you get the results for manual review and correction", "tokens": [50776, 795, 25792, 322, 309, 293, 550, 4476, 291, 483, 264, 3542, 337, 9688, 3131, 293, 19984, 51286], "temperature": 0.0, "avg_logprob": -0.16103461294463187, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.011677367612719536}, {"id": 25, "seek": 24700, "start": 265.44, "end": 273.08, "text": " and whatnot. So you really need to sit down, inspect the result, make decisions on where", "tokens": [51286, 293, 25882, 13, 407, 291, 534, 643, 281, 1394, 760, 11, 15018, 264, 1874, 11, 652, 5327, 322, 689, 51668], "temperature": 0.0, "avg_logprob": -0.16103461294463187, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.011677367612719536}, {"id": 26, "seek": 27308, "start": 273.08, "end": 286.32, "text": " the scanners are unsure and make a final verdict and then you can output the data, put it into", "tokens": [50364, 264, 795, 25792, 366, 32486, 293, 652, 257, 2572, 33957, 293, 550, 291, 393, 5598, 264, 1412, 11, 829, 309, 666, 51026], "temperature": 0.0, "avg_logprob": -0.1739992987025868, "compression_ratio": 1.453125, "no_speech_prob": 0.000534923339728266}, {"id": 27, "seek": 27308, "start": 286.32, "end": 302.24, "text": " other tooling. Meanwhile, there are at least three different tools supported in that layer.", "tokens": [51026, 661, 46593, 13, 13879, 11, 456, 366, 412, 1935, 1045, 819, 3873, 8104, 294, 300, 4583, 13, 51822], "temperature": 0.0, "avg_logprob": -0.1739992987025868, "compression_ratio": 1.453125, "no_speech_prob": 0.000534923339728266}, {"id": 28, "seek": 30224, "start": 302.24, "end": 310.40000000000003, "text": " One is for Solotree, the other is CanCode and the third is an uploader for commercial", "tokens": [50364, 1485, 307, 337, 7026, 310, 701, 11, 264, 661, 307, 1664, 34, 1429, 293, 264, 2636, 307, 364, 6580, 260, 337, 6841, 50772], "temperature": 0.0, "avg_logprob": -0.34639124967614, "compression_ratio": 1.3088235294117647, "no_speech_prob": 0.09775962680578232}, {"id": 29, "seek": 30224, "start": 310.40000000000003, "end": 328.92, "text": " tool. After that, later Joshua Hulthog right after me added support for exporting SPDX files", "tokens": [50772, 2290, 13, 2381, 300, 11, 1780, 24005, 389, 425, 392, 664, 558, 934, 385, 3869, 1406, 337, 44686, 19572, 55, 7098, 51698], "temperature": 0.0, "avg_logprob": -0.34639124967614, "compression_ratio": 1.3088235294117647, "no_speech_prob": 0.09775962680578232}, {"id": 30, "seek": 32892, "start": 328.92, "end": 336.24, "text": " right during the build from Yocto. So the difference is that this happens right at the", "tokens": [50364, 558, 1830, 264, 1322, 490, 7616, 349, 78, 13, 407, 264, 2649, 307, 300, 341, 2314, 558, 412, 264, 50730], "temperature": 0.0, "avg_logprob": -0.15035457611083985, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.19112811982631683}, {"id": 31, "seek": 32892, "start": 336.24, "end": 345.96000000000004, "text": " build stage with all the data, metadata we know there and it does not require an external", "tokens": [50730, 1322, 3233, 365, 439, 264, 1412, 11, 26603, 321, 458, 456, 293, 309, 775, 406, 3651, 364, 8320, 51216], "temperature": 0.0, "avg_logprob": -0.15035457611083985, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.19112811982631683}, {"id": 32, "seek": 32892, "start": 345.96000000000004, "end": 357.20000000000005, "text": " server. It uses the available metadata we have. So it's faster for us. It runs during", "tokens": [51216, 7154, 13, 467, 4960, 264, 2435, 26603, 321, 362, 13, 407, 309, 311, 4663, 337, 505, 13, 467, 6676, 1830, 51778], "temperature": 0.0, "avg_logprob": -0.15035457611083985, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.19112811982631683}, {"id": 33, "seek": 35720, "start": 357.2, "end": 367.12, "text": " the build and basically it's close to no additional resources consumed. We now have", "tokens": [50364, 264, 1322, 293, 1936, 309, 311, 1998, 281, 572, 4497, 3593, 21226, 13, 492, 586, 362, 50860], "temperature": 0.0, "avg_logprob": -0.16731088502066477, "compression_ratio": 1.2878787878787878, "no_speech_prob": 0.016894962638616562}, {"id": 34, "seek": 35720, "start": 367.12, "end": 375.91999999999996, "text": " that enabled. So for our releases and the stuff, you'll find the SPDX files right next", "tokens": [50860, 300, 15172, 13, 407, 337, 527, 16952, 293, 264, 1507, 11, 291, 603, 915, 264, 19572, 55, 7098, 558, 958, 51300], "temperature": 0.0, "avg_logprob": -0.16731088502066477, "compression_ratio": 1.2878787878787878, "no_speech_prob": 0.016894962638616562}, {"id": 35, "seek": 37592, "start": 375.92, "end": 390.0, "text": " to the artifacts. Okay, great. What did we learn essentially? It depends now from an", "tokens": [50364, 281, 264, 24617, 13, 1033, 11, 869, 13, 708, 630, 321, 1466, 4476, 30, 467, 5946, 586, 490, 364, 51068], "temperature": 0.0, "avg_logprob": -0.17440692238185718, "compression_ratio": 1.2835820895522387, "no_speech_prob": 0.12745924293994904}, {"id": 36, "seek": 37592, "start": 390.0, "end": 399.16, "text": " open source project versus in-house product and so on. For us, the Solotree approach or", "tokens": [51068, 1269, 4009, 1716, 5717, 294, 12, 6410, 1674, 293, 370, 322, 13, 1171, 505, 11, 264, 7026, 310, 701, 3109, 420, 51526], "temperature": 0.0, "avg_logprob": -0.17440692238185718, "compression_ratio": 1.2835820895522387, "no_speech_prob": 0.12745924293994904}, {"id": 37, "seek": 39916, "start": 399.16, "end": 406.76000000000005, "text": " the approach with the scanner, I don't want to pick on one here, it required way more", "tokens": [50364, 264, 3109, 365, 264, 30211, 11, 286, 500, 380, 528, 281, 1888, 322, 472, 510, 11, 309, 4739, 636, 544, 50744], "temperature": 0.0, "avg_logprob": -0.21175731312144885, "compression_ratio": 1.303030303030303, "no_speech_prob": 0.06456781178712845}, {"id": 38, "seek": 39916, "start": 406.76000000000005, "end": 420.40000000000003, "text": " CPU resources. You need to shuffle all the source tower balls up and down. It requires", "tokens": [50744, 13199, 3593, 13, 509, 643, 281, 39426, 439, 264, 4009, 10567, 9803, 493, 293, 760, 13, 467, 7029, 51426], "temperature": 0.0, "avg_logprob": -0.21175731312144885, "compression_ratio": 1.303030303030303, "no_speech_prob": 0.06456781178712845}, {"id": 39, "seek": 42040, "start": 420.4, "end": 429.08, "text": " manual review and that was for kind of for the open source project side. That was just", "tokens": [50364, 9688, 3131, 293, 300, 390, 337, 733, 295, 337, 264, 1269, 4009, 1716, 1252, 13, 663, 390, 445, 50798], "temperature": 0.0, "avg_logprob": -0.19543031204578487, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.23616914451122284}, {"id": 40, "seek": 42040, "start": 429.08, "end": 444.23999999999995, "text": " too much, right? And actually we lost information once we went from the build to the external", "tokens": [50798, 886, 709, 11, 558, 30, 400, 767, 321, 2731, 1589, 1564, 321, 1437, 490, 264, 1322, 281, 264, 8320, 51556], "temperature": 0.0, "avg_logprob": -0.19543031204578487, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.23616914451122284}, {"id": 41, "seek": 44424, "start": 444.24, "end": 455.36, "text": " scanner. Basically, what does this belong to? Which build is this? Yes, you can partially", "tokens": [50364, 30211, 13, 8537, 11, 437, 775, 341, 5784, 281, 30, 3013, 1322, 307, 341, 30, 1079, 11, 291, 393, 18886, 50920], "temperature": 0.0, "avg_logprob": -0.17522068023681642, "compression_ratio": 1.2941176470588236, "no_speech_prob": 0.00757195707410574}, {"id": 42, "seek": 44424, "start": 455.36, "end": 465.52, "text": " solve that by folder naming and help out on that but you'll lose a connection here. On", "tokens": [50920, 5039, 300, 538, 10820, 25290, 293, 854, 484, 322, 300, 457, 291, 603, 3624, 257, 4984, 510, 13, 1282, 51428], "temperature": 0.0, "avg_logprob": -0.17522068023681642, "compression_ratio": 1.2941176470588236, "no_speech_prob": 0.00757195707410574}, {"id": 43, "seek": 46552, "start": 465.52, "end": 476.76, "text": " the other side, it depends on your requirements. If your legal department in the end says we", "tokens": [50364, 264, 661, 1252, 11, 309, 5946, 322, 428, 7728, 13, 759, 428, 5089, 5882, 294, 264, 917, 1619, 321, 50926], "temperature": 0.0, "avg_logprob": -0.1727037691090205, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.061856236308813095}, {"id": 44, "seek": 46552, "start": 476.76, "end": 486.47999999999996, "text": " have to scan, right? Because even if we get most of the artifacts from, let's say, supplier,", "tokens": [50926, 362, 281, 11049, 11, 558, 30, 1436, 754, 498, 321, 483, 881, 295, 264, 24617, 490, 11, 718, 311, 584, 11, 31909, 11, 51412], "temperature": 0.0, "avg_logprob": -0.1727037691090205, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.061856236308813095}, {"id": 45, "seek": 46552, "start": 486.47999999999996, "end": 495.0, "text": " we still add something, right? Or we need to know for sure, then you have to scan, period.", "tokens": [51412, 321, 920, 909, 746, 11, 558, 30, 1610, 321, 643, 281, 458, 337, 988, 11, 550, 291, 362, 281, 11049, 11, 2896, 13, 51838], "temperature": 0.0, "avg_logprob": -0.1727037691090205, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.061856236308813095}, {"id": 46, "seek": 49500, "start": 495.0, "end": 506.04, "text": " And that's what actually happens for us. Our members, essentially, they have to scan", "tokens": [50364, 400, 300, 311, 437, 767, 2314, 337, 505, 13, 2621, 2679, 11, 4476, 11, 436, 362, 281, 11049, 50916], "temperature": 0.0, "avg_logprob": -0.23258748921481046, "compression_ratio": 1.421487603305785, "no_speech_prob": 0.001956574385985732}, {"id": 47, "seek": 49500, "start": 506.04, "end": 511.88, "text": " because they add stuff on their own. So in the end, they have to scan their final stuff", "tokens": [50916, 570, 436, 909, 1507, 322, 641, 1065, 13, 407, 294, 264, 917, 11, 436, 362, 281, 11049, 641, 2572, 1507, 51208], "temperature": 0.0, "avg_logprob": -0.23258748921481046, "compression_ratio": 1.421487603305785, "no_speech_prob": 0.001956574385985732}, {"id": 48, "seek": 51188, "start": 511.88, "end": 527.12, "text": " anyway, right? So for us, we took then the route to take the faster way. We take the", "tokens": [50364, 4033, 11, 558, 30, 407, 337, 505, 11, 321, 1890, 550, 264, 7955, 281, 747, 264, 4663, 636, 13, 492, 747, 264, 51126], "temperature": 0.0, "avg_logprob": -0.19809783422029936, "compression_ratio": 1.105263157894737, "no_speech_prob": 0.04079747945070267}, {"id": 49, "seek": 52712, "start": 527.12, "end": 546.84, "text": " analysis during the build and use that. And there is one basically thing that we have to", "tokens": [50364, 5215, 1830, 264, 1322, 293, 764, 300, 13, 400, 456, 307, 472, 1936, 551, 300, 321, 362, 281, 51350], "temperature": 0.0, "avg_logprob": -0.17339734597639603, "compression_ratio": 1.1282051282051282, "no_speech_prob": 0.06554219871759415}, {"id": 50, "seek": 54684, "start": 546.84, "end": 565.0, "text": " solve at a more global level. The data we have and we provide, which we basically can", "tokens": [50364, 5039, 412, 257, 544, 4338, 1496, 13, 440, 1412, 321, 362, 293, 321, 2893, 11, 597, 321, 1936, 393, 51272], "temperature": 0.0, "avg_logprob": -0.19905148852955212, "compression_ratio": 1.3435114503816794, "no_speech_prob": 0.49131709337234497}, {"id": 51, "seek": 54684, "start": 565.0, "end": 571.2800000000001, "text": " say, okay, this is our sources that you consume. Does the legal department accept that and", "tokens": [51272, 584, 11, 1392, 11, 341, 307, 527, 7139, 300, 291, 14732, 13, 4402, 264, 5089, 5882, 3241, 300, 293, 51586], "temperature": 0.0, "avg_logprob": -0.19905148852955212, "compression_ratio": 1.3435114503816794, "no_speech_prob": 0.49131709337234497}, {"id": 52, "seek": 57128, "start": 571.28, "end": 582.64, "text": " trust it? Or will they go ahead and say, we have inspected everything again? So that's", "tokens": [50364, 3361, 309, 30, 1610, 486, 436, 352, 2286, 293, 584, 11, 321, 362, 1028, 10729, 1203, 797, 30, 407, 300, 311, 50932], "temperature": 0.0, "avg_logprob": -0.18740465203110052, "compression_ratio": 1.3129770992366412, "no_speech_prob": 0.09655935317277908}, {"id": 53, "seek": 57128, "start": 582.64, "end": 595.04, "text": " a crucial point. Yeah, so right now, we are basically at the stage, all right, we can", "tokens": [50932, 257, 11462, 935, 13, 865, 11, 370, 558, 586, 11, 321, 366, 1936, 412, 264, 3233, 11, 439, 558, 11, 321, 393, 51552], "temperature": 0.0, "avg_logprob": -0.18740465203110052, "compression_ratio": 1.3129770992366412, "no_speech_prob": 0.09655935317277908}, {"id": 54, "seek": 59504, "start": 595.12, "end": 604.76, "text": " create the SPDX files. But how can I consume it? How can I present it? Basically, the", "tokens": [50368, 1884, 264, 8420, 35, 55, 7098, 13, 583, 577, 393, 286, 14732, 309, 30, 1012, 393, 286, 1974, 309, 30, 8537, 11, 264, 50850], "temperature": 0.0, "avg_logprob": -0.23150573586517909, "compression_ratio": 1.3461538461538463, "no_speech_prob": 0.17967990040779114}, {"id": 55, "seek": 59504, "start": 604.76, "end": 613.76, "text": " S-bombs, it's relatively new in the end. So the tooling is still evolving. So the tooling", "tokens": [50850, 318, 12, 65, 298, 929, 11, 309, 311, 7226, 777, 294, 264, 917, 13, 407, 264, 46593, 307, 920, 21085, 13, 407, 264, 46593, 51300], "temperature": 0.0, "avg_logprob": -0.23150573586517909, "compression_ratio": 1.3461538461538463, "no_speech_prob": 0.17967990040779114}, {"id": 56, "seek": 61376, "start": 613.76, "end": 628.3199999999999, "text": " is new. And for us, we are looking for how can we present this in a way that makes it", "tokens": [50364, 307, 777, 13, 400, 337, 505, 11, 321, 366, 1237, 337, 577, 393, 321, 1974, 341, 294, 257, 636, 300, 1669, 309, 51092], "temperature": 0.0, "avg_logprob": -0.19242256245714554, "compression_ratio": 1.3, "no_speech_prob": 0.00733921816572547}, {"id": 57, "seek": 61376, "start": 628.3199999999999, "end": 643.68, "text": " easily consumable. Essentially, let's say for our CI purpose, we would like to know", "tokens": [51092, 3612, 3978, 712, 13, 23596, 11, 718, 311, 584, 337, 527, 37777, 4334, 11, 321, 576, 411, 281, 458, 51860], "temperature": 0.0, "avg_logprob": -0.19242256245714554, "compression_ratio": 1.3, "no_speech_prob": 0.00733921816572547}, {"id": 58, "seek": 64368, "start": 643.68, "end": 655.88, "text": " is there anything that was added that changed? So the diff is interesting. Yeah, that's an", "tokens": [50364, 307, 456, 1340, 300, 390, 3869, 300, 3105, 30, 407, 264, 7593, 307, 1880, 13, 865, 11, 300, 311, 364, 50974], "temperature": 0.0, "avg_logprob": -0.32778917776571737, "compression_ratio": 1.238938053097345, "no_speech_prob": 0.003632250474765897}, {"id": 59, "seek": 64368, "start": 655.88, "end": 662.4, "text": " essential next step for us. All right, questions?", "tokens": [50974, 7115, 958, 1823, 337, 505, 13, 1057, 558, 11, 1651, 30, 51300], "temperature": 0.0, "avg_logprob": -0.32778917776571737, "compression_ratio": 1.238938053097345, "no_speech_prob": 0.003632250474765897}, {"id": 60, "seek": 66240, "start": 662.4, "end": 687.04, "text": " So, Josh will detail that. Yes, so what information goes into the SPDX files here? Yeah, what", "tokens": [50364, 407, 11, 9785, 486, 2607, 300, 13, 1079, 11, 370, 437, 1589, 1709, 666, 264, 8420, 35, 55, 7098, 510, 30, 865, 11, 437, 51596], "temperature": 0.0, "avg_logprob": -0.3231348991394043, "compression_ratio": 1.0568181818181819, "no_speech_prob": 0.03148921951651573}, {"id": 61, "seek": 68704, "start": 688.0, "end": 694.88, "text": " that will come in the next talk. Yeah, so I don't want to steal Josh, the funder from Josh. He has it", "tokens": [50412, 300, 486, 808, 294, 264, 958, 751, 13, 865, 11, 370, 286, 500, 380, 528, 281, 11009, 9785, 11, 264, 2374, 260, 490, 9785, 13, 634, 575, 309, 50756], "temperature": 0.0, "avg_logprob": -0.249909695063796, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.5537821054458618}, {"id": 62, "seek": 68704, "start": 694.88, "end": 702.4, "text": " in his slides, I know. So I think your slide probably answers this. You're producing S-bombs,", "tokens": [50756, 294, 702, 9788, 11, 286, 458, 13, 407, 286, 519, 428, 4137, 1391, 6338, 341, 13, 509, 434, 10501, 318, 12, 65, 298, 929, 11, 51132], "temperature": 0.0, "avg_logprob": -0.249909695063796, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.5537821054458618}, {"id": 63, "seek": 68704, "start": 703.36, "end": 707.68, "text": " but you're not doing anything with them. So it's just basically, have I created a file?", "tokens": [51180, 457, 291, 434, 406, 884, 1340, 365, 552, 13, 407, 309, 311, 445, 1936, 11, 362, 286, 2942, 257, 3991, 30, 51396], "temperature": 0.0, "avg_logprob": -0.249909695063796, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.5537821054458618}, {"id": 64, "seek": 68704, "start": 707.68, "end": 714.24, "text": " Yes. Yeah, right now, we are at the stage, okay, check, S-bombs created.", "tokens": [51396, 1079, 13, 865, 11, 558, 586, 11, 321, 366, 412, 264, 3233, 11, 1392, 11, 1520, 11, 318, 12, 65, 298, 929, 2942, 13, 51724], "temperature": 0.0, "avg_logprob": -0.249909695063796, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.5537821054458618}, {"id": 65, "seek": 71704, "start": 717.04, "end": 721.92, "text": " Actually, I failed now a decision to say the build's not long. I've got to go back and change the", "tokens": [50364, 5135, 11, 286, 7612, 586, 257, 3537, 281, 584, 264, 1322, 311, 406, 938, 13, 286, 600, 658, 281, 352, 646, 293, 1319, 264, 50608], "temperature": 0.0, "avg_logprob": -0.34038341336134004, "compression_ratio": 1.564516129032258, "no_speech_prob": 0.06944804638624191}, {"id": 66, "seek": 71704, "start": 721.92, "end": 732.0799999999999, "text": " build. Yeah, no, no, okay, no, no. So what are you doing differently to what you were doing before", "tokens": [50608, 1322, 13, 865, 11, 572, 11, 572, 11, 1392, 11, 572, 11, 572, 13, 407, 437, 366, 291, 884, 7614, 281, 437, 291, 645, 884, 949, 51116], "temperature": 0.0, "avg_logprob": -0.34038341336134004, "compression_ratio": 1.564516129032258, "no_speech_prob": 0.06944804638624191}, {"id": 67, "seek": 71704, "start": 733.04, "end": 742.0, "text": " three years ago? We just do generating release notes. Yeah, yeah, so you're not so okay. Yeah,", "tokens": [51164, 1045, 924, 2057, 30, 492, 445, 360, 17746, 4374, 5570, 13, 865, 11, 1338, 11, 370, 291, 434, 406, 370, 1392, 13, 865, 11, 51612], "temperature": 0.0, "avg_logprob": -0.34038341336134004, "compression_ratio": 1.564516129032258, "no_speech_prob": 0.06944804638624191}, {"id": 68, "seek": 74200, "start": 742.72, "end": 751.28, "text": " yeah. So, I mean, we are using the report tool. So we can basically ease and the", "tokens": [50400, 1338, 13, 407, 11, 286, 914, 11, 321, 366, 1228, 264, 2275, 2290, 13, 407, 321, 393, 1936, 12708, 293, 264, 50828], "temperature": 0.0, "avg_logprob": -0.28072170182770373, "compression_ratio": 1.5128205128205128, "no_speech_prob": 0.002321277977898717}, {"id": 69, "seek": 74200, "start": 751.28, "end": 757.84, "text": " diopto recipes. So we can easily say that's the diff in the recipes. So we changed this and this", "tokens": [50828, 1026, 404, 1353, 13035, 13, 407, 321, 393, 3612, 584, 300, 311, 264, 7593, 294, 264, 13035, 13, 407, 321, 3105, 341, 293, 341, 51156], "temperature": 0.0, "avg_logprob": -0.28072170182770373, "compression_ratio": 1.5128205128205128, "no_speech_prob": 0.002321277977898717}, {"id": 70, "seek": 75784, "start": 757.84, "end": 763.84, "text": " and this and that. But back then, no. Yeah.", "tokens": [50364, 293, 341, 293, 300, 13, 583, 646, 550, 11, 572, 13, 865, 13, 50664], "temperature": 0.0, "avg_logprob": -0.34683202107747396, "compression_ratio": 1.2377049180327868, "no_speech_prob": 0.10263378173112869}, {"id": 71, "seek": 75784, "start": 771.12, "end": 771.9200000000001, "text": " No, not yet.", "tokens": [51028, 883, 11, 406, 1939, 13, 51068], "temperature": 0.0, "avg_logprob": -0.34683202107747396, "compression_ratio": 1.2377049180327868, "no_speech_prob": 0.10263378173112869}, {"id": 72, "seek": 75784, "start": 775.36, "end": 781.6800000000001, "text": " So there's two questions. How much of this code was used from the double open original project", "tokens": [51240, 407, 456, 311, 732, 1651, 13, 1012, 709, 295, 341, 3089, 390, 1143, 490, 264, 3834, 1269, 3380, 1716, 51556], "temperature": 0.0, "avg_logprob": -0.34683202107747396, "compression_ratio": 1.2377049180327868, "no_speech_prob": 0.10263378173112869}, {"id": 73, "seek": 78168, "start": 781.76, "end": 788.0, "text": " that was in the app too? This is the one that created the whole spdx generation on the app too.", "tokens": [50368, 300, 390, 294, 264, 724, 886, 30, 639, 307, 264, 472, 300, 2942, 264, 1379, 637, 67, 87, 5125, 322, 264, 724, 886, 13, 50680], "temperature": 0.0, "avg_logprob": -0.34123114744822186, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00924274418503046}, {"id": 74, "seek": 78168, "start": 788.64, "end": 794.56, "text": " This is, I think this is the original code. Do you know? That's the question for Josh. Next talk.", "tokens": [50712, 639, 307, 11, 286, 519, 341, 307, 264, 3380, 3089, 13, 1144, 291, 458, 30, 663, 311, 264, 1168, 337, 9785, 13, 3087, 751, 13, 51008], "temperature": 0.0, "avg_logprob": -0.34123114744822186, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00924274418503046}, {"id": 75, "seek": 78168, "start": 797.1999999999999, "end": 801.76, "text": " Why do you need the presentation visualization tool? Why are you reinventing the use if you already", "tokens": [51140, 1545, 360, 291, 643, 264, 5860, 25801, 2290, 30, 1545, 366, 291, 33477, 278, 264, 764, 498, 291, 1217, 51368], "temperature": 0.0, "avg_logprob": -0.34123114744822186, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00924274418503046}, {"id": 76, "seek": 78168, "start": 801.76, "end": 810.88, "text": " have a couple of tools already doing that? For presentation and presentation. Why are you working", "tokens": [51368, 362, 257, 1916, 295, 3873, 1217, 884, 300, 30, 1171, 5860, 293, 5860, 13, 1545, 366, 291, 1364, 51824], "temperature": 0.0, "avg_logprob": -0.34123114744822186, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00924274418503046}, {"id": 77, "seek": 81088, "start": 810.96, "end": 819.6, "text": " now? It would be the next step for us. So I'm not saying we develop this. Basically, we are looking", "tokens": [50368, 586, 30, 467, 576, 312, 264, 958, 1823, 337, 505, 13, 407, 286, 478, 406, 1566, 321, 1499, 341, 13, 8537, 11, 321, 366, 1237, 50800], "temperature": 0.0, "avg_logprob": -0.16316281424628365, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0019224854186177254}, {"id": 78, "seek": 81088, "start": 819.6, "end": 830.32, "text": " now, start using what exists. I'm not saying we are reinventing the wheel. I'm going step by", "tokens": [50800, 586, 11, 722, 1228, 437, 8198, 13, 286, 478, 406, 1566, 321, 366, 33477, 278, 264, 5589, 13, 286, 478, 516, 1823, 538, 51336], "temperature": 0.0, "avg_logprob": -0.16316281424628365, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0019224854186177254}, {"id": 79, "seek": 83032, "start": 830.32, "end": 837.84, "text": " step. So I'm an, I'm an adopter. Yeah. So that's why I'll sit in and listen.", "tokens": [50364, 1823, 13, 407, 286, 478, 364, 11, 286, 478, 364, 22486, 391, 13, 865, 13, 407, 300, 311, 983, 286, 603, 1394, 294, 293, 2140, 13, 50740], "temperature": 0.0, "avg_logprob": -0.2842101770288804, "compression_ratio": 1.4390243902439024, "no_speech_prob": 0.05922279879450798}, {"id": 80, "seek": 83032, "start": 842.48, "end": 847.36, "text": " As to the problem you mentioned before about the choice between", "tokens": [50972, 1018, 281, 264, 1154, 291, 2835, 949, 466, 264, 3922, 1296, 51216], "temperature": 0.0, "avg_logprob": -0.2842101770288804, "compression_ratio": 1.4390243902439024, "no_speech_prob": 0.05922279879450798}, {"id": 81, "seek": 83032, "start": 848.08, "end": 857.6800000000001, "text": " using phosology review, we face the same problem in our project. And the way we solved it is to", "tokens": [51252, 1228, 903, 329, 1793, 3131, 11, 321, 1851, 264, 912, 1154, 294, 527, 1716, 13, 400, 264, 636, 321, 13041, 309, 307, 281, 51732], "temperature": 0.0, "avg_logprob": -0.2842101770288804, "compression_ratio": 1.4390243902439024, "no_speech_prob": 0.05922279879450798}, {"id": 82, "seek": 85768, "start": 857.76, "end": 865.5999999999999, "text": " decouple the two processes. So you provide input for phosology with one more pipeline. Yeah. And then", "tokens": [50368, 979, 263, 781, 264, 732, 7555, 13, 407, 291, 2893, 4846, 337, 903, 329, 1793, 365, 472, 544, 15517, 13, 865, 13, 400, 550, 50760], "temperature": 0.0, "avg_logprob": -0.2685945931967203, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.02946009300649166}, {"id": 83, "seek": 85768, "start": 866.3199999999999, "end": 873.68, "text": " leave it, the only thing work. And then when the data is ready, you can import them in subsequently.", "tokens": [50796, 1856, 309, 11, 264, 787, 551, 589, 13, 400, 550, 562, 264, 1412, 307, 1919, 11, 291, 393, 974, 552, 294, 26514, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2685945931967203, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.02946009300649166}, {"id": 84, "seek": 85768, "start": 873.68, "end": 880.9599999999999, "text": " Yeah. So the only way, because in this way you can provide input to the audit team so they can", "tokens": [51164, 865, 13, 407, 264, 787, 636, 11, 570, 294, 341, 636, 291, 393, 2893, 4846, 281, 264, 17748, 1469, 370, 436, 393, 51528], "temperature": 0.0, "avg_logprob": -0.2685945931967203, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.02946009300649166}, {"id": 85, "seek": 88096, "start": 880.96, "end": 887.2800000000001, "text": " work timely before the release. Yes. And then you basically feed that back into, I mean, if you", "tokens": [50364, 589, 25150, 949, 264, 4374, 13, 1079, 13, 400, 550, 291, 1936, 3154, 300, 646, 666, 11, 286, 914, 11, 498, 291, 50680], "temperature": 0.0, "avg_logprob": -0.2677394549051921, "compression_ratio": 1.39568345323741, "no_speech_prob": 0.014420515857636929}, {"id": 86, "seek": 88096, "start": 887.2800000000001, "end": 894.5600000000001, "text": " have a release build, right? For release builds, we have, we can. No, but we do that also from the", "tokens": [50680, 362, 257, 4374, 1322, 11, 558, 30, 1171, 4374, 15182, 11, 321, 362, 11, 321, 393, 13, 883, 11, 457, 321, 360, 300, 611, 490, 264, 51044], "temperature": 0.0, "avg_logprob": -0.2677394549051921, "compression_ratio": 1.39568345323741, "no_speech_prob": 0.014420515857636929}, {"id": 87, "seek": 89456, "start": 894.56, "end": 900.16, "text": " time. Okay. Okay. Thank you very much. Thank you.", "tokens": [50404, 565, 13, 1033, 13, 1033, 13, 1044, 291, 588, 709, 13, 1044, 291, 13, 50644], "temperature": 0.0, "avg_logprob": -0.5777709624346565, "compression_ratio": 1.1951219512195121, "no_speech_prob": 0.09562955796718597}], "language": "en"}