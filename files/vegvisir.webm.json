{"text": " Alright, so good morning everybody, my name is Joris and I'm a PhD student over at Hasselt University here in Belgium and I'm doing a PhD on multimedia streaming and network transport layer protocols or even better the intersection of those two. Today I'm here to talk a little bit about a project we did called Vagvizir which is an automated testing framework for orchestrating client and server setups using the quick transport layer protocols but before we jump into that maybe let's talk a little bit about what quick actually is because I assume not everybody has heard about it. Well quick is a general purpose transport layer protocol that was standardized by the ITF in May 2021 and if you have any updated like applications on your phone or have been using the latest releases of browsers such as Firefox, Chrome or whatever you're using you've probably been already using quick as it has been deployed to a lot of many different applications and websites already. For example Facebook, Instagram they are using it, if you're streaming videos over YouTube you have probably been already using quick. Quick is a name, it's not an acronym, it used to stand for quick UDP internet connections but it has actually not been called that for quite some time already now. Some of its features, the biggest feature is encryption so the protocol actually encrypts everything by default which is great because that's the main driver against ossification also it's reason that it was created because TCP is actually an ossified protocol when we compare the two. It's also great for preventing third parties from actually interfering with the data you are transmitting over the network. It's less great for research and development as you have to actually account for that in your test setups which we are going to talk about a little bit further ahead. It's currently most implementations implemented on top of UDP in user space. Some implementations are actually looking at implementing it more towards the kernel but those steps have not been taken by many of the implementations. At present at least as far as I know 25 implementations exist most of them also being open source written in multiple programming languages. They also provide libraries which you can directly use to actually use quick in your applications. Another benefit of quick or another new thing with quick is HTTP 3 which you might have heard of. The reason for the introduction of H3 is that H1 and H2 actually only run over TCP that's why they created a new version of HTTP called HTTP 3. There's not that big of a difference between H2 and H3 in practice but just for sake of naming it it's HTTP 3. Right so now that you know what quick is that's at least a requirement for understanding the stock. Let's talk about how we can actually use this in like experiments and stuff. Maybe let's try doing something very simple. I just told you that most browsers implement quick. Maybe let's try connecting to a website that only implements an HTTP 3 server. Should be simple right but as you can see on the screenshot it is not in practice. And the reason for that is really simple that's because browsers decided early on that HTTP 3 server should be discoverable through the old SVC header provided by an H1 or H2 deployment which really sucks if you want to do some automated testing because that means you also have to put up like or spin up an H1 or H2 server and actually account for this. Luckily we have some options like for example within Chrome and Firefox to enable force quick on certain domains which we can automate through or by means of for example parameters supplied in the command line or by configurations in the browser itself. Right so we can connect to a web server at this point. How do we actually know what's happening under the hood should also be simple right. Remember everything is encrypted so actually seeing what's happening is a little bit is not that trivial actually. Luckily most implementations nowadays use like standard of the shelf TLS libraries and these TLS back ends actually support an environment variable called SSL key lock file and the idea behind the SSL key lock file is that you can like point it towards a file which then gets used by these TLS back ends to like output all the secrets used for encryption during a whatever the application is actually doing. If you load those SSL key lock files into programs like wire shark you can actually decrypt the traffic which is nice if you want to see what happened. Unfortunately tools like wire shark at least as far as I know don't actually have any visualizations about stuff that's happening at like the congestion or flow control layer. You have that for TCP but quick those things don't exist yet. But luckily we have other stuff for that. Q lock is one of them. There has been a nice talk about this by its inventor a couple of years ago at FOSDOM. I really invite you to look at it. But basically in a nutshell what Q lock is is like a structured way of logging and a unified way of logging that can be implemented by any endpoint implementation using quick. In a nutshell this is basically a file for example a JSON file that just locks everything that's happening and if you have some scripts or tools that can parse this you can actually do a lot of fun stuff with it. For example the QVIS visualization tool which is also by the same creator is a tool that allows you to load these files and like actually visualize similar to what wire shark can do for TCP but then for quick what's happening on the congestion layers. For example on the left you see a flow control and congestion flow graph and on the right you see a plot of the home trip time that was experienced by the application. So we can look at what's happening under the hood maybe let's try something more advanced setting up like your own quick client and quick server to do some local experiments maybe change something to the implementations it doesn't matter really what you want to do. Even that is not that trivial simply because there are many implementations written in many languages meaning that they have their own requirements their own installation procedures. Another distinction is that different implementations actually have different performance characteristics meaning that some are more tuned towards certain scenarios some only support a certain feature set so you also have to account for that. An additional requirement is that you also have to set up like self-signed certificates and for some reason some implementations accept all kinds of certificates and then for some reason others fail we have never really figured out why we just use a common way that works for them all now anyway. Another query that you can experience is within the code bases themselves a fun one I always show to my students is this one this is from the quick code base which uses the cubic congestion control algorithm if you know something about congestion control and makes sense like the file is called new cubic sander the function is called new cubic new cubic sander it even specifies in documentation that it makes a new cubic sander unless you actually put a Renault ball on true then it behaves like a totally different beast actually new Renault in that case so some some weird quirks that you actually have to account for too. So the point I'm trying to make it is is that there are a lot of different implementations testing the mall takes time it's not that easy to set it up you experience a lot of these small issues it's cumbersome to like test multiple implementations which is the reason why I am presenting Vagvizir today. The idea behind Vagvizir is to actually aid with this kind of development so if you're doing research or even development within quick the idea is that Vagvizir can automatically set up these kinds of interactions between clients and servers but also using simulated networks such that you can have actual repeatable and shareable experiments. The way you do it this is by defining experiments with configuration files and a single experiment can consist out of multiple test cases and the idea is that a single test case looks something like this. So you have the two entities the server and the client which just assume their prototypical roles as known within the server client model and in between them sits a network component that we call the shaper and the idea of the shaper is that it actually applies some kind of scenario on the traffic passing between the server and client for example it can introduce some latency or it could limit the throughput doesn't really matter what you want to do the idea is that you can do it in a repeatable way. You also see the docker container stuff on top the idea of using or actually deploying these test cases within docker containers is that we can easily share them with other people which is a really nice benefit within the academic community but also we can free certain implementations like we can actually save a docker container and reuse it at a later point so say for example something changes and we want to try an older version that's totally possible with this setup. Additionally within the quick community there have been some other efforts if you are part of the quick community you might actually recognize this setup it's pretty much the same as one used by an interoperability project called the quick interoperability runner. They also provide containers for their setup that are more tuned towards testing the actual interoperability between quick implementations but the benefit of using the same architecture is that we are actually completely compatible with their setups so that means that even though Vegvizir is relatively new at this point in time we are already compatible with 15 out of the 25 quick implementations right out of the box. You also see on the right side that we have a client that can be defined as a CLI command that's because early on we realized that if we want to test applications not everything is not every kind of test is suitable to be placed in a docker container which is why we also allow to define test by just spinning up local programs as you are used to from a terminal. A good example of this is a browser if you're doing some kind of media streaming experiments you actually want hardware acceleration as such to be enabled which I guess you can do this in docker containers but it's really cumbersome to actually do this in a good way. Right okay so how are these experiments actually defined? Well we decided to not use one single configuration file simply because that would mean we had to be very verbose. We actually split it up in two types of configurations. On the left you can see the implementation configuration which is actually what defines what is available within an experiment. So the idea is that an implementation configuration is similar to like your list of installed software on your computer. You simply have a list of entities that you can pick from. We also introduced a parametric system to make it actually really dynamic steerable from within an experiment configuration and we will see some examples on that in a second. On the right you see the experiment configuration that's the actual definition of what needs to happen within one experiment so what defines the test cases. The idea is that you define how the entities from the implementation configuration should behave and what parameters should actually contain as values through arguments. Also configure sensors I'm going to talk about that in a second but the biggest benefit of splitting these two up is actually that the experiment configuration automatically produces this permutation or rather a total of combinations from all these entities. So say for example you define two servers, two clients and two shapers. The total amount of tests within this experiment will actually be eight because it just compiles a complete combination of all these configurations. Another benefit is loose coupling so you might wonder yeah I still don't see the reason why you split these two up. Well a big thing with an academic research is that we actually want to test different versions. So if we have an implementation configuration that for example defines a client called Chrome which then refers to a Chrome browser we can actually have one implementation configuration that refers to version for example 99 and we can have another implementation configuration that refers to for example version 100. The benefit of that is that if we simply swap these implementation configurations we don't need to change the experiment configurations meaning that we can without having to verbose rewrite all these stats really easily test multiple setups. Some examples this is an example of an implementation configuration. I do invite you to go to the GitHub repository where everything is really nicely explained and we provide some more examples unfortunately limited by the screen size. You see that we always have to define in the implementation configuration three types of entities like we talked about earlier the clients the servers and the shapers and these three are examples using Docker system. So in the top two you see that we actually refer to Docker Hub images. These are actual examples that come from the quick interop runner project which we are compatible with. The bottom one is a locally built Docker image. The reason I highlight this difference is because the framework automatically pulls the latest Docker Hub images if these are available. But if you are using some kind of local implementation that you build as a Docker image you actually have to build it locally and then refer to it locally. Another thing you can see here is the parametric system. So for example the top client defines a request parameter that is then used within an experiment. The idea is that an experiment configuration then contains a value of it and that you can access this value within a Docker image simply by using requests then in this case as a environment variable. So all the parameters are passed as environment variables if you are using Docker images. Or in the case that you are using CLI commands or even in a more specific case of shapers because shapers are a little bit more complicated. You can also use them directly in the commands you specify within the implementation and experiment configurations. These are directly substituted and you can actually reference other parameters within arguments which is nice. A simple example of a CLI client, so one that is not using a Docker image in other words, you can see that the command is rather long. That is because we cannot, well compared to a Docker container we actually have to specify everything that needs to happen in CLI command. This example provides three or rather four system parameters which are highlighted here. The reason I did this is because the framework automatically generates all these details for you such that the experiments can be even more dynamically steered. This is especially handy for future use cases where we for example want to expand upon multiple client setups and stuff like that. On the bottom you see a construct key. We actually have two special mechanisms for CLI commands. In Docker images, the benefit of Docker images is that they can actually have scripts on board that actually prime the environment. That is the downside of using CLI commands unless you want to put everything on one single line which is rather also cumbersome. Instead we provide two mechanisms called construct and destruct which are run before and after a command is executed. These can be used to prime an environment and clean it up afterwards. This example sets like the changes or manipulates actually the Google Chrome preferences to set like the standard download folder output towards one generated by the framework. Then we come to the experiment configurations examples. These are the actual configurations that define how a test should behave. You see here once again we have client shapers and servers which we picked from the implementation that we just showed. We simply filled them in with the arguments required for the test to work. A special thing to notice here is the shapers scenarios. Clients and servers are really simple. You just mentioned which one you want to use. But for shapers we have a more complicated setup. The idea behind the shapers is that it actually entails one kind of shaping. For example, you can use a TC-netum shaper within one container. But this one container does not only do one kind of shaping. The idea is that you can define multiple scenarios within this container and by passing through the scenario key you can actually pick which one is used during a test. In this use case we have one client, two shapers and three servers which means that we will have a total of six test cases that will get generated and compiled by the framework and run sequentially one after the other. I mentioned sensors earlier. That is also a configuration you can do with the experiment configuration files. The idea is normally that the framework just automates all these tests and that when a client exits this should signal like the end of the test. However, in certain circumstances it is not possible. For example, if you use a browser, well, it is obvious that browsers do not have the ability to shut down from within a web page which would pose some security risks. Which is why we built a sensor system which can actually govern what happens within a client. For example, we provide two simple sensor setups, time mode, which simply checks if a certain amount of time has passed and then closes the client and signals that the test case has ended. Another one that we built is the browser file watchdog sensor which enables us to check if certain files were downloaded by a browser context. This enables us to pull metrics from the browser and also signify the end of a test. If you provide these two configuration files to the framework, the framework will spin up a nice story. On the bottom you can see which tests are happening, how much time has passed. You can see a little bit of packet spossing between them, signaling that some kind of traffic is happening. You can actually increase the verbosity, but this is not necessarily needed from within the terminal as the framework automatically saves everything that happens as output in a file within the test case folders that we will now discuss. The experiment output is always saved under the label that is provided with an experiment configuration because we can have multiple runs of an experiment. The first entries that you will find within such a folder are actually time stamped to signify multiple runs. If you enter that, you will actually find the different folders that contain the data of the multiple test cases that were compiled by the framework. If you take a dive into one of these folders, you can see what output we are collecting in these cases. By default, the framework will always create a server, client and shaper folder which get automatically mounted on the Docker volumes under the slash logs directory. Anything the implementations want to save, they can just write files to this directory and the framework will capture this and save this to in the log files. Additionally, clients also have a downloads folder mounted simply because we want to differentiate and not come into a situation where downloads accidentally override output logs generated by a client. You can also see that we have, especially under the server and client entries, you can see keys.log and a Qlog folder. The framework is automatically primed to save these encryption details and what's happening at the quick and HTTP tree layers by setting the SSL Qlog file which we discussed in the beginning but also by setting a Qlog environment variable which gets recognized by most quick implementations out there nowadays. Finally, we come to extensibility. At this point in time, we have a framework that is great at aggregating a lot of data. We did some tests that ran for two or three days straight containing more than 8,000 test cases which were great if you want to gather a lot of data. But what makes a testing framework, a testing framework, is the actual ability to infer something from the output generated by a test which is why we provide these two programmable interfaces called sensors and hooks. I explain sensors a little bit. We provide some basic sensors but you actually also have the ability to program custom sensors. This makes a lot of sense if you want to do very specific or test for very specific behavior within your experiment. For example, if you are doing a video stream in the browser, you can actually send the decoding metrics of the video out of band to an HTTP endpoint, for example, that you set up in a custom sensor. If the sensor, for example, detects that some frames are being dropped or decoded in a wrong way, it could prematurely hold a test signaling that something went wrong. If you have lots of test cases like we do, we actually have test cases like I just said, running 48 hours, this is really beneficial because it holds the test in an early phase, saving us a lot of time. On the other hand, we have the hook system. So the framework currently is very broadly applicable. The downside of that is that we don't really know what's happening inside the test. But you can actually program some custom behavior through the pre-run hook and post-run hook system. As the name suggests, the pre-run hook runs before an actual test is run. So you can prime environments by, for example, generating some dynamic files that you will need during the experiment. It doesn't really matter what you want to do there. The post-run hook is really nice because you can use it to analyze whatever happened during a test. For example, you could, if queue logs are being generated, look at the queue logs and maybe even generate some nice graphs that you can immediately check after a test case has ended. Right. Another thing I need to mention with the pre-run hook and the post-run hook, if you don't like programming in Python, it's not really a problem. Python has this really great submodule called subprocesses. If you have some existing scripts that are made to work with the output produced by your experiment, you can simply call them also from this hook, meaning that you get exactly the same results without having to actually translate your existing code within these provided hooks. Right. That's in a nutshell what Vekvizir does. Thank you for your attention. And I think we have a couple of minutes left for questions. Yeah. So, a test case can be anything you want. If you have, like, if you're programming right now, you're developing something locally. The thing you need to do is actually wrap it within a Docker container. That's one way. Or run it as a CLI command. You simply need to provide it to the framework, and the framework will just spin it up. So, the framework doesn't actually check what your test case is doing. If you want to, like, spin up a simple, let's say, CLI command, like, echo, and you want to print something to the terminal, you simply put it in the JSON, it will run. So, more questions, please. We have a couple of minutes. Okay. I have a question. I see you're from university. What does university have to do with testing, like, what's the question? Okay. So, good question, actually. I'm not sure if there is a direct relationship with testing in the university. It's just that, like, during my PhD, and also the PhD of some of my colleagues here in front of me, we actually encountered that we had a need of such a framework, right? We had an actual need of spinning up multiple test cases and like, helping us with setting up these experiments, which is why we designed this. Early on, we just had a very minimal thing that just worked for us. And then, as time progressed, it actually became more and more mature, and we decided, well, this is actually a very good idea. So, we created an open source project for it, and we actually also submitted it to a open source and data set track for the MMSIS conference, which is happening in June in Vancouver. So, okay. I think we have time for one more question. The last question. No thankers. So, thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.36, "text": " Alright, so good morning everybody, my name is Joris and I'm a PhD student over at Hasselt", "tokens": [2798, 11, 370, 665, 2446, 2201, 11, 452, 1315, 307, 508, 46198, 293, 286, 478, 257, 14476, 3107, 670, 412, 389, 640, 2018], "temperature": 0.0, "avg_logprob": -0.29953007581757335, "compression_ratio": 1.46875, "no_speech_prob": 0.13604140281677246}, {"id": 1, "seek": 0, "start": 11.36, "end": 17.0, "text": " University here in Belgium and I'm doing a PhD on multimedia streaming and network", "tokens": [3535, 510, 294, 28094, 293, 286, 478, 884, 257, 14476, 322, 49202, 11791, 293, 3209], "temperature": 0.0, "avg_logprob": -0.29953007581757335, "compression_ratio": 1.46875, "no_speech_prob": 0.13604140281677246}, {"id": 2, "seek": 0, "start": 17.0, "end": 20.84, "text": " transport layer protocols or even better the intersection of those two.", "tokens": [5495, 4583, 20618, 420, 754, 1101, 264, 15236, 295, 729, 732, 13], "temperature": 0.0, "avg_logprob": -0.29953007581757335, "compression_ratio": 1.46875, "no_speech_prob": 0.13604140281677246}, {"id": 3, "seek": 0, "start": 20.84, "end": 25.88, "text": " Today I'm here to talk a little bit about a project we did called Vagvizir which is", "tokens": [2692, 286, 478, 510, 281, 751, 257, 707, 857, 466, 257, 1716, 321, 630, 1219, 691, 559, 85, 590, 347, 597, 307], "temperature": 0.0, "avg_logprob": -0.29953007581757335, "compression_ratio": 1.46875, "no_speech_prob": 0.13604140281677246}, {"id": 4, "seek": 2588, "start": 25.88, "end": 32.24, "text": " an automated testing framework for orchestrating client and server setups using the quick transport", "tokens": [364, 18473, 4997, 8388, 337, 14161, 8754, 6423, 293, 7154, 46832, 1228, 264, 1702, 5495], "temperature": 0.0, "avg_logprob": -0.14982447725661258, "compression_ratio": 1.6366906474820144, "no_speech_prob": 8.468954911222681e-05}, {"id": 5, "seek": 2588, "start": 32.24, "end": 37.56, "text": " layer protocols but before we jump into that maybe let's talk a little bit about what quick", "tokens": [4583, 20618, 457, 949, 321, 3012, 666, 300, 1310, 718, 311, 751, 257, 707, 857, 466, 437, 1702], "temperature": 0.0, "avg_logprob": -0.14982447725661258, "compression_ratio": 1.6366906474820144, "no_speech_prob": 8.468954911222681e-05}, {"id": 6, "seek": 2588, "start": 37.56, "end": 42.32, "text": " actually is because I assume not everybody has heard about it. Well quick is a general", "tokens": [767, 307, 570, 286, 6552, 406, 2201, 575, 2198, 466, 309, 13, 1042, 1702, 307, 257, 2674], "temperature": 0.0, "avg_logprob": -0.14982447725661258, "compression_ratio": 1.6366906474820144, "no_speech_prob": 8.468954911222681e-05}, {"id": 7, "seek": 2588, "start": 42.32, "end": 47.480000000000004, "text": " purpose transport layer protocol that was standardized by the ITF in May 2021 and if", "tokens": [4334, 5495, 4583, 10336, 300, 390, 31677, 538, 264, 6783, 37, 294, 1891, 7201, 293, 498], "temperature": 0.0, "avg_logprob": -0.14982447725661258, "compression_ratio": 1.6366906474820144, "no_speech_prob": 8.468954911222681e-05}, {"id": 8, "seek": 2588, "start": 47.480000000000004, "end": 53.08, "text": " you have any updated like applications on your phone or have been using the latest releases", "tokens": [291, 362, 604, 10588, 411, 5821, 322, 428, 2593, 420, 362, 668, 1228, 264, 6792, 16952], "temperature": 0.0, "avg_logprob": -0.14982447725661258, "compression_ratio": 1.6366906474820144, "no_speech_prob": 8.468954911222681e-05}, {"id": 9, "seek": 5308, "start": 53.08, "end": 57.4, "text": " of browsers such as Firefox, Chrome or whatever you're using you've probably been already", "tokens": [295, 36069, 1270, 382, 46613, 11, 15327, 420, 2035, 291, 434, 1228, 291, 600, 1391, 668, 1217], "temperature": 0.0, "avg_logprob": -0.19659276962280273, "compression_ratio": 1.6842105263157894, "no_speech_prob": 6.577822205144912e-05}, {"id": 10, "seek": 5308, "start": 57.4, "end": 62.599999999999994, "text": " using quick as it has been deployed to a lot of many different applications and websites", "tokens": [1228, 1702, 382, 309, 575, 668, 17826, 281, 257, 688, 295, 867, 819, 5821, 293, 12891], "temperature": 0.0, "avg_logprob": -0.19659276962280273, "compression_ratio": 1.6842105263157894, "no_speech_prob": 6.577822205144912e-05}, {"id": 11, "seek": 5308, "start": 62.599999999999994, "end": 66.48, "text": " already. For example Facebook, Instagram they are using it, if you're streaming videos", "tokens": [1217, 13, 1171, 1365, 4384, 11, 5281, 436, 366, 1228, 309, 11, 498, 291, 434, 11791, 2145], "temperature": 0.0, "avg_logprob": -0.19659276962280273, "compression_ratio": 1.6842105263157894, "no_speech_prob": 6.577822205144912e-05}, {"id": 12, "seek": 5308, "start": 66.48, "end": 72.24, "text": " over YouTube you have probably been already using quick. Quick is a name, it's not an", "tokens": [670, 3088, 291, 362, 1391, 668, 1217, 1228, 1702, 13, 12101, 307, 257, 1315, 11, 309, 311, 406, 364], "temperature": 0.0, "avg_logprob": -0.19659276962280273, "compression_ratio": 1.6842105263157894, "no_speech_prob": 6.577822205144912e-05}, {"id": 13, "seek": 5308, "start": 72.24, "end": 77.4, "text": " acronym, it used to stand for quick UDP internet connections but it has actually not been called", "tokens": [39195, 11, 309, 1143, 281, 1463, 337, 1702, 624, 11373, 4705, 9271, 457, 309, 575, 767, 406, 668, 1219], "temperature": 0.0, "avg_logprob": -0.19659276962280273, "compression_ratio": 1.6842105263157894, "no_speech_prob": 6.577822205144912e-05}, {"id": 14, "seek": 7740, "start": 77.4, "end": 84.60000000000001, "text": " that for quite some time already now. Some of its features, the biggest feature is encryption", "tokens": [300, 337, 1596, 512, 565, 1217, 586, 13, 2188, 295, 1080, 4122, 11, 264, 3880, 4111, 307, 29575], "temperature": 0.0, "avg_logprob": -0.15472468995211416, "compression_ratio": 1.7807308970099667, "no_speech_prob": 4.118272408959456e-05}, {"id": 15, "seek": 7740, "start": 84.60000000000001, "end": 89.16000000000001, "text": " so the protocol actually encrypts everything by default which is great because that's the", "tokens": [370, 264, 10336, 767, 17972, 39280, 1203, 538, 7576, 597, 307, 869, 570, 300, 311, 264], "temperature": 0.0, "avg_logprob": -0.15472468995211416, "compression_ratio": 1.7807308970099667, "no_speech_prob": 4.118272408959456e-05}, {"id": 16, "seek": 7740, "start": 89.16000000000001, "end": 93.84, "text": " main driver against ossification also it's reason that it was created because TCP is", "tokens": [2135, 6787, 1970, 19508, 3774, 611, 309, 311, 1778, 300, 309, 390, 2942, 570, 48965, 307], "temperature": 0.0, "avg_logprob": -0.15472468995211416, "compression_ratio": 1.7807308970099667, "no_speech_prob": 4.118272408959456e-05}, {"id": 17, "seek": 7740, "start": 93.84, "end": 98.36000000000001, "text": " actually an ossified protocol when we compare the two. It's also great for preventing third", "tokens": [767, 364, 19508, 2587, 10336, 562, 321, 6794, 264, 732, 13, 467, 311, 611, 869, 337, 19965, 2636], "temperature": 0.0, "avg_logprob": -0.15472468995211416, "compression_ratio": 1.7807308970099667, "no_speech_prob": 4.118272408959456e-05}, {"id": 18, "seek": 7740, "start": 98.36000000000001, "end": 102.56, "text": " parties from actually interfering with the data you are transmitting over the network.", "tokens": [8265, 490, 767, 48721, 365, 264, 1412, 291, 366, 7715, 2414, 670, 264, 3209, 13], "temperature": 0.0, "avg_logprob": -0.15472468995211416, "compression_ratio": 1.7807308970099667, "no_speech_prob": 4.118272408959456e-05}, {"id": 19, "seek": 7740, "start": 102.56, "end": 105.80000000000001, "text": " It's less great for research and development as you have to actually account for that in", "tokens": [467, 311, 1570, 869, 337, 2132, 293, 3250, 382, 291, 362, 281, 767, 2696, 337, 300, 294], "temperature": 0.0, "avg_logprob": -0.15472468995211416, "compression_ratio": 1.7807308970099667, "no_speech_prob": 4.118272408959456e-05}, {"id": 20, "seek": 10580, "start": 105.8, "end": 111.12, "text": " your test setups which we are going to talk about a little bit further ahead. It's currently", "tokens": [428, 1500, 46832, 597, 321, 366, 516, 281, 751, 466, 257, 707, 857, 3052, 2286, 13, 467, 311, 4362], "temperature": 0.0, "avg_logprob": -0.1262180682310124, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00020272900292184204}, {"id": 21, "seek": 10580, "start": 111.12, "end": 116.47999999999999, "text": " most implementations implemented on top of UDP in user space. Some implementations are", "tokens": [881, 4445, 763, 12270, 322, 1192, 295, 624, 11373, 294, 4195, 1901, 13, 2188, 4445, 763, 366], "temperature": 0.0, "avg_logprob": -0.1262180682310124, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00020272900292184204}, {"id": 22, "seek": 10580, "start": 116.47999999999999, "end": 122.16, "text": " actually looking at implementing it more towards the kernel but those steps have not been taken", "tokens": [767, 1237, 412, 18114, 309, 544, 3030, 264, 28256, 457, 729, 4439, 362, 406, 668, 2726], "temperature": 0.0, "avg_logprob": -0.1262180682310124, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00020272900292184204}, {"id": 23, "seek": 10580, "start": 122.16, "end": 128.8, "text": " by many of the implementations. At present at least as far as I know 25 implementations", "tokens": [538, 867, 295, 264, 4445, 763, 13, 1711, 1974, 412, 1935, 382, 1400, 382, 286, 458, 3552, 4445, 763], "temperature": 0.0, "avg_logprob": -0.1262180682310124, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00020272900292184204}, {"id": 24, "seek": 10580, "start": 128.8, "end": 134.2, "text": " exist most of them also being open source written in multiple programming languages.", "tokens": [2514, 881, 295, 552, 611, 885, 1269, 4009, 3720, 294, 3866, 9410, 8650, 13], "temperature": 0.0, "avg_logprob": -0.1262180682310124, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00020272900292184204}, {"id": 25, "seek": 13420, "start": 134.2, "end": 139.44, "text": " They also provide libraries which you can directly use to actually use quick in your", "tokens": [814, 611, 2893, 15148, 597, 291, 393, 3838, 764, 281, 767, 764, 1702, 294, 428], "temperature": 0.0, "avg_logprob": -0.17411883480577584, "compression_ratio": 1.5818181818181818, "no_speech_prob": 6.226256664376706e-05}, {"id": 26, "seek": 13420, "start": 139.44, "end": 147.0, "text": " applications. Another benefit of quick or another new thing with quick is HTTP 3 which", "tokens": [5821, 13, 3996, 5121, 295, 1702, 420, 1071, 777, 551, 365, 1702, 307, 33283, 805, 597], "temperature": 0.0, "avg_logprob": -0.17411883480577584, "compression_ratio": 1.5818181818181818, "no_speech_prob": 6.226256664376706e-05}, {"id": 27, "seek": 13420, "start": 147.0, "end": 153.07999999999998, "text": " you might have heard of. The reason for the introduction of H3 is that H1 and H2 actually", "tokens": [291, 1062, 362, 2198, 295, 13, 440, 1778, 337, 264, 9339, 295, 389, 18, 307, 300, 389, 16, 293, 389, 17, 767], "temperature": 0.0, "avg_logprob": -0.17411883480577584, "compression_ratio": 1.5818181818181818, "no_speech_prob": 6.226256664376706e-05}, {"id": 28, "seek": 13420, "start": 153.07999999999998, "end": 159.39999999999998, "text": " only run over TCP that's why they created a new version of HTTP called HTTP 3. There's", "tokens": [787, 1190, 670, 48965, 300, 311, 983, 436, 2942, 257, 777, 3037, 295, 33283, 1219, 33283, 805, 13, 821, 311], "temperature": 0.0, "avg_logprob": -0.17411883480577584, "compression_ratio": 1.5818181818181818, "no_speech_prob": 6.226256664376706e-05}, {"id": 29, "seek": 15940, "start": 159.4, "end": 164.64000000000001, "text": " not that big of a difference between H2 and H3 in practice but just for sake of naming", "tokens": [406, 300, 955, 295, 257, 2649, 1296, 389, 17, 293, 389, 18, 294, 3124, 457, 445, 337, 9717, 295, 25290], "temperature": 0.0, "avg_logprob": -0.1458602263548664, "compression_ratio": 1.654275092936803, "no_speech_prob": 5.145536124473438e-05}, {"id": 30, "seek": 15940, "start": 164.64000000000001, "end": 171.76, "text": " it it's HTTP 3. Right so now that you know what quick is that's at least a requirement", "tokens": [309, 309, 311, 33283, 805, 13, 1779, 370, 586, 300, 291, 458, 437, 1702, 307, 300, 311, 412, 1935, 257, 11695], "temperature": 0.0, "avg_logprob": -0.1458602263548664, "compression_ratio": 1.654275092936803, "no_speech_prob": 5.145536124473438e-05}, {"id": 31, "seek": 15940, "start": 171.76, "end": 177.88, "text": " for understanding the stock. Let's talk about how we can actually use this in like experiments", "tokens": [337, 3701, 264, 4127, 13, 961, 311, 751, 466, 577, 321, 393, 767, 764, 341, 294, 411, 12050], "temperature": 0.0, "avg_logprob": -0.1458602263548664, "compression_ratio": 1.654275092936803, "no_speech_prob": 5.145536124473438e-05}, {"id": 32, "seek": 15940, "start": 177.88, "end": 183.8, "text": " and stuff. Maybe let's try doing something very simple. I just told you that most browsers", "tokens": [293, 1507, 13, 2704, 718, 311, 853, 884, 746, 588, 2199, 13, 286, 445, 1907, 291, 300, 881, 36069], "temperature": 0.0, "avg_logprob": -0.1458602263548664, "compression_ratio": 1.654275092936803, "no_speech_prob": 5.145536124473438e-05}, {"id": 33, "seek": 15940, "start": 183.8, "end": 189.0, "text": " implement quick. Maybe let's try connecting to a website that only implements an HTTP", "tokens": [4445, 1702, 13, 2704, 718, 311, 853, 11015, 281, 257, 3144, 300, 787, 704, 17988, 364, 33283], "temperature": 0.0, "avg_logprob": -0.1458602263548664, "compression_ratio": 1.654275092936803, "no_speech_prob": 5.145536124473438e-05}, {"id": 34, "seek": 18900, "start": 189.0, "end": 194.56, "text": " 3 server. Should be simple right but as you can see on the screenshot it is not in practice.", "tokens": [805, 7154, 13, 6454, 312, 2199, 558, 457, 382, 291, 393, 536, 322, 264, 27712, 309, 307, 406, 294, 3124, 13], "temperature": 0.0, "avg_logprob": -0.1369478243206619, "compression_ratio": 1.6425992779783394, "no_speech_prob": 9.728843724587932e-05}, {"id": 35, "seek": 18900, "start": 194.56, "end": 199.16, "text": " And the reason for that is really simple that's because browsers decided early on that HTTP", "tokens": [400, 264, 1778, 337, 300, 307, 534, 2199, 300, 311, 570, 36069, 3047, 2440, 322, 300, 33283], "temperature": 0.0, "avg_logprob": -0.1369478243206619, "compression_ratio": 1.6425992779783394, "no_speech_prob": 9.728843724587932e-05}, {"id": 36, "seek": 18900, "start": 199.16, "end": 208.12, "text": " 3 server should be discoverable through the old SVC header provided by an H1 or H2 deployment", "tokens": [805, 7154, 820, 312, 4411, 712, 807, 264, 1331, 31910, 34, 23117, 5649, 538, 364, 389, 16, 420, 389, 17, 19317], "temperature": 0.0, "avg_logprob": -0.1369478243206619, "compression_ratio": 1.6425992779783394, "no_speech_prob": 9.728843724587932e-05}, {"id": 37, "seek": 18900, "start": 208.12, "end": 211.44, "text": " which really sucks if you want to do some automated testing because that means you also", "tokens": [597, 534, 15846, 498, 291, 528, 281, 360, 512, 18473, 4997, 570, 300, 1355, 291, 611], "temperature": 0.0, "avg_logprob": -0.1369478243206619, "compression_ratio": 1.6425992779783394, "no_speech_prob": 9.728843724587932e-05}, {"id": 38, "seek": 18900, "start": 211.44, "end": 217.44, "text": " have to put up like or spin up an H1 or H2 server and actually account for this. Luckily", "tokens": [362, 281, 829, 493, 411, 420, 6060, 493, 364, 389, 16, 420, 389, 17, 7154, 293, 767, 2696, 337, 341, 13, 19726], "temperature": 0.0, "avg_logprob": -0.1369478243206619, "compression_ratio": 1.6425992779783394, "no_speech_prob": 9.728843724587932e-05}, {"id": 39, "seek": 21744, "start": 217.44, "end": 222.96, "text": " we have some options like for example within Chrome and Firefox to enable force quick on", "tokens": [321, 362, 512, 3956, 411, 337, 1365, 1951, 15327, 293, 46613, 281, 9528, 3464, 1702, 322], "temperature": 0.0, "avg_logprob": -0.13864241148296155, "compression_ratio": 1.6752767527675276, "no_speech_prob": 2.7618976673693396e-05}, {"id": 40, "seek": 21744, "start": 222.96, "end": 229.28, "text": " certain domains which we can automate through or by means of for example parameters supplied", "tokens": [1629, 25514, 597, 321, 393, 31605, 807, 420, 538, 1355, 295, 337, 1365, 9834, 27625], "temperature": 0.0, "avg_logprob": -0.13864241148296155, "compression_ratio": 1.6752767527675276, "no_speech_prob": 2.7618976673693396e-05}, {"id": 41, "seek": 21744, "start": 229.28, "end": 236.56, "text": " in the command line or by configurations in the browser itself. Right so we can connect", "tokens": [294, 264, 5622, 1622, 420, 538, 31493, 294, 264, 11185, 2564, 13, 1779, 370, 321, 393, 1745], "temperature": 0.0, "avg_logprob": -0.13864241148296155, "compression_ratio": 1.6752767527675276, "no_speech_prob": 2.7618976673693396e-05}, {"id": 42, "seek": 21744, "start": 236.56, "end": 240.52, "text": " to a web server at this point. How do we actually know what's happening under the hood should", "tokens": [281, 257, 3670, 7154, 412, 341, 935, 13, 1012, 360, 321, 767, 458, 437, 311, 2737, 833, 264, 13376, 820], "temperature": 0.0, "avg_logprob": -0.13864241148296155, "compression_ratio": 1.6752767527675276, "no_speech_prob": 2.7618976673693396e-05}, {"id": 43, "seek": 21744, "start": 240.52, "end": 244.6, "text": " also be simple right. Remember everything is encrypted so actually seeing what's happening", "tokens": [611, 312, 2199, 558, 13, 5459, 1203, 307, 36663, 370, 767, 2577, 437, 311, 2737], "temperature": 0.0, "avg_logprob": -0.13864241148296155, "compression_ratio": 1.6752767527675276, "no_speech_prob": 2.7618976673693396e-05}, {"id": 44, "seek": 24460, "start": 244.6, "end": 251.28, "text": " is a little bit is not that trivial actually. Luckily most implementations nowadays use", "tokens": [307, 257, 707, 857, 307, 406, 300, 26703, 767, 13, 19726, 881, 4445, 763, 13434, 764], "temperature": 0.0, "avg_logprob": -0.1658663230367226, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.875595863675699e-05}, {"id": 45, "seek": 24460, "start": 251.28, "end": 258.44, "text": " like standard of the shelf TLS libraries and these TLS back ends actually support an environment", "tokens": [411, 3832, 295, 264, 15222, 314, 19198, 15148, 293, 613, 314, 19198, 646, 5314, 767, 1406, 364, 2823], "temperature": 0.0, "avg_logprob": -0.1658663230367226, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.875595863675699e-05}, {"id": 46, "seek": 24460, "start": 258.44, "end": 262.76, "text": " variable called SSL key lock file and the idea behind the SSL key lock file is that you can", "tokens": [7006, 1219, 12238, 43, 2141, 4017, 3991, 293, 264, 1558, 2261, 264, 12238, 43, 2141, 4017, 3991, 307, 300, 291, 393], "temperature": 0.0, "avg_logprob": -0.1658663230367226, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.875595863675699e-05}, {"id": 47, "seek": 24460, "start": 262.76, "end": 268.04, "text": " like point it towards a file which then gets used by these TLS back ends to like output", "tokens": [411, 935, 309, 3030, 257, 3991, 597, 550, 2170, 1143, 538, 613, 314, 19198, 646, 5314, 281, 411, 5598], "temperature": 0.0, "avg_logprob": -0.1658663230367226, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.875595863675699e-05}, {"id": 48, "seek": 24460, "start": 268.04, "end": 272.92, "text": " all the secrets used for encryption during a whatever the application is actually doing.", "tokens": [439, 264, 14093, 1143, 337, 29575, 1830, 257, 2035, 264, 3861, 307, 767, 884, 13], "temperature": 0.0, "avg_logprob": -0.1658663230367226, "compression_ratio": 1.7976190476190477, "no_speech_prob": 6.875595863675699e-05}, {"id": 49, "seek": 27292, "start": 272.92, "end": 277.0, "text": " If you load those SSL key lock files into programs like wire shark you can actually", "tokens": [759, 291, 3677, 729, 12238, 43, 2141, 4017, 7098, 666, 4268, 411, 6234, 13327, 291, 393, 767], "temperature": 0.0, "avg_logprob": -0.1575736443973282, "compression_ratio": 1.6162361623616237, "no_speech_prob": 0.00010769422078737989}, {"id": 50, "seek": 27292, "start": 277.0, "end": 282.44, "text": " decrypt the traffic which is nice if you want to see what happened. Unfortunately tools", "tokens": [979, 627, 662, 264, 6419, 597, 307, 1481, 498, 291, 528, 281, 536, 437, 2011, 13, 8590, 3873], "temperature": 0.0, "avg_logprob": -0.1575736443973282, "compression_ratio": 1.6162361623616237, "no_speech_prob": 0.00010769422078737989}, {"id": 51, "seek": 27292, "start": 282.44, "end": 287.52000000000004, "text": " like wire shark at least as far as I know don't actually have any visualizations about", "tokens": [411, 6234, 13327, 412, 1935, 382, 1400, 382, 286, 458, 500, 380, 767, 362, 604, 5056, 14455, 466], "temperature": 0.0, "avg_logprob": -0.1575736443973282, "compression_ratio": 1.6162361623616237, "no_speech_prob": 0.00010769422078737989}, {"id": 52, "seek": 27292, "start": 287.52000000000004, "end": 292.64, "text": " stuff that's happening at like the congestion or flow control layer. You have that for TCP", "tokens": [1507, 300, 311, 2737, 412, 411, 264, 40816, 420, 3095, 1969, 4583, 13, 509, 362, 300, 337, 48965], "temperature": 0.0, "avg_logprob": -0.1575736443973282, "compression_ratio": 1.6162361623616237, "no_speech_prob": 0.00010769422078737989}, {"id": 53, "seek": 27292, "start": 292.64, "end": 299.28000000000003, "text": " but quick those things don't exist yet. But luckily we have other stuff for that. Q lock", "tokens": [457, 1702, 729, 721, 500, 380, 2514, 1939, 13, 583, 22880, 321, 362, 661, 1507, 337, 300, 13, 1249, 4017], "temperature": 0.0, "avg_logprob": -0.1575736443973282, "compression_ratio": 1.6162361623616237, "no_speech_prob": 0.00010769422078737989}, {"id": 54, "seek": 29928, "start": 299.28, "end": 303.15999999999997, "text": " is one of them. There has been a nice talk about this by its inventor a couple of years", "tokens": [307, 472, 295, 552, 13, 821, 575, 668, 257, 1481, 751, 466, 341, 538, 1080, 41593, 257, 1916, 295, 924], "temperature": 0.0, "avg_logprob": -0.1472676446504682, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00019281702407170087}, {"id": 55, "seek": 29928, "start": 303.15999999999997, "end": 307.35999999999996, "text": " ago at FOSDOM. I really invite you to look at it. But basically in a nutshell what Q", "tokens": [2057, 412, 479, 4367, 35, 5251, 13, 286, 534, 7980, 291, 281, 574, 412, 309, 13, 583, 1936, 294, 257, 37711, 437, 1249], "temperature": 0.0, "avg_logprob": -0.1472676446504682, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00019281702407170087}, {"id": 56, "seek": 29928, "start": 307.35999999999996, "end": 313.71999999999997, "text": " lock is is like a structured way of logging and a unified way of logging that can be implemented", "tokens": [4017, 307, 307, 411, 257, 18519, 636, 295, 27991, 293, 257, 26787, 636, 295, 27991, 300, 393, 312, 12270], "temperature": 0.0, "avg_logprob": -0.1472676446504682, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00019281702407170087}, {"id": 57, "seek": 29928, "start": 313.71999999999997, "end": 321.55999999999995, "text": " by any endpoint implementation using quick. In a nutshell this is basically a file for", "tokens": [538, 604, 35795, 11420, 1228, 1702, 13, 682, 257, 37711, 341, 307, 1936, 257, 3991, 337], "temperature": 0.0, "avg_logprob": -0.1472676446504682, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00019281702407170087}, {"id": 58, "seek": 29928, "start": 321.55999999999995, "end": 327.44, "text": " example a JSON file that just locks everything that's happening and if you have some scripts", "tokens": [1365, 257, 31828, 3991, 300, 445, 20703, 1203, 300, 311, 2737, 293, 498, 291, 362, 512, 23294], "temperature": 0.0, "avg_logprob": -0.1472676446504682, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00019281702407170087}, {"id": 59, "seek": 32744, "start": 327.44, "end": 331.88, "text": " or tools that can parse this you can actually do a lot of fun stuff with it. For example", "tokens": [420, 3873, 300, 393, 48377, 341, 291, 393, 767, 360, 257, 688, 295, 1019, 1507, 365, 309, 13, 1171, 1365], "temperature": 0.0, "avg_logprob": -0.15381264105075743, "compression_ratio": 1.7903780068728523, "no_speech_prob": 7.251545321196318e-05}, {"id": 60, "seek": 32744, "start": 331.88, "end": 336.44, "text": " the QVIS visualization tool which is also by the same creator is a tool that allows", "tokens": [264, 1249, 53, 2343, 25801, 2290, 597, 307, 611, 538, 264, 912, 14181, 307, 257, 2290, 300, 4045], "temperature": 0.0, "avg_logprob": -0.15381264105075743, "compression_ratio": 1.7903780068728523, "no_speech_prob": 7.251545321196318e-05}, {"id": 61, "seek": 32744, "start": 336.44, "end": 340.88, "text": " you to load these files and like actually visualize similar to what wire shark can do", "tokens": [291, 281, 3677, 613, 7098, 293, 411, 767, 23273, 2531, 281, 437, 6234, 13327, 393, 360], "temperature": 0.0, "avg_logprob": -0.15381264105075743, "compression_ratio": 1.7903780068728523, "no_speech_prob": 7.251545321196318e-05}, {"id": 62, "seek": 32744, "start": 340.88, "end": 345.24, "text": " for TCP but then for quick what's happening on the congestion layers. For example on the", "tokens": [337, 48965, 457, 550, 337, 1702, 437, 311, 2737, 322, 264, 40816, 7914, 13, 1171, 1365, 322, 264], "temperature": 0.0, "avg_logprob": -0.15381264105075743, "compression_ratio": 1.7903780068728523, "no_speech_prob": 7.251545321196318e-05}, {"id": 63, "seek": 32744, "start": 345.24, "end": 351.64, "text": " left you see a flow control and congestion flow graph and on the right you see a plot", "tokens": [1411, 291, 536, 257, 3095, 1969, 293, 40816, 3095, 4295, 293, 322, 264, 558, 291, 536, 257, 7542], "temperature": 0.0, "avg_logprob": -0.15381264105075743, "compression_ratio": 1.7903780068728523, "no_speech_prob": 7.251545321196318e-05}, {"id": 64, "seek": 32744, "start": 351.64, "end": 356.8, "text": " of the home trip time that was experienced by the application. So we can look at what's", "tokens": [295, 264, 1280, 4931, 565, 300, 390, 6751, 538, 264, 3861, 13, 407, 321, 393, 574, 412, 437, 311], "temperature": 0.0, "avg_logprob": -0.15381264105075743, "compression_ratio": 1.7903780068728523, "no_speech_prob": 7.251545321196318e-05}, {"id": 65, "seek": 35680, "start": 356.8, "end": 362.76, "text": " happening under the hood maybe let's try something more advanced setting up like your own quick", "tokens": [2737, 833, 264, 13376, 1310, 718, 311, 853, 746, 544, 7339, 3287, 493, 411, 428, 1065, 1702], "temperature": 0.0, "avg_logprob": -0.13313951699630075, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.00019302360306028277}, {"id": 66, "seek": 35680, "start": 362.76, "end": 367.52000000000004, "text": " client and quick server to do some local experiments maybe change something to the implementations", "tokens": [6423, 293, 1702, 7154, 281, 360, 512, 2654, 12050, 1310, 1319, 746, 281, 264, 4445, 763], "temperature": 0.0, "avg_logprob": -0.13313951699630075, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.00019302360306028277}, {"id": 67, "seek": 35680, "start": 367.52000000000004, "end": 371.84000000000003, "text": " it doesn't matter really what you want to do. Even that is not that trivial simply because", "tokens": [309, 1177, 380, 1871, 534, 437, 291, 528, 281, 360, 13, 2754, 300, 307, 406, 300, 26703, 2935, 570], "temperature": 0.0, "avg_logprob": -0.13313951699630075, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.00019302360306028277}, {"id": 68, "seek": 35680, "start": 371.84000000000003, "end": 375.44, "text": " there are many implementations written in many languages meaning that they have their", "tokens": [456, 366, 867, 4445, 763, 3720, 294, 867, 8650, 3620, 300, 436, 362, 641], "temperature": 0.0, "avg_logprob": -0.13313951699630075, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.00019302360306028277}, {"id": 69, "seek": 35680, "start": 375.44, "end": 382.36, "text": " own requirements their own installation procedures. Another distinction is that different implementations", "tokens": [1065, 7728, 641, 1065, 13260, 13846, 13, 3996, 16844, 307, 300, 819, 4445, 763], "temperature": 0.0, "avg_logprob": -0.13313951699630075, "compression_ratio": 1.7798507462686568, "no_speech_prob": 0.00019302360306028277}, {"id": 70, "seek": 38236, "start": 382.36, "end": 386.96000000000004, "text": " actually have different performance characteristics meaning that some are more tuned towards certain", "tokens": [767, 362, 819, 3389, 10891, 3620, 300, 512, 366, 544, 10870, 3030, 1629], "temperature": 0.0, "avg_logprob": -0.14743604967671056, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.00013854897406417876}, {"id": 71, "seek": 38236, "start": 386.96000000000004, "end": 394.52000000000004, "text": " scenarios some only support a certain feature set so you also have to account for that.", "tokens": [15077, 512, 787, 1406, 257, 1629, 4111, 992, 370, 291, 611, 362, 281, 2696, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.14743604967671056, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.00013854897406417876}, {"id": 72, "seek": 38236, "start": 394.52000000000004, "end": 399.96000000000004, "text": " An additional requirement is that you also have to set up like self-signed certificates", "tokens": [1107, 4497, 11695, 307, 300, 291, 611, 362, 281, 992, 493, 411, 2698, 12, 82, 16690, 32941], "temperature": 0.0, "avg_logprob": -0.14743604967671056, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.00013854897406417876}, {"id": 73, "seek": 38236, "start": 399.96000000000004, "end": 404.8, "text": " and for some reason some implementations accept all kinds of certificates and then for some", "tokens": [293, 337, 512, 1778, 512, 4445, 763, 3241, 439, 3685, 295, 32941, 293, 550, 337, 512], "temperature": 0.0, "avg_logprob": -0.14743604967671056, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.00013854897406417876}, {"id": 74, "seek": 38236, "start": 404.8, "end": 410.8, "text": " reason others fail we have never really figured out why we just use a common way that works", "tokens": [1778, 2357, 3061, 321, 362, 1128, 534, 8932, 484, 983, 321, 445, 764, 257, 2689, 636, 300, 1985], "temperature": 0.0, "avg_logprob": -0.14743604967671056, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.00013854897406417876}, {"id": 75, "seek": 41080, "start": 410.8, "end": 416.08, "text": " for them all now anyway. Another query that you can experience is within the code bases", "tokens": [337, 552, 439, 586, 4033, 13, 3996, 14581, 300, 291, 393, 1752, 307, 1951, 264, 3089, 17949], "temperature": 0.0, "avg_logprob": -0.1901271016974198, "compression_ratio": 1.8361344537815125, "no_speech_prob": 0.00019124166283290833}, {"id": 76, "seek": 41080, "start": 416.08, "end": 421.16, "text": " themselves a fun one I always show to my students is this one this is from the quick", "tokens": [2969, 257, 1019, 472, 286, 1009, 855, 281, 452, 1731, 307, 341, 472, 341, 307, 490, 264, 1702], "temperature": 0.0, "avg_logprob": -0.1901271016974198, "compression_ratio": 1.8361344537815125, "no_speech_prob": 0.00019124166283290833}, {"id": 77, "seek": 41080, "start": 421.16, "end": 427.0, "text": " code base which uses the cubic congestion control algorithm if you know something about", "tokens": [3089, 3096, 597, 4960, 264, 28733, 40816, 1969, 9284, 498, 291, 458, 746, 466], "temperature": 0.0, "avg_logprob": -0.1901271016974198, "compression_ratio": 1.8361344537815125, "no_speech_prob": 0.00019124166283290833}, {"id": 78, "seek": 41080, "start": 427.0, "end": 431.92, "text": " congestion control and makes sense like the file is called new cubic sander the function", "tokens": [40816, 1969, 293, 1669, 2020, 411, 264, 3991, 307, 1219, 777, 28733, 262, 4483, 264, 2445], "temperature": 0.0, "avg_logprob": -0.1901271016974198, "compression_ratio": 1.8361344537815125, "no_speech_prob": 0.00019124166283290833}, {"id": 79, "seek": 41080, "start": 431.92, "end": 435.8, "text": " is called new cubic new cubic sander it even specifies in documentation that it makes a", "tokens": [307, 1219, 777, 28733, 777, 28733, 262, 4483, 309, 754, 1608, 11221, 294, 14333, 300, 309, 1669, 257], "temperature": 0.0, "avg_logprob": -0.1901271016974198, "compression_ratio": 1.8361344537815125, "no_speech_prob": 0.00019124166283290833}, {"id": 80, "seek": 43580, "start": 435.8, "end": 441.12, "text": " new cubic sander unless you actually put a Renault ball on true then it behaves like", "tokens": [777, 28733, 262, 4483, 5969, 291, 767, 829, 257, 23068, 723, 2594, 322, 2074, 550, 309, 36896, 411], "temperature": 0.0, "avg_logprob": -0.17158640210873613, "compression_ratio": 1.7729083665338645, "no_speech_prob": 7.505813118768856e-05}, {"id": 81, "seek": 43580, "start": 441.12, "end": 447.08, "text": " a totally different beast actually new Renault in that case so some some weird quirks that", "tokens": [257, 3879, 819, 13464, 767, 777, 23068, 723, 294, 300, 1389, 370, 512, 512, 3657, 35645, 1694, 300], "temperature": 0.0, "avg_logprob": -0.17158640210873613, "compression_ratio": 1.7729083665338645, "no_speech_prob": 7.505813118768856e-05}, {"id": 82, "seek": 43580, "start": 447.08, "end": 452.76, "text": " you actually have to account for too. So the point I'm trying to make it is is that there", "tokens": [291, 767, 362, 281, 2696, 337, 886, 13, 407, 264, 935, 286, 478, 1382, 281, 652, 309, 307, 307, 300, 456], "temperature": 0.0, "avg_logprob": -0.17158640210873613, "compression_ratio": 1.7729083665338645, "no_speech_prob": 7.505813118768856e-05}, {"id": 83, "seek": 43580, "start": 452.76, "end": 456.12, "text": " are a lot of different implementations testing the mall takes time it's not that easy to", "tokens": [366, 257, 688, 295, 819, 4445, 763, 4997, 264, 16026, 2516, 565, 309, 311, 406, 300, 1858, 281], "temperature": 0.0, "avg_logprob": -0.17158640210873613, "compression_ratio": 1.7729083665338645, "no_speech_prob": 7.505813118768856e-05}, {"id": 84, "seek": 43580, "start": 456.12, "end": 461.04, "text": " set it up you experience a lot of these small issues it's cumbersome to like test multiple", "tokens": [992, 309, 493, 291, 1752, 257, 688, 295, 613, 1359, 2663, 309, 311, 12713, 1616, 423, 281, 411, 1500, 3866], "temperature": 0.0, "avg_logprob": -0.17158640210873613, "compression_ratio": 1.7729083665338645, "no_speech_prob": 7.505813118768856e-05}, {"id": 85, "seek": 46104, "start": 461.04, "end": 467.04, "text": " implementations which is the reason why I am presenting Vagvizir today. The idea behind", "tokens": [4445, 763, 597, 307, 264, 1778, 983, 286, 669, 15578, 691, 559, 85, 590, 347, 965, 13, 440, 1558, 2261], "temperature": 0.0, "avg_logprob": -0.173615623922909, "compression_ratio": 1.7109375, "no_speech_prob": 5.793306991108693e-05}, {"id": 86, "seek": 46104, "start": 467.04, "end": 470.72, "text": " Vagvizir is to actually aid with this kind of development so if you're doing research", "tokens": [691, 559, 85, 590, 347, 307, 281, 767, 9418, 365, 341, 733, 295, 3250, 370, 498, 291, 434, 884, 2132], "temperature": 0.0, "avg_logprob": -0.173615623922909, "compression_ratio": 1.7109375, "no_speech_prob": 5.793306991108693e-05}, {"id": 87, "seek": 46104, "start": 470.72, "end": 474.96000000000004, "text": " or even development within quick the idea is that Vagvizir can automatically set up", "tokens": [420, 754, 3250, 1951, 1702, 264, 1558, 307, 300, 691, 559, 85, 590, 347, 393, 6772, 992, 493], "temperature": 0.0, "avg_logprob": -0.173615623922909, "compression_ratio": 1.7109375, "no_speech_prob": 5.793306991108693e-05}, {"id": 88, "seek": 46104, "start": 474.96000000000004, "end": 480.20000000000005, "text": " these kinds of interactions between clients and servers but also using simulated networks", "tokens": [613, 3685, 295, 13280, 1296, 6982, 293, 15909, 457, 611, 1228, 41713, 9590], "temperature": 0.0, "avg_logprob": -0.173615623922909, "compression_ratio": 1.7109375, "no_speech_prob": 5.793306991108693e-05}, {"id": 89, "seek": 46104, "start": 480.20000000000005, "end": 485.68, "text": " such that you can have actual repeatable and shareable experiments. The way you do it this", "tokens": [1270, 300, 291, 393, 362, 3539, 7149, 712, 293, 2073, 712, 12050, 13, 440, 636, 291, 360, 309, 341], "temperature": 0.0, "avg_logprob": -0.173615623922909, "compression_ratio": 1.7109375, "no_speech_prob": 5.793306991108693e-05}, {"id": 90, "seek": 48568, "start": 485.68, "end": 491.6, "text": " is by defining experiments with configuration files and a single experiment can consist", "tokens": [307, 538, 17827, 12050, 365, 11694, 7098, 293, 257, 2167, 5120, 393, 4603], "temperature": 0.0, "avg_logprob": -0.1210430086273508, "compression_ratio": 1.834008097165992, "no_speech_prob": 5.472741031553596e-05}, {"id": 91, "seek": 48568, "start": 491.6, "end": 495.48, "text": " out of multiple test cases and the idea is that a single test case looks something like", "tokens": [484, 295, 3866, 1500, 3331, 293, 264, 1558, 307, 300, 257, 2167, 1500, 1389, 1542, 746, 411], "temperature": 0.0, "avg_logprob": -0.1210430086273508, "compression_ratio": 1.834008097165992, "no_speech_prob": 5.472741031553596e-05}, {"id": 92, "seek": 48568, "start": 495.48, "end": 502.2, "text": " this. So you have the two entities the server and the client which just assume their prototypical", "tokens": [341, 13, 407, 291, 362, 264, 732, 16667, 264, 7154, 293, 264, 6423, 597, 445, 6552, 641, 46219, 34061], "temperature": 0.0, "avg_logprob": -0.1210430086273508, "compression_ratio": 1.834008097165992, "no_speech_prob": 5.472741031553596e-05}, {"id": 93, "seek": 48568, "start": 502.2, "end": 507.2, "text": " roles as known within the server client model and in between them sits a network component", "tokens": [9604, 382, 2570, 1951, 264, 7154, 6423, 2316, 293, 294, 1296, 552, 12696, 257, 3209, 6542], "temperature": 0.0, "avg_logprob": -0.1210430086273508, "compression_ratio": 1.834008097165992, "no_speech_prob": 5.472741031553596e-05}, {"id": 94, "seek": 48568, "start": 507.2, "end": 510.6, "text": " that we call the shaper and the idea of the shaper is that it actually applies some kind", "tokens": [300, 321, 818, 264, 402, 2332, 293, 264, 1558, 295, 264, 402, 2332, 307, 300, 309, 767, 13165, 512, 733], "temperature": 0.0, "avg_logprob": -0.1210430086273508, "compression_ratio": 1.834008097165992, "no_speech_prob": 5.472741031553596e-05}, {"id": 95, "seek": 51060, "start": 510.6, "end": 516.2, "text": " of scenario on the traffic passing between the server and client for example it can introduce", "tokens": [295, 9005, 322, 264, 6419, 8437, 1296, 264, 7154, 293, 6423, 337, 1365, 309, 393, 5366], "temperature": 0.0, "avg_logprob": -0.13561016082763672, "compression_ratio": 1.76171875, "no_speech_prob": 7.442192872986197e-05}, {"id": 96, "seek": 51060, "start": 516.2, "end": 521.12, "text": " some latency or it could limit the throughput doesn't really matter what you want to do", "tokens": [512, 27043, 420, 309, 727, 4948, 264, 44629, 1177, 380, 534, 1871, 437, 291, 528, 281, 360], "temperature": 0.0, "avg_logprob": -0.13561016082763672, "compression_ratio": 1.76171875, "no_speech_prob": 7.442192872986197e-05}, {"id": 97, "seek": 51060, "start": 521.12, "end": 526.0, "text": " the idea is that you can do it in a repeatable way. You also see the docker container stuff", "tokens": [264, 1558, 307, 300, 291, 393, 360, 309, 294, 257, 7149, 712, 636, 13, 509, 611, 536, 264, 360, 9178, 10129, 1507], "temperature": 0.0, "avg_logprob": -0.13561016082763672, "compression_ratio": 1.76171875, "no_speech_prob": 7.442192872986197e-05}, {"id": 98, "seek": 51060, "start": 526.0, "end": 532.0400000000001, "text": " on top the idea of using or actually deploying these test cases within docker containers", "tokens": [322, 1192, 264, 1558, 295, 1228, 420, 767, 34198, 613, 1500, 3331, 1951, 360, 9178, 17089], "temperature": 0.0, "avg_logprob": -0.13561016082763672, "compression_ratio": 1.76171875, "no_speech_prob": 7.442192872986197e-05}, {"id": 99, "seek": 51060, "start": 532.0400000000001, "end": 537.24, "text": " is that we can easily share them with other people which is a really nice benefit within", "tokens": [307, 300, 321, 393, 3612, 2073, 552, 365, 661, 561, 597, 307, 257, 534, 1481, 5121, 1951], "temperature": 0.0, "avg_logprob": -0.13561016082763672, "compression_ratio": 1.76171875, "no_speech_prob": 7.442192872986197e-05}, {"id": 100, "seek": 53724, "start": 537.24, "end": 542.5600000000001, "text": " the academic community but also we can free certain implementations like we can actually", "tokens": [264, 7778, 1768, 457, 611, 321, 393, 1737, 1629, 4445, 763, 411, 321, 393, 767], "temperature": 0.0, "avg_logprob": -0.15059902312907766, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.00011062525300076231}, {"id": 101, "seek": 53724, "start": 542.5600000000001, "end": 547.08, "text": " save a docker container and reuse it at a later point so say for example something changes", "tokens": [3155, 257, 360, 9178, 10129, 293, 26225, 309, 412, 257, 1780, 935, 370, 584, 337, 1365, 746, 2962], "temperature": 0.0, "avg_logprob": -0.15059902312907766, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.00011062525300076231}, {"id": 102, "seek": 53724, "start": 547.08, "end": 551.12, "text": " and we want to try an older version that's totally possible with this setup. Additionally", "tokens": [293, 321, 528, 281, 853, 364, 4906, 3037, 300, 311, 3879, 1944, 365, 341, 8657, 13, 19927], "temperature": 0.0, "avg_logprob": -0.15059902312907766, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.00011062525300076231}, {"id": 103, "seek": 53724, "start": 551.12, "end": 556.6, "text": " within the quick community there have been some other efforts if you are part of the", "tokens": [1951, 264, 1702, 1768, 456, 362, 668, 512, 661, 6484, 498, 291, 366, 644, 295, 264], "temperature": 0.0, "avg_logprob": -0.15059902312907766, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.00011062525300076231}, {"id": 104, "seek": 53724, "start": 556.6, "end": 562.32, "text": " quick community you might actually recognize this setup it's pretty much the same as one", "tokens": [1702, 1768, 291, 1062, 767, 5521, 341, 8657, 309, 311, 1238, 709, 264, 912, 382, 472], "temperature": 0.0, "avg_logprob": -0.15059902312907766, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.00011062525300076231}, {"id": 105, "seek": 56232, "start": 562.32, "end": 568.12, "text": " used by an interoperability project called the quick interoperability runner. They also", "tokens": [1143, 538, 364, 728, 7192, 2310, 1716, 1219, 264, 1702, 728, 7192, 2310, 24376, 13, 814, 611], "temperature": 0.0, "avg_logprob": -0.12985201084867437, "compression_ratio": 1.8299595141700404, "no_speech_prob": 4.053645898238756e-05}, {"id": 106, "seek": 56232, "start": 568.12, "end": 572.48, "text": " provide containers for their setup that are more tuned towards testing the actual interoperability", "tokens": [2893, 17089, 337, 641, 8657, 300, 366, 544, 10870, 3030, 4997, 264, 3539, 728, 7192, 2310], "temperature": 0.0, "avg_logprob": -0.12985201084867437, "compression_ratio": 1.8299595141700404, "no_speech_prob": 4.053645898238756e-05}, {"id": 107, "seek": 56232, "start": 572.48, "end": 577.8000000000001, "text": " between quick implementations but the benefit of using the same architecture is that we", "tokens": [1296, 1702, 4445, 763, 457, 264, 5121, 295, 1228, 264, 912, 9482, 307, 300, 321], "temperature": 0.0, "avg_logprob": -0.12985201084867437, "compression_ratio": 1.8299595141700404, "no_speech_prob": 4.053645898238756e-05}, {"id": 108, "seek": 56232, "start": 577.8000000000001, "end": 584.0400000000001, "text": " are actually completely compatible with their setups so that means that even though Vegvizir", "tokens": [366, 767, 2584, 18218, 365, 641, 46832, 370, 300, 1355, 300, 754, 1673, 12895, 85, 590, 347], "temperature": 0.0, "avg_logprob": -0.12985201084867437, "compression_ratio": 1.8299595141700404, "no_speech_prob": 4.053645898238756e-05}, {"id": 109, "seek": 56232, "start": 584.0400000000001, "end": 588.6, "text": " is relatively new at this point in time we are already compatible with 15 out of the", "tokens": [307, 7226, 777, 412, 341, 935, 294, 565, 321, 366, 1217, 18218, 365, 2119, 484, 295, 264], "temperature": 0.0, "avg_logprob": -0.12985201084867437, "compression_ratio": 1.8299595141700404, "no_speech_prob": 4.053645898238756e-05}, {"id": 110, "seek": 58860, "start": 588.6, "end": 594.9200000000001, "text": " 25 quick implementations right out of the box. You also see on the right side that we", "tokens": [3552, 1702, 4445, 763, 558, 484, 295, 264, 2424, 13, 509, 611, 536, 322, 264, 558, 1252, 300, 321], "temperature": 0.0, "avg_logprob": -0.11743707745988792, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.418392826570198e-05}, {"id": 111, "seek": 58860, "start": 594.9200000000001, "end": 600.36, "text": " have a client that can be defined as a CLI command that's because early on we realized", "tokens": [362, 257, 6423, 300, 393, 312, 7642, 382, 257, 12855, 40, 5622, 300, 311, 570, 2440, 322, 321, 5334], "temperature": 0.0, "avg_logprob": -0.11743707745988792, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.418392826570198e-05}, {"id": 112, "seek": 58860, "start": 600.36, "end": 606.32, "text": " that if we want to test applications not everything is not every kind of test is suitable to be", "tokens": [300, 498, 321, 528, 281, 1500, 5821, 406, 1203, 307, 406, 633, 733, 295, 1500, 307, 12873, 281, 312], "temperature": 0.0, "avg_logprob": -0.11743707745988792, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.418392826570198e-05}, {"id": 113, "seek": 58860, "start": 606.32, "end": 611.96, "text": " placed in a docker container which is why we also allow to define test by just spinning", "tokens": [7074, 294, 257, 360, 9178, 10129, 597, 307, 983, 321, 611, 2089, 281, 6964, 1500, 538, 445, 15640], "temperature": 0.0, "avg_logprob": -0.11743707745988792, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.418392826570198e-05}, {"id": 114, "seek": 58860, "start": 611.96, "end": 618.08, "text": " up local programs as you are used to from a terminal. A good example of this is a browser", "tokens": [493, 2654, 4268, 382, 291, 366, 1143, 281, 490, 257, 14709, 13, 316, 665, 1365, 295, 341, 307, 257, 11185], "temperature": 0.0, "avg_logprob": -0.11743707745988792, "compression_ratio": 1.5985663082437276, "no_speech_prob": 8.418392826570198e-05}, {"id": 115, "seek": 61808, "start": 618.08, "end": 622.0400000000001, "text": " if you're doing some kind of media streaming experiments you actually want hardware acceleration", "tokens": [498, 291, 434, 884, 512, 733, 295, 3021, 11791, 12050, 291, 767, 528, 8837, 17162], "temperature": 0.0, "avg_logprob": -0.15060758127749546, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.368744940729812e-05}, {"id": 116, "seek": 61808, "start": 622.0400000000001, "end": 626.5600000000001, "text": " as such to be enabled which I guess you can do this in docker containers but it's really", "tokens": [382, 1270, 281, 312, 15172, 597, 286, 2041, 291, 393, 360, 341, 294, 360, 9178, 17089, 457, 309, 311, 534], "temperature": 0.0, "avg_logprob": -0.15060758127749546, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.368744940729812e-05}, {"id": 117, "seek": 61808, "start": 626.5600000000001, "end": 632.5200000000001, "text": " cumbersome to actually do this in a good way. Right okay so how are these experiments", "tokens": [12713, 1616, 423, 281, 767, 360, 341, 294, 257, 665, 636, 13, 1779, 1392, 370, 577, 366, 613, 12050], "temperature": 0.0, "avg_logprob": -0.15060758127749546, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.368744940729812e-05}, {"id": 118, "seek": 61808, "start": 632.5200000000001, "end": 639.6, "text": " actually defined? Well we decided to not use one single configuration file simply because", "tokens": [767, 7642, 30, 1042, 321, 3047, 281, 406, 764, 472, 2167, 11694, 3991, 2935, 570], "temperature": 0.0, "avg_logprob": -0.15060758127749546, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.368744940729812e-05}, {"id": 119, "seek": 61808, "start": 639.6, "end": 645.32, "text": " that would mean we had to be very verbose. We actually split it up in two types of configurations.", "tokens": [300, 576, 914, 321, 632, 281, 312, 588, 9595, 541, 13, 492, 767, 7472, 309, 493, 294, 732, 3467, 295, 31493, 13], "temperature": 0.0, "avg_logprob": -0.15060758127749546, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.368744940729812e-05}, {"id": 120, "seek": 64532, "start": 645.32, "end": 650.08, "text": " On the left you can see the implementation configuration which is actually what defines", "tokens": [1282, 264, 1411, 291, 393, 536, 264, 11420, 11694, 597, 307, 767, 437, 23122], "temperature": 0.0, "avg_logprob": -0.10836352777043613, "compression_ratio": 1.9558823529411764, "no_speech_prob": 3.965997530031018e-05}, {"id": 121, "seek": 64532, "start": 650.08, "end": 655.0400000000001, "text": " what is available within an experiment. So the idea is that an implementation configuration", "tokens": [437, 307, 2435, 1951, 364, 5120, 13, 407, 264, 1558, 307, 300, 364, 11420, 11694], "temperature": 0.0, "avg_logprob": -0.10836352777043613, "compression_ratio": 1.9558823529411764, "no_speech_prob": 3.965997530031018e-05}, {"id": 122, "seek": 64532, "start": 655.0400000000001, "end": 659.4000000000001, "text": " is similar to like your list of installed software on your computer. You simply have", "tokens": [307, 2531, 281, 411, 428, 1329, 295, 8899, 4722, 322, 428, 3820, 13, 509, 2935, 362], "temperature": 0.0, "avg_logprob": -0.10836352777043613, "compression_ratio": 1.9558823529411764, "no_speech_prob": 3.965997530031018e-05}, {"id": 123, "seek": 64532, "start": 659.4000000000001, "end": 663.88, "text": " a list of entities that you can pick from. We also introduced a parametric system to", "tokens": [257, 1329, 295, 16667, 300, 291, 393, 1888, 490, 13, 492, 611, 7268, 257, 6220, 17475, 1185, 281], "temperature": 0.0, "avg_logprob": -0.10836352777043613, "compression_ratio": 1.9558823529411764, "no_speech_prob": 3.965997530031018e-05}, {"id": 124, "seek": 64532, "start": 663.88, "end": 668.0400000000001, "text": " make it actually really dynamic steerable from within an experiment configuration and", "tokens": [652, 309, 767, 534, 8546, 30814, 712, 490, 1951, 364, 5120, 11694, 293], "temperature": 0.0, "avg_logprob": -0.10836352777043613, "compression_ratio": 1.9558823529411764, "no_speech_prob": 3.965997530031018e-05}, {"id": 125, "seek": 64532, "start": 668.0400000000001, "end": 673.1600000000001, "text": " we will see some examples on that in a second. On the right you see the experiment configuration", "tokens": [321, 486, 536, 512, 5110, 322, 300, 294, 257, 1150, 13, 1282, 264, 558, 291, 536, 264, 5120, 11694], "temperature": 0.0, "avg_logprob": -0.10836352777043613, "compression_ratio": 1.9558823529411764, "no_speech_prob": 3.965997530031018e-05}, {"id": 126, "seek": 67316, "start": 673.16, "end": 677.48, "text": " that's the actual definition of what needs to happen within one experiment so what defines", "tokens": [300, 311, 264, 3539, 7123, 295, 437, 2203, 281, 1051, 1951, 472, 5120, 370, 437, 23122], "temperature": 0.0, "avg_logprob": -0.16804653474654274, "compression_ratio": 1.7786561264822134, "no_speech_prob": 0.00010099354403791949}, {"id": 127, "seek": 67316, "start": 677.48, "end": 683.28, "text": " the test cases. The idea is that you define how the entities from the implementation configuration", "tokens": [264, 1500, 3331, 13, 440, 1558, 307, 300, 291, 6964, 577, 264, 16667, 490, 264, 11420, 11694], "temperature": 0.0, "avg_logprob": -0.16804653474654274, "compression_ratio": 1.7786561264822134, "no_speech_prob": 0.00010099354403791949}, {"id": 128, "seek": 67316, "start": 683.28, "end": 691.56, "text": " should behave and what parameters should actually contain as values through arguments.", "tokens": [820, 15158, 293, 437, 9834, 820, 767, 5304, 382, 4190, 807, 12869, 13], "temperature": 0.0, "avg_logprob": -0.16804653474654274, "compression_ratio": 1.7786561264822134, "no_speech_prob": 0.00010099354403791949}, {"id": 129, "seek": 67316, "start": 691.56, "end": 695.52, "text": " Also configure sensors I'm going to talk about that in a second but the biggest benefit", "tokens": [2743, 22162, 14840, 286, 478, 516, 281, 751, 466, 300, 294, 257, 1150, 457, 264, 3880, 5121], "temperature": 0.0, "avg_logprob": -0.16804653474654274, "compression_ratio": 1.7786561264822134, "no_speech_prob": 0.00010099354403791949}, {"id": 130, "seek": 67316, "start": 695.52, "end": 702.0799999999999, "text": " of splitting these two up is actually that the experiment configuration automatically", "tokens": [295, 30348, 613, 732, 493, 307, 767, 300, 264, 5120, 11694, 6772], "temperature": 0.0, "avg_logprob": -0.16804653474654274, "compression_ratio": 1.7786561264822134, "no_speech_prob": 0.00010099354403791949}, {"id": 131, "seek": 70208, "start": 702.08, "end": 708.9200000000001, "text": " produces this permutation or rather a total of combinations from all these entities. So", "tokens": [14725, 341, 4784, 11380, 420, 2831, 257, 3217, 295, 21267, 490, 439, 613, 16667, 13, 407], "temperature": 0.0, "avg_logprob": -0.14801531722865155, "compression_ratio": 1.6654135338345866, "no_speech_prob": 5.369462087401189e-05}, {"id": 132, "seek": 70208, "start": 708.9200000000001, "end": 713.08, "text": " say for example you define two servers, two clients and two shapers. The total amount", "tokens": [584, 337, 1365, 291, 6964, 732, 15909, 11, 732, 6982, 293, 732, 6706, 433, 13, 440, 3217, 2372], "temperature": 0.0, "avg_logprob": -0.14801531722865155, "compression_ratio": 1.6654135338345866, "no_speech_prob": 5.369462087401189e-05}, {"id": 133, "seek": 70208, "start": 713.08, "end": 719.76, "text": " of tests within this experiment will actually be eight because it just compiles a complete", "tokens": [295, 6921, 1951, 341, 5120, 486, 767, 312, 3180, 570, 309, 445, 715, 4680, 257, 3566], "temperature": 0.0, "avg_logprob": -0.14801531722865155, "compression_ratio": 1.6654135338345866, "no_speech_prob": 5.369462087401189e-05}, {"id": 134, "seek": 70208, "start": 719.76, "end": 724.84, "text": " combination of all these configurations. Another benefit is loose coupling so you might wonder", "tokens": [6562, 295, 439, 613, 31493, 13, 3996, 5121, 307, 9612, 37447, 370, 291, 1062, 2441], "temperature": 0.0, "avg_logprob": -0.14801531722865155, "compression_ratio": 1.6654135338345866, "no_speech_prob": 5.369462087401189e-05}, {"id": 135, "seek": 70208, "start": 724.84, "end": 729.24, "text": " yeah I still don't see the reason why you split these two up. Well a big thing with", "tokens": [1338, 286, 920, 500, 380, 536, 264, 1778, 983, 291, 7472, 613, 732, 493, 13, 1042, 257, 955, 551, 365], "temperature": 0.0, "avg_logprob": -0.14801531722865155, "compression_ratio": 1.6654135338345866, "no_speech_prob": 5.369462087401189e-05}, {"id": 136, "seek": 72924, "start": 729.24, "end": 733.72, "text": " an academic research is that we actually want to test different versions. So if we have", "tokens": [364, 7778, 2132, 307, 300, 321, 767, 528, 281, 1500, 819, 9606, 13, 407, 498, 321, 362], "temperature": 0.0, "avg_logprob": -0.13308339118957518, "compression_ratio": 2.1646090534979425, "no_speech_prob": 5.52993624296505e-05}, {"id": 137, "seek": 72924, "start": 733.72, "end": 738.32, "text": " an implementation configuration that for example defines a client called Chrome which", "tokens": [364, 11420, 11694, 300, 337, 1365, 23122, 257, 6423, 1219, 15327, 597], "temperature": 0.0, "avg_logprob": -0.13308339118957518, "compression_ratio": 2.1646090534979425, "no_speech_prob": 5.52993624296505e-05}, {"id": 138, "seek": 72924, "start": 738.32, "end": 743.6, "text": " then refers to a Chrome browser we can actually have one implementation configuration that", "tokens": [550, 14942, 281, 257, 15327, 11185, 321, 393, 767, 362, 472, 11420, 11694, 300], "temperature": 0.0, "avg_logprob": -0.13308339118957518, "compression_ratio": 2.1646090534979425, "no_speech_prob": 5.52993624296505e-05}, {"id": 139, "seek": 72924, "start": 743.6, "end": 748.24, "text": " refers to version for example 99 and we can have another implementation configuration", "tokens": [14942, 281, 3037, 337, 1365, 11803, 293, 321, 393, 362, 1071, 11420, 11694], "temperature": 0.0, "avg_logprob": -0.13308339118957518, "compression_ratio": 2.1646090534979425, "no_speech_prob": 5.52993624296505e-05}, {"id": 140, "seek": 72924, "start": 748.24, "end": 752.88, "text": " that refers to for example version 100. The benefit of that is that if we simply swap", "tokens": [300, 14942, 281, 337, 1365, 3037, 2319, 13, 440, 5121, 295, 300, 307, 300, 498, 321, 2935, 18135], "temperature": 0.0, "avg_logprob": -0.13308339118957518, "compression_ratio": 2.1646090534979425, "no_speech_prob": 5.52993624296505e-05}, {"id": 141, "seek": 72924, "start": 752.88, "end": 757.12, "text": " these implementation configurations we don't need to change the experiment configurations", "tokens": [613, 11420, 31493, 321, 500, 380, 643, 281, 1319, 264, 5120, 31493], "temperature": 0.0, "avg_logprob": -0.13308339118957518, "compression_ratio": 2.1646090534979425, "no_speech_prob": 5.52993624296505e-05}, {"id": 142, "seek": 75712, "start": 757.12, "end": 761.5600000000001, "text": " meaning that we can without having to verbose rewrite all these stats really easily test", "tokens": [3620, 300, 321, 393, 1553, 1419, 281, 9595, 541, 28132, 439, 613, 18152, 534, 3612, 1500], "temperature": 0.0, "avg_logprob": -0.16600872169841419, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.300012005842291e-05}, {"id": 143, "seek": 75712, "start": 761.5600000000001, "end": 767.84, "text": " multiple setups. Some examples this is an example of an implementation configuration.", "tokens": [3866, 46832, 13, 2188, 5110, 341, 307, 364, 1365, 295, 364, 11420, 11694, 13], "temperature": 0.0, "avg_logprob": -0.16600872169841419, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.300012005842291e-05}, {"id": 144, "seek": 75712, "start": 767.84, "end": 772.44, "text": " I do invite you to go to the GitHub repository where everything is really nicely explained", "tokens": [286, 360, 7980, 291, 281, 352, 281, 264, 23331, 25841, 689, 1203, 307, 534, 9594, 8825], "temperature": 0.0, "avg_logprob": -0.16600872169841419, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.300012005842291e-05}, {"id": 145, "seek": 75712, "start": 772.44, "end": 780.28, "text": " and we provide some more examples unfortunately limited by the screen size. You see that we", "tokens": [293, 321, 2893, 512, 544, 5110, 7015, 5567, 538, 264, 2568, 2744, 13, 509, 536, 300, 321], "temperature": 0.0, "avg_logprob": -0.16600872169841419, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.300012005842291e-05}, {"id": 146, "seek": 75712, "start": 780.28, "end": 784.08, "text": " always have to define in the implementation configuration three types of entities like", "tokens": [1009, 362, 281, 6964, 294, 264, 11420, 11694, 1045, 3467, 295, 16667, 411], "temperature": 0.0, "avg_logprob": -0.16600872169841419, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.300012005842291e-05}, {"id": 147, "seek": 78408, "start": 784.08, "end": 789.08, "text": " we talked about earlier the clients the servers and the shapers and these three are examples", "tokens": [321, 2825, 466, 3071, 264, 6982, 264, 15909, 293, 264, 6706, 433, 293, 613, 1045, 366, 5110], "temperature": 0.0, "avg_logprob": -0.17718545186150933, "compression_ratio": 1.7547892720306513, "no_speech_prob": 0.00013697746908292174}, {"id": 148, "seek": 78408, "start": 789.08, "end": 794.2800000000001, "text": " using Docker system. So in the top two you see that we actually refer to Docker Hub images.", "tokens": [1228, 33772, 1185, 13, 407, 294, 264, 1192, 732, 291, 536, 300, 321, 767, 2864, 281, 33772, 18986, 5267, 13], "temperature": 0.0, "avg_logprob": -0.17718545186150933, "compression_ratio": 1.7547892720306513, "no_speech_prob": 0.00013697746908292174}, {"id": 149, "seek": 78408, "start": 794.2800000000001, "end": 798.12, "text": " These are actual examples that come from the quick interop runner project which we are", "tokens": [1981, 366, 3539, 5110, 300, 808, 490, 264, 1702, 728, 404, 24376, 1716, 597, 321, 366], "temperature": 0.0, "avg_logprob": -0.17718545186150933, "compression_ratio": 1.7547892720306513, "no_speech_prob": 0.00013697746908292174}, {"id": 150, "seek": 78408, "start": 798.12, "end": 803.8000000000001, "text": " compatible with. The bottom one is a locally built Docker image. The reason I highlight", "tokens": [18218, 365, 13, 440, 2767, 472, 307, 257, 16143, 3094, 33772, 3256, 13, 440, 1778, 286, 5078], "temperature": 0.0, "avg_logprob": -0.17718545186150933, "compression_ratio": 1.7547892720306513, "no_speech_prob": 0.00013697746908292174}, {"id": 151, "seek": 78408, "start": 803.8000000000001, "end": 808.88, "text": " this difference is because the framework automatically pulls the latest Docker Hub images if these", "tokens": [341, 2649, 307, 570, 264, 8388, 6772, 16982, 264, 6792, 33772, 18986, 5267, 498, 613], "temperature": 0.0, "avg_logprob": -0.17718545186150933, "compression_ratio": 1.7547892720306513, "no_speech_prob": 0.00013697746908292174}, {"id": 152, "seek": 80888, "start": 808.88, "end": 814.68, "text": " are available. But if you are using some kind of local implementation that you build as", "tokens": [366, 2435, 13, 583, 498, 291, 366, 1228, 512, 733, 295, 2654, 11420, 300, 291, 1322, 382], "temperature": 0.0, "avg_logprob": -0.12200723780263768, "compression_ratio": 1.7976653696498055, "no_speech_prob": 3.777772872126661e-05}, {"id": 153, "seek": 80888, "start": 814.68, "end": 819.88, "text": " a Docker image you actually have to build it locally and then refer to it locally. Another", "tokens": [257, 33772, 3256, 291, 767, 362, 281, 1322, 309, 16143, 293, 550, 2864, 281, 309, 16143, 13, 3996], "temperature": 0.0, "avg_logprob": -0.12200723780263768, "compression_ratio": 1.7976653696498055, "no_speech_prob": 3.777772872126661e-05}, {"id": 154, "seek": 80888, "start": 819.88, "end": 825.6, "text": " thing you can see here is the parametric system. So for example the top client defines a request", "tokens": [551, 291, 393, 536, 510, 307, 264, 6220, 17475, 1185, 13, 407, 337, 1365, 264, 1192, 6423, 23122, 257, 5308], "temperature": 0.0, "avg_logprob": -0.12200723780263768, "compression_ratio": 1.7976653696498055, "no_speech_prob": 3.777772872126661e-05}, {"id": 155, "seek": 80888, "start": 825.6, "end": 831.6, "text": " parameter that is then used within an experiment. The idea is that an experiment configuration", "tokens": [13075, 300, 307, 550, 1143, 1951, 364, 5120, 13, 440, 1558, 307, 300, 364, 5120, 11694], "temperature": 0.0, "avg_logprob": -0.12200723780263768, "compression_ratio": 1.7976653696498055, "no_speech_prob": 3.777772872126661e-05}, {"id": 156, "seek": 80888, "start": 831.6, "end": 837.84, "text": " then contains a value of it and that you can access this value within a Docker image simply", "tokens": [550, 8306, 257, 2158, 295, 309, 293, 300, 291, 393, 2105, 341, 2158, 1951, 257, 33772, 3256, 2935], "temperature": 0.0, "avg_logprob": -0.12200723780263768, "compression_ratio": 1.7976653696498055, "no_speech_prob": 3.777772872126661e-05}, {"id": 157, "seek": 83784, "start": 837.84, "end": 844.0, "text": " by using requests then in this case as a environment variable. So all the parameters are passed", "tokens": [538, 1228, 12475, 550, 294, 341, 1389, 382, 257, 2823, 7006, 13, 407, 439, 264, 9834, 366, 4678], "temperature": 0.0, "avg_logprob": -0.1328273360262212, "compression_ratio": 1.779527559055118, "no_speech_prob": 2.397897515038494e-05}, {"id": 158, "seek": 83784, "start": 844.0, "end": 849.6800000000001, "text": " as environment variables if you are using Docker images. Or in the case that you are", "tokens": [382, 2823, 9102, 498, 291, 366, 1228, 33772, 5267, 13, 1610, 294, 264, 1389, 300, 291, 366], "temperature": 0.0, "avg_logprob": -0.1328273360262212, "compression_ratio": 1.779527559055118, "no_speech_prob": 2.397897515038494e-05}, {"id": 159, "seek": 83784, "start": 849.6800000000001, "end": 854.64, "text": " using CLI commands or even in a more specific case of shapers because shapers are a little", "tokens": [1228, 12855, 40, 16901, 420, 754, 294, 257, 544, 2685, 1389, 295, 6706, 433, 570, 6706, 433, 366, 257, 707], "temperature": 0.0, "avg_logprob": -0.1328273360262212, "compression_ratio": 1.779527559055118, "no_speech_prob": 2.397897515038494e-05}, {"id": 160, "seek": 83784, "start": 854.64, "end": 859.24, "text": " bit more complicated. You can also use them directly in the commands you specify within", "tokens": [857, 544, 6179, 13, 509, 393, 611, 764, 552, 3838, 294, 264, 16901, 291, 16500, 1951], "temperature": 0.0, "avg_logprob": -0.1328273360262212, "compression_ratio": 1.779527559055118, "no_speech_prob": 2.397897515038494e-05}, {"id": 161, "seek": 83784, "start": 859.24, "end": 863.6800000000001, "text": " the implementation and experiment configurations. These are directly substituted and you can", "tokens": [264, 11420, 293, 5120, 31493, 13, 1981, 366, 3838, 26441, 4866, 293, 291, 393], "temperature": 0.0, "avg_logprob": -0.1328273360262212, "compression_ratio": 1.779527559055118, "no_speech_prob": 2.397897515038494e-05}, {"id": 162, "seek": 86368, "start": 863.68, "end": 874.04, "text": " actually reference other parameters within arguments which is nice. A simple example", "tokens": [767, 6408, 661, 9834, 1951, 12869, 597, 307, 1481, 13, 316, 2199, 1365], "temperature": 0.0, "avg_logprob": -0.18372894805154683, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.3192761798563879e-05}, {"id": 163, "seek": 86368, "start": 874.04, "end": 879.5999999999999, "text": " of a CLI client, so one that is not using a Docker image in other words, you can see", "tokens": [295, 257, 12855, 40, 6423, 11, 370, 472, 300, 307, 406, 1228, 257, 33772, 3256, 294, 661, 2283, 11, 291, 393, 536], "temperature": 0.0, "avg_logprob": -0.18372894805154683, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.3192761798563879e-05}, {"id": 164, "seek": 86368, "start": 879.5999999999999, "end": 884.92, "text": " that the command is rather long. That is because we cannot, well compared to a Docker container", "tokens": [300, 264, 5622, 307, 2831, 938, 13, 663, 307, 570, 321, 2644, 11, 731, 5347, 281, 257, 33772, 10129], "temperature": 0.0, "avg_logprob": -0.18372894805154683, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.3192761798563879e-05}, {"id": 165, "seek": 86368, "start": 884.92, "end": 891.52, "text": " we actually have to specify everything that needs to happen in CLI command. This example", "tokens": [321, 767, 362, 281, 16500, 1203, 300, 2203, 281, 1051, 294, 12855, 40, 5622, 13, 639, 1365], "temperature": 0.0, "avg_logprob": -0.18372894805154683, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.3192761798563879e-05}, {"id": 166, "seek": 89152, "start": 891.52, "end": 897.3199999999999, "text": " provides three or rather four system parameters which are highlighted here. The reason I did", "tokens": [6417, 1045, 420, 2831, 1451, 1185, 9834, 597, 366, 17173, 510, 13, 440, 1778, 286, 630], "temperature": 0.0, "avg_logprob": -0.16921857128972592, "compression_ratio": 1.6483516483516483, "no_speech_prob": 4.605626963893883e-05}, {"id": 167, "seek": 89152, "start": 897.3199999999999, "end": 902.12, "text": " this is because the framework automatically generates all these details for you such that", "tokens": [341, 307, 570, 264, 8388, 6772, 23815, 439, 613, 4365, 337, 291, 1270, 300], "temperature": 0.0, "avg_logprob": -0.16921857128972592, "compression_ratio": 1.6483516483516483, "no_speech_prob": 4.605626963893883e-05}, {"id": 168, "seek": 89152, "start": 902.12, "end": 907.12, "text": " the experiments can be even more dynamically steered. This is especially handy for future", "tokens": [264, 12050, 393, 312, 754, 544, 43492, 2126, 4073, 13, 639, 307, 2318, 13239, 337, 2027], "temperature": 0.0, "avg_logprob": -0.16921857128972592, "compression_ratio": 1.6483516483516483, "no_speech_prob": 4.605626963893883e-05}, {"id": 169, "seek": 89152, "start": 907.12, "end": 911.8, "text": " use cases where we for example want to expand upon multiple client setups and stuff like", "tokens": [764, 3331, 689, 321, 337, 1365, 528, 281, 5268, 3564, 3866, 6423, 46832, 293, 1507, 411], "temperature": 0.0, "avg_logprob": -0.16921857128972592, "compression_ratio": 1.6483516483516483, "no_speech_prob": 4.605626963893883e-05}, {"id": 170, "seek": 89152, "start": 911.8, "end": 917.6, "text": " that. On the bottom you see a construct key. We actually have two special mechanisms for", "tokens": [300, 13, 1282, 264, 2767, 291, 536, 257, 7690, 2141, 13, 492, 767, 362, 732, 2121, 15902, 337], "temperature": 0.0, "avg_logprob": -0.16921857128972592, "compression_ratio": 1.6483516483516483, "no_speech_prob": 4.605626963893883e-05}, {"id": 171, "seek": 91760, "start": 917.6, "end": 922.72, "text": " CLI commands. In Docker images, the benefit of Docker images is that they can actually", "tokens": [12855, 40, 16901, 13, 682, 33772, 5267, 11, 264, 5121, 295, 33772, 5267, 307, 300, 436, 393, 767], "temperature": 0.0, "avg_logprob": -0.14893197078330844, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.00010324717732146382}, {"id": 172, "seek": 91760, "start": 922.72, "end": 928.24, "text": " have scripts on board that actually prime the environment. That is the downside of using", "tokens": [362, 23294, 322, 3150, 300, 767, 5835, 264, 2823, 13, 663, 307, 264, 25060, 295, 1228], "temperature": 0.0, "avg_logprob": -0.14893197078330844, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.00010324717732146382}, {"id": 173, "seek": 91760, "start": 928.24, "end": 935.32, "text": " CLI commands unless you want to put everything on one single line which is rather also cumbersome.", "tokens": [12855, 40, 16901, 5969, 291, 528, 281, 829, 1203, 322, 472, 2167, 1622, 597, 307, 2831, 611, 12713, 1616, 423, 13], "temperature": 0.0, "avg_logprob": -0.14893197078330844, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.00010324717732146382}, {"id": 174, "seek": 91760, "start": 935.32, "end": 939.4, "text": " Instead we provide two mechanisms called construct and destruct which are run before and after", "tokens": [7156, 321, 2893, 732, 15902, 1219, 7690, 293, 2677, 1757, 597, 366, 1190, 949, 293, 934], "temperature": 0.0, "avg_logprob": -0.14893197078330844, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.00010324717732146382}, {"id": 175, "seek": 91760, "start": 939.4, "end": 945.9200000000001, "text": " a command is executed. These can be used to prime an environment and clean it up afterwards.", "tokens": [257, 5622, 307, 17577, 13, 1981, 393, 312, 1143, 281, 5835, 364, 2823, 293, 2541, 309, 493, 10543, 13], "temperature": 0.0, "avg_logprob": -0.14893197078330844, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.00010324717732146382}, {"id": 176, "seek": 94592, "start": 945.92, "end": 952.68, "text": " This example sets like the changes or manipulates actually the Google Chrome preferences to", "tokens": [639, 1365, 6352, 411, 264, 2962, 420, 9258, 26192, 767, 264, 3329, 15327, 21910, 281], "temperature": 0.0, "avg_logprob": -0.15099933412339953, "compression_ratio": 1.6779026217228465, "no_speech_prob": 5.272955968393944e-05}, {"id": 177, "seek": 94592, "start": 952.68, "end": 958.52, "text": " set like the standard download folder output towards one generated by the framework.", "tokens": [992, 411, 264, 3832, 5484, 10820, 5598, 3030, 472, 10833, 538, 264, 8388, 13], "temperature": 0.0, "avg_logprob": -0.15099933412339953, "compression_ratio": 1.6779026217228465, "no_speech_prob": 5.272955968393944e-05}, {"id": 178, "seek": 94592, "start": 958.52, "end": 965.92, "text": " Then we come to the experiment configurations examples. These are the actual configurations", "tokens": [1396, 321, 808, 281, 264, 5120, 31493, 5110, 13, 1981, 366, 264, 3539, 31493], "temperature": 0.0, "avg_logprob": -0.15099933412339953, "compression_ratio": 1.6779026217228465, "no_speech_prob": 5.272955968393944e-05}, {"id": 179, "seek": 94592, "start": 965.92, "end": 969.8399999999999, "text": " that define how a test should behave. You see here once again we have client shapers", "tokens": [300, 6964, 577, 257, 1500, 820, 15158, 13, 509, 536, 510, 1564, 797, 321, 362, 6423, 6706, 433], "temperature": 0.0, "avg_logprob": -0.15099933412339953, "compression_ratio": 1.6779026217228465, "no_speech_prob": 5.272955968393944e-05}, {"id": 180, "seek": 94592, "start": 969.8399999999999, "end": 974.88, "text": " and servers which we picked from the implementation that we just showed. We simply filled them", "tokens": [293, 15909, 597, 321, 6183, 490, 264, 11420, 300, 321, 445, 4712, 13, 492, 2935, 6412, 552], "temperature": 0.0, "avg_logprob": -0.15099933412339953, "compression_ratio": 1.6779026217228465, "no_speech_prob": 5.272955968393944e-05}, {"id": 181, "seek": 97488, "start": 974.88, "end": 983.04, "text": " in with the arguments required for the test to work. A special thing to notice here is", "tokens": [294, 365, 264, 12869, 4739, 337, 264, 1500, 281, 589, 13, 316, 2121, 551, 281, 3449, 510, 307], "temperature": 0.0, "avg_logprob": -0.17607535602890442, "compression_ratio": 1.7125984251968505, "no_speech_prob": 6.86144339852035e-05}, {"id": 182, "seek": 97488, "start": 983.04, "end": 987.4399999999999, "text": " the shapers scenarios. Clients and servers are really simple. You just mentioned which", "tokens": [264, 6706, 433, 15077, 13, 2033, 2448, 293, 15909, 366, 534, 2199, 13, 509, 445, 2835, 597], "temperature": 0.0, "avg_logprob": -0.17607535602890442, "compression_ratio": 1.7125984251968505, "no_speech_prob": 6.86144339852035e-05}, {"id": 183, "seek": 97488, "start": 987.4399999999999, "end": 992.08, "text": " one you want to use. But for shapers we have a more complicated setup. The idea behind", "tokens": [472, 291, 528, 281, 764, 13, 583, 337, 6706, 433, 321, 362, 257, 544, 6179, 8657, 13, 440, 1558, 2261], "temperature": 0.0, "avg_logprob": -0.17607535602890442, "compression_ratio": 1.7125984251968505, "no_speech_prob": 6.86144339852035e-05}, {"id": 184, "seek": 97488, "start": 992.08, "end": 995.6, "text": " the shapers is that it actually entails one kind of shaping. For example, you can use", "tokens": [264, 6706, 433, 307, 300, 309, 767, 50133, 472, 733, 295, 25945, 13, 1171, 1365, 11, 291, 393, 764], "temperature": 0.0, "avg_logprob": -0.17607535602890442, "compression_ratio": 1.7125984251968505, "no_speech_prob": 6.86144339852035e-05}, {"id": 185, "seek": 97488, "start": 995.6, "end": 1001.76, "text": " a TC-netum shaper within one container. But this one container does not only do one kind", "tokens": [257, 34150, 12, 7129, 449, 402, 2332, 1951, 472, 10129, 13, 583, 341, 472, 10129, 775, 406, 787, 360, 472, 733], "temperature": 0.0, "avg_logprob": -0.17607535602890442, "compression_ratio": 1.7125984251968505, "no_speech_prob": 6.86144339852035e-05}, {"id": 186, "seek": 100176, "start": 1001.76, "end": 1005.6, "text": " of shaping. The idea is that you can define multiple scenarios within this container and", "tokens": [295, 25945, 13, 440, 1558, 307, 300, 291, 393, 6964, 3866, 15077, 1951, 341, 10129, 293], "temperature": 0.0, "avg_logprob": -0.13913450146665668, "compression_ratio": 1.7272727272727273, "no_speech_prob": 4.408048698678613e-05}, {"id": 187, "seek": 100176, "start": 1005.6, "end": 1012.24, "text": " by passing through the scenario key you can actually pick which one is used during a test.", "tokens": [538, 8437, 807, 264, 9005, 2141, 291, 393, 767, 1888, 597, 472, 307, 1143, 1830, 257, 1500, 13], "temperature": 0.0, "avg_logprob": -0.13913450146665668, "compression_ratio": 1.7272727272727273, "no_speech_prob": 4.408048698678613e-05}, {"id": 188, "seek": 100176, "start": 1012.24, "end": 1016.68, "text": " In this use case we have one client, two shapers and three servers which means that we will", "tokens": [682, 341, 764, 1389, 321, 362, 472, 6423, 11, 732, 6706, 433, 293, 1045, 15909, 597, 1355, 300, 321, 486], "temperature": 0.0, "avg_logprob": -0.13913450146665668, "compression_ratio": 1.7272727272727273, "no_speech_prob": 4.408048698678613e-05}, {"id": 189, "seek": 100176, "start": 1016.68, "end": 1022.08, "text": " have a total of six test cases that will get generated and compiled by the framework and", "tokens": [362, 257, 3217, 295, 2309, 1500, 3331, 300, 486, 483, 10833, 293, 36548, 538, 264, 8388, 293], "temperature": 0.0, "avg_logprob": -0.13913450146665668, "compression_ratio": 1.7272727272727273, "no_speech_prob": 4.408048698678613e-05}, {"id": 190, "seek": 100176, "start": 1022.08, "end": 1028.68, "text": " run sequentially one after the other. I mentioned sensors earlier. That is also a configuration", "tokens": [1190, 5123, 3137, 472, 934, 264, 661, 13, 286, 2835, 14840, 3071, 13, 663, 307, 611, 257, 11694], "temperature": 0.0, "avg_logprob": -0.13913450146665668, "compression_ratio": 1.7272727272727273, "no_speech_prob": 4.408048698678613e-05}, {"id": 191, "seek": 102868, "start": 1028.68, "end": 1033.1200000000001, "text": " you can do with the experiment configuration files. The idea is normally that the framework", "tokens": [291, 393, 360, 365, 264, 5120, 11694, 7098, 13, 440, 1558, 307, 5646, 300, 264, 8388], "temperature": 0.0, "avg_logprob": -0.1551962632399339, "compression_ratio": 1.6308243727598566, "no_speech_prob": 5.912869892199524e-05}, {"id": 192, "seek": 102868, "start": 1033.1200000000001, "end": 1037.64, "text": " just automates all these tests and that when a client exits this should signal like the", "tokens": [445, 3553, 1024, 439, 613, 6921, 293, 300, 562, 257, 6423, 44183, 341, 820, 6358, 411, 264], "temperature": 0.0, "avg_logprob": -0.1551962632399339, "compression_ratio": 1.6308243727598566, "no_speech_prob": 5.912869892199524e-05}, {"id": 193, "seek": 102868, "start": 1037.64, "end": 1043.64, "text": " end of the test. However, in certain circumstances it is not possible. For example, if you use", "tokens": [917, 295, 264, 1500, 13, 2908, 11, 294, 1629, 9121, 309, 307, 406, 1944, 13, 1171, 1365, 11, 498, 291, 764], "temperature": 0.0, "avg_logprob": -0.1551962632399339, "compression_ratio": 1.6308243727598566, "no_speech_prob": 5.912869892199524e-05}, {"id": 194, "seek": 102868, "start": 1043.64, "end": 1049.0, "text": " a browser, well, it is obvious that browsers do not have the ability to shut down from", "tokens": [257, 11185, 11, 731, 11, 309, 307, 6322, 300, 36069, 360, 406, 362, 264, 3485, 281, 5309, 760, 490], "temperature": 0.0, "avg_logprob": -0.1551962632399339, "compression_ratio": 1.6308243727598566, "no_speech_prob": 5.912869892199524e-05}, {"id": 195, "seek": 102868, "start": 1049.0, "end": 1054.5600000000002, "text": " within a web page which would pose some security risks. Which is why we built a sensor system", "tokens": [1951, 257, 3670, 3028, 597, 576, 10774, 512, 3825, 10888, 13, 3013, 307, 983, 321, 3094, 257, 10200, 1185], "temperature": 0.0, "avg_logprob": -0.1551962632399339, "compression_ratio": 1.6308243727598566, "no_speech_prob": 5.912869892199524e-05}, {"id": 196, "seek": 105456, "start": 1054.56, "end": 1061.24, "text": " which can actually govern what happens within a client. For example, we provide two simple", "tokens": [597, 393, 767, 1980, 437, 2314, 1951, 257, 6423, 13, 1171, 1365, 11, 321, 2893, 732, 2199], "temperature": 0.0, "avg_logprob": -0.1510802364349365, "compression_ratio": 1.735632183908046, "no_speech_prob": 4.285725663066842e-05}, {"id": 197, "seek": 105456, "start": 1061.24, "end": 1066.32, "text": " sensor setups, time mode, which simply checks if a certain amount of time has passed and", "tokens": [10200, 46832, 11, 565, 4391, 11, 597, 2935, 13834, 498, 257, 1629, 2372, 295, 565, 575, 4678, 293], "temperature": 0.0, "avg_logprob": -0.1510802364349365, "compression_ratio": 1.735632183908046, "no_speech_prob": 4.285725663066842e-05}, {"id": 198, "seek": 105456, "start": 1066.32, "end": 1071.48, "text": " then closes the client and signals that the test case has ended. Another one that we built", "tokens": [550, 24157, 264, 6423, 293, 12354, 300, 264, 1500, 1389, 575, 4590, 13, 3996, 472, 300, 321, 3094], "temperature": 0.0, "avg_logprob": -0.1510802364349365, "compression_ratio": 1.735632183908046, "no_speech_prob": 4.285725663066842e-05}, {"id": 199, "seek": 105456, "start": 1071.48, "end": 1078.28, "text": " is the browser file watchdog sensor which enables us to check if certain files were downloaded", "tokens": [307, 264, 11185, 3991, 1159, 14833, 10200, 597, 17077, 505, 281, 1520, 498, 1629, 7098, 645, 21748], "temperature": 0.0, "avg_logprob": -0.1510802364349365, "compression_ratio": 1.735632183908046, "no_speech_prob": 4.285725663066842e-05}, {"id": 200, "seek": 105456, "start": 1078.28, "end": 1082.8799999999999, "text": " by a browser context. This enables us to pull metrics from the browser and also signify", "tokens": [538, 257, 11185, 4319, 13, 639, 17077, 505, 281, 2235, 16367, 490, 264, 11185, 293, 611, 1465, 2505], "temperature": 0.0, "avg_logprob": -0.1510802364349365, "compression_ratio": 1.735632183908046, "no_speech_prob": 4.285725663066842e-05}, {"id": 201, "seek": 108288, "start": 1082.88, "end": 1089.24, "text": " the end of a test. If you provide these two configuration files to the framework, the", "tokens": [264, 917, 295, 257, 1500, 13, 759, 291, 2893, 613, 732, 11694, 7098, 281, 264, 8388, 11, 264], "temperature": 0.0, "avg_logprob": -0.15634339542712195, "compression_ratio": 1.7946127946127945, "no_speech_prob": 5.8077508583664894e-05}, {"id": 202, "seek": 108288, "start": 1089.24, "end": 1093.0400000000002, "text": " framework will spin up a nice story. On the bottom you can see which tests are happening,", "tokens": [8388, 486, 6060, 493, 257, 1481, 1657, 13, 1282, 264, 2767, 291, 393, 536, 597, 6921, 366, 2737, 11], "temperature": 0.0, "avg_logprob": -0.15634339542712195, "compression_ratio": 1.7946127946127945, "no_speech_prob": 5.8077508583664894e-05}, {"id": 203, "seek": 108288, "start": 1093.0400000000002, "end": 1096.68, "text": " how much time has passed. You can see a little bit of packet spossing between them, signaling", "tokens": [577, 709, 565, 575, 4678, 13, 509, 393, 536, 257, 707, 857, 295, 20300, 637, 35652, 1296, 552, 11, 38639], "temperature": 0.0, "avg_logprob": -0.15634339542712195, "compression_ratio": 1.7946127946127945, "no_speech_prob": 5.8077508583664894e-05}, {"id": 204, "seek": 108288, "start": 1096.68, "end": 1101.6000000000001, "text": " that some kind of traffic is happening. You can actually increase the verbosity, but this", "tokens": [300, 512, 733, 295, 6419, 307, 2737, 13, 509, 393, 767, 3488, 264, 9595, 20373, 11, 457, 341], "temperature": 0.0, "avg_logprob": -0.15634339542712195, "compression_ratio": 1.7946127946127945, "no_speech_prob": 5.8077508583664894e-05}, {"id": 205, "seek": 108288, "start": 1101.6000000000001, "end": 1106.64, "text": " is not necessarily needed from within the terminal as the framework automatically saves", "tokens": [307, 406, 4725, 2978, 490, 1951, 264, 14709, 382, 264, 8388, 6772, 19155], "temperature": 0.0, "avg_logprob": -0.15634339542712195, "compression_ratio": 1.7946127946127945, "no_speech_prob": 5.8077508583664894e-05}, {"id": 206, "seek": 108288, "start": 1106.64, "end": 1111.0, "text": " everything that happens as output in a file within the test case folders that we will", "tokens": [1203, 300, 2314, 382, 5598, 294, 257, 3991, 1951, 264, 1500, 1389, 31082, 300, 321, 486], "temperature": 0.0, "avg_logprob": -0.15634339542712195, "compression_ratio": 1.7946127946127945, "no_speech_prob": 5.8077508583664894e-05}, {"id": 207, "seek": 111100, "start": 1111.0, "end": 1117.36, "text": " now discuss. The experiment output is always saved under the label that is provided with", "tokens": [586, 2248, 13, 440, 5120, 5598, 307, 1009, 6624, 833, 264, 7645, 300, 307, 5649, 365], "temperature": 0.0, "avg_logprob": -0.14368647525185033, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.00010604262934066355}, {"id": 208, "seek": 111100, "start": 1117.36, "end": 1123.12, "text": " an experiment configuration because we can have multiple runs of an experiment. The first", "tokens": [364, 5120, 11694, 570, 321, 393, 362, 3866, 6676, 295, 364, 5120, 13, 440, 700], "temperature": 0.0, "avg_logprob": -0.14368647525185033, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.00010604262934066355}, {"id": 209, "seek": 111100, "start": 1123.12, "end": 1128.12, "text": " entries that you will find within such a folder are actually time stamped to signify multiple", "tokens": [23041, 300, 291, 486, 915, 1951, 1270, 257, 10820, 366, 767, 565, 39111, 281, 1465, 2505, 3866], "temperature": 0.0, "avg_logprob": -0.14368647525185033, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.00010604262934066355}, {"id": 210, "seek": 111100, "start": 1128.12, "end": 1133.92, "text": " runs. If you enter that, you will actually find the different folders that contain the", "tokens": [6676, 13, 759, 291, 3242, 300, 11, 291, 486, 767, 915, 264, 819, 31082, 300, 5304, 264], "temperature": 0.0, "avg_logprob": -0.14368647525185033, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.00010604262934066355}, {"id": 211, "seek": 111100, "start": 1133.92, "end": 1138.2, "text": " data of the multiple test cases that were compiled by the framework. If you take a dive", "tokens": [1412, 295, 264, 3866, 1500, 3331, 300, 645, 36548, 538, 264, 8388, 13, 759, 291, 747, 257, 9192], "temperature": 0.0, "avg_logprob": -0.14368647525185033, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.00010604262934066355}, {"id": 212, "seek": 113820, "start": 1138.2, "end": 1143.28, "text": " into one of these folders, you can see what output we are collecting in these cases. By", "tokens": [666, 472, 295, 613, 31082, 11, 291, 393, 536, 437, 5598, 321, 366, 12510, 294, 613, 3331, 13, 3146], "temperature": 0.0, "avg_logprob": -0.14855273564656576, "compression_ratio": 1.7054263565891472, "no_speech_prob": 4.2861149267992005e-05}, {"id": 213, "seek": 113820, "start": 1143.28, "end": 1150.68, "text": " default, the framework will always create a server, client and shaper folder which get", "tokens": [7576, 11, 264, 8388, 486, 1009, 1884, 257, 7154, 11, 6423, 293, 402, 2332, 10820, 597, 483], "temperature": 0.0, "avg_logprob": -0.14855273564656576, "compression_ratio": 1.7054263565891472, "no_speech_prob": 4.2861149267992005e-05}, {"id": 214, "seek": 113820, "start": 1150.68, "end": 1156.28, "text": " automatically mounted on the Docker volumes under the slash logs directory. Anything the", "tokens": [6772, 19138, 322, 264, 33772, 22219, 833, 264, 17330, 20820, 21120, 13, 11998, 264], "temperature": 0.0, "avg_logprob": -0.14855273564656576, "compression_ratio": 1.7054263565891472, "no_speech_prob": 4.2861149267992005e-05}, {"id": 215, "seek": 113820, "start": 1156.28, "end": 1160.24, "text": " implementations want to save, they can just write files to this directory and the framework", "tokens": [4445, 763, 528, 281, 3155, 11, 436, 393, 445, 2464, 7098, 281, 341, 21120, 293, 264, 8388], "temperature": 0.0, "avg_logprob": -0.14855273564656576, "compression_ratio": 1.7054263565891472, "no_speech_prob": 4.2861149267992005e-05}, {"id": 216, "seek": 113820, "start": 1160.24, "end": 1165.1200000000001, "text": " will capture this and save this to in the log files. Additionally, clients also have", "tokens": [486, 7983, 341, 293, 3155, 341, 281, 294, 264, 3565, 7098, 13, 19927, 11, 6982, 611, 362], "temperature": 0.0, "avg_logprob": -0.14855273564656576, "compression_ratio": 1.7054263565891472, "no_speech_prob": 4.2861149267992005e-05}, {"id": 217, "seek": 116512, "start": 1165.12, "end": 1169.6799999999998, "text": " a downloads folder mounted simply because we want to differentiate and not come into", "tokens": [257, 36553, 10820, 19138, 2935, 570, 321, 528, 281, 23203, 293, 406, 808, 666], "temperature": 0.0, "avg_logprob": -0.15962020796958845, "compression_ratio": 1.5971731448763251, "no_speech_prob": 2.9542203265009448e-05}, {"id": 218, "seek": 116512, "start": 1169.6799999999998, "end": 1176.9599999999998, "text": " a situation where downloads accidentally override output logs generated by a client. You can", "tokens": [257, 2590, 689, 36553, 15715, 42321, 5598, 20820, 10833, 538, 257, 6423, 13, 509, 393], "temperature": 0.0, "avg_logprob": -0.15962020796958845, "compression_ratio": 1.5971731448763251, "no_speech_prob": 2.9542203265009448e-05}, {"id": 219, "seek": 116512, "start": 1176.9599999999998, "end": 1182.4799999999998, "text": " also see that we have, especially under the server and client entries, you can see keys.log", "tokens": [611, 536, 300, 321, 362, 11, 2318, 833, 264, 7154, 293, 6423, 23041, 11, 291, 393, 536, 9317, 13, 4987], "temperature": 0.0, "avg_logprob": -0.15962020796958845, "compression_ratio": 1.5971731448763251, "no_speech_prob": 2.9542203265009448e-05}, {"id": 220, "seek": 116512, "start": 1182.4799999999998, "end": 1189.4399999999998, "text": " and a Qlog folder. The framework is automatically primed to save these encryption details and", "tokens": [293, 257, 1249, 4987, 10820, 13, 440, 8388, 307, 6772, 2886, 292, 281, 3155, 613, 29575, 4365, 293], "temperature": 0.0, "avg_logprob": -0.15962020796958845, "compression_ratio": 1.5971731448763251, "no_speech_prob": 2.9542203265009448e-05}, {"id": 221, "seek": 116512, "start": 1189.4399999999998, "end": 1194.32, "text": " what's happening at the quick and HTTP tree layers by setting the SSL Qlog file which we", "tokens": [437, 311, 2737, 412, 264, 1702, 293, 33283, 4230, 7914, 538, 3287, 264, 12238, 43, 1249, 4987, 3991, 597, 321], "temperature": 0.0, "avg_logprob": -0.15962020796958845, "compression_ratio": 1.5971731448763251, "no_speech_prob": 2.9542203265009448e-05}, {"id": 222, "seek": 119432, "start": 1194.32, "end": 1200.6, "text": " discussed in the beginning but also by setting a Qlog environment variable which gets recognized", "tokens": [7152, 294, 264, 2863, 457, 611, 538, 3287, 257, 1249, 4987, 2823, 7006, 597, 2170, 9823], "temperature": 0.0, "avg_logprob": -0.12485122680664062, "compression_ratio": 1.5103734439834025, "no_speech_prob": 3.168448165524751e-05}, {"id": 223, "seek": 119432, "start": 1200.6, "end": 1207.6799999999998, "text": " by most quick implementations out there nowadays. Finally, we come to extensibility. At this", "tokens": [538, 881, 1702, 4445, 763, 484, 456, 13434, 13, 6288, 11, 321, 808, 281, 1279, 694, 2841, 13, 1711, 341], "temperature": 0.0, "avg_logprob": -0.12485122680664062, "compression_ratio": 1.5103734439834025, "no_speech_prob": 3.168448165524751e-05}, {"id": 224, "seek": 119432, "start": 1207.6799999999998, "end": 1213.6399999999999, "text": " point in time, we have a framework that is great at aggregating a lot of data. We did", "tokens": [935, 294, 565, 11, 321, 362, 257, 8388, 300, 307, 869, 412, 16743, 990, 257, 688, 295, 1412, 13, 492, 630], "temperature": 0.0, "avg_logprob": -0.12485122680664062, "compression_ratio": 1.5103734439834025, "no_speech_prob": 3.168448165524751e-05}, {"id": 225, "seek": 119432, "start": 1213.6399999999999, "end": 1220.6399999999999, "text": " some tests that ran for two or three days straight containing more than 8,000 test cases", "tokens": [512, 6921, 300, 5872, 337, 732, 420, 1045, 1708, 2997, 19273, 544, 813, 1649, 11, 1360, 1500, 3331], "temperature": 0.0, "avg_logprob": -0.12485122680664062, "compression_ratio": 1.5103734439834025, "no_speech_prob": 3.168448165524751e-05}, {"id": 226, "seek": 122064, "start": 1220.64, "end": 1224.88, "text": " which were great if you want to gather a lot of data. But what makes a testing framework,", "tokens": [597, 645, 869, 498, 291, 528, 281, 5448, 257, 688, 295, 1412, 13, 583, 437, 1669, 257, 4997, 8388, 11], "temperature": 0.0, "avg_logprob": -0.17615512847900391, "compression_ratio": 1.7935222672064777, "no_speech_prob": 6.068326911190525e-05}, {"id": 227, "seek": 122064, "start": 1224.88, "end": 1230.16, "text": " a testing framework, is the actual ability to infer something from the output generated", "tokens": [257, 4997, 8388, 11, 307, 264, 3539, 3485, 281, 13596, 746, 490, 264, 5598, 10833], "temperature": 0.0, "avg_logprob": -0.17615512847900391, "compression_ratio": 1.7935222672064777, "no_speech_prob": 6.068326911190525e-05}, {"id": 228, "seek": 122064, "start": 1230.16, "end": 1235.2800000000002, "text": " by a test which is why we provide these two programmable interfaces called sensors and", "tokens": [538, 257, 1500, 597, 307, 983, 321, 2893, 613, 732, 37648, 712, 28416, 1219, 14840, 293], "temperature": 0.0, "avg_logprob": -0.17615512847900391, "compression_ratio": 1.7935222672064777, "no_speech_prob": 6.068326911190525e-05}, {"id": 229, "seek": 122064, "start": 1235.2800000000002, "end": 1239.88, "text": " hooks. I explain sensors a little bit. We provide some basic sensors but you actually", "tokens": [26485, 13, 286, 2903, 14840, 257, 707, 857, 13, 492, 2893, 512, 3875, 14840, 457, 291, 767], "temperature": 0.0, "avg_logprob": -0.17615512847900391, "compression_ratio": 1.7935222672064777, "no_speech_prob": 6.068326911190525e-05}, {"id": 230, "seek": 122064, "start": 1239.88, "end": 1245.96, "text": " also have the ability to program custom sensors. This makes a lot of sense if you want to do", "tokens": [611, 362, 264, 3485, 281, 1461, 2375, 14840, 13, 639, 1669, 257, 688, 295, 2020, 498, 291, 528, 281, 360], "temperature": 0.0, "avg_logprob": -0.17615512847900391, "compression_ratio": 1.7935222672064777, "no_speech_prob": 6.068326911190525e-05}, {"id": 231, "seek": 124596, "start": 1245.96, "end": 1251.92, "text": " very specific or test for very specific behavior within your experiment. For example, if you", "tokens": [588, 2685, 420, 1500, 337, 588, 2685, 5223, 1951, 428, 5120, 13, 1171, 1365, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.13588830090444023, "compression_ratio": 1.7538461538461538, "no_speech_prob": 9.87981547950767e-05}, {"id": 232, "seek": 124596, "start": 1251.92, "end": 1257.08, "text": " are doing a video stream in the browser, you can actually send the decoding metrics of", "tokens": [366, 884, 257, 960, 4309, 294, 264, 11185, 11, 291, 393, 767, 2845, 264, 979, 8616, 16367, 295], "temperature": 0.0, "avg_logprob": -0.13588830090444023, "compression_ratio": 1.7538461538461538, "no_speech_prob": 9.87981547950767e-05}, {"id": 233, "seek": 124596, "start": 1257.08, "end": 1262.8, "text": " the video out of band to an HTTP endpoint, for example, that you set up in a custom sensor.", "tokens": [264, 960, 484, 295, 4116, 281, 364, 33283, 35795, 11, 337, 1365, 11, 300, 291, 992, 493, 294, 257, 2375, 10200, 13], "temperature": 0.0, "avg_logprob": -0.13588830090444023, "compression_ratio": 1.7538461538461538, "no_speech_prob": 9.87981547950767e-05}, {"id": 234, "seek": 124596, "start": 1262.8, "end": 1267.64, "text": " If the sensor, for example, detects that some frames are being dropped or decoded in a wrong", "tokens": [759, 264, 10200, 11, 337, 1365, 11, 5531, 82, 300, 512, 12083, 366, 885, 8119, 420, 979, 12340, 294, 257, 2085], "temperature": 0.0, "avg_logprob": -0.13588830090444023, "compression_ratio": 1.7538461538461538, "no_speech_prob": 9.87981547950767e-05}, {"id": 235, "seek": 124596, "start": 1267.64, "end": 1272.68, "text": " way, it could prematurely hold a test signaling that something went wrong. If you have lots", "tokens": [636, 11, 309, 727, 34877, 356, 1797, 257, 1500, 38639, 300, 746, 1437, 2085, 13, 759, 291, 362, 3195], "temperature": 0.0, "avg_logprob": -0.13588830090444023, "compression_ratio": 1.7538461538461538, "no_speech_prob": 9.87981547950767e-05}, {"id": 236, "seek": 127268, "start": 1272.68, "end": 1277.44, "text": " of test cases like we do, we actually have test cases like I just said, running 48 hours,", "tokens": [295, 1500, 3331, 411, 321, 360, 11, 321, 767, 362, 1500, 3331, 411, 286, 445, 848, 11, 2614, 11174, 2496, 11], "temperature": 0.0, "avg_logprob": -0.15322961073655347, "compression_ratio": 1.7656765676567656, "no_speech_prob": 9.206257527694106e-05}, {"id": 237, "seek": 127268, "start": 1277.44, "end": 1281.76, "text": " this is really beneficial because it holds the test in an early phase, saving us a lot", "tokens": [341, 307, 534, 14072, 570, 309, 9190, 264, 1500, 294, 364, 2440, 5574, 11, 6816, 505, 257, 688], "temperature": 0.0, "avg_logprob": -0.15322961073655347, "compression_ratio": 1.7656765676567656, "no_speech_prob": 9.206257527694106e-05}, {"id": 238, "seek": 127268, "start": 1281.76, "end": 1286.78, "text": " of time. On the other hand, we have the hook system. So the framework currently is very", "tokens": [295, 565, 13, 1282, 264, 661, 1011, 11, 321, 362, 264, 6328, 1185, 13, 407, 264, 8388, 4362, 307, 588], "temperature": 0.0, "avg_logprob": -0.15322961073655347, "compression_ratio": 1.7656765676567656, "no_speech_prob": 9.206257527694106e-05}, {"id": 239, "seek": 127268, "start": 1286.78, "end": 1291.8, "text": " broadly applicable. The downside of that is that we don't really know what's happening", "tokens": [19511, 21142, 13, 440, 25060, 295, 300, 307, 300, 321, 500, 380, 534, 458, 437, 311, 2737], "temperature": 0.0, "avg_logprob": -0.15322961073655347, "compression_ratio": 1.7656765676567656, "no_speech_prob": 9.206257527694106e-05}, {"id": 240, "seek": 127268, "start": 1291.8, "end": 1296.8400000000001, "text": " inside the test. But you can actually program some custom behavior through the pre-run hook", "tokens": [1854, 264, 1500, 13, 583, 291, 393, 767, 1461, 512, 2375, 5223, 807, 264, 659, 12, 12997, 6328], "temperature": 0.0, "avg_logprob": -0.15322961073655347, "compression_ratio": 1.7656765676567656, "no_speech_prob": 9.206257527694106e-05}, {"id": 241, "seek": 127268, "start": 1296.8400000000001, "end": 1302.3600000000001, "text": " and post-run hook system. As the name suggests, the pre-run hook runs before an actual test", "tokens": [293, 2183, 12, 12997, 6328, 1185, 13, 1018, 264, 1315, 13409, 11, 264, 659, 12, 12997, 6328, 6676, 949, 364, 3539, 1500], "temperature": 0.0, "avg_logprob": -0.15322961073655347, "compression_ratio": 1.7656765676567656, "no_speech_prob": 9.206257527694106e-05}, {"id": 242, "seek": 130236, "start": 1302.36, "end": 1308.52, "text": " is run. So you can prime environments by, for example, generating some dynamic files", "tokens": [307, 1190, 13, 407, 291, 393, 5835, 12388, 538, 11, 337, 1365, 11, 17746, 512, 8546, 7098], "temperature": 0.0, "avg_logprob": -0.13869374341303758, "compression_ratio": 1.7244094488188977, "no_speech_prob": 7.30156316421926e-05}, {"id": 243, "seek": 130236, "start": 1308.52, "end": 1313.56, "text": " that you will need during the experiment. It doesn't really matter what you want to do", "tokens": [300, 291, 486, 643, 1830, 264, 5120, 13, 467, 1177, 380, 534, 1871, 437, 291, 528, 281, 360], "temperature": 0.0, "avg_logprob": -0.13869374341303758, "compression_ratio": 1.7244094488188977, "no_speech_prob": 7.30156316421926e-05}, {"id": 244, "seek": 130236, "start": 1313.56, "end": 1317.84, "text": " there. The post-run hook is really nice because you can use it to analyze whatever happened", "tokens": [456, 13, 440, 2183, 12, 12997, 6328, 307, 534, 1481, 570, 291, 393, 764, 309, 281, 12477, 2035, 2011], "temperature": 0.0, "avg_logprob": -0.13869374341303758, "compression_ratio": 1.7244094488188977, "no_speech_prob": 7.30156316421926e-05}, {"id": 245, "seek": 130236, "start": 1317.84, "end": 1322.56, "text": " during a test. For example, you could, if queue logs are being generated, look at the", "tokens": [1830, 257, 1500, 13, 1171, 1365, 11, 291, 727, 11, 498, 18639, 20820, 366, 885, 10833, 11, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.13869374341303758, "compression_ratio": 1.7244094488188977, "no_speech_prob": 7.30156316421926e-05}, {"id": 246, "seek": 130236, "start": 1322.56, "end": 1327.32, "text": " queue logs and maybe even generate some nice graphs that you can immediately check after", "tokens": [18639, 20820, 293, 1310, 754, 8460, 512, 1481, 24877, 300, 291, 393, 4258, 1520, 934], "temperature": 0.0, "avg_logprob": -0.13869374341303758, "compression_ratio": 1.7244094488188977, "no_speech_prob": 7.30156316421926e-05}, {"id": 247, "seek": 132732, "start": 1327.32, "end": 1334.1599999999999, "text": " a test case has ended. Right. Another thing I need to mention with the pre-run hook and", "tokens": [257, 1500, 1389, 575, 4590, 13, 1779, 13, 3996, 551, 286, 643, 281, 2152, 365, 264, 659, 12, 12997, 6328, 293], "temperature": 0.0, "avg_logprob": -0.13266408226706766, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.00011271719995420426}, {"id": 248, "seek": 132732, "start": 1334.1599999999999, "end": 1337.96, "text": " the post-run hook, if you don't like programming in Python, it's not really a problem. Python", "tokens": [264, 2183, 12, 12997, 6328, 11, 498, 291, 500, 380, 411, 9410, 294, 15329, 11, 309, 311, 406, 534, 257, 1154, 13, 15329], "temperature": 0.0, "avg_logprob": -0.13266408226706766, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.00011271719995420426}, {"id": 249, "seek": 132732, "start": 1337.96, "end": 1344.6799999999998, "text": " has this really great submodule called subprocesses. If you have some existing scripts that are", "tokens": [575, 341, 534, 869, 1422, 8014, 2271, 1219, 1422, 41075, 279, 13, 759, 291, 362, 512, 6741, 23294, 300, 366], "temperature": 0.0, "avg_logprob": -0.13266408226706766, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.00011271719995420426}, {"id": 250, "seek": 132732, "start": 1344.6799999999998, "end": 1348.6799999999998, "text": " made to work with the output produced by your experiment, you can simply call them also from", "tokens": [1027, 281, 589, 365, 264, 5598, 7126, 538, 428, 5120, 11, 291, 393, 2935, 818, 552, 611, 490], "temperature": 0.0, "avg_logprob": -0.13266408226706766, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.00011271719995420426}, {"id": 251, "seek": 132732, "start": 1348.6799999999998, "end": 1353.24, "text": " this hook, meaning that you get exactly the same results without having to actually translate", "tokens": [341, 6328, 11, 3620, 300, 291, 483, 2293, 264, 912, 3542, 1553, 1419, 281, 767, 13799], "temperature": 0.0, "avg_logprob": -0.13266408226706766, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.00011271719995420426}, {"id": 252, "seek": 135324, "start": 1353.24, "end": 1361.4, "text": " your existing code within these provided hooks. Right. That's in a nutshell what Vekvizir", "tokens": [428, 6741, 3089, 1951, 613, 5649, 26485, 13, 1779, 13, 663, 311, 294, 257, 37711, 437, 691, 916, 85, 590, 347], "temperature": 0.0, "avg_logprob": -0.34602535247802735, "compression_ratio": 1.3120567375886525, "no_speech_prob": 0.0003416136314626783}, {"id": 253, "seek": 135324, "start": 1361.4, "end": 1365.4, "text": " does. Thank you for your attention. And I think we have a couple of minutes left for", "tokens": [775, 13, 1044, 291, 337, 428, 3202, 13, 400, 286, 519, 321, 362, 257, 1916, 295, 2077, 1411, 337], "temperature": 0.0, "avg_logprob": -0.34602535247802735, "compression_ratio": 1.3120567375886525, "no_speech_prob": 0.0003416136314626783}, {"id": 254, "seek": 135324, "start": 1365.4, "end": 1366.4, "text": " questions.", "tokens": [1651, 13], "temperature": 0.0, "avg_logprob": -0.34602535247802735, "compression_ratio": 1.3120567375886525, "no_speech_prob": 0.0003416136314626783}, {"id": 255, "seek": 136640, "start": 1366.4, "end": 1385.76, "text": " Yeah. So, a test case can be anything you want. If you have, like, if you're programming", "tokens": [865, 13, 407, 11, 257, 1500, 1389, 393, 312, 1340, 291, 528, 13, 759, 291, 362, 11, 411, 11, 498, 291, 434, 9410], "temperature": 0.0, "avg_logprob": -0.1662062406539917, "compression_ratio": 1.4331550802139037, "no_speech_prob": 0.00031403565662913024}, {"id": 256, "seek": 136640, "start": 1385.76, "end": 1389.88, "text": " right now, you're developing something locally. The thing you need to do is actually wrap", "tokens": [558, 586, 11, 291, 434, 6416, 746, 16143, 13, 440, 551, 291, 643, 281, 360, 307, 767, 7019], "temperature": 0.0, "avg_logprob": -0.1662062406539917, "compression_ratio": 1.4331550802139037, "no_speech_prob": 0.00031403565662913024}, {"id": 257, "seek": 136640, "start": 1389.88, "end": 1394.4, "text": " it within a Docker container. That's one way. Or run it as a CLI command. You simply need", "tokens": [309, 1951, 257, 33772, 10129, 13, 663, 311, 472, 636, 13, 1610, 1190, 309, 382, 257, 12855, 40, 5622, 13, 509, 2935, 643], "temperature": 0.0, "avg_logprob": -0.1662062406539917, "compression_ratio": 1.4331550802139037, "no_speech_prob": 0.00031403565662913024}, {"id": 258, "seek": 139440, "start": 1394.4, "end": 1397.8400000000001, "text": " to provide it to the framework, and the framework will just spin it up. So, the framework doesn't", "tokens": [281, 2893, 309, 281, 264, 8388, 11, 293, 264, 8388, 486, 445, 6060, 309, 493, 13, 407, 11, 264, 8388, 1177, 380], "temperature": 0.0, "avg_logprob": -0.18537580555882946, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.0003979009052272886}, {"id": 259, "seek": 139440, "start": 1397.8400000000001, "end": 1402.5600000000002, "text": " actually check what your test case is doing. If you want to, like, spin up a simple, let's", "tokens": [767, 1520, 437, 428, 1500, 1389, 307, 884, 13, 759, 291, 528, 281, 11, 411, 11, 6060, 493, 257, 2199, 11, 718, 311], "temperature": 0.0, "avg_logprob": -0.18537580555882946, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.0003979009052272886}, {"id": 260, "seek": 139440, "start": 1402.5600000000002, "end": 1407.5600000000002, "text": " say, CLI command, like, echo, and you want to print something to the terminal, you simply", "tokens": [584, 11, 12855, 40, 5622, 11, 411, 11, 14300, 11, 293, 291, 528, 281, 4482, 746, 281, 264, 14709, 11, 291, 2935], "temperature": 0.0, "avg_logprob": -0.18537580555882946, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.0003979009052272886}, {"id": 261, "seek": 139440, "start": 1407.5600000000002, "end": 1410.5600000000002, "text": " put it in the JSON, it will run.", "tokens": [829, 309, 294, 264, 31828, 11, 309, 486, 1190, 13], "temperature": 0.0, "avg_logprob": -0.18537580555882946, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.0003979009052272886}, {"id": 262, "seek": 141056, "start": 1410.56, "end": 1430.56, "text": " So, more questions, please. We have a couple of minutes. Okay. I have a question. I see", "tokens": [407, 11, 544, 1651, 11, 1767, 13, 492, 362, 257, 1916, 295, 2077, 13, 1033, 13, 286, 362, 257, 1168, 13, 286, 536], "temperature": 0.0, "avg_logprob": -0.38141194979349774, "compression_ratio": 1.380952380952381, "no_speech_prob": 0.00022907694801688194}, {"id": 263, "seek": 141056, "start": 1430.56, "end": 1435.56, "text": " you're from university. What does university have to do with testing, like, what's the", "tokens": [291, 434, 490, 5454, 13, 708, 775, 5454, 362, 281, 360, 365, 4997, 11, 411, 11, 437, 311, 264], "temperature": 0.0, "avg_logprob": -0.38141194979349774, "compression_ratio": 1.380952380952381, "no_speech_prob": 0.00022907694801688194}, {"id": 264, "seek": 143556, "start": 1435.56, "end": 1442.28, "text": " question? Okay. So, good question, actually. I'm not sure if there is a direct relationship", "tokens": [1168, 30, 1033, 13, 407, 11, 665, 1168, 11, 767, 13, 286, 478, 406, 988, 498, 456, 307, 257, 2047, 2480], "temperature": 0.0, "avg_logprob": -0.18144173092312282, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.0001547137217130512}, {"id": 265, "seek": 143556, "start": 1442.28, "end": 1449.84, "text": " with testing in the university. It's just that, like, during my PhD, and also the PhD", "tokens": [365, 4997, 294, 264, 5454, 13, 467, 311, 445, 300, 11, 411, 11, 1830, 452, 14476, 11, 293, 611, 264, 14476], "temperature": 0.0, "avg_logprob": -0.18144173092312282, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.0001547137217130512}, {"id": 266, "seek": 143556, "start": 1449.84, "end": 1456.76, "text": " of some of my colleagues here in front of me, we actually encountered that we had a need", "tokens": [295, 512, 295, 452, 7734, 510, 294, 1868, 295, 385, 11, 321, 767, 20381, 300, 321, 632, 257, 643], "temperature": 0.0, "avg_logprob": -0.18144173092312282, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.0001547137217130512}, {"id": 267, "seek": 143556, "start": 1456.76, "end": 1461.6399999999999, "text": " of such a framework, right? We had an actual need of spinning up multiple test cases and", "tokens": [295, 1270, 257, 8388, 11, 558, 30, 492, 632, 364, 3539, 643, 295, 15640, 493, 3866, 1500, 3331, 293], "temperature": 0.0, "avg_logprob": -0.18144173092312282, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.0001547137217130512}, {"id": 268, "seek": 146164, "start": 1461.64, "end": 1467.92, "text": " like, helping us with setting up these experiments, which is why we designed this. Early on, we", "tokens": [411, 11, 4315, 505, 365, 3287, 493, 613, 12050, 11, 597, 307, 983, 321, 4761, 341, 13, 18344, 322, 11, 321], "temperature": 0.0, "avg_logprob": -0.1551819873112504, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00014064721472095698}, {"id": 269, "seek": 146164, "start": 1467.92, "end": 1475.3600000000001, "text": " just had a very minimal thing that just worked for us. And then, as time progressed, it actually", "tokens": [445, 632, 257, 588, 13206, 551, 300, 445, 2732, 337, 505, 13, 400, 550, 11, 382, 565, 36789, 11, 309, 767], "temperature": 0.0, "avg_logprob": -0.1551819873112504, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00014064721472095698}, {"id": 270, "seek": 146164, "start": 1475.3600000000001, "end": 1479.2, "text": " became more and more mature, and we decided, well, this is actually a very good idea. So,", "tokens": [3062, 544, 293, 544, 14442, 11, 293, 321, 3047, 11, 731, 11, 341, 307, 767, 257, 588, 665, 1558, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.1551819873112504, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00014064721472095698}, {"id": 271, "seek": 146164, "start": 1479.2, "end": 1484.92, "text": " we created an open source project for it, and we actually also submitted it to a open source", "tokens": [321, 2942, 364, 1269, 4009, 1716, 337, 309, 11, 293, 321, 767, 611, 14405, 309, 281, 257, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.1551819873112504, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00014064721472095698}, {"id": 272, "seek": 148492, "start": 1484.92, "end": 1491.92, "text": " and data set track for the MMSIS conference, which is happening in June in Vancouver. So,", "tokens": [293, 1412, 992, 2837, 337, 264, 376, 10288, 2343, 7586, 11, 597, 307, 2737, 294, 6928, 294, 26563, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.3290882428487142, "compression_ratio": 1.392156862745098, "no_speech_prob": 0.00020503305131569505}, {"id": 273, "seek": 148492, "start": 1491.92, "end": 1506.92, "text": " okay. I think we have time for one more question. The last question. No thankers. So, thank", "tokens": [1392, 13, 286, 519, 321, 362, 565, 337, 472, 544, 1168, 13, 440, 1036, 1168, 13, 883, 1309, 433, 13, 407, 11, 1309], "temperature": 0.0, "avg_logprob": -0.3290882428487142, "compression_ratio": 1.392156862745098, "no_speech_prob": 0.00020503305131569505}, {"id": 274, "seek": 150692, "start": 1506.92, "end": 1516.92, "text": " you very much.", "tokens": [50364, 291, 588, 709, 13, 50864], "temperature": 0.0, "avg_logprob": -0.69519989831107, "compression_ratio": 0.6363636363636364, "no_speech_prob": 0.0003668663848657161}], "language": "en"}