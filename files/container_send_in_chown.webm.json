{"text": " Okay, then our next talk is by Frazier. Over to you. Okay. Thank you. So I'm going to talk about user namespaces and delegation of control of C groups in container orchestration systems. So yeah, containers and container standards. This is the containers dev room, I think, hopefully most people should have some idea. Talk about Kubernetes and OpenShift, user namespaces and C groups, and then a demo of a system B based workload on Kubernetes and more specifically OpenShift. So container is a process isolation and confinement abstraction. Most commonly it uses operating system level virtualization where the processes running in the container are using the same kernel as the host system. Examples of this include FreeBSD Jails and Solaris Zones as well as Linux containers. And the container image is not a container, the container image just defines the file system contents for a container and some metadata suggesting what process should be run, what user ID it should run underneath and so on. On Linux containers use a combination of the following technologies, so namespaces, process ID namespaces, mount namespaces, network namespaces, et cetera, to restrict what the process running in the container can see. The container may have restricted capabilities or a second profile that limits which system calls or operating system features it can use. There may be SE Linux or app armor confinement and it can use C groups for resource limits. Not necessarily all of these are used at the same time, it depends on the implementation. The OpenContainer initiative defines standards around containers in the free software ecosystem and its runtime specification in particular defines a low level runtime interface for containers that is not just for Linux containers but it defines the runtime semantics for Linux Solaris containers, Windows containers, virtual machines and so there are a bunch of implementations of the runtime spec including RunC, the reference implementation, CRUN and CART containers which is a virtual machine based container runtime. The OCI runtime spec has a JSON configuration and there's a link to an example, it defines or lets you define the mounts, what process to be executed, its environment, life cycle hooks so extra code to run when the container is created, destroyed, started, stopped and the Linux specific capabilities that can be controlled via the OCI runtime spec include the capabilities, that's the kernel feature capabilities, namespaces, the C group, the system controls that should be set for that container, the seccomp profile and so on. This is what an example runtime specification looks like, so it has a process structure which includes a field for the user ID and the group ID, it has this Linux structure which defines the Linux specific attributes for this container and one of those attributes is the namespaces list which defines a list of the different namespaces that should be used or should be newly created for that container. So Kubernetes is a container orchestration platform, has a declarative configuration system and it integrates with many different cloud providers. Anyone not know what Kubernetes is in the room? So the terminology in Kubernetes, the container is an isolated or confined process or process tree, a pod is one or more related containers that together constitute an application of some sort, so it might be an HTTP server and a database to encapsulate the entire web application. A namespace in Kubernetes terminology is not a namespace in Linux kernel terminology, a namespace is just an object scope and authorization scope for a bunch of objects in the Kubernetes data store, so if you have a particular team or project in your organization you might deploy all of the Kubernetes applications in a single namespace. And a node is a machine in the cluster where pods are executed, there are different kinds of nodes, there are control pane nodes, there are worker nodes where the actual business applications run. Kubelet is the agent that executes pods on nodes, so there's a scheduling system, the scheduler will, when a pod is created, decide what node that pod should run on and Kubelet is the agent on the node that takes the pod specification and turns it into a container running on that node. The Kubernetes terminology uses the term sandbox, that's an isolation or confinement mechanism, and there's one sandbox per pod, so there could be multiple containers running in the sandbox. And the container runtime interface defines how Kubelet actually starts and stops the containers for the sandboxes. So cryo is one implementation of the container runtime interface, that's what's used in OpenShift, there's also container d, that's used in some other distributions of Kubernetes. So visualizing this, the whole box is one Kubernetes node, the Kubelet has the gRPC client to talk to us CRI runtime, the CRI runtime does something and containers appear. So we could instantiate the container runtime interface implementation as cryo, and then we can see that cryo talks to an OCI runtime, it uses exec to use the OCI runtime, and we can go one step further and say that the OCI runtime implementation will be run seat. And this is the setup that we use on OpenShift. This is a pod spec in YAML format, so we have kind pod, the specification has a list of containers, in this case there's one, the container has a name, defines the image to use, the command to execute, environment variables that should be set, and so on. OpenShift or OpenShift container platform is an enterprise-ready Kubernetes container platform, it's commercially supported by Red Hat, there's a community upstream distribution called OKD, as I mentioned before, it uses cryo and run seat, and the latest stable release is 4.12, I think that came out just a week ago or so. And its default way that it creates containers is it uses SE Linux and namespaces to confine the processes, each namespace gets assigned a unique user ID range and the processes for the pods in that namespace have to run in those host UIDs. You can circumvent this using the run as user security context constraint, but that is not a good idea, you don't want your containers running as root on the container host because if they escape the sandbox, then your cluster got owned. So this is the why of user namespaces, user namespaces as we're talking about Linux kernel, user namespaces can be used to improve the workload isolation and the confinement of the pods in your cluster. They can also be used to run applications that require or assume that they're running as specific user IDs, or to phrase this a different way, you can drag your legacy applications kicking and screaming into the cloud and get the benefits of all of the orchestration and networking support that these platforms like Kubernetes and OpenShift can give you while still running that workload securely. In other words, trick it to believe it is running as root. And yeah, there have been a bunch of CVEs in Kubernetes and the broader container orchestration ecosystem arising from sandbox escapes where user namespaces would have prevented the vulnerability or severely limited or curtailed its impact. So visualizing a user namespace, we can have two separate containers with a user namespace mapping of UID range 0 to 65535 inside the container's user namespace to a range of unprivileged user IDs in the host's user ID namespace. So the processes running in the container believe that they are running as, for example, root UID 0 or some other privileged user ID when, in fact, it's running as UID 200,000 on the host, an unprivileged user ID. Take the sandbox and you're still an unprivileged user on the host. So in Linux, there's some references to some man pages about user namespaces and how to use them. The critical thing is the unshare system call, which is how you create and use the user namespace. In the OCI runtime specification, there are some fields. And again, this is Linux specific, so it's inside the Linux specific part of that configuration that you can specify that a user namespace should be created or used for that container and you can specify the mapping. So how do we map the containers user ID range to the host user ID range? User namespaces were implemented before they were implemented in Kubernetes upstream. We did it in cryo, it first shipped in OpenShift 4.7, but it required a considerable amount of additional configuration of the cluster to use it. And since OpenShift 4.10, you've been able to use it out of the box. You do still have to opt in using annotations on a per pod basis. It requires the NEU ID security context constraint or an equivalent privileged security context constraint in order to admit the pod because the admission machinery does not yet understand about user namespaces. So the pod spec says, I want to run as user ID 0 and the admission machinery says, uh-uh, no way. We need to circumvent that for the time being, but the workload itself will run in the user namespace. And depending on the workload, it may still require some additional cluster configuration. So the annotations to opt in, you can say IO.OpenShift.Builder is true. That activates a particular cryo, what we call a workload, basically an alternative bunch of runtime settings. And then we use the user NS mode annotation to specify that we want an arbitrary user namespace of size 65536. So that'll allocate you a contiguous host UID range for that container and map it to unprivileged host user IDs. In the Kubernetes upstream, it took a bit longer to get user namespace support and it's still a work in progress, but the initial support was delivered in Kubernetes 1.25. And that version is what we've moved to in OpenShift 4.12. So you can now use the first class user namespace support in OpenShift. It is an alpha feature, so it's not enabled by default. You have to turn it on with a feature gate. And at the moment, it only supports ephemeral volume types, so empty to a config maps, secrets, no persistent volume support yet. You opt in by putting host users false in your pod spec and currently gives you a fixed mapping size of 65536 that will be unique to that pod. It is hoped that a later phase will deliver support for the additional volume types. The reason that we didn't have them is the complexity around ID mapped mounts and how to adapt the volume mounts to understand how to map the user IDs between the host UID namespace and the container's username space. There's also very simple heuristics around the ID range assignment. As I mentioned, it's a fixed size of 65536 that limits the number of pods that you could run in user namespaces on a given node, and there are still some other mount point and file ownership issues, for example, with the C-group FS. And that takes us to the C-group's topic. So OpenShift creates a unique C-group for each container, and it also creates a C-group namespace so that the container in the CISFS C-group mount only sees its namespace. Inside the container, CISFS C-group actually points to CISFS C-group slash a whole bunch of stuff specific to that container in the host's file system. If you want to run a systemD-based workload, systemD needs right access to the C-group FS, but by default, the C-group FS will be mounted read only. So the solution, we modify the container runtime to chone the C-group to the container's process UID. So that is we chone it to the host UID corresponding to UID0 in the container's user namespace. But first, before we did this in an ad hoc basis, we engaged with the OpenContainer initiative to define the semantics for C-group ownership in a container, and those proposals were workshopped and accepted, and after that, we were able to implement those semantics in RunC. So what are the semantics? Well, the container's C-group will be choned to the host UID matching the process UID in the container's user namespace, if and only if the node is using C-groups V2, and the container has its own C-group namespace and the C-group FS is mounted read-write. So only the C-group directory itself and the files mentioned in sys-kernel C-group delegate are choned. These are the ones that are safe to delegate to a sub-process. And the container runtime, if that file sys-kernel C-group delegate is defined, then it will read that file and only chone the files mentioned there. So it can respond to the evolution of the kernel where new C-group nodes may come and go, some of them may be safe to delegate, some of them may not. In OpenShift, C-groups V2 is not yet the default when you deploy a cluster, but it does work and it is supported, and to activate the C-group choned semantics that I just explained, we still require an annotation in the pod spec. So let's do a demo. Here's a cluster I prepared earlier, and we can see new project test, okay, OC create user test, maybe test already exists, okay, we'll just use test. So we can now, oh, well, I'll show you the pod I'm going to create, cat pod nginx, host users false. So this is a pod spec, let's get some syntax highlighting. This is going to run nginx, it's a system D based workload, so it's a fedora system that will come up and system D will run and it will start nginx. We're setting host users false so that it will run in a user namespace. I have already enabled the feature flag on this cluster. There's that annotation for the C-group choned, and the name of the pod will be nginx, so let's create that. So OC as test, create a share. Okay, fingers crossed. Okay, so we'll say OC admin policy add role to user edit, okay, let's try that again. So the pod has been created, and we'll just check it's status to see which node it is running on, and it hasn't yet started, so we don't have a container ID for it yet, but in the upper pane, I'll get a shell on that worker node. Okay, pod is now running, so we can run cry control, inspect, container ID, and we'll just pull out the PID, so this is our PID. Now if we have a look at the user ID map for this process, okay, so here we see that we have a user namespace with the user ID mapping of size 65536, which is mapping user ID 0 in the container's user namespace to user ID 131072 in the host user namespace. And now we can look at the processes that are actually running there, so we'll do pgrep, l-ns says show me everything with the same set of namespaces as this process ID, and then I'll just pipe that to PS, let's print the user, the PID, and the command, sorting by PID, okay. So we can see that this container is running, well, in it, and then bunch of systemd processes, and then eventually nginx, and these are running under, see, 131072, yeah, 132071, yeah, so these are running as various user IDs in the container's user namespace, and those are being mapped to the host user ID namespace as these PIDs. If we look at the logs, we can see that it looks like a regular systemd system has come up, indeed it has, and let's see, I see, maybe we'll get a shell on the node, on the pod, and yeah, if we have a look at what is the container's view of the processes that are running, it sees that systemd is running as root or other systemd-related users inside the container's user namespace, nginx is running as the nginx user in that container's user namespace, but as we saw, these are all mapped to unprivileged host UIDs in the host user namespace. So that concludes the demo, here's a link to various resources, I have a lot of blog posts on this and related topics, so you can hit my blog and just look at the containers tag, a recording of a demo or a similar demo, slightly earlier version, link to KEP127, which is where all of the discussion around how to do the upstream support for user namespaces in Kubernetes, all of that discussion happened there, the OCI runtime spec is referenced there, and that's it, so I think there is time for some questions. Please stay seated until 25 so we can ask questions, okay, there's one in the back, do you want to read the one from the chat first? There's a question in chat, I don't see it anymore, it says, why would I want to run systemd in a container, it's cool that it's possible with user namespaces, but I lack an idea for use case. So the use case is you have a complicated legacy workload that runs under systemd or makes assumptions about the environment it runs in, the user IDs that the different components are running as, you've got two choices, one is to spend a whole lot of upfront engineering effort to break up that application and containerize it and make it a cloud native application, which is expensive and typically has a long lead time, or you can just wrap that whole application up in a container and run it securely, hopefully, in a container orchestration platform and get the benefit of all of the scaling, networking, observability features that the orchestration platform gives you without having to spend that effort to bust your application into a hundred pieces. So I would say that that is the use case, I think it's a compelling one, if you were building applications today you certainly wouldn't do that, but there are 100 million legacy applications out there and people don't want to break them up and change them. Hi, thanks for the talk, I'm actually doing this right now at my company, but basically the container is running as privileged, so that's why it can access C group, it doesn't use user namespaces, it just runs as a privilege, so I was wondering if using this method you could set a memory max, memory high, or other values for some processes in the C group running in the container, I mean. I'm sorry, I couldn't hear the question because it's rather echo-y. Sorry, yeah, so can you set memory high, memory max, values, CPU affinities, like all these kinds of things you would set in the C group usually, can you set them from this particular use case of C groups in the container? Yes, absolutely, because the container still has its own C group namespace, so all of the standard C group confinement and resource limit capabilities can be used. Okay, I guess I got confused by the list of values that were allowed to do a listed in the previous slide, there was a restricted list of values. Yeah, so those were just the particular files that need to be choned in order for a safe delegation of control of that branch of the C group hierarchy to another process, so you can still set on the C group directory all of the limits and the container won't be able to change those because those will not be choned to the container's process UID. Okay, thank you. So I have a question regarding the CFFC group C-H own, so you mentioned it's going to be changed to the UID of the container, of the process container, can you do that if you want to have several ports to run their own system D? Is your question around can you do it in a nested way? No, not in a nested way, you have three different ports which each port needs their own system D. Yes, yes, absolutely. So if I created more pods in my demo, you would see that they would then be mapped to different host UID ranges, so the limit is only how many of the range allocations can you fit into the host UID range? So the limit will be a little under 6.536 because the size of the host UID range on Linux by default is 2 to the 32, yeah. Okay, I think we have time for one more question and thank you all for your patience. Thank you Fraser. I just wanted to know if v2, secret v2 by default in OpenShift is on the road map yet and whether or not there's any sort of estimated time scale for that. Yes it is, yep, so there is a plan to eventually move to secret v2 as the default, I don't know the exact time frame. Thank you so much for your talk, thank you all for your patience and I know this sounds weird but you're free to leave.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.56, "text": " Okay, then our next talk is by Frazier.", "tokens": [1033, 11, 550, 527, 958, 751, 307, 538, 5849, 33352, 13], "temperature": 0.0, "avg_logprob": -0.2768849204568302, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.14970332384109497}, {"id": 1, "seek": 0, "start": 10.56, "end": 11.56, "text": " Over to you.", "tokens": [4886, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.2768849204568302, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.14970332384109497}, {"id": 2, "seek": 0, "start": 11.56, "end": 12.56, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2768849204568302, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.14970332384109497}, {"id": 3, "seek": 0, "start": 12.56, "end": 13.56, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.2768849204568302, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.14970332384109497}, {"id": 4, "seek": 0, "start": 13.56, "end": 21.8, "text": " So I'm going to talk about user namespaces and delegation of control of C groups in container", "tokens": [407, 286, 478, 516, 281, 751, 466, 4195, 5288, 79, 2116, 293, 36602, 295, 1969, 295, 383, 3935, 294, 10129], "temperature": 0.0, "avg_logprob": -0.2768849204568302, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.14970332384109497}, {"id": 5, "seek": 0, "start": 21.8, "end": 24.8, "text": " orchestration systems.", "tokens": [14161, 2405, 3652, 13], "temperature": 0.0, "avg_logprob": -0.2768849204568302, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.14970332384109497}, {"id": 6, "seek": 0, "start": 24.8, "end": 28.28, "text": " So yeah, containers and container standards.", "tokens": [407, 1338, 11, 17089, 293, 10129, 7787, 13], "temperature": 0.0, "avg_logprob": -0.2768849204568302, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.14970332384109497}, {"id": 7, "seek": 2828, "start": 28.28, "end": 33.44, "text": " This is the containers dev room, I think, hopefully most people should have some idea.", "tokens": [639, 307, 264, 17089, 1905, 1808, 11, 286, 519, 11, 4696, 881, 561, 820, 362, 512, 1558, 13], "temperature": 0.0, "avg_logprob": -0.20427961782975632, "compression_ratio": 1.5856573705179282, "no_speech_prob": 5.256874646875076e-05}, {"id": 8, "seek": 2828, "start": 33.44, "end": 39.120000000000005, "text": " Talk about Kubernetes and OpenShift, user namespaces and C groups, and then a demo of", "tokens": [8780, 466, 23145, 293, 7238, 7774, 2008, 11, 4195, 5288, 79, 2116, 293, 383, 3935, 11, 293, 550, 257, 10723, 295], "temperature": 0.0, "avg_logprob": -0.20427961782975632, "compression_ratio": 1.5856573705179282, "no_speech_prob": 5.256874646875076e-05}, {"id": 9, "seek": 2828, "start": 39.120000000000005, "end": 45.84, "text": " a system B based workload on Kubernetes and more specifically OpenShift.", "tokens": [257, 1185, 363, 2361, 20139, 322, 23145, 293, 544, 4682, 7238, 7774, 2008, 13], "temperature": 0.0, "avg_logprob": -0.20427961782975632, "compression_ratio": 1.5856573705179282, "no_speech_prob": 5.256874646875076e-05}, {"id": 10, "seek": 2828, "start": 45.84, "end": 51.88, "text": " So container is a process isolation and confinement abstraction.", "tokens": [407, 10129, 307, 257, 1399, 16001, 293, 41064, 37765, 13], "temperature": 0.0, "avg_logprob": -0.20427961782975632, "compression_ratio": 1.5856573705179282, "no_speech_prob": 5.256874646875076e-05}, {"id": 11, "seek": 2828, "start": 51.88, "end": 57.84, "text": " Most commonly it uses operating system level virtualization where the processes running", "tokens": [4534, 12719, 309, 4960, 7447, 1185, 1496, 6374, 2144, 689, 264, 7555, 2614], "temperature": 0.0, "avg_logprob": -0.20427961782975632, "compression_ratio": 1.5856573705179282, "no_speech_prob": 5.256874646875076e-05}, {"id": 12, "seek": 5784, "start": 57.84, "end": 63.28, "text": " in the container are using the same kernel as the host system.", "tokens": [294, 264, 10129, 366, 1228, 264, 912, 28256, 382, 264, 3975, 1185, 13], "temperature": 0.0, "avg_logprob": -0.16359676711860743, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.3545601177611388e-05}, {"id": 13, "seek": 5784, "start": 63.28, "end": 69.80000000000001, "text": " Examples of this include FreeBSD Jails and Solaris Zones as well as Linux containers.", "tokens": [48591, 295, 341, 4090, 11551, 8176, 35, 508, 6227, 293, 22385, 271, 1176, 2213, 382, 731, 382, 18734, 17089, 13], "temperature": 0.0, "avg_logprob": -0.16359676711860743, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.3545601177611388e-05}, {"id": 14, "seek": 5784, "start": 69.80000000000001, "end": 74.4, "text": " And the container image is not a container, the container image just defines the file", "tokens": [400, 264, 10129, 3256, 307, 406, 257, 10129, 11, 264, 10129, 3256, 445, 23122, 264, 3991], "temperature": 0.0, "avg_logprob": -0.16359676711860743, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.3545601177611388e-05}, {"id": 15, "seek": 5784, "start": 74.4, "end": 81.24000000000001, "text": " system contents for a container and some metadata suggesting what process should be run, what", "tokens": [1185, 15768, 337, 257, 10129, 293, 512, 26603, 18094, 437, 1399, 820, 312, 1190, 11, 437], "temperature": 0.0, "avg_logprob": -0.16359676711860743, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.3545601177611388e-05}, {"id": 16, "seek": 5784, "start": 81.24000000000001, "end": 85.48, "text": " user ID it should run underneath and so on.", "tokens": [4195, 7348, 309, 820, 1190, 7223, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.16359676711860743, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.3545601177611388e-05}, {"id": 17, "seek": 8548, "start": 85.48, "end": 92.84, "text": " On Linux containers use a combination of the following technologies, so namespaces,", "tokens": [1282, 18734, 17089, 764, 257, 6562, 295, 264, 3480, 7943, 11, 370, 5288, 79, 2116, 11], "temperature": 0.0, "avg_logprob": -0.17517622505746236, "compression_ratio": 1.7163461538461537, "no_speech_prob": 8.705354048288427e-06}, {"id": 18, "seek": 8548, "start": 92.84, "end": 98.60000000000001, "text": " process ID namespaces, mount namespaces, network namespaces, et cetera, to restrict", "tokens": [1399, 7348, 5288, 79, 2116, 11, 3746, 5288, 79, 2116, 11, 3209, 5288, 79, 2116, 11, 1030, 11458, 11, 281, 7694], "temperature": 0.0, "avg_logprob": -0.17517622505746236, "compression_ratio": 1.7163461538461537, "no_speech_prob": 8.705354048288427e-06}, {"id": 19, "seek": 8548, "start": 98.60000000000001, "end": 103.04, "text": " what the process running in the container can see.", "tokens": [437, 264, 1399, 2614, 294, 264, 10129, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.17517622505746236, "compression_ratio": 1.7163461538461537, "no_speech_prob": 8.705354048288427e-06}, {"id": 20, "seek": 8548, "start": 103.04, "end": 108.0, "text": " The container may have restricted capabilities or a second profile that limits which system", "tokens": [440, 10129, 815, 362, 20608, 10862, 420, 257, 1150, 7964, 300, 10406, 597, 1185], "temperature": 0.0, "avg_logprob": -0.17517622505746236, "compression_ratio": 1.7163461538461537, "no_speech_prob": 8.705354048288427e-06}, {"id": 21, "seek": 8548, "start": 108.0, "end": 112.08000000000001, "text": " calls or operating system features it can use.", "tokens": [5498, 420, 7447, 1185, 4122, 309, 393, 764, 13], "temperature": 0.0, "avg_logprob": -0.17517622505746236, "compression_ratio": 1.7163461538461537, "no_speech_prob": 8.705354048288427e-06}, {"id": 22, "seek": 11208, "start": 112.08, "end": 119.75999999999999, "text": " There may be SE Linux or app armor confinement and it can use C groups for resource limits.", "tokens": [821, 815, 312, 10269, 18734, 420, 724, 13124, 41064, 293, 309, 393, 764, 383, 3935, 337, 7684, 10406, 13], "temperature": 0.0, "avg_logprob": -0.14434308369954427, "compression_ratio": 1.5851528384279476, "no_speech_prob": 1.4685628229926806e-05}, {"id": 23, "seek": 11208, "start": 119.75999999999999, "end": 128.16, "text": " Not necessarily all of these are used at the same time, it depends on the implementation.", "tokens": [1726, 4725, 439, 295, 613, 366, 1143, 412, 264, 912, 565, 11, 309, 5946, 322, 264, 11420, 13], "temperature": 0.0, "avg_logprob": -0.14434308369954427, "compression_ratio": 1.5851528384279476, "no_speech_prob": 1.4685628229926806e-05}, {"id": 24, "seek": 11208, "start": 128.16, "end": 135.92, "text": " The OpenContainer initiative defines standards around containers in the free software ecosystem", "tokens": [440, 7238, 29821, 491, 260, 11552, 23122, 7787, 926, 17089, 294, 264, 1737, 4722, 11311], "temperature": 0.0, "avg_logprob": -0.14434308369954427, "compression_ratio": 1.5851528384279476, "no_speech_prob": 1.4685628229926806e-05}, {"id": 25, "seek": 11208, "start": 135.92, "end": 141.44, "text": " and its runtime specification in particular defines a low level runtime interface for", "tokens": [293, 1080, 34474, 31256, 294, 1729, 23122, 257, 2295, 1496, 34474, 9226, 337], "temperature": 0.0, "avg_logprob": -0.14434308369954427, "compression_ratio": 1.5851528384279476, "no_speech_prob": 1.4685628229926806e-05}, {"id": 26, "seek": 14144, "start": 141.44, "end": 148.88, "text": " containers that is not just for Linux containers but it defines the runtime semantics for Linux", "tokens": [17089, 300, 307, 406, 445, 337, 18734, 17089, 457, 309, 23122, 264, 34474, 4361, 45298, 337, 18734], "temperature": 0.0, "avg_logprob": -0.20103629430135092, "compression_ratio": 1.7936507936507937, "no_speech_prob": 1.3345083061722107e-05}, {"id": 27, "seek": 14144, "start": 148.88, "end": 155.72, "text": " Solaris containers, Windows containers, virtual machines and so there are a bunch of implementations", "tokens": [22385, 271, 17089, 11, 8591, 17089, 11, 6374, 8379, 293, 370, 456, 366, 257, 3840, 295, 4445, 763], "temperature": 0.0, "avg_logprob": -0.20103629430135092, "compression_ratio": 1.7936507936507937, "no_speech_prob": 1.3345083061722107e-05}, {"id": 28, "seek": 14144, "start": 155.72, "end": 163.24, "text": " of the runtime spec including RunC, the reference implementation, CRUN and CART containers which", "tokens": [295, 264, 34474, 1608, 3009, 8950, 34, 11, 264, 6408, 11420, 11, 14123, 3979, 293, 383, 15118, 17089, 597], "temperature": 0.0, "avg_logprob": -0.20103629430135092, "compression_ratio": 1.7936507936507937, "no_speech_prob": 1.3345083061722107e-05}, {"id": 29, "seek": 14144, "start": 163.24, "end": 168.16, "text": " is a virtual machine based container runtime.", "tokens": [307, 257, 6374, 3479, 2361, 10129, 34474, 13], "temperature": 0.0, "avg_logprob": -0.20103629430135092, "compression_ratio": 1.7936507936507937, "no_speech_prob": 1.3345083061722107e-05}, {"id": 30, "seek": 16816, "start": 168.16, "end": 175.32, "text": " The OCI runtime spec has a JSON configuration and there's a link to an example, it defines", "tokens": [440, 422, 25240, 34474, 1608, 575, 257, 31828, 11694, 293, 456, 311, 257, 2113, 281, 364, 1365, 11, 309, 23122], "temperature": 0.0, "avg_logprob": -0.18891466399769724, "compression_ratio": 1.5682819383259912, "no_speech_prob": 1.3965878679300658e-05}, {"id": 31, "seek": 16816, "start": 175.32, "end": 180.88, "text": " or lets you define the mounts, what process to be executed, its environment, life cycle", "tokens": [420, 6653, 291, 6964, 264, 40982, 11, 437, 1399, 281, 312, 17577, 11, 1080, 2823, 11, 993, 6586], "temperature": 0.0, "avg_logprob": -0.18891466399769724, "compression_ratio": 1.5682819383259912, "no_speech_prob": 1.3965878679300658e-05}, {"id": 32, "seek": 16816, "start": 180.88, "end": 187.07999999999998, "text": " hooks so extra code to run when the container is created, destroyed, started, stopped and", "tokens": [26485, 370, 2857, 3089, 281, 1190, 562, 264, 10129, 307, 2942, 11, 8937, 11, 1409, 11, 5936, 293], "temperature": 0.0, "avg_logprob": -0.18891466399769724, "compression_ratio": 1.5682819383259912, "no_speech_prob": 1.3965878679300658e-05}, {"id": 33, "seek": 16816, "start": 187.07999999999998, "end": 194.44, "text": " the Linux specific capabilities that can be controlled via the OCI runtime spec include", "tokens": [264, 18734, 2685, 10862, 300, 393, 312, 10164, 5766, 264, 422, 25240, 34474, 1608, 4090], "temperature": 0.0, "avg_logprob": -0.18891466399769724, "compression_ratio": 1.5682819383259912, "no_speech_prob": 1.3965878679300658e-05}, {"id": 34, "seek": 19444, "start": 194.44, "end": 202.84, "text": " the capabilities, that's the kernel feature capabilities, namespaces, the C group, the", "tokens": [264, 10862, 11, 300, 311, 264, 28256, 4111, 10862, 11, 5288, 79, 2116, 11, 264, 383, 1594, 11, 264], "temperature": 0.0, "avg_logprob": -0.20967588268342566, "compression_ratio": 1.5294117647058822, "no_speech_prob": 4.695533061749302e-05}, {"id": 35, "seek": 19444, "start": 202.84, "end": 209.56, "text": " system controls that should be set for that container, the seccomp profile and so on.", "tokens": [1185, 9003, 300, 820, 312, 992, 337, 300, 10129, 11, 264, 907, 21541, 7964, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.20967588268342566, "compression_ratio": 1.5294117647058822, "no_speech_prob": 4.695533061749302e-05}, {"id": 36, "seek": 19444, "start": 209.56, "end": 219.36, "text": " This is what an example runtime specification looks like, so it has a process structure", "tokens": [639, 307, 437, 364, 1365, 34474, 31256, 1542, 411, 11, 370, 309, 575, 257, 1399, 3877], "temperature": 0.0, "avg_logprob": -0.20967588268342566, "compression_ratio": 1.5294117647058822, "no_speech_prob": 4.695533061749302e-05}, {"id": 37, "seek": 21936, "start": 219.36, "end": 226.76000000000002, "text": " which includes a field for the user ID and the group ID, it has this Linux structure", "tokens": [597, 5974, 257, 2519, 337, 264, 4195, 7348, 293, 264, 1594, 7348, 11, 309, 575, 341, 18734, 3877], "temperature": 0.0, "avg_logprob": -0.09979349458721322, "compression_ratio": 1.7640449438202248, "no_speech_prob": 1.4647344869445078e-05}, {"id": 38, "seek": 21936, "start": 226.76000000000002, "end": 233.76000000000002, "text": " which defines the Linux specific attributes for this container and one of those attributes", "tokens": [597, 23122, 264, 18734, 2685, 17212, 337, 341, 10129, 293, 472, 295, 729, 17212], "temperature": 0.0, "avg_logprob": -0.09979349458721322, "compression_ratio": 1.7640449438202248, "no_speech_prob": 1.4647344869445078e-05}, {"id": 39, "seek": 21936, "start": 233.76000000000002, "end": 239.92000000000002, "text": " is the namespaces list which defines a list of the different namespaces that should be", "tokens": [307, 264, 5288, 79, 2116, 1329, 597, 23122, 257, 1329, 295, 264, 819, 5288, 79, 2116, 300, 820, 312], "temperature": 0.0, "avg_logprob": -0.09979349458721322, "compression_ratio": 1.7640449438202248, "no_speech_prob": 1.4647344869445078e-05}, {"id": 40, "seek": 21936, "start": 239.92000000000002, "end": 246.32000000000002, "text": " used or should be newly created for that container.", "tokens": [1143, 420, 820, 312, 15109, 2942, 337, 300, 10129, 13], "temperature": 0.0, "avg_logprob": -0.09979349458721322, "compression_ratio": 1.7640449438202248, "no_speech_prob": 1.4647344869445078e-05}, {"id": 41, "seek": 24632, "start": 246.32, "end": 251.88, "text": " So Kubernetes is a container orchestration platform, has a declarative configuration", "tokens": [407, 23145, 307, 257, 10129, 14161, 2405, 3663, 11, 575, 257, 16694, 1166, 11694], "temperature": 0.0, "avg_logprob": -0.16382597313552608, "compression_ratio": 1.591160220994475, "no_speech_prob": 4.562986214295961e-05}, {"id": 42, "seek": 24632, "start": 251.88, "end": 259.64, "text": " system and it integrates with many different cloud providers.", "tokens": [1185, 293, 309, 3572, 1024, 365, 867, 819, 4588, 11330, 13], "temperature": 0.0, "avg_logprob": -0.16382597313552608, "compression_ratio": 1.591160220994475, "no_speech_prob": 4.562986214295961e-05}, {"id": 43, "seek": 24632, "start": 259.64, "end": 265.68, "text": " Anyone not know what Kubernetes is in the room?", "tokens": [14643, 406, 458, 437, 23145, 307, 294, 264, 1808, 30], "temperature": 0.0, "avg_logprob": -0.16382597313552608, "compression_ratio": 1.591160220994475, "no_speech_prob": 4.562986214295961e-05}, {"id": 44, "seek": 24632, "start": 265.68, "end": 270.2, "text": " So the terminology in Kubernetes, the container is an isolated or confined process or process", "tokens": [407, 264, 27575, 294, 23145, 11, 264, 10129, 307, 364, 14621, 420, 31745, 1399, 420, 1399], "temperature": 0.0, "avg_logprob": -0.16382597313552608, "compression_ratio": 1.591160220994475, "no_speech_prob": 4.562986214295961e-05}, {"id": 45, "seek": 27020, "start": 270.2, "end": 278.2, "text": " tree, a pod is one or more related containers that together constitute an application of", "tokens": [4230, 11, 257, 2497, 307, 472, 420, 544, 4077, 17089, 300, 1214, 41658, 364, 3861, 295], "temperature": 0.0, "avg_logprob": -0.14140895056346106, "compression_ratio": 1.5337078651685394, "no_speech_prob": 3.306003782199696e-05}, {"id": 46, "seek": 27020, "start": 278.2, "end": 286.12, "text": " some sort, so it might be an HTTP server and a database to encapsulate the entire", "tokens": [512, 1333, 11, 370, 309, 1062, 312, 364, 33283, 7154, 293, 257, 8149, 281, 38745, 5256, 264, 2302], "temperature": 0.0, "avg_logprob": -0.14140895056346106, "compression_ratio": 1.5337078651685394, "no_speech_prob": 3.306003782199696e-05}, {"id": 47, "seek": 27020, "start": 286.12, "end": 288.48, "text": " web application.", "tokens": [3670, 3861, 13], "temperature": 0.0, "avg_logprob": -0.14140895056346106, "compression_ratio": 1.5337078651685394, "no_speech_prob": 3.306003782199696e-05}, {"id": 48, "seek": 27020, "start": 288.48, "end": 295.12, "text": " A namespace in Kubernetes terminology is not a namespace in Linux kernel terminology,", "tokens": [316, 5288, 17940, 294, 23145, 27575, 307, 406, 257, 5288, 17940, 294, 18734, 28256, 27575, 11], "temperature": 0.0, "avg_logprob": -0.14140895056346106, "compression_ratio": 1.5337078651685394, "no_speech_prob": 3.306003782199696e-05}, {"id": 49, "seek": 29512, "start": 295.12, "end": 301.72, "text": " a namespace is just an object scope and authorization scope for a bunch of objects in the Kubernetes", "tokens": [257, 5288, 17940, 307, 445, 364, 2657, 11923, 293, 33697, 11923, 337, 257, 3840, 295, 6565, 294, 264, 23145], "temperature": 0.0, "avg_logprob": -0.14547107094212583, "compression_ratio": 1.78099173553719, "no_speech_prob": 7.06049904692918e-05}, {"id": 50, "seek": 29512, "start": 301.72, "end": 307.24, "text": " data store, so if you have a particular team or project in your organization you might", "tokens": [1412, 3531, 11, 370, 498, 291, 362, 257, 1729, 1469, 420, 1716, 294, 428, 4475, 291, 1062], "temperature": 0.0, "avg_logprob": -0.14547107094212583, "compression_ratio": 1.78099173553719, "no_speech_prob": 7.06049904692918e-05}, {"id": 51, "seek": 29512, "start": 307.24, "end": 313.72, "text": " deploy all of the Kubernetes applications in a single namespace.", "tokens": [7274, 439, 295, 264, 23145, 5821, 294, 257, 2167, 5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.14547107094212583, "compression_ratio": 1.78099173553719, "no_speech_prob": 7.06049904692918e-05}, {"id": 52, "seek": 29512, "start": 313.72, "end": 317.76, "text": " And a node is a machine in the cluster where pods are executed, there are different kinds", "tokens": [400, 257, 9984, 307, 257, 3479, 294, 264, 13630, 689, 31925, 366, 17577, 11, 456, 366, 819, 3685], "temperature": 0.0, "avg_logprob": -0.14547107094212583, "compression_ratio": 1.78099173553719, "no_speech_prob": 7.06049904692918e-05}, {"id": 53, "seek": 29512, "start": 317.76, "end": 322.56, "text": " of nodes, there are control pane nodes, there are worker nodes where the actual business", "tokens": [295, 13891, 11, 456, 366, 1969, 32605, 13891, 11, 456, 366, 11346, 13891, 689, 264, 3539, 1606], "temperature": 0.0, "avg_logprob": -0.14547107094212583, "compression_ratio": 1.78099173553719, "no_speech_prob": 7.06049904692918e-05}, {"id": 54, "seek": 32256, "start": 322.56, "end": 328.24, "text": " applications run.", "tokens": [5821, 1190, 13], "temperature": 0.0, "avg_logprob": -0.16767175381000227, "compression_ratio": 1.7078651685393258, "no_speech_prob": 5.691425030818209e-05}, {"id": 55, "seek": 32256, "start": 328.24, "end": 334.6, "text": " Kubelet is the agent that executes pods on nodes, so there's a scheduling system, the", "tokens": [35805, 15966, 307, 264, 9461, 300, 4454, 1819, 31925, 322, 13891, 11, 370, 456, 311, 257, 29055, 1185, 11, 264], "temperature": 0.0, "avg_logprob": -0.16767175381000227, "compression_ratio": 1.7078651685393258, "no_speech_prob": 5.691425030818209e-05}, {"id": 56, "seek": 32256, "start": 334.6, "end": 342.56, "text": " scheduler will, when a pod is created, decide what node that pod should run on and Kubelet", "tokens": [12000, 260, 486, 11, 562, 257, 2497, 307, 2942, 11, 4536, 437, 9984, 300, 2497, 820, 1190, 322, 293, 35805, 15966], "temperature": 0.0, "avg_logprob": -0.16767175381000227, "compression_ratio": 1.7078651685393258, "no_speech_prob": 5.691425030818209e-05}, {"id": 57, "seek": 32256, "start": 342.56, "end": 348.48, "text": " is the agent on the node that takes the pod specification and turns it into a container", "tokens": [307, 264, 9461, 322, 264, 9984, 300, 2516, 264, 2497, 31256, 293, 4523, 309, 666, 257, 10129], "temperature": 0.0, "avg_logprob": -0.16767175381000227, "compression_ratio": 1.7078651685393258, "no_speech_prob": 5.691425030818209e-05}, {"id": 58, "seek": 32256, "start": 348.48, "end": 351.56, "text": " running on that node.", "tokens": [2614, 322, 300, 9984, 13], "temperature": 0.0, "avg_logprob": -0.16767175381000227, "compression_ratio": 1.7078651685393258, "no_speech_prob": 5.691425030818209e-05}, {"id": 59, "seek": 35156, "start": 351.56, "end": 357.36, "text": " The Kubernetes terminology uses the term sandbox, that's an isolation or confinement", "tokens": [440, 23145, 27575, 4960, 264, 1433, 42115, 11, 300, 311, 364, 16001, 420, 41064], "temperature": 0.0, "avg_logprob": -0.13978299098228342, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.625114782655146e-05}, {"id": 60, "seek": 35156, "start": 357.36, "end": 363.84000000000003, "text": " mechanism, and there's one sandbox per pod, so there could be multiple containers running", "tokens": [7513, 11, 293, 456, 311, 472, 42115, 680, 2497, 11, 370, 456, 727, 312, 3866, 17089, 2614], "temperature": 0.0, "avg_logprob": -0.13978299098228342, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.625114782655146e-05}, {"id": 61, "seek": 35156, "start": 363.84000000000003, "end": 365.96, "text": " in the sandbox.", "tokens": [294, 264, 42115, 13], "temperature": 0.0, "avg_logprob": -0.13978299098228342, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.625114782655146e-05}, {"id": 62, "seek": 35156, "start": 365.96, "end": 374.2, "text": " And the container runtime interface defines how Kubelet actually starts and stops the", "tokens": [400, 264, 10129, 34474, 9226, 23122, 577, 35805, 15966, 767, 3719, 293, 10094, 264], "temperature": 0.0, "avg_logprob": -0.13978299098228342, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.625114782655146e-05}, {"id": 63, "seek": 35156, "start": 374.2, "end": 377.6, "text": " containers for the sandboxes.", "tokens": [17089, 337, 264, 42115, 279, 13], "temperature": 0.0, "avg_logprob": -0.13978299098228342, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.625114782655146e-05}, {"id": 64, "seek": 37760, "start": 377.6, "end": 383.0, "text": " So cryo is one implementation of the container runtime interface, that's what's used in", "tokens": [407, 3305, 78, 307, 472, 11420, 295, 264, 10129, 34474, 9226, 11, 300, 311, 437, 311, 1143, 294], "temperature": 0.0, "avg_logprob": -0.17331146110187878, "compression_ratio": 1.6875, "no_speech_prob": 3.071282844757661e-05}, {"id": 65, "seek": 37760, "start": 383.0, "end": 391.08000000000004, "text": " OpenShift, there's also container d, that's used in some other distributions of Kubernetes.", "tokens": [7238, 7774, 2008, 11, 456, 311, 611, 10129, 274, 11, 300, 311, 1143, 294, 512, 661, 37870, 295, 23145, 13], "temperature": 0.0, "avg_logprob": -0.17331146110187878, "compression_ratio": 1.6875, "no_speech_prob": 3.071282844757661e-05}, {"id": 66, "seek": 37760, "start": 391.08000000000004, "end": 398.04, "text": " So visualizing this, the whole box is one Kubernetes node, the Kubelet has the gRPC", "tokens": [407, 5056, 3319, 341, 11, 264, 1379, 2424, 307, 472, 23145, 9984, 11, 264, 35805, 15966, 575, 264, 290, 49, 12986], "temperature": 0.0, "avg_logprob": -0.17331146110187878, "compression_ratio": 1.6875, "no_speech_prob": 3.071282844757661e-05}, {"id": 67, "seek": 37760, "start": 398.04, "end": 406.24, "text": " client to talk to us CRI runtime, the CRI runtime does something and containers appear.", "tokens": [6423, 281, 751, 281, 505, 383, 5577, 34474, 11, 264, 383, 5577, 34474, 775, 746, 293, 17089, 4204, 13], "temperature": 0.0, "avg_logprob": -0.17331146110187878, "compression_ratio": 1.6875, "no_speech_prob": 3.071282844757661e-05}, {"id": 68, "seek": 40624, "start": 406.24, "end": 414.32, "text": " So we could instantiate the container runtime interface implementation as cryo, and then", "tokens": [407, 321, 727, 9836, 13024, 264, 10129, 34474, 9226, 11420, 382, 3305, 78, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.131849393612001, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.1597967386478558e-05}, {"id": 69, "seek": 40624, "start": 414.32, "end": 421.40000000000003, "text": " we can see that cryo talks to an OCI runtime, it uses exec to use the OCI runtime, and we", "tokens": [321, 393, 536, 300, 3305, 78, 6686, 281, 364, 422, 25240, 34474, 11, 309, 4960, 4454, 281, 764, 264, 422, 25240, 34474, 11, 293, 321], "temperature": 0.0, "avg_logprob": -0.131849393612001, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.1597967386478558e-05}, {"id": 70, "seek": 40624, "start": 421.40000000000003, "end": 428.6, "text": " can go one step further and say that the OCI runtime implementation will be run seat.", "tokens": [393, 352, 472, 1823, 3052, 293, 584, 300, 264, 422, 25240, 34474, 11420, 486, 312, 1190, 6121, 13], "temperature": 0.0, "avg_logprob": -0.131849393612001, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.1597967386478558e-05}, {"id": 71, "seek": 40624, "start": 428.6, "end": 433.84000000000003, "text": " And this is the setup that we use on OpenShift.", "tokens": [400, 341, 307, 264, 8657, 300, 321, 764, 322, 7238, 7774, 2008, 13], "temperature": 0.0, "avg_logprob": -0.131849393612001, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.1597967386478558e-05}, {"id": 72, "seek": 43384, "start": 433.84, "end": 441.23999999999995, "text": " This is a pod spec in YAML format, so we have kind pod, the specification has a list of", "tokens": [639, 307, 257, 2497, 1608, 294, 398, 2865, 43, 7877, 11, 370, 321, 362, 733, 2497, 11, 264, 31256, 575, 257, 1329, 295], "temperature": 0.0, "avg_logprob": -0.16082442084024118, "compression_ratio": 1.619047619047619, "no_speech_prob": 3.36511257046368e-05}, {"id": 73, "seek": 43384, "start": 441.23999999999995, "end": 446.0, "text": " containers, in this case there's one, the container has a name, defines the image to", "tokens": [17089, 11, 294, 341, 1389, 456, 311, 472, 11, 264, 10129, 575, 257, 1315, 11, 23122, 264, 3256, 281], "temperature": 0.0, "avg_logprob": -0.16082442084024118, "compression_ratio": 1.619047619047619, "no_speech_prob": 3.36511257046368e-05}, {"id": 74, "seek": 43384, "start": 446.0, "end": 453.96, "text": " use, the command to execute, environment variables that should be set, and so on.", "tokens": [764, 11, 264, 5622, 281, 14483, 11, 2823, 9102, 300, 820, 312, 992, 11, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.16082442084024118, "compression_ratio": 1.619047619047619, "no_speech_prob": 3.36511257046368e-05}, {"id": 75, "seek": 43384, "start": 453.96, "end": 459.47999999999996, "text": " OpenShift or OpenShift container platform is an enterprise-ready Kubernetes container", "tokens": [7238, 7774, 2008, 420, 7238, 7774, 2008, 10129, 3663, 307, 364, 14132, 12, 1201, 23145, 10129], "temperature": 0.0, "avg_logprob": -0.16082442084024118, "compression_ratio": 1.619047619047619, "no_speech_prob": 3.36511257046368e-05}, {"id": 76, "seek": 45948, "start": 459.48, "end": 464.20000000000005, "text": " platform, it's commercially supported by Red Hat, there's a community upstream distribution", "tokens": [3663, 11, 309, 311, 41751, 8104, 538, 4477, 15867, 11, 456, 311, 257, 1768, 33915, 7316], "temperature": 0.0, "avg_logprob": -0.15161923801197724, "compression_ratio": 1.4601769911504425, "no_speech_prob": 1.245038311026292e-05}, {"id": 77, "seek": 45948, "start": 464.20000000000005, "end": 471.52000000000004, "text": " called OKD, as I mentioned before, it uses cryo and run seat, and the latest stable release", "tokens": [1219, 2264, 35, 11, 382, 286, 2835, 949, 11, 309, 4960, 3305, 78, 293, 1190, 6121, 11, 293, 264, 6792, 8351, 4374], "temperature": 0.0, "avg_logprob": -0.15161923801197724, "compression_ratio": 1.4601769911504425, "no_speech_prob": 1.245038311026292e-05}, {"id": 78, "seek": 45948, "start": 471.52000000000004, "end": 478.12, "text": " is 4.12, I think that came out just a week ago or so.", "tokens": [307, 1017, 13, 4762, 11, 286, 519, 300, 1361, 484, 445, 257, 1243, 2057, 420, 370, 13], "temperature": 0.0, "avg_logprob": -0.15161923801197724, "compression_ratio": 1.4601769911504425, "no_speech_prob": 1.245038311026292e-05}, {"id": 79, "seek": 45948, "start": 478.12, "end": 487.0, "text": " And its default way that it creates containers is it uses SE Linux and namespaces to confine", "tokens": [400, 1080, 7576, 636, 300, 309, 7829, 17089, 307, 309, 4960, 10269, 18734, 293, 5288, 79, 2116, 281, 1497, 533], "temperature": 0.0, "avg_logprob": -0.15161923801197724, "compression_ratio": 1.4601769911504425, "no_speech_prob": 1.245038311026292e-05}, {"id": 80, "seek": 48700, "start": 487.0, "end": 497.0, "text": " the processes, each namespace gets assigned a unique user ID range and the processes for", "tokens": [264, 7555, 11, 1184, 5288, 17940, 2170, 13279, 257, 3845, 4195, 7348, 3613, 293, 264, 7555, 337], "temperature": 0.0, "avg_logprob": -0.12069241004654124, "compression_ratio": 1.6482412060301508, "no_speech_prob": 2.4292254238389432e-05}, {"id": 81, "seek": 48700, "start": 497.0, "end": 502.04, "text": " the pods in that namespace have to run in those host UIDs.", "tokens": [264, 31925, 294, 300, 5288, 17940, 362, 281, 1190, 294, 729, 3975, 624, 2777, 82, 13], "temperature": 0.0, "avg_logprob": -0.12069241004654124, "compression_ratio": 1.6482412060301508, "no_speech_prob": 2.4292254238389432e-05}, {"id": 82, "seek": 48700, "start": 502.04, "end": 508.8, "text": " You can circumvent this using the run as user security context constraint, but that is not", "tokens": [509, 393, 7125, 2475, 341, 1228, 264, 1190, 382, 4195, 3825, 4319, 25534, 11, 457, 300, 307, 406], "temperature": 0.0, "avg_logprob": -0.12069241004654124, "compression_ratio": 1.6482412060301508, "no_speech_prob": 2.4292254238389432e-05}, {"id": 83, "seek": 48700, "start": 508.8, "end": 515.6, "text": " a good idea, you don't want your containers running as root on the container host because", "tokens": [257, 665, 1558, 11, 291, 500, 380, 528, 428, 17089, 2614, 382, 5593, 322, 264, 10129, 3975, 570], "temperature": 0.0, "avg_logprob": -0.12069241004654124, "compression_ratio": 1.6482412060301508, "no_speech_prob": 2.4292254238389432e-05}, {"id": 84, "seek": 51560, "start": 515.6, "end": 521.32, "text": " if they escape the sandbox, then your cluster got owned.", "tokens": [498, 436, 7615, 264, 42115, 11, 550, 428, 13630, 658, 11684, 13], "temperature": 0.0, "avg_logprob": -0.20242933385512407, "compression_ratio": 1.6829268292682926, "no_speech_prob": 9.743918781168759e-06}, {"id": 85, "seek": 51560, "start": 521.32, "end": 528.44, "text": " So this is the why of user namespaces, user namespaces as we're talking about Linux kernel,", "tokens": [407, 341, 307, 264, 983, 295, 4195, 5288, 79, 2116, 11, 4195, 5288, 79, 2116, 382, 321, 434, 1417, 466, 18734, 28256, 11], "temperature": 0.0, "avg_logprob": -0.20242933385512407, "compression_ratio": 1.6829268292682926, "no_speech_prob": 9.743918781168759e-06}, {"id": 86, "seek": 51560, "start": 528.44, "end": 534.64, "text": " user namespaces can be used to improve the workload isolation and the confinement of the", "tokens": [4195, 5288, 79, 2116, 393, 312, 1143, 281, 3470, 264, 20139, 16001, 293, 264, 41064, 295, 264], "temperature": 0.0, "avg_logprob": -0.20242933385512407, "compression_ratio": 1.6829268292682926, "no_speech_prob": 9.743918781168759e-06}, {"id": 87, "seek": 51560, "start": 534.64, "end": 537.2, "text": " pods in your cluster.", "tokens": [31925, 294, 428, 13630, 13], "temperature": 0.0, "avg_logprob": -0.20242933385512407, "compression_ratio": 1.6829268292682926, "no_speech_prob": 9.743918781168759e-06}, {"id": 88, "seek": 51560, "start": 537.2, "end": 541.88, "text": " They can also be used to run applications that require or assume that they're running", "tokens": [814, 393, 611, 312, 1143, 281, 1190, 5821, 300, 3651, 420, 6552, 300, 436, 434, 2614], "temperature": 0.0, "avg_logprob": -0.20242933385512407, "compression_ratio": 1.6829268292682926, "no_speech_prob": 9.743918781168759e-06}, {"id": 89, "seek": 54188, "start": 541.88, "end": 548.12, "text": " as specific user IDs, or to phrase this a different way, you can drag your legacy applications", "tokens": [382, 2685, 4195, 48212, 11, 420, 281, 9535, 341, 257, 819, 636, 11, 291, 393, 5286, 428, 11711, 5821], "temperature": 0.0, "avg_logprob": -0.12313882988619518, "compression_ratio": 1.574468085106383, "no_speech_prob": 2.231867256341502e-05}, {"id": 90, "seek": 54188, "start": 548.12, "end": 556.04, "text": " kicking and screaming into the cloud and get the benefits of all of the orchestration and", "tokens": [19137, 293, 12636, 666, 264, 4588, 293, 483, 264, 5311, 295, 439, 295, 264, 14161, 2405, 293], "temperature": 0.0, "avg_logprob": -0.12313882988619518, "compression_ratio": 1.574468085106383, "no_speech_prob": 2.231867256341502e-05}, {"id": 91, "seek": 54188, "start": 556.04, "end": 562.84, "text": " networking support that these platforms like Kubernetes and OpenShift can give you while", "tokens": [17985, 1406, 300, 613, 9473, 411, 23145, 293, 7238, 7774, 2008, 393, 976, 291, 1339], "temperature": 0.0, "avg_logprob": -0.12313882988619518, "compression_ratio": 1.574468085106383, "no_speech_prob": 2.231867256341502e-05}, {"id": 92, "seek": 54188, "start": 562.84, "end": 565.48, "text": " still running that workload securely.", "tokens": [920, 2614, 300, 20139, 38348, 13], "temperature": 0.0, "avg_logprob": -0.12313882988619518, "compression_ratio": 1.574468085106383, "no_speech_prob": 2.231867256341502e-05}, {"id": 93, "seek": 54188, "start": 565.48, "end": 571.36, "text": " In other words, trick it to believe it is running as root.", "tokens": [682, 661, 2283, 11, 4282, 309, 281, 1697, 309, 307, 2614, 382, 5593, 13], "temperature": 0.0, "avg_logprob": -0.12313882988619518, "compression_ratio": 1.574468085106383, "no_speech_prob": 2.231867256341502e-05}, {"id": 94, "seek": 57136, "start": 571.36, "end": 578.28, "text": " And yeah, there have been a bunch of CVEs in Kubernetes and the broader container orchestration", "tokens": [400, 1338, 11, 456, 362, 668, 257, 3840, 295, 22995, 20442, 294, 23145, 293, 264, 13227, 10129, 14161, 2405], "temperature": 0.0, "avg_logprob": -0.12922157653390545, "compression_ratio": 1.5913461538461537, "no_speech_prob": 1.0698397090891376e-05}, {"id": 95, "seek": 57136, "start": 578.28, "end": 586.72, "text": " ecosystem arising from sandbox escapes where user namespaces would have prevented the vulnerability", "tokens": [11311, 44900, 490, 42115, 43769, 689, 4195, 5288, 79, 2116, 576, 362, 27314, 264, 24210], "temperature": 0.0, "avg_logprob": -0.12922157653390545, "compression_ratio": 1.5913461538461537, "no_speech_prob": 1.0698397090891376e-05}, {"id": 96, "seek": 57136, "start": 586.72, "end": 593.04, "text": " or severely limited or curtailed its impact.", "tokens": [420, 26271, 5567, 420, 1262, 14430, 292, 1080, 2712, 13], "temperature": 0.0, "avg_logprob": -0.12922157653390545, "compression_ratio": 1.5913461538461537, "no_speech_prob": 1.0698397090891376e-05}, {"id": 97, "seek": 57136, "start": 593.04, "end": 598.6, "text": " So visualizing a user namespace, we can have two separate containers with a user namespace", "tokens": [407, 5056, 3319, 257, 4195, 5288, 17940, 11, 321, 393, 362, 732, 4994, 17089, 365, 257, 4195, 5288, 17940], "temperature": 0.0, "avg_logprob": -0.12922157653390545, "compression_ratio": 1.5913461538461537, "no_speech_prob": 1.0698397090891376e-05}, {"id": 98, "seek": 59860, "start": 598.6, "end": 608.32, "text": " mapping of UID range 0 to 65535 inside the container's user namespace to a range of unprivileged", "tokens": [18350, 295, 624, 2777, 3613, 1958, 281, 11624, 20, 8794, 1854, 264, 10129, 311, 4195, 5288, 17940, 281, 257, 3613, 295, 20994, 29994, 794, 3004], "temperature": 0.0, "avg_logprob": -0.18930784546502746, "compression_ratio": 1.7425742574257426, "no_speech_prob": 1.2727476132567972e-05}, {"id": 99, "seek": 59860, "start": 608.32, "end": 612.24, "text": " user IDs in the host's user ID namespace.", "tokens": [4195, 48212, 294, 264, 3975, 311, 4195, 7348, 5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.18930784546502746, "compression_ratio": 1.7425742574257426, "no_speech_prob": 1.2727476132567972e-05}, {"id": 100, "seek": 59860, "start": 612.24, "end": 616.76, "text": " So the processes running in the container believe that they are running as, for example,", "tokens": [407, 264, 7555, 2614, 294, 264, 10129, 1697, 300, 436, 366, 2614, 382, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.18930784546502746, "compression_ratio": 1.7425742574257426, "no_speech_prob": 1.2727476132567972e-05}, {"id": 101, "seek": 59860, "start": 616.76, "end": 624.96, "text": " root UID 0 or some other privileged user ID when, in fact, it's running as UID 200,000", "tokens": [5593, 624, 2777, 1958, 420, 512, 661, 25293, 4195, 7348, 562, 11, 294, 1186, 11, 309, 311, 2614, 382, 624, 2777, 2331, 11, 1360], "temperature": 0.0, "avg_logprob": -0.18930784546502746, "compression_ratio": 1.7425742574257426, "no_speech_prob": 1.2727476132567972e-05}, {"id": 102, "seek": 59860, "start": 624.96, "end": 628.36, "text": " on the host, an unprivileged user ID.", "tokens": [322, 264, 3975, 11, 364, 20994, 29994, 794, 3004, 4195, 7348, 13], "temperature": 0.0, "avg_logprob": -0.18930784546502746, "compression_ratio": 1.7425742574257426, "no_speech_prob": 1.2727476132567972e-05}, {"id": 103, "seek": 62836, "start": 628.36, "end": 635.44, "text": " Take the sandbox and you're still an unprivileged user on the host.", "tokens": [3664, 264, 42115, 293, 291, 434, 920, 364, 20994, 29994, 794, 3004, 4195, 322, 264, 3975, 13], "temperature": 0.0, "avg_logprob": -0.13230902649635493, "compression_ratio": 1.558252427184466, "no_speech_prob": 2.577501072664745e-05}, {"id": 104, "seek": 62836, "start": 635.44, "end": 640.6, "text": " So in Linux, there's some references to some man pages about user namespaces and how to", "tokens": [407, 294, 18734, 11, 456, 311, 512, 15400, 281, 512, 587, 7183, 466, 4195, 5288, 79, 2116, 293, 577, 281], "temperature": 0.0, "avg_logprob": -0.13230902649635493, "compression_ratio": 1.558252427184466, "no_speech_prob": 2.577501072664745e-05}, {"id": 105, "seek": 62836, "start": 640.6, "end": 641.6, "text": " use them.", "tokens": [764, 552, 13], "temperature": 0.0, "avg_logprob": -0.13230902649635493, "compression_ratio": 1.558252427184466, "no_speech_prob": 2.577501072664745e-05}, {"id": 106, "seek": 62836, "start": 641.6, "end": 650.32, "text": " The critical thing is the unshare system call, which is how you create and use the user namespace.", "tokens": [440, 4924, 551, 307, 264, 2693, 31932, 1185, 818, 11, 597, 307, 577, 291, 1884, 293, 764, 264, 4195, 5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.13230902649635493, "compression_ratio": 1.558252427184466, "no_speech_prob": 2.577501072664745e-05}, {"id": 107, "seek": 62836, "start": 650.32, "end": 655.48, "text": " In the OCI runtime specification, there are some fields.", "tokens": [682, 264, 422, 25240, 34474, 31256, 11, 456, 366, 512, 7909, 13], "temperature": 0.0, "avg_logprob": -0.13230902649635493, "compression_ratio": 1.558252427184466, "no_speech_prob": 2.577501072664745e-05}, {"id": 108, "seek": 65548, "start": 655.48, "end": 660.72, "text": " And again, this is Linux specific, so it's inside the Linux specific part of that configuration", "tokens": [400, 797, 11, 341, 307, 18734, 2685, 11, 370, 309, 311, 1854, 264, 18734, 2685, 644, 295, 300, 11694], "temperature": 0.0, "avg_logprob": -0.17063251761502998, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.735678051772993e-05}, {"id": 109, "seek": 65548, "start": 660.72, "end": 666.4, "text": " that you can specify that a user namespace should be created or used for that container", "tokens": [300, 291, 393, 16500, 300, 257, 4195, 5288, 17940, 820, 312, 2942, 420, 1143, 337, 300, 10129], "temperature": 0.0, "avg_logprob": -0.17063251761502998, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.735678051772993e-05}, {"id": 110, "seek": 65548, "start": 666.4, "end": 668.28, "text": " and you can specify the mapping.", "tokens": [293, 291, 393, 16500, 264, 18350, 13], "temperature": 0.0, "avg_logprob": -0.17063251761502998, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.735678051772993e-05}, {"id": 111, "seek": 65548, "start": 668.28, "end": 676.9200000000001, "text": " So how do we map the containers user ID range to the host user ID range?", "tokens": [407, 577, 360, 321, 4471, 264, 17089, 4195, 7348, 3613, 281, 264, 3975, 4195, 7348, 3613, 30], "temperature": 0.0, "avg_logprob": -0.17063251761502998, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.735678051772993e-05}, {"id": 112, "seek": 65548, "start": 676.9200000000001, "end": 682.0, "text": " User namespaces were implemented before they were implemented in Kubernetes upstream.", "tokens": [32127, 5288, 79, 2116, 645, 12270, 949, 436, 645, 12270, 294, 23145, 33915, 13], "temperature": 0.0, "avg_logprob": -0.17063251761502998, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.735678051772993e-05}, {"id": 113, "seek": 68200, "start": 682.0, "end": 691.52, "text": " We did it in cryo, it first shipped in OpenShift 4.7, but it required a considerable amount", "tokens": [492, 630, 309, 294, 3305, 78, 11, 309, 700, 25312, 294, 7238, 7774, 2008, 1017, 13, 22, 11, 457, 309, 4739, 257, 24167, 2372], "temperature": 0.0, "avg_logprob": -0.10218031612443335, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.6858823073562235e-05}, {"id": 114, "seek": 68200, "start": 691.52, "end": 694.8, "text": " of additional configuration of the cluster to use it.", "tokens": [295, 4497, 11694, 295, 264, 13630, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.10218031612443335, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.6858823073562235e-05}, {"id": 115, "seek": 68200, "start": 694.8, "end": 698.64, "text": " And since OpenShift 4.10, you've been able to use it out of the box.", "tokens": [400, 1670, 7238, 7774, 2008, 1017, 13, 3279, 11, 291, 600, 668, 1075, 281, 764, 309, 484, 295, 264, 2424, 13], "temperature": 0.0, "avg_logprob": -0.10218031612443335, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.6858823073562235e-05}, {"id": 116, "seek": 68200, "start": 698.64, "end": 706.64, "text": " You do still have to opt in using annotations on a per pod basis.", "tokens": [509, 360, 920, 362, 281, 2427, 294, 1228, 25339, 763, 322, 257, 680, 2497, 5143, 13], "temperature": 0.0, "avg_logprob": -0.10218031612443335, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.6858823073562235e-05}, {"id": 117, "seek": 70664, "start": 706.64, "end": 713.24, "text": " It requires the NEU ID security context constraint or an equivalent privileged security context", "tokens": [467, 7029, 264, 12384, 52, 7348, 3825, 4319, 25534, 420, 364, 10344, 25293, 3825, 4319], "temperature": 0.0, "avg_logprob": -0.18205648599211702, "compression_ratio": 1.684873949579832, "no_speech_prob": 2.650941132742446e-05}, {"id": 118, "seek": 70664, "start": 713.24, "end": 718.88, "text": " constraint in order to admit the pod because the admission machinery does not yet understand", "tokens": [25534, 294, 1668, 281, 9796, 264, 2497, 570, 264, 24668, 27302, 775, 406, 1939, 1223], "temperature": 0.0, "avg_logprob": -0.18205648599211702, "compression_ratio": 1.684873949579832, "no_speech_prob": 2.650941132742446e-05}, {"id": 119, "seek": 70664, "start": 718.88, "end": 721.48, "text": " about user namespaces.", "tokens": [466, 4195, 5288, 79, 2116, 13], "temperature": 0.0, "avg_logprob": -0.18205648599211702, "compression_ratio": 1.684873949579832, "no_speech_prob": 2.650941132742446e-05}, {"id": 120, "seek": 70664, "start": 721.48, "end": 727.72, "text": " So the pod spec says, I want to run as user ID 0 and the admission machinery says, uh-uh,", "tokens": [407, 264, 2497, 1608, 1619, 11, 286, 528, 281, 1190, 382, 4195, 7348, 1958, 293, 264, 24668, 27302, 1619, 11, 2232, 12, 3232, 11], "temperature": 0.0, "avg_logprob": -0.18205648599211702, "compression_ratio": 1.684873949579832, "no_speech_prob": 2.650941132742446e-05}, {"id": 121, "seek": 70664, "start": 727.72, "end": 728.72, "text": " no way.", "tokens": [572, 636, 13], "temperature": 0.0, "avg_logprob": -0.18205648599211702, "compression_ratio": 1.684873949579832, "no_speech_prob": 2.650941132742446e-05}, {"id": 122, "seek": 70664, "start": 728.72, "end": 735.4, "text": " We need to circumvent that for the time being, but the workload itself will run in the user", "tokens": [492, 643, 281, 7125, 2475, 300, 337, 264, 565, 885, 11, 457, 264, 20139, 2564, 486, 1190, 294, 264, 4195], "temperature": 0.0, "avg_logprob": -0.18205648599211702, "compression_ratio": 1.684873949579832, "no_speech_prob": 2.650941132742446e-05}, {"id": 123, "seek": 73540, "start": 735.4, "end": 738.76, "text": " namespace.", "tokens": [5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.15906764365531303, "compression_ratio": 1.4416243654822336, "no_speech_prob": 1.381763013341697e-05}, {"id": 124, "seek": 73540, "start": 738.76, "end": 745.12, "text": " And depending on the workload, it may still require some additional cluster configuration.", "tokens": [400, 5413, 322, 264, 20139, 11, 309, 815, 920, 3651, 512, 4497, 13630, 11694, 13], "temperature": 0.0, "avg_logprob": -0.15906764365531303, "compression_ratio": 1.4416243654822336, "no_speech_prob": 1.381763013341697e-05}, {"id": 125, "seek": 73540, "start": 745.12, "end": 750.3199999999999, "text": " So the annotations to opt in, you can say IO.OpenShift.Builder is true.", "tokens": [407, 264, 25339, 763, 281, 2427, 294, 11, 291, 393, 584, 39839, 13, 45569, 7774, 2008, 13, 28110, 793, 260, 307, 2074, 13], "temperature": 0.0, "avg_logprob": -0.15906764365531303, "compression_ratio": 1.4416243654822336, "no_speech_prob": 1.381763013341697e-05}, {"id": 126, "seek": 73540, "start": 750.3199999999999, "end": 756.9599999999999, "text": " That activates a particular cryo, what we call a workload, basically an alternative bunch", "tokens": [663, 43869, 257, 1729, 3305, 78, 11, 437, 321, 818, 257, 20139, 11, 1936, 364, 8535, 3840], "temperature": 0.0, "avg_logprob": -0.15906764365531303, "compression_ratio": 1.4416243654822336, "no_speech_prob": 1.381763013341697e-05}, {"id": 127, "seek": 73540, "start": 756.9599999999999, "end": 759.3, "text": " of runtime settings.", "tokens": [295, 34474, 6257, 13], "temperature": 0.0, "avg_logprob": -0.15906764365531303, "compression_ratio": 1.4416243654822336, "no_speech_prob": 1.381763013341697e-05}, {"id": 128, "seek": 75930, "start": 759.3, "end": 766.68, "text": " And then we use the user NS mode annotation to specify that we want an arbitrary user", "tokens": [400, 550, 321, 764, 264, 4195, 15943, 4391, 48654, 281, 16500, 300, 321, 528, 364, 23211, 4195], "temperature": 0.0, "avg_logprob": -0.16643313901970186, "compression_ratio": 1.4951923076923077, "no_speech_prob": 1.3364617188926786e-05}, {"id": 129, "seek": 75930, "start": 766.68, "end": 769.92, "text": " namespace of size 65536.", "tokens": [5288, 17940, 295, 2744, 11624, 20, 11309, 13], "temperature": 0.0, "avg_logprob": -0.16643313901970186, "compression_ratio": 1.4951923076923077, "no_speech_prob": 1.3364617188926786e-05}, {"id": 130, "seek": 75930, "start": 769.92, "end": 775.5999999999999, "text": " So that'll allocate you a contiguous host UID range for that container and map it to", "tokens": [407, 300, 603, 35713, 291, 257, 660, 30525, 3975, 624, 2777, 3613, 337, 300, 10129, 293, 4471, 309, 281], "temperature": 0.0, "avg_logprob": -0.16643313901970186, "compression_ratio": 1.4951923076923077, "no_speech_prob": 1.3364617188926786e-05}, {"id": 131, "seek": 75930, "start": 775.5999999999999, "end": 780.4799999999999, "text": " unprivileged host user IDs.", "tokens": [20994, 29994, 794, 3004, 3975, 4195, 48212, 13], "temperature": 0.0, "avg_logprob": -0.16643313901970186, "compression_ratio": 1.4951923076923077, "no_speech_prob": 1.3364617188926786e-05}, {"id": 132, "seek": 75930, "start": 780.4799999999999, "end": 784.7199999999999, "text": " In the Kubernetes upstream, it took a bit longer to get user namespace support and it's", "tokens": [682, 264, 23145, 33915, 11, 309, 1890, 257, 857, 2854, 281, 483, 4195, 5288, 17940, 1406, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.16643313901970186, "compression_ratio": 1.4951923076923077, "no_speech_prob": 1.3364617188926786e-05}, {"id": 133, "seek": 78472, "start": 784.72, "end": 790.84, "text": " still a work in progress, but the initial support was delivered in Kubernetes 1.25.", "tokens": [920, 257, 589, 294, 4205, 11, 457, 264, 5883, 1406, 390, 10144, 294, 23145, 502, 13, 6074, 13], "temperature": 0.0, "avg_logprob": -0.12989935122038188, "compression_ratio": 1.5648854961832062, "no_speech_prob": 8.579333552916069e-06}, {"id": 134, "seek": 78472, "start": 790.84, "end": 795.36, "text": " And that version is what we've moved to in OpenShift 4.12.", "tokens": [400, 300, 3037, 307, 437, 321, 600, 4259, 281, 294, 7238, 7774, 2008, 1017, 13, 4762, 13], "temperature": 0.0, "avg_logprob": -0.12989935122038188, "compression_ratio": 1.5648854961832062, "no_speech_prob": 8.579333552916069e-06}, {"id": 135, "seek": 78472, "start": 795.36, "end": 801.9200000000001, "text": " So you can now use the first class user namespace support in OpenShift.", "tokens": [407, 291, 393, 586, 764, 264, 700, 1508, 4195, 5288, 17940, 1406, 294, 7238, 7774, 2008, 13], "temperature": 0.0, "avg_logprob": -0.12989935122038188, "compression_ratio": 1.5648854961832062, "no_speech_prob": 8.579333552916069e-06}, {"id": 136, "seek": 78472, "start": 801.9200000000001, "end": 804.9200000000001, "text": " It is an alpha feature, so it's not enabled by default.", "tokens": [467, 307, 364, 8961, 4111, 11, 370, 309, 311, 406, 15172, 538, 7576, 13], "temperature": 0.0, "avg_logprob": -0.12989935122038188, "compression_ratio": 1.5648854961832062, "no_speech_prob": 8.579333552916069e-06}, {"id": 137, "seek": 78472, "start": 804.9200000000001, "end": 808.1, "text": " You have to turn it on with a feature gate.", "tokens": [509, 362, 281, 1261, 309, 322, 365, 257, 4111, 8539, 13], "temperature": 0.0, "avg_logprob": -0.12989935122038188, "compression_ratio": 1.5648854961832062, "no_speech_prob": 8.579333552916069e-06}, {"id": 138, "seek": 78472, "start": 808.1, "end": 814.36, "text": " And at the moment, it only supports ephemeral volume types, so empty to a config maps, secrets,", "tokens": [400, 412, 264, 1623, 11, 309, 787, 9346, 308, 41245, 2790, 5523, 3467, 11, 370, 6707, 281, 257, 6662, 11317, 11, 14093, 11], "temperature": 0.0, "avg_logprob": -0.12989935122038188, "compression_ratio": 1.5648854961832062, "no_speech_prob": 8.579333552916069e-06}, {"id": 139, "seek": 81436, "start": 814.36, "end": 817.88, "text": " no persistent volume support yet.", "tokens": [572, 24315, 5523, 1406, 1939, 13], "temperature": 0.0, "avg_logprob": -0.12069534510374069, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.700519144127611e-05}, {"id": 140, "seek": 81436, "start": 817.88, "end": 827.4, "text": " You opt in by putting host users false in your pod spec and currently gives you a fixed", "tokens": [509, 2427, 294, 538, 3372, 3975, 5022, 7908, 294, 428, 2497, 1608, 293, 4362, 2709, 291, 257, 6806], "temperature": 0.0, "avg_logprob": -0.12069534510374069, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.700519144127611e-05}, {"id": 141, "seek": 81436, "start": 827.4, "end": 834.76, "text": " mapping size of 65536 that will be unique to that pod.", "tokens": [18350, 2744, 295, 11624, 20, 11309, 300, 486, 312, 3845, 281, 300, 2497, 13], "temperature": 0.0, "avg_logprob": -0.12069534510374069, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.700519144127611e-05}, {"id": 142, "seek": 81436, "start": 834.76, "end": 841.24, "text": " It is hoped that a later phase will deliver support for the additional volume types.", "tokens": [467, 307, 19737, 300, 257, 1780, 5574, 486, 4239, 1406, 337, 264, 4497, 5523, 3467, 13], "temperature": 0.0, "avg_logprob": -0.12069534510374069, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.700519144127611e-05}, {"id": 143, "seek": 84124, "start": 841.24, "end": 846.2, "text": " The reason that we didn't have them is the complexity around ID mapped mounts and how", "tokens": [440, 1778, 300, 321, 994, 380, 362, 552, 307, 264, 14024, 926, 7348, 33318, 40982, 293, 577], "temperature": 0.0, "avg_logprob": -0.14433534249015476, "compression_ratio": 1.5847457627118644, "no_speech_prob": 2.833541111613158e-05}, {"id": 144, "seek": 84124, "start": 846.2, "end": 855.5, "text": " to adapt the volume mounts to understand how to map the user IDs between the host UID", "tokens": [281, 6231, 264, 5523, 40982, 281, 1223, 577, 281, 4471, 264, 4195, 48212, 1296, 264, 3975, 624, 2777], "temperature": 0.0, "avg_logprob": -0.14433534249015476, "compression_ratio": 1.5847457627118644, "no_speech_prob": 2.833541111613158e-05}, {"id": 145, "seek": 84124, "start": 855.5, "end": 858.92, "text": " namespace and the container's username space.", "tokens": [5288, 17940, 293, 264, 10129, 311, 30351, 1901, 13], "temperature": 0.0, "avg_logprob": -0.14433534249015476, "compression_ratio": 1.5847457627118644, "no_speech_prob": 2.833541111613158e-05}, {"id": 146, "seek": 84124, "start": 858.92, "end": 862.72, "text": " There's also very simple heuristics around the ID range assignment.", "tokens": [821, 311, 611, 588, 2199, 415, 374, 6006, 926, 264, 7348, 3613, 15187, 13], "temperature": 0.0, "avg_logprob": -0.14433534249015476, "compression_ratio": 1.5847457627118644, "no_speech_prob": 2.833541111613158e-05}, {"id": 147, "seek": 84124, "start": 862.72, "end": 868.44, "text": " As I mentioned, it's a fixed size of 65536 that limits the number of pods that you could", "tokens": [1018, 286, 2835, 11, 309, 311, 257, 6806, 2744, 295, 11624, 20, 11309, 300, 10406, 264, 1230, 295, 31925, 300, 291, 727], "temperature": 0.0, "avg_logprob": -0.14433534249015476, "compression_ratio": 1.5847457627118644, "no_speech_prob": 2.833541111613158e-05}, {"id": 148, "seek": 86844, "start": 868.44, "end": 875.4000000000001, "text": " run in user namespaces on a given node, and there are still some other mount point and", "tokens": [1190, 294, 4195, 5288, 79, 2116, 322, 257, 2212, 9984, 11, 293, 456, 366, 920, 512, 661, 3746, 935, 293], "temperature": 0.0, "avg_logprob": -0.19507294834250272, "compression_ratio": 1.7, "no_speech_prob": 1.2750473615597002e-05}, {"id": 149, "seek": 86844, "start": 875.4000000000001, "end": 879.9200000000001, "text": " file ownership issues, for example, with the C-group FS.", "tokens": [3991, 15279, 2663, 11, 337, 1365, 11, 365, 264, 383, 12, 17377, 41138, 13], "temperature": 0.0, "avg_logprob": -0.19507294834250272, "compression_ratio": 1.7, "no_speech_prob": 1.2750473615597002e-05}, {"id": 150, "seek": 86844, "start": 879.9200000000001, "end": 882.32, "text": " And that takes us to the C-group's topic.", "tokens": [400, 300, 2516, 505, 281, 264, 383, 12, 17377, 311, 4829, 13], "temperature": 0.0, "avg_logprob": -0.19507294834250272, "compression_ratio": 1.7, "no_speech_prob": 1.2750473615597002e-05}, {"id": 151, "seek": 86844, "start": 882.32, "end": 888.84, "text": " So OpenShift creates a unique C-group for each container, and it also creates a C-group", "tokens": [407, 7238, 7774, 2008, 7829, 257, 3845, 383, 12, 17377, 337, 1184, 10129, 11, 293, 309, 611, 7829, 257, 383, 12, 17377], "temperature": 0.0, "avg_logprob": -0.19507294834250272, "compression_ratio": 1.7, "no_speech_prob": 1.2750473615597002e-05}, {"id": 152, "seek": 86844, "start": 888.84, "end": 898.4000000000001, "text": " namespace so that the container in the CISFS C-group mount only sees its namespace.", "tokens": [5288, 17940, 370, 300, 264, 10129, 294, 264, 383, 2343, 29318, 383, 12, 17377, 3746, 787, 8194, 1080, 5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.19507294834250272, "compression_ratio": 1.7, "no_speech_prob": 1.2750473615597002e-05}, {"id": 153, "seek": 89840, "start": 898.4, "end": 903.9599999999999, "text": " Inside the container, CISFS C-group actually points to CISFS C-group slash a whole bunch", "tokens": [15123, 264, 10129, 11, 383, 2343, 29318, 383, 12, 17377, 767, 2793, 281, 383, 2343, 29318, 383, 12, 17377, 17330, 257, 1379, 3840], "temperature": 0.0, "avg_logprob": -0.12099724937887753, "compression_ratio": 1.5706806282722514, "no_speech_prob": 6.839015895820921e-06}, {"id": 154, "seek": 89840, "start": 903.9599999999999, "end": 911.6, "text": " of stuff specific to that container in the host's file system.", "tokens": [295, 1507, 2685, 281, 300, 10129, 294, 264, 3975, 311, 3991, 1185, 13], "temperature": 0.0, "avg_logprob": -0.12099724937887753, "compression_ratio": 1.5706806282722514, "no_speech_prob": 6.839015895820921e-06}, {"id": 155, "seek": 89840, "start": 911.6, "end": 917.52, "text": " If you want to run a systemD-based workload, systemD needs right access to the C-group", "tokens": [759, 291, 528, 281, 1190, 257, 1185, 35, 12, 6032, 20139, 11, 1185, 35, 2203, 558, 2105, 281, 264, 383, 12, 17377], "temperature": 0.0, "avg_logprob": -0.12099724937887753, "compression_ratio": 1.5706806282722514, "no_speech_prob": 6.839015895820921e-06}, {"id": 156, "seek": 89840, "start": 917.52, "end": 924.8, "text": " FS, but by default, the C-group FS will be mounted read only.", "tokens": [41138, 11, 457, 538, 7576, 11, 264, 383, 12, 17377, 41138, 486, 312, 19138, 1401, 787, 13], "temperature": 0.0, "avg_logprob": -0.12099724937887753, "compression_ratio": 1.5706806282722514, "no_speech_prob": 6.839015895820921e-06}, {"id": 157, "seek": 92480, "start": 924.8, "end": 931.4399999999999, "text": " So the solution, we modify the container runtime to chone the C-group to the container's", "tokens": [407, 264, 3827, 11, 321, 16927, 264, 10129, 34474, 281, 417, 546, 264, 383, 12, 17377, 281, 264, 10129, 311], "temperature": 0.0, "avg_logprob": -0.1465123141253436, "compression_ratio": 1.5783783783783785, "no_speech_prob": 1.3068090993328951e-05}, {"id": 158, "seek": 92480, "start": 931.4399999999999, "end": 933.0799999999999, "text": " process UID.", "tokens": [1399, 624, 2777, 13], "temperature": 0.0, "avg_logprob": -0.1465123141253436, "compression_ratio": 1.5783783783783785, "no_speech_prob": 1.3068090993328951e-05}, {"id": 159, "seek": 92480, "start": 933.0799999999999, "end": 943.52, "text": " So that is we chone it to the host UID corresponding to UID0 in the container's user namespace.", "tokens": [407, 300, 307, 321, 417, 546, 309, 281, 264, 3975, 624, 2777, 11760, 281, 624, 2777, 15, 294, 264, 10129, 311, 4195, 5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.1465123141253436, "compression_ratio": 1.5783783783783785, "no_speech_prob": 1.3068090993328951e-05}, {"id": 160, "seek": 92480, "start": 943.52, "end": 950.9599999999999, "text": " But first, before we did this in an ad hoc basis, we engaged with the OpenContainer initiative", "tokens": [583, 700, 11, 949, 321, 630, 341, 294, 364, 614, 16708, 5143, 11, 321, 8237, 365, 264, 7238, 29821, 491, 260, 11552], "temperature": 0.0, "avg_logprob": -0.1465123141253436, "compression_ratio": 1.5783783783783785, "no_speech_prob": 1.3068090993328951e-05}, {"id": 161, "seek": 95096, "start": 950.96, "end": 959.8000000000001, "text": " to define the semantics for C-group ownership in a container, and those proposals were workshopped", "tokens": [281, 6964, 264, 4361, 45298, 337, 383, 12, 17377, 15279, 294, 257, 10129, 11, 293, 729, 20198, 645, 13541, 3452], "temperature": 0.0, "avg_logprob": -0.1329833525645582, "compression_ratio": 1.5775401069518717, "no_speech_prob": 1.1792226359830238e-05}, {"id": 162, "seek": 95096, "start": 959.8000000000001, "end": 967.08, "text": " and accepted, and after that, we were able to implement those semantics in RunC.", "tokens": [293, 9035, 11, 293, 934, 300, 11, 321, 645, 1075, 281, 4445, 729, 4361, 45298, 294, 8950, 34, 13], "temperature": 0.0, "avg_logprob": -0.1329833525645582, "compression_ratio": 1.5775401069518717, "no_speech_prob": 1.1792226359830238e-05}, {"id": 163, "seek": 95096, "start": 967.08, "end": 968.36, "text": " So what are the semantics?", "tokens": [407, 437, 366, 264, 4361, 45298, 30], "temperature": 0.0, "avg_logprob": -0.1329833525645582, "compression_ratio": 1.5775401069518717, "no_speech_prob": 1.1792226359830238e-05}, {"id": 164, "seek": 95096, "start": 968.36, "end": 976.48, "text": " Well, the container's C-group will be choned to the host UID matching the process UID in", "tokens": [1042, 11, 264, 10129, 311, 383, 12, 17377, 486, 312, 417, 19009, 281, 264, 3975, 624, 2777, 14324, 264, 1399, 624, 2777, 294], "temperature": 0.0, "avg_logprob": -0.1329833525645582, "compression_ratio": 1.5775401069518717, "no_speech_prob": 1.1792226359830238e-05}, {"id": 165, "seek": 97648, "start": 976.48, "end": 984.24, "text": " the container's user namespace, if and only if the node is using C-groups V2, and the", "tokens": [264, 10129, 311, 4195, 5288, 17940, 11, 498, 293, 787, 498, 264, 9984, 307, 1228, 383, 12, 17377, 82, 691, 17, 11, 293, 264], "temperature": 0.0, "avg_logprob": -0.16704959404177783, "compression_ratio": 1.6625766871165644, "no_speech_prob": 5.491313913807971e-06}, {"id": 166, "seek": 97648, "start": 984.24, "end": 994.2, "text": " container has its own C-group namespace and the C-group FS is mounted read-write.", "tokens": [10129, 575, 1080, 1065, 383, 12, 17377, 5288, 17940, 293, 264, 383, 12, 17377, 41138, 307, 19138, 1401, 12, 21561, 13], "temperature": 0.0, "avg_logprob": -0.16704959404177783, "compression_ratio": 1.6625766871165644, "no_speech_prob": 5.491313913807971e-06}, {"id": 167, "seek": 97648, "start": 994.2, "end": 1001.32, "text": " So only the C-group directory itself and the files mentioned in sys-kernel C-group delegate", "tokens": [407, 787, 264, 383, 12, 17377, 21120, 2564, 293, 264, 7098, 2835, 294, 262, 749, 12, 74, 1248, 338, 383, 12, 17377, 40999], "temperature": 0.0, "avg_logprob": -0.16704959404177783, "compression_ratio": 1.6625766871165644, "no_speech_prob": 5.491313913807971e-06}, {"id": 168, "seek": 97648, "start": 1001.32, "end": 1002.5600000000001, "text": " are choned.", "tokens": [366, 417, 19009, 13], "temperature": 0.0, "avg_logprob": -0.16704959404177783, "compression_ratio": 1.6625766871165644, "no_speech_prob": 5.491313913807971e-06}, {"id": 169, "seek": 100256, "start": 1002.56, "end": 1011.5999999999999, "text": " These are the ones that are safe to delegate to a sub-process.", "tokens": [1981, 366, 264, 2306, 300, 366, 3273, 281, 40999, 281, 257, 1422, 12, 41075, 13], "temperature": 0.0, "avg_logprob": -0.10741652472544524, "compression_ratio": 1.4825174825174825, "no_speech_prob": 9.449742719880305e-06}, {"id": 170, "seek": 100256, "start": 1011.5999999999999, "end": 1018.3599999999999, "text": " And the container runtime, if that file sys-kernel C-group delegate is defined, then it will", "tokens": [400, 264, 10129, 34474, 11, 498, 300, 3991, 262, 749, 12, 74, 1248, 338, 383, 12, 17377, 40999, 307, 7642, 11, 550, 309, 486], "temperature": 0.0, "avg_logprob": -0.10741652472544524, "compression_ratio": 1.4825174825174825, "no_speech_prob": 9.449742719880305e-06}, {"id": 171, "seek": 100256, "start": 1018.3599999999999, "end": 1023.68, "text": " read that file and only chone the files mentioned there.", "tokens": [1401, 300, 3991, 293, 787, 417, 546, 264, 7098, 2835, 456, 13], "temperature": 0.0, "avg_logprob": -0.10741652472544524, "compression_ratio": 1.4825174825174825, "no_speech_prob": 9.449742719880305e-06}, {"id": 172, "seek": 102368, "start": 1023.68, "end": 1033.12, "text": " So it can respond to the evolution of the kernel where new C-group nodes may come and", "tokens": [407, 309, 393, 4196, 281, 264, 9303, 295, 264, 28256, 689, 777, 383, 12, 17377, 13891, 815, 808, 293], "temperature": 0.0, "avg_logprob": -0.08314974648611886, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.0865522199310362e-05}, {"id": 173, "seek": 102368, "start": 1033.12, "end": 1039.44, "text": " go, some of them may be safe to delegate, some of them may not.", "tokens": [352, 11, 512, 295, 552, 815, 312, 3273, 281, 40999, 11, 512, 295, 552, 815, 406, 13], "temperature": 0.0, "avg_logprob": -0.08314974648611886, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.0865522199310362e-05}, {"id": 174, "seek": 102368, "start": 1039.44, "end": 1044.36, "text": " In OpenShift, C-groups V2 is not yet the default when you deploy a cluster, but it does work", "tokens": [682, 7238, 7774, 2008, 11, 383, 12, 17377, 82, 691, 17, 307, 406, 1939, 264, 7576, 562, 291, 7274, 257, 13630, 11, 457, 309, 775, 589], "temperature": 0.0, "avg_logprob": -0.08314974648611886, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.0865522199310362e-05}, {"id": 175, "seek": 104436, "start": 1044.36, "end": 1055.28, "text": " and it is supported, and to activate the C-group choned semantics that I just explained, we", "tokens": [293, 309, 307, 8104, 11, 293, 281, 13615, 264, 383, 12, 17377, 417, 19009, 4361, 45298, 300, 286, 445, 8825, 11, 321], "temperature": 0.0, "avg_logprob": -0.2144859977390455, "compression_ratio": 1.2682926829268293, "no_speech_prob": 1.2115228855691385e-05}, {"id": 176, "seek": 104436, "start": 1055.28, "end": 1061.1599999999999, "text": " still require an annotation in the pod spec.", "tokens": [920, 3651, 364, 48654, 294, 264, 2497, 1608, 13], "temperature": 0.0, "avg_logprob": -0.2144859977390455, "compression_ratio": 1.2682926829268293, "no_speech_prob": 1.2115228855691385e-05}, {"id": 177, "seek": 104436, "start": 1061.1599999999999, "end": 1066.32, "text": " So let's do a demo.", "tokens": [407, 718, 311, 360, 257, 10723, 13], "temperature": 0.0, "avg_logprob": -0.2144859977390455, "compression_ratio": 1.2682926829268293, "no_speech_prob": 1.2115228855691385e-05}, {"id": 178, "seek": 106632, "start": 1066.32, "end": 1077.28, "text": " Here's a cluster I prepared earlier, and we can see new project test, okay, OC create", "tokens": [1692, 311, 257, 13630, 286, 4927, 3071, 11, 293, 321, 393, 536, 777, 1716, 1500, 11, 1392, 11, 42278, 1884], "temperature": 0.0, "avg_logprob": -0.26235468975909343, "compression_ratio": 1.485207100591716, "no_speech_prob": 2.821802263497375e-05}, {"id": 179, "seek": 106632, "start": 1077.28, "end": 1083.3999999999999, "text": " user test, maybe test already exists, okay, we'll just use test.", "tokens": [4195, 1500, 11, 1310, 1500, 1217, 8198, 11, 1392, 11, 321, 603, 445, 764, 1500, 13], "temperature": 0.0, "avg_logprob": -0.26235468975909343, "compression_ratio": 1.485207100591716, "no_speech_prob": 2.821802263497375e-05}, {"id": 180, "seek": 106632, "start": 1083.3999999999999, "end": 1092.6399999999999, "text": " So we can now, oh, well, I'll show you the pod I'm going to create, cat pod nginx, host", "tokens": [407, 321, 393, 586, 11, 1954, 11, 731, 11, 286, 603, 855, 291, 264, 2497, 286, 478, 516, 281, 1884, 11, 3857, 2497, 297, 1494, 87, 11, 3975], "temperature": 0.0, "avg_logprob": -0.26235468975909343, "compression_ratio": 1.485207100591716, "no_speech_prob": 2.821802263497375e-05}, {"id": 181, "seek": 106632, "start": 1092.6399999999999, "end": 1094.36, "text": " users false.", "tokens": [5022, 7908, 13], "temperature": 0.0, "avg_logprob": -0.26235468975909343, "compression_ratio": 1.485207100591716, "no_speech_prob": 2.821802263497375e-05}, {"id": 182, "seek": 109436, "start": 1094.36, "end": 1102.84, "text": " So this is a pod spec, let's get some syntax highlighting.", "tokens": [407, 341, 307, 257, 2497, 1608, 11, 718, 311, 483, 512, 28431, 26551, 13], "temperature": 0.0, "avg_logprob": -0.1714875523636981, "compression_ratio": 1.5942857142857143, "no_speech_prob": 1.7113337889895774e-05}, {"id": 183, "seek": 109436, "start": 1102.84, "end": 1110.12, "text": " This is going to run nginx, it's a system D based workload, so it's a fedora system", "tokens": [639, 307, 516, 281, 1190, 297, 1494, 87, 11, 309, 311, 257, 1185, 413, 2361, 20139, 11, 370, 309, 311, 257, 4636, 3252, 1185], "temperature": 0.0, "avg_logprob": -0.1714875523636981, "compression_ratio": 1.5942857142857143, "no_speech_prob": 1.7113337889895774e-05}, {"id": 184, "seek": 109436, "start": 1110.12, "end": 1118.24, "text": " that will come up and system D will run and it will start nginx.", "tokens": [300, 486, 808, 493, 293, 1185, 413, 486, 1190, 293, 309, 486, 722, 297, 1494, 87, 13], "temperature": 0.0, "avg_logprob": -0.1714875523636981, "compression_ratio": 1.5942857142857143, "no_speech_prob": 1.7113337889895774e-05}, {"id": 185, "seek": 109436, "start": 1118.24, "end": 1122.28, "text": " We're setting host users false so that it will run in a user namespace.", "tokens": [492, 434, 3287, 3975, 5022, 7908, 370, 300, 309, 486, 1190, 294, 257, 4195, 5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.1714875523636981, "compression_ratio": 1.5942857142857143, "no_speech_prob": 1.7113337889895774e-05}, {"id": 186, "seek": 112228, "start": 1122.28, "end": 1129.72, "text": " I have already enabled the feature flag on this cluster.", "tokens": [286, 362, 1217, 15172, 264, 4111, 7166, 322, 341, 13630, 13], "temperature": 0.0, "avg_logprob": -0.3369533197203679, "compression_ratio": 1.3773584905660377, "no_speech_prob": 3.587402170524001e-05}, {"id": 187, "seek": 112228, "start": 1129.72, "end": 1137.76, "text": " There's that annotation for the C-group choned, and the name of the pod will be nginx, so", "tokens": [821, 311, 300, 48654, 337, 264, 383, 12, 17377, 417, 19009, 11, 293, 264, 1315, 295, 264, 2497, 486, 312, 297, 1494, 87, 11, 370], "temperature": 0.0, "avg_logprob": -0.3369533197203679, "compression_ratio": 1.3773584905660377, "no_speech_prob": 3.587402170524001e-05}, {"id": 188, "seek": 112228, "start": 1137.76, "end": 1139.44, "text": " let's create that.", "tokens": [718, 311, 1884, 300, 13], "temperature": 0.0, "avg_logprob": -0.3369533197203679, "compression_ratio": 1.3773584905660377, "no_speech_prob": 3.587402170524001e-05}, {"id": 189, "seek": 112228, "start": 1139.44, "end": 1145.3999999999999, "text": " So OC as test, create a share.", "tokens": [407, 42278, 382, 1500, 11, 1884, 257, 2073, 13], "temperature": 0.0, "avg_logprob": -0.3369533197203679, "compression_ratio": 1.3773584905660377, "no_speech_prob": 3.587402170524001e-05}, {"id": 190, "seek": 112228, "start": 1145.3999999999999, "end": 1151.12, "text": " Okay, fingers crossed.", "tokens": [1033, 11, 7350, 14622, 13], "temperature": 0.0, "avg_logprob": -0.3369533197203679, "compression_ratio": 1.3773584905660377, "no_speech_prob": 3.587402170524001e-05}, {"id": 191, "seek": 115112, "start": 1151.12, "end": 1169.36, "text": " Okay, so we'll say OC admin policy add role to user edit, okay, let's try that again.", "tokens": [1033, 11, 370, 321, 603, 584, 42278, 24236, 3897, 909, 3090, 281, 4195, 8129, 11, 1392, 11, 718, 311, 853, 300, 797, 13], "temperature": 0.0, "avg_logprob": -0.19724102020263673, "compression_ratio": 1.3153846153846154, "no_speech_prob": 2.3855403924244456e-05}, {"id": 192, "seek": 115112, "start": 1169.36, "end": 1177.04, "text": " So the pod has been created, and we'll just check it's status to see which node it is", "tokens": [407, 264, 2497, 575, 668, 2942, 11, 293, 321, 603, 445, 1520, 309, 311, 6558, 281, 536, 597, 9984, 309, 307], "temperature": 0.0, "avg_logprob": -0.19724102020263673, "compression_ratio": 1.3153846153846154, "no_speech_prob": 2.3855403924244456e-05}, {"id": 193, "seek": 117704, "start": 1177.04, "end": 1185.84, "text": " running on, and it hasn't yet started, so we don't have a container ID for it yet, but", "tokens": [2614, 322, 11, 293, 309, 6132, 380, 1939, 1409, 11, 370, 321, 500, 380, 362, 257, 10129, 7348, 337, 309, 1939, 11, 457], "temperature": 0.0, "avg_logprob": -0.26180486245588824, "compression_ratio": 1.2654867256637168, "no_speech_prob": 3.4788161428878084e-05}, {"id": 194, "seek": 117704, "start": 1185.84, "end": 1194.3999999999999, "text": " in the upper pane, I'll get a shell on that worker node.", "tokens": [294, 264, 6597, 32605, 11, 286, 603, 483, 257, 8720, 322, 300, 11346, 9984, 13], "temperature": 0.0, "avg_logprob": -0.26180486245588824, "compression_ratio": 1.2654867256637168, "no_speech_prob": 3.4788161428878084e-05}, {"id": 195, "seek": 119440, "start": 1194.4, "end": 1209.92, "text": " Okay, pod is now running, so we can run cry control, inspect, container ID, and we'll", "tokens": [1033, 11, 2497, 307, 586, 2614, 11, 370, 321, 393, 1190, 3305, 1969, 11, 15018, 11, 10129, 7348, 11, 293, 321, 603], "temperature": 0.0, "avg_logprob": -0.15585050128755115, "compression_ratio": 1.1743119266055047, "no_speech_prob": 2.9643300877069123e-05}, {"id": 196, "seek": 119440, "start": 1209.92, "end": 1215.8400000000001, "text": " just pull out the PID, so this is our PID.", "tokens": [445, 2235, 484, 264, 430, 2777, 11, 370, 341, 307, 527, 430, 2777, 13], "temperature": 0.0, "avg_logprob": -0.15585050128755115, "compression_ratio": 1.1743119266055047, "no_speech_prob": 2.9643300877069123e-05}, {"id": 197, "seek": 121584, "start": 1215.84, "end": 1227.32, "text": " Now if we have a look at the user ID map for this process, okay, so here we see that", "tokens": [823, 498, 321, 362, 257, 574, 412, 264, 4195, 7348, 4471, 337, 341, 1399, 11, 1392, 11, 370, 510, 321, 536, 300], "temperature": 0.0, "avg_logprob": -0.10246211655285893, "compression_ratio": 1.3902439024390243, "no_speech_prob": 1.764094668033067e-05}, {"id": 198, "seek": 121584, "start": 1227.32, "end": 1242.04, "text": " we have a user namespace with the user ID mapping of size 65536, which is mapping user", "tokens": [321, 362, 257, 4195, 5288, 17940, 365, 264, 4195, 7348, 18350, 295, 2744, 11624, 20, 11309, 11, 597, 307, 18350, 4195], "temperature": 0.0, "avg_logprob": -0.10246211655285893, "compression_ratio": 1.3902439024390243, "no_speech_prob": 1.764094668033067e-05}, {"id": 199, "seek": 124204, "start": 1242.04, "end": 1253.96, "text": " ID 0 in the container's user namespace to user ID 131072 in the host user namespace.", "tokens": [7348, 1958, 294, 264, 10129, 311, 4195, 5288, 17940, 281, 4195, 7348, 3705, 3279, 28890, 294, 264, 3975, 4195, 5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.2503970718383789, "compression_ratio": 1.3410852713178294, "no_speech_prob": 1.5609251931891777e-05}, {"id": 200, "seek": 124204, "start": 1253.96, "end": 1262.1599999999999, "text": " And now we can look at the processes that are actually running there, so we'll do pgrep,", "tokens": [400, 586, 321, 393, 574, 412, 264, 7555, 300, 366, 767, 2614, 456, 11, 370, 321, 603, 360, 280, 70, 19919, 11], "temperature": 0.0, "avg_logprob": -0.2503970718383789, "compression_ratio": 1.3410852713178294, "no_speech_prob": 1.5609251931891777e-05}, {"id": 201, "seek": 126216, "start": 1262.16, "end": 1272.68, "text": " l-ns says show me everything with the same set of namespaces as this process ID, and", "tokens": [287, 12, 3695, 1619, 855, 385, 1203, 365, 264, 912, 992, 295, 5288, 79, 2116, 382, 341, 1399, 7348, 11, 293], "temperature": 0.0, "avg_logprob": -0.27393040414583886, "compression_ratio": 1.3576642335766422, "no_speech_prob": 1.706252442090772e-05}, {"id": 202, "seek": 126216, "start": 1272.68, "end": 1284.8000000000002, "text": " then I'll just pipe that to PS, let's print the user, the PID, and the command, sorting", "tokens": [550, 286, 603, 445, 11240, 300, 281, 8168, 11, 718, 311, 4482, 264, 4195, 11, 264, 430, 2777, 11, 293, 264, 5622, 11, 32411], "temperature": 0.0, "avg_logprob": -0.27393040414583886, "compression_ratio": 1.3576642335766422, "no_speech_prob": 1.706252442090772e-05}, {"id": 203, "seek": 126216, "start": 1284.8000000000002, "end": 1288.3600000000001, "text": " by PID, okay.", "tokens": [538, 430, 2777, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.27393040414583886, "compression_ratio": 1.3576642335766422, "no_speech_prob": 1.706252442090772e-05}, {"id": 204, "seek": 128836, "start": 1288.36, "end": 1300.52, "text": " So we can see that this container is running, well, in it, and then bunch of systemd processes,", "tokens": [407, 321, 393, 536, 300, 341, 10129, 307, 2614, 11, 731, 11, 294, 309, 11, 293, 550, 3840, 295, 1185, 67, 7555, 11], "temperature": 0.0, "avg_logprob": -0.2199045315123441, "compression_ratio": 1.4166666666666667, "no_speech_prob": 1.2349368262221105e-05}, {"id": 205, "seek": 128836, "start": 1300.52, "end": 1314.6, "text": " and then eventually nginx, and these are running under, see, 131072, yeah, 132071, yeah, so", "tokens": [293, 550, 4728, 297, 1494, 87, 11, 293, 613, 366, 2614, 833, 11, 536, 11, 3705, 3279, 28890, 11, 1338, 11, 3705, 2009, 29985, 11, 1338, 11, 370], "temperature": 0.0, "avg_logprob": -0.2199045315123441, "compression_ratio": 1.4166666666666667, "no_speech_prob": 1.2349368262221105e-05}, {"id": 206, "seek": 131460, "start": 1314.6, "end": 1324.36, "text": " these are running as various user IDs in the container's user namespace, and those are", "tokens": [613, 366, 2614, 382, 3683, 4195, 48212, 294, 264, 10129, 311, 4195, 5288, 17940, 11, 293, 729, 366], "temperature": 0.0, "avg_logprob": -0.1529017110024729, "compression_ratio": 1.5364238410596027, "no_speech_prob": 7.021161763987038e-06}, {"id": 207, "seek": 131460, "start": 1324.36, "end": 1330.6399999999999, "text": " being mapped to the host user ID namespace as these PIDs.", "tokens": [885, 33318, 281, 264, 3975, 4195, 7348, 5288, 17940, 382, 613, 430, 2777, 82, 13], "temperature": 0.0, "avg_logprob": -0.1529017110024729, "compression_ratio": 1.5364238410596027, "no_speech_prob": 7.021161763987038e-06}, {"id": 208, "seek": 131460, "start": 1330.6399999999999, "end": 1341.12, "text": " If we look at the logs, we can see that it looks like a regular systemd system has come", "tokens": [759, 321, 574, 412, 264, 20820, 11, 321, 393, 536, 300, 309, 1542, 411, 257, 3890, 1185, 67, 1185, 575, 808], "temperature": 0.0, "avg_logprob": -0.1529017110024729, "compression_ratio": 1.5364238410596027, "no_speech_prob": 7.021161763987038e-06}, {"id": 209, "seek": 134112, "start": 1341.12, "end": 1362.6799999999998, "text": " up, indeed it has, and let's see, I see, maybe we'll get a shell on the node, on the pod,", "tokens": [493, 11, 6451, 309, 575, 11, 293, 718, 311, 536, 11, 286, 536, 11, 1310, 321, 603, 483, 257, 8720, 322, 264, 9984, 11, 322, 264, 2497, 11], "temperature": 0.0, "avg_logprob": -0.17215227197717736, "compression_ratio": 1.4112903225806452, "no_speech_prob": 3.853003727272153e-05}, {"id": 210, "seek": 134112, "start": 1362.6799999999998, "end": 1368.84, "text": " and yeah, if we have a look at what is the container's view of the processes that are", "tokens": [293, 1338, 11, 498, 321, 362, 257, 574, 412, 437, 307, 264, 10129, 311, 1910, 295, 264, 7555, 300, 366], "temperature": 0.0, "avg_logprob": -0.17215227197717736, "compression_ratio": 1.4112903225806452, "no_speech_prob": 3.853003727272153e-05}, {"id": 211, "seek": 136884, "start": 1368.84, "end": 1377.52, "text": " running, it sees that systemd is running as root or other systemd-related users inside", "tokens": [2614, 11, 309, 8194, 300, 1185, 67, 307, 2614, 382, 5593, 420, 661, 1185, 67, 12, 12004, 5022, 1854], "temperature": 0.0, "avg_logprob": -0.13749576807022096, "compression_ratio": 1.74375, "no_speech_prob": 2.235771535197273e-05}, {"id": 212, "seek": 136884, "start": 1377.52, "end": 1385.8799999999999, "text": " the container's user namespace, nginx is running as the nginx user in that container's user", "tokens": [264, 10129, 311, 4195, 5288, 17940, 11, 297, 1494, 87, 307, 2614, 382, 264, 297, 1494, 87, 4195, 294, 300, 10129, 311, 4195], "temperature": 0.0, "avg_logprob": -0.13749576807022096, "compression_ratio": 1.74375, "no_speech_prob": 2.235771535197273e-05}, {"id": 213, "seek": 136884, "start": 1385.8799999999999, "end": 1391.1999999999998, "text": " namespace, but as we saw, these are all mapped to unprivileged host UIDs in the host user", "tokens": [5288, 17940, 11, 457, 382, 321, 1866, 11, 613, 366, 439, 33318, 281, 20994, 29994, 794, 3004, 3975, 624, 2777, 82, 294, 264, 3975, 4195], "temperature": 0.0, "avg_logprob": -0.13749576807022096, "compression_ratio": 1.74375, "no_speech_prob": 2.235771535197273e-05}, {"id": 214, "seek": 136884, "start": 1391.1999999999998, "end": 1396.8, "text": " namespace.", "tokens": [5288, 17940, 13], "temperature": 0.0, "avg_logprob": -0.13749576807022096, "compression_ratio": 1.74375, "no_speech_prob": 2.235771535197273e-05}, {"id": 215, "seek": 139680, "start": 1396.8, "end": 1403.24, "text": " So that concludes the demo, here's a link to various resources, I have a lot of blog", "tokens": [407, 300, 24643, 264, 10723, 11, 510, 311, 257, 2113, 281, 3683, 3593, 11, 286, 362, 257, 688, 295, 6968], "temperature": 0.0, "avg_logprob": -0.17233778356195806, "compression_ratio": 1.5148936170212766, "no_speech_prob": 4.18137751694303e-05}, {"id": 216, "seek": 139680, "start": 1403.24, "end": 1408.6399999999999, "text": " posts on this and related topics, so you can hit my blog and just look at the containers", "tokens": [12300, 322, 341, 293, 4077, 8378, 11, 370, 291, 393, 2045, 452, 6968, 293, 445, 574, 412, 264, 17089], "temperature": 0.0, "avg_logprob": -0.17233778356195806, "compression_ratio": 1.5148936170212766, "no_speech_prob": 4.18137751694303e-05}, {"id": 217, "seek": 139680, "start": 1408.6399999999999, "end": 1418.48, "text": " tag, a recording of a demo or a similar demo, slightly earlier version, link to KEP127,", "tokens": [6162, 11, 257, 6613, 295, 257, 10723, 420, 257, 2531, 10723, 11, 4748, 3071, 3037, 11, 2113, 281, 591, 8929, 4762, 22, 11], "temperature": 0.0, "avg_logprob": -0.17233778356195806, "compression_ratio": 1.5148936170212766, "no_speech_prob": 4.18137751694303e-05}, {"id": 218, "seek": 139680, "start": 1418.48, "end": 1424.24, "text": " which is where all of the discussion around how to do the upstream support for user namespaces", "tokens": [597, 307, 689, 439, 295, 264, 5017, 926, 577, 281, 360, 264, 33915, 1406, 337, 4195, 5288, 79, 2116], "temperature": 0.0, "avg_logprob": -0.17233778356195806, "compression_ratio": 1.5148936170212766, "no_speech_prob": 4.18137751694303e-05}, {"id": 219, "seek": 142424, "start": 1424.24, "end": 1432.8, "text": " in Kubernetes, all of that discussion happened there, the OCI runtime spec is referenced there,", "tokens": [294, 23145, 11, 439, 295, 300, 5017, 2011, 456, 11, 264, 422, 25240, 34474, 1608, 307, 32734, 456, 11], "temperature": 0.0, "avg_logprob": -0.19662445469906456, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00028363088495098054}, {"id": 220, "seek": 142424, "start": 1432.8, "end": 1444.4, "text": " and that's it, so I think there is time for some questions.", "tokens": [293, 300, 311, 309, 11, 370, 286, 519, 456, 307, 565, 337, 512, 1651, 13], "temperature": 0.0, "avg_logprob": -0.19662445469906456, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00028363088495098054}, {"id": 221, "seek": 142424, "start": 1444.4, "end": 1450.44, "text": " Please stay seated until 25 so we can ask questions, okay, there's one in the back, do you want", "tokens": [2555, 1754, 20959, 1826, 3552, 370, 321, 393, 1029, 1651, 11, 1392, 11, 456, 311, 472, 294, 264, 646, 11, 360, 291, 528], "temperature": 0.0, "avg_logprob": -0.19662445469906456, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00028363088495098054}, {"id": 222, "seek": 142424, "start": 1450.44, "end": 1453.08, "text": " to read the one from the chat first?", "tokens": [281, 1401, 264, 472, 490, 264, 5081, 700, 30], "temperature": 0.0, "avg_logprob": -0.19662445469906456, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00028363088495098054}, {"id": 223, "seek": 145308, "start": 1453.08, "end": 1459.3999999999999, "text": " There's a question in chat, I don't see it anymore, it says, why would I want to run", "tokens": [821, 311, 257, 1168, 294, 5081, 11, 286, 500, 380, 536, 309, 3602, 11, 309, 1619, 11, 983, 576, 286, 528, 281, 1190], "temperature": 0.0, "avg_logprob": -0.16533992687861124, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0001807572116376832}, {"id": 224, "seek": 145308, "start": 1459.3999999999999, "end": 1464.08, "text": " systemd in a container, it's cool that it's possible with user namespaces, but I lack", "tokens": [1185, 67, 294, 257, 10129, 11, 309, 311, 1627, 300, 309, 311, 1944, 365, 4195, 5288, 79, 2116, 11, 457, 286, 5011], "temperature": 0.0, "avg_logprob": -0.16533992687861124, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0001807572116376832}, {"id": 225, "seek": 145308, "start": 1464.08, "end": 1466.6399999999999, "text": " an idea for use case.", "tokens": [364, 1558, 337, 764, 1389, 13], "temperature": 0.0, "avg_logprob": -0.16533992687861124, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0001807572116376832}, {"id": 226, "seek": 145308, "start": 1466.6399999999999, "end": 1474.3999999999999, "text": " So the use case is you have a complicated legacy workload that runs under systemd or", "tokens": [407, 264, 764, 1389, 307, 291, 362, 257, 6179, 11711, 20139, 300, 6676, 833, 1185, 67, 420], "temperature": 0.0, "avg_logprob": -0.16533992687861124, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0001807572116376832}, {"id": 227, "seek": 145308, "start": 1474.3999999999999, "end": 1480.6799999999998, "text": " makes assumptions about the environment it runs in, the user IDs that the different components", "tokens": [1669, 17695, 466, 264, 2823, 309, 6676, 294, 11, 264, 4195, 48212, 300, 264, 819, 6677], "temperature": 0.0, "avg_logprob": -0.16533992687861124, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0001807572116376832}, {"id": 228, "seek": 148068, "start": 1480.68, "end": 1487.64, "text": " are running as, you've got two choices, one is to spend a whole lot of upfront engineering", "tokens": [366, 2614, 382, 11, 291, 600, 658, 732, 7994, 11, 472, 307, 281, 3496, 257, 1379, 688, 295, 30264, 7043], "temperature": 0.0, "avg_logprob": -0.12195072855268206, "compression_ratio": 1.7188940092165899, "no_speech_prob": 3.694815677590668e-05}, {"id": 229, "seek": 148068, "start": 1487.64, "end": 1495.8400000000001, "text": " effort to break up that application and containerize it and make it a cloud native application,", "tokens": [4630, 281, 1821, 493, 300, 3861, 293, 10129, 1125, 309, 293, 652, 309, 257, 4588, 8470, 3861, 11], "temperature": 0.0, "avg_logprob": -0.12195072855268206, "compression_ratio": 1.7188940092165899, "no_speech_prob": 3.694815677590668e-05}, {"id": 230, "seek": 148068, "start": 1495.8400000000001, "end": 1500.76, "text": " which is expensive and typically has a long lead time, or you can just wrap that whole", "tokens": [597, 307, 5124, 293, 5850, 575, 257, 938, 1477, 565, 11, 420, 291, 393, 445, 7019, 300, 1379], "temperature": 0.0, "avg_logprob": -0.12195072855268206, "compression_ratio": 1.7188940092165899, "no_speech_prob": 3.694815677590668e-05}, {"id": 231, "seek": 148068, "start": 1500.76, "end": 1507.76, "text": " application up in a container and run it securely, hopefully, in a container orchestration platform", "tokens": [3861, 493, 294, 257, 10129, 293, 1190, 309, 38348, 11, 4696, 11, 294, 257, 10129, 14161, 2405, 3663], "temperature": 0.0, "avg_logprob": -0.12195072855268206, "compression_ratio": 1.7188940092165899, "no_speech_prob": 3.694815677590668e-05}, {"id": 232, "seek": 150776, "start": 1507.76, "end": 1514.64, "text": " and get the benefit of all of the scaling, networking, observability features that the", "tokens": [293, 483, 264, 5121, 295, 439, 295, 264, 21589, 11, 17985, 11, 9951, 2310, 4122, 300, 264], "temperature": 0.0, "avg_logprob": -0.13739761086397392, "compression_ratio": 1.5914893617021277, "no_speech_prob": 1.713777965051122e-05}, {"id": 233, "seek": 150776, "start": 1514.64, "end": 1520.84, "text": " orchestration platform gives you without having to spend that effort to bust your application", "tokens": [14161, 2405, 3663, 2709, 291, 1553, 1419, 281, 3496, 300, 4630, 281, 19432, 428, 3861], "temperature": 0.0, "avg_logprob": -0.13739761086397392, "compression_ratio": 1.5914893617021277, "no_speech_prob": 1.713777965051122e-05}, {"id": 234, "seek": 150776, "start": 1520.84, "end": 1523.56, "text": " into a hundred pieces.", "tokens": [666, 257, 3262, 3755, 13], "temperature": 0.0, "avg_logprob": -0.13739761086397392, "compression_ratio": 1.5914893617021277, "no_speech_prob": 1.713777965051122e-05}, {"id": 235, "seek": 150776, "start": 1523.56, "end": 1528.52, "text": " So I would say that that is the use case, I think it's a compelling one, if you were", "tokens": [407, 286, 576, 584, 300, 300, 307, 264, 764, 1389, 11, 286, 519, 309, 311, 257, 20050, 472, 11, 498, 291, 645], "temperature": 0.0, "avg_logprob": -0.13739761086397392, "compression_ratio": 1.5914893617021277, "no_speech_prob": 1.713777965051122e-05}, {"id": 236, "seek": 150776, "start": 1528.52, "end": 1533.68, "text": " building applications today you certainly wouldn't do that, but there are 100 million", "tokens": [2390, 5821, 965, 291, 3297, 2759, 380, 360, 300, 11, 457, 456, 366, 2319, 2459], "temperature": 0.0, "avg_logprob": -0.13739761086397392, "compression_ratio": 1.5914893617021277, "no_speech_prob": 1.713777965051122e-05}, {"id": 237, "seek": 153368, "start": 1533.68, "end": 1539.68, "text": " legacy applications out there and people don't want to break them up and change them.", "tokens": [11711, 5821, 484, 456, 293, 561, 500, 380, 528, 281, 1821, 552, 493, 293, 1319, 552, 13], "temperature": 0.0, "avg_logprob": -0.24822972329814783, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0002040265972027555}, {"id": 238, "seek": 153368, "start": 1539.68, "end": 1548.5600000000002, "text": " Hi, thanks for the talk, I'm actually doing this right now at my company, but basically", "tokens": [2421, 11, 3231, 337, 264, 751, 11, 286, 478, 767, 884, 341, 558, 586, 412, 452, 2237, 11, 457, 1936], "temperature": 0.0, "avg_logprob": -0.24822972329814783, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0002040265972027555}, {"id": 239, "seek": 153368, "start": 1548.5600000000002, "end": 1555.28, "text": " the container is running as privileged, so that's why it can access C group, it doesn't", "tokens": [264, 10129, 307, 2614, 382, 25293, 11, 370, 300, 311, 983, 309, 393, 2105, 383, 1594, 11, 309, 1177, 380], "temperature": 0.0, "avg_logprob": -0.24822972329814783, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0002040265972027555}, {"id": 240, "seek": 153368, "start": 1555.28, "end": 1562.76, "text": " use user namespaces, it just runs as a privilege, so I was wondering if using this method you", "tokens": [764, 4195, 5288, 79, 2116, 11, 309, 445, 6676, 382, 257, 12122, 11, 370, 286, 390, 6359, 498, 1228, 341, 3170, 291], "temperature": 0.0, "avg_logprob": -0.24822972329814783, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0002040265972027555}, {"id": 241, "seek": 156276, "start": 1562.76, "end": 1571.92, "text": " could set a memory max, memory high, or other values for some processes in the C group running", "tokens": [727, 992, 257, 4675, 11469, 11, 4675, 1090, 11, 420, 661, 4190, 337, 512, 7555, 294, 264, 383, 1594, 2614], "temperature": 0.0, "avg_logprob": -0.2249111557006836, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0003292652836535126}, {"id": 242, "seek": 156276, "start": 1571.92, "end": 1573.84, "text": " in the container, I mean.", "tokens": [294, 264, 10129, 11, 286, 914, 13], "temperature": 0.0, "avg_logprob": -0.2249111557006836, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0003292652836535126}, {"id": 243, "seek": 156276, "start": 1573.84, "end": 1577.96, "text": " I'm sorry, I couldn't hear the question because it's rather echo-y.", "tokens": [286, 478, 2597, 11, 286, 2809, 380, 1568, 264, 1168, 570, 309, 311, 2831, 14300, 12, 88, 13], "temperature": 0.0, "avg_logprob": -0.2249111557006836, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0003292652836535126}, {"id": 244, "seek": 156276, "start": 1577.96, "end": 1586.2, "text": " Sorry, yeah, so can you set memory high, memory max, values, CPU affinities, like all these", "tokens": [4919, 11, 1338, 11, 370, 393, 291, 992, 4675, 1090, 11, 4675, 11469, 11, 4190, 11, 13199, 2096, 259, 1088, 11, 411, 439, 613], "temperature": 0.0, "avg_logprob": -0.2249111557006836, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0003292652836535126}, {"id": 245, "seek": 156276, "start": 1586.2, "end": 1592.32, "text": " kinds of things you would set in the C group usually, can you set them from this particular", "tokens": [3685, 295, 721, 291, 576, 992, 294, 264, 383, 1594, 2673, 11, 393, 291, 992, 552, 490, 341, 1729], "temperature": 0.0, "avg_logprob": -0.2249111557006836, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0003292652836535126}, {"id": 246, "seek": 159232, "start": 1592.32, "end": 1594.4399999999998, "text": " use case of C groups in the container?", "tokens": [764, 1389, 295, 383, 3935, 294, 264, 10129, 30], "temperature": 0.0, "avg_logprob": -0.24636326958151425, "compression_ratio": 1.6261682242990654, "no_speech_prob": 0.00033230340341106057}, {"id": 247, "seek": 159232, "start": 1594.4399999999998, "end": 1601.2, "text": " Yes, absolutely, because the container still has its own C group namespace, so all of the", "tokens": [1079, 11, 3122, 11, 570, 264, 10129, 920, 575, 1080, 1065, 383, 1594, 5288, 17940, 11, 370, 439, 295, 264], "temperature": 0.0, "avg_logprob": -0.24636326958151425, "compression_ratio": 1.6261682242990654, "no_speech_prob": 0.00033230340341106057}, {"id": 248, "seek": 159232, "start": 1601.2, "end": 1607.96, "text": " standard C group confinement and resource limit capabilities can be used.", "tokens": [3832, 383, 1594, 41064, 293, 7684, 4948, 10862, 393, 312, 1143, 13], "temperature": 0.0, "avg_logprob": -0.24636326958151425, "compression_ratio": 1.6261682242990654, "no_speech_prob": 0.00033230340341106057}, {"id": 249, "seek": 159232, "start": 1607.96, "end": 1615.52, "text": " Okay, I guess I got confused by the list of values that were allowed to do a listed in", "tokens": [1033, 11, 286, 2041, 286, 658, 9019, 538, 264, 1329, 295, 4190, 300, 645, 4350, 281, 360, 257, 10052, 294], "temperature": 0.0, "avg_logprob": -0.24636326958151425, "compression_ratio": 1.6261682242990654, "no_speech_prob": 0.00033230340341106057}, {"id": 250, "seek": 159232, "start": 1615.52, "end": 1620.0, "text": " the previous slide, there was a restricted list of values.", "tokens": [264, 3894, 4137, 11, 456, 390, 257, 20608, 1329, 295, 4190, 13], "temperature": 0.0, "avg_logprob": -0.24636326958151425, "compression_ratio": 1.6261682242990654, "no_speech_prob": 0.00033230340341106057}, {"id": 251, "seek": 162000, "start": 1620.0, "end": 1629.44, "text": " Yeah, so those were just the particular files that need to be choned in order for a safe", "tokens": [865, 11, 370, 729, 645, 445, 264, 1729, 7098, 300, 643, 281, 312, 417, 19009, 294, 1668, 337, 257, 3273], "temperature": 0.0, "avg_logprob": -0.1352442310702416, "compression_ratio": 1.5542168674698795, "no_speech_prob": 4.546433410723694e-05}, {"id": 252, "seek": 162000, "start": 1629.44, "end": 1639.52, "text": " delegation of control of that branch of the C group hierarchy to another process, so", "tokens": [36602, 295, 1969, 295, 300, 9819, 295, 264, 383, 1594, 22333, 281, 1071, 1399, 11, 370], "temperature": 0.0, "avg_logprob": -0.1352442310702416, "compression_ratio": 1.5542168674698795, "no_speech_prob": 4.546433410723694e-05}, {"id": 253, "seek": 162000, "start": 1639.52, "end": 1648.48, "text": " you can still set on the C group directory all of the limits and the container won't", "tokens": [291, 393, 920, 992, 322, 264, 383, 1594, 21120, 439, 295, 264, 10406, 293, 264, 10129, 1582, 380], "temperature": 0.0, "avg_logprob": -0.1352442310702416, "compression_ratio": 1.5542168674698795, "no_speech_prob": 4.546433410723694e-05}, {"id": 254, "seek": 164848, "start": 1648.48, "end": 1654.8, "text": " be able to change those because those will not be choned to the container's process", "tokens": [312, 1075, 281, 1319, 729, 570, 729, 486, 406, 312, 417, 19009, 281, 264, 10129, 311, 1399], "temperature": 0.0, "avg_logprob": -0.24558824481386127, "compression_ratio": 1.1170212765957446, "no_speech_prob": 0.0004035929450765252}, {"id": 255, "seek": 164848, "start": 1654.8, "end": 1655.8, "text": " UID.", "tokens": [624, 2777, 13], "temperature": 0.0, "avg_logprob": -0.24558824481386127, "compression_ratio": 1.1170212765957446, "no_speech_prob": 0.0004035929450765252}, {"id": 256, "seek": 164848, "start": 1655.8, "end": 1678.3600000000001, "text": " Okay, thank you.", "tokens": [1033, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.24558824481386127, "compression_ratio": 1.1170212765957446, "no_speech_prob": 0.0004035929450765252}, {"id": 257, "seek": 167836, "start": 1678.36, "end": 1691.28, "text": " So I have a question regarding the CFFC group C-H own, so you mentioned it's going to be", "tokens": [407, 286, 362, 257, 1168, 8595, 264, 383, 6345, 34, 1594, 383, 12, 39, 1065, 11, 370, 291, 2835, 309, 311, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.23447881698608397, "compression_ratio": 1.359375, "no_speech_prob": 0.0010623104171827435}, {"id": 258, "seek": 167836, "start": 1691.28, "end": 1699.6799999999998, "text": " changed to the UID of the container, of the process container, can you do that if you", "tokens": [3105, 281, 264, 624, 2777, 295, 264, 10129, 11, 295, 264, 1399, 10129, 11, 393, 291, 360, 300, 498, 291], "temperature": 0.0, "avg_logprob": -0.23447881698608397, "compression_ratio": 1.359375, "no_speech_prob": 0.0010623104171827435}, {"id": 259, "seek": 169968, "start": 1699.68, "end": 1715.3600000000001, "text": " want to have several ports to run their own system D?", "tokens": [528, 281, 362, 2940, 18160, 281, 1190, 641, 1065, 1185, 413, 30], "temperature": 0.0, "avg_logprob": -0.20087179497106752, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.00031424537883140147}, {"id": 260, "seek": 169968, "start": 1715.3600000000001, "end": 1718.3600000000001, "text": " Is your question around can you do it in a nested way?", "tokens": [1119, 428, 1168, 926, 393, 291, 360, 309, 294, 257, 15646, 292, 636, 30], "temperature": 0.0, "avg_logprob": -0.20087179497106752, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.00031424537883140147}, {"id": 261, "seek": 169968, "start": 1718.3600000000001, "end": 1725.92, "text": " No, not in a nested way, you have three different ports which each port needs their own system", "tokens": [883, 11, 406, 294, 257, 15646, 292, 636, 11, 291, 362, 1045, 819, 18160, 597, 1184, 2436, 2203, 641, 1065, 1185], "temperature": 0.0, "avg_logprob": -0.20087179497106752, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.00031424537883140147}, {"id": 262, "seek": 169968, "start": 1725.92, "end": 1726.92, "text": " D.", "tokens": [413, 13], "temperature": 0.0, "avg_logprob": -0.20087179497106752, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.00031424537883140147}, {"id": 263, "seek": 169968, "start": 1726.92, "end": 1728.5600000000002, "text": " Yes, yes, absolutely.", "tokens": [1079, 11, 2086, 11, 3122, 13], "temperature": 0.0, "avg_logprob": -0.20087179497106752, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.00031424537883140147}, {"id": 264, "seek": 172856, "start": 1728.56, "end": 1736.3999999999999, "text": " So if I created more pods in my demo, you would see that they would then be mapped to", "tokens": [407, 498, 286, 2942, 544, 31925, 294, 452, 10723, 11, 291, 576, 536, 300, 436, 576, 550, 312, 33318, 281], "temperature": 0.0, "avg_logprob": -0.11053462539400373, "compression_ratio": 1.4366197183098592, "no_speech_prob": 3.0065179089433514e-05}, {"id": 265, "seek": 172856, "start": 1736.3999999999999, "end": 1745.24, "text": " different host UID ranges, so the limit is only how many of the range allocations can", "tokens": [819, 3975, 624, 2777, 22526, 11, 370, 264, 4948, 307, 787, 577, 867, 295, 264, 3613, 12660, 763, 393], "temperature": 0.0, "avg_logprob": -0.11053462539400373, "compression_ratio": 1.4366197183098592, "no_speech_prob": 3.0065179089433514e-05}, {"id": 266, "seek": 172856, "start": 1745.24, "end": 1749.6399999999999, "text": " you fit into the host UID range?", "tokens": [291, 3318, 666, 264, 3975, 624, 2777, 3613, 30], "temperature": 0.0, "avg_logprob": -0.11053462539400373, "compression_ratio": 1.4366197183098592, "no_speech_prob": 3.0065179089433514e-05}, {"id": 267, "seek": 174964, "start": 1749.64, "end": 1761.76, "text": " So the limit will be a little under 6.536 because the size of the host UID range on Linux by", "tokens": [407, 264, 4948, 486, 312, 257, 707, 833, 1386, 13, 20, 11309, 570, 264, 2744, 295, 264, 3975, 624, 2777, 3613, 322, 18734, 538], "temperature": 0.0, "avg_logprob": -0.25662797870058, "compression_ratio": 1.3372781065088757, "no_speech_prob": 0.00011207525676582009}, {"id": 268, "seek": 174964, "start": 1761.76, "end": 1767.0, "text": " default is 2 to the 32, yeah.", "tokens": [7576, 307, 568, 281, 264, 8858, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.25662797870058, "compression_ratio": 1.3372781065088757, "no_speech_prob": 0.00011207525676582009}, {"id": 269, "seek": 174964, "start": 1767.0, "end": 1774.68, "text": " Okay, I think we have time for one more question and thank you all for your patience.", "tokens": [1033, 11, 286, 519, 321, 362, 565, 337, 472, 544, 1168, 293, 1309, 291, 439, 337, 428, 14826, 13], "temperature": 0.0, "avg_logprob": -0.25662797870058, "compression_ratio": 1.3372781065088757, "no_speech_prob": 0.00011207525676582009}, {"id": 270, "seek": 174964, "start": 1774.68, "end": 1775.68, "text": " Thank you Fraser.", "tokens": [1044, 291, 49119, 13], "temperature": 0.0, "avg_logprob": -0.25662797870058, "compression_ratio": 1.3372781065088757, "no_speech_prob": 0.00011207525676582009}, {"id": 271, "seek": 177568, "start": 1775.68, "end": 1781.72, "text": " I just wanted to know if v2, secret v2 by default in OpenShift is on the road map yet", "tokens": [286, 445, 1415, 281, 458, 498, 371, 17, 11, 4054, 371, 17, 538, 7576, 294, 7238, 7774, 2008, 307, 322, 264, 3060, 4471, 1939], "temperature": 0.0, "avg_logprob": -0.23614683245668316, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0006386779714375734}, {"id": 272, "seek": 177568, "start": 1781.72, "end": 1785.44, "text": " and whether or not there's any sort of estimated time scale for that.", "tokens": [293, 1968, 420, 406, 456, 311, 604, 1333, 295, 14109, 565, 4373, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.23614683245668316, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0006386779714375734}, {"id": 273, "seek": 177568, "start": 1785.44, "end": 1791.28, "text": " Yes it is, yep, so there is a plan to eventually move to secret v2 as the default, I don't", "tokens": [1079, 309, 307, 11, 18633, 11, 370, 456, 307, 257, 1393, 281, 4728, 1286, 281, 4054, 371, 17, 382, 264, 7576, 11, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.23614683245668316, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0006386779714375734}, {"id": 274, "seek": 177568, "start": 1791.28, "end": 1796.3200000000002, "text": " know the exact time frame.", "tokens": [458, 264, 1900, 565, 3920, 13], "temperature": 0.0, "avg_logprob": -0.23614683245668316, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0006386779714375734}, {"id": 275, "seek": 177568, "start": 1796.3200000000002, "end": 1802.5600000000002, "text": " Thank you so much for your talk, thank you all for your patience and I know this sounds", "tokens": [1044, 291, 370, 709, 337, 428, 751, 11, 1309, 291, 439, 337, 428, 14826, 293, 286, 458, 341, 3263], "temperature": 0.0, "avg_logprob": -0.23614683245668316, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0006386779714375734}, {"id": 276, "seek": 180256, "start": 1802.56, "end": 1817.56, "text": " weird but you're free to leave.", "tokens": [50364, 3657, 457, 291, 434, 1737, 281, 1856, 13, 51114], "temperature": 0.0, "avg_logprob": -0.7161500670693137, "compression_ratio": 0.7948717948717948, "no_speech_prob": 0.0047437516041100025}], "language": "en"}