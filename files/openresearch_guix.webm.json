{"text": " So, sorry for the mess. It's a bit impressing all these people and so on. I'm Simon. I'm working as a research engineer in the University of Paris and I'm going here to present you Geeks to be able to do some reversible research and there is a group Geeks HPC which tried to apply Geeks tooling for scientific context. So, currently we are in a replication and reproducibility crisis. So, more than 70% of researchers are enabled to reproduce the results of peers or more than half are enabled to reproduce their own results. So, we have a big issue. So, there is many problems of this replication crisis and maybe one solution is open science. So, what does it mean open science? So, what does it mean science? Science means being transparent and collective activity. And what is a scientific result? Scientific result is some experiment. So, producing experimental data and then we have some numerical processing. So, to do that in today, we have different way because we need to communicate so we need to write results. So, we need open article to be able to read the results. We need to share the data. So, we have open data. We need to share the source code. But there is something that we never discuss is that all that need to be glued together because there is a numerical processing. So, we need to glue everything together. So, we need another one. We need a computational environment and this is really mean is one of the issue is that if this is not open, all the other stack is failing. So, that is the topic of today. How do we manage this computational environment? So, again, a result is a paper, some data and an analysis. And there is some parts which are mean possible to audit. For example, a paper, you can read it. A data, you can read the protocol that generates the data. You have analysis. You can read the script. But there is some part that are opaque. For example, the instrument, a telescope, a microscope. This is opaque. We don't know how it works. But there is something that is depend on our collective practice as researcher. And this is something that we can act on to do a better research. So, the question is to be able to eliminate at least this dependent and turn this as an auditable task to be really transparent. So, yeah, from my point of view, a computation and computing is just similar to an instrument. So, we should apply the same strategy that experimental people are applying for any instrument. And computing is just an experiment, in fact. So, the challenge about reputable science. From my point of view, there is two kinds. The first one is controlling the source of variation. What is different between this and that? So, between this computational environment and this computational environment. Because as with a telescope, for example, we want to know what is different between this telescope and this telescope to be sure that what we are observing is correct. So, from a scientific method, we need that the computational environment is transparent. And from a scientific knowledge viewpoint, what we are building together need to be independent. So, what I'm observing, you should observe the same. And this observation should be sustainable when the time is passing. We should be able to observe the same thing. Otherwise, it means that maybe we miss something. So, the big question today is with this kind of context, how do we redo later and elsewhere? So, I did something on my machine and you have to do this thing on your machine, for example, six months or one year or five years later, with the computer. And this is a big issue and is part of the reputable crisis in science from my point of view. So, what is a computational environment? Computational environment implies various points. For example, what is a source code? But, for example, if, say, I use Python and this script, okay, we have the source code of Python is in C and we have the source code of this Python script, okay. But the Python interpreter requires a C compiler. So, we need tools for building. And my script, for example, needs some Python library. So, we need also tools for running at runtime. So, and each tool has the same issue. What is the source code? What is the tools for building? And so, this is really reclusive. So, this is a big issue. And answering all these questions is controlling the source of variation. So, the question is, so, how do we capture the answer of all these questions? So, the question is not new. We have already tools, package manager, modified container. So, for example, with package manager, like APT for Debian, you can control this computational environment. But there is some issue. For example, how do you have several versions of open blasts on the same machine? It doesn't work really easily with Debian or with you and so on. So, there is fixes, but it's not really, I mean, practically, sometimes it's difficult. So, you have, to fix this issue, you have an environment manager, like Conda, PIP, Modifies, and so on. But this is really difficult because, for example, in Conda, how do you know how it is built? What is inside what you install? So, this is for transparency in science. Modifies, how do you use Modifies on the laptop? I think no one. And Docker is for container, Docker, Singularity, or whatever, is a strategy which generally based on the previous solution. So, in fact, you have exactly the same problems as the previous solution. It just helps to move stuff from one place to the other one, but it doesn't help to be able to have the correct thing in the first time. Geeks, in fact, is all these three solutions glued together. So, it tries to fix all the annoyance from each to have something, I mean, working, fixing all the issues of everything. So, Geeks is a package manager, like APT, UME, etc. It's transactional and declarative. It means that you can roll back, you can have a concurrent version, and so on. You can produce a pack, which is Docker images, for example. You can produce virtual machines, like Ansible for deploying on some machine. You can build a complete distribution, and it's also a self-came library, so you can extend Geeks. So, okay, the talk is 25 minutes. So, it's just a kind of aperitif before lunch. So, I don't speak about all that, because it's a little too much. So, I just speak about how Geeks help in open research from my point of view. So, I think it's really easy to try. You have just a script, and give a look before installing it. It's just a bar script, but check it. And you can install Geeks on any recent distribution. So, it's really easy to try. You are running Debian. You can try Geeks without installing the complete distribution. You can use Geeks on the top of any distribution, and it's really easy to try. Give a try. So, now, Geeks is just another package manager. So, you have the same command that you have in any package manager, for sharing packages, showing packages, installing packages, removing packages, and so on. It's exactly the same as any package manager. But you have some more functionality, like transactional. So, everything, you can do two actions in the same time. So, for example, removing and installing in the same transaction. Or you can roll back. So, for example, you install something, and you want to roll back to uninstall this thing without breaking nothing. So, okay, this is another package manager. But is it really another package manager? So, yeah, we can have, it's a command line. It's a, we install, remove without special privilege. So, this is nice. It's transactional. So, there is no broken state. We have been able to substitute. So, we don't have to wait hours and hours to have our binary. But this is nice. But what is really, really nice is decorative management. It means that everything is a configuration file with scheme. But you can declare everything. And you can produce isolated environment on the fly. This is something that's really helpful. And you can also see Geeks as a factory for the Docker images, for example. So, okay, this is all interesting feature. But why Geeks is reproducible? Or what does it mean it's reproducible? For reproducibility, we need to talk about what is a version. So, what is a version? Alice say, for example, I use GCC Adversion 11. Okay, nice. But what does it mean, concretely, I use GCC Adversion 11. It means that you need GCC, the compiler. But you also need AD, which is the linker. And you know, Binitils, for example. And the Jelitsi library. But the compiler GCC, it needs, for example, MPC, which is a package that does, I don't know what exactly. Anyway. And you need also MPFR and so on. And you have this kind of graph. And we can ask the question, is it the same GCC Adversion 11 if we replace this MPFR Adversion 4.1 by MPFR Adversion 4.0? Is it the same GCC or not? And maybe not. And if it is not the same, maybe you are feeling a difference. How can we be sure that we are using the exact same GCC? So this is just an extract of the graph because the graph have roots. And yeah, it can be really large. And maybe we can also talk about what are the roots of this graph. But this is another talk. So when you say that, okay, but I need to have a version. So what is my version in GICS? So GICS describe the state of GICS. So in fact, GICS describe is a version of GICS. And what it does, in fact, it pins the complete collection of all the packages and GICS itself. And because of that, we are able to freeze the complete graph. We can move this graph from one place to the other. So, okay. So this graph, in fact, describe the nodes of each, each, each node in this graph specify a receipt. And this receipt defines the code source, the build time tombs, and the dependency. So for me, yeah. And this graph can be really, really large. For example, for Skypy, which is a scientific Python library, there is more than 1,000 nodes. So, yeah, it can be really large. So for when I say GCC at version 11, it means one fixed graph. And providing the state which describe, this capture this complete graph. And I can reproduce this complete graph on another machine. So this is collaboration in action. So Alice describes the list of the tools in a manifest, declarative way. She generates the environment, GICS shell, and providing the tools. So this creates an environment containing the tools that are listed in the manifest file. Okay. This is nice. But now she describes the revision of GICS. So she writes GICS describe and this fix the state of Alice. So, okay, this Alice is working on her laptop. But collaboration is share this computational environment. So it's about sharing the state. To share this state, you need to share one specific graph. To share this graph, you need to only share these two files. And if, sorry, if Blake has these two files, Blake can create the exact same computational environment as Alice. So you have the GICS time machine. You specify the state of Alice shell and specify the tools that Alice used. And Blake and Alice are running the exact same computational environment. And for example, if you have Carol, who knows these two files, she also can reproduce the exact same that Alice and Blake. So, in fact, you only need two files. And with these two files, you can reproduce everything from one place to the other. So, in fact, you have this kind of picture. Alice, Blake, Carol are in different time frame. But they can jump from this time frame, virtually time different time frame, to the same place. Because their machine are in different state, but they can temporarily go to another state to create the computational environment. To make this work, when the time is passing, you need to preserve all the source code. And this is not straightforward. It is not trivial to preserve all the source code. And you also need some backward compatibility of the Linux kernel and some compatibility of the hardware. But, okay. And when these three conditions are satisfied, you have the reproducibility. But what is the size of the window, of the time window, where these three conditions are satisfied? And this is, from my point of view, unknown. And GICS is, to my knowledge, a case unique by experimenting to be able, because we have the tooling to do all that. And now we can know what is the size that we are able to reproduce the past in the future. So what is software heritage? So software heritage is an archive. It collects preserved software in source code form from a very long term. And GICS is able to save the source code of the package and the receipt of the package itself. And GICS itself is also saved in software heritage. And GICS is able to use software heritage archive to fall back if a swim disappears. So you have the postdoc working on some GitLab and Stance. And the account is closed because the postdoc is moving to other place and so on. And now you have this paper with this URL of, with the GitLab package and say, oh, no, it doesn't work because the account is closed. If you were using GICS transparently, you can check if the source code is on software heritage. And this asks really good question about how to see the software and do you notice it only the source or, and what about the dependency and the build time options and so on. How do you see the software? And how, I mean, how do you see this? Do you see it with intrinsic identifier like checksum or with intrinsic identifier like version label? This is easy. So in summary, there is three commands. I'm almost done, right? Yeah. So in summary, you have three commands. And these three commands, which are GICS shell, GICS time machine and GICS subscribe, they help you to have a computational environment that you can, I mean, inspect and collectively share. So if you have this and two files, manifest and channel files, you are reproducible over the time. So okay, for offline, when you are, because I hope I convince you that is cool. So here is some resources that to, to, to, to, to read offline. So GICS HPC is a group of people trying to apply this GICS tooling to, to, to, to, to scientific research. And we are organizing coffee gigs where we, we drink coffee and speak about GICS. There is a, an article trying to explain this kind of vision of what GICS could provide for, for open research. And for French speaker, there is a one hour tutorial. So yeah. And there is a, now GICS is tenure, so it's kind of ready. So they, we organize the ten years events where there is some really nice materials about, about GICS. And GICS is not new at first them. So yeah, there is, all the number are, are linked to, to the previous presentation. So as you see, there is a 31 presentation about GICS in first them. So you have a lot of material about what GICS can do for, for your job, for your task. So you run in production on big cluster, but also in a lot of laptop and desktop. And here, for example, is to paper in completely, I mean, medical and biomedical stuff using GICS as a, as, as tooling with, as, as I presented about GICS shell, time machine and so on. So, okay, open science means to be able to trace and transparent because is to be able to, to collectively study bug to bug, to be what is different from one thing to the other thing. And this is a scientific method and we have to apply the scientific method to the computational environment. This is my, my opinion and the message that I, I would like you bring back to home. And if you, if, if we have GICS, we can do that by controlling the environment and compare two different environment to know what is different. So, okay, this is, yeah, the kind of, what we are trying to, to do with the GICS project. So, thank you. And I'm ready for your question. Yeah. Yeah. So, we have five minutes for questions and switching speakers. Please take question and do repeat them for the stream. Thanks. I will try to do my best. Yeah. Yeah. Ah. Lobing. So, the question is, okay, I, I, I don't have the, the, the root privilege to install GICS on the cluster because once GICS is installed on any cluster, you can, you can run it without privilege, but you need to install, the first time you need to install GICS, you need root privilege. And the system administrator of my cluster doesn't mean, yeah, I need to convince him. So, maybe the, the answer is to say other people are, are already doing that. So, it's, it's not, I mean, to reduce the scare to, to, to provide a new tool. This is what I, I, I would like to try to say, okay, these people are doing, they're doing it. So, maybe it's not so scary. Uh, I think it was after, yeah. So, yeah. Yeah. You mentioned that you're not sure how, how big the time window is. Yeah. If you look today, how far can you back and still reproduce? So, five years, ten years? No. So, the, the question is, okay, what is the size of the window and can we go back five years, uh, from now in the past? The issue is that the, the mechanism to, to bring back in time or to, to, to travel in time in GICS, uh, had been introduced in, uh, 2019. So, in fact, with GICS, we don't have the tooling to go back earlier. So, now, I mean, the, the, the zero for GICS is, uh, is version one. So, it's, uh, 2019. Yeah. Um, a lot of, um, scientists are using macOS and not Linux. Is there, is it possible to use all this stuff even though GICS can't really run on macOS? So, GICS cannot run on macOS. But we can ask the question, is it transparent if we are running on macOS? So, is it, are we are playing scientific method if we are running on macOS? So, I mean, I, I, I, I, I have not the question. It's, it's a collective decision. Yeah. My name is Alain. Um, as far as I understand, uh, GICS, uh, or GICS, uh, provides the same approach as the NICS. Yeah. So, um, I've never used, uh, GICS before, but I, uh, I have some experience with NICS. Uh, is there any crucial difference? So, from my point of view, oops. Ah, sorry, anyway. Um, in the slides, there, there is a, some, uh, appendix. So, there is extra slides. And there is one extra slide trying to, to explain what, from my point of view, the difference with NICS. So, the question is, uh, what is the difference between NICS and, and GICS? Because NICS, you, I mean, GICS use exactly the same, uh, functional strategy, package management, functional strategy. So, what is the difference? From my point of view, the difference is that you have a continuum in GICS in the language. The package are, are, are, are wrote in scheme and, and, and, and the, the code of, uh, GICS itself is also wrote in scheme. The configuration file are wrote in scheme. So, you have a, a, a big continuation with everything. And because of that, you can extend GICS for your own, uh, uh, stuff. So, for example, you can write a package transformation on the fly using, I mean, GICS as a library. You cannot do that with, with NICS because you have a lot of different tooling in C++ and some, uh, from my point of view, is this unity of, of, of the, the, the, the continuum of the language. Yeah. Yeah. But scheme allow you to, to write kind of domain specific language. It's, it's, uh, it's, uh, it's, uh, yeah. It's, it's a, it's a good language to, to write domain specific language. So, in fact, you have the both of, of the two worlds. From my point of view. Thank you. Oh yeah. Sorry. Last question. Yeah. Uh, that's good. It's, it's, it's, it's a good language to, to write domain specific language. So, in fact, you have the both of, of the two worlds. From my point of view. Yeah. This is, uh, so, when you are running GICS, for example, on the top of Debian, so, uh, how do we manage the graph and can we cut the graph to reuse a part of the Debian part? I mean, a part of the graph from Debian. So, the question is, uh, maybe it could be, maybe it could be, maybe it could be, maybe it could be, a part of the graph from Debian. So, the question is, uh, maybe it could be helpful for some packages. But, but when you do that, you are not able to, to manage the computational environment. Because if you have, for example, if I cut the graph on Debian, so I have a, a state in, in Debian with some packages, I cut the graph at some place to use these Debian packages. If I do that, how my collaborator can cut the graph in the same place with the same Debian packages? So this is kind of issue of replicability. So from a practical point of view, it could be nice because, for example, Debian has some machine learning packages that are not yet in Geek, so maybe we can reuse some part. But from a replicability point of view, you lose the property to move from one place to the other.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 15.64, "text": " So, sorry for the mess. It's a bit impressing all these people and so on. I'm Simon. I'm", "tokens": [407, 11, 2597, 337, 264, 2082, 13, 467, 311, 257, 857, 6729, 278, 439, 613, 561, 293, 370, 322, 13, 286, 478, 13193, 13, 286, 478], "temperature": 0.0, "avg_logprob": -0.3711602020263672, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.41818955540657043}, {"id": 1, "seek": 0, "start": 15.64, "end": 23.080000000000002, "text": " working as a research engineer in the University of Paris and I'm going here to present you", "tokens": [1364, 382, 257, 2132, 11403, 294, 264, 3535, 295, 8380, 293, 286, 478, 516, 510, 281, 1974, 291], "temperature": 0.0, "avg_logprob": -0.3711602020263672, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.41818955540657043}, {"id": 2, "seek": 2308, "start": 23.08, "end": 35.839999999999996, "text": " Geeks to be able to do some reversible research and there is a group Geeks HPC which tried", "tokens": [2876, 24785, 281, 312, 1075, 281, 360, 512, 44788, 2132, 293, 456, 307, 257, 1594, 2876, 24785, 12557, 34, 597, 3031], "temperature": 0.0, "avg_logprob": -0.2653256522284614, "compression_ratio": 1.325925925925926, "no_speech_prob": 0.00047956022899597883}, {"id": 3, "seek": 2308, "start": 35.839999999999996, "end": 47.44, "text": " to apply Geeks tooling for scientific context. So, currently we are in a replication and", "tokens": [281, 3079, 2876, 24785, 46593, 337, 8134, 4319, 13, 407, 11, 4362, 321, 366, 294, 257, 39911, 293], "temperature": 0.0, "avg_logprob": -0.2653256522284614, "compression_ratio": 1.325925925925926, "no_speech_prob": 0.00047956022899597883}, {"id": 4, "seek": 4744, "start": 47.44, "end": 56.599999999999994, "text": " reproducibility crisis. So, more than 70% of researchers are enabled to reproduce the", "tokens": [11408, 537, 39802, 5869, 13, 407, 11, 544, 813, 5285, 4, 295, 10309, 366, 15172, 281, 29501, 264], "temperature": 0.0, "avg_logprob": -0.21689442225864955, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0003207641711924225}, {"id": 5, "seek": 4744, "start": 56.599999999999994, "end": 65.8, "text": " results of peers or more than half are enabled to reproduce their own results. So, we have", "tokens": [3542, 295, 16739, 420, 544, 813, 1922, 366, 15172, 281, 29501, 641, 1065, 3542, 13, 407, 11, 321, 362], "temperature": 0.0, "avg_logprob": -0.21689442225864955, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0003207641711924225}, {"id": 6, "seek": 4744, "start": 65.8, "end": 73.47999999999999, "text": " a big issue. So, there is many problems of this replication crisis and maybe one solution", "tokens": [257, 955, 2734, 13, 407, 11, 456, 307, 867, 2740, 295, 341, 39911, 5869, 293, 1310, 472, 3827], "temperature": 0.0, "avg_logprob": -0.21689442225864955, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0003207641711924225}, {"id": 7, "seek": 7348, "start": 73.48, "end": 80.48, "text": " is open science. So, what does it mean open science? So, what does it mean science? Science", "tokens": [307, 1269, 3497, 13, 407, 11, 437, 775, 309, 914, 1269, 3497, 30, 407, 11, 437, 775, 309, 914, 3497, 30, 8976], "temperature": 0.0, "avg_logprob": -0.1878314410938936, "compression_ratio": 1.8706467661691542, "no_speech_prob": 0.00033093406818807125}, {"id": 8, "seek": 7348, "start": 80.48, "end": 87.32000000000001, "text": " means being transparent and collective activity. And what is a scientific result? Scientific", "tokens": [1355, 885, 12737, 293, 12590, 5191, 13, 400, 437, 307, 257, 8134, 1874, 30, 47437], "temperature": 0.0, "avg_logprob": -0.1878314410938936, "compression_ratio": 1.8706467661691542, "no_speech_prob": 0.00033093406818807125}, {"id": 9, "seek": 7348, "start": 87.32000000000001, "end": 94.96000000000001, "text": " result is some experiment. So, producing experimental data and then we have some numerical processing.", "tokens": [1874, 307, 512, 5120, 13, 407, 11, 10501, 17069, 1412, 293, 550, 321, 362, 512, 29054, 9007, 13], "temperature": 0.0, "avg_logprob": -0.1878314410938936, "compression_ratio": 1.8706467661691542, "no_speech_prob": 0.00033093406818807125}, {"id": 10, "seek": 7348, "start": 94.96000000000001, "end": 102.12, "text": " So, to do that in today, we have different way because we need to communicate so we need", "tokens": [407, 11, 281, 360, 300, 294, 965, 11, 321, 362, 819, 636, 570, 321, 643, 281, 7890, 370, 321, 643], "temperature": 0.0, "avg_logprob": -0.1878314410938936, "compression_ratio": 1.8706467661691542, "no_speech_prob": 0.00033093406818807125}, {"id": 11, "seek": 10212, "start": 102.12, "end": 106.60000000000001, "text": " to write results. So, we need open article to be able to read the results. We need to", "tokens": [281, 2464, 3542, 13, 407, 11, 321, 643, 1269, 7222, 281, 312, 1075, 281, 1401, 264, 3542, 13, 492, 643, 281], "temperature": 0.0, "avg_logprob": -0.1582521812938084, "compression_ratio": 1.9330357142857142, "no_speech_prob": 0.00017166382167488337}, {"id": 12, "seek": 10212, "start": 106.60000000000001, "end": 112.24000000000001, "text": " share the data. So, we have open data. We need to share the source code. But there is", "tokens": [2073, 264, 1412, 13, 407, 11, 321, 362, 1269, 1412, 13, 492, 643, 281, 2073, 264, 4009, 3089, 13, 583, 456, 307], "temperature": 0.0, "avg_logprob": -0.1582521812938084, "compression_ratio": 1.9330357142857142, "no_speech_prob": 0.00017166382167488337}, {"id": 13, "seek": 10212, "start": 112.24000000000001, "end": 117.08000000000001, "text": " something that we never discuss is that all that need to be glued together because there", "tokens": [746, 300, 321, 1128, 2248, 307, 300, 439, 300, 643, 281, 312, 28008, 1214, 570, 456], "temperature": 0.0, "avg_logprob": -0.1582521812938084, "compression_ratio": 1.9330357142857142, "no_speech_prob": 0.00017166382167488337}, {"id": 14, "seek": 10212, "start": 117.08000000000001, "end": 121.68, "text": " is a numerical processing. So, we need to glue everything together. So, we need another", "tokens": [307, 257, 29054, 9007, 13, 407, 11, 321, 643, 281, 8998, 1203, 1214, 13, 407, 11, 321, 643, 1071], "temperature": 0.0, "avg_logprob": -0.1582521812938084, "compression_ratio": 1.9330357142857142, "no_speech_prob": 0.00017166382167488337}, {"id": 15, "seek": 10212, "start": 121.68, "end": 130.20000000000002, "text": " one. We need a computational environment and this is really mean is one of the issue", "tokens": [472, 13, 492, 643, 257, 28270, 2823, 293, 341, 307, 534, 914, 307, 472, 295, 264, 2734], "temperature": 0.0, "avg_logprob": -0.1582521812938084, "compression_ratio": 1.9330357142857142, "no_speech_prob": 0.00017166382167488337}, {"id": 16, "seek": 13020, "start": 130.2, "end": 139.39999999999998, "text": " is that if this is not open, all the other stack is failing. So, that is the topic of", "tokens": [307, 300, 498, 341, 307, 406, 1269, 11, 439, 264, 661, 8630, 307, 18223, 13, 407, 11, 300, 307, 264, 4829, 295], "temperature": 0.0, "avg_logprob": -0.1909634548684825, "compression_ratio": 1.4886363636363635, "no_speech_prob": 0.00020669390505645424}, {"id": 17, "seek": 13020, "start": 139.39999999999998, "end": 148.28, "text": " today. How do we manage this computational environment? So, again, a result is a paper,", "tokens": [965, 13, 1012, 360, 321, 3067, 341, 28270, 2823, 30, 407, 11, 797, 11, 257, 1874, 307, 257, 3035, 11], "temperature": 0.0, "avg_logprob": -0.1909634548684825, "compression_ratio": 1.4886363636363635, "no_speech_prob": 0.00020669390505645424}, {"id": 18, "seek": 13020, "start": 148.28, "end": 155.12, "text": " some data and an analysis. And there is some parts which are mean possible to audit. For", "tokens": [512, 1412, 293, 364, 5215, 13, 400, 456, 307, 512, 3166, 597, 366, 914, 1944, 281, 17748, 13, 1171], "temperature": 0.0, "avg_logprob": -0.1909634548684825, "compression_ratio": 1.4886363636363635, "no_speech_prob": 0.00020669390505645424}, {"id": 19, "seek": 15512, "start": 155.12, "end": 161.12, "text": " example, a paper, you can read it. A data, you can read the protocol that generates the", "tokens": [1365, 11, 257, 3035, 11, 291, 393, 1401, 309, 13, 316, 1412, 11, 291, 393, 1401, 264, 10336, 300, 23815, 264], "temperature": 0.0, "avg_logprob": -0.19243475596110027, "compression_ratio": 1.6682242990654206, "no_speech_prob": 0.00016384611080866307}, {"id": 20, "seek": 15512, "start": 161.12, "end": 166.4, "text": " data. You have analysis. You can read the script. But there is some part that are opaque.", "tokens": [1412, 13, 509, 362, 5215, 13, 509, 393, 1401, 264, 5755, 13, 583, 456, 307, 512, 644, 300, 366, 42687, 13], "temperature": 0.0, "avg_logprob": -0.19243475596110027, "compression_ratio": 1.6682242990654206, "no_speech_prob": 0.00016384611080866307}, {"id": 21, "seek": 15512, "start": 166.4, "end": 171.56, "text": " For example, the instrument, a telescope, a microscope. This is opaque. We don't know", "tokens": [1171, 1365, 11, 264, 7198, 11, 257, 26114, 11, 257, 29753, 13, 639, 307, 42687, 13, 492, 500, 380, 458], "temperature": 0.0, "avg_logprob": -0.19243475596110027, "compression_ratio": 1.6682242990654206, "no_speech_prob": 0.00016384611080866307}, {"id": 22, "seek": 15512, "start": 171.56, "end": 179.44, "text": " how it works. But there is something that is depend on our collective practice as researcher.", "tokens": [577, 309, 1985, 13, 583, 456, 307, 746, 300, 307, 5672, 322, 527, 12590, 3124, 382, 21751, 13], "temperature": 0.0, "avg_logprob": -0.19243475596110027, "compression_ratio": 1.6682242990654206, "no_speech_prob": 0.00016384611080866307}, {"id": 23, "seek": 17944, "start": 179.44, "end": 186.16, "text": " And this is something that we can act on to do a better research. So, the question is", "tokens": [400, 341, 307, 746, 300, 321, 393, 605, 322, 281, 360, 257, 1101, 2132, 13, 407, 11, 264, 1168, 307], "temperature": 0.0, "avg_logprob": -0.1733175249242071, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.0003415235842112452}, {"id": 24, "seek": 17944, "start": 186.16, "end": 197.32, "text": " to be able to eliminate at least this dependent and turn this as an auditable task to be really", "tokens": [281, 312, 1075, 281, 13819, 412, 1935, 341, 12334, 293, 1261, 341, 382, 364, 2379, 16772, 5633, 281, 312, 534], "temperature": 0.0, "avg_logprob": -0.1733175249242071, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.0003415235842112452}, {"id": 25, "seek": 17944, "start": 197.32, "end": 205.64, "text": " transparent. So, yeah, from my point of view, a computation and computing is just similar", "tokens": [12737, 13, 407, 11, 1338, 11, 490, 452, 935, 295, 1910, 11, 257, 24903, 293, 15866, 307, 445, 2531], "temperature": 0.0, "avg_logprob": -0.1733175249242071, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.0003415235842112452}, {"id": 26, "seek": 20564, "start": 205.64, "end": 212.92, "text": " to an instrument. So, we should apply the same strategy that experimental people are", "tokens": [281, 364, 7198, 13, 407, 11, 321, 820, 3079, 264, 912, 5206, 300, 17069, 561, 366], "temperature": 0.0, "avg_logprob": -0.15579294779944042, "compression_ratio": 1.4886363636363635, "no_speech_prob": 0.00011177523265359923}, {"id": 27, "seek": 20564, "start": 212.92, "end": 222.2, "text": " applying for any instrument. And computing is just an experiment, in fact. So, the challenge", "tokens": [9275, 337, 604, 7198, 13, 400, 15866, 307, 445, 364, 5120, 11, 294, 1186, 13, 407, 11, 264, 3430], "temperature": 0.0, "avg_logprob": -0.15579294779944042, "compression_ratio": 1.4886363636363635, "no_speech_prob": 0.00011177523265359923}, {"id": 28, "seek": 20564, "start": 222.2, "end": 228.79999999999998, "text": " about reputable science. From my point of view, there is two kinds. The first one is", "tokens": [466, 1085, 32148, 3497, 13, 3358, 452, 935, 295, 1910, 11, 456, 307, 732, 3685, 13, 440, 700, 472, 307], "temperature": 0.0, "avg_logprob": -0.15579294779944042, "compression_ratio": 1.4886363636363635, "no_speech_prob": 0.00011177523265359923}, {"id": 29, "seek": 22880, "start": 228.8, "end": 235.8, "text": " controlling the source of variation. What is different between this and that? So, between", "tokens": [14905, 264, 4009, 295, 12990, 13, 708, 307, 819, 1296, 341, 293, 300, 30, 407, 11, 1296], "temperature": 0.0, "avg_logprob": -0.1813284905402215, "compression_ratio": 2.013574660633484, "no_speech_prob": 0.00016525226237718016}, {"id": 30, "seek": 22880, "start": 235.8, "end": 241.52, "text": " this computational environment and this computational environment. Because as with a telescope,", "tokens": [341, 28270, 2823, 293, 341, 28270, 2823, 13, 1436, 382, 365, 257, 26114, 11], "temperature": 0.0, "avg_logprob": -0.1813284905402215, "compression_ratio": 2.013574660633484, "no_speech_prob": 0.00016525226237718016}, {"id": 31, "seek": 22880, "start": 241.52, "end": 246.8, "text": " for example, we want to know what is different between this telescope and this telescope", "tokens": [337, 1365, 11, 321, 528, 281, 458, 437, 307, 819, 1296, 341, 26114, 293, 341, 26114], "temperature": 0.0, "avg_logprob": -0.1813284905402215, "compression_ratio": 2.013574660633484, "no_speech_prob": 0.00016525226237718016}, {"id": 32, "seek": 22880, "start": 246.8, "end": 252.16000000000003, "text": " to be sure that what we are observing is correct. So, from a scientific method, we", "tokens": [281, 312, 988, 300, 437, 321, 366, 22107, 307, 3006, 13, 407, 11, 490, 257, 8134, 3170, 11, 321], "temperature": 0.0, "avg_logprob": -0.1813284905402215, "compression_ratio": 2.013574660633484, "no_speech_prob": 0.00016525226237718016}, {"id": 33, "seek": 22880, "start": 252.16000000000003, "end": 257.2, "text": " need that the computational environment is transparent. And from a scientific knowledge", "tokens": [643, 300, 264, 28270, 2823, 307, 12737, 13, 400, 490, 257, 8134, 3601], "temperature": 0.0, "avg_logprob": -0.1813284905402215, "compression_ratio": 2.013574660633484, "no_speech_prob": 0.00016525226237718016}, {"id": 34, "seek": 25720, "start": 257.2, "end": 263.32, "text": " viewpoint, what we are building together need to be independent. So, what I'm observing,", "tokens": [35248, 11, 437, 321, 366, 2390, 1214, 643, 281, 312, 6695, 13, 407, 11, 437, 286, 478, 22107, 11], "temperature": 0.0, "avg_logprob": -0.18277575752951883, "compression_ratio": 1.654867256637168, "no_speech_prob": 5.115521344123408e-05}, {"id": 35, "seek": 25720, "start": 263.32, "end": 270.32, "text": " you should observe the same. And this observation should be sustainable when the time is passing.", "tokens": [291, 820, 11441, 264, 912, 13, 400, 341, 14816, 820, 312, 11235, 562, 264, 565, 307, 8437, 13], "temperature": 0.0, "avg_logprob": -0.18277575752951883, "compression_ratio": 1.654867256637168, "no_speech_prob": 5.115521344123408e-05}, {"id": 36, "seek": 25720, "start": 270.32, "end": 275.71999999999997, "text": " We should be able to observe the same thing. Otherwise, it means that maybe we miss something.", "tokens": [492, 820, 312, 1075, 281, 11441, 264, 912, 551, 13, 10328, 11, 309, 1355, 300, 1310, 321, 1713, 746, 13], "temperature": 0.0, "avg_logprob": -0.18277575752951883, "compression_ratio": 1.654867256637168, "no_speech_prob": 5.115521344123408e-05}, {"id": 37, "seek": 25720, "start": 275.71999999999997, "end": 285.91999999999996, "text": " So, the big question today is with this kind of context, how do we redo later and elsewhere?", "tokens": [407, 11, 264, 955, 1168, 965, 307, 365, 341, 733, 295, 4319, 11, 577, 360, 321, 29956, 1780, 293, 14517, 30], "temperature": 0.0, "avg_logprob": -0.18277575752951883, "compression_ratio": 1.654867256637168, "no_speech_prob": 5.115521344123408e-05}, {"id": 38, "seek": 28592, "start": 285.92, "end": 291.12, "text": " So, I did something on my machine and you have to do this thing on your machine, for", "tokens": [407, 11, 286, 630, 746, 322, 452, 3479, 293, 291, 362, 281, 360, 341, 551, 322, 428, 3479, 11, 337], "temperature": 0.0, "avg_logprob": -0.1832518134006234, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.00019621125829871744}, {"id": 39, "seek": 28592, "start": 291.12, "end": 296.52000000000004, "text": " example, six months or one year or five years later, with the computer. And this is a big", "tokens": [1365, 11, 2309, 2493, 420, 472, 1064, 420, 1732, 924, 1780, 11, 365, 264, 3820, 13, 400, 341, 307, 257, 955], "temperature": 0.0, "avg_logprob": -0.1832518134006234, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.00019621125829871744}, {"id": 40, "seek": 28592, "start": 296.52000000000004, "end": 304.72, "text": " issue and is part of the reputable crisis in science from my point of view. So, what", "tokens": [2734, 293, 307, 644, 295, 264, 1085, 32148, 5869, 294, 3497, 490, 452, 935, 295, 1910, 13, 407, 11, 437], "temperature": 0.0, "avg_logprob": -0.1832518134006234, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.00019621125829871744}, {"id": 41, "seek": 28592, "start": 304.72, "end": 311.12, "text": " is a computational environment? Computational environment implies various points. For example,", "tokens": [307, 257, 28270, 2823, 30, 37804, 1478, 2823, 18779, 3683, 2793, 13, 1171, 1365, 11], "temperature": 0.0, "avg_logprob": -0.1832518134006234, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.00019621125829871744}, {"id": 42, "seek": 31112, "start": 311.12, "end": 317.28000000000003, "text": " what is a source code? But, for example, if, say, I use Python and this script, okay,", "tokens": [437, 307, 257, 4009, 3089, 30, 583, 11, 337, 1365, 11, 498, 11, 584, 11, 286, 764, 15329, 293, 341, 5755, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.20875307854185712, "compression_ratio": 1.8736842105263158, "no_speech_prob": 0.00021118210861459374}, {"id": 43, "seek": 31112, "start": 317.28000000000003, "end": 325.2, "text": " we have the source code of Python is in C and we have the source code of this Python", "tokens": [321, 362, 264, 4009, 3089, 295, 15329, 307, 294, 383, 293, 321, 362, 264, 4009, 3089, 295, 341, 15329], "temperature": 0.0, "avg_logprob": -0.20875307854185712, "compression_ratio": 1.8736842105263158, "no_speech_prob": 0.00021118210861459374}, {"id": 44, "seek": 31112, "start": 325.2, "end": 333.28000000000003, "text": " script, okay. But the Python interpreter requires a C compiler. So, we need tools for building.", "tokens": [5755, 11, 1392, 13, 583, 264, 15329, 34132, 7029, 257, 383, 31958, 13, 407, 11, 321, 643, 3873, 337, 2390, 13], "temperature": 0.0, "avg_logprob": -0.20875307854185712, "compression_ratio": 1.8736842105263158, "no_speech_prob": 0.00021118210861459374}, {"id": 45, "seek": 31112, "start": 333.28000000000003, "end": 339.64, "text": " And my script, for example, needs some Python library. So, we need also tools for running", "tokens": [400, 452, 5755, 11, 337, 1365, 11, 2203, 512, 15329, 6405, 13, 407, 11, 321, 643, 611, 3873, 337, 2614], "temperature": 0.0, "avg_logprob": -0.20875307854185712, "compression_ratio": 1.8736842105263158, "no_speech_prob": 0.00021118210861459374}, {"id": 46, "seek": 33964, "start": 339.64, "end": 345.28, "text": " at runtime. So, and each tool has the same issue. What is the source code? What is the", "tokens": [412, 34474, 13, 407, 11, 293, 1184, 2290, 575, 264, 912, 2734, 13, 708, 307, 264, 4009, 3089, 30, 708, 307, 264], "temperature": 0.0, "avg_logprob": -0.2180580741480777, "compression_ratio": 1.81, "no_speech_prob": 0.0001027022663038224}, {"id": 47, "seek": 33964, "start": 345.28, "end": 353.12, "text": " tools for building? And so, this is really reclusive. So, this is a big issue. And answering", "tokens": [3873, 337, 2390, 30, 400, 370, 11, 341, 307, 534, 850, 7233, 13, 407, 11, 341, 307, 257, 955, 2734, 13, 400, 13430], "temperature": 0.0, "avg_logprob": -0.2180580741480777, "compression_ratio": 1.81, "no_speech_prob": 0.0001027022663038224}, {"id": 48, "seek": 33964, "start": 353.12, "end": 360.64, "text": " all these questions is controlling the source of variation. So, the question is, so, how", "tokens": [439, 613, 1651, 307, 14905, 264, 4009, 295, 12990, 13, 407, 11, 264, 1168, 307, 11, 370, 11, 577], "temperature": 0.0, "avg_logprob": -0.2180580741480777, "compression_ratio": 1.81, "no_speech_prob": 0.0001027022663038224}, {"id": 49, "seek": 33964, "start": 360.64, "end": 366.28, "text": " do we capture the answer of all these questions? So, the question is not new. We have already", "tokens": [360, 321, 7983, 264, 1867, 295, 439, 613, 1651, 30, 407, 11, 264, 1168, 307, 406, 777, 13, 492, 362, 1217], "temperature": 0.0, "avg_logprob": -0.2180580741480777, "compression_ratio": 1.81, "no_speech_prob": 0.0001027022663038224}, {"id": 50, "seek": 36628, "start": 366.28, "end": 372.23999999999995, "text": " tools, package manager, modified container. So, for example, with package manager, like", "tokens": [3873, 11, 7372, 6598, 11, 15873, 10129, 13, 407, 11, 337, 1365, 11, 365, 7372, 6598, 11, 411], "temperature": 0.0, "avg_logprob": -0.2774564512483366, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0005479680839926004}, {"id": 51, "seek": 36628, "start": 372.23999999999995, "end": 378.11999999999995, "text": " APT for Debian, you can control this computational environment. But there is some issue. For", "tokens": [5372, 51, 337, 1346, 20196, 11, 291, 393, 1969, 341, 28270, 2823, 13, 583, 456, 307, 512, 2734, 13, 1171], "temperature": 0.0, "avg_logprob": -0.2774564512483366, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0005479680839926004}, {"id": 52, "seek": 36628, "start": 378.11999999999995, "end": 383.64, "text": " example, how do you have several versions of open blasts on the same machine? It doesn't", "tokens": [1365, 11, 577, 360, 291, 362, 2940, 9606, 295, 1269, 12035, 82, 322, 264, 912, 3479, 30, 467, 1177, 380], "temperature": 0.0, "avg_logprob": -0.2774564512483366, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0005479680839926004}, {"id": 53, "seek": 36628, "start": 383.64, "end": 389.11999999999995, "text": " work really easily with Debian or with you and so on. So, there is fixes, but it's not", "tokens": [589, 534, 3612, 365, 1346, 20196, 420, 365, 291, 293, 370, 322, 13, 407, 11, 456, 307, 32539, 11, 457, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.2774564512483366, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0005479680839926004}, {"id": 54, "seek": 38912, "start": 389.12, "end": 397.64, "text": " really, I mean, practically, sometimes it's difficult. So, you have, to fix this issue,", "tokens": [534, 11, 286, 914, 11, 15667, 11, 2171, 309, 311, 2252, 13, 407, 11, 291, 362, 11, 281, 3191, 341, 2734, 11], "temperature": 0.0, "avg_logprob": -0.2729504986813194, "compression_ratio": 1.4833333333333334, "no_speech_prob": 0.0002557836414780468}, {"id": 55, "seek": 38912, "start": 397.64, "end": 402.88, "text": " you have an environment manager, like Conda, PIP, Modifies, and so on. But this is really", "tokens": [291, 362, 364, 2823, 6598, 11, 411, 383, 12233, 11, 430, 9139, 11, 6583, 11221, 11, 293, 370, 322, 13, 583, 341, 307, 534], "temperature": 0.0, "avg_logprob": -0.2729504986813194, "compression_ratio": 1.4833333333333334, "no_speech_prob": 0.0002557836414780468}, {"id": 56, "seek": 38912, "start": 402.88, "end": 410.76, "text": " difficult because, for example, in Conda, how do you know how it is built? What is inside", "tokens": [2252, 570, 11, 337, 1365, 11, 294, 383, 12233, 11, 577, 360, 291, 458, 577, 309, 307, 3094, 30, 708, 307, 1854], "temperature": 0.0, "avg_logprob": -0.2729504986813194, "compression_ratio": 1.4833333333333334, "no_speech_prob": 0.0002557836414780468}, {"id": 57, "seek": 41076, "start": 410.76, "end": 419.92, "text": " what you install? So, this is for transparency in science. Modifies, how do you use Modifies", "tokens": [437, 291, 3625, 30, 407, 11, 341, 307, 337, 17131, 294, 3497, 13, 6583, 11221, 11, 577, 360, 291, 764, 6583, 11221], "temperature": 0.0, "avg_logprob": -0.2038151906884235, "compression_ratio": 1.5938864628820961, "no_speech_prob": 0.00011721435294020921}, {"id": 58, "seek": 41076, "start": 419.92, "end": 427.2, "text": " on the laptop? I think no one. And Docker is for container, Docker, Singularity, or whatever,", "tokens": [322, 264, 10732, 30, 286, 519, 572, 472, 13, 400, 33772, 307, 337, 10129, 11, 33772, 11, 7474, 1040, 507, 11, 420, 2035, 11], "temperature": 0.0, "avg_logprob": -0.2038151906884235, "compression_ratio": 1.5938864628820961, "no_speech_prob": 0.00011721435294020921}, {"id": 59, "seek": 41076, "start": 427.2, "end": 431.96, "text": " is a strategy which generally based on the previous solution. So, in fact, you have exactly", "tokens": [307, 257, 5206, 597, 5101, 2361, 322, 264, 3894, 3827, 13, 407, 11, 294, 1186, 11, 291, 362, 2293], "temperature": 0.0, "avg_logprob": -0.2038151906884235, "compression_ratio": 1.5938864628820961, "no_speech_prob": 0.00011721435294020921}, {"id": 60, "seek": 41076, "start": 431.96, "end": 436.88, "text": " the same problems as the previous solution. It just helps to move stuff from one place", "tokens": [264, 912, 2740, 382, 264, 3894, 3827, 13, 467, 445, 3665, 281, 1286, 1507, 490, 472, 1081], "temperature": 0.0, "avg_logprob": -0.2038151906884235, "compression_ratio": 1.5938864628820961, "no_speech_prob": 0.00011721435294020921}, {"id": 61, "seek": 43688, "start": 436.88, "end": 442.28, "text": " to the other one, but it doesn't help to be able to have the correct thing in the first", "tokens": [281, 264, 661, 472, 11, 457, 309, 1177, 380, 854, 281, 312, 1075, 281, 362, 264, 3006, 551, 294, 264, 700], "temperature": 0.0, "avg_logprob": -0.23538036157589148, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00022995729523245245}, {"id": 62, "seek": 43688, "start": 442.28, "end": 450.4, "text": " time. Geeks, in fact, is all these three solutions glued together. So, it tries to fix all the", "tokens": [565, 13, 2876, 24785, 11, 294, 1186, 11, 307, 439, 613, 1045, 6547, 28008, 1214, 13, 407, 11, 309, 9898, 281, 3191, 439, 264], "temperature": 0.0, "avg_logprob": -0.23538036157589148, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00022995729523245245}, {"id": 63, "seek": 43688, "start": 450.4, "end": 458.15999999999997, "text": " annoyance from each to have something, I mean, working, fixing all the issues of everything.", "tokens": [8759, 719, 490, 1184, 281, 362, 746, 11, 286, 914, 11, 1364, 11, 19442, 439, 264, 2663, 295, 1203, 13], "temperature": 0.0, "avg_logprob": -0.23538036157589148, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00022995729523245245}, {"id": 64, "seek": 43688, "start": 458.15999999999997, "end": 464.28, "text": " So, Geeks is a package manager, like APT, UME, etc. It's transactional and declarative.", "tokens": [407, 11, 2876, 24785, 307, 257, 7372, 6598, 11, 411, 5372, 51, 11, 624, 15454, 11, 5183, 13, 467, 311, 46688, 1966, 293, 16694, 1166, 13], "temperature": 0.0, "avg_logprob": -0.23538036157589148, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00022995729523245245}, {"id": 65, "seek": 46428, "start": 464.28, "end": 470.08, "text": " It means that you can roll back, you can have a concurrent version, and so on. You can produce", "tokens": [467, 1355, 300, 291, 393, 3373, 646, 11, 291, 393, 362, 257, 37702, 3037, 11, 293, 370, 322, 13, 509, 393, 5258], "temperature": 0.0, "avg_logprob": -0.24594873540541706, "compression_ratio": 1.5632183908045978, "no_speech_prob": 0.0002537267282605171}, {"id": 66, "seek": 46428, "start": 470.08, "end": 478.71999999999997, "text": " a pack, which is Docker images, for example. You can produce virtual machines, like Ansible", "tokens": [257, 2844, 11, 597, 307, 33772, 5267, 11, 337, 1365, 13, 509, 393, 5258, 6374, 8379, 11, 411, 14590, 964], "temperature": 0.0, "avg_logprob": -0.24594873540541706, "compression_ratio": 1.5632183908045978, "no_speech_prob": 0.0002537267282605171}, {"id": 67, "seek": 46428, "start": 478.71999999999997, "end": 485.96, "text": " for deploying on some machine. You can build a complete distribution, and it's also a", "tokens": [337, 34198, 322, 512, 3479, 13, 509, 393, 1322, 257, 3566, 7316, 11, 293, 309, 311, 611, 257], "temperature": 0.0, "avg_logprob": -0.24594873540541706, "compression_ratio": 1.5632183908045978, "no_speech_prob": 0.0002537267282605171}, {"id": 68, "seek": 48596, "start": 485.96, "end": 494.52, "text": " self-came library, so you can extend Geeks. So, okay, the talk is 25 minutes. So, it's", "tokens": [2698, 12, 3005, 6405, 11, 370, 291, 393, 10101, 2876, 24785, 13, 407, 11, 1392, 11, 264, 751, 307, 3552, 2077, 13, 407, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.2540463220505487, "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.00037048273952677846}, {"id": 69, "seek": 48596, "start": 494.52, "end": 499.08, "text": " just a kind of aperitif before lunch. So, I don't speak about all that, because it's", "tokens": [445, 257, 733, 295, 43139, 270, 351, 949, 6349, 13, 407, 11, 286, 500, 380, 1710, 466, 439, 300, 11, 570, 309, 311], "temperature": 0.0, "avg_logprob": -0.2540463220505487, "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.00037048273952677846}, {"id": 70, "seek": 48596, "start": 499.08, "end": 503.79999999999995, "text": " a little too much. So, I just speak about how Geeks help in open research from my point", "tokens": [257, 707, 886, 709, 13, 407, 11, 286, 445, 1710, 466, 577, 2876, 24785, 854, 294, 1269, 2132, 490, 452, 935], "temperature": 0.0, "avg_logprob": -0.2540463220505487, "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.00037048273952677846}, {"id": 71, "seek": 48596, "start": 503.79999999999995, "end": 511.96, "text": " of view. So, I think it's really easy to try. You have just a script, and give a look before", "tokens": [295, 1910, 13, 407, 11, 286, 519, 309, 311, 534, 1858, 281, 853, 13, 509, 362, 445, 257, 5755, 11, 293, 976, 257, 574, 949], "temperature": 0.0, "avg_logprob": -0.2540463220505487, "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.00037048273952677846}, {"id": 72, "seek": 51196, "start": 511.96, "end": 517.52, "text": " installing it. It's just a bar script, but check it. And you can install Geeks on any", "tokens": [20762, 309, 13, 467, 311, 445, 257, 2159, 5755, 11, 457, 1520, 309, 13, 400, 291, 393, 3625, 2876, 24785, 322, 604], "temperature": 0.0, "avg_logprob": -0.13675924674751833, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0001838529424276203}, {"id": 73, "seek": 51196, "start": 517.52, "end": 522.48, "text": " recent distribution. So, it's really easy to try. You are running Debian. You can try", "tokens": [5162, 7316, 13, 407, 11, 309, 311, 534, 1858, 281, 853, 13, 509, 366, 2614, 1346, 20196, 13, 509, 393, 853], "temperature": 0.0, "avg_logprob": -0.13675924674751833, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0001838529424276203}, {"id": 74, "seek": 51196, "start": 522.48, "end": 529.12, "text": " Geeks without installing the complete distribution. You can use Geeks on the top of any distribution,", "tokens": [2876, 24785, 1553, 20762, 264, 3566, 7316, 13, 509, 393, 764, 2876, 24785, 322, 264, 1192, 295, 604, 7316, 11], "temperature": 0.0, "avg_logprob": -0.13675924674751833, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0001838529424276203}, {"id": 75, "seek": 51196, "start": 529.12, "end": 540.68, "text": " and it's really easy to try. Give a try. So, now, Geeks is just another package manager.", "tokens": [293, 309, 311, 534, 1858, 281, 853, 13, 5303, 257, 853, 13, 407, 11, 586, 11, 2876, 24785, 307, 445, 1071, 7372, 6598, 13], "temperature": 0.0, "avg_logprob": -0.13675924674751833, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0001838529424276203}, {"id": 76, "seek": 54068, "start": 540.68, "end": 546.52, "text": " So, you have the same command that you have in any package manager, for sharing packages,", "tokens": [407, 11, 291, 362, 264, 912, 5622, 300, 291, 362, 294, 604, 7372, 6598, 11, 337, 5414, 17401, 11], "temperature": 0.0, "avg_logprob": -0.19776857310327992, "compression_ratio": 1.9114583333333333, "no_speech_prob": 0.00012123566557420418}, {"id": 77, "seek": 54068, "start": 546.52, "end": 552.0, "text": " showing packages, installing packages, removing packages, and so on. It's exactly the same", "tokens": [4099, 17401, 11, 20762, 17401, 11, 12720, 17401, 11, 293, 370, 322, 13, 467, 311, 2293, 264, 912], "temperature": 0.0, "avg_logprob": -0.19776857310327992, "compression_ratio": 1.9114583333333333, "no_speech_prob": 0.00012123566557420418}, {"id": 78, "seek": 54068, "start": 552.0, "end": 560.3199999999999, "text": " as any package manager. But you have some more functionality, like transactional. So, everything,", "tokens": [382, 604, 7372, 6598, 13, 583, 291, 362, 512, 544, 14980, 11, 411, 46688, 1966, 13, 407, 11, 1203, 11], "temperature": 0.0, "avg_logprob": -0.19776857310327992, "compression_ratio": 1.9114583333333333, "no_speech_prob": 0.00012123566557420418}, {"id": 79, "seek": 54068, "start": 560.3199999999999, "end": 565.3599999999999, "text": " you can do two actions in the same time. So, for example, removing and installing in the", "tokens": [291, 393, 360, 732, 5909, 294, 264, 912, 565, 13, 407, 11, 337, 1365, 11, 12720, 293, 20762, 294, 264], "temperature": 0.0, "avg_logprob": -0.19776857310327992, "compression_ratio": 1.9114583333333333, "no_speech_prob": 0.00012123566557420418}, {"id": 80, "seek": 56536, "start": 565.36, "end": 570.92, "text": " same transaction. Or you can roll back. So, for example, you install something, and you", "tokens": [912, 14425, 13, 1610, 291, 393, 3373, 646, 13, 407, 11, 337, 1365, 11, 291, 3625, 746, 11, 293, 291], "temperature": 0.0, "avg_logprob": -0.21683280488364717, "compression_ratio": 1.8081632653061224, "no_speech_prob": 0.00017631350783631206}, {"id": 81, "seek": 56536, "start": 570.92, "end": 577.72, "text": " want to roll back to uninstall this thing without breaking nothing. So, okay, this is", "tokens": [528, 281, 3373, 646, 281, 517, 40166, 341, 551, 1553, 7697, 1825, 13, 407, 11, 1392, 11, 341, 307], "temperature": 0.0, "avg_logprob": -0.21683280488364717, "compression_ratio": 1.8081632653061224, "no_speech_prob": 0.00017631350783631206}, {"id": 82, "seek": 56536, "start": 577.72, "end": 583.28, "text": " another package manager. But is it really another package manager? So, yeah, we can have,", "tokens": [1071, 7372, 6598, 13, 583, 307, 309, 534, 1071, 7372, 6598, 30, 407, 11, 1338, 11, 321, 393, 362, 11], "temperature": 0.0, "avg_logprob": -0.21683280488364717, "compression_ratio": 1.8081632653061224, "no_speech_prob": 0.00017631350783631206}, {"id": 83, "seek": 56536, "start": 583.28, "end": 589.72, "text": " it's a command line. It's a, we install, remove without special privilege. So, this is nice.", "tokens": [309, 311, 257, 5622, 1622, 13, 467, 311, 257, 11, 321, 3625, 11, 4159, 1553, 2121, 12122, 13, 407, 11, 341, 307, 1481, 13], "temperature": 0.0, "avg_logprob": -0.21683280488364717, "compression_ratio": 1.8081632653061224, "no_speech_prob": 0.00017631350783631206}, {"id": 84, "seek": 56536, "start": 589.72, "end": 594.24, "text": " It's transactional. So, there is no broken state. We have been able to substitute. So,", "tokens": [467, 311, 46688, 1966, 13, 407, 11, 456, 307, 572, 5463, 1785, 13, 492, 362, 668, 1075, 281, 15802, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.21683280488364717, "compression_ratio": 1.8081632653061224, "no_speech_prob": 0.00017631350783631206}, {"id": 85, "seek": 59424, "start": 594.24, "end": 600.8, "text": " we don't have to wait hours and hours to have our binary. But this is nice. But what is", "tokens": [321, 500, 380, 362, 281, 1699, 2496, 293, 2496, 281, 362, 527, 17434, 13, 583, 341, 307, 1481, 13, 583, 437, 307], "temperature": 0.0, "avg_logprob": -0.16012063137320584, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.00032080349046736956}, {"id": 86, "seek": 59424, "start": 600.8, "end": 606.2, "text": " really, really nice is decorative management. It means that everything is a configuration", "tokens": [534, 11, 534, 1481, 307, 35185, 4592, 13, 467, 1355, 300, 1203, 307, 257, 11694], "temperature": 0.0, "avg_logprob": -0.16012063137320584, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.00032080349046736956}, {"id": 87, "seek": 59424, "start": 606.2, "end": 614.36, "text": " file with scheme. But you can declare everything. And you can produce isolated environment on", "tokens": [3991, 365, 12232, 13, 583, 291, 393, 19710, 1203, 13, 400, 291, 393, 5258, 14621, 2823, 322], "temperature": 0.0, "avg_logprob": -0.16012063137320584, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.00032080349046736956}, {"id": 88, "seek": 59424, "start": 614.36, "end": 622.0, "text": " the fly. This is something that's really helpful. And you can also see Geeks as a factory for", "tokens": [264, 3603, 13, 639, 307, 746, 300, 311, 534, 4961, 13, 400, 291, 393, 611, 536, 2876, 24785, 382, 257, 9265, 337], "temperature": 0.0, "avg_logprob": -0.16012063137320584, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.00032080349046736956}, {"id": 89, "seek": 62200, "start": 622.0, "end": 631.52, "text": " the Docker images, for example. So, okay, this is all interesting feature. But why Geeks", "tokens": [264, 33772, 5267, 11, 337, 1365, 13, 407, 11, 1392, 11, 341, 307, 439, 1880, 4111, 13, 583, 983, 2876, 24785], "temperature": 0.0, "avg_logprob": -0.22016198667761397, "compression_ratio": 1.5568862275449102, "no_speech_prob": 0.0002455363573972136}, {"id": 90, "seek": 62200, "start": 631.52, "end": 638.08, "text": " is reproducible? Or what does it mean it's reproducible? For reproducibility, we need", "tokens": [307, 11408, 32128, 30, 1610, 437, 775, 309, 914, 309, 311, 11408, 32128, 30, 1171, 11408, 537, 39802, 11, 321, 643], "temperature": 0.0, "avg_logprob": -0.22016198667761397, "compression_ratio": 1.5568862275449102, "no_speech_prob": 0.0002455363573972136}, {"id": 91, "seek": 62200, "start": 638.08, "end": 645.04, "text": " to talk about what is a version. So, what is a version? Alice say, for example, I use", "tokens": [281, 751, 466, 437, 307, 257, 3037, 13, 407, 11, 437, 307, 257, 3037, 30, 16004, 584, 11, 337, 1365, 11, 286, 764], "temperature": 0.0, "avg_logprob": -0.22016198667761397, "compression_ratio": 1.5568862275449102, "no_speech_prob": 0.0002455363573972136}, {"id": 92, "seek": 64504, "start": 645.04, "end": 652.88, "text": " GCC Adversion 11. Okay, nice. But what does it mean, concretely, I use GCC Adversion 11.", "tokens": [460, 11717, 1999, 29153, 2975, 13, 1033, 11, 1481, 13, 583, 437, 775, 309, 914, 11, 39481, 736, 11, 286, 764, 460, 11717, 1999, 29153, 2975, 13], "temperature": 0.0, "avg_logprob": -0.31578202681107953, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.00017863957327790558}, {"id": 93, "seek": 64504, "start": 652.88, "end": 658.64, "text": " It means that you need GCC, the compiler. But you also need AD, which is the linker.", "tokens": [467, 1355, 300, 291, 643, 460, 11717, 11, 264, 31958, 13, 583, 291, 611, 643, 9135, 11, 597, 307, 264, 2113, 260, 13], "temperature": 0.0, "avg_logprob": -0.31578202681107953, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.00017863957327790558}, {"id": 94, "seek": 64504, "start": 658.64, "end": 665.0799999999999, "text": " And you know, Binitils, for example. And the Jelitsi library. But the compiler GCC, it", "tokens": [400, 291, 458, 11, 18983, 270, 4174, 11, 337, 1365, 13, 400, 264, 508, 338, 1208, 72, 6405, 13, 583, 264, 31958, 460, 11717, 11, 309], "temperature": 0.0, "avg_logprob": -0.31578202681107953, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.00017863957327790558}, {"id": 95, "seek": 64504, "start": 665.0799999999999, "end": 672.04, "text": " needs, for example, MPC, which is a package that does, I don't know what exactly. Anyway.", "tokens": [2203, 11, 337, 1365, 11, 376, 12986, 11, 597, 307, 257, 7372, 300, 775, 11, 286, 500, 380, 458, 437, 2293, 13, 5684, 13], "temperature": 0.0, "avg_logprob": -0.31578202681107953, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.00017863957327790558}, {"id": 96, "seek": 67204, "start": 672.04, "end": 678.7199999999999, "text": " And you need also MPFR and so on. And you have this kind of graph. And we can ask the", "tokens": [400, 291, 643, 611, 14146, 34658, 293, 370, 322, 13, 400, 291, 362, 341, 733, 295, 4295, 13, 400, 321, 393, 1029, 264], "temperature": 0.0, "avg_logprob": -0.16011357307434082, "compression_ratio": 1.623456790123457, "no_speech_prob": 0.00021523528266698122}, {"id": 97, "seek": 67204, "start": 678.7199999999999, "end": 690.0, "text": " question, is it the same GCC Adversion 11 if we replace this MPFR Adversion 4.1 by MPFR", "tokens": [1168, 11, 307, 309, 264, 912, 460, 11717, 1999, 29153, 2975, 498, 321, 7406, 341, 14146, 34658, 1999, 29153, 1017, 13, 16, 538, 14146, 34658], "temperature": 0.0, "avg_logprob": -0.16011357307434082, "compression_ratio": 1.623456790123457, "no_speech_prob": 0.00021523528266698122}, {"id": 98, "seek": 67204, "start": 690.0, "end": 696.8399999999999, "text": " Adversion 4.0? Is it the same GCC or not? And maybe not. And if it is not the same, maybe", "tokens": [1999, 29153, 1017, 13, 15, 30, 1119, 309, 264, 912, 460, 11717, 420, 406, 30, 400, 1310, 406, 13, 400, 498, 309, 307, 406, 264, 912, 11, 1310], "temperature": 0.0, "avg_logprob": -0.16011357307434082, "compression_ratio": 1.623456790123457, "no_speech_prob": 0.00021523528266698122}, {"id": 99, "seek": 69684, "start": 696.84, "end": 702.84, "text": " you are feeling a difference. How can we be sure that we are using the exact same GCC?", "tokens": [291, 366, 2633, 257, 2649, 13, 1012, 393, 321, 312, 988, 300, 321, 366, 1228, 264, 1900, 912, 460, 11717, 30], "temperature": 0.0, "avg_logprob": -0.1916391650835673, "compression_ratio": 1.5919282511210762, "no_speech_prob": 5.091112689115107e-05}, {"id": 100, "seek": 69684, "start": 702.84, "end": 709.48, "text": " So this is just an extract of the graph because the graph have roots. And yeah, it can be", "tokens": [407, 341, 307, 445, 364, 8947, 295, 264, 4295, 570, 264, 4295, 362, 10669, 13, 400, 1338, 11, 309, 393, 312], "temperature": 0.0, "avg_logprob": -0.1916391650835673, "compression_ratio": 1.5919282511210762, "no_speech_prob": 5.091112689115107e-05}, {"id": 101, "seek": 69684, "start": 709.48, "end": 716.36, "text": " really large. And maybe we can also talk about what are the roots of this graph. But this", "tokens": [534, 2416, 13, 400, 1310, 321, 393, 611, 751, 466, 437, 366, 264, 10669, 295, 341, 4295, 13, 583, 341], "temperature": 0.0, "avg_logprob": -0.1916391650835673, "compression_ratio": 1.5919282511210762, "no_speech_prob": 5.091112689115107e-05}, {"id": 102, "seek": 69684, "start": 716.36, "end": 724.9200000000001, "text": " is another talk. So when you say that, okay, but I need to have a version. So what is my", "tokens": [307, 1071, 751, 13, 407, 562, 291, 584, 300, 11, 1392, 11, 457, 286, 643, 281, 362, 257, 3037, 13, 407, 437, 307, 452], "temperature": 0.0, "avg_logprob": -0.1916391650835673, "compression_ratio": 1.5919282511210762, "no_speech_prob": 5.091112689115107e-05}, {"id": 103, "seek": 72492, "start": 724.92, "end": 733.8399999999999, "text": " version in GICS? So GICS describe the state of GICS. So in fact, GICS describe is a version", "tokens": [3037, 294, 460, 2532, 50, 30, 407, 460, 2532, 50, 6786, 264, 1785, 295, 460, 2532, 50, 13, 407, 294, 1186, 11, 460, 2532, 50, 6786, 307, 257, 3037], "temperature": 0.0, "avg_logprob": -0.17860359615749782, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.00013813647092320025}, {"id": 104, "seek": 72492, "start": 733.8399999999999, "end": 741.16, "text": " of GICS. And what it does, in fact, it pins the complete collection of all the packages", "tokens": [295, 460, 2532, 50, 13, 400, 437, 309, 775, 11, 294, 1186, 11, 309, 16392, 264, 3566, 5765, 295, 439, 264, 17401], "temperature": 0.0, "avg_logprob": -0.17860359615749782, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.00013813647092320025}, {"id": 105, "seek": 72492, "start": 741.16, "end": 748.64, "text": " and GICS itself. And because of that, we are able to freeze the complete graph. We can", "tokens": [293, 460, 2532, 50, 2564, 13, 400, 570, 295, 300, 11, 321, 366, 1075, 281, 15959, 264, 3566, 4295, 13, 492, 393], "temperature": 0.0, "avg_logprob": -0.17860359615749782, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.00013813647092320025}, {"id": 106, "seek": 74864, "start": 748.64, "end": 758.1999999999999, "text": " move this graph from one place to the other. So, okay. So this graph, in fact, describe", "tokens": [1286, 341, 4295, 490, 472, 1081, 281, 264, 661, 13, 407, 11, 1392, 13, 407, 341, 4295, 11, 294, 1186, 11, 6786], "temperature": 0.0, "avg_logprob": -0.23338417212168375, "compression_ratio": 1.6837209302325582, "no_speech_prob": 7.205170550150797e-05}, {"id": 107, "seek": 74864, "start": 758.1999999999999, "end": 766.1999999999999, "text": " the nodes of each, each, each node in this graph specify a receipt. And this receipt", "tokens": [264, 13891, 295, 1184, 11, 1184, 11, 1184, 9984, 294, 341, 4295, 16500, 257, 33882, 13, 400, 341, 33882], "temperature": 0.0, "avg_logprob": -0.23338417212168375, "compression_ratio": 1.6837209302325582, "no_speech_prob": 7.205170550150797e-05}, {"id": 108, "seek": 74864, "start": 766.1999999999999, "end": 772.72, "text": " defines the code source, the build time tombs, and the dependency. So for me, yeah. And this", "tokens": [23122, 264, 3089, 4009, 11, 264, 1322, 565, 2916, 929, 11, 293, 264, 33621, 13, 407, 337, 385, 11, 1338, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.23338417212168375, "compression_ratio": 1.6837209302325582, "no_speech_prob": 7.205170550150797e-05}, {"id": 109, "seek": 74864, "start": 772.72, "end": 778.24, "text": " graph can be really, really large. For example, for Skypy, which is a scientific Python library,", "tokens": [4295, 393, 312, 534, 11, 534, 2416, 13, 1171, 1365, 11, 337, 9879, 8200, 11, 597, 307, 257, 8134, 15329, 6405, 11], "temperature": 0.0, "avg_logprob": -0.23338417212168375, "compression_ratio": 1.6837209302325582, "no_speech_prob": 7.205170550150797e-05}, {"id": 110, "seek": 77824, "start": 778.24, "end": 791.88, "text": " there is more than 1,000 nodes. So, yeah, it can be really large. So for when I say GCC", "tokens": [456, 307, 544, 813, 502, 11, 1360, 13891, 13, 407, 11, 1338, 11, 309, 393, 312, 534, 2416, 13, 407, 337, 562, 286, 584, 460, 11717], "temperature": 0.0, "avg_logprob": -0.2826650619506836, "compression_ratio": 1.5083798882681565, "no_speech_prob": 7.021566125331447e-05}, {"id": 111, "seek": 77824, "start": 791.88, "end": 800.48, "text": " at version 11, it means one fixed graph. And providing the state which describe, this capture", "tokens": [412, 3037, 2975, 11, 309, 1355, 472, 6806, 4295, 13, 400, 6530, 264, 1785, 597, 6786, 11, 341, 7983], "temperature": 0.0, "avg_logprob": -0.2826650619506836, "compression_ratio": 1.5083798882681565, "no_speech_prob": 7.021566125331447e-05}, {"id": 112, "seek": 77824, "start": 800.48, "end": 806.84, "text": " this complete graph. And I can reproduce this complete graph on another machine. So this", "tokens": [341, 3566, 4295, 13, 400, 286, 393, 29501, 341, 3566, 4295, 322, 1071, 3479, 13, 407, 341], "temperature": 0.0, "avg_logprob": -0.2826650619506836, "compression_ratio": 1.5083798882681565, "no_speech_prob": 7.021566125331447e-05}, {"id": 113, "seek": 80684, "start": 806.84, "end": 812.6800000000001, "text": " is collaboration in action. So Alice describes the list of the tools in a manifest, declarative", "tokens": [307, 9363, 294, 3069, 13, 407, 16004, 15626, 264, 1329, 295, 264, 3873, 294, 257, 10067, 11, 16694, 1166], "temperature": 0.0, "avg_logprob": -0.21002775972539728, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0001222592400154099}, {"id": 114, "seek": 80684, "start": 812.6800000000001, "end": 820.76, "text": " way. She generates the environment, GICS shell, and providing the tools. So this creates an", "tokens": [636, 13, 1240, 23815, 264, 2823, 11, 460, 2532, 50, 8720, 11, 293, 6530, 264, 3873, 13, 407, 341, 7829, 364], "temperature": 0.0, "avg_logprob": -0.21002775972539728, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0001222592400154099}, {"id": 115, "seek": 80684, "start": 820.76, "end": 828.72, "text": " environment containing the tools that are listed in the manifest file. Okay. This is", "tokens": [2823, 19273, 264, 3873, 300, 366, 10052, 294, 264, 10067, 3991, 13, 1033, 13, 639, 307], "temperature": 0.0, "avg_logprob": -0.21002775972539728, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0001222592400154099}, {"id": 116, "seek": 80684, "start": 828.72, "end": 836.08, "text": " nice. But now she describes the revision of GICS. So she writes GICS describe and this", "tokens": [1481, 13, 583, 586, 750, 15626, 264, 34218, 295, 460, 2532, 50, 13, 407, 750, 13657, 460, 2532, 50, 6786, 293, 341], "temperature": 0.0, "avg_logprob": -0.21002775972539728, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0001222592400154099}, {"id": 117, "seek": 83608, "start": 836.08, "end": 843.6800000000001, "text": " fix the state of Alice. So, okay, this Alice is working on her laptop. But collaboration", "tokens": [3191, 264, 1785, 295, 16004, 13, 407, 11, 1392, 11, 341, 16004, 307, 1364, 322, 720, 10732, 13, 583, 9363], "temperature": 0.0, "avg_logprob": -0.20873901660625752, "compression_ratio": 1.6772151898734178, "no_speech_prob": 0.0003068717778660357}, {"id": 118, "seek": 83608, "start": 843.6800000000001, "end": 849.76, "text": " is share this computational environment. So it's about sharing the state. To share this", "tokens": [307, 2073, 341, 28270, 2823, 13, 407, 309, 311, 466, 5414, 264, 1785, 13, 1407, 2073, 341], "temperature": 0.0, "avg_logprob": -0.20873901660625752, "compression_ratio": 1.6772151898734178, "no_speech_prob": 0.0003068717778660357}, {"id": 119, "seek": 83608, "start": 849.76, "end": 855.72, "text": " state, you need to share one specific graph. To share this graph, you need to only share", "tokens": [1785, 11, 291, 643, 281, 2073, 472, 2685, 4295, 13, 1407, 2073, 341, 4295, 11, 291, 643, 281, 787, 2073], "temperature": 0.0, "avg_logprob": -0.20873901660625752, "compression_ratio": 1.6772151898734178, "no_speech_prob": 0.0003068717778660357}, {"id": 120, "seek": 85572, "start": 855.72, "end": 867.12, "text": " these two files. And if, sorry, if Blake has these two files, Blake can create the exact", "tokens": [613, 732, 7098, 13, 400, 498, 11, 2597, 11, 498, 23451, 575, 613, 732, 7098, 11, 23451, 393, 1884, 264, 1900], "temperature": 0.0, "avg_logprob": -0.17558687383478339, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.0001154297060566023}, {"id": 121, "seek": 85572, "start": 867.12, "end": 872.84, "text": " same computational environment as Alice. So you have the GICS time machine. You specify", "tokens": [912, 28270, 2823, 382, 16004, 13, 407, 291, 362, 264, 460, 2532, 50, 565, 3479, 13, 509, 16500], "temperature": 0.0, "avg_logprob": -0.17558687383478339, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.0001154297060566023}, {"id": 122, "seek": 85572, "start": 872.84, "end": 880.64, "text": " the state of Alice shell and specify the tools that Alice used. And Blake and Alice are running", "tokens": [264, 1785, 295, 16004, 8720, 293, 16500, 264, 3873, 300, 16004, 1143, 13, 400, 23451, 293, 16004, 366, 2614], "temperature": 0.0, "avg_logprob": -0.17558687383478339, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.0001154297060566023}, {"id": 123, "seek": 88064, "start": 880.64, "end": 888.04, "text": " the exact same computational environment. And for example, if you have Carol, who knows", "tokens": [264, 1900, 912, 28270, 2823, 13, 400, 337, 1365, 11, 498, 291, 362, 7925, 11, 567, 3255], "temperature": 0.0, "avg_logprob": -0.1600569607166762, "compression_ratio": 1.7438423645320198, "no_speech_prob": 4.823517519980669e-05}, {"id": 124, "seek": 88064, "start": 888.04, "end": 894.0, "text": " these two files, she also can reproduce the exact same that Alice and Blake. So, in fact,", "tokens": [613, 732, 7098, 11, 750, 611, 393, 29501, 264, 1900, 912, 300, 16004, 293, 23451, 13, 407, 11, 294, 1186, 11], "temperature": 0.0, "avg_logprob": -0.1600569607166762, "compression_ratio": 1.7438423645320198, "no_speech_prob": 4.823517519980669e-05}, {"id": 125, "seek": 88064, "start": 894.0, "end": 899.84, "text": " you only need two files. And with these two files, you can reproduce everything from one", "tokens": [291, 787, 643, 732, 7098, 13, 400, 365, 613, 732, 7098, 11, 291, 393, 29501, 1203, 490, 472], "temperature": 0.0, "avg_logprob": -0.1600569607166762, "compression_ratio": 1.7438423645320198, "no_speech_prob": 4.823517519980669e-05}, {"id": 126, "seek": 88064, "start": 899.84, "end": 907.84, "text": " place to the other. So, in fact, you have this kind of picture. Alice, Blake, Carol are", "tokens": [1081, 281, 264, 661, 13, 407, 11, 294, 1186, 11, 291, 362, 341, 733, 295, 3036, 13, 16004, 11, 23451, 11, 7925, 366], "temperature": 0.0, "avg_logprob": -0.1600569607166762, "compression_ratio": 1.7438423645320198, "no_speech_prob": 4.823517519980669e-05}, {"id": 127, "seek": 90784, "start": 907.84, "end": 914.84, "text": " in different time frame. But they can jump from this time frame, virtually time different", "tokens": [294, 819, 565, 3920, 13, 583, 436, 393, 3012, 490, 341, 565, 3920, 11, 14103, 565, 819], "temperature": 0.0, "avg_logprob": -0.19734173510448041, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.00021744577679783106}, {"id": 128, "seek": 90784, "start": 914.84, "end": 920.48, "text": " time frame, to the same place. Because their machine are in different state, but they can", "tokens": [565, 3920, 11, 281, 264, 912, 1081, 13, 1436, 641, 3479, 366, 294, 819, 1785, 11, 457, 436, 393], "temperature": 0.0, "avg_logprob": -0.19734173510448041, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.00021744577679783106}, {"id": 129, "seek": 90784, "start": 920.48, "end": 928.08, "text": " temporarily go to another state to create the computational environment. To make this work,", "tokens": [23750, 352, 281, 1071, 1785, 281, 1884, 264, 28270, 2823, 13, 1407, 652, 341, 589, 11], "temperature": 0.0, "avg_logprob": -0.19734173510448041, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.00021744577679783106}, {"id": 130, "seek": 90784, "start": 928.08, "end": 934.4000000000001, "text": " when the time is passing, you need to preserve all the source code. And this is not straightforward.", "tokens": [562, 264, 565, 307, 8437, 11, 291, 643, 281, 15665, 439, 264, 4009, 3089, 13, 400, 341, 307, 406, 15325, 13], "temperature": 0.0, "avg_logprob": -0.19734173510448041, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.00021744577679783106}, {"id": 131, "seek": 93440, "start": 934.4, "end": 939.28, "text": " It is not trivial to preserve all the source code. And you also need some backward compatibility", "tokens": [467, 307, 406, 26703, 281, 15665, 439, 264, 4009, 3089, 13, 400, 291, 611, 643, 512, 23897, 34237], "temperature": 0.0, "avg_logprob": -0.18261716983936452, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.00014718282909598202}, {"id": 132, "seek": 93440, "start": 939.28, "end": 944.9599999999999, "text": " of the Linux kernel and some compatibility of the hardware. But, okay. And when these", "tokens": [295, 264, 18734, 28256, 293, 512, 34237, 295, 264, 8837, 13, 583, 11, 1392, 13, 400, 562, 613], "temperature": 0.0, "avg_logprob": -0.18261716983936452, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.00014718282909598202}, {"id": 133, "seek": 93440, "start": 944.9599999999999, "end": 949.36, "text": " three conditions are satisfied, you have the reproducibility. But what is the size of the", "tokens": [1045, 4487, 366, 11239, 11, 291, 362, 264, 11408, 537, 39802, 13, 583, 437, 307, 264, 2744, 295, 264], "temperature": 0.0, "avg_logprob": -0.18261716983936452, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.00014718282909598202}, {"id": 134, "seek": 93440, "start": 949.36, "end": 954.1999999999999, "text": " window, of the time window, where these three conditions are satisfied? And this is, from", "tokens": [4910, 11, 295, 264, 565, 4910, 11, 689, 613, 1045, 4487, 366, 11239, 30, 400, 341, 307, 11, 490], "temperature": 0.0, "avg_logprob": -0.18261716983936452, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.00014718282909598202}, {"id": 135, "seek": 93440, "start": 954.1999999999999, "end": 960.36, "text": " my point of view, unknown. And GICS is, to my knowledge, a case unique by experimenting", "tokens": [452, 935, 295, 1910, 11, 9841, 13, 400, 460, 2532, 50, 307, 11, 281, 452, 3601, 11, 257, 1389, 3845, 538, 29070], "temperature": 0.0, "avg_logprob": -0.18261716983936452, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.00014718282909598202}, {"id": 136, "seek": 96036, "start": 960.36, "end": 966.32, "text": " to be able, because we have the tooling to do all that. And now we can know what is the", "tokens": [281, 312, 1075, 11, 570, 321, 362, 264, 46593, 281, 360, 439, 300, 13, 400, 586, 321, 393, 458, 437, 307, 264], "temperature": 0.0, "avg_logprob": -0.1981197957242473, "compression_ratio": 1.7047619047619047, "no_speech_prob": 9.046871127793565e-05}, {"id": 137, "seek": 96036, "start": 966.32, "end": 975.0, "text": " size that we are able to reproduce the past in the future. So what is software heritage?", "tokens": [2744, 300, 321, 366, 1075, 281, 29501, 264, 1791, 294, 264, 2027, 13, 407, 437, 307, 4722, 16040, 30], "temperature": 0.0, "avg_logprob": -0.1981197957242473, "compression_ratio": 1.7047619047619047, "no_speech_prob": 9.046871127793565e-05}, {"id": 138, "seek": 96036, "start": 975.0, "end": 980.92, "text": " So software heritage is an archive. It collects preserved software in source code form from", "tokens": [407, 4722, 16040, 307, 364, 23507, 13, 467, 39897, 22242, 4722, 294, 4009, 3089, 1254, 490], "temperature": 0.0, "avg_logprob": -0.1981197957242473, "compression_ratio": 1.7047619047619047, "no_speech_prob": 9.046871127793565e-05}, {"id": 139, "seek": 96036, "start": 980.92, "end": 989.24, "text": " a very long term. And GICS is able to save the source code of the package and the receipt", "tokens": [257, 588, 938, 1433, 13, 400, 460, 2532, 50, 307, 1075, 281, 3155, 264, 4009, 3089, 295, 264, 7372, 293, 264, 33882], "temperature": 0.0, "avg_logprob": -0.1981197957242473, "compression_ratio": 1.7047619047619047, "no_speech_prob": 9.046871127793565e-05}, {"id": 140, "seek": 98924, "start": 989.24, "end": 996.0, "text": " of the package itself. And GICS itself is also saved in software heritage. And GICS is", "tokens": [295, 264, 7372, 2564, 13, 400, 460, 2532, 50, 2564, 307, 611, 6624, 294, 4722, 16040, 13, 400, 460, 2532, 50, 307], "temperature": 0.0, "avg_logprob": -0.1994433350615449, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.00037816321128048003}, {"id": 141, "seek": 98924, "start": 996.0, "end": 1001.4, "text": " able to use software heritage archive to fall back if a swim disappears. So you have the", "tokens": [1075, 281, 764, 4722, 16040, 23507, 281, 2100, 646, 498, 257, 7110, 25527, 13, 407, 291, 362, 264], "temperature": 0.0, "avg_logprob": -0.1994433350615449, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.00037816321128048003}, {"id": 142, "seek": 98924, "start": 1001.4, "end": 1006.4, "text": " postdoc working on some GitLab and Stance. And the account is closed because the postdoc", "tokens": [2183, 39966, 1364, 322, 512, 16939, 37880, 293, 745, 719, 13, 400, 264, 2696, 307, 5395, 570, 264, 2183, 39966], "temperature": 0.0, "avg_logprob": -0.1994433350615449, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.00037816321128048003}, {"id": 143, "seek": 98924, "start": 1006.4, "end": 1012.8, "text": " is moving to other place and so on. And now you have this paper with this URL of, with", "tokens": [307, 2684, 281, 661, 1081, 293, 370, 322, 13, 400, 586, 291, 362, 341, 3035, 365, 341, 12905, 295, 11, 365], "temperature": 0.0, "avg_logprob": -0.1994433350615449, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.00037816321128048003}, {"id": 144, "seek": 101280, "start": 1012.8, "end": 1020.64, "text": " the GitLab package and say, oh, no, it doesn't work because the account is closed. If you", "tokens": [264, 16939, 37880, 7372, 293, 584, 11, 1954, 11, 572, 11, 309, 1177, 380, 589, 570, 264, 2696, 307, 5395, 13, 759, 291], "temperature": 0.0, "avg_logprob": -0.23164694044325088, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.00020688616496045142}, {"id": 145, "seek": 101280, "start": 1020.64, "end": 1027.8, "text": " were using GICS transparently, you can check if the source code is on software heritage.", "tokens": [645, 1228, 460, 2532, 50, 7132, 6420, 11, 291, 393, 1520, 498, 264, 4009, 3089, 307, 322, 4722, 16040, 13], "temperature": 0.0, "avg_logprob": -0.23164694044325088, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.00020688616496045142}, {"id": 146, "seek": 101280, "start": 1027.8, "end": 1034.0, "text": " And this asks really good question about how to see the software and do you notice it only", "tokens": [400, 341, 8962, 534, 665, 1168, 466, 577, 281, 536, 264, 4722, 293, 360, 291, 3449, 309, 787], "temperature": 0.0, "avg_logprob": -0.23164694044325088, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.00020688616496045142}, {"id": 147, "seek": 101280, "start": 1034.0, "end": 1038.6, "text": " the source or, and what about the dependency and the build time options and so on. How", "tokens": [264, 4009, 420, 11, 293, 437, 466, 264, 33621, 293, 264, 1322, 565, 3956, 293, 370, 322, 13, 1012], "temperature": 0.0, "avg_logprob": -0.23164694044325088, "compression_ratio": 1.5478260869565217, "no_speech_prob": 0.00020688616496045142}, {"id": 148, "seek": 103860, "start": 1038.6, "end": 1044.52, "text": " do you see the software? And how, I mean, how do you see this? Do you see it with intrinsic", "tokens": [360, 291, 536, 264, 4722, 30, 400, 577, 11, 286, 914, 11, 577, 360, 291, 536, 341, 30, 1144, 291, 536, 309, 365, 35698], "temperature": 0.0, "avg_logprob": -0.2780114625629626, "compression_ratio": 1.7598039215686274, "no_speech_prob": 0.00036767107667401433}, {"id": 149, "seek": 103860, "start": 1044.52, "end": 1051.3999999999999, "text": " identifier like checksum or with intrinsic identifier like version label? This is easy.", "tokens": [45690, 411, 13834, 449, 420, 365, 35698, 45690, 411, 3037, 7645, 30, 639, 307, 1858, 13], "temperature": 0.0, "avg_logprob": -0.2780114625629626, "compression_ratio": 1.7598039215686274, "no_speech_prob": 0.00036767107667401433}, {"id": 150, "seek": 103860, "start": 1051.3999999999999, "end": 1059.0, "text": " So in summary, there is three commands. I'm almost done, right? Yeah. So in summary, you", "tokens": [407, 294, 12691, 11, 456, 307, 1045, 16901, 13, 286, 478, 1920, 1096, 11, 558, 30, 865, 13, 407, 294, 12691, 11, 291], "temperature": 0.0, "avg_logprob": -0.2780114625629626, "compression_ratio": 1.7598039215686274, "no_speech_prob": 0.00036767107667401433}, {"id": 151, "seek": 103860, "start": 1059.0, "end": 1064.48, "text": " have three commands. And these three commands, which are GICS shell, GICS time machine and", "tokens": [362, 1045, 16901, 13, 400, 613, 1045, 16901, 11, 597, 366, 460, 2532, 50, 8720, 11, 460, 2532, 50, 565, 3479, 293], "temperature": 0.0, "avg_logprob": -0.2780114625629626, "compression_ratio": 1.7598039215686274, "no_speech_prob": 0.00036767107667401433}, {"id": 152, "seek": 106448, "start": 1064.48, "end": 1076.28, "text": " GICS subscribe, they help you to have a computational environment that you can, I mean, inspect and", "tokens": [460, 2532, 50, 3022, 11, 436, 854, 291, 281, 362, 257, 28270, 2823, 300, 291, 393, 11, 286, 914, 11, 15018, 293], "temperature": 0.0, "avg_logprob": -0.2676905963731849, "compression_ratio": 1.3777777777777778, "no_speech_prob": 0.0003299249801784754}, {"id": 153, "seek": 106448, "start": 1076.28, "end": 1083.88, "text": " collectively share. So if you have this and two files, manifest and channel files, you", "tokens": [24341, 2073, 13, 407, 498, 291, 362, 341, 293, 732, 7098, 11, 10067, 293, 2269, 7098, 11, 291], "temperature": 0.0, "avg_logprob": -0.2676905963731849, "compression_ratio": 1.3777777777777778, "no_speech_prob": 0.0003299249801784754}, {"id": 154, "seek": 108388, "start": 1083.88, "end": 1095.3600000000001, "text": " are reproducible over the time. So okay, for offline, when you are, because I hope I convince", "tokens": [366, 11408, 32128, 670, 264, 565, 13, 407, 1392, 11, 337, 21857, 11, 562, 291, 366, 11, 570, 286, 1454, 286, 13447], "temperature": 0.0, "avg_logprob": -0.21313546343547543, "compression_ratio": 1.590643274853801, "no_speech_prob": 9.245129331247881e-05}, {"id": 155, "seek": 108388, "start": 1095.3600000000001, "end": 1102.2800000000002, "text": " you that is cool. So here is some resources that to, to, to, to, to read offline. So GICS", "tokens": [291, 300, 307, 1627, 13, 407, 510, 307, 512, 3593, 300, 281, 11, 281, 11, 281, 11, 281, 11, 281, 1401, 21857, 13, 407, 460, 2532, 50], "temperature": 0.0, "avg_logprob": -0.21313546343547543, "compression_ratio": 1.590643274853801, "no_speech_prob": 9.245129331247881e-05}, {"id": 156, "seek": 108388, "start": 1102.2800000000002, "end": 1111.64, "text": " HPC is a group of people trying to apply this GICS tooling to, to, to, to, to scientific", "tokens": [12557, 34, 307, 257, 1594, 295, 561, 1382, 281, 3079, 341, 460, 2532, 50, 46593, 281, 11, 281, 11, 281, 11, 281, 11, 281, 8134], "temperature": 0.0, "avg_logprob": -0.21313546343547543, "compression_ratio": 1.590643274853801, "no_speech_prob": 9.245129331247881e-05}, {"id": 157, "seek": 111164, "start": 1111.64, "end": 1118.96, "text": " research. And we are organizing coffee gigs where we, we drink coffee and speak about GICS.", "tokens": [2132, 13, 400, 321, 366, 17608, 4982, 34586, 689, 321, 11, 321, 2822, 4982, 293, 1710, 466, 460, 2532, 50, 13], "temperature": 0.0, "avg_logprob": -0.20895337386870047, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.00017787926481105387}, {"id": 158, "seek": 111164, "start": 1118.96, "end": 1129.1200000000001, "text": " There is a, an article trying to explain this kind of vision of what GICS could provide", "tokens": [821, 307, 257, 11, 364, 7222, 1382, 281, 2903, 341, 733, 295, 5201, 295, 437, 460, 2532, 50, 727, 2893], "temperature": 0.0, "avg_logprob": -0.20895337386870047, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.00017787926481105387}, {"id": 159, "seek": 111164, "start": 1129.1200000000001, "end": 1138.3200000000002, "text": " for, for open research. And for French speaker, there is a one hour tutorial. So yeah. And", "tokens": [337, 11, 337, 1269, 2132, 13, 400, 337, 5522, 8145, 11, 456, 307, 257, 472, 1773, 7073, 13, 407, 1338, 13, 400], "temperature": 0.0, "avg_logprob": -0.20895337386870047, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.00017787926481105387}, {"id": 160, "seek": 113832, "start": 1138.32, "end": 1148.56, "text": " there is a, now GICS is tenure, so it's kind of ready. So they, we organize the ten years", "tokens": [456, 307, 257, 11, 586, 460, 2532, 50, 307, 32256, 11, 370, 309, 311, 733, 295, 1919, 13, 407, 436, 11, 321, 13859, 264, 2064, 924], "temperature": 0.0, "avg_logprob": -0.24086145673479353, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0002348352427361533}, {"id": 161, "seek": 113832, "start": 1148.56, "end": 1154.32, "text": " events where there is some really nice materials about, about GICS. And GICS is not new at", "tokens": [3931, 689, 456, 307, 512, 534, 1481, 5319, 466, 11, 466, 460, 2532, 50, 13, 400, 460, 2532, 50, 307, 406, 777, 412], "temperature": 0.0, "avg_logprob": -0.24086145673479353, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0002348352427361533}, {"id": 162, "seek": 113832, "start": 1154.32, "end": 1161.36, "text": " first them. So yeah, there is, all the number are, are linked to, to the previous presentation.", "tokens": [700, 552, 13, 407, 1338, 11, 456, 307, 11, 439, 264, 1230, 366, 11, 366, 9408, 281, 11, 281, 264, 3894, 5860, 13], "temperature": 0.0, "avg_logprob": -0.24086145673479353, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0002348352427361533}, {"id": 163, "seek": 113832, "start": 1161.36, "end": 1165.4399999999998, "text": " So as you see, there is a 31 presentation about GICS in first them. So you have a lot", "tokens": [407, 382, 291, 536, 11, 456, 307, 257, 10353, 5860, 466, 460, 2532, 50, 294, 700, 552, 13, 407, 291, 362, 257, 688], "temperature": 0.0, "avg_logprob": -0.24086145673479353, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0002348352427361533}, {"id": 164, "seek": 116544, "start": 1165.44, "end": 1174.48, "text": " of material about what GICS can do for, for your job, for your task. So you run in production", "tokens": [295, 2527, 466, 437, 460, 2532, 50, 393, 360, 337, 11, 337, 428, 1691, 11, 337, 428, 5633, 13, 407, 291, 1190, 294, 4265], "temperature": 0.0, "avg_logprob": -0.2254627178876828, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.00041800207691267133}, {"id": 165, "seek": 116544, "start": 1174.48, "end": 1180.44, "text": " on big cluster, but also in a lot of laptop and desktop. And here, for example, is to", "tokens": [322, 955, 13630, 11, 457, 611, 294, 257, 688, 295, 10732, 293, 14502, 13, 400, 510, 11, 337, 1365, 11, 307, 281], "temperature": 0.0, "avg_logprob": -0.2254627178876828, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.00041800207691267133}, {"id": 166, "seek": 116544, "start": 1180.44, "end": 1189.8, "text": " paper in completely, I mean, medical and biomedical stuff using GICS as a, as, as tooling with,", "tokens": [3035, 294, 2584, 11, 286, 914, 11, 4625, 293, 49775, 1507, 1228, 460, 2532, 50, 382, 257, 11, 382, 11, 382, 46593, 365, 11], "temperature": 0.0, "avg_logprob": -0.2254627178876828, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.00041800207691267133}, {"id": 167, "seek": 118980, "start": 1189.8, "end": 1195.44, "text": " as, as I presented about GICS shell, time machine and so on. So, okay, open science", "tokens": [382, 11, 382, 286, 8212, 466, 460, 2532, 50, 8720, 11, 565, 3479, 293, 370, 322, 13, 407, 11, 1392, 11, 1269, 3497], "temperature": 0.0, "avg_logprob": -0.21602281231746495, "compression_ratio": 1.671875, "no_speech_prob": 0.0001804893254302442}, {"id": 168, "seek": 118980, "start": 1195.44, "end": 1202.44, "text": " means to be able to trace and transparent because is to be able to, to collectively", "tokens": [1355, 281, 312, 1075, 281, 13508, 293, 12737, 570, 307, 281, 312, 1075, 281, 11, 281, 24341], "temperature": 0.0, "avg_logprob": -0.21602281231746495, "compression_ratio": 1.671875, "no_speech_prob": 0.0001804893254302442}, {"id": 169, "seek": 118980, "start": 1202.44, "end": 1206.68, "text": " study bug to bug, to be what is different from one thing to the other thing. And this", "tokens": [2979, 7426, 281, 7426, 11, 281, 312, 437, 307, 819, 490, 472, 551, 281, 264, 661, 551, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.21602281231746495, "compression_ratio": 1.671875, "no_speech_prob": 0.0001804893254302442}, {"id": 170, "seek": 118980, "start": 1206.68, "end": 1211.28, "text": " is a scientific method and we have to apply the scientific method to the computational", "tokens": [307, 257, 8134, 3170, 293, 321, 362, 281, 3079, 264, 8134, 3170, 281, 264, 28270], "temperature": 0.0, "avg_logprob": -0.21602281231746495, "compression_ratio": 1.671875, "no_speech_prob": 0.0001804893254302442}, {"id": 171, "seek": 118980, "start": 1211.28, "end": 1216.72, "text": " environment. This is my, my opinion and the message that I, I would like you bring back", "tokens": [2823, 13, 639, 307, 452, 11, 452, 4800, 293, 264, 3636, 300, 286, 11, 286, 576, 411, 291, 1565, 646], "temperature": 0.0, "avg_logprob": -0.21602281231746495, "compression_ratio": 1.671875, "no_speech_prob": 0.0001804893254302442}, {"id": 172, "seek": 121672, "start": 1216.72, "end": 1221.4, "text": " to home. And if you, if, if we have GICS, we can do that by controlling the environment", "tokens": [281, 1280, 13, 400, 498, 291, 11, 498, 11, 498, 321, 362, 460, 2532, 50, 11, 321, 393, 360, 300, 538, 14905, 264, 2823], "temperature": 0.0, "avg_logprob": -0.24443737296170967, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.0004974345210939646}, {"id": 173, "seek": 121672, "start": 1221.4, "end": 1227.48, "text": " and compare two different environment to know what is different. So, okay, this is,", "tokens": [293, 6794, 732, 819, 2823, 281, 458, 437, 307, 819, 13, 407, 11, 1392, 11, 341, 307, 11], "temperature": 0.0, "avg_logprob": -0.24443737296170967, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.0004974345210939646}, {"id": 174, "seek": 121672, "start": 1227.48, "end": 1234.72, "text": " yeah, the kind of, what we are trying to, to do with the GICS project. So, thank you.", "tokens": [1338, 11, 264, 733, 295, 11, 437, 321, 366, 1382, 281, 11, 281, 360, 365, 264, 460, 2532, 50, 1716, 13, 407, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.24443737296170967, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.0004974345210939646}, {"id": 175, "seek": 121672, "start": 1234.72, "end": 1236.72, "text": " And I'm ready for your question.", "tokens": [400, 286, 478, 1919, 337, 428, 1168, 13], "temperature": 0.0, "avg_logprob": -0.24443737296170967, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.0004974345210939646}, {"id": 176, "seek": 123672, "start": 1236.72, "end": 1249.72, "text": " Yeah. Yeah. So, we have five minutes for questions and switching speakers. Please take question", "tokens": [865, 13, 865, 13, 407, 11, 321, 362, 1732, 2077, 337, 1651, 293, 16493, 9518, 13, 2555, 747, 1168], "temperature": 0.0, "avg_logprob": -0.33989929623074, "compression_ratio": 1.328125, "no_speech_prob": 0.013743716292083263}, {"id": 177, "seek": 123672, "start": 1249.72, "end": 1253.72, "text": " and do repeat them for the stream. Thanks. I will try to do my best. Yeah.", "tokens": [293, 360, 7149, 552, 337, 264, 4309, 13, 2561, 13, 286, 486, 853, 281, 360, 452, 1151, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.33989929623074, "compression_ratio": 1.328125, "no_speech_prob": 0.013743716292083263}, {"id": 178, "seek": 125372, "start": 1253.72, "end": 1277.08, "text": " Yeah. Ah. Lobing. So, the question is, okay, I, I, I don't have the, the, the root privilege", "tokens": [865, 13, 2438, 13, 30719, 278, 13, 407, 11, 264, 1168, 307, 11, 1392, 11, 286, 11, 286, 11, 286, 500, 380, 362, 264, 11, 264, 11, 264, 5593, 12122], "temperature": 0.0, "avg_logprob": -0.22281237306265994, "compression_ratio": 1.356060606060606, "no_speech_prob": 0.001903603901155293}, {"id": 179, "seek": 125372, "start": 1277.08, "end": 1281.76, "text": " to install GICS on the cluster because once GICS is installed on any cluster, you can,", "tokens": [281, 3625, 460, 2532, 50, 322, 264, 13630, 570, 1564, 460, 2532, 50, 307, 8899, 322, 604, 13630, 11, 291, 393, 11], "temperature": 0.0, "avg_logprob": -0.22281237306265994, "compression_ratio": 1.356060606060606, "no_speech_prob": 0.001903603901155293}, {"id": 180, "seek": 128176, "start": 1281.76, "end": 1285.76, "text": " you can run it without privilege, but you need to install, the first time you need to", "tokens": [291, 393, 1190, 309, 1553, 12122, 11, 457, 291, 643, 281, 3625, 11, 264, 700, 565, 291, 643, 281], "temperature": 0.0, "avg_logprob": -0.1717050357127753, "compression_ratio": 1.73828125, "no_speech_prob": 0.0013136263005435467}, {"id": 181, "seek": 128176, "start": 1285.76, "end": 1291.64, "text": " install GICS, you need root privilege. And the system administrator of my cluster doesn't", "tokens": [3625, 460, 2532, 50, 11, 291, 643, 5593, 12122, 13, 400, 264, 1185, 25529, 295, 452, 13630, 1177, 380], "temperature": 0.0, "avg_logprob": -0.1717050357127753, "compression_ratio": 1.73828125, "no_speech_prob": 0.0013136263005435467}, {"id": 182, "seek": 128176, "start": 1291.64, "end": 1298.36, "text": " mean, yeah, I need to convince him. So, maybe the, the answer is to say other people are,", "tokens": [914, 11, 1338, 11, 286, 643, 281, 13447, 796, 13, 407, 11, 1310, 264, 11, 264, 1867, 307, 281, 584, 661, 561, 366, 11], "temperature": 0.0, "avg_logprob": -0.1717050357127753, "compression_ratio": 1.73828125, "no_speech_prob": 0.0013136263005435467}, {"id": 183, "seek": 128176, "start": 1298.36, "end": 1303.36, "text": " are already doing that. So, it's, it's not, I mean, to reduce the scare to, to, to provide", "tokens": [366, 1217, 884, 300, 13, 407, 11, 309, 311, 11, 309, 311, 406, 11, 286, 914, 11, 281, 5407, 264, 17185, 281, 11, 281, 11, 281, 2893], "temperature": 0.0, "avg_logprob": -0.1717050357127753, "compression_ratio": 1.73828125, "no_speech_prob": 0.0013136263005435467}, {"id": 184, "seek": 128176, "start": 1303.36, "end": 1311.0, "text": " a new tool. This is what I, I, I would like to try to say, okay, these people are doing,", "tokens": [257, 777, 2290, 13, 639, 307, 437, 286, 11, 286, 11, 286, 576, 411, 281, 853, 281, 584, 11, 1392, 11, 613, 561, 366, 884, 11], "temperature": 0.0, "avg_logprob": -0.1717050357127753, "compression_ratio": 1.73828125, "no_speech_prob": 0.0013136263005435467}, {"id": 185, "seek": 131100, "start": 1311.0, "end": 1319.0, "text": " they're doing it. So, maybe it's not so scary. Uh, I think it was after, yeah. So, yeah.", "tokens": [436, 434, 884, 309, 13, 407, 11, 1310, 309, 311, 406, 370, 6958, 13, 4019, 11, 286, 519, 309, 390, 934, 11, 1338, 13, 407, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.28127369513878453, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.00038524935371242464}, {"id": 186, "seek": 131100, "start": 1319.0, "end": 1323.0, "text": " Yeah. You mentioned that you're not sure how, how big the time window is. Yeah.", "tokens": [865, 13, 509, 2835, 300, 291, 434, 406, 988, 577, 11, 577, 955, 264, 565, 4910, 307, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.28127369513878453, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.00038524935371242464}, {"id": 187, "seek": 131100, "start": 1323.0, "end": 1329.0, "text": " If you look today, how far can you back and still reproduce? So, five years, ten years?", "tokens": [759, 291, 574, 965, 11, 577, 1400, 393, 291, 646, 293, 920, 29501, 30, 407, 11, 1732, 924, 11, 2064, 924, 30], "temperature": 0.0, "avg_logprob": -0.28127369513878453, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.00038524935371242464}, {"id": 188, "seek": 131100, "start": 1329.0, "end": 1335.0, "text": " No. So, the, the question is, okay, what is the size of the window and can we go back", "tokens": [883, 13, 407, 11, 264, 11, 264, 1168, 307, 11, 1392, 11, 437, 307, 264, 2744, 295, 264, 4910, 293, 393, 321, 352, 646], "temperature": 0.0, "avg_logprob": -0.28127369513878453, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.00038524935371242464}, {"id": 189, "seek": 133500, "start": 1335.0, "end": 1341.0, "text": " five years, uh, from now in the past? The issue is that the, the mechanism to, to bring", "tokens": [1732, 924, 11, 2232, 11, 490, 586, 294, 264, 1791, 30, 440, 2734, 307, 300, 264, 11, 264, 7513, 281, 11, 281, 1565], "temperature": 0.0, "avg_logprob": -0.12272500991821289, "compression_ratio": 1.5934579439252337, "no_speech_prob": 0.000793111976236105}, {"id": 190, "seek": 133500, "start": 1341.0, "end": 1348.0, "text": " back in time or to, to, to travel in time in GICS, uh, had been introduced in, uh, 2019.", "tokens": [646, 294, 565, 420, 281, 11, 281, 11, 281, 3147, 294, 565, 294, 460, 2532, 50, 11, 2232, 11, 632, 668, 7268, 294, 11, 2232, 11, 6071, 13], "temperature": 0.0, "avg_logprob": -0.12272500991821289, "compression_ratio": 1.5934579439252337, "no_speech_prob": 0.000793111976236105}, {"id": 191, "seek": 133500, "start": 1348.0, "end": 1354.0, "text": " So, in fact, with GICS, we don't have the tooling to go back earlier. So, now, I mean,", "tokens": [407, 11, 294, 1186, 11, 365, 460, 2532, 50, 11, 321, 500, 380, 362, 264, 46593, 281, 352, 646, 3071, 13, 407, 11, 586, 11, 286, 914, 11], "temperature": 0.0, "avg_logprob": -0.12272500991821289, "compression_ratio": 1.5934579439252337, "no_speech_prob": 0.000793111976236105}, {"id": 192, "seek": 133500, "start": 1354.0, "end": 1363.0, "text": " the, the, the zero for GICS is, uh, is version one. So, it's, uh, 2019. Yeah.", "tokens": [264, 11, 264, 11, 264, 4018, 337, 460, 2532, 50, 307, 11, 2232, 11, 307, 3037, 472, 13, 407, 11, 309, 311, 11, 2232, 11, 6071, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.12272500991821289, "compression_ratio": 1.5934579439252337, "no_speech_prob": 0.000793111976236105}, {"id": 193, "seek": 136300, "start": 1363.0, "end": 1370.0, "text": " Um, a lot of, um, scientists are using macOS and not Linux. Is there, is it possible to", "tokens": [3301, 11, 257, 688, 295, 11, 1105, 11, 7708, 366, 1228, 7912, 4367, 293, 406, 18734, 13, 1119, 456, 11, 307, 309, 1944, 281], "temperature": 0.0, "avg_logprob": -0.12703029555503767, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004758773429784924}, {"id": 194, "seek": 136300, "start": 1370.0, "end": 1374.0, "text": " use all this stuff even though GICS can't really run on macOS?", "tokens": [764, 439, 341, 1507, 754, 1673, 460, 2532, 50, 393, 380, 534, 1190, 322, 7912, 4367, 30], "temperature": 0.0, "avg_logprob": -0.12703029555503767, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004758773429784924}, {"id": 195, "seek": 136300, "start": 1374.0, "end": 1380.0, "text": " So, GICS cannot run on macOS. But we can ask the question, is it transparent if we are", "tokens": [407, 11, 460, 2532, 50, 2644, 1190, 322, 7912, 4367, 13, 583, 321, 393, 1029, 264, 1168, 11, 307, 309, 12737, 498, 321, 366], "temperature": 0.0, "avg_logprob": -0.12703029555503767, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004758773429784924}, {"id": 196, "seek": 136300, "start": 1380.0, "end": 1386.0, "text": " running on macOS? So, is it, are we are playing scientific method if we are running on macOS?", "tokens": [2614, 322, 7912, 4367, 30, 407, 11, 307, 309, 11, 366, 321, 366, 2433, 8134, 3170, 498, 321, 366, 2614, 322, 7912, 4367, 30], "temperature": 0.0, "avg_logprob": -0.12703029555503767, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004758773429784924}, {"id": 197, "seek": 138600, "start": 1386.0, "end": 1395.0, "text": " So, I mean, I, I, I, I, I have not the question. It's, it's a collective decision. Yeah.", "tokens": [407, 11, 286, 914, 11, 286, 11, 286, 11, 286, 11, 286, 11, 286, 362, 406, 264, 1168, 13, 467, 311, 11, 309, 311, 257, 12590, 3537, 13, 865, 13], "temperature": 0.2, "avg_logprob": -0.3065067032008495, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0019114824244752526}, {"id": 198, "seek": 138600, "start": 1395.0, "end": 1403.0, "text": " My name is Alain. Um, as far as I understand, uh, GICS, uh, or GICS, uh, provides the same", "tokens": [1222, 1315, 307, 967, 491, 13, 3301, 11, 382, 1400, 382, 286, 1223, 11, 2232, 11, 460, 2532, 50, 11, 2232, 11, 420, 460, 2532, 50, 11, 2232, 11, 6417, 264, 912], "temperature": 0.2, "avg_logprob": -0.3065067032008495, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0019114824244752526}, {"id": 199, "seek": 138600, "start": 1403.0, "end": 1413.0, "text": " approach as the NICS. Yeah. So, um, I've never used, uh, GICS before, but I, uh, I have some", "tokens": [3109, 382, 264, 426, 2532, 50, 13, 865, 13, 407, 11, 1105, 11, 286, 600, 1128, 1143, 11, 2232, 11, 460, 2532, 50, 949, 11, 457, 286, 11, 2232, 11, 286, 362, 512], "temperature": 0.2, "avg_logprob": -0.3065067032008495, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0019114824244752526}, {"id": 200, "seek": 141300, "start": 1413.0, "end": 1418.0, "text": " experience with NICS. Uh, is there any crucial difference?", "tokens": [1752, 365, 426, 2532, 50, 13, 4019, 11, 307, 456, 604, 11462, 2649, 30], "temperature": 0.0, "avg_logprob": -0.15181924414446973, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.0006002361187711358}, {"id": 201, "seek": 141300, "start": 1418.0, "end": 1425.0, "text": " So, from my point of view, oops. Ah, sorry, anyway. Um, in the slides, there, there is", "tokens": [407, 11, 490, 452, 935, 295, 1910, 11, 34166, 13, 2438, 11, 2597, 11, 4033, 13, 3301, 11, 294, 264, 9788, 11, 456, 11, 456, 307], "temperature": 0.0, "avg_logprob": -0.15181924414446973, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.0006002361187711358}, {"id": 202, "seek": 141300, "start": 1425.0, "end": 1431.0, "text": " a, some, uh, appendix. So, there is extra slides. And there is one extra slide trying", "tokens": [257, 11, 512, 11, 2232, 11, 34116, 970, 13, 407, 11, 456, 307, 2857, 9788, 13, 400, 456, 307, 472, 2857, 4137, 1382], "temperature": 0.0, "avg_logprob": -0.15181924414446973, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.0006002361187711358}, {"id": 203, "seek": 141300, "start": 1431.0, "end": 1435.0, "text": " to, to explain what, from my point of view, the difference with NICS. So, the question", "tokens": [281, 11, 281, 2903, 437, 11, 490, 452, 935, 295, 1910, 11, 264, 2649, 365, 426, 2532, 50, 13, 407, 11, 264, 1168], "temperature": 0.0, "avg_logprob": -0.15181924414446973, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.0006002361187711358}, {"id": 204, "seek": 141300, "start": 1435.0, "end": 1440.0, "text": " is, uh, what is the difference between NICS and, and GICS? Because NICS, you, I mean,", "tokens": [307, 11, 2232, 11, 437, 307, 264, 2649, 1296, 426, 2532, 50, 293, 11, 293, 460, 2532, 50, 30, 1436, 426, 2532, 50, 11, 291, 11, 286, 914, 11], "temperature": 0.0, "avg_logprob": -0.15181924414446973, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.0006002361187711358}, {"id": 205, "seek": 144000, "start": 1440.0, "end": 1445.0, "text": " GICS use exactly the same, uh, functional strategy, package management, functional", "tokens": [460, 2532, 50, 764, 2293, 264, 912, 11, 2232, 11, 11745, 5206, 11, 7372, 4592, 11, 11745], "temperature": 0.0, "avg_logprob": -0.12734665014804938, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005291800480335951}, {"id": 206, "seek": 144000, "start": 1445.0, "end": 1449.0, "text": " strategy. So, what is the difference? From my point of view, the difference is that you", "tokens": [5206, 13, 407, 11, 437, 307, 264, 2649, 30, 3358, 452, 935, 295, 1910, 11, 264, 2649, 307, 300, 291], "temperature": 0.0, "avg_logprob": -0.12734665014804938, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005291800480335951}, {"id": 207, "seek": 144000, "start": 1449.0, "end": 1455.0, "text": " have a continuum in GICS in the language. The package are, are, are, are wrote in scheme", "tokens": [362, 257, 36120, 294, 460, 2532, 50, 294, 264, 2856, 13, 440, 7372, 366, 11, 366, 11, 366, 11, 366, 4114, 294, 12232], "temperature": 0.0, "avg_logprob": -0.12734665014804938, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005291800480335951}, {"id": 208, "seek": 144000, "start": 1455.0, "end": 1461.0, "text": " and, and, and, and the, the code of, uh, GICS itself is also wrote in scheme. The", "tokens": [293, 11, 293, 11, 293, 11, 293, 264, 11, 264, 3089, 295, 11, 2232, 11, 460, 2532, 50, 2564, 307, 611, 4114, 294, 12232, 13, 440], "temperature": 0.0, "avg_logprob": -0.12734665014804938, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005291800480335951}, {"id": 209, "seek": 144000, "start": 1461.0, "end": 1466.0, "text": " configuration file are wrote in scheme. So, you have a, a, a big continuation with", "tokens": [11694, 3991, 366, 4114, 294, 12232, 13, 407, 11, 291, 362, 257, 11, 257, 11, 257, 955, 29357, 365], "temperature": 0.0, "avg_logprob": -0.12734665014804938, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005291800480335951}, {"id": 210, "seek": 146600, "start": 1466.0, "end": 1471.0, "text": " everything. And because of that, you can extend GICS for your own, uh, uh, stuff.", "tokens": [1203, 13, 400, 570, 295, 300, 11, 291, 393, 10101, 460, 2532, 50, 337, 428, 1065, 11, 2232, 11, 2232, 11, 1507, 13], "temperature": 0.0, "avg_logprob": -0.10106391400362538, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0005516635719686747}, {"id": 211, "seek": 146600, "start": 1471.0, "end": 1477.0, "text": " So, for example, you can write a package transformation on the fly using, I mean,", "tokens": [407, 11, 337, 1365, 11, 291, 393, 2464, 257, 7372, 9887, 322, 264, 3603, 1228, 11, 286, 914, 11], "temperature": 0.0, "avg_logprob": -0.10106391400362538, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0005516635719686747}, {"id": 212, "seek": 146600, "start": 1477.0, "end": 1481.0, "text": " GICS as a library. You cannot do that with, with NICS because you have a lot of", "tokens": [460, 2532, 50, 382, 257, 6405, 13, 509, 2644, 360, 300, 365, 11, 365, 426, 2532, 50, 570, 291, 362, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.10106391400362538, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0005516635719686747}, {"id": 213, "seek": 146600, "start": 1481.0, "end": 1487.0, "text": " different tooling in C++ and some, uh, from my point of view, is this unity of,", "tokens": [819, 46593, 294, 383, 25472, 293, 512, 11, 2232, 11, 490, 452, 935, 295, 1910, 11, 307, 341, 18205, 295, 11], "temperature": 0.0, "avg_logprob": -0.10106391400362538, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0005516635719686747}, {"id": 214, "seek": 146600, "start": 1487.0, "end": 1491.0, "text": " of, of the, the, the, the continuum of the language.", "tokens": [295, 11, 295, 264, 11, 264, 11, 264, 11, 264, 36120, 295, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.10106391400362538, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0005516635719686747}, {"id": 215, "seek": 149100, "start": 1491.0, "end": 1496.0, "text": " Yeah. Yeah. But scheme allow you to, to write kind of domain specific language.", "tokens": [865, 13, 865, 13, 583, 12232, 2089, 291, 281, 11, 281, 2464, 733, 295, 9274, 2685, 2856, 13], "temperature": 0.0, "avg_logprob": -0.2626097855294586, "compression_ratio": 2.347826086956522, "no_speech_prob": 0.0014117786195129156}, {"id": 216, "seek": 149100, "start": 1496.0, "end": 1501.0, "text": " It's, it's, uh, it's, uh, it's, uh, yeah. It's, it's a, it's a good language to, to", "tokens": [467, 311, 11, 309, 311, 11, 2232, 11, 309, 311, 11, 2232, 11, 309, 311, 11, 2232, 11, 1338, 13, 467, 311, 11, 309, 311, 257, 11, 309, 311, 257, 665, 2856, 281, 11, 281], "temperature": 0.0, "avg_logprob": -0.2626097855294586, "compression_ratio": 2.347826086956522, "no_speech_prob": 0.0014117786195129156}, {"id": 217, "seek": 149100, "start": 1501.0, "end": 1505.0, "text": " write domain specific language. So, in fact, you have the both of, of the two worlds.", "tokens": [2464, 9274, 2685, 2856, 13, 407, 11, 294, 1186, 11, 291, 362, 264, 1293, 295, 11, 295, 264, 732, 13401, 13], "temperature": 0.0, "avg_logprob": -0.2626097855294586, "compression_ratio": 2.347826086956522, "no_speech_prob": 0.0014117786195129156}, {"id": 218, "seek": 149100, "start": 1505.0, "end": 1507.0, "text": " From my point of view. Thank you.", "tokens": [3358, 452, 935, 295, 1910, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.2626097855294586, "compression_ratio": 2.347826086956522, "no_speech_prob": 0.0014117786195129156}, {"id": 219, "seek": 149100, "start": 1507.0, "end": 1509.0, "text": " Oh yeah. Sorry. Last question. Yeah.", "tokens": [876, 1338, 13, 4919, 13, 5264, 1168, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.2626097855294586, "compression_ratio": 2.347826086956522, "no_speech_prob": 0.0014117786195129156}, {"id": 220, "seek": 149100, "start": 1509.0, "end": 1513.0, "text": " Uh, that's good. It's, it's, it's, it's a good language to, to write domain specific", "tokens": [4019, 11, 300, 311, 665, 13, 467, 311, 11, 309, 311, 11, 309, 311, 11, 309, 311, 257, 665, 2856, 281, 11, 281, 2464, 9274, 2685], "temperature": 0.0, "avg_logprob": -0.2626097855294586, "compression_ratio": 2.347826086956522, "no_speech_prob": 0.0014117786195129156}, {"id": 221, "seek": 149100, "start": 1513.0, "end": 1517.0, "text": " language. So, in fact, you have the both of, of the two worlds. From my point of", "tokens": [2856, 13, 407, 11, 294, 1186, 11, 291, 362, 264, 1293, 295, 11, 295, 264, 732, 13401, 13, 3358, 452, 935, 295], "temperature": 0.0, "avg_logprob": -0.2626097855294586, "compression_ratio": 2.347826086956522, "no_speech_prob": 0.0014117786195129156}, {"id": 222, "seek": 151700, "start": 1517.0, "end": 1522.0, "text": " view. Yeah. This is, uh, so, when you are running GICS, for example, on the top of", "tokens": [1910, 13, 865, 13, 639, 307, 11, 2232, 11, 370, 11, 562, 291, 366, 2614, 460, 2532, 50, 11, 337, 1365, 11, 322, 264, 1192, 295], "temperature": 0.0, "avg_logprob": -0.2865811665852865, "compression_ratio": 1.8426966292134832, "no_speech_prob": 0.0004148246080148965}, {"id": 223, "seek": 151700, "start": 1522.0, "end": 1529.0, "text": " Debian, so, uh, how do we manage the graph and can we cut the graph to reuse a part", "tokens": [1346, 20196, 11, 370, 11, 2232, 11, 577, 360, 321, 3067, 264, 4295, 293, 393, 321, 1723, 264, 4295, 281, 26225, 257, 644], "temperature": 0.0, "avg_logprob": -0.2865811665852865, "compression_ratio": 1.8426966292134832, "no_speech_prob": 0.0004148246080148965}, {"id": 224, "seek": 151700, "start": 1529.0, "end": 1535.0, "text": " of the Debian part? I mean, a part of the graph from Debian. So, the question is,", "tokens": [295, 264, 1346, 20196, 644, 30, 286, 914, 11, 257, 644, 295, 264, 4295, 490, 1346, 20196, 13, 407, 11, 264, 1168, 307, 11], "temperature": 0.0, "avg_logprob": -0.2865811665852865, "compression_ratio": 1.8426966292134832, "no_speech_prob": 0.0004148246080148965}, {"id": 225, "seek": 151700, "start": 1535.0, "end": 1541.0, "text": " uh, maybe it could be, maybe it could be, maybe it could be, maybe it could be,", "tokens": [2232, 11, 1310, 309, 727, 312, 11, 1310, 309, 727, 312, 11, 1310, 309, 727, 312, 11, 1310, 309, 727, 312, 11], "temperature": 0.0, "avg_logprob": -0.2865811665852865, "compression_ratio": 1.8426966292134832, "no_speech_prob": 0.0004148246080148965}, {"id": 226, "seek": 154100, "start": 1541.0, "end": 1547.0, "text": " a part of the graph from Debian. So, the question is, uh, maybe it could be", "tokens": [257, 644, 295, 264, 4295, 490, 1346, 20196, 13, 407, 11, 264, 1168, 307, 11, 2232, 11, 1310, 309, 727, 312], "temperature": 0.6000000000000001, "avg_logprob": -0.19370297635539194, "compression_ratio": 1.5656565656565657, "no_speech_prob": 0.0003035428235307336}, {"id": 227, "seek": 154100, "start": 1547.0, "end": 1555.0, "text": " helpful for some packages. But, but when you do that, you are not able to, to", "tokens": [4961, 337, 512, 17401, 13, 583, 11, 457, 562, 291, 360, 300, 11, 291, 366, 406, 1075, 281, 11, 281], "temperature": 0.6000000000000001, "avg_logprob": -0.19370297635539194, "compression_ratio": 1.5656565656565657, "no_speech_prob": 0.0003035428235307336}, {"id": 228, "seek": 154100, "start": 1555.0, "end": 1559.0, "text": " manage the computational environment. Because if you have, for example, if I", "tokens": [3067, 264, 28270, 2823, 13, 1436, 498, 291, 362, 11, 337, 1365, 11, 498, 286], "temperature": 0.6000000000000001, "avg_logprob": -0.19370297635539194, "compression_ratio": 1.5656565656565657, "no_speech_prob": 0.0003035428235307336}, {"id": 229, "seek": 154100, "start": 1559.0, "end": 1565.0, "text": " cut the graph on Debian, so I have a, a state in, in Debian with some packages,", "tokens": [1723, 264, 4295, 322, 1346, 20196, 11, 370, 286, 362, 257, 11, 257, 1785, 294, 11, 294, 1346, 20196, 365, 512, 17401, 11], "temperature": 0.6000000000000001, "avg_logprob": -0.19370297635539194, "compression_ratio": 1.5656565656565657, "no_speech_prob": 0.0003035428235307336}, {"id": 230, "seek": 156500, "start": 1565.0, "end": 1570.6, "text": " I cut the graph at some place to use these Debian packages.", "tokens": [286, 1723, 264, 4295, 412, 512, 1081, 281, 764, 613, 1346, 20196, 17401, 13], "temperature": 0.0, "avg_logprob": -0.22031614159335608, "compression_ratio": 1.771186440677966, "no_speech_prob": 0.07298202067613602}, {"id": 231, "seek": 156500, "start": 1570.6, "end": 1574.04, "text": " If I do that, how my collaborator can cut the graph", "tokens": [759, 286, 360, 300, 11, 577, 452, 5091, 1639, 393, 1723, 264, 4295], "temperature": 0.0, "avg_logprob": -0.22031614159335608, "compression_ratio": 1.771186440677966, "no_speech_prob": 0.07298202067613602}, {"id": 232, "seek": 156500, "start": 1574.04, "end": 1576.52, "text": " in the same place with the same Debian packages?", "tokens": [294, 264, 912, 1081, 365, 264, 912, 1346, 20196, 17401, 30], "temperature": 0.0, "avg_logprob": -0.22031614159335608, "compression_ratio": 1.771186440677966, "no_speech_prob": 0.07298202067613602}, {"id": 233, "seek": 156500, "start": 1576.52, "end": 1579.48, "text": " So this is kind of issue of replicability.", "tokens": [407, 341, 307, 733, 295, 2734, 295, 3248, 299, 2310, 13], "temperature": 0.0, "avg_logprob": -0.22031614159335608, "compression_ratio": 1.771186440677966, "no_speech_prob": 0.07298202067613602}, {"id": 234, "seek": 156500, "start": 1579.48, "end": 1580.76, "text": " So from a practical point of view,", "tokens": [407, 490, 257, 8496, 935, 295, 1910, 11], "temperature": 0.0, "avg_logprob": -0.22031614159335608, "compression_ratio": 1.771186440677966, "no_speech_prob": 0.07298202067613602}, {"id": 235, "seek": 156500, "start": 1580.76, "end": 1582.92, "text": " it could be nice because, for example,", "tokens": [309, 727, 312, 1481, 570, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.22031614159335608, "compression_ratio": 1.771186440677966, "no_speech_prob": 0.07298202067613602}, {"id": 236, "seek": 156500, "start": 1582.92, "end": 1586.84, "text": " Debian has some machine learning packages that are not", "tokens": [1346, 20196, 575, 512, 3479, 2539, 17401, 300, 366, 406], "temperature": 0.0, "avg_logprob": -0.22031614159335608, "compression_ratio": 1.771186440677966, "no_speech_prob": 0.07298202067613602}, {"id": 237, "seek": 156500, "start": 1586.84, "end": 1590.0, "text": " yet in Geek, so maybe we can reuse some part.", "tokens": [1939, 294, 2876, 916, 11, 370, 1310, 321, 393, 26225, 512, 644, 13], "temperature": 0.0, "avg_logprob": -0.22031614159335608, "compression_ratio": 1.771186440677966, "no_speech_prob": 0.07298202067613602}, {"id": 238, "seek": 156500, "start": 1590.0, "end": 1592.6, "text": " But from a replicability point of view,", "tokens": [583, 490, 257, 3248, 299, 2310, 935, 295, 1910, 11], "temperature": 0.0, "avg_logprob": -0.22031614159335608, "compression_ratio": 1.771186440677966, "no_speech_prob": 0.07298202067613602}, {"id": 239, "seek": 159260, "start": 1592.6, "end": 1596.76, "text": " you lose the property to move from one place to the other.", "tokens": [50364, 291, 3624, 264, 4707, 281, 1286, 490, 472, 1081, 281, 264, 661, 13, 50572], "temperature": 0.0, "avg_logprob": -0.29761502146720886, "compression_ratio": 1.0, "no_speech_prob": 0.006381439045071602}], "language": "en"}