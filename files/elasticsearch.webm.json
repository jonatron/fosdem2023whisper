{"text": " So, before we go on with the next security or later topic, we're going to talk about something completely different, and that is about elastic search internals by Martin from the Bulgaria jug, and maybe also about security in this context. So, we're going to talk about something completely different, and maybe also about security in this context. Test, test, test. Thank you. So, people coming in, please move to the middle of your row so that there's space on the side so people can sit. We're working in Cisco together, so a lot of people coming, so we can start. If you're standing along the side, please take a seat. So, hello, everyone. My name is Martin, and I'm a consulting architect at the European Patient Office. I've been also doing a lot of consultancy on elastic search in the past two to three years. So, just before we start with this session, how many of you are using or have used elastic search in a project? Okay, more than half of the people. So, why this talk at FOSDEM? So, multiple reasons, in fact. When I've worked with elastic search, I realized that even though it has quite a good documentation, in many cases, you need to go into the public code base and see what's in there, and to understand how it works. I've had questions from many people, how this functionality works, or how can I achieve something with elastic search. And not always it's clear from documentation or blocks over the Internet what you can achieve with elastic search. So, in this short session, I'll try to show you how this elastic search works internally, and I'll talk about the elastic search architecture. So, first of all, we'll do a 360-degree overview of the elastic search stack, which I believe most of you are familiar with. Then I'll go into the elastic search architecture, and at the end of this short session, I'll show you how you can write a very simple elastic search plugin. In most cases, you won't need to write an elastic search plugin because there is quite a rich ecosystem of elastic search plugins that you can use. But many companies find that that's not always the case. So, sometimes you need to either customize something in elastic search or write your own plugin to achieve something. All right. So, let's talk briefly about the elastic search stack. In the middle, we have elastic search, which is a Java application. It's being updated quite oftenly. There are a lot of features being implemented in elastic search, especially in the latest few releases. And around the elastic search server application, there are different applications that are being built to allow you to work more easily with elastic search, such as Kibana. Kibana is a user-rich user interface for elastic search that allows you to achieve multiple things, so not only querying elastic search, but Kibana allows you to also visualize data that's already in elastic search or build different dashboards that are quite nice, especially for management. Also, if you want to put different data from a variety of sources in elastic search, you can use LogStash. So, originally, LogStash was implemented to provide a way to aggregate logs into elastic search. But over time, LogStash evolves to an application that is used to integrate data in elastic search, not only log data, but any kind of data. So, you can think of LogStash as a log aggregation pipeline that allows you to put data in elastic search. And on top of that, we also have a different set of so-called bits applications that are lightweight log shippers that allow you to collect data and put it either directly into an elastic search or through LogStash into elastic search or different other data sources. The specific thing about the bit applications is that they are lightweight in nature, so they are supposed to not consume a lot of resources such as CPU and memory. And in that reason, they allow you to collect log data or other data and put it into elastic search. Now, you can think of elastic search as a web server built on top of the Apache Lucene library. So, the Apache Lucene library is an actively developed Java library that is used by different applications that want to implement some kind of search functionality. And elastic search is one of them. So, I'll show briefly in a few slides how elastic search interacts with the Apache Lucene library. And another way to describe elastic search is a document-oriented database. So, elastic search is used by different projects not only for searching, but also as a NoSQL database. So, I had a few projects where elastic search was used purely as a NoSQL database, not as a search engine. And one can think, okay, elastic search is a Java application. Why I cannot use Apache Lucene directly? And the reason is that elastic search provides a number of features that are missing in the Apache Lucene library that allow you to implement search in your project way more easily than using directly Apache Lucene. Some of these features are, for example, JSON-based REST API, which is quite easy to use, quite easy to write search queries, to index data into elastic search, and so on. There is also a really nice clustering mechanism implemented in elastic search that allows you to bring and scale your elastic search cluster quite easily, something that's not possible if you use directly Apache Lucene in your project directly. And also, it has a number of other features, such as, for example, caching, that allow you to improve the performance of your search queries, and so on. Now, the basic data structure used by elastic search is the so-called inverted index, and indexes are stored on disk in separate files or Lucene segments. Search can be performed on multiple indexes at a time. That's one of the capabilities of elastic search. And in earlier versions of elastic search, documents were logically grouped by types. That was effectively deprecated as a version 7 of elastic search, and it's expected to be dropped. In order to ensure score relevancy when you search for some data in elastic search, elastic search uses a set of different algorithms to score results relevance. In the later versions of elastic search, this algorithm is BM25. In earlier versions of elastic search, this was a simpler algorithm which is called TFIDF. And the base of those algorithms is the fact how many times does a term occur in a document, and how many times does this term occur across all documents that are currently indexed in elastic search. Based on that, by default, elastic search scores every result that gets returned by your search query, and by default, it returns results sorted by relevant score. Now, why would you use elastic search in favor, for example, of a relational database? Well, it provides faster retrieval for documents in way more scenarios than a traditional relational database can do. So, as you know, traditional relational databases provide faster searches through indexes. However, indexes in relational databases have many limitations based on the type of SQL queries that you write. In elastic search, the inverted index data structure provides with the capability to cover way more scenarios for searching using more complex queries. And for that reason, many projects choose to use elastic search as a search engine. Now, documents also in elastic search might not have an explicit schema, as you have in a relational database, and that's typical for many no-SQL databases. An explicit schema, however, can be defined on the fields, and certain fields can even have different types mapped to them. This is needed because sometimes you need to use different kinds of search queries based on the field type, and some field types pose limitations. So, that's why you might need to have multiple types on a single field in elastic search. Now, this was brief about what is elastic search and how it works. Now, let's see what the architecture of elastic search. Elastic search, as I mentioned to you, is designed with clustering in mind. By default, in later versions of elastic search, if you start, if you create an index, it has one primary chart and one replica chart. So, what is a chart? Now, an elastic search index contains one or more primary charts that distribute the data in the elastic search cluster. Below that, an elastic search chart is, in fact, a Lucene index, and a Lucene index is, in fact, the data structure that stores the data on disk in terms of Lucene segments. Lucene segments are the physical files that store data on the disk. Now, when you index data in elastic search, you might have also replica charts. Replica charts provide you with the possibility to enable high availability and data replication at the level of the elastic search cluster. So, two types of charts, primary and replica charts. The more notes you add to the elastic search cluster, the more data gets distributed among charts. Now, it's very important that up front you plan the number of primary charts based on the data growth that you have. It's very difficult to change later in your project lifecycle the number of primary charts you would need to re-index data. However, if you want to change the number of replica charts, that's more easy to do later in time. So, it's very important that you plan up front what's the number of primary charts on an index that you create. Now, by default, elastic search tries to balance the number of charts across the notes that you have. And one of the other capabilities that elastic search provides you is that if a note fails, you still can get search results, or so-called partial results can be returned, even if some of the notes in the cluster are not available. Now, by default, elastic search determines the chart where a document is indexed based on a relatively simple formula. You get the hash key of the routing key of the document. This is the document ID, which can be generated in different ways. You can generate it from elastic search. If you don't specify your application, you can supply the document ID, and so on and so forth. And you'll take the modules, the number of primary charts that you have defined on the index, where you index the document. Now, as I mentioned, by default, the routing key is the document ID, but you can also use a different routing key. And one interesting technique that some people use to enable distribution of data in the elastic search cluster is by specifying a custom routing key that allows you to enable so-called chart routing. This is a technique that allows you to specify at which particular chart you want to send the document to be indexed. But that's a case that's used in some specific scenarios. In most cases, people rely on the default mechanism that elastic search uses to distribute data in the cluster. Now, by default, new nodes are discovered via multicast. If a cluster is discovered, a new node joins the cluster if it has the same cluster name. If a node on the same instance already runs on a specified port, and if you try to run another node on that instance, elastic search automatically gives you the next available port. Now, however, in some cases, in some companies, multicast addresses are disabled for security reasons. And that's why the preferred mechanism to join new nodes in an elastic search cluster is by using unicast addresses. In the elastic search YAML configuration, you just need to specify one or more existing nodes from the elastic search cluster so that they can join that existing cluster. And in that list of unicast nodes, you don't need to specify all the nodes in the elastic search cluster. You just need to specify at least one node that has already joined the cluster. Now, when you bring up an elastic search cluster, there are some considerations that you need to take. First of all, as I mentioned, sharding, it's very important for you to consider what should be the number of primary shards that you define on the elastic search index, and the number of replica shards, which is more easy to change over time. You also need to consider how much data you store in an elastic search index. Indexes with too small amount of data are not good, because that implies a lot of management overhead. And the same is for indexes with too many amounts of data. I've seen some cases where people store, let's say, more than two, three hundred gigabytes of data in an elastic search index. And that really slows down search operations and other operations of that index. And people start wondering, okay, why is my indexing slow? Why are my search queries slow? And in many cases, the reason is that because data is not distributed properly in the elastic search index. The preferred amount of data that you should keep in an elastic search shard is between five and ten gigabytes, roughly speaking. So if you have more data that you want to put on a shard, you should consider splitting that data. So you either use more shards in the cluster, or you split the data into so-called sequential indexes. So for example, you might have daily, weekly, or monthly indexes. Now, this is what I mentioned. So you should avoid putting too less data in the elastic search cluster. Also, if you have too many shards defined on an index, that also introduces performance and management overhead. So you should consider rather splitting the data in the index rather than bringing too many shards on a single index. And determining the number of shards should be a matter of upfront planning. Now, apart from putting the fact that you need to avoid putting large amounts of data in a single index, the main strategy that people use is to use, for example, prefix when they split data into indexes. For example, you can put prefix for daily, weekly, or yearly indexes. And if you do that, it's a good practice that also you use aliases to reference data, directly reference a particular index in your application, but rather use aliases. In terms of concurrency control, elastic search does not provide pessimistic locking, like, for example, you have in relational databases. If you want to establish some form of concurrency control in elastic search in order to make sure that you don't have unexpected race conditions, so elastic search uses optimistic locking for concurrency control. The way this works is when you index a document, there is a version attribute that can be specified. And if there is already a document indexed with that version, then the operation is rejected from elastic search. Concurrency control can also be achieved with the two fields that can be specified when you index the document. If sequence number and if primary term parameters, if they already match the document that's indexed, then this operation gets rejected. So if you want to establish some form of concurrency control in elastic search, you can use this optimistic locking provided by elastic search. In terms of high availability, you can create one or more copies, or so-called replicas of an existing index. The number of primary charts is specified when you define the index mapping, or you can change it later. Once an index request is sent to a particular chart, determined based on the hash of the document ID. The document is also sent to the chart replicas. And one interesting property in elastic search is that the replicas are not used only for high availability, but also used for searching purposes to improve performance. So when you have replica charts, they also participate in the search requests that you have for elastic search. Now, this mechanism for improving performance is really nice, but this doesn't mean that you need to supply to increase the number of replicas because, of course, that increases management overhead. So it's also a matter of determining how many replicas up front you would need. And later on, if you plan to scale your cluster, you can also increase the amount of replicas. So you should not put a lot of replica charts also at the beginning when you define your indexes. Now, how is a chart request processed? Now, if we want to index a document in elastic search, what happens? We send the request to a coordinating node. This is one of the nodes in the elastic search cluster. And this coordinating node sends the request to the chart, to the node in the cluster where the document needs to be indexed and stored in Lucene segments. When the document reaches the elastic search node in the cluster, the particular chart, it gets sent not directly to the disk, but to two in-memory areas. This is the memory buffer and the transaction lock. Now, the memory buffer gets flushed every second to the disk. So when you index a document in elastic search, you cannot expect it to be available right way for searching purposes. But there is also a parameter that you can use to enforce it to be written to disk right away before waiting for this one second to be flushed on disk. There is also another area, which is called the transaction lock, where it gets flushed not so often. It gets flushed every 30 minutes or when it gets full. So the important takeover from this is that when you index a document, you should not expect it to be available right way for searching, but you can enforce it too. What happens if you send the search query to elastic search? First, the search request gets sent to one of the nodes in the elastic search cluster, the so-called coordinating node. Then we have two phases. First is the query phase. It asks all the shots, primary and replica shots, hey, do you contain some data for that search query? And this information gets returned to the coordinating node. Based on that information, the coordinating node determines which nodes it needs to query. And on the second fetch phase, it sends the request to the shots that have some data for that search query and return it back to the client. Now, in terms of how is the elastic search called base structured, this is a snapshot from the GitHub code base of elastic search from the public code base. Now, what I'm speaking about in this presentation applies for the public code base in elastic search because of version 7.16, there was a licensing change, and there is a lot of controversy in the open source communities whether elastic search is still open source or not. So we can have a discussion about that after the session. I'm not going to go into the details, but the main thing about this licensing change is to protect elastic search from other vendors willing to provide elastic search as a service, not from people willing to customize elastic search or to use it for their in-house projects and so on. So this is the structure of the elastic search code base that has been like this since the Apache license code base. So elastic search gets built with GitHub actions. You can see also the definition in the.github folder. The main server application is in the server folder. The documentation that gets generated on the official elastic search website is in the docs folder. We have the main modules for the elastic search server application in the modules folder and the internal plugins in the plugins folder. An implementation of the REST based Java client for elastic search, the high level and the low level REST funds are in the client folder, and the distribution folder, you can find the gradle scripts that allow you to build different distributions of elastic search for Linux, Windows, and so on. Now, I would say the structure of the code repository is very logical. It's easy to navigate. So you can just go into GitHub, and if you need to see, for example, how is a particular plugin or module implemented, you can just go to GitHub and check it out. Now, internally elastic search is comprised of different modules. And in earlier versions, elastic search used the modified version of Google GIS for module binding, but they're slowly shifting away from Google GIS in favor of their own internal module system. So modules are loaded on startup when the elastic search server starts up. And in this simple example, I've shown an example of how modules were bound internally when the node starts up. So we use a module binder. The earlier versions, B was a Google GIS binder. And then we bind particular module classes to their implementation. And then wherever you need them, you can reference them in the elastic search code base. It's a very simple dependency injection mechanism. Now, when elastic search starts up, you can imagine it's a simple Java application. The main class is Orc elastic search, bootstrap elastic search. It boils down to calling the start method of the node class. And the start method, in fact, loads up all the modules of the elastic search node. Now, some of these core modules are, for example, modules that provide the REST API of elastic search module that allows you to establish clustering and elastic search, or so-called transport module. There is a module that allows you to build plugins for elastic search, and so on and so forth. Now, how does elastic search internally interact with loosing? When you start up the node, the node also exposes, provides different services that are used by the modules of elastic search. And, for example, if you want to, when you start up a node, there is a createChart method that gets called, indexServiceCreateChart, to create and initialize the chart that is part of this elastic search node. And then, if you want to index a new document, it boils down to calling indexChartApplyIndexOperation on primary. Then, this boils down to calling the index method on the indexChart class. And the indexChart class goes down to an internal engine class that calls index into loosing. Then, that calls internal engine at docs. And at the end, we just call indexWriter, which is a class from the Apache Loosing Library, at documents. So, it boils down to calling different methods from the Loosing API. And on top of that, we have a lot of initialization and services happening. So, in a way, you can think that apart from all the functionality that elastic search provides, the integration with the Apache Loosing Library just boils down to calling the different APIs that Apache Loosing provides. And last but not least, I'll show how you can build a very simple elastic search plugin. Now, if you see the elastic search code base, it already has some building plugins that you can use. And there is a very nice elastic search plugin utility that you can use to manage plugins, to install them, remove them, and so on and so forth. If you build your own plugin, you can use the same utility to install the plugin, and it gets placed in a folder in your node installation. So, if you install a plugin, you need to make sure that it's installed on all the nodes in your cluster. Because many plugins are cluster aware, it needs to be installed on every node in the cluster. Elastic search plugins are bundled in ZIP archives, along with their dependencies, and all of them must have a class that implements our elastic search plugin's plugin class. There is a plugin service which is responsible to load the plugins in elastic search. Now, let's see how we can create a very simple ingest plugin that allows you to filter words from a field of an index document. So, if you index a document, you can specify from which field, which words you want to filter out. This is a very common scenario, for example, if you want, for example, to implement that allows you to clear contents from documents and so on and so forth. It's probably one of the simplest plugins you might have. So, first we have a filter ingest plugin class that extends the plugin class and implements ingest plugin. We have different interfaces for the different types of plugins you might have for elastic search, and ingest plugin is one of these types of interfaces. Then you specify you implement the get processors method because an ingest plugin needs to have processors that you can define that do something on the documents before their index. And the get processors method, what we do, we get a filter word from the parameters that we supply on the ingest processor that we define in elastic search. And then we get the filter field. So, we have two parameters, the word that we want to filter out, and from which field of the document we want to filter it out. Then we create a map of processors, and in that map we put the filter word processor that we create from this class and return it. You can also have multiple processors defined in that plugin. Now, what does the filter word processor look like? The filter word processor extends abstract processor from elastic search. It, again, comes from the core class of elastic search. And we have an execute method. In the execute method, we get the document that we want to index. This is the ingest document. We get the value from the particular field that we want to filter out, and then we replace that value with the empty string. And then we set back the value on top of that field and return the document. This, when you index a document and you specify that ingest processor, applies the filtering on that document before it gets indexed into elastic search. Now, those two classes, if you want to build a plugin, you also need to supply some simple plugin metadata, then build it, for example, with Maven or with Gradle, and then you can install it with the elastic search plugin utility. And in that manner, you can build any plugin you would like for elastic search. And since we are running out of time, I'm not sure if we have some time for one or two questions, maybe. Do you have time for? Yes, of course. Okay, so if anybody? Yeah? Hey, thanks for your insights. We saw how too many cats can go out and fall into the pool. Yeah. Yes? I was curious, how does one know how many cars are going to be in charge? Well, I would say it depends on upfront estimation of how much data do you expect to put in that index. So we need to do an upfront finding, okay, in the first phase of my project, how many, let's say, gigabytes of data I would have. And based on that, you determine how many initial set of shots do you put, and if those shots still have a lot of data, then you consider partitioning the index. And it's a matter of upfront planning to determine that. Okay? Yeah? What is the structure used for store indexes and data? It's inverted index. This is the data structure. Yeah? Inverted index. Inverted index. It's just called an inverted index because it's an app between terms, and if for each term you have a pointer to the document that contains that term. So it's called inverted index.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.0, "text": " So, before we go on with the next security or later topic, we're going to talk about", "tokens": [407, 11, 949, 321, 352, 322, 365, 264, 958, 3825, 420, 1780, 4829, 11, 321, 434, 516, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.26690475940704345, "compression_ratio": 1.3203125, "no_speech_prob": 0.588949978351593}, {"id": 1, "seek": 0, "start": 10.0, "end": 15.44, "text": " something completely different, and that is about elastic search internals by Martin", "tokens": [746, 2584, 819, 11, 293, 300, 307, 466, 17115, 3164, 2154, 1124, 538, 9184], "temperature": 0.0, "avg_logprob": -0.26690475940704345, "compression_ratio": 1.3203125, "no_speech_prob": 0.588949978351593}, {"id": 2, "seek": 1544, "start": 15.44, "end": 32.44, "text": " from the Bulgaria jug, and maybe also about security in this context.", "tokens": [490, 264, 47737, 9568, 11, 293, 1310, 611, 466, 3825, 294, 341, 4319, 13], "temperature": 0.0, "avg_logprob": -0.4416792657640245, "compression_ratio": 0.971830985915493, "no_speech_prob": 0.018736472353339195}, {"id": 3, "seek": 3244, "start": 32.44, "end": 50.44, "text": " So, we're going to talk about something completely different, and maybe also about security in", "tokens": [407, 11, 321, 434, 516, 281, 751, 466, 746, 2584, 819, 11, 293, 1310, 611, 466, 3825, 294], "temperature": 0.0, "avg_logprob": -0.8101946223865856, "compression_ratio": 1.119047619047619, "no_speech_prob": 0.030802663415670395}, {"id": 4, "seek": 5044, "start": 50.44, "end": 73.44, "text": " this context.", "tokens": [341, 4319, 13], "temperature": 0.0, "avg_logprob": -0.627828734261649, "compression_ratio": 0.6190476190476191, "no_speech_prob": 0.014382576569914818}, {"id": 5, "seek": 7344, "start": 73.44, "end": 82.44, "text": " Test, test, test.", "tokens": [9279, 11, 1500, 11, 1500, 13], "temperature": 0.0, "avg_logprob": -0.395093297958374, "compression_ratio": 1.0, "no_speech_prob": 0.009756160899996758}, {"id": 6, "seek": 8244, "start": 82.44, "end": 108.44, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22636939798082625, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.023843782022595406}, {"id": 7, "seek": 10844, "start": 108.44, "end": 113.44, "text": " So, people coming in, please move to the middle of your row so that there's space on the side", "tokens": [407, 11, 561, 1348, 294, 11, 1767, 1286, 281, 264, 2808, 295, 428, 5386, 370, 300, 456, 311, 1901, 322, 264, 1252], "temperature": 0.0, "avg_logprob": -0.35427668600371387, "compression_ratio": 1.2307692307692308, "no_speech_prob": 0.026868056505918503}, {"id": 8, "seek": 10844, "start": 113.44, "end": 126.44, "text": " so people can sit.", "tokens": [370, 561, 393, 1394, 13], "temperature": 0.0, "avg_logprob": -0.35427668600371387, "compression_ratio": 1.2307692307692308, "no_speech_prob": 0.026868056505918503}, {"id": 9, "seek": 12644, "start": 126.44, "end": 138.44, "text": " We're working in Cisco together, so a lot of people coming, so we can start.", "tokens": [492, 434, 1364, 294, 38528, 1214, 11, 370, 257, 688, 295, 561, 1348, 11, 370, 321, 393, 722, 13], "temperature": 0.0, "avg_logprob": -0.302503316298775, "compression_ratio": 1.0, "no_speech_prob": 0.02869921736419201}, {"id": 10, "seek": 13844, "start": 138.44, "end": 165.44, "text": " If you're standing along the side, please take a seat.", "tokens": [759, 291, 434, 4877, 2051, 264, 1252, 11, 1767, 747, 257, 6121, 13], "temperature": 0.0, "avg_logprob": -0.34589770260979147, "compression_ratio": 0.9152542372881356, "no_speech_prob": 0.0049263667315244675}, {"id": 11, "seek": 16544, "start": 165.44, "end": 170.44, "text": " So, hello, everyone.", "tokens": [407, 11, 7751, 11, 1518, 13], "temperature": 0.0, "avg_logprob": -0.11806632124859354, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.0022134266328066587}, {"id": 12, "seek": 16544, "start": 170.44, "end": 176.44, "text": " My name is Martin, and I'm a consulting architect at the European Patient Office.", "tokens": [1222, 1315, 307, 9184, 11, 293, 286, 478, 257, 23682, 6331, 412, 264, 6473, 25173, 8935, 13], "temperature": 0.0, "avg_logprob": -0.11806632124859354, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.0022134266328066587}, {"id": 13, "seek": 16544, "start": 176.44, "end": 182.44, "text": " I've been also doing a lot of consultancy on elastic search in the past two to three years.", "tokens": [286, 600, 668, 611, 884, 257, 688, 295, 7189, 6717, 322, 17115, 3164, 294, 264, 1791, 732, 281, 1045, 924, 13], "temperature": 0.0, "avg_logprob": -0.11806632124859354, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.0022134266328066587}, {"id": 14, "seek": 16544, "start": 182.44, "end": 186.44, "text": " So, just before we start with this session, how many of you are using or have used elastic", "tokens": [407, 11, 445, 949, 321, 722, 365, 341, 5481, 11, 577, 867, 295, 291, 366, 1228, 420, 362, 1143, 17115], "temperature": 0.0, "avg_logprob": -0.11806632124859354, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.0022134266328066587}, {"id": 15, "seek": 16544, "start": 186.44, "end": 188.44, "text": " search in a project?", "tokens": [3164, 294, 257, 1716, 30], "temperature": 0.0, "avg_logprob": -0.11806632124859354, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.0022134266328066587}, {"id": 16, "seek": 16544, "start": 188.44, "end": 191.44, "text": " Okay, more than half of the people.", "tokens": [1033, 11, 544, 813, 1922, 295, 264, 561, 13], "temperature": 0.0, "avg_logprob": -0.11806632124859354, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.0022134266328066587}, {"id": 17, "seek": 19144, "start": 191.44, "end": 195.44, "text": " So, why this talk at FOSDEM?", "tokens": [407, 11, 983, 341, 751, 412, 479, 4367, 35, 6683, 30], "temperature": 0.0, "avg_logprob": -0.14114689460167518, "compression_ratio": 1.707070707070707, "no_speech_prob": 0.0018063297029584646}, {"id": 18, "seek": 19144, "start": 195.44, "end": 196.44, "text": " So, multiple reasons, in fact.", "tokens": [407, 11, 3866, 4112, 11, 294, 1186, 13], "temperature": 0.0, "avg_logprob": -0.14114689460167518, "compression_ratio": 1.707070707070707, "no_speech_prob": 0.0018063297029584646}, {"id": 19, "seek": 19144, "start": 196.44, "end": 201.44, "text": " When I've worked with elastic search, I realized that even though it has quite a good documentation,", "tokens": [1133, 286, 600, 2732, 365, 17115, 3164, 11, 286, 5334, 300, 754, 1673, 309, 575, 1596, 257, 665, 14333, 11], "temperature": 0.0, "avg_logprob": -0.14114689460167518, "compression_ratio": 1.707070707070707, "no_speech_prob": 0.0018063297029584646}, {"id": 20, "seek": 19144, "start": 201.44, "end": 206.44, "text": " in many cases, you need to go into the public code base and see what's in there, and to", "tokens": [294, 867, 3331, 11, 291, 643, 281, 352, 666, 264, 1908, 3089, 3096, 293, 536, 437, 311, 294, 456, 11, 293, 281], "temperature": 0.0, "avg_logprob": -0.14114689460167518, "compression_ratio": 1.707070707070707, "no_speech_prob": 0.0018063297029584646}, {"id": 21, "seek": 19144, "start": 206.44, "end": 208.44, "text": " understand how it works.", "tokens": [1223, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.14114689460167518, "compression_ratio": 1.707070707070707, "no_speech_prob": 0.0018063297029584646}, {"id": 22, "seek": 19144, "start": 208.44, "end": 212.44, "text": " I've had questions from many people, how this functionality works, or how can I achieve", "tokens": [286, 600, 632, 1651, 490, 867, 561, 11, 577, 341, 14980, 1985, 11, 420, 577, 393, 286, 4584], "temperature": 0.0, "avg_logprob": -0.14114689460167518, "compression_ratio": 1.707070707070707, "no_speech_prob": 0.0018063297029584646}, {"id": 23, "seek": 19144, "start": 212.44, "end": 214.44, "text": " something with elastic search.", "tokens": [746, 365, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.14114689460167518, "compression_ratio": 1.707070707070707, "no_speech_prob": 0.0018063297029584646}, {"id": 24, "seek": 19144, "start": 214.44, "end": 219.44, "text": " And not always it's clear from documentation or blocks over the Internet what you can achieve", "tokens": [400, 406, 1009, 309, 311, 1850, 490, 14333, 420, 8474, 670, 264, 7703, 437, 291, 393, 4584], "temperature": 0.0, "avg_logprob": -0.14114689460167518, "compression_ratio": 1.707070707070707, "no_speech_prob": 0.0018063297029584646}, {"id": 25, "seek": 19144, "start": 219.44, "end": 220.44, "text": " with elastic search.", "tokens": [365, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.14114689460167518, "compression_ratio": 1.707070707070707, "no_speech_prob": 0.0018063297029584646}, {"id": 26, "seek": 22044, "start": 220.44, "end": 226.44, "text": " So, in this short session, I'll try to show you how this elastic search works internally,", "tokens": [407, 11, 294, 341, 2099, 5481, 11, 286, 603, 853, 281, 855, 291, 577, 341, 17115, 3164, 1985, 19501, 11], "temperature": 0.0, "avg_logprob": -0.06639837335657191, "compression_ratio": 1.905829596412556, "no_speech_prob": 0.00033126736525446177}, {"id": 27, "seek": 22044, "start": 226.44, "end": 230.44, "text": " and I'll talk about the elastic search architecture.", "tokens": [293, 286, 603, 751, 466, 264, 17115, 3164, 9482, 13], "temperature": 0.0, "avg_logprob": -0.06639837335657191, "compression_ratio": 1.905829596412556, "no_speech_prob": 0.00033126736525446177}, {"id": 28, "seek": 22044, "start": 230.44, "end": 236.44, "text": " So, first of all, we'll do a 360-degree overview of the elastic search stack, which I believe", "tokens": [407, 11, 700, 295, 439, 11, 321, 603, 360, 257, 13898, 12, 34368, 12492, 295, 264, 17115, 3164, 8630, 11, 597, 286, 1697], "temperature": 0.0, "avg_logprob": -0.06639837335657191, "compression_ratio": 1.905829596412556, "no_speech_prob": 0.00033126736525446177}, {"id": 29, "seek": 22044, "start": 236.44, "end": 238.44, "text": " most of you are familiar with.", "tokens": [881, 295, 291, 366, 4963, 365, 13], "temperature": 0.0, "avg_logprob": -0.06639837335657191, "compression_ratio": 1.905829596412556, "no_speech_prob": 0.00033126736525446177}, {"id": 30, "seek": 22044, "start": 238.44, "end": 242.44, "text": " Then I'll go into the elastic search architecture, and at the end of this short session, I'll", "tokens": [1396, 286, 603, 352, 666, 264, 17115, 3164, 9482, 11, 293, 412, 264, 917, 295, 341, 2099, 5481, 11, 286, 603], "temperature": 0.0, "avg_logprob": -0.06639837335657191, "compression_ratio": 1.905829596412556, "no_speech_prob": 0.00033126736525446177}, {"id": 31, "seek": 22044, "start": 242.44, "end": 246.44, "text": " show you how you can write a very simple elastic search plugin.", "tokens": [855, 291, 577, 291, 393, 2464, 257, 588, 2199, 17115, 3164, 23407, 13], "temperature": 0.0, "avg_logprob": -0.06639837335657191, "compression_ratio": 1.905829596412556, "no_speech_prob": 0.00033126736525446177}, {"id": 32, "seek": 24644, "start": 246.44, "end": 250.44, "text": " In most cases, you won't need to write an elastic search plugin because there is quite", "tokens": [682, 881, 3331, 11, 291, 1582, 380, 643, 281, 2464, 364, 17115, 3164, 23407, 570, 456, 307, 1596], "temperature": 0.0, "avg_logprob": -0.06538397812646282, "compression_ratio": 1.8014705882352942, "no_speech_prob": 9.8927273938898e-05}, {"id": 33, "seek": 24644, "start": 250.44, "end": 253.44, "text": " a rich ecosystem of elastic search plugins that you can use.", "tokens": [257, 4593, 11311, 295, 17115, 3164, 33759, 300, 291, 393, 764, 13], "temperature": 0.0, "avg_logprob": -0.06538397812646282, "compression_ratio": 1.8014705882352942, "no_speech_prob": 9.8927273938898e-05}, {"id": 34, "seek": 24644, "start": 253.44, "end": 256.44, "text": " But many companies find that that's not always the case.", "tokens": [583, 867, 3431, 915, 300, 300, 311, 406, 1009, 264, 1389, 13], "temperature": 0.0, "avg_logprob": -0.06538397812646282, "compression_ratio": 1.8014705882352942, "no_speech_prob": 9.8927273938898e-05}, {"id": 35, "seek": 24644, "start": 256.44, "end": 260.44, "text": " So, sometimes you need to either customize something in elastic search or write your", "tokens": [407, 11, 2171, 291, 643, 281, 2139, 19734, 746, 294, 17115, 3164, 420, 2464, 428], "temperature": 0.0, "avg_logprob": -0.06538397812646282, "compression_ratio": 1.8014705882352942, "no_speech_prob": 9.8927273938898e-05}, {"id": 36, "seek": 24644, "start": 260.44, "end": 263.44, "text": " own plugin to achieve something.", "tokens": [1065, 23407, 281, 4584, 746, 13], "temperature": 0.0, "avg_logprob": -0.06538397812646282, "compression_ratio": 1.8014705882352942, "no_speech_prob": 9.8927273938898e-05}, {"id": 37, "seek": 24644, "start": 263.44, "end": 264.44, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.06538397812646282, "compression_ratio": 1.8014705882352942, "no_speech_prob": 9.8927273938898e-05}, {"id": 38, "seek": 24644, "start": 264.44, "end": 267.44, "text": " So, let's talk briefly about the elastic search stack.", "tokens": [407, 11, 718, 311, 751, 10515, 466, 264, 17115, 3164, 8630, 13], "temperature": 0.0, "avg_logprob": -0.06538397812646282, "compression_ratio": 1.8014705882352942, "no_speech_prob": 9.8927273938898e-05}, {"id": 39, "seek": 24644, "start": 267.44, "end": 271.44, "text": " In the middle, we have elastic search, which is a Java application.", "tokens": [682, 264, 2808, 11, 321, 362, 17115, 3164, 11, 597, 307, 257, 10745, 3861, 13], "temperature": 0.0, "avg_logprob": -0.06538397812646282, "compression_ratio": 1.8014705882352942, "no_speech_prob": 9.8927273938898e-05}, {"id": 40, "seek": 24644, "start": 271.44, "end": 274.44, "text": " It's being updated quite oftenly.", "tokens": [467, 311, 885, 10588, 1596, 2049, 356, 13], "temperature": 0.0, "avg_logprob": -0.06538397812646282, "compression_ratio": 1.8014705882352942, "no_speech_prob": 9.8927273938898e-05}, {"id": 41, "seek": 27444, "start": 274.44, "end": 278.44, "text": " There are a lot of features being implemented in elastic search, especially in the latest", "tokens": [821, 366, 257, 688, 295, 4122, 885, 12270, 294, 17115, 3164, 11, 2318, 294, 264, 6792], "temperature": 0.0, "avg_logprob": -0.07932599385579427, "compression_ratio": 1.9392857142857143, "no_speech_prob": 0.0003401839639991522}, {"id": 42, "seek": 27444, "start": 278.44, "end": 279.44, "text": " few releases.", "tokens": [1326, 16952, 13], "temperature": 0.0, "avg_logprob": -0.07932599385579427, "compression_ratio": 1.9392857142857143, "no_speech_prob": 0.0003401839639991522}, {"id": 43, "seek": 27444, "start": 279.44, "end": 284.44, "text": " And around the elastic search server application, there are different applications that are", "tokens": [400, 926, 264, 17115, 3164, 7154, 3861, 11, 456, 366, 819, 5821, 300, 366], "temperature": 0.0, "avg_logprob": -0.07932599385579427, "compression_ratio": 1.9392857142857143, "no_speech_prob": 0.0003401839639991522}, {"id": 44, "seek": 27444, "start": 284.44, "end": 288.44, "text": " being built to allow you to work more easily with elastic search, such as Kibana.", "tokens": [885, 3094, 281, 2089, 291, 281, 589, 544, 3612, 365, 17115, 3164, 11, 1270, 382, 591, 897, 2095, 13], "temperature": 0.0, "avg_logprob": -0.07932599385579427, "compression_ratio": 1.9392857142857143, "no_speech_prob": 0.0003401839639991522}, {"id": 45, "seek": 27444, "start": 288.44, "end": 293.44, "text": " Kibana is a user-rich user interface for elastic search that allows you to achieve multiple", "tokens": [591, 897, 2095, 307, 257, 4195, 12, 10794, 4195, 9226, 337, 17115, 3164, 300, 4045, 291, 281, 4584, 3866], "temperature": 0.0, "avg_logprob": -0.07932599385579427, "compression_ratio": 1.9392857142857143, "no_speech_prob": 0.0003401839639991522}, {"id": 46, "seek": 27444, "start": 293.44, "end": 298.44, "text": " things, so not only querying elastic search, but Kibana allows you to also visualize data", "tokens": [721, 11, 370, 406, 787, 7083, 1840, 17115, 3164, 11, 457, 591, 897, 2095, 4045, 291, 281, 611, 23273, 1412], "temperature": 0.0, "avg_logprob": -0.07932599385579427, "compression_ratio": 1.9392857142857143, "no_speech_prob": 0.0003401839639991522}, {"id": 47, "seek": 27444, "start": 298.44, "end": 303.44, "text": " that's already in elastic search or build different dashboards that are quite nice,", "tokens": [300, 311, 1217, 294, 17115, 3164, 420, 1322, 819, 8240, 17228, 300, 366, 1596, 1481, 11], "temperature": 0.0, "avg_logprob": -0.07932599385579427, "compression_ratio": 1.9392857142857143, "no_speech_prob": 0.0003401839639991522}, {"id": 48, "seek": 30344, "start": 303.44, "end": 305.44, "text": " especially for management.", "tokens": [2318, 337, 4592, 13], "temperature": 0.0, "avg_logprob": -0.0797783685108972, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.0002494488435331732}, {"id": 49, "seek": 30344, "start": 305.44, "end": 309.44, "text": " Also, if you want to put different data from a variety of sources in elastic search, you", "tokens": [2743, 11, 498, 291, 528, 281, 829, 819, 1412, 490, 257, 5673, 295, 7139, 294, 17115, 3164, 11, 291], "temperature": 0.0, "avg_logprob": -0.0797783685108972, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.0002494488435331732}, {"id": 50, "seek": 30344, "start": 309.44, "end": 311.44, "text": " can use LogStash.", "tokens": [393, 764, 10824, 4520, 1299, 13], "temperature": 0.0, "avg_logprob": -0.0797783685108972, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.0002494488435331732}, {"id": 51, "seek": 30344, "start": 311.44, "end": 316.44, "text": " So, originally, LogStash was implemented to provide a way to aggregate logs into elastic", "tokens": [407, 11, 7993, 11, 10824, 4520, 1299, 390, 12270, 281, 2893, 257, 636, 281, 26118, 20820, 666, 17115], "temperature": 0.0, "avg_logprob": -0.0797783685108972, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.0002494488435331732}, {"id": 52, "seek": 30344, "start": 316.44, "end": 317.44, "text": " search.", "tokens": [3164, 13], "temperature": 0.0, "avg_logprob": -0.0797783685108972, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.0002494488435331732}, {"id": 53, "seek": 30344, "start": 317.44, "end": 322.44, "text": " But over time, LogStash evolves to an application that is used to integrate data in elastic", "tokens": [583, 670, 565, 11, 10824, 4520, 1299, 43737, 281, 364, 3861, 300, 307, 1143, 281, 13365, 1412, 294, 17115], "temperature": 0.0, "avg_logprob": -0.0797783685108972, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.0002494488435331732}, {"id": 54, "seek": 30344, "start": 322.44, "end": 325.44, "text": " search, not only log data, but any kind of data.", "tokens": [3164, 11, 406, 787, 3565, 1412, 11, 457, 604, 733, 295, 1412, 13], "temperature": 0.0, "avg_logprob": -0.0797783685108972, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.0002494488435331732}, {"id": 55, "seek": 30344, "start": 325.44, "end": 331.44, "text": " So, you can think of LogStash as a log aggregation pipeline that allows you to put data in elastic", "tokens": [407, 11, 291, 393, 519, 295, 10824, 4520, 1299, 382, 257, 3565, 16743, 399, 15517, 300, 4045, 291, 281, 829, 1412, 294, 17115], "temperature": 0.0, "avg_logprob": -0.0797783685108972, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.0002494488435331732}, {"id": 56, "seek": 30344, "start": 331.44, "end": 332.44, "text": " search.", "tokens": [3164, 13], "temperature": 0.0, "avg_logprob": -0.0797783685108972, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.0002494488435331732}, {"id": 57, "seek": 33244, "start": 332.44, "end": 337.44, "text": " And on top of that, we also have a different set of so-called bits applications that are", "tokens": [400, 322, 1192, 295, 300, 11, 321, 611, 362, 257, 819, 992, 295, 370, 12, 11880, 9239, 5821, 300, 366], "temperature": 0.0, "avg_logprob": -0.0765824268773659, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.00029978694510646164}, {"id": 58, "seek": 33244, "start": 337.44, "end": 343.44, "text": " lightweight log shippers that allow you to collect data and put it either directly into", "tokens": [22052, 3565, 402, 31323, 300, 2089, 291, 281, 2500, 1412, 293, 829, 309, 2139, 3838, 666], "temperature": 0.0, "avg_logprob": -0.0765824268773659, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.00029978694510646164}, {"id": 59, "seek": 33244, "start": 343.44, "end": 350.44, "text": " an elastic search or through LogStash into elastic search or different other data sources.", "tokens": [364, 17115, 3164, 420, 807, 10824, 4520, 1299, 666, 17115, 3164, 420, 819, 661, 1412, 7139, 13], "temperature": 0.0, "avg_logprob": -0.0765824268773659, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.00029978694510646164}, {"id": 60, "seek": 33244, "start": 350.44, "end": 354.44, "text": " The specific thing about the bit applications is that they are lightweight in nature, so", "tokens": [440, 2685, 551, 466, 264, 857, 5821, 307, 300, 436, 366, 22052, 294, 3687, 11, 370], "temperature": 0.0, "avg_logprob": -0.0765824268773659, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.00029978694510646164}, {"id": 61, "seek": 33244, "start": 354.44, "end": 359.44, "text": " they are supposed to not consume a lot of resources such as CPU and memory.", "tokens": [436, 366, 3442, 281, 406, 14732, 257, 688, 295, 3593, 1270, 382, 13199, 293, 4675, 13], "temperature": 0.0, "avg_logprob": -0.0765824268773659, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.00029978694510646164}, {"id": 62, "seek": 35944, "start": 359.44, "end": 366.44, "text": " And in that reason, they allow you to collect log data or other data and put it into elastic", "tokens": [400, 294, 300, 1778, 11, 436, 2089, 291, 281, 2500, 3565, 1412, 420, 661, 1412, 293, 829, 309, 666, 17115], "temperature": 0.0, "avg_logprob": -0.06932541758743758, "compression_ratio": 1.7292576419213974, "no_speech_prob": 6.376301462296396e-05}, {"id": 63, "seek": 35944, "start": 366.44, "end": 367.44, "text": " search.", "tokens": [3164, 13], "temperature": 0.0, "avg_logprob": -0.06932541758743758, "compression_ratio": 1.7292576419213974, "no_speech_prob": 6.376301462296396e-05}, {"id": 64, "seek": 35944, "start": 367.44, "end": 372.44, "text": " Now, you can think of elastic search as a web server built on top of the Apache Lucene", "tokens": [823, 11, 291, 393, 519, 295, 17115, 3164, 382, 257, 3670, 7154, 3094, 322, 1192, 295, 264, 46597, 9593, 1450], "temperature": 0.0, "avg_logprob": -0.06932541758743758, "compression_ratio": 1.7292576419213974, "no_speech_prob": 6.376301462296396e-05}, {"id": 65, "seek": 35944, "start": 372.44, "end": 373.44, "text": " library.", "tokens": [6405, 13], "temperature": 0.0, "avg_logprob": -0.06932541758743758, "compression_ratio": 1.7292576419213974, "no_speech_prob": 6.376301462296396e-05}, {"id": 66, "seek": 35944, "start": 373.44, "end": 380.44, "text": " So, the Apache Lucene library is an actively developed Java library that is used by different", "tokens": [407, 11, 264, 46597, 9593, 1450, 6405, 307, 364, 13022, 4743, 10745, 6405, 300, 307, 1143, 538, 819], "temperature": 0.0, "avg_logprob": -0.06932541758743758, "compression_ratio": 1.7292576419213974, "no_speech_prob": 6.376301462296396e-05}, {"id": 67, "seek": 35944, "start": 380.44, "end": 385.44, "text": " applications that want to implement some kind of search functionality.", "tokens": [5821, 300, 528, 281, 4445, 512, 733, 295, 3164, 14980, 13], "temperature": 0.0, "avg_logprob": -0.06932541758743758, "compression_ratio": 1.7292576419213974, "no_speech_prob": 6.376301462296396e-05}, {"id": 68, "seek": 35944, "start": 385.44, "end": 387.44, "text": " And elastic search is one of them.", "tokens": [400, 17115, 3164, 307, 472, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.06932541758743758, "compression_ratio": 1.7292576419213974, "no_speech_prob": 6.376301462296396e-05}, {"id": 69, "seek": 38744, "start": 387.44, "end": 391.44, "text": " So, I'll show briefly in a few slides how elastic search interacts with the Apache Lucene", "tokens": [407, 11, 286, 603, 855, 10515, 294, 257, 1326, 9788, 577, 17115, 3164, 43582, 365, 264, 46597, 9593, 1450], "temperature": 0.0, "avg_logprob": -0.10199339347973205, "compression_ratio": 1.8625, "no_speech_prob": 0.00025053328135982156}, {"id": 70, "seek": 38744, "start": 391.44, "end": 392.44, "text": " library.", "tokens": [6405, 13], "temperature": 0.0, "avg_logprob": -0.10199339347973205, "compression_ratio": 1.8625, "no_speech_prob": 0.00025053328135982156}, {"id": 71, "seek": 38744, "start": 392.44, "end": 396.44, "text": " And another way to describe elastic search is a document-oriented database.", "tokens": [400, 1071, 636, 281, 6786, 17115, 3164, 307, 257, 4166, 12, 27414, 8149, 13], "temperature": 0.0, "avg_logprob": -0.10199339347973205, "compression_ratio": 1.8625, "no_speech_prob": 0.00025053328135982156}, {"id": 72, "seek": 38744, "start": 396.44, "end": 403.44, "text": " So, elastic search is used by different projects not only for searching, but also as a NoSQL", "tokens": [407, 11, 17115, 3164, 307, 1143, 538, 819, 4455, 406, 787, 337, 10808, 11, 457, 611, 382, 257, 883, 39934], "temperature": 0.0, "avg_logprob": -0.10199339347973205, "compression_ratio": 1.8625, "no_speech_prob": 0.00025053328135982156}, {"id": 73, "seek": 38744, "start": 403.44, "end": 404.44, "text": " database.", "tokens": [8149, 13], "temperature": 0.0, "avg_logprob": -0.10199339347973205, "compression_ratio": 1.8625, "no_speech_prob": 0.00025053328135982156}, {"id": 74, "seek": 38744, "start": 404.44, "end": 409.44, "text": " So, I had a few projects where elastic search was used purely as a NoSQL database, not as", "tokens": [407, 11, 286, 632, 257, 1326, 4455, 689, 17115, 3164, 390, 1143, 17491, 382, 257, 883, 39934, 8149, 11, 406, 382], "temperature": 0.0, "avg_logprob": -0.10199339347973205, "compression_ratio": 1.8625, "no_speech_prob": 0.00025053328135982156}, {"id": 75, "seek": 38744, "start": 409.44, "end": 410.44, "text": " a search engine.", "tokens": [257, 3164, 2848, 13], "temperature": 0.0, "avg_logprob": -0.10199339347973205, "compression_ratio": 1.8625, "no_speech_prob": 0.00025053328135982156}, {"id": 76, "seek": 38744, "start": 410.44, "end": 414.44, "text": " And one can think, okay, elastic search is a Java application.", "tokens": [400, 472, 393, 519, 11, 1392, 11, 17115, 3164, 307, 257, 10745, 3861, 13], "temperature": 0.0, "avg_logprob": -0.10199339347973205, "compression_ratio": 1.8625, "no_speech_prob": 0.00025053328135982156}, {"id": 77, "seek": 41444, "start": 414.44, "end": 417.44, "text": " Why I cannot use Apache Lucene directly?", "tokens": [1545, 286, 2644, 764, 46597, 9593, 1450, 3838, 30], "temperature": 0.0, "avg_logprob": -0.07851048616262582, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.00047144180280156434}, {"id": 78, "seek": 41444, "start": 417.44, "end": 422.44, "text": " And the reason is that elastic search provides a number of features that are missing in the", "tokens": [400, 264, 1778, 307, 300, 17115, 3164, 6417, 257, 1230, 295, 4122, 300, 366, 5361, 294, 264], "temperature": 0.0, "avg_logprob": -0.07851048616262582, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.00047144180280156434}, {"id": 79, "seek": 41444, "start": 422.44, "end": 429.44, "text": " Apache Lucene library that allow you to implement search in your project way more easily than", "tokens": [46597, 9593, 1450, 6405, 300, 2089, 291, 281, 4445, 3164, 294, 428, 1716, 636, 544, 3612, 813], "temperature": 0.0, "avg_logprob": -0.07851048616262582, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.00047144180280156434}, {"id": 80, "seek": 41444, "start": 429.44, "end": 430.44, "text": " using directly Apache Lucene.", "tokens": [1228, 3838, 46597, 9593, 1450, 13], "temperature": 0.0, "avg_logprob": -0.07851048616262582, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.00047144180280156434}, {"id": 81, "seek": 41444, "start": 430.44, "end": 436.44, "text": " Some of these features are, for example, JSON-based REST API, which is quite easy to use, quite", "tokens": [2188, 295, 613, 4122, 366, 11, 337, 1365, 11, 31828, 12, 6032, 497, 14497, 9362, 11, 597, 307, 1596, 1858, 281, 764, 11, 1596], "temperature": 0.0, "avg_logprob": -0.07851048616262582, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.00047144180280156434}, {"id": 82, "seek": 41444, "start": 436.44, "end": 440.44, "text": " easy to write search queries, to index data into elastic search, and so on.", "tokens": [1858, 281, 2464, 3164, 24109, 11, 281, 8186, 1412, 666, 17115, 3164, 11, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.07851048616262582, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.00047144180280156434}, {"id": 83, "seek": 44044, "start": 440.44, "end": 445.44, "text": " There is also a really nice clustering mechanism implemented in elastic search that allows", "tokens": [821, 307, 611, 257, 534, 1481, 596, 48673, 7513, 12270, 294, 17115, 3164, 300, 4045], "temperature": 0.0, "avg_logprob": -0.060283090757287064, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005448686424642801}, {"id": 84, "seek": 44044, "start": 445.44, "end": 450.44, "text": " you to bring and scale your elastic search cluster quite easily, something that's not", "tokens": [291, 281, 1565, 293, 4373, 428, 17115, 3164, 13630, 1596, 3612, 11, 746, 300, 311, 406], "temperature": 0.0, "avg_logprob": -0.060283090757287064, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005448686424642801}, {"id": 85, "seek": 44044, "start": 450.44, "end": 455.44, "text": " possible if you use directly Apache Lucene in your project directly.", "tokens": [1944, 498, 291, 764, 3838, 46597, 9593, 1450, 294, 428, 1716, 3838, 13], "temperature": 0.0, "avg_logprob": -0.060283090757287064, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005448686424642801}, {"id": 86, "seek": 44044, "start": 455.44, "end": 459.44, "text": " And also, it has a number of other features, such as, for example, caching, that allow", "tokens": [400, 611, 11, 309, 575, 257, 1230, 295, 661, 4122, 11, 1270, 382, 11, 337, 1365, 11, 269, 2834, 11, 300, 2089], "temperature": 0.0, "avg_logprob": -0.060283090757287064, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005448686424642801}, {"id": 87, "seek": 44044, "start": 459.44, "end": 464.44, "text": " you to improve the performance of your search queries, and so on.", "tokens": [291, 281, 3470, 264, 3389, 295, 428, 3164, 24109, 11, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.060283090757287064, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005448686424642801}, {"id": 88, "seek": 46444, "start": 464.44, "end": 470.44, "text": " Now, the basic data structure used by elastic search is the so-called inverted index, and", "tokens": [823, 11, 264, 3875, 1412, 3877, 1143, 538, 17115, 3164, 307, 264, 370, 12, 11880, 38969, 8186, 11, 293], "temperature": 0.0, "avg_logprob": -0.08108012492840107, "compression_ratio": 1.7611336032388665, "no_speech_prob": 0.000602262036409229}, {"id": 89, "seek": 46444, "start": 470.44, "end": 475.44, "text": " indexes are stored on disk in separate files or Lucene segments.", "tokens": [8186, 279, 366, 12187, 322, 12355, 294, 4994, 7098, 420, 9593, 1450, 19904, 13], "temperature": 0.0, "avg_logprob": -0.08108012492840107, "compression_ratio": 1.7611336032388665, "no_speech_prob": 0.000602262036409229}, {"id": 90, "seek": 46444, "start": 475.44, "end": 478.44, "text": " Search can be performed on multiple indexes at a time.", "tokens": [17180, 393, 312, 10332, 322, 3866, 8186, 279, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.08108012492840107, "compression_ratio": 1.7611336032388665, "no_speech_prob": 0.000602262036409229}, {"id": 91, "seek": 46444, "start": 478.44, "end": 481.44, "text": " That's one of the capabilities of elastic search.", "tokens": [663, 311, 472, 295, 264, 10862, 295, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.08108012492840107, "compression_ratio": 1.7611336032388665, "no_speech_prob": 0.000602262036409229}, {"id": 92, "seek": 46444, "start": 481.44, "end": 486.44, "text": " And in earlier versions of elastic search, documents were logically grouped by types.", "tokens": [400, 294, 3071, 9606, 295, 17115, 3164, 11, 8512, 645, 38887, 41877, 538, 3467, 13], "temperature": 0.0, "avg_logprob": -0.08108012492840107, "compression_ratio": 1.7611336032388665, "no_speech_prob": 0.000602262036409229}, {"id": 93, "seek": 46444, "start": 486.44, "end": 492.44, "text": " That was effectively deprecated as a version 7 of elastic search, and it's expected to be", "tokens": [663, 390, 8659, 1367, 13867, 770, 382, 257, 3037, 1614, 295, 17115, 3164, 11, 293, 309, 311, 5176, 281, 312], "temperature": 0.0, "avg_logprob": -0.08108012492840107, "compression_ratio": 1.7611336032388665, "no_speech_prob": 0.000602262036409229}, {"id": 94, "seek": 49244, "start": 492.44, "end": 495.44, "text": " dropped.", "tokens": [8119, 13], "temperature": 0.0, "avg_logprob": -0.11571887870887657, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.000121894663607236}, {"id": 95, "seek": 49244, "start": 495.44, "end": 500.44, "text": " In order to ensure score relevancy when you search for some data in elastic search,", "tokens": [682, 1668, 281, 5586, 6175, 25916, 6717, 562, 291, 3164, 337, 512, 1412, 294, 17115, 3164, 11], "temperature": 0.0, "avg_logprob": -0.11571887870887657, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.000121894663607236}, {"id": 96, "seek": 49244, "start": 500.44, "end": 508.44, "text": " elastic search uses a set of different algorithms to score results relevance.", "tokens": [17115, 3164, 4960, 257, 992, 295, 819, 14642, 281, 6175, 3542, 32684, 13], "temperature": 0.0, "avg_logprob": -0.11571887870887657, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.000121894663607236}, {"id": 97, "seek": 49244, "start": 508.44, "end": 512.44, "text": " In the later versions of elastic search, this algorithm is BM25.", "tokens": [682, 264, 1780, 9606, 295, 17115, 3164, 11, 341, 9284, 307, 15901, 6074, 13], "temperature": 0.0, "avg_logprob": -0.11571887870887657, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.000121894663607236}, {"id": 98, "seek": 49244, "start": 512.44, "end": 518.44, "text": " In earlier versions of elastic search, this was a simpler algorithm which is called TFIDF.", "tokens": [682, 3071, 9606, 295, 17115, 3164, 11, 341, 390, 257, 18587, 9284, 597, 307, 1219, 40964, 2777, 37, 13], "temperature": 0.0, "avg_logprob": -0.11571887870887657, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.000121894663607236}, {"id": 99, "seek": 51844, "start": 518.44, "end": 524.44, "text": " And the base of those algorithms is the fact how many times does a term occur in a document,", "tokens": [400, 264, 3096, 295, 729, 14642, 307, 264, 1186, 577, 867, 1413, 775, 257, 1433, 5160, 294, 257, 4166, 11], "temperature": 0.0, "avg_logprob": -0.0835522697085426, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.00020411604782566428}, {"id": 100, "seek": 51844, "start": 524.44, "end": 528.44, "text": " and how many times does this term occur across all documents that are currently indexed in", "tokens": [293, 577, 867, 1413, 775, 341, 1433, 5160, 2108, 439, 8512, 300, 366, 4362, 8186, 292, 294], "temperature": 0.0, "avg_logprob": -0.0835522697085426, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.00020411604782566428}, {"id": 101, "seek": 51844, "start": 528.44, "end": 529.44, "text": " elastic search.", "tokens": [17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.0835522697085426, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.00020411604782566428}, {"id": 102, "seek": 51844, "start": 529.44, "end": 535.44, "text": " Based on that, by default, elastic search scores every result that gets returned by your search", "tokens": [18785, 322, 300, 11, 538, 7576, 11, 17115, 3164, 13444, 633, 1874, 300, 2170, 8752, 538, 428, 3164], "temperature": 0.0, "avg_logprob": -0.0835522697085426, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.00020411604782566428}, {"id": 103, "seek": 51844, "start": 535.44, "end": 542.44, "text": " query, and by default, it returns results sorted by relevant score.", "tokens": [14581, 11, 293, 538, 7576, 11, 309, 11247, 3542, 25462, 538, 7340, 6175, 13], "temperature": 0.0, "avg_logprob": -0.0835522697085426, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.00020411604782566428}, {"id": 104, "seek": 51844, "start": 542.44, "end": 547.44, "text": " Now, why would you use elastic search in favor, for example, of a relational database?", "tokens": [823, 11, 983, 576, 291, 764, 17115, 3164, 294, 2294, 11, 337, 1365, 11, 295, 257, 38444, 8149, 30], "temperature": 0.0, "avg_logprob": -0.0835522697085426, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.00020411604782566428}, {"id": 105, "seek": 54744, "start": 547.44, "end": 553.44, "text": " Well, it provides faster retrieval for documents in way more scenarios than a traditional", "tokens": [1042, 11, 309, 6417, 4663, 19817, 3337, 337, 8512, 294, 636, 544, 15077, 813, 257, 5164], "temperature": 0.0, "avg_logprob": -0.09854202708978763, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.00019113213056698442}, {"id": 106, "seek": 54744, "start": 553.44, "end": 555.44, "text": " relational database can do.", "tokens": [38444, 8149, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.09854202708978763, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.00019113213056698442}, {"id": 107, "seek": 54744, "start": 555.44, "end": 562.44, "text": " So, as you know, traditional relational databases provide faster searches through indexes.", "tokens": [407, 11, 382, 291, 458, 11, 5164, 38444, 22380, 2893, 4663, 26701, 807, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.09854202708978763, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.00019113213056698442}, {"id": 108, "seek": 54744, "start": 562.44, "end": 566.44, "text": " However, indexes in relational databases have many limitations based on the type of", "tokens": [2908, 11, 8186, 279, 294, 38444, 22380, 362, 867, 15705, 2361, 322, 264, 2010, 295], "temperature": 0.0, "avg_logprob": -0.09854202708978763, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.00019113213056698442}, {"id": 109, "seek": 54744, "start": 566.44, "end": 568.44, "text": " SQL queries that you write.", "tokens": [19200, 24109, 300, 291, 2464, 13], "temperature": 0.0, "avg_logprob": -0.09854202708978763, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.00019113213056698442}, {"id": 110, "seek": 54744, "start": 568.44, "end": 574.44, "text": " In elastic search, the inverted index data structure provides with the capability to cover", "tokens": [682, 17115, 3164, 11, 264, 38969, 8186, 1412, 3877, 6417, 365, 264, 13759, 281, 2060], "temperature": 0.0, "avg_logprob": -0.09854202708978763, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.00019113213056698442}, {"id": 111, "seek": 57444, "start": 574.44, "end": 578.44, "text": " way more scenarios for searching using more complex queries.", "tokens": [636, 544, 15077, 337, 10808, 1228, 544, 3997, 24109, 13], "temperature": 0.0, "avg_logprob": -0.08067662980821398, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.00010375255806138739}, {"id": 112, "seek": 57444, "start": 578.44, "end": 585.44, "text": " And for that reason, many projects choose to use elastic search as a search engine.", "tokens": [400, 337, 300, 1778, 11, 867, 4455, 2826, 281, 764, 17115, 3164, 382, 257, 3164, 2848, 13], "temperature": 0.0, "avg_logprob": -0.08067662980821398, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.00010375255806138739}, {"id": 113, "seek": 57444, "start": 585.44, "end": 591.44, "text": " Now, documents also in elastic search might not have an explicit schema, as you have in", "tokens": [823, 11, 8512, 611, 294, 17115, 3164, 1062, 406, 362, 364, 13691, 34078, 11, 382, 291, 362, 294], "temperature": 0.0, "avg_logprob": -0.08067662980821398, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.00010375255806138739}, {"id": 114, "seek": 57444, "start": 591.44, "end": 595.44, "text": " a relational database, and that's typical for many no-SQL databases.", "tokens": [257, 38444, 8149, 11, 293, 300, 311, 7476, 337, 867, 572, 12, 39934, 22380, 13], "temperature": 0.0, "avg_logprob": -0.08067662980821398, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.00010375255806138739}, {"id": 115, "seek": 57444, "start": 595.44, "end": 600.44, "text": " An explicit schema, however, can be defined on the fields, and certain fields can even", "tokens": [1107, 13691, 34078, 11, 4461, 11, 393, 312, 7642, 322, 264, 7909, 11, 293, 1629, 7909, 393, 754], "temperature": 0.0, "avg_logprob": -0.08067662980821398, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.00010375255806138739}, {"id": 116, "seek": 60044, "start": 600.44, "end": 604.44, "text": " have different types mapped to them.", "tokens": [362, 819, 3467, 33318, 281, 552, 13], "temperature": 0.0, "avg_logprob": -0.06804364354986893, "compression_ratio": 1.7678571428571428, "no_speech_prob": 5.8814239309867844e-05}, {"id": 117, "seek": 60044, "start": 604.44, "end": 610.44, "text": " This is needed because sometimes you need to use different kinds of search queries based", "tokens": [639, 307, 2978, 570, 2171, 291, 643, 281, 764, 819, 3685, 295, 3164, 24109, 2361], "temperature": 0.0, "avg_logprob": -0.06804364354986893, "compression_ratio": 1.7678571428571428, "no_speech_prob": 5.8814239309867844e-05}, {"id": 118, "seek": 60044, "start": 610.44, "end": 614.44, "text": " on the field type, and some field types pose limitations.", "tokens": [322, 264, 2519, 2010, 11, 293, 512, 2519, 3467, 10774, 15705, 13], "temperature": 0.0, "avg_logprob": -0.06804364354986893, "compression_ratio": 1.7678571428571428, "no_speech_prob": 5.8814239309867844e-05}, {"id": 119, "seek": 60044, "start": 614.44, "end": 619.44, "text": " So, that's why you might need to have multiple types on a single field in elastic search.", "tokens": [407, 11, 300, 311, 983, 291, 1062, 643, 281, 362, 3866, 3467, 322, 257, 2167, 2519, 294, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.06804364354986893, "compression_ratio": 1.7678571428571428, "no_speech_prob": 5.8814239309867844e-05}, {"id": 120, "seek": 60044, "start": 619.44, "end": 623.44, "text": " Now, this was brief about what is elastic search and how it works.", "tokens": [823, 11, 341, 390, 5353, 466, 437, 307, 17115, 3164, 293, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.06804364354986893, "compression_ratio": 1.7678571428571428, "no_speech_prob": 5.8814239309867844e-05}, {"id": 121, "seek": 60044, "start": 623.44, "end": 626.44, "text": " Now, let's see what the architecture of elastic search.", "tokens": [823, 11, 718, 311, 536, 437, 264, 9482, 295, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.06804364354986893, "compression_ratio": 1.7678571428571428, "no_speech_prob": 5.8814239309867844e-05}, {"id": 122, "seek": 62644, "start": 626.44, "end": 631.44, "text": " Elastic search, as I mentioned to you, is designed with clustering in mind.", "tokens": [2699, 2750, 3164, 11, 382, 286, 2835, 281, 291, 11, 307, 4761, 365, 596, 48673, 294, 1575, 13], "temperature": 0.0, "avg_logprob": -0.08117116152585208, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.00011948751489399001}, {"id": 123, "seek": 62644, "start": 631.44, "end": 637.44, "text": " By default, in later versions of elastic search, if you start, if you create an index, it has", "tokens": [3146, 7576, 11, 294, 1780, 9606, 295, 17115, 3164, 11, 498, 291, 722, 11, 498, 291, 1884, 364, 8186, 11, 309, 575], "temperature": 0.0, "avg_logprob": -0.08117116152585208, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.00011948751489399001}, {"id": 124, "seek": 62644, "start": 637.44, "end": 641.44, "text": " one primary chart and one replica chart.", "tokens": [472, 6194, 6927, 293, 472, 35456, 6927, 13], "temperature": 0.0, "avg_logprob": -0.08117116152585208, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.00011948751489399001}, {"id": 125, "seek": 62644, "start": 641.44, "end": 643.44, "text": " So, what is a chart?", "tokens": [407, 11, 437, 307, 257, 6927, 30], "temperature": 0.0, "avg_logprob": -0.08117116152585208, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.00011948751489399001}, {"id": 126, "seek": 62644, "start": 643.44, "end": 649.44, "text": " Now, an elastic search index contains one or more primary charts that distribute the data in the", "tokens": [823, 11, 364, 17115, 3164, 8186, 8306, 472, 420, 544, 6194, 17767, 300, 20594, 264, 1412, 294, 264], "temperature": 0.0, "avg_logprob": -0.08117116152585208, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.00011948751489399001}, {"id": 127, "seek": 62644, "start": 649.44, "end": 651.44, "text": " elastic search cluster.", "tokens": [17115, 3164, 13630, 13], "temperature": 0.0, "avg_logprob": -0.08117116152585208, "compression_ratio": 1.7339901477832513, "no_speech_prob": 0.00011948751489399001}, {"id": 128, "seek": 65144, "start": 651.44, "end": 657.44, "text": " Below that, an elastic search chart is, in fact, a Lucene index, and a Lucene index is,", "tokens": [36261, 300, 11, 364, 17115, 3164, 6927, 307, 11, 294, 1186, 11, 257, 9593, 1450, 8186, 11, 293, 257, 9593, 1450, 8186, 307, 11], "temperature": 0.0, "avg_logprob": -0.08750486373901367, "compression_ratio": 1.9743589743589745, "no_speech_prob": 7.503561209887266e-05}, {"id": 129, "seek": 65144, "start": 657.44, "end": 662.44, "text": " in fact, the data structure that stores the data on disk in terms of Lucene segments.", "tokens": [294, 1186, 11, 264, 1412, 3877, 300, 9512, 264, 1412, 322, 12355, 294, 2115, 295, 9593, 1450, 19904, 13], "temperature": 0.0, "avg_logprob": -0.08750486373901367, "compression_ratio": 1.9743589743589745, "no_speech_prob": 7.503561209887266e-05}, {"id": 130, "seek": 65144, "start": 662.44, "end": 667.44, "text": " Lucene segments are the physical files that store data on the disk.", "tokens": [9593, 1450, 19904, 366, 264, 4001, 7098, 300, 3531, 1412, 322, 264, 12355, 13], "temperature": 0.0, "avg_logprob": -0.08750486373901367, "compression_ratio": 1.9743589743589745, "no_speech_prob": 7.503561209887266e-05}, {"id": 131, "seek": 65144, "start": 667.44, "end": 672.44, "text": " Now, when you index data in elastic search, you might have also replica charts.", "tokens": [823, 11, 562, 291, 8186, 1412, 294, 17115, 3164, 11, 291, 1062, 362, 611, 35456, 17767, 13], "temperature": 0.0, "avg_logprob": -0.08750486373901367, "compression_ratio": 1.9743589743589745, "no_speech_prob": 7.503561209887266e-05}, {"id": 132, "seek": 65144, "start": 672.44, "end": 677.44, "text": " Replica charts provide you with the possibility to enable high availability and data replication", "tokens": [47762, 2262, 17767, 2893, 291, 365, 264, 7959, 281, 9528, 1090, 17945, 293, 1412, 39911], "temperature": 0.0, "avg_logprob": -0.08750486373901367, "compression_ratio": 1.9743589743589745, "no_speech_prob": 7.503561209887266e-05}, {"id": 133, "seek": 65144, "start": 677.44, "end": 680.44, "text": " at the level of the elastic search cluster.", "tokens": [412, 264, 1496, 295, 264, 17115, 3164, 13630, 13], "temperature": 0.0, "avg_logprob": -0.08750486373901367, "compression_ratio": 1.9743589743589745, "no_speech_prob": 7.503561209887266e-05}, {"id": 134, "seek": 68044, "start": 680.44, "end": 687.44, "text": " So, two types of charts, primary and replica charts.", "tokens": [407, 11, 732, 3467, 295, 17767, 11, 6194, 293, 35456, 17767, 13], "temperature": 0.0, "avg_logprob": -0.07412515854348942, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.00010910897253779694}, {"id": 135, "seek": 68044, "start": 687.44, "end": 692.44, "text": " The more notes you add to the elastic search cluster, the more data gets distributed among", "tokens": [440, 544, 5570, 291, 909, 281, 264, 17115, 3164, 13630, 11, 264, 544, 1412, 2170, 12631, 3654], "temperature": 0.0, "avg_logprob": -0.07412515854348942, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.00010910897253779694}, {"id": 136, "seek": 68044, "start": 692.44, "end": 693.44, "text": " charts.", "tokens": [17767, 13], "temperature": 0.0, "avg_logprob": -0.07412515854348942, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.00010910897253779694}, {"id": 137, "seek": 68044, "start": 693.44, "end": 698.44, "text": " Now, it's very important that up front you plan the number of primary charts based on", "tokens": [823, 11, 309, 311, 588, 1021, 300, 493, 1868, 291, 1393, 264, 1230, 295, 6194, 17767, 2361, 322], "temperature": 0.0, "avg_logprob": -0.07412515854348942, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.00010910897253779694}, {"id": 138, "seek": 68044, "start": 698.44, "end": 700.44, "text": " the data growth that you have.", "tokens": [264, 1412, 4599, 300, 291, 362, 13], "temperature": 0.0, "avg_logprob": -0.07412515854348942, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.00010910897253779694}, {"id": 139, "seek": 68044, "start": 700.44, "end": 705.44, "text": " It's very difficult to change later in your project lifecycle the number of primary charts", "tokens": [467, 311, 588, 2252, 281, 1319, 1780, 294, 428, 1716, 45722, 264, 1230, 295, 6194, 17767], "temperature": 0.0, "avg_logprob": -0.07412515854348942, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.00010910897253779694}, {"id": 140, "seek": 68044, "start": 705.44, "end": 708.44, "text": " you would need to re-index data.", "tokens": [291, 576, 643, 281, 319, 12, 471, 3121, 1412, 13], "temperature": 0.0, "avg_logprob": -0.07412515854348942, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.00010910897253779694}, {"id": 141, "seek": 70844, "start": 708.44, "end": 712.44, "text": " However, if you want to change the number of replica charts, that's more easy to do later", "tokens": [2908, 11, 498, 291, 528, 281, 1319, 264, 1230, 295, 35456, 17767, 11, 300, 311, 544, 1858, 281, 360, 1780], "temperature": 0.0, "avg_logprob": -0.06792016969109974, "compression_ratio": 1.8440677966101695, "no_speech_prob": 9.623875666875392e-05}, {"id": 142, "seek": 70844, "start": 712.44, "end": 713.44, "text": " in time.", "tokens": [294, 565, 13], "temperature": 0.0, "avg_logprob": -0.06792016969109974, "compression_ratio": 1.8440677966101695, "no_speech_prob": 9.623875666875392e-05}, {"id": 143, "seek": 70844, "start": 713.44, "end": 716.44, "text": " So, it's very important that you plan up front what's the number of primary charts on an", "tokens": [407, 11, 309, 311, 588, 1021, 300, 291, 1393, 493, 1868, 437, 311, 264, 1230, 295, 6194, 17767, 322, 364], "temperature": 0.0, "avg_logprob": -0.06792016969109974, "compression_ratio": 1.8440677966101695, "no_speech_prob": 9.623875666875392e-05}, {"id": 144, "seek": 70844, "start": 716.44, "end": 718.44, "text": " index that you create.", "tokens": [8186, 300, 291, 1884, 13], "temperature": 0.0, "avg_logprob": -0.06792016969109974, "compression_ratio": 1.8440677966101695, "no_speech_prob": 9.623875666875392e-05}, {"id": 145, "seek": 70844, "start": 718.44, "end": 722.44, "text": " Now, by default, elastic search tries to balance the number of charts across the notes that", "tokens": [823, 11, 538, 7576, 11, 17115, 3164, 9898, 281, 4772, 264, 1230, 295, 17767, 2108, 264, 5570, 300], "temperature": 0.0, "avg_logprob": -0.06792016969109974, "compression_ratio": 1.8440677966101695, "no_speech_prob": 9.623875666875392e-05}, {"id": 146, "seek": 70844, "start": 722.44, "end": 724.44, "text": " you have.", "tokens": [291, 362, 13], "temperature": 0.0, "avg_logprob": -0.06792016969109974, "compression_ratio": 1.8440677966101695, "no_speech_prob": 9.623875666875392e-05}, {"id": 147, "seek": 70844, "start": 724.44, "end": 728.44, "text": " And one of the other capabilities that elastic search provides you is that if a note fails,", "tokens": [400, 472, 295, 264, 661, 10862, 300, 17115, 3164, 6417, 291, 307, 300, 498, 257, 3637, 18199, 11], "temperature": 0.0, "avg_logprob": -0.06792016969109974, "compression_ratio": 1.8440677966101695, "no_speech_prob": 9.623875666875392e-05}, {"id": 148, "seek": 70844, "start": 728.44, "end": 734.44, "text": " you still can get search results, or so-called partial results can be returned, even if some", "tokens": [291, 920, 393, 483, 3164, 3542, 11, 420, 370, 12, 11880, 14641, 3542, 393, 312, 8752, 11, 754, 498, 512], "temperature": 0.0, "avg_logprob": -0.06792016969109974, "compression_ratio": 1.8440677966101695, "no_speech_prob": 9.623875666875392e-05}, {"id": 149, "seek": 70844, "start": 734.44, "end": 737.44, "text": " of the notes in the cluster are not available.", "tokens": [295, 264, 5570, 294, 264, 13630, 366, 406, 2435, 13], "temperature": 0.0, "avg_logprob": -0.06792016969109974, "compression_ratio": 1.8440677966101695, "no_speech_prob": 9.623875666875392e-05}, {"id": 150, "seek": 73744, "start": 737.44, "end": 743.44, "text": " Now, by default, elastic search determines the chart where a document is indexed based", "tokens": [823, 11, 538, 7576, 11, 17115, 3164, 24799, 264, 6927, 689, 257, 4166, 307, 8186, 292, 2361], "temperature": 0.0, "avg_logprob": -0.08742807781885541, "compression_ratio": 1.7801418439716312, "no_speech_prob": 0.0006154384464025497}, {"id": 151, "seek": 73744, "start": 743.44, "end": 745.44, "text": " on a relatively simple formula.", "tokens": [322, 257, 7226, 2199, 8513, 13], "temperature": 0.0, "avg_logprob": -0.08742807781885541, "compression_ratio": 1.7801418439716312, "no_speech_prob": 0.0006154384464025497}, {"id": 152, "seek": 73744, "start": 745.44, "end": 749.44, "text": " You get the hash key of the routing key of the document.", "tokens": [509, 483, 264, 22019, 2141, 295, 264, 32722, 2141, 295, 264, 4166, 13], "temperature": 0.0, "avg_logprob": -0.08742807781885541, "compression_ratio": 1.7801418439716312, "no_speech_prob": 0.0006154384464025497}, {"id": 153, "seek": 73744, "start": 749.44, "end": 753.44, "text": " This is the document ID, which can be generated in different ways.", "tokens": [639, 307, 264, 4166, 7348, 11, 597, 393, 312, 10833, 294, 819, 2098, 13], "temperature": 0.0, "avg_logprob": -0.08742807781885541, "compression_ratio": 1.7801418439716312, "no_speech_prob": 0.0006154384464025497}, {"id": 154, "seek": 73744, "start": 753.44, "end": 755.44, "text": " You can generate it from elastic search.", "tokens": [509, 393, 8460, 309, 490, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.08742807781885541, "compression_ratio": 1.7801418439716312, "no_speech_prob": 0.0006154384464025497}, {"id": 155, "seek": 73744, "start": 755.44, "end": 759.44, "text": " If you don't specify your application, you can supply the document ID, and so on and so", "tokens": [759, 291, 500, 380, 16500, 428, 3861, 11, 291, 393, 5847, 264, 4166, 7348, 11, 293, 370, 322, 293, 370], "temperature": 0.0, "avg_logprob": -0.08742807781885541, "compression_ratio": 1.7801418439716312, "no_speech_prob": 0.0006154384464025497}, {"id": 156, "seek": 73744, "start": 759.44, "end": 760.44, "text": " forth.", "tokens": [5220, 13], "temperature": 0.0, "avg_logprob": -0.08742807781885541, "compression_ratio": 1.7801418439716312, "no_speech_prob": 0.0006154384464025497}, {"id": 157, "seek": 73744, "start": 760.44, "end": 764.44, "text": " And you'll take the modules, the number of primary charts that you have defined on the", "tokens": [400, 291, 603, 747, 264, 16679, 11, 264, 1230, 295, 6194, 17767, 300, 291, 362, 7642, 322, 264], "temperature": 0.0, "avg_logprob": -0.08742807781885541, "compression_ratio": 1.7801418439716312, "no_speech_prob": 0.0006154384464025497}, {"id": 158, "seek": 73744, "start": 764.44, "end": 766.44, "text": " index, where you index the document.", "tokens": [8186, 11, 689, 291, 8186, 264, 4166, 13], "temperature": 0.0, "avg_logprob": -0.08742807781885541, "compression_ratio": 1.7801418439716312, "no_speech_prob": 0.0006154384464025497}, {"id": 159, "seek": 76644, "start": 766.44, "end": 770.44, "text": " Now, as I mentioned, by default, the routing key is the document ID, but you can also", "tokens": [823, 11, 382, 286, 2835, 11, 538, 7576, 11, 264, 32722, 2141, 307, 264, 4166, 7348, 11, 457, 291, 393, 611], "temperature": 0.0, "avg_logprob": -0.05128490548384817, "compression_ratio": 1.7456896551724137, "no_speech_prob": 0.0002029045863309875}, {"id": 160, "seek": 76644, "start": 770.44, "end": 773.44, "text": " use a different routing key.", "tokens": [764, 257, 819, 32722, 2141, 13], "temperature": 0.0, "avg_logprob": -0.05128490548384817, "compression_ratio": 1.7456896551724137, "no_speech_prob": 0.0002029045863309875}, {"id": 161, "seek": 76644, "start": 773.44, "end": 782.44, "text": " And one interesting technique that some people use to enable distribution of data in the", "tokens": [400, 472, 1880, 6532, 300, 512, 561, 764, 281, 9528, 7316, 295, 1412, 294, 264], "temperature": 0.0, "avg_logprob": -0.05128490548384817, "compression_ratio": 1.7456896551724137, "no_speech_prob": 0.0002029045863309875}, {"id": 162, "seek": 76644, "start": 782.44, "end": 789.44, "text": " elastic search cluster is by specifying a custom routing key that allows you to enable", "tokens": [17115, 3164, 13630, 307, 538, 1608, 5489, 257, 2375, 32722, 2141, 300, 4045, 291, 281, 9528], "temperature": 0.0, "avg_logprob": -0.05128490548384817, "compression_ratio": 1.7456896551724137, "no_speech_prob": 0.0002029045863309875}, {"id": 163, "seek": 76644, "start": 789.44, "end": 791.44, "text": " so-called chart routing.", "tokens": [370, 12, 11880, 6927, 32722, 13], "temperature": 0.0, "avg_logprob": -0.05128490548384817, "compression_ratio": 1.7456896551724137, "no_speech_prob": 0.0002029045863309875}, {"id": 164, "seek": 76644, "start": 791.44, "end": 795.44, "text": " This is a technique that allows you to specify at which particular chart you want to send", "tokens": [639, 307, 257, 6532, 300, 4045, 291, 281, 16500, 412, 597, 1729, 6927, 291, 528, 281, 2845], "temperature": 0.0, "avg_logprob": -0.05128490548384817, "compression_ratio": 1.7456896551724137, "no_speech_prob": 0.0002029045863309875}, {"id": 165, "seek": 79544, "start": 795.44, "end": 797.44, "text": " the document to be indexed.", "tokens": [264, 4166, 281, 312, 8186, 292, 13], "temperature": 0.0, "avg_logprob": -0.05678905140269886, "compression_ratio": 1.6699029126213591, "no_speech_prob": 8.901231922209263e-05}, {"id": 166, "seek": 79544, "start": 797.44, "end": 800.44, "text": " But that's a case that's used in some specific scenarios.", "tokens": [583, 300, 311, 257, 1389, 300, 311, 1143, 294, 512, 2685, 15077, 13], "temperature": 0.0, "avg_logprob": -0.05678905140269886, "compression_ratio": 1.6699029126213591, "no_speech_prob": 8.901231922209263e-05}, {"id": 167, "seek": 79544, "start": 800.44, "end": 807.44, "text": " In most cases, people rely on the default mechanism that elastic search uses to distribute", "tokens": [682, 881, 3331, 11, 561, 10687, 322, 264, 7576, 7513, 300, 17115, 3164, 4960, 281, 20594], "temperature": 0.0, "avg_logprob": -0.05678905140269886, "compression_ratio": 1.6699029126213591, "no_speech_prob": 8.901231922209263e-05}, {"id": 168, "seek": 79544, "start": 807.44, "end": 810.44, "text": " data in the cluster.", "tokens": [1412, 294, 264, 13630, 13], "temperature": 0.0, "avg_logprob": -0.05678905140269886, "compression_ratio": 1.6699029126213591, "no_speech_prob": 8.901231922209263e-05}, {"id": 169, "seek": 79544, "start": 810.44, "end": 815.44, "text": " Now, by default, new nodes are discovered via multicast.", "tokens": [823, 11, 538, 7576, 11, 777, 13891, 366, 6941, 5766, 30608, 525, 13], "temperature": 0.0, "avg_logprob": -0.05678905140269886, "compression_ratio": 1.6699029126213591, "no_speech_prob": 8.901231922209263e-05}, {"id": 170, "seek": 79544, "start": 815.44, "end": 821.44, "text": " If a cluster is discovered, a new node joins the cluster if it has the same cluster name.", "tokens": [759, 257, 13630, 307, 6941, 11, 257, 777, 9984, 24397, 264, 13630, 498, 309, 575, 264, 912, 13630, 1315, 13], "temperature": 0.0, "avg_logprob": -0.05678905140269886, "compression_ratio": 1.6699029126213591, "no_speech_prob": 8.901231922209263e-05}, {"id": 171, "seek": 82144, "start": 821.44, "end": 826.44, "text": " If a node on the same instance already runs on a specified port, and if you try to run", "tokens": [759, 257, 9984, 322, 264, 912, 5197, 1217, 6676, 322, 257, 22206, 2436, 11, 293, 498, 291, 853, 281, 1190], "temperature": 0.0, "avg_logprob": -0.06815295366896797, "compression_ratio": 1.6919831223628692, "no_speech_prob": 0.00011058586824219674}, {"id": 172, "seek": 82144, "start": 826.44, "end": 830.44, "text": " another node on that instance, elastic search automatically gives you the next available", "tokens": [1071, 9984, 322, 300, 5197, 11, 17115, 3164, 6772, 2709, 291, 264, 958, 2435], "temperature": 0.0, "avg_logprob": -0.06815295366896797, "compression_ratio": 1.6919831223628692, "no_speech_prob": 0.00011058586824219674}, {"id": 173, "seek": 82144, "start": 830.44, "end": 832.44, "text": " port.", "tokens": [2436, 13], "temperature": 0.0, "avg_logprob": -0.06815295366896797, "compression_ratio": 1.6919831223628692, "no_speech_prob": 0.00011058586824219674}, {"id": 174, "seek": 82144, "start": 832.44, "end": 839.44, "text": " Now, however, in some cases, in some companies, multicast addresses are disabled for security", "tokens": [823, 11, 4461, 11, 294, 512, 3331, 11, 294, 512, 3431, 11, 30608, 525, 16862, 366, 15191, 337, 3825], "temperature": 0.0, "avg_logprob": -0.06815295366896797, "compression_ratio": 1.6919831223628692, "no_speech_prob": 0.00011058586824219674}, {"id": 175, "seek": 82144, "start": 839.44, "end": 840.44, "text": " reasons.", "tokens": [4112, 13], "temperature": 0.0, "avg_logprob": -0.06815295366896797, "compression_ratio": 1.6919831223628692, "no_speech_prob": 0.00011058586824219674}, {"id": 176, "seek": 82144, "start": 840.44, "end": 844.44, "text": " And that's why the preferred mechanism to join new nodes in an elastic search cluster is", "tokens": [400, 300, 311, 983, 264, 16494, 7513, 281, 3917, 777, 13891, 294, 364, 17115, 3164, 13630, 307], "temperature": 0.0, "avg_logprob": -0.06815295366896797, "compression_ratio": 1.6919831223628692, "no_speech_prob": 0.00011058586824219674}, {"id": 177, "seek": 82144, "start": 844.44, "end": 846.44, "text": " by using unicast addresses.", "tokens": [538, 1228, 517, 299, 525, 16862, 13], "temperature": 0.0, "avg_logprob": -0.06815295366896797, "compression_ratio": 1.6919831223628692, "no_speech_prob": 0.00011058586824219674}, {"id": 178, "seek": 84644, "start": 846.44, "end": 851.44, "text": " In the elastic search YAML configuration, you just need to specify one or more existing", "tokens": [682, 264, 17115, 3164, 398, 2865, 43, 11694, 11, 291, 445, 643, 281, 16500, 472, 420, 544, 6741], "temperature": 0.0, "avg_logprob": -0.05382317720457565, "compression_ratio": 1.9668508287292819, "no_speech_prob": 0.00019301814609207213}, {"id": 179, "seek": 84644, "start": 851.44, "end": 857.44, "text": " nodes from the elastic search cluster so that they can join that existing cluster.", "tokens": [13891, 490, 264, 17115, 3164, 13630, 370, 300, 436, 393, 3917, 300, 6741, 13630, 13], "temperature": 0.0, "avg_logprob": -0.05382317720457565, "compression_ratio": 1.9668508287292819, "no_speech_prob": 0.00019301814609207213}, {"id": 180, "seek": 84644, "start": 857.44, "end": 862.44, "text": " And in that list of unicast nodes, you don't need to specify all the nodes in the elastic", "tokens": [400, 294, 300, 1329, 295, 517, 299, 525, 13891, 11, 291, 500, 380, 643, 281, 16500, 439, 264, 13891, 294, 264, 17115], "temperature": 0.0, "avg_logprob": -0.05382317720457565, "compression_ratio": 1.9668508287292819, "no_speech_prob": 0.00019301814609207213}, {"id": 181, "seek": 84644, "start": 862.44, "end": 863.44, "text": " search cluster.", "tokens": [3164, 13630, 13], "temperature": 0.0, "avg_logprob": -0.05382317720457565, "compression_ratio": 1.9668508287292819, "no_speech_prob": 0.00019301814609207213}, {"id": 182, "seek": 84644, "start": 863.44, "end": 871.44, "text": " You just need to specify at least one node that has already joined the cluster.", "tokens": [509, 445, 643, 281, 16500, 412, 1935, 472, 9984, 300, 575, 1217, 6869, 264, 13630, 13], "temperature": 0.0, "avg_logprob": -0.05382317720457565, "compression_ratio": 1.9668508287292819, "no_speech_prob": 0.00019301814609207213}, {"id": 183, "seek": 87144, "start": 871.44, "end": 876.44, "text": " Now, when you bring up an elastic search cluster, there are some considerations that you need", "tokens": [823, 11, 562, 291, 1565, 493, 364, 17115, 3164, 13630, 11, 456, 366, 512, 24070, 300, 291, 643], "temperature": 0.0, "avg_logprob": -0.07278226116510826, "compression_ratio": 1.7979094076655053, "no_speech_prob": 0.00011648274812614545}, {"id": 184, "seek": 87144, "start": 876.44, "end": 877.44, "text": " to take.", "tokens": [281, 747, 13], "temperature": 0.0, "avg_logprob": -0.07278226116510826, "compression_ratio": 1.7979094076655053, "no_speech_prob": 0.00011648274812614545}, {"id": 185, "seek": 87144, "start": 877.44, "end": 882.44, "text": " First of all, as I mentioned, sharding, it's very important for you to consider what should", "tokens": [2386, 295, 439, 11, 382, 286, 2835, 11, 402, 515, 278, 11, 309, 311, 588, 1021, 337, 291, 281, 1949, 437, 820], "temperature": 0.0, "avg_logprob": -0.07278226116510826, "compression_ratio": 1.7979094076655053, "no_speech_prob": 0.00011648274812614545}, {"id": 186, "seek": 87144, "start": 882.44, "end": 886.44, "text": " be the number of primary shards that you define on the elastic search index, and the number", "tokens": [312, 264, 1230, 295, 6194, 402, 2287, 300, 291, 6964, 322, 264, 17115, 3164, 8186, 11, 293, 264, 1230], "temperature": 0.0, "avg_logprob": -0.07278226116510826, "compression_ratio": 1.7979094076655053, "no_speech_prob": 0.00011648274812614545}, {"id": 187, "seek": 87144, "start": 886.44, "end": 890.44, "text": " of replica shards, which is more easy to change over time.", "tokens": [295, 35456, 402, 2287, 11, 597, 307, 544, 1858, 281, 1319, 670, 565, 13], "temperature": 0.0, "avg_logprob": -0.07278226116510826, "compression_ratio": 1.7979094076655053, "no_speech_prob": 0.00011648274812614545}, {"id": 188, "seek": 87144, "start": 890.44, "end": 895.44, "text": " You also need to consider how much data you store in an elastic search index.", "tokens": [509, 611, 643, 281, 1949, 577, 709, 1412, 291, 3531, 294, 364, 17115, 3164, 8186, 13], "temperature": 0.0, "avg_logprob": -0.07278226116510826, "compression_ratio": 1.7979094076655053, "no_speech_prob": 0.00011648274812614545}, {"id": 189, "seek": 87144, "start": 895.44, "end": 900.44, "text": " Indexes with too small amount of data are not good, because that implies a lot of management", "tokens": [33552, 279, 365, 886, 1359, 2372, 295, 1412, 366, 406, 665, 11, 570, 300, 18779, 257, 688, 295, 4592], "temperature": 0.0, "avg_logprob": -0.07278226116510826, "compression_ratio": 1.7979094076655053, "no_speech_prob": 0.00011648274812614545}, {"id": 190, "seek": 90044, "start": 900.44, "end": 901.44, "text": " overhead.", "tokens": [19922, 13], "temperature": 0.0, "avg_logprob": -0.08208200931549073, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.00018490408547222614}, {"id": 191, "seek": 90044, "start": 901.44, "end": 904.44, "text": " And the same is for indexes with too many amounts of data.", "tokens": [400, 264, 912, 307, 337, 8186, 279, 365, 886, 867, 11663, 295, 1412, 13], "temperature": 0.0, "avg_logprob": -0.08208200931549073, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.00018490408547222614}, {"id": 192, "seek": 90044, "start": 904.44, "end": 908.44, "text": " I've seen some cases where people store, let's say, more than two, three hundred gigabytes", "tokens": [286, 600, 1612, 512, 3331, 689, 561, 3531, 11, 718, 311, 584, 11, 544, 813, 732, 11, 1045, 3262, 42741], "temperature": 0.0, "avg_logprob": -0.08208200931549073, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.00018490408547222614}, {"id": 193, "seek": 90044, "start": 908.44, "end": 910.44, "text": " of data in an elastic search index.", "tokens": [295, 1412, 294, 364, 17115, 3164, 8186, 13], "temperature": 0.0, "avg_logprob": -0.08208200931549073, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.00018490408547222614}, {"id": 194, "seek": 90044, "start": 910.44, "end": 915.44, "text": " And that really slows down search operations and other operations of that index.", "tokens": [400, 300, 534, 35789, 760, 3164, 7705, 293, 661, 7705, 295, 300, 8186, 13], "temperature": 0.0, "avg_logprob": -0.08208200931549073, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.00018490408547222614}, {"id": 195, "seek": 90044, "start": 915.44, "end": 918.44, "text": " And people start wondering, okay, why is my indexing slow?", "tokens": [400, 561, 722, 6359, 11, 1392, 11, 983, 307, 452, 8186, 278, 2964, 30], "temperature": 0.0, "avg_logprob": -0.08208200931549073, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.00018490408547222614}, {"id": 196, "seek": 90044, "start": 918.44, "end": 920.44, "text": " Why are my search queries slow?", "tokens": [1545, 366, 452, 3164, 24109, 2964, 30], "temperature": 0.0, "avg_logprob": -0.08208200931549073, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.00018490408547222614}, {"id": 197, "seek": 90044, "start": 920.44, "end": 924.44, "text": " And in many cases, the reason is that because data is not distributed properly in the elastic", "tokens": [400, 294, 867, 3331, 11, 264, 1778, 307, 300, 570, 1412, 307, 406, 12631, 6108, 294, 264, 17115], "temperature": 0.0, "avg_logprob": -0.08208200931549073, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.00018490408547222614}, {"id": 198, "seek": 90044, "start": 924.44, "end": 926.44, "text": " search index.", "tokens": [3164, 8186, 13], "temperature": 0.0, "avg_logprob": -0.08208200931549073, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.00018490408547222614}, {"id": 199, "seek": 92644, "start": 926.44, "end": 932.44, "text": " The preferred amount of data that you should keep in an elastic search shard is between", "tokens": [440, 16494, 2372, 295, 1412, 300, 291, 820, 1066, 294, 364, 17115, 3164, 402, 515, 307, 1296], "temperature": 0.0, "avg_logprob": -0.0704607131869294, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.00013345955812837929}, {"id": 200, "seek": 92644, "start": 932.44, "end": 934.44, "text": " five and ten gigabytes, roughly speaking.", "tokens": [1732, 293, 2064, 42741, 11, 9810, 4124, 13], "temperature": 0.0, "avg_logprob": -0.0704607131869294, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.00013345955812837929}, {"id": 201, "seek": 92644, "start": 934.44, "end": 939.44, "text": " So if you have more data that you want to put on a shard, you should consider splitting", "tokens": [407, 498, 291, 362, 544, 1412, 300, 291, 528, 281, 829, 322, 257, 402, 515, 11, 291, 820, 1949, 30348], "temperature": 0.0, "avg_logprob": -0.0704607131869294, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.00013345955812837929}, {"id": 202, "seek": 92644, "start": 939.44, "end": 940.44, "text": " that data.", "tokens": [300, 1412, 13], "temperature": 0.0, "avg_logprob": -0.0704607131869294, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.00013345955812837929}, {"id": 203, "seek": 92644, "start": 940.44, "end": 947.44, "text": " So you either use more shards in the cluster, or you split the data into so-called sequential", "tokens": [407, 291, 2139, 764, 544, 402, 2287, 294, 264, 13630, 11, 420, 291, 7472, 264, 1412, 666, 370, 12, 11880, 42881], "temperature": 0.0, "avg_logprob": -0.0704607131869294, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.00013345955812837929}, {"id": 204, "seek": 92644, "start": 947.44, "end": 948.44, "text": " indexes.", "tokens": [8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.0704607131869294, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.00013345955812837929}, {"id": 205, "seek": 94844, "start": 948.44, "end": 956.44, "text": " So for example, you might have daily, weekly, or monthly indexes.", "tokens": [407, 337, 1365, 11, 291, 1062, 362, 5212, 11, 12460, 11, 420, 12878, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.06232120051528468, "compression_ratio": 1.6877637130801688, "no_speech_prob": 0.00016065800446085632}, {"id": 206, "seek": 94844, "start": 956.44, "end": 958.44, "text": " Now, this is what I mentioned.", "tokens": [823, 11, 341, 307, 437, 286, 2835, 13], "temperature": 0.0, "avg_logprob": -0.06232120051528468, "compression_ratio": 1.6877637130801688, "no_speech_prob": 0.00016065800446085632}, {"id": 207, "seek": 94844, "start": 958.44, "end": 962.44, "text": " So you should avoid putting too less data in the elastic search cluster.", "tokens": [407, 291, 820, 5042, 3372, 886, 1570, 1412, 294, 264, 17115, 3164, 13630, 13], "temperature": 0.0, "avg_logprob": -0.06232120051528468, "compression_ratio": 1.6877637130801688, "no_speech_prob": 0.00016065800446085632}, {"id": 208, "seek": 94844, "start": 962.44, "end": 968.44, "text": " Also, if you have too many shards defined on an index, that also introduces performance", "tokens": [2743, 11, 498, 291, 362, 886, 867, 402, 2287, 7642, 322, 364, 8186, 11, 300, 611, 31472, 3389], "temperature": 0.0, "avg_logprob": -0.06232120051528468, "compression_ratio": 1.6877637130801688, "no_speech_prob": 0.00016065800446085632}, {"id": 209, "seek": 94844, "start": 968.44, "end": 970.44, "text": " and management overhead.", "tokens": [293, 4592, 19922, 13], "temperature": 0.0, "avg_logprob": -0.06232120051528468, "compression_ratio": 1.6877637130801688, "no_speech_prob": 0.00016065800446085632}, {"id": 210, "seek": 94844, "start": 970.44, "end": 974.44, "text": " So you should consider rather splitting the data in the index rather than bringing too", "tokens": [407, 291, 820, 1949, 2831, 30348, 264, 1412, 294, 264, 8186, 2831, 813, 5062, 886], "temperature": 0.0, "avg_logprob": -0.06232120051528468, "compression_ratio": 1.6877637130801688, "no_speech_prob": 0.00016065800446085632}, {"id": 211, "seek": 94844, "start": 974.44, "end": 977.44, "text": " many shards on a single index.", "tokens": [867, 402, 2287, 322, 257, 2167, 8186, 13], "temperature": 0.0, "avg_logprob": -0.06232120051528468, "compression_ratio": 1.6877637130801688, "no_speech_prob": 0.00016065800446085632}, {"id": 212, "seek": 97744, "start": 977.44, "end": 983.44, "text": " And determining the number of shards should be a matter of upfront planning.", "tokens": [400, 23751, 264, 1230, 295, 402, 2287, 820, 312, 257, 1871, 295, 30264, 5038, 13], "temperature": 0.0, "avg_logprob": -0.04503796122095606, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.00020208192290738225}, {"id": 213, "seek": 97744, "start": 983.44, "end": 988.44, "text": " Now, apart from putting the fact that you need to avoid putting large amounts of data", "tokens": [823, 11, 4936, 490, 3372, 264, 1186, 300, 291, 643, 281, 5042, 3372, 2416, 11663, 295, 1412], "temperature": 0.0, "avg_logprob": -0.04503796122095606, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.00020208192290738225}, {"id": 214, "seek": 97744, "start": 988.44, "end": 995.44, "text": " in a single index, the main strategy that people use is to use, for example, prefix", "tokens": [294, 257, 2167, 8186, 11, 264, 2135, 5206, 300, 561, 764, 307, 281, 764, 11, 337, 1365, 11, 46969], "temperature": 0.0, "avg_logprob": -0.04503796122095606, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.00020208192290738225}, {"id": 215, "seek": 97744, "start": 995.44, "end": 997.44, "text": " when they split data into indexes.", "tokens": [562, 436, 7472, 1412, 666, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.04503796122095606, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.00020208192290738225}, {"id": 216, "seek": 97744, "start": 997.44, "end": 1001.44, "text": " For example, you can put prefix for daily, weekly, or yearly indexes.", "tokens": [1171, 1365, 11, 291, 393, 829, 46969, 337, 5212, 11, 12460, 11, 420, 39102, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.04503796122095606, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.00020208192290738225}, {"id": 217, "seek": 97744, "start": 1001.44, "end": 1005.44, "text": " And if you do that, it's a good practice that also you use aliases to reference data,", "tokens": [400, 498, 291, 360, 300, 11, 309, 311, 257, 665, 3124, 300, 611, 291, 764, 10198, 1957, 281, 6408, 1412, 11], "temperature": 0.0, "avg_logprob": -0.04503796122095606, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.00020208192290738225}, {"id": 218, "seek": 100544, "start": 1005.44, "end": 1012.44, "text": " directly reference a particular index in your application, but rather use aliases.", "tokens": [3838, 6408, 257, 1729, 8186, 294, 428, 3861, 11, 457, 2831, 764, 10198, 1957, 13], "temperature": 0.0, "avg_logprob": -0.08139681063200298, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.00058874482056126}, {"id": 219, "seek": 100544, "start": 1012.44, "end": 1017.44, "text": " In terms of concurrency control, elastic search does not provide pessimistic locking,", "tokens": [682, 2115, 295, 23702, 10457, 1969, 11, 17115, 3164, 775, 406, 2893, 37399, 3142, 23954, 11], "temperature": 0.0, "avg_logprob": -0.08139681063200298, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.00058874482056126}, {"id": 220, "seek": 100544, "start": 1017.44, "end": 1020.44, "text": " like, for example, you have in relational databases.", "tokens": [411, 11, 337, 1365, 11, 291, 362, 294, 38444, 22380, 13], "temperature": 0.0, "avg_logprob": -0.08139681063200298, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.00058874482056126}, {"id": 221, "seek": 100544, "start": 1020.44, "end": 1024.44, "text": " If you want to establish some form of concurrency control in elastic search in order to make", "tokens": [759, 291, 528, 281, 8327, 512, 1254, 295, 23702, 10457, 1969, 294, 17115, 3164, 294, 1668, 281, 652], "temperature": 0.0, "avg_logprob": -0.08139681063200298, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.00058874482056126}, {"id": 222, "seek": 100544, "start": 1024.44, "end": 1030.44, "text": " sure that you don't have unexpected race conditions, so elastic search uses optimistic", "tokens": [988, 300, 291, 500, 380, 362, 13106, 4569, 4487, 11, 370, 17115, 3164, 4960, 19397], "temperature": 0.0, "avg_logprob": -0.08139681063200298, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.00058874482056126}, {"id": 223, "seek": 100544, "start": 1030.44, "end": 1033.44, "text": " locking for concurrency control.", "tokens": [23954, 337, 23702, 10457, 1969, 13], "temperature": 0.0, "avg_logprob": -0.08139681063200298, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.00058874482056126}, {"id": 224, "seek": 103344, "start": 1033.44, "end": 1038.44, "text": " The way this works is when you index a document, there is a version attribute that can be", "tokens": [440, 636, 341, 1985, 307, 562, 291, 8186, 257, 4166, 11, 456, 307, 257, 3037, 19667, 300, 393, 312], "temperature": 0.0, "avg_logprob": -0.07975265957893582, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.00022115606407169253}, {"id": 225, "seek": 103344, "start": 1038.44, "end": 1039.44, "text": " specified.", "tokens": [22206, 13], "temperature": 0.0, "avg_logprob": -0.07975265957893582, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.00022115606407169253}, {"id": 226, "seek": 103344, "start": 1039.44, "end": 1044.44, "text": " And if there is already a document indexed with that version, then the operation is", "tokens": [400, 498, 456, 307, 1217, 257, 4166, 8186, 292, 365, 300, 3037, 11, 550, 264, 6916, 307], "temperature": 0.0, "avg_logprob": -0.07975265957893582, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.00022115606407169253}, {"id": 227, "seek": 103344, "start": 1044.44, "end": 1046.44, "text": " rejected from elastic search.", "tokens": [15749, 490, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.07975265957893582, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.00022115606407169253}, {"id": 228, "seek": 103344, "start": 1046.44, "end": 1051.44, "text": " Concurrency control can also be achieved with the two fields that can be specified", "tokens": [2656, 14112, 10457, 1969, 393, 611, 312, 11042, 365, 264, 732, 7909, 300, 393, 312, 22206], "temperature": 0.0, "avg_logprob": -0.07975265957893582, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.00022115606407169253}, {"id": 229, "seek": 103344, "start": 1051.44, "end": 1053.44, "text": " when you index the document.", "tokens": [562, 291, 8186, 264, 4166, 13], "temperature": 0.0, "avg_logprob": -0.07975265957893582, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.00022115606407169253}, {"id": 230, "seek": 103344, "start": 1053.44, "end": 1058.44, "text": " If sequence number and if primary term parameters, if they already match the document", "tokens": [759, 8310, 1230, 293, 498, 6194, 1433, 9834, 11, 498, 436, 1217, 2995, 264, 4166], "temperature": 0.0, "avg_logprob": -0.07975265957893582, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.00022115606407169253}, {"id": 231, "seek": 103344, "start": 1058.44, "end": 1060.44, "text": " that's indexed, then this operation gets rejected.", "tokens": [300, 311, 8186, 292, 11, 550, 341, 6916, 2170, 15749, 13], "temperature": 0.0, "avg_logprob": -0.07975265957893582, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.00022115606407169253}, {"id": 232, "seek": 106044, "start": 1060.44, "end": 1064.44, "text": " So if you want to establish some form of concurrency control in elastic search, you can", "tokens": [407, 498, 291, 528, 281, 8327, 512, 1254, 295, 23702, 10457, 1969, 294, 17115, 3164, 11, 291, 393], "temperature": 0.0, "avg_logprob": -0.08277978215898786, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.00016196424257941544}, {"id": 233, "seek": 106044, "start": 1064.44, "end": 1069.44, "text": " use this optimistic locking provided by elastic search.", "tokens": [764, 341, 19397, 23954, 5649, 538, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.08277978215898786, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.00016196424257941544}, {"id": 234, "seek": 106044, "start": 1069.44, "end": 1074.44, "text": " In terms of high availability, you can create one or more copies, or so-called replicas", "tokens": [682, 2115, 295, 1090, 17945, 11, 291, 393, 1884, 472, 420, 544, 14341, 11, 420, 370, 12, 11880, 3248, 9150], "temperature": 0.0, "avg_logprob": -0.08277978215898786, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.00016196424257941544}, {"id": 235, "seek": 106044, "start": 1074.44, "end": 1076.44, "text": " of an existing index.", "tokens": [295, 364, 6741, 8186, 13], "temperature": 0.0, "avg_logprob": -0.08277978215898786, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.00016196424257941544}, {"id": 236, "seek": 106044, "start": 1076.44, "end": 1081.44, "text": " The number of primary charts is specified when you define the index mapping, or you", "tokens": [440, 1230, 295, 6194, 17767, 307, 22206, 562, 291, 6964, 264, 8186, 18350, 11, 420, 291], "temperature": 0.0, "avg_logprob": -0.08277978215898786, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.00016196424257941544}, {"id": 237, "seek": 106044, "start": 1081.44, "end": 1083.44, "text": " can change it later.", "tokens": [393, 1319, 309, 1780, 13], "temperature": 0.0, "avg_logprob": -0.08277978215898786, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.00016196424257941544}, {"id": 238, "seek": 106044, "start": 1083.44, "end": 1087.44, "text": " Once an index request is sent to a particular chart, determined based on the hash of the", "tokens": [3443, 364, 8186, 5308, 307, 2279, 281, 257, 1729, 6927, 11, 9540, 2361, 322, 264, 22019, 295, 264], "temperature": 0.0, "avg_logprob": -0.08277978215898786, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.00016196424257941544}, {"id": 239, "seek": 106044, "start": 1087.44, "end": 1089.44, "text": " document ID.", "tokens": [4166, 7348, 13], "temperature": 0.0, "avg_logprob": -0.08277978215898786, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.00016196424257941544}, {"id": 240, "seek": 108944, "start": 1089.44, "end": 1091.44, "text": " The document is also sent to the chart replicas.", "tokens": [440, 4166, 307, 611, 2279, 281, 264, 6927, 3248, 9150, 13], "temperature": 0.0, "avg_logprob": -0.07598753385646369, "compression_ratio": 1.7754237288135593, "no_speech_prob": 0.00015041441656649113}, {"id": 241, "seek": 108944, "start": 1091.44, "end": 1096.44, "text": " And one interesting property in elastic search is that the replicas are not used only for", "tokens": [400, 472, 1880, 4707, 294, 17115, 3164, 307, 300, 264, 3248, 9150, 366, 406, 1143, 787, 337], "temperature": 0.0, "avg_logprob": -0.07598753385646369, "compression_ratio": 1.7754237288135593, "no_speech_prob": 0.00015041441656649113}, {"id": 242, "seek": 108944, "start": 1096.44, "end": 1100.44, "text": " high availability, but also used for searching purposes to improve performance.", "tokens": [1090, 17945, 11, 457, 611, 1143, 337, 10808, 9932, 281, 3470, 3389, 13], "temperature": 0.0, "avg_logprob": -0.07598753385646369, "compression_ratio": 1.7754237288135593, "no_speech_prob": 0.00015041441656649113}, {"id": 243, "seek": 108944, "start": 1100.44, "end": 1105.44, "text": " So when you have replica charts, they also participate in the search requests that you", "tokens": [407, 562, 291, 362, 35456, 17767, 11, 436, 611, 8197, 294, 264, 3164, 12475, 300, 291], "temperature": 0.0, "avg_logprob": -0.07598753385646369, "compression_ratio": 1.7754237288135593, "no_speech_prob": 0.00015041441656649113}, {"id": 244, "seek": 108944, "start": 1105.44, "end": 1110.44, "text": " have for elastic search.", "tokens": [362, 337, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.07598753385646369, "compression_ratio": 1.7754237288135593, "no_speech_prob": 0.00015041441656649113}, {"id": 245, "seek": 108944, "start": 1110.44, "end": 1116.44, "text": " Now, this mechanism for improving performance is really nice, but this doesn't mean that", "tokens": [823, 11, 341, 7513, 337, 11470, 3389, 307, 534, 1481, 11, 457, 341, 1177, 380, 914, 300], "temperature": 0.0, "avg_logprob": -0.07598753385646369, "compression_ratio": 1.7754237288135593, "no_speech_prob": 0.00015041441656649113}, {"id": 246, "seek": 111644, "start": 1116.44, "end": 1121.44, "text": " you need to supply to increase the number of replicas because, of course, that increases", "tokens": [291, 643, 281, 5847, 281, 3488, 264, 1230, 295, 3248, 9150, 570, 11, 295, 1164, 11, 300, 8637], "temperature": 0.0, "avg_logprob": -0.08051866149902344, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00024076584668364376}, {"id": 247, "seek": 111644, "start": 1121.44, "end": 1122.44, "text": " management overhead.", "tokens": [4592, 19922, 13], "temperature": 0.0, "avg_logprob": -0.08051866149902344, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00024076584668364376}, {"id": 248, "seek": 111644, "start": 1122.44, "end": 1126.44, "text": " So it's also a matter of determining how many replicas up front you would need.", "tokens": [407, 309, 311, 611, 257, 1871, 295, 23751, 577, 867, 3248, 9150, 493, 1868, 291, 576, 643, 13], "temperature": 0.0, "avg_logprob": -0.08051866149902344, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00024076584668364376}, {"id": 249, "seek": 111644, "start": 1126.44, "end": 1131.44, "text": " And later on, if you plan to scale your cluster, you can also increase the amount of replicas.", "tokens": [400, 1780, 322, 11, 498, 291, 1393, 281, 4373, 428, 13630, 11, 291, 393, 611, 3488, 264, 2372, 295, 3248, 9150, 13], "temperature": 0.0, "avg_logprob": -0.08051866149902344, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00024076584668364376}, {"id": 250, "seek": 111644, "start": 1131.44, "end": 1136.44, "text": " So you should not put a lot of replica charts also at the beginning when you define your", "tokens": [407, 291, 820, 406, 829, 257, 688, 295, 35456, 17767, 611, 412, 264, 2863, 562, 291, 6964, 428], "temperature": 0.0, "avg_logprob": -0.08051866149902344, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00024076584668364376}, {"id": 251, "seek": 111644, "start": 1136.44, "end": 1137.44, "text": " indexes.", "tokens": [8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.08051866149902344, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00024076584668364376}, {"id": 252, "seek": 111644, "start": 1137.44, "end": 1140.44, "text": " Now, how is a chart request processed?", "tokens": [823, 11, 577, 307, 257, 6927, 5308, 18846, 30], "temperature": 0.0, "avg_logprob": -0.08051866149902344, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00024076584668364376}, {"id": 253, "seek": 111644, "start": 1140.44, "end": 1143.44, "text": " Now, if we want to index a document in elastic search, what happens?", "tokens": [823, 11, 498, 321, 528, 281, 8186, 257, 4166, 294, 17115, 3164, 11, 437, 2314, 30], "temperature": 0.0, "avg_logprob": -0.08051866149902344, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00024076584668364376}, {"id": 254, "seek": 114344, "start": 1143.44, "end": 1146.44, "text": " We send the request to a coordinating node.", "tokens": [492, 2845, 264, 5308, 281, 257, 37824, 9984, 13], "temperature": 0.0, "avg_logprob": -0.08736832373965103, "compression_ratio": 1.9493670886075949, "no_speech_prob": 0.00034051938564516604}, {"id": 255, "seek": 114344, "start": 1146.44, "end": 1149.44, "text": " This is one of the nodes in the elastic search cluster.", "tokens": [639, 307, 472, 295, 264, 13891, 294, 264, 17115, 3164, 13630, 13], "temperature": 0.0, "avg_logprob": -0.08736832373965103, "compression_ratio": 1.9493670886075949, "no_speech_prob": 0.00034051938564516604}, {"id": 256, "seek": 114344, "start": 1149.44, "end": 1154.44, "text": " And this coordinating node sends the request to the chart, to the node in the cluster where", "tokens": [400, 341, 37824, 9984, 14790, 264, 5308, 281, 264, 6927, 11, 281, 264, 9984, 294, 264, 13630, 689], "temperature": 0.0, "avg_logprob": -0.08736832373965103, "compression_ratio": 1.9493670886075949, "no_speech_prob": 0.00034051938564516604}, {"id": 257, "seek": 114344, "start": 1154.44, "end": 1158.44, "text": " the document needs to be indexed and stored in Lucene segments.", "tokens": [264, 4166, 2203, 281, 312, 8186, 292, 293, 12187, 294, 9593, 1450, 19904, 13], "temperature": 0.0, "avg_logprob": -0.08736832373965103, "compression_ratio": 1.9493670886075949, "no_speech_prob": 0.00034051938564516604}, {"id": 258, "seek": 114344, "start": 1158.44, "end": 1164.44, "text": " When the document reaches the elastic search node in the cluster, the particular chart,", "tokens": [1133, 264, 4166, 14235, 264, 17115, 3164, 9984, 294, 264, 13630, 11, 264, 1729, 6927, 11], "temperature": 0.0, "avg_logprob": -0.08736832373965103, "compression_ratio": 1.9493670886075949, "no_speech_prob": 0.00034051938564516604}, {"id": 259, "seek": 114344, "start": 1164.44, "end": 1168.44, "text": " it gets sent not directly to the disk, but to two in-memory areas.", "tokens": [309, 2170, 2279, 406, 3838, 281, 264, 12355, 11, 457, 281, 732, 294, 12, 17886, 827, 3179, 13], "temperature": 0.0, "avg_logprob": -0.08736832373965103, "compression_ratio": 1.9493670886075949, "no_speech_prob": 0.00034051938564516604}, {"id": 260, "seek": 114344, "start": 1168.44, "end": 1171.44, "text": " This is the memory buffer and the transaction lock.", "tokens": [639, 307, 264, 4675, 21762, 293, 264, 14425, 4017, 13], "temperature": 0.0, "avg_logprob": -0.08736832373965103, "compression_ratio": 1.9493670886075949, "no_speech_prob": 0.00034051938564516604}, {"id": 261, "seek": 117144, "start": 1171.44, "end": 1175.44, "text": " Now, the memory buffer gets flushed every second to the disk.", "tokens": [823, 11, 264, 4675, 21762, 2170, 19568, 292, 633, 1150, 281, 264, 12355, 13], "temperature": 0.0, "avg_logprob": -0.05769975398614154, "compression_ratio": 1.7653429602888087, "no_speech_prob": 0.00015996793808881193}, {"id": 262, "seek": 117144, "start": 1175.44, "end": 1179.44, "text": " So when you index a document in elastic search, you cannot expect it to be available right", "tokens": [407, 562, 291, 8186, 257, 4166, 294, 17115, 3164, 11, 291, 2644, 2066, 309, 281, 312, 2435, 558], "temperature": 0.0, "avg_logprob": -0.05769975398614154, "compression_ratio": 1.7653429602888087, "no_speech_prob": 0.00015996793808881193}, {"id": 263, "seek": 117144, "start": 1179.44, "end": 1181.44, "text": " way for searching purposes.", "tokens": [636, 337, 10808, 9932, 13], "temperature": 0.0, "avg_logprob": -0.05769975398614154, "compression_ratio": 1.7653429602888087, "no_speech_prob": 0.00015996793808881193}, {"id": 264, "seek": 117144, "start": 1181.44, "end": 1185.44, "text": " But there is also a parameter that you can use to enforce it to be written to disk right", "tokens": [583, 456, 307, 611, 257, 13075, 300, 291, 393, 764, 281, 24825, 309, 281, 312, 3720, 281, 12355, 558], "temperature": 0.0, "avg_logprob": -0.05769975398614154, "compression_ratio": 1.7653429602888087, "no_speech_prob": 0.00015996793808881193}, {"id": 265, "seek": 117144, "start": 1185.44, "end": 1188.44, "text": " away before waiting for this one second to be flushed on disk.", "tokens": [1314, 949, 3806, 337, 341, 472, 1150, 281, 312, 19568, 292, 322, 12355, 13], "temperature": 0.0, "avg_logprob": -0.05769975398614154, "compression_ratio": 1.7653429602888087, "no_speech_prob": 0.00015996793808881193}, {"id": 266, "seek": 117144, "start": 1188.44, "end": 1193.44, "text": " There is also another area, which is called the transaction lock, where it gets flushed", "tokens": [821, 307, 611, 1071, 1859, 11, 597, 307, 1219, 264, 14425, 4017, 11, 689, 309, 2170, 19568, 292], "temperature": 0.0, "avg_logprob": -0.05769975398614154, "compression_ratio": 1.7653429602888087, "no_speech_prob": 0.00015996793808881193}, {"id": 267, "seek": 117144, "start": 1193.44, "end": 1194.44, "text": " not so often.", "tokens": [406, 370, 2049, 13], "temperature": 0.0, "avg_logprob": -0.05769975398614154, "compression_ratio": 1.7653429602888087, "no_speech_prob": 0.00015996793808881193}, {"id": 268, "seek": 117144, "start": 1194.44, "end": 1198.44, "text": " It gets flushed every 30 minutes or when it gets full.", "tokens": [467, 2170, 19568, 292, 633, 2217, 2077, 420, 562, 309, 2170, 1577, 13], "temperature": 0.0, "avg_logprob": -0.05769975398614154, "compression_ratio": 1.7653429602888087, "no_speech_prob": 0.00015996793808881193}, {"id": 269, "seek": 119844, "start": 1198.44, "end": 1203.44, "text": " So the important takeover from this is that when you index a document, you should not", "tokens": [407, 264, 1021, 747, 3570, 490, 341, 307, 300, 562, 291, 8186, 257, 4166, 11, 291, 820, 406], "temperature": 0.0, "avg_logprob": -0.08353214263916016, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.00013577683421317488}, {"id": 270, "seek": 119844, "start": 1203.44, "end": 1209.44, "text": " expect it to be available right way for searching, but you can enforce it too.", "tokens": [2066, 309, 281, 312, 2435, 558, 636, 337, 10808, 11, 457, 291, 393, 24825, 309, 886, 13], "temperature": 0.0, "avg_logprob": -0.08353214263916016, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.00013577683421317488}, {"id": 271, "seek": 119844, "start": 1209.44, "end": 1215.44, "text": " What happens if you send the search query to elastic search?", "tokens": [708, 2314, 498, 291, 2845, 264, 3164, 14581, 281, 17115, 3164, 30], "temperature": 0.0, "avg_logprob": -0.08353214263916016, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.00013577683421317488}, {"id": 272, "seek": 119844, "start": 1215.44, "end": 1219.44, "text": " First, the search request gets sent to one of the nodes in the elastic search cluster,", "tokens": [2386, 11, 264, 3164, 5308, 2170, 2279, 281, 472, 295, 264, 13891, 294, 264, 17115, 3164, 13630, 11], "temperature": 0.0, "avg_logprob": -0.08353214263916016, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.00013577683421317488}, {"id": 273, "seek": 119844, "start": 1219.44, "end": 1221.44, "text": " the so-called coordinating node.", "tokens": [264, 370, 12, 11880, 37824, 9984, 13], "temperature": 0.0, "avg_logprob": -0.08353214263916016, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.00013577683421317488}, {"id": 274, "seek": 119844, "start": 1221.44, "end": 1223.44, "text": " Then we have two phases.", "tokens": [1396, 321, 362, 732, 18764, 13], "temperature": 0.0, "avg_logprob": -0.08353214263916016, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.00013577683421317488}, {"id": 275, "seek": 119844, "start": 1223.44, "end": 1224.44, "text": " First is the query phase.", "tokens": [2386, 307, 264, 14581, 5574, 13], "temperature": 0.0, "avg_logprob": -0.08353214263916016, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.00013577683421317488}, {"id": 276, "seek": 122444, "start": 1224.44, "end": 1229.44, "text": " It asks all the shots, primary and replica shots, hey, do you contain some data for that", "tokens": [467, 8962, 439, 264, 8305, 11, 6194, 293, 35456, 8305, 11, 4177, 11, 360, 291, 5304, 512, 1412, 337, 300], "temperature": 0.0, "avg_logprob": -0.08874428166752368, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.00016267869796138257}, {"id": 277, "seek": 122444, "start": 1229.44, "end": 1230.44, "text": " search query?", "tokens": [3164, 14581, 30], "temperature": 0.0, "avg_logprob": -0.08874428166752368, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.00016267869796138257}, {"id": 278, "seek": 122444, "start": 1230.44, "end": 1233.44, "text": " And this information gets returned to the coordinating node.", "tokens": [400, 341, 1589, 2170, 8752, 281, 264, 37824, 9984, 13], "temperature": 0.0, "avg_logprob": -0.08874428166752368, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.00016267869796138257}, {"id": 279, "seek": 122444, "start": 1233.44, "end": 1238.44, "text": " Based on that information, the coordinating node determines which nodes it needs to query.", "tokens": [18785, 322, 300, 1589, 11, 264, 37824, 9984, 24799, 597, 13891, 309, 2203, 281, 14581, 13], "temperature": 0.0, "avg_logprob": -0.08874428166752368, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.00016267869796138257}, {"id": 280, "seek": 122444, "start": 1238.44, "end": 1242.44, "text": " And on the second fetch phase, it sends the request to the shots that have some data for", "tokens": [400, 322, 264, 1150, 23673, 5574, 11, 309, 14790, 264, 5308, 281, 264, 8305, 300, 362, 512, 1412, 337], "temperature": 0.0, "avg_logprob": -0.08874428166752368, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.00016267869796138257}, {"id": 281, "seek": 122444, "start": 1242.44, "end": 1247.44, "text": " that search query and return it back to the client.", "tokens": [300, 3164, 14581, 293, 2736, 309, 646, 281, 264, 6423, 13], "temperature": 0.0, "avg_logprob": -0.08874428166752368, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.00016267869796138257}, {"id": 282, "seek": 122444, "start": 1247.44, "end": 1253.44, "text": " Now, in terms of how is the elastic search called base structured, this is a snapshot", "tokens": [823, 11, 294, 2115, 295, 577, 307, 264, 17115, 3164, 1219, 3096, 18519, 11, 341, 307, 257, 30163], "temperature": 0.0, "avg_logprob": -0.08874428166752368, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.00016267869796138257}, {"id": 283, "seek": 125344, "start": 1253.44, "end": 1257.44, "text": " from the GitHub code base of elastic search from the public code base.", "tokens": [490, 264, 23331, 3089, 3096, 295, 17115, 3164, 490, 264, 1908, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.07619667053222656, "compression_ratio": 1.9595959595959596, "no_speech_prob": 0.0005427690339274704}, {"id": 284, "seek": 125344, "start": 1257.44, "end": 1261.44, "text": " Now, what I'm speaking about in this presentation applies for the public code base in elastic", "tokens": [823, 11, 437, 286, 478, 4124, 466, 294, 341, 5860, 13165, 337, 264, 1908, 3089, 3096, 294, 17115], "temperature": 0.0, "avg_logprob": -0.07619667053222656, "compression_ratio": 1.9595959595959596, "no_speech_prob": 0.0005427690339274704}, {"id": 285, "seek": 125344, "start": 1261.44, "end": 1265.44, "text": " search because of version 7.16, there was a licensing change, and there is a lot of", "tokens": [3164, 570, 295, 3037, 1614, 13, 6866, 11, 456, 390, 257, 29759, 1319, 11, 293, 456, 307, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.07619667053222656, "compression_ratio": 1.9595959595959596, "no_speech_prob": 0.0005427690339274704}, {"id": 286, "seek": 125344, "start": 1265.44, "end": 1270.44, "text": " controversy in the open source communities whether elastic search is still open source", "tokens": [22976, 294, 264, 1269, 4009, 4456, 1968, 17115, 3164, 307, 920, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.07619667053222656, "compression_ratio": 1.9595959595959596, "no_speech_prob": 0.0005427690339274704}, {"id": 287, "seek": 125344, "start": 1270.44, "end": 1271.44, "text": " or not.", "tokens": [420, 406, 13], "temperature": 0.0, "avg_logprob": -0.07619667053222656, "compression_ratio": 1.9595959595959596, "no_speech_prob": 0.0005427690339274704}, {"id": 288, "seek": 125344, "start": 1271.44, "end": 1273.44, "text": " So we can have a discussion about that after the session.", "tokens": [407, 321, 393, 362, 257, 5017, 466, 300, 934, 264, 5481, 13], "temperature": 0.0, "avg_logprob": -0.07619667053222656, "compression_ratio": 1.9595959595959596, "no_speech_prob": 0.0005427690339274704}, {"id": 289, "seek": 125344, "start": 1273.44, "end": 1277.44, "text": " I'm not going to go into the details, but the main thing about this licensing change", "tokens": [286, 478, 406, 516, 281, 352, 666, 264, 4365, 11, 457, 264, 2135, 551, 466, 341, 29759, 1319], "temperature": 0.0, "avg_logprob": -0.07619667053222656, "compression_ratio": 1.9595959595959596, "no_speech_prob": 0.0005427690339274704}, {"id": 290, "seek": 125344, "start": 1277.44, "end": 1282.44, "text": " is to protect elastic search from other vendors willing to provide elastic search as a service,", "tokens": [307, 281, 2371, 17115, 3164, 490, 661, 22056, 4950, 281, 2893, 17115, 3164, 382, 257, 2643, 11], "temperature": 0.0, "avg_logprob": -0.07619667053222656, "compression_ratio": 1.9595959595959596, "no_speech_prob": 0.0005427690339274704}, {"id": 291, "seek": 128244, "start": 1282.44, "end": 1287.44, "text": " not from people willing to customize elastic search or to use it for their in-house projects", "tokens": [406, 490, 561, 4950, 281, 19734, 17115, 3164, 420, 281, 764, 309, 337, 641, 294, 12, 6410, 4455], "temperature": 0.0, "avg_logprob": -0.07985654084578804, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.0001029684572131373}, {"id": 292, "seek": 128244, "start": 1287.44, "end": 1288.44, "text": " and so on.", "tokens": [293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.07985654084578804, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.0001029684572131373}, {"id": 293, "seek": 128244, "start": 1288.44, "end": 1293.44, "text": " So this is the structure of the elastic search code base that has been like this since the", "tokens": [407, 341, 307, 264, 3877, 295, 264, 17115, 3164, 3089, 3096, 300, 575, 668, 411, 341, 1670, 264], "temperature": 0.0, "avg_logprob": -0.07985654084578804, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.0001029684572131373}, {"id": 294, "seek": 128244, "start": 1293.44, "end": 1295.44, "text": " Apache license code base.", "tokens": [46597, 10476, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.07985654084578804, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.0001029684572131373}, {"id": 295, "seek": 128244, "start": 1295.44, "end": 1299.44, "text": " So elastic search gets built with GitHub actions.", "tokens": [407, 17115, 3164, 2170, 3094, 365, 23331, 5909, 13], "temperature": 0.0, "avg_logprob": -0.07985654084578804, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.0001029684572131373}, {"id": 296, "seek": 128244, "start": 1299.44, "end": 1303.44, "text": " You can see also the definition in the.github folder.", "tokens": [509, 393, 536, 611, 264, 7123, 294, 264, 2411, 70, 355, 836, 10820, 13], "temperature": 0.0, "avg_logprob": -0.07985654084578804, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.0001029684572131373}, {"id": 297, "seek": 128244, "start": 1303.44, "end": 1306.44, "text": " The main server application is in the server folder.", "tokens": [440, 2135, 7154, 3861, 307, 294, 264, 7154, 10820, 13], "temperature": 0.0, "avg_logprob": -0.07985654084578804, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.0001029684572131373}, {"id": 298, "seek": 128244, "start": 1306.44, "end": 1310.44, "text": " The documentation that gets generated on the official elastic search website is in the docs", "tokens": [440, 14333, 300, 2170, 10833, 322, 264, 4783, 17115, 3164, 3144, 307, 294, 264, 45623], "temperature": 0.0, "avg_logprob": -0.07985654084578804, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.0001029684572131373}, {"id": 299, "seek": 128244, "start": 1310.44, "end": 1311.44, "text": " folder.", "tokens": [10820, 13], "temperature": 0.0, "avg_logprob": -0.07985654084578804, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.0001029684572131373}, {"id": 300, "seek": 131144, "start": 1311.44, "end": 1315.44, "text": " We have the main modules for the elastic search server application in the modules folder and", "tokens": [492, 362, 264, 2135, 16679, 337, 264, 17115, 3164, 7154, 3861, 294, 264, 16679, 10820, 293], "temperature": 0.0, "avg_logprob": -0.12392938040136321, "compression_ratio": 1.8075601374570447, "no_speech_prob": 8.785375393927097e-05}, {"id": 301, "seek": 131144, "start": 1315.44, "end": 1318.44, "text": " the internal plugins in the plugins folder.", "tokens": [264, 6920, 33759, 294, 264, 33759, 10820, 13], "temperature": 0.0, "avg_logprob": -0.12392938040136321, "compression_ratio": 1.8075601374570447, "no_speech_prob": 8.785375393927097e-05}, {"id": 302, "seek": 131144, "start": 1318.44, "end": 1323.44, "text": " An implementation of the REST based Java client for elastic search, the high level and the", "tokens": [1107, 11420, 295, 264, 497, 14497, 2361, 10745, 6423, 337, 17115, 3164, 11, 264, 1090, 1496, 293, 264], "temperature": 0.0, "avg_logprob": -0.12392938040136321, "compression_ratio": 1.8075601374570447, "no_speech_prob": 8.785375393927097e-05}, {"id": 303, "seek": 131144, "start": 1323.44, "end": 1327.44, "text": " low level REST funds are in the client folder, and the distribution folder, you can find", "tokens": [2295, 1496, 497, 14497, 8271, 366, 294, 264, 6423, 10820, 11, 293, 264, 7316, 10820, 11, 291, 393, 915], "temperature": 0.0, "avg_logprob": -0.12392938040136321, "compression_ratio": 1.8075601374570447, "no_speech_prob": 8.785375393927097e-05}, {"id": 304, "seek": 131144, "start": 1327.44, "end": 1331.44, "text": " the gradle scripts that allow you to build different distributions of elastic search", "tokens": [264, 2771, 306, 23294, 300, 2089, 291, 281, 1322, 819, 37870, 295, 17115, 3164], "temperature": 0.0, "avg_logprob": -0.12392938040136321, "compression_ratio": 1.8075601374570447, "no_speech_prob": 8.785375393927097e-05}, {"id": 305, "seek": 131144, "start": 1331.44, "end": 1334.44, "text": " for Linux, Windows, and so on.", "tokens": [337, 18734, 11, 8591, 11, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.12392938040136321, "compression_ratio": 1.8075601374570447, "no_speech_prob": 8.785375393927097e-05}, {"id": 306, "seek": 131144, "start": 1334.44, "end": 1338.44, "text": " Now, I would say the structure of the code repository is very logical.", "tokens": [823, 11, 286, 576, 584, 264, 3877, 295, 264, 3089, 25841, 307, 588, 14978, 13], "temperature": 0.0, "avg_logprob": -0.12392938040136321, "compression_ratio": 1.8075601374570447, "no_speech_prob": 8.785375393927097e-05}, {"id": 307, "seek": 131144, "start": 1338.44, "end": 1340.44, "text": " It's easy to navigate.", "tokens": [467, 311, 1858, 281, 12350, 13], "temperature": 0.0, "avg_logprob": -0.12392938040136321, "compression_ratio": 1.8075601374570447, "no_speech_prob": 8.785375393927097e-05}, {"id": 308, "seek": 134044, "start": 1340.44, "end": 1345.44, "text": " So you can just go into GitHub, and if you need to see, for example, how is a particular", "tokens": [407, 291, 393, 445, 352, 666, 23331, 11, 293, 498, 291, 643, 281, 536, 11, 337, 1365, 11, 577, 307, 257, 1729], "temperature": 0.0, "avg_logprob": -0.1311947793671579, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.00018243982049170882}, {"id": 309, "seek": 134044, "start": 1345.44, "end": 1350.44, "text": " plugin or module implemented, you can just go to GitHub and check it out.", "tokens": [23407, 420, 10088, 12270, 11, 291, 393, 445, 352, 281, 23331, 293, 1520, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.1311947793671579, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.00018243982049170882}, {"id": 310, "seek": 134044, "start": 1350.44, "end": 1354.44, "text": " Now, internally elastic search is comprised of different modules.", "tokens": [823, 11, 19501, 17115, 3164, 307, 38062, 295, 819, 16679, 13], "temperature": 0.0, "avg_logprob": -0.1311947793671579, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.00018243982049170882}, {"id": 311, "seek": 134044, "start": 1354.44, "end": 1359.44, "text": " And in earlier versions, elastic search used the modified version of Google GIS for module", "tokens": [400, 294, 3071, 9606, 11, 17115, 3164, 1143, 264, 15873, 3037, 295, 3329, 47860, 337, 10088], "temperature": 0.0, "avg_logprob": -0.1311947793671579, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.00018243982049170882}, {"id": 312, "seek": 134044, "start": 1359.44, "end": 1364.44, "text": " binding, but they're slowly shifting away from Google GIS in favor of their own internal", "tokens": [17359, 11, 457, 436, 434, 5692, 17573, 1314, 490, 3329, 47860, 294, 2294, 295, 641, 1065, 6920], "temperature": 0.0, "avg_logprob": -0.1311947793671579, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.00018243982049170882}, {"id": 313, "seek": 134044, "start": 1364.44, "end": 1366.44, "text": " module system.", "tokens": [10088, 1185, 13], "temperature": 0.0, "avg_logprob": -0.1311947793671579, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.00018243982049170882}, {"id": 314, "seek": 136644, "start": 1366.44, "end": 1371.44, "text": " So modules are loaded on startup when the elastic search server starts up.", "tokens": [407, 16679, 366, 13210, 322, 18578, 562, 264, 17115, 3164, 7154, 3719, 493, 13], "temperature": 0.0, "avg_logprob": -0.0996794033050537, "compression_ratio": 1.7605042016806722, "no_speech_prob": 3.949581514461897e-05}, {"id": 315, "seek": 136644, "start": 1371.44, "end": 1377.44, "text": " And in this simple example, I've shown an example of how modules were bound internally", "tokens": [400, 294, 341, 2199, 1365, 11, 286, 600, 4898, 364, 1365, 295, 577, 16679, 645, 5472, 19501], "temperature": 0.0, "avg_logprob": -0.0996794033050537, "compression_ratio": 1.7605042016806722, "no_speech_prob": 3.949581514461897e-05}, {"id": 316, "seek": 136644, "start": 1377.44, "end": 1379.44, "text": " when the node starts up.", "tokens": [562, 264, 9984, 3719, 493, 13], "temperature": 0.0, "avg_logprob": -0.0996794033050537, "compression_ratio": 1.7605042016806722, "no_speech_prob": 3.949581514461897e-05}, {"id": 317, "seek": 136644, "start": 1379.44, "end": 1381.44, "text": " So we use a module binder.", "tokens": [407, 321, 764, 257, 10088, 45630, 13], "temperature": 0.0, "avg_logprob": -0.0996794033050537, "compression_ratio": 1.7605042016806722, "no_speech_prob": 3.949581514461897e-05}, {"id": 318, "seek": 136644, "start": 1381.44, "end": 1383.44, "text": " The earlier versions, B was a Google GIS binder.", "tokens": [440, 3071, 9606, 11, 363, 390, 257, 3329, 47860, 45630, 13], "temperature": 0.0, "avg_logprob": -0.0996794033050537, "compression_ratio": 1.7605042016806722, "no_speech_prob": 3.949581514461897e-05}, {"id": 319, "seek": 136644, "start": 1383.44, "end": 1388.44, "text": " And then we bind particular module classes to their implementation.", "tokens": [400, 550, 321, 14786, 1729, 10088, 5359, 281, 641, 11420, 13], "temperature": 0.0, "avg_logprob": -0.0996794033050537, "compression_ratio": 1.7605042016806722, "no_speech_prob": 3.949581514461897e-05}, {"id": 320, "seek": 136644, "start": 1388.44, "end": 1393.44, "text": " And then wherever you need them, you can reference them in the elastic search code base.", "tokens": [400, 550, 8660, 291, 643, 552, 11, 291, 393, 6408, 552, 294, 264, 17115, 3164, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.0996794033050537, "compression_ratio": 1.7605042016806722, "no_speech_prob": 3.949581514461897e-05}, {"id": 321, "seek": 139344, "start": 1393.44, "end": 1397.44, "text": " It's a very simple dependency injection mechanism.", "tokens": [467, 311, 257, 588, 2199, 33621, 22873, 7513, 13], "temperature": 0.0, "avg_logprob": -0.11239092849021734, "compression_ratio": 1.698019801980198, "no_speech_prob": 3.7902951589785516e-05}, {"id": 322, "seek": 139344, "start": 1397.44, "end": 1402.44, "text": " Now, when elastic search starts up, you can imagine it's a simple Java application.", "tokens": [823, 11, 562, 17115, 3164, 3719, 493, 11, 291, 393, 3811, 309, 311, 257, 2199, 10745, 3861, 13], "temperature": 0.0, "avg_logprob": -0.11239092849021734, "compression_ratio": 1.698019801980198, "no_speech_prob": 3.7902951589785516e-05}, {"id": 323, "seek": 139344, "start": 1402.44, "end": 1406.44, "text": " The main class is Orc elastic search, bootstrap elastic search.", "tokens": [440, 2135, 1508, 307, 1610, 66, 17115, 3164, 11, 11450, 372, 4007, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.11239092849021734, "compression_ratio": 1.698019801980198, "no_speech_prob": 3.7902951589785516e-05}, {"id": 324, "seek": 139344, "start": 1406.44, "end": 1410.44, "text": " It boils down to calling the start method of the node class.", "tokens": [467, 35049, 760, 281, 5141, 264, 722, 3170, 295, 264, 9984, 1508, 13], "temperature": 0.0, "avg_logprob": -0.11239092849021734, "compression_ratio": 1.698019801980198, "no_speech_prob": 3.7902951589785516e-05}, {"id": 325, "seek": 139344, "start": 1410.44, "end": 1416.44, "text": " And the start method, in fact, loads up all the modules of the elastic search node.", "tokens": [400, 264, 722, 3170, 11, 294, 1186, 11, 12668, 493, 439, 264, 16679, 295, 264, 17115, 3164, 9984, 13], "temperature": 0.0, "avg_logprob": -0.11239092849021734, "compression_ratio": 1.698019801980198, "no_speech_prob": 3.7902951589785516e-05}, {"id": 326, "seek": 141644, "start": 1416.44, "end": 1427.44, "text": " Now, some of these core modules are, for example, modules that provide the REST API of elastic", "tokens": [823, 11, 512, 295, 613, 4965, 16679, 366, 11, 337, 1365, 11, 16679, 300, 2893, 264, 497, 14497, 9362, 295, 17115], "temperature": 0.0, "avg_logprob": -0.10986439387003581, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.701174424961209e-05}, {"id": 327, "seek": 141644, "start": 1427.44, "end": 1432.44, "text": " search module that allows you to establish clustering and elastic search, or so-called", "tokens": [3164, 10088, 300, 4045, 291, 281, 8327, 596, 48673, 293, 17115, 3164, 11, 420, 370, 12, 11880], "temperature": 0.0, "avg_logprob": -0.10986439387003581, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.701174424961209e-05}, {"id": 328, "seek": 141644, "start": 1432.44, "end": 1434.44, "text": " transport module.", "tokens": [5495, 10088, 13], "temperature": 0.0, "avg_logprob": -0.10986439387003581, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.701174424961209e-05}, {"id": 329, "seek": 141644, "start": 1434.44, "end": 1442.44, "text": " There is a module that allows you to build plugins for elastic search, and so on and so forth.", "tokens": [821, 307, 257, 10088, 300, 4045, 291, 281, 1322, 33759, 337, 17115, 3164, 11, 293, 370, 322, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.10986439387003581, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.701174424961209e-05}, {"id": 330, "seek": 144244, "start": 1442.44, "end": 1446.44, "text": " Now, how does elastic search internally interact with loosing?", "tokens": [823, 11, 577, 775, 17115, 3164, 19501, 4648, 365, 450, 6110, 30], "temperature": 0.0, "avg_logprob": -0.14008158903855544, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.00010325801122235134}, {"id": 331, "seek": 144244, "start": 1446.44, "end": 1451.44, "text": " When you start up the node, the node also exposes, provides different services that are", "tokens": [1133, 291, 722, 493, 264, 9984, 11, 264, 9984, 611, 1278, 4201, 11, 6417, 819, 3328, 300, 366], "temperature": 0.0, "avg_logprob": -0.14008158903855544, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.00010325801122235134}, {"id": 332, "seek": 144244, "start": 1451.44, "end": 1454.44, "text": " used by the modules of elastic search.", "tokens": [1143, 538, 264, 16679, 295, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.14008158903855544, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.00010325801122235134}, {"id": 333, "seek": 144244, "start": 1454.44, "end": 1461.44, "text": " And, for example, if you want to, when you start up a node, there is a createChart method", "tokens": [400, 11, 337, 1365, 11, 498, 291, 528, 281, 11, 562, 291, 722, 493, 257, 9984, 11, 456, 307, 257, 1884, 6546, 446, 3170], "temperature": 0.0, "avg_logprob": -0.14008158903855544, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.00010325801122235134}, {"id": 334, "seek": 144244, "start": 1461.44, "end": 1467.44, "text": " that gets called, indexServiceCreateChart, to create and initialize the chart that is", "tokens": [300, 2170, 1219, 11, 8186, 50, 25006, 44637, 473, 6546, 446, 11, 281, 1884, 293, 5883, 1125, 264, 6927, 300, 307], "temperature": 0.0, "avg_logprob": -0.14008158903855544, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.00010325801122235134}, {"id": 335, "seek": 144244, "start": 1467.44, "end": 1469.44, "text": " part of this elastic search node.", "tokens": [644, 295, 341, 17115, 3164, 9984, 13], "temperature": 0.0, "avg_logprob": -0.14008158903855544, "compression_ratio": 1.7347826086956522, "no_speech_prob": 0.00010325801122235134}, {"id": 336, "seek": 146944, "start": 1469.44, "end": 1476.44, "text": " And then, if you want to index a new document, it boils down to calling indexChartApplyIndexOperation", "tokens": [400, 550, 11, 498, 291, 528, 281, 8186, 257, 777, 4166, 11, 309, 35049, 760, 281, 5141, 8186, 6546, 446, 9132, 356, 21790, 3121, 46, 610, 399], "temperature": 0.0, "avg_logprob": -0.15837382468856684, "compression_ratio": 1.894273127753304, "no_speech_prob": 0.00011407420970499516}, {"id": 337, "seek": 146944, "start": 1476.44, "end": 1478.44, "text": " on primary.", "tokens": [322, 6194, 13], "temperature": 0.0, "avg_logprob": -0.15837382468856684, "compression_ratio": 1.894273127753304, "no_speech_prob": 0.00011407420970499516}, {"id": 338, "seek": 146944, "start": 1478.44, "end": 1483.44, "text": " Then, this boils down to calling the index method on the indexChart class.", "tokens": [1396, 11, 341, 35049, 760, 281, 5141, 264, 8186, 3170, 322, 264, 8186, 6546, 446, 1508, 13], "temperature": 0.0, "avg_logprob": -0.15837382468856684, "compression_ratio": 1.894273127753304, "no_speech_prob": 0.00011407420970499516}, {"id": 339, "seek": 146944, "start": 1483.44, "end": 1490.44, "text": " And the indexChart class goes down to an internal engine class that calls index into loosing.", "tokens": [400, 264, 8186, 6546, 446, 1508, 1709, 760, 281, 364, 6920, 2848, 1508, 300, 5498, 8186, 666, 450, 6110, 13], "temperature": 0.0, "avg_logprob": -0.15837382468856684, "compression_ratio": 1.894273127753304, "no_speech_prob": 0.00011407420970499516}, {"id": 340, "seek": 146944, "start": 1490.44, "end": 1493.44, "text": " Then, that calls internal engine at docs.", "tokens": [1396, 11, 300, 5498, 6920, 2848, 412, 45623, 13], "temperature": 0.0, "avg_logprob": -0.15837382468856684, "compression_ratio": 1.894273127753304, "no_speech_prob": 0.00011407420970499516}, {"id": 341, "seek": 146944, "start": 1493.44, "end": 1497.44, "text": " And at the end, we just call indexWriter, which is a class from the Apache Loosing Library,", "tokens": [400, 412, 264, 917, 11, 321, 445, 818, 8186, 54, 81, 1681, 11, 597, 307, 257, 1508, 490, 264, 46597, 6130, 6110, 12806, 11], "temperature": 0.0, "avg_logprob": -0.15837382468856684, "compression_ratio": 1.894273127753304, "no_speech_prob": 0.00011407420970499516}, {"id": 342, "seek": 146944, "start": 1497.44, "end": 1498.44, "text": " at documents.", "tokens": [412, 8512, 13], "temperature": 0.0, "avg_logprob": -0.15837382468856684, "compression_ratio": 1.894273127753304, "no_speech_prob": 0.00011407420970499516}, {"id": 343, "seek": 149844, "start": 1498.44, "end": 1502.44, "text": " So, it boils down to calling different methods from the Loosing API.", "tokens": [407, 11, 309, 35049, 760, 281, 5141, 819, 7150, 490, 264, 6130, 6110, 9362, 13], "temperature": 0.0, "avg_logprob": -0.06670502174732297, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00021980813471600413}, {"id": 344, "seek": 149844, "start": 1502.44, "end": 1507.44, "text": " And on top of that, we have a lot of initialization and services happening.", "tokens": [400, 322, 1192, 295, 300, 11, 321, 362, 257, 688, 295, 5883, 2144, 293, 3328, 2737, 13], "temperature": 0.0, "avg_logprob": -0.06670502174732297, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00021980813471600413}, {"id": 345, "seek": 149844, "start": 1507.44, "end": 1512.44, "text": " So, in a way, you can think that apart from all the functionality that elastic search", "tokens": [407, 11, 294, 257, 636, 11, 291, 393, 519, 300, 4936, 490, 439, 264, 14980, 300, 17115, 3164], "temperature": 0.0, "avg_logprob": -0.06670502174732297, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00021980813471600413}, {"id": 346, "seek": 149844, "start": 1512.44, "end": 1516.44, "text": " provides, the integration with the Apache Loosing Library just boils down to calling the", "tokens": [6417, 11, 264, 10980, 365, 264, 46597, 6130, 6110, 12806, 445, 35049, 760, 281, 5141, 264], "temperature": 0.0, "avg_logprob": -0.06670502174732297, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00021980813471600413}, {"id": 347, "seek": 149844, "start": 1516.44, "end": 1522.44, "text": " different APIs that Apache Loosing provides.", "tokens": [819, 21445, 300, 46597, 6130, 6110, 6417, 13], "temperature": 0.0, "avg_logprob": -0.06670502174732297, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00021980813471600413}, {"id": 348, "seek": 152244, "start": 1522.44, "end": 1528.44, "text": " And last but not least, I'll show how you can build a very simple elastic search plugin.", "tokens": [400, 1036, 457, 406, 1935, 11, 286, 603, 855, 577, 291, 393, 1322, 257, 588, 2199, 17115, 3164, 23407, 13], "temperature": 0.0, "avg_logprob": -0.06524507602055868, "compression_ratio": 1.966804979253112, "no_speech_prob": 0.00033193666604347527}, {"id": 349, "seek": 152244, "start": 1528.44, "end": 1533.44, "text": " Now, if you see the elastic search code base, it already has some building plugins that", "tokens": [823, 11, 498, 291, 536, 264, 17115, 3164, 3089, 3096, 11, 309, 1217, 575, 512, 2390, 33759, 300], "temperature": 0.0, "avg_logprob": -0.06524507602055868, "compression_ratio": 1.966804979253112, "no_speech_prob": 0.00033193666604347527}, {"id": 350, "seek": 152244, "start": 1533.44, "end": 1534.44, "text": " you can use.", "tokens": [291, 393, 764, 13], "temperature": 0.0, "avg_logprob": -0.06524507602055868, "compression_ratio": 1.966804979253112, "no_speech_prob": 0.00033193666604347527}, {"id": 351, "seek": 152244, "start": 1534.44, "end": 1538.44, "text": " And there is a very nice elastic search plugin utility that you can use to manage plugins,", "tokens": [400, 456, 307, 257, 588, 1481, 17115, 3164, 23407, 14877, 300, 291, 393, 764, 281, 3067, 33759, 11], "temperature": 0.0, "avg_logprob": -0.06524507602055868, "compression_ratio": 1.966804979253112, "no_speech_prob": 0.00033193666604347527}, {"id": 352, "seek": 152244, "start": 1538.44, "end": 1541.44, "text": " to install them, remove them, and so on and so forth.", "tokens": [281, 3625, 552, 11, 4159, 552, 11, 293, 370, 322, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.06524507602055868, "compression_ratio": 1.966804979253112, "no_speech_prob": 0.00033193666604347527}, {"id": 353, "seek": 152244, "start": 1541.44, "end": 1545.44, "text": " If you build your own plugin, you can use the same utility to install the plugin, and", "tokens": [759, 291, 1322, 428, 1065, 23407, 11, 291, 393, 764, 264, 912, 14877, 281, 3625, 264, 23407, 11, 293], "temperature": 0.0, "avg_logprob": -0.06524507602055868, "compression_ratio": 1.966804979253112, "no_speech_prob": 0.00033193666604347527}, {"id": 354, "seek": 152244, "start": 1545.44, "end": 1548.44, "text": " it gets placed in a folder in your node installation.", "tokens": [309, 2170, 7074, 294, 257, 10820, 294, 428, 9984, 13260, 13], "temperature": 0.0, "avg_logprob": -0.06524507602055868, "compression_ratio": 1.966804979253112, "no_speech_prob": 0.00033193666604347527}, {"id": 355, "seek": 154844, "start": 1548.44, "end": 1552.44, "text": " So, if you install a plugin, you need to make sure that it's installed on all the nodes in", "tokens": [407, 11, 498, 291, 3625, 257, 23407, 11, 291, 643, 281, 652, 988, 300, 309, 311, 8899, 322, 439, 264, 13891, 294], "temperature": 0.0, "avg_logprob": -0.10376844235828944, "compression_ratio": 1.8253968253968254, "no_speech_prob": 4.3641950469464064e-05}, {"id": 356, "seek": 154844, "start": 1552.44, "end": 1554.44, "text": " your cluster.", "tokens": [428, 13630, 13], "temperature": 0.0, "avg_logprob": -0.10376844235828944, "compression_ratio": 1.8253968253968254, "no_speech_prob": 4.3641950469464064e-05}, {"id": 357, "seek": 154844, "start": 1554.44, "end": 1558.44, "text": " Because many plugins are cluster aware, it needs to be installed on every node in the", "tokens": [1436, 867, 33759, 366, 13630, 3650, 11, 309, 2203, 281, 312, 8899, 322, 633, 9984, 294, 264], "temperature": 0.0, "avg_logprob": -0.10376844235828944, "compression_ratio": 1.8253968253968254, "no_speech_prob": 4.3641950469464064e-05}, {"id": 358, "seek": 154844, "start": 1558.44, "end": 1561.44, "text": " cluster.", "tokens": [13630, 13], "temperature": 0.0, "avg_logprob": -0.10376844235828944, "compression_ratio": 1.8253968253968254, "no_speech_prob": 4.3641950469464064e-05}, {"id": 359, "seek": 154844, "start": 1561.44, "end": 1565.44, "text": " Elastic search plugins are bundled in ZIP archives, along with their dependencies, and", "tokens": [2699, 2750, 3164, 33759, 366, 13882, 1493, 294, 1176, 9139, 25607, 11, 2051, 365, 641, 36606, 11, 293], "temperature": 0.0, "avg_logprob": -0.10376844235828944, "compression_ratio": 1.8253968253968254, "no_speech_prob": 4.3641950469464064e-05}, {"id": 360, "seek": 154844, "start": 1565.44, "end": 1570.44, "text": " all of them must have a class that implements our elastic search plugin's plugin class.", "tokens": [439, 295, 552, 1633, 362, 257, 1508, 300, 704, 17988, 527, 17115, 3164, 23407, 311, 23407, 1508, 13], "temperature": 0.0, "avg_logprob": -0.10376844235828944, "compression_ratio": 1.8253968253968254, "no_speech_prob": 4.3641950469464064e-05}, {"id": 361, "seek": 154844, "start": 1570.44, "end": 1576.44, "text": " There is a plugin service which is responsible to load the plugins in elastic search.", "tokens": [821, 307, 257, 23407, 2643, 597, 307, 6250, 281, 3677, 264, 33759, 294, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.10376844235828944, "compression_ratio": 1.8253968253968254, "no_speech_prob": 4.3641950469464064e-05}, {"id": 362, "seek": 157644, "start": 1576.44, "end": 1582.44, "text": " Now, let's see how we can create a very simple ingest plugin that allows you to filter words", "tokens": [823, 11, 718, 311, 536, 577, 321, 393, 1884, 257, 588, 2199, 3957, 377, 23407, 300, 4045, 291, 281, 6608, 2283], "temperature": 0.0, "avg_logprob": -0.07923031559696904, "compression_ratio": 1.9523809523809523, "no_speech_prob": 9.75533839664422e-05}, {"id": 363, "seek": 157644, "start": 1582.44, "end": 1584.44, "text": " from a field of an index document.", "tokens": [490, 257, 2519, 295, 364, 8186, 4166, 13], "temperature": 0.0, "avg_logprob": -0.07923031559696904, "compression_ratio": 1.9523809523809523, "no_speech_prob": 9.75533839664422e-05}, {"id": 364, "seek": 157644, "start": 1584.44, "end": 1588.44, "text": " So, if you index a document, you can specify from which field, which words you want to", "tokens": [407, 11, 498, 291, 8186, 257, 4166, 11, 291, 393, 16500, 490, 597, 2519, 11, 597, 2283, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.07923031559696904, "compression_ratio": 1.9523809523809523, "no_speech_prob": 9.75533839664422e-05}, {"id": 365, "seek": 157644, "start": 1588.44, "end": 1589.44, "text": " filter out.", "tokens": [6608, 484, 13], "temperature": 0.0, "avg_logprob": -0.07923031559696904, "compression_ratio": 1.9523809523809523, "no_speech_prob": 9.75533839664422e-05}, {"id": 366, "seek": 157644, "start": 1589.44, "end": 1593.44, "text": " This is a very common scenario, for example, if you want, for example, to implement that", "tokens": [639, 307, 257, 588, 2689, 9005, 11, 337, 1365, 11, 498, 291, 528, 11, 337, 1365, 11, 281, 4445, 300], "temperature": 0.0, "avg_logprob": -0.07923031559696904, "compression_ratio": 1.9523809523809523, "no_speech_prob": 9.75533839664422e-05}, {"id": 367, "seek": 157644, "start": 1593.44, "end": 1598.44, "text": " allows you to clear contents from documents and so on and so forth.", "tokens": [4045, 291, 281, 1850, 15768, 490, 8512, 293, 370, 322, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.07923031559696904, "compression_ratio": 1.9523809523809523, "no_speech_prob": 9.75533839664422e-05}, {"id": 368, "seek": 157644, "start": 1598.44, "end": 1601.44, "text": " It's probably one of the simplest plugins you might have.", "tokens": [467, 311, 1391, 472, 295, 264, 22811, 33759, 291, 1062, 362, 13], "temperature": 0.0, "avg_logprob": -0.07923031559696904, "compression_ratio": 1.9523809523809523, "no_speech_prob": 9.75533839664422e-05}, {"id": 369, "seek": 157644, "start": 1601.44, "end": 1605.44, "text": " So, first we have a filter ingest plugin class that extends the plugin class and implements", "tokens": [407, 11, 700, 321, 362, 257, 6608, 3957, 377, 23407, 1508, 300, 26448, 264, 23407, 1508, 293, 704, 17988], "temperature": 0.0, "avg_logprob": -0.07923031559696904, "compression_ratio": 1.9523809523809523, "no_speech_prob": 9.75533839664422e-05}, {"id": 370, "seek": 160544, "start": 1605.44, "end": 1606.44, "text": " ingest plugin.", "tokens": [3957, 377, 23407, 13], "temperature": 0.0, "avg_logprob": -0.1094611323609644, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.00015281050582416356}, {"id": 371, "seek": 160544, "start": 1606.44, "end": 1610.44, "text": " We have different interfaces for the different types of plugins you might have for elastic", "tokens": [492, 362, 819, 28416, 337, 264, 819, 3467, 295, 33759, 291, 1062, 362, 337, 17115], "temperature": 0.0, "avg_logprob": -0.1094611323609644, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.00015281050582416356}, {"id": 372, "seek": 160544, "start": 1610.44, "end": 1614.44, "text": " search, and ingest plugin is one of these types of interfaces.", "tokens": [3164, 11, 293, 3957, 377, 23407, 307, 472, 295, 613, 3467, 295, 28416, 13], "temperature": 0.0, "avg_logprob": -0.1094611323609644, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.00015281050582416356}, {"id": 373, "seek": 160544, "start": 1614.44, "end": 1621.44, "text": " Then you specify you implement the get processors method because an ingest plugin needs to have", "tokens": [1396, 291, 16500, 291, 4445, 264, 483, 27751, 3170, 570, 364, 3957, 377, 23407, 2203, 281, 362], "temperature": 0.0, "avg_logprob": -0.1094611323609644, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.00015281050582416356}, {"id": 374, "seek": 160544, "start": 1621.44, "end": 1626.44, "text": " processors that you can define that do something on the documents before their index.", "tokens": [27751, 300, 291, 393, 6964, 300, 360, 746, 322, 264, 8512, 949, 641, 8186, 13], "temperature": 0.0, "avg_logprob": -0.1094611323609644, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.00015281050582416356}, {"id": 375, "seek": 160544, "start": 1626.44, "end": 1633.44, "text": " And the get processors method, what we do, we get a filter word from the parameters that", "tokens": [400, 264, 483, 27751, 3170, 11, 437, 321, 360, 11, 321, 483, 257, 6608, 1349, 490, 264, 9834, 300], "temperature": 0.0, "avg_logprob": -0.1094611323609644, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.00015281050582416356}, {"id": 376, "seek": 163344, "start": 1633.44, "end": 1637.44, "text": " we supply on the ingest processor that we define in elastic search.", "tokens": [321, 5847, 322, 264, 3957, 377, 15321, 300, 321, 6964, 294, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.07669233161712362, "compression_ratio": 1.8839285714285714, "no_speech_prob": 0.00020759399922098964}, {"id": 377, "seek": 163344, "start": 1637.44, "end": 1639.44, "text": " And then we get the filter field.", "tokens": [400, 550, 321, 483, 264, 6608, 2519, 13], "temperature": 0.0, "avg_logprob": -0.07669233161712362, "compression_ratio": 1.8839285714285714, "no_speech_prob": 0.00020759399922098964}, {"id": 378, "seek": 163344, "start": 1639.44, "end": 1643.44, "text": " So, we have two parameters, the word that we want to filter out, and from which field", "tokens": [407, 11, 321, 362, 732, 9834, 11, 264, 1349, 300, 321, 528, 281, 6608, 484, 11, 293, 490, 597, 2519], "temperature": 0.0, "avg_logprob": -0.07669233161712362, "compression_ratio": 1.8839285714285714, "no_speech_prob": 0.00020759399922098964}, {"id": 379, "seek": 163344, "start": 1643.44, "end": 1646.44, "text": " of the document we want to filter it out.", "tokens": [295, 264, 4166, 321, 528, 281, 6608, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.07669233161712362, "compression_ratio": 1.8839285714285714, "no_speech_prob": 0.00020759399922098964}, {"id": 380, "seek": 163344, "start": 1646.44, "end": 1653.44, "text": " Then we create a map of processors, and in that map we put the filter word processor", "tokens": [1396, 321, 1884, 257, 4471, 295, 27751, 11, 293, 294, 300, 4471, 321, 829, 264, 6608, 1349, 15321], "temperature": 0.0, "avg_logprob": -0.07669233161712362, "compression_ratio": 1.8839285714285714, "no_speech_prob": 0.00020759399922098964}, {"id": 381, "seek": 163344, "start": 1653.44, "end": 1656.44, "text": " that we create from this class and return it.", "tokens": [300, 321, 1884, 490, 341, 1508, 293, 2736, 309, 13], "temperature": 0.0, "avg_logprob": -0.07669233161712362, "compression_ratio": 1.8839285714285714, "no_speech_prob": 0.00020759399922098964}, {"id": 382, "seek": 163344, "start": 1656.44, "end": 1660.44, "text": " You can also have multiple processors defined in that plugin.", "tokens": [509, 393, 611, 362, 3866, 27751, 7642, 294, 300, 23407, 13], "temperature": 0.0, "avg_logprob": -0.07669233161712362, "compression_ratio": 1.8839285714285714, "no_speech_prob": 0.00020759399922098964}, {"id": 383, "seek": 166044, "start": 1660.44, "end": 1664.44, "text": " Now, what does the filter word processor look like?", "tokens": [823, 11, 437, 775, 264, 6608, 1349, 15321, 574, 411, 30], "temperature": 0.0, "avg_logprob": -0.07131506337059869, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.00025208364240825176}, {"id": 384, "seek": 166044, "start": 1664.44, "end": 1668.44, "text": " The filter word processor extends abstract processor from elastic search.", "tokens": [440, 6608, 1349, 15321, 26448, 12649, 15321, 490, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.07131506337059869, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.00025208364240825176}, {"id": 385, "seek": 166044, "start": 1668.44, "end": 1671.44, "text": " It, again, comes from the core class of elastic search.", "tokens": [467, 11, 797, 11, 1487, 490, 264, 4965, 1508, 295, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.07131506337059869, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.00025208364240825176}, {"id": 386, "seek": 166044, "start": 1671.44, "end": 1673.44, "text": " And we have an execute method.", "tokens": [400, 321, 362, 364, 14483, 3170, 13], "temperature": 0.0, "avg_logprob": -0.07131506337059869, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.00025208364240825176}, {"id": 387, "seek": 166044, "start": 1673.44, "end": 1677.44, "text": " In the execute method, we get the document that we want to index.", "tokens": [682, 264, 14483, 3170, 11, 321, 483, 264, 4166, 300, 321, 528, 281, 8186, 13], "temperature": 0.0, "avg_logprob": -0.07131506337059869, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.00025208364240825176}, {"id": 388, "seek": 166044, "start": 1677.44, "end": 1678.44, "text": " This is the ingest document.", "tokens": [639, 307, 264, 3957, 377, 4166, 13], "temperature": 0.0, "avg_logprob": -0.07131506337059869, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.00025208364240825176}, {"id": 389, "seek": 166044, "start": 1678.44, "end": 1683.44, "text": " We get the value from the particular field that we want to filter out, and then we replace", "tokens": [492, 483, 264, 2158, 490, 264, 1729, 2519, 300, 321, 528, 281, 6608, 484, 11, 293, 550, 321, 7406], "temperature": 0.0, "avg_logprob": -0.07131506337059869, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.00025208364240825176}, {"id": 390, "seek": 166044, "start": 1683.44, "end": 1685.44, "text": " that value with the empty string.", "tokens": [300, 2158, 365, 264, 6707, 6798, 13], "temperature": 0.0, "avg_logprob": -0.07131506337059869, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.00025208364240825176}, {"id": 391, "seek": 168544, "start": 1685.44, "end": 1690.44, "text": " And then we set back the value on top of that field and return the document.", "tokens": [400, 550, 321, 992, 646, 264, 2158, 322, 1192, 295, 300, 2519, 293, 2736, 264, 4166, 13], "temperature": 0.0, "avg_logprob": -0.07051485618658826, "compression_ratio": 1.7137546468401488, "no_speech_prob": 0.00023352708376478404}, {"id": 392, "seek": 168544, "start": 1690.44, "end": 1694.44, "text": " This, when you index a document and you specify that ingest processor,", "tokens": [639, 11, 562, 291, 8186, 257, 4166, 293, 291, 16500, 300, 3957, 377, 15321, 11], "temperature": 0.0, "avg_logprob": -0.07051485618658826, "compression_ratio": 1.7137546468401488, "no_speech_prob": 0.00023352708376478404}, {"id": 393, "seek": 168544, "start": 1694.44, "end": 1698.44, "text": " applies the filtering on that document before it gets indexed into elastic search.", "tokens": [13165, 264, 30822, 322, 300, 4166, 949, 309, 2170, 8186, 292, 666, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.07051485618658826, "compression_ratio": 1.7137546468401488, "no_speech_prob": 0.00023352708376478404}, {"id": 394, "seek": 168544, "start": 1698.44, "end": 1702.44, "text": " Now, those two classes, if you want to build a plugin, you also need to supply some simple", "tokens": [823, 11, 729, 732, 5359, 11, 498, 291, 528, 281, 1322, 257, 23407, 11, 291, 611, 643, 281, 5847, 512, 2199], "temperature": 0.0, "avg_logprob": -0.07051485618658826, "compression_ratio": 1.7137546468401488, "no_speech_prob": 0.00023352708376478404}, {"id": 395, "seek": 168544, "start": 1702.44, "end": 1708.44, "text": " plugin metadata, then build it, for example, with Maven or with Gradle,", "tokens": [23407, 26603, 11, 550, 1322, 309, 11, 337, 1365, 11, 365, 4042, 553, 420, 365, 16710, 306, 11], "temperature": 0.0, "avg_logprob": -0.07051485618658826, "compression_ratio": 1.7137546468401488, "no_speech_prob": 0.00023352708376478404}, {"id": 396, "seek": 168544, "start": 1708.44, "end": 1711.44, "text": " and then you can install it with the elastic search plugin utility.", "tokens": [293, 550, 291, 393, 3625, 309, 365, 264, 17115, 3164, 23407, 14877, 13], "temperature": 0.0, "avg_logprob": -0.07051485618658826, "compression_ratio": 1.7137546468401488, "no_speech_prob": 0.00023352708376478404}, {"id": 397, "seek": 171144, "start": 1711.44, "end": 1717.44, "text": " And in that manner, you can build any plugin you would like for elastic search.", "tokens": [400, 294, 300, 9060, 11, 291, 393, 1322, 604, 23407, 291, 576, 411, 337, 17115, 3164, 13], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 398, "seek": 171144, "start": 1717.44, "end": 1721.44, "text": " And since we are running out of time, I'm not sure if we have some time for one", "tokens": [400, 1670, 321, 366, 2614, 484, 295, 565, 11, 286, 478, 406, 988, 498, 321, 362, 512, 565, 337, 472], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 399, "seek": 171144, "start": 1721.44, "end": 1722.44, "text": " or two questions, maybe.", "tokens": [420, 732, 1651, 11, 1310, 13], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 400, "seek": 171144, "start": 1722.44, "end": 1730.44, "text": " Do you have time for?", "tokens": [1144, 291, 362, 565, 337, 30], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 401, "seek": 171144, "start": 1730.44, "end": 1731.44, "text": " Yes, of course.", "tokens": [1079, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 402, "seek": 171144, "start": 1731.44, "end": 1732.44, "text": " Okay, so if anybody?", "tokens": [1033, 11, 370, 498, 4472, 30], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 403, "seek": 171144, "start": 1732.44, "end": 1733.44, "text": " Yeah?", "tokens": [865, 30], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 404, "seek": 171144, "start": 1733.44, "end": 1735.44, "text": " Hey, thanks for your insights.", "tokens": [1911, 11, 3231, 337, 428, 14310, 13], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 405, "seek": 171144, "start": 1735.44, "end": 1739.44, "text": " We saw how too many cats can go out and fall into the pool.", "tokens": [492, 1866, 577, 886, 867, 11111, 393, 352, 484, 293, 2100, 666, 264, 7005, 13], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 406, "seek": 171144, "start": 1739.44, "end": 1740.44, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2949742387842249, "compression_ratio": 1.4978354978354977, "no_speech_prob": 0.0007154957856982946}, {"id": 407, "seek": 174044, "start": 1740.44, "end": 1741.44, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.18628240732046275, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0011983842123299837}, {"id": 408, "seek": 174044, "start": 1741.44, "end": 1746.44, "text": " I was curious, how does one know how many cars are going to be in charge?", "tokens": [286, 390, 6369, 11, 577, 775, 472, 458, 577, 867, 5163, 366, 516, 281, 312, 294, 4602, 30], "temperature": 0.0, "avg_logprob": -0.18628240732046275, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0011983842123299837}, {"id": 409, "seek": 174044, "start": 1746.44, "end": 1752.44, "text": " Well, I would say it depends on upfront estimation of how much data do you expect to put in that", "tokens": [1042, 11, 286, 576, 584, 309, 5946, 322, 30264, 35701, 295, 577, 709, 1412, 360, 291, 2066, 281, 829, 294, 300], "temperature": 0.0, "avg_logprob": -0.18628240732046275, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0011983842123299837}, {"id": 410, "seek": 174044, "start": 1752.44, "end": 1753.44, "text": " index.", "tokens": [8186, 13], "temperature": 0.0, "avg_logprob": -0.18628240732046275, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0011983842123299837}, {"id": 411, "seek": 174044, "start": 1753.44, "end": 1757.44, "text": " So we need to do an upfront finding, okay, in the first phase of my project,", "tokens": [407, 321, 643, 281, 360, 364, 30264, 5006, 11, 1392, 11, 294, 264, 700, 5574, 295, 452, 1716, 11], "temperature": 0.0, "avg_logprob": -0.18628240732046275, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0011983842123299837}, {"id": 412, "seek": 174044, "start": 1757.44, "end": 1761.44, "text": " how many, let's say, gigabytes of data I would have.", "tokens": [577, 867, 11, 718, 311, 584, 11, 42741, 295, 1412, 286, 576, 362, 13], "temperature": 0.0, "avg_logprob": -0.18628240732046275, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0011983842123299837}, {"id": 413, "seek": 174044, "start": 1761.44, "end": 1765.44, "text": " And based on that, you determine how many initial set of shots do you put,", "tokens": [400, 2361, 322, 300, 11, 291, 6997, 577, 867, 5883, 992, 295, 8305, 360, 291, 829, 11], "temperature": 0.0, "avg_logprob": -0.18628240732046275, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0011983842123299837}, {"id": 414, "seek": 174044, "start": 1765.44, "end": 1769.44, "text": " and if those shots still have a lot of data, then you consider partitioning the index.", "tokens": [293, 498, 729, 8305, 920, 362, 257, 688, 295, 1412, 11, 550, 291, 1949, 24808, 278, 264, 8186, 13], "temperature": 0.0, "avg_logprob": -0.18628240732046275, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0011983842123299837}, {"id": 415, "seek": 176944, "start": 1769.44, "end": 1774.44, "text": " And it's a matter of upfront planning to determine that.", "tokens": [400, 309, 311, 257, 1871, 295, 30264, 5038, 281, 6997, 300, 13], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 416, "seek": 176944, "start": 1774.44, "end": 1775.44, "text": " Okay?", "tokens": [1033, 30], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 417, "seek": 176944, "start": 1775.44, "end": 1776.44, "text": " Yeah?", "tokens": [865, 30], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 418, "seek": 176944, "start": 1776.44, "end": 1781.44, "text": " What is the structure used for store indexes and data?", "tokens": [708, 307, 264, 3877, 1143, 337, 3531, 8186, 279, 293, 1412, 30], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 419, "seek": 176944, "start": 1781.44, "end": 1782.44, "text": " It's inverted index.", "tokens": [467, 311, 38969, 8186, 13], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 420, "seek": 176944, "start": 1782.44, "end": 1783.44, "text": " This is the data structure.", "tokens": [639, 307, 264, 1412, 3877, 13], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 421, "seek": 176944, "start": 1783.44, "end": 1784.44, "text": " Yeah?", "tokens": [865, 30], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 422, "seek": 176944, "start": 1784.44, "end": 1785.44, "text": " Inverted index.", "tokens": [682, 18537, 8186, 13], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 423, "seek": 176944, "start": 1785.44, "end": 1786.44, "text": " Inverted index.", "tokens": [682, 18537, 8186, 13], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 424, "seek": 176944, "start": 1786.44, "end": 1791.44, "text": " It's just called an inverted index because it's an app between terms,", "tokens": [467, 311, 445, 1219, 364, 38969, 8186, 570, 309, 311, 364, 724, 1296, 2115, 11], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 425, "seek": 176944, "start": 1791.44, "end": 1796.44, "text": " and if for each term you have a pointer to the document that contains that term.", "tokens": [293, 498, 337, 1184, 1433, 291, 362, 257, 23918, 281, 264, 4166, 300, 8306, 300, 1433, 13], "temperature": 0.0, "avg_logprob": -0.20880819048200336, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.001495047123171389}, {"id": 426, "seek": 179644, "start": 1796.44, "end": 1799.44, "text": " So it's called inverted index.", "tokens": [50364, 407, 309, 311, 1219, 38969, 8186, 13, 50514], "temperature": 0.0, "avg_logprob": -0.18804417848587035, "compression_ratio": 0.8823529411764706, "no_speech_prob": 0.001418326050043106}], "language": "en"}