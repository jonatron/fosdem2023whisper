{"text": " Okay, our next speaker is going to talk about something we all used in Go, which is strings. If you didn't ever use it in Go, what are you doing here? So let's give a round of applause for Matej. Thank you, everyone. Thank you. Excited to be here, excited to see so many faces, excited to speak first time at the FOSDEM, also a bit intimidating, but hopefully I can show you a thing or two about string optimization in Go. About me, my name is Matej Gera. I work as a software engineer at a company called Coreologics, where we're building an observability platform. Apart from that, I'm active in different open source communities, mostly within the Cloud Native Computing Foundation, specifically in the observability area. I work a lot with metrics, I'm a maintainer of the TANAS project, which I will also talk a bit about during my presentation. And apart from that, I contribute to a couple different projects, most interestingly, Open Telemetry. And yeah, these are my handles. I'm not that active on social media, best is to reach me on the GitHub issues directly or PRs, and let's get into it. So if anything else, I'd like you to take at least three things today from this presentation. So first of all, I'd like you to understand how strings work behind the scenes in Go. This might be old news for many people who are more experienced with Go, or might be a new knowledge for newbies. But I want to set kind of a common ground from which we can talk about the optimization. Secondly, I want to tell you about the use cases in context of which I have been thinking about string optimization and where I think the presented strategies can be useful. And lastly, I want to tell you about the actual optimization strategies and show some examples of how they can be applied or where they have been applied. I won't be talking today much about stack versus heap, although a lot of this has to do with memory. For the presentation, I kind of assume we'll be talking more about the heap and kind of a long-term storage of strings in memory, also only going into encoding or related types like runes and charts, although it's all kind of related, but it's outside of the scope for today. So let me first tell you what kind of brought me to this topic, what was the inspiration behind this talk. As I already said, I worked primarily in the observability landscape with metrics and over the past almost two years, I was working a lot on the Thanos project, which I mentioned and which you can, for simplicity here, imagine as a distributed database for storing time series. And with these goals, it's intended to store millions of time series, even up to or more than billion series, we have heard also about deployments like that. And as I was working with Thanos and learning about these various aspects and components, one particular issue that has been standing out to me was the amount of memory needed for certain Thanos components to operate. And this is partly due to the fact that the time series data is stored in memory in a time series database. And this is where I decided to focus my attention, where I started to explore what are some possible avenues where we could optimize the performance here. The big role here was played by doing this in a data-driven way. So I started looking at different data points from Thanos, like metrics, profiles, benchmarks. And this small side note, because I considered data-driven performance optimization to be the most important when you're improving efficiency of your program. So I don't want to diverge here, but I highly recommend for you to check out a talk by Partik Plotka, who I think is in the room here. So he's talking a couple of thoughts after me, who is kind of dedicating a lot of his time into this data-driven approach to efficiency in the ecosystem. I don't have it on the slide, but also the presentation that's after me, that has to do with squeezing go functions, it seems interesting. So a lot of optimization talks today, which I love to see. And he might also ask why string-specific, what makes them so interesting or so optimization-worthy. And although I've been looking at Thanos for some time, something clicked after I've seen this particular image at the different presentation. So this was presentation from Brian Borum, I know it should be also somewhere around FOSDEM, who is working on a kind of a neighboring project called Prometheus, which is a time series database on which Thanos is built. So if Thanos is kind of a distributed version of Prometheus, we reuse a lot of the code from Prometheus and also the actual time series database code. So he shows, based on the profile and on the icicle graph that you see here, that the labels take most of the memory in Prometheus, and that was around one-third. And when I thought about it, the result was rather surprising to me, because the labels of the time series, we could think of them as some kind of metadata or some kind of contextual data about the actual data points, about the samples, as we call them, and these were taking up more spaces than those actual data points, those actual samples themselves. So there's been a lot of thought and work put into optimization and compression of the samples of the actual time series data, but Brian's finding indicated that there can be more, can be squeezed out of labels. And what are actually labels? Labels are key value pairs attached to a given time series to kind of characterize it. So in principle, they are nothing more than pairs of strings. So this is what brought me in the end to the strings. And it inspired me to talk about this topic to a large audience. I thought it might be useful to look at this from kind of a more general perspective, even though we're dealing with this problem in a limited space of observability, I think it can be also, some learnings from this can be gained and used also in different, in other types of programs. So first let's lay foundations to our talk by taking a look at what string actually is in Go. So most of you probably are familiar with different properties of strings. They are immutable. They can be converted easily into slides of bytes, can be concatenated, sliced, et cetera, et cetera. However, talking about the qualities of strings does not answer the question what strings really are. And if you look at the source code of Go, you'll see that the strings are actually represented by the string struct struct. So strings are structs, shocking, right? You can also get the runtime representation of this from the Reflect package, which contains the string header type. So based on these two types, we see that the string consists of a pointer to the actual string data in the memory, an integer which gives information about the size of the string. When Go creates a string, it allocates storage corresponding to the provided string size and then sets the string content as a slice of bytes. As you've seen, the string data is stored as a contingent slice of bytes memory. The size of the strings stays the same during its lifetime, since, as I mentioned previously, the string is immutable. And this also means that the size and the capacity of the backing slice of bytes stays the same. When you put this all together, the total size of the string will consist of the overhead of the string header, which is equal to 16 bytes, and I show in a bit why, and the byte length of the string. We can break this down on this small example of the string I created with FOSDEM, space, waving hand emoji. So this is just a snippet. I don't think it would compile this code, but for brevity, I decided to show these three small lines. And by calling the size method on the string type from the Reflect package, you would see it return number 16. Don't be fooled. The size method returns only the information of the size of the type, not size of the whole string. Therefore, it correctly tells us it's 16 bytes, 18 bytes due to pointer pointing to the string in memory, and 8 bytes for keeping the string length information. To get the size of the actual string data, we have to use the good old length method. This tells us it's 11 bytes. This is the string literal. Here is UTF-8 encoded. We count one byte per each letter and space, and we need actually four bytes to encode the waving hand emoji. And this brings our total to 27 bytes. Interestingly for such a short string, the overhead of storing it is bigger than the string data itself. It's also important to realize what happens if we declare a new string variable that is copying an existing string. In this case, co-creates what we can consider a shallow copy, meaning the data the string refers to is shared between the variables. Let's break it down again on the example of our FOSDEM string. So we declare a new string literal, FOSDEM waving hand emoji, and then create a new STR or new string variable, and set it to value equal to string or STR. What happens behind the scenes? If you would look at the values, pointer of each of the strings, you would see different addresses. We're making it obvious that these are two different strings strictly speaking, but looking at their headers, we would see identical information, same pointer to string data, and same length. But because... Excuse me, sir, can we turn the light on the front off first? I cannot. Sorry. Okay. Sorry. Yeah, it's a bit light, right, sorry. But anyway, so these are two different strings strictly speaking, and looking at the header information, we would see that they point to same string data and have same length. Because they are two different strings, we need to be mindful of the fact that the new STR comes with a brand new string header. So the bottom line is, when we do this copying, there is, again, even the data is shared, the overhead of 16 bytes is still there. So I briefly talked about my inspiration for this talk, but I also wanted to expand a bit on the context of the problems, where I think the string optimization strategies can be useful. I think in general, many programs with characteristics of in-memory stores may face performance issue. I will talk about in this slide such programs. I already mentioned numerous times, the time series database, DNS resolvers, or any other kind of key value store, where we come with an assumption that these are some long running programs, and over the runtime of the program, we will keep the number of strings we will keep accumulating. So we can be talking potentially billions of strings. There's also potential for repetitions of strings, since many of these stored values may repeat themselves. So for example, if we associate each of our entries with a label denoting which cluster they belong to, we are guaranteed to have repeated values, since we have a finite and often small amount of clusters. So the string cluster will be stored as many times as many entries there are in our database. There are also certain caveats when it comes to handling of incoming data. Data will often come in a form of request through HTTP or GRPC or any other protocol, and usually we handle this data in our program by un-martialing them into a struct, and then we might want to store some information, some string from this struct in the memory for future use. However, the side effect of this is that the whole struct will be prevented from being garbage collected, because as long as the string or as a matter of fact any other field from a struct is being referenced by our database in memory, the garbage collection won't kick in and eventually will lead to bloats in the memory consumption. I think the second kind of different type of programs where string optimization can be useful are kind of one of data processing situations as opposed to the long-running programs. So we can take an example of handling some large JSON file, perhaps it can be some data set from a study or a health data, which I think were some good examples I've seen out in the wild, and such processing will require a larger amount of memory to decode the data during processing. So even though we might be processing same strings that repeat themselves over and over again such as the keys in the JSON document, we're having to allocate such strings in new each time. So now that we have a better understanding of the problem zones, let's look at the actual optimization strategies. So the first strategy is related to the issue I mentioned a couple of slides before where we are wasting memory by keeping whole structs in memory when we only need part of the struct that is represented by the string. So what we want to do here is to have a mechanism that will allow us to quote unquote detach the string from the struct so that the rest of the struct can be garbage collected. Previously this was also possible to achieve with some unsafe manipulation of strings, but since Go 118 there's a new method called clone in the string standard library that makes it quite straightforward. Though clone creates a new fresh copy of the string, this decouples the string from the struct, meaning the struct can be garbage collected in the long term and will retain only the new copy of the string. So remember previously I showed that when we copy strings we create shallow copies, here we want to achieve the opposite, we want to truly copy the string and create a fresh copy of the underlying string data so the original string can be garbage collected together with the struct it's part of, so this we can refer to as deep copying. The next most interesting and I'd say one of the most widely used strategies in software in general is string interning. String interning is a technique which makes it possible to store only a single copy of each distinct string and subsequently we keep referencing the same underlying string in the memory. This concept is somewhat more common in other languages such as Java or Python but can be implemented effortlessly in Go as well and there are even some ready-made solutions out in the open that you can use. So at Simplus you could achieve this by having a simple map string string and you can keep the references to the string in this map which we can call our interning map or cache or anything like that. First complication comes with the concurrency, right, because we need a mechanism to prevent concurrent write and read to our interning map so obvious choice would be to use mutex which have our incurred performance penalty but so be it. Our concurrency save map version from the sync standard library. The second complication or the noteworthy fact is that with each new reference string we are incurring the 16 bytes overhead as I explained a couple of slides back. So even though we're saving on the actual string data, it's not, we're still incurring the overhead so with millions of strings, 16 bytes for every string, it's a non-trivial amount. Third complication comes from the unknown lifetime of the string in our interning map. At some point in the lifetime of the program there might be no more references to a particular string so it can be safely dropped. But how to know when these conditions are met? Ideally we don't want to be keeping unused strings as in an extreme case this can be a denial of service vector leading to exhaustion of memory if we allow the map to grow unbounded. One option could be to periodically clear the map or give the entries a certain time to live so after a given period the map or the given entries are dropped from the map and if a string reappears after such deletion we simply create the entry in the interning map so kind of like a cache and naturally this can lead to some unnecessary churning and unnecessary allocations because we don't know exactly which strings are no longer needed or referenced but we might be still dropping them. One and more elaborate way to do this is to keep counting the number of references of the used strings and this naturally requires a more eloquent and complex implementation but you can see here I linked a work done in the Prometheus project writing is a good example of how this can be implemented with counting the references. We can take this even to the next level as I recently learned there is an implementation of an interning library that is capable of automatically dropping unused references. The go4.org intern library is capable of doing this thanks to somewhat controversial concept of the finalizers in the go runtime. Finalizers set very plainly make it possible to attach a function that will be called on a variable that is deemed to be garbage collection ready by the garbage collector. At that point this library checks the sentinel boolean on the reference value and if it finds this is the last reference to that value it drops it from a map. The library also cleverly boxes the string header down to a single pointer which brings the overhead down to 8 bytes instead of 16. So as fascinating as this implementation is to me it makes uses of some potentially unsafe code behavior hence the dark arts reference in the slide title. However the library is deemed stable and major enough and has been created by some well-known names in the go community. So if you're interested I encourage you to study and look at the code it's just one file but it's quite interesting and you're sure to learn a thing or two about some less known parts of go. And as an example I recently tried this library in the last blood point in the TANOS project again I linked you the PR with the usage with the implementation which I think is rather straightforward. And we ran some synthetic benchmarks on this version in turning on this was the result. On the left side you can see probably not very clearly unfortunately but there is a graph showing metrics for both reported by the go runtime, how many bytes we have in the heap and metrics reported by the container itself and you can see the differences between the green and yellow line and the blue and red line so it came up to roughly two to three gigabytes improvement per instance so this is averaged per I think across six or nine instances so per instance this was around two to three gigabytes so we can count overall improvement around ten to twelve gigabytes but more interestingly on the right side of the slide there is another graph to kind of confirm that the interning is doing something that it's working then we can see we're following again a metric reported by the go runtime and we're looking at the number of objects held in the memory so we can see that it dropped almost by health when we look at the average. Finally there's a string interning with a slightly different flavor I would say which I refer to a string interning with symbol tables and in this alternative instead of keeping a reference string we replace it with another referring symbol such as for example an integer so the integer one will correspond to string apple or string integer two will correspond to string banana and so on and this can be beneficial with scenarios with a lot of duplicated strings again this brings me to my home field and to the time series databases where there is generally a high probability of the labels so also the strings being repeated and especially when such strings are being sent over the wire so instead of sending all the duplicated strings we can send a symbol table in their place and we can replace the strings with the references in this table so where this idea come from or where I got inspired for this was also in Thanos but this was by one of my fellow maintainers so you can look at that PR who implemented this for data series being sent over the network between Thanos components so instead of sending all the long and unduplicated label keys and values so instead of sending all of these strings we build a symbol table that we send together with the duplicated label data that includes that contains only references instead of the strings so that all we have to do on the other side once we receive the data is to replace the references by the actual strings based on the symbol table which saves us on one hand the cost of the network since the requests are smaller and also the allocations once we're dealing with the data on the receiving side. Lastly you could try putting all of the strings into one big structure into one big string and this can be useful to decrease the total overhead of the strings as this eliminates the already mentioned overhead of the string header so yeah since this is always 16 bytes plus the byte length of the string which consists which creates the size of the string by putting all the strings into the one we can effectively decrease the overhead of those string headers. So of course this is not without added complexity because now we have to deal with how to look up those sub strings or those smaller strings within the bigger structure and so you need a mechanism because you cannot simply look them up in a map or symbol table and obviously another already mentioned complication such as concurrent access you also have to deal with this and I think particularly interesting attempt at this is going on in the Prometheus project which again this is done by Brian Boren who I mentioned in the previous slides so if you're interested feel free to check out this PR. So I will conclude with a few words of caution so I have shown you some optimization techniques that I found particularly interesting when I was doing my research but let's not be naive these are not magic ones that will make your program suddenly work faster and with fewer resources this is still a balancing exercise so many of the presented techniques can save memory but will actually increase the time it takes to retrieve a string so when I mean optimization this is mostly in a situation where we want to decrease expensive memory footprint of our application while sacrificing a bit more CPU a tradeoff that I believe is reasonable in such setting. Also not making any concrete claims about performance improvements of various techniques as you have seen and I think this nicely ties into the introduction of my talk where I talked about the need of data data driven optimization so I believe there's still more data points needed to show how well these techniques work in practice how well they can work in your specific use case how they compare with each other when it comes to performance and whether there are some other real world implications or maybe properties of go or compiler or the runtime that might not render them useful in practice or the performance gain might be negligible so just to say that your mileage might vary but I think these ideas are worth exploring and can be interesting and that is all from my side thank you for your attention. Also included a couple more resources for those who are interested you can find the slides in the PENTA bar.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.24, "text": " Okay, our next speaker is going to talk about something we all used in Go, which is strings.", "tokens": [50364, 1033, 11, 527, 958, 8145, 307, 516, 281, 751, 466, 746, 321, 439, 1143, 294, 1037, 11, 597, 307, 13985, 13, 51026], "temperature": 0.0, "avg_logprob": -0.220269045986972, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.48393863439559937}, {"id": 1, "seek": 0, "start": 13.24, "end": 16.68, "text": " If you didn't ever use it in Go, what are you doing here?", "tokens": [51026, 759, 291, 994, 380, 1562, 764, 309, 294, 1037, 11, 437, 366, 291, 884, 510, 30, 51198], "temperature": 0.0, "avg_logprob": -0.220269045986972, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.48393863439559937}, {"id": 2, "seek": 0, "start": 16.68, "end": 23.6, "text": " So let's give a round of applause for Matej.", "tokens": [51198, 407, 718, 311, 976, 257, 3098, 295, 9969, 337, 27594, 73, 13, 51544], "temperature": 0.0, "avg_logprob": -0.220269045986972, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.48393863439559937}, {"id": 3, "seek": 0, "start": 23.6, "end": 24.6, "text": " Thank you, everyone.", "tokens": [51544, 1044, 291, 11, 1518, 13, 51594], "temperature": 0.0, "avg_logprob": -0.220269045986972, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.48393863439559937}, {"id": 4, "seek": 0, "start": 24.6, "end": 25.6, "text": " Thank you.", "tokens": [51594, 1044, 291, 13, 51644], "temperature": 0.0, "avg_logprob": -0.220269045986972, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.48393863439559937}, {"id": 5, "seek": 0, "start": 25.6, "end": 29.8, "text": " Excited to be here, excited to see so many faces, excited to speak first time at the", "tokens": [51644, 9368, 1226, 281, 312, 510, 11, 2919, 281, 536, 370, 867, 8475, 11, 2919, 281, 1710, 700, 565, 412, 264, 51854], "temperature": 0.0, "avg_logprob": -0.220269045986972, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.48393863439559937}, {"id": 6, "seek": 2980, "start": 29.8, "end": 35.72, "text": " FOSDEM, also a bit intimidating, but hopefully I can show you a thing or two about string", "tokens": [50364, 479, 4367, 35, 6683, 11, 611, 257, 857, 29714, 11, 457, 4696, 286, 393, 855, 291, 257, 551, 420, 732, 466, 6798, 50660], "temperature": 0.0, "avg_logprob": -0.24507982163202194, "compression_ratio": 1.5036496350364963, "no_speech_prob": 0.07650316506624222}, {"id": 7, "seek": 2980, "start": 35.72, "end": 38.92, "text": " optimization in Go.", "tokens": [50660, 19618, 294, 1037, 13, 50820], "temperature": 0.0, "avg_logprob": -0.24507982163202194, "compression_ratio": 1.5036496350364963, "no_speech_prob": 0.07650316506624222}, {"id": 8, "seek": 2980, "start": 38.92, "end": 41.0, "text": " About me, my name is Matej Gera.", "tokens": [50820, 7769, 385, 11, 452, 1315, 307, 27594, 73, 460, 1663, 13, 50924], "temperature": 0.0, "avg_logprob": -0.24507982163202194, "compression_ratio": 1.5036496350364963, "no_speech_prob": 0.07650316506624222}, {"id": 9, "seek": 2980, "start": 41.0, "end": 45.0, "text": " I work as a software engineer at a company called Coreologics, where we're building an", "tokens": [50924, 286, 589, 382, 257, 4722, 11403, 412, 257, 2237, 1219, 14798, 1132, 1167, 11, 689, 321, 434, 2390, 364, 51124], "temperature": 0.0, "avg_logprob": -0.24507982163202194, "compression_ratio": 1.5036496350364963, "no_speech_prob": 0.07650316506624222}, {"id": 10, "seek": 2980, "start": 45.0, "end": 46.8, "text": " observability platform.", "tokens": [51124, 9951, 2310, 3663, 13, 51214], "temperature": 0.0, "avg_logprob": -0.24507982163202194, "compression_ratio": 1.5036496350364963, "no_speech_prob": 0.07650316506624222}, {"id": 11, "seek": 2980, "start": 46.8, "end": 52.0, "text": " Apart from that, I'm active in different open source communities, mostly within the Cloud", "tokens": [51214, 24111, 490, 300, 11, 286, 478, 4967, 294, 819, 1269, 4009, 4456, 11, 5240, 1951, 264, 8061, 51474], "temperature": 0.0, "avg_logprob": -0.24507982163202194, "compression_ratio": 1.5036496350364963, "no_speech_prob": 0.07650316506624222}, {"id": 12, "seek": 2980, "start": 52.0, "end": 58.16, "text": " Native Computing Foundation, specifically in the observability area.", "tokens": [51474, 15093, 37804, 278, 10335, 11, 4682, 294, 264, 9951, 2310, 1859, 13, 51782], "temperature": 0.0, "avg_logprob": -0.24507982163202194, "compression_ratio": 1.5036496350364963, "no_speech_prob": 0.07650316506624222}, {"id": 13, "seek": 5816, "start": 58.16, "end": 63.279999999999994, "text": " I work a lot with metrics, I'm a maintainer of the TANAS project, which I will also talk", "tokens": [50364, 286, 589, 257, 688, 365, 16367, 11, 286, 478, 257, 6909, 260, 295, 264, 314, 1770, 3160, 1716, 11, 597, 286, 486, 611, 751, 50620], "temperature": 0.0, "avg_logprob": -0.21877202447855248, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.024298937991261482}, {"id": 14, "seek": 5816, "start": 63.279999999999994, "end": 66.47999999999999, "text": " a bit about during my presentation.", "tokens": [50620, 257, 857, 466, 1830, 452, 5860, 13, 50780], "temperature": 0.0, "avg_logprob": -0.21877202447855248, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.024298937991261482}, {"id": 15, "seek": 5816, "start": 66.47999999999999, "end": 72.0, "text": " And apart from that, I contribute to a couple different projects, most interestingly, Open", "tokens": [50780, 400, 4936, 490, 300, 11, 286, 10586, 281, 257, 1916, 819, 4455, 11, 881, 25873, 11, 7238, 51056], "temperature": 0.0, "avg_logprob": -0.21877202447855248, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.024298937991261482}, {"id": 16, "seek": 5816, "start": 72.0, "end": 73.8, "text": " Telemetry.", "tokens": [51056, 14889, 5537, 627, 13, 51146], "temperature": 0.0, "avg_logprob": -0.21877202447855248, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.024298937991261482}, {"id": 17, "seek": 5816, "start": 73.8, "end": 75.64, "text": " And yeah, these are my handles.", "tokens": [51146, 400, 1338, 11, 613, 366, 452, 18722, 13, 51238], "temperature": 0.0, "avg_logprob": -0.21877202447855248, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.024298937991261482}, {"id": 18, "seek": 5816, "start": 75.64, "end": 81.36, "text": " I'm not that active on social media, best is to reach me on the GitHub issues directly", "tokens": [51238, 286, 478, 406, 300, 4967, 322, 2093, 3021, 11, 1151, 307, 281, 2524, 385, 322, 264, 23331, 2663, 3838, 51524], "temperature": 0.0, "avg_logprob": -0.21877202447855248, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.024298937991261482}, {"id": 19, "seek": 5816, "start": 81.36, "end": 85.08, "text": " or PRs, and let's get into it.", "tokens": [51524, 420, 11568, 82, 11, 293, 718, 311, 483, 666, 309, 13, 51710], "temperature": 0.0, "avg_logprob": -0.21877202447855248, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.024298937991261482}, {"id": 20, "seek": 8508, "start": 85.08, "end": 92.0, "text": " So if anything else, I'd like you to take at least three things today from this presentation.", "tokens": [50364, 407, 498, 1340, 1646, 11, 286, 1116, 411, 291, 281, 747, 412, 1935, 1045, 721, 965, 490, 341, 5860, 13, 50710], "temperature": 0.0, "avg_logprob": -0.12332326173782349, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.015515170060098171}, {"id": 21, "seek": 8508, "start": 92.0, "end": 97.16, "text": " So first of all, I'd like you to understand how strings work behind the scenes in Go.", "tokens": [50710, 407, 700, 295, 439, 11, 286, 1116, 411, 291, 281, 1223, 577, 13985, 589, 2261, 264, 8026, 294, 1037, 13, 50968], "temperature": 0.0, "avg_logprob": -0.12332326173782349, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.015515170060098171}, {"id": 22, "seek": 8508, "start": 97.16, "end": 102.0, "text": " This might be old news for many people who are more experienced with Go, or might be", "tokens": [50968, 639, 1062, 312, 1331, 2583, 337, 867, 561, 567, 366, 544, 6751, 365, 1037, 11, 420, 1062, 312, 51210], "temperature": 0.0, "avg_logprob": -0.12332326173782349, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.015515170060098171}, {"id": 23, "seek": 8508, "start": 102.0, "end": 104.36, "text": " a new knowledge for newbies.", "tokens": [51210, 257, 777, 3601, 337, 777, 23177, 13, 51328], "temperature": 0.0, "avg_logprob": -0.12332326173782349, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.015515170060098171}, {"id": 24, "seek": 8508, "start": 104.36, "end": 110.32, "text": " But I want to set kind of a common ground from which we can talk about the optimization.", "tokens": [51328, 583, 286, 528, 281, 992, 733, 295, 257, 2689, 2727, 490, 597, 321, 393, 751, 466, 264, 19618, 13, 51626], "temperature": 0.0, "avg_logprob": -0.12332326173782349, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.015515170060098171}, {"id": 25, "seek": 11032, "start": 110.32, "end": 115.8, "text": " Secondly, I want to tell you about the use cases in context of which I have been thinking", "tokens": [50364, 19483, 11, 286, 528, 281, 980, 291, 466, 264, 764, 3331, 294, 4319, 295, 597, 286, 362, 668, 1953, 50638], "temperature": 0.0, "avg_logprob": -0.18977476119995118, "compression_ratio": 1.794979079497908, "no_speech_prob": 0.06160467118024826}, {"id": 26, "seek": 11032, "start": 115.8, "end": 120.16, "text": " about string optimization and where I think the presented strategies can be useful.", "tokens": [50638, 466, 6798, 19618, 293, 689, 286, 519, 264, 8212, 9029, 393, 312, 4420, 13, 50856], "temperature": 0.0, "avg_logprob": -0.18977476119995118, "compression_ratio": 1.794979079497908, "no_speech_prob": 0.06160467118024826}, {"id": 27, "seek": 11032, "start": 120.16, "end": 125.63999999999999, "text": " And lastly, I want to tell you about the actual optimization strategies and show some examples", "tokens": [50856, 400, 16386, 11, 286, 528, 281, 980, 291, 466, 264, 3539, 19618, 9029, 293, 855, 512, 5110, 51130], "temperature": 0.0, "avg_logprob": -0.18977476119995118, "compression_ratio": 1.794979079497908, "no_speech_prob": 0.06160467118024826}, {"id": 28, "seek": 11032, "start": 125.63999999999999, "end": 129.79999999999998, "text": " of how they can be applied or where they have been applied.", "tokens": [51130, 295, 577, 436, 393, 312, 6456, 420, 689, 436, 362, 668, 6456, 13, 51338], "temperature": 0.0, "avg_logprob": -0.18977476119995118, "compression_ratio": 1.794979079497908, "no_speech_prob": 0.06160467118024826}, {"id": 29, "seek": 11032, "start": 129.79999999999998, "end": 135.84, "text": " I won't be talking today much about stack versus heap, although a lot of this has to", "tokens": [51338, 286, 1582, 380, 312, 1417, 965, 709, 466, 8630, 5717, 33591, 11, 4878, 257, 688, 295, 341, 575, 281, 51640], "temperature": 0.0, "avg_logprob": -0.18977476119995118, "compression_ratio": 1.794979079497908, "no_speech_prob": 0.06160467118024826}, {"id": 30, "seek": 11032, "start": 135.84, "end": 138.2, "text": " do with memory.", "tokens": [51640, 360, 365, 4675, 13, 51758], "temperature": 0.0, "avg_logprob": -0.18977476119995118, "compression_ratio": 1.794979079497908, "no_speech_prob": 0.06160467118024826}, {"id": 31, "seek": 13820, "start": 138.2, "end": 141.79999999999998, "text": " For the presentation, I kind of assume we'll be talking more about the heap and kind of", "tokens": [50364, 1171, 264, 5860, 11, 286, 733, 295, 6552, 321, 603, 312, 1417, 544, 466, 264, 33591, 293, 733, 295, 50544], "temperature": 0.0, "avg_logprob": -0.1348571201850628, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.007871782407164574}, {"id": 32, "seek": 13820, "start": 141.79999999999998, "end": 150.67999999999998, "text": " a long-term storage of strings in memory, also only going into encoding or related types", "tokens": [50544, 257, 938, 12, 7039, 6725, 295, 13985, 294, 4675, 11, 611, 787, 516, 666, 43430, 420, 4077, 3467, 50988], "temperature": 0.0, "avg_logprob": -0.1348571201850628, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.007871782407164574}, {"id": 33, "seek": 13820, "start": 150.67999999999998, "end": 155.92, "text": " like runes and charts, although it's all kind of related, but it's outside of the scope", "tokens": [50988, 411, 1190, 279, 293, 17767, 11, 4878, 309, 311, 439, 733, 295, 4077, 11, 457, 309, 311, 2380, 295, 264, 11923, 51250], "temperature": 0.0, "avg_logprob": -0.1348571201850628, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.007871782407164574}, {"id": 34, "seek": 13820, "start": 155.92, "end": 158.0, "text": " for today.", "tokens": [51250, 337, 965, 13, 51354], "temperature": 0.0, "avg_logprob": -0.1348571201850628, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.007871782407164574}, {"id": 35, "seek": 13820, "start": 158.0, "end": 161.92, "text": " So let me first tell you what kind of brought me to this topic, what was the inspiration", "tokens": [51354, 407, 718, 385, 700, 980, 291, 437, 733, 295, 3038, 385, 281, 341, 4829, 11, 437, 390, 264, 10249, 51550], "temperature": 0.0, "avg_logprob": -0.1348571201850628, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.007871782407164574}, {"id": 36, "seek": 13820, "start": 161.92, "end": 162.92, "text": " behind this talk.", "tokens": [51550, 2261, 341, 751, 13, 51600], "temperature": 0.0, "avg_logprob": -0.1348571201850628, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.007871782407164574}, {"id": 37, "seek": 13820, "start": 162.92, "end": 167.83999999999997, "text": " As I already said, I worked primarily in the observability landscape with metrics and", "tokens": [51600, 1018, 286, 1217, 848, 11, 286, 2732, 10029, 294, 264, 9951, 2310, 9661, 365, 16367, 293, 51846], "temperature": 0.0, "avg_logprob": -0.1348571201850628, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.007871782407164574}, {"id": 38, "seek": 16784, "start": 167.88, "end": 173.52, "text": " over the past almost two years, I was working a lot on the Thanos project, which I mentioned", "tokens": [50366, 670, 264, 1791, 1920, 732, 924, 11, 286, 390, 1364, 257, 688, 322, 264, 35993, 1716, 11, 597, 286, 2835, 50648], "temperature": 0.0, "avg_logprob": -0.17777246641881259, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.05925896018743515}, {"id": 39, "seek": 16784, "start": 173.52, "end": 178.08, "text": " and which you can, for simplicity here, imagine as a distributed database for storing time", "tokens": [50648, 293, 597, 291, 393, 11, 337, 25632, 510, 11, 3811, 382, 257, 12631, 8149, 337, 26085, 565, 50876], "temperature": 0.0, "avg_logprob": -0.17777246641881259, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.05925896018743515}, {"id": 40, "seek": 16784, "start": 178.08, "end": 179.6, "text": " series.", "tokens": [50876, 2638, 13, 50952], "temperature": 0.0, "avg_logprob": -0.17777246641881259, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.05925896018743515}, {"id": 41, "seek": 16784, "start": 179.6, "end": 186.28, "text": " And with these goals, it's intended to store millions of time series, even up to or more", "tokens": [50952, 400, 365, 613, 5493, 11, 309, 311, 10226, 281, 3531, 6803, 295, 565, 2638, 11, 754, 493, 281, 420, 544, 51286], "temperature": 0.0, "avg_logprob": -0.17777246641881259, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.05925896018743515}, {"id": 42, "seek": 16784, "start": 186.28, "end": 191.4, "text": " than billion series, we have heard also about deployments like that.", "tokens": [51286, 813, 5218, 2638, 11, 321, 362, 2198, 611, 466, 7274, 1117, 411, 300, 13, 51542], "temperature": 0.0, "avg_logprob": -0.17777246641881259, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.05925896018743515}, {"id": 43, "seek": 16784, "start": 191.4, "end": 196.6, "text": " And as I was working with Thanos and learning about these various aspects and components,", "tokens": [51542, 400, 382, 286, 390, 1364, 365, 35993, 293, 2539, 466, 613, 3683, 7270, 293, 6677, 11, 51802], "temperature": 0.0, "avg_logprob": -0.17777246641881259, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.05925896018743515}, {"id": 44, "seek": 19660, "start": 196.6, "end": 200.44, "text": " one particular issue that has been standing out to me was the amount of memory needed", "tokens": [50364, 472, 1729, 2734, 300, 575, 668, 4877, 484, 281, 385, 390, 264, 2372, 295, 4675, 2978, 50556], "temperature": 0.0, "avg_logprob": -0.13896480303132133, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.012556968256831169}, {"id": 45, "seek": 19660, "start": 200.44, "end": 204.56, "text": " for certain Thanos components to operate.", "tokens": [50556, 337, 1629, 35993, 6677, 281, 9651, 13, 50762], "temperature": 0.0, "avg_logprob": -0.13896480303132133, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.012556968256831169}, {"id": 46, "seek": 19660, "start": 204.56, "end": 211.64, "text": " And this is partly due to the fact that the time series data is stored in memory in a", "tokens": [50762, 400, 341, 307, 17031, 3462, 281, 264, 1186, 300, 264, 565, 2638, 1412, 307, 12187, 294, 4675, 294, 257, 51116], "temperature": 0.0, "avg_logprob": -0.13896480303132133, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.012556968256831169}, {"id": 47, "seek": 19660, "start": 211.64, "end": 213.88, "text": " time series database.", "tokens": [51116, 565, 2638, 8149, 13, 51228], "temperature": 0.0, "avg_logprob": -0.13896480303132133, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.012556968256831169}, {"id": 48, "seek": 19660, "start": 213.88, "end": 219.44, "text": " And this is where I decided to focus my attention, where I started to explore what are some possible", "tokens": [51228, 400, 341, 307, 689, 286, 3047, 281, 1879, 452, 3202, 11, 689, 286, 1409, 281, 6839, 437, 366, 512, 1944, 51506], "temperature": 0.0, "avg_logprob": -0.13896480303132133, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.012556968256831169}, {"id": 49, "seek": 19660, "start": 219.44, "end": 224.24, "text": " avenues where we could optimize the performance here.", "tokens": [51506, 43039, 689, 321, 727, 19719, 264, 3389, 510, 13, 51746], "temperature": 0.0, "avg_logprob": -0.13896480303132133, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.012556968256831169}, {"id": 50, "seek": 22424, "start": 224.24, "end": 227.84, "text": " The big role here was played by doing this in a data-driven way.", "tokens": [50364, 440, 955, 3090, 510, 390, 3737, 538, 884, 341, 294, 257, 1412, 12, 25456, 636, 13, 50544], "temperature": 0.0, "avg_logprob": -0.2592330189932764, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.025117868557572365}, {"id": 51, "seek": 22424, "start": 227.84, "end": 234.84, "text": " So I started looking at different data points from Thanos, like metrics, profiles, benchmarks.", "tokens": [50544, 407, 286, 1409, 1237, 412, 819, 1412, 2793, 490, 35993, 11, 411, 16367, 11, 23693, 11, 43751, 13, 50894], "temperature": 0.0, "avg_logprob": -0.2592330189932764, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.025117868557572365}, {"id": 52, "seek": 22424, "start": 234.84, "end": 239.8, "text": " And this small side note, because I considered data-driven performance optimization to be", "tokens": [50894, 400, 341, 1359, 1252, 3637, 11, 570, 286, 4888, 1412, 12, 25456, 3389, 19618, 281, 312, 51142], "temperature": 0.0, "avg_logprob": -0.2592330189932764, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.025117868557572365}, {"id": 53, "seek": 22424, "start": 239.8, "end": 244.52, "text": " the most important when you're improving efficiency of your program.", "tokens": [51142, 264, 881, 1021, 562, 291, 434, 11470, 10493, 295, 428, 1461, 13, 51378], "temperature": 0.0, "avg_logprob": -0.2592330189932764, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.025117868557572365}, {"id": 54, "seek": 22424, "start": 244.52, "end": 249.04000000000002, "text": " So I don't want to diverge here, but I highly recommend for you to check out a talk by Partik", "tokens": [51378, 407, 286, 500, 380, 528, 281, 18558, 432, 510, 11, 457, 286, 5405, 2748, 337, 291, 281, 1520, 484, 257, 751, 538, 4100, 1035, 51604], "temperature": 0.0, "avg_logprob": -0.2592330189932764, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.025117868557572365}, {"id": 55, "seek": 22424, "start": 249.04000000000002, "end": 252.12, "text": " Plotka, who I think is in the room here.", "tokens": [51604, 2149, 310, 2330, 11, 567, 286, 519, 307, 294, 264, 1808, 510, 13, 51758], "temperature": 0.0, "avg_logprob": -0.2592330189932764, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.025117868557572365}, {"id": 56, "seek": 25212, "start": 252.12, "end": 257.2, "text": " So he's talking a couple of thoughts after me, who is kind of dedicating a lot of his", "tokens": [50364, 407, 415, 311, 1417, 257, 1916, 295, 4598, 934, 385, 11, 567, 307, 733, 295, 4172, 30541, 257, 688, 295, 702, 50618], "temperature": 0.0, "avg_logprob": -0.17079686281973855, "compression_ratio": 1.6865671641791045, "no_speech_prob": 0.05378288775682449}, {"id": 57, "seek": 25212, "start": 257.2, "end": 261.68, "text": " time into this data-driven approach to efficiency in the ecosystem.", "tokens": [50618, 565, 666, 341, 1412, 12, 25456, 3109, 281, 10493, 294, 264, 11311, 13, 50842], "temperature": 0.0, "avg_logprob": -0.17079686281973855, "compression_ratio": 1.6865671641791045, "no_speech_prob": 0.05378288775682449}, {"id": 58, "seek": 25212, "start": 261.68, "end": 265.8, "text": " I don't have it on the slide, but also the presentation that's after me, that has to", "tokens": [50842, 286, 500, 380, 362, 309, 322, 264, 4137, 11, 457, 611, 264, 5860, 300, 311, 934, 385, 11, 300, 575, 281, 51048], "temperature": 0.0, "avg_logprob": -0.17079686281973855, "compression_ratio": 1.6865671641791045, "no_speech_prob": 0.05378288775682449}, {"id": 59, "seek": 25212, "start": 265.8, "end": 268.64, "text": " do with squeezing go functions, it seems interesting.", "tokens": [51048, 360, 365, 36645, 352, 6828, 11, 309, 2544, 1880, 13, 51190], "temperature": 0.0, "avg_logprob": -0.17079686281973855, "compression_ratio": 1.6865671641791045, "no_speech_prob": 0.05378288775682449}, {"id": 60, "seek": 25212, "start": 268.64, "end": 274.52, "text": " So a lot of optimization talks today, which I love to see.", "tokens": [51190, 407, 257, 688, 295, 19618, 6686, 965, 11, 597, 286, 959, 281, 536, 13, 51484], "temperature": 0.0, "avg_logprob": -0.17079686281973855, "compression_ratio": 1.6865671641791045, "no_speech_prob": 0.05378288775682449}, {"id": 61, "seek": 25212, "start": 274.52, "end": 281.72, "text": " And he might also ask why string-specific, what makes them so interesting or so optimization-worthy.", "tokens": [51484, 400, 415, 1062, 611, 1029, 983, 6798, 12, 29258, 11, 437, 1669, 552, 370, 1880, 420, 370, 19618, 12, 23727, 13, 51844], "temperature": 0.0, "avg_logprob": -0.17079686281973855, "compression_ratio": 1.6865671641791045, "no_speech_prob": 0.05378288775682449}, {"id": 62, "seek": 28172, "start": 281.72, "end": 287.68, "text": " And although I've been looking at Thanos for some time, something clicked after I've", "tokens": [50364, 400, 4878, 286, 600, 668, 1237, 412, 35993, 337, 512, 565, 11, 746, 23370, 934, 286, 600, 50662], "temperature": 0.0, "avg_logprob": -0.2097259521484375, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013040979392826557}, {"id": 63, "seek": 28172, "start": 287.68, "end": 290.44000000000005, "text": " seen this particular image at the different presentation.", "tokens": [50662, 1612, 341, 1729, 3256, 412, 264, 819, 5860, 13, 50800], "temperature": 0.0, "avg_logprob": -0.2097259521484375, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013040979392826557}, {"id": 64, "seek": 28172, "start": 290.44000000000005, "end": 295.48, "text": " So this was presentation from Brian Borum, I know it should be also somewhere around", "tokens": [50800, 407, 341, 390, 5860, 490, 10765, 13739, 449, 11, 286, 458, 309, 820, 312, 611, 4079, 926, 51052], "temperature": 0.0, "avg_logprob": -0.2097259521484375, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013040979392826557}, {"id": 65, "seek": 28172, "start": 295.48, "end": 302.28000000000003, "text": " FOSDEM, who is working on a kind of a neighboring project called Prometheus, which is a time", "tokens": [51052, 479, 4367, 35, 6683, 11, 567, 307, 1364, 322, 257, 733, 295, 257, 31521, 1716, 1219, 2114, 649, 42209, 11, 597, 307, 257, 565, 51392], "temperature": 0.0, "avg_logprob": -0.2097259521484375, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013040979392826557}, {"id": 66, "seek": 28172, "start": 302.28000000000003, "end": 305.12, "text": " series database on which Thanos is built.", "tokens": [51392, 2638, 8149, 322, 597, 35993, 307, 3094, 13, 51534], "temperature": 0.0, "avg_logprob": -0.2097259521484375, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013040979392826557}, {"id": 67, "seek": 28172, "start": 305.12, "end": 310.44000000000005, "text": " So if Thanos is kind of a distributed version of Prometheus, we reuse a lot of the code", "tokens": [51534, 407, 498, 35993, 307, 733, 295, 257, 12631, 3037, 295, 2114, 649, 42209, 11, 321, 26225, 257, 688, 295, 264, 3089, 51800], "temperature": 0.0, "avg_logprob": -0.2097259521484375, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013040979392826557}, {"id": 68, "seek": 31044, "start": 310.44, "end": 316.44, "text": " from Prometheus and also the actual time series database code.", "tokens": [50364, 490, 2114, 649, 42209, 293, 611, 264, 3539, 565, 2638, 8149, 3089, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1626273405204699, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.011328878812491894}, {"id": 69, "seek": 31044, "start": 316.44, "end": 321.84, "text": " So he shows, based on the profile and on the icicle graph that you see here, that the labels", "tokens": [50664, 407, 415, 3110, 11, 2361, 322, 264, 7964, 293, 322, 264, 4376, 3520, 4295, 300, 291, 536, 510, 11, 300, 264, 16949, 50934], "temperature": 0.0, "avg_logprob": -0.1626273405204699, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.011328878812491894}, {"id": 70, "seek": 31044, "start": 321.84, "end": 325.84, "text": " take most of the memory in Prometheus, and that was around one-third.", "tokens": [50934, 747, 881, 295, 264, 4675, 294, 2114, 649, 42209, 11, 293, 300, 390, 926, 472, 12, 25095, 13, 51134], "temperature": 0.0, "avg_logprob": -0.1626273405204699, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.011328878812491894}, {"id": 71, "seek": 31044, "start": 325.84, "end": 330.12, "text": " And when I thought about it, the result was rather surprising to me, because the labels", "tokens": [51134, 400, 562, 286, 1194, 466, 309, 11, 264, 1874, 390, 2831, 8830, 281, 385, 11, 570, 264, 16949, 51348], "temperature": 0.0, "avg_logprob": -0.1626273405204699, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.011328878812491894}, {"id": 72, "seek": 31044, "start": 330.12, "end": 336.64, "text": " of the time series, we could think of them as some kind of metadata or some kind of contextual", "tokens": [51348, 295, 264, 565, 2638, 11, 321, 727, 519, 295, 552, 382, 512, 733, 295, 26603, 420, 512, 733, 295, 35526, 51674], "temperature": 0.0, "avg_logprob": -0.1626273405204699, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.011328878812491894}, {"id": 73, "seek": 33664, "start": 336.64, "end": 341.36, "text": " data about the actual data points, about the samples, as we call them, and these were", "tokens": [50364, 1412, 466, 264, 3539, 1412, 2793, 11, 466, 264, 10938, 11, 382, 321, 818, 552, 11, 293, 613, 645, 50600], "temperature": 0.0, "avg_logprob": -0.1384224842504128, "compression_ratio": 1.8274336283185841, "no_speech_prob": 0.040292736142873764}, {"id": 74, "seek": 33664, "start": 341.36, "end": 346.68, "text": " taking up more spaces than those actual data points, those actual samples themselves.", "tokens": [50600, 1940, 493, 544, 7673, 813, 729, 3539, 1412, 2793, 11, 729, 3539, 10938, 2969, 13, 50866], "temperature": 0.0, "avg_logprob": -0.1384224842504128, "compression_ratio": 1.8274336283185841, "no_speech_prob": 0.040292736142873764}, {"id": 75, "seek": 33664, "start": 346.68, "end": 351.32, "text": " So there's been a lot of thought and work put into optimization and compression of the", "tokens": [50866, 407, 456, 311, 668, 257, 688, 295, 1194, 293, 589, 829, 666, 19618, 293, 19355, 295, 264, 51098], "temperature": 0.0, "avg_logprob": -0.1384224842504128, "compression_ratio": 1.8274336283185841, "no_speech_prob": 0.040292736142873764}, {"id": 76, "seek": 33664, "start": 351.32, "end": 356.36, "text": " samples of the actual time series data, but Brian's finding indicated that there can be", "tokens": [51098, 10938, 295, 264, 3539, 565, 2638, 1412, 11, 457, 10765, 311, 5006, 16176, 300, 456, 393, 312, 51350], "temperature": 0.0, "avg_logprob": -0.1384224842504128, "compression_ratio": 1.8274336283185841, "no_speech_prob": 0.040292736142873764}, {"id": 77, "seek": 33664, "start": 356.36, "end": 359.12, "text": " more, can be squeezed out of labels.", "tokens": [51350, 544, 11, 393, 312, 39470, 484, 295, 16949, 13, 51488], "temperature": 0.0, "avg_logprob": -0.1384224842504128, "compression_ratio": 1.8274336283185841, "no_speech_prob": 0.040292736142873764}, {"id": 78, "seek": 33664, "start": 359.12, "end": 361.18, "text": " And what are actually labels?", "tokens": [51488, 400, 437, 366, 767, 16949, 30, 51591], "temperature": 0.0, "avg_logprob": -0.1384224842504128, "compression_ratio": 1.8274336283185841, "no_speech_prob": 0.040292736142873764}, {"id": 79, "seek": 36118, "start": 361.18, "end": 366.86, "text": " Labels are key value pairs attached to a given time series to kind of characterize it.", "tokens": [50364, 10137, 1625, 366, 2141, 2158, 15494, 8570, 281, 257, 2212, 565, 2638, 281, 733, 295, 38463, 309, 13, 50648], "temperature": 0.0, "avg_logprob": -0.12782720283225732, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.04094630479812622}, {"id": 80, "seek": 36118, "start": 366.86, "end": 370.86, "text": " So in principle, they are nothing more than pairs of strings.", "tokens": [50648, 407, 294, 8665, 11, 436, 366, 1825, 544, 813, 15494, 295, 13985, 13, 50848], "temperature": 0.0, "avg_logprob": -0.12782720283225732, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.04094630479812622}, {"id": 81, "seek": 36118, "start": 370.86, "end": 373.94, "text": " So this is what brought me in the end to the strings.", "tokens": [50848, 407, 341, 307, 437, 3038, 385, 294, 264, 917, 281, 264, 13985, 13, 51002], "temperature": 0.0, "avg_logprob": -0.12782720283225732, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.04094630479812622}, {"id": 82, "seek": 36118, "start": 373.94, "end": 377.7, "text": " And it inspired me to talk about this topic to a large audience.", "tokens": [51002, 400, 309, 7547, 385, 281, 751, 466, 341, 4829, 281, 257, 2416, 4034, 13, 51190], "temperature": 0.0, "avg_logprob": -0.12782720283225732, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.04094630479812622}, {"id": 83, "seek": 36118, "start": 377.7, "end": 383.26, "text": " I thought it might be useful to look at this from kind of a more general perspective, even", "tokens": [51190, 286, 1194, 309, 1062, 312, 4420, 281, 574, 412, 341, 490, 733, 295, 257, 544, 2674, 4585, 11, 754, 51468], "temperature": 0.0, "avg_logprob": -0.12782720283225732, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.04094630479812622}, {"id": 84, "seek": 36118, "start": 383.26, "end": 388.9, "text": " though we're dealing with this problem in a limited space of observability, I think", "tokens": [51468, 1673, 321, 434, 6260, 365, 341, 1154, 294, 257, 5567, 1901, 295, 9951, 2310, 11, 286, 519, 51750], "temperature": 0.0, "avg_logprob": -0.12782720283225732, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.04094630479812622}, {"id": 85, "seek": 38890, "start": 388.94, "end": 393.85999999999996, "text": " it can be also, some learnings from this can be gained and used also in different, in", "tokens": [50366, 309, 393, 312, 611, 11, 512, 2539, 82, 490, 341, 393, 312, 12634, 293, 1143, 611, 294, 819, 11, 294, 50612], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 86, "seek": 38890, "start": 393.85999999999996, "end": 397.41999999999996, "text": " other types of programs.", "tokens": [50612, 661, 3467, 295, 4268, 13, 50790], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 87, "seek": 38890, "start": 397.41999999999996, "end": 402.06, "text": " So first let's lay foundations to our talk by taking a look at what string actually is", "tokens": [50790, 407, 700, 718, 311, 2360, 22467, 281, 527, 751, 538, 1940, 257, 574, 412, 437, 6798, 767, 307, 51022], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 88, "seek": 38890, "start": 402.06, "end": 403.06, "text": " in Go.", "tokens": [51022, 294, 1037, 13, 51072], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 89, "seek": 38890, "start": 403.06, "end": 406.34, "text": " So most of you probably are familiar with different properties of strings.", "tokens": [51072, 407, 881, 295, 291, 1391, 366, 4963, 365, 819, 7221, 295, 13985, 13, 51236], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 90, "seek": 38890, "start": 406.34, "end": 407.7, "text": " They are immutable.", "tokens": [51236, 814, 366, 3397, 32148, 13, 51304], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 91, "seek": 38890, "start": 407.7, "end": 412.41999999999996, "text": " They can be converted easily into slides of bytes, can be concatenated, sliced, et cetera,", "tokens": [51304, 814, 393, 312, 16424, 3612, 666, 9788, 295, 36088, 11, 393, 312, 1588, 7186, 770, 11, 27098, 11, 1030, 11458, 11, 51540], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 92, "seek": 38890, "start": 412.41999999999996, "end": 413.41999999999996, "text": " et cetera.", "tokens": [51540, 1030, 11458, 13, 51590], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 93, "seek": 38890, "start": 413.41999999999996, "end": 417.26, "text": " However, talking about the qualities of strings does not answer the question what strings", "tokens": [51590, 2908, 11, 1417, 466, 264, 16477, 295, 13985, 775, 406, 1867, 264, 1168, 437, 13985, 51782], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 94, "seek": 38890, "start": 417.26, "end": 418.26, "text": " really are.", "tokens": [51782, 534, 366, 13, 51832], "temperature": 0.0, "avg_logprob": -0.18223953247070312, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.015242021530866623}, {"id": 95, "seek": 41826, "start": 418.5, "end": 422.74, "text": " And if you look at the source code of Go, you'll see that the strings are actually represented", "tokens": [50376, 400, 498, 291, 574, 412, 264, 4009, 3089, 295, 1037, 11, 291, 603, 536, 300, 264, 13985, 366, 767, 10379, 50588], "temperature": 0.0, "avg_logprob": -0.14661395442378414, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.002013884484767914}, {"id": 96, "seek": 41826, "start": 422.74, "end": 425.26, "text": " by the string struct struct.", "tokens": [50588, 538, 264, 6798, 6594, 6594, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14661395442378414, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.002013884484767914}, {"id": 97, "seek": 41826, "start": 425.26, "end": 428.9, "text": " So strings are structs, shocking, right?", "tokens": [50714, 407, 13985, 366, 6594, 82, 11, 18776, 11, 558, 30, 50896], "temperature": 0.0, "avg_logprob": -0.14661395442378414, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.002013884484767914}, {"id": 98, "seek": 41826, "start": 428.9, "end": 433.18, "text": " You can also get the runtime representation of this from the Reflect package, which contains", "tokens": [50896, 509, 393, 611, 483, 264, 34474, 10290, 295, 341, 490, 264, 16957, 1809, 7372, 11, 597, 8306, 51110], "temperature": 0.0, "avg_logprob": -0.14661395442378414, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.002013884484767914}, {"id": 99, "seek": 41826, "start": 433.18, "end": 435.38, "text": " the string header type.", "tokens": [51110, 264, 6798, 23117, 2010, 13, 51220], "temperature": 0.0, "avg_logprob": -0.14661395442378414, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.002013884484767914}, {"id": 100, "seek": 41826, "start": 435.38, "end": 439.98, "text": " So based on these two types, we see that the string consists of a pointer to the actual", "tokens": [51220, 407, 2361, 322, 613, 732, 3467, 11, 321, 536, 300, 264, 6798, 14689, 295, 257, 23918, 281, 264, 3539, 51450], "temperature": 0.0, "avg_logprob": -0.14661395442378414, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.002013884484767914}, {"id": 101, "seek": 41826, "start": 439.98, "end": 445.18, "text": " string data in the memory, an integer which gives information about the size of the string.", "tokens": [51450, 6798, 1412, 294, 264, 4675, 11, 364, 24922, 597, 2709, 1589, 466, 264, 2744, 295, 264, 6798, 13, 51710], "temperature": 0.0, "avg_logprob": -0.14661395442378414, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.002013884484767914}, {"id": 102, "seek": 44518, "start": 445.18, "end": 448.78000000000003, "text": " When Go creates a string, it allocates storage corresponding to the provided string size and", "tokens": [50364, 1133, 1037, 7829, 257, 6798, 11, 309, 12660, 1024, 6725, 11760, 281, 264, 5649, 6798, 2744, 293, 50544], "temperature": 0.0, "avg_logprob": -0.13802768290042877, "compression_ratio": 1.9377289377289377, "no_speech_prob": 0.00624099699780345}, {"id": 103, "seek": 44518, "start": 448.78000000000003, "end": 452.82, "text": " then sets the string content as a slice of bytes.", "tokens": [50544, 550, 6352, 264, 6798, 2701, 382, 257, 13153, 295, 36088, 13, 50746], "temperature": 0.0, "avg_logprob": -0.13802768290042877, "compression_ratio": 1.9377289377289377, "no_speech_prob": 0.00624099699780345}, {"id": 104, "seek": 44518, "start": 452.82, "end": 456.18, "text": " As you've seen, the string data is stored as a contingent slice of bytes memory.", "tokens": [50746, 1018, 291, 600, 1612, 11, 264, 6798, 1412, 307, 12187, 382, 257, 27820, 317, 13153, 295, 36088, 4675, 13, 50914], "temperature": 0.0, "avg_logprob": -0.13802768290042877, "compression_ratio": 1.9377289377289377, "no_speech_prob": 0.00624099699780345}, {"id": 105, "seek": 44518, "start": 456.18, "end": 461.1, "text": " The size of the strings stays the same during its lifetime, since, as I mentioned previously,", "tokens": [50914, 440, 2744, 295, 264, 13985, 10834, 264, 912, 1830, 1080, 11364, 11, 1670, 11, 382, 286, 2835, 8046, 11, 51160], "temperature": 0.0, "avg_logprob": -0.13802768290042877, "compression_ratio": 1.9377289377289377, "no_speech_prob": 0.00624099699780345}, {"id": 106, "seek": 44518, "start": 461.1, "end": 462.1, "text": " the string is immutable.", "tokens": [51160, 264, 6798, 307, 3397, 32148, 13, 51210], "temperature": 0.0, "avg_logprob": -0.13802768290042877, "compression_ratio": 1.9377289377289377, "no_speech_prob": 0.00624099699780345}, {"id": 107, "seek": 44518, "start": 462.1, "end": 465.86, "text": " And this also means that the size and the capacity of the backing slice of bytes stays", "tokens": [51210, 400, 341, 611, 1355, 300, 264, 2744, 293, 264, 6042, 295, 264, 19373, 13153, 295, 36088, 10834, 51398], "temperature": 0.0, "avg_logprob": -0.13802768290042877, "compression_ratio": 1.9377289377289377, "no_speech_prob": 0.00624099699780345}, {"id": 108, "seek": 44518, "start": 465.86, "end": 466.86, "text": " the same.", "tokens": [51398, 264, 912, 13, 51448], "temperature": 0.0, "avg_logprob": -0.13802768290042877, "compression_ratio": 1.9377289377289377, "no_speech_prob": 0.00624099699780345}, {"id": 109, "seek": 44518, "start": 466.86, "end": 471.34000000000003, "text": " When you put this all together, the total size of the string will consist of the overhead", "tokens": [51448, 1133, 291, 829, 341, 439, 1214, 11, 264, 3217, 2744, 295, 264, 6798, 486, 4603, 295, 264, 19922, 51672], "temperature": 0.0, "avg_logprob": -0.13802768290042877, "compression_ratio": 1.9377289377289377, "no_speech_prob": 0.00624099699780345}, {"id": 110, "seek": 47134, "start": 471.34, "end": 475.94, "text": " of the string header, which is equal to 16 bytes, and I show in a bit why, and the byte", "tokens": [50364, 295, 264, 6798, 23117, 11, 597, 307, 2681, 281, 3165, 36088, 11, 293, 286, 855, 294, 257, 857, 983, 11, 293, 264, 40846, 50594], "temperature": 0.0, "avg_logprob": -0.17667361003596607, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.12166368961334229}, {"id": 111, "seek": 47134, "start": 475.94, "end": 477.65999999999997, "text": " length of the string.", "tokens": [50594, 4641, 295, 264, 6798, 13, 50680], "temperature": 0.0, "avg_logprob": -0.17667361003596607, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.12166368961334229}, {"id": 112, "seek": 47134, "start": 477.65999999999997, "end": 483.26, "text": " We can break this down on this small example of the string I created with FOSDEM, space,", "tokens": [50680, 492, 393, 1821, 341, 760, 322, 341, 1359, 1365, 295, 264, 6798, 286, 2942, 365, 479, 4367, 35, 6683, 11, 1901, 11, 50960], "temperature": 0.0, "avg_logprob": -0.17667361003596607, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.12166368961334229}, {"id": 113, "seek": 47134, "start": 483.26, "end": 484.82, "text": " waving hand emoji.", "tokens": [50960, 35347, 1011, 31595, 13, 51038], "temperature": 0.0, "avg_logprob": -0.17667361003596607, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.12166368961334229}, {"id": 114, "seek": 47134, "start": 484.82, "end": 485.97999999999996, "text": " So this is just a snippet.", "tokens": [51038, 407, 341, 307, 445, 257, 35623, 302, 13, 51096], "temperature": 0.0, "avg_logprob": -0.17667361003596607, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.12166368961334229}, {"id": 115, "seek": 47134, "start": 485.97999999999996, "end": 492.85999999999996, "text": " I don't think it would compile this code, but for brevity, I decided to show these three", "tokens": [51096, 286, 500, 380, 519, 309, 576, 31413, 341, 3089, 11, 457, 337, 1403, 23110, 11, 286, 3047, 281, 855, 613, 1045, 51440], "temperature": 0.0, "avg_logprob": -0.17667361003596607, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.12166368961334229}, {"id": 116, "seek": 47134, "start": 492.85999999999996, "end": 494.7, "text": " small lines.", "tokens": [51440, 1359, 3876, 13, 51532], "temperature": 0.0, "avg_logprob": -0.17667361003596607, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.12166368961334229}, {"id": 117, "seek": 47134, "start": 494.7, "end": 499.46, "text": " And by calling the size method on the string type from the Reflect package, you would see", "tokens": [51532, 400, 538, 5141, 264, 2744, 3170, 322, 264, 6798, 2010, 490, 264, 16957, 1809, 7372, 11, 291, 576, 536, 51770], "temperature": 0.0, "avg_logprob": -0.17667361003596607, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.12166368961334229}, {"id": 118, "seek": 49946, "start": 499.46, "end": 502.18, "text": " it return number 16.", "tokens": [50364, 309, 2736, 1230, 3165, 13, 50500], "temperature": 0.0, "avg_logprob": -0.1896081577647816, "compression_ratio": 1.8193832599118942, "no_speech_prob": 0.040266696363687515}, {"id": 119, "seek": 49946, "start": 502.18, "end": 503.18, "text": " Don't be fooled.", "tokens": [50500, 1468, 380, 312, 33372, 13, 50550], "temperature": 0.0, "avg_logprob": -0.1896081577647816, "compression_ratio": 1.8193832599118942, "no_speech_prob": 0.040266696363687515}, {"id": 120, "seek": 49946, "start": 503.18, "end": 508.14, "text": " The size method returns only the information of the size of the type, not size of the whole", "tokens": [50550, 440, 2744, 3170, 11247, 787, 264, 1589, 295, 264, 2744, 295, 264, 2010, 11, 406, 2744, 295, 264, 1379, 50798], "temperature": 0.0, "avg_logprob": -0.1896081577647816, "compression_ratio": 1.8193832599118942, "no_speech_prob": 0.040266696363687515}, {"id": 121, "seek": 49946, "start": 508.14, "end": 509.14, "text": " string.", "tokens": [50798, 6798, 13, 50848], "temperature": 0.0, "avg_logprob": -0.1896081577647816, "compression_ratio": 1.8193832599118942, "no_speech_prob": 0.040266696363687515}, {"id": 122, "seek": 49946, "start": 509.14, "end": 513.34, "text": " Therefore, it correctly tells us it's 16 bytes, 18 bytes due to pointer pointing to the string", "tokens": [50848, 7504, 11, 309, 8944, 5112, 505, 309, 311, 3165, 36088, 11, 2443, 36088, 3462, 281, 23918, 12166, 281, 264, 6798, 51058], "temperature": 0.0, "avg_logprob": -0.1896081577647816, "compression_ratio": 1.8193832599118942, "no_speech_prob": 0.040266696363687515}, {"id": 123, "seek": 49946, "start": 513.34, "end": 517.54, "text": " in memory, and 8 bytes for keeping the string length information.", "tokens": [51058, 294, 4675, 11, 293, 1649, 36088, 337, 5145, 264, 6798, 4641, 1589, 13, 51268], "temperature": 0.0, "avg_logprob": -0.1896081577647816, "compression_ratio": 1.8193832599118942, "no_speech_prob": 0.040266696363687515}, {"id": 124, "seek": 49946, "start": 517.54, "end": 521.9, "text": " To get the size of the actual string data, we have to use the good old length method.", "tokens": [51268, 1407, 483, 264, 2744, 295, 264, 3539, 6798, 1412, 11, 321, 362, 281, 764, 264, 665, 1331, 4641, 3170, 13, 51486], "temperature": 0.0, "avg_logprob": -0.1896081577647816, "compression_ratio": 1.8193832599118942, "no_speech_prob": 0.040266696363687515}, {"id": 125, "seek": 49946, "start": 521.9, "end": 524.22, "text": " This tells us it's 11 bytes.", "tokens": [51486, 639, 5112, 505, 309, 311, 2975, 36088, 13, 51602], "temperature": 0.0, "avg_logprob": -0.1896081577647816, "compression_ratio": 1.8193832599118942, "no_speech_prob": 0.040266696363687515}, {"id": 126, "seek": 52422, "start": 524.22, "end": 525.38, "text": " This is the string literal.", "tokens": [50364, 639, 307, 264, 6798, 20411, 13, 50422], "temperature": 0.0, "avg_logprob": -0.19150999242609199, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.015224241651594639}, {"id": 127, "seek": 52422, "start": 525.38, "end": 527.3000000000001, "text": " Here is UTF-8 encoded.", "tokens": [50422, 1692, 307, 624, 20527, 12, 23, 2058, 12340, 13, 50518], "temperature": 0.0, "avg_logprob": -0.19150999242609199, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.015224241651594639}, {"id": 128, "seek": 52422, "start": 527.3000000000001, "end": 532.4200000000001, "text": " We count one byte per each letter and space, and we need actually four bytes to encode", "tokens": [50518, 492, 1207, 472, 40846, 680, 1184, 5063, 293, 1901, 11, 293, 321, 643, 767, 1451, 36088, 281, 2058, 1429, 50774], "temperature": 0.0, "avg_logprob": -0.19150999242609199, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.015224241651594639}, {"id": 129, "seek": 52422, "start": 532.4200000000001, "end": 534.34, "text": " the waving hand emoji.", "tokens": [50774, 264, 35347, 1011, 31595, 13, 50870], "temperature": 0.0, "avg_logprob": -0.19150999242609199, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.015224241651594639}, {"id": 130, "seek": 52422, "start": 534.34, "end": 538.14, "text": " And this brings our total to 27 bytes.", "tokens": [50870, 400, 341, 5607, 527, 3217, 281, 7634, 36088, 13, 51060], "temperature": 0.0, "avg_logprob": -0.19150999242609199, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.015224241651594639}, {"id": 131, "seek": 52422, "start": 538.14, "end": 542.58, "text": " Interestingly for such a short string, the overhead of storing it is bigger than the string", "tokens": [51060, 30564, 337, 1270, 257, 2099, 6798, 11, 264, 19922, 295, 26085, 309, 307, 3801, 813, 264, 6798, 51282], "temperature": 0.0, "avg_logprob": -0.19150999242609199, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.015224241651594639}, {"id": 132, "seek": 52422, "start": 542.58, "end": 545.7, "text": " data itself.", "tokens": [51282, 1412, 2564, 13, 51438], "temperature": 0.0, "avg_logprob": -0.19150999242609199, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.015224241651594639}, {"id": 133, "seek": 52422, "start": 545.7, "end": 549.5400000000001, "text": " It's also important to realize what happens if we declare a new string variable that is", "tokens": [51438, 467, 311, 611, 1021, 281, 4325, 437, 2314, 498, 321, 19710, 257, 777, 6798, 7006, 300, 307, 51630], "temperature": 0.0, "avg_logprob": -0.19150999242609199, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.015224241651594639}, {"id": 134, "seek": 52422, "start": 549.5400000000001, "end": 551.0600000000001, "text": " copying an existing string.", "tokens": [51630, 27976, 364, 6741, 6798, 13, 51706], "temperature": 0.0, "avg_logprob": -0.19150999242609199, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.015224241651594639}, {"id": 135, "seek": 55106, "start": 551.3, "end": 556.02, "text": " In this case, co-creates what we can consider a shallow copy, meaning the data the string", "tokens": [50376, 682, 341, 1389, 11, 598, 12, 35546, 279, 437, 321, 393, 1949, 257, 20488, 5055, 11, 3620, 264, 1412, 264, 6798, 50612], "temperature": 0.0, "avg_logprob": -0.2174871282060017, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.03380843624472618}, {"id": 136, "seek": 55106, "start": 556.02, "end": 558.78, "text": " refers to is shared between the variables.", "tokens": [50612, 14942, 281, 307, 5507, 1296, 264, 9102, 13, 50750], "temperature": 0.0, "avg_logprob": -0.2174871282060017, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.03380843624472618}, {"id": 137, "seek": 55106, "start": 558.78, "end": 561.38, "text": " Let's break it down again on the example of our FOSDEM string.", "tokens": [50750, 961, 311, 1821, 309, 760, 797, 322, 264, 1365, 295, 527, 479, 4367, 35, 6683, 6798, 13, 50880], "temperature": 0.0, "avg_logprob": -0.2174871282060017, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.03380843624472618}, {"id": 138, "seek": 55106, "start": 561.38, "end": 567.06, "text": " So we declare a new string literal, FOSDEM waving hand emoji, and then create a new", "tokens": [50880, 407, 321, 19710, 257, 777, 6798, 20411, 11, 479, 4367, 35, 6683, 35347, 1011, 31595, 11, 293, 550, 1884, 257, 777, 51164], "temperature": 0.0, "avg_logprob": -0.2174871282060017, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.03380843624472618}, {"id": 139, "seek": 55106, "start": 567.06, "end": 572.54, "text": " STR or new string variable, and set it to value equal to string or STR.", "tokens": [51164, 43013, 420, 777, 6798, 7006, 11, 293, 992, 309, 281, 2158, 2681, 281, 6798, 420, 43013, 13, 51438], "temperature": 0.0, "avg_logprob": -0.2174871282060017, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.03380843624472618}, {"id": 140, "seek": 55106, "start": 572.54, "end": 574.14, "text": " What happens behind the scenes?", "tokens": [51438, 708, 2314, 2261, 264, 8026, 30, 51518], "temperature": 0.0, "avg_logprob": -0.2174871282060017, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.03380843624472618}, {"id": 141, "seek": 55106, "start": 574.14, "end": 577.78, "text": " If you would look at the values, pointer of each of the strings, you would see different", "tokens": [51518, 759, 291, 576, 574, 412, 264, 4190, 11, 23918, 295, 1184, 295, 264, 13985, 11, 291, 576, 536, 819, 51700], "temperature": 0.0, "avg_logprob": -0.2174871282060017, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.03380843624472618}, {"id": 142, "seek": 55106, "start": 577.78, "end": 578.78, "text": " addresses.", "tokens": [51700, 16862, 13, 51750], "temperature": 0.0, "avg_logprob": -0.2174871282060017, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.03380843624472618}, {"id": 143, "seek": 57878, "start": 578.78, "end": 583.74, "text": " We're making it obvious that these are two different strings strictly speaking, but looking", "tokens": [50364, 492, 434, 1455, 309, 6322, 300, 613, 366, 732, 819, 13985, 20792, 4124, 11, 457, 1237, 50612], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 144, "seek": 57878, "start": 583.74, "end": 588.3399999999999, "text": " at their headers, we would see identical information, same pointer to string data,", "tokens": [50612, 412, 641, 45101, 11, 321, 576, 536, 14800, 1589, 11, 912, 23918, 281, 6798, 1412, 11, 50842], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 145, "seek": 57878, "start": 588.3399999999999, "end": 589.3399999999999, "text": " and same length.", "tokens": [50842, 293, 912, 4641, 13, 50892], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 146, "seek": 57878, "start": 589.3399999999999, "end": 590.3399999999999, "text": " But because...", "tokens": [50892, 583, 570, 485, 50942], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 147, "seek": 57878, "start": 590.3399999999999, "end": 595.18, "text": " Excuse me, sir, can we turn the light on the front off first?", "tokens": [50942, 11359, 385, 11, 4735, 11, 393, 321, 1261, 264, 1442, 322, 264, 1868, 766, 700, 30, 51184], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 148, "seek": 57878, "start": 595.18, "end": 596.18, "text": " I cannot.", "tokens": [51184, 286, 2644, 13, 51234], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 149, "seek": 57878, "start": 596.18, "end": 597.18, "text": " Sorry.", "tokens": [51234, 4919, 13, 51284], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 150, "seek": 57878, "start": 597.18, "end": 598.18, "text": " Okay.", "tokens": [51284, 1033, 13, 51334], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 151, "seek": 57878, "start": 598.18, "end": 599.18, "text": " Sorry.", "tokens": [51334, 4919, 13, 51384], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 152, "seek": 57878, "start": 599.18, "end": 605.14, "text": " Yeah, it's a bit light, right, sorry.", "tokens": [51384, 865, 11, 309, 311, 257, 857, 1442, 11, 558, 11, 2597, 13, 51682], "temperature": 0.0, "avg_logprob": -0.3955704046755421, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.02219609171152115}, {"id": 153, "seek": 60514, "start": 605.14, "end": 610.8199999999999, "text": " But anyway, so these are two different strings strictly speaking, and looking at the header", "tokens": [50364, 583, 4033, 11, 370, 613, 366, 732, 819, 13985, 20792, 4124, 11, 293, 1237, 412, 264, 23117, 50648], "temperature": 0.0, "avg_logprob": -0.190057237571645, "compression_ratio": 1.74, "no_speech_prob": 0.05896810442209244}, {"id": 154, "seek": 60514, "start": 610.8199999999999, "end": 616.78, "text": " information, we would see that they point to same string data and have same length.", "tokens": [50648, 1589, 11, 321, 576, 536, 300, 436, 935, 281, 912, 6798, 1412, 293, 362, 912, 4641, 13, 50946], "temperature": 0.0, "avg_logprob": -0.190057237571645, "compression_ratio": 1.74, "no_speech_prob": 0.05896810442209244}, {"id": 155, "seek": 60514, "start": 616.78, "end": 620.6999999999999, "text": " Because they are two different strings, we need to be mindful of the fact that the new", "tokens": [50946, 1436, 436, 366, 732, 819, 13985, 11, 321, 643, 281, 312, 14618, 295, 264, 1186, 300, 264, 777, 51142], "temperature": 0.0, "avg_logprob": -0.190057237571645, "compression_ratio": 1.74, "no_speech_prob": 0.05896810442209244}, {"id": 156, "seek": 60514, "start": 620.6999999999999, "end": 623.06, "text": " STR comes with a brand new string header.", "tokens": [51142, 43013, 1487, 365, 257, 3360, 777, 6798, 23117, 13, 51260], "temperature": 0.0, "avg_logprob": -0.190057237571645, "compression_ratio": 1.74, "no_speech_prob": 0.05896810442209244}, {"id": 157, "seek": 60514, "start": 623.06, "end": 628.5, "text": " So the bottom line is, when we do this copying, there is, again, even the data is shared,", "tokens": [51260, 407, 264, 2767, 1622, 307, 11, 562, 321, 360, 341, 27976, 11, 456, 307, 11, 797, 11, 754, 264, 1412, 307, 5507, 11, 51532], "temperature": 0.0, "avg_logprob": -0.190057237571645, "compression_ratio": 1.74, "no_speech_prob": 0.05896810442209244}, {"id": 158, "seek": 60514, "start": 628.5, "end": 632.66, "text": " the overhead of 16 bytes is still there.", "tokens": [51532, 264, 19922, 295, 3165, 36088, 307, 920, 456, 13, 51740], "temperature": 0.0, "avg_logprob": -0.190057237571645, "compression_ratio": 1.74, "no_speech_prob": 0.05896810442209244}, {"id": 159, "seek": 63266, "start": 632.66, "end": 636.5, "text": " So I briefly talked about my inspiration for this talk, but I also wanted to expand a bit", "tokens": [50364, 407, 286, 10515, 2825, 466, 452, 10249, 337, 341, 751, 11, 457, 286, 611, 1415, 281, 5268, 257, 857, 50556], "temperature": 0.0, "avg_logprob": -0.18642550556599594, "compression_ratio": 1.664516129032258, "no_speech_prob": 0.09340588748455048}, {"id": 160, "seek": 63266, "start": 636.5, "end": 642.1, "text": " on the context of the problems, where I think the string optimization strategies can be", "tokens": [50556, 322, 264, 4319, 295, 264, 2740, 11, 689, 286, 519, 264, 6798, 19618, 9029, 393, 312, 50836], "temperature": 0.0, "avg_logprob": -0.18642550556599594, "compression_ratio": 1.664516129032258, "no_speech_prob": 0.09340588748455048}, {"id": 161, "seek": 63266, "start": 642.1, "end": 643.1, "text": " useful.", "tokens": [50836, 4420, 13, 50886], "temperature": 0.0, "avg_logprob": -0.18642550556599594, "compression_ratio": 1.664516129032258, "no_speech_prob": 0.09340588748455048}, {"id": 162, "seek": 63266, "start": 643.1, "end": 648.74, "text": " I think in general, many programs with characteristics of in-memory stores may face performance issue.", "tokens": [50886, 286, 519, 294, 2674, 11, 867, 4268, 365, 10891, 295, 294, 12, 17886, 827, 9512, 815, 1851, 3389, 2734, 13, 51168], "temperature": 0.0, "avg_logprob": -0.18642550556599594, "compression_ratio": 1.664516129032258, "no_speech_prob": 0.09340588748455048}, {"id": 163, "seek": 63266, "start": 648.74, "end": 652.3399999999999, "text": " I will talk about in this slide such programs.", "tokens": [51168, 286, 486, 751, 466, 294, 341, 4137, 1270, 4268, 13, 51348], "temperature": 0.0, "avg_logprob": -0.18642550556599594, "compression_ratio": 1.664516129032258, "no_speech_prob": 0.09340588748455048}, {"id": 164, "seek": 63266, "start": 652.3399999999999, "end": 657.18, "text": " I already mentioned numerous times, the time series database, DNS resolvers, or any other", "tokens": [51348, 286, 1217, 2835, 12546, 1413, 11, 264, 565, 2638, 8149, 11, 35153, 7923, 840, 11, 420, 604, 661, 51590], "temperature": 0.0, "avg_logprob": -0.18642550556599594, "compression_ratio": 1.664516129032258, "no_speech_prob": 0.09340588748455048}, {"id": 165, "seek": 63266, "start": 657.18, "end": 662.1, "text": " kind of key value store, where we come with an assumption that these are some long running", "tokens": [51590, 733, 295, 2141, 2158, 3531, 11, 689, 321, 808, 365, 364, 15302, 300, 613, 366, 512, 938, 2614, 51836], "temperature": 0.0, "avg_logprob": -0.18642550556599594, "compression_ratio": 1.664516129032258, "no_speech_prob": 0.09340588748455048}, {"id": 166, "seek": 66210, "start": 662.1, "end": 669.82, "text": " programs, and over the runtime of the program, we will keep the number of strings we will", "tokens": [50364, 4268, 11, 293, 670, 264, 34474, 295, 264, 1461, 11, 321, 486, 1066, 264, 1230, 295, 13985, 321, 486, 50750], "temperature": 0.0, "avg_logprob": -0.19561182657877604, "compression_ratio": 1.776, "no_speech_prob": 0.04823079705238342}, {"id": 167, "seek": 66210, "start": 669.82, "end": 672.1800000000001, "text": " keep accumulating.", "tokens": [50750, 1066, 12989, 12162, 13, 50868], "temperature": 0.0, "avg_logprob": -0.19561182657877604, "compression_ratio": 1.776, "no_speech_prob": 0.04823079705238342}, {"id": 168, "seek": 66210, "start": 672.1800000000001, "end": 675.1800000000001, "text": " So we can be talking potentially billions of strings.", "tokens": [50868, 407, 321, 393, 312, 1417, 7263, 17375, 295, 13985, 13, 51018], "temperature": 0.0, "avg_logprob": -0.19561182657877604, "compression_ratio": 1.776, "no_speech_prob": 0.04823079705238342}, {"id": 169, "seek": 66210, "start": 675.1800000000001, "end": 679.1800000000001, "text": " There's also potential for repetitions of strings, since many of these stored values", "tokens": [51018, 821, 311, 611, 3995, 337, 13645, 2451, 295, 13985, 11, 1670, 867, 295, 613, 12187, 4190, 51218], "temperature": 0.0, "avg_logprob": -0.19561182657877604, "compression_ratio": 1.776, "no_speech_prob": 0.04823079705238342}, {"id": 170, "seek": 66210, "start": 679.1800000000001, "end": 681.0600000000001, "text": " may repeat themselves.", "tokens": [51218, 815, 7149, 2969, 13, 51312], "temperature": 0.0, "avg_logprob": -0.19561182657877604, "compression_ratio": 1.776, "no_speech_prob": 0.04823079705238342}, {"id": 171, "seek": 66210, "start": 681.0600000000001, "end": 685.7, "text": " So for example, if we associate each of our entries with a label denoting which cluster", "tokens": [51312, 407, 337, 1365, 11, 498, 321, 14644, 1184, 295, 527, 23041, 365, 257, 7645, 1441, 17001, 597, 13630, 51544], "temperature": 0.0, "avg_logprob": -0.19561182657877604, "compression_ratio": 1.776, "no_speech_prob": 0.04823079705238342}, {"id": 172, "seek": 66210, "start": 685.7, "end": 690.5400000000001, "text": " they belong to, we are guaranteed to have repeated values, since we have a finite and", "tokens": [51544, 436, 5784, 281, 11, 321, 366, 18031, 281, 362, 10477, 4190, 11, 1670, 321, 362, 257, 19362, 293, 51786], "temperature": 0.0, "avg_logprob": -0.19561182657877604, "compression_ratio": 1.776, "no_speech_prob": 0.04823079705238342}, {"id": 173, "seek": 69054, "start": 690.54, "end": 692.66, "text": " often small amount of clusters.", "tokens": [50364, 2049, 1359, 2372, 295, 23313, 13, 50470], "temperature": 0.0, "avg_logprob": -0.18728914568501134, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.03504577651619911}, {"id": 174, "seek": 69054, "start": 692.66, "end": 698.8199999999999, "text": " So the string cluster will be stored as many times as many entries there are in our database.", "tokens": [50470, 407, 264, 6798, 13630, 486, 312, 12187, 382, 867, 1413, 382, 867, 23041, 456, 366, 294, 527, 8149, 13, 50778], "temperature": 0.0, "avg_logprob": -0.18728914568501134, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.03504577651619911}, {"id": 175, "seek": 69054, "start": 698.8199999999999, "end": 702.74, "text": " There are also certain caveats when it comes to handling of incoming data.", "tokens": [50778, 821, 366, 611, 1629, 11730, 1720, 562, 309, 1487, 281, 13175, 295, 22341, 1412, 13, 50974], "temperature": 0.0, "avg_logprob": -0.18728914568501134, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.03504577651619911}, {"id": 176, "seek": 69054, "start": 702.74, "end": 710.4599999999999, "text": " Data will often come in a form of request through HTTP or GRPC or any other protocol,", "tokens": [50974, 11888, 486, 2049, 808, 294, 257, 1254, 295, 5308, 807, 33283, 420, 10903, 12986, 420, 604, 661, 10336, 11, 51360], "temperature": 0.0, "avg_logprob": -0.18728914568501134, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.03504577651619911}, {"id": 177, "seek": 69054, "start": 710.4599999999999, "end": 716.5, "text": " and usually we handle this data in our program by un-martialing them into a struct, and then", "tokens": [51360, 293, 2673, 321, 4813, 341, 1412, 294, 527, 1461, 538, 517, 12, 18696, 831, 278, 552, 666, 257, 6594, 11, 293, 550, 51662], "temperature": 0.0, "avg_logprob": -0.18728914568501134, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.03504577651619911}, {"id": 178, "seek": 71650, "start": 716.5, "end": 723.74, "text": " we might want to store some information, some string from this struct in the memory for", "tokens": [50364, 321, 1062, 528, 281, 3531, 512, 1589, 11, 512, 6798, 490, 341, 6594, 294, 264, 4675, 337, 50726], "temperature": 0.0, "avg_logprob": -0.15849738004730968, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.035135794430971146}, {"id": 179, "seek": 71650, "start": 723.74, "end": 724.74, "text": " future use.", "tokens": [50726, 2027, 764, 13, 50776], "temperature": 0.0, "avg_logprob": -0.15849738004730968, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.035135794430971146}, {"id": 180, "seek": 71650, "start": 724.74, "end": 729.58, "text": " However, the side effect of this is that the whole struct will be prevented from being", "tokens": [50776, 2908, 11, 264, 1252, 1802, 295, 341, 307, 300, 264, 1379, 6594, 486, 312, 27314, 490, 885, 51018], "temperature": 0.0, "avg_logprob": -0.15849738004730968, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.035135794430971146}, {"id": 181, "seek": 71650, "start": 729.58, "end": 734.34, "text": " garbage collected, because as long as the string or as a matter of fact any other field", "tokens": [51018, 14150, 11087, 11, 570, 382, 938, 382, 264, 6798, 420, 382, 257, 1871, 295, 1186, 604, 661, 2519, 51256], "temperature": 0.0, "avg_logprob": -0.15849738004730968, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.035135794430971146}, {"id": 182, "seek": 71650, "start": 734.34, "end": 741.06, "text": " from a struct is being referenced by our database in memory, the garbage collection", "tokens": [51256, 490, 257, 6594, 307, 885, 32734, 538, 527, 8149, 294, 4675, 11, 264, 14150, 5765, 51592], "temperature": 0.0, "avg_logprob": -0.15849738004730968, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.035135794430971146}, {"id": 183, "seek": 74106, "start": 741.06, "end": 745.5799999999999, "text": " won't kick in and eventually will lead to bloats in the memory consumption.", "tokens": [50364, 1582, 380, 4437, 294, 293, 4728, 486, 1477, 281, 1749, 1720, 294, 264, 4675, 12126, 13, 50590], "temperature": 0.0, "avg_logprob": -0.1988456964492798, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.02576509676873684}, {"id": 184, "seek": 74106, "start": 745.5799999999999, "end": 752.26, "text": " I think the second kind of different type of programs where string optimization can", "tokens": [50590, 286, 519, 264, 1150, 733, 295, 819, 2010, 295, 4268, 689, 6798, 19618, 393, 50924], "temperature": 0.0, "avg_logprob": -0.1988456964492798, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.02576509676873684}, {"id": 185, "seek": 74106, "start": 752.26, "end": 759.38, "text": " be useful are kind of one of data processing situations as opposed to the long-running", "tokens": [50924, 312, 4420, 366, 733, 295, 472, 295, 1412, 9007, 6851, 382, 8851, 281, 264, 938, 12, 45482, 51280], "temperature": 0.0, "avg_logprob": -0.1988456964492798, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.02576509676873684}, {"id": 186, "seek": 74106, "start": 759.38, "end": 760.38, "text": " programs.", "tokens": [51280, 4268, 13, 51330], "temperature": 0.0, "avg_logprob": -0.1988456964492798, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.02576509676873684}, {"id": 187, "seek": 74106, "start": 760.38, "end": 767.02, "text": " So we can take an example of handling some large JSON file, perhaps it can be some data", "tokens": [51330, 407, 321, 393, 747, 364, 1365, 295, 13175, 512, 2416, 31828, 3991, 11, 4317, 309, 393, 312, 512, 1412, 51662], "temperature": 0.0, "avg_logprob": -0.1988456964492798, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.02576509676873684}, {"id": 188, "seek": 76702, "start": 767.02, "end": 771.9, "text": " set from a study or a health data, which I think were some good examples I've seen", "tokens": [50364, 992, 490, 257, 2979, 420, 257, 1585, 1412, 11, 597, 286, 519, 645, 512, 665, 5110, 286, 600, 1612, 50608], "temperature": 0.0, "avg_logprob": -0.13661701637401916, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0712357759475708}, {"id": 189, "seek": 76702, "start": 771.9, "end": 777.1, "text": " out in the wild, and such processing will require a larger amount of memory to decode", "tokens": [50608, 484, 294, 264, 4868, 11, 293, 1270, 9007, 486, 3651, 257, 4833, 2372, 295, 4675, 281, 979, 1429, 50868], "temperature": 0.0, "avg_logprob": -0.13661701637401916, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0712357759475708}, {"id": 190, "seek": 76702, "start": 777.1, "end": 778.86, "text": " the data during processing.", "tokens": [50868, 264, 1412, 1830, 9007, 13, 50956], "temperature": 0.0, "avg_logprob": -0.13661701637401916, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0712357759475708}, {"id": 191, "seek": 76702, "start": 778.86, "end": 783.02, "text": " So even though we might be processing same strings that repeat themselves over and over", "tokens": [50956, 407, 754, 1673, 321, 1062, 312, 9007, 912, 13985, 300, 7149, 2969, 670, 293, 670, 51164], "temperature": 0.0, "avg_logprob": -0.13661701637401916, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0712357759475708}, {"id": 192, "seek": 76702, "start": 783.02, "end": 787.3, "text": " again such as the keys in the JSON document, we're having to allocate such strings in", "tokens": [51164, 797, 1270, 382, 264, 9317, 294, 264, 31828, 4166, 11, 321, 434, 1419, 281, 35713, 1270, 13985, 294, 51378], "temperature": 0.0, "avg_logprob": -0.13661701637401916, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0712357759475708}, {"id": 193, "seek": 76702, "start": 787.3, "end": 789.3, "text": " new each time.", "tokens": [51378, 777, 1184, 565, 13, 51478], "temperature": 0.0, "avg_logprob": -0.13661701637401916, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0712357759475708}, {"id": 194, "seek": 76702, "start": 789.3, "end": 795.9399999999999, "text": " So now that we have a better understanding of the problem zones, let's look at the actual", "tokens": [51478, 407, 586, 300, 321, 362, 257, 1101, 3701, 295, 264, 1154, 16025, 11, 718, 311, 574, 412, 264, 3539, 51810], "temperature": 0.0, "avg_logprob": -0.13661701637401916, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0712357759475708}, {"id": 195, "seek": 79594, "start": 795.94, "end": 798.86, "text": " optimization strategies.", "tokens": [50364, 19618, 9029, 13, 50510], "temperature": 0.0, "avg_logprob": -0.17349276591822044, "compression_ratio": 1.7872340425531914, "no_speech_prob": 0.06035970151424408}, {"id": 196, "seek": 79594, "start": 798.86, "end": 805.62, "text": " So the first strategy is related to the issue I mentioned a couple of slides before where", "tokens": [50510, 407, 264, 700, 5206, 307, 4077, 281, 264, 2734, 286, 2835, 257, 1916, 295, 9788, 949, 689, 50848], "temperature": 0.0, "avg_logprob": -0.17349276591822044, "compression_ratio": 1.7872340425531914, "no_speech_prob": 0.06035970151424408}, {"id": 197, "seek": 79594, "start": 805.62, "end": 813.62, "text": " we are wasting memory by keeping whole structs in memory when we only need part of the struct", "tokens": [50848, 321, 366, 20457, 4675, 538, 5145, 1379, 6594, 82, 294, 4675, 562, 321, 787, 643, 644, 295, 264, 6594, 51248], "temperature": 0.0, "avg_logprob": -0.17349276591822044, "compression_ratio": 1.7872340425531914, "no_speech_prob": 0.06035970151424408}, {"id": 198, "seek": 79594, "start": 813.62, "end": 815.6600000000001, "text": " that is represented by the string.", "tokens": [51248, 300, 307, 10379, 538, 264, 6798, 13, 51350], "temperature": 0.0, "avg_logprob": -0.17349276591822044, "compression_ratio": 1.7872340425531914, "no_speech_prob": 0.06035970151424408}, {"id": 199, "seek": 79594, "start": 815.6600000000001, "end": 820.1, "text": " So what we want to do here is to have a mechanism that will allow us to quote unquote detach", "tokens": [51350, 407, 437, 321, 528, 281, 360, 510, 307, 281, 362, 257, 7513, 300, 486, 2089, 505, 281, 6513, 37557, 43245, 51572], "temperature": 0.0, "avg_logprob": -0.17349276591822044, "compression_ratio": 1.7872340425531914, "no_speech_prob": 0.06035970151424408}, {"id": 200, "seek": 79594, "start": 820.1, "end": 824.5, "text": " the string from the struct so that the rest of the struct can be garbage collected.", "tokens": [51572, 264, 6798, 490, 264, 6594, 370, 300, 264, 1472, 295, 264, 6594, 393, 312, 14150, 11087, 13, 51792], "temperature": 0.0, "avg_logprob": -0.17349276591822044, "compression_ratio": 1.7872340425531914, "no_speech_prob": 0.06035970151424408}, {"id": 201, "seek": 82450, "start": 825.06, "end": 828.94, "text": " Previously this was also possible to achieve with some unsafe manipulation of strings,", "tokens": [50392, 33606, 341, 390, 611, 1944, 281, 4584, 365, 512, 35948, 26475, 295, 13985, 11, 50586], "temperature": 0.0, "avg_logprob": -0.19061776569911412, "compression_ratio": 1.7543859649122806, "no_speech_prob": 0.02503216452896595}, {"id": 202, "seek": 82450, "start": 828.94, "end": 835.06, "text": " but since Go 118 there's a new method called clone in the string standard library that", "tokens": [50586, 457, 1670, 1037, 2975, 23, 456, 311, 257, 777, 3170, 1219, 26506, 294, 264, 6798, 3832, 6405, 300, 50892], "temperature": 0.0, "avg_logprob": -0.19061776569911412, "compression_ratio": 1.7543859649122806, "no_speech_prob": 0.02503216452896595}, {"id": 203, "seek": 82450, "start": 835.06, "end": 837.46, "text": " makes it quite straightforward.", "tokens": [50892, 1669, 309, 1596, 15325, 13, 51012], "temperature": 0.0, "avg_logprob": -0.19061776569911412, "compression_ratio": 1.7543859649122806, "no_speech_prob": 0.02503216452896595}, {"id": 204, "seek": 82450, "start": 837.46, "end": 841.3, "text": " Though clone creates a new fresh copy of the string, this decouples the string from the", "tokens": [51012, 10404, 26506, 7829, 257, 777, 4451, 5055, 295, 264, 6798, 11, 341, 979, 263, 2622, 264, 6798, 490, 264, 51204], "temperature": 0.0, "avg_logprob": -0.19061776569911412, "compression_ratio": 1.7543859649122806, "no_speech_prob": 0.02503216452896595}, {"id": 205, "seek": 82450, "start": 841.3, "end": 846.3, "text": " struct, meaning the struct can be garbage collected in the long term and will retain", "tokens": [51204, 6594, 11, 3620, 264, 6594, 393, 312, 14150, 11087, 294, 264, 938, 1433, 293, 486, 18340, 51454], "temperature": 0.0, "avg_logprob": -0.19061776569911412, "compression_ratio": 1.7543859649122806, "no_speech_prob": 0.02503216452896595}, {"id": 206, "seek": 82450, "start": 846.3, "end": 848.62, "text": " only the new copy of the string.", "tokens": [51454, 787, 264, 777, 5055, 295, 264, 6798, 13, 51570], "temperature": 0.0, "avg_logprob": -0.19061776569911412, "compression_ratio": 1.7543859649122806, "no_speech_prob": 0.02503216452896595}, {"id": 207, "seek": 82450, "start": 848.62, "end": 853.06, "text": " So remember previously I showed that when we copy strings we create shallow copies, here", "tokens": [51570, 407, 1604, 8046, 286, 4712, 300, 562, 321, 5055, 13985, 321, 1884, 20488, 14341, 11, 510, 51792], "temperature": 0.0, "avg_logprob": -0.19061776569911412, "compression_ratio": 1.7543859649122806, "no_speech_prob": 0.02503216452896595}, {"id": 208, "seek": 85306, "start": 853.0999999999999, "end": 857.6999999999999, "text": " we want to achieve the opposite, we want to truly copy the string and create a fresh copy", "tokens": [50366, 321, 528, 281, 4584, 264, 6182, 11, 321, 528, 281, 4908, 5055, 264, 6798, 293, 1884, 257, 4451, 5055, 50596], "temperature": 0.0, "avg_logprob": -0.12019122649576063, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0018088570795953274}, {"id": 209, "seek": 85306, "start": 857.6999999999999, "end": 862.02, "text": " of the underlying string data so the original string can be garbage collected together", "tokens": [50596, 295, 264, 14217, 6798, 1412, 370, 264, 3380, 6798, 393, 312, 14150, 11087, 1214, 50812], "temperature": 0.0, "avg_logprob": -0.12019122649576063, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0018088570795953274}, {"id": 210, "seek": 85306, "start": 862.02, "end": 868.18, "text": " with the struct it's part of, so this we can refer to as deep copying.", "tokens": [50812, 365, 264, 6594, 309, 311, 644, 295, 11, 370, 341, 321, 393, 2864, 281, 382, 2452, 27976, 13, 51120], "temperature": 0.0, "avg_logprob": -0.12019122649576063, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0018088570795953274}, {"id": 211, "seek": 85306, "start": 868.18, "end": 872.5799999999999, "text": " The next most interesting and I'd say one of the most widely used strategies in software", "tokens": [51120, 440, 958, 881, 1880, 293, 286, 1116, 584, 472, 295, 264, 881, 13371, 1143, 9029, 294, 4722, 51340], "temperature": 0.0, "avg_logprob": -0.12019122649576063, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0018088570795953274}, {"id": 212, "seek": 85306, "start": 872.5799999999999, "end": 875.06, "text": " in general is string interning.", "tokens": [51340, 294, 2674, 307, 6798, 728, 773, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12019122649576063, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0018088570795953274}, {"id": 213, "seek": 85306, "start": 875.06, "end": 878.8199999999999, "text": " String interning is a technique which makes it possible to store only a single copy of", "tokens": [51464, 745, 2937, 728, 773, 307, 257, 6532, 597, 1669, 309, 1944, 281, 3531, 787, 257, 2167, 5055, 295, 51652], "temperature": 0.0, "avg_logprob": -0.12019122649576063, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0018088570795953274}, {"id": 214, "seek": 87882, "start": 878.82, "end": 883.1800000000001, "text": " each distinct string and subsequently we keep referencing the same underlying string", "tokens": [50364, 1184, 10644, 6798, 293, 26514, 321, 1066, 40582, 264, 912, 14217, 6798, 50582], "temperature": 0.0, "avg_logprob": -0.1731907268902203, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.016066305339336395}, {"id": 215, "seek": 87882, "start": 883.1800000000001, "end": 884.62, "text": " in the memory.", "tokens": [50582, 294, 264, 4675, 13, 50654], "temperature": 0.0, "avg_logprob": -0.1731907268902203, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.016066305339336395}, {"id": 216, "seek": 87882, "start": 884.62, "end": 889.4200000000001, "text": " This concept is somewhat more common in other languages such as Java or Python but can be", "tokens": [50654, 639, 3410, 307, 8344, 544, 2689, 294, 661, 8650, 1270, 382, 10745, 420, 15329, 457, 393, 312, 50894], "temperature": 0.0, "avg_logprob": -0.1731907268902203, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.016066305339336395}, {"id": 217, "seek": 87882, "start": 889.4200000000001, "end": 894.0600000000001, "text": " implemented effortlessly in Go as well and there are even some ready-made solutions out", "tokens": [50894, 12270, 4630, 12048, 294, 1037, 382, 731, 293, 456, 366, 754, 512, 1919, 12, 10341, 6547, 484, 51126], "temperature": 0.0, "avg_logprob": -0.1731907268902203, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.016066305339336395}, {"id": 218, "seek": 87882, "start": 894.0600000000001, "end": 896.58, "text": " in the open that you can use.", "tokens": [51126, 294, 264, 1269, 300, 291, 393, 764, 13, 51252], "temperature": 0.0, "avg_logprob": -0.1731907268902203, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.016066305339336395}, {"id": 219, "seek": 87882, "start": 896.58, "end": 903.3800000000001, "text": " So at Simplus you could achieve this by having a simple map string string and you can keep", "tokens": [51252, 407, 412, 3998, 18954, 291, 727, 4584, 341, 538, 1419, 257, 2199, 4471, 6798, 6798, 293, 291, 393, 1066, 51592], "temperature": 0.0, "avg_logprob": -0.1731907268902203, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.016066305339336395}, {"id": 220, "seek": 87882, "start": 903.3800000000001, "end": 908.74, "text": " the references to the string in this map which we can call our interning map or cache", "tokens": [51592, 264, 15400, 281, 264, 6798, 294, 341, 4471, 597, 321, 393, 818, 527, 728, 773, 4471, 420, 19459, 51860], "temperature": 0.0, "avg_logprob": -0.1731907268902203, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.016066305339336395}, {"id": 221, "seek": 90874, "start": 908.74, "end": 913.22, "text": " or anything like that.", "tokens": [50364, 420, 1340, 411, 300, 13, 50588], "temperature": 0.0, "avg_logprob": -0.2275218373721408, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.001924335490912199}, {"id": 222, "seek": 90874, "start": 913.22, "end": 918.54, "text": " First complication comes with the concurrency, right, because we need a mechanism to prevent", "tokens": [50588, 2386, 1209, 8758, 1487, 365, 264, 23702, 10457, 11, 558, 11, 570, 321, 643, 257, 7513, 281, 4871, 50854], "temperature": 0.0, "avg_logprob": -0.2275218373721408, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.001924335490912199}, {"id": 223, "seek": 90874, "start": 918.54, "end": 923.38, "text": " concurrent write and read to our interning map so obvious choice would be to use mutex", "tokens": [50854, 37702, 2464, 293, 1401, 281, 527, 728, 773, 4471, 370, 6322, 3922, 576, 312, 281, 764, 24523, 87, 51096], "temperature": 0.0, "avg_logprob": -0.2275218373721408, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.001924335490912199}, {"id": 224, "seek": 90874, "start": 923.38, "end": 927.26, "text": " which have our incurred performance penalty but so be it.", "tokens": [51096, 597, 362, 527, 35774, 986, 3389, 16263, 457, 370, 312, 309, 13, 51290], "temperature": 0.0, "avg_logprob": -0.2275218373721408, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.001924335490912199}, {"id": 225, "seek": 90874, "start": 927.26, "end": 931.78, "text": " Our concurrency save map version from the sync standard library.", "tokens": [51290, 2621, 23702, 10457, 3155, 4471, 3037, 490, 264, 20271, 3832, 6405, 13, 51516], "temperature": 0.0, "avg_logprob": -0.2275218373721408, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.001924335490912199}, {"id": 226, "seek": 90874, "start": 931.78, "end": 936.26, "text": " The second complication or the noteworthy fact is that with each new reference string", "tokens": [51516, 440, 1150, 1209, 8758, 420, 264, 406, 1023, 2652, 88, 1186, 307, 300, 365, 1184, 777, 6408, 6798, 51740], "temperature": 0.0, "avg_logprob": -0.2275218373721408, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.001924335490912199}, {"id": 227, "seek": 93626, "start": 936.26, "end": 941.38, "text": " we are incurring the 16 bytes overhead as I explained a couple of slides back.", "tokens": [50364, 321, 366, 35774, 2937, 264, 3165, 36088, 19922, 382, 286, 8825, 257, 1916, 295, 9788, 646, 13, 50620], "temperature": 0.0, "avg_logprob": -0.21095240247118605, "compression_ratio": 1.6186046511627907, "no_speech_prob": 0.02263675257563591}, {"id": 228, "seek": 93626, "start": 941.38, "end": 947.9, "text": " So even though we're saving on the actual string data, it's not, we're still incurring", "tokens": [50620, 407, 754, 1673, 321, 434, 6816, 322, 264, 3539, 6798, 1412, 11, 309, 311, 406, 11, 321, 434, 920, 35774, 2937, 50946], "temperature": 0.0, "avg_logprob": -0.21095240247118605, "compression_ratio": 1.6186046511627907, "no_speech_prob": 0.02263675257563591}, {"id": 229, "seek": 93626, "start": 947.9, "end": 955.62, "text": " the overhead so with millions of strings, 16 bytes for every string, it's a non-trivial", "tokens": [50946, 264, 19922, 370, 365, 6803, 295, 13985, 11, 3165, 36088, 337, 633, 6798, 11, 309, 311, 257, 2107, 12, 83, 470, 22640, 51332], "temperature": 0.0, "avg_logprob": -0.21095240247118605, "compression_ratio": 1.6186046511627907, "no_speech_prob": 0.02263675257563591}, {"id": 230, "seek": 93626, "start": 955.62, "end": 957.62, "text": " amount.", "tokens": [51332, 2372, 13, 51432], "temperature": 0.0, "avg_logprob": -0.21095240247118605, "compression_ratio": 1.6186046511627907, "no_speech_prob": 0.02263675257563591}, {"id": 231, "seek": 93626, "start": 957.62, "end": 962.22, "text": " Third complication comes from the unknown lifetime of the string in our interning map.", "tokens": [51432, 12548, 1209, 8758, 1487, 490, 264, 9841, 11364, 295, 264, 6798, 294, 527, 728, 773, 4471, 13, 51662], "temperature": 0.0, "avg_logprob": -0.21095240247118605, "compression_ratio": 1.6186046511627907, "no_speech_prob": 0.02263675257563591}, {"id": 232, "seek": 96222, "start": 962.22, "end": 967.02, "text": " At some point in the lifetime of the program there might be no more references to a particular", "tokens": [50364, 1711, 512, 935, 294, 264, 11364, 295, 264, 1461, 456, 1062, 312, 572, 544, 15400, 281, 257, 1729, 50604], "temperature": 0.0, "avg_logprob": -0.12824740636916387, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.035603899508714676}, {"id": 233, "seek": 96222, "start": 967.02, "end": 969.62, "text": " string so it can be safely dropped.", "tokens": [50604, 6798, 370, 309, 393, 312, 11750, 8119, 13, 50734], "temperature": 0.0, "avg_logprob": -0.12824740636916387, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.035603899508714676}, {"id": 234, "seek": 96222, "start": 969.62, "end": 972.78, "text": " But how to know when these conditions are met?", "tokens": [50734, 583, 577, 281, 458, 562, 613, 4487, 366, 1131, 30, 50892], "temperature": 0.0, "avg_logprob": -0.12824740636916387, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.035603899508714676}, {"id": 235, "seek": 96222, "start": 972.78, "end": 978.1, "text": " Ideally we don't want to be keeping unused strings as in an extreme case this can be", "tokens": [50892, 40817, 321, 500, 380, 528, 281, 312, 5145, 44383, 13985, 382, 294, 364, 8084, 1389, 341, 393, 312, 51158], "temperature": 0.0, "avg_logprob": -0.12824740636916387, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.035603899508714676}, {"id": 236, "seek": 96222, "start": 978.1, "end": 985.5, "text": " a denial of service vector leading to exhaustion of memory if we allow the map to grow unbounded.", "tokens": [51158, 257, 28754, 295, 2643, 8062, 5775, 281, 47408, 295, 4675, 498, 321, 2089, 264, 4471, 281, 1852, 517, 18767, 292, 13, 51528], "temperature": 0.0, "avg_logprob": -0.12824740636916387, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.035603899508714676}, {"id": 237, "seek": 96222, "start": 985.5, "end": 989.5400000000001, "text": " One option could be to periodically clear the map or give the entries a certain time", "tokens": [51528, 1485, 3614, 727, 312, 281, 38916, 1850, 264, 4471, 420, 976, 264, 23041, 257, 1629, 565, 51730], "temperature": 0.0, "avg_logprob": -0.12824740636916387, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.035603899508714676}, {"id": 238, "seek": 98954, "start": 989.54, "end": 994.54, "text": " to live so after a given period the map or the given entries are dropped from the map", "tokens": [50364, 281, 1621, 370, 934, 257, 2212, 2896, 264, 4471, 420, 264, 2212, 23041, 366, 8119, 490, 264, 4471, 50614], "temperature": 0.0, "avg_logprob": -0.14704932557775618, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.030641648918390274}, {"id": 239, "seek": 98954, "start": 994.54, "end": 999.54, "text": " and if a string reappears after such deletion we simply create the entry in the interning", "tokens": [50614, 293, 498, 257, 6798, 35638, 68, 685, 934, 1270, 1103, 302, 313, 321, 2935, 1884, 264, 8729, 294, 264, 728, 773, 50864], "temperature": 0.0, "avg_logprob": -0.14704932557775618, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.030641648918390274}, {"id": 240, "seek": 98954, "start": 999.54, "end": 1005.6999999999999, "text": " map so kind of like a cache and naturally this can lead to some unnecessary churning", "tokens": [50864, 4471, 370, 733, 295, 411, 257, 19459, 293, 8195, 341, 393, 1477, 281, 512, 19350, 417, 10656, 51172], "temperature": 0.0, "avg_logprob": -0.14704932557775618, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.030641648918390274}, {"id": 241, "seek": 98954, "start": 1005.6999999999999, "end": 1009.6999999999999, "text": " and unnecessary allocations because we don't know exactly which strings are no longer needed", "tokens": [51172, 293, 19350, 12660, 763, 570, 321, 500, 380, 458, 2293, 597, 13985, 366, 572, 2854, 2978, 51372], "temperature": 0.0, "avg_logprob": -0.14704932557775618, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.030641648918390274}, {"id": 242, "seek": 98954, "start": 1009.6999999999999, "end": 1014.14, "text": " or referenced but we might be still dropping them.", "tokens": [51372, 420, 32734, 457, 321, 1062, 312, 920, 13601, 552, 13, 51594], "temperature": 0.0, "avg_logprob": -0.14704932557775618, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.030641648918390274}, {"id": 243, "seek": 101414, "start": 1014.14, "end": 1019.9399999999999, "text": " One and more elaborate way to do this is to keep counting the number of references of", "tokens": [50364, 1485, 293, 544, 20945, 636, 281, 360, 341, 307, 281, 1066, 13251, 264, 1230, 295, 15400, 295, 50654], "temperature": 0.0, "avg_logprob": -0.17290899027948795, "compression_ratio": 1.7447698744769875, "no_speech_prob": 0.08877620100975037}, {"id": 244, "seek": 101414, "start": 1019.9399999999999, "end": 1025.54, "text": " the used strings and this naturally requires a more eloquent and complex implementation", "tokens": [50654, 264, 1143, 13985, 293, 341, 8195, 7029, 257, 544, 38682, 28842, 293, 3997, 11420, 50934], "temperature": 0.0, "avg_logprob": -0.17290899027948795, "compression_ratio": 1.7447698744769875, "no_speech_prob": 0.08877620100975037}, {"id": 245, "seek": 101414, "start": 1025.54, "end": 1030.66, "text": " but you can see here I linked a work done in the Prometheus project writing is a good", "tokens": [50934, 457, 291, 393, 536, 510, 286, 9408, 257, 589, 1096, 294, 264, 2114, 649, 42209, 1716, 3579, 307, 257, 665, 51190], "temperature": 0.0, "avg_logprob": -0.17290899027948795, "compression_ratio": 1.7447698744769875, "no_speech_prob": 0.08877620100975037}, {"id": 246, "seek": 101414, "start": 1030.66, "end": 1037.7, "text": " example of how this can be implemented with counting the references.", "tokens": [51190, 1365, 295, 577, 341, 393, 312, 12270, 365, 13251, 264, 15400, 13, 51542], "temperature": 0.0, "avg_logprob": -0.17290899027948795, "compression_ratio": 1.7447698744769875, "no_speech_prob": 0.08877620100975037}, {"id": 247, "seek": 101414, "start": 1037.7, "end": 1042.5, "text": " We can take this even to the next level as I recently learned there is an implementation", "tokens": [51542, 492, 393, 747, 341, 754, 281, 264, 958, 1496, 382, 286, 3938, 3264, 456, 307, 364, 11420, 51782], "temperature": 0.0, "avg_logprob": -0.17290899027948795, "compression_ratio": 1.7447698744769875, "no_speech_prob": 0.08877620100975037}, {"id": 248, "seek": 104250, "start": 1042.5, "end": 1047.9, "text": " of an interning library that is capable of automatically dropping unused references.", "tokens": [50364, 295, 364, 728, 773, 6405, 300, 307, 8189, 295, 6772, 13601, 44383, 15400, 13, 50634], "temperature": 0.0, "avg_logprob": -0.17423417635053118, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.042229391634464264}, {"id": 249, "seek": 104250, "start": 1047.9, "end": 1054.02, "text": " The go4.org intern library is capable of doing this thanks to somewhat controversial concept", "tokens": [50634, 440, 352, 19, 13, 4646, 2154, 6405, 307, 8189, 295, 884, 341, 3231, 281, 8344, 17323, 3410, 50940], "temperature": 0.0, "avg_logprob": -0.17423417635053118, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.042229391634464264}, {"id": 250, "seek": 104250, "start": 1054.02, "end": 1057.86, "text": " of the finalizers in the go runtime.", "tokens": [50940, 295, 264, 2572, 22525, 294, 264, 352, 34474, 13, 51132], "temperature": 0.0, "avg_logprob": -0.17423417635053118, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.042229391634464264}, {"id": 251, "seek": 104250, "start": 1057.86, "end": 1062.38, "text": " Finalizers set very plainly make it possible to attach a function that will be called on", "tokens": [51132, 13443, 22525, 992, 588, 11121, 356, 652, 309, 1944, 281, 5085, 257, 2445, 300, 486, 312, 1219, 322, 51358], "temperature": 0.0, "avg_logprob": -0.17423417635053118, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.042229391634464264}, {"id": 252, "seek": 104250, "start": 1062.38, "end": 1067.46, "text": " a variable that is deemed to be garbage collection ready by the garbage collector.", "tokens": [51358, 257, 7006, 300, 307, 27637, 281, 312, 14150, 5765, 1919, 538, 264, 14150, 23960, 13, 51612], "temperature": 0.0, "avg_logprob": -0.17423417635053118, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.042229391634464264}, {"id": 253, "seek": 104250, "start": 1067.46, "end": 1072.38, "text": " At that point this library checks the sentinel boolean on the reference value and if it finds", "tokens": [51612, 1711, 300, 935, 341, 6405, 13834, 264, 2279, 40952, 748, 4812, 282, 322, 264, 6408, 2158, 293, 498, 309, 10704, 51858], "temperature": 0.0, "avg_logprob": -0.17423417635053118, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.042229391634464264}, {"id": 254, "seek": 107238, "start": 1072.38, "end": 1077.46, "text": " this is the last reference to that value it drops it from a map.", "tokens": [50364, 341, 307, 264, 1036, 6408, 281, 300, 2158, 309, 11438, 309, 490, 257, 4471, 13, 50618], "temperature": 0.0, "avg_logprob": -0.1657620526235038, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.0038984455168247223}, {"id": 255, "seek": 107238, "start": 1077.46, "end": 1081.7, "text": " The library also cleverly boxes the string header down to a single pointer which brings", "tokens": [50618, 440, 6405, 611, 13494, 356, 9002, 264, 6798, 23117, 760, 281, 257, 2167, 23918, 597, 5607, 50830], "temperature": 0.0, "avg_logprob": -0.1657620526235038, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.0038984455168247223}, {"id": 256, "seek": 107238, "start": 1081.7, "end": 1086.0600000000002, "text": " the overhead down to 8 bytes instead of 16.", "tokens": [50830, 264, 19922, 760, 281, 1649, 36088, 2602, 295, 3165, 13, 51048], "temperature": 0.0, "avg_logprob": -0.1657620526235038, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.0038984455168247223}, {"id": 257, "seek": 107238, "start": 1086.0600000000002, "end": 1090.74, "text": " So as fascinating as this implementation is to me it makes uses of some potentially unsafe", "tokens": [51048, 407, 382, 10343, 382, 341, 11420, 307, 281, 385, 309, 1669, 4960, 295, 512, 7263, 35948, 51282], "temperature": 0.0, "avg_logprob": -0.1657620526235038, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.0038984455168247223}, {"id": 258, "seek": 107238, "start": 1090.74, "end": 1095.74, "text": " code behavior hence the dark arts reference in the slide title.", "tokens": [51282, 3089, 5223, 16678, 264, 2877, 8609, 6408, 294, 264, 4137, 4876, 13, 51532], "temperature": 0.0, "avg_logprob": -0.1657620526235038, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.0038984455168247223}, {"id": 259, "seek": 107238, "start": 1095.74, "end": 1099.5400000000002, "text": " However the library is deemed stable and major enough and has been created by some well-known", "tokens": [51532, 2908, 264, 6405, 307, 27637, 8351, 293, 2563, 1547, 293, 575, 668, 2942, 538, 512, 731, 12, 6861, 51722], "temperature": 0.0, "avg_logprob": -0.1657620526235038, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.0038984455168247223}, {"id": 260, "seek": 107238, "start": 1099.5400000000002, "end": 1101.38, "text": " names in the go community.", "tokens": [51722, 5288, 294, 264, 352, 1768, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1657620526235038, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.0038984455168247223}, {"id": 261, "seek": 110138, "start": 1101.38, "end": 1106.98, "text": " So if you're interested I encourage you to study and look at the code it's just one file", "tokens": [50364, 407, 498, 291, 434, 3102, 286, 5373, 291, 281, 2979, 293, 574, 412, 264, 3089, 309, 311, 445, 472, 3991, 50644], "temperature": 0.0, "avg_logprob": -0.21741852552994437, "compression_ratio": 1.5696202531645569, "no_speech_prob": 0.040351033210754395}, {"id": 262, "seek": 110138, "start": 1106.98, "end": 1113.8600000000001, "text": " but it's quite interesting and you're sure to learn a thing or two about some less known", "tokens": [50644, 457, 309, 311, 1596, 1880, 293, 291, 434, 988, 281, 1466, 257, 551, 420, 732, 466, 512, 1570, 2570, 50988], "temperature": 0.0, "avg_logprob": -0.21741852552994437, "compression_ratio": 1.5696202531645569, "no_speech_prob": 0.040351033210754395}, {"id": 263, "seek": 110138, "start": 1113.8600000000001, "end": 1117.22, "text": " parts of go.", "tokens": [50988, 3166, 295, 352, 13, 51156], "temperature": 0.0, "avg_logprob": -0.21741852552994437, "compression_ratio": 1.5696202531645569, "no_speech_prob": 0.040351033210754395}, {"id": 264, "seek": 110138, "start": 1117.22, "end": 1123.5, "text": " And as an example I recently tried this library in the last blood point in the TANOS project", "tokens": [51156, 400, 382, 364, 1365, 286, 3938, 3031, 341, 6405, 294, 264, 1036, 3390, 935, 294, 264, 314, 1770, 4367, 1716, 51470], "temperature": 0.0, "avg_logprob": -0.21741852552994437, "compression_ratio": 1.5696202531645569, "no_speech_prob": 0.040351033210754395}, {"id": 265, "seek": 110138, "start": 1123.5, "end": 1128.8600000000001, "text": " again I linked you the PR with the usage with the implementation which I think is rather", "tokens": [51470, 797, 286, 9408, 291, 264, 11568, 365, 264, 14924, 365, 264, 11420, 597, 286, 519, 307, 2831, 51738], "temperature": 0.0, "avg_logprob": -0.21741852552994437, "compression_ratio": 1.5696202531645569, "no_speech_prob": 0.040351033210754395}, {"id": 266, "seek": 112886, "start": 1128.86, "end": 1130.82, "text": " straightforward.", "tokens": [50364, 15325, 13, 50462], "temperature": 0.0, "avg_logprob": -0.21834680438041687, "compression_ratio": 1.5080213903743316, "no_speech_prob": 0.14875860512256622}, {"id": 267, "seek": 112886, "start": 1130.82, "end": 1139.6999999999998, "text": " And we ran some synthetic benchmarks on this version in turning on this was the result.", "tokens": [50462, 400, 321, 5872, 512, 23420, 43751, 322, 341, 3037, 294, 6246, 322, 341, 390, 264, 1874, 13, 50906], "temperature": 0.0, "avg_logprob": -0.21834680438041687, "compression_ratio": 1.5080213903743316, "no_speech_prob": 0.14875860512256622}, {"id": 268, "seek": 112886, "start": 1139.6999999999998, "end": 1145.06, "text": " On the left side you can see probably not very clearly unfortunately but there is a graph", "tokens": [50906, 1282, 264, 1411, 1252, 291, 393, 536, 1391, 406, 588, 4448, 7015, 457, 456, 307, 257, 4295, 51174], "temperature": 0.0, "avg_logprob": -0.21834680438041687, "compression_ratio": 1.5080213903743316, "no_speech_prob": 0.14875860512256622}, {"id": 269, "seek": 112886, "start": 1145.06, "end": 1153.4599999999998, "text": " showing metrics for both reported by the go runtime, how many bytes we have in the heap", "tokens": [51174, 4099, 16367, 337, 1293, 7055, 538, 264, 352, 34474, 11, 577, 867, 36088, 321, 362, 294, 264, 33591, 51594], "temperature": 0.0, "avg_logprob": -0.21834680438041687, "compression_ratio": 1.5080213903743316, "no_speech_prob": 0.14875860512256622}, {"id": 270, "seek": 115346, "start": 1153.46, "end": 1162.5, "text": " and metrics reported by the container itself and you can see the differences between the", "tokens": [50364, 293, 16367, 7055, 538, 264, 10129, 2564, 293, 291, 393, 536, 264, 7300, 1296, 264, 50816], "temperature": 0.0, "avg_logprob": -0.18415671900699013, "compression_ratio": 1.7626262626262625, "no_speech_prob": 0.07050284743309021}, {"id": 271, "seek": 115346, "start": 1162.5, "end": 1168.7, "text": " green and yellow line and the blue and red line so it came up to roughly two to three", "tokens": [50816, 3092, 293, 5566, 1622, 293, 264, 3344, 293, 2182, 1622, 370, 309, 1361, 493, 281, 9810, 732, 281, 1045, 51126], "temperature": 0.0, "avg_logprob": -0.18415671900699013, "compression_ratio": 1.7626262626262625, "no_speech_prob": 0.07050284743309021}, {"id": 272, "seek": 115346, "start": 1168.7, "end": 1175.94, "text": " gigabytes improvement per instance so this is averaged per I think across six or nine", "tokens": [51126, 42741, 10444, 680, 5197, 370, 341, 307, 18247, 2980, 680, 286, 519, 2108, 2309, 420, 4949, 51488], "temperature": 0.0, "avg_logprob": -0.18415671900699013, "compression_ratio": 1.7626262626262625, "no_speech_prob": 0.07050284743309021}, {"id": 273, "seek": 115346, "start": 1175.94, "end": 1181.1000000000001, "text": " instances so per instance this was around two to three gigabytes so we can count overall", "tokens": [51488, 14519, 370, 680, 5197, 341, 390, 926, 732, 281, 1045, 42741, 370, 321, 393, 1207, 4787, 51746], "temperature": 0.0, "avg_logprob": -0.18415671900699013, "compression_ratio": 1.7626262626262625, "no_speech_prob": 0.07050284743309021}, {"id": 274, "seek": 118110, "start": 1181.1, "end": 1186.78, "text": " improvement around ten to twelve gigabytes but more interestingly on the right side of", "tokens": [50364, 10444, 926, 2064, 281, 14390, 42741, 457, 544, 25873, 322, 264, 558, 1252, 295, 50648], "temperature": 0.0, "avg_logprob": -0.16482874155044555, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0721290111541748}, {"id": 275, "seek": 118110, "start": 1186.78, "end": 1192.6999999999998, "text": " the slide there is another graph to kind of confirm that the interning is doing something", "tokens": [50648, 264, 4137, 456, 307, 1071, 4295, 281, 733, 295, 9064, 300, 264, 728, 773, 307, 884, 746, 50944], "temperature": 0.0, "avg_logprob": -0.16482874155044555, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0721290111541748}, {"id": 276, "seek": 118110, "start": 1192.6999999999998, "end": 1199.98, "text": " that it's working then we can see we're following again a metric reported by the go runtime", "tokens": [50944, 300, 309, 311, 1364, 550, 321, 393, 536, 321, 434, 3480, 797, 257, 20678, 7055, 538, 264, 352, 34474, 51308], "temperature": 0.0, "avg_logprob": -0.16482874155044555, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0721290111541748}, {"id": 277, "seek": 118110, "start": 1199.98, "end": 1207.06, "text": " and we're looking at the number of objects held in the memory so we can see that it dropped", "tokens": [51308, 293, 321, 434, 1237, 412, 264, 1230, 295, 6565, 5167, 294, 264, 4675, 370, 321, 393, 536, 300, 309, 8119, 51662], "temperature": 0.0, "avg_logprob": -0.16482874155044555, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0721290111541748}, {"id": 278, "seek": 120706, "start": 1207.06, "end": 1212.1, "text": " almost by health when we look at the average.", "tokens": [50364, 1920, 538, 1585, 562, 321, 574, 412, 264, 4274, 13, 50616], "temperature": 0.0, "avg_logprob": -0.20531291587679995, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.15490217506885529}, {"id": 279, "seek": 120706, "start": 1212.1, "end": 1215.62, "text": " Finally there's a string interning with a slightly different flavor I would say which", "tokens": [50616, 6288, 456, 311, 257, 6798, 728, 773, 365, 257, 4748, 819, 6813, 286, 576, 584, 597, 50792], "temperature": 0.0, "avg_logprob": -0.20531291587679995, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.15490217506885529}, {"id": 280, "seek": 120706, "start": 1215.62, "end": 1220.82, "text": " I refer to a string interning with symbol tables and in this alternative instead of", "tokens": [50792, 286, 2864, 281, 257, 6798, 728, 773, 365, 5986, 8020, 293, 294, 341, 8535, 2602, 295, 51052], "temperature": 0.0, "avg_logprob": -0.20531291587679995, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.15490217506885529}, {"id": 281, "seek": 120706, "start": 1220.82, "end": 1226.26, "text": " keeping a reference string we replace it with another referring symbol such as for example", "tokens": [51052, 5145, 257, 6408, 6798, 321, 7406, 309, 365, 1071, 13761, 5986, 1270, 382, 337, 1365, 51324], "temperature": 0.0, "avg_logprob": -0.20531291587679995, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.15490217506885529}, {"id": 282, "seek": 120706, "start": 1226.26, "end": 1230.8999999999999, "text": " an integer so the integer one will correspond to string apple or string integer two will", "tokens": [51324, 364, 24922, 370, 264, 24922, 472, 486, 6805, 281, 6798, 10606, 420, 6798, 24922, 732, 486, 51556], "temperature": 0.0, "avg_logprob": -0.20531291587679995, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.15490217506885529}, {"id": 283, "seek": 120706, "start": 1230.8999999999999, "end": 1235.54, "text": " correspond to string banana and so on and this can be beneficial with scenarios with", "tokens": [51556, 6805, 281, 6798, 14194, 293, 370, 322, 293, 341, 393, 312, 14072, 365, 15077, 365, 51788], "temperature": 0.0, "avg_logprob": -0.20531291587679995, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.15490217506885529}, {"id": 284, "seek": 123554, "start": 1235.54, "end": 1240.98, "text": " a lot of duplicated strings again this brings me to my home field and to the time series", "tokens": [50364, 257, 688, 295, 1581, 564, 3587, 13985, 797, 341, 5607, 385, 281, 452, 1280, 2519, 293, 281, 264, 565, 2638, 50636], "temperature": 0.0, "avg_logprob": -0.11814626713388975, "compression_ratio": 1.896103896103896, "no_speech_prob": 0.03577324002981186}, {"id": 285, "seek": 123554, "start": 1240.98, "end": 1246.6599999999999, "text": " databases where there is generally a high probability of the labels so also the strings", "tokens": [50636, 22380, 689, 456, 307, 5101, 257, 1090, 8482, 295, 264, 16949, 370, 611, 264, 13985, 50920], "temperature": 0.0, "avg_logprob": -0.11814626713388975, "compression_ratio": 1.896103896103896, "no_speech_prob": 0.03577324002981186}, {"id": 286, "seek": 123554, "start": 1246.6599999999999, "end": 1253.1399999999999, "text": " being repeated and especially when such strings are being sent over the wire so instead of", "tokens": [50920, 885, 10477, 293, 2318, 562, 1270, 13985, 366, 885, 2279, 670, 264, 6234, 370, 2602, 295, 51244], "temperature": 0.0, "avg_logprob": -0.11814626713388975, "compression_ratio": 1.896103896103896, "no_speech_prob": 0.03577324002981186}, {"id": 287, "seek": 123554, "start": 1253.1399999999999, "end": 1258.7, "text": " sending all the duplicated strings we can send a symbol table in their place and we", "tokens": [51244, 7750, 439, 264, 1581, 564, 3587, 13985, 321, 393, 2845, 257, 5986, 3199, 294, 641, 1081, 293, 321, 51522], "temperature": 0.0, "avg_logprob": -0.11814626713388975, "compression_ratio": 1.896103896103896, "no_speech_prob": 0.03577324002981186}, {"id": 288, "seek": 123554, "start": 1258.7, "end": 1264.22, "text": " can replace the strings with the references in this table so where this idea come from", "tokens": [51522, 393, 7406, 264, 13985, 365, 264, 15400, 294, 341, 3199, 370, 689, 341, 1558, 808, 490, 51798], "temperature": 0.0, "avg_logprob": -0.11814626713388975, "compression_ratio": 1.896103896103896, "no_speech_prob": 0.03577324002981186}, {"id": 289, "seek": 126422, "start": 1264.26, "end": 1270.22, "text": " or where I got inspired for this was also in Thanos but this was by one of my fellow", "tokens": [50366, 420, 689, 286, 658, 7547, 337, 341, 390, 611, 294, 35993, 457, 341, 390, 538, 472, 295, 452, 7177, 50664], "temperature": 0.0, "avg_logprob": -0.16464513540267944, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.04544331133365631}, {"id": 290, "seek": 126422, "start": 1270.22, "end": 1275.9, "text": " maintainers so you can look at that PR who implemented this for data series being sent", "tokens": [50664, 6909, 433, 370, 291, 393, 574, 412, 300, 11568, 567, 12270, 341, 337, 1412, 2638, 885, 2279, 50948], "temperature": 0.0, "avg_logprob": -0.16464513540267944, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.04544331133365631}, {"id": 291, "seek": 126422, "start": 1275.9, "end": 1282.34, "text": " over the network between Thanos components so instead of sending all the long and unduplicated", "tokens": [50948, 670, 264, 3209, 1296, 35993, 6677, 370, 2602, 295, 7750, 439, 264, 938, 293, 674, 44810, 3587, 51270], "temperature": 0.0, "avg_logprob": -0.16464513540267944, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.04544331133365631}, {"id": 292, "seek": 126422, "start": 1282.34, "end": 1287.94, "text": " label keys and values so instead of sending all of these strings we build a symbol table", "tokens": [51270, 7645, 9317, 293, 4190, 370, 2602, 295, 7750, 439, 295, 613, 13985, 321, 1322, 257, 5986, 3199, 51550], "temperature": 0.0, "avg_logprob": -0.16464513540267944, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.04544331133365631}, {"id": 293, "seek": 128794, "start": 1287.94, "end": 1295.38, "text": " that we send together with the duplicated label data that includes that contains only", "tokens": [50364, 300, 321, 2845, 1214, 365, 264, 1581, 564, 3587, 7645, 1412, 300, 5974, 300, 8306, 787, 50736], "temperature": 0.0, "avg_logprob": -0.14682798584302267, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.03210374340415001}, {"id": 294, "seek": 128794, "start": 1295.38, "end": 1300.1000000000001, "text": " references instead of the strings so that all we have to do on the other side once", "tokens": [50736, 15400, 2602, 295, 264, 13985, 370, 300, 439, 321, 362, 281, 360, 322, 264, 661, 1252, 1564, 50972], "temperature": 0.0, "avg_logprob": -0.14682798584302267, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.03210374340415001}, {"id": 295, "seek": 128794, "start": 1300.1000000000001, "end": 1304.74, "text": " we receive the data is to replace the references by the actual strings based on the symbol", "tokens": [50972, 321, 4774, 264, 1412, 307, 281, 7406, 264, 15400, 538, 264, 3539, 13985, 2361, 322, 264, 5986, 51204], "temperature": 0.0, "avg_logprob": -0.14682798584302267, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.03210374340415001}, {"id": 296, "seek": 128794, "start": 1304.74, "end": 1310.46, "text": " table which saves us on one hand the cost of the network since the requests are smaller", "tokens": [51204, 3199, 597, 19155, 505, 322, 472, 1011, 264, 2063, 295, 264, 3209, 1670, 264, 12475, 366, 4356, 51490], "temperature": 0.0, "avg_logprob": -0.14682798584302267, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.03210374340415001}, {"id": 297, "seek": 128794, "start": 1310.46, "end": 1316.46, "text": " and also the allocations once we're dealing with the data on the receiving side.", "tokens": [51490, 293, 611, 264, 12660, 763, 1564, 321, 434, 6260, 365, 264, 1412, 322, 264, 10040, 1252, 13, 51790], "temperature": 0.0, "avg_logprob": -0.14682798584302267, "compression_ratio": 1.829059829059829, "no_speech_prob": 0.03210374340415001}, {"id": 298, "seek": 131646, "start": 1317.26, "end": 1322.94, "text": " Lastly you could try putting all of the strings into one big structure into one big string", "tokens": [50404, 18072, 291, 727, 853, 3372, 439, 295, 264, 13985, 666, 472, 955, 3877, 666, 472, 955, 6798, 50688], "temperature": 0.0, "avg_logprob": -0.1806042411110618, "compression_ratio": 1.9263157894736842, "no_speech_prob": 0.0039576212875545025}, {"id": 299, "seek": 131646, "start": 1322.94, "end": 1327.3400000000001, "text": " and this can be useful to decrease the total overhead of the strings as this eliminates", "tokens": [50688, 293, 341, 393, 312, 4420, 281, 11514, 264, 3217, 19922, 295, 264, 13985, 382, 341, 49893, 50908], "temperature": 0.0, "avg_logprob": -0.1806042411110618, "compression_ratio": 1.9263157894736842, "no_speech_prob": 0.0039576212875545025}, {"id": 300, "seek": 131646, "start": 1327.3400000000001, "end": 1337.54, "text": " the already mentioned overhead of the string header so yeah since this is always 16 bytes", "tokens": [50908, 264, 1217, 2835, 19922, 295, 264, 6798, 23117, 370, 1338, 1670, 341, 307, 1009, 3165, 36088, 51418], "temperature": 0.0, "avg_logprob": -0.1806042411110618, "compression_ratio": 1.9263157894736842, "no_speech_prob": 0.0039576212875545025}, {"id": 301, "seek": 131646, "start": 1337.54, "end": 1342.7, "text": " plus the byte length of the string which consists which creates the size of the string by putting", "tokens": [51418, 1804, 264, 40846, 4641, 295, 264, 6798, 597, 14689, 597, 7829, 264, 2744, 295, 264, 6798, 538, 3372, 51676], "temperature": 0.0, "avg_logprob": -0.1806042411110618, "compression_ratio": 1.9263157894736842, "no_speech_prob": 0.0039576212875545025}, {"id": 302, "seek": 134270, "start": 1342.7, "end": 1350.06, "text": " all the strings into the one we can effectively decrease the overhead of those string headers.", "tokens": [50364, 439, 264, 13985, 666, 264, 472, 321, 393, 8659, 11514, 264, 19922, 295, 729, 6798, 45101, 13, 50732], "temperature": 0.0, "avg_logprob": -0.15307409386885792, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.014939157292246819}, {"id": 303, "seek": 134270, "start": 1350.06, "end": 1354.14, "text": " So of course this is not without added complexity because now we have to deal with how to look", "tokens": [50732, 407, 295, 1164, 341, 307, 406, 1553, 3869, 14024, 570, 586, 321, 362, 281, 2028, 365, 577, 281, 574, 50936], "temperature": 0.0, "avg_logprob": -0.15307409386885792, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.014939157292246819}, {"id": 304, "seek": 134270, "start": 1354.14, "end": 1361.54, "text": " up those sub strings or those smaller strings within the bigger structure and so you need", "tokens": [50936, 493, 729, 1422, 13985, 420, 729, 4356, 13985, 1951, 264, 3801, 3877, 293, 370, 291, 643, 51306], "temperature": 0.0, "avg_logprob": -0.15307409386885792, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.014939157292246819}, {"id": 305, "seek": 134270, "start": 1361.54, "end": 1366.82, "text": " a mechanism because you cannot simply look them up in a map or symbol table and obviously", "tokens": [51306, 257, 7513, 570, 291, 2644, 2935, 574, 552, 493, 294, 257, 4471, 420, 5986, 3199, 293, 2745, 51570], "temperature": 0.0, "avg_logprob": -0.15307409386885792, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.014939157292246819}, {"id": 306, "seek": 134270, "start": 1366.82, "end": 1372.26, "text": " another already mentioned complication such as concurrent access you also have to deal", "tokens": [51570, 1071, 1217, 2835, 1209, 8758, 1270, 382, 37702, 2105, 291, 611, 362, 281, 2028, 51842], "temperature": 0.0, "avg_logprob": -0.15307409386885792, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.014939157292246819}, {"id": 307, "seek": 137226, "start": 1372.26, "end": 1377.34, "text": " with this and I think particularly interesting attempt at this is going on in the Prometheus", "tokens": [50364, 365, 341, 293, 286, 519, 4098, 1880, 5217, 412, 341, 307, 516, 322, 294, 264, 2114, 649, 42209, 50618], "temperature": 0.0, "avg_logprob": -0.17889239913538882, "compression_ratio": 1.5539906103286385, "no_speech_prob": 0.012247038073837757}, {"id": 308, "seek": 137226, "start": 1377.34, "end": 1384.1, "text": " project which again this is done by Brian Boren who I mentioned in the previous slides", "tokens": [50618, 1716, 597, 797, 341, 307, 1096, 538, 10765, 363, 10948, 567, 286, 2835, 294, 264, 3894, 9788, 50956], "temperature": 0.0, "avg_logprob": -0.17889239913538882, "compression_ratio": 1.5539906103286385, "no_speech_prob": 0.012247038073837757}, {"id": 309, "seek": 137226, "start": 1384.1, "end": 1391.46, "text": " so if you're interested feel free to check out this PR.", "tokens": [50956, 370, 498, 291, 434, 3102, 841, 1737, 281, 1520, 484, 341, 11568, 13, 51324], "temperature": 0.0, "avg_logprob": -0.17889239913538882, "compression_ratio": 1.5539906103286385, "no_speech_prob": 0.012247038073837757}, {"id": 310, "seek": 137226, "start": 1391.46, "end": 1397.78, "text": " So I will conclude with a few words of caution so I have shown you some optimization techniques", "tokens": [51324, 407, 286, 486, 16886, 365, 257, 1326, 2283, 295, 23585, 370, 286, 362, 4898, 291, 512, 19618, 7512, 51640], "temperature": 0.0, "avg_logprob": -0.17889239913538882, "compression_ratio": 1.5539906103286385, "no_speech_prob": 0.012247038073837757}, {"id": 311, "seek": 139778, "start": 1397.78, "end": 1402.22, "text": " that I found particularly interesting when I was doing my research but let's not be naive", "tokens": [50364, 300, 286, 1352, 4098, 1880, 562, 286, 390, 884, 452, 2132, 457, 718, 311, 406, 312, 29052, 50586], "temperature": 0.0, "avg_logprob": -0.14001969424161045, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.27550458908081055}, {"id": 312, "seek": 139778, "start": 1402.22, "end": 1406.42, "text": " these are not magic ones that will make your program suddenly work faster and with fewer", "tokens": [50586, 613, 366, 406, 5585, 2306, 300, 486, 652, 428, 1461, 5800, 589, 4663, 293, 365, 13366, 50796], "temperature": 0.0, "avg_logprob": -0.14001969424161045, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.27550458908081055}, {"id": 313, "seek": 139778, "start": 1406.42, "end": 1411.78, "text": " resources this is still a balancing exercise so many of the presented techniques can save", "tokens": [50796, 3593, 341, 307, 920, 257, 22495, 5380, 370, 867, 295, 264, 8212, 7512, 393, 3155, 51064], "temperature": 0.0, "avg_logprob": -0.14001969424161045, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.27550458908081055}, {"id": 314, "seek": 139778, "start": 1411.78, "end": 1416.46, "text": " memory but will actually increase the time it takes to retrieve a string so when I mean", "tokens": [51064, 4675, 457, 486, 767, 3488, 264, 565, 309, 2516, 281, 30254, 257, 6798, 370, 562, 286, 914, 51298], "temperature": 0.0, "avg_logprob": -0.14001969424161045, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.27550458908081055}, {"id": 315, "seek": 139778, "start": 1416.46, "end": 1420.98, "text": " optimization this is mostly in a situation where we want to decrease expensive memory", "tokens": [51298, 19618, 341, 307, 5240, 294, 257, 2590, 689, 321, 528, 281, 11514, 5124, 4675, 51524], "temperature": 0.0, "avg_logprob": -0.14001969424161045, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.27550458908081055}, {"id": 316, "seek": 139778, "start": 1420.98, "end": 1427.02, "text": " footprint of our application while sacrificing a bit more CPU a tradeoff that I believe is", "tokens": [51524, 24222, 295, 527, 3861, 1339, 42294, 257, 857, 544, 13199, 257, 4923, 4506, 300, 286, 1697, 307, 51826], "temperature": 0.0, "avg_logprob": -0.14001969424161045, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.27550458908081055}, {"id": 317, "seek": 142702, "start": 1427.02, "end": 1429.7, "text": " reasonable in such setting.", "tokens": [50364, 10585, 294, 1270, 3287, 13, 50498], "temperature": 0.0, "avg_logprob": -0.15744190216064452, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.06437258422374725}, {"id": 318, "seek": 142702, "start": 1429.7, "end": 1434.66, "text": " Also not making any concrete claims about performance improvements of various techniques", "tokens": [50498, 2743, 406, 1455, 604, 9859, 9441, 466, 3389, 13797, 295, 3683, 7512, 50746], "temperature": 0.0, "avg_logprob": -0.15744190216064452, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.06437258422374725}, {"id": 319, "seek": 142702, "start": 1434.66, "end": 1440.42, "text": " as you have seen and I think this nicely ties into the introduction of my talk where I talked", "tokens": [50746, 382, 291, 362, 1612, 293, 286, 519, 341, 9594, 14039, 666, 264, 9339, 295, 452, 751, 689, 286, 2825, 51034], "temperature": 0.0, "avg_logprob": -0.15744190216064452, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.06437258422374725}, {"id": 320, "seek": 142702, "start": 1440.42, "end": 1445.82, "text": " about the need of data data driven optimization so I believe there's still more data points", "tokens": [51034, 466, 264, 643, 295, 1412, 1412, 9555, 19618, 370, 286, 1697, 456, 311, 920, 544, 1412, 2793, 51304], "temperature": 0.0, "avg_logprob": -0.15744190216064452, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.06437258422374725}, {"id": 321, "seek": 142702, "start": 1445.82, "end": 1450.98, "text": " needed to show how well these techniques work in practice how well they can work in your", "tokens": [51304, 2978, 281, 855, 577, 731, 613, 7512, 589, 294, 3124, 577, 731, 436, 393, 589, 294, 428, 51562], "temperature": 0.0, "avg_logprob": -0.15744190216064452, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.06437258422374725}, {"id": 322, "seek": 142702, "start": 1450.98, "end": 1456.62, "text": " specific use case how they compare with each other when it comes to performance and whether", "tokens": [51562, 2685, 764, 1389, 577, 436, 6794, 365, 1184, 661, 562, 309, 1487, 281, 3389, 293, 1968, 51844], "temperature": 0.0, "avg_logprob": -0.15744190216064452, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.06437258422374725}, {"id": 323, "seek": 145662, "start": 1456.62, "end": 1462.54, "text": " there are some other real world implications or maybe properties of go or compiler or the", "tokens": [50364, 456, 366, 512, 661, 957, 1002, 16602, 420, 1310, 7221, 295, 352, 420, 31958, 420, 264, 50660], "temperature": 0.0, "avg_logprob": -0.1546320831566526, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.01244671456515789}, {"id": 324, "seek": 145662, "start": 1462.54, "end": 1470.2199999999998, "text": " runtime that might not render them useful in practice or the performance gain might", "tokens": [50660, 34474, 300, 1062, 406, 15529, 552, 4420, 294, 3124, 420, 264, 3389, 6052, 1062, 51044], "temperature": 0.0, "avg_logprob": -0.1546320831566526, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.01244671456515789}, {"id": 325, "seek": 145662, "start": 1470.2199999999998, "end": 1478.6999999999998, "text": " be negligible so just to say that your mileage might vary but I think these ideas are worth", "tokens": [51044, 312, 32570, 964, 370, 445, 281, 584, 300, 428, 43121, 1062, 10559, 457, 286, 519, 613, 3487, 366, 3163, 51468], "temperature": 0.0, "avg_logprob": -0.1546320831566526, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.01244671456515789}, {"id": 326, "seek": 147870, "start": 1478.7, "end": 1495.94, "text": " exploring and can be interesting and that is all from my side thank you for your attention.", "tokens": [50364, 12736, 293, 393, 312, 1880, 293, 300, 307, 439, 490, 452, 1252, 1309, 291, 337, 428, 3202, 13, 51226], "temperature": 0.0, "avg_logprob": -0.292588730653127, "compression_ratio": 1.3986013986013985, "no_speech_prob": 0.1896025836467743}, {"id": 327, "seek": 147870, "start": 1495.94, "end": 1500.7, "text": " Also included a couple more resources for those who are interested you can find the slides", "tokens": [51226, 2743, 5556, 257, 1916, 544, 3593, 337, 729, 567, 366, 3102, 291, 393, 915, 264, 9788, 51464], "temperature": 0.0, "avg_logprob": -0.292588730653127, "compression_ratio": 1.3986013986013985, "no_speech_prob": 0.1896025836467743}, {"id": 328, "seek": 147870, "start": 1500.7, "end": 1502.5800000000002, "text": " in the PENTA bar.", "tokens": [51464, 294, 264, 430, 2195, 8241, 2159, 13, 51558], "temperature": 0.0, "avg_logprob": -0.292588730653127, "compression_ratio": 1.3986013986013985, "no_speech_prob": 0.1896025836467743}], "language": "en"}