{"text": " So we are at our penultimate talk for this dev room, and we have Mathias Horvat, which I hope I pronounced it right, with the staff software engineer on the Mozilla localization team, and he's going to talk about how you can localize your open-source project with pontoon. Thank you. Hello, everyone. First of all, I would like to thank you all for coming all the way to Brussels to listen to me. I really, really appreciate it. I hope you're having a good day today, and you're going to be having a good day tomorrow. As Francesca said, I'm an engineer with Mozilla for some time now, and today I wanted to talk to you about localization, specifically how we do localization at Mozilla, and hopefully how it can benefit you as well, be it within Mozilla or some Mozilla-related project or not. But first things first, I have to mention something very important. This is Inti. She's my oldest daughter, and she just turned seven today, and her dad is at some conference with Geeks, spending time away from her. But can somebody take a picture of... Thank you for that. Actually brought her to Brussels, so she's here. So we spent like an hour today together, and by the time I get back home, she's going to go to bed. No, I'm kidding. But I actually wanted to make this talk shorter, because I want to spend more time with her, so sorry about that. It's going to be a pretty short talk. And then if you're going to have any questions, Emily, you'll answer them, okay? Is that fine? Thank you. Emily's my colleague over there who's going to do the last talk today. So big round of applause for Emily for being the last to speak today. She really appreciates that. Okay, back to localization and to some serious business. This is actual data. There's just 13% of Firefox users that are based in the U.S. That's maybe not very surprising. What could be a little bit more surprising is that 60% of all Firefox users use non-default locale, which is ENUS, American English. In case it's not obvious, what I'm trying to say is that localization matters. It's actually very important. We all, me included, often think of localization as an obstacle or something that we're going to do later or we're going to do it one day. But it actually really matters because apparently it keeps the door shut if you don't do localization of your software. I want to say a few things first about how localization actually works at Mozilla. It's driven by hundreds if not thousands of contributors, volunteers, who spend their free time contributing to Mozilla because they like it or because they like the products that Mozilla develops or they like the mission or they care about their language. We're truly grateful that we have such an, as we call it, army of awesome people who are, as you saw earlier, basically responsible for 60% of the Firefox market share. There's not just Firefox. As you'll see later, there's many, many more projects that Mozilla localizes. The platform that we use for localization is called Pontoon. It's like a classic translation management system through which localizers interact. But it's basically, as I mentioned, just an interface. The actual strings, the actual English strings and translations are stored in repositories. So usually that's GitHub, I think also GitLab. Sometimes there's also hg.mozilla.org. That's what we call a single source of truth. And then Pontoon is basically just an interface because many of our localizers are surprised, not really developers, don't really want to work with repositories directly. So it's much easier for them to make contributions through a tool that is hopefully not much more complicated to use than, say, email client or Facebook. As you can see from this page, this is a profile page of one of our active localizers. We really like version control systems, in particular GitHub, as you can say, by a particular widget on this page. And the way things work is that localizer would log in, they start by picking their team, their locale, like the localizer's software to French. And they start on the French page, in this case, which has some basic stats, some basic information about the locale in general. And more importantly, at least all the projects that this community localizes. This is a screenshot, so I can't really scroll. There's 35 projects in total that the French community localizes. I think in total we have 36, and they are being translated to over 200 different locales. For those of you who are not familiar, the difference between a language and a locale is that Spanish is one language, but then you have several variants of Spanish, for example, like Spanish Spanish or Argentine Spanish or Mexican Spanish, those are locales. All specific variants. So localizer would go to this page, pick one project, for example, AMO front-end, which is not fully translated yet. And then the translate view opens up, which is again a pretty straightforward page. On the left you see the list of strings, and in the middle you have on top, source string, and then the text field into which you enter translations. And then in the bottom right corner you see two tabs from which translators get some inspiration from. You get suggestions from several machine translation engines, translation memory, and you can also look into how other locales might have translated the same string. There's two ways most of our teams operate in. One is some localizers submit translations directly, which means as soon as they are submitted to Pontoon they end up in the version control system and can be used in product. The alternative and more common way is that localizers just submit suggestions, and those suggestions then need to be approved by our trusted localizers who have worked with localization for some time and have a proven track record of submitting quality translations, and then they get into the repository. So here in this case we're actually seeing on the left we're seeing strings with corresponding suggestions, which are then approved by a reviewer. Maybe one more detail around this. Since you see the source string and the translation also in the sidebar on the left, the status boxes on the left are actually check boxes, so you can select multiple strings and approve them at the same time or reject them all at once. One last thing before I start to stop with the presentation of Pontoon. We're currently working on pre-translation feature, which is essentially engaging machine translation and translation memory, and as soon as source strings get exposed in the repository to be translated, and as soon as they are served to localizers and localizers get notifications, hey, new strings are available, these strings get pre-translated using a combination of translation memory and machine translation. So if we find a perfect match, we would use a translation memory. If we don't find anything usable in translation memory, we fall back to machine translation. This is a pretty controversial topic, because pre-translation can yield interesting results. Thank you. That means that we're really slowly rolling this out for particular project-local combinations, where there's actual needs, where, for example, locales are a little bit falling behind, but at the same time, they have reviewers who are active enough to hop in and correct potential errors that the pre-translation produces. Pontoon is open source, it's freely available, so there's actually other users of Pontoon outside Mozilla. We're not aware of many, maybe a dozen, but we also don't know in case there are more. It's relatively easy to set it up. We sadly don't offer any official support, but if you do come to our discourse, I'm going to show the links at the last slide, or to our chat, chat.mozilla.org. We try to help, but like I said, we don't offer any official support. There are some requirements that need to be met in order for a project to be localized with Pontoon. Obviously, you need to use GitHub or some other VCS backend as a storage for translations. Then you have two options for organizing the files, either you follow a predefined folder structure or you use our Altenand.toml specification, which is then read by Pontoon to detect where the source files are and where the translations are submitted. Obviously, you need to use one of the, you need to store your translations in one of the supported file formats. Here's some of them. You might be familiar with Fluent. This is one of the formats that Mozilla developed. It's now basically slowly being, Emil is going to talk about it in the next talk, is basically transitioning slowly towards message format two, which is the format that is being developed. That's why there's an asterisk at the end. We don't technically have a full-blown support for it yet, but we're working on that. There's also most common file formats are supported by Pontoon. And once your project meets those requirements, you just need to create it on your Pontoon instance, which is typically a very simple step. You need to add a project name, select target locales, and add a link to your repository, and that's basically it. You save it, you sync it, and you have strings ready. Now the tricky part here is that you need your own instance, and that's a little bit more work than filling out this form. Like I said, there is documentation on how to do that in our repository. It is, however, in our minds for some time now. We're testing waters whether there's an interest for us to create something like a multi-tenant Pontoon instance where you wouldn't need to maintain your own instance. You would just come and create your own project there and use that instance. Yeah, that's pretty much it. I would like to end here. This is the link to the repository, obviously, and all the links to this course and to chat that I mentioned and the documentation are there. You can also find me on Matrix or Twitter, sorry, Matt Jazz, or you can send me an email, and I'd be also happy to answer any questions here. Thank you. Thank you very much. So we already have two questions in the Matrix room. Does it support more complex translation like full articles, example given, what we can find on support.modzilla.org? Short answer, no. Pontoon is designed to be software localization translation system, and we currently don't have any support for, yeah, I don't know how to call it, articles, longer blocks of text. We sometimes abuse that, basically, and split some of the articles or some of our web pages by paragraphs into multiple strings, but that's not really it. That's not really the same as Wikipedia localization works or how MDN localization used to work in the past. We have a ticket on file for that probably since the first week, since Pontoon repository was created, but there has been basically no work on that. We do, not only do we try to help you if you want to set up your instance, we're very happy to take patches. This one would be obviously huge. But anything that doesn't interfere with Mozilla needs, we would be definitely happy to support. The reason why we haven't implemented that feature is because at Mozilla there simply was no real need for that, apart from the exceptions that I mentioned earlier. I hope that answers the question. We have another question from Sylvia. I wonder, why does Pontoon exist when other of us translation projects like WebBlade exist? What WebBlade not yet around when the project started? Were there any specific feature design decision you were missing that didn't work with WebBlade? Not to say that Pontoon shouldn't exist, I'm just wondering what its unique selling feature. That's a great question. I think it's good that people have options when they go to the store and they can choose different types of milk or different types of cars. So it's sort of like the same question as why does BMW exist if there's Mercedes? I think Pontoon, I don't know WebBlade too well, I have to admit that. I was at the presentation today and from what I heard I think it's an amazing piece of software. I know that, for example, Mozilla is very eager about supporting natural selling translations through Fluent and Message Format. We have special UI for that. Maybe that also exists in WebBlade, I don't know, but I would guess that no, because Fluent never really passed the borders of Mozilla very intensively. So that would be one of the things that, and the Message Format support which is related to that would be one of the things that comes to my mind. But other than that, I think it's mostly, there's probably a bunch of other tools. I don't know if Puddle is still in development. There's also close source systems. I don't think, I think it's good that people have different choices and somebody likes that type of UI, somebody likes other types of UI. So, can we add support for Firefox translations in addition to Google and Sistran? Is it easy to do? It's very easy to do. Actually we've been, when we started working on pre-translation support, we wanted to only use machine translation engines that could be customized and trained with our own data. And when we were evaluating several engines, obviously Firefox translations was the first on the list. The challenge at that point, and that was maybe half a year ago, things might have changed, was that the quality was a little bit lower, at least from our experience. We were using, I think, BlueScore system, and I think BlueScore was about five to ten percent lower for the locales that were supported by Firefox translations. And it's killing us because we would like to support Firefox translations, and I'm sure that one day we will. The other issue was that, at least at that point, there was maybe a dozen of locales that Firefox translations support, whereas with Altima, it's around 50, and then there's 50 additional supported by the generic engine of Google. So yeah, hopefully we're going to extend support to Firefox translations soon. And it's actually a good point, since adding an engine itself is quite trivial, which we should probably just add it, not to pre-translation, but at least to that machinery tab where you could get suggestions from. Shit, why haven't we done that? Thank you. We do collect that, yes. Oh, sorry, sorry. So the suggestion was that it would be nice to also collect telemetry to see which engine is preferred by users. We actually do that already for each translation that's submitted by just copying it over from translation memory or any of the machine translation engine. We keep track of that, and we can see that, okay, this engine is more likely to be used than the other. So one thing I was wondering regarding, like, Fluent, for example, like other libraries, for example, the translate toolkit does not have support for Fluent yet, and I was wondering if Mozilla was planning to help on the development of Fluent support in the translate toolkit. And another and related thing is that if there are any way of doing, like, validations, verifications, because in our project we have a lot of very beautiful translators, but they are, many times, it's the first time they translate, so, like, they make a lot of mistakes with the HTML, markdown syntax, and if you have any kind of validation. Okay, thank you. So maybe I can split my answer into two pieces, one piece around Fluent support in translate toolkits or maybe some other libraries, and the other question is about whether Pontoon has any sort of quality checks. So the first question. I think Emily will have much better answer to that in the next talk, which is going to be about message format 2.0 standard, which I see, maybe I don't see clearly, Emily is going to correct me, which I see as Fluent 2.0, it's developed under the standardization bodies, and that, I think, means that the wider support in multiple tools is going to come. If you're specifically interested about Fluent and adding Fluent support to translate toolkit, then I think we should definitely talk and see if there's an opportunity for that. It's already supported, so it's not going to be a question. Okay, apparently it's already supported. So, translate toolkit already supports Fluent. That's the answer to the first question. Thank you. The second question about quality checks, and that's actually related to translate toolkit, Fluent uses three different libraries for quality checks. One is actually two are internal Mozilla libraries, and another one is translate toolkit library, which also has its own checks. So yes, if there are any obvious errors that can be automatically detected, we will most likely detect it. There's probably errors that we could detect, but we don't, but I think most of them, most of them we do. We work on improvements to our check system through developers telling us, oh, you broke our product. Okay, apparently our checks are not good enough. So over the years, I think our check system became quite bulletproof. Thank you. We have time for one last question, if someone has one. I don't see anyone. So, thank you very much, everyone, and thank you very much. There's a cake under the seat, just check it out. Okay. Thank you very much. Thank you. Thank you very much, everyone. Thank you very much. There's a cake under the seat.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 16.12, "text": " So we are at our penultimate talk for this dev room, and we have Mathias Horvat, which", "tokens": [50364, 407, 321, 366, 412, 527, 3435, 723, 2905, 751, 337, 341, 1905, 1808, 11, 293, 321, 362, 15776, 4609, 10691, 23352, 11, 597, 51170], "temperature": 0.0, "avg_logprob": -0.3435288248835383, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.23520153760910034}, {"id": 1, "seek": 0, "start": 16.12, "end": 21.16, "text": " I hope I pronounced it right, with the staff software engineer on the Mozilla localization", "tokens": [51170, 286, 1454, 286, 23155, 309, 558, 11, 365, 264, 3525, 4722, 11403, 322, 264, 3335, 26403, 2654, 2144, 51422], "temperature": 0.0, "avg_logprob": -0.3435288248835383, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.23520153760910034}, {"id": 2, "seek": 0, "start": 21.16, "end": 26.36, "text": " team, and he's going to talk about how you can localize your open-source project with", "tokens": [51422, 1469, 11, 293, 415, 311, 516, 281, 751, 466, 577, 291, 393, 2654, 1125, 428, 1269, 12, 41676, 1716, 365, 51682], "temperature": 0.0, "avg_logprob": -0.3435288248835383, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.23520153760910034}, {"id": 3, "seek": 0, "start": 26.36, "end": 27.36, "text": " pontoon.", "tokens": [51682, 18770, 4106, 13, 51732], "temperature": 0.0, "avg_logprob": -0.3435288248835383, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.23520153760910034}, {"id": 4, "seek": 2736, "start": 28.12, "end": 29.12, "text": " Thank you.", "tokens": [50402, 1044, 291, 13, 50452], "temperature": 0.0, "avg_logprob": -0.20920270803023358, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.014481634832918644}, {"id": 5, "seek": 2736, "start": 29.12, "end": 31.12, "text": " Hello, everyone.", "tokens": [50452, 2425, 11, 1518, 13, 50552], "temperature": 0.0, "avg_logprob": -0.20920270803023358, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.014481634832918644}, {"id": 6, "seek": 2736, "start": 31.12, "end": 36.879999999999995, "text": " First of all, I would like to thank you all for coming all the way to Brussels to listen", "tokens": [50552, 2386, 295, 439, 11, 286, 576, 411, 281, 1309, 291, 439, 337, 1348, 439, 264, 636, 281, 38717, 281, 2140, 50840], "temperature": 0.0, "avg_logprob": -0.20920270803023358, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.014481634832918644}, {"id": 7, "seek": 2736, "start": 36.879999999999995, "end": 37.879999999999995, "text": " to me.", "tokens": [50840, 281, 385, 13, 50890], "temperature": 0.0, "avg_logprob": -0.20920270803023358, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.014481634832918644}, {"id": 8, "seek": 2736, "start": 37.879999999999995, "end": 40.28, "text": " I really, really appreciate it.", "tokens": [50890, 286, 534, 11, 534, 4449, 309, 13, 51010], "temperature": 0.0, "avg_logprob": -0.20920270803023358, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.014481634832918644}, {"id": 9, "seek": 2736, "start": 40.28, "end": 46.519999999999996, "text": " I hope you're having a good day today, and you're going to be having a good day tomorrow.", "tokens": [51010, 286, 1454, 291, 434, 1419, 257, 665, 786, 965, 11, 293, 291, 434, 516, 281, 312, 1419, 257, 665, 786, 4153, 13, 51322], "temperature": 0.0, "avg_logprob": -0.20920270803023358, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.014481634832918644}, {"id": 10, "seek": 2736, "start": 46.519999999999996, "end": 52.08, "text": " As Francesca said, I'm an engineer with Mozilla for some time now, and today I wanted to talk", "tokens": [51322, 1018, 31441, 496, 848, 11, 286, 478, 364, 11403, 365, 3335, 26403, 337, 512, 565, 586, 11, 293, 965, 286, 1415, 281, 751, 51600], "temperature": 0.0, "avg_logprob": -0.20920270803023358, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.014481634832918644}, {"id": 11, "seek": 5208, "start": 52.08, "end": 60.8, "text": " to you about localization, specifically how we do localization at Mozilla, and hopefully", "tokens": [50364, 281, 291, 466, 2654, 2144, 11, 4682, 577, 321, 360, 2654, 2144, 412, 3335, 26403, 11, 293, 4696, 50800], "temperature": 0.0, "avg_logprob": -0.1783190369606018, "compression_ratio": 1.55625, "no_speech_prob": 0.10258445143699646}, {"id": 12, "seek": 5208, "start": 60.8, "end": 67.84, "text": " how it can benefit you as well, be it within Mozilla or some Mozilla-related project or", "tokens": [50800, 577, 309, 393, 5121, 291, 382, 731, 11, 312, 309, 1951, 3335, 26403, 420, 512, 3335, 26403, 12, 12004, 1716, 420, 51152], "temperature": 0.0, "avg_logprob": -0.1783190369606018, "compression_ratio": 1.55625, "no_speech_prob": 0.10258445143699646}, {"id": 13, "seek": 5208, "start": 67.84, "end": 70.2, "text": " not.", "tokens": [51152, 406, 13, 51270], "temperature": 0.0, "avg_logprob": -0.1783190369606018, "compression_ratio": 1.55625, "no_speech_prob": 0.10258445143699646}, {"id": 14, "seek": 5208, "start": 70.2, "end": 75.08, "text": " But first things first, I have to mention something very important.", "tokens": [51270, 583, 700, 721, 700, 11, 286, 362, 281, 2152, 746, 588, 1021, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1783190369606018, "compression_ratio": 1.55625, "no_speech_prob": 0.10258445143699646}, {"id": 15, "seek": 7508, "start": 75.08, "end": 76.08, "text": " This is Inti.", "tokens": [50364, 639, 307, 5681, 72, 13, 50414], "temperature": 0.0, "avg_logprob": -0.29542277610465273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.2283945083618164}, {"id": 16, "seek": 7508, "start": 76.08, "end": 84.48, "text": " She's my oldest daughter, and she just turned seven today, and her dad is at some conference", "tokens": [50414, 1240, 311, 452, 14026, 4653, 11, 293, 750, 445, 3574, 3407, 965, 11, 293, 720, 3546, 307, 412, 512, 7586, 50834], "temperature": 0.0, "avg_logprob": -0.29542277610465273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.2283945083618164}, {"id": 17, "seek": 7508, "start": 84.48, "end": 89.92, "text": " with Geeks, spending time away from her.", "tokens": [50834, 365, 2876, 24785, 11, 6434, 565, 1314, 490, 720, 13, 51106], "temperature": 0.0, "avg_logprob": -0.29542277610465273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.2283945083618164}, {"id": 18, "seek": 7508, "start": 89.92, "end": 94.44, "text": " But can somebody take a picture of...", "tokens": [51106, 583, 393, 2618, 747, 257, 3036, 295, 485, 51332], "temperature": 0.0, "avg_logprob": -0.29542277610465273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.2283945083618164}, {"id": 19, "seek": 7508, "start": 94.44, "end": 98.2, "text": " Thank you for that.", "tokens": [51332, 1044, 291, 337, 300, 13, 51520], "temperature": 0.0, "avg_logprob": -0.29542277610465273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.2283945083618164}, {"id": 20, "seek": 7508, "start": 98.2, "end": 101.92, "text": " Actually brought her to Brussels, so she's here.", "tokens": [51520, 5135, 3038, 720, 281, 38717, 11, 370, 750, 311, 510, 13, 51706], "temperature": 0.0, "avg_logprob": -0.29542277610465273, "compression_ratio": 1.3879781420765027, "no_speech_prob": 0.2283945083618164}, {"id": 21, "seek": 10192, "start": 101.92, "end": 107.2, "text": " So we spent like an hour today together, and by the time I get back home, she's going", "tokens": [50364, 407, 321, 4418, 411, 364, 1773, 965, 1214, 11, 293, 538, 264, 565, 286, 483, 646, 1280, 11, 750, 311, 516, 50628], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 22, "seek": 10192, "start": 107.2, "end": 108.2, "text": " to go to bed.", "tokens": [50628, 281, 352, 281, 2901, 13, 50678], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 23, "seek": 10192, "start": 108.2, "end": 110.44, "text": " No, I'm kidding.", "tokens": [50678, 883, 11, 286, 478, 9287, 13, 50790], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 24, "seek": 10192, "start": 110.44, "end": 115.44, "text": " But I actually wanted to make this talk shorter, because I want to spend more time with her,", "tokens": [50790, 583, 286, 767, 1415, 281, 652, 341, 751, 11639, 11, 570, 286, 528, 281, 3496, 544, 565, 365, 720, 11, 51040], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 25, "seek": 10192, "start": 115.44, "end": 116.44, "text": " so sorry about that.", "tokens": [51040, 370, 2597, 466, 300, 13, 51090], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 26, "seek": 10192, "start": 116.44, "end": 118.44, "text": " It's going to be a pretty short talk.", "tokens": [51090, 467, 311, 516, 281, 312, 257, 1238, 2099, 751, 13, 51190], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 27, "seek": 10192, "start": 118.44, "end": 122.4, "text": " And then if you're going to have any questions, Emily, you'll answer them, okay?", "tokens": [51190, 400, 550, 498, 291, 434, 516, 281, 362, 604, 1651, 11, 15034, 11, 291, 603, 1867, 552, 11, 1392, 30, 51388], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 28, "seek": 10192, "start": 122.4, "end": 123.4, "text": " Is that fine?", "tokens": [51388, 1119, 300, 2489, 30, 51438], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 29, "seek": 10192, "start": 123.4, "end": 124.4, "text": " Thank you.", "tokens": [51438, 1044, 291, 13, 51488], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 30, "seek": 10192, "start": 124.4, "end": 127.68, "text": " Emily's my colleague over there who's going to do the last talk today.", "tokens": [51488, 15034, 311, 452, 13532, 670, 456, 567, 311, 516, 281, 360, 264, 1036, 751, 965, 13, 51652], "temperature": 0.0, "avg_logprob": -0.1539583784161192, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.5257143378257751}, {"id": 31, "seek": 12768, "start": 127.68, "end": 134.6, "text": " So big round of applause for Emily for being the last to speak today.", "tokens": [50364, 407, 955, 3098, 295, 9969, 337, 15034, 337, 885, 264, 1036, 281, 1710, 965, 13, 50710], "temperature": 0.0, "avg_logprob": -0.20712888868231522, "compression_ratio": 1.3897435897435897, "no_speech_prob": 0.0066228643991053104}, {"id": 32, "seek": 12768, "start": 134.6, "end": 136.6, "text": " She really appreciates that.", "tokens": [50710, 1240, 534, 3616, 1024, 300, 13, 50810], "temperature": 0.0, "avg_logprob": -0.20712888868231522, "compression_ratio": 1.3897435897435897, "no_speech_prob": 0.0066228643991053104}, {"id": 33, "seek": 12768, "start": 136.6, "end": 145.64000000000001, "text": " Okay, back to localization and to some serious business.", "tokens": [50810, 1033, 11, 646, 281, 2654, 2144, 293, 281, 512, 3156, 1606, 13, 51262], "temperature": 0.0, "avg_logprob": -0.20712888868231522, "compression_ratio": 1.3897435897435897, "no_speech_prob": 0.0066228643991053104}, {"id": 34, "seek": 12768, "start": 145.64000000000001, "end": 146.76000000000002, "text": " This is actual data.", "tokens": [51262, 639, 307, 3539, 1412, 13, 51318], "temperature": 0.0, "avg_logprob": -0.20712888868231522, "compression_ratio": 1.3897435897435897, "no_speech_prob": 0.0066228643991053104}, {"id": 35, "seek": 12768, "start": 146.76000000000002, "end": 151.44, "text": " There's just 13% of Firefox users that are based in the U.S.", "tokens": [51318, 821, 311, 445, 3705, 4, 295, 46613, 5022, 300, 366, 2361, 294, 264, 624, 13, 50, 13, 51552], "temperature": 0.0, "avg_logprob": -0.20712888868231522, "compression_ratio": 1.3897435897435897, "no_speech_prob": 0.0066228643991053104}, {"id": 36, "seek": 12768, "start": 151.44, "end": 153.60000000000002, "text": " That's maybe not very surprising.", "tokens": [51552, 663, 311, 1310, 406, 588, 8830, 13, 51660], "temperature": 0.0, "avg_logprob": -0.20712888868231522, "compression_ratio": 1.3897435897435897, "no_speech_prob": 0.0066228643991053104}, {"id": 37, "seek": 15360, "start": 153.6, "end": 162.28, "text": " What could be a little bit more surprising is that 60% of all Firefox users use non-default", "tokens": [50364, 708, 727, 312, 257, 707, 857, 544, 8830, 307, 300, 4060, 4, 295, 439, 46613, 5022, 764, 2107, 12, 20595, 5107, 50798], "temperature": 0.0, "avg_logprob": -0.11922967032100378, "compression_ratio": 1.4502164502164503, "no_speech_prob": 0.006661948282271624}, {"id": 38, "seek": 15360, "start": 162.28, "end": 167.92, "text": " locale, which is ENUS, American English.", "tokens": [50798, 1628, 1220, 11, 597, 307, 15244, 3447, 11, 2665, 3669, 13, 51080], "temperature": 0.0, "avg_logprob": -0.11922967032100378, "compression_ratio": 1.4502164502164503, "no_speech_prob": 0.006661948282271624}, {"id": 39, "seek": 15360, "start": 167.92, "end": 171.88, "text": " In case it's not obvious, what I'm trying to say is that localization matters.", "tokens": [51080, 682, 1389, 309, 311, 406, 6322, 11, 437, 286, 478, 1382, 281, 584, 307, 300, 2654, 2144, 7001, 13, 51278], "temperature": 0.0, "avg_logprob": -0.11922967032100378, "compression_ratio": 1.4502164502164503, "no_speech_prob": 0.006661948282271624}, {"id": 40, "seek": 15360, "start": 171.88, "end": 174.2, "text": " It's actually very important.", "tokens": [51278, 467, 311, 767, 588, 1021, 13, 51394], "temperature": 0.0, "avg_logprob": -0.11922967032100378, "compression_ratio": 1.4502164502164503, "no_speech_prob": 0.006661948282271624}, {"id": 41, "seek": 15360, "start": 174.2, "end": 181.79999999999998, "text": " We all, me included, often think of localization as an obstacle or something that we're going", "tokens": [51394, 492, 439, 11, 385, 5556, 11, 2049, 519, 295, 2654, 2144, 382, 364, 23112, 420, 746, 300, 321, 434, 516, 51774], "temperature": 0.0, "avg_logprob": -0.11922967032100378, "compression_ratio": 1.4502164502164503, "no_speech_prob": 0.006661948282271624}, {"id": 42, "seek": 18180, "start": 181.8, "end": 185.28, "text": " to do later or we're going to do it one day.", "tokens": [50364, 281, 360, 1780, 420, 321, 434, 516, 281, 360, 309, 472, 786, 13, 50538], "temperature": 0.0, "avg_logprob": -0.16607964038848877, "compression_ratio": 1.5060975609756098, "no_speech_prob": 0.006459645926952362}, {"id": 43, "seek": 18180, "start": 185.28, "end": 197.24, "text": " But it actually really matters because apparently it keeps the door shut if you don't do localization", "tokens": [50538, 583, 309, 767, 534, 7001, 570, 7970, 309, 5965, 264, 2853, 5309, 498, 291, 500, 380, 360, 2654, 2144, 51136], "temperature": 0.0, "avg_logprob": -0.16607964038848877, "compression_ratio": 1.5060975609756098, "no_speech_prob": 0.006459645926952362}, {"id": 44, "seek": 18180, "start": 197.24, "end": 201.68, "text": " of your software.", "tokens": [51136, 295, 428, 4722, 13, 51358], "temperature": 0.0, "avg_logprob": -0.16607964038848877, "compression_ratio": 1.5060975609756098, "no_speech_prob": 0.006459645926952362}, {"id": 45, "seek": 18180, "start": 201.68, "end": 208.68, "text": " I want to say a few things first about how localization actually works at Mozilla.", "tokens": [51358, 286, 528, 281, 584, 257, 1326, 721, 700, 466, 577, 2654, 2144, 767, 1985, 412, 3335, 26403, 13, 51708], "temperature": 0.0, "avg_logprob": -0.16607964038848877, "compression_ratio": 1.5060975609756098, "no_speech_prob": 0.006459645926952362}, {"id": 46, "seek": 20868, "start": 208.68, "end": 218.92000000000002, "text": " It's driven by hundreds if not thousands of contributors, volunteers, who spend their", "tokens": [50364, 467, 311, 9555, 538, 6779, 498, 406, 5383, 295, 45627, 11, 14352, 11, 567, 3496, 641, 50876], "temperature": 0.0, "avg_logprob": -0.15134245310074243, "compression_ratio": 1.6473429951690821, "no_speech_prob": 0.06972578167915344}, {"id": 47, "seek": 20868, "start": 218.92000000000002, "end": 223.84, "text": " free time contributing to Mozilla because they like it or because they like the products", "tokens": [50876, 1737, 565, 19270, 281, 3335, 26403, 570, 436, 411, 309, 420, 570, 436, 411, 264, 3383, 51122], "temperature": 0.0, "avg_logprob": -0.15134245310074243, "compression_ratio": 1.6473429951690821, "no_speech_prob": 0.06972578167915344}, {"id": 48, "seek": 20868, "start": 223.84, "end": 230.84, "text": " that Mozilla develops or they like the mission or they care about their language.", "tokens": [51122, 300, 3335, 26403, 25453, 420, 436, 411, 264, 4447, 420, 436, 1127, 466, 641, 2856, 13, 51472], "temperature": 0.0, "avg_logprob": -0.15134245310074243, "compression_ratio": 1.6473429951690821, "no_speech_prob": 0.06972578167915344}, {"id": 49, "seek": 20868, "start": 230.84, "end": 238.32, "text": " We're truly grateful that we have such an, as we call it, army of awesome people who", "tokens": [51472, 492, 434, 4908, 7941, 300, 321, 362, 1270, 364, 11, 382, 321, 818, 309, 11, 7267, 295, 3476, 561, 567, 51846], "temperature": 0.0, "avg_logprob": -0.15134245310074243, "compression_ratio": 1.6473429951690821, "no_speech_prob": 0.06972578167915344}, {"id": 50, "seek": 23832, "start": 238.32, "end": 245.35999999999999, "text": " are, as you saw earlier, basically responsible for 60% of the Firefox market share.", "tokens": [50364, 366, 11, 382, 291, 1866, 3071, 11, 1936, 6250, 337, 4060, 4, 295, 264, 46613, 2142, 2073, 13, 50716], "temperature": 0.0, "avg_logprob": -0.17252191683141196, "compression_ratio": 1.5205479452054795, "no_speech_prob": 0.007639266084879637}, {"id": 51, "seek": 23832, "start": 245.35999999999999, "end": 246.56, "text": " There's not just Firefox.", "tokens": [50716, 821, 311, 406, 445, 46613, 13, 50776], "temperature": 0.0, "avg_logprob": -0.17252191683141196, "compression_ratio": 1.5205479452054795, "no_speech_prob": 0.007639266084879637}, {"id": 52, "seek": 23832, "start": 246.56, "end": 254.4, "text": " As you'll see later, there's many, many more projects that Mozilla localizes.", "tokens": [50776, 1018, 291, 603, 536, 1780, 11, 456, 311, 867, 11, 867, 544, 4455, 300, 3335, 26403, 2654, 5660, 13, 51168], "temperature": 0.0, "avg_logprob": -0.17252191683141196, "compression_ratio": 1.5205479452054795, "no_speech_prob": 0.007639266084879637}, {"id": 53, "seek": 23832, "start": 254.4, "end": 260.71999999999997, "text": " The platform that we use for localization is called Pontoon.", "tokens": [51168, 440, 3663, 300, 321, 764, 337, 2654, 2144, 307, 1219, 41127, 4106, 13, 51484], "temperature": 0.0, "avg_logprob": -0.17252191683141196, "compression_ratio": 1.5205479452054795, "no_speech_prob": 0.007639266084879637}, {"id": 54, "seek": 23832, "start": 260.71999999999997, "end": 266.8, "text": " It's like a classic translation management system through which localizers interact.", "tokens": [51484, 467, 311, 411, 257, 7230, 12853, 4592, 1185, 807, 597, 2654, 22525, 4648, 13, 51788], "temperature": 0.0, "avg_logprob": -0.17252191683141196, "compression_ratio": 1.5205479452054795, "no_speech_prob": 0.007639266084879637}, {"id": 55, "seek": 26680, "start": 267.8, "end": 270.92, "text": " But it's basically, as I mentioned, just an interface.", "tokens": [50414, 583, 309, 311, 1936, 11, 382, 286, 2835, 11, 445, 364, 9226, 13, 50570], "temperature": 0.0, "avg_logprob": -0.1792749563852946, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0026654505636543036}, {"id": 56, "seek": 26680, "start": 270.92, "end": 278.64, "text": " The actual strings, the actual English strings and translations are stored in repositories.", "tokens": [50570, 440, 3539, 13985, 11, 264, 3539, 3669, 13985, 293, 37578, 366, 12187, 294, 22283, 2083, 13, 50956], "temperature": 0.0, "avg_logprob": -0.1792749563852946, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0026654505636543036}, {"id": 57, "seek": 26680, "start": 278.64, "end": 283.52, "text": " So usually that's GitHub, I think also GitLab.", "tokens": [50956, 407, 2673, 300, 311, 23331, 11, 286, 519, 611, 16939, 37880, 13, 51200], "temperature": 0.0, "avg_logprob": -0.1792749563852946, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0026654505636543036}, {"id": 58, "seek": 26680, "start": 283.52, "end": 287.44, "text": " Sometimes there's also hg.mozilla.org.", "tokens": [51200, 4803, 456, 311, 611, 276, 70, 13, 3280, 26403, 13, 4646, 13, 51396], "temperature": 0.0, "avg_logprob": -0.1792749563852946, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0026654505636543036}, {"id": 59, "seek": 26680, "start": 287.44, "end": 289.72, "text": " That's what we call a single source of truth.", "tokens": [51396, 663, 311, 437, 321, 818, 257, 2167, 4009, 295, 3494, 13, 51510], "temperature": 0.0, "avg_logprob": -0.1792749563852946, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0026654505636543036}, {"id": 60, "seek": 26680, "start": 289.72, "end": 294.76, "text": " And then Pontoon is basically just an interface because many of our localizers are surprised,", "tokens": [51510, 400, 550, 41127, 4106, 307, 1936, 445, 364, 9226, 570, 867, 295, 527, 2654, 22525, 366, 6100, 11, 51762], "temperature": 0.0, "avg_logprob": -0.1792749563852946, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.0026654505636543036}, {"id": 61, "seek": 29476, "start": 294.76, "end": 300.44, "text": " not really developers, don't really want to work with repositories directly.", "tokens": [50364, 406, 534, 8849, 11, 500, 380, 534, 528, 281, 589, 365, 22283, 2083, 3838, 13, 50648], "temperature": 0.0, "avg_logprob": -0.1057322242043235, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.001805741572752595}, {"id": 62, "seek": 29476, "start": 300.44, "end": 307.52, "text": " So it's much easier for them to make contributions through a tool that is hopefully not much", "tokens": [50648, 407, 309, 311, 709, 3571, 337, 552, 281, 652, 15725, 807, 257, 2290, 300, 307, 4696, 406, 709, 51002], "temperature": 0.0, "avg_logprob": -0.1057322242043235, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.001805741572752595}, {"id": 63, "seek": 29476, "start": 307.52, "end": 313.24, "text": " more complicated to use than, say, email client or Facebook.", "tokens": [51002, 544, 6179, 281, 764, 813, 11, 584, 11, 3796, 6423, 420, 4384, 13, 51288], "temperature": 0.0, "avg_logprob": -0.1057322242043235, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.001805741572752595}, {"id": 64, "seek": 29476, "start": 313.24, "end": 319.44, "text": " As you can see from this page, this is a profile page of one of our active localizers.", "tokens": [51288, 1018, 291, 393, 536, 490, 341, 3028, 11, 341, 307, 257, 7964, 3028, 295, 472, 295, 527, 4967, 2654, 22525, 13, 51598], "temperature": 0.0, "avg_logprob": -0.1057322242043235, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.001805741572752595}, {"id": 65, "seek": 31944, "start": 319.44, "end": 326.2, "text": " We really like version control systems, in particular GitHub, as you can say, by a particular", "tokens": [50364, 492, 534, 411, 3037, 1969, 3652, 11, 294, 1729, 23331, 11, 382, 291, 393, 584, 11, 538, 257, 1729, 50702], "temperature": 0.0, "avg_logprob": -0.21932058192011136, "compression_ratio": 1.4971098265895955, "no_speech_prob": 0.0050459676422178745}, {"id": 66, "seek": 31944, "start": 326.2, "end": 329.8, "text": " widget on this page.", "tokens": [50702, 34047, 322, 341, 3028, 13, 50882], "temperature": 0.0, "avg_logprob": -0.21932058192011136, "compression_ratio": 1.4971098265895955, "no_speech_prob": 0.0050459676422178745}, {"id": 67, "seek": 31944, "start": 329.8, "end": 337.36, "text": " And the way things work is that localizer would log in, they start by picking their team,", "tokens": [50882, 400, 264, 636, 721, 589, 307, 300, 2654, 6545, 576, 3565, 294, 11, 436, 722, 538, 8867, 641, 1469, 11, 51260], "temperature": 0.0, "avg_logprob": -0.21932058192011136, "compression_ratio": 1.4971098265895955, "no_speech_prob": 0.0050459676422178745}, {"id": 68, "seek": 31944, "start": 337.36, "end": 344.76, "text": " their locale, like the localizer's software to French.", "tokens": [51260, 641, 1628, 1220, 11, 411, 264, 2654, 6545, 311, 4722, 281, 5522, 13, 51630], "temperature": 0.0, "avg_logprob": -0.21932058192011136, "compression_ratio": 1.4971098265895955, "no_speech_prob": 0.0050459676422178745}, {"id": 69, "seek": 34476, "start": 344.76, "end": 350.32, "text": " And they start on the French page, in this case, which has some basic stats, some basic", "tokens": [50364, 400, 436, 722, 322, 264, 5522, 3028, 11, 294, 341, 1389, 11, 597, 575, 512, 3875, 18152, 11, 512, 3875, 50642], "temperature": 0.0, "avg_logprob": -0.16015465259552003, "compression_ratio": 1.646153846153846, "no_speech_prob": 0.01111365482211113}, {"id": 70, "seek": 34476, "start": 350.32, "end": 352.64, "text": " information about the locale in general.", "tokens": [50642, 1589, 466, 264, 1628, 1220, 294, 2674, 13, 50758], "temperature": 0.0, "avg_logprob": -0.16015465259552003, "compression_ratio": 1.646153846153846, "no_speech_prob": 0.01111365482211113}, {"id": 71, "seek": 34476, "start": 352.64, "end": 359.12, "text": " And more importantly, at least all the projects that this community localizes.", "tokens": [50758, 400, 544, 8906, 11, 412, 1935, 439, 264, 4455, 300, 341, 1768, 2654, 5660, 13, 51082], "temperature": 0.0, "avg_logprob": -0.16015465259552003, "compression_ratio": 1.646153846153846, "no_speech_prob": 0.01111365482211113}, {"id": 72, "seek": 34476, "start": 359.12, "end": 361.8, "text": " This is a screenshot, so I can't really scroll.", "tokens": [51082, 639, 307, 257, 27712, 11, 370, 286, 393, 380, 534, 11369, 13, 51216], "temperature": 0.0, "avg_logprob": -0.16015465259552003, "compression_ratio": 1.646153846153846, "no_speech_prob": 0.01111365482211113}, {"id": 73, "seek": 34476, "start": 361.8, "end": 367.56, "text": " There's 35 projects in total that the French community localizes.", "tokens": [51216, 821, 311, 6976, 4455, 294, 3217, 300, 264, 5522, 1768, 2654, 5660, 13, 51504], "temperature": 0.0, "avg_logprob": -0.16015465259552003, "compression_ratio": 1.646153846153846, "no_speech_prob": 0.01111365482211113}, {"id": 74, "seek": 36756, "start": 367.56, "end": 376.6, "text": " I think in total we have 36, and they are being translated to over 200 different locales.", "tokens": [50364, 286, 519, 294, 3217, 321, 362, 8652, 11, 293, 436, 366, 885, 16805, 281, 670, 2331, 819, 2654, 279, 13, 50816], "temperature": 0.0, "avg_logprob": -0.18297408000532403, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.01684463582932949}, {"id": 75, "seek": 36756, "start": 376.6, "end": 380.4, "text": " For those of you who are not familiar, the difference between a language and a locale", "tokens": [50816, 1171, 729, 295, 291, 567, 366, 406, 4963, 11, 264, 2649, 1296, 257, 2856, 293, 257, 1628, 1220, 51006], "temperature": 0.0, "avg_logprob": -0.18297408000532403, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.01684463582932949}, {"id": 76, "seek": 36756, "start": 380.4, "end": 385.84000000000003, "text": " is that Spanish is one language, but then you have several variants of Spanish, for", "tokens": [51006, 307, 300, 8058, 307, 472, 2856, 11, 457, 550, 291, 362, 2940, 21669, 295, 8058, 11, 337, 51278], "temperature": 0.0, "avg_logprob": -0.18297408000532403, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.01684463582932949}, {"id": 77, "seek": 36756, "start": 385.84000000000003, "end": 394.24, "text": " example, like Spanish Spanish or Argentine Spanish or Mexican Spanish, those are locales.", "tokens": [51278, 1365, 11, 411, 8058, 8058, 420, 15183, 533, 8058, 420, 16164, 8058, 11, 729, 366, 2654, 279, 13, 51698], "temperature": 0.0, "avg_logprob": -0.18297408000532403, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.01684463582932949}, {"id": 78, "seek": 39424, "start": 394.36, "end": 397.96000000000004, "text": " All specific variants.", "tokens": [50370, 1057, 2685, 21669, 13, 50550], "temperature": 0.0, "avg_logprob": -0.20084872877741433, "compression_ratio": 1.5242718446601942, "no_speech_prob": 0.016333619132637978}, {"id": 79, "seek": 39424, "start": 397.96000000000004, "end": 403.88, "text": " So localizer would go to this page, pick one project, for example, AMO front-end, which", "tokens": [50550, 407, 2654, 6545, 576, 352, 281, 341, 3028, 11, 1888, 472, 1716, 11, 337, 1365, 11, 6475, 46, 1868, 12, 521, 11, 597, 50846], "temperature": 0.0, "avg_logprob": -0.20084872877741433, "compression_ratio": 1.5242718446601942, "no_speech_prob": 0.016333619132637978}, {"id": 80, "seek": 39424, "start": 403.88, "end": 408.0, "text": " is not fully translated yet.", "tokens": [50846, 307, 406, 4498, 16805, 1939, 13, 51052], "temperature": 0.0, "avg_logprob": -0.20084872877741433, "compression_ratio": 1.5242718446601942, "no_speech_prob": 0.016333619132637978}, {"id": 81, "seek": 39424, "start": 408.0, "end": 414.56, "text": " And then the translate view opens up, which is again a pretty straightforward page.", "tokens": [51052, 400, 550, 264, 13799, 1910, 9870, 493, 11, 597, 307, 797, 257, 1238, 15325, 3028, 13, 51380], "temperature": 0.0, "avg_logprob": -0.20084872877741433, "compression_ratio": 1.5242718446601942, "no_speech_prob": 0.016333619132637978}, {"id": 82, "seek": 39424, "start": 414.56, "end": 419.68, "text": " On the left you see the list of strings, and in the middle you have on top, source string,", "tokens": [51380, 1282, 264, 1411, 291, 536, 264, 1329, 295, 13985, 11, 293, 294, 264, 2808, 291, 362, 322, 1192, 11, 4009, 6798, 11, 51636], "temperature": 0.0, "avg_logprob": -0.20084872877741433, "compression_ratio": 1.5242718446601942, "no_speech_prob": 0.016333619132637978}, {"id": 83, "seek": 41968, "start": 419.68, "end": 426.36, "text": " and then the text field into which you enter translations.", "tokens": [50364, 293, 550, 264, 2487, 2519, 666, 597, 291, 3242, 37578, 13, 50698], "temperature": 0.0, "avg_logprob": -0.1300119161605835, "compression_ratio": 1.703125, "no_speech_prob": 0.0008269310346804559}, {"id": 84, "seek": 41968, "start": 426.36, "end": 434.40000000000003, "text": " And then in the bottom right corner you see two tabs from which translators get some inspiration", "tokens": [50698, 400, 550, 294, 264, 2767, 558, 4538, 291, 536, 732, 20743, 490, 597, 5105, 3391, 483, 512, 10249, 51100], "temperature": 0.0, "avg_logprob": -0.1300119161605835, "compression_ratio": 1.703125, "no_speech_prob": 0.0008269310346804559}, {"id": 85, "seek": 41968, "start": 434.40000000000003, "end": 435.56, "text": " from.", "tokens": [51100, 490, 13, 51158], "temperature": 0.0, "avg_logprob": -0.1300119161605835, "compression_ratio": 1.703125, "no_speech_prob": 0.0008269310346804559}, {"id": 86, "seek": 41968, "start": 435.56, "end": 441.92, "text": " You get suggestions from several machine translation engines, translation memory, and you can also", "tokens": [51158, 509, 483, 13396, 490, 2940, 3479, 12853, 12982, 11, 12853, 4675, 11, 293, 291, 393, 611, 51476], "temperature": 0.0, "avg_logprob": -0.1300119161605835, "compression_ratio": 1.703125, "no_speech_prob": 0.0008269310346804559}, {"id": 87, "seek": 41968, "start": 441.92, "end": 447.56, "text": " look into how other locales might have translated the same string.", "tokens": [51476, 574, 666, 577, 661, 2654, 279, 1062, 362, 16805, 264, 912, 6798, 13, 51758], "temperature": 0.0, "avg_logprob": -0.1300119161605835, "compression_ratio": 1.703125, "no_speech_prob": 0.0008269310346804559}, {"id": 88, "seek": 44756, "start": 447.6, "end": 452.96, "text": " There's two ways most of our teams operate in.", "tokens": [50366, 821, 311, 732, 2098, 881, 295, 527, 5491, 9651, 294, 13, 50634], "temperature": 0.0, "avg_logprob": -0.15834498405456543, "compression_ratio": 1.56, "no_speech_prob": 0.0036889081820845604}, {"id": 89, "seek": 44756, "start": 452.96, "end": 459.28000000000003, "text": " One is some localizers submit translations directly, which means as soon as they are", "tokens": [50634, 1485, 307, 512, 2654, 22525, 10315, 37578, 3838, 11, 597, 1355, 382, 2321, 382, 436, 366, 50950], "temperature": 0.0, "avg_logprob": -0.15834498405456543, "compression_ratio": 1.56, "no_speech_prob": 0.0036889081820845604}, {"id": 90, "seek": 44756, "start": 459.28000000000003, "end": 466.64, "text": " submitted to Pontoon they end up in the version control system and can be used in product.", "tokens": [50950, 14405, 281, 41127, 4106, 436, 917, 493, 294, 264, 3037, 1969, 1185, 293, 393, 312, 1143, 294, 1674, 13, 51318], "temperature": 0.0, "avg_logprob": -0.15834498405456543, "compression_ratio": 1.56, "no_speech_prob": 0.0036889081820845604}, {"id": 91, "seek": 44756, "start": 466.64, "end": 472.8, "text": " The alternative and more common way is that localizers just submit suggestions, and those", "tokens": [51318, 440, 8535, 293, 544, 2689, 636, 307, 300, 2654, 22525, 445, 10315, 13396, 11, 293, 729, 51626], "temperature": 0.0, "avg_logprob": -0.15834498405456543, "compression_ratio": 1.56, "no_speech_prob": 0.0036889081820845604}, {"id": 92, "seek": 47280, "start": 472.84000000000003, "end": 481.2, "text": " suggestions then need to be approved by our trusted localizers who have worked with localization", "tokens": [50366, 13396, 550, 643, 281, 312, 10826, 538, 527, 16034, 2654, 22525, 567, 362, 2732, 365, 2654, 2144, 50784], "temperature": 0.0, "avg_logprob": -0.20055889177925978, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0007905454258434474}, {"id": 93, "seek": 47280, "start": 481.2, "end": 486.52000000000004, "text": " for some time and have a proven track record of submitting quality translations, and then", "tokens": [50784, 337, 512, 565, 293, 362, 257, 12785, 2837, 2136, 295, 31836, 3125, 37578, 11, 293, 550, 51050], "temperature": 0.0, "avg_logprob": -0.20055889177925978, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0007905454258434474}, {"id": 94, "seek": 47280, "start": 486.52000000000004, "end": 488.88, "text": " they get into the repository.", "tokens": [51050, 436, 483, 666, 264, 25841, 13, 51168], "temperature": 0.0, "avg_logprob": -0.20055889177925978, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0007905454258434474}, {"id": 95, "seek": 47280, "start": 488.88, "end": 494.36, "text": " So here in this case we're actually seeing on the left we're seeing strings with corresponding", "tokens": [51168, 407, 510, 294, 341, 1389, 321, 434, 767, 2577, 322, 264, 1411, 321, 434, 2577, 13985, 365, 11760, 51442], "temperature": 0.0, "avg_logprob": -0.20055889177925978, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0007905454258434474}, {"id": 96, "seek": 47280, "start": 494.36, "end": 500.68, "text": " suggestions, which are then approved by a reviewer.", "tokens": [51442, 13396, 11, 597, 366, 550, 10826, 538, 257, 3131, 260, 13, 51758], "temperature": 0.0, "avg_logprob": -0.20055889177925978, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.0007905454258434474}, {"id": 97, "seek": 50280, "start": 503.8, "end": 506.52000000000004, "text": " Maybe one more detail around this.", "tokens": [50414, 2704, 472, 544, 2607, 926, 341, 13, 50550], "temperature": 0.0, "avg_logprob": -0.1423485062339089, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0006601765635423362}, {"id": 98, "seek": 50280, "start": 506.52000000000004, "end": 514.16, "text": " Since you see the source string and the translation also in the sidebar on the left, the status", "tokens": [50550, 4162, 291, 536, 264, 4009, 6798, 293, 264, 12853, 611, 294, 264, 1252, 5356, 322, 264, 1411, 11, 264, 6558, 50932], "temperature": 0.0, "avg_logprob": -0.1423485062339089, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0006601765635423362}, {"id": 99, "seek": 50280, "start": 514.16, "end": 519.04, "text": " boxes on the left are actually check boxes, so you can select multiple strings and approve", "tokens": [50932, 9002, 322, 264, 1411, 366, 767, 1520, 9002, 11, 370, 291, 393, 3048, 3866, 13985, 293, 18827, 51176], "temperature": 0.0, "avg_logprob": -0.1423485062339089, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0006601765635423362}, {"id": 100, "seek": 50280, "start": 519.04, "end": 526.52, "text": " them at the same time or reject them all at once.", "tokens": [51176, 552, 412, 264, 912, 565, 420, 8248, 552, 439, 412, 1564, 13, 51550], "temperature": 0.0, "avg_logprob": -0.1423485062339089, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0006601765635423362}, {"id": 101, "seek": 52652, "start": 526.52, "end": 533.92, "text": " One last thing before I start to stop with the presentation of Pontoon.", "tokens": [50364, 1485, 1036, 551, 949, 286, 722, 281, 1590, 365, 264, 5860, 295, 41127, 4106, 13, 50734], "temperature": 0.0, "avg_logprob": -0.1604924975214778, "compression_ratio": 1.6919191919191918, "no_speech_prob": 0.015319219790399075}, {"id": 102, "seek": 52652, "start": 533.92, "end": 542.0, "text": " We're currently working on pre-translation feature, which is essentially engaging machine", "tokens": [50734, 492, 434, 4362, 1364, 322, 659, 12, 24999, 24278, 4111, 11, 597, 307, 4476, 11268, 3479, 51138], "temperature": 0.0, "avg_logprob": -0.1604924975214778, "compression_ratio": 1.6919191919191918, "no_speech_prob": 0.015319219790399075}, {"id": 103, "seek": 52652, "start": 542.0, "end": 548.76, "text": " translation and translation memory, and as soon as source strings get exposed in the", "tokens": [51138, 12853, 293, 12853, 4675, 11, 293, 382, 2321, 382, 4009, 13985, 483, 9495, 294, 264, 51476], "temperature": 0.0, "avg_logprob": -0.1604924975214778, "compression_ratio": 1.6919191919191918, "no_speech_prob": 0.015319219790399075}, {"id": 104, "seek": 52652, "start": 548.76, "end": 554.28, "text": " repository to be translated, and as soon as they are served to localizers and localizers", "tokens": [51476, 25841, 281, 312, 16805, 11, 293, 382, 2321, 382, 436, 366, 7584, 281, 2654, 22525, 293, 2654, 22525, 51752], "temperature": 0.0, "avg_logprob": -0.1604924975214778, "compression_ratio": 1.6919191919191918, "no_speech_prob": 0.015319219790399075}, {"id": 105, "seek": 55428, "start": 554.3199999999999, "end": 562.1999999999999, "text": " get notifications, hey, new strings are available, these strings get pre-translated using a combination", "tokens": [50366, 483, 13426, 11, 4177, 11, 777, 13985, 366, 2435, 11, 613, 13985, 483, 659, 12, 24999, 38539, 1228, 257, 6562, 50760], "temperature": 0.0, "avg_logprob": -0.14944417136056082, "compression_ratio": 1.7861271676300579, "no_speech_prob": 0.0008524478180333972}, {"id": 106, "seek": 55428, "start": 562.1999999999999, "end": 566.3199999999999, "text": " of translation memory and machine translation.", "tokens": [50760, 295, 12853, 4675, 293, 3479, 12853, 13, 50966], "temperature": 0.0, "avg_logprob": -0.14944417136056082, "compression_ratio": 1.7861271676300579, "no_speech_prob": 0.0008524478180333972}, {"id": 107, "seek": 55428, "start": 566.3199999999999, "end": 569.76, "text": " So if we find a perfect match, we would use a translation memory.", "tokens": [50966, 407, 498, 321, 915, 257, 2176, 2995, 11, 321, 576, 764, 257, 12853, 4675, 13, 51138], "temperature": 0.0, "avg_logprob": -0.14944417136056082, "compression_ratio": 1.7861271676300579, "no_speech_prob": 0.0008524478180333972}, {"id": 108, "seek": 55428, "start": 569.76, "end": 577.3199999999999, "text": " If we don't find anything usable in translation memory, we fall back to machine translation.", "tokens": [51138, 759, 321, 500, 380, 915, 1340, 29975, 294, 12853, 4675, 11, 321, 2100, 646, 281, 3479, 12853, 13, 51516], "temperature": 0.0, "avg_logprob": -0.14944417136056082, "compression_ratio": 1.7861271676300579, "no_speech_prob": 0.0008524478180333972}, {"id": 109, "seek": 57732, "start": 577.36, "end": 588.36, "text": " This is a pretty controversial topic, because pre-translation can yield interesting results.", "tokens": [50366, 639, 307, 257, 1238, 17323, 4829, 11, 570, 659, 12, 24999, 24278, 393, 11257, 1880, 3542, 13, 50916], "temperature": 0.0, "avg_logprob": -0.2664902728536855, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.0018282325472682714}, {"id": 110, "seek": 57732, "start": 588.36, "end": 592.2, "text": " Thank you.", "tokens": [50916, 1044, 291, 13, 51108], "temperature": 0.0, "avg_logprob": -0.2664902728536855, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.0018282325472682714}, {"id": 111, "seek": 57732, "start": 592.2, "end": 600.1600000000001, "text": " That means that we're really slowly rolling this out for particular project-local combinations,", "tokens": [51108, 663, 1355, 300, 321, 434, 534, 5692, 9439, 341, 484, 337, 1729, 1716, 12, 5842, 304, 21267, 11, 51506], "temperature": 0.0, "avg_logprob": -0.2664902728536855, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.0018282325472682714}, {"id": 112, "seek": 57732, "start": 600.1600000000001, "end": 604.24, "text": " where there's actual needs, where, for example, locales are a little bit falling behind, but", "tokens": [51506, 689, 456, 311, 3539, 2203, 11, 689, 11, 337, 1365, 11, 2654, 279, 366, 257, 707, 857, 7440, 2261, 11, 457, 51710], "temperature": 0.0, "avg_logprob": -0.2664902728536855, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.0018282325472682714}, {"id": 113, "seek": 60424, "start": 604.24, "end": 610.84, "text": " at the same time, they have reviewers who are active enough to hop in and correct potential", "tokens": [50364, 412, 264, 912, 565, 11, 436, 362, 45837, 567, 366, 4967, 1547, 281, 3818, 294, 293, 3006, 3995, 50694], "temperature": 0.0, "avg_logprob": -0.15969755483228107, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.002440044889226556}, {"id": 114, "seek": 60424, "start": 610.84, "end": 615.44, "text": " errors that the pre-translation produces.", "tokens": [50694, 13603, 300, 264, 659, 12, 24999, 24278, 14725, 13, 50924], "temperature": 0.0, "avg_logprob": -0.15969755483228107, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.002440044889226556}, {"id": 115, "seek": 60424, "start": 615.44, "end": 620.08, "text": " Pontoon is open source, it's freely available, so there's actually other users of Pontoon", "tokens": [50924, 41127, 4106, 307, 1269, 4009, 11, 309, 311, 16433, 2435, 11, 370, 456, 311, 767, 661, 5022, 295, 41127, 4106, 51156], "temperature": 0.0, "avg_logprob": -0.15969755483228107, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.002440044889226556}, {"id": 116, "seek": 60424, "start": 620.08, "end": 623.2, "text": " outside Mozilla.", "tokens": [51156, 2380, 3335, 26403, 13, 51312], "temperature": 0.0, "avg_logprob": -0.15969755483228107, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.002440044889226556}, {"id": 117, "seek": 60424, "start": 623.2, "end": 631.76, "text": " We're not aware of many, maybe a dozen, but we also don't know in case there are more.", "tokens": [51312, 492, 434, 406, 3650, 295, 867, 11, 1310, 257, 16654, 11, 457, 321, 611, 500, 380, 458, 294, 1389, 456, 366, 544, 13, 51740], "temperature": 0.0, "avg_logprob": -0.15969755483228107, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.002440044889226556}, {"id": 118, "seek": 63176, "start": 631.76, "end": 635.4399999999999, "text": " It's relatively easy to set it up.", "tokens": [50364, 467, 311, 7226, 1858, 281, 992, 309, 493, 13, 50548], "temperature": 0.0, "avg_logprob": -0.13771915435791016, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.010085145942866802}, {"id": 119, "seek": 63176, "start": 635.4399999999999, "end": 641.96, "text": " We sadly don't offer any official support, but if you do come to our discourse, I'm", "tokens": [50548, 492, 22023, 500, 380, 2626, 604, 4783, 1406, 11, 457, 498, 291, 360, 808, 281, 527, 23938, 11, 286, 478, 50874], "temperature": 0.0, "avg_logprob": -0.13771915435791016, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.010085145942866802}, {"id": 120, "seek": 63176, "start": 641.96, "end": 651.84, "text": " going to show the links at the last slide, or to our chat, chat.mozilla.org.", "tokens": [50874, 516, 281, 855, 264, 6123, 412, 264, 1036, 4137, 11, 420, 281, 527, 5081, 11, 5081, 13, 3280, 26403, 13, 4646, 13, 51368], "temperature": 0.0, "avg_logprob": -0.13771915435791016, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.010085145942866802}, {"id": 121, "seek": 63176, "start": 651.84, "end": 660.96, "text": " We try to help, but like I said, we don't offer any official support.", "tokens": [51368, 492, 853, 281, 854, 11, 457, 411, 286, 848, 11, 321, 500, 380, 2626, 604, 4783, 1406, 13, 51824], "temperature": 0.0, "avg_logprob": -0.13771915435791016, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.010085145942866802}, {"id": 122, "seek": 66096, "start": 660.96, "end": 667.9200000000001, "text": " There are some requirements that need to be met in order for a project to be localized", "tokens": [50364, 821, 366, 512, 7728, 300, 643, 281, 312, 1131, 294, 1668, 337, 257, 1716, 281, 312, 44574, 50712], "temperature": 0.0, "avg_logprob": -0.18513011932373047, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.06922735273838043}, {"id": 123, "seek": 66096, "start": 667.9200000000001, "end": 668.9200000000001, "text": " with Pontoon.", "tokens": [50712, 365, 41127, 4106, 13, 50762], "temperature": 0.0, "avg_logprob": -0.18513011932373047, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.06922735273838043}, {"id": 124, "seek": 66096, "start": 668.9200000000001, "end": 677.6, "text": " Obviously, you need to use GitHub or some other VCS backend as a storage for translations.", "tokens": [50762, 7580, 11, 291, 643, 281, 764, 23331, 420, 512, 661, 691, 26283, 38087, 382, 257, 6725, 337, 37578, 13, 51196], "temperature": 0.0, "avg_logprob": -0.18513011932373047, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.06922735273838043}, {"id": 125, "seek": 66096, "start": 677.6, "end": 682.8000000000001, "text": " Then you have two options for organizing the files, either you follow a predefined folder", "tokens": [51196, 1396, 291, 362, 732, 3956, 337, 17608, 264, 7098, 11, 2139, 291, 1524, 257, 659, 37716, 10820, 51456], "temperature": 0.0, "avg_logprob": -0.18513011932373047, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.06922735273838043}, {"id": 126, "seek": 66096, "start": 682.8000000000001, "end": 690.48, "text": " structure or you use our Altenand.toml specification, which is then read by Pontoon to detect", "tokens": [51456, 3877, 420, 291, 764, 527, 967, 1147, 474, 13, 83, 298, 75, 31256, 11, 597, 307, 550, 1401, 538, 41127, 4106, 281, 5531, 51840], "temperature": 0.0, "avg_logprob": -0.18513011932373047, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.06922735273838043}, {"id": 127, "seek": 69048, "start": 691.2, "end": 700.8000000000001, "text": " where the source files are and where the translations are submitted.", "tokens": [50400, 689, 264, 4009, 7098, 366, 293, 689, 264, 37578, 366, 14405, 13, 50880], "temperature": 0.0, "avg_logprob": -0.2607637023925781, "compression_ratio": 1.6, "no_speech_prob": 0.007055207621306181}, {"id": 128, "seek": 69048, "start": 700.8000000000001, "end": 703.76, "text": " Obviously, you need to use one of the, you need to store your translations in one of", "tokens": [50880, 7580, 11, 291, 643, 281, 764, 472, 295, 264, 11, 291, 643, 281, 3531, 428, 37578, 294, 472, 295, 51028], "temperature": 0.0, "avg_logprob": -0.2607637023925781, "compression_ratio": 1.6, "no_speech_prob": 0.007055207621306181}, {"id": 129, "seek": 69048, "start": 703.76, "end": 705.6, "text": " the supported file formats.", "tokens": [51028, 264, 8104, 3991, 25879, 13, 51120], "temperature": 0.0, "avg_logprob": -0.2607637023925781, "compression_ratio": 1.6, "no_speech_prob": 0.007055207621306181}, {"id": 130, "seek": 69048, "start": 705.6, "end": 709.36, "text": " Here's some of them.", "tokens": [51120, 1692, 311, 512, 295, 552, 13, 51308], "temperature": 0.0, "avg_logprob": -0.2607637023925781, "compression_ratio": 1.6, "no_speech_prob": 0.007055207621306181}, {"id": 131, "seek": 69048, "start": 709.36, "end": 711.08, "text": " You might be familiar with Fluent.", "tokens": [51308, 509, 1062, 312, 4963, 365, 33612, 317, 13, 51394], "temperature": 0.0, "avg_logprob": -0.2607637023925781, "compression_ratio": 1.6, "no_speech_prob": 0.007055207621306181}, {"id": 132, "seek": 69048, "start": 711.08, "end": 717.2, "text": " This is one of the formats that Mozilla developed.", "tokens": [51394, 639, 307, 472, 295, 264, 25879, 300, 3335, 26403, 4743, 13, 51700], "temperature": 0.0, "avg_logprob": -0.2607637023925781, "compression_ratio": 1.6, "no_speech_prob": 0.007055207621306181}, {"id": 133, "seek": 71720, "start": 717.2, "end": 725.5200000000001, "text": " It's now basically slowly being, Emil is going to talk about it in the next talk, is", "tokens": [50364, 467, 311, 586, 1936, 5692, 885, 11, 36983, 307, 516, 281, 751, 466, 309, 294, 264, 958, 751, 11, 307, 50780], "temperature": 0.0, "avg_logprob": -0.21803206626815025, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0021916725672781467}, {"id": 134, "seek": 71720, "start": 725.5200000000001, "end": 731.2800000000001, "text": " basically transitioning slowly towards message format two, which is the format that is being", "tokens": [50780, 1936, 33777, 5692, 3030, 3636, 7877, 732, 11, 597, 307, 264, 7877, 300, 307, 885, 51068], "temperature": 0.0, "avg_logprob": -0.21803206626815025, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0021916725672781467}, {"id": 135, "seek": 71720, "start": 731.2800000000001, "end": 732.2800000000001, "text": " developed.", "tokens": [51068, 4743, 13, 51118], "temperature": 0.0, "avg_logprob": -0.21803206626815025, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0021916725672781467}, {"id": 136, "seek": 71720, "start": 732.2800000000001, "end": 733.6400000000001, "text": " That's why there's an asterisk at the end.", "tokens": [51118, 663, 311, 983, 456, 311, 364, 257, 3120, 7797, 412, 264, 917, 13, 51186], "temperature": 0.0, "avg_logprob": -0.21803206626815025, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0021916725672781467}, {"id": 137, "seek": 71720, "start": 733.6400000000001, "end": 739.6, "text": " We don't technically have a full-blown support for it yet, but we're working on that.", "tokens": [51186, 492, 500, 380, 12120, 362, 257, 1577, 12, 5199, 648, 1406, 337, 309, 1939, 11, 457, 321, 434, 1364, 322, 300, 13, 51484], "temperature": 0.0, "avg_logprob": -0.21803206626815025, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0021916725672781467}, {"id": 138, "seek": 71720, "start": 739.6, "end": 747.1600000000001, "text": " There's also most common file formats are supported by Pontoon.", "tokens": [51484, 821, 311, 611, 881, 2689, 3991, 25879, 366, 8104, 538, 41127, 4106, 13, 51862], "temperature": 0.0, "avg_logprob": -0.21803206626815025, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0021916725672781467}, {"id": 139, "seek": 74716, "start": 747.16, "end": 753.04, "text": " And once your project meets those requirements, you just need to create it on your Pontoon", "tokens": [50364, 400, 1564, 428, 1716, 13961, 729, 7728, 11, 291, 445, 643, 281, 1884, 309, 322, 428, 41127, 4106, 50658], "temperature": 0.0, "avg_logprob": -0.15105359694536993, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.004552384838461876}, {"id": 140, "seek": 74716, "start": 753.04, "end": 757.28, "text": " instance, which is typically a very simple step.", "tokens": [50658, 5197, 11, 597, 307, 5850, 257, 588, 2199, 1823, 13, 50870], "temperature": 0.0, "avg_logprob": -0.15105359694536993, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.004552384838461876}, {"id": 141, "seek": 74716, "start": 757.28, "end": 763.88, "text": " You need to add a project name, select target locales, and add a link to your repository,", "tokens": [50870, 509, 643, 281, 909, 257, 1716, 1315, 11, 3048, 3779, 2654, 279, 11, 293, 909, 257, 2113, 281, 428, 25841, 11, 51200], "temperature": 0.0, "avg_logprob": -0.15105359694536993, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.004552384838461876}, {"id": 142, "seek": 74716, "start": 763.88, "end": 765.16, "text": " and that's basically it.", "tokens": [51200, 293, 300, 311, 1936, 309, 13, 51264], "temperature": 0.0, "avg_logprob": -0.15105359694536993, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.004552384838461876}, {"id": 143, "seek": 74716, "start": 765.16, "end": 768.24, "text": " You save it, you sync it, and you have strings ready.", "tokens": [51264, 509, 3155, 309, 11, 291, 20271, 309, 11, 293, 291, 362, 13985, 1919, 13, 51418], "temperature": 0.0, "avg_logprob": -0.15105359694536993, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.004552384838461876}, {"id": 144, "seek": 74716, "start": 768.24, "end": 773.64, "text": " Now the tricky part here is that you need your own instance, and that's a little bit", "tokens": [51418, 823, 264, 12414, 644, 510, 307, 300, 291, 643, 428, 1065, 5197, 11, 293, 300, 311, 257, 707, 857, 51688], "temperature": 0.0, "avg_logprob": -0.15105359694536993, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.004552384838461876}, {"id": 145, "seek": 77364, "start": 773.64, "end": 777.76, "text": " more work than filling out this form.", "tokens": [50364, 544, 589, 813, 10623, 484, 341, 1254, 13, 50570], "temperature": 0.0, "avg_logprob": -0.16437741179964435, "compression_ratio": 1.4941176470588236, "no_speech_prob": 0.030577315017580986}, {"id": 146, "seek": 77364, "start": 777.76, "end": 784.68, "text": " Like I said, there is documentation on how to do that in our repository.", "tokens": [50570, 1743, 286, 848, 11, 456, 307, 14333, 322, 577, 281, 360, 300, 294, 527, 25841, 13, 50916], "temperature": 0.0, "avg_logprob": -0.16437741179964435, "compression_ratio": 1.4941176470588236, "no_speech_prob": 0.030577315017580986}, {"id": 147, "seek": 77364, "start": 784.68, "end": 790.24, "text": " It is, however, in our minds for some time now.", "tokens": [50916, 467, 307, 11, 4461, 11, 294, 527, 9634, 337, 512, 565, 586, 13, 51194], "temperature": 0.0, "avg_logprob": -0.16437741179964435, "compression_ratio": 1.4941176470588236, "no_speech_prob": 0.030577315017580986}, {"id": 148, "seek": 77364, "start": 790.24, "end": 797.28, "text": " We're testing waters whether there's an interest for us to create something like a multi-tenant", "tokens": [51194, 492, 434, 4997, 12975, 1968, 456, 311, 364, 1179, 337, 505, 281, 1884, 746, 411, 257, 4825, 12, 1147, 394, 51546], "temperature": 0.0, "avg_logprob": -0.16437741179964435, "compression_ratio": 1.4941176470588236, "no_speech_prob": 0.030577315017580986}, {"id": 149, "seek": 79728, "start": 797.28, "end": 802.52, "text": " Pontoon instance where you wouldn't need to maintain your own instance.", "tokens": [50364, 41127, 4106, 5197, 689, 291, 2759, 380, 643, 281, 6909, 428, 1065, 5197, 13, 50626], "temperature": 0.0, "avg_logprob": -0.21494064832988538, "compression_ratio": 1.6761363636363635, "no_speech_prob": 0.00993266236037016}, {"id": 150, "seek": 79728, "start": 802.52, "end": 810.24, "text": " You would just come and create your own project there and use that instance.", "tokens": [50626, 509, 576, 445, 808, 293, 1884, 428, 1065, 1716, 456, 293, 764, 300, 5197, 13, 51012], "temperature": 0.0, "avg_logprob": -0.21494064832988538, "compression_ratio": 1.6761363636363635, "no_speech_prob": 0.00993266236037016}, {"id": 151, "seek": 79728, "start": 810.24, "end": 815.48, "text": " Yeah, that's pretty much it.", "tokens": [51012, 865, 11, 300, 311, 1238, 709, 309, 13, 51274], "temperature": 0.0, "avg_logprob": -0.21494064832988538, "compression_ratio": 1.6761363636363635, "no_speech_prob": 0.00993266236037016}, {"id": 152, "seek": 79728, "start": 815.48, "end": 818.6, "text": " I would like to end here.", "tokens": [51274, 286, 576, 411, 281, 917, 510, 13, 51430], "temperature": 0.0, "avg_logprob": -0.21494064832988538, "compression_ratio": 1.6761363636363635, "no_speech_prob": 0.00993266236037016}, {"id": 153, "seek": 79728, "start": 818.6, "end": 823.68, "text": " This is the link to the repository, obviously, and all the links to this course and to chat", "tokens": [51430, 639, 307, 264, 2113, 281, 264, 25841, 11, 2745, 11, 293, 439, 264, 6123, 281, 341, 1164, 293, 281, 5081, 51684], "temperature": 0.0, "avg_logprob": -0.21494064832988538, "compression_ratio": 1.6761363636363635, "no_speech_prob": 0.00993266236037016}, {"id": 154, "seek": 82368, "start": 823.68, "end": 827.68, "text": " that I mentioned and the documentation are there.", "tokens": [50364, 300, 286, 2835, 293, 264, 14333, 366, 456, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2938821718290255, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.003903856035321951}, {"id": 155, "seek": 82368, "start": 827.68, "end": 834.28, "text": " You can also find me on Matrix or Twitter, sorry, Matt Jazz, or you can send me an email,", "tokens": [50564, 509, 393, 611, 915, 385, 322, 36274, 420, 5794, 11, 2597, 11, 7397, 32213, 11, 420, 291, 393, 2845, 385, 364, 3796, 11, 50894], "temperature": 0.0, "avg_logprob": -0.2938821718290255, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.003903856035321951}, {"id": 156, "seek": 82368, "start": 834.28, "end": 837.4, "text": " and I'd be also happy to answer any questions here.", "tokens": [50894, 293, 286, 1116, 312, 611, 2055, 281, 1867, 604, 1651, 510, 13, 51050], "temperature": 0.0, "avg_logprob": -0.2938821718290255, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.003903856035321951}, {"id": 157, "seek": 82368, "start": 837.4, "end": 839.4, "text": " Thank you.", "tokens": [51050, 1044, 291, 13, 51150], "temperature": 0.0, "avg_logprob": -0.2938821718290255, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.003903856035321951}, {"id": 158, "seek": 82368, "start": 839.4, "end": 846.4399999999999, "text": " Thank you very much.", "tokens": [51150, 1044, 291, 588, 709, 13, 51502], "temperature": 0.0, "avg_logprob": -0.2938821718290255, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.003903856035321951}, {"id": 159, "seek": 82368, "start": 846.4399999999999, "end": 853.04, "text": " So we already have two questions in the Matrix room.", "tokens": [51502, 407, 321, 1217, 362, 732, 1651, 294, 264, 36274, 1808, 13, 51832], "temperature": 0.0, "avg_logprob": -0.2938821718290255, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.003903856035321951}, {"id": 160, "seek": 85304, "start": 854.0, "end": 859.5999999999999, "text": " Does it support more complex translation like full articles, example given, what we", "tokens": [50412, 4402, 309, 1406, 544, 3997, 12853, 411, 1577, 11290, 11, 1365, 2212, 11, 437, 321, 50692], "temperature": 0.0, "avg_logprob": -0.24519895071006684, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.04009291157126427}, {"id": 161, "seek": 85304, "start": 859.5999999999999, "end": 863.24, "text": " can find on support.modzilla.org?", "tokens": [50692, 393, 915, 322, 1406, 13, 8014, 89, 5291, 13, 4646, 30, 50874], "temperature": 0.0, "avg_logprob": -0.24519895071006684, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.04009291157126427}, {"id": 162, "seek": 85304, "start": 863.24, "end": 864.9599999999999, "text": " Short answer, no.", "tokens": [50874, 16881, 1867, 11, 572, 13, 50960], "temperature": 0.0, "avg_logprob": -0.24519895071006684, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.04009291157126427}, {"id": 163, "seek": 85304, "start": 864.9599999999999, "end": 871.0, "text": " Pontoon is designed to be software localization translation system, and we currently don't", "tokens": [50960, 41127, 4106, 307, 4761, 281, 312, 4722, 2654, 2144, 12853, 1185, 11, 293, 321, 4362, 500, 380, 51262], "temperature": 0.0, "avg_logprob": -0.24519895071006684, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.04009291157126427}, {"id": 164, "seek": 85304, "start": 871.0, "end": 880.4, "text": " have any support for, yeah, I don't know how to call it, articles, longer blocks of text.", "tokens": [51262, 362, 604, 1406, 337, 11, 1338, 11, 286, 500, 380, 458, 577, 281, 818, 309, 11, 11290, 11, 2854, 8474, 295, 2487, 13, 51732], "temperature": 0.0, "avg_logprob": -0.24519895071006684, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.04009291157126427}, {"id": 165, "seek": 88040, "start": 880.4, "end": 890.52, "text": " We sometimes abuse that, basically, and split some of the articles or some of our web pages", "tokens": [50364, 492, 2171, 9852, 300, 11, 1936, 11, 293, 7472, 512, 295, 264, 11290, 420, 512, 295, 527, 3670, 7183, 50870], "temperature": 0.0, "avg_logprob": -0.13474633476950906, "compression_ratio": 1.5380116959064327, "no_speech_prob": 0.016789725050330162}, {"id": 166, "seek": 88040, "start": 890.52, "end": 895.1999999999999, "text": " by paragraphs into multiple strings, but that's not really it.", "tokens": [50870, 538, 48910, 666, 3866, 13985, 11, 457, 300, 311, 406, 534, 309, 13, 51104], "temperature": 0.0, "avg_logprob": -0.13474633476950906, "compression_ratio": 1.5380116959064327, "no_speech_prob": 0.016789725050330162}, {"id": 167, "seek": 88040, "start": 895.1999999999999, "end": 902.4399999999999, "text": " That's not really the same as Wikipedia localization works or how MDN localization used to work", "tokens": [51104, 663, 311, 406, 534, 264, 912, 382, 28999, 2654, 2144, 1985, 420, 577, 22521, 45, 2654, 2144, 1143, 281, 589, 51466], "temperature": 0.0, "avg_logprob": -0.13474633476950906, "compression_ratio": 1.5380116959064327, "no_speech_prob": 0.016789725050330162}, {"id": 168, "seek": 88040, "start": 902.4399999999999, "end": 905.8, "text": " in the past.", "tokens": [51466, 294, 264, 1791, 13, 51634], "temperature": 0.0, "avg_logprob": -0.13474633476950906, "compression_ratio": 1.5380116959064327, "no_speech_prob": 0.016789725050330162}, {"id": 169, "seek": 90580, "start": 905.8, "end": 911.5999999999999, "text": " We have a ticket on file for that probably since the first week, since Pontoon repository", "tokens": [50364, 492, 362, 257, 10550, 322, 3991, 337, 300, 1391, 1670, 264, 700, 1243, 11, 1670, 41127, 4106, 25841, 50654], "temperature": 0.0, "avg_logprob": -0.19552853168585363, "compression_ratio": 1.5, "no_speech_prob": 0.03592120483517647}, {"id": 170, "seek": 90580, "start": 911.5999999999999, "end": 917.88, "text": " was created, but there has been basically no work on that.", "tokens": [50654, 390, 2942, 11, 457, 456, 575, 668, 1936, 572, 589, 322, 300, 13, 50968], "temperature": 0.0, "avg_logprob": -0.19552853168585363, "compression_ratio": 1.5, "no_speech_prob": 0.03592120483517647}, {"id": 171, "seek": 90580, "start": 917.88, "end": 926.0, "text": " We do, not only do we try to help you if you want to set up your instance, we're very happy", "tokens": [50968, 492, 360, 11, 406, 787, 360, 321, 853, 281, 854, 291, 498, 291, 528, 281, 992, 493, 428, 5197, 11, 321, 434, 588, 2055, 51374], "temperature": 0.0, "avg_logprob": -0.19552853168585363, "compression_ratio": 1.5, "no_speech_prob": 0.03592120483517647}, {"id": 172, "seek": 90580, "start": 926.0, "end": 927.7199999999999, "text": " to take patches.", "tokens": [51374, 281, 747, 26531, 13, 51460], "temperature": 0.0, "avg_logprob": -0.19552853168585363, "compression_ratio": 1.5, "no_speech_prob": 0.03592120483517647}, {"id": 173, "seek": 90580, "start": 927.7199999999999, "end": 930.4799999999999, "text": " This one would be obviously huge.", "tokens": [51460, 639, 472, 576, 312, 2745, 2603, 13, 51598], "temperature": 0.0, "avg_logprob": -0.19552853168585363, "compression_ratio": 1.5, "no_speech_prob": 0.03592120483517647}, {"id": 174, "seek": 93048, "start": 930.48, "end": 938.28, "text": " But anything that doesn't interfere with Mozilla needs, we would be definitely happy", "tokens": [50364, 583, 1340, 300, 1177, 380, 23946, 365, 3335, 26403, 2203, 11, 321, 576, 312, 2138, 2055, 50754], "temperature": 0.0, "avg_logprob": -0.18660439252853395, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.006522485986351967}, {"id": 175, "seek": 93048, "start": 938.28, "end": 940.2, "text": " to support.", "tokens": [50754, 281, 1406, 13, 50850], "temperature": 0.0, "avg_logprob": -0.18660439252853395, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.006522485986351967}, {"id": 176, "seek": 93048, "start": 940.2, "end": 944.4, "text": " The reason why we haven't implemented that feature is because at Mozilla there simply", "tokens": [50850, 440, 1778, 983, 321, 2378, 380, 12270, 300, 4111, 307, 570, 412, 3335, 26403, 456, 2935, 51060], "temperature": 0.0, "avg_logprob": -0.18660439252853395, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.006522485986351967}, {"id": 177, "seek": 93048, "start": 944.4, "end": 950.44, "text": " was no real need for that, apart from the exceptions that I mentioned earlier.", "tokens": [51060, 390, 572, 957, 643, 337, 300, 11, 4936, 490, 264, 22847, 300, 286, 2835, 3071, 13, 51362], "temperature": 0.0, "avg_logprob": -0.18660439252853395, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.006522485986351967}, {"id": 178, "seek": 93048, "start": 950.44, "end": 953.44, "text": " I hope that answers the question.", "tokens": [51362, 286, 1454, 300, 6338, 264, 1168, 13, 51512], "temperature": 0.0, "avg_logprob": -0.18660439252853395, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.006522485986351967}, {"id": 179, "seek": 93048, "start": 953.44, "end": 956.32, "text": " We have another question from Sylvia.", "tokens": [51512, 492, 362, 1071, 1168, 490, 33349, 11617, 13, 51656], "temperature": 0.0, "avg_logprob": -0.18660439252853395, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.006522485986351967}, {"id": 180, "seek": 95632, "start": 956.32, "end": 962.6400000000001, "text": " I wonder, why does Pontoon exist when other of us translation projects like WebBlade exist?", "tokens": [50364, 286, 2441, 11, 983, 775, 41127, 4106, 2514, 562, 661, 295, 505, 12853, 4455, 411, 9573, 14520, 762, 2514, 30, 50680], "temperature": 0.0, "avg_logprob": -0.1925846966830167, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00635170703753829}, {"id": 181, "seek": 95632, "start": 962.6400000000001, "end": 966.2, "text": " What WebBlade not yet around when the project started?", "tokens": [50680, 708, 9573, 14520, 762, 406, 1939, 926, 562, 264, 1716, 1409, 30, 50858], "temperature": 0.0, "avg_logprob": -0.1925846966830167, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00635170703753829}, {"id": 182, "seek": 95632, "start": 966.2, "end": 971.88, "text": " Were there any specific feature design decision you were missing that didn't work with WebBlade?", "tokens": [50858, 12448, 456, 604, 2685, 4111, 1715, 3537, 291, 645, 5361, 300, 994, 380, 589, 365, 9573, 14520, 762, 30, 51142], "temperature": 0.0, "avg_logprob": -0.1925846966830167, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00635170703753829}, {"id": 183, "seek": 95632, "start": 971.88, "end": 978.72, "text": " Not to say that Pontoon shouldn't exist, I'm just wondering what its unique selling feature.", "tokens": [51142, 1726, 281, 584, 300, 41127, 4106, 4659, 380, 2514, 11, 286, 478, 445, 6359, 437, 1080, 3845, 6511, 4111, 13, 51484], "temperature": 0.0, "avg_logprob": -0.1925846966830167, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00635170703753829}, {"id": 184, "seek": 95632, "start": 978.72, "end": 980.5200000000001, "text": " That's a great question.", "tokens": [51484, 663, 311, 257, 869, 1168, 13, 51574], "temperature": 0.0, "avg_logprob": -0.1925846966830167, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00635170703753829}, {"id": 185, "seek": 95632, "start": 980.5200000000001, "end": 985.48, "text": " I think it's good that people have options when they go to the store and they can choose", "tokens": [51574, 286, 519, 309, 311, 665, 300, 561, 362, 3956, 562, 436, 352, 281, 264, 3531, 293, 436, 393, 2826, 51822], "temperature": 0.0, "avg_logprob": -0.1925846966830167, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00635170703753829}, {"id": 186, "seek": 98548, "start": 985.52, "end": 989.08, "text": " different types of milk or different types of cars.", "tokens": [50366, 819, 3467, 295, 5392, 420, 819, 3467, 295, 5163, 13, 50544], "temperature": 0.0, "avg_logprob": -0.19260041507673853, "compression_ratio": 1.49009900990099, "no_speech_prob": 0.005874400958418846}, {"id": 187, "seek": 98548, "start": 989.08, "end": 995.2, "text": " So it's sort of like the same question as why does BMW exist if there's Mercedes?", "tokens": [50544, 407, 309, 311, 1333, 295, 411, 264, 912, 1168, 382, 983, 775, 21355, 2514, 498, 456, 311, 22899, 30, 50850], "temperature": 0.0, "avg_logprob": -0.19260041507673853, "compression_ratio": 1.49009900990099, "no_speech_prob": 0.005874400958418846}, {"id": 188, "seek": 98548, "start": 995.2, "end": 1000.84, "text": " I think Pontoon, I don't know WebBlade too well, I have to admit that.", "tokens": [50850, 286, 519, 41127, 4106, 11, 286, 500, 380, 458, 9573, 14520, 762, 886, 731, 11, 286, 362, 281, 9796, 300, 13, 51132], "temperature": 0.0, "avg_logprob": -0.19260041507673853, "compression_ratio": 1.49009900990099, "no_speech_prob": 0.005874400958418846}, {"id": 189, "seek": 98548, "start": 1000.84, "end": 1009.16, "text": " I was at the presentation today and from what I heard I think it's an amazing piece of software.", "tokens": [51132, 286, 390, 412, 264, 5860, 965, 293, 490, 437, 286, 2198, 286, 519, 309, 311, 364, 2243, 2522, 295, 4722, 13, 51548], "temperature": 0.0, "avg_logprob": -0.19260041507673853, "compression_ratio": 1.49009900990099, "no_speech_prob": 0.005874400958418846}, {"id": 190, "seek": 100916, "start": 1009.16, "end": 1015.8, "text": " I know that, for example, Mozilla is very eager about supporting natural selling translations", "tokens": [50364, 286, 458, 300, 11, 337, 1365, 11, 3335, 26403, 307, 588, 18259, 466, 7231, 3303, 6511, 37578, 50696], "temperature": 0.0, "avg_logprob": -0.17406986727572904, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.012074166908860207}, {"id": 191, "seek": 100916, "start": 1015.8, "end": 1018.4399999999999, "text": " through Fluent and Message Format.", "tokens": [50696, 807, 33612, 317, 293, 45947, 10126, 267, 13, 50828], "temperature": 0.0, "avg_logprob": -0.17406986727572904, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.012074166908860207}, {"id": 192, "seek": 100916, "start": 1018.4399999999999, "end": 1021.28, "text": " We have special UI for that.", "tokens": [50828, 492, 362, 2121, 15682, 337, 300, 13, 50970], "temperature": 0.0, "avg_logprob": -0.17406986727572904, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.012074166908860207}, {"id": 193, "seek": 100916, "start": 1021.28, "end": 1026.24, "text": " Maybe that also exists in WebBlade, I don't know, but I would guess that no, because Fluent", "tokens": [50970, 2704, 300, 611, 8198, 294, 9573, 14520, 762, 11, 286, 500, 380, 458, 11, 457, 286, 576, 2041, 300, 572, 11, 570, 33612, 317, 51218], "temperature": 0.0, "avg_logprob": -0.17406986727572904, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.012074166908860207}, {"id": 194, "seek": 100916, "start": 1026.24, "end": 1032.12, "text": " never really passed the borders of Mozilla very intensively.", "tokens": [51218, 1128, 534, 4678, 264, 16287, 295, 3335, 26403, 588, 18957, 356, 13, 51512], "temperature": 0.0, "avg_logprob": -0.17406986727572904, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.012074166908860207}, {"id": 195, "seek": 100916, "start": 1032.12, "end": 1037.3999999999999, "text": " So that would be one of the things that, and the Message Format support which is related", "tokens": [51512, 407, 300, 576, 312, 472, 295, 264, 721, 300, 11, 293, 264, 45947, 10126, 267, 1406, 597, 307, 4077, 51776], "temperature": 0.0, "avg_logprob": -0.17406986727572904, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.012074166908860207}, {"id": 196, "seek": 103740, "start": 1037.44, "end": 1040.8000000000002, "text": " to that would be one of the things that comes to my mind.", "tokens": [50366, 281, 300, 576, 312, 472, 295, 264, 721, 300, 1487, 281, 452, 1575, 13, 50534], "temperature": 0.0, "avg_logprob": -0.2257724684111926, "compression_ratio": 1.663594470046083, "no_speech_prob": 0.006577101070433855}, {"id": 197, "seek": 103740, "start": 1040.8000000000002, "end": 1046.44, "text": " But other than that, I think it's mostly, there's probably a bunch of other tools.", "tokens": [50534, 583, 661, 813, 300, 11, 286, 519, 309, 311, 5240, 11, 456, 311, 1391, 257, 3840, 295, 661, 3873, 13, 50816], "temperature": 0.0, "avg_logprob": -0.2257724684111926, "compression_ratio": 1.663594470046083, "no_speech_prob": 0.006577101070433855}, {"id": 198, "seek": 103740, "start": 1046.44, "end": 1049.6000000000001, "text": " I don't know if Puddle is still in development.", "tokens": [50816, 286, 500, 380, 458, 498, 430, 532, 2285, 307, 920, 294, 3250, 13, 50974], "temperature": 0.0, "avg_logprob": -0.2257724684111926, "compression_ratio": 1.663594470046083, "no_speech_prob": 0.006577101070433855}, {"id": 199, "seek": 103740, "start": 1049.6000000000001, "end": 1053.3600000000001, "text": " There's also close source systems.", "tokens": [50974, 821, 311, 611, 1998, 4009, 3652, 13, 51162], "temperature": 0.0, "avg_logprob": -0.2257724684111926, "compression_ratio": 1.663594470046083, "no_speech_prob": 0.006577101070433855}, {"id": 200, "seek": 103740, "start": 1053.3600000000001, "end": 1058.2, "text": " I don't think, I think it's good that people have different choices and somebody likes", "tokens": [51162, 286, 500, 380, 519, 11, 286, 519, 309, 311, 665, 300, 561, 362, 819, 7994, 293, 2618, 5902, 51404], "temperature": 0.0, "avg_logprob": -0.2257724684111926, "compression_ratio": 1.663594470046083, "no_speech_prob": 0.006577101070433855}, {"id": 201, "seek": 103740, "start": 1058.2, "end": 1061.64, "text": " that type of UI, somebody likes other types of UI.", "tokens": [51404, 300, 2010, 295, 15682, 11, 2618, 5902, 661, 3467, 295, 15682, 13, 51576], "temperature": 0.0, "avg_logprob": -0.2257724684111926, "compression_ratio": 1.663594470046083, "no_speech_prob": 0.006577101070433855}, {"id": 202, "seek": 106164, "start": 1061.64, "end": 1078.5200000000002, "text": " So, can we add support for Firefox translations in addition to Google and Sistran?", "tokens": [50364, 407, 11, 393, 321, 909, 1406, 337, 46613, 37578, 294, 4500, 281, 3329, 293, 318, 468, 4257, 30, 51208], "temperature": 0.0, "avg_logprob": -0.32717698415120444, "compression_ratio": 1.4246575342465753, "no_speech_prob": 0.038574427366256714}, {"id": 203, "seek": 106164, "start": 1078.5200000000002, "end": 1080.3200000000002, "text": " Is it easy to do?", "tokens": [51208, 1119, 309, 1858, 281, 360, 30, 51298], "temperature": 0.0, "avg_logprob": -0.32717698415120444, "compression_ratio": 1.4246575342465753, "no_speech_prob": 0.038574427366256714}, {"id": 204, "seek": 106164, "start": 1080.3200000000002, "end": 1082.48, "text": " It's very easy to do.", "tokens": [51298, 467, 311, 588, 1858, 281, 360, 13, 51406], "temperature": 0.0, "avg_logprob": -0.32717698415120444, "compression_ratio": 1.4246575342465753, "no_speech_prob": 0.038574427366256714}, {"id": 205, "seek": 106164, "start": 1082.48, "end": 1091.6000000000001, "text": " Actually we've been, when we started working on pre-translation support, we wanted to", "tokens": [51406, 5135, 321, 600, 668, 11, 562, 321, 1409, 1364, 322, 659, 12, 24999, 24278, 1406, 11, 321, 1415, 281, 51862], "temperature": 0.0, "avg_logprob": -0.32717698415120444, "compression_ratio": 1.4246575342465753, "no_speech_prob": 0.038574427366256714}, {"id": 206, "seek": 109160, "start": 1092.56, "end": 1100.4399999999998, "text": " only use machine translation engines that could be customized and trained with our own data.", "tokens": [50412, 787, 764, 3479, 12853, 12982, 300, 727, 312, 30581, 293, 8895, 365, 527, 1065, 1412, 13, 50806], "temperature": 0.0, "avg_logprob": -0.2147594690322876, "compression_ratio": 1.5026178010471205, "no_speech_prob": 0.0004575976054184139}, {"id": 207, "seek": 109160, "start": 1100.4399999999998, "end": 1108.24, "text": " And when we were evaluating several engines, obviously Firefox translations was the first", "tokens": [50806, 400, 562, 321, 645, 27479, 2940, 12982, 11, 2745, 46613, 37578, 390, 264, 700, 51196], "temperature": 0.0, "avg_logprob": -0.2147594690322876, "compression_ratio": 1.5026178010471205, "no_speech_prob": 0.0004575976054184139}, {"id": 208, "seek": 109160, "start": 1108.24, "end": 1110.04, "text": " on the list.", "tokens": [51196, 322, 264, 1329, 13, 51286], "temperature": 0.0, "avg_logprob": -0.2147594690322876, "compression_ratio": 1.5026178010471205, "no_speech_prob": 0.0004575976054184139}, {"id": 209, "seek": 109160, "start": 1110.04, "end": 1116.1599999999999, "text": " The challenge at that point, and that was maybe half a year ago, things might have changed,", "tokens": [51286, 440, 3430, 412, 300, 935, 11, 293, 300, 390, 1310, 1922, 257, 1064, 2057, 11, 721, 1062, 362, 3105, 11, 51592], "temperature": 0.0, "avg_logprob": -0.2147594690322876, "compression_ratio": 1.5026178010471205, "no_speech_prob": 0.0004575976054184139}, {"id": 210, "seek": 111616, "start": 1116.16, "end": 1124.24, "text": " was that the quality was a little bit lower, at least from our experience.", "tokens": [50364, 390, 300, 264, 3125, 390, 257, 707, 857, 3126, 11, 412, 1935, 490, 527, 1752, 13, 50768], "temperature": 0.0, "avg_logprob": -0.20387972484935413, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.004891398828476667}, {"id": 211, "seek": 111616, "start": 1124.24, "end": 1128.96, "text": " We were using, I think, BlueScore system, and I think BlueScore was about five to ten", "tokens": [50768, 492, 645, 1228, 11, 286, 519, 11, 8510, 50, 12352, 1185, 11, 293, 286, 519, 8510, 50, 12352, 390, 466, 1732, 281, 2064, 51004], "temperature": 0.0, "avg_logprob": -0.20387972484935413, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.004891398828476667}, {"id": 212, "seek": 111616, "start": 1128.96, "end": 1133.8400000000001, "text": " percent lower for the locales that were supported by Firefox translations.", "tokens": [51004, 3043, 3126, 337, 264, 2654, 279, 300, 645, 8104, 538, 46613, 37578, 13, 51248], "temperature": 0.0, "avg_logprob": -0.20387972484935413, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.004891398828476667}, {"id": 213, "seek": 111616, "start": 1133.8400000000001, "end": 1138.92, "text": " And it's killing us because we would like to support Firefox translations, and I'm sure", "tokens": [51248, 400, 309, 311, 8011, 505, 570, 321, 576, 411, 281, 1406, 46613, 37578, 11, 293, 286, 478, 988, 51502], "temperature": 0.0, "avg_logprob": -0.20387972484935413, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.004891398828476667}, {"id": 214, "seek": 111616, "start": 1138.92, "end": 1142.52, "text": " that one day we will.", "tokens": [51502, 300, 472, 786, 321, 486, 13, 51682], "temperature": 0.0, "avg_logprob": -0.20387972484935413, "compression_ratio": 1.6350710900473933, "no_speech_prob": 0.004891398828476667}, {"id": 215, "seek": 114252, "start": 1143.44, "end": 1147.44, "text": " The other issue was that, at least at that point, there was maybe a dozen of locales", "tokens": [50410, 440, 661, 2734, 390, 300, 11, 412, 1935, 412, 300, 935, 11, 456, 390, 1310, 257, 16654, 295, 2654, 279, 50610], "temperature": 0.0, "avg_logprob": -0.2782374131052118, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.012874273583292961}, {"id": 216, "seek": 114252, "start": 1147.44, "end": 1152.6, "text": " that Firefox translations support, whereas with Altima, it's around 50, and then there's", "tokens": [50610, 300, 46613, 37578, 1406, 11, 9735, 365, 15992, 4775, 11, 309, 311, 926, 2625, 11, 293, 550, 456, 311, 50868], "temperature": 0.0, "avg_logprob": -0.2782374131052118, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.012874273583292961}, {"id": 217, "seek": 114252, "start": 1152.6, "end": 1158.8, "text": " 50 additional supported by the generic engine of Google.", "tokens": [50868, 2625, 4497, 8104, 538, 264, 19577, 2848, 295, 3329, 13, 51178], "temperature": 0.0, "avg_logprob": -0.2782374131052118, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.012874273583292961}, {"id": 218, "seek": 114252, "start": 1158.8, "end": 1163.8799999999999, "text": " So yeah, hopefully we're going to extend support to Firefox translations soon.", "tokens": [51178, 407, 1338, 11, 4696, 321, 434, 516, 281, 10101, 1406, 281, 46613, 37578, 2321, 13, 51432], "temperature": 0.0, "avg_logprob": -0.2782374131052118, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.012874273583292961}, {"id": 219, "seek": 114252, "start": 1163.8799999999999, "end": 1170.6399999999999, "text": " And it's actually a good point, since adding an engine itself is quite trivial, which we", "tokens": [51432, 400, 309, 311, 767, 257, 665, 935, 11, 1670, 5127, 364, 2848, 2564, 307, 1596, 26703, 11, 597, 321, 51770], "temperature": 0.0, "avg_logprob": -0.2782374131052118, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.012874273583292961}, {"id": 220, "seek": 117064, "start": 1170.64, "end": 1174.96, "text": " should probably just add it, not to pre-translation, but at least to that machinery tab where you", "tokens": [50364, 820, 1391, 445, 909, 309, 11, 406, 281, 659, 12, 24999, 24278, 11, 457, 412, 1935, 281, 300, 27302, 4421, 689, 291, 50580], "temperature": 0.0, "avg_logprob": -0.29867093316439924, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00197613169439137}, {"id": 221, "seek": 117064, "start": 1174.96, "end": 1176.76, "text": " could get suggestions from.", "tokens": [50580, 727, 483, 13396, 490, 13, 50670], "temperature": 0.0, "avg_logprob": -0.29867093316439924, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00197613169439137}, {"id": 222, "seek": 117064, "start": 1176.76, "end": 1179.68, "text": " Shit, why haven't we done that?", "tokens": [50670, 19593, 11, 983, 2378, 380, 321, 1096, 300, 30, 50816], "temperature": 0.0, "avg_logprob": -0.29867093316439924, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00197613169439137}, {"id": 223, "seek": 117064, "start": 1179.68, "end": 1180.68, "text": " Thank you.", "tokens": [50816, 1044, 291, 13, 50866], "temperature": 0.0, "avg_logprob": -0.29867093316439924, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00197613169439137}, {"id": 224, "seek": 117064, "start": 1180.68, "end": 1188.0800000000002, "text": " We do collect that, yes.", "tokens": [50866, 492, 360, 2500, 300, 11, 2086, 13, 51236], "temperature": 0.0, "avg_logprob": -0.29867093316439924, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00197613169439137}, {"id": 225, "seek": 117064, "start": 1188.0800000000002, "end": 1190.3200000000002, "text": " Oh, sorry, sorry.", "tokens": [51236, 876, 11, 2597, 11, 2597, 13, 51348], "temperature": 0.0, "avg_logprob": -0.29867093316439924, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00197613169439137}, {"id": 226, "seek": 117064, "start": 1190.3200000000002, "end": 1198.72, "text": " So the suggestion was that it would be nice to also collect telemetry to see which engine", "tokens": [51348, 407, 264, 16541, 390, 300, 309, 576, 312, 1481, 281, 611, 2500, 4304, 5537, 627, 281, 536, 597, 2848, 51768], "temperature": 0.0, "avg_logprob": -0.29867093316439924, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00197613169439137}, {"id": 227, "seek": 119872, "start": 1198.72, "end": 1201.56, "text": " is preferred by users.", "tokens": [50364, 307, 16494, 538, 5022, 13, 50506], "temperature": 0.0, "avg_logprob": -0.23051722390311105, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.009610166773200035}, {"id": 228, "seek": 119872, "start": 1201.56, "end": 1207.92, "text": " We actually do that already for each translation that's submitted by just copying it over from", "tokens": [50506, 492, 767, 360, 300, 1217, 337, 1184, 12853, 300, 311, 14405, 538, 445, 27976, 309, 670, 490, 50824], "temperature": 0.0, "avg_logprob": -0.23051722390311105, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.009610166773200035}, {"id": 229, "seek": 119872, "start": 1207.92, "end": 1211.48, "text": " translation memory or any of the machine translation engine.", "tokens": [50824, 12853, 4675, 420, 604, 295, 264, 3479, 12853, 2848, 13, 51002], "temperature": 0.0, "avg_logprob": -0.23051722390311105, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.009610166773200035}, {"id": 230, "seek": 119872, "start": 1211.48, "end": 1217.92, "text": " We keep track of that, and we can see that, okay, this engine is more likely to be used", "tokens": [51002, 492, 1066, 2837, 295, 300, 11, 293, 321, 393, 536, 300, 11, 1392, 11, 341, 2848, 307, 544, 3700, 281, 312, 1143, 51324], "temperature": 0.0, "avg_logprob": -0.23051722390311105, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.009610166773200035}, {"id": 231, "seek": 119872, "start": 1217.92, "end": 1219.92, "text": " than the other.", "tokens": [51324, 813, 264, 661, 13, 51424], "temperature": 0.0, "avg_logprob": -0.23051722390311105, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.009610166773200035}, {"id": 232, "seek": 121992, "start": 1219.92, "end": 1239.76, "text": " So one thing I was wondering regarding, like, Fluent, for example, like other libraries,", "tokens": [50364, 407, 472, 551, 286, 390, 6359, 8595, 11, 411, 11, 33612, 317, 11, 337, 1365, 11, 411, 661, 15148, 11, 51356], "temperature": 0.0, "avg_logprob": -0.29804344177246095, "compression_ratio": 1.4958677685950412, "no_speech_prob": 0.07110603153705597}, {"id": 233, "seek": 121992, "start": 1239.76, "end": 1246.4, "text": " for example, the translate toolkit does not have support for Fluent yet, and I was wondering", "tokens": [51356, 337, 1365, 11, 264, 13799, 40167, 775, 406, 362, 1406, 337, 33612, 317, 1939, 11, 293, 286, 390, 6359, 51688], "temperature": 0.0, "avg_logprob": -0.29804344177246095, "compression_ratio": 1.4958677685950412, "no_speech_prob": 0.07110603153705597}, {"id": 234, "seek": 124640, "start": 1246.4, "end": 1258.0, "text": " if Mozilla was planning to help on the development of Fluent support in the translate toolkit.", "tokens": [50364, 498, 3335, 26403, 390, 5038, 281, 854, 322, 264, 3250, 295, 33612, 317, 1406, 294, 264, 13799, 40167, 13, 50944], "temperature": 0.0, "avg_logprob": -0.2601295692333277, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.08589669317007065}, {"id": 235, "seek": 124640, "start": 1258.0, "end": 1265.0, "text": " And another and related thing is that if there are any way of doing, like, validations, verifications,", "tokens": [50944, 400, 1071, 293, 4077, 551, 307, 300, 498, 456, 366, 604, 636, 295, 884, 11, 411, 11, 7363, 763, 11, 1306, 7833, 11, 51294], "temperature": 0.0, "avg_logprob": -0.2601295692333277, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.08589669317007065}, {"id": 236, "seek": 124640, "start": 1265.0, "end": 1273.0400000000002, "text": " because in our project we have a lot of very beautiful translators, but they are, many", "tokens": [51294, 570, 294, 527, 1716, 321, 362, 257, 688, 295, 588, 2238, 5105, 3391, 11, 457, 436, 366, 11, 867, 51696], "temperature": 0.0, "avg_logprob": -0.2601295692333277, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.08589669317007065}, {"id": 237, "seek": 127304, "start": 1273.04, "end": 1276.92, "text": " times, it's the first time they translate, so, like, they make a lot of mistakes with", "tokens": [50364, 1413, 11, 309, 311, 264, 700, 565, 436, 13799, 11, 370, 11, 411, 11, 436, 652, 257, 688, 295, 8038, 365, 50558], "temperature": 0.0, "avg_logprob": -0.2170770263671875, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.13520033657550812}, {"id": 238, "seek": 127304, "start": 1276.92, "end": 1282.76, "text": " the HTML, markdown syntax, and if you have any kind of validation.", "tokens": [50558, 264, 17995, 11, 1491, 5093, 28431, 11, 293, 498, 291, 362, 604, 733, 295, 24071, 13, 50850], "temperature": 0.0, "avg_logprob": -0.2170770263671875, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.13520033657550812}, {"id": 239, "seek": 127304, "start": 1282.76, "end": 1284.48, "text": " Okay, thank you.", "tokens": [50850, 1033, 11, 1309, 291, 13, 50936], "temperature": 0.0, "avg_logprob": -0.2170770263671875, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.13520033657550812}, {"id": 240, "seek": 127304, "start": 1284.48, "end": 1290.68, "text": " So maybe I can split my answer into two pieces, one piece around Fluent support in translate", "tokens": [50936, 407, 1310, 286, 393, 7472, 452, 1867, 666, 732, 3755, 11, 472, 2522, 926, 33612, 317, 1406, 294, 13799, 51246], "temperature": 0.0, "avg_logprob": -0.2170770263671875, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.13520033657550812}, {"id": 241, "seek": 127304, "start": 1290.68, "end": 1295.32, "text": " toolkits or maybe some other libraries, and the other question is about whether Pontoon", "tokens": [51246, 2290, 74, 1208, 420, 1310, 512, 661, 15148, 11, 293, 264, 661, 1168, 307, 466, 1968, 41127, 4106, 51478], "temperature": 0.0, "avg_logprob": -0.2170770263671875, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.13520033657550812}, {"id": 242, "seek": 127304, "start": 1295.32, "end": 1298.44, "text": " has any sort of quality checks.", "tokens": [51478, 575, 604, 1333, 295, 3125, 13834, 13, 51634], "temperature": 0.0, "avg_logprob": -0.2170770263671875, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.13520033657550812}, {"id": 243, "seek": 129844, "start": 1298.44, "end": 1301.04, "text": " So the first question.", "tokens": [50364, 407, 264, 700, 1168, 13, 50494], "temperature": 0.0, "avg_logprob": -0.1639988238994892, "compression_ratio": 1.5, "no_speech_prob": 0.021374816074967384}, {"id": 244, "seek": 129844, "start": 1301.04, "end": 1306.6000000000001, "text": " I think Emily will have much better answer to that in the next talk, which is going to", "tokens": [50494, 286, 519, 15034, 486, 362, 709, 1101, 1867, 281, 300, 294, 264, 958, 751, 11, 597, 307, 516, 281, 50772], "temperature": 0.0, "avg_logprob": -0.1639988238994892, "compression_ratio": 1.5, "no_speech_prob": 0.021374816074967384}, {"id": 245, "seek": 129844, "start": 1306.6000000000001, "end": 1313.0800000000002, "text": " be about message format 2.0 standard, which I see, maybe I don't see clearly, Emily is", "tokens": [50772, 312, 466, 3636, 7877, 568, 13, 15, 3832, 11, 597, 286, 536, 11, 1310, 286, 500, 380, 536, 4448, 11, 15034, 307, 51096], "temperature": 0.0, "avg_logprob": -0.1639988238994892, "compression_ratio": 1.5, "no_speech_prob": 0.021374816074967384}, {"id": 246, "seek": 129844, "start": 1313.0800000000002, "end": 1323.0800000000002, "text": " going to correct me, which I see as Fluent 2.0, it's developed under the standardization", "tokens": [51096, 516, 281, 3006, 385, 11, 597, 286, 536, 382, 33612, 317, 568, 13, 15, 11, 309, 311, 4743, 833, 264, 3832, 2144, 51596], "temperature": 0.0, "avg_logprob": -0.1639988238994892, "compression_ratio": 1.5, "no_speech_prob": 0.021374816074967384}, {"id": 247, "seek": 132308, "start": 1323.08, "end": 1330.48, "text": " bodies, and that, I think, means that the wider support in multiple tools is going to", "tokens": [50364, 7510, 11, 293, 300, 11, 286, 519, 11, 1355, 300, 264, 11842, 1406, 294, 3866, 3873, 307, 516, 281, 50734], "temperature": 0.0, "avg_logprob": -0.32050580563752545, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.06931546330451965}, {"id": 248, "seek": 132308, "start": 1330.48, "end": 1331.48, "text": " come.", "tokens": [50734, 808, 13, 50784], "temperature": 0.0, "avg_logprob": -0.32050580563752545, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.06931546330451965}, {"id": 249, "seek": 132308, "start": 1331.48, "end": 1337.6, "text": " If you're specifically interested about Fluent and adding Fluent support to translate toolkit,", "tokens": [50784, 759, 291, 434, 4682, 3102, 466, 33612, 317, 293, 5127, 33612, 317, 1406, 281, 13799, 40167, 11, 51090], "temperature": 0.0, "avg_logprob": -0.32050580563752545, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.06931546330451965}, {"id": 250, "seek": 132308, "start": 1337.6, "end": 1343.04, "text": " then I think we should definitely talk and see if there's an opportunity for that.", "tokens": [51090, 550, 286, 519, 321, 820, 2138, 751, 293, 536, 498, 456, 311, 364, 2650, 337, 300, 13, 51362], "temperature": 0.0, "avg_logprob": -0.32050580563752545, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.06931546330451965}, {"id": 251, "seek": 132308, "start": 1343.04, "end": 1346.6799999999998, "text": " It's already supported, so it's not going to be a question.", "tokens": [51362, 467, 311, 1217, 8104, 11, 370, 309, 311, 406, 516, 281, 312, 257, 1168, 13, 51544], "temperature": 0.0, "avg_logprob": -0.32050580563752545, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.06931546330451965}, {"id": 252, "seek": 132308, "start": 1346.6799999999998, "end": 1348.6799999999998, "text": " Okay, apparently it's already supported.", "tokens": [51544, 1033, 11, 7970, 309, 311, 1217, 8104, 13, 51644], "temperature": 0.0, "avg_logprob": -0.32050580563752545, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.06931546330451965}, {"id": 253, "seek": 134868, "start": 1348.68, "end": 1368.68, "text": " So, translate toolkit already supports Fluent.", "tokens": [50364, 407, 11, 13799, 40167, 1217, 9346, 33612, 317, 13, 51364], "temperature": 0.0, "avg_logprob": -0.26619188836280333, "compression_ratio": 1.4728682170542635, "no_speech_prob": 0.01240833941847086}, {"id": 254, "seek": 134868, "start": 1368.68, "end": 1370.2, "text": " That's the answer to the first question.", "tokens": [51364, 663, 311, 264, 1867, 281, 264, 700, 1168, 13, 51440], "temperature": 0.0, "avg_logprob": -0.26619188836280333, "compression_ratio": 1.4728682170542635, "no_speech_prob": 0.01240833941847086}, {"id": 255, "seek": 134868, "start": 1370.2, "end": 1371.2, "text": " Thank you.", "tokens": [51440, 1044, 291, 13, 51490], "temperature": 0.0, "avg_logprob": -0.26619188836280333, "compression_ratio": 1.4728682170542635, "no_speech_prob": 0.01240833941847086}, {"id": 256, "seek": 134868, "start": 1371.2, "end": 1376.68, "text": " The second question about quality checks, and that's actually related to translate toolkit,", "tokens": [51490, 440, 1150, 1168, 466, 3125, 13834, 11, 293, 300, 311, 767, 4077, 281, 13799, 40167, 11, 51764], "temperature": 0.0, "avg_logprob": -0.26619188836280333, "compression_ratio": 1.4728682170542635, "no_speech_prob": 0.01240833941847086}, {"id": 257, "seek": 137668, "start": 1376.68, "end": 1382.6000000000001, "text": " Fluent uses three different libraries for quality checks.", "tokens": [50364, 33612, 317, 4960, 1045, 819, 15148, 337, 3125, 13834, 13, 50660], "temperature": 0.0, "avg_logprob": -0.1579216766357422, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.08506118506193161}, {"id": 258, "seek": 137668, "start": 1382.6000000000001, "end": 1389.3600000000001, "text": " One is actually two are internal Mozilla libraries, and another one is translate toolkit library,", "tokens": [50660, 1485, 307, 767, 732, 366, 6920, 3335, 26403, 15148, 11, 293, 1071, 472, 307, 13799, 40167, 6405, 11, 50998], "temperature": 0.0, "avg_logprob": -0.1579216766357422, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.08506118506193161}, {"id": 259, "seek": 137668, "start": 1389.3600000000001, "end": 1391.24, "text": " which also has its own checks.", "tokens": [50998, 597, 611, 575, 1080, 1065, 13834, 13, 51092], "temperature": 0.0, "avg_logprob": -0.1579216766357422, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.08506118506193161}, {"id": 260, "seek": 137668, "start": 1391.24, "end": 1397.6000000000001, "text": " So yes, if there are any obvious errors that can be automatically detected, we will most", "tokens": [51092, 407, 2086, 11, 498, 456, 366, 604, 6322, 13603, 300, 393, 312, 6772, 21896, 11, 321, 486, 881, 51410], "temperature": 0.0, "avg_logprob": -0.1579216766357422, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.08506118506193161}, {"id": 261, "seek": 137668, "start": 1397.6000000000001, "end": 1398.72, "text": " likely detect it.", "tokens": [51410, 3700, 5531, 309, 13, 51466], "temperature": 0.0, "avg_logprob": -0.1579216766357422, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.08506118506193161}, {"id": 262, "seek": 137668, "start": 1398.72, "end": 1403.68, "text": " There's probably errors that we could detect, but we don't, but I think most of them, most", "tokens": [51466, 821, 311, 1391, 13603, 300, 321, 727, 5531, 11, 457, 321, 500, 380, 11, 457, 286, 519, 881, 295, 552, 11, 881, 51714], "temperature": 0.0, "avg_logprob": -0.1579216766357422, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.08506118506193161}, {"id": 263, "seek": 137668, "start": 1403.68, "end": 1405.6000000000001, "text": " of them we do.", "tokens": [51714, 295, 552, 321, 360, 13, 51810], "temperature": 0.0, "avg_logprob": -0.1579216766357422, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.08506118506193161}, {"id": 264, "seek": 140560, "start": 1405.6, "end": 1412.08, "text": " We work on improvements to our check system through developers telling us, oh, you broke", "tokens": [50364, 492, 589, 322, 13797, 281, 527, 1520, 1185, 807, 8849, 3585, 505, 11, 1954, 11, 291, 6902, 50688], "temperature": 0.0, "avg_logprob": -0.2437026242175734, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.007489622104912996}, {"id": 265, "seek": 140560, "start": 1412.08, "end": 1413.08, "text": " our product.", "tokens": [50688, 527, 1674, 13, 50738], "temperature": 0.0, "avg_logprob": -0.2437026242175734, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.007489622104912996}, {"id": 266, "seek": 140560, "start": 1413.08, "end": 1415.76, "text": " Okay, apparently our checks are not good enough.", "tokens": [50738, 1033, 11, 7970, 527, 13834, 366, 406, 665, 1547, 13, 50872], "temperature": 0.0, "avg_logprob": -0.2437026242175734, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.007489622104912996}, {"id": 267, "seek": 140560, "start": 1415.76, "end": 1420.52, "text": " So over the years, I think our check system became quite bulletproof.", "tokens": [50872, 407, 670, 264, 924, 11, 286, 519, 527, 1520, 1185, 3062, 1596, 11632, 15690, 13, 51110], "temperature": 0.0, "avg_logprob": -0.2437026242175734, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.007489622104912996}, {"id": 268, "seek": 140560, "start": 1420.52, "end": 1421.52, "text": " Thank you.", "tokens": [51110, 1044, 291, 13, 51160], "temperature": 0.0, "avg_logprob": -0.2437026242175734, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.007489622104912996}, {"id": 269, "seek": 140560, "start": 1421.52, "end": 1428.36, "text": " We have time for one last question, if someone has one.", "tokens": [51160, 492, 362, 565, 337, 472, 1036, 1168, 11, 498, 1580, 575, 472, 13, 51502], "temperature": 0.0, "avg_logprob": -0.2437026242175734, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.007489622104912996}, {"id": 270, "seek": 140560, "start": 1428.36, "end": 1431.7199999999998, "text": " I don't see anyone.", "tokens": [51502, 286, 500, 380, 536, 2878, 13, 51670], "temperature": 0.0, "avg_logprob": -0.2437026242175734, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.007489622104912996}, {"id": 271, "seek": 143172, "start": 1431.72, "end": 1437.16, "text": " So, thank you very much, everyone, and thank you very much.", "tokens": [50364, 407, 11, 1309, 291, 588, 709, 11, 1518, 11, 293, 1309, 291, 588, 709, 13, 50636], "temperature": 0.0, "avg_logprob": -0.48243238867782967, "compression_ratio": 2.1842105263157894, "no_speech_prob": 0.2787386476993561}, {"id": 272, "seek": 143172, "start": 1437.16, "end": 1441.0, "text": " There's a cake under the seat, just check it out.", "tokens": [50636, 821, 311, 257, 5908, 833, 264, 6121, 11, 445, 1520, 309, 484, 13, 50828], "temperature": 0.0, "avg_logprob": -0.48243238867782967, "compression_ratio": 2.1842105263157894, "no_speech_prob": 0.2787386476993561}, {"id": 273, "seek": 143172, "start": 1441.0, "end": 1442.0, "text": " Okay.", "tokens": [50828, 1033, 13, 50878], "temperature": 0.0, "avg_logprob": -0.48243238867782967, "compression_ratio": 2.1842105263157894, "no_speech_prob": 0.2787386476993561}, {"id": 274, "seek": 143172, "start": 1442.0, "end": 1443.0, "text": " Thank you very much.", "tokens": [50878, 1044, 291, 588, 709, 13, 50928], "temperature": 0.0, "avg_logprob": -0.48243238867782967, "compression_ratio": 2.1842105263157894, "no_speech_prob": 0.2787386476993561}, {"id": 275, "seek": 143172, "start": 1443.0, "end": 1444.0, "text": " Thank you.", "tokens": [50928, 1044, 291, 13, 50978], "temperature": 0.0, "avg_logprob": -0.48243238867782967, "compression_ratio": 2.1842105263157894, "no_speech_prob": 0.2787386476993561}, {"id": 276, "seek": 143172, "start": 1444.0, "end": 1445.0, "text": " Thank you very much, everyone.", "tokens": [50978, 1044, 291, 588, 709, 11, 1518, 13, 51028], "temperature": 0.0, "avg_logprob": -0.48243238867782967, "compression_ratio": 2.1842105263157894, "no_speech_prob": 0.2787386476993561}, {"id": 277, "seek": 143172, "start": 1445.0, "end": 1446.0, "text": " Thank you very much.", "tokens": [51028, 1044, 291, 588, 709, 13, 51078], "temperature": 0.0, "avg_logprob": -0.48243238867782967, "compression_ratio": 2.1842105263157894, "no_speech_prob": 0.2787386476993561}, {"id": 278, "seek": 143172, "start": 1446.0, "end": 1447.0, "text": " There's a cake under the seat.", "tokens": [51078, 821, 311, 257, 5908, 833, 264, 6121, 13, 51128], "temperature": 0.0, "avg_logprob": -0.48243238867782967, "compression_ratio": 2.1842105263157894, "no_speech_prob": 0.2787386476993561}, {"id": 279, "seek": 143172, "start": 1447.0, "end": 1447.0, "text": "", "tokens": [], "temperature": 0.0, "avg_logprob": -0.48243238867782967, "compression_ratio": 2.1842105263157894, "no_speech_prob": 0.2787386476993561, "words": []}], "language": "en"}