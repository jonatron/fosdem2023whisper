{"text": " Hi everyone, so that's the last speaker of the day, so I'm going to talk about community spot connecting to multiple networks. So Doug already spoke about this in a slightly different way, I'll take a slightly different approach. So first a few things about myself, I'm a software engineer at Cisco working on container networking things, and I'm a maintainer of Calico VPP, which is going to be the topic of this talk. This talk is also a bit particular, it's a result of a collaboration effort with many awesome people like Tajera, Intel mostly and Cisco, and direct on collaboration with Mritika Ganguly, which is a P at Intel, but she sadly couldn't be here today because it's quite far from the US where she lives, but I'll do my best to present her work. So first, a bit of a background story of this work, so in the world of employee applications Kubernetes has really become the solution of choice when it comes to deploying large scale services in various environments because it provides the primitives for scalability, so Metal LB that we saw in a previous talk, services, health checks and so on. It also provides the uniformity of deployment, and it's also far from the sequence, so you don't need to know what you're running on. But coming from the CNF land, so trying to deploy a network function in this environment, the story is not the same. So I'll define a bit more what I mean by CNF because it's a bit different between the standard CNF use case, the 5G one. What I mean by that is, so I'll take an example for the sake of this presentation, so typically what I mean by that is the wire guard head end. For example, you have a customer and you want to deploy a fleet of wire guard head ends to give that user access to a resource in a company network, so typically a very prior printer that everybody wants to access to because people like to print. So the particularity of this use case is that it's dynamic enough to benefit from the abstraction that humanities brings, and I've lost my mouse. So typically load balancing, scheduling and those kinds of things. But it has a lot of specific needs, for example ingress has to be done in a particular way because you have some wire guard encrypted traffic, so typically you want to see which IP it's coming from. You also constrain on how you receive traffic because typically, and that's the place where you need multiple interfaces to go into your pod. And you also require high performance because encrypted traffic, so typically you want those things to run fast and you have a lot of user using them. So not for that printer, but assuming it's a bigger use case. So we tried to design a solution for that. So there are lots of components at play, I'll try to go quickly into them. So in the top we have our application, so here the wire guard VPN head end. We want to deploy it on top of humanity, so we have to choose a CNI, so we want to have it with Calico, mainly because of the cuteness of the cat, but also because it provides a really nice interface into supporting multiple data planes and also a nice BGP integration that allows to tweak the way we process packets. And for carrying packets we use the FDIO's LPP as a data plane that gave us more control on how packets are processed. And so that allowed us to go deeper into the way networks actually manage at a really low level. There are also other components that are going to play, but more on this later. So I'm going to go quickly over Calico and VPP because they have been presented many times. So in short Calico is a community CNI, providing a lot of great features, policies, BGP, support for really huge clusters, and the point that's important for this presentation is that it has a very well-defined control plane data plane interface, allowing to plug new performance oriented software underneath it without much hassle, and that's what we are going to leverage. So we choose to sleep VPP underneath Calico, first because we were originally contributors in this open-source user space networking data plane, so it was a solution of choice. But also it has a lot of cool functionalities that are built in and it's extensible. So I am doing a bit of publicity for the software I'm coming from, but it was a good tool for this use case. And also it's quite fast, so it really fits the needs for this application. So how did we bind the two together? What we do is we built an agent running in a demand set on every node, so deployment is the same as a simple pod, just with more privileges. We registered these agents in Calico as a Calico data plane and used their GRPC interface and their APIs that they exposed to decouple control data plane. That agent listens for Calico events and then programs VPP accordingly. And we also built a series of custom plug-ins for handling that, servicing and so on. And we tweaked the configuration so that things behave nicely in a container-oriented environment. And with all this, we have every brick to bring VPP into the clusters and so to have really control on everything that happens, indeed, the communities networking. How does that happen under the hood? So what happens exactly under the hood, what we do is we swap all the network logic that was happening in Linux to VPP, so from this configuration to there. In order to, so, yeah, the thing is as VPP is a user space stack, we have to do a few things a bit differently compared to what was previously done in Linux. So in order to insert VPP between the host and the network, we will grab the host interface, the uplink, and consume it in VPP with the appropriate driver. And then we restore the host connectivity by creating a turn interface in the host root network main space. So that's the turn tap here. And we replicate everything on that interface, it resists the routes. So basically we insert ourselves as a bump in the wire on the uplink. It's not very network-ish, but it works pretty well in that configuration. And that way we restore pod connectivity as before with turn taps instead of a VIF. We create an interface in every pod. And then everything runs normally, the Calico control plane is running normally on the host and it configures the data plan functions in VPP via the agent. So now we have the green part covered. So all those components run neatly. And what we achieve with that is that when we create a pod, Kubernetes will call Calico, Calico will call VPP. And we can provide an interface that we fully handle on a network network player directly in VPP. But for this specific wire guard add-on application, we need a bit more than that. We need multiple interfaces and we also potentially have overlapping addresses. So we don't really manage where the IPs are going to end. So for the multiple interface part, our goal to show us was to go with multis that provides multiplexing. And we chose also dedicated IPAM that we patched, which we were about because it was quite simple to patch and brought those two pieces in. So when I mean multiple interfaces, what does that exactly contain? So the thing is, the typical Kubernetes deployment looks like this. So each pod has a single interface. And the CNI provides a pod-to-pod connectivity, typically with an encapsulation from node to node. But in our application, we want to differentiate the encrypted traffic from the clear-text traffic, so before and after the head end. But we still want Kubernetes as the end to operate. So we still want the nice things about Kubernetes, so service IPs and everything. So it's not only multiple interfaces, it's really multiple interfaces wired into Kubernetes. So it's more multiple isolated networks. So conceptually, what we needed was the ability to create multiple Kubernetes networks. So each network behaving a bit like a standalone cluster stacked on top of each other. So with this, we request networks that provide complete isolation between each other, meaning that traffic cannot cross from a network to another without going from to the outside world. And so that means that we have to bind Calico, VPP, so on, integration, and multist together to create a model where everybody is aware of that definition of networks, have a catalog of isolated networks, specify the way they are going to communicate from node to node via VXLAN encapsulations, and have a way to propose to attach to those networks with annotations, so that in the end, Kubernetes is aware of these networks and we can still maintain the SDN part of the logic. So the way this works quickly is that the C&I interface will call Calico once per pod. So the thing is, multist will call the C&I Calico once per top all pod interface. And we will in turn receive in origin those calls and we can map those with annotations and do our magics to provide the logic. And having also the IPAM patch allows us to support multiple IPs and to have different realms where the IP lives and gets located from. So from a user's perspective, what we expose is a network catalog where our networks are defining CRDs for now. We are starting a standardization effort to bring that into Kubernetes, but that will probably take time. So right now we kept it that simple with just specifying a V&I using VXLAN by default, just passing a range. And we also keep a network attachment definition from multist with one-to-one mapping to network so that things, we don't change too many things at once. And then we use those networks into the pod definitions. So we reference them the multist way. We can reference them as well in services with dedicated annotations. And so that way we tell our agents to program VP in a way where the services apply only in a specific network. The policy is the same way. And also that gives us the ability for pods to have a bit more tweaking on the parameters exposed on the interface. So to specify the number of queues we want, the queue depth, and also support multiple types. So that gives a lot of flexibility to get the performance right and to get, so first to get the functionalities. So the fact that we have multiple interfaces and so also size them so that the performance is appropriate for the use case that we want to achieve. The last nice feature of this is that as we have GoBGP support, we can pair those networks with the outside world if we have a fabric that's VXLAN and if GoBGP supports it. So that part is still a bit work in progress and there are a lot of things to get right. But that's the end picture we want to go. And this could, so if we put everything together, we would get probably something like that, that looks like that. So basically when the users want to connect to this hypothetical VPN and that hypothetical printer, it would get into the cluster via GoBGP peering, so traffic is going to be attracted to the green network, heat service IP in that network, so get some load balancing across the nodes, then it's going to be deciphered in a pod that then encapsulate traffic and pass it, for example, to a NAT pod running in user space. So here I put another type of interface that is more performance oriented and then exit the cluster on a different VLAN peered with the outside world. So some parts still need to be done, but the general internal logic of the cluster is still something that works and that brings the ability for container networking functions to run unmodified with their multiple interfaces directly in a somewhat regular cluster. So we spoke about improving performance of the network, of the underlying interface, but we can also improve the performance with which the application in the pod consumes their own interfaces. So the standard way applications usually consume packets within pods is via socket APIs. So it's really standard, but you have to go through the kernel and it's a code path that wasn't designed for the performance levels of modern apps. So that's why GSO came up as a network stack optimization. But here with VPP running, it would be nice to be able to bypass the network stack and pass the packets directly from VPP and not touching the kernel. So fortunately, VPP exposes two different ways to consume those interfaces. We'll mostly go into the first one, which is the memory interface. So basically, it's a packet oriented interface standard relying on a memory segment for speed. And this can be leveraged by an application via a simple library. So either GoMemi, PhiliBMMF in C, or DPDK, or even a VPP. And so provide a really high speed way of consuming that extra interface in the pod. And the really nice thing about this is that it brings also the connection between the Kubernetes network, Kubernetes SDN, and the pod into user space, meaning that now that connection lives in a regular C program, we can also leverage. So it's easier to leverage CPU optimizations and new features. And that's where the Silicon re-enters the picture and the work from Mrytka from Intel and their team. So they benchmarked this kind of setup and also introduced an optimization that's coming into the fourth generation Intel Xeon that's called Data Streaming Accelerator. Basically, it's a way to optimize copies between processes on some CPUs. And so what they did is compare the performance that we get with the Kubernetes clusters, multiple interfaces, and a simple pod. So not bringing in the old VPN logic, just doing L3 patch and seeing how fast things could go between regular kernel interfaces, the turn, the memory interfaces, and the memory interfaces leveraging those optimizations in the CPU. So that gives those graphs that are really, so that have a lot of numbers in them. But basically, I try to sum up quite quickly what this gives. There are two MTUs, 1,500 bytes and 9,000 bytes here. The performance for turn interfaces in dark blue. Blue is the first MAMIF and the DSA optimized MAMIF is in yellow. And basically, what this gives is that the performance is really, so it brings really a huge difference between, so, sorry, throughput with DSA is 2.3 times faster than with regular MAMIF for the 1,500 bytes packets. And if you go with DSA enabled, it's 23 times faster than turn tap. And with a 9,000 byte MTU, basically, you get more than 60 times faster with the MAMIF that's optimized with DSA. Basically the digit, so the number that's really interesting is that with 200,000, so basically you get a single call doing 100 Gs with that. And that without too much modifications of the applications. So basically, you just spin a regular cluster. If the CPU supports it, you use a regular library and you're able to consume packets at really huge speeds without modifying the application too much. So there is another graph looking into the scaling with number of calls, both with small MTUs and large MTUs. Basically that shows that we can spare calls when going, so turn tap does not scale very well. So the regular MAMIF scales with 1 to 6 calls and DSA achieves the same results with 2 to 3 less calls than its regular MAMIF counterpart. So basically you achieve 100 Gs, which was the limit of the setup with a single call in the case of large MTUs and 3 calls in the case of smaller MTUs. So that's all for the talk. Sorry I went into a variety of different subjects because that topic goes into a lot of different directions. Basically that was to give you another view of the duration we are trying to go, trying to bring all those pieces together in a framework that allows us to make those CNFs run into a community environment. This work is open source. There are the details of the tests that were done in the following slides. You can find us on GitHub and there is also a Slack channel open where you can ask questions. And we have a new release coming up in Beta aiming for GA that's going to go without soon. So thanks a lot for listening, so here are the details. And I'm open for questions if you have any. Just one question for the sake of it, have you ever thought about some shared memory between the different parts to eliminate the need to copy over the packets? So we thought of this, so there are different ways to do that. So there is the VCR which I haven't spoken about, which is a way of opening the sockets directly in VPP. So basically you do a list in VPP for TCP, UDP or given protocol, so like the sockets APIs. And that supports directly, so basically the data never leaves VPP and you can do direct copies between processes without having to copy because everything stays in VPP in the end. For MMF, we don't support that out of the box but nothing forbids you to spawn two pods, make them share a socket and it's only shared memory so you can directly do it without having to spin up the whole thing. So you could even do that in any cluster or directly on bare metal. So MMF is really a lightweight protocol so you can do that just with a regular socket. Okay, cool, thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 15.48, "text": " Hi everyone, so that's the last speaker of the day, so I'm going to talk about community", "tokens": [2421, 1518, 11, 370, 300, 311, 264, 1036, 8145, 295, 264, 786, 11, 370, 286, 478, 516, 281, 751, 466, 1768], "temperature": 0.0, "avg_logprob": -0.3490610959237082, "compression_ratio": 1.4774193548387098, "no_speech_prob": 0.19740097224712372}, {"id": 1, "seek": 0, "start": 15.48, "end": 18.64, "text": " spot connecting to multiple networks.", "tokens": [4008, 11015, 281, 3866, 9590, 13], "temperature": 0.0, "avg_logprob": -0.3490610959237082, "compression_ratio": 1.4774193548387098, "no_speech_prob": 0.19740097224712372}, {"id": 2, "seek": 0, "start": 18.64, "end": 24.36, "text": " So Doug already spoke about this in a slightly different way, I'll take a slightly different", "tokens": [407, 12742, 1217, 7179, 466, 341, 294, 257, 4748, 819, 636, 11, 286, 603, 747, 257, 4748, 819], "temperature": 0.0, "avg_logprob": -0.3490610959237082, "compression_ratio": 1.4774193548387098, "no_speech_prob": 0.19740097224712372}, {"id": 3, "seek": 0, "start": 24.36, "end": 26.36, "text": " approach.", "tokens": [3109, 13], "temperature": 0.0, "avg_logprob": -0.3490610959237082, "compression_ratio": 1.4774193548387098, "no_speech_prob": 0.19740097224712372}, {"id": 4, "seek": 2636, "start": 26.36, "end": 31.36, "text": " So first a few things about myself, I'm a software engineer at Cisco working on container", "tokens": [407, 700, 257, 1326, 721, 466, 2059, 11, 286, 478, 257, 4722, 11403, 412, 38528, 1364, 322, 10129], "temperature": 0.0, "avg_logprob": -0.2483788351727347, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.000980925397016108}, {"id": 5, "seek": 2636, "start": 31.36, "end": 37.4, "text": " networking things, and I'm a maintainer of Calico VPP, which is going to be the topic", "tokens": [17985, 721, 11, 293, 286, 478, 257, 6909, 260, 295, 3511, 2789, 691, 17755, 11, 597, 307, 516, 281, 312, 264, 4829], "temperature": 0.0, "avg_logprob": -0.2483788351727347, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.000980925397016108}, {"id": 6, "seek": 2636, "start": 37.4, "end": 38.4, "text": " of this talk.", "tokens": [295, 341, 751, 13], "temperature": 0.0, "avg_logprob": -0.2483788351727347, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.000980925397016108}, {"id": 7, "seek": 2636, "start": 38.4, "end": 43.16, "text": " This talk is also a bit particular, it's a result of a collaboration effort with many", "tokens": [639, 751, 307, 611, 257, 857, 1729, 11, 309, 311, 257, 1874, 295, 257, 9363, 4630, 365, 867], "temperature": 0.0, "avg_logprob": -0.2483788351727347, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.000980925397016108}, {"id": 8, "seek": 2636, "start": 43.16, "end": 49.04, "text": " awesome people like Tajera, Intel mostly and Cisco, and direct on collaboration with", "tokens": [3476, 561, 411, 314, 1805, 1663, 11, 19762, 5240, 293, 38528, 11, 293, 2047, 322, 9363, 365], "temperature": 0.0, "avg_logprob": -0.2483788351727347, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.000980925397016108}, {"id": 9, "seek": 2636, "start": 49.04, "end": 54.519999999999996, "text": " Mritika Ganguly, which is a P at Intel, but she sadly couldn't be here today because it's", "tokens": [376, 3210, 5439, 17984, 3540, 11, 597, 307, 257, 430, 412, 19762, 11, 457, 750, 22023, 2809, 380, 312, 510, 965, 570, 309, 311], "temperature": 0.0, "avg_logprob": -0.2483788351727347, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.000980925397016108}, {"id": 10, "seek": 5452, "start": 54.52, "end": 62.92, "text": " quite far from the US where she lives, but I'll do my best to present her work.", "tokens": [1596, 1400, 490, 264, 2546, 689, 750, 2909, 11, 457, 286, 603, 360, 452, 1151, 281, 1974, 720, 589, 13], "temperature": 0.0, "avg_logprob": -0.20936154715622526, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.00029922820976935327}, {"id": 11, "seek": 5452, "start": 62.92, "end": 69.0, "text": " So first, a bit of a background story of this work, so in the world of employee applications", "tokens": [407, 700, 11, 257, 857, 295, 257, 3678, 1657, 295, 341, 589, 11, 370, 294, 264, 1002, 295, 10738, 5821], "temperature": 0.0, "avg_logprob": -0.20936154715622526, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.00029922820976935327}, {"id": 12, "seek": 5452, "start": 69.0, "end": 76.28, "text": " Kubernetes has really become the solution of choice when it comes to deploying large", "tokens": [23145, 575, 534, 1813, 264, 3827, 295, 3922, 562, 309, 1487, 281, 34198, 2416], "temperature": 0.0, "avg_logprob": -0.20936154715622526, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.00029922820976935327}, {"id": 13, "seek": 5452, "start": 76.28, "end": 82.88, "text": " scale services in various environments because it provides the primitives for scalability,", "tokens": [4373, 3328, 294, 3683, 12388, 570, 309, 6417, 264, 2886, 38970, 337, 15664, 2310, 11], "temperature": 0.0, "avg_logprob": -0.20936154715622526, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.00029922820976935327}, {"id": 14, "seek": 8288, "start": 82.88, "end": 88.32, "text": " so Metal LB that we saw in a previous talk, services, health checks and so on.", "tokens": [370, 23488, 441, 33, 300, 321, 1866, 294, 257, 3894, 751, 11, 3328, 11, 1585, 13834, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.21466268811907088, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.00018823915161192417}, {"id": 15, "seek": 8288, "start": 88.32, "end": 93.75999999999999, "text": " It also provides the uniformity of deployment, and it's also far from the sequence, so you", "tokens": [467, 611, 6417, 264, 9452, 507, 295, 19317, 11, 293, 309, 311, 611, 1400, 490, 264, 8310, 11, 370, 291], "temperature": 0.0, "avg_logprob": -0.21466268811907088, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.00018823915161192417}, {"id": 16, "seek": 8288, "start": 93.75999999999999, "end": 96.88, "text": " don't need to know what you're running on.", "tokens": [500, 380, 643, 281, 458, 437, 291, 434, 2614, 322, 13], "temperature": 0.0, "avg_logprob": -0.21466268811907088, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.00018823915161192417}, {"id": 17, "seek": 8288, "start": 96.88, "end": 102.64, "text": " But coming from the CNF land, so trying to deploy a network function in this environment,", "tokens": [583, 1348, 490, 264, 14589, 37, 2117, 11, 370, 1382, 281, 7274, 257, 3209, 2445, 294, 341, 2823, 11], "temperature": 0.0, "avg_logprob": -0.21466268811907088, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.00018823915161192417}, {"id": 18, "seek": 8288, "start": 102.64, "end": 104.28, "text": " the story is not the same.", "tokens": [264, 1657, 307, 406, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.21466268811907088, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.00018823915161192417}, {"id": 19, "seek": 8288, "start": 104.28, "end": 109.24, "text": " So I'll define a bit more what I mean by CNF because it's a bit different between the", "tokens": [407, 286, 603, 6964, 257, 857, 544, 437, 286, 914, 538, 14589, 37, 570, 309, 311, 257, 857, 819, 1296, 264], "temperature": 0.0, "avg_logprob": -0.21466268811907088, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.00018823915161192417}, {"id": 20, "seek": 10924, "start": 109.24, "end": 114.19999999999999, "text": " standard CNF use case, the 5G one.", "tokens": [3832, 14589, 37, 764, 1389, 11, 264, 1025, 38, 472, 13], "temperature": 0.0, "avg_logprob": -0.20695649816634806, "compression_ratio": 1.6572769953051643, "no_speech_prob": 8.169112697942182e-05}, {"id": 21, "seek": 10924, "start": 114.19999999999999, "end": 120.08, "text": " What I mean by that is, so I'll take an example for the sake of this presentation, so typically", "tokens": [708, 286, 914, 538, 300, 307, 11, 370, 286, 603, 747, 364, 1365, 337, 264, 9717, 295, 341, 5860, 11, 370, 5850], "temperature": 0.0, "avg_logprob": -0.20695649816634806, "compression_ratio": 1.6572769953051643, "no_speech_prob": 8.169112697942182e-05}, {"id": 22, "seek": 10924, "start": 120.08, "end": 122.6, "text": " what I mean by that is the wire guard head end.", "tokens": [437, 286, 914, 538, 300, 307, 264, 6234, 6290, 1378, 917, 13], "temperature": 0.0, "avg_logprob": -0.20695649816634806, "compression_ratio": 1.6572769953051643, "no_speech_prob": 8.169112697942182e-05}, {"id": 23, "seek": 10924, "start": 122.6, "end": 126.91999999999999, "text": " For example, you have a customer and you want to deploy a fleet of wire guard head ends", "tokens": [1171, 1365, 11, 291, 362, 257, 5474, 293, 291, 528, 281, 7274, 257, 19396, 295, 6234, 6290, 1378, 5314], "temperature": 0.0, "avg_logprob": -0.20695649816634806, "compression_ratio": 1.6572769953051643, "no_speech_prob": 8.169112697942182e-05}, {"id": 24, "seek": 10924, "start": 126.91999999999999, "end": 135.72, "text": " to give that user access to a resource in a company network, so typically a very prior", "tokens": [281, 976, 300, 4195, 2105, 281, 257, 7684, 294, 257, 2237, 3209, 11, 370, 5850, 257, 588, 4059], "temperature": 0.0, "avg_logprob": -0.20695649816634806, "compression_ratio": 1.6572769953051643, "no_speech_prob": 8.169112697942182e-05}, {"id": 25, "seek": 13572, "start": 135.72, "end": 141.64, "text": " printer that everybody wants to access to because people like to print.", "tokens": [16671, 300, 2201, 2738, 281, 2105, 281, 570, 561, 411, 281, 4482, 13], "temperature": 0.0, "avg_logprob": -0.17974180524999445, "compression_ratio": 1.5889830508474576, "no_speech_prob": 0.00010597297659842297}, {"id": 26, "seek": 13572, "start": 141.64, "end": 147.0, "text": " So the particularity of this use case is that it's dynamic enough to benefit from the abstraction", "tokens": [407, 264, 1729, 507, 295, 341, 764, 1389, 307, 300, 309, 311, 8546, 1547, 281, 5121, 490, 264, 37765], "temperature": 0.0, "avg_logprob": -0.17974180524999445, "compression_ratio": 1.5889830508474576, "no_speech_prob": 0.00010597297659842297}, {"id": 27, "seek": 13572, "start": 147.0, "end": 151.4, "text": " that humanities brings, and I've lost my mouse.", "tokens": [300, 36140, 5607, 11, 293, 286, 600, 2731, 452, 9719, 13], "temperature": 0.0, "avg_logprob": -0.17974180524999445, "compression_ratio": 1.5889830508474576, "no_speech_prob": 0.00010597297659842297}, {"id": 28, "seek": 13572, "start": 151.4, "end": 157.04, "text": " So typically load balancing, scheduling and those kinds of things.", "tokens": [407, 5850, 3677, 22495, 11, 29055, 293, 729, 3685, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.17974180524999445, "compression_ratio": 1.5889830508474576, "no_speech_prob": 0.00010597297659842297}, {"id": 29, "seek": 13572, "start": 157.04, "end": 162.88, "text": " But it has a lot of specific needs, for example ingress has to be done in a particular way", "tokens": [583, 309, 575, 257, 688, 295, 2685, 2203, 11, 337, 1365, 3957, 735, 575, 281, 312, 1096, 294, 257, 1729, 636], "temperature": 0.0, "avg_logprob": -0.17974180524999445, "compression_ratio": 1.5889830508474576, "no_speech_prob": 0.00010597297659842297}, {"id": 30, "seek": 16288, "start": 162.88, "end": 166.32, "text": " because you have some wire guard encrypted traffic, so typically you want to see which", "tokens": [570, 291, 362, 512, 6234, 6290, 36663, 6419, 11, 370, 5850, 291, 528, 281, 536, 597], "temperature": 0.0, "avg_logprob": -0.19856446789157006, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00043160023051314056}, {"id": 31, "seek": 16288, "start": 166.32, "end": 169.88, "text": " IP it's coming from.", "tokens": [8671, 309, 311, 1348, 490, 13], "temperature": 0.0, "avg_logprob": -0.19856446789157006, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00043160023051314056}, {"id": 32, "seek": 16288, "start": 169.88, "end": 173.72, "text": " You also constrain on how you receive traffic because typically, and that's the place where", "tokens": [509, 611, 1817, 7146, 322, 577, 291, 4774, 6419, 570, 5850, 11, 293, 300, 311, 264, 1081, 689], "temperature": 0.0, "avg_logprob": -0.19856446789157006, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00043160023051314056}, {"id": 33, "seek": 16288, "start": 173.72, "end": 176.96, "text": " you need multiple interfaces to go into your pod.", "tokens": [291, 643, 3866, 28416, 281, 352, 666, 428, 2497, 13], "temperature": 0.0, "avg_logprob": -0.19856446789157006, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00043160023051314056}, {"id": 34, "seek": 16288, "start": 176.96, "end": 182.92, "text": " And you also require high performance because encrypted traffic, so typically you want those", "tokens": [400, 291, 611, 3651, 1090, 3389, 570, 36663, 6419, 11, 370, 5850, 291, 528, 729], "temperature": 0.0, "avg_logprob": -0.19856446789157006, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00043160023051314056}, {"id": 35, "seek": 16288, "start": 182.92, "end": 186.92, "text": " things to run fast and you have a lot of user using them.", "tokens": [721, 281, 1190, 2370, 293, 291, 362, 257, 688, 295, 4195, 1228, 552, 13], "temperature": 0.0, "avg_logprob": -0.19856446789157006, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00043160023051314056}, {"id": 36, "seek": 18692, "start": 186.92, "end": 193.44, "text": " So not for that printer, but assuming it's a bigger use case.", "tokens": [407, 406, 337, 300, 16671, 11, 457, 11926, 309, 311, 257, 3801, 764, 1389, 13], "temperature": 0.0, "avg_logprob": -0.23211168505481838, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.00020788252004422247}, {"id": 37, "seek": 18692, "start": 193.44, "end": 195.88, "text": " So we tried to design a solution for that.", "tokens": [407, 321, 3031, 281, 1715, 257, 3827, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.23211168505481838, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.00020788252004422247}, {"id": 38, "seek": 18692, "start": 195.88, "end": 202.35999999999999, "text": " So there are lots of components at play, I'll try to go quickly into them.", "tokens": [407, 456, 366, 3195, 295, 6677, 412, 862, 11, 286, 603, 853, 281, 352, 2661, 666, 552, 13], "temperature": 0.0, "avg_logprob": -0.23211168505481838, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.00020788252004422247}, {"id": 39, "seek": 18692, "start": 202.35999999999999, "end": 208.16, "text": " So in the top we have our application, so here the wire guard VPN head end.", "tokens": [407, 294, 264, 1192, 321, 362, 527, 3861, 11, 370, 510, 264, 6234, 6290, 24512, 1378, 917, 13], "temperature": 0.0, "avg_logprob": -0.23211168505481838, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.00020788252004422247}, {"id": 40, "seek": 18692, "start": 208.16, "end": 212.27999999999997, "text": " We want to deploy it on top of humanity, so we have to choose a CNI, so we want to have", "tokens": [492, 528, 281, 7274, 309, 322, 1192, 295, 10243, 11, 370, 321, 362, 281, 2826, 257, 14589, 40, 11, 370, 321, 528, 281, 362], "temperature": 0.0, "avg_logprob": -0.23211168505481838, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.00020788252004422247}, {"id": 41, "seek": 21228, "start": 212.28, "end": 218.8, "text": " it with Calico, mainly because of the cuteness of the cat, but also because it provides a", "tokens": [309, 365, 3511, 2789, 11, 8704, 570, 295, 264, 1723, 15264, 295, 264, 3857, 11, 457, 611, 570, 309, 6417, 257], "temperature": 0.0, "avg_logprob": -0.2450915369494208, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0001185779256047681}, {"id": 42, "seek": 21228, "start": 218.8, "end": 225.08, "text": " really nice interface into supporting multiple data planes and also a nice BGP integration", "tokens": [534, 1481, 9226, 666, 7231, 3866, 1412, 14952, 293, 611, 257, 1481, 363, 38, 47, 10980], "temperature": 0.0, "avg_logprob": -0.2450915369494208, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0001185779256047681}, {"id": 43, "seek": 21228, "start": 225.08, "end": 232.52, "text": " that allows to tweak the way we process packets.", "tokens": [300, 4045, 281, 29879, 264, 636, 321, 1399, 30364, 13], "temperature": 0.0, "avg_logprob": -0.2450915369494208, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0001185779256047681}, {"id": 44, "seek": 21228, "start": 232.52, "end": 238.84, "text": " And for carrying packets we use the FDIO's LPP as a data plane that gave us more control", "tokens": [400, 337, 9792, 30364, 321, 764, 264, 479, 3085, 46, 311, 441, 17755, 382, 257, 1412, 5720, 300, 2729, 505, 544, 1969], "temperature": 0.0, "avg_logprob": -0.2450915369494208, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0001185779256047681}, {"id": 45, "seek": 21228, "start": 238.84, "end": 241.96, "text": " on how packets are processed.", "tokens": [322, 577, 30364, 366, 18846, 13], "temperature": 0.0, "avg_logprob": -0.2450915369494208, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0001185779256047681}, {"id": 46, "seek": 24196, "start": 241.96, "end": 249.68, "text": " And so that allowed us to go deeper into the way networks actually manage at a really low", "tokens": [400, 370, 300, 4350, 505, 281, 352, 7731, 666, 264, 636, 9590, 767, 3067, 412, 257, 534, 2295], "temperature": 0.0, "avg_logprob": -0.15386023963849568, "compression_ratio": 1.5082644628099173, "no_speech_prob": 0.00012504142068792135}, {"id": 47, "seek": 24196, "start": 249.68, "end": 250.68, "text": " level.", "tokens": [1496, 13], "temperature": 0.0, "avg_logprob": -0.15386023963849568, "compression_ratio": 1.5082644628099173, "no_speech_prob": 0.00012504142068792135}, {"id": 48, "seek": 24196, "start": 250.68, "end": 256.82, "text": " There are also other components that are going to play, but more on this later.", "tokens": [821, 366, 611, 661, 6677, 300, 366, 516, 281, 862, 11, 457, 544, 322, 341, 1780, 13], "temperature": 0.0, "avg_logprob": -0.15386023963849568, "compression_ratio": 1.5082644628099173, "no_speech_prob": 0.00012504142068792135}, {"id": 49, "seek": 24196, "start": 256.82, "end": 262.48, "text": " So I'm going to go quickly over Calico and VPP because they have been presented many", "tokens": [407, 286, 478, 516, 281, 352, 2661, 670, 3511, 2789, 293, 691, 17755, 570, 436, 362, 668, 8212, 867], "temperature": 0.0, "avg_logprob": -0.15386023963849568, "compression_ratio": 1.5082644628099173, "no_speech_prob": 0.00012504142068792135}, {"id": 50, "seek": 24196, "start": 262.48, "end": 263.48, "text": " times.", "tokens": [1413, 13], "temperature": 0.0, "avg_logprob": -0.15386023963849568, "compression_ratio": 1.5082644628099173, "no_speech_prob": 0.00012504142068792135}, {"id": 51, "seek": 24196, "start": 263.48, "end": 269.36, "text": " So in short Calico is a community CNI, providing a lot of great features, policies, BGP, support", "tokens": [407, 294, 2099, 3511, 2789, 307, 257, 1768, 14589, 40, 11, 6530, 257, 688, 295, 869, 4122, 11, 7657, 11, 363, 38, 47, 11, 1406], "temperature": 0.0, "avg_logprob": -0.15386023963849568, "compression_ratio": 1.5082644628099173, "no_speech_prob": 0.00012504142068792135}, {"id": 52, "seek": 26936, "start": 269.36, "end": 274.84000000000003, "text": " for really huge clusters, and the point that's important for this presentation is that it", "tokens": [337, 534, 2603, 23313, 11, 293, 264, 935, 300, 311, 1021, 337, 341, 5860, 307, 300, 309], "temperature": 0.0, "avg_logprob": -0.19377042070219788, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.00020730422693304718}, {"id": 53, "seek": 26936, "start": 274.84000000000003, "end": 280.16, "text": " has a very well-defined control plane data plane interface, allowing to plug new performance", "tokens": [575, 257, 588, 731, 12, 37716, 1969, 5720, 1412, 5720, 9226, 11, 8293, 281, 5452, 777, 3389], "temperature": 0.0, "avg_logprob": -0.19377042070219788, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.00020730422693304718}, {"id": 54, "seek": 26936, "start": 280.16, "end": 286.88, "text": " oriented software underneath it without much hassle, and that's what we are going to leverage.", "tokens": [21841, 4722, 7223, 309, 1553, 709, 39526, 11, 293, 300, 311, 437, 321, 366, 516, 281, 13982, 13], "temperature": 0.0, "avg_logprob": -0.19377042070219788, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.00020730422693304718}, {"id": 55, "seek": 26936, "start": 286.88, "end": 293.6, "text": " So we choose to sleep VPP underneath Calico, first because we were originally contributors", "tokens": [407, 321, 2826, 281, 2817, 691, 17755, 7223, 3511, 2789, 11, 700, 570, 321, 645, 7993, 45627], "temperature": 0.0, "avg_logprob": -0.19377042070219788, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.00020730422693304718}, {"id": 56, "seek": 29360, "start": 293.6, "end": 299.56, "text": " in this open-source user space networking data plane, so it was a solution of choice.", "tokens": [294, 341, 1269, 12, 41676, 4195, 1901, 17985, 1412, 5720, 11, 370, 309, 390, 257, 3827, 295, 3922, 13], "temperature": 0.0, "avg_logprob": -0.13579193918328536, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.00012513418914750218}, {"id": 57, "seek": 29360, "start": 299.56, "end": 306.52000000000004, "text": " But also it has a lot of cool functionalities that are built in and it's extensible.", "tokens": [583, 611, 309, 575, 257, 688, 295, 1627, 11745, 1088, 300, 366, 3094, 294, 293, 309, 311, 1279, 30633, 13], "temperature": 0.0, "avg_logprob": -0.13579193918328536, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.00012513418914750218}, {"id": 58, "seek": 29360, "start": 306.52000000000004, "end": 313.24, "text": " So I am doing a bit of publicity for the software I'm coming from, but it was a good tool for", "tokens": [407, 286, 669, 884, 257, 857, 295, 37264, 337, 264, 4722, 286, 478, 1348, 490, 11, 457, 309, 390, 257, 665, 2290, 337], "temperature": 0.0, "avg_logprob": -0.13579193918328536, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.00012513418914750218}, {"id": 59, "seek": 29360, "start": 313.24, "end": 314.24, "text": " this use case.", "tokens": [341, 764, 1389, 13], "temperature": 0.0, "avg_logprob": -0.13579193918328536, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.00012513418914750218}, {"id": 60, "seek": 29360, "start": 314.24, "end": 321.12, "text": " And also it's quite fast, so it really fits the needs for this application.", "tokens": [400, 611, 309, 311, 1596, 2370, 11, 370, 309, 534, 9001, 264, 2203, 337, 341, 3861, 13], "temperature": 0.0, "avg_logprob": -0.13579193918328536, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.00012513418914750218}, {"id": 61, "seek": 32112, "start": 321.12, "end": 323.8, "text": " So how did we bind the two together?", "tokens": [407, 577, 630, 321, 14786, 264, 732, 1214, 30], "temperature": 0.0, "avg_logprob": -0.21626708086799173, "compression_ratio": 1.6031746031746033, "no_speech_prob": 7.280008867383003e-05}, {"id": 62, "seek": 32112, "start": 323.8, "end": 328.16, "text": " What we do is we built an agent running in a demand set on every node, so deployment", "tokens": [708, 321, 360, 307, 321, 3094, 364, 9461, 2614, 294, 257, 4733, 992, 322, 633, 9984, 11, 370, 19317], "temperature": 0.0, "avg_logprob": -0.21626708086799173, "compression_ratio": 1.6031746031746033, "no_speech_prob": 7.280008867383003e-05}, {"id": 63, "seek": 32112, "start": 328.16, "end": 333.52, "text": " is the same as a simple pod, just with more privileges.", "tokens": [307, 264, 912, 382, 257, 2199, 2497, 11, 445, 365, 544, 32588, 13], "temperature": 0.0, "avg_logprob": -0.21626708086799173, "compression_ratio": 1.6031746031746033, "no_speech_prob": 7.280008867383003e-05}, {"id": 64, "seek": 32112, "start": 333.52, "end": 340.12, "text": " We registered these agents in Calico as a Calico data plane and used their GRPC interface", "tokens": [492, 13968, 613, 12554, 294, 3511, 2789, 382, 257, 3511, 2789, 1412, 5720, 293, 1143, 641, 10903, 12986, 9226], "temperature": 0.0, "avg_logprob": -0.21626708086799173, "compression_ratio": 1.6031746031746033, "no_speech_prob": 7.280008867383003e-05}, {"id": 65, "seek": 32112, "start": 340.12, "end": 345.64, "text": " and their APIs that they exposed to decouple control data plane.", "tokens": [293, 641, 21445, 300, 436, 9495, 281, 979, 263, 781, 1969, 1412, 5720, 13], "temperature": 0.0, "avg_logprob": -0.21626708086799173, "compression_ratio": 1.6031746031746033, "no_speech_prob": 7.280008867383003e-05}, {"id": 66, "seek": 32112, "start": 345.64, "end": 350.24, "text": " That agent listens for Calico events and then programs VPP accordingly.", "tokens": [663, 9461, 35959, 337, 3511, 2789, 3931, 293, 550, 4268, 691, 17755, 19717, 13], "temperature": 0.0, "avg_logprob": -0.21626708086799173, "compression_ratio": 1.6031746031746033, "no_speech_prob": 7.280008867383003e-05}, {"id": 67, "seek": 35024, "start": 350.24, "end": 356.08, "text": " And we also built a series of custom plug-ins for handling that, servicing and so on.", "tokens": [400, 321, 611, 3094, 257, 2638, 295, 2375, 5452, 12, 1292, 337, 13175, 300, 11, 1658, 5776, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.2758248163306195, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.00017578240658622235}, {"id": 68, "seek": 35024, "start": 356.08, "end": 361.88, "text": " And we tweaked the configuration so that things behave nicely in a container-oriented environment.", "tokens": [400, 321, 6986, 7301, 264, 11694, 370, 300, 721, 15158, 9594, 294, 257, 10129, 12, 27414, 2823, 13], "temperature": 0.0, "avg_logprob": -0.2758248163306195, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.00017578240658622235}, {"id": 69, "seek": 35024, "start": 361.88, "end": 368.24, "text": " And with all this, we have every brick to bring VPP into the clusters and so to have", "tokens": [400, 365, 439, 341, 11, 321, 362, 633, 16725, 281, 1565, 691, 17755, 666, 264, 23313, 293, 370, 281, 362], "temperature": 0.0, "avg_logprob": -0.2758248163306195, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.00017578240658622235}, {"id": 70, "seek": 35024, "start": 368.24, "end": 375.28000000000003, "text": " really control on everything that happens, indeed, the communities networking.", "tokens": [534, 1969, 322, 1203, 300, 2314, 11, 6451, 11, 264, 4456, 17985, 13], "temperature": 0.0, "avg_logprob": -0.2758248163306195, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.00017578240658622235}, {"id": 71, "seek": 35024, "start": 375.28000000000003, "end": 377.28000000000003, "text": " How does that happen under the hood?", "tokens": [1012, 775, 300, 1051, 833, 264, 13376, 30], "temperature": 0.0, "avg_logprob": -0.2758248163306195, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.00017578240658622235}, {"id": 72, "seek": 37728, "start": 377.28, "end": 383.59999999999997, "text": " So what happens exactly under the hood, what we do is we swap all the network logic that", "tokens": [407, 437, 2314, 2293, 833, 264, 13376, 11, 437, 321, 360, 307, 321, 18135, 439, 264, 3209, 9952, 300], "temperature": 0.0, "avg_logprob": -0.14493077059826218, "compression_ratio": 1.5621890547263682, "no_speech_prob": 5.788715134258382e-05}, {"id": 73, "seek": 37728, "start": 383.59999999999997, "end": 391.28, "text": " was happening in Linux to VPP, so from this configuration to there.", "tokens": [390, 2737, 294, 18734, 281, 691, 17755, 11, 370, 490, 341, 11694, 281, 456, 13], "temperature": 0.0, "avg_logprob": -0.14493077059826218, "compression_ratio": 1.5621890547263682, "no_speech_prob": 5.788715134258382e-05}, {"id": 74, "seek": 37728, "start": 391.28, "end": 399.0, "text": " In order to, so, yeah, the thing is as VPP is a user space stack, we have to do a few", "tokens": [682, 1668, 281, 11, 370, 11, 1338, 11, 264, 551, 307, 382, 691, 17755, 307, 257, 4195, 1901, 8630, 11, 321, 362, 281, 360, 257, 1326], "temperature": 0.0, "avg_logprob": -0.14493077059826218, "compression_ratio": 1.5621890547263682, "no_speech_prob": 5.788715134258382e-05}, {"id": 75, "seek": 37728, "start": 399.0, "end": 403.52, "text": " things a bit differently compared to what was previously done in Linux.", "tokens": [721, 257, 857, 7614, 5347, 281, 437, 390, 8046, 1096, 294, 18734, 13], "temperature": 0.0, "avg_logprob": -0.14493077059826218, "compression_ratio": 1.5621890547263682, "no_speech_prob": 5.788715134258382e-05}, {"id": 76, "seek": 40352, "start": 403.52, "end": 408.76, "text": " So in order to insert VPP between the host and the network, we will grab the host interface,", "tokens": [407, 294, 1668, 281, 8969, 691, 17755, 1296, 264, 3975, 293, 264, 3209, 11, 321, 486, 4444, 264, 3975, 9226, 11], "temperature": 0.0, "avg_logprob": -0.19249345606023616, "compression_ratio": 1.8, "no_speech_prob": 9.62048361543566e-05}, {"id": 77, "seek": 40352, "start": 408.76, "end": 414.32, "text": " the uplink, and consume it in VPP with the appropriate driver.", "tokens": [264, 493, 22473, 11, 293, 14732, 309, 294, 691, 17755, 365, 264, 6854, 6787, 13], "temperature": 0.0, "avg_logprob": -0.19249345606023616, "compression_ratio": 1.8, "no_speech_prob": 9.62048361543566e-05}, {"id": 78, "seek": 40352, "start": 414.32, "end": 418.2, "text": " And then we restore the host connectivity by creating a turn interface in the host root", "tokens": [400, 550, 321, 15227, 264, 3975, 21095, 538, 4084, 257, 1261, 9226, 294, 264, 3975, 5593], "temperature": 0.0, "avg_logprob": -0.19249345606023616, "compression_ratio": 1.8, "no_speech_prob": 9.62048361543566e-05}, {"id": 79, "seek": 40352, "start": 418.2, "end": 419.35999999999996, "text": " network main space.", "tokens": [3209, 2135, 1901, 13], "temperature": 0.0, "avg_logprob": -0.19249345606023616, "compression_ratio": 1.8, "no_speech_prob": 9.62048361543566e-05}, {"id": 80, "seek": 40352, "start": 419.35999999999996, "end": 421.88, "text": " So that's the turn tap here.", "tokens": [407, 300, 311, 264, 1261, 5119, 510, 13], "temperature": 0.0, "avg_logprob": -0.19249345606023616, "compression_ratio": 1.8, "no_speech_prob": 9.62048361543566e-05}, {"id": 81, "seek": 40352, "start": 421.88, "end": 425.84, "text": " And we replicate everything on that interface, it resists the routes.", "tokens": [400, 321, 25356, 1203, 322, 300, 9226, 11, 309, 725, 1751, 264, 18242, 13], "temperature": 0.0, "avg_logprob": -0.19249345606023616, "compression_ratio": 1.8, "no_speech_prob": 9.62048361543566e-05}, {"id": 82, "seek": 40352, "start": 425.84, "end": 429.44, "text": " So basically we insert ourselves as a bump in the wire on the uplink.", "tokens": [407, 1936, 321, 8969, 4175, 382, 257, 9961, 294, 264, 6234, 322, 264, 493, 22473, 13], "temperature": 0.0, "avg_logprob": -0.19249345606023616, "compression_ratio": 1.8, "no_speech_prob": 9.62048361543566e-05}, {"id": 83, "seek": 42944, "start": 429.44, "end": 435.12, "text": " It's not very network-ish, but it works pretty well in that configuration.", "tokens": [467, 311, 406, 588, 3209, 12, 742, 11, 457, 309, 1985, 1238, 731, 294, 300, 11694, 13], "temperature": 0.0, "avg_logprob": -0.22092459667688127, "compression_ratio": 1.588235294117647, "no_speech_prob": 5.6342571042478085e-05}, {"id": 84, "seek": 42944, "start": 435.12, "end": 442.76, "text": " And that way we restore pod connectivity as before with turn taps instead of a VIF.", "tokens": [400, 300, 636, 321, 15227, 2497, 21095, 382, 949, 365, 1261, 42536, 2602, 295, 257, 691, 12775, 13], "temperature": 0.0, "avg_logprob": -0.22092459667688127, "compression_ratio": 1.588235294117647, "no_speech_prob": 5.6342571042478085e-05}, {"id": 85, "seek": 42944, "start": 442.76, "end": 447.44, "text": " We create an interface in every pod.", "tokens": [492, 1884, 364, 9226, 294, 633, 2497, 13], "temperature": 0.0, "avg_logprob": -0.22092459667688127, "compression_ratio": 1.588235294117647, "no_speech_prob": 5.6342571042478085e-05}, {"id": 86, "seek": 42944, "start": 447.44, "end": 450.8, "text": " And then everything runs normally, the Calico control plane is running normally on the host", "tokens": [400, 550, 1203, 6676, 5646, 11, 264, 3511, 2789, 1969, 5720, 307, 2614, 5646, 322, 264, 3975], "temperature": 0.0, "avg_logprob": -0.22092459667688127, "compression_ratio": 1.588235294117647, "no_speech_prob": 5.6342571042478085e-05}, {"id": 87, "seek": 42944, "start": 450.8, "end": 457.04, "text": " and it configures the data plan functions in VPP via the agent.", "tokens": [293, 309, 6662, 1303, 264, 1412, 1393, 6828, 294, 691, 17755, 5766, 264, 9461, 13], "temperature": 0.0, "avg_logprob": -0.22092459667688127, "compression_ratio": 1.588235294117647, "no_speech_prob": 5.6342571042478085e-05}, {"id": 88, "seek": 45704, "start": 457.04, "end": 460.36, "text": " So now we have the green part covered.", "tokens": [407, 586, 321, 362, 264, 3092, 644, 5343, 13], "temperature": 0.0, "avg_logprob": -0.25585275766800863, "compression_ratio": 1.5775862068965518, "no_speech_prob": 4.2040468542836607e-05}, {"id": 89, "seek": 45704, "start": 460.36, "end": 462.08000000000004, "text": " So all those components run neatly.", "tokens": [407, 439, 729, 6677, 1190, 36634, 13], "temperature": 0.0, "avg_logprob": -0.25585275766800863, "compression_ratio": 1.5775862068965518, "no_speech_prob": 4.2040468542836607e-05}, {"id": 90, "seek": 45704, "start": 462.08000000000004, "end": 467.76000000000005, "text": " And what we achieve with that is that when we create a pod, Kubernetes will call Calico,", "tokens": [400, 437, 321, 4584, 365, 300, 307, 300, 562, 321, 1884, 257, 2497, 11, 23145, 486, 818, 3511, 2789, 11], "temperature": 0.0, "avg_logprob": -0.25585275766800863, "compression_ratio": 1.5775862068965518, "no_speech_prob": 4.2040468542836607e-05}, {"id": 91, "seek": 45704, "start": 467.76000000000005, "end": 469.32000000000005, "text": " Calico will call VPP.", "tokens": [3511, 2789, 486, 818, 691, 17755, 13], "temperature": 0.0, "avg_logprob": -0.25585275766800863, "compression_ratio": 1.5775862068965518, "no_speech_prob": 4.2040468542836607e-05}, {"id": 92, "seek": 45704, "start": 469.32000000000005, "end": 474.76, "text": " And we can provide an interface that we fully handle on a network network player directly", "tokens": [400, 321, 393, 2893, 364, 9226, 300, 321, 4498, 4813, 322, 257, 3209, 3209, 4256, 3838], "temperature": 0.0, "avg_logprob": -0.25585275766800863, "compression_ratio": 1.5775862068965518, "no_speech_prob": 4.2040468542836607e-05}, {"id": 93, "seek": 45704, "start": 474.76, "end": 475.76, "text": " in VPP.", "tokens": [294, 691, 17755, 13], "temperature": 0.0, "avg_logprob": -0.25585275766800863, "compression_ratio": 1.5775862068965518, "no_speech_prob": 4.2040468542836607e-05}, {"id": 94, "seek": 45704, "start": 475.76, "end": 482.16, "text": " But for this specific wire guard add-on application, we need a bit more than that.", "tokens": [583, 337, 341, 2685, 6234, 6290, 909, 12, 266, 3861, 11, 321, 643, 257, 857, 544, 813, 300, 13], "temperature": 0.0, "avg_logprob": -0.25585275766800863, "compression_ratio": 1.5775862068965518, "no_speech_prob": 4.2040468542836607e-05}, {"id": 95, "seek": 48216, "start": 482.16, "end": 488.20000000000005, "text": " We need multiple interfaces and we also potentially have overlapping addresses.", "tokens": [492, 643, 3866, 28416, 293, 321, 611, 7263, 362, 33535, 16862, 13], "temperature": 0.0, "avg_logprob": -0.2550765117966985, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00014120712876319885}, {"id": 96, "seek": 48216, "start": 488.20000000000005, "end": 493.84000000000003, "text": " So we don't really manage where the IPs are going to end.", "tokens": [407, 321, 500, 380, 534, 3067, 689, 264, 8671, 82, 366, 516, 281, 917, 13], "temperature": 0.0, "avg_logprob": -0.2550765117966985, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00014120712876319885}, {"id": 97, "seek": 48216, "start": 493.84000000000003, "end": 500.04, "text": " So for the multiple interface part, our goal to show us was to go with multis that provides", "tokens": [407, 337, 264, 3866, 9226, 644, 11, 527, 3387, 281, 855, 505, 390, 281, 352, 365, 2120, 271, 300, 6417], "temperature": 0.0, "avg_logprob": -0.2550765117966985, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00014120712876319885}, {"id": 98, "seek": 48216, "start": 500.04, "end": 501.04, "text": " multiplexing.", "tokens": [3311, 2021, 278, 13], "temperature": 0.0, "avg_logprob": -0.2550765117966985, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00014120712876319885}, {"id": 99, "seek": 48216, "start": 501.04, "end": 506.92, "text": " And we chose also dedicated IPAM that we patched, which we were about because it was quite", "tokens": [400, 321, 5111, 611, 8374, 8671, 2865, 300, 321, 9972, 292, 11, 597, 321, 645, 466, 570, 309, 390, 1596], "temperature": 0.0, "avg_logprob": -0.2550765117966985, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00014120712876319885}, {"id": 100, "seek": 50692, "start": 506.92, "end": 513.5600000000001, "text": " simple to patch and brought those two pieces in.", "tokens": [2199, 281, 9972, 293, 3038, 729, 732, 3755, 294, 13], "temperature": 0.0, "avg_logprob": -0.19963499351784034, "compression_ratio": 1.4285714285714286, "no_speech_prob": 5.4630789236398414e-05}, {"id": 101, "seek": 50692, "start": 513.5600000000001, "end": 519.4, "text": " So when I mean multiple interfaces, what does that exactly contain?", "tokens": [407, 562, 286, 914, 3866, 28416, 11, 437, 775, 300, 2293, 5304, 30], "temperature": 0.0, "avg_logprob": -0.19963499351784034, "compression_ratio": 1.4285714285714286, "no_speech_prob": 5.4630789236398414e-05}, {"id": 102, "seek": 50692, "start": 519.4, "end": 527.72, "text": " So the thing is, the typical Kubernetes deployment looks like this.", "tokens": [407, 264, 551, 307, 11, 264, 7476, 23145, 19317, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.19963499351784034, "compression_ratio": 1.4285714285714286, "no_speech_prob": 5.4630789236398414e-05}, {"id": 103, "seek": 50692, "start": 527.72, "end": 531.88, "text": " So each pod has a single interface.", "tokens": [407, 1184, 2497, 575, 257, 2167, 9226, 13], "temperature": 0.0, "avg_logprob": -0.19963499351784034, "compression_ratio": 1.4285714285714286, "no_speech_prob": 5.4630789236398414e-05}, {"id": 104, "seek": 53188, "start": 531.88, "end": 537.32, "text": " And the CNI provides a pod-to-pod connectivity, typically with an encapsulation from node", "tokens": [400, 264, 14589, 40, 6417, 257, 2497, 12, 1353, 12, 43388, 21095, 11, 5850, 365, 364, 38745, 2776, 490, 9984], "temperature": 0.0, "avg_logprob": -0.17984476175394143, "compression_ratio": 1.7320754716981133, "no_speech_prob": 8.564806921640411e-05}, {"id": 105, "seek": 53188, "start": 537.32, "end": 538.32, "text": " to node.", "tokens": [281, 9984, 13], "temperature": 0.0, "avg_logprob": -0.17984476175394143, "compression_ratio": 1.7320754716981133, "no_speech_prob": 8.564806921640411e-05}, {"id": 106, "seek": 53188, "start": 538.32, "end": 543.64, "text": " But in our application, we want to differentiate the encrypted traffic from the clear-text", "tokens": [583, 294, 527, 3861, 11, 321, 528, 281, 23203, 264, 36663, 6419, 490, 264, 1850, 12, 25111], "temperature": 0.0, "avg_logprob": -0.17984476175394143, "compression_ratio": 1.7320754716981133, "no_speech_prob": 8.564806921640411e-05}, {"id": 107, "seek": 53188, "start": 543.64, "end": 547.8, "text": " traffic, so before and after the head end.", "tokens": [6419, 11, 370, 949, 293, 934, 264, 1378, 917, 13], "temperature": 0.0, "avg_logprob": -0.17984476175394143, "compression_ratio": 1.7320754716981133, "no_speech_prob": 8.564806921640411e-05}, {"id": 108, "seek": 53188, "start": 547.8, "end": 550.8, "text": " But we still want Kubernetes as the end to operate.", "tokens": [583, 321, 920, 528, 23145, 382, 264, 917, 281, 9651, 13], "temperature": 0.0, "avg_logprob": -0.17984476175394143, "compression_ratio": 1.7320754716981133, "no_speech_prob": 8.564806921640411e-05}, {"id": 109, "seek": 53188, "start": 550.8, "end": 555.24, "text": " So we still want the nice things about Kubernetes, so service IPs and everything.", "tokens": [407, 321, 920, 528, 264, 1481, 721, 466, 23145, 11, 370, 2643, 8671, 82, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.17984476175394143, "compression_ratio": 1.7320754716981133, "no_speech_prob": 8.564806921640411e-05}, {"id": 110, "seek": 53188, "start": 555.24, "end": 560.8, "text": " So it's not only multiple interfaces, it's really multiple interfaces wired into Kubernetes.", "tokens": [407, 309, 311, 406, 787, 3866, 28416, 11, 309, 311, 534, 3866, 28416, 27415, 666, 23145, 13], "temperature": 0.0, "avg_logprob": -0.17984476175394143, "compression_ratio": 1.7320754716981133, "no_speech_prob": 8.564806921640411e-05}, {"id": 111, "seek": 56080, "start": 560.8, "end": 563.9599999999999, "text": " So it's more multiple isolated networks.", "tokens": [407, 309, 311, 544, 3866, 14621, 9590, 13], "temperature": 0.0, "avg_logprob": -0.15663873065601697, "compression_ratio": 1.7179487179487178, "no_speech_prob": 6.565456715179607e-05}, {"id": 112, "seek": 56080, "start": 563.9599999999999, "end": 569.88, "text": " So conceptually, what we needed was the ability to create multiple Kubernetes networks.", "tokens": [407, 3410, 671, 11, 437, 321, 2978, 390, 264, 3485, 281, 1884, 3866, 23145, 9590, 13], "temperature": 0.0, "avg_logprob": -0.15663873065601697, "compression_ratio": 1.7179487179487178, "no_speech_prob": 6.565456715179607e-05}, {"id": 113, "seek": 56080, "start": 569.88, "end": 575.64, "text": " So each network behaving a bit like a standalone cluster stacked on top of each other.", "tokens": [407, 1184, 3209, 35263, 257, 857, 411, 257, 37454, 13630, 28867, 322, 1192, 295, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.15663873065601697, "compression_ratio": 1.7179487179487178, "no_speech_prob": 6.565456715179607e-05}, {"id": 114, "seek": 56080, "start": 575.64, "end": 583.7199999999999, "text": " So with this, we request networks that provide complete isolation between each other, meaning", "tokens": [407, 365, 341, 11, 321, 5308, 9590, 300, 2893, 3566, 16001, 1296, 1184, 661, 11, 3620], "temperature": 0.0, "avg_logprob": -0.15663873065601697, "compression_ratio": 1.7179487179487178, "no_speech_prob": 6.565456715179607e-05}, {"id": 115, "seek": 56080, "start": 583.7199999999999, "end": 588.3599999999999, "text": " that traffic cannot cross from a network to another without going from to the outside", "tokens": [300, 6419, 2644, 3278, 490, 257, 3209, 281, 1071, 1553, 516, 490, 281, 264, 2380], "temperature": 0.0, "avg_logprob": -0.15663873065601697, "compression_ratio": 1.7179487179487178, "no_speech_prob": 6.565456715179607e-05}, {"id": 116, "seek": 56080, "start": 588.3599999999999, "end": 589.3599999999999, "text": " world.", "tokens": [1002, 13], "temperature": 0.0, "avg_logprob": -0.15663873065601697, "compression_ratio": 1.7179487179487178, "no_speech_prob": 6.565456715179607e-05}, {"id": 117, "seek": 58936, "start": 589.36, "end": 596.36, "text": " And so that means that we have to bind Calico, VPP, so on, integration, and multist together", "tokens": [400, 370, 300, 1355, 300, 321, 362, 281, 14786, 3511, 2789, 11, 691, 17755, 11, 370, 322, 11, 10980, 11, 293, 2120, 468, 1214], "temperature": 0.0, "avg_logprob": -0.30051201080607476, "compression_ratio": 1.743083003952569, "no_speech_prob": 9.547449735691771e-05}, {"id": 118, "seek": 58936, "start": 596.36, "end": 603.0, "text": " to create a model where everybody is aware of that definition of networks, have a catalog", "tokens": [281, 1884, 257, 2316, 689, 2201, 307, 3650, 295, 300, 7123, 295, 9590, 11, 362, 257, 19746], "temperature": 0.0, "avg_logprob": -0.30051201080607476, "compression_ratio": 1.743083003952569, "no_speech_prob": 9.547449735691771e-05}, {"id": 119, "seek": 58936, "start": 603.0, "end": 606.96, "text": " of isolated networks, specify the way they are going to communicate from node to node", "tokens": [295, 14621, 9590, 11, 16500, 264, 636, 436, 366, 516, 281, 7890, 490, 9984, 281, 9984], "temperature": 0.0, "avg_logprob": -0.30051201080607476, "compression_ratio": 1.743083003952569, "no_speech_prob": 9.547449735691771e-05}, {"id": 120, "seek": 58936, "start": 606.96, "end": 613.36, "text": " via VXLAN encapsulations, and have a way to propose to attach to those networks with", "tokens": [5766, 691, 55, 36527, 38745, 4136, 11, 293, 362, 257, 636, 281, 17421, 281, 5085, 281, 729, 9590, 365], "temperature": 0.0, "avg_logprob": -0.30051201080607476, "compression_ratio": 1.743083003952569, "no_speech_prob": 9.547449735691771e-05}, {"id": 121, "seek": 58936, "start": 613.36, "end": 618.84, "text": " annotations, so that in the end, Kubernetes is aware of these networks and we can still", "tokens": [25339, 763, 11, 370, 300, 294, 264, 917, 11, 23145, 307, 3650, 295, 613, 9590, 293, 321, 393, 920], "temperature": 0.0, "avg_logprob": -0.30051201080607476, "compression_ratio": 1.743083003952569, "no_speech_prob": 9.547449735691771e-05}, {"id": 122, "seek": 61884, "start": 618.84, "end": 623.6, "text": " maintain the SDN part of the logic.", "tokens": [6909, 264, 14638, 45, 644, 295, 264, 9952, 13], "temperature": 0.0, "avg_logprob": -0.29134407043457033, "compression_ratio": 1.6404494382022472, "no_speech_prob": 8.011875615920871e-05}, {"id": 123, "seek": 61884, "start": 623.6, "end": 633.36, "text": " So the way this works quickly is that the C&I interface will call Calico once per pod.", "tokens": [407, 264, 636, 341, 1985, 2661, 307, 300, 264, 383, 5, 40, 9226, 486, 818, 3511, 2789, 1564, 680, 2497, 13], "temperature": 0.0, "avg_logprob": -0.29134407043457033, "compression_ratio": 1.6404494382022472, "no_speech_prob": 8.011875615920871e-05}, {"id": 124, "seek": 61884, "start": 633.36, "end": 640.2, "text": " So the thing is, multist will call the C&I Calico once per top all pod interface.", "tokens": [407, 264, 551, 307, 11, 2120, 468, 486, 818, 264, 383, 5, 40, 3511, 2789, 1564, 680, 1192, 439, 2497, 9226, 13], "temperature": 0.0, "avg_logprob": -0.29134407043457033, "compression_ratio": 1.6404494382022472, "no_speech_prob": 8.011875615920871e-05}, {"id": 125, "seek": 61884, "start": 640.2, "end": 646.0400000000001, "text": " And we will in turn receive in origin those calls and we can map those with annotations", "tokens": [400, 321, 486, 294, 1261, 4774, 294, 4957, 729, 5498, 293, 321, 393, 4471, 729, 365, 25339, 763], "temperature": 0.0, "avg_logprob": -0.29134407043457033, "compression_ratio": 1.6404494382022472, "no_speech_prob": 8.011875615920871e-05}, {"id": 126, "seek": 64604, "start": 646.04, "end": 650.4, "text": " and do our magics to provide the logic.", "tokens": [293, 360, 527, 2258, 1167, 281, 2893, 264, 9952, 13], "temperature": 0.0, "avg_logprob": -0.19859265799474235, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.00013124835095368326}, {"id": 127, "seek": 64604, "start": 650.4, "end": 654.76, "text": " And having also the IPAM patch allows us to support multiple IPs and to have different", "tokens": [400, 1419, 611, 264, 8671, 2865, 9972, 4045, 505, 281, 1406, 3866, 8671, 82, 293, 281, 362, 819], "temperature": 0.0, "avg_logprob": -0.19859265799474235, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.00013124835095368326}, {"id": 128, "seek": 64604, "start": 654.76, "end": 659.5999999999999, "text": " realms where the IP lives and gets located from.", "tokens": [42824, 689, 264, 8671, 2909, 293, 2170, 6870, 490, 13], "temperature": 0.0, "avg_logprob": -0.19859265799474235, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.00013124835095368326}, {"id": 129, "seek": 64604, "start": 659.5999999999999, "end": 663.8399999999999, "text": " So from a user's perspective, what we expose is a network catalog where our networks are", "tokens": [407, 490, 257, 4195, 311, 4585, 11, 437, 321, 19219, 307, 257, 3209, 19746, 689, 527, 9590, 366], "temperature": 0.0, "avg_logprob": -0.19859265799474235, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.00013124835095368326}, {"id": 130, "seek": 64604, "start": 663.8399999999999, "end": 666.16, "text": " defining CRDs for now.", "tokens": [17827, 14123, 35, 82, 337, 586, 13], "temperature": 0.0, "avg_logprob": -0.19859265799474235, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.00013124835095368326}, {"id": 131, "seek": 64604, "start": 666.16, "end": 670.5999999999999, "text": " We are starting a standardization effort to bring that into Kubernetes, but that will", "tokens": [492, 366, 2891, 257, 3832, 2144, 4630, 281, 1565, 300, 666, 23145, 11, 457, 300, 486], "temperature": 0.0, "avg_logprob": -0.19859265799474235, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.00013124835095368326}, {"id": 132, "seek": 64604, "start": 670.5999999999999, "end": 672.56, "text": " probably take time.", "tokens": [1391, 747, 565, 13], "temperature": 0.0, "avg_logprob": -0.19859265799474235, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.00013124835095368326}, {"id": 133, "seek": 67256, "start": 672.56, "end": 678.4399999999999, "text": " So right now we kept it that simple with just specifying a V&I using VXLAN by default,", "tokens": [407, 558, 586, 321, 4305, 309, 300, 2199, 365, 445, 1608, 5489, 257, 691, 5, 40, 1228, 691, 55, 36527, 538, 7576, 11], "temperature": 0.0, "avg_logprob": -0.17566184202829996, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0001362430484732613}, {"id": 134, "seek": 67256, "start": 678.4399999999999, "end": 679.9599999999999, "text": " just passing a range.", "tokens": [445, 8437, 257, 3613, 13], "temperature": 0.0, "avg_logprob": -0.17566184202829996, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0001362430484732613}, {"id": 135, "seek": 67256, "start": 679.9599999999999, "end": 685.2399999999999, "text": " And we also keep a network attachment definition from multist with one-to-one mapping to network", "tokens": [400, 321, 611, 1066, 257, 3209, 19431, 7123, 490, 2120, 468, 365, 472, 12, 1353, 12, 546, 18350, 281, 3209], "temperature": 0.0, "avg_logprob": -0.17566184202829996, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0001362430484732613}, {"id": 136, "seek": 67256, "start": 685.2399999999999, "end": 690.64, "text": " so that things, we don't change too many things at once.", "tokens": [370, 300, 721, 11, 321, 500, 380, 1319, 886, 867, 721, 412, 1564, 13], "temperature": 0.0, "avg_logprob": -0.17566184202829996, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0001362430484732613}, {"id": 137, "seek": 67256, "start": 690.64, "end": 694.92, "text": " And then we use those networks into the pod definitions.", "tokens": [400, 550, 321, 764, 729, 9590, 666, 264, 2497, 21988, 13], "temperature": 0.0, "avg_logprob": -0.17566184202829996, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0001362430484732613}, {"id": 138, "seek": 67256, "start": 694.92, "end": 699.4399999999999, "text": " So we reference them the multist way.", "tokens": [407, 321, 6408, 552, 264, 2120, 468, 636, 13], "temperature": 0.0, "avg_logprob": -0.17566184202829996, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0001362430484732613}, {"id": 139, "seek": 69944, "start": 699.44, "end": 704.72, "text": " We can reference them as well in services with dedicated annotations.", "tokens": [492, 393, 6408, 552, 382, 731, 294, 3328, 365, 8374, 25339, 763, 13], "temperature": 0.0, "avg_logprob": -0.15061231938804068, "compression_ratio": 1.588235294117647, "no_speech_prob": 9.875115938484669e-05}, {"id": 140, "seek": 69944, "start": 704.72, "end": 710.48, "text": " And so that way we tell our agents to program VP in a way where the services apply only", "tokens": [400, 370, 300, 636, 321, 980, 527, 12554, 281, 1461, 35812, 294, 257, 636, 689, 264, 3328, 3079, 787], "temperature": 0.0, "avg_logprob": -0.15061231938804068, "compression_ratio": 1.588235294117647, "no_speech_prob": 9.875115938484669e-05}, {"id": 141, "seek": 69944, "start": 710.48, "end": 712.6, "text": " in a specific network.", "tokens": [294, 257, 2685, 3209, 13], "temperature": 0.0, "avg_logprob": -0.15061231938804068, "compression_ratio": 1.588235294117647, "no_speech_prob": 9.875115938484669e-05}, {"id": 142, "seek": 69944, "start": 712.6, "end": 714.2, "text": " The policy is the same way.", "tokens": [440, 3897, 307, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.15061231938804068, "compression_ratio": 1.588235294117647, "no_speech_prob": 9.875115938484669e-05}, {"id": 143, "seek": 69944, "start": 714.2, "end": 721.8800000000001, "text": " And also that gives us the ability for pods to have a bit more tweaking on the parameters", "tokens": [400, 611, 300, 2709, 505, 264, 3485, 337, 31925, 281, 362, 257, 857, 544, 6986, 2456, 322, 264, 9834], "temperature": 0.0, "avg_logprob": -0.15061231938804068, "compression_ratio": 1.588235294117647, "no_speech_prob": 9.875115938484669e-05}, {"id": 144, "seek": 69944, "start": 721.8800000000001, "end": 723.24, "text": " exposed on the interface.", "tokens": [9495, 322, 264, 9226, 13], "temperature": 0.0, "avg_logprob": -0.15061231938804068, "compression_ratio": 1.588235294117647, "no_speech_prob": 9.875115938484669e-05}, {"id": 145, "seek": 72324, "start": 723.24, "end": 729.4, "text": " So to specify the number of queues we want, the queue depth, and also support multiple", "tokens": [407, 281, 16500, 264, 1230, 295, 631, 1247, 321, 528, 11, 264, 18639, 7161, 11, 293, 611, 1406, 3866], "temperature": 0.0, "avg_logprob": -0.20131932605396619, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00010127491987077519}, {"id": 146, "seek": 72324, "start": 729.4, "end": 730.4, "text": " types.", "tokens": [3467, 13], "temperature": 0.0, "avg_logprob": -0.20131932605396619, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00010127491987077519}, {"id": 147, "seek": 72324, "start": 730.4, "end": 735.12, "text": " So that gives a lot of flexibility to get the performance right and to get, so first", "tokens": [407, 300, 2709, 257, 688, 295, 12635, 281, 483, 264, 3389, 558, 293, 281, 483, 11, 370, 700], "temperature": 0.0, "avg_logprob": -0.20131932605396619, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00010127491987077519}, {"id": 148, "seek": 72324, "start": 735.12, "end": 736.8, "text": " to get the functionalities.", "tokens": [281, 483, 264, 11745, 1088, 13], "temperature": 0.0, "avg_logprob": -0.20131932605396619, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00010127491987077519}, {"id": 149, "seek": 72324, "start": 736.8, "end": 741.48, "text": " So the fact that we have multiple interfaces and so also size them so that the performance", "tokens": [407, 264, 1186, 300, 321, 362, 3866, 28416, 293, 370, 611, 2744, 552, 370, 300, 264, 3389], "temperature": 0.0, "avg_logprob": -0.20131932605396619, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00010127491987077519}, {"id": 150, "seek": 72324, "start": 741.48, "end": 746.12, "text": " is appropriate for the use case that we want to achieve.", "tokens": [307, 6854, 337, 264, 764, 1389, 300, 321, 528, 281, 4584, 13], "temperature": 0.0, "avg_logprob": -0.20131932605396619, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.00010127491987077519}, {"id": 151, "seek": 74612, "start": 746.12, "end": 753.48, "text": " The last nice feature of this is that as we have GoBGP support, we can pair those networks", "tokens": [440, 1036, 1481, 4111, 295, 341, 307, 300, 382, 321, 362, 1037, 33, 38, 47, 1406, 11, 321, 393, 6119, 729, 9590], "temperature": 0.0, "avg_logprob": -0.18728528077574982, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.00014626119809690863}, {"id": 152, "seek": 74612, "start": 753.48, "end": 759.72, "text": " with the outside world if we have a fabric that's VXLAN and if GoBGP supports it.", "tokens": [365, 264, 2380, 1002, 498, 321, 362, 257, 7253, 300, 311, 691, 55, 36527, 293, 498, 1037, 33, 38, 47, 9346, 309, 13], "temperature": 0.0, "avg_logprob": -0.18728528077574982, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.00014626119809690863}, {"id": 153, "seek": 74612, "start": 759.72, "end": 764.4, "text": " So that part is still a bit work in progress and there are a lot of things to get right.", "tokens": [407, 300, 644, 307, 920, 257, 857, 589, 294, 4205, 293, 456, 366, 257, 688, 295, 721, 281, 483, 558, 13], "temperature": 0.0, "avg_logprob": -0.18728528077574982, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.00014626119809690863}, {"id": 154, "seek": 74612, "start": 764.4, "end": 769.32, "text": " But that's the end picture we want to go.", "tokens": [583, 300, 311, 264, 917, 3036, 321, 528, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.18728528077574982, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.00014626119809690863}, {"id": 155, "seek": 76932, "start": 769.32, "end": 777.08, "text": " And this could, so if we put everything together, we would get probably something like that,", "tokens": [400, 341, 727, 11, 370, 498, 321, 829, 1203, 1214, 11, 321, 576, 483, 1391, 746, 411, 300, 11], "temperature": 0.0, "avg_logprob": -0.2269032446892707, "compression_ratio": 1.6422413793103448, "no_speech_prob": 4.405171057442203e-05}, {"id": 156, "seek": 76932, "start": 777.08, "end": 778.48, "text": " that looks like that.", "tokens": [300, 1542, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2269032446892707, "compression_ratio": 1.6422413793103448, "no_speech_prob": 4.405171057442203e-05}, {"id": 157, "seek": 76932, "start": 778.48, "end": 784.2800000000001, "text": " So basically when the users want to connect to this hypothetical VPN and that hypothetical", "tokens": [407, 1936, 562, 264, 5022, 528, 281, 1745, 281, 341, 33053, 24512, 293, 300, 33053], "temperature": 0.0, "avg_logprob": -0.2269032446892707, "compression_ratio": 1.6422413793103448, "no_speech_prob": 4.405171057442203e-05}, {"id": 158, "seek": 76932, "start": 784.2800000000001, "end": 792.12, "text": " printer, it would get into the cluster via GoBGP peering, so traffic is going to be", "tokens": [16671, 11, 309, 576, 483, 666, 264, 13630, 5766, 1037, 33, 38, 47, 520, 1794, 11, 370, 6419, 307, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.2269032446892707, "compression_ratio": 1.6422413793103448, "no_speech_prob": 4.405171057442203e-05}, {"id": 159, "seek": 76932, "start": 792.12, "end": 798.7600000000001, "text": " attracted to the green network, heat service IP in that network, so get some load balancing", "tokens": [15912, 281, 264, 3092, 3209, 11, 3738, 2643, 8671, 294, 300, 3209, 11, 370, 483, 512, 3677, 22495], "temperature": 0.0, "avg_logprob": -0.2269032446892707, "compression_ratio": 1.6422413793103448, "no_speech_prob": 4.405171057442203e-05}, {"id": 160, "seek": 79876, "start": 798.76, "end": 807.3199999999999, "text": " across the nodes, then it's going to be deciphered in a pod that then encapsulate traffic and", "tokens": [2108, 264, 13891, 11, 550, 309, 311, 516, 281, 312, 49859, 292, 294, 257, 2497, 300, 550, 38745, 5256, 6419, 293], "temperature": 0.0, "avg_logprob": -0.15629723145789706, "compression_ratio": 1.6213991769547325, "no_speech_prob": 5.900839823880233e-05}, {"id": 161, "seek": 79876, "start": 807.3199999999999, "end": 811.28, "text": " pass it, for example, to a NAT pod running in user space.", "tokens": [1320, 309, 11, 337, 1365, 11, 281, 257, 14500, 2497, 2614, 294, 4195, 1901, 13], "temperature": 0.0, "avg_logprob": -0.15629723145789706, "compression_ratio": 1.6213991769547325, "no_speech_prob": 5.900839823880233e-05}, {"id": 162, "seek": 79876, "start": 811.28, "end": 818.2, "text": " So here I put another type of interface that is more performance oriented and then exit", "tokens": [407, 510, 286, 829, 1071, 2010, 295, 9226, 300, 307, 544, 3389, 21841, 293, 550, 11043], "temperature": 0.0, "avg_logprob": -0.15629723145789706, "compression_ratio": 1.6213991769547325, "no_speech_prob": 5.900839823880233e-05}, {"id": 163, "seek": 79876, "start": 818.2, "end": 823.8, "text": " the cluster on a different VLAN peered with the outside world.", "tokens": [264, 13630, 322, 257, 819, 691, 36527, 520, 4073, 365, 264, 2380, 1002, 13], "temperature": 0.0, "avg_logprob": -0.15629723145789706, "compression_ratio": 1.6213991769547325, "no_speech_prob": 5.900839823880233e-05}, {"id": 164, "seek": 79876, "start": 823.8, "end": 828.48, "text": " So some parts still need to be done, but the general internal logic of the cluster is still", "tokens": [407, 512, 3166, 920, 643, 281, 312, 1096, 11, 457, 264, 2674, 6920, 9952, 295, 264, 13630, 307, 920], "temperature": 0.0, "avg_logprob": -0.15629723145789706, "compression_ratio": 1.6213991769547325, "no_speech_prob": 5.900839823880233e-05}, {"id": 165, "seek": 82848, "start": 828.48, "end": 836.6, "text": " something that works and that brings the ability for container networking functions to run", "tokens": [746, 300, 1985, 293, 300, 5607, 264, 3485, 337, 10129, 17985, 6828, 281, 1190], "temperature": 0.0, "avg_logprob": -0.17586218609529383, "compression_ratio": 1.3870967741935485, "no_speech_prob": 9.641877113608643e-05}, {"id": 166, "seek": 82848, "start": 836.6, "end": 847.6, "text": " unmodified with their multiple interfaces directly in a somewhat regular cluster.", "tokens": [517, 8014, 2587, 365, 641, 3866, 28416, 3838, 294, 257, 8344, 3890, 13630, 13], "temperature": 0.0, "avg_logprob": -0.17586218609529383, "compression_ratio": 1.3870967741935485, "no_speech_prob": 9.641877113608643e-05}, {"id": 167, "seek": 84760, "start": 847.6, "end": 858.9200000000001, "text": " So we spoke about improving performance of the network, of the underlying interface,", "tokens": [407, 321, 7179, 466, 11470, 3389, 295, 264, 3209, 11, 295, 264, 14217, 9226, 11], "temperature": 0.0, "avg_logprob": -0.18644547866562666, "compression_ratio": 1.630057803468208, "no_speech_prob": 8.741523197386414e-05}, {"id": 168, "seek": 84760, "start": 858.9200000000001, "end": 867.8000000000001, "text": " but we can also improve the performance with which the application in the pod consumes their", "tokens": [457, 321, 393, 611, 3470, 264, 3389, 365, 597, 264, 3861, 294, 264, 2497, 48823, 641], "temperature": 0.0, "avg_logprob": -0.18644547866562666, "compression_ratio": 1.630057803468208, "no_speech_prob": 8.741523197386414e-05}, {"id": 169, "seek": 84760, "start": 867.8000000000001, "end": 869.2, "text": " own interfaces.", "tokens": [1065, 28416, 13], "temperature": 0.0, "avg_logprob": -0.18644547866562666, "compression_ratio": 1.630057803468208, "no_speech_prob": 8.741523197386414e-05}, {"id": 170, "seek": 84760, "start": 869.2, "end": 876.4, "text": " So the standard way applications usually consume packets within pods is via socket APIs.", "tokens": [407, 264, 3832, 636, 5821, 2673, 14732, 30364, 1951, 31925, 307, 5766, 19741, 21445, 13], "temperature": 0.0, "avg_logprob": -0.18644547866562666, "compression_ratio": 1.630057803468208, "no_speech_prob": 8.741523197386414e-05}, {"id": 171, "seek": 87640, "start": 876.4, "end": 880.6, "text": " So it's really standard, but you have to go through the kernel and it's a code path that", "tokens": [407, 309, 311, 534, 3832, 11, 457, 291, 362, 281, 352, 807, 264, 28256, 293, 309, 311, 257, 3089, 3100, 300], "temperature": 0.0, "avg_logprob": -0.2015591374150029, "compression_ratio": 1.6156716417910448, "no_speech_prob": 0.00018818554235622287}, {"id": 172, "seek": 87640, "start": 880.6, "end": 884.12, "text": " wasn't designed for the performance levels of modern apps.", "tokens": [2067, 380, 4761, 337, 264, 3389, 4358, 295, 4363, 7733, 13], "temperature": 0.0, "avg_logprob": -0.2015591374150029, "compression_ratio": 1.6156716417910448, "no_speech_prob": 0.00018818554235622287}, {"id": 173, "seek": 87640, "start": 884.12, "end": 888.12, "text": " So that's why GSO came up as a network stack optimization.", "tokens": [407, 300, 311, 983, 460, 17188, 1361, 493, 382, 257, 3209, 8630, 19618, 13], "temperature": 0.0, "avg_logprob": -0.2015591374150029, "compression_ratio": 1.6156716417910448, "no_speech_prob": 0.00018818554235622287}, {"id": 174, "seek": 87640, "start": 888.12, "end": 893.24, "text": " But here with VPP running, it would be nice to be able to bypass the network stack and", "tokens": [583, 510, 365, 691, 17755, 2614, 11, 309, 576, 312, 1481, 281, 312, 1075, 281, 24996, 264, 3209, 8630, 293], "temperature": 0.0, "avg_logprob": -0.2015591374150029, "compression_ratio": 1.6156716417910448, "no_speech_prob": 0.00018818554235622287}, {"id": 175, "seek": 87640, "start": 893.24, "end": 897.16, "text": " pass the packets directly from VPP and not touching the kernel.", "tokens": [1320, 264, 30364, 3838, 490, 691, 17755, 293, 406, 11175, 264, 28256, 13], "temperature": 0.0, "avg_logprob": -0.2015591374150029, "compression_ratio": 1.6156716417910448, "no_speech_prob": 0.00018818554235622287}, {"id": 176, "seek": 87640, "start": 897.16, "end": 904.36, "text": " So fortunately, VPP exposes two different ways to consume those interfaces.", "tokens": [407, 25511, 11, 691, 17755, 1278, 4201, 732, 819, 2098, 281, 14732, 729, 28416, 13], "temperature": 0.0, "avg_logprob": -0.2015591374150029, "compression_ratio": 1.6156716417910448, "no_speech_prob": 0.00018818554235622287}, {"id": 177, "seek": 90436, "start": 904.36, "end": 909.88, "text": " We'll mostly go into the first one, which is the memory interface.", "tokens": [492, 603, 5240, 352, 666, 264, 700, 472, 11, 597, 307, 264, 4675, 9226, 13], "temperature": 0.0, "avg_logprob": -0.28866835338313407, "compression_ratio": 1.4108910891089108, "no_speech_prob": 0.00017831043805927038}, {"id": 178, "seek": 90436, "start": 909.88, "end": 918.2, "text": " So basically, it's a packet oriented interface standard relying on a memory segment for speed.", "tokens": [407, 1936, 11, 309, 311, 257, 20300, 21841, 9226, 3832, 24140, 322, 257, 4675, 9469, 337, 3073, 13], "temperature": 0.0, "avg_logprob": -0.28866835338313407, "compression_ratio": 1.4108910891089108, "no_speech_prob": 0.00017831043805927038}, {"id": 179, "seek": 90436, "start": 918.2, "end": 921.04, "text": " And this can be leveraged by an application via a simple library.", "tokens": [400, 341, 393, 312, 12451, 2980, 538, 364, 3861, 5766, 257, 2199, 6405, 13], "temperature": 0.0, "avg_logprob": -0.28866835338313407, "compression_ratio": 1.4108910891089108, "no_speech_prob": 0.00017831043805927038}, {"id": 180, "seek": 90436, "start": 921.04, "end": 928.6800000000001, "text": " So either GoMemi, PhiliBMMF in C, or DPDK, or even a VPP.", "tokens": [407, 2139, 1037, 44, 13372, 11, 2623, 2312, 33, 17365, 37, 294, 383, 11, 420, 413, 17349, 42, 11, 420, 754, 257, 691, 17755, 13], "temperature": 0.0, "avg_logprob": -0.28866835338313407, "compression_ratio": 1.4108910891089108, "no_speech_prob": 0.00017831043805927038}, {"id": 181, "seek": 92868, "start": 928.68, "end": 937.9599999999999, "text": " And so provide a really high speed way of consuming that extra interface in the pod.", "tokens": [400, 370, 2893, 257, 534, 1090, 3073, 636, 295, 19867, 300, 2857, 9226, 294, 264, 2497, 13], "temperature": 0.0, "avg_logprob": -0.18828837935988968, "compression_ratio": 1.5891089108910892, "no_speech_prob": 3.4820444852812216e-05}, {"id": 182, "seek": 92868, "start": 937.9599999999999, "end": 944.28, "text": " And the really nice thing about this is that it brings also the connection between the", "tokens": [400, 264, 534, 1481, 551, 466, 341, 307, 300, 309, 5607, 611, 264, 4984, 1296, 264], "temperature": 0.0, "avg_logprob": -0.18828837935988968, "compression_ratio": 1.5891089108910892, "no_speech_prob": 3.4820444852812216e-05}, {"id": 183, "seek": 92868, "start": 944.28, "end": 951.56, "text": " Kubernetes network, Kubernetes SDN, and the pod into user space, meaning that now that", "tokens": [23145, 3209, 11, 23145, 14638, 45, 11, 293, 264, 2497, 666, 4195, 1901, 11, 3620, 300, 586, 300], "temperature": 0.0, "avg_logprob": -0.18828837935988968, "compression_ratio": 1.5891089108910892, "no_speech_prob": 3.4820444852812216e-05}, {"id": 184, "seek": 92868, "start": 951.56, "end": 957.88, "text": " connection lives in a regular C program, we can also leverage.", "tokens": [4984, 2909, 294, 257, 3890, 383, 1461, 11, 321, 393, 611, 13982, 13], "temperature": 0.0, "avg_logprob": -0.18828837935988968, "compression_ratio": 1.5891089108910892, "no_speech_prob": 3.4820444852812216e-05}, {"id": 185, "seek": 95788, "start": 957.88, "end": 962.6, "text": " So it's easier to leverage CPU optimizations and new features.", "tokens": [407, 309, 311, 3571, 281, 13982, 13199, 5028, 14455, 293, 777, 4122, 13], "temperature": 0.0, "avg_logprob": -0.29077032634190153, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00017483778356108814}, {"id": 186, "seek": 95788, "start": 962.6, "end": 969.32, "text": " And that's where the Silicon re-enters the picture and the work from Mrytka from Intel", "tokens": [400, 300, 311, 689, 264, 25351, 319, 12, 317, 433, 264, 3036, 293, 264, 589, 490, 376, 627, 83, 2330, 490, 19762], "temperature": 0.0, "avg_logprob": -0.29077032634190153, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00017483778356108814}, {"id": 187, "seek": 95788, "start": 969.32, "end": 972.2, "text": " and their team.", "tokens": [293, 641, 1469, 13], "temperature": 0.0, "avg_logprob": -0.29077032634190153, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00017483778356108814}, {"id": 188, "seek": 95788, "start": 972.2, "end": 980.84, "text": " So they benchmarked this kind of setup and also introduced an optimization that's coming", "tokens": [407, 436, 18927, 292, 341, 733, 295, 8657, 293, 611, 7268, 364, 19618, 300, 311, 1348], "temperature": 0.0, "avg_logprob": -0.29077032634190153, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00017483778356108814}, {"id": 189, "seek": 95788, "start": 980.84, "end": 985.8, "text": " into the fourth generation Intel Xeon that's called Data Streaming Accelerator.", "tokens": [666, 264, 6409, 5125, 19762, 1783, 27015, 300, 311, 1219, 11888, 24904, 278, 5725, 6185, 1639, 13], "temperature": 0.0, "avg_logprob": -0.29077032634190153, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.00017483778356108814}, {"id": 190, "seek": 98580, "start": 985.8, "end": 993.8399999999999, "text": " Basically, it's a way to optimize copies between processes on some CPUs.", "tokens": [8537, 11, 309, 311, 257, 636, 281, 19719, 14341, 1296, 7555, 322, 512, 13199, 82, 13], "temperature": 0.0, "avg_logprob": -0.15768375396728515, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.00011089146573795006}, {"id": 191, "seek": 98580, "start": 993.8399999999999, "end": 999.04, "text": " And so what they did is compare the performance that we get with the Kubernetes clusters,", "tokens": [400, 370, 437, 436, 630, 307, 6794, 264, 3389, 300, 321, 483, 365, 264, 23145, 23313, 11], "temperature": 0.0, "avg_logprob": -0.15768375396728515, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.00011089146573795006}, {"id": 192, "seek": 98580, "start": 999.04, "end": 1002.1999999999999, "text": " multiple interfaces, and a simple pod.", "tokens": [3866, 28416, 11, 293, 257, 2199, 2497, 13], "temperature": 0.0, "avg_logprob": -0.15768375396728515, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.00011089146573795006}, {"id": 193, "seek": 98580, "start": 1002.1999999999999, "end": 1010.8399999999999, "text": " So not bringing in the old VPN logic, just doing L3 patch and seeing how fast things", "tokens": [407, 406, 5062, 294, 264, 1331, 24512, 9952, 11, 445, 884, 441, 18, 9972, 293, 2577, 577, 2370, 721], "temperature": 0.0, "avg_logprob": -0.15768375396728515, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.00011089146573795006}, {"id": 194, "seek": 101084, "start": 1010.84, "end": 1020.44, "text": " could go between regular kernel interfaces, the turn, the memory interfaces, and the memory", "tokens": [727, 352, 1296, 3890, 28256, 28416, 11, 264, 1261, 11, 264, 4675, 28416, 11, 293, 264, 4675], "temperature": 0.0, "avg_logprob": -0.20432891485826024, "compression_ratio": 1.5616438356164384, "no_speech_prob": 9.4764975074213e-05}, {"id": 195, "seek": 101084, "start": 1020.44, "end": 1027.4, "text": " interfaces leveraging those optimizations in the CPU.", "tokens": [28416, 32666, 729, 5028, 14455, 294, 264, 13199, 13], "temperature": 0.0, "avg_logprob": -0.20432891485826024, "compression_ratio": 1.5616438356164384, "no_speech_prob": 9.4764975074213e-05}, {"id": 196, "seek": 101084, "start": 1027.4, "end": 1035.3600000000001, "text": " So that gives those graphs that are really, so that have a lot of numbers in them.", "tokens": [407, 300, 2709, 729, 24877, 300, 366, 534, 11, 370, 300, 362, 257, 688, 295, 3547, 294, 552, 13], "temperature": 0.0, "avg_logprob": -0.20432891485826024, "compression_ratio": 1.5616438356164384, "no_speech_prob": 9.4764975074213e-05}, {"id": 197, "seek": 103536, "start": 1035.36, "end": 1041.28, "text": " But basically, I try to sum up quite quickly what this gives.", "tokens": [583, 1936, 11, 286, 853, 281, 2408, 493, 1596, 2661, 437, 341, 2709, 13], "temperature": 0.0, "avg_logprob": -0.2124770897022192, "compression_ratio": 1.3352601156069364, "no_speech_prob": 0.0006779662799090147}, {"id": 198, "seek": 103536, "start": 1041.28, "end": 1047.12, "text": " There are two MTUs, 1,500 bytes and 9,000 bytes here.", "tokens": [821, 366, 732, 37333, 29211, 11, 502, 11, 7526, 36088, 293, 1722, 11, 1360, 36088, 510, 13], "temperature": 0.0, "avg_logprob": -0.2124770897022192, "compression_ratio": 1.3352601156069364, "no_speech_prob": 0.0006779662799090147}, {"id": 199, "seek": 103536, "start": 1047.12, "end": 1050.8799999999999, "text": " The performance for turn interfaces in dark blue.", "tokens": [440, 3389, 337, 1261, 28416, 294, 2877, 3344, 13], "temperature": 0.0, "avg_logprob": -0.2124770897022192, "compression_ratio": 1.3352601156069364, "no_speech_prob": 0.0006779662799090147}, {"id": 200, "seek": 103536, "start": 1050.8799999999999, "end": 1056.9199999999998, "text": " Blue is the first MAMIF and the DSA optimized MAMIF is in yellow.", "tokens": [8510, 307, 264, 700, 376, 2865, 12775, 293, 264, 413, 8886, 26941, 376, 2865, 12775, 307, 294, 5566, 13], "temperature": 0.0, "avg_logprob": -0.2124770897022192, "compression_ratio": 1.3352601156069364, "no_speech_prob": 0.0006779662799090147}, {"id": 201, "seek": 105692, "start": 1056.92, "end": 1069.92, "text": " And basically, what this gives is that the performance is really, so it brings really", "tokens": [400, 1936, 11, 437, 341, 2709, 307, 300, 264, 3389, 307, 534, 11, 370, 309, 5607, 534], "temperature": 0.0, "avg_logprob": -0.2673540963066949, "compression_ratio": 1.3507462686567164, "no_speech_prob": 5.09703422721941e-05}, {"id": 202, "seek": 105692, "start": 1069.92, "end": 1084.88, "text": " a huge difference between, so, sorry, throughput with DSA is 2.3 times faster than with regular", "tokens": [257, 2603, 2649, 1296, 11, 370, 11, 2597, 11, 44629, 365, 413, 8886, 307, 568, 13, 18, 1413, 4663, 813, 365, 3890], "temperature": 0.0, "avg_logprob": -0.2673540963066949, "compression_ratio": 1.3507462686567164, "no_speech_prob": 5.09703422721941e-05}, {"id": 203, "seek": 108488, "start": 1084.88, "end": 1089.0800000000002, "text": " MAMIF for the 1,500 bytes packets.", "tokens": [376, 2865, 12775, 337, 264, 502, 11, 7526, 36088, 30364, 13], "temperature": 0.0, "avg_logprob": -0.22246999740600587, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.00016045928350649774}, {"id": 204, "seek": 108488, "start": 1089.0800000000002, "end": 1094.64, "text": " And if you go with DSA enabled, it's 23 times faster than turn tap.", "tokens": [400, 498, 291, 352, 365, 413, 8886, 15172, 11, 309, 311, 6673, 1413, 4663, 813, 1261, 5119, 13], "temperature": 0.0, "avg_logprob": -0.22246999740600587, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.00016045928350649774}, {"id": 205, "seek": 108488, "start": 1094.64, "end": 1102.72, "text": " And with a 9,000 byte MTU, basically, you get more than 60 times faster with the MAMIF", "tokens": [400, 365, 257, 1722, 11, 1360, 40846, 37333, 52, 11, 1936, 11, 291, 483, 544, 813, 4060, 1413, 4663, 365, 264, 376, 2865, 12775], "temperature": 0.0, "avg_logprob": -0.22246999740600587, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.00016045928350649774}, {"id": 206, "seek": 108488, "start": 1102.72, "end": 1106.2, "text": " that's optimized with DSA.", "tokens": [300, 311, 26941, 365, 413, 8886, 13], "temperature": 0.0, "avg_logprob": -0.22246999740600587, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.00016045928350649774}, {"id": 207, "seek": 110620, "start": 1106.2, "end": 1116.24, "text": " Basically the digit, so the number that's really interesting is that with 200,000, so", "tokens": [8537, 264, 14293, 11, 370, 264, 1230, 300, 311, 534, 1880, 307, 300, 365, 2331, 11, 1360, 11, 370], "temperature": 0.0, "avg_logprob": -0.22142866181164253, "compression_ratio": 1.568075117370892, "no_speech_prob": 7.349078077822924e-05}, {"id": 208, "seek": 110620, "start": 1116.24, "end": 1120.6000000000001, "text": " basically you get a single call doing 100 Gs with that.", "tokens": [1936, 291, 483, 257, 2167, 818, 884, 2319, 460, 82, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.22142866181164253, "compression_ratio": 1.568075117370892, "no_speech_prob": 7.349078077822924e-05}, {"id": 209, "seek": 110620, "start": 1120.6000000000001, "end": 1125.0, "text": " And that without too much modifications of the applications.", "tokens": [400, 300, 1553, 886, 709, 26881, 295, 264, 5821, 13], "temperature": 0.0, "avg_logprob": -0.22142866181164253, "compression_ratio": 1.568075117370892, "no_speech_prob": 7.349078077822924e-05}, {"id": 210, "seek": 110620, "start": 1125.0, "end": 1127.92, "text": " So basically, you just spin a regular cluster.", "tokens": [407, 1936, 11, 291, 445, 6060, 257, 3890, 13630, 13], "temperature": 0.0, "avg_logprob": -0.22142866181164253, "compression_ratio": 1.568075117370892, "no_speech_prob": 7.349078077822924e-05}, {"id": 211, "seek": 110620, "start": 1127.92, "end": 1132.76, "text": " If the CPU supports it, you use a regular library and you're able to consume packets", "tokens": [759, 264, 13199, 9346, 309, 11, 291, 764, 257, 3890, 6405, 293, 291, 434, 1075, 281, 14732, 30364], "temperature": 0.0, "avg_logprob": -0.22142866181164253, "compression_ratio": 1.568075117370892, "no_speech_prob": 7.349078077822924e-05}, {"id": 212, "seek": 113276, "start": 1132.76, "end": 1139.96, "text": " at really huge speeds without modifying the application too much.", "tokens": [412, 534, 2603, 16411, 1553, 42626, 264, 3861, 886, 709, 13], "temperature": 0.0, "avg_logprob": -0.206636571172458, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.00017773888248484582}, {"id": 213, "seek": 113276, "start": 1139.96, "end": 1150.12, "text": " So there is another graph looking into the scaling with number of calls, both with small", "tokens": [407, 456, 307, 1071, 4295, 1237, 666, 264, 21589, 365, 1230, 295, 5498, 11, 1293, 365, 1359], "temperature": 0.0, "avg_logprob": -0.206636571172458, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.00017773888248484582}, {"id": 214, "seek": 113276, "start": 1150.12, "end": 1153.52, "text": " MTUs and large MTUs.", "tokens": [37333, 29211, 293, 2416, 37333, 29211, 13], "temperature": 0.0, "avg_logprob": -0.206636571172458, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.00017773888248484582}, {"id": 215, "seek": 113276, "start": 1153.52, "end": 1159.92, "text": " Basically that shows that we can spare calls when going, so turn tap does not scale very", "tokens": [8537, 300, 3110, 300, 321, 393, 13798, 5498, 562, 516, 11, 370, 1261, 5119, 775, 406, 4373, 588], "temperature": 0.0, "avg_logprob": -0.206636571172458, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.00017773888248484582}, {"id": 216, "seek": 113276, "start": 1159.92, "end": 1160.92, "text": " well.", "tokens": [731, 13], "temperature": 0.0, "avg_logprob": -0.206636571172458, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.00017773888248484582}, {"id": 217, "seek": 116092, "start": 1160.92, "end": 1174.52, "text": " So the regular MAMIF scales with 1 to 6 calls and DSA achieves the same results with 2 to", "tokens": [407, 264, 3890, 376, 2865, 12775, 17408, 365, 502, 281, 1386, 5498, 293, 413, 8886, 3538, 977, 264, 912, 3542, 365, 568, 281], "temperature": 0.0, "avg_logprob": -0.2934683502697554, "compression_ratio": 1.448051948051948, "no_speech_prob": 0.00023342181521002203}, {"id": 218, "seek": 116092, "start": 1174.52, "end": 1178.5600000000002, "text": " 3 less calls than its regular MAMIF counterpart.", "tokens": [805, 1570, 5498, 813, 1080, 3890, 376, 2865, 12775, 22335, 13], "temperature": 0.0, "avg_logprob": -0.2934683502697554, "compression_ratio": 1.448051948051948, "no_speech_prob": 0.00023342181521002203}, {"id": 219, "seek": 116092, "start": 1178.5600000000002, "end": 1184.3600000000001, "text": " So basically you achieve 100 Gs, which was the limit of the setup with a single call", "tokens": [407, 1936, 291, 4584, 2319, 460, 82, 11, 597, 390, 264, 4948, 295, 264, 8657, 365, 257, 2167, 818], "temperature": 0.0, "avg_logprob": -0.2934683502697554, "compression_ratio": 1.448051948051948, "no_speech_prob": 0.00023342181521002203}, {"id": 220, "seek": 118436, "start": 1184.36, "end": 1193.6, "text": " in the case of large MTUs and 3 calls in the case of smaller MTUs.", "tokens": [294, 264, 1389, 295, 2416, 37333, 29211, 293, 805, 5498, 294, 264, 1389, 295, 4356, 37333, 29211, 13], "temperature": 0.0, "avg_logprob": -0.17252208057202792, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00010853847197722644}, {"id": 221, "seek": 118436, "start": 1193.6, "end": 1196.08, "text": " So that's all for the talk.", "tokens": [407, 300, 311, 439, 337, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.17252208057202792, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00010853847197722644}, {"id": 222, "seek": 118436, "start": 1196.08, "end": 1203.4399999999998, "text": " Sorry I went into a variety of different subjects because that topic goes into a lot of different", "tokens": [4919, 286, 1437, 666, 257, 5673, 295, 819, 13066, 570, 300, 4829, 1709, 666, 257, 688, 295, 819], "temperature": 0.0, "avg_logprob": -0.17252208057202792, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00010853847197722644}, {"id": 223, "seek": 118436, "start": 1203.4399999999998, "end": 1204.4399999999998, "text": " directions.", "tokens": [11095, 13], "temperature": 0.0, "avg_logprob": -0.17252208057202792, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00010853847197722644}, {"id": 224, "seek": 118436, "start": 1204.4399999999998, "end": 1210.8, "text": " Basically that was to give you another view of the duration we are trying to go, trying", "tokens": [8537, 300, 390, 281, 976, 291, 1071, 1910, 295, 264, 16365, 321, 366, 1382, 281, 352, 11, 1382], "temperature": 0.0, "avg_logprob": -0.17252208057202792, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00010853847197722644}, {"id": 225, "seek": 121080, "start": 1210.8, "end": 1216.68, "text": " to bring all those pieces together in a framework that allows us to make those CNFs run into", "tokens": [281, 1565, 439, 729, 3755, 1214, 294, 257, 8388, 300, 4045, 505, 281, 652, 729, 14589, 37, 82, 1190, 666], "temperature": 0.0, "avg_logprob": -0.17655948638916016, "compression_ratio": 1.580392156862745, "no_speech_prob": 0.00039836333598941565}, {"id": 226, "seek": 121080, "start": 1216.68, "end": 1219.52, "text": " a community environment.", "tokens": [257, 1768, 2823, 13], "temperature": 0.0, "avg_logprob": -0.17655948638916016, "compression_ratio": 1.580392156862745, "no_speech_prob": 0.00039836333598941565}, {"id": 227, "seek": 121080, "start": 1219.52, "end": 1221.44, "text": " This work is open source.", "tokens": [639, 589, 307, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.17655948638916016, "compression_ratio": 1.580392156862745, "no_speech_prob": 0.00039836333598941565}, {"id": 228, "seek": 121080, "start": 1221.44, "end": 1227.48, "text": " There are the details of the tests that were done in the following slides.", "tokens": [821, 366, 264, 4365, 295, 264, 6921, 300, 645, 1096, 294, 264, 3480, 9788, 13], "temperature": 0.0, "avg_logprob": -0.17655948638916016, "compression_ratio": 1.580392156862745, "no_speech_prob": 0.00039836333598941565}, {"id": 229, "seek": 121080, "start": 1227.48, "end": 1233.68, "text": " You can find us on GitHub and there is also a Slack channel open where you can ask questions.", "tokens": [509, 393, 915, 505, 322, 23331, 293, 456, 307, 611, 257, 37211, 2269, 1269, 689, 291, 393, 1029, 1651, 13], "temperature": 0.0, "avg_logprob": -0.17655948638916016, "compression_ratio": 1.580392156862745, "no_speech_prob": 0.00039836333598941565}, {"id": 230, "seek": 121080, "start": 1233.68, "end": 1239.28, "text": " And we have a new release coming up in Beta aiming for GA that's going to go without soon.", "tokens": [400, 321, 362, 257, 777, 4374, 1348, 493, 294, 33286, 20253, 337, 22841, 300, 311, 516, 281, 352, 1553, 2321, 13], "temperature": 0.0, "avg_logprob": -0.17655948638916016, "compression_ratio": 1.580392156862745, "no_speech_prob": 0.00039836333598941565}, {"id": 231, "seek": 123928, "start": 1239.28, "end": 1245.2, "text": " So thanks a lot for listening, so here are the details.", "tokens": [407, 3231, 257, 688, 337, 4764, 11, 370, 510, 366, 264, 4365, 13], "temperature": 0.0, "avg_logprob": -0.2575131607055664, "compression_ratio": 1.3714285714285714, "no_speech_prob": 0.00163697125390172}, {"id": 232, "seek": 123928, "start": 1245.2, "end": 1260.72, "text": " And I'm open for questions if you have any.", "tokens": [400, 286, 478, 1269, 337, 1651, 498, 291, 362, 604, 13], "temperature": 0.0, "avg_logprob": -0.2575131607055664, "compression_ratio": 1.3714285714285714, "no_speech_prob": 0.00163697125390172}, {"id": 233, "seek": 123928, "start": 1260.72, "end": 1266.68, "text": " Just one question for the sake of it, have you ever thought about some shared memory between", "tokens": [1449, 472, 1168, 337, 264, 9717, 295, 309, 11, 362, 291, 1562, 1194, 466, 512, 5507, 4675, 1296], "temperature": 0.0, "avg_logprob": -0.2575131607055664, "compression_ratio": 1.3714285714285714, "no_speech_prob": 0.00163697125390172}, {"id": 234, "seek": 126668, "start": 1266.68, "end": 1273.72, "text": " the different parts to eliminate the need to copy over the packets?", "tokens": [264, 819, 3166, 281, 13819, 264, 643, 281, 5055, 670, 264, 30364, 30], "temperature": 0.0, "avg_logprob": -0.1947828879723182, "compression_ratio": 1.4596273291925466, "no_speech_prob": 0.0013078151969239116}, {"id": 235, "seek": 126668, "start": 1273.72, "end": 1284.8400000000001, "text": " So we thought of this, so there are different ways to do that.", "tokens": [407, 321, 1194, 295, 341, 11, 370, 456, 366, 819, 2098, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1947828879723182, "compression_ratio": 1.4596273291925466, "no_speech_prob": 0.0013078151969239116}, {"id": 236, "seek": 126668, "start": 1284.8400000000001, "end": 1292.72, "text": " So there is the VCR which I haven't spoken about, which is a way of opening the sockets", "tokens": [407, 456, 307, 264, 691, 18547, 597, 286, 2378, 380, 10759, 466, 11, 597, 307, 257, 636, 295, 5193, 264, 370, 11984], "temperature": 0.0, "avg_logprob": -0.1947828879723182, "compression_ratio": 1.4596273291925466, "no_speech_prob": 0.0013078151969239116}, {"id": 237, "seek": 126668, "start": 1292.72, "end": 1293.96, "text": " directly in VPP.", "tokens": [3838, 294, 691, 17755, 13], "temperature": 0.0, "avg_logprob": -0.1947828879723182, "compression_ratio": 1.4596273291925466, "no_speech_prob": 0.0013078151969239116}, {"id": 238, "seek": 129396, "start": 1293.96, "end": 1300.48, "text": " So basically you do a list in VPP for TCP, UDP or given protocol, so like the sockets", "tokens": [407, 1936, 291, 360, 257, 1329, 294, 691, 17755, 337, 48965, 11, 624, 11373, 420, 2212, 10336, 11, 370, 411, 264, 370, 11984], "temperature": 0.0, "avg_logprob": -0.28027263130109337, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00018229958368465304}, {"id": 239, "seek": 129396, "start": 1300.48, "end": 1301.48, "text": " APIs.", "tokens": [21445, 13], "temperature": 0.0, "avg_logprob": -0.28027263130109337, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00018229958368465304}, {"id": 240, "seek": 129396, "start": 1301.48, "end": 1307.48, "text": " And that supports directly, so basically the data never leaves VPP and you can do direct", "tokens": [400, 300, 9346, 3838, 11, 370, 1936, 264, 1412, 1128, 5510, 691, 17755, 293, 291, 393, 360, 2047], "temperature": 0.0, "avg_logprob": -0.28027263130109337, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00018229958368465304}, {"id": 241, "seek": 129396, "start": 1307.48, "end": 1315.2, "text": " copies between processes without having to copy because everything stays in VPP in the", "tokens": [14341, 1296, 7555, 1553, 1419, 281, 5055, 570, 1203, 10834, 294, 691, 17755, 294, 264], "temperature": 0.0, "avg_logprob": -0.28027263130109337, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00018229958368465304}, {"id": 242, "seek": 129396, "start": 1315.2, "end": 1316.2, "text": " end.", "tokens": [917, 13], "temperature": 0.0, "avg_logprob": -0.28027263130109337, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00018229958368465304}, {"id": 243, "seek": 129396, "start": 1316.2, "end": 1322.76, "text": " For MMF, we don't support that out of the box but nothing forbids you to spawn two pods,", "tokens": [1171, 34191, 37, 11, 321, 500, 380, 1406, 300, 484, 295, 264, 2424, 457, 1825, 16603, 3742, 291, 281, 17088, 732, 31925, 11], "temperature": 0.0, "avg_logprob": -0.28027263130109337, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.00018229958368465304}, {"id": 244, "seek": 132276, "start": 1322.76, "end": 1327.64, "text": " make them share a socket and it's only shared memory so you can directly do it without having", "tokens": [652, 552, 2073, 257, 19741, 293, 309, 311, 787, 5507, 4675, 370, 291, 393, 3838, 360, 309, 1553, 1419], "temperature": 0.0, "avg_logprob": -0.2289106913975307, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00040057505248114467}, {"id": 245, "seek": 132276, "start": 1327.64, "end": 1330.76, "text": " to spin up the whole thing.", "tokens": [281, 6060, 493, 264, 1379, 551, 13], "temperature": 0.0, "avg_logprob": -0.2289106913975307, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00040057505248114467}, {"id": 246, "seek": 132276, "start": 1330.76, "end": 1336.0, "text": " So you could even do that in any cluster or directly on bare metal.", "tokens": [407, 291, 727, 754, 360, 300, 294, 604, 13630, 420, 3838, 322, 6949, 5760, 13], "temperature": 0.0, "avg_logprob": -0.2289106913975307, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00040057505248114467}, {"id": 247, "seek": 132276, "start": 1336.0, "end": 1345.6, "text": " So MMF is really a lightweight protocol so you can do that just with a regular socket.", "tokens": [407, 34191, 37, 307, 534, 257, 22052, 10336, 370, 291, 393, 360, 300, 445, 365, 257, 3890, 19741, 13], "temperature": 0.0, "avg_logprob": -0.2289106913975307, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00040057505248114467}, {"id": 248, "seek": 134560, "start": 1345.6, "end": 1355.6, "text": " Okay, cool, thank you very much.", "tokens": [50364, 1033, 11, 1627, 11, 1309, 291, 588, 709, 13, 50864], "temperature": 0.0, "avg_logprob": -0.4827464024225871, "compression_ratio": 0.8, "no_speech_prob": 0.003810848807916045}], "language": "en"}