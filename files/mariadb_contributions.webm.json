{"text": " Alright everyone, good morning. So my name is Andrew Hutchings, I'm also known as Linux Jedi everywhere, long story behind that, another time. I'm the Chief Contributions Officer for MariaDB Foundation and I want to start out by kind of saying what all the different MariaDBs are because when someone uses the term MariaDB it can mean a lot of different things. So there's MariaDB Server which is the software kind of everyone knows, there's MariaDB Corporation which is the kind of for-profit entity that does all the support, consulting, they do SkySQL, Max Scale, etc. Then there's the Foundation which is a non-profit entity, we're funded by kind of lots of different third party companies and we are there to essentially continue the MariaDB source code for the community essentially. So bit of a weird job title, Chief Contributions Officer. So I'm going to explain it using the pillars of the MariaDB Foundation and how they apply to my roles. So this and the MariaDB Foundation are openness, adoption and continuity. And on the continuity side I try and make all the kinds of different contributions easier for the community to contribute by reducing the kind of time between opening and closing pull requests but not on the cost of quality or communications to the contributor. On the openness side we create and publish metrics, I'll be talking about those a little bit but essentially it's so you can see exactly what is going on with the community contributions. And on the adoption side we work with communities such as operating systems and also end applications such as WordPress that use MariaDB to make sure that we can integrate well with them and grow adoption that way. So there are lots of different types of contributions, when people hear the word contribution they usually think of code contributions and those are the ones I'm mostly going to be talking about today. But there are lots of others that are important, you know funding for a non-profit kind of foundation is really important, it helps us kind of grow the community around everything. Documentation is really important, if you can't contribute code then contributing documentation is quite useful for us. See I say this because we have a Zulip, we have people asking questions on Stack Overflow, Reddit, we have a community Slack, we have mailing lists etc. and the small foundation can't get to everyone and everywhere so you know if you know how to answer a question then you know it's a contribution to kind of reply and would love you for it. And so I grew up in England, we suck at languages, I barely speak English, it's terrible. So any help we can get with translating error messages, things like that is really useful to us and we're working on making that a bit easier on a workflow point of view. And then usage, bug reports, feature requests, actually using the thing and telling us what you like, you don't like, what's broken, what's not broken, what you want in there. That's a contribution and that's really useful to us as well, just as much as a code contribution is. So going a bit further into non-code contributions, I'm going to talk a little bit about Intel who's a sponsor of ours. They do lots of non-code contributions, sorry morning, and they can't really do that many code contributions due to some legal stuff that they have to go through every time they contribute code. But they are doing things like they're constantly benchmarking MariaDB against their current and upcoming hardware and feeding back the information to us of what's working, what's not working, what hardware combinations are working, what's not working. And when they do spot some kind of regression on some new hardware or something like that or there's a release that's caused a regression on their hardware, they will dig deep and tell us where to look in the code, what they've spotted and then our engineers can then work on improving that. So they've worked a lot with Marco in ADB, I'm sure he's in here somewhere, to improve the performance certainly in 10.6 recently. They do supply us with hardware to test against, so a lot of the billboard infrastructures on Intel hardware, they've given us financial support. And Steve Shaw from Intel is on the board for the MariaDB Foundation. So there will always be things you can do to contribute even if you can't contribute code to MariaDB. Why contribution is important? Well, so we get a more diverse input from each life experience. So if a project is built by one team in one country, in one office, for example, you're not going to get a diverse feel of not just culture, but use cases, et cetera. So I think it's really important to get contributions for a wide group of people. You get to direct a project the way the users want rather than being led by one single entity, one single corporation. So if a corporation says, OK, all the money is here, they're going to put all the resources to develop those features and it might not be what somebody using WordPress wants, for example. You're fixing bugs and things that are important to you, and I think that's quite important. And you're building a real community around the project. So it wouldn't be a fuss to me if I don't talk about Drizzle. For those who don't know, Drizzle was a database server, it was a fork in MySQL 6 back in 2009. It started in some micro systems and it was designed to be a micro kernel kind of fork with loads of different plugins optimized for web and cloud usage. It eventually died, so that's why you probably haven't heard of it. But in 2009, we had a talk where we said we want 50% of the code contributions to come outside of some micro systems, and we kind of met this goal in a unique way. Oracle bought some and fired everybody. So we did meet the goal and everyone went to Rackspace, but my point is, MariaDB Server has more external contributors than internal contributors. So the corporation has, in 2022, 36 code contributors, there's eight from the MariaDB Foundation, and there were 68 code contributors elsewhere. Now, obviously, those contributors are not working full time on the code base, but it does mean that they kind of fix the problems that are important to them. And it's a pretty impressive stat, I think. And we had similar stats in 2019, you know, kind of something happened in 2020, can't think what, that kind of, of course it was kind of implied, but yes. Also, many of the contributions we've got from China, and that was visited a lot before the COVID. Yeah. So if you don't see contributors, they forget. Exactly. So as Monty said, COVID hit, China kind of caused the stats to dip a little bit, and things like that. They started to get back up again in 2021 and 2022 has probably been our best year ever, and I think we got some really big stuff lined up for 2023 as well. So the actual stats for 2022 are on screen right now. So corporation, obviously, is the biggest contributor. They pay a lot of full time developers to work on it. We have a smaller number in the foundation of full time developers and some people who work part time on the code and things like that as well. So even I contribute a little bit, but now we're near as much as everyone else, you know, at most one day a week, so it's not the huge amount. And then other contributors kind of outside of the MariaDB circle, pretty much on par with what the foundation contributes, so pretty good. So we use Git DM, which is called Git Data Miner, to actually process the Git commit stream to generate this. And I've actually open sourced the tooling that does all this, and it has all the kind of metadata in there to generate this. So you can actually break it down by user, by entity they work for, et cetera. And if you find that I've made a mistake on identifying someone, you can actually open a pull request on that and change the data accordingly. So it's kind of open in that respect as well, if you see what I mean. Git Data Miner was something that was generated, it was created for the Linux kernel. We tweaked it a little bit so we can count hackers and things like that, but yeah, it's essentially the same tool. We have a script to generate pull requests. I know this chart is going to be difficult to see on the screen, but kind of the trend is the important part. So this scrapes GitHub for weekly pull request metrics. So the X axis here is weak numbers, and then the Y axis is the number of open pull requests. So the bottom is 80, the top is 120. Part of my job is to help bring this down. I have been failing. I will be working on that quite a bit in 2023. So I'd run. You should also add how many actually close to that one, how many are open. I do have that, but showing that on this chart was getting very messy. So it's hard enough just showing this. We do close a hell of a lot of pull requests as well, and we don't just go in and say, no, that's rubbish close. We tend to talk to people through the pull request, and that's why some of us stay open quite a long time. So in the metrics future, I kind of want to break down the commit contributions by module, engine, et cetera. So we know how many contributions are coming to InnoDB, how many to connect engine, how many to ROXDB, et cetera, so that we can track that kind of usage. I want to track the average time to merge pull requests, median and mean, I guess, probably median because we've got some that have been open a couple of years and some that only stay open a week or two, for example. But we'll track that. We'll bring it down. Buildbot contribution metrics. So we use buildbot for continuous integration. We do get pull requests through that, contributions through that. So we'd love to track that kind of stuff. More community-wide metrics. So we're talking Jira. We're talking Stack Overflow Reddit metrics, et cetera, like that, capturing those kind of things and publishing along with the quarterly stats that I already published on meridb.org. And if there's any other metrics you want to see, let us know. Contact us because we are happy to generate them. So we'll talk about how to contribute code to Meridb. I wrote a blog post about this on meridb.org, but there are some basic steps you can follow. And it kind of helps reduce the round trip time during review. And also, I don't want you to spend hours, days working on something and opening a pull request and saying, sorry, this doesn't really fit with what we're doing at all or someone else has already done this. And I have to say no, because I don't want to crush people's hopes or anything like that. So if you follow these steps, it will kind of help reduce that quite a bit. So the first step is communication, talking to us. We can guide you through kind of every step of the way. Meridb team are quite approachable, preferably via Jira and Zulit, but there are other ways to talk to us as well. In particular, Vicente Daniel and me at the foundation, there are a list of people at the corporation I'm sure you can talk to as well. Tell us what you want to work on. And if you don't know what you want to work on, there is a beginner-friendly tag on Jira where we've tagged tickets that should be relatively easy to pick up and work on. And we can talk you through these. If there's no Jira for what you want to work on yet, open one and again, talk to us and we can figure out the best solution for it. Next step is hacking. Write some codes. If you are making a bug fix, it needs to be against the oldest-affected version of Meridb, so if it affects 10.5 upwards, then against 10.5. What is the thing that active release? Yes, active release. Yes, this is a good point. Always check the end of life as well for the releases when you do this because we're in this weird phase right now where we have got, we changed release cycles a couple of years ago, so some releases are on the old release cycle and some are on the new release cycles so some in the middle are end of life but some are. So it's a bit funny right now, but again, you can talk to us about this and we can help point in the right direction. The new features always go in the latest development version, which currently is 11.0 for the next couple of weeks. When that hits GA, there'll be another release you can bolt things on. Please stick to the coding standards to the surrounding code. You'll find that different engines have different coding standards because they've come from different places. Connect engine was originally a MySQL contribution that came through to MarineDB and that's got a different coding standard to say NODB and the core server code. I've put together a coding standards document which should be merged shortly and that's just for the core server and at the moment it's descriptive, run and prescriptive, but we're going to improve on that over time. Some test cases, we don't want you to write something, us merge it and then us break it later. So if you have some test cases in there, A, it proves exactly what you're doing and B, it means that it will stay like that in the future. Run the MTR test suite locally because otherwise you might get build bar errors that you don't expect and it just reduces the cycle a little bit there. If it's a new feature, help us write some documentation or at least describe what it does in the JIRA tickets so that we can put that into the knowledge base at a later day. Next up, pull requests. When you open a pull request, a form will pop up and filling this in will help us triage the pull request essentially. So a lot of your questions about whether this is a bug or a feature, have you added a test, does this break things, stuff like that. If it's your first time doing a pull request, something called the CLA assistant will pop up. It's not 100% intuitive right now, it's something we need to improve on, but right now it will pop up and ask you to sign the CLA. You can click through that and either sign the CLA or tick to say, I want to contribute under the three clause BSD license or you can just literally put a comment in and say, I'm contributing this under the three clause BSD license and then we can take it from there. What will run on the pull request automatically, lots and lots of different builders. The most important ones will report back to GitHub and show you that if anything has failed during compiling or testing on lots of different platforms we support. When we actually go to review it, we'll actually look at the full build list where there might be some obscure platforms that might have broken in weird ways, but at least it gives you some idea of what's gone wrong and you can click through and look at the cause. Again, if you don't understand the error that popped up, we can look at it for you and point you in the right direction. Code review process, the MariaDB engineers, both at the Foundation and Corporation will review, give feedback, advice. If we think the code is ready, we'll approve it and merge it. Community members are also welcome to come look at the codes that people have contributed to it, review it, comment on it, and it's another way you can contribute. If we are taking time to get to your pull request and we're dropping the ball or something like that or you need advice, you can tag me at Linus Jedi on GitHub and I will take a look at it for you. I'm lagging a bit behind on that because I'm at FOSDM right now, but I will try and keep up with that. We have a large backlog right now, so it is very easy for us to miss things. That is all I have. Any questions from anyone? Yes. Is the Foundation and the Corporation have different release cycles or is that? It's Foundational Corporation different release cycles. So no. At the moment, the Corporation are generating the releases, so the engineers at the Corporation are generating the releases, if you see what I mean. The releases you get are generated by the Corporation. Built by the Foundation, yes. There's a lot of synergies between the two, which is a good thing. We want to be working closely with them, if you see what I mean. But if anything, God forbid, happened to the Corporation, the Foundation existing means that MarineDB Server will still exist, will still be developed, et cetera. All right. Thank you very much. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 17.68, "text": " Alright everyone, good morning.", "tokens": [2798, 1518, 11, 665, 2446, 13], "temperature": 0.0, "avg_logprob": -0.3324922903990134, "compression_ratio": 1.2033898305084745, "no_speech_prob": 0.3461110293865204}, {"id": 1, "seek": 0, "start": 17.68, "end": 24.2, "text": " So my name is Andrew Hutchings, I'm also known as Linux Jedi everywhere, long story", "tokens": [407, 452, 1315, 307, 10110, 48499, 1109, 11, 286, 478, 611, 2570, 382, 18734, 21746, 5315, 11, 938, 1657], "temperature": 0.0, "avg_logprob": -0.3324922903990134, "compression_ratio": 1.2033898305084745, "no_speech_prob": 0.3461110293865204}, {"id": 2, "seek": 0, "start": 24.2, "end": 26.2, "text": " behind that, another time.", "tokens": [2261, 300, 11, 1071, 565, 13], "temperature": 0.0, "avg_logprob": -0.3324922903990134, "compression_ratio": 1.2033898305084745, "no_speech_prob": 0.3461110293865204}, {"id": 3, "seek": 2620, "start": 26.2, "end": 31.4, "text": " I'm the Chief Contributions Officer for MariaDB Foundation and I want to start out by kind", "tokens": [286, 478, 264, 10068, 4839, 2024, 3666, 15434, 337, 12734, 27735, 10335, 293, 286, 528, 281, 722, 484, 538, 733], "temperature": 0.0, "avg_logprob": -0.2322811727170591, "compression_ratio": 1.6589147286821706, "no_speech_prob": 0.00019433567649684846}, {"id": 4, "seek": 2620, "start": 31.4, "end": 35.64, "text": " of saying what all the different MariaDBs are because when someone uses the term MariaDB", "tokens": [295, 1566, 437, 439, 264, 819, 12734, 27735, 82, 366, 570, 562, 1580, 4960, 264, 1433, 12734, 27735], "temperature": 0.0, "avg_logprob": -0.2322811727170591, "compression_ratio": 1.6589147286821706, "no_speech_prob": 0.00019433567649684846}, {"id": 5, "seek": 2620, "start": 35.64, "end": 37.2, "text": " it can mean a lot of different things.", "tokens": [309, 393, 914, 257, 688, 295, 819, 721, 13], "temperature": 0.0, "avg_logprob": -0.2322811727170591, "compression_ratio": 1.6589147286821706, "no_speech_prob": 0.00019433567649684846}, {"id": 6, "seek": 2620, "start": 37.2, "end": 42.28, "text": " So there's MariaDB Server which is the software kind of everyone knows, there's MariaDB Corporation", "tokens": [407, 456, 311, 12734, 27735, 25684, 597, 307, 264, 4722, 733, 295, 1518, 3255, 11, 456, 311, 12734, 27735, 26464], "temperature": 0.0, "avg_logprob": -0.2322811727170591, "compression_ratio": 1.6589147286821706, "no_speech_prob": 0.00019433567649684846}, {"id": 7, "seek": 2620, "start": 42.28, "end": 48.36, "text": " which is the kind of for-profit entity that does all the support, consulting, they do", "tokens": [597, 307, 264, 733, 295, 337, 12, 14583, 13977, 300, 775, 439, 264, 1406, 11, 23682, 11, 436, 360], "temperature": 0.0, "avg_logprob": -0.2322811727170591, "compression_ratio": 1.6589147286821706, "no_speech_prob": 0.00019433567649684846}, {"id": 8, "seek": 2620, "start": 48.36, "end": 51.36, "text": " SkySQL, Max Scale, etc.", "tokens": [9879, 39934, 11, 7402, 42999, 11, 5183, 13], "temperature": 0.0, "avg_logprob": -0.2322811727170591, "compression_ratio": 1.6589147286821706, "no_speech_prob": 0.00019433567649684846}, {"id": 9, "seek": 5136, "start": 51.36, "end": 57.24, "text": " Then there's the Foundation which is a non-profit entity, we're funded by kind of lots of different", "tokens": [1396, 456, 311, 264, 10335, 597, 307, 257, 2107, 12, 14583, 13977, 11, 321, 434, 14385, 538, 733, 295, 3195, 295, 819], "temperature": 0.0, "avg_logprob": -0.15422406760595178, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.1255636865098495e-06}, {"id": 10, "seek": 5136, "start": 57.24, "end": 64.36, "text": " third party companies and we are there to essentially continue the MariaDB source code", "tokens": [2636, 3595, 3431, 293, 321, 366, 456, 281, 4476, 2354, 264, 12734, 27735, 4009, 3089], "temperature": 0.0, "avg_logprob": -0.15422406760595178, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.1255636865098495e-06}, {"id": 11, "seek": 5136, "start": 64.36, "end": 68.28, "text": " for the community essentially.", "tokens": [337, 264, 1768, 4476, 13], "temperature": 0.0, "avg_logprob": -0.15422406760595178, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.1255636865098495e-06}, {"id": 12, "seek": 5136, "start": 68.28, "end": 72.44, "text": " So bit of a weird job title, Chief Contributions Officer.", "tokens": [407, 857, 295, 257, 3657, 1691, 4876, 11, 10068, 4839, 2024, 3666, 15434, 13], "temperature": 0.0, "avg_logprob": -0.15422406760595178, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.1255636865098495e-06}, {"id": 13, "seek": 5136, "start": 72.44, "end": 76.72, "text": " So I'm going to explain it using the pillars of the MariaDB Foundation and how they apply", "tokens": [407, 286, 478, 516, 281, 2903, 309, 1228, 264, 26729, 295, 264, 12734, 27735, 10335, 293, 577, 436, 3079], "temperature": 0.0, "avg_logprob": -0.15422406760595178, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.1255636865098495e-06}, {"id": 14, "seek": 5136, "start": 76.72, "end": 77.72, "text": " to my roles.", "tokens": [281, 452, 9604, 13], "temperature": 0.0, "avg_logprob": -0.15422406760595178, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.1255636865098495e-06}, {"id": 15, "seek": 7772, "start": 77.72, "end": 83.56, "text": " So this and the MariaDB Foundation are openness, adoption and continuity.", "tokens": [407, 341, 293, 264, 12734, 27735, 10335, 366, 36200, 11, 19215, 293, 23807, 13], "temperature": 0.0, "avg_logprob": -0.14706980387369792, "compression_ratio": 1.7235772357723578, "no_speech_prob": 2.5276678570662625e-05}, {"id": 16, "seek": 7772, "start": 83.56, "end": 89.28, "text": " And on the continuity side I try and make all the kinds of different contributions easier", "tokens": [400, 322, 264, 23807, 1252, 286, 853, 293, 652, 439, 264, 3685, 295, 819, 15725, 3571], "temperature": 0.0, "avg_logprob": -0.14706980387369792, "compression_ratio": 1.7235772357723578, "no_speech_prob": 2.5276678570662625e-05}, {"id": 17, "seek": 7772, "start": 89.28, "end": 94.52, "text": " for the community to contribute by reducing the kind of time between opening and closing", "tokens": [337, 264, 1768, 281, 10586, 538, 12245, 264, 733, 295, 565, 1296, 5193, 293, 10377], "temperature": 0.0, "avg_logprob": -0.14706980387369792, "compression_ratio": 1.7235772357723578, "no_speech_prob": 2.5276678570662625e-05}, {"id": 18, "seek": 7772, "start": 94.52, "end": 103.3, "text": " pull requests but not on the cost of quality or communications to the contributor.", "tokens": [2235, 12475, 457, 406, 322, 264, 2063, 295, 3125, 420, 15163, 281, 264, 42859, 13], "temperature": 0.0, "avg_logprob": -0.14706980387369792, "compression_ratio": 1.7235772357723578, "no_speech_prob": 2.5276678570662625e-05}, {"id": 19, "seek": 7772, "start": 103.3, "end": 107.36, "text": " On the openness side we create and publish metrics, I'll be talking about those a little", "tokens": [1282, 264, 36200, 1252, 321, 1884, 293, 11374, 16367, 11, 286, 603, 312, 1417, 466, 729, 257, 707], "temperature": 0.0, "avg_logprob": -0.14706980387369792, "compression_ratio": 1.7235772357723578, "no_speech_prob": 2.5276678570662625e-05}, {"id": 20, "seek": 10736, "start": 107.36, "end": 115.6, "text": " bit but essentially it's so you can see exactly what is going on with the community contributions.", "tokens": [857, 457, 4476, 309, 311, 370, 291, 393, 536, 2293, 437, 307, 516, 322, 365, 264, 1768, 15725, 13], "temperature": 0.0, "avg_logprob": -0.16289242454197095, "compression_ratio": 1.5808080808080809, "no_speech_prob": 2.162836244679056e-05}, {"id": 21, "seek": 10736, "start": 115.6, "end": 124.6, "text": " And on the adoption side we work with communities such as operating systems and also end applications", "tokens": [400, 322, 264, 19215, 1252, 321, 589, 365, 4456, 1270, 382, 7447, 3652, 293, 611, 917, 5821], "temperature": 0.0, "avg_logprob": -0.16289242454197095, "compression_ratio": 1.5808080808080809, "no_speech_prob": 2.162836244679056e-05}, {"id": 22, "seek": 10736, "start": 124.6, "end": 130.28, "text": " such as WordPress that use MariaDB to make sure that we can integrate well with them", "tokens": [1270, 382, 23239, 300, 764, 12734, 27735, 281, 652, 988, 300, 321, 393, 13365, 731, 365, 552], "temperature": 0.0, "avg_logprob": -0.16289242454197095, "compression_ratio": 1.5808080808080809, "no_speech_prob": 2.162836244679056e-05}, {"id": 23, "seek": 10736, "start": 130.28, "end": 133.84, "text": " and grow adoption that way.", "tokens": [293, 1852, 19215, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.16289242454197095, "compression_ratio": 1.5808080808080809, "no_speech_prob": 2.162836244679056e-05}, {"id": 24, "seek": 13384, "start": 133.84, "end": 137.8, "text": " So there are lots of different types of contributions, when people hear the word contribution they", "tokens": [407, 456, 366, 3195, 295, 819, 3467, 295, 15725, 11, 562, 561, 1568, 264, 1349, 13150, 436], "temperature": 0.0, "avg_logprob": -0.15234430486505682, "compression_ratio": 1.8943396226415095, "no_speech_prob": 2.263488386233803e-05}, {"id": 25, "seek": 13384, "start": 137.8, "end": 140.92000000000002, "text": " usually think of code contributions and those are the ones I'm mostly going to be talking", "tokens": [2673, 519, 295, 3089, 15725, 293, 729, 366, 264, 2306, 286, 478, 5240, 516, 281, 312, 1417], "temperature": 0.0, "avg_logprob": -0.15234430486505682, "compression_ratio": 1.8943396226415095, "no_speech_prob": 2.263488386233803e-05}, {"id": 26, "seek": 13384, "start": 140.92000000000002, "end": 141.92000000000002, "text": " about today.", "tokens": [466, 965, 13], "temperature": 0.0, "avg_logprob": -0.15234430486505682, "compression_ratio": 1.8943396226415095, "no_speech_prob": 2.263488386233803e-05}, {"id": 27, "seek": 13384, "start": 141.92000000000002, "end": 147.24, "text": " But there are lots of others that are important, you know funding for a non-profit kind of", "tokens": [583, 456, 366, 3195, 295, 2357, 300, 366, 1021, 11, 291, 458, 6137, 337, 257, 2107, 12, 14583, 733, 295], "temperature": 0.0, "avg_logprob": -0.15234430486505682, "compression_ratio": 1.8943396226415095, "no_speech_prob": 2.263488386233803e-05}, {"id": 28, "seek": 13384, "start": 147.24, "end": 153.24, "text": " foundation is really important, it helps us kind of grow the community around everything.", "tokens": [7030, 307, 534, 1021, 11, 309, 3665, 505, 733, 295, 1852, 264, 1768, 926, 1203, 13], "temperature": 0.0, "avg_logprob": -0.15234430486505682, "compression_ratio": 1.8943396226415095, "no_speech_prob": 2.263488386233803e-05}, {"id": 29, "seek": 13384, "start": 153.24, "end": 158.28, "text": " Documentation is really important, if you can't contribute code then contributing documentation", "tokens": [37684, 399, 307, 534, 1021, 11, 498, 291, 393, 380, 10586, 3089, 550, 19270, 14333], "temperature": 0.0, "avg_logprob": -0.15234430486505682, "compression_ratio": 1.8943396226415095, "no_speech_prob": 2.263488386233803e-05}, {"id": 30, "seek": 13384, "start": 158.28, "end": 161.28, "text": " is quite useful for us.", "tokens": [307, 1596, 4420, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.15234430486505682, "compression_ratio": 1.8943396226415095, "no_speech_prob": 2.263488386233803e-05}, {"id": 31, "seek": 16128, "start": 161.28, "end": 168.96, "text": " See I say this because we have a Zulip, we have people asking questions on Stack Overflow,", "tokens": [3008, 286, 584, 341, 570, 321, 362, 257, 1176, 425, 647, 11, 321, 362, 561, 3365, 1651, 322, 37649, 4886, 10565, 11], "temperature": 0.0, "avg_logprob": -0.24035353993260583, "compression_ratio": 1.6084905660377358, "no_speech_prob": 5.903930286876857e-05}, {"id": 32, "seek": 16128, "start": 168.96, "end": 175.64, "text": " Reddit, we have a community Slack, we have mailing lists etc. and the small foundation", "tokens": [32210, 11, 321, 362, 257, 1768, 37211, 11, 321, 362, 41612, 14511, 5183, 13, 293, 264, 1359, 7030], "temperature": 0.0, "avg_logprob": -0.24035353993260583, "compression_ratio": 1.6084905660377358, "no_speech_prob": 5.903930286876857e-05}, {"id": 33, "seek": 16128, "start": 175.64, "end": 179.44, "text": " can't get to everyone and everywhere so you know if you know how to answer a question", "tokens": [393, 380, 483, 281, 1518, 293, 5315, 370, 291, 458, 498, 291, 458, 577, 281, 1867, 257, 1168], "temperature": 0.0, "avg_logprob": -0.24035353993260583, "compression_ratio": 1.6084905660377358, "no_speech_prob": 5.903930286876857e-05}, {"id": 34, "seek": 16128, "start": 179.44, "end": 186.88, "text": " then you know it's a contribution to kind of reply and would love you for it.", "tokens": [550, 291, 458, 309, 311, 257, 13150, 281, 733, 295, 16972, 293, 576, 959, 291, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.24035353993260583, "compression_ratio": 1.6084905660377358, "no_speech_prob": 5.903930286876857e-05}, {"id": 35, "seek": 18688, "start": 186.88, "end": 196.16, "text": " And so I grew up in England, we suck at languages, I barely speak English, it's terrible.", "tokens": [400, 370, 286, 6109, 493, 294, 8196, 11, 321, 9967, 412, 8650, 11, 286, 10268, 1710, 3669, 11, 309, 311, 6237, 13], "temperature": 0.0, "avg_logprob": -0.13722962731713648, "compression_ratio": 1.6577946768060836, "no_speech_prob": 6.066472997190431e-05}, {"id": 36, "seek": 18688, "start": 196.16, "end": 201.2, "text": " So any help we can get with translating error messages, things like that is really useful", "tokens": [407, 604, 854, 321, 393, 483, 365, 35030, 6713, 7897, 11, 721, 411, 300, 307, 534, 4420], "temperature": 0.0, "avg_logprob": -0.13722962731713648, "compression_ratio": 1.6577946768060836, "no_speech_prob": 6.066472997190431e-05}, {"id": 37, "seek": 18688, "start": 201.2, "end": 207.07999999999998, "text": " to us and we're working on making that a bit easier on a workflow point of view.", "tokens": [281, 505, 293, 321, 434, 1364, 322, 1455, 300, 257, 857, 3571, 322, 257, 20993, 935, 295, 1910, 13], "temperature": 0.0, "avg_logprob": -0.13722962731713648, "compression_ratio": 1.6577946768060836, "no_speech_prob": 6.066472997190431e-05}, {"id": 38, "seek": 18688, "start": 207.07999999999998, "end": 212.32, "text": " And then usage, bug reports, feature requests, actually using the thing and telling us what", "tokens": [400, 550, 14924, 11, 7426, 7122, 11, 4111, 12475, 11, 767, 1228, 264, 551, 293, 3585, 505, 437], "temperature": 0.0, "avg_logprob": -0.13722962731713648, "compression_ratio": 1.6577946768060836, "no_speech_prob": 6.066472997190431e-05}, {"id": 39, "seek": 18688, "start": 212.32, "end": 216.48, "text": " you like, you don't like, what's broken, what's not broken, what you want in there.", "tokens": [291, 411, 11, 291, 500, 380, 411, 11, 437, 311, 5463, 11, 437, 311, 406, 5463, 11, 437, 291, 528, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.13722962731713648, "compression_ratio": 1.6577946768060836, "no_speech_prob": 6.066472997190431e-05}, {"id": 40, "seek": 21648, "start": 216.48, "end": 219.79999999999998, "text": " That's a contribution and that's really useful to us as well, just as much as a code contribution", "tokens": [663, 311, 257, 13150, 293, 300, 311, 534, 4420, 281, 505, 382, 731, 11, 445, 382, 709, 382, 257, 3089, 13150], "temperature": 0.0, "avg_logprob": -0.1773661434060276, "compression_ratio": 1.8054298642533937, "no_speech_prob": 3.699127410072833e-05}, {"id": 41, "seek": 21648, "start": 219.79999999999998, "end": 223.0, "text": " is.", "tokens": [307, 13], "temperature": 0.0, "avg_logprob": -0.1773661434060276, "compression_ratio": 1.8054298642533937, "no_speech_prob": 3.699127410072833e-05}, {"id": 42, "seek": 21648, "start": 223.0, "end": 228.35999999999999, "text": " So going a bit further into non-code contributions, I'm going to talk a little bit about Intel", "tokens": [407, 516, 257, 857, 3052, 666, 2107, 12, 22332, 15725, 11, 286, 478, 516, 281, 751, 257, 707, 857, 466, 19762], "temperature": 0.0, "avg_logprob": -0.1773661434060276, "compression_ratio": 1.8054298642533937, "no_speech_prob": 3.699127410072833e-05}, {"id": 43, "seek": 21648, "start": 228.35999999999999, "end": 231.95999999999998, "text": " who's a sponsor of ours.", "tokens": [567, 311, 257, 16198, 295, 11896, 13], "temperature": 0.0, "avg_logprob": -0.1773661434060276, "compression_ratio": 1.8054298642533937, "no_speech_prob": 3.699127410072833e-05}, {"id": 44, "seek": 21648, "start": 231.95999999999998, "end": 241.92, "text": " They do lots of non-code contributions, sorry morning, and they can't really do that many", "tokens": [814, 360, 3195, 295, 2107, 12, 22332, 15725, 11, 2597, 2446, 11, 293, 436, 393, 380, 534, 360, 300, 867], "temperature": 0.0, "avg_logprob": -0.1773661434060276, "compression_ratio": 1.8054298642533937, "no_speech_prob": 3.699127410072833e-05}, {"id": 45, "seek": 21648, "start": 241.92, "end": 245.67999999999998, "text": " code contributions due to some legal stuff that they have to go through every time they", "tokens": [3089, 15725, 3462, 281, 512, 5089, 1507, 300, 436, 362, 281, 352, 807, 633, 565, 436], "temperature": 0.0, "avg_logprob": -0.1773661434060276, "compression_ratio": 1.8054298642533937, "no_speech_prob": 3.699127410072833e-05}, {"id": 46, "seek": 24568, "start": 245.68, "end": 246.68, "text": " contribute code.", "tokens": [10586, 3089, 13], "temperature": 0.0, "avg_logprob": -0.14721901690373657, "compression_ratio": 1.9219858156028369, "no_speech_prob": 9.060638694791123e-05}, {"id": 47, "seek": 24568, "start": 246.68, "end": 252.12, "text": " But they are doing things like they're constantly benchmarking MariaDB against their current", "tokens": [583, 436, 366, 884, 721, 411, 436, 434, 6460, 18927, 278, 12734, 27735, 1970, 641, 2190], "temperature": 0.0, "avg_logprob": -0.14721901690373657, "compression_ratio": 1.9219858156028369, "no_speech_prob": 9.060638694791123e-05}, {"id": 48, "seek": 24568, "start": 252.12, "end": 256.6, "text": " and upcoming hardware and feeding back the information to us of what's working, what's", "tokens": [293, 11500, 8837, 293, 12919, 646, 264, 1589, 281, 505, 295, 437, 311, 1364, 11, 437, 311], "temperature": 0.0, "avg_logprob": -0.14721901690373657, "compression_ratio": 1.9219858156028369, "no_speech_prob": 9.060638694791123e-05}, {"id": 49, "seek": 24568, "start": 256.6, "end": 260.96000000000004, "text": " not working, what hardware combinations are working, what's not working.", "tokens": [406, 1364, 11, 437, 8837, 21267, 366, 1364, 11, 437, 311, 406, 1364, 13], "temperature": 0.0, "avg_logprob": -0.14721901690373657, "compression_ratio": 1.9219858156028369, "no_speech_prob": 9.060638694791123e-05}, {"id": 50, "seek": 24568, "start": 260.96000000000004, "end": 265.04, "text": " And when they do spot some kind of regression on some new hardware or something like that", "tokens": [400, 562, 436, 360, 4008, 512, 733, 295, 24590, 322, 512, 777, 8837, 420, 746, 411, 300], "temperature": 0.0, "avg_logprob": -0.14721901690373657, "compression_ratio": 1.9219858156028369, "no_speech_prob": 9.060638694791123e-05}, {"id": 51, "seek": 24568, "start": 265.04, "end": 270.68, "text": " or there's a release that's caused a regression on their hardware, they will dig deep and", "tokens": [420, 456, 311, 257, 4374, 300, 311, 7008, 257, 24590, 322, 641, 8837, 11, 436, 486, 2528, 2452, 293], "temperature": 0.0, "avg_logprob": -0.14721901690373657, "compression_ratio": 1.9219858156028369, "no_speech_prob": 9.060638694791123e-05}, {"id": 52, "seek": 24568, "start": 270.68, "end": 275.2, "text": " tell us where to look in the code, what they've spotted and then our engineers can then work", "tokens": [980, 505, 689, 281, 574, 294, 264, 3089, 11, 437, 436, 600, 21010, 293, 550, 527, 11955, 393, 550, 589], "temperature": 0.0, "avg_logprob": -0.14721901690373657, "compression_ratio": 1.9219858156028369, "no_speech_prob": 9.060638694791123e-05}, {"id": 53, "seek": 27520, "start": 275.2, "end": 276.71999999999997, "text": " on improving that.", "tokens": [322, 11470, 300, 13], "temperature": 0.0, "avg_logprob": -0.16664858031691165, "compression_ratio": 1.618705035971223, "no_speech_prob": 3.9822160033509135e-05}, {"id": 54, "seek": 27520, "start": 276.71999999999997, "end": 283.2, "text": " So they've worked a lot with Marco in ADB, I'm sure he's in here somewhere, to improve", "tokens": [407, 436, 600, 2732, 257, 688, 365, 26535, 294, 9135, 33, 11, 286, 478, 988, 415, 311, 294, 510, 4079, 11, 281, 3470], "temperature": 0.0, "avg_logprob": -0.16664858031691165, "compression_ratio": 1.618705035971223, "no_speech_prob": 3.9822160033509135e-05}, {"id": 55, "seek": 27520, "start": 283.2, "end": 286.28, "text": " the performance certainly in 10.6 recently.", "tokens": [264, 3389, 3297, 294, 1266, 13, 21, 3938, 13], "temperature": 0.0, "avg_logprob": -0.16664858031691165, "compression_ratio": 1.618705035971223, "no_speech_prob": 3.9822160033509135e-05}, {"id": 56, "seek": 27520, "start": 286.28, "end": 290.84, "text": " They do supply us with hardware to test against, so a lot of the billboard infrastructures", "tokens": [814, 360, 5847, 505, 365, 8837, 281, 1500, 1970, 11, 370, 257, 688, 295, 264, 2961, 3787, 6534, 44513], "temperature": 0.0, "avg_logprob": -0.16664858031691165, "compression_ratio": 1.618705035971223, "no_speech_prob": 3.9822160033509135e-05}, {"id": 57, "seek": 27520, "start": 290.84, "end": 294.76, "text": " on Intel hardware, they've given us financial support.", "tokens": [322, 19762, 8837, 11, 436, 600, 2212, 505, 4669, 1406, 13], "temperature": 0.0, "avg_logprob": -0.16664858031691165, "compression_ratio": 1.618705035971223, "no_speech_prob": 3.9822160033509135e-05}, {"id": 58, "seek": 27520, "start": 294.76, "end": 300.0, "text": " And Steve Shaw from Intel is on the board for the MariaDB Foundation.", "tokens": [400, 7466, 27132, 490, 19762, 307, 322, 264, 3150, 337, 264, 12734, 27735, 10335, 13], "temperature": 0.0, "avg_logprob": -0.16664858031691165, "compression_ratio": 1.618705035971223, "no_speech_prob": 3.9822160033509135e-05}, {"id": 59, "seek": 27520, "start": 300.0, "end": 303.84, "text": " So there will always be things you can do to contribute even if you can't contribute", "tokens": [407, 456, 486, 1009, 312, 721, 291, 393, 360, 281, 10586, 754, 498, 291, 393, 380, 10586], "temperature": 0.0, "avg_logprob": -0.16664858031691165, "compression_ratio": 1.618705035971223, "no_speech_prob": 3.9822160033509135e-05}, {"id": 60, "seek": 30384, "start": 303.84, "end": 306.56, "text": " code to MariaDB.", "tokens": [3089, 281, 12734, 27735, 13], "temperature": 0.0, "avg_logprob": -0.18263854583104452, "compression_ratio": 1.5584415584415585, "no_speech_prob": 3.2092895708046854e-05}, {"id": 61, "seek": 30384, "start": 306.56, "end": 308.15999999999997, "text": " Why contribution is important?", "tokens": [1545, 13150, 307, 1021, 30], "temperature": 0.0, "avg_logprob": -0.18263854583104452, "compression_ratio": 1.5584415584415585, "no_speech_prob": 3.2092895708046854e-05}, {"id": 62, "seek": 30384, "start": 308.15999999999997, "end": 313.08, "text": " Well, so we get a more diverse input from each life experience.", "tokens": [1042, 11, 370, 321, 483, 257, 544, 9521, 4846, 490, 1184, 993, 1752, 13], "temperature": 0.0, "avg_logprob": -0.18263854583104452, "compression_ratio": 1.5584415584415585, "no_speech_prob": 3.2092895708046854e-05}, {"id": 63, "seek": 30384, "start": 313.08, "end": 318.4, "text": " So if a project is built by one team in one country, in one office, for example, you're", "tokens": [407, 498, 257, 1716, 307, 3094, 538, 472, 1469, 294, 472, 1941, 11, 294, 472, 3398, 11, 337, 1365, 11, 291, 434], "temperature": 0.0, "avg_logprob": -0.18263854583104452, "compression_ratio": 1.5584415584415585, "no_speech_prob": 3.2092895708046854e-05}, {"id": 64, "seek": 30384, "start": 318.4, "end": 326.12, "text": " not going to get a diverse feel of not just culture, but use cases, et cetera.", "tokens": [406, 516, 281, 483, 257, 9521, 841, 295, 406, 445, 3713, 11, 457, 764, 3331, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.18263854583104452, "compression_ratio": 1.5584415584415585, "no_speech_prob": 3.2092895708046854e-05}, {"id": 65, "seek": 30384, "start": 326.12, "end": 332.52, "text": " So I think it's really important to get contributions for a wide group of people.", "tokens": [407, 286, 519, 309, 311, 534, 1021, 281, 483, 15725, 337, 257, 4874, 1594, 295, 561, 13], "temperature": 0.0, "avg_logprob": -0.18263854583104452, "compression_ratio": 1.5584415584415585, "no_speech_prob": 3.2092895708046854e-05}, {"id": 66, "seek": 33252, "start": 332.52, "end": 337.56, "text": " You get to direct a project the way the users want rather than being led by one single entity,", "tokens": [509, 483, 281, 2047, 257, 1716, 264, 636, 264, 5022, 528, 2831, 813, 885, 4684, 538, 472, 2167, 13977, 11], "temperature": 0.0, "avg_logprob": -0.16481222547926344, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.4186577573127579e-05}, {"id": 67, "seek": 33252, "start": 337.56, "end": 339.47999999999996, "text": " one single corporation.", "tokens": [472, 2167, 22197, 13], "temperature": 0.0, "avg_logprob": -0.16481222547926344, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.4186577573127579e-05}, {"id": 68, "seek": 33252, "start": 339.47999999999996, "end": 345.12, "text": " So if a corporation says, OK, all the money is here, they're going to put all the resources", "tokens": [407, 498, 257, 22197, 1619, 11, 2264, 11, 439, 264, 1460, 307, 510, 11, 436, 434, 516, 281, 829, 439, 264, 3593], "temperature": 0.0, "avg_logprob": -0.16481222547926344, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.4186577573127579e-05}, {"id": 69, "seek": 33252, "start": 345.12, "end": 350.12, "text": " to develop those features and it might not be what somebody using WordPress wants, for", "tokens": [281, 1499, 729, 4122, 293, 309, 1062, 406, 312, 437, 2618, 1228, 23239, 2738, 11, 337], "temperature": 0.0, "avg_logprob": -0.16481222547926344, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.4186577573127579e-05}, {"id": 70, "seek": 33252, "start": 350.12, "end": 351.12, "text": " example.", "tokens": [1365, 13], "temperature": 0.0, "avg_logprob": -0.16481222547926344, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.4186577573127579e-05}, {"id": 71, "seek": 33252, "start": 351.12, "end": 356.47999999999996, "text": " You're fixing bugs and things that are important to you, and I think that's quite important.", "tokens": [509, 434, 19442, 15120, 293, 721, 300, 366, 1021, 281, 291, 11, 293, 286, 519, 300, 311, 1596, 1021, 13], "temperature": 0.0, "avg_logprob": -0.16481222547926344, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.4186577573127579e-05}, {"id": 72, "seek": 33252, "start": 356.47999999999996, "end": 360.15999999999997, "text": " And you're building a real community around the project.", "tokens": [400, 291, 434, 2390, 257, 957, 1768, 926, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.16481222547926344, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.4186577573127579e-05}, {"id": 73, "seek": 36016, "start": 360.16, "end": 363.68, "text": " So it wouldn't be a fuss to me if I don't talk about Drizzle.", "tokens": [407, 309, 2759, 380, 312, 257, 34792, 281, 385, 498, 286, 500, 380, 751, 466, 19150, 9260, 13], "temperature": 0.0, "avg_logprob": -0.1973576639212814, "compression_ratio": 1.5099601593625498, "no_speech_prob": 8.182714736904018e-06}, {"id": 74, "seek": 36016, "start": 363.68, "end": 373.36, "text": " For those who don't know, Drizzle was a database server, it was a fork in MySQL 6 back in 2009.", "tokens": [1171, 729, 567, 500, 380, 458, 11, 19150, 9260, 390, 257, 8149, 7154, 11, 309, 390, 257, 17716, 294, 1222, 39934, 1386, 646, 294, 11453, 13], "temperature": 0.0, "avg_logprob": -0.1973576639212814, "compression_ratio": 1.5099601593625498, "no_speech_prob": 8.182714736904018e-06}, {"id": 75, "seek": 36016, "start": 373.36, "end": 379.6, "text": " It started in some micro systems and it was designed to be a micro kernel kind of fork", "tokens": [467, 1409, 294, 512, 4532, 3652, 293, 309, 390, 4761, 281, 312, 257, 4532, 28256, 733, 295, 17716], "temperature": 0.0, "avg_logprob": -0.1973576639212814, "compression_ratio": 1.5099601593625498, "no_speech_prob": 8.182714736904018e-06}, {"id": 76, "seek": 36016, "start": 379.6, "end": 386.6, "text": " with loads of different plugins optimized for web and cloud usage.", "tokens": [365, 12668, 295, 819, 33759, 26941, 337, 3670, 293, 4588, 14924, 13], "temperature": 0.0, "avg_logprob": -0.1973576639212814, "compression_ratio": 1.5099601593625498, "no_speech_prob": 8.182714736904018e-06}, {"id": 77, "seek": 36016, "start": 386.6, "end": 389.88, "text": " It eventually died, so that's why you probably haven't heard of it.", "tokens": [467, 4728, 4539, 11, 370, 300, 311, 983, 291, 1391, 2378, 380, 2198, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.1973576639212814, "compression_ratio": 1.5099601593625498, "no_speech_prob": 8.182714736904018e-06}, {"id": 78, "seek": 38988, "start": 389.88, "end": 397.52, "text": " But in 2009, we had a talk where we said we want 50% of the code contributions to come", "tokens": [583, 294, 11453, 11, 321, 632, 257, 751, 689, 321, 848, 321, 528, 2625, 4, 295, 264, 3089, 15725, 281, 808], "temperature": 0.0, "avg_logprob": -0.19308835809881036, "compression_ratio": 1.5283842794759825, "no_speech_prob": 1.961502493941225e-05}, {"id": 79, "seek": 38988, "start": 397.52, "end": 402.6, "text": " outside of some micro systems, and we kind of met this goal in a unique way.", "tokens": [2380, 295, 512, 4532, 3652, 11, 293, 321, 733, 295, 1131, 341, 3387, 294, 257, 3845, 636, 13], "temperature": 0.0, "avg_logprob": -0.19308835809881036, "compression_ratio": 1.5283842794759825, "no_speech_prob": 1.961502493941225e-05}, {"id": 80, "seek": 38988, "start": 402.6, "end": 405.08, "text": " Oracle bought some and fired everybody.", "tokens": [25654, 4243, 512, 293, 11777, 2201, 13], "temperature": 0.0, "avg_logprob": -0.19308835809881036, "compression_ratio": 1.5283842794759825, "no_speech_prob": 1.961502493941225e-05}, {"id": 81, "seek": 38988, "start": 405.08, "end": 414.71999999999997, "text": " So we did meet the goal and everyone went to Rackspace, but my point is, MariaDB Server", "tokens": [407, 321, 630, 1677, 264, 3387, 293, 1518, 1437, 281, 497, 501, 24824, 11, 457, 452, 935, 307, 11, 12734, 27735, 25684], "temperature": 0.0, "avg_logprob": -0.19308835809881036, "compression_ratio": 1.5283842794759825, "no_speech_prob": 1.961502493941225e-05}, {"id": 82, "seek": 38988, "start": 414.71999999999997, "end": 419.0, "text": " has more external contributors than internal contributors.", "tokens": [575, 544, 8320, 45627, 813, 6920, 45627, 13], "temperature": 0.0, "avg_logprob": -0.19308835809881036, "compression_ratio": 1.5283842794759825, "no_speech_prob": 1.961502493941225e-05}, {"id": 83, "seek": 41900, "start": 419.0, "end": 426.0, "text": " So the corporation has, in 2022, 36 code contributors, there's eight from the MariaDB Foundation,", "tokens": [407, 264, 22197, 575, 11, 294, 20229, 11, 8652, 3089, 45627, 11, 456, 311, 3180, 490, 264, 12734, 27735, 10335, 11], "temperature": 0.0, "avg_logprob": -0.2774747713344304, "compression_ratio": 1.6902356902356903, "no_speech_prob": 1.4474821000476368e-05}, {"id": 84, "seek": 41900, "start": 426.0, "end": 428.16, "text": " and there were 68 code contributors elsewhere.", "tokens": [293, 456, 645, 23317, 3089, 45627, 14517, 13], "temperature": 0.0, "avg_logprob": -0.2774747713344304, "compression_ratio": 1.6902356902356903, "no_speech_prob": 1.4474821000476368e-05}, {"id": 85, "seek": 41900, "start": 428.16, "end": 432.36, "text": " Now, obviously, those contributors are not working full time on the code base, but it", "tokens": [823, 11, 2745, 11, 729, 45627, 366, 406, 1364, 1577, 565, 322, 264, 3089, 3096, 11, 457, 309], "temperature": 0.0, "avg_logprob": -0.2774747713344304, "compression_ratio": 1.6902356902356903, "no_speech_prob": 1.4474821000476368e-05}, {"id": 86, "seek": 41900, "start": 432.36, "end": 436.08, "text": " does mean that they kind of fix the problems that are important to them.", "tokens": [775, 914, 300, 436, 733, 295, 3191, 264, 2740, 300, 366, 1021, 281, 552, 13], "temperature": 0.0, "avg_logprob": -0.2774747713344304, "compression_ratio": 1.6902356902356903, "no_speech_prob": 1.4474821000476368e-05}, {"id": 87, "seek": 41900, "start": 436.08, "end": 439.76, "text": " And it's a pretty impressive stat, I think.", "tokens": [400, 309, 311, 257, 1238, 8992, 2219, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.2774747713344304, "compression_ratio": 1.6902356902356903, "no_speech_prob": 1.4474821000476368e-05}, {"id": 88, "seek": 41900, "start": 439.76, "end": 444.28, "text": " And we had similar stats in 2019, you know, kind of something happened in 2020, can't", "tokens": [400, 321, 632, 2531, 18152, 294, 6071, 11, 291, 458, 11, 733, 295, 746, 2011, 294, 4808, 11, 393, 380], "temperature": 0.0, "avg_logprob": -0.2774747713344304, "compression_ratio": 1.6902356902356903, "no_speech_prob": 1.4474821000476368e-05}, {"id": 89, "seek": 41900, "start": 444.28, "end": 448.96, "text": " think what, that kind of, of course it was kind of implied, but yes.", "tokens": [519, 437, 11, 300, 733, 295, 11, 295, 1164, 309, 390, 733, 295, 32614, 11, 457, 2086, 13], "temperature": 0.0, "avg_logprob": -0.2774747713344304, "compression_ratio": 1.6902356902356903, "no_speech_prob": 1.4474821000476368e-05}, {"id": 90, "seek": 44896, "start": 448.96, "end": 455.88, "text": " Also, many of the contributions we've got from China, and that was visited a lot before", "tokens": [2743, 11, 867, 295, 264, 15725, 321, 600, 658, 490, 3533, 11, 293, 300, 390, 11220, 257, 688, 949], "temperature": 0.0, "avg_logprob": -0.28315453610177765, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.00024327047867700458}, {"id": 91, "seek": 44896, "start": 455.88, "end": 456.88, "text": " the COVID.", "tokens": [264, 4566, 13], "temperature": 0.0, "avg_logprob": -0.28315453610177765, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.00024327047867700458}, {"id": 92, "seek": 44896, "start": 456.88, "end": 457.88, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.28315453610177765, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.00024327047867700458}, {"id": 93, "seek": 44896, "start": 457.88, "end": 461.64, "text": " So if you don't see contributors, they forget.", "tokens": [407, 498, 291, 500, 380, 536, 45627, 11, 436, 2870, 13], "temperature": 0.0, "avg_logprob": -0.28315453610177765, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.00024327047867700458}, {"id": 94, "seek": 44896, "start": 461.64, "end": 462.64, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.28315453610177765, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.00024327047867700458}, {"id": 95, "seek": 44896, "start": 462.64, "end": 467.59999999999997, "text": " So as Monty said, COVID hit, China kind of caused the stats to dip a little bit, and", "tokens": [407, 382, 4713, 874, 848, 11, 4566, 2045, 11, 3533, 733, 295, 7008, 264, 18152, 281, 10460, 257, 707, 857, 11, 293], "temperature": 0.0, "avg_logprob": -0.28315453610177765, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.00024327047867700458}, {"id": 96, "seek": 44896, "start": 467.59999999999997, "end": 468.59999999999997, "text": " things like that.", "tokens": [721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.28315453610177765, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.00024327047867700458}, {"id": 97, "seek": 44896, "start": 468.59999999999997, "end": 473.64, "text": " They started to get back up again in 2021 and 2022 has probably been our best year ever,", "tokens": [814, 1409, 281, 483, 646, 493, 797, 294, 7201, 293, 20229, 575, 1391, 668, 527, 1151, 1064, 1562, 11], "temperature": 0.0, "avg_logprob": -0.28315453610177765, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.00024327047867700458}, {"id": 98, "seek": 44896, "start": 473.64, "end": 477.67999999999995, "text": " and I think we got some really big stuff lined up for 2023 as well.", "tokens": [293, 286, 519, 321, 658, 512, 534, 955, 1507, 17189, 493, 337, 44377, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.28315453610177765, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.00024327047867700458}, {"id": 99, "seek": 47768, "start": 477.68, "end": 482.64, "text": " So the actual stats for 2022 are on screen right now.", "tokens": [407, 264, 3539, 18152, 337, 20229, 366, 322, 2568, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.14781143318893564, "compression_ratio": 1.6568265682656826, "no_speech_prob": 5.996703293931205e-06}, {"id": 100, "seek": 47768, "start": 482.64, "end": 485.96, "text": " So corporation, obviously, is the biggest contributor.", "tokens": [407, 22197, 11, 2745, 11, 307, 264, 3880, 42859, 13], "temperature": 0.0, "avg_logprob": -0.14781143318893564, "compression_ratio": 1.6568265682656826, "no_speech_prob": 5.996703293931205e-06}, {"id": 101, "seek": 47768, "start": 485.96, "end": 489.04, "text": " They pay a lot of full time developers to work on it.", "tokens": [814, 1689, 257, 688, 295, 1577, 565, 8849, 281, 589, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.14781143318893564, "compression_ratio": 1.6568265682656826, "no_speech_prob": 5.996703293931205e-06}, {"id": 102, "seek": 47768, "start": 489.04, "end": 492.92, "text": " We have a smaller number in the foundation of full time developers and some people who", "tokens": [492, 362, 257, 4356, 1230, 294, 264, 7030, 295, 1577, 565, 8849, 293, 512, 561, 567], "temperature": 0.0, "avg_logprob": -0.14781143318893564, "compression_ratio": 1.6568265682656826, "no_speech_prob": 5.996703293931205e-06}, {"id": 103, "seek": 47768, "start": 492.92, "end": 495.52, "text": " work part time on the code and things like that as well.", "tokens": [589, 644, 565, 322, 264, 3089, 293, 721, 411, 300, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.14781143318893564, "compression_ratio": 1.6568265682656826, "no_speech_prob": 5.996703293931205e-06}, {"id": 104, "seek": 47768, "start": 495.52, "end": 499.76, "text": " So even I contribute a little bit, but now we're near as much as everyone else, you", "tokens": [407, 754, 286, 10586, 257, 707, 857, 11, 457, 586, 321, 434, 2651, 382, 709, 382, 1518, 1646, 11, 291], "temperature": 0.0, "avg_logprob": -0.14781143318893564, "compression_ratio": 1.6568265682656826, "no_speech_prob": 5.996703293931205e-06}, {"id": 105, "seek": 47768, "start": 499.76, "end": 503.16, "text": " know, at most one day a week, so it's not the huge amount.", "tokens": [458, 11, 412, 881, 472, 786, 257, 1243, 11, 370, 309, 311, 406, 264, 2603, 2372, 13], "temperature": 0.0, "avg_logprob": -0.14781143318893564, "compression_ratio": 1.6568265682656826, "no_speech_prob": 5.996703293931205e-06}, {"id": 106, "seek": 50316, "start": 503.16, "end": 509.44, "text": " And then other contributors kind of outside of the MariaDB circle, pretty much on par", "tokens": [400, 550, 661, 45627, 733, 295, 2380, 295, 264, 12734, 27735, 6329, 11, 1238, 709, 322, 971], "temperature": 0.0, "avg_logprob": -0.16516409529016374, "compression_ratio": 1.6592920353982301, "no_speech_prob": 1.0847157682292163e-05}, {"id": 107, "seek": 50316, "start": 509.44, "end": 513.64, "text": " with what the foundation contributes, so pretty good.", "tokens": [365, 437, 264, 7030, 32035, 11, 370, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.16516409529016374, "compression_ratio": 1.6592920353982301, "no_speech_prob": 1.0847157682292163e-05}, {"id": 108, "seek": 50316, "start": 513.64, "end": 518.48, "text": " So we use Git DM, which is called Git Data Miner, to actually process the Git commit", "tokens": [407, 321, 764, 16939, 15322, 11, 597, 307, 1219, 16939, 11888, 2829, 260, 11, 281, 767, 1399, 264, 16939, 5599], "temperature": 0.0, "avg_logprob": -0.16516409529016374, "compression_ratio": 1.6592920353982301, "no_speech_prob": 1.0847157682292163e-05}, {"id": 109, "seek": 50316, "start": 518.48, "end": 520.1600000000001, "text": " stream to generate this.", "tokens": [4309, 281, 8460, 341, 13], "temperature": 0.0, "avg_logprob": -0.16516409529016374, "compression_ratio": 1.6592920353982301, "no_speech_prob": 1.0847157682292163e-05}, {"id": 110, "seek": 50316, "start": 520.1600000000001, "end": 524.72, "text": " And I've actually open sourced the tooling that does all this, and it has all the kind", "tokens": [400, 286, 600, 767, 1269, 11006, 1232, 264, 46593, 300, 775, 439, 341, 11, 293, 309, 575, 439, 264, 733], "temperature": 0.0, "avg_logprob": -0.16516409529016374, "compression_ratio": 1.6592920353982301, "no_speech_prob": 1.0847157682292163e-05}, {"id": 111, "seek": 50316, "start": 524.72, "end": 526.96, "text": " of metadata in there to generate this.", "tokens": [295, 26603, 294, 456, 281, 8460, 341, 13], "temperature": 0.0, "avg_logprob": -0.16516409529016374, "compression_ratio": 1.6592920353982301, "no_speech_prob": 1.0847157682292163e-05}, {"id": 112, "seek": 52696, "start": 526.96, "end": 533.32, "text": " So you can actually break it down by user, by entity they work for, et cetera.", "tokens": [407, 291, 393, 767, 1821, 309, 760, 538, 4195, 11, 538, 13977, 436, 589, 337, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.12926897406578064, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.1970859304710757e-05}, {"id": 113, "seek": 52696, "start": 533.32, "end": 537.2800000000001, "text": " And if you find that I've made a mistake on identifying someone, you can actually open", "tokens": [400, 498, 291, 915, 300, 286, 600, 1027, 257, 6146, 322, 16696, 1580, 11, 291, 393, 767, 1269], "temperature": 0.0, "avg_logprob": -0.12926897406578064, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.1970859304710757e-05}, {"id": 114, "seek": 52696, "start": 537.2800000000001, "end": 541.8000000000001, "text": " a pull request on that and change the data accordingly.", "tokens": [257, 2235, 5308, 322, 300, 293, 1319, 264, 1412, 19717, 13], "temperature": 0.0, "avg_logprob": -0.12926897406578064, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.1970859304710757e-05}, {"id": 115, "seek": 52696, "start": 541.8000000000001, "end": 546.6800000000001, "text": " So it's kind of open in that respect as well, if you see what I mean.", "tokens": [407, 309, 311, 733, 295, 1269, 294, 300, 3104, 382, 731, 11, 498, 291, 536, 437, 286, 914, 13], "temperature": 0.0, "avg_logprob": -0.12926897406578064, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.1970859304710757e-05}, {"id": 116, "seek": 52696, "start": 546.6800000000001, "end": 549.6800000000001, "text": " Git Data Miner was something that was generated, it was created for the Linux kernel.", "tokens": [16939, 11888, 2829, 260, 390, 746, 300, 390, 10833, 11, 309, 390, 2942, 337, 264, 18734, 28256, 13], "temperature": 0.0, "avg_logprob": -0.12926897406578064, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.1970859304710757e-05}, {"id": 117, "seek": 52696, "start": 549.6800000000001, "end": 553.9200000000001, "text": " We tweaked it a little bit so we can count hackers and things like that, but yeah, it's", "tokens": [492, 6986, 7301, 309, 257, 707, 857, 370, 321, 393, 1207, 39766, 293, 721, 411, 300, 11, 457, 1338, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.12926897406578064, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.1970859304710757e-05}, {"id": 118, "seek": 52696, "start": 553.9200000000001, "end": 556.64, "text": " essentially the same tool.", "tokens": [4476, 264, 912, 2290, 13], "temperature": 0.0, "avg_logprob": -0.12926897406578064, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.1970859304710757e-05}, {"id": 119, "seek": 55664, "start": 556.64, "end": 558.1999999999999, "text": " We have a script to generate pull requests.", "tokens": [492, 362, 257, 5755, 281, 8460, 2235, 12475, 13], "temperature": 0.0, "avg_logprob": -0.15822044440678187, "compression_ratio": 1.6448979591836734, "no_speech_prob": 1.7355976524413563e-05}, {"id": 120, "seek": 55664, "start": 558.1999999999999, "end": 563.6, "text": " I know this chart is going to be difficult to see on the screen, but kind of the trend", "tokens": [286, 458, 341, 6927, 307, 516, 281, 312, 2252, 281, 536, 322, 264, 2568, 11, 457, 733, 295, 264, 6028], "temperature": 0.0, "avg_logprob": -0.15822044440678187, "compression_ratio": 1.6448979591836734, "no_speech_prob": 1.7355976524413563e-05}, {"id": 121, "seek": 55664, "start": 563.6, "end": 565.36, "text": " is the important part.", "tokens": [307, 264, 1021, 644, 13], "temperature": 0.0, "avg_logprob": -0.15822044440678187, "compression_ratio": 1.6448979591836734, "no_speech_prob": 1.7355976524413563e-05}, {"id": 122, "seek": 55664, "start": 565.36, "end": 568.84, "text": " So this scrapes GitHub for weekly pull request metrics.", "tokens": [407, 341, 23138, 279, 23331, 337, 12460, 2235, 5308, 16367, 13], "temperature": 0.0, "avg_logprob": -0.15822044440678187, "compression_ratio": 1.6448979591836734, "no_speech_prob": 1.7355976524413563e-05}, {"id": 123, "seek": 55664, "start": 568.84, "end": 575.68, "text": " So the X axis here is weak numbers, and then the Y axis is the number of open pull requests.", "tokens": [407, 264, 1783, 10298, 510, 307, 5336, 3547, 11, 293, 550, 264, 398, 10298, 307, 264, 1230, 295, 1269, 2235, 12475, 13], "temperature": 0.0, "avg_logprob": -0.15822044440678187, "compression_ratio": 1.6448979591836734, "no_speech_prob": 1.7355976524413563e-05}, {"id": 124, "seek": 55664, "start": 575.68, "end": 579.52, "text": " So the bottom is 80, the top is 120.", "tokens": [407, 264, 2767, 307, 4688, 11, 264, 1192, 307, 10411, 13], "temperature": 0.0, "avg_logprob": -0.15822044440678187, "compression_ratio": 1.6448979591836734, "no_speech_prob": 1.7355976524413563e-05}, {"id": 125, "seek": 55664, "start": 579.52, "end": 581.2, "text": " Part of my job is to help bring this down.", "tokens": [4100, 295, 452, 1691, 307, 281, 854, 1565, 341, 760, 13], "temperature": 0.0, "avg_logprob": -0.15822044440678187, "compression_ratio": 1.6448979591836734, "no_speech_prob": 1.7355976524413563e-05}, {"id": 126, "seek": 55664, "start": 581.2, "end": 583.16, "text": " I have been failing.", "tokens": [286, 362, 668, 18223, 13], "temperature": 0.0, "avg_logprob": -0.15822044440678187, "compression_ratio": 1.6448979591836734, "no_speech_prob": 1.7355976524413563e-05}, {"id": 127, "seek": 58316, "start": 583.16, "end": 587.28, "text": " I will be working on that quite a bit in 2023.", "tokens": [286, 486, 312, 1364, 322, 300, 1596, 257, 857, 294, 44377, 13], "temperature": 0.0, "avg_logprob": -0.2835072931253685, "compression_ratio": 1.5726872246696035, "no_speech_prob": 7.025195372989401e-05}, {"id": 128, "seek": 58316, "start": 587.28, "end": 588.28, "text": " So I'd run.", "tokens": [407, 286, 1116, 1190, 13], "temperature": 0.0, "avg_logprob": -0.2835072931253685, "compression_ratio": 1.5726872246696035, "no_speech_prob": 7.025195372989401e-05}, {"id": 129, "seek": 58316, "start": 588.28, "end": 593.36, "text": " You should also add how many actually close to that one, how many are open.", "tokens": [509, 820, 611, 909, 577, 867, 767, 1998, 281, 300, 472, 11, 577, 867, 366, 1269, 13], "temperature": 0.0, "avg_logprob": -0.2835072931253685, "compression_ratio": 1.5726872246696035, "no_speech_prob": 7.025195372989401e-05}, {"id": 130, "seek": 58316, "start": 593.36, "end": 598.8, "text": " I do have that, but showing that on this chart was getting very messy.", "tokens": [286, 360, 362, 300, 11, 457, 4099, 300, 322, 341, 6927, 390, 1242, 588, 16191, 13], "temperature": 0.0, "avg_logprob": -0.2835072931253685, "compression_ratio": 1.5726872246696035, "no_speech_prob": 7.025195372989401e-05}, {"id": 131, "seek": 58316, "start": 598.8, "end": 602.56, "text": " So it's hard enough just showing this.", "tokens": [407, 309, 311, 1152, 1547, 445, 4099, 341, 13], "temperature": 0.0, "avg_logprob": -0.2835072931253685, "compression_ratio": 1.5726872246696035, "no_speech_prob": 7.025195372989401e-05}, {"id": 132, "seek": 58316, "start": 602.56, "end": 608.4, "text": " We do close a hell of a lot of pull requests as well, and we don't just go in and say,", "tokens": [492, 360, 1998, 257, 4921, 295, 257, 688, 295, 2235, 12475, 382, 731, 11, 293, 321, 500, 380, 445, 352, 294, 293, 584, 11], "temperature": 0.0, "avg_logprob": -0.2835072931253685, "compression_ratio": 1.5726872246696035, "no_speech_prob": 7.025195372989401e-05}, {"id": 133, "seek": 58316, "start": 608.4, "end": 609.52, "text": " no, that's rubbish close.", "tokens": [572, 11, 300, 311, 29978, 1998, 13], "temperature": 0.0, "avg_logprob": -0.2835072931253685, "compression_ratio": 1.5726872246696035, "no_speech_prob": 7.025195372989401e-05}, {"id": 134, "seek": 60952, "start": 609.52, "end": 613.48, "text": " We tend to talk to people through the pull request, and that's why some of us stay open", "tokens": [492, 3928, 281, 751, 281, 561, 807, 264, 2235, 5308, 11, 293, 300, 311, 983, 512, 295, 505, 1754, 1269], "temperature": 0.0, "avg_logprob": -0.1867529364193187, "compression_ratio": 1.6488888888888888, "no_speech_prob": 1.7318345271633007e-05}, {"id": 135, "seek": 60952, "start": 613.48, "end": 616.48, "text": " quite a long time.", "tokens": [1596, 257, 938, 565, 13], "temperature": 0.0, "avg_logprob": -0.1867529364193187, "compression_ratio": 1.6488888888888888, "no_speech_prob": 1.7318345271633007e-05}, {"id": 136, "seek": 60952, "start": 616.48, "end": 622.0, "text": " So in the metrics future, I kind of want to break down the commit contributions by module,", "tokens": [407, 294, 264, 16367, 2027, 11, 286, 733, 295, 528, 281, 1821, 760, 264, 5599, 15725, 538, 10088, 11], "temperature": 0.0, "avg_logprob": -0.1867529364193187, "compression_ratio": 1.6488888888888888, "no_speech_prob": 1.7318345271633007e-05}, {"id": 137, "seek": 60952, "start": 622.0, "end": 623.0, "text": " engine, et cetera.", "tokens": [2848, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.1867529364193187, "compression_ratio": 1.6488888888888888, "no_speech_prob": 1.7318345271633007e-05}, {"id": 138, "seek": 60952, "start": 623.0, "end": 628.28, "text": " So we know how many contributions are coming to InnoDB, how many to connect engine, how", "tokens": [407, 321, 458, 577, 867, 15725, 366, 1348, 281, 682, 1771, 27735, 11, 577, 867, 281, 1745, 2848, 11, 577], "temperature": 0.0, "avg_logprob": -0.1867529364193187, "compression_ratio": 1.6488888888888888, "no_speech_prob": 1.7318345271633007e-05}, {"id": 139, "seek": 60952, "start": 628.28, "end": 633.4, "text": " many to ROXDB, et cetera, so that we can track that kind of usage.", "tokens": [867, 281, 9025, 55, 27735, 11, 1030, 11458, 11, 370, 300, 321, 393, 2837, 300, 733, 295, 14924, 13], "temperature": 0.0, "avg_logprob": -0.1867529364193187, "compression_ratio": 1.6488888888888888, "no_speech_prob": 1.7318345271633007e-05}, {"id": 140, "seek": 63340, "start": 633.4, "end": 640.6, "text": " I want to track the average time to merge pull requests, median and mean, I guess, probably", "tokens": [286, 528, 281, 2837, 264, 4274, 565, 281, 22183, 2235, 12475, 11, 26779, 293, 914, 11, 286, 2041, 11, 1391], "temperature": 0.0, "avg_logprob": -0.12339477355663593, "compression_ratio": 1.7370689655172413, "no_speech_prob": 5.636384230456315e-06}, {"id": 141, "seek": 63340, "start": 640.6, "end": 644.68, "text": " median because we've got some that have been open a couple of years and some that only", "tokens": [26779, 570, 321, 600, 658, 512, 300, 362, 668, 1269, 257, 1916, 295, 924, 293, 512, 300, 787], "temperature": 0.0, "avg_logprob": -0.12339477355663593, "compression_ratio": 1.7370689655172413, "no_speech_prob": 5.636384230456315e-06}, {"id": 142, "seek": 63340, "start": 644.68, "end": 649.4399999999999, "text": " stay open a week or two, for example.", "tokens": [1754, 1269, 257, 1243, 420, 732, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.12339477355663593, "compression_ratio": 1.7370689655172413, "no_speech_prob": 5.636384230456315e-06}, {"id": 143, "seek": 63340, "start": 649.4399999999999, "end": 650.4399999999999, "text": " But we'll track that.", "tokens": [583, 321, 603, 2837, 300, 13], "temperature": 0.0, "avg_logprob": -0.12339477355663593, "compression_ratio": 1.7370689655172413, "no_speech_prob": 5.636384230456315e-06}, {"id": 144, "seek": 63340, "start": 650.4399999999999, "end": 653.16, "text": " We'll bring it down.", "tokens": [492, 603, 1565, 309, 760, 13], "temperature": 0.0, "avg_logprob": -0.12339477355663593, "compression_ratio": 1.7370689655172413, "no_speech_prob": 5.636384230456315e-06}, {"id": 145, "seek": 63340, "start": 653.16, "end": 654.16, "text": " Buildbot contribution metrics.", "tokens": [11875, 18870, 13150, 16367, 13], "temperature": 0.0, "avg_logprob": -0.12339477355663593, "compression_ratio": 1.7370689655172413, "no_speech_prob": 5.636384230456315e-06}, {"id": 146, "seek": 63340, "start": 654.16, "end": 657.1999999999999, "text": " So we use buildbot for continuous integration.", "tokens": [407, 321, 764, 1322, 18870, 337, 10957, 10980, 13], "temperature": 0.0, "avg_logprob": -0.12339477355663593, "compression_ratio": 1.7370689655172413, "no_speech_prob": 5.636384230456315e-06}, {"id": 147, "seek": 63340, "start": 657.1999999999999, "end": 661.0, "text": " We do get pull requests through that, contributions through that.", "tokens": [492, 360, 483, 2235, 12475, 807, 300, 11, 15725, 807, 300, 13], "temperature": 0.0, "avg_logprob": -0.12339477355663593, "compression_ratio": 1.7370689655172413, "no_speech_prob": 5.636384230456315e-06}, {"id": 148, "seek": 66100, "start": 661.0, "end": 664.92, "text": " So we'd love to track that kind of stuff.", "tokens": [407, 321, 1116, 959, 281, 2837, 300, 733, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.18796248435974122, "compression_ratio": 1.6145454545454545, "no_speech_prob": 6.871249297546456e-06}, {"id": 149, "seek": 66100, "start": 664.92, "end": 666.4, "text": " More community-wide metrics.", "tokens": [5048, 1768, 12, 7990, 16367, 13], "temperature": 0.0, "avg_logprob": -0.18796248435974122, "compression_ratio": 1.6145454545454545, "no_speech_prob": 6.871249297546456e-06}, {"id": 150, "seek": 66100, "start": 666.4, "end": 667.48, "text": " So we're talking Jira.", "tokens": [407, 321, 434, 1417, 508, 4271, 13], "temperature": 0.0, "avg_logprob": -0.18796248435974122, "compression_ratio": 1.6145454545454545, "no_speech_prob": 6.871249297546456e-06}, {"id": 151, "seek": 66100, "start": 667.48, "end": 671.48, "text": " We're talking Stack Overflow Reddit metrics, et cetera, like that, capturing those kind", "tokens": [492, 434, 1417, 37649, 4886, 10565, 32210, 16367, 11, 1030, 11458, 11, 411, 300, 11, 23384, 729, 733], "temperature": 0.0, "avg_logprob": -0.18796248435974122, "compression_ratio": 1.6145454545454545, "no_speech_prob": 6.871249297546456e-06}, {"id": 152, "seek": 66100, "start": 671.48, "end": 678.24, "text": " of things and publishing along with the quarterly stats that I already published on meridb.org.", "tokens": [295, 721, 293, 17832, 2051, 365, 264, 38633, 18152, 300, 286, 1217, 6572, 322, 3551, 327, 65, 13, 4646, 13], "temperature": 0.0, "avg_logprob": -0.18796248435974122, "compression_ratio": 1.6145454545454545, "no_speech_prob": 6.871249297546456e-06}, {"id": 153, "seek": 66100, "start": 678.24, "end": 680.92, "text": " And if there's any other metrics you want to see, let us know.", "tokens": [400, 498, 456, 311, 604, 661, 16367, 291, 528, 281, 536, 11, 718, 505, 458, 13], "temperature": 0.0, "avg_logprob": -0.18796248435974122, "compression_ratio": 1.6145454545454545, "no_speech_prob": 6.871249297546456e-06}, {"id": 154, "seek": 66100, "start": 680.92, "end": 685.28, "text": " Contact us because we are happy to generate them.", "tokens": [30683, 505, 570, 321, 366, 2055, 281, 8460, 552, 13], "temperature": 0.0, "avg_logprob": -0.18796248435974122, "compression_ratio": 1.6145454545454545, "no_speech_prob": 6.871249297546456e-06}, {"id": 155, "seek": 66100, "start": 685.28, "end": 688.2, "text": " So we'll talk about how to contribute code to Meridb.", "tokens": [407, 321, 603, 751, 466, 577, 281, 10586, 3089, 281, 6124, 327, 65, 13], "temperature": 0.0, "avg_logprob": -0.18796248435974122, "compression_ratio": 1.6145454545454545, "no_speech_prob": 6.871249297546456e-06}, {"id": 156, "seek": 68820, "start": 688.2, "end": 694.0, "text": " I wrote a blog post about this on meridb.org, but there are some basic steps you can follow.", "tokens": [286, 4114, 257, 6968, 2183, 466, 341, 322, 3551, 327, 65, 13, 4646, 11, 457, 456, 366, 512, 3875, 4439, 291, 393, 1524, 13], "temperature": 0.0, "avg_logprob": -0.16202674993947774, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.986999425047543e-05}, {"id": 157, "seek": 68820, "start": 694.0, "end": 698.1600000000001, "text": " And it kind of helps reduce the round trip time during review.", "tokens": [400, 309, 733, 295, 3665, 5407, 264, 3098, 4931, 565, 1830, 3131, 13], "temperature": 0.0, "avg_logprob": -0.16202674993947774, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.986999425047543e-05}, {"id": 158, "seek": 68820, "start": 698.1600000000001, "end": 704.96, "text": " And also, I don't want you to spend hours, days working on something and opening a pull", "tokens": [400, 611, 11, 286, 500, 380, 528, 291, 281, 3496, 2496, 11, 1708, 1364, 322, 746, 293, 5193, 257, 2235], "temperature": 0.0, "avg_logprob": -0.16202674993947774, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.986999425047543e-05}, {"id": 159, "seek": 68820, "start": 704.96, "end": 709.6800000000001, "text": " request and saying, sorry, this doesn't really fit with what we're doing at all or someone", "tokens": [5308, 293, 1566, 11, 2597, 11, 341, 1177, 380, 534, 3318, 365, 437, 321, 434, 884, 412, 439, 420, 1580], "temperature": 0.0, "avg_logprob": -0.16202674993947774, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.986999425047543e-05}, {"id": 160, "seek": 68820, "start": 709.6800000000001, "end": 711.12, "text": " else has already done this.", "tokens": [1646, 575, 1217, 1096, 341, 13], "temperature": 0.0, "avg_logprob": -0.16202674993947774, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.986999425047543e-05}, {"id": 161, "seek": 68820, "start": 711.12, "end": 715.96, "text": " And I have to say no, because I don't want to crush people's hopes or anything like that.", "tokens": [400, 286, 362, 281, 584, 572, 11, 570, 286, 500, 380, 528, 281, 10321, 561, 311, 13681, 420, 1340, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.16202674993947774, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.986999425047543e-05}, {"id": 162, "seek": 71596, "start": 715.96, "end": 720.5600000000001, "text": " So if you follow these steps, it will kind of help reduce that quite a bit.", "tokens": [407, 498, 291, 1524, 613, 4439, 11, 309, 486, 733, 295, 854, 5407, 300, 1596, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.22514359400822567, "compression_ratio": 1.6798561151079137, "no_speech_prob": 2.7147703804075718e-05}, {"id": 163, "seek": 71596, "start": 720.5600000000001, "end": 724.0, "text": " So the first step is communication, talking to us.", "tokens": [407, 264, 700, 1823, 307, 6101, 11, 1417, 281, 505, 13], "temperature": 0.0, "avg_logprob": -0.22514359400822567, "compression_ratio": 1.6798561151079137, "no_speech_prob": 2.7147703804075718e-05}, {"id": 164, "seek": 71596, "start": 724.0, "end": 727.08, "text": " We can guide you through kind of every step of the way.", "tokens": [492, 393, 5934, 291, 807, 733, 295, 633, 1823, 295, 264, 636, 13], "temperature": 0.0, "avg_logprob": -0.22514359400822567, "compression_ratio": 1.6798561151079137, "no_speech_prob": 2.7147703804075718e-05}, {"id": 165, "seek": 71596, "start": 727.08, "end": 732.0, "text": " Meridb team are quite approachable, preferably via Jira and Zulit, but there are other ways", "tokens": [6124, 327, 65, 1469, 366, 1596, 3109, 712, 11, 45916, 5766, 508, 4271, 293, 1176, 425, 270, 11, 457, 456, 366, 661, 2098], "temperature": 0.0, "avg_logprob": -0.22514359400822567, "compression_ratio": 1.6798561151079137, "no_speech_prob": 2.7147703804075718e-05}, {"id": 166, "seek": 71596, "start": 732.0, "end": 733.72, "text": " to talk to us as well.", "tokens": [281, 751, 281, 505, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.22514359400822567, "compression_ratio": 1.6798561151079137, "no_speech_prob": 2.7147703804075718e-05}, {"id": 167, "seek": 71596, "start": 733.72, "end": 737.36, "text": " In particular, Vicente Daniel and me at the foundation, there are a list of people at", "tokens": [682, 1729, 11, 33316, 1576, 8033, 293, 385, 412, 264, 7030, 11, 456, 366, 257, 1329, 295, 561, 412], "temperature": 0.0, "avg_logprob": -0.22514359400822567, "compression_ratio": 1.6798561151079137, "no_speech_prob": 2.7147703804075718e-05}, {"id": 168, "seek": 71596, "start": 737.36, "end": 741.2800000000001, "text": " the corporation I'm sure you can talk to as well.", "tokens": [264, 22197, 286, 478, 988, 291, 393, 751, 281, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.22514359400822567, "compression_ratio": 1.6798561151079137, "no_speech_prob": 2.7147703804075718e-05}, {"id": 169, "seek": 71596, "start": 741.2800000000001, "end": 742.8000000000001, "text": " Tell us what you want to work on.", "tokens": [5115, 505, 437, 291, 528, 281, 589, 322, 13], "temperature": 0.0, "avg_logprob": -0.22514359400822567, "compression_ratio": 1.6798561151079137, "no_speech_prob": 2.7147703804075718e-05}, {"id": 170, "seek": 74280, "start": 742.8, "end": 747.16, "text": " And if you don't know what you want to work on, there is a beginner-friendly tag on Jira", "tokens": [400, 498, 291, 500, 380, 458, 437, 291, 528, 281, 589, 322, 11, 456, 307, 257, 22080, 12, 22864, 6162, 322, 508, 4271], "temperature": 0.0, "avg_logprob": -0.13639318163149824, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.465389686927665e-05}, {"id": 171, "seek": 74280, "start": 747.16, "end": 753.12, "text": " where we've tagged tickets that should be relatively easy to pick up and work on.", "tokens": [689, 321, 600, 40239, 12628, 300, 820, 312, 7226, 1858, 281, 1888, 493, 293, 589, 322, 13], "temperature": 0.0, "avg_logprob": -0.13639318163149824, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.465389686927665e-05}, {"id": 172, "seek": 74280, "start": 753.12, "end": 755.0, "text": " And we can talk you through these.", "tokens": [400, 321, 393, 751, 291, 807, 613, 13], "temperature": 0.0, "avg_logprob": -0.13639318163149824, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.465389686927665e-05}, {"id": 173, "seek": 74280, "start": 755.0, "end": 758.4, "text": " If there's no Jira for what you want to work on yet, open one and again, talk to us and", "tokens": [759, 456, 311, 572, 508, 4271, 337, 437, 291, 528, 281, 589, 322, 1939, 11, 1269, 472, 293, 797, 11, 751, 281, 505, 293], "temperature": 0.0, "avg_logprob": -0.13639318163149824, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.465389686927665e-05}, {"id": 174, "seek": 74280, "start": 758.4, "end": 764.64, "text": " we can figure out the best solution for it.", "tokens": [321, 393, 2573, 484, 264, 1151, 3827, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.13639318163149824, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.465389686927665e-05}, {"id": 175, "seek": 74280, "start": 764.64, "end": 765.8399999999999, "text": " Next step is hacking.", "tokens": [3087, 1823, 307, 31422, 13], "temperature": 0.0, "avg_logprob": -0.13639318163149824, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.465389686927665e-05}, {"id": 176, "seek": 74280, "start": 765.8399999999999, "end": 767.8399999999999, "text": " Write some codes.", "tokens": [23499, 512, 14211, 13], "temperature": 0.0, "avg_logprob": -0.13639318163149824, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.465389686927665e-05}, {"id": 177, "seek": 76784, "start": 767.84, "end": 772.96, "text": " If you are making a bug fix, it needs to be against the oldest-affected version of Meridb,", "tokens": [759, 291, 366, 1455, 257, 7426, 3191, 11, 309, 2203, 281, 312, 1970, 264, 14026, 12, 2518, 39963, 3037, 295, 6124, 327, 65, 11], "temperature": 0.0, "avg_logprob": -0.25500781500517433, "compression_ratio": 1.7805755395683454, "no_speech_prob": 3.4239477827213705e-05}, {"id": 178, "seek": 76784, "start": 772.96, "end": 776.64, "text": " so if it affects 10.5 upwards, then against 10.5.", "tokens": [370, 498, 309, 11807, 1266, 13, 20, 22167, 11, 550, 1970, 1266, 13, 20, 13], "temperature": 0.0, "avg_logprob": -0.25500781500517433, "compression_ratio": 1.7805755395683454, "no_speech_prob": 3.4239477827213705e-05}, {"id": 179, "seek": 76784, "start": 776.64, "end": 780.0400000000001, "text": " What is the thing that active release?", "tokens": [708, 307, 264, 551, 300, 4967, 4374, 30], "temperature": 0.0, "avg_logprob": -0.25500781500517433, "compression_ratio": 1.7805755395683454, "no_speech_prob": 3.4239477827213705e-05}, {"id": 180, "seek": 76784, "start": 780.0400000000001, "end": 781.0400000000001, "text": " Yes, active release.", "tokens": [1079, 11, 4967, 4374, 13], "temperature": 0.0, "avg_logprob": -0.25500781500517433, "compression_ratio": 1.7805755395683454, "no_speech_prob": 3.4239477827213705e-05}, {"id": 181, "seek": 76784, "start": 781.0400000000001, "end": 783.32, "text": " Yes, this is a good point.", "tokens": [1079, 11, 341, 307, 257, 665, 935, 13], "temperature": 0.0, "avg_logprob": -0.25500781500517433, "compression_ratio": 1.7805755395683454, "no_speech_prob": 3.4239477827213705e-05}, {"id": 182, "seek": 76784, "start": 783.32, "end": 788.0400000000001, "text": " Always check the end of life as well for the releases when you do this because we're in", "tokens": [11270, 1520, 264, 917, 295, 993, 382, 731, 337, 264, 16952, 562, 291, 360, 341, 570, 321, 434, 294], "temperature": 0.0, "avg_logprob": -0.25500781500517433, "compression_ratio": 1.7805755395683454, "no_speech_prob": 3.4239477827213705e-05}, {"id": 183, "seek": 76784, "start": 788.0400000000001, "end": 794.24, "text": " this weird phase right now where we have got, we changed release cycles a couple of years", "tokens": [341, 3657, 5574, 558, 586, 689, 321, 362, 658, 11, 321, 3105, 4374, 17796, 257, 1916, 295, 924], "temperature": 0.0, "avg_logprob": -0.25500781500517433, "compression_ratio": 1.7805755395683454, "no_speech_prob": 3.4239477827213705e-05}, {"id": 184, "seek": 76784, "start": 794.24, "end": 797.6800000000001, "text": " ago, so some releases are on the old release cycle and some are on the new release cycles", "tokens": [2057, 11, 370, 512, 16952, 366, 322, 264, 1331, 4374, 6586, 293, 512, 366, 322, 264, 777, 4374, 17796], "temperature": 0.0, "avg_logprob": -0.25500781500517433, "compression_ratio": 1.7805755395683454, "no_speech_prob": 3.4239477827213705e-05}, {"id": 185, "seek": 79768, "start": 797.68, "end": 801.16, "text": " so some in the middle are end of life but some are.", "tokens": [370, 512, 294, 264, 2808, 366, 917, 295, 993, 457, 512, 366, 13], "temperature": 0.0, "avg_logprob": -0.1793930417015439, "compression_ratio": 1.6699346405228759, "no_speech_prob": 2.220694295829162e-05}, {"id": 186, "seek": 79768, "start": 801.16, "end": 805.4799999999999, "text": " So it's a bit funny right now, but again, you can talk to us about this and we can help", "tokens": [407, 309, 311, 257, 857, 4074, 558, 586, 11, 457, 797, 11, 291, 393, 751, 281, 505, 466, 341, 293, 321, 393, 854], "temperature": 0.0, "avg_logprob": -0.1793930417015439, "compression_ratio": 1.6699346405228759, "no_speech_prob": 2.220694295829162e-05}, {"id": 187, "seek": 79768, "start": 805.4799999999999, "end": 807.0, "text": " point in the right direction.", "tokens": [935, 294, 264, 558, 3513, 13], "temperature": 0.0, "avg_logprob": -0.1793930417015439, "compression_ratio": 1.6699346405228759, "no_speech_prob": 2.220694295829162e-05}, {"id": 188, "seek": 79768, "start": 807.0, "end": 813.5999999999999, "text": " The new features always go in the latest development version, which currently is 11.0 for the next", "tokens": [440, 777, 4122, 1009, 352, 294, 264, 6792, 3250, 3037, 11, 597, 4362, 307, 2975, 13, 15, 337, 264, 958], "temperature": 0.0, "avg_logprob": -0.1793930417015439, "compression_ratio": 1.6699346405228759, "no_speech_prob": 2.220694295829162e-05}, {"id": 189, "seek": 79768, "start": 813.5999999999999, "end": 814.5999999999999, "text": " couple of weeks.", "tokens": [1916, 295, 3259, 13], "temperature": 0.0, "avg_logprob": -0.1793930417015439, "compression_ratio": 1.6699346405228759, "no_speech_prob": 2.220694295829162e-05}, {"id": 190, "seek": 79768, "start": 814.5999999999999, "end": 819.76, "text": " When that hits GA, there'll be another release you can bolt things on.", "tokens": [1133, 300, 8664, 22841, 11, 456, 603, 312, 1071, 4374, 291, 393, 13436, 721, 322, 13], "temperature": 0.0, "avg_logprob": -0.1793930417015439, "compression_ratio": 1.6699346405228759, "no_speech_prob": 2.220694295829162e-05}, {"id": 191, "seek": 79768, "start": 819.76, "end": 822.1999999999999, "text": " Please stick to the coding standards to the surrounding code.", "tokens": [2555, 2897, 281, 264, 17720, 7787, 281, 264, 11498, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1793930417015439, "compression_ratio": 1.6699346405228759, "no_speech_prob": 2.220694295829162e-05}, {"id": 192, "seek": 79768, "start": 822.1999999999999, "end": 826.4799999999999, "text": " You'll find that different engines have different coding standards because they've come from", "tokens": [509, 603, 915, 300, 819, 12982, 362, 819, 17720, 7787, 570, 436, 600, 808, 490], "temperature": 0.0, "avg_logprob": -0.1793930417015439, "compression_ratio": 1.6699346405228759, "no_speech_prob": 2.220694295829162e-05}, {"id": 193, "seek": 82648, "start": 826.48, "end": 827.6800000000001, "text": " different places.", "tokens": [819, 3190, 13], "temperature": 0.0, "avg_logprob": -0.22090925772984824, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.543191319797188e-05}, {"id": 194, "seek": 82648, "start": 827.6800000000001, "end": 832.72, "text": " Connect engine was originally a MySQL contribution that came through to MarineDB and that's got", "tokens": [11653, 2848, 390, 7993, 257, 1222, 39934, 13150, 300, 1361, 807, 281, 20415, 27735, 293, 300, 311, 658], "temperature": 0.0, "avg_logprob": -0.22090925772984824, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.543191319797188e-05}, {"id": 195, "seek": 82648, "start": 832.72, "end": 836.64, "text": " a different coding standard to say NODB and the core server code.", "tokens": [257, 819, 17720, 3832, 281, 584, 426, 14632, 33, 293, 264, 4965, 7154, 3089, 13], "temperature": 0.0, "avg_logprob": -0.22090925772984824, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.543191319797188e-05}, {"id": 196, "seek": 82648, "start": 836.64, "end": 841.84, "text": " I've put together a coding standards document which should be merged shortly and that's", "tokens": [286, 600, 829, 1214, 257, 17720, 7787, 4166, 597, 820, 312, 36427, 13392, 293, 300, 311], "temperature": 0.0, "avg_logprob": -0.22090925772984824, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.543191319797188e-05}, {"id": 197, "seek": 82648, "start": 841.84, "end": 846.96, "text": " just for the core server and at the moment it's descriptive, run and prescriptive, but", "tokens": [445, 337, 264, 4965, 7154, 293, 412, 264, 1623, 309, 311, 42585, 11, 1190, 293, 1183, 5944, 488, 11, 457], "temperature": 0.0, "avg_logprob": -0.22090925772984824, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.543191319797188e-05}, {"id": 198, "seek": 82648, "start": 846.96, "end": 850.8000000000001, "text": " we're going to improve on that over time.", "tokens": [321, 434, 516, 281, 3470, 322, 300, 670, 565, 13], "temperature": 0.0, "avg_logprob": -0.22090925772984824, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.543191319797188e-05}, {"id": 199, "seek": 85080, "start": 850.8, "end": 857.04, "text": " Some test cases, we don't want you to write something, us merge it and then us break it", "tokens": [2188, 1500, 3331, 11, 321, 500, 380, 528, 291, 281, 2464, 746, 11, 505, 22183, 309, 293, 550, 505, 1821, 309], "temperature": 0.0, "avg_logprob": -0.1876298716810883, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2777388292306568e-05}, {"id": 200, "seek": 85080, "start": 857.04, "end": 858.04, "text": " later.", "tokens": [1780, 13], "temperature": 0.0, "avg_logprob": -0.1876298716810883, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2777388292306568e-05}, {"id": 201, "seek": 85080, "start": 858.04, "end": 862.4799999999999, "text": " So if you have some test cases in there, A, it proves exactly what you're doing and", "tokens": [407, 498, 291, 362, 512, 1500, 3331, 294, 456, 11, 316, 11, 309, 25019, 2293, 437, 291, 434, 884, 293], "temperature": 0.0, "avg_logprob": -0.1876298716810883, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2777388292306568e-05}, {"id": 202, "seek": 85080, "start": 862.4799999999999, "end": 867.76, "text": " B, it means that it will stay like that in the future.", "tokens": [363, 11, 309, 1355, 300, 309, 486, 1754, 411, 300, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.1876298716810883, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2777388292306568e-05}, {"id": 203, "seek": 85080, "start": 867.76, "end": 872.0799999999999, "text": " Run the MTR test suite locally because otherwise you might get build bar errors that you don't", "tokens": [8950, 264, 376, 25936, 1500, 14205, 16143, 570, 5911, 291, 1062, 483, 1322, 2159, 13603, 300, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.1876298716810883, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2777388292306568e-05}, {"id": 204, "seek": 85080, "start": 872.0799999999999, "end": 876.28, "text": " expect and it just reduces the cycle a little bit there.", "tokens": [2066, 293, 309, 445, 18081, 264, 6586, 257, 707, 857, 456, 13], "temperature": 0.0, "avg_logprob": -0.1876298716810883, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2777388292306568e-05}, {"id": 205, "seek": 85080, "start": 876.28, "end": 880.16, "text": " If it's a new feature, help us write some documentation or at least describe what it", "tokens": [759, 309, 311, 257, 777, 4111, 11, 854, 505, 2464, 512, 14333, 420, 412, 1935, 6786, 437, 309], "temperature": 0.0, "avg_logprob": -0.1876298716810883, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2777388292306568e-05}, {"id": 206, "seek": 88016, "start": 880.16, "end": 887.12, "text": " does in the JIRA tickets so that we can put that into the knowledge base at a later day.", "tokens": [775, 294, 264, 50172, 3750, 12628, 370, 300, 321, 393, 829, 300, 666, 264, 3601, 3096, 412, 257, 1780, 786, 13], "temperature": 0.0, "avg_logprob": -0.20137444320990114, "compression_ratio": 1.6177777777777778, "no_speech_prob": 5.2758929086849093e-05}, {"id": 207, "seek": 88016, "start": 887.12, "end": 889.52, "text": " Next up, pull requests.", "tokens": [3087, 493, 11, 2235, 12475, 13], "temperature": 0.0, "avg_logprob": -0.20137444320990114, "compression_ratio": 1.6177777777777778, "no_speech_prob": 5.2758929086849093e-05}, {"id": 208, "seek": 88016, "start": 889.52, "end": 894.4399999999999, "text": " When you open a pull request, a form will pop up and filling this in will help us triage", "tokens": [1133, 291, 1269, 257, 2235, 5308, 11, 257, 1254, 486, 1665, 493, 293, 10623, 341, 294, 486, 854, 505, 1376, 609], "temperature": 0.0, "avg_logprob": -0.20137444320990114, "compression_ratio": 1.6177777777777778, "no_speech_prob": 5.2758929086849093e-05}, {"id": 209, "seek": 88016, "start": 894.4399999999999, "end": 896.4399999999999, "text": " the pull request essentially.", "tokens": [264, 2235, 5308, 4476, 13], "temperature": 0.0, "avg_logprob": -0.20137444320990114, "compression_ratio": 1.6177777777777778, "no_speech_prob": 5.2758929086849093e-05}, {"id": 210, "seek": 88016, "start": 896.4399999999999, "end": 902.04, "text": " So a lot of your questions about whether this is a bug or a feature, have you added a test,", "tokens": [407, 257, 688, 295, 428, 1651, 466, 1968, 341, 307, 257, 7426, 420, 257, 4111, 11, 362, 291, 3869, 257, 1500, 11], "temperature": 0.0, "avg_logprob": -0.20137444320990114, "compression_ratio": 1.6177777777777778, "no_speech_prob": 5.2758929086849093e-05}, {"id": 211, "seek": 88016, "start": 902.04, "end": 905.4399999999999, "text": " does this break things, stuff like that.", "tokens": [775, 341, 1821, 721, 11, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.20137444320990114, "compression_ratio": 1.6177777777777778, "no_speech_prob": 5.2758929086849093e-05}, {"id": 212, "seek": 90544, "start": 905.44, "end": 910.2800000000001, "text": " If it's your first time doing a pull request, something called the CLA assistant will pop", "tokens": [759, 309, 311, 428, 700, 565, 884, 257, 2235, 5308, 11, 746, 1219, 264, 383, 11435, 10994, 486, 1665], "temperature": 0.0, "avg_logprob": -0.13712860987736628, "compression_ratio": 1.7761732851985559, "no_speech_prob": 1.7228336218977347e-05}, {"id": 213, "seek": 90544, "start": 910.2800000000001, "end": 911.2800000000001, "text": " up.", "tokens": [493, 13], "temperature": 0.0, "avg_logprob": -0.13712860987736628, "compression_ratio": 1.7761732851985559, "no_speech_prob": 1.7228336218977347e-05}, {"id": 214, "seek": 90544, "start": 911.2800000000001, "end": 915.7600000000001, "text": " It's not 100% intuitive right now, it's something we need to improve on, but right now it will", "tokens": [467, 311, 406, 2319, 4, 21769, 558, 586, 11, 309, 311, 746, 321, 643, 281, 3470, 322, 11, 457, 558, 586, 309, 486], "temperature": 0.0, "avg_logprob": -0.13712860987736628, "compression_ratio": 1.7761732851985559, "no_speech_prob": 1.7228336218977347e-05}, {"id": 215, "seek": 90544, "start": 915.7600000000001, "end": 918.12, "text": " pop up and ask you to sign the CLA.", "tokens": [1665, 493, 293, 1029, 291, 281, 1465, 264, 383, 11435, 13], "temperature": 0.0, "avg_logprob": -0.13712860987736628, "compression_ratio": 1.7761732851985559, "no_speech_prob": 1.7228336218977347e-05}, {"id": 216, "seek": 90544, "start": 918.12, "end": 923.0, "text": " You can click through that and either sign the CLA or tick to say, I want to contribute", "tokens": [509, 393, 2052, 807, 300, 293, 2139, 1465, 264, 383, 11435, 420, 5204, 281, 584, 11, 286, 528, 281, 10586], "temperature": 0.0, "avg_logprob": -0.13712860987736628, "compression_ratio": 1.7761732851985559, "no_speech_prob": 1.7228336218977347e-05}, {"id": 217, "seek": 90544, "start": 923.0, "end": 927.36, "text": " under the three clause BSD license or you can just literally put a comment in and say,", "tokens": [833, 264, 1045, 25925, 363, 23969, 10476, 420, 291, 393, 445, 3736, 829, 257, 2871, 294, 293, 584, 11], "temperature": 0.0, "avg_logprob": -0.13712860987736628, "compression_ratio": 1.7761732851985559, "no_speech_prob": 1.7228336218977347e-05}, {"id": 218, "seek": 90544, "start": 927.36, "end": 933.08, "text": " I'm contributing this under the three clause BSD license and then we can take it from there.", "tokens": [286, 478, 19270, 341, 833, 264, 1045, 25925, 363, 23969, 10476, 293, 550, 321, 393, 747, 309, 490, 456, 13], "temperature": 0.0, "avg_logprob": -0.13712860987736628, "compression_ratio": 1.7761732851985559, "no_speech_prob": 1.7228336218977347e-05}, {"id": 219, "seek": 93308, "start": 933.08, "end": 937.6, "text": " What will run on the pull request automatically, lots and lots of different builders.", "tokens": [708, 486, 1190, 322, 264, 2235, 5308, 6772, 11, 3195, 293, 3195, 295, 819, 36281, 13], "temperature": 0.0, "avg_logprob": -0.13578083640650698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 4.106747292098589e-05}, {"id": 220, "seek": 93308, "start": 937.6, "end": 945.6, "text": " The most important ones will report back to GitHub and show you that if anything has failed", "tokens": [440, 881, 1021, 2306, 486, 2275, 646, 281, 23331, 293, 855, 291, 300, 498, 1340, 575, 7612], "temperature": 0.0, "avg_logprob": -0.13578083640650698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 4.106747292098589e-05}, {"id": 221, "seek": 93308, "start": 945.6, "end": 950.4000000000001, "text": " during compiling or testing on lots of different platforms we support.", "tokens": [1830, 715, 4883, 420, 4997, 322, 3195, 295, 819, 9473, 321, 1406, 13], "temperature": 0.0, "avg_logprob": -0.13578083640650698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 4.106747292098589e-05}, {"id": 222, "seek": 93308, "start": 950.4000000000001, "end": 954.76, "text": " When we actually go to review it, we'll actually look at the full build list where there might", "tokens": [1133, 321, 767, 352, 281, 3131, 309, 11, 321, 603, 767, 574, 412, 264, 1577, 1322, 1329, 689, 456, 1062], "temperature": 0.0, "avg_logprob": -0.13578083640650698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 4.106747292098589e-05}, {"id": 223, "seek": 93308, "start": 954.76, "end": 959.44, "text": " be some obscure platforms that might have broken in weird ways, but at least it gives", "tokens": [312, 512, 34443, 9473, 300, 1062, 362, 5463, 294, 3657, 2098, 11, 457, 412, 1935, 309, 2709], "temperature": 0.0, "avg_logprob": -0.13578083640650698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 4.106747292098589e-05}, {"id": 224, "seek": 95944, "start": 959.44, "end": 964.12, "text": " you some idea of what's gone wrong and you can click through and look at the cause.", "tokens": [291, 512, 1558, 295, 437, 311, 2780, 2085, 293, 291, 393, 2052, 807, 293, 574, 412, 264, 3082, 13], "temperature": 0.0, "avg_logprob": -0.20234391628167567, "compression_ratio": 1.6608391608391608, "no_speech_prob": 2.4138707885867916e-05}, {"id": 225, "seek": 95944, "start": 964.12, "end": 968.96, "text": " Again, if you don't understand the error that popped up, we can look at it for you and point", "tokens": [3764, 11, 498, 291, 500, 380, 1223, 264, 6713, 300, 21545, 493, 11, 321, 393, 574, 412, 309, 337, 291, 293, 935], "temperature": 0.0, "avg_logprob": -0.20234391628167567, "compression_ratio": 1.6608391608391608, "no_speech_prob": 2.4138707885867916e-05}, {"id": 226, "seek": 95944, "start": 968.96, "end": 972.08, "text": " you in the right direction.", "tokens": [291, 294, 264, 558, 3513, 13], "temperature": 0.0, "avg_logprob": -0.20234391628167567, "compression_ratio": 1.6608391608391608, "no_speech_prob": 2.4138707885867916e-05}, {"id": 227, "seek": 95944, "start": 972.08, "end": 977.5200000000001, "text": " Code review process, the MariaDB engineers, both at the Foundation and Corporation will", "tokens": [15549, 3131, 1399, 11, 264, 12734, 27735, 11955, 11, 1293, 412, 264, 10335, 293, 26464, 486], "temperature": 0.0, "avg_logprob": -0.20234391628167567, "compression_ratio": 1.6608391608391608, "no_speech_prob": 2.4138707885867916e-05}, {"id": 228, "seek": 95944, "start": 977.5200000000001, "end": 980.24, "text": " review, give feedback, advice.", "tokens": [3131, 11, 976, 5824, 11, 5192, 13], "temperature": 0.0, "avg_logprob": -0.20234391628167567, "compression_ratio": 1.6608391608391608, "no_speech_prob": 2.4138707885867916e-05}, {"id": 229, "seek": 95944, "start": 980.24, "end": 984.5200000000001, "text": " If we think the code is ready, we'll approve it and merge it.", "tokens": [759, 321, 519, 264, 3089, 307, 1919, 11, 321, 603, 18827, 309, 293, 22183, 309, 13], "temperature": 0.0, "avg_logprob": -0.20234391628167567, "compression_ratio": 1.6608391608391608, "no_speech_prob": 2.4138707885867916e-05}, {"id": 230, "seek": 95944, "start": 984.5200000000001, "end": 988.44, "text": " Community members are also welcome to come look at the codes that people have contributed", "tokens": [10421, 2679, 366, 611, 2928, 281, 808, 574, 412, 264, 14211, 300, 561, 362, 18434], "temperature": 0.0, "avg_logprob": -0.20234391628167567, "compression_ratio": 1.6608391608391608, "no_speech_prob": 2.4138707885867916e-05}, {"id": 231, "seek": 98844, "start": 988.44, "end": 993.72, "text": " to it, review it, comment on it, and it's another way you can contribute.", "tokens": [281, 309, 11, 3131, 309, 11, 2871, 322, 309, 11, 293, 309, 311, 1071, 636, 291, 393, 10586, 13], "temperature": 0.0, "avg_logprob": -0.16389985120933476, "compression_ratio": 1.628158844765343, "no_speech_prob": 3.185309105901979e-05}, {"id": 232, "seek": 98844, "start": 993.72, "end": 997.5200000000001, "text": " If we are taking time to get to your pull request and we're dropping the ball or something", "tokens": [759, 321, 366, 1940, 565, 281, 483, 281, 428, 2235, 5308, 293, 321, 434, 13601, 264, 2594, 420, 746], "temperature": 0.0, "avg_logprob": -0.16389985120933476, "compression_ratio": 1.628158844765343, "no_speech_prob": 3.185309105901979e-05}, {"id": 233, "seek": 98844, "start": 997.5200000000001, "end": 1003.32, "text": " like that or you need advice, you can tag me at Linus Jedi on GitHub and I will take", "tokens": [411, 300, 420, 291, 643, 5192, 11, 291, 393, 6162, 385, 412, 9355, 301, 21746, 322, 23331, 293, 286, 486, 747], "temperature": 0.0, "avg_logprob": -0.16389985120933476, "compression_ratio": 1.628158844765343, "no_speech_prob": 3.185309105901979e-05}, {"id": 234, "seek": 98844, "start": 1003.32, "end": 1005.44, "text": " a look at it for you.", "tokens": [257, 574, 412, 309, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.16389985120933476, "compression_ratio": 1.628158844765343, "no_speech_prob": 3.185309105901979e-05}, {"id": 235, "seek": 98844, "start": 1005.44, "end": 1009.5200000000001, "text": " I'm lagging a bit behind on that because I'm at FOSDM right now, but I will try and", "tokens": [286, 478, 8953, 3249, 257, 857, 2261, 322, 300, 570, 286, 478, 412, 479, 4367, 35, 44, 558, 586, 11, 457, 286, 486, 853, 293], "temperature": 0.0, "avg_logprob": -0.16389985120933476, "compression_ratio": 1.628158844765343, "no_speech_prob": 3.185309105901979e-05}, {"id": 236, "seek": 98844, "start": 1009.5200000000001, "end": 1011.44, "text": " keep up with that.", "tokens": [1066, 493, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.16389985120933476, "compression_ratio": 1.628158844765343, "no_speech_prob": 3.185309105901979e-05}, {"id": 237, "seek": 98844, "start": 1011.44, "end": 1016.84, "text": " We have a large backlog right now, so it is very easy for us to miss things.", "tokens": [492, 362, 257, 2416, 47364, 558, 586, 11, 370, 309, 307, 588, 1858, 337, 505, 281, 1713, 721, 13], "temperature": 0.0, "avg_logprob": -0.16389985120933476, "compression_ratio": 1.628158844765343, "no_speech_prob": 3.185309105901979e-05}, {"id": 238, "seek": 101684, "start": 1016.84, "end": 1018.5600000000001, "text": " That is all I have.", "tokens": [663, 307, 439, 286, 362, 13], "temperature": 0.0, "avg_logprob": -0.33961899426518655, "compression_ratio": 2.020304568527919, "no_speech_prob": 0.00016398691514041275}, {"id": 239, "seek": 101684, "start": 1018.5600000000001, "end": 1020.5600000000001, "text": " Any questions from anyone?", "tokens": [2639, 1651, 490, 2878, 30], "temperature": 0.0, "avg_logprob": -0.33961899426518655, "compression_ratio": 2.020304568527919, "no_speech_prob": 0.00016398691514041275}, {"id": 240, "seek": 101684, "start": 1020.5600000000001, "end": 1021.5600000000001, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.33961899426518655, "compression_ratio": 2.020304568527919, "no_speech_prob": 0.00016398691514041275}, {"id": 241, "seek": 101684, "start": 1021.5600000000001, "end": 1027.92, "text": " Is the Foundation and the Corporation have different release cycles or is that?", "tokens": [1119, 264, 10335, 293, 264, 26464, 362, 819, 4374, 17796, 420, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.33961899426518655, "compression_ratio": 2.020304568527919, "no_speech_prob": 0.00016398691514041275}, {"id": 242, "seek": 101684, "start": 1027.92, "end": 1029.92, "text": " It's Foundational Corporation different release cycles.", "tokens": [467, 311, 8207, 1478, 26464, 819, 4374, 17796, 13], "temperature": 0.0, "avg_logprob": -0.33961899426518655, "compression_ratio": 2.020304568527919, "no_speech_prob": 0.00016398691514041275}, {"id": 243, "seek": 101684, "start": 1029.92, "end": 1032.1200000000001, "text": " So no.", "tokens": [407, 572, 13], "temperature": 0.0, "avg_logprob": -0.33961899426518655, "compression_ratio": 2.020304568527919, "no_speech_prob": 0.00016398691514041275}, {"id": 244, "seek": 101684, "start": 1032.1200000000001, "end": 1038.48, "text": " At the moment, the Corporation are generating the releases, so the engineers at the Corporation", "tokens": [1711, 264, 1623, 11, 264, 26464, 366, 17746, 264, 16952, 11, 370, 264, 11955, 412, 264, 26464], "temperature": 0.0, "avg_logprob": -0.33961899426518655, "compression_ratio": 2.020304568527919, "no_speech_prob": 0.00016398691514041275}, {"id": 245, "seek": 101684, "start": 1038.48, "end": 1040.68, "text": " are generating the releases, if you see what I mean.", "tokens": [366, 17746, 264, 16952, 11, 498, 291, 536, 437, 286, 914, 13], "temperature": 0.0, "avg_logprob": -0.33961899426518655, "compression_ratio": 2.020304568527919, "no_speech_prob": 0.00016398691514041275}, {"id": 246, "seek": 101684, "start": 1040.68, "end": 1043.04, "text": " The releases you get are generated by the Corporation.", "tokens": [440, 16952, 291, 483, 366, 10833, 538, 264, 26464, 13], "temperature": 0.0, "avg_logprob": -0.33961899426518655, "compression_ratio": 2.020304568527919, "no_speech_prob": 0.00016398691514041275}, {"id": 247, "seek": 104304, "start": 1043.04, "end": 1050.3999999999999, "text": " Built by the Foundation, yes.", "tokens": [49822, 538, 264, 10335, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.2786755363146464, "compression_ratio": 1.5278969957081545, "no_speech_prob": 4.8335703468183056e-05}, {"id": 248, "seek": 104304, "start": 1050.3999999999999, "end": 1053.36, "text": " There's a lot of synergies between the two, which is a good thing.", "tokens": [821, 311, 257, 688, 295, 33781, 25480, 1296, 264, 732, 11, 597, 307, 257, 665, 551, 13], "temperature": 0.0, "avg_logprob": -0.2786755363146464, "compression_ratio": 1.5278969957081545, "no_speech_prob": 4.8335703468183056e-05}, {"id": 249, "seek": 104304, "start": 1053.36, "end": 1055.84, "text": " We want to be working closely with them, if you see what I mean.", "tokens": [492, 528, 281, 312, 1364, 8185, 365, 552, 11, 498, 291, 536, 437, 286, 914, 13], "temperature": 0.0, "avg_logprob": -0.2786755363146464, "compression_ratio": 1.5278969957081545, "no_speech_prob": 4.8335703468183056e-05}, {"id": 250, "seek": 104304, "start": 1055.84, "end": 1060.1599999999999, "text": " But if anything, God forbid, happened to the Corporation, the Foundation existing means", "tokens": [583, 498, 1340, 11, 1265, 34117, 11, 2011, 281, 264, 26464, 11, 264, 10335, 6741, 1355], "temperature": 0.0, "avg_logprob": -0.2786755363146464, "compression_ratio": 1.5278969957081545, "no_speech_prob": 4.8335703468183056e-05}, {"id": 251, "seek": 104304, "start": 1060.1599999999999, "end": 1067.36, "text": " that MarineDB Server will still exist, will still be developed, et cetera.", "tokens": [300, 20415, 27735, 25684, 486, 920, 2514, 11, 486, 920, 312, 4743, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.2786755363146464, "compression_ratio": 1.5278969957081545, "no_speech_prob": 4.8335703468183056e-05}, {"id": 252, "seek": 104304, "start": 1067.36, "end": 1070.76, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.2786755363146464, "compression_ratio": 1.5278969957081545, "no_speech_prob": 4.8335703468183056e-05}, {"id": 253, "seek": 104304, "start": 1070.76, "end": 1071.76, "text": " Thank you very much.", "tokens": [1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.2786755363146464, "compression_ratio": 1.5278969957081545, "no_speech_prob": 4.8335703468183056e-05}, {"id": 254, "seek": 107176, "start": 1071.76, "end": 1076.76, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50614], "temperature": 0.6000000000000001, "avg_logprob": -0.7970817883809408, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.001024122815579176}], "language": "en"}