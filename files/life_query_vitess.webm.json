{"text": " Hello everyone, let's, all right, thank you. So I'm Harshad Angal, I work for PlanetSkill, and I'm a maintainer of Wittes, and today I'm going to talk about life of a query. Why not? Because I work in query serving team in Wittes. So what is Wittes basically? Wittes is nothing but it's used to scale out your MySQL, and it also manages your MySQL for you. It's a CNCF gadget project, and it is open source with a partial license 2.0. So this is the architecture of Wittes, which is basically, there are so many components, but today we'll just focus on few of them, which is one is VTGate, where your application connects to, and then we have VT Tablet, where once the application connects to VTGate, then the queries are sent over there, and then you have the MySQL, where actually your data are getting stored. Let's talk about few terminologies, which I'll be using across my presentation, which is one is key space. Key space is a logical representation of a database, and it's basically a collection of your physical databases. Shard, it's basically a subset of your data, which resides in a key space. And there's some term called Windex. Windex is similar to your MySQL indexes, which is basically, it's maintained by the Wittes, and there's a thing called primary Windexes, which means it will decide where your row actually live in a particular shard, or in particular table. So once your query comes in, then it decides, okay, this row, while inserting, where it should actually, which shard it should actually go to. So let's take some query, right, then we'll go further. So let's say we have two tables, customer and order table, and what we want to do is we want to find a customer who has at least a spend of 1000 bucks basically in their whole order history. So we have to take two tables, we take a join, and do a grouping on them, and take a filter on top of it. So first thing first. So the client wants to send a query to you, how they will do it. So first, the client has to connect to something called VVol VT gates, and so they can use MySQL protocol. You have all the MySQL drivers, like in different languages you have, and you can use the already available MySQL driver to connect directly to VT gate. VT gate supports the MySQL protocol, so you don't have to do anything on that front. But it also supports GRPC, and it was supported earlier before we implemented the MySQL protocol, but it still stays here for its own benefits. And the reason is like, in MySQL protocol, once you connect, it's like your session is tied, which means if you open a transaction, you have to commit transaction using that. But in GRPC, what the initial benefit you get is you can connect to any VT gate, and you start a transaction over there, and then you can connect to any other VT gate, and you can commit your transaction using that VT gate. So let's talk about the different phases that we have to go through. Once the query is now received by the VT gate, it has to go through parsing, rewriting, planning, and execution. And we'll talk in details about each of the phases, but this is what the VT gate does once it receives the query on its end. So in the parsing phase, now you receive the query. Now basically, it will parse it to know whether the query is tactically correct or not. And once it is tactically correct, then it constructs the abstract syntax tree of it. So here it will have the select expression from clauses, group by, and the having for the query we mentioned before. Now once it's parsed, it goes into the rewriting phase. And it's very important to have this rewriting phase because we are trying to mimic a single data store, though your data is distributed across multiple charts. And this rewriting phase, what we try to do is basically, we first try to see, oh, is there any literals, is there anything which we can parameterize? So once we are done with the planning phase, we don't have to plan again and again similar kind of query. So what we do is we say, okay, here's IC 1000, but I don't need to plan specifically for 1000. So I just make it a parameter, and then I plan for this kind of query rather than planning with the 1000. The other thing we do is we do some replacement functions. So like if you want to get last insert ID, you cannot just send it to any MySQL and get a last insert ID. So we do a session management at the VTGate level where for each session, we have to know what was the last insert ID inserted, so you cannot send directly. So we need a rewriting phase for these kind of functions. There are multiple, but I'm just talking about one of them, which is last insert ID. So you have to do it at the VTGate level. So then you are replacing that with function with a value, and you know what that value is for that session. And the third is you might have to add another SQL node after you construct the AST. So this is like if on the session you said, I cannot select more than 100 rows. So after AST, we have in the rewriting phase, we'll add a limit clause as well. So the planning happens with the limit in place in it. So after rewriting and the AST generation, before we go into the planning, the planner needs some additional information, which is it should know what are the key spaces that exist and what are the shards that the key space map to. And in the key spaces, what are the tables that exist and what are the indexes that you use for those tables. And these information is basically cached in the VTGate, and you have an event watcher which watches. And this information comes from, actually, we have something called Topo Server, which is ZooKeeper at CDSIM, which is where this metadata kind of information is stored. And let's see what the sharding information looks like that we get from that ZooKeeper. So what we call is called vschema. And here it's saying that there's one thing called commerce, and it's sharded. This is the index that exists. And these are the two tables, customer and the order table, which use, and they use the CID column, and they use this index function to shard their table. So now the VTGate knows about everything, that now it can go into the planning phase. And the first thing that it does is does the semantic analysis, which is it does basically scoping, binding, and typing, which is like it's validating, not validated your syntactic thing before, and now it's trying to validate whether you are using the right columns in the right places or not, whether they are actually scoped correctly or not, is the visibility correct or not for those operations, the operations you're using. And then once it validates that, then it goes into the binding phase, where it binds those columns to the table that it belongs to, and then it also does the typing, which means it tries to understand that, okay, once the results come back, we'll know that what type it will be of. The second is once the semantic analysis happens, then your AST is converted into an operator tree, which is basically a logical operator, like you have joints, and then you have tables and stuff, so it convert into those logical operators. And then once those logical operator are converted, it then goes into the optimization phase. So in the optimization phase, we basically make a decision that how the plan should look like, and in the innovators, basically what we do is we get the SQL, and ultimately after the planning phase, we'll get another SQL, because the data does not reside on the VTGit, it resides on the MySQL, and we want to optimize on the way that we should get less and less information back on the VTGit to process your data. So we try to push as much as down to the query to the MySQL so that that can resolve much faster for us than we do it at the VTGit. So in the optimization phase, basically after the optimization completes, we call something like routes, which tell us that, okay, this query will go to which all shards, so that's what the ultimate step becomes, and that's where we call it as a physical operator. And then once we have the physical operators, we transform the plan into an execution plan. And the execution plan is nothing but a collection of engine primitives that we call. So let's look at how the execution plan looks like. So if both the tables which I showed in the V schema were using same sharding function, so that's why we were able to basically make it as a single route, which is telling you that, okay, just go scatter to all the shards and just gather the result at the VTGit level and send it back to the user. But if both the tables, the customer table and the order table were using some different sharding functions, then you cannot merge it like that. Then it says basically, it will look something like that, like you'll have, now, because it gets very complex enough to show everything over here, so I'm just showing that there's a, there'll be two routes that will happen, and then ultimately the join will also happen at the VTGit level, sorting and projecting and the aggregation, and then finally the filtering based on how much customers have spent those thousand bucks. So everything happens on the VTGit. Let's just look at the two routes that I showed on the left. So first one we'll do is basically doing a scatter, and it's trying to do on the order table that, okay, give me for all the customer IDs what is the spend they have done, and then on the right-hand side, we need the customer emails. So for every customer ID, I need to get their email IDs, and because the customer ID was the sharding key, the primary index for that table, we are able to send the second query as a, only to a specific shard, we don't have to do again, go to all the shards. So what all steps happened in the execution? So first thing is, once we get the route, we resolve it using those indexes, and so that it can go to the specific correct shard. Another is then, it basically then we take a decide, okay, now we know which shard we have to go to, then it will also decide, okay, this is a query that we have to send it to something that we call the VT tablets, which basically in the shard we have VT tablets and MySQL, so it's sent to the VT tablet, and then once you receive the result back, you gather the information, but sometimes you also have to do transactions, so if transaction is needed, then the VT gate will also tell VT tablets, go and also open the transaction when you execute the query, and then the session, the transactions will be managed by the VT gate that will know in which shard what is the transaction being opened, so that when you do the commit, it knows which shard it has to send the commit information as well too. And the last thing that execution also handles is basically, if you have a select query and you want to read it on the replicas, then it also does the load balancing for you, so it doesn't overload a single replica. So now the query is being sent to VT tablets, and now the VT job is to basically get the result back to the VT gate. So what are the things that goes in the VT tablet? It's exactly similar thing that goes in the VT tablets as well, but what are different reasons? So first thing is, VT gate has some view of the VT tablet of what this state is, but the first thing that events the query received by the VT tablet, it does this, okay, let me validate whether that's current, am I able to serve this query or not, if any view has changed before, after sending the query and before it reads the VT tablet, so it validates if everything is okay, okay, then let's go and do the parsing. So it will parse the query, and the reason is it has to parse the query is because VT tablet has its checks and balances over here where it tries to put some limitation, like it says that don't overload the MySQL resource, so it will basically add its own limits onto the query so that it doesn't overload your MySQL, that you can configure and do things, and then it goes into the planning phase, and in the planning field, it basically tries to see whether did you have put any query rules, which means like any bad query, if you put like, okay, somebody does select star and without a wear condition and stuff, so it basically says, okay, this query cannot be executed because it's a bad query, so those kind of query rules you can put, and another thing that we check in the planning phase is basically it will say, okay, this is the user that sent this query, but is the user allowed to even access the tables or not? So if it's not allowed, then we throw the error back. After the planning phase, also VT tablet does this, again, and all these are there to just not to load your MySQL, so another thing that it does is query consolidation, which is basically it checks whether any same query is running on the MySQL or not. If it's already running, then it just waits for that query to return the result, and all the threads which are waiting for the same query will get the result and it will return back, so only one query ultimately gets executed on the MySQL and not all the queries get executed with the same exact same query, yes. So once it thinks, okay, nothing can be done, like it has to finally send it to MySQL, then it will use one of the connection from the connection pool to send the query to MySQL, and once the results are written back, it will send it to VTGate, VTGate, if it has to do some operations, it will do it, and finally the client will receive the query. So yeah, so that's what the life of query is, but then there are some custom operations which also affect your query path, and which is like when there's a plan maintenance going, like you're promoting one replica to primary for some reason, and there is basically if you are splitting your data, like you have some N charts and you want to go to two N charts or N plus one charts or such thing like that, so while doing those operations, what VTGate does is it notifies the topo that some operation is going, VTGate understands it, so it doesn't send query to the VTGate tablet, it basically buffers a certain duration, and once everything comes back right, then the queries start going to the VTGate tablet, or it times out and VTGate does the time out from itself rather than sending it down. So yeah, thank you. Questions? So currently we don't do cross-shared transactions, we do it, but in the best effort way, but it's currently on the application to know that they are doing cross-shared transactions, but we allow it, but the application should know that they are going cross-shared. Yes? So join I already showed in how we have the two routes, and then from one we get the result and the other one, this is join. So we have hash joins available, but then it will consume your memory, and otherwise it's like from one you'll get the result and then you send it to the other one, so it's just sequential. Aggregation happens at the VTGate level, he has a sorting layer, so before aggregation we have to sort, yes, that's what it was there in the diagram as well, that after joint there was sort layer, because you have to sort, so we have an in-memory sort, so there are multiple again sort based on what we can do the best, so there's a merge sort also and then you have a complete sort as well, based on what can we do best. And then sorting, then it goes to the aggregation. So that's why we said we try to push as much as with MySQL, so we actually push the sort as well to MySQL if possible for the merge sort, but if you do it in the memory then we still sort it, so it depends whether we can push it down or not, if you are able to push it down we push as much as to the MySQL, yes, thank you, all right I think we have a question, thank you very much, thank you. You", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.32, "text": " Hello everyone, let's, all right, thank you.", "tokens": [2425, 1518, 11, 718, 311, 11, 439, 558, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.34519904310053046, "compression_ratio": 1.430939226519337, "no_speech_prob": 0.49921339750289917}, {"id": 1, "seek": 0, "start": 13.32, "end": 19.240000000000002, "text": " So I'm Harshad Angal, I work for PlanetSkill, and I'm a maintainer of Wittes, and today", "tokens": [407, 286, 478, 48914, 345, 4521, 304, 11, 286, 589, 337, 22146, 50, 34213, 11, 293, 286, 478, 257, 6909, 260, 295, 343, 593, 279, 11, 293, 965], "temperature": 0.0, "avg_logprob": -0.34519904310053046, "compression_ratio": 1.430939226519337, "no_speech_prob": 0.49921339750289917}, {"id": 2, "seek": 0, "start": 19.240000000000002, "end": 21.96, "text": " I'm going to talk about life of a query.", "tokens": [286, 478, 516, 281, 751, 466, 993, 295, 257, 14581, 13], "temperature": 0.0, "avg_logprob": -0.34519904310053046, "compression_ratio": 1.430939226519337, "no_speech_prob": 0.49921339750289917}, {"id": 3, "seek": 0, "start": 21.96, "end": 22.96, "text": " Why not?", "tokens": [1545, 406, 30], "temperature": 0.0, "avg_logprob": -0.34519904310053046, "compression_ratio": 1.430939226519337, "no_speech_prob": 0.49921339750289917}, {"id": 4, "seek": 0, "start": 22.96, "end": 27.04, "text": " Because I work in query serving team in Wittes.", "tokens": [1436, 286, 589, 294, 14581, 8148, 1469, 294, 343, 593, 279, 13], "temperature": 0.0, "avg_logprob": -0.34519904310053046, "compression_ratio": 1.430939226519337, "no_speech_prob": 0.49921339750289917}, {"id": 5, "seek": 0, "start": 27.04, "end": 29.84, "text": " So what is Wittes basically?", "tokens": [407, 437, 307, 343, 593, 279, 1936, 30], "temperature": 0.0, "avg_logprob": -0.34519904310053046, "compression_ratio": 1.430939226519337, "no_speech_prob": 0.49921339750289917}, {"id": 6, "seek": 2984, "start": 29.84, "end": 35.04, "text": " Wittes is nothing but it's used to scale out your MySQL, and it also manages your MySQL", "tokens": [343, 593, 279, 307, 1825, 457, 309, 311, 1143, 281, 4373, 484, 428, 1222, 39934, 11, 293, 309, 611, 22489, 428, 1222, 39934], "temperature": 0.0, "avg_logprob": -0.16110041737556458, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0006765755242668092}, {"id": 7, "seek": 2984, "start": 35.04, "end": 36.28, "text": " for you.", "tokens": [337, 291, 13], "temperature": 0.0, "avg_logprob": -0.16110041737556458, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0006765755242668092}, {"id": 8, "seek": 2984, "start": 36.28, "end": 43.76, "text": " It's a CNCF gadget project, and it is open source with a partial license 2.0.", "tokens": [467, 311, 257, 48714, 37, 38090, 1716, 11, 293, 309, 307, 1269, 4009, 365, 257, 14641, 10476, 568, 13, 15, 13], "temperature": 0.0, "avg_logprob": -0.16110041737556458, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0006765755242668092}, {"id": 9, "seek": 2984, "start": 43.76, "end": 49.2, "text": " So this is the architecture of Wittes, which is basically, there are so many components,", "tokens": [407, 341, 307, 264, 9482, 295, 343, 593, 279, 11, 597, 307, 1936, 11, 456, 366, 370, 867, 6677, 11], "temperature": 0.0, "avg_logprob": -0.16110041737556458, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0006765755242668092}, {"id": 10, "seek": 2984, "start": 49.2, "end": 53.64, "text": " but today we'll just focus on few of them, which is one is VTGate, where your application", "tokens": [457, 965, 321, 603, 445, 1879, 322, 1326, 295, 552, 11, 597, 307, 472, 307, 691, 51, 38, 473, 11, 689, 428, 3861], "temperature": 0.0, "avg_logprob": -0.16110041737556458, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0006765755242668092}, {"id": 11, "seek": 2984, "start": 53.64, "end": 58.92, "text": " connects to, and then we have VT Tablet, where once the application connects to VTGate, then", "tokens": [16967, 281, 11, 293, 550, 321, 362, 691, 51, 14106, 2631, 11, 689, 1564, 264, 3861, 16967, 281, 691, 51, 38, 473, 11, 550], "temperature": 0.0, "avg_logprob": -0.16110041737556458, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0006765755242668092}, {"id": 12, "seek": 5892, "start": 58.92, "end": 62.800000000000004, "text": " the queries are sent over there, and then you have the MySQL, where actually your data", "tokens": [264, 24109, 366, 2279, 670, 456, 11, 293, 550, 291, 362, 264, 1222, 39934, 11, 689, 767, 428, 1412], "temperature": 0.0, "avg_logprob": -0.17651491257750873, "compression_ratio": 1.7587719298245614, "no_speech_prob": 4.661992352339439e-05}, {"id": 13, "seek": 5892, "start": 62.800000000000004, "end": 66.32000000000001, "text": " are getting stored.", "tokens": [366, 1242, 12187, 13], "temperature": 0.0, "avg_logprob": -0.17651491257750873, "compression_ratio": 1.7587719298245614, "no_speech_prob": 4.661992352339439e-05}, {"id": 14, "seek": 5892, "start": 66.32000000000001, "end": 70.64, "text": " Let's talk about few terminologies, which I'll be using across my presentation, which", "tokens": [961, 311, 751, 466, 1326, 10761, 6204, 11, 597, 286, 603, 312, 1228, 2108, 452, 5860, 11, 597], "temperature": 0.0, "avg_logprob": -0.17651491257750873, "compression_ratio": 1.7587719298245614, "no_speech_prob": 4.661992352339439e-05}, {"id": 15, "seek": 5892, "start": 70.64, "end": 72.56, "text": " is one is key space.", "tokens": [307, 472, 307, 2141, 1901, 13], "temperature": 0.0, "avg_logprob": -0.17651491257750873, "compression_ratio": 1.7587719298245614, "no_speech_prob": 4.661992352339439e-05}, {"id": 16, "seek": 5892, "start": 72.56, "end": 77.04, "text": " Key space is a logical representation of a database, and it's basically a collection", "tokens": [12759, 1901, 307, 257, 14978, 10290, 295, 257, 8149, 11, 293, 309, 311, 1936, 257, 5765], "temperature": 0.0, "avg_logprob": -0.17651491257750873, "compression_ratio": 1.7587719298245614, "no_speech_prob": 4.661992352339439e-05}, {"id": 17, "seek": 5892, "start": 77.04, "end": 79.0, "text": " of your physical databases.", "tokens": [295, 428, 4001, 22380, 13], "temperature": 0.0, "avg_logprob": -0.17651491257750873, "compression_ratio": 1.7587719298245614, "no_speech_prob": 4.661992352339439e-05}, {"id": 18, "seek": 5892, "start": 79.0, "end": 87.2, "text": " Shard, it's basically a subset of your data, which resides in a key space.", "tokens": [1160, 515, 11, 309, 311, 1936, 257, 25993, 295, 428, 1412, 11, 597, 47157, 294, 257, 2141, 1901, 13], "temperature": 0.0, "avg_logprob": -0.17651491257750873, "compression_ratio": 1.7587719298245614, "no_speech_prob": 4.661992352339439e-05}, {"id": 19, "seek": 8720, "start": 87.2, "end": 89.76, "text": " And there's some term called Windex.", "tokens": [400, 456, 311, 512, 1433, 1219, 6320, 3121, 13], "temperature": 0.0, "avg_logprob": -0.186690126146589, "compression_ratio": 1.7679324894514767, "no_speech_prob": 9.89330728771165e-05}, {"id": 20, "seek": 8720, "start": 89.76, "end": 96.96000000000001, "text": " Windex is similar to your MySQL indexes, which is basically, it's maintained by the Wittes,", "tokens": [6320, 3121, 307, 2531, 281, 428, 1222, 39934, 8186, 279, 11, 597, 307, 1936, 11, 309, 311, 17578, 538, 264, 343, 593, 279, 11], "temperature": 0.0, "avg_logprob": -0.186690126146589, "compression_ratio": 1.7679324894514767, "no_speech_prob": 9.89330728771165e-05}, {"id": 21, "seek": 8720, "start": 96.96000000000001, "end": 101.44, "text": " and there's a thing called primary Windexes, which means it will decide where your row", "tokens": [293, 456, 311, 257, 551, 1219, 6194, 6320, 3121, 279, 11, 597, 1355, 309, 486, 4536, 689, 428, 5386], "temperature": 0.0, "avg_logprob": -0.186690126146589, "compression_ratio": 1.7679324894514767, "no_speech_prob": 9.89330728771165e-05}, {"id": 22, "seek": 8720, "start": 101.44, "end": 106.04, "text": " actually live in a particular shard, or in particular table.", "tokens": [767, 1621, 294, 257, 1729, 402, 515, 11, 420, 294, 1729, 3199, 13], "temperature": 0.0, "avg_logprob": -0.186690126146589, "compression_ratio": 1.7679324894514767, "no_speech_prob": 9.89330728771165e-05}, {"id": 23, "seek": 8720, "start": 106.04, "end": 110.56, "text": " So once your query comes in, then it decides, okay, this row, while inserting, where it", "tokens": [407, 1564, 428, 14581, 1487, 294, 11, 550, 309, 14898, 11, 1392, 11, 341, 5386, 11, 1339, 46567, 11, 689, 309], "temperature": 0.0, "avg_logprob": -0.186690126146589, "compression_ratio": 1.7679324894514767, "no_speech_prob": 9.89330728771165e-05}, {"id": 24, "seek": 8720, "start": 110.56, "end": 116.60000000000001, "text": " should actually, which shard it should actually go to.", "tokens": [820, 767, 11, 597, 402, 515, 309, 820, 767, 352, 281, 13], "temperature": 0.0, "avg_logprob": -0.186690126146589, "compression_ratio": 1.7679324894514767, "no_speech_prob": 9.89330728771165e-05}, {"id": 25, "seek": 11660, "start": 116.6, "end": 120.67999999999999, "text": " So let's take some query, right, then we'll go further.", "tokens": [407, 718, 311, 747, 512, 14581, 11, 558, 11, 550, 321, 603, 352, 3052, 13], "temperature": 0.0, "avg_logprob": -0.1788278685675727, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00012703391257673502}, {"id": 26, "seek": 11660, "start": 120.67999999999999, "end": 126.0, "text": " So let's say we have two tables, customer and order table, and what we want to do is", "tokens": [407, 718, 311, 584, 321, 362, 732, 8020, 11, 5474, 293, 1668, 3199, 11, 293, 437, 321, 528, 281, 360, 307], "temperature": 0.0, "avg_logprob": -0.1788278685675727, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00012703391257673502}, {"id": 27, "seek": 11660, "start": 126.0, "end": 134.68, "text": " we want to find a customer who has at least a spend of 1000 bucks basically in their whole", "tokens": [321, 528, 281, 915, 257, 5474, 567, 575, 412, 1935, 257, 3496, 295, 9714, 11829, 1936, 294, 641, 1379], "temperature": 0.0, "avg_logprob": -0.1788278685675727, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00012703391257673502}, {"id": 28, "seek": 11660, "start": 134.68, "end": 135.68, "text": " order history.", "tokens": [1668, 2503, 13], "temperature": 0.0, "avg_logprob": -0.1788278685675727, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00012703391257673502}, {"id": 29, "seek": 11660, "start": 135.68, "end": 140.28, "text": " So we have to take two tables, we take a join, and do a grouping on them, and take a filter", "tokens": [407, 321, 362, 281, 747, 732, 8020, 11, 321, 747, 257, 3917, 11, 293, 360, 257, 40149, 322, 552, 11, 293, 747, 257, 6608], "temperature": 0.0, "avg_logprob": -0.1788278685675727, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00012703391257673502}, {"id": 30, "seek": 11660, "start": 140.28, "end": 143.95999999999998, "text": " on top of it.", "tokens": [322, 1192, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.1788278685675727, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00012703391257673502}, {"id": 31, "seek": 11660, "start": 143.95999999999998, "end": 144.95999999999998, "text": " So first thing first.", "tokens": [407, 700, 551, 700, 13], "temperature": 0.0, "avg_logprob": -0.1788278685675727, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.00012703391257673502}, {"id": 32, "seek": 14496, "start": 144.96, "end": 148.92000000000002, "text": " So the client wants to send a query to you, how they will do it.", "tokens": [407, 264, 6423, 2738, 281, 2845, 257, 14581, 281, 291, 11, 577, 436, 486, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.21645769051143102, "compression_ratio": 1.7478632478632479, "no_speech_prob": 0.0003780858824029565}, {"id": 33, "seek": 14496, "start": 148.92000000000002, "end": 154.76000000000002, "text": " So first, the client has to connect to something called VVol VT gates, and so they can use", "tokens": [407, 700, 11, 264, 6423, 575, 281, 1745, 281, 746, 1219, 691, 53, 401, 691, 51, 19792, 11, 293, 370, 436, 393, 764], "temperature": 0.0, "avg_logprob": -0.21645769051143102, "compression_ratio": 1.7478632478632479, "no_speech_prob": 0.0003780858824029565}, {"id": 34, "seek": 14496, "start": 154.76000000000002, "end": 155.76000000000002, "text": " MySQL protocol.", "tokens": [1222, 39934, 10336, 13], "temperature": 0.0, "avg_logprob": -0.21645769051143102, "compression_ratio": 1.7478632478632479, "no_speech_prob": 0.0003780858824029565}, {"id": 35, "seek": 14496, "start": 155.76000000000002, "end": 164.72, "text": " You have all the MySQL drivers, like in different languages you have, and you can use the already", "tokens": [509, 362, 439, 264, 1222, 39934, 11590, 11, 411, 294, 819, 8650, 291, 362, 11, 293, 291, 393, 764, 264, 1217], "temperature": 0.0, "avg_logprob": -0.21645769051143102, "compression_ratio": 1.7478632478632479, "no_speech_prob": 0.0003780858824029565}, {"id": 36, "seek": 14496, "start": 164.72, "end": 167.64000000000001, "text": " available MySQL driver to connect directly to VT gate.", "tokens": [2435, 1222, 39934, 6787, 281, 1745, 3838, 281, 691, 51, 8539, 13], "temperature": 0.0, "avg_logprob": -0.21645769051143102, "compression_ratio": 1.7478632478632479, "no_speech_prob": 0.0003780858824029565}, {"id": 37, "seek": 14496, "start": 167.64000000000001, "end": 171.96, "text": " VT gate supports the MySQL protocol, so you don't have to do anything on that front.", "tokens": [691, 51, 8539, 9346, 264, 1222, 39934, 10336, 11, 370, 291, 500, 380, 362, 281, 360, 1340, 322, 300, 1868, 13], "temperature": 0.0, "avg_logprob": -0.21645769051143102, "compression_ratio": 1.7478632478632479, "no_speech_prob": 0.0003780858824029565}, {"id": 38, "seek": 17196, "start": 171.96, "end": 179.88, "text": " But it also supports GRPC, and it was supported earlier before we implemented the MySQL protocol,", "tokens": [583, 309, 611, 9346, 10903, 12986, 11, 293, 309, 390, 8104, 3071, 949, 321, 12270, 264, 1222, 39934, 10336, 11], "temperature": 0.0, "avg_logprob": -0.1260389175415039, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00011533937504282221}, {"id": 39, "seek": 17196, "start": 179.88, "end": 183.96, "text": " but it still stays here for its own benefits.", "tokens": [457, 309, 920, 10834, 510, 337, 1080, 1065, 5311, 13], "temperature": 0.0, "avg_logprob": -0.1260389175415039, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00011533937504282221}, {"id": 40, "seek": 17196, "start": 183.96, "end": 188.92000000000002, "text": " And the reason is like, in MySQL protocol, once you connect, it's like your session is", "tokens": [400, 264, 1778, 307, 411, 11, 294, 1222, 39934, 10336, 11, 1564, 291, 1745, 11, 309, 311, 411, 428, 5481, 307], "temperature": 0.0, "avg_logprob": -0.1260389175415039, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00011533937504282221}, {"id": 41, "seek": 17196, "start": 188.92000000000002, "end": 193.48000000000002, "text": " tied, which means if you open a transaction, you have to commit transaction using that.", "tokens": [9601, 11, 597, 1355, 498, 291, 1269, 257, 14425, 11, 291, 362, 281, 5599, 14425, 1228, 300, 13], "temperature": 0.0, "avg_logprob": -0.1260389175415039, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00011533937504282221}, {"id": 42, "seek": 17196, "start": 193.48000000000002, "end": 198.56, "text": " But in GRPC, what the initial benefit you get is you can connect to any VT gate, and", "tokens": [583, 294, 10903, 12986, 11, 437, 264, 5883, 5121, 291, 483, 307, 291, 393, 1745, 281, 604, 691, 51, 8539, 11, 293], "temperature": 0.0, "avg_logprob": -0.1260389175415039, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00011533937504282221}, {"id": 43, "seek": 17196, "start": 198.56, "end": 201.48000000000002, "text": " you start a transaction over there, and then you can connect to any other VT gate, and", "tokens": [291, 722, 257, 14425, 670, 456, 11, 293, 550, 291, 393, 1745, 281, 604, 661, 691, 51, 8539, 11, 293], "temperature": 0.0, "avg_logprob": -0.1260389175415039, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00011533937504282221}, {"id": 44, "seek": 20148, "start": 201.48, "end": 206.56, "text": " you can commit your transaction using that VT gate.", "tokens": [291, 393, 5599, 428, 14425, 1228, 300, 691, 51, 8539, 13], "temperature": 0.0, "avg_logprob": -0.14177891216446867, "compression_ratio": 1.7446808510638299, "no_speech_prob": 8.38745545479469e-05}, {"id": 45, "seek": 20148, "start": 206.56, "end": 210.23999999999998, "text": " So let's talk about the different phases that we have to go through.", "tokens": [407, 718, 311, 751, 466, 264, 819, 18764, 300, 321, 362, 281, 352, 807, 13], "temperature": 0.0, "avg_logprob": -0.14177891216446867, "compression_ratio": 1.7446808510638299, "no_speech_prob": 8.38745545479469e-05}, {"id": 46, "seek": 20148, "start": 210.23999999999998, "end": 215.32, "text": " Once the query is now received by the VT gate, it has to go through parsing, rewriting, planning,", "tokens": [3443, 264, 14581, 307, 586, 4613, 538, 264, 691, 51, 8539, 11, 309, 575, 281, 352, 807, 21156, 278, 11, 319, 19868, 11, 5038, 11], "temperature": 0.0, "avg_logprob": -0.14177891216446867, "compression_ratio": 1.7446808510638299, "no_speech_prob": 8.38745545479469e-05}, {"id": 47, "seek": 20148, "start": 215.32, "end": 216.39999999999998, "text": " and execution.", "tokens": [293, 15058, 13], "temperature": 0.0, "avg_logprob": -0.14177891216446867, "compression_ratio": 1.7446808510638299, "no_speech_prob": 8.38745545479469e-05}, {"id": 48, "seek": 20148, "start": 216.39999999999998, "end": 220.51999999999998, "text": " And we'll talk in details about each of the phases, but this is what the VT gate does", "tokens": [400, 321, 603, 751, 294, 4365, 466, 1184, 295, 264, 18764, 11, 457, 341, 307, 437, 264, 691, 51, 8539, 775], "temperature": 0.0, "avg_logprob": -0.14177891216446867, "compression_ratio": 1.7446808510638299, "no_speech_prob": 8.38745545479469e-05}, {"id": 49, "seek": 20148, "start": 220.51999999999998, "end": 224.07999999999998, "text": " once it receives the query on its end.", "tokens": [1564, 309, 20717, 264, 14581, 322, 1080, 917, 13], "temperature": 0.0, "avg_logprob": -0.14177891216446867, "compression_ratio": 1.7446808510638299, "no_speech_prob": 8.38745545479469e-05}, {"id": 50, "seek": 20148, "start": 224.07999999999998, "end": 228.23999999999998, "text": " So in the parsing phase, now you receive the query.", "tokens": [407, 294, 264, 21156, 278, 5574, 11, 586, 291, 4774, 264, 14581, 13], "temperature": 0.0, "avg_logprob": -0.14177891216446867, "compression_ratio": 1.7446808510638299, "no_speech_prob": 8.38745545479469e-05}, {"id": 51, "seek": 22824, "start": 228.24, "end": 233.08, "text": " Now basically, it will parse it to know whether the query is tactically correct or not.", "tokens": [823, 1936, 11, 309, 486, 48377, 309, 281, 458, 1968, 264, 14581, 307, 9959, 984, 3006, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.22969181754372336, "compression_ratio": 1.749003984063745, "no_speech_prob": 9.682441304903477e-05}, {"id": 52, "seek": 22824, "start": 233.08, "end": 237.56, "text": " And once it is tactically correct, then it constructs the abstract syntax tree of it.", "tokens": [400, 1564, 309, 307, 9959, 984, 3006, 11, 550, 309, 7690, 82, 264, 12649, 28431, 4230, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.22969181754372336, "compression_ratio": 1.749003984063745, "no_speech_prob": 9.682441304903477e-05}, {"id": 53, "seek": 22824, "start": 237.56, "end": 241.36, "text": " So here it will have the select expression from clauses, group by, and the having for", "tokens": [407, 510, 309, 486, 362, 264, 3048, 6114, 490, 49072, 11, 1594, 538, 11, 293, 264, 1419, 337], "temperature": 0.0, "avg_logprob": -0.22969181754372336, "compression_ratio": 1.749003984063745, "no_speech_prob": 9.682441304903477e-05}, {"id": 54, "seek": 22824, "start": 241.36, "end": 245.48000000000002, "text": " the query we mentioned before.", "tokens": [264, 14581, 321, 2835, 949, 13], "temperature": 0.0, "avg_logprob": -0.22969181754372336, "compression_ratio": 1.749003984063745, "no_speech_prob": 9.682441304903477e-05}, {"id": 55, "seek": 22824, "start": 245.48000000000002, "end": 249.16000000000003, "text": " Now once it's parsed, it goes into the rewriting phase.", "tokens": [823, 1564, 309, 311, 21156, 292, 11, 309, 1709, 666, 264, 319, 19868, 5574, 13], "temperature": 0.0, "avg_logprob": -0.22969181754372336, "compression_ratio": 1.749003984063745, "no_speech_prob": 9.682441304903477e-05}, {"id": 56, "seek": 22824, "start": 249.16000000000003, "end": 255.28, "text": " And it's very important to have this rewriting phase because we are trying to mimic a single", "tokens": [400, 309, 311, 588, 1021, 281, 362, 341, 319, 19868, 5574, 570, 321, 366, 1382, 281, 31075, 257, 2167], "temperature": 0.0, "avg_logprob": -0.22969181754372336, "compression_ratio": 1.749003984063745, "no_speech_prob": 9.682441304903477e-05}, {"id": 57, "seek": 25528, "start": 255.28, "end": 259.64, "text": " data store, though your data is distributed across multiple charts.", "tokens": [1412, 3531, 11, 1673, 428, 1412, 307, 12631, 2108, 3866, 17767, 13], "temperature": 0.0, "avg_logprob": -0.18761761519160583, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.00019056140445172787}, {"id": 58, "seek": 25528, "start": 259.64, "end": 264.52, "text": " And this rewriting phase, what we try to do is basically, we first try to see, oh, is", "tokens": [400, 341, 319, 19868, 5574, 11, 437, 321, 853, 281, 360, 307, 1936, 11, 321, 700, 853, 281, 536, 11, 1954, 11, 307], "temperature": 0.0, "avg_logprob": -0.18761761519160583, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.00019056140445172787}, {"id": 59, "seek": 25528, "start": 264.52, "end": 268.12, "text": " there any literals, is there anything which we can parameterize?", "tokens": [456, 604, 2733, 1124, 11, 307, 456, 1340, 597, 321, 393, 13075, 1125, 30], "temperature": 0.0, "avg_logprob": -0.18761761519160583, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.00019056140445172787}, {"id": 60, "seek": 25528, "start": 268.12, "end": 272.88, "text": " So once we are done with the planning phase, we don't have to plan again and again similar", "tokens": [407, 1564, 321, 366, 1096, 365, 264, 5038, 5574, 11, 321, 500, 380, 362, 281, 1393, 797, 293, 797, 2531], "temperature": 0.0, "avg_logprob": -0.18761761519160583, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.00019056140445172787}, {"id": 61, "seek": 25528, "start": 272.88, "end": 274.32, "text": " kind of query.", "tokens": [733, 295, 14581, 13], "temperature": 0.0, "avg_logprob": -0.18761761519160583, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.00019056140445172787}, {"id": 62, "seek": 25528, "start": 274.32, "end": 279.24, "text": " So what we do is we say, okay, here's IC 1000, but I don't need to plan specifically", "tokens": [407, 437, 321, 360, 307, 321, 584, 11, 1392, 11, 510, 311, 14360, 9714, 11, 457, 286, 500, 380, 643, 281, 1393, 4682], "temperature": 0.0, "avg_logprob": -0.18761761519160583, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.00019056140445172787}, {"id": 63, "seek": 25528, "start": 279.24, "end": 280.24, "text": " for 1000.", "tokens": [337, 9714, 13], "temperature": 0.0, "avg_logprob": -0.18761761519160583, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.00019056140445172787}, {"id": 64, "seek": 25528, "start": 280.24, "end": 285.0, "text": " So I just make it a parameter, and then I plan for this kind of query rather than planning", "tokens": [407, 286, 445, 652, 309, 257, 13075, 11, 293, 550, 286, 1393, 337, 341, 733, 295, 14581, 2831, 813, 5038], "temperature": 0.0, "avg_logprob": -0.18761761519160583, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.00019056140445172787}, {"id": 65, "seek": 28500, "start": 285.0, "end": 288.96, "text": " with the 1000.", "tokens": [365, 264, 9714, 13], "temperature": 0.0, "avg_logprob": -0.17555360060471756, "compression_ratio": 1.7545787545787546, "no_speech_prob": 8.054891077335924e-05}, {"id": 66, "seek": 28500, "start": 288.96, "end": 292.84, "text": " The other thing we do is we do some replacement functions.", "tokens": [440, 661, 551, 321, 360, 307, 321, 360, 512, 14419, 6828, 13], "temperature": 0.0, "avg_logprob": -0.17555360060471756, "compression_ratio": 1.7545787545787546, "no_speech_prob": 8.054891077335924e-05}, {"id": 67, "seek": 28500, "start": 292.84, "end": 297.48, "text": " So like if you want to get last insert ID, you cannot just send it to any MySQL and get", "tokens": [407, 411, 498, 291, 528, 281, 483, 1036, 8969, 7348, 11, 291, 2644, 445, 2845, 309, 281, 604, 1222, 39934, 293, 483], "temperature": 0.0, "avg_logprob": -0.17555360060471756, "compression_ratio": 1.7545787545787546, "no_speech_prob": 8.054891077335924e-05}, {"id": 68, "seek": 28500, "start": 297.48, "end": 298.72, "text": " a last insert ID.", "tokens": [257, 1036, 8969, 7348, 13], "temperature": 0.0, "avg_logprob": -0.17555360060471756, "compression_ratio": 1.7545787545787546, "no_speech_prob": 8.054891077335924e-05}, {"id": 69, "seek": 28500, "start": 298.72, "end": 304.44, "text": " So we do a session management at the VTGate level where for each session, we have to know", "tokens": [407, 321, 360, 257, 5481, 4592, 412, 264, 691, 51, 38, 473, 1496, 689, 337, 1184, 5481, 11, 321, 362, 281, 458], "temperature": 0.0, "avg_logprob": -0.17555360060471756, "compression_ratio": 1.7545787545787546, "no_speech_prob": 8.054891077335924e-05}, {"id": 70, "seek": 28500, "start": 304.44, "end": 307.64, "text": " what was the last insert ID inserted, so you cannot send directly.", "tokens": [437, 390, 264, 1036, 8969, 7348, 27992, 11, 370, 291, 2644, 2845, 3838, 13], "temperature": 0.0, "avg_logprob": -0.17555360060471756, "compression_ratio": 1.7545787545787546, "no_speech_prob": 8.054891077335924e-05}, {"id": 71, "seek": 28500, "start": 307.64, "end": 310.84, "text": " So we need a rewriting phase for these kind of functions.", "tokens": [407, 321, 643, 257, 319, 19868, 5574, 337, 613, 733, 295, 6828, 13], "temperature": 0.0, "avg_logprob": -0.17555360060471756, "compression_ratio": 1.7545787545787546, "no_speech_prob": 8.054891077335924e-05}, {"id": 72, "seek": 28500, "start": 310.84, "end": 314.08, "text": " There are multiple, but I'm just talking about one of them, which is last insert ID.", "tokens": [821, 366, 3866, 11, 457, 286, 478, 445, 1417, 466, 472, 295, 552, 11, 597, 307, 1036, 8969, 7348, 13], "temperature": 0.0, "avg_logprob": -0.17555360060471756, "compression_ratio": 1.7545787545787546, "no_speech_prob": 8.054891077335924e-05}, {"id": 73, "seek": 31408, "start": 314.08, "end": 316.88, "text": " So you have to do it at the VTGate level.", "tokens": [407, 291, 362, 281, 360, 309, 412, 264, 691, 51, 38, 473, 1496, 13], "temperature": 0.0, "avg_logprob": -0.19193364048863318, "compression_ratio": 1.625514403292181, "no_speech_prob": 8.983002771856263e-05}, {"id": 74, "seek": 31408, "start": 316.88, "end": 322.08, "text": " So then you are replacing that with function with a value, and you know what that value", "tokens": [407, 550, 291, 366, 19139, 300, 365, 2445, 365, 257, 2158, 11, 293, 291, 458, 437, 300, 2158], "temperature": 0.0, "avg_logprob": -0.19193364048863318, "compression_ratio": 1.625514403292181, "no_speech_prob": 8.983002771856263e-05}, {"id": 75, "seek": 31408, "start": 322.08, "end": 324.91999999999996, "text": " is for that session.", "tokens": [307, 337, 300, 5481, 13], "temperature": 0.0, "avg_logprob": -0.19193364048863318, "compression_ratio": 1.625514403292181, "no_speech_prob": 8.983002771856263e-05}, {"id": 76, "seek": 31408, "start": 324.91999999999996, "end": 330.96, "text": " And the third is you might have to add another SQL node after you construct the AST.", "tokens": [400, 264, 2636, 307, 291, 1062, 362, 281, 909, 1071, 19200, 9984, 934, 291, 7690, 264, 316, 6840, 13], "temperature": 0.0, "avg_logprob": -0.19193364048863318, "compression_ratio": 1.625514403292181, "no_speech_prob": 8.983002771856263e-05}, {"id": 77, "seek": 31408, "start": 330.96, "end": 336.15999999999997, "text": " So this is like if on the session you said, I cannot select more than 100 rows.", "tokens": [407, 341, 307, 411, 498, 322, 264, 5481, 291, 848, 11, 286, 2644, 3048, 544, 813, 2319, 13241, 13], "temperature": 0.0, "avg_logprob": -0.19193364048863318, "compression_ratio": 1.625514403292181, "no_speech_prob": 8.983002771856263e-05}, {"id": 78, "seek": 31408, "start": 336.15999999999997, "end": 341.08, "text": " So after AST, we have in the rewriting phase, we'll add a limit clause as well.", "tokens": [407, 934, 316, 6840, 11, 321, 362, 294, 264, 319, 19868, 5574, 11, 321, 603, 909, 257, 4948, 25925, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19193364048863318, "compression_ratio": 1.625514403292181, "no_speech_prob": 8.983002771856263e-05}, {"id": 79, "seek": 34108, "start": 341.08, "end": 347.15999999999997, "text": " So the planning happens with the limit in place in it.", "tokens": [407, 264, 5038, 2314, 365, 264, 4948, 294, 1081, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.14046257798389722, "compression_ratio": 1.9378238341968912, "no_speech_prob": 3.16371260851156e-05}, {"id": 80, "seek": 34108, "start": 347.15999999999997, "end": 353.03999999999996, "text": " So after rewriting and the AST generation, before we go into the planning, the planner", "tokens": [407, 934, 319, 19868, 293, 264, 316, 6840, 5125, 11, 949, 321, 352, 666, 264, 5038, 11, 264, 31268], "temperature": 0.0, "avg_logprob": -0.14046257798389722, "compression_ratio": 1.9378238341968912, "no_speech_prob": 3.16371260851156e-05}, {"id": 81, "seek": 34108, "start": 353.03999999999996, "end": 357.03999999999996, "text": " needs some additional information, which is it should know what are the key spaces that", "tokens": [2203, 512, 4497, 1589, 11, 597, 307, 309, 820, 458, 437, 366, 264, 2141, 7673, 300], "temperature": 0.0, "avg_logprob": -0.14046257798389722, "compression_ratio": 1.9378238341968912, "no_speech_prob": 3.16371260851156e-05}, {"id": 82, "seek": 34108, "start": 357.03999999999996, "end": 362.2, "text": " exist and what are the shards that the key space map to.", "tokens": [2514, 293, 437, 366, 264, 402, 2287, 300, 264, 2141, 1901, 4471, 281, 13], "temperature": 0.0, "avg_logprob": -0.14046257798389722, "compression_ratio": 1.9378238341968912, "no_speech_prob": 3.16371260851156e-05}, {"id": 83, "seek": 34108, "start": 362.2, "end": 370.15999999999997, "text": " And in the key spaces, what are the tables that exist and what are the indexes that you", "tokens": [400, 294, 264, 2141, 7673, 11, 437, 366, 264, 8020, 300, 2514, 293, 437, 366, 264, 8186, 279, 300, 291], "temperature": 0.0, "avg_logprob": -0.14046257798389722, "compression_ratio": 1.9378238341968912, "no_speech_prob": 3.16371260851156e-05}, {"id": 84, "seek": 37016, "start": 370.16, "end": 372.84000000000003, "text": " use for those tables.", "tokens": [764, 337, 729, 8020, 13], "temperature": 0.0, "avg_logprob": -0.19928054471986484, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00016567419515922666}, {"id": 85, "seek": 37016, "start": 372.84000000000003, "end": 378.36, "text": " And these information is basically cached in the VTGate, and you have an event watcher", "tokens": [400, 613, 1589, 307, 1936, 269, 15095, 294, 264, 691, 51, 38, 473, 11, 293, 291, 362, 364, 2280, 1159, 260], "temperature": 0.0, "avg_logprob": -0.19928054471986484, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00016567419515922666}, {"id": 86, "seek": 37016, "start": 378.36, "end": 379.36, "text": " which watches.", "tokens": [597, 17062, 13], "temperature": 0.0, "avg_logprob": -0.19928054471986484, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00016567419515922666}, {"id": 87, "seek": 37016, "start": 379.36, "end": 382.40000000000003, "text": " And this information comes from, actually, we have something called Topo Server, which", "tokens": [400, 341, 1589, 1487, 490, 11, 767, 11, 321, 362, 746, 1219, 8840, 78, 25684, 11, 597], "temperature": 0.0, "avg_logprob": -0.19928054471986484, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00016567419515922666}, {"id": 88, "seek": 37016, "start": 382.40000000000003, "end": 388.8, "text": " is ZooKeeper at CDSIM, which is where this metadata kind of information is stored.", "tokens": [307, 34589, 41856, 260, 412, 6743, 50, 6324, 11, 597, 307, 689, 341, 26603, 733, 295, 1589, 307, 12187, 13], "temperature": 0.0, "avg_logprob": -0.19928054471986484, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00016567419515922666}, {"id": 89, "seek": 37016, "start": 388.8, "end": 393.88, "text": " And let's see what the sharding information looks like that we get from that ZooKeeper.", "tokens": [400, 718, 311, 536, 437, 264, 402, 515, 278, 1589, 1542, 411, 300, 321, 483, 490, 300, 34589, 41856, 260, 13], "temperature": 0.0, "avg_logprob": -0.19928054471986484, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00016567419515922666}, {"id": 90, "seek": 37016, "start": 393.88, "end": 396.36, "text": " So what we call is called vschema.", "tokens": [407, 437, 321, 818, 307, 1219, 371, 6145, 5619, 13], "temperature": 0.0, "avg_logprob": -0.19928054471986484, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00016567419515922666}, {"id": 91, "seek": 39636, "start": 396.36, "end": 401.36, "text": " And here it's saying that there's one thing called commerce, and it's sharded.", "tokens": [400, 510, 309, 311, 1566, 300, 456, 311, 472, 551, 1219, 26320, 11, 293, 309, 311, 402, 22803, 13], "temperature": 0.0, "avg_logprob": -0.15523568203574734, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.00013917480828240514}, {"id": 92, "seek": 39636, "start": 401.36, "end": 403.32, "text": " This is the index that exists.", "tokens": [639, 307, 264, 8186, 300, 8198, 13], "temperature": 0.0, "avg_logprob": -0.15523568203574734, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.00013917480828240514}, {"id": 93, "seek": 39636, "start": 403.32, "end": 407.96000000000004, "text": " And these are the two tables, customer and the order table, which use, and they use", "tokens": [400, 613, 366, 264, 732, 8020, 11, 5474, 293, 264, 1668, 3199, 11, 597, 764, 11, 293, 436, 764], "temperature": 0.0, "avg_logprob": -0.15523568203574734, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.00013917480828240514}, {"id": 94, "seek": 39636, "start": 407.96000000000004, "end": 419.12, "text": " the CID column, and they use this index function to shard their table.", "tokens": [264, 383, 2777, 7738, 11, 293, 436, 764, 341, 8186, 2445, 281, 402, 515, 641, 3199, 13], "temperature": 0.0, "avg_logprob": -0.15523568203574734, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.00013917480828240514}, {"id": 95, "seek": 39636, "start": 419.12, "end": 424.72, "text": " So now the VTGate knows about everything, that now it can go into the planning phase.", "tokens": [407, 586, 264, 691, 51, 38, 473, 3255, 466, 1203, 11, 300, 586, 309, 393, 352, 666, 264, 5038, 5574, 13], "temperature": 0.0, "avg_logprob": -0.15523568203574734, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.00013917480828240514}, {"id": 96, "seek": 42472, "start": 424.72, "end": 432.20000000000005, "text": " And the first thing that it does is does the semantic analysis, which is it does basically", "tokens": [400, 264, 700, 551, 300, 309, 775, 307, 775, 264, 47982, 5215, 11, 597, 307, 309, 775, 1936], "temperature": 0.0, "avg_logprob": -0.15170030671406567, "compression_ratio": 1.9771863117870723, "no_speech_prob": 0.0002941384445875883}, {"id": 97, "seek": 42472, "start": 432.20000000000005, "end": 437.48, "text": " scoping, binding, and typing, which is like it's validating, not validated your syntactic", "tokens": [795, 26125, 11, 17359, 11, 293, 18444, 11, 597, 307, 411, 309, 311, 7363, 990, 11, 406, 40693, 428, 23980, 19892], "temperature": 0.0, "avg_logprob": -0.15170030671406567, "compression_ratio": 1.9771863117870723, "no_speech_prob": 0.0002941384445875883}, {"id": 98, "seek": 42472, "start": 437.48, "end": 441.32000000000005, "text": " thing before, and now it's trying to validate whether you are using the right columns in", "tokens": [551, 949, 11, 293, 586, 309, 311, 1382, 281, 29562, 1968, 291, 366, 1228, 264, 558, 13766, 294], "temperature": 0.0, "avg_logprob": -0.15170030671406567, "compression_ratio": 1.9771863117870723, "no_speech_prob": 0.0002941384445875883}, {"id": 99, "seek": 42472, "start": 441.32000000000005, "end": 445.52000000000004, "text": " the right places or not, whether they are actually scoped correctly or not, is the visibility", "tokens": [264, 558, 3190, 420, 406, 11, 1968, 436, 366, 767, 795, 27277, 8944, 420, 406, 11, 307, 264, 19883], "temperature": 0.0, "avg_logprob": -0.15170030671406567, "compression_ratio": 1.9771863117870723, "no_speech_prob": 0.0002941384445875883}, {"id": 100, "seek": 42472, "start": 445.52000000000004, "end": 450.16, "text": " correct or not for those operations, the operations you're using.", "tokens": [3006, 420, 406, 337, 729, 7705, 11, 264, 7705, 291, 434, 1228, 13], "temperature": 0.0, "avg_logprob": -0.15170030671406567, "compression_ratio": 1.9771863117870723, "no_speech_prob": 0.0002941384445875883}, {"id": 101, "seek": 42472, "start": 450.16, "end": 454.32000000000005, "text": " And then once it validates that, then it goes into the binding phase, where it binds those", "tokens": [400, 550, 1564, 309, 7363, 1024, 300, 11, 550, 309, 1709, 666, 264, 17359, 5574, 11, 689, 309, 41515, 729], "temperature": 0.0, "avg_logprob": -0.15170030671406567, "compression_ratio": 1.9771863117870723, "no_speech_prob": 0.0002941384445875883}, {"id": 102, "seek": 45432, "start": 454.32, "end": 458.68, "text": " columns to the table that it belongs to, and then it also does the typing, which means", "tokens": [13766, 281, 264, 3199, 300, 309, 12953, 281, 11, 293, 550, 309, 611, 775, 264, 18444, 11, 597, 1355], "temperature": 0.0, "avg_logprob": -0.1471566434176463, "compression_ratio": 1.7449392712550607, "no_speech_prob": 4.121958772884682e-05}, {"id": 103, "seek": 45432, "start": 458.68, "end": 463.84, "text": " it tries to understand that, okay, once the results come back, we'll know that what type", "tokens": [309, 9898, 281, 1223, 300, 11, 1392, 11, 1564, 264, 3542, 808, 646, 11, 321, 603, 458, 300, 437, 2010], "temperature": 0.0, "avg_logprob": -0.1471566434176463, "compression_ratio": 1.7449392712550607, "no_speech_prob": 4.121958772884682e-05}, {"id": 104, "seek": 45432, "start": 463.84, "end": 467.15999999999997, "text": " it will be of.", "tokens": [309, 486, 312, 295, 13], "temperature": 0.0, "avg_logprob": -0.1471566434176463, "compression_ratio": 1.7449392712550607, "no_speech_prob": 4.121958772884682e-05}, {"id": 105, "seek": 45432, "start": 467.15999999999997, "end": 472.24, "text": " The second is once the semantic analysis happens, then your AST is converted into an operator", "tokens": [440, 1150, 307, 1564, 264, 47982, 5215, 2314, 11, 550, 428, 316, 6840, 307, 16424, 666, 364, 12973], "temperature": 0.0, "avg_logprob": -0.1471566434176463, "compression_ratio": 1.7449392712550607, "no_speech_prob": 4.121958772884682e-05}, {"id": 106, "seek": 45432, "start": 472.24, "end": 479.8, "text": " tree, which is basically a logical operator, like you have joints, and then you have tables", "tokens": [4230, 11, 597, 307, 1936, 257, 14978, 12973, 11, 411, 291, 362, 19949, 11, 293, 550, 291, 362, 8020], "temperature": 0.0, "avg_logprob": -0.1471566434176463, "compression_ratio": 1.7449392712550607, "no_speech_prob": 4.121958772884682e-05}, {"id": 107, "seek": 45432, "start": 479.8, "end": 482.88, "text": " and stuff, so it convert into those logical operators.", "tokens": [293, 1507, 11, 370, 309, 7620, 666, 729, 14978, 19077, 13], "temperature": 0.0, "avg_logprob": -0.1471566434176463, "compression_ratio": 1.7449392712550607, "no_speech_prob": 4.121958772884682e-05}, {"id": 108, "seek": 48288, "start": 482.88, "end": 488.64, "text": " And then once those logical operator are converted, it then goes into the optimization phase.", "tokens": [400, 550, 1564, 729, 14978, 12973, 366, 16424, 11, 309, 550, 1709, 666, 264, 19618, 5574, 13], "temperature": 0.0, "avg_logprob": -0.13134000982557023, "compression_ratio": 1.8273092369477912, "no_speech_prob": 7.010201807133853e-05}, {"id": 109, "seek": 48288, "start": 488.64, "end": 494.76, "text": " So in the optimization phase, we basically make a decision that how the plan should look", "tokens": [407, 294, 264, 19618, 5574, 11, 321, 1936, 652, 257, 3537, 300, 577, 264, 1393, 820, 574], "temperature": 0.0, "avg_logprob": -0.13134000982557023, "compression_ratio": 1.8273092369477912, "no_speech_prob": 7.010201807133853e-05}, {"id": 110, "seek": 48288, "start": 494.76, "end": 501.4, "text": " like, and in the innovators, basically what we do is we get the SQL, and ultimately after", "tokens": [411, 11, 293, 294, 264, 5083, 3391, 11, 1936, 437, 321, 360, 307, 321, 483, 264, 19200, 11, 293, 6284, 934], "temperature": 0.0, "avg_logprob": -0.13134000982557023, "compression_ratio": 1.8273092369477912, "no_speech_prob": 7.010201807133853e-05}, {"id": 111, "seek": 48288, "start": 501.4, "end": 505.84, "text": " the planning phase, we'll get another SQL, because the data does not reside on the VTGit,", "tokens": [264, 5038, 5574, 11, 321, 603, 483, 1071, 19200, 11, 570, 264, 1412, 775, 406, 40134, 322, 264, 691, 51, 38, 270, 11], "temperature": 0.0, "avg_logprob": -0.13134000982557023, "compression_ratio": 1.8273092369477912, "no_speech_prob": 7.010201807133853e-05}, {"id": 112, "seek": 48288, "start": 505.84, "end": 511.76, "text": " it resides on the MySQL, and we want to optimize on the way that we should get less and less", "tokens": [309, 47157, 322, 264, 1222, 39934, 11, 293, 321, 528, 281, 19719, 322, 264, 636, 300, 321, 820, 483, 1570, 293, 1570], "temperature": 0.0, "avg_logprob": -0.13134000982557023, "compression_ratio": 1.8273092369477912, "no_speech_prob": 7.010201807133853e-05}, {"id": 113, "seek": 51176, "start": 511.76, "end": 515.08, "text": " information back on the VTGit to process your data.", "tokens": [1589, 646, 322, 264, 691, 51, 38, 270, 281, 1399, 428, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1323986053466797, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.91374009673018e-05}, {"id": 114, "seek": 51176, "start": 515.08, "end": 522.08, "text": " So we try to push as much as down to the query to the MySQL so that that can resolve much", "tokens": [407, 321, 853, 281, 2944, 382, 709, 382, 760, 281, 264, 14581, 281, 264, 1222, 39934, 370, 300, 300, 393, 14151, 709], "temperature": 0.0, "avg_logprob": -0.1323986053466797, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.91374009673018e-05}, {"id": 115, "seek": 51176, "start": 522.08, "end": 525.0, "text": " faster for us than we do it at the VTGit.", "tokens": [4663, 337, 505, 813, 321, 360, 309, 412, 264, 691, 51, 38, 270, 13], "temperature": 0.0, "avg_logprob": -0.1323986053466797, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.91374009673018e-05}, {"id": 116, "seek": 51176, "start": 525.0, "end": 531.4399999999999, "text": " So in the optimization phase, basically after the optimization completes, we call something", "tokens": [407, 294, 264, 19618, 5574, 11, 1936, 934, 264, 19618, 36362, 11, 321, 818, 746], "temperature": 0.0, "avg_logprob": -0.1323986053466797, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.91374009673018e-05}, {"id": 117, "seek": 51176, "start": 531.4399999999999, "end": 537.92, "text": " like routes, which tell us that, okay, this query will go to which all shards, so that's", "tokens": [411, 18242, 11, 597, 980, 505, 300, 11, 1392, 11, 341, 14581, 486, 352, 281, 597, 439, 402, 2287, 11, 370, 300, 311], "temperature": 0.0, "avg_logprob": -0.1323986053466797, "compression_ratio": 1.6774193548387097, "no_speech_prob": 5.91374009673018e-05}, {"id": 118, "seek": 53792, "start": 537.92, "end": 544.4, "text": " what the ultimate step becomes, and that's where we call it as a physical operator.", "tokens": [437, 264, 9705, 1823, 3643, 11, 293, 300, 311, 689, 321, 818, 309, 382, 257, 4001, 12973, 13], "temperature": 0.0, "avg_logprob": -0.13692150115966797, "compression_ratio": 1.7486033519553073, "no_speech_prob": 2.790774669847451e-05}, {"id": 119, "seek": 53792, "start": 544.4, "end": 552.4, "text": " And then once we have the physical operators, we transform the plan into an execution plan.", "tokens": [400, 550, 1564, 321, 362, 264, 4001, 19077, 11, 321, 4088, 264, 1393, 666, 364, 15058, 1393, 13], "temperature": 0.0, "avg_logprob": -0.13692150115966797, "compression_ratio": 1.7486033519553073, "no_speech_prob": 2.790774669847451e-05}, {"id": 120, "seek": 53792, "start": 552.4, "end": 557.4, "text": " And the execution plan is nothing but a collection of engine primitives that we call.", "tokens": [400, 264, 15058, 1393, 307, 1825, 457, 257, 5765, 295, 2848, 2886, 38970, 300, 321, 818, 13], "temperature": 0.0, "avg_logprob": -0.13692150115966797, "compression_ratio": 1.7486033519553073, "no_speech_prob": 2.790774669847451e-05}, {"id": 121, "seek": 53792, "start": 557.4, "end": 562.36, "text": " So let's look at how the execution plan looks like.", "tokens": [407, 718, 311, 574, 412, 577, 264, 15058, 1393, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.13692150115966797, "compression_ratio": 1.7486033519553073, "no_speech_prob": 2.790774669847451e-05}, {"id": 122, "seek": 56236, "start": 562.36, "end": 571.16, "text": " So if both the tables which I showed in the V schema were using same sharding function,", "tokens": [407, 498, 1293, 264, 8020, 597, 286, 4712, 294, 264, 691, 34078, 645, 1228, 912, 402, 515, 278, 2445, 11], "temperature": 0.0, "avg_logprob": -0.12609541125413848, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.1958199290093035e-05}, {"id": 123, "seek": 56236, "start": 571.16, "end": 575.24, "text": " so that's why we were able to basically make it as a single route, which is telling you", "tokens": [370, 300, 311, 983, 321, 645, 1075, 281, 1936, 652, 309, 382, 257, 2167, 7955, 11, 597, 307, 3585, 291], "temperature": 0.0, "avg_logprob": -0.12609541125413848, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.1958199290093035e-05}, {"id": 124, "seek": 56236, "start": 575.24, "end": 582.08, "text": " that, okay, just go scatter to all the shards and just gather the result at the VTGit level", "tokens": [300, 11, 1392, 11, 445, 352, 34951, 281, 439, 264, 402, 2287, 293, 445, 5448, 264, 1874, 412, 264, 691, 51, 38, 270, 1496], "temperature": 0.0, "avg_logprob": -0.12609541125413848, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.1958199290093035e-05}, {"id": 125, "seek": 56236, "start": 582.08, "end": 586.12, "text": " and send it back to the user.", "tokens": [293, 2845, 309, 646, 281, 264, 4195, 13], "temperature": 0.0, "avg_logprob": -0.12609541125413848, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.1958199290093035e-05}, {"id": 126, "seek": 58612, "start": 586.12, "end": 592.84, "text": " But if both the tables, the customer table and the order table were using some different", "tokens": [583, 498, 1293, 264, 8020, 11, 264, 5474, 3199, 293, 264, 1668, 3199, 645, 1228, 512, 819], "temperature": 0.0, "avg_logprob": -0.18235025249543738, "compression_ratio": 1.7695035460992907, "no_speech_prob": 8.20609275251627e-05}, {"id": 127, "seek": 58612, "start": 592.84, "end": 596.52, "text": " sharding functions, then you cannot merge it like that.", "tokens": [402, 515, 278, 6828, 11, 550, 291, 2644, 22183, 309, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.18235025249543738, "compression_ratio": 1.7695035460992907, "no_speech_prob": 8.20609275251627e-05}, {"id": 128, "seek": 58612, "start": 596.52, "end": 601.2, "text": " Then it says basically, it will look something like that, like you'll have, now, because", "tokens": [1396, 309, 1619, 1936, 11, 309, 486, 574, 746, 411, 300, 11, 411, 291, 603, 362, 11, 586, 11, 570], "temperature": 0.0, "avg_logprob": -0.18235025249543738, "compression_ratio": 1.7695035460992907, "no_speech_prob": 8.20609275251627e-05}, {"id": 129, "seek": 58612, "start": 601.2, "end": 605.48, "text": " it gets very complex enough to show everything over here, so I'm just showing that there's", "tokens": [309, 2170, 588, 3997, 1547, 281, 855, 1203, 670, 510, 11, 370, 286, 478, 445, 4099, 300, 456, 311], "temperature": 0.0, "avg_logprob": -0.18235025249543738, "compression_ratio": 1.7695035460992907, "no_speech_prob": 8.20609275251627e-05}, {"id": 130, "seek": 58612, "start": 605.48, "end": 609.32, "text": " a, there'll be two routes that will happen, and then ultimately the join will also happen", "tokens": [257, 11, 456, 603, 312, 732, 18242, 300, 486, 1051, 11, 293, 550, 6284, 264, 3917, 486, 611, 1051], "temperature": 0.0, "avg_logprob": -0.18235025249543738, "compression_ratio": 1.7695035460992907, "no_speech_prob": 8.20609275251627e-05}, {"id": 131, "seek": 58612, "start": 609.32, "end": 613.48, "text": " at the VTGit level, sorting and projecting and the aggregation, and then finally the", "tokens": [412, 264, 691, 51, 38, 270, 1496, 11, 32411, 293, 43001, 293, 264, 16743, 399, 11, 293, 550, 2721, 264], "temperature": 0.0, "avg_logprob": -0.18235025249543738, "compression_ratio": 1.7695035460992907, "no_speech_prob": 8.20609275251627e-05}, {"id": 132, "seek": 61348, "start": 613.48, "end": 618.12, "text": " filtering based on how much customers have spent those thousand bucks.", "tokens": [30822, 2361, 322, 577, 709, 4581, 362, 4418, 729, 4714, 11829, 13], "temperature": 0.0, "avg_logprob": -0.14748044771568797, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.0001927937555592507}, {"id": 133, "seek": 61348, "start": 618.12, "end": 623.2, "text": " So everything happens on the VTGit.", "tokens": [407, 1203, 2314, 322, 264, 691, 51, 38, 270, 13], "temperature": 0.0, "avg_logprob": -0.14748044771568797, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.0001927937555592507}, {"id": 134, "seek": 61348, "start": 623.2, "end": 627.12, "text": " Let's just look at the two routes that I showed on the left.", "tokens": [961, 311, 445, 574, 412, 264, 732, 18242, 300, 286, 4712, 322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.14748044771568797, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.0001927937555592507}, {"id": 135, "seek": 61348, "start": 627.12, "end": 631.5600000000001, "text": " So first one we'll do is basically doing a scatter, and it's trying to do on the order", "tokens": [407, 700, 472, 321, 603, 360, 307, 1936, 884, 257, 34951, 11, 293, 309, 311, 1382, 281, 360, 322, 264, 1668], "temperature": 0.0, "avg_logprob": -0.14748044771568797, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.0001927937555592507}, {"id": 136, "seek": 61348, "start": 631.5600000000001, "end": 638.84, "text": " table that, okay, give me for all the customer IDs what is the spend they have done, and", "tokens": [3199, 300, 11, 1392, 11, 976, 385, 337, 439, 264, 5474, 48212, 437, 307, 264, 3496, 436, 362, 1096, 11, 293], "temperature": 0.0, "avg_logprob": -0.14748044771568797, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.0001927937555592507}, {"id": 137, "seek": 61348, "start": 638.84, "end": 641.32, "text": " then on the right-hand side, we need the customer emails.", "tokens": [550, 322, 264, 558, 12, 5543, 1252, 11, 321, 643, 264, 5474, 12524, 13], "temperature": 0.0, "avg_logprob": -0.14748044771568797, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.0001927937555592507}, {"id": 138, "seek": 64132, "start": 641.32, "end": 647.24, "text": " So for every customer ID, I need to get their email IDs, and because the customer ID was", "tokens": [407, 337, 633, 5474, 7348, 11, 286, 643, 281, 483, 641, 3796, 48212, 11, 293, 570, 264, 5474, 7348, 390], "temperature": 0.0, "avg_logprob": -0.13300136117374195, "compression_ratio": 1.5618556701030928, "no_speech_prob": 9.271111048292369e-05}, {"id": 139, "seek": 64132, "start": 647.24, "end": 653.6800000000001, "text": " the sharding key, the primary index for that table, we are able to send the second query", "tokens": [264, 402, 515, 278, 2141, 11, 264, 6194, 8186, 337, 300, 3199, 11, 321, 366, 1075, 281, 2845, 264, 1150, 14581], "temperature": 0.0, "avg_logprob": -0.13300136117374195, "compression_ratio": 1.5618556701030928, "no_speech_prob": 9.271111048292369e-05}, {"id": 140, "seek": 64132, "start": 653.6800000000001, "end": 664.24, "text": " as a, only to a specific shard, we don't have to do again, go to all the shards.", "tokens": [382, 257, 11, 787, 281, 257, 2685, 402, 515, 11, 321, 500, 380, 362, 281, 360, 797, 11, 352, 281, 439, 264, 402, 2287, 13], "temperature": 0.0, "avg_logprob": -0.13300136117374195, "compression_ratio": 1.5618556701030928, "no_speech_prob": 9.271111048292369e-05}, {"id": 141, "seek": 64132, "start": 664.24, "end": 667.4000000000001, "text": " So what all steps happened in the execution?", "tokens": [407, 437, 439, 4439, 2011, 294, 264, 15058, 30], "temperature": 0.0, "avg_logprob": -0.13300136117374195, "compression_ratio": 1.5618556701030928, "no_speech_prob": 9.271111048292369e-05}, {"id": 142, "seek": 66740, "start": 667.4, "end": 672.64, "text": " So first thing is, once we get the route, we resolve it using those indexes, and so", "tokens": [407, 700, 551, 307, 11, 1564, 321, 483, 264, 7955, 11, 321, 14151, 309, 1228, 729, 8186, 279, 11, 293, 370], "temperature": 0.0, "avg_logprob": -0.15430833659040818, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.00018180054030381143}, {"id": 143, "seek": 66740, "start": 672.64, "end": 676.56, "text": " that it can go to the specific correct shard.", "tokens": [300, 309, 393, 352, 281, 264, 2685, 3006, 402, 515, 13], "temperature": 0.0, "avg_logprob": -0.15430833659040818, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.00018180054030381143}, {"id": 144, "seek": 66740, "start": 676.56, "end": 680.72, "text": " Another is then, it basically then we take a decide, okay, now we know which shard we", "tokens": [3996, 307, 550, 11, 309, 1936, 550, 321, 747, 257, 4536, 11, 1392, 11, 586, 321, 458, 597, 402, 515, 321], "temperature": 0.0, "avg_logprob": -0.15430833659040818, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.00018180054030381143}, {"id": 145, "seek": 66740, "start": 680.72, "end": 685.92, "text": " have to go to, then it will also decide, okay, this is a query that we have to send it to", "tokens": [362, 281, 352, 281, 11, 550, 309, 486, 611, 4536, 11, 1392, 11, 341, 307, 257, 14581, 300, 321, 362, 281, 2845, 309, 281], "temperature": 0.0, "avg_logprob": -0.15430833659040818, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.00018180054030381143}, {"id": 146, "seek": 66740, "start": 685.92, "end": 690.92, "text": " something that we call the VT tablets, which basically in the shard we have VT tablets", "tokens": [746, 300, 321, 818, 264, 691, 51, 27622, 11, 597, 1936, 294, 264, 402, 515, 321, 362, 691, 51, 27622], "temperature": 0.0, "avg_logprob": -0.15430833659040818, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.00018180054030381143}, {"id": 147, "seek": 69092, "start": 690.92, "end": 697.4799999999999, "text": " and MySQL, so it's sent to the VT tablet, and then once you receive the result back,", "tokens": [293, 1222, 39934, 11, 370, 309, 311, 2279, 281, 264, 691, 51, 14136, 11, 293, 550, 1564, 291, 4774, 264, 1874, 646, 11], "temperature": 0.0, "avg_logprob": -0.1850696254420925, "compression_ratio": 1.8936170212765957, "no_speech_prob": 6.293421029113233e-05}, {"id": 148, "seek": 69092, "start": 697.4799999999999, "end": 704.64, "text": " you gather the information, but sometimes you also have to do transactions, so if transaction", "tokens": [291, 5448, 264, 1589, 11, 457, 2171, 291, 611, 362, 281, 360, 16856, 11, 370, 498, 14425], "temperature": 0.0, "avg_logprob": -0.1850696254420925, "compression_ratio": 1.8936170212765957, "no_speech_prob": 6.293421029113233e-05}, {"id": 149, "seek": 69092, "start": 704.64, "end": 708.92, "text": " is needed, then the VT gate will also tell VT tablets, go and also open the transaction", "tokens": [307, 2978, 11, 550, 264, 691, 51, 8539, 486, 611, 980, 691, 51, 27622, 11, 352, 293, 611, 1269, 264, 14425], "temperature": 0.0, "avg_logprob": -0.1850696254420925, "compression_ratio": 1.8936170212765957, "no_speech_prob": 6.293421029113233e-05}, {"id": 150, "seek": 69092, "start": 708.92, "end": 716.4, "text": " when you execute the query, and then the session, the transactions will be managed by the VT", "tokens": [562, 291, 14483, 264, 14581, 11, 293, 550, 264, 5481, 11, 264, 16856, 486, 312, 6453, 538, 264, 691, 51], "temperature": 0.0, "avg_logprob": -0.1850696254420925, "compression_ratio": 1.8936170212765957, "no_speech_prob": 6.293421029113233e-05}, {"id": 151, "seek": 69092, "start": 716.4, "end": 720.12, "text": " gate that will know in which shard what is the transaction being opened, so that when", "tokens": [8539, 300, 486, 458, 294, 597, 402, 515, 437, 307, 264, 14425, 885, 5625, 11, 370, 300, 562], "temperature": 0.0, "avg_logprob": -0.1850696254420925, "compression_ratio": 1.8936170212765957, "no_speech_prob": 6.293421029113233e-05}, {"id": 152, "seek": 72012, "start": 720.12, "end": 723.48, "text": " you do the commit, it knows which shard it has to send the commit information as well", "tokens": [291, 360, 264, 5599, 11, 309, 3255, 597, 402, 515, 309, 575, 281, 2845, 264, 5599, 1589, 382, 731], "temperature": 0.0, "avg_logprob": -0.2047490358352661, "compression_ratio": 1.619047619047619, "no_speech_prob": 4.327146598370746e-05}, {"id": 153, "seek": 72012, "start": 723.48, "end": 726.68, "text": " too.", "tokens": [886, 13], "temperature": 0.0, "avg_logprob": -0.2047490358352661, "compression_ratio": 1.619047619047619, "no_speech_prob": 4.327146598370746e-05}, {"id": 154, "seek": 72012, "start": 726.68, "end": 732.72, "text": " And the last thing that execution also handles is basically, if you have a select query and", "tokens": [400, 264, 1036, 551, 300, 15058, 611, 18722, 307, 1936, 11, 498, 291, 362, 257, 3048, 14581, 293], "temperature": 0.0, "avg_logprob": -0.2047490358352661, "compression_ratio": 1.619047619047619, "no_speech_prob": 4.327146598370746e-05}, {"id": 155, "seek": 72012, "start": 732.72, "end": 736.6, "text": " you want to read it on the replicas, then it also does the load balancing for you, so", "tokens": [291, 528, 281, 1401, 309, 322, 264, 3248, 9150, 11, 550, 309, 611, 775, 264, 3677, 22495, 337, 291, 11, 370], "temperature": 0.0, "avg_logprob": -0.2047490358352661, "compression_ratio": 1.619047619047619, "no_speech_prob": 4.327146598370746e-05}, {"id": 156, "seek": 72012, "start": 736.6, "end": 748.64, "text": " it doesn't overload a single replica.", "tokens": [309, 1177, 380, 28777, 257, 2167, 35456, 13], "temperature": 0.0, "avg_logprob": -0.2047490358352661, "compression_ratio": 1.619047619047619, "no_speech_prob": 4.327146598370746e-05}, {"id": 157, "seek": 74864, "start": 748.64, "end": 753.92, "text": " So now the query is being sent to VT tablets, and now the VT job is to basically get the", "tokens": [407, 586, 264, 14581, 307, 885, 2279, 281, 691, 51, 27622, 11, 293, 586, 264, 691, 51, 1691, 307, 281, 1936, 483, 264], "temperature": 0.0, "avg_logprob": -0.16194704276363867, "compression_ratio": 1.929889298892989, "no_speech_prob": 0.00023311295080929995}, {"id": 158, "seek": 74864, "start": 753.92, "end": 755.84, "text": " result back to the VT gate.", "tokens": [1874, 646, 281, 264, 691, 51, 8539, 13], "temperature": 0.0, "avg_logprob": -0.16194704276363867, "compression_ratio": 1.929889298892989, "no_speech_prob": 0.00023311295080929995}, {"id": 159, "seek": 74864, "start": 755.84, "end": 757.8, "text": " So what are the things that goes in the VT tablet?", "tokens": [407, 437, 366, 264, 721, 300, 1709, 294, 264, 691, 51, 14136, 30], "temperature": 0.0, "avg_logprob": -0.16194704276363867, "compression_ratio": 1.929889298892989, "no_speech_prob": 0.00023311295080929995}, {"id": 160, "seek": 74864, "start": 757.8, "end": 763.24, "text": " It's exactly similar thing that goes in the VT tablets as well, but what are different", "tokens": [467, 311, 2293, 2531, 551, 300, 1709, 294, 264, 691, 51, 27622, 382, 731, 11, 457, 437, 366, 819], "temperature": 0.0, "avg_logprob": -0.16194704276363867, "compression_ratio": 1.929889298892989, "no_speech_prob": 0.00023311295080929995}, {"id": 161, "seek": 74864, "start": 763.24, "end": 764.24, "text": " reasons?", "tokens": [4112, 30], "temperature": 0.0, "avg_logprob": -0.16194704276363867, "compression_ratio": 1.929889298892989, "no_speech_prob": 0.00023311295080929995}, {"id": 162, "seek": 74864, "start": 764.24, "end": 768.3199999999999, "text": " So first thing is, VT gate has some view of the VT tablet of what this state is, but the", "tokens": [407, 700, 551, 307, 11, 691, 51, 8539, 575, 512, 1910, 295, 264, 691, 51, 14136, 295, 437, 341, 1785, 307, 11, 457, 264], "temperature": 0.0, "avg_logprob": -0.16194704276363867, "compression_ratio": 1.929889298892989, "no_speech_prob": 0.00023311295080929995}, {"id": 163, "seek": 74864, "start": 768.3199999999999, "end": 772.1999999999999, "text": " first thing that events the query received by the VT tablet, it does this, okay, let", "tokens": [700, 551, 300, 3931, 264, 14581, 4613, 538, 264, 691, 51, 14136, 11, 309, 775, 341, 11, 1392, 11, 718], "temperature": 0.0, "avg_logprob": -0.16194704276363867, "compression_ratio": 1.929889298892989, "no_speech_prob": 0.00023311295080929995}, {"id": 164, "seek": 74864, "start": 772.1999999999999, "end": 776.56, "text": " me validate whether that's current, am I able to serve this query or not, if any view", "tokens": [385, 29562, 1968, 300, 311, 2190, 11, 669, 286, 1075, 281, 4596, 341, 14581, 420, 406, 11, 498, 604, 1910], "temperature": 0.0, "avg_logprob": -0.16194704276363867, "compression_ratio": 1.929889298892989, "no_speech_prob": 0.00023311295080929995}, {"id": 165, "seek": 77656, "start": 776.56, "end": 783.8, "text": " has changed before, after sending the query and before it reads the VT tablet, so it validates", "tokens": [575, 3105, 949, 11, 934, 7750, 264, 14581, 293, 949, 309, 15700, 264, 691, 51, 14136, 11, 370, 309, 7363, 1024], "temperature": 0.0, "avg_logprob": -0.16617518884164315, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00017819268396124244}, {"id": 166, "seek": 77656, "start": 783.8, "end": 787.56, "text": " if everything is okay, okay, then let's go and do the parsing.", "tokens": [498, 1203, 307, 1392, 11, 1392, 11, 550, 718, 311, 352, 293, 360, 264, 21156, 278, 13], "temperature": 0.0, "avg_logprob": -0.16617518884164315, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00017819268396124244}, {"id": 167, "seek": 77656, "start": 787.56, "end": 793.1199999999999, "text": " So it will parse the query, and the reason is it has to parse the query is because VT", "tokens": [407, 309, 486, 48377, 264, 14581, 11, 293, 264, 1778, 307, 309, 575, 281, 48377, 264, 14581, 307, 570, 691, 51], "temperature": 0.0, "avg_logprob": -0.16617518884164315, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00017819268396124244}, {"id": 168, "seek": 77656, "start": 793.1199999999999, "end": 799.8399999999999, "text": " tablet has its checks and balances over here where it tries to put some limitation, like", "tokens": [14136, 575, 1080, 13834, 293, 33993, 670, 510, 689, 309, 9898, 281, 829, 512, 27432, 11, 411], "temperature": 0.0, "avg_logprob": -0.16617518884164315, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00017819268396124244}, {"id": 169, "seek": 77656, "start": 799.8399999999999, "end": 805.56, "text": " it says that don't overload the MySQL resource, so it will basically add its own limits onto", "tokens": [309, 1619, 300, 500, 380, 28777, 264, 1222, 39934, 7684, 11, 370, 309, 486, 1936, 909, 1080, 1065, 10406, 3911], "temperature": 0.0, "avg_logprob": -0.16617518884164315, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00017819268396124244}, {"id": 170, "seek": 80556, "start": 805.56, "end": 812.2399999999999, "text": " the query so that it doesn't overload your MySQL, that you can configure and do things,", "tokens": [264, 14581, 370, 300, 309, 1177, 380, 28777, 428, 1222, 39934, 11, 300, 291, 393, 22162, 293, 360, 721, 11], "temperature": 0.0, "avg_logprob": -0.18964341422107733, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.588322816649452e-05}, {"id": 171, "seek": 80556, "start": 812.2399999999999, "end": 815.88, "text": " and then it goes into the planning phase, and in the planning field, it basically tries", "tokens": [293, 550, 309, 1709, 666, 264, 5038, 5574, 11, 293, 294, 264, 5038, 2519, 11, 309, 1936, 9898], "temperature": 0.0, "avg_logprob": -0.18964341422107733, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.588322816649452e-05}, {"id": 172, "seek": 80556, "start": 815.88, "end": 822.3599999999999, "text": " to see whether did you have put any query rules, which means like any bad query, if", "tokens": [281, 536, 1968, 630, 291, 362, 829, 604, 14581, 4474, 11, 597, 1355, 411, 604, 1578, 14581, 11, 498], "temperature": 0.0, "avg_logprob": -0.18964341422107733, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.588322816649452e-05}, {"id": 173, "seek": 80556, "start": 822.3599999999999, "end": 827.88, "text": " you put like, okay, somebody does select star and without a wear condition and stuff, so", "tokens": [291, 829, 411, 11, 1392, 11, 2618, 775, 3048, 3543, 293, 1553, 257, 3728, 4188, 293, 1507, 11, 370], "temperature": 0.0, "avg_logprob": -0.18964341422107733, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.588322816649452e-05}, {"id": 174, "seek": 80556, "start": 827.88, "end": 831.8, "text": " it basically says, okay, this query cannot be executed because it's a bad query, so", "tokens": [309, 1936, 1619, 11, 1392, 11, 341, 14581, 2644, 312, 17577, 570, 309, 311, 257, 1578, 14581, 11, 370], "temperature": 0.0, "avg_logprob": -0.18964341422107733, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.588322816649452e-05}, {"id": 175, "seek": 83180, "start": 831.8, "end": 837.76, "text": " those kind of query rules you can put, and another thing that we check in the planning", "tokens": [729, 733, 295, 14581, 4474, 291, 393, 829, 11, 293, 1071, 551, 300, 321, 1520, 294, 264, 5038], "temperature": 0.0, "avg_logprob": -0.14405457448151152, "compression_ratio": 1.7876447876447876, "no_speech_prob": 2.0775540178874508e-05}, {"id": 176, "seek": 83180, "start": 837.76, "end": 841.68, "text": " phase is basically it will say, okay, this is the user that sent this query, but is the", "tokens": [5574, 307, 1936, 309, 486, 584, 11, 1392, 11, 341, 307, 264, 4195, 300, 2279, 341, 14581, 11, 457, 307, 264], "temperature": 0.0, "avg_logprob": -0.14405457448151152, "compression_ratio": 1.7876447876447876, "no_speech_prob": 2.0775540178874508e-05}, {"id": 177, "seek": 83180, "start": 841.68, "end": 843.88, "text": " user allowed to even access the tables or not?", "tokens": [4195, 4350, 281, 754, 2105, 264, 8020, 420, 406, 30], "temperature": 0.0, "avg_logprob": -0.14405457448151152, "compression_ratio": 1.7876447876447876, "no_speech_prob": 2.0775540178874508e-05}, {"id": 178, "seek": 83180, "start": 843.88, "end": 849.4799999999999, "text": " So if it's not allowed, then we throw the error back.", "tokens": [407, 498, 309, 311, 406, 4350, 11, 550, 321, 3507, 264, 6713, 646, 13], "temperature": 0.0, "avg_logprob": -0.14405457448151152, "compression_ratio": 1.7876447876447876, "no_speech_prob": 2.0775540178874508e-05}, {"id": 179, "seek": 83180, "start": 849.4799999999999, "end": 854.3199999999999, "text": " After the planning phase, also VT tablet does this, again, and all these are there to just", "tokens": [2381, 264, 5038, 5574, 11, 611, 691, 51, 14136, 775, 341, 11, 797, 11, 293, 439, 613, 366, 456, 281, 445], "temperature": 0.0, "avg_logprob": -0.14405457448151152, "compression_ratio": 1.7876447876447876, "no_speech_prob": 2.0775540178874508e-05}, {"id": 180, "seek": 83180, "start": 854.3199999999999, "end": 859.16, "text": " not to load your MySQL, so another thing that it does is query consolidation, which is basically", "tokens": [406, 281, 3677, 428, 1222, 39934, 11, 370, 1071, 551, 300, 309, 775, 307, 14581, 39114, 11, 597, 307, 1936], "temperature": 0.0, "avg_logprob": -0.14405457448151152, "compression_ratio": 1.7876447876447876, "no_speech_prob": 2.0775540178874508e-05}, {"id": 181, "seek": 85916, "start": 859.16, "end": 865.9599999999999, "text": " it checks whether any same query is running on the MySQL or not.", "tokens": [309, 13834, 1968, 604, 912, 14581, 307, 2614, 322, 264, 1222, 39934, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.16526451931204847, "compression_ratio": 1.8038277511961722, "no_speech_prob": 2.9746206564595923e-05}, {"id": 182, "seek": 85916, "start": 865.9599999999999, "end": 870.88, "text": " If it's already running, then it just waits for that query to return the result, and all", "tokens": [759, 309, 311, 1217, 2614, 11, 550, 309, 445, 40597, 337, 300, 14581, 281, 2736, 264, 1874, 11, 293, 439], "temperature": 0.0, "avg_logprob": -0.16526451931204847, "compression_ratio": 1.8038277511961722, "no_speech_prob": 2.9746206564595923e-05}, {"id": 183, "seek": 85916, "start": 870.88, "end": 875.04, "text": " the threads which are waiting for the same query will get the result and it will return", "tokens": [264, 19314, 597, 366, 3806, 337, 264, 912, 14581, 486, 483, 264, 1874, 293, 309, 486, 2736], "temperature": 0.0, "avg_logprob": -0.16526451931204847, "compression_ratio": 1.8038277511961722, "no_speech_prob": 2.9746206564595923e-05}, {"id": 184, "seek": 85916, "start": 875.04, "end": 880.56, "text": " back, so only one query ultimately gets executed on the MySQL and not all the queries get executed", "tokens": [646, 11, 370, 787, 472, 14581, 6284, 2170, 17577, 322, 264, 1222, 39934, 293, 406, 439, 264, 24109, 483, 17577], "temperature": 0.0, "avg_logprob": -0.16526451931204847, "compression_ratio": 1.8038277511961722, "no_speech_prob": 2.9746206564595923e-05}, {"id": 185, "seek": 85916, "start": 880.56, "end": 885.4, "text": " with the same exact same query, yes.", "tokens": [365, 264, 912, 1900, 912, 14581, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.16526451931204847, "compression_ratio": 1.8038277511961722, "no_speech_prob": 2.9746206564595923e-05}, {"id": 186, "seek": 88540, "start": 885.4, "end": 890.36, "text": " So once it thinks, okay, nothing can be done, like it has to finally send it to MySQL, then", "tokens": [407, 1564, 309, 7309, 11, 1392, 11, 1825, 393, 312, 1096, 11, 411, 309, 575, 281, 2721, 2845, 309, 281, 1222, 39934, 11, 550], "temperature": 0.0, "avg_logprob": -0.18333234786987304, "compression_ratio": 1.8432203389830508, "no_speech_prob": 4.8239860916510224e-05}, {"id": 187, "seek": 88540, "start": 890.36, "end": 896.6, "text": " it will use one of the connection from the connection pool to send the query to MySQL,", "tokens": [309, 486, 764, 472, 295, 264, 4984, 490, 264, 4984, 7005, 281, 2845, 264, 14581, 281, 1222, 39934, 11], "temperature": 0.0, "avg_logprob": -0.18333234786987304, "compression_ratio": 1.8432203389830508, "no_speech_prob": 4.8239860916510224e-05}, {"id": 188, "seek": 88540, "start": 896.6, "end": 900.0799999999999, "text": " and once the results are written back, it will send it to VTGate, VTGate, if it has to", "tokens": [293, 1564, 264, 3542, 366, 3720, 646, 11, 309, 486, 2845, 309, 281, 691, 51, 38, 473, 11, 691, 51, 38, 473, 11, 498, 309, 575, 281], "temperature": 0.0, "avg_logprob": -0.18333234786987304, "compression_ratio": 1.8432203389830508, "no_speech_prob": 4.8239860916510224e-05}, {"id": 189, "seek": 88540, "start": 900.0799999999999, "end": 908.48, "text": " do some operations, it will do it, and finally the client will receive the query.", "tokens": [360, 512, 7705, 11, 309, 486, 360, 309, 11, 293, 2721, 264, 6423, 486, 4774, 264, 14581, 13], "temperature": 0.0, "avg_logprob": -0.18333234786987304, "compression_ratio": 1.8432203389830508, "no_speech_prob": 4.8239860916510224e-05}, {"id": 190, "seek": 88540, "start": 908.48, "end": 914.16, "text": " So yeah, so that's what the life of query is, but then there are some custom operations", "tokens": [407, 1338, 11, 370, 300, 311, 437, 264, 993, 295, 14581, 307, 11, 457, 550, 456, 366, 512, 2375, 7705], "temperature": 0.0, "avg_logprob": -0.18333234786987304, "compression_ratio": 1.8432203389830508, "no_speech_prob": 4.8239860916510224e-05}, {"id": 191, "seek": 91416, "start": 914.16, "end": 919.88, "text": " which also affect your query path, and which is like when there's a plan maintenance going,", "tokens": [597, 611, 3345, 428, 14581, 3100, 11, 293, 597, 307, 411, 562, 456, 311, 257, 1393, 11258, 516, 11], "temperature": 0.0, "avg_logprob": -0.2088723863874163, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0001844149228418246}, {"id": 192, "seek": 91416, "start": 919.88, "end": 927.6, "text": " like you're promoting one replica to primary for some reason, and there is basically if", "tokens": [411, 291, 434, 16383, 472, 35456, 281, 6194, 337, 512, 1778, 11, 293, 456, 307, 1936, 498], "temperature": 0.0, "avg_logprob": -0.2088723863874163, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0001844149228418246}, {"id": 193, "seek": 91416, "start": 927.6, "end": 932.16, "text": " you are splitting your data, like you have some N charts and you want to go to two N", "tokens": [291, 366, 30348, 428, 1412, 11, 411, 291, 362, 512, 426, 17767, 293, 291, 528, 281, 352, 281, 732, 426], "temperature": 0.0, "avg_logprob": -0.2088723863874163, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0001844149228418246}, {"id": 194, "seek": 91416, "start": 932.16, "end": 939.3199999999999, "text": " charts or N plus one charts or such thing like that, so while doing those operations,", "tokens": [17767, 420, 426, 1804, 472, 17767, 420, 1270, 551, 411, 300, 11, 370, 1339, 884, 729, 7705, 11], "temperature": 0.0, "avg_logprob": -0.2088723863874163, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0001844149228418246}, {"id": 195, "seek": 93932, "start": 939.32, "end": 945.36, "text": " what VTGate does is it notifies the topo that some operation is going, VTGate understands", "tokens": [437, 691, 51, 38, 473, 775, 307, 309, 406, 11221, 264, 1192, 78, 300, 512, 6916, 307, 516, 11, 691, 51, 38, 473, 15146], "temperature": 0.0, "avg_logprob": -0.18578720092773438, "compression_ratio": 1.6952380952380952, "no_speech_prob": 9.879612480290234e-05}, {"id": 196, "seek": 93932, "start": 945.36, "end": 950.5200000000001, "text": " it, so it doesn't send query to the VTGate tablet, it basically buffers a certain duration,", "tokens": [309, 11, 370, 309, 1177, 380, 2845, 14581, 281, 264, 691, 51, 38, 473, 14136, 11, 309, 1936, 9204, 433, 257, 1629, 16365, 11], "temperature": 0.0, "avg_logprob": -0.18578720092773438, "compression_ratio": 1.6952380952380952, "no_speech_prob": 9.879612480290234e-05}, {"id": 197, "seek": 93932, "start": 950.5200000000001, "end": 956.44, "text": " and once everything comes back right, then the queries start going to the VTGate tablet,", "tokens": [293, 1564, 1203, 1487, 646, 558, 11, 550, 264, 24109, 722, 516, 281, 264, 691, 51, 38, 473, 14136, 11], "temperature": 0.0, "avg_logprob": -0.18578720092773438, "compression_ratio": 1.6952380952380952, "no_speech_prob": 9.879612480290234e-05}, {"id": 198, "seek": 93932, "start": 956.44, "end": 967.8800000000001, "text": " or it times out and VTGate does the time out from itself rather than sending it down.", "tokens": [420, 309, 1413, 484, 293, 691, 51, 38, 473, 775, 264, 565, 484, 490, 2564, 2831, 813, 7750, 309, 760, 13], "temperature": 0.0, "avg_logprob": -0.18578720092773438, "compression_ratio": 1.6952380952380952, "no_speech_prob": 9.879612480290234e-05}, {"id": 199, "seek": 96788, "start": 967.88, "end": 970.8, "text": " So yeah, thank you.", "tokens": [407, 1338, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.31862649917602537, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.00011340001947246492}, {"id": 200, "seek": 96788, "start": 970.8, "end": 971.8, "text": " Questions?", "tokens": [27738, 30], "temperature": 0.0, "avg_logprob": -0.31862649917602537, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.00011340001947246492}, {"id": 201, "seek": 96788, "start": 971.8, "end": 991.24, "text": " So currently we don't do cross-shared transactions, we do it, but in the best effort way, but", "tokens": [407, 4362, 321, 500, 380, 360, 3278, 12, 2716, 1642, 16856, 11, 321, 360, 309, 11, 457, 294, 264, 1151, 4630, 636, 11, 457], "temperature": 0.0, "avg_logprob": -0.31862649917602537, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.00011340001947246492}, {"id": 202, "seek": 96788, "start": 991.24, "end": 995.76, "text": " it's currently on the application to know that they are doing cross-shared transactions,", "tokens": [309, 311, 4362, 322, 264, 3861, 281, 458, 300, 436, 366, 884, 3278, 12, 2716, 1642, 16856, 11], "temperature": 0.0, "avg_logprob": -0.31862649917602537, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.00011340001947246492}, {"id": 203, "seek": 99576, "start": 995.76, "end": 1000.16, "text": " but we allow it, but the application should know that they are going cross-shared.", "tokens": [457, 321, 2089, 309, 11, 457, 264, 3861, 820, 458, 300, 436, 366, 516, 3278, 12, 2716, 1642, 13], "temperature": 0.0, "avg_logprob": -0.32290277675706514, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00019964476814493537}, {"id": 204, "seek": 99576, "start": 1000.16, "end": 1001.16, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.32290277675706514, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00019964476814493537}, {"id": 205, "seek": 99576, "start": 1001.16, "end": 1025.72, "text": " So join I already showed in how we have the two routes, and then from one we get the", "tokens": [407, 3917, 286, 1217, 4712, 294, 577, 321, 362, 264, 732, 18242, 11, 293, 550, 490, 472, 321, 483, 264], "temperature": 0.0, "avg_logprob": -0.32290277675706514, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00019964476814493537}, {"id": 206, "seek": 102572, "start": 1025.72, "end": 1036.44, "text": " result and the other one, this is join.", "tokens": [1874, 293, 264, 661, 472, 11, 341, 307, 3917, 13], "temperature": 0.0, "avg_logprob": -0.2891796316419329, "compression_ratio": 1.556390977443609, "no_speech_prob": 0.000303369335597381}, {"id": 207, "seek": 102572, "start": 1036.44, "end": 1044.24, "text": " So we have hash joins available, but then it will consume your memory, and otherwise", "tokens": [407, 321, 362, 22019, 24397, 2435, 11, 457, 550, 309, 486, 14732, 428, 4675, 11, 293, 5911], "temperature": 0.0, "avg_logprob": -0.2891796316419329, "compression_ratio": 1.556390977443609, "no_speech_prob": 0.000303369335597381}, {"id": 208, "seek": 102572, "start": 1044.24, "end": 1049.28, "text": " it's like from one you'll get the result and then you send it to the other one, so", "tokens": [309, 311, 411, 490, 472, 291, 603, 483, 264, 1874, 293, 550, 291, 2845, 309, 281, 264, 661, 472, 11, 370], "temperature": 0.0, "avg_logprob": -0.2891796316419329, "compression_ratio": 1.556390977443609, "no_speech_prob": 0.000303369335597381}, {"id": 209, "seek": 104928, "start": 1049.28, "end": 1067.56, "text": " it's just sequential.", "tokens": [309, 311, 445, 42881, 13], "temperature": 0.0, "avg_logprob": -0.24699556827545166, "compression_ratio": 1.380281690140845, "no_speech_prob": 7.568271394120529e-05}, {"id": 210, "seek": 104928, "start": 1067.56, "end": 1073.48, "text": " Aggregation happens at the VTGate level, he has a sorting layer, so before aggregation", "tokens": [41512, 20167, 2314, 412, 264, 691, 51, 38, 473, 1496, 11, 415, 575, 257, 32411, 4583, 11, 370, 949, 16743, 399], "temperature": 0.0, "avg_logprob": -0.24699556827545166, "compression_ratio": 1.380281690140845, "no_speech_prob": 7.568271394120529e-05}, {"id": 211, "seek": 104928, "start": 1073.48, "end": 1078.92, "text": " we have to sort, yes, that's what it was there in the diagram as well, that after joint", "tokens": [321, 362, 281, 1333, 11, 2086, 11, 300, 311, 437, 309, 390, 456, 294, 264, 10686, 382, 731, 11, 300, 934, 7225], "temperature": 0.0, "avg_logprob": -0.24699556827545166, "compression_ratio": 1.380281690140845, "no_speech_prob": 7.568271394120529e-05}, {"id": 212, "seek": 107892, "start": 1078.92, "end": 1083.8000000000002, "text": " there was sort layer, because you have to sort, so we have an in-memory sort, so there", "tokens": [456, 390, 1333, 4583, 11, 570, 291, 362, 281, 1333, 11, 370, 321, 362, 364, 294, 12, 17886, 827, 1333, 11, 370, 456], "temperature": 0.0, "avg_logprob": -0.19806809023202185, "compression_ratio": 1.7470588235294118, "no_speech_prob": 0.00020248210057616234}, {"id": 213, "seek": 107892, "start": 1083.8000000000002, "end": 1091.0800000000002, "text": " are multiple again sort based on what we can do the best, so there's a merge sort also", "tokens": [366, 3866, 797, 1333, 2361, 322, 437, 321, 393, 360, 264, 1151, 11, 370, 456, 311, 257, 22183, 1333, 611], "temperature": 0.0, "avg_logprob": -0.19806809023202185, "compression_ratio": 1.7470588235294118, "no_speech_prob": 0.00020248210057616234}, {"id": 214, "seek": 107892, "start": 1091.0800000000002, "end": 1096.5600000000002, "text": " and then you have a complete sort as well, based on what can we do best.", "tokens": [293, 550, 291, 362, 257, 3566, 1333, 382, 731, 11, 2361, 322, 437, 393, 321, 360, 1151, 13], "temperature": 0.0, "avg_logprob": -0.19806809023202185, "compression_ratio": 1.7470588235294118, "no_speech_prob": 0.00020248210057616234}, {"id": 215, "seek": 107892, "start": 1096.5600000000002, "end": 1104.8000000000002, "text": " And then sorting, then it goes to the aggregation.", "tokens": [400, 550, 32411, 11, 550, 309, 1709, 281, 264, 16743, 399, 13], "temperature": 0.0, "avg_logprob": -0.19806809023202185, "compression_ratio": 1.7470588235294118, "no_speech_prob": 0.00020248210057616234}, {"id": 216, "seek": 110480, "start": 1104.8, "end": 1119.9199999999998, "text": " So that's why we said we try to push as much as with MySQL, so we actually push the sort", "tokens": [407, 300, 311, 983, 321, 848, 321, 853, 281, 2944, 382, 709, 382, 365, 1222, 39934, 11, 370, 321, 767, 2944, 264, 1333], "temperature": 0.0, "avg_logprob": -0.25380621729670344, "compression_ratio": 1.5950920245398772, "no_speech_prob": 0.00013286194007378072}, {"id": 217, "seek": 110480, "start": 1119.9199999999998, "end": 1124.36, "text": " as well to MySQL if possible for the merge sort, but if you do it in the memory then", "tokens": [382, 731, 281, 1222, 39934, 498, 1944, 337, 264, 22183, 1333, 11, 457, 498, 291, 360, 309, 294, 264, 4675, 550], "temperature": 0.0, "avg_logprob": -0.25380621729670344, "compression_ratio": 1.5950920245398772, "no_speech_prob": 0.00013286194007378072}, {"id": 218, "seek": 110480, "start": 1124.36, "end": 1130.24, "text": " we still sort it, so it depends whether we can push it down or not, if you are able to", "tokens": [321, 920, 1333, 309, 11, 370, 309, 5946, 1968, 321, 393, 2944, 309, 760, 420, 406, 11, 498, 291, 366, 1075, 281], "temperature": 0.0, "avg_logprob": -0.25380621729670344, "compression_ratio": 1.5950920245398772, "no_speech_prob": 0.00013286194007378072}, {"id": 219, "seek": 113024, "start": 1130.24, "end": 1152.4, "text": " push it down we push as much as to the MySQL, yes, thank you, all right I think we have", "tokens": [2944, 309, 760, 321, 2944, 382, 709, 382, 281, 264, 1222, 39934, 11, 2086, 11, 1309, 291, 11, 439, 558, 286, 519, 321, 362], "temperature": 0.0, "avg_logprob": -0.37320572989327566, "compression_ratio": 1.0481927710843373, "no_speech_prob": 6.99589800206013e-05}, {"id": 220, "seek": 115240, "start": 1152.4, "end": 1168.7800000000002, "text": " a question, thank you very much, thank you.", "tokens": [257, 1168, 11, 1309, 291, 588, 709, 11, 1309, 291, 13], "temperature": 1.0, "avg_logprob": -0.9797459284464518, "compression_ratio": 1.0238095238095237, "no_speech_prob": 0.0021389713510870934}, {"id": 221, "seek": 116878, "start": 1168.78, "end": 1170.78, "text": " You", "tokens": [50364, 509, 50464], "temperature": 0.0, "avg_logprob": -0.8680161237716675, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.8395225405693054}], "language": "en"}