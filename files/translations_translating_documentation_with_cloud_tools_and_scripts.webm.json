{"text": " Okay. So, good afternoon. I'm Nilo Menezes, and I would like to share some scripts, and after all these presentations we had this afternoon, quick hacks that I need to implement while translating a NIN document, how Python developers could use NIN on the wiki. Okay, so I will explain it better later on. So, translation documentations with cloud tools and scripts. So, how it started, we had a document called NIN for Python programmers that was written in English and Spanish by the same author. And this document is simply a translation table from Python to NIN. So, if you already know how to write Python programs, you can read this document and it will explain, okay, this is a structure you have to write that way and so on and so on. But it was written by the same developer in English and Spanish in a wiki format using the markdown, and it's the wiki of GitHub. So, in the Brazilian NIN group, when people started to say, hey, it would be useful to get more users to the NIN language, if we had this document, NIN for Python programmers, also translated in Brazilian Portuguese. And then I said, okay, I did some translations before, I think I can help on this. So, I started checking how I could do the contribution. So, I went to the GitHub wiki, I saw that the source code was in markdown format. I just checked it out on Git, and I started translating. Just after the table of contents, I said, this will not end very well. I will have lots of problems later on because this document will be changed, it will be updated, nobody will tell me that the original was updated. And in a document, you can also move sections and do different things. So, I said, this is not a good start. So, the idea was, how can I help translating but also building an initial infrastructure to help translating this document to other languages, okay? So, how they were doing, they just cloned the English page, and they started writing, overwriting the text in the native language, okay? If you are the same author, it's fine. So, he wrote the English version, he also translated to Spanish. Three or four languages, I think it's still workable, but if you start to have as many languages as we saw in very big projects, you know that it's impossible to keep up to date. So, I started to think about how can I update this? And I had the previous experience of working with translations in PO files, using PO files for Lin City, and also translations like December how to, and in very old document formats where we really have to translate copy and translate. But the PO format started to be very interesting, because I said, if I managed to convert this markdown to PO and create a process around it, then we'll be back to the standard translation process where we can use PO edit, for example, to do the translation and move on. So, I will report what I did and the tools I selected for doing this job. As I said, it looked very much like an old problem. So, how to translate software to another language? The PO and get text combinations is very, very good. It's easy to use. Even if it's the first time you are translating software to just tag the text you want to be translated using get text, it's relatively easy. But I wasn't working with source code, I was working with markdown. And the markdown, you also have some extra markers regarding the text formatting and very specific items that I didn't want to spend time creating a converter from markdown to the PO file format. Of course, I started searching, I found some tools. But not all tools support the same kind of markdown as the GitHub markdown. And also, they create PO files with different qualities. So, I spent some time tweaking. So, if you're never working with the PO file, it looks like this. You have a message ID that is usually the original string and you have the message string that is the translated one. And you create a new file for each language you are working on. So, usually English is the base language. And then you create a PO file for Portuguese, another for Spanish, and so on. Prerestanda, I think most of the afternoon we heard about PO. So, I think it was a good idea to keep this format. So, this was the process if we were translating standard source code. So, we have the source file, we extract the PO file. Using the PO file, we use a translation tool or an editor to do the translation manually, string by string. After that, we compile the ML file and the executables or the script can use the ML file and present the text translated to the end user. So, I just needed to adapt this for markdown. And there is also a very special point regarding how the wiki is kept on GitHub that I will explain later. So, how to convert markdown, this specific for GitHub markdown to the PO file. And also, I started to test multiple packages because as I said, if you Google, you find many converters from markdown to PO file, I think I tested two or three. I didn't rule down each one, but the final one is MD-PO. There is a library, a series of Python scripts, so it would be, it is much more easier for me to use packages in the same language because I could just write a PyProject and put all these libraries in the same PyProject. The previous one was in Java, JavaScript. And you know, if you want to run something in JavaScript, especially if you are not using Linux, you need to install a lot of other software. So, this would enable the translation from markdown to PO and vice versa because this is the hardest part. Once you transform the markdown file into a PO file, you do the translation, but the main objective is to get a translated markdown file back so you can use it in GitHub and present the page in your native language with all the formatting that the original auto did before. Okay. And I also started to think, okay, maybe I can write another script that you manipulate the PO file and help me do the initial translation. Why? We have a series of tools for automatic translation, but of course, this was something I just started. I didn't have the integrations or anything like this, but I also didn't want to mess with the PO file itself. So, I found a Python library called POlib that does exactly this. I can open a PO file. I can, for example, do some filtering, like, okay, give me just the strings that are not yet translated, and so it's very, very easy to build and manipulate the PO files with it. Okay. So, this is the example problem, program. You simply open the file, we start the translation, and with the help with AWS translator that I was using because most of the time I work with AWS, I could easily send string by string to the cloud and get an initial translation that I would just review later on. Okay. Because you can never trust the automatic translation, especially if you are working phrase by phrase, it's very easy to miss your target. But it's very good nowadays. So, I would say at least 80% of everything you do in the automatic translation, you can keep as it is, but you still have to fix the 20%, and most of the times the 20% is quite embarrassing. So, you really need to review and double check before you publish anything. And as it's a paid service, as many translation services, and as our colleague, I didn't know the delivery translator that was presented this afternoon, you don't want to pay every time you do this. So, I use the previous script to create a list of the strings that were never translated, they were still empty. So, I know that if I run it multiple times, I will not be bugging AWS translator and paying for the translation of strings that are already translated or reviewed. Okay. And as you can see, the script is very simple. You open the PO file, you send the text to the cloud, in this case, AWS translate. You save, you replace the string and you save it in the new PO file, it's done. Okay. So, the script is almost out of this. You have it complete on GitHub. And this is the main job. Another advantage of these tools is that you can create a list of words that should not be translated. And this helps a lot, especially if you have a product or a document with a common name, that is, that you don't want to be translated. So, you can pass these special lists, you can create some exceptions. But as was explaining in the previous presentation, it's also a problem because as we, most of the time, we select English as the main or the source translation language, you cannot create exclusion lists using programming languages, keywords. So, in this document, Python, name for Python programmers, of course, there are lots of source code and we're not translated to Portuguese, for example, keywords like for, in, we're all translated to Portuguese. So, by using the automatic translation engine, you have to review and revert this translation, so the translated program will continue to be valid. And you have to pay very close attention, because of course, you also translate variable names if you have source code in the document. So, you need to pay attention that the output is still coherent, okay? And of course, as you need to do this manual work, you can use a PO edit tool or any other tool that you are used to use to work with PO files. So, here we have the English version and there we have the Brazilian Portuguese version. I could just step item by item and reveal these translations until I was satisfied with the result and then you can simply regenerate the markdown file from the PO file, okay? So, we started with the markdown source code, we tracked using AMD PO to create the initial PO file. I ran the script that sends the untranslated strings to AWS translate, but you can use any provider you want. You review with PO edit and you do the opposite conversion from PO file to markdown and publish the wiki, okay? So, this is the workflow I tried to implement using my collection of scripts or hacks. It is not really a tool, but with the intention to facilitate a single markdown file translation, okay? So, the document looks like this. This is the English version. Yes, I put the English, no, this is the Portuguese one, okay? So, in the end, I could publish this document in GitHub. It's not yet fully integrated with the GitHub wiki because ideally, I should put the GitHub wiki of this documentation as a sub module of my project. So, when I updated it, I also get the newest version of the markdown and if I do this kind of integration using GitHub, you'll be able to publish the markdown file also using GitHub. For this initial version, I just went to the editor and I paste the markdown file, but it's possible to do the integration. It's the next step that I still have to do. So, I published the scripts in this GitHub. So, it's an info Python programmer. It's useful for any markdown file. You may want to apply the same workflow. And the page is in beta because I asked all the translators, all the people that can read Brazilian Portuguese to check if everything is fine. Because the main goal to have a process is that usually, you never do the translation a single time. The translation is something that you need to keep alive. As soon as the English version is extended, translated, updated, you have to do the same thing in Portuguese. If you don't have an automatic process able to license this document and present a subset of changes, you'll be obliged to review a full document and this can be very, very cumbersome over time if the document has 15, 20 pages. So, it's not ideal. And another advantage is that the tool is smart enough to detect repetitions of the same stream. So, you also, you don't have the boring work to re-translate the same text multiple times. This also saves a lot of time. Yes. So, these are the main findings and the main problems I try to solve. And that's it if you have any questions. You can say. My phrase. Yes. So, it's much easier and especially if your text has source code because the challenge was the source code. And sometimes you have to keep the indentation and so on and so on. You don't want to pass the indentation mess to the translator. So, if you use a tool like this, it will structure just the part of the program with text. And if you keep the white space, which is very important in Python, so you can translate. But you still have to pay attention because of the automatic translation to translate everything to the target language. So, you have to revert the keywords. But at least the generation is quite strong. So, when you have generated this, the program is still a correct program in the end. So, it's good. Okay. I think it's the last one. Okay. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.88, "text": " Okay. So, good afternoon. I'm Nilo Menezes, and I would like to share some scripts, and", "tokens": [1033, 13, 407, 11, 665, 6499, 13, 286, 478, 426, 10720, 376, 1450, 12214, 11, 293, 286, 576, 411, 281, 2073, 512, 23294, 11, 293], "temperature": 0.0, "avg_logprob": -0.3445696729294797, "compression_ratio": 1.3208955223880596, "no_speech_prob": 0.2932557761669159}, {"id": 1, "seek": 0, "start": 13.88, "end": 25.6, "text": " after all these presentations we had this afternoon, quick hacks that I need to implement", "tokens": [934, 439, 613, 18964, 321, 632, 341, 6499, 11, 1702, 33617, 300, 286, 643, 281, 4445], "temperature": 0.0, "avg_logprob": -0.3445696729294797, "compression_ratio": 1.3208955223880596, "no_speech_prob": 0.2932557761669159}, {"id": 2, "seek": 2560, "start": 25.6, "end": 38.04, "text": " while translating a NIN document, how Python developers could use NIN on the wiki. Okay,", "tokens": [1339, 35030, 257, 426, 1464, 4166, 11, 577, 15329, 8849, 727, 764, 426, 1464, 322, 264, 261, 9850, 13, 1033, 11], "temperature": 0.0, "avg_logprob": -0.2472967001108023, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.0006024157628417015}, {"id": 3, "seek": 2560, "start": 38.04, "end": 42.88, "text": " so I will explain it better later on. So, translation documentations with cloud tools", "tokens": [370, 286, 486, 2903, 309, 1101, 1780, 322, 13, 407, 11, 12853, 4166, 763, 365, 4588, 3873], "temperature": 0.0, "avg_logprob": -0.2472967001108023, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.0006024157628417015}, {"id": 4, "seek": 2560, "start": 42.88, "end": 50.480000000000004, "text": " and scripts. So, how it started, we had a document called NIN for Python programmers", "tokens": [293, 23294, 13, 407, 11, 577, 309, 1409, 11, 321, 632, 257, 4166, 1219, 426, 1464, 337, 15329, 41504], "temperature": 0.0, "avg_logprob": -0.2472967001108023, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.0006024157628417015}, {"id": 5, "seek": 5048, "start": 50.48, "end": 57.68, "text": " that was written in English and Spanish by the same author. And this document is simply", "tokens": [300, 390, 3720, 294, 3669, 293, 8058, 538, 264, 912, 3793, 13, 400, 341, 4166, 307, 2935], "temperature": 0.0, "avg_logprob": -0.1767865405993515, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.0007591323810629547}, {"id": 6, "seek": 5048, "start": 57.68, "end": 66.39999999999999, "text": " a translation table from Python to NIN. So, if you already know how to write Python programs,", "tokens": [257, 12853, 3199, 490, 15329, 281, 426, 1464, 13, 407, 11, 498, 291, 1217, 458, 577, 281, 2464, 15329, 4268, 11], "temperature": 0.0, "avg_logprob": -0.1767865405993515, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.0007591323810629547}, {"id": 7, "seek": 5048, "start": 66.39999999999999, "end": 71.67999999999999, "text": " you can read this document and it will explain, okay, this is a structure you have to write", "tokens": [291, 393, 1401, 341, 4166, 293, 309, 486, 2903, 11, 1392, 11, 341, 307, 257, 3877, 291, 362, 281, 2464], "temperature": 0.0, "avg_logprob": -0.1767865405993515, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.0007591323810629547}, {"id": 8, "seek": 5048, "start": 71.67999999999999, "end": 79.36, "text": " that way and so on and so on. But it was written by the same developer in English and Spanish", "tokens": [300, 636, 293, 370, 322, 293, 370, 322, 13, 583, 309, 390, 3720, 538, 264, 912, 10754, 294, 3669, 293, 8058], "temperature": 0.0, "avg_logprob": -0.1767865405993515, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.0007591323810629547}, {"id": 9, "seek": 7936, "start": 79.36, "end": 88.4, "text": " in a wiki format using the markdown, and it's the wiki of GitHub. So, in the Brazilian NIN", "tokens": [294, 257, 261, 9850, 7877, 1228, 264, 1491, 5093, 11, 293, 309, 311, 264, 261, 9850, 295, 23331, 13, 407, 11, 294, 264, 23435, 426, 1464], "temperature": 0.0, "avg_logprob": -0.18976553690802192, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.0002060404367512092}, {"id": 10, "seek": 7936, "start": 88.4, "end": 95.24, "text": " group, when people started to say, hey, it would be useful to get more users to the NIN", "tokens": [1594, 11, 562, 561, 1409, 281, 584, 11, 4177, 11, 309, 576, 312, 4420, 281, 483, 544, 5022, 281, 264, 426, 1464], "temperature": 0.0, "avg_logprob": -0.18976553690802192, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.0002060404367512092}, {"id": 11, "seek": 7936, "start": 95.24, "end": 100.52, "text": " language, if we had this document, NIN for Python programmers, also translated in Brazilian", "tokens": [2856, 11, 498, 321, 632, 341, 4166, 11, 426, 1464, 337, 15329, 41504, 11, 611, 16805, 294, 23435], "temperature": 0.0, "avg_logprob": -0.18976553690802192, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.0002060404367512092}, {"id": 12, "seek": 7936, "start": 100.52, "end": 106.96000000000001, "text": " Portuguese. And then I said, okay, I did some translations before, I think I can help on", "tokens": [22759, 13, 400, 550, 286, 848, 11, 1392, 11, 286, 630, 512, 37578, 949, 11, 286, 519, 286, 393, 854, 322], "temperature": 0.0, "avg_logprob": -0.18976553690802192, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.0002060404367512092}, {"id": 13, "seek": 10696, "start": 106.96, "end": 113.19999999999999, "text": " this. So, I started checking how I could do the contribution. So, I went to the GitHub", "tokens": [341, 13, 407, 11, 286, 1409, 8568, 577, 286, 727, 360, 264, 13150, 13, 407, 11, 286, 1437, 281, 264, 23331], "temperature": 0.0, "avg_logprob": -0.18450560777083688, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00033057580003514886}, {"id": 14, "seek": 10696, "start": 113.19999999999999, "end": 122.55999999999999, "text": " wiki, I saw that the source code was in markdown format. I just checked it out on Git, and", "tokens": [261, 9850, 11, 286, 1866, 300, 264, 4009, 3089, 390, 294, 1491, 5093, 7877, 13, 286, 445, 10033, 309, 484, 322, 16939, 11, 293], "temperature": 0.0, "avg_logprob": -0.18450560777083688, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00033057580003514886}, {"id": 15, "seek": 10696, "start": 122.55999999999999, "end": 128.44, "text": " I started translating. Just after the table of contents, I said, this will not end very", "tokens": [286, 1409, 35030, 13, 1449, 934, 264, 3199, 295, 15768, 11, 286, 848, 11, 341, 486, 406, 917, 588], "temperature": 0.0, "avg_logprob": -0.18450560777083688, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00033057580003514886}, {"id": 16, "seek": 10696, "start": 128.44, "end": 132.32, "text": " well. I will have lots of problems later on because this document will be changed, it", "tokens": [731, 13, 286, 486, 362, 3195, 295, 2740, 1780, 322, 570, 341, 4166, 486, 312, 3105, 11, 309], "temperature": 0.0, "avg_logprob": -0.18450560777083688, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00033057580003514886}, {"id": 17, "seek": 13232, "start": 132.32, "end": 138.84, "text": " will be updated, nobody will tell me that the original was updated. And in a document,", "tokens": [486, 312, 10588, 11, 5079, 486, 980, 385, 300, 264, 3380, 390, 10588, 13, 400, 294, 257, 4166, 11], "temperature": 0.0, "avg_logprob": -0.14891964890236079, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.00010968002607114613}, {"id": 18, "seek": 13232, "start": 138.84, "end": 145.44, "text": " you can also move sections and do different things. So, I said, this is not a good start.", "tokens": [291, 393, 611, 1286, 10863, 293, 360, 819, 721, 13, 407, 11, 286, 848, 11, 341, 307, 406, 257, 665, 722, 13], "temperature": 0.0, "avg_logprob": -0.14891964890236079, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.00010968002607114613}, {"id": 19, "seek": 13232, "start": 145.44, "end": 153.79999999999998, "text": " So, the idea was, how can I help translating but also building an initial infrastructure", "tokens": [407, 11, 264, 1558, 390, 11, 577, 393, 286, 854, 35030, 457, 611, 2390, 364, 5883, 6896], "temperature": 0.0, "avg_logprob": -0.14891964890236079, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.00010968002607114613}, {"id": 20, "seek": 13232, "start": 153.79999999999998, "end": 161.44, "text": " to help translating this document to other languages, okay? So, how they were doing,", "tokens": [281, 854, 35030, 341, 4166, 281, 661, 8650, 11, 1392, 30, 407, 11, 577, 436, 645, 884, 11], "temperature": 0.0, "avg_logprob": -0.14891964890236079, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.00010968002607114613}, {"id": 21, "seek": 16144, "start": 161.44, "end": 166.44, "text": " they just cloned the English page, and they started writing, overwriting the text in the", "tokens": [436, 445, 596, 19009, 264, 3669, 3028, 11, 293, 436, 1409, 3579, 11, 670, 19868, 264, 2487, 294, 264], "temperature": 0.0, "avg_logprob": -0.1610034691108452, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0001435232989024371}, {"id": 22, "seek": 16144, "start": 166.44, "end": 172.56, "text": " native language, okay? If you are the same author, it's fine. So, he wrote the English", "tokens": [8470, 2856, 11, 1392, 30, 759, 291, 366, 264, 912, 3793, 11, 309, 311, 2489, 13, 407, 11, 415, 4114, 264, 3669], "temperature": 0.0, "avg_logprob": -0.1610034691108452, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0001435232989024371}, {"id": 23, "seek": 16144, "start": 172.56, "end": 178.8, "text": " version, he also translated to Spanish. Three or four languages, I think it's still workable,", "tokens": [3037, 11, 415, 611, 16805, 281, 8058, 13, 6244, 420, 1451, 8650, 11, 286, 519, 309, 311, 920, 589, 712, 11], "temperature": 0.0, "avg_logprob": -0.1610034691108452, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0001435232989024371}, {"id": 24, "seek": 16144, "start": 178.8, "end": 184.12, "text": " but if you start to have as many languages as we saw in very big projects, you know", "tokens": [457, 498, 291, 722, 281, 362, 382, 867, 8650, 382, 321, 1866, 294, 588, 955, 4455, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.1610034691108452, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0001435232989024371}, {"id": 25, "seek": 18412, "start": 184.12, "end": 191.52, "text": " that it's impossible to keep up to date. So, I started to think about how can I update", "tokens": [300, 309, 311, 6243, 281, 1066, 493, 281, 4002, 13, 407, 11, 286, 1409, 281, 519, 466, 577, 393, 286, 5623], "temperature": 0.0, "avg_logprob": -0.26775309551193055, "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.000447528378572315}, {"id": 26, "seek": 18412, "start": 191.52, "end": 197.44, "text": " this? And I had the previous experience of working with translations in PO files, using", "tokens": [341, 30, 400, 286, 632, 264, 3894, 1752, 295, 1364, 365, 37578, 294, 22299, 7098, 11, 1228], "temperature": 0.0, "avg_logprob": -0.26775309551193055, "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.000447528378572315}, {"id": 27, "seek": 18412, "start": 197.44, "end": 204.56, "text": " PO files for Lin City, and also translations like December how to, and in very old document", "tokens": [22299, 7098, 337, 9355, 4392, 11, 293, 611, 37578, 411, 7687, 577, 281, 11, 293, 294, 588, 1331, 4166], "temperature": 0.0, "avg_logprob": -0.26775309551193055, "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.000447528378572315}, {"id": 28, "seek": 18412, "start": 204.56, "end": 213.8, "text": " formats where we really have to translate copy and translate. But the PO format started", "tokens": [25879, 689, 321, 534, 362, 281, 13799, 5055, 293, 13799, 13, 583, 264, 22299, 7877, 1409], "temperature": 0.0, "avg_logprob": -0.26775309551193055, "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.000447528378572315}, {"id": 29, "seek": 21380, "start": 213.8, "end": 219.96, "text": " to be very interesting, because I said, if I managed to convert this markdown to PO", "tokens": [281, 312, 588, 1880, 11, 570, 286, 848, 11, 498, 286, 6453, 281, 7620, 341, 1491, 5093, 281, 22299], "temperature": 0.0, "avg_logprob": -0.1491422438889407, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.00012123350461479276}, {"id": 30, "seek": 21380, "start": 219.96, "end": 225.48000000000002, "text": " and create a process around it, then we'll be back to the standard translation process", "tokens": [293, 1884, 257, 1399, 926, 309, 11, 550, 321, 603, 312, 646, 281, 264, 3832, 12853, 1399], "temperature": 0.0, "avg_logprob": -0.1491422438889407, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.00012123350461479276}, {"id": 31, "seek": 21380, "start": 225.48000000000002, "end": 230.8, "text": " where we can use PO edit, for example, to do the translation and move on. So, I will", "tokens": [689, 321, 393, 764, 22299, 8129, 11, 337, 1365, 11, 281, 360, 264, 12853, 293, 1286, 322, 13, 407, 11, 286, 486], "temperature": 0.0, "avg_logprob": -0.1491422438889407, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.00012123350461479276}, {"id": 32, "seek": 21380, "start": 230.8, "end": 239.76000000000002, "text": " report what I did and the tools I selected for doing this job. As I said, it looked very", "tokens": [2275, 437, 286, 630, 293, 264, 3873, 286, 8209, 337, 884, 341, 1691, 13, 1018, 286, 848, 11, 309, 2956, 588], "temperature": 0.0, "avg_logprob": -0.1491422438889407, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.00012123350461479276}, {"id": 33, "seek": 23976, "start": 239.76, "end": 244.76, "text": " much like an old problem. So, how to translate software to another language? The PO and get", "tokens": [709, 411, 364, 1331, 1154, 13, 407, 11, 577, 281, 13799, 4722, 281, 1071, 2856, 30, 440, 22299, 293, 483], "temperature": 0.0, "avg_logprob": -0.20237998962402343, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0003745341091416776}, {"id": 34, "seek": 23976, "start": 244.76, "end": 250.95999999999998, "text": " text combinations is very, very good. It's easy to use. Even if it's the first time you", "tokens": [2487, 21267, 307, 588, 11, 588, 665, 13, 467, 311, 1858, 281, 764, 13, 2754, 498, 309, 311, 264, 700, 565, 291], "temperature": 0.0, "avg_logprob": -0.20237998962402343, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0003745341091416776}, {"id": 35, "seek": 23976, "start": 250.95999999999998, "end": 258.28, "text": " are translating software to just tag the text you want to be translated using get text,", "tokens": [366, 35030, 4722, 281, 445, 6162, 264, 2487, 291, 528, 281, 312, 16805, 1228, 483, 2487, 11], "temperature": 0.0, "avg_logprob": -0.20237998962402343, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0003745341091416776}, {"id": 36, "seek": 23976, "start": 258.28, "end": 265.03999999999996, "text": " it's relatively easy. But I wasn't working with source code, I was working with markdown.", "tokens": [309, 311, 7226, 1858, 13, 583, 286, 2067, 380, 1364, 365, 4009, 3089, 11, 286, 390, 1364, 365, 1491, 5093, 13], "temperature": 0.0, "avg_logprob": -0.20237998962402343, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0003745341091416776}, {"id": 37, "seek": 26504, "start": 265.04, "end": 273.88, "text": " And the markdown, you also have some extra markers regarding the text formatting and very", "tokens": [400, 264, 1491, 5093, 11, 291, 611, 362, 512, 2857, 19175, 8595, 264, 2487, 39366, 293, 588], "temperature": 0.0, "avg_logprob": -0.1329578459262848, "compression_ratio": 1.5, "no_speech_prob": 0.0005541005521081388}, {"id": 38, "seek": 26504, "start": 273.88, "end": 279.64000000000004, "text": " specific items that I didn't want to spend time creating a converter from markdown to", "tokens": [2685, 4754, 300, 286, 994, 380, 528, 281, 3496, 565, 4084, 257, 33905, 490, 1491, 5093, 281], "temperature": 0.0, "avg_logprob": -0.1329578459262848, "compression_ratio": 1.5, "no_speech_prob": 0.0005541005521081388}, {"id": 39, "seek": 26504, "start": 279.64000000000004, "end": 288.28000000000003, "text": " the PO file format. Of course, I started searching, I found some tools. But not all tools support", "tokens": [264, 22299, 3991, 7877, 13, 2720, 1164, 11, 286, 1409, 10808, 11, 286, 1352, 512, 3873, 13, 583, 406, 439, 3873, 1406], "temperature": 0.0, "avg_logprob": -0.1329578459262848, "compression_ratio": 1.5, "no_speech_prob": 0.0005541005521081388}, {"id": 40, "seek": 28828, "start": 288.28, "end": 296.44, "text": " the same kind of markdown as the GitHub markdown. And also, they create PO files with different", "tokens": [264, 912, 733, 295, 1491, 5093, 382, 264, 23331, 1491, 5093, 13, 400, 611, 11, 436, 1884, 22299, 7098, 365, 819], "temperature": 0.0, "avg_logprob": -0.14316585037734483, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0003685686970129609}, {"id": 41, "seek": 28828, "start": 296.44, "end": 302.59999999999997, "text": " qualities. So, I spent some time tweaking. So, if you're never working with the PO file,", "tokens": [16477, 13, 407, 11, 286, 4418, 512, 565, 6986, 2456, 13, 407, 11, 498, 291, 434, 1128, 1364, 365, 264, 22299, 3991, 11], "temperature": 0.0, "avg_logprob": -0.14316585037734483, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0003685686970129609}, {"id": 42, "seek": 28828, "start": 302.59999999999997, "end": 307.76, "text": " it looks like this. You have a message ID that is usually the original string and you", "tokens": [309, 1542, 411, 341, 13, 509, 362, 257, 3636, 7348, 300, 307, 2673, 264, 3380, 6798, 293, 291], "temperature": 0.0, "avg_logprob": -0.14316585037734483, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0003685686970129609}, {"id": 43, "seek": 28828, "start": 307.76, "end": 312.79999999999995, "text": " have the message string that is the translated one. And you create a new file for each language", "tokens": [362, 264, 3636, 6798, 300, 307, 264, 16805, 472, 13, 400, 291, 1884, 257, 777, 3991, 337, 1184, 2856], "temperature": 0.0, "avg_logprob": -0.14316585037734483, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0003685686970129609}, {"id": 44, "seek": 31280, "start": 312.8, "end": 319.48, "text": " you are working on. So, usually English is the base language. And then you create a PO", "tokens": [291, 366, 1364, 322, 13, 407, 11, 2673, 3669, 307, 264, 3096, 2856, 13, 400, 550, 291, 1884, 257, 22299], "temperature": 0.0, "avg_logprob": -0.24287623355263158, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.0004002475761808455}, {"id": 45, "seek": 31280, "start": 319.48, "end": 326.48, "text": " file for Portuguese, another for Spanish, and so on. Prerestanda, I think most of the", "tokens": [3991, 337, 22759, 11, 1071, 337, 8058, 11, 293, 370, 322, 13, 2114, 323, 1115, 64, 11, 286, 519, 881, 295, 264], "temperature": 0.0, "avg_logprob": -0.24287623355263158, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.0004002475761808455}, {"id": 46, "seek": 31280, "start": 326.48, "end": 334.68, "text": " afternoon we heard about PO. So, I think it was a good idea to keep this format. So, this", "tokens": [6499, 321, 2198, 466, 22299, 13, 407, 11, 286, 519, 309, 390, 257, 665, 1558, 281, 1066, 341, 7877, 13, 407, 11, 341], "temperature": 0.0, "avg_logprob": -0.24287623355263158, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.0004002475761808455}, {"id": 47, "seek": 31280, "start": 334.68, "end": 341.76, "text": " was the process if we were translating standard source code. So, we have the source file, we", "tokens": [390, 264, 1399, 498, 321, 645, 35030, 3832, 4009, 3089, 13, 407, 11, 321, 362, 264, 4009, 3991, 11, 321], "temperature": 0.0, "avg_logprob": -0.24287623355263158, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.0004002475761808455}, {"id": 48, "seek": 34176, "start": 341.76, "end": 351.03999999999996, "text": " extract the PO file. Using the PO file, we use a translation tool or an editor to do", "tokens": [8947, 264, 22299, 3991, 13, 11142, 264, 22299, 3991, 11, 321, 764, 257, 12853, 2290, 420, 364, 9839, 281, 360], "temperature": 0.0, "avg_logprob": -0.17850850642412558, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00030315344338305295}, {"id": 49, "seek": 34176, "start": 351.03999999999996, "end": 356.88, "text": " the translation manually, string by string. After that, we compile the ML file and the", "tokens": [264, 12853, 16945, 11, 6798, 538, 6798, 13, 2381, 300, 11, 321, 31413, 264, 21601, 3991, 293, 264], "temperature": 0.0, "avg_logprob": -0.17850850642412558, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00030315344338305295}, {"id": 50, "seek": 34176, "start": 356.88, "end": 362.36, "text": " executables or the script can use the ML file and present the text translated to the end", "tokens": [7568, 2965, 420, 264, 5755, 393, 764, 264, 21601, 3991, 293, 1974, 264, 2487, 16805, 281, 264, 917], "temperature": 0.0, "avg_logprob": -0.17850850642412558, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00030315344338305295}, {"id": 51, "seek": 34176, "start": 362.36, "end": 368.68, "text": " user. So, I just needed to adapt this for markdown. And there is also a very special", "tokens": [4195, 13, 407, 11, 286, 445, 2978, 281, 6231, 341, 337, 1491, 5093, 13, 400, 456, 307, 611, 257, 588, 2121], "temperature": 0.0, "avg_logprob": -0.17850850642412558, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00030315344338305295}, {"id": 52, "seek": 36868, "start": 368.68, "end": 377.64, "text": " point regarding how the wiki is kept on GitHub that I will explain later. So, how to convert", "tokens": [935, 8595, 577, 264, 261, 9850, 307, 4305, 322, 23331, 300, 286, 486, 2903, 1780, 13, 407, 11, 577, 281, 7620], "temperature": 0.0, "avg_logprob": -0.18557408927143484, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0006716071511618793}, {"id": 53, "seek": 36868, "start": 377.64, "end": 387.0, "text": " markdown, this specific for GitHub markdown to the PO file. And also, I started to test", "tokens": [1491, 5093, 11, 341, 2685, 337, 23331, 1491, 5093, 281, 264, 22299, 3991, 13, 400, 611, 11, 286, 1409, 281, 1500], "temperature": 0.0, "avg_logprob": -0.18557408927143484, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0006716071511618793}, {"id": 54, "seek": 36868, "start": 387.0, "end": 392.28000000000003, "text": " multiple packages because as I said, if you Google, you find many converters from markdown", "tokens": [3866, 17401, 570, 382, 286, 848, 11, 498, 291, 3329, 11, 291, 915, 867, 9652, 1559, 490, 1491, 5093], "temperature": 0.0, "avg_logprob": -0.18557408927143484, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0006716071511618793}, {"id": 55, "seek": 39228, "start": 392.28, "end": 399.71999999999997, "text": " to PO file, I think I tested two or three. I didn't rule down each one, but the final", "tokens": [281, 22299, 3991, 11, 286, 519, 286, 8246, 732, 420, 1045, 13, 286, 994, 380, 4978, 760, 1184, 472, 11, 457, 264, 2572], "temperature": 0.0, "avg_logprob": -0.218507058841666, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.0004147589497733861}, {"id": 56, "seek": 39228, "start": 399.71999999999997, "end": 408.52, "text": " one is MD-PO. There is a library, a series of Python scripts, so it would be, it is much", "tokens": [472, 307, 22521, 12, 34885, 13, 821, 307, 257, 6405, 11, 257, 2638, 295, 15329, 23294, 11, 370, 309, 576, 312, 11, 309, 307, 709], "temperature": 0.0, "avg_logprob": -0.218507058841666, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.0004147589497733861}, {"id": 57, "seek": 39228, "start": 408.52, "end": 414.59999999999997, "text": " more easier for me to use packages in the same language because I could just write a", "tokens": [544, 3571, 337, 385, 281, 764, 17401, 294, 264, 912, 2856, 570, 286, 727, 445, 2464, 257], "temperature": 0.0, "avg_logprob": -0.218507058841666, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.0004147589497733861}, {"id": 58, "seek": 39228, "start": 414.59999999999997, "end": 422.23999999999995, "text": " PyProject and put all these libraries in the same PyProject. The previous one was in Java,", "tokens": [9953, 12681, 1020, 293, 829, 439, 613, 15148, 294, 264, 912, 9953, 12681, 1020, 13, 440, 3894, 472, 390, 294, 10745, 11], "temperature": 0.0, "avg_logprob": -0.218507058841666, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.0004147589497733861}, {"id": 59, "seek": 42224, "start": 422.24, "end": 426.48, "text": " JavaScript. And you know, if you want to run something in JavaScript, especially if you", "tokens": [15778, 13, 400, 291, 458, 11, 498, 291, 528, 281, 1190, 746, 294, 15778, 11, 2318, 498, 291], "temperature": 0.0, "avg_logprob": -0.12381991431826637, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0002621990570332855}, {"id": 60, "seek": 42224, "start": 426.48, "end": 432.36, "text": " are not using Linux, you need to install a lot of other software. So, this would enable", "tokens": [366, 406, 1228, 18734, 11, 291, 643, 281, 3625, 257, 688, 295, 661, 4722, 13, 407, 11, 341, 576, 9528], "temperature": 0.0, "avg_logprob": -0.12381991431826637, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0002621990570332855}, {"id": 61, "seek": 42224, "start": 432.36, "end": 437.64, "text": " the translation from markdown to PO and vice versa because this is the hardest part. Once", "tokens": [264, 12853, 490, 1491, 5093, 281, 22299, 293, 11964, 25650, 570, 341, 307, 264, 13158, 644, 13, 3443], "temperature": 0.0, "avg_logprob": -0.12381991431826637, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0002621990570332855}, {"id": 62, "seek": 42224, "start": 437.64, "end": 445.16, "text": " you transform the markdown file into a PO file, you do the translation, but the main", "tokens": [291, 4088, 264, 1491, 5093, 3991, 666, 257, 22299, 3991, 11, 291, 360, 264, 12853, 11, 457, 264, 2135], "temperature": 0.0, "avg_logprob": -0.12381991431826637, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0002621990570332855}, {"id": 63, "seek": 42224, "start": 445.16, "end": 451.24, "text": " objective is to get a translated markdown file back so you can use it in GitHub and", "tokens": [10024, 307, 281, 483, 257, 16805, 1491, 5093, 3991, 646, 370, 291, 393, 764, 309, 294, 23331, 293], "temperature": 0.0, "avg_logprob": -0.12381991431826637, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0002621990570332855}, {"id": 64, "seek": 45124, "start": 451.24, "end": 456.8, "text": " present the page in your native language with all the formatting that the original auto", "tokens": [1974, 264, 3028, 294, 428, 8470, 2856, 365, 439, 264, 39366, 300, 264, 3380, 8399], "temperature": 0.0, "avg_logprob": -0.13539523170107887, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.00015812974015716463}, {"id": 65, "seek": 45124, "start": 456.8, "end": 467.16, "text": " did before. Okay. And I also started to think, okay, maybe I can write another script that", "tokens": [630, 949, 13, 1033, 13, 400, 286, 611, 1409, 281, 519, 11, 1392, 11, 1310, 286, 393, 2464, 1071, 5755, 300], "temperature": 0.0, "avg_logprob": -0.13539523170107887, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.00015812974015716463}, {"id": 66, "seek": 45124, "start": 467.16, "end": 476.68, "text": " you manipulate the PO file and help me do the initial translation. Why? We have a series", "tokens": [291, 20459, 264, 22299, 3991, 293, 854, 385, 360, 264, 5883, 12853, 13, 1545, 30, 492, 362, 257, 2638], "temperature": 0.0, "avg_logprob": -0.13539523170107887, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.00015812974015716463}, {"id": 67, "seek": 47668, "start": 476.68, "end": 485.04, "text": " of tools for automatic translation, but of course, this was something I just started.", "tokens": [295, 3873, 337, 12509, 12853, 11, 457, 295, 1164, 11, 341, 390, 746, 286, 445, 1409, 13], "temperature": 0.0, "avg_logprob": -0.1599548173987347, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0002917269885074347}, {"id": 68, "seek": 47668, "start": 485.04, "end": 490.24, "text": " I didn't have the integrations or anything like this, but I also didn't want to mess", "tokens": [286, 994, 380, 362, 264, 3572, 763, 420, 1340, 411, 341, 11, 457, 286, 611, 994, 380, 528, 281, 2082], "temperature": 0.0, "avg_logprob": -0.1599548173987347, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0002917269885074347}, {"id": 69, "seek": 47668, "start": 490.24, "end": 497.56, "text": " with the PO file itself. So, I found a Python library called POlib that does exactly this.", "tokens": [365, 264, 22299, 3991, 2564, 13, 407, 11, 286, 1352, 257, 15329, 6405, 1219, 22299, 38270, 300, 775, 2293, 341, 13], "temperature": 0.0, "avg_logprob": -0.1599548173987347, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0002917269885074347}, {"id": 70, "seek": 47668, "start": 497.56, "end": 502.92, "text": " I can open a PO file. I can, for example, do some filtering, like, okay, give me just", "tokens": [286, 393, 1269, 257, 22299, 3991, 13, 286, 393, 11, 337, 1365, 11, 360, 512, 30822, 11, 411, 11, 1392, 11, 976, 385, 445], "temperature": 0.0, "avg_logprob": -0.1599548173987347, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0002917269885074347}, {"id": 71, "seek": 50292, "start": 502.92, "end": 509.24, "text": " the strings that are not yet translated, and so it's very, very easy to build and manipulate", "tokens": [264, 13985, 300, 366, 406, 1939, 16805, 11, 293, 370, 309, 311, 588, 11, 588, 1858, 281, 1322, 293, 20459], "temperature": 0.0, "avg_logprob": -0.13670323404033533, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.0002573958190623671}, {"id": 72, "seek": 50292, "start": 509.24, "end": 517.24, "text": " the PO files with it. Okay. So, this is the example problem, program. You simply open", "tokens": [264, 22299, 7098, 365, 309, 13, 1033, 13, 407, 11, 341, 307, 264, 1365, 1154, 11, 1461, 13, 509, 2935, 1269], "temperature": 0.0, "avg_logprob": -0.13670323404033533, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.0002573958190623671}, {"id": 73, "seek": 50292, "start": 517.24, "end": 523.04, "text": " the file, we start the translation, and with the help with AWS translator that I was using", "tokens": [264, 3991, 11, 321, 722, 264, 12853, 11, 293, 365, 264, 854, 365, 17650, 35223, 300, 286, 390, 1228], "temperature": 0.0, "avg_logprob": -0.13670323404033533, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.0002573958190623671}, {"id": 74, "seek": 50292, "start": 523.04, "end": 530.24, "text": " because most of the time I work with AWS, I could easily send string by string to the", "tokens": [570, 881, 295, 264, 565, 286, 589, 365, 17650, 11, 286, 727, 3612, 2845, 6798, 538, 6798, 281, 264], "temperature": 0.0, "avg_logprob": -0.13670323404033533, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.0002573958190623671}, {"id": 75, "seek": 53024, "start": 530.24, "end": 536.8, "text": " cloud and get an initial translation that I would just review later on. Okay. Because", "tokens": [4588, 293, 483, 364, 5883, 12853, 300, 286, 576, 445, 3131, 1780, 322, 13, 1033, 13, 1436], "temperature": 0.0, "avg_logprob": -0.14299210734751033, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.00015707375132478774}, {"id": 76, "seek": 53024, "start": 536.8, "end": 543.76, "text": " you can never trust the automatic translation, especially if you are working phrase by phrase,", "tokens": [291, 393, 1128, 3361, 264, 12509, 12853, 11, 2318, 498, 291, 366, 1364, 9535, 538, 9535, 11], "temperature": 0.0, "avg_logprob": -0.14299210734751033, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.00015707375132478774}, {"id": 77, "seek": 53024, "start": 543.76, "end": 550.12, "text": " it's very easy to miss your target. But it's very good nowadays. So, I would say at least", "tokens": [309, 311, 588, 1858, 281, 1713, 428, 3779, 13, 583, 309, 311, 588, 665, 13434, 13, 407, 11, 286, 576, 584, 412, 1935], "temperature": 0.0, "avg_logprob": -0.14299210734751033, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.00015707375132478774}, {"id": 78, "seek": 53024, "start": 550.12, "end": 556.6800000000001, "text": " 80% of everything you do in the automatic translation, you can keep as it is, but you", "tokens": [4688, 4, 295, 1203, 291, 360, 294, 264, 12509, 12853, 11, 291, 393, 1066, 382, 309, 307, 11, 457, 291], "temperature": 0.0, "avg_logprob": -0.14299210734751033, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.00015707375132478774}, {"id": 79, "seek": 55668, "start": 556.68, "end": 561.4399999999999, "text": " still have to fix the 20%, and most of the times the 20% is quite embarrassing. So, you", "tokens": [920, 362, 281, 3191, 264, 945, 8923, 293, 881, 295, 264, 1413, 264, 945, 4, 307, 1596, 17299, 13, 407, 11, 291], "temperature": 0.0, "avg_logprob": -0.15768133039059845, "compression_ratio": 1.6, "no_speech_prob": 0.00029421201907098293}, {"id": 80, "seek": 55668, "start": 561.4399999999999, "end": 567.3199999999999, "text": " really need to review and double check before you publish anything. And as it's a paid service,", "tokens": [534, 643, 281, 3131, 293, 3834, 1520, 949, 291, 11374, 1340, 13, 400, 382, 309, 311, 257, 4835, 2643, 11], "temperature": 0.0, "avg_logprob": -0.15768133039059845, "compression_ratio": 1.6, "no_speech_prob": 0.00029421201907098293}, {"id": 81, "seek": 55668, "start": 567.3199999999999, "end": 574.68, "text": " as many translation services, and as our colleague, I didn't know the delivery translator that", "tokens": [382, 867, 12853, 3328, 11, 293, 382, 527, 13532, 11, 286, 994, 380, 458, 264, 8982, 35223, 300], "temperature": 0.0, "avg_logprob": -0.15768133039059845, "compression_ratio": 1.6, "no_speech_prob": 0.00029421201907098293}, {"id": 82, "seek": 55668, "start": 574.68, "end": 580.68, "text": " was presented this afternoon, you don't want to pay every time you do this. So, I use the", "tokens": [390, 8212, 341, 6499, 11, 291, 500, 380, 528, 281, 1689, 633, 565, 291, 360, 341, 13, 407, 11, 286, 764, 264], "temperature": 0.0, "avg_logprob": -0.15768133039059845, "compression_ratio": 1.6, "no_speech_prob": 0.00029421201907098293}, {"id": 83, "seek": 58068, "start": 580.68, "end": 587.76, "text": " previous script to create a list of the strings that were never translated, they were still", "tokens": [3894, 5755, 281, 1884, 257, 1329, 295, 264, 13985, 300, 645, 1128, 16805, 11, 436, 645, 920], "temperature": 0.0, "avg_logprob": -0.19610760428688742, "compression_ratio": 1.6126126126126126, "no_speech_prob": 0.0002434274210827425}, {"id": 84, "seek": 58068, "start": 587.76, "end": 593.8399999999999, "text": " empty. So, I know that if I run it multiple times, I will not be bugging AWS translator", "tokens": [6707, 13, 407, 11, 286, 458, 300, 498, 286, 1190, 309, 3866, 1413, 11, 286, 486, 406, 312, 7426, 3249, 17650, 35223], "temperature": 0.0, "avg_logprob": -0.19610760428688742, "compression_ratio": 1.6126126126126126, "no_speech_prob": 0.0002434274210827425}, {"id": 85, "seek": 58068, "start": 593.8399999999999, "end": 601.0, "text": " and paying for the translation of strings that are already translated or reviewed. Okay.", "tokens": [293, 6229, 337, 264, 12853, 295, 13985, 300, 366, 1217, 16805, 420, 18429, 13, 1033, 13], "temperature": 0.0, "avg_logprob": -0.19610760428688742, "compression_ratio": 1.6126126126126126, "no_speech_prob": 0.0002434274210827425}, {"id": 86, "seek": 58068, "start": 601.0, "end": 607.16, "text": " And as you can see, the script is very simple. You open the PO file, you send the text to", "tokens": [400, 382, 291, 393, 536, 11, 264, 5755, 307, 588, 2199, 13, 509, 1269, 264, 22299, 3991, 11, 291, 2845, 264, 2487, 281], "temperature": 0.0, "avg_logprob": -0.19610760428688742, "compression_ratio": 1.6126126126126126, "no_speech_prob": 0.0002434274210827425}, {"id": 87, "seek": 60716, "start": 607.16, "end": 613.52, "text": " the cloud, in this case, AWS translate. You save, you replace the string and you save", "tokens": [264, 4588, 11, 294, 341, 1389, 11, 17650, 13799, 13, 509, 3155, 11, 291, 7406, 264, 6798, 293, 291, 3155], "temperature": 0.0, "avg_logprob": -0.18094335661994088, "compression_ratio": 1.4719101123595506, "no_speech_prob": 0.00018628835096023977}, {"id": 88, "seek": 60716, "start": 613.52, "end": 619.88, "text": " it in the new PO file, it's done. Okay. So, the script is almost out of this. You have", "tokens": [309, 294, 264, 777, 22299, 3991, 11, 309, 311, 1096, 13, 1033, 13, 407, 11, 264, 5755, 307, 1920, 484, 295, 341, 13, 509, 362], "temperature": 0.0, "avg_logprob": -0.18094335661994088, "compression_ratio": 1.4719101123595506, "no_speech_prob": 0.00018628835096023977}, {"id": 89, "seek": 60716, "start": 619.88, "end": 631.0799999999999, "text": " it complete on GitHub. And this is the main job. Another advantage of these tools is that", "tokens": [309, 3566, 322, 23331, 13, 400, 341, 307, 264, 2135, 1691, 13, 3996, 5002, 295, 613, 3873, 307, 300], "temperature": 0.0, "avg_logprob": -0.18094335661994088, "compression_ratio": 1.4719101123595506, "no_speech_prob": 0.00018628835096023977}, {"id": 90, "seek": 63108, "start": 631.08, "end": 637.8000000000001, "text": " you can create a list of words that should not be translated. And this helps a lot, especially", "tokens": [291, 393, 1884, 257, 1329, 295, 2283, 300, 820, 406, 312, 16805, 13, 400, 341, 3665, 257, 688, 11, 2318], "temperature": 0.0, "avg_logprob": -0.12684208552042645, "compression_ratio": 1.6454545454545455, "no_speech_prob": 0.00035787423257716}, {"id": 91, "seek": 63108, "start": 637.8000000000001, "end": 643.9200000000001, "text": " if you have a product or a document with a common name, that is, that you don't want", "tokens": [498, 291, 362, 257, 1674, 420, 257, 4166, 365, 257, 2689, 1315, 11, 300, 307, 11, 300, 291, 500, 380, 528], "temperature": 0.0, "avg_logprob": -0.12684208552042645, "compression_ratio": 1.6454545454545455, "no_speech_prob": 0.00035787423257716}, {"id": 92, "seek": 63108, "start": 643.9200000000001, "end": 652.6800000000001, "text": " to be translated. So, you can pass these special lists, you can create some exceptions. But", "tokens": [281, 312, 16805, 13, 407, 11, 291, 393, 1320, 613, 2121, 14511, 11, 291, 393, 1884, 512, 22847, 13, 583], "temperature": 0.0, "avg_logprob": -0.12684208552042645, "compression_ratio": 1.6454545454545455, "no_speech_prob": 0.00035787423257716}, {"id": 93, "seek": 63108, "start": 652.6800000000001, "end": 658.48, "text": " as was explaining in the previous presentation, it's also a problem because as we, most of", "tokens": [382, 390, 13468, 294, 264, 3894, 5860, 11, 309, 311, 611, 257, 1154, 570, 382, 321, 11, 881, 295], "temperature": 0.0, "avg_logprob": -0.12684208552042645, "compression_ratio": 1.6454545454545455, "no_speech_prob": 0.00035787423257716}, {"id": 94, "seek": 65848, "start": 658.48, "end": 664.32, "text": " the time, we select English as the main or the source translation language, you cannot", "tokens": [264, 565, 11, 321, 3048, 3669, 382, 264, 2135, 420, 264, 4009, 12853, 2856, 11, 291, 2644], "temperature": 0.0, "avg_logprob": -0.20214734311963692, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.00017144490266218781}, {"id": 95, "seek": 65848, "start": 664.32, "end": 676.6800000000001, "text": " create exclusion lists using programming languages, keywords. So, in this document, Python, name", "tokens": [1884, 33049, 14511, 1228, 9410, 8650, 11, 21009, 13, 407, 11, 294, 341, 4166, 11, 15329, 11, 1315], "temperature": 0.0, "avg_logprob": -0.20214734311963692, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.00017144490266218781}, {"id": 96, "seek": 65848, "start": 676.6800000000001, "end": 681.64, "text": " for Python programmers, of course, there are lots of source code and we're not translated", "tokens": [337, 15329, 41504, 11, 295, 1164, 11, 456, 366, 3195, 295, 4009, 3089, 293, 321, 434, 406, 16805], "temperature": 0.0, "avg_logprob": -0.20214734311963692, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.00017144490266218781}, {"id": 97, "seek": 68164, "start": 681.64, "end": 688.64, "text": " to Portuguese, for example, keywords like for, in, we're all translated to Portuguese.", "tokens": [281, 22759, 11, 337, 1365, 11, 21009, 411, 337, 11, 294, 11, 321, 434, 439, 16805, 281, 22759, 13], "temperature": 0.0, "avg_logprob": -0.1873493194580078, "compression_ratio": 1.6972477064220184, "no_speech_prob": 6.335414946079254e-05}, {"id": 98, "seek": 68164, "start": 688.64, "end": 696.12, "text": " So, by using the automatic translation engine, you have to review and revert this translation,", "tokens": [407, 11, 538, 1228, 264, 12509, 12853, 2848, 11, 291, 362, 281, 3131, 293, 319, 3281, 341, 12853, 11], "temperature": 0.0, "avg_logprob": -0.1873493194580078, "compression_ratio": 1.6972477064220184, "no_speech_prob": 6.335414946079254e-05}, {"id": 99, "seek": 68164, "start": 696.12, "end": 702.76, "text": " so the translated program will continue to be valid. And you have to pay very close attention,", "tokens": [370, 264, 16805, 1461, 486, 2354, 281, 312, 7363, 13, 400, 291, 362, 281, 1689, 588, 1998, 3202, 11], "temperature": 0.0, "avg_logprob": -0.1873493194580078, "compression_ratio": 1.6972477064220184, "no_speech_prob": 6.335414946079254e-05}, {"id": 100, "seek": 68164, "start": 702.76, "end": 707.48, "text": " because of course, you also translate variable names if you have source code in the document.", "tokens": [570, 295, 1164, 11, 291, 611, 13799, 7006, 5288, 498, 291, 362, 4009, 3089, 294, 264, 4166, 13], "temperature": 0.0, "avg_logprob": -0.1873493194580078, "compression_ratio": 1.6972477064220184, "no_speech_prob": 6.335414946079254e-05}, {"id": 101, "seek": 70748, "start": 707.48, "end": 713.4, "text": " So, you need to pay attention that the output is still coherent, okay? And of course, as", "tokens": [407, 11, 291, 643, 281, 1689, 3202, 300, 264, 5598, 307, 920, 36239, 11, 1392, 30, 400, 295, 1164, 11, 382], "temperature": 0.0, "avg_logprob": -0.166192889213562, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.00024090037913993}, {"id": 102, "seek": 70748, "start": 713.4, "end": 719.6800000000001, "text": " you need to do this manual work, you can use a PO edit tool or any other tool that you", "tokens": [291, 643, 281, 360, 341, 9688, 589, 11, 291, 393, 764, 257, 22299, 8129, 2290, 420, 604, 661, 2290, 300, 291], "temperature": 0.0, "avg_logprob": -0.166192889213562, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.00024090037913993}, {"id": 103, "seek": 70748, "start": 719.6800000000001, "end": 725.9200000000001, "text": " are used to use to work with PO files. So, here we have the English version and there", "tokens": [366, 1143, 281, 764, 281, 589, 365, 22299, 7098, 13, 407, 11, 510, 321, 362, 264, 3669, 3037, 293, 456], "temperature": 0.0, "avg_logprob": -0.166192889213562, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.00024090037913993}, {"id": 104, "seek": 70748, "start": 725.9200000000001, "end": 731.5600000000001, "text": " we have the Brazilian Portuguese version. I could just step item by item and reveal", "tokens": [321, 362, 264, 23435, 22759, 3037, 13, 286, 727, 445, 1823, 3174, 538, 3174, 293, 10658], "temperature": 0.0, "avg_logprob": -0.166192889213562, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.00024090037913993}, {"id": 105, "seek": 73156, "start": 731.56, "end": 739.68, "text": " these translations until I was satisfied with the result and then you can simply regenerate", "tokens": [613, 37578, 1826, 286, 390, 11239, 365, 264, 1874, 293, 550, 291, 393, 2935, 26358, 473], "temperature": 0.0, "avg_logprob": -0.1842908752098512, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.00010827993537532166}, {"id": 106, "seek": 73156, "start": 739.68, "end": 746.5999999999999, "text": " the markdown file from the PO file, okay? So, we started with the markdown source code,", "tokens": [264, 1491, 5093, 3991, 490, 264, 22299, 3991, 11, 1392, 30, 407, 11, 321, 1409, 365, 264, 1491, 5093, 4009, 3089, 11], "temperature": 0.0, "avg_logprob": -0.1842908752098512, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.00010827993537532166}, {"id": 107, "seek": 73156, "start": 746.5999999999999, "end": 754.8, "text": " we tracked using AMD PO to create the initial PO file. I ran the script that sends the untranslated", "tokens": [321, 31703, 1228, 34808, 22299, 281, 1884, 264, 5883, 22299, 3991, 13, 286, 5872, 264, 5755, 300, 14790, 264, 1701, 25392, 38539], "temperature": 0.0, "avg_logprob": -0.1842908752098512, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.00010827993537532166}, {"id": 108, "seek": 73156, "start": 754.8, "end": 761.0799999999999, "text": " strings to AWS translate, but you can use any provider you want. You review with PO edit", "tokens": [13985, 281, 17650, 13799, 11, 457, 291, 393, 764, 604, 12398, 291, 528, 13, 509, 3131, 365, 22299, 8129], "temperature": 0.0, "avg_logprob": -0.1842908752098512, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.00010827993537532166}, {"id": 109, "seek": 76108, "start": 761.08, "end": 767.8000000000001, "text": " and you do the opposite conversion from PO file to markdown and publish the wiki, okay?", "tokens": [293, 291, 360, 264, 6182, 14298, 490, 22299, 3991, 281, 1491, 5093, 293, 11374, 264, 261, 9850, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.2129347107627175, "compression_ratio": 1.4623655913978495, "no_speech_prob": 7.309081411221996e-05}, {"id": 110, "seek": 76108, "start": 767.8000000000001, "end": 774.48, "text": " So, this is the workflow I tried to implement using my collection of scripts or hacks. It", "tokens": [407, 11, 341, 307, 264, 20993, 286, 3031, 281, 4445, 1228, 452, 5765, 295, 23294, 420, 33617, 13, 467], "temperature": 0.0, "avg_logprob": -0.2129347107627175, "compression_ratio": 1.4623655913978495, "no_speech_prob": 7.309081411221996e-05}, {"id": 111, "seek": 76108, "start": 774.48, "end": 784.5600000000001, "text": " is not really a tool, but with the intention to facilitate a single markdown file translation,", "tokens": [307, 406, 534, 257, 2290, 11, 457, 365, 264, 7789, 281, 20207, 257, 2167, 1491, 5093, 3991, 12853, 11], "temperature": 0.0, "avg_logprob": -0.2129347107627175, "compression_ratio": 1.4623655913978495, "no_speech_prob": 7.309081411221996e-05}, {"id": 112, "seek": 78456, "start": 784.56, "end": 791.8399999999999, "text": " okay? So, the document looks like this. This is the English version. Yes, I put the English,", "tokens": [1392, 30, 407, 11, 264, 4166, 1542, 411, 341, 13, 639, 307, 264, 3669, 3037, 13, 1079, 11, 286, 829, 264, 3669, 11], "temperature": 0.0, "avg_logprob": -0.21357722948956234, "compression_ratio": 1.6650717703349283, "no_speech_prob": 6.242965173441917e-05}, {"id": 113, "seek": 78456, "start": 791.8399999999999, "end": 798.04, "text": " no, this is the Portuguese one, okay? So, in the end, I could publish this document in", "tokens": [572, 11, 341, 307, 264, 22759, 472, 11, 1392, 30, 407, 11, 294, 264, 917, 11, 286, 727, 11374, 341, 4166, 294], "temperature": 0.0, "avg_logprob": -0.21357722948956234, "compression_ratio": 1.6650717703349283, "no_speech_prob": 6.242965173441917e-05}, {"id": 114, "seek": 78456, "start": 798.04, "end": 804.4799999999999, "text": " GitHub. It's not yet fully integrated with the GitHub wiki because ideally, I should", "tokens": [23331, 13, 467, 311, 406, 1939, 4498, 10919, 365, 264, 23331, 261, 9850, 570, 22915, 11, 286, 820], "temperature": 0.0, "avg_logprob": -0.21357722948956234, "compression_ratio": 1.6650717703349283, "no_speech_prob": 6.242965173441917e-05}, {"id": 115, "seek": 78456, "start": 804.4799999999999, "end": 812.0, "text": " put the GitHub wiki of this documentation as a sub module of my project. So, when I", "tokens": [829, 264, 23331, 261, 9850, 295, 341, 14333, 382, 257, 1422, 10088, 295, 452, 1716, 13, 407, 11, 562, 286], "temperature": 0.0, "avg_logprob": -0.21357722948956234, "compression_ratio": 1.6650717703349283, "no_speech_prob": 6.242965173441917e-05}, {"id": 116, "seek": 81200, "start": 812.0, "end": 818.8, "text": " updated it, I also get the newest version of the markdown and if I do this kind of integration", "tokens": [10588, 309, 11, 286, 611, 483, 264, 17569, 3037, 295, 264, 1491, 5093, 293, 498, 286, 360, 341, 733, 295, 10980], "temperature": 0.0, "avg_logprob": -0.14875097477689703, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.00010950242722174153}, {"id": 117, "seek": 81200, "start": 818.8, "end": 823.68, "text": " using GitHub, you'll be able to publish the markdown file also using GitHub. For this", "tokens": [1228, 23331, 11, 291, 603, 312, 1075, 281, 11374, 264, 1491, 5093, 3991, 611, 1228, 23331, 13, 1171, 341], "temperature": 0.0, "avg_logprob": -0.14875097477689703, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.00010950242722174153}, {"id": 118, "seek": 81200, "start": 823.68, "end": 828.8, "text": " initial version, I just went to the editor and I paste the markdown file, but it's possible", "tokens": [5883, 3037, 11, 286, 445, 1437, 281, 264, 9839, 293, 286, 9163, 264, 1491, 5093, 3991, 11, 457, 309, 311, 1944], "temperature": 0.0, "avg_logprob": -0.14875097477689703, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.00010950242722174153}, {"id": 119, "seek": 81200, "start": 828.8, "end": 836.64, "text": " to do the integration. It's the next step that I still have to do. So, I published the scripts", "tokens": [281, 360, 264, 10980, 13, 467, 311, 264, 958, 1823, 300, 286, 920, 362, 281, 360, 13, 407, 11, 286, 6572, 264, 23294], "temperature": 0.0, "avg_logprob": -0.14875097477689703, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.00010950242722174153}, {"id": 120, "seek": 83664, "start": 836.64, "end": 843.3199999999999, "text": " in this GitHub. So, it's an info Python programmer. It's useful for any markdown file. You may", "tokens": [294, 341, 23331, 13, 407, 11, 309, 311, 364, 13614, 15329, 32116, 13, 467, 311, 4420, 337, 604, 1491, 5093, 3991, 13, 509, 815], "temperature": 0.0, "avg_logprob": -0.2073188194861779, "compression_ratio": 1.508130081300813, "no_speech_prob": 9.47947264648974e-05}, {"id": 121, "seek": 83664, "start": 843.3199999999999, "end": 852.68, "text": " want to apply the same workflow. And the page is in beta because I asked all the translators,", "tokens": [528, 281, 3079, 264, 912, 20993, 13, 400, 264, 3028, 307, 294, 9861, 570, 286, 2351, 439, 264, 5105, 3391, 11], "temperature": 0.0, "avg_logprob": -0.2073188194861779, "compression_ratio": 1.508130081300813, "no_speech_prob": 9.47947264648974e-05}, {"id": 122, "seek": 83664, "start": 852.68, "end": 858.48, "text": " all the people that can read Brazilian Portuguese to check if everything is fine. Because the", "tokens": [439, 264, 561, 300, 393, 1401, 23435, 22759, 281, 1520, 498, 1203, 307, 2489, 13, 1436, 264], "temperature": 0.0, "avg_logprob": -0.2073188194861779, "compression_ratio": 1.508130081300813, "no_speech_prob": 9.47947264648974e-05}, {"id": 123, "seek": 83664, "start": 858.48, "end": 865.6, "text": " main goal to have a process is that usually, you never do the translation a single time.", "tokens": [2135, 3387, 281, 362, 257, 1399, 307, 300, 2673, 11, 291, 1128, 360, 264, 12853, 257, 2167, 565, 13], "temperature": 0.0, "avg_logprob": -0.2073188194861779, "compression_ratio": 1.508130081300813, "no_speech_prob": 9.47947264648974e-05}, {"id": 124, "seek": 86560, "start": 865.6, "end": 870.48, "text": " The translation is something that you need to keep alive. As soon as the English version", "tokens": [440, 12853, 307, 746, 300, 291, 643, 281, 1066, 5465, 13, 1018, 2321, 382, 264, 3669, 3037], "temperature": 0.0, "avg_logprob": -0.14847299030848912, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.00010804442717926577}, {"id": 125, "seek": 86560, "start": 870.48, "end": 876.48, "text": " is extended, translated, updated, you have to do the same thing in Portuguese. If you", "tokens": [307, 10913, 11, 16805, 11, 10588, 11, 291, 362, 281, 360, 264, 912, 551, 294, 22759, 13, 759, 291], "temperature": 0.0, "avg_logprob": -0.14847299030848912, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.00010804442717926577}, {"id": 126, "seek": 86560, "start": 876.48, "end": 882.36, "text": " don't have an automatic process able to license this document and present a subset of changes,", "tokens": [500, 380, 362, 364, 12509, 1399, 1075, 281, 10476, 341, 4166, 293, 1974, 257, 25993, 295, 2962, 11], "temperature": 0.0, "avg_logprob": -0.14847299030848912, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.00010804442717926577}, {"id": 127, "seek": 86560, "start": 882.36, "end": 888.0400000000001, "text": " you'll be obliged to review a full document and this can be very, very cumbersome over", "tokens": [291, 603, 312, 47194, 281, 3131, 257, 1577, 4166, 293, 341, 393, 312, 588, 11, 588, 12713, 1616, 423, 670], "temperature": 0.0, "avg_logprob": -0.14847299030848912, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.00010804442717926577}, {"id": 128, "seek": 88804, "start": 888.04, "end": 896.48, "text": " time if the document has 15, 20 pages. So, it's not ideal. And another advantage is that", "tokens": [565, 498, 264, 4166, 575, 2119, 11, 945, 7183, 13, 407, 11, 309, 311, 406, 7157, 13, 400, 1071, 5002, 307, 300], "temperature": 0.0, "avg_logprob": -0.16732641061147055, "compression_ratio": 1.4565217391304348, "no_speech_prob": 6.24552121735178e-05}, {"id": 129, "seek": 88804, "start": 896.48, "end": 903.1999999999999, "text": " the tool is smart enough to detect repetitions of the same stream. So, you also, you don't", "tokens": [264, 2290, 307, 4069, 1547, 281, 5531, 13645, 2451, 295, 264, 912, 4309, 13, 407, 11, 291, 611, 11, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.16732641061147055, "compression_ratio": 1.4565217391304348, "no_speech_prob": 6.24552121735178e-05}, {"id": 130, "seek": 88804, "start": 903.1999999999999, "end": 909.36, "text": " have the boring work to re-translate the same text multiple times. This also saves a lot", "tokens": [362, 264, 9989, 589, 281, 319, 12, 24999, 17593, 264, 912, 2487, 3866, 1413, 13, 639, 611, 19155, 257, 688], "temperature": 0.0, "avg_logprob": -0.16732641061147055, "compression_ratio": 1.4565217391304348, "no_speech_prob": 6.24552121735178e-05}, {"id": 131, "seek": 90936, "start": 909.36, "end": 920.16, "text": " of time. Yes. So, these are the main findings and the main problems I try to solve. And", "tokens": [295, 565, 13, 1079, 13, 407, 11, 613, 366, 264, 2135, 16483, 293, 264, 2135, 2740, 286, 853, 281, 5039, 13, 400], "temperature": 0.0, "avg_logprob": -0.2968084747726853, "compression_ratio": 1.180952380952381, "no_speech_prob": 0.00025493453722447157}, {"id": 132, "seek": 90936, "start": 920.16, "end": 923.16, "text": " that's it if you have any questions.", "tokens": [300, 311, 309, 498, 291, 362, 604, 1651, 13], "temperature": 0.0, "avg_logprob": -0.2968084747726853, "compression_ratio": 1.180952380952381, "no_speech_prob": 0.00025493453722447157}, {"id": 133, "seek": 92316, "start": 923.16, "end": 945.0799999999999, "text": " You can say. My phrase. Yes. So, it's much easier and especially if your text has source", "tokens": [509, 393, 584, 13, 1222, 9535, 13, 1079, 13, 407, 11, 309, 311, 709, 3571, 293, 2318, 498, 428, 2487, 575, 4009], "temperature": 0.0, "avg_logprob": -0.25011788243832794, "compression_ratio": 1.3555555555555556, "no_speech_prob": 0.000561337627004832}, {"id": 134, "seek": 92316, "start": 945.0799999999999, "end": 950.1999999999999, "text": " code because the challenge was the source code. And sometimes you have to keep the indentation", "tokens": [3089, 570, 264, 3430, 390, 264, 4009, 3089, 13, 400, 2171, 291, 362, 281, 1066, 264, 44494, 399], "temperature": 0.0, "avg_logprob": -0.25011788243832794, "compression_ratio": 1.3555555555555556, "no_speech_prob": 0.000561337627004832}, {"id": 135, "seek": 95020, "start": 950.2, "end": 957.0400000000001, "text": " and so on and so on. You don't want to pass the indentation mess to the translator. So,", "tokens": [293, 370, 322, 293, 370, 322, 13, 509, 500, 380, 528, 281, 1320, 264, 44494, 399, 2082, 281, 264, 35223, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.19702477888627487, "compression_ratio": 1.6334841628959276, "no_speech_prob": 0.00048716343007981777}, {"id": 136, "seek": 95020, "start": 957.0400000000001, "end": 962.2, "text": " if you use a tool like this, it will structure just the part of the program with text. And", "tokens": [498, 291, 764, 257, 2290, 411, 341, 11, 309, 486, 3877, 445, 264, 644, 295, 264, 1461, 365, 2487, 13, 400], "temperature": 0.0, "avg_logprob": -0.19702477888627487, "compression_ratio": 1.6334841628959276, "no_speech_prob": 0.00048716343007981777}, {"id": 137, "seek": 95020, "start": 962.2, "end": 968.4000000000001, "text": " if you keep the white space, which is very important in Python, so you can translate.", "tokens": [498, 291, 1066, 264, 2418, 1901, 11, 597, 307, 588, 1021, 294, 15329, 11, 370, 291, 393, 13799, 13], "temperature": 0.0, "avg_logprob": -0.19702477888627487, "compression_ratio": 1.6334841628959276, "no_speech_prob": 0.00048716343007981777}, {"id": 138, "seek": 95020, "start": 968.4000000000001, "end": 972.88, "text": " But you still have to pay attention because of the automatic translation to translate everything", "tokens": [583, 291, 920, 362, 281, 1689, 3202, 570, 295, 264, 12509, 12853, 281, 13799, 1203], "temperature": 0.0, "avg_logprob": -0.19702477888627487, "compression_ratio": 1.6334841628959276, "no_speech_prob": 0.00048716343007981777}, {"id": 139, "seek": 97288, "start": 972.88, "end": 980.8, "text": " to the target language. So, you have to revert the keywords. But at least the generation", "tokens": [281, 264, 3779, 2856, 13, 407, 11, 291, 362, 281, 319, 3281, 264, 21009, 13, 583, 412, 1935, 264, 5125], "temperature": 0.0, "avg_logprob": -0.24704439598217345, "compression_ratio": 1.5413533834586466, "no_speech_prob": 0.0004951413138769567}, {"id": 140, "seek": 97288, "start": 980.8, "end": 985.36, "text": " is quite strong. So, when you have generated this, the program is still a correct program", "tokens": [307, 1596, 2068, 13, 407, 11, 562, 291, 362, 10833, 341, 11, 264, 1461, 307, 920, 257, 3006, 1461], "temperature": 0.0, "avg_logprob": -0.24704439598217345, "compression_ratio": 1.5413533834586466, "no_speech_prob": 0.0004951413138769567}, {"id": 141, "seek": 97288, "start": 985.36, "end": 990.36, "text": " in the end. So, it's good.", "tokens": [294, 264, 917, 13, 407, 11, 309, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.24704439598217345, "compression_ratio": 1.5413533834586466, "no_speech_prob": 0.0004951413138769567}, {"id": 142, "seek": 99036, "start": 990.36, "end": 1006.0, "text": " Okay. I think it's the last one. Okay. Thank you.", "tokens": [50364, 1033, 13, 286, 519, 309, 311, 264, 1036, 472, 13, 1033, 13, 1044, 291, 13, 51146], "temperature": 0.0, "avg_logprob": -0.49799225065443253, "compression_ratio": 0.9607843137254902, "no_speech_prob": 0.01551143266260624}], "language": "en"}