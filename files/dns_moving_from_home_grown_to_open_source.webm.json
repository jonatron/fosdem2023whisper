{"text": " So, my name is Robin Geuze. I used to work for TransIP at first and Team Blue after they merged with a bunch of other companies for about a decade until a month ago. During that time period we transitioned from running our own closed source DNS server software to running open source DNS server software and just like the talk we just had, that happens to be power DNS. So, I'll take you through the issues we had going from closed source to open source, which roughly took the entire time I was there, about nine years. So, yeah, let's start. So, how it started for me. TransDNS, which they called the home root DNS software, was written originally in about 2003, 2004 and it had the DNS support added in 2012. When I started working at TransIP in 2013 as a PHP coder, I was asked to help them debug a crasher in the TransDNS code. It basically came down to a buffer overflow because somebody had, one of our customers had managed to put more than 16 kilobytes of text record data on one single label. The really quickly quick fix was to increase the buffer to 32 kilobytes. And one small disclaimer, I was involved in almost all the work that I mentioned here, but there are some things that I didn't do myself or just consulted on, stuff like that. I'll try to make a distinction about it, but I might miss some stuff. Yeah, so back then it was a really basic setup. We basically had three servers. They were all running TransDNS. There was no load balancing. The signing stack was built using DNS stack tools for those few people who still know what it is. And there was a lot of automation on top of DNS stack tools in PHP to make all of that work and ultimately upload stuff to the registry because we were one of the, we were a registrar, so a lot of the stuff was automated. All of this DNS propagation was done to cron jobs, which means it was very slow. It took roughly five minutes to propagate a DNS change, which back then wasn't really a big problem. But as we went on, it became more and more an issue, especially when we got let's encrypts and you needed to quickly update your DNS to get your certificate signed. We had at the high, I think we still have roughly one million zones in the setup, most of which so about 80, 90% are DNS signed. There were very few people back then that actually knew stuff about it and dared to work on it. I think maybe three or four people, one of which was I. It had very bad RSC compatibility, which I will get into a little bit later. Adding new record types, which Kevin mentioned like SSHFP was a lot of work because there was a interpreter in TransDNS itself, which had to be written in C and writing interpreters in C for stack strings is not fun. And well, I fixed that initial buffer overflow block, but the main problem was there just not a lot of bound checking in the code. So yeah, there were a lot of hidden bugs that probably should be fixed as well. So we took a few initial steps because initially, because we had the three servers, there was no loan financing, we meant that if we restarted TransDNS, one of the servers would stop responding until the restart was done. And the restart took roughly 15 minutes because every single record would get loaded into memory. And since we had a million zones, I think it was like 25 million records or something back then, it just took a lot of time and might have used the quick DNS zone parser stuff. So the first thing we did was implement load balancing. This was before DNS. This was a thing. So what we tried initially was relay day, which some of the BSD folks might know. It did work, but we had a lot of weird issues. It was really hard to debug. And so eventually we switched to using HAProxy for TCP, which works, nothing more to say about it. And I wrote something rather quickly in C roughly based on the TransDNS code to forward the UDP stuff. That worked quite well and actually enabled us to actually iterate on the TransDNS code because we could do save restarts without having to worry about queries being dropped. And that allowed me to fix the glaring issues like there not being any bounce checking in the code. So we had less risk of buffer overflows. And I fixed a lot of the EDS issues that were becoming a problem at that point. Eventually when DNS was a little bit more mature, we switched to that because otherwise I had to maintain another piece of software and I really didn't feel like that. In the meantime, it did improve the TCP stack a lot in TransDNS because we noticed that especially SIDN, the.nlRegistrar registry, did a lot of TCP queries and the original implementation was basically just spawn a new thread for every TCP connection, but once you get to about a thousand threads, that's not a great solution. So I changed to a polling-based model, worked great, got pretty high performance, and we never had a problem with it after that. The only thing I changed later is when we moved to Linux, I changed to ePool. Yeah, so SIDN had validation monitoring and we kept getting reminded about the fact that we were doing a lot of stuff wrong. So yeah, we actually had one specific case that basically covered most of the, I think it was about 80% of those errors, and that's, it's 62 issues, but they have the same cause. So the first issue was the incorrect handling of wildcards. So if you have a wildcard that, for example, star.nl, then you have a record c.nl, and then you try to resolve a.c.nl, it should not hit the wildcard, because c.nl exists, which means you should return a no-data, or an extra main in this case, but transdns didn't really care, so it would just return the data from the wildcard. Very useful, makes it a lot easier to configure DNS, but it causes some issues, especially with DNS validation. The second issue was basically the same only in the empty non-terminals. If a.b.c exists, and you try to resolve b.c, even though there's nothing specific on b.c, you should say there's no data, rather than it's a non-existent domain, also causes the DNS validation errors. Same basic cause. The solution was to switch from, in transdns, to switch from an ordered map that used the type and the domain name as the key, to a map that only used the domain name as the key, and have an array in there with the type, which could also be empty, so we would immediately notice if there was a label in our way. That worked well. I actually did it this next slide, so the only problem is we couldn't just deploy that, because we might break stuff for our customers, and customers get a little bit difficult if you break stuff for them. So what I decided was, okay, for the NSIC it's broken anyways, because the NSIC enables for the resolvers would just return errors when you have one of these labels. So what I did is fixing the two steps. I initially enabled it only for the NSIC queries, so the correct behavior, and kept the wrong behavior for non-DNSIC queries, and in between we just covered a large amount of queries. I think I did two days of DCP dumping, and milling it down to the actual unique queries, and compared what our name servers would respond for DNSIC versus non-DNSIC. For everything that had a difference, we contacted the customers, and told them, hey, you need to fix this. I think it was only about 20 to 30 customers. It was actually not that many, so that made it a lot easier. And then we just, at some point I decided I'll flip the switch. There were a few customers that didn't respond, but at some point you just have to decide to. Don't give a fuck. One other small issue we have with RFC implementation was the NSIC implementation, because almost all of our zones use NSIC tree. The NSIC implementation was not as well tested as the NSIC tree implementation, so it was wrong, like really wrong. I just rewrote it from scratch, and then it worked, but yeah. So we started to think about moving to PowerDNS, and the main reason we did was because SIDN announced that we would no longer get a DNSIC incentive for domains using the NSIC algorithm 7. So that's the RSA plus NSIC tree algorithm. That would cost us a bunch of money, and that's a very good way to stimulate people to do stuff. So at this point we decided to buy the bullet and just start over from scratch, and build a really new, more modern setup. We picked PowerDNS, basically, partially because we already had some experience with it, and we didn't really want to deal with zone files, because we had a million zones, and putting them all on a file system makes things annoying. So PowerDNS was the only one where we thought, oh, this allows us to do changes via the API. We don't need to worry about having separate zone files for every single zone. So we needed to pick a PowerDNS backend to use, because PowerDNS is one thing, but you still need something to put stuff in. And there we sort of had to hit a problem, because PowerDNS is really fast, because it's literally just a hash map in memory, so it can basically do instant answers. And while the PowerDNS, as you go back in, is very nice and flexible, but it's not really fast, especially because we had a lot of zones that would not get very frequent queries. So they'd have a lot of non-active data, which means the query cache wouldn't really help a lot, which means that we would have a lot of SQL queries continuously, because they would get queries sometimes. It's not a lot. The bind backend had the same problem as all the other name servers. We didn't have API support, and it would mean we needed to use a lot of zone files, which we didn't want to. So introducing the LMDB backend. This already exists at the point that we started looking at it, because Hubert had written it. It's very fast, and it has support for the API, which is really nice. It only had one major issue. Because of the way Hubert had implemented it, it didn't really allow records bigger than 512 bytes. We have quite a lot of zones. So I decided to fix that in the end. I wrote a pull request for the Power Genius team, and I think that was pretty quickly accepted into there. It also included some migration code, so the older the LMDB database would automatically be migrated to the new LMDB database format. It also improved performance in some corner cases, but that was not really the goal of this patch. So then we started moving over. We built a setup. It was really cool. There's a lot of automation around it. It does actually do all the zone transfers via XFR, even though Kevin just said it's a bad idea if you have a lot of zones. But in practice, it works quite well, except for one issue. Every first day, our updates would take ages to go through. Basically, we traced it down to an enormous bump in the XFR queues. We would literally have 400,000 XFR queued up. So that was a bit of a problem. So the reason this happens is because Power Genius renews its signatures every first day of the week. Very nice. We don't have to think about it. Problem is, if you have a million zones, that takes quite a while, especially because we were running our hidden primary on a VM, so it was also not that quick to answer queries. So we could have just shown more hardware in it, but we decided to look a little bit more at a more sustainable solution, because, well, if it works with one million zones on the Phosomers scene, it will still work if you have 10 million zones. So I discussed it with the Power Genius guys, and I came up with a solution which is XFR priority levels. So rather than treating all XFRs that need to be done at the same level, we gave more priority to things that are user-initiated. So if you initiate an XFR via Power Genius control, it will be first in the queue. Whatever else is in the queue, that one was treated first. After that, there's the API, notifies, solar refresh, and signature refresh is the lowest priority. That meant that, yes, we would still have a quite a large queue, but we could still process our updates very quickly. That was included into Power Genius, right with us. Well, in 4.5, it was included. We still saw the use queues, but those own updates would pretty quickly propagate. So that, for us, was fine. We never had a problem with it after that. Yeah, and then we had some other issues, most of which were in a minor solved in the low-banus layer or just fixed in Power Genius updates. The TCP performance is still something I want to look at in Power Genius just for fun, as a open-source developer. It's on my list of things I want to improve. We had some various smaller bugs in the NMDB backend because it was quite new. We were not the first one that ran it at really large scale, but we were one of the first ones, and we did see some problems that nobody else had had yet. One CVE we discovered literally within the day of rolling out a new version, so that was very fun for Peter because he got to roll out a new lose a day after he released the previous one. We had an issue that there were certain query patterns that we would get that were specifically designed to target a weakness in Power Genius. That was a transient as we didn't care about them, but Power Genius did get affected. We eventually resolved this by adding some detection at the low-banus layer that would just block queries for those affected domains. It would mean that that customer's domain would have limited functionality, but at least it would still work, and all the other customers would not be affected, which was for us the most important thing. Yeah, so some closing thoughts. Yeah, migrating a home root setup is really not for the faint of heart. However, running one is also not for the faint of heart. Yeah, it is worth it. It just gives you a lot more flexibility because now adding new record types is just a question of adding them in our front end and making them work. Whereas before, we had to add the new record type at every single step in the stack, and it just really took a lot of time. We can even, in theory, add different brands of secondaries. Currently, there's a few issues that were prevented, but it's relatively easy to solve, so we could just run not as a secondary or NSD or even bind if he would want to do that for some reason. What I did really, really notice is don't try to do this in one go, because it's a lot of work, and you'll make mistakes. If you do it in smaller steps, the mistakes will be smaller, easier to fix, and it also just feels a lot better if you can accomplish some things in between rather than trying to do it all at once. One thing I wanted to ask, DNSSEC incentives, they work both when trying to get people to use DNSSEC, but they also work to improve the quality of the DNSSEC, because we've seen, especially in the.nl zone, because I've also been involved in that work a little bit, some very bad implementations that got fixed when the rules were made stricter, including ours initially, but were even the worst ones. Yeah, that is it. For the people that would like to see, I've open sourced DNS before I left the company, so I can see it myself as well, so that's fun. It's on GitHub. I've also put the URLs for the two major pull requests I made. There's a bunch of other ones, but I haven't put all of them in there, and that's about it. So, questions? So, that makes it a bit of a more concern in your case, and I used to be a customer. On the upside, most of these methods probably weren't noticed by the majority, but I think you should take it more seriously if you were a company that actually makes money out of posting here. So, the comment is that we both made mistakes. It was a bit related to the talk Kevin did, so a lot of the things that we said are related, and the comment is Kevin was only doing it for himself, and we were doing it for paying customers. Yeah, I agree. When I started, there were a lot of issues, and I've tried three years to attempt to fix them as much as I could. To be clear, I wasn't hired to maintain trans-DNS. That just happened to be something that got shoved into my lab because I knew some C and C++. I became pretty passionate about it. I came pretty quickly rolled into the PowerDNS community. I also added a lot of contributions to DNS when that was getting started up. I agree with the initial statement. I've tried to fix it as much as I could. Sometimes, you set out with certain criteria. You build something that can meet that criteria, and it scales to a certain point. Eventually, you get to a million customers, a lot of customers. The company would start off with a million customers, and maybe at the time that this was a good system, things would fly to me. But as the business grew and things grow, you have to do exactly what he did. You evaluate it and say, you know, it's time for something different. He identified that and made the changes accordingly. A brief resume, he said that sometimes due to scaling, you run into issues that you hadn't foreseen when you were in it, and he set something up. Just taking a step to resolve them in the end can be a good thing. There was a question there. The question is how did they get them to agree with over sourcing it. At the point that I open sourced it, I was sort of CTO slash head of R&D of the Dutch part of the organization. Also, I only open sourced it after we totally took it out of production, so it's mainly a historic interest thing. Did you ever consider open sourcing trans-DNS before switching? So the question is, did we consider open sourcing before switching? No. And I'll tell you, we weren't very proud of, at least I wasn't proud of the source quality. I didn't write it myself, all of it. I only contributed to it later. I tried to improve it as much as I could, but it's still not... It's very focused on just doing one thing, and it's very good at that, but it's not very applicable to use by others. So I think it's interesting now to see some of the tricks to make things really fast that you can see in the code. But beyond that, I would never use it in a production environment other than the one it was in, because that one was built specifically to run around that code. What's actually the motivation for implementing the DNS hosting and trans-DNS? I think even around the time when you started as a company, there was not a software available that could have been used. So the question is, what was the motivation to implement their own DNS software? So to be clear, trans-DNS was implemented in 2003, so this was roughly when power-DNS started to grow, but the problem was that there were already quite a lot of zones in there, and it just got a little bit cumbersome using bind, because that was the primary name-server software you'd use back then, and yeah, that was the main motivation. Bind was getting annoying because you had to have a lot of zone files, and everything was running on 3BSD using UFS, so there was a 32,000 files per directory limit at that point, which also didn't help. I mean, there's ways to solve that, that's not that complicated, but that was the main motivation as well, as I think there were some performance issues in bind back then that were relatively easily resolved. The other alternatives would have been GGB DNS, but that had its own things, like the guy that wrote it, not saying you should use it. Anything else?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.36, "text": " So, my name is Robin Geuze. I used to work for TransIP at first and Team Blue after they", "tokens": [407, 11, 452, 1315, 307, 16533, 2876, 84, 1381, 13, 286, 1143, 281, 589, 337, 6531, 9139, 412, 700, 293, 7606, 8510, 934, 436], "temperature": 0.0, "avg_logprob": -0.22175268026498648, "compression_ratio": 1.4041450777202074, "no_speech_prob": 0.4773595631122589}, {"id": 1, "seek": 0, "start": 11.36, "end": 17.8, "text": " merged with a bunch of other companies for about a decade until a month ago. During that", "tokens": [36427, 365, 257, 3840, 295, 661, 3431, 337, 466, 257, 10378, 1826, 257, 1618, 2057, 13, 6842, 300], "temperature": 0.0, "avg_logprob": -0.22175268026498648, "compression_ratio": 1.4041450777202074, "no_speech_prob": 0.4773595631122589}, {"id": 2, "seek": 0, "start": 17.8, "end": 24.92, "text": " time period we transitioned from running our own closed source DNS server software to running", "tokens": [565, 2896, 321, 47346, 490, 2614, 527, 1065, 5395, 4009, 35153, 7154, 4722, 281, 2614], "temperature": 0.0, "avg_logprob": -0.22175268026498648, "compression_ratio": 1.4041450777202074, "no_speech_prob": 0.4773595631122589}, {"id": 3, "seek": 2492, "start": 24.92, "end": 30.400000000000002, "text": " open source DNS server software and just like the talk we just had, that happens to be power", "tokens": [1269, 4009, 35153, 7154, 4722, 293, 445, 411, 264, 751, 321, 445, 632, 11, 300, 2314, 281, 312, 1347], "temperature": 0.0, "avg_logprob": -0.1996310551961263, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0004219376132823527}, {"id": 4, "seek": 2492, "start": 30.400000000000002, "end": 38.040000000000006, "text": " DNS. So, I'll take you through the issues we had going from closed source to open source,", "tokens": [35153, 13, 407, 11, 286, 603, 747, 291, 807, 264, 2663, 321, 632, 516, 490, 5395, 4009, 281, 1269, 4009, 11], "temperature": 0.0, "avg_logprob": -0.1996310551961263, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0004219376132823527}, {"id": 5, "seek": 2492, "start": 38.040000000000006, "end": 46.96, "text": " which roughly took the entire time I was there, about nine years. So, yeah, let's start. So,", "tokens": [597, 9810, 1890, 264, 2302, 565, 286, 390, 456, 11, 466, 4949, 924, 13, 407, 11, 1338, 11, 718, 311, 722, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.1996310551961263, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0004219376132823527}, {"id": 6, "seek": 2492, "start": 46.96, "end": 53.120000000000005, "text": " how it started for me. TransDNS, which they called the home root DNS software, was written originally", "tokens": [577, 309, 1409, 337, 385, 13, 6531, 35, 42003, 11, 597, 436, 1219, 264, 1280, 5593, 35153, 4722, 11, 390, 3720, 7993], "temperature": 0.0, "avg_logprob": -0.1996310551961263, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0004219376132823527}, {"id": 7, "seek": 5312, "start": 53.12, "end": 62.64, "text": " in about 2003, 2004 and it had the DNS support added in 2012. When I started working at TransIP in", "tokens": [294, 466, 16416, 11, 15817, 293, 309, 632, 264, 35153, 1406, 3869, 294, 9125, 13, 1133, 286, 1409, 1364, 412, 6531, 9139, 294], "temperature": 0.0, "avg_logprob": -0.18608738540054917, "compression_ratio": 1.4154589371980677, "no_speech_prob": 0.00029480524244718254}, {"id": 8, "seek": 5312, "start": 62.64, "end": 73.47999999999999, "text": " 2013 as a PHP coder, I was asked to help them debug a crasher in the TransDNS code. It basically", "tokens": [9012, 382, 257, 47298, 17656, 260, 11, 286, 390, 2351, 281, 854, 552, 24083, 257, 941, 296, 511, 294, 264, 6531, 35, 42003, 3089, 13, 467, 1936], "temperature": 0.0, "avg_logprob": -0.18608738540054917, "compression_ratio": 1.4154589371980677, "no_speech_prob": 0.00029480524244718254}, {"id": 9, "seek": 5312, "start": 73.47999999999999, "end": 79.75999999999999, "text": " came down to a buffer overflow because somebody had, one of our customers had managed to put more", "tokens": [1361, 760, 281, 257, 21762, 37772, 570, 2618, 632, 11, 472, 295, 527, 4581, 632, 6453, 281, 829, 544], "temperature": 0.0, "avg_logprob": -0.18608738540054917, "compression_ratio": 1.4154589371980677, "no_speech_prob": 0.00029480524244718254}, {"id": 10, "seek": 7976, "start": 79.76, "end": 87.32000000000001, "text": " than 16 kilobytes of text record data on one single label. The really quickly quick fix was to", "tokens": [813, 3165, 5128, 996, 43673, 295, 2487, 2136, 1412, 322, 472, 2167, 7645, 13, 440, 534, 2661, 1702, 3191, 390, 281], "temperature": 0.0, "avg_logprob": -0.14339847171429507, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.0002513671643100679}, {"id": 11, "seek": 7976, "start": 87.32000000000001, "end": 95.08000000000001, "text": " increase the buffer to 32 kilobytes. And one small disclaimer, I was involved in almost all the work", "tokens": [3488, 264, 21762, 281, 8858, 5128, 996, 43673, 13, 400, 472, 1359, 40896, 11, 286, 390, 3288, 294, 1920, 439, 264, 589], "temperature": 0.0, "avg_logprob": -0.14339847171429507, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.0002513671643100679}, {"id": 12, "seek": 7976, "start": 95.08000000000001, "end": 100.08000000000001, "text": " that I mentioned here, but there are some things that I didn't do myself or just consulted on,", "tokens": [300, 286, 2835, 510, 11, 457, 456, 366, 512, 721, 300, 286, 994, 380, 360, 2059, 420, 445, 47941, 322, 11], "temperature": 0.0, "avg_logprob": -0.14339847171429507, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.0002513671643100679}, {"id": 13, "seek": 7976, "start": 100.08000000000001, "end": 106.72, "text": " stuff like that. I'll try to make a distinction about it, but I might miss some stuff. Yeah,", "tokens": [1507, 411, 300, 13, 286, 603, 853, 281, 652, 257, 16844, 466, 309, 11, 457, 286, 1062, 1713, 512, 1507, 13, 865, 11], "temperature": 0.0, "avg_logprob": -0.14339847171429507, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.0002513671643100679}, {"id": 14, "seek": 10672, "start": 106.72, "end": 110.28, "text": " so back then it was a really basic setup. We basically had three servers. They were all running", "tokens": [370, 646, 550, 309, 390, 257, 534, 3875, 8657, 13, 492, 1936, 632, 1045, 15909, 13, 814, 645, 439, 2614], "temperature": 0.0, "avg_logprob": -0.13443655886892544, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.00035846757236868143}, {"id": 15, "seek": 10672, "start": 110.28, "end": 117.44, "text": " TransDNS. There was no load balancing. The signing stack was built using DNS stack tools for those", "tokens": [6531, 35, 42003, 13, 821, 390, 572, 3677, 22495, 13, 440, 13393, 8630, 390, 3094, 1228, 35153, 8630, 3873, 337, 729], "temperature": 0.0, "avg_logprob": -0.13443655886892544, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.00035846757236868143}, {"id": 16, "seek": 10672, "start": 117.44, "end": 122.75999999999999, "text": " few people who still know what it is. And there was a lot of automation on top of DNS stack tools", "tokens": [1326, 561, 567, 920, 458, 437, 309, 307, 13, 400, 456, 390, 257, 688, 295, 17769, 322, 1192, 295, 35153, 8630, 3873], "temperature": 0.0, "avg_logprob": -0.13443655886892544, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.00035846757236868143}, {"id": 17, "seek": 10672, "start": 122.75999999999999, "end": 127.52, "text": " in PHP to make all of that work and ultimately upload stuff to the registry because we were one", "tokens": [294, 47298, 281, 652, 439, 295, 300, 589, 293, 6284, 6580, 1507, 281, 264, 36468, 570, 321, 645, 472], "temperature": 0.0, "avg_logprob": -0.13443655886892544, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.00035846757236868143}, {"id": 18, "seek": 10672, "start": 127.52, "end": 133.76, "text": " of the, we were a registrar, so a lot of the stuff was automated. All of this DNS propagation was", "tokens": [295, 264, 11, 321, 645, 257, 11376, 5352, 11, 370, 257, 688, 295, 264, 1507, 390, 18473, 13, 1057, 295, 341, 35153, 38377, 390], "temperature": 0.0, "avg_logprob": -0.13443655886892544, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.00035846757236868143}, {"id": 19, "seek": 13376, "start": 133.76, "end": 140.2, "text": " done to cron jobs, which means it was very slow. It took roughly five minutes to propagate a DNS", "tokens": [1096, 281, 941, 266, 4782, 11, 597, 1355, 309, 390, 588, 2964, 13, 467, 1890, 9810, 1732, 2077, 281, 48256, 257, 35153], "temperature": 0.0, "avg_logprob": -0.17441912778874033, "compression_ratio": 1.556, "no_speech_prob": 0.00018014817032963037}, {"id": 20, "seek": 13376, "start": 140.2, "end": 146.44, "text": " change, which back then wasn't really a big problem. But as we went on, it became more and more an", "tokens": [1319, 11, 597, 646, 550, 2067, 380, 534, 257, 955, 1154, 13, 583, 382, 321, 1437, 322, 11, 309, 3062, 544, 293, 544, 364], "temperature": 0.0, "avg_logprob": -0.17441912778874033, "compression_ratio": 1.556, "no_speech_prob": 0.00018014817032963037}, {"id": 21, "seek": 13376, "start": 146.44, "end": 151.12, "text": " issue, especially when we got let's encrypts and you needed to quickly update your DNS to get your", "tokens": [2734, 11, 2318, 562, 321, 658, 718, 311, 17972, 39280, 293, 291, 2978, 281, 2661, 5623, 428, 35153, 281, 483, 428], "temperature": 0.0, "avg_logprob": -0.17441912778874033, "compression_ratio": 1.556, "no_speech_prob": 0.00018014817032963037}, {"id": 22, "seek": 13376, "start": 151.12, "end": 158.48, "text": " certificate signed. We had at the high, I think we still have roughly one million zones in the", "tokens": [15953, 8175, 13, 492, 632, 412, 264, 1090, 11, 286, 519, 321, 920, 362, 9810, 472, 2459, 16025, 294, 264], "temperature": 0.0, "avg_logprob": -0.17441912778874033, "compression_ratio": 1.556, "no_speech_prob": 0.00018014817032963037}, {"id": 23, "seek": 15848, "start": 158.48, "end": 166.39999999999998, "text": " setup, most of which so about 80, 90% are DNS signed. There were very few people back then that", "tokens": [8657, 11, 881, 295, 597, 370, 466, 4688, 11, 4289, 4, 366, 35153, 8175, 13, 821, 645, 588, 1326, 561, 646, 550, 300], "temperature": 0.0, "avg_logprob": -0.1863378602631238, "compression_ratio": 1.5, "no_speech_prob": 9.391173080075532e-05}, {"id": 24, "seek": 15848, "start": 166.39999999999998, "end": 172.44, "text": " actually knew stuff about it and dared to work on it. I think maybe three or four people, one of", "tokens": [767, 2586, 1507, 466, 309, 293, 44564, 281, 589, 322, 309, 13, 286, 519, 1310, 1045, 420, 1451, 561, 11, 472, 295], "temperature": 0.0, "avg_logprob": -0.1863378602631238, "compression_ratio": 1.5, "no_speech_prob": 9.391173080075532e-05}, {"id": 25, "seek": 15848, "start": 172.44, "end": 180.28, "text": " which was I. It had very bad RSC compatibility, which I will get into a little bit later. Adding", "tokens": [597, 390, 286, 13, 467, 632, 588, 1578, 497, 20839, 34237, 11, 597, 286, 486, 483, 666, 257, 707, 857, 1780, 13, 31204], "temperature": 0.0, "avg_logprob": -0.1863378602631238, "compression_ratio": 1.5, "no_speech_prob": 9.391173080075532e-05}, {"id": 26, "seek": 15848, "start": 180.28, "end": 185.44, "text": " new record types, which Kevin mentioned like SSHFP was a lot of work because there was a", "tokens": [777, 2136, 3467, 11, 597, 9954, 2835, 411, 12238, 39, 45882, 390, 257, 688, 295, 589, 570, 456, 390, 257], "temperature": 0.0, "avg_logprob": -0.1863378602631238, "compression_ratio": 1.5, "no_speech_prob": 9.391173080075532e-05}, {"id": 27, "seek": 18544, "start": 185.44, "end": 191.56, "text": " interpreter in TransDNS itself, which had to be written in C and writing interpreters in C for", "tokens": [34132, 294, 6531, 35, 42003, 2564, 11, 597, 632, 281, 312, 3720, 294, 383, 293, 3579, 17489, 1559, 294, 383, 337], "temperature": 0.0, "avg_logprob": -0.2012809630363218, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.00012764029088430107}, {"id": 28, "seek": 18544, "start": 191.56, "end": 198.44, "text": " stack strings is not fun. And well, I fixed that initial buffer overflow block, but the main", "tokens": [8630, 13985, 307, 406, 1019, 13, 400, 731, 11, 286, 6806, 300, 5883, 21762, 37772, 3461, 11, 457, 264, 2135], "temperature": 0.0, "avg_logprob": -0.2012809630363218, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.00012764029088430107}, {"id": 29, "seek": 18544, "start": 198.44, "end": 204.68, "text": " problem was there just not a lot of bound checking in the code. So yeah, there were a lot of hidden", "tokens": [1154, 390, 456, 445, 406, 257, 688, 295, 5472, 8568, 294, 264, 3089, 13, 407, 1338, 11, 456, 645, 257, 688, 295, 7633], "temperature": 0.0, "avg_logprob": -0.2012809630363218, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.00012764029088430107}, {"id": 30, "seek": 18544, "start": 204.68, "end": 212.56, "text": " bugs that probably should be fixed as well. So we took a few initial steps because initially,", "tokens": [15120, 300, 1391, 820, 312, 6806, 382, 731, 13, 407, 321, 1890, 257, 1326, 5883, 4439, 570, 9105, 11], "temperature": 0.0, "avg_logprob": -0.2012809630363218, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.00012764029088430107}, {"id": 31, "seek": 21256, "start": 212.56, "end": 217.72, "text": " because we had the three servers, there was no loan financing, we meant that if we restarted", "tokens": [570, 321, 632, 264, 1045, 15909, 11, 456, 390, 572, 10529, 22286, 11, 321, 4140, 300, 498, 321, 21022, 292], "temperature": 0.0, "avg_logprob": -0.17449171353230433, "compression_ratio": 1.7, "no_speech_prob": 0.00018221385835204273}, {"id": 32, "seek": 21256, "start": 217.72, "end": 223.04, "text": " TransDNS, one of the servers would stop responding until the restart was done. And the restart took", "tokens": [6531, 35, 42003, 11, 472, 295, 264, 15909, 576, 1590, 16670, 1826, 264, 21022, 390, 1096, 13, 400, 264, 21022, 1890], "temperature": 0.0, "avg_logprob": -0.17449171353230433, "compression_ratio": 1.7, "no_speech_prob": 0.00018221385835204273}, {"id": 33, "seek": 21256, "start": 223.04, "end": 229.4, "text": " roughly 15 minutes because every single record would get loaded into memory. And since we had a", "tokens": [9810, 2119, 2077, 570, 633, 2167, 2136, 576, 483, 13210, 666, 4675, 13, 400, 1670, 321, 632, 257], "temperature": 0.0, "avg_logprob": -0.17449171353230433, "compression_ratio": 1.7, "no_speech_prob": 0.00018221385835204273}, {"id": 34, "seek": 21256, "start": 229.4, "end": 235.4, "text": " million zones, I think it was like 25 million records or something back then, it just took a", "tokens": [2459, 16025, 11, 286, 519, 309, 390, 411, 3552, 2459, 7724, 420, 746, 646, 550, 11, 309, 445, 1890, 257], "temperature": 0.0, "avg_logprob": -0.17449171353230433, "compression_ratio": 1.7, "no_speech_prob": 0.00018221385835204273}, {"id": 35, "seek": 21256, "start": 235.4, "end": 242.4, "text": " lot of time and might have used the quick DNS zone parser stuff. So the first thing we did was", "tokens": [688, 295, 565, 293, 1062, 362, 1143, 264, 1702, 35153, 6668, 21156, 260, 1507, 13, 407, 264, 700, 551, 321, 630, 390], "temperature": 0.0, "avg_logprob": -0.17449171353230433, "compression_ratio": 1.7, "no_speech_prob": 0.00018221385835204273}, {"id": 36, "seek": 24240, "start": 242.4, "end": 248.44, "text": " implement load balancing. This was before DNS. This was a thing. So what we tried initially was", "tokens": [4445, 3677, 22495, 13, 639, 390, 949, 35153, 13, 639, 390, 257, 551, 13, 407, 437, 321, 3031, 9105, 390], "temperature": 0.0, "avg_logprob": -0.18900538713504106, "compression_ratio": 1.4623115577889447, "no_speech_prob": 0.0002874146157409996}, {"id": 37, "seek": 24240, "start": 248.44, "end": 255.96, "text": " relay day, which some of the BSD folks might know. It did work, but we had a lot of weird issues.", "tokens": [24214, 786, 11, 597, 512, 295, 264, 363, 23969, 4024, 1062, 458, 13, 467, 630, 589, 11, 457, 321, 632, 257, 688, 295, 3657, 2663, 13], "temperature": 0.0, "avg_logprob": -0.18900538713504106, "compression_ratio": 1.4623115577889447, "no_speech_prob": 0.0002874146157409996}, {"id": 38, "seek": 24240, "start": 255.96, "end": 264.84000000000003, "text": " It was really hard to debug. And so eventually we switched to using HAProxy for TCP, which works,", "tokens": [467, 390, 534, 1152, 281, 24083, 13, 400, 370, 4728, 321, 16858, 281, 1228, 389, 4715, 340, 12876, 337, 48965, 11, 597, 1985, 11], "temperature": 0.0, "avg_logprob": -0.18900538713504106, "compression_ratio": 1.4623115577889447, "no_speech_prob": 0.0002874146157409996}, {"id": 39, "seek": 26484, "start": 264.84, "end": 272.79999999999995, "text": " nothing more to say about it. And I wrote something rather quickly in C roughly based on the", "tokens": [1825, 544, 281, 584, 466, 309, 13, 400, 286, 4114, 746, 2831, 2661, 294, 383, 9810, 2361, 322, 264], "temperature": 0.0, "avg_logprob": -0.11997737007579584, "compression_ratio": 1.6120689655172413, "no_speech_prob": 0.0001086754709831439}, {"id": 40, "seek": 26484, "start": 272.79999999999995, "end": 279.08, "text": " TransDNS code to forward the UDP stuff. That worked quite well and actually enabled us to", "tokens": [6531, 35, 42003, 3089, 281, 2128, 264, 624, 11373, 1507, 13, 663, 2732, 1596, 731, 293, 767, 15172, 505, 281], "temperature": 0.0, "avg_logprob": -0.11997737007579584, "compression_ratio": 1.6120689655172413, "no_speech_prob": 0.0001086754709831439}, {"id": 41, "seek": 26484, "start": 279.08, "end": 283.91999999999996, "text": " actually iterate on the TransDNS code because we could do save restarts without having to worry", "tokens": [767, 44497, 322, 264, 6531, 35, 42003, 3089, 570, 321, 727, 360, 3155, 1472, 11814, 1553, 1419, 281, 3292], "temperature": 0.0, "avg_logprob": -0.11997737007579584, "compression_ratio": 1.6120689655172413, "no_speech_prob": 0.0001086754709831439}, {"id": 42, "seek": 26484, "start": 283.91999999999996, "end": 290.12, "text": " about queries being dropped. And that allowed me to fix the glaring issues like there not being", "tokens": [466, 24109, 885, 8119, 13, 400, 300, 4350, 385, 281, 3191, 264, 1563, 1921, 2663, 411, 456, 406, 885], "temperature": 0.0, "avg_logprob": -0.11997737007579584, "compression_ratio": 1.6120689655172413, "no_speech_prob": 0.0001086754709831439}, {"id": 43, "seek": 29012, "start": 290.12, "end": 296.36, "text": " any bounce checking in the code. So we had less risk of buffer overflows. And I fixed a lot of", "tokens": [604, 15894, 8568, 294, 264, 3089, 13, 407, 321, 632, 1570, 3148, 295, 21762, 670, 33229, 13, 400, 286, 6806, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.1855836968672903, "compression_ratio": 1.515748031496063, "no_speech_prob": 0.0001093577011488378}, {"id": 44, "seek": 29012, "start": 296.36, "end": 303.48, "text": " the EDS issues that were becoming a problem at that point. Eventually when DNS was a little bit", "tokens": [264, 462, 11844, 2663, 300, 645, 5617, 257, 1154, 412, 300, 935, 13, 17586, 562, 35153, 390, 257, 707, 857], "temperature": 0.0, "avg_logprob": -0.1855836968672903, "compression_ratio": 1.515748031496063, "no_speech_prob": 0.0001093577011488378}, {"id": 45, "seek": 29012, "start": 303.48, "end": 308.24, "text": " more mature, we switched to that because otherwise I had to maintain another piece of software and", "tokens": [544, 14442, 11, 321, 16858, 281, 300, 570, 5911, 286, 632, 281, 6909, 1071, 2522, 295, 4722, 293], "temperature": 0.0, "avg_logprob": -0.1855836968672903, "compression_ratio": 1.515748031496063, "no_speech_prob": 0.0001093577011488378}, {"id": 46, "seek": 29012, "start": 308.24, "end": 315.88, "text": " I really didn't feel like that. In the meantime, it did improve the TCP stack a lot in TransDNS", "tokens": [286, 534, 994, 380, 841, 411, 300, 13, 682, 264, 14991, 11, 309, 630, 3470, 264, 48965, 8630, 257, 688, 294, 6531, 35, 42003], "temperature": 0.0, "avg_logprob": -0.1855836968672903, "compression_ratio": 1.515748031496063, "no_speech_prob": 0.0001093577011488378}, {"id": 47, "seek": 31588, "start": 315.88, "end": 324.56, "text": " because we noticed that especially SIDN, the.nlRegistrar registry, did a lot of TCP queries", "tokens": [570, 321, 5694, 300, 2318, 318, 2777, 45, 11, 264, 2411, 77, 75, 40888, 468, 5352, 36468, 11, 630, 257, 688, 295, 48965, 24109], "temperature": 0.0, "avg_logprob": -0.215690674320344, "compression_ratio": 1.516, "no_speech_prob": 0.00013602315448224545}, {"id": 48, "seek": 31588, "start": 324.56, "end": 332.52, "text": " and the original implementation was basically just spawn a new thread for every TCP connection,", "tokens": [293, 264, 3380, 11420, 390, 1936, 445, 17088, 257, 777, 7207, 337, 633, 48965, 4984, 11], "temperature": 0.0, "avg_logprob": -0.215690674320344, "compression_ratio": 1.516, "no_speech_prob": 0.00013602315448224545}, {"id": 49, "seek": 31588, "start": 332.52, "end": 338.96, "text": " but once you get to about a thousand threads, that's not a great solution. So I changed to a", "tokens": [457, 1564, 291, 483, 281, 466, 257, 4714, 19314, 11, 300, 311, 406, 257, 869, 3827, 13, 407, 286, 3105, 281, 257], "temperature": 0.0, "avg_logprob": -0.215690674320344, "compression_ratio": 1.516, "no_speech_prob": 0.00013602315448224545}, {"id": 50, "seek": 31588, "start": 338.96, "end": 345.04, "text": " polling-based model, worked great, got pretty high performance, and we never had a problem with it", "tokens": [29518, 12, 6032, 2316, 11, 2732, 869, 11, 658, 1238, 1090, 3389, 11, 293, 321, 1128, 632, 257, 1154, 365, 309], "temperature": 0.0, "avg_logprob": -0.215690674320344, "compression_ratio": 1.516, "no_speech_prob": 0.00013602315448224545}, {"id": 51, "seek": 34504, "start": 345.04, "end": 349.68, "text": " after that. The only thing I changed later is when we moved to Linux, I changed to ePool.", "tokens": [934, 300, 13, 440, 787, 551, 286, 3105, 1780, 307, 562, 321, 4259, 281, 18734, 11, 286, 3105, 281, 308, 47, 1092, 13], "temperature": 0.0, "avg_logprob": -0.19564088633362675, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00024170501274056733}, {"id": 52, "seek": 34504, "start": 349.68, "end": 359.16, "text": " Yeah, so SIDN had validation monitoring and we kept getting reminded about the fact that we were", "tokens": [865, 11, 370, 318, 2777, 45, 632, 24071, 11028, 293, 321, 4305, 1242, 15920, 466, 264, 1186, 300, 321, 645], "temperature": 0.0, "avg_logprob": -0.19564088633362675, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00024170501274056733}, {"id": 53, "seek": 34504, "start": 359.16, "end": 368.88, "text": " doing a lot of stuff wrong. So yeah, we actually had one specific case that basically covered most", "tokens": [884, 257, 688, 295, 1507, 2085, 13, 407, 1338, 11, 321, 767, 632, 472, 2685, 1389, 300, 1936, 5343, 881], "temperature": 0.0, "avg_logprob": -0.19564088633362675, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00024170501274056733}, {"id": 54, "seek": 36888, "start": 368.88, "end": 376.92, "text": " of the, I think it was about 80% of those errors, and that's, it's 62 issues, but they have the", "tokens": [295, 264, 11, 286, 519, 309, 390, 466, 4688, 4, 295, 729, 13603, 11, 293, 300, 311, 11, 309, 311, 24536, 2663, 11, 457, 436, 362, 264], "temperature": 0.0, "avg_logprob": -0.18740709092881944, "compression_ratio": 1.545945945945946, "no_speech_prob": 0.0001618333044461906}, {"id": 55, "seek": 36888, "start": 376.92, "end": 382.32, "text": " same cause. So the first issue was the incorrect handling of wildcards. So if you have a wildcard", "tokens": [912, 3082, 13, 407, 264, 700, 2734, 390, 264, 18424, 13175, 295, 4868, 40604, 13, 407, 498, 291, 362, 257, 4868, 22259], "temperature": 0.0, "avg_logprob": -0.18740709092881944, "compression_ratio": 1.545945945945946, "no_speech_prob": 0.0001618333044461906}, {"id": 56, "seek": 36888, "start": 382.32, "end": 393.92, "text": " that, for example, star.nl, then you have a record c.nl, and then you try to resolve a.c.nl,", "tokens": [300, 11, 337, 1365, 11, 3543, 13, 77, 75, 11, 550, 291, 362, 257, 2136, 269, 13, 77, 75, 11, 293, 550, 291, 853, 281, 14151, 257, 13, 66, 13, 77, 75, 11], "temperature": 0.0, "avg_logprob": -0.18740709092881944, "compression_ratio": 1.545945945945946, "no_speech_prob": 0.0001618333044461906}, {"id": 57, "seek": 39392, "start": 393.92, "end": 400.16, "text": " it should not hit the wildcard, because c.nl exists, which means you should return a no-data,", "tokens": [309, 820, 406, 2045, 264, 4868, 22259, 11, 570, 269, 13, 77, 75, 8198, 11, 597, 1355, 291, 820, 2736, 257, 572, 12, 67, 3274, 11], "temperature": 0.0, "avg_logprob": -0.20151578163614078, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.00018268960411660373}, {"id": 58, "seek": 39392, "start": 400.16, "end": 408.08000000000004, "text": " or an extra main in this case, but transdns didn't really care, so it would just return the data", "tokens": [420, 364, 2857, 2135, 294, 341, 1389, 11, 457, 1145, 67, 3695, 994, 380, 534, 1127, 11, 370, 309, 576, 445, 2736, 264, 1412], "temperature": 0.0, "avg_logprob": -0.20151578163614078, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.00018268960411660373}, {"id": 59, "seek": 39392, "start": 408.08000000000004, "end": 413.56, "text": " from the wildcard. Very useful, makes it a lot easier to configure DNS, but it causes some issues,", "tokens": [490, 264, 4868, 22259, 13, 4372, 4420, 11, 1669, 309, 257, 688, 3571, 281, 22162, 35153, 11, 457, 309, 7700, 512, 2663, 11], "temperature": 0.0, "avg_logprob": -0.20151578163614078, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.00018268960411660373}, {"id": 60, "seek": 39392, "start": 413.56, "end": 418.88, "text": " especially with DNS validation. The second issue was basically the same only in the", "tokens": [2318, 365, 35153, 24071, 13, 440, 1150, 2734, 390, 1936, 264, 912, 787, 294, 264], "temperature": 0.0, "avg_logprob": -0.20151578163614078, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.00018268960411660373}, {"id": 61, "seek": 41888, "start": 418.88, "end": 427.48, "text": " empty non-terminals. If a.b.c exists, and you try to resolve b.c, even though there's nothing", "tokens": [6707, 2107, 12, 29725, 1124, 13, 759, 257, 13, 65, 13, 66, 8198, 11, 293, 291, 853, 281, 14151, 272, 13, 66, 11, 754, 1673, 456, 311, 1825], "temperature": 0.0, "avg_logprob": -0.17810682150033805, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.00012733327457681298}, {"id": 62, "seek": 41888, "start": 427.48, "end": 432.08, "text": " specific on b.c, you should say there's no data, rather than it's a non-existent domain,", "tokens": [2685, 322, 272, 13, 66, 11, 291, 820, 584, 456, 311, 572, 1412, 11, 2831, 813, 309, 311, 257, 2107, 12, 18217, 317, 9274, 11], "temperature": 0.0, "avg_logprob": -0.17810682150033805, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.00012733327457681298}, {"id": 63, "seek": 41888, "start": 432.08, "end": 440.15999999999997, "text": " also causes the DNS validation errors. Same basic cause. The solution was to switch from,", "tokens": [611, 7700, 264, 35153, 24071, 13603, 13, 10635, 3875, 3082, 13, 440, 3827, 390, 281, 3679, 490, 11], "temperature": 0.0, "avg_logprob": -0.17810682150033805, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.00012733327457681298}, {"id": 64, "seek": 41888, "start": 440.15999999999997, "end": 448.6, "text": " in transdns, to switch from an ordered map that used the type and the domain name as the key,", "tokens": [294, 1145, 67, 3695, 11, 281, 3679, 490, 364, 8866, 4471, 300, 1143, 264, 2010, 293, 264, 9274, 1315, 382, 264, 2141, 11], "temperature": 0.0, "avg_logprob": -0.17810682150033805, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.00012733327457681298}, {"id": 65, "seek": 44860, "start": 448.6, "end": 454.44, "text": " to a map that only used the domain name as the key, and have an array in there with the type,", "tokens": [281, 257, 4471, 300, 787, 1143, 264, 9274, 1315, 382, 264, 2141, 11, 293, 362, 364, 10225, 294, 456, 365, 264, 2010, 11], "temperature": 0.0, "avg_logprob": -0.1316431619787729, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00013604217383544892}, {"id": 66, "seek": 44860, "start": 454.44, "end": 460.84000000000003, "text": " which could also be empty, so we would immediately notice if there was a label in our way. That", "tokens": [597, 727, 611, 312, 6707, 11, 370, 321, 576, 4258, 3449, 498, 456, 390, 257, 7645, 294, 527, 636, 13, 663], "temperature": 0.0, "avg_logprob": -0.1316431619787729, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00013604217383544892}, {"id": 67, "seek": 44860, "start": 460.84000000000003, "end": 468.12, "text": " worked well. I actually did it this next slide, so the only problem is we couldn't just deploy", "tokens": [2732, 731, 13, 286, 767, 630, 309, 341, 958, 4137, 11, 370, 264, 787, 1154, 307, 321, 2809, 380, 445, 7274], "temperature": 0.0, "avg_logprob": -0.1316431619787729, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00013604217383544892}, {"id": 68, "seek": 44860, "start": 468.12, "end": 473.92, "text": " that, because we might break stuff for our customers, and customers get a little bit difficult", "tokens": [300, 11, 570, 321, 1062, 1821, 1507, 337, 527, 4581, 11, 293, 4581, 483, 257, 707, 857, 2252], "temperature": 0.0, "avg_logprob": -0.1316431619787729, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00013604217383544892}, {"id": 69, "seek": 47392, "start": 473.92, "end": 479.32, "text": " if you break stuff for them. So what I decided was, okay, for the NSIC it's broken anyways,", "tokens": [498, 291, 1821, 1507, 337, 552, 13, 407, 437, 286, 3047, 390, 11, 1392, 11, 337, 264, 15943, 2532, 309, 311, 5463, 13448, 11], "temperature": 0.0, "avg_logprob": -0.217682916290906, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00020519924873951823}, {"id": 70, "seek": 47392, "start": 479.32, "end": 485.68, "text": " because the NSIC enables for the resolvers would just return errors when you have one of these", "tokens": [570, 264, 15943, 2532, 17077, 337, 264, 7923, 840, 576, 445, 2736, 13603, 562, 291, 362, 472, 295, 613], "temperature": 0.0, "avg_logprob": -0.217682916290906, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00020519924873951823}, {"id": 71, "seek": 47392, "start": 485.68, "end": 492.20000000000005, "text": " labels. So what I did is fixing the two steps. I initially enabled it only for the NSIC queries,", "tokens": [16949, 13, 407, 437, 286, 630, 307, 19442, 264, 732, 4439, 13, 286, 9105, 15172, 309, 787, 337, 264, 15943, 2532, 24109, 11], "temperature": 0.0, "avg_logprob": -0.217682916290906, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00020519924873951823}, {"id": 72, "seek": 47392, "start": 492.20000000000005, "end": 499.12, "text": " so the correct behavior, and kept the wrong behavior for non-DNSIC queries, and in between we", "tokens": [370, 264, 3006, 5223, 11, 293, 4305, 264, 2085, 5223, 337, 2107, 12, 35, 42003, 2532, 24109, 11, 293, 294, 1296, 321], "temperature": 0.0, "avg_logprob": -0.217682916290906, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00020519924873951823}, {"id": 73, "seek": 49912, "start": 499.12, "end": 504.68, "text": " just covered a large amount of queries. I think I did two days of DCP dumping, and milling it down", "tokens": [445, 5343, 257, 2416, 2372, 295, 24109, 13, 286, 519, 286, 630, 732, 1708, 295, 9114, 47, 42224, 11, 293, 1728, 278, 309, 760], "temperature": 0.0, "avg_logprob": -0.17988871583844177, "compression_ratio": 1.5789473684210527, "no_speech_prob": 7.641858974238858e-05}, {"id": 74, "seek": 49912, "start": 504.68, "end": 511.32, "text": " to the actual unique queries, and compared what our name servers would respond for DNSIC versus", "tokens": [281, 264, 3539, 3845, 24109, 11, 293, 5347, 437, 527, 1315, 15909, 576, 4196, 337, 413, 42003, 2532, 5717], "temperature": 0.0, "avg_logprob": -0.17988871583844177, "compression_ratio": 1.5789473684210527, "no_speech_prob": 7.641858974238858e-05}, {"id": 75, "seek": 49912, "start": 511.32, "end": 516.6, "text": " non-DNSIC. For everything that had a difference, we contacted the customers, and told them, hey,", "tokens": [2107, 12, 35, 42003, 2532, 13, 1171, 1203, 300, 632, 257, 2649, 11, 321, 21546, 264, 4581, 11, 293, 1907, 552, 11, 4177, 11], "temperature": 0.0, "avg_logprob": -0.17988871583844177, "compression_ratio": 1.5789473684210527, "no_speech_prob": 7.641858974238858e-05}, {"id": 76, "seek": 49912, "start": 516.6, "end": 522.12, "text": " you need to fix this. I think it was only about 20 to 30 customers. It was actually not that many,", "tokens": [291, 643, 281, 3191, 341, 13, 286, 519, 309, 390, 787, 466, 945, 281, 2217, 4581, 13, 467, 390, 767, 406, 300, 867, 11], "temperature": 0.0, "avg_logprob": -0.17988871583844177, "compression_ratio": 1.5789473684210527, "no_speech_prob": 7.641858974238858e-05}, {"id": 77, "seek": 52212, "start": 522.12, "end": 529.52, "text": " so that made it a lot easier. And then we just, at some point I decided I'll flip the switch.", "tokens": [370, 300, 1027, 309, 257, 688, 3571, 13, 400, 550, 321, 445, 11, 412, 512, 935, 286, 3047, 286, 603, 7929, 264, 3679, 13], "temperature": 0.0, "avg_logprob": -0.1817798614501953, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.00014020926028024405}, {"id": 78, "seek": 52212, "start": 529.52, "end": 533.8, "text": " There were a few customers that didn't respond, but at some point you just have to decide to.", "tokens": [821, 645, 257, 1326, 4581, 300, 994, 380, 4196, 11, 457, 412, 512, 935, 291, 445, 362, 281, 4536, 281, 13], "temperature": 0.0, "avg_logprob": -0.1817798614501953, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.00014020926028024405}, {"id": 79, "seek": 52212, "start": 533.8, "end": 542.5600000000001, "text": " Don't give a fuck. One other small issue we have with RFC implementation was the NSIC", "tokens": [1468, 380, 976, 257, 3275, 13, 1485, 661, 1359, 2734, 321, 362, 365, 497, 18671, 11420, 390, 264, 15943, 2532], "temperature": 0.0, "avg_logprob": -0.1817798614501953, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.00014020926028024405}, {"id": 80, "seek": 52212, "start": 542.5600000000001, "end": 547.84, "text": " implementation, because almost all of our zones use NSIC tree. The NSIC implementation was not", "tokens": [11420, 11, 570, 1920, 439, 295, 527, 16025, 764, 15943, 2532, 4230, 13, 440, 15943, 2532, 11420, 390, 406], "temperature": 0.0, "avg_logprob": -0.1817798614501953, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.00014020926028024405}, {"id": 81, "seek": 54784, "start": 547.84, "end": 555.72, "text": " as well tested as the NSIC tree implementation, so it was wrong, like really wrong. I just rewrote", "tokens": [382, 731, 8246, 382, 264, 15943, 2532, 4230, 11420, 11, 370, 309, 390, 2085, 11, 411, 534, 2085, 13, 286, 445, 319, 7449, 1370], "temperature": 0.0, "avg_logprob": -0.1829843887915978, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.00022866373183205724}, {"id": 82, "seek": 54784, "start": 555.72, "end": 565.72, "text": " it from scratch, and then it worked, but yeah. So we started to think about moving to PowerDNS,", "tokens": [309, 490, 8459, 11, 293, 550, 309, 2732, 11, 457, 1338, 13, 407, 321, 1409, 281, 519, 466, 2684, 281, 7086, 35, 42003, 11], "temperature": 0.0, "avg_logprob": -0.1829843887915978, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.00022866373183205724}, {"id": 83, "seek": 54784, "start": 565.72, "end": 572.1600000000001, "text": " and the main reason we did was because SIDN announced that we would no longer get a DNSIC", "tokens": [293, 264, 2135, 1778, 321, 630, 390, 570, 318, 2777, 45, 7548, 300, 321, 576, 572, 2854, 483, 257, 413, 42003, 2532], "temperature": 0.0, "avg_logprob": -0.1829843887915978, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.00022866373183205724}, {"id": 84, "seek": 57216, "start": 572.16, "end": 579.48, "text": " incentive for domains using the NSIC algorithm 7. So that's the RSA plus NSIC tree algorithm.", "tokens": [22346, 337, 25514, 1228, 264, 15943, 2532, 9284, 1614, 13, 407, 300, 311, 264, 497, 8886, 1804, 15943, 2532, 4230, 9284, 13], "temperature": 0.0, "avg_logprob": -0.12704341676500108, "compression_ratio": 1.4763948497854078, "no_speech_prob": 0.0003586741804610938}, {"id": 85, "seek": 57216, "start": 579.48, "end": 585.48, "text": " That would cost us a bunch of money, and that's a very good way to stimulate people to do stuff.", "tokens": [663, 576, 2063, 505, 257, 3840, 295, 1460, 11, 293, 300, 311, 257, 588, 665, 636, 281, 31269, 561, 281, 360, 1507, 13], "temperature": 0.0, "avg_logprob": -0.12704341676500108, "compression_ratio": 1.4763948497854078, "no_speech_prob": 0.0003586741804610938}, {"id": 86, "seek": 57216, "start": 585.48, "end": 590.76, "text": " So at this point we decided to buy the bullet and just start over from scratch,", "tokens": [407, 412, 341, 935, 321, 3047, 281, 2256, 264, 11632, 293, 445, 722, 670, 490, 8459, 11], "temperature": 0.0, "avg_logprob": -0.12704341676500108, "compression_ratio": 1.4763948497854078, "no_speech_prob": 0.0003586741804610938}, {"id": 87, "seek": 57216, "start": 590.76, "end": 596.6, "text": " and build a really new, more modern setup. We picked PowerDNS, basically,", "tokens": [293, 1322, 257, 534, 777, 11, 544, 4363, 8657, 13, 492, 6183, 7086, 35, 42003, 11, 1936, 11], "temperature": 0.0, "avg_logprob": -0.12704341676500108, "compression_ratio": 1.4763948497854078, "no_speech_prob": 0.0003586741804610938}, {"id": 88, "seek": 59660, "start": 596.6, "end": 602.6, "text": " partially because we already had some experience with it, and we didn't really want to deal with", "tokens": [18886, 570, 321, 1217, 632, 512, 1752, 365, 309, 11, 293, 321, 994, 380, 534, 528, 281, 2028, 365], "temperature": 0.0, "avg_logprob": -0.10584769406161465, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003512910916469991}, {"id": 89, "seek": 59660, "start": 602.6, "end": 607.28, "text": " zone files, because we had a million zones, and putting them all on a file system makes things", "tokens": [6668, 7098, 11, 570, 321, 632, 257, 2459, 16025, 11, 293, 3372, 552, 439, 322, 257, 3991, 1185, 1669, 721], "temperature": 0.0, "avg_logprob": -0.10584769406161465, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003512910916469991}, {"id": 90, "seek": 59660, "start": 607.28, "end": 617.44, "text": " annoying. So PowerDNS was the only one where we thought, oh, this allows us to do changes via", "tokens": [11304, 13, 407, 7086, 35, 42003, 390, 264, 787, 472, 689, 321, 1194, 11, 1954, 11, 341, 4045, 505, 281, 360, 2962, 5766], "temperature": 0.0, "avg_logprob": -0.10584769406161465, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003512910916469991}, {"id": 91, "seek": 59660, "start": 617.44, "end": 623.36, "text": " the API. We don't need to worry about having separate zone files for every single zone.", "tokens": [264, 9362, 13, 492, 500, 380, 643, 281, 3292, 466, 1419, 4994, 6668, 7098, 337, 633, 2167, 6668, 13], "temperature": 0.0, "avg_logprob": -0.10584769406161465, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003512910916469991}, {"id": 92, "seek": 62336, "start": 623.36, "end": 628.48, "text": " So we needed to pick a PowerDNS backend to use, because PowerDNS is one thing,", "tokens": [407, 321, 2978, 281, 1888, 257, 7086, 35, 42003, 38087, 281, 764, 11, 570, 7086, 35, 42003, 307, 472, 551, 11], "temperature": 0.0, "avg_logprob": -0.18534613899562669, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.0003977797750849277}, {"id": 93, "seek": 62336, "start": 628.48, "end": 633.64, "text": " but you still need something to put stuff in. And there we sort of had to hit a problem,", "tokens": [457, 291, 920, 643, 746, 281, 829, 1507, 294, 13, 400, 456, 321, 1333, 295, 632, 281, 2045, 257, 1154, 11], "temperature": 0.0, "avg_logprob": -0.18534613899562669, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.0003977797750849277}, {"id": 94, "seek": 62336, "start": 633.64, "end": 638.24, "text": " because PowerDNS is really fast, because it's literally just a hash map in memory,", "tokens": [570, 7086, 35, 42003, 307, 534, 2370, 11, 570, 309, 311, 3736, 445, 257, 22019, 4471, 294, 4675, 11], "temperature": 0.0, "avg_logprob": -0.18534613899562669, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.0003977797750849277}, {"id": 95, "seek": 62336, "start": 638.24, "end": 646.12, "text": " so it can basically do instant answers. And while the PowerDNS, as you go back in,", "tokens": [370, 309, 393, 1936, 360, 9836, 6338, 13, 400, 1339, 264, 7086, 35, 42003, 11, 382, 291, 352, 646, 294, 11], "temperature": 0.0, "avg_logprob": -0.18534613899562669, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.0003977797750849277}, {"id": 96, "seek": 62336, "start": 646.12, "end": 651.9200000000001, "text": " is very nice and flexible, but it's not really fast, especially because we had a lot of zones", "tokens": [307, 588, 1481, 293, 11358, 11, 457, 309, 311, 406, 534, 2370, 11, 2318, 570, 321, 632, 257, 688, 295, 16025], "temperature": 0.0, "avg_logprob": -0.18534613899562669, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.0003977797750849277}, {"id": 97, "seek": 65192, "start": 651.92, "end": 659.68, "text": " that would not get very frequent queries. So they'd have a lot of non-active data,", "tokens": [300, 576, 406, 483, 588, 18004, 24109, 13, 407, 436, 1116, 362, 257, 688, 295, 2107, 12, 12596, 1412, 11], "temperature": 0.0, "avg_logprob": -0.12315939153943743, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00010497667972231284}, {"id": 98, "seek": 65192, "start": 659.68, "end": 664.04, "text": " which means the query cache wouldn't really help a lot, which means that we would have", "tokens": [597, 1355, 264, 14581, 19459, 2759, 380, 534, 854, 257, 688, 11, 597, 1355, 300, 321, 576, 362], "temperature": 0.0, "avg_logprob": -0.12315939153943743, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00010497667972231284}, {"id": 99, "seek": 65192, "start": 664.04, "end": 668.24, "text": " a lot of SQL queries continuously, because they would get queries sometimes. It's not a lot.", "tokens": [257, 688, 295, 19200, 24109, 15684, 11, 570, 436, 576, 483, 24109, 2171, 13, 467, 311, 406, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.12315939153943743, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00010497667972231284}, {"id": 100, "seek": 65192, "start": 668.24, "end": 673.92, "text": " The bind backend had the same problem as all the other name servers. We didn't have API support,", "tokens": [440, 14786, 38087, 632, 264, 912, 1154, 382, 439, 264, 661, 1315, 15909, 13, 492, 994, 380, 362, 9362, 1406, 11], "temperature": 0.0, "avg_logprob": -0.12315939153943743, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00010497667972231284}, {"id": 101, "seek": 65192, "start": 673.92, "end": 677.68, "text": " and it would mean we needed to use a lot of zone files, which we didn't want to.", "tokens": [293, 309, 576, 914, 321, 2978, 281, 764, 257, 688, 295, 6668, 7098, 11, 597, 321, 994, 380, 528, 281, 13], "temperature": 0.0, "avg_logprob": -0.12315939153943743, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00010497667972231284}, {"id": 102, "seek": 67768, "start": 677.68, "end": 685.0799999999999, "text": " So introducing the LMDB backend. This already exists at the point that we started looking at it,", "tokens": [407, 15424, 264, 46529, 27735, 38087, 13, 639, 1217, 8198, 412, 264, 935, 300, 321, 1409, 1237, 412, 309, 11], "temperature": 0.0, "avg_logprob": -0.1462583230889362, "compression_ratio": 1.459016393442623, "no_speech_prob": 0.00035720891901291907}, {"id": 103, "seek": 67768, "start": 685.0799999999999, "end": 691.12, "text": " because Hubert had written it. It's very fast, and it has support for the API, which is really nice.", "tokens": [570, 11874, 4290, 632, 3720, 309, 13, 467, 311, 588, 2370, 11, 293, 309, 575, 1406, 337, 264, 9362, 11, 597, 307, 534, 1481, 13], "temperature": 0.0, "avg_logprob": -0.1462583230889362, "compression_ratio": 1.459016393442623, "no_speech_prob": 0.00035720891901291907}, {"id": 104, "seek": 67768, "start": 691.12, "end": 699.4, "text": " It only had one major issue. Because of the way Hubert had implemented it,", "tokens": [467, 787, 632, 472, 2563, 2734, 13, 1436, 295, 264, 636, 11874, 4290, 632, 12270, 309, 11], "temperature": 0.0, "avg_logprob": -0.1462583230889362, "compression_ratio": 1.459016393442623, "no_speech_prob": 0.00035720891901291907}, {"id": 105, "seek": 67768, "start": 699.4, "end": 704.8, "text": " it didn't really allow records bigger than 512 bytes. We have quite a lot of zones.", "tokens": [309, 994, 380, 534, 2089, 7724, 3801, 813, 1025, 4762, 36088, 13, 492, 362, 1596, 257, 688, 295, 16025, 13], "temperature": 0.0, "avg_logprob": -0.1462583230889362, "compression_ratio": 1.459016393442623, "no_speech_prob": 0.00035720891901291907}, {"id": 106, "seek": 70480, "start": 704.8, "end": 713.24, "text": " So I decided to fix that in the end. I wrote a pull request for the Power Genius team,", "tokens": [407, 286, 3047, 281, 3191, 300, 294, 264, 917, 13, 286, 4114, 257, 2235, 5308, 337, 264, 7086, 45818, 1469, 11], "temperature": 0.0, "avg_logprob": -0.18355948274785822, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0003385629097465426}, {"id": 107, "seek": 70480, "start": 713.24, "end": 718.68, "text": " and I think that was pretty quickly accepted into there. It also included some migration code,", "tokens": [293, 286, 519, 300, 390, 1238, 2661, 9035, 666, 456, 13, 467, 611, 5556, 512, 17011, 3089, 11], "temperature": 0.0, "avg_logprob": -0.18355948274785822, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0003385629097465426}, {"id": 108, "seek": 70480, "start": 718.68, "end": 725.68, "text": " so the older the LMDB database would automatically be migrated to the new LMDB database format.", "tokens": [370, 264, 4906, 264, 46529, 27735, 8149, 576, 6772, 312, 48329, 281, 264, 777, 46529, 27735, 8149, 7877, 13], "temperature": 0.0, "avg_logprob": -0.18355948274785822, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0003385629097465426}, {"id": 109, "seek": 70480, "start": 725.68, "end": 731.88, "text": " It also improved performance in some corner cases, but that was not really the goal of this patch.", "tokens": [467, 611, 9689, 3389, 294, 512, 4538, 3331, 11, 457, 300, 390, 406, 534, 264, 3387, 295, 341, 9972, 13], "temperature": 0.0, "avg_logprob": -0.18355948274785822, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0003385629097465426}, {"id": 110, "seek": 73188, "start": 731.88, "end": 739.56, "text": " So then we started moving over. We built a setup. It was really cool. There's a lot of automation", "tokens": [407, 550, 321, 1409, 2684, 670, 13, 492, 3094, 257, 8657, 13, 467, 390, 534, 1627, 13, 821, 311, 257, 688, 295, 17769], "temperature": 0.0, "avg_logprob": -0.18342679089838915, "compression_ratio": 1.5058365758754864, "no_speech_prob": 0.0001423000212525949}, {"id": 111, "seek": 73188, "start": 739.56, "end": 745.08, "text": " around it. It does actually do all the zone transfers via XFR, even though Kevin just said", "tokens": [926, 309, 13, 467, 775, 767, 360, 439, 264, 6668, 29137, 5766, 1783, 34658, 11, 754, 1673, 9954, 445, 848], "temperature": 0.0, "avg_logprob": -0.18342679089838915, "compression_ratio": 1.5058365758754864, "no_speech_prob": 0.0001423000212525949}, {"id": 112, "seek": 73188, "start": 745.08, "end": 749.84, "text": " it's a bad idea if you have a lot of zones. But in practice, it works quite well, except for one", "tokens": [309, 311, 257, 1578, 1558, 498, 291, 362, 257, 688, 295, 16025, 13, 583, 294, 3124, 11, 309, 1985, 1596, 731, 11, 3993, 337, 472], "temperature": 0.0, "avg_logprob": -0.18342679089838915, "compression_ratio": 1.5058365758754864, "no_speech_prob": 0.0001423000212525949}, {"id": 113, "seek": 73188, "start": 749.84, "end": 759.0, "text": " issue. Every first day, our updates would take ages to go through. Basically, we traced it down to an", "tokens": [2734, 13, 2048, 700, 786, 11, 527, 9205, 576, 747, 12357, 281, 352, 807, 13, 8537, 11, 321, 38141, 309, 760, 281, 364], "temperature": 0.0, "avg_logprob": -0.18342679089838915, "compression_ratio": 1.5058365758754864, "no_speech_prob": 0.0001423000212525949}, {"id": 114, "seek": 75900, "start": 759.0, "end": 767.84, "text": " enormous bump in the XFR queues. We would literally have 400,000 XFR queued up. So that was a bit", "tokens": [11322, 9961, 294, 264, 1783, 34658, 631, 1247, 13, 492, 576, 3736, 362, 8423, 11, 1360, 1783, 34658, 631, 5827, 493, 13, 407, 300, 390, 257, 857], "temperature": 0.0, "avg_logprob": -0.12203548922397123, "compression_ratio": 1.5236220472440944, "no_speech_prob": 0.00012016340770060197}, {"id": 115, "seek": 75900, "start": 767.84, "end": 772.96, "text": " of a problem. So the reason this happens is because Power Genius renews its signatures every", "tokens": [295, 257, 1154, 13, 407, 264, 1778, 341, 2314, 307, 570, 7086, 45818, 10162, 82, 1080, 32322, 633], "temperature": 0.0, "avg_logprob": -0.12203548922397123, "compression_ratio": 1.5236220472440944, "no_speech_prob": 0.00012016340770060197}, {"id": 116, "seek": 75900, "start": 772.96, "end": 779.24, "text": " first day of the week. Very nice. We don't have to think about it. Problem is, if you have a million", "tokens": [700, 786, 295, 264, 1243, 13, 4372, 1481, 13, 492, 500, 380, 362, 281, 519, 466, 309, 13, 11676, 307, 11, 498, 291, 362, 257, 2459], "temperature": 0.0, "avg_logprob": -0.12203548922397123, "compression_ratio": 1.5236220472440944, "no_speech_prob": 0.00012016340770060197}, {"id": 117, "seek": 75900, "start": 779.24, "end": 784.68, "text": " zones, that takes quite a while, especially because we were running our hidden primary on a VM,", "tokens": [16025, 11, 300, 2516, 1596, 257, 1339, 11, 2318, 570, 321, 645, 2614, 527, 7633, 6194, 322, 257, 18038, 11], "temperature": 0.0, "avg_logprob": -0.12203548922397123, "compression_ratio": 1.5236220472440944, "no_speech_prob": 0.00012016340770060197}, {"id": 118, "seek": 78468, "start": 784.68, "end": 789.64, "text": " so it was also not that quick to answer queries. So we could have just shown more hardware in it,", "tokens": [370, 309, 390, 611, 406, 300, 1702, 281, 1867, 24109, 13, 407, 321, 727, 362, 445, 4898, 544, 8837, 294, 309, 11], "temperature": 0.0, "avg_logprob": -0.17846511021133296, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00013672481873072684}, {"id": 119, "seek": 78468, "start": 789.64, "end": 794.56, "text": " but we decided to look a little bit more at a more sustainable solution, because, well,", "tokens": [457, 321, 3047, 281, 574, 257, 707, 857, 544, 412, 257, 544, 11235, 3827, 11, 570, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.17846511021133296, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00013672481873072684}, {"id": 120, "seek": 78468, "start": 794.56, "end": 799.8, "text": " if it works with one million zones on the Phosomers scene, it will still work if you have 10", "tokens": [498, 309, 1985, 365, 472, 2459, 16025, 322, 264, 2623, 329, 298, 433, 4145, 11, 309, 486, 920, 589, 498, 291, 362, 1266], "temperature": 0.0, "avg_logprob": -0.17846511021133296, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00013672481873072684}, {"id": 121, "seek": 78468, "start": 799.8, "end": 805.88, "text": " million zones. So I discussed it with the Power Genius guys, and I came up with a solution which", "tokens": [2459, 16025, 13, 407, 286, 7152, 309, 365, 264, 7086, 45818, 1074, 11, 293, 286, 1361, 493, 365, 257, 3827, 597], "temperature": 0.0, "avg_logprob": -0.17846511021133296, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00013672481873072684}, {"id": 122, "seek": 78468, "start": 805.88, "end": 811.4799999999999, "text": " is XFR priority levels. So rather than treating all XFRs that need to be done at the same level,", "tokens": [307, 1783, 34658, 9365, 4358, 13, 407, 2831, 813, 15083, 439, 1783, 34658, 82, 300, 643, 281, 312, 1096, 412, 264, 912, 1496, 11], "temperature": 0.0, "avg_logprob": -0.17846511021133296, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00013672481873072684}, {"id": 123, "seek": 81148, "start": 811.48, "end": 817.48, "text": " we gave more priority to things that are user-initiated. So if you initiate an XFR", "tokens": [321, 2729, 544, 9365, 281, 721, 300, 366, 4195, 12, 259, 8707, 770, 13, 407, 498, 291, 31574, 364, 1783, 34658], "temperature": 0.0, "avg_logprob": -0.16913913927580182, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.00019765981414821}, {"id": 124, "seek": 81148, "start": 817.48, "end": 822.88, "text": " via Power Genius control, it will be first in the queue. Whatever else is in the queue,", "tokens": [5766, 7086, 45818, 1969, 11, 309, 486, 312, 700, 294, 264, 18639, 13, 8541, 1646, 307, 294, 264, 18639, 11], "temperature": 0.0, "avg_logprob": -0.16913913927580182, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.00019765981414821}, {"id": 125, "seek": 81148, "start": 822.88, "end": 828.6800000000001, "text": " that one was treated first. After that, there's the API, notifies, solar refresh, and signature", "tokens": [300, 472, 390, 8668, 700, 13, 2381, 300, 11, 456, 311, 264, 9362, 11, 406, 11221, 11, 7936, 15134, 11, 293, 13397], "temperature": 0.0, "avg_logprob": -0.16913913927580182, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.00019765981414821}, {"id": 126, "seek": 81148, "start": 828.6800000000001, "end": 834.64, "text": " refresh is the lowest priority. That meant that, yes, we would still have a quite a large queue,", "tokens": [15134, 307, 264, 12437, 9365, 13, 663, 4140, 300, 11, 2086, 11, 321, 576, 920, 362, 257, 1596, 257, 2416, 18639, 11], "temperature": 0.0, "avg_logprob": -0.16913913927580182, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.00019765981414821}, {"id": 127, "seek": 83464, "start": 834.64, "end": 841.52, "text": " but we could still process our updates very quickly. That was included into Power Genius,", "tokens": [457, 321, 727, 920, 1399, 527, 9205, 588, 2661, 13, 663, 390, 5556, 666, 7086, 45818, 11], "temperature": 0.0, "avg_logprob": -0.24019280659783745, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.00021657162869814783}, {"id": 128, "seek": 83464, "start": 841.52, "end": 847.88, "text": " right with us. Well, in 4.5, it was included. We still saw the use queues, but those own", "tokens": [558, 365, 505, 13, 1042, 11, 294, 1017, 13, 20, 11, 309, 390, 5556, 13, 492, 920, 1866, 264, 764, 631, 1247, 11, 457, 729, 1065], "temperature": 0.0, "avg_logprob": -0.24019280659783745, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.00021657162869814783}, {"id": 129, "seek": 83464, "start": 847.88, "end": 852.8, "text": " updates would pretty quickly propagate. So that, for us, was fine. We never had a problem with it", "tokens": [9205, 576, 1238, 2661, 48256, 13, 407, 300, 11, 337, 505, 11, 390, 2489, 13, 492, 1128, 632, 257, 1154, 365, 309], "temperature": 0.0, "avg_logprob": -0.24019280659783745, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.00021657162869814783}, {"id": 130, "seek": 83464, "start": 852.8, "end": 861.4, "text": " after that. Yeah, and then we had some other issues, most of which were in a minor solved in", "tokens": [934, 300, 13, 865, 11, 293, 550, 321, 632, 512, 661, 2663, 11, 881, 295, 597, 645, 294, 257, 6696, 13041, 294], "temperature": 0.0, "avg_logprob": -0.24019280659783745, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.00021657162869814783}, {"id": 131, "seek": 86140, "start": 861.4, "end": 865.6, "text": " the low-banus layer or just fixed in Power Genius updates. The TCP performance is still", "tokens": [264, 2295, 12, 5144, 301, 4583, 420, 445, 6806, 294, 7086, 45818, 9205, 13, 440, 48965, 3389, 307, 920], "temperature": 0.0, "avg_logprob": -0.22349645653549505, "compression_ratio": 1.551440329218107, "no_speech_prob": 0.0005412248428910971}, {"id": 132, "seek": 86140, "start": 865.6, "end": 872.16, "text": " something I want to look at in Power Genius just for fun, as a open-source developer. It's on my", "tokens": [746, 286, 528, 281, 574, 412, 294, 7086, 45818, 445, 337, 1019, 11, 382, 257, 1269, 12, 41676, 10754, 13, 467, 311, 322, 452], "temperature": 0.0, "avg_logprob": -0.22349645653549505, "compression_ratio": 1.551440329218107, "no_speech_prob": 0.0005412248428910971}, {"id": 133, "seek": 86140, "start": 872.16, "end": 878.92, "text": " list of things I want to improve. We had some various smaller bugs in the NMDB backend because", "tokens": [1329, 295, 721, 286, 528, 281, 3470, 13, 492, 632, 512, 3683, 4356, 15120, 294, 264, 426, 44, 27735, 38087, 570], "temperature": 0.0, "avg_logprob": -0.22349645653549505, "compression_ratio": 1.551440329218107, "no_speech_prob": 0.0005412248428910971}, {"id": 134, "seek": 86140, "start": 878.92, "end": 887.0, "text": " it was quite new. We were not the first one that ran it at really large scale, but we were one of", "tokens": [309, 390, 1596, 777, 13, 492, 645, 406, 264, 700, 472, 300, 5872, 309, 412, 534, 2416, 4373, 11, 457, 321, 645, 472, 295], "temperature": 0.0, "avg_logprob": -0.22349645653549505, "compression_ratio": 1.551440329218107, "no_speech_prob": 0.0005412248428910971}, {"id": 135, "seek": 88700, "start": 887.0, "end": 893.2, "text": " the first ones, and we did see some problems that nobody else had had yet. One CVE we discovered", "tokens": [264, 700, 2306, 11, 293, 321, 630, 536, 512, 2740, 300, 5079, 1646, 632, 632, 1939, 13, 1485, 383, 7540, 321, 6941], "temperature": 0.0, "avg_logprob": -0.1609354235909202, "compression_ratio": 1.625, "no_speech_prob": 0.00019515470194164664}, {"id": 136, "seek": 88700, "start": 893.2, "end": 899.04, "text": " literally within the day of rolling out a new version, so that was very fun for Peter because", "tokens": [3736, 1951, 264, 786, 295, 9439, 484, 257, 777, 3037, 11, 370, 300, 390, 588, 1019, 337, 6508, 570], "temperature": 0.0, "avg_logprob": -0.1609354235909202, "compression_ratio": 1.625, "no_speech_prob": 0.00019515470194164664}, {"id": 137, "seek": 88700, "start": 899.04, "end": 907.68, "text": " he got to roll out a new lose a day after he released the previous one. We had an issue that", "tokens": [415, 658, 281, 3373, 484, 257, 777, 3624, 257, 786, 934, 415, 4736, 264, 3894, 472, 13, 492, 632, 364, 2734, 300], "temperature": 0.0, "avg_logprob": -0.1609354235909202, "compression_ratio": 1.625, "no_speech_prob": 0.00019515470194164664}, {"id": 138, "seek": 88700, "start": 907.68, "end": 913.4, "text": " there were certain query patterns that we would get that were specifically designed to target", "tokens": [456, 645, 1629, 14581, 8294, 300, 321, 576, 483, 300, 645, 4682, 4761, 281, 3779], "temperature": 0.0, "avg_logprob": -0.1609354235909202, "compression_ratio": 1.625, "no_speech_prob": 0.00019515470194164664}, {"id": 139, "seek": 91340, "start": 913.4, "end": 920.04, "text": " a weakness in Power Genius. That was a transient as we didn't care about them, but Power Genius did", "tokens": [257, 12772, 294, 7086, 45818, 13, 663, 390, 257, 41998, 382, 321, 994, 380, 1127, 466, 552, 11, 457, 7086, 45818, 630], "temperature": 0.0, "avg_logprob": -0.1650371876629916, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.00011796130274888128}, {"id": 140, "seek": 91340, "start": 920.04, "end": 925.3199999999999, "text": " get affected. We eventually resolved this by adding some detection at the low-banus layer that would", "tokens": [483, 8028, 13, 492, 4728, 20772, 341, 538, 5127, 512, 17784, 412, 264, 2295, 12, 5144, 301, 4583, 300, 576], "temperature": 0.0, "avg_logprob": -0.1650371876629916, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.00011796130274888128}, {"id": 141, "seek": 91340, "start": 925.3199999999999, "end": 932.68, "text": " just block queries for those affected domains. It would mean that that customer's domain would", "tokens": [445, 3461, 24109, 337, 729, 8028, 25514, 13, 467, 576, 914, 300, 300, 5474, 311, 9274, 576], "temperature": 0.0, "avg_logprob": -0.1650371876629916, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.00011796130274888128}, {"id": 142, "seek": 91340, "start": 932.68, "end": 937.84, "text": " have limited functionality, but at least it would still work, and all the other customers would not", "tokens": [362, 5567, 14980, 11, 457, 412, 1935, 309, 576, 920, 589, 11, 293, 439, 264, 661, 4581, 576, 406], "temperature": 0.0, "avg_logprob": -0.1650371876629916, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.00011796130274888128}, {"id": 143, "seek": 93784, "start": 937.84, "end": 947.8000000000001, "text": " be affected, which was for us the most important thing. Yeah, so some closing thoughts. Yeah,", "tokens": [312, 8028, 11, 597, 390, 337, 505, 264, 881, 1021, 551, 13, 865, 11, 370, 512, 10377, 4598, 13, 865, 11], "temperature": 0.0, "avg_logprob": -0.1665756956059882, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.00026534468634054065}, {"id": 144, "seek": 93784, "start": 947.8000000000001, "end": 953.32, "text": " migrating a home root setup is really not for the faint of heart. However, running one is also", "tokens": [6186, 8754, 257, 1280, 5593, 8657, 307, 534, 406, 337, 264, 21104, 295, 1917, 13, 2908, 11, 2614, 472, 307, 611], "temperature": 0.0, "avg_logprob": -0.1665756956059882, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.00026534468634054065}, {"id": 145, "seek": 93784, "start": 953.32, "end": 961.0400000000001, "text": " not for the faint of heart. Yeah, it is worth it. It just gives you a lot more flexibility because", "tokens": [406, 337, 264, 21104, 295, 1917, 13, 865, 11, 309, 307, 3163, 309, 13, 467, 445, 2709, 291, 257, 688, 544, 12635, 570], "temperature": 0.0, "avg_logprob": -0.1665756956059882, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.00026534468634054065}, {"id": 146, "seek": 93784, "start": 961.0400000000001, "end": 966.84, "text": " now adding new record types is just a question of adding them in our front end and making them", "tokens": [586, 5127, 777, 2136, 3467, 307, 445, 257, 1168, 295, 5127, 552, 294, 527, 1868, 917, 293, 1455, 552], "temperature": 0.0, "avg_logprob": -0.1665756956059882, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.00026534468634054065}, {"id": 147, "seek": 96684, "start": 966.84, "end": 972.36, "text": " work. Whereas before, we had to add the new record type at every single step in the stack,", "tokens": [589, 13, 13813, 949, 11, 321, 632, 281, 909, 264, 777, 2136, 2010, 412, 633, 2167, 1823, 294, 264, 8630, 11], "temperature": 0.0, "avg_logprob": -0.20373503694829254, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.00012853795487899333}, {"id": 148, "seek": 96684, "start": 972.36, "end": 983.4, "text": " and it just really took a lot of time. We can even, in theory, add different brands of", "tokens": [293, 309, 445, 534, 1890, 257, 688, 295, 565, 13, 492, 393, 754, 11, 294, 5261, 11, 909, 819, 11324, 295], "temperature": 0.0, "avg_logprob": -0.20373503694829254, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.00012853795487899333}, {"id": 149, "seek": 96684, "start": 983.4, "end": 988.44, "text": " secondaries. Currently, there's a few issues that were prevented, but it's relatively easy to solve,", "tokens": [1150, 4889, 13, 19964, 11, 456, 311, 257, 1326, 2663, 300, 645, 27314, 11, 457, 309, 311, 7226, 1858, 281, 5039, 11], "temperature": 0.0, "avg_logprob": -0.20373503694829254, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.00012853795487899333}, {"id": 150, "seek": 96684, "start": 988.44, "end": 996.5600000000001, "text": " so we could just run not as a secondary or NSD or even bind if he would want to do that for", "tokens": [370, 321, 727, 445, 1190, 406, 382, 257, 11396, 420, 15943, 35, 420, 754, 14786, 498, 415, 576, 528, 281, 360, 300, 337], "temperature": 0.0, "avg_logprob": -0.20373503694829254, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.00012853795487899333}, {"id": 151, "seek": 99656, "start": 996.56, "end": 1005.64, "text": " some reason. What I did really, really notice is don't try to do this in one go, because it's a lot", "tokens": [512, 1778, 13, 708, 286, 630, 534, 11, 534, 3449, 307, 500, 380, 853, 281, 360, 341, 294, 472, 352, 11, 570, 309, 311, 257, 688], "temperature": 0.0, "avg_logprob": -0.1300764272708704, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.00029410235583782196}, {"id": 152, "seek": 99656, "start": 1005.64, "end": 1011.16, "text": " of work, and you'll make mistakes. If you do it in smaller steps, the mistakes will be smaller,", "tokens": [295, 589, 11, 293, 291, 603, 652, 8038, 13, 759, 291, 360, 309, 294, 4356, 4439, 11, 264, 8038, 486, 312, 4356, 11], "temperature": 0.0, "avg_logprob": -0.1300764272708704, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.00029410235583782196}, {"id": 153, "seek": 99656, "start": 1011.16, "end": 1018.64, "text": " easier to fix, and it also just feels a lot better if you can accomplish some things in", "tokens": [3571, 281, 3191, 11, 293, 309, 611, 445, 3417, 257, 688, 1101, 498, 291, 393, 9021, 512, 721, 294], "temperature": 0.0, "avg_logprob": -0.1300764272708704, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.00029410235583782196}, {"id": 154, "seek": 99656, "start": 1018.64, "end": 1023.9599999999999, "text": " between rather than trying to do it all at once. One thing I wanted to ask, DNSSEC incentives,", "tokens": [1296, 2831, 813, 1382, 281, 360, 309, 439, 412, 1564, 13, 1485, 551, 286, 1415, 281, 1029, 11, 35153, 5879, 34, 23374, 11], "temperature": 0.0, "avg_logprob": -0.1300764272708704, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.00029410235583782196}, {"id": 155, "seek": 102396, "start": 1023.96, "end": 1031.4, "text": " they work both when trying to get people to use DNSSEC, but they also work to improve the", "tokens": [436, 589, 1293, 562, 1382, 281, 483, 561, 281, 764, 35153, 5879, 34, 11, 457, 436, 611, 589, 281, 3470, 264], "temperature": 0.0, "avg_logprob": -0.13877085277012416, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0003374912485014647}, {"id": 156, "seek": 102396, "start": 1031.4, "end": 1036.2, "text": " quality of the DNSSEC, because we've seen, especially in the.nl zone, because I've also", "tokens": [3125, 295, 264, 35153, 5879, 34, 11, 570, 321, 600, 1612, 11, 2318, 294, 264, 2411, 77, 75, 6668, 11, 570, 286, 600, 611], "temperature": 0.0, "avg_logprob": -0.13877085277012416, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0003374912485014647}, {"id": 157, "seek": 102396, "start": 1036.2, "end": 1041.96, "text": " been involved in that work a little bit, some very bad implementations that got fixed when the", "tokens": [668, 3288, 294, 300, 589, 257, 707, 857, 11, 512, 588, 1578, 4445, 763, 300, 658, 6806, 562, 264], "temperature": 0.0, "avg_logprob": -0.13877085277012416, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0003374912485014647}, {"id": 158, "seek": 102396, "start": 1041.96, "end": 1050.52, "text": " rules were made stricter, including ours initially, but were even the worst ones. Yeah, that is it.", "tokens": [4474, 645, 1027, 1056, 299, 391, 11, 3009, 11896, 9105, 11, 457, 645, 754, 264, 5855, 2306, 13, 865, 11, 300, 307, 309, 13], "temperature": 0.0, "avg_logprob": -0.13877085277012416, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0003374912485014647}, {"id": 159, "seek": 105052, "start": 1050.52, "end": 1056.96, "text": " For the people that would like to see, I've open sourced DNS before I left the company,", "tokens": [1171, 264, 561, 300, 576, 411, 281, 536, 11, 286, 600, 1269, 11006, 1232, 35153, 949, 286, 1411, 264, 2237, 11], "temperature": 0.0, "avg_logprob": -0.16177201572852798, "compression_ratio": 1.4270833333333333, "no_speech_prob": 0.0004899806226603687}, {"id": 160, "seek": 105052, "start": 1056.96, "end": 1065.12, "text": " so I can see it myself as well, so that's fun. It's on GitHub. I've also put the URLs for", "tokens": [370, 286, 393, 536, 309, 2059, 382, 731, 11, 370, 300, 311, 1019, 13, 467, 311, 322, 23331, 13, 286, 600, 611, 829, 264, 43267, 337], "temperature": 0.0, "avg_logprob": -0.16177201572852798, "compression_ratio": 1.4270833333333333, "no_speech_prob": 0.0004899806226603687}, {"id": 161, "seek": 105052, "start": 1065.12, "end": 1070.2, "text": " the two major pull requests I made. There's a bunch of other ones, but I haven't put all of them", "tokens": [264, 732, 2563, 2235, 12475, 286, 1027, 13, 821, 311, 257, 3840, 295, 661, 2306, 11, 457, 286, 2378, 380, 829, 439, 295, 552], "temperature": 0.0, "avg_logprob": -0.16177201572852798, "compression_ratio": 1.4270833333333333, "no_speech_prob": 0.0004899806226603687}, {"id": 162, "seek": 107020, "start": 1070.2, "end": 1084.3600000000001, "text": " in there, and that's about it. So, questions?", "tokens": [294, 456, 11, 293, 300, 311, 466, 309, 13, 407, 11, 1651, 30], "temperature": 0.0, "avg_logprob": -0.3626990037805894, "compression_ratio": 0.8823529411764706, "no_speech_prob": 0.0003053602413274348}, {"id": 163, "seek": 108436, "start": 1084.36, "end": 1110.08, "text": " So, that makes it a bit of a more concern in your case, and I used to be a customer. On the upside,", "tokens": [407, 11, 300, 1669, 309, 257, 857, 295, 257, 544, 3136, 294, 428, 1389, 11, 293, 286, 1143, 281, 312, 257, 5474, 13, 1282, 264, 14119, 11], "temperature": 0.0, "avg_logprob": -0.5541143109721522, "compression_ratio": 1.1, "no_speech_prob": 0.007814111188054085}, {"id": 164, "seek": 111008, "start": 1110.08, "end": 1115.72, "text": " most of these methods probably weren't noticed by the majority, but I think you should take it", "tokens": [881, 295, 613, 7150, 1391, 4999, 380, 5694, 538, 264, 6286, 11, 457, 286, 519, 291, 820, 747, 309], "temperature": 0.0, "avg_logprob": -0.28600832049766284, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0004937290214002132}, {"id": 165, "seek": 111008, "start": 1115.72, "end": 1120.6399999999999, "text": " more seriously if you were a company that actually makes money out of posting here.", "tokens": [544, 6638, 498, 291, 645, 257, 2237, 300, 767, 1669, 1460, 484, 295, 15978, 510, 13], "temperature": 0.0, "avg_logprob": -0.28600832049766284, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0004937290214002132}, {"id": 166, "seek": 111008, "start": 1120.6399999999999, "end": 1128.1999999999998, "text": " So, the comment is that we both made mistakes. It was a bit related to the talk Kevin did,", "tokens": [407, 11, 264, 2871, 307, 300, 321, 1293, 1027, 8038, 13, 467, 390, 257, 857, 4077, 281, 264, 751, 9954, 630, 11], "temperature": 0.0, "avg_logprob": -0.28600832049766284, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0004937290214002132}, {"id": 167, "seek": 111008, "start": 1128.1999999999998, "end": 1136.48, "text": " so a lot of the things that we said are related, and the comment is Kevin was only doing it for", "tokens": [370, 257, 688, 295, 264, 721, 300, 321, 848, 366, 4077, 11, 293, 264, 2871, 307, 9954, 390, 787, 884, 309, 337], "temperature": 0.0, "avg_logprob": -0.28600832049766284, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0004937290214002132}, {"id": 168, "seek": 113648, "start": 1136.48, "end": 1143.88, "text": " himself, and we were doing it for paying customers. Yeah, I agree. When I started, there were a lot", "tokens": [3647, 11, 293, 321, 645, 884, 309, 337, 6229, 4581, 13, 865, 11, 286, 3986, 13, 1133, 286, 1409, 11, 456, 645, 257, 688], "temperature": 0.0, "avg_logprob": -0.14174902195833167, "compression_ratio": 1.4836065573770492, "no_speech_prob": 0.000535225379280746}, {"id": 169, "seek": 113648, "start": 1143.88, "end": 1150.64, "text": " of issues, and I've tried three years to attempt to fix them as much as I could. To be clear,", "tokens": [295, 2663, 11, 293, 286, 600, 3031, 1045, 924, 281, 5217, 281, 3191, 552, 382, 709, 382, 286, 727, 13, 1407, 312, 1850, 11], "temperature": 0.0, "avg_logprob": -0.14174902195833167, "compression_ratio": 1.4836065573770492, "no_speech_prob": 0.000535225379280746}, {"id": 170, "seek": 113648, "start": 1150.64, "end": 1156.2, "text": " I wasn't hired to maintain trans-DNS. That just happened to be something that got shoved", "tokens": [286, 2067, 380, 13144, 281, 6909, 1145, 12, 35, 42003, 13, 663, 445, 2011, 281, 312, 746, 300, 658, 2223, 937], "temperature": 0.0, "avg_logprob": -0.14174902195833167, "compression_ratio": 1.4836065573770492, "no_speech_prob": 0.000535225379280746}, {"id": 171, "seek": 113648, "start": 1156.2, "end": 1165.28, "text": " into my lab because I knew some C and C++. I became pretty passionate about it.", "tokens": [666, 452, 2715, 570, 286, 2586, 512, 383, 293, 383, 25472, 13, 286, 3062, 1238, 11410, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.14174902195833167, "compression_ratio": 1.4836065573770492, "no_speech_prob": 0.000535225379280746}, {"id": 172, "seek": 116528, "start": 1165.28, "end": 1171.3999999999999, "text": " I came pretty quickly rolled into the PowerDNS community. I also added a lot of contributions", "tokens": [286, 1361, 1238, 2661, 14306, 666, 264, 7086, 35, 42003, 1768, 13, 286, 611, 3869, 257, 688, 295, 15725], "temperature": 0.0, "avg_logprob": -0.26705510565575136, "compression_ratio": 1.3546099290780143, "no_speech_prob": 0.0004325909831095487}, {"id": 173, "seek": 116528, "start": 1171.3999999999999, "end": 1180.68, "text": " to DNS when that was getting started up. I agree with the initial statement. I've tried to fix it", "tokens": [281, 35153, 562, 300, 390, 1242, 1409, 493, 13, 286, 3986, 365, 264, 5883, 5629, 13, 286, 600, 3031, 281, 3191, 309], "temperature": 0.0, "avg_logprob": -0.26705510565575136, "compression_ratio": 1.3546099290780143, "no_speech_prob": 0.0004325909831095487}, {"id": 174, "seek": 118068, "start": 1180.68, "end": 1196.68, "text": " as much as I could. Sometimes, you set out with certain criteria. You build something that can meet that criteria, and it scales to a certain point.", "tokens": [382, 709, 382, 286, 727, 13, 4803, 11, 291, 992, 484, 365, 1629, 11101, 13, 509, 1322, 746, 300, 393, 1677, 300, 11101, 11, 293, 309, 17408, 281, 257, 1629, 935, 13], "temperature": 0.2, "avg_logprob": -0.3022994465298123, "compression_ratio": 1.3097345132743363, "no_speech_prob": 0.001367464428767562}, {"id": 175, "seek": 119668, "start": 1196.68, "end": 1212.68, "text": " Eventually, you get to a million customers, a lot of customers. The company would start off with a million customers, and maybe at the time that this was a good system, things would fly to me. But as the business grew and things grow,", "tokens": [17586, 11, 291, 483, 281, 257, 2459, 4581, 11, 257, 688, 295, 4581, 13, 440, 2237, 576, 722, 766, 365, 257, 2459, 4581, 11, 293, 1310, 412, 264, 565, 300, 341, 390, 257, 665, 1185, 11, 721, 576, 3603, 281, 385, 13, 583, 382, 264, 1606, 6109, 293, 721, 1852, 11], "temperature": 0.0, "avg_logprob": -0.507756874778054, "compression_ratio": 1.5394736842105263, "no_speech_prob": 0.00020559609401971102}, {"id": 176, "seek": 121268, "start": 1212.68, "end": 1228.68, "text": " you have to do exactly what he did. You evaluate it and say, you know, it's time for something different. He identified that and made the changes accordingly.", "tokens": [291, 362, 281, 360, 2293, 437, 415, 630, 13, 509, 13059, 309, 293, 584, 11, 291, 458, 11, 309, 311, 565, 337, 746, 819, 13, 634, 9234, 300, 293, 1027, 264, 2962, 19717, 13], "temperature": 0.0, "avg_logprob": -0.35137312035811574, "compression_ratio": 1.2741935483870968, "no_speech_prob": 0.0003123227215837687}, {"id": 177, "seek": 122868, "start": 1228.68, "end": 1245.68, "text": " A brief resume, he said that sometimes due to scaling, you run into issues that you hadn't foreseen when you were in it, and he set something up. Just taking a step to resolve them in the end can be a good thing.", "tokens": [316, 5353, 15358, 11, 415, 848, 300, 2171, 3462, 281, 21589, 11, 291, 1190, 666, 2663, 300, 291, 8782, 380, 2091, 22008, 562, 291, 645, 294, 309, 11, 293, 415, 992, 746, 493, 13, 1449, 1940, 257, 1823, 281, 14151, 552, 294, 264, 917, 393, 312, 257, 665, 551, 13], "temperature": 0.0, "avg_logprob": -0.2469373279147678, "compression_ratio": 1.4228187919463087, "no_speech_prob": 0.0014613025123253465}, {"id": 178, "seek": 124568, "start": 1245.68, "end": 1267.68, "text": " There was a question there. The question is how did they get them to agree with over sourcing it. At the point that I open sourced it, I was sort of CTO slash head of R&D of the Dutch part of the organization.", "tokens": [821, 390, 257, 1168, 456, 13, 440, 1168, 307, 577, 630, 436, 483, 552, 281, 3986, 365, 670, 11006, 2175, 309, 13, 1711, 264, 935, 300, 286, 1269, 11006, 1232, 309, 11, 286, 390, 1333, 295, 383, 15427, 17330, 1378, 295, 497, 5, 35, 295, 264, 15719, 644, 295, 264, 4475, 13], "temperature": 0.0, "avg_logprob": -0.2334280354636056, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0028308092150837183}, {"id": 179, "seek": 126768, "start": 1267.68, "end": 1277.68, "text": " Also, I only open sourced it after we totally took it out of production, so it's mainly a historic interest thing.", "tokens": [2743, 11, 286, 787, 1269, 11006, 1232, 309, 934, 321, 3879, 1890, 309, 484, 295, 4265, 11, 370, 309, 311, 8704, 257, 13236, 1179, 551, 13], "temperature": 0.0, "avg_logprob": -0.12664580345153809, "compression_ratio": 1.289855072463768, "no_speech_prob": 0.0005072979256510735}, {"id": 180, "seek": 126768, "start": 1277.68, "end": 1284.68, "text": " Did you ever consider open sourcing trans-DNS before switching?", "tokens": [2589, 291, 1562, 1949, 1269, 11006, 2175, 1145, 12, 35, 42003, 949, 16493, 30], "temperature": 0.0, "avg_logprob": -0.12664580345153809, "compression_ratio": 1.289855072463768, "no_speech_prob": 0.0005072979256510735}, {"id": 181, "seek": 128468, "start": 1284.68, "end": 1300.68, "text": " So the question is, did we consider open sourcing before switching? No. And I'll tell you, we weren't very proud of, at least I wasn't proud of the source quality.", "tokens": [407, 264, 1168, 307, 11, 630, 321, 1949, 1269, 11006, 2175, 949, 16493, 30, 883, 13, 400, 286, 603, 980, 291, 11, 321, 4999, 380, 588, 4570, 295, 11, 412, 1935, 286, 2067, 380, 4570, 295, 264, 4009, 3125, 13], "temperature": 0.0, "avg_logprob": -0.14404220345579546, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.000337832432705909}, {"id": 182, "seek": 128468, "start": 1300.68, "end": 1308.68, "text": " I didn't write it myself, all of it. I only contributed to it later. I tried to improve it as much as I could, but it's still not...", "tokens": [286, 994, 380, 2464, 309, 2059, 11, 439, 295, 309, 13, 286, 787, 18434, 281, 309, 1780, 13, 286, 3031, 281, 3470, 309, 382, 709, 382, 286, 727, 11, 457, 309, 311, 920, 406, 485], "temperature": 0.0, "avg_logprob": -0.14404220345579546, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.000337832432705909}, {"id": 183, "seek": 130868, "start": 1308.68, "end": 1317.68, "text": " It's very focused on just doing one thing, and it's very good at that, but it's not very applicable to use by others.", "tokens": [467, 311, 588, 5178, 322, 445, 884, 472, 551, 11, 293, 309, 311, 588, 665, 412, 300, 11, 457, 309, 311, 406, 588, 21142, 281, 764, 538, 2357, 13], "temperature": 0.0, "avg_logprob": -0.06307904092889083, "compression_ratio": 1.6866952789699572, "no_speech_prob": 0.0007560436497442424}, {"id": 184, "seek": 130868, "start": 1317.68, "end": 1323.68, "text": " So I think it's interesting now to see some of the tricks to make things really fast that you can see in the code.", "tokens": [407, 286, 519, 309, 311, 1880, 586, 281, 536, 512, 295, 264, 11733, 281, 652, 721, 534, 2370, 300, 291, 393, 536, 294, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.06307904092889083, "compression_ratio": 1.6866952789699572, "no_speech_prob": 0.0007560436497442424}, {"id": 185, "seek": 132368, "start": 1323.68, "end": 1338.68, "text": " But beyond that, I would never use it in a production environment other than the one it was in, because that one was built specifically to run around that code.", "tokens": [583, 4399, 300, 11, 286, 576, 1128, 764, 309, 294, 257, 4265, 2823, 661, 813, 264, 472, 309, 390, 294, 11, 570, 300, 472, 390, 3094, 4682, 281, 1190, 926, 300, 3089, 13], "temperature": 0.0, "avg_logprob": -0.08095618196435876, "compression_ratio": 1.322314049586777, "no_speech_prob": 0.0008500897092744708}, {"id": 186, "seek": 133868, "start": 1338.68, "end": 1352.68, "text": " What's actually the motivation for implementing the DNS hosting and trans-DNS? I think even around the time when you started as a company, there was not a software available that could have been used.", "tokens": [708, 311, 767, 264, 12335, 337, 18114, 264, 35153, 16058, 293, 1145, 12, 35, 42003, 30, 286, 519, 754, 926, 264, 565, 562, 291, 1409, 382, 257, 2237, 11, 456, 390, 406, 257, 4722, 2435, 300, 727, 362, 668, 1143, 13], "temperature": 0.0, "avg_logprob": -0.28030895657009547, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0009376747184433043}, {"id": 187, "seek": 135268, "start": 1352.68, "end": 1371.68, "text": " So the question is, what was the motivation to implement their own DNS software? So to be clear, trans-DNS was implemented in 2003, so this was roughly when power-DNS started to grow, but the problem was that there were already quite a lot of zones in there,", "tokens": [407, 264, 1168, 307, 11, 437, 390, 264, 12335, 281, 4445, 641, 1065, 35153, 4722, 30, 407, 281, 312, 1850, 11, 1145, 12, 35, 42003, 390, 12270, 294, 16416, 11, 370, 341, 390, 9810, 562, 1347, 12, 35, 42003, 1409, 281, 1852, 11, 457, 264, 1154, 390, 300, 456, 645, 1217, 1596, 257, 688, 295, 16025, 294, 456, 11], "temperature": 0.0, "avg_logprob": -0.12483979028368754, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.0002496040251571685}, {"id": 188, "seek": 137168, "start": 1371.68, "end": 1382.68, "text": " and it just got a little bit cumbersome using bind, because that was the primary name-server software you'd use back then, and yeah, that was the main motivation.", "tokens": [293, 309, 445, 658, 257, 707, 857, 12713, 1616, 423, 1228, 14786, 11, 570, 300, 390, 264, 6194, 1315, 12, 12484, 331, 4722, 291, 1116, 764, 646, 550, 11, 293, 1338, 11, 300, 390, 264, 2135, 12335, 13], "temperature": 0.0, "avg_logprob": -0.15199417196294313, "compression_ratio": 1.5186721991701244, "no_speech_prob": 0.0005884417914785445}, {"id": 189, "seek": 137168, "start": 1382.68, "end": 1396.68, "text": " Bind was getting annoying because you had to have a lot of zone files, and everything was running on 3BSD using UFS, so there was a 32,000 files per directory limit at that point, which also didn't help.", "tokens": [363, 471, 390, 1242, 11304, 570, 291, 632, 281, 362, 257, 688, 295, 6668, 7098, 11, 293, 1203, 390, 2614, 322, 805, 8176, 35, 1228, 624, 29318, 11, 370, 456, 390, 257, 8858, 11, 1360, 7098, 680, 21120, 4948, 412, 300, 935, 11, 597, 611, 994, 380, 854, 13], "temperature": 0.0, "avg_logprob": -0.15199417196294313, "compression_ratio": 1.5186721991701244, "no_speech_prob": 0.0005884417914785445}, {"id": 190, "seek": 139668, "start": 1396.68, "end": 1407.68, "text": " I mean, there's ways to solve that, that's not that complicated, but that was the main motivation as well, as I think there were some performance issues in bind back then that were relatively easily resolved.", "tokens": [286, 914, 11, 456, 311, 2098, 281, 5039, 300, 11, 300, 311, 406, 300, 6179, 11, 457, 300, 390, 264, 2135, 12335, 382, 731, 11, 382, 286, 519, 456, 645, 512, 3389, 2663, 294, 14786, 646, 550, 300, 645, 7226, 3612, 20772, 13], "temperature": 0.0, "avg_logprob": -0.12983262538909912, "compression_ratio": 1.573394495412844, "no_speech_prob": 0.0002983855956699699}, {"id": 191, "seek": 139668, "start": 1407.68, "end": 1420.68, "text": " The other alternatives would have been GGB DNS, but that had its own things, like the guy that wrote it, not saying you should use it.", "tokens": [440, 661, 20478, 576, 362, 668, 460, 8769, 35153, 11, 457, 300, 632, 1080, 1065, 721, 11, 411, 264, 2146, 300, 4114, 309, 11, 406, 1566, 291, 820, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.12983262538909912, "compression_ratio": 1.573394495412844, "no_speech_prob": 0.0002983855956699699}, {"id": 192, "seek": 142068, "start": 1420.68, "end": 1426.68, "text": " Anything else?", "tokens": [50364, 11998, 1646, 30, 50664], "temperature": 0.0, "avg_logprob": -0.2904215455055237, "compression_ratio": 0.6363636363636364, "no_speech_prob": 0.0008611531229689717}], "language": "en"}