{"text": " Hello, hello, good day, good day. I think that's sort of the Brussels welcome. So I want to talk about what we're doing in the Postgres project with respect to translation. Seems like the last two talks already solved 50% of my problems, so there was already a good outcome of coming here. I want to talk a little bit more sort of the lower levels of what Getax specifically does, but also goes kind of through what other things we're doing. So I, in the Postgres project, I'm just a C programmer, it's my job really to do the translation sort of as a hobby on the side. I have done initially sort of most of the setup of, you know, sort of the source code level, what do you call it, internationalization in that case, right, and then I'm also doing some of the translation. And yeah, I've been, it turns out also the first false I went to was 20 years ago, so I like coming here because, you know, there's a Postgres dev room happening at the same time in a different building, but I like to come to all the other places and sort of intersect with other communities and learn about other kind of stuff that's happening. So it's kind of a good benefit of FOSDEM. So what's Postgres? It's a, you know, don't need to go into details, but just, it's a little bit, it's a little bit different. It has different sort of requirements, right? It's a database system. It's, you know, fairly big and fairly old and, but it's, you know, it's different from like a GUI program, let's say, right? Something we've, you know, leap off is, or we'll hear from KDE later and things like that. I think it just, you know, it lives, it lives much longer and has sort of longer like sort of stability requirements and things like that. And that also kind of makes the maintenance of everything a little bit more complicated. We also maintain back branches, so we have a yearly release and, but we still maintain the old releases for at least five years. So at any given moment, we have four or five or six releases live and then that gives it sort of interesting challenges with like backpatching stuff. Just I was quite interested in the last question we had in the previous talk about this translation memory and sort of that wrong truth. Can we like automatically apply the memory to the previous branches and stuff like that? So this sort of stuff is sort of a practical challenge because you have to keep copying the same thing to all the different branches and so on. In any case, so how, what are we doing in Postgres? You know, we use GetX as in the title. Now put this sort of standard new question mark, it's kind of weird because, again, Postgres is old and, you know, runs on servers is a little bit different from sort of what runs on a laptop or an app, right? Because for example, we also support operating systems that might still be already be forgotten like AIX and Solaris and they have GetX originally came from the sort of Solaris here somehow and there's still a, well, I don't know what it is now, but like a Solaris native Solaris GetX exists. It's, you know, that's distinct from new. But it's sort of old, has bugs and doesn't parse stuff correctly sometimes. So when you just sort of use the new version, then sometimes the files you distribute don't work on old Solaris for some reason, right? And then this is sort of just a weird situation. You have to like then fix these things and then, or hope that Solaris dies at some point, right? Stuff like that. So it's like that. So we have, I mean, you know, we hear from KDE next, I already looked at their abstract. This is obviously not a lot in terms of how many languages and message catalogs and strings we have, but it's more than something you can just deal with in an afternoon, right? It's just a lot of stuff to move around. I mentioned with the different branches, we also have it, we have it in a separate Git repository. I think that's kind of common, I think, so that you can manage access to translator separate from the source repository and then you just move it back and forth. Again, maybe the web late will help with that. And we have also sort of other projects in the vicinity of the core server projects such as the JDBC driver, which is obviously in Java, which is slightly different sort of tooling and stuff like that. And PG Edmund is a GUI, they have their own workflows. So it's all a little bit all over the place and it's hard to kind of keep that all moving in the sort of, in the same way. And there's also some documentations are being translated, but that's also handled completely separately. We were actually just talking the break, we could use Slipper Translate for that maybe at some point. So all kinds of interesting ideas are already coming up here. All right, so this is sort of my like web late but terrible job here, this is kind of how we handle it, the web interface is under bobble.postgresco.org. And that just gives you sort of the status of what language is and what the message catalogs are and it does sort of the string extraction and the merging in the background as you would do in the make file, but it just kind of runs it for you from a cron job. Again, it's just sort of really old, but it does the job. And then the workflow is, yeah, you go like, you know, you pick your language, pick what you want to work on, you click on it, you download it, you do the translation with the, you know, the get text tools, whatever editor you want to use, different people use different things and then you commit it back. And there's different, all the branches are available here, so you can scroll down and you're just going to fill these up. So, yeah, these are the languages across here. What the colors mean is that green is 100% translated and then one thing we did, which I don't, we just kind of made up, but we decided if a message catalog is not translated to at least 80%, we're not going to ship it, right? You don't want to just ship like one string, you could, but it would be weird for a user that all of a sudden a translated string pops up and nothing else is translated, right? That's maybe a little bit weird, so that's something we sort of decided on until randomly and it seems to actually kind of work pretty well. So, the yellow ones are the ones that we would ship and then the white ones are just the ones that are not complete at all. All right, so workflow is the usual get text workflow for at least C programs, you know, there's other stuff happening now there, so if the developer marks up the messages with this kind of underscore thing that they recommend and our developers are, you know, totally good about that, right, they're all aware of that you need to do that and for the most part it's wrapped into things like this, so you don't actually have to manually mark up everything. If you use like this sort of standard internal API, say print an error, log an error, whatever the case may be, you know, then it's already done for you. That works pretty well, it's, you know, every once in a while something gets missed but it's not a big problem. All the developer group is aware of that. Then I mentioned the website uses those standard tools to give you something you just have to download and then you just translate it and upload it back. And then at release time someone, often me, just then runs a script to copy that over, which could be automated but, you know, it's one of those things we have releases four times a year and you just do it manually four times a year or you could spend X hours automating it, right, so usually it's just done manually. All right, so this is our tool chain at the moment, again GNU, question mark get text, we have a pretty standard sort of configure make make install build system. We don't use any of these make file templates and things like that that ship it get text because we have our own sort of very convoluted build system based on GNU make, we're also in the process of getting rid of that so we're moving to Mason now, which has some support for that built in but it's kind of incomplete so we're sort of stuck sort of half way here, half way there, that's kind of work we're doing right now, I have to figure that out. So people use whatever editor they want to use, you know, PoEdit it seems to be somewhat popular, I use just Emacs, some teams have used, by teams I mean sort of language teams they have used CrowdIn which I suppose is sort of similar to Weblate maybe, but again we were just talking to break maybe we'll look at Weblate and then a horrible bag of shell scripts and purl scripts and make files that sort of hold it all together, which again could be replaced by something better, it's just never really figured out what that could be. So pros and cons of doing any of this, one thing I've obviously we want to translate because we want to translate right, so that's sort of the ultimate requirement, but what I found interesting as a sort of secondary benefits is actually that by putting all your messages of your programs through a translation process you get an automatic review of every message string, right, because every thing you put in the source code is looked again later by at least one more person or several other translators and you catch typos and stuff like that, but also if something doesn't make any sense, right, maybe some developer wrote it and it makes sense to them, but then you know someone else who is not that very developer looks at it again, I don't really understand this, I can't translate it because I don't understand it or it looks weird, could we look at it again, so you get this review process and you've gotten really good in in in postgres about really tuning error messages because it's a complicated piece of software and you get all these weird scenarios with sort of transaction processing and weird right ahead log and replication and all these kinds of things and so you want to be really good and precise to explain that you was okay this failed because of this and you could try this but don't try that and you know so this is really I think people appreciate that independent of translation and everything else I think people appreciate that and this process actually helps that because you sort of refine your program's messages through this process as well, right, and secondly actually it also turned out that sometimes people come in, do some translation, maybe find a bug or want to look something up in a source code, go into the source code and then become a programmer so you can also kind of recruit people that way, it's kind of interesting, so but then there are many challenges, right, so first of all you want to get people in there to use the translation, right, and it's just this you know because postgres is not sort of or similar systems as well, right, it's not end user facing, it's not used by sort of random average people, right, it's used by technically minded people, experts, database administrators and so on, so a lot of those people there's not too much pressure to actually have things translated, people be okay it's not translated, it's fine, right, which is different from you know if LibreOffice or Firefox is not translated and you install in a school, it wouldn't work, it's just you can't do that, right, but here it's like okay if it's not, if it's not, if it doesn't get done it's not a problem in a way, but we just want to do it because we like it, but if it doesn't get done it's like okay then we'll just move on, right, so you got to kind of, it relies on a lot of enthusiasm, individual enthusiasm, right, a lot of the, yeah I found also at least personally as doing some of the translation work myself the terminology is hard sometimes, right, because again I just mentioned something like that, it's not just press this button to download a thing, okay you can translate that in any language probably by now, but what if you get into terms like you know sub transaction rollback or incremental materialized view maintenance, you know some languages might not even have terms for that maybe, you know sometimes when I do the work I pick you know I have some textbooks like academic textbooks in German in my case and I just go through them like anybody in here talk about materialized views, what kind of terminology are they using and then I have like six books and three do this way and three do it that way and then I just pick something at some point, right, and so in some way we have to kind of define, make up the terminology in some cases even, right, so and as I alluded to the work flow is not as cool as what we saw in the previous talk so maybe we can improve that. So here's some sort of source code level challenges, some of those are solvable, some of those are not, people who work in translation know about like plural issues, right, we do handle that, works fine, but then if you, I've never figured out how to handle the first one, like if you have two or more numbers in a sentence like then you would have to have some combinatorial sort of list of translations, what if the first one is singular and the last one is five and what if the first one is two and the last one is 18, you know, I don't think you can really solve that and you just start rephrasing things in weird ways. We have the second one which obviously everybody knows you shouldn't do if you sort of paste terms together that doesn't work, right, let's say you're just going to make something up like you can't, cannot apply a generation expression to a materialized view, let's say something like that, that's a thing that could happen in postgres, more or less, right, like okay you shouldn't, you shouldn't do that, you shouldn't sort of stick that into the middle of the sentence because then the grammar doesn't match in some sentences, so you write those out, but what if you have like five options here and six options there, are you going to make 30 strings in your source code, at some point probably not, right, so at some point then developers, the actual developers do get annoyed if you tell them like no, you can't do that, you have to write actually 35 error messages by hand, so I'm not going to do that. Yeah, you start then tweaking it, can you say something, something semi-colon, something something, and then maybe at that point it's okay, I don't know, but yeah, exactly, so you have to make judgment, use some judgment calls in these cases, and one thing that sometimes happened if developers add a new file to source code then it has to be added somewhere else also to make sure the translation system catches it and that sometimes gets forgotten, it's just one of those things, I don't know if there's a solution for that, you just gotta do it, there's also some weird thing, we have like files that get compiled into multiple components and then you kind of have to add them to all of those components and re-translate everything in each component which could be handled with some of those translation memory things and stuff like that, but it's just kind of weird the way we have it laid out and it kind of makes it annoying, yeah, so this is maybe specific to something like Postgres being A, a client server system, B, a database, and C having its own sort of ideas about what encoding on locale and stuff like that means, right, so in, you know, a database stores data which is often text which has an encoding and because of, you know, it doesn't have nowadays you think everything's UTF-8 but in a database you can also store things in other encodings for historical reasons or in some cases because UTF-8 doesn't actually match what doesn't support what you want to store which sounds maybe bizarre but happens especially in sort of Japanese and things like that, so we do support automatic encoding conversion between client and server so that all works and happens, but then this all sort of, what if you have, you know, your strings, your translated strings are in a file, they also have an encoding, they then get loaded into the server process, the server process prints stuff to its own log but also sends error messages to the client, all of those things could have different ideas of what they want, right, you might want to log stuff in English to your server log but the client wants the error message in French or for some, maybe it's like legacy client that wants it, you know, transcoded to Latin 9 and then at the same time there's a different client connected that also is doing things to a different language, you want to log it to the same server log in the same language, in the same encoding, hopefully as the other guy, all of this works quite poorly the way the get-txt, intl, api's work, you can sort of have some subsets of this working but if you really try hard, it's a total mess and it just basically doesn't work and so that's a real problem really and we'd have to really redesign some of this to support all of these combinations, yeah. So the tools, well the tools are fine, they're actually quite cool and get-txt has some internal sort of optimizations that are quite interesting, has like sort of internal parallelization and stuff like that so work has been done but I still find it quite slow, you know, even on our scale, I'm interested to see what the KDE report is going to be later, how they handle that but it is still quite slow, right, this sort of website thing I showed, if you just do a full rebuild of that, it takes like 20 minutes or something, right, just to re-merge and re-extract and recombine everything so also the format, the PO format is sort of pre-source control I find because it has all these dates and timestamps in it which you don't need because you have it in your source control management but these, hello. Can you be more explicit under 10 minutes, what do you do in these 20 minutes because it sounds very slow? Well it runs a loop, it extracts, runs x get-txt over the source code and then it runs message merge against all these catalogs which are, you know, sort of this many by that many times that many branches and you run that on just a machine, right, so, I mean you could optimize this by maybe a beefier machine and you can probably parallelize this a little bit but it's still, you know, the main message catalog for the actual server has like, you know, 5000 strings and that is still going to run like, I don't really know why but it runs like a couple of minutes, right, so it just, it's not, we're doing this build system work now, right, when we go from make to mace on a ninja because make is too slow even if you don't have to do anything, right, so we're trying to sort of go from, I can rebuild everything in five seconds to two seconds and this thing takes like 10 minutes so that's just kind of annoying, right, yeah and I mentioned sort of the back patching, sort of, you, often times what happens is that there's like a bug fix, right, and because of the bug fix there's a new, a message changes when one new one is added and then, so that then pops up in your website but then it gets backpatched, the same bug fix gets backpatched so the same message has to then also be updated in the back branches so you just kind of have to like download this, upload this, then it gets added to the translation memory, then you can do this, I have a bunch of shell scripts to kind of make this work, it's just all, could be better, right, so a lot of people know this chart here, you know, so, you know, some of the projects that we know, you know, maybe Postgres is somewhere in here, KDE, LibreOffice, they're all pretty good but then there's, you know, maybe things like that down here that everybody builds on but they're sort of maintained by a few people in there, sort of, on the side, right, and this way, I mean, this is sort of a general problem, I gave the same, I gave a talk, it was the online one two years ago about the documentation, Choolchain, Postgres, it's the same problem, right, we have, you know, open source, everything's very successful but then there's like these little tools you need just to make your build run, right, and then there's, they don't have the same necessarily amount of staffing and funding and things like that but you still kind of rely on them and they just barely sort of chug along, so that's a sort of general concern, right, but it applies here, right, so what are we doing, what are we planning to do, I mentioned in the middle, right now we're sort of redoing our build system, that is kind of a good reason to clean up some of that old stuff that we don't need anymore. We're also moving more to using ICU which is, you know, an internationalization library that does lots of good things but then adds another dimension to this issue of, you know, locale encoding and then there's sort of another dimension of what ICU thinks the current locale encoding is, it just gets ever more messy and complicated and then one sort of important issue in databases is the sort order, right, a lot of people care about that, what the sort order of your data is and different collisions have to be supported and that's another kind of sort of localization kind of work we do but all of this is sort of weirdly connected, right, if you configure one part of the system to be in this language then all of a sudden get text also thinks it's the same but maybe you don't even want that, right, you might want your error messages in French but you want to sort something in Swedish, right, why not, right, but because of these APIs the way they're historically built it just doesn't quite work smoothly. But again we want to modernize the workflows, again maybe Weblate, I heard Omega T here also this weekend and there's crowd in but the issue I had, I mean I heard of Weblate some years ago too but again the issue is sort of we can't just adopt like the hottest new thing, right, because again whatever, the way I always think about it is whatever I sort of do today in Postgres, write some piece of code or make some infrastructure change still has to work in 10 years, right, and it doesn't meaning it also has to like build from source, right, because that's the way open source works, right, so I can't just use a tool that was just invented yesterday and I don't know if it's still going to be here in two years, now they mentioned Weblate is 11 years old so that's pretty good, so I think we can maybe look into that, right, so this is something maybe a question anybody knows, is Getex still the thing or is there something totally different that everybody should be using now, it's part of sort of the low level API of how this works, I don't know, I was sort of half hoping that from the ICU ecosystem something would be evolving or it's sort of emerging but I haven't seen anything like that so I don't know if there's anything or is this still the thing to use, I don't know, so maybe somebody has a, yes please. The ICU upcoming solution is message format 2, it's currently in the ICU for J72 that came out in October, it's an attack preview there but it's going to progress from there, it's not yet in ICU for C, it's effectively, message format 2 is a new message format in syntax, the resource level syntax for that is a little bit more still in progress but if you move into more of an ICU world that's likely going to provide a decent future thing for you to migrate to from Getex, it's not that yet but it's becoming that. That is excellent news, thank you, I'll definitely look into that. WebLate is adopting that as well or supporting that, it's more compatible, it seems like it supported a bunch of things, so yeah this is wonderful, useful information we can like. So yeah, this is good, thank you, so this is also the end of my presentation so I just wanted to say what we're doing and what some of the unique challenges are, got some good feedback here, we're going to look into WebLate, we're going to look into emerging ICU things, update some of our infrastructure and we have a few minutes for questions, otherwise thank you very much for listening. So if you're worried about WebLate, it doesn't really matter what you're doing. It doesn't really interact with, it doesn't go too deep in your automation system because the way you communicate with WebLate, with the world of the translators, is FICE, FICE, an agreed repository. So whatever happens in WebLate, matching the translations and the search and the check and stuff, but still you as a developer interact with the FICE, so you still have control on how to build, you don't create a national dependency on your resource. Yeah, it sounds like it, yeah. And get text looks like to be alive again, I think they did a release not so far away. Yeah, it was kind of funny because I had submitted various bugs to savannah.new.org over the years, also feature requests and stuff like that and just like two or three weeks ago all of these bugs were updated and some of them closed and I was like, whoa, does somebody know that I'm going to complain about them? I trust them? I don't know. Is the person here in any case, I don't know who is, no. Well, I guess it's just sort of, I mean, this is a problem, I guess it is a problem in some of these people maintain some of these specialty new tools and some of these older tools that are sort of on maintenance. I mean, we don't need tons of new features but you don't really know, right? It could just be that that person changes job and then nothing happens again for five years, right? So, but, well, got some good new information here, thank you. All right. All right, then we'll move on to the next one.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.68, "text": " Hello, hello, good day, good day.", "tokens": [50364, 2425, 11, 7751, 11, 665, 786, 11, 665, 786, 13, 51048], "temperature": 0.0, "avg_logprob": -0.3587215647977941, "compression_ratio": 1.441340782122905, "no_speech_prob": 0.1644880473613739}, {"id": 1, "seek": 0, "start": 13.68, "end": 18.56, "text": " I think that's sort of the Brussels welcome.", "tokens": [51048, 286, 519, 300, 311, 1333, 295, 264, 38717, 2928, 13, 51292], "temperature": 0.0, "avg_logprob": -0.3587215647977941, "compression_ratio": 1.441340782122905, "no_speech_prob": 0.1644880473613739}, {"id": 2, "seek": 0, "start": 18.56, "end": 24.36, "text": " So I want to talk about what we're doing in the Postgres project with respect to translation.", "tokens": [51292, 407, 286, 528, 281, 751, 466, 437, 321, 434, 884, 294, 264, 10223, 45189, 1716, 365, 3104, 281, 12853, 13, 51582], "temperature": 0.0, "avg_logprob": -0.3587215647977941, "compression_ratio": 1.441340782122905, "no_speech_prob": 0.1644880473613739}, {"id": 3, "seek": 0, "start": 24.36, "end": 29.76, "text": " Seems like the last two talks already solved 50% of my problems, so there was already", "tokens": [51582, 22524, 411, 264, 1036, 732, 6686, 1217, 13041, 2625, 4, 295, 452, 2740, 11, 370, 456, 390, 1217, 51852], "temperature": 0.0, "avg_logprob": -0.3587215647977941, "compression_ratio": 1.441340782122905, "no_speech_prob": 0.1644880473613739}, {"id": 4, "seek": 2976, "start": 29.76, "end": 32.160000000000004, "text": " a good outcome of coming here.", "tokens": [50364, 257, 665, 9700, 295, 1348, 510, 13, 50484], "temperature": 0.0, "avg_logprob": -0.26883500121360604, "compression_ratio": 1.4880382775119618, "no_speech_prob": 0.01125937607139349}, {"id": 5, "seek": 2976, "start": 32.160000000000004, "end": 37.52, "text": " I want to talk a little bit more sort of the lower levels of what Getax specifically does,", "tokens": [50484, 286, 528, 281, 751, 257, 707, 857, 544, 1333, 295, 264, 3126, 4358, 295, 437, 3240, 2797, 4682, 775, 11, 50752], "temperature": 0.0, "avg_logprob": -0.26883500121360604, "compression_ratio": 1.4880382775119618, "no_speech_prob": 0.01125937607139349}, {"id": 6, "seek": 2976, "start": 37.52, "end": 42.400000000000006, "text": " but also goes kind of through what other things we're doing.", "tokens": [50752, 457, 611, 1709, 733, 295, 807, 437, 661, 721, 321, 434, 884, 13, 50996], "temperature": 0.0, "avg_logprob": -0.26883500121360604, "compression_ratio": 1.4880382775119618, "no_speech_prob": 0.01125937607139349}, {"id": 7, "seek": 2976, "start": 42.400000000000006, "end": 49.36, "text": " So I, in the Postgres project, I'm just a C programmer, it's my job really to do the", "tokens": [50996, 407, 286, 11, 294, 264, 10223, 45189, 1716, 11, 286, 478, 445, 257, 383, 32116, 11, 309, 311, 452, 1691, 534, 281, 360, 264, 51344], "temperature": 0.0, "avg_logprob": -0.26883500121360604, "compression_ratio": 1.4880382775119618, "no_speech_prob": 0.01125937607139349}, {"id": 8, "seek": 2976, "start": 49.36, "end": 53.44, "text": " translation sort of as a hobby on the side.", "tokens": [51344, 12853, 1333, 295, 382, 257, 18240, 322, 264, 1252, 13, 51548], "temperature": 0.0, "avg_logprob": -0.26883500121360604, "compression_ratio": 1.4880382775119618, "no_speech_prob": 0.01125937607139349}, {"id": 9, "seek": 5344, "start": 53.44, "end": 61.839999999999996, "text": " I have done initially sort of most of the setup of, you know, sort of the source code", "tokens": [50364, 286, 362, 1096, 9105, 1333, 295, 881, 295, 264, 8657, 295, 11, 291, 458, 11, 1333, 295, 264, 4009, 3089, 50784], "temperature": 0.0, "avg_logprob": -0.24799303914986404, "compression_ratio": 1.6016949152542372, "no_speech_prob": 0.010799705050885677}, {"id": 10, "seek": 5344, "start": 61.839999999999996, "end": 66.75999999999999, "text": " level, what do you call it, internationalization in that case, right, and then I'm also doing", "tokens": [50784, 1496, 11, 437, 360, 291, 818, 309, 11, 5058, 2144, 294, 300, 1389, 11, 558, 11, 293, 550, 286, 478, 611, 884, 51030], "temperature": 0.0, "avg_logprob": -0.24799303914986404, "compression_ratio": 1.6016949152542372, "no_speech_prob": 0.010799705050885677}, {"id": 11, "seek": 5344, "start": 66.75999999999999, "end": 69.56, "text": " some of the translation.", "tokens": [51030, 512, 295, 264, 12853, 13, 51170], "temperature": 0.0, "avg_logprob": -0.24799303914986404, "compression_ratio": 1.6016949152542372, "no_speech_prob": 0.010799705050885677}, {"id": 12, "seek": 5344, "start": 69.56, "end": 77.68, "text": " And yeah, I've been, it turns out also the first false I went to was 20 years ago, so", "tokens": [51170, 400, 1338, 11, 286, 600, 668, 11, 309, 4523, 484, 611, 264, 700, 7908, 286, 1437, 281, 390, 945, 924, 2057, 11, 370, 51576], "temperature": 0.0, "avg_logprob": -0.24799303914986404, "compression_ratio": 1.6016949152542372, "no_speech_prob": 0.010799705050885677}, {"id": 13, "seek": 5344, "start": 77.68, "end": 81.32, "text": " I like coming here because, you know, there's a Postgres dev room happening at the same", "tokens": [51576, 286, 411, 1348, 510, 570, 11, 291, 458, 11, 456, 311, 257, 10223, 45189, 1905, 1808, 2737, 412, 264, 912, 51758], "temperature": 0.0, "avg_logprob": -0.24799303914986404, "compression_ratio": 1.6016949152542372, "no_speech_prob": 0.010799705050885677}, {"id": 14, "seek": 8132, "start": 81.32, "end": 85.88, "text": " time in a different building, but I like to come to all the other places and sort of intersect", "tokens": [50364, 565, 294, 257, 819, 2390, 11, 457, 286, 411, 281, 808, 281, 439, 264, 661, 3190, 293, 1333, 295, 27815, 50592], "temperature": 0.0, "avg_logprob": -0.16242811414930555, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.024767637252807617}, {"id": 15, "seek": 8132, "start": 85.88, "end": 89.03999999999999, "text": " with other communities and learn about other kind of stuff that's happening.", "tokens": [50592, 365, 661, 4456, 293, 1466, 466, 661, 733, 295, 1507, 300, 311, 2737, 13, 50750], "temperature": 0.0, "avg_logprob": -0.16242811414930555, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.024767637252807617}, {"id": 16, "seek": 8132, "start": 89.03999999999999, "end": 93.63999999999999, "text": " So it's kind of a good benefit of FOSDEM.", "tokens": [50750, 407, 309, 311, 733, 295, 257, 665, 5121, 295, 479, 4367, 35, 6683, 13, 50980], "temperature": 0.0, "avg_logprob": -0.16242811414930555, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.024767637252807617}, {"id": 17, "seek": 8132, "start": 93.63999999999999, "end": 94.63999999999999, "text": " So what's Postgres?", "tokens": [50980, 407, 437, 311, 10223, 45189, 30, 51030], "temperature": 0.0, "avg_logprob": -0.16242811414930555, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.024767637252807617}, {"id": 18, "seek": 8132, "start": 94.63999999999999, "end": 100.39999999999999, "text": " It's a, you know, don't need to go into details, but just, it's a little bit, it's a little", "tokens": [51030, 467, 311, 257, 11, 291, 458, 11, 500, 380, 643, 281, 352, 666, 4365, 11, 457, 445, 11, 309, 311, 257, 707, 857, 11, 309, 311, 257, 707, 51318], "temperature": 0.0, "avg_logprob": -0.16242811414930555, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.024767637252807617}, {"id": 19, "seek": 8132, "start": 100.39999999999999, "end": 101.39999999999999, "text": " bit different.", "tokens": [51318, 857, 819, 13, 51368], "temperature": 0.0, "avg_logprob": -0.16242811414930555, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.024767637252807617}, {"id": 20, "seek": 8132, "start": 101.39999999999999, "end": 102.52, "text": " It has different sort of requirements, right?", "tokens": [51368, 467, 575, 819, 1333, 295, 7728, 11, 558, 30, 51424], "temperature": 0.0, "avg_logprob": -0.16242811414930555, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.024767637252807617}, {"id": 21, "seek": 8132, "start": 102.52, "end": 103.52, "text": " It's a database system.", "tokens": [51424, 467, 311, 257, 8149, 1185, 13, 51474], "temperature": 0.0, "avg_logprob": -0.16242811414930555, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.024767637252807617}, {"id": 22, "seek": 8132, "start": 103.52, "end": 110.16, "text": " It's, you know, fairly big and fairly old and, but it's, you know, it's different from", "tokens": [51474, 467, 311, 11, 291, 458, 11, 6457, 955, 293, 6457, 1331, 293, 11, 457, 309, 311, 11, 291, 458, 11, 309, 311, 819, 490, 51806], "temperature": 0.0, "avg_logprob": -0.16242811414930555, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.024767637252807617}, {"id": 23, "seek": 11016, "start": 110.16, "end": 112.6, "text": " like a GUI program, let's say, right?", "tokens": [50364, 411, 257, 17917, 40, 1461, 11, 718, 311, 584, 11, 558, 30, 50486], "temperature": 0.0, "avg_logprob": -0.18301529719911772, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.032086268067359924}, {"id": 24, "seek": 11016, "start": 112.6, "end": 116.39999999999999, "text": " Something we've, you know, leap off is, or we'll hear from KDE later and things like", "tokens": [50486, 6595, 321, 600, 11, 291, 458, 11, 19438, 766, 307, 11, 420, 321, 603, 1568, 490, 591, 22296, 1780, 293, 721, 411, 50676], "temperature": 0.0, "avg_logprob": -0.18301529719911772, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.032086268067359924}, {"id": 25, "seek": 11016, "start": 116.39999999999999, "end": 117.39999999999999, "text": " that.", "tokens": [50676, 300, 13, 50726], "temperature": 0.0, "avg_logprob": -0.18301529719911772, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.032086268067359924}, {"id": 26, "seek": 11016, "start": 117.39999999999999, "end": 125.03999999999999, "text": " I think it just, you know, it lives, it lives much longer and has sort of longer like sort", "tokens": [50726, 286, 519, 309, 445, 11, 291, 458, 11, 309, 2909, 11, 309, 2909, 709, 2854, 293, 575, 1333, 295, 2854, 411, 1333, 51108], "temperature": 0.0, "avg_logprob": -0.18301529719911772, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.032086268067359924}, {"id": 27, "seek": 11016, "start": 125.03999999999999, "end": 126.8, "text": " of stability requirements and things like that.", "tokens": [51108, 295, 11826, 7728, 293, 721, 411, 300, 13, 51196], "temperature": 0.0, "avg_logprob": -0.18301529719911772, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.032086268067359924}, {"id": 28, "seek": 11016, "start": 126.8, "end": 131.92, "text": " And that also kind of makes the maintenance of everything a little bit more complicated.", "tokens": [51196, 400, 300, 611, 733, 295, 1669, 264, 11258, 295, 1203, 257, 707, 857, 544, 6179, 13, 51452], "temperature": 0.0, "avg_logprob": -0.18301529719911772, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.032086268067359924}, {"id": 29, "seek": 11016, "start": 131.92, "end": 139.72, "text": " We also maintain back branches, so we have a yearly release and, but we still maintain", "tokens": [51452, 492, 611, 6909, 646, 14770, 11, 370, 321, 362, 257, 39102, 4374, 293, 11, 457, 321, 920, 6909, 51842], "temperature": 0.0, "avg_logprob": -0.18301529719911772, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.032086268067359924}, {"id": 30, "seek": 13972, "start": 139.72, "end": 141.44, "text": " the old releases for at least five years.", "tokens": [50364, 264, 1331, 16952, 337, 412, 1935, 1732, 924, 13, 50450], "temperature": 0.0, "avg_logprob": -0.15177152882451597, "compression_ratio": 1.816546762589928, "no_speech_prob": 0.05917268991470337}, {"id": 31, "seek": 13972, "start": 141.44, "end": 148.2, "text": " So at any given moment, we have four or five or six releases live and then that gives it", "tokens": [50450, 407, 412, 604, 2212, 1623, 11, 321, 362, 1451, 420, 1732, 420, 2309, 16952, 1621, 293, 550, 300, 2709, 309, 50788], "temperature": 0.0, "avg_logprob": -0.15177152882451597, "compression_ratio": 1.816546762589928, "no_speech_prob": 0.05917268991470337}, {"id": 32, "seek": 13972, "start": 148.2, "end": 150.84, "text": " sort of interesting challenges with like backpatching stuff.", "tokens": [50788, 1333, 295, 1880, 4759, 365, 411, 646, 79, 29569, 1507, 13, 50920], "temperature": 0.0, "avg_logprob": -0.15177152882451597, "compression_ratio": 1.816546762589928, "no_speech_prob": 0.05917268991470337}, {"id": 33, "seek": 13972, "start": 150.84, "end": 154.92, "text": " Just I was quite interested in the last question we had in the previous talk about this translation", "tokens": [50920, 1449, 286, 390, 1596, 3102, 294, 264, 1036, 1168, 321, 632, 294, 264, 3894, 751, 466, 341, 12853, 51124], "temperature": 0.0, "avg_logprob": -0.15177152882451597, "compression_ratio": 1.816546762589928, "no_speech_prob": 0.05917268991470337}, {"id": 34, "seek": 13972, "start": 154.92, "end": 157.4, "text": " memory and sort of that wrong truth.", "tokens": [51124, 4675, 293, 1333, 295, 300, 2085, 3494, 13, 51248], "temperature": 0.0, "avg_logprob": -0.15177152882451597, "compression_ratio": 1.816546762589928, "no_speech_prob": 0.05917268991470337}, {"id": 35, "seek": 13972, "start": 157.4, "end": 163.52, "text": " Can we like automatically apply the memory to the previous branches and stuff like that?", "tokens": [51248, 1664, 321, 411, 6772, 3079, 264, 4675, 281, 264, 3894, 14770, 293, 1507, 411, 300, 30, 51554], "temperature": 0.0, "avg_logprob": -0.15177152882451597, "compression_ratio": 1.816546762589928, "no_speech_prob": 0.05917268991470337}, {"id": 36, "seek": 13972, "start": 163.52, "end": 169.28, "text": " So this sort of stuff is sort of a practical challenge because you have to keep copying", "tokens": [51554, 407, 341, 1333, 295, 1507, 307, 1333, 295, 257, 8496, 3430, 570, 291, 362, 281, 1066, 27976, 51842], "temperature": 0.0, "avg_logprob": -0.15177152882451597, "compression_ratio": 1.816546762589928, "no_speech_prob": 0.05917268991470337}, {"id": 37, "seek": 16928, "start": 169.28, "end": 174.2, "text": " the same thing to all the different branches and so on.", "tokens": [50364, 264, 912, 551, 281, 439, 264, 819, 14770, 293, 370, 322, 13, 50610], "temperature": 0.0, "avg_logprob": -0.26285458536981376, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.009409586898982525}, {"id": 38, "seek": 16928, "start": 174.2, "end": 180.16, "text": " In any case, so how, what are we doing in Postgres?", "tokens": [50610, 682, 604, 1389, 11, 370, 577, 11, 437, 366, 321, 884, 294, 10223, 45189, 30, 50908], "temperature": 0.0, "avg_logprob": -0.26285458536981376, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.009409586898982525}, {"id": 39, "seek": 16928, "start": 180.16, "end": 184.8, "text": " You know, we use GetX as in the title.", "tokens": [50908, 509, 458, 11, 321, 764, 3240, 55, 382, 294, 264, 4876, 13, 51140], "temperature": 0.0, "avg_logprob": -0.26285458536981376, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.009409586898982525}, {"id": 40, "seek": 16928, "start": 184.8, "end": 190.16, "text": " Now put this sort of standard new question mark, it's kind of weird because, again, Postgres", "tokens": [51140, 823, 829, 341, 1333, 295, 3832, 777, 1168, 1491, 11, 309, 311, 733, 295, 3657, 570, 11, 797, 11, 10223, 45189, 51408], "temperature": 0.0, "avg_logprob": -0.26285458536981376, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.009409586898982525}, {"id": 41, "seek": 16928, "start": 190.16, "end": 195.56, "text": " is old and, you know, runs on servers is a little bit different from sort of what runs", "tokens": [51408, 307, 1331, 293, 11, 291, 458, 11, 6676, 322, 15909, 307, 257, 707, 857, 819, 490, 1333, 295, 437, 6676, 51678], "temperature": 0.0, "avg_logprob": -0.26285458536981376, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.009409586898982525}, {"id": 42, "seek": 16928, "start": 195.56, "end": 197.56, "text": " on a laptop or an app, right?", "tokens": [51678, 322, 257, 10732, 420, 364, 724, 11, 558, 30, 51778], "temperature": 0.0, "avg_logprob": -0.26285458536981376, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.009409586898982525}, {"id": 43, "seek": 19756, "start": 197.56, "end": 203.36, "text": " Because for example, we also support operating systems that might still be already be forgotten", "tokens": [50364, 1436, 337, 1365, 11, 321, 611, 1406, 7447, 3652, 300, 1062, 920, 312, 1217, 312, 11832, 50654], "temperature": 0.0, "avg_logprob": -0.2626042683919271, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.03020477667450905}, {"id": 44, "seek": 19756, "start": 203.36, "end": 212.32, "text": " like AIX and Solaris and they have GetX originally came from the sort of Solaris here somehow", "tokens": [50654, 411, 7318, 55, 293, 22385, 271, 293, 436, 362, 3240, 55, 7993, 1361, 490, 264, 1333, 295, 22385, 271, 510, 6063, 51102], "temperature": 0.0, "avg_logprob": -0.2626042683919271, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.03020477667450905}, {"id": 45, "seek": 19756, "start": 212.32, "end": 219.92000000000002, "text": " and there's still a, well, I don't know what it is now, but like a Solaris native Solaris", "tokens": [51102, 293, 456, 311, 920, 257, 11, 731, 11, 286, 500, 380, 458, 437, 309, 307, 586, 11, 457, 411, 257, 22385, 271, 8470, 22385, 271, 51482], "temperature": 0.0, "avg_logprob": -0.2626042683919271, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.03020477667450905}, {"id": 46, "seek": 19756, "start": 219.92000000000002, "end": 221.92000000000002, "text": " GetX exists.", "tokens": [51482, 3240, 55, 8198, 13, 51582], "temperature": 0.0, "avg_logprob": -0.2626042683919271, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.03020477667450905}, {"id": 47, "seek": 19756, "start": 221.92000000000002, "end": 224.8, "text": " It's, you know, that's distinct from new.", "tokens": [51582, 467, 311, 11, 291, 458, 11, 300, 311, 10644, 490, 777, 13, 51726], "temperature": 0.0, "avg_logprob": -0.2626042683919271, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.03020477667450905}, {"id": 48, "seek": 22480, "start": 224.8, "end": 229.4, "text": " But it's sort of old, has bugs and doesn't parse stuff correctly sometimes.", "tokens": [50364, 583, 309, 311, 1333, 295, 1331, 11, 575, 15120, 293, 1177, 380, 48377, 1507, 8944, 2171, 13, 50594], "temperature": 0.0, "avg_logprob": -0.19232487459795192, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.042064566165208817}, {"id": 49, "seek": 22480, "start": 229.4, "end": 236.04000000000002, "text": " So when you just sort of use the new version, then sometimes the files you distribute don't", "tokens": [50594, 407, 562, 291, 445, 1333, 295, 764, 264, 777, 3037, 11, 550, 2171, 264, 7098, 291, 20594, 500, 380, 50926], "temperature": 0.0, "avg_logprob": -0.19232487459795192, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.042064566165208817}, {"id": 50, "seek": 22480, "start": 236.04000000000002, "end": 238.44, "text": " work on old Solaris for some reason, right?", "tokens": [50926, 589, 322, 1331, 22385, 271, 337, 512, 1778, 11, 558, 30, 51046], "temperature": 0.0, "avg_logprob": -0.19232487459795192, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.042064566165208817}, {"id": 51, "seek": 22480, "start": 238.44, "end": 240.92000000000002, "text": " And then this is sort of just a weird situation.", "tokens": [51046, 400, 550, 341, 307, 1333, 295, 445, 257, 3657, 2590, 13, 51170], "temperature": 0.0, "avg_logprob": -0.19232487459795192, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.042064566165208817}, {"id": 52, "seek": 22480, "start": 240.92000000000002, "end": 247.76000000000002, "text": " You have to like then fix these things and then, or hope that Solaris dies at some point,", "tokens": [51170, 509, 362, 281, 411, 550, 3191, 613, 721, 293, 550, 11, 420, 1454, 300, 22385, 271, 2714, 412, 512, 935, 11, 51512], "temperature": 0.0, "avg_logprob": -0.19232487459795192, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.042064566165208817}, {"id": 53, "seek": 22480, "start": 247.76000000000002, "end": 248.76000000000002, "text": " right?", "tokens": [51512, 558, 30, 51562], "temperature": 0.0, "avg_logprob": -0.19232487459795192, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.042064566165208817}, {"id": 54, "seek": 22480, "start": 248.76000000000002, "end": 249.76000000000002, "text": " Stuff like that.", "tokens": [51562, 31347, 411, 300, 13, 51612], "temperature": 0.0, "avg_logprob": -0.19232487459795192, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.042064566165208817}, {"id": 55, "seek": 22480, "start": 249.76000000000002, "end": 250.8, "text": " So it's like that.", "tokens": [51612, 407, 309, 311, 411, 300, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19232487459795192, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.042064566165208817}, {"id": 56, "seek": 25080, "start": 250.8, "end": 257.40000000000003, "text": " So we have, I mean, you know, we hear from KDE next, I already looked at their abstract.", "tokens": [50364, 407, 321, 362, 11, 286, 914, 11, 291, 458, 11, 321, 1568, 490, 591, 22296, 958, 11, 286, 1217, 2956, 412, 641, 12649, 13, 50694], "temperature": 0.0, "avg_logprob": -0.16301467067511508, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.004398756194859743}, {"id": 57, "seek": 25080, "start": 257.40000000000003, "end": 261.56, "text": " This is obviously not a lot in terms of how many languages and message catalogs and strings", "tokens": [50694, 639, 307, 2745, 406, 257, 688, 294, 2115, 295, 577, 867, 8650, 293, 3636, 19746, 82, 293, 13985, 50902], "temperature": 0.0, "avg_logprob": -0.16301467067511508, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.004398756194859743}, {"id": 58, "seek": 25080, "start": 261.56, "end": 267.76, "text": " we have, but it's more than something you can just deal with in an afternoon, right?", "tokens": [50902, 321, 362, 11, 457, 309, 311, 544, 813, 746, 291, 393, 445, 2028, 365, 294, 364, 6499, 11, 558, 30, 51212], "temperature": 0.0, "avg_logprob": -0.16301467067511508, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.004398756194859743}, {"id": 59, "seek": 25080, "start": 267.76, "end": 269.64, "text": " It's just a lot of stuff to move around.", "tokens": [51212, 467, 311, 445, 257, 688, 295, 1507, 281, 1286, 926, 13, 51306], "temperature": 0.0, "avg_logprob": -0.16301467067511508, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.004398756194859743}, {"id": 60, "seek": 25080, "start": 269.64, "end": 273.76, "text": " I mentioned with the different branches, we also have it, we have it in a separate Git", "tokens": [51306, 286, 2835, 365, 264, 819, 14770, 11, 321, 611, 362, 309, 11, 321, 362, 309, 294, 257, 4994, 16939, 51512], "temperature": 0.0, "avg_logprob": -0.16301467067511508, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.004398756194859743}, {"id": 61, "seek": 25080, "start": 273.76, "end": 274.76, "text": " repository.", "tokens": [51512, 25841, 13, 51562], "temperature": 0.0, "avg_logprob": -0.16301467067511508, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.004398756194859743}, {"id": 62, "seek": 25080, "start": 274.76, "end": 278.84000000000003, "text": " I think that's kind of common, I think, so that you can manage access to translator", "tokens": [51562, 286, 519, 300, 311, 733, 295, 2689, 11, 286, 519, 11, 370, 300, 291, 393, 3067, 2105, 281, 35223, 51766], "temperature": 0.0, "avg_logprob": -0.16301467067511508, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.004398756194859743}, {"id": 63, "seek": 27884, "start": 278.84, "end": 282.88, "text": " separate from the source repository and then you just move it back and forth.", "tokens": [50364, 4994, 490, 264, 4009, 25841, 293, 550, 291, 445, 1286, 309, 646, 293, 5220, 13, 50566], "temperature": 0.0, "avg_logprob": -0.23068024317423502, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0212798323482275}, {"id": 64, "seek": 27884, "start": 282.88, "end": 287.03999999999996, "text": " Again, maybe the web late will help with that.", "tokens": [50566, 3764, 11, 1310, 264, 3670, 3469, 486, 854, 365, 300, 13, 50774], "temperature": 0.0, "avg_logprob": -0.23068024317423502, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0212798323482275}, {"id": 65, "seek": 27884, "start": 287.03999999999996, "end": 292.76, "text": " And we have also sort of other projects in the vicinity of the core server projects such", "tokens": [50774, 400, 321, 362, 611, 1333, 295, 661, 4455, 294, 264, 42387, 295, 264, 4965, 7154, 4455, 1270, 51060], "temperature": 0.0, "avg_logprob": -0.23068024317423502, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0212798323482275}, {"id": 66, "seek": 27884, "start": 292.76, "end": 298.0, "text": " as the JDBC driver, which is obviously in Java, which is slightly different sort of tooling", "tokens": [51060, 382, 264, 37082, 7869, 6787, 11, 597, 307, 2745, 294, 10745, 11, 597, 307, 4748, 819, 1333, 295, 46593, 51322], "temperature": 0.0, "avg_logprob": -0.23068024317423502, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0212798323482275}, {"id": 67, "seek": 27884, "start": 298.0, "end": 299.0, "text": " and stuff like that.", "tokens": [51322, 293, 1507, 411, 300, 13, 51372], "temperature": 0.0, "avg_logprob": -0.23068024317423502, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0212798323482275}, {"id": 68, "seek": 27884, "start": 299.0, "end": 302.76, "text": " And PG Edmund is a GUI, they have their own workflows.", "tokens": [51372, 400, 40975, 3977, 35578, 307, 257, 17917, 40, 11, 436, 362, 641, 1065, 43461, 13, 51560], "temperature": 0.0, "avg_logprob": -0.23068024317423502, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0212798323482275}, {"id": 69, "seek": 27884, "start": 302.76, "end": 307.84, "text": " So it's all a little bit all over the place and it's hard to kind of keep that all moving", "tokens": [51560, 407, 309, 311, 439, 257, 707, 857, 439, 670, 264, 1081, 293, 309, 311, 1152, 281, 733, 295, 1066, 300, 439, 2684, 51814], "temperature": 0.0, "avg_logprob": -0.23068024317423502, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0212798323482275}, {"id": 70, "seek": 30784, "start": 307.84, "end": 312.4, "text": " in the sort of, in the same way.", "tokens": [50364, 294, 264, 1333, 295, 11, 294, 264, 912, 636, 13, 50592], "temperature": 0.0, "avg_logprob": -0.29146823316517445, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.027992943301796913}, {"id": 71, "seek": 30784, "start": 312.4, "end": 316.79999999999995, "text": " And there's also some documentations are being translated, but that's also handled completely", "tokens": [50592, 400, 456, 311, 611, 512, 4166, 763, 366, 885, 16805, 11, 457, 300, 311, 611, 18033, 2584, 50812], "temperature": 0.0, "avg_logprob": -0.29146823316517445, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.027992943301796913}, {"id": 72, "seek": 30784, "start": 316.79999999999995, "end": 317.79999999999995, "text": " separately.", "tokens": [50812, 14759, 13, 50862], "temperature": 0.0, "avg_logprob": -0.29146823316517445, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.027992943301796913}, {"id": 73, "seek": 30784, "start": 317.79999999999995, "end": 320.47999999999996, "text": " We were actually just talking the break, we could use Slipper Translate for that maybe", "tokens": [50862, 492, 645, 767, 445, 1417, 264, 1821, 11, 321, 727, 764, 318, 2081, 3717, 6531, 17593, 337, 300, 1310, 50996], "temperature": 0.0, "avg_logprob": -0.29146823316517445, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.027992943301796913}, {"id": 74, "seek": 30784, "start": 320.47999999999996, "end": 321.47999999999996, "text": " at some point.", "tokens": [50996, 412, 512, 935, 13, 51046], "temperature": 0.0, "avg_logprob": -0.29146823316517445, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.027992943301796913}, {"id": 75, "seek": 30784, "start": 321.47999999999996, "end": 325.2, "text": " So all kinds of interesting ideas are already coming up here.", "tokens": [51046, 407, 439, 3685, 295, 1880, 3487, 366, 1217, 1348, 493, 510, 13, 51232], "temperature": 0.0, "avg_logprob": -0.29146823316517445, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.027992943301796913}, {"id": 76, "seek": 30784, "start": 325.2, "end": 335.32, "text": " All right, so this is sort of my like web late but terrible job here, this is kind of", "tokens": [51232, 1057, 558, 11, 370, 341, 307, 1333, 295, 452, 411, 3670, 3469, 457, 6237, 1691, 510, 11, 341, 307, 733, 295, 51738], "temperature": 0.0, "avg_logprob": -0.29146823316517445, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.027992943301796913}, {"id": 77, "seek": 33532, "start": 335.32, "end": 342.59999999999997, "text": " how we handle it, the web interface is under bobble.postgresco.org.", "tokens": [50364, 577, 321, 4813, 309, 11, 264, 3670, 9226, 307, 833, 748, 10387, 13, 23744, 45189, 1291, 13, 4646, 13, 50728], "temperature": 0.0, "avg_logprob": -0.21763069516136532, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.39541420340538025}, {"id": 78, "seek": 33532, "start": 342.59999999999997, "end": 347.36, "text": " And that just gives you sort of the status of what language is and what the message catalogs", "tokens": [50728, 400, 300, 445, 2709, 291, 1333, 295, 264, 6558, 295, 437, 2856, 307, 293, 437, 264, 3636, 19746, 82, 50966], "temperature": 0.0, "avg_logprob": -0.21763069516136532, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.39541420340538025}, {"id": 79, "seek": 33532, "start": 347.36, "end": 356.12, "text": " are and it does sort of the string extraction and the merging in the background as you would", "tokens": [50966, 366, 293, 309, 775, 1333, 295, 264, 6798, 30197, 293, 264, 44559, 294, 264, 3678, 382, 291, 576, 51404], "temperature": 0.0, "avg_logprob": -0.21763069516136532, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.39541420340538025}, {"id": 80, "seek": 33532, "start": 356.12, "end": 359.84, "text": " do in the make file, but it just kind of runs it for you from a cron job.", "tokens": [51404, 360, 294, 264, 652, 3991, 11, 457, 309, 445, 733, 295, 6676, 309, 337, 291, 490, 257, 941, 266, 1691, 13, 51590], "temperature": 0.0, "avg_logprob": -0.21763069516136532, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.39541420340538025}, {"id": 81, "seek": 33532, "start": 359.84, "end": 362.28, "text": " Again, it's just sort of really old, but it does the job.", "tokens": [51590, 3764, 11, 309, 311, 445, 1333, 295, 534, 1331, 11, 457, 309, 775, 264, 1691, 13, 51712], "temperature": 0.0, "avg_logprob": -0.21763069516136532, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.39541420340538025}, {"id": 82, "seek": 36228, "start": 362.28, "end": 368.08, "text": " And then the workflow is, yeah, you go like, you know, you pick your language, pick what", "tokens": [50364, 400, 550, 264, 20993, 307, 11, 1338, 11, 291, 352, 411, 11, 291, 458, 11, 291, 1888, 428, 2856, 11, 1888, 437, 50654], "temperature": 0.0, "avg_logprob": -0.22195581027439662, "compression_ratio": 1.825531914893617, "no_speech_prob": 0.0453329011797905}, {"id": 83, "seek": 36228, "start": 368.08, "end": 373.15999999999997, "text": " you want to work on, you click on it, you download it, you do the translation with the, you know,", "tokens": [50654, 291, 528, 281, 589, 322, 11, 291, 2052, 322, 309, 11, 291, 5484, 309, 11, 291, 360, 264, 12853, 365, 264, 11, 291, 458, 11, 50908], "temperature": 0.0, "avg_logprob": -0.22195581027439662, "compression_ratio": 1.825531914893617, "no_speech_prob": 0.0453329011797905}, {"id": 84, "seek": 36228, "start": 373.15999999999997, "end": 378.52, "text": " the get text tools, whatever editor you want to use, different people use different things", "tokens": [50908, 264, 483, 2487, 3873, 11, 2035, 9839, 291, 528, 281, 764, 11, 819, 561, 764, 819, 721, 51176], "temperature": 0.0, "avg_logprob": -0.22195581027439662, "compression_ratio": 1.825531914893617, "no_speech_prob": 0.0453329011797905}, {"id": 85, "seek": 36228, "start": 378.52, "end": 380.47999999999996, "text": " and then you commit it back.", "tokens": [51176, 293, 550, 291, 5599, 309, 646, 13, 51274], "temperature": 0.0, "avg_logprob": -0.22195581027439662, "compression_ratio": 1.825531914893617, "no_speech_prob": 0.0453329011797905}, {"id": 86, "seek": 36228, "start": 380.47999999999996, "end": 386.2, "text": " And there's different, all the branches are available here, so you can scroll down and", "tokens": [51274, 400, 456, 311, 819, 11, 439, 264, 14770, 366, 2435, 510, 11, 370, 291, 393, 11369, 760, 293, 51560], "temperature": 0.0, "avg_logprob": -0.22195581027439662, "compression_ratio": 1.825531914893617, "no_speech_prob": 0.0453329011797905}, {"id": 87, "seek": 36228, "start": 386.2, "end": 388.88, "text": " you're just going to fill these up.", "tokens": [51560, 291, 434, 445, 516, 281, 2836, 613, 493, 13, 51694], "temperature": 0.0, "avg_logprob": -0.22195581027439662, "compression_ratio": 1.825531914893617, "no_speech_prob": 0.0453329011797905}, {"id": 88, "seek": 38888, "start": 389.04, "end": 392.76, "text": " So, yeah, these are the languages across here.", "tokens": [50372, 407, 11, 1338, 11, 613, 366, 264, 8650, 2108, 510, 13, 50558], "temperature": 0.0, "avg_logprob": -0.20257349014282228, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0021825917065143585}, {"id": 89, "seek": 38888, "start": 392.76, "end": 400.0, "text": " What the colors mean is that green is 100% translated and then one thing we did, which", "tokens": [50558, 708, 264, 4577, 914, 307, 300, 3092, 307, 2319, 4, 16805, 293, 550, 472, 551, 321, 630, 11, 597, 50920], "temperature": 0.0, "avg_logprob": -0.20257349014282228, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0021825917065143585}, {"id": 90, "seek": 38888, "start": 400.0, "end": 407.15999999999997, "text": " I don't, we just kind of made up, but we decided if a message catalog is not translated to", "tokens": [50920, 286, 500, 380, 11, 321, 445, 733, 295, 1027, 493, 11, 457, 321, 3047, 498, 257, 3636, 19746, 307, 406, 16805, 281, 51278], "temperature": 0.0, "avg_logprob": -0.20257349014282228, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0021825917065143585}, {"id": 91, "seek": 38888, "start": 407.15999999999997, "end": 410.28, "text": " at least 80%, we're not going to ship it, right?", "tokens": [51278, 412, 1935, 4688, 8923, 321, 434, 406, 516, 281, 5374, 309, 11, 558, 30, 51434], "temperature": 0.0, "avg_logprob": -0.20257349014282228, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0021825917065143585}, {"id": 92, "seek": 38888, "start": 410.28, "end": 414.6, "text": " You don't want to just ship like one string, you could, but it would be weird for a user", "tokens": [51434, 509, 500, 380, 528, 281, 445, 5374, 411, 472, 6798, 11, 291, 727, 11, 457, 309, 576, 312, 3657, 337, 257, 4195, 51650], "temperature": 0.0, "avg_logprob": -0.20257349014282228, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0021825917065143585}, {"id": 93, "seek": 38888, "start": 414.6, "end": 418.84, "text": " that all of a sudden a translated string pops up and nothing else is translated, right?", "tokens": [51650, 300, 439, 295, 257, 3990, 257, 16805, 6798, 16795, 493, 293, 1825, 1646, 307, 16805, 11, 558, 30, 51862], "temperature": 0.0, "avg_logprob": -0.20257349014282228, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0021825917065143585}, {"id": 94, "seek": 41884, "start": 418.84, "end": 423.44, "text": " That's maybe a little bit weird, so that's something we sort of decided on until randomly", "tokens": [50364, 663, 311, 1310, 257, 707, 857, 3657, 11, 370, 300, 311, 746, 321, 1333, 295, 3047, 322, 1826, 16979, 50594], "temperature": 0.0, "avg_logprob": -0.25110234251809777, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0005192400421947241}, {"id": 95, "seek": 41884, "start": 423.44, "end": 426.03999999999996, "text": " and it seems to actually kind of work pretty well.", "tokens": [50594, 293, 309, 2544, 281, 767, 733, 295, 589, 1238, 731, 13, 50724], "temperature": 0.0, "avg_logprob": -0.25110234251809777, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0005192400421947241}, {"id": 96, "seek": 41884, "start": 426.03999999999996, "end": 431.32, "text": " So, the yellow ones are the ones that we would ship and then the white ones are just the ones", "tokens": [50724, 407, 11, 264, 5566, 2306, 366, 264, 2306, 300, 321, 576, 5374, 293, 550, 264, 2418, 2306, 366, 445, 264, 2306, 50988], "temperature": 0.0, "avg_logprob": -0.25110234251809777, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0005192400421947241}, {"id": 97, "seek": 41884, "start": 431.32, "end": 434.12, "text": " that are not complete at all.", "tokens": [50988, 300, 366, 406, 3566, 412, 439, 13, 51128], "temperature": 0.0, "avg_logprob": -0.25110234251809777, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0005192400421947241}, {"id": 98, "seek": 41884, "start": 436.52, "end": 443.15999999999997, "text": " All right, so workflow is the usual get text workflow for at least C programs, you know,", "tokens": [51248, 1057, 558, 11, 370, 20993, 307, 264, 7713, 483, 2487, 20993, 337, 412, 1935, 383, 4268, 11, 291, 458, 11, 51580], "temperature": 0.0, "avg_logprob": -0.25110234251809777, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0005192400421947241}, {"id": 99, "seek": 41884, "start": 443.15999999999997, "end": 447.03999999999996, "text": " there's other stuff happening now there, so if the developer marks up the messages with", "tokens": [51580, 456, 311, 661, 1507, 2737, 586, 456, 11, 370, 498, 264, 10754, 10640, 493, 264, 7897, 365, 51774], "temperature": 0.0, "avg_logprob": -0.25110234251809777, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0005192400421947241}, {"id": 100, "seek": 44704, "start": 447.08000000000004, "end": 453.16, "text": " this kind of underscore thing that they recommend and our developers are, you know, totally good", "tokens": [50366, 341, 733, 295, 37556, 551, 300, 436, 2748, 293, 527, 8849, 366, 11, 291, 458, 11, 3879, 665, 50670], "temperature": 0.0, "avg_logprob": -0.18153833459924767, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0014102421700954437}, {"id": 101, "seek": 44704, "start": 453.16, "end": 458.28000000000003, "text": " about that, right, they're all aware of that you need to do that and for the most part", "tokens": [50670, 466, 300, 11, 558, 11, 436, 434, 439, 3650, 295, 300, 291, 643, 281, 360, 300, 293, 337, 264, 881, 644, 50926], "temperature": 0.0, "avg_logprob": -0.18153833459924767, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0014102421700954437}, {"id": 102, "seek": 44704, "start": 458.28000000000003, "end": 464.28000000000003, "text": " it's wrapped into things like this, so you don't actually have to manually mark up everything.", "tokens": [50926, 309, 311, 14226, 666, 721, 411, 341, 11, 370, 291, 500, 380, 767, 362, 281, 16945, 1491, 493, 1203, 13, 51226], "temperature": 0.0, "avg_logprob": -0.18153833459924767, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0014102421700954437}, {"id": 103, "seek": 44704, "start": 464.28000000000003, "end": 468.64000000000004, "text": " If you use like this sort of standard internal API, say print an error, log an error, whatever", "tokens": [51226, 759, 291, 764, 411, 341, 1333, 295, 3832, 6920, 9362, 11, 584, 4482, 364, 6713, 11, 3565, 364, 6713, 11, 2035, 51444], "temperature": 0.0, "avg_logprob": -0.18153833459924767, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0014102421700954437}, {"id": 104, "seek": 44704, "start": 468.64000000000004, "end": 471.40000000000003, "text": " the case may be, you know, then it's already done for you.", "tokens": [51444, 264, 1389, 815, 312, 11, 291, 458, 11, 550, 309, 311, 1217, 1096, 337, 291, 13, 51582], "temperature": 0.0, "avg_logprob": -0.18153833459924767, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0014102421700954437}, {"id": 105, "seek": 47140, "start": 471.84, "end": 476.64, "text": " That works pretty well, it's, you know, every once in a while something gets missed but", "tokens": [50386, 663, 1985, 1238, 731, 11, 309, 311, 11, 291, 458, 11, 633, 1564, 294, 257, 1339, 746, 2170, 6721, 457, 50626], "temperature": 0.0, "avg_logprob": -0.22619135968096846, "compression_ratio": 1.5427135678391959, "no_speech_prob": 0.0011513162171468139}, {"id": 106, "seek": 47140, "start": 476.64, "end": 477.64, "text": " it's not a big problem.", "tokens": [50626, 309, 311, 406, 257, 955, 1154, 13, 50676], "temperature": 0.0, "avg_logprob": -0.22619135968096846, "compression_ratio": 1.5427135678391959, "no_speech_prob": 0.0011513162171468139}, {"id": 107, "seek": 47140, "start": 477.64, "end": 480.96, "text": " All the developer group is aware of that.", "tokens": [50676, 1057, 264, 10754, 1594, 307, 3650, 295, 300, 13, 50842], "temperature": 0.0, "avg_logprob": -0.22619135968096846, "compression_ratio": 1.5427135678391959, "no_speech_prob": 0.0011513162171468139}, {"id": 108, "seek": 47140, "start": 480.96, "end": 491.15999999999997, "text": " Then I mentioned the website uses those standard tools to give you something you just have", "tokens": [50842, 1396, 286, 2835, 264, 3144, 4960, 729, 3832, 3873, 281, 976, 291, 746, 291, 445, 362, 51352], "temperature": 0.0, "avg_logprob": -0.22619135968096846, "compression_ratio": 1.5427135678391959, "no_speech_prob": 0.0011513162171468139}, {"id": 109, "seek": 47140, "start": 491.15999999999997, "end": 497.35999999999996, "text": " to download and then you just translate it and upload it back.", "tokens": [51352, 281, 5484, 293, 550, 291, 445, 13799, 309, 293, 6580, 309, 646, 13, 51662], "temperature": 0.0, "avg_logprob": -0.22619135968096846, "compression_ratio": 1.5427135678391959, "no_speech_prob": 0.0011513162171468139}, {"id": 110, "seek": 49736, "start": 497.36, "end": 504.16, "text": " And then at release time someone, often me, just then runs a script to copy that over,", "tokens": [50364, 400, 550, 412, 4374, 565, 1580, 11, 2049, 385, 11, 445, 550, 6676, 257, 5755, 281, 5055, 300, 670, 11, 50704], "temperature": 0.0, "avg_logprob": -0.21636306948778106, "compression_ratio": 1.6772486772486772, "no_speech_prob": 0.04399954900145531}, {"id": 111, "seek": 49736, "start": 504.16, "end": 510.08000000000004, "text": " which could be automated but, you know, it's one of those things we have releases four", "tokens": [50704, 597, 727, 312, 18473, 457, 11, 291, 458, 11, 309, 311, 472, 295, 729, 721, 321, 362, 16952, 1451, 51000], "temperature": 0.0, "avg_logprob": -0.21636306948778106, "compression_ratio": 1.6772486772486772, "no_speech_prob": 0.04399954900145531}, {"id": 112, "seek": 49736, "start": 510.08000000000004, "end": 515.2, "text": " times a year and you just do it manually four times a year or you could spend X hours", "tokens": [51000, 1413, 257, 1064, 293, 291, 445, 360, 309, 16945, 1451, 1413, 257, 1064, 420, 291, 727, 3496, 1783, 2496, 51256], "temperature": 0.0, "avg_logprob": -0.21636306948778106, "compression_ratio": 1.6772486772486772, "no_speech_prob": 0.04399954900145531}, {"id": 113, "seek": 49736, "start": 515.2, "end": 519.6800000000001, "text": " automating it, right, so usually it's just done manually.", "tokens": [51256, 3553, 990, 309, 11, 558, 11, 370, 2673, 309, 311, 445, 1096, 16945, 13, 51480], "temperature": 0.0, "avg_logprob": -0.21636306948778106, "compression_ratio": 1.6772486772486772, "no_speech_prob": 0.04399954900145531}, {"id": 114, "seek": 51968, "start": 520.68, "end": 528.7199999999999, "text": " All right, so this is our tool chain at the moment, again GNU, question mark get text,", "tokens": [50414, 1057, 558, 11, 370, 341, 307, 527, 2290, 5021, 412, 264, 1623, 11, 797, 46411, 52, 11, 1168, 1491, 483, 2487, 11, 50816], "temperature": 0.0, "avg_logprob": -0.23410547190699085, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.003649600548669696}, {"id": 115, "seek": 51968, "start": 528.7199999999999, "end": 535.3199999999999, "text": " we have a pretty standard sort of configure make make install build system.", "tokens": [50816, 321, 362, 257, 1238, 3832, 1333, 295, 22162, 652, 652, 3625, 1322, 1185, 13, 51146], "temperature": 0.0, "avg_logprob": -0.23410547190699085, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.003649600548669696}, {"id": 116, "seek": 51968, "start": 535.3199999999999, "end": 539.0, "text": " We don't use any of these make file templates and things like that that ship it get text", "tokens": [51146, 492, 500, 380, 764, 604, 295, 613, 652, 3991, 21165, 293, 721, 411, 300, 300, 5374, 309, 483, 2487, 51330], "temperature": 0.0, "avg_logprob": -0.23410547190699085, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.003649600548669696}, {"id": 117, "seek": 51968, "start": 539.0, "end": 546.24, "text": " because we have our own sort of very convoluted build system based on GNU make, we're also", "tokens": [51330, 570, 321, 362, 527, 1065, 1333, 295, 588, 3754, 2308, 292, 1322, 1185, 2361, 322, 46411, 52, 652, 11, 321, 434, 611, 51692], "temperature": 0.0, "avg_logprob": -0.23410547190699085, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.003649600548669696}, {"id": 118, "seek": 54624, "start": 546.24, "end": 554.12, "text": " in the process of getting rid of that so we're moving to Mason now, which has some support", "tokens": [50364, 294, 264, 1399, 295, 1242, 3973, 295, 300, 370, 321, 434, 2684, 281, 25730, 586, 11, 597, 575, 512, 1406, 50758], "temperature": 0.0, "avg_logprob": -0.2228199607447574, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.06752477586269379}, {"id": 119, "seek": 54624, "start": 554.12, "end": 560.64, "text": " for that built in but it's kind of incomplete so we're sort of stuck sort of half way here,", "tokens": [50758, 337, 300, 3094, 294, 457, 309, 311, 733, 295, 31709, 370, 321, 434, 1333, 295, 5541, 1333, 295, 1922, 636, 510, 11, 51084], "temperature": 0.0, "avg_logprob": -0.2228199607447574, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.06752477586269379}, {"id": 120, "seek": 54624, "start": 560.64, "end": 568.12, "text": " half way there, that's kind of work we're doing right now, I have to figure that out.", "tokens": [51084, 1922, 636, 456, 11, 300, 311, 733, 295, 589, 321, 434, 884, 558, 586, 11, 286, 362, 281, 2573, 300, 484, 13, 51458], "temperature": 0.0, "avg_logprob": -0.2228199607447574, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.06752477586269379}, {"id": 121, "seek": 54624, "start": 568.12, "end": 573.84, "text": " So people use whatever editor they want to use, you know, PoEdit it seems to be somewhat", "tokens": [51458, 407, 561, 764, 2035, 9839, 436, 528, 281, 764, 11, 291, 458, 11, 6165, 36, 17975, 309, 2544, 281, 312, 8344, 51744], "temperature": 0.0, "avg_logprob": -0.2228199607447574, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.06752477586269379}, {"id": 122, "seek": 57384, "start": 573.84, "end": 580.1600000000001, "text": " popular, I use just Emacs, some teams have used, by teams I mean sort of language teams", "tokens": [50364, 3743, 11, 286, 764, 445, 3968, 44937, 11, 512, 5491, 362, 1143, 11, 538, 5491, 286, 914, 1333, 295, 2856, 5491, 50680], "temperature": 0.0, "avg_logprob": -0.22535427137352954, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.02194371446967125}, {"id": 123, "seek": 57384, "start": 580.1600000000001, "end": 589.12, "text": " they have used CrowdIn which I suppose is sort of similar to Weblate maybe, but again", "tokens": [50680, 436, 362, 1143, 40110, 4575, 597, 286, 7297, 307, 1333, 295, 2531, 281, 9573, 17593, 1310, 11, 457, 797, 51128], "temperature": 0.0, "avg_logprob": -0.22535427137352954, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.02194371446967125}, {"id": 124, "seek": 57384, "start": 589.12, "end": 595.1800000000001, "text": " we were just talking to break maybe we'll look at Weblate and then a horrible bag of", "tokens": [51128, 321, 645, 445, 1417, 281, 1821, 1310, 321, 603, 574, 412, 9573, 17593, 293, 550, 257, 9263, 3411, 295, 51431], "temperature": 0.0, "avg_logprob": -0.22535427137352954, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.02194371446967125}, {"id": 125, "seek": 57384, "start": 595.1800000000001, "end": 601.6800000000001, "text": " shell scripts and purl scripts and make files that sort of hold it all together, which again", "tokens": [51431, 8720, 23294, 293, 48943, 23294, 293, 652, 7098, 300, 1333, 295, 1797, 309, 439, 1214, 11, 597, 797, 51756], "temperature": 0.0, "avg_logprob": -0.22535427137352954, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.02194371446967125}, {"id": 126, "seek": 60168, "start": 601.7199999999999, "end": 606.0799999999999, "text": " could be replaced by something better, it's just never really figured out what that could", "tokens": [50366, 727, 312, 10772, 538, 746, 1101, 11, 309, 311, 445, 1128, 534, 8932, 484, 437, 300, 727, 50584], "temperature": 0.0, "avg_logprob": -0.18634079751514254, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0036494280211627483}, {"id": 127, "seek": 60168, "start": 606.0799999999999, "end": 609.16, "text": " be.", "tokens": [50584, 312, 13, 50738], "temperature": 0.0, "avg_logprob": -0.18634079751514254, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0036494280211627483}, {"id": 128, "seek": 60168, "start": 609.16, "end": 615.56, "text": " So pros and cons of doing any of this, one thing I've obviously we want to translate", "tokens": [50738, 407, 6267, 293, 1014, 295, 884, 604, 295, 341, 11, 472, 551, 286, 600, 2745, 321, 528, 281, 13799, 51058], "temperature": 0.0, "avg_logprob": -0.18634079751514254, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0036494280211627483}, {"id": 129, "seek": 60168, "start": 615.56, "end": 620.92, "text": " because we want to translate right, so that's sort of the ultimate requirement, but what", "tokens": [51058, 570, 321, 528, 281, 13799, 558, 11, 370, 300, 311, 1333, 295, 264, 9705, 11695, 11, 457, 437, 51326], "temperature": 0.0, "avg_logprob": -0.18634079751514254, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0036494280211627483}, {"id": 130, "seek": 60168, "start": 620.92, "end": 629.8399999999999, "text": " I found interesting as a sort of secondary benefits is actually that by putting all your", "tokens": [51326, 286, 1352, 1880, 382, 257, 1333, 295, 11396, 5311, 307, 767, 300, 538, 3372, 439, 428, 51772], "temperature": 0.0, "avg_logprob": -0.18634079751514254, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0036494280211627483}, {"id": 131, "seek": 62984, "start": 629.84, "end": 635.52, "text": " messages of your programs through a translation process you get an automatic review of every", "tokens": [50364, 7897, 295, 428, 4268, 807, 257, 12853, 1399, 291, 483, 364, 12509, 3131, 295, 633, 50648], "temperature": 0.0, "avg_logprob": -0.18823293176027808, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0913163349032402}, {"id": 132, "seek": 62984, "start": 635.52, "end": 641.32, "text": " message string, right, because every thing you put in the source code is looked again", "tokens": [50648, 3636, 6798, 11, 558, 11, 570, 633, 551, 291, 829, 294, 264, 4009, 3089, 307, 2956, 797, 50938], "temperature": 0.0, "avg_logprob": -0.18823293176027808, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0913163349032402}, {"id": 133, "seek": 62984, "start": 641.32, "end": 648.32, "text": " later by at least one more person or several other translators and you catch typos and", "tokens": [50938, 1780, 538, 412, 1935, 472, 544, 954, 420, 2940, 661, 5105, 3391, 293, 291, 3745, 2125, 329, 293, 51288], "temperature": 0.0, "avg_logprob": -0.18823293176027808, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0913163349032402}, {"id": 134, "seek": 62984, "start": 648.32, "end": 652.48, "text": " stuff like that, but also if something doesn't make any sense, right, maybe some developer", "tokens": [51288, 1507, 411, 300, 11, 457, 611, 498, 746, 1177, 380, 652, 604, 2020, 11, 558, 11, 1310, 512, 10754, 51496], "temperature": 0.0, "avg_logprob": -0.18823293176027808, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0913163349032402}, {"id": 135, "seek": 62984, "start": 652.48, "end": 657.72, "text": " wrote it and it makes sense to them, but then you know someone else who is not that very", "tokens": [51496, 4114, 309, 293, 309, 1669, 2020, 281, 552, 11, 457, 550, 291, 458, 1580, 1646, 567, 307, 406, 300, 588, 51758], "temperature": 0.0, "avg_logprob": -0.18823293176027808, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0913163349032402}, {"id": 136, "seek": 65772, "start": 657.76, "end": 661.76, "text": " developer looks at it again, I don't really understand this, I can't translate it because", "tokens": [50366, 10754, 1542, 412, 309, 797, 11, 286, 500, 380, 534, 1223, 341, 11, 286, 393, 380, 13799, 309, 570, 50566], "temperature": 0.0, "avg_logprob": -0.2600389046244102, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.01495418231934309}, {"id": 137, "seek": 65772, "start": 661.76, "end": 665.36, "text": " I don't understand it or it looks weird, could we look at it again, so you get this review", "tokens": [50566, 286, 500, 380, 1223, 309, 420, 309, 1542, 3657, 11, 727, 321, 574, 412, 309, 797, 11, 370, 291, 483, 341, 3131, 50746], "temperature": 0.0, "avg_logprob": -0.2600389046244102, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.01495418231934309}, {"id": 138, "seek": 65772, "start": 665.36, "end": 672.36, "text": " process and you've gotten really good in in in postgres about really tuning error messages", "tokens": [50746, 1399, 293, 291, 600, 5768, 534, 665, 294, 294, 294, 2183, 45189, 466, 534, 15164, 6713, 7897, 51096], "temperature": 0.0, "avg_logprob": -0.2600389046244102, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.01495418231934309}, {"id": 139, "seek": 65772, "start": 673.52, "end": 678.6, "text": " because it's a complicated piece of software and you get all these weird scenarios with", "tokens": [51154, 570, 309, 311, 257, 6179, 2522, 295, 4722, 293, 291, 483, 439, 613, 3657, 15077, 365, 51408], "temperature": 0.0, "avg_logprob": -0.2600389046244102, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.01495418231934309}, {"id": 140, "seek": 65772, "start": 678.6, "end": 685.0400000000001, "text": " sort of transaction processing and weird right ahead log and replication and all these kinds", "tokens": [51408, 1333, 295, 14425, 9007, 293, 3657, 558, 2286, 3565, 293, 39911, 293, 439, 613, 3685, 51730], "temperature": 0.0, "avg_logprob": -0.2600389046244102, "compression_ratio": 1.8373983739837398, "no_speech_prob": 0.01495418231934309}, {"id": 141, "seek": 68504, "start": 685.04, "end": 688.64, "text": " of things and so you want to be really good and precise to explain that you was okay this", "tokens": [50364, 295, 721, 293, 370, 291, 528, 281, 312, 534, 665, 293, 13600, 281, 2903, 300, 291, 390, 1392, 341, 50544], "temperature": 0.0, "avg_logprob": -0.18790183464686075, "compression_ratio": 1.902542372881356, "no_speech_prob": 0.014056912623345852}, {"id": 142, "seek": 68504, "start": 688.64, "end": 695.16, "text": " failed because of this and you could try this but don't try that and you know so this is", "tokens": [50544, 7612, 570, 295, 341, 293, 291, 727, 853, 341, 457, 500, 380, 853, 300, 293, 291, 458, 370, 341, 307, 50870], "temperature": 0.0, "avg_logprob": -0.18790183464686075, "compression_ratio": 1.902542372881356, "no_speech_prob": 0.014056912623345852}, {"id": 143, "seek": 68504, "start": 695.16, "end": 698.68, "text": " really I think people appreciate that independent of translation and everything else I think", "tokens": [50870, 534, 286, 519, 561, 4449, 300, 6695, 295, 12853, 293, 1203, 1646, 286, 519, 51046], "temperature": 0.0, "avg_logprob": -0.18790183464686075, "compression_ratio": 1.902542372881356, "no_speech_prob": 0.014056912623345852}, {"id": 144, "seek": 68504, "start": 698.68, "end": 705.68, "text": " people appreciate that and this process actually helps that because you sort of refine your", "tokens": [51046, 561, 4449, 300, 293, 341, 1399, 767, 3665, 300, 570, 291, 1333, 295, 33906, 428, 51396], "temperature": 0.0, "avg_logprob": -0.18790183464686075, "compression_ratio": 1.902542372881356, "no_speech_prob": 0.014056912623345852}, {"id": 145, "seek": 68504, "start": 705.68, "end": 711.12, "text": " program's messages through this process as well, right, and secondly actually it also", "tokens": [51396, 1461, 311, 7897, 807, 341, 1399, 382, 731, 11, 558, 11, 293, 26246, 767, 309, 611, 51668], "temperature": 0.0, "avg_logprob": -0.18790183464686075, "compression_ratio": 1.902542372881356, "no_speech_prob": 0.014056912623345852}, {"id": 146, "seek": 71112, "start": 711.16, "end": 718.16, "text": " turned out that sometimes people come in, do some translation, maybe find a bug or want", "tokens": [50366, 3574, 484, 300, 2171, 561, 808, 294, 11, 360, 512, 12853, 11, 1310, 915, 257, 7426, 420, 528, 50716], "temperature": 0.0, "avg_logprob": -0.1475681038789971, "compression_ratio": 1.729064039408867, "no_speech_prob": 0.0026310025714337826}, {"id": 147, "seek": 71112, "start": 718.16, "end": 721.8, "text": " to look something up in a source code, go into the source code and then become a programmer", "tokens": [50716, 281, 574, 746, 493, 294, 257, 4009, 3089, 11, 352, 666, 264, 4009, 3089, 293, 550, 1813, 257, 32116, 50898], "temperature": 0.0, "avg_logprob": -0.1475681038789971, "compression_ratio": 1.729064039408867, "no_speech_prob": 0.0026310025714337826}, {"id": 148, "seek": 71112, "start": 721.8, "end": 728.8, "text": " so you can also kind of recruit people that way, it's kind of interesting, so but then", "tokens": [50898, 370, 291, 393, 611, 733, 295, 15119, 561, 300, 636, 11, 309, 311, 733, 295, 1880, 11, 370, 457, 550, 51248], "temperature": 0.0, "avg_logprob": -0.1475681038789971, "compression_ratio": 1.729064039408867, "no_speech_prob": 0.0026310025714337826}, {"id": 149, "seek": 71112, "start": 729.5600000000001, "end": 736.5600000000001, "text": " there are many challenges, right, so first of all you want to get people in there to", "tokens": [51286, 456, 366, 867, 4759, 11, 558, 11, 370, 700, 295, 439, 291, 528, 281, 483, 561, 294, 456, 281, 51636], "temperature": 0.0, "avg_logprob": -0.1475681038789971, "compression_ratio": 1.729064039408867, "no_speech_prob": 0.0026310025714337826}, {"id": 150, "seek": 73656, "start": 736.76, "end": 741.4399999999999, "text": " use the translation, right, and it's just this you know because postgres is not sort", "tokens": [50374, 764, 264, 12853, 11, 558, 11, 293, 309, 311, 445, 341, 291, 458, 570, 2183, 45189, 307, 406, 1333, 50608], "temperature": 0.0, "avg_logprob": -0.18652962771329012, "compression_ratio": 1.86864406779661, "no_speech_prob": 0.02634301967918873}, {"id": 151, "seek": 73656, "start": 741.4399999999999, "end": 747.5999999999999, "text": " of or similar systems as well, right, it's not end user facing, it's not used by sort", "tokens": [50608, 295, 420, 2531, 3652, 382, 731, 11, 558, 11, 309, 311, 406, 917, 4195, 7170, 11, 309, 311, 406, 1143, 538, 1333, 50916], "temperature": 0.0, "avg_logprob": -0.18652962771329012, "compression_ratio": 1.86864406779661, "no_speech_prob": 0.02634301967918873}, {"id": 152, "seek": 73656, "start": 747.5999999999999, "end": 754.5999999999999, "text": " of random average people, right, it's used by technically minded people, experts, database", "tokens": [50916, 295, 4974, 4274, 561, 11, 558, 11, 309, 311, 1143, 538, 12120, 36707, 561, 11, 8572, 11, 8149, 51266], "temperature": 0.0, "avg_logprob": -0.18652962771329012, "compression_ratio": 1.86864406779661, "no_speech_prob": 0.02634301967918873}, {"id": 153, "seek": 73656, "start": 754.68, "end": 760.5999999999999, "text": " administrators and so on, so a lot of those people there's not too much pressure to actually", "tokens": [51270, 27754, 293, 370, 322, 11, 370, 257, 688, 295, 729, 561, 456, 311, 406, 886, 709, 3321, 281, 767, 51566], "temperature": 0.0, "avg_logprob": -0.18652962771329012, "compression_ratio": 1.86864406779661, "no_speech_prob": 0.02634301967918873}, {"id": 154, "seek": 73656, "start": 760.5999999999999, "end": 764.92, "text": " have things translated, people be okay it's not translated, it's fine, right, which is", "tokens": [51566, 362, 721, 16805, 11, 561, 312, 1392, 309, 311, 406, 16805, 11, 309, 311, 2489, 11, 558, 11, 597, 307, 51782], "temperature": 0.0, "avg_logprob": -0.18652962771329012, "compression_ratio": 1.86864406779661, "no_speech_prob": 0.02634301967918873}, {"id": 155, "seek": 76492, "start": 764.9599999999999, "end": 769.4399999999999, "text": " different from you know if LibreOffice or Firefox is not translated and you install", "tokens": [50366, 819, 490, 291, 458, 498, 15834, 265, 29745, 573, 420, 46613, 307, 406, 16805, 293, 291, 3625, 50590], "temperature": 0.0, "avg_logprob": -0.17908931341696913, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.007009181659668684}, {"id": 156, "seek": 76492, "start": 769.4399999999999, "end": 773.28, "text": " in a school, it wouldn't work, it's just you can't do that, right, but here it's like", "tokens": [50590, 294, 257, 1395, 11, 309, 2759, 380, 589, 11, 309, 311, 445, 291, 393, 380, 360, 300, 11, 558, 11, 457, 510, 309, 311, 411, 50782], "temperature": 0.0, "avg_logprob": -0.17908931341696913, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.007009181659668684}, {"id": 157, "seek": 76492, "start": 773.28, "end": 778.1999999999999, "text": " okay if it's not, if it's not, if it doesn't get done it's not a problem in a way, but", "tokens": [50782, 1392, 498, 309, 311, 406, 11, 498, 309, 311, 406, 11, 498, 309, 1177, 380, 483, 1096, 309, 311, 406, 257, 1154, 294, 257, 636, 11, 457, 51028], "temperature": 0.0, "avg_logprob": -0.17908931341696913, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.007009181659668684}, {"id": 158, "seek": 76492, "start": 778.1999999999999, "end": 781.9599999999999, "text": " we just want to do it because we like it, but if it doesn't get done it's like okay", "tokens": [51028, 321, 445, 528, 281, 360, 309, 570, 321, 411, 309, 11, 457, 498, 309, 1177, 380, 483, 1096, 309, 311, 411, 1392, 51216], "temperature": 0.0, "avg_logprob": -0.17908931341696913, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.007009181659668684}, {"id": 159, "seek": 76492, "start": 781.9599999999999, "end": 787.5999999999999, "text": " then we'll just move on, right, so you got to kind of, it relies on a lot of enthusiasm,", "tokens": [51216, 550, 321, 603, 445, 1286, 322, 11, 558, 11, 370, 291, 658, 281, 733, 295, 11, 309, 30910, 322, 257, 688, 295, 23417, 11, 51498], "temperature": 0.0, "avg_logprob": -0.17908931341696913, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.007009181659668684}, {"id": 160, "seek": 78760, "start": 787.9200000000001, "end": 794.9200000000001, "text": " individual enthusiasm, right, a lot of the, yeah I found also at least personally as", "tokens": [50380, 2609, 23417, 11, 558, 11, 257, 688, 295, 264, 11, 1338, 286, 1352, 611, 412, 1935, 5665, 382, 50730], "temperature": 0.0, "avg_logprob": -0.20972914548264338, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.31046172976493835}, {"id": 161, "seek": 78760, "start": 795.6, "end": 800.72, "text": " doing some of the translation work myself the terminology is hard sometimes, right, because", "tokens": [50764, 884, 512, 295, 264, 12853, 589, 2059, 264, 27575, 307, 1152, 2171, 11, 558, 11, 570, 51020], "temperature": 0.0, "avg_logprob": -0.20972914548264338, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.31046172976493835}, {"id": 162, "seek": 78760, "start": 800.72, "end": 805.88, "text": " again I just mentioned something like that, it's not just press this button to download", "tokens": [51020, 797, 286, 445, 2835, 746, 411, 300, 11, 309, 311, 406, 445, 1886, 341, 2960, 281, 5484, 51278], "temperature": 0.0, "avg_logprob": -0.20972914548264338, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.31046172976493835}, {"id": 163, "seek": 78760, "start": 805.88, "end": 810.28, "text": " a thing, okay you can translate that in any language probably by now, but what if you", "tokens": [51278, 257, 551, 11, 1392, 291, 393, 13799, 300, 294, 604, 2856, 1391, 538, 586, 11, 457, 437, 498, 291, 51498], "temperature": 0.0, "avg_logprob": -0.20972914548264338, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.31046172976493835}, {"id": 164, "seek": 78760, "start": 810.28, "end": 816.12, "text": " get into terms like you know sub transaction rollback or incremental materialized view", "tokens": [51498, 483, 666, 2115, 411, 291, 458, 1422, 14425, 3373, 3207, 420, 35759, 2527, 1602, 1910, 51790], "temperature": 0.0, "avg_logprob": -0.20972914548264338, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.31046172976493835}, {"id": 165, "seek": 81612, "start": 816.12, "end": 821.4, "text": " maintenance, you know some languages might not even have terms for that maybe, you know", "tokens": [50364, 11258, 11, 291, 458, 512, 8650, 1062, 406, 754, 362, 2115, 337, 300, 1310, 11, 291, 458, 50628], "temperature": 0.0, "avg_logprob": -0.16872609578646147, "compression_ratio": 1.8178137651821862, "no_speech_prob": 0.015641700476408005}, {"id": 166, "seek": 81612, "start": 821.4, "end": 828.4, "text": " sometimes when I do the work I pick you know I have some textbooks like academic textbooks", "tokens": [50628, 2171, 562, 286, 360, 264, 589, 286, 1888, 291, 458, 286, 362, 512, 33587, 411, 7778, 33587, 50978], "temperature": 0.0, "avg_logprob": -0.16872609578646147, "compression_ratio": 1.8178137651821862, "no_speech_prob": 0.015641700476408005}, {"id": 167, "seek": 81612, "start": 828.5600000000001, "end": 834.12, "text": " in German in my case and I just go through them like anybody in here talk about materialized", "tokens": [50986, 294, 6521, 294, 452, 1389, 293, 286, 445, 352, 807, 552, 411, 4472, 294, 510, 751, 466, 2527, 1602, 51264], "temperature": 0.0, "avg_logprob": -0.16872609578646147, "compression_ratio": 1.8178137651821862, "no_speech_prob": 0.015641700476408005}, {"id": 168, "seek": 81612, "start": 834.12, "end": 839.32, "text": " views, what kind of terminology are they using and then I have like six books and three do", "tokens": [51264, 6809, 11, 437, 733, 295, 27575, 366, 436, 1228, 293, 550, 286, 362, 411, 2309, 3642, 293, 1045, 360, 51524], "temperature": 0.0, "avg_logprob": -0.16872609578646147, "compression_ratio": 1.8178137651821862, "no_speech_prob": 0.015641700476408005}, {"id": 169, "seek": 81612, "start": 839.32, "end": 843.12, "text": " this way and three do it that way and then I just pick something at some point, right,", "tokens": [51524, 341, 636, 293, 1045, 360, 309, 300, 636, 293, 550, 286, 445, 1888, 746, 412, 512, 935, 11, 558, 11, 51714], "temperature": 0.0, "avg_logprob": -0.16872609578646147, "compression_ratio": 1.8178137651821862, "no_speech_prob": 0.015641700476408005}, {"id": 170, "seek": 84312, "start": 843.16, "end": 849.84, "text": " and so in some way we have to kind of define, make up the terminology in some cases even,", "tokens": [50366, 293, 370, 294, 512, 636, 321, 362, 281, 733, 295, 6964, 11, 652, 493, 264, 27575, 294, 512, 3331, 754, 11, 50700], "temperature": 0.0, "avg_logprob": -0.27224911281040737, "compression_ratio": 1.5, "no_speech_prob": 0.0003919572045560926}, {"id": 171, "seek": 84312, "start": 849.84, "end": 856.84, "text": " right, so and as I alluded to the work flow is not as cool as what we saw in the previous", "tokens": [50700, 558, 11, 370, 293, 382, 286, 33919, 281, 264, 589, 3095, 307, 406, 382, 1627, 382, 437, 321, 1866, 294, 264, 3894, 51050], "temperature": 0.0, "avg_logprob": -0.27224911281040737, "compression_ratio": 1.5, "no_speech_prob": 0.0003919572045560926}, {"id": 172, "seek": 84312, "start": 859.84, "end": 866.84, "text": " talk so maybe we can improve that. So here's some sort of source code level challenges,", "tokens": [51200, 751, 370, 1310, 321, 393, 3470, 300, 13, 407, 510, 311, 512, 1333, 295, 4009, 3089, 1496, 4759, 11, 51550], "temperature": 0.0, "avg_logprob": -0.27224911281040737, "compression_ratio": 1.5, "no_speech_prob": 0.0003919572045560926}, {"id": 173, "seek": 86684, "start": 866.84, "end": 873.4, "text": " some of those are solvable, some of those are not, people who work in translation know", "tokens": [50364, 512, 295, 729, 366, 1404, 17915, 11, 512, 295, 729, 366, 406, 11, 561, 567, 589, 294, 12853, 458, 50692], "temperature": 0.0, "avg_logprob": -0.18686573479765206, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.0251641683280468}, {"id": 174, "seek": 86684, "start": 873.4, "end": 878.9200000000001, "text": " about like plural issues, right, we do handle that, works fine, but then if you, I've never", "tokens": [50692, 466, 411, 25377, 2663, 11, 558, 11, 321, 360, 4813, 300, 11, 1985, 2489, 11, 457, 550, 498, 291, 11, 286, 600, 1128, 50968], "temperature": 0.0, "avg_logprob": -0.18686573479765206, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.0251641683280468}, {"id": 175, "seek": 86684, "start": 878.9200000000001, "end": 885.9200000000001, "text": " figured out how to handle the first one, like if you have two or more numbers in a sentence", "tokens": [50968, 8932, 484, 577, 281, 4813, 264, 700, 472, 11, 411, 498, 291, 362, 732, 420, 544, 3547, 294, 257, 8174, 51318], "temperature": 0.0, "avg_logprob": -0.18686573479765206, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.0251641683280468}, {"id": 176, "seek": 86684, "start": 887.88, "end": 894.48, "text": " like then you would have to have some combinatorial sort of list of translations, what if the first", "tokens": [51416, 411, 550, 291, 576, 362, 281, 362, 512, 2512, 31927, 831, 1333, 295, 1329, 295, 37578, 11, 437, 498, 264, 700, 51746], "temperature": 0.0, "avg_logprob": -0.18686573479765206, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.0251641683280468}, {"id": 177, "seek": 89448, "start": 894.52, "end": 898.9200000000001, "text": " one is singular and the last one is five and what if the first one is two and the last", "tokens": [50366, 472, 307, 20010, 293, 264, 1036, 472, 307, 1732, 293, 437, 498, 264, 700, 472, 307, 732, 293, 264, 1036, 50586], "temperature": 0.0, "avg_logprob": -0.19287956761949845, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.0027568633668124676}, {"id": 178, "seek": 89448, "start": 898.9200000000001, "end": 904.48, "text": " one is 18, you know, I don't think you can really solve that and you just start rephrasing", "tokens": [50586, 472, 307, 2443, 11, 291, 458, 11, 286, 500, 380, 519, 291, 393, 534, 5039, 300, 293, 291, 445, 722, 319, 44598, 3349, 50864], "temperature": 0.0, "avg_logprob": -0.19287956761949845, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.0027568633668124676}, {"id": 179, "seek": 89448, "start": 904.48, "end": 909.28, "text": " things in weird ways. We have the second one which obviously everybody knows you shouldn't", "tokens": [50864, 721, 294, 3657, 2098, 13, 492, 362, 264, 1150, 472, 597, 2745, 2201, 3255, 291, 4659, 380, 51104], "temperature": 0.0, "avg_logprob": -0.19287956761949845, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.0027568633668124676}, {"id": 180, "seek": 89448, "start": 909.28, "end": 914.9200000000001, "text": " do if you sort of paste terms together that doesn't work, right, let's say you're just", "tokens": [51104, 360, 498, 291, 1333, 295, 9163, 2115, 1214, 300, 1177, 380, 589, 11, 558, 11, 718, 311, 584, 291, 434, 445, 51386], "temperature": 0.0, "avg_logprob": -0.19287956761949845, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.0027568633668124676}, {"id": 181, "seek": 89448, "start": 914.9200000000001, "end": 918.72, "text": " going to make something up like you can't, cannot apply a generation expression to a", "tokens": [51386, 516, 281, 652, 746, 493, 411, 291, 393, 380, 11, 2644, 3079, 257, 5125, 6114, 281, 257, 51576], "temperature": 0.0, "avg_logprob": -0.19287956761949845, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.0027568633668124676}, {"id": 182, "seek": 89448, "start": 918.72, "end": 922.24, "text": " materialized view, let's say something like that, that's a thing that could happen in", "tokens": [51576, 2527, 1602, 1910, 11, 718, 311, 584, 746, 411, 300, 11, 300, 311, 257, 551, 300, 727, 1051, 294, 51752], "temperature": 0.0, "avg_logprob": -0.19287956761949845, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.0027568633668124676}, {"id": 183, "seek": 92224, "start": 922.28, "end": 927.6800000000001, "text": " postgres, more or less, right, like okay you shouldn't, you shouldn't do that, you shouldn't", "tokens": [50366, 2183, 45189, 11, 544, 420, 1570, 11, 558, 11, 411, 1392, 291, 4659, 380, 11, 291, 4659, 380, 360, 300, 11, 291, 4659, 380, 50636], "temperature": 0.0, "avg_logprob": -0.20447111129760742, "compression_ratio": 1.7277227722772277, "no_speech_prob": 0.00263121142052114}, {"id": 184, "seek": 92224, "start": 927.6800000000001, "end": 930.64, "text": " sort of stick that into the middle of the sentence because then the grammar doesn't", "tokens": [50636, 1333, 295, 2897, 300, 666, 264, 2808, 295, 264, 8174, 570, 550, 264, 22317, 1177, 380, 50784], "temperature": 0.0, "avg_logprob": -0.20447111129760742, "compression_ratio": 1.7277227722772277, "no_speech_prob": 0.00263121142052114}, {"id": 185, "seek": 92224, "start": 930.64, "end": 937.64, "text": " match in some sentences, so you write those out, but what if you have like five options", "tokens": [50784, 2995, 294, 512, 16579, 11, 370, 291, 2464, 729, 484, 11, 457, 437, 498, 291, 362, 411, 1732, 3956, 51134], "temperature": 0.0, "avg_logprob": -0.20447111129760742, "compression_ratio": 1.7277227722772277, "no_speech_prob": 0.00263121142052114}, {"id": 186, "seek": 92224, "start": 938.96, "end": 945.2, "text": " here and six options there, are you going to make 30 strings in your source code, at", "tokens": [51200, 510, 293, 2309, 3956, 456, 11, 366, 291, 516, 281, 652, 2217, 13985, 294, 428, 4009, 3089, 11, 412, 51512], "temperature": 0.0, "avg_logprob": -0.20447111129760742, "compression_ratio": 1.7277227722772277, "no_speech_prob": 0.00263121142052114}, {"id": 187, "seek": 94520, "start": 945.24, "end": 952.24, "text": " some point probably not, right, so at some point then developers, the actual developers", "tokens": [50366, 512, 935, 1391, 406, 11, 558, 11, 370, 412, 512, 935, 550, 8849, 11, 264, 3539, 8849, 50716], "temperature": 0.0, "avg_logprob": -0.24265532895743128, "compression_ratio": 1.6701570680628273, "no_speech_prob": 0.04141749441623688}, {"id": 188, "seek": 94520, "start": 953.8000000000001, "end": 957.0400000000001, "text": " do get annoyed if you tell them like no, you can't do that, you have to write actually", "tokens": [50794, 360, 483, 25921, 498, 291, 980, 552, 411, 572, 11, 291, 393, 380, 360, 300, 11, 291, 362, 281, 2464, 767, 50956], "temperature": 0.0, "avg_logprob": -0.24265532895743128, "compression_ratio": 1.6701570680628273, "no_speech_prob": 0.04141749441623688}, {"id": 189, "seek": 94520, "start": 957.0400000000001, "end": 960.0400000000001, "text": " 35 error messages by hand, so I'm not going to do that.", "tokens": [50956, 6976, 6713, 7897, 538, 1011, 11, 370, 286, 478, 406, 516, 281, 360, 300, 13, 51106], "temperature": 0.0, "avg_logprob": -0.24265532895743128, "compression_ratio": 1.6701570680628273, "no_speech_prob": 0.04141749441623688}, {"id": 190, "seek": 94520, "start": 960.0400000000001, "end": 967.0400000000001, "text": " Yeah, you start then tweaking it, can you say something, something semi-colon, something", "tokens": [51106, 865, 11, 291, 722, 550, 6986, 2456, 309, 11, 393, 291, 584, 746, 11, 746, 12909, 12, 8768, 266, 11, 746, 51456], "temperature": 0.0, "avg_logprob": -0.24265532895743128, "compression_ratio": 1.6701570680628273, "no_speech_prob": 0.04141749441623688}, {"id": 191, "seek": 97520, "start": 975.36, "end": 979.6800000000001, "text": " something, and then maybe at that point it's okay, I don't know, but yeah, exactly, so", "tokens": [50372, 746, 11, 293, 550, 1310, 412, 300, 935, 309, 311, 1392, 11, 286, 500, 380, 458, 11, 457, 1338, 11, 2293, 11, 370, 50588], "temperature": 0.0, "avg_logprob": -0.1692932507463994, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.03903685882687569}, {"id": 192, "seek": 97520, "start": 979.6800000000001, "end": 986.6800000000001, "text": " you have to make judgment, use some judgment calls in these cases, and one thing that sometimes", "tokens": [50588, 291, 362, 281, 652, 12216, 11, 764, 512, 12216, 5498, 294, 613, 3331, 11, 293, 472, 551, 300, 2171, 50938], "temperature": 0.0, "avg_logprob": -0.1692932507463994, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.03903685882687569}, {"id": 193, "seek": 97520, "start": 986.8000000000001, "end": 990.5200000000001, "text": " happened if developers add a new file to source code then it has to be added somewhere else", "tokens": [50944, 2011, 498, 8849, 909, 257, 777, 3991, 281, 4009, 3089, 550, 309, 575, 281, 312, 3869, 4079, 1646, 51130], "temperature": 0.0, "avg_logprob": -0.1692932507463994, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.03903685882687569}, {"id": 194, "seek": 97520, "start": 990.5200000000001, "end": 995.8000000000001, "text": " also to make sure the translation system catches it and that sometimes gets forgotten, it's", "tokens": [51130, 611, 281, 652, 988, 264, 12853, 1185, 25496, 309, 293, 300, 2171, 2170, 11832, 11, 309, 311, 51394], "temperature": 0.0, "avg_logprob": -0.1692932507463994, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.03903685882687569}, {"id": 195, "seek": 97520, "start": 995.8000000000001, "end": 999.0400000000001, "text": " just one of those things, I don't know if there's a solution for that, you just gotta", "tokens": [51394, 445, 472, 295, 729, 721, 11, 286, 500, 380, 458, 498, 456, 311, 257, 3827, 337, 300, 11, 291, 445, 3428, 51556], "temperature": 0.0, "avg_logprob": -0.1692932507463994, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.03903685882687569}, {"id": 196, "seek": 97520, "start": 999.0400000000001, "end": 1004.0400000000001, "text": " do it, there's also some weird thing, we have like files that get compiled into multiple", "tokens": [51556, 360, 309, 11, 456, 311, 611, 512, 3657, 551, 11, 321, 362, 411, 7098, 300, 483, 36548, 666, 3866, 51806], "temperature": 0.0, "avg_logprob": -0.1692932507463994, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.03903685882687569}, {"id": 197, "seek": 100404, "start": 1004.04, "end": 1011.04, "text": " components and then you kind of have to add them to all of those components and re-translate", "tokens": [50364, 6677, 293, 550, 291, 733, 295, 362, 281, 909, 552, 281, 439, 295, 729, 6677, 293, 319, 12, 24999, 17593, 50714], "temperature": 0.0, "avg_logprob": -0.21161229269845144, "compression_ratio": 1.7427184466019416, "no_speech_prob": 0.00546709168702364}, {"id": 198, "seek": 100404, "start": 1011.16, "end": 1015.8, "text": " everything in each component which could be handled with some of those translation memory", "tokens": [50720, 1203, 294, 1184, 6542, 597, 727, 312, 18033, 365, 512, 295, 729, 12853, 4675, 50952], "temperature": 0.0, "avg_logprob": -0.21161229269845144, "compression_ratio": 1.7427184466019416, "no_speech_prob": 0.00546709168702364}, {"id": 199, "seek": 100404, "start": 1015.8, "end": 1019.88, "text": " things and stuff like that, but it's just kind of weird the way we have it laid out", "tokens": [50952, 721, 293, 1507, 411, 300, 11, 457, 309, 311, 445, 733, 295, 3657, 264, 636, 321, 362, 309, 9897, 484, 51156], "temperature": 0.0, "avg_logprob": -0.21161229269845144, "compression_ratio": 1.7427184466019416, "no_speech_prob": 0.00546709168702364}, {"id": 200, "seek": 100404, "start": 1019.88, "end": 1026.8799999999999, "text": " and it kind of makes it annoying, yeah, so this is maybe specific to something like Postgres", "tokens": [51156, 293, 309, 733, 295, 1669, 309, 11304, 11, 1338, 11, 370, 341, 307, 1310, 2685, 281, 746, 411, 10223, 45189, 51506], "temperature": 0.0, "avg_logprob": -0.21161229269845144, "compression_ratio": 1.7427184466019416, "no_speech_prob": 0.00546709168702364}, {"id": 201, "seek": 102688, "start": 1027.0, "end": 1034.0, "text": " being A, a client server system, B, a database, and C having its own sort of ideas about what", "tokens": [50370, 885, 316, 11, 257, 6423, 7154, 1185, 11, 363, 11, 257, 8149, 11, 293, 383, 1419, 1080, 1065, 1333, 295, 3487, 466, 437, 50720], "temperature": 0.0, "avg_logprob": -0.29991055878115375, "compression_ratio": 1.5976331360946745, "no_speech_prob": 0.0032721729949116707}, {"id": 202, "seek": 102688, "start": 1034.0, "end": 1041.0, "text": " encoding on locale and stuff like that means, right, so in, you know, a database stores", "tokens": [50720, 43430, 322, 1628, 1220, 293, 1507, 411, 300, 1355, 11, 558, 11, 370, 294, 11, 291, 458, 11, 257, 8149, 9512, 51070], "temperature": 0.0, "avg_logprob": -0.29991055878115375, "compression_ratio": 1.5976331360946745, "no_speech_prob": 0.0032721729949116707}, {"id": 203, "seek": 102688, "start": 1047.8000000000002, "end": 1054.8000000000002, "text": " data which is often text which has an encoding and because of, you know, it doesn't have", "tokens": [51410, 1412, 597, 307, 2049, 2487, 597, 575, 364, 43430, 293, 570, 295, 11, 291, 458, 11, 309, 1177, 380, 362, 51760], "temperature": 0.0, "avg_logprob": -0.29991055878115375, "compression_ratio": 1.5976331360946745, "no_speech_prob": 0.0032721729949116707}, {"id": 204, "seek": 105688, "start": 1057.0, "end": 1061.6000000000001, "text": " nowadays you think everything's UTF-8 but in a database you can also store things in", "tokens": [50370, 13434, 291, 519, 1203, 311, 624, 20527, 12, 23, 457, 294, 257, 8149, 291, 393, 611, 3531, 721, 294, 50600], "temperature": 0.0, "avg_logprob": -0.17916453968394885, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0033757516648620367}, {"id": 205, "seek": 105688, "start": 1061.6000000000001, "end": 1066.96, "text": " other encodings for historical reasons or in some cases because UTF-8 doesn't actually", "tokens": [50600, 661, 2058, 378, 1109, 337, 8584, 4112, 420, 294, 512, 3331, 570, 624, 20527, 12, 23, 1177, 380, 767, 50868], "temperature": 0.0, "avg_logprob": -0.17916453968394885, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0033757516648620367}, {"id": 206, "seek": 105688, "start": 1066.96, "end": 1072.16, "text": " match what doesn't support what you want to store which sounds maybe bizarre but happens", "tokens": [50868, 2995, 437, 1177, 380, 1406, 437, 291, 528, 281, 3531, 597, 3263, 1310, 18265, 457, 2314, 51128], "temperature": 0.0, "avg_logprob": -0.17916453968394885, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0033757516648620367}, {"id": 207, "seek": 105688, "start": 1072.16, "end": 1078.2800000000002, "text": " especially in sort of Japanese and things like that, so we do support automatic encoding", "tokens": [51128, 2318, 294, 1333, 295, 5433, 293, 721, 411, 300, 11, 370, 321, 360, 1406, 12509, 43430, 51434], "temperature": 0.0, "avg_logprob": -0.17916453968394885, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0033757516648620367}, {"id": 208, "seek": 105688, "start": 1078.2800000000002, "end": 1084.24, "text": " conversion between client and server so that all works and happens, but then this all sort", "tokens": [51434, 14298, 1296, 6423, 293, 7154, 370, 300, 439, 1985, 293, 2314, 11, 457, 550, 341, 439, 1333, 51732], "temperature": 0.0, "avg_logprob": -0.17916453968394885, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0033757516648620367}, {"id": 209, "seek": 108424, "start": 1084.28, "end": 1089.2, "text": " of, what if you have, you know, your strings, your translated strings are in a file, they", "tokens": [50366, 295, 11, 437, 498, 291, 362, 11, 291, 458, 11, 428, 13985, 11, 428, 16805, 13985, 366, 294, 257, 3991, 11, 436, 50612], "temperature": 0.0, "avg_logprob": -0.149623678280757, "compression_ratio": 1.8836206896551724, "no_speech_prob": 0.006587994284927845}, {"id": 210, "seek": 108424, "start": 1089.2, "end": 1094.68, "text": " also have an encoding, they then get loaded into the server process, the server process", "tokens": [50612, 611, 362, 364, 43430, 11, 436, 550, 483, 13210, 666, 264, 7154, 1399, 11, 264, 7154, 1399, 50886], "temperature": 0.0, "avg_logprob": -0.149623678280757, "compression_ratio": 1.8836206896551724, "no_speech_prob": 0.006587994284927845}, {"id": 211, "seek": 108424, "start": 1094.68, "end": 1099.4, "text": " prints stuff to its own log but also sends error messages to the client, all of those", "tokens": [50886, 22305, 1507, 281, 1080, 1065, 3565, 457, 611, 14790, 6713, 7897, 281, 264, 6423, 11, 439, 295, 729, 51122], "temperature": 0.0, "avg_logprob": -0.149623678280757, "compression_ratio": 1.8836206896551724, "no_speech_prob": 0.006587994284927845}, {"id": 212, "seek": 108424, "start": 1099.4, "end": 1104.92, "text": " things could have different ideas of what they want, right, you might want to log stuff", "tokens": [51122, 721, 727, 362, 819, 3487, 295, 437, 436, 528, 11, 558, 11, 291, 1062, 528, 281, 3565, 1507, 51398], "temperature": 0.0, "avg_logprob": -0.149623678280757, "compression_ratio": 1.8836206896551724, "no_speech_prob": 0.006587994284927845}, {"id": 213, "seek": 108424, "start": 1104.92, "end": 1110.92, "text": " in English to your server log but the client wants the error message in French or for", "tokens": [51398, 294, 3669, 281, 428, 7154, 3565, 457, 264, 6423, 2738, 264, 6713, 3636, 294, 5522, 420, 337, 51698], "temperature": 0.0, "avg_logprob": -0.149623678280757, "compression_ratio": 1.8836206896551724, "no_speech_prob": 0.006587994284927845}, {"id": 214, "seek": 111092, "start": 1110.96, "end": 1117.96, "text": " some, maybe it's like legacy client that wants it, you know, transcoded to Latin 9 and then", "tokens": [50366, 512, 11, 1310, 309, 311, 411, 11711, 6423, 300, 2738, 309, 11, 291, 458, 11, 43800, 12340, 281, 10803, 1722, 293, 550, 50716], "temperature": 0.0, "avg_logprob": -0.24702466920364735, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0011155963875353336}, {"id": 215, "seek": 111092, "start": 1119.8400000000001, "end": 1125.04, "text": " at the same time there's a different client connected that also is doing things to a", "tokens": [50810, 412, 264, 912, 565, 456, 311, 257, 819, 6423, 4582, 300, 611, 307, 884, 721, 281, 257, 51070], "temperature": 0.0, "avg_logprob": -0.24702466920364735, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0011155963875353336}, {"id": 216, "seek": 111092, "start": 1125.04, "end": 1128.3200000000002, "text": " different language, you want to log it to the same server log in the same language,", "tokens": [51070, 819, 2856, 11, 291, 528, 281, 3565, 309, 281, 264, 912, 7154, 3565, 294, 264, 912, 2856, 11, 51234], "temperature": 0.0, "avg_logprob": -0.24702466920364735, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0011155963875353336}, {"id": 217, "seek": 111092, "start": 1128.3200000000002, "end": 1134.8200000000002, "text": " in the same encoding, hopefully as the other guy, all of this works quite poorly the way", "tokens": [51234, 294, 264, 912, 43430, 11, 4696, 382, 264, 661, 2146, 11, 439, 295, 341, 1985, 1596, 22271, 264, 636, 51559], "temperature": 0.0, "avg_logprob": -0.24702466920364735, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0011155963875353336}, {"id": 218, "seek": 113482, "start": 1135.82, "end": 1142.82, "text": " the get-txt, intl, api's work, you can sort of have some subsets of this working but if", "tokens": [50414, 264, 483, 12, 83, 734, 11, 560, 75, 11, 1882, 72, 311, 589, 11, 291, 393, 1333, 295, 362, 512, 2090, 1385, 295, 341, 1364, 457, 498, 50764], "temperature": 0.0, "avg_logprob": -0.35779027585630063, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.01825670152902603}, {"id": 219, "seek": 113482, "start": 1142.82, "end": 1149.4199999999998, "text": " you really try hard, it's a total mess and it just basically doesn't work and so that's", "tokens": [50764, 291, 534, 853, 1152, 11, 309, 311, 257, 3217, 2082, 293, 309, 445, 1936, 1177, 380, 589, 293, 370, 300, 311, 51094], "temperature": 0.0, "avg_logprob": -0.35779027585630063, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.01825670152902603}, {"id": 220, "seek": 113482, "start": 1149.4199999999998, "end": 1156.4199999999998, "text": " a real problem really and we'd have to really redesign some of this to support all of these", "tokens": [51094, 257, 957, 1154, 534, 293, 321, 1116, 362, 281, 534, 39853, 512, 295, 341, 281, 1406, 439, 295, 613, 51444], "temperature": 0.0, "avg_logprob": -0.35779027585630063, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.01825670152902603}, {"id": 221, "seek": 113482, "start": 1157.1799999999998, "end": 1162.4199999999998, "text": " combinations, yeah.", "tokens": [51482, 21267, 11, 1338, 13, 51744], "temperature": 0.0, "avg_logprob": -0.35779027585630063, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.01825670152902603}, {"id": 222, "seek": 116242, "start": 1162.42, "end": 1169.42, "text": " So the tools, well the tools are fine, they're actually quite cool and get-txt has some", "tokens": [50364, 407, 264, 3873, 11, 731, 264, 3873, 366, 2489, 11, 436, 434, 767, 1596, 1627, 293, 483, 12, 83, 734, 575, 512, 50714], "temperature": 0.0, "avg_logprob": -0.22604272676550824, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.012814714573323727}, {"id": 223, "seek": 116242, "start": 1170.8200000000002, "end": 1176.1000000000001, "text": " internal sort of optimizations that are quite interesting, has like sort of internal parallelization", "tokens": [50784, 6920, 1333, 295, 5028, 14455, 300, 366, 1596, 1880, 11, 575, 411, 1333, 295, 6920, 8952, 2144, 51048], "temperature": 0.0, "avg_logprob": -0.22604272676550824, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.012814714573323727}, {"id": 224, "seek": 116242, "start": 1176.1000000000001, "end": 1181.66, "text": " and stuff like that so work has been done but I still find it quite slow, you know, even", "tokens": [51048, 293, 1507, 411, 300, 370, 589, 575, 668, 1096, 457, 286, 920, 915, 309, 1596, 2964, 11, 291, 458, 11, 754, 51326], "temperature": 0.0, "avg_logprob": -0.22604272676550824, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.012814714573323727}, {"id": 225, "seek": 116242, "start": 1181.66, "end": 1188.18, "text": " on our scale, I'm interested to see what the KDE report is going to be later, how they", "tokens": [51326, 322, 527, 4373, 11, 286, 478, 3102, 281, 536, 437, 264, 591, 22296, 2275, 307, 516, 281, 312, 1780, 11, 577, 436, 51652], "temperature": 0.0, "avg_logprob": -0.22604272676550824, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.012814714573323727}, {"id": 226, "seek": 118818, "start": 1188.26, "end": 1192.8200000000002, "text": " handle that but it is still quite slow, right, this sort of website thing I showed, if you", "tokens": [50368, 4813, 300, 457, 309, 307, 920, 1596, 2964, 11, 558, 11, 341, 1333, 295, 3144, 551, 286, 4712, 11, 498, 291, 50596], "temperature": 0.0, "avg_logprob": -0.20595106786611128, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.07259926199913025}, {"id": 227, "seek": 118818, "start": 1192.8200000000002, "end": 1197.38, "text": " just do a full rebuild of that, it takes like 20 minutes or something, right, just to re-merge", "tokens": [50596, 445, 360, 257, 1577, 16877, 295, 300, 11, 309, 2516, 411, 945, 2077, 420, 746, 11, 558, 11, 445, 281, 319, 12, 936, 432, 50824], "temperature": 0.0, "avg_logprob": -0.20595106786611128, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.07259926199913025}, {"id": 228, "seek": 118818, "start": 1197.38, "end": 1204.38, "text": " and re-extract and recombine everything so also the format, the PO format is sort of pre-source", "tokens": [50824, 293, 319, 12, 3828, 1897, 293, 850, 3548, 533, 1203, 370, 611, 264, 7877, 11, 264, 22299, 7877, 307, 1333, 295, 659, 12, 41676, 51174], "temperature": 0.0, "avg_logprob": -0.20595106786611128, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.07259926199913025}, {"id": 229, "seek": 118818, "start": 1211.0600000000002, "end": 1216.8600000000001, "text": " control I find because it has all these dates and timestamps in it which you don't need", "tokens": [51508, 1969, 286, 915, 570, 309, 575, 439, 613, 11691, 293, 49108, 23150, 294, 309, 597, 291, 500, 380, 643, 51798], "temperature": 0.0, "avg_logprob": -0.20595106786611128, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.07259926199913025}, {"id": 230, "seek": 121686, "start": 1216.9399999999998, "end": 1220.9399999999998, "text": " because you have it in your source control management but these, hello.", "tokens": [50368, 570, 291, 362, 309, 294, 428, 4009, 1969, 4592, 457, 613, 11, 7751, 13, 50568], "temperature": 0.0, "avg_logprob": -0.3029282289392808, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.002670948626473546}, {"id": 231, "seek": 121686, "start": 1220.9399999999998, "end": 1225.9399999999998, "text": " Can you be more explicit under 10 minutes, what do you do in these 20 minutes because", "tokens": [50568, 1664, 291, 312, 544, 13691, 833, 1266, 2077, 11, 437, 360, 291, 360, 294, 613, 945, 2077, 570, 50818], "temperature": 0.0, "avg_logprob": -0.3029282289392808, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.002670948626473546}, {"id": 232, "seek": 121686, "start": 1225.9399999999998, "end": 1232.9399999999998, "text": " it sounds very slow? Well it runs a loop, it extracts, runs x get-txt over the source", "tokens": [50818, 309, 3263, 588, 2964, 30, 1042, 309, 6676, 257, 6367, 11, 309, 8947, 82, 11, 6676, 2031, 483, 12, 83, 734, 670, 264, 4009, 51168], "temperature": 0.0, "avg_logprob": -0.3029282289392808, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.002670948626473546}, {"id": 233, "seek": 121686, "start": 1235.02, "end": 1242.02, "text": " code and then it runs message merge against all these catalogs which are, you know, sort", "tokens": [51272, 3089, 293, 550, 309, 6676, 3636, 22183, 1970, 439, 613, 19746, 82, 597, 366, 11, 291, 458, 11, 1333, 51622], "temperature": 0.0, "avg_logprob": -0.3029282289392808, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.002670948626473546}, {"id": 234, "seek": 124202, "start": 1243.02, "end": 1250.02, "text": " of this many by that many times that many branches and you run that on just a machine,", "tokens": [50414, 295, 341, 867, 538, 300, 867, 1413, 300, 867, 14770, 293, 291, 1190, 300, 322, 445, 257, 3479, 11, 50764], "temperature": 0.0, "avg_logprob": -0.2040603553855812, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.003375478321686387}, {"id": 235, "seek": 124202, "start": 1254.26, "end": 1260.02, "text": " right, so, I mean you could optimize this by maybe a beefier machine and you can probably", "tokens": [50976, 558, 11, 370, 11, 286, 914, 291, 727, 19719, 341, 538, 1310, 257, 9256, 811, 3479, 293, 291, 393, 1391, 51264], "temperature": 0.0, "avg_logprob": -0.2040603553855812, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.003375478321686387}, {"id": 236, "seek": 124202, "start": 1260.02, "end": 1264.74, "text": " parallelize this a little bit but it's still, you know, the main message catalog for the", "tokens": [51264, 8952, 1125, 341, 257, 707, 857, 457, 309, 311, 920, 11, 291, 458, 11, 264, 2135, 3636, 19746, 337, 264, 51500], "temperature": 0.0, "avg_logprob": -0.2040603553855812, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.003375478321686387}, {"id": 237, "seek": 124202, "start": 1264.74, "end": 1271.74, "text": " actual server has like, you know, 5000 strings and that is still going to run like, I don't", "tokens": [51500, 3539, 7154, 575, 411, 11, 291, 458, 11, 23777, 13985, 293, 300, 307, 920, 516, 281, 1190, 411, 11, 286, 500, 380, 51850], "temperature": 0.0, "avg_logprob": -0.2040603553855812, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.003375478321686387}, {"id": 238, "seek": 127174, "start": 1271.82, "end": 1277.94, "text": " really know why but it runs like a couple of minutes, right, so it just, it's not, we're", "tokens": [50368, 534, 458, 983, 457, 309, 6676, 411, 257, 1916, 295, 2077, 11, 558, 11, 370, 309, 445, 11, 309, 311, 406, 11, 321, 434, 50674], "temperature": 0.0, "avg_logprob": -0.20030047529834813, "compression_ratio": 1.7598425196850394, "no_speech_prob": 0.0021821828559041023}, {"id": 239, "seek": 127174, "start": 1277.94, "end": 1284.94, "text": " doing this build system work now, right, when we go from make to mace on a ninja because", "tokens": [50674, 884, 341, 1322, 1185, 589, 586, 11, 558, 11, 562, 321, 352, 490, 652, 281, 275, 617, 322, 257, 31604, 570, 51024], "temperature": 0.0, "avg_logprob": -0.20030047529834813, "compression_ratio": 1.7598425196850394, "no_speech_prob": 0.0021821828559041023}, {"id": 240, "seek": 127174, "start": 1286.1, "end": 1290.98, "text": " make is too slow even if you don't have to do anything, right, so we're trying to sort", "tokens": [51082, 652, 307, 886, 2964, 754, 498, 291, 500, 380, 362, 281, 360, 1340, 11, 558, 11, 370, 321, 434, 1382, 281, 1333, 51326], "temperature": 0.0, "avg_logprob": -0.20030047529834813, "compression_ratio": 1.7598425196850394, "no_speech_prob": 0.0021821828559041023}, {"id": 241, "seek": 127174, "start": 1290.98, "end": 1295.38, "text": " of go from, I can rebuild everything in five seconds to two seconds and this thing takes", "tokens": [51326, 295, 352, 490, 11, 286, 393, 16877, 1203, 294, 1732, 3949, 281, 732, 3949, 293, 341, 551, 2516, 51546], "temperature": 0.0, "avg_logprob": -0.20030047529834813, "compression_ratio": 1.7598425196850394, "no_speech_prob": 0.0021821828559041023}, {"id": 242, "seek": 127174, "start": 1295.38, "end": 1301.42, "text": " like 10 minutes so that's just kind of annoying, right, yeah and I mentioned sort of the back", "tokens": [51546, 411, 1266, 2077, 370, 300, 311, 445, 733, 295, 11304, 11, 558, 11, 1338, 293, 286, 2835, 1333, 295, 264, 646, 51848], "temperature": 0.0, "avg_logprob": -0.20030047529834813, "compression_ratio": 1.7598425196850394, "no_speech_prob": 0.0021821828559041023}, {"id": 243, "seek": 130142, "start": 1301.46, "end": 1308.46, "text": " patching, sort of, you, often times what happens is that there's like a bug fix, right, and", "tokens": [50366, 9972, 278, 11, 1333, 295, 11, 291, 11, 2049, 1413, 437, 2314, 307, 300, 456, 311, 411, 257, 7426, 3191, 11, 558, 11, 293, 50716], "temperature": 0.0, "avg_logprob": -0.22533525972284824, "compression_ratio": 1.891213389121339, "no_speech_prob": 0.004197879694402218}, {"id": 244, "seek": 130142, "start": 1309.6200000000001, "end": 1314.46, "text": " because of the bug fix there's a new, a message changes when one new one is added and then,", "tokens": [50774, 570, 295, 264, 7426, 3191, 456, 311, 257, 777, 11, 257, 3636, 2962, 562, 472, 777, 472, 307, 3869, 293, 550, 11, 51016], "temperature": 0.0, "avg_logprob": -0.22533525972284824, "compression_ratio": 1.891213389121339, "no_speech_prob": 0.004197879694402218}, {"id": 245, "seek": 130142, "start": 1314.46, "end": 1321.46, "text": " so that then pops up in your website but then it gets backpatched, the same bug fix gets", "tokens": [51016, 370, 300, 550, 16795, 493, 294, 428, 3144, 457, 550, 309, 2170, 646, 79, 24102, 11, 264, 912, 7426, 3191, 2170, 51366], "temperature": 0.0, "avg_logprob": -0.22533525972284824, "compression_ratio": 1.891213389121339, "no_speech_prob": 0.004197879694402218}, {"id": 246, "seek": 130142, "start": 1322.0600000000002, "end": 1326.02, "text": " backpatched so the same message has to then also be updated in the back branches so you", "tokens": [51396, 646, 79, 24102, 370, 264, 912, 3636, 575, 281, 550, 611, 312, 10588, 294, 264, 646, 14770, 370, 291, 51594], "temperature": 0.0, "avg_logprob": -0.22533525972284824, "compression_ratio": 1.891213389121339, "no_speech_prob": 0.004197879694402218}, {"id": 247, "seek": 130142, "start": 1326.02, "end": 1330.94, "text": " just kind of have to like download this, upload this, then it gets added to the translation", "tokens": [51594, 445, 733, 295, 362, 281, 411, 5484, 341, 11, 6580, 341, 11, 550, 309, 2170, 3869, 281, 264, 12853, 51840], "temperature": 0.0, "avg_logprob": -0.22533525972284824, "compression_ratio": 1.891213389121339, "no_speech_prob": 0.004197879694402218}, {"id": 248, "seek": 133094, "start": 1330.98, "end": 1334.22, "text": " memory, then you can do this, I have a bunch of shell scripts to kind of make this work,", "tokens": [50366, 4675, 11, 550, 291, 393, 360, 341, 11, 286, 362, 257, 3840, 295, 8720, 23294, 281, 733, 295, 652, 341, 589, 11, 50528], "temperature": 0.0, "avg_logprob": -0.20046661895455667, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00211542216129601}, {"id": 249, "seek": 133094, "start": 1334.22, "end": 1341.22, "text": " it's just all, could be better, right, so a lot of people know this chart here, you", "tokens": [50528, 309, 311, 445, 439, 11, 727, 312, 1101, 11, 558, 11, 370, 257, 688, 295, 561, 458, 341, 6927, 510, 11, 291, 50878], "temperature": 0.0, "avg_logprob": -0.20046661895455667, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00211542216129601}, {"id": 250, "seek": 133094, "start": 1347.18, "end": 1354.18, "text": " know, so, you know, some of the projects that we know, you know, maybe Postgres is somewhere", "tokens": [51176, 458, 11, 370, 11, 291, 458, 11, 512, 295, 264, 4455, 300, 321, 458, 11, 291, 458, 11, 1310, 10223, 45189, 307, 4079, 51526], "temperature": 0.0, "avg_logprob": -0.20046661895455667, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00211542216129601}, {"id": 251, "seek": 133094, "start": 1354.18, "end": 1358.74, "text": " in here, KDE, LibreOffice, they're all pretty good but then there's, you know, maybe things", "tokens": [51526, 294, 510, 11, 591, 22296, 11, 15834, 265, 29745, 573, 11, 436, 434, 439, 1238, 665, 457, 550, 456, 311, 11, 291, 458, 11, 1310, 721, 51754], "temperature": 0.0, "avg_logprob": -0.20046661895455667, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00211542216129601}, {"id": 252, "seek": 135874, "start": 1358.78, "end": 1365.78, "text": " like that down here that everybody builds on but they're sort of maintained by a few", "tokens": [50366, 411, 300, 760, 510, 300, 2201, 15182, 322, 457, 436, 434, 1333, 295, 17578, 538, 257, 1326, 50716], "temperature": 0.0, "avg_logprob": -0.2368960477867905, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.002472053747624159}, {"id": 253, "seek": 135874, "start": 1366.5, "end": 1372.98, "text": " people in there, sort of, on the side, right, and this way, I mean, this is sort of a general", "tokens": [50752, 561, 294, 456, 11, 1333, 295, 11, 322, 264, 1252, 11, 558, 11, 293, 341, 636, 11, 286, 914, 11, 341, 307, 1333, 295, 257, 2674, 51076], "temperature": 0.0, "avg_logprob": -0.2368960477867905, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.002472053747624159}, {"id": 254, "seek": 135874, "start": 1372.98, "end": 1379.98, "text": " problem, I gave the same, I gave a talk, it was the online one two years ago about the", "tokens": [51076, 1154, 11, 286, 2729, 264, 912, 11, 286, 2729, 257, 751, 11, 309, 390, 264, 2950, 472, 732, 924, 2057, 466, 264, 51426], "temperature": 0.0, "avg_logprob": -0.2368960477867905, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.002472053747624159}, {"id": 255, "seek": 135874, "start": 1380.22, "end": 1387.22, "text": " documentation, Choolchain, Postgres, it's the same problem, right, we have, you know,", "tokens": [51438, 14333, 11, 761, 1092, 11509, 11, 10223, 45189, 11, 309, 311, 264, 912, 1154, 11, 558, 11, 321, 362, 11, 291, 458, 11, 51788], "temperature": 0.0, "avg_logprob": -0.2368960477867905, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.002472053747624159}, {"id": 256, "seek": 138722, "start": 1387.3, "end": 1390.38, "text": " open source, everything's very successful but then there's like these little tools you", "tokens": [50368, 1269, 4009, 11, 1203, 311, 588, 4406, 457, 550, 456, 311, 411, 613, 707, 3873, 291, 50522], "temperature": 0.0, "avg_logprob": -0.17022708424350672, "compression_ratio": 1.8070866141732282, "no_speech_prob": 0.004608679097145796}, {"id": 257, "seek": 138722, "start": 1390.38, "end": 1397.38, "text": " need just to make your build run, right, and then there's, they don't have the same necessarily", "tokens": [50522, 643, 445, 281, 652, 428, 1322, 1190, 11, 558, 11, 293, 550, 456, 311, 11, 436, 500, 380, 362, 264, 912, 4725, 50872], "temperature": 0.0, "avg_logprob": -0.17022708424350672, "compression_ratio": 1.8070866141732282, "no_speech_prob": 0.004608679097145796}, {"id": 258, "seek": 138722, "start": 1397.58, "end": 1401.34, "text": " amount of staffing and funding and things like that but you still kind of rely on them and", "tokens": [50882, 2372, 295, 38918, 293, 6137, 293, 721, 411, 300, 457, 291, 920, 733, 295, 10687, 322, 552, 293, 51070], "temperature": 0.0, "avg_logprob": -0.17022708424350672, "compression_ratio": 1.8070866141732282, "no_speech_prob": 0.004608679097145796}, {"id": 259, "seek": 138722, "start": 1401.34, "end": 1408.34, "text": " they just barely sort of chug along, so that's a sort of general concern, right, but it applies", "tokens": [51070, 436, 445, 10268, 1333, 295, 417, 697, 2051, 11, 370, 300, 311, 257, 1333, 295, 2674, 3136, 11, 558, 11, 457, 309, 13165, 51420], "temperature": 0.0, "avg_logprob": -0.17022708424350672, "compression_ratio": 1.8070866141732282, "no_speech_prob": 0.004608679097145796}, {"id": 260, "seek": 138722, "start": 1408.34, "end": 1415.34, "text": " here, right, so what are we doing, what are we planning to do, I mentioned in the middle,", "tokens": [51420, 510, 11, 558, 11, 370, 437, 366, 321, 884, 11, 437, 366, 321, 5038, 281, 360, 11, 286, 2835, 294, 264, 2808, 11, 51770], "temperature": 0.0, "avg_logprob": -0.17022708424350672, "compression_ratio": 1.8070866141732282, "no_speech_prob": 0.004608679097145796}, {"id": 261, "seek": 141534, "start": 1416.06, "end": 1423.06, "text": " right now we're sort of redoing our build system, that is kind of a good reason to", "tokens": [50400, 558, 586, 321, 434, 1333, 295, 29956, 278, 527, 1322, 1185, 11, 300, 307, 733, 295, 257, 665, 1778, 281, 50750], "temperature": 0.0, "avg_logprob": -0.15992836518721146, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.002550126053392887}, {"id": 262, "seek": 141534, "start": 1424.26, "end": 1428.3, "text": " clean up some of that old stuff that we don't need anymore. We're also moving more to using", "tokens": [50810, 2541, 493, 512, 295, 300, 1331, 1507, 300, 321, 500, 380, 643, 3602, 13, 492, 434, 611, 2684, 544, 281, 1228, 51012], "temperature": 0.0, "avg_logprob": -0.15992836518721146, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.002550126053392887}, {"id": 263, "seek": 141534, "start": 1428.3, "end": 1435.3, "text": " ICU which is, you know, an internationalization library that does lots of good things but", "tokens": [51012, 38123, 597, 307, 11, 291, 458, 11, 364, 5058, 2144, 6405, 300, 775, 3195, 295, 665, 721, 457, 51362], "temperature": 0.0, "avg_logprob": -0.15992836518721146, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.002550126053392887}, {"id": 264, "seek": 141534, "start": 1436.3, "end": 1441.82, "text": " then adds another dimension to this issue of, you know, locale encoding and then there's", "tokens": [51412, 550, 10860, 1071, 10139, 281, 341, 2734, 295, 11, 291, 458, 11, 1628, 1220, 43430, 293, 550, 456, 311, 51688], "temperature": 0.0, "avg_logprob": -0.15992836518721146, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.002550126053392887}, {"id": 265, "seek": 144182, "start": 1441.86, "end": 1446.58, "text": " sort of another dimension of what ICU thinks the current locale encoding is, it just gets", "tokens": [50366, 1333, 295, 1071, 10139, 295, 437, 38123, 7309, 264, 2190, 1628, 1220, 43430, 307, 11, 309, 445, 2170, 50602], "temperature": 0.0, "avg_logprob": -0.16258632219754732, "compression_ratio": 1.75390625, "no_speech_prob": 0.0020502859260886908}, {"id": 266, "seek": 144182, "start": 1446.58, "end": 1453.1799999999998, "text": " ever more messy and complicated and then one sort of important issue in databases is the", "tokens": [50602, 1562, 544, 16191, 293, 6179, 293, 550, 472, 1333, 295, 1021, 2734, 294, 22380, 307, 264, 50932], "temperature": 0.0, "avg_logprob": -0.16258632219754732, "compression_ratio": 1.75390625, "no_speech_prob": 0.0020502859260886908}, {"id": 267, "seek": 144182, "start": 1453.1799999999998, "end": 1457.1, "text": " sort order, right, a lot of people care about that, what the sort order of your data is", "tokens": [50932, 1333, 1668, 11, 558, 11, 257, 688, 295, 561, 1127, 466, 300, 11, 437, 264, 1333, 1668, 295, 428, 1412, 307, 51128], "temperature": 0.0, "avg_logprob": -0.16258632219754732, "compression_ratio": 1.75390625, "no_speech_prob": 0.0020502859260886908}, {"id": 268, "seek": 144182, "start": 1457.1, "end": 1464.1, "text": " and different collisions have to be supported and that's another kind of sort of localization", "tokens": [51128, 293, 819, 46537, 362, 281, 312, 8104, 293, 300, 311, 1071, 733, 295, 1333, 295, 2654, 2144, 51478], "temperature": 0.0, "avg_logprob": -0.16258632219754732, "compression_ratio": 1.75390625, "no_speech_prob": 0.0020502859260886908}, {"id": 269, "seek": 144182, "start": 1464.3, "end": 1469.74, "text": " kind of work we do but all of this is sort of weirdly connected, right, if you configure", "tokens": [51488, 733, 295, 589, 321, 360, 457, 439, 295, 341, 307, 1333, 295, 48931, 4582, 11, 558, 11, 498, 291, 22162, 51760], "temperature": 0.0, "avg_logprob": -0.16258632219754732, "compression_ratio": 1.75390625, "no_speech_prob": 0.0020502859260886908}, {"id": 270, "seek": 146974, "start": 1469.74, "end": 1473.5, "text": " one part of the system to be in this language then all of a sudden get text also thinks", "tokens": [50364, 472, 644, 295, 264, 1185, 281, 312, 294, 341, 2856, 550, 439, 295, 257, 3990, 483, 2487, 611, 7309, 50552], "temperature": 0.0, "avg_logprob": -0.1950275526134246, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.004537047352641821}, {"id": 271, "seek": 146974, "start": 1473.5, "end": 1477.7, "text": " it's the same but maybe you don't even want that, right, you might want your error messages", "tokens": [50552, 309, 311, 264, 912, 457, 1310, 291, 500, 380, 754, 528, 300, 11, 558, 11, 291, 1062, 528, 428, 6713, 7897, 50762], "temperature": 0.0, "avg_logprob": -0.1950275526134246, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.004537047352641821}, {"id": 272, "seek": 146974, "start": 1477.7, "end": 1483.86, "text": " in French but you want to sort something in Swedish, right, why not, right, but because", "tokens": [50762, 294, 5522, 457, 291, 528, 281, 1333, 746, 294, 23523, 11, 558, 11, 983, 406, 11, 558, 11, 457, 570, 51070], "temperature": 0.0, "avg_logprob": -0.1950275526134246, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.004537047352641821}, {"id": 273, "seek": 146974, "start": 1483.86, "end": 1490.86, "text": " of these APIs the way they're historically built it just doesn't quite work smoothly.", "tokens": [51070, 295, 613, 21445, 264, 636, 436, 434, 16180, 3094, 309, 445, 1177, 380, 1596, 589, 19565, 13, 51420], "temperature": 0.0, "avg_logprob": -0.1950275526134246, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.004537047352641821}, {"id": 274, "seek": 146974, "start": 1492.86, "end": 1499.06, "text": " But again we want to modernize the workflows, again maybe Weblate, I heard Omega T here", "tokens": [51520, 583, 797, 321, 528, 281, 4363, 1125, 264, 43461, 11, 797, 1310, 9573, 17593, 11, 286, 2198, 27645, 314, 510, 51830], "temperature": 0.0, "avg_logprob": -0.1950275526134246, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.004537047352641821}, {"id": 275, "seek": 149906, "start": 1499.06, "end": 1506.06, "text": " also this weekend and there's crowd in but the issue I had, I mean I heard of Weblate", "tokens": [50364, 611, 341, 6711, 293, 456, 311, 6919, 294, 457, 264, 2734, 286, 632, 11, 286, 914, 286, 2198, 295, 9573, 17593, 50714], "temperature": 0.0, "avg_logprob": -0.19394087236981059, "compression_ratio": 1.6411483253588517, "no_speech_prob": 0.004194784909486771}, {"id": 276, "seek": 149906, "start": 1508.34, "end": 1513.6599999999999, "text": " some years ago too but again the issue is sort of we can't just adopt like the hottest", "tokens": [50828, 512, 924, 2057, 886, 457, 797, 264, 2734, 307, 1333, 295, 321, 393, 380, 445, 6878, 411, 264, 32780, 51094], "temperature": 0.0, "avg_logprob": -0.19394087236981059, "compression_ratio": 1.6411483253588517, "no_speech_prob": 0.004194784909486771}, {"id": 277, "seek": 149906, "start": 1513.6599999999999, "end": 1517.74, "text": " new thing, right, because again whatever, the way I always think about it is whatever", "tokens": [51094, 777, 551, 11, 558, 11, 570, 797, 2035, 11, 264, 636, 286, 1009, 519, 466, 309, 307, 2035, 51298], "temperature": 0.0, "avg_logprob": -0.19394087236981059, "compression_ratio": 1.6411483253588517, "no_speech_prob": 0.004194784909486771}, {"id": 278, "seek": 149906, "start": 1517.74, "end": 1523.98, "text": " I sort of do today in Postgres, write some piece of code or make some infrastructure", "tokens": [51298, 286, 1333, 295, 360, 965, 294, 10223, 45189, 11, 2464, 512, 2522, 295, 3089, 420, 652, 512, 6896, 51610], "temperature": 0.0, "avg_logprob": -0.19394087236981059, "compression_ratio": 1.6411483253588517, "no_speech_prob": 0.004194784909486771}, {"id": 279, "seek": 152398, "start": 1523.98, "end": 1529.38, "text": " change still has to work in 10 years, right, and it doesn't meaning it also has to like", "tokens": [50364, 1319, 920, 575, 281, 589, 294, 1266, 924, 11, 558, 11, 293, 309, 1177, 380, 3620, 309, 611, 575, 281, 411, 50634], "temperature": 0.0, "avg_logprob": -0.16022360428519872, "compression_ratio": 1.7509881422924902, "no_speech_prob": 0.08875227719545364}, {"id": 280, "seek": 152398, "start": 1529.38, "end": 1532.66, "text": " build from source, right, because that's the way open source works, right, so I can't", "tokens": [50634, 1322, 490, 4009, 11, 558, 11, 570, 300, 311, 264, 636, 1269, 4009, 1985, 11, 558, 11, 370, 286, 393, 380, 50798], "temperature": 0.0, "avg_logprob": -0.16022360428519872, "compression_ratio": 1.7509881422924902, "no_speech_prob": 0.08875227719545364}, {"id": 281, "seek": 152398, "start": 1532.66, "end": 1537.7, "text": " just use a tool that was just invented yesterday and I don't know if it's still going to be", "tokens": [50798, 445, 764, 257, 2290, 300, 390, 445, 14479, 5186, 293, 286, 500, 380, 458, 498, 309, 311, 920, 516, 281, 312, 51050], "temperature": 0.0, "avg_logprob": -0.16022360428519872, "compression_ratio": 1.7509881422924902, "no_speech_prob": 0.08875227719545364}, {"id": 282, "seek": 152398, "start": 1537.7, "end": 1542.5, "text": " here in two years, now they mentioned Weblate is 11 years old so that's pretty good, so", "tokens": [51050, 510, 294, 732, 924, 11, 586, 436, 2835, 9573, 17593, 307, 2975, 924, 1331, 370, 300, 311, 1238, 665, 11, 370, 51290], "temperature": 0.0, "avg_logprob": -0.16022360428519872, "compression_ratio": 1.7509881422924902, "no_speech_prob": 0.08875227719545364}, {"id": 283, "seek": 152398, "start": 1542.5, "end": 1549.66, "text": " I think we can maybe look into that, right, so this is something maybe a question anybody", "tokens": [51290, 286, 519, 321, 393, 1310, 574, 666, 300, 11, 558, 11, 370, 341, 307, 746, 1310, 257, 1168, 4472, 51648], "temperature": 0.0, "avg_logprob": -0.16022360428519872, "compression_ratio": 1.7509881422924902, "no_speech_prob": 0.08875227719545364}, {"id": 284, "seek": 154966, "start": 1549.74, "end": 1554.14, "text": " knows, is Getex still the thing or is there something totally different that everybody", "tokens": [50368, 3255, 11, 307, 3240, 3121, 920, 264, 551, 420, 307, 456, 746, 3879, 819, 300, 2201, 50588], "temperature": 0.0, "avg_logprob": -0.24644509383610316, "compression_ratio": 1.825, "no_speech_prob": 0.14774133265018463}, {"id": 285, "seek": 154966, "start": 1554.14, "end": 1559.38, "text": " should be using now, it's part of sort of the low level API of how this works, I don't", "tokens": [50588, 820, 312, 1228, 586, 11, 309, 311, 644, 295, 1333, 295, 264, 2295, 1496, 9362, 295, 577, 341, 1985, 11, 286, 500, 380, 50850], "temperature": 0.0, "avg_logprob": -0.24644509383610316, "compression_ratio": 1.825, "no_speech_prob": 0.14774133265018463}, {"id": 286, "seek": 154966, "start": 1559.38, "end": 1566.38, "text": " know, I was sort of half hoping that from the ICU ecosystem something would be evolving", "tokens": [50850, 458, 11, 286, 390, 1333, 295, 1922, 7159, 300, 490, 264, 38123, 11311, 746, 576, 312, 21085, 51200], "temperature": 0.0, "avg_logprob": -0.24644509383610316, "compression_ratio": 1.825, "no_speech_prob": 0.14774133265018463}, {"id": 287, "seek": 154966, "start": 1566.6200000000001, "end": 1569.42, "text": " or it's sort of emerging but I haven't seen anything like that so I don't know if there's", "tokens": [51212, 420, 309, 311, 1333, 295, 14989, 457, 286, 2378, 380, 1612, 1340, 411, 300, 370, 286, 500, 380, 458, 498, 456, 311, 51352], "temperature": 0.0, "avg_logprob": -0.24644509383610316, "compression_ratio": 1.825, "no_speech_prob": 0.14774133265018463}, {"id": 288, "seek": 154966, "start": 1569.42, "end": 1576.5400000000002, "text": " anything or is this still the thing to use, I don't know, so maybe somebody has a, yes", "tokens": [51352, 1340, 420, 307, 341, 920, 264, 551, 281, 764, 11, 286, 500, 380, 458, 11, 370, 1310, 2618, 575, 257, 11, 2086, 51708], "temperature": 0.0, "avg_logprob": -0.24644509383610316, "compression_ratio": 1.825, "no_speech_prob": 0.14774133265018463}, {"id": 289, "seek": 157654, "start": 1576.62, "end": 1577.62, "text": " please.", "tokens": [50368, 1767, 13, 50418], "temperature": 0.0, "avg_logprob": -0.2961406707763672, "compression_ratio": 1.7, "no_speech_prob": 0.3278569281101227}, {"id": 290, "seek": 157654, "start": 1577.62, "end": 1584.62, "text": " The ICU upcoming solution is message format 2, it's currently in the ICU for J72 that", "tokens": [50418, 440, 38123, 11500, 3827, 307, 3636, 7877, 568, 11, 309, 311, 4362, 294, 264, 38123, 337, 508, 28890, 300, 50768], "temperature": 0.0, "avg_logprob": -0.2961406707763672, "compression_ratio": 1.7, "no_speech_prob": 0.3278569281101227}, {"id": 291, "seek": 157654, "start": 1586.18, "end": 1591.3799999999999, "text": " came out in October, it's an attack preview there but it's going to progress from there,", "tokens": [50846, 1361, 484, 294, 7617, 11, 309, 311, 364, 2690, 14281, 456, 457, 309, 311, 516, 281, 4205, 490, 456, 11, 51106], "temperature": 0.0, "avg_logprob": -0.2961406707763672, "compression_ratio": 1.7, "no_speech_prob": 0.3278569281101227}, {"id": 292, "seek": 157654, "start": 1591.3799999999999, "end": 1598.3799999999999, "text": " it's not yet in ICU for C, it's effectively, message format 2 is a new message format in", "tokens": [51106, 309, 311, 406, 1939, 294, 38123, 337, 383, 11, 309, 311, 8659, 11, 3636, 7877, 568, 307, 257, 777, 3636, 7877, 294, 51456], "temperature": 0.0, "avg_logprob": -0.2961406707763672, "compression_ratio": 1.7, "no_speech_prob": 0.3278569281101227}, {"id": 293, "seek": 157654, "start": 1599.02, "end": 1606.02, "text": " syntax, the resource level syntax for that is a little bit more still in progress but", "tokens": [51488, 28431, 11, 264, 7684, 1496, 28431, 337, 300, 307, 257, 707, 857, 544, 920, 294, 4205, 457, 51838], "temperature": 0.0, "avg_logprob": -0.2961406707763672, "compression_ratio": 1.7, "no_speech_prob": 0.3278569281101227}, {"id": 294, "seek": 160602, "start": 1606.18, "end": 1613.18, "text": " if you move into more of an ICU world that's likely going to provide a decent future thing", "tokens": [50372, 498, 291, 1286, 666, 544, 295, 364, 38123, 1002, 300, 311, 3700, 516, 281, 2893, 257, 8681, 2027, 551, 50722], "temperature": 0.0, "avg_logprob": -0.25623547646307177, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.0035822875797748566}, {"id": 295, "seek": 160602, "start": 1613.94, "end": 1619.94, "text": " for you to migrate to from Getex, it's not that yet but it's becoming that.", "tokens": [50760, 337, 291, 281, 31821, 281, 490, 3240, 3121, 11, 309, 311, 406, 300, 1939, 457, 309, 311, 5617, 300, 13, 51060], "temperature": 0.0, "avg_logprob": -0.25623547646307177, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.0035822875797748566}, {"id": 296, "seek": 160602, "start": 1619.94, "end": 1626.94, "text": " That is excellent news, thank you, I'll definitely look into that.", "tokens": [51060, 663, 307, 7103, 2583, 11, 1309, 291, 11, 286, 603, 2138, 574, 666, 300, 13, 51410], "temperature": 0.0, "avg_logprob": -0.25623547646307177, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.0035822875797748566}, {"id": 297, "seek": 162694, "start": 1626.94, "end": 1633.94, "text": " WebLate is adopting that as well or supporting that, it's more compatible, it seems like", "tokens": [50364, 9573, 43, 473, 307, 32328, 300, 382, 731, 420, 7231, 300, 11, 309, 311, 544, 18218, 11, 309, 2544, 411, 50714], "temperature": 0.0, "avg_logprob": -0.37275980520939483, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.020612601190805435}, {"id": 298, "seek": 162694, "start": 1638.02, "end": 1645.02, "text": " it supported a bunch of things, so yeah this is wonderful, useful information we can like.", "tokens": [50918, 309, 8104, 257, 3840, 295, 721, 11, 370, 1338, 341, 307, 3715, 11, 4420, 1589, 321, 393, 411, 13, 51268], "temperature": 0.0, "avg_logprob": -0.37275980520939483, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.020612601190805435}, {"id": 299, "seek": 162694, "start": 1649.46, "end": 1656.46, "text": " So yeah, this is good, thank you, so this is also the end of my presentation so I just", "tokens": [51490, 407, 1338, 11, 341, 307, 665, 11, 1309, 291, 11, 370, 341, 307, 611, 264, 917, 295, 452, 5860, 370, 286, 445, 51840], "temperature": 0.0, "avg_logprob": -0.37275980520939483, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.020612601190805435}, {"id": 300, "seek": 165646, "start": 1656.66, "end": 1661.3, "text": " wanted to say what we're doing and what some of the unique challenges are, got some good", "tokens": [50374, 1415, 281, 584, 437, 321, 434, 884, 293, 437, 512, 295, 264, 3845, 4759, 366, 11, 658, 512, 665, 50606], "temperature": 0.0, "avg_logprob": -0.30379763151469985, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0023145584855228662}, {"id": 301, "seek": 165646, "start": 1661.3, "end": 1668.3, "text": " feedback here, we're going to look into WebLate, we're going to look into emerging ICU things,", "tokens": [50606, 5824, 510, 11, 321, 434, 516, 281, 574, 666, 9573, 43, 473, 11, 321, 434, 516, 281, 574, 666, 14989, 38123, 721, 11, 50956], "temperature": 0.0, "avg_logprob": -0.30379763151469985, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0023145584855228662}, {"id": 302, "seek": 165646, "start": 1669.58, "end": 1675.66, "text": " update some of our infrastructure and we have a few minutes for questions, otherwise thank", "tokens": [51020, 5623, 512, 295, 527, 6896, 293, 321, 362, 257, 1326, 2077, 337, 1651, 11, 5911, 1309, 51324], "temperature": 0.0, "avg_logprob": -0.30379763151469985, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0023145584855228662}, {"id": 303, "seek": 165646, "start": 1675.66, "end": 1678.66, "text": " you very much for listening.", "tokens": [51324, 291, 588, 709, 337, 4764, 13, 51474], "temperature": 0.0, "avg_logprob": -0.30379763151469985, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0023145584855228662}, {"id": 304, "seek": 165646, "start": 1678.66, "end": 1685.66, "text": " So if you're worried about WebLate, it doesn't really matter what you're doing.", "tokens": [51474, 407, 498, 291, 434, 5804, 466, 9573, 43, 473, 11, 309, 1177, 380, 534, 1871, 437, 291, 434, 884, 13, 51824], "temperature": 0.0, "avg_logprob": -0.30379763151469985, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0023145584855228662}, {"id": 305, "seek": 168646, "start": 1686.46, "end": 1693.46, "text": " It doesn't really interact with, it doesn't go too deep in your automation system because", "tokens": [50364, 467, 1177, 380, 534, 4648, 365, 11, 309, 1177, 380, 352, 886, 2452, 294, 428, 17769, 1185, 570, 50714], "temperature": 0.0, "avg_logprob": -0.48610679308573407, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.276297926902771}, {"id": 306, "seek": 168646, "start": 1693.46, "end": 1699.46, "text": " the way you communicate with WebLate, with the world of the translators, is FICE, FICE,", "tokens": [50714, 264, 636, 291, 7890, 365, 9573, 43, 473, 11, 365, 264, 1002, 295, 264, 5105, 3391, 11, 307, 479, 13663, 11, 479, 13663, 11, 51014], "temperature": 0.0, "avg_logprob": -0.48610679308573407, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.276297926902771}, {"id": 307, "seek": 168646, "start": 1699.46, "end": 1701.46, "text": " an agreed repository.", "tokens": [51014, 364, 9166, 25841, 13, 51114], "temperature": 0.0, "avg_logprob": -0.48610679308573407, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.276297926902771}, {"id": 308, "seek": 168646, "start": 1701.46, "end": 1708.46, "text": " So whatever happens in WebLate, matching the translations and the search and the check", "tokens": [51114, 407, 2035, 2314, 294, 9573, 43, 473, 11, 14324, 264, 37578, 293, 264, 3164, 293, 264, 1520, 51464], "temperature": 0.0, "avg_logprob": -0.48610679308573407, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.276297926902771}, {"id": 309, "seek": 168646, "start": 1709.46, "end": 1714.46, "text": " and stuff, but still you as a developer interact with the FICE, so you still have control on", "tokens": [51514, 293, 1507, 11, 457, 920, 291, 382, 257, 10754, 4648, 365, 264, 479, 13663, 11, 370, 291, 920, 362, 1969, 322, 51764], "temperature": 0.0, "avg_logprob": -0.48610679308573407, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.276297926902771}, {"id": 310, "seek": 171446, "start": 1714.46, "end": 1719.46, "text": " how to build, you don't create a national dependency on your resource.", "tokens": [50364, 577, 281, 1322, 11, 291, 500, 380, 1884, 257, 4048, 33621, 322, 428, 7684, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2383450594815341, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.014691110700368881}, {"id": 311, "seek": 171446, "start": 1719.46, "end": 1721.46, "text": " Yeah, it sounds like it, yeah.", "tokens": [50614, 865, 11, 309, 3263, 411, 309, 11, 1338, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2383450594815341, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.014691110700368881}, {"id": 312, "seek": 171446, "start": 1721.46, "end": 1728.46, "text": " And get text looks like to be alive again, I think they did a release not so far away.", "tokens": [50714, 400, 483, 2487, 1542, 411, 281, 312, 5465, 797, 11, 286, 519, 436, 630, 257, 4374, 406, 370, 1400, 1314, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2383450594815341, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.014691110700368881}, {"id": 313, "seek": 171446, "start": 1728.46, "end": 1735.46, "text": " Yeah, it was kind of funny because I had submitted various bugs to savannah.new.org over the years,", "tokens": [51064, 865, 11, 309, 390, 733, 295, 4074, 570, 286, 632, 14405, 3683, 15120, 281, 11163, 15143, 13, 7686, 13, 4646, 670, 264, 924, 11, 51414], "temperature": 0.0, "avg_logprob": -0.2383450594815341, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.014691110700368881}, {"id": 314, "seek": 171446, "start": 1736.46, "end": 1743.46, "text": " also feature requests and stuff like that and just like two or three weeks ago all of these", "tokens": [51464, 611, 4111, 12475, 293, 1507, 411, 300, 293, 445, 411, 732, 420, 1045, 3259, 2057, 439, 295, 613, 51814], "temperature": 0.0, "avg_logprob": -0.2383450594815341, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.014691110700368881}, {"id": 315, "seek": 174346, "start": 1743.46, "end": 1749.46, "text": " bugs were updated and some of them closed and I was like, whoa, does somebody know that I'm going to complain about them?", "tokens": [50364, 15120, 645, 10588, 293, 512, 295, 552, 5395, 293, 286, 390, 411, 11, 13310, 11, 775, 2618, 458, 300, 286, 478, 516, 281, 11024, 466, 552, 30, 50664], "temperature": 0.0, "avg_logprob": -0.2122397630111031, "compression_ratio": 1.8754716981132076, "no_speech_prob": 0.002251297701150179}, {"id": 316, "seek": 174346, "start": 1749.46, "end": 1750.46, "text": " I trust them?", "tokens": [50664, 286, 3361, 552, 30, 50714], "temperature": 0.0, "avg_logprob": -0.2122397630111031, "compression_ratio": 1.8754716981132076, "no_speech_prob": 0.002251297701150179}, {"id": 317, "seek": 174346, "start": 1750.46, "end": 1751.46, "text": " I don't know.", "tokens": [50714, 286, 500, 380, 458, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2122397630111031, "compression_ratio": 1.8754716981132076, "no_speech_prob": 0.002251297701150179}, {"id": 318, "seek": 174346, "start": 1751.46, "end": 1756.46, "text": " Is the person here in any case, I don't know who is, no.", "tokens": [50764, 1119, 264, 954, 510, 294, 604, 1389, 11, 286, 500, 380, 458, 567, 307, 11, 572, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2122397630111031, "compression_ratio": 1.8754716981132076, "no_speech_prob": 0.002251297701150179}, {"id": 319, "seek": 174346, "start": 1756.46, "end": 1763.46, "text": " Well, I guess it's just sort of, I mean, this is a problem, I guess it is a problem in some of these people", "tokens": [51014, 1042, 11, 286, 2041, 309, 311, 445, 1333, 295, 11, 286, 914, 11, 341, 307, 257, 1154, 11, 286, 2041, 309, 307, 257, 1154, 294, 512, 295, 613, 561, 51364], "temperature": 0.0, "avg_logprob": -0.2122397630111031, "compression_ratio": 1.8754716981132076, "no_speech_prob": 0.002251297701150179}, {"id": 320, "seek": 174346, "start": 1763.46, "end": 1767.46, "text": " maintain some of these specialty new tools and some of these older tools that are sort of on maintenance.", "tokens": [51364, 6909, 512, 295, 613, 22000, 777, 3873, 293, 512, 295, 613, 4906, 3873, 300, 366, 1333, 295, 322, 11258, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2122397630111031, "compression_ratio": 1.8754716981132076, "no_speech_prob": 0.002251297701150179}, {"id": 321, "seek": 174346, "start": 1767.46, "end": 1772.46, "text": " I mean, we don't need tons of new features but you don't really know, right?", "tokens": [51564, 286, 914, 11, 321, 500, 380, 643, 9131, 295, 777, 4122, 457, 291, 500, 380, 534, 458, 11, 558, 30, 51814], "temperature": 0.0, "avg_logprob": -0.2122397630111031, "compression_ratio": 1.8754716981132076, "no_speech_prob": 0.002251297701150179}, {"id": 322, "seek": 177246, "start": 1772.46, "end": 1776.46, "text": " It could just be that that person changes job and then nothing happens again for five years, right?", "tokens": [50364, 467, 727, 445, 312, 300, 300, 954, 2962, 1691, 293, 550, 1825, 2314, 797, 337, 1732, 924, 11, 558, 30, 50564], "temperature": 0.0, "avg_logprob": -0.17219202635718173, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.005380772519856691}, {"id": 323, "seek": 177246, "start": 1776.46, "end": 1781.46, "text": " So, but, well, got some good new information here, thank you.", "tokens": [50564, 407, 11, 457, 11, 731, 11, 658, 512, 665, 777, 1589, 510, 11, 1309, 291, 13, 50814], "temperature": 0.0, "avg_logprob": -0.17219202635718173, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.005380772519856691}, {"id": 324, "seek": 177246, "start": 1781.46, "end": 1783.46, "text": " All right.", "tokens": [50814, 1057, 558, 13, 50914], "temperature": 0.0, "avg_logprob": -0.17219202635718173, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.005380772519856691}, {"id": 325, "seek": 177246, "start": 1783.46, "end": 1785.46, "text": " All right, then we'll move on to the next one.", "tokens": [50914, 1057, 558, 11, 550, 321, 603, 1286, 322, 281, 264, 958, 472, 13, 51014], "temperature": 0.0, "avg_logprob": -0.17219202635718173, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.005380772519856691}], "language": "en"}