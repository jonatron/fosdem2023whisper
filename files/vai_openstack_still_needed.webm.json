{"text": " Thank you for coming, first and quick introduction, my name is Thierry Tha\u00efd, I've been involved in a software and software project for the last three years, and today I'm working on a software and software project. I'm also the general manager for the Open Infrastructure Foundation, which is the foundation that hosts OpenStack and Curator projects in OLC. So I'm here as the vice-chair of the OpenSoft Initiative as the next project, and today I wanted to talk to you about OpenStack and its relevance today, because a lot of people are saying that OpenStack is dead. I mean, it's a fair question, right? It's been around for 13 years and nobody has much anymore and less than you mentioned, so I mean, is it dead? It could be, maybe, you know, nobody is using it anymore and nobody cares. So let's look at the data. So OpenStack, according to our latest user survey that was run in 2022, is run over a footprint of more than 40 million CPU cores of 15 hours. So that's a massive footprint. There's a lot of usage of OpenStack and a lot more people getting comfortable mentioning it. It's actually increased from 25 million to 40 million around the course of between 2021 and 2022. So it grew between 25 to 40 million CPU cores in our user survey reports between 2021 and 2022. It's happening in all verticals, so you can see the traditional OpenStack strongholds. It was originally formed by a public cloud company and a research institution. So on the public cloud side, it's still very strong with workspace being involved, but also OVH Cloud or Infomaniac or Deutsche Telecom or Leroy. All of those companies running OpenStack based public clouds. It's also strong in the research area where it started at NASA, but now it's used at CERN, it's used at Harvard, it's used at MIT, it's used at the European Center for Medium Weather Forecast, which right now has hold up, and basically that's one of the weather forecasts here. So all of those research institutions that have developed for public cloud, it's also strong in the telecom industry. It's well known that OpenStack is used there. Nine out of the ten telecom companies are actually using OpenStack as their back-end for handling everyday calls. It's also strong in retail and e-commerce with the largest company in the world, Walmart, still using it. Financial services with banks like Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or Financial Services like PayPal or China Union Bank. It's strong in energy, transportation, government manufacturing, web entertainment with one-on-one brands, Comcast, Salesforce, Adobe, Bloomberg, all the games, game servers, it's a lot of usage. It's also that those users are actually increasing their usage. We used to give stickers to companies that would reach 100,000 CPU calls, and now we have to create a new sticker because a bunch of them are actually more than one billion CPU calls, including China Mobile and China Unicom, which are the two cell-phone mobile companies in China. So that's providing basically all Chinese citizens with their users. So it definitely has usage. So why are people saying it's dead? It may be, you know, it's still working, but it's dead inside, and nobody's really developing it anymore, and has no development activity, so it moves more like it's only me or something. It's not dead, but it's almost dead. And if you look at activity, development activity, you have to compare with very well-known, very active projects like Kubernetes for example. Kubernetes is a massive, open collaboration, and I'm sure everyone in this room has heard of Kubernetes, and they have a very large, it's one of the most active business projects in the world. It has more than 33,000 Internet public requests, I mean, reviewed by Uniman and merged into the code base over the last year. It's more like one of our changed projects today, which is really massive. And if we try to see how OpenStack compares with that, OpenStack in 2022 was actually 29,000 year changes merged, the same thing for the reviewed by Uniman, and then merged into the code. And so it's definitely the same ballpark. It's definitely the same level of activity. Definitely one of the three most active open source projects out there in terms of development activity, like with the Linux kernel and Chromium. So it's not dead from the development perspective either. So why are people saying it's dead? I used to think it's because they just didn't like us. They just wanted us to feel bad and get up in the morning. But then I started thinking, like, maybe there's something else. Maybe there is a deeper reason why people think about OpenStack is dead. But then we did think about it. So why are people thinking of OpenStack is dead? We need to take a step back and look at OpenStack is strange. We need to answer that question. So let's rewind back to 2010. It might sound like yesterday, as for all those people, young people, it will be very, very near. So it might sound like yesterday, but from an open source perspective, it's actually a long time. Back in 2010, Open Source and the open source initiative has been there for 12 years. And 12 years have passed since OpenStack was created. If you look at popular projects, Firefox was eight years old when OpenStack was created. Ubuntu was six years old. Git was five years old. Android was only two and a half years old. So it's really the middle ages of Open Source. And Open Source was very successful back then. But we didn't have that much open source options for infrastructure. The infrastructure market was cornered by proprietary software. It was VMware on the private side and Amazon Web Services on the public side, which is no option there. And that's what OpenStack was created. We created an open source solution for providing infrastructure to power clouds of all sizes, public clouds and private clouds. It was the first solution to try to be a bit universal. And so the first six years of OpenStack was famously created by, like I said, Nova, which is the compute, the VMware as a service component that came out of NASA. So we've researched private cloud systems, baked into it, and Swift, which is an object storage component that came from a white space with all the public cloud providers. It's how we set the requirements from both areas just online. And then people got very excited. It was called the Linux of the data center. It was called the technology to end old technology. So you ended up with like startups everywhere, trying to make money, going to the gold mine, and trying to say, oh, you can get involved with OpenStack. And then that's when we had more than 100,000 changes per year. So like three times more active than Kubernetes is today. It was like crazy to think about it. Everyone wanted to be a part of it. Everyone wanted their use case. Everyone wanted their product to be integrated with it. And so that created a lot of scope creep because we basically extended to solve all of those, all of that demands. Really hard to say no if you are not going to be developed open source product. People want to give you code and why would you reject it? So in the end, that resulted in a lot of scope creep, especially in areas where OpenStack was not as strong like orchestration, for example. And that's when we had this question, like who is the OpenStack user? Is it the people that actually choose to deploy, install it, operate it? Is it the people that consume the cloud APIs? Is it the end user? Is it the person that uses the consumer? And that tension between the two was really difficult to solve from an audience perspective. How do you present it? That's when Kubernetes appeared. Kubernetes appeared mid-2014, moved to open development around 2015. And it really brought for us a welcome clarification. Because to understand how it helped us, we need to take a step back and look at how you provide applications. Like 20 years ago, you would just procure some physical hardware. And as an application developer, as a developer, you would install the operating system, your dependencies, and your application on top of that. But that was a bit inconvenient. So we added layers. The first layer that was added, one of these devos, is hardware actualization. Basically, abstracting the server on your application is running on from the physical hardware that runs on it. And then we added cloud APIs, basically allowing to programmatically access those virtualized resources. And then another layer, which is application deployment APIs, basically what Kubernetes does, which is providing higher level privilege to deploy complex applications on top of that programmable infrastructure. So you have this programmable infrastructure on one side, and cloud native cloud aware applications being deployed on top of that. It's actually two different types of populations, people that provide infrastructure on one end, and people that write applications and deploy them at the top. And Kubernetes really helped us having that layer between those two different, very different things. And so, yes, the advent of Kubernetes really provided this welcome clarification about this interface layer between infrastructure providers and infrastructure consumers. And if you are an infrastructure consumer, developers, employers, infrastructure is a given. It's someone else's job. You don't have to care about it. And so, they no longer talk to OpenStack directly. OpenStack is irrelevant to them. OpenStack is invisible to them. So OpenStack is dead to them. It's not dead. It just grew up. It found its purpose in life. And it found its user. So, in the end, its users are the people that are providing infrastructure. Only had appropriate solutions before, and now can rely on open source solutions to do that. It's a role that is very separate from the traditional developers. It's a new class of actors. And that's recognizing that it's a new group of people. That's why the foundation, the OpenStack Foundation transitioned to becoming the opening infrastructure foundation. Because there is this group of people that want to provide infrastructure using open source solutions. They need more than just OpenStack. They need all the help they can get. So, that's why we formed the OpenInfra Foundation, and we have more than OpenStack now. We also have Kata containers, or Zoo, or Starling eggs, or other projects. All about providing infrastructure for open source solutions for open source providers. Back to OpenStack. If OpenStack is not dead, what makes it relevant for the next year? Why would you care? Why should we just all use public peer for the hyperscaler of public clouds and not care about infrastructure? I mean, hyperscalers are not going away. Amazon will be there tomorrow. The initial goal of OpenStack ends all the Amazons. It's not going to happen, it's fine. But we think it's important that there is open source solutions for providing infrastructure. There is an option there. The reason for that is that there is this combination of solutions that you can use. Basically, Linux and the organic system layer, OpenStack and the cloud APIs layer, combined with Kubernetes and the application deployment layer. And that forms an end-to-end solution for providing infrastructure using purely open source software. That's what we call the log stack. So, Linux, OpenStack, Kubernetes, and infrastructure. End-to-end solution to provide basic infrastructure to run cloud native orchestration on and for public and for private cloud. It's a very popular combination to use all of them together. But why would you use it? Why would you go through the hustle of running your own? There are like three main reasons to do that. That's the cost, compliance and capabilities. It's a framework that's been there for a while. We first talked about it in 2017. But it's more relevant than ever today. So, for example, if you look at cost, there was this study by Amazon over its last year about the cost of cloud. And that's the idea of venture executives. They are not financial business. They looked at the cost of operating all those startups on top of Amazon Web Services and Microsoft. And they found that when those companies would repatriate their workloads locally, they would save half to two thirds of the cost. So, they would get from 50 to 66 percent cost reduction by repatriating their workloads in the private cloud. And the reason for that is once you get a stable workload, once you get a stable workload, public infrastructure is great to handle the elasticity, the growth, all of those things. But once you have a stable workload, it's an exceptionally costly way of finding infrastructure. And so, the ideal model is a hybrid model where you use private infrastructure for the base and public infrastructure for the spikes. Compliance. I'll try to go fast. So, digital service IT is a big topic. There is a full development service cloud this afternoon. So, you should go there if you like that you will be running right now. So, it drives a lot of open stack adoption, especially in South-East Asia. Not in the U.S. I don't really care that much. But for open stack, it's clearly where the growth is. All the research institutions need to have their own thing. All the EU countries want to have solutions that are local. And that drives a lot of adoption today. Most of that 25 to 40 million job is probably linked to digital service. And finally, there is this capability state. You would think that cloud is a pretty defined space by now. It's been around for a while. But there are new use cases. And those new use cases are enabled by the fact that you have a solution to experiment and play with. Like, for example, we have this company called OneCode that is running game servers in a small island in the middle of the Pacific Ocean that sits on top of Internet cables. Because what they want to provide is equal latency to players in the U.S., in China, in Japan, and in Australia, which is quite a corner case, I guess. But they couldn't wait until... And they, like, post-game e-sports tournaments. They could have waited for Amazon Web Services to set up the data center there, but it probably would never have happened. So clearly, one use case that could not be served without an open source option out there. Closer up to here, Exion is a French subsidiary of ETF for French people in the room. That's where most of our electricity is coming from. And so they had those super calculators that are used for nuclear plant simulation that are regularly decommissioned because clearly they need more power to simulate what's happening in there. And what they used to do is they would just put them to school. And what that guy at Exion decided to do is to actually repurpose that into high-density, super-converged clouds that basically use the resources that are within those super calculators. And they are running HPC as a service, like workloads, with an high environmental impact. Because since they got the servers for free from climate impact, they're also tracking exactly the mixed energy mix of your workloads based on when you run them so that they track the environmental impact of your workloads as well. And finally, LeafCloud is a public cloud based in Amsterdam where they actually distribute the compute servers all over the city. And those are used to heat the water for those buildings. Swimming pools, apartment complexes, all of them being served by those servers. So clearly, again, a corner case because Amsterdam has those black fiber things between those buildings that actually make that possible. But you end up with the data center that's really the most energy efficiency in the world just by doing that. And so those use cases, those specific things, this kind of research innovation is enabled by opening infrastructure. So I think it's simple. In conclusion, OpenStack is not dead. It has a massive user footprint. It's growing year over year. It's still one of the most active open source projects in the world. But it might be dead to you. It's someone else's job to provide infrastructure. It's someone else's job to care. And it's fine. It will not take over Amazon Web Services. Andrea still has a job. It will not replace every technology going forward. It will not be the technology that ends all technology. But it is a necessary component in the infrastructure to provide investment. It's a tool for enabling hybrid usage. It's a tool for use cases that are not served by hyperscale. It's a tool for workloads which can't be served out of U.S. based servers due to digital services. So for costs, for compliance, for catalytic reasons, OpenStack is here to stay for the next decade. Thank you. Thank you. Obviously, six years ago I went to a conference that was about using OpenStack in scientific and in large data analysis. The thing I came away from that conference was that OpenStack was really complicated to set up. And your only hope of getting something working was the higher-end app to do it for you. So is that, I mean, is that kind of, I mean, is that the part because of the scope, I think, that now that you've focused on is kind of easy to set up, or can you take a comment on that? So the question is, OpenStack has this information of being very hard to set up, and this message that you have to hire somebody who will do it for you, is it still the case and what's the minimum cost? So I would say, I mean, it's still a complex job to run infrastructure, like for various reasons, mostly because of the 24-hour type service constraints, one of those things. But I would say that running OpenStack has gotten a lot easier, especially one of the big concerns, but not necessarily the scope, because you can just deploy a few services. And it wasn't really affecting that. And today, yes, there is less scope. We've focused on the main pieces. It was really more the upgrade cycle. If you wanted to keep up to date with the release that were produced, it created a lot of tension because every six months you would have to upgrade your infrastructure if you wanted to do that. And so the work was done to really make those upgrades a lot more streamlined. There is a lot less breaking changes happening, because the pace of, I would say, new future development is still going on in the maintenance and maintenance mode. I believe in new hardware functions, all of those. It's more like a driver space than a course space. So you see a lot less disruption when you do the upgrade. It's also that the upgrades are much more tested. We have solutions for distributions that can be used, that handle that, that are pretty nice, not necessarily solved by one of the players in the OpenStack space that you can rely on to actually do the updates. So it's no longer that difficult, but it's still a job in itself. It's still like something that you have to talk about. It's an interesting thing to think about. I'm always amazed when, so the use of guys are running this gigantic OpenStack to power game servers and they are doing that to the best team of the team. It's not curable not to buy yourself a new crash, but it's still doable with a relatively small team. And I think no big guys, they have a very large, they have a very large team. Well, it's like, it's not, it's not completely out of reach. The smaller it is, the less constrained there is from the users. Do you think the fact that you've got 29,000 full requests over quite a number of projects where, you know, you've got, for example, Nova, Keystone, but you've also got some more skill projects versus, sorry, Kubernetes, which has like one key component that everyone contributes to, based towards this perception of, you know, things don't move as fast as Kubernetes? No, I don't think it's, it's the fact that OpenStack is more of a collection of services versus Kubernetes, which is much more in Monolith, could play to the, like, the scale that people, people see as less active. I think there are a lot of reasons. We are not using GitHub. We are using our own, we software tools based on Garrett and Zool. And so, there is a bit of a visibility that is right there, because we are not appealing on those, like, reports, gender reports that we are using. There is this perception that all of this is happening in GitHub and everything else is not really existing. So all of those things contribute to it. The fact that it's a Monolith versus a set of projects, I don't think that plays that matter, because if you look at the amount of development that's happening on those French services, it's not that much. It's sort of the core of the developments we have in, you know, the I1A. And so, it's, I would say it's not, yeah. Thank you. I'll take questions outside.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.0, "text": " Thank you for coming, first and quick introduction, my name is Thierry Tha\u00efd, I've been involved", "tokens": [50364, 1044, 291, 337, 1348, 11, 700, 293, 1702, 9339, 11, 452, 1315, 307, 334, 811, 627, 334, 64, 15487, 67, 11, 286, 600, 668, 3288, 50964], "temperature": 0.0, "avg_logprob": -0.6607765883542178, "compression_ratio": 1.6026785714285714, "no_speech_prob": 0.5444355607032776}, {"id": 1, "seek": 0, "start": 12.0, "end": 17.0, "text": " in a software and software project for the last three years, and today I'm working on", "tokens": [50964, 294, 257, 4722, 293, 4722, 1716, 337, 264, 1036, 1045, 924, 11, 293, 965, 286, 478, 1364, 322, 51214], "temperature": 0.0, "avg_logprob": -0.6607765883542178, "compression_ratio": 1.6026785714285714, "no_speech_prob": 0.5444355607032776}, {"id": 2, "seek": 0, "start": 17.0, "end": 21.0, "text": " a software and software project. I'm also the general manager for the Open Infrastructure", "tokens": [51214, 257, 4722, 293, 4722, 1716, 13, 286, 478, 611, 264, 2674, 6598, 337, 264, 7238, 38425, 2885, 51414], "temperature": 0.0, "avg_logprob": -0.6607765883542178, "compression_ratio": 1.6026785714285714, "no_speech_prob": 0.5444355607032776}, {"id": 3, "seek": 0, "start": 21.0, "end": 27.0, "text": " Foundation, which is the foundation that hosts OpenStack and Curator projects in OLC.", "tokens": [51414, 10335, 11, 597, 307, 264, 7030, 300, 21573, 7238, 4520, 501, 293, 7907, 1639, 4455, 294, 422, 14766, 13, 51714], "temperature": 0.0, "avg_logprob": -0.6607765883542178, "compression_ratio": 1.6026785714285714, "no_speech_prob": 0.5444355607032776}, {"id": 4, "seek": 2700, "start": 27.0, "end": 34.0, "text": " So I'm here as the vice-chair of the OpenSoft Initiative as the next project, and today I", "tokens": [50364, 407, 286, 478, 510, 382, 264, 11964, 12, 17892, 295, 264, 7238, 6455, 844, 26166, 382, 264, 958, 1716, 11, 293, 965, 286, 50714], "temperature": 0.0, "avg_logprob": -0.31956831614176434, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.42371124029159546}, {"id": 5, "seek": 2700, "start": 34.0, "end": 40.0, "text": " wanted to talk to you about OpenStack and its relevance today, because a lot of people", "tokens": [50714, 1415, 281, 751, 281, 291, 466, 7238, 4520, 501, 293, 1080, 32684, 965, 11, 570, 257, 688, 295, 561, 51014], "temperature": 0.0, "avg_logprob": -0.31956831614176434, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.42371124029159546}, {"id": 6, "seek": 2700, "start": 40.0, "end": 46.0, "text": " are saying that OpenStack is dead. I mean, it's a fair question, right? It's been around", "tokens": [51014, 366, 1566, 300, 7238, 4520, 501, 307, 3116, 13, 286, 914, 11, 309, 311, 257, 3143, 1168, 11, 558, 30, 467, 311, 668, 926, 51314], "temperature": 0.0, "avg_logprob": -0.31956831614176434, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.42371124029159546}, {"id": 7, "seek": 2700, "start": 46.0, "end": 55.0, "text": " for 13 years and nobody has much anymore and less than you mentioned, so I mean, is it", "tokens": [51314, 337, 3705, 924, 293, 5079, 575, 709, 3602, 293, 1570, 813, 291, 2835, 11, 370, 286, 914, 11, 307, 309, 51764], "temperature": 0.0, "avg_logprob": -0.31956831614176434, "compression_ratio": 1.550660792951542, "no_speech_prob": 0.42371124029159546}, {"id": 8, "seek": 5500, "start": 55.0, "end": 62.0, "text": " dead? It could be, maybe, you know, nobody is using it anymore and nobody cares. So let's", "tokens": [50364, 3116, 30, 467, 727, 312, 11, 1310, 11, 291, 458, 11, 5079, 307, 1228, 309, 3602, 293, 5079, 12310, 13, 407, 718, 311, 50714], "temperature": 0.0, "avg_logprob": -0.1619418428299275, "compression_ratio": 1.5219298245614035, "no_speech_prob": 0.08853946626186371}, {"id": 9, "seek": 5500, "start": 62.0, "end": 69.0, "text": " look at the data. So OpenStack, according to our latest user survey that was run in", "tokens": [50714, 574, 412, 264, 1412, 13, 407, 7238, 4520, 501, 11, 4650, 281, 527, 6792, 4195, 8984, 300, 390, 1190, 294, 51064], "temperature": 0.0, "avg_logprob": -0.1619418428299275, "compression_ratio": 1.5219298245614035, "no_speech_prob": 0.08853946626186371}, {"id": 10, "seek": 5500, "start": 69.0, "end": 76.0, "text": " 2022, is run over a footprint of more than 40 million CPU cores of 15 hours. So that's", "tokens": [51064, 20229, 11, 307, 1190, 670, 257, 24222, 295, 544, 813, 3356, 2459, 13199, 24826, 295, 2119, 2496, 13, 407, 300, 311, 51414], "temperature": 0.0, "avg_logprob": -0.1619418428299275, "compression_ratio": 1.5219298245614035, "no_speech_prob": 0.08853946626186371}, {"id": 11, "seek": 5500, "start": 76.0, "end": 83.0, "text": " a massive footprint. There's a lot of usage of OpenStack and a lot more people getting", "tokens": [51414, 257, 5994, 24222, 13, 821, 311, 257, 688, 295, 14924, 295, 7238, 4520, 501, 293, 257, 688, 544, 561, 1242, 51764], "temperature": 0.0, "avg_logprob": -0.1619418428299275, "compression_ratio": 1.5219298245614035, "no_speech_prob": 0.08853946626186371}, {"id": 12, "seek": 8300, "start": 83.0, "end": 89.0, "text": " comfortable mentioning it. It's actually increased from 25 million to 40 million", "tokens": [50364, 4619, 18315, 309, 13, 467, 311, 767, 6505, 490, 3552, 2459, 281, 3356, 2459, 50664], "temperature": 0.0, "avg_logprob": -0.13742941220601398, "compression_ratio": 1.532934131736527, "no_speech_prob": 0.08584804087877274}, {"id": 13, "seek": 8300, "start": 89.0, "end": 97.0, "text": " around the course of between 2021 and 2022. So it grew between 25 to 40 million CPU cores", "tokens": [50664, 926, 264, 1164, 295, 1296, 7201, 293, 20229, 13, 407, 309, 6109, 1296, 3552, 281, 3356, 2459, 13199, 24826, 51064], "temperature": 0.0, "avg_logprob": -0.13742941220601398, "compression_ratio": 1.532934131736527, "no_speech_prob": 0.08584804087877274}, {"id": 14, "seek": 8300, "start": 97.0, "end": 104.0, "text": " in our user survey reports between 2021 and 2022. It's happening in all verticals, so", "tokens": [51064, 294, 527, 4195, 8984, 7122, 1296, 7201, 293, 20229, 13, 467, 311, 2737, 294, 439, 9429, 82, 11, 370, 51414], "temperature": 0.0, "avg_logprob": -0.13742941220601398, "compression_ratio": 1.532934131736527, "no_speech_prob": 0.08584804087877274}, {"id": 15, "seek": 10400, "start": 104.0, "end": 114.0, "text": " you can see the traditional OpenStack strongholds. It was originally formed by a public cloud", "tokens": [50364, 291, 393, 536, 264, 5164, 7238, 4520, 501, 2068, 4104, 82, 13, 467, 390, 7993, 8693, 538, 257, 1908, 4588, 50864], "temperature": 0.0, "avg_logprob": -0.2494668248874038, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.653981626033783}, {"id": 16, "seek": 10400, "start": 114.0, "end": 120.0, "text": " company and a research institution. So on the public cloud side, it's still very strong", "tokens": [50864, 2237, 293, 257, 2132, 7818, 13, 407, 322, 264, 1908, 4588, 1252, 11, 309, 311, 920, 588, 2068, 51164], "temperature": 0.0, "avg_logprob": -0.2494668248874038, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.653981626033783}, {"id": 17, "seek": 10400, "start": 120.0, "end": 127.0, "text": " with workspace being involved, but also OVH Cloud or Infomaniac or Deutsche Telecom or", "tokens": [51164, 365, 32706, 885, 3288, 11, 457, 611, 422, 53, 39, 8061, 420, 11537, 298, 3782, 326, 420, 45567, 14889, 1112, 420, 51514], "temperature": 0.0, "avg_logprob": -0.2494668248874038, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.653981626033783}, {"id": 18, "seek": 12700, "start": 127.0, "end": 133.0, "text": " Leroy. All of those companies running OpenStack based public clouds. It's also strong in the", "tokens": [50364, 441, 260, 939, 13, 1057, 295, 729, 3431, 2614, 7238, 4520, 501, 2361, 1908, 12193, 13, 467, 311, 611, 2068, 294, 264, 50664], "temperature": 0.0, "avg_logprob": -0.26580971479415894, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.5018293857574463}, {"id": 19, "seek": 12700, "start": 133.0, "end": 140.0, "text": " research area where it started at NASA, but now it's used at CERN, it's used at Harvard,", "tokens": [50664, 2132, 1859, 689, 309, 1409, 412, 12077, 11, 457, 586, 309, 311, 1143, 412, 383, 1598, 45, 11, 309, 311, 1143, 412, 13378, 11, 51014], "temperature": 0.0, "avg_logprob": -0.26580971479415894, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.5018293857574463}, {"id": 20, "seek": 12700, "start": 140.0, "end": 145.0, "text": " it's used at MIT, it's used at the European Center for Medium Weather Forecast, which", "tokens": [51014, 309, 311, 1143, 412, 13100, 11, 309, 311, 1143, 412, 264, 6473, 5169, 337, 38915, 34441, 9018, 3734, 11, 597, 51264], "temperature": 0.0, "avg_logprob": -0.26580971479415894, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.5018293857574463}, {"id": 21, "seek": 12700, "start": 145.0, "end": 150.0, "text": " right now has hold up, and basically that's one of the weather forecasts here. So all of", "tokens": [51264, 558, 586, 575, 1797, 493, 11, 293, 1936, 300, 311, 472, 295, 264, 5503, 49421, 510, 13, 407, 439, 295, 51514], "temperature": 0.0, "avg_logprob": -0.26580971479415894, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.5018293857574463}, {"id": 22, "seek": 15000, "start": 150.0, "end": 161.0, "text": " those research institutions that have developed for public cloud, it's also strong in the", "tokens": [50364, 729, 2132, 8142, 300, 362, 4743, 337, 1908, 4588, 11, 309, 311, 611, 2068, 294, 264, 50914], "temperature": 0.0, "avg_logprob": -0.21107487345850745, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.24751707911491394}, {"id": 23, "seek": 15000, "start": 161.0, "end": 167.0, "text": " telecom industry. It's well known that OpenStack is used there. Nine out of the ten telecom", "tokens": [50914, 4304, 1112, 3518, 13, 467, 311, 731, 2570, 300, 7238, 4520, 501, 307, 1143, 456, 13, 18939, 484, 295, 264, 2064, 4304, 1112, 51214], "temperature": 0.0, "avg_logprob": -0.21107487345850745, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.24751707911491394}, {"id": 24, "seek": 15000, "start": 167.0, "end": 173.0, "text": " companies are actually using OpenStack as their back-end for handling everyday calls.", "tokens": [51214, 3431, 366, 767, 1228, 7238, 4520, 501, 382, 641, 646, 12, 521, 337, 13175, 7429, 5498, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21107487345850745, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.24751707911491394}, {"id": 25, "seek": 15000, "start": 173.0, "end": 178.0, "text": " It's also strong in retail and e-commerce with the largest company in the world, Walmart,", "tokens": [51514, 467, 311, 611, 2068, 294, 10800, 293, 308, 12, 26926, 365, 264, 6443, 2237, 294, 264, 1002, 11, 25237, 11, 51764], "temperature": 0.0, "avg_logprob": -0.21107487345850745, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.24751707911491394}, {"id": 26, "seek": 17800, "start": 178.0, "end": 185.0, "text": " still using it. Financial services with banks like Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or Financial Services", "tokens": [50364, 920, 1228, 309, 13, 25560, 3328, 365, 10237, 411, 12276, 21210, 460, 3516, 4198, 1220, 420, 25560, 12124, 50714], "temperature": 0.0, "avg_logprob": -0.29058919634137836, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.15900997817516327}, {"id": 27, "seek": 17800, "start": 185.0, "end": 192.0, "text": " like PayPal or China Union Bank. It's strong in energy, transportation, government manufacturing,", "tokens": [50714, 411, 39906, 420, 3533, 8133, 8915, 13, 467, 311, 2068, 294, 2281, 11, 11328, 11, 2463, 11096, 11, 51064], "temperature": 0.0, "avg_logprob": -0.29058919634137836, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.15900997817516327}, {"id": 28, "seek": 17800, "start": 192.0, "end": 198.0, "text": " web entertainment with one-on-one brands, Comcast, Salesforce, Adobe, Bloomberg,", "tokens": [51064, 3670, 12393, 365, 472, 12, 266, 12, 546, 11324, 11, 2432, 3734, 11, 40398, 11, 24862, 11, 40363, 11, 51364], "temperature": 0.0, "avg_logprob": -0.29058919634137836, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.15900997817516327}, {"id": 29, "seek": 19800, "start": 199.0, "end": 215.0, "text": " all the games, game servers, it's a lot of usage. It's also that those users are actually", "tokens": [50414, 439, 264, 2813, 11, 1216, 15909, 11, 309, 311, 257, 688, 295, 14924, 13, 467, 311, 611, 300, 729, 5022, 366, 767, 51214], "temperature": 0.0, "avg_logprob": -0.24852718524078823, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.7202478051185608}, {"id": 30, "seek": 19800, "start": 215.0, "end": 221.0, "text": " increasing their usage. We used to give stickers to companies that would reach 100,000 CPU", "tokens": [51214, 5662, 641, 14924, 13, 492, 1143, 281, 976, 21019, 281, 3431, 300, 576, 2524, 2319, 11, 1360, 13199, 51514], "temperature": 0.0, "avg_logprob": -0.24852718524078823, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.7202478051185608}, {"id": 31, "seek": 19800, "start": 221.0, "end": 226.0, "text": " calls, and now we have to create a new sticker because a bunch of them are actually more", "tokens": [51514, 5498, 11, 293, 586, 321, 362, 281, 1884, 257, 777, 20400, 570, 257, 3840, 295, 552, 366, 767, 544, 51764], "temperature": 0.0, "avg_logprob": -0.24852718524078823, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.7202478051185608}, {"id": 32, "seek": 22600, "start": 226.0, "end": 232.0, "text": " than one billion CPU calls, including China Mobile and China Unicom, which are the two", "tokens": [50364, 813, 472, 5218, 13199, 5498, 11, 3009, 3533, 22625, 293, 3533, 1156, 299, 298, 11, 597, 366, 264, 732, 50664], "temperature": 0.0, "avg_logprob": -0.3735368549823761, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.053852543234825134}, {"id": 33, "seek": 22600, "start": 232.0, "end": 240.0, "text": " cell-phone mobile companies in China. So that's providing basically all Chinese citizens", "tokens": [50664, 2815, 12, 4977, 6013, 3431, 294, 3533, 13, 407, 300, 311, 6530, 1936, 439, 4649, 7180, 51064], "temperature": 0.0, "avg_logprob": -0.3735368549823761, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.053852543234825134}, {"id": 34, "seek": 22600, "start": 240.0, "end": 248.0, "text": " with their users. So it definitely has usage. So why are people saying it's dead? It may", "tokens": [51064, 365, 641, 5022, 13, 407, 309, 2138, 575, 14924, 13, 407, 983, 366, 561, 1566, 309, 311, 3116, 30, 467, 815, 51464], "temperature": 0.0, "avg_logprob": -0.3735368549823761, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.053852543234825134}, {"id": 35, "seek": 24800, "start": 248.0, "end": 255.0, "text": " be, you know, it's still working, but it's dead inside, and nobody's really developing", "tokens": [50364, 312, 11, 291, 458, 11, 309, 311, 920, 1364, 11, 457, 309, 311, 3116, 1854, 11, 293, 5079, 311, 534, 6416, 50714], "temperature": 0.0, "avg_logprob": -0.2540947002368969, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.24310290813446045}, {"id": 36, "seek": 24800, "start": 255.0, "end": 260.0, "text": " it anymore, and has no development activity, so it moves more like it's only me or something.", "tokens": [50714, 309, 3602, 11, 293, 575, 572, 3250, 5191, 11, 370, 309, 6067, 544, 411, 309, 311, 787, 385, 420, 746, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2540947002368969, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.24310290813446045}, {"id": 37, "seek": 24800, "start": 260.0, "end": 266.0, "text": " It's not dead, but it's almost dead. And if you look at activity, development activity,", "tokens": [50964, 467, 311, 406, 3116, 11, 457, 309, 311, 1920, 3116, 13, 400, 498, 291, 574, 412, 5191, 11, 3250, 5191, 11, 51264], "temperature": 0.0, "avg_logprob": -0.2540947002368969, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.24310290813446045}, {"id": 38, "seek": 24800, "start": 266.0, "end": 272.0, "text": " you have to compare with very well-known, very active projects like Kubernetes for example.", "tokens": [51264, 291, 362, 281, 6794, 365, 588, 731, 12, 6861, 11, 588, 4967, 4455, 411, 23145, 337, 1365, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2540947002368969, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.24310290813446045}, {"id": 39, "seek": 27200, "start": 272.0, "end": 277.0, "text": " Kubernetes is a massive, open collaboration, and I'm sure everyone in this room has heard", "tokens": [50364, 23145, 307, 257, 5994, 11, 1269, 9363, 11, 293, 286, 478, 988, 1518, 294, 341, 1808, 575, 2198, 50614], "temperature": 0.0, "avg_logprob": -0.33346299691633746, "compression_ratio": 1.5550660792951543, "no_speech_prob": 0.478273868560791}, {"id": 40, "seek": 27200, "start": 277.0, "end": 282.0, "text": " of Kubernetes, and they have a very large, it's one of the most active business projects", "tokens": [50614, 295, 23145, 11, 293, 436, 362, 257, 588, 2416, 11, 309, 311, 472, 295, 264, 881, 4967, 1606, 4455, 50864], "temperature": 0.0, "avg_logprob": -0.33346299691633746, "compression_ratio": 1.5550660792951543, "no_speech_prob": 0.478273868560791}, {"id": 41, "seek": 27200, "start": 282.0, "end": 289.0, "text": " in the world. It has more than 33,000 Internet public requests, I mean, reviewed by Uniman", "tokens": [50864, 294, 264, 1002, 13, 467, 575, 544, 813, 11816, 11, 1360, 7703, 1908, 12475, 11, 286, 914, 11, 18429, 538, 1156, 25504, 51214], "temperature": 0.0, "avg_logprob": -0.33346299691633746, "compression_ratio": 1.5550660792951543, "no_speech_prob": 0.478273868560791}, {"id": 42, "seek": 27200, "start": 289.0, "end": 296.0, "text": " and merged into the code base over the last year. It's more like one of our changed", "tokens": [51214, 293, 36427, 666, 264, 3089, 3096, 670, 264, 1036, 1064, 13, 467, 311, 544, 411, 472, 295, 527, 3105, 51564], "temperature": 0.0, "avg_logprob": -0.33346299691633746, "compression_ratio": 1.5550660792951543, "no_speech_prob": 0.478273868560791}, {"id": 43, "seek": 29600, "start": 296.0, "end": 301.0, "text": " projects today, which is really massive. And if we try to see how OpenStack compares", "tokens": [50364, 4455, 965, 11, 597, 307, 534, 5994, 13, 400, 498, 321, 853, 281, 536, 577, 7238, 4520, 501, 38334, 50614], "temperature": 0.0, "avg_logprob": -0.20264040340076794, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.1964239925146103}, {"id": 44, "seek": 29600, "start": 301.0, "end": 307.0, "text": " with that, OpenStack in 2022 was actually 29,000 year changes merged, the same thing", "tokens": [50614, 365, 300, 11, 7238, 4520, 501, 294, 20229, 390, 767, 9413, 11, 1360, 1064, 2962, 36427, 11, 264, 912, 551, 50914], "temperature": 0.0, "avg_logprob": -0.20264040340076794, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.1964239925146103}, {"id": 45, "seek": 29600, "start": 307.0, "end": 314.0, "text": " for the reviewed by Uniman, and then merged into the code. And so it's definitely the", "tokens": [50914, 337, 264, 18429, 538, 1156, 25504, 11, 293, 550, 36427, 666, 264, 3089, 13, 400, 370, 309, 311, 2138, 264, 51264], "temperature": 0.0, "avg_logprob": -0.20264040340076794, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.1964239925146103}, {"id": 46, "seek": 29600, "start": 314.0, "end": 320.0, "text": " same ballpark. It's definitely the same level of activity. Definitely one of the three most", "tokens": [51264, 912, 2594, 31239, 13, 467, 311, 2138, 264, 912, 1496, 295, 5191, 13, 12151, 472, 295, 264, 1045, 881, 51564], "temperature": 0.0, "avg_logprob": -0.20264040340076794, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.1964239925146103}, {"id": 47, "seek": 32000, "start": 320.0, "end": 326.0, "text": " active open source projects out there in terms of development activity, like with the", "tokens": [50364, 4967, 1269, 4009, 4455, 484, 456, 294, 2115, 295, 3250, 5191, 11, 411, 365, 264, 50664], "temperature": 0.0, "avg_logprob": -0.2596359696499137, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.05654537305235863}, {"id": 48, "seek": 32000, "start": 326.0, "end": 335.0, "text": " Linux kernel and Chromium. So it's not dead from the development perspective either.", "tokens": [50664, 18734, 28256, 293, 1721, 298, 2197, 13, 407, 309, 311, 406, 3116, 490, 264, 3250, 4585, 2139, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2596359696499137, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.05654537305235863}, {"id": 49, "seek": 32000, "start": 335.0, "end": 339.0, "text": " So why are people saying it's dead? I used to think it's because they just didn't like", "tokens": [51114, 407, 983, 366, 561, 1566, 309, 311, 3116, 30, 286, 1143, 281, 519, 309, 311, 570, 436, 445, 994, 380, 411, 51314], "temperature": 0.0, "avg_logprob": -0.2596359696499137, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.05654537305235863}, {"id": 50, "seek": 32000, "start": 339.0, "end": 347.0, "text": " us. They just wanted us to feel bad and get up in the morning. But then I started thinking,", "tokens": [51314, 505, 13, 814, 445, 1415, 505, 281, 841, 1578, 293, 483, 493, 294, 264, 2446, 13, 583, 550, 286, 1409, 1953, 11, 51714], "temperature": 0.0, "avg_logprob": -0.2596359696499137, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.05654537305235863}, {"id": 51, "seek": 34700, "start": 347.0, "end": 351.0, "text": " like, maybe there's something else. Maybe there is a deeper reason why people think", "tokens": [50364, 411, 11, 1310, 456, 311, 746, 1646, 13, 2704, 456, 307, 257, 7731, 1778, 983, 561, 519, 50564], "temperature": 0.0, "avg_logprob": -0.19136881566309666, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.17302878201007843}, {"id": 52, "seek": 34700, "start": 351.0, "end": 358.0, "text": " about OpenStack is dead. But then we did think about it. So why are people thinking of", "tokens": [50564, 466, 7238, 4520, 501, 307, 3116, 13, 583, 550, 321, 630, 519, 466, 309, 13, 407, 983, 366, 561, 1953, 295, 50914], "temperature": 0.0, "avg_logprob": -0.19136881566309666, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.17302878201007843}, {"id": 53, "seek": 34700, "start": 358.0, "end": 363.0, "text": " OpenStack is dead? We need to take a step back and look at OpenStack is strange. We need", "tokens": [50914, 7238, 4520, 501, 307, 3116, 30, 492, 643, 281, 747, 257, 1823, 646, 293, 574, 412, 7238, 4520, 501, 307, 5861, 13, 492, 643, 51164], "temperature": 0.0, "avg_logprob": -0.19136881566309666, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.17302878201007843}, {"id": 54, "seek": 34700, "start": 363.0, "end": 369.0, "text": " to answer that question. So let's rewind back to 2010. It might sound like yesterday,", "tokens": [51164, 281, 1867, 300, 1168, 13, 407, 718, 311, 41458, 646, 281, 9657, 13, 467, 1062, 1626, 411, 5186, 11, 51464], "temperature": 0.0, "avg_logprob": -0.19136881566309666, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.17302878201007843}, {"id": 55, "seek": 36900, "start": 369.0, "end": 376.0, "text": " as for all those people, young people, it will be very, very near.", "tokens": [50364, 382, 337, 439, 729, 561, 11, 2037, 561, 11, 309, 486, 312, 588, 11, 588, 2651, 13, 50714], "temperature": 0.0, "avg_logprob": -0.616323743547712, "compression_ratio": 1.064516129032258, "no_speech_prob": 0.6655015349388123}, {"id": 56, "seek": 37600, "start": 376.0, "end": 402.0, "text": " So it might sound like yesterday, but from an open source perspective, it's actually", "tokens": [50364, 407, 309, 1062, 1626, 411, 5186, 11, 457, 490, 364, 1269, 4009, 4585, 11, 309, 311, 767, 51664], "temperature": 0.0, "avg_logprob": -0.24206649689447313, "compression_ratio": 1.05, "no_speech_prob": 0.47287294268608093}, {"id": 57, "seek": 40200, "start": 402.0, "end": 408.0, "text": " a long time. Back in 2010, Open Source and the open source initiative has been there", "tokens": [50364, 257, 938, 565, 13, 5833, 294, 9657, 11, 7238, 29629, 293, 264, 1269, 4009, 11552, 575, 668, 456, 50664], "temperature": 0.0, "avg_logprob": -0.14559112124972873, "compression_ratio": 1.6232558139534883, "no_speech_prob": 0.8857693672180176}, {"id": 58, "seek": 40200, "start": 408.0, "end": 415.0, "text": " for 12 years. And 12 years have passed since OpenStack was created. If you look at popular", "tokens": [50664, 337, 2272, 924, 13, 400, 2272, 924, 362, 4678, 1670, 7238, 4520, 501, 390, 2942, 13, 759, 291, 574, 412, 3743, 51014], "temperature": 0.0, "avg_logprob": -0.14559112124972873, "compression_ratio": 1.6232558139534883, "no_speech_prob": 0.8857693672180176}, {"id": 59, "seek": 40200, "start": 415.0, "end": 421.0, "text": " projects, Firefox was eight years old when OpenStack was created. Ubuntu was six years", "tokens": [51014, 4455, 11, 46613, 390, 3180, 924, 1331, 562, 7238, 4520, 501, 390, 2942, 13, 30230, 45605, 390, 2309, 924, 51314], "temperature": 0.0, "avg_logprob": -0.14559112124972873, "compression_ratio": 1.6232558139534883, "no_speech_prob": 0.8857693672180176}, {"id": 60, "seek": 40200, "start": 421.0, "end": 427.0, "text": " old. Git was five years old. Android was only two and a half years old. So it's really", "tokens": [51314, 1331, 13, 16939, 390, 1732, 924, 1331, 13, 8853, 390, 787, 732, 293, 257, 1922, 924, 1331, 13, 407, 309, 311, 534, 51614], "temperature": 0.0, "avg_logprob": -0.14559112124972873, "compression_ratio": 1.6232558139534883, "no_speech_prob": 0.8857693672180176}, {"id": 61, "seek": 42700, "start": 427.0, "end": 432.0, "text": " the middle ages of Open Source. And Open Source was very successful back then. But we didn't", "tokens": [50364, 264, 2808, 12357, 295, 7238, 29629, 13, 400, 7238, 29629, 390, 588, 4406, 646, 550, 13, 583, 321, 994, 380, 50614], "temperature": 0.0, "avg_logprob": -0.17175449326980946, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.5724650621414185}, {"id": 62, "seek": 42700, "start": 432.0, "end": 439.0, "text": " have that much open source options for infrastructure. The infrastructure market was cornered by proprietary", "tokens": [50614, 362, 300, 709, 1269, 4009, 3956, 337, 6896, 13, 440, 6896, 2142, 390, 4538, 292, 538, 38992, 50964], "temperature": 0.0, "avg_logprob": -0.17175449326980946, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.5724650621414185}, {"id": 63, "seek": 42700, "start": 439.0, "end": 445.0, "text": " software. It was VMware on the private side and Amazon Web Services on the public side,", "tokens": [50964, 4722, 13, 467, 390, 40146, 322, 264, 4551, 1252, 293, 6795, 9573, 12124, 322, 264, 1908, 1252, 11, 51264], "temperature": 0.0, "avg_logprob": -0.17175449326980946, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.5724650621414185}, {"id": 64, "seek": 42700, "start": 445.0, "end": 451.0, "text": " which is no option there. And that's what OpenStack was created. We created an open source", "tokens": [51264, 597, 307, 572, 3614, 456, 13, 400, 300, 311, 437, 7238, 4520, 501, 390, 2942, 13, 492, 2942, 364, 1269, 4009, 51564], "temperature": 0.0, "avg_logprob": -0.17175449326980946, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.5724650621414185}, {"id": 65, "seek": 45100, "start": 451.0, "end": 457.0, "text": " solution for providing infrastructure to power clouds of all sizes, public clouds and private", "tokens": [50364, 3827, 337, 6530, 6896, 281, 1347, 12193, 295, 439, 11602, 11, 1908, 12193, 293, 4551, 50664], "temperature": 0.0, "avg_logprob": -0.2036145982288179, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.6980545520782471}, {"id": 66, "seek": 45100, "start": 457.0, "end": 464.0, "text": " clouds. It was the first solution to try to be a bit universal. And so the first six", "tokens": [50664, 12193, 13, 467, 390, 264, 700, 3827, 281, 853, 281, 312, 257, 857, 11455, 13, 400, 370, 264, 700, 2309, 51014], "temperature": 0.0, "avg_logprob": -0.2036145982288179, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.6980545520782471}, {"id": 67, "seek": 45100, "start": 464.0, "end": 470.0, "text": " years of OpenStack was famously created by, like I said, Nova, which is the compute, the", "tokens": [51014, 924, 295, 7238, 4520, 501, 390, 34360, 2942, 538, 11, 411, 286, 848, 11, 27031, 11, 597, 307, 264, 14722, 11, 264, 51314], "temperature": 0.0, "avg_logprob": -0.2036145982288179, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.6980545520782471}, {"id": 68, "seek": 45100, "start": 470.0, "end": 477.0, "text": " VMware as a service component that came out of NASA. So we've researched private cloud", "tokens": [51314, 40146, 382, 257, 2643, 6542, 300, 1361, 484, 295, 12077, 13, 407, 321, 600, 37098, 4551, 4588, 51664], "temperature": 0.0, "avg_logprob": -0.2036145982288179, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.6980545520782471}, {"id": 69, "seek": 47700, "start": 477.0, "end": 483.0, "text": " systems, baked into it, and Swift, which is an object storage component that came from", "tokens": [50364, 3652, 11, 19453, 666, 309, 11, 293, 25539, 11, 597, 307, 364, 2657, 6725, 6542, 300, 1361, 490, 50664], "temperature": 0.0, "avg_logprob": -0.21698567953454442, "compression_ratio": 1.5695067264573992, "no_speech_prob": 0.08258798718452454}, {"id": 70, "seek": 47700, "start": 483.0, "end": 489.0, "text": " a white space with all the public cloud providers. It's how we set the requirements from both", "tokens": [50664, 257, 2418, 1901, 365, 439, 264, 1908, 4588, 11330, 13, 467, 311, 577, 321, 992, 264, 7728, 490, 1293, 50964], "temperature": 0.0, "avg_logprob": -0.21698567953454442, "compression_ratio": 1.5695067264573992, "no_speech_prob": 0.08258798718452454}, {"id": 71, "seek": 47700, "start": 489.0, "end": 496.0, "text": " areas just online. And then people got very excited. It was called the Linux of the", "tokens": [50964, 3179, 445, 2950, 13, 400, 550, 561, 658, 588, 2919, 13, 467, 390, 1219, 264, 18734, 295, 264, 51314], "temperature": 0.0, "avg_logprob": -0.21698567953454442, "compression_ratio": 1.5695067264573992, "no_speech_prob": 0.08258798718452454}, {"id": 72, "seek": 47700, "start": 496.0, "end": 503.0, "text": " data center. It was called the technology to end old technology. So you ended up with", "tokens": [51314, 1412, 3056, 13, 467, 390, 1219, 264, 2899, 281, 917, 1331, 2899, 13, 407, 291, 4590, 493, 365, 51664], "temperature": 0.0, "avg_logprob": -0.21698567953454442, "compression_ratio": 1.5695067264573992, "no_speech_prob": 0.08258798718452454}, {"id": 73, "seek": 50300, "start": 503.0, "end": 508.0, "text": " like startups everywhere, trying to make money, going to the gold mine, and trying to say,", "tokens": [50364, 411, 28041, 5315, 11, 1382, 281, 652, 1460, 11, 516, 281, 264, 3821, 3892, 11, 293, 1382, 281, 584, 11, 50614], "temperature": 0.0, "avg_logprob": -0.20794945794182854, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.023312335833907127}, {"id": 74, "seek": 50300, "start": 508.0, "end": 513.0, "text": " oh, you can get involved with OpenStack. And then that's when we had more than 100,000", "tokens": [50614, 1954, 11, 291, 393, 483, 3288, 365, 7238, 4520, 501, 13, 400, 550, 300, 311, 562, 321, 632, 544, 813, 2319, 11, 1360, 50864], "temperature": 0.0, "avg_logprob": -0.20794945794182854, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.023312335833907127}, {"id": 75, "seek": 50300, "start": 513.0, "end": 518.0, "text": " changes per year. So like three times more active than Kubernetes is today. It was like", "tokens": [50864, 2962, 680, 1064, 13, 407, 411, 1045, 1413, 544, 4967, 813, 23145, 307, 965, 13, 467, 390, 411, 51114], "temperature": 0.0, "avg_logprob": -0.20794945794182854, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.023312335833907127}, {"id": 76, "seek": 50300, "start": 518.0, "end": 523.0, "text": " crazy to think about it. Everyone wanted to be a part of it. Everyone wanted their use", "tokens": [51114, 3219, 281, 519, 466, 309, 13, 5198, 1415, 281, 312, 257, 644, 295, 309, 13, 5198, 1415, 641, 764, 51364], "temperature": 0.0, "avg_logprob": -0.20794945794182854, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.023312335833907127}, {"id": 77, "seek": 50300, "start": 523.0, "end": 528.0, "text": " case. Everyone wanted their product to be integrated with it. And so that created a lot of", "tokens": [51364, 1389, 13, 5198, 1415, 641, 1674, 281, 312, 10919, 365, 309, 13, 400, 370, 300, 2942, 257, 688, 295, 51614], "temperature": 0.0, "avg_logprob": -0.20794945794182854, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.023312335833907127}, {"id": 78, "seek": 52800, "start": 528.0, "end": 532.0, "text": " scope creep because we basically extended to solve all of those, all of that demands.", "tokens": [50364, 11923, 9626, 570, 321, 1936, 10913, 281, 5039, 439, 295, 729, 11, 439, 295, 300, 15107, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17419064044952393, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.21444803476333618}, {"id": 79, "seek": 52800, "start": 532.0, "end": 537.0, "text": " Really hard to say no if you are not going to be developed open source product. People", "tokens": [50564, 4083, 1152, 281, 584, 572, 498, 291, 366, 406, 516, 281, 312, 4743, 1269, 4009, 1674, 13, 3432, 50814], "temperature": 0.0, "avg_logprob": -0.17419064044952393, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.21444803476333618}, {"id": 80, "seek": 52800, "start": 537.0, "end": 543.0, "text": " want to give you code and why would you reject it? So in the end, that resulted in a lot of", "tokens": [50814, 528, 281, 976, 291, 3089, 293, 983, 576, 291, 8248, 309, 30, 407, 294, 264, 917, 11, 300, 18753, 294, 257, 688, 295, 51114], "temperature": 0.0, "avg_logprob": -0.17419064044952393, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.21444803476333618}, {"id": 81, "seek": 52800, "start": 543.0, "end": 548.0, "text": " scope creep, especially in areas where OpenStack was not as strong like orchestration, for", "tokens": [51114, 11923, 9626, 11, 2318, 294, 3179, 689, 7238, 4520, 501, 390, 406, 382, 2068, 411, 14161, 2405, 11, 337, 51364], "temperature": 0.0, "avg_logprob": -0.17419064044952393, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.21444803476333618}, {"id": 82, "seek": 52800, "start": 548.0, "end": 557.0, "text": " example. And that's when we had this question, like who is the OpenStack user? Is it the", "tokens": [51364, 1365, 13, 400, 300, 311, 562, 321, 632, 341, 1168, 11, 411, 567, 307, 264, 7238, 4520, 501, 4195, 30, 1119, 309, 264, 51814], "temperature": 0.0, "avg_logprob": -0.17419064044952393, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.21444803476333618}, {"id": 83, "seek": 55700, "start": 557.0, "end": 564.0, "text": " people that actually choose to deploy, install it, operate it? Is it the people that consume", "tokens": [50364, 561, 300, 767, 2826, 281, 7274, 11, 3625, 309, 11, 9651, 309, 30, 1119, 309, 264, 561, 300, 14732, 50714], "temperature": 0.0, "avg_logprob": -0.15746378898620605, "compression_ratio": 1.6542056074766356, "no_speech_prob": 0.0335196852684021}, {"id": 84, "seek": 55700, "start": 564.0, "end": 569.0, "text": " the cloud APIs? Is it the end user? Is it the person that uses the consumer? And that", "tokens": [50714, 264, 4588, 21445, 30, 1119, 309, 264, 917, 4195, 30, 1119, 309, 264, 954, 300, 4960, 264, 9711, 30, 400, 300, 50964], "temperature": 0.0, "avg_logprob": -0.15746378898620605, "compression_ratio": 1.6542056074766356, "no_speech_prob": 0.0335196852684021}, {"id": 85, "seek": 55700, "start": 569.0, "end": 576.0, "text": " tension between the two was really difficult to solve from an audience perspective. How", "tokens": [50964, 8980, 1296, 264, 732, 390, 534, 2252, 281, 5039, 490, 364, 4034, 4585, 13, 1012, 51314], "temperature": 0.0, "avg_logprob": -0.15746378898620605, "compression_ratio": 1.6542056074766356, "no_speech_prob": 0.0335196852684021}, {"id": 86, "seek": 55700, "start": 576.0, "end": 583.0, "text": " do you present it? That's when Kubernetes appeared. Kubernetes appeared mid-2014, moved", "tokens": [51314, 360, 291, 1974, 309, 30, 663, 311, 562, 23145, 8516, 13, 23145, 8516, 2062, 12, 2009, 7271, 11, 4259, 51664], "temperature": 0.0, "avg_logprob": -0.15746378898620605, "compression_ratio": 1.6542056074766356, "no_speech_prob": 0.0335196852684021}, {"id": 87, "seek": 58300, "start": 584.0, "end": 593.0, "text": " to open development around 2015. And it really brought for us a welcome clarification. Because", "tokens": [50414, 281, 1269, 3250, 926, 7546, 13, 400, 309, 534, 3038, 337, 505, 257, 2928, 34449, 13, 1436, 50864], "temperature": 0.0, "avg_logprob": -0.18547407388687134, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.07902341336011887}, {"id": 88, "seek": 58300, "start": 593.0, "end": 600.0, "text": " to understand how it helped us, we need to take a step back and look at how you provide", "tokens": [50864, 281, 1223, 577, 309, 4254, 505, 11, 321, 643, 281, 747, 257, 1823, 646, 293, 574, 412, 577, 291, 2893, 51214], "temperature": 0.0, "avg_logprob": -0.18547407388687134, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.07902341336011887}, {"id": 89, "seek": 58300, "start": 600.0, "end": 605.0, "text": " applications. Like 20 years ago, you would just procure some physical hardware. And as", "tokens": [51214, 5821, 13, 1743, 945, 924, 2057, 11, 291, 576, 445, 26846, 512, 4001, 8837, 13, 400, 382, 51464], "temperature": 0.0, "avg_logprob": -0.18547407388687134, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.07902341336011887}, {"id": 90, "seek": 58300, "start": 605.0, "end": 611.0, "text": " an application developer, as a developer, you would install the operating system, your", "tokens": [51464, 364, 3861, 10754, 11, 382, 257, 10754, 11, 291, 576, 3625, 264, 7447, 1185, 11, 428, 51764], "temperature": 0.0, "avg_logprob": -0.18547407388687134, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.07902341336011887}, {"id": 91, "seek": 61100, "start": 611.0, "end": 615.0, "text": " dependencies, and your application on top of that. But that was a bit inconvenient. So", "tokens": [50364, 36606, 11, 293, 428, 3861, 322, 1192, 295, 300, 13, 583, 300, 390, 257, 857, 46196, 13, 407, 50564], "temperature": 0.0, "avg_logprob": -0.22135349195830675, "compression_ratio": 1.728, "no_speech_prob": 0.05490925535559654}, {"id": 92, "seek": 61100, "start": 615.0, "end": 620.0, "text": " we added layers. The first layer that was added, one of these devos, is hardware", "tokens": [50564, 321, 3869, 7914, 13, 440, 700, 4583, 300, 390, 3869, 11, 472, 295, 613, 1905, 329, 11, 307, 8837, 50814], "temperature": 0.0, "avg_logprob": -0.22135349195830675, "compression_ratio": 1.728, "no_speech_prob": 0.05490925535559654}, {"id": 93, "seek": 61100, "start": 620.0, "end": 625.0, "text": " actualization. Basically, abstracting the server on your application is running on from", "tokens": [50814, 3539, 2144, 13, 8537, 11, 12649, 278, 264, 7154, 322, 428, 3861, 307, 2614, 322, 490, 51064], "temperature": 0.0, "avg_logprob": -0.22135349195830675, "compression_ratio": 1.728, "no_speech_prob": 0.05490925535559654}, {"id": 94, "seek": 61100, "start": 625.0, "end": 631.0, "text": " the physical hardware that runs on it. And then we added cloud APIs, basically allowing", "tokens": [51064, 264, 4001, 8837, 300, 6676, 322, 309, 13, 400, 550, 321, 3869, 4588, 21445, 11, 1936, 8293, 51364], "temperature": 0.0, "avg_logprob": -0.22135349195830675, "compression_ratio": 1.728, "no_speech_prob": 0.05490925535559654}, {"id": 95, "seek": 61100, "start": 631.0, "end": 637.0, "text": " to programmatically access those virtualized resources. And then another layer, which is", "tokens": [51364, 281, 37648, 5030, 2105, 729, 6374, 1602, 3593, 13, 400, 550, 1071, 4583, 11, 597, 307, 51664], "temperature": 0.0, "avg_logprob": -0.22135349195830675, "compression_ratio": 1.728, "no_speech_prob": 0.05490925535559654}, {"id": 96, "seek": 63700, "start": 637.0, "end": 642.0, "text": " application deployment APIs, basically what Kubernetes does, which is providing higher", "tokens": [50364, 3861, 19317, 21445, 11, 1936, 437, 23145, 775, 11, 597, 307, 6530, 2946, 50614], "temperature": 0.0, "avg_logprob": -0.17907016978544346, "compression_ratio": 1.8565400843881856, "no_speech_prob": 0.02475867047905922}, {"id": 97, "seek": 63700, "start": 642.0, "end": 648.0, "text": " level privilege to deploy complex applications on top of that programmable infrastructure.", "tokens": [50614, 1496, 12122, 281, 7274, 3997, 5821, 322, 1192, 295, 300, 37648, 712, 6896, 13, 50914], "temperature": 0.0, "avg_logprob": -0.17907016978544346, "compression_ratio": 1.8565400843881856, "no_speech_prob": 0.02475867047905922}, {"id": 98, "seek": 63700, "start": 648.0, "end": 653.0, "text": " So you have this programmable infrastructure on one side, and cloud native cloud aware", "tokens": [50914, 407, 291, 362, 341, 37648, 712, 6896, 322, 472, 1252, 11, 293, 4588, 8470, 4588, 3650, 51164], "temperature": 0.0, "avg_logprob": -0.17907016978544346, "compression_ratio": 1.8565400843881856, "no_speech_prob": 0.02475867047905922}, {"id": 99, "seek": 63700, "start": 653.0, "end": 658.0, "text": " applications being deployed on top of that. It's actually two different types of", "tokens": [51164, 5821, 885, 17826, 322, 1192, 295, 300, 13, 467, 311, 767, 732, 819, 3467, 295, 51414], "temperature": 0.0, "avg_logprob": -0.17907016978544346, "compression_ratio": 1.8565400843881856, "no_speech_prob": 0.02475867047905922}, {"id": 100, "seek": 63700, "start": 658.0, "end": 663.0, "text": " populations, people that provide infrastructure on one end, and people that write applications", "tokens": [51414, 12822, 11, 561, 300, 2893, 6896, 322, 472, 917, 11, 293, 561, 300, 2464, 5821, 51664], "temperature": 0.0, "avg_logprob": -0.17907016978544346, "compression_ratio": 1.8565400843881856, "no_speech_prob": 0.02475867047905922}, {"id": 101, "seek": 66300, "start": 663.0, "end": 668.0, "text": " and deploy them at the top. And Kubernetes really helped us having that layer between", "tokens": [50364, 293, 7274, 552, 412, 264, 1192, 13, 400, 23145, 534, 4254, 505, 1419, 300, 4583, 1296, 50614], "temperature": 0.0, "avg_logprob": -0.13579585586768994, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.004263423848897219}, {"id": 102, "seek": 66300, "start": 668.0, "end": 676.0, "text": " those two different, very different things. And so, yes, the advent of Kubernetes really", "tokens": [50614, 729, 732, 819, 11, 588, 819, 721, 13, 400, 370, 11, 2086, 11, 264, 7045, 295, 23145, 534, 51014], "temperature": 0.0, "avg_logprob": -0.13579585586768994, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.004263423848897219}, {"id": 103, "seek": 66300, "start": 676.0, "end": 681.0, "text": " provided this welcome clarification about this interface layer between infrastructure", "tokens": [51014, 5649, 341, 2928, 34449, 466, 341, 9226, 4583, 1296, 6896, 51264], "temperature": 0.0, "avg_logprob": -0.13579585586768994, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.004263423848897219}, {"id": 104, "seek": 66300, "start": 681.0, "end": 688.0, "text": " providers and infrastructure consumers. And if you are an infrastructure consumer, developers,", "tokens": [51264, 11330, 293, 6896, 11883, 13, 400, 498, 291, 366, 364, 6896, 9711, 11, 8849, 11, 51614], "temperature": 0.0, "avg_logprob": -0.13579585586768994, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.004263423848897219}, {"id": 105, "seek": 68800, "start": 688.0, "end": 694.0, "text": " employers, infrastructure is a given. It's someone else's job. You don't have to care", "tokens": [50364, 16744, 11, 6896, 307, 257, 2212, 13, 467, 311, 1580, 1646, 311, 1691, 13, 509, 500, 380, 362, 281, 1127, 50664], "temperature": 0.0, "avg_logprob": -0.17317744401785043, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.09394019097089767}, {"id": 106, "seek": 68800, "start": 694.0, "end": 700.0, "text": " about it. And so, they no longer talk to OpenStack directly. OpenStack is irrelevant to them.", "tokens": [50664, 466, 309, 13, 400, 370, 11, 436, 572, 2854, 751, 281, 7238, 4520, 501, 3838, 13, 7238, 4520, 501, 307, 28682, 281, 552, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17317744401785043, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.09394019097089767}, {"id": 107, "seek": 68800, "start": 700.0, "end": 707.0, "text": " OpenStack is invisible to them. So OpenStack is dead to them. It's not dead. It just grew", "tokens": [50964, 7238, 4520, 501, 307, 14603, 281, 552, 13, 407, 7238, 4520, 501, 307, 3116, 281, 552, 13, 467, 311, 406, 3116, 13, 467, 445, 6109, 51314], "temperature": 0.0, "avg_logprob": -0.17317744401785043, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.09394019097089767}, {"id": 108, "seek": 68800, "start": 707.0, "end": 715.0, "text": " up. It found its purpose in life. And it found its user. So, in the end, its users are the", "tokens": [51314, 493, 13, 467, 1352, 1080, 4334, 294, 993, 13, 400, 309, 1352, 1080, 4195, 13, 407, 11, 294, 264, 917, 11, 1080, 5022, 366, 264, 51714], "temperature": 0.0, "avg_logprob": -0.17317744401785043, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.09394019097089767}, {"id": 109, "seek": 71500, "start": 715.0, "end": 720.0, "text": " people that are providing infrastructure. Only had appropriate solutions before, and now", "tokens": [50364, 561, 300, 366, 6530, 6896, 13, 5686, 632, 6854, 6547, 949, 11, 293, 586, 50614], "temperature": 0.0, "avg_logprob": -0.133152391492706, "compression_ratio": 1.7903225806451613, "no_speech_prob": 0.034542884677648544}, {"id": 110, "seek": 71500, "start": 720.0, "end": 727.0, "text": " can rely on open source solutions to do that. It's a role that is very separate from the", "tokens": [50614, 393, 10687, 322, 1269, 4009, 6547, 281, 360, 300, 13, 467, 311, 257, 3090, 300, 307, 588, 4994, 490, 264, 50964], "temperature": 0.0, "avg_logprob": -0.133152391492706, "compression_ratio": 1.7903225806451613, "no_speech_prob": 0.034542884677648544}, {"id": 111, "seek": 71500, "start": 727.0, "end": 733.0, "text": " traditional developers. It's a new class of actors. And that's recognizing that it's a", "tokens": [50964, 5164, 8849, 13, 467, 311, 257, 777, 1508, 295, 10037, 13, 400, 300, 311, 18538, 300, 309, 311, 257, 51264], "temperature": 0.0, "avg_logprob": -0.133152391492706, "compression_ratio": 1.7903225806451613, "no_speech_prob": 0.034542884677648544}, {"id": 112, "seek": 71500, "start": 733.0, "end": 739.0, "text": " new group of people. That's why the foundation, the OpenStack Foundation transitioned to", "tokens": [51264, 777, 1594, 295, 561, 13, 663, 311, 983, 264, 7030, 11, 264, 7238, 4520, 501, 10335, 47346, 281, 51564], "temperature": 0.0, "avg_logprob": -0.133152391492706, "compression_ratio": 1.7903225806451613, "no_speech_prob": 0.034542884677648544}, {"id": 113, "seek": 71500, "start": 739.0, "end": 743.0, "text": " becoming the opening infrastructure foundation. Because there is this group of people that", "tokens": [51564, 5617, 264, 5193, 6896, 7030, 13, 1436, 456, 307, 341, 1594, 295, 561, 300, 51764], "temperature": 0.0, "avg_logprob": -0.133152391492706, "compression_ratio": 1.7903225806451613, "no_speech_prob": 0.034542884677648544}, {"id": 114, "seek": 74300, "start": 743.0, "end": 747.0, "text": " want to provide infrastructure using open source solutions. They need more than just", "tokens": [50364, 528, 281, 2893, 6896, 1228, 1269, 4009, 6547, 13, 814, 643, 544, 813, 445, 50564], "temperature": 0.0, "avg_logprob": -0.20206988941539417, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.012798838317394257}, {"id": 115, "seek": 74300, "start": 747.0, "end": 752.0, "text": " OpenStack. They need all the help they can get. So, that's why we formed the OpenInfra", "tokens": [50564, 7238, 4520, 501, 13, 814, 643, 439, 264, 854, 436, 393, 483, 13, 407, 11, 300, 311, 983, 321, 8693, 264, 7238, 4575, 69, 424, 50814], "temperature": 0.0, "avg_logprob": -0.20206988941539417, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.012798838317394257}, {"id": 116, "seek": 74300, "start": 752.0, "end": 757.0, "text": " Foundation, and we have more than OpenStack now. We also have Kata containers, or Zoo,", "tokens": [50814, 10335, 11, 293, 321, 362, 544, 813, 7238, 4520, 501, 586, 13, 492, 611, 362, 591, 3274, 17089, 11, 420, 34589, 11, 51064], "temperature": 0.0, "avg_logprob": -0.20206988941539417, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.012798838317394257}, {"id": 117, "seek": 74300, "start": 757.0, "end": 764.0, "text": " or Starling eggs, or other projects. All about providing infrastructure for open source", "tokens": [51064, 420, 5705, 1688, 6466, 11, 420, 661, 4455, 13, 1057, 466, 6530, 6896, 337, 1269, 4009, 51414], "temperature": 0.0, "avg_logprob": -0.20206988941539417, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.012798838317394257}, {"id": 118, "seek": 74300, "start": 764.0, "end": 772.0, "text": " solutions for open source providers. Back to OpenStack. If OpenStack is not dead, what", "tokens": [51414, 6547, 337, 1269, 4009, 11330, 13, 5833, 281, 7238, 4520, 501, 13, 759, 7238, 4520, 501, 307, 406, 3116, 11, 437, 51814], "temperature": 0.0, "avg_logprob": -0.20206988941539417, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.012798838317394257}, {"id": 119, "seek": 77200, "start": 772.0, "end": 778.0, "text": " makes it relevant for the next year? Why would you care? Why should we just all use", "tokens": [50364, 1669, 309, 7340, 337, 264, 958, 1064, 30, 1545, 576, 291, 1127, 30, 1545, 820, 321, 445, 439, 764, 50664], "temperature": 0.0, "avg_logprob": -0.19726375823325298, "compression_ratio": 1.5446428571428572, "no_speech_prob": 0.03608196973800659}, {"id": 120, "seek": 77200, "start": 778.0, "end": 783.0, "text": " public peer for the hyperscaler of public clouds and not care about infrastructure?", "tokens": [50664, 1908, 15108, 337, 264, 7420, 433, 9895, 260, 295, 1908, 12193, 293, 406, 1127, 466, 6896, 30, 50914], "temperature": 0.0, "avg_logprob": -0.19726375823325298, "compression_ratio": 1.5446428571428572, "no_speech_prob": 0.03608196973800659}, {"id": 121, "seek": 77200, "start": 783.0, "end": 790.0, "text": " I mean, hyperscalers are not going away. Amazon will be there tomorrow. The initial goal of", "tokens": [50914, 286, 914, 11, 7420, 433, 9895, 433, 366, 406, 516, 1314, 13, 6795, 486, 312, 456, 4153, 13, 440, 5883, 3387, 295, 51264], "temperature": 0.0, "avg_logprob": -0.19726375823325298, "compression_ratio": 1.5446428571428572, "no_speech_prob": 0.03608196973800659}, {"id": 122, "seek": 77200, "start": 790.0, "end": 797.0, "text": " OpenStack ends all the Amazons. It's not going to happen, it's fine. But we think it's", "tokens": [51264, 7238, 4520, 501, 5314, 439, 264, 2012, 921, 892, 13, 467, 311, 406, 516, 281, 1051, 11, 309, 311, 2489, 13, 583, 321, 519, 309, 311, 51614], "temperature": 0.0, "avg_logprob": -0.19726375823325298, "compression_ratio": 1.5446428571428572, "no_speech_prob": 0.03608196973800659}, {"id": 123, "seek": 79700, "start": 797.0, "end": 802.0, "text": " important that there is open source solutions for providing infrastructure. There is an", "tokens": [50364, 1021, 300, 456, 307, 1269, 4009, 6547, 337, 6530, 6896, 13, 821, 307, 364, 50614], "temperature": 0.0, "avg_logprob": -0.18823255251531731, "compression_ratio": 1.6394230769230769, "no_speech_prob": 0.04261637479066849}, {"id": 124, "seek": 79700, "start": 802.0, "end": 813.0, "text": " option there. The reason for that is that there is this combination of solutions that", "tokens": [50614, 3614, 456, 13, 440, 1778, 337, 300, 307, 300, 456, 307, 341, 6562, 295, 6547, 300, 51164], "temperature": 0.0, "avg_logprob": -0.18823255251531731, "compression_ratio": 1.6394230769230769, "no_speech_prob": 0.04261637479066849}, {"id": 125, "seek": 79700, "start": 813.0, "end": 818.0, "text": " you can use. Basically, Linux and the organic system layer, OpenStack and the cloud", "tokens": [51164, 291, 393, 764, 13, 8537, 11, 18734, 293, 264, 10220, 1185, 4583, 11, 7238, 4520, 501, 293, 264, 4588, 51414], "temperature": 0.0, "avg_logprob": -0.18823255251531731, "compression_ratio": 1.6394230769230769, "no_speech_prob": 0.04261637479066849}, {"id": 126, "seek": 79700, "start": 818.0, "end": 823.0, "text": " APIs layer, combined with Kubernetes and the application deployment layer. And that", "tokens": [51414, 21445, 4583, 11, 9354, 365, 23145, 293, 264, 3861, 19317, 4583, 13, 400, 300, 51664], "temperature": 0.0, "avg_logprob": -0.18823255251531731, "compression_ratio": 1.6394230769230769, "no_speech_prob": 0.04261637479066849}, {"id": 127, "seek": 82300, "start": 823.0, "end": 829.0, "text": " forms an end-to-end solution for providing infrastructure using purely open source", "tokens": [50364, 6422, 364, 917, 12, 1353, 12, 521, 3827, 337, 6530, 6896, 1228, 17491, 1269, 4009, 50664], "temperature": 0.0, "avg_logprob": -0.158743953704834, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.054832153022289276}, {"id": 128, "seek": 82300, "start": 829.0, "end": 834.0, "text": " software. That's what we call the log stack. So, Linux, OpenStack, Kubernetes,", "tokens": [50664, 4722, 13, 663, 311, 437, 321, 818, 264, 3565, 8630, 13, 407, 11, 18734, 11, 7238, 4520, 501, 11, 23145, 11, 50914], "temperature": 0.0, "avg_logprob": -0.158743953704834, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.054832153022289276}, {"id": 129, "seek": 82300, "start": 834.0, "end": 839.0, "text": " and infrastructure. End-to-end solution to provide basic infrastructure to run cloud", "tokens": [50914, 293, 6896, 13, 6967, 12, 1353, 12, 521, 3827, 281, 2893, 3875, 6896, 281, 1190, 4588, 51164], "temperature": 0.0, "avg_logprob": -0.158743953704834, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.054832153022289276}, {"id": 130, "seek": 82300, "start": 839.0, "end": 844.0, "text": " native orchestration on and for public and for private cloud. It's a very popular", "tokens": [51164, 8470, 14161, 2405, 322, 293, 337, 1908, 293, 337, 4551, 4588, 13, 467, 311, 257, 588, 3743, 51414], "temperature": 0.0, "avg_logprob": -0.158743953704834, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.054832153022289276}, {"id": 131, "seek": 82300, "start": 844.0, "end": 850.0, "text": " combination to use all of them together. But why would you use it? Why would you go", "tokens": [51414, 6562, 281, 764, 439, 295, 552, 1214, 13, 583, 983, 576, 291, 764, 309, 30, 1545, 576, 291, 352, 51714], "temperature": 0.0, "avg_logprob": -0.158743953704834, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.054832153022289276}, {"id": 132, "seek": 85000, "start": 850.0, "end": 857.0, "text": " through the hustle of running your own? There are like three main reasons to do that.", "tokens": [50364, 807, 264, 34639, 295, 2614, 428, 1065, 30, 821, 366, 411, 1045, 2135, 4112, 281, 360, 300, 13, 50714], "temperature": 0.0, "avg_logprob": -0.13400517569647896, "compression_ratio": 1.5021097046413503, "no_speech_prob": 0.09511996060609818}, {"id": 133, "seek": 85000, "start": 857.0, "end": 863.0, "text": " That's the cost, compliance and capabilities. It's a framework that's been there for a while.", "tokens": [50714, 663, 311, 264, 2063, 11, 15882, 293, 10862, 13, 467, 311, 257, 8388, 300, 311, 668, 456, 337, 257, 1339, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13400517569647896, "compression_ratio": 1.5021097046413503, "no_speech_prob": 0.09511996060609818}, {"id": 134, "seek": 85000, "start": 863.0, "end": 870.0, "text": " We first talked about it in 2017. But it's more relevant than ever today. So, for example,", "tokens": [51014, 492, 700, 2825, 466, 309, 294, 6591, 13, 583, 309, 311, 544, 7340, 813, 1562, 965, 13, 407, 11, 337, 1365, 11, 51364], "temperature": 0.0, "avg_logprob": -0.13400517569647896, "compression_ratio": 1.5021097046413503, "no_speech_prob": 0.09511996060609818}, {"id": 135, "seek": 85000, "start": 870.0, "end": 876.0, "text": " if you look at cost, there was this study by Amazon over its last year about the cost", "tokens": [51364, 498, 291, 574, 412, 2063, 11, 456, 390, 341, 2979, 538, 6795, 670, 1080, 1036, 1064, 466, 264, 2063, 51664], "temperature": 0.0, "avg_logprob": -0.13400517569647896, "compression_ratio": 1.5021097046413503, "no_speech_prob": 0.09511996060609818}, {"id": 136, "seek": 87600, "start": 876.0, "end": 883.0, "text": " of cloud. And that's the idea of venture executives. They are not financial business.", "tokens": [50364, 295, 4588, 13, 400, 300, 311, 264, 1558, 295, 18474, 28485, 13, 814, 366, 406, 4669, 1606, 13, 50714], "temperature": 0.0, "avg_logprob": -0.22255777701353416, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.04323446750640869}, {"id": 137, "seek": 87600, "start": 883.0, "end": 889.0, "text": " They looked at the cost of operating all those startups on top of Amazon Web Services", "tokens": [50714, 814, 2956, 412, 264, 2063, 295, 7447, 439, 729, 28041, 322, 1192, 295, 6795, 9573, 12124, 51014], "temperature": 0.0, "avg_logprob": -0.22255777701353416, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.04323446750640869}, {"id": 138, "seek": 87600, "start": 889.0, "end": 896.0, "text": " and Microsoft. And they found that when those companies would repatriate their", "tokens": [51014, 293, 8116, 13, 400, 436, 1352, 300, 562, 729, 3431, 576, 1085, 31674, 473, 641, 51364], "temperature": 0.0, "avg_logprob": -0.22255777701353416, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.04323446750640869}, {"id": 139, "seek": 87600, "start": 896.0, "end": 902.0, "text": " workloads locally, they would save half to two thirds of the cost. So, they would get", "tokens": [51364, 32452, 16143, 11, 436, 576, 3155, 1922, 281, 732, 34552, 295, 264, 2063, 13, 407, 11, 436, 576, 483, 51664], "temperature": 0.0, "avg_logprob": -0.22255777701353416, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.04323446750640869}, {"id": 140, "seek": 90200, "start": 902.0, "end": 909.0, "text": " from 50 to 66 percent cost reduction by repatriating their workloads in the private", "tokens": [50364, 490, 2625, 281, 21126, 3043, 2063, 11004, 538, 1085, 31674, 990, 641, 32452, 294, 264, 4551, 50714], "temperature": 0.0, "avg_logprob": -0.11815564632415772, "compression_ratio": 1.6945812807881773, "no_speech_prob": 0.0020178696140646935}, {"id": 141, "seek": 90200, "start": 909.0, "end": 917.0, "text": " cloud. And the reason for that is once you get a stable workload, once you get a stable", "tokens": [50714, 4588, 13, 400, 264, 1778, 337, 300, 307, 1564, 291, 483, 257, 8351, 20139, 11, 1564, 291, 483, 257, 8351, 51114], "temperature": 0.0, "avg_logprob": -0.11815564632415772, "compression_ratio": 1.6945812807881773, "no_speech_prob": 0.0020178696140646935}, {"id": 142, "seek": 90200, "start": 917.0, "end": 922.0, "text": " workload, public infrastructure is great to handle the elasticity, the growth, all of", "tokens": [51114, 20139, 11, 1908, 6896, 307, 869, 281, 4813, 264, 46260, 11, 264, 4599, 11, 439, 295, 51364], "temperature": 0.0, "avg_logprob": -0.11815564632415772, "compression_ratio": 1.6945812807881773, "no_speech_prob": 0.0020178696140646935}, {"id": 143, "seek": 90200, "start": 922.0, "end": 927.0, "text": " those things. But once you have a stable workload, it's an exceptionally costly way of", "tokens": [51364, 729, 721, 13, 583, 1564, 291, 362, 257, 8351, 20139, 11, 309, 311, 364, 37807, 28328, 636, 295, 51614], "temperature": 0.0, "avg_logprob": -0.11815564632415772, "compression_ratio": 1.6945812807881773, "no_speech_prob": 0.0020178696140646935}, {"id": 144, "seek": 92700, "start": 927.0, "end": 932.0, "text": " finding infrastructure. And so, the ideal model is a hybrid model where you use private", "tokens": [50364, 5006, 6896, 13, 400, 370, 11, 264, 7157, 2316, 307, 257, 13051, 2316, 689, 291, 764, 4551, 50614], "temperature": 0.0, "avg_logprob": -0.28078058242797854, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.1402089148759842}, {"id": 145, "seek": 92700, "start": 932.0, "end": 938.0, "text": " infrastructure for the base and public infrastructure for the spikes.", "tokens": [50614, 6896, 337, 264, 3096, 293, 1908, 6896, 337, 264, 28997, 13, 50914], "temperature": 0.0, "avg_logprob": -0.28078058242797854, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.1402089148759842}, {"id": 146, "seek": 92700, "start": 938.0, "end": 944.0, "text": " Compliance. I'll try to go fast. So, digital service IT is a big topic. There is a full", "tokens": [50914, 33736, 6276, 13, 286, 603, 853, 281, 352, 2370, 13, 407, 11, 4562, 2643, 6783, 307, 257, 955, 4829, 13, 821, 307, 257, 1577, 51214], "temperature": 0.0, "avg_logprob": -0.28078058242797854, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.1402089148759842}, {"id": 147, "seek": 92700, "start": 944.0, "end": 950.0, "text": " development service cloud this afternoon. So, you should go there if you like that you", "tokens": [51214, 3250, 2643, 4588, 341, 6499, 13, 407, 11, 291, 820, 352, 456, 498, 291, 411, 300, 291, 51514], "temperature": 0.0, "avg_logprob": -0.28078058242797854, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.1402089148759842}, {"id": 148, "seek": 92700, "start": 950.0, "end": 955.0, "text": " will be running right now. So, it drives a lot of open stack adoption, especially in", "tokens": [51514, 486, 312, 2614, 558, 586, 13, 407, 11, 309, 11754, 257, 688, 295, 1269, 8630, 19215, 11, 2318, 294, 51764], "temperature": 0.0, "avg_logprob": -0.28078058242797854, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.1402089148759842}, {"id": 149, "seek": 95500, "start": 955.0, "end": 960.0, "text": " South-East Asia. Not in the U.S. I don't really care that much. But for open stack, it's", "tokens": [50364, 4242, 12, 36, 525, 10038, 13, 1726, 294, 264, 624, 13, 50, 13, 286, 500, 380, 534, 1127, 300, 709, 13, 583, 337, 1269, 8630, 11, 309, 311, 50614], "temperature": 0.0, "avg_logprob": -0.1966294984559755, "compression_ratio": 1.5765124555160142, "no_speech_prob": 0.24297091364860535}, {"id": 150, "seek": 95500, "start": 960.0, "end": 964.0, "text": " clearly where the growth is. All the research institutions need to have their own thing.", "tokens": [50614, 4448, 689, 264, 4599, 307, 13, 1057, 264, 2132, 8142, 643, 281, 362, 641, 1065, 551, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1966294984559755, "compression_ratio": 1.5765124555160142, "no_speech_prob": 0.24297091364860535}, {"id": 151, "seek": 95500, "start": 964.0, "end": 970.0, "text": " All the EU countries want to have solutions that are local. And that drives a lot of", "tokens": [50814, 1057, 264, 10887, 3517, 528, 281, 362, 6547, 300, 366, 2654, 13, 400, 300, 11754, 257, 688, 295, 51114], "temperature": 0.0, "avg_logprob": -0.1966294984559755, "compression_ratio": 1.5765124555160142, "no_speech_prob": 0.24297091364860535}, {"id": 152, "seek": 95500, "start": 970.0, "end": 977.0, "text": " adoption today. Most of that 25 to 40 million job is probably linked to digital service.", "tokens": [51114, 19215, 965, 13, 4534, 295, 300, 3552, 281, 3356, 2459, 1691, 307, 1391, 9408, 281, 4562, 2643, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1966294984559755, "compression_ratio": 1.5765124555160142, "no_speech_prob": 0.24297091364860535}, {"id": 153, "seek": 95500, "start": 977.0, "end": 984.0, "text": " And finally, there is this capability state. You would think that cloud is a pretty defined", "tokens": [51464, 400, 2721, 11, 456, 307, 341, 13759, 1785, 13, 509, 576, 519, 300, 4588, 307, 257, 1238, 7642, 51814], "temperature": 0.0, "avg_logprob": -0.1966294984559755, "compression_ratio": 1.5765124555160142, "no_speech_prob": 0.24297091364860535}, {"id": 154, "seek": 98400, "start": 984.0, "end": 990.0, "text": " space by now. It's been around for a while. But there are new use cases. And those new", "tokens": [50364, 1901, 538, 586, 13, 467, 311, 668, 926, 337, 257, 1339, 13, 583, 456, 366, 777, 764, 3331, 13, 400, 729, 777, 50664], "temperature": 0.0, "avg_logprob": -0.1492152554648263, "compression_ratio": 1.5992779783393503, "no_speech_prob": 0.04456425830721855}, {"id": 155, "seek": 98400, "start": 990.0, "end": 995.0, "text": " use cases are enabled by the fact that you have a solution to experiment and play with.", "tokens": [50664, 764, 3331, 366, 15172, 538, 264, 1186, 300, 291, 362, 257, 3827, 281, 5120, 293, 862, 365, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1492152554648263, "compression_ratio": 1.5992779783393503, "no_speech_prob": 0.04456425830721855}, {"id": 156, "seek": 98400, "start": 995.0, "end": 1001.0, "text": " Like, for example, we have this company called OneCode that is running game servers in a small", "tokens": [50914, 1743, 11, 337, 1365, 11, 321, 362, 341, 2237, 1219, 1485, 34, 1429, 300, 307, 2614, 1216, 15909, 294, 257, 1359, 51214], "temperature": 0.0, "avg_logprob": -0.1492152554648263, "compression_ratio": 1.5992779783393503, "no_speech_prob": 0.04456425830721855}, {"id": 157, "seek": 98400, "start": 1001.0, "end": 1007.0, "text": " island in the middle of the Pacific Ocean that sits on top of Internet cables. Because", "tokens": [51214, 6077, 294, 264, 2808, 295, 264, 13335, 18101, 300, 12696, 322, 1192, 295, 7703, 17555, 13, 1436, 51514], "temperature": 0.0, "avg_logprob": -0.1492152554648263, "compression_ratio": 1.5992779783393503, "no_speech_prob": 0.04456425830721855}, {"id": 158, "seek": 98400, "start": 1007.0, "end": 1012.0, "text": " what they want to provide is equal latency to players in the U.S., in China, in Japan,", "tokens": [51514, 437, 436, 528, 281, 2893, 307, 2681, 27043, 281, 4150, 294, 264, 624, 13, 50, 7933, 294, 3533, 11, 294, 3367, 11, 51764], "temperature": 0.0, "avg_logprob": -0.1492152554648263, "compression_ratio": 1.5992779783393503, "no_speech_prob": 0.04456425830721855}, {"id": 159, "seek": 101200, "start": 1012.0, "end": 1018.0, "text": " and in Australia, which is quite a corner case, I guess. But they couldn't wait until...", "tokens": [50364, 293, 294, 7060, 11, 597, 307, 1596, 257, 4538, 1389, 11, 286, 2041, 13, 583, 436, 2809, 380, 1699, 1826, 485, 50664], "temperature": 0.0, "avg_logprob": -0.22446147255275561, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.07789294421672821}, {"id": 160, "seek": 101200, "start": 1018.0, "end": 1025.0, "text": " And they, like, post-game e-sports tournaments. They could have waited for Amazon Web Services", "tokens": [50664, 400, 436, 11, 411, 11, 2183, 12, 15038, 308, 12, 82, 17845, 32004, 13, 814, 727, 362, 15240, 337, 6795, 9573, 12124, 51014], "temperature": 0.0, "avg_logprob": -0.22446147255275561, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.07789294421672821}, {"id": 161, "seek": 101200, "start": 1025.0, "end": 1031.0, "text": " to set up the data center there, but it probably would never have happened. So clearly, one", "tokens": [51014, 281, 992, 493, 264, 1412, 3056, 456, 11, 457, 309, 1391, 576, 1128, 362, 2011, 13, 407, 4448, 11, 472, 51314], "temperature": 0.0, "avg_logprob": -0.22446147255275561, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.07789294421672821}, {"id": 162, "seek": 101200, "start": 1031.0, "end": 1036.0, "text": " use case that could not be served without an open source option out there. Closer up to", "tokens": [51314, 764, 1389, 300, 727, 406, 312, 7584, 1553, 364, 1269, 4009, 3614, 484, 456, 13, 2033, 22150, 493, 281, 51564], "temperature": 0.0, "avg_logprob": -0.22446147255275561, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.07789294421672821}, {"id": 163, "seek": 103600, "start": 1036.0, "end": 1043.0, "text": " here, Exion is a French subsidiary of ETF for French people in the room. That's where most", "tokens": [50364, 510, 11, 2111, 313, 307, 257, 5522, 48296, 822, 295, 37436, 337, 5522, 561, 294, 264, 1808, 13, 663, 311, 689, 881, 50714], "temperature": 0.0, "avg_logprob": -0.12785725313074447, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.5144102573394775}, {"id": 164, "seek": 103600, "start": 1043.0, "end": 1049.0, "text": " of our electricity is coming from. And so they had those super calculators that are used", "tokens": [50714, 295, 527, 10356, 307, 1348, 490, 13, 400, 370, 436, 632, 729, 1687, 4322, 3391, 300, 366, 1143, 51014], "temperature": 0.0, "avg_logprob": -0.12785725313074447, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.5144102573394775}, {"id": 165, "seek": 103600, "start": 1049.0, "end": 1054.0, "text": " for nuclear plant simulation that are regularly decommissioned because clearly they need more", "tokens": [51014, 337, 8179, 3709, 16575, 300, 366, 11672, 979, 1204, 3106, 292, 570, 4448, 436, 643, 544, 51264], "temperature": 0.0, "avg_logprob": -0.12785725313074447, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.5144102573394775}, {"id": 166, "seek": 103600, "start": 1054.0, "end": 1061.0, "text": " power to simulate what's happening in there. And what they used to do is they would just", "tokens": [51264, 1347, 281, 27817, 437, 311, 2737, 294, 456, 13, 400, 437, 436, 1143, 281, 360, 307, 436, 576, 445, 51614], "temperature": 0.0, "avg_logprob": -0.12785725313074447, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.5144102573394775}, {"id": 167, "seek": 106100, "start": 1061.0, "end": 1067.0, "text": " put them to school. And what that guy at Exion decided to do is to actually repurpose that", "tokens": [50364, 829, 552, 281, 1395, 13, 400, 437, 300, 2146, 412, 2111, 313, 3047, 281, 360, 307, 281, 767, 1085, 31345, 300, 50664], "temperature": 0.0, "avg_logprob": -0.22006074933038242, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.22650888562202454}, {"id": 168, "seek": 106100, "start": 1067.0, "end": 1076.0, "text": " into high-density, super-converged clouds that basically use the resources that are within", "tokens": [50664, 666, 1090, 12, 67, 6859, 11, 1687, 12, 1671, 331, 3004, 12193, 300, 1936, 764, 264, 3593, 300, 366, 1951, 51114], "temperature": 0.0, "avg_logprob": -0.22006074933038242, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.22650888562202454}, {"id": 169, "seek": 106100, "start": 1076.0, "end": 1082.0, "text": " those super calculators. And they are running HPC as a service, like workloads, with an", "tokens": [51114, 729, 1687, 4322, 3391, 13, 400, 436, 366, 2614, 12557, 34, 382, 257, 2643, 11, 411, 32452, 11, 365, 364, 51414], "temperature": 0.0, "avg_logprob": -0.22006074933038242, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.22650888562202454}, {"id": 170, "seek": 108200, "start": 1082.0, "end": 1090.0, "text": " high environmental impact. Because since they got the servers for free from climate impact,", "tokens": [50364, 1090, 8303, 2712, 13, 1436, 1670, 436, 658, 264, 15909, 337, 1737, 490, 5659, 2712, 11, 50764], "temperature": 0.0, "avg_logprob": -0.20190372467041015, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.18681621551513672}, {"id": 171, "seek": 108200, "start": 1090.0, "end": 1096.0, "text": " they're also tracking exactly the mixed energy mix of your workloads based on when you run", "tokens": [50764, 436, 434, 611, 11603, 2293, 264, 7467, 2281, 2890, 295, 428, 32452, 2361, 322, 562, 291, 1190, 51064], "temperature": 0.0, "avg_logprob": -0.20190372467041015, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.18681621551513672}, {"id": 172, "seek": 108200, "start": 1096.0, "end": 1102.0, "text": " them so that they track the environmental impact of your workloads as well. And finally,", "tokens": [51064, 552, 370, 300, 436, 2837, 264, 8303, 2712, 295, 428, 32452, 382, 731, 13, 400, 2721, 11, 51364], "temperature": 0.0, "avg_logprob": -0.20190372467041015, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.18681621551513672}, {"id": 173, "seek": 108200, "start": 1102.0, "end": 1109.0, "text": " LeafCloud is a public cloud based in Amsterdam where they actually distribute the compute", "tokens": [51364, 32290, 32787, 307, 257, 1908, 4588, 2361, 294, 28291, 689, 436, 767, 20594, 264, 14722, 51714], "temperature": 0.0, "avg_logprob": -0.20190372467041015, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.18681621551513672}, {"id": 174, "seek": 110900, "start": 1109.0, "end": 1116.0, "text": " servers all over the city. And those are used to heat the water for those buildings.", "tokens": [50364, 15909, 439, 670, 264, 2307, 13, 400, 729, 366, 1143, 281, 3738, 264, 1281, 337, 729, 7446, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11652172803878784, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.10500132292509079}, {"id": 175, "seek": 110900, "start": 1116.0, "end": 1125.0, "text": " Swimming pools, apartment complexes, all of them being served by those servers. So clearly,", "tokens": [50714, 3926, 40471, 28688, 11, 9587, 43676, 11, 439, 295, 552, 885, 7584, 538, 729, 15909, 13, 407, 4448, 11, 51164], "temperature": 0.0, "avg_logprob": -0.11652172803878784, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.10500132292509079}, {"id": 176, "seek": 110900, "start": 1125.0, "end": 1130.0, "text": " again, a corner case because Amsterdam has those black fiber things between those buildings", "tokens": [51164, 797, 11, 257, 4538, 1389, 570, 28291, 575, 729, 2211, 12874, 721, 1296, 729, 7446, 51414], "temperature": 0.0, "avg_logprob": -0.11652172803878784, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.10500132292509079}, {"id": 177, "seek": 110900, "start": 1130.0, "end": 1135.0, "text": " that actually make that possible. But you end up with the data center that's really the", "tokens": [51414, 300, 767, 652, 300, 1944, 13, 583, 291, 917, 493, 365, 264, 1412, 3056, 300, 311, 534, 264, 51664], "temperature": 0.0, "avg_logprob": -0.11652172803878784, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.10500132292509079}, {"id": 178, "seek": 113500, "start": 1135.0, "end": 1140.0, "text": " most energy efficiency in the world just by doing that. And so those use cases, those", "tokens": [50364, 881, 2281, 10493, 294, 264, 1002, 445, 538, 884, 300, 13, 400, 370, 729, 764, 3331, 11, 729, 50614], "temperature": 0.0, "avg_logprob": -0.1453709602355957, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.20922894775867462}, {"id": 179, "seek": 113500, "start": 1140.0, "end": 1147.0, "text": " specific things, this kind of research innovation is enabled by opening infrastructure. So I", "tokens": [50614, 2685, 721, 11, 341, 733, 295, 2132, 8504, 307, 15172, 538, 5193, 6896, 13, 407, 286, 50964], "temperature": 0.0, "avg_logprob": -0.1453709602355957, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.20922894775867462}, {"id": 180, "seek": 113500, "start": 1147.0, "end": 1153.0, "text": " think it's simple. In conclusion, OpenStack is not dead. It has a massive user footprint.", "tokens": [50964, 519, 309, 311, 2199, 13, 682, 10063, 11, 7238, 4520, 501, 307, 406, 3116, 13, 467, 575, 257, 5994, 4195, 24222, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1453709602355957, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.20922894775867462}, {"id": 181, "seek": 113500, "start": 1153.0, "end": 1157.0, "text": " It's growing year over year. It's still one of the most active open source projects in", "tokens": [51264, 467, 311, 4194, 1064, 670, 1064, 13, 467, 311, 920, 472, 295, 264, 881, 4967, 1269, 4009, 4455, 294, 51464], "temperature": 0.0, "avg_logprob": -0.1453709602355957, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.20922894775867462}, {"id": 182, "seek": 113500, "start": 1157.0, "end": 1164.0, "text": " the world. But it might be dead to you. It's someone else's job to provide infrastructure.", "tokens": [51464, 264, 1002, 13, 583, 309, 1062, 312, 3116, 281, 291, 13, 467, 311, 1580, 1646, 311, 1691, 281, 2893, 6896, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1453709602355957, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.20922894775867462}, {"id": 183, "seek": 116400, "start": 1164.0, "end": 1173.0, "text": " It's someone else's job to care. And it's fine. It will not take over Amazon Web Services.", "tokens": [50364, 467, 311, 1580, 1646, 311, 1691, 281, 1127, 13, 400, 309, 311, 2489, 13, 467, 486, 406, 747, 670, 6795, 9573, 12124, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10645094882236437, "compression_ratio": 1.7004608294930876, "no_speech_prob": 0.011493991129100323}, {"id": 184, "seek": 116400, "start": 1173.0, "end": 1180.0, "text": " Andrea still has a job. It will not replace every technology going forward. It will not", "tokens": [50814, 24215, 920, 575, 257, 1691, 13, 467, 486, 406, 7406, 633, 2899, 516, 2128, 13, 467, 486, 406, 51164], "temperature": 0.0, "avg_logprob": -0.10645094882236437, "compression_ratio": 1.7004608294930876, "no_speech_prob": 0.011493991129100323}, {"id": 185, "seek": 116400, "start": 1180.0, "end": 1186.0, "text": " be the technology that ends all technology. But it is a necessary component in the infrastructure", "tokens": [51164, 312, 264, 2899, 300, 5314, 439, 2899, 13, 583, 309, 307, 257, 4818, 6542, 294, 264, 6896, 51464], "temperature": 0.0, "avg_logprob": -0.10645094882236437, "compression_ratio": 1.7004608294930876, "no_speech_prob": 0.011493991129100323}, {"id": 186, "seek": 116400, "start": 1186.0, "end": 1191.0, "text": " to provide investment. It's a tool for enabling hybrid usage. It's a tool for use cases that", "tokens": [51464, 281, 2893, 6078, 13, 467, 311, 257, 2290, 337, 23148, 13051, 14924, 13, 467, 311, 257, 2290, 337, 764, 3331, 300, 51714], "temperature": 0.0, "avg_logprob": -0.10645094882236437, "compression_ratio": 1.7004608294930876, "no_speech_prob": 0.011493991129100323}, {"id": 187, "seek": 119100, "start": 1191.0, "end": 1196.0, "text": " are not served by hyperscale. It's a tool for workloads which can't be served out of", "tokens": [50364, 366, 406, 7584, 538, 7420, 433, 37088, 13, 467, 311, 257, 2290, 337, 32452, 597, 393, 380, 312, 7584, 484, 295, 50614], "temperature": 0.0, "avg_logprob": -0.260883929124519, "compression_ratio": 1.4311377245508983, "no_speech_prob": 0.4287548065185547}, {"id": 188, "seek": 119100, "start": 1196.0, "end": 1202.0, "text": " U.S. based servers due to digital services. So for costs, for compliance, for catalytic", "tokens": [50614, 624, 13, 50, 13, 2361, 15909, 3462, 281, 4562, 3328, 13, 407, 337, 5497, 11, 337, 15882, 11, 337, 13192, 43658, 50914], "temperature": 0.0, "avg_logprob": -0.260883929124519, "compression_ratio": 1.4311377245508983, "no_speech_prob": 0.4287548065185547}, {"id": 189, "seek": 119100, "start": 1202.0, "end": 1207.0, "text": " reasons, OpenStack is here to stay for the next decade. Thank you.", "tokens": [50914, 4112, 11, 7238, 4520, 501, 307, 510, 281, 1754, 337, 264, 958, 10378, 13, 1044, 291, 13, 51164], "temperature": 0.0, "avg_logprob": -0.260883929124519, "compression_ratio": 1.4311377245508983, "no_speech_prob": 0.4287548065185547}, {"id": 190, "seek": 120700, "start": 1207.0, "end": 1210.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50514], "temperature": 0.0, "avg_logprob": -0.3882992024324378, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.641665518283844}, {"id": 191, "seek": 120700, "start": 1220.0, "end": 1227.0, "text": " Obviously, six years ago I went to a conference that was about using OpenStack in scientific", "tokens": [51014, 7580, 11, 2309, 924, 2057, 286, 1437, 281, 257, 7586, 300, 390, 466, 1228, 7238, 4520, 501, 294, 8134, 51364], "temperature": 0.0, "avg_logprob": -0.3882992024324378, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.641665518283844}, {"id": 192, "seek": 120700, "start": 1227.0, "end": 1234.0, "text": " and in large data analysis. The thing I came away from that conference was that OpenStack", "tokens": [51364, 293, 294, 2416, 1412, 5215, 13, 440, 551, 286, 1361, 1314, 490, 300, 7586, 390, 300, 7238, 4520, 501, 51714], "temperature": 0.0, "avg_logprob": -0.3882992024324378, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.641665518283844}, {"id": 193, "seek": 123400, "start": 1234.0, "end": 1239.0, "text": " was really complicated to set up. And your only hope of getting something working was the", "tokens": [50364, 390, 534, 6179, 281, 992, 493, 13, 400, 428, 787, 1454, 295, 1242, 746, 1364, 390, 264, 50614], "temperature": 0.0, "avg_logprob": -0.3402378197872277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.17885702848434448}, {"id": 194, "seek": 123400, "start": 1239.0, "end": 1245.0, "text": " higher-end app to do it for you. So is that, I mean, is that kind of, I mean, is that", "tokens": [50614, 2946, 12, 521, 724, 281, 360, 309, 337, 291, 13, 407, 307, 300, 11, 286, 914, 11, 307, 300, 733, 295, 11, 286, 914, 11, 307, 300, 50914], "temperature": 0.0, "avg_logprob": -0.3402378197872277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.17885702848434448}, {"id": 195, "seek": 123400, "start": 1245.0, "end": 1248.0, "text": " the part because of the scope, I think, that now that you've focused on is kind of easy", "tokens": [50914, 264, 644, 570, 295, 264, 11923, 11, 286, 519, 11, 300, 586, 300, 291, 600, 5178, 322, 307, 733, 295, 1858, 51064], "temperature": 0.0, "avg_logprob": -0.3402378197872277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.17885702848434448}, {"id": 196, "seek": 123400, "start": 1248.0, "end": 1250.0, "text": " to set up, or can you take a comment on that?", "tokens": [51064, 281, 992, 493, 11, 420, 393, 291, 747, 257, 2871, 322, 300, 30, 51164], "temperature": 0.0, "avg_logprob": -0.3402378197872277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.17885702848434448}, {"id": 197, "seek": 123400, "start": 1250.0, "end": 1255.0, "text": " So the question is, OpenStack has this information of being very hard to set up, and", "tokens": [51164, 407, 264, 1168, 307, 11, 7238, 4520, 501, 575, 341, 1589, 295, 885, 588, 1152, 281, 992, 493, 11, 293, 51414], "temperature": 0.0, "avg_logprob": -0.3402378197872277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.17885702848434448}, {"id": 198, "seek": 123400, "start": 1255.0, "end": 1260.0, "text": " this message that you have to hire somebody who will do it for you, is it still the case", "tokens": [51414, 341, 3636, 300, 291, 362, 281, 11158, 2618, 567, 486, 360, 309, 337, 291, 11, 307, 309, 920, 264, 1389, 51664], "temperature": 0.0, "avg_logprob": -0.3402378197872277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.17885702848434448}, {"id": 199, "seek": 126000, "start": 1260.0, "end": 1264.0, "text": " and what's the minimum cost?", "tokens": [50364, 293, 437, 311, 264, 7285, 2063, 30, 50564], "temperature": 0.0, "avg_logprob": -0.20698977018657483, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.0438314825296402}, {"id": 200, "seek": 126000, "start": 1264.0, "end": 1270.0, "text": " So I would say, I mean, it's still a complex job to run infrastructure, like for various", "tokens": [50564, 407, 286, 576, 584, 11, 286, 914, 11, 309, 311, 920, 257, 3997, 1691, 281, 1190, 6896, 11, 411, 337, 3683, 50864], "temperature": 0.0, "avg_logprob": -0.20698977018657483, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.0438314825296402}, {"id": 201, "seek": 126000, "start": 1270.0, "end": 1278.0, "text": " reasons, mostly because of the 24-hour type service constraints, one of those things.", "tokens": [50864, 4112, 11, 5240, 570, 295, 264, 4022, 12, 18048, 2010, 2643, 18491, 11, 472, 295, 729, 721, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20698977018657483, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.0438314825296402}, {"id": 202, "seek": 126000, "start": 1278.0, "end": 1282.0, "text": " But I would say that running OpenStack has gotten a lot easier, especially one of the", "tokens": [51264, 583, 286, 576, 584, 300, 2614, 7238, 4520, 501, 575, 5768, 257, 688, 3571, 11, 2318, 472, 295, 264, 51464], "temperature": 0.0, "avg_logprob": -0.20698977018657483, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.0438314825296402}, {"id": 203, "seek": 126000, "start": 1282.0, "end": 1287.0, "text": " big concerns, but not necessarily the scope, because you can just deploy a few services.", "tokens": [51464, 955, 7389, 11, 457, 406, 4725, 264, 11923, 11, 570, 291, 393, 445, 7274, 257, 1326, 3328, 13, 51714], "temperature": 0.0, "avg_logprob": -0.20698977018657483, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.0438314825296402}, {"id": 204, "seek": 128700, "start": 1287.0, "end": 1291.0, "text": " And it wasn't really affecting that. And today, yes, there is less scope.", "tokens": [50364, 400, 309, 2067, 380, 534, 17476, 300, 13, 400, 965, 11, 2086, 11, 456, 307, 1570, 11923, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2488185805503768, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.3470991849899292}, {"id": 205, "seek": 128700, "start": 1291.0, "end": 1297.0, "text": " We've focused on the main pieces. It was really more the upgrade cycle.", "tokens": [50564, 492, 600, 5178, 322, 264, 2135, 3755, 13, 467, 390, 534, 544, 264, 11484, 6586, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2488185805503768, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.3470991849899292}, {"id": 206, "seek": 128700, "start": 1297.0, "end": 1303.0, "text": " If you wanted to keep up to date with the release that were produced, it created a lot of", "tokens": [50864, 759, 291, 1415, 281, 1066, 493, 281, 4002, 365, 264, 4374, 300, 645, 7126, 11, 309, 2942, 257, 688, 295, 51164], "temperature": 0.0, "avg_logprob": -0.2488185805503768, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.3470991849899292}, {"id": 207, "seek": 128700, "start": 1303.0, "end": 1307.0, "text": " tension because every six months you would have to upgrade your infrastructure if you", "tokens": [51164, 8980, 570, 633, 2309, 2493, 291, 576, 362, 281, 11484, 428, 6896, 498, 291, 51364], "temperature": 0.0, "avg_logprob": -0.2488185805503768, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.3470991849899292}, {"id": 208, "seek": 128700, "start": 1307.0, "end": 1313.0, "text": " wanted to do that. And so the work was done to really make those upgrades a lot more", "tokens": [51364, 1415, 281, 360, 300, 13, 400, 370, 264, 589, 390, 1096, 281, 534, 652, 729, 24868, 257, 688, 544, 51664], "temperature": 0.0, "avg_logprob": -0.2488185805503768, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.3470991849899292}, {"id": 209, "seek": 131300, "start": 1313.0, "end": 1322.0, "text": " streamlined. There is a lot less breaking changes happening, because the pace of, I would", "tokens": [50364, 48155, 13, 821, 307, 257, 688, 1570, 7697, 2962, 2737, 11, 570, 264, 11638, 295, 11, 286, 576, 50814], "temperature": 0.0, "avg_logprob": -0.3174649477005005, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.06547508388757706}, {"id": 210, "seek": 131300, "start": 1322.0, "end": 1327.0, "text": " say, new future development is still going on in the maintenance and maintenance mode.", "tokens": [50814, 584, 11, 777, 2027, 3250, 307, 920, 516, 322, 294, 264, 11258, 293, 11258, 4391, 13, 51064], "temperature": 0.0, "avg_logprob": -0.3174649477005005, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.06547508388757706}, {"id": 211, "seek": 131300, "start": 1327.0, "end": 1332.0, "text": " I believe in new hardware functions, all of those. It's more like a driver space than", "tokens": [51064, 286, 1697, 294, 777, 8837, 6828, 11, 439, 295, 729, 13, 467, 311, 544, 411, 257, 6787, 1901, 813, 51314], "temperature": 0.0, "avg_logprob": -0.3174649477005005, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.06547508388757706}, {"id": 212, "seek": 131300, "start": 1332.0, "end": 1336.0, "text": " a course space. So you see a lot less disruption when you do the upgrade.", "tokens": [51314, 257, 1164, 1901, 13, 407, 291, 536, 257, 688, 1570, 28751, 562, 291, 360, 264, 11484, 13, 51514], "temperature": 0.0, "avg_logprob": -0.3174649477005005, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.06547508388757706}, {"id": 213, "seek": 133600, "start": 1336.0, "end": 1343.0, "text": " It's also that the upgrades are much more tested. We have solutions for distributions", "tokens": [50364, 467, 311, 611, 300, 264, 24868, 366, 709, 544, 8246, 13, 492, 362, 6547, 337, 37870, 50714], "temperature": 0.0, "avg_logprob": -0.22494416120575694, "compression_ratio": 1.5825242718446602, "no_speech_prob": 0.3027697205543518}, {"id": 214, "seek": 133600, "start": 1343.0, "end": 1349.0, "text": " that can be used, that handle that, that are pretty nice, not necessarily solved by one", "tokens": [50714, 300, 393, 312, 1143, 11, 300, 4813, 300, 11, 300, 366, 1238, 1481, 11, 406, 4725, 13041, 538, 472, 51014], "temperature": 0.0, "avg_logprob": -0.22494416120575694, "compression_ratio": 1.5825242718446602, "no_speech_prob": 0.3027697205543518}, {"id": 215, "seek": 133600, "start": 1349.0, "end": 1356.0, "text": " of the players in the OpenStack space that you can rely on to actually do the updates.", "tokens": [51014, 295, 264, 4150, 294, 264, 7238, 4520, 501, 1901, 300, 291, 393, 10687, 322, 281, 767, 360, 264, 9205, 13, 51364], "temperature": 0.0, "avg_logprob": -0.22494416120575694, "compression_ratio": 1.5825242718446602, "no_speech_prob": 0.3027697205543518}, {"id": 216, "seek": 133600, "start": 1356.0, "end": 1361.0, "text": " So it's no longer that difficult, but it's still a job in itself.", "tokens": [51364, 407, 309, 311, 572, 2854, 300, 2252, 11, 457, 309, 311, 920, 257, 1691, 294, 2564, 13, 51614], "temperature": 0.0, "avg_logprob": -0.22494416120575694, "compression_ratio": 1.5825242718446602, "no_speech_prob": 0.3027697205543518}, {"id": 217, "seek": 136100, "start": 1361.0, "end": 1367.0, "text": " It's still like something that you have to talk about. It's an interesting thing to think about.", "tokens": [50364, 467, 311, 920, 411, 746, 300, 291, 362, 281, 751, 466, 13, 467, 311, 364, 1880, 551, 281, 519, 466, 13, 50664], "temperature": 0.0, "avg_logprob": -0.5000397693151715, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.6921178102493286}, {"id": 218, "seek": 136100, "start": 1367.0, "end": 1376.0, "text": " I'm always amazed when, so the use of guys are running this gigantic OpenStack to power", "tokens": [50664, 286, 478, 1009, 20507, 562, 11, 370, 264, 764, 295, 1074, 366, 2614, 341, 26800, 7238, 4520, 501, 281, 1347, 51114], "temperature": 0.0, "avg_logprob": -0.5000397693151715, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.6921178102493286}, {"id": 219, "seek": 136100, "start": 1376.0, "end": 1380.0, "text": " game servers and they are doing that to the best team of the team.", "tokens": [51114, 1216, 15909, 293, 436, 366, 884, 300, 281, 264, 1151, 1469, 295, 264, 1469, 13, 51314], "temperature": 0.0, "avg_logprob": -0.5000397693151715, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.6921178102493286}, {"id": 220, "seek": 136100, "start": 1380.0, "end": 1386.0, "text": " It's not curable not to buy yourself a new crash, but it's still doable with a relatively", "tokens": [51314, 467, 311, 406, 1262, 712, 406, 281, 2256, 1803, 257, 777, 8252, 11, 457, 309, 311, 920, 41183, 365, 257, 7226, 51614], "temperature": 0.0, "avg_logprob": -0.5000397693151715, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.6921178102493286}, {"id": 221, "seek": 138600, "start": 1386.0, "end": 1394.0, "text": " small team. And I think no big guys, they have a very large, they have a very large team.", "tokens": [50364, 1359, 1469, 13, 400, 286, 519, 572, 955, 1074, 11, 436, 362, 257, 588, 2416, 11, 436, 362, 257, 588, 2416, 1469, 13, 50764], "temperature": 0.0, "avg_logprob": -0.3726571703714038, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.7171371579170227}, {"id": 222, "seek": 138600, "start": 1394.0, "end": 1402.0, "text": " Well, it's like, it's not, it's not completely out of reach.", "tokens": [50764, 1042, 11, 309, 311, 411, 11, 309, 311, 406, 11, 309, 311, 406, 2584, 484, 295, 2524, 13, 51164], "temperature": 0.0, "avg_logprob": -0.3726571703714038, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.7171371579170227}, {"id": 223, "seek": 138600, "start": 1402.0, "end": 1407.0, "text": " The smaller it is, the less constrained there is from the users.", "tokens": [51164, 440, 4356, 309, 307, 11, 264, 1570, 38901, 456, 307, 490, 264, 5022, 13, 51414], "temperature": 0.0, "avg_logprob": -0.3726571703714038, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.7171371579170227}, {"id": 224, "seek": 140700, "start": 1407.0, "end": 1426.0, "text": " Do you think the fact that you've got 29,000 full requests over quite a number of projects", "tokens": [50364, 1144, 291, 519, 264, 1186, 300, 291, 600, 658, 9413, 11, 1360, 1577, 12475, 670, 1596, 257, 1230, 295, 4455, 51314], "temperature": 0.0, "avg_logprob": -0.22211274913713044, "compression_ratio": 1.3049645390070923, "no_speech_prob": 0.7009691596031189}, {"id": 225, "seek": 140700, "start": 1426.0, "end": 1431.0, "text": " where, you know, you've got, for example, Nova, Keystone, but you've also got some more skill", "tokens": [51314, 689, 11, 291, 458, 11, 291, 600, 658, 11, 337, 1365, 11, 27031, 11, 12759, 11243, 11, 457, 291, 600, 611, 658, 512, 544, 5389, 51564], "temperature": 0.0, "avg_logprob": -0.22211274913713044, "compression_ratio": 1.3049645390070923, "no_speech_prob": 0.7009691596031189}, {"id": 226, "seek": 143100, "start": 1431.0, "end": 1437.0, "text": " projects versus, sorry, Kubernetes, which has like one key component that everyone contributes", "tokens": [50364, 4455, 5717, 11, 2597, 11, 23145, 11, 597, 575, 411, 472, 2141, 6542, 300, 1518, 32035, 50664], "temperature": 0.0, "avg_logprob": -0.247822634379069, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.5757103562355042}, {"id": 227, "seek": 143100, "start": 1437.0, "end": 1443.0, "text": " to, based towards this perception of, you know, things don't move as fast as Kubernetes?", "tokens": [50664, 281, 11, 2361, 3030, 341, 12860, 295, 11, 291, 458, 11, 721, 500, 380, 1286, 382, 2370, 382, 23145, 30, 50964], "temperature": 0.0, "avg_logprob": -0.247822634379069, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.5757103562355042}, {"id": 228, "seek": 143100, "start": 1443.0, "end": 1450.0, "text": " No, I don't think it's, it's the fact that OpenStack is more of a collection of services", "tokens": [50964, 883, 11, 286, 500, 380, 519, 309, 311, 11, 309, 311, 264, 1186, 300, 7238, 4520, 501, 307, 544, 295, 257, 5765, 295, 3328, 51314], "temperature": 0.0, "avg_logprob": -0.247822634379069, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.5757103562355042}, {"id": 229, "seek": 143100, "start": 1450.0, "end": 1457.0, "text": " versus Kubernetes, which is much more in Monolith, could play to the, like, the scale", "tokens": [51314, 5717, 23145, 11, 597, 307, 709, 544, 294, 4713, 29131, 11, 727, 862, 281, 264, 11, 411, 11, 264, 4373, 51664], "temperature": 0.0, "avg_logprob": -0.247822634379069, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.5757103562355042}, {"id": 230, "seek": 145700, "start": 1457.0, "end": 1461.0, "text": " that people, people see as less active.", "tokens": [50364, 300, 561, 11, 561, 536, 382, 1570, 4967, 13, 50564], "temperature": 0.0, "avg_logprob": -0.4350318908691406, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.35083332657814026}, {"id": 231, "seek": 145700, "start": 1461.0, "end": 1465.0, "text": " I think there are a lot of reasons. We are not using GitHub.", "tokens": [50564, 286, 519, 456, 366, 257, 688, 295, 4112, 13, 492, 366, 406, 1228, 23331, 13, 50764], "temperature": 0.0, "avg_logprob": -0.4350318908691406, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.35083332657814026}, {"id": 232, "seek": 145700, "start": 1465.0, "end": 1470.0, "text": " We are using our own, we software tools based on Garrett and Zool.", "tokens": [50764, 492, 366, 1228, 527, 1065, 11, 321, 4722, 3873, 2361, 322, 40266, 293, 1176, 1092, 13, 51014], "temperature": 0.0, "avg_logprob": -0.4350318908691406, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.35083332657814026}, {"id": 233, "seek": 145700, "start": 1470.0, "end": 1476.0, "text": " And so, there is a bit of a visibility that is right there, because we are not appealing", "tokens": [51014, 400, 370, 11, 456, 307, 257, 857, 295, 257, 19883, 300, 307, 558, 456, 11, 570, 321, 366, 406, 23842, 51314], "temperature": 0.0, "avg_logprob": -0.4350318908691406, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.35083332657814026}, {"id": 234, "seek": 145700, "start": 1476.0, "end": 1480.0, "text": " on those, like, reports, gender reports that we are using.", "tokens": [51314, 322, 729, 11, 411, 11, 7122, 11, 7898, 7122, 300, 321, 366, 1228, 13, 51514], "temperature": 0.0, "avg_logprob": -0.4350318908691406, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.35083332657814026}, {"id": 235, "seek": 145700, "start": 1480.0, "end": 1486.0, "text": " There is this perception that all of this is happening in GitHub and everything else is not really existing.", "tokens": [51514, 821, 307, 341, 12860, 300, 439, 295, 341, 307, 2737, 294, 23331, 293, 1203, 1646, 307, 406, 534, 6741, 13, 51814], "temperature": 0.0, "avg_logprob": -0.4350318908691406, "compression_ratio": 1.7235772357723578, "no_speech_prob": 0.35083332657814026}, {"id": 236, "seek": 148600, "start": 1486.0, "end": 1489.0, "text": " So all of those things contribute to it.", "tokens": [50364, 407, 439, 295, 729, 721, 10586, 281, 309, 13, 50514], "temperature": 0.0, "avg_logprob": -0.32172630828561133, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.17372967302799225}, {"id": 237, "seek": 148600, "start": 1489.0, "end": 1495.0, "text": " The fact that it's a Monolith versus a set of projects, I don't think that plays that matter,", "tokens": [50514, 440, 1186, 300, 309, 311, 257, 4713, 29131, 5717, 257, 992, 295, 4455, 11, 286, 500, 380, 519, 300, 5749, 300, 1871, 11, 50814], "temperature": 0.0, "avg_logprob": -0.32172630828561133, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.17372967302799225}, {"id": 238, "seek": 148600, "start": 1495.0, "end": 1500.0, "text": " because if you look at the amount of development that's happening on those French services,", "tokens": [50814, 570, 498, 291, 574, 412, 264, 2372, 295, 3250, 300, 311, 2737, 322, 729, 5522, 3328, 11, 51064], "temperature": 0.0, "avg_logprob": -0.32172630828561133, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.17372967302799225}, {"id": 239, "seek": 148600, "start": 1500.0, "end": 1507.0, "text": " it's not that much. It's sort of the core of the developments we have in, you know, the I1A.", "tokens": [51064, 309, 311, 406, 300, 709, 13, 467, 311, 1333, 295, 264, 4965, 295, 264, 20862, 321, 362, 294, 11, 291, 458, 11, 264, 286, 16, 32, 13, 51414], "temperature": 0.0, "avg_logprob": -0.32172630828561133, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.17372967302799225}, {"id": 240, "seek": 148600, "start": 1507.0, "end": 1512.0, "text": " And so, it's, I would say it's not, yeah.", "tokens": [51414, 400, 370, 11, 309, 311, 11, 286, 576, 584, 309, 311, 406, 11, 1338, 13, 51664], "temperature": 0.0, "avg_logprob": -0.32172630828561133, "compression_ratio": 1.5903083700440528, "no_speech_prob": 0.17372967302799225}, {"id": 241, "seek": 151200, "start": 1513.0, "end": 1514.0, "text": " Thank you.", "tokens": [50414, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.3223141261509487, "compression_ratio": 0.8297872340425532, "no_speech_prob": 0.3686971962451935}, {"id": 242, "seek": 151200, "start": 1514.0, "end": 1516.0, "text": " I'll take questions outside.", "tokens": [50464, 286, 603, 747, 1651, 2380, 13, 50564], "temperature": 0.0, "avg_logprob": -0.3223141261509487, "compression_ratio": 0.8297872340425532, "no_speech_prob": 0.3686971962451935}], "language": "en"}